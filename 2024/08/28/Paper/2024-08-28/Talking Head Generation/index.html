<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Talking Head Generation">
    <meta name="description" content="Talking Head Generation 方向最新论文已更新，请持续关注 Update in 2024-08-28  SpeechCaps Advancing Instruction-Based Universal Speech Models with   Multi-Talker Speaking Style Captioning">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>Talking Head Generation | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/favicon.png">
    
    <style>
        body{
            background-image: url(/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/css/matery.css">
<link rel="stylesheet" type="text/css" href="/css/my.css">
<link rel="stylesheet" type="text/css" href="/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/css/post.css">




    



    <script src="/libs/jquery/jquery-3.6.0.min.js"></script>
    <script src="https://sdk.jinrishici.com/v2/browser/jinrishici.js" charset="utf-8"></script>
<meta name="generator" content="Hexo 7.3.0"></head>


<body>
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/" class="waves-effect waves-light">
                    
                    <img src="/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>首页</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>标签</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>分类</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>归档</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="搜索" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="深色/浅色模式" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			首页
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			标签
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			分类
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			归档
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://pic1.zhimg.com/v2-4760bb1b1f83c77ff470a2676d9247aa.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Talking Head Generation</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/tags/Talking-Head-Generation/">
                                <span class="chip bg-color">Talking Head Generation</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/categories/Talking-Head-Generation/" class="post-category">
                                Talking Head Generation
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2024-08-28
                </div>
                

                

                

                

                
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>⚠️ 以下所有内容总结都来自于 Google的大语言模型<a target="_blank" rel="noopener" href="https://ai.google.dev/">Gemini-Pro</a>的能力，如有错误，仅供参考，谨慎使用<br>🔴 请注意：千万不要用于严肃的学术场景，只能用于论文阅读前的初筛！<br>💗 如果您觉得我们的项目对您有帮助 <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ，还请您给我们一些鼓励！⭐️ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFace免费体验</a></p>
</blockquote>
<h1 id="2024-08-28-更新"><a href="#2024-08-28-更新" class="headerlink" title="2024-08-28 更新"></a>2024-08-28 更新</h1><h2 id="SpeechCaps-Advancing-Instruction-Based-Universal-Speech-Models-with-Multi-Talker-Speaking-Style-Captioning"><a href="#SpeechCaps-Advancing-Instruction-Based-Universal-Speech-Models-with-Multi-Talker-Speaking-Style-Captioning" class="headerlink" title="SpeechCaps: Advancing Instruction-Based Universal Speech Models with   Multi-Talker Speaking Style Captioning"></a>SpeechCaps: Advancing Instruction-Based Universal Speech Models with   Multi-Talker Speaking Style Captioning</h2><p><strong>Authors:Chien-yu Huang, Min-Han Shih, Ke-Han Lu, Chi-Yuan Hsiao, Hung-yi Lee</strong></p>
<p>Instruction-based speech processing is becoming popular. Studies show that training with multiple tasks boosts performance, but collecting diverse, large-scale tasks and datasets is expensive. Thus, it is highly desirable to design a fundamental task that benefits other downstream tasks. This paper introduces a multi-talker speaking style captioning task to enhance the understanding of speaker and prosodic information. We used large language models to generate descriptions for multi-talker speech. Then, we trained our model with pre-training on this captioning task followed by instruction tuning. Evaluation on Dynamic-SUPERB shows our model outperforming the baseline pre-trained only on single-talker tasks, particularly in speaker and emotion recognition. Additionally, tests on a multi-talker QA task reveal that current models struggle with attributes such as gender, pitch, and speaking rate. The code and dataset are available at <a target="_blank" rel="noopener" href="https://github.com/cyhuang-tw/speechcaps">https://github.com/cyhuang-tw/speechcaps</a>. </p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2408.13891v1">PDF</a> SynData4GenAI 2024</p>
<p><strong>Summary</strong><br>多说话者风格字幕任务提升语言模型在说话者和韵律信息理解上的性能。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>指令式语音处理逐渐流行。</li>
<li>多任务训练提升模型性能。</li>
<li>收集多样、大规模数据集成本高昂。</li>
<li>提出多说话者风格字幕任务作为基础任务。</li>
<li>使用大语言模型生成多说话者语音描述。</li>
<li>模型在字幕任务上进行预训练和指令微调。</li>
<li>在Dynamic-SUPERB上优于仅训练单说话者任务的基线模型。</li>
<li>在多说话者问答任务中，模型在性别、音高和语速等属性上表现不佳。</li>
<li>模型代码和数据集可在GitHub上获取。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li><p>Title: SPEECHCAPS: Advancing Instruction-Based Universal Speech Models with Multi-Talker Speaking Style Captioning (SPEECHCAPS：通过多说话人说话风格字幕任务推进基于指令的通用语音模型)</p>
</li>
<li><p>Authors: Chien-yu Huang, Min-Han Shih, Ke-Han Lu, Chi-Yuan Hsiao, Hung-yi Lee</p>
</li>
<li><p>Affiliation: National Taiwan University, Taiwan</p>
</li>
<li><p>Keywords: speech captioning, speaking style, instruction tuning, large language model</p>
</li>
<li><p>Urls: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2408.13891">https://arxiv.org/abs/2408.13891</a>, Github: <a target="_blank" rel="noopener" href="https://github.com/cyhuang-tw/speechcaps">https://github.com/cyhuang-tw/speechcaps</a></p>
</li>
<li><p>Summary:</p>
<ul>
<li><p>(1): 研究背景为基于指令的语音处理技术逐渐流行，但收集多样化的大规模任务和数据集成本高昂。因此，设计一个对下游任务有益的基础任务是高度期望的。</p>
</li>
<li><p>(2): 过去的方法包括LTU-AS、SALMONN、Qwen-Audio和WavLLM等，它们通过多任务训练或激活调整来提升性能。然而，这些方法存在数据收集成本高的问题，且对说话人和情感等任务的识别能力不足。所提出的方法是合理的，因为它旨在通过基础任务提升模型对通用语音的理解能力。</p>
</li>
<li><p>(3): 论文中提出的方法是创建一个名为SPEECHCAPS的多说话人说话风格字幕任务数据集，并使用大型语言模型生成多说话人语音的描述。然后，通过在字幕任务上进行预训练和指令调整来训练模型。</p>
</li>
<li><p>(4): 在Dynamic-SUPERB数据集上进行的评估表明，该方法在说话人和情感识别任务上优于仅对单说话人任务进行预训练的基线模型。此外，在多说话人问答任务上的测试显示，当前模型在处理性别、音调和说话速率等属性时存在困难。这些性能支持了研究的目标，即通过基础任务提升模型对说话人和韵律信息的理解。</p>
</li>
</ul>
</li>
<li><p>Conclusion:</p>
<ul>
<li><p>(1): 这项工作的重要意义在于，它提出了一种新的多说话人说话风格字幕任务（SPEECHCAPS），通过在指令基础上对通用语音模型进行训练，有效提升了模型对说话人和韵律信息的理解能力，为基于指令的语音处理技术提供了新的研究思路和方向。</p>
</li>
<li><p>(2): Innovation point: SPEECHCAPS的创新点在于提出了一个针对多说话人说话风格字幕的任务，结合了指令调整和预训练技术，为通用语音模型的训练提供了新的视角和途径；Performance: 在Dynamic-SUPERB数据集上的评估结果显示，该方法在说话人和情感识别任务上优于基线模型，但在多说话人问答任务上仍存在一些困难；Workload: 该方法需要收集大量多说话人语音数据并构建相应的字幕数据集，对数据收集和标注的工作量较大。</p>
</li>
</ul>
</li>
</ol>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-8021415f823c5ce0acd5bb92d61e09b7.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-8e1c7406db684343030a6fdc9a395106.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f5d9ab1e6a16acb6ef52191ed789cd35.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-5efff236d713d07c1290261d93c716a3.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-f110c7a74d2aae8799ee5d832e200c66.jpg" align="middle">
</details>




<h2 id="TalkLoRA-Low-Rank-Adaptation-for-Speech-Driven-Animation"><a href="#TalkLoRA-Low-Rank-Adaptation-for-Speech-Driven-Animation" class="headerlink" title="TalkLoRA: Low-Rank Adaptation for Speech-Driven Animation"></a>TalkLoRA: Low-Rank Adaptation for Speech-Driven Animation</h2><p><strong>Authors:Jack Saunders, Vinay Namboodiri</strong></p>
<p>Speech-driven facial animation is important for many applications including TV, film, video games, telecommunication and AR&#x2F;VR. Recently, transformers have been shown to be extremely effective for this task. However, we identify two issues with the existing transformer-based models. Firstly, they are difficult to adapt to new personalised speaking styles and secondly, they are slow to run for long sentences due to the quadratic complexity of the transformer. We propose TalkLoRA to address both of these issues. TalkLoRA uses Low-Rank Adaptation to effectively and efficiently adapt to new speaking styles, even with limited data. It does this by training an adaptor with a small number of parameters for each subject. We also utilise a chunking strategy to reduce the complexity of the underlying transformer, allowing for long sentences at inference time. TalkLoRA can be applied to any transformer-based speech-driven animation method. We perform extensive experiments to show that TalkLoRA archives state-of-the-art style adaptation and that it allows for an order-of-complexity reduction in inference times without sacrificing quality. We also investigate and provide insights into the hyperparameter selection for LoRA fine-tuning of speech-driven facial animation models. </p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2408.13714v1">PDF</a> </p>
<p><strong>Summary</strong><br>语音驱动的面部动画对电视、电影、游戏等领域至关重要，TalkLoRA通过低秩自适应和分块策略，有效解决现有模型的问题，实现高效风格适应和快速运行。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>语音驱动的面部动画应用广泛，transformer模型有效但存在适应性和速度问题。</li>
<li>TalkLoRA通过低秩自适应适应新说话风格，适应数据有限。</li>
<li>小参数适配器实现针对不同主题的训练。</li>
<li>分块策略降低transformer复杂度，支持长句处理。</li>
<li>TalkLoRA适用于任何基于transformer的语音驱动动画方法。</li>
<li>实验证明TalkLoRA实现风格适应的突破，且不影响质量。</li>
<li>研究提供LoRA微调面部动画模型的超参数选择见解。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li><p>Title: TalkLoRA: Low-Rank Adaptation for Speech-Driven Animation<br>          (标题：TalkLoRA：用于语音驱动动画的低秩自适应)</p>
</li>
<li><p>Authors: Jack Saunders, Vinay P Namboodiri<br>          (作者：Jack Saunders, Vinay P Namboodiri)</p>
</li>
<li><p>Affiliation: University of Bath<br>          (所属机构：巴斯大学)</p>
</li>
<li><p>Keywords: Speech-Driven Animation, Transformer, Low-Rank Adaptation, Chunking<br>          (关键词：语音驱动动画，Transformer，低秩自适应，分块)</p>
</li>
<li><p>Urls: <a target="_blank" rel="noopener" href="https://jsaunders909.github.io/">https://jsaunders909.github.io/</a> or <a target="_blank" rel="noopener" href="https://vinaypn.github.io/">https://vinaypn.github.io/</a><br>          (网址：<a target="_blank" rel="noopener" href="https://jsaunders909.github.io/">https://jsaunders909.github.io/</a> 或 <a target="_blank" rel="noopener" href="https://vinaypn.github.io/">https://vinaypn.github.io/</a> , Github:None)</p>
</li>
<li><p>Summary:</p>
<pre><code>             - (1):该文章的研究背景是语音驱动面部动画在电视、电影、视频游戏、电信和AR/VR等领域的应用，而Transformer模型在此任务中表现出极高的有效性。

             - (2):过去的方法包括基于Transformer的模型，但它们难以适应新的个性化说话风格，且由于Transformer的二次复杂性，运行长句子时速度较慢。该研究方法很好地解决了这些问题。

             - (3)：该文提出的方法TalkLoRA使用低秩自适应有效地适应新的说话风格，即使数据有限。它通过为每个主题训练具有少量参数的适配器来实现。此外，还利用了分块策略来降低复杂性。

             - (4)：该方法在语音驱动动画任务上实现了有效的性能，尤其是在适应新说话风格和提高运行速度方面。其性能支持了研究目标。
</code></pre>
</li>
<li><p>Methods:</p>
<ul>
<li><p>(1): 本文针对现有的基于Transformer的语音驱动动画系统，提出了一种名为TalkLoRA的低秩自适应方法，以提升模型适应新说话风格的能力和运行速度。</p>
</li>
<li><p>(2): TalkLoRA利用低秩自适应（LoRA）技术，通过为模型添加少量参数的适配器，实现对现有模型的个性化调整。</p>
</li>
<li><p>(3): 为了降低模型复杂性，TalkLoRA引入了分块策略，将输入音频分割成重叠的固定大小的块，并行处理，从而减少Transformer的上下文窗口大小。</p>
</li>
<li><p>(4): 在音频编码器部分，由于其强大的泛化能力，TalkLoRA没有应用LoRA技术，以避免过度拟合。</p>
</li>
<li><p>(5): 对于解码器部分，TalkLoRA可以选择性地应用LoRA技术到Transformer解码器或运动解码器，以实现模型对单个身份的适应。</p>
</li>
<li><p>(6): 通过实验确定了LoRA的秩（r）的最佳值，以平衡模型的表示能力和正则化能力。</p>
</li>
<li><p>(7): 通过调整模型架构，实现Transformer的上下文窗口限制，从而提高长序列的推理速度。</p>
</li>
<li><p>(8): 在训练过程中，TalkLoRA使用AdamW优化器和适当的学习率，并在50个epoch后收敛。</p>
</li>
</ul>
</li>
<li><p>Conclusion:</p>
<pre><code>             - (1): 该研究工作的重要性在于，它提出了一种名为TalkLoRA的低秩自适应方法，有效提高了基于Transformer的语音驱动动画模型的适应性和推理速度，这对于电视、电影、视频游戏等领域的应用具有重要意义。

             - (2): Innovation point: 创新点在于提出了低秩自适应技术应用于语音驱动动画，实现了对现有模型的个性化调整，并通过分块策略降低了模型复杂性；Performance: 性能方面，TalkLoRA在适应新说话风格和提高运行速度方面均优于现有模型；Workload: 工作量方面，TalkLoRA通过优化模型架构和使用AdamW优化器等手段，使得训练过程高效且收敛。
</code></pre>
</li>
</ol>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pica.zhimg.com/v2-3313994c278d325c8ef3fb44a5ba2d76.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-7c2db76f55115f8dd725a17800048f2f.jpg" align="middle">
</details>




<h2 id="Empowering-Whisper-as-a-Joint-Multi-Talker-and-Target-Talker-Speech-Recognition-System"><a href="#Empowering-Whisper-as-a-Joint-Multi-Talker-and-Target-Talker-Speech-Recognition-System" class="headerlink" title="Empowering Whisper as a Joint Multi-Talker and Target-Talker Speech   Recognition System"></a>Empowering Whisper as a Joint Multi-Talker and Target-Talker Speech   Recognition System</h2><p><strong>Authors:Lingwei Meng, Jiawen Kang, Yuejiao Wang, Zengrui Jin, Xixin Wu, Xunying Liu, Helen Meng</strong></p>
<p>Multi-talker speech recognition and target-talker speech recognition, both involve transcription in multi-talker contexts, remain significant challenges. However, existing methods rarely attempt to simultaneously address both tasks. In this study, we propose a pioneering approach to empower Whisper, which is a speech foundation model, to tackle joint multi-talker and target-talker speech recognition tasks. Specifically, (i) we freeze Whisper and plug a Sidecar separator into its encoder to separate mixed embedding for multiple talkers; (ii) a Target Talker Identifier is introduced to identify the embedding flow of the target talker on the fly, requiring only three-second enrollment speech as a cue; (iii) soft prompt tuning for decoder is explored for better task adaptation. Our method outperforms previous methods on two- and three-talker LibriMix and LibriSpeechMix datasets for both tasks, and delivers acceptable zero-shot performance on multi-talker ASR on AishellMix Mandarin dataset. </p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2407.09817v2">PDF</a> Accepted to INTERSPEECH 2024</p>
<p><strong>Summary</strong><br>提出新方法，使Whisper模型同时处理多说话者和目标说话者语音识别任务。</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>同时处理多说话者和目标说话者语音识别。</li>
<li>使用Sidecar分离器分离混合嵌入。</li>
<li>引入目标说话者识别器。</li>
<li>需要简短的声音作为识别线索。</li>
<li>软提示调整解码器以适应任务。</li>
<li>在LibriMix和LibriSpeechMix数据集上优于先前方法。</li>
<li>在AishellMix数据集上实现可接受的零样本性能。</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li><p>Title: 赋能Whisper作为联合多说话者和目标说话者语音识别系统<br>          2. Authors: Lingwei Meng, Jiawen Kang, Yuejiao Wang, Zengrui Jin, Xixin Wu, Xunying Liu, Helen Meng<br>          3. Affiliation: 香港中文大学<br>          4. Keywords: 多说话者语音识别，目标说话者语音识别，提示微调，领域自适应<br>          5. Urls: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2407.09817v2">https://arxiv.org/abs/2407.09817v2</a> or <a target="_blank" rel="noopener" href="https://github.com/LingweiMeng/Whisper-Sidecar">https://github.com/LingweiMeng/Whisper-Sidecar</a><br><br>          6. Summary:<br>             - (1):该研究背景是多说话者和目标说话者语音识别在多说话者环境下的转录仍然是一个重大挑战。<br><br>             - (2):过去的方法包括传统的级联系统和端到端模型。级联系统通常由于优化目标不匹配而表现有限。端到端模型需要复杂的训练策略，如置换不变性训练（PIT）、启发式错误分配训练（HEAT）和序列输出训练（SOT），且通常需要从头开始训练或对预训练模型进行完全微调。这些方法虽然取得了显著成果，但未能充分利用标准单说话者ASR中开发的现有进步。该研究方法动机明确，旨在提高多说话者和目标说话者语音识别的性能。<br><br>             - (3)：该论文提出的方法包括：冻结Whisper的权重，将其编码器中的Sidecar分离器用于多说话者嵌入分离；引入目标说话者识别器（TTI）模块以实时识别目标说话者的嵌入流，只需3秒钟的注册语音作为提示；探索解码器的软提示微调以更好地适应任务。<br><br>             - (4)：该方法在两个和三个说话者的LibriMix和LibriSpeechMix数据集上实现了领先的性能，在AishellMix（普通话）数据集上达到了可接受的零样本多说话者ASR性能，支持了其研究目标。</p>
</li>
<li><p>Methods:</p>
<ul>
<li><p>(1): 采用Whisper作为基础模型，并引入Sidecar分离器将多说话者嵌入分离，以处理多说话者语音识别任务。</p>
</li>
<li><p>(2): 设计目标说话者识别器（TTI）模块，通过3秒的注册语音作为提示，实时识别目标说话者的嵌入流。</p>
</li>
<li><p>(3): 对解码器进行软提示微调，以更好地适应多说话者和目标说话者语音识别任务。</p>
</li>
<li><p>(4): 在训练过程中，80%的概率进行多说话者ASR训练，20%的概率进行包含注册语音的联合多说话者和目标说话者ASR训练。</p>
</li>
<li><p>(5): 使用置换不变性训练（PIT）解决标签模糊性问题，并计算最终的损失函数，包括ASR损失和TTI的交叉熵损失。</p>
</li>
</ul>
</li>
<li><p>Conclusion:</p>
<ul>
<li><p>(1):该研究具有显著意义，因为它为多说话者和目标说话者语音识别领域提供了一种新的解决方案，通过引入Whisper模型和Sidecar分离器，有效提升了多说话者环境下语音识别的准确性和实时性。</p>
</li>
<li><p>(2):Innovation point: 该文章的创新点在于将Whisper模型与Sidecar分离器结合，并设计目标说话者识别器（TTI）模块，实现了高效的多说话者和目标说话者语音识别；Performance: 在LibriMix和LibriSpeechMix数据集上，该方法达到了领先的性能，在AishellMix数据集上也取得了可接受的零样本多说话者ASR性能；Workload: 该方法在保持高性能的同时，降低了训练和运行的工作量，通过软提示微调和解码器优化，简化了训练策略。</p>
</li>
</ul>
</li>
</ol>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-ad0809bf1f2a0e13bfb58fed883c328f.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-4760bb1b1f83c77ff470a2676d9247aa.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-ba94c08ea3020d878a6417b75885d8b6.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-bbbcd66af9e5a0c566946800bba17655.jpg" align="middle">
</details>





                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        文章作者:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        文章链接:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/2024/08/28/Paper/2024-08-28/Talking%20Head%20Generation/">https://kedreamix.github.io/2024/08/28/Paper/2024-08-28/Talking%20Head%20Generation/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        版权声明:
                    </i>
                </span>
                <span class="reprint-info">
                    本博客所有文章除特別声明外，均采用
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    许可协议。转载请注明来源
                    <a href="/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/tags/Talking-Head-Generation/">
                                    <span class="chip bg-color">Talking Head Generation</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;上一篇</div>
            <div class="card">
                <a href="/2024/08/28/Paper/2024-08-28/3DGS/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-b72c589cdf9131b150d1c25d4921e305.jpg" class="responsive-img" alt="3DGS">
                        
                        <span class="card-title">3DGS</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            3DGS 方向最新论文已更新，请持续关注 Update in 2024-08-28  Avatar Concept Slider Manipulate Concepts In Your Human Avatar With   Fine-grained Control
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2024-08-28
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/3DGS/" class="post-category">
                                    3DGS
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/3DGS/">
                        <span class="chip bg-color">3DGS</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/2024/08/27/Paper/2024-08-27/Diffusion%20Models/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-806fc1c8232da95cacb188f0dc1e33f3.jpg" class="responsive-img" alt="Diffusion Models">
                        
                        <span class="card-title">Diffusion Models</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Diffusion Models 方向最新论文已更新，请持续关注 Update in 2024-08-27  How Diffusion Models Learn to Factorize and Compose
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2024-08-27
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/Diffusion-Models/" class="post-category">
                                    Diffusion Models
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/Diffusion-Models/">
                        <span class="chip bg-color">Diffusion Models</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/libs/codeBlock/codeBlockFuction.js"></script>



<!-- 代码语言 -->

<script type="text/javascript" src="/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>

    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/libs/aplayer/APlayer.min.js"></script>
<script src="/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 0px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024</span>
            
            <a href="/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
                <span id="translate">|&nbsp;繁/简：</span><a id="translateLink" href="javascript:translatePage();">繁</a>
            
            <br>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- 运行天数提醒. -->
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>













</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- 白天和黑夜主题 -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/libs/materialize/materialize.min.js"></script>
    <script src="/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/libs/aos/aos.js"></script>
    <script src="/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/js/matery.js"></script>

    

    
        <script type="text/javascript" src="/js/tw_cn.js"></script>
        <script type="text/javascript">
          var defaultEncoding = 2; //网站编写字体是否繁体，1-繁体，2-简体
          var translateDelay = 0; //延迟时间,若不在前, 要设定延迟翻译时间, 如100表示100ms,默认为0
          var cookieDomain = "https://kedreamix.github.io"; //Cookie地址, 一定要设定, 通常为你的网址
          var msgToTraditionalChinese = "繁"; //此处可以更改为你想要显示的文字
          var msgToSimplifiedChinese = "简"; //同上，但两处均不建议更改
          var translateButtonId = "translateLink"; //默认互换id
          translateInitilization();
        </script>
    
    
    

    <!-- 雪花特效 -->
    

    <!-- 鼠标星星特效 -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--腾讯兔小巢-->
    
    

    

    
    <script type="text/javascript" src="/libs/background/ribbon-dynamic.js" async="async"></script>
    

    
    <script src="/libs/instantpage/instantpage.js" type="module"></script>
    

</body>

</html>
