<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="3DGS">
    <meta name="description" content="3DGS æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-08-13  Learning an Implicit Physics Model for Image-based Fluid Simulation">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>3DGS | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://pic1.zhimg.com/v2-4ce27ae180b2af69b37d3867ec61d6ae.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">3DGS</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/3DGS/">
                                <span class="chip bg-color">3DGS</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/3DGS/" class="post-category">
                                3DGS
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-08-13
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-08-20
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    19.5k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    79 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-08-13-æ›´æ–°"><a href="#2025-08-13-æ›´æ–°" class="headerlink" title="2025-08-13 æ›´æ–°"></a>2025-08-13 æ›´æ–°</h1><h2 id="Learning-an-Implicit-Physics-Model-for-Image-based-Fluid-Simulation"><a href="#Learning-an-Implicit-Physics-Model-for-Image-based-Fluid-Simulation" class="headerlink" title="Learning an Implicit Physics Model for Image-based Fluid Simulation"></a>Learning an Implicit Physics Model for Image-based Fluid Simulation</h2><p><strong>Authors:Emily Yue-Ting Jia, Jiageng Mao, Zhiyuan Gao, Yajie Zhao, Yue Wang</strong></p>
<p>Humans possess an exceptional ability to imagine 4D scenes, encompassing both motion and 3D geometry, from a single still image. This ability is rooted in our accumulated observations of similar scenes and an intuitive understanding of physics. In this paper, we aim to replicate this capacity in neural networks, specifically focusing on natural fluid imagery. Existing methods for this task typically employ simplistic 2D motion estimators to animate the image, leading to motion predictions that often defy physical principles, resulting in unrealistic animations. Our approach introduces a novel method for generating 4D scenes with physics-consistent animation from a single image. We propose the use of a physics-informed neural network that predicts motion for each surface point, guided by a loss term derived from fundamental physical principles, including the Navier-Stokes equations. To capture appearance, we predict feature-based 3D Gaussians from the input image and its estimated depth, which are then animated using the predicted motions and rendered from any desired camera perspective. Experimental results highlight the effectiveness of our method in producing physically plausible animations, showcasing significant performance improvements over existing methods. Our project page is <a target="_blank" rel="noopener" href="https://physfluid.github.io/">https://physfluid.github.io/</a> . </p>
<blockquote>
<p>äººç±»æ‹¥æœ‰ä»å•ä¸€é™æ€å›¾åƒä¸­æƒ³è±¡å‡ºåŒ…å«è¿åŠ¨å’Œ3Då‡ ä½•çš„4Dåœºæ™¯çš„ç‰¹æ®Šèƒ½åŠ›ã€‚è¿™ç§èƒ½åŠ›æºäºæˆ‘ä»¬å¯¹ç±»ä¼¼åœºæ™¯çš„ç´¯ç§¯è§‚å¯Ÿå’Œå¯¹ç‰©ç†çš„ç›´è§‚ç†è§£ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æ—¨åœ¨åœ¨ç¥ç»ç½‘ç»œä¸­å¤åˆ¶è¿™ç§èƒ½åŠ›ï¼Œç‰¹åˆ«ä¸“æ³¨äºè‡ªç„¶æµä½“å›¾åƒã€‚ç°æœ‰æ–¹æ³•é€šå¸¸ä½¿ç”¨ç®€å•çš„2Dè¿åŠ¨ä¼°è®¡å™¨æ¥ä½¿å›¾åƒåŠ¨ç”»åŒ–ï¼Œå¯¼è‡´è¿åŠ¨é¢„æµ‹å¾€å¾€è¿èƒŒç‰©ç†åŸç†ï¼Œä»è€Œäº§ç”Ÿä¸çœŸå®çš„åŠ¨ç”»ã€‚æˆ‘ä»¬çš„æ–¹æ³•å¼•å…¥äº†ä¸€ç§ä»å•å¼ å›¾åƒç”Ÿæˆå…·æœ‰ç‰©ç†ä¸€è‡´æ€§åŠ¨ç”»çš„4Dåœºæ™¯çš„æ–°æ–¹æ³•ã€‚æˆ‘ä»¬å»ºè®®ä½¿ç”¨å—ç‰©ç†å¯å‘çš„ç¥ç»ç½‘ç»œæ¥é¢„æµ‹æ¯ä¸ªè¡¨é¢ç‚¹çš„è¿åŠ¨ï¼Œè¯¥ç½‘ç»œå—åŸºæœ¬ç‰©ç†åŸç†å¾—å‡ºçš„æŸå¤±é¡¹çš„æŒ‡å¯¼ï¼ŒåŒ…æ‹¬Navier-Stokesæ–¹ç¨‹ã€‚ä¸ºäº†æ•æ‰å¤–è§‚ï¼Œæˆ‘ä»¬ä»è¾“å…¥å›¾åƒå’Œå…¶ä¼°è®¡çš„æ·±åº¦é¢„æµ‹åŸºäºç‰¹å¾çš„3Dé«˜æ–¯åˆ†å¸ƒï¼Œç„¶åä½¿ç”¨é¢„æµ‹çš„è¿åŠ¨ä½¿å…¶åŠ¨ç”»åŒ–ï¼Œå¹¶ä»ä»»ä½•æƒ³è¦çš„ç›¸æœºè§’åº¦è¿›è¡Œæ¸²æŸ“ã€‚å®éªŒç»“æœçªå‡ºäº†æˆ‘ä»¬çš„æ–¹æ³•åœ¨äº§ç”Ÿç‰©ç†å¯è¡ŒåŠ¨ç”»æ–¹é¢çš„æœ‰æ•ˆæ€§ï¼Œå±•ç¤ºäº†ç›¸è¾ƒäºç°æœ‰æ–¹æ³•çš„æ˜¾è‘—æ€§èƒ½æå‡ã€‚æˆ‘ä»¬çš„é¡¹ç›®é¡µé¢æ˜¯<a target="_blank" rel="noopener" href="https://physfluid.github.io/%E3%80%82">https://physfluid.github.io/ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.08254v1">PDF</a> Accepted at ICCV 2025</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æ¢è®¨äººç±»ä»å•ä¸€é™æ€å›¾åƒä¸­æƒ³è±¡4Dåœºæ™¯ï¼ˆåŒ…æ‹¬è¿åŠ¨å’Œ3Då‡ ä½•ï¼‰çš„éå‡¡èƒ½åŠ›ï¼Œå¹¶æå‡ºä¸€ç§åœ¨ç¥ç»ç½‘ç»œä¸­å¤åˆ¶è¿™ç§èƒ½åŠ›çš„æ–¹æ³•ï¼Œç‰¹åˆ«å…³æ³¨è‡ªç„¶æµä½“å›¾åƒã€‚ç°æœ‰æ–¹æ³•é€šå¸¸ä½¿ç”¨ç®€å•çš„2Dè¿åŠ¨ä¼°è®¡å™¨æ¥é©±åŠ¨å›¾åƒè¿åŠ¨ï¼Œå¯¼è‡´é¢„æµ‹çš„è¿åŠ¨å¾€å¾€è¿èƒŒç‰©ç†åŸåˆ™ï¼Œäº§ç”Ÿä¸çœŸå®çš„åŠ¨ç”»ã€‚æœ¬æ–‡æå‡ºä¸€ç§æ–°å‹æ–¹æ³•ï¼Œåˆ©ç”¨ç‰©ç†ä¿¡æ¯ç¥ç»ç½‘ç»œé¢„æµ‹æ¯ä¸ªè¡¨é¢ç‚¹çš„è¿åŠ¨ï¼Œå¹¶é€šè¿‡åŸºäºNavier-Stokesæ–¹ç¨‹ç­‰åŸºç¡€ç‰©ç†åŸç†çš„æŸå¤±å‡½æ•°è¿›è¡Œå¼•å¯¼ã€‚ä¸ºäº†æ•æ‰å¤–è§‚ï¼Œæˆ‘ä»¬ä»è¾“å…¥å›¾åƒå’Œå…¶ä¼°è®¡çš„æ·±åº¦é¢„æµ‹ç‰¹å¾åŒ–çš„3Dé«˜æ–¯æ¨¡å‹ï¼Œç„¶åä½¿ç”¨é¢„æµ‹çš„è¿åŠ¨å’Œä»»æ„æœŸæœ›çš„ç›¸æœºè§†è§’è¿›è¡ŒåŠ¨ç”»æ¸²æŸ“ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•èƒ½ç”Ÿæˆç‰©ç†ä¸Šåˆç†çš„åŠ¨ç”»ï¼Œæ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>äººç±»å…·æœ‰ä»å•ä¸€é™æ€å›¾åƒä¸­æƒ³è±¡4Dåœºæ™¯ï¼ˆåŒ…æ‹¬è¿åŠ¨å’Œ3Då‡ ä½•ï¼‰çš„éå‡¡èƒ½åŠ›ã€‚</li>
<li>ç°æœ‰æ–¹æ³•ä½¿ç”¨ç®€å•çš„2Dè¿åŠ¨ä¼°è®¡å™¨ï¼Œå¯¼è‡´é¢„æµ‹çš„è¿åŠ¨å¸¸å¸¸è¿èƒŒç‰©ç†è§„å¾‹ï¼Œäº§ç”Ÿä¸çœŸå®åŠ¨ç”»ã€‚</li>
<li>æœ¬æ–‡æå‡ºä¸€ç§æ–°å‹æ–¹æ³•ï¼Œä½¿ç”¨ç‰©ç†ä¿¡æ¯ç¥ç»ç½‘ç»œé¢„æµ‹æ¯ä¸ªè¡¨é¢ç‚¹çš„è¿åŠ¨ã€‚</li>
<li>é¢„æµ‹çš„è¿åŠ¨é€šè¿‡åŸºäºNavier-Stokesæ–¹ç¨‹ç­‰åŸºç¡€ç‰©ç†åŸç†çš„æŸå¤±å‡½æ•°è¿›è¡Œå¼•å¯¼ã€‚</li>
<li>è¯¥æ–¹æ³•å¯ä»¥é¢„æµ‹ç‰¹å¾åŒ–çš„3Dé«˜æ–¯æ¨¡å‹ï¼Œæ•æ‰å›¾åƒå¤–è§‚ã€‚</li>
<li>é¢„æµ‹çš„è¿åŠ¨å’Œä»»æ„æœŸæœ›çš„ç›¸æœºè§†è§’å¯ç”¨äºåŠ¨ç”»æ¸²æŸ“ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.08254">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-cadbe572e02659f5cd9594964ba0b581.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c5a004f62b65ffa64c1c02f714e9004f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-cf653e3dc916aa06665c5df7d38cb964.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-e34ea898145131d50befcb75321495da.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="ReferSplat-Referring-Segmentation-in-3D-Gaussian-Splatting"><a href="#ReferSplat-Referring-Segmentation-in-3D-Gaussian-Splatting" class="headerlink" title="ReferSplat: Referring Segmentation in 3D Gaussian Splatting"></a>ReferSplat: Referring Segmentation in 3D Gaussian Splatting</h2><p><strong>Authors:Shuting He, Guangquan Jie, Changshuo Wang, Yun Zhou, Shuming Hu, Guanbin Li, Henghui Ding</strong></p>
<p>We introduce Referring 3D Gaussian Splatting Segmentation (R3DGS), a new task that aims to segment target objects in a 3D Gaussian scene based on natural language descriptions, which often contain spatial relationships or object attributes. This task requires the model to identify newly described objects that may be occluded or not directly visible in a novel view, posing a significant challenge for 3D multi-modal understanding. Developing this capability is crucial for advancing embodied AI. To support research in this area, we construct the first R3DGS dataset, Ref-LERF. Our analysis reveals that 3D multi-modal understanding and spatial relationship modeling are key challenges for R3DGS. To address these challenges, we propose ReferSplat, a framework that explicitly models 3D Gaussian points with natural language expressions in a spatially aware paradigm. ReferSplat achieves state-of-the-art performance on both the newly proposed R3DGS task and 3D open-vocabulary segmentation benchmarks. Dataset and code are available at <a target="_blank" rel="noopener" href="https://github.com/heshuting555/ReferSplat">https://github.com/heshuting555/ReferSplat</a>. </p>
<blockquote>
<p>æˆ‘ä»¬ä»‹ç»äº†åŸºäºè‡ªç„¶è¯­è¨€æè¿°çš„å‚ç…§ä¸‰ç»´é«˜æ–¯å–·å°„åˆ†å‰²ï¼ˆR3DGSï¼‰è¿™ä¸€æ–°ä»»åŠ¡ï¼Œè¯¥ä»»åŠ¡æ—¨åœ¨æ ¹æ®åŒ…å«ç©ºé—´å…³ç³»æˆ–å¯¹è±¡å±æ€§çš„è‡ªç„¶è¯­è¨€æè¿°æ¥åˆ†å‰²ä¸‰ç»´é«˜æ–¯åœºæ™¯ä¸­çš„ç›®æ ‡å¯¹è±¡ã€‚è¿™ä¸€ä»»åŠ¡è¦æ±‚æ¨¡å‹è¯†åˆ«æ–°æè¿°çš„å¯¹è±¡ï¼Œè¿™äº›å¯¹è±¡å¯èƒ½åœ¨ä¸€ä¸ªæ–°è§†è§’ä¸­è¢«é®æŒ¡æˆ–ç›´æ¥ä¸å¯è§ï¼Œè¿™ä¸ºä¸‰ç»´å¤šæ¨¡æ€ç†è§£å¸¦æ¥äº†é‡å¤§æŒ‘æˆ˜ã€‚å¼€å‘è¿™ç§èƒ½åŠ›å¯¹äºæ¨åŠ¨åµŒå…¥å¼äººå·¥æ™ºèƒ½çš„å‘å±•è‡³å…³é‡è¦ã€‚ä¸ºäº†æ”¯æŒè¿™ä¸€é¢†åŸŸçš„ç ”ç©¶ï¼Œæˆ‘ä»¬æ„å»ºäº†ç¬¬ä¸€ä¸ªR3DGSæ•°æ®é›†Ref-LERFã€‚æˆ‘ä»¬çš„åˆ†æè¡¨æ˜ï¼Œä¸‰ç»´å¤šæ¨¡æ€ç†è§£å’Œç©ºé—´å…³ç³»å»ºæ¨¡æ˜¯R3DGSçš„å…³é”®æŒ‘æˆ˜ã€‚ä¸ºäº†åº”å¯¹è¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†ReferSplatæ¡†æ¶ï¼Œè¯¥æ¡†æ¶é‡‡ç”¨ç©ºé—´æ„ŸçŸ¥èŒƒå¼æ˜¾å¼åœ°åˆ©ç”¨ä¸‰ç»´é«˜æ–¯ç‚¹å¯¹è‡ªç„¶è¯­è¨€è¡¨è¾¾å¼è¿›è¡Œå»ºæ¨¡ã€‚ReferSplatåœ¨æ–°æå‡ºçš„R3DGSä»»åŠ¡å’Œä¸‰ç»´å¼€æ”¾è¯æ±‡åˆ†å‰²åŸºå‡†æµ‹è¯•ä¸Šéƒ½è¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚æ•°æ®é›†å’Œä»£ç å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/heshuting555/ReferSplat%E8%8E%B7%E5%8F%96%E3%80%82">https://github.com/heshuting555/ReferSplatè·å–ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.08252v1">PDF</a> ICML 2025 Oral, Code: <a target="_blank" rel="noopener" href="https://github.com/heshuting555/ReferSplat">https://github.com/heshuting555/ReferSplat</a></p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†ä¸€é¡¹æ–°çš„ä»»åŠ¡â€”â€”åŸºäºè‡ªç„¶è¯­è¨€æè¿°çš„3Dé«˜æ–¯åœºæ™¯åˆ†å‰²ï¼ˆR3DGSï¼‰ã€‚è¯¥ä»»åŠ¡æ—¨åœ¨è¯†åˆ«å’Œåˆ†å‰²åœ¨å¤æ‚ç¯å¢ƒä¸­é€šè¿‡è‡ªç„¶è¯­è¨€æè¿°çš„ç›®æ ‡ç‰©ä½“ï¼Œå°¤å…¶å…³æ³¨è¯­è¨€ä¸­çš„ç©ºé—´å…³ç³»å’Œç‰©ä½“å±æ€§ã€‚ä¸ºæ­¤ï¼Œæ–‡ç« æå‡ºäº†é¦–ä¸ªR3DGSæ•°æ®é›†Ref-LERFï¼Œå¹¶æŒ‡å‡ºè¯¥é¢†åŸŸçš„æ ¸å¿ƒæŒ‘æˆ˜åœ¨äºå¤šæ¨¡æ€ç†è§£å’Œç©ºé—´å…³ç³»å»ºæ¨¡ã€‚ä¸ºè§£å†³è¿™äº›æŒ‘æˆ˜ï¼Œæ–‡ç« æå‡ºäº†ReferSplatæ¡†æ¶ï¼Œé€šè¿‡æ˜ç¡®å»ºæ¨¡é«˜æ–¯ç‚¹ä¸è‡ªç„¶è¯­è¨€çš„ç©ºé—´å…³ç³»è¾¾åˆ°å“è¶Šæ€§èƒ½ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ä»‹ç»æ–°çš„ä»»åŠ¡ï¼šåŸºäºè‡ªç„¶è¯­è¨€æè¿°çš„3Dé«˜æ–¯åœºæ™¯åˆ†å‰²ï¼ˆR3DGSï¼‰ã€‚</li>
<li>R3DGSçš„ç›®æ ‡æ˜¯åœ¨å¤æ‚ç¯å¢ƒä¸­è¯†åˆ«å’Œåˆ†å‰²é€šè¿‡è‡ªç„¶è¯­è¨€æè¿°çš„ç›®æ ‡ç‰©ä½“ã€‚</li>
<li>è‡ªç„¶è¯­è¨€æè¿°ä¸­çš„ç©ºé—´å…³ç³»å’Œç‰©ä½“å±æ€§æ˜¯å®Œæˆä»»åŠ¡çš„å…³é”®è¦ç´ ã€‚</li>
<li>ä¸ºæ”¯æŒè¯¥é¢†åŸŸçš„ç ”ç©¶ï¼Œæ„å»ºäº†é¦–ä¸ªR3DGSæ•°æ®é›†Ref-LERFã€‚</li>
<li>å¤šæ¨¡æ€ç†è§£å’Œç©ºé—´å…³ç³»å»ºæ¨¡æ˜¯å®ŒæˆR3DGSä»»åŠ¡çš„æ ¸å¿ƒæŒ‘æˆ˜ã€‚</li>
<li>ä¸ºè§£å†³è¿™äº›æŒ‘æˆ˜ï¼Œæå‡ºäº†ReferSplatæ¡†æ¶ï¼Œå…¶èƒ½æ˜ç¡®å»ºæ¨¡é«˜æ–¯ç‚¹ä¸è‡ªç„¶è¯­è¨€çš„ç©ºé—´å…³ç³»ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.08252">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-31dce7137bfe5145c8f02504f8e9b56d.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-342966e1acc3b0a17afeaa71df7a69bd.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-65d4ff68ff2fe2989ab7743343f50815.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-dcb91aad49491732fba65d35561adb5a.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="SAGOnline-Segment-Any-Gaussians-Online"><a href="#SAGOnline-Segment-Any-Gaussians-Online" class="headerlink" title="SAGOnline: Segment Any Gaussians Online"></a>SAGOnline: Segment Any Gaussians Online</h2><p><strong>Authors:Wentao Sun, Quanyun Wu, Hanqing Xu, Kyle Gao, Zhengsen Xu, Yiping Chen, Dedong Zhang, Lingfei Ma, John S. Zelek, Jonathan Li</strong></p>
<p>3D Gaussian Splatting (3DGS) has emerged as a powerful paradigm for explicit 3D scene representation, yet achieving efficient and consistent 3D segmentation remains challenging. Current methods suffer from prohibitive computational costs, limited 3D spatial reasoning, and an inability to track multiple objects simultaneously. We present Segment Any Gaussians Online (SAGOnline), a lightweight and zero-shot framework for real-time 3D segmentation in Gaussian scenes that addresses these limitations through two key innovations: (1) a decoupled strategy that integrates video foundation models (e.g., SAM2) for view-consistent 2D mask propagation across synthesized views; and (2) a GPU-accelerated 3D mask generation and Gaussian-level instance labeling algorithm that assigns unique identifiers to 3D primitives, enabling lossless multi-object tracking and segmentation across views. SAGOnline achieves state-of-the-art performance on NVOS (92.7% mIoU) and Spin-NeRF (95.2% mIoU) benchmarks, outperforming Feature3DGS, OmniSeg3D-gs, and SA3D by 15â€“1500 times in inference speed (27 ms&#x2F;frame). Qualitative results demonstrate robust multi-object segmentation and tracking in complex scenes. Our contributions include: (i) a lightweight and zero-shot framework for 3D segmentation in Gaussian scenes, (ii) explicit labeling of Gaussian primitives enabling simultaneous segmentation and tracking, and (iii) the effective adaptation of 2D video foundation models to the 3D domain. This work allows real-time rendering and 3D scene understanding, paving the way for practical AR&#x2F;VR and robotic applications. </p>
<blockquote>
<p>3Dé«˜æ–¯å±•å¼€ï¼ˆ3DGSï¼‰å·²ç»æˆä¸ºä¸€ç§å¼ºå¤§çš„æ˜¾å¼3Dåœºæ™¯è¡¨ç¤ºèŒƒå¼ï¼Œä½†å®ç°é«˜æ•ˆä¸”ä¸€è‡´çš„3Dåˆ†å‰²ä»ç„¶å…·æœ‰æŒ‘æˆ˜æ€§ã€‚å½“å‰çš„æ–¹æ³•å­˜åœ¨è®¡ç®—æˆæœ¬é«˜ã€3Dç©ºé—´æ¨ç†æœ‰é™ã€æ— æ³•åŒæ—¶è·Ÿè¸ªå¤šä¸ªç‰©ä½“ç­‰ç¼ºç‚¹ã€‚æˆ‘ä»¬æå‡ºäº†åœ¨çº¿é«˜æ–¯åˆ†å‰²ä»»æ„ç‰©ä½“ï¼ˆSAGOnlineï¼‰ï¼Œè¿™æ˜¯ä¸€ä¸ªç”¨äºé«˜æ–¯åœºæ™¯å®æ—¶3Dåˆ†å‰²çš„è½»é‡çº§é›¶æ ·æœ¬æ¡†æ¶ï¼Œé€šè¿‡ä¸¤ä¸ªå…³é”®åˆ›æ–°è§£å†³äº†è¿™äº›é™åˆ¶ï¼šï¼ˆ1ï¼‰ä¸€ç§åˆ†ç¦»ç­–ç•¥ï¼Œé›†æˆäº†è§†é¢‘åŸºç¡€æ¨¡å‹ï¼ˆä¾‹å¦‚SAM2ï¼‰ï¼Œç”¨äºåœ¨åˆæˆè§†å›¾ä¹‹é—´è¿›è¡Œä¸€è‡´çš„2Dæ©è†œä¼ æ’­ï¼›ï¼ˆ2ï¼‰ä¸€ä¸ªGPUåŠ é€Ÿçš„3Dæ©è†œç”Ÿæˆå’Œé«˜æ–¯çº§åˆ«å®ä¾‹æ ‡è®°ç®—æ³•ï¼Œè¯¥ç®—æ³•ä¸º3DåŸºæœ¬å…ƒç´ åˆ†é…å”¯ä¸€æ ‡è¯†ç¬¦ï¼Œä»è€Œå®ç°è·¨è§†å›¾çš„æ— æŸå¤šç›®æ ‡è·Ÿè¸ªå’Œåˆ†å‰²ã€‚SAGOnlineåœ¨NVOSï¼ˆ92.7% mIoUï¼‰å’ŒSpin-NeRFï¼ˆ95.2% mIoUï¼‰åŸºå‡†æµ‹è¯•ä¸­å®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œç›¸è¾ƒäºFeature3DGSã€OmniSeg3D-gså’ŒSA3Dåœ¨æ¨ç†é€Ÿåº¦ä¸Šæå‡äº†15è‡³1500å€ï¼ˆæ¯ç§’å¤„ç†å¸§æ•°ä¸ºæ¯å¸§ä»…çº¦éœ€æ—¶27æ¯«ç§’ï¼‰ã€‚å®šæ€§ç»“æœè¡¨æ˜å…¶åœ¨å¤æ‚åœºæ™¯ä¸­å®ç°äº†ç¨³å¥çš„å¤šç›®æ ‡åˆ†å‰²å’Œè·Ÿè¸ªã€‚æˆ‘ä»¬çš„è´¡çŒ®åŒ…æ‹¬ï¼šï¼ˆä¸€ï¼‰é«˜æ–¯åœºæ™¯ä¸‹ç”¨äºä¸‰ç»´åˆ†å‰²çš„è½»é‡çº§é›¶æ ·æœ¬æ¡†æ¶ï¼Œï¼ˆäºŒï¼‰å¯¹é«˜æ–¯åŸºæœ¬å…ƒç´ è¿›è¡Œæ˜ç¡®æ ‡è®°ï¼Œä»¥å®ç°åŒæ—¶åˆ†å‰²å’Œè·Ÿè¸ªï¼Œï¼ˆä¸‰ï¼‰æœ‰æ•ˆé€‚åº”äºŒç»´è§†é¢‘åŸºç¡€æ¨¡å‹åˆ°ä¸‰ç»´é¢†åŸŸã€‚è¿™é¡¹å·¥ä½œä¸ºå®æ—¶æ¸²æŸ“å’Œä¸‰ç»´åœºæ™¯ç†è§£é“ºå¹³äº†é“è·¯ï¼Œä¸ºå¢å¼ºç°å®&#x2F;è™šæ‹Ÿç°å®å’Œæœºå™¨äººåº”ç”¨ç­‰å®ç”¨é¢†åŸŸæä¾›äº†å¯èƒ½ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.08219v1">PDF</a> 19 pages, 10 figures</p>
<p><strong>æ‘˜è¦</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†é’ˆå¯¹é«˜æ–¯åœºæ™¯å®æ—¶ä¸‰ç»´åˆ†å‰²çš„æ–°å‹åœ¨çº¿é›¶ç‚¹æ¡†æ¶Segment Any Gaussians Onlineï¼ˆSAGOnlineï¼‰ã€‚è¯¥æ¡†æ¶å…·æœ‰ä¸¤é¡¹å…³é”®åˆ›æ–°ï¼Œå³ä¸€é¡¹è€¦åˆç­–ç•¥ä¸å¦ä¸€é¡¹é’ˆå¯¹è§†é¢‘åŸºç¡€çš„é›†æˆæ–¹æ³•ç›¸ç»“åˆã€‚æ¡†æ¶èƒ½åœ¨GPUä¸Šå®ç°é«˜æ•ˆçš„è¿è¡Œé€Ÿåº¦å’Œé«˜æ–¯çº§åˆ«å®ä¾‹çš„æ ‡ç­¾ç®—æ³•åˆ†é…ç‹¬ç‰¹æ ‡è¯†ç¬¦è¿›è¡Œä¸‰ç»´å…ƒç´ åˆ†å‰²ï¼Œèƒ½å¤Ÿå®ç°æ— æŸè€—çš„å¤šå¯¹è±¡è·Ÿè¸ªä¸ä¸åŒè§†è§’åˆ†å‰²ã€‚æœ¬æ–‡è¿˜åŒ…æ‹¬è´¡çŒ®ä¸€ï¼šåœ¨ç®€åŒ–ä¸‰ç»´åœºæ™¯çš„åŸºç¡€ä¸Šå¼€å‘æ–°å‹é«˜æ•ˆé›¶ç‚¹æ¡†æ¶è¿›è¡Œé«˜æ–¯åœºæ™¯åˆ†å‰²ï¼›è´¡çŒ®äºŒï¼šæ˜ç¡®é«˜æ–¯å…ƒç´ æ ‡ç­¾ï¼Œå®ç°åŒæ—¶åˆ†å‰²å’Œè·Ÿè¸ªï¼›è´¡çŒ®ä¸‰ï¼šæœ‰æ•ˆé€‚åº”äºŒç»´è§†é¢‘åŸºç¡€æ¨¡å‹åˆ°ä¸‰ç»´é¢†åŸŸçš„å¹¿æ³›åº”ç”¨åœºæ™¯ï¼Œä¸”æ•ˆç‡è¾¾åˆ°å†å²é¡¶å°–ã€‚æœ¬æ–‡ä¸»è¦ç»“æœä¿ƒè¿›é«˜æ•ˆå®ç”¨æ¸²æŸ“æŠ€æœ¯åœ¨è™šæ‹Ÿç°å®åŠå¢å¼ºç°å®åº”ç”¨åœºæ™¯çš„è¿ç”¨å’Œç†è§£åœºæ™¯ä¿¡æ¯çš„æ™®éæ¨å¹¿ç­‰ARå’ŒVRåº”ç”¨åœºæ™¯çš„åº”ç”¨ä¸å‘å±•æ–¹å‘çš„ç ”ç©¶å’Œå‘å±•æä¾›äº†å¯ç¤ºå’Œæ–¹å‘æŒ‡å¯¼ã€‚è¿™å¯¹äºæ‰©å¤§åº”ç”¨è¡Œä¸šåŠå…¶çœŸå®æ„Ÿå’Œåœºæ™¯çš„å‘ˆç°æ— ç–‘èµ·åˆ°ç§¯æçš„æ¨åŠ¨ä½œç”¨ã€‚æ­¤å¤–ï¼Œè¯¥æ¡†æ¶åœ¨NVOSå’ŒSpin-NeRFåŸºå‡†æµ‹è¯•ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œç›¸å¯¹äºå…¶ä»–æ¨¡å‹å¦‚Feature3DGSç­‰æœ‰ç€æ˜¾è‘—æå‡çš„æ¨ç†é€Ÿåº¦ï¼ˆé«˜è¾¾15å€è‡³æœ€é«˜å¯è¾¾è‡³150å€ï¼‰ã€‚å®šé‡ç»“æœè¡¨æ˜åœ¨å¤æ‚åœºæ™¯ä¸­å¤šå¯¹è±¡åˆ†å‰²å’Œè·Ÿè¸ªçš„ç¨³å¥æ€§ã€‚å› æ­¤ï¼Œæœ¬æ–‡ä¸ºå®æ—¶æ¸²æŸ“å’Œä¸‰ç»´åœºæ™¯ç†è§£å¼€è¾Ÿäº†æ–°çš„é“è·¯ã€‚ </p>
<p><strong>å…³é”®è§è§£</strong></p>
<p>ä¸€ã€æå‡ºäº†ä¸€ç§æ–°å‹çš„åœ¨çº¿é›¶ç‚¹æ¡†æ¶ç”¨äºé«˜æ–¯åœºæ™¯çš„ä¸‰ç»´åˆ†å‰²ï¼Œå®ç°äº†é«˜æ•ˆå®æ—¶çš„åˆ†å‰²æ€§èƒ½ã€‚<br>äºŒã€é€šè¿‡æ˜ç¡®é«˜æ–¯å…ƒç´ çš„æ ‡ç­¾ï¼Œå®ç°äº†åŒæ—¶åˆ†å‰²å’Œè·Ÿè¸ªçš„åŠŸèƒ½ï¼Œæé«˜äº†å¤šå¯¹è±¡å¤„ç†çš„æ•ˆç‡ã€‚</p>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.08219">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-f3e33c60198b8587de428e13fe69987e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-830dae18f9e1ab1d11b36454dd7b9a1d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-efe6f5e32ab59a2b17d2b4b869902c62.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="FantasyStyle-Controllable-Stylized-Distillation-for-3D-Gaussian-Splatting"><a href="#FantasyStyle-Controllable-Stylized-Distillation-for-3D-Gaussian-Splatting" class="headerlink" title="FantasyStyle: Controllable Stylized Distillation for 3D Gaussian   Splatting"></a>FantasyStyle: Controllable Stylized Distillation for 3D Gaussian   Splatting</h2><p><strong>Authors:Yitong Yang, Yinglin Wang, Changshuo Wang, Huajie Wang, Shuting He</strong></p>
<p>The success of 3DGS in generative and editing applications has sparked growing interest in 3DGS-based style transfer. However, current methods still face two major challenges: (1) multi-view inconsistency often leads to style conflicts, resulting in appearance smoothing and distortion; and (2) heavy reliance on VGG features, which struggle to disentangle style and content from style images, often causing content leakage and excessive stylization. To tackle these issues, we introduce \textbf{FantasyStyle}, a 3DGS-based style transfer framework, and the first to rely entirely on diffusion model distillation. It comprises two key components: (1) \textbf{Multi-View Frequency Consistency}. We enhance cross-view consistency by applying a 3D filter to multi-view noisy latent, selectively reducing low-frequency components to mitigate stylized prior conflicts. (2) \textbf{Controllable Stylized Distillation}. To suppress content leakage from style images, we introduce negative guidance to exclude undesired content. In addition, we identify the limitations of Score Distillation Sampling and Delta Denoising Score in 3D style transfer and remove the reconstruction term accordingly. Building on these insights, we propose a controllable stylized distillation that leverages negative guidance to more effectively optimize the 3D Gaussians. Extensive experiments demonstrate that our method consistently outperforms state-of-the-art approaches, achieving higher stylization quality and visual realism across various scenes and styles. </p>
<blockquote>
<p>3DGSåœ¨ç”Ÿæˆå’Œç¼–è¾‘åº”ç”¨ä¸­çš„æˆåŠŸå¼•å‘äº†åŸºäº3DGSçš„é£æ ¼è½¬æ¢çš„æ—¥ç›Šå¢é•¿çš„å…´è¶£ã€‚ç„¶è€Œï¼Œå½“å‰çš„æ–¹æ³•ä»ç„¶é¢ä¸´ä¸¤å¤§æŒ‘æˆ˜ï¼š(1)å¤šè§†å›¾ä¸ä¸€è‡´æ€§ç»å¸¸å¯¼è‡´é£æ ¼å†²çªï¼Œä»è€Œå¯¼è‡´å¤–è§‚å¹³æ»‘å’Œå¤±çœŸï¼›(2)ä¸¥é‡ä¾èµ–VGGç‰¹å¾ï¼Œå…¶åœ¨ä»é£æ ¼å›¾åƒä¸­åˆ†ç¦»é£æ ¼å’Œå†…å®¹æ—¶é‡åˆ°å›°éš¾ï¼Œç»å¸¸å¯¼è‡´å†…å®¹æ³„éœ²å’Œè¿‡åº¦é£æ ¼åŒ–ã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬å¼•å…¥äº†\textbf{FantasyStyle}ï¼Œè¿™æ˜¯ä¸€ä¸ªåŸºäº3DGSçš„é£æ ¼è½¬ç§»æ¡†æ¶ï¼Œä¹Ÿæ˜¯ç¬¬ä¸€ä¸ªå®Œå…¨ä¾èµ–æ‰©æ•£æ¨¡å‹è’¸é¦çš„æ¡†æ¶ã€‚å®ƒåŒ…å«ä¸¤ä¸ªå…³é”®ç»„æˆéƒ¨åˆ†ï¼š(1)\textbf{å¤šè§†å›¾é¢‘ç‡ä¸€è‡´æ€§}ã€‚æˆ‘ä»¬é€šè¿‡åº”ç”¨3Dæ»¤æ³¢å™¨å¢å¼ºè·¨è§†å›¾çš„ä¸€è‡´æ€§ï¼Œå¯¹å¤šè§†å›¾å™ªå£°æ½œåœ¨è¿›è¡Œé€‰æ‹©æ€§é™ä½ä½é¢‘åˆ†é‡ï¼Œä»¥ç¼“è§£é£æ ¼åŒ–å…ˆéªŒå†²çªã€‚(2)\textbf{å¯æ§é£æ ¼åŒ–è’¸é¦}ã€‚ä¸ºäº†æŠ‘åˆ¶æ¥è‡ªé£æ ¼å›¾åƒçš„å†…å®¹æ³„éœ²ï¼Œæˆ‘ä»¬å¼•å…¥è´Ÿå¼•å¯¼æ¥æ’é™¤ä¸éœ€è¦çš„å†…å®¹ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å‘ç°äº†3Dé£æ ¼è½¬ç§»ä¸­Score Distillation Samplingå’ŒDelta Denoising Scoreçš„å±€é™æ€§ï¼Œå¹¶ç›¸åº”åœ°åˆ é™¤äº†é‡å»ºé¡¹ã€‚åŸºäºè¿™äº›è§è§£ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§å¯æ§çš„é£æ ¼åŒ–è’¸é¦ï¼Œåˆ©ç”¨è´Ÿå¼•å¯¼æ›´æœ‰æ•ˆåœ°ä¼˜åŒ–3Dé«˜æ–¯ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•å§‹ç»ˆä¼˜äºæœ€å…ˆè¿›çš„æ–¹æ³•ï¼Œåœ¨å„ç§åœºæ™¯å’Œé£æ ¼ä¸‹å®ç°æ›´é«˜çš„é£æ ¼åŒ–è´¨é‡å’Œè§†è§‰çœŸå®æ€§ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.08136v1">PDF</a> </p>
<p><strong>æ‘˜è¦</strong><br>    åŸºäº3DGSçš„é£æ ¼è½¬ç§»æ¡†æ¶FantasyStyleè§£å†³äº†ç°æœ‰æ–¹æ³•çš„ä¸¤å¤§æŒ‘æˆ˜ï¼šå¤šè§†è§’ä¸ä¸€è‡´å¯¼è‡´çš„é£æ ¼å†²çªä»¥åŠè¿‡åº¦ä¾èµ–VGGç‰¹å¾å¸¦æ¥çš„å†…å®¹æ³„éœ²å’Œè¿‡åº¦é£æ ¼åŒ–é—®é¢˜ã€‚å®ƒé€šè¿‡å¼•å…¥æ‰©æ•£æ¨¡å‹è’¸é¦å’Œä¸¤ç§å…³é”®æŠ€æœ¯â€”â€”å¤šè§†è§’é¢‘ç‡ä¸€è‡´æ€§åŠå¯æ§é£æ ¼åŒ–è’¸é¦ï¼Œæé«˜äº†è·¨è§†è§’ä¸€è‡´æ€§å¹¶æœ‰æ•ˆæŠ‘åˆ¶äº†å†…å®¹æ³„éœ²ã€‚å®éªŒè¯æ˜ï¼Œè¯¥æ–¹æ³•åœ¨åœºæ™¯å’Œé£æ ¼æ–¹é¢å‡ä¼˜äºç°æœ‰æŠ€æœ¯ï¼Œæé«˜äº†é£æ ¼åŒ–çš„è´¨é‡å’Œè§†è§‰é€¼çœŸåº¦ã€‚</p>
<p><strong>å…³é”®è§è§£</strong></p>
<ul>
<li>åŸºäº3DGSçš„é£æ ¼è½¬ç§»æ¡†æ¶FantasyStyleæ—¨åœ¨è§£å†³å¤šè§†è§’ä¸ä¸€è‡´å’Œè¿‡åº¦ä¾èµ–VGGç‰¹å¾å¯¼è‡´çš„é£æ ¼å†²çªå’Œå†…å®¹æ³„éœ²é—®é¢˜ã€‚</li>
<li>å¤šè§†è§’é¢‘ç‡ä¸€è‡´æ€§æŠ€æœ¯é€šè¿‡åº”ç”¨3Dæ»¤æ³¢å™¨å¢å¼ºè·¨è§†è§’ä¸€è‡´æ€§ï¼Œå‡å°‘ä½é¢‘é¢‘æ®µä»¥ç¼“è§£é£æ ¼åŒ–å†²çªã€‚</li>
<li>å¯æ§é£æ ¼åŒ–è’¸é¦é€šè¿‡å¼•å…¥è´Ÿå¯¼å‘æŠ‘åˆ¶å†…å®¹æ³„éœ²ã€‚æ­¤å¤–ï¼Œè¯¥ç ”ç©¶æŒ‡å‡ºäº†Score Distillation Samplingå’ŒDelta Denoising Scoreåœ¨3Dé£æ ¼è½¬ç§»ä¸­çš„å±€é™æ€§å¹¶è¿›è¡Œäº†ç›¸åº”çš„æ”¹è¿›ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.08136">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-c46ec103dd413da754aa808b72b90eb9.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-e51dc8e474b4e5050366eef9f0ae30cd.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f9c54230ab89c017d1032702352e35ce.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-2c06fbe62f6e29126ecf97ab424ee2e8.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-32914e3398f29474803d27d09621eb53.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="NeeCo-Image-Synthesis-of-Novel-Instrument-States-Based-on-Dynamic-and-Deformable-3D-Gaussian-Reconstruction"><a href="#NeeCo-Image-Synthesis-of-Novel-Instrument-States-Based-on-Dynamic-and-Deformable-3D-Gaussian-Reconstruction" class="headerlink" title="NeeCo: Image Synthesis of Novel Instrument States Based on Dynamic and   Deformable 3D Gaussian Reconstruction"></a>NeeCo: Image Synthesis of Novel Instrument States Based on Dynamic and   Deformable 3D Gaussian Reconstruction</h2><p><strong>Authors:Tianle Zeng, Junlei Hu, Gerardo Loza Galindo, Sharib Ali, Duygu Sarikaya, Pietro Valdastri, Dominic Jones</strong></p>
<p>Computer vision-based technologies significantly enhance surgical automation by advancing tool tracking, detection, and localization. However, Current data-driven approaches are data-voracious, requiring large, high-quality labeled image datasets, which limits their application in surgical data science. Our Work introduces a novel dynamic Gaussian Splatting technique to address the data scarcity in surgical image datasets. We propose a dynamic Gaussian model to represent dynamic surgical scenes, enabling the rendering of surgical instruments from unseen viewpoints and deformations with real tissue backgrounds. We utilize a dynamic training adjustment strategy to address challenges posed by poorly calibrated camera poses from real-world scenarios. Additionally, we propose a method based on dynamic Gaussians for automatically generating annotations for our synthetic data. For evaluation, we constructed a new dataset featuring seven scenes with 14,000 frames of tool and camera motion and tool jaw articulation, with a background of an ex-vivo porcine model. Using this dataset, we synthetically replicate the scene deformation from the ground truth data, allowing direct comparisons of synthetic image quality. Experimental results illustrate that our method generates photo-realistic labeled image datasets with the highest values in Peak-Signal-to-Noise Ratio (29.87). We further evaluate the performance of medical-specific neural networks trained on real and synthetic images using an unseen real-world image dataset. Our results show that the performance of models trained on synthetic images generated by the proposed method outperforms those trained with state-of-the-art standard data augmentation by 10%, leading to an overall improvement in model performances by nearly 15%. </p>
<blockquote>
<p>åŸºäºè®¡ç®—æœºè§†è§‰çš„æŠ€æœ¯é€šè¿‡æ¨åŠ¨å·¥å…·è¿½è¸ªã€æ£€æµ‹å’Œå®šä½ï¼Œæ˜¾è‘—å¢å¼ºäº†æ‰‹æœ¯çš„è‡ªåŠ¨åŒ–ç¨‹åº¦ã€‚ç„¶è€Œï¼Œå½“å‰çš„æ•°æ®é©±åŠ¨æ–¹æ³•éœ€è¦å¤§é‡çš„é«˜è´¨é‡æ ‡è®°å›¾åƒæ•°æ®é›†ï¼Œè¿™é™åˆ¶äº†å®ƒä»¬åœ¨æ‰‹æœ¯æ•°æ®ç§‘å­¦ä¸­çš„åº”ç”¨ã€‚æˆ‘ä»¬çš„å·¥ä½œå¼•å…¥äº†ä¸€ç§æ–°çš„åŠ¨æ€é«˜æ–¯æ··åˆæŠ€æœ¯æ¥è§£å†³æ‰‹æœ¯å›¾åƒæ•°æ®é›†ä¸­æ•°æ®ç¨€ç¼ºçš„é—®é¢˜ã€‚æˆ‘ä»¬æå‡ºä¸€ä¸ªåŠ¨æ€é«˜æ–¯æ¨¡å‹æ¥è¡¨ç¤ºåŠ¨æ€æ‰‹æœ¯åœºæ™¯ï¼Œèƒ½å¤Ÿä»æœªè§è¿‡çš„è§†è§’å’Œå˜å½¢ä¸­å‘ˆç°æ‰‹æœ¯å™¨æ¢°ï¼Œå¹¶ä¸çœŸå®ç»„ç»‡èƒŒæ™¯ç›¸ç»“åˆã€‚æˆ‘ä»¬é‡‡ç”¨åŠ¨æ€è®­ç»ƒè°ƒæ•´ç­–ç•¥ï¼Œä»¥è§£å†³ç”±ç°å®ä¸–ç•Œåœºæ™¯ä¸­ç›¸æœºå§¿æ€æ ¡å‡†ä¸è‰¯æ‰€å¸¦æ¥çš„æŒ‘æˆ˜ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜æå‡ºäº†ä¸€ç§åŸºäºåŠ¨æ€é«˜æ–¯çš„æ–¹æ³•ï¼Œç”¨äºè‡ªåŠ¨ä¸ºæˆ‘ä»¬åˆæˆçš„æ•°æ®ç”Ÿæˆæ³¨é‡Šã€‚ä¸ºäº†è¿›è¡Œè¯„ä¼°ï¼Œæˆ‘ä»¬æ„å»ºäº†ä¸€ä¸ªæ–°çš„æ•°æ®é›†ï¼ŒåŒ…å«ä¸ƒä¸ªåœºæ™¯ï¼Œ14000å¸§çš„å·¥å…·å’Œç›¸æœºè¿åŠ¨ä»¥åŠå·¥å…·é¢šå…³èŠ‚è¿åŠ¨ï¼ŒèƒŒæ™¯æ˜¯ä¸€ä¸ªç¦»ä½“çš„çŒªæ¨¡å‹ã€‚ä½¿ç”¨è¿™ä¸ªæ•°æ®é›†ï¼Œæˆ‘ä»¬åˆæˆåœ°å¤åˆ¶äº†åœºæ™¯å˜å½¢ï¼Œä¸çœŸå®æ•°æ®ç›´æ¥æ¯”è¾ƒåˆæˆå›¾åƒçš„è´¨é‡ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•ç”Ÿæˆäº†å…·æœ‰æœ€é«˜å³°å€¼ä¿¡å·å™ªå£°æ¯”ï¼ˆ29.87ï¼‰çš„ç…§ç‰‡çº§çœŸå®æ ‡è®°å›¾åƒæ•°æ®é›†ã€‚æˆ‘ä»¬è¿›ä¸€æ­¥è¯„ä¼°äº†ä½¿ç”¨çœŸå®å’Œåˆæˆå›¾åƒè®­ç»ƒçš„åŒ»å­¦ä¸“ç”¨ç¥ç»ç½‘ç»œåœ¨æœªè§è¿‡çš„çœŸå®ä¸–ç•Œå›¾åƒæ•°æ®é›†ä¸Šçš„æ€§èƒ½ã€‚æˆ‘ä»¬çš„ç»“æœè¡¨æ˜ï¼Œä½¿ç”¨åˆæˆå›¾åƒè®­ç»ƒçš„æ¨¡å‹æ€§èƒ½ä¼˜äºä½¿ç”¨æœ€æ–°æ ‡å‡†æ•°æ®å¢å¼ºçš„æ¨¡å‹ï¼Œæé«˜äº†çº¦10%ï¼Œå¯¼è‡´æ¨¡å‹æ€»ä½“æ€§èƒ½æé«˜äº†è¿‘15%ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.07897v1">PDF</a> 13 pages, 9 figures</p>
<p><strong>æ‘˜è¦</strong><br>     åŸºäºè®¡ç®—æœºè§†è§‰çš„æŠ€æœ¯é€šè¿‡æ¨è¿›å·¥å…·è¿½è¸ªã€æ£€æµ‹å’Œå®šä½æ¥æ˜¾è‘—å¢å¼ºæ‰‹æœ¯çš„è‡ªåŠ¨åŒ–ç¨‹åº¦ã€‚ç„¶è€Œï¼Œå½“å‰çš„æ•°æ®é©±åŠ¨æ–¹æ³•éœ€è¦å¤§é‡çš„é«˜è´¨é‡æ ‡è®°å›¾åƒæ•°æ®é›†ï¼Œè¿™é™åˆ¶äº†å®ƒä»¬åœ¨æ‰‹æœ¯æ•°æ®ç§‘å­¦ä¸­çš„åº”ç”¨ã€‚æˆ‘ä»¬çš„å·¥ä½œå¼•å…¥äº†ä¸€ç§æ–°çš„åŠ¨æ€é«˜æ–¯æ¶‚å¸ƒæŠ€æœ¯æ¥è§£å†³æ‰‹æœ¯å›¾åƒæ•°æ®é›†ä¸­æ•°æ®ç¼ºä¹çš„é—®é¢˜ã€‚æˆ‘ä»¬æå‡ºä¸€ä¸ªåŠ¨æ€é«˜æ–¯æ¨¡å‹æ¥è¡¨ç¤ºåŠ¨æ€æ‰‹æœ¯åœºæ™¯ï¼Œèƒ½å¤Ÿå®ç°ä»æœªè§è¿‡çš„è§†è§’å’Œå˜å½¢å¯¹æ‰‹æœ¯å™¨æ¢°è¿›è¡Œæ¸²æŸ“ï¼Œå¹¶å…·æœ‰çœŸå®çš„ç»„ç»‡èƒŒæ™¯ã€‚æˆ‘ä»¬é‡‡ç”¨åŠ¨æ€è®­ç»ƒè°ƒæ•´ç­–ç•¥ï¼Œä»¥è§£å†³ç”±ç°å®ä¸–ç•Œåœºæ™¯ä¸­çš„ç›¸æœºå§¿åŠ¿æ ¡å‡†ä¸è‰¯æ‰€å¸¦æ¥çš„æŒ‘æˆ˜ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜æå‡ºäº†ä¸€ç§åŸºäºåŠ¨æ€é«˜æ–¯çš„æ–¹æ³•ï¼Œå¯ä»¥è‡ªåŠ¨ä¸ºæˆ‘ä»¬åˆæˆçš„æ•°æ®ç”Ÿæˆæ³¨é‡Šã€‚ä¸ºäº†è¯„ä¼°ï¼Œæˆ‘ä»¬æ„å»ºäº†ä¸€ä¸ªæ–°çš„æ•°æ®é›†ï¼ŒåŒ…å«ä¸ƒä¸ªåœºæ™¯ï¼Œæœ‰14000å¸§çš„å·¥å…·å’Œç›¸æœºè¿åŠ¨ä»¥åŠå·¥å…·å…³èŠ‚è¿åŠ¨çš„ç”»é¢ï¼ŒèƒŒæ™¯æ˜¯ä¸€ä¸ªç¦»ä½“çš„çŒªæ¨¡å‹ã€‚ä½¿ç”¨æ­¤æ•°æ®é›†ï¼Œæˆ‘ä»¬åˆæˆåœ°å¤åˆ¶äº†åœºæ™¯å˜å½¢ä»çœŸå®æ•°æ®ï¼Œå…è®¸ç›´æ¥æ¯”è¾ƒåˆæˆå›¾åƒçš„è´¨é‡ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•ç”Ÿæˆäº†å…·æœ‰æœ€é«˜å³°å€¼ä¿¡å·å™ªå£°æ¯”ï¼ˆ29.87ï¼‰çš„ç…§ç‰‡çº§çœŸå®æ ‡è®°å›¾åƒæ•°æ®é›†ã€‚æˆ‘ä»¬è¿›ä¸€æ­¥è¯„ä¼°äº†åœ¨çœŸå®å’Œåˆæˆå›¾åƒä¸Šè®­ç»ƒçš„åŒ»ç–—ä¸“ç”¨ç¥ç»ç½‘ç»œåœ¨æœªè§è¿‡çš„çœŸå®ä¸–ç•Œå›¾åƒæ•°æ®é›†ä¸Šçš„æ€§èƒ½ã€‚ç»“æœè¡¨æ˜ï¼Œç”±æ‰€æå‡ºæ–¹æ³•ç”Ÿæˆçš„åˆæˆå›¾åƒè®­ç»ƒçš„æ¨¡å‹æ€§èƒ½æ¯”ä½¿ç”¨æœ€æ–°æ ‡å‡†æ•°æ®å¢å¼ºçš„æ¨¡å‹é«˜å‡º10%ï¼Œæ€»ä½“ä¸Šæé«˜äº†æ¨¡å‹æ€§èƒ½è¿‘15%ã€‚</p>
<p><strong>è¦ç‚¹</strong></p>
<ol>
<li>è®¡ç®—æœºè§†è§‰æŠ€æœ¯åœ¨æ‰‹æœ¯è‡ªåŠ¨åŒ–ä¸­æ‰®æ¼”é‡è¦è§’è‰²ï¼Œä½†æ•°æ®éœ€æ±‚æˆä¸ºé™åˆ¶ã€‚</li>
<li>å¼•å…¥åŠ¨æ€é«˜æ–¯æ¶‚å¸ƒæŠ€æœ¯è§£å†³æ‰‹æœ¯å›¾åƒæ•°æ®é›†ä¸­æ•°æ®ç¼ºä¹çš„é—®é¢˜ã€‚</li>
<li>æå‡ºåŠ¨æ€é«˜æ–¯æ¨¡å‹è¡¨ç¤ºåŠ¨æ€æ‰‹æœ¯åœºæ™¯ï¼Œèƒ½æ¸²æŸ“æ‰‹æœ¯å™¨æ¢°å¹¶å¤„ç†å¤æ‚çš„èƒŒæ™¯ã€‚</li>
<li>é‡‡ç”¨åŠ¨æ€è®­ç»ƒè°ƒæ•´ç­–ç•¥åº”å¯¹ç›¸æœºå§¿åŠ¿æ ¡å‡†çš„æŒ‘æˆ˜ã€‚</li>
<li>è‡ªåŠ¨ç”Ÿæˆåˆæˆæ•°æ®çš„æ³¨é‡Šæ–¹æ³•åŸºäºåŠ¨æ€é«˜æ–¯ã€‚</li>
<li>æ„å»ºæ–°æ•°æ®é›†è¿›è¡Œè¯„ä¼°ï¼ŒåŒ…å«å¤æ‚æ‰‹æœ¯åœºæ™¯å’ŒçœŸå®çš„çŒªæ¨¡å‹èƒŒæ™¯ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.07897">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-259a7aaff1d57ce3a40ba6bd75dcf67e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c51d898d127169ae262180f3927ff3b8.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-77e0f1e70ef232aed8626bcbf488b3dd.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c1c9d1c280a6d05b10f6a88ced11cba3.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-08dd91d3baafc26068ae48235d58bf37.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="Multi-view-Normal-and-Distance-Guidance-Gaussian-Splatting-for-Surface-Reconstruction"><a href="#Multi-view-Normal-and-Distance-Guidance-Gaussian-Splatting-for-Surface-Reconstruction" class="headerlink" title="Multi-view Normal and Distance Guidance Gaussian Splatting for Surface   Reconstruction"></a>Multi-view Normal and Distance Guidance Gaussian Splatting for Surface   Reconstruction</h2><p><strong>Authors:Bo Jia, Yanan Guo, Ying Chang, Benkui Zhang, Ying Xie, Kangning Du, Lin Cao</strong></p>
<p>3D Gaussian Splatting (3DGS) achieves remarkable results in the field of surface reconstruction. However, when Gaussian normal vectors are aligned within the single-view projection plane, while the geometry appears reasonable in the current view, biases may emerge upon switching to nearby views. To address the distance and global matching challenges in multi-view scenes, we design multi-view normal and distance-guided Gaussian splatting. This method achieves geometric depth unification and high-accuracy reconstruction by constraining nearby depth maps and aligning 3D normals. Specifically, for the reconstruction of small indoor and outdoor scenes, we propose a multi-view distance reprojection regularization module that achieves multi-view Gaussian alignment by computing the distance loss between two nearby views and the same Gaussian surface. Additionally, we develop a multi-view normal enhancement module, which ensures consistency across views by matching the normals of pixel points in nearby views and calculating the loss. Extensive experimental results demonstrate that our method outperforms the baseline in both quantitative and qualitative evaluations, significantly enhancing the surface reconstruction capability of 3DGS. </p>
<blockquote>
<p>3Dé«˜æ–¯è´´å›¾ï¼ˆ3DGSï¼‰åœ¨è¡¨é¢é‡å»ºé¢†åŸŸå–å¾—äº†æ˜¾è‘—æˆæœã€‚ç„¶è€Œï¼Œå½“é«˜æ–¯æ³•çº¿å‘é‡åœ¨å•è§†æŠ•å½±å¹³é¢å†…å¯¹é½æ—¶ï¼Œè™½ç„¶åœ¨å½“å‰è§†è§’ä¸‹å‡ ä½•ç»“æ„çœ‹èµ·æ¥æ˜¯åˆç†çš„ï¼Œä½†åœ¨åˆ‡æ¢åˆ°é‚»è¿‘è§†è§’æ—¶å¯èƒ½ä¼šå‡ºç°åå·®ã€‚ä¸ºäº†è§£å†³å¤šè§†è§’åœºæ™¯ä¸­çš„è·ç¦»å’Œå…¨å±€åŒ¹é…æŒ‘æˆ˜ï¼Œæˆ‘ä»¬è®¾è®¡äº†å¤šè§†è§’æ³•çº¿å’Œè·ç¦»å¼•å¯¼çš„é«˜æ–¯è´´å›¾æ–¹æ³•ã€‚é€šè¿‡çº¦æŸé‚»è¿‘æ·±åº¦å›¾å¹¶å¯¹é½3Dæ³•çº¿ï¼Œè¯¥æ–¹æ³•å®ç°äº†å‡ ä½•æ·±åº¦ç»Ÿä¸€å’Œé«˜ç²¾åº¦é‡å»ºã€‚å…·ä½“æ¥è¯´ï¼Œå¯¹äºå®¤å†…å¤–å°åœºæ™¯çš„é‡å»ºï¼Œæˆ‘ä»¬æå‡ºäº†å¤šè§†è§’è·ç¦»é‡æŠ•å½±æ­£åˆ™åŒ–æ¨¡å—ï¼Œé€šè¿‡è®¡ç®—ä¸¤ä¸ªé‚»è¿‘è§†è§’ä¸åŒä¸€é«˜æ–¯è¡¨é¢ä¹‹é—´çš„è·ç¦»æŸå¤±ï¼Œå®ç°å¤šè§†è§’é«˜æ–¯å¯¹é½ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜å¼€å‘äº†ä¸€ä¸ªå¤šè§†è§’æ³•çº¿å¢å¼ºæ¨¡å—ï¼Œé€šè¿‡åŒ¹é…é‚»è¿‘è§†è§’ä¸­åƒç´ ç‚¹çš„æ³•çº¿å¹¶è®¡ç®—æŸå¤±ï¼Œç¡®ä¿ä¸åŒè§†è§’ä¹‹é—´çš„ä¸€è‡´æ€§ã€‚å¤§é‡çš„å®éªŒç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨å®šé‡å’Œå®šæ€§è¯„ä¼°ä¸Šéƒ½ä¼˜äºåŸºçº¿æ–¹æ³•ï¼Œæ˜¾è‘—æé«˜äº†3DGSçš„è¡¨é¢é‡å»ºèƒ½åŠ›ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.07701v1">PDF</a> This paper has been accepted by IROS 2025</p>
<p><strong>Summary</strong></p>
<p>è¿™ç¯‡å…³äºä¸‰ç»´é«˜æ–¯æ¨¡æ¿æ³•ï¼ˆ3DGSï¼‰çš„æ–‡ç« ä¸»è¦è®¨è®ºäº†å¤šè§†å›¾é‡å»ºçš„é—®é¢˜å’Œè§£å†³æ–¹æ³•ã€‚ä¸ºæé«˜è¡¨é¢é‡å»ºçš„å‡†ç¡®æ€§ï¼Œæå‡ºå¤šè§†è§’æ­£å¸¸å’Œè·ç¦»å¼•å¯¼çš„é«˜æ–¯æ¨¡æ¿æ³•ï¼Œå®ç°äº†æ·±åº¦ç»Ÿä¸€å’Œé«˜ç²¾åº¦é‡å»ºã€‚å¯¹äºå®¤å†…å’Œå®¤å¤–å°åœºæ™¯çš„é‡å»ºï¼Œå¼•å…¥äº†å¤šè§†è§’è·ç¦»å†æŠ•å½±æ­£åˆ™åŒ–æ¨¡å—å’Œå¤šè§†è§’æ­£å¸¸å¢å¼ºæ¨¡å—ï¼Œå–å¾—äº†è‰¯å¥½çš„å¤šè§†è§’é«˜æ–¯å¯¹é½æ•ˆæœã€‚æ­¤æ–¹æ³•ç›¸è¾ƒäºåŸºçº¿æ–¹æ³•åœ¨å®šé‡å’Œå®šæ€§è¯„ä¼°ä¸Šè¡¨ç°å‡ºæ›´å¥½çš„æ€§èƒ½ï¼Œæ˜¾è‘—æå‡äº†3DGSçš„è¡¨é¢é‡å»ºèƒ½åŠ›ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<p>ä»¥ä¸‹æ˜¯å…³äºè¯¥æ–‡ç« çš„ä¸»è¦è§è§£ï¼š</p>
<ol>
<li>3DGSåœ¨å¤šè§†è§’é‡å»ºä¸­å­˜åœ¨è·ç¦»å’Œå…¨å±€åŒ¹é…æŒ‘æˆ˜ã€‚</li>
<li>æå‡ºå¤šè§†è§’æ­£å¸¸å’Œè·ç¦»å¼•å¯¼çš„é«˜æ–¯æ¨¡æ¿æ³•ï¼Œç”¨äºè§£å†³è¿™äº›æŒ‘æˆ˜ã€‚</li>
<li>é€šè¿‡çº¦æŸé‚»è¿‘æ·±åº¦å›¾å’Œå¯¹é½ä¸‰ç»´æ­£å¸¸å‘é‡å®ç°å‡ ä½•æ·±åº¦ç»Ÿä¸€å’Œé«˜ç²¾åº¦é‡å»ºã€‚</li>
<li>é’ˆå¯¹å®¤å†…å’Œå®¤å¤–å°åœºæ™¯çš„é‡å»ºï¼Œå¼•å…¥å¤šè§†è§’è·ç¦»å†æŠ•å½±æ­£åˆ™åŒ–æ¨¡å—ã€‚</li>
<li>å¼€å‘å¤šè§†è§’æ­£å¸¸å¢å¼ºæ¨¡å—ï¼Œç¡®ä¿è·¨è§†å›¾çš„ä¸€è‡´æ€§ã€‚</li>
<li>å¯¹æ¯”å®éªŒæ˜¾ç¤ºæ–°æ–¹æ³•åœ¨å®šé‡å’Œå®šæ€§è¯„ä¼°ä¸Šéƒ½ä¼˜äºåŸºçº¿æ–¹æ³•ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.07701">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-cc4c98771ef46aa25dd07a3223ca0910.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a8e8931ee993272e3dcbc60fdfed74fa.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-5cbe6f532c58912af6fdbd1cf76b3322.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-21f968f4386427148eeb320d00f436cf.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-2fdd1e52decbcdd1c685fb57c9fda9ee.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="Splat4D-Diffusion-Enhanced-4D-Gaussian-Splatting-for-Temporally-and-Spatially-Consistent-Content-Creation"><a href="#Splat4D-Diffusion-Enhanced-4D-Gaussian-Splatting-for-Temporally-and-Spatially-Consistent-Content-Creation" class="headerlink" title="Splat4D: Diffusion-Enhanced 4D Gaussian Splatting for Temporally and   Spatially Consistent Content Creation"></a>Splat4D: Diffusion-Enhanced 4D Gaussian Splatting for Temporally and   Spatially Consistent Content Creation</h2><p><strong>Authors:Minghao Yin, Yukang Cao, Songyou Peng, Kai Han</strong></p>
<p>Generating high-quality 4D content from monocular videos for applications such as digital humans and AR&#x2F;VR poses challenges in ensuring temporal and spatial consistency, preserving intricate details, and incorporating user guidance effectively. To overcome these challenges, we introduce Splat4D, a novel framework enabling high-fidelity 4D content generation from a monocular video. Splat4D achieves superior performance while maintaining faithful spatial-temporal coherence by leveraging multi-view rendering, inconsistency identification, a video diffusion model, and an asymmetric U-Net for refinement. Through extensive evaluations on public benchmarks, Splat4D consistently demonstrates state-of-the-art performance across various metrics, underscoring the efficacy of our approach. Additionally, the versatility of Splat4D is validated in various applications such as text&#x2F;image conditioned 4D generation, 4D human generation, and text-guided content editing, producing coherent outcomes following user instructions. </p>
<blockquote>
<p>ä»å•ç›®è§†é¢‘ä¸­ç”Ÿæˆé«˜è´¨é‡4Då†…å®¹ï¼Œç”¨äºæ•°å­—äººç±»å’ŒAR&#x2F;VRç­‰åº”ç”¨ï¼Œåœ¨ä¿éšœæ—¶é—´ç©ºé—´ä¸€è‡´æ€§ã€ä¿ç•™ç²¾ç»†ç»†èŠ‚å’Œæœ‰æ•ˆèå…¥ç”¨æˆ·æŒ‡å¯¼æ–¹é¢é¢ä¸´æŒ‘æˆ˜ã€‚ä¸ºäº†åº”å¯¹è¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æ¨å‡ºäº†Splat4Dï¼Œè¿™æ˜¯ä¸€ä¸ªæ–°å‹æ¡†æ¶ï¼Œèƒ½å¤Ÿä»å•ç›®è§†é¢‘ä¸­ç”Ÿæˆé«˜ä¿çœŸ4Då†…å®¹ã€‚Splat4Dé€šè¿‡åˆ©ç”¨å¤šè§†è§’æ¸²æŸ“ã€ä¸ä¸€è‡´æ€§è¯†åˆ«ã€è§†é¢‘æ‰©æ•£æ¨¡å‹ä»¥åŠç”¨äºç²¾ç»†åŒ–çš„ä¸å¯¹ç§°U-Netï¼Œåœ¨ä¿æŒæ—¶ç©ºè¿è´¯æ€§çš„åŒæ—¶å®ç°äº†å“è¶Šæ€§èƒ½ã€‚åœ¨å…¬å…±åŸºå‡†æµ‹è¯•ä¸Šçš„å¹¿æ³›è¯„ä¼°è¡¨æ˜ï¼ŒSplat4Dåœ¨å„ç§æŒ‡æ ‡ä¸Šå‡è¡¨ç°å‡ºå“è¶Šçš„æ€§èƒ½ï¼Œå‡¸æ˜¾äº†æˆ‘ä»¬çš„æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚æ­¤å¤–ï¼ŒSplat4Dçš„é€šç”¨æ€§åœ¨å„ç§åº”ç”¨ä¸­å¾—åˆ°äº†éªŒè¯ï¼Œå¦‚æ–‡æœ¬&#x2F;å›¾åƒæ§åˆ¶çš„4Dç”Ÿæˆã€4Däººç±»ç”Ÿæˆå’Œæ–‡æœ¬å¼•å¯¼çš„å†…å®¹ç¼–è¾‘ï¼Œèƒ½å¤Ÿæ ¹æ®ç”¨æˆ·çš„æŒ‡ä»¤äº§ç”Ÿè¿è´¯çš„ç»“æœã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.07557v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†ä»å•ç›®è§†é¢‘ä¸­ç”Ÿæˆé«˜è´¨é‡4Då†…å®¹æ‰€é¢ä¸´çš„æŒ‘æˆ˜ï¼ŒåŒ…æ‹¬ç¡®ä¿æ—¶é—´æ€§å’Œç©ºé—´æ€§çš„ä¸€è‡´æ€§ã€ä¿ç•™ç»†èŠ‚ä»¥åŠæœ‰æ•ˆåœ°èå…¥ç”¨æˆ·æŒ‡å¯¼ã€‚ä¸ºè§£å†³è¿™äº›æŒ‘æˆ˜ï¼Œæœ¬æ–‡æå‡ºäº†Splat4Dè¿™ä¸€æ–°å‹æ¡†æ¶ï¼Œè¯¥æ¡†æ¶èƒ½å¤Ÿå®ç°ä»å•ç›®è§†é¢‘çš„é«˜ä¿çœŸ4Då†…å®¹ç”Ÿæˆã€‚Splat4Dé€šè¿‡åˆ©ç”¨å¤šè§†è§’æ¸²æŸ“ã€ä¸ä¸€è‡´æ€§è¯†åˆ«ã€è§†é¢‘æ‰©æ•£æ¨¡å‹ä»¥åŠä¸å¯¹ç§°U-Netè¿›è¡Œç²¾ç»†åŒ–å¤„ç†ï¼Œå–å¾—äº†å“è¶Šçš„æ€§èƒ½è¡¨ç°ã€‚åœ¨å…¬å…±åŸºå‡†æµ‹è¯•ä¸Šçš„å¹¿æ³›è¯„ä¼°è¯æ˜äº†Splat4Dåœ¨å„ç§æŒ‡æ ‡ä¸Šçš„è¡¨ç°å‡è¾¾åˆ°ä¸šç•Œé¢†å…ˆï¼ŒéªŒè¯äº†å…¶åœ¨æ–‡æœ¬&#x2F;å›¾åƒæ¡ä»¶é©±åŠ¨çš„4Dç”Ÿæˆã€4Däººåƒç”Ÿæˆä»¥åŠæ–‡æœ¬å¼•å¯¼çš„å†…å®¹ç¼–è¾‘ç­‰å¤šç§åº”ç”¨ä¸­çš„é€šç”¨æ€§å’Œæœ‰æ•ˆæ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ç”Ÿæˆé«˜è´¨é‡4Då†…å®¹é¢ä¸´çš„æŒ‘æˆ˜åŒ…æ‹¬ç¡®ä¿æ—¶é—´æ€§å’Œç©ºé—´æ€§çš„ä¸€è‡´æ€§ã€ä¿ç•™ç»†èŠ‚ä»¥åŠèå…¥ç”¨æˆ·æŒ‡å¯¼ã€‚</li>
<li>Splat4Dæ¡†æ¶èƒ½å¤Ÿå®ç°ä»å•ç›®è§†é¢‘çš„é«˜ä¿çœŸ4Då†…å®¹ç”Ÿæˆã€‚</li>
<li>Splat4Dåˆ©ç”¨å¤šè§†è§’æ¸²æŸ“ã€ä¸ä¸€è‡´æ€§è¯†åˆ«ç­‰æŠ€æœ¯å®ç°å“è¶Šæ€§èƒ½ã€‚</li>
<li>Splat4Dåœ¨å…¬å…±åŸºå‡†æµ‹è¯•ä¸Šçš„è¡¨ç°è¾¾åˆ°ä¸šç•Œé¢†å…ˆã€‚</li>
<li>Splat4Då…·æœ‰å¤šç§åº”ç”¨ï¼ŒåŒ…æ‹¬æ–‡æœ¬&#x2F;å›¾åƒæ¡ä»¶é©±åŠ¨çš„4Dç”Ÿæˆã€4Däººåƒç”Ÿæˆä»¥åŠæ–‡æœ¬å¼•å¯¼çš„å†…å®¹ç¼–è¾‘ç­‰ã€‚</li>
<li>Splat4Dèƒ½å¤Ÿäº§ç”Ÿè¿è´¯çš„ç»“æœï¼Œå¹¶éµå¾ªç”¨æˆ·æŒ‡å¯¼ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.07557">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-9ac0633b2afcf959fbf220b47ed643aa.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-3b9674feceb14948ed8172e036a84a91.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-a5130cad14d07ccc73a468a9dae761b1.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="Novel-View-Synthesis-with-Gaussian-Splatting-Impact-on-Photogrammetry-Model-Accuracy-and-Resolution"><a href="#Novel-View-Synthesis-with-Gaussian-Splatting-Impact-on-Photogrammetry-Model-Accuracy-and-Resolution" class="headerlink" title="Novel View Synthesis with Gaussian Splatting: Impact on Photogrammetry   Model Accuracy and Resolution"></a>Novel View Synthesis with Gaussian Splatting: Impact on Photogrammetry   Model Accuracy and Resolution</h2><p><strong>Authors:Pranav Chougule</strong></p>
<p>In this paper, I present a comprehensive study comparing Photogrammetry and Gaussian Splatting techniques for 3D model reconstruction and view synthesis. I created a dataset of images from a real-world scene and constructed 3D models using both methods. To evaluate the performance, I compared the models using structural similarity index (SSIM), peak signal-to-noise ratio (PSNR), learned perceptual image patch similarity (LPIPS), and lp&#x2F;mm resolution based on the USAF resolution chart. A significant contribution of this work is the development of a modified Gaussian Splatting repository, which I forked and enhanced to enable rendering images from novel camera poses generated in the Blender environment. This innovation allows for the synthesis of high-quality novel views, showcasing the flexibility and potential of Gaussian Splatting. My investigation extends to an augmented dataset that includes both original ground images and novel views synthesized via Gaussian Splatting. This augmented dataset was employed to generate a new photogrammetry model, which was then compared against the original photogrammetry model created using only the original images. The results demonstrate the efficacy of using Gaussian Splatting to generate novel high-quality views and its potential to improve photogrammetry-based 3D reconstructions. The comparative analysis highlights the strengths and limitations of both approaches, providing valuable information for applications in extended reality (XR), photogrammetry, and autonomous vehicle simulations. Code is available at <a target="_blank" rel="noopener" href="https://github.com/pranavc2255/gaussian-splatting-novel-view-render.git">https://github.com/pranavc2255/gaussian-splatting-novel-view-render.git</a>. </p>
<blockquote>
<p>åœ¨è¿™ç¯‡è®ºæ–‡ä¸­ï¼Œæˆ‘å¯¹æ‘„å½±æµ‹é‡æ³•å’Œé«˜æ–¯è´´å›¾æŠ€æœ¯è¿›è¡Œäº†å…¨é¢çš„æ¯”è¾ƒç ”ç©¶ï¼Œè¿™ä¸¤ç§æŠ€æœ¯ç”¨äº3Dæ¨¡å‹é‡å»ºå’Œè§†å›¾åˆæˆã€‚æˆ‘ä»çœŸå®åœºæ™¯åˆ›å»ºäº†ä¸€ä¸ªå›¾åƒæ•°æ®é›†ï¼Œå¹¶ä½¿ç”¨è¿™ä¸¤ç§æ–¹æ³•æ„å»ºäº†3Dæ¨¡å‹ã€‚ä¸ºäº†è¯„ä¼°æ€§èƒ½ï¼Œæˆ‘ä½¿ç”¨ç»“æ„ç›¸ä¼¼æ€§æŒ‡æ•°ï¼ˆSSIMï¼‰ã€å³°å€¼ä¿¡å™ªæ¯”ï¼ˆPSNRï¼‰ã€å­¦ä¹ æ„ŸçŸ¥å›¾åƒå—ç›¸ä¼¼æ€§ï¼ˆLPIPSï¼‰ä»¥åŠåŸºäºç¾å›½ç©ºå†›åˆ†è¾¨ç‡å›¾çš„lp&#x2F;mmåˆ†è¾¨ç‡å¯¹æ¨¡å‹è¿›è¡Œäº†æ¯”è¾ƒã€‚è¿™é¡¹å·¥ä½œçš„ä¸€ä¸ªé‡è¦è´¡çŒ®æ˜¯å¼€å‘äº†ä¸€ä¸ªä¿®æ”¹åçš„é«˜æ–¯è´´å›¾å­˜å‚¨åº“ï¼Œæˆ‘å¯¹å…¶è¿›è¡Œäº†åˆ†å‰å¹¶å¢å¼ºå…¶åŠŸèƒ½ï¼Œä»¥å‘ˆç°Blenderç¯å¢ƒä¸­ç”Ÿæˆçš„æ–°å‹ç›¸æœºå§¿æ€çš„å›¾åƒã€‚è¿™ä¸€åˆ›æ–°å…è®¸åˆæˆé«˜è´¨é‡çš„æ–°å‹è§†å›¾ï¼Œå±•ç¤ºäº†é«˜æ–¯è´´å›¾çš„çµæ´»æ€§å’Œæ½œåŠ›ã€‚æˆ‘çš„è°ƒæŸ¥æ‰©å±•åˆ°ä¸€ä¸ªå¢å¼ºæ•°æ®é›†ï¼Œå…¶ä¸­åŒ…æ‹¬åŸå§‹åœ°é¢å›¾åƒå’Œé€šè¿‡é«˜æ–¯è´´å›¾åˆæˆçš„æ–°å‹è§†å›¾ã€‚è¿™ä¸ªå¢å¼ºæ•°æ®é›†è¢«ç”¨æ¥ç”Ÿæˆä¸€ä¸ªæ–°çš„æ‘„å½±æµ‹é‡æ¨¡å‹ï¼Œç„¶åå°†å…¶ä¸ä»…ä½¿ç”¨åŸå§‹å›¾åƒåˆ›å»ºçš„åŸå§‹æ‘„å½±æµ‹é‡æ¨¡å‹è¿›è¡Œæ¯”è¾ƒã€‚ç»“æœè¡¨æ˜ï¼Œä½¿ç”¨é«˜æ–¯è´´å›¾ç”Ÿæˆæ–°å‹é«˜è´¨é‡è§†å›¾çš„æ•ˆç”¨åŠå…¶æ”¹å–„åŸºäºæ‘„å½±æµ‹é‡çš„3Dé‡å»ºçš„æ½œåŠ›ã€‚æ¯”è¾ƒåˆ†æçªå‡ºäº†è¿™ä¸¤ç§æ–¹æ³•çš„ä¼˜åŠ¿å’Œå±€é™æ€§ï¼Œä¸ºæ‰©å±•ç°å®ï¼ˆXRï¼‰ã€æ‘„å½±æµ‹é‡å’Œè‡ªåŠ¨é©¾é©¶æ±½è½¦æ¨¡æ‹Ÿåº”ç”¨æä¾›äº†æœ‰ä»·å€¼çš„ä¿¡æ¯ã€‚ä»£ç å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/pranavc2255/gaussian-splatting-novel-view-render.git%E4%B8%8A%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/pranavc2255/gaussian-splatting-novel-view-render.gitä¸Šæ‰¾åˆ°ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.07483v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡å¯¹æ¯”ç ”ç©¶äº†Photogrammetryå’ŒGaussian SplattingæŠ€æœ¯åœ¨3Dæ¨¡å‹é‡å»ºå’Œè§†å›¾åˆæˆæ–¹é¢çš„åº”ç”¨ã€‚ä½œè€…åˆ›å»ºäº†ä¸€ä¸ªçœŸå®åœºæ™¯å›¾åƒæ•°æ®é›†ï¼Œä½¿ç”¨ä¸¤ç§æ–¹æ³•æ„å»º3Dæ¨¡å‹ï¼Œå¹¶é€šè¿‡ç»“æ„ç›¸ä¼¼æ€§æŒ‡æ•°ï¼ˆSSIMï¼‰ã€å³°å€¼ä¿¡å™ªæ¯”ï¼ˆPSNRï¼‰ã€å­¦ä¹ æ„ŸçŸ¥å›¾åƒå—ç›¸ä¼¼æ€§ï¼ˆLPIPSï¼‰å’ŒUSAFåˆ†è¾¨ç‡å›¾è¿›è¡Œäº†æ¨¡å‹è¯„ä¼°ã€‚é‡è¦åˆ›æ–°åœ¨äºæ”¹è¿›äº†Gaussian Splattingåº“ï¼Œä½¿å…¶èƒ½å¤Ÿåœ¨Blenderç¯å¢ƒä¸­ç”Ÿæˆçš„æ–°ç›¸æœºå§¿æ€ä¸‹æ¸²æŸ“å›¾åƒã€‚è¯¥ç ”ç©¶è¿˜æ‰©å±•äº†æ•°æ®é›†ï¼ŒåŒ…æ‹¬åŸå§‹åœ°é¢å›¾åƒå’Œé€šè¿‡Gaussian Splattingåˆæˆçš„æ–°è§†å›¾ï¼Œè¿›ä¸€æ­¥å¯¹æ¯”äº†ä»…ä½¿ç”¨åŸå§‹å›¾åƒçš„æ‘„å½±æµ‹é‡æ¨¡å‹ä¸é‡‡ç”¨åˆæˆè§†å›¾çš„æ–°å‹æ‘„å½±æµ‹é‡æ¨¡å‹çš„æ€§èƒ½ã€‚ç»“æœè¡¨æ˜ï¼Œåˆ©ç”¨Gaussian Splattingç”Ÿæˆæ–°å‹é«˜è´¨é‡è§†å›¾çš„æœ‰æ•ˆæ€§åŠå…¶å¯¹æ‘„å½±æµ‹é‡åŸºäºçš„3Dé‡å»ºçš„æ½œåŠ›ã€‚æ¯”è¾ƒåˆ†æçªå‡ºäº†ä¸¤ç§æ–¹æ³•çš„ä¼˜ç‚¹å’Œå±€é™æ€§ï¼Œä¸ºæ‰©å±•ç°å®ï¼ˆXRï¼‰ã€æ‘„å½±æµ‹é‡å’Œè‡ªåŠ¨é©¾é©¶æ±½è½¦æ¨¡æ‹Ÿåº”ç”¨æä¾›äº†æœ‰ä»·å€¼çš„ä¿¡æ¯ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>è®ºæ–‡å¯¹Photogrammetryå’ŒGaussian SplattingæŠ€æœ¯è¿›è¡Œäº†å…¨é¢çš„æ¯”è¾ƒç ”ç©¶ã€‚</li>
<li>ä½œè€…åˆ›å»ºäº†ä¸€ä¸ªçœŸå®åœºæ™¯å›¾åƒæ•°æ®é›†ï¼Œå¹¶ä½¿ç”¨ä¸¤ç§æ–¹æ³•æ„å»º3Dæ¨¡å‹ã€‚</li>
<li>é€šè¿‡å¤šç§æŒ‡æ ‡è¯„ä¼°äº†æ¨¡å‹çš„æ€§èƒ½ï¼ŒåŒ…æ‹¬SSIMã€PSNRã€LPIPSå’ŒUSAFåˆ†è¾¨ç‡å›¾ã€‚</li>
<li>è®ºæ–‡å¯¹Gaussian Splattingåº“è¿›è¡Œäº†æ”¹è¿›ï¼Œå¯ä»¥åœ¨æ–°ç›¸æœºå§¿æ€ä¸‹ç”Ÿæˆé«˜è´¨é‡æ¸²æŸ“å›¾åƒã€‚</li>
<li>ç ”ç©¶è¿˜æ¶‰åŠæ‰©å±•æ•°æ®é›†çš„ä½¿ç”¨ï¼ŒåŒ…æ‹¬åŸå§‹åœ°é¢å›¾åƒå’Œé€šè¿‡Gaussian SplattingæŠ€æœ¯åˆæˆçš„è§†å›¾ã€‚</li>
<li>å¯¹æ¯”äº†ä»…ä½¿ç”¨åŸå§‹å›¾åƒçš„æ‘„å½±æµ‹é‡æ¨¡å‹ä¸ä½¿ç”¨åˆæˆè§†å›¾çš„æ–°å‹æ‘„å½±æµ‹é‡æ¨¡å‹çš„æ€§èƒ½å·®å¼‚ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.07483">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-f9cc44dd763b8a4dd1a2d9f0dbf7de45.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c52ff65544e37de3d7a9c012ef551f11.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c4f1a09dc15ed1bdb9ee1af3688ddb16.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-0e46518cb1c9cff9f9a826f228d13dce.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-34783b08273cbbc79ac11f02dcd0a379.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-256a2dc21ad7930bf785c32ff621f9a8.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-26903491960ba43a92932aa67fbd7340.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-1fb3c51d747c2ee44e5737de956038e5.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-af054cba4df426885695f8a8dcaf4d25.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-710df021b07e410c5d5901ab5302fbd8.jpg" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="CharacterShot-Controllable-and-Consistent-4D-Character-Animation"><a href="#CharacterShot-Controllable-and-Consistent-4D-Character-Animation" class="headerlink" title="CharacterShot: Controllable and Consistent 4D Character Animation"></a>CharacterShot: Controllable and Consistent 4D Character Animation</h2><p><strong>Authors:Junyao Gao, Jiaxing Li, Wenran Liu, Yanhong Zeng, Fei Shen, Kai Chen, Yanan Sun, Cairong Zhao</strong></p>
<p>In this paper, we propose \textbf{CharacterShot}, a controllable and consistent 4D character animation framework that enables any individual designer to create dynamic 3D characters (i.e., 4D character animation) from a single reference character image and a 2D pose sequence. We begin by pretraining a powerful 2D character animation model based on a cutting-edge DiT-based image-to-video model, which allows for any 2D pose sequnce as controllable signal. We then lift the animation model from 2D to 3D through introducing dual-attention module together with camera prior to generate multi-view videos with spatial-temporal and spatial-view consistency. Finally, we employ a novel neighbor-constrained 4D gaussian splatting optimization on these multi-view videos, resulting in continuous and stable 4D character representations. Moreover, to improve character-centric performance, we construct a large-scale dataset Character4D, containing 13,115 unique characters with diverse appearances and motions, rendered from multiple viewpoints. Extensive experiments on our newly constructed benchmark, CharacterBench, demonstrate that our approach outperforms current state-of-the-art methods. Code, models, and datasets will be publicly available at <a target="_blank" rel="noopener" href="https://github.com/Jeoyal/CharacterShot">https://github.com/Jeoyal/CharacterShot</a>. </p>
<blockquote>
<p>æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†<strong>CharacterShot</strong>ï¼Œè¿™æ˜¯ä¸€ä¸ªå¯æ§ä¸”ä¸€è‡´çš„4Dè§’è‰²åŠ¨ç”»æ¡†æ¶ï¼Œå®ƒå…è®¸ä»»ä½•ä¸ªäººè®¾è®¡å¸ˆä»å•ä¸ªå‚è€ƒè§’è‰²å›¾åƒå’Œ2Då§¿åŠ¿åºåˆ—ä¸­åˆ›å»ºåŠ¨æ€3Dè§’è‰²ï¼ˆå³4Dè§’è‰²åŠ¨ç”»ï¼‰ã€‚æˆ‘ä»¬é¦–å…ˆåŸºäºå…ˆè¿›çš„DiTå›¾åƒåˆ°è§†é¢‘æ¨¡å‹çš„å¼ºå¤§2Dè§’è‰²åŠ¨ç”»æ¨¡å‹è¿›è¡Œé¢„è®­ç»ƒï¼Œè¯¥æ¨¡å‹å…è®¸ä»»ä½•2Då§¿åŠ¿åºåˆ—ä½œä¸ºå¯æ§ä¿¡å·ã€‚ç„¶åæˆ‘ä»¬é€šè¿‡å¼•å…¥åŒæ³¨æ„åŠ›æ¨¡å—å’Œç›¸æœºå…ˆéªŒï¼Œå°†åŠ¨ç”»æ¨¡å‹ä»2Dæå‡åˆ°3Dï¼Œç”Ÿæˆå…·æœ‰æ—¶ç©ºå’Œè§†ç©ºä¸€è‡´æ€§çš„å¤šè§†è§’è§†é¢‘ã€‚æœ€åï¼Œæˆ‘ä»¬åœ¨è¿™äº›å¤šè§†è§’è§†é¢‘ä¸Šé‡‡ç”¨æ–°å‹é‚»åŸŸçº¦æŸçš„4Dé«˜æ–¯ç‚¹æä¼˜åŒ–æ–¹æ³•ï¼Œäº§ç”Ÿè¿ç»­ç¨³å®šçš„4Dè§’è‰²è¡¨ç¤ºã€‚æ­¤å¤–ï¼Œä¸ºäº†æå‡ä»¥è§’è‰²ä¸ºä¸­å¿ƒçš„æ€§èƒ½ï¼Œæˆ‘ä»¬æ„å»ºäº†ä¸€ä¸ªå¤§è§„æ¨¡æ•°æ®é›†Character4Dï¼ŒåŒ…å«ä»å¤šä¸ªè§†è§’æ¸²æŸ“çš„å…·æœ‰ä¸åŒå¤–è§‚å’ŒåŠ¨ä½œçš„ç‹¬ç‰¹è§’è‰²å›¾åƒå…±13,115å¼ ã€‚åœ¨æˆ‘ä»¬æ–°æ„å»ºçš„åŸºå‡†æµ‹è¯•CharacterBenchä¸Šçš„å¤§é‡å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•ä¼˜äºå½“å‰æœ€å…ˆè¿›çš„ç®—æ³•ã€‚ä»£ç ã€æ¨¡å‹å’Œæ•°æ®é›†å°†åœ¨<a target="_blank" rel="noopener" href="https://github.com/Jeoyal/CharacterShot%E5%85%AC%E5%BC%80%E5%8F%AF%E7%94%A8%E3%80%82">https://github.com/Jeoyal/CharacterShotå…¬å¼€å¯ç”¨ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.07409v1">PDF</a> 13 pages, 10 figures. Code at <a target="_blank" rel="noopener" href="https://github.com/Jeoyal/CharacterShot">https://github.com/Jeoyal/CharacterShot</a></p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ä¸ªå¯æ§ä¸”ä¸€è‡´çš„4Dè§’è‰²åŠ¨ç”»æ¡†æ¶â€”â€”CharacterShotã€‚è¯¥æ¡†æ¶å…è®¸è®¾è®¡å¸ˆä»…é€šè¿‡å•ä¸ªå‚è€ƒè§’è‰²å›¾åƒå’Œ2Då§¿æ€åºåˆ—åˆ›å»ºåŠ¨æ€çš„3Dè§’è‰²ï¼ˆå³4Dè§’è‰²åŠ¨ç”»ï¼‰ã€‚é€šè¿‡åŸºäºå…ˆè¿›çš„DiTå›¾åƒåˆ°è§†é¢‘æ¨¡å‹çš„2Dè§’è‰²åŠ¨ç”»æ¨¡å‹è¿›è¡Œé¢„è®­ç»ƒï¼Œå¼•å…¥åŒæ³¨æ„åŠ›æ¨¡å—å’Œç›¸æœºå…ˆéªŒï¼Œå°†åŠ¨ç”»æ¨¡å‹ä»2Dæå‡åˆ°3Dï¼Œç”Ÿæˆå…·æœ‰æ—¶ç©ºå’Œç©ºè§†ä¸€è‡´æ€§çš„å¤šè§†è§’è§†é¢‘ã€‚é‡‡ç”¨æ–°å‹é‚»å±…çº¦æŸçš„4Dé«˜æ–¯å–·æ¶‚ä¼˜åŒ–æŠ€æœ¯ï¼Œå®ç°è¿ç»­ç¨³å®šçš„4Dè§’è‰²è¡¨ç¤ºã€‚æ­¤å¤–ï¼Œä¸ºæå‡è§’è‰²ä¸ºä¸­å¿ƒçš„æ€§èƒ½ï¼Œæ„å»ºäº†å¤§è§„æ¨¡Character4Dæ•°æ®é›†ï¼ŒåŒ…å«13,115ä¸ªç‹¬ç‰¹è§’è‰²ï¼Œå…·æœ‰å¤šæ ·åŒ–çš„å¤–è§‚å’Œè¿åŠ¨ï¼Œä»å¤šä¸ªè§†è§’è¿›è¡Œæ¸²æŸ“ã€‚åœ¨å…¨æ–°æ„å»ºçš„CharacterBenchåŸºå‡†æµ‹è¯•ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•ä¼˜äºå½“å‰çš„æœ€ä¼˜æ–¹æ³•ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>CharacterShotæ˜¯ä¸€ä¸ª4Dè§’è‰²åŠ¨ç”»æ¡†æ¶ï¼Œèƒ½ä»å•ä¸€å‚è€ƒè§’è‰²å›¾åƒå’Œ2Då§¿æ€åºåˆ—åˆ›å»ºåŠ¨æ€3Dè§’è‰²ã€‚</li>
<li>åˆ©ç”¨å…ˆè¿›çš„DiTå›¾åƒåˆ°è§†é¢‘æ¨¡å‹è¿›è¡Œ2Dè§’è‰²åŠ¨ç”»æ¨¡å‹çš„é¢„è®­ç»ƒï¼Œå®ç°å¯æ§çš„2Då§¿æ€åºåˆ—ã€‚</li>
<li>é€šè¿‡å¼•å…¥åŒæ³¨æ„åŠ›æ¨¡å—å’Œç›¸æœºå…ˆéªŒï¼Œå°†åŠ¨ç”»æ¨¡å‹ä»2Dæå‡åˆ°3Dã€‚</li>
<li>ç”Ÿæˆå…·æœ‰æ—¶ç©ºå’Œç©ºè§†ä¸€è‡´æ€§çš„å¤šè§†è§’è§†é¢‘ã€‚</li>
<li>é‡‡ç”¨é‚»å±…çº¦æŸçš„4Dé«˜æ–¯å–·æ¶‚ä¼˜åŒ–æŠ€æœ¯ï¼Œç¡®ä¿4Dè§’è‰²è¡¨ç¤ºçš„è¿ç»­ç¨³å®šæ€§ã€‚</li>
<li>æ„å»ºäº†å¤§è§„æ¨¡Character4Dæ•°æ®é›†ï¼ŒåŒ…å«å¤šæ ·åŒ–å¤–è§‚å’Œè¿åŠ¨çš„ç‹¬ç‰¹è§’è‰²ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.07409">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-b7e282f2852c99c837990dd2aba595b1.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-9276adab63c1db9a145ac88dd250e439.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-6a7d949fa3fed4f144fd91df20ded1ce.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-6de1e035b0e396d07d8f4a4dc69ab5db.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-4c831841e1e6063a57c10dabdc2c418b.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-d046f99a90a7de1df3baa6bd7f84b6a2.jpg" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1><h2 id="DIP-GS-Deep-Image-Prior-For-Gaussian-Splatting-Sparse-View-Recovery"><a href="#DIP-GS-Deep-Image-Prior-For-Gaussian-Splatting-Sparse-View-Recovery" class="headerlink" title="DIP-GS: Deep Image Prior For Gaussian Splatting Sparse View Recovery"></a>DIP-GS: Deep Image Prior For Gaussian Splatting Sparse View Recovery</h2><p><strong>Authors:Rajaei Khatib, Raja Giryes</strong></p>
<p>3D Gaussian Splatting (3DGS) is a leading 3D scene reconstruction method, obtaining high-quality reconstruction with real-time rendering runtime performance. The main idea behind 3DGS is to represent the scene as a collection of 3D gaussians, while learning their parameters to fit the given views of the scene. While achieving superior performance in the presence of many views, 3DGS struggles with sparse view reconstruction, where the input views are sparse and do not fully cover the scene and have low overlaps. In this paper, we propose DIP-GS, a Deep Image Prior (DIP) 3DGS representation. By using the DIP prior, which utilizes internal structure and patterns, with coarse-to-fine manner, DIP-based 3DGS can operate in scenarios where vanilla 3DGS fails, such as sparse view recovery. Note that our approach does not use any pre-trained models such as generative models and depth estimation, but rather relies only on the input frames. Among such methods, DIP-GS obtains state-of-the-art (SOTA) competitive results on various sparse-view reconstruction tasks, demonstrating its capabilities. </p>
<blockquote>
<p>3Dé«˜æ–¯æ‹¼è´´ï¼ˆ3DGSï¼‰æ˜¯ä¸€ç§é¢†å…ˆçš„3Dåœºæ™¯é‡å»ºæ–¹æ³•ï¼Œå…·æœ‰å®æ—¶æ¸²æŸ“è¿è¡Œæ—¶æ€§èƒ½ï¼Œå¹¶èƒ½è·å¾—é«˜è´¨é‡é‡å»ºã€‚3DGSçš„ä¸»è¦æ€æƒ³æ˜¯å°†åœºæ™¯è¡¨ç¤ºä¸º3Dé«˜æ–¯é›†åˆï¼ŒåŒæ—¶å­¦ä¹ å…¶å‚æ•°ä»¥é€‚åº”åœºæ™¯çš„ç»™å®šè§†å›¾ã€‚è™½ç„¶åœ¨å¤šè§†å›¾æƒ…å†µä¸‹è¡¨ç°ä¼˜è¶Šï¼Œä½†3DGSåœ¨ç¨€ç–è§†å›¾é‡å»ºæ–¹é¢å­˜åœ¨å›°éš¾ï¼Œå³è¾“å…¥è§†å›¾ç¨€ç–ä¸”ä¸å…¨é¢è¦†ç›–åœºæ™¯ï¼Œé‡å åº¦è¾ƒä½ã€‚æœ¬æ–‡æå‡ºäº†DIP-GSï¼Œä¸€ç§åŸºäºæ·±åº¦å›¾åƒå…ˆéªŒï¼ˆDIPï¼‰çš„3DGSè¡¨ç¤ºæ–¹æ³•ã€‚é€šè¿‡ä½¿ç”¨DIPå…ˆéªŒï¼Œåˆ©ç”¨å†…éƒ¨ç»“æ„æ¨¡å¼å’Œç”±ç²—åˆ°ç»†çš„æ–¹å¼ï¼ŒåŸºäºDIPçš„3DGSå¯ä»¥åœ¨æ™®é€š3DGSå¤±è´¥çš„æƒ…å†µä¸‹è¿›è¡Œæ“ä½œï¼Œå¦‚ç¨€ç–è§†å›¾æ¢å¤ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œæˆ‘ä»¬çš„æ–¹æ³•æ²¡æœ‰ä½¿ç”¨ä»»ä½•é¢„è®­ç»ƒæ¨¡å‹ï¼Œå¦‚ç”Ÿæˆæ¨¡å‹å’Œæ·±åº¦ä¼°è®¡ï¼Œè€Œæ˜¯ä»…ä¾èµ–äºè¾“å…¥å¸§ã€‚åœ¨è¿™äº›æ–¹æ³•ä¸­ï¼ŒDIP-GSåœ¨å„ç§ç¨€ç–è§†å›¾é‡å»ºä»»åŠ¡ä¸Šå–å¾—äº†æœ€å…ˆè¿›çš„ç«äº‰ç»“æœï¼Œè¯æ˜äº†å…¶èƒ½åŠ›ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.07372v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†ä¸‰ç»´é«˜æ–¯å±•å¼€æŠ€æœ¯ï¼ˆ3DGSï¼‰çš„ä¸€ç§æ”¹è¿›æ–¹æ³•â€”â€”DIP-GSã€‚ç›¸è¾ƒäºä¼ ç»Ÿä¸‰ç»´é‡å»ºæ–¹æ³•ï¼ŒDIP-GSå¼•å…¥äº†ä¸€ç§ç§°ä¸ºæ·±åº¦å›¾åƒå…ˆéªŒï¼ˆDIPï¼‰çš„æ–°æ€è·¯ï¼Œæ— éœ€ä¾èµ–å¤æ‚çš„é¢„è®­ç»ƒæ¨¡å‹å³å¯åœ¨ç¨€ç–è§†å›¾æ¢å¤åœºæ™¯ä¸­ä½¿ç”¨ï¼Œä»¥é«˜è¿˜åŸåº¦çš„é‡å»ºè´¨é‡å’Œé«˜æ•ˆçš„æ¸²æŸ“é€Ÿåº¦å±•ç¤ºåœºæ™¯å†…å®¹ã€‚åœ¨å¤„ç†ç¨€ç¨€ç–è§†å›¾æ—¶å…·æœ‰å‡ºè‰²è¡¨ç°ã€‚å…¶åœ¨æ— å¯†é›†è§†å›¾çš„æ¡ä»¶ä¸‹é‡æ„åœºæ™¯ä¸­è¡¨ç°å¾—å°¤ä¸ºçªå‡ºã€‚æ­¤é¡¹æŠ€æœ¯ä»£è¡¨äº†è¯¥é¢†åŸŸæœ€å‰æ²¿çš„æŠ€æœ¯è¿›å±•ã€‚ </p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>3DGSä½œä¸ºå‰æ²¿çš„ä¸‰ç»´é‡å»ºæŠ€æœ¯ï¼Œèƒ½å¤Ÿåœ¨å®æ—¶æ¸²æŸ“æ€§èƒ½ä¸‹å®ç°é«˜è´¨é‡é‡å»ºã€‚</li>
<li>3DGSé€šè¿‡å°†åœºæ™¯è¡¨ç¤ºä¸ºä¸€ç³»åˆ—ä¸‰ç»´é«˜æ–¯é›†åˆï¼Œé€šè¿‡æ‹Ÿåˆåœºæ™¯è§†å›¾æ¥å­¦ä¹ å‚æ•°ã€‚</li>
<li>åœ¨å¤„ç†å¤šä¸ªè§†å›¾æ—¶è¡¨ç°ä¼˜è¶Šï¼Œä½†åœ¨ç¨€ç–è§†å›¾é‡å»ºä¸­é¢ä¸´æŒ‘æˆ˜ï¼Œå¦‚è¾“å…¥è§†å›¾ç¨€ç–ã€ä¸å®Œå…¨è¦†ç›–åœºæ™¯ä»¥åŠé‡å åº¦ä½ç­‰é—®é¢˜ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.07372">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-ab0cd268b6d65953cb3f1453bdcd8091.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-36646ba66e8ae3590ee7e3e516a86838.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-636ee74ca8af406e5b78e94f045ca03b.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-929efdcf437e9a1fb8e5f3160620c66e.jpg" align="middle">
</details>


<h1 id="-9"><a href="#-9" class="headerlink" title=""></a></h1><h2 id="GS4Buildings-Prior-Guided-Gaussian-Splatting-for-3D-Building-Reconstruction"><a href="#GS4Buildings-Prior-Guided-Gaussian-Splatting-for-3D-Building-Reconstruction" class="headerlink" title="GS4Buildings: Prior-Guided Gaussian Splatting for 3D Building   Reconstruction"></a>GS4Buildings: Prior-Guided Gaussian Splatting for 3D Building   Reconstruction</h2><p><strong>Authors:Qilin Zhang, Olaf Wysocki, Boris Jutzi</strong></p>
<p>Recent advances in Gaussian Splatting (GS) have demonstrated its effectiveness in photo-realistic rendering and 3D reconstruction. Among these, 2D Gaussian Splatting (2DGS) is particularly suitable for surface reconstruction due to its flattened Gaussian representation and integrated normal regularization. However, its performance often degrades in large-scale and complex urban scenes with frequent occlusions, leading to incomplete building reconstructions. We propose GS4Buildings, a novel prior-guided Gaussian Splatting method leveraging the ubiquity of semantic 3D building models for robust and scalable building surface reconstruction. Instead of relying on traditional Structure-from-Motion (SfM) pipelines, GS4Buildings initializes Gaussians directly from low-level Level of Detail (LoD)2 semantic 3D building models. Moreover, we generate prior depth and normal maps from the planar building geometry and incorporate them into the optimization process, providing strong geometric guidance for surface consistency and structural accuracy. We also introduce an optional building-focused mode that limits reconstruction to building regions, achieving a 71.8% reduction in Gaussian primitives and enabling a more efficient and compact representation. Experiments on urban datasets demonstrate that GS4Buildings improves reconstruction completeness by 20.5% and geometric accuracy by 32.8%. These results highlight the potential of semantic building model integration to advance GS-based reconstruction toward real-world urban applications such as smart cities and digital twins. Our project is available: <a target="_blank" rel="noopener" href="https://github.com/zqlin0521/GS4Buildings">https://github.com/zqlin0521/GS4Buildings</a>. </p>
<blockquote>
<p>è¿‘æœŸé«˜æ–¯æ··åˆæŠ€æœ¯ï¼ˆGSï¼‰çš„è¿›æ­¥åœ¨å…‰çœŸå®æ¸²æŸ“å’Œä¸‰ç»´é‡å»ºé¢†åŸŸæ˜¾ç¤ºå‡ºå…¶æœ‰æ•ˆæ€§ã€‚å…¶ä¸­ï¼ŒäºŒç»´é«˜æ–¯æ··åˆï¼ˆ2DGSï¼‰ç”±äºå…¶æ‰å¹³åŒ–é«˜æ–¯è¡¨ç¤ºå’Œé›†æˆæ­£è§„åŒ–ï¼Œç‰¹åˆ«é€‚åˆç”¨äºè¡¨é¢é‡å»ºã€‚ç„¶è€Œï¼Œå®ƒåœ¨å¤„ç†å¤§è§„æ¨¡ä¸”å¤æ‚çš„åŸå¸‚åœºæ™¯æ—¶ï¼Œç»å¸¸é‡åˆ°é®æŒ¡é—®é¢˜ï¼Œå¯¼è‡´å»ºç­‘é‡å»ºä¸å®Œæ•´ã€‚æˆ‘ä»¬æå‡ºä¸€ç§æ–°å‹çš„å…ˆéªŒå¼•å¯¼é«˜æ–¯æ··åˆæ–¹æ³•â€”â€”GS4Buildingsï¼Œè¯¥æ–¹æ³•åˆ©ç”¨è¯­ä¹‰ä¸‰ç»´å»ºç­‘æ¨¡å‹çš„æ™®éæ€§ï¼Œå®ç°ç¨³å¥ä¸”å¯æ‰©å±•çš„å»ºç­‘è¡¨é¢é‡å»ºã€‚ä¸ä¼ ç»Ÿçš„è¿åŠ¨æ¢å¤ç»“æ„ï¼ˆSfMï¼‰æµç¨‹ä¸åŒï¼ŒGS4Buildingsç›´æ¥ä»ä½çº§åˆ«ç»†èŠ‚ï¼ˆLoDï¼‰2è¯­ä¹‰ä¸‰ç»´å»ºç­‘æ¨¡å‹åˆå§‹åŒ–é«˜æ–¯åˆ†å¸ƒã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬ä»å¹³é¢å»ºç­‘å‡ ä½•ç”Ÿæˆå…ˆéªŒæ·±åº¦å›¾å’Œæ­£è§„å›¾ï¼Œå¹¶å°†å…¶çº³å…¥ä¼˜åŒ–æµç¨‹ï¼Œä¸ºè¡¨é¢ä¸€è‡´æ€§å’Œç»“æ„å‡†ç¡®æ€§æä¾›å¼ºå¤§çš„å‡ ä½•æŒ‡å¯¼ã€‚æˆ‘ä»¬è¿˜å¼•å…¥äº†ä¸€ç§å¯é€‰çš„å»ºç­‘ä¸“æ³¨æ¨¡å¼ï¼Œå°†é‡å»ºé™åˆ¶åœ¨å»ºç­‘åŒºåŸŸï¼Œå®ç°äº†é«˜æ–¯åŸå§‹æ•°æ®71.8%çš„å‡å°‘ï¼Œä½¿è¡¨ç¤ºæ›´åŠ é«˜æ•ˆå’Œç´§å‡‘ã€‚å¯¹åŸå¸‚æ•°æ®é›†çš„å®éªŒè¡¨æ˜ï¼ŒGS4Buildingsæé«˜äº†é‡å»ºå®Œæ•´æ€§20.5%å’Œå‡ ä½•ç²¾åº¦32.8%ã€‚è¿™äº›ç»“æœå‡¸æ˜¾äº†è¯­ä¹‰å»ºç­‘æ¨¡å‹æ•´åˆçš„æ½œåŠ›ï¼Œæ¨åŠ¨äº†åŸºäºGSçš„é‡å»ºæŠ€æœ¯å‘æ™ºæ…§åŸå¸‚å’Œæ•°å­—å­ªç”Ÿç­‰å®é™…åº”ç”¨çš„å‘å±•ã€‚æˆ‘ä»¬çš„é¡¹ç›®å¯åœ¨ä»¥ä¸‹ç½‘å€æ‰¾åˆ°ï¼š<a target="_blank" rel="noopener" href="https://github.com/zqlin0521/GS4Buildings%E3%80%82">https://github.com/zqlin0521/GS4Buildingsã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.07355v1">PDF</a> Accepted for presentation at ISPRS 3D GeoInfo &amp; Smart Data, Smart   Cities 2025, Kashiwa, Japan. To appear in the ISPRS Annals of the   Photogrammetry, Remote Sensing and Spatial Information Sciences</p>
<p><strong>Summary</strong></p>
<p>è¯¥æ–‡ä»‹ç»äº†é«˜æ–¯èåˆï¼ˆGSï¼‰åœ¨ä¸‰ç»´é‡å»ºä¸­çš„æœ€æ–°è¿›å±•ï¼Œç‰¹åˆ«æ˜¯äºŒç»´é«˜æ–¯èåˆï¼ˆ2DGSï¼‰åœ¨è¡¨é¢é‡å»ºä¸­çš„é€‚ç”¨æ€§ã€‚ç„¶è€Œï¼Œåœ¨å¤§è§„æ¨¡ã€å¤æ‚çš„åŸå¸‚åœºæ™¯ä¸­ï¼Œç”±äºé®æŒ¡é—®é¢˜ï¼Œå…¶æ€§èƒ½å¾€å¾€ä¸‹é™ï¼Œå¯¼è‡´å»ºç­‘é‡å»ºä¸å®Œæ•´ã€‚ä¸ºæ­¤ï¼Œæ–‡ç« æå‡ºäº†ä¸€ç§æ–°çš„åŸºäºè¯­ä¹‰ä¸‰ç»´å»ºç­‘æ¨¡å‹çš„å…ˆéªŒå¼•å¯¼é«˜æ–¯èåˆæ–¹æ³•GS4Buildingsã€‚è¯¥æ–¹æ³•ç›´æ¥ä»ä½çº§åˆ«ç»†èŠ‚ï¼ˆLoDï¼‰çš„è¯­ä¹‰ä¸‰ç»´å»ºç­‘æ¨¡å‹åˆå§‹åŒ–é«˜æ–¯ï¼Œå¹¶ç”Ÿæˆå…ˆéªŒæ·±åº¦å›¾å’Œæ³•çº¿å›¾ï¼Œèå…¥ä¼˜åŒ–è¿‡ç¨‹ï¼Œä¸ºè¡¨é¢ä¸€è‡´æ€§å’Œç»“æ„å‡†ç¡®æ€§æä¾›å¼ºæœ‰åŠ›çš„å‡ ä½•æŒ‡å¯¼ã€‚å®éªŒè¡¨æ˜ï¼ŒGS4Buildingsèƒ½æé«˜åŸå¸‚æ•°æ®é›†é‡å»ºçš„å®Œæ•´æ€§å’Œå‡ ä½•ç²¾åº¦ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>é«˜æ–¯èåˆï¼ˆGSï¼‰åœ¨ä¸‰ç»´é‡å»ºä¸­æœ‰æ˜¾è‘—è¿›å±•ï¼Œå°¤å…¶æ˜¯äºŒç»´é«˜æ–¯èåˆï¼ˆ2DGSï¼‰é€‚ç”¨äºè¡¨é¢é‡å»ºã€‚</li>
<li>åœ¨å¤§è§„æ¨¡ã€å¤æ‚çš„åŸå¸‚åœºæ™¯ä¸­ï¼Œä¼ ç»Ÿæ–¹æ³•å¦‚ç»“æ„ä»è¿åŠ¨ï¼ˆSfMï¼‰ç®¡çº¿åœ¨é«˜æ–¯èåˆä¸­é¢ä¸´æ€§èƒ½ä¸‹é™çš„é—®é¢˜ã€‚</li>
<li>GS4Buildingsæ˜¯ä¸€ç§æ–°çš„åŸºäºè¯­ä¹‰ä¸‰ç»´å»ºç­‘æ¨¡å‹çš„å…ˆéªŒå¼•å¯¼é«˜æ–¯èåˆæ–¹æ³•ï¼Œå¯æé«˜å»ºç­‘é‡å»ºçš„é²æ£’æ€§å’Œå¯æ‰©å±•æ€§ã€‚</li>
<li>GS4Buildingsç›´æ¥ä»ä½çº§åˆ«ç»†èŠ‚ï¼ˆLoDï¼‰çš„è¯­ä¹‰ä¸‰ç»´å»ºç­‘æ¨¡å‹åˆå§‹åŒ–é«˜æ–¯ï¼Œå¢å¼ºäº†é‡å»ºçš„å‡†ç¡®æ€§å’Œæ•ˆç‡ã€‚</li>
<li>é€šè¿‡ç”Ÿæˆå…ˆéªŒæ·±åº¦å›¾å’Œæ³•çº¿å›¾ï¼Œèå…¥ä¼˜åŒ–è¿‡ç¨‹ï¼ŒGS4Buildingsä¸ºè¡¨é¢ä¸€è‡´æ€§å’Œç»“æ„å‡†ç¡®æ€§æä¾›å¼ºæœ‰åŠ›çš„å‡ ä½•æŒ‡å¯¼ã€‚</li>
<li>å®éªŒè¡¨æ˜ï¼ŒGS4Buildingsèƒ½æé«˜åŸå¸‚æ•°æ®é›†é‡å»ºçš„å®Œæ•´æ€§å’Œå‡ ä½•ç²¾åº¦ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.07355">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-780c0cb030cb64187d7a54e4847c1202.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-a0828462a7998f8299d8e21666d44642.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-496240ab8f60f7fb35c8ef23cc02dc9a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f401b34d8b44a33d3e631bf826752291.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-71b7ccdd2b36e56753c4e6ccbbf109c7.jpg" align="middle">
</details>


<h1 id="-10"><a href="#-10" class="headerlink" title=""></a></h1><h2 id="3D-Gaussian-Representations-with-Motion-Trajectory-Field-for-Dynamic-Scene-Reconstruction"><a href="#3D-Gaussian-Representations-with-Motion-Trajectory-Field-for-Dynamic-Scene-Reconstruction" class="headerlink" title="3D Gaussian Representations with Motion Trajectory Field for Dynamic   Scene Reconstruction"></a>3D Gaussian Representations with Motion Trajectory Field for Dynamic   Scene Reconstruction</h2><p><strong>Authors:Xuesong Li, Lars Petersson, Vivien Rolland</strong></p>
<p>This paper addresses the challenge of novel-view synthesis and motion reconstruction of dynamic scenes from monocular video, which is critical for many robotic applications. Although Neural Radiance Fields (NeRF) and 3D Gaussian Splatting (3DGS) have demonstrated remarkable success in rendering static scenes, extending them to reconstruct dynamic scenes remains challenging. In this work, we introduce a novel approach that combines 3DGS with a motion trajectory field, enabling precise handling of complex object motions and achieving physically plausible motion trajectories. By decoupling dynamic objects from static background, our method compactly optimizes the motion trajectory field. The approach incorporates time-invariant motion coefficients and shared motion trajectory bases to capture intricate motion patterns while minimizing optimization complexity. Extensive experiments demonstrate that our approach achieves state-of-the-art results in both novel-view synthesis and motion trajectory recovery from monocular video, advancing the capabilities of dynamic scene reconstruction. </p>
<blockquote>
<p>æœ¬æ–‡æ—¨åœ¨è§£å†³ä»å•ç›®è§†é¢‘ä¸­åˆæˆæ–°è§†è§’å’Œé‡å»ºåŠ¨æ€åœºæ™¯çš„æŒ‘æˆ˜ï¼Œè¿™å¯¹äºè®¸å¤šæœºå™¨äººåº”ç”¨è‡³å…³é‡è¦ã€‚å°½ç®¡ç¥ç»è¾å°„åœºï¼ˆNeRFï¼‰å’Œä¸‰ç»´é«˜æ–¯æ‹¼æ¥ï¼ˆ3DGSï¼‰åœ¨æ¸²æŸ“é™æ€åœºæ™¯æ–¹é¢å–å¾—äº†æ˜¾è‘—çš„æˆåŠŸï¼Œä½†å®ƒä»¬æ‰©å±•åˆ°é‡å»ºåŠ¨æ€åœºæ™¯ä»ç„¶å…·æœ‰æŒ‘æˆ˜æ€§ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°é¢–çš„æ–¹æ³•ï¼Œç»“åˆäº†ä¸‰ç»´é«˜æ–¯æ‹¼æ¥å’ŒåŠ¨æ€è½¨è¿¹åœºï¼Œèƒ½å¤Ÿç²¾ç¡®å¤„ç†å¤æ‚ç‰©ä½“çš„è¿åŠ¨ï¼Œå®ç°ç‰©ç†åˆç†çš„è¿åŠ¨è½¨è¿¹ã€‚é€šè¿‡å°†åŠ¨æ€ç‰©ä½“ä¸é™æ€èƒŒæ™¯è§£è€¦ï¼Œæˆ‘ä»¬çš„æ–¹æ³•ç´§å‡‘åœ°ä¼˜åŒ–äº†è¿åŠ¨è½¨è¿¹åœºã€‚è¯¥æ–¹æ³•ç»“åˆäº†æ—¶é—´ä¸å˜çš„åŠ¨æ€ç³»æ•°å’Œå…±äº«çš„è¿åŠ¨è½¨è¿¹åŸºï¼Œèƒ½å¤Ÿæ•æ‰å¤æ‚çš„è¿åŠ¨æ¨¡å¼ï¼ŒåŒæ—¶æœ€å°åŒ–ä¼˜åŒ–å¤æ‚åº¦ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨å•ç›®è§†é¢‘çš„æ–°è§†è§’åˆæˆå’Œè¿åŠ¨è½¨è¿¹æ¢å¤æ–¹é¢å–å¾—äº†æœ€å…ˆè¿›çš„æˆæœï¼Œæé«˜äº†åŠ¨æ€åœºæ™¯é‡å»ºçš„èƒ½åŠ›ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.07182v1">PDF</a> </p>
<p><strong>Summary</strong><br>     æœ¬æ–‡æå‡ºä¸€ç§ç»“åˆ3DGSå’Œè¿åŠ¨è½¨è¿¹åœºçš„æ–°æ–¹æ³•ï¼Œç”¨äºä»å•ç›®è§†é¢‘ä¸­é‡å»ºåŠ¨æ€åœºæ™¯ã€‚è¯¥æ–¹æ³•èƒ½å¤Ÿç²¾ç¡®å¤„ç†å¤æ‚ç‰©ä½“è¿åŠ¨ï¼Œå®ç°ç‰©ç†ä¸Šå¯è¡Œçš„è¿åŠ¨è½¨è¿¹ã€‚é€šè¿‡è§£è€¦åŠ¨æ€ç‰©ä½“å’Œé™æ€èƒŒæ™¯ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿç´§å‡‘åœ°ä¼˜åŒ–è¿åŠ¨è½¨è¿¹åœºï¼Œé‡‡ç”¨æ—¶é—´ä¸å˜è¿åŠ¨ç³»æ•°å’Œå…±äº«è¿åŠ¨è½¨è¿¹åŸºï¼Œä»¥æ•æ‰å¤æ‚çš„è¿åŠ¨æ¨¡å¼ï¼ŒåŒæ—¶é™ä½ä¼˜åŒ–å¤æ‚åº¦ã€‚å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å•ç›®è§†é¢‘çš„æ–°è§†è§’åˆæˆå’Œè¿åŠ¨è½¨è¿¹æ¢å¤æ–¹é¢å‡è¾¾åˆ°é¢†å…ˆæ°´å¹³ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æœ¬æ–‡è§£å†³äº†ä»å•ç›®è§†é¢‘ä¸­é‡å»ºåŠ¨æ€åœºæ™¯çš„æŒ‘æˆ˜ï¼Œè¿™å¯¹äºè®¸å¤šæœºå™¨äººåº”ç”¨è‡³å…³é‡è¦ã€‚</li>
<li>å¼•å…¥äº†ä¸€ç§ç»“åˆ3DGSå’Œè¿åŠ¨è½¨è¿¹åœºçš„æ–°æ–¹æ³•ï¼Œä»¥å¤„ç†å¤æ‚çš„ç‰©ä½“è¿åŠ¨å¹¶å®ç°ç‰©ç†ä¸Šå¯è¡Œçš„è¿åŠ¨è½¨è¿¹ã€‚</li>
<li>é€šè¿‡è§£è€¦åŠ¨æ€ç‰©ä½“å’Œé™æ€èƒŒæ™¯ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿç´§å‡‘åœ°ä¼˜åŒ–è¿åŠ¨è½¨è¿¹åœºã€‚</li>
<li>é‡‡ç”¨æ—¶é—´ä¸å˜è¿åŠ¨ç³»æ•°å’Œå…±äº«è¿åŠ¨è½¨è¿¹åŸºæ¥é™ä½ä¼˜åŒ–å¤æ‚åº¦ï¼ŒåŒæ—¶æ•æ‰å¤æ‚çš„è¿åŠ¨æ¨¡å¼ã€‚</li>
<li>è¯¥æ–¹æ³•èƒ½å¤Ÿå®ç°æ–°è§†è§’åˆæˆå’Œä»å•ç›®è§†é¢‘ä¸­çš„è¿åŠ¨è½¨è¿¹æ¢å¤ã€‚</li>
<li>å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨åŠ¨æ€åœºæ™¯é‡å»ºæ–¹é¢è¾¾åˆ°é¢†å…ˆæ°´å¹³ã€‚</li>
<li>è¯¥æ–¹æ³•å¯¹æœªæ¥æœºå™¨äººåº”ç”¨ï¼Œå¦‚è‡ªåŠ¨é©¾é©¶ã€æ™ºèƒ½ç›‘æ§ç­‰ï¼Œå…·æœ‰æ½œåœ¨çš„åº”ç”¨ä»·å€¼ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.07182">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-c371c68060f2288a20caddac90a2a593.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-87c69000d678c89ec43209927b0d43cd.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-345a209b928011588fac7dc9c6942ddd.jpg" align="middle">
</details>


<h1 id="-11"><a href="#-11" class="headerlink" title=""></a></h1><h2 id="DexFruit-Dexterous-Manipulation-and-Gaussian-Splatting-Inspection-of-Fruit"><a href="#DexFruit-Dexterous-Manipulation-and-Gaussian-Splatting-Inspection-of-Fruit" class="headerlink" title="DexFruit: Dexterous Manipulation and Gaussian Splatting Inspection of   Fruit"></a>DexFruit: Dexterous Manipulation and Gaussian Splatting Inspection of   Fruit</h2><p><strong>Authors:Aiden Swann, Alex Qiu, Matthew Strong, Angelina Zhang, Samuel Morstein, Kai Rayle, Monroe Kennedy III</strong></p>
<p>DexFruit is a robotic manipulation framework that enables gentle, autonomous handling of fragile fruit and precise evaluation of damage. Many fruits are fragile and prone to bruising, thus requiring humans to manually harvest them with care. In this work, we demonstrate by using optical tactile sensing, autonomous manipulation of fruit with minimal damage can be achieved. We show that our tactile informed diffusion policies outperform baselines in both reduced bruising and pick-and-place success rate across three fruits: strawberries, tomatoes, and blackberries. In addition, we introduce FruitSplat, a novel technique to represent and quantify visual damage in high-resolution 3D representation via 3D Gaussian Splatting (3DGS). Existing metrics for measuring damage lack quantitative rigor or require expensive equipment. With FruitSplat, we distill a 2D strawberry mask as well as a 2D bruise segmentation mask into the 3DGS representation. Furthermore, this representation is modular and general, compatible with any relevant 2D model. Overall, we demonstrate a 92% grasping policy success rate, up to a 20% reduction in visual bruising, and up to an 31% improvement in grasp success rate on challenging fruit compared to our baselines across our three tested fruits. We rigorously evaluate this result with over 630 trials. Please checkout our website at <a target="_blank" rel="noopener" href="https://dex-fruit.github.io/">https://dex-fruit.github.io</a> . </p>
<blockquote>
<p>DexFruitæ˜¯ä¸€ä¸ªæœºå™¨äººæ“ä½œæ¡†æ¶ï¼Œèƒ½å¤Ÿå®ç°è„†å¼±æ°´æœçš„è½»æŸ”è‡ªä¸»å¤„ç†å’ŒæŸä¼¤çš„ç²¾ç¡®è¯„ä¼°ã€‚è®¸å¤šæ°´æœæ˜¯è„†å¼±çš„ï¼Œå®¹æ˜“å—æŸï¼Œå› æ­¤éœ€è¦äººä»¬å°å¿ƒåœ°æ‰‹å·¥é‡‡æ‘˜å®ƒä»¬ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬é€šè¿‡ä½¿ç”¨å…‰å­¦è§¦è§‰æ„Ÿåº”æŠ€æœ¯ï¼Œå±•ç¤ºäº†å¯ä»¥å¯¹æ°´æœè¿›è¡Œè‡ªä¸»æ“ä½œï¼Œå®ç°æœ€å°çš„æŸä¼¤ã€‚æˆ‘ä»¬è¯æ˜ï¼Œæˆ‘ä»¬çš„è§¦è§‰æ„ŸçŸ¥æ‰©æ•£ç­–ç•¥åœ¨å‡å°‘æŸä¼¤å’Œé‡‡æ‘˜æ”¾ç½®æˆåŠŸç‡æ–¹é¢è¶…è¿‡äº†åŸºçº¿æ ‡å‡†ã€‚è¿™é¡¹æŠ€æœ¯åœ¨è‰è“ã€ç•ªèŒ„å’Œé»‘è“è¿™ä¸‰ç§æ°´æœä¸Šå¾—åˆ°äº†éªŒè¯ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜æ¨å‡ºäº†ä¸€ç§æ–°å‹æŠ€æœ¯FruitSplatï¼Œå®ƒå¯ä»¥é€šè¿‡3Dé«˜æ–¯å–·æ¶‚æŠ€æœ¯ï¼ˆ3DGSï¼‰ä»¥é«˜åˆ†è¾¨ç‡çš„3Då½¢å¼è¡¨ç¤ºå’Œé‡åŒ–è§†è§‰æŸä¼¤ã€‚ç°æœ‰çš„æŸä¼¤æµ‹é‡æŒ‡æ ‡ç¼ºä¹å®šé‡ä¸¥è°¨æ€§æˆ–éœ€è¦æ˜‚è´µçš„è®¾å¤‡ã€‚å€ŸåŠ©FruitSplatï¼Œæˆ‘ä»¬å°†ä¸€ä¸ªäºŒç»´è‰è“æ©è†œå’Œä¸€ä¸ªäºŒç»´æ·¤è¡€åˆ†å‰²æ©è†œè’¸é¦åˆ°3DGSè¡¨ç¤ºä¸­ã€‚æ­¤å¤–ï¼Œè¿™ç§è¡¨ç¤ºæ˜¯æ¨¡å—åŒ–å’Œé€šç”¨çš„ï¼Œå¯ä»¥ä¸ä»»ä½•ç›¸å…³çš„äºŒç»´æ¨¡å‹å…¼å®¹ã€‚æ€»çš„æ¥è¯´ï¼Œæˆ‘ä»¬å®ç°äº†92%çš„æŠ“å–ç­–ç•¥æˆåŠŸç‡ï¼Œè§†è§‰æ·¤è¡€å‡å°‘äº†é«˜è¾¾20%ï¼Œåœ¨å…·æœ‰æŒ‘æˆ˜æ€§çš„æ°´æœä¸Šä¸åŸºçº¿ç›¸æ¯”ï¼ŒæŠ“å–æˆåŠŸç‡æé«˜äº†é«˜è¾¾31%ã€‚æˆ‘ä»¬å¯¹è¿™ä¸€ç»“æœè¿›è¡Œäº†è¶…è¿‡630æ¬¡çš„ä¸¥æ ¼è¯•éªŒè¯„ä»·ã€‚è¯·è®¿é—®æˆ‘ä»¬çš„ç½‘ç«™<a target="_blank" rel="noopener" href="https://dex-fruit.github.ioäº†è§£æ›´å¤šä¿¡æ¯./">https://dex-fruit.github.ioäº†è§£æ›´å¤šä¿¡æ¯ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.07118v1">PDF</a> 8 pages, 5 figures</p>
<p><strong>Summary</strong></p>
<p>DexFruitæ¡†æ¶å®ç°äº†å¯¹è„†å¼±æ°´æœçš„è½»æŸ”è‡ªä¸»æ“æ§ä¸æŸä¼¤ç²¾ç¡®è¯„ä¼°ã€‚é€šè¿‡å…‰å­¦è§¦è§‰æ„ŸçŸ¥æŠ€æœ¯ï¼Œå®ç°äº†å¯¹è‰è“ã€ç•ªèŒ„å’Œè¦†ç›†å­ç­‰ä¸‰ç§æ°´æœçš„è‡ªä¸»æ“æ§ï¼Œå‡å°‘äº†æŸä¼¤å¹¶æé«˜äº†æ‹¾å–æ”¾ç½®çš„æˆåŠŸç‡ã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜å¼•å…¥äº†FruitSplatæŠ€æœ¯ï¼Œé€šè¿‡3Dé«˜æ–¯è´´å›¾ï¼ˆ3DGSï¼‰ä»¥é«˜åˆ†è¾¨ç‡3Då½¢å¼å‘ˆç°å’Œé‡åŒ–è§†è§‰æŸä¼¤ã€‚æ­¤æŠ€æœ¯å¯æ¨¡å—åŒ–å¹¶é€šç”¨åŒ–ï¼Œé€‚ç”¨äºä»»ä½•ç›¸å…³2Dæ¨¡å‹ã€‚æ•´ä½“è€Œè¨€ï¼Œç ”ç©¶å®ç°äº†92%çš„æŠ“å–ç­–ç•¥æˆåŠŸç‡ï¼Œè§†è§‰æŸä¼¤å‡å°‘è¾¾20%ï¼Œä¸åŸºçº¿ç›¸æ¯”åœ¨æŒ‘æˆ˜æ€§æ°´æœä¸ŠæŠ“å–æˆåŠŸç‡æé«˜è¾¾31%ï¼Œç»è¿‡è¶…è¿‡630æ¬¡è¯•éªŒçš„ä¸¥æ ¼è¯„ä¼°ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>DexFruitæ˜¯ä¸€ä¸ªç”¨äºæ“æ§è„†å¼±æ°´æœçš„æ¡†æ¶ï¼Œèƒ½å®ç°è‡ªä¸»æ“æ§å’ŒæŸä¼¤è¯„ä¼°ã€‚</li>
<li>é€šè¿‡å…‰å­¦è§¦è§‰æ„ŸçŸ¥æŠ€æœ¯ï¼Œå®ç°äº†å¯¹å¤šç§æ°´æœçš„è‡ªä¸»æ“æ§ï¼Œå‡å°‘äº†æŸä¼¤å¹¶æé«˜æ‹¾å–æ”¾ç½®æˆåŠŸç‡ã€‚</li>
<li>å¼•å…¥FruitSplatæŠ€æœ¯ï¼Œä½¿ç”¨3Dé«˜æ–¯è´´å›¾ï¼ˆ3DGSï¼‰è¿›è¡Œè§†è§‰æŸä¼¤çš„ç²¾å‡†å‘ˆç°å’Œé‡åŒ–ã€‚</li>
<li>æ­¤æŠ€æœ¯é€‚ç”¨äºä»»ä½•ç›¸å…³2Dæ¨¡å‹å¹¶å…·æœ‰æ¨¡å—åŒ–ç‰¹ç‚¹ã€‚</li>
<li>ç ”ç©¶è¾¾åˆ°äº†è¾ƒé«˜çš„æŠ“å–ç­–ç•¥æˆåŠŸç‡ï¼Œå¹¶æ˜¾è‘—å‡å°‘äº†è§†è§‰æŸä¼¤ã€‚</li>
<li>ä¸åŸºçº¿ç›¸æ¯”ï¼Œåœ¨æŒ‘æˆ˜æ€§æ°´æœä¸Šçš„æŠ“å–æˆåŠŸç‡æ˜¾è‘—æé«˜ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.07118">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-42f0814216eff6f495ef6e88329c0c94.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-6cb5244ac7b8af32d639069dbfb64ce9.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-4e06ef9c1c3dec8debd61351fe5e36e4.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e287baf48855de1454b62866dfad8917.jpg" align="middle">
</details>


<h1 id="-12"><a href="#-12" class="headerlink" title=""></a></h1><h2 id="3DGS-VBench-A-Comprehensive-Video-Quality-Evaluation-Benchmark-for-3DGS-Compression"><a href="#3DGS-VBench-A-Comprehensive-Video-Quality-Evaluation-Benchmark-for-3DGS-Compression" class="headerlink" title="3DGS-VBench: A Comprehensive Video Quality Evaluation Benchmark for 3DGS   Compression"></a>3DGS-VBench: A Comprehensive Video Quality Evaluation Benchmark for 3DGS   Compression</h2><p><strong>Authors:Yuke Xing, William Gordon, Qi Yang, Kaifa Yang, Jiarui Wang, Yiling Xu</strong></p>
<p>3D Gaussian Splatting (3DGS) enables real-time novel view synthesis with high visual fidelity, but its substantial storage requirements hinder practical deployment, prompting state-of-the-art (SOTA) 3DGS methods to incorporate compression modules. However, these 3DGS generative compression techniques introduce unique distortions lacking systematic quality assessment research. To this end, we establish 3DGS-VBench, a large-scale Video Quality Assessment (VQA) Dataset and Benchmark with 660 compressed 3DGS models and video sequences generated from 11 scenes across 6 SOTA 3DGS compression algorithms with systematically designed parameter levels. With annotations from 50 participants, we obtained MOS scores with outlier removal and validated dataset reliability. We benchmark 6 3DGS compression algorithms on storage efficiency and visual quality, and evaluate 15 quality assessment metrics across multiple paradigms. Our work enables specialized VQA model training for 3DGS, serving as a catalyst for compression and quality assessment research. The dataset is available at <a target="_blank" rel="noopener" href="https://github.com/YukeXing/3DGS-VBench">https://github.com/YukeXing/3DGS-VBench</a>. </p>
<blockquote>
<p>3Dé«˜æ–¯æ··æˆï¼ˆ3DGSï¼‰èƒ½å¤Ÿä»¥é«˜è§†è§‰ä¿çœŸåº¦å®ç°å®æ—¶æ–°å‹è§†å›¾åˆæˆï¼Œä½†å…¶å·¨å¤§çš„å­˜å‚¨éœ€æ±‚é˜»ç¢äº†å®é™…åº”ç”¨éƒ¨ç½²ï¼Œä¿ƒä½¿æœ€å…ˆè¿›çš„ï¼ˆSOTAï¼‰3DGSæ–¹æ³•èå…¥å‹ç¼©æ¨¡å—ã€‚ç„¶è€Œï¼Œè¿™äº›3DGSç”Ÿæˆå‹ç¼©æŠ€æœ¯å¼•å…¥äº†ç‹¬ç‰¹çš„å¤±çœŸï¼Œç¼ºä¹ç³»ç»Ÿçš„è´¨é‡è¯„ä¼°ç ”ç©¶ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬å»ºç«‹äº†å¤§è§„æ¨¡çš„Video Quality Assessmentï¼ˆè§†é¢‘è´¨é‡è¯„ä¼°ï¼Œç®€ç§°VQAï¼‰æ•°æ®é›†å’ŒåŸºå‡†æµ‹è¯•å¹³å°â€”â€”3DGS-VBenchï¼ŒåŒ…å«660ä¸ªå‹ç¼©çš„3DGSæ¨¡å‹å’Œç”±6ç§æœ€å…ˆè¿›3DGSå‹ç¼©ç®—æ³•ç”Ÿæˆçš„è§†é¢‘åºåˆ—ï¼Œè¿™äº›è§†é¢‘åºåˆ—æ¶µç›–äº†11ä¸ªåœºæ™¯å¹¶å¸¦æœ‰ç³»ç»Ÿè®¾è®¡çš„å‚æ•°çº§åˆ«ã€‚é€šè¿‡50åå‚ä¸è€…çš„æ ‡æ³¨ï¼Œæˆ‘ä»¬è·å¾—äº†å»é™¤å¼‚å¸¸å€¼åçš„å¹³å‡æ„è§åˆ†æ•°ï¼ˆMOSï¼‰ï¼Œå¹¶éªŒè¯äº†æ•°æ®é›†å¯é æ€§ã€‚æˆ‘ä»¬åœ¨å­˜å‚¨æ•ˆç‡å’Œè§†è§‰è´¨é‡æ–¹é¢å¯¹6ç§3DGSå‹ç¼©ç®—æ³•è¿›è¡Œäº†åŸºå‡†æµ‹è¯•ï¼Œå¹¶è¯„ä¼°äº†è·¨å¤šç§èŒƒå¼çš„15ç§è´¨é‡è¯„ä¼°æŒ‡æ ‡ã€‚æˆ‘ä»¬çš„å·¥ä½œèƒ½å¤Ÿå®ç°é’ˆå¯¹3DGSçš„ä¸“é—¨åŒ–VQAæ¨¡å‹è®­ç»ƒï¼Œæˆä¸ºå‹ç¼©å’Œè´¨é‡è¯„ä¼°ç ”ç©¶çš„å‚¬åŒ–å‰‚ã€‚æ•°æ®é›†å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/YukeXing/3DGS-VBench">https://github.com/YukeXing/3DGS-VBench</a>è·å–ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.07038v1">PDF</a> </p>
<p><strong>æ‘˜è¦</strong><br>æœ¬æ–‡ä»‹ç»äº†ä¸€ç§ç”¨äºè¯„ä¼°ä¸‰ç»´é«˜æ–¯èåˆï¼ˆ3DGSï¼‰å‹ç¼©æŠ€æœ¯è§†é¢‘è´¨é‡çš„å¤§å‹æ•°æ®é›†å’ŒåŸºå‡†æµ‹è¯•ã€‚è¯¥æ•°æ®é›†åŒ…å«æ¥è‡ªä¸åŒåœºæ™¯çš„å‹ç¼©è§†é¢‘åºåˆ—å’Œæ¨¡å‹ï¼Œæ¶µç›–äº†å¤šç§å…ˆè¿›çš„å‹ç¼©ç®—æ³•ã€‚é€šè¿‡å‚ä¸è€…è¯„ä¼°å’Œæ ‡æ³¨ï¼Œå»ºç«‹äº†æ•°æ®é›†å¯é æ€§ã€‚è¯¥ç ”ç©¶æœ‰åŠ©äºè®­ç»ƒä¸“é—¨é’ˆå¯¹ä¸‰ç»´é«˜æ–¯èåˆçš„ç‰¹æ®Šè§†é¢‘è´¨é‡è¯„ä¼°æ¨¡å‹ï¼Œæ¨åŠ¨å‹ç¼©æŠ€æœ¯ä¸è´¨é‡è¯„ä¼°é¢†åŸŸçš„ç ”ç©¶è¿›å±•ã€‚æ•°æ®é›†å¯ä»é“¾æ¥è·å–ï¼š<a target="_blank" rel="noopener" href="https://github.com/YukeXing/3DGS-VBench">https://github.com/YukeXing/3DGS-VBench</a>ã€‚</p>
<p><strong>å…³é”®è§è§£</strong></p>
<ul>
<li>3DGSå¯å®ç°å…·æœ‰é«˜è´¨é‡è§†è§‰æ•ˆæœçš„å®æ—¶æ–°è§†è§’åˆæˆï¼Œä½†å…¶å¤§é‡å­˜å‚¨éœ€æ±‚é™åˆ¶äº†å®é™…åº”ç”¨ã€‚å› æ­¤ï¼Œæœ€æ–°çš„æ–¹æ³•èå…¥äº†å‹ç¼©æ¨¡å—ã€‚</li>
<li>ç°æœ‰ç ”ç©¶ç¼ºå°‘å…³äºå¦‚ä½•ç³»ç»Ÿæ€§åœ°è¯„ä¼°è¿™ç§æ–°çš„3DGSå‹ç¼©æŠ€æœ¯æ‰€ç‰¹æœ‰çš„æ‰­æ›²çš„æŠ€æœ¯åˆ†æã€‚è¿™å¸¦æ¥äº†éœ€æ±‚è¿›è¡Œä¸“é—¨çš„è´¨é‡è¯„ä¼°ç ”ç©¶ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.07038">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-2d0f9bdb25d358b0c724cf7a68c819e9.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-cac2a03c3f4201fbc23c76265f03a86f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c6ff60cc1f6a8e330a1409425aa13052.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-187e7c7cf83ef990444c02186289bec3.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-8b77666192de7abe2fa11fa6caf508b0.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-6b3e26540a86c0bbab5eaccd3bdb8ba0.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-701b1a3b1eb7416e45738de25548f410.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-83cbe0da3f8f675525bb2eca18397eed.jpg" align="middle">
</details>


<h1 id="-13"><a href="#-13" class="headerlink" title=""></a></h1><h2 id="EGS-SLAM-RGB-D-Gaussian-Splatting-SLAM-with-Events"><a href="#EGS-SLAM-RGB-D-Gaussian-Splatting-SLAM-with-Events" class="headerlink" title="EGS-SLAM: RGB-D Gaussian Splatting SLAM with Events"></a>EGS-SLAM: RGB-D Gaussian Splatting SLAM with Events</h2><p><strong>Authors:Siyu Chen, Shenghai Yuan, Thien-Minh Nguyen, Zhuyu Huang, Chenyang Shi, Jin Jing, Lihua Xie</strong></p>
<p>Gaussian Splatting SLAM (GS-SLAM) offers a notable improvement over traditional SLAM methods, enabling photorealistic 3D reconstruction that conventional approaches often struggle to achieve. However, existing GS-SLAM systems perform poorly under persistent and severe motion blur commonly encountered in real-world scenarios, leading to significantly degraded tracking accuracy and compromised 3D reconstruction quality. To address this limitation, we propose EGS-SLAM, a novel GS-SLAM framework that fuses event data with RGB-D inputs to simultaneously reduce motion blur in images and compensate for the sparse and discrete nature of event streams, enabling robust tracking and high-fidelity 3D Gaussian Splatting reconstruction. Specifically, our system explicitly models the cameraâ€™s continuous trajectory during exposure, supporting event- and blur-aware tracking and mapping on a unified 3D Gaussian Splatting scene. Furthermore, we introduce a learnable camera response function to align the dynamic ranges of events and images, along with a no-event loss to suppress ringing artifacts during reconstruction. We validate our approach on a new dataset comprising synthetic and real-world sequences with significant motion blur. Extensive experimental results demonstrate that EGS-SLAM consistently outperforms existing GS-SLAM systems in both trajectory accuracy and photorealistic 3D Gaussian Splatting reconstruction. The source code will be available at <a target="_blank" rel="noopener" href="https://github.com/Chensiyu00/EGS-SLAM">https://github.com/Chensiyu00/EGS-SLAM</a>. </p>
<blockquote>
<p>é«˜æ–¯èåˆSLAMï¼ˆGS-SLAMï¼‰ç›¸è¾ƒäºä¼ ç»ŸSLAMæ–¹æ³•åœ¨å…‰å¹»çœŸ3Dé‡å»ºæ–¹é¢æä¾›äº†æ˜¾è‘—çš„æ”¹è¿›ï¼Œè€Œä¼ ç»Ÿæ–¹æ³•å¾€å¾€éš¾ä»¥å®ç°è¿™ä¸€ç‚¹ã€‚ç„¶è€Œï¼Œç°æœ‰GS-SLAMç³»ç»Ÿåœ¨ç°å®åœºæ™¯ä¸­å¸¸è§çš„æŒä¹…æ€§ä¸¥é‡è¿åŠ¨æ¨¡ç³Šæƒ…å†µä¸‹è¡¨ç°ä¸ä½³ï¼Œå¯¼è‡´è·Ÿè¸ªç²¾åº¦æ˜¾è‘—é™ä½å’Œ3Dé‡å»ºè´¨é‡å—æŸã€‚ä¸ºäº†è§£å†³è¿™ä¸€å±€é™æ€§ï¼Œæˆ‘ä»¬æå‡ºäº†EGS-SLAMï¼Œè¿™æ˜¯ä¸€ç§æ–°çš„GS-SLAMæ¡†æ¶ï¼Œå®ƒå°†äº‹ä»¶æ•°æ®ä¸RGB-Dè¾“å…¥èåˆï¼Œå¯åŒæ—¶å‡å°‘å›¾åƒä¸­çš„è¿åŠ¨æ¨¡ç³Šå¹¶è¡¥å¿äº‹ä»¶æµçš„ç¨€ç–ç¦»æ•£æ€§è´¨ï¼Œä»è€Œå®ç°ç¨³å¥çš„è·Ÿè¸ªå’Œé«˜ä¿çœŸåº¦çš„3Dé«˜æ–¯èåˆé‡å»ºã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬çš„ç³»ç»Ÿæ˜¾å¼å»ºæ¨¡ç›¸æœºæ›å…‰è¿‡ç¨‹ä¸­çš„è¿ç»­è½¨è¿¹ï¼Œæ”¯æŒäº‹ä»¶å’Œæ¨¡ç³Šæ„ŸçŸ¥çš„è·Ÿè¸ªå’Œæ˜ å°„åœ¨ç»Ÿä¸€çš„3Dé«˜æ–¯èåˆåœºæ™¯ä¸Šã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ä¸ªå¯å­¦ä¹ çš„ç›¸æœºå“åº”å‡½æ•°æ¥å¯¹é½äº‹ä»¶å’Œå›¾åƒçš„åŠ¨æ€èŒƒå›´ï¼Œä»¥åŠæ— äº‹ä»¶æŸå¤±æ¥æŠ‘åˆ¶é‡å»ºè¿‡ç¨‹ä¸­çš„æŒ¯é“ƒä¼ªå½±ã€‚æˆ‘ä»¬åœ¨åŒ…å«åˆæˆå’ŒçœŸå®åºåˆ—çš„æ–°æ•°æ®é›†ä¸ŠéªŒè¯äº†æˆ‘ä»¬çš„æ–¹æ³•ï¼Œè¯¥æ•°æ®é›†å…·æœ‰æ˜¾è‘—çš„è¿åŠ¨æ¨¡ç³Šã€‚å¤§é‡å®éªŒç»“æœè¡¨æ˜ï¼ŒEGS-SLAMåœ¨è½¨è¿¹å‡†ç¡®æ€§å’Œå…‰å¹»çœŸ3Dé«˜æ–¯èåˆé‡å»ºæ–¹é¢å‡ä¼˜äºç°æœ‰GS-SLAMç³»ç»Ÿã€‚æºä»£ç å°†åœ¨<a target="_blank" rel="noopener" href="https://github.com/Chensiyu00/EGS-SLAM%E4%B8%8A%E6%8F%90%E4%BE%9B%E3%80%82">https://github.com/Chensiyu00/EGS-SLAMä¸Šæä¾›ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.07003v1">PDF</a> Accepted by IEEE RAL</p>
<p><strong>Summary</strong></p>
<p>GS-SLAMæ–¹æ³•åœ¨çœŸå®ä¸–ç•Œåœºæ™¯ä¸­å­˜åœ¨è¿åŠ¨æ¨¡ç³Šé—®é¢˜ï¼Œå¯¼è‡´è·Ÿè¸ªç²¾åº¦ä¸‹é™å’Œ3Dé‡å»ºè´¨é‡å—æŸã€‚é’ˆå¯¹æ­¤é—®é¢˜ï¼Œæå‡ºEGS-SLAMæ¡†æ¶ï¼Œèåˆäº‹ä»¶æ•°æ®å’ŒRGB-Dè¾“å…¥ï¼Œå‡å°‘å›¾åƒè¿åŠ¨æ¨¡ç³Šï¼Œå¹¶è¡¥å¿äº‹ä»¶æµçš„ç¨€ç–å’Œç¦»æ•£æ€§ï¼Œå®ç°ç¨³å¥è·Ÿè¸ªå’Œé«˜ä¿çœŸ3Dé«˜æ–¯å–·æº…é‡å»ºã€‚è¯¥æ¡†æ¶æ˜¾å¼å»ºæ¨¡ç›¸æœºæ›å…‰æœŸé—´çš„è¿ç»­è½¨è¿¹ï¼Œæ”¯æŒäº‹ä»¶å’Œæ¨¡ç³Šæ„ŸçŸ¥çš„è·Ÿè¸ªå’Œæ˜ å°„ï¼Œå¹¶å¼•å…¥å¯å­¦ä¹ çš„ç›¸æœºå“åº”å‡½æ•°å’Œå¯¹é½äº‹ä»¶å’Œå›¾åƒåŠ¨æ€èŒƒå›´çš„æ–¹æ³•ï¼Œä»¥åŠæ— äº‹ä»¶æŸå¤±æ¥æŠ‘åˆ¶é‡å»ºè¿‡ç¨‹ä¸­çš„æŒ¯é“ƒä¼ªå½±ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>GS-SLAMåœ¨çœŸå®åœºæ™¯ä¸­å­˜åœ¨è¿åŠ¨æ¨¡ç³Šé—®é¢˜ã€‚</li>
<li>EGS-SLAMæ¡†æ¶èåˆäº‹ä»¶æ•°æ®å’ŒRGB-Dè¾“å…¥ï¼Œå‡å°‘å›¾åƒè¿åŠ¨æ¨¡ç³Šã€‚</li>
<li>EGS-SLAMè¡¥å¿äº‹ä»¶æµçš„ç¨€ç–å’Œç¦»æ•£æ€§ï¼Œå®ç°ç¨³å¥è·Ÿè¸ªå’Œé«˜ä¿çœŸ3Dé‡å»ºã€‚</li>
<li>æ¡†æ¶æ˜¾å¼å»ºæ¨¡ç›¸æœºæ›å…‰æœŸé—´çš„è¿ç»­è½¨è¿¹ï¼Œæ”¯æŒäº‹ä»¶å’Œæ¨¡ç³Šæ„ŸçŸ¥çš„è·Ÿè¸ªå’Œæ˜ å°„ã€‚</li>
<li>å¼•å…¥å¯å­¦ä¹ çš„ç›¸æœºå“åº”å‡½æ•°ï¼Œå¯¹é½äº‹ä»¶å’Œå›¾åƒåŠ¨æ€èŒƒå›´ã€‚</li>
<li>é‡‡ç”¨æ— äº‹ä»¶æŸå¤±æŠ‘åˆ¶é‡å»ºè¿‡ç¨‹ä¸­çš„æŒ¯é“ƒä¼ªå½±ã€‚</li>
<li>éªŒè¯æ–¹æ³•åœ¨æ–°æ•°æ®é›†ä¸Šè¡¨ç°ä¼˜å¼‚ï¼ŒåŒ…æ‹¬åˆæˆå’ŒçœŸå®ä¸–ç•Œåºåˆ—ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.07003">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-f31e3abfc3fa66982492b43cf3dfd763.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-206f14266b6076996f2060637c0471da.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-070c33e262e61729533cea9c30a53ba4.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ab84c91e07b8b8547a875875f301ff93.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-7e170ae2855544a571b5844335a78b30.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b52f27523a2aeddbbcac36ca32c2fb76.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-dd4ed1fde6b0e63b0fb85ed8e860c7b3.jpg" align="middle">
</details>


<h1 id="-14"><a href="#-14" class="headerlink" title=""></a></h1><h2 id="Uni3R-Unified-3D-Reconstruction-and-Semantic-Understanding-via-Generalizable-Gaussian-Splatting-from-Unposed-Multi-View-Images"><a href="#Uni3R-Unified-3D-Reconstruction-and-Semantic-Understanding-via-Generalizable-Gaussian-Splatting-from-Unposed-Multi-View-Images" class="headerlink" title="Uni3R: Unified 3D Reconstruction and Semantic Understanding via   Generalizable Gaussian Splatting from Unposed Multi-View Images"></a>Uni3R: Unified 3D Reconstruction and Semantic Understanding via   Generalizable Gaussian Splatting from Unposed Multi-View Images</h2><p><strong>Authors:Xiangyu Sun, Haoyi Jiang, Liu Liu, Seungtae Nam, Gyeongjin Kang, Xinjie Wang, Wei Sui, Zhizhong Su, Wenyu Liu, Xinggang Wang, Eunbyung Park</strong></p>
<p>Reconstructing and semantically interpreting 3D scenes from sparse 2D views remains a fundamental challenge in computer vision. Conventional methods often decouple semantic understanding from reconstruction or necessitate costly per-scene optimization, thereby restricting their scalability and generalizability. In this paper, we introduce Uni3R, a novel feed-forward framework that jointly reconstructs a unified 3D scene representation enriched with open-vocabulary semantics, directly from unposed multi-view images. Our approach leverages a Cross-View Transformer to robustly integrate information across arbitrary multi-view inputs, which then regresses a set of 3D Gaussian primitives endowed with semantic feature fields. This unified representation facilitates high-fidelity novel view synthesis, open-vocabulary 3D semantic segmentation, and depth prediction, all within a single, feed-forward pass. Extensive experiments demonstrate that Uni3R establishes a new state-of-the-art across multiple benchmarks, including 25.07 PSNR on RE10K and 55.84 mIoU on ScanNet. Our work signifies a novel paradigm towards generalizable, unified 3D scene reconstruction and understanding. The code is available at <a target="_blank" rel="noopener" href="https://github.com/HorizonRobotics/Uni3R">https://github.com/HorizonRobotics/Uni3R</a>. </p>
<blockquote>
<p>ä»ç¨€ç–çš„äºŒç»´è§†è§’é‡å»ºå’Œè¯­ä¹‰è§£é‡Šä¸‰ç»´åœºæ™¯ä»æ˜¯è®¡ç®—æœºè§†è§‰é¢†åŸŸçš„ä¸€ä¸ªåŸºæœ¬æŒ‘æˆ˜ã€‚ä¼ ç»Ÿçš„æ–¹æ³•å¸¸å¸¸å°†è¯­ä¹‰ç†è§£ä¸é‡å»ºè§£è€¦ï¼Œæˆ–è€…éœ€è¦æ˜‚è´µçš„åœºæ™¯ä¼˜åŒ–ï¼Œä»è€Œé™åˆ¶äº†å…¶å¯æ‰©å±•æ€§å’Œé€šç”¨æ€§ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬ä»‹ç»äº†Uni3Rï¼Œè¿™æ˜¯ä¸€ç§æ–°å‹å‰é¦ˆæ¡†æ¶ï¼Œå®ƒç›´æ¥ä»æœªå®šä½çš„å¤šè§†è§’å›¾åƒä¸­è”åˆé‡å»ºäº†ä¸°å¯Œçš„å¼€æ”¾è¯æ±‡è¯­ä¹‰çš„ç»Ÿä¸€ä¸‰ç»´åœºæ™¯è¡¨ç¤ºã€‚æˆ‘ä»¬çš„æ–¹æ³•åˆ©ç”¨è·¨è§†å›¾å˜å‹å™¨ç¨³å¥åœ°æ•´åˆä»»æ„å¤šè§†è§’è¾“å…¥çš„ä¿¡æ¯ï¼Œç„¶åå›å½’ä¸€ç»„å¸¦æœ‰è¯­ä¹‰ç‰¹å¾åœºçš„ä¸‰ç»´é«˜æ–¯åŸºå…ƒã€‚è¿™ç§ç»Ÿä¸€è¡¨ç¤ºæœ‰åŠ©äºé«˜ä¿çœŸåº¦çš„æ–°è§†è§’åˆæˆã€å¼€æ”¾è¯æ±‡çš„3Dè¯­ä¹‰åˆ†å‰²å’Œæ·±åº¦é¢„æµ‹ï¼Œæ‰€æœ‰è¿™äº›éƒ½åœ¨å•æ¬¡å‰é¦ˆä¼ é€’ä¸­å®Œæˆã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼ŒUni3Råœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­å»ºç«‹äº†æ–°çš„æœ€å…ˆè¿›çš„æ€§èƒ½ï¼ŒåŒ…æ‹¬RE10Kä¸Šçš„25.07 PSNRå’ŒScanNetä¸Šçš„55.84 mIoUã€‚æˆ‘ä»¬çš„å·¥ä½œæ ‡å¿—ç€æœç€é€šç”¨ã€ç»Ÿä¸€çš„ä¸‰ç»´åœºæ™¯é‡å»ºå’Œç†è§£çš„æ–°èŒƒå¼ã€‚ä»£ç å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/HorizonRobotics/Uni3R%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/HorizonRobotics/Uni3Ræ‰¾åˆ°ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.03643v3">PDF</a> The code is available at <a target="_blank" rel="noopener" href="https://github.com/HorizonRobotics/Uni3R">https://github.com/HorizonRobotics/Uni3R</a></p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸ºUni3Rçš„æ–°å‹å‰é¦ˆæ¡†æ¶ï¼Œèƒ½å¤Ÿä»æ— å§¿æ€çš„å¤šè§†è§’å›¾åƒç›´æ¥é‡å»ºç»Ÿä¸€ä¸”å¯Œå«å¼€æ”¾è¯æ±‡è¯­ä¹‰çš„3Dåœºæ™¯è¡¨ç¤ºã€‚è¯¥æ¡†æ¶åˆ©ç”¨è·¨è§†å›¾å˜å‹å™¨ç¨³å¥åœ°æ•´åˆä»»æ„å¤šè§†è§’è¾“å…¥ä¿¡æ¯ï¼Œç„¶åå›å½’ä¸€ç»„å¸¦æœ‰è¯­ä¹‰ç‰¹å¾åœºçš„3Dé«˜æ–¯åŸå§‹æ•°æ®ã€‚è¿™ä¸€ç»Ÿä¸€è¡¨ç¤ºæœ‰åŠ©äºé«˜ä¿çœŸæ–°é¢–è§†å›¾åˆæˆã€å¼€æ”¾è¯æ±‡3Dè¯­ä¹‰åˆ†å‰²å’Œæ·±åº¦é¢„æµ‹ï¼Œæ‰€æœ‰è¿™äº›éƒ½å¯åœ¨å•æ¬¡å‰é¦ˆä¼ é€’ä¸­å®Œæˆã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>Uni3Ræ˜¯ä¸€ä¸ªå‰é¦ˆæ¡†æ¶ï¼Œèƒ½å¤Ÿä»ç¨€ç–çš„2Dè§†è§’é‡å»º3Dåœºæ™¯ã€‚</li>
<li>å®ƒè”åˆäº†è¯­ä¹‰ç†è§£å’Œåœºæ™¯é‡å»ºï¼Œæ— éœ€å¯¹æ¯ä¸ªåœºæ™¯è¿›è¡Œä¼˜åŒ–ã€‚</li>
<li>Uni3Råˆ©ç”¨è·¨è§†å›¾å˜å‹å™¨æ•´åˆå¤šè§†è§’ä¿¡æ¯ã€‚</li>
<li>è¯¥æ¡†æ¶å›å½’å¸¦æœ‰è¯­ä¹‰ç‰¹å¾åœºçš„3Dé«˜æ–¯åŸå§‹æ•°æ®ï¼Œå½¢æˆç»Ÿä¸€çš„åœºæ™¯è¡¨ç¤ºã€‚</li>
<li>Uni3Ræ”¯æŒé«˜ä¿çœŸæ–°é¢–è§†å›¾åˆæˆã€å¼€æ”¾è¯æ±‡3Dè¯­ä¹‰åˆ†å‰²å’Œæ·±åº¦é¢„æµ‹ã€‚</li>
<li>è¯¥æ–¹æ³•åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­è¾¾åˆ°æœ€æ–°æ°´å¹³ï¼ŒåŒ…æ‹¬RE10Kä¸Šçš„25.07 PSNRå’ŒScanNetä¸Šçš„55.84 mIoUã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.03643">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-b24c7ef4c6cd561b26496695e406d57c.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-872d963a6c288f84b81c606193208246.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-0a73727611f9f533d373a7a345f03b9f.jpg" align="middle">
</details>


<h1 id="-15"><a href="#-15" class="headerlink" title=""></a></h1><h2 id="MoGA-3D-Generative-Avatar-Prior-for-Monocular-Gaussian-Avatar-Reconstruction"><a href="#MoGA-3D-Generative-Avatar-Prior-for-Monocular-Gaussian-Avatar-Reconstruction" class="headerlink" title="MoGA: 3D Generative Avatar Prior for Monocular Gaussian Avatar   Reconstruction"></a>MoGA: 3D Generative Avatar Prior for Monocular Gaussian Avatar   Reconstruction</h2><p><strong>Authors:Zijian Dong, Longteng Duan, Jie Song, Michael J. Black, Andreas Geiger</strong></p>
<p>We present MoGA, a novel method to reconstruct high-fidelity 3D Gaussian avatars from a single-view image. The main challenge lies in inferring unseen appearance and geometric details while ensuring 3D consistency and realism. Most previous methods rely on 2D diffusion models to synthesize unseen views; however, these generated views are sparse and inconsistent, resulting in unrealistic 3D artifacts and blurred appearance. To address these limitations, we leverage a generative avatar model, that can generate diverse 3D avatars by sampling deformed Gaussians from a learned prior distribution. Due to limited 3D training data, such a 3D model alone cannot capture all image details of unseen identities. Consequently, we integrate it as a prior, ensuring 3D consistency by projecting input images into its latent space and enforcing additional 3D appearance and geometric constraints. Our novel approach formulates Gaussian avatar creation as model inversion by fitting the generative avatar to synthetic views from 2D diffusion models. The generative avatar provides an initialization for model fitting, enforces 3D regularization, and helps in refining pose. Experiments show that our method surpasses state-of-the-art techniques and generalizes well to real-world scenarios. Our Gaussian avatars are also inherently animatable. For code, see <a target="_blank" rel="noopener" href="https://zj-dong.github.io/MoGA/">https://zj-dong.github.io/MoGA/</a>. </p>
<blockquote>
<p>æˆ‘ä»¬æå‡ºäº†MoGAï¼Œè¿™æ˜¯ä¸€ç§ä»å•è§†å›¾å›¾åƒé‡å»ºé«˜ä¿çœŸ3Dé«˜æ–¯å¤´åƒçš„æ–°æ–¹æ³•ã€‚ä¸»è¦æŒ‘æˆ˜åœ¨äºæ¨æ–­å‡ºçœ‹ä¸è§çš„å¤–è§‚å’Œå‡ ä½•ç»†èŠ‚ï¼ŒåŒæ—¶ç¡®ä¿3Dçš„ä¸€è‡´æ€§å’ŒçœŸå®æ€§ã€‚å¤§å¤šæ•°ä¹‹å‰çš„æ–¹æ³•ä¾èµ–äº2Dæ‰©æ•£æ¨¡å‹æ¥åˆæˆæœªè§çš„è§†å›¾ï¼›ç„¶è€Œï¼Œè¿™äº›ç”Ÿæˆçš„è§†å›¾æ˜¯ç¨€ç–ä¸”ä¸ä¸€è‡´çš„ï¼Œå¯¼è‡´3Dä¼ªå½±ä¸çœŸå®å’Œå¤–è§‚æ¨¡ç³Šã€‚ä¸ºäº†è§£å†³è¿™äº›å±€é™æ€§ï¼Œæˆ‘ä»¬åˆ©ç”¨ç”Ÿæˆå¤´åƒæ¨¡å‹ï¼Œé€šè¿‡ä»å­¦ä¹ çš„å…ˆéªŒåˆ†å¸ƒä¸­é‡‡æ ·å˜å½¢é«˜æ–¯æ¥ç”Ÿæˆå„ç§3Då¤´åƒã€‚ç”±äºæœ‰é™çš„3Dè®­ç»ƒæ•°æ®ï¼Œä»…ä½¿ç”¨è¿™æ ·çš„3Dæ¨¡å‹æ— æ³•æ•è·æœªè§èº«ä»½çš„æ‰€æœ‰å›¾åƒç»†èŠ‚ã€‚å› æ­¤ï¼Œæˆ‘ä»¬å°†å…¶æ•´åˆä¸ºä¼˜å…ˆäº‹é¡¹ï¼Œé€šè¿‡å°†è¾“å…¥å›¾åƒæŠ•å½±åˆ°å…¶æ½œåœ¨ç©ºé—´å¹¶å¼ºåˆ¶æ‰§è¡Œé¢å¤–çš„3Då¤–è§‚å’Œå‡ ä½•çº¦æŸæ¥ç¡®ä¿3Dçš„ä¸€è‡´æ€§ã€‚æˆ‘ä»¬çš„æ–°æ–¹æ³•å°†é«˜æ–¯å¤´åƒåˆ›å»ºå…¬å¼åŒ–ä¸ºæ¨¡å‹åè½¬ï¼Œé€šè¿‡å°†ç”Ÿæˆå¤´åƒæ‹Ÿåˆåˆ°2Dæ‰©æ•£æ¨¡å‹çš„åˆæˆè§†å›¾æ¥å®ç°ã€‚ç”Ÿæˆå¤´åƒä¸ºæ¨¡å‹æ‹Ÿåˆæä¾›äº†åˆå§‹åŒ–ï¼Œå¼ºåˆ¶æ‰§è¡Œ3Dæ­£åˆ™åŒ–ï¼Œå¹¶æœ‰åŠ©äºç»†åŒ–å§¿æ€ã€‚å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•è¶…è¶Šäº†æœ€å…ˆè¿›çš„æŠ€æœ¯ï¼Œå¹¶å¾ˆå¥½åœ°æ¨å¹¿åˆ°äº†ç°å®ä¸–ç•Œåœºæ™¯ã€‚æˆ‘ä»¬çš„é«˜æ–¯å¤´åƒä¹Ÿæ˜¯å›ºæœ‰å¯åŠ¨ç”»çš„ã€‚æœ‰å…³ä»£ç ï¼Œè¯·å‚é˜…<a target="_blank" rel="noopener" href="https://zj-dong.github.io/MoGA/%E3%80%82">https://zj-dong.github.io/MoGA/ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2507.23597v3">PDF</a> ICCV 2025 (Highlight), Project Page: <a target="_blank" rel="noopener" href="https://zj-dong.github.io/MoGA/">https://zj-dong.github.io/MoGA/</a></p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†ä¸€ç§åä¸ºMoGAçš„æ–°æ–¹æ³•ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿä»å•ä¸€è§†è§’çš„å›¾åƒé‡å»ºå‡ºé«˜ä¿çœŸåº¦çš„3Dé«˜æ–¯åŒ–èº«ã€‚MoGAé€šè¿‡åˆ©ç”¨ç”ŸæˆåŒ–èº«æ¨¡å‹æ¥è§£å†³åœ¨æ¨æ–­éšè—çš„å¤–è§‚å’Œå‡ ä½•ç»†èŠ‚æ—¶é¢ä¸´çš„æŒ‘æˆ˜ï¼Œç¡®ä¿3Dä¸€è‡´æ€§å’ŒçœŸå®æ€§ã€‚è¯¥æ–¹æ³•é€šè¿‡å°†ç”ŸæˆåŒ–èº«æ¨¡å‹ä½œä¸ºå…ˆéªŒï¼Œå°†è¾“å…¥å›¾åƒæŠ•å½±åˆ°å…¶æ½œåœ¨ç©ºé—´å¹¶æ–½åŠ é¢å¤–çš„3Då¤–è§‚å’Œå‡ ä½•çº¦æŸï¼Œè§£å†³äº†ç°æœ‰æ–¹æ³•ç”Ÿæˆè§†å›¾ç¨€ç–ä¸”ä¸ä¸€è‡´çš„é—®é¢˜ã€‚MoGAå°†é«˜æ–¯åŒ–èº«åˆ›å»ºå…¬å¼åŒ–ä¸ºæ¨¡å‹åæ¼”é—®é¢˜ï¼Œé€šè¿‡å°†ç”ŸæˆåŒ–èº«æ‹Ÿåˆåˆ°æ¥è‡ªäºŒç»´æ‰©æ•£æ¨¡å‹çš„åˆæˆè§†å›¾æ¥å®ç°ã€‚å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•è¶…è¶Šäº†ç°æœ‰æŠ€æœ¯å¹¶åœ¨çœŸå®ä¸–ç•Œåœºæ™¯ä¸­å…·æœ‰è‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>MoGAæ˜¯ä¸€ç§ä»å•ä¸€è§†è§’å›¾åƒé‡å»ºé«˜ä¿çœŸ3Dé«˜æ–¯åŒ–èº«çš„æ–°æ–¹æ³•ã€‚</li>
<li>è¯¥æ–¹æ³•ä¸»è¦æŒ‘æˆ˜åœ¨äºæ¨æ–­éšè—çš„å¤–è§‚å’Œå‡ ä½•ç»†èŠ‚ï¼ŒåŒæ—¶ç¡®ä¿3Dä¸€è‡´æ€§å’ŒçœŸå®æ€§ã€‚</li>
<li>MoGAåˆ©ç”¨ç”ŸæˆåŒ–èº«æ¨¡å‹æ¥è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œè¯¥æ¨¡å‹å¯ä»¥ç”Ÿæˆå¤šæ ·åŒ–çš„3DåŒ–èº«ã€‚</li>
<li>MoGAé€šè¿‡å°†ç”ŸæˆåŒ–èº«æ¨¡å‹ä½œä¸ºå…ˆéªŒï¼Œè§£å†³äº†ç°æœ‰æ–¹æ³•ç”Ÿæˆè§†å›¾ç¨€ç–ä¸”ä¸ä¸€è‡´çš„é—®é¢˜ã€‚</li>
<li>MoGAé€šè¿‡å°†é«˜æ–¯åŒ–èº«åˆ›å»ºå…¬å¼åŒ–ä¸ºæ¨¡å‹åæ¼”é—®é¢˜ï¼Œå®ç°äº†å¯¹äºŒç»´æ‰©æ•£æ¨¡å‹çš„åˆæˆè§†å›¾çš„æ‹Ÿåˆã€‚</li>
<li>å®éªŒè¡¨æ˜MoGAåœ¨æ€§èƒ½ä¸Šè¶…è¶Šäº†ç°æœ‰æŠ€æœ¯ï¼Œå¹¶åœ¨çœŸå®ä¸–ç•Œåœºæ™¯ä¸­å…·æœ‰è‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2507.23597">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-151437717114e341423e55cce8940f33.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-92c4cfb63cc8def479f57a52e048adf5.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-4030795a97d1504b3de20f5c85aeca83.jpg" align="middle">
</details>


<h1 id="-16"><a href="#-16" class="headerlink" title=""></a></h1><h2 id="FROSS-Faster-than-Real-Time-Online-3D-Semantic-Scene-Graph-Generation-from-RGB-D-Images"><a href="#FROSS-Faster-than-Real-Time-Online-3D-Semantic-Scene-Graph-Generation-from-RGB-D-Images" class="headerlink" title="FROSS: Faster-than-Real-Time Online 3D Semantic Scene Graph Generation   from RGB-D Images"></a>FROSS: Faster-than-Real-Time Online 3D Semantic Scene Graph Generation   from RGB-D Images</h2><p><strong>Authors:Hao-Yu Hou, Chun-Yi Lee, Motoharu Sonogashira, Yasutomo Kawanishi</strong></p>
<p>The ability to abstract complex 3D environments into simplified and structured representations is crucial across various domains. 3D semantic scene graphs (SSGs) achieve this by representing objects as nodes and their interrelationships as edges, facilitating high-level scene understanding. Existing methods for 3D SSG generation, however, face significant challenges, including high computational demands and non-incremental processing that hinder their suitability for real-time open-world applications. To address this issue, we propose FROSS (Faster-than-Real-Time Online 3D Semantic Scene Graph Generation), an innovative approach for online and faster-than-real-time 3D SSG generation that leverages the direct lifting of 2D scene graphs to 3D space and represents objects as 3D Gaussian distributions. This framework eliminates the dependency on precise and computationally-intensive point cloud processing. Furthermore, we extend the Replica dataset with inter-object relationship annotations, creating the ReplicaSSG dataset for comprehensive evaluation of FROSS. The experimental results from evaluations on ReplicaSSG and 3DSSG datasets show that FROSS can achieve superior performance while operating significantly faster than prior 3D SSG generation methods. Our implementation and dataset are publicly available at <a target="_blank" rel="noopener" href="https://github.com/Howardkhh/FROSS">https://github.com/Howardkhh/FROSS</a>. </p>
<blockquote>
<p>å°†å¤æ‚çš„ä¸‰ç»´ç¯å¢ƒæŠ½è±¡ä¸ºç®€æ´çš„ç»“æ„åŒ–è¡¨ç¤ºï¼Œåœ¨ä¸åŒé¢†åŸŸä¸­éƒ½è‡³å…³é‡è¦ã€‚ä¸‰ç»´è¯­ä¹‰åœºæ™¯å›¾ï¼ˆSSGï¼‰é€šè¿‡ä»¥èŠ‚ç‚¹è¡¨ç¤ºç‰©ä½“ã€ä»¥è¾¹è¡¨ç¤ºå®ƒä»¬ä¹‹é—´çš„ç›¸äº’å…³ç³»ï¼Œæ¥å®ç°è¿™ä¸€ç›®çš„ï¼Œä»è€Œä¿ƒè¿›å¯¹é«˜çº§åœºæ™¯çš„ç†è§£ã€‚ç„¶è€Œï¼Œç°æœ‰çš„ä¸‰ç»´SSGç”Ÿæˆæ–¹æ³•é¢ä¸´é‡å¤§æŒ‘æˆ˜ï¼ŒåŒ…æ‹¬è®¡ç®—éœ€æ±‚é«˜å’Œéå¢é‡å¤„ç†ï¼Œè¿™é˜»ç¢äº†å®ƒä»¬åœ¨å®æ—¶å¼€æ”¾ä¸–ç•Œåº”ç”¨ä¸­çš„é€‚ç”¨æ€§ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†FROSSï¼ˆå®æ—¶ä¸‰ç»´è¯­ä¹‰åœºæ™¯å›¾å¿«é€Ÿç”Ÿæˆï¼‰ï¼Œè¿™æ˜¯ä¸€ç§åˆ›æ–°çš„åœ¨çº¿ä¸‰ç»´SSGå¿«é€Ÿç”Ÿæˆæ–¹æ³•ï¼Œå®ƒåˆ©ç”¨äºŒç»´åœºæ™¯å›¾åˆ°ä¸‰ç»´ç©ºé—´çš„ç›´æ¥æå‡ï¼Œå¹¶å°†ç‰©ä½“è¡¨ç¤ºä¸ºä¸‰ç»´é«˜æ–¯åˆ†å¸ƒã€‚è¯¥æ¡†æ¶æ¶ˆé™¤äº†å¯¹ç²¾ç¡®ä¸”è®¡ç®—å¯†é›†çš„ç‚¹äº‘å¤„ç†çš„ä¾èµ–ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æ‰©å±•äº†Replicaæ•°æ®é›†ï¼Œå¢åŠ äº†ç‰©ä½“é—´å…³ç³»æ³¨é‡Šï¼Œåˆ›å»ºäº†ReplicaSSGæ•°æ®é›†ï¼Œä»¥ä¾¿å…¨é¢è¯„ä¼°FROSSã€‚åœ¨ReplicaSSGå’Œ3DSSGæ•°æ®é›†ä¸Šçš„è¯„ä¼°å®éªŒç»“æœè¡¨æ˜ï¼ŒFROSSåœ¨æ€§èƒ½ä¸Šä¼˜äºä»¥å‰çš„ä¸‰ç»´SSGç”Ÿæˆæ–¹æ³•ï¼ŒåŒæ—¶è¿è¡Œé€Ÿåº¦æ›´å¿«ã€‚æˆ‘ä»¬çš„å®ç°å’Œæ•°æ®é›†å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/Howardkhh/FROSS%E4%B8%8A%E5%85%AC%E5%BC%80%E8%AE%BF%E9%97%AE%E3%80%82">https://github.com/Howardkhh/FROSSä¸Šå…¬å¼€è®¿é—®ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2507.19993v2">PDF</a> International Conference on Computer Vision (ICCV 2025)</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºä¸€ç§åä¸ºFROSSçš„å¿«é€Ÿåœ¨çº¿ä¸‰ç»´è¯­ä¹‰åœºæ™¯å›¾ç”Ÿæˆæ–¹æ³•ï¼Œé€šè¿‡å°†äºŒç»´åœºæ™¯å›¾ç›´æ¥æå‡åˆ°ä¸‰ç»´ç©ºé—´å¹¶ç”¨ä¸‰ç»´é«˜æ–¯åˆ†å¸ƒè¡¨ç¤ºç‰©ä½“ï¼Œå®ç°äº†åœ¨çº¿ã€å®æ—¶ä¸‰ç»´è¯­ä¹‰åœºæ™¯å›¾çš„å¿«é€Ÿç”Ÿæˆã€‚è¯¥æ–¹æ³•å…‹æœäº†ç°æœ‰ä¸‰ç»´SSGç”Ÿæˆæ–¹æ³•çš„è®¡ç®—é‡å¤§å’Œéå¢é‡å¤„ç†çš„ç¼ºç‚¹ï¼Œé€‚ç”¨äºå®æ—¶å¼€æ”¾ä¸–ç•Œåº”ç”¨ã€‚åŒæ—¶ï¼Œæ‰©å±•äº†Replicaæ•°æ®é›†ï¼Œå¢åŠ äº†ç‰©ä½“é—´å…³ç³»æ³¨é‡Šï¼Œåˆ›å»ºäº†ReplicaSSGæ•°æ®é›†ç”¨äºå…¨é¢è¯„ä¼°FROSSæ€§èƒ½ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒFROSSåœ¨æ€§èƒ½ä¸Šä¼˜äºå…¶ä»–ä¸‰ç»´SSGç”Ÿæˆæ–¹æ³•ï¼Œä¸”è¿è¡Œé€Ÿåº¦æ›´å¿«ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>3Dè¯­ä¹‰åœºæ™¯å›¾ï¼ˆSSGsï¼‰åœ¨è¡¨ç¤ºç‰©ä½“çš„èŠ‚ç‚¹åŠå…¶ç›¸äº’å…³ç³»è¾¹ç¼˜æ–¹é¢ï¼Œä¿ƒè¿›äº†é«˜çº§åœºæ™¯ç†è§£ï¼Œå¹¿æ³›åº”ç”¨äºä¸åŒé¢†åŸŸã€‚</li>
<li>ç°æœ‰3D SSGç”Ÿæˆæ–¹æ³•é¢ä¸´é«˜è®¡ç®—éœ€æ±‚å’Œä¸é€‚åˆå®æ—¶å¼€æ”¾ä¸–ç•Œåº”ç”¨çš„æŒ‘æˆ˜ã€‚</li>
<li>FROSSæ–¹æ³•é€šè¿‡å°†äºŒç»´åœºæ™¯å›¾ç›´æ¥æå‡åˆ°ä¸‰ç»´ç©ºé—´å¹¶ç”¨ä¸‰ç»´é«˜æ–¯åˆ†å¸ƒè¡¨ç¤ºç‰©ä½“ï¼Œå®ç°äº†å¿«é€Ÿåœ¨çº¿ä¸‰ç»´SSGç”Ÿæˆã€‚</li>
<li>FROSSæ¶ˆé™¤äº†å¯¹ç²¾ç¡®ä¸”è®¡ç®—å¯†é›†çš„ç‚¹äº‘å¤„ç†çš„ä¾èµ–ï¼Œæ˜¾è‘—æé«˜äº†æ€§èƒ½ã€‚</li>
<li>ä¸ºå…¨é¢è¯„ä¼°FROSSæ€§èƒ½ï¼Œæ‰©å±•äº†Replicaæ•°æ®é›†å¹¶åˆ›å»ºäº†ReplicaSSGæ•°æ®é›†ã€‚</li>
<li>å®éªŒç»“æœè¡¨æ˜ï¼ŒFROSSåœ¨æ€§èƒ½ä¸Šä¼˜äºå…¶ä»–ä¸‰ç»´SSGç”Ÿæˆæ–¹æ³•ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2507.19993">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-1ed32fdb433caa2d0e5db66f83c29cf6.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-67715437c8522280da5972c04e142e1a.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-4ce27ae180b2af69b37d3867ec61d6ae.jpg" align="middle">
</details>


<h1 id="-17"><a href="#-17" class="headerlink" title=""></a></h1><h2 id="QuickSplat-Fast-3D-Surface-Reconstruction-via-Learned-Gaussian-Initialization"><a href="#QuickSplat-Fast-3D-Surface-Reconstruction-via-Learned-Gaussian-Initialization" class="headerlink" title="QuickSplat: Fast 3D Surface Reconstruction via Learned Gaussian   Initialization"></a>QuickSplat: Fast 3D Surface Reconstruction via Learned Gaussian   Initialization</h2><p><strong>Authors:Yueh-Cheng Liu, Lukas HÃ¶llein, Matthias NieÃŸner, Angela Dai</strong></p>
<p>Surface reconstruction is fundamental to computer vision and graphics, enabling applications in 3D modeling, mixed reality, robotics, and more. Existing approaches based on volumetric rendering obtain promising results, but optimize on a per-scene basis, resulting in a slow optimization that can struggle to model under-observed or textureless regions. We introduce QuickSplat, which learns data-driven priors to generate dense initializations for 2D gaussian splatting optimization of large-scale indoor scenes. This provides a strong starting point for the reconstruction, which accelerates the convergence of the optimization and improves the geometry of flat wall structures. We further learn to jointly estimate the densification and update of the scene parameters during each iteration; our proposed densifier network predicts new Gaussians based on the rendering gradients of existing ones, removing the needs of heuristics for densification. Extensive experiments on large-scale indoor scene reconstruction demonstrate the superiority of our data-driven optimization. Concretely, we accelerate runtime by 8x, while decreasing depth errors by up to 48% in comparison to state of the art methods. </p>
<blockquote>
<p>è¡¨é¢é‡å»ºæ˜¯è®¡ç®—æœºè§†è§‰å’Œå›¾å½¢å­¦çš„åŸºç¡€ï¼Œåœ¨3Då»ºæ¨¡ã€æ··åˆç°å®ã€æœºå™¨äººæŠ€æœ¯ç­‰é¢†åŸŸæœ‰ç€å¹¿æ³›çš„åº”ç”¨ã€‚ç°æœ‰çš„åŸºäºä½“ç§¯æ¸²æŸ“çš„æ–¹æ³•å–å¾—äº†æœ‰å‰æ™¯çš„ç»“æœï¼Œä½†å®ƒä»¬æ˜¯é’ˆå¯¹æ¯ä¸ªåœºæ™¯è¿›è¡Œä¼˜åŒ–çš„ï¼Œå¯¼è‡´ä¼˜åŒ–è¿‡ç¨‹ç¼“æ…¢ï¼Œéš¾ä»¥å¯¹è§‚æµ‹ä¸è¶³æˆ–æ— çº¹ç†çš„åŒºåŸŸè¿›è¡Œå»ºæ¨¡ã€‚æˆ‘ä»¬æ¨å‡ºäº†QuickSplatï¼Œå®ƒåˆ©ç”¨æ•°æ®é©±åŠ¨å…ˆéªŒçŸ¥è¯†ç”Ÿæˆå¤§è§„æ¨¡å®¤å†…åœºæ™¯çš„2Dé«˜æ–¯æ‹¼è´´ä¼˜åŒ–çš„å¯†é›†åˆå§‹åŒ–ã€‚è¿™ä¸ºé‡å»ºæä¾›äº†ä¸€ä¸ªè‰¯å¥½çš„èµ·ç‚¹ï¼ŒåŠ é€Ÿäº†ä¼˜åŒ–çš„æ”¶æ•›ï¼Œå¹¶æ”¹å–„äº†å¹³é¢å¢™ç»“æ„çš„å‡ ä½•å½¢çŠ¶ã€‚æˆ‘ä»¬è¿›ä¸€æ­¥å­¦ä¹ åœ¨æ¯æ¬¡è¿­ä»£æœŸé—´è”åˆä¼°è®¡åœºæ™¯çš„å¯†é›†åŒ–å’Œå‚æ•°æ›´æ–°ï¼›æˆ‘ä»¬æå‡ºçš„å¯†åº¦ç½‘ç»œæ ¹æ®ç°æœ‰æ¸²æŸ“æ¢¯åº¦é¢„æµ‹æ–°çš„é«˜æ–¯åˆ†å¸ƒï¼Œä»è€Œæ¶ˆé™¤äº†å¯å‘å¼å¯†é›†åŒ–çš„éœ€æ±‚ã€‚å¤§è§„æ¨¡å®¤å†…åœºæ™¯é‡å»ºçš„å¹¿æ³›å®éªŒè¯æ˜äº†æˆ‘ä»¬æ•°æ®é©±åŠ¨ä¼˜åŒ–çš„ä¼˜è¶Šæ€§ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬çš„æ–¹æ³•å°†è¿è¡Œæ—¶é€Ÿåº¦æé«˜äº†8å€ï¼Œä¸æœ€æ–°æŠ€æœ¯ç›¸æ¯”ï¼Œæ·±åº¦è¯¯å·®é™ä½äº†é«˜è¾¾48%ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.05591v2">PDF</a> ICCV 2025. Project page: <a target="_blank" rel="noopener" href="https://liu115.github.io/quicksplat">https://liu115.github.io/quicksplat</a>, Video:   <a target="_blank" rel="noopener" href="https://youtu.be/2IA_gnFvFG8">https://youtu.be/2IA_gnFvFG8</a></p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†QuickSplatæ–¹æ³•ï¼Œè¯¥æ–¹æ³•åˆ©ç”¨æ•°æ®é©±åŠ¨å…ˆéªŒç”Ÿæˆå¤§è§„æ¨¡å®¤å†…åœºæ™¯çš„å¯†é›†åˆå§‹åŒ–ï¼Œç”¨äº2Dé«˜æ–¯æ¶‚æŠ¹ä¼˜åŒ–ã€‚æ­¤æ–¹æ³•ä¸ºé‡å»ºæä¾›äº†ä¸€ä¸ªè‰¯å¥½çš„èµ·ç‚¹ï¼ŒåŠ é€Ÿäº†ä¼˜åŒ–çš„æ”¶æ•›ï¼Œå¹¶æ”¹è¿›äº†å¹³é¢å¢™ç»“æ„çš„å‡ ä½•å½¢çŠ¶ã€‚é€šè¿‡è”åˆä¼°è®¡åœºæ™¯å‚æ•°çš„å¯†é›†å’Œæ›´æ–°ï¼Œæå‡ºçš„æ–°å‹å¯†åº¦ç½‘ç»œèƒ½å¤Ÿé¢„æµ‹åŸºäºç°æœ‰æ¸²æŸ“æ¢¯åº¦çš„æ–°çš„é«˜æ–¯åˆ†å¸ƒï¼Œæ— éœ€å¯†åº¦å¯å‘å¼ç®—æ³•ã€‚å®éªŒè¯æ˜ï¼Œåœ¨å¤§å‹å®¤å†…åœºæ™¯é‡å»ºä¸­ï¼Œæ•°æ®é©±åŠ¨çš„ä¼˜åŒ–æ–¹æ³•å…·æœ‰ä¼˜è¶Šæ€§ï¼Œè¿è¡Œæ—¶é€Ÿåº¦æé«˜äº†8å€ï¼Œæ·±åº¦è¯¯å·®é™ä½äº†é«˜è¾¾48%ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>QuickSplatæ–¹æ³•åˆ©ç”¨æ•°æ®é©±åŠ¨å…ˆéªŒç”Ÿæˆå¤§è§„æ¨¡å®¤å†…åœºæ™¯çš„å¯†é›†åˆå§‹åŒ–ï¼Œç”¨äºåŠ é€Ÿ3Då»ºæ¨¡çš„2Dé«˜æ–¯æ¶‚æŠ¹ä¼˜åŒ–ã€‚</li>
<li>è¯¥æ–¹æ³•æä¾›äº†ä¸€ä¸ªå¼ºå¤§çš„èµ·ç‚¹ï¼Œä½¿ä¼˜åŒ–è¿‡ç¨‹æ›´å¿«æ”¶æ•›ï¼Œå¹¶æ”¹è¿›äº†å¹³é¢å¢™ç»“æ„çš„å‡ ä½•å½¢çŠ¶ã€‚</li>
<li>é€šè¿‡è”åˆä¼°è®¡åœºæ™¯å‚æ•°çš„å¯†é›†å’Œæ›´æ–°ï¼Œæé«˜äº†ä¼˜åŒ–æ•ˆç‡ã€‚</li>
<li>æå‡ºçš„å¯†åº¦ç½‘ç»œèƒ½å¤Ÿé¢„æµ‹æ–°çš„é«˜æ–¯åˆ†å¸ƒï¼ŒåŸºäºç°æœ‰æ¸²æŸ“æ¢¯åº¦çš„ä¿¡æ¯ï¼Œæ— éœ€é¢å¤–çš„å¯å‘å¼ç®—æ³•ã€‚</li>
<li>å®éªŒç»“æœæ˜¾ç¤ºï¼Œä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼ŒQuickSplatæ–¹æ³•åœ¨è¿è¡Œæ—¶é€Ÿåº¦ä¸Šæé«˜äº†8å€ã€‚</li>
<li>QuickSplatæ–¹æ³•èƒ½å¤Ÿé™ä½æ·±åº¦è¯¯å·®ï¼Œå…¶é™ä½å¹…åº¦é«˜è¾¾48%ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.05591">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-1ff797b4cbf59c4a58573871d0c33516.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-58b4700c7a58cd084cb78ccdc9146702.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ea6d1a9c5b279b3abc4b1f5bdeb655f6.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-3b70da1de0a9348d646c16cb5d19824e.jpg" align="middle">
</details>


<h1 id="-18"><a href="#-18" class="headerlink" title=""></a></h1><h2 id="3D-Gaussian-Splatting-Data-Compression-with-Mixture-of-Priors"><a href="#3D-Gaussian-Splatting-Data-Compression-with-Mixture-of-Priors" class="headerlink" title="3D Gaussian Splatting Data Compression with Mixture of Priors"></a>3D Gaussian Splatting Data Compression with Mixture of Priors</h2><p><strong>Authors:Lei Liu, Zhenghao Chen, Dong Xu</strong></p>
<p>3D Gaussian Splatting (3DGS) data compression is crucial for enabling efficient storage and transmission in 3D scene modeling. However, its development remains limited due to inadequate entropy models and suboptimal quantization strategies for both lossless and lossy compression scenarios, where existing methods have yet to 1) fully leverage hyperprior information to construct robust conditional entropy models, and 2) apply fine-grained, element-wise quantization strategies for improved compression granularity. In this work, we propose a novel Mixture of Priors (MoP) strategy to simultaneously address these two challenges. Specifically, inspired by the Mixture-of-Experts (MoE) paradigm, our MoP approach processes hyperprior information through multiple lightweight MLPs to generate diverse prior features, which are subsequently integrated into the MoP feature via a gating mechanism. To enhance lossless compression, the resulting MoP feature is utilized as a hyperprior to improve conditional entropy modeling. Meanwhile, for lossy compression, we employ the MoP feature as guidance information in an element-wise quantization procedure, leveraging a prior-guided Coarse-to-Fine Quantization (C2FQ) strategy with a predefined quantization step value. Specifically, we expand the quantization step value into a matrix and adaptively refine it from coarse to fine granularity, guided by the MoP feature, thereby obtaining a quantization step matrix that facilitates element-wise quantization. Extensive experiments demonstrate that our proposed 3DGS data compression framework achieves state-of-the-art performance across multiple benchmarks, including Mip-NeRF360, BungeeNeRF, DeepBlending, and Tank&amp;Temples. </p>
<blockquote>
<p>3Dé«˜æ–¯æ··åˆï¼ˆ3DGSï¼‰æ•°æ®å‹ç¼©å¯¹äºå®ç°ä¸‰ç»´åœºæ™¯å»ºæ¨¡ä¸­çš„é«˜æ•ˆå­˜å‚¨å’Œä¼ è¾“è‡³å…³é‡è¦ã€‚ç„¶è€Œï¼Œå…¶å¼€å‘ä»ç„¶å—é™ï¼Œå› ä¸ºåœ¨æ— æŸå’Œæœ‰æŸå‹ç¼©åœºæ™¯ä¸­ï¼Œç°æœ‰çš„ç†µæ¨¡å‹ä¸å¤Ÿå……åˆ†ï¼Œé‡åŒ–ç­–ç•¥ä¹Ÿä¸ä½³ã€‚ç°æœ‰æ–¹æ³•å°šæœªå……åˆ†åˆ©ç”¨è¶…å…ˆéªŒä¿¡æ¯æ¥æ„å»ºç¨³å¥çš„æ¡ä»¶ç†µæ¨¡å‹ï¼Œå¹¶ä¸”æœªé‡‡ç”¨ç²¾ç»†ç²’åº¦çš„å…ƒç´ çº§é‡åŒ–ç­–ç•¥æ¥æé«˜å‹ç¼©ç²’åº¦ã€‚é’ˆå¯¹è¿™ä¸¤ä¸ªæŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°é¢–çš„å…ˆéªŒæ··åˆï¼ˆMoPï¼‰ç­–ç•¥ã€‚å…·ä½“æ¥è¯´ï¼Œå—åˆ°æ··åˆä¸“å®¶ï¼ˆMoEï¼‰èŒƒå¼çš„å¯å‘ï¼Œæˆ‘ä»¬çš„MoPæ–¹æ³•é€šè¿‡å¤šä¸ªè½»é‡çº§MLPå¤„ç†è¶…å…ˆéªŒä¿¡æ¯ï¼Œä»¥ç”Ÿæˆå¤šç§å…ˆéªŒç‰¹å¾ï¼Œç„¶åé€šè¿‡é—¨æ§æœºåˆ¶å°†è¿™äº›ç‰¹å¾é›†æˆåˆ°MoPç‰¹å¾ä¸­ã€‚ä¸ºäº†æé«˜æ— æŸå‹ç¼©æ€§èƒ½ï¼Œæˆ‘ä»¬å°†å¾—åˆ°çš„MoPç‰¹å¾ç”¨ä½œè¶…å…ˆéªŒä¿¡æ¯ï¼Œä»¥æ”¹è¿›æ¡ä»¶ç†µå»ºæ¨¡ã€‚è€Œå¯¹äºæœ‰æŸå‹ç¼©ï¼Œæˆ‘ä»¬å°†MoPç‰¹å¾ç”¨ä½œå…ƒç´ çº§é‡åŒ–è¿‡ç¨‹ä¸­çš„å¼•å¯¼ä¿¡æ¯ï¼Œé‡‡ç”¨å—å…ˆéªŒå¼•å¯¼çš„ç²—ç»†é‡åŒ–ï¼ˆC2FQï¼‰ç­–ç•¥åŠé¢„è®¾çš„é‡åŒ–æ­¥é•¿å€¼ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬å°†é‡åŒ–æ­¥é•¿å€¼æ‰©å±•ä¸ºçŸ©é˜µï¼Œå¹¶åœ¨MoPç‰¹å¾çš„å¼•å¯¼ä¸‹ä»ç²—åˆ°ç»†ç²’åº¦è¿›è¡Œè‡ªé€‚åº”ç»†åŒ–ï¼Œä»è€Œè·å¾—ä¸€ä¸ªé‡åŒ–æ­¥é•¿çŸ©é˜µï¼Œä»¥æ”¯æŒå…ƒç´ çº§é‡åŒ–ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬æå‡ºçš„3DGSæ•°æ®å‹ç¼©æ¡†æ¶åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­è¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½æ°´å¹³ï¼ŒåŒ…æ‹¬Mip-NeRF360ã€BungeeNeRFã€DeepBlendingå’ŒTankï¼†Templesã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.03310v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æ¢è®¨äº†åŸºäºä¸‰ç»´é«˜æ–¯èåˆï¼ˆ3DGSï¼‰çš„æ•°æ®å‹ç¼©æŠ€æœ¯å¯¹äºä¸‰ç»´åœºæ™¯å»ºæ¨¡çš„é‡è¦æ€§ã€‚é’ˆå¯¹ç°æœ‰æ–¹æ³•çš„ä¸è¶³ï¼Œå¦‚ç¼ºä¹é«˜æ•ˆçš„ç†µæ¨¡å‹å’Œé‡åŒ–ç­–ç•¥ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„æ··åˆå…ˆéªŒï¼ˆMoPï¼‰ç­–ç•¥æ¥åŒæ—¶è§£å†³æ— æŸå’Œæœ‰æŸå‹ç¼©çš„é—®é¢˜ã€‚MoPç­–ç•¥åˆ©ç”¨å¤šä¸ªè½»é‡çº§MLPå¤„ç†è¶…å…ˆéªŒä¿¡æ¯ç”Ÿæˆå¤šç§å…ˆéªŒç‰¹å¾ï¼Œç„¶åé€šè¿‡é—¨æ§æœºåˆ¶æ•´åˆåˆ°MoPç‰¹å¾ä¸­ã€‚åœ¨æ— æŸå‹ç¼©æ–¹é¢ï¼Œä½¿ç”¨MoPç‰¹å¾æé«˜æ¡ä»¶ç†µå»ºæ¨¡ã€‚å¯¹äºæœ‰æŸå‹ç¼©ï¼Œå°†MoPç‰¹å¾ç”¨ä½œå¼•å¯¼ä¿¡æ¯è¿›è¡Œå…ƒç´ çº§é‡åŒ–è¿‡ç¨‹ï¼Œå¹¶åˆ©ç”¨å…ˆéªŒå¼•å¯¼ä¸‹çš„ç²—ç»†é‡åŒ–ç­–ç•¥è·å¾—è‡ªé€‚åº”çš„é‡åŒ–æ­¥é•¿çŸ©é˜µã€‚å®éªŒè¯æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šå–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>3DGSæ•°æ®å‹ç¼©å¯¹äºé«˜æ•ˆå­˜å‚¨å’Œä¼ è¾“åœ¨3Dåœºæ™¯å»ºæ¨¡ä¸­è‡³å…³é‡è¦ã€‚</li>
<li>ç°æœ‰æ–¹æ³•åœ¨æ— æŸå’ŒæŸå¤±å‹ç¼©åœºæ™¯ä¸­ï¼Œç”±äºç¼ºä¹é«˜æ•ˆçš„ç†µæ¨¡å‹å’Œé‡åŒ–ç­–ç•¥è€Œå—åˆ°é™åˆ¶ã€‚</li>
<li>æå‡ºäº†ä¸€ç§æ–°é¢–çš„æ··åˆå…ˆéªŒï¼ˆMoPï¼‰ç­–ç•¥æ¥æ”¹è¿›æ¡ä»¶ç†µå»ºæ¨¡å’Œæé«˜é‡åŒ–ç²¾åº¦ã€‚</li>
<li>MoPç­–ç•¥ä½¿ç”¨å¤šä¸ªè½»é‡çº§MLPå¤„ç†è¶…å…ˆéªŒä¿¡æ¯å¹¶æ•´åˆåˆ°MoPç‰¹å¾ä¸­ã€‚</li>
<li>MoPç‰¹å¾åœ¨æ— æŸå‹ç¼©ä¸­ç”¨äºæé«˜æ¡ä»¶ç†µå»ºæ¨¡ï¼Œåœ¨æŸå¤±å‹ç¼©ä¸­ç”¨ä½œå¼•å¯¼ä¿¡æ¯æ¥è¿›è¡Œå…ƒç´ çº§é‡åŒ–ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.03310">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-ab742fd5931711bc3a6803c997f596d8.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-4138f53ae00de72fa3513b27a35d4977.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-43455c4d6b46b9a98201a690a81c64c6.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d2ba30cd89b6e2181f891308da4ebdf2.jpg" align="middle">
</details>


<h1 id="-19"><a href="#-19" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-08-13/3DGS/">https://kedreamix.github.io/Talk2Paper/Paper/2025-08-13/3DGS/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/3DGS/">
                                    <span class="chip bg-color">3DGS</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-08-13/NeRF/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-996752574dbcc3a99aa5a5196bf1704c.jpg" class="responsive-img" alt="NeRF">
                        
                        <span class="card-title">NeRF</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            NeRF æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-08-13  SAGOnline Segment Any Gaussians Online
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-08-13
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/NeRF/" class="post-category">
                                    NeRF
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/NeRF/">
                        <span class="chip bg-color">NeRF</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-08-13/%E5%85%83%E5%AE%87%E5%AE%99_%E8%99%9A%E6%8B%9F%E4%BA%BA/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-151437717114e341423e55cce8940f33.jpg" class="responsive-img" alt="å…ƒå®‡å®™/è™šæ‹Ÿäºº">
                        
                        <span class="card-title">å…ƒå®‡å®™/è™šæ‹Ÿäºº</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            å…ƒå®‡å®™/è™šæ‹Ÿäºº æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-08-13  MoGA 3D Generative Avatar Prior for Monocular Gaussian Avatar   Reconstruction
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-08-13
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/%E5%85%83%E5%AE%87%E5%AE%99-%E8%99%9A%E6%8B%9F%E4%BA%BA/" class="post-category">
                                    å…ƒå®‡å®™/è™šæ‹Ÿäºº
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/%E5%85%83%E5%AE%87%E5%AE%99-%E8%99%9A%E6%8B%9F%E4%BA%BA/">
                        <span class="chip bg-color">å…ƒå®‡å®™/è™šæ‹Ÿäºº</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">32714.1k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
