<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Agent">
    <meta name="description" content="Agent æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-08-13  MuaLLM A Multimodal Large Language Model Agent for Circuit Design   Assistance with Hybrid Contextual Retrieval-Augmented Generation">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>Agent | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://picx.zhimg.com/v2-fe227313b697f8ef6630d0cca633b67d.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Agent</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/Agent/">
                                <span class="chip bg-color">Agent</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/Agent/" class="post-category">
                                Agent
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-08-13
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-08-20
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    17.6k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    71 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-08-13-æ›´æ–°"><a href="#2025-08-13-æ›´æ–°" class="headerlink" title="2025-08-13 æ›´æ–°"></a>2025-08-13 æ›´æ–°</h1><h2 id="MuaLLM-A-Multimodal-Large-Language-Model-Agent-for-Circuit-Design-Assistance-with-Hybrid-Contextual-Retrieval-Augmented-Generation"><a href="#MuaLLM-A-Multimodal-Large-Language-Model-Agent-for-Circuit-Design-Assistance-with-Hybrid-Contextual-Retrieval-Augmented-Generation" class="headerlink" title="MuaLLM: A Multimodal Large Language Model Agent for Circuit Design   Assistance with Hybrid Contextual Retrieval-Augmented Generation"></a>MuaLLM: A Multimodal Large Language Model Agent for Circuit Design   Assistance with Hybrid Contextual Retrieval-Augmented Generation</h2><p><strong>Authors:Pravallika Abbineni, Saoud Aldowaish, Colin Liechty, Soroosh Noorzad, Ali Ghazizadeh, Morteza Fayazi</strong></p>
<p>Conducting a comprehensive literature review is crucial for advancing circuit design methodologies. However, the rapid influx of state-of-the-art research, inconsistent data representation, and the complexity of optimizing circuit design objectives make this task significantly challenging. In this paper, we propose MuaLLM, an open-source multimodal Large Language Model (LLM) agent for circuit design assistance that integrates a hybrid Retrieval-Augmented Generation (RAG) framework with an adaptive vector database of circuit design research papers. Unlike conventional LLMs, the MuaLLM agent employs a Reason + Act (ReAct) workflow for iterative reasoning, goal-setting, and multi-step information retrieval. It functions as a question-answering design assistant, capable of interpreting complex queries and providing reasoned responses grounded in circuit literature. Its multimodal capabilities enable processing of both textual and visual data, facilitating more efficient and comprehensive analysis. The system dynamically adapts using intelligent search tools, automated document retrieval from the internet, and real-time database updates. Unlike conventional approaches constrained by model context limits, MuaLLM decouples retrieval from inference, enabling scalable reasoning over arbitrarily large corpora. At the maximum context length supported by standard LLMs, MuaLLM remains up to 10x less costly and 1.6x faster while maintaining the same accuracy. This allows rapid, no-human-in-the-loop database generation, overcoming the bottleneck of simulation-based dataset creation for circuits. To evaluate MuaLLM, we introduce two custom datasets: RAG-250, targeting retrieval and citation performance, and Reasoning-100 (Reas-100), focused on multistep reasoning in circuit design. MuaLLM achieves 90.1% recall on RAG-250, and 86.8% accuracy on Reas-100. </p>
<blockquote>
<p>å¯¹ç”µè·¯è®¾è®¡æ–¹æ³•è¿›è¡Œå…¨é¢çš„æ–‡çŒ®ç»¼è¿°å¯¹äºæ¨åŠ¨ç”µè·¯è®¾è®¡æ–¹æ³•çš„è¿›æ­¥è‡³å…³é‡è¦ã€‚ç„¶è€Œï¼Œå°–ç«¯ç ”ç©¶çš„è¿…é€Ÿæ¶Œå…¥ã€æ•°æ®è¡¨ç¤ºçš„ä¸ä¸€è‡´æ€§ä»¥åŠä¼˜åŒ–ç”µè·¯è®¾è®¡ç›®æ ‡çš„å¤æ‚æ€§ä½¿è¿™é¡¹ä»»åŠ¡æå…·æŒ‘æˆ˜æ€§ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†MuaLLMï¼Œè¿™æ˜¯ä¸€ä¸ªç”¨äºç”µè·¯è®¾è®¡è¾…åŠ©çš„å¼€æºå¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä»£ç†ã€‚å®ƒç»“åˆäº†æ··åˆæ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰æ¡†æ¶å’Œç”µè·¯è®¾è®¡ç ”ç©¶è®ºæ–‡çš„è‡ªé€‚åº”å‘é‡æ•°æ®åº“ã€‚ä¸ä¼ ç»Ÿçš„LLMä¸åŒï¼ŒMuaLLMä»£ç†é‡‡ç”¨Reason + Actï¼ˆReActï¼‰å·¥ä½œæµç¨‹è¿›è¡Œè¿­ä»£æ¨ç†ã€ç›®æ ‡è®¾å®šå’Œå¤šæ­¥ä¿¡æ¯æ£€ç´¢ã€‚å®ƒä½œä¸ºé—®ç­”è®¾è®¡åŠ©ç†ï¼Œèƒ½å¤Ÿè§£é‡Šå¤æ‚æŸ¥è¯¢å¹¶æä¾›åŸºäºç”µè·¯æ–‡çŒ®çš„åˆç†è§£ç­”ã€‚å®ƒçš„å¤šæ¨¡æ€åŠŸèƒ½èƒ½å¤Ÿå¤„ç†æ–‡æœ¬å’Œè§†è§‰æ•°æ®ï¼Œä¿ƒè¿›æ›´é«˜æ•ˆå’Œå…¨é¢çš„åˆ†æã€‚è¯¥ç³»ç»Ÿä½¿ç”¨æ™ºèƒ½æœç´¢å·¥å…·ã€ä»äº’è”ç½‘è‡ªåŠ¨æ£€ç´¢æ–‡æ¡£å’Œå®æ—¶æ•°æ®åº“æ›´æ–°è¿›è¡ŒåŠ¨æ€é€‚åº”ã€‚ä¸å—æ¨¡å‹ä¸Šä¸‹æ–‡é™åˆ¶çš„ä¼ ç»Ÿæ–¹æ³•ä¸åŒï¼ŒMuaLLMå°†æ£€ç´¢ä¸æ¨ç†è§£è€¦ï¼Œèƒ½å¤Ÿåœ¨ä»»æ„å¤§å‹è¯­æ–™åº“ä¸Šè¿›è¡Œå¯æ‰©å±•æ¨ç†ã€‚åœ¨æ ‡å‡†LLMæ‰€æ”¯æŒçš„æœ€å¤§ä¸Šä¸‹æ–‡é•¿åº¦ä¸‹ï¼ŒMuaLLMçš„æˆæœ¬é™ä½é«˜è¾¾10å€ï¼Œé€Ÿåº¦æé«˜1.6å€ï¼ŒåŒæ—¶ä¿æŒç›¸åŒçš„å‡†ç¡®æ€§ã€‚è¿™å…è®¸å¿«é€Ÿã€æ— éœ€äººå·¥å‚ä¸çš„æ•°æ®åº“ç”Ÿæˆï¼Œçªç ´äº†åŸºäºæ¨¡æ‹Ÿçš„æ•°æ®é›†åˆ›å»ºç“¶é¢ˆã€‚ä¸ºäº†è¯„ä¼°MuaLLMçš„æ€§èƒ½ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸¤ä¸ªè‡ªå®šä¹‰æ•°æ®é›†ï¼šRAG-250ï¼Œé’ˆå¯¹æ£€ç´¢å’Œå¼•ç”¨æ€§èƒ½ï¼›ä»¥åŠä¸“æ³¨äºç”µè·¯è®¾è®¡ä¸­çš„å¤šæ­¥éª¤æ¨ç†çš„Reasoning-100ï¼ˆReas-100ï¼‰ã€‚MuaLLMåœ¨RAG-250ä¸Šçš„å¬å›ç‡ä¸º90.1%ï¼Œåœ¨Reas-100ä¸Šçš„å‡†ç¡®ç‡ä¸º86.8%ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.08137v1">PDF</a> </p>
<p><strong>Summary</strong><br>     è®ºæ–‡æå‡ºä¸€ç§åä¸ºMuaLLMçš„å¼€æºå¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ç”µè·¯è®¾è®¡è¾…åŠ©ä»£ç†ã€‚å®ƒç»“åˆäº†æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰æ¡†æ¶å’Œç”µè·¯è®¾è®¡ç ”ç©¶è®ºæ–‡çš„è‡ªé€‚åº”å‘é‡æ•°æ®åº“ã€‚MuaLLMé‡‡ç”¨Reason + Actï¼ˆReActï¼‰å·¥ä½œæµç¨‹è¿›è¡Œè¿­ä»£æ¨ç†ã€ç›®æ ‡è®¾å®šå’Œå¤šæ­¥ä¿¡æ¯æ£€ç´¢ï¼Œå¯è§£é‡Šå¤æ‚æŸ¥è¯¢å¹¶æä¾›åŸºäºç”µè·¯è®¾è®¡æ–‡çŒ®çš„åˆç†è§£ç­”ã€‚å…¶å¤šæ¨¡æ€èƒ½åŠ›å¯å¤„ç†æ–‡æœ¬å’Œè§†è§‰æ•°æ®ï¼Œä¿ƒè¿›æ›´é«˜æ•ˆå’Œå…¨é¢çš„åˆ†æã€‚ç³»ç»Ÿå¯é€šè¿‡æ™ºèƒ½æœç´¢å·¥å…·ã€è‡ªåŠ¨åœ¨çº¿æ–‡æ¡£æ£€ç´¢å’Œå®æ—¶æ•°æ®åº“æ›´æ–°è¿›è¡ŒåŠ¨æ€é€‚åº”ã€‚ç›¸è¾ƒäºæ ‡å‡†LLMsï¼ŒMuaLLMåœ¨æœ€å¤§ä¸Šä¸‹æ–‡é•¿åº¦æ”¯æŒä¸‹ï¼Œæˆæœ¬é™ä½10å€ï¼Œé€Ÿåº¦æé«˜1.6å€ï¼ŒåŒæ—¶ä¿æŒç›¸åŒçš„å‡†ç¡®æ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>MuaLLMæ˜¯ä¸€ä¸ªå¤šæ¨¡æ€LLMä»£ç†ï¼Œç”¨äºç”µè·¯è®¾è®¡çš„è¾…åŠ©ã€‚</li>
<li>å®ƒé›†æˆäº†RAGæ¡†æ¶å’Œç”µè·¯è®¾è®¡çš„è‡ªé€‚åº”å‘é‡æ•°æ®åº“ã€‚</li>
<li>MuaLLMé‡‡ç”¨ReActå·¥ä½œæµç¨‹ï¼Œæ”¯æŒè¿­ä»£æ¨ç†ã€ç›®æ ‡è®¾å®šå’Œå¤šæ­¥ä¿¡æ¯æ£€ç´¢ã€‚</li>
<li>è¯¥ç³»ç»Ÿå…·å¤‡å¤„ç†æ–‡æœ¬å’Œè§†è§‰æ•°æ®çš„å¤šæ¨¡æ€èƒ½åŠ›ï¼Œæé«˜åˆ†ææ•ˆç‡å’Œå…¨é¢æ€§ã€‚</li>
<li>MuaLLMé€šè¿‡æ™ºèƒ½æœç´¢å·¥å…·ã€è‡ªåŠ¨åœ¨çº¿æ–‡æ¡£æ£€ç´¢å’Œå®æ—¶æ•°æ®åº“æ›´æ–°è¿›è¡ŒåŠ¨æ€é€‚åº”ã€‚</li>
<li>MuaLLMåœ¨æ ‡å‡†ä¸Šä¸‹æ–‡é•¿åº¦ä¸‹çš„æ€§èƒ½è¡¨ç°ä¼˜è¶Šï¼Œç›¸è¾ƒäºä¼ ç»ŸLLMsæˆæœ¬æ›´ä½ã€é€Ÿåº¦æ›´å¿«ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.08137">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-db2f43cfe5fb81ad144979452f25803b.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-86542e5321101efa41b5c18faeae1b89.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-571423ca80f3e9830f2a43dc1f83e934.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-c177c1b6dfb301c5faa834c3f7437e6a.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="BlindGuard-Safeguarding-LLM-based-Multi-Agent-Systems-under-Unknown-Attacks"><a href="#BlindGuard-Safeguarding-LLM-based-Multi-Agent-Systems-under-Unknown-Attacks" class="headerlink" title="BlindGuard: Safeguarding LLM-based Multi-Agent Systems under Unknown   Attacks"></a>BlindGuard: Safeguarding LLM-based Multi-Agent Systems under Unknown   Attacks</h2><p><strong>Authors:Rui Miao, Yixin Liu, Yili Wang, Xu Shen, Yue Tan, Yiwei Dai, Shirui Pan, Xin Wang</strong></p>
<p>The security of LLM-based multi-agent systems (MAS) is critically threatened by propagation vulnerability, where malicious agents can distort collective decision-making through inter-agent message interactions. While existing supervised defense methods demonstrate promising performance, they may be impractical in real-world scenarios due to their heavy reliance on labeled malicious agents to train a supervised malicious detection model. To enable practical and generalizable MAS defenses, in this paper, we propose BlindGuard, an unsupervised defense method that learns without requiring any attack-specific labels or prior knowledge of malicious behaviors. To this end, we establish a hierarchical agent encoder to capture individual, neighborhood, and global interaction patterns of each agent, providing a comprehensive understanding for malicious agent detection. Meanwhile, we design a corruption-guided detector that consists of directional noise injection and contrastive learning, allowing effective detection model training solely on normal agent behaviors. Extensive experiments show that BlindGuard effectively detects diverse attack types (i.e., prompt injection, memory poisoning, and tool attack) across MAS with various communication patterns while maintaining superior generalizability compared to supervised baselines. The code is available at: <a target="_blank" rel="noopener" href="https://github.com/MR9812/BlindGuard">https://github.com/MR9812/BlindGuard</a>. </p>
<blockquote>
<p>åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„å¤šæ™ºèƒ½ä½“ç³»ç»Ÿï¼ˆMASï¼‰çš„å®‰å…¨æ€§å—åˆ°ä¼ æ’­æ¼æ´çš„ä¸¥é‡å¨èƒï¼Œæ¶æ„æ™ºèƒ½ä½“å¯ä»¥é€šè¿‡æ™ºèƒ½ä½“ä¹‹é—´çš„æ¶ˆæ¯äº¤äº’æ‰­æ›²é›†ä½“å†³ç­–ã€‚è™½ç„¶ç°æœ‰çš„ç›‘ç£é˜²å¾¡æ–¹æ³•è¡¨ç°å‡ºæœ‰å‰æ™¯çš„æ€§èƒ½ï¼Œä½†ç”±äºå®ƒä»¬ä¸¥é‡ä¾èµ–äºå¸¦æœ‰æ ‡ç­¾çš„æ¶æ„æ™ºèƒ½ä½“æ¥è®­ç»ƒç›‘ç£æ¶æ„æ£€æµ‹æ¨¡å‹ï¼Œå› æ­¤åœ¨ç°å®åœºæ™¯ä¸­å¯èƒ½ä¸åˆ‡å®é™…ã€‚ä¸ºäº†å®ç°å¯¹å®é™…å’Œå¯æ¨å¹¿çš„MASé˜²å¾¡ï¼Œæœ¬æ–‡æå‡ºäº†BlindGuardï¼Œè¿™æ˜¯ä¸€ç§æ— éœ€ä»»ä½•é’ˆå¯¹æ”»å‡»çš„ç‰¹å®šæ ‡ç­¾æˆ–å…³äºæ¶æ„è¡Œä¸ºçš„å…ˆéªŒçŸ¥è¯†çš„æ— ç›‘ç£é˜²å¾¡æ–¹æ³•ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬å»ºç«‹äº†ä¸€ä¸ªåˆ†å±‚æ™ºèƒ½ä½“ç¼–ç å™¨æ¥æ•æ‰æ¯ä¸ªæ™ºèƒ½ä½“çš„ä¸ªä½“ã€é‚»è¿‘å’Œå…¨å±€äº¤äº’æ¨¡å¼ï¼Œä¸ºæ¶æ„æ™ºèƒ½ä½“æ£€æµ‹æä¾›å…¨é¢çš„ç†è§£ã€‚åŒæ—¶ï¼Œæˆ‘ä»¬è®¾è®¡äº†ä¸€ä¸ªç”±è…è´¥å¼•å¯¼çš„æ£€æµ‹å™¨ï¼Œå®ƒç”±å®šå‘å™ªå£°æ³¨å…¥å’Œå¯¹æ¯”å­¦ä¹ ç»„æˆï¼Œå…è®¸ä»…åœ¨æ­£å¸¸æ™ºèƒ½ä½“è¡Œä¸ºä¸Šæœ‰æ•ˆåœ°è®­ç»ƒæ£€æµ‹æ¨¡å‹ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼ŒBlindGuardåœ¨å…·æœ‰å„ç§é€šä¿¡æ¨¡å¼çš„å¤šæ™ºèƒ½ä½“ç³»ç»Ÿä¸­æœ‰æ•ˆåœ°æ£€æµ‹äº†å„ç§æ”»å‡»ç±»å‹ï¼ˆå³æç¤ºæ³¨å…¥ã€å†…å­˜ä¸­æ¯’å’Œå·¥å…·æ”»å‡»ï¼‰ï¼ŒåŒæ—¶åœ¨ä¿æŒä¼˜è¶Šæ€§çš„åŒæ—¶ä¸ç›‘ç£åŸºçº¿ç›¸æ¯”å…·æœ‰æ›´å¥½çš„æ³›åŒ–èƒ½åŠ›ã€‚ä»£ç å¯åœ¨ä»¥ä¸‹ç½‘å€æ‰¾åˆ°ï¼š<a target="_blank" rel="noopener" href="https://github.com/MR9812/BlindGuard">https://github.com/MR9812/BlindGuard</a>ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.08127v1">PDF</a> </p>
<p><strong>Summary</strong><br>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä¸ºåŸºç¡€çš„å¤šæ™ºèƒ½ä½“ç³»ç»Ÿï¼ˆMASï¼‰å®‰å…¨æ€§å—åˆ°ä¼ æ’­æ¼æ´çš„ä¸¥é‡å¨èƒï¼Œæ¶æ„æ™ºèƒ½ä½“å¯ä»¥é€šè¿‡æ™ºèƒ½ä½“ä¹‹é—´çš„æ¶ˆæ¯äº¤äº’æ‰­æ›²é›†ä½“å†³ç­–ã€‚ç°æœ‰ç›‘ç£é˜²å¾¡æ–¹æ³•è™½ç„¶è¡¨ç°è‰¯å¥½ï¼Œä½†ç”±äºå®ƒä»¬ä¸¥é‡ä¾èµ–äºæ ‡è®°æ¶æ„æ™ºèƒ½ä½“æ¥è®­ç»ƒç›‘ç£æ¶æ„æ£€æµ‹æ¨¡å‹ï¼Œå› æ­¤åœ¨ç°å®åœºæ™¯ä¸­å¯èƒ½ä¸åˆ‡å®é™…ã€‚ä¸ºè§£å†³è¿™ä¸€é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºä¸€ç§åä¸ºBlindGuardçš„æ— ç›‘ç£é˜²å¾¡æ–¹æ³•ï¼Œè¯¥æ–¹æ³•æ— éœ€ä»»ä½•æ”»å‡»ç‰¹å®šæ ‡ç­¾æˆ–æ¶æ„è¡Œä¸ºçš„å…ˆéªŒçŸ¥è¯†å³å¯è¿›è¡Œå­¦ä¹ ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬å»ºç«‹äº†ä¸€ä¸ªåˆ†å±‚æ™ºèƒ½ä½“ç¼–ç å™¨æ¥æ•æ‰å•ä¸ªæ™ºèƒ½ä½“ã€é‚»å±…æ™ºèƒ½ä½“å’Œå…¨å±€æ™ºèƒ½ä½“çš„äº¤äº’æ¨¡å¼ï¼Œä¸ºæ¶æ„æ™ºèƒ½ä½“æ£€æµ‹æä¾›å…¨é¢çš„ç†è§£ã€‚åŒæ—¶ï¼Œæˆ‘ä»¬è®¾è®¡äº†ä¸€ç§ç”±è…è´¥å¼•å¯¼çš„æ¢æµ‹å™¨ï¼Œå®ƒç”±å®šå‘å™ªå£°æ³¨å…¥å’Œå¯¹æ¯”å­¦ä¹ ç»„æˆï¼Œèƒ½å¤Ÿåœ¨ä»…ä½¿ç”¨æ­£å¸¸æ™ºèƒ½ä½“è¡Œä¸ºçš„æƒ…å†µä¸‹è¿›è¡Œæœ‰æ•ˆè®­ç»ƒã€‚å®éªŒè¡¨æ˜ï¼ŒBlindGuardèƒ½å¤Ÿæ£€æµ‹åˆ°å¤šæ ·åŒ–çš„æ”»å‡»ç±»å‹å¹¶ä¿æŒè‰¯å¥½çš„æ³›åŒ–æ€§èƒ½ã€‚<br>ä»£ç åœ°å€ï¼š<a target="_blank" rel="noopener" href="https://github.com/MR9812/BlindGuard">https://github.com/MR9812/BlindGuard</a>ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>LLM-based MASé¢ä¸´ä¼ æ’­æ¼æ´é—®é¢˜ï¼Œæ¶æ„æ™ºèƒ½ä½“èƒ½å¹²æ‰°é›†ä½“å†³ç­–ã€‚</li>
<li>å½“å‰ç›‘ç£é˜²å¾¡æ–¹æ³•è¿‡äºä¾èµ–æ ‡ç­¾æ•°æ®ï¼Œå®é™…éƒ¨ç½²å¯èƒ½ä¸å®ç”¨ã€‚</li>
<li>BlindGuardä½œä¸ºä¸€ç§æ— ç›‘ç£æ–¹æ³•è¢«æå‡ºï¼Œæ— éœ€æ”»å‡»ç‰¹å®šæ ‡ç­¾æˆ–æ¶æ„è¡Œä¸ºçš„å…ˆéªŒçŸ¥è¯†ã€‚</li>
<li>BlindGuardé€šè¿‡åˆ†å±‚æ™ºèƒ½ä½“ç¼–ç å™¨æ•æ‰ä¸ªä½“åŠç¾¤ä½“äº¤äº’æ¨¡å¼æ¥æ£€æµ‹æ¶æ„æ™ºèƒ½ä½“ã€‚</li>
<li>BlindGuardé‡‡ç”¨ç”±è…è´¥å¼•å¯¼çš„æ¢æµ‹å™¨ï¼Œç»“åˆå®šå‘å™ªå£°æ³¨å…¥å’Œå¯¹æ¯”å­¦ä¹ æŠ€æœ¯ã€‚</li>
<li>BlindGuardèƒ½å¤Ÿæœ‰æ•ˆæ£€æµ‹å¤šç§æ”»å‡»ç±»å‹ï¼ŒåŒ…æ‹¬æç¤ºæ³¨å…¥ã€å†…å­˜ä¸­æ¯’å’Œå·¥å…·æ”»å‡»ç­‰ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.08127">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-699b1b8fd8c0d2c695ba81073a90dd11.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-db78fbfa4503912c803c0c7eb27bd571.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-7c85e81424722608b9347b548016824d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-950b672b69dc99eb45f5f189eb9ab1cc.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="WideSearch-Benchmarking-Agentic-Broad-Info-Seeking"><a href="#WideSearch-Benchmarking-Agentic-Broad-Info-Seeking" class="headerlink" title="WideSearch: Benchmarking Agentic Broad Info-Seeking"></a>WideSearch: Benchmarking Agentic Broad Info-Seeking</h2><p><strong>Authors:Ryan Wong, Jiawei Wang, Junjie Zhao, Li Chen, Yan Gao, Long Zhang, Xuan Zhou, Zuo Wang, Kai Xiang, Ge Zhang, Wenhao Huang, Yang Wang, Ke Wang</strong></p>
<p>From professional research to everyday planning, many tasks are bottlenecked by wide-scale information seeking, which is more repetitive than cognitively complex. With the rapid development of Large Language Models (LLMs), automated search agents powered by LLMs offer a promising solution to liberate humans from this tedious work. However, the capability of these agents to perform such â€œwide-contextâ€ collection reliably and completely remains largely unevaluated due to a lack of suitable benchmarks. To bridge this gap, we introduce WideSearch, a new benchmark engineered to evaluate agent reliability on these large-scale collection tasks. The benchmark features 200 manually curated questions (100 in English, 100 in Chinese) from over 15 diverse domains, grounded in real user queries. Each task requires agents to collect large-scale atomic information, which could be verified one by one objectively, and arrange it into a well-organized output. A rigorous five-stage quality control pipeline ensures the difficulty, completeness, and verifiability of the dataset. We benchmark over 10 state-of-the-art agentic search systems, including single-agent, multi-agent frameworks, and end-to-end commercial systems. Most systems achieve overall success rates near 0%, with the best performer reaching just 5%. However, given sufficient time, cross-validation by multiple human testers can achieve a near 100% success rate. These results demonstrate that present search agents have critical deficiencies in large-scale information seeking, underscoring urgent areas for future research and development in agentic search. Our dataset, evaluation pipeline, and benchmark results have been publicly released at <a target="_blank" rel="noopener" href="https://widesearch-seed.github.io/">https://widesearch-seed.github.io/</a> </p>
<blockquote>
<p>ä»ä¸“ä¸šç ”ç©¶åˆ°æ—¥å¸¸è§„åˆ’ï¼Œè®¸å¤šä»»åŠ¡éƒ½è¢«å¤§è§„æ¨¡çš„ä¿¡æ¯æœç´¢æ‰€é™åˆ¶ï¼Œè€Œè¿™é¡¹å·¥ä½œæ›´å…·é‡å¤æ€§è€Œéè®¤çŸ¥å¤æ‚æ€§ã€‚éšç€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„å¿«é€Ÿå‘å±•ï¼Œç”±LLMsé©±åŠ¨çš„è‡ªåŠ¨åŒ–æœç´¢ä»£ç†äººä¸ºäººç±»æ‘†è„±è¿™ç§æ¯ç‡¥çš„å·¥ä½œæä¾›äº†æœ‰å¸Œæœ›çš„è§£å†³æ–¹æ¡ˆã€‚ç„¶è€Œï¼Œè¿™äº›ä»£ç†äººåœ¨æ‰§è¡Œè¿™ç§å¤§è§„æ¨¡ä¸Šä¸‹æ–‡ä¿¡æ¯å¯é æ”¶é›†æ–¹é¢çš„èƒ½åŠ›åœ¨å¾ˆå¤§ç¨‹åº¦ä¸Šå°šæœªå¾—åˆ°è¯„ä¼°ï¼Œè¿™ä¸»è¦æ˜¯ç”±äºç¼ºä¹åˆé€‚çš„åŸºå‡†æµ‹è¯•ã€‚ä¸ºäº†å¼¥è¡¥è¿™ä¸€å·®è·ï¼Œæˆ‘ä»¬å¼•å…¥äº†WideSearchåŸºå‡†æµ‹è¯•ï¼Œè¯¥åŸºå‡†æµ‹è¯•æ—¨åœ¨è¯„ä¼°ä»£ç†äººåœ¨è¿™äº›å¤§è§„æ¨¡æ”¶é›†ä»»åŠ¡ä¸Šçš„å¯é æ€§ã€‚è¯¥åŸºå‡†æµ‹è¯•åŒ…å«200ä¸ªç»è¿‡äººå·¥æ•´ç†çš„é—®é¢˜ï¼ˆè‹±è¯­100ä¸ªï¼Œä¸­æ–‡100ä¸ªï¼‰ï¼Œæ¶µç›–è¶…è¿‡15ä¸ªä¸åŒé¢†åŸŸï¼ŒåŸºäºçœŸå®ç”¨æˆ·æŸ¥è¯¢ã€‚æ¯ä¸ªä»»åŠ¡è¦æ±‚ä»£ç†äººæ”¶é›†å¤§è§„æ¨¡åŸå­ä¿¡æ¯ï¼Œè¿™äº›ä¿¡æ¯å¯ä»¥å®¢è§‚é€ä¸€éªŒè¯ï¼Œå¹¶å°†å…¶æ•´ç†æˆç»„ç»‡è‰¯å¥½çš„è¾“å‡ºã€‚ä¸€ä¸ªä¸¥æ ¼çš„äº”é˜¶æ®µè´¨é‡æ§åˆ¶æµç¨‹ç¡®ä¿äº†æ•°æ®é›†çš„éš¾åº¦ã€å®Œæ•´æ€§å’Œå¯éªŒè¯æ€§ã€‚æˆ‘ä»¬å¯¹è¶…è¿‡10ç§å…ˆè¿›çš„ä»£ç†æœç´¢ç³»ç»Ÿè¿›è¡Œäº†åŸºå‡†æµ‹è¯•ï¼ŒåŒ…æ‹¬å•ä»£ç†ã€å¤šä»£ç†æ¡†æ¶å’Œç«¯åˆ°ç«¯çš„å•†ä¸šç³»ç»Ÿã€‚å¤§å¤šæ•°ç³»ç»Ÿçš„æ€»ä½“æˆåŠŸç‡æ¥è¿‘0%ï¼Œè¡¨ç°æœ€å¥½çš„ä¹Ÿåªæœ‰5%ã€‚ç„¶è€Œï¼Œç»™è¶³å¤Ÿçš„æ—¶é—´å¹¶é€šè¿‡å¤šä¸ªäººç±»æµ‹è¯•è€…è¿›è¡Œäº¤å‰éªŒè¯å¯ä»¥è¾¾åˆ°æ¥è¿‘ç™¾åˆ†ä¹‹ç™¾çš„æˆåŠŸç‡ã€‚è¿™äº›ç»“æœè¡¨æ˜ï¼Œç›®å‰çš„æœç´¢ä»£ç†åœ¨å¤§è§„æ¨¡ä¿¡æ¯æœç´¢æ–¹é¢å­˜åœ¨é‡å¤§ç¼ºé™·ï¼Œå¼ºè°ƒäº†æœªæ¥å¯¹ä»£ç†æœç´¢ç ”ç©¶å’Œå‘å±•çš„è¿«åˆ‡éœ€æ±‚ã€‚æˆ‘ä»¬çš„æ•°æ®é›†ã€è¯„ä¼°æµç¨‹å’ŒåŸºå‡†æµ‹è¯•ç»“æœå·²åœ¨<a target="_blank" rel="noopener" href="https://widesearch-seed.github.io/%E5%85%AC%E5%BC%80%E5%8F%91%E5%B8%83%E3%80%82">https://widesearch-seed.github.io/å…¬å¼€å‘å¸ƒã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.07999v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>è¯¥æ–‡æœ¬ä»‹ç»äº†éšç€è‡ªç„¶è¯­è¨€å¤„ç†æŠ€æœ¯çš„ä¸æ–­å‘å±•ï¼Œç‰¹åˆ«æ˜¯å¤§å‹è¯­è¨€æ¨¡å‹çš„åº”ç”¨ï¼Œä¿¡æ¯æœç´¢å˜å¾—è¶Šæ¥è¶Šæ™ºèƒ½åŒ–ã€‚æ–‡ç« é’ˆå¯¹ä¿¡æ¯æ£€ç´¢çš„ç°çŠ¶å’ŒæŒ‘æˆ˜ï¼Œæå‡ºäº†ä¸€ä¸ªåä¸ºWideSearchçš„æ–°åŸºå‡†æµ‹è¯•é›†ï¼Œæ—¨åœ¨è¯„ä¼°è‡ªåŠ¨åŒ–æœç´¢ä»£ç†åœ¨å¤§è§„æ¨¡ä¿¡æ¯æ£€ç´¢ä»»åŠ¡ä¸­çš„å¯é æ€§ã€‚å°½ç®¡ç°æœ‰ç³»ç»Ÿåœ¨åŸºå‡†æµ‹è¯•ä¸­çš„è¡¨ç°ä¸å°½å¦‚äººæ„ï¼Œä½†æ–‡ç« å¼ºè°ƒäº†æœªæ¥ç ”ç©¶å’Œå¼€å‘çš„é‡è¦æ€§å’Œè¿«åˆ‡æ€§ã€‚åŒæ—¶ï¼Œæ–‡ç« è¿˜å…¬å¼€äº†æ•°æ®é›†å’Œè¯„ä¼°æµç¨‹ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤§å‹è¯­è¨€æ¨¡å‹åœ¨ä¿¡æ¯æ£€ç´¢é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ã€‚</li>
<li>WideSearchæ˜¯ä¸€ä¸ªæ–°çš„åŸºå‡†æµ‹è¯•é›†ï¼Œæ—¨åœ¨è¯„ä¼°è‡ªåŠ¨åŒ–æœç´¢ä»£ç†åœ¨å¤§è§„æ¨¡ä¿¡æ¯æ£€ç´¢ä»»åŠ¡ä¸­çš„å¯é æ€§ã€‚</li>
<li>WideSearchåŒ…å«200ä¸ªæ‰‹å·¥æ•´ç†çš„é—®é¢˜ï¼Œæ¶µç›–å¤šä¸ªé¢†åŸŸï¼Œæ¨¡ä»¿çœŸå®ç”¨æˆ·æŸ¥è¯¢ã€‚</li>
<li>ç°æœ‰è‡ªåŠ¨åŒ–æœç´¢ä»£ç†åœ¨å¤§è§„æ¨¡ä¿¡æ¯æ£€ç´¢ä»»åŠ¡ä¸­çš„è¡¨ç°å­˜åœ¨ä¸¥é‡ä¸è¶³ã€‚</li>
<li>è‡ªåŠ¨åŒ–æœç´¢ä»£ç†çš„æˆåŠŸç‡æ™®éè¾ƒä½ï¼Œä½†äººç±»æµ‹è¯•è€…é€šè¿‡äº¤å‰éªŒè¯å¯ä»¥è¾¾åˆ°è¿‘100%çš„æˆåŠŸç‡ã€‚</li>
<li>æ–‡ç« å¼ºè°ƒäº†æœªæ¥åœ¨è‡ªåŠ¨åŒ–æœç´¢ä»£ç†é¢†åŸŸçš„ç ”ç©¶å’Œå¼€å‘çš„é‡è¦æ€§å’Œè¿«åˆ‡æ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.07999">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-11d931ee49baca779adb73b0c062ae99.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-6dab8d6d4e31c9756426c9d1dee63d58.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f432e56aa1f8c1ca1bba4f4910c27150.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b13867995d068cd35b83fff0e80cbcec.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="Beyond-Ten-Turns-Unlocking-Long-Horizon-Agentic-Search-with-Large-Scale-Asynchronous-RL"><a href="#Beyond-Ten-Turns-Unlocking-Long-Horizon-Agentic-Search-with-Large-Scale-Asynchronous-RL" class="headerlink" title="Beyond Ten Turns: Unlocking Long-Horizon Agentic Search with Large-Scale   Asynchronous RL"></a>Beyond Ten Turns: Unlocking Long-Horizon Agentic Search with Large-Scale   Asynchronous RL</h2><p><strong>Authors:Jiaxuan Gao, Wei Fu, Minyang Xie, Shusheng Xu, Chuyi He, Zhiyu Mei, Banghua Zhu, Yi Wu</strong></p>
<p>Recent advancements in LLM-based agents have demonstrated remarkable capabilities in handling complex, knowledge-intensive tasks by integrating external tools. Among diverse choices of tools, search tools play a pivotal role in accessing vast external knowledge. However, open-source agents still fall short of achieving expert-level Search Intelligence, the ability to resolve ambiguous queries, generate precise searches, analyze results, and conduct thorough exploration. Existing approaches fall short in scalability, efficiency, and data quality. For example, small turn limits in existing online RL methods, e.g. &lt;&#x3D;10, restrict complex strategy learning. This paper introduces ASearcher, an open-source project for large-scale RL training of search agents. Our key contributions include: (1) Scalable fully asynchronous RL training that enables long-horizon search while maintaining high training efficiency. (2) A prompt-based LLM agent that autonomously synthesizes high-quality and challenging QAs, creating a large-scale QA dataset. Through RL training, our prompt-based QwQ-32B agent achieves substantial improvements, with 46.7% and 20.8% Avg@4 gains on xBench and GAIA, respectively. Notably, our agent exhibits extreme long-horizon search, with tool calls exceeding 40 turns and output tokens exceeding 150k during training time. With a simple agent design and no external LLMs, ASearcher-Web-QwQ achieves Avg@4 scores of 42.1 on xBench and 52.8 on GAIA, surpassing existing open-source 32B agents. We open-source our models, training data, and codes in <a target="_blank" rel="noopener" href="https://github.com/inclusionAI/ASearcher">https://github.com/inclusionAI/ASearcher</a>. </p>
<blockquote>
<p>æœ€è¿‘åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„ä»£ç†äººçš„è¿›å±•ï¼Œé€šè¿‡æ•´åˆå¤–éƒ¨å·¥å…·ï¼Œåœ¨å¤„ç†å¤æ‚ã€çŸ¥è¯†å¯†é›†å‹ä»»åŠ¡æ–¹é¢è¡¨ç°å‡ºäº†æ˜¾è‘—çš„èƒ½åŠ›ã€‚åœ¨å¤šç§å·¥å…·é€‰æ‹©ä¸­ï¼Œæœç´¢å·¥å…·åœ¨è®¿é—®å¤§é‡å¤–éƒ¨çŸ¥è¯†æ–¹é¢å‘æŒ¥ç€è‡³å…³é‡è¦çš„ä½œç”¨ã€‚ç„¶è€Œï¼Œå¼€æºä»£ç†äººä»æœªèƒ½å®ç°ä¸“å®¶çº§çš„æœç´¢æ™ºèƒ½ï¼ˆSearch Intelligenceï¼‰ï¼Œå³è§£å†³æ¨¡ç³ŠæŸ¥è¯¢ã€è¿›è¡Œç²¾ç¡®æœç´¢ã€åˆ†æç»“æœä»¥åŠè¿›è¡Œå…¨é¢æ¢ç´¢çš„èƒ½åŠ›ã€‚ç°æœ‰æ–¹æ³•åœ¨å¯æ‰©å±•æ€§ã€æ•ˆç‡å’Œæ•°æ®è´¨é‡æ–¹é¢å­˜åœ¨ä¸è¶³ã€‚ä¾‹å¦‚ï¼Œç°æœ‰åœ¨çº¿å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰æ–¹æ³•çš„å°å›åˆé™åˆ¶ï¼ˆä¾‹å¦‚&lt;&#x3D;10ï¼‰ï¼Œé™åˆ¶äº†å¤æ‚ç­–ç•¥çš„å­¦ä¹ ã€‚æœ¬æ–‡ä»‹ç»äº†ASearcherï¼Œè¿™æ˜¯ä¸€ä¸ªç”¨äºå¤§è§„æ¨¡RLè®­ç»ƒæœç´¢ä»£ç†çš„å¼€æºé¡¹ç›®ã€‚æˆ‘ä»¬çš„ä¸»è¦è´¡çŒ®åŒ…æ‹¬ï¼šï¼ˆ1ï¼‰å¯æ‰©å±•çš„å®Œå…¨å¼‚æ­¥RLè®­ç»ƒï¼Œèƒ½å¤Ÿåœ¨ç»´æŒé«˜è®­ç»ƒæ•ˆç‡çš„åŒæ—¶å®ç°é•¿æœŸæœç´¢ã€‚ï¼ˆ2ï¼‰åŸºäºæç¤ºçš„å¤§å‹è¯­è¨€æ¨¡å‹ä»£ç†äººèƒ½å¤Ÿè‡ªä¸»åˆæˆé«˜è´¨é‡ã€å…·æœ‰æŒ‘æˆ˜æ€§çš„é—®ç­”ï¼Œåˆ›å»ºå¤§è§„æ¨¡é—®ç­”æ•°æ®é›†ã€‚é€šè¿‡å¼ºåŒ–å­¦ä¹ è®­ç»ƒï¼Œæˆ‘ä»¬çš„åŸºäºæç¤ºçš„QwQ-32Bä»£ç†äººå–å¾—äº†æ˜¾è‘—æ”¹è¿›ï¼Œåœ¨xBenchå’ŒGAIAä¸Šåˆ†åˆ«å®ç°äº†46.7%å’Œ20.8%çš„Avg@4å¢ç›Šã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œæˆ‘ä»¬çš„ä»£ç†äººå±•ç¤ºäº†æç«¯çš„é•¿æœŸæœç´¢ï¼Œåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­çš„å·¥å…·è°ƒç”¨è¶…è¿‡40å›åˆï¼Œè¾“å‡ºä»¤ç‰Œè¶…è¿‡15ä¸‡ã€‚é€šè¿‡ç®€å•çš„ä»£ç†äººè®¾è®¡å’Œä¸ä½¿ç”¨å¤–éƒ¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ŒASearcher-Web-QwQåœ¨xBenchä¸Šå®ç°äº†Avg@4å¾—åˆ†42.1ï¼Œåœ¨GAIAä¸Šå®ç°äº†52.8ï¼Œè¶…è¶Šäº†ç°æœ‰çš„å¼€æº32Bä»£ç†äººã€‚æˆ‘ä»¬åœ¨<a target="_blank" rel="noopener" href="https://github.com/inclusionAI/ASearcher%E5%85%AC%E5%BC%80%E6%88%91%E4%BB%AC%E7%9A%84%E6%A8%A1%E5%9E%8B%E3%80%81%E8%AE%AD%E7%BB%83%E6%95%B0%E6%8D%AE%E5%92%8C%E4%BB%A3%E7%A0%81%E3%80%82">https://github.com/inclusionAI/ASearcherå…¬å¼€æˆ‘ä»¬çš„æ¨¡å‹ã€è®­ç»ƒæ•°æ®å’Œä»£ç ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.07976v1">PDF</a> </p>
<p><strong>æ‘˜è¦</strong></p>
<p>è¿‘æœŸLLMï¼ˆå¤§å‹é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹ï¼‰åŸºäºçš„ä»£ç†æŠ€æœ¯è¿›å±•æ˜¾è‘—ï¼Œé€šè¿‡é›†æˆå¤–éƒ¨å·¥å…·å¤„ç†å¤æ‚ã€çŸ¥è¯†å¯†é›†å‹ä»»åŠ¡çš„èƒ½åŠ›å¾—åˆ°äº†æå‡ã€‚æœç´¢å·¥å…·åœ¨è®¿é—®æµ·é‡å¤–éƒ¨çŸ¥è¯†ä¸­å‘æŒ¥ç€å…³é”®ä½œç”¨ï¼Œä½†å¼€æºä»£ç†å°šæœªå®ç°ä¸“å®¶çº§çš„æœç´¢æ™ºèƒ½ï¼Œå³åœ¨è§£å†³æ¨¡ç³ŠæŸ¥è¯¢ã€ç”Ÿæˆç²¾ç¡®æœç´¢ã€åˆ†æç»“æœå’Œå…¨é¢æ¢ç´¢æ–¹é¢çš„èƒ½åŠ›ã€‚ç°æœ‰æ–¹æ³•å­˜åœ¨å¯æ‰©å±•æ€§ã€æ•ˆç‡å’Œæ•°æ®è´¨é‡æ–¹é¢çš„ä¸è¶³ã€‚æœ¬æ–‡ä»‹ç»äº†ä¸€ä¸ªç”¨äºå¤§è§„æ¨¡å¼ºåŒ–å­¦ä¹ è®­ç»ƒæœç´¢ä»£ç†çš„å¼€æºé¡¹ç›®ASearcherã€‚ä¸»è¦è´¡çŒ®åŒ…æ‹¬ï¼šä¸€æ˜¯å¯æ‰©å±•çš„å®Œå…¨å¼‚æ­¥å¼ºåŒ–å­¦ä¹ è®­ç»ƒï¼Œèƒ½å¤Ÿåœ¨ç»´æŒé«˜æ•ˆç‡çš„åŒæ—¶è¿›è¡Œé•¿æœŸæœç´¢ï¼›äºŒæ˜¯åŸºäºæç¤ºçš„LLMä»£ç†èƒ½å¤Ÿè‡ªä¸»åˆæˆé«˜è´¨é‡ã€æœ‰æŒ‘æˆ˜çš„QAï¼ˆé—®ç­”ï¼‰ï¼Œåˆ›å»ºå¤§è§„æ¨¡QAæ•°æ®é›†ã€‚é€šè¿‡å¼ºåŒ–å­¦ä¹ è®­ç»ƒï¼Œæˆ‘ä»¬çš„åŸºäºæç¤ºçš„QwQ-32Bä»£ç†åœ¨xBenchå’ŒGAIAä¸Šåˆ†åˆ«å®ç°äº†46.7%å’Œ20.8%çš„Avg@4å¢ç›Šã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œæˆ‘ä»¬çš„ä»£ç†å±•ç°äº†æç«¯é•¿æœŸæœç´¢ï¼Œè®­ç»ƒè¿‡ç¨‹ä¸­çš„å·¥å…·è°ƒç”¨è¶…è¿‡40è½®ï¼Œè¾“å‡ºä»¤ç‰Œè¶…è¿‡150kã€‚é‡‡ç”¨ç®€å•çš„ä»£ç†è®¾è®¡å’Œä¸ä½¿ç”¨å¤–éƒ¨LLMsï¼ŒASearcher-Web-QwQåœ¨xBenchå’ŒGAIAä¸Šå®ç°äº†Avg@4åˆ†æ•°åˆ†åˆ«ä¸º42.1å’Œ52.8ï¼Œè¶…è¶Šäº†ç°æœ‰çš„å¼€æº32Bä»£ç†ã€‚æˆ‘ä»¬çš„æ¨¡å‹ã€è®­ç»ƒæ•°æ®å’Œä»£ç å·²å…¬å¼€åœ¨<a target="_blank" rel="noopener" href="https://github.com/inclusionAI/ASearcher%E3%80%82">https://github.com/inclusionAI/ASearcherã€‚</a></p>
<p><strong>å…³é”®è§è§£</strong></p>
<ol>
<li>LLM-basedä»£ç†é€šè¿‡é›†æˆå¤–éƒ¨å·¥å…·å¤„ç†å¤æ‚ã€çŸ¥è¯†å¯†é›†å‹ä»»åŠ¡çš„èƒ½åŠ›å¾—åˆ°äº†å¢å¼ºã€‚</li>
<li>æœç´¢å·¥å…·åœ¨è®¿é—®å¤–éƒ¨çŸ¥è¯†ä¸­èµ·åˆ°å…³é”®ä½œç”¨ï¼Œä½†å¼€æºä»£ç†åœ¨æœç´¢æ™ºèƒ½æ–¹é¢ä»æœ‰æ‰€ä¸è¶³ã€‚</li>
<li>ASearcheré¡¹ç›®é€šè¿‡å¼ºåŒ–å­¦ä¹ è®­ç»ƒæé«˜äº†æœç´¢ä»£ç†çš„å¯æ‰©å±•æ€§å’Œæ•ˆç‡ã€‚</li>
<li>åŸºäºæç¤ºçš„LLMä»£ç†èƒ½å¤Ÿè‡ªä¸»åˆæˆé«˜è´¨é‡é—®ç­”ï¼Œåˆ›å»ºå¤§è§„æ¨¡QAæ•°æ®é›†ã€‚</li>
<li>QwQ-32Bä»£ç†é€šè¿‡å¼ºåŒ–å­¦ä¹ è®­ç»ƒåœ¨æ€§èƒ½ä¸Šå®ç°äº†æ˜¾è‘—çš„æå‡ã€‚</li>
<li>ASearcherä»£ç†å±•ç°äº†æç«¯é•¿æœŸæœç´¢çš„èƒ½åŠ›ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.07976">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-6a4cb248d903cc37b829af4020f2f7ea.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c836bbede69c8863e7b4fbacbf3545ea.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-760778ade6cb934839ce86ea2ff26424.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="FEAT-A-Multi-Agent-Forensic-AI-System-with-Domain-Adapted-Large-Language-Model-for-Automated-Cause-of-Death-Analysis"><a href="#FEAT-A-Multi-Agent-Forensic-AI-System-with-Domain-Adapted-Large-Language-Model-for-Automated-Cause-of-Death-Analysis" class="headerlink" title="FEAT: A Multi-Agent Forensic AI System with Domain-Adapted Large   Language Model for Automated Cause-of-Death Analysis"></a>FEAT: A Multi-Agent Forensic AI System with Domain-Adapted Large   Language Model for Automated Cause-of-Death Analysis</h2><p><strong>Authors:Chen Shen, Wanqing Zhang, Kehan Li, Erwen Huang, Haitao Bi, Aiying Fan, Yiwen Shen, Hongmei Dong, Ji Zhang, Yuming Shao, Zengjia Liu, Xinshe Liu, Tao Li, Chunxia Yan, Shuanliang Fan, Di Wu, Jianhua Ma, Bin Cong, Zhenyuan Wang, Chunfeng Lian</strong></p>
<p>Forensic cause-of-death determination faces systemic challenges, including workforce shortages and diagnostic variability, particularly in high-volume systems like Chinaâ€™s medicolegal infrastructure. We introduce FEAT (ForEnsic AgenT), a multi-agent AI framework that automates and standardizes death investigations through a domain-adapted large language model. FEATâ€™s application-oriented architecture integrates: (i) a central Planner for task decomposition, (ii) specialized Local Solvers for evidence analysis, (iii) a Memory &amp; Reflection module for iterative refinement, and (iv) a Global Solver for conclusion synthesis. The system employs tool-augmented reasoning, hierarchical retrieval-augmented generation, forensic-tuned LLMs, and human-in-the-loop feedback to ensure legal and medical validity. In evaluations across diverse Chinese case cohorts, FEAT outperformed state-of-the-art AI systems in both long-form autopsy analyses and concise cause-of-death conclusions. It demonstrated robust generalization across six geographic regions and achieved high expert concordance in blinded validations. Senior pathologists validated FEATâ€™s outputs as comparable to those of human experts, with improved detection of subtle evidentiary nuances. To our knowledge, FEAT is the first LLM-based AI agent system dedicated to forensic medicine, offering scalable, consistent death certification while maintaining expert-level rigor. By integrating AI efficiency with human oversight, this work could advance equitable access to reliable medicolegal services while addressing critical capacity constraints in forensic systems. </p>
<blockquote>
<p>æ³•åŒ»æ­»å› é‰´å®šé¢ä¸´ç€åŒ…æ‹¬äººåŠ›èµ„æºçŸ­ç¼ºå’Œè¯Šæ–­å·®å¼‚åœ¨å†…çš„ç³»ç»Ÿæ€§æŒ‘æˆ˜ï¼Œç‰¹åˆ«æ˜¯åœ¨ä¸­å›½æ³•åŒ»å­¦åŸºç¡€è®¾æ–½ç­‰å¤§è§„æ¨¡ç³»ç»Ÿä¸­ã€‚æˆ‘ä»¬å¼•å…¥äº†FEATï¼ˆForEnsic AgenTï¼‰å¤šæ™ºèƒ½ä½“AIæ¡†æ¶ï¼Œå®ƒé€šè¿‡åŸŸè‡ªé€‚åº”çš„å¤§å‹è¯­è¨€æ¨¡å‹è‡ªåŠ¨åŒ–å’Œæ ‡å‡†åŒ–æ­»äº¡è°ƒæŸ¥ã€‚FEATé¢å‘åº”ç”¨çš„æ¶æ„é›†æˆäº†ï¼šï¼ˆiï¼‰ä¸­å¤®Plannerç”¨äºä»»åŠ¡åˆ†è§£ï¼Œï¼ˆiiï¼‰ä¸“ä¸šLocal Solversç”¨äºè¯æ®åˆ†æï¼Œï¼ˆiiiï¼‰ç”¨äºè¿­ä»£ä¼˜åŒ–çš„Memoryï¼†Reflectionæ¨¡å—ï¼Œä»¥åŠï¼ˆivï¼‰ç”¨äºç»“è®ºåˆæˆçš„Global Solverã€‚è¯¥ç³»ç»Ÿé‡‡ç”¨å·¥å…·å¢å¼ºæ¨ç†ã€åˆ†å±‚æ£€ç´¢å¢å¼ºç”Ÿæˆã€æ³•åŒ»è°ƒä¼˜LLMsä»¥åŠäººç±»å‚ä¸å¾ªç¯åé¦ˆï¼Œä»¥ç¡®ä¿æ³•å¾‹å’ŒåŒ»å­¦æœ‰æ•ˆæ€§ã€‚åœ¨å¤šæ ·åŒ–çš„ä¸­æ–‡æ¡ˆä¾‹ç¾¤ä½“è¯„ä¼°ä¸­ï¼ŒFEATåœ¨é•¿ç¯‡å°¸æ£€åˆ†æå’Œç®€æ´æ­»å› ç»“è®ºæ–¹é¢ä¼˜äºæœ€æ–°çš„AIç³»ç»Ÿã€‚å®ƒåœ¨å…­ä¸ªåœ°ç†åŒºåŸŸä¹‹é—´è¡¨ç°å‡ºç¨³å¥çš„æ³›åŒ–èƒ½åŠ›ï¼Œå¹¶åœ¨ç›²æ€éªŒè¯ä¸­å®ç°äº†é«˜ä¸“å®¶ä¸€è‡´æ€§ã€‚é«˜çº§ç—…ç†å­¦å®¶éªŒè¯FEATçš„è¾“å‡ºç»“æœä¸äººç±»ä¸“å®¶ç›¸å½“ï¼Œå¹¶ä¸”åœ¨æ£€æµ‹å¾®å¦™çš„è¯æ®ç»†å¾®å·®åˆ«æ–¹é¢æœ‰æ‰€æ”¹è¿›ã€‚æ®æˆ‘ä»¬æ‰€çŸ¥ï¼ŒFEATæ˜¯åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹çš„ç¬¬ä¸€ä¸ªä¸“é—¨ç”¨äºæ³•åŒ»å­¦çš„AIæ™ºèƒ½ä½“ç³»ç»Ÿï¼Œåœ¨ä¿æŒä¸“å®¶çº§ä¸¥è°¨æ€§çš„åŒæ—¶ï¼Œæä¾›å¯ä¼¸ç¼©ã€ä¸€è‡´æ€§çš„æ­»äº¡è¯æ˜ã€‚é€šè¿‡å°†AIæ•ˆç‡ä¸äººç±»ç›‘ç£ç›¸ç»“åˆï¼Œè¿™é¡¹å·¥ä½œå¯ä»¥ä¿ƒè¿›å¯é çš„æ³•åŒ»å­¦æœåŠ¡çš„å…¬å¹³è®¿é—®ï¼ŒåŒæ—¶è§£å†³æ³•åŒ»ç³»ç»Ÿä¸­çš„å…³é”®èƒ½åŠ›çº¦æŸã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.07950v1">PDF</a> 18pages, 6 figures</p>
<p><strong>Summary</strong></p>
<p>åŸºäºäººå·¥æ™ºèƒ½çš„å¤šä»£ç†æ¡†æ¶FEATï¼Œé€šè¿‡å¤§å‹è¯­è¨€æ¨¡å‹è‡ªåŠ¨åŒ–å’Œæ ‡å‡†åŒ–æ­»äº¡è°ƒæŸ¥ï¼Œè§£å†³æ³•åŒ»æ­»å› é‰´å®šé¢ä¸´çš„ç³»ç»Ÿæ€§æŒ‘æˆ˜ï¼Œå¦‚äººåŠ›èµ„æºçŸ­ç¼ºå’Œè¯Šæ–­å·®å¼‚ã€‚FEATç³»ç»Ÿé‡‡ç”¨å·¥å…·å¢å¼ºæ¨ç†ã€åˆ†å±‚æ£€ç´¢å¢å¼ºç”Ÿæˆã€æ³•åŒ»è°ƒæ•´çš„å¤§å‹è¯­è¨€æ¨¡å‹ä»¥åŠäººç±»åé¦ˆå¾ªç¯ï¼Œç¡®ä¿æ³•å¾‹å’ŒåŒ»å­¦æœ‰æ•ˆæ€§ã€‚è¯„ä¼°æ˜¾ç¤ºï¼ŒFEATåœ¨ä¸­æ–‡æ¡ˆä¾‹ç¾¤ä½“ä¸­è¡¨ç°å‡ºä¼˜äºç°æœ‰AIç³»ç»Ÿçš„æ€§èƒ½ï¼Œå¹¶åœ¨ç›²éªŒè¯ä¸­è¾¾åˆ°é«˜ä¸“å®¶å…±è¯†ã€‚é«˜çº§ç—…ç†å­¦å®¶éªŒè¯FEATè¾“å‡ºä¸ä¸“å®¶ç›¸å½“ï¼Œèƒ½æ›´å¥½æ£€æµ‹ç»†å¾®è¯æ®ã€‚å®ƒæ˜¯é¦–ä¸ªä¸“é—¨ç”¨äºæ³•åŒ»åŒ»å­¦çš„å¤§å‹è¯­è¨€æ¨¡å‹ä¸ºåŸºç¡€çš„AIä»£ç†ç³»ç»Ÿï¼Œå¯æä¾›å¯ä¼¸ç¼©ã€ä¸€è‡´æ€§çš„æ­»äº¡è¯æ˜ï¼ŒåŒæ—¶ä¿æŒä¸“å®¶çº§ä¸¥è°¨æ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æ³•åŒ»æ­»å› é‰´å®šé¢ä¸´äººåŠ›èµ„æºçŸ­ç¼ºå’Œè¯Šæ–­å·®å¼‚ç­‰ç³»ç»Ÿæ€§æŒ‘æˆ˜ã€‚</li>
<li>FEATæ˜¯ä¸€ä¸ªå¤šä»£ç†AIæ¡†æ¶ï¼Œæ—¨åœ¨é€šè¿‡å¤§å‹è¯­è¨€æ¨¡å‹è‡ªåŠ¨åŒ–å’Œæ ‡å‡†åŒ–æ­»äº¡è°ƒæŸ¥ã€‚</li>
<li>FEATç³»ç»Ÿé‡‡ç”¨å·¥å…·å¢å¼ºæ¨ç†ã€åˆ†å±‚æ£€ç´¢å¢å¼ºç”Ÿæˆä»¥åŠæ³•åŒ»è°ƒæ•´çš„å¤§å‹è¯­è¨€æ¨¡å‹ç­‰æŠ€æœ¯ã€‚</li>
<li>FEATåœ¨ä¸­æ–‡æ¡ˆä¾‹ç¾¤ä½“è¯„ä¼°ä¸­è¡¨ç°å‡ºå“è¶Šæ€§èƒ½ï¼Œè¾¾åˆ°é«˜ä¸“å®¶å…±è¯†ã€‚</li>
<li>é«˜çº§ç—…ç†å­¦å®¶éªŒè¯FEATè¾“å‡ºä¸ä¸“å®¶ç›¸å½“ï¼Œèƒ½æ›´å¥½è¯†åˆ«ç»†å¾®è¯æ®ã€‚</li>
<li>FEATæ˜¯é¦–ä¸ªä¸“é—¨ç”¨äºæ³•åŒ»åŒ»å­¦çš„å¤§å‹è¯­è¨€æ¨¡å‹ä¸ºåŸºç¡€çš„AIç³»ç»Ÿã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.07950">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-7450b2cff15ce0a312f21a3bf0ec60cf.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-223767ca8ef9b810fd54fb650e5b2bf1.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-842db70800b612b27baeff0c2d8d96f5.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-fec18b1c9a12c32b4c2546cc3755e761.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="Multi-agent-systems-for-chemical-engineering-A-review-and-perspective"><a href="#Multi-agent-systems-for-chemical-engineering-A-review-and-perspective" class="headerlink" title="Multi-agent systems for chemical engineering: A review and perspective"></a>Multi-agent systems for chemical engineering: A review and perspective</h2><p><strong>Authors:Sophia Rupprecht, Qinghe Gao, Tanuj Karia, Artur M. Schweidtmann</strong></p>
<p>Large language model (LLM)-based multi-agent systems (MASs) are a recent but rapidly evolving technology with the potential to transform chemical engineering by decomposing complex workflows into teams of collaborative agents with specialized knowledge and tools. This review surveys the state-of-the-art of MAS within chemical engineering. While early studies demonstrate promising results, scientific challenges remain, including the design of tailored architectures, integration of heterogeneous data modalities, development of foundation models with domain-specific modalities, and strategies for ensuring transparency, safety, and environmental impact. As a young but fast-moving field, MASs offer exciting opportunities to rethink chemical engineering workflows. </p>
<blockquote>
<p>åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„å¤šæ™ºèƒ½ä½“ç³»ç»Ÿï¼ˆMASï¼‰æ˜¯ä¸€é¡¹æœ€æ–°çš„å¿«é€Ÿå‘å±•æŠ€æœ¯ï¼Œå…·æœ‰å°†å¤æ‚å·¥ä½œæµç¨‹åˆ†è§£æˆå…·æœ‰ä¸“ä¸šçŸ¥è¯†å’Œå·¥å…·çš„åä½œæ™ºèƒ½ä½“å›¢é˜Ÿçš„æ½œåŠ›ï¼Œä»è€Œæ”¹å˜åŒ–å­¦å·¥ç¨‹ã€‚æœ¬æ–‡ç»¼è¿°äº†åŒ–å­¦å·¥ç¨‹ä¸­MASçš„æœ€æ–°è¿›å±•ã€‚å°½ç®¡æ—©æœŸç ”ç©¶æ˜¾ç¤ºå‡ºæœ‰å¸Œæœ›çš„ç»“æœï¼Œä½†ä»å­˜åœ¨ç§‘å­¦æŒ‘æˆ˜ï¼ŒåŒ…æ‹¬è®¾è®¡å®šåˆ¶æ¶æ„ã€é›†æˆå¼‚è´¨æ•°æ®æ¨¡å¼ã€å¼€å‘å…·æœ‰é¢†åŸŸç‰¹å®šæ¨¡å¼çš„åŸºç¡€æ¨¡å‹ï¼Œä»¥åŠç¡®ä¿é€æ˜åº¦ã€å®‰å…¨æ€§å’Œç¯å¢ƒå½±å“çš„ç­–ç•¥ã€‚ä½œä¸ºä¸€ä¸ªå¹´è½»ä½†å‘å±•è¿…é€Ÿçš„é¢†åŸŸï¼ŒMASä¸ºé‡æ–°æ€è€ƒåŒ–å­¦å·¥ç¨‹å·¥ä½œæµç¨‹æä¾›äº†ä»¤äººå…´å¥‹çš„æœºä¼šã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.07880v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„å¤šæ™ºèƒ½ä½“ç³»ç»Ÿï¼ˆMASï¼‰æ˜¯åŒ–å­¦å·¥ç¨‹ä¸­æ­£åœ¨è¿…é€Ÿå‘å±•çš„æ–°æŠ€æœ¯ã€‚å®ƒå¯å°†å¤æ‚çš„å·¥ä½œæµç¨‹åˆ†è§£ä¸ºå…·æœ‰ä¸“ä¸šçŸ¥è¯†å’Œå·¥å…·çš„åä½œæ™ºèƒ½ä½“å›¢é˜Ÿï¼Œä»è€Œå…·æœ‰å˜é©æ½œåŠ›ã€‚æœ¬æ–‡ç»¼è¿°äº†åŒ–å­¦å·¥ç¨‹ä¸­çš„MASæœ€æ–°ç ”ç©¶æˆæœã€‚å°½ç®¡æ—©æœŸç ”ç©¶å–å¾—è‰¯å¥½ç»“æœï¼Œä½†ä»å­˜åœ¨è¯¸å¤šç§‘å­¦æŒ‘æˆ˜ï¼Œå¦‚å®šåˆ¶æ¶æ„çš„è®¾è®¡ã€å¼‚è´¨æ•°æ®æ¨¡å¼çš„é›†æˆã€å…·æœ‰ç‰¹å®šé¢†åŸŸæ¨¡å¼çš„æ¨¡å‹åŸºç¡€çš„å¼€å‘ï¼Œä»¥åŠç¡®ä¿é€æ˜åº¦ã€å®‰å…¨æ€§å’Œç¯å¢ƒå½±å“çš„ç­–ç•¥ç­‰ã€‚ä½œä¸ºå¹´è½»ä½†å¿«é€Ÿå‘å±•çš„é¢†åŸŸï¼ŒMASä¸ºé‡æ–°æ€è€ƒåŒ–å­¦å·¥ç¨‹å·¥ä½œæµç¨‹æä¾›äº†æ¿€åŠ¨äººå¿ƒçš„æœºä¼šã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>LLM-based MASæ˜¯åŒ–å­¦å·¥ç¨‹ä¸­æ­£åœ¨è¿…é€Ÿå‘å±•çš„æ–°æŠ€æœ¯ã€‚</li>
<li>MASèƒ½å°†å¤æ‚çš„å·¥ä½œæµç¨‹åˆ†è§£ä¸ºå…·æœ‰ä¸“ä¸šçŸ¥è¯†å’Œå·¥å…·çš„åä½œæ™ºèƒ½ä½“å›¢é˜Ÿã€‚</li>
<li>æ—©æœŸç ”ç©¶åœ¨MASä¸Šå–å¾—äº†è‰¯å¥½ç»“æœï¼Œä½†ä»å­˜åœ¨ç§‘å­¦æŒ‘æˆ˜ã€‚</li>
<li>éœ€è¦è®¾è®¡å®šåˆ¶æ¶æ„ã€é›†æˆå¼‚è´¨æ•°æ®æ¨¡å¼ä»¥åŠå¼€å‘å…·æœ‰ç‰¹å®šé¢†åŸŸæ¨¡å¼çš„æ¨¡å‹åŸºç¡€ã€‚</li>
<li>ä¿è¯é€æ˜åº¦ã€å®‰å…¨æ€§å’Œç¯å¢ƒå½±å“æ˜¯MASå‘å±•ä¸­çš„å…³é”®ç­–ç•¥ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.07880">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-a8d5362001384f9e98b43f854fdc1ad8.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-1c1d07a45bfff380a301cd8b887088b6.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-8c55ede388312e73f0bac94c3e8a7319.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="1-2-3-Check-Enhancing-Contextual-Privacy-in-LLM-via-Multi-Agent-Reasoning"><a href="#1-2-3-Check-Enhancing-Contextual-Privacy-in-LLM-via-Multi-Agent-Reasoning" class="headerlink" title="1-2-3 Check: Enhancing Contextual Privacy in LLM via Multi-Agent   Reasoning"></a>1-2-3 Check: Enhancing Contextual Privacy in LLM via Multi-Agent   Reasoning</h2><p><strong>Authors:Wenkai Li, Liwen Sun, Zhenxiang Guan, Xuhui Zhou, Maarten Sap</strong></p>
<p>Addressing contextual privacy concerns remains challenging in interactive settings where large language models (LLMs) process information from multiple sources (e.g., summarizing meetings with private and public information). We introduce a multi-agent framework that decomposes privacy reasoning into specialized subtasks (extraction, classification), reducing the information load on any single agent while enabling iterative validation and more reliable adherence to contextual privacy norms. To understand how privacy errors emerge and propagate, we conduct a systematic ablation over information-flow topologies, revealing when and why upstream detection mistakes cascade into downstream leakage. Experiments on the ConfAIde and PrivacyLens benchmark with several open-source and closed-sourced LLMs demonstrate that our best multi-agent configuration substantially reduces private information leakage (\textbf{18%} on ConfAIde and \textbf{19%} on PrivacyLens with GPT-4o) while preserving the fidelity of public content, outperforming single-agent baselines. These results highlight the promise of principled information-flow design in multi-agent systems for contextual privacy with LLMs. </p>
<blockquote>
<p>åœ¨å¤„ç†æ¥è‡ªå¤šä¸ªæºçš„ä¿¡æ¯ï¼ˆä¾‹å¦‚ï¼Œæ€»ç»“åŒ…å«ç§æœ‰å’Œå…¬å…±ä¿¡æ¯çš„ä¼šè®®ï¼‰çš„è¯­è¨€æ¨¡å‹ç¯å¢ƒä¸­ï¼Œè§£å†³ä¸Šä¸‹æ–‡éšç§æ‹…å¿§ä»ç„¶æ˜¯ä¸€ä¸ªæŒ‘æˆ˜ã€‚æˆ‘ä»¬å¼•å…¥äº†ä¸€ä¸ªå¤šæ™ºèƒ½ä½“æ¡†æ¶ï¼Œè¯¥æ¡†æ¶å°†éšç§æ¨ç†åˆ†è§£æˆä¸“é—¨çš„å­ä»»åŠ¡ï¼ˆæå–ã€åˆ†ç±»ç­‰ï¼‰ï¼Œè¿™æ—¢å‡è½»äº†ä»»ä½•å•ä¸ªæ™ºèƒ½ä½“çš„ä¿¡æ¯è´Ÿè·ï¼Œåˆå®ç°äº†è¿­ä»£éªŒè¯å¹¶æ›´å¯é åœ°éµå®ˆä¸Šä¸‹æ–‡éšç§è§„èŒƒã€‚ä¸ºäº†äº†è§£éšç§é”™è¯¯æ˜¯å¦‚ä½•äº§ç”Ÿå’Œä¼ æ’­çš„ï¼Œæˆ‘ä»¬å¯¹ä¿¡æ¯æµæ‹“æ‰‘è¿›è¡Œäº†ç³»ç»Ÿçš„å‰–æï¼Œæ­ç¤ºäº†ä¸Šæ¸¸æ£€æµ‹é”™è¯¯ä½•æ—¶ä»¥åŠä¸ºä½•ä¼šçº§è”æˆä¸‹æ¸¸æ³„éœ²ã€‚åœ¨ConfAIdeå’ŒPrivacyLensåŸºå‡†æµ‹è¯•ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œä½¿ç”¨å¼€æºå’Œé—­æºçš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼Œæˆ‘ä»¬æœ€ä½³çš„å¤šæ™ºèƒ½ä½“é…ç½®å¤§å¹…å‡å°‘äº†ç§äººä¿¡æ¯çš„æ³„éœ²ï¼ˆåœ¨ConfAIdeä¸Šå‡å°‘**18%<strong>ï¼Œåœ¨PrivacyLensä¸Šä¸GPT-4oä¸€èµ·ä½¿ç”¨å‡å°‘</strong>19%**ï¼‰ï¼ŒåŒæ—¶ä¿æŒäº†å…¬å…±å†…å®¹çš„ä¿çœŸåº¦ï¼Œè¶…è¶Šäº†å•æ™ºèƒ½ä½“çš„åŸºçº¿ã€‚è¿™äº›ç»“æœçªæ˜¾äº†åœ¨å¤§å‹è¯­è¨€æ¨¡å‹ä¸Šä¸‹æ–‡ä¸­ï¼Œä»¥åŸåˆ™ä¸ºåŸºç¡€çš„ä¿¡æ¯æµè®¾è®¡åœ¨å¤šæ™ºèƒ½ä½“ç³»ç»Ÿä¸­å¯¹éšç§ä¿æŠ¤çš„æ½œåŠ›ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.07667v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å¤„ç†æ¥è‡ªå¤šä¸ªæºçš„ä¿¡æ¯æ—¶ï¼Œé¢ä¸´åœ¨äº¤äº’å¼ç¯å¢ƒä¸­è§£å†³ä¸Šä¸‹æ–‡éšç§é—®é¢˜çš„æŒ‘æˆ˜ã€‚æœ¬æ–‡å¼•å…¥äº†ä¸€ç§å¤šæ™ºèƒ½ä½“æ¡†æ¶ï¼Œå°†éšç§æ¨ç†åˆ†è§£æˆä¸“é—¨çš„å­ä»»åŠ¡ï¼Œå‡å°‘å•ä¸ªæ™ºèƒ½ä½“çš„ä¿¡æ¯è´Ÿè½½ï¼ŒåŒæ—¶å®ç°è¿­ä»£éªŒè¯å’Œæ›´å¯é åœ°éµå®ˆä¸Šä¸‹æ–‡éšç§è§„èŒƒã€‚é€šè¿‡ç³»ç»Ÿåœ°å‰–æä¿¡æ¯æµæ‹“æ‰‘æ¥äº†è§£éšç§é”™è¯¯çš„å‡ºç°å’Œä¼ æ’­ã€‚åœ¨ConfAIdeå’ŒPrivacyLensåŸºå‡†æµ‹è¯•ä¸Šè¿›è¡Œçš„å®éªŒè¡¨æ˜ï¼Œæœ€ä½³å¤šæ™ºèƒ½ä½“é…ç½®å¯å¤§å¹…å‡å°‘ç§äººä¿¡æ¯æ³„éœ²ï¼ŒåŒæ—¶ä¿æŒå…¬å…±å†…å®¹çš„ä¿çœŸåº¦ï¼Œä¼˜äºå•æ™ºèƒ½ä½“åŸºçº¿ã€‚è¿™çªæ˜¾äº†åŸºäºåŸåˆ™çš„ä¿¡æ¯æµè®¾è®¡åœ¨å¤šæ™ºèƒ½ä½“ç³»ç»Ÿä¸å¤§å‹è¯­è¨€æ¨¡å‹ç›¸ç»“åˆè¿›è¡Œä¸Šä¸‹æ–‡éšç§ä¿æŠ¤çš„æ½œåŠ›ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤§å‹è¯­è¨€æ¨¡å‹åœ¨äº¤äº’å¼ç¯å¢ƒä¸­å¤„ç†å¤šæºä¿¡æ¯æ—¶é¢ä¸´ä¸Šä¸‹æ–‡éšç§æŒ‘æˆ˜ã€‚</li>
<li>å¼•å…¥å¤šæ™ºèƒ½ä½“æ¡†æ¶ï¼Œå°†éšç§æ¨ç†åˆ†è§£æˆä¸“é—¨å­ä»»åŠ¡ï¼Œé™ä½å•ä¸€æ™ºèƒ½ä½“çš„ä¿¡æ¯è´Ÿè½½ã€‚</li>
<li>é€šè¿‡è¿­ä»£éªŒè¯å’Œéµå®ˆä¸Šä¸‹æ–‡éšç§è§„èŒƒï¼Œå®ç°æ›´å¯é çš„éšç§ä¿æŠ¤ã€‚</li>
<li>ç³»ç»Ÿåˆ†æä¿¡æ¯æµæ‹“æ‰‘ï¼Œäº†è§£éšç§é”™è¯¯çš„å‡ºç°å’Œä¼ æ’­æœºåˆ¶ã€‚</li>
<li>åœ¨ConfAIdeå’ŒPrivacyLensåŸºå‡†æµ‹è¯•ä¸Šï¼Œå¤šæ™ºèƒ½ä½“é…ç½®å¤§å¹…å‡å°‘ç§äººä¿¡æ¯æ³„éœ²ã€‚</li>
<li>å¤šæ™ºèƒ½ä½“é…ç½®åŒæ—¶ä¿æŒå…¬å…±å†…å®¹çš„ä¿çœŸåº¦ï¼Œä¼˜äºå•æ™ºèƒ½ä½“åŸºçº¿ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.07667">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-59887f98cc2c2daa146f890c1bb3877e.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-38e2366ef585ad9ab8f0bae303ba73a3.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-9fd6aa00c0f832aab4dc49f4f445cd49.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-cb22eb3084b01f69b8800284f5f333fd.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="Breaking-Down-and-Building-Up-Mixture-of-Skill-Based-Vision-and-Language-Navigation-Agents"><a href="#Breaking-Down-and-Building-Up-Mixture-of-Skill-Based-Vision-and-Language-Navigation-Agents" class="headerlink" title="Breaking Down and Building Up: Mixture of Skill-Based   Vision-and-Language Navigation Agents"></a>Breaking Down and Building Up: Mixture of Skill-Based   Vision-and-Language Navigation Agents</h2><p><strong>Authors:Tianyi Ma, Yue Zhang, Zehao Wang, Parisa Kordjamshidi</strong></p>
<p>Vision-and-Language Navigation (VLN) poses significant challenges in enabling agents to interpret natural language instructions and navigate complex 3D environments. While recent progress has been driven by large-scale pre-training and data augmentation, current methods still struggle to generalize to unseen scenarios, particularly when complex spatial and temporal reasoning is required. In this work, we propose SkillNav, a modular framework that introduces structured, skill-based reasoning into Transformer-based VLN agents. Our method decomposes navigation into a set of interpretable atomic skills (e.g., Vertical Movement, Area and Region Identification, Stop and Pause), each handled by a specialized agent. We then introduce a novel zero-shot Vision-Language Model (VLM)-based router, which dynamically selects the most suitable agent at each time step by aligning sub-goals with visual observations and historical actions. SkillNav achieves a new state-of-the-art performance on the R2R benchmark and demonstrates strong generalization to the GSA-R2R benchmark that includes novel instruction styles and unseen environments. </p>
<blockquote>
<p>è§†è§‰ä¸è¯­è¨€å¯¼èˆªï¼ˆVLNï¼‰ä¸ºæ™ºèƒ½ä½“åœ¨è§£è¯»è‡ªç„¶è¯­è¨€æŒ‡ä»¤å’Œå¯¼èˆªå¤æ‚ä¸‰ç»´ç¯å¢ƒæ–¹é¢å¸¦æ¥äº†é‡å¤§æŒ‘æˆ˜ã€‚è™½ç„¶æœ€è¿‘çš„è¿›å±•å¾—ç›Šäºå¤§è§„æ¨¡é¢„è®­ç»ƒå’Œæ•°æ®å¢å¼ºï¼Œä½†å½“å‰çš„æ–¹æ³•ä»ç„¶éš¾ä»¥æ¨å¹¿åˆ°æœªè§è¿‡çš„åœºæ™¯ï¼Œç‰¹åˆ«æ˜¯åœ¨éœ€è¦å¤æ‚ç©ºé—´å’Œæ—¶é—´æ¨ç†çš„æƒ…å†µä¸‹ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†SkillNavï¼Œè¿™æ˜¯ä¸€ä¸ªæ¨¡å—åŒ–æ¡†æ¶ï¼Œå®ƒå¼•å…¥äº†åŸºäºæŠ€èƒ½çš„ç»“æ„åŒ–æ¨ç†åˆ°åŸºäºTransformerçš„VLNæ™ºèƒ½ä½“ä¸­ã€‚æˆ‘ä»¬çš„æ–¹æ³•å°†å¯¼èˆªåˆ†è§£æˆä¸€ç»„å¯è§£é‡Šçš„åŸå­æŠ€èƒ½ï¼ˆä¾‹å¦‚å‚ç›´ç§»åŠ¨ã€åŒºåŸŸè¯†åˆ«ã€åœæ­¢å’Œæš‚åœç­‰ï¼‰ï¼Œæ¯ä¸ªæŠ€èƒ½éƒ½ç”±ä¸€ä¸ªä¸“é—¨çš„æ™ºèƒ½ä½“å¤„ç†ã€‚ç„¶åæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§æ–°å‹çš„é›¶æ ·æœ¬è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMï¼‰è·¯ç”±å™¨ï¼Œå®ƒé€šè¿‡å¯¹å­ç›®æ ‡ä¸è§†è§‰è§‚å¯Ÿå’Œå†å²è¡ŒåŠ¨è¿›è¡ŒåŒ¹é…ï¼ŒåŠ¨æ€é€‰æ‹©æ¯ä¸ªæ—¶é—´æ­¥é•¿ä¸‹æœ€åˆé€‚çš„æ™ºèƒ½ä½“ã€‚SkillNavåœ¨R2RåŸºå‡†æµ‹è¯•ä¸Šè¾¾åˆ°äº†æ–°çš„æœ€æ–°æŠ€æœ¯æ°´å¹³ï¼Œå¹¶ä¸”åœ¨åŒ…æ‹¬æ–°å‹æŒ‡ä»¤é£æ ¼å’Œæœªè§è¿‡çš„ç¯å¢ƒçš„GSA-R2RåŸºå‡†æµ‹è¯•ä¸Šè¡¨ç°å‡ºå¼ºå¤§çš„æ³›åŒ–èƒ½åŠ›ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.07642v1">PDF</a> 18 pages, 5 Figures,</p>
<p><strong>Summary</strong></p>
<p>è¯¥æ–‡ç« æ¢è®¨äº†è§†è§‰ä¸è¯­è¨€å¯¼èˆªï¼ˆVLNï¼‰é¢ä¸´çš„æŒ‘æˆ˜ï¼ŒåŒ…æ‹¬æ™ºèƒ½ä½“åœ¨è§£è¯»è‡ªç„¶è¯­è¨€æŒ‡ä»¤å’Œå¯¼èˆªå¤æ‚ä¸‰ç»´ç¯å¢ƒæ—¶çš„å›°éš¾ã€‚æ–‡ç« æå‡ºäº†ä¸€ç§åä¸ºSkillNavçš„æ¨¡å—åŒ–æ¡†æ¶ï¼Œè¯¥æ¡†æ¶å¼•å…¥äº†ç»“æ„åŒ–ã€åŸºäºæŠ€èƒ½çš„æ¨ç†åˆ°åŸºäºTransformerçš„VLNæ™ºèƒ½ä½“ä¸­ã€‚è¯¥æ–¹æ³•å°†å¯¼èˆªåˆ†è§£æˆä¸€ç»„å¯è§£é‡Šçš„åŸå­æŠ€èƒ½ï¼ˆå¦‚å‚ç›´ç§»åŠ¨ã€åŒºåŸŸè¯†åˆ«ã€åœæ­¢å’Œæš‚åœç­‰ï¼‰ï¼Œæ¯ä¸ªæŠ€èƒ½ç”±ä¸“é—¨çš„æ™ºèƒ½ä½“å¤„ç†ã€‚ç„¶åï¼Œæ–‡ç« å¼•å…¥äº†ä¸€ç§æ–°å‹çš„é›¶æ ·æœ¬è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMï¼‰è·¯ç”±å™¨ï¼Œè¯¥è·¯ç”±å™¨é€šè¿‡åŠ¨æ€é€‰æ‹©ä¸è§†è§‰è§‚å¯Ÿå’Œå†å²è¡Œä¸ºç›¸åŒ¹é…çš„å­ç›®æ ‡æ¥é€‰æ‹©æœ€åˆé€‚çš„æ™ºèƒ½ä½“ã€‚SkillNavåœ¨R2RåŸºå‡†æµ‹è¯•ä¸­å–å¾—äº†æœ€æ–°æ€§èƒ½æ°´å¹³ï¼Œå¹¶åœ¨åŒ…æ‹¬æ–°å‹æŒ‡ä»¤é£æ ¼å’Œæœªè§è¿‡çš„ç¯å¢ƒçš„GSA-R2RåŸºå‡†æµ‹è¯•ä¸­å±•ç°å‡ºå¼ºå¤§çš„æ³›åŒ–èƒ½åŠ›ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>VLNé¢ä¸´çš„ä¸»è¦æŒ‘æˆ˜æ˜¯æ™ºèƒ½ä½“åœ¨è§£è¯»è‡ªç„¶è¯­è¨€æŒ‡ä»¤å’Œå¯¼èˆªå¤æ‚ä¸‰ç»´ç¯å¢ƒæ–¹é¢çš„å›°éš¾ã€‚</li>
<li>SkillNavæ˜¯ä¸€ç§æ¨¡å—åŒ–æ¡†æ¶ï¼Œå¼•å…¥äº†ç»“æ„åŒ–ã€åŸºäºæŠ€èƒ½çš„æ¨ç†åˆ°VLNæ™ºèƒ½ä½“ä¸­ã€‚</li>
<li>SkillNavå°†å¯¼èˆªåˆ†è§£æˆä¸€ç»„å¯è§£é‡Šçš„åŸå­æŠ€èƒ½ï¼Œæ¯ä¸ªæŠ€èƒ½ç”±ä¸“é—¨çš„æ™ºèƒ½ä½“å¤„ç†ã€‚</li>
<li>æ–°å‹é›¶æ ·æœ¬è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMï¼‰è·¯ç”±å™¨è¢«ç”¨æ¥åŠ¨æ€é€‰æ‹©æœ€åˆé€‚çš„æ™ºèƒ½ä½“ã€‚</li>
<li>SkillNavåœ¨R2RåŸºå‡†æµ‹è¯•ä¸­å–å¾—äº†æœ€æ–°æ€§èƒ½æ°´å¹³ã€‚</li>
<li>SkillNavåœ¨æ³›åŒ–åˆ°æ–°å‹æŒ‡ä»¤é£æ ¼å’Œæœªè§è¿‡çš„ç¯å¢ƒæ–¹é¢è¡¨ç°å‡ºå¼ºå¤§çš„èƒ½åŠ›ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.07642">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-0d96f96185d952b889b2d937756831b4.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-5fa0948d4e4ebe763219c13b80c7b158.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-18737fcb9c00fbd49aea86eab0709758.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-06375f60d6bb95400cde22d933b1623e.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-c32eeba86611f6160bf7261113a62f44.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d2c3f8788eb3299a91e9a399a9d6f439.jpg" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="MCPToolBench-A-Large-Scale-AI-Agent-Model-Context-Protocol-MCP-Tool-Use-Benchmark"><a href="#MCPToolBench-A-Large-Scale-AI-Agent-Model-Context-Protocol-MCP-Tool-Use-Benchmark" class="headerlink" title="MCPToolBench++: A Large Scale AI Agent Model Context Protocol MCP Tool   Use Benchmark"></a>MCPToolBench++: A Large Scale AI Agent Model Context Protocol MCP Tool   Use Benchmark</h2><p><strong>Authors:Shiqing Fan, Xichen Ding, Liang Zhang, Linjian Mo</strong></p>
<p>LLMsâ€™ capabilities are enhanced by using function calls to integrate various data sources or API results into the context window. Typical tools include search, web crawlers, maps, financial data, file systems, and browser usage, etc. Integrating these data sources or functions requires a standardized method. The Model Context Protocol (MCP) provides a standardized way to supply context to LLMs. However, the evaluation of LLMs and AI Agentsâ€™ MCP tool use abilities suffer from several issues. First, thereâ€™s a lack of comprehensive datasets or benchmarks to evaluate various MCP tools. Second, the diverse formats of response from MCP tool call execution further increase the difficulty of evaluation. Additionally, unlike existing tool-use benchmarks with high success rates in functions like programming and math functions, the success rate of real-world MCP tool is not guaranteed and varies across different MCP servers. Furthermore, the LLMsâ€™ context window also limits the number of available tools that can be called in a single run, because the textual descriptions of tool and the parameters have long token length for an LLM to process all at once. To help address the challenges of evaluating LLMsâ€™ performance on calling MCP tools, we propose MCPToolBench++, a large-scale, multi-domain AI Agent tool use benchmark. As of July 2025, this benchmark is build upon marketplace of over 4k MCP servers from more than 40 categories, collected from the MCP marketplaces and GitHub communities. The datasets consist of both single-step and multi-step tool calls across different categories. We evaluated SOTA LLMs with agentic abilities on this benchmark and reported the results. </p>
<blockquote>
<p>ä½¿ç”¨åŠŸèƒ½è°ƒç”¨å°†å„ç§æ•°æ®æºæˆ–APIç»“æœé›†æˆåˆ°ä¸Šä¸‹æ–‡çª—å£ä¸­æ¥å¢å¼ºLLMsçš„èƒ½åŠ›ã€‚å…¸å‹å·¥å…·åŒ…æ‹¬æœç´¢ã€ç½‘ç»œçˆ¬è™«ã€åœ°å›¾ã€é‡‘èæ•°æ®ã€æ–‡ä»¶ç³»ç»Ÿå’Œæµè§ˆå™¨ä½¿ç”¨ç­‰ã€‚é›†æˆè¿™äº›æ•°æ®æºæˆ–åŠŸèƒ½éœ€è¦ä¸€ç§æ ‡å‡†åŒ–çš„æ–¹æ³•ã€‚æ¨¡å‹ä¸Šä¸‹æ–‡åè®®ï¼ˆMCPï¼‰æä¾›äº†ä¸€ç§ä¸ºLLMsæä¾›ä¸Šä¸‹æ–‡çš„æ ‡å‡†æ–¹å¼ã€‚ç„¶è€Œï¼ŒLLMså’ŒAIä»£ç†çš„MCPå·¥å…·ä½¿ç”¨èƒ½åŠ›çš„è¯„ä¼°å­˜åœ¨ä¸€äº›é—®é¢˜ã€‚é¦–å…ˆï¼Œç¼ºä¹ç»¼åˆæ•°æ®é›†æˆ–åŸºå‡†æµ‹è¯•æ¥è¯„ä¼°å„ç§MCPå·¥å…·ã€‚å…¶æ¬¡ï¼Œç”±äºMCPå·¥å…·è°ƒç”¨æ‰§è¡Œçš„å“åº”æ ¼å¼å¤šæ ·ï¼Œè¿›ä¸€æ­¥å¢åŠ äº†è¯„ä¼°çš„éš¾åº¦ã€‚æ­¤å¤–ï¼Œä¸ç°æœ‰å·¥å…·ä½¿ç”¨åŸºå‡†æµ‹è¯•åœ¨ç¼–ç¨‹å’Œæ•°å­¦å‡½æ•°ç­‰åŠŸèƒ½ä¸Šå®ç°çš„é«˜æˆåŠŸç‡ä¸åŒï¼Œç°å®ä¸–ç•Œä¸­çš„MCPå·¥å…·çš„æˆåŠŸç‡å¹¶ä¸èƒ½ä¿è¯ï¼Œå¹¶ä¸”ä¼šå› ä¸åŒçš„MCPæœåŠ¡å™¨è€Œæœ‰æ‰€å˜åŒ–ã€‚å¦å¤–ï¼ŒLLMsçš„ä¸Šä¸‹æ–‡çª—å£è¿˜é™åˆ¶äº†å•æ¬¡è¿è¡Œä¸­å¯è°ƒç”¨å·¥å…·çš„æ•°é‡ï¼Œå› ä¸ºLLMä¸€æ¬¡å¤„ç†å·¥å…·å’Œå‚æ•°çš„æ–‡æœ¬æè¿°éœ€è¦è¾ƒé•¿çš„ä»¤ç‰Œé•¿åº¦ã€‚ä¸ºäº†è§£å†³è¯„ä¼°LLMsåœ¨è°ƒç”¨MCPå·¥å…·æ–¹é¢çš„æ€§èƒ½çš„æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†MCPToolBench++ï¼Œè¿™æ˜¯ä¸€ä¸ªå¤§è§„æ¨¡ã€å¤šé¢†åŸŸçš„AIä»£ç†å·¥å…·ä½¿ç”¨åŸºå‡†æµ‹è¯•ã€‚æˆªè‡³2025å¹´7æœˆï¼Œè¯¥åŸºå‡†æµ‹è¯•å»ºç«‹åœ¨æ¥è‡ª40å¤šä¸ªç±»åˆ«çš„4000å¤šä¸ªMCPæœåŠ¡å™¨å¸‚åœºä¹‹ä¸Šï¼Œè¿™äº›æœåŠ¡å™¨æ¥è‡ªMCPå¸‚åœºå’ŒGitHubç¤¾åŒºã€‚æ•°æ®é›†åŒ…å«ä¸åŒç±»åˆ«çš„å•æ­¥å’Œå¤šæ­¥å·¥å…·è°ƒç”¨ã€‚æˆ‘ä»¬åœ¨è¯¥åŸºå‡†æµ‹è¯•ä¸Šè¯„ä¼°äº†å…·æœ‰ä»£ç†èƒ½åŠ›çš„æœ€æ–°LLMså¹¶æŠ¥å‘Šäº†ç»“æœã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.07575v1">PDF</a> Benchmarks and Source Code Released</p>
<p><strong>Summary</strong></p>
<p>åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„èƒ½åŠ›ï¼Œé€šè¿‡ä½¿ç”¨å‡½æ•°è°ƒç”¨æ•´åˆå¤šç§æ•°æ®æºæˆ–APIç»“æœåˆ°è¯­å¢ƒçª—å£æ¥å¢å¼ºå…¶èƒ½åŠ›ã€‚æ¨¡å‹ä¸Šä¸‹æ–‡åè®®ï¼ˆMCPï¼‰ä¸ºLLMæä¾›äº†æ ‡å‡†åŒ–çš„è¯­å¢ƒä¾›åº”æ–¹å¼ã€‚ç„¶è€Œï¼Œè¯„ä¼°LLMå’Œäººå·¥æ™ºèƒ½ä»£ç†çš„MCPå·¥å…·ä½¿ç”¨èƒ½åŠ›é¢ä¸´å‡ ä¸ªæŒ‘æˆ˜ã€‚ç¼ºä¹ç»¼åˆæ•°æ®é›†æˆ–åŸºå‡†æµ‹è¯•æ¥è¯„ä¼°å„ç§MCPå·¥å…·ï¼›MCPå·¥å…·è°ƒç”¨æ‰§è¡Œçš„å“åº”æ ¼å¼å¤šæ ·ï¼Œå¢åŠ äº†è¯„ä¼°éš¾åº¦ï¼›ä¸ç¼–ç¨‹å’Œæ•°å­¦å‡½æ•°ç­‰ç°æœ‰å·¥å…·ä½¿ç”¨åŸºå‡†æµ‹è¯•çš„é«˜æˆåŠŸç‡ä¸åŒï¼Œç°å®ä¸–ç•Œä¸­çš„MCPå·¥å…·æˆåŠŸç‡æ— æ³•ä¿è¯ï¼Œä¸”å› ä¸åŒçš„MCPæœåŠ¡å™¨è€Œæœ‰æ‰€å·®å¼‚ï¼›LLMçš„è¯­å¢ƒçª—å£é™åˆ¶äº†å•æ¬¡è¿è¡Œä¸­å¯è°ƒç”¨çš„å·¥å…·æ•°é‡ã€‚ä¸ºåº”å¯¹è¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†MCPToolBench++ï¼Œè¿™æ˜¯ä¸€ä¸ªå¤§è§„æ¨¡ã€å¤šé¢†åŸŸçš„AIä»£ç†å·¥å…·ä½¿ç”¨åŸºå‡†æµ‹è¯•ã€‚æˆªè‡³2025å¹´7æœˆï¼Œè¯¥åŸºå‡†æµ‹è¯•å»ºç«‹åœ¨åŒ…å«è¶…è¿‡40ä¸ªç±»åˆ«çš„4000å¤šä¸ªMCPæœåŠ¡å™¨å¸‚åœºä¸Šï¼Œä»MCPå¸‚åœºå’ŒGitHubç¤¾åŒºæ”¶é›†ã€‚æ•°æ®é›†åŒ…å«ä¸åŒç±»åˆ«çš„å•æ­¥å’Œå¤šæ­¥å·¥å…·è°ƒç”¨ã€‚æˆ‘ä»¬åœ¨è¯¥åŸºå‡†æµ‹è¯•ä¸Šè¯„ä¼°äº†å…·æœ‰ä»£ç†èƒ½åŠ›çš„é¡¶å°–LLMå¹¶æŠ¥å‘Šäº†ç»“æœã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>LLMsçš„èƒ½åŠ›å¯ä»¥é€šè¿‡ä½¿ç”¨å‡½æ•°è°ƒç”¨æ•´åˆå¤šç§æ•°æ®æºæˆ–APIç»“æœåˆ°è¯­å¢ƒçª—å£æ¥å¢å¼ºã€‚</li>
<li>Model Context Protocol (MCP) ä¸ºLLMsæä¾›äº†æ ‡å‡†åŒ–çš„è¯­å¢ƒä¾›åº”æ–¹å¼ã€‚</li>
<li>è¯„ä¼°LLMså’ŒAIä»£ç†çš„MCPå·¥å…·ä½¿ç”¨èƒ½åŠ›å­˜åœ¨å¤šä¸ªæŒ‘æˆ˜ï¼Œå¦‚ç¼ºä¹ç»¼åˆæ•°æ®é›†ã€å“åº”æ ¼å¼å¤šæ ·ã€ç°å®ä¸–ç•Œä¸­çš„æˆåŠŸç‡ä¸ç¡®å®šä»¥åŠè¯­å¢ƒçª—å£çš„é™åˆ¶ç­‰ã€‚</li>
<li>MCPToolBench++æ˜¯ä¸€ä¸ªæ–°çš„å¤§è§„æ¨¡ã€å¤šé¢†åŸŸçš„AIä»£ç†å·¥å…·ä½¿ç”¨åŸºå‡†æµ‹è¯•ï¼Œç”¨äºåº”å¯¹è¿™äº›æŒ‘æˆ˜ã€‚</li>
<li>è¯¥åŸºå‡†æµ‹è¯•åŒ…å«æ¥è‡ªå¤šä¸ªç±»åˆ«çš„å•æ­¥å’Œå¤šæ­¥å·¥å…·è°ƒç”¨ã€‚</li>
<li>æˆªè‡³2025å¹´7æœˆï¼Œè¯¥åŸºå‡†æµ‹è¯•å»ºç«‹åœ¨åŒ…å«è¶…è¿‡40ä¸ªç±»åˆ«çš„4000å¤šä¸ªMCPæœåŠ¡å™¨çš„åŸºç¡€ä¸Šã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.07575">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-69fa33a8a71978e6340c7746d5628efa.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-bb9c91339a356b0ebd183f80350df6f3.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-749c952f60357e6bfb04709591116c8d.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-72677a677fb8bb9a806d86b2d65c035a.jpg" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1><h2 id="Evolutionary-Optimization-of-Deep-Learning-Agents-for-Sparrow-Mahjong"><a href="#Evolutionary-Optimization-of-Deep-Learning-Agents-for-Sparrow-Mahjong" class="headerlink" title="Evolutionary Optimization of Deep Learning Agents for Sparrow Mahjong"></a>Evolutionary Optimization of Deep Learning Agents for Sparrow Mahjong</h2><p><strong>Authors:Jim Oâ€™Connor, Derin Gezgin, Gary B. Parker</strong></p>
<p>We present Evo-Sparrow, a deep learning-based agent for AI decision-making in Sparrow Mahjong, trained by optimizing Long Short-Term Memory (LSTM) networks using Covariance Matrix Adaptation Evolution Strategy (CMA-ES). Our model evaluates board states and optimizes decision policies in a non-deterministic, partially observable game environment. Empirical analysis conducted over a significant number of simulations demonstrates that our model outperforms both random and rule-based agents, and achieves performance comparable to a Proximal Policy Optimization (PPO) baseline, indicating strong strategic play and robust policy quality. By combining deep learning with evolutionary optimization, our approach provides a computationally effective alternative to traditional reinforcement learning and gradient-based optimization methods. This research contributes to the broader field of AI game playing, demonstrating the viability of hybrid learning strategies for complex stochastic games. These findings also offer potential applications in adaptive decision-making and strategic AI development beyond Sparrow Mahjong. </p>
<blockquote>
<p>æˆ‘ä»¬ä»‹ç»äº†Evo-Sparrowï¼Œè¿™æ˜¯ä¸€ä¸ªåŸºäºæ·±åº¦å­¦ä¹ çš„Agentï¼Œç”¨äºåœ¨éº»å°†æ¸¸æˆä¸­è¿›è¡ŒAIå†³ç­–ã€‚è¯¥æ¨¡å‹é€šè¿‡ä¼˜åŒ–é•¿çŸ­æœŸè®°å¿†ï¼ˆLSTMï¼‰ç½‘ç»œï¼Œä½¿ç”¨åæ–¹å·®çŸ©é˜µè‡ªé€‚åº”è¿›åŒ–ç­–ç•¥ï¼ˆCMA-ESï¼‰è¿›è¡Œè®­ç»ƒã€‚æˆ‘ä»¬çš„æ¨¡å‹èƒ½å¤Ÿè¯„ä¼°æ£‹ç›˜çŠ¶æ€å¹¶åœ¨éç¡®å®šæ€§ã€éƒ¨åˆ†å¯è§‚å¯Ÿçš„æ¸¸æˆç¯å¢ƒä¸­ä¼˜åŒ–å†³ç­–ç­–ç•¥ã€‚é€šè¿‡å¯¹å¤§é‡æ¨¡æ‹Ÿçš„å®è¯åˆ†æè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ¨¡å‹åœ¨æ€§èƒ½å’Œè¡¨ç°ä¸Šéƒ½ä¼˜äºéšæœºå’ŒåŸºäºè§„åˆ™çš„Agentï¼Œå¹¶ä¸”æ€§èƒ½ä¸è¿‘ç«¯ç­–ç•¥ä¼˜åŒ–ï¼ˆPPOï¼‰åŸºçº¿ç›¸å½“ï¼Œè¡¨ç°å‡ºå¼ºå¤§çš„æˆ˜ç•¥æ€§å’Œç¨³å¥çš„ç­–ç•¥è´¨é‡ã€‚é€šè¿‡å°†æ·±åº¦å­¦ä¹ ä¸è¿›åŒ–ä¼˜åŒ–ç›¸ç»“åˆï¼Œæˆ‘ä»¬çš„æ–¹æ³•æä¾›äº†ä¸€ç§åœ¨è®¡ç®—ä¸Šæœ‰æ•ˆçš„æ›¿ä»£ä¼ ç»Ÿå¼ºåŒ–å­¦ä¹ å’ŒåŸºäºæ¢¯åº¦çš„ä¼˜åŒ–æ–¹æ³•ã€‚æœ¬ç ”ç©¶ä¸ºæ›´å¹¿æ³›çš„AIæ¸¸æˆé¢†åŸŸåšå‡ºäº†è´¡çŒ®ï¼Œè¯æ˜äº†æ··åˆå­¦ä¹ ç­–ç•¥å¯¹äºå¤æ‚éšæœºæ¸¸æˆçš„å¯è¡Œæ€§ã€‚æ­¤å¤–ï¼Œè¿™ä¸€å‘ç°è¿˜å¯èƒ½åœ¨è‡ªé€‚åº”å†³ç­–åˆ¶å®šå’Œéº»å°†ä»¥å¤–é¢†åŸŸçš„æˆ˜ç•¥å‹AIå¼€å‘ä¸­å¾—åˆ°æ½œåœ¨åº”ç”¨ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.07522v1">PDF</a> AAAI conference on Artificial Intelligence and Interactive Digital   Entertainment</p>
<p><strong>Summary</strong>ï¼š</p>
<p>Evo-Sparrowæ˜¯ä¸€æ¬¾åŸºäºæ·±åº¦å­¦ä¹ çš„éº»å°†å†³ç­–æ™ºèƒ½ä½“ï¼Œé€šè¿‡ä¼˜åŒ–LSTMç½‘ç»œå¹¶ä½¿ç”¨CMA-ESè¿›åŒ–ç­–ç•¥è¿›è¡Œè®­ç»ƒã€‚è¯¥æ¨¡å‹åœ¨éç¡®å®šæ€§ã€éƒ¨åˆ†å¯è§‚å¯Ÿçš„æ¸¸æˆç¯å¢ƒä¸­è¯„ä¼°æ£‹ç›˜çŠ¶æ€å¹¶ä¼˜åŒ–å†³ç­–ç­–ç•¥ã€‚æ¨¡æ‹Ÿå®éªŒè¡¨æ˜ï¼Œè¯¥æ¨¡å‹åœ¨æ€§èƒ½ä¸Šè¶…è¶Šäº†éšæœºå’ŒåŸºäºè§„åˆ™çš„ä¼ ç»Ÿæ™ºèƒ½ä½“ï¼Œå¹¶è¾¾åˆ°äº†ä¸PPOåŸºçº¿ç›¸å½“çš„æ°´å¹³ï¼Œå±•ç°äº†å¼ºå¤§çš„æˆ˜ç•¥èƒ½åŠ›å’Œç¨³å¥çš„ç­–ç•¥è´¨é‡ã€‚è¯¥ç ”ç©¶ç»“åˆäº†æ·±åº¦å­¦ä¹ ä¸è¿›åŒ–ä¼˜åŒ–ï¼Œä¸ºä¼ ç»Ÿå¼ºåŒ–å­¦ä¹ å’ŒåŸºäºæ¢¯åº¦çš„ä¼˜åŒ–æ–¹æ³•æä¾›äº†æœ‰æ•ˆçš„è®¡ç®—æ›¿ä»£æ–¹æ¡ˆã€‚è¯¥ç ”ç©¶ä¸ºå¤æ‚éšæœºæ¸¸æˆä¸­çš„æ··åˆå­¦ä¹ ç­–ç•¥æä¾›äº†å¯è¡Œæ€§è¯æ˜ï¼Œå¹¶åœ¨è‡ªé€‚åº”å†³ç­–å’Œæˆ˜ç•¥AIå¼€å‘é¢†åŸŸå…·æœ‰æ½œåœ¨åº”ç”¨ã€‚</p>
<p><strong>Key Takeaways</strong>ï¼š</p>
<ol>
<li>Evo-Sparrowæ˜¯ä¸€ä¸ªç»“åˆäº†æ·±åº¦å­¦ä¹ å’Œè¿›åŒ–ä¼˜åŒ–çš„æ™ºèƒ½ä½“ï¼Œç”¨äºéç¡®å®šæ€§æ¸¸æˆä¸­çš„å†³ç­–åˆ¶å®šã€‚</li>
<li>LSTMç½‘ç»œè¢«ç”¨äºå¤„ç†æ¸¸æˆä¸­çš„å¤æ‚æ•°æ®å¹¶ä¼˜åŒ–å†³ç­–ç­–ç•¥ã€‚</li>
<li>CMA-ESè¿›åŒ–ç­–ç•¥è¢«ç”¨äºè®­ç»ƒæ¨¡å‹ï¼Œä½¿å…¶åœ¨éƒ¨åˆ†å¯è§‚å¯Ÿçš„ç¯å¢ƒä¸­è¡¨ç°è‰¯å¥½ã€‚</li>
<li>æ¨¡æ‹Ÿå®éªŒè¯æ˜ï¼ŒEvo-Sparrowåœ¨æ€§èƒ½ä¸Šè¶…è¶Šäº†éšæœºå’ŒåŸºäºè§„åˆ™çš„ä¼ ç»Ÿæ™ºèƒ½ä½“ã€‚</li>
<li>Evo-Sparrowè¾¾åˆ°äº†ä¸PPOåŸºçº¿ç›¸å½“çš„æ€§èƒ½æ°´å¹³ï¼Œå±•ç°äº†å¼ºå¤§çš„æˆ˜ç•¥èƒ½åŠ›å’Œç¨³å¥çš„ç­–ç•¥è´¨é‡ã€‚</li>
<li>è¯¥ç ”ç©¶ä¸ºä¼ ç»Ÿå¼ºåŒ–å­¦ä¹ å’ŒåŸºäºæ¢¯åº¦çš„ä¼˜åŒ–æ–¹æ³•æä¾›äº†è®¡ç®—æ•ˆç‡æ›´é«˜çš„æ›¿ä»£æ–¹æ¡ˆã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.07522">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-1db34c94fdb156045cb41695222470e8.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-b83afc9d0c112a37db7895d271f23cab.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-62095b9201ca56e42585eebaa5afcc5f.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-b99aaf4ea78b30033b19c8bd431b8aa3.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a41dcd8952d06b34ad98fa908f3bdf78.jpg" align="middle">
</details>


<h1 id="-9"><a href="#-9" class="headerlink" title=""></a></h1><h2 id="CP-Agent-Agentic-Constraint-Programming"><a href="#CP-Agent-Agentic-Constraint-Programming" class="headerlink" title="CP-Agent: Agentic Constraint Programming"></a>CP-Agent: Agentic Constraint Programming</h2><p><strong>Authors:Stefan Szeider</strong></p>
<p>Translating natural language problem descriptions into formal constraint models remains a fundamental challenge in constraint programming, requiring deep expertise in both the problem domain and modeling frameworks. Previous approaches to automating this translation have employed fixed workflows with predetermined modeling steps, failing on a significant number of benchmark problems. We present a new approach using a pure agentic strategy without any fixed pipeline. We developed a general-purpose Python coding agent based on the ReAct (Reason and Act) principle, utilizing a persistent IPython kernel for stateful code execution and iterative development. Rather than embedding constraint programming logic into the agent architecture, domain-specific expertise is injected solely through a carefully crafted project prompt. The agent combines this prompt-encoded knowledge with access to file operations and code execution tools, enabling it to test hypotheses, debug failures, and verify solutions dynamically. Implemented in just a few hundred lines of code, this architecture successfully solves all 101 problems of the CP-Bench constraint programming benchmark set. The results suggest that constraint modeling tasks require the combination of general coding tools and domain expertise encoded in prompts, rather than specialized agent architectures or predefined workflows. </p>
<blockquote>
<p>å°†è‡ªç„¶è¯­è¨€é—®é¢˜æè¿°ç¿»è¯‘ä¸ºæ­£å¼çš„çº¦æŸæ¨¡å‹ä»ç„¶æ˜¯çº¦æŸç¼–ç¨‹ä¸­çš„ä¸€ä¸ªåŸºæœ¬æŒ‘æˆ˜ï¼Œè¿™éœ€è¦æ·±å…¥çš„é—®é¢˜é¢†åŸŸå’Œå»ºæ¨¡æ¡†æ¶çš„ä¸“ä¸šçŸ¥è¯†ã€‚ä¹‹å‰è‡ªåŠ¨åŒ–æ­¤ç¿»è¯‘çš„æ–¹æ³•é‡‡ç”¨äº†å…·æœ‰é¢„å®šå»ºæ¨¡æ­¥éª¤çš„å›ºå®šå·¥ä½œæµç¨‹ï¼Œæ— æ³•åœ¨å¤§é‡åŸºå‡†é—®é¢˜ä¸Šå–å¾—æˆåŠŸã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°çš„æ–¹æ³•ï¼Œé‡‡ç”¨çº¯ç²¹çš„ä»£ç†ç­–ç•¥ï¼Œæ²¡æœ‰ä»»ä½•å›ºå®šæµç¨‹ã€‚æˆ‘ä»¬å¼€å‘äº†ä¸€ä¸ªåŸºäºReActï¼ˆæ¨ç†ä¸è¡ŒåŠ¨ï¼‰åŸç†çš„é€šç”¨Pythonç¼–ç ä»£ç†ï¼Œåˆ©ç”¨æŒä¹…çš„IPythonå†…æ ¸è¿›è¡ŒçŠ¶æ€åŒ–çš„ä»£ç æ‰§è¡Œå’Œè¿­ä»£å¼€å‘ã€‚æˆ‘ä»¬ä¸æ˜¯å°†çº¦æŸç¼–ç¨‹é€»è¾‘åµŒå…¥åˆ°ä»£ç†æ¶æ„ä¸­ï¼Œè€Œæ˜¯ä»…é€šè¿‡ç²¾å¿ƒè®¾è®¡çš„é¡¹ç›®æç¤ºæ³¨å…¥é¢†åŸŸä¸“ä¸šçŸ¥è¯†ã€‚è¯¥ä»£ç†ç»“åˆäº†æç¤ºç¼–ç çš„çŸ¥è¯†ä»¥åŠæ–‡ä»¶æ“ä½œå’Œä»£ç æ‰§è¡Œå·¥å…·çš„è®¿é—®æƒé™ï¼Œèƒ½å¤ŸåŠ¨æ€åœ°æµ‹è¯•å‡è®¾ã€è°ƒè¯•æ•…éšœå¹¶éªŒè¯è§£å†³æ–¹æ¡ˆã€‚è¿™ä¸ªæ¶æ„ä»…åœ¨æ•°ç™¾è¡Œä»£ç ä¸­å®ç°ï¼ŒæˆåŠŸè§£å†³äº†CP-Benchçº¦æŸç¼–ç¨‹åŸºå‡†æµ‹è¯•é›†ä¸­çš„æ‰€æœ‰101ä¸ªé—®é¢˜ã€‚ç»“æœè¡¨æ˜ï¼Œçº¦æŸå»ºæ¨¡ä»»åŠ¡éœ€è¦é€šç”¨ç¼–ç å·¥å…·ä¸æç¤ºä¸­ç¼–ç çš„åŸŸä¸“ä¸šçŸ¥è¯†çš„ç»“åˆï¼Œè€Œä¸æ˜¯ç‰¹æ®Šçš„ä»£ç†æ¶æ„æˆ–é¢„å…ˆå®šä¹‰çš„å·¥ä½œæµç¨‹ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.07468v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä¸»è¦ä»‹ç»äº†ä¸€ç§æ–°çš„è‡ªç„¶è¯­è¨€é—®é¢˜æè¿°ç¿»è¯‘æˆçº¦æŸæ¨¡å‹çš„æ–¹æ³•ï¼Œä½¿ç”¨åŸºäºReActåŸç†çš„Pythonç¼–ç ä»£ç†ï¼Œé€šè¿‡é¡¹ç›®æç¤ºæ³¨å…¥é¢†åŸŸä¸“ä¸šçŸ¥è¯†ï¼ŒæˆåŠŸè§£å†³äº†CP-Benchçº¦æŸç¼–ç¨‹åŸºå‡†æµ‹è¯•é›†ä¸­çš„æ‰€æœ‰é—®é¢˜ã€‚è¯¥æ–¹æ³•å¼ºè°ƒäº†çº¦æŸå»ºæ¨¡ä»»åŠ¡éœ€è¦ç»“åˆä¸€èˆ¬ç¼–ç¨‹å·¥å…·å’Œé¢†åŸŸä¸“ä¸šçŸ¥è¯†ï¼Œè€Œéç‰¹å®šä»£ç†æ¶æ„æˆ–é¢„å…ˆå®šä¹‰çš„å·¥ä½œæµç¨‹ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>è‡ªç„¶è¯­è¨€é—®é¢˜ç¿»è¯‘åˆ°çº¦æŸæ¨¡å‹æ˜¯çº¦æŸç¼–ç¨‹ä¸­çš„æ ¸å¿ƒæŒ‘æˆ˜ï¼Œéœ€è¦é¢†åŸŸçŸ¥è¯†å’Œå»ºæ¨¡æ¡†æ¶çš„åŒé‡ä¸“é•¿ã€‚</li>
<li>ç°æœ‰è‡ªåŠ¨åŒ–ç¿»è¯‘æ–¹æ³•é‡‡ç”¨å›ºå®šå·¥ä½œæµç¨‹å’Œé¢„å®šå»ºæ¨¡æ­¥éª¤ï¼Œæ— æ³•åœ¨å¤§é‡åŸºå‡†é—®é¢˜ä¸Šå–å¾—è‰¯å¥½æ•ˆæœã€‚</li>
<li>æå‡ºäº†ä¸€ç§æ–°çš„åŸºäºReActåŸç†çš„çº¯ä»£ç†ç­–ç•¥ï¼Œä¸ä½¿ç”¨ä»»ä½•å›ºå®šæµç¨‹ã€‚</li>
<li>å¼€å‘äº†åŸºäºPythonçš„é€šç”¨ç¼–ç ä»£ç†ï¼Œåˆ©ç”¨æŒä¹…IPythonå†…æ ¸è¿›è¡ŒçŠ¶æ€ä»£ç æ‰§è¡Œå’Œè¿­ä»£å¼€å‘ã€‚</li>
<li>ä»£ç†é€šè¿‡ç²¾å¿ƒæ„å»ºçš„é¡¹ç›®æç¤ºæ³¨å…¥é¢†åŸŸä¸“ä¸šçŸ¥è¯†ï¼Œç»“åˆæ–‡ä»¶æ“ä½œå’Œä»£ç æ‰§è¡Œå·¥å…·ï¼Œå®ç°åŠ¨æ€æµ‹è¯•å‡è®¾ã€è°ƒè¯•å¤±è´¥å’ŒéªŒè¯è§£å†³æ–¹æ¡ˆã€‚</li>
<li>è¯¥æ¶æ„ä»…åœ¨æ•°ç™¾è¡Œä»£ç ä¸­å®ç°ï¼ŒæˆåŠŸè§£å†³äº†CP-Benchçº¦æŸç¼–ç¨‹åŸºå‡†æµ‹è¯•é›†ä¸­çš„æ‰€æœ‰é—®é¢˜ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.07468">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-e00d38c6ec450859c2c79d522b7b62fd.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-b2c388d90d819204ea920a72c07643f1.jpg" align="middle">
</details>


<h1 id="-10"><a href="#-10" class="headerlink" title=""></a></h1><h2 id="WebWatcher-Breaking-New-Frontier-of-Vision-Language-Deep-Research-Agent"><a href="#WebWatcher-Breaking-New-Frontier-of-Vision-Language-Deep-Research-Agent" class="headerlink" title="WebWatcher: Breaking New Frontier of Vision-Language Deep Research Agent"></a>WebWatcher: Breaking New Frontier of Vision-Language Deep Research Agent</h2><p><strong>Authors:Xinyu Geng, Peng Xia, Zhen Zhang, Xinyu Wang, Qiuchen Wang, Ruixue Ding, Chenxi Wang, Jialong Wu, Yida Zhao, Kuan Li, Yong Jiang, Pengjun Xie, Fei Huang, Jingren Zhou</strong></p>
<p>Web agents such as Deep Research have demonstrated superhuman cognitive abilities, capable of solving highly challenging information-seeking problems. However, most research remains primarily text-centric, overlooking visual information in the real world. This makes multimodal Deep Research highly challenging, as such agents require much stronger reasoning abilities in perception, logic, knowledge, and the use of more sophisticated tools compared to text-based agents. To address this limitation, we introduce WebWatcher, a multi-modal Agent for Deep Research equipped with enhanced visual-language reasoning capabilities. It leverages high-quality synthetic multimodal trajectories for efficient cold start training, utilizes various tools for deep reasoning, and further enhances generalization through reinforcement learning. To better evaluate the capabilities of multimodal agents, we propose BrowseComp-VL, a benchmark with BrowseComp-style that requires complex information retrieval involving both visual and textual information. Experimental results show that WebWatcher significantly outperforms proprietary baseline, RAG workflow and open-source agents in four challenging VQA benchmarks, which paves the way for solving complex multimodal information-seeking tasks. </p>
<blockquote>
<p>Deep Researchç­‰ç½‘ç»œæ™ºèƒ½ä½“å·²ç»å±•ç°å‡ºè¶…äººçš„è®¤çŸ¥èƒ½åŠ›ï¼Œèƒ½å¤Ÿè§£å†³å…·æœ‰é«˜åº¦æŒ‘æˆ˜æ€§çš„ä¿¡æ¯æœç´¢é—®é¢˜ã€‚ç„¶è€Œï¼Œå¤§å¤šæ•°ç ”ç©¶ä»ç„¶ä¸»è¦é›†ä¸­åœ¨æ–‡æœ¬ä¸Šï¼Œå¿½è§†äº†ç°å®ä¸–ç•Œä¸­çš„è§†è§‰ä¿¡æ¯ã€‚è¿™ä½¿å¾—å¤šæ¨¡æ€æ·±åº¦ç ”ç©¶é¢ä¸´å·¨å¤§æŒ‘æˆ˜ï¼Œå› ä¸ºä¸åŸºäºæ–‡æœ¬çš„æ™ºèƒ½ä½“ç›¸æ¯”ï¼Œæ­¤ç±»æ™ºèƒ½ä½“éœ€è¦åœ¨æ„ŸçŸ¥ã€é€»è¾‘ã€çŸ¥è¯†ç­‰æ–¹é¢å…·å¤‡æ›´å¼ºçš„æ¨ç†èƒ½åŠ›ï¼Œå¹¶ä½¿ç”¨æ›´å…ˆè¿›çš„å·¥å…·ã€‚ä¸ºäº†è§£å†³è¿™ä¸€å±€é™æ€§ï¼Œæˆ‘ä»¬å¼•å…¥äº†WebWatcherï¼Œè¿™æ˜¯ä¸€ä¸ªä¸ºæ·±åº¦ç ”ç©¶è®¾è®¡çš„å¤šæ¨¡æ€æ™ºèƒ½ä½“ï¼Œå…·å¤‡å¢å¼ºçš„è§†è§‰è¯­è¨€æ¨ç†èƒ½åŠ›ã€‚å®ƒåˆ©ç”¨é«˜è´¨é‡åˆæˆå¤šæ¨¡æ€è½¨è¿¹è¿›è¡Œé«˜æ•ˆå†·å¯åŠ¨è®­ç»ƒï¼Œä½¿ç”¨å„ç§å·¥å…·è¿›è¡Œæ·±å…¥æ¨ç†ï¼Œå¹¶é€šè¿‡å¼ºåŒ–å­¦ä¹ è¿›ä¸€æ­¥æé«˜æ³›åŒ–èƒ½åŠ›ã€‚ä¸ºäº†æ›´å¥½åœ°è¯„ä¼°å¤šæ¨¡æ€æ™ºèƒ½ä½“çš„èƒ½åŠ›ï¼Œæˆ‘ä»¬æå‡ºäº†BrowseComp-VLåŸºå‡†æµ‹è¯•ï¼Œè¿™æ˜¯ä¸€ä¸ªéœ€è¦æ¶‰åŠè§†è§‰å’Œæ–‡æœ¬ä¿¡æ¯çš„å¤æ‚ä¿¡æ¯æ£€ç´¢çš„BrowseCompé£æ ¼åŸºå‡†æµ‹è¯•ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒWebWatcheråœ¨å››ä¸ªå…·æœ‰æŒ‘æˆ˜æ€§çš„è§†è§‰é—®ç­”åŸºå‡†æµ‹è¯•ä¸­æ˜¾è‘—ä¼˜äºä¸“æœ‰åŸºçº¿ã€RAGå·¥ä½œæµå’Œå¼€æºæ™ºèƒ½ä½“ï¼Œè¿™ä¸ºè§£å†³å¤æ‚çš„è·¨æ¨¡æ€ä¿¡æ¯æœç´¢ä»»åŠ¡å¥ å®šäº†åŸºç¡€ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.05748v2">PDF</a> </p>
<p><strong>Summary</strong><br>æ·±åº¦ç ”ç©¶ç½‘ç»œä»£ç†å¦‚Deep Researchå±•ç°å‡ºè¶…äººè®¤çŸ¥åŠ›ï¼Œèƒ½è§£å†³é«˜éš¾åº¦ä¿¡æ¯æœå¯»é—®é¢˜ã€‚ç„¶è€Œï¼Œç°æœ‰ç ”ç©¶å¤šèšç„¦äºæ–‡æœ¬ä¿¡æ¯ï¼Œå¿½è§†ç°å®ä¸–ç•Œä¸­çš„è§†è§‰ä¿¡æ¯ï¼Œå¯¼è‡´å¤šæ¨¡æ€æ·±åº¦ç ”ç©¶é¢ä¸´æŒ‘æˆ˜ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬æ¨å‡ºå…·å¤‡å¢å¼ºè§†è§‰è¯­è¨€æ¨ç†èƒ½åŠ›çš„å¤šæ¨¡æ€æ·±åº¦ç ”ç©¶ä»£ç†WebWatcherï¼Œå…¶åˆ©ç”¨é«˜è´¨é‡åˆæˆå¤šæ¨¡æ€è½¨è¿¹è¿›è¡Œé«˜æ•ˆå†·å¯åŠ¨è®­ç»ƒï¼Œä½¿ç”¨å¤šç§å·¥å…·è¿›è¡Œæ·±åº¦æ¨ç†ï¼Œå¹¶é€šè¿‡å¼ºåŒ–å­¦ä¹ æé«˜æ³›åŒ–èƒ½åŠ›ã€‚ä¸ºè¯„ä¼°å¤šæ¨¡æ€ä»£ç†èƒ½åŠ›ï¼Œæˆ‘ä»¬æå‡ºåŒ…å«è§†è§‰å’Œæ–‡æœ¬ä¿¡æ¯çš„å¤æ‚ä¿¡æ¯æ£€ç´¢åŸºå‡†æµ‹è¯•BrowseComp-VLã€‚å®éªŒç»“æœæ˜¾ç¤ºWebWatcheråœ¨å››é¡¹æŒ‘æˆ˜å‹è§†è§‰é—®ç­”åŸºå‡†æµ‹è¯•ä¸­æ˜¾è‘—ä¼˜äºä¸“æœ‰åŸºçº¿ã€RAGå·¥ä½œæµå’Œå¼€æºä»£ç†ï¼Œä¸ºå¤æ‚å¤šæ¨¡æ€ä¿¡æ¯æœå¯»ä»»åŠ¡æä¾›äº†è§£å†³æ–¹æ¡ˆã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>Webä»£ç†å¦‚Deep Researchå…·æœ‰è¶…äººè®¤çŸ¥åŠ›ï¼Œå¯è§£å†³é«˜éš¾åº¦ä¿¡æ¯æœå¯»é—®é¢˜ã€‚</li>
<li>å½“å‰ç ”ç©¶è¿‡äºä¾èµ–æ–‡æœ¬ä¿¡æ¯ï¼Œå¿½è§†è§†è§‰ä¿¡æ¯ï¼Œå¯¼è‡´å¤šæ¨¡æ€æ·±åº¦ç ”ç©¶æŒ‘æˆ˜ã€‚</li>
<li>WebWatcherä»£ç†å…·å¤‡å¢å¼ºè§†è§‰è¯­è¨€æ¨ç†èƒ½åŠ›ï¼Œåˆ©ç”¨åˆæˆå¤šæ¨¡æ€è½¨è¿¹è¿›è¡Œå†·å¯åŠ¨è®­ç»ƒã€‚</li>
<li>WebWatcherä½¿ç”¨å¤šç§å·¥å…·è¿›è¡Œæ·±åº¦æ¨ç†ï¼Œå¹¶é€šè¿‡å¼ºåŒ–å­¦ä¹ æé«˜æ³›åŒ–èƒ½åŠ›ã€‚</li>
<li>ä¸ºè¯„ä¼°å¤šæ¨¡æ€ä»£ç†èƒ½åŠ›ï¼Œæ¨å‡ºåŸºå‡†æµ‹è¯•BrowseComp-VLï¼ŒåŒ…å«è§†è§‰å’Œæ–‡æœ¬ä¿¡æ¯çš„å¤æ‚ä¿¡æ¯æ£€ç´¢ã€‚</li>
<li>WebWatcheråœ¨å¤šé¡¹è§†è§‰é—®ç­”åŸºå‡†æµ‹è¯•ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œæ˜¾è‘—ä¼˜äºå…¶ä»–ä»£ç†ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.05748">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-0e56590de784c74d92dba63fbfe976c0.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-42e172a7439a4d1e6895db200cdacce2.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-1806ad7a8042101142af4de27f2f34b0.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-958a8aac9af03c956ddb7532465ee158.jpg" align="middle">
</details>


<h1 id="-11"><a href="#-11" class="headerlink" title=""></a></h1><h2 id="MV-Debate-Multi-view-Agent-Debate-with-Dynamic-Reflection-Gating-for-Multimodal-Harmful-Content-Detection-in-Social-Media"><a href="#MV-Debate-Multi-view-Agent-Debate-with-Dynamic-Reflection-Gating-for-Multimodal-Harmful-Content-Detection-in-Social-Media" class="headerlink" title="MV-Debate: Multi-view Agent Debate with Dynamic Reflection Gating for   Multimodal Harmful Content Detection in Social Media"></a>MV-Debate: Multi-view Agent Debate with Dynamic Reflection Gating for   Multimodal Harmful Content Detection in Social Media</h2><p><strong>Authors:Rui Lu, Jinhe Bi, Yunpu Ma, Feng Xiao, Yuntao Du, Yijun Tian</strong></p>
<p>Social media has evolved into a complex multimodal environment where text, images, and other signals interact to shape nuanced meanings, often concealing harmful intent. Identifying such intent, whether sarcasm, hate speech, or misinformation, remains challenging due to cross-modal contradictions, rapid cultural shifts, and subtle pragmatic cues. To address these challenges, we propose MV-Debate, a multi-view agent debate framework with dynamic reflection gating for unified multimodal harmful content detection. MV-Debate assembles four complementary debate agents, a surface analyst, a deep reasoner, a modality contrast, and a social contextualist, to analyze content from diverse interpretive perspectives. Through iterative debate and reflection, the agents refine responses under a reflection-gain criterion, ensuring both accuracy and efficiency. Experiments on three benchmark datasets demonstrate that MV-Debate significantly outperforms strong single-model and existing multi-agent debate baselines. This work highlights the promise of multi-agent debate in advancing reliable social intent detection in safety-critical online contexts. </p>
<blockquote>
<p>ç¤¾äº¤åª’ä½“å·²ç»æ¼”å˜ä¸ºä¸€ä¸ªå¤æ‚çš„å¤šåª’ä½“ç¯å¢ƒï¼Œæ–‡æœ¬ã€å›¾åƒå’Œå…¶ä»–ä¿¡å·åœ¨æ­¤ç¯å¢ƒä¸­ç›¸äº’ä½œç”¨ï¼Œå½¢æˆå¾®å¦™çš„å«ä¹‰ï¼Œå¸¸å¸¸éšè—æœ‰å®³çš„æ„å›¾ã€‚è¯†åˆ«è¿™ç§æ„å›¾ï¼Œæ— è®ºæ˜¯è®½åˆºã€ä»‡æ¨è¨€è®ºè¿˜æ˜¯é”™è¯¯ä¿¡æ¯ï¼Œä»ç„¶æ˜¯ä¸€ä¸ªæŒ‘æˆ˜ï¼ŒåŸå› åœ¨äºè·¨æ¨¡æ€çš„çŸ›ç›¾ã€å¿«é€Ÿçš„æ–‡åŒ–å˜è¿å’Œå¾®å¦™çš„è¯­ç”¨çº¿ç´¢ã€‚ä¸ºäº†è§£å†³è¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†MV-Debateï¼Œè¿™æ˜¯ä¸€ä¸ªå…·æœ‰åŠ¨æ€åå°„é—¨æ§çš„å¤šè§†å›¾ä»£ç†è¾©è®ºæ¡†æ¶ï¼Œç”¨äºç»Ÿä¸€çš„å¤šæ¨¡å¼æœ‰å®³å†…å®¹æ£€æµ‹ã€‚MV-Debateé›†æˆäº†å››ç§äº’è¡¥çš„è¾©è®ºä»£ç†ï¼ŒåŒ…æ‹¬è¡¨é¢åˆ†æå¸ˆã€æ·±åº¦æ¨ç†è€…ã€æ¨¡æ€å¯¹æ¯”å™¨å’Œç¤¾ä¼šè¯­å¢ƒä¸»ä¹‰è€…ï¼Œä»¥ä»å¤šç§è§£é‡Šæ€§è§†è§’åˆ†æå†…å®¹ã€‚é€šè¿‡è¿­ä»£è¾©è®ºå’Œåæ€ï¼Œä»£ç†åœ¨åæ€å¢ç›Šæ ‡å‡†ä¸‹å®Œå–„å›åº”ï¼Œç¡®ä¿å‡†ç¡®æ€§å’Œæ•ˆç‡ã€‚åœ¨ä¸‰ä¸ªåŸºå‡†æ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒMV-Debateæ˜¾è‘—ä¼˜äºå¼ºå¤§çš„å•æ¨¡å‹å’Œç°æœ‰çš„å¤šä»£ç†è¾©è®ºåŸºçº¿ã€‚è¿™é¡¹å·¥ä½œå¼ºè°ƒäº†å¤šä»£ç†è¾©è®ºåœ¨æ¨è¿›å®‰å…¨å…³é”®åœ¨çº¿ç¯å¢ƒä¸‹çš„å¯é ç¤¾ä¼šæ„å›¾æ£€æµ‹æ–¹é¢çš„å‰æ™¯ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.05557v2">PDF</a> </p>
<p><strong>Summary</strong><br>ç¤¾äº¤åª’ä½“çš„å¤æ‚å¤šåª’ä½“ç¯å¢ƒä¸­æ–‡æœ¬ã€å›¾åƒç­‰ä¿¡å·ç›¸äº’ä½œç”¨ï¼Œäº§ç”Ÿå¾®å¦™çš„å«ä¹‰ï¼Œå¸¸å¸¸éšè—æœ‰å®³æ„å›¾ã€‚è¯†åˆ«è¿™ç§æ„å›¾ï¼ˆå¦‚è®½åˆºã€ä»‡æ¨è¨€è®ºæˆ–è™šå‡ä¿¡æ¯ï¼‰å……æ»¡æŒ‘æˆ˜ï¼Œå› ä¸ºå­˜åœ¨è·¨æ¨¡æ€çŸ›ç›¾ã€æ–‡åŒ–å¿«é€Ÿå˜è¿å’Œå¾®å¦™çš„è¯­ç”¨çº¿ç´¢ã€‚æœ¬ç ”ç©¶æå‡ºäº†MV-Debateå¤šè§†è§’è¾©è®ºæ¡†æ¶ï¼Œé‡‡ç”¨åŠ¨æ€åæ€é—¨æ§æŠ€æœ¯ï¼Œç”¨äºç»Ÿä¸€å¤šåª’ä½“æœ‰å®³å†…å®¹æ£€æµ‹ã€‚MV-Debateé›†ç»“äº†å››ç§äº’è¡¥çš„è¾©è®ºæ™ºèƒ½ä½“ï¼ŒåŒ…æ‹¬è¡¨é¢åˆ†æå¸ˆã€æ·±åº¦æ¨ç†è€…ã€æ¨¡æ€å¯¹æ¯”å™¨å’Œç¤¾ä¼šè¯­å¢ƒä¸“å®¶ï¼Œä»ä¸åŒè§’åº¦è§£æå†…å®¹ã€‚é€šè¿‡è¿­ä»£è¾©è®ºå’Œåæ€ï¼Œæ™ºèƒ½ä½“åœ¨åæ€å¢ç›Šæ ‡å‡†ä¸‹ä¼˜åŒ–å“åº”ï¼Œç¡®ä¿å‡†ç¡®æ€§å’Œæ•ˆç‡ã€‚åœ¨ä¸‰ä¸ªåŸºå‡†æ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒMV-Debateæ˜¾è‘—ä¼˜äºå¼ºå¤§çš„å•æ¨¡å‹å’Œå¤šæ™ºèƒ½ä½“è¾©è®ºåŸºçº¿ã€‚æœ¬ç ”ç©¶çªæ˜¾äº†å¤šæ™ºèƒ½ä½“è¾©è®ºåœ¨æ¨è¿›åœ¨çº¿å®‰å…¨ç¯å¢ƒä¸­çš„å¯é ç¤¾ä¼šæ„å›¾æ£€æµ‹æ–¹é¢çš„æ½œåŠ›ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ç¤¾äº¤åª’ä½“å·²æ¼”å˜ä¸ºä¸€ä¸ªå¤æ‚çš„å¤šåª’ä½“ç¯å¢ƒï¼Œå…¶ä¸­æ–‡æœ¬ã€å›¾åƒç­‰ä¿¡å·ç›¸äº’ä½œç”¨äº§ç”Ÿå¾®å¦™çš„å«ä¹‰ï¼Œå¯èƒ½éšè—æœ‰å®³æ„å›¾ã€‚</li>
<li>è¯†åˆ«è¿™äº›æœ‰å®³æ„å›¾ï¼ˆå¦‚è®½åˆºã€ä»‡æ¨è¨€è®ºå’Œè™šå‡ä¿¡æ¯ï¼‰å…·æœ‰æŒ‘æˆ˜æ€§ï¼ŒåŸå› æ˜¯è·¨æ¨¡æ€çŸ›ç›¾ã€æ–‡åŒ–å¿«é€Ÿå˜è¿å’Œå¾®å¦™çš„è¯­ç”¨çº¿ç´¢ã€‚</li>
<li>MV-Debateæ˜¯ä¸€ä¸ªå¤šè§†è§’çš„è¾©è®ºæ¡†æ¶ï¼ŒåŒ…å«å››ä¸ªäº’è¡¥çš„è¾©è®ºæ™ºèƒ½ä½“ï¼Œç”¨äºç»Ÿä¸€åˆ†æå¤šåª’ä½“å†…å®¹ã€‚</li>
<li>MV-Debateé€šè¿‡è¿­ä»£è¾©è®ºå’Œåæ€ä¼˜åŒ–å“åº”ï¼Œç¡®ä¿å‡†ç¡®æ€§å’Œæ•ˆç‡ã€‚</li>
<li>å®éªŒè¡¨æ˜ï¼ŒMV-Debateåœ¨ä¸‰ä¸ªåŸºå‡†æ•°æ®é›†ä¸Šçš„æ€§èƒ½æ˜¾è‘—ä¼˜äºå•æ¨¡å‹å’Œå…¶ä»–å¤šæ™ºèƒ½ä½“è¾©è®ºæ–¹æ³•ã€‚</li>
<li>MV-Debateæ¡†æ¶å…·æœ‰æ½œåŠ›æ¨è¿›åœ¨çº¿å®‰å…¨ç¯å¢ƒä¸­çš„ç¤¾ä¼šæ„å›¾æ£€æµ‹çš„å¯é æ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.05557">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-3cef351eb026421d2f9a698fd26cab9b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-9687c24758f0d6cc2bbd34e16beb022b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-fe227313b697f8ef6630d0cca633b67d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-5c61bbaf5207d6c0f9b49ecda64b2bcb.jpg" align="middle">
</details>


<h1 id="-12"><a href="#-12" class="headerlink" title=""></a></h1><h2 id="ARAG-Agentic-Retrieval-Augmented-Generation-for-Personalized-Recommendation"><a href="#ARAG-Agentic-Retrieval-Augmented-Generation-for-Personalized-Recommendation" class="headerlink" title="ARAG: Agentic Retrieval Augmented Generation for Personalized   Recommendation"></a>ARAG: Agentic Retrieval Augmented Generation for Personalized   Recommendation</h2><p><strong>Authors:Reza Yousefi Maragheh, Pratheek Vadla, Priyank Gupta, Kai Zhao, Aysenur Inan, Kehui Yao, Jianpeng Xu, Praveen Kanumala, Jason Cho, Sushant Kumar</strong></p>
<p>Retrieval-Augmented Generation (RAG) has shown promise in enhancing recommendation systems by incorporating external context into large language model prompts. However, existing RAG-based approaches often rely on static retrieval heuristics and fail to capture nuanced user preferences in dynamic recommendation scenarios. In this work, we introduce ARAG, an Agentic Retrieval-Augmented Generation framework for Personalized Recommendation, which integrates a multi-agent collaboration mechanism into the RAG pipeline. To better understand the long-term and session behavior of the user, ARAG leverages four specialized LLM-based agents: a User Understanding Agent that summarizes user preferences from long-term and session contexts, a Natural Language Inference (NLI) Agent that evaluates semantic alignment between candidate items retrieved by RAG and inferred intent, a context summary agent that summarizes the findings of NLI agent, and an Item Ranker Agent that generates a ranked list of recommendations based on contextual fit. We evaluate ARAG accross three datasets. Experimental results demonstrate that ARAG significantly outperforms standard RAG and recency-based baselines, achieving up to 42.1% improvement in NDCG@5 and 35.5% in Hit@5. We also, conduct an ablation study to analyse the effect by different components of ARAG. Our findings highlight the effectiveness of integrating agentic reasoning into retrieval-augmented recommendation and provide new directions for LLM-based personalization. </p>
<blockquote>
<p>æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰é€šè¿‡å°†å¤–éƒ¨ä¸Šä¸‹æ–‡èå…¥å¤§å‹è¯­è¨€æ¨¡å‹æç¤ºï¼Œåœ¨å¢å¼ºæ¨èç³»ç»Ÿæ–¹é¢æ˜¾ç¤ºå‡ºå·¨å¤§æ½œåŠ›ã€‚ç„¶è€Œï¼Œç°æœ‰çš„åŸºäºRAGçš„æ–¹æ³•å¸¸å¸¸ä¾èµ–äºé™æ€æ£€ç´¢å¯å‘å¼ç­–ç•¥ï¼Œæ— æ³•åœ¨åŠ¨æ€æ¨èåœºæ™¯ä¸­æ•æ‰å¾®å¦™çš„ç”¨æˆ·åå¥½ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬ä»‹ç»äº†ARAGï¼Œä¸€ä¸ªç”¨äºä¸ªæ€§åŒ–æ¨èçš„Agenticæ£€ç´¢å¢å¼ºç”Ÿæˆæ¡†æ¶ï¼Œå®ƒå°†å¤šæ™ºèƒ½ä½“åä½œæœºåˆ¶æ•´åˆåˆ°RAGç®¡é“ä¸­ã€‚ä¸ºäº†æ›´å¥½åœ°ç†è§£ç”¨æˆ·çš„é•¿æœŸå’Œä¼šè¯è¡Œä¸ºï¼ŒARAGåˆ©ç”¨å››ä¸ªåŸºäºLLMçš„ä¸“ç”¨æ™ºèƒ½ä½“ï¼šä¸€ä¸ªç†è§£ç”¨æˆ·æ™ºèƒ½ä½“ï¼Œå®ƒæ€»ç»“æ¥è‡ªé•¿æœŸå’Œä¼šè¯è¯­å¢ƒçš„ç”¨æˆ·åå¥½ï¼›ä¸€ä¸ªè‡ªç„¶è¯­è¨€æ¨ç†ï¼ˆNLIï¼‰æ™ºèƒ½ä½“ï¼Œå®ƒè¯„ä¼°ç”±RAGæ£€ç´¢çš„å€™é€‰ç‰©å“ä¸æ¨æ–­æ„å›¾ä¹‹é—´çš„è¯­ä¹‰å¯¹é½ï¼›ä¸€ä¸ªä¸Šä¸‹æ–‡æ‘˜è¦æ™ºèƒ½ä½“ï¼Œå®ƒæ€»ç»“NLIæ™ºèƒ½ä½“çš„å‘ç°ï¼›ä»¥åŠä¸€ä¸ªé¡¹ç›®æ’åæ™ºèƒ½ä½“ï¼Œå®ƒæ ¹æ®ä¸Šä¸‹æ–‡å…¼å®¹æ€§ç”Ÿæˆæ’åæ¨èåˆ—è¡¨ã€‚æˆ‘ä»¬åœ¨ä¸‰ä¸ªæ•°æ®é›†ä¸Šè¯„ä¼°ARAGã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒARAGæ˜¾è‘—ä¼˜äºæ ‡å‡†RAGå’ŒåŸºäºæ—¶æ•ˆæ€§çš„åŸºå‡†çº¿ï¼Œåœ¨NDCG@5ä¸Šæé«˜äº†42.1%ï¼Œåœ¨Hit@5ä¸Šæé«˜äº†35.5%ã€‚æˆ‘ä»¬è¿˜è¿›è¡Œäº†ä¸€é¡¹æ¶ˆèç ”ç©¶ï¼Œåˆ†æARAGä¸åŒç»„æˆéƒ¨åˆ†çš„å½±å“ã€‚æˆ‘ä»¬çš„ç ”ç©¶ç»“æœçªå‡ºäº†å°†æ™ºèƒ½ä½“æ¨ç†æ•´åˆåˆ°æ£€ç´¢å¢å¼ºæ¨èä¸­çš„æœ‰æ•ˆæ€§ï¼Œå¹¶ä¸ºåŸºäºLLMçš„ä¸ªæ€§åŒ–æä¾›äº†æ–°æ–¹å‘ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.21931v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†ARAGï¼ˆAgentic Retrieval-Augmented Generationæ¡†æ¶ï¼‰åœ¨ä¸ªæ€§åŒ–æ¨èç³»ç»Ÿä¸­çš„åº”ç”¨ã€‚ARAGé€šè¿‡å¤šæ™ºèƒ½ä½“åä½œæœºåˆ¶ï¼Œå°†å¤–éƒ¨ä¸Šä¸‹æ–‡èå…¥å¤§å‹è¯­è¨€æ¨¡å‹æç¤ºä¸­ï¼Œå¢å¼ºäº†æ¨èç³»ç»Ÿçš„æ€§èƒ½ã€‚é€šè¿‡å››ä¸ªåŸºäºLLMçš„æ™ºèƒ½ä½“ï¼ˆç”¨æˆ·ç†è§£æ™ºèƒ½ä½“ã€è‡ªç„¶è¯­è¨€æ¨ç†æ™ºèƒ½ä½“ã€ä¸Šä¸‹æ–‡æ‘˜è¦æ™ºèƒ½ä½“å’Œé¡¹ç›®æ’åæ™ºèƒ½ä½“ï¼‰ï¼ŒARAGèƒ½å¤Ÿæ›´å¥½åœ°ç†è§£ç”¨æˆ·çš„é•¿æœŸå’Œä¼šè¯è¡Œä¸ºï¼Œå¹¶ç”ŸæˆåŸºäºä¸Šä¸‹æ–‡åŒ¹é…çš„æ’åæ¨èã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒARAGåœ¨NDCG@5å’ŒHit@5æŒ‡æ ‡ä¸Šåˆ†åˆ«æé«˜äº†42.1%å’Œ35.5%ï¼Œæ˜¾è‘—ä¼˜äºæ ‡å‡†RAGå’ŒåŸºäºæ—¶æ•ˆæ€§çš„åŸºå‡†æµ‹è¯•ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ARAGæ˜¯ä¸€ä¸ªåŸºäºæ™ºèƒ½ä½“çš„æ£€ç´¢å¢å¼ºç”Ÿæˆæ¡†æ¶ï¼Œç”¨äºä¸ªæ€§åŒ–æ¨èç³»ç»Ÿã€‚</li>
<li>ARAGé€šè¿‡å¤šæ™ºèƒ½ä½“åä½œæœºåˆ¶ï¼Œå°†å¤–éƒ¨ä¸Šä¸‹æ–‡èå…¥å¤§å‹è¯­è¨€æ¨¡å‹æç¤ºä¸­ã€‚</li>
<li>ARAGåŒ…æ‹¬å››ä¸ªåŸºäºLLMçš„æ™ºèƒ½ä½“ï¼Œç”¨äºç†è§£ç”¨æˆ·è¡Œä¸ºå¹¶ç”Ÿæˆæ¨èã€‚</li>
<li>å®éªŒè¡¨æ˜ï¼ŒARAGåœ¨æ¨èç³»ç»Ÿçš„æ€§èƒ½æŒ‡æ ‡ä¸Šæ˜¾è‘—ä¼˜äºæ ‡å‡†RAGå’ŒåŸºäºæ—¶æ•ˆæ€§çš„åŸºå‡†æµ‹è¯•ã€‚</li>
<li>ARAGé€šè¿‡èåˆæ™ºèƒ½ä½“æ¨ç†ï¼Œæé«˜äº†æ£€ç´¢å¢å¼ºæ¨èçš„æ•ˆç‡ã€‚</li>
<li>ARAGæ¡†æ¶ä¸ºLLMä¸ªæ€§åŒ–æ¨èæä¾›äº†æ–°çš„ç ”ç©¶æ–¹å‘ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.21931">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-da3a7790e518066c985382b5a14a59cb.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-a60348237877c064fe7d60a17d9696aa.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-48b8911cc41247821f139f12e9134750.jpg" align="middle">
</details>


<h1 id="-13"><a href="#-13" class="headerlink" title=""></a></h1><h2 id="Verbal-Werewolf-Engage-Users-with-Verbalized-Agentic-Werewolf-Game-Framework"><a href="#Verbal-Werewolf-Engage-Users-with-Verbalized-Agentic-Werewolf-Game-Framework" class="headerlink" title="Verbal Werewolf: Engage Users with Verbalized Agentic Werewolf Game   Framework"></a>Verbal Werewolf: Engage Users with Verbalized Agentic Werewolf Game   Framework</h2><p><strong>Authors:Qihui Fan, Wenbo Li, Enfu Nan, Yixiao Chen, Lei Lu, Pu Zhao, Yanzhi Wang</strong></p>
<p>The growing popularity of social deduction games has created an increasing need for intelligent frameworks where humans can collaborate with AI agents, particularly in post-pandemic contexts with heightened psychological and social pressures. Social deduction games like Werewolf, traditionally played through verbal communication, present an ideal application for Large Language Models (LLMs) given their advanced reasoning and conversational capabilities. Prior studies have shown that LLMs can outperform humans in Werewolf games, but their reliance on external modules introduces latency that left their contribution in academic domain only, and omit such game should be user-facing. We propose \textbf{Verbal Werewolf}, a novel LLM-based Werewolf game system that optimizes two parallel pipelines: gameplay powered by state-of-the-art LLMs and a fine-tuned Text-to-Speech (TTS) module that brings text output to life. Our system operates in near real-time without external decision-making modules, leveraging the enhanced reasoning capabilities of modern LLMs like DeepSeek V3 to create a more engaging and anthropomorphic gaming experience that significantly improves user engagement compared to existing text-only frameworks. </p>
<blockquote>
<p>éšç€ç¤¾äº¤æ¨ç†æ¸¸æˆçš„æ—¥ç›Šæ™®åŠï¼Œäººç±»å¯¹ä¸äººå·¥æ™ºèƒ½ä»£ç†åä½œçš„æ™ºèƒ½æ¡†æ¶çš„éœ€æ±‚ä¸æ–­å¢é•¿ï¼Œç‰¹åˆ«æ˜¯åœ¨å¿ƒç†å’Œç¤¾ä¼šå‹åŠ›åŠ å‰§çš„åç–«æƒ…èƒŒæ™¯ä¸‹ã€‚åƒç‹¼äººæ€è¿™æ ·çš„ç¤¾äº¤æ¨ç†æ¸¸æˆï¼Œä¼ ç»Ÿä¸Šæ˜¯é€šè¿‡å£å¤´äº¤æµè¿›è¡Œçš„ï¼Œè€ƒè™‘åˆ°å…¶å…ˆè¿›çš„æ¨ç†å’Œå¯¹è¯èƒ½åŠ›ï¼Œå¯¹äºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ¥è¯´æ˜¯ä¸€ä¸ªç†æƒ³çš„åº”ç”¨ã€‚æ—©æœŸçš„ç ”ç©¶è¡¨æ˜ï¼ŒLLMåœ¨ç‹¼äººæ€æ¸¸æˆä¸­å¯ä»¥è¶…è¶Šäººç±»çš„è¡¨ç°ï¼Œä½†å®ƒä»¬å¯¹å¤–éƒ¨æ¨¡å—çš„ä¾èµ–å¼•å…¥äº†å»¶è¿Ÿï¼Œä½¿å…¶ä»…åœ¨å­¦æœ¯é¢†åŸŸæœ‰æ‰€è´¡çŒ®ï¼Œè€Œå¿½è§†äº†è¿™ç±»æ¸¸æˆåº”è¯¥æ˜¯é¢å‘ç”¨æˆ·çš„ã€‚æˆ‘ä»¬æå‡ºäº†<strong>Verbal Werewolf</strong>ï¼Œè¿™æ˜¯ä¸€ç§åŸºäºLLMçš„æ–°å‹ç‹¼äººæ€æ¸¸æˆç³»ç»Ÿï¼Œä¼˜åŒ–äº†ä¸¤ä¸ªå¹¶è¡Œç®¡é“ï¼šç”±æœ€æ–°LLMé©±åŠ¨çš„æ¸¸æˆç©æ³•å’Œä¸€ä¸ªç»è¿‡ç²¾ç»†è°ƒæ•´çš„æ–‡æœ¬åˆ°è¯­éŸ³ï¼ˆTTSï¼‰æ¨¡å—ï¼Œå°†æ–‡æœ¬è¾“å‡ºè½¬åŒ–ä¸ºç”ŸåŠ¨çš„å£°éŸ³ã€‚æˆ‘ä»¬çš„ç³»ç»Ÿåœ¨è¿‘å®æ—¶å†…è¿è¡Œï¼Œæ— éœ€å¤–éƒ¨å†³ç­–æ¨¡å—ï¼Œåˆ©ç”¨ç°ä»£LLMï¼ˆå¦‚DeepSeek V3ï¼‰å¢å¼ºçš„æ¨ç†èƒ½åŠ›ï¼Œåˆ›é€ äº†ä¸€ä¸ªæ›´å…·å¸å¼•åŠ›å’Œæ‹ŸäººåŒ–çš„æ¸¸æˆä½“éªŒï¼Œä¸ç°æœ‰çš„çº¯æ–‡æœ¬æ¡†æ¶ç›¸æ¯”ï¼Œæ˜¾è‘—æé«˜äº†ç”¨æˆ·å‚ä¸åº¦ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.00160v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>éšç€ç¤¾äº¤æ¨ç†æ¸¸æˆæ—¥ç›Šæµè¡Œï¼Œäººç±»ä¸AIä»£ç†äººçš„æ™ºèƒ½åä½œæ¡†æ¶éœ€æ±‚ä¸æ–­å¢é•¿ï¼Œç‰¹åˆ«æ˜¯åœ¨å¿ƒç†å’Œç¤¾ä¼šå‹åŠ›å¢å¤§çš„ç–«æƒ…åç¯å¢ƒä¸­ã€‚ä¼ ç»Ÿé€šè¿‡å£å¤´äº¤æµè¿›è¡Œçš„ç¤¾äº¤æ¨ç†æ¸¸æˆï¼ˆå¦‚ç‹¼äººæ¸¸æˆï¼‰æ˜¯å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„ç†æƒ³åº”ç”¨ï¼ŒLLMå‡­å€Ÿå…ˆè¿›çš„æ¨ç†å’Œå¯¹è¯èƒ½åŠ›ï¼Œåœ¨æ¸¸æˆä¸­å±•ç°å‡ºè¶…è¶Šäººç±»çš„è¡¨ç°ã€‚ç„¶è€Œï¼Œå…¶ä¾èµ–å¤–éƒ¨æ¨¡å—å¯¼è‡´çš„å»¶è¿Ÿé—®é¢˜ä½¿å…¶ä»…é€‚ç”¨äºå­¦æœ¯é¢†åŸŸã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬æå‡ºäº†åŸºäºLLMçš„ç‹¼äººæ¸¸æˆç³»ç»Ÿâ€”â€”Verbal Werewolfï¼Œä¼˜åŒ–äº†æ¸¸æˆæµç¨‹å¹¶å¼•å…¥ç²¾ç»†è°ƒæ•´çš„æ–‡æœ¬è½¬è¯­éŸ³ï¼ˆTTSï¼‰æ¨¡å—ï¼Œå°†æ–‡æœ¬è¾“å‡ºè½¬åŒ–ä¸ºç”ŸåŠ¨å½¢å¼ã€‚è¯¥ç³»ç»Ÿåˆ©ç”¨æœ€æ–°LLMæŠ€æœ¯å®ç°è¿‘å®æ—¶æ“ä½œï¼Œæ— éœ€å¤–éƒ¨å†³ç­–æ¨¡å—ï¼Œåˆ›é€ æ›´åŠ å¼•äººå…¥èƒœçš„äººç±»åŒ–æ¸¸æˆä½“éªŒï¼Œæ˜¾è‘—æé«˜äº†ç”¨æˆ·å‚ä¸åº¦ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ç¤¾äº¤æ¨ç†æ¸¸æˆçš„æµè¡Œæ¨åŠ¨äº†äººç±»ä¸AIåä½œæ¡†æ¶çš„éœ€æ±‚å¢é•¿ã€‚</li>
<li>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨ç¤¾äº¤æ¨ç†æ¸¸æˆä¸­å±•ç°å‡ºè‰²çš„èƒ½åŠ›ã€‚</li>
<li>LLMåœ¨ç‹¼äººæ¸¸æˆä¸­è¡¨ç°è¶…è¶Šäººç±»ã€‚</li>
<li>LLMä¾èµ–å¤–éƒ¨æ¨¡å—å¯¼è‡´å»¶è¿Ÿé—®é¢˜ã€‚</li>
<li>æå‡ºäº†åŸºäºLLMçš„ç‹¼äººæ¸¸æˆç³»ç»Ÿâ€”â€”Verbal Werewolfã€‚</li>
<li>Verbal Werewolfä¼˜åŒ–äº†æ¸¸æˆæµç¨‹å¹¶å¼•å…¥TTSæ¨¡å—ï¼Œæé«˜ç”¨æˆ·ä½“éªŒã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.00160">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-3ee0fd2b5cfacca1961c36a37a108581.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-1caaddeb0632cb637c347708c653112d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f5622418dd1803c7444a1e930848d4e7.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-d1fbfaa06e7aeedeb6cd012fb18ed839.jpg" align="middle">
</details>


<h1 id="-14"><a href="#-14" class="headerlink" title=""></a></h1><h2 id="mAIstro-an-open-source-multi-agentic-system-for-automated-end-to-end-development-of-radiomics-and-deep-learning-models-for-medical-imaging"><a href="#mAIstro-an-open-source-multi-agentic-system-for-automated-end-to-end-development-of-radiomics-and-deep-learning-models-for-medical-imaging" class="headerlink" title="mAIstro: an open-source multi-agentic system for automated end-to-end   development of radiomics and deep learning models for medical imaging"></a>mAIstro: an open-source multi-agentic system for automated end-to-end   development of radiomics and deep learning models for medical imaging</h2><p><strong>Authors:Eleftherios Tzanis, Michail E. Klontzas</strong></p>
<p>Agentic systems built on large language models (LLMs) offer promising capabilities for automating complex workflows in healthcare AI. We introduce mAIstro, an open-source, autonomous multi-agentic framework for end-to-end development and deployment of medical AI models. The system orchestrates exploratory data analysis, radiomic feature extraction, image segmentation, classification, and regression through a natural language interface, requiring no coding from the user. Built on a modular architecture, mAIstro supports both open- and closed-source LLMs, and was evaluated using a large and diverse set of prompts across 16 open-source datasets, covering a wide range of imaging modalities, anatomical regions, and data types. The agents successfully executed all tasks, producing interpretable outputs and validated models. This work presents the first agentic framework capable of unifying data analysis, AI model development, and inference across varied healthcare applications, offering a reproducible and extensible foundation for clinical and research AI integration. The code is available at: <a target="_blank" rel="noopener" href="https://github.com/eltzanis/mAIstro">https://github.com/eltzanis/mAIstro</a> </p>
<blockquote>
<p>åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„Agenticç³»ç»Ÿä¸ºåœ¨åŒ»ç–—AIä¸­è‡ªåŠ¨åŒ–å¤æ‚å·¥ä½œæµç¨‹æä¾›äº†æœ‰å‰æ™¯çš„èƒ½åŠ›ã€‚æˆ‘ä»¬ä»‹ç»äº†mAIstroï¼Œè¿™æ˜¯ä¸€ä¸ªå¼€æºçš„ã€è‡ªä¸»çš„ã€å¤šAgenticæ¡†æ¶ï¼Œç”¨äºåŒ»ç–—AIæ¨¡å‹çš„ç«¯åˆ°ç«¯å¼€å‘å’Œéƒ¨ç½²ã€‚è¯¥ç³»ç»Ÿé€šè¿‡è‡ªç„¶è¯­è¨€æ¥å£åè°ƒæ¢ç´¢æ€§åˆ†æã€æ”¾å°„ç»„å­¦ç‰¹å¾æå–ã€å›¾åƒåˆ†å‰²ã€åˆ†ç±»å’Œå›å½’ï¼Œæ— éœ€ç”¨æˆ·ç¼–ç ã€‚mAIstroé‡‡ç”¨æ¨¡å—åŒ–æ¶æ„ï¼Œæ”¯æŒå¼€æºå’Œé—­æºLLMï¼Œå¹¶ä½¿ç”¨æ¶µç›–å¹¿æ³›æˆåƒæ¨¡å¼ã€è§£å‰–åŒºåŸŸå’Œæ•°æ®ç±»å‹çš„16ä¸ªå¼€æºæ•°æ®é›†çš„å¤§å‹å’Œå¤šæ ·åŒ–çš„æç¤ºé›†è¿›è¡Œè¯„ä¼°ã€‚ä»£ç†æˆåŠŸæ‰§è¡Œäº†æ‰€æœ‰ä»»åŠ¡ï¼Œäº§ç”Ÿäº†å¯è§£é‡Šçš„è¾“å‡ºå’Œç»è¿‡éªŒè¯çš„æ¨¡å‹ã€‚è¿™é¡¹å·¥ä½œæå‡ºäº†ç¬¬ä¸€ä¸ªèƒ½å¤Ÿåœ¨å„ç§åŒ»ç–—ä¿å¥åº”ç”¨ä¸­ç»Ÿä¸€æ•°æ®åˆ†æã€AIæ¨¡å‹å¼€å‘å’Œæ¨ç†çš„Agenticæ¡†æ¶ï¼Œä¸ºä¸´åºŠå’Œç ”ç©¶AIé›†æˆæä¾›äº†å¯é‡å¤å’Œå¯æ‰©å±•çš„åŸºç¡€ã€‚ä»£ç å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/eltzanis/mAIstro%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/eltzanis/mAIstroæ‰¾åˆ°ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.03785v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„Agenticç³»ç»Ÿä¸ºåŒ»ç–—ä¿å¥AIä¸­è‡ªåŠ¨åŒ–å¤æ‚å·¥ä½œæµç¨‹æä¾›äº†å‰æ™¯å¹¿é˜”çš„èƒ½åŠ›ã€‚æœ¬æ–‡ä»‹ç»äº†mAIstroï¼Œè¿™æ˜¯ä¸€ä¸ªå¼€æºçš„ã€è‡ªä¸»çš„å¤šAgenticæ¡†æ¶ï¼Œç”¨äºç«¯åˆ°ç«¯å¼€å‘å’Œéƒ¨ç½²åŒ»ç–—AIæ¨¡å‹ã€‚è¯¥ç³»ç»Ÿé€šè¿‡è‡ªç„¶è¯­è¨€ç•Œé¢è¿›è¡Œæ¢ç´¢æ€§æ•°æ®åˆ†æã€æ”¾å°„å­¦ç‰¹å¾æå–ã€å›¾åƒåˆ†å‰²ã€åˆ†ç±»å’Œå›å½’ï¼Œæ— éœ€ç”¨æˆ·ç¼–ç ã€‚mAIstroé‡‡ç”¨æ¨¡å—åŒ–æ¶æ„ï¼Œæ”¯æŒå¼€æºå’Œé—­æºLLMï¼Œå¹¶åœ¨æ¶µç›–å¹¿æ³›æˆåƒæ¨¡å¼ã€è§£å‰–éƒ¨ä½å’Œæ•°æ®ç±»å‹çš„16ä¸ªå¼€æºæ•°æ®é›†ä¸Šè¿›è¡Œäº†å¤§é‡å’Œå¤šæ ·åŒ–çš„æç¤ºè¯„ä¼°ã€‚ä»£ç†æˆåŠŸæ‰§è¡Œæ‰€æœ‰ä»»åŠ¡ï¼Œäº§ç”Ÿå¯è§£é‡Šçš„è¾“å‡ºå’Œç»è¿‡éªŒè¯çš„æ¨¡å‹ã€‚è¿™é¡¹å·¥ä½œæå‡ºäº†ç¬¬ä¸€ä¸ªèƒ½å¤Ÿåœ¨å„ç§åŒ»ç–—ä¿å¥åº”ç”¨ä¸­ç»Ÿä¸€æ•°æ®åˆ†æã€AIæ¨¡å‹å¼€å‘å’Œæ¨ç†çš„Agenticæ¡†æ¶ï¼Œä¸ºä¸´åºŠå’Œç ”ç©¶AIé›†æˆæä¾›äº†å¯é‡å¤å’Œå¯æ‰©å±•çš„åŸºç¡€ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>Agenticç³»ç»Ÿåˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨åŒ»ç–—ä¿å¥AIä¸­å®ç°äº†å¤æ‚å·¥ä½œæµç¨‹çš„è‡ªåŠ¨åŒ–ã€‚</li>
<li>mAIstroæ˜¯ä¸€ä¸ªå¼€æºçš„ã€å¤šåŠŸèƒ½çš„è‡ªä¸»å¤šAgenticæ¡†æ¶ï¼Œç”¨äºåŒ»ç–—AIæ¨¡å‹çš„ç«¯åˆ°ç«¯å¼€å‘å’Œéƒ¨ç½²ã€‚</li>
<li>mAIstroé€šè¿‡è‡ªç„¶è¯­è¨€æ¥å£è¿›è¡Œæ¢ç´¢æ€§æ•°æ®åˆ†æã€æ”¾å°„å­¦ç‰¹å¾æå–å’Œå›¾åƒåˆ†å‰²ç­‰ä»»åŠ¡ã€‚</li>
<li>ç³»ç»Ÿæ— éœ€ç”¨æˆ·ç¼–ç ï¼Œé™ä½äº†ä½¿ç”¨é—¨æ§›ã€‚</li>
<li>mAIstroæ”¯æŒå¤šç§å¼€æºå’Œé—­æºçš„LLMï¼Œå…·æœ‰æ¨¡å—åŒ–æ¶æ„ã€‚</li>
<li>åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šçš„è¯„ä¼°è¡¨æ˜ï¼Œä»£ç†èƒ½å¤ŸæˆåŠŸæ‰§è¡Œä»»åŠ¡å¹¶äº§ç”Ÿå¯éªŒè¯çš„ç»“æœã€‚</li>
<li>mAIstroä¸ºä¸´åºŠå’Œç ”ç©¶AIé›†æˆæä¾›äº†å¯é‡å¤å’Œå¯æ‰©å±•çš„åŸºç¡€ï¼Œæ˜¯ç¬¬ä¸€ä¸ªç»Ÿä¸€æ•°æ®åˆ†æã€AIæ¨¡å‹å¼€å‘å’Œæ¨ç†çš„Agenticæ¡†æ¶ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.03785">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-5390074709152f2f05ba2776966b9f34.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-76c2fc88c3e80b59e2fec82b783ac4fd.jpg" align="middle">
</details>


<h1 id="-15"><a href="#-15" class="headerlink" title=""></a></h1><h2 id="A-Communication-Consistent-Approach-to-Signal-Temporal-Logic-Task-Decomposition-in-Multi-Agent-Systems"><a href="#A-Communication-Consistent-Approach-to-Signal-Temporal-Logic-Task-Decomposition-in-Multi-Agent-Systems" class="headerlink" title="A Communication Consistent Approach to Signal Temporal Logic Task   Decomposition in Multi-Agent Systems"></a>A Communication Consistent Approach to Signal Temporal Logic Task   Decomposition in Multi-Agent Systems</h2><p><strong>Authors:Gregorio Marchesini, Siyuan Liu, Lars Lindemann, Dimos V. Dimarogonas</strong></p>
<p>We consider the problem of decomposing a global task assigned to a multi-agent system, expressed as a formula within a fragment of Signal Temporal Logic (STL), under range-limited communication. Given a global task expressed as a conjunction of local tasks defined over the individual and relative states of agents in the system, we propose representing task dependencies among agents as edges of a suitably defined task graph. At the same time, range-limited communication naturally induces the definition of a communication graph that defines which agents have access to each otherâ€™s states. Within these settings, inconsistencies arise when a task dependency between a pair of agents is not supported by a corresponding communication link due to the limited communication range. As a result, state feedback control laws previously derived to achieve the tasksâ€™ satisfaction can not be leveraged. We propose a task decomposition mechanism to distribute tasks assigned to pairs of non-communicating agents in the system as conjunctions of tasks defined over the relative states of communicating agents, thus enforcing consistency between task and communication graphs. Assuming the super-level sets of the predicate functions composing the STL tasks are bounded polytopes, our task decomposition mechanism can be cast as a parameter optimization problem and solved via state-of-the-art decentralized convex optimization algorithms. To guarantee the soundness of our approach, we present various conditions under which the tasks defined in the applied STL fragment are unsatisfiable, and we show sufficient conditions such that our decomposition approach yields satisfiable global tasks after decomposition. </p>
<blockquote>
<p>é’ˆå¯¹åˆ†é…ç»™å¤šæ™ºèƒ½ä½“ç³»ç»Ÿçš„å…¨å±€ä»»åŠ¡çš„é—®é¢˜ï¼Œåœ¨èŒƒå›´å—é™çš„é€šä¿¡æ¡ä»¶ä¸‹ï¼Œæˆ‘ä»¬å°†è¯¥é—®é¢˜è¡¨è¾¾ä¸ºä¿¡å·æ—¶åºé€»è¾‘ï¼ˆSTLï¼‰ç‰‡æ®µä¸­çš„å…¬å¼ã€‚ç»™å®šè¡¨è¾¾ä¸ºç³»ç»Ÿä¸­ä¸ªä½“æ™ºèƒ½ä½“å’Œç›¸å¯¹çŠ¶æ€ä¸Šå®šä¹‰çš„å±€éƒ¨ä»»åŠ¡çš„å¹¶é›†çš„å…¨å±€ä»»åŠ¡ï¼Œæˆ‘ä»¬æè®®å°†æ™ºèƒ½ä½“ä¹‹é—´çš„ä»»åŠ¡ä¾èµ–å…³ç³»è¡¨ç¤ºä¸ºé€‚å½“å®šä¹‰çš„ä»»åŠ¡å›¾çš„è¾¹ã€‚åŒæ—¶ï¼ŒèŒƒå›´æœ‰é™çš„é€šä¿¡è‡ªç„¶åœ°å¼•å‘äº†é€šä¿¡å›¾çš„å®šä¹‰ï¼Œè¯¥å®šä¹‰ç¡®å®šäº†å“ªäº›æ™ºèƒ½ä½“å¯ä»¥ç›¸äº’è®¿é—®çŠ¶æ€ã€‚åœ¨è¿™äº›æƒ…å†µä¸‹ï¼Œå½“ä¸€å¯¹æ™ºèƒ½ä½“ä¹‹é—´çš„ä»»åŠ¡ä¾èµ–å…³ç³»å› é€šä¿¡èŒƒå›´æœ‰é™è€Œå¾—ä¸åˆ°ç›¸åº”çš„é€šä¿¡é“¾æ¥æ”¯æŒæ—¶ï¼Œå°±ä¼šå‡ºç°ä¸ä¸€è‡´æ€§ã€‚å› æ­¤ï¼Œå…ˆå‰æ´¾ç”Ÿçš„ç”¨äºå®ç°ä»»åŠ¡æ»¡æ„åº¦çš„çŠ¶æ€åé¦ˆæ§åˆ¶å®šå¾‹æ— æ³•åˆ©ç”¨ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§ä»»åŠ¡åˆ†è§£æœºåˆ¶ï¼Œå°†åˆ†é…ç»™ç³»ç»Ÿä¸­æ— æ³•é€šä¿¡çš„æ™ºèƒ½ä½“å¯¹çš„ä»»åŠ¡åˆ†å¸ƒä¸ºåœ¨é€šä¿¡æ™ºèƒ½ä½“çš„ç›¸å¯¹çŠ¶æ€ä¸Šå®šä¹‰çš„ä»»åŠ¡çš„å¹¶é›†ï¼Œä»è€Œåœ¨ä»»åŠ¡å›¾å’Œé€šä¿¡å›¾ä¹‹é—´å¼ºåˆ¶æ‰§è¡Œä¸€è‡´æ€§ã€‚å‡è®¾ç»„æˆSTLä»»åŠ¡çš„è°“è¯å‡½æ•°çš„è¶…æ°´å¹³é›†æ˜¯æœ‰ç•Œçš„å¤šé¢ä½“ï¼Œæˆ‘ä»¬çš„ä»»åŠ¡åˆ†è§£æœºåˆ¶å¯ä»¥è½¬åŒ–ä¸ºå‚æ•°ä¼˜åŒ–é—®é¢˜ï¼Œå¹¶é€šè¿‡æœ€æ–°çš„åˆ†æ•£å¼å‡¸ä¼˜åŒ–ç®—æ³•è§£å†³ã€‚ä¸ºäº†ä¿è¯æˆ‘ä»¬çš„æ–¹æ³•çš„æ­£ç¡®æ€§ï¼Œæˆ‘ä»¬æå‡ºäº†åœ¨åº”ç”¨çš„STLç‰‡æ®µä¸­å®šä¹‰çš„ä»»åŠ¡ä¸å¯æ»¡è¶³çš„å„ç§æ¡ä»¶ï¼Œå¹¶å±•ç¤ºäº†è¶³å¤Ÿçš„æ¡ä»¶ï¼Œä½¿å¾—æˆ‘ä»¬çš„åˆ†è§£æ–¹æ³•åœ¨åˆ†è§£åäº§ç”Ÿå¯æ»¡è¶³çš„å…¨å±€ä»»åŠ¡ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2410.12563v2">PDF</a> This work has been submitted to the IEEE for possible publication</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ç ”ç©¶äº†åœ¨èŒƒå›´å—é™é€šä¿¡ä¸‹ï¼Œå¦‚ä½•å°†å…¨å±€ä»»åŠ¡åˆ†è§£ä¸ºå¤šæ™ºèƒ½ä½“ç³»ç»Ÿçš„å±€éƒ¨ä»»åŠ¡çš„é—®é¢˜ã€‚ä»»åŠ¡ä¾èµ–å…³ç³»è¢«è¡¨ç¤ºä¸ºä»»åŠ¡å›¾çš„è¾¹ï¼Œè€Œé€šä¿¡èŒƒå›´é™åˆ¶è‡ªç„¶åœ°å®šä¹‰äº†é€šä¿¡å›¾ã€‚å½“ä»»åŠ¡ä¾èµ–ä¸é€šä¿¡é“¾æ¥ä¸ä¸€è‡´æ—¶ï¼Œä¼šå‡ºç°ä¸ä¸€è‡´é—®é¢˜ã€‚ä¸ºè§£å†³è¿™ä¸€é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºä¸€ç§ä»»åŠ¡åˆ†è§£æœºåˆ¶ï¼Œå°†éé€šä¿¡æ™ºèƒ½ä½“é—´çš„ä»»åŠ¡åˆ†é…ç»™ç³»ç»Ÿä¸­çš„é€šä¿¡æ™ºèƒ½ä½“å¯¹ä½œä¸ºç›¸å¯¹çŠ¶æ€çš„ç»„åˆä»»åŠ¡ï¼Œä»è€Œä¿è¯ä»»åŠ¡å›¾å’Œé€šä¿¡å›¾çš„ä¸€è‡´æ€§ã€‚å‡è®¾ç»„æˆSTLä»»åŠ¡çš„è°“è¯å‡½æ•°çš„è¶…æ°´å¹³é›†ä¸ºæœ‰ç•Œå¤šè¾¹å½¢ï¼Œè¯¥ä»»åŠ¡åˆ†è§£æœºåˆ¶å¯è½¬åŒ–ä¸ºå‚æ•°ä¼˜åŒ–é—®é¢˜ï¼Œå¹¶é€šè¿‡ç°æœ‰çš„åˆ†æ•£å¼å‡¸ä¼˜åŒ–ç®—æ³•æ±‚è§£ã€‚åŒæ—¶ï¼Œæœ¬æ–‡ç»™å‡ºäº†ä»»åŠ¡ä¸å¯æ»¡è¶³çš„æ¡ä»¶å’Œä»»åŠ¡åˆ†è§£åå…¨å±€ä»»åŠ¡å¯å®ç°çš„å……åˆ†æ¡ä»¶ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>æå‡ºäº†åœ¨èŒƒå›´å—é™é€šä¿¡ä¸‹ï¼Œå¦‚ä½•å°†å…¨å±€ä»»åŠ¡è¡¨è¾¾ä¸ºSignal Temporal Logicï¼ˆSTLï¼‰å†…çš„å…¬å¼å¹¶åˆ†è§£ä¸ºå¤šæ™ºèƒ½ä½“ç³»ç»Ÿçš„å±€éƒ¨ä»»åŠ¡çš„é—®é¢˜ã€‚</li>
<li>é€šè¿‡å®šä¹‰ä»»åŠ¡å›¾è¡¨ç¤ºä»»åŠ¡ä¾èµ–å…³ç³»ï¼ŒåŒæ—¶å®šä¹‰äº†é€šä¿¡å›¾æ¥è¡¨ç¤ºæ™ºèƒ½ä½“ä¹‹é—´çš„é€šä¿¡èŒƒå›´ã€‚</li>
<li>å½“ä»»åŠ¡ä¾èµ–ä¸é€šä¿¡é“¾æ¥ä¸ä¸€è‡´æ—¶ï¼Œä¼šå¯¼è‡´åé¦ˆæ§åˆ¶å¾‹æ— æ³•åˆ©ç”¨çš„é—®é¢˜ã€‚</li>
<li>æå‡ºä¸€ç§ä»»åŠ¡åˆ†è§£æœºåˆ¶ï¼Œé€šè¿‡åˆ†é…ç»™é€šä¿¡æ™ºèƒ½ä½“çš„ç›¸å¯¹çŠ¶æ€ç»„åˆä»»åŠ¡æ¥åˆ†å¸ƒéé€šä¿¡æ™ºèƒ½ä½“çš„ä»»åŠ¡ï¼Œä¿è¯ä»»åŠ¡å›¾å’Œé€šä¿¡å›¾çš„ä¸€è‡´æ€§ã€‚</li>
<li>ä»»åŠ¡åˆ†è§£æœºåˆ¶å¯è½¬åŒ–ä¸ºå‚æ•°ä¼˜åŒ–é—®é¢˜ï¼Œå¹¶åˆ©ç”¨ç°æœ‰çš„åˆ†æ•£å¼å‡¸ä¼˜åŒ–ç®—æ³•è¿›è¡Œæ±‚è§£ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2410.12563">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-c9ec838a77cdfcd92a300082c3f2f681.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-09ec10be2c87046034ed91b48b1933d2.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-63849f6775577f7026e7f284b2bcbc99.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a7c343a673b709d400429eb3adf944cb.jpg" align="middle">
</details>


<h1 id="-16"><a href="#-16" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-08-13/Agent/">https://kedreamix.github.io/Talk2Paper/Paper/2025-08-13/Agent/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/Agent/">
                                    <span class="chip bg-color">Agent</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-08-13/Few-Shot/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-ad342342c4d5f43a495cc5445f33b7c9.jpg" class="responsive-img" alt="Few-Shot">
                        
                        <span class="card-title">Few-Shot</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Few-Shot æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-08-13  Expert Preference-based Evaluation of Automated Related Work Generation
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-08-13
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Few-Shot/" class="post-category">
                                    Few-Shot
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Few-Shot/">
                        <span class="chip bg-color">Few-Shot</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-08-13/LLM/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-d2f526f54f9eff944fd028d31717a3c2.jpg" class="responsive-img" alt="LLM">
                        
                        <span class="card-title">LLM</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            LLM æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-08-13  ODYSSEY Open-World Quadrupeds Exploration and Manipulation for   Long-Horizon Tasks
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-08-13
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/LLM/" class="post-category">
                                    LLM
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/LLM/">
                        <span class="chip bg-color">LLM</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">28315.1k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
