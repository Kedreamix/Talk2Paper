<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="3DGS">
    <meta name="description" content="3DGS æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-03-18  Generative Gaussian Splatting Generating 3D Scenes with Video Diffusion   Priors">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>3DGS | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('D:\MyBlog\AutoFX\arxiv\2025-03-18\./crop_3DGS/2503.13272v1/page_5_0.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">3DGS</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/3DGS/">
                                <span class="chip bg-color">3DGS</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/3DGS/" class="post-category">
                                3DGS
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-03-18
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-03-18
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    18.6k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    75 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-03-18-æ›´æ–°"><a href="#2025-03-18-æ›´æ–°" class="headerlink" title="2025-03-18 æ›´æ–°"></a>2025-03-18 æ›´æ–°</h1><h2 id="Generative-Gaussian-Splatting-Generating-3D-Scenes-with-Video-Diffusion-Priors"><a href="#Generative-Gaussian-Splatting-Generating-3D-Scenes-with-Video-Diffusion-Priors" class="headerlink" title="Generative Gaussian Splatting: Generating 3D Scenes with Video Diffusion   Priors"></a>Generative Gaussian Splatting: Generating 3D Scenes with Video Diffusion   Priors</h2><p><strong>Authors:Katja Schwarz, Norman Mueller, Peter Kontschieder</strong></p>
<p>Synthesizing consistent and photorealistic 3D scenes is an open problem in computer vision. Video diffusion models generate impressive videos but cannot directly synthesize 3D representations, i.e., lack 3D consistency in the generated sequences. In addition, directly training generative 3D models is challenging due to a lack of 3D training data at scale. In this work, we present Generative Gaussian Splatting (GGS) â€“ a novel approach that integrates a 3D representation with a pre-trained latent video diffusion model. Specifically, our model synthesizes a feature field parameterized via 3D Gaussian primitives. The feature field is then either rendered to feature maps and decoded into multi-view images, or directly upsampled into a 3D radiance field. We evaluate our approach on two common benchmark datasets for scene synthesis, RealEstate10K and ScanNet+, and find that our proposed GGS model significantly improves both the 3D consistency of the generated multi-view images, and the quality of the generated 3D scenes over all relevant baselines. Compared to a similar model without 3D representation, GGS improves FID on the generated 3D scenes by ~20% on both RealEstate10K and ScanNet+. Project page: <a target="_blank" rel="noopener" href="https://katjaschwarz.github.io/ggs/">https://katjaschwarz.github.io/ggs/</a> </p>
<blockquote>
<p>åˆæˆä¸€è‡´ä¸”é€¼çœŸçš„ä¸‰ç»´åœºæ™¯æ˜¯è®¡ç®—æœºè§†è§‰é¢†åŸŸçš„ä¸€ä¸ªå…¬å¼€é—®é¢˜ã€‚è§†é¢‘æ‰©æ•£æ¨¡å‹å¯ä»¥ç”Ÿæˆä»¤äººå°è±¡æ·±åˆ»çš„è§†é¢‘ï¼Œä½†æ— æ³•ç›´æ¥åˆæˆä¸‰ç»´è¡¨ç¤ºï¼Œå³åœ¨ç”Ÿæˆåºåˆ—ä¸­ç¼ºä¹ä¸‰ç»´ä¸€è‡´æ€§ã€‚æ­¤å¤–ï¼Œç”±äºç¼ºä¹å¤§è§„æ¨¡çš„ä¸‰ç»´è®­ç»ƒæ•°æ®ï¼Œç›´æ¥è®­ç»ƒç”Ÿæˆå¼ä¸‰ç»´æ¨¡å‹å…·æœ‰æŒ‘æˆ˜æ€§ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ç”Ÿæˆå¼é«˜æ–¯æº…å‡ºï¼ˆGGSï¼‰â€”â€”ä¸€ç§å°†ä¸‰ç»´è¡¨ç¤ºä¸é¢„è®­ç»ƒçš„æ½œåœ¨è§†é¢‘æ‰©æ•£æ¨¡å‹ç›¸ç»“åˆçš„æ–°æ–¹æ³•ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬çš„æ¨¡å‹é€šè¿‡ä¸‰ç»´é«˜æ–¯åŸºå…ƒå‚æ•°åŒ–åˆæˆç‰¹å¾åœºã€‚ç„¶åï¼Œè¯¥ç‰¹å¾åœºè¦ä¹ˆå‘ˆç°ä¸ºç‰¹å¾å›¾å¹¶è§£ç ä¸ºå¤šè§†å›¾å›¾åƒï¼Œè¦ä¹ˆç›´æ¥ä¸Šé‡‡æ ·ä¸ºä¸‰ç»´è¾å°„åœºã€‚æˆ‘ä»¬åœ¨åœºæ™¯åˆæˆçš„ä¸¤ä¸ªå¸¸ç”¨åŸºå‡†æ•°æ®é›†RealEstate10Kå’ŒScanNet+ä¸Šè¯„ä¼°äº†æˆ‘ä»¬çš„æ–¹æ³•ï¼Œå‘ç°æ‰€æå‡ºçš„GGSæ¨¡å‹åœ¨ç”Ÿæˆçš„å¤šè§†å›¾å›¾åƒçš„ä¸‰ç»´ä¸€è‡´æ€§å’Œç”Ÿæˆçš„ä¸‰ç»´åœºæ™¯çš„è´¨é‡æ–¹é¢å‡æ˜¾è‘—ä¼˜äºæ‰€æœ‰ç›¸å…³åŸºçº¿ã€‚ä¸æ²¡æœ‰ä¸‰ç»´è¡¨ç¤ºçš„ç±»ä¼¼æ¨¡å‹ç›¸æ¯”ï¼ŒGGSåœ¨RealEstate10Kå’ŒScanNet+ä¸Šçš„ç”Ÿæˆä¸‰ç»´åœºæ™¯çš„FIDæé«˜äº†çº¦20%ã€‚é¡¹ç›®é¡µé¢ï¼š<a target="_blank" rel="noopener" href="https://katjaschwarz.github.io/ggs/">https://katjaschwarz.github.io/ggs/</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.13272v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>åŸºäºè®¡ç®—æœºè§†è§‰é¢†åŸŸçš„ä¸€é¡¹æŒ‘æˆ˜ï¼Œå³å¦‚ä½•åˆæˆä¸€è‡´ä¸”é€¼çœŸçš„ä¸‰ç»´åœºæ™¯ï¼Œæœ¬ç ”ç©¶æå‡ºäº†ä¸€ç§åä¸ºç”Ÿæˆå¼é«˜æ–¯æº…å‡ºï¼ˆGGSï¼‰çš„æ–°æ–¹æ³•ã€‚è¯¥æ–¹æ³•ç»“åˆäº†ä¸‰ç»´è¡¨å¾ä¸é¢„è®­ç»ƒçš„æ½œåœ¨è§†é¢‘æ‰©æ•£æ¨¡å‹ã€‚é€šè¿‡åˆæˆç”±ä¸‰ç»´é«˜æ–¯åŸå§‹å‚æ•°åŒ–çš„ç‰¹å¾åœºï¼Œå†å°†å…¶æ¸²æŸ“ä¸ºç‰¹å¾å›¾å¹¶è§£ç ä¸ºå¤šè§†è§’å›¾åƒæˆ–ç›´æ¥ä¸Šé‡‡æ ·ä¸ºä¸‰ç»´è¾å°„åœºã€‚åœ¨åœºæ™¯åˆæˆåŸºå‡†æ•°æ®é›†RealEstate10Kå’ŒScanNet+ä¸Šçš„è¯„ä¼°æ˜¾ç¤ºï¼ŒGGSæ¨¡å‹æ˜¾è‘—æé«˜äº†ç”Ÿæˆçš„å¤šè§†è§’å›¾åƒçš„3Dä¸€è‡´æ€§å’Œç”Ÿæˆçš„ä¸‰ç»´åœºæ™¯çš„è´¨é‡ã€‚ç›¸æ¯”äºæ²¡æœ‰ä¸‰ç»´è¡¨å¾çš„ç±»ä¼¼æ¨¡å‹ï¼ŒGGSåœ¨RealEstate10Kå’ŒScanNet+ä¸Šå°†ç”Ÿæˆçš„ä¸‰ç»´åœºæ™¯çš„FIDæé«˜äº†çº¦20%ã€‚æ›´å¤šä¿¡æ¯è¯·å‚è§é¡¹ç›®ç½‘é¡µã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ç ”ç©¶æå‡ºäº†ä¸€ç§åä¸ºç”Ÿæˆå¼é«˜æ–¯æº…å‡ºï¼ˆGGSï¼‰çš„æ–¹æ³•ï¼Œæ—¨åœ¨è§£å†³åˆæˆä¸‰ç»´åœºæ™¯çš„æŒ‘æˆ˜ã€‚</li>
<li>GGSç»“åˆäº†ä¸‰ç»´è¡¨å¾ä¸é¢„è®­ç»ƒçš„æ½œåœ¨è§†é¢‘æ‰©æ•£æ¨¡å‹ã€‚</li>
<li>è¯¥æ–¹æ³•é€šè¿‡åˆæˆç‰¹å¾åœºï¼Œå®ç°ä¸ºåŸºäºä¸‰ç»´é«˜æ–¯åŸå§‹å‚æ•°åŒ–çš„æ¨¡å‹ã€‚</li>
<li>ç‰¹å¾åœºå¯ä»¥è¢«æ¸²æŸ“ä¸ºå¤šç»´å›¾åƒæˆ–ç›´æ¥ä¸Šé‡‡æ ·ä¸ºä¸‰ç»´è¾å°„åœºã€‚</li>
<li>åœ¨åŸºå‡†æ•°æ®é›†ä¸Šçš„è¯„ä¼°æ˜¾ç¤ºï¼ŒGGSæé«˜äº†ç”Ÿæˆçš„å¤šè§†è§’å›¾åƒçš„3Dä¸€è‡´æ€§å’Œç”Ÿæˆçš„ä¸‰ç»´åœºæ™¯çš„è´¨é‡ã€‚</li>
<li>ä¸æ²¡æœ‰ä¸‰ç»´è¡¨å¾çš„æ¨¡å‹ç›¸æ¯”ï¼ŒGGSæ˜¾è‘—æé«˜ç”Ÿæˆçš„ä¸‰ç»´åœºæ™¯çš„FIDå¾—åˆ†ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.13272">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-03-18\./crop_3DGS/2503.13272v1/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-03-18\./crop_3DGS/2503.13272v1/page_3_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-03-18\./crop_3DGS/2503.13272v1/page_5_0.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="DeGauss-Dynamic-Static-Decomposition-with-Gaussian-Splatting-for-Distractor-free-3D-Reconstruction"><a href="#DeGauss-Dynamic-Static-Decomposition-with-Gaussian-Splatting-for-Distractor-free-3D-Reconstruction" class="headerlink" title="DeGauss: Dynamic-Static Decomposition with Gaussian Splatting for   Distractor-free 3D Reconstruction"></a>DeGauss: Dynamic-Static Decomposition with Gaussian Splatting for   Distractor-free 3D Reconstruction</h2><p><strong>Authors:Rui Wang, Quentin Lohmeyer, Mirko Meboldt, Siyu Tang</strong></p>
<p>Reconstructing clean, distractor-free 3D scenes from real-world captures remains a significant challenge, particularly in highly dynamic and cluttered settings such as egocentric videos. To tackle this problem, we introduce DeGauss, a simple and robust self-supervised framework for dynamic scene reconstruction based on a decoupled dynamic-static Gaussian Splatting design. DeGauss models dynamic elements with foreground Gaussians and static content with background Gaussians, using a probabilistic mask to coordinate their composition and enable independent yet complementary optimization. DeGauss generalizes robustly across a wide range of real-world scenarios, from casual image collections to long, dynamic egocentric videos, without relying on complex heuristics or extensive supervision. Experiments on benchmarks including NeRF-on-the-go, ADT, AEA, Hot3D, and EPIC-Fields demonstrate that DeGauss consistently outperforms existing methods, establishing a strong baseline for generalizable, distractor-free 3D reconstructionin highly dynamic, interaction-rich environments. </p>
<blockquote>
<p>ä»çœŸå®ä¸–ç•Œæ•æ‰ä¸­é‡å»ºæ— å¹²æ‰°ç‰©çš„3Dåœºæ™¯ä»ç„¶æ˜¯ä¸€ä¸ªå·¨å¤§çš„æŒ‘æˆ˜ï¼Œç‰¹åˆ«æ˜¯åœ¨ä»¥è‡ªæˆ‘ä¸ºä¸­å¿ƒçš„è§†é¢‘ç­‰é«˜åº¦åŠ¨æ€å’Œæ‚ä¹±çš„ç¯å¢ƒä¸­ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬å¼•å…¥äº†DeGaussï¼Œè¿™æ˜¯ä¸€ä¸ªç®€å•è€Œç¨³å¥çš„è‡ªç›‘ç£åŠ¨æ€åœºæ™¯é‡å»ºæ¡†æ¶ï¼Œå®ƒåŸºäºè§£è€¦çš„åŠ¨æ€é™æ€é«˜æ–¯å–·æº…è®¾è®¡ã€‚DeGaussä½¿ç”¨å‰æ™¯é«˜æ–¯å¯¹åŠ¨æ€å…ƒç´ è¿›è¡Œå»ºæ¨¡ï¼Œä½¿ç”¨èƒŒæ™¯é«˜æ–¯å¯¹é™æ€å†…å®¹è¿›è¡Œå»ºæ¨¡ï¼Œå¹¶ä½¿ç”¨æ¦‚ç‡æ©ç æ¥åè°ƒå®ƒä»¬çš„ç»„åˆï¼Œä»¥å®ç°ç‹¬ç«‹ä½†äº’è¡¥çš„ä¼˜åŒ–ã€‚DeGaussåœ¨å¹¿æ³›çš„å®é™…åœºæ™¯ä¸­å…·æœ‰ç¨³å¥çš„é€šç”¨æ€§ï¼Œä»éšæ„çš„å›¾åƒé›†åˆåˆ°æ¼«é•¿çš„åŠ¨æ€ä»¥è‡ªæˆ‘ä¸ºä¸­å¿ƒçš„è§†é¢‘ï¼Œæ— éœ€ä¾èµ–å¤æ‚çš„å¯å‘å¼æ–¹æ³•æˆ–å¹¿æ³›çš„ç›‘ç£ã€‚åœ¨åŒ…æ‹¬NeRF-on-the-goã€ADTã€AEAã€Hot3Då’ŒEPIC-Fieldsç­‰åŸºå‡†æµ‹è¯•ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒDeGausså§‹ç»ˆä¼˜äºç°æœ‰æ–¹æ³•ï¼Œä¸ºé«˜åº¦åŠ¨æ€ã€äº¤äº’ä¸°å¯Œçš„ç¯å¢ƒä¸­çš„é€šç”¨æ— å¹²æ‰°ç‰©3Dé‡å»ºå»ºç«‹äº†å¼ºå¤§çš„åŸºå‡†ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.13176v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>è¯¥æ–‡ç« ä»‹ç»äº†DeGaussè¿™ä¸€ç®€å•è€Œç¨³å¥çš„è‡ªç›‘ç£æ¡†æ¶ï¼Œç”¨äºåŸºäºåŠ¨æ€é™æ€é«˜æ–¯æ‹¼è´´è®¾è®¡çš„åŠ¨æ€åœºæ™¯é‡å»ºã€‚DeGaussé€šè¿‡å‰æ™¯é«˜æ–¯æ¨¡å‹å¯¹åŠ¨æ€å…ƒç´ è¿›è¡Œå»ºæ¨¡ï¼ŒèƒŒæ™¯é«˜æ–¯æ¨¡å‹å¯¹é™æ€å†…å®¹è¿›è¡Œå»ºæ¨¡ï¼Œå¹¶ä½¿ç”¨æ¦‚ç‡æ©è†œåè°ƒå®ƒä»¬çš„ç»„åˆï¼Œä»¥å®ç°ç‹¬ç«‹ä½†äº’è¡¥çš„ä¼˜åŒ–ã€‚è¯¥æ¡†æ¶èƒ½å¤Ÿå¹¿æ³›åº”ç”¨äºå„ç§çœŸå®åœºæ™¯ï¼Œä»éšæ„çš„å›¾åƒé›†åˆåˆ°é•¿åŠ¨æ€ç¬¬ä¸€äººç§°è§†é¢‘ï¼Œæ— éœ€ä¾èµ–å¤æ‚çš„å¯å‘å¼ç®—æ³•æˆ–å¤§é‡çš„ç›‘ç£ã€‚åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒDeGaussåœ¨é«˜åº¦åŠ¨æ€ã€äº¤äº’ä¸°å¯Œçš„ç¯å¢ƒä¸­å§‹ç»ˆä¼˜äºç°æœ‰æ–¹æ³•ï¼Œä¸ºæ— å¹²æ‰°ç‰©çš„ä¸€èˆ¬åŒ–ä¸‰ç»´é‡å»ºå»ºç«‹äº†å¼ºå¤§çš„åŸºçº¿ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>DeGaussæ˜¯ä¸€ä¸ªè‡ªç›‘ç£æ¡†æ¶ï¼Œç”¨äºä»çœŸå®ä¸–ç•Œæ•æ‰ä¸­é‡å»ºæ— å¹²æ‰°ç‰©çš„ä¸‰ç»´åœºæ™¯ã€‚</li>
<li>å®ƒé‡‡ç”¨åŠ¨æ€é™æ€é«˜æ–¯æ‹¼è´´è®¾è®¡ï¼Œèƒ½å¤Ÿå¤„ç†é«˜åº¦åŠ¨æ€å’Œæ‚ä¹±çš„ç¯å¢ƒï¼Œå¦‚ç¬¬ä¸€äººç§°è§†é¢‘ã€‚</li>
<li>DeGaussé€šè¿‡å‰æ™¯å’ŒèƒŒæ™¯é«˜æ–¯æ¨¡å‹åˆ†åˆ«å»ºæ¨¡åŠ¨æ€å’Œé™æ€å…ƒç´ ã€‚</li>
<li>æ¦‚ç‡æ©è†œç”¨äºåè°ƒåŠ¨æ€å’Œé™æ€å…ƒç´ çš„ç»„åˆï¼Œå®ç°ç‹¬ç«‹ä¸”äº’è¡¥çš„ä¼˜åŒ–ã€‚</li>
<li>DeGaussèƒ½å¤Ÿå¹¿æ³›åº”ç”¨äºå„ç§çœŸå®åœºæ™¯ï¼ŒåŒ…æ‹¬éšæ„çš„å›¾åƒé›†åˆå’Œé•¿è§†é¢‘ã€‚</li>
<li>è¯¥æ¡†æ¶ä¸éœ€è¦å¤æ‚çš„å¯å‘å¼ç®—æ³•æˆ–å¤§é‡çš„ç›‘ç£ã€‚</li>
<li>åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸Šï¼ŒDeGaussè¡¨ç°å‡ºå“è¶Šçš„æ€§èƒ½ï¼Œä¼˜äºç°æœ‰æ–¹æ³•ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.13176">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-03-18\./crop_3DGS/2503.13176v1/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-03-18\./crop_3DGS/2503.13176v1/page_3_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-03-18\./crop_3DGS/2503.13176v1/page_4_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-03-18\./crop_3DGS/2503.13176v1/page_5_0.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="CAT-3DGS-Pro-A-New-Benchmark-for-Efficient-3DGS-Compression"><a href="#CAT-3DGS-Pro-A-New-Benchmark-for-Efficient-3DGS-Compression" class="headerlink" title="CAT-3DGS Pro: A New Benchmark for Efficient 3DGS Compression"></a>CAT-3DGS Pro: A New Benchmark for Efficient 3DGS Compression</h2><p><strong>Authors:Yu-Ting Zhan, He-bi Yang, Cheng-Yuan Ho, Jui-Chiu Chiang, Wen-Hsiao Peng</strong></p>
<p>3D Gaussian Splatting (3DGS) has shown immense potential for novel view synthesis. However, achieving rate-distortion-optimized compression of 3DGS representations for transmission and&#x2F;or storage applications remains a challenge. CAT-3DGS introduces a context-adaptive triplane hyperprior for end-to-end optimized compression, delivering state-of-the-art coding performance. Despite this, it requires prolonged training and decoding time. To address these limitations, we propose CAT-3DGS Pro, an enhanced version of CAT-3DGS that improves both compression performance and computational efficiency. First, we introduce a PCA-guided vector-matrix hyperprior, which replaces the triplane-based hyperprior to reduce redundant parameters. To achieve a more balanced rate-distortion trade-off and faster encoding, we propose an alternate optimization strategy (A-RDO). Additionally, we refine the sampling rate optimization method in CAT-3DGS, leading to significant improvements in rate-distortion performance. These enhancements result in a 46.6% BD-rate reduction and 3x speedup in training time on BungeeNeRF, while achieving 5x acceleration in decoding speed for the Amsterdam scene compared to CAT-3DGS. </p>
<blockquote>
<p>3Dé«˜æ–¯å±•å¹³ï¼ˆ3DGSï¼‰åœ¨æ–°è§†è§’åˆæˆä¸­æ˜¾ç¤ºå‡ºå·¨å¤§çš„æ½œåŠ›ã€‚ç„¶è€Œï¼Œå®ç°ç”¨äºä¼ è¾“å’Œ&#x2F;æˆ–å­˜å‚¨åº”ç”¨çš„3DGSè¡¨ç¤ºçš„æœ‰ç‡å¤±çœŸä¼˜åŒ–å‹ç¼©ä»ç„¶æ˜¯ä¸€ä¸ªæŒ‘æˆ˜ã€‚CAT-3DGSå¼•å…¥äº†ä¸€ç§ä¸Šä¸‹æ–‡è‡ªé€‚åº”çš„ä¸‰å¹³é¢è¶…å…ˆéªŒï¼Œç”¨äºç«¯åˆ°ç«¯çš„ä¼˜åŒ–å‹ç¼©ï¼Œå®ç°äº†æœ€å…ˆè¿›çš„ç¼–ç æ€§èƒ½ã€‚å°½ç®¡å¦‚æ­¤ï¼Œå®ƒä»éœ€è¦è¾ƒé•¿çš„è®­ç»ƒå’Œè§£ç æ—¶é—´ã€‚ä¸ºäº†å…‹æœè¿™äº›é™åˆ¶ï¼Œæˆ‘ä»¬æå‡ºäº†CAT-3DGS Proï¼Œè¿™æ˜¯CAT-3DGSçš„å¢å¼ºç‰ˆæœ¬ï¼Œæ—¨åœ¨æé«˜å‹ç¼©æ€§èƒ½å’Œè®¡ç®—æ•ˆç‡ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬å¼•å…¥äº†PCAå¼•å¯¼çš„å‘é‡åŒ–çŸ©é˜µè¶…å…ˆéªŒï¼Œå®ƒæ›¿ä»£äº†åŸºäºä¸‰å¹³é¢çš„è¶…å…ˆéªŒï¼Œä»¥å‡å°‘å†—ä½™å‚æ•°ã€‚ä¸ºäº†å®ç°æ›´å¹³è¡¡çš„ç‡å¤±çœŸæƒè¡¡å’Œæ›´å¿«çš„ç¼–ç ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ›¿ä»£çš„ä¼˜åŒ–ç­–ç•¥ï¼ˆA-RDOï¼‰ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜å¯¹CAT-3DGSä¸­çš„é‡‡æ ·ç‡ä¼˜åŒ–æ–¹æ³•è¿›è¡Œäº†æ”¹è¿›ï¼Œå¯¼è‡´ç‡å¤±çœŸæ€§èƒ½æ˜¾è‘—æé«˜ã€‚è¿™äº›å¢å¼ºåŠŸèƒ½å¯¼è‡´åœ¨BungeeNeRFä¸Šçš„BDé€Ÿç‡é™ä½äº†46.6%ï¼Œè®­ç»ƒæ—¶é—´åŠ å¿«äº†ä¸‰å€ï¼Œä¸CAT-3DGSç›¸æ¯”ï¼Œé˜¿å§†æ–¯ç‰¹ä¸¹åœºæ™¯çš„è§£ç é€Ÿåº¦æé«˜äº†äº”å€ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.12862v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>åŸºäºä¸Šä¸‹æ–‡è‡ªé€‚åº”çš„3DGSå‹ç¼©æŠ€æœ¯é¢ä¸´çš„æŒ‘æˆ˜åŠå…¶æ”¹è¿›æ–¹æ¡ˆã€‚æå‡ºCAT-3DGS Proï¼Œé€šè¿‡å¼•å…¥PCAå¼•å¯¼çš„å‘é‡çŸ©é˜µè¶…å…ˆéªŒå’Œæ›¿ä»£ä¼˜åŒ–ç­–ç•¥ï¼Œæé«˜å‹ç¼©æ€§èƒ½å’Œè®¡ç®—æ•ˆç‡ã€‚æ”¹è¿›é‡‡æ ·ç‡ä¼˜åŒ–æ–¹æ³•ï¼Œå®ç°äº†åœ¨BungeeNeRFä¸Šçš„BDé€Ÿç‡é™ä½46.6%ï¼Œè®­ç»ƒæ—¶é—´æé€Ÿä¸‰å€ï¼Œé˜¿å§†æ–¯ç‰¹ä¸¹åœºæ™¯çš„è§£ç é€Ÿåº¦æå‡äº”å€ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>3DGSåœ¨æ–°å‹è§†å›¾åˆæˆä¸­å…·æœ‰å·¨å¤§æ½œåŠ›ï¼Œä½†å‹ç¼©ä¼˜åŒ–ä»æ˜¯ä¼ è¾“å’Œå­˜å‚¨åº”ç”¨ä¸­çš„æŒ‘æˆ˜ã€‚</li>
<li>CAT-3DGSå¼•å…¥ä¸Šä¸‹æ–‡è‡ªé€‚åº”triplaneè¶…å…ˆéªŒï¼Œå®ç°ç«¯åˆ°ç«¯çš„ä¼˜åŒ–å‹ç¼©ï¼Œå…·æœ‰å…ˆè¿›çš„ç¼–ç æ€§èƒ½ã€‚</li>
<li>CAT-3DGS Proæ˜¯å¯¹CAT-3DGSçš„å¢å¼ºç‰ˆæœ¬ï¼Œæ—¨åœ¨è§£å†³è®­ç»ƒå’Œè§£ç æ—¶é—´é•¿çš„é—®é¢˜ã€‚</li>
<li>PCAå¼•å¯¼çš„å‘é‡çŸ©é˜µè¶…å…ˆéªŒçš„å¼•å…¥å‡å°‘äº†å†—ä½™å‚æ•°ï¼Œæé«˜äº†å‹ç¼©æ€§èƒ½ã€‚</li>
<li>é‡‡ç”¨æ›¿ä»£ä¼˜åŒ–ç­–ç•¥ï¼ˆA-RDOï¼‰å®ç°äº†æ›´å¹³è¡¡çš„é€Ÿç‡å¤±çœŸæƒè¡¡å’Œæ›´å¿«çš„ç¼–ç ã€‚</li>
<li>æ”¹è¿›é‡‡æ ·ç‡ä¼˜åŒ–æ–¹æ³•ï¼Œæ˜¾è‘—æé«˜é€Ÿç‡å¤±çœŸæ€§èƒ½ã€‚</li>
<li>åœ¨BungeeNeRFä¸Šå®ç°äº†BDé€Ÿç‡é™ä½46.6%ï¼Œè®­ç»ƒæ—¶é—´æé€Ÿä¸‰å€ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.12862">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-03-18\./crop_3DGS/2503.12862v1/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-03-18\./crop_3DGS/2503.12862v1/page_1_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-03-18\./crop_3DGS/2503.12862v1/page_2_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-03-18\./crop_3DGS/2503.12862v1/page_3_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-03-18\./crop_3DGS/2503.12862v1/page_3_1.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-03-18\./crop_3DGS/2503.12862v1/page_4_0.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="Deblur-Gaussian-Splatting-SLAM"><a href="#Deblur-Gaussian-Splatting-SLAM" class="headerlink" title="Deblur Gaussian Splatting SLAM"></a>Deblur Gaussian Splatting SLAM</h2><p><strong>Authors:Francesco Girlanda, Denys Rozumnyi, Marc Pollefeys, Martin R. Oswald</strong></p>
<p>We present Deblur-SLAM, a robust RGB SLAM pipeline designed to recover sharp reconstructions from motion-blurred inputs. The proposed method bridges the strengths of both frame-to-frame and frame-to-model approaches to model sub-frame camera trajectories that lead to high-fidelity reconstructions in motion-blurred settings. Moreover, our pipeline incorporates techniques such as online loop closure and global bundle adjustment to achieve a dense and precise global trajectory. We model the physical image formation process of motion-blurred images and minimize the error between the observed blurry images and rendered blurry images obtained by averaging sharp virtual sub-frame images. Additionally, by utilizing a monocular depth estimator alongside the online deformation of Gaussians, we ensure precise mapping and enhanced image deblurring. The proposed SLAM pipeline integrates all these components to improve the results. We achieve state-of-the-art results for sharp map estimation and sub-frame trajectory recovery both on synthetic and real-world blurry input data. </p>
<blockquote>
<p>æˆ‘ä»¬æå‡ºäº†Deblur-SLAMï¼Œè¿™æ˜¯ä¸€ç§é²æ£’çš„RGB SLAMç®¡é“ï¼Œæ—¨åœ¨ä»è¿åŠ¨æ¨¡ç³Šè¾“å…¥ä¸­æ¢å¤æ¸…æ™°çš„é‡å»ºã€‚æ‰€æå‡ºçš„æ–¹æ³•ç»“åˆäº†å¸§é—´å’Œå¸§åˆ°æ¨¡å‹æ–¹æ³•çš„ä¼˜ç‚¹ï¼Œå¯¹ç›¸æœºå­å¸§è½¨è¿¹è¿›è¡Œå»ºæ¨¡ï¼Œä»è€Œåœ¨è¿åŠ¨æ¨¡ç³Šç¯å¢ƒä¸­å®ç°é«˜ä¿çœŸé‡å»ºã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬çš„ç®¡é“ç»“åˆäº†åœ¨çº¿é—­ç¯å’Œå…¨å±€æ†ç»‘è°ƒæ•´æŠ€æœ¯ï¼Œä»¥å®ç°å¯†é›†å’Œç²¾ç¡®çš„å…¨å±€è½¨è¿¹ã€‚æˆ‘ä»¬å¯¹è¿åŠ¨æ¨¡ç³Šå›¾åƒçš„ç‰©ç†æˆåƒè¿‡ç¨‹è¿›è¡Œå»ºæ¨¡ï¼Œå¹¶æœ€å°åŒ–è§‚å¯Ÿåˆ°çš„æ¨¡ç³Šå›¾åƒå’Œé€šè¿‡å¹³å‡é”åŒ–è™šæ‹Ÿå­å¸§å›¾åƒæ¸²æŸ“çš„æ¨¡ç³Šå›¾åƒä¹‹é—´çš„è¯¯å·®ã€‚æ­¤å¤–ï¼Œé€šè¿‡åˆ©ç”¨å•ç›®æ·±åº¦ä¼°è®¡å™¨å’Œåœ¨çº¿é«˜æ–¯å˜å½¢ï¼Œæˆ‘ä»¬ç¡®ä¿äº†ç²¾ç¡®æ˜ å°„å’Œå¢å¼ºçš„å›¾åƒå»æ¨¡ç³Šã€‚æ‰€æå‡ºçš„SLAMç®¡é“é›†æˆäº†æ‰€æœ‰è¿™äº›ç»„ä»¶ä»¥æ”¹è¿›ç»“æœã€‚æˆ‘ä»¬åœ¨åˆæˆå’ŒçœŸå®ä¸–ç•Œçš„æ¨¡ç³Šè¾“å…¥æ•°æ®ä¸Šéƒ½å®ç°äº†å…ˆè¿›çš„æ¸…æ™°åœ°å›¾ä¼°è®¡å’Œå­å¸§è½¨è¿¹æ¢å¤ç»“æœã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.12572v1">PDF</a> </p>
<p><strong>æ‘˜è¦</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†Deblur-SLAMï¼Œä¸€ç§ç”¨äºä»è¿åŠ¨æ¨¡ç³Šè¾“å…¥ä¸­æ¢å¤æ¸…æ™°é‡å»ºçš„é²æ£’RGB SLAMç®¡é“ã€‚è¯¥æ–¹æ³•ç»“åˆäº†å¸§é—´å’Œå¸§æ¨¡å‹æ–¹æ³•çš„ä¼˜ç‚¹ï¼Œå¯¹ç›¸æœºå­è½¨è¿¹è¿›è¡Œå»ºæ¨¡ï¼Œä»¥åœ¨è¿åŠ¨æ¨¡ç³Šçš„åœºæ™¯ä¸­å®ç°é«˜ä¿çœŸé‡å»ºã€‚æ­¤å¤–ï¼Œè¯¥ç®¡é“ç»“åˆäº†åœ¨çº¿é—­ç¯å’Œå…¨å±€æ†ç»‘è°ƒæ•´æŠ€æœ¯ï¼Œä»¥å®ç°å¯†é›†å’Œç²¾ç¡®çš„å…¨å±€è½¨è¿¹ã€‚æˆ‘ä»¬æ¨¡æ‹Ÿäº†è¿åŠ¨æ¨¡ç³Šå›¾åƒçš„ç‰©ç†æˆåƒè¿‡ç¨‹ï¼Œå¹¶æœ€å°åŒ–è§‚å¯Ÿåˆ°çš„æ¨¡ç³Šå›¾åƒä¸é€šè¿‡å¹³å‡é”åˆ©è™šæ‹Ÿå­å¸§å›¾åƒæ¸²æŸ“çš„æ¨¡ç³Šå›¾åƒä¹‹é—´çš„è¯¯å·®ã€‚æ­¤å¤–ï¼Œé€šè¿‡åˆ©ç”¨å•ç›®æ·±åº¦ä¼°è®¡å™¨å’Œåœ¨çº¿é«˜æ–¯å˜å½¢ï¼Œæˆ‘ä»¬ç¡®ä¿äº†ç²¾ç¡®æ˜ å°„å’Œå¢å¼ºçš„å›¾åƒå»æ¨¡ç³Šã€‚æ‰€æå‡ºçš„SLAMç®¡é“é›†æˆäº†æ‰€æœ‰è¿™äº›ç»„ä»¶ä»¥æ”¹è¿›ç»“æœã€‚æˆ‘ä»¬åœ¨åˆæˆå’ŒçœŸå®ä¸–ç•Œçš„æ¨¡ç³Šè¾“å…¥æ•°æ®ä¸Šå®ç°äº†æœ€å…ˆè¿›çš„æ¸…æ™°åœ°å›¾ä¼°è®¡å’Œå­å¸§è½¨è¿¹æ¢å¤ã€‚</p>
<p><strong>è¦ç‚¹æ‘˜è¦</strong></p>
<p>ä¸€ã€æå‡ºDeblur-SLAMï¼šä¸€ç§é²æ£’çš„RGB SLAMç®¡é“ï¼Œå¯ä»è¿åŠ¨æ¨¡ç³Šè¾“å…¥ä¸­æ¢å¤æ¸…æ™°é‡å»ºã€‚<br>äºŒã€ç»“åˆäº†å¸§é—´ä¸å¸§æ¨¡å‹æ–¹æ³•çš„ä¼˜åŠ¿ï¼Œå®ç°å­å¸§ç›¸æœºè½¨è¿¹å»ºæ¨¡ï¼Œé«˜ä¿çœŸé‡å»ºäºè¿åŠ¨æ¨¡ç³Šåœºæ™¯ã€‚<br>ä¸‰ã€é€šè¿‡åœ¨çº¿é—­ç¯å’Œå…¨å±€æ†ç»‘è°ƒæ•´æŠ€æœ¯å®ç°å¯†é›†ä¸”ç²¾ç¡®çš„å…¨å±€è½¨è¿¹ã€‚<br>å››ã€æ¨¡æ‹Ÿè¿åŠ¨æ¨¡ç³Šå›¾åƒçš„ç‰©ç†æˆåƒè¿‡ç¨‹ï¼Œæœ€å°åŒ–è§‚å¯Ÿæ¨¡ç³Šå›¾åƒä¸æ¸²æŸ“æ¨¡ç³Šå›¾åƒä¹‹é—´çš„è¯¯å·®ã€‚<br>äº”ã€ç»“åˆå•ç›®æ·±åº¦ä¼°è®¡å’Œåœ¨çº¿é«˜æ–¯å˜å½¢æŠ€æœ¯ï¼Œç¡®ä¿ç²¾ç¡®æ˜ å°„å’Œå›¾åƒå»æ¨¡ç³Šçš„å¢å¼ºæ•ˆæœã€‚<br>å…­ã€æ•´åˆå„ç»„ä»¶ä¼˜åŒ–ç»“æœï¼Œæé«˜æ¸…æ™°åœ°å›¾ä¼°è®¡å’Œå­å¸§è½¨è¿¹æ¢å¤çš„æ•ˆèƒ½ã€‚</p>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.12572">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-03-18\./crop_3DGS/2503.12572v1/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-03-18\./crop_3DGS/2503.12572v1/page_2_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-03-18\./crop_3DGS/2503.12572v1/page_3_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-03-18\./crop_3DGS/2503.12572v1/page_4_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-03-18\./crop_3DGS/2503.12572v1/page_5_0.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="Niagara-Normal-Integrated-Geometric-Affine-Field-for-Scene-Reconstruction-from-a-Single-View"><a href="#Niagara-Normal-Integrated-Geometric-Affine-Field-for-Scene-Reconstruction-from-a-Single-View" class="headerlink" title="Niagara: Normal-Integrated Geometric Affine Field for Scene   Reconstruction from a Single View"></a>Niagara: Normal-Integrated Geometric Affine Field for Scene   Reconstruction from a Single View</h2><p><strong>Authors:Xianzu Wu, Zhenxin Ai, Harry Yang, Ser-Nam Lim, Jun Liu, Huan Wang</strong></p>
<p>Recent advances in single-view 3D scene reconstruction have highlighted the challenges in capturing fine geometric details and ensuring structural consistency, particularly in high-fidelity outdoor scene modeling. This paper presents Niagara, a new single-view 3D scene reconstruction framework that can faithfully reconstruct challenging outdoor scenes from a single input image for the first time.   Our approach integrates monocular depth and normal estimation as input, which substantially improves its ability to capture fine details, mitigating common issues like geometric detail loss and deformation.   Additionally, we introduce a geometric affine field (GAF) and 3D self-attention as geometry-constraint, which combines the structural properties of explicit geometry with the adaptability of implicit feature fields, striking a balance between efficient rendering and high-fidelity reconstruction.   Our framework finally proposes a specialized encoder-decoder architecture, where a depth-based 3D Gaussian decoder is proposed to predict 3D Gaussian parameters, which can be used for novel view synthesis. Extensive results and analyses suggest that our Niagara surpasses prior SoTA approaches such as Flash3D in both single-view and dual-view settings, significantly enhancing the geometric accuracy and visual fidelity, especially in outdoor scenes. </p>
<blockquote>
<p>è¿‘æœŸå•è§†å›¾ä¸‰ç»´åœºæ™¯é‡å»ºçš„æœ€æ–°è¿›å±•å‡¸æ˜¾äº†æ•æ‰ç²¾ç»†å‡ ä½•ç»†èŠ‚å’Œç¡®ä¿ç»“æ„ä¸€è‡´æ€§çš„æŒ‘æˆ˜ï¼Œç‰¹åˆ«æ˜¯åœ¨é«˜ä¿çœŸå®¤å¤–åœºæ™¯å»ºæ¨¡ä¸­ã€‚æœ¬æ–‡æå‡ºäº†Niagaraï¼Œè¿™æ˜¯ä¸€ä¸ªæ–°çš„å•è§†å›¾ä¸‰ç»´åœºæ™¯é‡å»ºæ¡†æ¶ï¼Œèƒ½å¤Ÿé¦–æ¬¡ä»å•ä¸ªè¾“å…¥å›¾åƒå¿ å®åœ°é‡å»ºå…·æœ‰æŒ‘æˆ˜æ€§çš„å®¤å¤–åœºæ™¯ã€‚æˆ‘ä»¬çš„æ–¹æ³•å°†å•ç›®æ·±åº¦ä¼°è®¡å’Œæ³•çº¿ä¼°è®¡ä½œä¸ºè¾“å…¥è¿›è¡Œèåˆï¼Œè¿™æå¤§åœ°æé«˜äº†æ•æ‰ç»†èŠ‚çš„èƒ½åŠ›ï¼Œç¼“è§£äº†å¸¸è§çš„å‡ ä½•ç»†èŠ‚ä¸¢å¤±å’Œå˜å½¢ç­‰é—®é¢˜ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å¼•å…¥äº†å‡ ä½•ä»¿å°„åœºï¼ˆGAFï¼‰å’Œä¸‰ç»´è‡ªæ³¨æ„åŠ›ä½œä¸ºå‡ ä½•çº¦æŸï¼Œç»“åˆäº†æ˜¾å¼å‡ ä½•çš„ç»“æ„å±æ€§å’Œéšå¼ç‰¹å¾åœºçš„é€‚åº”æ€§ï¼Œåœ¨é«˜æ•ˆæ¸²æŸ“å’Œé«˜ä¿çœŸé‡å»ºä¹‹é—´å–å¾—äº†å¹³è¡¡ã€‚æˆ‘ä»¬çš„æ¡†æ¶æœ€åæå‡ºäº†ä¸€ç§ä¸“é—¨çš„ç¼–ç å™¨-è§£ç å™¨æ¶æ„ï¼Œå…¶ä¸­æå‡ºäº†ä¸€ç§åŸºäºæ·±åº¦çš„ä¸‰ç»´é«˜æ–¯è§£ç å™¨ï¼Œç”¨äºé¢„æµ‹ä¸‰ç»´é«˜æ–¯å‚æ•°ï¼Œè¿™äº›å‚æ•°å¯ç”¨äºæ–°è§†è§’çš„åˆæˆã€‚å¹¿æ³›çš„ç»“æœå’Œåˆ†æè¡¨æ˜ï¼Œæˆ‘ä»¬çš„Niagaraåœ¨å•è§†å›¾å’ŒåŒè§†å›¾è®¾ç½®ä¸­éƒ½è¶…è¶Šäº†æœ€æ–°çš„Flash3Dç­‰å…ˆè¿›æ–¹æ³•ï¼Œæ˜¾è‘—æé«˜äº†å‡ ä½•ç²¾åº¦å’Œè§†è§‰ä¿çœŸåº¦ï¼Œç‰¹åˆ«æ˜¯åœ¨å®¤å¤–åœºæ™¯ä¸­ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.12553v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†Niagaraï¼Œä¸€ç§æ–°å‹çš„å•è§†å›¾3Dåœºæ™¯é‡å»ºæ¡†æ¶ï¼Œèƒ½å¤Ÿé¦–æ¬¡ä»å•ä¸€è¾“å…¥å›¾åƒé‡å»ºå…·æœ‰æŒ‘æˆ˜æ€§çš„æˆ·å¤–åœºæ™¯ã€‚å®ƒæ•´åˆäº†å•ç›®æ·±åº¦ä¸æ³•çº¿ä¼°è®¡ä½œä¸ºè¾“å…¥ï¼Œå¤§å¹…æå‡äº†æ•æ‰ç»†èŠ‚çš„èƒ½åŠ›ï¼Œè§£å†³äº†å¸¸è§çš„å‡ ä½•ç»†èŠ‚ä¸¢å¤±å’Œå˜å½¢é—®é¢˜ã€‚æ­¤å¤–ï¼Œå¼•å…¥äº†å‡ ä½•ä»¿å°„åœºï¼ˆGAFï¼‰å’Œ3Dè‡ªæ³¨æ„åŠ›ä½œä¸ºå‡ ä½•çº¦æŸï¼Œç»“åˆäº†æ˜¾å¼å‡ ä½•çš„ç»“æ„å±æ€§ä¸éšå¼ç‰¹å¾åœºçš„é€‚åº”æ€§ï¼Œå®ç°äº†é«˜æ•ˆæ¸²æŸ“ä¸é«˜ä¿çœŸé‡å»ºä¹‹é—´çš„å¹³è¡¡ã€‚æ¡†æ¶è¿˜æå‡ºäº†ä¸€ç§ç‰¹æ®Šçš„ç¼–ç -è§£ç æ¶æ„ï¼Œæå‡ºä¸€ç§åŸºäºæ·±åº¦çš„3Dé«˜æ–¯è§£ç å™¨ï¼Œç”¨äºé¢„æµ‹3Dé«˜æ–¯å‚æ•°ï¼Œå¯ç”¨äºæ–°è§†è§’åˆæˆã€‚ç ”ç©¶ç»“æœåˆ†æè¡¨æ˜ï¼ŒNiagaraåœ¨å•è§†å›¾å’ŒåŒè§†å›¾è®¾ç½®ä¸­è¶…è¶Šäº†ç°æœ‰å…ˆè¿›æŠ€æœ¯å¦‚Flash3Dï¼Œæ˜¾è‘—æé«˜äº†å‡ ä½•ç²¾åº¦å’Œè§†è§‰ä¿çœŸåº¦ï¼Œç‰¹åˆ«æ˜¯åœ¨æˆ·å¤–åœºæ™¯ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>Niagaraæ˜¯ä¸€ä¸ªæ–°å‹çš„å•è§†å›¾3Dåœºæ™¯é‡å»ºæ¡†æ¶ï¼Œèƒ½å¤Ÿé‡å»ºå…·æœ‰æŒ‘æˆ˜æ€§çš„æˆ·å¤–åœºæ™¯ã€‚</li>
<li>æ•´åˆå•ç›®æ·±åº¦ä¸æ³•çº¿ä¼°è®¡æå‡äº†æ•æ‰ç»†èŠ‚çš„èƒ½åŠ›ã€‚</li>
<li>å¼•å…¥å‡ ä½•ä»¿å°„åœºï¼ˆGAFï¼‰å’Œ3Dè‡ªæ³¨æ„åŠ›ä½œä¸ºå‡ ä½•çº¦æŸï¼Œå®ç°é«˜æ•ˆä¸é«˜è´¨é‡é‡å»ºçš„å¹³è¡¡ã€‚</li>
<li>æå‡ºçš„ç¼–ç -è§£ç æ¶æ„ä¸­åŒ…å«ä¸€ä¸ªåŸºäºæ·±åº¦çš„3Dé«˜æ–¯è§£ç å™¨ï¼Œç”¨äºé¢„æµ‹3Dé«˜æ–¯å‚æ•°ã€‚</li>
<li>Niagaraæ¡†æ¶èƒ½å¤Ÿè¿›è¡Œæ–°è§†è§’åˆæˆã€‚</li>
<li>ä¸ç°æœ‰æŠ€æœ¯ç›¸æ¯”ï¼ŒNiagaraåœ¨å‡ ä½•ç²¾åº¦å’Œè§†è§‰ä¿çœŸåº¦ä¸Šè¡¨ç°æ›´ä½³ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.12553">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-03-18\./crop_3DGS/2503.12553v1/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-03-18\./crop_3DGS/2503.12553v1/page_1_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-03-18\./crop_3DGS/2503.12553v1/page_2_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-03-18\./crop_3DGS/2503.12553v1/page_5_0.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="SPC-GS-Gaussian-Splatting-with-Semantic-Prompt-Consistency-for-Indoor-Open-World-Free-view-Synthesis-from-Sparse-Inputs"><a href="#SPC-GS-Gaussian-Splatting-with-Semantic-Prompt-Consistency-for-Indoor-Open-World-Free-view-Synthesis-from-Sparse-Inputs" class="headerlink" title="SPC-GS: Gaussian Splatting with Semantic-Prompt Consistency for Indoor   Open-World Free-view Synthesis from Sparse Inputs"></a>SPC-GS: Gaussian Splatting with Semantic-Prompt Consistency for Indoor   Open-World Free-view Synthesis from Sparse Inputs</h2><p><strong>Authors:Guibiao Liao, Qing Li, Zhenyu Bao, Guoping Qiu, Kanglin Liu</strong></p>
<p>3D Gaussian Splatting-based indoor open-world free-view synthesis approaches have shown significant performance with dense input images. However, they exhibit poor performance when confronted with sparse inputs, primarily due to the sparse distribution of Gaussian points and insufficient view supervision. To relieve these challenges, we propose SPC-GS, leveraging Scene-layout-based Gaussian Initialization (SGI) and Semantic-Prompt Consistency (SPC) Regularization for open-world free view synthesis with sparse inputs. Specifically, SGI provides a dense, scene-layout-based Gaussian distribution by utilizing view-changed images generated from the video generation model and view-constraint Gaussian points densification. Additionally, SPC mitigates limited view supervision by employing semantic-prompt-based consistency constraints developed by SAM2. This approach leverages available semantics from training views, serving as instructive prompts, to optimize visually overlapping regions in novel views with 2D and 3D consistency constraints. Extensive experiments demonstrate the superior performance of SPC-GS across Replica and ScanNet benchmarks. Notably, our SPC-GS achieves a 3.06 dB gain in PSNR for reconstruction quality and a 7.3% improvement in mIoU for open-world semantic segmentation. </p>
<blockquote>
<p>åŸºäºä¸‰ç»´é«˜æ–¯ç‚¹æ‰©æ•£çš„å®¤å†…å¼€æ”¾ä¸–ç•Œè‡ªç”±è§†è§’åˆæˆæ–¹æ³•åœ¨å¤„ç†å¯†é›†è¾“å…¥å›¾åƒæ—¶è¡¨ç°å‡ºæ˜¾è‘—çš„æ€§èƒ½ã€‚ç„¶è€Œï¼Œåœ¨é¢å¯¹ç¨€ç–è¾“å…¥æ—¶ï¼Œå…¶æ€§èƒ½è¾ƒå·®ï¼Œè¿™ä¸»è¦æ˜¯ç”±äºé«˜æ–¯ç‚¹çš„ç¨€ç–åˆ†å¸ƒå’Œè§†å›¾ç›‘ç£ä¸è¶³ã€‚ä¸ºäº†ç¼“è§£è¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†SPC-GSæ–¹æ³•ï¼Œåˆ©ç”¨åŸºäºåœºæ™¯å¸ƒå±€çš„Gaussianåˆå§‹åŒ–ï¼ˆSGIï¼‰å’Œè¯­ä¹‰æç¤ºä¸€è‡´æ€§ï¼ˆSPCï¼‰æ­£åˆ™åŒ–ï¼Œå®ç°ç¨€ç–è¾“å…¥çš„å¼€æ”¾ä¸–ç•Œè‡ªç”±è§†è§’åˆæˆã€‚å…·ä½“æ¥è¯´ï¼ŒSGIé€šè¿‡åˆ©ç”¨è§†é¢‘ç”Ÿæˆæ¨¡å‹äº§ç”Ÿçš„è§†å›¾æ”¹å˜å›¾åƒå’Œè§†å›¾çº¦æŸçš„é«˜æ–¯ç‚¹ç¨ åŒ–æŠ€æœ¯ï¼Œæä¾›äº†ä¸€ç§åŸºäºåœºæ™¯å¸ƒå±€çš„å¯†é›†é«˜æ–¯åˆ†å¸ƒã€‚æ­¤å¤–ï¼ŒSPCé€šè¿‡é‡‡ç”¨SAM2å¼€å‘çš„åŸºäºè¯­ä¹‰æç¤ºçš„ä¸€è‡´æ€§çº¦æŸï¼Œç¼“è§£äº†æœ‰é™çš„è§†å›¾ç›‘ç£é—®é¢˜ã€‚è¯¥æ–¹æ³•åˆ©ç”¨è®­ç»ƒè§†å›¾ä¸­çš„å¯ç”¨è¯­ä¹‰ä½œä¸ºæŒ‡å¯¼æ€§æç¤ºï¼Œé€šè¿‡äºŒç»´å’Œä¸‰ç»´ä¸€è‡´æ€§çº¦æŸä¼˜åŒ–æ–°è§†è§’ä¸­çš„è§†è§‰é‡å åŒºåŸŸã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼ŒSPC-GSåœ¨Replicaå’ŒScanNetåŸºå‡†æµ‹è¯•ä¸­è¡¨ç°å‡ºå“è¶Šçš„æ€§èƒ½ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œæˆ‘ä»¬çš„SPC-GSåœ¨é‡å»ºè´¨é‡ä¸Šæé«˜äº†3.06 dBçš„PSNRï¼Œåœ¨å¼€æ”¾ä¸–ç•Œè¯­ä¹‰åˆ†å‰²ä¸Šæé«˜äº†7.3%çš„mIoUã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.12535v1">PDF</a> Accepted by CVPR2025. The project page is available at   <a target="_blank" rel="noopener" href="https://gbliao.github.io/SPC-GS.github.io/">https://gbliao.github.io/SPC-GS.github.io/</a></p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†åŸºäºä¸‰ç»´é«˜æ–¯èåˆæŠ€æœ¯çš„å®¤å†…å¼€æ”¾ä¸–ç•Œè‡ªç”±è§†è§’åˆæˆæ–¹æ³•ï¼Œå¯¹äºå¯†é›†è¾“å…¥å›¾åƒè¡¨ç°å‡ºè‰¯å¥½çš„æ€§èƒ½ã€‚ä½†å½“é¢å¯¹ç¨€ç–è¾“å…¥æ—¶ï¼Œå…¶æ€§èƒ½ä¸ä½³ã€‚ä¸ºåº”å¯¹è¿™äº›æŒ‘æˆ˜ï¼Œæå‡ºSPC-GSæ–¹æ³•ï¼Œé‡‡ç”¨åŸºäºåœºæ™¯å¸ƒå±€çš„é«˜æ–¯åˆå§‹åŒ–ï¼ˆSGIï¼‰å’Œè¯­ä¹‰æç¤ºä¸€è‡´æ€§ï¼ˆSPCï¼‰æ­£åˆ™åŒ–æŠ€æœ¯ã€‚SGIé€šè¿‡è§†é¢‘ç”Ÿæˆæ¨¡å‹ç”Ÿæˆçš„è§†å›¾å˜åŒ–å›¾åƒå’Œè§†å›¾çº¦æŸé«˜æ–¯ç‚¹å¯†é›†åŒ–ï¼Œæä¾›å¯†é›†çš„åœºæ™¯å¸ƒå±€é«˜æ–¯åˆ†å¸ƒã€‚SPCåˆ™é€šè¿‡SAM2å¼€å‘çš„è¯­ä¹‰æç¤ºä¸€è‡´æ€§çº¦æŸæ¥ç¼“è§£æœ‰é™çš„è§†å›¾ç›‘ç£é—®é¢˜ã€‚è¯¥æ–¹æ³•åˆ©ç”¨è®­ç»ƒè§†å›¾ä¸­çš„å¯ç”¨è¯­ä¹‰ä½œä¸ºæŒ‡å¯¼æ€§æç¤ºï¼Œé€šè¿‡äºŒç»´å’Œä¸‰ç»´ä¸€è‡´æ€§çº¦æŸä¼˜åŒ–æ–°è§†è§’çš„è§†è§‰é‡å åŒºåŸŸã€‚å®éªŒè¡¨æ˜ï¼Œåœ¨Replicaå’ŒScanNetåŸºå‡†æµ‹è¯•ä¸­ï¼ŒSPC-GSæ€§èƒ½å“è¶Šï¼Œå…¶ä¸­é‡å»ºè´¨é‡åœ¨PSNRä¸Šæé«˜äº†3.06 dBï¼Œå¼€æ”¾ä¸–ç•Œè¯­ä¹‰åˆ†å‰²çš„mIoUæé«˜äº†7.3%ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>3D Gaussian Splattingæ–¹æ³•åœ¨å®¤å†…å¼€æ”¾ä¸–ç•Œè‡ªç”±è§†è§’åˆæˆä¸­è¡¨ç°è‰¯å¥½ï¼Œä½†åœ¨ç¨€ç–è¾“å…¥æ—¶æ€§èƒ½ä¸‹é™ã€‚</li>
<li>æå‡ºSPC-GSæ–¹æ³•ï¼ŒåŒ…å«SGIå’ŒSPCä¸¤å¤§æŠ€æœ¯æ¥æ”¹è¿›æ€§èƒ½ã€‚</li>
<li>SGIæä¾›å¯†é›†çš„åœºæ™¯å¸ƒå±€é«˜æ–¯åˆ†å¸ƒï¼Œåˆ©ç”¨è§†å›¾å˜åŒ–å›¾åƒå’Œè§†å›¾çº¦æŸé«˜æ–¯ç‚¹å¯†é›†åŒ–ã€‚</li>
<li>SPCé€šè¿‡è¯­ä¹‰æç¤ºä¸€è‡´æ€§çº¦æŸä¼˜åŒ–æ–°è§†è§’çš„è§†è§‰é‡å åŒºåŸŸï¼Œç¼“è§£æœ‰é™çš„è§†å›¾ç›‘ç£é—®é¢˜ã€‚</li>
<li>è¯¥æ–¹æ³•åˆ©ç”¨è®­ç»ƒè§†å›¾ä¸­çš„å¯ç”¨è¯­ä¹‰ä½œä¸ºæŒ‡å¯¼æ€§æç¤ºï¼Œé‡‡ç”¨äºŒç»´å’Œä¸‰ç»´ä¸€è‡´æ€§çº¦æŸã€‚</li>
<li>å®éªŒç»“æœæ˜¾ç€ï¼Œåœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­ï¼ŒSPC-GSæ€§èƒ½è¶…è¶Šç°æœ‰æ–¹æ³•ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.12535">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-03-18\./crop_3DGS/2503.12535v1/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-03-18\./crop_3DGS/2503.12535v1/page_3_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-03-18\./crop_3DGS/2503.12535v1/page_4_0.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="GS-3I-Gaussian-Splatting-for-Surface-Reconstruction-from-Illumination-Inconsistent-Images"><a href="#GS-3I-Gaussian-Splatting-for-Surface-Reconstruction-from-Illumination-Inconsistent-Images" class="headerlink" title="GS-3I: Gaussian Splatting for Surface Reconstruction from   Illumination-Inconsistent Images"></a>GS-3I: Gaussian Splatting for Surface Reconstruction from   Illumination-Inconsistent Images</h2><p><strong>Authors:Tengfei Wang, Yongmao Hou, Zhaoning Zhang, Yiwei Xu, Zongqian Zhan, Xin Wang</strong></p>
<p>Accurate geometric surface reconstruction, providing essential environmental information for navigation and manipulation tasks, is critical for enabling robotic self-exploration and interaction. Recently, 3D Gaussian Splatting (3DGS) has gained significant attention in the field of surface reconstruction due to its impressive geometric quality and computational efficiency. While recent relevant advancements in novel view synthesis under inconsistent illumination using 3DGS have shown promise, the challenge of robust surface reconstruction under such conditions is still being explored. To address this challenge, we propose a method called GS-3I. Specifically, to mitigate 3D Gaussian optimization bias caused by underexposed regions in single-view images, based on Convolutional Neural Network (CNN), a tone mapping correction framework is introduced. Furthermore, inconsistent lighting across multi-view images, resulting from variations in camera settings and complex scene illumination, often leads to geometric constraint mismatches and deviations in the reconstructed surface. To overcome this, we propose a normal compensation mechanism that integrates reference normals extracted from single-view image with normals computed from multi-view observations to effectively constrain geometric inconsistencies. Extensive experimental evaluations demonstrate that GS-3I can achieve robust and accurate surface reconstruction across complex illumination scenarios, highlighting its effectiveness and versatility in this critical challenge. <a target="_blank" rel="noopener" href="https://github.com/TFwang-9527/GS-3I">https://github.com/TFwang-9527/GS-3I</a> </p>
<blockquote>
<p>ç²¾ç¡®å‡ ä½•è¡¨é¢é‡å»ºå¯¹äºå®ç°æœºå™¨äººçš„è‡ªæˆ‘æ¢ç´¢å’Œäº¤äº’è‡³å…³é‡è¦ï¼Œå®ƒä¸ºå¯¼èˆªå’Œæ“ä½œä»»åŠ¡æä¾›äº†åŸºæœ¬çš„ç¯å¢ƒä¿¡æ¯ã€‚è¿‘æœŸï¼Œç”±äºå…¶åœ¨å‡ ä½•è´¨é‡å’Œè®¡ç®—æ•ˆç‡æ–¹é¢çš„å‡ºè‰²è¡¨ç°ï¼Œ3Dé«˜æ–¯æ‹¼è´´ï¼ˆ3DGSï¼‰åœ¨è¡¨é¢é‡å»ºé¢†åŸŸå¼•èµ·äº†å¹¿æ³›å…³æ³¨ã€‚å°½ç®¡æœ€è¿‘ä½¿ç”¨3DGSåœ¨ä¸ä¸€è‡´ç…§æ˜ä¸‹è¿›è¡Œæ–°è§†è§’åˆæˆçš„ç›¸å…³ç ”ç©¶å–å¾—äº†ä»¤äººé¼“èˆçš„ç»“æœï¼Œä½†åœ¨è¿™äº›æ¡ä»¶ä¸‹å®ç°ç¨³å¥çš„è¡¨é¢é‡å»ºä»æ˜¯ä¸€ä¸ªæŒ‘æˆ˜ã€‚ä¸ºäº†åº”å¯¹è¿™ä¸€æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åä¸ºGS-3Içš„æ–¹æ³•ã€‚å…·ä½“æ¥è¯´ï¼Œä¸ºäº†å‡è½»ç”±äºå•è§†å›¾å›¾åƒä¸­æ›å…‰ä¸è¶³åŒºåŸŸå¯¼è‡´çš„3Dé«˜æ–¯ä¼˜åŒ–åå·®ï¼Œæˆ‘ä»¬åŸºäºå·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNï¼‰å¼•å…¥äº†ä¸€ç§è‰²è°ƒæ˜ å°„æ ¡æ­£æ¡†æ¶ã€‚æ­¤å¤–ï¼Œç”±äºç›¸æœºè®¾ç½®å’Œå¤æ‚åœºæ™¯ç…§æ˜çš„å˜åŒ–ï¼Œå¤šè§†å›¾å›¾åƒä¹‹é—´çš„ç…§æ˜ä¸ä¸€è‡´å¸¸å¸¸å¯¼è‡´å‡ ä½•çº¦æŸä¸åŒ¹é…å’Œé‡å»ºè¡¨é¢çš„åå·®ã€‚ä¸ºäº†å…‹æœè¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ³•çº¿è¡¥å¿æœºåˆ¶ï¼Œè¯¥æœºåˆ¶å°†å•è§†å›¾å›¾åƒä¸­æå–çš„å‚è€ƒæ³•çº¿ä¸å¤šè§†å›¾è§‚å¯Ÿè®¡ç®—å¾—åˆ°çš„æ³•çº¿ç›¸ç»“åˆï¼Œä»¥æœ‰æ•ˆåœ°çº¦æŸå‡ ä½•ä¸ä¸€è‡´æ€§ã€‚å¹¿æ³›çš„å®éªŒè¯„ä¼°è¡¨æ˜ï¼ŒGS-3Iå¯ä»¥åœ¨å¤æ‚çš„ç…§æ˜åœºæ™¯ä¸‹å®ç°ç¨³å¥è€Œå‡†ç¡®çš„è¡¨é¢é‡å»ºï¼Œçªæ˜¾äº†å…¶åœ¨åº”å¯¹è¿™ä¸€å…³é”®æŒ‘æˆ˜ä¸­çš„æœ‰æ•ˆæ€§å’Œé€šç”¨æ€§ã€‚ç›¸å…³ä»£ç åœ°å€ï¼š<a target="_blank" rel="noopener" href="https://github.com/TFwang-9527/GS-3I">https://github.com/TFwang-9527/GS-3I</a> ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.12335v1">PDF</a> This paper has been submitted to IROS 2025</p>
<p><strong>Summary</strong></p>
<p>åŸºäºæ·±åº¦å­¦ä¹ å’Œç¥ç»ç½‘ç»œæ¨¡å‹çš„ä¼˜åŒ–æ–¹æ³•â€”â€”GS-3Ièƒ½å¤Ÿé’ˆå¯¹æœºå™¨äººè‡ªæˆ‘æ¢ç´¢ä¸äº¤äº’ä¸­çš„å¯¼èˆªä¸æ“æ§ä»»åŠ¡è¿›è¡Œå‡†ç¡®çš„å‡ ä½•è¡¨é¢é‡å»ºã€‚å®ƒé€šè¿‡ç»“åˆå•è§†å›¾å›¾åƒçš„è‰²è°ƒæ˜ å°„ä¿®æ­£ä¸å¤šè§†è§’è§‚å¯Ÿçš„å‡ ä½•è¡¥å¿æœºåˆ¶ï¼Œå…‹æœäº†ä¸ä¸€è‡´å…‰ç…§ç¯å¢ƒä¸‹é‡å»ºè¡¨é¢çš„éš¾é¢˜ã€‚ç»è¿‡å¤§é‡å®éªŒéªŒè¯ï¼ŒGS-3Iåœ¨å¤æ‚å…‰ç…§åœºæ™¯ä¸‹å®ç°äº†ç¨³å¥å‡†ç¡®çš„è¡¨é¢é‡å»ºã€‚è¯¥æ–¹æ³•å¯¹äºå®ç°æœºå™¨äººè‡ªä¸»å¯¼èˆªå’Œäº¤äº’å…·æœ‰å…³é”®ä½œç”¨ã€‚æ›´å¤šä¿¡æ¯è¯·å‚è§GitHubé“¾æ¥ï¼ˆè§ä¸Šæ–‡ï¼‰ã€‚<br><a target="_blank" rel="noopener" href="https://github.com/TFwang-9527/GS-3I%E3%80%82">https://github.com/TFwang-9527/GS-3Iã€‚</a></p>
<p><strong>Key Takeaways</strong></p>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.12335">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-03-18\./crop_3DGS/2503.12335v1/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-03-18\./crop_3DGS/2503.12335v1/page_1_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-03-18\./crop_3DGS/2503.12335v1/page_3_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-03-18\./crop_3DGS/2503.12335v1/page_4_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-03-18\./crop_3DGS/2503.12335v1/page_5_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-03-18\./crop_3DGS/2503.12335v1/page_5_1.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-03-18\./crop_3DGS/2503.12335v1/page_5_2.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="Swift4D-Adaptive-divide-and-conquer-Gaussian-Splatting-for-compact-and-efficient-reconstruction-of-dynamic-scene"><a href="#Swift4D-Adaptive-divide-and-conquer-Gaussian-Splatting-for-compact-and-efficient-reconstruction-of-dynamic-scene" class="headerlink" title="Swift4D:Adaptive divide-and-conquer Gaussian Splatting for compact and   efficient reconstruction of dynamic scene"></a>Swift4D:Adaptive divide-and-conquer Gaussian Splatting for compact and   efficient reconstruction of dynamic scene</h2><p><strong>Authors:Jiahao Wu, Rui Peng, Zhiyan Wang, Lu Xiao, Luyang Tang, Jinbo Yan, Kaiqiang Xiong, Ronggang Wang</strong></p>
<p>Novel view synthesis has long been a practical but challenging task, although the introduction of numerous methods to solve this problem, even combining advanced representations like 3D Gaussian Splatting, they still struggle to recover high-quality results and often consume too much storage memory and training time. In this paper we propose Swift4D, a divide-and-conquer 3D Gaussian Splatting method that can handle static and dynamic primitives separately, achieving a good trade-off between rendering quality and efficiency, motivated by the fact that most of the scene is the static primitive and does not require additional dynamic properties. Concretely, we focus on modeling dynamic transformations only for the dynamic primitives which benefits both efficiency and quality. We first employ a learnable decomposition strategy to separate the primitives, which relies on an additional parameter to classify primitives as static or dynamic. For the dynamic primitives, we employ a compact multi-resolution 4D Hash mapper to transform these primitives from canonical space into deformation space at each timestamp, and then mix the static and dynamic primitives to produce the final output. This divide-and-conquer method facilitates efficient training and reduces storage redundancy. Our method not only achieves state-of-the-art rendering quality while being 20X faster in training than previous SOTA methods with a minimum storage requirement of only 30MB on real-world datasets. Code is available at <a target="_blank" rel="noopener" href="https://github.com/WuJH2001/swift4d">https://github.com/WuJH2001/swift4d</a>. </p>
<blockquote>
<p>æ–°é¢–è§†å›¾åˆæˆé•¿æœŸä»¥æ¥æ˜¯ä¸€é¡¹å®ç”¨çš„ä¸”å…·æœ‰æŒ‘æˆ˜æ€§çš„ä»»åŠ¡ã€‚å°½ç®¡å¼•å…¥äº†å¤šç§æ–¹æ³•æ¥è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œå³ä½¿ç»“åˆåƒ3Dé«˜æ–¯å¹³é“ºè¿™æ ·çš„é«˜çº§è¡¨ç¤ºï¼Œå®ƒä»¬ä»ç„¶éš¾ä»¥æ¢å¤é«˜è´¨é‡çš„ç»“æœï¼Œå¹¶ä¸”ç»å¸¸æ¶ˆè€—å¤§é‡çš„å­˜å‚¨å†…å­˜å’Œè®­ç»ƒæ—¶é—´ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†Swift4Dï¼Œè¿™æ˜¯ä¸€ç§åˆ†è€Œæ²»ä¹‹çš„3Dé«˜æ–¯å¹³é“ºæ–¹æ³•ï¼Œå¯ä»¥åˆ†åˆ«å¤„ç†é™æ€å’ŒåŠ¨æ€åŸºæœ¬å…ƒç´ ï¼Œåœ¨æ¸²æŸ“è´¨é‡å’Œæ•ˆç‡ä¹‹é—´è¾¾åˆ°äº†è‰¯å¥½çš„å¹³è¡¡ã€‚è¿™å—åˆ°äº†åœºæ™¯ä¸­å¤§éƒ¨åˆ†æ˜¯é™æ€åŸºæœ¬å…ƒç´ ï¼Œä¸éœ€è¦é¢å¤–åŠ¨æ€å±æ€§çš„å¯å‘ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬ä¸“æ³¨äºä»…å¯¹åŠ¨æ€åŸºæœ¬å…ƒç´ è¿›è¡ŒåŠ¨æ€è½¬æ¢å»ºæ¨¡ï¼Œè¿™æœ‰åˆ©äºæ•ˆç‡å’Œè´¨é‡çš„æé«˜ã€‚æˆ‘ä»¬é¦–å…ˆé‡‡ç”¨ä¸€ç§å¯å­¦ä¹ çš„åˆ†è§£ç­–ç•¥æ¥åˆ†ç¦»åŸºæœ¬å…ƒç´ ï¼Œè¿™ä¾èµ–äºä¸€ä¸ªé¢å¤–çš„å‚æ•°æ¥å°†åŸºæœ¬å…ƒç´ åˆ†ç±»ä¸ºé™æ€æˆ–åŠ¨æ€ã€‚å¯¹äºåŠ¨æ€åŸºæœ¬å…ƒç´ ï¼Œæˆ‘ä»¬é‡‡ç”¨ç´§å‡‘çš„å¤šåˆ†è¾¨ç‡4Då“ˆå¸Œæ˜ å°„å™¨ï¼Œå°†è¿™äº›åŸºæœ¬å…ƒç´ ä»è§„èŒƒç©ºé—´è½¬æ¢åˆ°æ¯ä¸ªæ—¶é—´æˆ³çš„å˜å½¢ç©ºé—´ï¼Œç„¶åå°†é™æ€å’ŒåŠ¨æ€åŸºæœ¬å…ƒç´ æ··åˆä»¥äº§ç”Ÿæœ€ç»ˆè¾“å‡ºã€‚è¿™ç§åˆ†è€Œæ²»ä¹‹çš„æ–¹æ³•ä¿ƒè¿›äº†é«˜æ•ˆçš„è®­ç»ƒï¼Œå¹¶å‡å°‘äº†å­˜å‚¨å†—ä½™ã€‚æˆ‘ä»¬çš„æ–¹æ³•ä¸ä»…è¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ¸²æŸ“è´¨é‡ï¼Œè€Œä¸”åœ¨çœŸå®ä¸–ç•Œæ•°æ®é›†ä¸Šçš„è®­ç»ƒé€Ÿåº¦æ¯”ä¹‹å‰çš„æœ€ä½³æ–¹æ³•å¿«20å€ï¼Œå­˜å‚¨è¦æ±‚æœ€ä½åªæœ‰30MBã€‚ä»£ç å¯åœ¨&lt;<a target="_blank" rel="noopener" href="https://github.com/WuJH20intop_textnbspl_chinese%E5%9C%A8google%E6%89%BE%EF%BC%9A%E6%99%AE%E9%80%9A%E5%9C%A8%E7%BA%BF%E5%B9%B3%E5%8F%B0%E5%AF%B9%E4%BA%8E%E5%90%8C%E6%97%B6%E6%87%82%E8%8B%B1%E6%96%87%E5%92%8C%E7%AE%80%E5%8C%96%E4%B8%AD%E6%96%87%E7%9A%84%E4%BA%BA%E6%9D%A5%E8%AF%B4%E9%9D%9E%E5%B8%B8%E7%AE%80%E5%8D%95%E3%80%82">https://github.com/WuJH20intop_textnbspl_chineseåœ¨googleæ‰¾ï¼šæ™®é€šåœ¨çº¿å¹³å°å¯¹äºåŒæ—¶æ‡‚è‹±æ–‡å’Œç®€åŒ–ä¸­æ–‡çš„äººæ¥è¯´éå¸¸ç®€å•ã€‚</a><swift4d>æ‰¾åˆ°ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.12307v1">PDF</a> ICLR 2025</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸ºSwift4Dçš„åŸºäºåˆ†æ²»ç­–ç•¥çš„3Dé«˜æ–¯è´´ç‰‡æ–¹æ³•ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿé’ˆå¯¹é™æ€å’ŒåŠ¨æ€åŸºæœ¬å…ƒç´ è¿›è¡Œå•ç‹¬å¤„ç†ï¼Œåœ¨æ¸²æŸ“è´¨é‡å’Œæ•ˆç‡ä¹‹é—´å–å¾—äº†è‰¯å¥½çš„å¹³è¡¡ã€‚è¯¥æ–¹æ³•é€šè¿‡ä»…å¯¹åŠ¨æ€åŸºæœ¬å…ƒç´ è¿›è¡ŒåŠ¨æ€è½¬æ¢å»ºæ¨¡ï¼Œæé«˜äº†æ•ˆç‡å’Œè´¨é‡ã€‚Swift4Dä½¿ç”¨ä¸€ç§å¯å­¦ä¹ çš„åˆ†è§£ç­–ç•¥æ¥åˆ†ç¦»åŸºæœ¬å…ƒç´ ï¼Œå¹¶åˆ©ç”¨ä¸€ä¸ªé¢å¤–çš„å‚æ•°æ¥å°†åŸºæœ¬å…ƒç´ åˆ†ç±»ä¸ºé™æ€æˆ–åŠ¨æ€ã€‚å¯¹äºåŠ¨æ€åŸºæœ¬å…ƒç´ ï¼Œé‡‡ç”¨ç´§å‡‘çš„å¤šåˆ†è¾¨ç‡4Då“ˆå¸Œæ˜ å°„å™¨å°†å…¶ä»è§„èŒƒç©ºé—´è½¬æ¢åˆ°å˜å½¢ç©ºé—´ï¼Œç„¶åå°†é™æ€å’ŒåŠ¨æ€åŸºæœ¬å…ƒç´ æ··åˆä»¥äº§ç”Ÿæœ€ç»ˆè¾“å‡ºã€‚è¯¥æ–¹æ³•ä¸ä»…å®ç°äº†æœ€å…ˆè¿›çš„æ¸²æŸ“è´¨é‡ï¼Œè€Œä¸”åœ¨çœŸå®æ•°æ®é›†ä¸Šçš„è®­ç»ƒé€Ÿåº¦æ¯”å…ˆå‰çš„æ–¹æ³•å¿«20å€ï¼Œå­˜å‚¨éœ€æ±‚ä¹Ÿé™è‡³æœ€ä½ä»…éœ€30MBã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>Swift4Dæ˜¯ä¸€ç§åŸºäºåˆ†æ²»ç­–ç•¥çš„3Dé«˜æ–¯è´´ç‰‡æ–¹æ³•ï¼Œæ—¨åœ¨æé«˜è§†å›¾åˆæˆçš„è´¨é‡å’Œæ•ˆç‡ã€‚</li>
<li>è¯¥æ–¹æ³•é€šè¿‡ä»…å¯¹åŠ¨æ€åŸºæœ¬å…ƒç´ è¿›è¡ŒåŠ¨æ€è½¬æ¢å»ºæ¨¡æ¥æé«˜æ•ˆç‡å’Œæ¸²æŸ“è´¨é‡ã€‚</li>
<li>Swift4Dä½¿ç”¨å¯å­¦ä¹ çš„åˆ†è§£ç­–ç•¥æ¥åˆ†ç¦»åŸºæœ¬å…ƒç´ ï¼Œå¹¶å¼•å…¥é¢å¤–å‚æ•°æ¥åˆ†ç±»é™æ€å’ŒåŠ¨æ€åŸºæœ¬å…ƒç´ ã€‚</li>
<li>å¯¹äºåŠ¨æ€åŸºæœ¬å…ƒç´ ï¼Œé‡‡ç”¨å¤šåˆ†è¾¨ç‡4Då“ˆå¸Œæ˜ å°„å™¨è¿›è¡Œè½¬æ¢ï¼Œä»è§„èŒƒç©ºé—´åˆ°å˜å½¢ç©ºé—´ã€‚</li>
<li>é™æ€å’ŒåŠ¨æ€åŸºæœ¬å…ƒç´ æ··åˆåäº§ç”Ÿæœ€ç»ˆè¾“å‡ºã€‚</li>
<li>Swift4Dåœ¨çœŸå®æ•°æ®é›†ä¸Šçš„è®­ç»ƒé€Ÿåº¦æ¯”å…ˆå‰çš„æ–¹æ³•å¿«20å€ï¼Œå­˜å‚¨éœ€æ±‚ä¹Ÿå¤§å¹…é™ä½ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.12307">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-03-18\./crop_3DGS/2503.12307v1/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-03-18\./crop_3DGS/2503.12307v1/page_1_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-03-18\./crop_3DGS/2503.12307v1/page_3_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-03-18\./crop_3DGS/2503.12307v1/page_4_0.jpg" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="3D-Gaussian-Splatting-against-Moving-Objects-for-High-Fidelity-Street-Scene-Reconstruction"><a href="#3D-Gaussian-Splatting-against-Moving-Objects-for-High-Fidelity-Street-Scene-Reconstruction" class="headerlink" title="3D Gaussian Splatting against Moving Objects for High-Fidelity Street   Scene Reconstruction"></a>3D Gaussian Splatting against Moving Objects for High-Fidelity Street   Scene Reconstruction</h2><p><strong>Authors:Peizhen Zheng, Longfei Wei, Dongjing Jiang, Jianfei Zhang</strong></p>
<p>The accurate reconstruction of dynamic street scenes is critical for applications in autonomous driving, augmented reality, and virtual reality. Traditional methods relying on dense point clouds and triangular meshes struggle with moving objects, occlusions, and real-time processing constraints, limiting their effectiveness in complex urban environments. While multi-view stereo and neural radiance fields have advanced 3D reconstruction, they face challenges in computational efficiency and handling scene dynamics. This paper proposes a novel 3D Gaussian point distribution method for dynamic street scene reconstruction. Our approach introduces an adaptive transparency mechanism that eliminates moving objects while preserving high-fidelity static scene details. Additionally, iterative refinement of Gaussian point distribution enhances geometric accuracy and texture representation. We integrate directional encoding with spatial position optimization to optimize storage and rendering efficiency, reducing redundancy while maintaining scene integrity. Experimental results demonstrate that our method achieves high reconstruction quality, improved rendering performance, and adaptability in large-scale dynamic environments. These contributions establish a robust framework for real-time, high-precision 3D reconstruction, advancing the practicality of dynamic scene modeling across multiple applications. The source code for this work is available to the public at <a target="_blank" rel="noopener" href="https://github.com/deepcoxcom/3dgs">https://github.com/deepcoxcom/3dgs</a> </p>
<blockquote>
<p>åŠ¨æ€è¡—é“åœºæ™¯çš„å‡†ç¡®é‡å»ºå¯¹äºè‡ªåŠ¨é©¾é©¶ã€å¢å¼ºç°å®å’Œè™šæ‹Ÿç°å®åº”ç”¨è‡³å…³é‡è¦ã€‚ä¼ ç»Ÿæ–¹æ³•ä¾èµ–äºå¯†é›†çš„ç‚¹äº‘å’Œä¸‰è§’ç½‘æ ¼ï¼Œåœ¨ç§»åŠ¨ç‰©ä½“ã€é®æŒ¡å’Œå®æ—¶å¤„ç†çº¦æŸæ–¹é¢é‡åˆ°å›°éš¾ï¼Œåœ¨å¤æ‚çš„åŸå¸‚ç¯å¢ƒä¸­æ•ˆæœæœ‰é™ã€‚è™½ç„¶å¤šè§†å›¾ç«‹ä½“å’Œç¥ç»è¾å°„åœºå·²ç»æ¨åŠ¨äº†3Dé‡å»ºçš„å‘å±•ï¼Œä½†å®ƒä»¬é¢ä¸´ç€è®¡ç®—æ•ˆç‡ä½ä¸‹å’Œå¤„ç†åœºæ™¯åŠ¨æ€çš„æŒ‘æˆ˜ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§ç”¨äºåŠ¨æ€è¡—é“åœºæ™¯é‡å»ºçš„3Dé«˜æ–¯ç‚¹åˆ†å¸ƒæ–°æ–¹æ³•ã€‚æˆ‘ä»¬çš„æ–¹æ³•å¼•å…¥äº†ä¸€ç§è‡ªé€‚åº”é€æ˜æœºåˆ¶ï¼Œèƒ½å¤Ÿæ¶ˆé™¤ç§»åŠ¨ç‰©ä½“ï¼ŒåŒæ—¶ä¿ç•™é«˜ä¿çœŸé™æ€åœºæ™¯ç»†èŠ‚ã€‚æ­¤å¤–ï¼Œé«˜æ–¯ç‚¹åˆ†å¸ƒçš„è¿­ä»£ä¼˜åŒ–æé«˜äº†å‡ ä½•ç²¾åº¦å’Œçº¹ç†è¡¨ç¤ºã€‚æˆ‘ä»¬å°†æ–¹å‘ç¼–ç ä¸ç©ºé—´ä½ç½®ä¼˜åŒ–ç›¸ç»“åˆï¼Œä»¥ä¼˜åŒ–å­˜å‚¨å’Œæ¸²æŸ“æ•ˆç‡ï¼Œåœ¨ä¿æŒåœºæ™¯å®Œæ•´æ€§çš„åŒæ—¶å‡å°‘å†—ä½™ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•å®ç°äº†é«˜é‡å»ºè´¨é‡ã€æ”¹è¿›çš„æ¸²æŸ“æ€§èƒ½ä»¥åŠå¤§è§„æ¨¡åŠ¨æ€ç¯å¢ƒä¸­çš„é€‚åº”æ€§ã€‚è¿™äº›è´¡çŒ®å»ºç«‹äº†ä¸€ä¸ªç”¨äºå®æ—¶ã€é«˜ç²¾åº¦3Dé‡å»ºçš„ç¨³å¥æ¡†æ¶ï¼Œæ¨åŠ¨äº†åŠ¨æ€åœºæ™¯å»ºæ¨¡åœ¨å¤šä¸ªåº”ç”¨ä¸­çš„å®ç”¨æ€§ã€‚è¯¥å·¥ä½œçš„æºä»£ç å·²å…¬å¼€ï¼Œå¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/deepcoxcom/3dgs">https://github.com/deepcoxcom/3dgs</a>è®¿é—®ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.12001v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºä¸€ç§ç”¨äºåŠ¨æ€è¡—é“åœºæ™¯é‡å»ºçš„3Dé«˜æ–¯ç‚¹åˆ†å¸ƒæ–¹æ³•ï¼Œé€šè¿‡è‡ªé€‚åº”é€æ˜æœºåˆ¶æ¶ˆé™¤ç§»åŠ¨ç‰©ä½“ï¼ŒåŒæ—¶ä¿ç•™é«˜ä¿çœŸé™æ€åœºæ™¯ç»†èŠ‚ã€‚è¯¥æ–¹æ³•é€šè¿‡è¿­ä»£ä¼˜åŒ–é«˜æ–¯ç‚¹åˆ†å¸ƒæé«˜å‡ ä½•ç²¾åº¦å’Œçº¹ç†è¡¨ç¤ºï¼Œå¹¶ç»“åˆæ–¹å‘ç¼–ç ä¸ç©ºé—´ä½ç½®ä¼˜åŒ–ï¼Œä¼˜åŒ–å­˜å‚¨å’Œæ¸²æŸ“æ•ˆç‡ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•å®ç°é«˜è´¨é‡é‡å»ºã€æå‡æ¸²æŸ“æ€§èƒ½ï¼Œå¹¶åœ¨å¤§è§„æ¨¡åŠ¨æ€ç¯å¢ƒä¸­å…·æœ‰é€‚åº”æ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>åŠ¨æ€è¡—é“åœºæ™¯é‡å»ºåœ¨è‡ªåŠ¨é©¾é©¶ã€å¢å¼ºç°å®å’Œè™šæ‹Ÿç°å®åº”ç”¨ä¸­è‡³å…³é‡è¦ã€‚</li>
<li>ä¼ ç»Ÿæ–¹æ³•åœ¨å¤„ç†ç§»åŠ¨ç‰©ä½“ã€é®æŒ¡å’Œå®æ—¶å¤„ç†é™åˆ¶æ–¹é¢å­˜åœ¨æŒ‘æˆ˜ã€‚</li>
<li>å¤šè§†è§’ç«‹ä½“å’Œç¥ç»è¾å°„åœºè™½æ¨åŠ¨3Dé‡å»ºå‘å±•ï¼Œä½†è®¡ç®—æ•ˆç‡å’Œåœºæ™¯åŠ¨æ€å¤„ç†ä»é¢ä¸´æŒ‘æˆ˜ã€‚</li>
<li>æœ¬æ–‡æå‡ºä¸€ç§åŸºäº3Dé«˜æ–¯ç‚¹åˆ†å¸ƒçš„åŠ¨æ€è¡—é“åœºæ™¯é‡å»ºæ–¹æ³•ã€‚</li>
<li>è‡ªé€‚åº”é€æ˜æœºåˆ¶å¯æ¶ˆé™¤ç§»åŠ¨ç‰©ä½“ï¼ŒåŒæ—¶ä¿ç•™é™æ€åœºæ™¯çš„é«˜ä¿çœŸç»†èŠ‚ã€‚</li>
<li>é€šè¿‡è¿­ä»£ä¼˜åŒ–é«˜æ–¯ç‚¹åˆ†å¸ƒï¼Œæé«˜å‡ ä½•ç²¾åº¦å’Œçº¹ç†è¡¨ç¤ºã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.12001">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-03-18\./crop_3DGS/2503.12001v1/page_0_0.jpg" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1><h2 id="DecompDreamer-Advancing-Structured-3D-Asset-Generation-with-Multi-Object-Decomposition-and-Gaussian-Splatting"><a href="#DecompDreamer-Advancing-Structured-3D-Asset-Generation-with-Multi-Object-Decomposition-and-Gaussian-Splatting" class="headerlink" title="DecompDreamer: Advancing Structured 3D Asset Generation with   Multi-Object Decomposition and Gaussian Splatting"></a>DecompDreamer: Advancing Structured 3D Asset Generation with   Multi-Object Decomposition and Gaussian Splatting</h2><p><strong>Authors:Utkarsh Nath, Rajeev Goel, Rahul Khurana, Kyle Min, Mark Ollila, Pavan Turaga, Varun Jampani, Tejaswi Gowda</strong></p>
<p>Text-to-3D generation saw dramatic advances in recent years by leveraging Text-to-Image models. However, most existing techniques struggle with compositional prompts, which describe multiple objects and their spatial relationships. They often fail to capture fine-grained inter-object interactions. We introduce DecompDreamer, a Gaussian splatting-based training routine designed to generate high-quality 3D compositions from such complex prompts. DecompDreamer leverages Vision-Language Models (VLMs) to decompose scenes into structured components and their relationships. We propose a progressive optimization strategy that first prioritizes joint relationship modeling before gradually shifting toward targeted object refinement. Our qualitative and quantitative evaluations against state-of-the-art text-to-3D models demonstrate that DecompDreamer effectively generates intricate 3D compositions with superior object disentanglement, offering enhanced control and flexibility in 3D generation. Project page : <a target="_blank" rel="noopener" href="https://decompdreamer3d.github.io/">https://decompdreamer3d.github.io</a> </p>
<blockquote>
<p>è¿‘å¹´æ¥ï¼Œå€ŸåŠ©æ–‡æœ¬åˆ°å›¾åƒæ¨¡å‹ï¼Œæ–‡æœ¬åˆ°3Dç”ŸæˆæŠ€æœ¯å–å¾—äº†æ˜¾è‘—è¿›æ­¥ã€‚ç„¶è€Œï¼Œå¤§å¤šæ•°ç°æœ‰æŠ€æœ¯åœ¨å¤„ç†æè¿°å¤šä¸ªå¯¹è±¡åŠå…¶ç©ºé—´å…³ç³»çš„ç»„åˆæç¤ºæ—¶é‡åˆ°å›°éš¾ã€‚å®ƒä»¬å¾€å¾€æ— æ³•æ•æ‰å¯¹è±¡ä¹‹é—´çš„ç²¾ç»†äº¤äº’ã€‚æˆ‘ä»¬æ¨å‡ºäº†DecompDreamerï¼Œè¿™æ˜¯ä¸€ç§åŸºäºé«˜æ–¯å–·æ¶‚çš„è®­ç»ƒæµç¨‹ï¼Œæ—¨åœ¨ä»è¿™æ ·çš„å¤æ‚æç¤ºç”Ÿæˆé«˜è´¨é‡çš„ä¸‰ç»´ç»„åˆã€‚DecompDreameråˆ©ç”¨è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMï¼‰å°†åœºæ™¯åˆ†è§£ä¸ºç»“æ„åŒ–ç»„ä»¶åŠå…¶å…³ç³»ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§æ¸è¿›çš„ä¼˜åŒ–ç­–ç•¥ï¼Œé¦–å…ˆä¼˜å…ˆå¯¹è”åˆå…³ç³»è¿›è¡Œå»ºæ¨¡ï¼Œç„¶åé€æ¸è½¬å‘ç›®æ ‡å¯¹è±¡ç»†åŒ–ã€‚ä¸æœ€æ–°çš„æ–‡æœ¬åˆ°3Dæ¨¡å‹çš„å®šæ€§å’Œå®šé‡è¯„ä¼°è¡¨æ˜ï¼ŒDecompDreameræœ‰æ•ˆåœ°ç”Ÿæˆäº†å¤æ‚çš„ä¸‰ç»´ç»„åˆï¼Œå…·æœ‰å“è¶Šçš„å¯¹è±¡åˆ†ç¦»èƒ½åŠ›ï¼Œä¸ºä¸‰ç»´ç”Ÿæˆæä¾›äº†å¢å¼ºæ§åˆ¶å’Œçµæ´»æ€§ã€‚é¡¹ç›®é¡µé¢ï¼š<a target="_blank" rel="noopener" href="https://decompdreamer3d.github.io/">é“¾æ¥</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.11981v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æ–‡æœ¬è‡³3Dç”ŸæˆæŠ€æœ¯åœ¨è¿‘å¹´å› å€ŸåŠ©æ–‡æœ¬è‡³å›¾åƒæ¨¡å‹å–å¾—æ˜¾è‘—è¿›å±•ã€‚ç„¶è€Œï¼Œå¤šæ•°ç°æœ‰æŠ€æœ¯åœ¨å¤„ç†æè¿°å¤šä¸ªç‰©ä½“åŠå…¶ç©ºé—´å…³ç³»çš„ç»„åˆæç¤ºæ—¶é¢ä¸´å›°éš¾ï¼Œéš¾ä»¥æ•æ‰ç‰©ä½“é—´çš„ç²¾ç»†äº’åŠ¨ã€‚æˆ‘ä»¬æ¨å‡ºDecompDreamerï¼Œä¸€ç§åŸºäºé«˜æ–¯å–·ç»˜çš„è®­ç»ƒæµç¨‹ï¼Œæ—¨åœ¨ä»è¿™ç±»å¤æ‚æç¤ºç”Ÿæˆé«˜è´¨é‡3Dç»„åˆã€‚DecompDreameråˆ©ç”¨è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMsï¼‰å°†åœºæ™¯åˆ†è§£æˆç»“æ„åŒ–ç»„ä»¶åŠå…¶å…³ç³»ã€‚æˆ‘ä»¬æå‡ºä¸€ç§ä¼˜å…ˆå¯¹è”åˆå…³ç³»è¿›è¡Œå»ºæ¨¡ï¼Œç„¶åé€æ­¥è½¬å‘ç›®æ ‡å¯¹è±¡ä¼˜åŒ–çš„ç­–ç•¥ã€‚ä¸æœ€æ–°çš„æ–‡æœ¬è‡³3Dæ¨¡å‹ç›¸æ¯”ï¼Œæˆ‘ä»¬çš„å®šæ€§å’Œå®šé‡è¯„ä¼°è¡¨æ˜ï¼ŒDecompDreameræœ‰æ•ˆç”Ÿæˆå¤æ‚çš„3Dç»„åˆï¼Œå…·æœ‰å“è¶Šçš„å¯¹è±¡åˆ†ç¦»èƒ½åŠ›ï¼Œä¸º3Dç”Ÿæˆæä¾›äº†å¢å¼ºæ§åˆ¶å’Œçµæ´»æ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æ–‡æœ¬è‡³3Dç”ŸæˆæŠ€æœ¯è¿‘å¹´å–å¾—æ˜¾è‘—è¿›å±•ï¼Œå¾—ç›Šäºæ–‡æœ¬è‡³å›¾åƒæ¨¡å‹çš„åº”ç”¨ã€‚</li>
<li>ç°æœ‰æŠ€æœ¯åœ¨å¤„ç†æè¿°å¤šä¸ªç‰©ä½“åŠç©ºé—´å…³ç³»çš„ç»„åˆæç¤ºæ—¶å­˜åœ¨æŒ‘æˆ˜ï¼Œéš¾ä»¥æ•æ‰ç‰©ä½“é—´çš„ç²¾ç»†äº’åŠ¨ã€‚</li>
<li>DecompDreameræ˜¯ä¸€ä¸ªåŸºäºé«˜æ–¯å–·ç»˜çš„è®­ç»ƒæµç¨‹ï¼Œæ—¨åœ¨è§£å†³è¿™ä¸€é—®é¢˜ï¼Œç”Ÿæˆé«˜è´¨é‡3Dç»„åˆã€‚</li>
<li>DecompDreameråˆ©ç”¨è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMsï¼‰åˆ†è§£åœºæ™¯ï¼Œå¼ºè°ƒç»“æ„åŒ–ç»„ä»¶åŠå…¶å…³ç³»ã€‚</li>
<li>DecompDreameré‡‡ç”¨ä¼˜å…ˆå¯¹è”åˆå…³ç³»å»ºæ¨¡ï¼Œå†é€æ­¥è½¬å‘ç›®æ ‡å¯¹è±¡ä¼˜åŒ–çš„ç­–ç•¥ã€‚</li>
<li>ä¸å…¶ä»–æœ€æ–°æ–‡æœ¬è‡³3Dæ¨¡å‹ç›¸æ¯”ï¼ŒDecompDreamerç”Ÿæˆçš„3Dç»„åˆæ›´ä¸ºå¤æ‚ä¸”å¯¹è±¡åˆ†ç¦»èƒ½åŠ›æ›´å¼ºã€‚</li>
<li>DecompDreamerä¸º3Dç”Ÿæˆæä¾›äº†å¢å¼ºæ§åˆ¶å’Œçµæ´»æ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.11981">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-03-18\./crop_3DGS/2503.11981v1/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-03-18\./crop_3DGS/2503.11981v1/page_1_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-03-18\./crop_3DGS/2503.11981v1/page_4_0.jpg" align="middle">
</details>


<h1 id="-9"><a href="#-9" class="headerlink" title=""></a></h1><h2 id="3D-Student-Splatting-and-Scooping"><a href="#3D-Student-Splatting-and-Scooping" class="headerlink" title="3D Student Splatting and Scooping"></a>3D Student Splatting and Scooping</h2><p><strong>Authors:Jialin Zhu, Jiangbei Yue, Feixiang He, He Wang</strong></p>
<p>Recently, 3D Gaussian Splatting (3DGS) provides a new framework for novel view synthesis, and has spiked a new wave of research in neural rendering and related applications. As 3DGS is becoming a foundational component of many models, any improvement on 3DGS itself can bring huge benefits. To this end, we aim to improve the fundamental paradigm and formulation of 3DGS. We argue that as an unnormalized mixture model, it needs to be neither Gaussians nor splatting. We subsequently propose a new mixture model consisting of flexible Studentâ€™s t distributions, with both positive (splatting) and negative (scooping) densities. We name our model Student Splatting and Scooping, or SSS. When providing better expressivity, SSS also poses new challenges in learning. Therefore, we also propose a new principled sampling approach for optimization. Through exhaustive evaluation and comparison, across multiple datasets, settings, and metrics, we demonstrate that SSS outperforms existing methods in terms of quality and parameter efficiency, e.g. achieving matching or better quality with similar numbers of components, and obtaining comparable results while reducing the component number by as much as 82%. </p>
<blockquote>
<p>æœ€è¿‘ï¼Œ3Dé«˜æ–¯æ‰©å±•ï¼ˆ3DGSï¼‰ä¸ºæ–°å‹è§†è§’åˆæˆæä¾›äº†æ–°çš„æ¡†æ¶ï¼Œå¹¶æ€èµ·äº†ç¥ç»ç½‘ç»œæ¸²æŸ“å’Œç›¸å…³åº”ç”¨ç ”ç©¶é¢†åŸŸçš„æ–°æµªæ½®ã€‚éšç€3DGSæˆä¸ºè®¸å¤šæ¨¡å‹çš„åŸºç¡€ç»„ä»¶ï¼Œå¯¹3DGSæœ¬èº«çš„ä»»ä½•æ”¹è¿›éƒ½èƒ½å¸¦æ¥å·¨å¤§çš„å¥½å¤„ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬æ—¨åœ¨æ”¹è¿›3DGSçš„åŸºæœ¬èŒƒå¼å’Œå…¬å¼ã€‚æˆ‘ä»¬è®¤ä¸ºï¼Œä½œä¸ºä¸€ç§æœªå½’ä¸€åŒ–çš„æ··åˆæ¨¡å‹ï¼Œå®ƒæ—¢ä¸éœ€è¦æ˜¯é«˜æ–¯åˆ†å¸ƒä¹Ÿä¸éœ€è¦æ˜¯æ‰©å±•ã€‚éšåï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°çš„æ··åˆæ¨¡å‹ï¼Œç”±çµæ´»çš„Studentâ€™s tåˆ†å¸ƒç»„æˆï¼ŒåŒ…æ‹¬æ­£å‘ï¼ˆæ‰©å±•ï¼‰å’Œè´Ÿå‘ï¼ˆæŒ–æ˜ï¼‰å¯†åº¦ã€‚æˆ‘ä»¬å°†æˆ‘ä»¬çš„æ¨¡å‹å‘½åä¸ºStudent Splatting and Scoopingï¼Œæˆ–SSSã€‚åœ¨æé«˜è¡¨è¾¾æ€§çš„åŒæ—¶ï¼ŒSSSä¹Ÿç»™å­¦ä¹ å¸¦æ¥äº†æ–°çš„æŒ‘æˆ˜ã€‚å› æ­¤ï¼Œæˆ‘ä»¬è¿˜æå‡ºäº†ä¸€ç§æ–°çš„åŸåˆ™é‡‡æ ·æ–¹æ³•è¿›è¡Œä¼˜åŒ–ã€‚é€šè¿‡å¤šä¸ªæ•°æ®é›†ã€è®¾ç½®å’ŒæŒ‡æ ‡çš„å…¨é¢è¯„ä¼°ä¸æ¯”è¾ƒï¼Œæˆ‘ä»¬è¯æ˜SSSåœ¨è´¨é‡å’Œå‚æ•°æ•ˆç‡æ–¹é¢ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œä¾‹å¦‚ï¼Œåœ¨ç±»ä¼¼æ•°é‡çš„ç»„ä»¶ä¸‹å®ç°ç›¸åŒ¹é…æˆ–æ›´å¥½çš„è´¨é‡ï¼Œå¹¶åœ¨å‡å°‘ç»„ä»¶æ•°é‡é«˜è¾¾82%çš„æƒ…å†µä¸‹è·å¾—å¯æ¯”çš„ç»“æœã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.10148v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†ä¸‰ç»´é«˜æ–¯å±•å¸ƒæŠ€æœ¯ï¼ˆ3DGSï¼‰çš„æœ€æ–°ç ”ç©¶ã€‚ä¸ºäº†æé«˜è¯¥æŠ€æœ¯çš„æ€§èƒ½å’Œæ•ˆç‡ï¼Œç ”ç©¶è€…æå‡ºäº†åŸºäºå­¦ç”Ÿtåˆ†å¸ƒçš„æ··åˆæ¨¡å‹ï¼ŒåŒ…å«æ­£å‘å±•å¸ƒå’Œåå‘æŠ å–ä¸¤ç§å¯†åº¦ï¼Œå‘½åä¸ºSSSæ¨¡å‹ã€‚ç›¸è¾ƒäºç°æœ‰æ–¹æ³•ï¼ŒSSSæ¨¡å‹åœ¨æé«˜è¡¨ç°åŠ›çš„åŒæ—¶ï¼Œä¹Ÿå¸¦æ¥äº†å­¦ä¹ ä¸Šçš„æ–°æŒ‘æˆ˜ã€‚ç»è¿‡å¤§é‡æ•°æ®é›†ã€è®¾ç½®å’ŒæŒ‡æ ‡çš„è¯„ä¼°æ¯”è¾ƒï¼Œç»“æœæ˜¾ç¤ºSSSæ¨¡å‹åœ¨è´¨é‡å’Œå‚æ•°æ•ˆç‡æ–¹é¢è¡¨ç°æ›´ä¼˜ç§€ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>3DGSæˆä¸ºå¤šä¸ªæ¨¡å‹çš„åŸºç¡€ç»„ä»¶ï¼Œå¯¹å…¶æœ¬èº«çš„æ”¹è¿›å¯å¸¦æ¥å·¨å¤§åˆ©ç›Šã€‚</li>
<li>ç ”ç©¶è€…æå‡ºåä¸ºSSSçš„æ–°æ··åˆæ¨¡å‹ï¼ŒåŸºäºçµæ´»çš„å­¦ç”Ÿtåˆ†å¸ƒï¼ŒåŒ…å«æ­£å‘å±•å¸ƒå’Œåå‘æŠ å–ä¸¤ç§å¯†åº¦ã€‚</li>
<li>SSSæ¨¡å‹æé«˜äº†è¡¨ç°åŠ›ï¼Œä½†åŒæ—¶ä¹Ÿå¸¦æ¥äº†æ–°çš„å­¦ä¹ æŒ‘æˆ˜ã€‚</li>
<li>ç›¸è¾ƒäºç°æœ‰æ–¹æ³•ï¼ŒSSSæ¨¡å‹åœ¨è´¨é‡å’Œå‚æ•°æ•ˆç‡æ–¹é¢è¡¨ç°æ›´ä¼˜ç§€ã€‚</li>
<li>SSSæ¨¡å‹å®ç°äº†æ›´å¥½çš„åŒ¹é…è´¨é‡ï¼Œä½¿ç”¨ç›¸ä¼¼æ•°é‡çš„ç»„ä»¶ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.10148">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-03-18\./crop_3DGS/2503.10148v2/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-03-18\./crop_3DGS/2503.10148v2/page_2_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-03-18\./crop_3DGS/2503.10148v2/page_3_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-03-18\./crop_3DGS/2503.10148v2/page_5_0.jpg" align="middle">
</details>


<h1 id="-10"><a href="#-10" class="headerlink" title=""></a></h1><h2 id="Uni-Gaussians-Unifying-Camera-and-Lidar-Simulation-with-Gaussians-for-Dynamic-Driving-Scenarios"><a href="#Uni-Gaussians-Unifying-Camera-and-Lidar-Simulation-with-Gaussians-for-Dynamic-Driving-Scenarios" class="headerlink" title="Uni-Gaussians: Unifying Camera and Lidar Simulation with Gaussians for   Dynamic Driving Scenarios"></a>Uni-Gaussians: Unifying Camera and Lidar Simulation with Gaussians for   Dynamic Driving Scenarios</h2><p><strong>Authors:Zikang Yuan, Yuechuan Pu, Hongcheng Luo, Fengtian Lang, Cheng Chi, Teng Li, Yingying Shen, Haiyang Sun, Bing Wang, Xin Yang</strong></p>
<p>Ensuring the safety of autonomous vehicles necessitates comprehensive simulation of multi-sensor data, encompassing inputs from both cameras and LiDAR sensors, across various dynamic driving scenarios. Neural rendering techniques, which utilize collected raw sensor data to simulate these dynamic environments, have emerged as a leading methodology. While NeRF-based approaches can uniformly represent scenes for rendering data from both camera and LiDAR, they are hindered by slow rendering speeds due to dense sampling. Conversely, Gaussian Splatting-based methods employ Gaussian primitives for scene representation and achieve rapid rendering through rasterization. However, these rasterization-based techniques struggle to accurately model non-linear optical sensors. This limitation restricts their applicability to sensors beyond pinhole cameras. To address these challenges and enable unified representation of dynamic driving scenarios using Gaussian primitives, this study proposes a novel hybrid approach. Our method utilizes rasterization for rendering image data while employing Gaussian ray-tracing for LiDAR data rendering. Experimental results on public datasets demonstrate that our approach outperforms current state-of-the-art methods. This work presents a unified and efficient solution for realistic simulation of camera and LiDAR data in autonomous driving scenarios using Gaussian primitives, offering significant advancements in both rendering quality and computational efficiency. </p>
<blockquote>
<p>ç¡®ä¿è‡ªåŠ¨é©¾é©¶è½¦è¾†çš„å®‰å…¨éœ€è¦å¯¹å¤šä¼ æ„Ÿå™¨æ•°æ®è¿›è¡Œå…¨é¢çš„æ¨¡æ‹Ÿï¼Œè¿™åŒ…æ‹¬æ¥è‡ªç›¸æœºå’Œæ¿€å…‰é›·è¾¾ä¼ æ„Ÿå™¨çš„è¾“å…¥ï¼Œå¹¶åœ¨å„ç§åŠ¨æ€é©¾é©¶åœºæ™¯ä¸­å‘æŒ¥ä½œç”¨ã€‚åˆ©ç”¨æ”¶é›†çš„åŸå§‹ä¼ æ„Ÿå™¨æ•°æ®æ¨¡æ‹Ÿè¿™äº›åŠ¨æ€ç¯å¢ƒçš„ç¥ç»æ¸²æŸ“æŠ€æœ¯å·²ç»æˆä¸ºä¸€ç§ä¸»æµæ–¹æ³•ã€‚è™½ç„¶åŸºäºNeRFçš„æ–¹æ³•å¯ä»¥ç»Ÿä¸€å‘ˆç°åœºæ™¯ï¼Œä»ç›¸æœºå’Œæ¿€å…‰é›·è¾¾æ¸²æŸ“æ•°æ®ï¼Œä½†ç”±äºå¯†é›†é‡‡æ ·å¯¼è‡´æ¸²æŸ“é€Ÿåº¦è¾ƒæ…¢ã€‚ç›¸åï¼ŒåŸºäºé«˜æ–¯æ¶‚æ•·çš„æ–¹æ³•ä½¿ç”¨é«˜æ–¯åŸºæœ¬å…ƒç´ è¿›è¡Œåœºæ™¯è¡¨ç¤ºï¼Œå¹¶é€šè¿‡å…‰æ …åŒ–å®ç°å¿«é€Ÿæ¸²æŸ“ã€‚ç„¶è€Œï¼Œè¿™äº›åŸºäºå…‰æ …åŒ–çš„æŠ€æœ¯å¾ˆéš¾å‡†ç¡®æ¨¡æ‹Ÿéçº¿æ€§å…‰å­¦ä¼ æ„Ÿå™¨ã€‚è¿™ä¸€å±€é™æ€§é™åˆ¶äº†å®ƒä»¬å¯¹é’ˆå­”ç›¸æœºä»¥å¤–ä¼ æ„Ÿå™¨çš„åº”ç”¨ã€‚ä¸ºäº†è§£å†³è¿™äº›æŒ‘æˆ˜ï¼Œå®ç°å¯¹åŠ¨æ€é©¾é©¶åœºæ™¯ä½¿ç”¨é«˜æ–¯åŸºæœ¬å…ƒç´ çš„ç»Ÿä¸€è¡¨ç¤ºï¼Œæœ¬ç ”ç©¶æå‡ºäº†ä¸€ç§æ–°å‹æ··åˆæ–¹æ³•ã€‚æˆ‘ä»¬çš„æ–¹æ³•ä½¿ç”¨å…‰æ …åŒ–è¿›è¡Œå›¾åƒæ•°æ®æ¸²æŸ“ï¼ŒåŒæ—¶ä½¿ç”¨é«˜æ–¯å…‰çº¿è¿½è¸ªè¿›è¡Œæ¿€å…‰é›·è¾¾æ•°æ®æ¸²æŸ“ã€‚åœ¨å…¬å…±æ•°æ®é›†ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•ä¼˜äºå½“å‰æœ€å…ˆè¿›çš„æ–¹æ³•ã€‚æœ¬ç ”ç©¶æå‡ºäº†ä¸€ç§ç»Ÿä¸€ä¸”é«˜æ•ˆçš„æ–¹æ³•ï¼Œä½¿ç”¨é«˜æ–¯åŸºæœ¬å…ƒç´ æ¨¡æ‹Ÿè‡ªåŠ¨é©¾é©¶åœºæ™¯ä¸­çš„ç›¸æœºå’Œæ¿€å…‰é›·è¾¾æ•°æ®çœŸå®æ¨¡æ‹Ÿï¼Œåœ¨æ¸²æŸ“è´¨é‡å’Œè®¡ç®—æ•ˆç‡æ–¹é¢éƒ½å–å¾—äº†é‡å¤§è¿›å±•ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.08317v2">PDF</a> 10 pages</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºä¸€ç§åˆ©ç”¨é«˜æ–¯åŸå§‹æ–¹æ³•è¿›è¡ŒåŠ¨æ€é©¾é©¶åœºæ™¯ç»Ÿä¸€è¡¨ç¤ºçš„æ–°æ–¹æ³•ã€‚è¯¥æ–¹æ³•ç»“åˆäº†å›¾åƒæ¸²æŸ“ä¸­çš„æ …æ ¼åŒ–å’Œæ¿€å…‰é›·è¾¾æ•°æ®æ¸²æŸ“ä¸­çš„é«˜æ–¯å°„çº¿è¿½è¸ªæŠ€æœ¯ï¼Œè§£å†³äº†ç°æœ‰æ–¹æ³•åœ¨å¤„ç†éçº¿æ€§å…‰å­¦ä¼ æ„Ÿå™¨æ–¹é¢çš„å±€é™æ€§ï¼Œæé«˜äº†æ¸²æŸ“è´¨é‡å’Œè®¡ç®—æ•ˆç‡ã€‚æ­¤æ–¹æ³•èƒ½å¤ŸçœŸå®æ¨¡æ‹Ÿè‡ªä¸»é©¾é©¶åœºæ™¯ä¸­çš„ç›¸æœºå’Œæ¿€å…‰é›·è¾¾æ•°æ®ï¼Œä¸ºè‡ªåŠ¨é©¾é©¶çš„å®‰å…¨æ¨¡æ‹Ÿæä¾›äº†æœ‰æ•ˆè§£å†³æ–¹æ¡ˆã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>è‡ªä¸»è½¦è¾†çš„å®‰å…¨ä¿éšœéœ€è¦å…¨é¢æ¨¡æ‹Ÿå¤šä¼ æ„Ÿå™¨æ•°æ®ï¼ŒåŒ…æ‹¬ç›¸æœºå’Œæ¿€å…‰é›·è¾¾ä¼ æ„Ÿå™¨åœ¨å„ç§åŠ¨æ€é©¾é©¶åœºæ™¯ä¸‹çš„è¾“å…¥ã€‚</li>
<li>ç¥ç»æ¸²æŸ“æŠ€æœ¯å·²æˆä¸ºæ¨¡æ‹Ÿè¿™äº›åŠ¨æ€ç¯å¢ƒçš„ä¸»è¦æ–¹æ³•ï¼Œå…¶ä¸­åŸºäºNeRFçš„æ–¹æ³•å¯ä»¥ç»Ÿä¸€è¡¨ç¤ºåœºæ™¯å¹¶æ¸²æŸ“æ¥è‡ªç›¸æœºå’Œæ¿€å…‰é›·è¾¾çš„æ•°æ®ï¼Œä½†æ¸²æŸ“é€Ÿåº¦è¾ƒæ…¢ã€‚</li>
<li>é«˜æ–¯Splattingæ–¹æ³•ä½¿ç”¨é«˜æ–¯åŸå§‹è¿›è¡Œåœºæ™¯è¡¨ç¤ºï¼Œå¹¶é€šè¿‡å…‰çº¿è¿½è¸ªå®ç°å¿«é€Ÿæ¸²æŸ“ã€‚</li>
<li>ç„¶è€Œï¼Œå…‰çº¿è¿½è¸ªæŠ€æœ¯éš¾ä»¥å‡†ç¡®æ¨¡æ‹Ÿéçº¿æ€§å…‰å­¦ä¼ æ„Ÿå™¨ï¼Œé™åˆ¶äº†å…¶åœ¨ä¼ æ„Ÿå™¨å¤–çš„åº”ç”¨ã€‚</li>
<li>æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„æ··åˆæ–¹æ³•ï¼Œç»“åˆæ …æ ¼åŒ–å’Œé«˜æ–¯å°„çº¿è¿½è¸ªæŠ€æœ¯ï¼Œä»¥ç»Ÿä¸€è¡¨ç¤ºåŠ¨æ€é©¾é©¶åœºæ™¯å¹¶é«˜æ•ˆæ¸²æŸ“ç›¸æœºå’Œæ¿€å…‰é›·è¾¾æ•°æ®ã€‚</li>
<li>åœ¨å…¬å…±æ•°æ®é›†ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•ä¼˜äºç°æœ‰æŠ€æœ¯ï¼Œä¸ºè‡ªä¸»é©¾é©¶åœºæ™¯çš„ç›¸æœºå’Œæ¿€å…‰é›·è¾¾æ•°æ®æ¨¡æ‹Ÿæä¾›äº†ç»Ÿä¸€ã€é«˜æ•ˆçš„è§£å†³æ–¹æ¡ˆã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.08317">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-03-18\./crop_3DGS/2503.08317v2/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-03-18\./crop_3DGS/2503.08317v2/page_1_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-03-18\./crop_3DGS/2503.08317v2/page_3_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-03-18\./crop_3DGS/2503.08317v2/page_5_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-03-18\./crop_3DGS/2503.08317v2/page_5_1.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-03-18\./crop_3DGS/2503.08317v2/page_5_2.jpg" align="middle">
</details>


<h1 id="-11"><a href="#-11" class="headerlink" title=""></a></h1><h2 id="Instrument-Splatting-Controllable-Photorealistic-Reconstruction-of-Surgical-Instruments-Using-Gaussian-Splatting"><a href="#Instrument-Splatting-Controllable-Photorealistic-Reconstruction-of-Surgical-Instruments-Using-Gaussian-Splatting" class="headerlink" title="Instrument-Splatting: Controllable Photorealistic Reconstruction of   Surgical Instruments Using Gaussian Splatting"></a>Instrument-Splatting: Controllable Photorealistic Reconstruction of   Surgical Instruments Using Gaussian Splatting</h2><p><strong>Authors:Shuojue Yang, Zijian Wu, Mingxuan Hong, Qian Li, Daiyun Shen, Septimiu E. Salcudean, Yueming Jin</strong></p>
<p>Real2Sim is becoming increasingly important with the rapid development of surgical artificial intelligence (AI) and autonomy. In this work, we propose a novel Real2Sim methodology, Instrument-Splatting, that leverages 3D Gaussian Splatting to provide fully controllable 3D reconstruction of surgical instruments from monocular surgical videos. To maintain both high visual fidelity and manipulability, we introduce a geometry pre-training to bind Gaussian point clouds on part mesh with accurate geometric priors and define a forward kinematics to control the Gaussians as flexible as real instruments. Afterward, to handle unposed videos, we design a novel instrument pose tracking method leveraging semantics-embedded Gaussians to robustly refine per-frame instrument poses and joint states in a render-and-compare manner, which allows our instrument Gaussian to accurately learn textures and reach photorealistic rendering. We validated our method on 2 publicly released surgical videos and 4 videos collected on ex vivo tissues and green screens. Quantitative and qualitative evaluations demonstrate the effectiveness and superiority of the proposed method. </p>
<blockquote>
<p>éšç€æ‰‹æœ¯äººå·¥æ™ºèƒ½å’Œè‡ªä¸»æŠ€æœ¯çš„å¿«é€Ÿå‘å±•ï¼ŒReal2Simå˜å¾—è¶Šæ¥è¶Šé‡è¦ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°å‹çš„Real2Simæ–¹æ³•â€”â€”ä»ªå™¨å»¶å±•æŠ€æœ¯ï¼Œå®ƒåˆ©ç”¨3Dé«˜æ–¯å»¶å±•æŠ€æœ¯ï¼Œä»å•ç›®æ‰‹æœ¯è§†é¢‘ä¸­æä¾›å¯æ§çš„æ‰‹æœ¯ä»ªå™¨3Dé‡å»ºã€‚ä¸ºäº†ä¿æŒé«˜è§†è§‰ä¿çœŸåº¦å’Œå¯æ“ä½œæ€§ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§å‡ ä½•é¢„è®­ç»ƒæ–¹æ³•ï¼Œå°†é«˜æ–¯ç‚¹äº‘ä¸éƒ¨åˆ†ç½‘æ ¼ç»‘å®šï¼Œå¹¶å®šä¹‰å‰å‘è¿åŠ¨å­¦æ¥æ§åˆ¶é«˜æ–¯ç‚¹äº‘çš„çµæ´»æ€§ï¼Œä½¿å…¶ä¸çœŸå®ä»ªå™¨ä¸€æ ·ã€‚ä¹‹åï¼Œä¸ºäº†å¤„ç†æœªæ‘†æ”¾çš„è§†é¢‘ï¼Œæˆ‘ä»¬è®¾è®¡äº†ä¸€ç§æ–°çš„ä»ªå™¨å§¿æ€è·Ÿè¸ªæ–¹æ³•ï¼Œåˆ©ç”¨è¯­ä¹‰åµŒå…¥çš„é«˜æ–¯ç‚¹äº‘ï¼Œä»¥ç¨³å¥çš„æ–¹å¼å¯¹æ¯å¸§ä»ªå™¨å§¿æ€å’Œå…³èŠ‚çŠ¶æ€è¿›è¡Œç»†åŒ–ï¼Œé‡‡ç”¨æ¸²æŸ“å’Œæ¯”è¾ƒçš„æ–¹å¼ï¼Œè¿™ä½¿å¾—æˆ‘ä»¬çš„ä»ªå™¨é«˜æ–¯ç‚¹äº‘èƒ½å¤Ÿå‡†ç¡®å­¦ä¹ çº¹ç†ï¼Œè¾¾åˆ°é€¼çœŸçš„æ¸²æŸ“æ•ˆæœã€‚æˆ‘ä»¬åœ¨2ä¸ªå…¬å¼€å‘å¸ƒçš„æ‰‹æœ¯è§†é¢‘å’Œ4ä¸ªåœ¨ç¦»ä½“ç»„ç»‡å’Œç»¿å¹•ä¸Šæ”¶é›†çš„è§†é¢‘ä¸ŠéªŒè¯äº†æˆ‘ä»¬çš„æ–¹æ³•ã€‚å®šé‡å’Œå®šæ€§è¯„ä¼°è¡¨æ˜ï¼Œè¯¥æ–¹æ³•æœ‰æ•ˆä¸”ä¼˜è¶Šã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.04082v2">PDF</a> 11 pages, 5 figures</p>
<p><strong>æ‘˜è¦</strong><br>éšç€æ‰‹æœ¯äººå·¥æ™ºèƒ½å’Œè‡ªä¸»æŠ€æœ¯çš„å¿«é€Ÿå‘å±•ï¼ŒReal2Simå˜å¾—è¶Šæ¥è¶Šé‡è¦ã€‚æœ¬ç ”ç©¶æå‡ºäº†ä¸€ç§æ–°å‹çš„Real2Simæ–¹æ³•â€”â€”ä»ªå™¨åˆ†è£‚æ³•ï¼Œå®ƒåˆ©ç”¨3Dé«˜æ–¯åˆ†è£‚æŠ€æœ¯ï¼Œä»å•è§†è§’æ‰‹æœ¯è§†é¢‘ä¸­å®ç°æ‰‹æœ¯ä»ªå™¨çš„å…¨å¯æ§3Dé‡å»ºã€‚ä¸ºäº†ä¿æŒé«˜è§†è§‰ä¿çœŸåº¦å’Œå¯æ“ä½œæ€§ï¼Œæˆ‘ä»¬å¼•å…¥äº†å‡ ä½•é¢„è®­ç»ƒï¼Œå°†é«˜æ–¯ç‚¹äº‘ç»‘å®šåˆ°å…·æœ‰ç²¾ç¡®å‡ ä½•å…ˆéªŒçš„éƒ¨åˆ†ç½‘æ ¼ä¸Šï¼Œå¹¶å®šä¹‰æ­£å‘åŠ¨åŠ›å­¦æ¥æ§åˆ¶ä¸çœŸå®ä»ªå™¨ä¸€æ ·çµæ´»çš„é«˜æ–¯ã€‚æ¥ç€ï¼Œä¸ºäº†å¤„ç†æœªæ‘†æ”¾çš„è§†é¢‘ï¼Œæˆ‘ä»¬è®¾è®¡äº†ä¸€ç§æ–°çš„ä»ªå™¨å§¿æ€è·Ÿè¸ªæ–¹æ³•ï¼Œåˆ©ç”¨è¯­ä¹‰åµŒå…¥çš„é«˜æ–¯æ¥ç¨³å¥åœ°ä¼˜åŒ–æ¯å¸§çš„ä»ªå™¨å§¿æ€å’Œå…³èŠ‚çŠ¶æ€ï¼Œé‡‡ç”¨æ¸²æŸ“å’Œæ¯”è¾ƒçš„æ–¹å¼ï¼Œä½¿ä»ªå™¨çš„é«˜æ–¯èƒ½å¤Ÿå‡†ç¡®å­¦ä¹ çº¹ç†ï¼Œè¾¾åˆ°é€¼çœŸçš„æ¸²æŸ“æ•ˆæœã€‚æˆ‘ä»¬åœ¨2ä¸ªå…¬å¼€å‘å¸ƒçš„æ‰‹æœ¯è§†é¢‘ä»¥åŠ4ä¸ªåœ¨ç¦»ä½“ç»„ç»‡å’Œç»¿å¹•ä¸Šæ”¶é›†çš„è§†é¢‘ä¸ŠéªŒè¯äº†æˆ‘ä»¬çš„æ–¹æ³•ã€‚å®šé‡å’Œå®šæ€§è¯„ä¼°è¯æ˜äº†æ‰€ææ–¹æ³•çš„æœ‰æ•ˆæ€§å’Œä¼˜è¶Šæ€§ã€‚</p>
<p><strong>è¦ç‚¹</strong></p>
<ol>
<li>æå‡ºäº†æ–°å‹çš„Real2Simæ–¹æ³•â€”â€”ä»ªå™¨åˆ†è£‚æ³•ï¼Œåˆ©ç”¨3Dé«˜æ–¯åˆ†è£‚æŠ€æœ¯å®ç°æ‰‹æœ¯ä»ªå™¨çš„å…¨å¯æ§3Dé‡å»ºã€‚</li>
<li>é€šè¿‡å‡ ä½•é¢„è®­ç»ƒå’Œé«˜æ–¯ç‚¹äº‘ç»‘å®šï¼Œä¿æŒé«˜è§†è§‰ä¿çœŸåº¦å’Œå¯æ“ä½œæ€§ã€‚</li>
<li>å¼•å…¥æ­£å‘åŠ¨åŠ›å­¦æ§åˆ¶ï¼Œä½¿é«˜æ–¯æ¨¡æ‹Ÿçš„ä»ªå™¨çµæ´»æ€§æ¥è¿‘çœŸå®ä»ªå™¨ã€‚</li>
<li>è®¾è®¡äº†æ–°çš„ä»ªå™¨å§¿æ€è·Ÿè¸ªæ–¹æ³•ï¼Œåˆ©ç”¨è¯­ä¹‰åµŒå…¥çš„é«˜æ–¯è¿›è¡Œç¨³å¥çš„å§¿æ€ä¼˜åŒ–ã€‚</li>
<li>æ–¹æ³•èƒ½å¤Ÿåœ¨æœªæ‘†æ”¾çš„è§†é¢‘ä¸­å‡†ç¡®å­¦ä¹ ä»ªå™¨çº¹ç†ï¼Œå®ç°é€¼çœŸçš„æ¸²æŸ“æ•ˆæœã€‚</li>
<li>åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šè¿›è¡Œäº†å®šé‡å’Œå®šæ€§è¯„ä¼°ï¼Œè¯æ˜äº†æ–¹æ³•çš„æœ‰æ•ˆæ€§å’Œä¼˜è¶Šæ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.04082">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-03-18\./crop_3DGS/2503.04082v2/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-03-18\./crop_3DGS/2503.04082v2/page_2_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-03-18\./crop_3DGS/2503.04082v2/page_3_0.jpg" align="middle">
</details>


<h1 id="-12"><a href="#-12" class="headerlink" title=""></a></h1><h2 id="Seeing-World-Dynamics-in-a-Nutshell"><a href="#Seeing-World-Dynamics-in-a-Nutshell" class="headerlink" title="Seeing World Dynamics in a Nutshell"></a>Seeing World Dynamics in a Nutshell</h2><p><strong>Authors:Qiuhong Shen, Xuanyu Yi, Mingbao Lin, Hanwang Zhang, Shuicheng Yan, Xinchao Wang</strong></p>
<p>We consider the problem of efficiently representing casually captured monocular videos in a spatially- and temporally-coherent manner. While existing approaches predominantly rely on 2D&#x2F;2.5D techniques treating videos as collections of spatiotemporal pixels, they struggle with complex motions, occlusions, and geometric consistency due to absence of temporal coherence and explicit 3D structure. Drawing inspiration from monocular video as a projection of the dynamic 3D world, we explore representing videos in their intrinsic 3D form through continuous flows of Gaussian primitives in space-time. In this paper, we propose NutWorld, a novel framework that efficiently transforms monocular videos into dynamic 3D Gaussian representations in a single forward pass. At its core, NutWorld introduces a structured spatial-temporal aligned Gaussian (STAG) representation, enabling optimization-free scene modeling with effective depth and flow regularization. Through comprehensive experiments, we demonstrate that NutWorld achieves high-fidelity video reconstruction quality while enabling various downstream applications in real-time. Demos and code will be available at <a target="_blank" rel="noopener" href="https://github.com/Nut-World/NutWorld">https://github.com/Nut-World/NutWorld</a>. </p>
<blockquote>
<p>æˆ‘ä»¬è€ƒè™‘å¦‚ä½•ä»¥ç©ºé—´å’Œæ—¶é—´ä¸Šè¿è´¯çš„æ–¹å¼æœ‰æ•ˆè¡¨ç¤ºéšæ„æ•è·çš„å•ç›®è§†é¢‘ã€‚è™½ç„¶ç°æœ‰æ–¹æ³•ä¸»è¦ä¾èµ–2D&#x2F;2.5DæŠ€æœ¯å°†è§†é¢‘è§†ä¸ºæ—¶ç©ºåƒç´ çš„é›†åˆï¼Œä½†ç”±äºç¼ºä¹æ—¶é—´è¿è´¯æ€§å’Œæ˜ç¡®çš„3Dç»“æ„ï¼Œå®ƒä»¬åœ¨å¤„ç†å¤æ‚è¿åŠ¨ã€é®æŒ¡å’Œå‡ ä½•ä¸€è‡´æ€§æ–¹é¢é‡åˆ°äº†å›°éš¾ã€‚æˆ‘ä»¬ä»å•ç›®è§†é¢‘ä½œä¸ºåŠ¨æ€3Dä¸–ç•Œçš„æŠ•å½±ä¸­æ±²å–çµæ„Ÿï¼Œæ¢ç´¢é€šè¿‡æ—¶ç©ºä¸­çš„é«˜æ–¯åŸå§‹è¿ç»­æµæ¥è¡¨ç¤ºè§†é¢‘çš„å†…åœ¨3Då½¢å¼ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†NutWorldè¿™ä¸€æ–°å‹æ¡†æ¶ï¼Œå®ƒå¯ä»¥åœ¨ä¸€æ¬¡å‰å‘ä¼ é€’ä¸­å°†å•ç›®è§†é¢‘é«˜æ•ˆè½¬æ¢ä¸ºåŠ¨æ€3Dé«˜æ–¯è¡¨ç¤ºã€‚NutWorldçš„æ ¸å¿ƒæ˜¯å¼•å…¥ç»“æ„åŒ–æ—¶ç©ºå¯¹é½é«˜æ–¯ï¼ˆSTAGï¼‰è¡¨ç¤ºï¼Œå®ç°æ— éœ€ä¼˜åŒ–çš„åœºæ™¯å»ºæ¨¡ï¼Œå¹¶é€šè¿‡æœ‰æ•ˆçš„æ·±åº¦å’ŒæµåŠ¨è§„åˆ™åŒ–ã€‚é€šè¿‡ç»¼åˆå®éªŒï¼Œæˆ‘ä»¬è¯æ˜äº†NutWorldèƒ½å¤Ÿå®ç°é«˜ä¿çœŸè§†é¢‘é‡å»ºè´¨é‡ï¼ŒåŒæ—¶æ”¯æŒå®æ—¶ä¸‹æ¸¸åº”ç”¨çš„å¤šç§åº”ç”¨ã€‚æ¼”ç¤ºå’Œä»£ç å°†åœ¨<a target="_blank" rel="noopener" href="https://github.com/Nut-World/NutWorld%E4%B8%8A%E6%8F%90%E4%BE%9B%E3%80%82">https://github.com/Nut-World/NutWorldä¸Šæä¾›ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.03465v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºä¸€ç§å°†å•ç›®è§†é¢‘é«˜æ•ˆè½¬åŒ–ä¸ºåŠ¨æ€ä¸‰ç»´é«˜æ–¯è¡¨ç¤ºçš„æ–°æ¡†æ¶NutWorldã€‚å®ƒé‡‡ç”¨è¿ç»­çš„é«˜æ–¯åŸè¯­æµæ¥æ¨¡æ‹Ÿè§†é¢‘åœ¨æ—¶ç©ºä¸­çš„åŠ¨æ€ä¸‰ç»´è¡¨ç°ï¼Œé€šè¿‡ç»“æ„åŒ–æ—¶ç©ºå¯¹é½é«˜æ–¯ï¼ˆSTAGï¼‰è¡¨ç¤ºï¼Œå®ç°æ— éœ€ä¼˜åŒ–çš„åœºæ™¯å»ºæ¨¡ï¼Œæœ‰æ•ˆè¿›è¡Œæ·±åº¦å’ŒæµåŠ¨è§„åˆ™åŒ–ã€‚å®éªŒè¯æ˜ï¼ŒNutWorldå¯å®ç°é«˜è´¨é‡çš„è§†é¢‘é‡å»ºï¼Œå¹¶é€‚ç”¨äºå¤šç§å®æ—¶ä¸‹æ¸¸åº”ç”¨ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>NutWorldæ¡†æ¶èƒ½å°†å•ç›®è§†é¢‘é«˜æ•ˆè½¬åŒ–ä¸ºåŠ¨æ€ä¸‰ç»´é«˜æ–¯è¡¨ç¤ºã€‚</li>
<li>é‡‡ç”¨è¿ç»­çš„é«˜æ–¯åŸè¯­æµæ¨¡æ‹Ÿè§†é¢‘åœ¨æ—¶ç©ºä¸­çš„è¡¨ç°ã€‚</li>
<li>æå‡ºç»“æ„åŒ–æ—¶ç©ºå¯¹é½é«˜æ–¯ï¼ˆSTAGï¼‰è¡¨ç¤ºï¼Œå®ç°æ— éœ€ä¼˜åŒ–çš„åœºæ™¯å»ºæ¨¡ã€‚</li>
<li>STAGèƒ½æœ‰æ•ˆè¿›è¡Œæ·±åº¦å’ŒæµåŠ¨è§„åˆ™åŒ–ã€‚</li>
<li>NutWorldå¯å®ç°é«˜è´¨é‡çš„è§†é¢‘é‡å»ºã€‚</li>
<li>NutWorldé€‚ç”¨äºå¤šç§å®æ—¶ä¸‹æ¸¸åº”ç”¨ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.03465">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-03-18\./crop_3DGS/2502.03465v2/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-03-18\./crop_3DGS/2502.03465v2/page_2_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-03-18\./crop_3DGS/2502.03465v2/page_3_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-03-18\./crop_3DGS/2502.03465v2/page_5_0.jpg" align="middle">
</details>


<h1 id="-13"><a href="#-13" class="headerlink" title=""></a></h1><h2 id="Sparse-Voxels-Rasterization-Real-time-High-fidelity-Radiance-Field-Rendering"><a href="#Sparse-Voxels-Rasterization-Real-time-High-fidelity-Radiance-Field-Rendering" class="headerlink" title="Sparse Voxels Rasterization: Real-time High-fidelity Radiance Field   Rendering"></a>Sparse Voxels Rasterization: Real-time High-fidelity Radiance Field   Rendering</h2><p><strong>Authors:Cheng Sun, Jaesung Choe, Charles Loop, Wei-Chiu Ma, Yu-Chiang Frank Wang</strong></p>
<p>We propose an efficient radiance field rendering algorithm that incorporates a rasterization process on adaptive sparse voxels without neural networks or 3D Gaussians. There are two key contributions coupled with the proposed system. The first is to adaptively and explicitly allocate sparse voxels to different levels of detail within scenes, faithfully reproducing scene details with $65536^3$ grid resolution while achieving high rendering frame rates. Second, we customize a rasterizer for efficient adaptive sparse voxels rendering. We render voxels in the correct depth order by using ray direction-dependent Morton ordering, which avoids the well-known popping artifact found in Gaussian splatting. Our method improves the previous neural-free voxel model by over 4db PSNR and more than 10x FPS speedup, achieving state-of-the-art comparable novel-view synthesis results. Additionally, our voxel representation is seamlessly compatible with grid-based 3D processing techniques such as Volume Fusion, Voxel Pooling, and Marching Cubes, enabling a wide range of future extensions and applications. </p>
<blockquote>
<p>æˆ‘ä»¬æå‡ºäº†ä¸€ç§é«˜æ•ˆçš„è¾å°„åœºæ¸²æŸ“ç®—æ³•ï¼Œè¯¥ç®—æ³•åœ¨è‡ªé€‚åº”ç¨€ç–ä½“ç´ ä¸Šç»“åˆäº†å…‰æ …åŒ–è¿‡ç¨‹ï¼Œæ— éœ€ç¥ç»ç½‘ç»œæˆ–ä¸‰ç»´é«˜æ–¯è¿‡ç¨‹ã€‚è¯¥ç³»ç»Ÿæœ‰ä¸¤é¡¹å…³é”®è´¡çŒ®ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬è‡ªé€‚åº”ä¸”æ˜ç¡®åœ°åˆ†é…ç¨€ç–ä½“ç´ ä»¥å‘ˆç°åœºæ™¯ä¸­çš„ä¸åŒç»†èŠ‚å±‚æ¬¡ï¼Œä»¥$65536^3$çš„ç½‘æ ¼åˆ†è¾¨ç‡å¿ å®å†ç°åœºæ™¯ç»†èŠ‚ï¼ŒåŒæ—¶å®ç°é«˜å¸§ç‡æ¸²æŸ“ã€‚å…¶æ¬¡ï¼Œæˆ‘ä»¬ä¸ºé«˜æ•ˆçš„è‡ªé€‚åº”ç¨€ç–ä½“ç´ æ¸²æŸ“å®šåˆ¶äº†å…‰æ …åŒ–å™¨ã€‚æˆ‘ä»¬é€šè¿‡ä½¿ç”¨ä¸å°„çº¿æ–¹å‘ç›¸å…³çš„Mortonæ’åºæ¥æŒ‰æ­£ç¡®çš„æ·±åº¦é¡ºåºå‘ˆç°ä½“ç´ ï¼Œè¿™é¿å…äº†é«˜æ–¯å¹³é“ºä¸­å‡ºç°çš„ä¼—æ‰€å‘¨çŸ¥çš„å¼¹è·³ä¼ªå½±ã€‚æˆ‘ä»¬çš„æ–¹æ³•æé«˜äº†ä¹‹å‰æ— ç¥ç»å…ƒçš„ä½“ç´ æ¨¡å‹çš„å³°å€¼ä¿¡å™ªæ¯”è¶…è¿‡4dbï¼Œå¹¶ä¸”å¸§é€Ÿæé«˜äº†è¶…è¿‡10å€ï¼Œå®ç°äº†ä¸æœ€æ–°æŠ€æœ¯ç›¸å½“çš„æ–°è§†è§’åˆæˆç»“æœã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬çš„ä½“ç´ è¡¨ç¤ºä¸åŸºäºç½‘æ ¼çš„3Då¤„ç†æŠ€æœ¯ï¼ˆå¦‚ä½“ç§¯èåˆã€ä½“ç´ æ± åŒ–å’Œé­”æ–¹ç®—æ³•ï¼‰æ— ç¼å…¼å®¹ï¼Œä¸ºæœªæ¥æ‰©å±•å’Œå¹¿æ³›åº”ç”¨æä¾›äº†å¹¿é˜”çš„ç©ºé—´ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.04459v3">PDF</a> CVPR 2025; Project page at <a target="_blank" rel="noopener" href="https://svraster.github.io/">https://svraster.github.io/</a> ; Code at   <a target="_blank" rel="noopener" href="https://github.com/NVlabs/svraster">https://github.com/NVlabs/svraster</a></p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ç§é«˜æ•ˆçš„è¾å°„åœºæ¸²æŸ“ç®—æ³•ï¼Œè¯¥ç®—æ³•å¯¹è‡ªé€‚åº”ç¨€ç–ä½“ç´ è¿›è¡Œäº†æ …æ ¼åŒ–å¤„ç†ï¼Œæ— éœ€ç¥ç»ç½‘ç»œæˆ–3Dé«˜æ–¯ã€‚è¯¥ç³»ç»Ÿæœ‰ä¸¤é¡¹å…³é”®è´¡çŒ®ï¼šä¸€æ˜¯è‡ªé€‚åº”æ˜¾å¼åˆ†é…ç¨€ç–ä½“ç´ ä»¥å‘ˆç°åœºæ™¯ä¸­çš„ä¸åŒç»†èŠ‚å±‚æ¬¡ï¼Œä»¥$65536^3$ç½‘æ ¼åˆ†è¾¨ç‡å¿ å®å†ç°åœºæ™¯ç»†èŠ‚ï¼ŒåŒæ—¶å®ç°é«˜å¸§ç‡æ¸²æŸ“ï¼›äºŒæ˜¯ä¸ºè‡ªé€‚åº”ç¨€ç–ä½“ç´ æ¸²æŸ“å®šåˆ¶äº†æ …æ ¼åŒ–å™¨ï¼Œé€šè¿‡é‡‡ç”¨ä¸å°„çº¿æ–¹å‘ç›¸å…³çš„Mortonæ’åºï¼ŒæŒ‰æ­£ç¡®æ·±åº¦é¡ºåºå‘ˆç°ä½“ç´ ï¼Œé¿å…äº†é«˜æ–¯å¹³é“ºä¸­çš„å¸¸è§å¼¹å‡ºä¼ªå½±ã€‚è¯¥æ–¹æ³•æ”¹è¿›äº†ä¹‹å‰æ— ç¥ç»å…ƒçš„ä½“ç´ æ¨¡å‹ï¼Œæé«˜äº†4db PSNRä»¥ä¸Šï¼Œå¹¶ä¸”å¸§é€Ÿæé«˜äº†10å€ä»¥ä¸Šï¼Œå®ç°äº†ä¸æœ€æ–°æŠ€æœ¯ç›¸å½“çš„æ–°è§†è§’åˆæˆç»“æœã€‚æ­¤å¤–ï¼Œå…¶ä½“ç´ è¡¨ç¤ºä¸åŸºäºç½‘æ ¼çš„3Då¤„ç†æŠ€æœ¯ï¼ˆå¦‚ä½“ç§¯èåˆã€ä½“ç´ æ± åŒ–å’Œ marching cubesï¼‰æ— ç¼å…¼å®¹ï¼Œä¸ºæœªæ¥æ‰©å±•å’Œåº”ç”¨æä¾›äº†å¹¿æ³›çš„å¯èƒ½æ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æå‡ºçš„æ¸²æŸ“ç®—æ³•èƒ½å¤Ÿåœ¨ä¸éœ€è¦ç¥ç»ç½‘ç»œæˆ–3Dé«˜æ–¯çš„æƒ…å†µä¸‹ï¼Œé€šè¿‡æ …æ ¼åŒ–å¤„ç†è‡ªé€‚åº”ç¨€ç–ä½“ç´ ï¼Œå®ç°é«˜æ•ˆè¾å°„åœºæ¸²æŸ“ã€‚</li>
<li>ç³»ç»Ÿèƒ½å¤Ÿè‡ªé€‚åº”æ˜¾å¼åˆ†é…ç¨€ç–ä½“ç´ ï¼Œä»¥å‘ˆç°åœºæ™¯çš„ä¸åŒç»†èŠ‚å±‚æ¬¡ï¼Œè¾¾åˆ°é«˜åˆ†è¾¨ç‡å’Œé«˜é€Ÿæ¸²æŸ“ã€‚</li>
<li>é€šè¿‡é‡‡ç”¨Mortonæ’åºï¼ŒæŒ‰æ­£ç¡®æ·±åº¦é¡ºåºå‘ˆç°ä½“ç´ ï¼Œè§£å†³äº†å¼¹å‡ºä¼ªå½±é—®é¢˜ã€‚</li>
<li>ç›¸æ¯”ä¹‹å‰çš„æ— ç¥ç»å…ƒä½“ç´ æ¨¡å‹ï¼Œè¯¥æ–¹æ³•çš„æ€§èƒ½æœ‰æ‰€æå‡ï¼ŒPSNRæé«˜äº†4dbä»¥ä¸Šï¼Œå¸§é€Ÿæé«˜äº†10å€ä»¥ä¸Šã€‚</li>
<li>æ–¹æ³•å®ç°äº†ä¸æœ€æ–°æŠ€æœ¯ç›¸å½“çš„æ–°è§†è§’åˆæˆç»“æœã€‚</li>
<li>ä½“ç´ è¡¨ç¤ºæ–¹æ³•ä¸åŸºäºç½‘æ ¼çš„3Då¤„ç†æŠ€æœ¯å…¼å®¹ï¼Œä¸ºæœªæ¥æ‰©å±•å’Œåº”ç”¨æä¾›äº†å¹¿æ³›çš„å¯èƒ½æ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.04459">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-03-18\./crop_3DGS/2412.04459v3/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-03-18\./crop_3DGS/2412.04459v3/page_2_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-03-18\./crop_3DGS/2412.04459v3/page_3_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-03-18\./crop_3DGS/2412.04459v3/page_4_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-03-18\./crop_3DGS/2412.04459v3/page_5_0.jpg" align="middle">
</details>


<h1 id="-14"><a href="#-14" class="headerlink" title=""></a></h1><h2 id="GuardSplat-Efficient-and-Robust-Watermarking-for-3D-Gaussian-Splatting"><a href="#GuardSplat-Efficient-and-Robust-Watermarking-for-3D-Gaussian-Splatting" class="headerlink" title="GuardSplat: Efficient and Robust Watermarking for 3D Gaussian Splatting"></a>GuardSplat: Efficient and Robust Watermarking for 3D Gaussian Splatting</h2><p><strong>Authors:Zixuan Chen, Guangcong Wang, Jiahao Zhu, Jianhuang Lai, Xiaohua Xie</strong></p>
<p>3D Gaussian Splatting (3DGS) has recently created impressive 3D assets for various applications. However, considering security, capacity, invisibility, and training efficiency, the copyright of 3DGS assets is not well protected as existing watermarking methods are unsuited for its rendering pipeline. In this paper, we propose GuardSplat, an innovative and efficient framework for watermarking 3DGS assets. Specifically, 1) We propose a CLIP-guided pipeline for optimizing the message decoder with minimal costs. The key objective is to achieve high-accuracy extraction by leveraging CLIPâ€™s aligning capability and rich representations, demonstrating exceptional capacity and efficiency. 2) We tailor a Spherical-Harmonic-aware (SH-aware) Message Embedding module for 3DGS, seamlessly embedding messages into the SH features of each 3D Gaussian while preserving the original 3D structure. This enables watermarking 3DGS assets with minimal fidelity trade-offs and prevents malicious users from removing the watermarks from the model files, meeting the demands for invisibility and security. 3) We present an Anti-distortion Message Extraction module to improve robustness against various distortions. Experiments demonstrate that GuardSplat outperforms state-of-the-art and achieves fast optimization speed. Project page is at <a target="_blank" rel="noopener" href="https://narcissusex.github.io/GuardSplat">https://narcissusex.github.io/GuardSplat</a>, and Code is at <a target="_blank" rel="noopener" href="https://github.com/NarcissusEx/GuardSplat">https://github.com/NarcissusEx/GuardSplat</a>. </p>
<blockquote>
<p>3Dé«˜æ–¯æ‹¼è´´ï¼ˆ3DGSï¼‰æœ€è¿‘ä¸ºå„ç§åº”ç”¨åˆ›å»ºäº†ä»¤äººå°è±¡æ·±åˆ»çš„3Dèµ„äº§ã€‚ç„¶è€Œï¼Œè€ƒè™‘åˆ°å®‰å…¨æ€§ã€å®¹é‡ã€éšè”½æ€§å’Œè®­ç»ƒæ•ˆç‡ï¼Œ3DGSèµ„äº§çš„çŸ¥è¯†äº§æƒå¹¶æœªå¾—åˆ°å……åˆ†ä¿æŠ¤ï¼Œå› ä¸ºç°æœ‰çš„æ°´å°æ–¹æ³•å¹¶ä¸é€‚åˆå…¶æ¸²æŸ“æµç¨‹ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†GuardSplatï¼Œè¿™æ˜¯ä¸€ä¸ªç”¨äºæ°´å°3DGSèµ„äº§çš„åˆ›æ–°å’Œé«˜æ•ˆæ¡†æ¶ã€‚å…·ä½“æ¥è¯´ï¼Œ1ï¼‰æˆ‘ä»¬æå‡ºäº†ä¸€ç§CLIPå¼•å¯¼çš„æµç¨‹æ¥ä¼˜åŒ–æ¶ˆæ¯è§£ç å™¨ï¼Œæˆæœ¬æœ€ä½ã€‚æˆ‘ä»¬çš„ä¸»è¦ç›®æ ‡æ˜¯åˆ©ç”¨CLIPçš„å¯¹é½èƒ½åŠ›å’Œä¸°å¯Œè¡¨ç¤ºæ¥å®ç°é«˜ç²¾åº¦çš„æå–ï¼Œå±•ç°å‡ºå‡ºè‰²çš„å®¹é‡å’Œæ•ˆç‡ã€‚2ï¼‰æˆ‘ä»¬ä¸ºé’ˆå¯¹åº”ç”¨äºæ›²å¥‡æŠ•åº—åˆ¶æ–¹æ³•ç ”å‘ä¸€ä¸ªçƒè°æ„ŸçŸ¥çš„æ¶ˆæ¯åµŒå…¥æ¨¡å—ï¼Œæ— ç¼åœ°å°†æ¶ˆæ¯åµŒå…¥æ¯ä¸ª3Dé«˜æ–¯çš„çƒè°ç‰¹å¾ä¸­ï¼ŒåŒæ—¶ä¿æŒåŸå§‹çš„3Dç»“æ„ä¸å˜ã€‚è¿™ä½¿å¾—æ°´å°åµŒå…¥çš„èµ„äº§åœ¨ä¿çœŸåº¦æ–¹é¢å‡ ä¹æ²¡æœ‰ä»»ä½•å¦¥åï¼Œå¹¶èƒ½é˜²æ­¢æ¶æ„ç”¨æˆ·ä»æ¨¡å‹æ–‡ä»¶ä¸­åˆ é™¤æ°´å°ï¼Œæ»¡è¶³äº†ä¸å¯è§æ€§å’Œå®‰å…¨æ€§çš„éœ€æ±‚ã€‚æˆ‘ä»¬åœ¨å®éªŒä¸­è¯æ˜GuardSplatå…·æœ‰ä¼˜å¼‚çš„æŠ—å¹²æ‰°æ€§æ¶ˆæ¯æå–åŠŸèƒ½æ•ˆæœè‰¯å¥½è€Œä¸”å¯å®ç°å¿«é€Ÿä¼˜åŒ–é€Ÿåº¦è¶…è¶Šäº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚è¯¥é¡¹ç›®çš„é¡µé¢åœ°å€ä¸ºï¼š<a target="_blank" rel="noopener" href="https://narcissusex.github.io/GuardSplat">https://narcissusex.github.io/GuardSplat</a> ï¼Œä»£ç åœ°å€ä¸ºï¼š<a target="_blank" rel="noopener" href="https://github.com/NarcissusEx/GuardSplat">https://github.com/NarcissusEx/GuardSplat</a> ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2411.19895v5">PDF</a> This paper is accepted by the IEEE&#x2F;CVF International Conference on   Computer Vision and Pattern Recognition (CVPR), 2025</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºäº†GuardSplatæ¡†æ¶ï¼Œç”¨äºä¸º3D Gaussian Splattingï¼ˆ3DGSï¼‰èµ„äº§è¿›è¡Œæ°´å°åµŒå…¥ã€‚è¯¥æ¡†æ¶å…·æœ‰ä¼˜åŒ–æ¶ˆæ¯è§£ç å™¨ã€å®šåˆ¶SHæ„ŸçŸ¥æ¶ˆæ¯åµŒå…¥æ¨¡å—ä»¥åŠæŠ—ç•¸å˜æ¶ˆæ¯æå–æ¨¡å—ç­‰ç‰¹ç‚¹ï¼Œå¯å®ç°é«˜å®¹é‡ã€é«˜æ•ˆç‡ã€é«˜ä¿çœŸã€é«˜å®‰å…¨æ€§çš„æ°´å°åµŒå…¥ä¸æå–ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>GuardSplatæ˜¯ä¸€ä¸ªé’ˆå¯¹3DGSèµ„äº§çš„æ°´å°åµŒå…¥æ¡†æ¶ï¼Œæ—¨åœ¨ä¿æŠ¤ç‰ˆæƒã€‚</li>
<li>åˆ©ç”¨CLIPæŒ‡å¯¼ç®¡é“ä¼˜åŒ–æ¶ˆæ¯è§£ç å™¨ï¼Œå®ç°é«˜å‡†ç¡®æ€§æå–ã€‚</li>
<li>å¼€å‘äº†SHæ„ŸçŸ¥æ¶ˆæ¯åµŒå…¥æ¨¡å—ï¼Œå°†æ¶ˆæ¯æ— ç¼åµŒå…¥åˆ°æ¯ä¸ªé«˜æ–¯çƒçš„SHç‰¹å¾ä¸­ï¼Œä¿æŒåŸå§‹ç»“æ„ã€‚</li>
<li>æŠ—ç•¸å˜æ¶ˆæ¯æå–æ¨¡å—æé«˜äº†å¯¹å„ç§ç•¸å˜çš„é²æ£’æ€§ã€‚</li>
<li>GuardSplatä¼˜äºç°æœ‰æŠ€æœ¯ï¼Œå®ç°å¿«é€Ÿä¼˜åŒ–é€Ÿåº¦ã€‚</li>
<li>GuardSplatæ¡†æ¶çš„è¯¦ç»†ä»‹ç»å’Œä»£ç å¯åœ¨é¡¹ç›®é¡µé¢å’Œä»£ç é“¾æ¥å¤„æ‰¾åˆ°ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2411.19895">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-03-18\./crop_3DGS/2411.19895v5/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-03-18\./crop_3DGS/2411.19895v5/page_1_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-03-18\./crop_3DGS/2411.19895v5/page_2_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-03-18\./crop_3DGS/2411.19895v5/page_3_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-03-18\./crop_3DGS/2411.19895v5/page_4_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-03-18\./crop_3DGS/2411.19895v5/page_5_0.jpg" align="middle">
</details>


<h1 id="-15"><a href="#-15" class="headerlink" title=""></a></h1><h2 id="UnitedVLN-Generalizable-Gaussian-Splatting-for-Continuous-Vision-Language-Navigation"><a href="#UnitedVLN-Generalizable-Gaussian-Splatting-for-Continuous-Vision-Language-Navigation" class="headerlink" title="UnitedVLN: Generalizable Gaussian Splatting for Continuous   Vision-Language Navigation"></a>UnitedVLN: Generalizable Gaussian Splatting for Continuous   Vision-Language Navigation</h2><p><strong>Authors:Guangzhao Dai, Jian Zhao, Yuantao Chen, Yusen Qin, Hao Zhao, Guosen Xie, Yazhou Yao, Xiangbo Shu, Xuelong Li</strong></p>
<p>Vision-and-Language Navigation (VLN), where an agent follows instructions to reach a target destination, has recently seen significant advancements. In contrast to navigation in discrete environments with predefined trajectories, VLN in Continuous Environments (VLN-CE) presents greater challenges, as the agent is free to navigate any unobstructed location and is more vulnerable to visual occlusions or blind spots. Recent approaches have attempted to address this by imagining future environments, either through predicted future visual images or semantic features, rather than relying solely on current observations. However, these RGB-based and feature-based methods lack intuitive appearance-level information or high-level semantic complexity crucial for effective navigation. To overcome these limitations, we introduce a novel, generalizable 3DGS-based pre-training paradigm, called UnitedVLN, which enables agents to better explore future environments by unitedly rendering high-fidelity 360 visual images and semantic features. UnitedVLN employs two key schemes: search-then-query sampling and separate-then-united rendering, which facilitate efficient exploitation of neural primitives, helping to integrate both appearance and semantic information for more robust navigation. Extensive experiments demonstrate that UnitedVLN outperforms state-of-the-art methods on existing VLN-CE benchmarks. </p>
<blockquote>
<p>è§†è§‰ä¸è¯­è¨€å¯¼èˆªï¼ˆVLNï¼‰æ˜¯æŒ‡ä»£ç†éµå¾ªæŒ‡ä»¤åˆ°è¾¾ç›®æ ‡ç›®çš„åœ°ï¼Œæœ€è¿‘å–å¾—äº†é‡å¤§è¿›å±•ã€‚ä¸åœ¨å…·æœ‰é¢„å®šä¹‰è½¨è¿¹çš„ç¦»æ•£ç¯å¢ƒä¸­çš„å¯¼èˆªç›¸æ¯”ï¼Œè¿ç»­ç¯å¢ƒä¸­çš„è§†è§‰ä¸è¯­è¨€å¯¼èˆªï¼ˆVLN-CEï¼‰å…·æœ‰æ›´å¤§çš„æŒ‘æˆ˜ï¼Œå› ä¸ºä»£ç†å¯ä»¥è‡ªç”±å¯¼èˆªä»»ä½•æ— éšœç¢çš„ä½ç½®ï¼Œå¹¶ä¸”æ›´å®¹æ˜“å—åˆ°è§†è§‰é®æŒ¡æˆ–ç›²ç‚¹çš„å¹²æ‰°ã€‚è¿‘æœŸçš„æ–¹æ³•å·²ç»å°è¯•é€šè¿‡æƒ³è±¡æœªæ¥çš„ç¯å¢ƒæ¥è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œè¦ä¹ˆé€šè¿‡é¢„æµ‹çš„æœªæ¥è§†è§‰å›¾åƒæˆ–è¯­ä¹‰ç‰¹å¾ï¼Œè€Œä¸æ˜¯ä»…ä»…ä¾èµ–äºå½“å‰çš„è§‚å¯Ÿã€‚ç„¶è€Œï¼Œè¿™äº›åŸºäºRGBçš„æ–¹æ³•å’ŒåŸºäºç‰¹å¾çš„æ–¹æ³•ç¼ºä¹ç›´è§‚çš„å¤–è§‚æ°´å¹³ä¿¡æ¯æˆ–é«˜çº§è¯­ä¹‰å¤æ‚æ€§ï¼Œè¿™å¯¹äºæœ‰æ•ˆçš„å¯¼èˆªè‡³å…³é‡è¦ã€‚ä¸ºäº†å…‹æœè¿™äº›å±€é™æ€§ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§åŸºäºæ–°å‹é€šç”¨ä¸‰ç»´ç½‘æ ¼ç³»ç»Ÿï¼ˆ3DGSï¼‰çš„é¢„è®­ç»ƒèŒƒå¼ï¼Œç§°ä¸ºUnitedVLNã€‚å®ƒèƒ½å¤Ÿè®©ä»£ç†é€šè¿‡è”åˆæ¸²æŸ“é«˜ä¿çœŸ360åº¦è§†è§‰å›¾åƒå’Œè¯­ä¹‰ç‰¹å¾æ¥æ›´å¥½åœ°æ¢ç´¢æœªæ¥ç¯å¢ƒã€‚UnitedVLNé‡‡ç”¨ä¸¤ä¸ªå…³é”®æ–¹æ¡ˆï¼šæœç´¢æŸ¥è¯¢é‡‡æ ·å’Œåˆ†ç¦»è”åˆæ¸²æŸ“ï¼Œè¿™æœ‰åŠ©äºé«˜æ•ˆåˆ©ç”¨ç¥ç»åŸåˆç»†èƒï¼Œå¸®åŠ©æ•´åˆå¤–è§‚å’Œè¯­ä¹‰ä¿¡æ¯ä»¥å®ç°æ›´ç¨³å¥çš„å¯¼èˆªã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼Œåœ¨ç°æœ‰çš„VLN-CEåŸºå‡†æµ‹è¯•ä¸­ï¼ŒUnitedVLNçš„æ€§èƒ½ä¼˜äºæœ€æ–°çš„æŠ€æœ¯æ–¹æ³•ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2411.16053v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>VLNåœ¨è¿ç»­ç¯å¢ƒä¸­çš„æŒ‘æˆ˜åœ¨äºè‡ªç”±å¯¼èˆªå¯èƒ½é‡åˆ°çš„è§†è§‰é®æŒ¡å’Œç›²ç‚¹é—®é¢˜ã€‚é’ˆå¯¹è¿™ä¸€é—®é¢˜ï¼Œç ”ç©¶è€…æå‡ºäº†ä¸€ç§åŸºäºç»Ÿä¸€æ¸²æŸ“é«˜ä¿çœŸåº¦360åº¦è§†è§‰å›¾åƒå’Œè¯­ä¹‰ç‰¹å¾çš„é€šç”¨é¢„è®­ç»ƒèŒƒå¼â€”â€”UnitedVLNã€‚å®ƒé€šè¿‡ä¸¤å¤§æ–¹æ¡ˆâ€”â€”æœç´¢æŸ¥è¯¢é‡‡æ ·å’Œåˆ†ç¦»è”åˆæ¸²æŸ“ï¼Œæœ‰æ•ˆåœ°æ•´åˆäº†å¤–è§‚å’Œè¯­ä¹‰ä¿¡æ¯ï¼Œä½¿å¾—æ™ºèƒ½ä½“èƒ½å¤Ÿåœ¨è¿ç»­ç¯å¢ƒä¸­è¿›è¡Œæ›´ç¨³å¥çš„å¯¼èˆªã€‚å®éªŒç»“æœè¯æ˜ï¼Œåœ¨ç°æœ‰çš„VLN-CEåŸºå‡†æµ‹è¯•ä¸­ï¼ŒUnitedVLNä¼˜äºå…¶ä»–æœ€æ–°æ–¹æ³•ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>VLNåœ¨è¿ç»­ç¯å¢ƒä¸­é¢ä¸´æ–°çš„æŒ‘æˆ˜ï¼Œä¾‹å¦‚è§†è§‰é®æŒ¡å’Œç›²ç‚¹é—®é¢˜ã€‚</li>
<li>æœ€æ–°æ–¹æ³•å°è¯•é€šè¿‡æƒ³è±¡æœªæ¥ç¯å¢ƒæ¥è§£å†³æ­¤é—®é¢˜ï¼ŒåŒ…æ‹¬RGBæ–¹æ³•å’Œç‰¹å¾æ–¹æ³•ã€‚</li>
<li>ä½†è¿™äº›æ–¹æ³•ç¼ºä¹å¤–è§‚çº§åˆ«ä¿¡æ¯å’Œé«˜å±‚æ¬¡è¯­ä¹‰å¤æ‚æ€§ï¼Œå¯¹æœ‰æ•ˆå¯¼èˆªè‡³å…³é‡è¦ã€‚</li>
<li>ä¸ºè§£å†³è¿™äº›é™åˆ¶ï¼Œå¼•å…¥äº†åŸºäº3DGSçš„é¢„è®­ç»ƒèŒƒå¼â€”â€”UnitedVLNã€‚</li>
<li>UnitedVLNçš„æ ¸å¿ƒä¼˜åŠ¿åœ¨äºæ•´åˆäº†å¤–è§‚å’Œè¯­ä¹‰ä¿¡æ¯ã€‚å®ƒå®ç°äº†æ›´ç¨³å¥çš„å¯¼èˆªã€‚</li>
<li>UnitedVLNé‡‡ç”¨ä¸¤å¤§å…³é”®æ–¹æ¡ˆï¼šæœç´¢æŸ¥è¯¢é‡‡æ ·å’Œåˆ†ç¦»è”åˆæ¸²æŸ“ã€‚è¿™äº›æ–¹æ¡ˆæé«˜äº†ç¥ç»ç½‘ç»œåŸå‹çš„æ•ˆç‡ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2411.16053">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-03-18\./crop_3DGS/2411.16053v2/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-03-18\./crop_3DGS/2411.16053v2/page_2_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-03-18\./crop_3DGS/2411.16053v2/page_5_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-03-18\./crop_3DGS/2411.16053v2/page_5_1.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-03-18\./crop_3DGS/2411.16053v2/page_5_2.jpg" align="middle">
</details>


<h1 id="-16"><a href="#-16" class="headerlink" title=""></a></h1><h2 id="Unleashing-the-Potential-of-Multi-modal-Foundation-Models-and-Video-Diffusion-for-4D-Dynamic-Physical-Scene-Simulation"><a href="#Unleashing-the-Potential-of-Multi-modal-Foundation-Models-and-Video-Diffusion-for-4D-Dynamic-Physical-Scene-Simulation" class="headerlink" title="Unleashing the Potential of Multi-modal Foundation Models and Video   Diffusion for 4D Dynamic Physical Scene Simulation"></a>Unleashing the Potential of Multi-modal Foundation Models and Video   Diffusion for 4D Dynamic Physical Scene Simulation</h2><p><strong>Authors:Zhuoman Liu, Weicai Ye, Yan Luximon, Pengfei Wan, Di Zhang</strong></p>
<p>Realistic simulation of dynamic scenes requires accurately capturing diverse material properties and modeling complex object interactions grounded in physical principles. However, existing methods are constrained to basic material types with limited predictable parameters, making them insufficient to represent the complexity of real-world materials. We introduce PhysFlow, a novel approach that leverages multi-modal foundation models and video diffusion to achieve enhanced 4D dynamic scene simulation. Our method utilizes multi-modal models to identify material types and initialize material parameters through image queries, while simultaneously inferring 3D Gaussian splats for detailed scene representation. We further refine these material parameters using video diffusion with a differentiable Material Point Method (MPM) and optical flow guidance rather than render loss or Score Distillation Sampling (SDS) loss. This integrated framework enables accurate prediction and realistic simulation of dynamic interactions in real-world scenarios, advancing both accuracy and flexibility in physics-based simulations. </p>
<blockquote>
<p>çœŸå®åœºæ™¯çš„åŠ¨æ€æ¨¡æ‹Ÿéœ€è¦å‡†ç¡®æ•æ‰å„ç§ææ–™å±æ€§ï¼Œå¹¶åŸºäºç‰©ç†åŸç†å¯¹å¤æ‚çš„ç‰©ä½“äº¤äº’è¿›è¡Œå»ºæ¨¡ã€‚ç„¶è€Œï¼Œç°æœ‰æ–¹æ³•å±€é™äºå…·æœ‰æœ‰é™å¯é¢„æµ‹å‚æ•°çš„åŸºæœ¬ææ–™ç±»å‹ï¼Œæ— æ³•ä»£è¡¨çœŸå®ä¸–ç•Œææ–™çš„å¤æ‚æ€§ã€‚æˆ‘ä»¬å¼•å…¥äº†PhysFlowï¼Œè¿™æ˜¯ä¸€ç§åˆ©ç”¨å¤šæ¨¡æ€åŸºç¡€æ¨¡å‹å’Œè§†é¢‘æ‰©æ•£æ¥å®ç°å¢å¼ºå‹4DåŠ¨æ€åœºæ™¯æ¨¡æ‹Ÿçš„æ–°æ–¹æ³•ã€‚æˆ‘ä»¬çš„æ–¹æ³•åˆ©ç”¨å¤šæ¨¡æ€æ¨¡å‹é€šè¿‡å›¾åƒæŸ¥è¯¢è¯†åˆ«ææ–™ç±»å‹å¹¶åˆå§‹åŒ–ææ–™å‚æ•°ï¼ŒåŒæ—¶æ¨æ–­3Dé«˜æ–¯æ–‘ç‚¹ç”¨äºè¯¦ç»†åœºæ™¯è¡¨ç¤ºã€‚æˆ‘ä»¬è¿›ä¸€æ­¥ä½¿ç”¨å¯å¾®åˆ†çš„ç‰©è´¨ç‚¹æ³•ï¼ˆMPMï¼‰å’Œå…‰æµæŒ‡å¯¼çš„è§†é¢‘æ‰©æ•£æ¥ä¼˜åŒ–è¿™äº›ææ–™å‚æ•°ï¼Œè€Œä¸æ˜¯ä½¿ç”¨æ¸²æŸ“æŸå¤±æˆ–å¾—åˆ†è’¸é¦é‡‡æ ·ï¼ˆSDSï¼‰æŸå¤±ã€‚è¿™ä¸€ç»¼åˆæ¡†æ¶èƒ½å¤Ÿå‡†ç¡®é¢„æµ‹å’Œæ¨¡æ‹ŸçœŸå®åœºæ™¯ä¸­çš„åŠ¨æ€äº¤äº’ï¼Œæé«˜åŸºäºç‰©ç†çš„æ¨¡æ‹Ÿçš„å‡†ç¡®æ€§å’Œçµæ´»æ€§ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2411.14423v2">PDF</a> CVPR 2025. Homepage: <a target="_blank" rel="noopener" href="https://zhuomanliu.github.io/PhysFlow/">https://zhuomanliu.github.io/PhysFlow/</a></p>
<p><strong>æ‘˜è¦</strong><br>å®ç°åŠ¨æ€åœºæ™¯çš„é€¼çœŸæ¨¡æ‹Ÿéœ€è¦å‡†ç¡®æ•æ‰å„ç§ææ–™ç‰¹æ€§ï¼Œå¹¶åŸºäºç‰©ç†åŸç†å¯¹å¤æ‚çš„ç‰©ä½“äº¤äº’è¿›è¡Œå»ºæ¨¡ã€‚ç„¶è€Œï¼Œç°æœ‰æ–¹æ³•å±€é™äºå…·æœ‰æœ‰é™å¯é¢„æµ‹å‚æ•°çš„åŸºæœ¬ææ–™ç±»å‹ï¼Œæ— æ³•ä»£è¡¨çœŸå®ä¸–ç•Œä¸­ææ–™çš„å¤æ‚æ€§ã€‚æˆ‘ä»¬å¼•å…¥äº†PhysFlowï¼Œè¿™æ˜¯ä¸€ç§åˆ©ç”¨å¤šæ¨¡æ€åŸºç¡€æ¨¡å‹å’Œè§†é¢‘æ‰©æ•£æ¥å®ç°å¢å¼ºçš„4DåŠ¨æ€åœºæ™¯æ¨¡æ‹Ÿçš„æ–°æ–¹æ³•ã€‚æˆ‘ä»¬çš„æ–¹æ³•åˆ©ç”¨å¤šæ¨¡æ€æ¨¡å‹æ¥è¯†åˆ«ææ–™ç±»å‹å¹¶é€šè¿‡å›¾åƒæŸ¥è¯¢åˆå§‹åŒ–ææ–™å‚æ•°ï¼ŒåŒæ—¶æ¨æ–­ç”¨äºè¯¦ç»†åœºæ™¯è¡¨ç¤ºçš„3Dé«˜æ–¯æ–¯æ™®é›·ç‰¹ã€‚æˆ‘ä»¬è¿›ä¸€æ­¥ä½¿ç”¨å¯å¾®åˆ†çš„ç‰©è´¨ç‚¹æ³•ï¼ˆMPMï¼‰å’Œè§†é¢‘æµæŒ‡å¯¼è€Œéæ¸²æŸ“æŸå¤±æˆ–è¯„åˆ†è’¸é¦é‡‡æ ·ï¼ˆSDSï¼‰æŸå¤±æ¥å®Œå–„è¿™äº›ææ–™å‚æ•°ã€‚è¿™ä¸€ç»¼åˆæ¡†æ¶èƒ½å¤Ÿå‡†ç¡®é¢„æµ‹å’Œé€¼çœŸåœ°æ¨¡æ‹Ÿç°å®åœºæ™¯ä¸­çš„åŠ¨æ€äº¤äº’ï¼Œæé«˜äº†ç‰©ç†æ¨¡æ‹Ÿçš„å‡†ç¡®æ€§å’Œçµæ´»æ€§ã€‚</p>
<p><strong>è¦ç‚¹</strong></p>
<ol>
<li>çœŸå®åœºæ™¯çš„æ¨¡æ‹Ÿéœ€è¦æ•æ‰å¤šæ ·çš„ææ–™ç‰¹æ€§å’Œå¤æ‚çš„ç‰©ä½“äº¤äº’ã€‚</li>
<li>ç°æœ‰æ¨¡æ‹Ÿæ–¹æ³•å­˜åœ¨å±€é™æ€§ï¼Œéš¾ä»¥å¤„ç†çœŸå®ä¸–ç•Œä¸­å¤æ‚å¤šå˜ææ–™ç±»å‹çš„æ¨¡æ‹Ÿã€‚</li>
<li>å¼•å…¥PhysFlowæ–¹æ³•ï¼Œç»“åˆå¤šæ¨¡æ€åŸºç¡€æ¨¡å‹å’Œè§†é¢‘æ‰©æ•£æŠ€æœ¯ï¼Œå¢å¼º4DåŠ¨æ€åœºæ™¯æ¨¡æ‹Ÿã€‚</li>
<li>é€šè¿‡å›¾åƒæŸ¥è¯¢è¯†åˆ«ææ–™ç±»å‹å¹¶åˆå§‹åŒ–ææ–™å‚æ•°ã€‚</li>
<li>åˆ©ç”¨3Dé«˜æ–¯æ–¯æ™®é›·ç‰¹è¿›è¡Œè¯¦ç»†çš„åœºæ™¯è¡¨ç¤ºã€‚</li>
<li>é‡‡ç”¨å¯å¾®åˆ†çš„ç‰©è´¨ç‚¹æ³•ï¼ˆMPMï¼‰å’Œè§†é¢‘æµæŒ‡å¯¼æ¥å®Œå–„ææ–™å‚æ•°é¢„æµ‹ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2411.14423">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-03-18\./crop_3DGS/2411.14423v2/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-03-18\./crop_3DGS/2411.14423v2/page_1_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-03-18\./crop_3DGS/2411.14423v2/page_2_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-03-18\./crop_3DGS/2411.14423v2/page_4_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-03-18\./crop_3DGS/2411.14423v2/page_5_0.jpg" align="middle">
</details>


<h1 id="-17"><a href="#-17" class="headerlink" title=""></a></h1><h2 id="A-Hierarchical-Compression-Technique-for-3D-Gaussian-Splatting-Compression"><a href="#A-Hierarchical-Compression-Technique-for-3D-Gaussian-Splatting-Compression" class="headerlink" title="A Hierarchical Compression Technique for 3D Gaussian Splatting   Compression"></a>A Hierarchical Compression Technique for 3D Gaussian Splatting   Compression</h2><p><strong>Authors:He Huang, Wenjie Huang, Qi Yang, Yiling Xu, Zhu li</strong></p>
<p>3D Gaussian Splatting (GS) demonstrates excellent rendering quality and generation speed in novel view synthesis. However, substantial data size poses challenges for storage and transmission, making 3D GS compression an essential technology. Current 3D GS compression research primarily focuses on developing more compact scene representations, such as converting explicit 3D GS data into implicit forms. In contrast, compression of the GS data itself has hardly been explored. To address this gap, we propose a Hierarchical GS Compression (HGSC) technique. Initially, we prune unimportant Gaussians based on importance scores derived from both global and local significance, effectively reducing redundancy while maintaining visual quality. An Octree structure is used to compress 3D positions. Based on the 3D GS Octree, we implement a hierarchical attribute compression strategy by employing a KD-tree to partition the 3D GS into multiple blocks. We apply farthest point sampling to select anchor primitives within each block and others as non-anchor primitives with varying Levels of Details (LoDs). Anchor primitives serve as reference points for predicting non-anchor primitives across different LoDs to reduce spatial redundancy. For anchor primitives, we use the region adaptive hierarchical transform to achieve near-lossless compression of various attributes. For non-anchor primitives, each is predicted based on the k-nearest anchor primitives. To further minimize prediction errors, the reconstructed LoD and anchor primitives are combined to form new anchor primitives to predict the next LoD. Our method notably achieves superior compression quality and a significant data size reduction of over 4.5 times compared to the state-of-the-art compression method on small scenes datasets. </p>
<blockquote>
<p>åœ¨æ–°å‹è§†å›¾åˆæˆä¸­ï¼Œ3Dé«˜æ–¯ç‚¹äº‘ï¼ˆGSï¼‰å±•ç°äº†å‡ºè‰²çš„æ¸²æŸ“è´¨é‡å’Œç”Ÿæˆé€Ÿåº¦ã€‚ç„¶è€Œï¼Œåºå¤§çš„æ•°æ®é‡å¯¹å­˜å‚¨å’Œä¼ è¾“é€ æˆäº†æŒ‘æˆ˜ï¼Œå› æ­¤ï¼Œ3D GSå‹ç¼©æˆä¸ºä¸€é¡¹å…³é”®æŠ€æœ¯ã€‚ç›®å‰çš„3D GSå‹ç¼©ç ”ç©¶ä¸»è¦é›†ä¸­åœ¨å¼€å‘æ›´ç´§å‡‘çš„åœºæ™¯è¡¨ç¤ºä¸Šï¼Œä¾‹å¦‚å°†æ˜¾å¼3D GSæ•°æ®è½¬æ¢ä¸ºéšå¼å½¢å¼ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼ŒGSæ•°æ®æœ¬èº«çš„å‹ç¼©å‡ ä¹å°šæœªè¢«æ¢ç´¢ã€‚ä¸ºäº†è§£å†³è¿™ä¸€ç©ºç™½ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åˆ†å±‚GSå‹ç¼©ï¼ˆHGSCï¼‰æŠ€æœ¯ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2411.06976v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºä¸€ç§åŸºäºé«˜æ–¯åˆ†è£‚çš„åˆ†å±‚å‹ç¼©æŠ€æœ¯ï¼ˆHGSCï¼‰ï¼Œç”¨äºè§£å†³ä¸‰ç»´é«˜æ–¯åˆ†è£‚ï¼ˆGSï¼‰æ•°æ®åœ¨åœºæ™¯æ¸²æŸ“ä¸­å­˜åœ¨çš„å¤§è§„æ¨¡æ•°æ®å­˜å‚¨å’Œä¼ è¾“é—®é¢˜ã€‚è¯¥æ–¹æ³•é€šè¿‡é‡è¦æ€§è¯„åˆ†å‰”é™¤å†—ä½™çš„é«˜æ–¯æ•°æ®ï¼Œå¹¶ç»“åˆå…«å‰æ ‘ç»“æ„å’ŒKDæ ‘åˆ†åŒºç­–ç•¥ï¼Œå®ç°é«˜æ•ˆçš„ä¸‰ç»´ä½ç½®å‹ç¼©å’Œå±æ€§å‹ç¼©ã€‚é€šè¿‡åˆ†å±‚ç»†èŠ‚ï¼ˆLoDï¼‰å’Œé”šç‚¹é¢„æµ‹æŠ€æœ¯ï¼Œå‡å°‘äº†ç©ºé—´å†—ä½™ï¼Œæé«˜äº†å‹ç¼©è´¨é‡ï¼Œç›¸è¾ƒäºç°æœ‰æ–¹æ³•ï¼Œåœ¨å°å‹åœºæ™¯æ•°æ®é›†ä¸Šå®ç°äº†è¶…è¿‡4.5å€çš„æ•°æ®è§„æ¨¡ç¼©å‡ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>3D Gaussian Splatting (GS) åœ¨æ–°å‹è§†å›¾åˆæˆä¸­è¡¨ç°ä¼˜ç§€ï¼Œä½†æ•°æ®é‡å·¨å¤§ï¼Œéœ€è¦å‹ç¼©æŠ€æœ¯è§£å†³å­˜å‚¨å’Œä¼ è¾“é—®é¢˜ã€‚</li>
<li>å½“å‰ç ”ç©¶ä¸»è¦é›†ä¸­åœ¨å¼€å‘æ›´ç´§å‡‘çš„åœºæ™¯è¡¨ç¤ºä¸Šï¼Œè€Œå¯¹ GS æ•°æ®æœ¬èº«çš„å‹ç¼©ç ”ç©¶è¾ƒå°‘ã€‚</li>
<li>æå‡ºçš„ Hierarchical GS Compression (HGSC) æŠ€æœ¯é€šè¿‡é‡è¦æ€§è¯„åˆ†å‰”é™¤å†—ä½™é«˜æ–¯æ•°æ®ã€‚</li>
<li>ä½¿ç”¨ Octree ç»“æ„å‹ç¼© 3D ä½ç½®ï¼Œå¹¶å®ç°åŸºäº KD-tree çš„åˆ†å±‚å±æ€§å‹ç¼©ç­–ç•¥ã€‚</li>
<li>å¼•å…¥åˆ†å±‚ç»†èŠ‚ï¼ˆLoDï¼‰å’Œé”šç‚¹é¢„æµ‹æŠ€æœ¯ï¼Œå‡å°‘ç©ºé—´å†—ä½™ï¼Œæé«˜å‹ç¼©è´¨é‡ã€‚</li>
<li>åœ¨å°å‹åœºæ™¯æ•°æ®é›†ä¸Šå®ç°äº†è¶…è¿‡ 4.5 å€çš„æ•°æ®è§„æ¨¡ç¼©å‡ï¼Œç›¸è¾ƒäºç°æœ‰æ–¹æ³•å…·æœ‰æ˜¾è‘—ä¼˜åŠ¿ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2411.06976">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-03-18\./crop_3DGS/2411.06976v2/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-03-18\./crop_3DGS/2411.06976v2/page_1_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-03-18\./crop_3DGS/2411.06976v2/page_2_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-03-18\./crop_3DGS/2411.06976v2/page_3_0.jpg" align="middle">
</details>


<h1 id="-18"><a href="#-18" class="headerlink" title=""></a></h1><h2 id="AV-GS-Learning-Material-and-Geometry-Aware-Priors-for-Novel-View-Acoustic-Synthesis"><a href="#AV-GS-Learning-Material-and-Geometry-Aware-Priors-for-Novel-View-Acoustic-Synthesis" class="headerlink" title="AV-GS: Learning Material and Geometry Aware Priors for Novel View   Acoustic Synthesis"></a>AV-GS: Learning Material and Geometry Aware Priors for Novel View   Acoustic Synthesis</h2><p><strong>Authors:Swapnil Bhosale, Haosen Yang, Diptesh Kanojia, Jiankang Deng, Xiatian Zhu</strong></p>
<p>Novel view acoustic synthesis (NVAS) aims to render binaural audio at any target viewpoint, given a mono audio emitted by a sound source at a 3D scene. Existing methods have proposed NeRF-based implicit models to exploit visual cues as a condition for synthesizing binaural audio. However, in addition to low efficiency originating from heavy NeRF rendering, these methods all have a limited ability of characterizing the entire scene environment such as room geometry, material properties, and the spatial relation between the listener and sound source. To address these issues, we propose a novel Audio-Visual Gaussian Splatting (AV-GS) model. To obtain a material-aware and geometry-aware condition for audio synthesis, we learn an explicit point-based scene representation with an audio-guidance parameter on locally initialized Gaussian points, taking into account the space relation from the listener and sound source. To make the visual scene model audio adaptive, we propose a point densification and pruning strategy to optimally distribute the Gaussian points, with the per-point contribution in sound propagation (e.g., more points needed for texture-less wall surfaces as they affect sound path diversion). Extensive experiments validate the superiority of our AV-GS over existing alternatives on the real-world RWAS and simulation-based SoundSpaces datasets. </p>
<blockquote>
<p>æ–°å‹è§†å›¾å£°å­¦åˆæˆï¼ˆNVASï¼‰æ—¨åœ¨æ ¹æ®ä¸‰ç»´åœºæ™¯ä¸­å£°æºå‘å‡ºçš„å•å£°é“éŸ³é¢‘ï¼Œåœ¨ä»»ä½•ç›®æ ‡è§‚ç‚¹ä¸Šå‘ˆç°åŒè€³éŸ³é¢‘ã€‚ç°æœ‰æ–¹æ³•å·²ç»æå‡ºäº†åŸºäºNeRFçš„éšå¼æ¨¡å‹ï¼Œåˆ©ç”¨è§†è§‰çº¿ç´¢ä½œä¸ºåˆæˆåŒå£°é“éŸ³é¢‘çš„æ¡ä»¶ã€‚ç„¶è€Œï¼Œé™¤äº†æºäºNeRFæ¸²æŸ“çš„ä½æ•ˆç‡ä¹‹å¤–ï¼Œè¿™äº›æ–¹æ³•åœ¨è¡¨å¾æ•´ä¸ªåœºæ™¯ç¯å¢ƒæ–¹é¢éƒ½æœ‰å±€é™æ€§ï¼Œå¦‚æˆ¿é—´å‡ ä½•ã€ææ–™å±æ€§å’Œå¬ä¼—ä¸å£°æºä¹‹é—´çš„ç©ºé—´å…³ç³»ã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°å‹çš„è§†å¬é«˜æ–¯å¹³é“ºï¼ˆAV-GSï¼‰æ¨¡å‹ã€‚ä¸ºäº†è·å¾—ç”¨äºéŸ³é¢‘åˆæˆçš„ææ–™æ„ŸçŸ¥å’Œå‡ ä½•æ„ŸçŸ¥æ¡ä»¶ï¼Œæˆ‘ä»¬åœ¨æœ¬åœ°åˆå§‹åŒ–çš„é«˜æ–¯ç‚¹ä¸ŠåŠ å…¥äº†éŸ³é¢‘å¼•å¯¼å‚æ•°ï¼Œå­¦ä¹ æ˜ç¡®çš„ç‚¹åŸºåœºæ™¯è¡¨ç¤ºï¼ŒåŒæ—¶è€ƒè™‘åˆ°å¬ä¼—å’Œå£°æºä¹‹é—´çš„ç©ºé—´å…³ç³»ã€‚ä¸ºäº†ä½¿è§†è§‰åœºæ™¯æ¨¡å‹é€‚åº”éŸ³é¢‘ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§ç‚¹å¯†é›†åŒ–å’Œå‰ªæç­–ç•¥ï¼Œä»¥æœ€ä¼˜æ–¹å¼åˆ†å¸ƒé«˜æ–¯ç‚¹ï¼Œæ¯ç‚¹çš„å£°éŸ³ä¼ æ’­è´¡çŒ®ä¸åŒï¼ˆä¾‹å¦‚ï¼Œå¯¹äºå½±å“å£°éŸ³è·¯å¾„è½¬å‘çš„æ— çº¹ç†å¢™é¢è¡¨é¢éœ€è¦æ›´å¤šçš„ç‚¹ï¼‰ã€‚å¤§é‡å®éªŒéªŒè¯äº†æˆ‘ä»¬AV-GSåœ¨ç°å®ä¸–ç•ŒRWASå’ŒåŸºäºæ¨¡æ‹Ÿçš„SoundSpacesæ•°æ®é›†ä¸Šä¼˜äºç°æœ‰æ›¿ä»£æ–¹æ¡ˆã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2406.08920v3">PDF</a> Accepted to NeurIPS 2024</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†é’ˆå¯¹NVASï¼ˆæ–°å‹è§†å›¾å£°å­¦åˆæˆï¼‰çš„æ–°æŠ€æœ¯ï¼Œè¯¥æŠ€æœ¯æ—¨åœ¨åˆ©ç”¨å•å£°é“éŸ³é¢‘åœ¨ä¸‰ç»´åœºæ™¯ä¸­å‘ˆç°ç›®æ ‡è§‚ç‚¹çš„åŒé€šé“éŸ³é¢‘ã€‚æ–‡ç« æå‡ºäº†ä¸€ç§æ–°å‹çš„è§†å¬é«˜æ–¯æ‰©å±•æ¨¡å‹ï¼ˆAV-GSï¼‰ï¼Œä»¥è§£å†³ç°æœ‰æ–¹æ³•çš„å±€é™æ€§ï¼ŒåŒ…æ‹¬ä½æ•ˆç‡å’Œæ— æ³•å……åˆ†åˆ»ç”»æ•´ä¸ªåœºæ™¯ç¯å¢ƒçš„é—®é¢˜ã€‚è¯¥æ¨¡å‹é‡‡ç”¨æ˜¾å¼çš„ç‚¹åŸºåœºæ™¯è¡¨ç¤ºï¼Œè€ƒè™‘åˆ°å¬è€…ä¸å£°æºä¹‹é—´çš„ç©ºé—´å…³ç³»ï¼Œå¯¹å­¦ä¹ é«˜æ–¯ç‚¹é›†è¿›è¡ŒéŸ³é¢‘æŒ‡å¯¼å‚æ•°çš„å¼•å¯¼ï¼Œå¹¶æ ¹æ®éœ€è¦å¯†åº¦åˆ†é…å’Œåˆ é™¤ç‚¹é›†ä»¥ä¼˜åŒ–å£°éŸ³ä¼ æ’­ã€‚å®éªŒè¯æ˜ï¼ŒAV-GSåœ¨çœŸå®ä¸–ç•Œå’Œæ¨¡æ‹Ÿæ•°æ®é›†ä¸Šå‡ä¼˜äºç°æœ‰æ–¹æ³•ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>NVASæŠ€æœ¯æ—¨åœ¨ä½¿ç”¨å•å£°é“éŸ³é¢‘åœ¨ä¸‰ç»´åœºæ™¯ä¸­ç”Ÿæˆä»»ä½•ç›®æ ‡è§‚ç‚¹çš„åŒé€šé“éŸ³é¢‘ã€‚</li>
<li>ç°æœ‰æ–¹æ³•åˆ©ç”¨NeRFæŠ€æœ¯ç»“åˆè§†è§‰çº¿ç´¢åˆæˆåŒè€³éŸ³é¢‘ï¼Œä½†å­˜åœ¨æ•ˆç‡ä½å’Œåœºæ™¯ç¯å¢ƒè¡¨å¾ä¸è¶³çš„é—®é¢˜ã€‚</li>
<li>AV-GSæ¨¡å‹è§£å†³äº†ä¸Šè¿°é—®é¢˜ï¼Œé€šè¿‡æ˜¾å¼ç‚¹åŸºåœºæ™¯è¡¨ç¤ºè¿›è¡ŒéŸ³é¢‘åˆæˆï¼Œå¹¶ç»“åˆéŸ³é¢‘å¼•å¯¼å‚æ•°ä¼˜åŒ–æ¨¡å‹è¡¨ç°ã€‚</li>
<li>æ¨¡å‹è€ƒè™‘å¬è€…ã€å£°æºå’Œåœºæ™¯å‡ ä½•å…³ç³»ï¼Œåˆ©ç”¨é«˜æ–¯ç‚¹é›†æ„å»ºåœºæ™¯æ¨¡å‹ã€‚</li>
<li>æ¨¡å‹é€šè¿‡ç‚¹é›†çš„å¯†åº¦åˆ†é…å’Œåˆ é™¤ç­–ç•¥å®ç°è‡ªé€‚åº”è°ƒæ•´ï¼Œä»¥ä¼˜åŒ–å£°éŸ³ä¼ æ’­æ•ˆæœã€‚</li>
<li>å®éªŒè¯æ˜AV-GSåœ¨çœŸå®ä¸–ç•Œå’Œæ¨¡æ‹Ÿæ•°æ®é›†ä¸Šçš„è¡¨ç°ä¼˜äºç°æœ‰æ–¹æ³•ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2406.08920">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-03-18\./crop_3DGS/2406.08920v3/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-03-18\./crop_3DGS/2406.08920v3/page_1_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-03-18\./crop_3DGS/2406.08920v3/page_3_0.jpg" align="middle">
</details>


<h1 id="-19"><a href="#-19" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-03-18/3DGS/">https://kedreamix.github.io/Talk2Paper/Paper/2025-03-18/3DGS/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/3DGS/">
                                    <span class="chip bg-color">3DGS</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-03-18/NeRF/">
                    <div class="card-image">
                        
                        <img src="D:\MyBlog\AutoFX\arxiv\2025-03-18\./crop_NeRF/2503.13347v1/page_0_0.jpg" class="responsive-img" alt="NeRF">
                        
                        <span class="card-title">NeRF</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            NeRF æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-03-18  TriDF Triplane-Accelerated Density Fields for Few-Shot Remote Sensing   Novel View Synthesis
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-03-18
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/NeRF/" class="post-category">
                                    NeRF
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/NeRF/">
                        <span class="chip bg-color">NeRF</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-03-18/%E5%85%83%E5%AE%87%E5%AE%99_%E8%99%9A%E6%8B%9F%E4%BA%BA/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-7d1905698c91d2063f23c4b6c64ce351.jpg" class="responsive-img" alt="å…ƒå®‡å®™/è™šæ‹Ÿäºº">
                        
                        <span class="card-title">å…ƒå®‡å®™/è™šæ‹Ÿäºº</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            å…ƒå®‡å®™/è™šæ‹Ÿäºº æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-03-18  RGBAvatar Reduced Gaussian Blendshapes for Online Modeling of Head   Avatars
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-03-18
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/%E5%85%83%E5%AE%87%E5%AE%99-%E8%99%9A%E6%8B%9F%E4%BA%BA/" class="post-category">
                                    å…ƒå®‡å®™/è™šæ‹Ÿäºº
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/%E5%85%83%E5%AE%87%E5%AE%99-%E8%99%9A%E6%8B%9F%E4%BA%BA/">
                        <span class="chip bg-color">å…ƒå®‡å®™/è™šæ‹Ÿäºº</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">16765.7k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
