<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="è§†é¢‘ç†è§£">
    <meta name="description" content="è§†é¢‘ç†è§£ æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-03-18  Logic-in-Frames Dynamic Keyframe Search via Visual Semantic-Logical   Verification for Long Video Understanding">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>è§†é¢‘ç†è§£ | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://pic1.zhimg.com/v2-bc135ad0d0def72cacde9f8a014dd998.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">è§†é¢‘ç†è§£</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/%E8%A7%86%E9%A2%91%E7%90%86%E8%A7%A3/">
                                <span class="chip bg-color">è§†é¢‘ç†è§£</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/%E8%A7%86%E9%A2%91%E7%90%86%E8%A7%A3/" class="post-category">
                                è§†é¢‘ç†è§£
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-03-18
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-05-14
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    6.1k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    25 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-03-18-æ›´æ–°"><a href="#2025-03-18-æ›´æ–°" class="headerlink" title="2025-03-18 æ›´æ–°"></a>2025-03-18 æ›´æ–°</h1><h2 id="Logic-in-Frames-Dynamic-Keyframe-Search-via-Visual-Semantic-Logical-Verification-for-Long-Video-Understanding"><a href="#Logic-in-Frames-Dynamic-Keyframe-Search-via-Visual-Semantic-Logical-Verification-for-Long-Video-Understanding" class="headerlink" title="Logic-in-Frames: Dynamic Keyframe Search via Visual Semantic-Logical   Verification for Long Video Understanding"></a>Logic-in-Frames: Dynamic Keyframe Search via Visual Semantic-Logical   Verification for Long Video Understanding</h2><p><strong>Authors:Weiyu Guo, Ziyang Chen, Shaoguang Wang, Jianxiang He, Yijie Xu, Jinhui Ye, Ying Sun, Hui Xiong</strong></p>
<p>Understanding long video content is a complex endeavor that often relies on densely sampled frame captions or end-to-end feature selectors, yet these techniques commonly overlook the logical relationships between textual queries and visual elements. In practice, computational constraints necessitate coarse frame subsampling, a challenge analogous to &#96;&#96;finding a needle in a haystack.â€™â€™ To address this issue, we introduce a semantics-driven search framework that reformulates keyframe selection under the paradigm of Visual Semantic-Logical Search. Specifically, we systematically define four fundamental logical dependencies: 1) spatial co-occurrence, 2) temporal proximity, 3) attribute dependency, and 4) causal order. These relations dynamically update frame sampling distributions through an iterative refinement process, enabling context-aware identification of semantically critical frames tailored to specific query requirements. Our method establishes new SOTA performance on the manually annotated benchmark in key-frame selection metrics. Furthermore, when applied to downstream video question-answering tasks, the proposed approach demonstrates the best performance gains over existing methods on LongVideoBench and Video-MME, validating its effectiveness in bridging the logical gap between textual queries and visual-temporal reasoning. The code will be publicly available. </p>
<blockquote>
<p>ç†è§£é•¿è§†é¢‘å†…å®¹æ˜¯ä¸€é¡¹å¤æ‚çš„ä»»åŠ¡ï¼Œé€šå¸¸ä¾èµ–äºå¯†é›†é‡‡æ ·çš„å¸§å­—å¹•æˆ–ç«¯åˆ°ç«¯ç‰¹å¾é€‰æ‹©å™¨ï¼Œç„¶è€Œè¿™äº›æŠ€æœ¯é€šå¸¸å¿½ç•¥äº†æ–‡æœ¬æŸ¥è¯¢å’Œè§†è§‰å…ƒç´ ä¹‹é—´çš„é€»è¾‘å…³ç³»ã€‚å®é™…ä¸Šï¼Œè®¡ç®—çº¦æŸéœ€è¦è¿›è¡Œç²—ç•¥çš„å¸§å­é‡‡æ ·ï¼Œè¿™ç±»ä¼¼äºâ€œåœ¨ç¨»è‰ä¸­å¯»æ‰¾é’ˆâ€çš„æŒ‘æˆ˜ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ä¸ªè¯­ä¹‰é©±åŠ¨æœç´¢æ¡†æ¶ï¼Œè¯¥æ¡†æ¶åœ¨è§†è§‰è¯­ä¹‰é€»è¾‘æœç´¢çš„èŒƒå¼ä¸‹é‡æ–°åˆ¶å®šå…³é”®å¸§é€‰æ‹©ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬ç³»ç»Ÿåœ°å®šä¹‰äº†å››ç§åŸºæœ¬é€»è¾‘ä¾èµ–å…³ç³»ï¼š1ï¼‰ç©ºé—´å…±ç°ï¼Œ2ï¼‰æ—¶é—´é‚»è¿‘ï¼Œ3ï¼‰å±æ€§ä¾èµ–ï¼Œ4ï¼‰å› æœé¡ºåºã€‚è¿™äº›å…³ç³»é€šè¿‡è¿­ä»£ä¼˜åŒ–è¿‡ç¨‹åŠ¨æ€æ›´æ–°å¸§é‡‡æ ·åˆ†å¸ƒï¼Œä½¿ä¸Šä¸‹æ–‡æ„ŸçŸ¥çš„è¯­ä¹‰å…³é”®å¸§è¯†åˆ«èƒ½å¤Ÿé’ˆå¯¹ç‰¹å®šæŸ¥è¯¢è¦æ±‚è¿›è¡Œå®šåˆ¶ã€‚æˆ‘ä»¬çš„æ–¹æ³•åœ¨å…³é”®å¸§é€‰æ‹©æŒ‡æ ‡çš„æ‰‹åŠ¨æ³¨é‡ŠåŸºå‡†æµ‹è¯•ä¸Šå»ºç«‹äº†æ–°çš„æœ€ä½³æ€§èƒ½ã€‚æ­¤å¤–ï¼Œå½“åº”ç”¨äºä¸‹æ¸¸è§†é¢‘é—®ç­”ä»»åŠ¡æ—¶ï¼Œæ‰€æå‡ºçš„æ–¹æ³•åœ¨LongVideoBenchå’ŒVideo-MMEä¸Šçš„æ€§èƒ½è¶…è¿‡äº†ç°æœ‰æ–¹æ³•ï¼ŒéªŒè¯äº†å…¶åœ¨å¼¥åˆæ–‡æœ¬æŸ¥è¯¢å’Œè§†è§‰æ—¶é—´æ¨ç†ä¹‹é—´çš„é€»è¾‘å·®è·æ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚ä»£ç å°†å…¬å¼€å¯ç”¨ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.13139v1">PDF</a> 18 pages, under review</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºè¯­ä¹‰é©±åŠ¨çš„æœç´¢æ¡†æ¶ï¼Œç”¨äºæ”¹è¿›é•¿è§†é¢‘å†…å®¹ç†è§£ä¸­çš„å…³é”®å¸§é€‰æ‹©é—®é¢˜ã€‚è¯¥æ¡†æ¶é€šè¿‡å®šä¹‰å››ç§åŸºæœ¬é€»è¾‘ä¾èµ–å…³ç³»ï¼ŒåŒ…æ‹¬ç©ºé—´å…±ç°ã€æ—¶é—´é‚»è¿‘ã€å±æ€§ä¾èµ–å’Œå› æœé¡ºåºï¼Œæ¥åŠ¨æ€æ›´æ–°å¸§é‡‡æ ·åˆ†å¸ƒï¼Œä»è€Œå®ç°é’ˆå¯¹ç‰¹å®šæŸ¥è¯¢è¦æ±‚çš„ä¸Šä¸‹æ–‡æ„ŸçŸ¥è¯­ä¹‰å…³é”®å¸§è¯†åˆ«ã€‚è¯¥æ–¹æ³•åœ¨å…³é”®å¸§é€‰æ‹©æŒ‡æ ‡ä¸Šçš„æ€§èƒ½è¾¾åˆ°äº†æ–°çš„å…ˆè¿›æ°´å¹³ï¼Œå¹¶åœ¨è§†é¢‘é—®ç­”ç­‰ä¸‹æ¸¸ä»»åŠ¡ä¸­æ˜¾ç¤ºå‡ºæœ€ä½³çš„æ€§èƒ½æå‡ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æå‡ºäº†ä¸€ç§è¯­ä¹‰é©±åŠ¨çš„æœç´¢æ¡†æ¶ï¼Œç”¨äºæ”¹è¿›é•¿è§†é¢‘å†…å®¹ç†è§£ä¸­çš„å…³é”®å¸§é€‰æ‹©ã€‚</li>
<li>å®šä¹‰äº†å››ç§åŸºæœ¬é€»è¾‘ä¾èµ–å…³ç³»ï¼šç©ºé—´å…±ç°ã€æ—¶é—´é‚»è¿‘ã€å±æ€§ä¾èµ–å’Œå› æœé¡ºåºã€‚</li>
<li>é€šè¿‡è¿­ä»£ä¼˜åŒ–è¿‡ç¨‹ï¼Œè¿™äº›é€»è¾‘ä¾èµ–å…³ç³»èƒ½å¤ŸåŠ¨æ€æ›´æ–°å¸§é‡‡æ ·åˆ†å¸ƒã€‚</li>
<li>è¯¥æ–¹æ³•å®ç°äº†ä¸Šä¸‹æ–‡æ„ŸçŸ¥çš„è¯­ä¹‰å…³é”®å¸§è¯†åˆ«ï¼Œé€‚åº”äºç‰¹å®šæŸ¥è¯¢è¦æ±‚ã€‚</li>
<li>åœ¨å…³é”®å¸§é€‰æ‹©æŒ‡æ ‡ä¸Šè¾¾åˆ°äº†æ–°çš„å…ˆè¿›æ°´å¹³ã€‚</li>
<li>åœ¨è§†é¢‘é—®ç­”ç­‰ä¸‹æ¸¸ä»»åŠ¡ä¸­ï¼Œè¯¥æ–¹æ³•æ˜¾ç¤ºå‡ºæœ€ä½³æ€§èƒ½æå‡ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.13139">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-66e1c11349c0ba136a059bfbb58a8231.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c55efc44c170919f0bd05a539dd6b61b.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-fa440d4624264adf46a56330b1c3dc39.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-0c2a1788fe2af183e8905d1e13f8d411.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-b79d0aa4e1591dd5dca5279aa166860a.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="AdaReTaKe-Adaptive-Redundancy-Reduction-to-Perceive-Longer-for-Video-language-Understanding"><a href="#AdaReTaKe-Adaptive-Redundancy-Reduction-to-Perceive-Longer-for-Video-language-Understanding" class="headerlink" title="AdaReTaKe: Adaptive Redundancy Reduction to Perceive Longer for   Video-language Understanding"></a>AdaReTaKe: Adaptive Redundancy Reduction to Perceive Longer for   Video-language Understanding</h2><p><strong>Authors:Xiao Wang, Qingyi Si, Jianlong Wu, Shiyu Zhu, Li Cao, Liqiang Nie</strong></p>
<p>Multimodal Large Language Models (MLLMs) have revolutionized video understanding, yet are still limited by context length when processing long videos. Recent methods compress videos by leveraging visual redundancy uniformly, yielding promising results. Nevertheless, our quantitative analysis shows that redundancy varies significantly across time and model layers, necessitating a more flexible compression strategy. We propose AdaReTaKe, a training-free method that flexibly reduces visual redundancy by allocating compression ratios among time and layers with theoretical guarantees. Integrated into state-of-the-art MLLMs, AdaReTaKe improves processing capacity from 256 to 2048 frames while preserving critical information. Experiments on VideoMME, MLVU, LongVideoBench, and LVBench datasets demonstrate that AdaReTaKe outperforms existing methods by 2.3% and 2.8% for 7B and 72B models, respectively, with even greater improvements of 5.9% and 6.0% on the longest LVBench. Our code is available at <a target="_blank" rel="noopener" href="https://github.com/SCZwangxiao/video-FlexReduc.git">https://github.com/SCZwangxiao/video-FlexReduc.git</a>. </p>
<blockquote>
<p>å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰å·²ç»å½»åº•æ”¹å˜äº†è§†é¢‘ç†è§£çš„æ–¹å¼ï¼Œä½†åœ¨å¤„ç†é•¿è§†é¢‘æ—¶ä»å—åˆ°ä¸Šä¸‹æ–‡é•¿åº¦çš„é™åˆ¶ã€‚æœ€è¿‘çš„æ–¹æ³•é€šè¿‡ç»Ÿä¸€åˆ©ç”¨è§†è§‰å†—ä½™æ¥å‹ç¼©è§†é¢‘ï¼Œå–å¾—äº†ä»¤äººé¼“èˆçš„ç»“æœã€‚ç„¶è€Œï¼Œæˆ‘ä»¬çš„å®šé‡åˆ†æè¡¨æ˜ï¼Œå†—ä½™æ€§åœ¨æ—¶é—´å’Œæ¨¡å‹å±‚ä¹‹é—´æœ‰å¾ˆå¤§çš„å˜åŒ–ï¼Œå› æ­¤éœ€è¦æ›´çµæ´»çš„å‹ç¼©ç­–ç•¥ã€‚æˆ‘ä»¬æå‡ºäº†AdaReTaKeï¼Œè¿™æ˜¯ä¸€ç§æ— éœ€è®­ç»ƒçš„æ–¹æ³•ï¼Œå®ƒå¯ä»¥é€šè¿‡åœ¨æ—¶é—´å’Œå±‚ä¹‹é—´åˆ†é…å‹ç¼©æ¯”æ¥çµæ´»åœ°å‡å°‘è§†è§‰å†—ä½™æ€§ï¼Œå¹¶æœ‰ç†è®ºä¿è¯ã€‚å°†AdaReTaKeé›†æˆåˆ°æœ€æ–°MLLMsä¸­ï¼Œå¯ä»¥åœ¨ä¿æŒå…³é”®ä¿¡æ¯çš„åŒæ—¶ï¼Œå°†å¤„ç†å®¹é‡ä»256å¸§æé«˜åˆ°2048å¸§ã€‚åœ¨VideoMMEã€MLVUã€LongVideoBenchå’ŒLVBenchæ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒAdaReTaKeä¼˜äºç°æœ‰æ–¹æ³•ï¼Œå¯¹äº7Bå’Œ72Bæ¨¡å‹çš„æ€§èƒ½åˆ†åˆ«æé«˜äº†2.3%å’Œ2.8%ï¼Œåœ¨æœ€é•¿LVBenchä¸Šçš„æ€§èƒ½ç”šè‡³åˆ†åˆ«æé«˜äº†5.9%å’Œ6.0%ã€‚æˆ‘ä»¬çš„ä»£ç å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/SCZwangxiao/video-FlexReduc.git%E4%B8%8A%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/SCZwangxiao/video-FlexReduc.gitä¸Šæ‰¾åˆ°ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.12559v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æ–‡æœ¬æŒ‡å‡ºå¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰åœ¨è§†é¢‘ç†è§£é¢†åŸŸå…·æœ‰é©å‘½æ€§ä½œç”¨ï¼Œä½†åœ¨å¤„ç†é•¿è§†é¢‘æ—¶å—é™äºä¸Šä¸‹æ–‡é•¿åº¦ã€‚æœ€è¿‘çš„æ–¹æ³•é€šè¿‡åˆ©ç”¨è§†è§‰å†—ä½™è¿›è¡Œè§†é¢‘å‹ç¼©ï¼Œä½†ä»å­˜åœ¨æ˜¾è‘—çš„æ—¶é—´ä¸æ¨¡å‹å±‚é—´å†—ä½™å˜åŒ–ï¼Œéœ€è¦æ›´çµæ´»çš„å‹ç¼©ç­–ç•¥ã€‚æå‡ºä¸€ç§åä¸ºAdaReTaKeçš„è®­ç»ƒå¤–æ–¹æ³•ï¼Œå®ƒé€šè¿‡åˆ†é…æ—¶é—´ä¸å±‚é—´çš„å‹ç¼©æ¯”ç‡æ¥çµæ´»å‡å°‘è§†è§‰å†—ä½™ï¼Œå¹¶å…·æœ‰ç†è®ºä¿è¯ã€‚é›†æˆåˆ°æœ€å…ˆè¿›çš„MLLMsä¸­ï¼ŒAdaReTaKeå°†å¤„ç†å®¹é‡ä»256å¸§æé«˜åˆ°2048å¸§ï¼ŒåŒæ—¶ä¿ç•™å…³é”®ä¿¡æ¯ã€‚åœ¨VideoMMEã€MLVUã€LongVideoBenchå’ŒLVBenchæ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒAdaReTaKeåœ¨æ•ˆç‡å’Œæ€§èƒ½ä¸Šå‡ä¼˜äºç°æœ‰æ–¹æ³•ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰åœ¨è§†é¢‘ç†è§£ä¸Šè¡¨ç°å‡ºå¼ºå¤§èƒ½åŠ›ï¼Œä½†å¤„ç†é•¿è§†é¢‘æ—¶å—åˆ°ä¸Šä¸‹æ–‡é•¿åº¦çš„é™åˆ¶ã€‚</li>
<li>ç°æœ‰è§†é¢‘å‹ç¼©æ–¹æ³•è™½ç„¶èƒ½åˆ©ç”¨è§†è§‰å†—ä½™è¿›è¡Œå‹ç¼©ï¼Œä½†æœªèƒ½å……åˆ†é€‚åº”æ—¶é—´ä¸æ¨¡å‹å±‚é—´å†—ä½™çš„å˜åŒ–ã€‚</li>
<li>AdaReTaKeæ˜¯ä¸€ç§è®­ç»ƒå¤–æ–¹æ³•ï¼Œèƒ½å¤Ÿçµæ´»å‡å°‘è§†è§‰å†—ä½™ï¼Œé€šè¿‡åˆ†é…æ—¶é—´ä¸å±‚é—´çš„å‹ç¼©æ¯”ç‡æ¥ä¼˜åŒ–æ€§èƒ½ã€‚</li>
<li>AdaReTaKeæ˜¾è‘—æé«˜äº†è§†é¢‘å¤„ç†å®¹é‡ï¼Œä»256å¸§æå‡è‡³2048å¸§ï¼ŒåŒæ—¶ä¿ç•™å…³é”®ä¿¡æ¯ã€‚</li>
<li>AdaReTaKeåœ¨å¤šä¸ªæ•°æ®é›†ä¸Šçš„å®éªŒç»“æœè¡¨æ˜å…¶æ€§èƒ½ä¼˜äºç°æœ‰æ–¹æ³•ã€‚</li>
<li>AdaReTaKeæ–¹æ³•å…·æœ‰ç†è®ºä¿è¯ï¼Œç¨³å®šæ€§ä¸å¯é æ€§è¾ƒé«˜ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.12559">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-0e73039b93c99c8327607be9dbd7ff6d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c8ae23442064f76d012aac55b4e228a2.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-8c1fa5c86bd87a8d44fbee6a09611d04.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-95d6ee139bea08f22920d6fd366a249a.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="Vamba-Understanding-Hour-Long-Videos-with-Hybrid-Mamba-Transformers"><a href="#Vamba-Understanding-Hour-Long-Videos-with-Hybrid-Mamba-Transformers" class="headerlink" title="Vamba: Understanding Hour-Long Videos with Hybrid Mamba-Transformers"></a>Vamba: Understanding Hour-Long Videos with Hybrid Mamba-Transformers</h2><p><strong>Authors:Weiming Ren, Wentao Ma, Huan Yang, Cong Wei, Ge Zhang, Wenhu Chen</strong></p>
<p>State-of-the-art transformer-based large multimodal models (LMMs) struggle to handle hour-long video inputs due to the quadratic complexity of the causal self-attention operations, leading to high computational costs during training and inference. Existing token compression-based methods reduce the number of video tokens but often incur information loss and remain inefficient for extremely long sequences. In this paper, we explore an orthogonal direction to build a hybrid Mamba-Transformer model (VAMBA) that employs Mamba-2 blocks to encode video tokens with linear complexity. Without any token reduction, VAMBA can encode more than 1024 frames (640$\times$360) on a single GPU, while transformer-based models can only encode 256 frames. On long video input, VAMBA achieves at least 50% reduction in GPU memory usage during training and inference, and nearly doubles the speed per training step compared to transformer-based LMMs. Our experimental results demonstrate that VAMBA improves accuracy by 4.3% on the challenging hour-long video understanding benchmark LVBench over prior efficient video LMMs, and maintains strong performance on a broad spectrum of long and short video understanding tasks. </p>
<blockquote>
<p>æœ€å…ˆè¿›çš„åŸºäºtransformerçš„å¤§å‹å¤šæ¨¡æ€æ¨¡å‹ï¼ˆLMMsï¼‰åœ¨å¤„ç†é•¿è¾¾æ•°å°æ—¶çš„è§†é¢‘è¾“å…¥æ—¶é¢ä¸´å›°éš¾ï¼ŒåŸå› åœ¨äºå› æœè‡ªæ³¨æ„åŠ›æ“ä½œçš„äºŒæ¬¡å¤æ‚æ€§ï¼Œå¯¼è‡´è®­ç»ƒå’Œæ¨ç†è¿‡ç¨‹ä¸­çš„è®¡ç®—æˆæœ¬é«˜æ˜‚ã€‚ç°æœ‰çš„åŸºäºä»¤ç‰Œå‹ç¼©çš„æ–¹æ³•å‡å°‘äº†è§†é¢‘ä»¤ç‰Œçš„æ•°é‡ï¼Œä½†å¾€å¾€ä¼šé€ æˆä¿¡æ¯ä¸¢å¤±ï¼Œå¯¹äºæé•¿çš„åºåˆ—ä»ç„¶æ•ˆç‡ä½ä¸‹ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æ¢ç´¢äº†ä¸€ä¸ªä¸å½“å‰æ–¹æ³•ä¸åŒçš„æ–¹å‘ï¼Œå³æ„å»ºæ··åˆMamba-Transformeræ¨¡å‹ï¼ˆVAMBAï¼‰ï¼Œè¯¥æ¨¡å‹é‡‡ç”¨Mamba-2å—ä»¥çº¿æ€§å¤æ‚åº¦ç¼–ç è§†é¢‘ä»¤ç‰Œã€‚æ— éœ€å‡å°‘ä»¤ç‰Œï¼ŒVAMBAå¯ä»¥åœ¨å•ä¸ªGPUä¸Šç¼–ç è¶…è¿‡1024å¸§ï¼ˆ640Ã—360ï¼‰ï¼Œè€ŒåŸºäºtransformerçš„æ¨¡å‹åªèƒ½ç¼–ç 256å¸§ã€‚å¯¹äºé•¿è§†é¢‘è¾“å…¥ï¼ŒVAMBAåœ¨è®­ç»ƒå’Œæ¨ç†æœŸé—´å®ç°äº†GPUå†…å­˜ä½¿ç”¨è‡³å°‘å‡å°‘50%ï¼Œå¹¶ä¸”ä¸åŸºäºtransformerçš„LMMç›¸æ¯”ï¼Œæ¯æ­¥è®­ç»ƒé€Ÿåº¦å‡ ä¹ç¿»å€ã€‚æˆ‘ä»¬çš„å®éªŒç»“æœè¡¨æ˜ï¼Œåœ¨å…·æœ‰æŒ‘æˆ˜æ€§çš„é•¿è¾¾ä¸€å°æ—¶çš„è§†é¢‘ç†è§£åŸºå‡†æµ‹è¯•LVBenchä¸Šï¼ŒVAMBAç›¸è¾ƒäºå…ˆå‰çš„æœ‰æ•ˆè§†é¢‘LMMæé«˜äº†4.3%çš„å‡†ç¡®ç‡ï¼Œå¹¶åœ¨å¹¿æ³›çš„é•¿æœŸå’ŒçŸ­æœŸè§†é¢‘ç†è§£ä»»åŠ¡ä¸­ä¿æŒäº†å¼ºåŠ²çš„è¡¨ç°ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.11579v1">PDF</a> Project Page: <a target="_blank" rel="noopener" href="https://tiger-ai-lab.github.io/Vamba/">https://tiger-ai-lab.github.io/Vamba/</a></p>
<p><strong>Summary</strong><br>è§†é¢‘ç†è§£é¢†åŸŸçš„å¤§å‹å¤šæ¨¡æ€æ¨¡å‹åœ¨å¤„ç†é•¿è¾¾ä¸€å°æ—¶çš„è§†é¢‘è¾“å…¥æ—¶é¢ä¸´è®¡ç®—æˆæœ¬é«˜çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•è¯•å›¾é€šè¿‡å‡å°‘è§†é¢‘ä»¤ç‰Œæ•°é‡æ¥è§£å†³è¿™ä¸€é—®é¢˜ï¼Œä½†è¿™æ ·åšä¼šå¯¼è‡´ä¿¡æ¯æŸå¤±ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§æ··åˆMamba-Transformeræ¨¡å‹ï¼ˆVAMBAï¼‰ï¼Œé‡‡ç”¨å…·æœ‰çº¿æ€§å¤æ‚åº¦çš„Mamba-2å—è¿›è¡Œè§†é¢‘ä»¤ç‰Œç¼–ç ï¼Œæ— éœ€å‡å°‘ä»¤ç‰Œæ•°é‡å³å¯åœ¨å•ä¸ªGPUä¸Šç¼–ç è¶…è¿‡1024å¸§ï¼ˆ640Ã—360ï¼‰ã€‚ä¸åŸºäºTransformerçš„æ¨¡å‹ç›¸æ¯”ï¼ŒVAMBAåœ¨è®­ç»ƒå’Œæ¨ç†æœŸé—´çš„GPUå†…å­˜ä½¿ç”¨ç‡é™ä½äº†è‡³å°‘50%ï¼Œä¸”è®­ç»ƒæ­¥éª¤é€Ÿåº¦æé«˜äº†è¿‘ä¸€å€ã€‚å®éªŒç»“æœè¯æ˜äº†VAMBAåœ¨æŒ‘æˆ˜æ€§çš„é•¿è¾¾ä¸€å°æ—¶è§†é¢‘ç†è§£åŸºå‡†æµ‹è¯•LVBenchä¸Šçš„å‡†ç¡®ç‡æé«˜äº†4.3%ï¼Œå¹¶åœ¨å¹¿æ³›çš„é•¿çŸ­è§†é¢‘ç†è§£ä»»åŠ¡ä¸Šä¿æŒäº†å‡ºè‰²çš„æ€§èƒ½ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤§å‹å¤šæ¨¡æ€æ¨¡å‹å¤„ç†é•¿è§†é¢‘æ—¶é¢ä¸´è®¡ç®—æˆæœ¬é«˜çš„é—®é¢˜ã€‚</li>
<li>ç°æœ‰æ–¹æ³•é€šè¿‡å‡å°‘è§†é¢‘ä»¤ç‰Œæ•°é‡æ¥é™ä½è®¡ç®—æˆæœ¬ï¼Œä½†ä¼šå¯¼è‡´ä¿¡æ¯æŸå¤±ã€‚</li>
<li>VAMBAæ¨¡å‹é‡‡ç”¨Mamba-2å—è¿›è¡Œè§†é¢‘ä»¤ç‰Œç¼–ç ï¼Œå…·æœ‰çº¿æ€§å¤æ‚åº¦ï¼Œæ— éœ€å‡å°‘ä»¤ç‰Œæ•°é‡ã€‚</li>
<li>VAMBAåœ¨å•ä¸ªGPUä¸Šå¯ç¼–ç æ›´å¤šçš„è§†é¢‘å¸§ï¼Œç›¸æ¯”åŸºäºTransformerçš„æ¨¡å‹æœ‰ä¼˜åŠ¿ã€‚</li>
<li>VAMBAé™ä½äº†GPUå†…å­˜ä½¿ç”¨ç‡å¹¶æé«˜äº†è®­ç»ƒæ­¥éª¤é€Ÿåº¦ã€‚</li>
<li>VAMBAåœ¨é•¿è¾¾ä¸€å°æ—¶çš„è§†é¢‘ç†è§£åŸºå‡†æµ‹è¯•ä¸Šæé«˜äº†å‡†ç¡®ç‡ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.11579">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-bc135ad0d0def72cacde9f8a014dd998.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-4e2152a137954001c6744cf4db5e8289.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-595bec5bb2114a3c035d59ce5c35fec1.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-b5d71a9d9b899f23cfe553d1f61102fc.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-7f105481f2595ea34b0c32c660107b29.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="Watch-and-Learn-Leveraging-Expert-Knowledge-and-Language-for-Surgical-Video-Understanding"><a href="#Watch-and-Learn-Leveraging-Expert-Knowledge-and-Language-for-Surgical-Video-Understanding" class="headerlink" title="Watch and Learn: Leveraging Expert Knowledge and Language for Surgical   Video Understanding"></a>Watch and Learn: Leveraging Expert Knowledge and Language for Surgical   Video Understanding</h2><p><strong>Authors:David Gastager, Ghazal Ghazaei, Constantin Patsch</strong></p>
<p>Automated surgical workflow analysis is crucial for education, research, and clinical decision-making, but the lack of annotated datasets hinders the development of accurate and comprehensive workflow analysis solutions. We introduce a novel approach for addressing the sparsity and heterogeneity of annotated training data inspired by the human learning procedure of watching experts and understanding their explanations. Our method leverages a video-language model trained on alignment, denoising, and generative tasks to learn short-term spatio-temporal and multimodal representations. A task-specific temporal model is then used to capture relationships across entire videos. To achieve comprehensive video-language understanding in the surgical domain, we introduce a data collection and filtering strategy to construct a large-scale pretraining dataset from educational YouTube videos. We then utilize parameter-efficient fine-tuning by projecting downstream task annotations from publicly available surgical datasets into the language domain. Extensive experiments in two surgical domains demonstrate the effectiveness of our approach, with performance improvements of up to 7% in phase segmentation tasks, 8% in zero-shot phase segmentation, and comparable capabilities to fully-supervised models in few-shot settings. Harnessing our modelâ€™s capabilities for long-range temporal localization and text generation, we present the first comprehensive solution for dense video captioning (DVC) of surgical videos, addressing this task despite the absence of existing DVC datasets in the surgical domain. We introduce a novel approach to surgical workflow understanding that leverages video-language pretraining, large-scale video pretraining, and optimized fine-tuning. Our method improves performance over state-of-the-art techniques and enables new downstream tasks for surgical video understanding. </p>
<blockquote>
<p>è‡ªåŠ¨åŒ–æ‰‹æœ¯å·¥ä½œæµç¨‹åˆ†æå¯¹åŒ»ç–—æ•™è‚²ã€ç ”ç©¶å’Œä¸´åºŠå†³ç­–è‡³å…³é‡è¦ï¼Œä½†ç¼ºä¹æ ‡æ³¨æ•°æ®é›†é˜»ç¢äº†å‡†ç¡®ã€å…¨é¢çš„å·¥ä½œæµç¨‹åˆ†æè§£å†³æ–¹æ¡ˆçš„å‘å±•ã€‚æˆ‘ä»¬å¼•å…¥äº†ä¸€ç§æ–°çš„æ–¹æ³•æ¥è§£å†³æ ‡æ³¨è®­ç»ƒæ•°æ®çš„ç¨€ç¼ºå’Œå¼‚è´¨æ€§ï¼Œè¯¥æ–¹æ³•å—åˆ°äººç±»è§‚å¯Ÿä¸“å®¶å¹¶ç†è§£å…¶è§£é‡Šçš„å­¦ä¹ è¿‡ç¨‹çš„å¯å‘ã€‚æˆ‘ä»¬çš„æ–¹æ³•åˆ©ç”¨åœ¨æ’åˆ—ã€å»å™ªå’Œç”Ÿæˆä»»åŠ¡ä¸Šè®­ç»ƒçš„è§†å¬è¯­è¨€æ¨¡å‹æ¥å­¦ä¹ çŸ­æœŸçš„æ—¶ç©ºå’Œå¤šæ¨¡æ€è¡¨ç¤ºã€‚ç„¶åï¼Œä½¿ç”¨ç‰¹å®šä»»åŠ¡çš„æ—¶åºæ¨¡å‹æ¥æ•æ‰æ•´ä¸ªè§†é¢‘çš„å…³ç³»ã€‚ä¸ºäº†å®ç°æ‰‹æœ¯é¢†åŸŸå…¨é¢çš„è§†å¬ç†è§£ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§æ•°æ®æ”¶é›†å’Œè¿‡æ»¤ç­–ç•¥ï¼Œä»æ•™è‚²æ€§è´¨çš„YouTubeè§†é¢‘ä¸­æ„å»ºå¤§è§„æ¨¡é¢„è®­ç»ƒæ•°æ®é›†ã€‚ç„¶åï¼Œæˆ‘ä»¬é€šè¿‡å°†å…¬å¼€å¯ç”¨çš„æ‰‹æœ¯æ•°æ®é›†çš„ä¸‹æ¸¸ä»»åŠ¡æ³¨é‡ŠæŠ•å½±åˆ°è¯­è¨€é¢†åŸŸï¼Œå®ç°äº†å‚æ•°çš„ç²¾ç»†è°ƒæ•´ã€‚åœ¨ä¸¤ä¸ªæ‰‹æœ¯é¢†åŸŸçš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•éå¸¸æœ‰æ•ˆï¼Œåœ¨é˜¶æ®µåˆ†å‰²ä»»åŠ¡ä¸­çš„æ€§èƒ½æé«˜äº†é«˜è¾¾7%ï¼Œåœ¨é›¶æ ·æœ¬é˜¶æ®µåˆ†å‰²ä¸­çš„æ€§èƒ½æé«˜äº†8%ï¼Œå¹¶ä¸”åœ¨å°‘é‡æ ·æœ¬çš„æƒ…å†µä¸‹ä¸å®Œå…¨ç›‘ç£çš„æ¨¡å‹ç›¸æ¯”å…·æœ‰ç›¸å½“çš„èƒ½åŠ›ã€‚åˆ©ç”¨æˆ‘ä»¬çš„æ¨¡å‹è¿›è¡Œè¿œç¨‹æ—¶åºå®šä½å’Œæ–‡æœ¬ç”Ÿæˆçš„èƒ½åŠ›ï¼Œæˆ‘ä»¬é¦–æ¬¡ä¸ºæ‰‹æœ¯è§†é¢‘æä¾›äº†å¯†é›†è§†é¢‘å­—å¹•ï¼ˆDVCï¼‰çš„å…¨é¢è§£å†³æ–¹æ¡ˆï¼Œå°½ç®¡æ‰‹æœ¯é¢†åŸŸç¼ºä¹ç°æœ‰çš„DVCæ•°æ®é›†ï¼Œæˆ‘ä»¬ä»è§£å†³äº†æ­¤ä»»åŠ¡ã€‚æˆ‘ä»¬å¼•å…¥äº†ä¸€ç§æ–°çš„æ‰‹æœ¯å·¥ä½œæµç¨‹ç†è§£æ–¹æ³•ï¼Œè¯¥æ–¹æ³•åˆ©ç”¨è§†å¬è¯­è¨€é¢„è®­ç»ƒã€å¤§è§„æ¨¡è§†é¢‘é¢„è®­ç»ƒå’Œä¼˜åŒ–å¾®è°ƒã€‚æˆ‘ä»¬çš„æ–¹æ³•åœ¨æœ€æ–°æŠ€æœ¯çš„åŸºç¡€ä¸Šæé«˜äº†æ€§èƒ½ï¼Œå¹¶ä¸ºæ‰‹æœ¯è§†é¢‘ç†è§£å¯ç”¨äº†æ–°çš„ä¸‹æ¸¸ä»»åŠ¡ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.11392v1">PDF</a> 14 pages main manuscript with 3 figures; 6 pages supplementary   material with 3 figures. To be presented at International Conference on   Information Processing in Computer-Assisted Interventions (IPCAI 2025). To be   published in International Journal of Computer Assisted Radiology and Surgery   (IJCARS)</p>
<p><strong>æ‘˜è¦</strong></p>
<p>æœ¬æ–‡ä¸»è¦æ¢è®¨æ‰‹æœ¯å·¥ä½œæµè‡ªåŠ¨åŒ–åˆ†æåœ¨æ•™è‚²ã€ç ”ç©¶å’Œä¸´åºŠå†³ç­–ä¸­çš„é‡è¦æ€§ã€‚ä¸ºè§£å†³æ ‡æ³¨æ•°æ®é›†ç¨€ç¼ºå’Œå¤šæ ·æ€§é—®é¢˜ï¼Œæå‡ºä¸€ç§æ–°å‹è§£å†³æ–¹æ¡ˆã€‚è¯¥æ–¹æ³•åŸºäºäººç±»è§‚çœ‹ä¸“å®¶å¹¶ç†è§£å…¶è§£é‡Šçš„å­¦ä¹ è¿‡ç¨‹ï¼Œåˆ©ç”¨è§†é¢‘è¯­è¨€æ¨¡å‹è¿›è¡Œè®­ç»ƒï¼Œå­¦ä¹ çŸ­æœŸæ—¶ç©ºå’Œå¤šæ¨¡æ€è¡¨ç¤ºã€‚é€šè¿‡ç‰¹å®šä»»åŠ¡çš„æ—¶é—´æ¨¡å‹æ•æ‰æ•´ä¸ªè§†é¢‘çš„å…³è”ã€‚ä¸ºåœ¨æ‰‹æœ¯é¢†åŸŸå®ç°å…¨é¢çš„è§†é¢‘è¯­è¨€ç†è§£ï¼Œä»æ•™è‚²YouTubeè§†é¢‘ä¸­æ„å»ºå¤§è§„æ¨¡é¢„è®­ç»ƒæ•°æ®é›†ã€‚åˆ©ç”¨ä¸‹æ¸¸ä»»åŠ¡æ ‡æ³¨å…¬å¼€æ‰‹æœ¯æ•°æ®é›†ï¼Œå°†å…¶æŠ•å½±åˆ°è¯­è¨€é¢†åŸŸè¿›è¡Œå¾®è°ƒä¼˜åŒ–ã€‚å®éªŒè¯æ˜è¯¥æ–¹æ³•æœ‰æ•ˆï¼Œé˜¶æ®µåˆ†å‰²ä»»åŠ¡æ€§èƒ½æå‡é«˜è¾¾7%ï¼Œé›¶é˜¶æ®µåˆ†å‰²æå‡8%ï¼Œåœ¨å°‘æ ·æœ¬è®¾ç½®ä¸­å…·æœ‰ä¸å…¨ç›‘ç£æ¨¡å‹ç›¸å½“çš„å®åŠ›ã€‚å€ŸåŠ©æ¨¡å‹çš„é•¿ç¨‹æ—¶ç©ºå®šä½å’Œæ–‡æœ¬ç”Ÿæˆèƒ½åŠ›ï¼Œæœ¬æ–‡æå‡ºé¦–ä¸ªé’ˆå¯¹æ‰‹æœ¯è§†é¢‘çš„å¯†é›†è§†é¢‘å­—å¹•ï¼ˆDVCï¼‰å…¨é¢è§£å†³æ–¹æ¡ˆï¼Œè§£å†³æ‰‹æœ¯é¢†åŸŸç¼ºä¹ç°æœ‰DVCæ•°æ®é›†çš„é—®é¢˜ã€‚æœ¬æ–‡æå‡ºä¸€ç§åŸºäºè§†é¢‘è¯­è¨€é¢„è®­ç»ƒã€å¤§è§„æ¨¡è§†é¢‘é¢„è®­ç»ƒå’Œä¼˜åŒ–å¾®è°ƒçš„æ–°å‹æ‰‹æœ¯å·¥ä½œæµç¨‹ç†è§£æ–¹æ³•ã€‚è¯¥æ–¹æ³•æé«˜äº†æ€§èƒ½ï¼Œå¹¶ä¸ºæ‰‹æœ¯è§†é¢‘ç†è§£å¼€å¯äº†æ–°çš„ä¸‹æ¸¸ä»»åŠ¡ã€‚</p>
<p><strong>å…³é”®è§è§£</strong></p>
<ol>
<li>è‡ªåŠ¨åŒ–æ‰‹æœ¯å·¥ä½œæµåˆ†æåœ¨æ•™è‚²ã€ç ”ç©¶å’Œä¸´åºŠå†³ç­–ä¸­å…·æœ‰é‡è¦æ€§ã€‚</li>
<li>ç¼ºä¹æ ‡æ³¨æ•°æ®é›†é™åˆ¶äº†å‡†ç¡®å’Œå…¨é¢çš„æ‰‹æœ¯å·¥ä½œæµåˆ†æè§£å†³æ–¹æ¡ˆçš„å‘å±•ã€‚</li>
<li>å¼•å…¥ä¸€ç§æ–°å‹æ–¹æ³•ï¼ŒåŸºäºäººç±»å­¦ä¹ è§‚çœ‹ä¸“å®¶å¹¶ç†è§£å…¶è§£é‡Šçš„è¿‡ç¨‹ã€‚</li>
<li>åˆ©ç”¨è§†é¢‘è¯­è¨€æ¨¡å‹è¿›è¡Œè®­ç»ƒï¼Œå­¦ä¹ çŸ­æœŸæ—¶ç©ºå’Œå¤šæ¨¡æ€è¡¨ç¤ºã€‚</li>
<li>é‡‡ç”¨ç‰¹å®šä»»åŠ¡çš„æ—¶é—´æ¨¡å‹æ•æ‰æ•´ä¸ªè§†é¢‘çš„å…³è”ã€‚</li>
<li>æ„å»ºå¤§è§„æ¨¡é¢„è®­ç»ƒæ•°æ®é›†ï¼Œä»æ•™è‚²YouTubeè§†é¢‘ä¸­å®ç°å…¨é¢çš„è§†é¢‘è¯­è¨€ç†è§£ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.11392">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-bae6d8b10389321eb371236d5e57c533.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-6dbe8bf3e031183d7b9eaec63ebb3ac5.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-e54ead2c466b09b370449c728181b6da.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="ReTaKe-Reducing-Temporal-and-Knowledge-Redundancy-for-Long-Video-Understanding"><a href="#ReTaKe-Reducing-Temporal-and-Knowledge-Redundancy-for-Long-Video-Understanding" class="headerlink" title="ReTaKe: Reducing Temporal and Knowledge Redundancy for Long Video   Understanding"></a>ReTaKe: Reducing Temporal and Knowledge Redundancy for Long Video   Understanding</h2><p><strong>Authors:Xiao Wang, Qingyi Si, Jianlong Wu, Shiyu Zhu, Li Cao, Liqiang Nie</strong></p>
<p>Video Large Language Models (VideoLLMs) have made significant strides in video understanding but struggle with long videos due to the limitations of their backbone LLMs. Existing solutions rely on length extrapolation, which is memory-constrained, or visual token compression, which primarily leverages low-level temporal redundancy while overlooking the more effective high-level knowledge redundancy. To address this, we propose $\textbf{ReTaKe}$, a training-free method with two novel modules DPSelect and PivotKV, to jointly reduce both temporal visual redundancy and knowledge redundancy for video compression. To align with the way of human temporal perception, DPSelect identifies keyframes based on inter-frame distance peaks. To leverage LLMsâ€™ learned prior knowledge, PivotKV marks the keyframes as pivots and compress non-pivot frames by pruning low-attention tokens in their KV cache. ReTaKe enables VideoLLMs to process 8 times longer frames (up to 2048), outperforming similar-sized models by 3-5% and even rivaling much larger ones on VideoMME, MLVU, LongVideoBench, and LVBench. Moreover, by overlapping compression operations with prefilling, ReTaKe introduces only ~10% prefilling latency overhead while reducing decoding latency by ~20%. Our code is available at <a target="_blank" rel="noopener" href="https://github.com/SCZwangxiao/video-ReTaKe">https://github.com/SCZwangxiao/video-ReTaKe</a>. </p>
<blockquote>
<p>è§†é¢‘å¤§è¯­è¨€æ¨¡å‹ï¼ˆVideoLLMsï¼‰åœ¨è§†é¢‘ç†è§£æ–¹é¢å–å¾—äº†é‡å¤§è¿›å±•ï¼Œä½†ç”±äºå…¶ä¸»å¹²LLMsçš„å±€é™æ€§ï¼Œåœ¨å¤„ç†é•¿è§†é¢‘æ—¶é¢ä¸´å›°éš¾ã€‚ç°æœ‰è§£å†³æ–¹æ¡ˆä¾èµ–äºå†…å­˜å—é™çš„é•¿åº¦æ‰©å±•æˆ–è§†è§‰ä»¤ç‰Œå‹ç¼©ï¼Œåè€…ä¸»è¦åˆ©ç”¨ä½çº§åˆ«çš„æ—¶åºå†—ä½™è€Œå¿½è§†æ›´æœ‰æ•ˆçš„é«˜çº§çŸ¥è¯†å†—ä½™ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†æ— éœ€è®­ç»ƒçš„ReTaKeæ–¹æ³•ï¼ŒåŒ…å«ä¸¤ä¸ªæ–°é¢–æ¨¡å—DPSelectå’ŒPivotKVï¼Œä»¥è”åˆå‡å°‘æ—¶åºè§†è§‰å†—ä½™å’ŒçŸ¥è¯†å†—ä½™ï¼Œä»è€Œå®ç°è§†é¢‘å‹ç¼©ã€‚ä¸ºäº†ä¸äººç±»çš„æ—¶é—´æ„ŸçŸ¥æ–¹å¼ä¿æŒä¸€è‡´ï¼ŒDPSelectæ ¹æ®å¸§é—´è·ç¦»å³°å€¼è¯†åˆ«å…³é”®å¸§ã€‚ä¸ºäº†åˆ©ç”¨LLMsçš„å…ˆéªŒçŸ¥è¯†ï¼ŒPivotKVå°†å…³é”®å¸§æ ‡è®°ä¸ºæ¢è½´ç‚¹ï¼Œå¹¶é€šè¿‡åˆ é™¤å…¶KVç¼“å­˜ä¸­çš„ä½å…³æ³¨ä»¤ç‰Œæ¥å‹ç¼©éæ¢è½´å¸§ã€‚ReTaKeä½¿VideoLLMsèƒ½å¤Ÿå¤„ç†é•¿è¾¾8å€çš„è§†é¢‘å¸§ï¼ˆæœ€å¤šå¯è¾¾2048å¸§ï¼‰ï¼Œåœ¨VideoMMEã€MLVUã€LongVideoBenchå’ŒLVBenchä¸Šçš„æ€§èƒ½ä¼˜äºåŒç±»æ¨¡å‹3-5%ï¼Œç”šè‡³ä¸æ›´å¤§çš„æ¨¡å‹ä¸ç›¸ä¸Šä¸‹ã€‚æ­¤å¤–ï¼Œé€šè¿‡å‹ç¼©æ“ä½œä¸é¢„å¡«å……çš„é‡å ï¼ŒReTaKeä»…å¼•å…¥äº†çº¦10%çš„é¢„å¡«å……å»¶è¿Ÿå¼€é”€ï¼ŒåŒæ—¶é™ä½äº†çº¦20%çš„è§£ç å»¶è¿Ÿã€‚æˆ‘ä»¬çš„ä»£ç å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/SCZwangxiao/video-ReTaKe%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/SCZwangxiao/video-ReTaKeæ‰¾åˆ°ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.20504v4">PDF</a> Rewrite the methods section. Add more ablation studies and results in   LongVideoBench. Update metadata</p>
<p><strong>Summary</strong></p>
<p>è§†é¢‘å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆVideoLLMsï¼‰åœ¨è§†é¢‘ç†è§£æ–¹é¢å–å¾—äº†æ˜¾è‘—è¿›å±•ï¼Œä½†åœ¨å¤„ç†é•¿è§†é¢‘æ—¶å› æ¨¡å‹æ¶æ„é™åˆ¶è€Œé¢ä¸´æŒ‘æˆ˜ã€‚ç°æœ‰è§£å†³æ–¹æ¡ˆä¸»è¦é€šè¿‡é•¿åº¦æ¨æ–­æˆ–è§†è§‰ä»¤ç‰Œå‹ç¼©æ¥å®ç°ï¼Œä½†å®ƒä»¬å­˜åœ¨è®°å¿†å—é™æˆ–å¿½ç•¥é«˜çº§çŸ¥è¯†å†—ä½™çš„é—®é¢˜ã€‚é’ˆå¯¹æ­¤ï¼Œæˆ‘ä»¬æå‡ºæ— éœ€è®­ç»ƒçš„ReTaKeæ–¹æ³•ï¼ŒåŒ…å«DPSelectå’ŒPivotKVä¸¤ä¸ªæ–°æ¨¡å—ï¼Œæ—¨åœ¨å‡å°‘è§†é¢‘å‹ç¼©ä¸­çš„æ—¶é—´è§†è§‰å†—ä½™å’ŒçŸ¥è¯†å†—ä½™ã€‚ReTaKeé€šè¿‡DPSelectåŸºäºå¸§é—´è·ç¦»å³°å€¼è¯†åˆ«å…³é”®å¸§ï¼Œå¹¶åˆ©ç”¨LLMsçš„å…ˆéªŒçŸ¥è¯†ï¼Œé€šè¿‡PivotKVæ ‡è®°å…³é”®å¸§ä½œä¸ºæ”¯ç‚¹ï¼Œå‹ç¼©éæ”¯ç‚¹å¸§é€šè¿‡åˆ é™¤ä½æ³¨æ„åŠ›ä»¤ç‰Œã€‚ReTaKeä½¿VideoLLMsèƒ½å¤Ÿå¤„ç†é•¿è¾¾å…«å€çš„è§†é¢‘å¸§ï¼ˆè¾¾2048å¸§ï¼‰ï¼Œåœ¨VideoMMEã€MLVUã€LongVideoBenchå’ŒLVBenchä¸Šè¡¨ç°ä¼˜å¼‚ã€‚æ­¤å¤–ï¼Œé€šè¿‡å‹ç¼©æ“ä½œä¸é¢„å¡«å……çš„é‡å ï¼ŒReTaKeä»…å¼•å…¥çº¦10%çš„é¢„å¡«å……å»¶è¿Ÿå¼€é”€ï¼ŒåŒæ—¶å‡å°‘çº¦20%çš„è§£ç å»¶è¿Ÿã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>VideoLLMsåœ¨è§†é¢‘ç†è§£æ–¹é¢å–å¾—äº†æ˜¾è‘—è¿›å±•ï¼Œä½†åœ¨å¤„ç†é•¿è§†é¢‘æ—¶é¢ä¸´æŒ‘æˆ˜ã€‚</li>
<li>ç°æœ‰è§£å†³æ–¹æ¡ˆä¸»è¦ä¾èµ–é•¿åº¦æ¨æ–­å’Œè§†è§‰ä»¤ç‰Œå‹ç¼©ï¼Œä½†å­˜åœ¨è®°å¿†å—é™å’Œå¿½ç•¥é«˜çº§çŸ¥è¯†å†—ä½™çš„é—®é¢˜ã€‚</li>
<li>ReTaKeæ˜¯ä¸€ç§æ— éœ€è®­ç»ƒçš„æ–¹æ³•ï¼Œæ—¨åœ¨å‡å°‘è§†é¢‘å‹ç¼©ä¸­çš„æ—¶é—´è§†è§‰å†—ä½™å’ŒçŸ¥è¯†å†—ä½™ã€‚</li>
<li>ReTaKeé€šè¿‡DPSelectè¯†åˆ«å…³é”®å¸§ï¼Œå¹¶åˆ©ç”¨PivotKVæ¨¡å—åˆ©ç”¨LLMsçš„å…ˆéªŒçŸ¥è¯†ã€‚</li>
<li>ReTaKeä½¿VideoLLMsèƒ½å¤Ÿå¤„ç†æ›´é•¿çš„è§†é¢‘å¸§ï¼Œè¡¨ç°ä¼˜äºåŒç±»æ¨¡å‹ï¼Œç”šè‡³ä¸æ›´å¤§çš„æ¨¡å‹ç›¸å½“ã€‚</li>
<li>ReTaKeé€šè¿‡å‹ç¼©æ“ä½œä¸é¢„å¡«å……çš„é‡å ï¼Œæœ‰æ•ˆç®¡ç†å»¶è¿Ÿå¼€é”€ã€‚</li>
<li>ReTaKeçš„ä»£ç å·²å…¬å¼€å¯ç”¨ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.20504">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-54d12041a1fe4d924396cd90ffbca2b9.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-6db153dfca6177d0c8180bb7801d989d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-8a00103e34a75a19679aa504eb809259.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-9026225b9be41f510d7630003d48ea92.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-60d990fba2e2cecf45f073fa1e6d99b1.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a1cc8bd4295efd2a33e7d6b8d44fa980.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="Holmes-VAU-Towards-Long-term-Video-Anomaly-Understanding-at-Any-Granularity"><a href="#Holmes-VAU-Towards-Long-term-Video-Anomaly-Understanding-at-Any-Granularity" class="headerlink" title="Holmes-VAU: Towards Long-term Video Anomaly Understanding at Any   Granularity"></a>Holmes-VAU: Towards Long-term Video Anomaly Understanding at Any   Granularity</h2><p><strong>Authors:Huaxin Zhang, Xiaohao Xu, Xiang Wang, Jialong Zuo, Xiaonan Huang, Changxin Gao, Shanjun Zhang, Li Yu, Nong Sang</strong></p>
<p>How can we enable models to comprehend video anomalies occurring over varying temporal scales and contexts? Traditional Video Anomaly Understanding (VAU) methods focus on frame-level anomaly prediction, often missing the interpretability of complex and diverse real-world anomalies. Recent multimodal approaches leverage visual and textual data but lack hierarchical annotations that capture both short-term and long-term anomalies. To address this challenge, we introduce HIVAU-70k, a large-scale benchmark for hierarchical video anomaly understanding across any granularity. We develop a semi-automated annotation engine that efficiently scales high-quality annotations by combining manual video segmentation with recursive free-text annotation using large language models (LLMs). This results in over 70,000 multi-granular annotations organized at clip-level, event-level, and video-level segments. For efficient anomaly detection in long videos, we propose the Anomaly-focused Temporal Sampler (ATS). ATS integrates an anomaly scorer with a density-aware sampler to adaptively select frames based on anomaly scores, ensuring that the multimodal LLM concentrates on anomaly-rich regions, which significantly enhances both efficiency and accuracy. Extensive experiments demonstrate that our hierarchical instruction data markedly improves anomaly comprehension. The integrated ATS and visual-language model outperform traditional methods in processing long videos. Our benchmark and model are publicly available at <a target="_blank" rel="noopener" href="https://github.com/pipixin321/HolmesVAU">https://github.com/pipixin321/HolmesVAU</a>. </p>
<blockquote>
<p>æˆ‘ä»¬å¦‚ä½•ä½¿æ¨¡å‹èƒ½å¤Ÿç†è§£å‘ç”Ÿåœ¨ä¸åŒæ—¶é—´å°ºåº¦å’Œä¸Šä¸‹æ–‡ä¸­çš„è§†é¢‘å¼‚å¸¸ï¼Ÿä¼ ç»Ÿçš„è§†é¢‘å¼‚å¸¸ç†è§£ï¼ˆVAUï¼‰æ–¹æ³•ä¸»è¦å…³æ³¨å¸§çº§å¼‚å¸¸é¢„æµ‹ï¼Œå¾€å¾€å¿½ç•¥äº†å¤æ‚å’Œå¤šæ ·åŒ–çš„ç°å®ä¸–ç•Œå¼‚å¸¸çš„è§£è¯»æ€§ã€‚æœ€è¿‘çš„å¤šæ¨¡å¼æ–¹æ³•åˆ©ç”¨è§†è§‰å’Œæ–‡æœ¬æ•°æ®ï¼Œä½†ç¼ºä¹èƒ½å¤Ÿæ•æ‰çŸ­æœŸå’Œé•¿æœŸå¼‚å¸¸çš„å±‚æ¬¡åŒ–æ³¨é‡Šã€‚ä¸ºäº†è§£å†³è¿™ä¸€æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æ¨å‡ºäº†HIVAU-70kï¼Œè¿™æ˜¯ä¸€ä¸ªç”¨äºä»»ä½•ç²’åº¦å±‚æ¬¡è§†é¢‘å¼‚å¸¸ç†è§£çš„å¤§è§„æ¨¡åŸºå‡†æµ‹è¯•ã€‚æˆ‘ä»¬å¼€å‘äº†ä¸€ä¸ªåŠè‡ªåŠ¨æ³¨é‡Šå¼•æ“ï¼Œé€šè¿‡ç»“åˆæ‰‹åŠ¨è§†é¢‘åˆ†å‰²å’ŒåŸºäºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„é€’å½’æ–‡æœ¬æ³¨é‡Šï¼Œæœ‰æ•ˆåœ°æ‰©å±•äº†é«˜è´¨é‡æ³¨é‡Šã€‚è¿™äº§ç”Ÿäº†è¶…è¿‡7ä¸‡ä¸ªå¤šç²’åº¦æ³¨é‡Šï¼ŒæŒ‰å‰ªè¾‘çº§ã€äº‹ä»¶çº§å’Œè§†é¢‘çº§åˆ†æ®µç»„ç»‡ã€‚ä¸ºäº†å®ç°é•¿è§†é¢‘ä¸­é«˜æ•ˆçš„å¼‚å¸¸æ£€æµ‹ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸“æ³¨äºå¼‚å¸¸çš„ä¸´æ—¶é‡‡æ ·å™¨ï¼ˆATSï¼‰ã€‚ATSå°†å¼‚å¸¸è¯„åˆ†è€…ä¸å¯†åº¦æ„ŸçŸ¥é‡‡æ ·å™¨ç›¸ç»“åˆï¼Œæ ¹æ®å¼‚å¸¸åˆ†æ•°è‡ªé€‚åº”åœ°é€‰æ‹©å¸§ï¼Œç¡®ä¿å¤šæ¨¡å¼LLMä¸“æ³¨äºå¼‚å¸¸ä¸°å¯Œçš„åŒºåŸŸï¼Œè¿™æ˜¾è‘—æé«˜äº†æ•ˆç‡å’Œå‡†ç¡®æ€§ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„å±‚æ¬¡åŒ–æŒ‡ä»¤æ•°æ®æ˜¾è‘—æé«˜äº†å¼‚å¸¸ç†è§£èƒ½åŠ›ã€‚æˆ‘ä»¬çš„åŸºå‡†æµ‹è¯•å’Œæ¨¡å‹ä¸è§†è§‰è¯­è¨€æ¨¡å‹é›†æˆçš„ATSåœ¨å¤„ç†é•¿è§†é¢‘æ—¶ï¼Œå…¶è¡¨ç°ä¼˜äºä¼ ç»Ÿæ–¹æ³•ã€‚æˆ‘ä»¬çš„åŸºå‡†æµ‹è¯•å’Œæ¨¡å‹åœ¨<a target="_blank" rel="noopener" href="https://github.com/pipixin321/HolmesVAU%E5%85%AC%E5%BC%80%E5%8F%AF%E7%94%A8%E3%80%82">https://github.com/pipixin321/HolmesVAUå…¬å¼€å¯ç”¨ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.06171v2">PDF</a> Accepted by CVPR2025</p>
<p><strong>æ‘˜è¦</strong><br>    ä¸ºè§£å†³æ¨¡å‹å¯¹ä¸åŒæ—¶é—´å°ºåº¦å’Œä¸Šä¸‹æ–‡è§†é¢‘å¼‚å¸¸ç†è§£çš„é—®é¢˜ï¼Œå¼•å…¥HIVAU-70kå¤§è§„æ¨¡åŸºå‡†æµ‹è¯•é›†ï¼Œæå‡ºåŠè‡ªåŠ¨æ³¨é‡Šå¼•æ“å’ŒAnomaly-focused Temporal Samplerï¼ˆATSï¼‰ã€‚è¯¥å¼•æ“ç»“åˆæ‰‹åŠ¨è§†é¢‘åˆ†å‰²å’Œé€’å½’æ–‡æœ¬æ³¨é‡Šï¼Œå®ç°é«˜è´¨é‡æ³¨é‡Šçš„é«˜æ•ˆæ‰©å±•ã€‚ATSç»“åˆå¼‚å¸¸è¯„åˆ†è€…å’Œå¯†åº¦æ„ŸçŸ¥é‡‡æ ·å™¨ï¼Œè‡ªé€‚åº”é€‰æ‹©å…³é”®å¸§è¿›è¡Œå¼‚å¸¸æ£€æµ‹ã€‚å®éªŒè¯æ˜ï¼Œæ–°æ–¹æ³•åœ¨å¤„ç†é•¿è§†é¢‘æ—¶æ˜¾è‘—æé«˜äº†æ•ˆç‡å’Œå‡†ç¡®æ€§ã€‚åŸºå‡†æµ‹è¯•å’Œæ¨¡å‹å·²å…¬å¼€ã€‚</p>
<p><strong>è¦ç‚¹</strong></p>
<ul>
<li>æå‡ºè§£å†³æ¨¡å‹ç†è§£ä¸åŒæ—¶é—´å°ºåº¦å’Œä¸Šä¸‹æ–‡è§†é¢‘å¼‚å¸¸çš„æŒ‘æˆ˜ã€‚</li>
<li>å¼•å…¥HIVAU-70kå¤§è§„æ¨¡åŸºå‡†æµ‹è¯•é›†ï¼Œç”¨äºå±‚æ¬¡åŒ–è§†é¢‘å¼‚å¸¸ç†è§£ã€‚</li>
<li>å¼€å‘åŠè‡ªåŠ¨æ³¨é‡Šå¼•æ“ï¼Œç»“åˆæ‰‹åŠ¨è§†é¢‘åˆ†å‰²å’Œé€’å½’æ–‡æœ¬æ³¨é‡Šã€‚</li>
<li>æå‡ºAnomaly-focused Temporal Samplerï¼ˆATSï¼‰ï¼Œæé«˜å¼‚å¸¸æ£€æµ‹æ•ˆç‡å’Œå‡†ç¡®æ€§ã€‚</li>
<li>å±‚æ¬¡åŒ–æŒ‡ä»¤æ•°æ®æ˜¾è‘—æ”¹å–„å¼‚å¸¸ç†è§£ã€‚</li>
<li>å…¬å¼€åŸºå‡†æµ‹è¯•å’Œæ¨¡å‹ï¼Œä¾¿äºå…¬ä¼—è®¿é—®å’Œä½¿ç”¨ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.06171">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-8dd5826f24832c7f7768b982cb9d2391.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-5da5db093e91fae53737077d8017edba.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-364272ae2d4b90227d6d8fdc3d001cd5.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-4a9e4cdaba881a0bbb9e08c59186a353.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-814758e026e94c30eefbe3c7cb476f60.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-03-18/%E8%A7%86%E9%A2%91%E7%90%86%E8%A7%A3/">https://kedreamix.github.io/Talk2Paper/Paper/2025-03-18/%E8%A7%86%E9%A2%91%E7%90%86%E8%A7%A3/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/%E8%A7%86%E9%A2%91%E7%90%86%E8%A7%A3/">
                                    <span class="chip bg-color">è§†é¢‘ç†è§£</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-03-18/Vision%20Transformer/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-ac915e3876c60b287ac49530c98cf191.jpg" class="responsive-img" alt="Vision Transformer">
                        
                        <span class="card-title">Vision Transformer</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Vision Transformer æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-03-18  Towards Scalable Foundation Model for Multi-modal and Hyperspectral   Geospatial Data
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-03-18
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Vision-Transformer/" class="post-category">
                                    Vision Transformer
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Vision-Transformer/">
                        <span class="chip bg-color">Vision Transformer</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-03-18/I2I%20Translation/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-ff0097c597a4034c4aef4a18d8813f90.jpg" class="responsive-img" alt="I2I Translation">
                        
                        <span class="card-title">I2I Translation</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            I2I Translation æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-03-18  Realization of a Pre-Sample Photonic-based Free-Electron Modulator in   Ultrafast Transmission Electron Microscopes
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-03-18
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/I2I-Translation/" class="post-category">
                                    I2I Translation
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/I2I-Translation/">
                        <span class="chip bg-color">I2I Translation</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">27663.8k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
