<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Agent">
    <meta name="description" content="Agent æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-03-18  VideoMind A Chain-of-LoRA Agent for Long Video Reasoning">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>Agent | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://picx.zhimg.com/v2-6e023b873a4405186db6379b15919ad2.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Agent</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/Agent/">
                                <span class="chip bg-color">Agent</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/Agent/" class="post-category">
                                Agent
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-03-18
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-05-14
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    11.2k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    46 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-03-18-æ›´æ–°"><a href="#2025-03-18-æ›´æ–°" class="headerlink" title="2025-03-18 æ›´æ–°"></a>2025-03-18 æ›´æ–°</h1><h2 id="VideoMind-A-Chain-of-LoRA-Agent-for-Long-Video-Reasoning"><a href="#VideoMind-A-Chain-of-LoRA-Agent-for-Long-Video-Reasoning" class="headerlink" title="VideoMind: A Chain-of-LoRA Agent for Long Video Reasoning"></a>VideoMind: A Chain-of-LoRA Agent for Long Video Reasoning</h2><p><strong>Authors:Ye Liu, Kevin Qinghong Lin, Chang Wen Chen, Mike Zheng Shou</strong></p>
<p>Videos, with their unique temporal dimension, demand precise grounded understanding, where answers are directly linked to visual, interpretable evidence. Despite significant breakthroughs in reasoning capabilities within Large Language Models, multi-modal reasoning - especially for videos - remains unexplored. In this work, we introduce VideoMind, a novel video-language agent designed for temporal-grounded video understanding. VideoMind incorporates two key innovations: (i) We identify essential capabilities for video temporal reasoning and develop a role-based agentic workflow, including a planner for coordinating different roles, a grounder for temporal localization, a verifier to assess temporal interval accuracy, and an answerer for question-answering. (ii) To efficiently integrate these diverse roles, we propose a novel Chain-of-LoRA strategy, enabling seamless role-switching via lightweight LoRA adaptors while avoiding the overhead of multiple models, thus balancing efficiency and flexibility. Extensive experiments on 14 public benchmarks demonstrate that our agent achieves state-of-the-art performance on diverse video understanding tasks, including 3 on grounded video question-answering, 6 on video temporal grounding, and 5 on general video question-answering, underscoring its effectiveness in advancing video agent and long-form temporal reasoning. </p>
<blockquote>
<p>è§†é¢‘ä»¥å…¶ç‹¬ç‰¹çš„æ—¶é—´ç»´åº¦ä¸ºç‰¹è‰²ï¼Œè¦æ±‚ç²¾ç¡®ä¸”åŸºäºæƒ…å¢ƒçš„ç†è§£ï¼Œç­”æ¡ˆç›´æ¥ä¸è§†è§‰ã€å¯è§£é‡Šçš„è¯æ®ç›¸å…³è”ã€‚å°½ç®¡å¤§å‹è¯­è¨€æ¨¡å‹åœ¨æ¨ç†èƒ½åŠ›æ–¹é¢å–å¾—äº†é‡å¤§çªç ´ï¼Œä½†å¤šæ¨¡æ€æ¨ç†â€”â€”å°¤å…¶æ˜¯è§†é¢‘æ¨ç†â€”â€”ä»ç„¶æœªå¾—åˆ°å……åˆ†æ¢ç´¢ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬å¼•å…¥äº†VideoMindï¼Œè¿™æ˜¯ä¸€ä¸ªä¸ºåŸºäºæ—¶é—´æƒ…å¢ƒçš„è§†é¢‘ç†è§£è€Œè®¾è®¡çš„æ–°å‹è§†é¢‘è¯­è¨€ä»£ç†ã€‚VideoMindæœ‰ä¸¤ä¸ªå…³é”®çš„åˆ›æ–°ç‚¹ï¼šï¼ˆä¸€ï¼‰æˆ‘ä»¬ç¡®å®šäº†è§†é¢‘æ—¶é—´æ¨ç†çš„å¿…è¦èƒ½åŠ›ï¼Œå¹¶åŸºäºè§’è‰²è®¾è®¡äº†ä¸€ä¸ªä»£ç†å·¥ä½œæµç¨‹ï¼ŒåŒ…æ‹¬ä¸€ä¸ªåè°ƒä¸åŒè§’è‰²çš„è§„åˆ’å™¨ã€ä¸€ä¸ªç”¨äºæ—¶é—´å®šä½çš„å®šä½å™¨ã€ä¸€ä¸ªè¯„ä¼°æ—¶é—´é—´éš”å‡†ç¡®æ€§çš„éªŒè¯å™¨ï¼Œä»¥åŠä¸€ä¸ªç”¨äºé—®é¢˜å›ç­”çš„è§£ç­”å™¨ã€‚ï¼ˆäºŒï¼‰ä¸ºäº†æœ‰æ•ˆåœ°æ•´åˆè¿™äº›ä¸åŒçš„è§’è‰²ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°é¢–çš„Chain-of-LoRAç­–ç•¥ï¼Œé€šè¿‡è½»é‡çº§çš„LoRAé€‚é…å™¨å®ç°æ— ç¼çš„è§’è‰²åˆ‡æ¢ï¼ŒåŒæ—¶é¿å…ä½¿ç”¨å¤šä¸ªæ¨¡å‹å¸¦æ¥çš„å¼€é”€ï¼Œä»è€Œåœ¨æ•ˆç‡å’Œçµæ´»æ€§ä¹‹é—´å–å¾—å¹³è¡¡ã€‚åœ¨14ä¸ªå…¬å¼€åŸºå‡†æµ‹è¯•ä¸Šçš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„ä»£ç†åœ¨å¤šç§è§†é¢‘ç†è§£ä»»åŠ¡ä¸Šå®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œå…¶ä¸­åŒ…æ‹¬3é¡¹åŸºäºæƒ…å¢ƒçš„è§†é¢‘é—®ç­”ä»»åŠ¡ã€6é¡¹è§†é¢‘æ—¶é—´å®šä½ä»»åŠ¡å’Œ5é¡¹é€šç”¨è§†é¢‘é—®ç­”ä»»åŠ¡ï¼Œè¿™å‡¸æ˜¾äº†å…¶åœ¨æ¨è¿›è§†é¢‘ä»£ç†å’Œé•¿æ ¼å¼æ—¶é—´æ¨ç†æ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.13444v1">PDF</a> Project Page: <a target="_blank" rel="noopener" href="https://videomind.github.io/">https://videomind.github.io/</a></p>
<p><strong>Summary</strong>ï¼šè§†é¢‘å…·æœ‰ç‹¬ç‰¹çš„æ—¶é—´ç»´åº¦ï¼Œéœ€è¦ç²¾ç¡®çš„ç†è§£ã€‚å°½ç®¡å¤§å‹è¯­è¨€æ¨¡å‹åœ¨æ¨ç†èƒ½åŠ›æ–¹é¢å–å¾—äº†é‡å¤§çªç ´ï¼Œä½†å¤šæ¨¡æ€æ¨ç†ï¼Œå°¤å…¶æ˜¯å¯¹è§†é¢‘çš„å¤šæ¨¡æ€æ¨ç†ï¼Œä»ç„¶æœªå¾—åˆ°æ·±å…¥ç ”ç©¶ã€‚åœ¨è¿™é¡¹ç ”ç©¶ä¸­ï¼Œæˆ‘ä»¬æ¨å‡ºäº†VideoMindï¼Œè¿™æ˜¯ä¸€ç§ç”¨äºæ—¶é—´å®šä½è§†é¢‘ç†è§£çš„æ–°å‹è§†é¢‘è¯­è¨€ä»£ç†ã€‚VideoMindæœ‰ä¸¤ä¸ªå…³é”®çš„åˆ›æ–°ç‚¹ï¼šä¸€æ˜¯ç¡®å®šäº†è§†é¢‘æ—¶é—´æ¨ç†çš„å¿…è¦èƒ½åŠ›ï¼Œå¹¶åŸºäºè§’è‰²è®¾è®¡äº†ä¸€ä¸ªä»£ç†å·¥ä½œæµç¨‹ï¼›äºŒæ˜¯æå‡ºäº†é«˜æ•ˆçš„Chain-of-LoRAç­–ç•¥ï¼Œå¯ä»¥åœ¨ä¸ç‰ºç‰²æ•ˆç‡çš„æƒ…å†µä¸‹çµæ´»åˆ‡æ¢è§’è‰²ã€‚åœ¨å¤šä¸ªå…¬å…±åŸºå‡†æµ‹è¯•ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒVideoMindåœ¨å¤šç§è§†é¢‘ç†è§£ä»»åŠ¡ä¸Šè¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚</p>
<p><strong>Key Takeaways</strong>ï¼š</p>
<ol>
<li>è§†é¢‘ç†è§£éœ€è¦ç²¾ç¡®çš„æ—¶é—´å®šä½ï¼Œå¤§å‹è¯­è¨€æ¨¡å‹åœ¨å¤šæ¨¡æ€æ¨ç†æ–¹é¢ä»éœ€æå‡ã€‚</li>
<li>VideoMindæ˜¯ä¸€ç§æ–°å‹çš„è§†é¢‘è¯­è¨€ä»£ç†ï¼Œç”¨äºæ—¶é—´å®šä½çš„è§†é¢‘ç†è§£ã€‚</li>
<li>VideoMindåŒ…å«åŸºäºè§’è‰²çš„ä»£ç†å·¥ä½œæµç¨‹ï¼Œå…¶ä¸­åŒ…æ‹¬è§„åˆ’å™¨ã€å®šä½å™¨ã€éªŒè¯å™¨å’Œé—®ç­”å™¨å››ä¸ªå…³é”®è§’è‰²ã€‚</li>
<li>å¼•å…¥äº†ä¸€ç§æ–°çš„Chain-of-LoRAç­–ç•¥ï¼Œä»¥å¹³è¡¡æ•ˆç‡å’Œçµæ´»æ€§ï¼Œå®ç°æ— ç¼çš„è§’è‰²åˆ‡æ¢ã€‚</li>
<li>VideoMindåœ¨å¤šä¸ªå…¬å…±åŸºå‡†æµ‹è¯•ä¸Šå–å¾—äº†æœ€å…ˆè¿›çš„æ€§èƒ½è¡¨ç°ã€‚</li>
<li>VideoMindå¯¹äºæå‡è§†é¢‘ä»£ç†å’Œé•¿æ—¶é—´æ¨ç†çš„æ•ˆèƒ½æœ‰æ˜¾è‘—å½±å“ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.13444">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-03-18\./crop_Agent/2503.13444v1/page_0_0.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d86845e5943d8d4f83c93a98953ba4ee.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-0ecd8e7a2ab1ee00fecb4e352d4a7368.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b0ad1e51ad6980ab765146c580ff7b3d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f64f9f3ca2ee88900720c4541e3ea15e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-54666f24476073a8e24f97694f7e00d2.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="Agents-Play-Thousands-of-3D-Video-Games"><a href="#Agents-Play-Thousands-of-3D-Video-Games" class="headerlink" title="Agents Play Thousands of 3D Video Games"></a>Agents Play Thousands of 3D Video Games</h2><p><strong>Authors:Zhongwen Xu, Xianliang Wang, Siyi Li, Tao Yu, Liang Wang, Qiang Fu, Wei Yang</strong></p>
<p>We present PORTAL, a novel framework for developing artificial intelligence agents capable of playing thousands of 3D video games through language-guided policy generation. By transforming decision-making problems into language modeling tasks, our approach leverages large language models (LLMs) to generate behavior trees represented in domain-specific language (DSL). This method eliminates the computational burden associated with traditional reinforcement learning approaches while preserving strategic depth and rapid adaptability. Our framework introduces a hybrid policy structure that combines rule-based nodes with neural network components, enabling both high-level strategic reasoning and precise low-level control. A dual-feedback mechanism incorporating quantitative game metrics and vision-language model analysis facilitates iterative policy improvement at both tactical and strategic levels. The resulting policies are instantaneously deployable, human-interpretable, and capable of generalizing across diverse gaming environments. Experimental results demonstrate PORTALâ€™s effectiveness across thousands of first-person shooter (FPS) games, showcasing significant improvements in development efficiency, policy generalization, and behavior diversity compared to traditional approaches. PORTAL represents a significant advancement in game AI development, offering a practical solution for creating sophisticated agents that can operate across thousands of commercial video games with minimal development overhead. Experiment results on the 3D video games are best viewed on <a target="_blank" rel="noopener" href="https://zhongwen.one/projects/portal">https://zhongwen.one/projects/portal</a> . </p>
<blockquote>
<p>æˆ‘ä»¬æ¨å‡ºäº†PORTALï¼Œè¿™æ˜¯ä¸€ä¸ªæ–°å‹æ¡†æ¶ï¼Œç”¨äºå¼€å‘èƒ½å¤Ÿé€šè¿‡è¯­è¨€æŒ‡å¯¼ç­–ç•¥ç”Ÿæˆç©æ•°åƒæ¬¾3Dè§†é¢‘æ¸¸æˆçš„äººå·¥æ™ºèƒ½ä»£ç†ã€‚é€šè¿‡å°†å†³ç­–é—®é¢˜è½¬åŒ–ä¸ºè¯­è¨€å»ºæ¨¡ä»»åŠ¡ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ¥ç”Ÿæˆä»¥é¢†åŸŸç‰¹å®šè¯­è¨€ï¼ˆDSLï¼‰è¡¨ç¤ºçš„è¡Œä¸ºæ ‘ã€‚è¿™ç§æ–¹æ³•æ¶ˆé™¤äº†ä¼ ç»Ÿå¼ºåŒ–å­¦ä¹ æ–¹æ³•çš„è®¡ç®—è´Ÿæ‹…ï¼ŒåŒæ—¶ä¿ç•™äº†æˆ˜ç•¥æ·±åº¦å’Œå¿«é€Ÿé€‚åº”æ€§ã€‚æˆ‘ä»¬çš„æ¡†æ¶å¼•å…¥äº†ä¸€ç§æ··åˆç­–ç•¥ç»“æ„ï¼Œç»“åˆäº†åŸºäºè§„åˆ™çš„èŠ‚ç‚¹å’Œç¥ç»ç½‘ç»œç»„ä»¶ï¼Œæ—¢å¯å®ç°é«˜çº§æˆ˜ç•¥æ¨ç†ï¼Œåˆèƒ½å®ç°ç²¾ç¡®çš„ä½çº§æ§åˆ¶ã€‚é‡‡ç”¨åŒåé¦ˆæœºåˆ¶ç»“åˆå®šé‡æ¸¸æˆæŒ‡æ ‡å’Œè§†è§‰è¯­è¨€æ¨¡å‹åˆ†æï¼Œä¿ƒè¿›äº†æˆ˜æœ¯å’Œæˆ˜ç•¥å±‚é¢çš„ç­–ç•¥è¿­ä»£æ”¹è¿›ã€‚ç”Ÿæˆçš„ç­–ç•¥å¯å³æ—¶éƒ¨ç½²ã€äººç±»å¯è§£é‡Šï¼Œå¹¶èƒ½è·¨ä¸åŒæ¸¸æˆç¯å¢ƒè¿›è¡Œæ¨å¹¿ã€‚å®éªŒç»“æœè¯æ˜äº†PORTALåœ¨æ•°åƒæ¬¾ç¬¬ä¸€äººç§°å°„å‡»æ¸¸æˆï¼ˆFPSï¼‰ä¸­çš„æœ‰æ•ˆæ€§ï¼Œä¸ä¼ ç»Ÿæ–¹æ³•ç›¸æ¯”ï¼Œåœ¨å¼€å‘æ•ˆç‡ã€ç­–ç•¥æ¨å¹¿å’Œè¡Œä¸ºå¤šæ ·æ€§æ–¹é¢éƒ½æœ‰æ˜¾è‘—æé«˜ã€‚PORTALä»£è¡¨äº†æ¸¸æˆAIå¼€å‘ä¸­çš„é‡å¤§è¿›å±•ï¼Œä¸ºåˆ›å»ºèƒ½å¤Ÿåœ¨æ•°åƒæ¬¾å•†ä¸šè§†é¢‘æ¸¸æˆä¸­è¿è¡Œä¸”å¼€å‘æˆæœ¬è¾ƒä½çš„å¤æ‚ä»£ç†æä¾›äº†å®ç”¨è§£å†³æ–¹æ¡ˆã€‚å…³äº3Dè§†é¢‘æ¸¸æˆçš„å®éªŒç»“æœï¼Œå»ºè®®è®¿é—®<a target="_blank" rel="noopener" href="https://zhongwen.one/projects/portal%E8%BF%9B%E8%A1%8C%E6%9F%A5%E7%9C%8B%E3%80%82">https://zhongwen.one/projects/portalè¿›è¡ŒæŸ¥çœ‹ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.13356v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>åŸºäºè¯­è¨€æŒ‡å¯¼ç­–ç•¥ç”Ÿæˆçš„ç†å¿µï¼Œæå‡ºäº†PORTALè¿™ä¸€æ–°å‹äººå·¥æ™ºèƒ½ä»£ç†å¼€å‘æ¡†æ¶ï¼Œè¯¥æ¡†æ¶èƒ½æ”¯æŒæ•°åƒæ¬¾3Dè§†é¢‘æ¸¸æˆã€‚é€šè¿‡æŠŠå†³ç­–é—®é¢˜è½¬åŒ–ä¸ºè¯­è¨€å»ºæ¨¡ä»»åŠ¡ï¼Œåˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ç”Ÿæˆè¡Œä¸ºæ ‘ï¼Œå®ç°ç­–ç•¥ç”Ÿæˆã€‚æ­¤æ¡†æ¶ç»“åˆäº†è§„åˆ™èŠ‚ç‚¹å’Œç¥ç»ç½‘ç»œç»„ä»¶çš„æ··åˆç­–ç•¥ç»“æ„ï¼Œå®ç°äº†é«˜çº§æˆ˜ç•¥æ¨ç†å’Œç²¾ç¡®ä½çº§æ§åˆ¶ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒPORTALåœ¨FPSæ¸¸æˆçš„å¤šä¸ªç¯å¢ƒä¸­è¡¨ç°ä¼˜è¶Šï¼Œæ˜¾è‘—æé«˜å¼€å‘æ•ˆç‡ã€ç­–ç•¥æ³›åŒ–å’Œè¡Œä¸ºå¤šæ ·æ€§ã€‚è¯¦æƒ…è¯·è®¿é—®<a target="_blank" rel="noopener" href="https://zhongwen.one/projects/portal">é“¾æ¥</a>ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>PORTALæ¡†æ¶é€šè¿‡è¯­è¨€æŒ‡å¯¼ç­–ç•¥ç”Ÿæˆï¼Œæ”¯æŒæ•°åƒæ¬¾3Dè§†é¢‘æ¸¸æˆã€‚</li>
<li>åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å°†å†³ç­–é—®é¢˜è½¬åŒ–ä¸ºè¯­è¨€å»ºæ¨¡ä»»åŠ¡ï¼Œç”Ÿæˆè¡Œä¸ºæ ‘ã€‚</li>
<li>æ¡†æ¶é‡‡ç”¨æ··åˆç­–ç•¥ç»“æ„ï¼Œç»“åˆè§„åˆ™èŠ‚ç‚¹å’Œç¥ç»ç½‘ç»œç»„ä»¶ï¼Œå®ç°æˆ˜ç•¥å’Œç²¾ç¡®æ§åˆ¶ã€‚</li>
<li>é€šè¿‡åŒåé¦ˆæœºåˆ¶ç»“åˆæ¸¸æˆæŒ‡æ ‡å’Œè§†è§‰è¯­è¨€æ¨¡å‹åˆ†æï¼Œæ”¹è¿›ç­–ç•¥ã€‚</li>
<li>å®éªŒç»“æœæ˜¾ç¤ºï¼ŒPORTALåœ¨FPSæ¸¸æˆä¸­è¡¨ç°å‡ºé«˜å¼€å‘æ•ˆç‡ã€ç­–ç•¥æ³›åŒ–å’Œè¡Œä¸ºå¤šæ ·æ€§ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.13356">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-c167cc28f9e4d1240446b3e2193eb448.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-8b0b221d0b53ecebb1c021db30418ac3.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="Goal2Story-A-Multi-Agent-Fleet-based-on-Privately-Enabled-sLLMs-for-Impacting-Mapping-on-Requirements-Elicitation"><a href="#Goal2Story-A-Multi-Agent-Fleet-based-on-Privately-Enabled-sLLMs-for-Impacting-Mapping-on-Requirements-Elicitation" class="headerlink" title="Goal2Story: A Multi-Agent Fleet based on Privately Enabled sLLMs for   Impacting Mapping on Requirements Elicitation"></a>Goal2Story: A Multi-Agent Fleet based on Privately Enabled sLLMs for   Impacting Mapping on Requirements Elicitation</h2><p><strong>Authors:Xinkai Zou, Yan Liu, Xiongbo Shi, Chen Yang</strong></p>
<p>As requirements drift with rapid iterations, agile development becomes the dominant paradigm. Goal-driven Requirements Elicitation (RE) is a pivotal yet challenging task in agile project development due to its heavy tangling with adaptive planning and efficient collaboration. Recently, AI agents have shown promising ability in supporting requirements analysis by saving significant time and effort for stakeholders. However, current research mainly focuses on functional RE, and research works have not been reported bridging the long journey from goal to user stories. Moreover, considering the cost of LLM facilities and the need for data and idea protection, privately hosted small-sized LLM should be further utilized in RE. To address these challenges, we propose Goal2Story, a multi-agent fleet that adopts the Impact Mapping (IM) framework while merely using cost-effective sLLMs for goal-driven RE. Moreover, we introduce a StorySeek dataset that contains over 1,000 user stories (USs) with corresponding goals and project context information, as well as the semi-automatic dataset construction method. For evaluation, we proposed two metrics: Factuality Hit Rate (FHR) to measure consistency between the generated USs with the dataset and Quality And Consistency Evaluation (QuACE) to evaluate the quality of the generated USs. Experimental results demonstrate that Goal2Story outperforms the baseline performance of the Super-Agent adopting powerful LLMs, while also showcasing the performance improvements in key metrics brought by CoT and Agent Profile to Goal2Story, as well as its exploration in identifying latent needs. </p>
<blockquote>
<p>éšç€éœ€æ±‚çš„å¿«é€Ÿè¿­ä»£å˜åŒ–ï¼Œæ•æ·å¼€å‘å·²æˆä¸ºä¸»æµçš„å¼€å‘æ¨¡å¼ã€‚åœ¨æ•æ·é¡¹ç›®å¼€å‘ä¸­ï¼Œä»¥ç›®æ ‡é©±åŠ¨çš„éœ€æ±‚é‡‡é›†ï¼ˆREï¼‰æ˜¯è‡³å…³é‡è¦ä¸”å……æ»¡æŒ‘æˆ˜çš„ä»»åŠ¡ï¼Œå› ä¸ºå®ƒä¸é€‚åº”æ€§è§„åˆ’å’Œé«˜æ•ˆåä½œå¯†åˆ‡ç›¸å…³ã€‚æœ€è¿‘ï¼ŒAIä»£ç†äººåœ¨æ”¯æŒéœ€æ±‚åˆ†æä¸­è¡¨ç°å‡ºäº†ä»¤äººç©ç›®çš„èƒ½åŠ›ï¼Œä¸ºåˆ©ç›Šç›¸å…³è€…èŠ‚çœäº†å¤§é‡æ—¶é—´å’Œç²¾åŠ›ã€‚ç„¶è€Œï¼Œå½“å‰çš„ç ”ç©¶ä¸»è¦é›†ä¸­åœ¨åŠŸèƒ½REä¸Šï¼Œå°šæœªæœ‰ç ”ç©¶æŠ¥å‘Šå¡«è¡¥ä»ç›®æ ‡åˆ°ç”¨æˆ·æ•…äº‹çš„æ¼«é•¿æ—…ç¨‹ä¸­çš„ç©ºç™½ã€‚æ­¤å¤–ï¼Œè€ƒè™‘åˆ°å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰è®¾æ–½çš„æˆæœ¬ä»¥åŠæ•°æ®å’Œæ€æƒ³ä¿æŠ¤çš„éœ€æ±‚ï¼Œåº”è¿›ä¸€æ­¥åˆ©ç”¨ç§æœ‰æ‰˜ç®¡çš„å°å‹LLMè¿›è¡ŒREã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.13279v1">PDF</a> </p>
<p><strong>Summary</strong><br>    æ•æ·å¼€å‘é€æ¸æˆä¸ºä¸»æµèŒƒå¼ï¼Œè¦æ±‚å¿«é€Ÿè¿­ä»£çš„éœ€æ±‚é©±åŠ¨è½¯ä»¶å¼€å‘ã€‚ç›®æ ‡é©±åŠ¨çš„éœ€æ±‚é‡‡é›†ï¼ˆREï¼‰æ˜¯æ•æ·é¡¹ç›®å¼€å‘ä¸­çš„å…³é”®ä»»åŠ¡ï¼Œä½†å……æ»¡æŒ‘æˆ˜ã€‚AIä»£ç†äººåœ¨éœ€æ±‚åˆ†æä¸­æ˜¾ç¤ºå‡ºæ½œåŠ›ï¼Œå¯èŠ‚çœåˆ©ç›Šç›¸å…³è€…çš„æ—¶é—´å’ŒåŠªåŠ›ã€‚ç„¶è€Œï¼Œå½“å‰ç ”ç©¶ä¸»è¦é›†ä¸­åœ¨åŠŸèƒ½REä¸Šï¼Œå°šæœªæœ‰æŠ¥é“è·¨è¶Šä»ç›®æ ‡åˆ°ç”¨æˆ·æ•…äº‹çš„æ¼«é•¿æ—…ç¨‹ã€‚ä¸ºè§£å†³æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºGoal2Storyï¼Œé‡‡ç”¨å½±å“æ˜ å°„æ¡†æ¶çš„å¤šä»£ç†å›¢é˜Ÿï¼Œä»…ä½¿ç”¨æˆæœ¬æ•ˆç›Šé«˜çš„sLLMè¿›è¡Œç›®æ ‡é©±åŠ¨REã€‚æˆ‘ä»¬è¿˜ä»‹ç»äº†åŒ…å«è¶…è¿‡1000ä¸ªç”¨æˆ·æ•…äº‹çš„æ•°æ®é›†å’ŒåŠè‡ªåŠ¨æ•°æ®é›†æ„å»ºæ–¹æ³•ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒGoal2Storyä¼˜äºé‡‡ç”¨å¼ºå¤§LLMçš„è¶…çº§ä»£ç†çš„åŸºçº¿æ€§èƒ½ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æ•æ·å¼€å‘æˆä¸ºä¸»æµï¼Œéœ€æ±‚å¿«é€Ÿè¿­ä»£ï¼Œç›®æ ‡é©±åŠ¨çš„éœ€æ±‚é‡‡é›†ï¼ˆREï¼‰åœ¨æ•æ·é¡¹ç›®å¼€å‘ä¸­è‡³å…³é‡è¦ã€‚</li>
<li>AIä»£ç†åœ¨éœ€æ±‚åˆ†æå’Œç”¨æˆ·æ•…äº‹ç”Ÿæˆæ–¹é¢æ˜¾ç¤ºå‡ºæ½œåŠ›ï¼Œå¯ä»¥èŠ‚çœåˆ©ç›Šç›¸å…³è€…çš„æ—¶é—´å’ŒåŠªåŠ›ã€‚</li>
<li>å½“å‰ç ”ç©¶ä¸»è¦é›†ä¸­åœ¨åŠŸèƒ½æ€§REä¸Šï¼Œç¼ºä¹ä»ç›®æ ‡åˆ°ç”¨æˆ·æ•…äº‹çš„æ¡¥æ¢ã€‚</li>
<li>Goal2Storyæ˜¯ä¸€ä¸ªé‡‡ç”¨å¤šä»£ç†å›¢é˜Ÿå’Œå½±å“åŠ›æ˜ å°„æ¡†æ¶çš„è§£å†³æ–¹æ¡ˆï¼Œæ—¨åœ¨è§£å†³REä¸­çš„æŒ‘æˆ˜ã€‚</li>
<li>Goal2Storyä½¿ç”¨æˆæœ¬æ•ˆç›Šé«˜çš„sLLMï¼Œè€Œä¸æ˜¯å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ï¼Œä»¥é™ä½æˆæœ¬å¹¶ä¿æŠ¤æ•°æ®ã€‚</li>
<li>ä»‹ç»äº†StorySeekæ•°æ®é›†å’ŒåŠè‡ªåŠ¨æ•°æ®é›†æ„å»ºæ–¹æ³•ï¼Œç”¨äºè¯„ä¼°ç”¨æˆ·æ•…äº‹çš„è´¨é‡å’Œä¸€è‡´æ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.13279">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-f655c469c74d6473b62a4a9e187e1c6b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-6ef71cfd9a555b0dbfd6ff4230546197.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-2865fb19868fad7ad190b8925cc79c84.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="Knowledge-Aware-Iterative-Retrieval-for-Multi-Agent-Systems"><a href="#Knowledge-Aware-Iterative-Retrieval-for-Multi-Agent-Systems" class="headerlink" title="Knowledge-Aware Iterative Retrieval for Multi-Agent Systems"></a>Knowledge-Aware Iterative Retrieval for Multi-Agent Systems</h2><p><strong>Authors:Seyoung Song</strong></p>
<p>We introduce a novel large language model (LLM)-driven agent framework, which iteratively refines queries and filters contextual evidence by leveraging dynamically evolving knowledge. A defining feature of the system is its decoupling of external sources from an internal knowledge cache that is progressively updated to guide both query generation and evidence selection. This design mitigates bias-reinforcement loops and enables dynamic, trackable search exploration paths, thereby optimizing the trade-off between exploring diverse information and maintaining accuracy through autonomous agent decision-making. Our approach is evaluated on a broad range of open-domain question answering benchmarks, including multi-step tasks that mirror real-world scenarios where integrating information from multiple sources is critical, especially given the vulnerabilities of LLMs that lack explicit reasoning or planning capabilities. The results show that the proposed system not only outperforms single-step baselines regardless of task difficulty but also, compared to conventional iterative retrieval methods, demonstrates pronounced advantages in complex tasks through precise evidence-based reasoning and enhanced efficiency. The proposed system supports both competitive and collaborative sharing of updated context, enabling multi-agent extension. The benefits of multi-agent configurations become especially prominent as task difficulty increases. The number of convergence steps scales with task difficulty, suggesting cost-effective scalability. </p>
<blockquote>
<p>æˆ‘ä»¬å¼•å…¥äº†ä¸€ç§æ–°å‹çš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰é©±åŠ¨çš„æ™ºèƒ½ä»£ç†æ¡†æ¶ï¼Œè¯¥æ¡†æ¶é€šè¿‡åˆ©ç”¨åŠ¨æ€æ¼”åŒ–çš„çŸ¥è¯†æ¥è¿­ä»£ä¼˜åŒ–æŸ¥è¯¢å’Œè¿‡æ»¤ä¸Šä¸‹æ–‡è¯æ®ã€‚è¯¥ç³»ç»Ÿçš„ç‰¹ç‚¹æ˜¯å°†å…¶å¤–éƒ¨æ¥æºä¸å†…éƒ¨çŸ¥è¯†ç¼“å­˜ç›¸åˆ†ç¦»ï¼Œå†…éƒ¨çŸ¥è¯†ç¼“å­˜ä¼šé€æ­¥æ›´æ–°ï¼Œä»¥æŒ‡å¯¼æŸ¥è¯¢ç”Ÿæˆå’Œè¯æ®é€‰æ‹©ã€‚è¿™ç§è®¾è®¡å‡è½»äº†åè§åŠ å¼ºå¾ªç¯ï¼Œå¹¶å®ç°äº†åŠ¨æ€ã€å¯è¿½è¸ªçš„æœç´¢æ¢ç´¢è·¯å¾„ï¼Œä»è€Œä¼˜åŒ–äº†æ¢ç´¢å¤šæ ·ä¿¡æ¯ä¸é€šè¿‡è‡ªä¸»ä»£ç†å†³ç­–ä¿æŒå‡†ç¡®æ€§ä¹‹é—´çš„æƒè¡¡ã€‚æˆ‘ä»¬çš„æ–¹æ³•åœ¨ä¸€ç³»åˆ—å¼€æ”¾åŸŸé—®ç­”åŸºå‡†æµ‹è¯•ä¸Šè¿›è¡Œäº†è¯„ä¼°ï¼ŒåŒ…æ‹¬å¤šæ­¥éª¤ä»»åŠ¡ï¼Œè¿™äº›ä»»åŠ¡åæ˜ äº†ç°å®ä¸–ç•Œåœºæ™¯ï¼Œå…¶ä¸­ä»å¤šä¸ªæºæ•´åˆä¿¡æ¯è‡³å…³é‡è¦ï¼Œå°¤å…¶æ˜¯é‰´äºç¼ºä¹æ˜ç¡®æ¨ç†æˆ–è§„åˆ’èƒ½åŠ›çš„å¤§å‹è¯­è¨€æ¨¡å‹çš„è„†å¼±æ€§ã€‚ç»“æœè¡¨æ˜ï¼Œæ‰€æå‡ºçš„ç³»ç»Ÿä¸ä»…åœ¨å„ç§ä»»åŠ¡éš¾åº¦ä¸Šéƒ½ä¼˜äºå•æ­¥éª¤åŸºçº¿ï¼Œè€Œä¸”ä¸ä¼ ç»Ÿè¿­ä»£æ£€ç´¢æ–¹æ³•ç›¸æ¯”ï¼Œåœ¨å¤æ‚ä»»åŠ¡ä¸­é€šè¿‡ç²¾ç¡®çš„åŸºäºè¯æ®çš„æ¨ç†å’Œæ•ˆç‡æå‡è¡¨ç°å‡ºäº†æ˜¾è‘—ä¼˜åŠ¿ã€‚æ‰€æå‡ºçš„ç³»ç»Ÿæ”¯æŒæ›´æ–°çš„ä¸Šä¸‹æ–‡çš„ç«äº‰æ€§å’Œåä½œæ€§å…±äº«ï¼Œèƒ½å¤Ÿå®ç°å¤šæ™ºèƒ½ä½“æ‰©å±•ã€‚éšç€ä»»åŠ¡éš¾åº¦çš„å¢åŠ ï¼Œå¤šæ™ºèƒ½ä½“é…ç½®çš„ä¼˜åŠ¿å˜å¾—å°¤ä¸ºçªå‡ºã€‚æ”¶æ•›æ­¥éª¤çš„æ•°é‡éšä»»åŠ¡éš¾åº¦çš„å¢åŠ è€Œå¢åŠ ï¼Œè¿™è¡¨æ˜å…¶å…·æœ‰æˆæœ¬æ•ˆç›Šçš„å¯æ‰©å±•æ€§ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.13275v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>è¯¥æ–‡æœ¬ä»‹ç»äº†ä¸€ç§æ–°å‹çš„å¤§å‹è¯­è¨€æ¨¡å‹é©±åŠ¨çš„æ™ºèƒ½ä»£ç†æ¡†æ¶ï¼Œå®ƒé€šè¿‡åˆ©ç”¨ä¸æ–­æ¼”å˜çš„å¤–éƒ¨çŸ¥è¯†æ¥è¿­ä»£ä¼˜åŒ–æŸ¥è¯¢å’Œè¿‡æ»¤ä¸Šä¸‹æ–‡è¯æ®ã€‚è¯¥ç³»ç»Ÿé€šè¿‡å°†å¤–éƒ¨æ•°æ®æºä¸å†…éƒ¨çŸ¥è¯†ç¼“å­˜ç›¸åˆ†ç¦»çš„è®¾è®¡ï¼Œé¿å…äº†åè§å¼ºåŒ–å¾ªç¯ï¼Œå®ç°äº†åŠ¨æ€ã€å¯è¿½è¸ªçš„æœç´¢æ¢ç´¢è·¯å¾„ï¼Œä»è€Œåœ¨æ¢ç´¢å¤šæ ·ä¿¡æ¯å’Œä¿æŒå‡†ç¡®æ€§ä¹‹é—´å–å¾—äº†å¹³è¡¡ã€‚é€šè¿‡å¹¿æ³›çš„å¼€æ”¾åŸŸé—®ç­”åŸºå‡†æµ‹è¯•è¯„ä¼°ï¼ŒåŒ…æ‹¬æ¨¡æ‹Ÿç°å®ä¸–ç•Œä¸­éœ€è¦ä»å¤šä¸ªæ¥æºæ•´åˆä¿¡æ¯çš„å¤šæ­¥éª¤ä»»åŠ¡ï¼Œç»“æœè¡¨æ˜è¯¥ç³»ç»Ÿä¸ä»…åœ¨ä»»åŠ¡éš¾åº¦ä¸åŒçš„æƒ…å†µä¸‹è¡¨ç°å‡ºè¶…è¶Šå•æ­¥éª¤åŸºå‡†çš„æ€§èƒ½ï¼Œè€Œä¸”åœ¨å¤æ‚ä»»åŠ¡ä¸­ä¸ä¼ ç»Ÿçš„è¿­ä»£æ£€ç´¢æ–¹æ³•ç›¸æ¯”ä¹Ÿæ˜¾ç¤ºå‡ºæ˜¾è‘—ä¼˜åŠ¿ã€‚æ­¤å¤–ï¼Œè¯¥ç³»ç»Ÿæ”¯æŒç«äº‰æ€§å’Œåä½œæ€§çš„å…±äº«æ›´æ–°ä¸Šä¸‹æ–‡ï¼Œå¯å®ç°å¤šæ™ºèƒ½ä½“æ‰©å±•ï¼Œéšç€ä»»åŠ¡éš¾åº¦çš„å¢åŠ ï¼Œå¤šæ™ºèƒ½ä½“é…ç½®çš„ä¼˜åŠ¿å˜å¾—å°¤ä¸ºçªå‡ºã€‚è¯¥ç³»ç»Ÿçš„æˆæœ¬æ•ˆç›Šä¹Ÿè¾ƒé«˜ï¼Œæ”¶æ•›æ­¥éª¤çš„æ•°é‡éšä»»åŠ¡éš¾åº¦çš„å¢åŠ è€Œå¢åŠ ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ä»‹ç»äº†ä¸€ç§æ–°å‹çš„å¤§å‹è¯­è¨€æ¨¡å‹é©±åŠ¨çš„æ™ºèƒ½ä»£ç†æ¡†æ¶ã€‚</li>
<li>é€šè¿‡åˆ©ç”¨åŠ¨æ€æ¼”å˜çš„å¤–éƒ¨çŸ¥è¯†æ¥è¿­ä»£ä¼˜åŒ–æŸ¥è¯¢å’Œè¿‡æ»¤ä¸Šä¸‹æ–‡è¯æ®ã€‚</li>
<li>é€šè¿‡å°†å¤–éƒ¨æ•°æ®æºä¸å†…éƒ¨çŸ¥è¯†ç¼“å­˜åˆ†ç¦»çš„è®¾è®¡é¿å…äº†åè§å¼ºåŒ–å¾ªç¯ã€‚</li>
<li>è¯¥ç³»ç»Ÿå¯å®ç°åŠ¨æ€ã€å¯è¿½è¸ªçš„æœç´¢æ¢ç´¢è·¯å¾„ï¼Œå¹³è¡¡æ¢ç´¢å¤šæ ·ä¿¡æ¯å’Œä¿æŒå‡†ç¡®æ€§ã€‚</li>
<li>åœ¨å¹¿æ³›çš„å¼€æ”¾åŸŸé—®ç­”åŸºå‡†æµ‹è¯•ä¸­è¡¨ç°å‡ºè¶…è¶Šå•æ­¥éª¤åŸºå‡†çš„æ€§èƒ½ã€‚</li>
<li>åœ¨å¤æ‚ä»»åŠ¡ä¸­æ˜¾ç¤ºå‡ºæ˜¾è‘—ä¼˜åŠ¿ï¼Œé€šè¿‡ç²¾ç¡®çš„è¯æ®æ¨ç†æé«˜æ•ˆç‡å’Œå‡†ç¡®æ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.13275">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-ea735dcf82fa92f07a2f7cd4e89aef79.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="DAgent-A-Relational-Database-Driven-Data-Analysis-Report-Generation-Agent"><a href="#DAgent-A-Relational-Database-Driven-Data-Analysis-Report-Generation-Agent" class="headerlink" title="DAgent: A Relational Database-Driven Data Analysis Report Generation   Agent"></a>DAgent: A Relational Database-Driven Data Analysis Report Generation   Agent</h2><p><strong>Authors:Wenyi Xu, Yuren Mao, Xiaolu Zhang, Chao Zhang, Xuemei Dong, Mengfei Zhang, Jun Zhou, Yunjun Gao</strong></p>
<p>Relational database-driven data analysis (RDB-DA) report generation, which aims to generate data analysis reports after querying relational databases, has been widely applied in fields such as finance and healthcare. Typically, these tasks are manually completed by data scientists, making the process very labor-intensive and showing a clear need for automation. Although existing methods (e.g., Table QA or Text-to-SQL) have been proposed to reduce human dependency, they cannot handle complex analytical tasks that require multi-step reasoning, cross-table associations, and synthesizing insights into reports. Moreover, there is no dataset available for developing automatic RDB-DA report generation. To fill this gap, this paper proposes an LLM agent system for RDB-DA report generation tasks, dubbed DAgent; moreover, we construct a benchmark for automatic data analysis report generation, which includes a new dataset DA-Dataset and evaluation metrics. DAgent integrates planning, tools, and memory modules to decompose natural language questions into logically independent sub-queries, accurately retrieve key information from relational databases, and generate analytical reports that meet the requirements of completeness, correctness, and conciseness through multi-step reasoning and effective data integration. Experimental analysis on the DA-Dataset demonstrates that DAgentâ€™s superiority in retrieval performance and analysis report generation quality, showcasing its strong potential for tackling complex database analysis report generation tasks. </p>
<blockquote>
<p>å…³ç³»æ•°æ®åº“é©±åŠ¨çš„æ•°æ®åˆ†æï¼ˆRDB-DAï¼‰æŠ¥å‘Šç”Ÿæˆå¹¿æ³›åº”ç”¨äºé‡‘èã€åŒ»ç–—ç­‰é¢†åŸŸï¼Œå…¶ç›®æ ‡æ˜¯åœ¨æŸ¥è¯¢å…³ç³»æ•°æ®åº“åç”Ÿæˆæ•°æ®åˆ†ææŠ¥å‘Šã€‚é€šå¸¸ï¼Œè¿™äº›ä»»åŠ¡ç”±æ•°æ®ç§‘å­¦å®¶æ‰‹åŠ¨å®Œæˆï¼Œä½¿å¾—æµç¨‹éå¸¸åŠ³åŠ¨å¯†é›†ï¼Œå¹¶æ˜¾ç¤ºå‡ºæ˜æ˜¾çš„è‡ªåŠ¨åŒ–éœ€æ±‚ã€‚å°½ç®¡å·²æœ‰æ–¹æ³•ï¼ˆä¾‹å¦‚è¡¨æ ¼é—®ç­”æˆ–æ–‡æœ¬åˆ°SQLï¼‰è¢«æå‡ºä»¥å‡å°‘å¯¹äººå·¥çš„ä¾èµ–ï¼Œä½†å®ƒä»¬æ— æ³•å¤„ç†å¤æ‚çš„åˆ†æä»»åŠ¡ï¼Œè¿™äº›ä»»åŠ¡éœ€è¦å¤šæ­¥éª¤æ¨ç†ã€è·¨è¡¨å…³è”å’Œå°†è§è§£ç»¼åˆæˆæŠ¥å‘Šã€‚è€Œä¸”ï¼Œç›®å‰å°šæ— å¯ç”¨äºå¼€å‘è‡ªåŠ¨RDB-DAæŠ¥å‘Šç”Ÿæˆçš„æ•°æ®é›†ã€‚ä¸ºäº†å¡«è¡¥è¿™ä¸€ç©ºç™½ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ä¸ªç”¨äºRDB-DAæŠ¥å‘Šç”Ÿæˆä»»åŠ¡çš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä»£ç†ç³»ç»Ÿï¼Œç§°ä¸ºDAgentï¼›æ­¤å¤–ï¼Œæˆ‘ä»¬æ„å»ºäº†ä¸€ä¸ªç”¨äºè‡ªåŠ¨æ•°æ®åˆ†ææŠ¥å‘Šç”Ÿæˆçš„æ ‡å‡†åŸºå‡†ï¼Œå…¶ä¸­åŒ…æ‹¬æ–°çš„æ•°æ®é›†DA-Datasetå’Œè¯„ä¼°æŒ‡æ ‡ã€‚DAgenté›†æˆäº†è§„åˆ’ã€å·¥å…·ã€è®°å¿†æ¨¡å—ï¼Œèƒ½å¤Ÿå°†è‡ªç„¶è¯­è¨€é—®é¢˜åˆ†è§£ä¸ºé€»è¾‘ä¸Šç‹¬ç«‹çš„å­æŸ¥è¯¢ï¼Œå‡†ç¡®ä»å…³ç³»æ•°æ®åº“ä¸­æ£€ç´¢å…³é”®ä¿¡æ¯ï¼Œå¹¶é€šè¿‡å¤šæ­¥éª¤æ¨ç†å’Œæœ‰æ•ˆçš„æ•°æ®é›†æˆç”Ÿæˆç¬¦åˆå®Œæ•´æ€§ã€æ­£ç¡®æ€§å’Œç®€æ´æ€§è¦æ±‚çš„åˆ†ææŠ¥å‘Šã€‚åœ¨DA-Datasetä¸Šçš„å®éªŒåˆ†æè¯æ˜äº†DAgentåœ¨æ£€ç´¢æ€§èƒ½å’Œåˆ†ææŠ¥å‘Šç”Ÿæˆè´¨é‡ä¸Šçš„ä¼˜è¶Šæ€§ï¼Œå±•ç¤ºäº†å…¶å¤„ç†å¤æ‚æ•°æ®åº“åˆ†ææŠ¥å‘Šç”Ÿæˆä»»åŠ¡çš„å¼ºå¤§æ½œåŠ›ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.13269v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†ä¸€ç§é¢å‘å…³ç³»æ•°æ®åº“æ•°æ®åˆ†ææŠ¥å‘Šç”Ÿæˆçš„LLMä»£ç†ç³»ç»Ÿâ€”â€”DAgentã€‚é’ˆå¯¹ç°æœ‰æ–¹æ³•çš„ä¸è¶³ï¼ŒDAgenté€šè¿‡æ•´åˆè§„åˆ’ã€å·¥å…·å’Œè®°å¿†æ¨¡å—ï¼Œèƒ½å¤Ÿå¤„ç†å¤æ‚çš„å¤šæ­¥æ¨ç†ã€è·¨è¡¨å…³è”å’ŒæŠ¥å‘Šç»¼åˆæ´å¯ŸåŠ›çš„ä»»åŠ¡ã€‚ä¸ºå¡«è¡¥è‡ªåŠ¨RDB-DAæŠ¥å‘Šç”Ÿæˆé¢†åŸŸçš„ç©ºç™½ï¼Œæœ¬æ–‡è¿˜æ„å»ºäº†ä¸€ä¸ªåŸºå‡†æµ‹è¯•ï¼ŒåŒ…æ‹¬æ–°çš„æ•°æ®é›†DA-Datasetå’Œè¯„ä¼°æŒ‡æ ‡ã€‚å®éªŒåˆ†æè¡¨æ˜ï¼ŒDAgentåœ¨æ£€ç´¢æ€§èƒ½å’Œåˆ†ææŠ¥å‘Šç”Ÿæˆè´¨é‡æ–¹é¢å…·æœ‰æ˜¾è‘—ä¼˜åŠ¿ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å…³ç³»æ•°æ®åº“é©±åŠ¨çš„æ•°æ®åˆ†ææŠ¥å‘Šç”Ÿæˆï¼ˆRDB-DAï¼‰åœ¨è´¢åŠ¡å’ŒåŒ»ç–—ç­‰é¢†åŸŸæœ‰å¹¿æ³›åº”ç”¨ï¼Œä½†ç°æœ‰æ–¹æ³•æ— æ³•å¤„ç†å¤æ‚çš„åˆ†æä»»åŠ¡ã€‚</li>
<li>ç›®å‰ç¼ºä¹é’ˆå¯¹è‡ªåŠ¨RDB-DAæŠ¥å‘Šç”Ÿæˆçš„æ•°æ®é›†ã€‚</li>
<li>DAgentæ˜¯ä¸€ä¸ªé¢å‘RDB-DAæŠ¥å‘Šç”Ÿæˆçš„LLMä»£ç†ç³»ç»Ÿï¼Œé€šè¿‡æ•´åˆè§„åˆ’ã€å·¥å…·å’Œè®°å¿†æ¨¡å—ï¼Œèƒ½å¤Ÿå¤„ç†å¤æ‚çš„å¤šæ­¥æ¨ç†å’Œè·¨è¡¨å…³è”ä»»åŠ¡ã€‚</li>
<li>DAgentç”Ÿæˆçš„åˆ†ææŠ¥å‘Šè¦æ±‚å®Œæ•´æ€§ã€æ­£ç¡®æ€§å’Œç®€æ´æ€§ã€‚</li>
<li>DA-Datasetæ˜¯ä¸ºè‡ªåŠ¨æ•°æ®åˆ†ææŠ¥å‘Šç”Ÿæˆè€Œæ„å»ºçš„æ–°æ•°æ®é›†ã€‚</li>
<li>å®éªŒåˆ†æè¡¨æ˜ï¼ŒDAgentåœ¨æ£€ç´¢æ€§èƒ½å’Œåˆ†ææŠ¥å‘Šç”Ÿæˆè´¨é‡æ–¹é¢è¡¨ç°å‡ºå“è¶Šçš„ä¼˜åŠ¿ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.13269">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-d9b29889ecaa0a528d6b83c8e64e7556.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-0fda211450446696f993bc2d33629d7f.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="MAP-Evaluation-and-Multi-Agent-Enhancement-of-Large-Language-Models-for-Inpatient-Pathways"><a href="#MAP-Evaluation-and-Multi-Agent-Enhancement-of-Large-Language-Models-for-Inpatient-Pathways" class="headerlink" title="MAP: Evaluation and Multi-Agent Enhancement of Large Language Models for   Inpatient Pathways"></a>MAP: Evaluation and Multi-Agent Enhancement of Large Language Models for   Inpatient Pathways</h2><p><strong>Authors:Zhen Chen, Zhihao Peng, Xusheng Liang, Cheng Wang, Peigan Liang, Linsheng Zeng, Minjie Ju, Yixuan Yuan</strong></p>
<p>Inpatient pathways demand complex clinical decision-making based on comprehensive patient information, posing critical challenges for clinicians. Despite advancements in large language models (LLMs) in medical applications, limited research focused on artificial intelligence (AI) inpatient pathways systems, due to the lack of large-scale inpatient datasets. Moreover, existing medical benchmarks typically concentrated on medical question-answering and examinations, ignoring the multifaceted nature of clinical decision-making in inpatient settings. To address these gaps, we first developed the Inpatient Pathway Decision Support (IPDS) benchmark from the MIMIC-IV database, encompassing 51,274 cases across nine triage departments and 17 major disease categories alongside 16 standardized treatment options. Then, we proposed the Multi-Agent Inpatient Pathways (MAP) framework to accomplish inpatient pathways with three clinical agents, including a triage agent managing the patient admission, a diagnosis agent serving as the primary decision maker at the department, and a treatment agent providing treatment plans. Additionally, our MAP framework includes a chief agent overseeing the inpatient pathways to guide and promote these three clinician agents. Extensive experiments showed our MAP improved the diagnosis accuracy by 25.10% compared to the state-of-the-art LLM HuatuoGPT2-13B. It is worth noting that our MAP demonstrated significant clinical compliance, outperforming three board-certified clinicians by 10%-12%, establishing a foundation for inpatient pathways systems. </p>
<blockquote>
<p>ä½é™¢è·¯å¾„éœ€è¦æ ¹æ®å…¨é¢çš„æ‚£è€…ä¿¡æ¯è¿›è¡Œå¤æ‚çš„ä¸´åºŠå†³ç­–ï¼Œè¿™å¯¹ä¸´åºŠåŒ»ç”Ÿæå‡ºäº†å·¨å¤§çš„æŒ‘æˆ˜ã€‚å°½ç®¡åŒ»ç–—åº”ç”¨ä¸­çš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æœ‰æ‰€è¿›å±•ï¼Œä½†ç”±äºç¼ºä¹å¤§è§„æ¨¡çš„ä½é™¢æ‚£è€…æ•°æ®é›†ï¼Œå…³äºäººå·¥æ™ºèƒ½ï¼ˆAIï¼‰ä½é™¢è·¯å¾„ç³»ç»Ÿçš„ç ”ç©¶æœ‰é™ã€‚æ­¤å¤–ï¼Œç°æœ‰çš„åŒ»ç–—åŸºå‡†æµ‹è¯•é€šå¸¸é›†ä¸­åœ¨åŒ»ç–—é—®é¢˜å›ç­”å’Œè€ƒè¯•ä¸Šï¼Œå¿½è§†äº†ä½é™¢ç¯å¢ƒä¸­ä¸´åºŠå†³ç­–çš„å¤šå…ƒåŒ–æ€§è´¨ã€‚ä¸ºäº†è§£å†³è¿™äº›å·®è·ï¼Œæˆ‘ä»¬é¦–å…ˆä»MIMIC-IVæ•°æ®åº“å¼€å‘ä½é™¢è·¯å¾„å†³ç­–æ”¯æŒï¼ˆIPDSï¼‰åŸºå‡†æµ‹è¯•ï¼Œæ¶µç›–51274ä¾‹è·¨è¶Šä¹ä¸ªæ€¥è¯Šéƒ¨é—¨å’Œ17ä¸ªä¸»è¦ç–¾ç—…ç±»åˆ«çš„ç—…ä¾‹ï¼Œä»¥åŠ16ç§æ ‡å‡†åŒ–æ²»ç–—æ–¹æ¡ˆã€‚æ¥ç€ï¼Œæˆ‘ä»¬æå‡ºäº†å¤šæ™ºèƒ½ä½“ä½é™¢è·¯å¾„ï¼ˆMAPï¼‰æ¡†æ¶ï¼Œé€šè¿‡ä¸‰ä¸ªæ™ºèƒ½ä½“å®Œæˆä½é™¢è·¯å¾„ï¼ŒåŒ…æ‹¬ç®¡ç†æ‚£è€…å…¥é™¢çš„é¦–è¯Šæ™ºèƒ½ä½“ã€ä½œä¸ºéƒ¨é—¨ä¸»è¦å†³ç­–è€…çš„è¯Šæ–­æ™ºèƒ½ä½“ã€ä»¥åŠæä¾›æ²»ç–—è®¡åˆ’çš„åŒ»ç–—æ™ºèƒ½ä½“ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬çš„MAPæ¡†æ¶è¿˜åŒ…æ‹¬ä¸€ä¸ªä¸»ç®¡ä½é™¢è·¯å¾„çš„é¦–å¸­æ™ºèƒ½ä½“ï¼Œä»¥æŒ‡å¯¼å’Œä¿ƒè¿›è¿™ä¸‰ä¸ªä¸´åºŠæ™ºèƒ½ä½“çš„åä½œã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼Œä¸æœ€å…ˆè¿›çš„LLMåå›¾GPT2-13Bç›¸æ¯”ï¼Œæˆ‘ä»¬çš„MAPæé«˜äº†25.10%çš„è¯Šæ–­å‡†ç¡®ç‡ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œæˆ‘ä»¬çš„MAPè¡¨ç°å‡ºæ˜¾è‘—çš„ä¸´åºŠåˆè§„æ€§ï¼Œæ¯”ä¸‰åä¸“ä¸šè®¤è¯çš„ä¸´åºŠåŒ»ç”Ÿé«˜å‡º10%-12%ï¼Œä¸ºä½é™¢è·¯å¾„ç³»ç»Ÿå¥ å®šäº†åŸºç¡€ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.13205v1">PDF</a> </p>
<p><strong>Summary</strong>ï¼š<br>åŸºäºæ‚£è€…å…¨é¢ä¿¡æ¯çš„ä½é™¢è·¯å¾„éœ€è¦å¤æ‚çš„ä¸´åºŠå†³ç­–ï¼Œå¯¹ä¸´åºŠåŒ»ç”Ÿæå‡ºäº†é‡å¤§æŒ‘æˆ˜ã€‚é’ˆå¯¹å¤§å‹è¯­è¨€æ¨¡å‹åœ¨åŒ»ç–—åº”ç”¨ä¸­çš„å‘å±•ï¼Œæœ¬ç ”ç©¶å¼€å‘äº†ä½é™¢è·¯å¾„å†³ç­–æ”¯æŒï¼ˆIPDSï¼‰åŸºå‡†æµ‹è¯•ï¼Œå¹¶æå‡ºäº†å¤šæ™ºèƒ½ä½“ä½é™¢è·¯å¾„ï¼ˆMAPï¼‰æ¡†æ¶ä»¥åº”å¯¹æŒ‘æˆ˜ã€‚è¯¥æ¡†æ¶åŒ…æ‹¬æ¥è¯Šæ™ºèƒ½ä½“ã€è¯Šæ–­æ™ºèƒ½ä½“å’Œæ²»ç–—æ™ºèƒ½ä½“ä¸‰å¤§æ™ºèƒ½ä½“ã€‚é€šè¿‡è¯•éªŒæ˜¾ç¤ºï¼Œä¸æœ€å…ˆè¿›çš„HuatuoGPT2-13Bå¤§å‹è¯­è¨€æ¨¡å‹ç›¸æ¯”ï¼Œè¯¥æ¡†æ¶çš„è¯Šæ–­å‡†ç¡®ç‡æé«˜äº†25.10%ï¼Œå¹¶åœ¨æ¨¡æ‹Ÿå®é™…ç¯å¢ƒä¸­å±•ç°å‡ºè‰¯å¥½çš„ä¸´åºŠåˆè§„æ€§ï¼Œè¶…è¶Šäº†ä¸‰ä½èµ„æ·±ä¸´åºŠåŒ»ç”Ÿçš„è¯Šæ–­å‡†ç¡®ç‡çº¦è¾¾åˆ°äº†çº¦ç™¾åˆ†ä¹‹åè‡³åäºŒã€‚</p>
<p><strong>Key Takeaways</strong>ï¼š</p>
<ul>
<li>ä½é™¢è·¯å¾„éœ€è¦åŸºäºå…¨é¢çš„æ‚£è€…ä¿¡æ¯çš„å¤æ‚ä¸´åºŠå†³ç­–ã€‚</li>
<li>å¤§å‹è¯­è¨€æ¨¡å‹åœ¨åŒ»ç–—åº”ç”¨ä¸­æœ‰ä¸€å®šçš„ä¼˜åŠ¿ï¼Œä½†åœ¨ä½é™¢è·¯å¾„ç³»ç»Ÿä¸­ç›¸å…³ç ”ç©¶ä»æœ‰é™ã€‚</li>
<li>ç¼ºä¹å¤§è§„æ¨¡ä½é™¢æ•°æ®é›†é™åˆ¶äº†AIåœ¨ä½é™¢è·¯å¾„çš„åº”ç”¨ã€‚</li>
<li>å¼€å‘ä½é™¢è·¯å¾„å†³ç­–æ”¯æŒåŸºå‡†æµ‹è¯•ï¼Œå¦‚IPDSåŸºå‡†æµ‹è¯•æ˜¯è§£å†³ä¸Šè¿°æŒ‘æˆ˜çš„é‡è¦ä¸€æ­¥ã€‚</li>
<li>MAPæ¡†æ¶ç”±æ¥è¯Šæ™ºèƒ½ä½“ã€è¯Šæ–­æ™ºèƒ½ä½“å’Œæ²»ç–—æ™ºèƒ½ä½“ä¸‰å¤§æ™ºèƒ½ä½“ç»„æˆï¼Œé€šè¿‡åˆ†å·¥åˆä½œå®ç°é«˜æ•ˆçš„ä½é™¢è·¯å¾„ç®¡ç†ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.13205">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-4c39294afb4295677f8760adb44c0eb3.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-305dbfea79f4780685946cf14e10f04c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-6997176d7e7957d8c9c6f01ea09568e2.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-33832616a409866126917e8aa04d03a0.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-653337cbb360d5a4a37587ecc1fbf707.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="Towards-Better-Sample-Efficiency-in-Multi-Agent-Reinforcement-Learning-via-Exploration"><a href="#Towards-Better-Sample-Efficiency-in-Multi-Agent-Reinforcement-Learning-via-Exploration" class="headerlink" title="Towards Better Sample Efficiency in Multi-Agent Reinforcement Learning   via Exploration"></a>Towards Better Sample Efficiency in Multi-Agent Reinforcement Learning   via Exploration</h2><p><strong>Authors:Amir Baghi, Jens SjÃ¶lund, Joakim Bergdahl, Linus GisslÃ©n, Alessandro Sestini</strong></p>
<p>Multi-agent reinforcement learning has shown promise in learning cooperative behaviors in team-based environments. However, such methods often demand extensive training time. For instance, the state-of-the-art method TiZero takes 40 days to train high-quality policies for a football environment. In this paper, we hypothesize that better exploration mechanisms can improve the sample efficiency of multi-agent methods. We propose two different approaches for better exploration in TiZero: a self-supervised intrinsic reward and a random network distillation bonus. Additionally, we introduce architectural modifications to the original algorithm to enhance TiZeroâ€™s computational efficiency. We evaluate the sample efficiency of these approaches through extensive experiments. Our results show that random network distillation improves training sample efficiency by 18.8% compared to the original TiZero. Furthermore, we evaluate the qualitative behavior of the models produced by both variants against a heuristic AI, with the self-supervised reward encouraging possession and random network distillation leading to a more offensive performance. Our results highlights the applicability of our random network distillation variant in practical settings. Lastly, due to the nature of the proposed method, we acknowledge its use beyond football simulation, especially in environments with strong multi-agent and strategic aspects. </p>
<blockquote>
<p>å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ åœ¨å›¢é˜Ÿç¯å¢ƒä¸­çš„å­¦ä¹ åˆä½œè¡Œä¸ºæ–¹é¢æ˜¾ç¤ºå‡ºæ½œåŠ›ã€‚ç„¶è€Œï¼Œè¿™äº›æ–¹æ³•é€šå¸¸éœ€è¦å¤§é‡çš„è®­ç»ƒæ—¶é—´ã€‚ä¾‹å¦‚ï¼Œç›®å‰æœ€å…ˆè¿›çš„æ–¹æ³•TiZeroåœ¨è¶³çƒç¯å¢ƒä¸­è®­ç»ƒé«˜è´¨é‡çš„ç­–ç•¥éœ€è¦40å¤©ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬å‡è®¾æ›´å¥½çš„æ¢ç´¢æœºåˆ¶å¯ä»¥æé«˜å¤šæ™ºèƒ½ä½“æ–¹æ³•çš„æ ·æœ¬æ•ˆç‡ã€‚æˆ‘ä»¬ä¸ºTiZeroæå‡ºäº†ä¸¤ç§æ›´å¥½çš„æ¢ç´¢æ–¹æ³•ï¼šè‡ªæˆ‘ç›‘ç£çš„å†…åœ¨å¥–åŠ±å’Œéšæœºç½‘ç»œè’¸é¦å¥–åŠ±ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å¯¹åŸå§‹ç®—æ³•è¿›è¡Œäº†æ¶æ„ä¿®æ”¹ï¼Œä»¥æé«˜TiZeroçš„è®¡ç®—æ•ˆç‡ã€‚æˆ‘ä»¬é€šè¿‡å¤§é‡çš„å®éªŒè¯„ä¼°äº†è¿™äº›æ–¹æ³•çš„æ ·æœ¬æ•ˆç‡ã€‚ç»“æœè¡¨æ˜ï¼Œä¸åŸå§‹TiZeroç›¸æ¯”ï¼Œéšæœºç½‘ç»œè’¸é¦å°†è®­ç»ƒæ ·æœ¬æ•ˆç‡æé«˜äº†18.8%ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å°†è¿™ä¸¤ç§å˜ä½“äº§ç”Ÿçš„æ¨¡å‹ä¸å¯å‘å¼AIè¿›è¡Œäº†å®šæ€§è¡Œä¸ºè¯„ä¼°ï¼Œè‡ªæˆ‘ç›‘ç£å¥–åŠ±é¼“åŠ±æ§çƒï¼Œè€Œéšæœºç½‘ç»œè’¸é¦åˆ™å¯¼è‡´æ›´è¿›æ”»æ€§çš„è¡¨ç°ã€‚æˆ‘ä»¬çš„ç»“æœçªå‡ºäº†éšæœºç½‘ç»œè’¸é¦å˜ä½“åœ¨å®é™…åº”ç”¨ä¸­çš„é€‚ç”¨æ€§ã€‚æœ€åï¼Œç”±äºæ‰€ææ–¹æ³•çš„ç‰¹ç‚¹ï¼Œæˆ‘ä»¬è®¤è¯†åˆ°å…¶ä¸ä»…é€‚ç”¨äºè¶³çƒæ¨¡æ‹Ÿï¼Œå°¤å…¶é€‚ç”¨äºå…·æœ‰å¼ºçƒˆå¤šæ™ºèƒ½ä½“å’Œæˆ˜ç•¥æ–¹é¢çš„ç¯å¢ƒã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.13077v1">PDF</a> 8 pages, 3 figures</p>
<p><strong>Summary</strong></p>
<p>æœ¬è®ºæ–‡é’ˆå¯¹å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ åœ¨å›¢é˜Ÿç¯å¢ƒä¸­çš„åˆä½œè¡Œä¸ºå­¦ä¹ è¿›è¡Œäº†æ¢ç´¢ï¼Œå‘ç°ç°æœ‰æ–¹æ³•è®­ç»ƒæ—¶é—´é•¿ã€‚ä¸ºæ­¤ï¼Œæå‡ºä¸¤ç§æ”¹è¿›æ¢ç´¢æœºåˆ¶çš„æ–¹æ³•ï¼Œå³è‡ªç›‘ç£å†…åœ¨å¥–åŠ±å’Œéšæœºç½‘ç»œè’¸é¦å¥–åŠ±ï¼Œå¹¶å¯¹åŸæœ‰ç®—æ³•è¿›è¡Œæ¶æ„ä¿®æ”¹ä»¥æé«˜è®¡ç®—æ•ˆç‡ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œéšæœºç½‘ç»œè’¸é¦æé«˜äº†æ ·æœ¬æ•ˆç‡ï¼Œå¹¶ä¸”æ‰€æå‡ºçš„æ–¹æ³•åœ¨è¶³çƒæ¨¡æ‹Ÿç¯å¢ƒä¸­è¡¨ç°å‡ºæ›´å¥½çš„è¿›æ”»æ€§èƒ½ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•è¿˜å¯åº”ç”¨äºå…¶ä»–å…·æœ‰å¼ºå¤šæ™ºèƒ½ä½“å’Œæˆ˜ç•¥æ–¹é¢çš„ç¯å¢ƒã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ åœ¨å›¢é˜Ÿç¯å¢ƒä¸­å­¦ä¹ åˆä½œè¡Œä¸ºå…·æœ‰æ½œåŠ›ï¼Œä½†è®­ç»ƒæ—¶é—´é•¿ã€‚</li>
<li>æå‡ºä¸¤ç§æ”¹è¿›æ¢ç´¢æœºåˆ¶çš„æ–¹æ³•ï¼šè‡ªç›‘ç£å†…åœ¨å¥–åŠ±å’Œéšæœºç½‘ç»œè’¸é¦å¥–åŠ±ã€‚</li>
<li>æ¶æ„ä¿®æ”¹æé«˜äº†åŸæœ‰ç®—æ³•çš„è®¡ç®—æ•ˆç‡ã€‚</li>
<li>éšæœºç½‘ç»œè’¸é¦æé«˜äº†æ ·æœ¬æ•ˆç‡ï¼Œç›¸è¾ƒäºåŸå§‹æ–¹æ³•æå‡äº†18.8%ã€‚</li>
<li>è‡ªç›‘ç£å¥–åŠ±é¼“åŠ±æŒæœ‰çƒæƒï¼Œè€Œéšæœºç½‘ç»œè’¸é¦å¯¼è‡´æ›´è¿›æ”»æ€§çš„è¡¨ç°ã€‚</li>
<li>æ–¹æ³•åœ¨è¶³çƒæ¨¡æ‹Ÿç¯å¢ƒä¸­è¡¨ç°è‰¯å¥½ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.13077">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-2e549fa383dcb3453a5e7dd2439db2a7.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-2afa8acacf44bac1d2411612b184ec31.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-7761dd6732d34e8aaa58facb8f002394.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-5010547669abe772c9d3a55c621f4b44.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="Identifying-Cooperative-Personalities-in-Multi-agent-Contexts-through-Personality-Steering-with-Representation-Engineering"><a href="#Identifying-Cooperative-Personalities-in-Multi-agent-Contexts-through-Personality-Steering-with-Representation-Engineering" class="headerlink" title="Identifying Cooperative Personalities in Multi-agent Contexts through   Personality Steering with Representation Engineering"></a>Identifying Cooperative Personalities in Multi-agent Contexts through   Personality Steering with Representation Engineering</h2><p><strong>Authors:Kenneth J. K. Ong, Lye Jia Jun, Hieu Minh â€œJordâ€ Nguyen, Seong Hah Cho, Natalia PÃ©rez-Campanero AntolÃ­n</strong></p>
<p>As Large Language Models (LLMs) gain autonomous capabilities, their coordination in multi-agent settings becomes increasingly important. However, they often struggle with cooperation, leading to suboptimal outcomes. Inspired by Axelrodâ€™s Iterated Prisonerâ€™s Dilemma (IPD) tournaments, we explore how personality traits influence LLM cooperation. Using representation engineering, we steer Big Five traits (e.g., Agreeableness, Conscientiousness) in LLMs and analyze their impact on IPD decision-making. Our results show that higher Agreeableness and Conscientiousness improve cooperation but increase susceptibility to exploitation, highlighting both the potential and limitations of personality-based steering for aligning AI agents. </p>
<blockquote>
<p>éšç€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰è·å¾—è‡ªä¸»èƒ½åŠ›ï¼Œå®ƒä»¬åœ¨å¤šæ™ºèƒ½ä½“ç¯å¢ƒä¸­çš„åè°ƒå˜å¾—æ„ˆå‘é‡è¦ã€‚ç„¶è€Œï¼Œå®ƒä»¬åœ¨åˆä½œæ–¹é¢ç»å¸¸é‡åˆ°å›°éš¾ï¼Œå¯¼è‡´ç»“æœä¸å°½å¦‚äººæ„ã€‚å—è‰¾å…‹å¡å°”ç½—å¾·é‡å¤å›šå¾’å›°å¢ƒï¼ˆIPDï¼‰é”¦æ ‡èµ›çš„å¯å‘ï¼Œæˆ‘ä»¬æ¢ç´¢äº†äººæ ¼ç‰¹è´¨å¦‚ä½•å½±å“LLMåˆä½œã€‚æˆ‘ä»¬ä½¿ç”¨è¡¨å¾å·¥ç¨‹æ¥å¼•å¯¼LLMä¸­çš„äº”å¤§ç‰¹è´¨ï¼ˆä¾‹å¦‚ï¼Œå‹å–„æ€§ã€å°½è´£æ€§ï¼‰ï¼Œå¹¶åˆ†æå®ƒä»¬å¯¹IPDå†³ç­–åˆ¶å®šçš„å½±å“ã€‚æˆ‘ä»¬çš„ç»“æœè¡¨æ˜ï¼Œè¾ƒé«˜çš„å‹å–„æ€§å’Œå°½è´£æ€§å¯ä»¥æé«˜åˆä½œæ°´å¹³ï¼Œä½†ä¹Ÿä¼šå¢åŠ è¢«åˆ©ç”¨çš„é£é™©ï¼Œä»è€Œçªå‡ºäº†åŸºäºäººæ ¼å¼•å¯¼åœ¨ä½¿AIæ™ºèƒ½ä½“ååŒæ–¹é¢çš„æ½œåŠ›å’Œå±€é™æ€§ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.12722v1">PDF</a> Poster, Technical AI Safety Conference 2025</p>
<p><strong>Summary</strong></p>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨è·å¾—è‡ªä¸»èƒ½åŠ›åï¼Œåœ¨å¤šæ™ºèƒ½ä½“ç¯å¢ƒä¸­çš„åä½œå˜å¾—å°¤ä¸ºé‡è¦ã€‚ç„¶è€Œï¼Œå®ƒä»¬åœ¨åˆä½œæ–¹é¢ç»å¸¸é‡åˆ°å›°éš¾ï¼Œå¯¼è‡´ç»“æœä¸å°½å¦‚äººæ„ã€‚æœ¬ç ”ç©¶å—åˆ°é˜¿å…‹å¡å°”ç½—å¾·çš„é‡å¤å›šå¾’å›°å¢ƒï¼ˆIPDï¼‰é”¦æ ‡èµ›çš„å¯å‘ï¼Œæ¢è®¨äº†äººæ ¼ç‰¹è´¨å¦‚ä½•å½±å“LLMçš„åˆä½œã€‚é€šè¿‡è¡¨å¾å·¥ç¨‹ï¼Œæˆ‘ä»¬å¼•å¯¼äº”å¤§äººæ ¼ç‰¹è´¨ï¼ˆä¾‹å¦‚ï¼Œå‹å–„æ€§ã€å°½è´£æ€§ï¼‰åœ¨LLMä¸­ï¼Œå¹¶åˆ†æå®ƒä»¬å¯¹IPDå†³ç­–åˆ¶å®šçš„å½±å“ã€‚ç»“æœè¡¨æ˜ï¼Œè¾ƒé«˜çš„å‹å–„æ€§å’Œå°½è´£æ€§æœ‰åŠ©äºæé«˜åˆä½œèƒ½åŠ›ï¼Œä½†åŒæ—¶ä¹Ÿå¢åŠ äº†è¢«åˆ©ç”¨çš„é£é™©ï¼Œçªæ˜¾äº†åŸºäºäººæ ¼å¼•å¯¼åœ¨äººå·¥æ™ºèƒ½ä»£ç†ä¸­çš„æ½œåŠ›å’Œå±€é™æ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨å¤šæ™ºèƒ½ä½“ç¯å¢ƒä¸­çš„åä½œè‡³å…³é‡è¦ã€‚</li>
<li>LLMåœ¨åˆä½œæ–¹é¢é¢ä¸´æŒ‘æˆ˜ï¼Œå¸¸å¸¸å¯¼è‡´ç»“æœä¸å°½å¦‚äººæ„ã€‚</li>
<li>äººæ ¼ç‰¹è´¨å½±å“LLMåœ¨IPDå†³ç­–åˆ¶å®šä¸­çš„åˆä½œè¡Œä¸ºã€‚</li>
<li>ä½¿ç”¨è¡¨å¾å·¥ç¨‹æ¥å¼•å¯¼LLMçš„äº”å¤§äººæ ¼ç‰¹è´¨ï¼ˆå‹å–„æ€§ã€å°½è´£æ€§ç­‰ï¼‰ã€‚</li>
<li>é«˜å‹å–„æ€§å’Œå°½è´£æ€§èƒ½å¤Ÿæé«˜LLMçš„åˆä½œèƒ½åŠ›ã€‚</li>
<li>ç„¶è€Œï¼Œæé«˜å‹å–„æ€§å’Œå°½è´£æ€§çš„LLMæ›´å®¹æ˜“å—åˆ°åˆ©ç”¨ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.12722">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-4aa0ac66632414975d75421ae11bc5ef.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-d1ca884335c9a35df8276ce30258b39d.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-2741cfff886cf1c24d8f1f3bee689762.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-5cb44632131f116b68a9142d795786f2.jpg" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="AI-Agents-Evolution-Architecture-and-Real-World-Applications"><a href="#AI-Agents-Evolution-Architecture-and-Real-World-Applications" class="headerlink" title="AI Agents: Evolution, Architecture, and Real-World Applications"></a>AI Agents: Evolution, Architecture, and Real-World Applications</h2><p><strong>Authors:Naveen Krishnan</strong></p>
<p>This paper examines the evolution, architecture, and practical applications of AI agents from their early, rule-based incarnations to modern sophisticated systems that integrate large language models with dedicated modules for perception, planning, and tool use. Emphasizing both theoretical foundations and real-world deployments, the paper reviews key agent paradigms, discusses limitations of current evaluation benchmarks, and proposes a holistic evaluation framework that balances task effectiveness, efficiency, robustness, and safety. Applications across enterprise, personal assistance, and specialized domains are analyzed, with insights into future research directions for more resilient and adaptive AI agent systems. </p>
<blockquote>
<p>æœ¬æ–‡æ¢è®¨äº†äººå·¥æ™ºèƒ½ä»£ç†çš„æ¼”å˜ã€æ¶æ„å’Œå®é™…åº”ç”¨ç¨‹åºï¼Œä»æ—©æœŸåŸºäºè§„åˆ™çš„å½¢å¼å‘å±•åˆ°ç°ä»£å…ˆè¿›çš„ç³»ç»Ÿï¼Œè¿™äº›ç³»ç»Ÿé›†æˆäº†å¤§å‹è¯­è¨€æ¨¡å‹ï¼Œå¹¶æ‹¥æœ‰ä¸“é—¨çš„æ„ŸçŸ¥ã€è§„åˆ’å’Œå·¥å…·ä½¿ç”¨æ¨¡å—ã€‚æœ¬æ–‡å¼ºè°ƒç†è®ºåŸºç¡€å’Œå®é™…åº”ç”¨éƒ¨ç½²ï¼Œå›é¡¾äº†å…³é”®ä»£ç†èŒƒå¼ï¼Œè®¨è®ºäº†å½“å‰è¯„ä¼°åŸºå‡†çš„å±€é™æ€§ï¼Œå¹¶æå‡ºäº†ä¸€ä¸ªå…¨é¢çš„è¯„ä¼°æ¡†æ¶ï¼Œè¯¥æ¡†æ¶å¹³è¡¡äº†ä»»åŠ¡çš„æœ‰æ•ˆæ€§ã€æ•ˆç‡ã€é²æ£’æ€§å’Œå®‰å…¨æ€§ã€‚åˆ†æäº†åœ¨ä¼ä¸šã€ä¸ªäººåŠ©ç†å’Œç‰¹æ®Šé¢†åŸŸçš„åº”ç”¨ï¼Œå¹¶æ·±å…¥æ¢è®¨äº†æœªæ¥ç ”ç©¶æ–¹å‘ï¼Œä»¥ä¾¿å»ºç«‹æ›´åŠ çµæ´»å’Œé€‚åº”æ€§æ›´å¼ºçš„äººå·¥æ™ºèƒ½ä»£ç†ç³»ç»Ÿã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.12687v1">PDF</a> 52 pages, 4 figures, comprehensive survey and analysis of AI agent   evolution, architecture, evaluation frameworks, and applications</p>
<p><strong>Summary</strong><br>äººå·¥æ™ºèƒ½ä»£ç†äººçš„æ¼”å˜ã€æ¶æ„å’Œå®é™…åº”ç”¨ä»æ—©æœŸçš„è§„åˆ™åŸºç¡€å½¢æ€åˆ°ç°ä»£é›†æˆäº†å¤§å‹è¯­è¨€æ¨¡å‹çš„ä¸“ä¸šç³»ç»Ÿå¾—åˆ°äº†è¯¦å°½çš„æ¢è®¨ã€‚è¯¥è®ºæ–‡å¼ºè°ƒäº†ç†è®ºåŸºç¡€çš„ç°å®åº”ç”¨éƒ¨ç½²ï¼Œå›é¡¾äº†å…³é”®ä»£ç†èŒƒå¼ï¼Œè®¨è®ºäº†å½“å‰è¯„ä¼°åŸºå‡†çš„å±€é™æ€§ï¼Œå¹¶æå‡ºäº†ä¸€ä¸ªå¹³è¡¡ä»»åŠ¡æœ‰æ•ˆæ€§ã€æ•ˆç‡ã€å¥å£®æ€§å’Œå®‰å…¨æ€§çš„å…¨é¢è¯„ä¼°æ¡†æ¶ã€‚å…³äºåœ¨ä¼ä¸šã€ä¸ªäººåŠ©ç†å’Œä¸“é—¨é¢†åŸŸçš„åº”ç”¨è¿›è¡Œäº†æ·±å…¥åˆ†æï¼Œå¹¶æ´å¯Ÿäº†æœªæ¥æ›´å…·å¼¹æ€§å’Œé€‚åº”æ€§çš„AIä»£ç†äººç³»ç»Ÿçš„ç ”ç©¶æ–¹å‘ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>äººå·¥æ™ºèƒ½ä»£ç†äººä»æ—©æœŸçš„è§„åˆ™åŸºç¡€å½¢æ€è¿›åŒ–åˆ°ç°ä»£é›†æˆå¤§å‹è¯­è¨€æ¨¡å‹çš„ç³»ç»Ÿã€‚</li>
<li>è®ºæ–‡æ¢è®¨äº†AIä»£ç†äººçš„æ¶æ„æ¼”å˜åŠå…¶å®è·µåº”ç”¨ã€‚</li>
<li>è®ºæ–‡å¼ºè°ƒAIä»£ç†äººçš„ç†è®ºåŸºç¡€å’Œç°å®ä¸–ç•Œéƒ¨ç½²çš„é‡è¦æ€§ã€‚</li>
<li>è®ºæ–‡å›é¡¾äº†å…³é”®çš„AIä»£ç†äººèŒƒå¼ã€‚</li>
<li>å½“å‰è¯„ä¼°åŸºå‡†å­˜åœ¨å±€é™æ€§ï¼Œéœ€è¦æ›´å…¨é¢ã€å¹³è¡¡çš„è¯„ä¼°æ¡†æ¶ã€‚</li>
<li>è®ºæ–‡åˆ†æäº†AIä»£ç†äººåœ¨ä¼ä¸šã€ä¸ªäººåŠ©ç†å’Œä¸“é—¨é¢†åŸŸçš„åº”ç”¨ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.12687">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-60ad82153afb709a5bcaf394396f51e5.jpg" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1><h2 id="Being-0-A-Humanoid-Robotic-Agent-with-Vision-Language-Models-and-Modular-Skills"><a href="#Being-0-A-Humanoid-Robotic-Agent-with-Vision-Language-Models-and-Modular-Skills" class="headerlink" title="Being-0: A Humanoid Robotic Agent with Vision-Language Models and   Modular Skills"></a>Being-0: A Humanoid Robotic Agent with Vision-Language Models and   Modular Skills</h2><p><strong>Authors:Haoqi Yuan, Yu Bai, Yuhui Fu, Bohan Zhou, Yicheng Feng, Xinrun Xu, Yi Zhan, BÃ¶rje F. Karlsson, Zongqing Lu</strong></p>
<p>Building autonomous robotic agents capable of achieving human-level performance in real-world embodied tasks is an ultimate goal in humanoid robot research. Recent advances have made significant progress in high-level cognition with Foundation Models (FMs) and low-level skill development for humanoid robots. However, directly combining these components often results in poor robustness and efficiency due to compounding errors in long-horizon tasks and the varied latency of different modules. We introduce Being-0, a hierarchical agent framework that integrates an FM with a modular skill library. The FM handles high-level cognitive tasks such as instruction understanding, task planning, and reasoning, while the skill library provides stable locomotion and dexterous manipulation for low-level control. To bridge the gap between these levels, we propose a novel Connector module, powered by a lightweight vision-language model (VLM). The Connector enhances the FMâ€™s embodied capabilities by translating language-based plans into actionable skill commands and dynamically coordinating locomotion and manipulation to improve task success. With all components, except the FM, deployable on low-cost onboard computation devices, Being-0 achieves efficient, real-time performance on a full-sized humanoid robot equipped with dexterous hands and active vision. Extensive experiments in large indoor environments demonstrate Being-0â€™s effectiveness in solving complex, long-horizon tasks that require challenging navigation and manipulation subtasks. For further details and videos, visit <a target="_blank" rel="noopener" href="https://beingbeyond.github.io/being-0">https://beingbeyond.github.io/being-0</a>. </p>
<blockquote>
<p>æ„å»ºèƒ½å¤Ÿåœ¨çœŸå®ä¸–ç•Œä¸­çš„å®ä½“ä»»åŠ¡ä¸­å®ç°äººç±»æ°´å¹³æ€§èƒ½çš„è‡ªä¸»æœºå™¨äººä»£ç†ï¼Œæ˜¯äººç±»å‹æœºå™¨äººç ”ç©¶çš„ç»ˆæç›®æ ‡ã€‚æœ€è¿‘çš„è¿›å±•åœ¨é«˜å±‚æ¬¡çš„è®¤çŸ¥ä¸åŸºç¡€æ¨¡å‹ï¼ˆFMsï¼‰ä»¥åŠäººç±»æœºå™¨äººçš„ä½çº§æŠ€èƒ½å‘å±•æ–¹é¢éƒ½å–å¾—äº†é‡å¤§è¿›å±•ã€‚ç„¶è€Œï¼Œç›´æ¥å°†è¿™ä¸¤ä¸ªç»„ä»¶ç»“åˆé€šå¸¸ä¼šå¯¼è‡´é•¿æœŸä»»åŠ¡çš„é²æ£’æ€§å’Œæ•ˆç‡è¾ƒå·®ï¼Œä»¥åŠä¸åŒæ¨¡å—çš„å»¶è¿Ÿå·®å¼‚ã€‚æˆ‘ä»¬å¼•å…¥äº†Being-0ï¼Œè¿™æ˜¯ä¸€ä¸ªå±‚æ¬¡åŒ–çš„ä»£ç†æ¡†æ¶ï¼Œå®ƒæ•´åˆäº†åŸºç¡€æ¨¡å‹å’Œä¸€ä¸ªæ¨¡å—åŒ–æŠ€èƒ½åº“ã€‚åŸºç¡€æ¨¡å‹å¤„ç†é«˜çº§è®¤çŸ¥ä»»åŠ¡ï¼Œå¦‚æŒ‡ä»¤ç†è§£ã€ä»»åŠ¡è§„åˆ’å’Œæ¨ç†ï¼Œè€ŒæŠ€èƒ½åº“åˆ™æä¾›ç¨³å®šçš„è¿åŠ¨å’Œçµæ´»çš„æ“æ§èƒ½åŠ›ä»¥å®ç°ä½çº§æ§åˆ¶ã€‚ä¸ºäº†å¡«è¡¥è¿™äº›å±‚æ¬¡ä¹‹é—´çš„é¸¿æ²Ÿï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°å‹è¿æ¥å™¨æ¨¡å—ï¼Œå®ƒç”±è½»é‡çº§è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMï¼‰é©±åŠ¨ã€‚è¿æ¥å™¨é€šè¿‡ç¿»è¯‘åŸºäºè¯­è¨€çš„è®¡åˆ’ä¸ºå¯æ“ä½œçš„æŠ€èƒ½å‘½ä»¤ï¼Œå¹¶åŠ¨æ€åè°ƒè¿åŠ¨å’Œæ“æ§èƒ½åŠ›ï¼Œä»è€Œæå‡åŸºç¡€æ¨¡å‹çš„å®ä½“èƒ½åŠ›ã€‚é™¤äº†åŸºç¡€æ¨¡å‹å¤–ï¼Œæ‰€æœ‰ç»„ä»¶éƒ½éƒ¨ç½²åœ¨ä½æˆæœ¬çš„å†…è½½è®¡ç®—è®¾å¤‡ä¸Šï¼ŒBeing-0åœ¨å…¨å°ºå¯¸çš„äººç±»æœºå™¨äººä¸Šå®ç°äº†é«˜æ•ˆçš„å®æ—¶æ€§èƒ½ï¼Œè¯¥æœºå™¨äººé…å¤‡äº†çµæ´»çš„åŒæ‰‹å’Œä¸»åŠ¨è§†è§‰ã€‚åœ¨å¤§è§„æ¨¡å®¤å†…ç¯å¢ƒä¸­çš„å¤§é‡å®éªŒè¯æ˜äº†Being-0åœ¨è§£å†³å¤æ‚ã€é•¿æœŸçš„å¯¼èˆªå’Œæ“æ§ä»»åŠ¡æ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚æ›´å¤šè¯¦æƒ…å’Œè§†é¢‘è¯·è®¿é—®ï¼š<a target="_blank" rel="noopener" href="https://beingbeyond.github.io/being-0%E3%80%82">https://beingbeyond.github.io/being-0ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.12533v1">PDF</a> </p>
<p><strong>Summary</strong><br>å®ç°è‡ªä¸»æœºå™¨äººå®ç°äººç±»æ°´å¹³çš„çœŸå®ä¸–ç•Œä»»åŠ¡ä»æ˜¯æœºå™¨äººç ”ç©¶çš„é‡è¦ç›®æ ‡ã€‚è¿‘æœŸå‘å±•é«˜çº§è®¤çŸ¥çš„Foundation Modelså’Œä½çº§æŠ€èƒ½çš„humanoidæœºå™¨äººå·²å–å¾—è¿›å±•ï¼Œä½†ä¸¤è€…ç»“åˆæ—¶ä»é¢ä¸´é²æ£’æ€§å’Œæ•ˆç‡é—®é¢˜ã€‚æˆ‘ä»¬æ¨å‡ºBeing-0ï¼Œä¸€ç§é›†æˆFoundation Modelå’Œæ¨¡å—åŒ–æŠ€èƒ½åº“çš„åˆ†å±‚æ™ºèƒ½ä½“æ¡†æ¶ï¼Œå€ŸåŠ©è§†è§‰è¯­è¨€æ¨¡å‹æ¥å¼¥åˆé«˜è®¤çŸ¥å’Œä½æ§åˆ¶ä¹‹é—´çš„å·®è·ã€‚è¯¥æ¡†æ¶å¯å®ç°é«˜æ•ˆå®æ—¶æ€§èƒ½ï¼Œåœ¨é…å¤‡çµå·§æ‰‹å’Œä¸»åŠ¨è§†è§‰çš„å…¨å°ºå¯¸äººå½¢æœºå™¨äººä¸Šå±•ç¤ºæœ‰æ•ˆå®Œæˆå¤æ‚é•¿æœŸä»»åŠ¡çš„èƒ½åŠ›ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>Building human-level performance in real-world tasks remains a key goal in humanoid robot research.</li>
<li>Recent advances have been made in both high-level cognition with Foundation Models (FMs) and low-level skill development for humanoid robots.</li>
<li>Direct combination of FM and low-level skills often leads to poor robustness and efficiency due to compounding errors and module latency.</li>
<li>Being-0 introduces a hierarchical agent framework that integrates FM with a modular skill library, enhancing high-level cognitive tasks and low-level control.</li>
<li>The Connector module, powered by a lightweight vision-language model (VLM), bridges the gap between high and low levels, translating language-based plans into actionable skill commands and coordinating locomotion and manipulation.</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.12533">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-016338fe0afbbe9e58269982cb278c80.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-6e023b873a4405186db6379b15919ad2.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-22d68ef2c5998b5230fdab2ddaaab48d.jpg" align="middle">
</details>


<h1 id="-9"><a href="#-9" class="headerlink" title=""></a></h1><h2 id="Long-Video-Audio-Synthesis-with-Multi-Agent-Collaboration"><a href="#Long-Video-Audio-Synthesis-with-Multi-Agent-Collaboration" class="headerlink" title="Long-Video Audio Synthesis with Multi-Agent Collaboration"></a>Long-Video Audio Synthesis with Multi-Agent Collaboration</h2><p><strong>Authors:Yehang Zhang, Xinli Xu, Xiaojie Xu, Li Liu, Yingcong Chen</strong></p>
<p>Video-to-audio synthesis, which generates synchronized audio for visual content, critically enhances viewer immersion and narrative coherence in film and interactive media. However, video-to-audio dubbing for long-form content remains an unsolved challenge due to dynamic semantic shifts, temporal misalignment, and the absence of dedicated datasets. While existing methods excel in short videos, they falter in long scenarios (e.g., movies) due to fragmented synthesis and inadequate cross-scene consistency. We propose LVAS-Agent, a novel multi-agent framework that emulates professional dubbing workflows through collaborative role specialization. Our approach decomposes long-video synthesis into four steps including scene segmentation, script generation, sound design and audio synthesis. Central innovations include a discussion-correction mechanism for scene&#x2F;script refinement and a generation-retrieval loop for temporal-semantic alignment. To enable systematic evaluation, we introduce LVAS-Bench, the first benchmark with 207 professionally curated long videos spanning diverse scenarios. Experiments demonstrate superior audio-visual alignment over baseline methods. Project page: <a target="_blank" rel="noopener" href="https://lvas-agent.github.io/">https://lvas-agent.github.io</a> </p>
<blockquote>
<p>è§†é¢‘åˆ°éŸ³é¢‘çš„åˆæˆæŠ€æœ¯ä¸ºè§†è§‰å†…å®¹ç”ŸæˆåŒæ­¥éŸ³é¢‘ï¼Œæå¤§åœ°å¢å¼ºäº†è§‚ä¼—åœ¨ç”µå½±å’Œäº¤äº’åª’ä½“ä¸­çš„æ²‰æµ¸æ„Ÿå’Œå™äº‹è¿è´¯æ€§ã€‚ç„¶è€Œï¼Œç”±äºåŠ¨æ€è¯­ä¹‰è½¬æ¢ã€æ—¶é—´é”™ä½ä»¥åŠç¼ºä¹ä¸“ç”¨æ•°æ®é›†ï¼Œé•¿å†…å®¹çš„è§†é¢‘åˆ°éŸ³é¢‘é…éŸ³ä»ç„¶æ˜¯ä¸€ä¸ªæœªè§£å†³çš„éš¾é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨çŸ­è§†é¢‘ä¸Šè¡¨ç°ä¼˜å¼‚ï¼Œä½†åœ¨é•¿åœºæ™¯ï¼ˆå¦‚ç”µå½±ï¼‰ä¸­ç”±äºåˆæˆç‰‡æ®µåŒ–å’Œè·¨åœºæ™¯è¿è´¯æ€§ä¸è¶³è€Œè¡¨ç°ä¸ä½³ã€‚æˆ‘ä»¬æå‡ºäº†LVAS-Agentï¼Œä¸€ç§æ–°å‹å¤šæ™ºèƒ½ä½“æ¡†æ¶ï¼Œé€šè¿‡åä½œè§’è‰²ä¸“ä¸šåŒ–æ¨¡æ‹Ÿä¸“ä¸šé…éŸ³å·¥ä½œæµç¨‹ã€‚æˆ‘ä»¬çš„æ–¹æ³•å°†é•¿è§†é¢‘åˆæˆåˆ†è§£æˆå››ä¸ªæ­¥éª¤ï¼ŒåŒ…æ‹¬åœºæ™¯åˆ†å‰²ã€å‰§æœ¬ç”Ÿæˆã€å£°éŸ³è®¾è®¡å’ŒéŸ³é¢‘åˆæˆã€‚ä¸»è¦åˆ›æ–°ç‚¹åŒ…æ‹¬ç”¨äºåœºæ™¯&#x2F;å‰§æœ¬ç²¾ç»†åŒ–çš„è®¨è®ºæ ¡æ­£æœºåˆ¶å’Œç”¨äºæ—¶é—´è¯­ä¹‰å¯¹é½çš„ç”Ÿæˆæ£€ç´¢å¾ªç¯ã€‚ä¸ºäº†è¿›è¡Œç³»ç»Ÿè¯„ä¼°ï¼Œæˆ‘ä»¬å¼•å…¥äº†LVAS-Benchï¼Œè¿™æ˜¯ç¬¬ä¸€ä¸ªåŒ…å«207ä¸ªä¸“ä¸šç­–åˆ’çš„é•¿è§†é¢‘ã€æ¶µç›–å„ç§åœºæ™¯çš„åŸºå‡†æµ‹è¯•ã€‚å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨éŸ³é¢‘è§†è§‰å¯¹é½æ–¹é¢ä¼˜äºåŸºçº¿æ–¹æ³•ã€‚é¡¹ç›®é¡µé¢ï¼š<a target="_blank" rel="noopener" href="https://lvas-agent.github.io/">https://lvas-agent.github.io</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.10719v2">PDF</a> </p>
<p><strong>Summary</strong><br>è§†é¢‘è½¬éŸ³é¢‘åˆæˆæŠ€æœ¯ä¸ºè§†è§‰å†…å®¹ç”ŸæˆåŒæ­¥éŸ³é¢‘ï¼Œæ˜¾è‘—å¢å¼ºäº†ç”µå½±å’Œäº¤äº’å¼åª’ä½“ä¸­çš„è§‚ä¼—æ²‰æµ¸æ„Ÿå’Œå™äº‹è¿è´¯æ€§ã€‚ç„¶è€Œï¼Œå¯¹äºé•¿æ ¼å¼å†…å®¹çš„è§†é¢‘è½¬éŸ³é¢‘é…éŸ³ä»ç„¶å­˜åœ¨æŒ‘æˆ˜ï¼Œå¦‚åŠ¨æ€è¯­ä¹‰å˜åŒ–ã€æ—¶é—´ä¸å¯¹é½å’Œç¼ºä¹ä¸“ç”¨æ•°æ®é›†ã€‚ç°æœ‰æ–¹æ³•åœ¨çŸ­è§†é¢‘ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œä½†åœ¨é•¿åœºæ™¯ï¼ˆå¦‚ç”µå½±ï¼‰ä¸­å› åˆæˆç‰‡æ®µåŒ–å’Œè·¨åœºæ™¯ä¸€è‡´æ€§ä¸è¶³è€Œè¡¨ç°ä¸ä½³ã€‚æˆ‘ä»¬æå‡ºLVAS-Agentï¼Œä¸€ç§æ–°å‹å¤šä»£ç†æ¡†æ¶ï¼Œé€šè¿‡åä½œè§’è‰²ä¸“ä¸šåŒ–æ¨¡æ‹Ÿä¸“ä¸šé…éŸ³å·¥ä½œæµç¨‹ã€‚æˆ‘ä»¬çš„æ–¹æ³•å°†é•¿è§†é¢‘åˆæˆåˆ†è§£ä¸ºå››ä¸ªæ­¥éª¤ï¼ŒåŒ…æ‹¬åœºæ™¯åˆ†å‰²ã€å‰§æœ¬ç”Ÿæˆã€å£°éŸ³è®¾è®¡å’ŒéŸ³é¢‘åˆæˆã€‚ä¸»è¦åˆ›æ–°åŒ…æ‹¬ç”¨äºåœºæ™¯&#x2F;å‰§æœ¬ç²¾ç»†åŒ–çš„è®¨è®ºæ ¡æ­£æœºåˆ¶å’Œç”¨äºæ—¶é—´è¯­ä¹‰å¯¹é½çš„ç”Ÿæˆæ£€ç´¢å¾ªç¯ã€‚ä¸ºäº†è¿›è¡Œç³»ç»Ÿè¯„ä¼°ï¼Œæˆ‘ä»¬å¼•å…¥äº†LVAS-Benchï¼Œç¬¬ä¸€ä¸ªåŒ…å«207ä¸ªä¸“ä¸šç­–åˆ’çš„é•¿è§†é¢‘ã€æ¶µç›–å„ç§åœºæ™¯çš„æ ‡å‡†åŸºå‡†æµ‹è¯•ã€‚å®éªŒè¯æ˜ï¼Œè¯¥æ–¹æ³•åœ¨è§†å¬å¯¹é½æ–¹é¢ä¼˜äºåŸºå‡†æ–¹æ³•ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>è§†é¢‘è½¬éŸ³é¢‘åˆæˆæŠ€æœ¯å¢å¼ºè§‚ä¼—æ²‰æµ¸æ„Ÿå’Œå™äº‹è¿è´¯æ€§ã€‚</li>
<li>é•¿æ ¼å¼å†…å®¹è§†é¢‘è½¬éŸ³é¢‘é…éŸ³é¢ä¸´åŠ¨æ€è¯­ä¹‰å˜åŒ–ã€æ—¶é—´ä¸å¯¹é½å’Œç¼ºä¹æ•°æ®é›†ç­‰æŒ‘æˆ˜ã€‚</li>
<li>ç°æœ‰æ–¹æ³•åœ¨é•¿åœºæ™¯åˆæˆä¸­è¡¨ç°ä¸è¶³ï¼Œå­˜åœ¨åˆæˆç‰‡æ®µåŒ–å’Œè·¨åœºæ™¯ä¸€è‡´æ€§å·®çš„é—®é¢˜ã€‚</li>
<li>LVAS-Agentæ˜¯ä¸€ç§å¤šä»£ç†æ¡†æ¶ï¼Œæ¨¡æ‹Ÿä¸“ä¸šé…éŸ³å·¥ä½œæµç¨‹ï¼ŒåŒ…æ‹¬åœºæ™¯åˆ†å‰²ã€å‰§æœ¬ç”Ÿæˆã€å£°éŸ³è®¾è®¡å’ŒéŸ³é¢‘åˆæˆå››ä¸ªæ­¥éª¤ã€‚</li>
<li>LVAS-Agentä¸»è¦åˆ›æ–°åŒ…æ‹¬è®¨è®ºæ ¡æ­£æœºåˆ¶å’Œç”Ÿæˆæ£€ç´¢å¾ªç¯ï¼Œç”¨äºä¼˜åŒ–åœºæ™¯&#x2F;å‰§æœ¬å’Œæ—¶ç©ºè¯­ä¹‰å¯¹é½ã€‚</li>
<li>ä¸ºè¯„ä¼°è§†é¢‘è½¬éŸ³é¢‘åˆæˆæŠ€æœ¯ï¼Œå¼•å…¥äº†LVAS-Benchæ ‡å‡†åŸºå‡†æµ‹è¯•ï¼ŒåŒ…å«å¤šç§åœºæ™¯çš„é•¿è§†é¢‘ç´ æã€‚</li>
<li>å®éªŒè¡¨æ˜ï¼ŒLVAS-Agentåœ¨è§†å¬å¯¹é½æ–¹é¢ç›¸æ¯”åŸºå‡†æ–¹æ³•æœ‰ä¼˜åŠ¿ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.10719">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-397e16897300cc100dc2659dd55e3e51.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-9b219c06545e17e2f9a7896bd4118c62.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-bd43362e17c963c21a04ff630df7453f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a2bfbc97f7c2d588e909a74a86260474.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b988299b3f31e9d55bfb64edbcb68f8b.jpg" align="middle">
</details>


<h1 id="-10"><a href="#-10" class="headerlink" title=""></a></h1><h2 id="Scaling-Large-Language-Model-based-Multi-Agent-Collaboration"><a href="#Scaling-Large-Language-Model-based-Multi-Agent-Collaboration" class="headerlink" title="Scaling Large Language Model-based Multi-Agent Collaboration"></a>Scaling Large Language Model-based Multi-Agent Collaboration</h2><p><strong>Authors:Chen Qian, Zihao Xie, YiFei Wang, Wei Liu, Kunlun Zhu, Hanchen Xia, Yufan Dang, Zhuoyun Du, Weize Chen, Cheng Yang, Zhiyuan Liu, Maosong Sun</strong></p>
<p>Recent breakthroughs in large language model-driven autonomous agents have revealed that multi-agent collaboration often surpasses each individual through collective reasoning. Inspired by the neural scaling lawâ€“increasing neurons enhances performance, this study explores whether the continuous addition of collaborative agents can yield similar benefits. Technically, we utilize directed acyclic graphs to organize agents into a multi-agent collaboration network (MacNet), upon which their interactive reasoning is topologically orchestrated for autonomous task solving. Extensive evaluations reveal that it effectively supports collaboration among over a thousand agents, with irregular topologies outperforming regular ones. We also identify a collaborative scaling lawâ€“the overall performance follows a logistic growth pattern as agents scale, with collaborative emergence occurring earlier than traditional neural emergence. We speculate this may be because scaling agents catalyzes their multidimensional considerations during interactive reflection and refinement, thereby producing more comprehensive artifacts. The code is available at <a target="_blank" rel="noopener" href="https://github.com/OpenBMB/ChatDev/tree/macnet">https://github.com/OpenBMB/ChatDev/tree/macnet</a>. </p>
<blockquote>
<p>è¿‘æœŸå¤§å‹è¯­è¨€æ¨¡å‹é©±åŠ¨çš„è‡ªé€‚åº”ä»£ç†çš„é‡å¤§çªç ´è¡¨æ˜ï¼Œå¤šä»£ç†åä½œé€šå¸¸é€šè¿‡é›†ä½“æ¨ç†è¶…è¶Šä¸ªä½“ã€‚æœ¬ç ”ç©¶å—ç¥ç»å¯ä¼¸ç¼©å®šå¾‹çš„å¯å‘â€”â€”å¢åŠ ç¥ç»å…ƒå¯ä»¥æé«˜æ€§èƒ½ï¼Œæ¢ç´¢è¿ç»­æ·»åŠ åä½œä»£ç†æ˜¯å¦èƒ½äº§ç”Ÿç±»ä¼¼çš„å¥½å¤„ã€‚æŠ€æœ¯ä¸Šï¼Œæˆ‘ä»¬ä½¿ç”¨æœ‰å‘æ— ç¯å›¾æ¥ç»„ç»‡ä»£ç†å½¢æˆä¸€ä¸ªå¤šä»£ç†åä½œç½‘ç»œï¼ˆMacNetï¼‰ï¼Œåœ¨æ­¤åŸºç¡€ä¸Šï¼Œä»–ä»¬çš„äº¤äº’æ¨ç†è¢«æ‹“æ‰‘åè°ƒç”¨äºè‡ªä¸»ä»»åŠ¡è§£å†³ã€‚å¹¿æ³›çš„è¯„ä¼°è¡¨æ˜ï¼Œå®ƒæœ‰æ•ˆåœ°æ”¯æŒäº†ä¸Šåƒä¸ªä»£ç†ä¹‹é—´çš„åä½œï¼Œä¸è§„åˆ™æ‹“æ‰‘çš„æ€§èƒ½ä¼˜äºè§„åˆ™æ‹“æ‰‘ã€‚æˆ‘ä»¬è¿˜ç¡®å®šäº†ä¸€ä¸ªåä½œæ‰©å±•å®šå¾‹â€”â€”éšç€ä»£ç†çš„æ‰©å±•ï¼Œæ€»ä½“æ€§èƒ½éµå¾ªé€»è¾‘å¢é•¿æ¨¡å¼ï¼Œåä½œæ¶Œç°æ¯”ä¼ ç»Ÿçš„ç¥ç»æ¶Œç°æ›´æ—©å‡ºç°ã€‚æˆ‘ä»¬æ¨æµ‹è¿™å¯èƒ½æ˜¯å› ä¸ºæ‰©å±•ä»£ç†åœ¨äº¤äº’åæ€å’Œç»†åŒ–è¿‡ç¨‹ä¸­å‚¬åŒ–äº†ä»–ä»¬çš„å¤šç»´è€ƒè™‘ï¼Œä»è€Œäº§ç”Ÿäº†æ›´å…¨é¢çš„ç»“æœã€‚ä»£ç å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/OpenBMB/ChatDev/tree/macnet">https://github.com/OpenBMB/ChatDev/tree/macnet</a>è·å–ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2406.07155v3">PDF</a> Accepted to ICLR-2025</p>
<p><strong>Summary</strong></p>
<p>å¤§å‹è¯­è¨€æ¨¡å‹é©±åŠ¨çš„è‡ªé€‚åº”ä»£ç†çš„æœ€æ–°çªç ´è¡¨æ˜ï¼Œå¤šä»£ç†åä½œé€šå¸¸é€šè¿‡é›†ä½“æ¨ç†è¶…è¶Šä¸ªä½“è¡¨ç°ã€‚æœ¬ç ”ç©¶å—ç¥ç»å…ƒè§„æ¨¡å®šå¾‹å¯å‘â€”â€”å¢åŠ ç¥ç»å…ƒæ•°é‡èƒ½æé«˜æ€§èƒ½ï¼Œæ¢è®¨äº†æŒç»­æ·»åŠ åä½œä»£ç†æ˜¯å¦èƒ½å¸¦æ¥ç±»ä¼¼æ•ˆç›Šã€‚æˆ‘ä»¬åˆ©ç”¨æœ‰å‘æ— ç¯å›¾æ¥ç»„ç»‡ä¸€ä¸ªå¤šä»£ç†åä½œç½‘ç»œï¼ˆMacNetï¼‰ï¼Œåœ¨è¿™ä¸ªç½‘ç»œä¸Šï¼Œä»–ä»¬çš„äº’åŠ¨æ¨ç†è¢«æ‹“æ‰‘åœ°åè°ƒç”¨äºè‡ªä¸»ä»»åŠ¡è§£å†³ã€‚è¯„ä¼°æ˜¾ç¤ºï¼Œè¯¥ç½‘ç»œæœ‰æ•ˆæ”¯æŒè¶…è¿‡ä¸€åƒä¸ªä»£ç†çš„åä½œï¼Œä¸è§„åˆ™æ‹“æ‰‘ä¼˜äºè§„åˆ™æ‹“æ‰‘ã€‚æˆ‘ä»¬è¿˜å‘ç°äº†åä½œè§„æ¨¡å®šå¾‹â€”â€”éšç€ä»£ç†çš„æ‰©å±•ï¼Œæ€»ä½“æ€§èƒ½éµå¾ªé€»è¾‘å¢é•¿æ¨¡å¼ï¼Œåä½œæ¶Œç°æ¯”ä¼ ç»Ÿç¥ç»æ¶Œç°æ›´æ—©å‘ç”Ÿã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤šä»£ç†åä½œé€šè¿‡é›†ä½“æ¨ç†è¶…è¶Šä¸ªä½“è¡¨ç°ã€‚</li>
<li>åˆ©ç”¨æœ‰å‘æ— ç¯å›¾æ„å»ºå¤šä»£ç†åä½œç½‘ç»œï¼ˆMacNetï¼‰ã€‚</li>
<li>MacNetæœ‰æ•ˆæ”¯æŒè¶…è¿‡ä¸€åƒä¸ªä»£ç†çš„åä½œã€‚</li>
<li>ä¸è§„åˆ™æ‹“æ‰‘åœ¨ä»£ç†åä½œä¸­è¡¨ç°ä¼˜äºè§„åˆ™æ‹“æ‰‘ã€‚</li>
<li>å‘ç°äº†åä½œè§„æ¨¡å®šå¾‹ï¼Œæ€»ä½“æ€§èƒ½éšä»£ç†æ‰©å±•è€Œéµå¾ªé€»è¾‘å¢é•¿æ¨¡å¼ã€‚</li>
<li>åä½œæ¶Œç°æ¯”ä¼ ç»Ÿç¥ç»æ¶Œç°æ›´æ—©å‘ç”Ÿã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2406.07155">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-f3b2e62f717414137500fafad9a7bdbd.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-13767a2602b68de874417b9b5e162439.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-8f158181361eb30ff9f009b5f1e9373d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-73847743c922dfeb542efc19c104dfa5.jpg" align="middle">
</details>


<h1 id="-11"><a href="#-11" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-03-18/Agent/">https://kedreamix.github.io/Talk2Paper/Paper/2025-03-18/Agent/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/Agent/">
                                    <span class="chip bg-color">Agent</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-03-18/MMT/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-16ac621e5356ed6f81ab09edccc21589.jpg" class="responsive-img" alt="MMT">
                        
                        <span class="card-title">MMT</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            MMT æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-03-18  New Trends for Modern Machine Translation with Large Reasoning Models
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-03-18
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/MMT/" class="post-category">
                                    MMT
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/MMT/">
                        <span class="chip bg-color">MMT</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-03-18/LLM/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-ae4aa0d01a00b084fbf0a3221e0f44c7.jpg" class="responsive-img" alt="LLM">
                        
                        <span class="card-title">LLM</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            LLM æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-03-18  MetaScale Test-Time Scaling with Evolving Meta-Thoughts
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-03-18
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/LLM/" class="post-category">
                                    LLM
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/LLM/">
                        <span class="chip bg-color">LLM</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">19778.5k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
