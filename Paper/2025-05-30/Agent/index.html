<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Agent">
    <meta name="description" content="Agent 方向最新论文已更新，请持续关注 Update in 2025-05-30  Position Uncertainty Quantification Needs Reassessment for   Large-language Model Agents">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>Agent | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loader页面消失采用渐隐的方式*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logo出现动画 */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//使用渐隐的方法淡出loading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//强制显示loading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">嘘~  正在从服务器偷取页面 . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>首页</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>标签</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>分类</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>归档</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="搜索" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="深色/浅色模式" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			首页
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			标签
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			分类
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			归档
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://pica.zhimg.com/v2-bb307dc4e1461f88213a6d3aa7fc133c.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Agent</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/Agent/">
                                <span class="chip bg-color">Agent</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/Agent/" class="post-category">
                                Agent
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2025-05-30
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>更新日期:&nbsp;&nbsp;
                    2025-06-24
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp;
                    15k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp;
                    61 分
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>阅读次数:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>⚠️ 以下所有内容总结都来自于 大语言模型的能力，如有错误，仅供参考，谨慎使用<br>🔴 请注意：千万不要用于严肃的学术场景，只能用于论文阅读前的初筛！<br>💗 如果您觉得我们的项目对您有帮助 <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ，还请您给我们一些鼓励！⭐️ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFace免费体验</a></p>
</blockquote>
<h1 id="2025-05-30-更新"><a href="#2025-05-30-更新" class="headerlink" title="2025-05-30 更新"></a>2025-05-30 更新</h1><h2 id="Position-Uncertainty-Quantification-Needs-Reassessment-for-Large-language-Model-Agents"><a href="#Position-Uncertainty-Quantification-Needs-Reassessment-for-Large-language-Model-Agents" class="headerlink" title="Position: Uncertainty Quantification Needs Reassessment for   Large-language Model Agents"></a>Position: Uncertainty Quantification Needs Reassessment for   Large-language Model Agents</h2><p><strong>Authors:Michael Kirchhof, Gjergji Kasneci, Enkelejda Kasneci</strong></p>
<p>Large-language models (LLMs) and chatbot agents are known to provide wrong outputs at times, and it was recently found that this can never be fully prevented. Hence, uncertainty quantification plays a crucial role, aiming to quantify the level of ambiguity in either one overall number or two numbers for aleatoric and epistemic uncertainty. This position paper argues that this traditional dichotomy of uncertainties is too limited for the open and interactive setup that LLM agents operate in when communicating with a user, and that we need to research avenues that enrich uncertainties in this novel scenario. We review the literature and find that popular definitions of aleatoric and epistemic uncertainties directly contradict each other and lose their meaning in interactive LLM agent settings. Hence, we propose three novel research directions that focus on uncertainties in such human-computer interactions: Underspecification uncertainties, for when users do not provide all information or define the exact task at the first go, interactive learning, to ask follow-up questions and reduce the uncertainty about the current context, and output uncertainties, to utilize the rich language and speech space to express uncertainties as more than mere numbers. We expect that these new ways of dealing with and communicating uncertainties will lead to LLM agent interactions that are more transparent, trustworthy, and intuitive. </p>
<blockquote>
<p>大型语言模型（LLM）和聊天机器人代理有时会产生错误的输出，最近的研究发现这种情况无法完全避免。因此，不确定性量化扮演着至关重要的角色，旨在量化总体上的一个数字或两个数字分别代表偶然不确定性和认知不确定性的模糊程度。这篇立场论文认为，对于与用户进行交流的大型语言模型代理所处的开放互动环境中，这种传统的不确定性二分法过于局限。我们需要研究如何在这个新场景中丰富不确定性的方法。我们回顾了文献，发现偶然不确定性和认知不确定性的流行定义直接相互矛盾，在互动的大型语言模型代理环境中失去意义。因此，我们提出了三个新的研究方向，侧重于在人机互动中的不确定性：当用户没有提供所有信息或首次定义确切任务时的规格不明确性、通过提出后续问题减少当前上下文不确定性的互动学习，以及利用丰富的语言和语音空间表达不仅仅是数字的不确定性输出不确定性。我们预计这些新的处理和管理不确定性的方法将使大型语言模型代理的互动更加透明、可信和直观。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.22655v1">PDF</a> Accepted at ICML 2025</p>
<p><strong>Summary</strong></p>
<p>大型语言模型（LLM）和聊天机器人代理有时会提供错误的输出，且这无法完全避免。因此，不确定性量化是关键，旨在量化aleatoric和epistemic不确定性的水平。这篇立场论文认为，对于与用户交互的大型语言模型代理的开放和交互式设置，传统的不确定性二分法过于局限。我们提出了三个新的研究方向，重点关注这种人机交互中的不确定性：未指定信息的不确定性、互动学习减少当前上下文不确定性的方法和输出不确定性，利用丰富的语言和语音空间来表达不仅仅是数字的不确定性。预期这些新的不确定性处理和沟通方式将带来更加透明、可靠和直观的大型语言模型代理交互。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>大型语言模型（LLM）和聊天机器人代理有时会提供错误的输出，这是无法完全避免的。</li>
<li>不确定性量化在大型语言模型（LLM）中至关重要，尤其是在与用户交互时。</li>
<li>传统的不确定性二分法对于大型语言模型代理的开放式和交互式设置过于局限。</li>
<li>未指定信息的不确定性在大型语言模型代理与用户交互中是一个重要的问题。</li>
<li>通过互动学习可以减少上下文的不确定性。</li>
<li>输出不确定性可以利用丰富的语言和语音空间来表达不确定性。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.22655">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pica.zhimg.com/v2-7266bd01812f1fcbf5103ebd858a6790.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-5cd1cbb1418e22ca035c93e7a6fbea02.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-bca35510bc394b19ec3858d33979d00e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a4007323d2cd7996885b5bfe9edf29ac.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-96aba5bf41e8a4cceece2931a4a09452.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="HDDLGym-A-Tool-for-Studying-Multi-Agent-Hierarchical-Problems-Defined-in-HDDL-with-OpenAI-Gym"><a href="#HDDLGym-A-Tool-for-Studying-Multi-Agent-Hierarchical-Problems-Defined-in-HDDL-with-OpenAI-Gym" class="headerlink" title="HDDLGym: A Tool for Studying Multi-Agent Hierarchical Problems Defined   in HDDL with OpenAI Gym"></a>HDDLGym: A Tool for Studying Multi-Agent Hierarchical Problems Defined   in HDDL with OpenAI Gym</h2><p><strong>Authors:Ngoc La, Ruaridh Mon-Williams, Julie A. Shah</strong></p>
<p>In recent years, reinforcement learning (RL) methods have been widely tested using tools like OpenAI Gym, though many tasks in these environments could also benefit from hierarchical planning. However, there is a lack of a tool that enables seamless integration of hierarchical planning with RL. Hierarchical Domain Definition Language (HDDL), used in classical planning, introduces a structured approach well-suited for model-based RL to address this gap. To bridge this integration, we introduce HDDLGym, a Python-based tool that automatically generates OpenAI Gym environments from HDDL domains and problems. HDDLGym serves as a link between RL and hierarchical planning, supporting multi-agent scenarios and enabling collaborative planning among agents. This paper provides an overview of HDDLGym’s design and implementation, highlighting the challenges and design choices involved in integrating HDDL with the Gym interface, and applying RL policies to support hierarchical planning. We also provide detailed instructions and demonstrations for using the HDDLGym framework, including how to work with existing HDDL domains and problems from International Planning Competitions, exemplified by the Transport domain. Additionally, we offer guidance on creating new HDDL domains for multi-agent scenarios and demonstrate the practical use of HDDLGym in the Overcooked domain. By leveraging the advantages of HDDL and Gym, HDDLGym aims to be a valuable tool for studying RL in hierarchical planning, particularly in multi-agent contexts. </p>
<blockquote>
<p>近年来，强化学习（RL）方法已广泛利用OpenAI Gym等工具进行测试，尽管这些环境中的许多任务也可以从分层规划中受益。然而，目前缺乏能够将分层规划与RL无缝集成的工具。用于经典规划的分层领域定义语言（HDDL）引入了一种适用于基于模型的RL的结构化方法，以弥补这一空白。为了弥这一整合鸿沟，我们引入了HDDLGym，这是一个基于Python的工具，它可以从HDDL领域和问题自动生成OpenAI Gym环境。HDDLGym是RL和分层规划之间的桥梁，支持多智能体场景并在智能体之间进行协作规划。本文概述了HDDLGym的设计与实施，重点介绍了将HDDL与Gym接口集成所涉及的挑战和设计选择，以及应用RL策略来支持分层规划。我们还提供了使用HDDLGym框架的详细说明和演示，包括如何与国际规划竞赛中的现有HDDL领域和问题一起工作，以运输领域为例。此外，我们还提供了为多人场景创建新HDDL领域的指导，并在Overcooked领域中展示了HDDLGym的实际应用。通过利用HDDL和Gym的优势，HDDLGym旨在成为研究分层规划中的RL，特别是在多智能体环境中的宝贵工具。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.22597v1">PDF</a> Accepted to Proceedings of ICAPS 2025</p>
<p><strong>Summary</strong></p>
<p>强化学习（RL）近年来广泛使用OpenAI Gym等工具进行测试，然而这些环境中的许多任务也能从层次化规划受益。为了解决这一空白，我们引入了Hierarchical Domain Definition Language（HDDL）这一在经典规划中使用的结构化方法，适用于模型基础RL。为了整合RL与层次化规划，我们推出HDDLGym——基于Python的工具，可从HDDL领域与问题自动生成OpenAI Gym环境。HDDLGym作为RL与层次化规划之间的桥梁，支持多智能体场景并实现智能体间的协同规划。本文概述了HDDLGym的设计与实施，强调了整合HDDL与Gym接口的挑战与设计选择，并展示了如何应用RL策略以支持层次化规划。同时提供使用HDDLGym框架的详细指南与演示，包括如何使用国际规划竞赛中的现有HDDL领域与问题，如在运输领域中的应用。通过利用HDDL与Gym的优势，HDDLGym旨在为层次化规划中的RL研究提供有价值的工具，特别是在多智能体场景中。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>强化学习（RL）在OpenAI Gym等工具中广泛应用，但缺乏将层次化规划与RL无缝集成的工具。</li>
<li>Hierarchical Domain Definition Language（HDDL）为模型基础RL提供了结构化方法。</li>
<li>HDDLGym是首个基于Python的工具，可从HDDL领域与问题自动生成OpenAI Gym环境。</li>
<li>HDDLGym支持多智能体场景并实现了智能体间的协同规划。</li>
<li>HDDLGym的设计与实施涉及整合HDDL与Gym接口的挑战与设计选择。</li>
<li>HDDLGym提供了使用指南和演示，包括如何应用国际规划竞赛中的现有HDDL领域与问题。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.22597">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pica.zhimg.com/v2-975765b491952feb0a92c752d7b472af.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-f4d4a6215c707967cd0a6c9fffb82464.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-b68de3edc52bcafc9b25ca176abca1a7.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-987ee24048a48addb871547b3301677a.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="EvolveSearch-An-Iterative-Self-Evolving-Search-Agent"><a href="#EvolveSearch-An-Iterative-Self-Evolving-Search-Agent" class="headerlink" title="EvolveSearch: An Iterative Self-Evolving Search Agent"></a>EvolveSearch: An Iterative Self-Evolving Search Agent</h2><p><strong>Authors:Dingchu Zhang, Yida Zhao, Jialong Wu, Baixuan Li, Wenbiao Yin, Liwen Zhang, Yong Jiang, Yufeng Li, Kewei Tu, Pengjun Xie, Fei Huang</strong></p>
<p>The rapid advancement of large language models (LLMs) has transformed the landscape of agentic information seeking capabilities through the integration of tools such as search engines and web browsers. However, current mainstream approaches for enabling LLM web search proficiency face significant challenges: supervised fine-tuning struggles with data production in open-search domains, while RL converges quickly, limiting their data utilization efficiency. To address these issues, we propose EvolveSearch, a novel iterative self-evolution framework that combines SFT and RL to enhance agentic web search capabilities without any external human-annotated reasoning data. Extensive experiments on seven multi-hop question-answering (MHQA) benchmarks demonstrate that EvolveSearch consistently improves performance across iterations, ultimately achieving an average improvement of 4.7% over the current state-of-the-art across seven benchmarks, opening the door to self-evolution agentic capabilities in open web search domains. </p>
<blockquote>
<p>大型语言模型（LLM）的快速发展通过整合搜索引擎和网页浏览器等工具，改变了信息检索能力的格局。然而，目前主流的实现LLM网页搜索能力的方法面临着巨大的挑战：监督微调在开放搜索领域的数据生产方面表现挣扎，而强化学习虽然收敛迅速，但数据利用效率有限。为了解决这些问题，我们提出了EvolveSearch，这是一个新型迭代自进化框架，结合了监督微调（SFT）和强化学习，提高了智能网页搜索能力，无需任何外部人工标注的推理数据。在七个多跳问答（MHQA）基准测试上的大量实验表明，EvolveSearch在迭代过程中性能持续提升，最终实现了平均提高4.7%，超过了七个基准测试中的最新技术状态，为开放网络搜索领域的智能自我进化能力开启了大门。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.22501v1">PDF</a> </p>
<p><strong>Summary</strong>：随着大型语言模型（LLM）的快速发展，搜索引擎和浏览器等工具的集成改变了信息检索能力。然而，主流方法面临挑战：监督微调面临开放搜索域数据生产困难，强化学习收敛迅速但数据利用效率有限。为解决这些问题，提出了EvolveSearch框架，结合监督微调与强化学习进行自我进化，提高信息检索能力，无需外部人类注释数据。在七个多跳问答基准测试上的实验表明，EvolveSearch在迭代中性能持续提高，平均改进了当前最新技术的4.7%，为开放网络搜索域的自我进化能力打开了大门。</p>
<p><strong>Key Takeaways</strong>：</p>
<ol>
<li>大型语言模型（LLM）在信息检索领域有重大进展。</li>
<li>当前主流方法面临数据生产和数据利用效率的挑战。</li>
<li>EvolveSearch框架结合了监督微调与强化学习。</li>
<li>EvolveSearch提高了信息检索能力，无需外部人类注释数据。</li>
<li>EvolveSearch在多个基准测试上表现优越，平均改进了当前最新技术的4.7%。</li>
<li>EvolveSearch为开放网络搜索域的自我进化能力提供了可能。</li>
<li>该框架的迭代自我进化策略是其核心创新之一。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.22501">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-dfd9154c86cac4e5e5cfc7e08d4e607e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-557d0c5829cdfab924638210d82ff347.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-88614c79c35ddbfdb75eb084c3839332.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-87deee97464e91d6fcb3200ba6e65738.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-bb307dc4e1461f88213a6d3aa7fc133c.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="AgentDNS-A-Root-Domain-Naming-System-for-LLM-Agents"><a href="#AgentDNS-A-Root-Domain-Naming-System-for-LLM-Agents" class="headerlink" title="AgentDNS: A Root Domain Naming System for LLM Agents"></a>AgentDNS: A Root Domain Naming System for LLM Agents</h2><p><strong>Authors:Enfang Cui, Yujun Cheng, Rui She, Dan Liu, Zhiyuan Liang, Minxin Guo, Tianzheng Li, Qian Wei, Wenjuan Xing, Zhijie Zhong</strong></p>
<p>The rapid evolution of Large Language Model (LLM) agents has highlighted critical challenges in cross-vendor service discovery, interoperability, and communication. Existing protocols like model context protocol and agent-to-agent protocol have made significant strides in standardizing interoperability between agents and tools, as well as communication among multi-agents. However, there remains a lack of standardized protocols and solutions for service discovery across different agent and tool vendors. In this paper, we propose AgentDNS, a root domain naming and service discovery system designed to enable LLM agents to autonomously discover, resolve, and securely invoke third-party agent and tool services across organizational and technological boundaries. Inspired by the principles of the traditional DNS, AgentDNS introduces a structured mechanism for service registration, semantic service discovery, secure invocation, and unified billing. We detail the architecture, core functionalities, and use cases of AgentDNS, demonstrating its potential to streamline multi-agent collaboration in real-world scenarios. The source code will be published on <a target="_blank" rel="noopener" href="https://github.com/agentdns">https://github.com/agentdns</a>. </p>
<blockquote>
<p>大型语言模型（LLM）代理的快速进化突显了跨供应商服务发现、互操作性和通信方面的关键挑战。现有的模型上下文协议和代理对代理协议等协议在标准化代理和工具之间的互操作性以及多代理之间的通信方面取得了重大进展。然而，仍然存在跨不同代理和工具供应商的服务发现缺乏标准化协议和解决方案的问题。在本文中，我们提出了AgentDNS，这是一个根域名解析和服务发现系统，旨在使LLM代理能够自主发现、解决并安全地调用跨组织和跨技术边界的第三方代理和工具服务。该系统以传统DNS的原则为灵感，引入了服务注册、语义服务发现、安全调用和统一计费的结构化机制。我们详细介绍了AgentDNS的架构、核心功能和使用案例，展示了其在现实场景中简化多代理协作的潜力。源代码将在<a target="_blank" rel="noopener" href="https://github.com/agentdns%E4%B8%8A%E5%8F%91%E5%B8%83%E3%80%82">https://github.com/agentdns上发布。</a></p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.22368v1">PDF</a> 7 pages, 6 figures</p>
<p><strong>Summary</strong></p>
<p>大型语言模型（LLM）代理的快速进化凸显了跨供应商服务发现、互操作性和通信方面的关键挑战。现有协议如模型上下文协议和代理到代理协议在标准化代理和工具之间的互操作性以及多代理之间的通信方面取得了重大进展。然而，不同代理和工具供应商之间的服务发现仍然缺乏标准化协议和解决方案。本文提出AgentDNS，一个根域名解析和服务发现系统，旨在使LLM代理能够自主发现、解析和安全调用跨组织和技术边界的第三方代理和工具服务。AgentDNS借鉴了传统DNS的原理，引入了服务注册、语义服务发现、安全调用和统一计费的结构化机制。本文详细描述了AgentDNS的架构、核心功能和使用案例，展示了其在现实场景中简化多代理协作的潜力。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>大型语言模型（LLM）的发展带来了跨供应商服务发现、互操作性和通信的挑战。</li>
<li>现有协议在代理标准化方面已有所进展，但仍需改进服务发现的标准化协议和解决方案。</li>
<li>AgentDNS是一个基于传统DNS原理的根域名解析和服务发现系统。</li>
<li>AgentDNS使LLM代理能够自主发现、解析和安全调用跨组织和技术边界的第三方服务和工具。</li>
<li>AgentDNS提供了服务注册、语义服务发现、安全调用和统一计费的机制。</li>
<li>AgentDNS的架构、核心功能和使用案例被详细阐述。</li>
<li>AgentDNS有潜力在现实场景中简化多代理协作。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.22368">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-4237177d76ba1f2d40c3b5a6545f1784.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-2bd692e0a77ed24ca4583c51ce0432d0.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-2cada25266a1a3cd13ca550f98705176.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-2eed1b93302dfbb7129e193047121313.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b561c6afad8203988ca3e4ce43e44f5e.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="Oryx-a-Performant-and-Scalable-Algorithm-for-Many-Agent-Coordination-in-Offline-MARL"><a href="#Oryx-a-Performant-and-Scalable-Algorithm-for-Many-Agent-Coordination-in-Offline-MARL" class="headerlink" title="Oryx: a Performant and Scalable Algorithm for Many-Agent Coordination in   Offline MARL"></a>Oryx: a Performant and Scalable Algorithm for Many-Agent Coordination in   Offline MARL</h2><p><strong>Authors:Claude Formanek, Omayma Mahjoub, Louay Ben Nessir, Sasha Abramowitz, Ruan de Kock, Wiem Khlifi, Simon Du Toit, Felix Chalumeau, Daniel Rajaonarivonivelomanantsoa, Arnol Fokam, Siddarth Singh, Ulrich Mbou Sob, Arnu Pretorius</strong></p>
<p>A key challenge in offline multi-agent reinforcement learning (MARL) is achieving effective many-agent multi-step coordination in complex environments. In this work, we propose Oryx, a novel algorithm for offline cooperative MARL to directly address this challenge. Oryx adapts the recently proposed retention-based architecture Sable and combines it with a sequential form of implicit constraint Q-learning (ICQ), to develop a novel offline auto-regressive policy update scheme. This allows Oryx to solve complex coordination challenges while maintaining temporal coherence over lengthy trajectories. We evaluate Oryx across a diverse set of benchmarks from prior works (SMAC, RWARE, and Multi-Agent MuJoCo) covering tasks of both discrete and continuous control, varying in scale and difficulty. Oryx achieves state-of-the-art performance on more than 80% of the 65 tested datasets, outperforming prior offline MARL methods and demonstrating robust generalisation across domains with many agents and long horizons. Finally, we introduce new datasets to push the limits of many-agent coordination in offline MARL, and demonstrate Oryx’s superior ability to scale effectively in such settings. We will make all of our datasets, experimental data, and code available upon publication. </p>
<blockquote>
<p>在离线多智能体强化学习（MARL）中，一个关键挑战是在复杂环境中实现有效的多智能体多步协调。针对这一挑战，我们提出了Oryx这一新型的离线协同MARL算法。Oryx适应了最近提出的基于保留的架构Sable，并将其与隐式约束Q学习（ICQ）的序列形式相结合，开发了一种新型的离线自回归策略更新方案。这使得Oryx能够在解决复杂的协调挑战的同时，在漫长的轨迹上保持时间连贯性。我们在来自先前工作的多样化基准测试集（SMAC、RWARE和Multi-Agent MuJoCo）上评估了Oryx的性能，这些基准测试涵盖了离散和连续控制任务，规模和难度各异。Oryx在65个测试数据集中的80%以上达到了最新技术水平，超越了先前的离线MARL方法，并在多个智能体和长期视野的跨领域任务中展示了稳健的泛化能力。最后，我们引入了新的数据集来推动离线MARL中多智能体协调的极限，并展示了Oryx在这种环境下进行有效扩展的卓越能力。所有数据集、实验数据和代码将在发布时提供。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.22151v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>本文提出一种针对离线多智能体强化学习（MARL）的关键挑战的解决方案，名为Oryx。它通过结合基于保留的架构Sable和隐式约束Q学习（ICQ）的序列形式，开发了一种新颖的离线自回归策略更新方案。这使得Oryx能够在解决复杂的协调挑战时，在漫长的轨迹上保持时间连贯性。在多个基准测试（如SMAC、RWARE和Multi-Agent MuJoCo）中，Oryx在超过80%的65个测试数据集上实现了卓越的性能，超越了先前的离线MARL方法，并在多个领域的多智能体环境中展示了强大的泛化能力。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>Oryx是一种针对离线多智能体强化学习（MARL）的新型算法，旨在解决多智能体在复杂环境中的多步协调挑战。</li>
<li>Oryx结合了Sable的保留架构和ICQ的序列形式，形成了一种新颖的离线自回归策略更新方案。</li>
<li>该方案允许解决复杂的协调问题，同时在长时间的轨迹上保持时间连贯性。</li>
<li>在多个基准测试中，包括离散和连续控制任务，不同规模和难度的任务，Oryx在超过80%的数据集上实现了卓越性能。</li>
<li>与先前的离线MARL方法相比，Oryx表现出了出色的性能，并在多个领域的泛化能力上具有优势。</li>
<li>为了推动离线MARL中多智能体协调的极限，作者引入了新的数据集。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.22151">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-a38ffb10ef1129df7b47caf813a2d07f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-14f58c854b00528cd617f51995f2e4d6.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-8a018eb0f39a9ac59e4c0d4ac9dd082d.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="Towards-Conversational-Development-Environments-Using-Theory-of-Mind-and-Multi-Agent-Architectures-for-Requirements-Refinement"><a href="#Towards-Conversational-Development-Environments-Using-Theory-of-Mind-and-Multi-Agent-Architectures-for-Requirements-Refinement" class="headerlink" title="Towards Conversational Development Environments: Using Theory-of-Mind   and Multi-Agent Architectures for Requirements Refinement"></a>Towards Conversational Development Environments: Using Theory-of-Mind   and Multi-Agent Architectures for Requirements Refinement</h2><p><strong>Authors:Keheliya Gallaba, Ali Arabat, Dayi Lin, Mohammed Sayagh, Ahmed E. Hassan</strong></p>
<p>Foundation Models (FMs) have shown remarkable capabilities in various natural language tasks. However, their ability to accurately capture stakeholder requirements remains a significant challenge for using FMs for software development. This paper introduces a novel approach that leverages an FM-powered multi-agent system called AlignMind to address this issue. By having a cognitive architecture that enhances FMs with Theory-of-Mind capabilities, our approach considers the mental states and perspectives of software makers. This allows our solution to iteratively clarify the beliefs, desires, and intentions of stakeholders, translating these into a set of refined requirements and a corresponding actionable natural language workflow in the often-overlooked requirements refinement phase of software engineering, which is crucial after initial elicitation. Through a multifaceted evaluation covering 150 diverse use cases, we demonstrate that our approach can accurately capture the intents and requirements of stakeholders, articulating them as both specifications and a step-by-step plan of action. Our findings suggest that the potential for significant improvements in the software development process justifies these investments. Our work lays the groundwork for future innovation in building intent-first development environments, where software makers can seamlessly collaborate with AIs to create software that truly meets their needs. </p>
<blockquote>
<p>基础模型（FMs）在各种自然语言任务中表现出了显著的能力。然而，准确捕捉利益相关者的要求在软件开发中使用基础模型仍是一个重大挑战。本文介绍了一种利用基础模型驱动的多智能体系统AlignMind来解决这一问题的新方法。通过增强基础模型的认知架构，使其具备心智理论能力，我们的方法考虑了软件制造者的心理状态和视角。这使得我们的解决方案能够迭代地澄清利益相关者的信念、欲望和意图，并将其转化为一套精细的要求和相应的可操作的自然语言工作流程，在常被忽视的软件开发需求优化阶段至关重要，这很重要，因为在初步激励之后是尤为关键的。通过涵盖多个维度的评估和包括有 150 个不同用例的研究分析，我们证明了我们的方法可以准确地捕捉利益相关者的意图和要求，将其细化为规范和逐步行动计划。我们的研究结果表明，软件开发的潜在改进足以证明这些投资是值得的。我们的工作为建立意图优先的开发环境奠定了基础，在这样的环境中，软件制造商可以无缝地与人工智能协作创建真正满足其需求的软件。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.20973v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>基于模型的智能系统成功应用于多个自然语言任务，但在软件开发领域捕捉利益相关者的准确需求上仍有局限。本文通过提出一个由Foundation Models驱动的多智能体系统（名为AlignMind）来解决此问题。通过强化模型心智能力的认知架构，此系统考虑了软件开发者的心理状态和视角。因此，该解决方案能够迭代地澄清利益相关者的信念、欲望和意图，并将其转化为精细的需求和相应的可操作的自然语言工作流程，这在常被忽略的软件工程需求细化阶段至关重要。通过涵盖150个不同用例的多方面评估，本文证明了该方案能够准确捕捉利益相关者的意图和需求，并将其表达为具体的规范和操作步骤。这为未来的软件开发过程带来了显著的改进潜力，并为建立以意图为先的开发环境奠定了基础，使软件开发者能与人工智能无缝协作，创造出真正符合需求的产品。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>Foundation Models在捕捉软件开发利益相关者的需求方面存在挑战。</li>
<li>引入了一种名为AlignMind的FM驱动多智能体系统来解决这一挑战。</li>
<li>AlignMind通过增强FM的心智能力，考虑了软件开者的心理状况和视角。</li>
<li>该系统能迭代澄清利益相关者的信念、欲望和意图。</li>
<li>这些信息被转化为精细的需求和可操作的自然语言工作流程，对需求细化阶段至关重要。</li>
<li>通过涵盖多个用例的评估，证明该方案能准确捕捉并表达利益相关者的意图和需求。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.20973">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-368159c81b2e79a20294a815a8d24657.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-025778454c40a1284d8b47c689abdf79.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="JEDI-Latent-End-to-end-Diffusion-Mitigates-Agent-Human-Performance-Asymmetry-in-Model-Based-Reinforcement-Learning"><a href="#JEDI-Latent-End-to-end-Diffusion-Mitigates-Agent-Human-Performance-Asymmetry-in-Model-Based-Reinforcement-Learning" class="headerlink" title="JEDI: Latent End-to-end Diffusion Mitigates Agent-Human Performance   Asymmetry in Model-Based Reinforcement Learning"></a>JEDI: Latent End-to-end Diffusion Mitigates Agent-Human Performance   Asymmetry in Model-Based Reinforcement Learning</h2><p><strong>Authors:Jing Yu Lim, Zarif Ikram, Samson Yu, Haozhe Ma, Tze-Yun Leong, Dianbo Liu</strong></p>
<p>Recent advances in model-based reinforcement learning (MBRL) have achieved super-human level performance on the Atari100k benchmark, driven by reinforcement learning agents trained on powerful diffusion world models. However, we identify that the current aggregates mask a major performance asymmetry: MBRL agents dramatically outperform humans in some tasks despite drastically underperforming in others, with the former inflating the aggregate metrics. This is especially pronounced in pixel-based agents trained with diffusion world models. In this work, we address the pronounced asymmetry observed in pixel-based agents as an initial attempt to reverse the worrying upward trend observed in them. We address the problematic aggregates by delineating all tasks as Agent-Optimal or Human-Optimal and advocate for equal importance on metrics from both sets. Next, we hypothesize this pronounced asymmetry is due to the lack of temporally-structured latent space trained with the World Model objective in pixel-based methods. Lastly, to address this issue, we propose Joint Embedding DIffusion (JEDI), a novel latent diffusion world model trained end-to-end with the self-consistency objective. JEDI outperforms SOTA models in human-optimal tasks while staying competitive across the Atari100k benchmark, and runs 3 times faster with 43% lower memory than the latest pixel-based diffusion baseline. Overall, our work rethinks what it truly means to cross human-level performance in Atari100k. </p>
<blockquote>
<p>近期模型化强化学习（MBRL）的进步在Atari100k基准测试中实现了超人水平的性能表现，其背后的驱动力量是训练在强大扩散世界模型上的强化学习智能体。然而，我们发现当前的总体评估掩盖了一个重要的性能不对称问题：MBRL智能体在某些任务上大大超越人类的表现，却在其他任务上表现不佳，前者过度膨胀了总体指标。这在基于像素的、使用扩散世界模型训练的智能体中尤为突出。在这项工作中，我们针对在基于像素的智能体中观察到的明显不对称性作为初步尝试，来扭转这种令人担忧的上升趋势。我们通过将任务划分为以智能体为中心的最优或以人为中心的最优来解决有问题的总体评估问题，并主张两者集合的指标应同等重要。接下来，我们假设这种突出的不对称性是由于基于像素的方法中缺乏与世界模型目标一起训练的、具有时间结构化的潜在空间所导致的。最后，为了解决这个问题，我们提出了联合嵌入扩散（JEDI），这是一种新型潜在扩散世界模型，与自洽目标一起进行端到端的训练。JEDI在人类最优任务上超越了SOTA模型，同时在Atari100k基准测试中保持竞争力，并且与最新的基于像素的扩散基准相比，运行速度提高了三倍，内存降低了43%。总的来说，我们的工作重新思考了在Atari100k中实现超越人类水平的性能的真正含义。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.19698v2">PDF</a> Preprint</p>
<p><strong>Summary</strong></p>
<p>本文探讨了基于模型的强化学习（MBRL）在Atari100k基准测试上的性能不对称问题。研究发现，尽管MBRL在某些任务上表现超人类，但在其他任务上表现较差。为解决这一问题，本文提出一种新方法——联合嵌入扩散（JEDI），该方法通过端到端训练带有自一致性目标的潜在扩散世界模型，旨在优化在人类社会最佳任务的性能并保持Atari 100k基准测试中的竞争力。此外，JEDI模型运行速度更快且内存占用更低。本文重新思考了在Atari 100k基准测试中超越人类水平的真正含义。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>MBRL在某些任务上表现超人类，但在其他任务上表现较差，导致性能不对称问题。</li>
<li>性能不对称问题在基于像素的强化学习代理中尤为突出。</li>
<li>提出了一种新方法——联合嵌入扩散（JEDI），旨在解决性能不对称问题并优化在人类社会最佳任务的性能。</li>
<li>JEDI模型通过端到端训练带有自一致性目标的潜在扩散世界模型实现性能提升。</li>
<li>JEDI模型在Atari 100k基准测试中保持竞争力，同时运行速度更快且内存占用更低。</li>
<li>本文研究重新思考了在Atari 100k基准测试中超越人类水平的真正含义。</li>
<li>需要关注强化学习代理在各类任务上的全面性能评估，不仅仅是单一的基准测试指标。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.19698">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-aee366c6d61be392313f311897406265.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-9b2fa6709b3beaf6921e39d823f452bb.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-54e120c819ad1188f2523f8fc6940e20.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-6960958586b6893fb95331e62f80e769.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="AgentRecBench-Benchmarking-LLM-Agent-based-Personalized-Recommender-Systems"><a href="#AgentRecBench-Benchmarking-LLM-Agent-based-Personalized-Recommender-Systems" class="headerlink" title="AgentRecBench: Benchmarking LLM Agent-based Personalized Recommender   Systems"></a>AgentRecBench: Benchmarking LLM Agent-based Personalized Recommender   Systems</h2><p><strong>Authors:Yu Shang, Peijie Liu, Yuwei Yan, Zijing Wu, Leheng Sheng, Yuanqing Yu, Chumeng Jiang, An Zhang, Fengli Xu, Yu Wang, Min Zhang, Yong Li</strong></p>
<p>The emergence of agentic recommender systems powered by Large Language Models (LLMs) represents a paradigm shift in personalized recommendations, leveraging LLMs’ advanced reasoning and role-playing capabilities to enable autonomous, adaptive decision-making. Unlike traditional recommendation approaches, agentic recommender systems can dynamically gather and interpret user-item interactions from complex environments, generating robust recommendation strategies that generalize across diverse scenarios. However, the field currently lacks standardized evaluation protocols to systematically assess these methods. To address this critical gap, we propose: (1) an interactive textual recommendation simulator incorporating rich user and item metadata and three typical evaluation scenarios (classic, evolving-interest, and cold-start recommendation tasks); (2) a unified modular framework for developing and studying agentic recommender systems; and (3) the first comprehensive benchmark comparing 10 classical and agentic recommendation methods. Our findings demonstrate the superiority of agentic systems and establish actionable design guidelines for their core components. The benchmark environment has been rigorously validated through an open challenge and remains publicly available with a continuously maintained leaderboard~\footnote[2]{<a target="_blank" rel="noopener" href="https://tsinghua-fib-lab.github.io/AgentSocietyChallenge/pages/overview.html%7D">https://tsinghua-fib-lab.github.io/AgentSocietyChallenge/pages/overview.html}</a>, fostering ongoing community engagement and reproducible research. The benchmark is available at: \hyperlink{<a target="_blank" rel="noopener" href="https://huggingface.co/datasets/SGJQovo/AgentRecBench%7D%7Bhttps://huggingface.co/datasets/SGJQovo/AgentRecBench%7D">https://huggingface.co/datasets/SGJQovo/AgentRecBench}{https://huggingface.co/datasets/SGJQovo/AgentRecBench}</a>. </p>
<blockquote>
<p>基于大型语言模型（LLM）的代理推荐系统的出现，代表着个性化推荐中的范式转变。它利用LLM的先进推理和角色扮演能力，实现自主、自适应的决策。与传统的推荐方法不同，代理推荐系统可以动态地收集和解释用户与物品的互动，从复杂的环境中生成稳健的推荐策略，这些策略可以在不同的场景中推广。然而，目前该领域缺乏标准化的评估协议来系统地评估这些方法。为了解决这一关键差距，我们提出：（1）一个交互文本推荐模拟器，融入丰富的用户和物品元数据以及三种典型评估场景（经典、兴趣发展和冷启动推荐任务）；（2）一个统一的模块化框架，用于开发和研究代理推荐系统；（3）第一个全面基准测试，比较10种经典和代理推荐方法。我们的研究发现代理系统的优越性，并为其核心组件提供可行的设计指南。基准环境已经通过公开挑战进行了严格验证，并持续维护排行榜~②（<a target="_blank" rel="noopener" href="https://tsinghua-fib-lab.github.io/AgentSocietyChallenge/pages/overview.html%EF%BC%89%EF%BC%8C%E4%BF%83%E8%BF%9B%E7%A4%BE%E5%8C%BA%E6%8C%81%E7%BB%AD%E5%8F%82%E4%B8%8E%E5%92%8C%E5%8F%AF%E9%87%8D%E5%A4%8D%E7%9A%84%E7%A0%94%E7%A9%B6%E3%80%82%E5%9F%BA%E5%87%86%E6%B5%8B%E8%AF%95%E5%B9%B3%E5%8F%B0%E9%93%BE%E6%8E%A5%E4%B8%BA%EF%BC%9Ahttps://huggingface.co/datasets/SGJQovo/AgentRecBench%E3%80%82">https://tsinghua-fib-lab.github.io/AgentSocietyChallenge/pages/overview.html），促进社区持续参与和可重复的研究。基准测试平台链接为：https://huggingface.co/datasets/SGJQovo/AgentRecBench。</a></p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.19623v2">PDF</a> 15 pages, 6 figures</p>
<p><strong>Summary</strong>：<br>基于大型语言模型（LLM）的代理推荐系统出现，标志着个性化推荐领域出现范式转变。这种系统利用LLM的高级推理和角色扮演能力，实现自主、自适应的决策制定。与传统推荐方法不同，代理推荐系统能够动态收集并解读用户与项目的互动，适应复杂环境生成稳健的推荐策略。但当前该领域缺乏标准化的评估协议来系统地评估这些方法。为解决这一关键空白，提出了一交互式文本推荐模拟器、一统一模块化框架来开发和研究代理推荐系统以及第一份综合基准测试，对比了10种经典和代理推荐方法。结果表明代理系统的优越性，并为其核心组件提供了可操作的设计指南。</p>
<p><strong>Key Takeaways</strong>：</p>
<ol>
<li>代理推荐系统利用大型语言模型的推理和角色扮演能力实现自主、自适应决策。</li>
<li>代理推荐系统能动态收集并解读用户与项目的互动，适应复杂环境。</li>
<li>当前代理推荐系统领域缺乏标准化的评估协议。</li>
<li>提出了一交互式文本推荐模拟器用于评估代理推荐系统。</li>
<li>提出了统一模块化框架来开发和研究代理推荐系统。</li>
<li>综合基准测试显示代理推荐方法的优越性。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.19623">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pica.zhimg.com/v2-4e4c5ef99906508b46ea35f6b486254e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-012374a3de0a29712347e20f5a7395be.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ad3a185f9517e61e665533bc0fb062f9.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-925638b5ebc6d135890c0a3eb6bea746.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-6ab75a36672412c31eee2f856a3c882d.jpg" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="Deep-Video-Discovery-Agentic-Search-with-Tool-Use-for-Long-form-Video-Understanding"><a href="#Deep-Video-Discovery-Agentic-Search-with-Tool-Use-for-Long-form-Video-Understanding" class="headerlink" title="Deep Video Discovery: Agentic Search with Tool Use for Long-form Video   Understanding"></a>Deep Video Discovery: Agentic Search with Tool Use for Long-form Video   Understanding</h2><p><strong>Authors:Xiaoyi Zhang, Zhaoyang Jia, Zongyu Guo, Jiahao Li, Bin Li, Houqiang Li, Yan Lu</strong></p>
<p>Long-form video understanding presents significant challenges due to extensive temporal-spatial complexity and the difficulty of question answering under such extended contexts. While Large Language Models (LLMs) have demonstrated considerable advancements in video analysis capabilities and long context handling, they continue to exhibit limitations when processing information-dense hour-long videos. To overcome such limitations, we propose the Deep Video Discovery agent to leverage an agentic search strategy over segmented video clips. Different from previous video agents manually designing a rigid workflow, our approach emphasizes the autonomous nature of agents. By providing a set of search-centric tools on multi-granular video database, our DVD agent leverages the advanced reasoning capability of LLM to plan on its current observation state, strategically selects tools, formulates appropriate parameters for actions, and iteratively refines its internal reasoning in light of the gathered information. We perform comprehensive evaluation on multiple long video understanding benchmarks that demonstrates the advantage of the entire system design. Our DVD agent achieves SOTA performance, significantly surpassing prior works by a large margin on the challenging LVBench dataset. Comprehensive ablation studies and in-depth tool analyses are also provided, yielding insights to further advance intelligent agents tailored for long-form video understanding tasks. The code will be released later. </p>
<blockquote>
<p>长视频理解由于巨大的时空复杂性和在如此扩展的上下文下进行问答的困难而面临重大挑战。虽然大型语言模型（LLM）在视频分析能力和长上下文处理方面取得了显著的进步，但在处理信息密集的一小时长的视频时，它们仍然表现出局限性。为了克服这些局限性，我们提出了深度视频发现代理，采用代理搜索策略对分割的视频片段进行处理。不同于以前的手动设计刚性工作流程的视频代理，我们的方法强调代理的自主性。通过在多粒度视频数据库上提供一系列以搜索为中心的工具，我们的DVD代理利用LLM的高级推理能力来规划其当前观察状态，战略性地选择工具，为行动制定适当参数，并根据收集的信息迭代优化其内部推理。我们在多个长视频理解基准测试上进行了全面评估，证明了整个系统设计的优势。我们的DVD代理实现了最先进的性能，在具有挑战性的LVBench数据集上大幅度超越了以前的工作。还提供了全面的消融研究和深入的工具分析，为进一步推进针对长视频理解任务的智能代理提供了见解。代码将在稍后发布。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.18079v2">PDF</a> V2 draft. Under review</p>
<p><strong>Summary</strong>：<br>长视频理解面临巨大的挑战，包括广泛的时空复杂性和在扩展环境下的问答难度。尽管大型语言模型（LLM）在视频分析能力和处理长文本方面取得了显著进展，但在处理信息密集的长视频时仍存在局限性。为解决这一问题，我们提出了Deep Video Discovery（DVD）代理，采用代理搜索策略对分割的视频片段进行处理。不同于以往的视频代理手动设计刚性工作流程，我们的方法侧重于代理的自主性。DVD代理通过提供一系列面向多粒度视频数据库的搜索工具，利用LLM的高级推理能力来规划当前观察状态，战略性地选择工具，制定适当的行动参数，并根据获取的信息迭代地完善其内部推理。我们在多个长视频理解基准测试上对DVD代理进行了全面评估，证明了我们整个系统的优势。DVD代理实现了出色的性能，在具有挑战性的LVBench数据集上大幅超越了以前的工作。同时提供了全面的消融研究和深入的工具分析，为针对长视频理解任务进一步开发智能代理提供了见解。代码将随后发布。</p>
<p><strong>Key Takeaways</strong>：</p>
<ul>
<li>长视频理解存在巨大挑战，源于时空复杂性和问答难度。</li>
<li>大型语言模型（LLM）在处理信息密集的长视频时存在局限性。</li>
<li>Deep Video Discovery（DVD）代理采用自主搜索策略处理分割的视频片段。</li>
<li>DVD代理提供一系列面向多粒度视频数据库的搜索工具，利用LLM的推理能力进行规划、选择工具和参数制定。</li>
<li>DVD代理在多个长视频理解基准测试上表现优异，特别是在具有挑战性的LVBench数据集上。</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.18079">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pica.zhimg.com/v2-6f08ec5ce87cfba6ac999363060b25f5.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-953a2e0735dc1523c356980ffc004edb.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-9bb3d4505eeba5bafd3e3b5fe7e6761c.jpg" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1><h2 id="AI-for-Climate-Finance-Agentic-Retrieval-and-Multi-Step-Reasoning-for-Early-Warning-System-Investments"><a href="#AI-for-Climate-Finance-Agentic-Retrieval-and-Multi-Step-Reasoning-for-Early-Warning-System-Investments" class="headerlink" title="AI for Climate Finance: Agentic Retrieval and Multi-Step Reasoning for   Early Warning System Investments"></a>AI for Climate Finance: Agentic Retrieval and Multi-Step Reasoning for   Early Warning System Investments</h2><p><strong>Authors:Saeid Ario Vaghefi, Aymane Hachcham, Veronica Grasso, Jiska Manicus, Nakiete Msemo, Chiara Colesanti Senni, Markus Leippold</strong></p>
<p>Tracking financial investments in climate adaptation is a complex and expertise-intensive task, particularly for Early Warning Systems (EWS), which lack standardized financial reporting across multilateral development banks (MDBs) and funds. To address this challenge, we introduce an LLM-based agentic AI system that integrates contextual retrieval, fine-tuning, and multi-step reasoning to extract relevant financial data, classify investments, and ensure compliance with funding guidelines. Our study focuses on a real-world application: tracking EWS investments in the Climate Risk and Early Warning Systems (CREWS) Fund. We analyze 25 MDB project documents and evaluate multiple AI-driven classification methods, including zero-shot and few-shot learning, fine-tuned transformer-based classifiers, chain-of-thought (CoT) prompting, and an agent-based retrieval-augmented generation (RAG) approach. Our results show that the agent-based RAG approach significantly outperforms other methods, achieving 87% accuracy, 89% precision, and 83% recall. Additionally, we contribute a benchmark dataset and expert-annotated corpus, providing a valuable resource for future research in AI-driven financial tracking and climate finance transparency. </p>
<blockquote>
<p>跟踪气候适应方面的金融投资是一项复杂且需要专业技能的任务，特别是对于缺乏多边发展银行和基金标准化财务报告的早期预警系统（EWS）而言。为了应对这一挑战，我们引入了一个基于大型语言模型（LLM）的代理人工智能系统，该系统结合了上下文检索、微调和多步推理，以提取相关财务数据、分类投资并确保符合资金指导方针。我们的研究侧重于实际应用：跟踪气候风险与早期预警系统（CREWS）基金中EWS的投资。我们分析了25个MDB项目文件，并评估了多种AI驱动的分类方法，包括零样本和少样本学习、基于微调转换器的分类器、链式思维（CoT）提示和基于代理的检索增强生成（RAG）方法。我们的结果表明，基于代理的RAG方法在其他方法中具有显著优势，达到了87%的准确率、89%的精确率和83%的召回率。此外，我们还提供了一个基准数据集和专家注释语料库，为AI驱动的金融跟踪和气候融资透明度的未来研究提供了宝贵资源。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.05104v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>该文本介绍了一个基于大型语言模型（LLM）的代理人工智能系统，用于追踪气候适应的金融投资。该系统集成了上下文检索、微调和多步推理，能够提取相关财务数据、分类投资并确保符合资金指导方针。研究以气候风险和预警系统基金中的早期预警系统投资追踪为例，分析了25个多边发展银行项目文件，并评估了多种人工智能驱动的分类方法。结果表明，基于代理的RAG方法显著优于其他方法，准确率、精确率和召回率分别达到了87%、89%和83%。此外，该研究还贡献了一个基准数据集和专家注释语料库，为未来的人工智能金融追踪和气候财务透明度研究提供了宝贵资源。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>追踪气候适应的金融投资是一项复杂且需要专业知识的任务，特别是对于缺乏标准化财务报告的早期预警系统而言。</li>
<li>介绍了一个基于大型语言模型的代理人工智能系统，该系统集成上下文检索、微调、多步推理等功能，能有效提取相关财务数据并进行分类。</li>
<li>以气候风险和预警系统基金中的投资追踪为例，研究了25个多边发展银行的项目文件。</li>
<li>评估了多种人工智能驱动的分类方法，包括零样本和少样本学习、微调基于转换器的分类器、链式思维提示和基于代理的检索增强生成方法等。</li>
<li>基于代理的RAG方法被证明在准确率、精确率和召回率方面显著优于其他方法。</li>
<li>研究结果对于提高气候财务透明度具有重要意义。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.05104">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-19184a7ea6fdf4e28241d56e586ef998.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-baa2cf8ae15e9964dd8f8e8bfe075efa.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-09365514e6267da7826d5f8b5cde5eba.jpg" align="middle">
</details>


<h1 id="-9"><a href="#-9" class="headerlink" title=""></a></h1><h2 id="SynWorld-Virtual-Scenario-Synthesis-for-Agentic-Action-Knowledge-Refinement"><a href="#SynWorld-Virtual-Scenario-Synthesis-for-Agentic-Action-Knowledge-Refinement" class="headerlink" title="SynWorld: Virtual Scenario Synthesis for Agentic Action Knowledge   Refinement"></a>SynWorld: Virtual Scenario Synthesis for Agentic Action Knowledge   Refinement</h2><p><strong>Authors:Runnan Fang, Xiaobin Wang, Yuan Liang, Shuofei Qiao, Jialong Wu, Zekun Xi, Ningyu Zhang, Yong Jiang, Pengjun Xie, Fei Huang, Huajun Chen</strong></p>
<p>In the interaction between agents and their environments, agents expand their capabilities by planning and executing actions. However, LLM-based agents face substantial challenges when deployed in novel environments or required to navigate unconventional action spaces. To empower agents to autonomously explore environments, optimize workflows, and enhance their understanding of actions, we propose SynWorld, a framework that allows agents to synthesize possible scenarios with multi-step action invocation within the action space and perform Monte Carlo Tree Search (MCTS) exploration to effectively refine their action knowledge in the current environment. Our experiments demonstrate that SynWorld is an effective and general approach to learning action knowledge in new environments. Code is available at <a target="_blank" rel="noopener" href="https://github.com/zjunlp/SynWorld">https://github.com/zjunlp/SynWorld</a>. </p>
<blockquote>
<p>在智能体与其环境之间的交互中，智能体通过规划和执行行动来扩展其能力。然而，当部署在新型环境中或需要执行非常规动作时，基于大型语言模型的智能体会面临巨大的挑战。为了增强智能体自主探索环境、优化工作流程以及增强对动作的理解能力，我们提出了SynWorld框架。该框架允许智能体在动作空间内合成多步动作调用情景，并执行蒙特卡洛树搜索（MCTS）探索，以有效地在当前环境中优化其动作知识。我们的实验表明，SynWorld是一种在新环境中学习动作知识的有效且通用的方法。代码可在<a target="_blank" rel="noopener" href="https://github.com/zjunlp/SynWorld%E8%8E%B7%E5%8F%96%E3%80%82">https://github.com/zjunlp/SynWorld获取。</a></p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.03561v2">PDF</a> ACL 2025 Findings</p>
<p><strong>Summary</strong></p>
<p>在智能代理与其环境互动的过程中，通过规划与执行动作来扩展其能力。然而，基于大型语言模型（LLM）的代理在部署于新环境或需要执行非传统动作时面临巨大挑战。为此，我们提出SynWorld框架，让代理能够自主探索环境、优化工作流程、增强对动作的理解。该框架允许代理在动作空间内合成可能场景并进行多步骤动作调用，通过蒙特卡洛树搜索（MCTS）探索来有效优化其动作知识。实验证明，SynWorld是在新环境中学习动作知识的一种有效且通用的方法。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>智能代理通过规划与执行动作来扩展其能力。</li>
<li>在新环境或执行非传统动作时，基于大型语言模型的代理面临挑战。</li>
<li>SynWorld框架允许代理合成可能场景并在动作空间内进行多步骤动作调用。</li>
<li>通过蒙特卡洛树搜索（MCTS）探索，SynWorld框架能有效优化代理的动作知识。</li>
<li>SynWorld框架适用于新环境中学习动作知识。</li>
<li>SynWorld框架具有通用性，可广泛应用于各种环境和任务。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.03561">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-a367bb0aeb51185dbbd0861e7c9e4e86.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-5b06fca3d8fa227acc07e5128e2533f9.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-0daf6717e1a34d1f73ddb49930f675d8.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-0ba058e549f3f1e0d1bf4d9dee7766ff.jpg" align="middle">
</details>


<h1 id="-10"><a href="#-10" class="headerlink" title=""></a></h1><h2 id="Leveraging-Dual-Process-Theory-in-Language-Agent-Framework-for-Real-time-Simultaneous-Human-AI-Collaboration"><a href="#Leveraging-Dual-Process-Theory-in-Language-Agent-Framework-for-Real-time-Simultaneous-Human-AI-Collaboration" class="headerlink" title="Leveraging Dual Process Theory in Language Agent Framework for Real-time   Simultaneous Human-AI Collaboration"></a>Leveraging Dual Process Theory in Language Agent Framework for Real-time   Simultaneous Human-AI Collaboration</h2><p><strong>Authors:Shao Zhang, Xihuai Wang, Wenhao Zhang, Chaoran Li, Junru Song, Tingyu Li, Lin Qiu, Xuezhi Cao, Xunliang Cai, Wen Yao, Weinan Zhang, Xinbing Wang, Ying Wen</strong></p>
<p>Agents built on large language models (LLMs) have excelled in turn-by-turn human-AI collaboration but struggle with simultaneous tasks requiring real-time interaction. Latency issues and the challenge of inferring variable human strategies hinder their ability to make autonomous decisions without explicit instructions. Through experiments with current independent System 1 and System 2 methods, we validate the necessity of using Dual Process Theory (DPT) in real-time tasks. We propose DPT-Agent, a novel language agent framework that integrates System 1 and System 2 for efficient real-time simultaneous human-AI collaboration. DPT-Agent’s System 1 uses a Finite-state Machine (FSM) and code-as-policy for fast, intuitive, and controllable decision-making. DPT-Agent’s System 2 integrates Theory of Mind (ToM) and asynchronous reflection to infer human intentions and perform reasoning-based autonomous decisions. We demonstrate the effectiveness of DPT-Agent through further experiments with rule-based agents and human collaborators, showing significant improvements over mainstream LLM-based frameworks. DPT-Agent can effectively help LLMs convert correct slow thinking and reasoning into executable actions, thereby improving performance. To the best of our knowledge, DPT-Agent is the first language agent framework that achieves successful real-time simultaneous human-AI collaboration autonomously. Code of DPT-Agent can be found in <a target="_blank" rel="noopener" href="https://github.com/sjtu-marl/DPT-Agent">https://github.com/sjtu-marl/DPT-Agent</a>. </p>
<blockquote>
<p>基于大型语言模型（LLM）的代理人在逐轮的人机协作中表现出色，但在需要实时交互的同时任务中遇到了困难。延迟问题和推断可变人类策略的挑战影响了它们在没有明确指令的情况下进行自主决策的能力。通过当前独立的System 1和System 2方法的实验，我们验证了在实时任务中使用双过程理论（DPT）的必要性。我们提出了DPT-Agent，这是一种新型的语言代理框架，它融合了System 1和System 2，以实现高效实时的同时人机协作。DPT-Agent的System 1使用有限状态机（FSM）和代码即策略，以实现快速、直观和可控的决策。DPT-Agent的System 2融合了心智理论（ToM）和异步反射，以推断人类意图并进行基于推理的自主决策。我们通过与基于规则的代理人和人类合作者进一步实验，证明了DPT-Agent的有效性，显示出在主流LLM框架上的显著改进。DPT-Agent可以有效地帮助LLM将正确的慢思考和推理转化为可执行行动，从而提高性能。据我们所知，DPT-Agent是第一个成功实现实时同时人机协作的自主语言代理框架。DPT-Agent的代码可在<a target="_blank" rel="noopener" href="https://github.com/sjtu-marl/DPT-Agent">https://github.com/sjtu-marl/DPT-Agent</a>找到。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.11882v5">PDF</a> Accepted by ACL 2025 Main. Camera Ready Version</p>
<p><strong>Summary</strong>：<br>基于大型语言模型的代理在逐步人机协作方面表现出色，但在需要实时互动的同时多任务中表现出局限性。为应对此挑战，本研究提出Dual Process Theory（DPT）的必要性，并设计DPT-Agent框架，整合System 1和System 2以实现高效实时人机协作。DPT-Agent通过Finite-state Machine（FSM）进行直观可控的决策，并集成Theory of Mind（ToM）进行推理自主决策。实验证明，DPT-Agent在基于规则的主流语言模型框架上有显著改善，能成功实现实时同步人机协作自主化。其代码可访问：<a target="_blank" rel="noopener" href="https://github.com/sjtu-marl/DPT-Agent">链接地址</a>。</p>
<p><strong>Key Takeaways</strong>：</p>
<ul>
<li>大型语言模型代理在逐步人机协作中表现出优势，但在实时多任务中面临挑战。</li>
<li>实时任务需要自主决策能力，要求AI理解并推断人类意图。</li>
<li>Dual Process Theory（DPT）是解决这些问题的关键理论工具。</li>
<li>DPT-Agent结合了System 1和System 2实现高效实时人机协作。</li>
<li>DPT-Agent使用Finite-state Machine（FSM）进行快速决策，并结合Theory of Mind（ToM）进行推理自主决策。</li>
<li>与基于规则的主流语言模型相比，DPT-Agent在实验中表现优异。</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.11882">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-f1418b7c758a3532db72017e2c0bdb44.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-86beff2b8789d6bbf5206fd03f5858ca.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c5bce3d669de34c6bbd8bd3e1abc137a.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-daab1b28b518650e2816271c74d45227.jpg" align="middle">
</details>


<h1 id="-11"><a href="#-11" class="headerlink" title=""></a></h1><h2 id="Memento-No-More-Coaching-AI-Agents-to-Master-Multiple-Tasks-via-Hints-Internalization"><a href="#Memento-No-More-Coaching-AI-Agents-to-Master-Multiple-Tasks-via-Hints-Internalization" class="headerlink" title="Memento No More: Coaching AI Agents to Master Multiple Tasks via Hints   Internalization"></a>Memento No More: Coaching AI Agents to Master Multiple Tasks via Hints   Internalization</h2><p><strong>Authors:Minttu Alakuijala, Ya Gao, Georgy Ananov, Samuel Kaski, Pekka Marttinen, Alexander Ilin, Harri Valpola</strong></p>
<p>As the general capabilities of artificial intelligence (AI) agents continue to evolve, their ability to learn to master multiple complex tasks through experience remains a key challenge. Current LLM agents, particularly those based on proprietary language models, typically rely on prompts to incorporate knowledge about the target tasks. This approach does not allow the agent to internalize this information and instead relies on ever-expanding prompts to sustain its functionality in diverse scenarios. This resembles a system of notes used by a person affected by anterograde amnesia, the inability to form new memories. In this paper, we propose a novel method to train AI agents to incorporate knowledge and skills for multiple tasks without the need for either cumbersome note systems or prior high-quality demonstration data. Our approach employs an iterative process where the agent collects new experiences, receives corrective feedback from humans in the form of hints, and integrates this feedback into its weights via a context distillation training procedure. We demonstrate the efficacy of our approach by implementing it in a Llama-3-based agent that, after only a few rounds of feedback, outperforms advanced models GPT-4o and DeepSeek-V3 in tasksets requiring correct sequencing of information retrieval, tool use, and question answering. </p>
<blockquote>
<p>随着人工智能（AI）代理的一般能力不断发展，它们通过经验学习掌握多种复杂任务的能力仍然是一个关键挑战。当前的大型语言模型代理（LLM代理），特别是基于专有语言模型的代理，通常依赖于提示来融入目标任务的知识。这种方法不允许代理内化这些信息，而是依赖于不断扩大的提示来维持其在不同场景中的功能。这就像一个患有顺行性失忆症的人使用的笔记系统，患者无法形成新的记忆。在本文中，我们提出了一种新方法，用于训练AI代理融入多项任务的知识和技能，无需使用繁琐的笔记系统或预先的高质量演示数据。我们的方法采用迭代过程，代理收集新经验，以提示的形式接收来自人类的纠正反馈，并通过上下文蒸馏训练程序将反馈整合到其权重中。我们通过在一个基于Llama-3的代理中实现该方法，证明了我们方法的有效性。该代理仅在几轮反馈后，就在需要正确排序信息检索、工具使用和问答的任务集中表现出优于GPT-4o和DeepSeek-V3等先进模型的表现。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.01562v2">PDF</a> </p>
<p><strong>Summary</strong><br>     人工智能代理人的通用能力不断进化，当前的大型语言模型（LLM）代理人在面对多样化场景时仍面临学习掌握多重复杂任务的主要挑战。传统的依赖提示融入目标任务知识的方法不允许代理人内化这些信息，并依赖于不断扩展的提示来维持其功能。本文提出一种新型方法来训练AI代理人无需冗长的提示系统或优质示范数据即可完成多项任务的方法。该方法采用迭代过程，代理人收集新经验，从人类提示中获得纠正反馈，通过上下文蒸馏训练程序将反馈融入权重。通过基于Llama-3的代理人实践证实该方法的有效性，在经过几轮反馈后，其在需要正确排序信息检索、工具使用和问答的任务集中表现优于GPT-4o和DeepSeek-V3模型。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>人工智能代理人在学习掌握多重复杂任务方面面临挑战。</li>
<li>当前的大型语言模型（LLM）代理人依赖提示来融入目标任务的情境信息。</li>
<li>传统方法不允许AI代理人内化任务知识，依赖于不断扩展的提示维持功能。</li>
<li>本文提出一种新型训练AI代理人方法，无需冗长的提示系统或优质示范数据即可实现多项任务处理。</li>
<li>该方法采用迭代过程，包括收集新经验、从人类提示中获得纠正反馈、通过上下文蒸馏训练程序将反馈融入权重。</li>
<li>实施方法的是基于Llama-3的代理人，经过几轮反馈后表现优异。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.01562">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-bb0a53d07e67b24d76cec7d7e4f0e29b.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-d65cb9ea7ef00425730f99f36c059156.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-3ee70df3f4e68b97d3a832f4fdd52f67.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-23a1270a58580185d47fc1986ee0984a.jpg" align="middle">
</details>


<h1 id="-12"><a href="#-12" class="headerlink" title=""></a></h1><h2 id="AdvAgent-Controllable-Blackbox-Red-teaming-on-Web-Agents"><a href="#AdvAgent-Controllable-Blackbox-Red-teaming-on-Web-Agents" class="headerlink" title="AdvAgent: Controllable Blackbox Red-teaming on Web Agents"></a>AdvAgent: Controllable Blackbox Red-teaming on Web Agents</h2><p><strong>Authors:Chejian Xu, Mintong Kang, Jiawei Zhang, Zeyi Liao, Lingbo Mo, Mengqi Yuan, Huan Sun, Bo Li</strong></p>
<p>Foundation model-based agents are increasingly used to automate complex tasks, enhancing efficiency and productivity. However, their access to sensitive resources and autonomous decision-making also introduce significant security risks, where successful attacks could lead to severe consequences. To systematically uncover these vulnerabilities, we propose AdvAgent, a black-box red-teaming framework for attacking web agents. Unlike existing approaches, AdvAgent employs a reinforcement learning-based pipeline to train an adversarial prompter model that optimizes adversarial prompts using feedback from the black-box agent. With careful attack design, these prompts effectively exploit agent weaknesses while maintaining stealthiness and controllability. Extensive evaluations demonstrate that AdvAgent achieves high success rates against state-of-the-art GPT-4-based web agents across diverse web tasks. Furthermore, we find that existing prompt-based defenses provide only limited protection, leaving agents vulnerable to our framework. These findings highlight critical vulnerabilities in current web agents and emphasize the urgent need for stronger defense mechanisms. We release code at <a target="_blank" rel="noopener" href="https://ai-secure.github.io/AdvAgent/">https://ai-secure.github.io/AdvAgent/</a>. </p>
<blockquote>
<p>基于模型的智能代理正被越来越多地用于自动化复杂任务，以提高效率和生产力。然而，它们访问敏感资源和自主决策的能力也带来了重大的安全风险，成功的攻击可能导致严重后果。为了系统地揭示这些漏洞，我们提出了AdvAgent，这是一个用于攻击网络智能代理的黑箱红队框架。与现有方法不同，AdvAgent采用基于强化学习的管道来训练对抗性提示模型，该模型使用来自黑箱智能代理的反馈来优化对抗性提示。通过精心设计的攻击，这些提示能够有效地利用智能代理的弱点，同时保持隐蔽性和可控性。广泛的评估表明，AdvAgent在多种网络任务上针对最先进的GPT-4基于网络的智能代理取得了较高的成功率。此外，我们发现现有的基于提示的防御措施只提供了有限的保护，使智能代理容易受到我们的框架的攻击。这些发现突出了当前网络智能代理中的关键漏洞，并强调了迫切需要更强大的防御机制。我们已将代码发布在<a target="_blank" rel="noopener" href="https://ai-secure.github.io/AdvAgent/%E4%B8%8A%E3%80%82">https://ai-secure.github.io/AdvAgent/上。</a></p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2410.17401v3">PDF</a> ICML 2025</p>
<p><strong>Summary</strong></p>
<p>基于模型的自动化代理广泛应用于复杂任务，提高了效率和生产力，但其访问敏感资源和自主决策能力也带来了安全风险。为此，我们提出了AdvAgent这一针对网络代理攻击的黑盒红队框架。AdvAgent采用基于强化学习的管道训练对抗提示模型，通过对黑盒代理的反馈优化对抗提示，有效地发现并利用代理弱点。评估显示，AdvAgent针对先进的GPT-4网络代理取得了高成功率。现有基于提示的防御措施仅提供有限保护，强调了增强防御机制的紧迫性。代码公开在<a target="_blank" rel="noopener" href="https://ai-secure.github.io/AdvAgent/">https://ai-secure.github.io/AdvAgent/</a>。</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>基于模型的代理广泛应用于自动化复杂任务，提高效率和生产力。</li>
<li>这些代理存在安全风险，特别是关于访问敏感资源和自主决策。</li>
<li>AdvAgent是一种针对网络代理的黑盒红队攻击框架。</li>
<li>AdvAgent采用强化学习管道训练对抗提示模型来优化对抗提示。</li>
<li>该框架能有效发现并利用网络代理的弱点。</li>
<li>AdvAgent针对先进的GPT-4网络代理取得了高成功率。</li>
<li>目前基于提示的防御措施仅提供有限保护。</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2410.17401">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-4857beba288720e79001e15e5efc0364.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-3e6b21e9aceebe77bdb85f7c8a696f4d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-75b749f30a4b57aa6d135082f3837938.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c985d0b26efce827993f5d742643a64a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-53a0d7031a484d6944aed63374b5cddd.jpg" align="middle">
</details>


<h1 id="-13"><a href="#-13" class="headerlink" title=""></a></h1><h2 id="LAMBDA-A-Large-Model-Based-Data-Agent"><a href="#LAMBDA-A-Large-Model-Based-Data-Agent" class="headerlink" title="LAMBDA: A Large Model Based Data Agent"></a>LAMBDA: A Large Model Based Data Agent</h2><p><strong>Authors:Maojun Sun, Ruijian Han, Binyan Jiang, Houduo Qi, Defeng Sun, Yancheng Yuan, Jian Huang</strong></p>
<p>We introduce LArge Model Based Data Agent (LAMBDA), a novel open-source, code-free multi-agent data analysis system that leverages the power of large language models. LAMBDA is designed to address data analysis challenges in data-driven applications through innovatively designed data agents using natural language. At the core of LAMBDA are two key agent roles: the programmer and the inspector, which are engineered to work together seamlessly. Specifically, the programmer generates code based on the user’s instructions and domain-specific knowledge, while the inspector debugs the code when necessary. To ensure robustness and handle adverse scenarios, LAMBDA features a user interface that allows direct user intervention. Moreover, LAMBDA can flexibly integrate external models and algorithms through our proposed Knowledge Integration Mechanism, catering to the needs of customized data analysis. LAMBDA has demonstrated strong performance on various data analysis tasks. It has the potential to enhance data analysis paradigms by seamlessly integrating human and artificial intelligence, making it more accessible, effective, and efficient for users from diverse backgrounds. The strong performance of LAMBDA in solving data analysis problems is demonstrated using real-world data examples. The code for LAMBDA is available at <a target="_blank" rel="noopener" href="https://github.com/AMA-CMFAI/LAMBDA">https://github.com/AMA-CMFAI/LAMBDA</a> and videos of three case studies can be viewed at <a target="_blank" rel="noopener" href="https://www.polyu.edu.hk/ama/cmfai/lambda.html">https://www.polyu.edu.hk/ama/cmfai/lambda.html</a>. </p>
<blockquote>
<p>我们介绍基于大模型的Data Agent（LAMBDA），这是一个新型开源、免编程的多智能体数据分析系统，利用大型语言模型的强大功能。LAMBDA旨在通过采用自然语言创新设计的智能体来解决数据驱动应用中的数据分析挑战。在LAMBDA的核心是两个关键智能体角色：程序员和检查员，它们被无缝地设计在一起协同工作。具体来说，程序员根据用户的指令和领域特定知识生成代码，而检查员在必要时进行调试。为了确保稳健性并应对不利场景，LAMBDA提供了一个用户界面，允许直接用户干预。此外，LAMBDA可以通过我们提出的知识整合机制灵活地集成外部模型和算法，满足定制数据分析的需求。在各种数据分析任务中，LAMBDA表现出了强大的性能。它具有通过无缝整合人工智能和人类智能来提升数据分析模式的潜力，为来自不同背景的用户提供更便捷、有效和高效的分析体验。通过真实世界的数据示例展示了LAMBDA在解决数据分析问题方面的强大性能。有关LAMBDA的代码可在[<a target="_blank" rel="noopener" href="https://github.com/AMA-CMFAI/LAMBDA%E6%89%BE%E5%88%B0%EF%BC%8C%E4%B8%89%E4%B8%AA%E6%A1%88%E4%BE%8B%E7%A0%94%E7%A9%B6%E7%9A%84%E8%A7%86%E9%A2%91%E5%8F%AF%E5%9C%A8[https://www.polyu.edu.hk/ama/cmfai/lambda.html%E8%A7%82%E7%9C%8B%E3%80%82](https://www.polyu.edu.hk/ama/cmfai/lambda.html%E8%A7%A3%E5%B9%BF%E3%80%82)">https://github.com/AMA-CMFAI/LAMBDA找到，三个案例研究的视频可在[https://www.polyu.edu.hk/ama/cmfai/lambda.html观看。](https://www.polyu.edu.hk/ama/cmfai/lambda.html%E8%A7%A3%E5%B9%BF%E3%80%82)</a></p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2407.17535v3">PDF</a> 56 pages</p>
<p><strong>Summary</strong></p>
<p>LAMBDA是一个开源、免编程的多智能体数据分析系统，它利用大型语言模型的威力，通过自然语言创新设计的数据智能体来解决数据分析挑战。系统核心包括程序员和检查员两个关键智能体角色，可生成代码、调试代码，并可通过用户界面直接干预。此外，LAMBDA可灵活集成外部模型和算法，满足定制数据分析的需求。它在各种数据分析任务中表现出强大的性能，展示了人与人工智能无缝集成的潜力。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>LAMBDA是一个开源、免编程的多智能体数据分析系统。</li>
<li>利用大型语言模型的威力进行数据分析。</li>
<li>系统中包含两个关键智能体角色：程序员和检查员。</li>
<li>程序员根据用户指令和领域知识生成代码，检查员则负责调试。</li>
<li>用户界面允许直接干预，确保系统的稳健性。</li>
<li>LAMBDA可灵活集成外部模型和算法，满足定制需求。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2407.17535">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-8539fc8a58030c552ebfef2ccfe3d871.jpg" align="middle">
</details>


<h1 id="-14"><a href="#-14" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        文章作者:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        文章链接:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-05-30/Agent/">https://kedreamix.github.io/Talk2Paper/Paper/2025-05-30/Agent/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        版权声明:
                    </i>
                </span>
                <span class="reprint-info">
                    本博客所有文章除特別声明外，均采用
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    许可协议。转载请注明来源
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/Agent/">
                                    <span class="chip bg-color">Agent</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;上一篇</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-05-30/MMT/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-b65ecbcd674cfe162fe2029826adc661.jpg" class="responsive-img" alt="MMT">
                        
                        <span class="card-title">MMT</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            MMT 方向最新论文已更新，请持续关注 Update in 2025-05-30  MTVQA Benchmarking Multilingual Text-Centric Visual Question Answering
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-05-30
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/MMT/" class="post-category">
                                    MMT
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/MMT/">
                        <span class="chip bg-color">MMT</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-05-30/LLM/">
                    <div class="card-image">
                        
                        <img src="https://pic1.zhimg.com/v2-89671461f58ca318de287f7fc336ee70.jpg" class="responsive-img" alt="LLM">
                        
                        <span class="card-title">LLM</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            LLM 方向最新论文已更新，请持续关注 Update in 2025-05-30  3DLLM-Mem Long-Term Spatial-Temporal Memory for Embodied 3D Large   Language Model
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-05-30
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/LLM/" class="post-category">
                                    LLM
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/LLM/">
                        <span class="chip bg-color">LLM</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- 代码语言 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span
                        class="white-color">26548.9k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- 运行天数提醒. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // 区分是否有年份.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = '本站已运行 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                daysTip = '本站已運行 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = '本站已运行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = '本站已運行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="关注我的知乎: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">知</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- 白天和黑夜主题 -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // 只在桌面版网页启用特效
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- 雪花特效 -->
    

    <!-- 鼠标星星特效 -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--腾讯兔小巢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- 动态标签 -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Σ(っ °Д °;)っ诶，页面崩溃了嘛？", clearTimeout(st)) : (document.title = "φ(゜▽゜*)♪咦，又好了！", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
