<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Agent">
    <meta name="description" content="Agent æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-05-30  Position Uncertainty Quantification Needs Reassessment for   Large-language Model Agents">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>Agent | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://pica.zhimg.com/v2-bb307dc4e1461f88213a6d3aa7fc133c.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Agent</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/Agent/">
                                <span class="chip bg-color">Agent</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/Agent/" class="post-category">
                                Agent
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-05-30
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-06-24
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    15k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    61 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-05-30-æ›´æ–°"><a href="#2025-05-30-æ›´æ–°" class="headerlink" title="2025-05-30 æ›´æ–°"></a>2025-05-30 æ›´æ–°</h1><h2 id="Position-Uncertainty-Quantification-Needs-Reassessment-for-Large-language-Model-Agents"><a href="#Position-Uncertainty-Quantification-Needs-Reassessment-for-Large-language-Model-Agents" class="headerlink" title="Position: Uncertainty Quantification Needs Reassessment for   Large-language Model Agents"></a>Position: Uncertainty Quantification Needs Reassessment for   Large-language Model Agents</h2><p><strong>Authors:Michael Kirchhof, Gjergji Kasneci, Enkelejda Kasneci</strong></p>
<p>Large-language models (LLMs) and chatbot agents are known to provide wrong outputs at times, and it was recently found that this can never be fully prevented. Hence, uncertainty quantification plays a crucial role, aiming to quantify the level of ambiguity in either one overall number or two numbers for aleatoric and epistemic uncertainty. This position paper argues that this traditional dichotomy of uncertainties is too limited for the open and interactive setup that LLM agents operate in when communicating with a user, and that we need to research avenues that enrich uncertainties in this novel scenario. We review the literature and find that popular definitions of aleatoric and epistemic uncertainties directly contradict each other and lose their meaning in interactive LLM agent settings. Hence, we propose three novel research directions that focus on uncertainties in such human-computer interactions: Underspecification uncertainties, for when users do not provide all information or define the exact task at the first go, interactive learning, to ask follow-up questions and reduce the uncertainty about the current context, and output uncertainties, to utilize the rich language and speech space to express uncertainties as more than mere numbers. We expect that these new ways of dealing with and communicating uncertainties will lead to LLM agent interactions that are more transparent, trustworthy, and intuitive. </p>
<blockquote>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å’ŒèŠå¤©æœºå™¨äººä»£ç†æœ‰æ—¶ä¼šäº§ç”Ÿé”™è¯¯çš„è¾“å‡ºï¼Œæœ€è¿‘çš„ç ”ç©¶å‘ç°è¿™ç§æƒ…å†µæ— æ³•å®Œå…¨é¿å…ã€‚å› æ­¤ï¼Œä¸ç¡®å®šæ€§é‡åŒ–æ‰®æ¼”ç€è‡³å…³é‡è¦çš„è§’è‰²ï¼Œæ—¨åœ¨é‡åŒ–æ€»ä½“ä¸Šçš„ä¸€ä¸ªæ•°å­—æˆ–ä¸¤ä¸ªæ•°å­—åˆ†åˆ«ä»£è¡¨å¶ç„¶ä¸ç¡®å®šæ€§å’Œè®¤çŸ¥ä¸ç¡®å®šæ€§çš„æ¨¡ç³Šç¨‹åº¦ã€‚è¿™ç¯‡ç«‹åœºè®ºæ–‡è®¤ä¸ºï¼Œå¯¹äºä¸ç”¨æˆ·è¿›è¡Œäº¤æµçš„å¤§å‹è¯­è¨€æ¨¡å‹ä»£ç†æ‰€å¤„çš„å¼€æ”¾äº’åŠ¨ç¯å¢ƒä¸­ï¼Œè¿™ç§ä¼ ç»Ÿçš„ä¸ç¡®å®šæ€§äºŒåˆ†æ³•è¿‡äºå±€é™ã€‚æˆ‘ä»¬éœ€è¦ç ”ç©¶å¦‚ä½•åœ¨è¿™ä¸ªæ–°åœºæ™¯ä¸­ä¸°å¯Œä¸ç¡®å®šæ€§çš„æ–¹æ³•ã€‚æˆ‘ä»¬å›é¡¾äº†æ–‡çŒ®ï¼Œå‘ç°å¶ç„¶ä¸ç¡®å®šæ€§å’Œè®¤çŸ¥ä¸ç¡®å®šæ€§çš„æµè¡Œå®šä¹‰ç›´æ¥ç›¸äº’çŸ›ç›¾ï¼Œåœ¨äº’åŠ¨çš„å¤§å‹è¯­è¨€æ¨¡å‹ä»£ç†ç¯å¢ƒä¸­å¤±å»æ„ä¹‰ã€‚å› æ­¤ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸‰ä¸ªæ–°çš„ç ”ç©¶æ–¹å‘ï¼Œä¾§é‡äºåœ¨äººæœºäº’åŠ¨ä¸­çš„ä¸ç¡®å®šæ€§ï¼šå½“ç”¨æˆ·æ²¡æœ‰æä¾›æ‰€æœ‰ä¿¡æ¯æˆ–é¦–æ¬¡å®šä¹‰ç¡®åˆ‡ä»»åŠ¡æ—¶çš„è§„æ ¼ä¸æ˜ç¡®æ€§ã€é€šè¿‡æå‡ºåç»­é—®é¢˜å‡å°‘å½“å‰ä¸Šä¸‹æ–‡ä¸ç¡®å®šæ€§çš„äº’åŠ¨å­¦ä¹ ï¼Œä»¥åŠåˆ©ç”¨ä¸°å¯Œçš„è¯­è¨€å’Œè¯­éŸ³ç©ºé—´è¡¨è¾¾ä¸ä»…ä»…æ˜¯æ•°å­—çš„ä¸ç¡®å®šæ€§è¾“å‡ºä¸ç¡®å®šæ€§ã€‚æˆ‘ä»¬é¢„è®¡è¿™äº›æ–°çš„å¤„ç†å’Œç®¡ç†ä¸ç¡®å®šæ€§çš„æ–¹æ³•å°†ä½¿å¤§å‹è¯­è¨€æ¨¡å‹ä»£ç†çš„äº’åŠ¨æ›´åŠ é€æ˜ã€å¯ä¿¡å’Œç›´è§‚ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.22655v1">PDF</a> Accepted at ICML 2025</p>
<p><strong>Summary</strong></p>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å’ŒèŠå¤©æœºå™¨äººä»£ç†æœ‰æ—¶ä¼šæä¾›é”™è¯¯çš„è¾“å‡ºï¼Œä¸”è¿™æ— æ³•å®Œå…¨é¿å…ã€‚å› æ­¤ï¼Œä¸ç¡®å®šæ€§é‡åŒ–æ˜¯å…³é”®ï¼Œæ—¨åœ¨é‡åŒ–aleatoricå’Œepistemicä¸ç¡®å®šæ€§çš„æ°´å¹³ã€‚è¿™ç¯‡ç«‹åœºè®ºæ–‡è®¤ä¸ºï¼Œå¯¹äºä¸ç”¨æˆ·äº¤äº’çš„å¤§å‹è¯­è¨€æ¨¡å‹ä»£ç†çš„å¼€æ”¾å’Œäº¤äº’å¼è®¾ç½®ï¼Œä¼ ç»Ÿçš„ä¸ç¡®å®šæ€§äºŒåˆ†æ³•è¿‡äºå±€é™ã€‚æˆ‘ä»¬æå‡ºäº†ä¸‰ä¸ªæ–°çš„ç ”ç©¶æ–¹å‘ï¼Œé‡ç‚¹å…³æ³¨è¿™ç§äººæœºäº¤äº’ä¸­çš„ä¸ç¡®å®šæ€§ï¼šæœªæŒ‡å®šä¿¡æ¯çš„ä¸ç¡®å®šæ€§ã€äº’åŠ¨å­¦ä¹ å‡å°‘å½“å‰ä¸Šä¸‹æ–‡ä¸ç¡®å®šæ€§çš„æ–¹æ³•å’Œè¾“å‡ºä¸ç¡®å®šæ€§ï¼Œåˆ©ç”¨ä¸°å¯Œçš„è¯­è¨€å’Œè¯­éŸ³ç©ºé—´æ¥è¡¨è¾¾ä¸ä»…ä»…æ˜¯æ•°å­—çš„ä¸ç¡®å®šæ€§ã€‚é¢„æœŸè¿™äº›æ–°çš„ä¸ç¡®å®šæ€§å¤„ç†å’Œæ²Ÿé€šæ–¹å¼å°†å¸¦æ¥æ›´åŠ é€æ˜ã€å¯é å’Œç›´è§‚çš„å¤§å‹è¯­è¨€æ¨¡å‹ä»£ç†äº¤äº’ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å’ŒèŠå¤©æœºå™¨äººä»£ç†æœ‰æ—¶ä¼šæä¾›é”™è¯¯çš„è¾“å‡ºï¼Œè¿™æ˜¯æ— æ³•å®Œå…¨é¿å…çš„ã€‚</li>
<li>ä¸ç¡®å®šæ€§é‡åŒ–åœ¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä¸­è‡³å…³é‡è¦ï¼Œå°¤å…¶æ˜¯åœ¨ä¸ç”¨æˆ·äº¤äº’æ—¶ã€‚</li>
<li>ä¼ ç»Ÿçš„ä¸ç¡®å®šæ€§äºŒåˆ†æ³•å¯¹äºå¤§å‹è¯­è¨€æ¨¡å‹ä»£ç†çš„å¼€æ”¾å¼å’Œäº¤äº’å¼è®¾ç½®è¿‡äºå±€é™ã€‚</li>
<li>æœªæŒ‡å®šä¿¡æ¯çš„ä¸ç¡®å®šæ€§åœ¨å¤§å‹è¯­è¨€æ¨¡å‹ä»£ç†ä¸ç”¨æˆ·äº¤äº’ä¸­æ˜¯ä¸€ä¸ªé‡è¦çš„é—®é¢˜ã€‚</li>
<li>é€šè¿‡äº’åŠ¨å­¦ä¹ å¯ä»¥å‡å°‘ä¸Šä¸‹æ–‡çš„ä¸ç¡®å®šæ€§ã€‚</li>
<li>è¾“å‡ºä¸ç¡®å®šæ€§å¯ä»¥åˆ©ç”¨ä¸°å¯Œçš„è¯­è¨€å’Œè¯­éŸ³ç©ºé—´æ¥è¡¨è¾¾ä¸ç¡®å®šæ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.22655">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-7266bd01812f1fcbf5103ebd858a6790.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-5cd1cbb1418e22ca035c93e7a6fbea02.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-bca35510bc394b19ec3858d33979d00e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a4007323d2cd7996885b5bfe9edf29ac.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-96aba5bf41e8a4cceece2931a4a09452.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="HDDLGym-A-Tool-for-Studying-Multi-Agent-Hierarchical-Problems-Defined-in-HDDL-with-OpenAI-Gym"><a href="#HDDLGym-A-Tool-for-Studying-Multi-Agent-Hierarchical-Problems-Defined-in-HDDL-with-OpenAI-Gym" class="headerlink" title="HDDLGym: A Tool for Studying Multi-Agent Hierarchical Problems Defined   in HDDL with OpenAI Gym"></a>HDDLGym: A Tool for Studying Multi-Agent Hierarchical Problems Defined   in HDDL with OpenAI Gym</h2><p><strong>Authors:Ngoc La, Ruaridh Mon-Williams, Julie A. Shah</strong></p>
<p>In recent years, reinforcement learning (RL) methods have been widely tested using tools like OpenAI Gym, though many tasks in these environments could also benefit from hierarchical planning. However, there is a lack of a tool that enables seamless integration of hierarchical planning with RL. Hierarchical Domain Definition Language (HDDL), used in classical planning, introduces a structured approach well-suited for model-based RL to address this gap. To bridge this integration, we introduce HDDLGym, a Python-based tool that automatically generates OpenAI Gym environments from HDDL domains and problems. HDDLGym serves as a link between RL and hierarchical planning, supporting multi-agent scenarios and enabling collaborative planning among agents. This paper provides an overview of HDDLGymâ€™s design and implementation, highlighting the challenges and design choices involved in integrating HDDL with the Gym interface, and applying RL policies to support hierarchical planning. We also provide detailed instructions and demonstrations for using the HDDLGym framework, including how to work with existing HDDL domains and problems from International Planning Competitions, exemplified by the Transport domain. Additionally, we offer guidance on creating new HDDL domains for multi-agent scenarios and demonstrate the practical use of HDDLGym in the Overcooked domain. By leveraging the advantages of HDDL and Gym, HDDLGym aims to be a valuable tool for studying RL in hierarchical planning, particularly in multi-agent contexts. </p>
<blockquote>
<p>è¿‘å¹´æ¥ï¼Œå¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰æ–¹æ³•å·²å¹¿æ³›åˆ©ç”¨OpenAI Gymç­‰å·¥å…·è¿›è¡Œæµ‹è¯•ï¼Œå°½ç®¡è¿™äº›ç¯å¢ƒä¸­çš„è®¸å¤šä»»åŠ¡ä¹Ÿå¯ä»¥ä»åˆ†å±‚è§„åˆ’ä¸­å—ç›Šã€‚ç„¶è€Œï¼Œç›®å‰ç¼ºä¹èƒ½å¤Ÿå°†åˆ†å±‚è§„åˆ’ä¸RLæ— ç¼é›†æˆçš„å·¥å…·ã€‚ç”¨äºç»å…¸è§„åˆ’çš„åˆ†å±‚é¢†åŸŸå®šä¹‰è¯­è¨€ï¼ˆHDDLï¼‰å¼•å…¥äº†ä¸€ç§é€‚ç”¨äºåŸºäºæ¨¡å‹çš„RLçš„ç»“æ„åŒ–æ–¹æ³•ï¼Œä»¥å¼¥è¡¥è¿™ä¸€ç©ºç™½ã€‚ä¸ºäº†å¼¥è¿™ä¸€æ•´åˆé¸¿æ²Ÿï¼Œæˆ‘ä»¬å¼•å…¥äº†HDDLGymï¼Œè¿™æ˜¯ä¸€ä¸ªåŸºäºPythonçš„å·¥å…·ï¼Œå®ƒå¯ä»¥ä»HDDLé¢†åŸŸå’Œé—®é¢˜è‡ªåŠ¨ç”ŸæˆOpenAI Gymç¯å¢ƒã€‚HDDLGymæ˜¯RLå’Œåˆ†å±‚è§„åˆ’ä¹‹é—´çš„æ¡¥æ¢ï¼Œæ”¯æŒå¤šæ™ºèƒ½ä½“åœºæ™¯å¹¶åœ¨æ™ºèƒ½ä½“ä¹‹é—´è¿›è¡Œåä½œè§„åˆ’ã€‚æœ¬æ–‡æ¦‚è¿°äº†HDDLGymçš„è®¾è®¡ä¸å®æ–½ï¼Œé‡ç‚¹ä»‹ç»äº†å°†HDDLä¸Gymæ¥å£é›†æˆæ‰€æ¶‰åŠçš„æŒ‘æˆ˜å’Œè®¾è®¡é€‰æ‹©ï¼Œä»¥åŠåº”ç”¨RLç­–ç•¥æ¥æ”¯æŒåˆ†å±‚è§„åˆ’ã€‚æˆ‘ä»¬è¿˜æä¾›äº†ä½¿ç”¨HDDLGymæ¡†æ¶çš„è¯¦ç»†è¯´æ˜å’Œæ¼”ç¤ºï¼ŒåŒ…æ‹¬å¦‚ä½•ä¸å›½é™…è§„åˆ’ç«èµ›ä¸­çš„ç°æœ‰HDDLé¢†åŸŸå’Œé—®é¢˜ä¸€èµ·å·¥ä½œï¼Œä»¥è¿è¾“é¢†åŸŸä¸ºä¾‹ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜æä¾›äº†ä¸ºå¤šäººåœºæ™¯åˆ›å»ºæ–°HDDLé¢†åŸŸçš„æŒ‡å¯¼ï¼Œå¹¶åœ¨Overcookedé¢†åŸŸä¸­å±•ç¤ºäº†HDDLGymçš„å®é™…åº”ç”¨ã€‚é€šè¿‡åˆ©ç”¨HDDLå’ŒGymçš„ä¼˜åŠ¿ï¼ŒHDDLGymæ—¨åœ¨æˆä¸ºç ”ç©¶åˆ†å±‚è§„åˆ’ä¸­çš„RLï¼Œç‰¹åˆ«æ˜¯åœ¨å¤šæ™ºèƒ½ä½“ç¯å¢ƒä¸­çš„å®è´µå·¥å…·ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.22597v1">PDF</a> Accepted to Proceedings of ICAPS 2025</p>
<p><strong>Summary</strong></p>
<p>å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰è¿‘å¹´æ¥å¹¿æ³›ä½¿ç”¨OpenAI Gymç­‰å·¥å…·è¿›è¡Œæµ‹è¯•ï¼Œç„¶è€Œè¿™äº›ç¯å¢ƒä¸­çš„è®¸å¤šä»»åŠ¡ä¹Ÿèƒ½ä»å±‚æ¬¡åŒ–è§„åˆ’å—ç›Šã€‚ä¸ºäº†è§£å†³è¿™ä¸€ç©ºç™½ï¼Œæˆ‘ä»¬å¼•å…¥äº†Hierarchical Domain Definition Languageï¼ˆHDDLï¼‰è¿™ä¸€åœ¨ç»å…¸è§„åˆ’ä¸­ä½¿ç”¨çš„ç»“æ„åŒ–æ–¹æ³•ï¼Œé€‚ç”¨äºæ¨¡å‹åŸºç¡€RLã€‚ä¸ºäº†æ•´åˆRLä¸å±‚æ¬¡åŒ–è§„åˆ’ï¼Œæˆ‘ä»¬æ¨å‡ºHDDLGymâ€”â€”åŸºäºPythonçš„å·¥å…·ï¼Œå¯ä»HDDLé¢†åŸŸä¸é—®é¢˜è‡ªåŠ¨ç”ŸæˆOpenAI Gymç¯å¢ƒã€‚HDDLGymä½œä¸ºRLä¸å±‚æ¬¡åŒ–è§„åˆ’ä¹‹é—´çš„æ¡¥æ¢ï¼Œæ”¯æŒå¤šæ™ºèƒ½ä½“åœºæ™¯å¹¶å®ç°æ™ºèƒ½ä½“é—´çš„ååŒè§„åˆ’ã€‚æœ¬æ–‡æ¦‚è¿°äº†HDDLGymçš„è®¾è®¡ä¸å®æ–½ï¼Œå¼ºè°ƒäº†æ•´åˆHDDLä¸Gymæ¥å£çš„æŒ‘æˆ˜ä¸è®¾è®¡é€‰æ‹©ï¼Œå¹¶å±•ç¤ºäº†å¦‚ä½•åº”ç”¨RLç­–ç•¥ä»¥æ”¯æŒå±‚æ¬¡åŒ–è§„åˆ’ã€‚åŒæ—¶æä¾›ä½¿ç”¨HDDLGymæ¡†æ¶çš„è¯¦ç»†æŒ‡å—ä¸æ¼”ç¤ºï¼ŒåŒ…æ‹¬å¦‚ä½•ä½¿ç”¨å›½é™…è§„åˆ’ç«èµ›ä¸­çš„ç°æœ‰HDDLé¢†åŸŸä¸é—®é¢˜ï¼Œå¦‚åœ¨è¿è¾“é¢†åŸŸä¸­çš„åº”ç”¨ã€‚é€šè¿‡åˆ©ç”¨HDDLä¸Gymçš„ä¼˜åŠ¿ï¼ŒHDDLGymæ—¨åœ¨ä¸ºå±‚æ¬¡åŒ–è§„åˆ’ä¸­çš„RLç ”ç©¶æä¾›æœ‰ä»·å€¼çš„å·¥å…·ï¼Œç‰¹åˆ«æ˜¯åœ¨å¤šæ™ºèƒ½ä½“åœºæ™¯ä¸­ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰åœ¨OpenAI Gymç­‰å·¥å…·ä¸­å¹¿æ³›åº”ç”¨ï¼Œä½†ç¼ºä¹å°†å±‚æ¬¡åŒ–è§„åˆ’ä¸RLæ— ç¼é›†æˆçš„å·¥å…·ã€‚</li>
<li>Hierarchical Domain Definition Languageï¼ˆHDDLï¼‰ä¸ºæ¨¡å‹åŸºç¡€RLæä¾›äº†ç»“æ„åŒ–æ–¹æ³•ã€‚</li>
<li>HDDLGymæ˜¯é¦–ä¸ªåŸºäºPythonçš„å·¥å…·ï¼Œå¯ä»HDDLé¢†åŸŸä¸é—®é¢˜è‡ªåŠ¨ç”ŸæˆOpenAI Gymç¯å¢ƒã€‚</li>
<li>HDDLGymæ”¯æŒå¤šæ™ºèƒ½ä½“åœºæ™¯å¹¶å®ç°äº†æ™ºèƒ½ä½“é—´çš„ååŒè§„åˆ’ã€‚</li>
<li>HDDLGymçš„è®¾è®¡ä¸å®æ–½æ¶‰åŠæ•´åˆHDDLä¸Gymæ¥å£çš„æŒ‘æˆ˜ä¸è®¾è®¡é€‰æ‹©ã€‚</li>
<li>HDDLGymæä¾›äº†ä½¿ç”¨æŒ‡å—å’Œæ¼”ç¤ºï¼ŒåŒ…æ‹¬å¦‚ä½•åº”ç”¨å›½é™…è§„åˆ’ç«èµ›ä¸­çš„ç°æœ‰HDDLé¢†åŸŸä¸é—®é¢˜ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.22597">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-975765b491952feb0a92c752d7b472af.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-f4d4a6215c707967cd0a6c9fffb82464.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-b68de3edc52bcafc9b25ca176abca1a7.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-987ee24048a48addb871547b3301677a.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="EvolveSearch-An-Iterative-Self-Evolving-Search-Agent"><a href="#EvolveSearch-An-Iterative-Self-Evolving-Search-Agent" class="headerlink" title="EvolveSearch: An Iterative Self-Evolving Search Agent"></a>EvolveSearch: An Iterative Self-Evolving Search Agent</h2><p><strong>Authors:Dingchu Zhang, Yida Zhao, Jialong Wu, Baixuan Li, Wenbiao Yin, Liwen Zhang, Yong Jiang, Yufeng Li, Kewei Tu, Pengjun Xie, Fei Huang</strong></p>
<p>The rapid advancement of large language models (LLMs) has transformed the landscape of agentic information seeking capabilities through the integration of tools such as search engines and web browsers. However, current mainstream approaches for enabling LLM web search proficiency face significant challenges: supervised fine-tuning struggles with data production in open-search domains, while RL converges quickly, limiting their data utilization efficiency. To address these issues, we propose EvolveSearch, a novel iterative self-evolution framework that combines SFT and RL to enhance agentic web search capabilities without any external human-annotated reasoning data. Extensive experiments on seven multi-hop question-answering (MHQA) benchmarks demonstrate that EvolveSearch consistently improves performance across iterations, ultimately achieving an average improvement of 4.7% over the current state-of-the-art across seven benchmarks, opening the door to self-evolution agentic capabilities in open web search domains. </p>
<blockquote>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„å¿«é€Ÿå‘å±•é€šè¿‡æ•´åˆæœç´¢å¼•æ“å’Œç½‘é¡µæµè§ˆå™¨ç­‰å·¥å…·ï¼Œæ”¹å˜äº†ä¿¡æ¯æ£€ç´¢èƒ½åŠ›çš„æ ¼å±€ã€‚ç„¶è€Œï¼Œç›®å‰ä¸»æµçš„å®ç°LLMç½‘é¡µæœç´¢èƒ½åŠ›çš„æ–¹æ³•é¢ä¸´ç€å·¨å¤§çš„æŒ‘æˆ˜ï¼šç›‘ç£å¾®è°ƒåœ¨å¼€æ”¾æœç´¢é¢†åŸŸçš„æ•°æ®ç”Ÿäº§æ–¹é¢è¡¨ç°æŒ£æ‰ï¼Œè€Œå¼ºåŒ–å­¦ä¹ è™½ç„¶æ”¶æ•›è¿…é€Ÿï¼Œä½†æ•°æ®åˆ©ç”¨æ•ˆç‡æœ‰é™ã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†EvolveSearchï¼Œè¿™æ˜¯ä¸€ä¸ªæ–°å‹è¿­ä»£è‡ªè¿›åŒ–æ¡†æ¶ï¼Œç»“åˆäº†ç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰å’Œå¼ºåŒ–å­¦ä¹ ï¼Œæé«˜äº†æ™ºèƒ½ç½‘é¡µæœç´¢èƒ½åŠ›ï¼Œæ— éœ€ä»»ä½•å¤–éƒ¨äººå·¥æ ‡æ³¨çš„æ¨ç†æ•°æ®ã€‚åœ¨ä¸ƒä¸ªå¤šè·³é—®ç­”ï¼ˆMHQAï¼‰åŸºå‡†æµ‹è¯•ä¸Šçš„å¤§é‡å®éªŒè¡¨æ˜ï¼ŒEvolveSearchåœ¨è¿­ä»£è¿‡ç¨‹ä¸­æ€§èƒ½æŒç»­æå‡ï¼Œæœ€ç»ˆå®ç°äº†å¹³å‡æé«˜4.7%ï¼Œè¶…è¿‡äº†ä¸ƒä¸ªåŸºå‡†æµ‹è¯•ä¸­çš„æœ€æ–°æŠ€æœ¯çŠ¶æ€ï¼Œä¸ºå¼€æ”¾ç½‘ç»œæœç´¢é¢†åŸŸçš„æ™ºèƒ½è‡ªæˆ‘è¿›åŒ–èƒ½åŠ›å¼€å¯äº†å¤§é—¨ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.22501v1">PDF</a> </p>
<p><strong>Summary</strong>ï¼šéšç€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„å¿«é€Ÿå‘å±•ï¼Œæœç´¢å¼•æ“å’Œæµè§ˆå™¨ç­‰å·¥å…·çš„é›†æˆæ”¹å˜äº†ä¿¡æ¯æ£€ç´¢èƒ½åŠ›ã€‚ç„¶è€Œï¼Œä¸»æµæ–¹æ³•é¢ä¸´æŒ‘æˆ˜ï¼šç›‘ç£å¾®è°ƒé¢ä¸´å¼€æ”¾æœç´¢åŸŸæ•°æ®ç”Ÿäº§å›°éš¾ï¼Œå¼ºåŒ–å­¦ä¹ æ”¶æ•›è¿…é€Ÿä½†æ•°æ®åˆ©ç”¨æ•ˆç‡æœ‰é™ã€‚ä¸ºè§£å†³è¿™äº›é—®é¢˜ï¼Œæå‡ºäº†EvolveSearchæ¡†æ¶ï¼Œç»“åˆç›‘ç£å¾®è°ƒä¸å¼ºåŒ–å­¦ä¹ è¿›è¡Œè‡ªæˆ‘è¿›åŒ–ï¼Œæé«˜ä¿¡æ¯æ£€ç´¢èƒ½åŠ›ï¼Œæ— éœ€å¤–éƒ¨äººç±»æ³¨é‡Šæ•°æ®ã€‚åœ¨ä¸ƒä¸ªå¤šè·³é—®ç­”åŸºå‡†æµ‹è¯•ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒEvolveSearchåœ¨è¿­ä»£ä¸­æ€§èƒ½æŒç»­æé«˜ï¼Œå¹³å‡æ”¹è¿›äº†å½“å‰æœ€æ–°æŠ€æœ¯çš„4.7%ï¼Œä¸ºå¼€æ”¾ç½‘ç»œæœç´¢åŸŸçš„è‡ªæˆ‘è¿›åŒ–èƒ½åŠ›æ‰“å¼€äº†å¤§é—¨ã€‚</p>
<p><strong>Key Takeaways</strong>ï¼š</p>
<ol>
<li>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨ä¿¡æ¯æ£€ç´¢é¢†åŸŸæœ‰é‡å¤§è¿›å±•ã€‚</li>
<li>å½“å‰ä¸»æµæ–¹æ³•é¢ä¸´æ•°æ®ç”Ÿäº§å’Œæ•°æ®åˆ©ç”¨æ•ˆç‡çš„æŒ‘æˆ˜ã€‚</li>
<li>EvolveSearchæ¡†æ¶ç»“åˆäº†ç›‘ç£å¾®è°ƒä¸å¼ºåŒ–å­¦ä¹ ã€‚</li>
<li>EvolveSearchæé«˜äº†ä¿¡æ¯æ£€ç´¢èƒ½åŠ›ï¼Œæ— éœ€å¤–éƒ¨äººç±»æ³¨é‡Šæ•°æ®ã€‚</li>
<li>EvolveSearchåœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸Šè¡¨ç°ä¼˜è¶Šï¼Œå¹³å‡æ”¹è¿›äº†å½“å‰æœ€æ–°æŠ€æœ¯çš„4.7%ã€‚</li>
<li>EvolveSearchä¸ºå¼€æ”¾ç½‘ç»œæœç´¢åŸŸçš„è‡ªæˆ‘è¿›åŒ–èƒ½åŠ›æä¾›äº†å¯èƒ½ã€‚</li>
<li>è¯¥æ¡†æ¶çš„è¿­ä»£è‡ªæˆ‘è¿›åŒ–ç­–ç•¥æ˜¯å…¶æ ¸å¿ƒåˆ›æ–°ä¹‹ä¸€ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.22501">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-dfd9154c86cac4e5e5cfc7e08d4e607e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-557d0c5829cdfab924638210d82ff347.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-88614c79c35ddbfdb75eb084c3839332.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-87deee97464e91d6fcb3200ba6e65738.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-bb307dc4e1461f88213a6d3aa7fc133c.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="AgentDNS-A-Root-Domain-Naming-System-for-LLM-Agents"><a href="#AgentDNS-A-Root-Domain-Naming-System-for-LLM-Agents" class="headerlink" title="AgentDNS: A Root Domain Naming System for LLM Agents"></a>AgentDNS: A Root Domain Naming System for LLM Agents</h2><p><strong>Authors:Enfang Cui, Yujun Cheng, Rui She, Dan Liu, Zhiyuan Liang, Minxin Guo, Tianzheng Li, Qian Wei, Wenjuan Xing, Zhijie Zhong</strong></p>
<p>The rapid evolution of Large Language Model (LLM) agents has highlighted critical challenges in cross-vendor service discovery, interoperability, and communication. Existing protocols like model context protocol and agent-to-agent protocol have made significant strides in standardizing interoperability between agents and tools, as well as communication among multi-agents. However, there remains a lack of standardized protocols and solutions for service discovery across different agent and tool vendors. In this paper, we propose AgentDNS, a root domain naming and service discovery system designed to enable LLM agents to autonomously discover, resolve, and securely invoke third-party agent and tool services across organizational and technological boundaries. Inspired by the principles of the traditional DNS, AgentDNS introduces a structured mechanism for service registration, semantic service discovery, secure invocation, and unified billing. We detail the architecture, core functionalities, and use cases of AgentDNS, demonstrating its potential to streamline multi-agent collaboration in real-world scenarios. The source code will be published on <a target="_blank" rel="noopener" href="https://github.com/agentdns">https://github.com/agentdns</a>. </p>
<blockquote>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä»£ç†çš„å¿«é€Ÿè¿›åŒ–çªæ˜¾äº†è·¨ä¾›åº”å•†æœåŠ¡å‘ç°ã€äº’æ“ä½œæ€§å’Œé€šä¿¡æ–¹é¢çš„å…³é”®æŒ‘æˆ˜ã€‚ç°æœ‰çš„æ¨¡å‹ä¸Šä¸‹æ–‡åè®®å’Œä»£ç†å¯¹ä»£ç†åè®®ç­‰åè®®åœ¨æ ‡å‡†åŒ–ä»£ç†å’Œå·¥å…·ä¹‹é—´çš„äº’æ“ä½œæ€§ä»¥åŠå¤šä»£ç†ä¹‹é—´çš„é€šä¿¡æ–¹é¢å–å¾—äº†é‡å¤§è¿›å±•ã€‚ç„¶è€Œï¼Œä»ç„¶å­˜åœ¨è·¨ä¸åŒä»£ç†å’Œå·¥å…·ä¾›åº”å•†çš„æœåŠ¡å‘ç°ç¼ºä¹æ ‡å‡†åŒ–åè®®å’Œè§£å†³æ–¹æ¡ˆçš„é—®é¢˜ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†AgentDNSï¼Œè¿™æ˜¯ä¸€ä¸ªæ ¹åŸŸåè§£æå’ŒæœåŠ¡å‘ç°ç³»ç»Ÿï¼Œæ—¨åœ¨ä½¿LLMä»£ç†èƒ½å¤Ÿè‡ªä¸»å‘ç°ã€è§£å†³å¹¶å®‰å…¨åœ°è°ƒç”¨è·¨ç»„ç»‡å’Œè·¨æŠ€æœ¯è¾¹ç•Œçš„ç¬¬ä¸‰æ–¹ä»£ç†å’Œå·¥å…·æœåŠ¡ã€‚è¯¥ç³»ç»Ÿä»¥ä¼ ç»ŸDNSçš„åŸåˆ™ä¸ºçµæ„Ÿï¼Œå¼•å…¥äº†æœåŠ¡æ³¨å†Œã€è¯­ä¹‰æœåŠ¡å‘ç°ã€å®‰å…¨è°ƒç”¨å’Œç»Ÿä¸€è®¡è´¹çš„ç»“æ„åŒ–æœºåˆ¶ã€‚æˆ‘ä»¬è¯¦ç»†ä»‹ç»äº†AgentDNSçš„æ¶æ„ã€æ ¸å¿ƒåŠŸèƒ½å’Œä½¿ç”¨æ¡ˆä¾‹ï¼Œå±•ç¤ºäº†å…¶åœ¨ç°å®åœºæ™¯ä¸­ç®€åŒ–å¤šä»£ç†åä½œçš„æ½œåŠ›ã€‚æºä»£ç å°†åœ¨<a target="_blank" rel="noopener" href="https://github.com/agentdns%E4%B8%8A%E5%8F%91%E5%B8%83%E3%80%82">https://github.com/agentdnsä¸Šå‘å¸ƒã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.22368v1">PDF</a> 7 pages, 6 figures</p>
<p><strong>Summary</strong></p>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä»£ç†çš„å¿«é€Ÿè¿›åŒ–å‡¸æ˜¾äº†è·¨ä¾›åº”å•†æœåŠ¡å‘ç°ã€äº’æ“ä½œæ€§å’Œé€šä¿¡æ–¹é¢çš„å…³é”®æŒ‘æˆ˜ã€‚ç°æœ‰åè®®å¦‚æ¨¡å‹ä¸Šä¸‹æ–‡åè®®å’Œä»£ç†åˆ°ä»£ç†åè®®åœ¨æ ‡å‡†åŒ–ä»£ç†å’Œå·¥å…·ä¹‹é—´çš„äº’æ“ä½œæ€§ä»¥åŠå¤šä»£ç†ä¹‹é—´çš„é€šä¿¡æ–¹é¢å–å¾—äº†é‡å¤§è¿›å±•ã€‚ç„¶è€Œï¼Œä¸åŒä»£ç†å’Œå·¥å…·ä¾›åº”å•†ä¹‹é—´çš„æœåŠ¡å‘ç°ä»ç„¶ç¼ºä¹æ ‡å‡†åŒ–åè®®å’Œè§£å†³æ–¹æ¡ˆã€‚æœ¬æ–‡æå‡ºAgentDNSï¼Œä¸€ä¸ªæ ¹åŸŸåè§£æå’ŒæœåŠ¡å‘ç°ç³»ç»Ÿï¼Œæ—¨åœ¨ä½¿LLMä»£ç†èƒ½å¤Ÿè‡ªä¸»å‘ç°ã€è§£æå’Œå®‰å…¨è°ƒç”¨è·¨ç»„ç»‡å’ŒæŠ€æœ¯è¾¹ç•Œçš„ç¬¬ä¸‰æ–¹ä»£ç†å’Œå·¥å…·æœåŠ¡ã€‚AgentDNSå€Ÿé‰´äº†ä¼ ç»ŸDNSçš„åŸç†ï¼Œå¼•å…¥äº†æœåŠ¡æ³¨å†Œã€è¯­ä¹‰æœåŠ¡å‘ç°ã€å®‰å…¨è°ƒç”¨å’Œç»Ÿä¸€è®¡è´¹çš„ç»“æ„åŒ–æœºåˆ¶ã€‚æœ¬æ–‡è¯¦ç»†æè¿°äº†AgentDNSçš„æ¶æ„ã€æ ¸å¿ƒåŠŸèƒ½å’Œä½¿ç”¨æ¡ˆä¾‹ï¼Œå±•ç¤ºäº†å…¶åœ¨ç°å®åœºæ™¯ä¸­ç®€åŒ–å¤šä»£ç†åä½œçš„æ½œåŠ›ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„å‘å±•å¸¦æ¥äº†è·¨ä¾›åº”å•†æœåŠ¡å‘ç°ã€äº’æ“ä½œæ€§å’Œé€šä¿¡çš„æŒ‘æˆ˜ã€‚</li>
<li>ç°æœ‰åè®®åœ¨ä»£ç†æ ‡å‡†åŒ–æ–¹é¢å·²æœ‰æ‰€è¿›å±•ï¼Œä½†ä»éœ€æ”¹è¿›æœåŠ¡å‘ç°çš„æ ‡å‡†åŒ–åè®®å’Œè§£å†³æ–¹æ¡ˆã€‚</li>
<li>AgentDNSæ˜¯ä¸€ä¸ªåŸºäºä¼ ç»ŸDNSåŸç†çš„æ ¹åŸŸåè§£æå’ŒæœåŠ¡å‘ç°ç³»ç»Ÿã€‚</li>
<li>AgentDNSä½¿LLMä»£ç†èƒ½å¤Ÿè‡ªä¸»å‘ç°ã€è§£æå’Œå®‰å…¨è°ƒç”¨è·¨ç»„ç»‡å’ŒæŠ€æœ¯è¾¹ç•Œçš„ç¬¬ä¸‰æ–¹æœåŠ¡å’Œå·¥å…·ã€‚</li>
<li>AgentDNSæä¾›äº†æœåŠ¡æ³¨å†Œã€è¯­ä¹‰æœåŠ¡å‘ç°ã€å®‰å…¨è°ƒç”¨å’Œç»Ÿä¸€è®¡è´¹çš„æœºåˆ¶ã€‚</li>
<li>AgentDNSçš„æ¶æ„ã€æ ¸å¿ƒåŠŸèƒ½å’Œä½¿ç”¨æ¡ˆä¾‹è¢«è¯¦ç»†é˜è¿°ã€‚</li>
<li>AgentDNSæœ‰æ½œåŠ›åœ¨ç°å®åœºæ™¯ä¸­ç®€åŒ–å¤šä»£ç†åä½œã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.22368">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-4237177d76ba1f2d40c3b5a6545f1784.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-2bd692e0a77ed24ca4583c51ce0432d0.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-2cada25266a1a3cd13ca550f98705176.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-2eed1b93302dfbb7129e193047121313.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b561c6afad8203988ca3e4ce43e44f5e.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="Oryx-a-Performant-and-Scalable-Algorithm-for-Many-Agent-Coordination-in-Offline-MARL"><a href="#Oryx-a-Performant-and-Scalable-Algorithm-for-Many-Agent-Coordination-in-Offline-MARL" class="headerlink" title="Oryx: a Performant and Scalable Algorithm for Many-Agent Coordination in   Offline MARL"></a>Oryx: a Performant and Scalable Algorithm for Many-Agent Coordination in   Offline MARL</h2><p><strong>Authors:Claude Formanek, Omayma Mahjoub, Louay Ben Nessir, Sasha Abramowitz, Ruan de Kock, Wiem Khlifi, Simon Du Toit, Felix Chalumeau, Daniel Rajaonarivonivelomanantsoa, Arnol Fokam, Siddarth Singh, Ulrich Mbou Sob, Arnu Pretorius</strong></p>
<p>A key challenge in offline multi-agent reinforcement learning (MARL) is achieving effective many-agent multi-step coordination in complex environments. In this work, we propose Oryx, a novel algorithm for offline cooperative MARL to directly address this challenge. Oryx adapts the recently proposed retention-based architecture Sable and combines it with a sequential form of implicit constraint Q-learning (ICQ), to develop a novel offline auto-regressive policy update scheme. This allows Oryx to solve complex coordination challenges while maintaining temporal coherence over lengthy trajectories. We evaluate Oryx across a diverse set of benchmarks from prior works (SMAC, RWARE, and Multi-Agent MuJoCo) covering tasks of both discrete and continuous control, varying in scale and difficulty. Oryx achieves state-of-the-art performance on more than 80% of the 65 tested datasets, outperforming prior offline MARL methods and demonstrating robust generalisation across domains with many agents and long horizons. Finally, we introduce new datasets to push the limits of many-agent coordination in offline MARL, and demonstrate Oryxâ€™s superior ability to scale effectively in such settings. We will make all of our datasets, experimental data, and code available upon publication. </p>
<blockquote>
<p>åœ¨ç¦»çº¿å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ ï¼ˆMARLï¼‰ä¸­ï¼Œä¸€ä¸ªå…³é”®æŒ‘æˆ˜æ˜¯åœ¨å¤æ‚ç¯å¢ƒä¸­å®ç°æœ‰æ•ˆçš„å¤šæ™ºèƒ½ä½“å¤šæ­¥åè°ƒã€‚é’ˆå¯¹è¿™ä¸€æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†Oryxè¿™ä¸€æ–°å‹çš„ç¦»çº¿ååŒMARLç®—æ³•ã€‚Oryxé€‚åº”äº†æœ€è¿‘æå‡ºçš„åŸºäºä¿ç•™çš„æ¶æ„Sableï¼Œå¹¶å°†å…¶ä¸éšå¼çº¦æŸQå­¦ä¹ ï¼ˆICQï¼‰çš„åºåˆ—å½¢å¼ç›¸ç»“åˆï¼Œå¼€å‘äº†ä¸€ç§æ–°å‹çš„ç¦»çº¿è‡ªå›å½’ç­–ç•¥æ›´æ–°æ–¹æ¡ˆã€‚è¿™ä½¿å¾—Oryxèƒ½å¤Ÿåœ¨è§£å†³å¤æ‚çš„åè°ƒæŒ‘æˆ˜çš„åŒæ—¶ï¼Œåœ¨æ¼«é•¿çš„è½¨è¿¹ä¸Šä¿æŒæ—¶é—´è¿è´¯æ€§ã€‚æˆ‘ä»¬åœ¨æ¥è‡ªå…ˆå‰å·¥ä½œçš„å¤šæ ·åŒ–åŸºå‡†æµ‹è¯•é›†ï¼ˆSMACã€RWAREå’ŒMulti-Agent MuJoCoï¼‰ä¸Šè¯„ä¼°äº†Oryxçš„æ€§èƒ½ï¼Œè¿™äº›åŸºå‡†æµ‹è¯•æ¶µç›–äº†ç¦»æ•£å’Œè¿ç»­æ§åˆ¶ä»»åŠ¡ï¼Œè§„æ¨¡å’Œéš¾åº¦å„å¼‚ã€‚Oryxåœ¨65ä¸ªæµ‹è¯•æ•°æ®é›†ä¸­çš„80%ä»¥ä¸Šè¾¾åˆ°äº†æœ€æ–°æŠ€æœ¯æ°´å¹³ï¼Œè¶…è¶Šäº†å…ˆå‰çš„ç¦»çº¿MARLæ–¹æ³•ï¼Œå¹¶åœ¨å¤šä¸ªæ™ºèƒ½ä½“å’Œé•¿æœŸè§†é‡çš„è·¨é¢†åŸŸä»»åŠ¡ä¸­å±•ç¤ºäº†ç¨³å¥çš„æ³›åŒ–èƒ½åŠ›ã€‚æœ€åï¼Œæˆ‘ä»¬å¼•å…¥äº†æ–°çš„æ•°æ®é›†æ¥æ¨åŠ¨ç¦»çº¿MARLä¸­å¤šæ™ºèƒ½ä½“åè°ƒçš„æé™ï¼Œå¹¶å±•ç¤ºäº†Oryxåœ¨è¿™ç§ç¯å¢ƒä¸‹è¿›è¡Œæœ‰æ•ˆæ‰©å±•çš„å“è¶Šèƒ½åŠ›ã€‚æ‰€æœ‰æ•°æ®é›†ã€å®éªŒæ•°æ®å’Œä»£ç å°†åœ¨å‘å¸ƒæ—¶æä¾›ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.22151v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºä¸€ç§é’ˆå¯¹ç¦»çº¿å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ ï¼ˆMARLï¼‰çš„å…³é”®æŒ‘æˆ˜çš„è§£å†³æ–¹æ¡ˆï¼Œåä¸ºOryxã€‚å®ƒé€šè¿‡ç»“åˆåŸºäºä¿ç•™çš„æ¶æ„Sableå’Œéšå¼çº¦æŸQå­¦ä¹ ï¼ˆICQï¼‰çš„åºåˆ—å½¢å¼ï¼Œå¼€å‘äº†ä¸€ç§æ–°é¢–çš„ç¦»çº¿è‡ªå›å½’ç­–ç•¥æ›´æ–°æ–¹æ¡ˆã€‚è¿™ä½¿å¾—Oryxèƒ½å¤Ÿåœ¨è§£å†³å¤æ‚çš„åè°ƒæŒ‘æˆ˜æ—¶ï¼Œåœ¨æ¼«é•¿çš„è½¨è¿¹ä¸Šä¿æŒæ—¶é—´è¿è´¯æ€§ã€‚åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ï¼ˆå¦‚SMACã€RWAREå’ŒMulti-Agent MuJoCoï¼‰ä¸­ï¼ŒOryxåœ¨è¶…è¿‡80%çš„65ä¸ªæµ‹è¯•æ•°æ®é›†ä¸Šå®ç°äº†å“è¶Šçš„æ€§èƒ½ï¼Œè¶…è¶Šäº†å…ˆå‰çš„ç¦»çº¿MARLæ–¹æ³•ï¼Œå¹¶åœ¨å¤šä¸ªé¢†åŸŸçš„å¤šæ™ºèƒ½ä½“ç¯å¢ƒä¸­å±•ç¤ºäº†å¼ºå¤§çš„æ³›åŒ–èƒ½åŠ›ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>Oryxæ˜¯ä¸€ç§é’ˆå¯¹ç¦»çº¿å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ ï¼ˆMARLï¼‰çš„æ–°å‹ç®—æ³•ï¼Œæ—¨åœ¨è§£å†³å¤šæ™ºèƒ½ä½“åœ¨å¤æ‚ç¯å¢ƒä¸­çš„å¤šæ­¥åè°ƒæŒ‘æˆ˜ã€‚</li>
<li>Oryxç»“åˆäº†Sableçš„ä¿ç•™æ¶æ„å’ŒICQçš„åºåˆ—å½¢å¼ï¼Œå½¢æˆäº†ä¸€ç§æ–°é¢–çš„ç¦»çº¿è‡ªå›å½’ç­–ç•¥æ›´æ–°æ–¹æ¡ˆã€‚</li>
<li>è¯¥æ–¹æ¡ˆå…è®¸è§£å†³å¤æ‚çš„åè°ƒé—®é¢˜ï¼ŒåŒæ—¶åœ¨é•¿æ—¶é—´çš„è½¨è¿¹ä¸Šä¿æŒæ—¶é—´è¿è´¯æ€§ã€‚</li>
<li>åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­ï¼ŒåŒ…æ‹¬ç¦»æ•£å’Œè¿ç»­æ§åˆ¶ä»»åŠ¡ï¼Œä¸åŒè§„æ¨¡å’Œéš¾åº¦çš„ä»»åŠ¡ï¼ŒOryxåœ¨è¶…è¿‡80%çš„æ•°æ®é›†ä¸Šå®ç°äº†å“è¶Šæ€§èƒ½ã€‚</li>
<li>ä¸å…ˆå‰çš„ç¦»çº¿MARLæ–¹æ³•ç›¸æ¯”ï¼ŒOryxè¡¨ç°å‡ºäº†å‡ºè‰²çš„æ€§èƒ½ï¼Œå¹¶åœ¨å¤šä¸ªé¢†åŸŸçš„æ³›åŒ–èƒ½åŠ›ä¸Šå…·æœ‰ä¼˜åŠ¿ã€‚</li>
<li>ä¸ºäº†æ¨åŠ¨ç¦»çº¿MARLä¸­å¤šæ™ºèƒ½ä½“åè°ƒçš„æé™ï¼Œä½œè€…å¼•å…¥äº†æ–°çš„æ•°æ®é›†ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.22151">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-a38ffb10ef1129df7b47caf813a2d07f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-14f58c854b00528cd617f51995f2e4d6.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-8a018eb0f39a9ac59e4c0d4ac9dd082d.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="Towards-Conversational-Development-Environments-Using-Theory-of-Mind-and-Multi-Agent-Architectures-for-Requirements-Refinement"><a href="#Towards-Conversational-Development-Environments-Using-Theory-of-Mind-and-Multi-Agent-Architectures-for-Requirements-Refinement" class="headerlink" title="Towards Conversational Development Environments: Using Theory-of-Mind   and Multi-Agent Architectures for Requirements Refinement"></a>Towards Conversational Development Environments: Using Theory-of-Mind   and Multi-Agent Architectures for Requirements Refinement</h2><p><strong>Authors:Keheliya Gallaba, Ali Arabat, Dayi Lin, Mohammed Sayagh, Ahmed E. Hassan</strong></p>
<p>Foundation Models (FMs) have shown remarkable capabilities in various natural language tasks. However, their ability to accurately capture stakeholder requirements remains a significant challenge for using FMs for software development. This paper introduces a novel approach that leverages an FM-powered multi-agent system called AlignMind to address this issue. By having a cognitive architecture that enhances FMs with Theory-of-Mind capabilities, our approach considers the mental states and perspectives of software makers. This allows our solution to iteratively clarify the beliefs, desires, and intentions of stakeholders, translating these into a set of refined requirements and a corresponding actionable natural language workflow in the often-overlooked requirements refinement phase of software engineering, which is crucial after initial elicitation. Through a multifaceted evaluation covering 150 diverse use cases, we demonstrate that our approach can accurately capture the intents and requirements of stakeholders, articulating them as both specifications and a step-by-step plan of action. Our findings suggest that the potential for significant improvements in the software development process justifies these investments. Our work lays the groundwork for future innovation in building intent-first development environments, where software makers can seamlessly collaborate with AIs to create software that truly meets their needs. </p>
<blockquote>
<p>åŸºç¡€æ¨¡å‹ï¼ˆFMsï¼‰åœ¨å„ç§è‡ªç„¶è¯­è¨€ä»»åŠ¡ä¸­è¡¨ç°å‡ºäº†æ˜¾è‘—çš„èƒ½åŠ›ã€‚ç„¶è€Œï¼Œå‡†ç¡®æ•æ‰åˆ©ç›Šç›¸å…³è€…çš„è¦æ±‚åœ¨è½¯ä»¶å¼€å‘ä¸­ä½¿ç”¨åŸºç¡€æ¨¡å‹ä»æ˜¯ä¸€ä¸ªé‡å¤§æŒ‘æˆ˜ã€‚æœ¬æ–‡ä»‹ç»äº†ä¸€ç§åˆ©ç”¨åŸºç¡€æ¨¡å‹é©±åŠ¨çš„å¤šæ™ºèƒ½ä½“ç³»ç»ŸAlignMindæ¥è§£å†³è¿™ä¸€é—®é¢˜çš„æ–°æ–¹æ³•ã€‚é€šè¿‡å¢å¼ºåŸºç¡€æ¨¡å‹çš„è®¤çŸ¥æ¶æ„ï¼Œä½¿å…¶å…·å¤‡å¿ƒæ™ºç†è®ºèƒ½åŠ›ï¼Œæˆ‘ä»¬çš„æ–¹æ³•è€ƒè™‘äº†è½¯ä»¶åˆ¶é€ è€…çš„å¿ƒç†çŠ¶æ€å’Œè§†è§’ã€‚è¿™ä½¿å¾—æˆ‘ä»¬çš„è§£å†³æ–¹æ¡ˆèƒ½å¤Ÿè¿­ä»£åœ°æ¾„æ¸…åˆ©ç›Šç›¸å…³è€…çš„ä¿¡å¿µã€æ¬²æœ›å’Œæ„å›¾ï¼Œå¹¶å°†å…¶è½¬åŒ–ä¸ºä¸€å¥—ç²¾ç»†çš„è¦æ±‚å’Œç›¸åº”çš„å¯æ“ä½œçš„è‡ªç„¶è¯­è¨€å·¥ä½œæµç¨‹ï¼Œåœ¨å¸¸è¢«å¿½è§†çš„è½¯ä»¶å¼€å‘éœ€æ±‚ä¼˜åŒ–é˜¶æ®µè‡³å…³é‡è¦ï¼Œè¿™å¾ˆé‡è¦ï¼Œå› ä¸ºåœ¨åˆæ­¥æ¿€åŠ±ä¹‹åæ˜¯å°¤ä¸ºå…³é”®çš„ã€‚é€šè¿‡æ¶µç›–å¤šä¸ªç»´åº¦çš„è¯„ä¼°å’ŒåŒ…æ‹¬æœ‰ 150 ä¸ªä¸åŒç”¨ä¾‹çš„ç ”ç©¶åˆ†æï¼Œæˆ‘ä»¬è¯æ˜äº†æˆ‘ä»¬çš„æ–¹æ³•å¯ä»¥å‡†ç¡®åœ°æ•æ‰åˆ©ç›Šç›¸å…³è€…çš„æ„å›¾å’Œè¦æ±‚ï¼Œå°†å…¶ç»†åŒ–ä¸ºè§„èŒƒå’Œé€æ­¥è¡ŒåŠ¨è®¡åˆ’ã€‚æˆ‘ä»¬çš„ç ”ç©¶ç»“æœè¡¨æ˜ï¼Œè½¯ä»¶å¼€å‘çš„æ½œåœ¨æ”¹è¿›è¶³ä»¥è¯æ˜è¿™äº›æŠ•èµ„æ˜¯å€¼å¾—çš„ã€‚æˆ‘ä»¬çš„å·¥ä½œä¸ºå»ºç«‹æ„å›¾ä¼˜å…ˆçš„å¼€å‘ç¯å¢ƒå¥ å®šäº†åŸºç¡€ï¼Œåœ¨è¿™æ ·çš„ç¯å¢ƒä¸­ï¼Œè½¯ä»¶åˆ¶é€ å•†å¯ä»¥æ— ç¼åœ°ä¸äººå·¥æ™ºèƒ½åä½œåˆ›å»ºçœŸæ­£æ»¡è¶³å…¶éœ€æ±‚çš„è½¯ä»¶ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.20973v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>åŸºäºæ¨¡å‹çš„æ™ºèƒ½ç³»ç»ŸæˆåŠŸåº”ç”¨äºå¤šä¸ªè‡ªç„¶è¯­è¨€ä»»åŠ¡ï¼Œä½†åœ¨è½¯ä»¶å¼€å‘é¢†åŸŸæ•æ‰åˆ©ç›Šç›¸å…³è€…çš„å‡†ç¡®éœ€æ±‚ä¸Šä»æœ‰å±€é™ã€‚æœ¬æ–‡é€šè¿‡æå‡ºä¸€ä¸ªç”±Foundation Modelsé©±åŠ¨çš„å¤šæ™ºèƒ½ä½“ç³»ç»Ÿï¼ˆåä¸ºAlignMindï¼‰æ¥è§£å†³æ­¤é—®é¢˜ã€‚é€šè¿‡å¼ºåŒ–æ¨¡å‹å¿ƒæ™ºèƒ½åŠ›çš„è®¤çŸ¥æ¶æ„ï¼Œæ­¤ç³»ç»Ÿè€ƒè™‘äº†è½¯ä»¶å¼€å‘è€…çš„å¿ƒç†çŠ¶æ€å’Œè§†è§’ã€‚å› æ­¤ï¼Œè¯¥è§£å†³æ–¹æ¡ˆèƒ½å¤Ÿè¿­ä»£åœ°æ¾„æ¸…åˆ©ç›Šç›¸å…³è€…çš„ä¿¡å¿µã€æ¬²æœ›å’Œæ„å›¾ï¼Œå¹¶å°†å…¶è½¬åŒ–ä¸ºç²¾ç»†çš„éœ€æ±‚å’Œç›¸åº”çš„å¯æ“ä½œçš„è‡ªç„¶è¯­è¨€å·¥ä½œæµç¨‹ï¼Œè¿™åœ¨å¸¸è¢«å¿½ç•¥çš„è½¯ä»¶å·¥ç¨‹éœ€æ±‚ç»†åŒ–é˜¶æ®µè‡³å…³é‡è¦ã€‚é€šè¿‡æ¶µç›–150ä¸ªä¸åŒç”¨ä¾‹çš„å¤šæ–¹é¢è¯„ä¼°ï¼Œæœ¬æ–‡è¯æ˜äº†è¯¥æ–¹æ¡ˆèƒ½å¤Ÿå‡†ç¡®æ•æ‰åˆ©ç›Šç›¸å…³è€…çš„æ„å›¾å’Œéœ€æ±‚ï¼Œå¹¶å°†å…¶è¡¨è¾¾ä¸ºå…·ä½“çš„è§„èŒƒå’Œæ“ä½œæ­¥éª¤ã€‚è¿™ä¸ºæœªæ¥çš„è½¯ä»¶å¼€å‘è¿‡ç¨‹å¸¦æ¥äº†æ˜¾è‘—çš„æ”¹è¿›æ½œåŠ›ï¼Œå¹¶ä¸ºå»ºç«‹ä»¥æ„å›¾ä¸ºå…ˆçš„å¼€å‘ç¯å¢ƒå¥ å®šäº†åŸºç¡€ï¼Œä½¿è½¯ä»¶å¼€å‘è€…èƒ½ä¸äººå·¥æ™ºèƒ½æ— ç¼åä½œï¼Œåˆ›é€ å‡ºçœŸæ­£ç¬¦åˆéœ€æ±‚çš„äº§å“ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>Foundation Modelsåœ¨æ•æ‰è½¯ä»¶å¼€å‘åˆ©ç›Šç›¸å…³è€…çš„éœ€æ±‚æ–¹é¢å­˜åœ¨æŒ‘æˆ˜ã€‚</li>
<li>å¼•å…¥äº†ä¸€ç§åä¸ºAlignMindçš„FMé©±åŠ¨å¤šæ™ºèƒ½ä½“ç³»ç»Ÿæ¥è§£å†³è¿™ä¸€æŒ‘æˆ˜ã€‚</li>
<li>AlignMindé€šè¿‡å¢å¼ºFMçš„å¿ƒæ™ºèƒ½åŠ›ï¼Œè€ƒè™‘äº†è½¯ä»¶å¼€è€…çš„å¿ƒç†çŠ¶å†µå’Œè§†è§’ã€‚</li>
<li>è¯¥ç³»ç»Ÿèƒ½è¿­ä»£æ¾„æ¸…åˆ©ç›Šç›¸å…³è€…çš„ä¿¡å¿µã€æ¬²æœ›å’Œæ„å›¾ã€‚</li>
<li>è¿™äº›ä¿¡æ¯è¢«è½¬åŒ–ä¸ºç²¾ç»†çš„éœ€æ±‚å’Œå¯æ“ä½œçš„è‡ªç„¶è¯­è¨€å·¥ä½œæµç¨‹ï¼Œå¯¹éœ€æ±‚ç»†åŒ–é˜¶æ®µè‡³å…³é‡è¦ã€‚</li>
<li>é€šè¿‡æ¶µç›–å¤šä¸ªç”¨ä¾‹çš„è¯„ä¼°ï¼Œè¯æ˜è¯¥æ–¹æ¡ˆèƒ½å‡†ç¡®æ•æ‰å¹¶è¡¨è¾¾åˆ©ç›Šç›¸å…³è€…çš„æ„å›¾å’Œéœ€æ±‚ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.20973">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-368159c81b2e79a20294a815a8d24657.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-025778454c40a1284d8b47c689abdf79.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="JEDI-Latent-End-to-end-Diffusion-Mitigates-Agent-Human-Performance-Asymmetry-in-Model-Based-Reinforcement-Learning"><a href="#JEDI-Latent-End-to-end-Diffusion-Mitigates-Agent-Human-Performance-Asymmetry-in-Model-Based-Reinforcement-Learning" class="headerlink" title="JEDI: Latent End-to-end Diffusion Mitigates Agent-Human Performance   Asymmetry in Model-Based Reinforcement Learning"></a>JEDI: Latent End-to-end Diffusion Mitigates Agent-Human Performance   Asymmetry in Model-Based Reinforcement Learning</h2><p><strong>Authors:Jing Yu Lim, Zarif Ikram, Samson Yu, Haozhe Ma, Tze-Yun Leong, Dianbo Liu</strong></p>
<p>Recent advances in model-based reinforcement learning (MBRL) have achieved super-human level performance on the Atari100k benchmark, driven by reinforcement learning agents trained on powerful diffusion world models. However, we identify that the current aggregates mask a major performance asymmetry: MBRL agents dramatically outperform humans in some tasks despite drastically underperforming in others, with the former inflating the aggregate metrics. This is especially pronounced in pixel-based agents trained with diffusion world models. In this work, we address the pronounced asymmetry observed in pixel-based agents as an initial attempt to reverse the worrying upward trend observed in them. We address the problematic aggregates by delineating all tasks as Agent-Optimal or Human-Optimal and advocate for equal importance on metrics from both sets. Next, we hypothesize this pronounced asymmetry is due to the lack of temporally-structured latent space trained with the World Model objective in pixel-based methods. Lastly, to address this issue, we propose Joint Embedding DIffusion (JEDI), a novel latent diffusion world model trained end-to-end with the self-consistency objective. JEDI outperforms SOTA models in human-optimal tasks while staying competitive across the Atari100k benchmark, and runs 3 times faster with 43% lower memory than the latest pixel-based diffusion baseline. Overall, our work rethinks what it truly means to cross human-level performance in Atari100k. </p>
<blockquote>
<p>è¿‘æœŸæ¨¡å‹åŒ–å¼ºåŒ–å­¦ä¹ ï¼ˆMBRLï¼‰çš„è¿›æ­¥åœ¨Atari100kåŸºå‡†æµ‹è¯•ä¸­å®ç°äº†è¶…äººæ°´å¹³çš„æ€§èƒ½è¡¨ç°ï¼Œå…¶èƒŒåçš„é©±åŠ¨åŠ›é‡æ˜¯è®­ç»ƒåœ¨å¼ºå¤§æ‰©æ•£ä¸–ç•Œæ¨¡å‹ä¸Šçš„å¼ºåŒ–å­¦ä¹ æ™ºèƒ½ä½“ã€‚ç„¶è€Œï¼Œæˆ‘ä»¬å‘ç°å½“å‰çš„æ€»ä½“è¯„ä¼°æ©ç›–äº†ä¸€ä¸ªé‡è¦çš„æ€§èƒ½ä¸å¯¹ç§°é—®é¢˜ï¼šMBRLæ™ºèƒ½ä½“åœ¨æŸäº›ä»»åŠ¡ä¸Šå¤§å¤§è¶…è¶Šäººç±»çš„è¡¨ç°ï¼Œå´åœ¨å…¶ä»–ä»»åŠ¡ä¸Šè¡¨ç°ä¸ä½³ï¼Œå‰è€…è¿‡åº¦è†¨èƒ€äº†æ€»ä½“æŒ‡æ ‡ã€‚è¿™åœ¨åŸºäºåƒç´ çš„ã€ä½¿ç”¨æ‰©æ•£ä¸–ç•Œæ¨¡å‹è®­ç»ƒçš„æ™ºèƒ½ä½“ä¸­å°¤ä¸ºçªå‡ºã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬é’ˆå¯¹åœ¨åŸºäºåƒç´ çš„æ™ºèƒ½ä½“ä¸­è§‚å¯Ÿåˆ°çš„æ˜æ˜¾ä¸å¯¹ç§°æ€§ä½œä¸ºåˆæ­¥å°è¯•ï¼Œæ¥æ‰­è½¬è¿™ç§ä»¤äººæ‹…å¿§çš„ä¸Šå‡è¶‹åŠ¿ã€‚æˆ‘ä»¬é€šè¿‡å°†ä»»åŠ¡åˆ’åˆ†ä¸ºä»¥æ™ºèƒ½ä½“ä¸ºä¸­å¿ƒçš„æœ€ä¼˜æˆ–ä»¥äººä¸ºä¸­å¿ƒçš„æœ€ä¼˜æ¥è§£å†³æœ‰é—®é¢˜çš„æ€»ä½“è¯„ä¼°é—®é¢˜ï¼Œå¹¶ä¸»å¼ ä¸¤è€…é›†åˆçš„æŒ‡æ ‡åº”åŒç­‰é‡è¦ã€‚æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å‡è®¾è¿™ç§çªå‡ºçš„ä¸å¯¹ç§°æ€§æ˜¯ç”±äºåŸºäºåƒç´ çš„æ–¹æ³•ä¸­ç¼ºä¹ä¸ä¸–ç•Œæ¨¡å‹ç›®æ ‡ä¸€èµ·è®­ç»ƒçš„ã€å…·æœ‰æ—¶é—´ç»“æ„åŒ–çš„æ½œåœ¨ç©ºé—´æ‰€å¯¼è‡´çš„ã€‚æœ€åï¼Œä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†è”åˆåµŒå…¥æ‰©æ•£ï¼ˆJEDIï¼‰ï¼Œè¿™æ˜¯ä¸€ç§æ–°å‹æ½œåœ¨æ‰©æ•£ä¸–ç•Œæ¨¡å‹ï¼Œä¸è‡ªæ´½ç›®æ ‡ä¸€èµ·è¿›è¡Œç«¯åˆ°ç«¯çš„è®­ç»ƒã€‚JEDIåœ¨äººç±»æœ€ä¼˜ä»»åŠ¡ä¸Šè¶…è¶Šäº†SOTAæ¨¡å‹ï¼ŒåŒæ—¶åœ¨Atari100kåŸºå‡†æµ‹è¯•ä¸­ä¿æŒç«äº‰åŠ›ï¼Œå¹¶ä¸”ä¸æœ€æ–°çš„åŸºäºåƒç´ çš„æ‰©æ•£åŸºå‡†ç›¸æ¯”ï¼Œè¿è¡Œé€Ÿåº¦æé«˜äº†ä¸‰å€ï¼Œå†…å­˜é™ä½äº†43%ã€‚æ€»çš„æ¥è¯´ï¼Œæˆ‘ä»¬çš„å·¥ä½œé‡æ–°æ€è€ƒäº†åœ¨Atari100kä¸­å®ç°è¶…è¶Šäººç±»æ°´å¹³çš„æ€§èƒ½çš„çœŸæ­£å«ä¹‰ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.19698v2">PDF</a> Preprint</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æ¢è®¨äº†åŸºäºæ¨¡å‹çš„å¼ºåŒ–å­¦ä¹ ï¼ˆMBRLï¼‰åœ¨Atari100kåŸºå‡†æµ‹è¯•ä¸Šçš„æ€§èƒ½ä¸å¯¹ç§°é—®é¢˜ã€‚ç ”ç©¶å‘ç°ï¼Œå°½ç®¡MBRLåœ¨æŸäº›ä»»åŠ¡ä¸Šè¡¨ç°è¶…äººç±»ï¼Œä½†åœ¨å…¶ä»–ä»»åŠ¡ä¸Šè¡¨ç°è¾ƒå·®ã€‚ä¸ºè§£å†³è¿™ä¸€é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºä¸€ç§æ–°æ–¹æ³•â€”â€”è”åˆåµŒå…¥æ‰©æ•£ï¼ˆJEDIï¼‰ï¼Œè¯¥æ–¹æ³•é€šè¿‡ç«¯åˆ°ç«¯è®­ç»ƒå¸¦æœ‰è‡ªä¸€è‡´æ€§ç›®æ ‡çš„æ½œåœ¨æ‰©æ•£ä¸–ç•Œæ¨¡å‹ï¼Œæ—¨åœ¨ä¼˜åŒ–åœ¨äººç±»ç¤¾ä¼šæœ€ä½³ä»»åŠ¡çš„æ€§èƒ½å¹¶ä¿æŒAtari 100kåŸºå‡†æµ‹è¯•ä¸­çš„ç«äº‰åŠ›ã€‚æ­¤å¤–ï¼ŒJEDIæ¨¡å‹è¿è¡Œé€Ÿåº¦æ›´å¿«ä¸”å†…å­˜å ç”¨æ›´ä½ã€‚æœ¬æ–‡é‡æ–°æ€è€ƒäº†åœ¨Atari 100kåŸºå‡†æµ‹è¯•ä¸­è¶…è¶Šäººç±»æ°´å¹³çš„çœŸæ­£å«ä¹‰ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>MBRLåœ¨æŸäº›ä»»åŠ¡ä¸Šè¡¨ç°è¶…äººç±»ï¼Œä½†åœ¨å…¶ä»–ä»»åŠ¡ä¸Šè¡¨ç°è¾ƒå·®ï¼Œå¯¼è‡´æ€§èƒ½ä¸å¯¹ç§°é—®é¢˜ã€‚</li>
<li>æ€§èƒ½ä¸å¯¹ç§°é—®é¢˜åœ¨åŸºäºåƒç´ çš„å¼ºåŒ–å­¦ä¹ ä»£ç†ä¸­å°¤ä¸ºçªå‡ºã€‚</li>
<li>æå‡ºäº†ä¸€ç§æ–°æ–¹æ³•â€”â€”è”åˆåµŒå…¥æ‰©æ•£ï¼ˆJEDIï¼‰ï¼Œæ—¨åœ¨è§£å†³æ€§èƒ½ä¸å¯¹ç§°é—®é¢˜å¹¶ä¼˜åŒ–åœ¨äººç±»ç¤¾ä¼šæœ€ä½³ä»»åŠ¡çš„æ€§èƒ½ã€‚</li>
<li>JEDIæ¨¡å‹é€šè¿‡ç«¯åˆ°ç«¯è®­ç»ƒå¸¦æœ‰è‡ªä¸€è‡´æ€§ç›®æ ‡çš„æ½œåœ¨æ‰©æ•£ä¸–ç•Œæ¨¡å‹å®ç°æ€§èƒ½æå‡ã€‚</li>
<li>JEDIæ¨¡å‹åœ¨Atari 100kåŸºå‡†æµ‹è¯•ä¸­ä¿æŒç«äº‰åŠ›ï¼ŒåŒæ—¶è¿è¡Œé€Ÿåº¦æ›´å¿«ä¸”å†…å­˜å ç”¨æ›´ä½ã€‚</li>
<li>æœ¬æ–‡ç ”ç©¶é‡æ–°æ€è€ƒäº†åœ¨Atari 100kåŸºå‡†æµ‹è¯•ä¸­è¶…è¶Šäººç±»æ°´å¹³çš„çœŸæ­£å«ä¹‰ã€‚</li>
<li>éœ€è¦å…³æ³¨å¼ºåŒ–å­¦ä¹ ä»£ç†åœ¨å„ç±»ä»»åŠ¡ä¸Šçš„å…¨é¢æ€§èƒ½è¯„ä¼°ï¼Œä¸ä»…ä»…æ˜¯å•ä¸€çš„åŸºå‡†æµ‹è¯•æŒ‡æ ‡ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.19698">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-aee366c6d61be392313f311897406265.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-9b2fa6709b3beaf6921e39d823f452bb.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-54e120c819ad1188f2523f8fc6940e20.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-6960958586b6893fb95331e62f80e769.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="AgentRecBench-Benchmarking-LLM-Agent-based-Personalized-Recommender-Systems"><a href="#AgentRecBench-Benchmarking-LLM-Agent-based-Personalized-Recommender-Systems" class="headerlink" title="AgentRecBench: Benchmarking LLM Agent-based Personalized Recommender   Systems"></a>AgentRecBench: Benchmarking LLM Agent-based Personalized Recommender   Systems</h2><p><strong>Authors:Yu Shang, Peijie Liu, Yuwei Yan, Zijing Wu, Leheng Sheng, Yuanqing Yu, Chumeng Jiang, An Zhang, Fengli Xu, Yu Wang, Min Zhang, Yong Li</strong></p>
<p>The emergence of agentic recommender systems powered by Large Language Models (LLMs) represents a paradigm shift in personalized recommendations, leveraging LLMsâ€™ advanced reasoning and role-playing capabilities to enable autonomous, adaptive decision-making. Unlike traditional recommendation approaches, agentic recommender systems can dynamically gather and interpret user-item interactions from complex environments, generating robust recommendation strategies that generalize across diverse scenarios. However, the field currently lacks standardized evaluation protocols to systematically assess these methods. To address this critical gap, we propose: (1) an interactive textual recommendation simulator incorporating rich user and item metadata and three typical evaluation scenarios (classic, evolving-interest, and cold-start recommendation tasks); (2) a unified modular framework for developing and studying agentic recommender systems; and (3) the first comprehensive benchmark comparing 10 classical and agentic recommendation methods. Our findings demonstrate the superiority of agentic systems and establish actionable design guidelines for their core components. The benchmark environment has been rigorously validated through an open challenge and remains publicly available with a continuously maintained leaderboard~\footnote[2]{<a target="_blank" rel="noopener" href="https://tsinghua-fib-lab.github.io/AgentSocietyChallenge/pages/overview.html%7D">https://tsinghua-fib-lab.github.io/AgentSocietyChallenge/pages/overview.html}</a>, fostering ongoing community engagement and reproducible research. The benchmark is available at: \hyperlink{<a target="_blank" rel="noopener" href="https://huggingface.co/datasets/SGJQovo/AgentRecBench%7D%7Bhttps://huggingface.co/datasets/SGJQovo/AgentRecBench%7D">https://huggingface.co/datasets/SGJQovo/AgentRecBench}{https://huggingface.co/datasets/SGJQovo/AgentRecBench}</a>. </p>
<blockquote>
<p>åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„ä»£ç†æ¨èç³»ç»Ÿçš„å‡ºç°ï¼Œä»£è¡¨ç€ä¸ªæ€§åŒ–æ¨èä¸­çš„èŒƒå¼è½¬å˜ã€‚å®ƒåˆ©ç”¨LLMçš„å…ˆè¿›æ¨ç†å’Œè§’è‰²æ‰®æ¼”èƒ½åŠ›ï¼Œå®ç°è‡ªä¸»ã€è‡ªé€‚åº”çš„å†³ç­–ã€‚ä¸ä¼ ç»Ÿçš„æ¨èæ–¹æ³•ä¸åŒï¼Œä»£ç†æ¨èç³»ç»Ÿå¯ä»¥åŠ¨æ€åœ°æ”¶é›†å’Œè§£é‡Šç”¨æˆ·ä¸ç‰©å“çš„äº’åŠ¨ï¼Œä»å¤æ‚çš„ç¯å¢ƒä¸­ç”Ÿæˆç¨³å¥çš„æ¨èç­–ç•¥ï¼Œè¿™äº›ç­–ç•¥å¯ä»¥åœ¨ä¸åŒçš„åœºæ™¯ä¸­æ¨å¹¿ã€‚ç„¶è€Œï¼Œç›®å‰è¯¥é¢†åŸŸç¼ºä¹æ ‡å‡†åŒ–çš„è¯„ä¼°åè®®æ¥ç³»ç»Ÿåœ°è¯„ä¼°è¿™äº›æ–¹æ³•ã€‚ä¸ºäº†è§£å†³è¿™ä¸€å…³é”®å·®è·ï¼Œæˆ‘ä»¬æå‡ºï¼šï¼ˆ1ï¼‰ä¸€ä¸ªäº¤äº’æ–‡æœ¬æ¨èæ¨¡æ‹Ÿå™¨ï¼Œèå…¥ä¸°å¯Œçš„ç”¨æˆ·å’Œç‰©å“å…ƒæ•°æ®ä»¥åŠä¸‰ç§å…¸å‹è¯„ä¼°åœºæ™¯ï¼ˆç»å…¸ã€å…´è¶£å‘å±•å’Œå†·å¯åŠ¨æ¨èä»»åŠ¡ï¼‰ï¼›ï¼ˆ2ï¼‰ä¸€ä¸ªç»Ÿä¸€çš„æ¨¡å—åŒ–æ¡†æ¶ï¼Œç”¨äºå¼€å‘å’Œç ”ç©¶ä»£ç†æ¨èç³»ç»Ÿï¼›ï¼ˆ3ï¼‰ç¬¬ä¸€ä¸ªå…¨é¢åŸºå‡†æµ‹è¯•ï¼Œæ¯”è¾ƒ10ç§ç»å…¸å’Œä»£ç†æ¨èæ–¹æ³•ã€‚æˆ‘ä»¬çš„ç ”ç©¶å‘ç°ä»£ç†ç³»ç»Ÿçš„ä¼˜è¶Šæ€§ï¼Œå¹¶ä¸ºå…¶æ ¸å¿ƒç»„ä»¶æä¾›å¯è¡Œçš„è®¾è®¡æŒ‡å—ã€‚åŸºå‡†ç¯å¢ƒå·²ç»é€šè¿‡å…¬å¼€æŒ‘æˆ˜è¿›è¡Œäº†ä¸¥æ ¼éªŒè¯ï¼Œå¹¶æŒç»­ç»´æŠ¤æ’è¡Œæ¦œ~â‘¡ï¼ˆ<a target="_blank" rel="noopener" href="https://tsinghua-fib-lab.github.io/AgentSocietyChallenge/pages/overview.html%EF%BC%89%EF%BC%8C%E4%BF%83%E8%BF%9B%E7%A4%BE%E5%8C%BA%E6%8C%81%E7%BB%AD%E5%8F%82%E4%B8%8E%E5%92%8C%E5%8F%AF%E9%87%8D%E5%A4%8D%E7%9A%84%E7%A0%94%E7%A9%B6%E3%80%82%E5%9F%BA%E5%87%86%E6%B5%8B%E8%AF%95%E5%B9%B3%E5%8F%B0%E9%93%BE%E6%8E%A5%E4%B8%BA%EF%BC%9Ahttps://huggingface.co/datasets/SGJQovo/AgentRecBench%E3%80%82">https://tsinghua-fib-lab.github.io/AgentSocietyChallenge/pages/overview.htmlï¼‰ï¼Œä¿ƒè¿›ç¤¾åŒºæŒç»­å‚ä¸å’Œå¯é‡å¤çš„ç ”ç©¶ã€‚åŸºå‡†æµ‹è¯•å¹³å°é“¾æ¥ä¸ºï¼šhttps://huggingface.co/datasets/SGJQovo/AgentRecBenchã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.19623v2">PDF</a> 15 pages, 6 figures</p>
<p><strong>Summary</strong>ï¼š<br>åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„ä»£ç†æ¨èç³»ç»Ÿå‡ºç°ï¼Œæ ‡å¿—ç€ä¸ªæ€§åŒ–æ¨èé¢†åŸŸå‡ºç°èŒƒå¼è½¬å˜ã€‚è¿™ç§ç³»ç»Ÿåˆ©ç”¨LLMçš„é«˜çº§æ¨ç†å’Œè§’è‰²æ‰®æ¼”èƒ½åŠ›ï¼Œå®ç°è‡ªä¸»ã€è‡ªé€‚åº”çš„å†³ç­–åˆ¶å®šã€‚ä¸ä¼ ç»Ÿæ¨èæ–¹æ³•ä¸åŒï¼Œä»£ç†æ¨èç³»ç»Ÿèƒ½å¤ŸåŠ¨æ€æ”¶é›†å¹¶è§£è¯»ç”¨æˆ·ä¸é¡¹ç›®çš„äº’åŠ¨ï¼Œé€‚åº”å¤æ‚ç¯å¢ƒç”Ÿæˆç¨³å¥çš„æ¨èç­–ç•¥ã€‚ä½†å½“å‰è¯¥é¢†åŸŸç¼ºä¹æ ‡å‡†åŒ–çš„è¯„ä¼°åè®®æ¥ç³»ç»Ÿåœ°è¯„ä¼°è¿™äº›æ–¹æ³•ã€‚ä¸ºè§£å†³è¿™ä¸€å…³é”®ç©ºç™½ï¼Œæå‡ºäº†ä¸€äº¤äº’å¼æ–‡æœ¬æ¨èæ¨¡æ‹Ÿå™¨ã€ä¸€ç»Ÿä¸€æ¨¡å—åŒ–æ¡†æ¶æ¥å¼€å‘å’Œç ”ç©¶ä»£ç†æ¨èç³»ç»Ÿä»¥åŠç¬¬ä¸€ä»½ç»¼åˆåŸºå‡†æµ‹è¯•ï¼Œå¯¹æ¯”äº†10ç§ç»å…¸å’Œä»£ç†æ¨èæ–¹æ³•ã€‚ç»“æœè¡¨æ˜ä»£ç†ç³»ç»Ÿçš„ä¼˜è¶Šæ€§ï¼Œå¹¶ä¸ºå…¶æ ¸å¿ƒç»„ä»¶æä¾›äº†å¯æ“ä½œçš„è®¾è®¡æŒ‡å—ã€‚</p>
<p><strong>Key Takeaways</strong>ï¼š</p>
<ol>
<li>ä»£ç†æ¨èç³»ç»Ÿåˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹çš„æ¨ç†å’Œè§’è‰²æ‰®æ¼”èƒ½åŠ›å®ç°è‡ªä¸»ã€è‡ªé€‚åº”å†³ç­–ã€‚</li>
<li>ä»£ç†æ¨èç³»ç»Ÿèƒ½åŠ¨æ€æ”¶é›†å¹¶è§£è¯»ç”¨æˆ·ä¸é¡¹ç›®çš„äº’åŠ¨ï¼Œé€‚åº”å¤æ‚ç¯å¢ƒã€‚</li>
<li>å½“å‰ä»£ç†æ¨èç³»ç»Ÿé¢†åŸŸç¼ºä¹æ ‡å‡†åŒ–çš„è¯„ä¼°åè®®ã€‚</li>
<li>æå‡ºäº†ä¸€äº¤äº’å¼æ–‡æœ¬æ¨èæ¨¡æ‹Ÿå™¨ç”¨äºè¯„ä¼°ä»£ç†æ¨èç³»ç»Ÿã€‚</li>
<li>æå‡ºäº†ç»Ÿä¸€æ¨¡å—åŒ–æ¡†æ¶æ¥å¼€å‘å’Œç ”ç©¶ä»£ç†æ¨èç³»ç»Ÿã€‚</li>
<li>ç»¼åˆåŸºå‡†æµ‹è¯•æ˜¾ç¤ºä»£ç†æ¨èæ–¹æ³•çš„ä¼˜è¶Šæ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.19623">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-4e4c5ef99906508b46ea35f6b486254e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-012374a3de0a29712347e20f5a7395be.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ad3a185f9517e61e665533bc0fb062f9.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-925638b5ebc6d135890c0a3eb6bea746.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-6ab75a36672412c31eee2f856a3c882d.jpg" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="Deep-Video-Discovery-Agentic-Search-with-Tool-Use-for-Long-form-Video-Understanding"><a href="#Deep-Video-Discovery-Agentic-Search-with-Tool-Use-for-Long-form-Video-Understanding" class="headerlink" title="Deep Video Discovery: Agentic Search with Tool Use for Long-form Video   Understanding"></a>Deep Video Discovery: Agentic Search with Tool Use for Long-form Video   Understanding</h2><p><strong>Authors:Xiaoyi Zhang, Zhaoyang Jia, Zongyu Guo, Jiahao Li, Bin Li, Houqiang Li, Yan Lu</strong></p>
<p>Long-form video understanding presents significant challenges due to extensive temporal-spatial complexity and the difficulty of question answering under such extended contexts. While Large Language Models (LLMs) have demonstrated considerable advancements in video analysis capabilities and long context handling, they continue to exhibit limitations when processing information-dense hour-long videos. To overcome such limitations, we propose the Deep Video Discovery agent to leverage an agentic search strategy over segmented video clips. Different from previous video agents manually designing a rigid workflow, our approach emphasizes the autonomous nature of agents. By providing a set of search-centric tools on multi-granular video database, our DVD agent leverages the advanced reasoning capability of LLM to plan on its current observation state, strategically selects tools, formulates appropriate parameters for actions, and iteratively refines its internal reasoning in light of the gathered information. We perform comprehensive evaluation on multiple long video understanding benchmarks that demonstrates the advantage of the entire system design. Our DVD agent achieves SOTA performance, significantly surpassing prior works by a large margin on the challenging LVBench dataset. Comprehensive ablation studies and in-depth tool analyses are also provided, yielding insights to further advance intelligent agents tailored for long-form video understanding tasks. The code will be released later. </p>
<blockquote>
<p>é•¿è§†é¢‘ç†è§£ç”±äºå·¨å¤§çš„æ—¶ç©ºå¤æ‚æ€§å’Œåœ¨å¦‚æ­¤æ‰©å±•çš„ä¸Šä¸‹æ–‡ä¸‹è¿›è¡Œé—®ç­”çš„å›°éš¾è€Œé¢ä¸´é‡å¤§æŒ‘æˆ˜ã€‚è™½ç„¶å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨è§†é¢‘åˆ†æèƒ½åŠ›å’Œé•¿ä¸Šä¸‹æ–‡å¤„ç†æ–¹é¢å–å¾—äº†æ˜¾è‘—çš„è¿›æ­¥ï¼Œä½†åœ¨å¤„ç†ä¿¡æ¯å¯†é›†çš„ä¸€å°æ—¶é•¿çš„è§†é¢‘æ—¶ï¼Œå®ƒä»¬ä»ç„¶è¡¨ç°å‡ºå±€é™æ€§ã€‚ä¸ºäº†å…‹æœè¿™äº›å±€é™æ€§ï¼Œæˆ‘ä»¬æå‡ºäº†æ·±åº¦è§†é¢‘å‘ç°ä»£ç†ï¼Œé‡‡ç”¨ä»£ç†æœç´¢ç­–ç•¥å¯¹åˆ†å‰²çš„è§†é¢‘ç‰‡æ®µè¿›è¡Œå¤„ç†ã€‚ä¸åŒäºä»¥å‰çš„æ‰‹åŠ¨è®¾è®¡åˆšæ€§å·¥ä½œæµç¨‹çš„è§†é¢‘ä»£ç†ï¼Œæˆ‘ä»¬çš„æ–¹æ³•å¼ºè°ƒä»£ç†çš„è‡ªä¸»æ€§ã€‚é€šè¿‡åœ¨å¤šç²’åº¦è§†é¢‘æ•°æ®åº“ä¸Šæä¾›ä¸€ç³»åˆ—ä»¥æœç´¢ä¸ºä¸­å¿ƒçš„å·¥å…·ï¼Œæˆ‘ä»¬çš„DVDä»£ç†åˆ©ç”¨LLMçš„é«˜çº§æ¨ç†èƒ½åŠ›æ¥è§„åˆ’å…¶å½“å‰è§‚å¯ŸçŠ¶æ€ï¼Œæˆ˜ç•¥æ€§åœ°é€‰æ‹©å·¥å…·ï¼Œä¸ºè¡ŒåŠ¨åˆ¶å®šé€‚å½“å‚æ•°ï¼Œå¹¶æ ¹æ®æ”¶é›†çš„ä¿¡æ¯è¿­ä»£ä¼˜åŒ–å…¶å†…éƒ¨æ¨ç†ã€‚æˆ‘ä»¬åœ¨å¤šä¸ªé•¿è§†é¢‘ç†è§£åŸºå‡†æµ‹è¯•ä¸Šè¿›è¡Œäº†å…¨é¢è¯„ä¼°ï¼Œè¯æ˜äº†æ•´ä¸ªç³»ç»Ÿè®¾è®¡çš„ä¼˜åŠ¿ã€‚æˆ‘ä»¬çš„DVDä»£ç†å®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œåœ¨å…·æœ‰æŒ‘æˆ˜æ€§çš„LVBenchæ•°æ®é›†ä¸Šå¤§å¹…åº¦è¶…è¶Šäº†ä»¥å‰çš„å·¥ä½œã€‚è¿˜æä¾›äº†å…¨é¢çš„æ¶ˆèç ”ç©¶å’Œæ·±å…¥çš„å·¥å…·åˆ†æï¼Œä¸ºè¿›ä¸€æ­¥æ¨è¿›é’ˆå¯¹é•¿è§†é¢‘ç†è§£ä»»åŠ¡çš„æ™ºèƒ½ä»£ç†æä¾›äº†è§è§£ã€‚ä»£ç å°†åœ¨ç¨åå‘å¸ƒã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.18079v2">PDF</a> V2 draft. Under review</p>
<p><strong>Summary</strong>ï¼š<br>é•¿è§†é¢‘ç†è§£é¢ä¸´å·¨å¤§çš„æŒ‘æˆ˜ï¼ŒåŒ…æ‹¬å¹¿æ³›çš„æ—¶ç©ºå¤æ‚æ€§å’Œåœ¨æ‰©å±•ç¯å¢ƒä¸‹çš„é—®ç­”éš¾åº¦ã€‚å°½ç®¡å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨è§†é¢‘åˆ†æèƒ½åŠ›å’Œå¤„ç†é•¿æ–‡æœ¬æ–¹é¢å–å¾—äº†æ˜¾è‘—è¿›å±•ï¼Œä½†åœ¨å¤„ç†ä¿¡æ¯å¯†é›†çš„é•¿è§†é¢‘æ—¶ä»å­˜åœ¨å±€é™æ€§ã€‚ä¸ºè§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†Deep Video Discoveryï¼ˆDVDï¼‰ä»£ç†ï¼Œé‡‡ç”¨ä»£ç†æœç´¢ç­–ç•¥å¯¹åˆ†å‰²çš„è§†é¢‘ç‰‡æ®µè¿›è¡Œå¤„ç†ã€‚ä¸åŒäºä»¥å¾€çš„è§†é¢‘ä»£ç†æ‰‹åŠ¨è®¾è®¡åˆšæ€§å·¥ä½œæµç¨‹ï¼Œæˆ‘ä»¬çš„æ–¹æ³•ä¾§é‡äºä»£ç†çš„è‡ªä¸»æ€§ã€‚DVDä»£ç†é€šè¿‡æä¾›ä¸€ç³»åˆ—é¢å‘å¤šç²’åº¦è§†é¢‘æ•°æ®åº“çš„æœç´¢å·¥å…·ï¼Œåˆ©ç”¨LLMçš„é«˜çº§æ¨ç†èƒ½åŠ›æ¥è§„åˆ’å½“å‰è§‚å¯ŸçŠ¶æ€ï¼Œæˆ˜ç•¥æ€§åœ°é€‰æ‹©å·¥å…·ï¼Œåˆ¶å®šé€‚å½“çš„è¡ŒåŠ¨å‚æ•°ï¼Œå¹¶æ ¹æ®è·å–çš„ä¿¡æ¯è¿­ä»£åœ°å®Œå–„å…¶å†…éƒ¨æ¨ç†ã€‚æˆ‘ä»¬åœ¨å¤šä¸ªé•¿è§†é¢‘ç†è§£åŸºå‡†æµ‹è¯•ä¸Šå¯¹DVDä»£ç†è¿›è¡Œäº†å…¨é¢è¯„ä¼°ï¼Œè¯æ˜äº†æˆ‘ä»¬æ•´ä¸ªç³»ç»Ÿçš„ä¼˜åŠ¿ã€‚DVDä»£ç†å®ç°äº†å‡ºè‰²çš„æ€§èƒ½ï¼Œåœ¨å…·æœ‰æŒ‘æˆ˜æ€§çš„LVBenchæ•°æ®é›†ä¸Šå¤§å¹…è¶…è¶Šäº†ä»¥å‰çš„å·¥ä½œã€‚åŒæ—¶æä¾›äº†å…¨é¢çš„æ¶ˆèç ”ç©¶å’Œæ·±å…¥çš„å·¥å…·åˆ†æï¼Œä¸ºé’ˆå¯¹é•¿è§†é¢‘ç†è§£ä»»åŠ¡è¿›ä¸€æ­¥å¼€å‘æ™ºèƒ½ä»£ç†æä¾›äº†è§è§£ã€‚ä»£ç å°†éšåå‘å¸ƒã€‚</p>
<p><strong>Key Takeaways</strong>ï¼š</p>
<ul>
<li>é•¿è§†é¢‘ç†è§£å­˜åœ¨å·¨å¤§æŒ‘æˆ˜ï¼Œæºäºæ—¶ç©ºå¤æ‚æ€§å’Œé—®ç­”éš¾åº¦ã€‚</li>
<li>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨å¤„ç†ä¿¡æ¯å¯†é›†çš„é•¿è§†é¢‘æ—¶å­˜åœ¨å±€é™æ€§ã€‚</li>
<li>Deep Video Discoveryï¼ˆDVDï¼‰ä»£ç†é‡‡ç”¨è‡ªä¸»æœç´¢ç­–ç•¥å¤„ç†åˆ†å‰²çš„è§†é¢‘ç‰‡æ®µã€‚</li>
<li>DVDä»£ç†æä¾›ä¸€ç³»åˆ—é¢å‘å¤šç²’åº¦è§†é¢‘æ•°æ®åº“çš„æœç´¢å·¥å…·ï¼Œåˆ©ç”¨LLMçš„æ¨ç†èƒ½åŠ›è¿›è¡Œè§„åˆ’ã€é€‰æ‹©å·¥å…·å’Œå‚æ•°åˆ¶å®šã€‚</li>
<li>DVDä»£ç†åœ¨å¤šä¸ªé•¿è§†é¢‘ç†è§£åŸºå‡†æµ‹è¯•ä¸Šè¡¨ç°ä¼˜å¼‚ï¼Œç‰¹åˆ«æ˜¯åœ¨å…·æœ‰æŒ‘æˆ˜æ€§çš„LVBenchæ•°æ®é›†ä¸Šã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.18079">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-6f08ec5ce87cfba6ac999363060b25f5.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-953a2e0735dc1523c356980ffc004edb.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-9bb3d4505eeba5bafd3e3b5fe7e6761c.jpg" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1><h2 id="AI-for-Climate-Finance-Agentic-Retrieval-and-Multi-Step-Reasoning-for-Early-Warning-System-Investments"><a href="#AI-for-Climate-Finance-Agentic-Retrieval-and-Multi-Step-Reasoning-for-Early-Warning-System-Investments" class="headerlink" title="AI for Climate Finance: Agentic Retrieval and Multi-Step Reasoning for   Early Warning System Investments"></a>AI for Climate Finance: Agentic Retrieval and Multi-Step Reasoning for   Early Warning System Investments</h2><p><strong>Authors:Saeid Ario Vaghefi, Aymane Hachcham, Veronica Grasso, Jiska Manicus, Nakiete Msemo, Chiara Colesanti Senni, Markus Leippold</strong></p>
<p>Tracking financial investments in climate adaptation is a complex and expertise-intensive task, particularly for Early Warning Systems (EWS), which lack standardized financial reporting across multilateral development banks (MDBs) and funds. To address this challenge, we introduce an LLM-based agentic AI system that integrates contextual retrieval, fine-tuning, and multi-step reasoning to extract relevant financial data, classify investments, and ensure compliance with funding guidelines. Our study focuses on a real-world application: tracking EWS investments in the Climate Risk and Early Warning Systems (CREWS) Fund. We analyze 25 MDB project documents and evaluate multiple AI-driven classification methods, including zero-shot and few-shot learning, fine-tuned transformer-based classifiers, chain-of-thought (CoT) prompting, and an agent-based retrieval-augmented generation (RAG) approach. Our results show that the agent-based RAG approach significantly outperforms other methods, achieving 87% accuracy, 89% precision, and 83% recall. Additionally, we contribute a benchmark dataset and expert-annotated corpus, providing a valuable resource for future research in AI-driven financial tracking and climate finance transparency. </p>
<blockquote>
<p>è·Ÿè¸ªæ°”å€™é€‚åº”æ–¹é¢çš„é‡‘èæŠ•èµ„æ˜¯ä¸€é¡¹å¤æ‚ä¸”éœ€è¦ä¸“ä¸šæŠ€èƒ½çš„ä»»åŠ¡ï¼Œç‰¹åˆ«æ˜¯å¯¹äºç¼ºä¹å¤šè¾¹å‘å±•é“¶è¡Œå’ŒåŸºé‡‘æ ‡å‡†åŒ–è´¢åŠ¡æŠ¥å‘Šçš„æ—©æœŸé¢„è­¦ç³»ç»Ÿï¼ˆEWSï¼‰è€Œè¨€ã€‚ä¸ºäº†åº”å¯¹è¿™ä¸€æŒ‘æˆ˜ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ä¸ªåŸºäºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„ä»£ç†äººå·¥æ™ºèƒ½ç³»ç»Ÿï¼Œè¯¥ç³»ç»Ÿç»“åˆäº†ä¸Šä¸‹æ–‡æ£€ç´¢ã€å¾®è°ƒå’Œå¤šæ­¥æ¨ç†ï¼Œä»¥æå–ç›¸å…³è´¢åŠ¡æ•°æ®ã€åˆ†ç±»æŠ•èµ„å¹¶ç¡®ä¿ç¬¦åˆèµ„é‡‘æŒ‡å¯¼æ–¹é’ˆã€‚æˆ‘ä»¬çš„ç ”ç©¶ä¾§é‡äºå®é™…åº”ç”¨ï¼šè·Ÿè¸ªæ°”å€™é£é™©ä¸æ—©æœŸé¢„è­¦ç³»ç»Ÿï¼ˆCREWSï¼‰åŸºé‡‘ä¸­EWSçš„æŠ•èµ„ã€‚æˆ‘ä»¬åˆ†æäº†25ä¸ªMDBé¡¹ç›®æ–‡ä»¶ï¼Œå¹¶è¯„ä¼°äº†å¤šç§AIé©±åŠ¨çš„åˆ†ç±»æ–¹æ³•ï¼ŒåŒ…æ‹¬é›¶æ ·æœ¬å’Œå°‘æ ·æœ¬å­¦ä¹ ã€åŸºäºå¾®è°ƒè½¬æ¢å™¨çš„åˆ†ç±»å™¨ã€é“¾å¼æ€ç»´ï¼ˆCoTï¼‰æç¤ºå’ŒåŸºäºä»£ç†çš„æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰æ–¹æ³•ã€‚æˆ‘ä»¬çš„ç»“æœè¡¨æ˜ï¼ŒåŸºäºä»£ç†çš„RAGæ–¹æ³•åœ¨å…¶ä»–æ–¹æ³•ä¸­å…·æœ‰æ˜¾è‘—ä¼˜åŠ¿ï¼Œè¾¾åˆ°äº†87%çš„å‡†ç¡®ç‡ã€89%çš„ç²¾ç¡®ç‡å’Œ83%çš„å¬å›ç‡ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜æä¾›äº†ä¸€ä¸ªåŸºå‡†æ•°æ®é›†å’Œä¸“å®¶æ³¨é‡Šè¯­æ–™åº“ï¼Œä¸ºAIé©±åŠ¨çš„é‡‘èè·Ÿè¸ªå’Œæ°”å€™èèµ„é€æ˜åº¦çš„æœªæ¥ç ”ç©¶æä¾›äº†å®è´µèµ„æºã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.05104v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>è¯¥æ–‡æœ¬ä»‹ç»äº†ä¸€ä¸ªåŸºäºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„ä»£ç†äººå·¥æ™ºèƒ½ç³»ç»Ÿï¼Œç”¨äºè¿½è¸ªæ°”å€™é€‚åº”çš„é‡‘èæŠ•èµ„ã€‚è¯¥ç³»ç»Ÿé›†æˆäº†ä¸Šä¸‹æ–‡æ£€ç´¢ã€å¾®è°ƒå’Œå¤šæ­¥æ¨ç†ï¼Œèƒ½å¤Ÿæå–ç›¸å…³è´¢åŠ¡æ•°æ®ã€åˆ†ç±»æŠ•èµ„å¹¶ç¡®ä¿ç¬¦åˆèµ„é‡‘æŒ‡å¯¼æ–¹é’ˆã€‚ç ”ç©¶ä»¥æ°”å€™é£é™©å’Œé¢„è­¦ç³»ç»ŸåŸºé‡‘ä¸­çš„æ—©æœŸé¢„è­¦ç³»ç»ŸæŠ•èµ„è¿½è¸ªä¸ºä¾‹ï¼Œåˆ†æäº†25ä¸ªå¤šè¾¹å‘å±•é“¶è¡Œé¡¹ç›®æ–‡ä»¶ï¼Œå¹¶è¯„ä¼°äº†å¤šç§äººå·¥æ™ºèƒ½é©±åŠ¨çš„åˆ†ç±»æ–¹æ³•ã€‚ç»“æœè¡¨æ˜ï¼ŒåŸºäºä»£ç†çš„RAGæ–¹æ³•æ˜¾è‘—ä¼˜äºå…¶ä»–æ–¹æ³•ï¼Œå‡†ç¡®ç‡ã€ç²¾ç¡®ç‡å’Œå¬å›ç‡åˆ†åˆ«è¾¾åˆ°äº†87%ã€89%å’Œ83%ã€‚æ­¤å¤–ï¼Œè¯¥ç ”ç©¶è¿˜è´¡çŒ®äº†ä¸€ä¸ªåŸºå‡†æ•°æ®é›†å’Œä¸“å®¶æ³¨é‡Šè¯­æ–™åº“ï¼Œä¸ºæœªæ¥çš„äººå·¥æ™ºèƒ½é‡‘èè¿½è¸ªå’Œæ°”å€™è´¢åŠ¡é€æ˜åº¦ç ”ç©¶æä¾›äº†å®è´µèµ„æºã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>è¿½è¸ªæ°”å€™é€‚åº”çš„é‡‘èæŠ•èµ„æ˜¯ä¸€é¡¹å¤æ‚ä¸”éœ€è¦ä¸“ä¸šçŸ¥è¯†çš„ä»»åŠ¡ï¼Œç‰¹åˆ«æ˜¯å¯¹äºç¼ºä¹æ ‡å‡†åŒ–è´¢åŠ¡æŠ¥å‘Šçš„æ—©æœŸé¢„è­¦ç³»ç»Ÿè€Œè¨€ã€‚</li>
<li>ä»‹ç»äº†ä¸€ä¸ªåŸºäºå¤§å‹è¯­è¨€æ¨¡å‹çš„ä»£ç†äººå·¥æ™ºèƒ½ç³»ç»Ÿï¼Œè¯¥ç³»ç»Ÿé›†æˆä¸Šä¸‹æ–‡æ£€ç´¢ã€å¾®è°ƒã€å¤šæ­¥æ¨ç†ç­‰åŠŸèƒ½ï¼Œèƒ½æœ‰æ•ˆæå–ç›¸å…³è´¢åŠ¡æ•°æ®å¹¶è¿›è¡Œåˆ†ç±»ã€‚</li>
<li>ä»¥æ°”å€™é£é™©å’Œé¢„è­¦ç³»ç»ŸåŸºé‡‘ä¸­çš„æŠ•èµ„è¿½è¸ªä¸ºä¾‹ï¼Œç ”ç©¶äº†25ä¸ªå¤šè¾¹å‘å±•é“¶è¡Œçš„é¡¹ç›®æ–‡ä»¶ã€‚</li>
<li>è¯„ä¼°äº†å¤šç§äººå·¥æ™ºèƒ½é©±åŠ¨çš„åˆ†ç±»æ–¹æ³•ï¼ŒåŒ…æ‹¬é›¶æ ·æœ¬å’Œå°‘æ ·æœ¬å­¦ä¹ ã€å¾®è°ƒåŸºäºè½¬æ¢å™¨çš„åˆ†ç±»å™¨ã€é“¾å¼æ€ç»´æç¤ºå’ŒåŸºäºä»£ç†çš„æ£€ç´¢å¢å¼ºç”Ÿæˆæ–¹æ³•ç­‰ã€‚</li>
<li>åŸºäºä»£ç†çš„RAGæ–¹æ³•è¢«è¯æ˜åœ¨å‡†ç¡®ç‡ã€ç²¾ç¡®ç‡å’Œå¬å›ç‡æ–¹é¢æ˜¾è‘—ä¼˜äºå…¶ä»–æ–¹æ³•ã€‚</li>
<li>ç ”ç©¶ç»“æœå¯¹äºæé«˜æ°”å€™è´¢åŠ¡é€æ˜åº¦å…·æœ‰é‡è¦æ„ä¹‰ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.05104">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-19184a7ea6fdf4e28241d56e586ef998.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-baa2cf8ae15e9964dd8f8e8bfe075efa.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-09365514e6267da7826d5f8b5cde5eba.jpg" align="middle">
</details>


<h1 id="-9"><a href="#-9" class="headerlink" title=""></a></h1><h2 id="SynWorld-Virtual-Scenario-Synthesis-for-Agentic-Action-Knowledge-Refinement"><a href="#SynWorld-Virtual-Scenario-Synthesis-for-Agentic-Action-Knowledge-Refinement" class="headerlink" title="SynWorld: Virtual Scenario Synthesis for Agentic Action Knowledge   Refinement"></a>SynWorld: Virtual Scenario Synthesis for Agentic Action Knowledge   Refinement</h2><p><strong>Authors:Runnan Fang, Xiaobin Wang, Yuan Liang, Shuofei Qiao, Jialong Wu, Zekun Xi, Ningyu Zhang, Yong Jiang, Pengjun Xie, Fei Huang, Huajun Chen</strong></p>
<p>In the interaction between agents and their environments, agents expand their capabilities by planning and executing actions. However, LLM-based agents face substantial challenges when deployed in novel environments or required to navigate unconventional action spaces. To empower agents to autonomously explore environments, optimize workflows, and enhance their understanding of actions, we propose SynWorld, a framework that allows agents to synthesize possible scenarios with multi-step action invocation within the action space and perform Monte Carlo Tree Search (MCTS) exploration to effectively refine their action knowledge in the current environment. Our experiments demonstrate that SynWorld is an effective and general approach to learning action knowledge in new environments. Code is available at <a target="_blank" rel="noopener" href="https://github.com/zjunlp/SynWorld">https://github.com/zjunlp/SynWorld</a>. </p>
<blockquote>
<p>åœ¨æ™ºèƒ½ä½“ä¸å…¶ç¯å¢ƒä¹‹é—´çš„äº¤äº’ä¸­ï¼Œæ™ºèƒ½ä½“é€šè¿‡è§„åˆ’å’Œæ‰§è¡Œè¡ŒåŠ¨æ¥æ‰©å±•å…¶èƒ½åŠ›ã€‚ç„¶è€Œï¼Œå½“éƒ¨ç½²åœ¨æ–°å‹ç¯å¢ƒä¸­æˆ–éœ€è¦æ‰§è¡Œéå¸¸è§„åŠ¨ä½œæ—¶ï¼ŒåŸºäºå¤§å‹è¯­è¨€æ¨¡å‹çš„æ™ºèƒ½ä½“ä¼šé¢ä¸´å·¨å¤§çš„æŒ‘æˆ˜ã€‚ä¸ºäº†å¢å¼ºæ™ºèƒ½ä½“è‡ªä¸»æ¢ç´¢ç¯å¢ƒã€ä¼˜åŒ–å·¥ä½œæµç¨‹ä»¥åŠå¢å¼ºå¯¹åŠ¨ä½œçš„ç†è§£èƒ½åŠ›ï¼Œæˆ‘ä»¬æå‡ºäº†SynWorldæ¡†æ¶ã€‚è¯¥æ¡†æ¶å…è®¸æ™ºèƒ½ä½“åœ¨åŠ¨ä½œç©ºé—´å†…åˆæˆå¤šæ­¥åŠ¨ä½œè°ƒç”¨æƒ…æ™¯ï¼Œå¹¶æ‰§è¡Œè’™ç‰¹å¡æ´›æ ‘æœç´¢ï¼ˆMCTSï¼‰æ¢ç´¢ï¼Œä»¥æœ‰æ•ˆåœ°åœ¨å½“å‰ç¯å¢ƒä¸­ä¼˜åŒ–å…¶åŠ¨ä½œçŸ¥è¯†ã€‚æˆ‘ä»¬çš„å®éªŒè¡¨æ˜ï¼ŒSynWorldæ˜¯ä¸€ç§åœ¨æ–°ç¯å¢ƒä¸­å­¦ä¹ åŠ¨ä½œçŸ¥è¯†çš„æœ‰æ•ˆä¸”é€šç”¨çš„æ–¹æ³•ã€‚ä»£ç å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/zjunlp/SynWorld%E8%8E%B7%E5%8F%96%E3%80%82">https://github.com/zjunlp/SynWorldè·å–ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.03561v2">PDF</a> ACL 2025 Findings</p>
<p><strong>Summary</strong></p>
<p>åœ¨æ™ºèƒ½ä»£ç†ä¸å…¶ç¯å¢ƒäº’åŠ¨çš„è¿‡ç¨‹ä¸­ï¼Œé€šè¿‡è§„åˆ’ä¸æ‰§è¡ŒåŠ¨ä½œæ¥æ‰©å±•å…¶èƒ½åŠ›ã€‚ç„¶è€Œï¼ŒåŸºäºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„ä»£ç†åœ¨éƒ¨ç½²äºæ–°ç¯å¢ƒæˆ–éœ€è¦æ‰§è¡Œéä¼ ç»ŸåŠ¨ä½œæ—¶é¢ä¸´å·¨å¤§æŒ‘æˆ˜ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬æå‡ºSynWorldæ¡†æ¶ï¼Œè®©ä»£ç†èƒ½å¤Ÿè‡ªä¸»æ¢ç´¢ç¯å¢ƒã€ä¼˜åŒ–å·¥ä½œæµç¨‹ã€å¢å¼ºå¯¹åŠ¨ä½œçš„ç†è§£ã€‚è¯¥æ¡†æ¶å…è®¸ä»£ç†åœ¨åŠ¨ä½œç©ºé—´å†…åˆæˆå¯èƒ½åœºæ™¯å¹¶è¿›è¡Œå¤šæ­¥éª¤åŠ¨ä½œè°ƒç”¨ï¼Œé€šè¿‡è’™ç‰¹å¡æ´›æ ‘æœç´¢ï¼ˆMCTSï¼‰æ¢ç´¢æ¥æœ‰æ•ˆä¼˜åŒ–å…¶åŠ¨ä½œçŸ¥è¯†ã€‚å®éªŒè¯æ˜ï¼ŒSynWorldæ˜¯åœ¨æ–°ç¯å¢ƒä¸­å­¦ä¹ åŠ¨ä½œçŸ¥è¯†çš„ä¸€ç§æœ‰æ•ˆä¸”é€šç”¨çš„æ–¹æ³•ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æ™ºèƒ½ä»£ç†é€šè¿‡è§„åˆ’ä¸æ‰§è¡ŒåŠ¨ä½œæ¥æ‰©å±•å…¶èƒ½åŠ›ã€‚</li>
<li>åœ¨æ–°ç¯å¢ƒæˆ–æ‰§è¡Œéä¼ ç»ŸåŠ¨ä½œæ—¶ï¼ŒåŸºäºå¤§å‹è¯­è¨€æ¨¡å‹çš„ä»£ç†é¢ä¸´æŒ‘æˆ˜ã€‚</li>
<li>SynWorldæ¡†æ¶å…è®¸ä»£ç†åˆæˆå¯èƒ½åœºæ™¯å¹¶åœ¨åŠ¨ä½œç©ºé—´å†…è¿›è¡Œå¤šæ­¥éª¤åŠ¨ä½œè°ƒç”¨ã€‚</li>
<li>é€šè¿‡è’™ç‰¹å¡æ´›æ ‘æœç´¢ï¼ˆMCTSï¼‰æ¢ç´¢ï¼ŒSynWorldæ¡†æ¶èƒ½æœ‰æ•ˆä¼˜åŒ–ä»£ç†çš„åŠ¨ä½œçŸ¥è¯†ã€‚</li>
<li>SynWorldæ¡†æ¶é€‚ç”¨äºæ–°ç¯å¢ƒä¸­å­¦ä¹ åŠ¨ä½œçŸ¥è¯†ã€‚</li>
<li>SynWorldæ¡†æ¶å…·æœ‰é€šç”¨æ€§ï¼Œå¯å¹¿æ³›åº”ç”¨äºå„ç§ç¯å¢ƒå’Œä»»åŠ¡ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.03561">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-a367bb0aeb51185dbbd0861e7c9e4e86.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-5b06fca3d8fa227acc07e5128e2533f9.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-0daf6717e1a34d1f73ddb49930f675d8.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-0ba058e549f3f1e0d1bf4d9dee7766ff.jpg" align="middle">
</details>


<h1 id="-10"><a href="#-10" class="headerlink" title=""></a></h1><h2 id="Leveraging-Dual-Process-Theory-in-Language-Agent-Framework-for-Real-time-Simultaneous-Human-AI-Collaboration"><a href="#Leveraging-Dual-Process-Theory-in-Language-Agent-Framework-for-Real-time-Simultaneous-Human-AI-Collaboration" class="headerlink" title="Leveraging Dual Process Theory in Language Agent Framework for Real-time   Simultaneous Human-AI Collaboration"></a>Leveraging Dual Process Theory in Language Agent Framework for Real-time   Simultaneous Human-AI Collaboration</h2><p><strong>Authors:Shao Zhang, Xihuai Wang, Wenhao Zhang, Chaoran Li, Junru Song, Tingyu Li, Lin Qiu, Xuezhi Cao, Xunliang Cai, Wen Yao, Weinan Zhang, Xinbing Wang, Ying Wen</strong></p>
<p>Agents built on large language models (LLMs) have excelled in turn-by-turn human-AI collaboration but struggle with simultaneous tasks requiring real-time interaction. Latency issues and the challenge of inferring variable human strategies hinder their ability to make autonomous decisions without explicit instructions. Through experiments with current independent System 1 and System 2 methods, we validate the necessity of using Dual Process Theory (DPT) in real-time tasks. We propose DPT-Agent, a novel language agent framework that integrates System 1 and System 2 for efficient real-time simultaneous human-AI collaboration. DPT-Agentâ€™s System 1 uses a Finite-state Machine (FSM) and code-as-policy for fast, intuitive, and controllable decision-making. DPT-Agentâ€™s System 2 integrates Theory of Mind (ToM) and asynchronous reflection to infer human intentions and perform reasoning-based autonomous decisions. We demonstrate the effectiveness of DPT-Agent through further experiments with rule-based agents and human collaborators, showing significant improvements over mainstream LLM-based frameworks. DPT-Agent can effectively help LLMs convert correct slow thinking and reasoning into executable actions, thereby improving performance. To the best of our knowledge, DPT-Agent is the first language agent framework that achieves successful real-time simultaneous human-AI collaboration autonomously. Code of DPT-Agent can be found in <a target="_blank" rel="noopener" href="https://github.com/sjtu-marl/DPT-Agent">https://github.com/sjtu-marl/DPT-Agent</a>. </p>
<blockquote>
<p>åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„ä»£ç†äººåœ¨é€è½®çš„äººæœºåä½œä¸­è¡¨ç°å‡ºè‰²ï¼Œä½†åœ¨éœ€è¦å®æ—¶äº¤äº’çš„åŒæ—¶ä»»åŠ¡ä¸­é‡åˆ°äº†å›°éš¾ã€‚å»¶è¿Ÿé—®é¢˜å’Œæ¨æ–­å¯å˜äººç±»ç­–ç•¥çš„æŒ‘æˆ˜å½±å“äº†å®ƒä»¬åœ¨æ²¡æœ‰æ˜ç¡®æŒ‡ä»¤çš„æƒ…å†µä¸‹è¿›è¡Œè‡ªä¸»å†³ç­–çš„èƒ½åŠ›ã€‚é€šè¿‡å½“å‰ç‹¬ç«‹çš„System 1å’ŒSystem 2æ–¹æ³•çš„å®éªŒï¼Œæˆ‘ä»¬éªŒè¯äº†åœ¨å®æ—¶ä»»åŠ¡ä¸­ä½¿ç”¨åŒè¿‡ç¨‹ç†è®ºï¼ˆDPTï¼‰çš„å¿…è¦æ€§ã€‚æˆ‘ä»¬æå‡ºäº†DPT-Agentï¼Œè¿™æ˜¯ä¸€ç§æ–°å‹çš„è¯­è¨€ä»£ç†æ¡†æ¶ï¼Œå®ƒèåˆäº†System 1å’ŒSystem 2ï¼Œä»¥å®ç°é«˜æ•ˆå®æ—¶çš„åŒæ—¶äººæœºåä½œã€‚DPT-Agentçš„System 1ä½¿ç”¨æœ‰é™çŠ¶æ€æœºï¼ˆFSMï¼‰å’Œä»£ç å³ç­–ç•¥ï¼Œä»¥å®ç°å¿«é€Ÿã€ç›´è§‚å’Œå¯æ§çš„å†³ç­–ã€‚DPT-Agentçš„System 2èåˆäº†å¿ƒæ™ºç†è®ºï¼ˆToMï¼‰å’Œå¼‚æ­¥åå°„ï¼Œä»¥æ¨æ–­äººç±»æ„å›¾å¹¶è¿›è¡ŒåŸºäºæ¨ç†çš„è‡ªä¸»å†³ç­–ã€‚æˆ‘ä»¬é€šè¿‡ä¸åŸºäºè§„åˆ™çš„ä»£ç†äººå’Œäººç±»åˆä½œè€…è¿›ä¸€æ­¥å®éªŒï¼Œè¯æ˜äº†DPT-Agentçš„æœ‰æ•ˆæ€§ï¼Œæ˜¾ç¤ºå‡ºåœ¨ä¸»æµLLMæ¡†æ¶ä¸Šçš„æ˜¾è‘—æ”¹è¿›ã€‚DPT-Agentå¯ä»¥æœ‰æ•ˆåœ°å¸®åŠ©LLMå°†æ­£ç¡®çš„æ…¢æ€è€ƒå’Œæ¨ç†è½¬åŒ–ä¸ºå¯æ‰§è¡Œè¡ŒåŠ¨ï¼Œä»è€Œæé«˜æ€§èƒ½ã€‚æ®æˆ‘ä»¬æ‰€çŸ¥ï¼ŒDPT-Agentæ˜¯ç¬¬ä¸€ä¸ªæˆåŠŸå®ç°å®æ—¶åŒæ—¶äººæœºåä½œçš„è‡ªä¸»è¯­è¨€ä»£ç†æ¡†æ¶ã€‚DPT-Agentçš„ä»£ç å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/sjtu-marl/DPT-Agent">https://github.com/sjtu-marl/DPT-Agent</a>æ‰¾åˆ°ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.11882v5">PDF</a> Accepted by ACL 2025 Main. Camera Ready Version</p>
<p><strong>Summary</strong>ï¼š<br>åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹çš„ä»£ç†åœ¨é€æ­¥äººæœºåä½œæ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œä½†åœ¨éœ€è¦å®æ—¶äº’åŠ¨çš„åŒæ—¶å¤šä»»åŠ¡ä¸­è¡¨ç°å‡ºå±€é™æ€§ã€‚ä¸ºåº”å¯¹æ­¤æŒ‘æˆ˜ï¼Œæœ¬ç ”ç©¶æå‡ºDual Process Theoryï¼ˆDPTï¼‰çš„å¿…è¦æ€§ï¼Œå¹¶è®¾è®¡DPT-Agentæ¡†æ¶ï¼Œæ•´åˆSystem 1å’ŒSystem 2ä»¥å®ç°é«˜æ•ˆå®æ—¶äººæœºåä½œã€‚DPT-Agenté€šè¿‡Finite-state Machineï¼ˆFSMï¼‰è¿›è¡Œç›´è§‚å¯æ§çš„å†³ç­–ï¼Œå¹¶é›†æˆTheory of Mindï¼ˆToMï¼‰è¿›è¡Œæ¨ç†è‡ªä¸»å†³ç­–ã€‚å®éªŒè¯æ˜ï¼ŒDPT-Agentåœ¨åŸºäºè§„åˆ™çš„ä¸»æµè¯­è¨€æ¨¡å‹æ¡†æ¶ä¸Šæœ‰æ˜¾è‘—æ”¹å–„ï¼Œèƒ½æˆåŠŸå®ç°å®æ—¶åŒæ­¥äººæœºåä½œè‡ªä¸»åŒ–ã€‚å…¶ä»£ç å¯è®¿é—®ï¼š<a target="_blank" rel="noopener" href="https://github.com/sjtu-marl/DPT-Agent">é“¾æ¥åœ°å€</a>ã€‚</p>
<p><strong>Key Takeaways</strong>ï¼š</p>
<ul>
<li>å¤§å‹è¯­è¨€æ¨¡å‹ä»£ç†åœ¨é€æ­¥äººæœºåä½œä¸­è¡¨ç°å‡ºä¼˜åŠ¿ï¼Œä½†åœ¨å®æ—¶å¤šä»»åŠ¡ä¸­é¢ä¸´æŒ‘æˆ˜ã€‚</li>
<li>å®æ—¶ä»»åŠ¡éœ€è¦è‡ªä¸»å†³ç­–èƒ½åŠ›ï¼Œè¦æ±‚AIç†è§£å¹¶æ¨æ–­äººç±»æ„å›¾ã€‚</li>
<li>Dual Process Theoryï¼ˆDPTï¼‰æ˜¯è§£å†³è¿™äº›é—®é¢˜çš„å…³é”®ç†è®ºå·¥å…·ã€‚</li>
<li>DPT-Agentç»“åˆäº†System 1å’ŒSystem 2å®ç°é«˜æ•ˆå®æ—¶äººæœºåä½œã€‚</li>
<li>DPT-Agentä½¿ç”¨Finite-state Machineï¼ˆFSMï¼‰è¿›è¡Œå¿«é€Ÿå†³ç­–ï¼Œå¹¶ç»“åˆTheory of Mindï¼ˆToMï¼‰è¿›è¡Œæ¨ç†è‡ªä¸»å†³ç­–ã€‚</li>
<li>ä¸åŸºäºè§„åˆ™çš„ä¸»æµè¯­è¨€æ¨¡å‹ç›¸æ¯”ï¼ŒDPT-Agentåœ¨å®éªŒä¸­è¡¨ç°ä¼˜å¼‚ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.11882">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-f1418b7c758a3532db72017e2c0bdb44.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-86beff2b8789d6bbf5206fd03f5858ca.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c5bce3d669de34c6bbd8bd3e1abc137a.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-daab1b28b518650e2816271c74d45227.jpg" align="middle">
</details>


<h1 id="-11"><a href="#-11" class="headerlink" title=""></a></h1><h2 id="Memento-No-More-Coaching-AI-Agents-to-Master-Multiple-Tasks-via-Hints-Internalization"><a href="#Memento-No-More-Coaching-AI-Agents-to-Master-Multiple-Tasks-via-Hints-Internalization" class="headerlink" title="Memento No More: Coaching AI Agents to Master Multiple Tasks via Hints   Internalization"></a>Memento No More: Coaching AI Agents to Master Multiple Tasks via Hints   Internalization</h2><p><strong>Authors:Minttu Alakuijala, Ya Gao, Georgy Ananov, Samuel Kaski, Pekka Marttinen, Alexander Ilin, Harri Valpola</strong></p>
<p>As the general capabilities of artificial intelligence (AI) agents continue to evolve, their ability to learn to master multiple complex tasks through experience remains a key challenge. Current LLM agents, particularly those based on proprietary language models, typically rely on prompts to incorporate knowledge about the target tasks. This approach does not allow the agent to internalize this information and instead relies on ever-expanding prompts to sustain its functionality in diverse scenarios. This resembles a system of notes used by a person affected by anterograde amnesia, the inability to form new memories. In this paper, we propose a novel method to train AI agents to incorporate knowledge and skills for multiple tasks without the need for either cumbersome note systems or prior high-quality demonstration data. Our approach employs an iterative process where the agent collects new experiences, receives corrective feedback from humans in the form of hints, and integrates this feedback into its weights via a context distillation training procedure. We demonstrate the efficacy of our approach by implementing it in a Llama-3-based agent that, after only a few rounds of feedback, outperforms advanced models GPT-4o and DeepSeek-V3 in tasksets requiring correct sequencing of information retrieval, tool use, and question answering. </p>
<blockquote>
<p>éšç€äººå·¥æ™ºèƒ½ï¼ˆAIï¼‰ä»£ç†çš„ä¸€èˆ¬èƒ½åŠ›ä¸æ–­å‘å±•ï¼Œå®ƒä»¬é€šè¿‡ç»éªŒå­¦ä¹ æŒæ¡å¤šç§å¤æ‚ä»»åŠ¡çš„èƒ½åŠ›ä»ç„¶æ˜¯ä¸€ä¸ªå…³é”®æŒ‘æˆ˜ã€‚å½“å‰çš„å¤§å‹è¯­è¨€æ¨¡å‹ä»£ç†ï¼ˆLLMä»£ç†ï¼‰ï¼Œç‰¹åˆ«æ˜¯åŸºäºä¸“æœ‰è¯­è¨€æ¨¡å‹çš„ä»£ç†ï¼Œé€šå¸¸ä¾èµ–äºæç¤ºæ¥èå…¥ç›®æ ‡ä»»åŠ¡çš„çŸ¥è¯†ã€‚è¿™ç§æ–¹æ³•ä¸å…è®¸ä»£ç†å†…åŒ–è¿™äº›ä¿¡æ¯ï¼Œè€Œæ˜¯ä¾èµ–äºä¸æ–­æ‰©å¤§çš„æç¤ºæ¥ç»´æŒå…¶åœ¨ä¸åŒåœºæ™¯ä¸­çš„åŠŸèƒ½ã€‚è¿™å°±åƒä¸€ä¸ªæ‚£æœ‰é¡ºè¡Œæ€§å¤±å¿†ç—‡çš„äººä½¿ç”¨çš„ç¬”è®°ç³»ç»Ÿï¼Œæ‚£è€…æ— æ³•å½¢æˆæ–°çš„è®°å¿†ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°æ–¹æ³•ï¼Œç”¨äºè®­ç»ƒAIä»£ç†èå…¥å¤šé¡¹ä»»åŠ¡çš„çŸ¥è¯†å’ŒæŠ€èƒ½ï¼Œæ— éœ€ä½¿ç”¨ç¹ççš„ç¬”è®°ç³»ç»Ÿæˆ–é¢„å…ˆçš„é«˜è´¨é‡æ¼”ç¤ºæ•°æ®ã€‚æˆ‘ä»¬çš„æ–¹æ³•é‡‡ç”¨è¿­ä»£è¿‡ç¨‹ï¼Œä»£ç†æ”¶é›†æ–°ç»éªŒï¼Œä»¥æç¤ºçš„å½¢å¼æ¥æ”¶æ¥è‡ªäººç±»çš„çº æ­£åé¦ˆï¼Œå¹¶é€šè¿‡ä¸Šä¸‹æ–‡è’¸é¦è®­ç»ƒç¨‹åºå°†åé¦ˆæ•´åˆåˆ°å…¶æƒé‡ä¸­ã€‚æˆ‘ä»¬é€šè¿‡åœ¨ä¸€ä¸ªåŸºäºLlama-3çš„ä»£ç†ä¸­å®ç°è¯¥æ–¹æ³•ï¼Œè¯æ˜äº†æˆ‘ä»¬æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚è¯¥ä»£ç†ä»…åœ¨å‡ è½®åé¦ˆåï¼Œå°±åœ¨éœ€è¦æ­£ç¡®æ’åºä¿¡æ¯æ£€ç´¢ã€å·¥å…·ä½¿ç”¨å’Œé—®ç­”çš„ä»»åŠ¡é›†ä¸­è¡¨ç°å‡ºä¼˜äºGPT-4oå’ŒDeepSeek-V3ç­‰å…ˆè¿›æ¨¡å‹çš„è¡¨ç°ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.01562v2">PDF</a> </p>
<p><strong>Summary</strong><br>     äººå·¥æ™ºèƒ½ä»£ç†äººçš„é€šç”¨èƒ½åŠ›ä¸æ–­è¿›åŒ–ï¼Œå½“å‰çš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä»£ç†äººåœ¨é¢å¯¹å¤šæ ·åŒ–åœºæ™¯æ—¶ä»é¢ä¸´å­¦ä¹ æŒæ¡å¤šé‡å¤æ‚ä»»åŠ¡çš„ä¸»è¦æŒ‘æˆ˜ã€‚ä¼ ç»Ÿçš„ä¾èµ–æç¤ºèå…¥ç›®æ ‡ä»»åŠ¡çŸ¥è¯†çš„æ–¹æ³•ä¸å…è®¸ä»£ç†äººå†…åŒ–è¿™äº›ä¿¡æ¯ï¼Œå¹¶ä¾èµ–äºä¸æ–­æ‰©å±•çš„æç¤ºæ¥ç»´æŒå…¶åŠŸèƒ½ã€‚æœ¬æ–‡æå‡ºä¸€ç§æ–°å‹æ–¹æ³•æ¥è®­ç»ƒAIä»£ç†äººæ— éœ€å†—é•¿çš„æç¤ºç³»ç»Ÿæˆ–ä¼˜è´¨ç¤ºèŒƒæ•°æ®å³å¯å®Œæˆå¤šé¡¹ä»»åŠ¡çš„æ–¹æ³•ã€‚è¯¥æ–¹æ³•é‡‡ç”¨è¿­ä»£è¿‡ç¨‹ï¼Œä»£ç†äººæ”¶é›†æ–°ç»éªŒï¼Œä»äººç±»æç¤ºä¸­è·å¾—çº æ­£åé¦ˆï¼Œé€šè¿‡ä¸Šä¸‹æ–‡è’¸é¦è®­ç»ƒç¨‹åºå°†åé¦ˆèå…¥æƒé‡ã€‚é€šè¿‡åŸºäºLlama-3çš„ä»£ç†äººå®è·µè¯å®è¯¥æ–¹æ³•çš„æœ‰æ•ˆæ€§ï¼Œåœ¨ç»è¿‡å‡ è½®åé¦ˆåï¼Œå…¶åœ¨éœ€è¦æ­£ç¡®æ’åºä¿¡æ¯æ£€ç´¢ã€å·¥å…·ä½¿ç”¨å’Œé—®ç­”çš„ä»»åŠ¡é›†ä¸­è¡¨ç°ä¼˜äºGPT-4oå’ŒDeepSeek-V3æ¨¡å‹ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>äººå·¥æ™ºèƒ½ä»£ç†äººåœ¨å­¦ä¹ æŒæ¡å¤šé‡å¤æ‚ä»»åŠ¡æ–¹é¢é¢ä¸´æŒ‘æˆ˜ã€‚</li>
<li>å½“å‰çš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä»£ç†äººä¾èµ–æç¤ºæ¥èå…¥ç›®æ ‡ä»»åŠ¡çš„æƒ…å¢ƒä¿¡æ¯ã€‚</li>
<li>ä¼ ç»Ÿæ–¹æ³•ä¸å…è®¸AIä»£ç†äººå†…åŒ–ä»»åŠ¡çŸ¥è¯†ï¼Œä¾èµ–äºä¸æ–­æ‰©å±•çš„æç¤ºç»´æŒåŠŸèƒ½ã€‚</li>
<li>æœ¬æ–‡æå‡ºä¸€ç§æ–°å‹è®­ç»ƒAIä»£ç†äººæ–¹æ³•ï¼Œæ— éœ€å†—é•¿çš„æç¤ºç³»ç»Ÿæˆ–ä¼˜è´¨ç¤ºèŒƒæ•°æ®å³å¯å®ç°å¤šé¡¹ä»»åŠ¡å¤„ç†ã€‚</li>
<li>è¯¥æ–¹æ³•é‡‡ç”¨è¿­ä»£è¿‡ç¨‹ï¼ŒåŒ…æ‹¬æ”¶é›†æ–°ç»éªŒã€ä»äººç±»æç¤ºä¸­è·å¾—çº æ­£åé¦ˆã€é€šè¿‡ä¸Šä¸‹æ–‡è’¸é¦è®­ç»ƒç¨‹åºå°†åé¦ˆèå…¥æƒé‡ã€‚</li>
<li>å®æ–½æ–¹æ³•çš„æ˜¯åŸºäºLlama-3çš„ä»£ç†äººï¼Œç»è¿‡å‡ è½®åé¦ˆåè¡¨ç°ä¼˜å¼‚ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.01562">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-bb0a53d07e67b24d76cec7d7e4f0e29b.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-d65cb9ea7ef00425730f99f36c059156.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-3ee70df3f4e68b97d3a832f4fdd52f67.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-23a1270a58580185d47fc1986ee0984a.jpg" align="middle">
</details>


<h1 id="-12"><a href="#-12" class="headerlink" title=""></a></h1><h2 id="AdvAgent-Controllable-Blackbox-Red-teaming-on-Web-Agents"><a href="#AdvAgent-Controllable-Blackbox-Red-teaming-on-Web-Agents" class="headerlink" title="AdvAgent: Controllable Blackbox Red-teaming on Web Agents"></a>AdvAgent: Controllable Blackbox Red-teaming on Web Agents</h2><p><strong>Authors:Chejian Xu, Mintong Kang, Jiawei Zhang, Zeyi Liao, Lingbo Mo, Mengqi Yuan, Huan Sun, Bo Li</strong></p>
<p>Foundation model-based agents are increasingly used to automate complex tasks, enhancing efficiency and productivity. However, their access to sensitive resources and autonomous decision-making also introduce significant security risks, where successful attacks could lead to severe consequences. To systematically uncover these vulnerabilities, we propose AdvAgent, a black-box red-teaming framework for attacking web agents. Unlike existing approaches, AdvAgent employs a reinforcement learning-based pipeline to train an adversarial prompter model that optimizes adversarial prompts using feedback from the black-box agent. With careful attack design, these prompts effectively exploit agent weaknesses while maintaining stealthiness and controllability. Extensive evaluations demonstrate that AdvAgent achieves high success rates against state-of-the-art GPT-4-based web agents across diverse web tasks. Furthermore, we find that existing prompt-based defenses provide only limited protection, leaving agents vulnerable to our framework. These findings highlight critical vulnerabilities in current web agents and emphasize the urgent need for stronger defense mechanisms. We release code at <a target="_blank" rel="noopener" href="https://ai-secure.github.io/AdvAgent/">https://ai-secure.github.io/AdvAgent/</a>. </p>
<blockquote>
<p>åŸºäºæ¨¡å‹çš„æ™ºèƒ½ä»£ç†æ­£è¢«è¶Šæ¥è¶Šå¤šåœ°ç”¨äºè‡ªåŠ¨åŒ–å¤æ‚ä»»åŠ¡ï¼Œä»¥æé«˜æ•ˆç‡å’Œç”Ÿäº§åŠ›ã€‚ç„¶è€Œï¼Œå®ƒä»¬è®¿é—®æ•æ„Ÿèµ„æºå’Œè‡ªä¸»å†³ç­–çš„èƒ½åŠ›ä¹Ÿå¸¦æ¥äº†é‡å¤§çš„å®‰å…¨é£é™©ï¼ŒæˆåŠŸçš„æ”»å‡»å¯èƒ½å¯¼è‡´ä¸¥é‡åæœã€‚ä¸ºäº†ç³»ç»Ÿåœ°æ­ç¤ºè¿™äº›æ¼æ´ï¼Œæˆ‘ä»¬æå‡ºäº†AdvAgentï¼Œè¿™æ˜¯ä¸€ä¸ªç”¨äºæ”»å‡»ç½‘ç»œæ™ºèƒ½ä»£ç†çš„é»‘ç®±çº¢é˜Ÿæ¡†æ¶ã€‚ä¸ç°æœ‰æ–¹æ³•ä¸åŒï¼ŒAdvAgenté‡‡ç”¨åŸºäºå¼ºåŒ–å­¦ä¹ çš„ç®¡é“æ¥è®­ç»ƒå¯¹æŠ—æ€§æç¤ºæ¨¡å‹ï¼Œè¯¥æ¨¡å‹ä½¿ç”¨æ¥è‡ªé»‘ç®±æ™ºèƒ½ä»£ç†çš„åé¦ˆæ¥ä¼˜åŒ–å¯¹æŠ—æ€§æç¤ºã€‚é€šè¿‡ç²¾å¿ƒè®¾è®¡çš„æ”»å‡»ï¼Œè¿™äº›æç¤ºèƒ½å¤Ÿæœ‰æ•ˆåœ°åˆ©ç”¨æ™ºèƒ½ä»£ç†çš„å¼±ç‚¹ï¼ŒåŒæ—¶ä¿æŒéšè”½æ€§å’Œå¯æ§æ€§ã€‚å¹¿æ³›çš„è¯„ä¼°è¡¨æ˜ï¼ŒAdvAgentåœ¨å¤šç§ç½‘ç»œä»»åŠ¡ä¸Šé’ˆå¯¹æœ€å…ˆè¿›çš„GPT-4åŸºäºç½‘ç»œçš„æ™ºèƒ½ä»£ç†å–å¾—äº†è¾ƒé«˜çš„æˆåŠŸç‡ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å‘ç°ç°æœ‰çš„åŸºäºæç¤ºçš„é˜²å¾¡æªæ–½åªæä¾›äº†æœ‰é™çš„ä¿æŠ¤ï¼Œä½¿æ™ºèƒ½ä»£ç†å®¹æ˜“å—åˆ°æˆ‘ä»¬çš„æ¡†æ¶çš„æ”»å‡»ã€‚è¿™äº›å‘ç°çªå‡ºäº†å½“å‰ç½‘ç»œæ™ºèƒ½ä»£ç†ä¸­çš„å…³é”®æ¼æ´ï¼Œå¹¶å¼ºè°ƒäº†è¿«åˆ‡éœ€è¦æ›´å¼ºå¤§çš„é˜²å¾¡æœºåˆ¶ã€‚æˆ‘ä»¬å·²å°†ä»£ç å‘å¸ƒåœ¨<a target="_blank" rel="noopener" href="https://ai-secure.github.io/AdvAgent/%E4%B8%8A%E3%80%82">https://ai-secure.github.io/AdvAgent/ä¸Šã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2410.17401v3">PDF</a> ICML 2025</p>
<p><strong>Summary</strong></p>
<p>åŸºäºæ¨¡å‹çš„è‡ªåŠ¨åŒ–ä»£ç†å¹¿æ³›åº”ç”¨äºå¤æ‚ä»»åŠ¡ï¼Œæé«˜äº†æ•ˆç‡å’Œç”Ÿäº§åŠ›ï¼Œä½†å…¶è®¿é—®æ•æ„Ÿèµ„æºå’Œè‡ªä¸»å†³ç­–èƒ½åŠ›ä¹Ÿå¸¦æ¥äº†å®‰å…¨é£é™©ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬æå‡ºäº†AdvAgentè¿™ä¸€é’ˆå¯¹ç½‘ç»œä»£ç†æ”»å‡»çš„é»‘ç›’çº¢é˜Ÿæ¡†æ¶ã€‚AdvAgenté‡‡ç”¨åŸºäºå¼ºåŒ–å­¦ä¹ çš„ç®¡é“è®­ç»ƒå¯¹æŠ—æç¤ºæ¨¡å‹ï¼Œé€šè¿‡å¯¹é»‘ç›’ä»£ç†çš„åé¦ˆä¼˜åŒ–å¯¹æŠ—æç¤ºï¼Œæœ‰æ•ˆåœ°å‘ç°å¹¶åˆ©ç”¨ä»£ç†å¼±ç‚¹ã€‚è¯„ä¼°æ˜¾ç¤ºï¼ŒAdvAgenté’ˆå¯¹å…ˆè¿›çš„GPT-4ç½‘ç»œä»£ç†å–å¾—äº†é«˜æˆåŠŸç‡ã€‚ç°æœ‰åŸºäºæç¤ºçš„é˜²å¾¡æªæ–½ä»…æä¾›æœ‰é™ä¿æŠ¤ï¼Œå¼ºè°ƒäº†å¢å¼ºé˜²å¾¡æœºåˆ¶çš„ç´§è¿«æ€§ã€‚ä»£ç å…¬å¼€åœ¨<a target="_blank" rel="noopener" href="https://ai-secure.github.io/AdvAgent/">https://ai-secure.github.io/AdvAgent/</a>ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>åŸºäºæ¨¡å‹çš„ä»£ç†å¹¿æ³›åº”ç”¨äºè‡ªåŠ¨åŒ–å¤æ‚ä»»åŠ¡ï¼Œæé«˜æ•ˆç‡å’Œç”Ÿäº§åŠ›ã€‚</li>
<li>è¿™äº›ä»£ç†å­˜åœ¨å®‰å…¨é£é™©ï¼Œç‰¹åˆ«æ˜¯å…³äºè®¿é—®æ•æ„Ÿèµ„æºå’Œè‡ªä¸»å†³ç­–ã€‚</li>
<li>AdvAgentæ˜¯ä¸€ç§é’ˆå¯¹ç½‘ç»œä»£ç†çš„é»‘ç›’çº¢é˜Ÿæ”»å‡»æ¡†æ¶ã€‚</li>
<li>AdvAgenté‡‡ç”¨å¼ºåŒ–å­¦ä¹ ç®¡é“è®­ç»ƒå¯¹æŠ—æç¤ºæ¨¡å‹æ¥ä¼˜åŒ–å¯¹æŠ—æç¤ºã€‚</li>
<li>è¯¥æ¡†æ¶èƒ½æœ‰æ•ˆå‘ç°å¹¶åˆ©ç”¨ç½‘ç»œä»£ç†çš„å¼±ç‚¹ã€‚</li>
<li>AdvAgenté’ˆå¯¹å…ˆè¿›çš„GPT-4ç½‘ç»œä»£ç†å–å¾—äº†é«˜æˆåŠŸç‡ã€‚</li>
<li>ç›®å‰åŸºäºæç¤ºçš„é˜²å¾¡æªæ–½ä»…æä¾›æœ‰é™ä¿æŠ¤ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2410.17401">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-4857beba288720e79001e15e5efc0364.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-3e6b21e9aceebe77bdb85f7c8a696f4d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-75b749f30a4b57aa6d135082f3837938.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c985d0b26efce827993f5d742643a64a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-53a0d7031a484d6944aed63374b5cddd.jpg" align="middle">
</details>


<h1 id="-13"><a href="#-13" class="headerlink" title=""></a></h1><h2 id="LAMBDA-A-Large-Model-Based-Data-Agent"><a href="#LAMBDA-A-Large-Model-Based-Data-Agent" class="headerlink" title="LAMBDA: A Large Model Based Data Agent"></a>LAMBDA: A Large Model Based Data Agent</h2><p><strong>Authors:Maojun Sun, Ruijian Han, Binyan Jiang, Houduo Qi, Defeng Sun, Yancheng Yuan, Jian Huang</strong></p>
<p>We introduce LArge Model Based Data Agent (LAMBDA), a novel open-source, code-free multi-agent data analysis system that leverages the power of large language models. LAMBDA is designed to address data analysis challenges in data-driven applications through innovatively designed data agents using natural language. At the core of LAMBDA are two key agent roles: the programmer and the inspector, which are engineered to work together seamlessly. Specifically, the programmer generates code based on the userâ€™s instructions and domain-specific knowledge, while the inspector debugs the code when necessary. To ensure robustness and handle adverse scenarios, LAMBDA features a user interface that allows direct user intervention. Moreover, LAMBDA can flexibly integrate external models and algorithms through our proposed Knowledge Integration Mechanism, catering to the needs of customized data analysis. LAMBDA has demonstrated strong performance on various data analysis tasks. It has the potential to enhance data analysis paradigms by seamlessly integrating human and artificial intelligence, making it more accessible, effective, and efficient for users from diverse backgrounds. The strong performance of LAMBDA in solving data analysis problems is demonstrated using real-world data examples. The code for LAMBDA is available at <a target="_blank" rel="noopener" href="https://github.com/AMA-CMFAI/LAMBDA">https://github.com/AMA-CMFAI/LAMBDA</a> and videos of three case studies can be viewed at <a target="_blank" rel="noopener" href="https://www.polyu.edu.hk/ama/cmfai/lambda.html">https://www.polyu.edu.hk/ama/cmfai/lambda.html</a>. </p>
<blockquote>
<p>æˆ‘ä»¬ä»‹ç»åŸºäºå¤§æ¨¡å‹çš„Data Agentï¼ˆLAMBDAï¼‰ï¼Œè¿™æ˜¯ä¸€ä¸ªæ–°å‹å¼€æºã€å…ç¼–ç¨‹çš„å¤šæ™ºèƒ½ä½“æ•°æ®åˆ†æç³»ç»Ÿï¼Œåˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹çš„å¼ºå¤§åŠŸèƒ½ã€‚LAMBDAæ—¨åœ¨é€šè¿‡é‡‡ç”¨è‡ªç„¶è¯­è¨€åˆ›æ–°è®¾è®¡çš„æ™ºèƒ½ä½“æ¥è§£å†³æ•°æ®é©±åŠ¨åº”ç”¨ä¸­çš„æ•°æ®åˆ†ææŒ‘æˆ˜ã€‚åœ¨LAMBDAçš„æ ¸å¿ƒæ˜¯ä¸¤ä¸ªå…³é”®æ™ºèƒ½ä½“è§’è‰²ï¼šç¨‹åºå‘˜å’Œæ£€æŸ¥å‘˜ï¼Œå®ƒä»¬è¢«æ— ç¼åœ°è®¾è®¡åœ¨ä¸€èµ·ååŒå·¥ä½œã€‚å…·ä½“æ¥è¯´ï¼Œç¨‹åºå‘˜æ ¹æ®ç”¨æˆ·çš„æŒ‡ä»¤å’Œé¢†åŸŸç‰¹å®šçŸ¥è¯†ç”Ÿæˆä»£ç ï¼Œè€Œæ£€æŸ¥å‘˜åœ¨å¿…è¦æ—¶è¿›è¡Œè°ƒè¯•ã€‚ä¸ºäº†ç¡®ä¿ç¨³å¥æ€§å¹¶åº”å¯¹ä¸åˆ©åœºæ™¯ï¼ŒLAMBDAæä¾›äº†ä¸€ä¸ªç”¨æˆ·ç•Œé¢ï¼Œå…è®¸ç›´æ¥ç”¨æˆ·å¹²é¢„ã€‚æ­¤å¤–ï¼ŒLAMBDAå¯ä»¥é€šè¿‡æˆ‘ä»¬æå‡ºçš„çŸ¥è¯†æ•´åˆæœºåˆ¶çµæ´»åœ°é›†æˆå¤–éƒ¨æ¨¡å‹å’Œç®—æ³•ï¼Œæ»¡è¶³å®šåˆ¶æ•°æ®åˆ†æçš„éœ€æ±‚ã€‚åœ¨å„ç§æ•°æ®åˆ†æä»»åŠ¡ä¸­ï¼ŒLAMBDAè¡¨ç°å‡ºäº†å¼ºå¤§çš„æ€§èƒ½ã€‚å®ƒå…·æœ‰é€šè¿‡æ— ç¼æ•´åˆäººå·¥æ™ºèƒ½å’Œäººç±»æ™ºèƒ½æ¥æå‡æ•°æ®åˆ†ææ¨¡å¼çš„æ½œåŠ›ï¼Œä¸ºæ¥è‡ªä¸åŒèƒŒæ™¯çš„ç”¨æˆ·æä¾›æ›´ä¾¿æ·ã€æœ‰æ•ˆå’Œé«˜æ•ˆçš„åˆ†æä½“éªŒã€‚é€šè¿‡çœŸå®ä¸–ç•Œçš„æ•°æ®ç¤ºä¾‹å±•ç¤ºäº†LAMBDAåœ¨è§£å†³æ•°æ®åˆ†æé—®é¢˜æ–¹é¢çš„å¼ºå¤§æ€§èƒ½ã€‚æœ‰å…³LAMBDAçš„ä»£ç å¯åœ¨[<a target="_blank" rel="noopener" href="https://github.com/AMA-CMFAI/LAMBDA%E6%89%BE%E5%88%B0%EF%BC%8C%E4%B8%89%E4%B8%AA%E6%A1%88%E4%BE%8B%E7%A0%94%E7%A9%B6%E7%9A%84%E8%A7%86%E9%A2%91%E5%8F%AF%E5%9C%A8[https://www.polyu.edu.hk/ama/cmfai/lambda.html%E8%A7%82%E7%9C%8B%E3%80%82](https://www.polyu.edu.hk/ama/cmfai/lambda.html%E8%A7%A3%E5%B9%BF%E3%80%82)">https://github.com/AMA-CMFAI/LAMBDAæ‰¾åˆ°ï¼Œä¸‰ä¸ªæ¡ˆä¾‹ç ”ç©¶çš„è§†é¢‘å¯åœ¨[https://www.polyu.edu.hk/ama/cmfai/lambda.htmlè§‚çœ‹ã€‚](https://www.polyu.edu.hk/ama/cmfai/lambda.html%E8%A7%A3%E5%B9%BF%E3%80%82)</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2407.17535v3">PDF</a> 56 pages</p>
<p><strong>Summary</strong></p>
<p>LAMBDAæ˜¯ä¸€ä¸ªå¼€æºã€å…ç¼–ç¨‹çš„å¤šæ™ºèƒ½ä½“æ•°æ®åˆ†æç³»ç»Ÿï¼Œå®ƒåˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹çš„å¨åŠ›ï¼Œé€šè¿‡è‡ªç„¶è¯­è¨€åˆ›æ–°è®¾è®¡çš„æ•°æ®æ™ºèƒ½ä½“æ¥è§£å†³æ•°æ®åˆ†ææŒ‘æˆ˜ã€‚ç³»ç»Ÿæ ¸å¿ƒåŒ…æ‹¬ç¨‹åºå‘˜å’Œæ£€æŸ¥å‘˜ä¸¤ä¸ªå…³é”®æ™ºèƒ½ä½“è§’è‰²ï¼Œå¯ç”Ÿæˆä»£ç ã€è°ƒè¯•ä»£ç ï¼Œå¹¶å¯é€šè¿‡ç”¨æˆ·ç•Œé¢ç›´æ¥å¹²é¢„ã€‚æ­¤å¤–ï¼ŒLAMBDAå¯çµæ´»é›†æˆå¤–éƒ¨æ¨¡å‹å’Œç®—æ³•ï¼Œæ»¡è¶³å®šåˆ¶æ•°æ®åˆ†æçš„éœ€æ±‚ã€‚å®ƒåœ¨å„ç§æ•°æ®åˆ†æä»»åŠ¡ä¸­è¡¨ç°å‡ºå¼ºå¤§çš„æ€§èƒ½ï¼Œå±•ç¤ºäº†äººä¸äººå·¥æ™ºèƒ½æ— ç¼é›†æˆçš„æ½œåŠ›ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>LAMBDAæ˜¯ä¸€ä¸ªå¼€æºã€å…ç¼–ç¨‹çš„å¤šæ™ºèƒ½ä½“æ•°æ®åˆ†æç³»ç»Ÿã€‚</li>
<li>åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹çš„å¨åŠ›è¿›è¡Œæ•°æ®åˆ†æã€‚</li>
<li>ç³»ç»Ÿä¸­åŒ…å«ä¸¤ä¸ªå…³é”®æ™ºèƒ½ä½“è§’è‰²ï¼šç¨‹åºå‘˜å’Œæ£€æŸ¥å‘˜ã€‚</li>
<li>ç¨‹åºå‘˜æ ¹æ®ç”¨æˆ·æŒ‡ä»¤å’Œé¢†åŸŸçŸ¥è¯†ç”Ÿæˆä»£ç ï¼Œæ£€æŸ¥å‘˜åˆ™è´Ÿè´£è°ƒè¯•ã€‚</li>
<li>ç”¨æˆ·ç•Œé¢å…è®¸ç›´æ¥å¹²é¢„ï¼Œç¡®ä¿ç³»ç»Ÿçš„ç¨³å¥æ€§ã€‚</li>
<li>LAMBDAå¯çµæ´»é›†æˆå¤–éƒ¨æ¨¡å‹å’Œç®—æ³•ï¼Œæ»¡è¶³å®šåˆ¶éœ€æ±‚ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2407.17535">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-8539fc8a58030c552ebfef2ccfe3d871.jpg" align="middle">
</details>


<h1 id="-14"><a href="#-14" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-05-30/Agent/">https://kedreamix.github.io/Talk2Paper/Paper/2025-05-30/Agent/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/Agent/">
                                    <span class="chip bg-color">Agent</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-05-30/MMT/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-b65ecbcd674cfe162fe2029826adc661.jpg" class="responsive-img" alt="MMT">
                        
                        <span class="card-title">MMT</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            MMT æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-05-30  MTVQA Benchmarking Multilingual Text-Centric Visual Question Answering
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-05-30
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/MMT/" class="post-category">
                                    MMT
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/MMT/">
                        <span class="chip bg-color">MMT</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-05-30/LLM/">
                    <div class="card-image">
                        
                        <img src="https://pic1.zhimg.com/v2-89671461f58ca318de287f7fc336ee70.jpg" class="responsive-img" alt="LLM">
                        
                        <span class="card-title">LLM</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            LLM æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-05-30  3DLLM-Mem Long-Term Spatial-Temporal Memory for Embodied 3D Large   Language Model
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-05-30
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/LLM/" class="post-category">
                                    LLM
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/LLM/">
                        <span class="chip bg-color">LLM</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">26548.9k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
