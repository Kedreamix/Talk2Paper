<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="TTS">
    <meta name="description" content="TTS æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-05-30  Tell me Habibi, is it Real or Fake?">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>TTS | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://picx.zhimg.com/v2-d4c856b39137d632c5e621835da585e0.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">TTS</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/TTS/">
                                <span class="chip bg-color">TTS</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/TTS/" class="post-category">
                                TTS
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-05-30
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-06-24
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    7.4k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    30 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-05-30-æ›´æ–°"><a href="#2025-05-30-æ›´æ–°" class="headerlink" title="2025-05-30 æ›´æ–°"></a>2025-05-30 æ›´æ–°</h1><h2 id="Tell-me-Habibi-is-it-Real-or-Fake"><a href="#Tell-me-Habibi-is-it-Real-or-Fake" class="headerlink" title="Tell me Habibi, is it Real or Fake?"></a>Tell me Habibi, is it Real or Fake?</h2><p><strong>Authors:Kartik Kuckreja, Parul Gupta, Injy Hamed, Thamar Solorio, Muhammad Haris Khan, Abhinav Dhall</strong></p>
<p>Deepfake generation methods are evolving fast, making fake media harder to detect and raising serious societal concerns. Most deepfake detection and dataset creation research focuses on monolingual content, often overlooking the challenges of multilingual and code-switched speech, where multiple languages are mixed within the same discourse. Code-switching, especially between Arabic and English, is common in the Arab world and is widely used in digital communication. This linguistic mixing poses extra challenges for deepfake detection, as it can confuse models trained mostly on monolingual data. To address this, we introduce \textbf{ArEnAV}, the first large-scale Arabic-English audio-visual deepfake dataset featuring intra-utterance code-switching, dialectal variation, and monolingual Arabic content. It \textbf{contains 387k videos and over 765 hours of real and fake videos}. Our dataset is generated using a novel pipeline integrating four Text-To-Speech and two lip-sync models, enabling comprehensive analysis of multilingual multimodal deepfake detection. We benchmark our dataset against existing monolingual and multilingual datasets, state-of-the-art deepfake detection models, and a human evaluation, highlighting its potential to advance deepfake research. The dataset can be accessed \href{<a target="_blank" rel="noopener" href="https://huggingface.co/datasets/kartik060702/ArEnAV-Full%7D%7Bhere%7D">https://huggingface.co/datasets/kartik060702/ArEnAV-Full}{here}</a>. </p>
<blockquote>
<p>æ·±åº¦ä¼ªé€ ç”Ÿæˆæ–¹æ³•æ­£åœ¨å¿«é€Ÿå‘å±•ï¼Œä½¿å¾—è™šå‡åª’ä½“æ›´éš¾æ£€æµ‹ï¼Œå¹¶å¼•å‘äº†ç¤¾ä¼šçš„ä¸¥é‡å…³æ³¨ã€‚å¤§å¤šæ•°æ·±åº¦ä¼ªé€ æ£€æµ‹å’Œæ•°æ®é›†åˆ›å»ºç ”ç©¶éƒ½é›†ä¸­åœ¨å•è¯­å†…å®¹ä¸Šï¼Œç»å¸¸å¿½è§†å¤šè¯­ç§å’Œä»£ç åˆ‡æ¢è¯­éŸ³çš„æŒ‘æˆ˜ï¼ŒåŒä¸€è¯è¯­ä¸­æ··åˆäº†å¤šç§è¯­è¨€ã€‚åœ¨é˜¿æ‹‰ä¼¯ä¸–ç•Œï¼Œä»£ç åˆ‡æ¢ï¼Œç‰¹åˆ«æ˜¯é˜¿æ‹‰ä¼¯è¯­å’Œè‹±è¯­ä¹‹é—´çš„åˆ‡æ¢ï¼Œæ˜¯å¸¸è§çš„ï¼Œå¹¶å¹¿æ³›ç”¨äºæ•°å­—é€šä¿¡ã€‚è¿™ç§è¯­è¨€æ··åˆç»™æ·±åº¦ä¼ªé€ æ£€æµ‹å¸¦æ¥äº†é¢å¤–çš„æŒ‘æˆ˜ï¼Œå› ä¸ºå®ƒå¯èƒ½ä¼šæ··æ·†ä¸»è¦åŸºäºå•è¯­æ•°æ®çš„æ¨¡å‹ã€‚ä¸ºè§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬æ¨å‡ºäº†ArEnAVï¼Œè¿™æ˜¯ç¬¬ä¸€ä¸ªå¤§è§„æ¨¡é˜¿æ‹‰ä¼¯è¯­-è‹±è¯­è§†å¬æ·±åº¦ä¼ªé€ æ•°æ®é›†ï¼Œå…·æœ‰è·¨è¯­ç è½¬æ¢ã€æ–¹è¨€å˜åŒ–å’Œå•è¯­é˜¿æ‹‰ä¼¯è¯­å†…å®¹çš„ç‰¹ç‚¹ã€‚å®ƒåŒ…å«äº†38.7ä¸‡å¤šä¸ªè§†é¢‘å’Œè¶…è¿‡765å°æ—¶çš„çœŸå®å’Œä¼ªé€ çš„è§†é¢‘å†…å®¹ã€‚æˆ‘ä»¬çš„æ•°æ®é›†æ˜¯é€šè¿‡ä¸€ä¸ªæ–°å‹ç®¡é“ç”Ÿæˆçš„ï¼Œè¯¥ç®¡é“é›†æˆäº†å››ç§æ–‡æœ¬åˆ°è¯­éŸ³å’Œä¸¤ç§å”‡åŒæ­¥æ¨¡å‹ï¼Œèƒ½å¤Ÿå…¨é¢åˆ†æå¤šè¯­ç§å¤šåª’ä½“æ·±åº¦ä¼ªé€ æ£€æµ‹ã€‚æˆ‘ä»¬å°†æ•°æ®é›†ä¸ç°æœ‰çš„å•è¯­ç§å’Œå¤šè¯­ç§æ•°æ®é›†ã€æœ€å…ˆè¿›çš„æ·±åº¦ä¼ªé€ æ£€æµ‹æ¨¡å‹ä»¥åŠäººç±»è¯„ä¼°è¿›è¡Œäº†æ¯”è¾ƒï¼Œå‡¸æ˜¾äº†å…¶åœ¨æ¨åŠ¨æ·±åº¦ä¼ªé€ ç ”ç©¶æ–¹é¢çš„æ½œåŠ›ã€‚æ•°æ®é›†å¯é€šè¿‡<a target="_blank" rel="noopener" href="https://huggingface.co/datasets/kartik060702/ArEnAV-Full">https://huggingface.co/datasets/kartik060702/ArEnAV-Full</a>è®¿é—®ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.22581v1">PDF</a> 9 pages, 2 figures, 12 tables</p>
<p><strong>Summary</strong><br>æ·±å‡æŠ€æœ¯ç”Ÿæˆæ–¹æ³•å‘å±•è¿…é€Ÿï¼Œä½¿å¾—å‡åª’ä½“æ›´éš¾æ£€æµ‹å¹¶å¼•å‘ç¤¾ä¼šå…³æ³¨ã€‚å½“å‰å¤§éƒ¨åˆ†æ·±åº¦ä¼ªé€ æ£€æµ‹å’Œæ•°æ®é›†åˆ›å»ºç ”ç©¶éƒ½é›†ä¸­åœ¨å•è¯­å†…å®¹ä¸Šï¼Œå¿½ç•¥äº†å¤šè¯­ç§å’Œæ··åˆè¯­è¨€å¸¦æ¥çš„æŒ‘æˆ˜ã€‚é˜¿æ‹‰ä¼¯å’Œè‹±è¯­çš„æ··åˆè¯­è¨€åœ¨é˜¿æ‹‰ä¼¯ä¸–ç•Œæ™®éå­˜åœ¨ï¼Œç»™æ·±åº¦ä¼ªé€ æ£€æµ‹å¸¦æ¥äº†é¢å¤–çš„æŒ‘æˆ˜ã€‚ä¸ºè§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬æ¨å‡ºäº†ArEnAVæ•°æ®é›†ï¼Œè¿™æ˜¯é¦–ä¸ªåŒ…å«é˜¿æ‹‰ä¼¯è¯­å’Œè‹±è¯­éŸ³è§†é¢‘æ·±åº¦ä¼ªé€ æ•°æ®é›†ï¼ŒåŒ…å«è·¨å¥æ··åˆè¯­è¨€ã€æ–¹è¨€å·®å¼‚å’Œå•è¯­é˜¿æ‹‰ä¼¯è¯­å†…å®¹ã€‚æ•°æ®é›†åŒ…å«38.7ä¸‡è§†é¢‘å’Œè¶…è¿‡765å°æ—¶çš„çœŸå®å’Œä¼ªé€ è§†é¢‘ã€‚æˆ‘ä»¬æ•´åˆäº†å››ä¸ªæ–‡æœ¬è½¬è¯­éŸ³å’Œä¸¤ä¸ªå”‡åŒæ­¥æ¨¡å‹æ¥ç”Ÿæˆè¯¥æ•°æ®é›†ï¼Œä»¥å…¨é¢åˆ†æå¤šè¯­ç§æ¨¡æ€æ·±åº¦ä¼ªé€ æ£€æµ‹ã€‚æˆ‘ä»¬å¯¹æ•°æ®é›†è¿›è¡Œäº†åŸºå‡†æµ‹è¯•ï¼Œä¸ç°æœ‰çš„å•è¯­ç§å’Œå¤šè¯­ç§æ•°æ®é›†ä»¥åŠæœ€å…ˆè¿›çš„æ·±åº¦ä¼ªé€ æ£€æµ‹æ¨¡å‹è¿›è¡Œäº†æ¯”è¾ƒï¼Œå¹¶è¿›è¡Œäº†äººç±»è¯„ä¼°ï¼Œçªå‡ºäº†å…¶å¯¹æ·±åº¦ä¼ªé€ ç ”ç©¶çš„æ½œåŠ›ã€‚æ•°æ®é›†å¯åœ¨æ­¤è®¿é—®ï¼š[é“¾æ¥åœ°å€]ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æ·±å‡æŠ€æœ¯å¿«é€Ÿå‘å±•å¸¦æ¥ç¤¾ä¼šæ‹…å¿§ã€‚</li>
<li>å½“å‰æ·±åº¦ä¼ªé€ æ£€æµ‹å’Œæ•°æ®é›†ç ”ç©¶ä¸»è¦å…³æ³¨å•è¯­å†…å®¹ã€‚</li>
<li>å¤šè¯­è¨€å’Œæ··åˆè¯­è¨€æŒ‘æˆ˜æ·±åº¦ä¼ªé€ æ£€æµ‹ã€‚</li>
<li>ArEnAVæ•°æ®é›†æ˜¯é¦–ä¸ªåŒ…å«é˜¿æ‹‰ä¼¯è¯­å’Œè‹±è¯­éŸ³è§†é¢‘æ·±åº¦ä¼ªé€ æ•°æ®é›†ã€‚</li>
<li>ArEnAVåŒ…å«çœŸå®å’Œä¼ªé€ è§†é¢‘æ•°æ®è¶…è¿‡765å°æ—¶ã€‚</li>
<li>ArEnAVæ•°æ®é›†çš„ç”Ÿæˆä½¿ç”¨äº†åˆ›æ–°çš„é›†æˆç®¡é“æŠ€æœ¯å¤„ç†å¤šç§æ¨¡å‹å’Œè¯­è¨€åˆ†æéœ€æ±‚ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.22581">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-9bd422b0b90b10eb8114746dcf2c0f88.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-6fb3326fa46cc0b857a52f0ecb1b98ea.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-e59ad237ae1b5b9e906994b4d2768169.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-07e29d028e4b88a84e427158a1842e2e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d23ad51e5a765d361f7b0789df9c4850.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-dcbff075bcd913a845b34f78c5e444b5.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c05434e5b44358dabe2f835c5c918eef.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-242c760d3cb2eaa60758cf1e3e29939e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-2e2276c2f0543201e2e4f9d3be4dbb0d.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="Analysis-and-Evaluation-of-Synthetic-Data-Generation-in-Speech-Dysfluency-Detection"><a href="#Analysis-and-Evaluation-of-Synthetic-Data-Generation-in-Speech-Dysfluency-Detection" class="headerlink" title="Analysis and Evaluation of Synthetic Data Generation in Speech   Dysfluency Detection"></a>Analysis and Evaluation of Synthetic Data Generation in Speech   Dysfluency Detection</h2><p><strong>Authors:Jinming Zhang, Xuanru Zhou, Jiachen Lian, Shuhe Li, William Li, Zoe Ezzes, Rian Bogley, Lisa Wauters, Zachary Miller, Jet Vonk, Brittany Morin, Maria Gorno-Tempini, Gopala Anumanchipalli</strong></p>
<p>Speech dysfluency detection is crucial for clinical diagnosis and language assessment, but existing methods are limited by the scarcity of high-quality annotated data. Although recent advances in TTS model have enabled synthetic dysfluency generation, existing synthetic datasets suffer from unnatural prosody and limited contextual diversity. To address these limitations, we propose LLM-Dys â€“ the most comprehensive dysfluent speech corpus with LLM-enhanced dysfluency simulation. This dataset captures 11 dysfluency categories spanning both word and phoneme levels. Building upon this resource, we improve an end-to-end dysfluency detection framework. Experimental validation demonstrates state-of-the-art performance. All data, models, and code are open-sourced at <a target="_blank" rel="noopener" href="https://github.com/Berkeley-Speech-Group/LLM-Dys">https://github.com/Berkeley-Speech-Group/LLM-Dys</a>. </p>
<blockquote>
<p>è¯­éŸ³æµç•…æ€§æ£€æµ‹å¯¹äºä¸´åºŠè¯Šæ–­å’Œæ²»ç–—è¯­è¨€è¯„ä¼°è‡³å…³é‡è¦ï¼Œä½†ç°æœ‰æ–¹æ³•å—åˆ°é«˜è´¨é‡æ ‡æ³¨æ•°æ®ç¨€ç¼ºçš„é™åˆ¶ã€‚å°½ç®¡æœ€è¿‘æ–‡æœ¬è½¬è¯­éŸ³æ¨¡å‹çš„è¿›æ­¥å·²ç»èƒ½å¤Ÿå®ç°åˆæˆæµç•…æ€§ç”Ÿæˆï¼Œä½†ç°æœ‰çš„åˆæˆæ•°æ®é›†å­˜åœ¨éŸµå¾‹ä¸è‡ªç„¶å’Œä¸Šä¸‹æ–‡å¤šæ ·æ€§æœ‰é™çš„ç¼ºç‚¹ã€‚ä¸ºäº†è§£å†³è¿™äº›å±€é™æ€§ï¼Œæˆ‘ä»¬æå‡ºäº†LLM-Dysâ€”â€”ä¸€ä¸ªç”±å¤§å‹è¯­è¨€æ¨¡å‹å¢å¼ºæµç•…æ€§æ¨¡æ‹Ÿçš„æœ€å…¨é¢çš„æµç•…æ€§è¯­éŸ³è¯­æ–™åº“ã€‚è¯¥æ•°æ®é›†æ¶µç›–äº†æ¶µç›–å•è¯å’ŒéŸ³ç´ çº§åˆ«çš„18ä¸ªæµç•…æ€§é—®é¢˜ç±»åˆ«ã€‚åŸºäºæ­¤èµ„æºï¼Œæˆ‘ä»¬æ”¹è¿›äº†ç«¯åˆ°ç«¯çš„æµç•…æ€§æ£€æµ‹æ¡†æ¶ã€‚å®éªŒéªŒè¯æ˜¾ç¤ºå…¶è¾¾åˆ°äº†æœ€æ–°æŠ€æœ¯æ°´å¹³ã€‚æ‰€æœ‰æ•°æ®å’Œæ¨¡å‹éƒ½åœ¨<a target="_blank" rel="noopener" href="https://github.com/Berkeley-Speech-Group/LLM-Dys%E4%B8%8A%E8%BF%9B%E8%A1%8C%E5%BC%80%E6%BA%90%E3%80%82">https://github.com/Berkeley-Speech-Group/LLM-Dysä¸Šè¿›è¡Œå¼€æºã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.22029v1">PDF</a> Submitted to Interspeech 2025</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†è¯­éŸ³æµç•…æ€§æ£€æµ‹åœ¨ä¸´åºŠè¯Šæ–­å’Œæ²»ç–—è¯­è¨€è¯„ä¼°ä¸­çš„é‡è¦æ€§ã€‚ç„¶è€Œï¼Œé«˜è´¨é‡æ ‡æ³¨æ•°æ®çš„ç¨€ç¼ºé™åˆ¶äº†ç°æœ‰æ–¹æ³•çš„æ€§èƒ½ã€‚å°½ç®¡æœ€è¿‘çš„TTSæ¨¡å‹è¿›æ­¥å·²ç»èƒ½å¤Ÿå®ç°åˆæˆæµç•…æ€§ç”Ÿæˆï¼Œä½†ç°æœ‰åˆæˆæ•°æ®é›†å­˜åœ¨è¯­éŸ³éŸµå¾‹ä¸è‡ªç„¶å’Œä¸Šä¸‹æ–‡å¤šæ ·æ€§æœ‰é™çš„é—®é¢˜ã€‚ä¸ºè§£å†³è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†LLM-Dysâ€”â€”ä¸€ä¸ªç”±å¤§å‹è¯­è¨€æ¨¡å‹å¢å¼ºæ¨¡æ‹Ÿæµç•…æ€§çš„æœ€å…¨é¢çš„æµç•…æ€§è¯­éŸ³è¯­æ–™åº“ã€‚è¯¥æ•°æ®é›†æ¶µç›–äº†è¯å’ŒéŸ³ç´ ä¸¤ä¸ªçº§åˆ«çš„11ç§æµç•…æ€§é—®é¢˜ç±»åˆ«ã€‚åŸºäºè¿™ä¸€èµ„æºï¼Œæˆ‘ä»¬æ”¹è¿›äº†ä¸€ä¸ªç«¯åˆ°ç«¯çš„æµç•…æ€§æ£€æµ‹æ¡†æ¶ï¼Œå¹¶é€šè¿‡å®éªŒéªŒè¯å–å¾—äº†ä¸šç•Œæœ€ä½³æ€§èƒ½ã€‚æ‰€æœ‰æ•°æ®ã€æ¨¡å‹å’Œä»£ç å‡å·²å¼€æºå…±äº«åœ¨<a target="_blank" rel="noopener" href="https://github.com/Berkeley-Speech-Group/LLM-Dys%E3%80%82">https://github.com/Berkeley-Speech-Group/LLM-Dysã€‚</a></p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>è¯­éŸ³æµç•…æ€§æ£€æµ‹åœ¨ä¸´åºŠè¯Šæ–­å’Œæ²»ç–—è¯­è¨€è¯„ä¼°ä¸­å…·æœ‰é‡è¦æ€§ã€‚</li>
<li>ç°æœ‰æ–¹æ³•å—é™äºé«˜è´¨é‡æ ‡æ³¨æ•°æ®çš„ç¨€ç¼ºã€‚</li>
<li>TTSæ¨¡å‹çš„æœ€æ–°è¿›å±•èƒ½å¤Ÿå®ç°åˆæˆæµç•…æ€§çš„ç”Ÿæˆã€‚</li>
<li>ç°æœ‰åˆæˆæ•°æ®é›†å­˜åœ¨è¯­éŸ³éŸµå¾‹ä¸è‡ªç„¶å’Œä¸Šä¸‹æ–‡å¤šæ ·æ€§æœ‰é™çš„é—®é¢˜ã€‚</li>
<li>LLM-Dysæ˜¯ä¸€ä¸ªå…¨é¢çš„æµç•…æ€§è¯­éŸ³è¯­æ–™åº“ï¼Œç”±å¤§å‹è¯­è¨€æ¨¡å‹å¢å¼ºæ¨¡æ‹Ÿæµç•…æ€§ã€‚</li>
<li>è¯¥æ•°æ®é›†æ¶µç›–äº†è¯å’ŒéŸ³ç´ ä¸¤ä¸ªçº§åˆ«çš„11ç§æµç•…æ€§é—®é¢˜ç±»åˆ«ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.22029">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-940820839a1fe5abc1d5ff4dd6770dc6.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f09ea430ad1b7c0b1ad598e4f7cab2fa.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b030629238cfa23ed174c5da4e1f06be.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-eae4225d2805104617350cc554123266.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d4c856b39137d632c5e621835da585e0.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-40f8c15c1bcb1f5c3aa3c4628cc2c9b9.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="OmniResponse-Online-Multimodal-Conversational-Response-Generation-in-Dyadic-Interactions"><a href="#OmniResponse-Online-Multimodal-Conversational-Response-Generation-in-Dyadic-Interactions" class="headerlink" title="OmniResponse: Online Multimodal Conversational Response Generation in   Dyadic Interactions"></a>OmniResponse: Online Multimodal Conversational Response Generation in   Dyadic Interactions</h2><p><strong>Authors:Cheng Luo, Jianghui Wang, Bing Li, Siyang Song, Bernard Ghanem</strong></p>
<p>In this paper, we introduce Online Multimodal Conversational Response Generation (OMCRG), a novel task that aims to online generate synchronized verbal and non-verbal listener feedback, conditioned on the speakerâ€™s multimodal input. OMCRG reflects natural dyadic interactions and poses new challenges in achieving synchronization between the generated audio and facial responses of the listener. To address these challenges, we innovatively introduce text as an intermediate modality to bridge the audio and facial responses. We hence propose OmniResponse, a Multimodal Large Language Model (MLLM) that autoregressively generates high-quality multi-modal listener responses. OmniResponse leverages a pretrained LLM enhanced with two novel components: Chrono-Text, which temporally anchors generated text tokens, and TempoVoice, a controllable online TTS module that produces speech synchronized with facial reactions. To support further OMCRG research, we present ResponseNet, a new dataset comprising 696 high-quality dyadic interactions featuring synchronized split-screen videos, multichannel audio, transcripts, and facial behavior annotations. Comprehensive evaluations conducted on ResponseNet demonstrate that OmniResponse significantly outperforms baseline models in terms of semantic speech content, audio-visual synchronization, and generation quality. </p>
<blockquote>
<p>æœ¬æ–‡ä»‹ç»äº†åœ¨çº¿å¤šæ¨¡æ€å¯¹è¯å“åº”ç”Ÿæˆï¼ˆOMCRGï¼‰è¿™ä¸€æ–°ä»»åŠ¡ï¼Œè¯¥ä»»åŠ¡æ—¨åœ¨æ ¹æ®è¯´è¯è€…çš„å¤šæ¨¡æ€è¾“å…¥ï¼Œåœ¨çº¿ç”ŸæˆåŒæ­¥çš„è¨€è¯­å’Œéè¨€è¯­å¬ä¼—åé¦ˆã€‚OMCRGåæ˜ äº†è‡ªç„¶çš„äºŒå…ƒäº¤äº’ï¼Œå¹¶åœ¨å®ç°ç”ŸæˆéŸ³é¢‘å’Œå¬ä¼—é¢éƒ¨å“åº”ä¹‹é—´çš„åŒæ­¥æ–¹é¢æå‡ºäº†æ–°çš„æŒ‘æˆ˜ã€‚ä¸ºäº†åº”å¯¹è¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬åˆ›æ–°æ€§åœ°å¼•å…¥æ–‡æœ¬ä½œä¸ºä¸­é—´æ¨¡æ€æ¥æ¡¥æ¥éŸ³é¢‘å’Œé¢éƒ¨å“åº”ã€‚å› æ­¤ï¼Œæˆ‘ä»¬æå‡ºäº†OmniResponseï¼Œè¿™æ˜¯ä¸€ç§å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆMLLMï¼‰ï¼Œå¯ä»¥è‡ªå›å½’åœ°ç”Ÿæˆé«˜è´¨é‡çš„å¤šæ¨¡æ€å¬ä¼—å“åº”ã€‚OmniResponseåˆ©ç”¨é¢„è®­ç»ƒçš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼Œå¹¶é…å¤‡äº†ä¸¤ä¸ªæ–°å‹ç»„ä»¶ï¼šChrono-Textï¼Œå®ƒæš‚æ—¶é”šå®šç”Ÿæˆçš„æ–‡æœ¬ä»¤ç‰Œï¼›ä»¥åŠTempoVoiceï¼Œè¿™æ˜¯ä¸€ä¸ªå¯æ§çš„åœ¨çº¿æ–‡æœ¬è½¬è¯­éŸ³ï¼ˆTTSï¼‰æ¨¡å—ï¼Œèƒ½å¤Ÿäº§ç”Ÿä¸é¢éƒ¨ååº”åŒæ­¥çš„è¯­éŸ³ã€‚ä¸ºäº†æ”¯æŒè¿›ä¸€æ­¥çš„OMCRGç ”ç©¶ï¼Œæˆ‘ä»¬æ¨å‡ºäº†ResponseNetæ•°æ®é›†ï¼ŒåŒ…å«696ä¸ªé«˜è´¨é‡çš„äºŒå…ƒäº¤äº’è§†é¢‘ï¼Œæ¯ä¸ªè§†é¢‘éƒ½åŒ…å«åŒæ­¥çš„åˆ†å‰²å±å¹•è§†é¢‘ã€å¤šé€šé“éŸ³é¢‘ã€å­—å¹•å’Œé¢éƒ¨è¡Œä¸ºæ³¨é‡Šã€‚åœ¨ResponseNetä¸Šè¿›è¡Œçš„ç»¼åˆè¯„ä¼°è¡¨æ˜ï¼ŒOmniResponseåœ¨è¯­ä¹‰è¯­éŸ³å†…å®¹ã€éŸ³è§†é¢‘åŒæ­¥å’Œç”Ÿæˆè´¨é‡æ–¹é¢å‡æ˜¾è‘—ä¼˜äºåŸºå‡†æ¨¡å‹ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.21724v1">PDF</a> 23 pages, 9 figures</p>
<p><strong>Summary</strong><br>åœ¨çº¿å¤šæ¨¡æ€å¯¹è¯å“åº”ç”Ÿæˆï¼ˆOMCRGï¼‰æ˜¯ä¸€é¡¹æ—¨åœ¨æ ¹æ®è¯´è¯è€…çš„å¤šæ¨¡æ€è¾“å…¥åœ¨çº¿ç”ŸæˆåŒæ­¥çš„è¨€è¯­å’Œéè¨€è¯­å¬ä¼—åé¦ˆçš„æ–°ä»»åŠ¡ã€‚ä¸ºåº”å¯¹æŒ‘æˆ˜ï¼Œå¼•å…¥äº†æ–‡æœ¬ä½œä¸ºè¿æ¥éŸ³é¢‘å’Œé¢éƒ¨å“åº”çš„ä¸­é—´æ¨¡æ€ï¼Œå¹¶æå‡ºäº†OmniResponseå¤šä»»åŠ¡å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆMLLMï¼‰ã€‚è¯¥æ¨¡å‹å¯è‡ªåŠ¨ç”Ÿæˆé«˜è´¨é‡çš„å¤šæ¨¡æ€å¬ä¼—å“åº”ï¼Œå¹¶åˆ©ç”¨å¸¦æœ‰ä¸¤ä¸ªæ–°ç»„ä»¶çš„é¢„è®­ç»ƒLLMï¼šç”¨äºä¸´æ—¶é”šå®šç”Ÿæˆæ–‡æœ¬ä»¤ç‰Œçš„Chrono-Textå’Œç”¨äºäº§ç”Ÿä¸é¢éƒ¨ååº”åŒæ­¥è¯­éŸ³çš„TempoVoiceå¯æ§åœ¨çº¿TTSæ¨¡å—ã€‚ä¸ºäº†æ”¯æŒOMCRGç ”ç©¶ï¼Œæ¨å‡ºResponseNetæ•°æ®é›†ï¼ŒåŒ…å«696ä¸ªé«˜è´¨é‡åŒäººäº’åŠ¨åŒæ­¥åˆ†å±è§†é¢‘ã€å¤šé€šé“éŸ³é¢‘ã€å­—å¹•å’Œé¢éƒ¨è¡Œä¸ºæ³¨é‡Šã€‚åœ¨ResponseNetä¸Šçš„ç»¼åˆè¯„ä¼°è¡¨æ˜ï¼ŒOmniResponseåœ¨è¯­ä¹‰è¯­éŸ³å†…å®¹ã€è§†å¬åŒæ­¥å’Œç”Ÿæˆè´¨é‡æ–¹é¢æ˜¾è‘—ä¼˜äºåŸºçº¿æ¨¡å‹ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>OMCRGä»»åŠ¡æ—¨åœ¨åœ¨çº¿ç”ŸæˆåŒæ­¥çš„è¨€è¯­å’Œéè¨€è¯­å¬ä¼—åé¦ˆï¼ŒåŸºäºè¯´è¯è€…çš„å¤šæ¨¡æ€è¾“å…¥ã€‚</li>
<li>å¼•å…¥æ–‡æœ¬ä½œä¸ºè¿æ¥éŸ³é¢‘å’Œé¢éƒ¨å“åº”çš„ä¸­é—´æ¨¡æ€ï¼Œä»¥åº”å¯¹æŒ‘æˆ˜ã€‚</li>
<li>æå‡ºOmniResponseå¤šä»»åŠ¡å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆMLLMï¼‰ï¼Œå¯è‡ªåŠ¨ç”Ÿæˆé«˜è´¨é‡çš„å¤šæ¨¡æ€å¬ä¼—å“åº”ã€‚</li>
<li>OmniResponseåˆ©ç”¨å¸¦æœ‰Chrono-Textå’ŒTempoVoiceä¸¤ä¸ªæ–°ç»„ä»¶çš„é¢„è®­ç»ƒLLMã€‚</li>
<li>ResponseNetæ•°æ®é›†åŒ…å«åŒæ­¥åˆ†å±è§†é¢‘ã€å¤šé€šé“éŸ³é¢‘ã€å­—å¹•å’Œé¢éƒ¨è¡Œä¸ºæ³¨é‡Šï¼Œæ”¯æŒOMCRGç ”ç©¶ã€‚</li>
<li>ç»¼åˆè¯„ä¼°æ˜¾ç¤ºï¼ŒOmniResponseåœ¨è¯­ä¹‰è¯­éŸ³å†…å®¹ã€è§†å¬åŒæ­¥å’Œç”Ÿæˆè´¨é‡æ–¹é¢ä¼˜äºåŸºçº¿æ¨¡å‹ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.21724">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-7ee89439a08a800f7f2bc627e7c2eed8.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-2c2f950db0761e9334fc4539985ab21a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-2f00d4b0043b1fde1c4f569f3780c9ca.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-7e3716546e46310ae6969f8875cfb7b4.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="Faster-and-Better-LLMs-via-Latency-Aware-Test-Time-Scaling"><a href="#Faster-and-Better-LLMs-via-Latency-Aware-Test-Time-Scaling" class="headerlink" title="Faster and Better LLMs via Latency-Aware Test-Time Scaling"></a>Faster and Better LLMs via Latency-Aware Test-Time Scaling</h2><p><strong>Authors:Zili Wang, Tianyu Zhang, Lei Zhu, Haoli Bai, Lu Hou, Shiming Xiang, Xianzhi Yu, Wulong Liu</strong></p>
<p>Test-Time Scaling (TTS) has proven effective in improving the performance of Large Language Models (LLMs) during inference. However, existing research has overlooked the efficiency of TTS from a latency-sensitive perspective. Through a latency-aware evaluation of representative TTS methods, we demonstrate that a compute-optimal TTS does not always result in the lowest latency in scenarios where latency is critical. To address this gap and achieve latency-optimal TTS, we propose two key approaches by optimizing the concurrency configurations: (1) branch-wise parallelism, which leverages multiple concurrent inference branches, and (2) sequence-wise parallelism, enabled by speculative decoding. By integrating these two approaches and allocating computational resources properly to each, our latency-optimal TTS enables a 32B model to reach 82.3% accuracy on MATH-500 within 1 minute and a smaller 3B model to achieve 72.4% within 10 seconds. Our work emphasizes the importance of latency-aware TTS and demonstrates its ability to deliver both speed and accuracy in latency-sensitive scenarios. </p>
<blockquote>
<p>æµ‹è¯•æ—¶ç¼©æ”¾ï¼ˆTTSï¼‰å·²è¯æ˜åœ¨æ¨ç†è¿‡ç¨‹ä¸­èƒ½æœ‰æ•ˆæé«˜å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„æ€§èƒ½ã€‚ç„¶è€Œï¼Œç°æœ‰ç ”ç©¶ä»å»¶è¿Ÿæ•æ„Ÿçš„è§’åº¦å¿½è§†äº†TTSçš„æ•ˆç‡ã€‚é€šè¿‡å¯¹ä»£è¡¨æ€§TTSæ–¹æ³•çš„å»¶è¿Ÿæ„ŸçŸ¥è¯„ä¼°ï¼Œæˆ‘ä»¬è¯æ˜è®¡ç®—æœ€ä¼˜çš„TTSå¹¶ä¸æ€»æ˜¯å¯¼è‡´å»¶è¿Ÿæœ€æ•æ„Ÿåœºæ™¯ä¸­å»¶è¿Ÿæœ€ä½ã€‚ä¸ºäº†å¼¥è¡¥è¿™ä¸€å·®è·å¹¶å®ç°å»¶è¿Ÿä¼˜åŒ–çš„TTSï¼Œæˆ‘ä»¬æå‡ºäº†ä¸¤ç§é€šè¿‡ä¼˜åŒ–å¹¶å‘é…ç½®çš„å…³é”®æ–¹æ³•ï¼šï¼ˆ1ï¼‰åˆ†æ”¯å¹¶è¡Œæ€§ï¼Œåˆ©ç”¨å¤šä¸ªå¹¶å‘æ¨ç†åˆ†æ”¯ï¼›ï¼ˆ2ï¼‰é€šè¿‡æŠ•æœºè§£ç å®ç°çš„åºåˆ—å¹¶è¡Œæ€§ã€‚é€šè¿‡æ•´åˆè¿™ä¸¤ç§æ–¹æ³•å¹¶ä¸ºæ¯ç§æ–¹æ³•é€‚å½“åˆ†é…è®¡ç®—èµ„æºï¼Œæˆ‘ä»¬çš„å»¶è¿Ÿä¼˜åŒ–TTSä½¿32Bæ¨¡å‹åœ¨MATH-500ä¸Š1åˆ†é’Ÿå†…è¾¾åˆ°82.3%çš„å‡†ç¡®ç‡ï¼Œè¾ƒå°çš„3Bæ¨¡å‹åœ¨10ç§’å†…è¾¾åˆ°72.4%çš„å‡†ç¡®ç‡ã€‚æˆ‘ä»¬çš„å·¥ä½œå¼ºè°ƒäº†å»¶è¿Ÿæ„ŸçŸ¥TTSçš„é‡è¦æ€§ï¼Œå¹¶å±•ç¤ºäº†å…¶åœ¨å»¶è¿Ÿæ•æ„Ÿåœºæ™¯ä¸­å®ç°é€Ÿåº¦å’Œå‡†ç¡®æ€§çš„èƒ½åŠ›ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.19634v3">PDF</a> </p>
<p><strong>æ‘˜è¦</strong><br>    æ–‡æœ¬ä¸»è¦ä»‹ç»äº†æµ‹è¯•æ—¶é—´ç¼©æ”¾ï¼ˆTTSï¼‰åœ¨æé«˜å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ¨ç†æ€§èƒ½æ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚ç„¶è€Œï¼Œç°æœ‰ç ”ç©¶ä»å»¶è¿Ÿæ•æ„Ÿçš„è§’åº¦å¿½è§†äº†TTSçš„æ•ˆç‡ã€‚é€šè¿‡å»¶è¿Ÿæ„ŸçŸ¥çš„ä»£è¡¨æ€§TTSæ–¹æ³•çš„è¯„ä¼°ï¼Œæˆ‘ä»¬è¯æ˜äº†è®¡ç®—æœ€ä¼˜çš„TTSå¹¶ä¸æ€»æ˜¯å¯¼è‡´å»¶è¿Ÿæœ€ä½çš„åœºæ™¯ã€‚ä¸ºäº†å¼¥è¡¥è¿™ä¸€å·®è·å¹¶å®ç°å»¶è¿Ÿæœ€ä¼˜çš„TTSï¼Œæˆ‘ä»¬æå‡ºäº†ä¸¤ç§é€šè¿‡ä¼˜åŒ–å¹¶å‘é…ç½®çš„å…³é”®æ–¹æ³•ï¼šï¼ˆ1ï¼‰åˆ†æ”¯å¹¶è¡Œæ€§ï¼Œåˆ©ç”¨å¤šä¸ªå¹¶å‘æ¨ç†åˆ†æ”¯ï¼›ï¼ˆ2ï¼‰åºåˆ—å¹¶è¡Œæ€§ï¼Œé€šè¿‡æŠ•æœºè§£ç å®ç°ã€‚é€šè¿‡æ•´åˆè¿™ä¸¤ç§æ–¹æ³•å¹¶é€‚å½“åˆ†é…è®¡ç®—èµ„æºç»™æ¯ä¸ªéƒ¨åˆ†ï¼Œæˆ‘ä»¬çš„å»¶è¿Ÿæœ€ä¼˜TTSä½¿ä¸€ä¸ªè§„æ¨¡ä¸º32Bçš„æ¨¡å‹èƒ½åœ¨MATH-500æµ‹è¯•ä¸­è¾¾åˆ°82.3%çš„å‡†ç¡®ç‡ï¼Œå¹¶ä¸”åªéœ€ä¸€åˆ†é’Ÿï¼›è€Œä¸€ä¸ªæ›´å°çš„è§„æ¨¡ä¸º3Bçš„æ¨¡å‹å¯ä»¥åœ¨10ç§’å†…è¾¾åˆ°72.4%çš„å‡†ç¡®ç‡ã€‚æˆ‘ä»¬çš„å·¥ä½œå¼ºè°ƒäº†å»¶è¿Ÿæ„ŸçŸ¥TTSçš„é‡è¦æ€§ï¼Œå¹¶å±•ç¤ºäº†å…¶åœ¨éœ€è¦å³æ—¶ååº”çš„åœºæ™¯ä¸­èƒ½å¤ŸåŒæ—¶å®ç°é€Ÿåº¦å’Œå‡†ç¡®åº¦çš„èƒ½åŠ›ã€‚</p>
<p><strong>å…³é”®è§è§£</strong></p>
<ol>
<li>æµ‹è¯•æ—¶é—´ç¼©æ”¾ï¼ˆTTSï¼‰èƒ½æé«˜å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„æ¨ç†æ€§èƒ½ã€‚</li>
<li>ç°æœ‰ç ”ç©¶å¿½ç•¥äº†ä»å»¶è¿Ÿæ•æ„Ÿçš„è§’åº¦è¯„ä¼°TTSçš„æ•ˆç‡ã€‚</li>
<li>å®ç°å»¶è¿Ÿæœ€ä¼˜çš„TTSéœ€è¦ä¼˜åŒ–å¹¶å‘é…ç½®ï¼ŒåŒ…æ‹¬åˆ†æ”¯å¹¶è¡Œæ€§å’Œåºåˆ—å¹¶è¡Œæ€§ã€‚</li>
<li>é€šè¿‡æ•´åˆè¿™ä¸¤ç§å¹¶è¡Œæ€§æ–¹æ³•ï¼Œæˆ‘ä»¬èƒ½æœ‰æ•ˆåœ°é™ä½æ¨¡å‹æ¨ç†çš„å»¶è¿Ÿã€‚</li>
<li>åœ¨å»¶è¿Ÿæ•æ„Ÿçš„åœºæ™¯ä¸­ï¼Œä¼˜åŒ–åçš„TTSèƒ½åœ¨ä¿æŒé«˜å‡†ç¡®ç‡çš„åŒæ—¶ï¼Œæ˜¾è‘—æé«˜æ¨ç†é€Ÿåº¦ã€‚</li>
<li>è§„æ¨¡ä¸º32Bçš„æ¨¡å‹èƒ½åœ¨MATH-500æµ‹è¯•ä¸­è¾¾åˆ°82.3%çš„å‡†ç¡®ç‡ï¼Œå¹¶ä¸”åªéœ€ä¸€åˆ†é’Ÿå®Œæˆæ¨ç†ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.19634">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-e291fd4b53af90917de07d21498d1c34.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-235616815750083229d9ac47ab79bf1a.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-bc11049b2a067213003b77acf7e59eda.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-1fa7f64c34abc1a76feb38474c46ef11.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-1cb2ab025abe0288742ee07fedafd092.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-5c9a08d1815a39687e6ed039c7f59d70.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="ClonEval-An-Open-Voice-Cloning-Benchmark"><a href="#ClonEval-An-Open-Voice-Cloning-Benchmark" class="headerlink" title="ClonEval: An Open Voice Cloning Benchmark"></a>ClonEval: An Open Voice Cloning Benchmark</h2><p><strong>Authors:Iwona Christop, Tomasz KuczyÅ„ski, Marek Kubis</strong></p>
<p>We present a novel benchmark for voice cloning text-to-speech models. The benchmark consists of an evaluation protocol, an open-source library for assessing the performance of voice cloning models, and an accompanying leaderboard. The paper discusses design considerations and presents a detailed description of the evaluation procedure. The usage of the software library is explained, along with the organization of results on the leaderboard. </p>
<blockquote>
<p>æˆ‘ä»¬ä¸ºè¯­éŸ³å…‹éš†æ–‡æœ¬åˆ°è¯­éŸ³æ¨¡å‹æå‡ºä¸€ä¸ªæ–°çš„åŸºå‡†æµ‹è¯•ã€‚è¯¥åŸºå‡†æµ‹è¯•åŒ…æ‹¬è¯„ä¼°åè®®ã€è¯„ä¼°è¯­éŸ³å…‹éš†æ¨¡å‹æ€§èƒ½çš„å¼€æºåº“ä»¥åŠä¼´éšçš„æ’è¡Œæ¦œã€‚è®ºæ–‡è®¨è®ºäº†è®¾è®¡è€ƒè™‘å› ç´ ï¼Œå¹¶è¯¦ç»†ä»‹ç»äº†è¯„ä¼°æµç¨‹ã€‚åŒæ—¶è§£é‡Šäº†è½¯ä»¶åº“çš„ä½¿ç”¨ä»¥åŠæ’è¡Œæ¦œä¸Šç»“æœçš„ç»„ç»‡æƒ…å†µã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.20581v2">PDF</a> Under review at NeurIPS</p>
<p><strong>Summary</strong><br>     æœ¬æ–‡ä»‹ç»äº†ä¸€ä¸ªç”¨äºè¯­éŸ³å…‹éš†æ–‡æœ¬åˆ°è¯­éŸ³æ¨¡å‹çš„æ–°å‹åŸºå‡†æµ‹è¯•ã€‚è¯¥åŸºå‡†æµ‹è¯•åŒ…æ‹¬è¯„ä¼°åè®®ã€å¼€æºåº“ä»¥åŠæ’è¡Œæ¦œï¼Œç”¨ä»¥è¯„ä¼°è¯­éŸ³å…‹éš†æ¨¡å‹çš„æ€§èƒ½ã€‚æ–‡ç« è®¨è®ºäº†è®¾è®¡è€ƒé‡ï¼Œå¹¶è¯¦ç»†ä»‹ç»äº†è¯„ä¼°æµç¨‹ã€è½¯ä»¶åº“çš„ä½¿ç”¨åŠç»“æœå±•ç¤ºæ–¹å¼ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ä»‹ç»äº†æ–°å‹çš„è¯­éŸ³å…‹éš†æ–‡æœ¬åˆ°è¯­éŸ³æ¨¡å‹åŸºå‡†æµ‹è¯•ï¼ŒåŒ…æ‹¬è¯„ä¼°åè®®å’Œå¼€æºåº“ã€‚</li>
<li>è¯¥åŸºå‡†æµ‹è¯•æä¾›äº†è¯„ä¼°è¯­éŸ³å…‹éš†æ¨¡å‹çš„æ€§èƒ½çš„å·¥å…·å’Œæ’è¡Œæ¦œã€‚</li>
<li>æ–‡ç« è®¨è®ºäº†è®¾è®¡è¯¥åŸºå‡†æµ‹è¯•æ—¶çš„è€ƒé‡å› ç´ ã€‚</li>
<li>è¯¦ç»†ä»‹ç»äº†è¯„ä¼°æµç¨‹çš„å…·ä½“æ­¥éª¤å’Œæ–¹æ³•ã€‚</li>
<li>è¯´æ˜äº†å¦‚ä½•ä½¿ç”¨å¼€æºåº“è¿›è¡Œæ¨¡å‹æ€§èƒ½çš„è¯„ä¼°ã€‚</li>
<li>æ–‡ç« è§£é‡Šäº†ç»“æœå±•ç¤ºçš„æ–¹å¼å’Œç»„ç»‡å½¢å¼ã€‚</li>
<li>æ­¤åŸºå‡†æµ‹è¯•å¯¹äºæå‡è¯­éŸ³å…‹éš†æ¨¡å‹çš„æ€§èƒ½å…·æœ‰é‡è¦çš„ä½œç”¨ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.20581">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-f21c079d59ae89a642d17ca069316342.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-4466c9a4d0a7a1f49633879933036587.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f588c699e20cf3e115cf5afff3fa0feb.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d44c465d993c71a26ea102c782838395.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-681bbf31dfb1895bc2f4f7e49e703c96.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="GOAT-TTS-Expressive-and-Realistic-Speech-Generation-via-A-Dual-Branch-LLM"><a href="#GOAT-TTS-Expressive-and-Realistic-Speech-Generation-via-A-Dual-Branch-LLM" class="headerlink" title="GOAT-TTS: Expressive and Realistic Speech Generation via A Dual-Branch   LLM"></a>GOAT-TTS: Expressive and Realistic Speech Generation via A Dual-Branch   LLM</h2><p><strong>Authors:Yaodong Song, Hongjie Chen, Jie Lian, Yuxin Zhang, Guangmin Xia, Zehan Li, Genliang Zhao, Jian Kang, Jie Li, Yongxiang Li, Xuelong Li</strong></p>
<p>While large language models (LLMs) have revolutionized text-to-speech (TTS) synthesis through discrete tokenization paradigms, current architectures exhibit fundamental tensions between three critical dimensions: 1) irreversible loss of acoustic characteristics caused by quantization of speech prompts; 2) stringent dependence on precisely aligned prompt speech-text pairs that limit real-world deployment; and 3) catastrophic forgetting of the LLMâ€™s native text comprehension during optimization for speech token generation. To address these challenges, we propose an LLM-based text-to-speech Generation approach Optimized via a novel dual-branch ArchiTecture (GOAT-TTS). Our framework introduces two key innovations: (1) The modality-alignment branch combines a speech encoder and projector to capture continuous acoustic embeddings, enabling bidirectional correlation between paralinguistic features (language, timbre, emotion) and semantic text representations without transcript dependency; (2) The speech-generation branch employs modular fine-tuning on top-k layers of an LLM for speech token prediction while freezing the bottom-n layers to preserve foundational linguistic knowledge. Moreover, multi-token prediction is introduced to support real-time streaming TTS synthesis. Experimental results demonstrate that our GOAT-TTS achieves performance comparable to state-of-the-art TTS models while validating the efficacy of synthesized dialect speech data. </p>
<blockquote>
<p>è™½ç„¶å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰é€šè¿‡ç¦»æ•£æ ‡è®°åŒ–èŒƒå¼åœ¨æ–‡æœ¬åˆ°è¯­éŸ³ï¼ˆTTSï¼‰åˆæˆé¢†åŸŸå¸¦æ¥äº†é©å‘½æ€§çš„å˜é©ï¼Œä½†å½“å‰æ¶æ„åœ¨ä¸‰ä¸ªå…³é”®ç»´åº¦ä¹‹é—´è¡¨ç°å‡ºåŸºæœ¬çŸ›ç›¾ï¼š1ï¼‰ç”±äºè¯­éŸ³æç¤ºçš„é‡åŒ–è€Œå¯¼è‡´çš„ä¸å¯é€†çš„å£°å­¦ç‰¹å¾æŸå¤±ï¼›2ï¼‰ä¸¥æ ¼ä¾èµ–äºç²¾ç¡®å¯¹é½çš„è¯­éŸ³æ–‡æœ¬å¯¹ï¼Œé™åˆ¶äº†å…¶åœ¨ç°å®ä¸–ç•Œçš„éƒ¨ç½²ï¼›3ï¼‰åœ¨ä¼˜åŒ–è¯­éŸ³æ ‡è®°ç”Ÿæˆè¿‡ç¨‹ä¸­ï¼ŒLLMå¯¹åŸç”Ÿæ–‡æœ¬ç†è§£èƒ½åŠ›çš„ç¾éš¾æ€§é—å¿˜ã€‚ä¸ºäº†åº”å¯¹è¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åŸºäºLLMçš„æ–‡æœ¬åˆ°è¯­éŸ³ç”Ÿæˆæ–¹æ³•ï¼Œé€šè¿‡ä¸€ç§æ–°çš„åŒåˆ†æ”¯æ¶æ„ï¼ˆGOAT-TTSï¼‰è¿›è¡Œä¼˜åŒ–ã€‚æˆ‘ä»¬çš„æ¡†æ¶å¼•å…¥äº†ä¸¤ä¸ªå…³é”®åˆ›æ–°ç‚¹ï¼šï¼ˆ1ï¼‰æ¨¡æ€å¯¹é½åˆ†æ”¯ç»“åˆäº†è¯­éŸ³ç¼–ç å™¨å’ŒæŠ•å½±ä»ªæ¥æ•è·è¿ç»­çš„å£°å­¦åµŒå…¥ï¼Œå®ç°äº†å‰¯è¯­è¨€ç‰¹å¾ï¼ˆè¯­è¨€ã€éŸ³è‰²ã€æƒ…æ„Ÿï¼‰å’Œè¯­ä¹‰æ–‡æœ¬è¡¨ç¤ºä¹‹é—´çš„åŒå‘å…³è”ï¼Œæ— éœ€è½¬å½•ä¾èµ–ï¼›ï¼ˆ2ï¼‰è¯­éŸ³ç”Ÿæˆåˆ†æ”¯é‡‡ç”¨æ¨¡å—åŒ–å¾®è°ƒï¼Œå¯¹LLMçš„å‰kå±‚è¿›è¡Œè¯­éŸ³æ ‡è®°é¢„æµ‹ï¼ŒåŒæ—¶å†»ç»“åº•éƒ¨nå±‚ä»¥ä¿æŒåŸºç¡€è¯­è¨€çŸ¥è¯†ã€‚æ­¤å¤–ï¼Œè¿˜å¼•å…¥äº†å¤šæ ‡è®°é¢„æµ‹ï¼Œä»¥æ”¯æŒå®æ—¶æµå¼TTSåˆæˆã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„GOAT-TTSåœ¨è¾¾åˆ°æœ€æ–°TTSæ¨¡å‹æ€§èƒ½çš„åŒæ—¶ï¼ŒéªŒè¯äº†åˆæˆæ–¹è¨€è¯­éŸ³æ•°æ®çš„æœ‰æ•ˆæ€§ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.12339v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„æ–‡æœ¬åˆ°è¯­éŸ³ï¼ˆTTSï¼‰åˆæˆæ–¹æ³•å·²ç»å–å¾—äº†æ˜¾è‘—è¿›å±•ã€‚ç„¶è€Œï¼Œå½“å‰æ¶æ„åœ¨ä¸‰ä¸ªå…³é”®æ–¹é¢å­˜åœ¨åŸºæœ¬çŸ›ç›¾ã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªä¼˜åŒ–çš„åŒåˆ†æ”¯æ¶æ„ï¼ˆGOAT-TTSï¼‰ã€‚è¯¥æ¡†æ¶åŒ…æ‹¬ä¸¤ä¸ªå…³é”®åˆ›æ–°ç‚¹ï¼šæ¨¡æ€å¯¹é½åˆ†æ”¯å’Œè¯­éŸ³ç”Ÿæˆåˆ†æ”¯ã€‚é€šè¿‡æ¨¡æ€å¯¹é½åˆ†æ”¯å®ç°æ— å­—å¹•ä¾èµ–çš„è·¨è¯­è¨€ç‰¹å¾åŒå‘å…³è”ï¼›é€šè¿‡è¯­éŸ³ç”Ÿæˆåˆ†æ”¯å¯¹LLMè¿›è¡Œæ¨¡å—åŒ–å¾®è°ƒä»¥å®ç°è¯­éŸ³ä»¤ç‰Œé¢„æµ‹ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒGOAT-TTSæ€§èƒ½å¯ä¸æœ€æ–°TTSæ¨¡å‹ç›¸æ¯”ï¼Œå¹¶éªŒè¯äº†åˆæˆæ–¹è¨€è¯­éŸ³æ•°æ®çš„æœ‰æ•ˆæ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨æ–‡æœ¬åˆ°è¯­éŸ³ï¼ˆTTSï¼‰åˆæˆä¸­å·²æœ‰æ˜¾è‘—è¿›å±•ï¼Œä½†ä»å­˜åœ¨ä¸‰å¤§æŒ‘æˆ˜ã€‚</li>
<li>ç°æœ‰æ¶æ„åœ¨é‡åŒ–è¯­éŸ³æç¤ºæ—¶ä¼šå¯¼è‡´ä¸å¯é€†çš„å£°å­¦ç‰¹å¾æŸå¤±ã€‚</li>
<li>ç²¾ç¡®çš„è¯­éŸ³-æ–‡æœ¬é…å¯¹é™åˆ¶äº†ç°å®ä¸–ç•Œçš„éƒ¨ç½²åº”ç”¨ã€‚</li>
<li>åœ¨ä¼˜åŒ–è¯­éŸ³ä»¤ç‰Œç”Ÿæˆè¿‡ç¨‹ä¸­ï¼ŒLLMä¼šé—å¿˜å…¶åŸæœ‰çš„æ–‡æœ¬ç†è§£èƒ½åŠ›ã€‚</li>
<li>GOAT-TTSæ¡†æ¶é€šè¿‡æ¨¡æ€å¯¹é½åˆ†æ”¯å®ç°äº†è·¨è¯­è¨€ç‰¹å¾çš„åŒå‘å…³è”ï¼Œæ— éœ€å­—å¹•ä¾èµ–ã€‚</li>
<li>GOAT-TTSæ¡†æ¶é€šè¿‡è¯­éŸ³ç”Ÿæˆåˆ†æ”¯å¯¹LLMè¿›è¡Œæ¨¡å—åŒ–å¾®è°ƒï¼Œä»¥æ”¯æŒå®æ—¶æµå¼ä¼ è¾“TTSåˆæˆã€‚</li>
<li>å®éªŒç»“æœè¡¨æ˜GOAT-TTSæ€§èƒ½ä¸æœ€æ–°TTSæ¨¡å‹ç›¸å½“ï¼Œå¹¶èƒ½æœ‰æ•ˆåˆæˆæ–¹è¨€è¯­éŸ³æ•°æ®ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.12339">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-ece75d2f0eeb436e5ad914455b47bc03.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-f34f2c4d8edab85c0cf5c33d19d59846.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-fe1384de69f524679eb319e8e902826e.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-dc9b90b6d0c199f1919fb1a047f39314.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-f7776e022a5ff5d5e18015ed415f82d2.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-71c4f455520eb725343096bf1cba2ddb.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="Zero-Shot-Mono-to-Binaural-Speech-Synthesis"><a href="#Zero-Shot-Mono-to-Binaural-Speech-Synthesis" class="headerlink" title="Zero-Shot Mono-to-Binaural Speech Synthesis"></a>Zero-Shot Mono-to-Binaural Speech Synthesis</h2><p><strong>Authors:Alon Levkovitch, Julian Salazar, Soroosh Mariooryad, RJ Skerry-Ryan, Nadav Bar, Bastiaan Kleijn, Eliya Nachmani</strong></p>
<p>We present ZeroBAS, a neural method to synthesize binaural audio from monaural audio recordings and positional information without training on any binaural data. To our knowledge, this is the first published zero-shot neural approach to mono-to-binaural audio synthesis. Specifically, we show that a parameter-free geometric time warping and amplitude scaling based on source location suffices to get an initial binaural synthesis that can be refined by iteratively applying a pretrained denoising vocoder. Furthermore, we find this leads to generalization across room conditions, which we measure by introducing a new dataset, TUT Mono-to-Binaural, to evaluate state-of-the-art monaural-to-binaural synthesis methods on unseen conditions. Our zero-shot method is perceptually on-par with the performance of supervised methods on the standard mono-to-binaural dataset, and even surpasses them on our out-of-distribution TUT Mono-to-Binaural dataset. Our results highlight the potential of pretrained generative audio models and zero-shot learning to unlock robust binaural audio synthesis. </p>
<blockquote>
<p>æˆ‘ä»¬æå‡ºäº†ZeroBASæ–¹æ³•ï¼Œè¿™æ˜¯ä¸€ç§ä»å•å£°é“éŸ³é¢‘å½•åˆ¶å’Œä½ç½®ä¿¡æ¯åˆæˆåŒå£°é“éŸ³é¢‘çš„ç¥ç»æ–¹æ³•ï¼Œæ— éœ€åœ¨ä»»ä½•åŒå£°é“æ•°æ®ä¸Šè¿›è¡Œè®­ç»ƒã€‚æ®æˆ‘ä»¬æ‰€çŸ¥ï¼Œè¿™æ˜¯é¦–æ¬¡å‘å¸ƒçš„ä»é›¶å¼€å§‹å­¦ä¹ å•å£°é“åˆ°åŒå£°é“éŸ³é¢‘åˆæˆçš„ç¥ç»æ–¹æ³•ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬å±•ç¤ºäº†åŸºäºæºä½ç½®çš„å‚æ•°åŒ–å‡ ä½•æ—¶é—´æ‰­æ›²å’ŒæŒ¯å¹…ç¼©æ”¾è¶³ä»¥è·å¾—åˆæ­¥çš„åŒå£°é“åˆæˆï¼Œå¯ä»¥é€šè¿‡è¿­ä»£åº”ç”¨é¢„è®­ç»ƒçš„é™å™ªç¼–ç å™¨è¿›è¡Œæ”¹è¿›ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å‘ç°è¿™å¯¼è‡´äº†è·¨æˆ¿é—´æ¡ä»¶çš„æ³›åŒ–ï¼Œæˆ‘ä»¬é€šè¿‡å¼•å…¥ä¸€ä¸ªæ–°çš„æ•°æ®é›†TUT Mono-to-Binauralæ¥è¡¡é‡è¿™ä¸€ç‚¹ï¼Œä»¥è¯„ä¼°æœ€å…ˆè¿›çš„å•å£°é“åˆ°åŒå£°é“åˆæˆæ–¹æ³•åœ¨æœªè§æ¡ä»¶ä¸‹çš„è¡¨ç°ã€‚æˆ‘ä»¬çš„é›¶æ ·æœ¬æ–¹æ³•ä¸æ ‡å‡†å•å£°é“åˆ°åŒå£°é“æ•°æ®é›†ä¸Šçš„æœ‰ç›‘ç£æ–¹æ³•åœ¨æ„ŸçŸ¥ä¸Šè¡¨ç°ç›¸å½“ï¼Œç”šè‡³åœ¨æˆ‘ä»¬çš„ç¦»ç¾¤TUT Mono-to-Binauralæ•°æ®é›†ä¸Šè¶…è¿‡äº†å®ƒä»¬ã€‚æˆ‘ä»¬çš„ç»“æœçªæ˜¾äº†é¢„è®­ç»ƒçš„ç”ŸæˆéŸ³é¢‘æ¨¡å‹å’Œé›¶æ ·æœ¬å­¦ä¹ åœ¨è§£é”ç¨³å¥çš„åŒå£°é“éŸ³é¢‘åˆæˆæ–¹é¢çš„æ½œåŠ›ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.08356v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æ— éœ€è®­ç»ƒå³å¯åˆæˆåŒè€³éŸ³é¢‘çš„æ–°ç¥ç»ç½‘ç»œæ–¹æ³•ZeroBASã€‚åŸºäºé›¶æ•°æ®å­¦ä¹ å’Œç°æœ‰ç”ŸæˆéŸ³é¢‘æ¨¡å‹æŠ€æœ¯ï¼Œå°†å•å£°é“éŸ³é¢‘è½¬æ¢ä¸ºåŒè€³éŸ³é¢‘ï¼Œä»…ä½¿ç”¨ä½ç½®ä¿¡æ¯ã€‚é€šè¿‡å‡ ä½•æ—¶é—´æ‰­æ›²å’ŒåŸºäºæºä½ç½®çš„æŒ¯å¹…ç¼©æ”¾å®ç°åˆæ­¥çš„åŒè€³åˆæˆï¼Œå†è¿­ä»£åº”ç”¨é¢„è®­ç»ƒçš„é™å™ªç¼–è§£ç å™¨è¿›è¡Œå®Œå–„ã€‚åœ¨æœªè§æ¡ä»¶ä¸‹çš„æ–°æ•°æ®é›†TUT Mono-to-Binauralä¸Šæµ‹è¯•ï¼Œé›¶æ ·æœ¬æ–¹æ³•æ€§èƒ½ä¸æ ‡å‡†å•å£°é“åˆ°åŒè€³éŸ³é¢‘åˆæˆæ•°æ®é›†ä¸Šçš„ç›‘ç£æ–¹æ³•ç›¸å½“ï¼Œç”šè‡³è¶…å‡ºå…¶è¡¨ç°ã€‚çªæ˜¾äº†é¢„è®­ç»ƒç”ŸæˆéŸ³é¢‘æ¨¡å‹å’Œé›¶æ ·æœ¬å­¦ä¹ çš„æ½œåŠ›ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æ— éœ€è®­ç»ƒå³å¯åˆæˆåŒè€³éŸ³é¢‘çš„æ–°ç¥ç»ç½‘ç»œæ–¹æ³•ZeroBASè¢«æå‡ºã€‚</li>
<li>åŸºäºé›¶æ•°æ®å­¦ä¹ å’Œç°æœ‰ç”ŸæˆéŸ³é¢‘æ¨¡å‹æŠ€æœ¯å®ç°å•å£°é“åˆ°åŒè€³éŸ³é¢‘çš„è½¬æ¢ã€‚</li>
<li>é€šè¿‡å‡ ä½•æ—¶é—´æ‰­æ›²å’ŒåŸºäºæºä½ç½®çš„æŒ¯å¹…ç¼©æ”¾å®ç°åˆæ­¥çš„åŒè€³åˆæˆã€‚</li>
<li>ä½¿ç”¨é¢„è®­ç»ƒçš„é™å™ªç¼–è§£ç å™¨å¯¹åˆæ­¥åˆæˆç»“æœè¿›è¡Œå®Œå–„ã€‚</li>
<li>åœ¨æœªè§æ¡ä»¶ä¸‹çš„æ–°æ•°æ®é›†TUT Mono-to-Binauralä¸Šè¿›è¡Œæµ‹è¯•ï¼ŒéªŒè¯äº†æ–¹æ³•çš„æ³›åŒ–èƒ½åŠ›ã€‚</li>
<li>é›¶æ ·æœ¬æ–¹æ³•åœ¨æ ‡å‡†æ•°æ®é›†ä¸Šçš„æ€§èƒ½ä¸ç›‘ç£æ–¹æ³•ç›¸å½“ï¼Œç”šè‡³åœ¨æœªè§æ¡ä»¶ä¸‹è¶…å‡ºå…¶è¡¨ç°ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.08356">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-4148be2f2fcbb735e45655624763a501.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-89e424c252c3689826fd886f28bbee6f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-9a11daf01d2014a55ab9323e1c582579.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-2c95350f658f15e67b5a0b6c51212ece.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="VQ-CTAP-Cross-Modal-Fine-Grained-Sequence-Representation-Learning-for-Speech-Processing"><a href="#VQ-CTAP-Cross-Modal-Fine-Grained-Sequence-Representation-Learning-for-Speech-Processing" class="headerlink" title="VQ-CTAP: Cross-Modal Fine-Grained Sequence Representation Learning for   Speech Processing"></a>VQ-CTAP: Cross-Modal Fine-Grained Sequence Representation Learning for   Speech Processing</h2><p><strong>Authors:Chunyu Qiang, Wang Geng, Yi Zhao, Ruibo Fu, Tao Wang, Cheng Gong, Tianrui Wang, Qiuyu Liu, Jiangyan Yi, Zhengqi Wen, Chen Zhang, Hao Che, Longbiao Wang, Jianwu Dang, Jianhua Tao</strong></p>
<p>Deep learning has brought significant improvements to the field of cross-modal representation learning. For tasks such as text-to-speech (TTS), voice conversion (VC), and automatic speech recognition (ASR), a cross-modal fine-grained (frame-level) sequence representation is desired, emphasizing the semantic content of the text modality while de-emphasizing the paralinguistic information of the speech modality. We propose a method called â€œVector Quantized Contrastive Token-Acoustic Pre-training (VQ-CTAP)â€, which uses the cross-modal aligned sequence transcoder to bring text and speech into a joint multimodal space, learning how to connect text and speech at the frame level. The proposed VQ-CTAP is a paradigm for cross-modal sequence representation learning, offering a promising solution for fine-grained generation and recognition tasks in speech processing. The VQ-CTAP can be directly applied to VC and ASR tasks without fine-tuning or additional structures. We propose a sequence-aware semantic connector, which connects multiple frozen pre-trained modules for the TTS task, exhibiting a plug-and-play capability. We design a stepping optimization strategy to ensure effective model convergence by gradually injecting and adjusting the influence of various loss components. Furthermore, we propose a semantic-transfer-wise paralinguistic consistency loss to enhance representational capabilities, allowing the model to better generalize to unseen data and capture the nuances of paralinguistic information. In addition, VQ-CTAP achieves high-compression speech coding at a rate of 25Hz from 24kHz input waveforms, which is a 960-fold reduction in the sampling rate. The audio demo is available at <a target="_blank" rel="noopener" href="https://qiangchunyu.github.io/VQCTAP/">https://qiangchunyu.github.io/VQCTAP/</a> </p>
<blockquote>
<p>æ·±åº¦å­¦ä¹ ä¸ºè·¨æ¨¡æ€è¡¨ç¤ºå­¦ä¹ é¢†åŸŸå¸¦æ¥äº†é‡å¤§æ”¹è¿›ã€‚å¯¹äºæ–‡æœ¬è½¬è¯­éŸ³ï¼ˆTTSï¼‰ã€è¯­éŸ³è½¬æ¢ï¼ˆVCï¼‰å’Œè‡ªåŠ¨è¯­éŸ³è¯†åˆ«ï¼ˆASRï¼‰ç­‰ä»»åŠ¡ï¼Œæˆ‘ä»¬æœŸæœ›å¾—åˆ°ä¸€ç§è·¨æ¨¡æ€ç²¾ç»†ï¼ˆå¸§çº§ï¼‰åºåˆ—è¡¨ç¤ºï¼Œå¼ºè°ƒæ–‡æœ¬æ¨¡æ€çš„è¯­ä¹‰å†…å®¹ï¼ŒåŒæ—¶æ·¡åŒ–è¯­éŸ³æ¨¡æ€çš„å‰¯è¯­è¨€ä¿¡æ¯ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§åä¸ºâ€œå‘é‡é‡åŒ–å¯¹æ¯”ä»¤ç‰Œå£°å­¦é¢„è®­ç»ƒï¼ˆVQ-CTAPï¼‰â€çš„æ–¹æ³•ï¼Œè¯¥æ–¹æ³•ä½¿ç”¨è·¨æ¨¡æ€å¯¹é½åºåˆ—è½¬ç å™¨å°†æ–‡æœ¬å’Œè¯­éŸ³å¸¦å…¥è”åˆå¤šæ¨¡æ€ç©ºé—´ï¼Œå­¦ä¹ å¦‚ä½•åœ¨å¸§çº§åˆ«è¿æ¥æ–‡æœ¬å’Œè¯­éŸ³ã€‚æå‡ºçš„VQ-CTAPæ˜¯è·¨æ¨¡æ€åºåˆ—è¡¨ç¤ºå­¦ä¹ çš„ä¸€ç§èŒƒå¼ï¼Œä¸ºè¯­éŸ³å¤„ç†ä¸­çš„ç²¾ç»†ç²’åº¦ç”Ÿæˆå’Œè¯†åˆ«ä»»åŠ¡æä¾›äº†æœ‰å‰æ™¯çš„è§£å†³æ–¹æ¡ˆã€‚VQ-CTAPå¯ç›´æ¥åº”ç”¨äºVCå’ŒASRä»»åŠ¡ï¼Œæ— éœ€å¾®è°ƒæˆ–é¢å¤–ç»“æ„ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§åºåˆ—æ„ŸçŸ¥è¯­ä¹‰è¿æ¥å™¨ï¼Œå®ƒå°†å¤šä¸ªå†»ç»“çš„é¢„è®­ç»ƒæ¨¡å—è¿æ¥åˆ°TTSä»»åŠ¡ä¸­ï¼Œå±•ç°å‡ºå³æ’å³ç”¨çš„èƒ½åŠ›ã€‚æˆ‘ä»¬è®¾è®¡äº†ä¸€ç§æ­¥è¿›ä¼˜åŒ–ç­–ç•¥ï¼Œé€šè¿‡é€æ­¥æ³¨å…¥å’Œè°ƒæ•´å„ç§æŸå¤±åˆ†é‡çš„å½±å“ï¼Œä»¥ç¡®ä¿æ¨¡å‹çš„æœ‰æ•ˆæ”¶æ•›ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§è¯­ä¹‰è½¬ç§»å‰¯è¯­è¨€ä¸€è‡´æ€§æŸå¤±ï¼Œä»¥å¢å¼ºè¡¨ç¤ºèƒ½åŠ›ï¼Œä½¿æ¨¡å‹èƒ½å¤Ÿæ›´å¥½åœ°æ¨å¹¿åˆ°æœªè§æ•°æ®å¹¶æ•æ‰å‰¯è¯­è¨€ä¿¡æ¯çš„ç»†å¾®å·®åˆ«ã€‚å¦å¤–ï¼ŒVQ-CTAPå®ç°äº†é«˜å‹ç¼©è¯­éŸ³ç¼–ç ï¼Œä»¥25Hzçš„é€Ÿç‡ä»24kHzè¾“å…¥æ³¢å½¢è¿›è¡Œç¼–ç ï¼Œé‡‡æ ·ç‡é™ä½äº†960å€ã€‚éŸ³é¢‘æ¼”ç¤ºå¯åœ¨<a target="_blank" rel="noopener" href="https://qiangchunyu.github.io/VQCTAP/%E8%BF%9B%E8%A1%8C%E6%9F%A5%E7%9C%8B%E3%80%82">https://qiangchunyu.github.io/VQCTAP/è¿›è¡ŒæŸ¥çœ‹ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2408.05758v2">PDF</a> </p>
<p><strong>æ‘˜è¦</strong><br>    æ·±åº¦å­¦ä¹ æå¤§æå‡äº†è·¨æ¨¡æ€è¡¨å¾å­¦ä¹ é¢†åŸŸçš„èƒ½åŠ›ï¼Œç‰¹åˆ«æ˜¯åœ¨æ–‡æœ¬è½¬è¯­éŸ³ï¼ˆTTSï¼‰ã€è¯­éŸ³è½¬æ¢ï¼ˆVCï¼‰å’Œè‡ªåŠ¨è¯­éŸ³è¯†åˆ«ï¼ˆASRï¼‰ç­‰ä»»åŠ¡ä¸­ã€‚æœ¬æ–‡æå‡ºä¸€ç§åä¸ºâ€œå‘é‡é‡åŒ–å¯¹æ¯”ä»¤ç‰Œå£°å­¦é¢„è®­ç»ƒï¼ˆVQ-CTAPï¼‰â€çš„æ–¹æ³•ï¼Œä½¿ç”¨è·¨æ¨¡æ€å¯¹é½åºåˆ—è½¬ç å™¨å°†æ–‡æœ¬å’Œè¯­éŸ³å¼•å…¥è”åˆå¤šæ¨¡æ€ç©ºé—´ï¼Œåœ¨å¸§çº§åˆ«è¿æ¥æ–‡æœ¬å’Œè¯­éŸ³ã€‚æ­¤æ–¹æ³•ä¸ºè·¨æ¨¡æ€åºåˆ—è¡¨å¾å­¦ä¹ æä¾›äº†æœ‰åŠ›è§£å†³æ–¹æ¡ˆï¼Œé€‚ç”¨äºç²¾ç»†ç²’åº¦çš„ç”Ÿæˆå’Œè¯†åˆ«ä»»åŠ¡ã€‚VQ-CTAPå¯ç›´æ¥åº”ç”¨äºVCå’ŒASRä»»åŠ¡ï¼Œæ— éœ€å¾®è°ƒæˆ–é¢å¤–ç»“æ„ã€‚è®¾è®¡åºåˆ—æ„ŸçŸ¥è¯­ä¹‰è¿æ¥å™¨ï¼Œä¸ºTTSä»»åŠ¡è¿æ¥å¤šä¸ªå†»ç»“çš„é¢„è®­ç»ƒæ¨¡å—ï¼Œå±•ç°å³æ’å³ç”¨èƒ½åŠ›ã€‚é€šè¿‡é€æ­¥ä¼˜åŒ–ç­–ç•¥ç¡®ä¿æ¨¡å‹æœ‰æ•ˆæ”¶æ•›ï¼ŒåŒæ—¶æå‡ºè¯­ä¹‰è½¬ç§»æ—è¯­ä¸€è‡´æ€§æŸå¤±ä»¥å¢å¼ºè¡¨å¾èƒ½åŠ›ï¼Œä½¿æ¨¡å‹æ›´å¥½åœ°æ³›åŒ–åˆ°æœªè§æ•°æ®å’Œæ•æ‰æ—è¯­ä¿¡æ¯çš„ç»†å¾®å·®åˆ«ã€‚æ­¤å¤–ï¼ŒVQ-CTAPå®ç°é«˜å‹ç¼©è¯­éŸ³ç¼–ç ï¼Œä»¥25Hzçš„é‡‡æ ·ç‡ä»24kHzè¾“å…¥æ³¢å½¢ï¼Œè¾¾åˆ°960å€çš„é‡‡æ ·ç‡é™ä½ã€‚</p>
<p><strong>å…³é”®è§è§£</strong></p>
<ol>
<li>æ·±åº¦å­¦ä¹ åœ¨è·¨æ¨¡æ€è¡¨å¾å­¦ä¹ é¢†åŸŸå–å¾—æ˜¾è‘—è¿›æ­¥ï¼Œå°¤å…¶åœ¨TTSã€VCå’ŒASRä»»åŠ¡ä¸­ã€‚</li>
<li>æå‡ºVQ-CTAPæ–¹æ³•ï¼Œä½¿ç”¨è·¨æ¨¡æ€å¯¹é½åºåˆ—è½¬ç å™¨åœ¨å¸§çº§åˆ«è¿æ¥æ–‡æœ¬å’Œè¯­éŸ³ã€‚</li>
<li>VQ-CTAPæ˜¯ä¸€ç§è·¨æ¨¡æ€åºåˆ—è¡¨å¾å­¦ä¹ çš„èŒƒå¼ï¼Œé€‚ç”¨äºç²¾ç»†ç²’åº¦çš„ç”Ÿæˆå’Œè¯†åˆ«ä»»åŠ¡ã€‚</li>
<li>VQ-CTAPå¯ç›´æ¥åº”ç”¨äºVCå’ŒASRä»»åŠ¡ï¼Œæ— éœ€é¢å¤–è°ƒæ•´æˆ–ç»“æ„ã€‚</li>
<li>è®¾è®¡åºåˆ—æ„ŸçŸ¥è¯­ä¹‰è¿æ¥å™¨ï¼Œå±•ç°å¯¹TTSä»»åŠ¡çš„å³æ’å³ç”¨èƒ½åŠ›ã€‚</li>
<li>é€šè¿‡é€æ­¥ä¼˜åŒ–ç­–ç•¥å’Œè¯­ä¹‰è½¬ç§»æ—è¯­ä¸€è‡´æ€§æŸå¤±æé«˜æ¨¡å‹æ•ˆèƒ½å’Œæ³›åŒ–èƒ½åŠ›ã€‚</li>
<li>VQ-CTAPå®ç°é«˜å‹ç¼©è¯­éŸ³ç¼–ç ï¼Œå¤§å¹…é™ä½é‡‡æ ·ç‡ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2408.05758">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-3b6370feb9110bfbbb3dfbeed3b9dabb.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-deac6e1246f33a95a531e19b52ca2cf4.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ba9ee7dcdedad1c0935aa97b057f44fb.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-8c4f1e3f74ca5f390c49bfa4ef9f5a7d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-1c6fce304b8432d8b73b31bde4d695f4.jpg" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-05-30/TTS/">https://kedreamix.github.io/Talk2Paper/Paper/2025-05-30/TTS/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/TTS/">
                                    <span class="chip bg-color">TTS</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-05-30/Interactive/">
                    <div class="card-image">
                        
                        <img src="https://pic1.zhimg.com/v2-7e3716546e46310ae6969f8875cfb7b4.jpg" class="responsive-img" alt="Interactive">
                        
                        <span class="card-title">Interactive</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Interactive æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-05-30  OmniResponse Online Multimodal Conversational Response Generation in   Dyadic Interactions
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-05-30
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Interactive/" class="post-category">
                                    Interactive
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Interactive/">
                        <span class="chip bg-color">Interactive</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-05-30/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-384e35f008881080ac4f07969a28155e.jpg" class="responsive-img" alt="åŒ»å­¦å›¾åƒ">
                        
                        <span class="card-title">åŒ»å­¦å›¾åƒ</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            åŒ»å­¦å›¾åƒ æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-05-30  Chest Disease Detection In X-Ray Images Using Deep Learning   Classification Method
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-05-30
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/" class="post-category">
                                    åŒ»å­¦å›¾åƒ
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/">
                        <span class="chip bg-color">åŒ»å­¦å›¾åƒ</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">25011.1k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
