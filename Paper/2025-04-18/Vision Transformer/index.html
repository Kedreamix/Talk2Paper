<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Vision Transformer">
    <meta name="description" content="Vision Transformer æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-04-18  Comparative Evaluation of Radiomics and Deep Learning Models for Disease   Detection in Chest Radiography">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>Vision Transformer | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://pic1.zhimg.com/v2-2bf5b49007c9a7fdf3dd56b63f6107ca.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Vision Transformer</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/Vision-Transformer/">
                                <span class="chip bg-color">Vision Transformer</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/Vision-Transformer/" class="post-category">
                                Vision Transformer
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-04-18
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-05-14
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    6.6k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    27 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-04-18-æ›´æ–°"><a href="#2025-04-18-æ›´æ–°" class="headerlink" title="2025-04-18 æ›´æ–°"></a>2025-04-18 æ›´æ–°</h1><h2 id="Comparative-Evaluation-of-Radiomics-and-Deep-Learning-Models-for-Disease-Detection-in-Chest-Radiography"><a href="#Comparative-Evaluation-of-Radiomics-and-Deep-Learning-Models-for-Disease-Detection-in-Chest-Radiography" class="headerlink" title="Comparative Evaluation of Radiomics and Deep Learning Models for Disease   Detection in Chest Radiography"></a>Comparative Evaluation of Radiomics and Deep Learning Models for Disease   Detection in Chest Radiography</h2><p><strong>Authors:Zhijin He, Alan B. McMillan</strong></p>
<p>The application of artificial intelligence (AI) in medical imaging has revolutionized diagnostic practices, enabling advanced analysis and interpretation of radiological data. This study presents a comprehensive evaluation of radiomics-based and deep learning-based approaches for disease detection in chest radiography, focusing on COVID-19, lung opacity, and viral pneumonia. While deep learning models, particularly convolutional neural networks (CNNs) and vision transformers (ViTs), learn directly from image data, radiomics-based models extract and analyze quantitative features, potentially providing advantages in data-limited scenarios. This study systematically compares the diagnostic accuracy and robustness of various AI models, including Decision Trees, Gradient Boosting, Random Forests, Support Vector Machines (SVM), and Multi-Layer Perceptrons (MLP) for radiomics, against state-of-the-art computer vision deep learning architectures. Performance metrics across varying sample sizes reveal insights into each modelâ€™s efficacy, highlighting the contexts in which specific AI approaches may offer enhanced diagnostic capabilities. The results aim to inform the integration of AI-driven diagnostic tools in clinical practice, particularly in automated and high-throughput environments where timely, reliable diagnosis is critical. This comparative study addresses an essential gap, establishing guidance for the selection of AI models based on clinical and operational needs. </p>
<blockquote>
<p>äººå·¥æ™ºèƒ½ï¼ˆAIï¼‰åœ¨åŒ»å­¦å½±åƒé¢†åŸŸçš„åº”ç”¨å·²ç»å½»åº•æ”¹å˜äº†è¯Šæ–­å®è·µï¼Œä½¿æ”¾å°„å­¦æ•°æ®çš„å…ˆè¿›åˆ†æå’Œè§£é‡Šæˆä¸ºå¯èƒ½ã€‚æœ¬ç ”ç©¶å…¨é¢è¯„ä¼°äº†åŸºäºæ”¾å°„ç»„å­¦å’ŒåŸºäºæ·±åº¦å­¦ä¹ çš„æ–¹æ³•åœ¨èƒ¸éƒ¨æ”¾å°„æ‘„å½±ä¸­æ£€æµ‹ç–¾ç—…çš„æ€§èƒ½ï¼Œé‡ç‚¹å…³æ³¨COVID-19ã€è‚ºéƒ¨ä¸é€æ˜å’Œç—…æ¯’æ€§è‚ºç‚ã€‚æ·±åº¦å­¦ä¹ æ¨¡å‹ï¼Œç‰¹åˆ«æ˜¯å·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNï¼‰å’Œè§†è§‰å˜å‹å™¨ï¼ˆViTï¼‰ï¼Œç›´æ¥ä»å›¾åƒæ•°æ®ä¸­å­¦ä¹ ï¼Œè€ŒåŸºäºæ”¾å°„ç»„å­¦çš„æ¨¡å‹åˆ™æå–å¹¶åˆ†æå®šé‡ç‰¹å¾ï¼Œåœ¨æ•°æ®æœ‰é™çš„åœºæ™¯ä¸­å¯èƒ½å…·æœ‰æ½œåœ¨ä¼˜åŠ¿ã€‚æœ¬ç ”ç©¶ç³»ç»Ÿåœ°æ¯”è¾ƒäº†å„ç§AIæ¨¡å‹çš„è¯Šæ–­å‡†ç¡®æ€§å’Œç¨³å¥æ€§ï¼ŒåŒ…æ‹¬ç”¨äºæ”¾å°„ç»„å­¦çš„å†³ç­–æ ‘ã€æ¢¯åº¦æå‡ã€éšæœºæ£®æ—ã€æ”¯æŒå‘é‡æœºï¼ˆSVMï¼‰å’Œå¤šå±‚æ„ŸçŸ¥å™¨ï¼ˆMLPï¼‰ä¸æœ€å…ˆè¿›çš„è®¡ç®—æœºè§†è§‰æ·±åº¦å­¦ä¹ æ¶æ„ä¹‹é—´çš„æ¯”è¾ƒã€‚ä¸åŒæ ·æœ¬é‡ä¸‹çš„æ€§èƒ½æŒ‡æ ‡æ­ç¤ºäº†æ¯ç§æ¨¡å‹çš„æœ‰æ•ˆæ€§ï¼Œçªå‡ºäº†ç‰¹å®šAIæ–¹æ³•å¯èƒ½åœ¨å“ªäº›æƒ…å†µä¸‹æä¾›å¢å¼ºçš„è¯Šæ–­èƒ½åŠ›ã€‚ç ”ç©¶ç»“æœæ—¨åœ¨ä¸ºAIé©±åŠ¨çš„è¯Šæ–­å·¥å…·åœ¨ä¸´åºŠå®è·µä¸­çš„æ•´åˆæä¾›ä¿¡æ¯ï¼Œç‰¹åˆ«æ˜¯åœ¨åŠæ—¶å¯é çš„è¯Šæ–­è‡³å…³é‡è¦çš„è‡ªåŠ¨åŒ–å’Œé«˜é€šé‡ç¯å¢ƒä¸­ã€‚è¿™é¡¹æ¯”è¾ƒç ”ç©¶è§£å†³äº†é‡è¦çš„é—®é¢˜ï¼Œæ ¹æ®ä¸´åºŠå’Œè¿è¥éœ€æ±‚ä¸ºé€‰æ‹©AIæ¨¡å‹æä¾›äº†æŒ‡å¯¼ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.12249v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>äººå·¥æ™ºèƒ½åœ¨åŒ»å­¦å½±åƒé¢†åŸŸçš„åº”ç”¨å·²ç»å½»åº•æ”¹å˜äº†è¯Šæ–­å®è·µï¼Œä¿ƒè¿›äº†å¯¹æ”¾å°„æ•°æ®çš„æ·±å…¥åˆ†æå’Œè§£è¯»ã€‚æœ¬ç ”ç©¶å…¨é¢è¯„ä¼°äº†åŸºäºæ”¾å°„ç»„å­¦å’Œæ·±åº¦å­¦ä¹ çš„æ–¹æ³•åœ¨èƒ¸éƒ¨æ”¾å°„æ‘„å½±ä¸­ç–¾ç—…æ£€æµ‹çš„è¡¨ç°ï¼Œé‡ç‚¹ç ”ç©¶COVID-19ã€è‚ºéƒ¨ä¸é€æ˜åº¦å’Œç—…æ¯’æ€§è‚ºç‚ã€‚æ·±åº¦å­¦ä¹ æ¨¡å‹ï¼Œå°¤å…¶æ˜¯å·ç§¯ç¥ç»ç½‘ç»œå’Œè§†è§‰è½¬æ¢å™¨ï¼Œç›´æ¥ä»å›¾åƒæ•°æ®ä¸­å­¦ä¹ ï¼›è€ŒåŸºäºæ”¾å°„ç»„å­¦çš„æ¨¡å‹åˆ™æå–å’Œåˆ†æå®šé‡ç‰¹å¾ï¼Œå¯èƒ½åœ¨æ•°æ®æœ‰é™çš„åœºæ™¯ä¸­æä¾›ä¼˜åŠ¿ã€‚æœ¬ç ”ç©¶ç³»ç»Ÿåœ°æ¯”è¾ƒäº†å„ç§äººå·¥æ™ºèƒ½æ¨¡å‹çš„è¯Šæ–­å‡†ç¡®æ€§å’Œç¨³å¥æ€§ï¼ŒåŒ…æ‹¬å†³ç­–æ ‘ã€æ¢¯åº¦æå‡ã€éšæœºæ£®æ—ã€æ”¯æŒå‘é‡æœºå’Œå¤šå±‚æ„ŸçŸ¥å™¨ï¼ˆç”¨äºæ”¾å°„ç»„å­¦ï¼‰ï¼Œä»¥åŠæœ€å…ˆè¿›çš„è®¡ç®—æœºè§†è§‰æ·±åº¦å­¦ä¹ æ¶æ„ã€‚ä¸åŒæ ·æœ¬é‡ä¸‹çš„æ€§èƒ½æŒ‡æ ‡æ­ç¤ºäº†æ¯ç§æ¨¡å‹çš„æœ‰æ•ˆæ€§ï¼Œå¹¶çªå‡ºäº†ç‰¹å®šäººå·¥æ™ºèƒ½æ–¹æ³•åœ¨å“ªäº›æƒ…å†µä¸‹å¯èƒ½æä¾›å¢å¼ºçš„è¯Šæ–­èƒ½åŠ›ã€‚ç ”ç©¶ç»“æœæ—¨åœ¨ä¸ºåœ¨ä¸´åºŠå®è·µä¸­æ•´åˆäººå·¥æ™ºèƒ½é©±åŠ¨çš„è¯Šæ–­å·¥å…·æä¾›ä¿¡æ¯ï¼Œç‰¹åˆ«æ˜¯åœ¨éœ€è¦åŠæ—¶å¯é è¯Šæ–­çš„è‡ªåŠ¨åŒ–å’Œé«˜é€šé‡ç¯å¢ƒä¸­ã€‚è¿™é¡¹æ¯”è¾ƒç ”ç©¶å¡«è¡¥äº†ä¸€ä¸ªé‡è¦ç©ºç™½ï¼Œæ ¹æ®ä¸´åºŠå’Œè¿è¥éœ€æ±‚æä¾›äº†é€‰æ‹©äººå·¥æ™ºèƒ½æ¨¡å‹çš„æŒ‡å¯¼ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>AIåœ¨åŒ»å­¦å½±åƒé¢†åŸŸçš„åº”ç”¨å·²ç»æ”¹å˜äº†è¯Šæ–­å®è·µï¼Œä¿ƒè¿›äº†æ”¾å°„æ•°æ®çš„æ·±å…¥åˆ†æã€‚</li>
<li>æœ¬ç ”ç©¶æ¯”è¾ƒäº†åŸºäºæ”¾å°„ç»„å­¦å’Œæ·±åº¦å­¦ä¹ çš„æ–¹æ³•åœ¨ç–¾ç—…æ£€æµ‹ä¸­çš„è¡¨ç°ï¼Œç‰¹åˆ«æ˜¯é’ˆå¯¹COVID-19ã€è‚ºéƒ¨ä¸é€æ˜åº¦å’Œç—…æ¯’æ€§è‚ºç‚ã€‚</li>
<li>æ·±åº¦å­¦ä¹ æ¨¡å‹ï¼Œç‰¹åˆ«æ˜¯å·ç§¯ç¥ç»ç½‘ç»œå’Œè§†è§‰è½¬æ¢å™¨ï¼Œç›´æ¥ä»å›¾åƒæ•°æ®ä¸­å­¦ä¹ ç‰¹å¾ã€‚</li>
<li>åŸºäºæ”¾å°„ç»„å­¦çš„æ¨¡å‹åœ¨æå–å’Œåˆ†æå®šé‡ç‰¹å¾æ–¹é¢å¯èƒ½å…·æœ‰ä¼˜åŠ¿ï¼Œå°¤å…¶åœ¨æ•°æ®æœ‰é™çš„åœºæ™¯ä¸­ã€‚</li>
<li>ç ”ç©¶é€šè¿‡æ¯”è¾ƒä¸åŒäººå·¥æ™ºèƒ½æ¨¡å‹çš„è¯Šæ–­å‡†ç¡®æ€§å’Œç¨³å¥æ€§ï¼ŒåŒ…æ‹¬å¤šç§ä¼ ç»Ÿæœºå™¨å­¦ä¹ æ–¹æ³•ä¸å…ˆè¿›çš„æ·±åº¦å­¦ä¹ æ¶æ„ã€‚</li>
<li>ä¸åŒæ ·æœ¬é‡ä¸‹çš„æ€§èƒ½æŒ‡æ ‡æ˜¾ç¤ºäº†å„ç§æ¨¡å‹çš„æœ‰æ•ˆæ€§ï¼Œå¹¶æŒ‡å‡ºç‰¹å®šAIæ–¹æ³•åœ¨ç‰¹å®šæƒ…å¢ƒä¸‹çš„ä¼˜åŠ¿ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.12249">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-da6ca1480f70c8211e78f91f28089bea.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="DC-SAM-In-Context-Segment-Anything-in-Images-and-Videos-via-Dual-Consistency"><a href="#DC-SAM-In-Context-Segment-Anything-in-Images-and-Videos-via-Dual-Consistency" class="headerlink" title="DC-SAM: In-Context Segment Anything in Images and Videos via Dual   Consistency"></a>DC-SAM: In-Context Segment Anything in Images and Videos via Dual   Consistency</h2><p><strong>Authors:Mengshi Qi, Pengfei Zhu, Xiangtai Li, Xiaoyang Bi, Lu Qi, Huadong Ma, Ming-Hsuan Yang</strong></p>
<p>Given a single labeled example, in-context segmentation aims to segment corresponding objects. This setting, known as one-shot segmentation in few-shot learning, explores the segmentation modelâ€™s generalization ability and has been applied to various vision tasks, including scene understanding and image&#x2F;video editing. While recent Segment Anything Models have achieved state-of-the-art results in interactive segmentation, these approaches are not directly applicable to in-context segmentation. In this work, we propose the Dual Consistency SAM (DC-SAM) method based on prompt-tuning to adapt SAM and SAM2 for in-context segmentation of both images and videos. Our key insights are to enhance the features of the SAMâ€™s prompt encoder in segmentation by providing high-quality visual prompts. When generating a mask prior, we fuse the SAM features to better align the prompt encoder. Then, we design a cycle-consistent cross-attention on fused features and initial visual prompts. Next, a dual-branch design is provided by using the discriminative positive and negative prompts in the prompt encoder. Furthermore, we design a simple mask-tube training strategy to adopt our proposed dual consistency method into the mask tube. Although the proposed DC-SAM is primarily designed for images, it can be seamlessly extended to the video domain with the support of SAM2. Given the absence of in-context segmentation in the video domain, we manually curate and construct the first benchmark from existing video segmentation datasets, named In-Context Video Object Segmentation (IC-VOS), to better assess the in-context capability of the model. Extensive experiments demonstrate that our method achieves 55.5 (+1.4) mIoU on COCO-20i, 73.0 (+1.1) mIoU on PASCAL-5i, and a J&amp;F score of 71.52 on the proposed IC-VOS benchmark. Our source code and benchmark are available at <a target="_blank" rel="noopener" href="https://github.com/zaplm/DC-SAM">https://github.com/zaplm/DC-SAM</a>. </p>
<blockquote>
<p>ç»™å®šå•ä¸ªæœ‰æ ‡ç­¾çš„æ ·æœ¬ï¼Œä¸Šä¸‹æ–‡åˆ†å‰²æ—¨åœ¨åˆ†å‰²å¯¹åº”çš„å¯¹è±¡ã€‚è¿™ç§è®¾ç½®è¢«ç§°ä¸ºå°æ ·æœ¬å­¦ä¹ ä¸­çš„ä¸€æ¬¡åˆ†å‰²ï¼Œå®ƒæ¢ç´¢äº†åˆ†å‰²æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ï¼Œå¹¶å·²åº”ç”¨äºå„ç§è§†è§‰ä»»åŠ¡ï¼ŒåŒ…æ‹¬åœºæ™¯ç†è§£ã€å›¾åƒ&#x2F;è§†é¢‘ç¼–è¾‘ç­‰ã€‚è™½ç„¶æœ€è¿‘çš„ä»»ä½•åˆ†å‰²æ¨¡å‹åœ¨äº¤äº’å¼åˆ†å‰²æ–¹é¢å–å¾—äº†æœ€æ–°ç»“æœï¼Œä½†è¿™äº›æ–¹æ³•å¹¶ä¸èƒ½ç›´æ¥åº”ç”¨äºä¸Šä¸‹æ–‡åˆ†å‰²ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†åŸºäºæç¤ºè°ƒæ•´çš„Dual Consistency SAMï¼ˆDC-SAMï¼‰æ–¹æ³•ï¼Œä»¥é€‚åº”å›¾åƒå’Œè§†é¢‘çš„ä¸Šä¸‹æ–‡åˆ†å‰²ã€‚æˆ‘ä»¬çš„å…³é”®è§è§£æ˜¯é€šè¿‡æä¾›é«˜è´¨é‡çš„è§†è§‰æç¤ºæ¥å¢å¼ºSAMæç¤ºç¼–ç å™¨åœ¨åˆ†å‰²ä¸­çš„åŠŸèƒ½ã€‚åœ¨ç”Ÿæˆæ©è†œå…ˆéªŒæ—¶ï¼Œæˆ‘ä»¬èåˆäº†SAMç‰¹å¾ä»¥æ›´å¥½åœ°å¯¹é½æç¤ºç¼–ç å™¨ã€‚ç„¶åï¼Œæˆ‘ä»¬åœ¨èåˆçš„ç‰¹å¾å’Œåˆå§‹è§†è§‰æç¤ºä¸Šè®¾è®¡äº†ä¸€ä¸ªå¾ªç¯ä¸€è‡´çš„äº¤å‰æ³¨æ„åŠ›ã€‚æ¥ä¸‹æ¥ï¼Œé€šè¿‡ä½¿ç”¨æç¤ºç¼–ç å™¨ä¸­çš„åˆ¤åˆ«æ€§æ­£å‘å’Œè´Ÿå‘æç¤ºï¼Œæä¾›äº†ä¸€ä¸ªåŒåˆ†æ”¯è®¾è®¡ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è®¾è®¡äº†ä¸€ä¸ªç®€å•çš„æ©è†œç®¡è®­ç»ƒç­–ç•¥ï¼Œå°†æˆ‘ä»¬æ‰€æå‡ºçš„åŒé‡ä¸€è‡´æ€§æ–¹æ³•åº”ç”¨äºæ©è†œç®¡ã€‚è™½ç„¶æå‡ºçš„DC-SAMä¸»è¦æ˜¯ä¸ºå›¾åƒè®¾è®¡çš„ï¼Œä½†å®ƒå¯ä»¥æ— ç¼åœ°æ‰©å±•åˆ°è§†é¢‘é¢†åŸŸï¼Œå¾—åˆ°SAM2çš„æ”¯æŒã€‚ç”±äºåœ¨è§†é¢‘é¢†åŸŸç¼ºä¹ä¸Šä¸‹æ–‡åˆ†å‰²ï¼Œæˆ‘ä»¬ä»ç°æœ‰çš„è§†é¢‘åˆ†å‰²æ•°æ®é›†ä¸­æ‰‹åŠ¨ç­›é€‰å’Œæ„å»ºäº†ç¬¬ä¸€ä¸ªåŸºå‡†æµ‹è¯•ï¼Œåä¸ºIn-Context Video Object Segmentationï¼ˆIC-VOSï¼‰ï¼Œä»¥æ›´å¥½åœ°è¯„ä¼°æ¨¡å‹çš„ä¸Šä¸‹æ–‡èƒ½åŠ›ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨COCO-20iä¸Šå®ç°äº†55.5ï¼ˆ+1.4ï¼‰çš„mIoUï¼Œåœ¨PASCAL-5iä¸Šå®ç°äº†73.0ï¼ˆ+1.1ï¼‰çš„mIoUï¼Œåœ¨æå‡ºçš„IC-VOSåŸºå‡†æµ‹è¯•ä¸Šè¾¾åˆ°äº†71.52çš„J&amp;Fåˆ†æ•°ã€‚æˆ‘ä»¬çš„æºä»£ç å’ŒåŸºå‡†æµ‹è¯•å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/zaplm/DC-SAM%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/zaplm/DC-SAMæ‰¾åˆ°ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.12080v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†ä¸€ç§åŸºäºæç¤ºè°ƒæ•´ï¼ˆprompt-tuningï¼‰çš„Dual Consistency SAMï¼ˆDC-SAMï¼‰æ–¹æ³•ï¼Œç”¨äºå®ç°åŸºäºå•ä¸ªç¤ºä¾‹çš„ä¸€é”®å¼ä¸Šä¸‹æ–‡æ„ŸçŸ¥åˆ†å‰²ã€‚æœ¬æ–‡é¦–æ¬¡å»ºç«‹äº†é€‚ç”¨äºè§†é¢‘çš„ä¸Šä¸‹æ–‡åˆ†å‰²è¯„ä¼°åŸºå‡†IC-VOSï¼Œå¹¶å±•ç¤ºäº†DC-SAMåœ¨å›¾åƒå’Œè§†é¢‘åˆ†å‰²ä»»åŠ¡ä¸Šçš„ä¼˜è¶Šæ€§èƒ½ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æ–‡ç« æå‡ºäº†åŸºäºæç¤ºè°ƒæ•´çš„Dual Consistency SAMï¼ˆDC-SAMï¼‰æ–¹æ³•ï¼Œç”¨äºå®ç°åŸºäºå•ä¸ªç¤ºä¾‹çš„ä¸Šä¸‹æ–‡æ„ŸçŸ¥åˆ†å‰²ã€‚</li>
<li>DC-SAMæ–¹æ³•é€šè¿‡å¢å¼ºSAMçš„æç¤ºç¼–ç å™¨ç‰¹å¾ï¼Œå¹¶ç»“åˆä½¿ç”¨é«˜è´¨é‡è§†è§‰æç¤ºï¼Œç”Ÿæˆé®ç½©å…ˆéªŒã€‚</li>
<li>æ–‡ç« è®¾è®¡äº†ä¸€ç§å¾ªç¯ä¸€è‡´çš„è·¨æ³¨æ„åŠ›æœºåˆ¶ï¼Œç”¨äºèåˆç‰¹å¾å’Œåˆå§‹è§†è§‰æç¤ºã€‚</li>
<li>é€šè¿‡é‡‡ç”¨åˆ¤åˆ«æ€§çš„æ­£è´Ÿæç¤ºï¼Œè®¾è®¡äº†ä¸€ç§åŒåˆ†æ”¯è®¾è®¡ï¼Œç”¨äºæç¤ºç¼–ç å™¨ã€‚</li>
<li>ä¸ºé€‚åº”æ‰€æå‡ºçš„åŒä¸€è‡´æ€§æ–¹æ³•ï¼Œæ–‡ç« è®¾è®¡äº†ä¸€ç§ç®€å•çš„é®ç½©ç®¡è®­ç»ƒç­–ç•¥ã€‚</li>
<li>DC-SAMæ–¹æ³•ä¸ä»…é€‚ç”¨äºå›¾åƒåˆ†å‰²ï¼Œè¿˜å¯æ— ç¼æ‰©å±•åˆ°è§†é¢‘é¢†åŸŸã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.12080">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-a3fe4a8637fa1fa8a6b7f865ef592495.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-75e61f7614c517d6ec749884c2652ad3.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f9a754d40555c6f27055dee7a7ff1f67.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-70bed93a9dceaf9cee81b47c1d2a2125.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-abc5fb8550165756f74379972b01831c.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-7edc4f0c930ed1957e8b8f07f7d47938.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="Beyond-Words-Augmenting-Discriminative-Richness-via-Diffusions-in-Unsupervised-Prompt-Learning"><a href="#Beyond-Words-Augmenting-Discriminative-Richness-via-Diffusions-in-Unsupervised-Prompt-Learning" class="headerlink" title="Beyond Words: Augmenting Discriminative Richness via Diffusions in   Unsupervised Prompt Learning"></a>Beyond Words: Augmenting Discriminative Richness via Diffusions in   Unsupervised Prompt Learning</h2><p><strong>Authors:Hairui Ren, Fan Tang, He Zhao, Zixuan Wang, Dandan Guo, Yi Chang</strong></p>
<p>Fine-tuning vision-language models (VLMs) with large amounts of unlabeled data has recently garnered significant interest. However, a key challenge remains the lack of high-quality pseudo-labeled data. Current pseudo-labeling strategies often struggle with mismatches between semantic and visual information, leading to sub-optimal performance of unsupervised prompt learning (UPL) methods. In this paper, we introduce a simple yet effective approach called \textbf{A}ugmenting D\textbf{i}scriminative \textbf{R}ichness via Diffusions (AiR), toward learning a richer discriminating way to represent the class comprehensively and thus facilitate classification. Specifically, our approach includes a pseudo-label generation module that leverages high-fidelity synthetic samples to create an auxiliary classifier, which captures richer visual variation, bridging text-image-pair classification to a more robust image-image-pair classification. Additionally, we exploit the diversity of diffusion-based synthetic samples to enhance prompt learning, providing greater information for semantic-visual alignment. Extensive experiments on five public benchmarks, including RESISC45 and Flowers102, and across three learning paradigms-UL, SSL, and TRZSL-demonstrate that AiR achieves substantial and consistent performance improvements over state-of-the-art unsupervised prompt learning methods. </p>
<blockquote>
<p>å¯¹å¤§é‡æ— æ ‡ç­¾æ•°æ®è¿›è¡Œè§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMsï¼‰çš„å¾®è°ƒæœ€è¿‘å¼•èµ·äº†æå¤§çš„å…´è¶£ã€‚ç„¶è€Œï¼Œç¼ºä¹é«˜è´¨é‡çš„ä¼ªæ ‡ç­¾æ•°æ®ä»ç„¶æ˜¯å…³é”®æŒ‘æˆ˜ã€‚å½“å‰çš„ä¼ªæ ‡ç­¾ç­–ç•¥é€šå¸¸é¢ä¸´è¯­ä¹‰å’Œè§†è§‰ä¿¡æ¯ä¹‹é—´çš„ä¸åŒ¹é…é—®é¢˜ï¼Œå¯¼è‡´æ— ç›‘ç£æç¤ºå­¦ä¹ ï¼ˆUPLï¼‰æ–¹æ³•æ€§èƒ½ä¸ä½³ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬ä»‹ç»äº†ä¸€ç§ç®€å•æœ‰æ•ˆçš„æ–¹æ³•ï¼Œç§°ä¸ºé€šè¿‡æ‰©æ•£å¢å¼ºè¾¨åˆ«ä¸°å¯Œæ€§ï¼ˆAiRï¼‰ï¼Œæ—¨åœ¨å­¦ä¹ ä¸€ç§æ›´ä¸°å¯Œçš„è¾¨åˆ«æ–¹å¼ï¼Œä»¥å…¨é¢ä»£è¡¨ç±»åˆ«ï¼Œä»è€Œä¿ƒè¿›åˆ†ç±»ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åŒ…æ‹¬ä¸€ä¸ªä¼ªæ ‡ç­¾ç”Ÿæˆæ¨¡å—ï¼Œè¯¥æ¨¡å—åˆ©ç”¨é«˜ä¿çœŸåˆæˆæ ·æœ¬åˆ›å»ºä¸€ä¸ªè¾…åŠ©åˆ†ç±»å™¨ï¼Œä»¥æ•æ‰æ›´ä¸°å¯Œçš„è§†è§‰å˜åŒ–ï¼Œå°†æ–‡æœ¬å›¾åƒå¯¹åˆ†ç±»è½¬å˜ä¸ºæ›´ç¨³å¥çš„å›¾åƒå›¾åƒå¯¹åˆ†ç±»ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬åˆ©ç”¨åŸºäºæ‰©æ•£çš„åˆæˆæ ·æœ¬çš„å¤šæ ·æ€§æ¥å¢å¼ºæç¤ºå­¦ä¹ ï¼Œä¸ºè¯­ä¹‰è§†è§‰å¯¹é½æä¾›æ›´å¤šä¿¡æ¯ã€‚åœ¨äº”ä¸ªå…¬å…±åŸºå‡†æµ‹è¯•ï¼ˆåŒ…æ‹¬RESISC45å’ŒFlowers102ï¼‰ä»¥åŠä¸‰ç§å­¦ä¹ æ¨¡å¼ï¼ˆULã€SSLå’ŒTRZSLï¼‰ä¸Šçš„å¤§é‡å®éªŒè¡¨æ˜ï¼Œä¸æœ€å…ˆè¿›çš„æ— ç›‘ç£æç¤ºå­¦ä¹ æ–¹æ³•ç›¸æ¯”ï¼ŒAiRå®ç°äº†æ˜¾è‘—ä¸”ä¸€è‡´çš„æ€§èƒ½æ”¹è¿›ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.11930v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ç§ç®€å•æœ‰æ•ˆçš„æ–¹æ³•â€”â€”AiRï¼ˆé€šè¿‡æ‰©æ•£å¢å¼ºåˆ¤åˆ«ä¸°å¯Œæ€§ï¼‰ï¼Œç”¨äºè§£å†³å¤§è§„æ¨¡è§†è§‰è¯­è¨€æ¨¡å‹çš„æ— ç›‘ç£æç¤ºå­¦ä¹ é¢ä¸´çš„æŒ‘æˆ˜ã€‚é€šè¿‡ä½¿ç”¨é«˜ä¿çœŸåˆæˆæ ·æœ¬ç”Ÿæˆä¼ªæ ‡ç­¾ï¼ŒAiRèƒ½æ•æ‰æ›´ä¸°å¯Œå¤šæ ·çš„è§†è§‰ç‰¹å¾ï¼Œä»è€Œå°†æ–‡æœ¬å›¾åƒé…å¯¹åˆ†ç±»æå‡ä¸ºæ›´ç¨³å¥çš„å›¾åƒå›¾åƒé…å¯¹åˆ†ç±»ã€‚åŒæ—¶ï¼Œåˆ©ç”¨åŸºäºæ‰©æ•£çš„åˆæˆæ ·æœ¬å¤šæ ·æ€§å¢å¼ºæç¤ºå­¦ä¹ ï¼Œä¿ƒè¿›è¯­ä¹‰ä¸è§†è§‰çš„å¯¹é½ã€‚åœ¨äº”ä¸ªå…¬å…±åŸºå‡†æµ‹è¯•ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼ŒAiRåœ¨å¤šç§å­¦ä¹ æ¨¡å¼ä¸‹å‡å®ç°äº†æ˜¾è‘—ä¸”æŒç»­çš„æ€§èƒ½æå‡ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>æå‡ºäº†ä¸€ç§åä¸ºAiRçš„æ–°æ–¹æ³•ï¼Œæ—¨åœ¨è§£å†³å¤§è§„æ¨¡è§†è§‰è¯­è¨€æ¨¡å‹æ— ç›‘ç£æç¤ºå­¦ä¹ ä¸­çš„æŒ‘æˆ˜ã€‚</li>
<li>åˆ©ç”¨é«˜ä¿çœŸåˆæˆæ ·æœ¬ç”Ÿæˆä¼ªæ ‡ç­¾ï¼Œåˆ›å»ºäº†è¾…åŠ©åˆ†ç±»å™¨ä»¥æ•æ‰æ›´ä¸°å¯Œå¤šæ ·çš„è§†è§‰ç‰¹å¾ã€‚</li>
<li>é€šè¿‡å°†æ–‡æœ¬å›¾åƒé…å¯¹åˆ†ç±»è½¬åŒ–ä¸ºå›¾åƒå›¾åƒé…å¯¹åˆ†ç±»ï¼Œæé«˜äº†æ¨¡å‹çš„ç¨³å¥æ€§ã€‚</li>
<li>åˆ©ç”¨åŸºäºæ‰©æ•£çš„åˆæˆæ ·æœ¬å¤šæ ·æ€§å¢å¼ºæç¤ºå­¦ä¹ ï¼Œä¿ƒè¿›è¯­ä¹‰ä¸è§†è§‰çš„å¯¹é½ã€‚</li>
<li>åœ¨äº”ä¸ªå…¬å…±åŸºå‡†æµ‹è¯•ä¸Šçš„å®éªŒç»“æœè¡¨æ˜AiRæ€§èƒ½ä¼˜è¶Šã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.11930">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-4e97d7359665a583d84217ebb27f3dae.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-1e4a5dabc4123785a4d5e5279ead4f5c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e5338ae4367e436c5e8c9130e61bf6dc.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="Zooming-In-on-Fakes-A-Novel-Dataset-for-Localized-AI-Generated-Image-Detection-with-Forgery-Amplification-Approach"><a href="#Zooming-In-on-Fakes-A-Novel-Dataset-for-Localized-AI-Generated-Image-Detection-with-Forgery-Amplification-Approach" class="headerlink" title="Zooming In on Fakes: A Novel Dataset for Localized AI-Generated Image   Detection with Forgery Amplification Approach"></a>Zooming In on Fakes: A Novel Dataset for Localized AI-Generated Image   Detection with Forgery Amplification Approach</h2><p><strong>Authors:Lvpan Cai, Haowei Wang, Jiayi Ji, YanShu ZhouMen, Yiwei Ma, Xiaoshuai Sun, Liujuan Cao, Rongrong Ji</strong></p>
<p>The rise of AI-generated image editing tools has made localized forgeries increasingly realistic, posing challenges for visual content integrity. Although recent efforts have explored localized AIGC detection, existing datasets predominantly focus on object-level forgeries while overlooking broader scene edits in regions such as sky or ground. To address these limitations, we introduce \textbf{BR-Gen}, a large-scale dataset of 150,000 locally forged images with diverse scene-aware annotations, which are based on semantic calibration to ensure high-quality samples. BR-Gen is constructed through a fully automated Perception-Creation-Evaluation pipeline to ensure semantic coherence and visual realism. In addition, we further propose \textbf{NFA-ViT}, a Noise-guided Forgery Amplification Vision Transformer that enhances the detection of localized forgeries by amplifying forgery-related features across the entire image. NFA-ViT mines heterogeneous regions in images, \emph{i.e.}, potential edited areas, by noise fingerprints. Subsequently, attention mechanism is introduced to compel the interaction between normal and abnormal features, thereby propagating the generalization traces throughout the entire image, allowing subtle forgeries to influence a broader context and improving overall detection robustness. Extensive experiments demonstrate that BR-Gen constructs entirely new scenarios that are not covered by existing methods. Take a step further, NFA-ViT outperforms existing methods on BR-Gen and generalizes well across current benchmarks. All data and codes are available at <a target="_blank" rel="noopener" href="https://github.com/clpbc/BR-Gen">https://github.com/clpbc/BR-Gen</a>. </p>
<blockquote>
<p>éšç€äººå·¥æ™ºèƒ½ç”Ÿæˆçš„å›¾åƒç¼–è¾‘å·¥å…·çš„æ™®åŠï¼Œå±€éƒ¨ä¼ªé€ å›¾åƒçš„çœŸå®æ€§è¶Šæ¥è¶Šé«˜ï¼Œè¿™ç»™è§†è§‰å†…å®¹å®Œæ•´æ€§å¸¦æ¥äº†æŒ‘æˆ˜ã€‚å°½ç®¡æœ€è¿‘çš„ç ”ç©¶å·²ç»æ¢ç´¢äº†å±€éƒ¨AIGCæ£€æµ‹ï¼Œä½†ç°æœ‰æ•°æ®é›†ä¸»è¦é›†ä¸­åœ¨å¯¹è±¡çº§åˆ«çš„ä¼ªé€ ä¸Šï¼Œè€Œå¿½ç•¥äº†å¤©ç©ºæˆ–åœ°é¢ç­‰åŒºåŸŸçš„æ›´å¹¿æ³›çš„åœºæ™¯ç¼–è¾‘ã€‚ä¸ºäº†è§£å†³è¿™äº›å±€é™æ€§ï¼Œæˆ‘ä»¬å¼•å…¥äº†<strong>BR-Gen</strong>ï¼Œè¿™æ˜¯ä¸€ä¸ªåŒ…å«15ä¸‡å¼ å±€éƒ¨ä¼ªé€ å›¾åƒçš„å¤§è§„æ¨¡æ•°æ®é›†ï¼Œå…·æœ‰åŸºäºè¯­ä¹‰æ ¡å‡†çš„å¤šæ ·åŒ–åœºæ™¯æ„ŸçŸ¥æ³¨é‡Šï¼Œä»¥ç¡®ä¿é«˜è´¨é‡æ ·æœ¬ã€‚BR-Gené€šè¿‡å…¨è‡ªåŠ¨çš„æ„ŸçŸ¥-åˆ›å»º-è¯„ä¼°æµç¨‹æ„å»ºï¼Œä»¥ç¡®ä¿è¯­ä¹‰è¿è´¯å’Œè§†è§‰çœŸå®æ€§ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿›ä¸€æ­¥æå‡ºäº†<strong>NFA-ViT</strong>ï¼Œè¿™æ˜¯ä¸€ç§å™ªå£°å¼•å¯¼çš„ä¼ªé€ æ”¾å¤§è§†è§‰è½¬æ¢å™¨ï¼Œé€šè¿‡æ”¾å¤§æ•´ä¸ªå›¾åƒä¸­çš„ä¼ªé€ ç›¸å…³ç‰¹å¾ï¼Œå¢å¼ºå±€éƒ¨ä¼ªé€ çš„æ£€æµ‹ã€‚NFA-ViTé€šè¿‡å™ªå£°æŒ‡çº¹æŒ–æ˜å›¾åƒä¸­çš„å¼‚æ„å›¾åœ°åŒºï¼Œå³æ½œåœ¨ç¼–è¾‘åŒºåŸŸã€‚éšåï¼Œå¼•å…¥æ³¨æ„åŠ›æœºåˆ¶ï¼Œè¿«ä½¿æ­£å¸¸å’Œå¼‚å¸¸ç‰¹å¾ä¹‹é—´çš„äº¤äº’ï¼Œä»è€Œåœ¨æ•´å¹…å›¾åƒä¸­ä¼ æ’­æ³›åŒ–ç—•è¿¹ï¼Œä½¿ç»†å¾®çš„ä¼ªé€ èƒ½å¤Ÿå½±å“æ›´å¹¿æ³›çš„ä¸Šä¸‹æ–‡ï¼Œæé«˜æ£€æµ‹çš„æ•´ä½“ç¨³å¥æ€§ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼ŒBR-Genæ„å»ºçš„åœºæ™¯å®Œå…¨è¶…å‡ºäº†ç°æœ‰æ–¹æ³•è¦†ç›–çš„èŒƒå›´ã€‚æ›´è¿›ä¸€æ­¥çš„æ˜¯ï¼ŒNFA-ViTåœ¨BR-Genä¸Šçš„è¡¨ç°ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œå¹¶åœ¨å½“å‰åŸºå‡†æµ‹è¯•ä¸­å…·æœ‰è‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›ã€‚æ‰€æœ‰æ•°æ®å’Œä»£ç éƒ½å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/clpbc/BR-Gen%E4%B8%8A%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/clpbc/BR-Genä¸Šæ‰¾åˆ°ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.11922v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†AIç”Ÿæˆå›¾åƒç¼–è¾‘å·¥å…·çš„å…´èµ·å¸¦æ¥çš„å±€éƒ¨ç¯¡æ”¹æŒ‘æˆ˜ã€‚é’ˆå¯¹ç°æœ‰æ•°æ®é›†ä¸»è¦å…³æ³¨å¯¹è±¡çº§ç¯¡æ”¹ï¼Œè€Œå¿½è§†å¤©ç©ºæˆ–åœ°é¢ç­‰æ›´å¹¿æ³›åœºæ™¯ç¼–è¾‘çš„é—®é¢˜ï¼Œæå‡ºäº†BR-Genæ•°æ®é›†ã€‚è¯¥æ•°æ®é›†åŒ…å«15ä¸‡å¼ å±€éƒ¨ä¼ªé€ å›¾åƒï¼Œå…·æœ‰åŸºäºè¯­ä¹‰æ ¡å‡†çš„ä¸°å¯Œåœºæ™¯æ„ŸçŸ¥æ³¨é‡Šã€‚æ­¤å¤–ï¼Œè¿˜æå‡ºäº†NFA-ViTæ¨¡å‹ï¼Œé€šè¿‡å™ªå£°å¼•å¯¼çš„ä¼ªé€ æ”¾å¤§è§†è§‰è½¬æ¢å™¨ï¼Œå¢å¼ºå¯¹å±€éƒ¨ç¯¡æ”¹çš„æ£€æµ‹ã€‚è¯¥æ¨¡å‹é€šè¿‡å™ªå£°æŒ‡çº¹æŒ–æ˜å›¾åƒä¸­çš„å¼‚è´¨åŒºåŸŸï¼Œå¼•å…¥æ³¨æ„åŠ›æœºåˆ¶ï¼Œè¿«ä½¿æ­£å¸¸å’Œå¼‚å¸¸ç‰¹å¾ä¹‹é—´çš„äº¤äº’ï¼Œæé«˜æ£€æµ‹ç¨³å¥æ€§ã€‚å®éªŒè¡¨æ˜ï¼ŒBR-Genæ•°æ®é›†å¼€åˆ›äº†å…¨æ–°åœºæ™¯ï¼Œè€ŒNFA-ViTåœ¨BR-Genä¸Šçš„è¡¨ç°ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œå¹¶åœ¨å½“å‰åŸºå‡†æµ‹è¯•ä¸­å…·æœ‰è‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>AIç”Ÿæˆçš„å›¾åƒç¼–è¾‘å·¥å…·ä½¿å¾—å±€éƒ¨ä¼ªé€ å›¾åƒè¶Šæ¥è¶Šé€¼çœŸï¼Œå¯¹è§†è§‰å†…å®¹å®Œæ•´æ€§æ„æˆæŒ‘æˆ˜ã€‚</li>
<li>ç°æœ‰æ•°æ®é›†ä¸»è¦å…³æ³¨å¯¹è±¡çº§ä¼ªé€ ï¼Œè€Œå¿½è§†æ›´å¹¿æ³›çš„åœºæ™¯ç¼–è¾‘ï¼Œå¦‚å¤©ç©ºæˆ–åœ°é¢ã€‚</li>
<li>å¼•å…¥BR-Genæ•°æ®é›†ï¼ŒåŒ…å«15ä¸‡å¼ å±€éƒ¨ä¼ªé€ å›¾åƒï¼Œå…·æœ‰ä¸°å¯Œåœºæ™¯æ„ŸçŸ¥æ³¨é‡Šï¼ŒåŸºäºè¯­ä¹‰æ ¡å‡†ç¡®ä¿é«˜è´¨é‡æ ·æœ¬ã€‚</li>
<li>æå‡ºNFA-ViTæ¨¡å‹ï¼Œé€šè¿‡å™ªå£°å¼•å¯¼çš„ä¼ªé€ æ”¾å¤§è§†è§‰è½¬æ¢å™¨å¢å¼ºå±€éƒ¨ä¼ªé€ æ£€æµ‹ã€‚</li>
<li>NFA-ViTæ¨¡å‹é€šè¿‡å™ªå£°æŒ‡çº¹æŒ–æ˜å›¾åƒä¸­çš„å¼‚è´¨åŒºåŸŸï¼Œå¹¶å¼•å…¥æ³¨æ„åŠ›æœºåˆ¶æ¥æé«˜æ£€æµ‹ç¨³å¥æ€§ã€‚</li>
<li>å®éªŒè¡¨æ˜BR-Genæ•°æ®é›†å…·æœ‰åˆ›æ–°æ€§ï¼ŒNFA-ViTåœ¨BR-Genä¸Šçš„è¡¨ç°ä¼˜äºç°æœ‰æ–¹æ³•ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.11922">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-4218c8d60a54efd07b778076b0c0ddce.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-a4f3b990b18034e7e5069a16e847a975.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-1149e5f29122b0b328ed32102afeef58.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-1ff20f0212f1bcd8d63c0eccd9476360.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="Efficient-Lung-Ultrasound-Severity-Scoring-Using-Dedicated-Feature-Extractor"><a href="#Efficient-Lung-Ultrasound-Severity-Scoring-Using-Dedicated-Feature-Extractor" class="headerlink" title="Efficient Lung Ultrasound Severity Scoring Using Dedicated Feature   Extractor"></a>Efficient Lung Ultrasound Severity Scoring Using Dedicated Feature   Extractor</h2><p><strong>Authors:Jiaqi Guo, Yunan Wu, Evangelos Kaimakamis, Georgios Petmezas, Vasileios E. Papageorgiou, Nicos Maglaveras, Aggelos K. Katsaggelos</strong></p>
<p>With the advent of the COVID-19 pandemic, ultrasound imaging has emerged as a promising technique for COVID-19 detection, due to its non-invasive nature, affordability, and portability. In response, researchers have focused on developing AI-based scoring systems to provide real-time diagnostic support. However, the limited size and lack of proper annotation in publicly available ultrasound datasets pose significant challenges for training a robust AI model. This paper proposes MeDiVLAD, a novel pipeline to address the above issue for multi-level lung-ultrasound (LUS) severity scoring. In particular, we leverage self-knowledge distillation to pretrain a vision transformer (ViT) without label and aggregate frame-level features via dual-level VLAD aggregation. We show that with minimal finetuning, MeDiVLAD outperforms conventional fully-supervised methods in both frame- and video-level scoring, while offering classification reasoning with exceptional quality. This superior performance enables key applications such as the automatic identification of critical lung pathology areas and provides a robust solution for broader medical video classification tasks. </p>
<blockquote>
<p>éšç€COVID-19å¤§æµè¡Œçš„åˆ°æ¥ï¼Œç”±äºå…¶æ— åˆ›ã€è´Ÿæ‹…å¾—èµ·å’Œä¾¿æºçš„ç‰¹ç‚¹ï¼Œè¶…å£°æˆåƒå·²å´­éœ²å¤´è§’ä¸ºä¸€ç§æœ‰å‰æ™¯çš„COVID-19æ£€æµ‹æŠ€æœ¯ã€‚ä¸ºæ­¤ï¼Œç ”ç©¶äººå‘˜è‡´åŠ›äºå¼€å‘åŸºäºäººå·¥æ™ºèƒ½çš„è¯„åˆ†ç³»ç»Ÿï¼Œä»¥æä¾›å®æ—¶è¯Šæ–­æ”¯æŒã€‚ç„¶è€Œï¼Œå…¬å¼€å¯ç”¨çš„è¶…å£°æ•°æ®é›†çš„è§„æ¨¡æœ‰é™ä¸”ç¼ºä¹é€‚å½“çš„æ³¨é‡Šï¼Œç»™è®­ç»ƒç¨³å¥çš„äººå·¥æ™ºèƒ½æ¨¡å‹å¸¦æ¥äº†å·¨å¤§æŒ‘æˆ˜ã€‚æœ¬æ–‡æå‡ºäº†MeDiVLADï¼Œè¿™æ˜¯ä¸€ä¸ªæ–°é¢–çš„ç®¡é“æµç¨‹ï¼Œæ—¨åœ¨è§£å†³ä¸Šè¿°é’ˆå¯¹å¤šçº§è‚ºè¶…å£°ï¼ˆLUSï¼‰ä¸¥é‡æ€§è¯„åˆ†çš„é—®é¢˜ã€‚ç‰¹åˆ«æ˜¯ï¼Œæˆ‘ä»¬åˆ©ç”¨è‡ªæˆ‘çŸ¥è¯†è’¸é¦å¯¹è§†è§‰è½¬æ¢å™¨ï¼ˆViTï¼‰è¿›è¡Œé¢„è®­ç»ƒï¼Œè€Œæ— éœ€æ ‡ç­¾å¹¶èšé›†å¸§çº§ç‰¹å¾çš„åŒçº§VLADèšåˆã€‚æˆ‘ä»¬è¡¨æ˜ï¼Œé€šè¿‡æœ€å°çš„å¾®è°ƒï¼ŒMeDiVLADåœ¨å¸§çº§å’Œè§†é¢‘çº§è¯„åˆ†æ–¹é¢éƒ½ä¼˜äºä¼ ç»Ÿçš„å…¨ç›‘ç£æ–¹æ³•ï¼ŒåŒæ—¶æä¾›å‡ºè‰²çš„åˆ†ç±»æ¨ç†è´¨é‡ã€‚è¿™ç§å“è¶Šçš„æ€§èƒ½èƒ½å¤Ÿåº”ç”¨äºè‡ªåŠ¨è¯†åˆ«å…³é”®è‚ºéƒ¨ç—…ç†åŒºåŸŸçš„å…³é”®åº”ç”¨ï¼Œå¹¶ä¸ºæ›´å¹¿æ³›çš„åŒ»å­¦è§†é¢‘åˆ†ç±»ä»»åŠ¡æä¾›äº†ç¨³å¥çš„è§£å†³æ–¹æ¡ˆã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.12524v2">PDF</a> Accepted by IEEE ISBI 2025 (Selected for oral presentation) 2025&#x2F;4&#x2F;15   (v2): Corrected a notation error in Figure 2</p>
<p><strong>Summary</strong></p>
<p>éšç€COVID-19çš„çˆ†å‘ï¼Œè¶…å£°æˆåƒå› å…¶æ— åˆ›æ€§ã€å¯è´Ÿæ‹…æ€§å’Œä¾¿æºæ€§è€Œæˆä¸ºæ£€æµ‹COVID-19çš„æœ‰å‰é€”çš„æŠ€æœ¯ã€‚ç ”ç©¶äººå‘˜è‡´åŠ›äºå¼€å‘åŸºäºäººå·¥æ™ºèƒ½çš„è¯„åˆ†ç³»ç»Ÿä»¥æä¾›å®æ—¶è¯Šæ–­æ”¯æŒã€‚ç„¶è€Œï¼Œå…¬å¼€å¯ç”¨çš„è¶…å£°æ•°æ®é›†çš„å¤§å°æœ‰é™ä¸”ç¼ºä¹é€‚å½“çš„æ³¨é‡Šï¼Œç»™è®­ç»ƒç¨³å¥çš„AIæ¨¡å‹å¸¦æ¥æŒ‘æˆ˜ã€‚æœ¬æ–‡æå‡ºMeDiVLADï¼Œä¸€ä¸ªé’ˆå¯¹å¤šçº§è‚ºéƒ¨è¶…å£°ï¼ˆLUSï¼‰ä¸¥é‡æ€§è¯„åˆ†é—®é¢˜çš„æ–°å‹ç®¡é“ã€‚æˆ‘ä»¬åˆ©ç”¨è‡ªæˆ‘çŸ¥è¯†è’¸é¦å¯¹è§†è§‰è½¬æ¢å™¨ï¼ˆViTï¼‰è¿›è¡Œé¢„è®­ç»ƒï¼Œå¹¶é€šè¿‡åŒçº§VLADèšåˆæŠ€æœ¯èšåˆå¸§çº§ç‰¹å¾ã€‚ç»“æœè¡¨æ˜ï¼ŒMeDiVLADåœ¨å¸§çº§å’Œè§†é¢‘çº§è¯„åˆ†ä¸Šå‡ä¼˜äºä¼ ç»Ÿçš„å…¨ç›‘ç£æ–¹æ³•ï¼ŒåŒæ—¶æä¾›å‡ºè‰²çš„åˆ†ç±»æ¨ç†è´¨é‡ã€‚å…¶å“è¶Šæ€§èƒ½ä½¿å¾—è‡ªåŠ¨è¯†åˆ«å…³é”®è‚ºéƒ¨ç—…ç†åŒºåŸŸæˆä¸ºå¯èƒ½ï¼Œå¹¶ä¸ºæ›´å¹¿æ³›çš„åŒ»ç–—è§†é¢‘åˆ†ç±»ä»»åŠ¡æä¾›äº†ç¨³å¥çš„è§£å†³æ–¹æ¡ˆã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>è¶…å£°æˆåƒå› å…¶åœ¨COVID-19æ£€æµ‹ä¸­çš„æ— åˆ›æ€§ã€å¯è´Ÿæ‹…æ€§å’Œä¾¿æºæ€§è€Œå—åˆ°å…³æ³¨ã€‚</li>
<li>å…¬å¼€å¯ç”¨çš„è¶…å£°æ•°æ®é›†å­˜åœ¨å¤§å°æœ‰é™å’Œç¼ºä¹é€‚å½“æ³¨é‡Šçš„é—®é¢˜ã€‚</li>
<li>MeDiVLADæ˜¯ä¸€ä¸ªé’ˆå¯¹å¤šçº§è‚ºéƒ¨è¶…å£°ä¸¥é‡æ€§è¯„åˆ†çš„æ–°å‹ç®¡é“ã€‚</li>
<li>åˆ©ç”¨è‡ªæˆ‘çŸ¥è¯†è’¸é¦å¯¹è§†è§‰è½¬æ¢å™¨ï¼ˆViTï¼‰è¿›è¡Œé¢„è®­ç»ƒã€‚</li>
<li>é€šè¿‡åŒçº§VLADèšåˆæŠ€æœ¯èšåˆå¸§çº§ç‰¹å¾ã€‚</li>
<li>MeDiVLADåœ¨å¸§çº§å’Œè§†é¢‘çº§è¯„åˆ†ä¸Šè¡¨ç°å‡ºå“è¶Šæ€§èƒ½ï¼Œä¼˜äºä¼ ç»Ÿå…¨ç›‘ç£æ–¹æ³•ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.12524">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-e61f801d25e2a7c323d62f350a3cb991.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f9e4aaaa220d3f51ac38f15e05ae5cf5.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d6cc56a18516d4bee7f51ecd5e1e9c22.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d5142fd1ddf9b34d7897321bf085dc1f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-6531beca76054e51b66f549a4ae5918e.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-f2cf6961262eb514e63d8f00efada832.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="Kernel-Aware-Graph-Prompt-Learning-for-Few-Shot-Anomaly-Detection"><a href="#Kernel-Aware-Graph-Prompt-Learning-for-Few-Shot-Anomaly-Detection" class="headerlink" title="Kernel-Aware Graph Prompt Learning for Few-Shot Anomaly Detection"></a>Kernel-Aware Graph Prompt Learning for Few-Shot Anomaly Detection</h2><p><strong>Authors:Fenfang Tao, Guo-Sen Xie, Fang Zhao, Xiangbo Shu</strong></p>
<p>Few-shot anomaly detection (FSAD) aims to detect unseen anomaly regions with the guidance of very few normal support images from the same class. Existing FSAD methods usually find anomalies by directly designing complex text prompts to align them with visual features under the prevailing large vision-language model paradigm. However, these methods, almost always, neglect intrinsic contextual information in visual features, e.g., the interaction relationships between different vision layers, which is an important clue for detecting anomalies comprehensively. To this end, we propose a kernel-aware graph prompt learning framework, termed as KAG-prompt, by reasoning the cross-layer relations among visual features for FSAD. Specifically, a kernel-aware hierarchical graph is built by taking the different layer features focusing on anomalous regions of different sizes as nodes, meanwhile, the relationships between arbitrary pairs of nodes stand for the edges of the graph. By message passing over this graph, KAG-prompt can capture cross-layer contextual information, thus leading to more accurate anomaly prediction. Moreover, to integrate the information of multiple important anomaly signals in the prediction map, we propose a novel image-level scoring method based on multi-level information fusion. Extensive experiments on MVTecAD and VisA datasets show that KAG-prompt achieves state-of-the-art FSAD results for image-level&#x2F;pixel-level anomaly detection. Code is available at <a target="_blank" rel="noopener" href="https://github.com/CVL-hub/KAG-prompt.git">https://github.com/CVL-hub/KAG-prompt.git</a>. </p>
<blockquote>
<p>å°‘æ•°é•œå¤´å¼‚å¸¸æ£€æµ‹ï¼ˆFSADï¼‰æ—¨åœ¨é€šè¿‡åŒä¸€ç±»åˆ«ä¸­éå¸¸å°‘çš„æ­£å¸¸æ”¯æŒå›¾åƒæ¥æ£€æµ‹æœªè§è¿‡çš„å¼‚å¸¸åŒºåŸŸã€‚ç°æœ‰çš„FSADæ–¹æ³•é€šå¸¸é€šè¿‡è®¾è®¡å¤æ‚çš„æ–‡æœ¬æç¤ºæ¥ä¸æµè¡Œçš„å¤§å‹è§†è§‰è¯­è¨€æ¨¡å‹èŒƒå¼ä¸‹çš„è§†è§‰ç‰¹å¾å¯¹é½æ¥å‘ç°å¼‚å¸¸å€¼ã€‚ç„¶è€Œï¼Œè¿™äº›æ–¹æ³•å‡ ä¹æ€»æ˜¯å¿½ç•¥äº†è§†è§‰ç‰¹å¾ä¸­çš„å†…åœ¨ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œä¾‹å¦‚ä¸åŒè§†è§‰å±‚ä¹‹é—´çš„äº¤äº’å…³ç³»ï¼Œè¿™æ˜¯å…¨é¢æ£€æµ‹å¼‚å¸¸å€¼çš„é‡è¦çº¿ç´¢ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªæ ¸å¿ƒæ„ŸçŸ¥å›¾æç¤ºå­¦ä¹ æ¡†æ¶ï¼Œç§°ä¸ºKAG-promptï¼Œé€šè¿‡æ¨ç†FSADä¸­è§†è§‰ç‰¹å¾çš„è·¨å±‚å…³ç³»ã€‚å…·ä½“æ¥è¯´ï¼Œä»¥ä¸åŒå±‚ç‰¹å¾ï¼ˆä»¥ä¸åŒå¤§å°çš„å¼‚å¸¸åŒºåŸŸä½œä¸ºèŠ‚ç‚¹ï¼‰ä¸ºåŸºç¡€æ„å»ºäº†ä¸€ä¸ªæ ¸å¿ƒæ„ŸçŸ¥åˆ†å±‚å›¾ï¼ŒåŒæ—¶ï¼Œä»»æ„èŠ‚ç‚¹å¯¹ä¹‹é—´çš„å…³ç³»ä»£è¡¨å›¾çš„è¾¹ã€‚é€šè¿‡åœ¨æ­¤å›¾ä¸Šè¿›è¡Œæ¶ˆæ¯ä¼ é€’ï¼ŒKAG-promptå¯ä»¥æ•è·è·¨å±‚ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œä»è€Œè¿›è¡Œæ›´å‡†ç¡®çš„å¼‚å¸¸é¢„æµ‹ã€‚æ­¤å¤–ï¼Œä¸ºäº†æ•´åˆé¢„æµ‹å›¾ä¸­å¤šä¸ªé‡è¦å¼‚å¸¸ä¿¡å·çš„ä¿¡æ¯ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åŸºäºå¤šå±‚æ¬¡ä¿¡æ¯èåˆçš„æ–°é¢–å›¾åƒçº§è¯„åˆ†æ–¹æ³•ã€‚åœ¨MVTecADå’ŒVisAæ•°æ®é›†ä¸Šçš„å¤§é‡å®éªŒè¡¨æ˜ï¼ŒKAG-promptåœ¨å›¾åƒçº§&#x2F;åƒç´ çº§çš„å¼‚å¸¸æ£€æµ‹ä¸­è¾¾åˆ°äº†æœ€æ–°çš„FSADç»“æœã€‚ä»£ç å¯é€šè¿‡ä»¥ä¸‹é“¾æ¥è·å–ï¼š<a target="_blank" rel="noopener" href="https://github.com/CVL-hub/KAG-prompt.git">https://github.com/CVL-hub/KAG-prompt.git</a>ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.17619v2">PDF</a> Accepted to AAAI 2025</p>
<p><strong>Summary</strong><br>å°‘é‡æ ·æœ¬å¼‚å¸¸æ£€æµ‹ï¼ˆFSADï¼‰æ—¨åœ¨åˆ©ç”¨åŒä¸€ç±»åˆ«ä¸­çš„å°‘é‡æ­£å¸¸æ”¯æŒå›¾åƒæ¥æ£€æµ‹æœªè§è¿‡çš„å¼‚å¸¸åŒºåŸŸã€‚ç°æœ‰FSADæ–¹æ³•ä¸»è¦é€šè¿‡è®¾è®¡å¤æ‚çš„æ–‡æœ¬æç¤ºæ¥ä¸è§†è§‰ç‰¹å¾å¯¹é½ï¼Œå¿½ç•¥è§†è§‰ç‰¹å¾çš„å†…åœ¨ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œå¦‚ä¸åŒè§†è§‰å±‚ä¹‹é—´çš„å…³ç³»ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªæ ¸å¿ƒæ„ŸçŸ¥å›¾æç¤ºå­¦ä¹ æ¡†æ¶ï¼Œç§°ä¸ºKAG-promptï¼Œé€šè¿‡æ¨ç†è§†è§‰ç‰¹å¾çš„è·¨å±‚å…³ç³»æ¥è¿›è¡ŒFSADã€‚è¯¥æ¡†æ¶å»ºç«‹äº†ä¸€ä¸ªæ ¸å¿ƒæ„ŸçŸ¥å±‚æ¬¡å›¾ï¼Œä»¥ä¸åŒå±‚çº§çš„ç‰¹å¾ï¼ˆé‡ç‚¹å…³æ³¨ä¸åŒå¤§å°çš„å¼‚å¸¸åŒºåŸŸï¼‰ä½œä¸ºèŠ‚ç‚¹ï¼Œä»»æ„ä¸¤ä¸ªèŠ‚ç‚¹ä¹‹é—´çš„å…³ç³»ä½œä¸ºå›¾çš„è¾¹ã€‚é€šè¿‡å›¾ä¸Šçš„ä¿¡æ¯ä¼ é€’ï¼ŒKAG-promptå¯ä»¥æ•æ‰è·¨å±‚ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œä»è€Œå®ç°æ›´å‡†ç¡®çš„å¼‚å¸¸é¢„æµ‹ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åŸºäºå¤šå±‚çº§ä¿¡æ¯èåˆçš„æ–°é¢–å›¾åƒçº§è¯„åˆ†æ–¹æ³•ï¼Œä»¥æ•´åˆé¢„æµ‹å›¾ä¸­çš„å¤šä¸ªé‡è¦å¼‚å¸¸ä¿¡å·ä¿¡æ¯ã€‚åœ¨MVTecADå’ŒVisAæ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒKAG-promptåœ¨å›¾åƒçº§å’Œåƒç´ çº§çš„å¼‚å¸¸æ£€æµ‹ä¸­å®ç°äº†æœ€å…ˆè¿›çš„FSADç»“æœã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ç°æœ‰FSADæ–¹æ³•ä¸»è¦é€šè¿‡å¤æ‚æ–‡æœ¬æç¤ºä¸è§†è§‰ç‰¹å¾å¯¹é½æ¥æ£€æµ‹å¼‚å¸¸ï¼Œå¿½ç•¥äº†è§†è§‰ç‰¹å¾çš„å†…åœ¨ä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚</li>
<li>æå‡ºäº†ä¸€ç§æ–°çš„å­¦ä¹ æ¡†æ¶KAG-promptï¼Œé€šè¿‡æ„å»ºæ ¸å¿ƒæ„ŸçŸ¥å±‚æ¬¡å›¾æ¥æ•æ‰è§†è§‰ç‰¹å¾çš„è·¨å±‚å…³ç³»ã€‚</li>
<li>å¼‚å¸¸åŒºåŸŸçš„ä¸åŒå°ºå¯¸è¢«ä½œä¸ºä¸åŒå±‚çº§çš„ç‰¹å¾èŠ‚ç‚¹ï¼Œè€Œä»»æ„ä¸¤ä¸ªèŠ‚ç‚¹é—´çš„å…³ç³»æ„æˆäº†å›¾çš„è¾¹ã€‚</li>
<li>é€šè¿‡åœ¨å›¾ä¸Šä¼ é€’æ¶ˆæ¯ï¼ŒKAG-promptèƒ½æ›´å‡†ç¡®åœ°é¢„æµ‹å¼‚å¸¸ã€‚</li>
<li>å¼•å…¥äº†ä¸€ç§åŸºäºå¤šå±‚çº§ä¿¡æ¯èåˆçš„æ–°é¢–å›¾åƒçº§è¯„åˆ†æ–¹æ³•ï¼Œä»¥æ•´åˆé¢„æµ‹å›¾ä¸­çš„å¤šä¸ªé‡è¦å¼‚å¸¸ä¿¡å·ã€‚</li>
<li>åœ¨MVTecADå’ŒVisAæ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒKAG-promptå®ç°äº†å…ˆè¿›çš„FSADç»“æœã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.17619">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-2bf5b49007c9a7fdf3dd56b63f6107ca.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-19523772394d7833b31f5c466946e64f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-da0b28b54c0b8692f44b391df54435db.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-04-18/Vision%20Transformer/">https://kedreamix.github.io/Talk2Paper/Paper/2025-04-18/Vision%20Transformer/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/Vision-Transformer/">
                                    <span class="chip bg-color">Vision Transformer</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-04-18/%E6%A3%80%E6%B5%8B_%E5%88%86%E5%89%B2_%E8%B7%9F%E8%B8%AA/">
                    <div class="card-image">
                        
                        <img src="https://pica.zhimg.com/v2-5ef269ba90aae3b9aeb1321931c03455.jpg" class="responsive-img" alt="æ£€æµ‹/åˆ†å‰²/è·Ÿè¸ª">
                        
                        <span class="card-title">æ£€æµ‹/åˆ†å‰²/è·Ÿè¸ª</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            æ£€æµ‹/åˆ†å‰²/è·Ÿè¸ª æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-04-18  RADLER Radar Object Detection Leveraging Semantic 3D City Models and   Self-Supervised Radar-Image Learning
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-04-18
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/%E6%A3%80%E6%B5%8B-%E5%88%86%E5%89%B2-%E8%B7%9F%E8%B8%AA/" class="post-category">
                                    æ£€æµ‹/åˆ†å‰²/è·Ÿè¸ª
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/%E6%A3%80%E6%B5%8B-%E5%88%86%E5%89%B2-%E8%B7%9F%E8%B8%AA/">
                        <span class="chip bg-color">æ£€æµ‹/åˆ†å‰²/è·Ÿè¸ª</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-04-18/I2I%20Translation/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-ca1f712f6ee96a259fc29c0453b3053f.jpg" class="responsive-img" alt="I2I Translation">
                        
                        <span class="card-title">I2I Translation</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            I2I Translation æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-04-18  Flow Intelligence Robust Feature Matching via Temporal Signature   Correlation
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-04-18
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/I2I-Translation/" class="post-category">
                                    I2I Translation
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/I2I-Translation/">
                        <span class="chip bg-color">I2I Translation</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">22950.1k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
