<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Few-Shot">
    <meta name="description" content="Few-Shot æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-04-18  Logits DeConfusion with CLIP for Few-Shot Learning">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>Few-Shot | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://pica.zhimg.com/v2-75e61f7614c517d6ec749884c2652ad3.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Few-Shot</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/Few-Shot/">
                                <span class="chip bg-color">Few-Shot</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/Few-Shot/" class="post-category">
                                Few-Shot
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-04-18
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-05-14
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    7.1k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    29 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-04-18-æ›´æ–°"><a href="#2025-04-18-æ›´æ–°" class="headerlink" title="2025-04-18 æ›´æ–°"></a>2025-04-18 æ›´æ–°</h1><h2 id="Logits-DeConfusion-with-CLIP-for-Few-Shot-Learning"><a href="#Logits-DeConfusion-with-CLIP-for-Few-Shot-Learning" class="headerlink" title="Logits DeConfusion with CLIP for Few-Shot Learning"></a>Logits DeConfusion with CLIP for Few-Shot Learning</h2><p><strong>Authors:Shuo Li, Fang Liu, Zehua Hao, Xinyi Wang, Lingling Li, Xu Liu, Puhua Chen, Wenping Ma</strong></p>
<p>With its powerful visual-language alignment capability, CLIP performs well in zero-shot and few-shot learning tasks. However, we found in experiments that CLIPâ€™s logits suffer from serious inter-class confusion problems in downstream tasks, and the ambiguity between categories seriously affects the accuracy. To address this challenge, we propose a novel method called Logits DeConfusion, which effectively learns and eliminates inter-class confusion in logits by combining our Multi-level Adapter Fusion (MAF) module with our Inter-Class Deconfusion (ICD) module. Our MAF extracts features from different levels and fuses them uniformly to enhance feature representation. Our ICD learnably eliminates inter-class confusion in logits with a residual structure. Experimental results show that our method can significantly improve the classification performance and alleviate the inter-class confusion problem. The code is available at <a target="_blank" rel="noopener" href="https://github.com/LiShuo1001/LDC">https://github.com/LiShuo1001/LDC</a>. </p>
<blockquote>
<p>CLIPå‡­å€Ÿå…¶å¼ºå¤§çš„è§†è§‰è¯­è¨€å¯¹é½èƒ½åŠ›ï¼Œåœ¨é›¶æ ·æœ¬å’Œå°‘æ ·æœ¬å­¦ä¹ ä»»åŠ¡ä¸­è¡¨ç°è‰¯å¥½ã€‚ç„¶è€Œï¼Œæˆ‘ä»¬åœ¨å®éªŒä¸­å‘ç°CLIPçš„logitsåœ¨ä¸‹æ¸¸ä»»åŠ¡ä¸­å­˜åœ¨ä¸¥é‡çš„è·¨ç±»æ··æ·†é—®é¢˜ï¼Œç±»åˆ«ä¹‹é—´çš„æ¨¡ç³Šæ€§ä¸¥é‡å½±å“äº†å‡†ç¡®æ€§ã€‚ä¸ºäº†åº”å¯¹è¿™ä¸€æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åä¸ºLogits DeConfusionçš„æ–°æ–¹æ³•ï¼Œè¯¥æ–¹æ³•é€šè¿‡ç»“åˆæˆ‘ä»¬çš„å¤šå±‚æ¬¡é€‚é…å™¨èåˆï¼ˆMAFï¼‰æ¨¡å—å’Œè·¨ç±»å»æ··æ·†ï¼ˆICDï¼‰æ¨¡å—ï¼Œæœ‰æ•ˆåœ°å­¦ä¹ å’Œæ¶ˆé™¤logitsä¸­çš„è·¨ç±»æ··æ·†ã€‚æˆ‘ä»¬çš„MAFä»ä¸åŒå±‚çº§æå–ç‰¹å¾ï¼Œå¹¶å¯¹å…¶è¿›è¡Œç»Ÿä¸€èåˆï¼Œä»¥å¢å¼ºç‰¹å¾è¡¨ç¤ºã€‚æˆ‘ä»¬çš„ICDä½¿ç”¨æ®‹å·®ç»“æ„å¯å­¦ä¹ åœ°æ¶ˆé™¤logitsä¸­çš„è·¨ç±»æ··æ·†ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•å¯ä»¥æ˜¾è‘—æé«˜åˆ†ç±»æ€§èƒ½ï¼Œå¹¶ç¼“è§£è·¨ç±»æ··æ·†é—®é¢˜ã€‚ä»£ç å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/LiShuo1001/LDC%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/LiShuo1001/LDCæ‰¾åˆ°ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.12104v1">PDF</a> CVPR 2025</p>
<p><strong>Summary</strong></p>
<p>CLIPæ¨¡å‹å…·å¤‡å¼ºå¤§çš„è§†è§‰è¯­è¨€å¯¹é½èƒ½åŠ›ï¼Œåœ¨é›¶æ ·æœ¬å’Œå°‘æ ·æœ¬å­¦ä¹ ä»»åŠ¡ä¸­è¡¨ç°ä¼˜å¼‚ã€‚ä½†åœ¨ä¸‹æ¸¸ä»»åŠ¡ä¸­ï¼ŒCLIPçš„logitsé¢ä¸´ä¸¥é‡çš„ç±»é—´æ··æ·†é—®é¢˜ï¼Œå½±å“å‡†ç¡®æ€§ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬æå‡ºLogits DeConfusionæ–¹æ³•ï¼Œé€šè¿‡ç»“åˆå¤šçº§åˆ«é€‚é…å™¨èåˆï¼ˆMAFï¼‰å’Œç±»é—´å»æ··æ·†ï¼ˆICDï¼‰æ¨¡å—ï¼Œæœ‰æ•ˆå­¦ä¹ å’Œæ¶ˆé™¤ç±»é—´æ··æ·†ã€‚MAFä»ä¸åŒçº§åˆ«æå–ç‰¹å¾å¹¶ç»Ÿä¸€èåˆï¼Œå¢å¼ºç‰¹å¾è¡¨ç¤ºã€‚ICDä½¿ç”¨æ®‹å·®ç»“æ„å¯å­¦ä¹ åœ°æ¶ˆé™¤logitsä¸­çš„ç±»é—´æ··æ·†ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•èƒ½æ˜¾è‘—æé«˜åˆ†ç±»æ€§èƒ½ï¼Œç¼“è§£ç±»é—´æ··æ·†é—®é¢˜ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>CLIPæ¨¡å‹åœ¨é›¶æ ·æœ¬å’Œå°‘æ ·æœ¬å­¦ä¹ ä»»åŠ¡ä¸­è¡¨ç°å‡ºå¼ºå¤§çš„è§†è§‰è¯­è¨€å¯¹é½èƒ½åŠ›ã€‚</li>
<li>CLIPçš„logitsåœ¨ä¸‹æ¸¸ä»»åŠ¡ä¸­å­˜åœ¨ä¸¥é‡çš„ç±»é—´æ··æ·†é—®é¢˜ã€‚</li>
<li>Logits DeConfusionæ–¹æ³•é€šè¿‡ç»“åˆMAFå’ŒICDæ¨¡å—ï¼Œæœ‰æ•ˆå­¦ä¹ å’Œæ¶ˆé™¤ç±»é—´æ··æ·†ã€‚</li>
<li>MAFæ¨¡å—èƒ½å¤Ÿæå–ä¸åŒçº§åˆ«çš„ç‰¹å¾å¹¶è¿›è¡Œç»Ÿä¸€èåˆï¼Œå¢å¼ºç‰¹å¾è¡¨ç¤ºã€‚</li>
<li>ICDæ¨¡å—ä½¿ç”¨æ®‹å·®ç»“æ„ï¼Œèƒ½å¤Ÿå­¦ä¹ åœ°æ¶ˆé™¤logitsä¸­çš„ç±»é—´æ··æ·†ã€‚</li>
<li>Logits DeConfusionæ–¹æ³•èƒ½æ˜¾è‘—æé«˜åˆ†ç±»æ€§èƒ½ï¼Œå¹¶ç¼“è§£ç±»é—´æ··æ·†é—®é¢˜ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.12104">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-63ff40ac749101faf3b68cd7e46cba5b.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-9edba312354b07af5cac9135ea899b53.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-60a815c24411c8ed64d38e9ad50a7eb6.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-66ce6c36c25984602788f2bb549bf56d.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="DC-SAM-In-Context-Segment-Anything-in-Images-and-Videos-via-Dual-Consistency"><a href="#DC-SAM-In-Context-Segment-Anything-in-Images-and-Videos-via-Dual-Consistency" class="headerlink" title="DC-SAM: In-Context Segment Anything in Images and Videos via Dual   Consistency"></a>DC-SAM: In-Context Segment Anything in Images and Videos via Dual   Consistency</h2><p><strong>Authors:Mengshi Qi, Pengfei Zhu, Xiangtai Li, Xiaoyang Bi, Lu Qi, Huadong Ma, Ming-Hsuan Yang</strong></p>
<p>Given a single labeled example, in-context segmentation aims to segment corresponding objects. This setting, known as one-shot segmentation in few-shot learning, explores the segmentation modelâ€™s generalization ability and has been applied to various vision tasks, including scene understanding and image&#x2F;video editing. While recent Segment Anything Models have achieved state-of-the-art results in interactive segmentation, these approaches are not directly applicable to in-context segmentation. In this work, we propose the Dual Consistency SAM (DC-SAM) method based on prompt-tuning to adapt SAM and SAM2 for in-context segmentation of both images and videos. Our key insights are to enhance the features of the SAMâ€™s prompt encoder in segmentation by providing high-quality visual prompts. When generating a mask prior, we fuse the SAM features to better align the prompt encoder. Then, we design a cycle-consistent cross-attention on fused features and initial visual prompts. Next, a dual-branch design is provided by using the discriminative positive and negative prompts in the prompt encoder. Furthermore, we design a simple mask-tube training strategy to adopt our proposed dual consistency method into the mask tube. Although the proposed DC-SAM is primarily designed for images, it can be seamlessly extended to the video domain with the support of SAM2. Given the absence of in-context segmentation in the video domain, we manually curate and construct the first benchmark from existing video segmentation datasets, named In-Context Video Object Segmentation (IC-VOS), to better assess the in-context capability of the model. Extensive experiments demonstrate that our method achieves 55.5 (+1.4) mIoU on COCO-20i, 73.0 (+1.1) mIoU on PASCAL-5i, and a J&amp;F score of 71.52 on the proposed IC-VOS benchmark. Our source code and benchmark are available at <a target="_blank" rel="noopener" href="https://github.com/zaplm/DC-SAM">https://github.com/zaplm/DC-SAM</a>. </p>
<blockquote>
<p>ç»™å®šä¸€ä¸ªå¸¦æ ‡ç­¾çš„æ ·æœ¬ï¼Œä¸Šä¸‹æ–‡å†…åˆ†å‰²æ—¨åœ¨åˆ†å‰²å¯¹åº”çš„ç›®æ ‡å¯¹è±¡ã€‚è¿™ç§è®¾ç½®è¢«ç§°ä¸ºå°æ ·æœ¬å­¦ä¹ ä¸­çš„ä¸€æ¬¡åˆ†å‰²ï¼Œæ—¨åœ¨æ¢ç´¢åˆ†å‰²æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ï¼Œå¹¶å·²åº”ç”¨äºå„ç§è§†è§‰ä»»åŠ¡ï¼ŒåŒ…æ‹¬åœºæ™¯ç†è§£å’Œå›¾åƒ&#x2F;è§†é¢‘ç¼–è¾‘ã€‚è™½ç„¶æœ€è¿‘çš„ä»»ä½•äº‹ç‰©åˆ†å‰²æ¨¡å‹åœ¨äº¤äº’å¼åˆ†å‰²æ–¹é¢è¾¾åˆ°äº†æœ€æ–°ç»“æœï¼Œä½†è¿™äº›æ–¹æ³•å¹¶ä¸ç›´æ¥é€‚ç”¨äºä¸Šä¸‹æ–‡åˆ†å‰²ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åŸºäºæç¤ºè°ƒæ•´çš„åŒä¸€è‡´æ€§SAMï¼ˆDC-SAMï¼‰æ–¹æ³•ï¼Œä»¥é€‚åº”å›¾åƒå’Œè§†é¢‘çš„ä¸Šä¸‹æ–‡åˆ†å‰²ã€‚æˆ‘ä»¬çš„å…³é”®è§è§£æ˜¯é€šè¿‡æä¾›é«˜è´¨é‡è§†è§‰æç¤ºæ¥å¢å¼ºSAMæç¤ºç¼–ç å™¨çš„åˆ†å‰²ç‰¹å¾ã€‚åœ¨ç”Ÿæˆé®ç½©å…ˆéªŒæ—¶ï¼Œæˆ‘ä»¬èåˆSAMç‰¹å¾ä»¥æ›´å¥½åœ°å¯¹é½æç¤ºç¼–ç å™¨ã€‚ç„¶åï¼Œæˆ‘ä»¬åœ¨èåˆçš„ç‰¹å¾å’Œåˆå§‹è§†è§‰æç¤ºä¸Šè®¾è®¡äº†ä¸€ä¸ªå¾ªç¯ä¸€è‡´çš„äº¤å‰æ³¨æ„åŠ›ã€‚æ¥ä¸‹æ¥ï¼Œé€šè¿‡ä½¿ç”¨æç¤ºç¼–ç å™¨ä¸­çš„é‰´åˆ«æ€§æ­£è´Ÿæç¤ºæ¥å®ç°åŒåˆ†æ”¯è®¾è®¡ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è®¾è®¡äº†ä¸€ä¸ªç®€å•çš„é®ç½©ç®¡è®­ç»ƒç­–ç•¥ï¼Œå°†æ‰€æå‡ºçš„åŒä¸€è‡´æ€§æ–¹æ³•åº”ç”¨äºé®ç½©ç®¡ä¸­ã€‚è™½ç„¶æå‡ºçš„DC-SAMä¸»è¦ä¸ºå›¾åƒè®¾è®¡ï¼Œä½†åœ¨SAM2çš„æ”¯æŒä¸‹ï¼Œå®ƒå¯ä»¥æ— ç¼æ‰©å±•åˆ°è§†é¢‘é¢†åŸŸã€‚é‰´äºè§†é¢‘é¢†åŸŸç¼ºä¹ä¸Šä¸‹æ–‡åˆ†å‰²ï¼Œæˆ‘ä»¬ä»ç°æœ‰çš„è§†é¢‘åˆ†å‰²æ•°æ®é›†ä¸­æ‰‹åŠ¨ç­›é€‰å’Œæ„å»ºäº†ä¸€ä¸ªåä¸ºIC-VOSï¼ˆä¸Šä¸‹æ–‡è§†é¢‘ç›®æ ‡åˆ†å‰²ï¼‰çš„ç¬¬ä¸€ä¸ªåŸºå‡†æµ‹è¯•é›†ï¼Œä»¥æ›´å¥½åœ°è¯„ä¼°æ¨¡å‹çš„ä¸Šä¸‹æ–‡èƒ½åŠ›ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨COCO-20iä¸Šå®ç°äº†55.5ï¼ˆ+1.4ï¼‰çš„mIoUï¼Œåœ¨PASCAL-5iä¸Šå®ç°äº†73.0ï¼ˆ+1.1ï¼‰çš„mIoUï¼Œåœ¨æå‡ºçš„IC-VOSåŸºå‡†æµ‹è¯•é›†ä¸Šè¾¾åˆ°äº†71.52çš„J&amp;Få¾—åˆ†ã€‚æˆ‘ä»¬çš„æºä»£ç å’ŒåŸºå‡†æµ‹è¯•é›†å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/zaplm/DC-SAM%E8%8E%B7%E5%8F%96%E3%80%82">https://github.com/zaplm/DC-SAMè·å–ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.12080v1">PDF</a> </p>
<p><strong>Summary</strong><br>     æœ¬è®ºæ–‡å…³æ³¨äºå•æ¬¡ç¤ºä¾‹ä¸‹çš„ç›®æ ‡åˆ†å‰²ä»»åŠ¡ï¼Œå³ç»™å®šå•ä¸ªæ ‡è®°æ ·æœ¬è¿›è¡Œä¸Šä¸‹æ–‡åˆ†å‰²ã€‚æå‡ºä¸€ç§åŸºäºæç¤ºè°ƒæ•´ï¼ˆprompt-tuningï¼‰çš„Dual Consistency SAMï¼ˆDC-SAMï¼‰æ–¹æ³•ï¼Œç”¨äºå›¾åƒå’Œè§†é¢‘ä¸Šä¸‹æ–‡åˆ†å‰²ã€‚é€šè¿‡å¢å¼ºSAMæç¤ºç¼–ç å™¨çš„ç‰¹å¾å’Œæé«˜æ©æ¨¡å…ˆéªŒçš„è´¨é‡ï¼Œè®¾è®¡å¾ªç¯ä¸€è‡´çš„è·¨æ³¨æ„åŠ›æœºåˆ¶å’ŒåŒé‡åˆ†æ”¯è®¾è®¡ï¼Œå®ç°åœ¨å›¾åƒå’Œè§†é¢‘çš„ä¸Šä¸‹æ–‡åˆ†å‰²ä»»åŠ¡ä¸­çš„ä¼˜ç§€è¡¨ç°ã€‚å¹¶åˆ›å»ºäº†ç¬¬ä¸€ä¸ªé’ˆå¯¹è§†é¢‘åŸŸä¸Šä¸‹æ–‡åˆ†å‰²çš„IC-VOSåŸºå‡†æµ‹è¯•é›†ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æå‡ºäº†ä¸€ç§åä¸ºDC-SAMçš„æ–¹æ³•ï¼ŒåŸºäºæç¤ºè°ƒæ•´ï¼ˆprompt-tuningï¼‰æŠ€æœ¯ï¼Œç”¨äºé€‚åº”ä¸Šä¸‹æ–‡åˆ†å‰²ä»»åŠ¡ã€‚</li>
<li>DC-SAMæ–¹æ³•é€šè¿‡å¢å¼ºSAMæç¤ºç¼–ç å™¨çš„ç‰¹å¾è´¨é‡æ¥æé«˜åˆ†å‰²æ€§èƒ½ã€‚</li>
<li>DC-SAMé‡‡ç”¨æ©æ¨¡å…ˆéªŒç”Ÿæˆï¼Œå¹¶é€šè¿‡èåˆSAMç‰¹å¾è¿›è¡Œæ”¹è¿›ã€‚</li>
<li>å¼•å…¥å¾ªç¯ä¸€è‡´çš„è·¨æ³¨æ„åŠ›æœºåˆ¶æ¥åŠ å¼ºæ¨¡å‹çš„ç‰¹å¾å¯¹é½ã€‚</li>
<li>è®¾è®¡äº†åŒé‡åˆ†æ”¯è®¾è®¡ï¼Œä½¿ç”¨åˆ¤åˆ«æ€§çš„æ­£è´Ÿæç¤ºåœ¨æç¤ºç¼–ç å™¨ä¸­è¿›è¡Œä¼˜åŒ–ã€‚</li>
<li>æå‡ºäº†ä¸€ç§ç®€å•çš„æ©æ¨¡ç®¡è®­ç»ƒç­–ç•¥ï¼Œå°†åŒä¸€è‡´æ€§æ–¹æ³•çº³å…¥æ©æ¨¡ç®¡ä¸­ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.12080">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-a3fe4a8637fa1fa8a6b7f865ef592495.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-75e61f7614c517d6ec749884c2652ad3.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-f9a754d40555c6f27055dee7a7ff1f67.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-70bed93a9dceaf9cee81b47c1d2a2125.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-abc5fb8550165756f74379972b01831c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-7edc4f0c930ed1957e8b8f07f7d47938.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="Search-is-All-You-Need-for-Few-shot-Anomaly-Detection"><a href="#Search-is-All-You-Need-for-Few-shot-Anomaly-Detection" class="headerlink" title="Search is All You Need for Few-shot Anomaly Detection"></a>Search is All You Need for Few-shot Anomaly Detection</h2><p><strong>Authors:Qishan Wang, Jia Guo, Shuyong Gao, Haofen Wang, Li Xiong, Junjie Hu, Hanqi Guo, Wenqiang Zhang</strong></p>
<p>Few-shot anomaly detection (FSAD) has emerged as a crucial yet challenging task in industrial inspection, where normal distribution modeling must be accomplished with only a few normal images. While existing approaches typically employ multi-modal foundation models combining language and vision modalities for prompt-guided anomaly detection, these methods often demand sophisticated prompt engineering and extensive manual tuning. In this paper, we demonstrate that a straightforward nearest-neighbor search framework can surpass state-of-the-art performance in both single-class and multi-class FSAD scenarios. Our proposed method, VisionAD, consists of four simple yet essential components: (1) scalable vision foundation models that extract universal and discriminative features; (2) dual augmentation strategies - support augmentation to enhance feature matching adaptability and query augmentation to address the oversights of single-view prediction; (3) multi-layer feature integration that captures both low-frequency global context and high-frequency local details with minimal computational overhead; and (4) a class-aware visual memory bank enabling efficient one-for-all multi-class detection. Extensive evaluations across MVTec-AD, VisA, and Real-IAD benchmarks demonstrate VisionADâ€™s exceptional performance. Using only 1 normal images as support, our method achieves remarkable image-level AUROC scores of 97.4%, 94.8%, and 70.8% respectively, outperforming current state-of-the-art approaches by significant margins (+1.6%, +3.2%, and +1.4%). The training-free nature and superior few-shot capabilities of VisionAD make it particularly appealing for real-world applications where samples are scarce or expensive to obtain. Code is available at <a target="_blank" rel="noopener" href="https://github.com/Qiqigeww/VisionAD">https://github.com/Qiqigeww/VisionAD</a>. </p>
<blockquote>
<p>å°‘é‡æ ·æœ¬å¼‚å¸¸æ£€æµ‹ï¼ˆFSADï¼‰åœ¨å·¥ä¸šæ£€æµ‹ä¸­æ˜¯ä¸€é¡¹è‡³å…³é‡è¦ä¸”å……æ»¡æŒ‘æˆ˜çš„ä»»åŠ¡ï¼Œåªéœ€è¦å°‘é‡çš„æ­£å¸¸å›¾åƒå³å¯å®Œæˆæ­£å¸¸åˆ†å¸ƒå»ºæ¨¡ã€‚å°½ç®¡ç°æœ‰æ–¹æ³•é€šå¸¸é‡‡ç”¨å¤šæ¨¡æ€åŸºç¡€æ¨¡å‹ï¼Œç»“åˆè¯­è¨€å’Œè§†è§‰æ¨¡å¼è¿›è¡Œæç¤ºå¼•å¯¼å¼‚å¸¸æ£€æµ‹ï¼Œä½†è¿™äº›æ–¹æ³•å¾€å¾€éœ€è¦è¿›è¡Œå¤æ‚çš„æç¤ºå·¥ç¨‹å’Œå¤§é‡çš„æ‰‹åŠ¨è°ƒæ•´ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬å±•ç¤ºäº†ç®€å•çš„æœ€è¿‘é‚»æœç´¢æ¡†æ¶å¯ä»¥åœ¨å•ç±»å’Œå¤šç±»FSADåœºæ™¯ä¸­è¶…è¶Šæœ€æ–°æŠ€æœ¯æ€§èƒ½ã€‚æˆ‘ä»¬æå‡ºçš„æ–¹æ³•VisionADç”±å››ä¸ªç®€å•ä½†è‡³å…³é‡è¦çš„ç»„ä»¶æ„æˆï¼šï¼ˆ1ï¼‰å¯æ‰©å±•çš„è§†è§‰åŸºç¡€æ¨¡å‹ï¼Œç”¨äºæå–é€šç”¨å’Œåˆ¤åˆ«ç‰¹å¾ï¼›ï¼ˆ2ï¼‰åŒå¢å¼ºç­–ç•¥â€”â€”æ”¯æŒå¢å¼ºä»¥æé«˜ç‰¹å¾åŒ¹é…çš„é€‚åº”æ€§ï¼ŒæŸ¥è¯¢å¢å¼ºä»¥è§£å†³å•è§†å›¾é¢„æµ‹çš„é—æ¼ï¼›ï¼ˆ3ï¼‰å¤šå±‚ç‰¹å¾èåˆï¼Œä»¥æœ€å°çš„è®¡ç®—å¼€é”€æ•è·ä½é¢‘å…¨å±€ä¸Šä¸‹æ–‡å’Œé«˜é¢‘å±€éƒ¨ç»†èŠ‚ï¼›ï¼ˆ4ï¼‰ç±»æ„ŸçŸ¥è§†è§‰å†…å­˜åº“ï¼Œå®ç°é«˜æ•ˆçš„ä¸€å¯¹å¤šç±»æ£€æµ‹ã€‚åœ¨MVTec-ADã€VisAå’ŒReal-IADç­‰å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸Šçš„å¹¿æ³›è¯„ä¼°è¡¨æ˜ï¼ŒVisionADå…·æœ‰å“è¶Šçš„æ€§èƒ½ã€‚ä»…ä½¿ç”¨1å¼ æ­£å¸¸å›¾åƒä½œä¸ºæ”¯æŒï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨å›¾åƒçº§AUROCå¾—åˆ†ä¸Šåˆ†åˆ«å®ç°äº†97.4%ã€94.8%å’Œ70.8%çš„æ˜¾è‘—æˆç»©ï¼Œæ˜¾è‘—ä¼˜äºå½“å‰æœ€æ–°æ–¹æ³•ï¼ˆåˆ†åˆ«æé«˜1.6%ã€3.2%å’Œ1.4%ï¼‰ã€‚VisionADçš„æ— è®­ç»ƒæ€§è´¨å’Œä¼˜è¶Šçš„å°‘é‡æ ·æœ¬èƒ½åŠ›ä½¿å…¶ç‰¹åˆ«é€‚ç”¨äºæ ·æœ¬ç¨€ç¼ºæˆ–æ˜‚è´µçš„å®é™…åº”ç”¨åœºæ™¯ã€‚ä»£ç å¯è®¿é—®ï¼š<a target="_blank" rel="noopener" href="https://github.com/Qiqigeww/VisionAD%E3%80%82">https://github.com/Qiqigeww/VisionADã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.11895v1">PDF</a> </p>
<p><strong>Summary</strong><br>     å°‘æ•°æ ·æœ¬å¼‚å¸¸æ£€æµ‹ï¼ˆFSADï¼‰åœ¨å·¥ä¸šæ£€æµ‹ä¸­æ˜¯ä¸€é¡¹é‡è¦ä¸”å…·æœ‰æŒ‘æˆ˜æ€§çš„ä»»åŠ¡ï¼Œåªéœ€å°‘é‡æ­£å¸¸å›¾åƒå³å¯å®Œæˆæ­£å¸¸åˆ†å¸ƒå»ºæ¨¡ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸é‡‡ç”¨å¤šæ¨¡æ€åŸºç¡€æ¨¡å‹ç»“åˆè¯­è¨€å’Œè§†è§‰æ¨¡æ€è¿›è¡Œæç¤ºå¼•å¯¼å¼‚å¸¸æ£€æµ‹ï¼Œä½†éœ€æ±‚å¤æ‚çš„æç¤ºå·¥ç¨‹å’Œç¹ççš„æ‰‹åŠ¨è°ƒæ•´ã€‚æœ¬ç ”ç©¶å±•ç¤ºäº†ä¸€ä¸ªç®€å•çš„æœ€è¿‘é‚»æœç´¢æ¡†æ¶ï¼Œåœ¨å•ç±»å’Œå¤šç±»FSADåœºæ™¯ä¸­å‡è¶…è¶Šç°æœ‰æŠ€æœ¯æ€§èƒ½ã€‚æ–¹æ³•åŒ…æ‹¬å››ä¸ªå…³é”®éƒ¨åˆ†ï¼šå¯æ‰©å±•çš„è§†è§‰åŸºç¡€æ¨¡å‹ã€åŒé‡å¢å¼ºç­–ç•¥ã€å¤šå±‚ç‰¹å¾èåˆå’Œç±»æ„ŸçŸ¥è§†è§‰è®°å¿†åº“ã€‚åœ¨MVTec-ADã€VisAå’ŒReal-IADåŸºå‡†æµ‹è¯•ä¸Šçš„è¯„ä¼°è¯æ˜äº†å…¶å“è¶Šæ€§èƒ½ã€‚ä»…ä½¿ç”¨ä¸€å¼ æ­£å¸¸å›¾åƒä½œä¸ºæ”¯æŒï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨å›¾åƒçº§AUROCå¾—åˆ†ä¸Šå®ç°äº†æƒŠäººçš„æˆç»©ï¼Œæ˜¾è‘—ä¼˜äºå½“å‰å…ˆè¿›æŠ€æœ¯ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å°‘æ•°æ ·æœ¬å¼‚å¸¸æ£€æµ‹ï¼ˆFSADï¼‰åœ¨å·¥ä¸šæ£€æµ‹ä¸­å…·æœ‰é‡è¦æ„ä¹‰ï¼Œä»…éœ€å°‘é‡æ­£å¸¸å›¾åƒè¿›è¡Œæ­£å¸¸åˆ†å¸ƒå»ºæ¨¡ã€‚</li>
<li>ç°æœ‰æ–¹æ³•é€šå¸¸ç»“åˆè¯­è¨€å’Œè§†è§‰æ¨¡æ€è¿›è¡Œå¼‚å¸¸æ£€æµ‹ï¼Œä½†éœ€æ±‚å¤æ‚çš„æç¤ºå·¥ç¨‹å’Œæ‰‹åŠ¨è°ƒæ•´ã€‚</li>
<li>æœ¬ç ”ç©¶æå‡ºä¸€ä¸ªç®€æ´çš„VisionADæ–¹æ³•ï¼ŒåŒ…å«å››ä¸ªå…³é”®ç»„ä»¶ï¼šå¯æ‰©å±•çš„è§†è§‰åŸºç¡€æ¨¡å‹ã€åŒé‡å¢å¼ºç­–ç•¥ã€å¤šå±‚ç‰¹å¾èåˆå’Œç±»æ„ŸçŸ¥è§†è§‰è®°å¿†åº“ã€‚</li>
<li>VisionADåœ¨MVTec-ADã€VisAå’ŒReal-IADç­‰å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸Šè¡¨ç°å‡ºå“è¶Šæ€§èƒ½ã€‚</li>
<li>ä½¿ç”¨ä»…ä¸€å¼ æ­£å¸¸å›¾åƒä½œä¸ºæ”¯æŒï¼ŒVisionADåœ¨å›¾åƒçº§AUROCå¾—åˆ†ä¸Šå®ç°æ˜¾è‘—æˆç»©ã€‚</li>
<li>VisionADå…·æœ‰æ— éœ€è®­ç»ƒçš„ä¼˜åŠ¿ï¼Œç‰¹åˆ«é€‚ç”¨äºæ ·æœ¬ç¨€ç¼ºæˆ–è·å–æˆæœ¬é«˜æ˜‚çš„å®é™…åº”ç”¨åœºæ™¯ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.11895">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-cc4e4c65b288490a54b1d53d79a1b640.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-93ffe254053fd759668e372e54e90347.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-9db877ce20b04d448eb7f469457f288c.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-473761b5ede54e71d026eb9f557f9dbd.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-1ba9f71e9be97d88c7a2d1b114ba840f.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="Learning-What-NOT-to-Count"><a href="#Learning-What-NOT-to-Count" class="headerlink" title="Learning What NOT to Count"></a>Learning What NOT to Count</h2><p><strong>Authors:Adriano Dâ€™Alessandro, Ali Mahdavi-Amiri, Ghassan Hamarneh</strong></p>
<p>Few&#x2F;zero-shot object counting methods reduce the need for extensive annotations but often struggle to distinguish between fine-grained categories, especially when multiple similar objects appear in the same scene. To address this limitation, we propose an annotation-free approach that enables the seamless integration of new fine-grained categories into existing few&#x2F;zero-shot counting models. By leveraging latent generative models, we synthesize high-quality, category-specific crowded scenes, providing a rich training source for adapting to new categories without manual labeling. Our approach introduces an attention prediction network that identifies fine-grained category boundaries trained using only synthetic pseudo-annotated data. At inference, these fine-grained attention estimates refine the output of existing few&#x2F;zero-shot counting networks. To benchmark our method, we further introduce the FGTC dataset, a taxonomy-specific fine-grained object counting dataset for natural images. Our method substantially enhances pre-trained state-of-the-art models on fine-grained taxon counting tasks, while using only synthetic data. Code and data to be released upon acceptance. </p>
<blockquote>
<p>å°‘é‡&#x2F;é›¶æ ·æœ¬ç›®æ ‡è®¡æ•°æ–¹æ³•å‡å°‘äº†å¤§é‡æ ‡æ³¨çš„éœ€æ±‚ï¼Œä½†åœ¨åŒºåˆ†ç²¾ç»†ç±»åˆ«æ—¶å¸¸å¸¸é‡åˆ°å›°éš¾ï¼Œç‰¹åˆ«æ˜¯åœ¨åŒä¸€åœºæ™¯ä¸­å‡ºç°å¤šä¸ªç›¸ä¼¼ç‰©ä½“æ—¶ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ— éœ€æ ‡æ³¨çš„æ–¹æ³•ï¼Œå¯ä»¥æ— ç¼åœ°å°†æ–°çš„ç²¾ç»†ç±»åˆ«é›†æˆåˆ°ç°æœ‰çš„å°‘é‡&#x2F;é›¶æ ·æœ¬è®¡æ•°æ¨¡å‹ä¸­ã€‚é€šè¿‡åˆ©ç”¨æ½œåœ¨ç”Ÿæˆæ¨¡å‹ï¼Œæˆ‘ä»¬åˆæˆé«˜è´¨é‡ã€ç‰¹å®šç±»åˆ«çš„æ‹¥æŒ¤åœºæ™¯ï¼Œä¸ºé€‚åº”æ–°ç±»åˆ«æä¾›äº†ä¸°å¯Œçš„è®­ç»ƒæºï¼Œæ— éœ€æ‰‹åŠ¨æ ‡æ³¨ã€‚æˆ‘ä»¬çš„æ–¹æ³•å¼•å…¥äº†ä¸€ä¸ªæ³¨æ„åŠ›é¢„æµ‹ç½‘ç»œï¼Œè¯¥ç½‘ç»œä½¿ç”¨ä»…åˆæˆä¼ªæ³¨é‡Šæ•°æ®æ¥è®­ç»ƒç²¾ç»†ç±»åˆ«è¾¹ç•Œã€‚åœ¨æ¨æ–­æ—¶ï¼Œè¿™äº›ç²¾ç»†çš„æ³¨æ„åŠ›ä¼°è®¡å€¼ä¼šä¼˜åŒ–ç°æœ‰çš„å°‘é‡&#x2F;é›¶æ ·æœ¬è®¡æ•°ç½‘ç»œçš„è¾“å‡ºã€‚ä¸ºäº†è¯„ä¼°æˆ‘ä»¬çš„æ–¹æ³•ï¼Œæˆ‘ä»¬è¿˜å¼•å…¥äº†FGTCæ•°æ®é›†ï¼Œè¿™æ˜¯ä¸€ä¸ªé’ˆå¯¹è‡ªç„¶å›¾åƒçš„ç‰¹å®šåˆ†ç±»ç²¾ç»†ç›®æ ‡è®¡æ•°æ•°æ®é›†ã€‚æˆ‘ä»¬çš„æ–¹æ³•åœ¨ç²¾ç»†ç±»åˆ«è®¡æ•°ä»»åŠ¡ä¸Šå¤§å¹…æé«˜äº†é¢„è®­ç»ƒçš„æœ€å…ˆè¿›æ¨¡å‹çš„è¡¨ç°ï¼Œä¸”ä»…ä½¿ç”¨åˆæˆæ•°æ®ã€‚è®ºæ–‡é€šè¿‡åå°†å…¬å¼€ä»£ç å’Œæ•°æ®ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.11705v1">PDF</a> </p>
<p><strong>æ€»ç»“</strong></p>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ç§æ— éœ€æ ‡æ³¨çš„ç²¾ç»†ç²’åº¦ç›®æ ‡è®¡æ•°æ–¹æ³•ï¼Œé€šè¿‡åˆ©ç”¨æ½œåœ¨ç”Ÿæˆæ¨¡å‹åˆæˆé«˜è´¨é‡ã€ç‰¹å®šç±»åˆ«çš„æ‹¥æŒ¤åœºæ™¯ï¼Œä¸ºç°æœ‰å°‘æ•°æˆ–é›¶æ ·æœ¬è®¡æ•°æ¨¡å‹é€‚åº”æ–°ç±»åˆ«æä¾›äº†ä¸°å¯Œçš„è®­ç»ƒæ¥æºã€‚å¼•å…¥æ³¨æ„åŠ›é¢„æµ‹ç½‘ç»œæ¥è¯†åˆ«ä»…ä½¿ç”¨åˆæˆä¼ªæ ‡æ³¨æ•°æ®è®­ç»ƒçš„ç²¾ç»†ç²’åº¦ç±»åˆ«è¾¹ç•Œã€‚åœ¨æ¨ç†è¿‡ç¨‹ä¸­ï¼Œè¿™äº›ç²¾ç»†ç²’åº¦æ³¨æ„åŠ›ä¼°è®¡å¯¹ç°æœ‰çš„å°‘æ•°æˆ–é›¶æ ·æœ¬è®¡æ•°ç½‘ç»œè¾“å‡ºè¿›è¡Œäº†æ”¹è¿›ã€‚æ–°æ–¹æ³•æå¤§åœ°æå‡äº†é¢„è®­ç»ƒå…ˆè¿›æ¨¡å‹åœ¨ç²¾ç»†ç²’åº¦åˆ†ç±»è®¡æ•°ä»»åŠ¡ä¸Šçš„æ€§èƒ½ï¼Œä¸”ä»…ä½¿ç”¨åˆæˆæ•°æ®ã€‚</p>
<p><strong>å…³é”®è§è§£</strong></p>
<ol>
<li>å°‘æ•°æˆ–é›¶æ ·æœ¬ç›®æ ‡è®¡æ•°æ–¹æ³•å¯ä»¥å‡å°‘å¯¹å¤§é‡æ ‡æ³¨çš„éœ€æ±‚ï¼Œä½†åœ¨åŒºåˆ†ç²¾ç»†ç²’åº¦ç±»åˆ«æ—¶ç»å¸¸é‡åˆ°å›°éš¾ã€‚</li>
<li>æå‡ºäº†ä¸€ç§æ— éœ€æ ‡æ³¨çš„ç²¾ç»†ç²’åº¦è®¡æ•°æ–¹æ³•ï¼Œåˆ©ç”¨æ½œåœ¨ç”Ÿæˆæ¨¡å‹åˆæˆç‰¹å®šç±»åˆ«çš„æ‹¥æŒ¤åœºæ™¯ã€‚</li>
<li>é€šè¿‡å¼•å…¥æ³¨æ„åŠ›é¢„æµ‹ç½‘ç»œï¼Œèƒ½å¤Ÿä½¿ç”¨ä»…åˆæˆçš„ä¼ªæ ‡æ³¨æ•°æ®è¿›è¡Œè®­ç»ƒï¼Œè¯†åˆ«ç²¾ç»†ç²’åº¦ç±»åˆ«è¾¹ç•Œã€‚</li>
<li>æå‡ºäº†æ–°çš„æ•°æ®é›†FGTCï¼Œä¸“ä¸ºè‡ªç„¶å›¾åƒçš„ç²¾ç»†ç²’åº¦ç›®æ ‡è®¡æ•°è€Œè®¾è®¡ã€‚</li>
<li>æ–¹æ³•åœ¨é¢„è®­ç»ƒçš„å…ˆè¿›æ¨¡å‹ä¸Šæ˜¾è‘—æé«˜äº†åœ¨ç²¾ç»†ç²’åº¦è®¡æ•°ä»»åŠ¡ä¸Šçš„æ€§èƒ½ã€‚</li>
<li>è¯¥æ–¹æ³•ä»…ä½¿ç”¨åˆæˆæ•°æ®ï¼Œé™ä½äº†å¯¹çœŸå®æ ‡æ³¨æ•°æ®çš„ä¾èµ–ã€‚</li>
<li>ä»£ç å’Œæ•°æ®å°†åœ¨æ¥å—åå‘å¸ƒã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.11705">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-de933534688e262ec819dd11912dc2eb.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-152bd2670273b1edd1388edd817e804b.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-5301264934dc6d26439a67d8a41ad7ce.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-afcd78f1335d78aff3a3980f90236ba5.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-f73090ed06c3ac06b13972021dff61b5.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-0d186dcc1a0b1741166853a911c74041.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a2b8827c9021526a92bc5f65fa3fb172.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-af5b18dbc2d3b5949a23608b9747fb20.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="Can-GPT-tell-us-why-these-images-are-synthesized-Empowering-Multimodal-Large-Language-Models-for-Forensics"><a href="#Can-GPT-tell-us-why-these-images-are-synthesized-Empowering-Multimodal-Large-Language-Models-for-Forensics" class="headerlink" title="Can GPT tell us why these images are synthesized? Empowering Multimodal   Large Language Models for Forensics"></a>Can GPT tell us why these images are synthesized? Empowering Multimodal   Large Language Models for Forensics</h2><p><strong>Authors:Yiran He, Yun Cao, Bowen Yang, Zeyu Zhang</strong></p>
<p>The rapid development of generative AI facilitates content creation and makes image manipulation easier and more difficult to detect. While multimodal Large Language Models (LLMs) have encoded rich world knowledge, they are not inherently tailored for combating AI-generated Content (AIGC) and struggle to comprehend local forgery details. In this work, we investigate the application of multimodal LLMs in forgery detection. We propose a framework capable of evaluating image authenticity, localizing tampered regions, providing evidence, and tracing generation methods based on semantic tampering clues. Our method demonstrates that the potential of LLMs in forgery analysis can be effectively unlocked through meticulous prompt engineering and the application of few-shot learning techniques. We conduct qualitative and quantitative experiments and show that GPT4V can achieve an accuracy of 92.1% in Autosplice and 86.3% in LaMa, which is competitive with state-of-the-art AIGC detection methods. We further discuss the limitations of multimodal LLMs in such tasks and propose potential improvements. </p>
<blockquote>
<p>éšç€ç”Ÿæˆå¼AIçš„å¿«é€Ÿå‘å±•ï¼Œå†…å®¹åˆ›å»ºå˜å¾—æ›´åŠ å®¹æ˜“ï¼Œå›¾åƒæ“ä½œä¹Ÿå˜å¾—æ›´åŠ ç®€å•ä¸”éš¾ä»¥æ£€æµ‹ã€‚è™½ç„¶å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å·²ç»ç¼–ç äº†ä¸°å¯Œçš„ä¸–ç•ŒçŸ¥è¯†ï¼Œä½†å®ƒä»¬å¹¶éå¤©ç”Ÿå°±é€‚åˆå¯¹æŠ—AIç”Ÿæˆçš„å†…å®¹ï¼ˆAIGCï¼‰ï¼Œåœ¨ç†è§£å±€éƒ¨ä¼ªé€ ç»†èŠ‚æ–¹é¢å­˜åœ¨å›°éš¾ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬ç ”ç©¶äº†å¤šæ¨¡æ€LLMåœ¨ä¼ªé€ æ£€æµ‹ä¸­çš„åº”ç”¨ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªèƒ½å¤Ÿè¯„ä¼°å›¾åƒçœŸå®æ€§ã€å®šä½ç¯¡æ”¹åŒºåŸŸã€æä¾›è¯æ®å¹¶æ ¹æ®è¯­ä¹‰ç¯¡æ”¹çº¿ç´¢è¿½è¸ªç”Ÿæˆæ–¹æ³•çš„æ¡†æ¶ã€‚æˆ‘ä»¬çš„æ–¹æ³•è¡¨æ˜ï¼Œé€šè¿‡ç»†è‡´çš„æç¤ºå·¥ç¨‹å’Œå°‘é‡å­¦ä¹ æŠ€æœ¯çš„åº”ç”¨ï¼ŒLLMåœ¨ä¼ªé€ åˆ†æä¸­çš„æ½œåŠ›å¯ä»¥å¾—åˆ°æœ‰æ•ˆè§£é”ã€‚æˆ‘ä»¬è¿›è¡Œäº†å®šæ€§å’Œå®šé‡å®éªŒï¼Œç»“æœè¡¨æ˜GPT4Våœ¨Autospliceä¸­å¯ä»¥è¾¾åˆ°92.1%çš„å‡†ç¡®ç‡ï¼Œåœ¨LaMaä¸­å¯ä»¥è¾¾åˆ°86.3%ï¼Œä¸æœ€å…ˆè¿›çš„AIGCæ£€æµ‹æ–¹æ³•å…·æœ‰ç«äº‰åŠ›ã€‚æˆ‘ä»¬è¿˜è¿›ä¸€æ­¥è®¨è®ºäº†å¤šæ¨¡æ€LLMåœ¨æ­¤ç±»ä»»åŠ¡ä¸­çš„å±€é™æ€§ï¼Œå¹¶æå‡ºäº†æ½œåœ¨çš„æ”¹è¿›æ–¹æ³•ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.11686v1">PDF</a> 12 pages, 11 figures, 13IHMMSec2025</p>
<p><strong>Summary</strong><br>     ç”Ÿæˆæ€§AIçš„å¿«é€Ÿå‘å±•ä¿ƒè¿›äº†å†…å®¹åˆ›ä½œï¼Œä½¿å¾—å›¾åƒæ“ä½œæ›´åŠ å®¹æ˜“ä¸”éš¾ä»¥æ£€æµ‹ã€‚æœ¬ç ”ç©¶æ¢è®¨äº†å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨ä¼ªé€ æ£€æµ‹ä¸­çš„åº”ç”¨ï¼Œæå‡ºäº†ä¸€ç§èƒ½å¤Ÿè¯„ä¼°å›¾åƒçœŸå®æ€§ã€å®šä½ç¯¡æ”¹åŒºåŸŸã€æä¾›è¯æ®å¹¶è¿½æº¯åŸºäºè¯­ä¹‰ç¯¡æ”¹çº¿ç´¢çš„ç”Ÿæˆæ–¹æ³•çš„æ¡†æ¶ã€‚è¯¥ç ”ç©¶é€šè¿‡ç²¾ç»†çš„æç¤ºå·¥ç¨‹å’Œå°‘æ ·æœ¬å­¦ä¹ æŠ€æœ¯çš„åº”ç”¨ï¼Œå±•ç¤ºäº†LLMåœ¨ä¼ªé€ åˆ†æä¸­çš„æ½œåŠ›ã€‚å®éªŒè¡¨æ˜ï¼ŒGPT4Våœ¨Autospliceå’ŒLaMaä»»åŠ¡ä¸­çš„å‡†ç¡®ç‡åˆ†åˆ«è¾¾åˆ°äº†92.1%å’Œ86.3%ï¼Œå…·æœ‰ä¸æœ€æ–°AIGCæ£€æµ‹æ–¹æ³•ç«äº‰çš„å®åŠ›ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ç”Ÿæˆæ€§AIä¿ƒè¿›äº†å†…å®¹åˆ›ä½œï¼Œä½¿å¾—å›¾åƒæ“ä½œæ›´æ˜“äºè¿›è¡Œä¸”éš¾ä»¥æ£€æµ‹ã€‚</li>
<li>å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨ä¼ªé€ æ£€æµ‹ä¸­å…·æœ‰æ½œåœ¨åº”ç”¨ä»·å€¼ã€‚</li>
<li>æå‡ºçš„æ¡†æ¶èƒ½å¤Ÿè¯„ä¼°å›¾åƒçœŸå®æ€§ã€å®šä½ç¯¡æ”¹åŒºåŸŸï¼Œå¹¶æä¾›è¯æ®å’Œè¿½æº¯ç”Ÿæˆæ–¹æ³•ã€‚</li>
<li>é€šè¿‡ç²¾ç»†çš„æç¤ºå·¥ç¨‹å’Œå°‘æ ·æœ¬å­¦ä¹ æŠ€æœ¯çš„åº”ç”¨ï¼ŒLLMåœ¨ä¼ªé€ åˆ†æä¸­çš„æ½œåŠ›å¾—ä»¥è§£é”ã€‚</li>
<li>GPT4Våœ¨Autospliceå’ŒLaMaä»»åŠ¡ä¸­çš„å‡†ç¡®ç‡è¾ƒé«˜ï¼Œå…·æœ‰ç«äº‰åŠ›ã€‚</li>
<li>ç ”ç©¶è®¨è®ºäº†å¤šæ¨¡æ€LLMåœ¨æ­¤ç±»ä»»åŠ¡ä¸­çš„å±€é™æ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.11686">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-4abedfe9546d57e5537f0ab084997771.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-5746052502c346a60b819fd9fc885c45.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-3ec1c902c01e3376c3dd32a071341e00.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-9148f7226d866d1dbc8494045216b23e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-9e3e59f057c0424dfece41963c87be87.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-980ed3dd2866d5a11dbb58f46195addb.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="Kernel-Aware-Graph-Prompt-Learning-for-Few-Shot-Anomaly-Detection"><a href="#Kernel-Aware-Graph-Prompt-Learning-for-Few-Shot-Anomaly-Detection" class="headerlink" title="Kernel-Aware Graph Prompt Learning for Few-Shot Anomaly Detection"></a>Kernel-Aware Graph Prompt Learning for Few-Shot Anomaly Detection</h2><p><strong>Authors:Fenfang Tao, Guo-Sen Xie, Fang Zhao, Xiangbo Shu</strong></p>
<p>Few-shot anomaly detection (FSAD) aims to detect unseen anomaly regions with the guidance of very few normal support images from the same class. Existing FSAD methods usually find anomalies by directly designing complex text prompts to align them with visual features under the prevailing large vision-language model paradigm. However, these methods, almost always, neglect intrinsic contextual information in visual features, e.g., the interaction relationships between different vision layers, which is an important clue for detecting anomalies comprehensively. To this end, we propose a kernel-aware graph prompt learning framework, termed as KAG-prompt, by reasoning the cross-layer relations among visual features for FSAD. Specifically, a kernel-aware hierarchical graph is built by taking the different layer features focusing on anomalous regions of different sizes as nodes, meanwhile, the relationships between arbitrary pairs of nodes stand for the edges of the graph. By message passing over this graph, KAG-prompt can capture cross-layer contextual information, thus leading to more accurate anomaly prediction. Moreover, to integrate the information of multiple important anomaly signals in the prediction map, we propose a novel image-level scoring method based on multi-level information fusion. Extensive experiments on MVTecAD and VisA datasets show that KAG-prompt achieves state-of-the-art FSAD results for image-level&#x2F;pixel-level anomaly detection. Code is available at <a target="_blank" rel="noopener" href="https://github.com/CVL-hub/KAG-prompt.git">https://github.com/CVL-hub/KAG-prompt.git</a>. </p>
<blockquote>
<p>å°æ ·å¼‚å¸¸æ£€æµ‹ï¼ˆFSADï¼‰æ—¨åœ¨ä½¿ç”¨åŒä¸€ç±»åˆ«ä¸­çš„å°‘é‡æ­£å¸¸æ”¯æŒå›¾åƒæ¥æ£€æµ‹æœªè§çš„å¼‚å¸¸åŒºåŸŸã€‚ç°æœ‰çš„FSADæ–¹æ³•é€šå¸¸é€šè¿‡ç›´æ¥è®¾è®¡å¤æ‚çš„æ–‡æœ¬æç¤ºæ¥ä¸æµè¡Œçš„å¤§å‹è§†è§‰è¯­è¨€æ¨¡å‹èŒƒå¼ä¸‹çš„è§†è§‰ç‰¹å¾å¯¹é½æ¥å‘ç°å¼‚å¸¸ã€‚ç„¶è€Œï¼Œè¿™äº›æ–¹æ³•å‡ ä¹æ€»æ˜¯å¿½ç•¥äº†è§†è§‰ç‰¹å¾ä¸­çš„å†…åœ¨ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œä¾‹å¦‚ä¸åŒè§†è§‰å±‚ä¹‹é—´çš„äº¤äº’å…³ç³»ï¼Œè¿™æ˜¯å…¨é¢æ£€æµ‹å¼‚å¸¸çš„é‡è¦çº¿ç´¢ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªæ ¸å¿ƒæ„ŸçŸ¥å›¾æç¤ºå­¦ä¹ æ¡†æ¶ï¼Œç§°ä¸ºKAG-promptï¼Œé€šè¿‡æ¨ç†è§†è§‰ç‰¹å¾ä¹‹é—´çš„è·¨å±‚å…³ç³»æ¥è¿›è¡ŒFSADã€‚å…·ä½“æ¥è¯´ï¼Œä»¥å…³æ³¨ä¸åŒå¤§å°å¼‚å¸¸åŒºåŸŸçš„ä¸åŒå±‚ç‰¹å¾ä½œä¸ºèŠ‚ç‚¹ï¼Œæ„å»ºäº†ä¸€ä¸ªæ ¸å¿ƒæ„ŸçŸ¥åˆ†å±‚å›¾ï¼ŒåŒæ—¶ï¼Œä»»æ„èŠ‚ç‚¹å¯¹ä¹‹é—´çš„å…³ç³»ä»£è¡¨å›¾çš„è¾¹ã€‚é€šè¿‡åœ¨æ­¤å›¾ä¸Šè¿›è¡Œæ¶ˆæ¯ä¼ é€’ï¼ŒKAG-promptå¯ä»¥æ•è·è·¨å±‚ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œä»è€Œå¯¼è‡´æ›´å‡†ç¡®çš„å¼‚å¸¸é¢„æµ‹ã€‚æ­¤å¤–ï¼Œä¸ºäº†æ•´åˆé¢„æµ‹å›¾ä¸­å¤šä¸ªé‡è¦å¼‚å¸¸ä¿¡å·çš„ä¿¡æ¯ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åŸºäºå¤šå±‚æ¬¡ä¿¡æ¯èåˆçš„æ–°å‹å›¾åƒçº§è¯„åˆ†æ–¹æ³•ã€‚åœ¨MVTecADå’ŒVisAæ•°æ®é›†ä¸Šçš„å¤§é‡å®éªŒè¡¨æ˜ï¼ŒKAG-promptåœ¨å›¾åƒçº§&#x2F;åƒç´ çº§çš„å¼‚å¸¸æ£€æµ‹ä¸­è¾¾åˆ°äº†æœ€å…ˆè¿›çš„FSADç»“æœã€‚ä»£ç å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/CVL-hub/KAG-prompt.git">https://github.com/CVL-hub/KAG-prompt.git</a>æ‰¾åˆ°ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.17619v2">PDF</a> Accepted to AAAI 2025</p>
<p><strong>Summary</strong><br>å°‘æ•°æ ·æœ¬å¼‚å¸¸æ£€æµ‹æ—¨åœ¨åˆ©ç”¨å°‘æ•°åŒç±»æ­£å¸¸æ ·æœ¬ä½œä¸ºå‚è€ƒè¿›è¡Œå¼‚å¸¸åŒºåŸŸæ£€æµ‹ã€‚ç°æœ‰æ–¹æ³•å¤§å¤šé€šè¿‡è®¾è®¡å¤æ‚çš„æ–‡æœ¬æç¤ºæ¥ä¸è§†è§‰ç‰¹å¾å¯¹é½ï¼Œä½†åœ¨å¤§å‹è§†è§‰è¯­è¨€æ¨¡å‹èŒƒå¼ä¸‹å¿½ç•¥äº†è§†è§‰ç‰¹å¾ä¸­çš„å†…åœ¨ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œå¦‚ä¸åŒè§†è§‰å±‚ä¹‹é—´çš„å…³ç³»ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªæ ¸å¿ƒæ„ŸçŸ¥å›¾æç¤ºå­¦ä¹ æ¡†æ¶KAG-promptï¼Œé€šè¿‡æ¨ç†ä¸åŒå±‚ä¹‹é—´çš„å…³ç³»æ¥è¿›è¡Œå°‘æ•°æ ·æœ¬å¼‚å¸¸æ£€æµ‹ã€‚KAG-prompté€šè¿‡æ„å»ºæ ¸å¿ƒæ„ŸçŸ¥å±‚æ¬¡å›¾æ¥æ•æ‰è·¨å±‚ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œå®ç°äº†æ›´å‡†ç¡®çš„å¼‚å¸¸é¢„æµ‹ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜æå‡ºäº†ä¸€ç§åŸºäºå¤šå±‚æ¬¡ä¿¡æ¯èåˆçš„æ–°å‹å›¾åƒçº§è¯„åˆ†æ–¹æ³•ï¼Œç”¨äºæ•´åˆé¢„æµ‹å›¾ä¸­çš„å¤šä¸ªé‡è¦å¼‚å¸¸ä¿¡å·ã€‚åœ¨MVTecADå’ŒVisAæ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒKAG-promptåœ¨å›¾åƒçº§å’Œåƒç´ çº§çš„å¼‚å¸¸æ£€æµ‹æ–¹é¢å–å¾—äº†æœ€å…ˆè¿›çš„å°‘æ•°æ ·æœ¬å¼‚å¸¸æ£€æµ‹ç»“æœã€‚ä»£ç å·²å…¬å¼€ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>å°‘æ•°æ ·æœ¬å¼‚å¸¸æ£€æµ‹çš„ç›®æ ‡æ˜¯å€ŸåŠ©å°‘æ•°åŒç±»æ­£å¸¸æ ·æœ¬æ£€æµ‹å¼‚å¸¸åŒºåŸŸã€‚</li>
<li>ç°æœ‰æ–¹æ³•ä¸»è¦é€šè¿‡å¤æ‚çš„æ–‡æœ¬æç¤ºä¸è§†è§‰ç‰¹å¾è¿›è¡Œå¯¹é½ï¼Œä½†å¿½ç•¥äº†è§†è§‰ç‰¹å¾çš„å†…åœ¨ä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚</li>
<li>KAG-promptæ¡†æ¶é€šè¿‡æ„å»ºæ ¸å¿ƒæ„ŸçŸ¥å±‚æ¬¡å›¾æ¥æ•æ‰è·¨å±‚ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œæé«˜å¼‚å¸¸æ£€æµ‹çš„å‡†ç¡®æ€§ã€‚</li>
<li>KAG-promptåˆ©ç”¨å¤šå±‚æ¬¡ä¿¡æ¯èåˆè¿›è¡Œå›¾åƒçº§è¯„åˆ†ï¼Œæ•´åˆé¢„æµ‹å›¾ä¸­çš„å¤šä¸ªé‡è¦å¼‚å¸¸ä¿¡å·ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.17619">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-2bf5b49007c9a7fdf3dd56b63f6107ca.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-19523772394d7833b31f5c466946e64f.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-da0b28b54c0b8692f44b391df54435db.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="Two-Effects-One-Trigger-On-the-Modality-Gap-Object-Bias-and-Information-Imbalance-in-Contrastive-Vision-Language-Models"><a href="#Two-Effects-One-Trigger-On-the-Modality-Gap-Object-Bias-and-Information-Imbalance-in-Contrastive-Vision-Language-Models" class="headerlink" title="Two Effects, One Trigger: On the Modality Gap, Object Bias, and   Information Imbalance in Contrastive Vision-Language Models"></a>Two Effects, One Trigger: On the Modality Gap, Object Bias, and   Information Imbalance in Contrastive Vision-Language Models</h2><p><strong>Authors:Simon Schrodi, David T. Hoffmann, Max Argus, Volker Fischer, Thomas Brox</strong></p>
<p>Contrastive vision-language models (VLMs), like CLIP, have gained popularity for their versatile applicability to various downstream tasks. Despite their successes in some tasks, like zero-shot object recognition, they perform surprisingly poor on other tasks, like attribute recognition. Previous work has attributed these challenges to the modality gap, a separation of image and text in the shared representation space, and to a bias towards objects over other factors, such as attributes. In this analysis paper, we investigate both phenomena thoroughly. We evaluated off-the-shelf VLMs and while the gapâ€™s influence on performance is typically overshadowed by other factors, we find indications that closing the gap indeed leads to improvements. Moreover, we find that, contrary to intuition, only few embedding dimensions drive the gap and that the embedding spaces are differently organized. To allow for a clean study of object bias, we introduce a definition and a corresponding measure of it. Equipped with this tool, we find that object bias does not lead to worse performance on other concepts, such as attributes per se. However, why do both phenomena, modality gap and object bias, emerge in the first place? To answer this fundamental question and uncover some of the inner workings of contrastive VLMs, we conducted experiments that allowed us to control the amount of shared information between the modalities. These experiments revealed that the driving factor behind both the modality gap and the object bias, is an information imbalance between images and captions, and unveiled an intriguing connection between the modality gap and entropy of the logits. </p>
<blockquote>
<p>å¯¹æ¯”è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMsï¼‰ï¼Œå¦‚CLIPï¼Œå› å…¶å¯¹å„ç§ä¸‹æ¸¸ä»»åŠ¡çš„é€šç”¨é€‚ç”¨æ€§è€Œå¹¿å—æ¬¢è¿ã€‚å°½ç®¡å®ƒä»¬åœ¨é›¶æ ·æœ¬ç›®æ ‡è¯†åˆ«ç­‰ä»»åŠ¡ä¸­å–å¾—äº†æˆåŠŸï¼Œä½†åœ¨å±æ€§è¯†åˆ«ç­‰å…¶ä»–ä»»åŠ¡ä¸Šçš„è¡¨ç°å´ä»¤äººæƒŠè®¶åœ°ä¸ä½³ã€‚ä»¥å‰çš„å·¥ä½œå°†è¿™äº›æŒ‘æˆ˜å½’å› äºæ¨¡æ€å·®è·ï¼Œå³å›¾åƒå’Œæ–‡æœ¬åœ¨å…±äº«è¡¨ç¤ºç©ºé—´ä¸­çš„åˆ†ç¦»ï¼Œä»¥åŠç›¸å¯¹äºå…¶ä»–å› ç´ ï¼ˆå¦‚å±æ€§ï¼‰å¯¹ç›®æ ‡çš„åå‘ã€‚åœ¨è¿™ç¯‡åˆ†æè®ºæ–‡ä¸­ï¼Œæˆ‘ä»¬å¯¹è¿™ä¸¤ç§ç°è±¡è¿›è¡Œäº†å½»åº•çš„ç ”ç©¶ã€‚æˆ‘ä»¬è¯„ä¼°äº†ç°æˆçš„VLMsï¼Œè™½ç„¶æ¨¡æ€å·®è·å¯¹æ€§èƒ½çš„å½±å“é€šå¸¸è¢«å…¶ä»–å› ç´ æ‰€æ©ç›–ï¼Œä½†æˆ‘ä»¬å‘ç°ç¼©å°å·®è·ç¡®å®ä¼šå¯¼è‡´æ€§èƒ½æé«˜çš„è¿¹è±¡ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å‘ç°ä¸ç›´è§‰ç›¸åçš„æ˜¯ï¼Œåªæœ‰å°‘æ•°åµŒå…¥ç»´åº¦åœ¨é©±åŠ¨å·®è·ï¼Œä¸”è¿™äº›åµŒå…¥ç©ºé—´çš„ç»„ç»‡æ–¹å¼æ˜¯ä¸åŒçš„ã€‚ä¸ºäº†èƒ½å¤Ÿå¯¹ç›®æ ‡åè§è¿›è¡Œæ¸…æ™°çš„ç ”ç©¶ï¼Œæˆ‘ä»¬å¼•å…¥äº†å®šä¹‰å’Œç›¸åº”çš„åº¦é‡æ ‡å‡†ã€‚åˆ©ç”¨è¿™ä¸€å·¥å…·ï¼Œæˆ‘ä»¬å‘ç°ç›®æ ‡åè§å¹¶ä¸ä¼šå¯¼è‡´å¯¹å±æ€§ç­‰æ¦‚å¿µçš„è¡¨ç°ä¸‹é™ã€‚ç„¶è€Œï¼Œä¸ºä»€ä¹ˆæ¨¡æ€å·®è·å’Œç›®æ ‡åè§è¿™ä¸¤ç§ç°è±¡é¦–å…ˆä¼šå‡ºç°å‘¢ï¼Ÿä¸ºäº†å›ç­”è¿™ä¸ªé—®é¢˜å¹¶æ­ç¤ºå¯¹æ¯”VLMsçš„ä¸€äº›å†…åœ¨å·¥ä½œåŸç†ï¼Œæˆ‘ä»¬è¿›è¡Œäº†ä¸€äº›å®éªŒï¼Œä»¥æ§åˆ¶å›¾åƒå’Œå­—å¹•ä¹‹é—´å…±äº«ä¿¡æ¯é‡çš„å¤šå°‘ã€‚è¿™äº›å®éªŒè¡¨æ˜ï¼Œæ¨¡æ€å·®è·å’Œç›®æ ‡åè§èƒŒåçš„é©±åŠ¨å› ç´ æ˜¯å›¾åƒå’Œå­—å¹•ä¹‹é—´çš„ä¿¡æ¯ä¸å¹³è¡¡ï¼Œå¹¶æ­ç¤ºäº†æ¨¡æ€å·®è·ä¸é€»è¾‘ç†µä¹‹é—´çš„æœ‰è¶£è”ç³»ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2404.07983v3">PDF</a> ICLR 2025 (Oral)</p>
<p><strong>Summary</strong></p>
<p>è¯¥åˆ†æè®ºæ–‡æ¢è®¨äº†å¯¹æ¯”è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆå¦‚CLIPï¼‰åœ¨ä¸‹æ¸¸ä»»åŠ¡åº”ç”¨ä¸­çš„æ€§èƒ½å·®å¼‚é—®é¢˜ã€‚å¯¹äºæ¨¡æ€é—´éš™å’ŒæŒ‘æˆ˜ï¼Œç ”ç©¶å‘ç°è¯¥é—´éš™é€šå¸¸åœ¨å…¶å®ƒå› ç´ æ©ç›–ä¸‹è¢«å¿½ç•¥ï¼Œä½†ç¼©å°é—´éš™èƒ½æé«˜æ€§èƒ½ã€‚ç ”ç©¶å‘ç°ï¼Œé©±åŠ¨é—´éš™çš„å…³é”®å› ç´ åœ¨äºå°‘é‡åµŒå…¥ç»´åº¦ï¼Œä¸”åµŒå…¥ç©ºé—´ç»„ç»‡ä¸åŒã€‚ä¸ºè§£å†³å¯¹è±¡åè§é—®é¢˜ï¼Œè®ºæ–‡å¼•å…¥äº†å®šä¹‰å’Œç›¸åº”åº¦é‡æ ‡å‡†ã€‚ç ”ç©¶è¿˜å‘ç°å¯¹è±¡åè§å¹¶ä¸ä¼šå¯¼è‡´å…¶ä»–æ¦‚å¿µï¼ˆå¦‚å±æ€§ï¼‰æ€§èƒ½æ¶åŒ–ã€‚æœ€ç»ˆå®éªŒæ˜¾ç¤ºï¼Œå›¾åƒå’Œå­—å¹•é—´ä¿¡æ¯é‡å¤±è¡¡æ˜¯é©±åŠ¨æ¨¡æ€é—´éš™å’Œå¯¹è±¡åè§çš„ä¸»è¦å› ç´ ï¼Œå¹¶æ­ç¤ºäº†æ¨¡æ€é—´éš™ä¸å¯¹æ•°ç†µä¹‹é—´çš„æœ‰è¶£è”ç³»ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¯¹æ¯”è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMsï¼‰åœ¨å¤šç§ä¸‹æ¸¸ä»»åŠ¡ä¸­è¡¨ç°å‡ºå¹¿æ³›çš„åº”ç”¨æ€§ï¼Œä½†åœ¨æŸäº›ä»»åŠ¡ä¸Šè¡¨ç°ä¸ä½³ã€‚</li>
<li>æ¨¡æ€é—´éš™æ˜¯å›¾åƒå’Œæ–‡æœ¬åœ¨å…±äº«è¡¨ç¤ºç©ºé—´ä¸­çš„åˆ†ç¦»ï¼Œå¯¹æ€§èƒ½å½±å“è¢«å…¶å®ƒå› ç´ æ©ç›–ï¼Œä½†ç¼©å°é—´éš™æœ‰åŠ©äºæé«˜æ€§èƒ½ã€‚</li>
<li>åªæœ‰å°‘æ•°åµŒå…¥ç»´åº¦é©±åŠ¨æ¨¡æ€é—´éš™ï¼Œä¸”åµŒå…¥ç©ºé—´ç»„ç»‡æ–¹å¼ä¸åŒã€‚</li>
<li>è®ºæ–‡å¼•å…¥äº†å¯¹è±¡åè§çš„å®šä¹‰å’Œç›¸åº”åº¦é‡æ ‡å‡†ã€‚</li>
<li>å¯¹è±¡åè§å¹¶ä¸ä¼šå¯¼è‡´å¯¹å±æ€§ç­‰å…¶å®ƒæ¦‚å¿µçš„æ€§èƒ½æ¶åŒ–ã€‚</li>
<li>ä¿¡æ¯é‡å¤±è¡¡æ˜¯é©±åŠ¨æ¨¡æ€é—´éš™å’Œå¯¹è±¡åè§çš„ä¸»è¦å› ç´ ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2404.07983">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-dafcd670e4aa8fef623c8d4a48245ee1.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-cf80f74e94973c0f564b8a205fd72f55.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-dc6ec02557bc39ba58d33e9176a84dbc.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-0bb034e8d18b8cfe3e506ce933cb934c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-8eacf60a70ffda991368c5c92964013f.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-04-18/Few-Shot/">https://kedreamix.github.io/Talk2Paper/Paper/2025-04-18/Few-Shot/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/Few-Shot/">
                                    <span class="chip bg-color">Few-Shot</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-04-18/I2I%20Translation/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-ca1f712f6ee96a259fc29c0453b3053f.jpg" class="responsive-img" alt="I2I Translation">
                        
                        <span class="card-title">I2I Translation</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            I2I Translation æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-04-18  Flow Intelligence Robust Feature Matching via Temporal Signature   Correlation
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-04-18
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/I2I-Translation/" class="post-category">
                                    I2I Translation
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/I2I-Translation/">
                        <span class="chip bg-color">I2I Translation</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-04-18/Agent/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-3a50c7d599d569532aa2b777fa0f53a9.jpg" class="responsive-img" alt="Agent">
                        
                        <span class="card-title">Agent</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Agent æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-04-18  ARCeR an Agentic RAG for the Automated Definition of Cyber Ranges
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-04-18
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Agent/" class="post-category">
                                    Agent
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Agent/">
                        <span class="chip bg-color">Agent</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">22950.1k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
