<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Agent">
    <meta name="description" content="Agent æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-04-18  ARCeR an Agentic RAG for the Automated Definition of Cyber Ranges">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>Agent | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://picx.zhimg.com/v2-3a50c7d599d569532aa2b777fa0f53a9.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Agent</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/Agent/">
                                <span class="chip bg-color">Agent</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/Agent/" class="post-category">
                                Agent
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-04-18
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-05-14
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    11.9k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    48 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-04-18-æ›´æ–°"><a href="#2025-04-18-æ›´æ–°" class="headerlink" title="2025-04-18 æ›´æ–°"></a>2025-04-18 æ›´æ–°</h1><h2 id="ARCeR-an-Agentic-RAG-for-the-Automated-Definition-of-Cyber-Ranges"><a href="#ARCeR-an-Agentic-RAG-for-the-Automated-Definition-of-Cyber-Ranges" class="headerlink" title="ARCeR: an Agentic RAG for the Automated Definition of Cyber Ranges"></a>ARCeR: an Agentic RAG for the Automated Definition of Cyber Ranges</h2><p><strong>Authors:Matteo Lupinacci, Francesco Blefari, Francesco Romeo, Francesco Aurelio Pironti, Angelo Furfaro</strong></p>
<p>The growing and evolving landscape of cybersecurity threats necessitates the development of supporting tools and platforms that allow for the creation of realistic IT environments operating within virtual, controlled settings as Cyber Ranges (CRs). CRs can be exploited for analyzing vulnerabilities and experimenting with the effectiveness of devised countermeasures, as well as serving as training environments for building cyber security skills and abilities for IT operators. This paper proposes ARCeR as an innovative solution for the automatic generation and deployment of CRs, starting from user-provided descriptions in a natural language. ARCeR relies on the Agentic RAG paradigm, which allows it to fully exploit state-of-art AI technologies. Experimental results show that ARCeR is able to successfully process prompts even in cases that LLMs or basic RAG systems are not able to cope with. Furthermore, ARCeR is able to target any CR framework provided that specific knowledge is made available to it. </p>
<blockquote>
<p>ç½‘ç»œå®‰å…¨å¨èƒçš„ä¸æ–­å¢é•¿å’Œæ¼”å˜ï¼Œéœ€è¦å¼€å‘æ”¯æŒå·¥å…·å’Œå¹³å°ï¼Œä»¥åœ¨è™šæ‹Ÿã€å—æ§çš„ç¯å¢ƒä¸­åˆ›å»ºç°å®çš„ITç¯å¢ƒä½œä¸ºç½‘ç»œå®‰å…¨èŒƒå›´ï¼ˆCRsï¼‰ã€‚ç½‘ç»œå®‰å…¨èŒƒå›´å¯ç”¨äºåˆ†ææ¼æ´ï¼Œæµ‹è¯•åˆ¶å®šçš„å¯¹ç­–çš„æœ‰æ•ˆæ€§ï¼Œè¿˜å¯ä»¥ä½œä¸ºæ„å»ºç½‘ç»œå®‰å…¨æŠ€èƒ½å’Œæé«˜itæ“ä½œå‘˜èƒ½åŠ›çš„è®­ç»ƒç¯å¢ƒã€‚æœ¬æ–‡æå‡ºARCeRä½œä¸ºä¸€ç§åˆ›æ–°è§£å†³æ–¹æ¡ˆï¼Œå¯ä»¥æ ¹æ®ç”¨æˆ·æä¾›è‡ªç„¶è¯­è¨€çš„æè¿°è‡ªåŠ¨ç”Ÿæˆå¹¶éƒ¨ç½²ç½‘ç»œå®‰å…¨èŒƒå›´ã€‚ARCeRä¾èµ–äºAgentic RAGèŒƒå¼ï¼Œå¯ä»¥å……åˆ†åˆ©ç”¨æœ€æ–°çš„AIæŠ€æœ¯ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œå³ä½¿åœ¨ä¸€äº›æƒ…å†µä¸‹å¤§å‹è¯­è¨€æ¨¡å‹æˆ–åŸºæœ¬çš„RAGç³»ç»Ÿæ— æ³•åº”å¯¹ï¼ŒARCeRä¹Ÿèƒ½æˆåŠŸå¤„ç†æç¤ºã€‚æ­¤å¤–ï¼Œåªè¦å‘å…¶æä¾›ç‰¹å®šçŸ¥è¯†ï¼ŒARCeRå°±èƒ½é’ˆå¯¹ä»»ä½•ç½‘ç»œå®‰å…¨èŒƒå›´æ¡†æ¶è¿›è¡Œéƒ¨ç½²ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.12143v1">PDF</a> </p>
<p><strong>Summary</strong><br>     ç½‘ç»œå®‰å…¨å¨èƒçš„ä¸æ–­å‘å±•å’Œæ¼”å˜å‚¬ç”Ÿäº†å¯¹æ”¯æŒå·¥å…·å’Œå¹³å°çš„éœ€æ±‚ï¼Œè¿™äº›å·¥å…·å¯ä»¥åˆ›å»ºåœ¨è™šæ‹Ÿã€å—æ§ç¯å¢ƒä¸­è¿è¡Œçš„ç°å®ITç¯å¢ƒï¼Œç§°ä¸ºç½‘ç»œå®‰å…¨èŒƒå›´ï¼ˆCRï¼‰ã€‚ç½‘ç»œå®‰å…¨èŒƒå›´å¯ç”¨äºåˆ†ææ¼æ´ã€æµ‹è¯•åˆ¶å®šçš„å¯¹ç­–çš„æœ‰æ•ˆæ€§ï¼Œå¹¶ä½œä¸ºåŸ¹è®­ç¯å¢ƒï¼ŒåŸ¹å…»ç½‘ç»œå®‰å…¨æŠ€èƒ½å’Œèƒ½åŠ›ã€‚æœ¬æ–‡æå‡ºARCeRä½œä¸ºä¸€ç§åˆ›æ–°çš„è§£å†³æ–¹æ¡ˆï¼Œå¯ä»¥æ ¹æ®ç”¨æˆ·æä¾›çš„è‡ªç„¶è¯­è¨€æè¿°è‡ªåŠ¨ç”Ÿæˆå’Œéƒ¨ç½²ç½‘ç»œå®‰å…¨èŒƒå›´ã€‚ARCeRä¾èµ–äºAgentic RAGèŒƒå¼ï¼Œèƒ½å¤Ÿå……åˆ†åˆ©ç”¨æœ€æ–°çš„AIæŠ€æœ¯ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒARCeRèƒ½å¤Ÿåœ¨å¤§å‹è¯­è¨€æ¨¡å‹æˆ–åŸºæœ¬RAGç³»ç»Ÿæ— æ³•å¤„ç†çš„æƒ…å†µä¸‹æˆåŠŸå¤„ç†æç¤ºã€‚æ­¤å¤–ï¼Œåªè¦å‘å…¶æä¾›ç‰¹å®šçŸ¥è¯†ï¼ŒARCeRå°±èƒ½å¤Ÿé’ˆå¯¹ä»»ä½•ç½‘ç»œå®‰å…¨èŒƒå›´æ¡†æ¶è¿›è¡Œéƒ¨ç½²ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ç½‘ç»œå®‰å…¨å¨èƒçš„æ¼”å˜æ¨åŠ¨äº†ç½‘ç»œå®‰å…¨èŒƒå›´ï¼ˆCRï¼‰çš„å‘å±•ï¼Œç”¨äºåˆ†æå’Œæµ‹è¯•æ¼æ´ä»¥åŠæé«˜ç½‘ç»œå®‰å…¨æŠ€èƒ½å’Œèƒ½åŠ›çš„åŸ¹è®­ã€‚</li>
<li>ARCeRæ˜¯ä¸€ç§åˆ›æ–°çš„è§£å†³æ–¹æ¡ˆï¼Œå¯ä»¥æ ¹æ®ç”¨æˆ·æä¾›çš„è‡ªç„¶è¯­è¨€æè¿°è‡ªåŠ¨ç”Ÿæˆå’Œéƒ¨ç½²ç½‘ç»œå®‰å…¨èŒƒå›´ã€‚</li>
<li>ARCeRä¾èµ–äºAgentic RAGèŒƒå¼ï¼Œèƒ½å¤Ÿå……åˆ†åˆ©ç”¨æœ€æ–°çš„AIæŠ€æœ¯æ¥æå‡ç”Ÿæˆè¿‡ç¨‹çš„æ™ºèƒ½åŒ–å’Œè‡ªåŠ¨åŒ–æ°´å¹³ã€‚</li>
<li>å®éªŒç»“æœæ˜¾ç¤ºï¼ŒARCeRåœ¨ç‰¹å®šåœºæ™¯ä¸‹æ¯”ç°æœ‰ç³»ç»Ÿæ›´å…·ä¼˜åŠ¿ï¼Œå¯ä»¥æˆåŠŸå¤„ç†å…¶ä»–ç³»ç»Ÿæ— æ³•åº”å¯¹çš„æç¤ºã€‚</li>
<li>ARCeRå…·æœ‰å¹¿æ³›çš„é€‚ç”¨æ€§ï¼Œèƒ½å¤Ÿæ”¯æŒå¤šç§ç½‘ç»œå®‰å…¨èŒƒå›´æ¡†æ¶ï¼Œåªè¦å‘å…¶æä¾›ç‰¹å®šçŸ¥è¯†å³å¯è¿›è¡Œéƒ¨ç½²å’Œåº”ç”¨ã€‚</li>
<li>ARCeRåœ¨æé«˜ç½‘ç»œå®‰å…¨å’Œæ¨åŠ¨ç½‘ç»œå®‰å…¨æŠ€èƒ½æå‡æ–¹é¢å…·æœ‰é‡è¦çš„å®é™…åº”ç”¨ä»·å€¼ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.12143">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-147ed9534f582c42439d7b07507c407c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d246b7fcb203a0311e43c7e233da27fe.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="EmoACT-a-Framework-to-Embed-Emotions-into-Artificial-Agents-Based-on-Affect-Control-Theory"><a href="#EmoACT-a-Framework-to-Embed-Emotions-into-Artificial-Agents-Based-on-Affect-Control-Theory" class="headerlink" title="EmoACT: a Framework to Embed Emotions into Artificial Agents Based on   Affect Control Theory"></a>EmoACT: a Framework to Embed Emotions into Artificial Agents Based on   Affect Control Theory</h2><p><strong>Authors:Francesca Corrao, Alice Nardelli, Jennifer Renoux, Carmine Tommaso Recchiuto</strong></p>
<p>As robots and artificial agents become increasingly integrated into daily life, enhancing their ability to interact with humans is essential. Emotions, which play a crucial role in human interactions, can improve the naturalness and transparency of human-robot interactions (HRI) when embodied in artificial agents. This study aims to employ Affect Control Theory (ACT), a psychological model of emotions deeply rooted in interaction, for the generation of synthetic emotions. A platform-agnostic framework inspired by ACT was developed and implemented in a humanoid robot to assess its impact on human perception. Results show that the frequency of emotional displays impacts how users perceive the robot. Moreover, appropriate emotional expressions seem to enhance the robotâ€™s perceived emotional and cognitive agency. The findings suggest that ACT can be successfully employed to embed synthetic emotions into robots, resulting in effective human-robot interactions, where the robot is perceived more as a social agent than merely a machine. </p>
<blockquote>
<p>éšç€æœºå™¨äººå’Œäººå·¥ä»£ç†åœ¨æ—¥å¸¸ç”Ÿæ´»ä¸­å¾—åˆ°è¶Šæ¥è¶Šæ·±å…¥çš„æ•´åˆï¼Œå¢å¼ºä»–ä»¬ä¸äººç±»äº’åŠ¨çš„èƒ½åŠ›å˜å¾—è‡³å…³é‡è¦ã€‚æƒ…æ„Ÿåœ¨äººç±»äº’åŠ¨ä¸­æ‰®æ¼”ç€è‡³å…³é‡è¦çš„è§’è‰²ï¼Œå½“èå…¥åˆ°äººå·¥ä»£ç†ä¸­æ—¶ï¼Œæƒ…æ„Ÿå¯ä»¥æé«˜äººæœºäº’åŠ¨çš„è‡ªç„¶æ€§å’Œé€æ˜åº¦ã€‚æœ¬ç ”ç©¶æ—¨åœ¨é‡‡ç”¨æƒ…æ„Ÿæ§åˆ¶ç†è®ºï¼ˆACTï¼‰ï¼Œè¿™æ˜¯ä¸€ç§æ·±æ·±æ ¹æ¤äºäº’åŠ¨ä¸­çš„æƒ…æ„Ÿå¿ƒç†å­¦æ¨¡å‹ï¼Œæ¥ç”Ÿæˆåˆæˆæƒ…æ„Ÿã€‚å—ACTå¯å‘çš„å¹³å°æ— å…³æ¡†æ¶è¢«å¼€å‘å¹¶åº”ç”¨åœ¨äººå½¢æœºå™¨äººä¸Šï¼Œä»¥è¯„ä¼°å…¶å¯¹äººç±»æ„ŸçŸ¥çš„å½±å“ã€‚ç»“æœè¡¨æ˜ï¼Œæƒ…æ„Ÿå±•ç¤ºçš„é¢‘ç‡ä¼šå½±å“ç”¨æˆ·å¦‚ä½•æ„ŸçŸ¥æœºå™¨äººã€‚æ­¤å¤–ï¼Œé€‚å½“çš„æƒ…æ„Ÿè¡¨è¾¾ä¼¼ä¹å¢å¼ºäº†æœºå™¨äººæ„ŸçŸ¥åˆ°çš„æƒ…æ„Ÿå’Œè®¤çŸ¥èƒ½åŠ›ã€‚ç ”ç©¶ç»“æœå»ºè®®ï¼Œå¯ä»¥æˆåŠŸè¿ç”¨ACTå°†åˆæˆæƒ…æ„ŸåµŒå…¥æœºå™¨äººï¼Œä»è€Œå®ç°æœ‰æ•ˆçš„äººæœºäº’åŠ¨ï¼Œå…¶ä¸­æœºå™¨äººè¢«è§†ä¸ºä¸€ä¸ªç¤¾ä¼šä»£ç†äººï¼Œè€Œä¸ä»…ä»…æ˜¯ä¸€å°æœºå™¨ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.12125v1">PDF</a> </p>
<p><strong>æ€»ç»“</strong><br>    éšç€æœºå™¨äººå’Œäººå·¥æ™ºèƒ½ä»£ç†åœ¨æ—¥å¸¸ç”Ÿæ´»ä¸­æ—¥ç›Šæ™®åŠï¼Œæé«˜å…¶ä¸äººç±»äº’åŠ¨çš„èƒ½åŠ›è‡³å…³é‡è¦ã€‚æƒ…æ„Ÿåœ¨äººç±»äº’åŠ¨ä¸­æ‰®æ¼”ç€é‡è¦è§’è‰²ï¼Œå½“èå…¥äººå·¥æ™ºèƒ½ä»£ç†æ—¶ï¼Œå¯ä»¥æ”¹å–„äººæœºäº’åŠ¨çš„è‡ªç„¶æ€§å’Œé€æ˜åº¦ã€‚æœ¬ç ”ç©¶æ—¨åœ¨è¿ç”¨æƒ…æ„Ÿæ§åˆ¶ç†è®ºï¼ˆACTï¼‰ï¼Œè¿™æ˜¯ä¸€ä¸ªæ·±æ·±æ¤æ ¹äºäº’åŠ¨çš„å¿ƒç†å­¦æƒ…æ„Ÿæ¨¡å‹ï¼Œæ¥ç”Ÿæˆåˆæˆæƒ…æ„Ÿã€‚å—ACTå¯å‘çš„è·¨å¹³å°æ¡†æ¶è¢«å¼€å‘å¹¶åº”ç”¨åœ¨ä¸€ä¸ªç±»äººæœºå™¨äººä¸Šï¼Œä»¥è¯„ä¼°å®ƒå¯¹äººç±»æ„ŸçŸ¥çš„å½±å“ã€‚ç»“æœæ˜¾ç¤ºï¼Œæƒ…æ„Ÿæ˜¾ç¤ºé¢‘ç‡å½±å“ç”¨æˆ·å¯¹æœºå™¨äººçš„æ„ŸçŸ¥ã€‚æ­¤å¤–ï¼Œé€‚å½“çš„æƒ…æ„Ÿè¡¨è¾¾ä¼¼ä¹å¯ä»¥å¢å¼ºæœºå™¨äººæ„ŸçŸ¥åˆ°çš„æƒ…æ„Ÿå’Œè®¤çŸ¥ä»£ç†ã€‚ç ”ç©¶è¡¨æ˜ï¼ŒæˆåŠŸè¿ç”¨ACTå°†åˆæˆæƒ…æ„ŸåµŒå…¥æœºå™¨äººï¼Œå¯å®ç°æœ‰æ•ˆçš„äººæœºäº’åŠ¨ï¼Œæœºå™¨äººè¢«è§†ä¸ºç¤¾ä¼šä»£ç†è€Œéä»…ä»…æ˜¯æœºå™¨ã€‚</p>
<p><strong>å…³é”®è§è§£</strong></p>
<ol>
<li>æƒ…æ„Ÿåœ¨äººæœºäº’åŠ¨ä¸­æ‰®æ¼”ç€é‡è¦è§’è‰²ï¼Œå¯ä»¥æé«˜äº’åŠ¨çš„è‡ªç„¶æ€§å’Œé€æ˜åº¦ã€‚</li>
<li>å°†æƒ…æ„Ÿèå…¥äººå·¥æ™ºèƒ½ä»£ç†æ˜¯å¿…è¦çš„ï¼Œå› ä¸ºè¿™å¯¹æ—¥å¸¸ç”Ÿæ´»ä¸­çš„æ™®åŠè¶Šæ¥è¶Šé‡è¦ã€‚</li>
<li>æœ¬ç ”ç©¶æ—¨åœ¨è¿ç”¨æƒ…æ„Ÿæ§åˆ¶ç†è®ºï¼ˆACTï¼‰æ¥ç”Ÿæˆåˆæˆæƒ…æ„Ÿï¼Œè¿™æ˜¯ä¸€ç§åŸºäºå¿ƒç†å­¦çš„æƒ…æ„Ÿæ¨¡å‹ã€‚</li>
<li>å¼€å‘äº†ä¸€ä¸ªè·¨å¹³å°çš„æ¡†æ¶å¹¶å°†å…¶åº”ç”¨äºç±»äººæœºå™¨äººä¸Šï¼Œä»¥è¯„ä¼°å…¶å¯¹äººç±»æ„ŸçŸ¥çš„å½±å“ã€‚</li>
<li>å®éªŒç»“æœè¡¨æ˜ï¼Œæƒ…æ„Ÿæ˜¾ç¤ºçš„é¢‘ç‡ä¼šå½±å“ç”¨æˆ·å¯¹æœºå™¨äººçš„æ„ŸçŸ¥ã€‚</li>
<li>é€‚å½“çš„æƒ…æ„Ÿè¡¨è¾¾å¯ä»¥å¢å¼ºç”¨æˆ·å¯¹æœºå™¨äººæƒ…æ„Ÿå’Œè®¤çŸ¥èƒ½åŠ›çš„æ„ŸçŸ¥ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.12125">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-b7797c8944a3106a58e843367e050585.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="Towards-LLM-Agents-for-Earth-Observation"><a href="#Towards-LLM-Agents-for-Earth-Observation" class="headerlink" title="Towards LLM Agents for Earth Observation"></a>Towards LLM Agents for Earth Observation</h2><p><strong>Authors:Chia Hsiang Kao, Wenting Zhao, Shreelekha Revankar, Samuel Speas, Snehal Bhagat, Rajeev Datta, Cheng Perng Phoo, Utkarsh Mall, Carl Vondrick, Kavita Bala, Bharath Hariharan</strong></p>
<p>Earth Observation (EO) provides critical planetary data for environmental monitoring, disaster management, climate science, and other scientific domains. Here we ask: Are AI systems ready for reliable Earth Observation? We introduce \datasetnamenospace, a benchmark of 140 yes&#x2F;no questions from NASA Earth Observatory articles across 13 topics and 17 satellite sensors. Using Google Earth Engine API as a tool, LLM agents can only achieve an accuracy of 33% because the code fails to run over 58% of the time. We improve the failure rate for open models by fine-tuning synthetic data, allowing much smaller models (Llama-3.1-8B) to achieve comparable accuracy to much larger ones (e.g., DeepSeek-R1). Taken together, our findings identify significant challenges to be solved before AI agents can automate earth observation, and suggest paths forward. The project page is available at <a target="_blank" rel="noopener" href="https://iandrover.github.io/UnivEarth">https://iandrover.github.io/UnivEarth</a>. </p>
<blockquote>
<p>åœ°çƒè§‚æµ‹ï¼ˆEOï¼‰ä¸ºç¯å¢ƒç›‘æµ‹ã€ç¾å®³ç®¡ç†ã€æ°”å€™ç§‘å­¦å’Œå…¶ä»–ç§‘å­¦é¢†åŸŸæä¾›äº†å…³é”®æ€§çš„è¡Œæ˜Ÿæ•°æ®ã€‚åœ¨è¿™é‡Œæˆ‘ä»¬æå‡ºä¸€ä¸ªé—®é¢˜ï¼šäººå·¥æ™ºèƒ½ç³»ç»Ÿæ˜¯å¦å·²ç»å‡†å¤‡å¥½è¿›è¡Œå¯é çš„åœ°çƒè§‚æµ‹ï¼Ÿæˆ‘ä»¬å¼•å…¥äº†\datasetnamenospaceæ•°æ®é›†ï¼Œè¯¥æ•°æ®é›†åŒ…å«æ¥è‡ªNASAåœ°çƒè§‚æµ‹ç«™æ–‡ç« çš„140ä¸ªæ˜¯ä¸éé—®é¢˜ï¼Œæ¶µç›–13ä¸ªä¸»é¢˜å’Œ17ä¸ªå«æ˜Ÿä¼ æ„Ÿå™¨ã€‚åˆ©ç”¨Googleåœ°çƒå¼•æ“APIä½œä¸ºå·¥å…·ï¼ŒLLMä»£ç†äººçš„å‡†ç¡®ç‡ä»…ä¸º33%ï¼Œå› ä¸ºä»£ç æœ‰è¶…è¿‡58%çš„æ—¶é—´æ— æ³•è¿è¡Œã€‚æˆ‘ä»¬é€šè¿‡å¾®è°ƒåˆæˆæ•°æ®æ¥æé«˜å¼€æ”¾æ¨¡å‹çš„å¤±è´¥ç‡ï¼Œå…è®¸è¾ƒå°çš„æ¨¡å‹ï¼ˆå¦‚Llama-3.1-8Bï¼‰è¾¾åˆ°ä¸è¾ƒå¤§çš„æ¨¡å‹ï¼ˆå¦‚DeepSeek-R1ï¼‰ç›¸å½“çš„å‡†ç¡®ç‡ã€‚æ€»ä¹‹ï¼Œæˆ‘ä»¬çš„ç ”ç©¶æŒ‡å‡ºäº†åœ¨äººå·¥æ™ºèƒ½ä»£ç†å®ç°è‡ªåŠ¨åŒ–åœ°çƒè§‚æµ‹ä¹‹å‰éœ€è¦è§£å†³çš„é‡å¤§æŒ‘æˆ˜ï¼Œå¹¶æå‡ºäº†ä»Šåçš„æ–¹å‘ã€‚é¡¹ç›®é¡µé¢å¯åœ¨<a target="_blank" rel="noopener" href="https://iandrover.github.io/UnivEarth%E6%9F%A5%E7%9C%8B%E3%80%82">https://iandrover.github.io/UnivEarthæŸ¥çœ‹ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.12110v1">PDF</a> 36 pages</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†åœ°çƒè§‚æµ‹ï¼ˆEOï¼‰çš„é‡è¦æ€§åŠå…¶åœ¨ç¯å¢ƒç›‘æµ‹ã€ç¾å®³ç®¡ç†ã€æ°”å€™ç§‘å­¦ç­‰é¢†åŸŸçš„åº”ç”¨ã€‚é’ˆå¯¹AIç³»ç»Ÿåœ¨åœ°çƒè§‚æµ‹ä¸­çš„å¯é æ€§é—®é¢˜ï¼Œæ–‡ç« æå‡ºäº†ä¸€ä¸ªåŸºå‡†æµ‹è¯•é›†ï¼ŒåŒ…å«NASAåœ°çƒè§‚æµ‹ç«™çš„140ä¸ªæ˜¯ä¸éæ˜¯é—®é¢˜ï¼Œæ¶‰åŠ13ä¸ªä¸»é¢˜å’Œ17é¢—å«æ˜Ÿä¼ æ„Ÿå™¨ã€‚æ–‡ç« æŒ‡å‡ºï¼Œä½¿ç”¨Googleåœ°çƒå¼•æ“APIä½œä¸ºå·¥å…·æ—¶ï¼Œå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä»£ç†çš„å‡†ç¡®ç‡ä»…ä¸º33%ï¼Œä¸”å­˜åœ¨ä»£ç è¿è¡Œå¤±è´¥ç‡é«˜è¾¾58%çš„é—®é¢˜ã€‚ç ”ç©¶é€šè¿‡å¾®è°ƒåˆæˆæ•°æ®æé«˜äº†å¼€æ”¾æ¨¡å‹çš„æ€§èƒ½ï¼Œå¹¶å‘ç°è¾ƒå°çš„æ¨¡å‹ï¼ˆå¦‚Llama-3.1-8Bï¼‰ä¹Ÿèƒ½è¾¾åˆ°ä¸å¤§å‹æ¨¡å‹ç›¸è¿‘çš„å‡†ç¡®ç‡ã€‚æ–‡ç« æ€»ç»“äº†AIä»£ç†åœ¨è‡ªåŠ¨åŒ–åœ°çƒè§‚æµ‹æ–¹é¢ä»éœ€è§£å†³çš„æŒ‘æˆ˜ï¼Œå¹¶æå‡ºäº†è§£å†³æ–¹æ¡ˆã€‚é¡¹ç›®é¡µé¢å¯é€šè¿‡é“¾æ¥è®¿é—®ï¼š<a target="_blank" rel="noopener" href="https://iandrover.github.io/UnivEarth">https://iandrover.github.io/UnivEarth</a>ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>åœ°çƒè§‚æµ‹ï¼ˆEOï¼‰å¯¹äºç¯å¢ƒç›‘æµ‹ã€ç¾å®³ç®¡ç†ã€æ°”å€™ç§‘å­¦ç­‰é¢†åŸŸè‡³å…³é‡è¦ã€‚</li>
<li>AIç³»ç»Ÿåœ¨åœ°çƒè§‚æµ‹ä¸­é¢ä¸´å¯é æ€§æŒ‘æˆ˜ã€‚</li>
<li>æå‡ºä¸€ä¸ªåŸºå‡†æµ‹è¯•é›†ï¼ŒåŒ…å«NASAåœ°çƒè§‚æµ‹ç«™çš„140ä¸ªæ˜¯ä¸éæ˜¯é—®é¢˜ï¼Œç”¨äºè¯„ä¼°AIç³»ç»Ÿåœ¨åœ°çƒè§‚æµ‹æ–¹é¢çš„è¡¨ç°ã€‚</li>
<li>ä½¿ç”¨Googleåœ°çƒå¼•æ“APIæ—¶ï¼Œå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä»£ç†çš„å‡†ç¡®ç‡ä»…ä¸º33%ï¼Œä¸”å­˜åœ¨ä»£ç è¿è¡Œå¤±è´¥ç‡é«˜è¾¾58%çš„é—®é¢˜ã€‚</li>
<li>é€šè¿‡å¾®è°ƒåˆæˆæ•°æ®å¯æé«˜å¼€æ”¾æ¨¡å‹çš„æ€§èƒ½ã€‚</li>
<li>è¾ƒå°æ¨¡å‹ï¼ˆå¦‚Llama-3.1-8Bï¼‰ä¹Ÿèƒ½è¾¾åˆ°ä¸å¤§å‹æ¨¡å‹ç›¸è¿‘çš„å‡†ç¡®ç‡ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.12110">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-3a50c7d599d569532aa2b777fa0f53a9.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-5ecd51e4caf54bb5546639a8750ae900.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-953d4a1b1acb6343294e31abafe62e01.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="GrabS-Generative-Embodied-Agent-for-3D-Object-Segmentation-without-Scene-Supervision"><a href="#GrabS-Generative-Embodied-Agent-for-3D-Object-Segmentation-without-Scene-Supervision" class="headerlink" title="GrabS: Generative Embodied Agent for 3D Object Segmentation without   Scene Supervision"></a>GrabS: Generative Embodied Agent for 3D Object Segmentation without   Scene Supervision</h2><p><strong>Authors:Zihui Zhang, Yafei Yang, Hongtao Wen, Bo Yang</strong></p>
<p>We study the hard problem of 3D object segmentation in complex point clouds without requiring human labels of 3D scenes for supervision. By relying on the similarity of pretrained 2D features or external signals such as motion to group 3D points as objects, existing unsupervised methods are usually limited to identifying simple objects like cars or their segmented objects are often inferior due to the lack of objectness in pretrained features. In this paper, we propose a new two-stage pipeline called GrabS. The core concept of our method is to learn generative and discriminative object-centric priors as a foundation from object datasets in the first stage, and then design an embodied agent to learn to discover multiple objects by querying against the pretrained generative priors in the second stage. We extensively evaluate our method on two real-world datasets and a newly created synthetic dataset, demonstrating remarkable segmentation performance, clearly surpassing all existing unsupervised methods. </p>
<blockquote>
<p>æˆ‘ä»¬ç ”ç©¶äº†å¤æ‚ç‚¹äº‘ä¸­çš„ä¸‰ç»´ç‰©ä½“åˆ†å‰²è¿™ä¸€éš¾é¢˜ï¼Œä¸”ç ”ç©¶è¿‡ç¨‹ä¸­æ— éœ€å¯¹ä¸‰ç»´åœºæ™¯è¿›è¡Œäººä¸ºæ ‡æ³¨ä»¥è¿›è¡Œç›‘ç£ã€‚ç°æœ‰æ— ç›‘ç£æ–¹æ³•é€šå¸¸ä¾èµ–äºé¢„è®­ç»ƒçš„äºŒç»´ç‰¹å¾æˆ–è¿åŠ¨ç­‰å¤–éƒ¨ä¿¡å·çš„ç›¸ä¼¼æ€§æ¥å¯¹ä¸‰ç»´ç‚¹è¿›è¡Œç‰©ä½“åˆ†ç»„ï¼Œè¿™äº›æ–¹æ³•é€šå¸¸ä»…é™äºè¯†åˆ«æ±½è½¦ç­‰ç®€å•ç‰©ä½“ï¼Œæˆ–è€…å…¶åˆ†å‰²çš„ç‰©ä½“è´¨é‡è¾ƒå·®ï¼Œå› ä¸ºé¢„è®­ç»ƒç‰¹å¾ä¸­ç¼ºä¹ç‰©ä½“ç‰¹æ€§ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°çš„ä¸¤é˜¶æ®µæµç¨‹ï¼Œç§°ä¸ºGrabSã€‚æˆ‘ä»¬çš„æ–¹æ³•çš„æ ¸å¿ƒæ¦‚å¿µæ˜¯åœ¨ç¬¬ä¸€é˜¶æ®µä»å¯¹è±¡æ•°æ®é›†ä¸­å­¦ä¹ ç”Ÿæˆå’Œåˆ¤åˆ«å¯¹è±¡ä¸­å¿ƒå…ˆéªŒçŸ¥è¯†ä½œä¸ºåŸºç¡€ï¼Œç„¶ååœ¨ç¬¬äºŒé˜¶æ®µè®¾è®¡ä¸€ä¸ªæ™ºèƒ½ä½“é€šè¿‡å­¦ä¹ æŸ¥è¯¢é¢„è®­ç»ƒçš„ç”Ÿæˆå…ˆéªŒçŸ¥è¯†æ¥å‘ç°å¤šä¸ªå¯¹è±¡ã€‚æˆ‘ä»¬åœ¨ä¸¤ä¸ªçœŸå®æ•°æ®é›†å’Œä¸€ä¸ªæ–°åˆ›å»ºåˆæˆæ•°æ®é›†ä¸Šå…¨é¢è¯„ä¼°äº†æˆ‘ä»¬çš„æ–¹æ³•ï¼Œå±•ç¤ºå‡ºäº†æ˜¾è‘—çš„åˆ†å‰²æ€§èƒ½ï¼Œæ˜æ˜¾è¶…è¶Šäº†æ‰€æœ‰ç°æœ‰çš„æ— ç›‘ç£æ–¹æ³•ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.11754v1">PDF</a> ICLR 2025 Spotlight. Code and data are available at:   <a target="_blank" rel="noopener" href="https://github.com/vLAR-group/GrabS">https://github.com/vLAR-group/GrabS</a></p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ç ”ç©¶äº†æ— éœ€äººå·¥æ ‡æ³¨çš„å¤æ‚ç‚¹äº‘ä¸­çš„ä¸‰ç»´ç‰©ä½“åˆ†å‰²é—®é¢˜ã€‚æ–‡ç« æå‡ºäº†ä¸€ç§æ–°çš„ä¸¤æ­¥æ–¹æ³•ï¼Œåä¸ºGrabSã€‚é¦–å…ˆé€šè¿‡åˆ©ç”¨é¢„å…ˆè®­ç»ƒå¥½çš„äºŒç»´ç‰¹å¾æˆ–å¤–éƒ¨ä¿¡å·ï¼ˆå¦‚è¿åŠ¨ï¼‰å°†ä¸‰ç»´ç‚¹åˆ†ä¸ºå¯¹è±¡æ¥å­¦ä¹ ç”Ÿæˆæ€§å’Œé‰´åˆ«æ€§å¯¹è±¡ä¸ºä¸­å¿ƒçš„å…ˆéªŒçŸ¥è¯†ã€‚åœ¨ç¬¬ä¸€é˜¶æ®µè¿›è¡Œã€‚ç„¶åè®¾è®¡ä¸€ç§è‡ªä¸»ä»£ç†ï¼Œé€šè¿‡æŸ¥è¯¢é¢„å…ˆè®­ç»ƒçš„ç”Ÿæˆå…ˆéªŒçŸ¥è¯†æ¥å‘ç°å¤šä¸ªå¯¹è±¡ã€‚è¯¥æ–¹æ³•åœ¨çœŸå®æ•°æ®é›†å’Œæ–°å»ºåˆæˆæ•°æ®é›†ä¸Šçš„è¡¨ç°ä»¤äººå°è±¡æ·±åˆ»ï¼Œæ˜¾è‘—ä¼˜äºç°æœ‰çš„æ— ç›‘ç£æ–¹æ³•ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>ç ”ç©¶é’ˆå¯¹å¤æ‚ç‚¹äº‘ä¸­çš„ä¸‰ç»´ç‰©ä½“åˆ†å‰²é—®é¢˜ï¼Œæ— éœ€äººå·¥æ ‡æ³¨ã€‚</li>
<li>æå‡ºäº†ä¸€ç§æ–°çš„ä¸¤æ­¥æ–¹æ³•GrabSè¿›è¡Œä¸‰ç»´ç‰©ä½“åˆ†å‰²ã€‚</li>
<li>ç¬¬ä¸€é˜¶æ®µå­¦ä¹ ç”Ÿæˆæ€§å’Œé‰´åˆ«æ€§å¯¹è±¡ä¸ºä¸­å¿ƒçš„å…ˆéªŒçŸ¥è¯†ã€‚</li>
<li>ç¬¬äºŒé˜¶æ®µè®¾è®¡è‡ªä¸»ä»£ç†ï¼Œé€šè¿‡æŸ¥è¯¢é¢„å…ˆè®­ç»ƒçš„ç”Ÿæˆå…ˆéªŒçŸ¥è¯†æ¥å‘ç°å¤šä¸ªå¯¹è±¡ã€‚</li>
<li>æ–¹æ³•åœ¨çœŸå®æ•°æ®é›†å’Œæ–°å»ºåˆæˆæ•°æ®é›†ä¸Šçš„è¡¨ç°ä¼˜å¼‚ï¼Œè¶…è¶Šç°æœ‰æ— ç›‘ç£æ–¹æ³•ã€‚</li>
<li>åˆ©ç”¨é¢„å…ˆè®­ç»ƒå¥½çš„äºŒç»´ç‰¹å¾å’Œå¤–éƒ¨ä¿¡å·ï¼ˆå¦‚è¿åŠ¨ï¼‰è¿›è¡Œä¸‰ç»´ç‚¹åˆ†ç»„ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.11754">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-0b0c0ae696fc4dd6629870acf9a0b536.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-b88170a9d116775ed14b9ff16209e718.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-9b387ccd0a6424e335d77a2233b5a2e4.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f408ba1466d06a4ac931b853356b19bb.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-634e86cf064251b6764724358a3afcb8.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-0d01f32fc8aa22460131e4cde9d61973.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="REAL-Benchmarking-Autonomous-Agents-on-Deterministic-Simulations-of-Real-Websites"><a href="#REAL-Benchmarking-Autonomous-Agents-on-Deterministic-Simulations-of-Real-Websites" class="headerlink" title="REAL: Benchmarking Autonomous Agents on Deterministic Simulations of   Real Websites"></a>REAL: Benchmarking Autonomous Agents on Deterministic Simulations of   Real Websites</h2><p><strong>Authors:Divyansh Garg, Shaun VanWeelden, Diego Caples, Andis Draguns, Nikil Ravi, Pranav Putta, Naman Garg, Tomas Abraham, Michael Lara, Federico Lopez, James Liu, Atharva Gundawar, Prannay Hebbar, Youngchul Joo, Charles London, Christian Schroeder de Witt, Sumeet Motwani</strong></p>
<p>We introduce REAL, a benchmark and framework for multi-turn agent evaluations on deterministic simulations of real-world websites. REAL comprises high-fidelity, deterministic replicas of 11 widely-used websites across domains such as e-commerce, travel, communication, and professional networking. We also release a benchmark consisting of 112 practical tasks that mirror everyday complex user interactions requiring both accurate information retrieval and state-changing actions. All interactions occur within this fully controlled setting, eliminating safety risks and enabling robust, reproducible evaluation of agent capability and reliability. Our novel evaluation framework combines programmatic checks of website state for action-based tasks with rubric-guided LLM-based judgments for information retrieval. The framework supports both open-source and proprietary agent systems through a flexible evaluation harness that accommodates black-box commands within browser environments, allowing research labs to test agentic systems without modification. Our empirical results show that frontier language models achieve at most a 41% success rate on REAL, highlighting critical gaps in autonomous web navigation and task completion capabilities. Our framework supports easy integration of new tasks, reproducible evaluation, and scalable data generation for training web agents. The websites, framework, and leaderboard are available at <a target="_blank" rel="noopener" href="https://realevals.xyz/">https://realevals.xyz</a> and <a target="_blank" rel="noopener" href="https://github.com/agi-inc/REAL">https://github.com/agi-inc/REAL</a>. </p>
<blockquote>
<p>æˆ‘ä»¬å¼•å…¥äº†REALï¼Œè¿™æ˜¯ä¸€ä¸ªåœ¨çœŸå®ç½‘ç«™ç¡®å®šæ€§æ¨¡æ‹Ÿä¸Šè¿›è¡Œå¤šè½®ä»£ç†è¯„ä¼°çš„åŸºå‡†å’Œæ¡†æ¶ã€‚REALåŒ…å«äº†é«˜ä¿çœŸã€ç¡®å®šæ€§çš„å¤åˆ¶ç‰ˆæœ¬ï¼Œæ¶µç›–äº†ç”µå­å•†åŠ¡ã€æ—…æ¸¸ã€é€šä¿¡å’Œä¸“ä¸šç½‘ç»œç­‰é¢†åŸŸçš„11ä¸ªå¹¿æ³›ä½¿ç”¨çš„ç½‘ç«™ã€‚æˆ‘ä»¬è¿˜å‘å¸ƒäº†ä¸€ä¸ªåŒ…å«112ä¸ªå®ç”¨ä»»åŠ¡çš„åŸºå‡†æµ‹è¯•ï¼Œè¿™äº›ä»»åŠ¡åæ˜ äº†æ—¥å¸¸å¤æ‚çš„ç”¨æˆ·äº¤äº’ï¼Œéœ€è¦å‡†ç¡®çš„ä¿¡æ¯æ£€ç´¢å’ŒçŠ¶æ€æ›´æ”¹æ“ä½œã€‚æ‰€æœ‰çš„äº¤äº’éƒ½å‘ç”Ÿåœ¨è¿™ä¸ªå®Œå…¨å—æ§çš„ç¯å¢ƒä¸­ï¼Œæ¶ˆé™¤äº†å®‰å…¨é£é™©ï¼Œå¹¶èƒ½å¤Ÿç¨³å¥ã€å¯é‡å¤åœ°è¯„ä¼°ä»£ç†çš„èƒ½åŠ›å’Œå¯é æ€§ã€‚æˆ‘ä»¬æ–°é¢–çš„è¯„ä»·æ¡†æ¶ç»“åˆäº†åŸºäºç½‘ç«™çŠ¶æ€çš„ç¨‹åºåŒ–æ£€æŸ¥ï¼ˆé’ˆå¯¹åŸºäºè¡ŒåŠ¨çš„ä»»åŠ¡ï¼‰å’ŒåŸºäºè§„åˆ™çš„LLMåˆ¤æ–­ï¼ˆé’ˆå¯¹ä¿¡æ¯æ£€ç´¢ï¼‰ã€‚è¯¥æ¡†æ¶æ”¯æŒå¼€æºå’Œä¸“æœ‰ä»£ç†ç³»ç»Ÿï¼Œé€šè¿‡ä¸€ä¸ªçµæ´»çš„è¯„ä»·è£…ç½®æ¥é€‚åº”æµè§ˆå™¨ç¯å¢ƒä¸­çš„é»‘ç®±å‘½ä»¤ï¼Œä½¿å¾—ç ”ç©¶å®éªŒå®¤èƒ½å¤Ÿæµ‹è¯•ä»£ç†ç³»ç»Ÿè€Œæ— éœ€è¿›è¡Œä¿®æ”¹ã€‚æˆ‘ä»¬çš„å®è¯ç»“æœè¡¨æ˜ï¼Œæœ€å…ˆè¿›çš„è¯­è¨€æ¨¡å‹åœ¨REALä¸Šçš„æˆåŠŸç‡æœ€é«˜ä»…ä¸º41%ï¼Œè¿™å‡¸æ˜¾äº†è‡ªä¸»ç½‘é¡µå¯¼èˆªå’Œä»»åŠ¡å®Œæˆèƒ½åŠ›çš„å…³é”®å·®è·ã€‚æˆ‘ä»¬çš„æ¡†æ¶æ”¯æŒè½»æ¾é›†æˆæ–°ä»»åŠ¡ã€å¯é‡å¤è¯„ä¼°å’Œå¯æ‰©å±•çš„æ•°æ®ç”Ÿæˆï¼Œä»¥è®­ç»ƒç½‘é¡µä»£ç†ã€‚ç½‘ç«™ã€æ¡†æ¶å’Œæ’è¡Œæ¦œå¯åœ¨<a target="_blank" rel="noopener" href="https://realevals.xyzå’Œhttps//github.com/agi-inc/REAL%E6%89%BE%E5%88%B0%E3%80%82">https://realevals.xyzå’Œhttps://github.com/agi-inc/REALæ‰¾åˆ°ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.11543v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†REALï¼Œè¿™æ˜¯ä¸€ä¸ªé’ˆå¯¹çœŸå®ä¸–ç•Œç½‘ç«™ç¡®å®šæ€§æ¨¡æ‹Ÿçš„å¤šè½®ä»£ç†è¯„ä¼°çš„åŸºå‡†å’Œæ¡†æ¶ã€‚REALåŒ…å«11ä¸ªé«˜ä¿çœŸç¡®å®šæ€§å‰¯æœ¬çš„å¹¿æ³›ä½¿ç”¨çš„ç½‘ç«™ï¼Œå¹¶å‘å¸ƒäº†ä¸€ä¸ªåŒ…å«112ä¸ªå®ç”¨ä»»åŠ¡çš„åŸºå‡†æµ‹è¯•ï¼Œè¿™äº›ä»»åŠ¡åæ˜ äº†æ—¥å¸¸å¤æ‚çš„ç”¨æˆ·äº¤äº’ï¼Œéœ€è¦å‡†ç¡®çš„ä¿¡æ¯æ£€ç´¢å’ŒçŠ¶æ€æ›´æ”¹æ“ä½œã€‚è¯¥è¯„ä¼°æ¡†æ¶ç»“åˆäº†ç½‘ç«™çŠ¶æ€çš„ç¨‹åºæ£€æŸ¥ï¼Œç”¨äºåŸºäºè¡ŒåŠ¨çš„ä»»åŠ¡ï¼Œä»¥åŠä¸æ£€ç´¢ä¿¡æ¯æŒ‡å—çš„LLMåˆ¤æ–­ã€‚å®ƒä¸ºå¼€æºå’Œä¸“æœ‰ä»£ç†ç³»ç»Ÿæä¾›äº†ä¸€ä¸ªçµæ´»çš„è¯„ä»·å¹³å°ï¼Œæ”¯æŒåœ¨æµè§ˆå™¨ç¯å¢ƒä¸­è¿›è¡Œé»‘ç®±å‘½ä»¤æ“ä½œï¼Œä½¿å¾—ç ”ç©¶å®éªŒå®¤èƒ½å¤Ÿæµ‹è¯•ä»£ç†ç³»ç»Ÿæ— éœ€ä¿®æ”¹ã€‚å®è¯ç ”ç©¶ç»“æœæ˜¾ç¤ºï¼Œæœ€å…ˆè¿›çš„è¯­è¨€æ¨¡å‹åœ¨REALä¸Šçš„æˆåŠŸç‡ä»…ä¸º41%ï¼Œè¿™å‡¸æ˜¾äº†è‡ªä¸»ç½‘é¡µå¯¼èˆªå’Œä»»åŠ¡å®Œæˆèƒ½åŠ›çš„å…³é”®å·®è·ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>REALæ˜¯ä¸€ä¸ªç”¨äºè¯„ä¼°å¤šè½®ä»£ç†åœ¨çœŸå®ç½‘ç«™ç¡®å®šæ€§æ¨¡æ‹Ÿä¸Šçš„è¡¨ç°çš„åŸºå‡†å’Œæ¡†æ¶ã€‚</li>
<li>å®ƒåŒ…å«11ä¸ªé«˜ä¿çœŸç½‘ç«™å‰¯æœ¬å’Œ112ä¸ªå®ç”¨ä»»åŠ¡ï¼Œåæ˜ æ—¥å¸¸ç”¨æˆ·äº¤äº’ã€‚</li>
<li>REALçš„è¯„ä¼°æ¡†æ¶ç»“åˆäº†ç¨‹åºæ£€æŸ¥å’ŒLLMåˆ¤æ–­ï¼Œç”¨äºè¯„ä»·ä»£ç†çš„èƒ½åŠ›å’Œå¯é æ€§ã€‚</li>
<li>æ¡†æ¶æ”¯æŒå¤šç§ä»£ç†ç³»ç»Ÿï¼Œå¹¶æä¾›çµæ´»çš„è¯„ä»·å¹³å°ï¼Œå…è®¸åœ¨æµè§ˆå™¨ç¯å¢ƒä¸­è¿›è¡Œé»‘ç®±æ“ä½œã€‚</li>
<li>å®è¯ç ”ç©¶æŒ‡å‡ºï¼Œç°æœ‰è¯­è¨€æ¨¡å‹åœ¨REALä¸Šçš„æˆåŠŸç‡è¾ƒä½ï¼Œå‡¸æ˜¾äº†è‡ªä¸»ç½‘é¡µå¯¼èˆªå’Œä»»åŠ¡å®Œæˆèƒ½åŠ›çš„å·®è·ã€‚</li>
<li>REALæ˜“äºé›†æˆæ–°ä»»åŠ¡ï¼Œæ”¯æŒå¯é‡å¤è¯„ä¼°å’Œå¯æ‰©å±•çš„æ•°æ®ç”Ÿæˆã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.11543">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-b2089e84f6bba8c84e814ebc04819e15.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-62681ad777dd6cb34bb1abdacc6a99df.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-acd0e40283c79364d0205c86a2ca3f53.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ce7baae5c4d9d27642c19d80d9591f58.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="Task-Memory-Engine-TME-A-Structured-Memory-Framework-with-Graph-Aware-Extensions-for-Multi-Step-LLM-Agent-Tasks"><a href="#Task-Memory-Engine-TME-A-Structured-Memory-Framework-with-Graph-Aware-Extensions-for-Multi-Step-LLM-Agent-Tasks" class="headerlink" title="Task Memory Engine (TME): A Structured Memory Framework with Graph-Aware   Extensions for Multi-Step LLM Agent Tasks"></a>Task Memory Engine (TME): A Structured Memory Framework with Graph-Aware   Extensions for Multi-Step LLM Agent Tasks</h2><p><strong>Authors:Ye Ye</strong></p>
<p>Large Language Models (LLMs) are increasingly used as autonomous agents for multi-step tasks. However, most existing frameworks fail to maintain a structured understanding of the task state, often relying on linear prompt concatenation or shallow memory buffers. This leads to brittle performance, frequent hallucinations, and poor long-range coherence. In this work, we propose the Task Memory Engine (TME), a lightweight and structured memory module that tracks task execution using a hierarchical Task Memory Tree (TMT). Each node in the tree corresponds to a task step, storing relevant input, output, status, and sub-task relationships. We introduce a prompt synthesis method that dynamically generates LLM prompts based on the active node path, significantly improving execution consistency and contextual grounding. Through case studies and comparative experiments on multi-step agent tasks, we demonstrate that TME leads to better task completion accuracy and more interpretable behavior with minimal implementation overhead. A reference implementation of the core TME components is available at <a target="_blank" rel="noopener" href="https://github.com/biubiutomato/TME-Agent">https://github.com/biubiutomato/TME-Agent</a>, including basic examples and structured memory integration. While the current implementation uses a tree-based structure, TME is designed to be graph-aware, supporting reusable substeps, converging task paths, and shared dependencies. This lays the groundwork for future DAG-based memory architectures. </p>
<blockquote>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰è¶Šæ¥è¶Šå¤šåœ°è¢«ç”¨ä½œå¤šæ­¥éª¤ä»»åŠ¡çš„è‡ªä¸»ä»£ç†ã€‚ç„¶è€Œï¼Œå¤§å¤šæ•°ç°æœ‰æ¡†æ¶æ— æ³•ç»´æŒå¯¹ä»»åŠ¡çŠ¶æ€çš„ç»“æ„åŒ–ç†è§£ï¼Œé€šå¸¸ä¾èµ–äºçº¿æ€§æç¤ºä¸²è”æˆ–æµ…å†…å­˜ç¼“å†²åŒºã€‚è¿™å¯¼è‡´æ€§èƒ½ä¸ç¨³å®šã€é¢‘ç¹å‡ºç°å¹»è§‰å’Œé•¿æœŸè¿è´¯æ€§å·®ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä»»åŠ¡è®°å¿†å¼•æ“ï¼ˆTMEï¼‰ï¼Œè¿™æ˜¯ä¸€ä¸ªè½»é‡çº§ã€ç»“æ„åŒ–çš„å†…å­˜æ¨¡å—ï¼Œä½¿ç”¨åˆ†å±‚çš„ä»»åŠ¡è®°å¿†æ ‘ï¼ˆTMTï¼‰æ¥è·Ÿè¸ªä»»åŠ¡æ‰§è¡Œæƒ…å†µã€‚æ ‘ä¸­çš„æ¯ä¸ªèŠ‚ç‚¹å¯¹åº”ä¸€ä¸ªä»»åŠ¡æ­¥éª¤ï¼Œå­˜å‚¨ç›¸å…³çš„è¾“å…¥ã€è¾“å‡ºã€çŠ¶æ€å’Œå­ä»»åŠ¡å…³ç³»ã€‚æˆ‘ä»¬å¼•å…¥äº†ä¸€ç§æç¤ºåˆæˆæ–¹æ³•ï¼Œè¯¥æ–¹æ³•æ ¹æ®æ´»åŠ¨èŠ‚ç‚¹è·¯å¾„åŠ¨æ€ç”ŸæˆLLMæç¤ºï¼Œæ˜¾è‘—æé«˜äº†æ‰§è¡Œä¸€è‡´æ€§ä¸Šä¸‹æ–‡å®šä½ã€‚é€šè¿‡å¤šæ­¥éª¤ä»£ç†ä»»åŠ¡çš„æ¡ˆä¾‹ç ”ç©¶å’Œå¯¹æ¯”å®éªŒï¼Œæˆ‘ä»¬è¯æ˜äº†TMEåœ¨æé«˜ä»»åŠ¡å®Œæˆå‡†ç¡®æ€§å’Œæ›´å¯è§£é‡Šçš„è¡Œä¸ºæ–¹é¢å…·æœ‰ä¼˜åŠ¿ï¼Œä¸”å®ç°å¼€é”€æœ€å°ã€‚æ ¸å¿ƒTMEç»„ä»¶çš„å‚è€ƒå®ç°å¯åœ¨[<a target="_blank" rel="noopener" href="https://github.com/biubiutomato/TME-Agent%E6%89%BE%E5%88%B0%EF%BC%8C%E5%8C%85%E6%8B%AC%E5%9F%BA%E6%9C%AC%E7%A4%BA%E4%BE%8B%E5%92%8C%E7%BB%93%E6%9E%84%E5%8C%96%E5%86%85%E5%AD%98%E9%9B%86%E6%88%90%E3%80%82%E8%99%BD%E7%84%B6%E5%BD%93%E5%89%8D%E5%AE%9E%E7%8E%B0%E4%BD%BF%E7%94%A8%E4%BA%86%E6%A0%91%E5%BD%A2%E7%BB%93%E6%9E%84%EF%BC%8C%E4%BD%86TME%E8%A2%AB%E8%AE%BE%E8%AE%A1%E4%B8%BA%E5%9B%BE%E6%84%9F%E7%9F%A5%EF%BC%8C%E6%94%AF%E6%8C%81%E5%8F%AF%E9%87%8D%E7%94%A8%E7%9A%84%E5%AD%90%E6%AD%A5%E9%AA%A4%E3%80%81%E6%94%B6%E6%95%9B%E7%9A%84%E4%BB%BB%E5%8A%A1%E8%B7%AF%E5%BE%84%E5%92%8C%E5%85%B1%E4%BA%AB%E4%BE%9D%E8%B5%96%E3%80%82%E8%BF%99%E4%B8%BA%E6%9C%AA%E6%9D%A5%E5%9F%BA%E4%BA%8EDAG%E7%9A%84%E5%86%85%E5%AD%98%E6%9E%B6%E6%9E%84%E5%A5%A0%E5%AE%9A%E4%BA%86%E5%9F%BA%E7%A1%80%E3%80%82">https://github.com/biubiutomato/TME-Agentæ‰¾åˆ°ï¼ŒåŒ…æ‹¬åŸºæœ¬ç¤ºä¾‹å’Œç»“æ„åŒ–å†…å­˜é›†æˆã€‚è™½ç„¶å½“å‰å®ç°ä½¿ç”¨äº†æ ‘å½¢ç»“æ„ï¼Œä½†TMEè¢«è®¾è®¡ä¸ºå›¾æ„ŸçŸ¥ï¼Œæ”¯æŒå¯é‡ç”¨çš„å­æ­¥éª¤ã€æ”¶æ•›çš„ä»»åŠ¡è·¯å¾„å’Œå…±äº«ä¾èµ–ã€‚è¿™ä¸ºæœªæ¥åŸºäºDAGçš„å†…å­˜æ¶æ„å¥ å®šäº†åŸºç¡€ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.08525v3">PDF</a> 14 pages, 5 figures. Preprint prepared for future submission.   Includes implementation and token-efficiency analysis. Code at   <a target="_blank" rel="noopener" href="https://github.com/biubiutomato/TME-Agent">https://github.com/biubiutomato/TME-Agent</a></p>
<p><strong>Summary</strong><br>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰è¢«è¶Šæ¥è¶Šå¤šåœ°ç”¨ä½œå¤šæ­¥éª¤ä»»åŠ¡çš„è‡ªä¸»ä»£ç†ï¼Œä½†å…¶ç°æœ‰æ¡†æ¶å¤§å¤šç¼ºä¹ä»»åŠ¡çŠ¶æ€çš„ç»“æ„åŒ–ç†è§£ï¼Œè¿™å¯¼è‡´äº†æ€§èƒ½ä¸ç¨³å®šã€ç»å¸¸å¹»æƒ³å’Œé•¿æœŸè¿è´¯æ€§å·®ã€‚ä¸ºè§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä»»åŠ¡è®°å¿†å¼•æ“ï¼ˆTMEï¼‰å’Œå±‚æ¬¡åŒ–ä»»åŠ¡è®°å¿†æ ‘ï¼ˆTMTï¼‰ã€‚TMEé€šè¿‡åŠ¨æ€ç”ŸæˆLLMæç¤ºæ¥æ”¹å–„æ‰§è¡Œä¸€è‡´æ€§ï¼Œæé«˜ä»»åŠ¡å®Œæˆå‡†ç¡®æ€§å¹¶å¢å¼ºè¡Œä¸ºå¯è§£é‡Šæ€§ã€‚ç›¸å…³å®ç°ç»†èŠ‚å¯å‚è€ƒï¼š<a target="_blank" rel="noopener" href="https://github.com/biubiutomato/TME-Agent">é“¾æ¥</a>ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å¤šæ­¥éª¤ä»»åŠ¡ä¸­çš„è‡ªä¸»ä»£ç†åº”ç”¨é¢ä¸´æŒ‘æˆ˜ã€‚</li>
<li>å½“å‰æ¡†æ¶ç¼ºä¹ä»»åŠ¡çŠ¶æ€çš„ç»“æ„åŒ–ç†è§£ï¼Œå¯¼è‡´æ€§èƒ½ä¸ç¨³å®šå’Œè¿è´¯æ€§å·®ã€‚</li>
<li>æå‡ºä»»åŠ¡è®°å¿†å¼•æ“ï¼ˆTMEï¼‰å’Œå±‚æ¬¡åŒ–ä»»åŠ¡è®°å¿†æ ‘ï¼ˆTMTï¼‰æ¥è§£å†³è¿™äº›é—®é¢˜ã€‚</li>
<li>TMEé€šè¿‡åŠ¨æ€ç”ŸæˆLLMæç¤ºæ”¹å–„æ‰§è¡Œä¸€è‡´æ€§ã€‚</li>
<li>TMEæé«˜äº†ä»»åŠ¡å®Œæˆå‡†ç¡®æ€§å’Œè¡Œä¸ºå¯è§£é‡Šæ€§ã€‚</li>
<li>TMEå…·æœ‰å›¾å½¢æ„ŸçŸ¥è®¾è®¡ï¼Œæ”¯æŒå¯é‡å¤çš„å­æ­¥éª¤ã€æ”¶æ•›ä»»åŠ¡è·¯å¾„å’Œå…±äº«ä¾èµ–ï¼Œä¸ºæœªæ¥åŸºäºDAGçš„å†…å­˜æ¶æ„å¥ å®šåŸºç¡€ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.08525">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-833c71abfb41f6d58cf8b4414cff583e.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-56cfc4f925f501a97f8aa2f5539a97f4.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="UI-R1-Enhancing-Action-Prediction-of-GUI-Agents-by-Reinforcement-Learning"><a href="#UI-R1-Enhancing-Action-Prediction-of-GUI-Agents-by-Reinforcement-Learning" class="headerlink" title="UI-R1: Enhancing Action Prediction of GUI Agents by Reinforcement   Learning"></a>UI-R1: Enhancing Action Prediction of GUI Agents by Reinforcement   Learning</h2><p><strong>Authors:Zhengxi Lu, Yuxiang Chai, Yaxuan Guo, Xi Yin, Liang Liu, Hao Wang, Han Xiao, Shuai Ren, Guanjing Xiong, Hongsheng Li</strong></p>
<p>The recent DeepSeek-R1 has showcased the emergence of reasoning capabilities in LLMs through reinforcement learning (RL) with rule-based rewards. Despite its success in language models, its application in multi-modal domains, particularly in graphic user interface (GUI) agent tasks, remains under-explored. To address this issue, we propose UI-R1, the first framework to explore how rule-based RL can enhance the reasoning capabilities of multimodal large language models (MLLMs) for GUI action prediction tasks. Specifically, UI-R1 introduces a novel rule-based action reward, enabling model optimization via policy-based algorithms such as Group Relative Policy Optimization (GRPO). For efficient training, we curate a small yet high-quality dataset of 136 challenging tasks, encompassing five common action types on mobile devices. Experimental results demonstrate that our proposed UI-R1-3B achieves significant improvements over the base model (i.e. Qwen2.5-VL-3B) on both in-domain (ID) and out-of-domain (OOD) tasks, with average accuracy gains of 22.1% on ScreenSpot, 6.0% on ScreenSpot-Pro, and 12.7% on ANDROIDCONTROL. Furthermore, UI-R1-3B delivers competitive performance compared to larger models (e.g., OS-Atlas-7B) trained via supervised fine-tuning (SFT) on 76K samples. These results underscore the potential of rule-based reinforcement learning to advance GUI understanding and control, paving the way for future research in this domain. Code website: <a target="_blank" rel="noopener" href="https://github.com/lll6gg/UI-R1">https://github.com/lll6gg/UI-R1</a>. </p>
<blockquote>
<p>æœ€è¿‘ï¼ŒDeepSeek-R1å±•ç¤ºäº†é€šè¿‡åŸºäºè§„åˆ™çš„å¥–åŠ±è¿›è¡Œå¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰åï¼Œå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä¸­æ¨ç†èƒ½åŠ›çš„å‡ºç°ã€‚å°½ç®¡å®ƒåœ¨è¯­è¨€æ¨¡å‹æ–¹é¢å–å¾—äº†æˆåŠŸï¼Œä½†åœ¨å¤šæ¨¡å¼é¢†åŸŸï¼Œç‰¹åˆ«æ˜¯åœ¨å›¾å½¢ç”¨æˆ·ç•Œé¢ï¼ˆGUIï¼‰ä»£ç†ä»»åŠ¡ä¸­çš„åº”ç”¨ä»ç„¶æœªè¢«å……åˆ†æ¢ç´¢ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†UI-R1ï¼Œè¿™æ˜¯ç¬¬ä¸€ä¸ªæ¢ç´¢åŸºäºè§„åˆ™çš„RLå¦‚ä½•å¢å¼ºå¤šæ¨¡å¼å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆMLLMï¼‰çš„æ¨ç†èƒ½åŠ›ï¼Œä»¥æ‰§è¡ŒGUIåŠ¨ä½œé¢„æµ‹ä»»åŠ¡çš„æ¡†æ¶ã€‚å…·ä½“æ¥è¯´ï¼ŒUI-R1å¼•å…¥äº†ä¸€ç§æ–°å‹çš„åŸºäºåŠ¨ä½œçš„è§„åˆ™å¥–åŠ±ï¼Œé€šè¿‡åŸºäºç­–ç•¥ç®—æ³•ï¼ˆå¦‚é›†å›¢ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–ï¼ˆGRPOï¼‰ï¼‰è¿›è¡Œæ¨¡å‹ä¼˜åŒ–ã€‚ä¸ºäº†è¿›è¡Œæœ‰æ•ˆçš„è®­ç»ƒï¼Œæˆ‘ä»¬åˆ›å»ºäº†ä¸€ä¸ªå°å‹ä½†é«˜è´¨é‡çš„æ•°æ®é›†ï¼ŒåŒ…å«136ä¸ªå…·æœ‰æŒ‘æˆ˜æ€§çš„ä»»åŠ¡ï¼Œæ¶µç›–ç§»åŠ¨è®¾å¤‡ä¸Šçš„äº”ç§å¸¸è§åŠ¨ä½œç±»å‹ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬æå‡ºçš„UI-R1-3Båœ¨åŸŸå†…ï¼ˆIDï¼‰å’ŒåŸŸå¤–ï¼ˆOODï¼‰ä»»åŠ¡ä¸Šéƒ½è¾ƒåŸºç¡€æ¨¡å‹ï¼ˆå³Qwen2.5-VL-3Bï¼‰æœ‰æ˜¾è‘—æ”¹è¿›ï¼Œåœ¨ScreenSpotä¸Šçš„å¹³å‡å‡†ç¡®ç‡æé«˜äº†22.1%ï¼Œåœ¨ScreenSpot-Proä¸Šæé«˜äº†6.0%ï¼Œåœ¨ANDROIDCONTROLä¸Šæé«˜äº†12.7%ã€‚æ­¤å¤–ï¼Œä¸åœ¨76Kæ ·æœ¬ä¸Šé€šè¿‡ç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰è®­ç»ƒçš„æ›´å¤§æ¨¡å‹ï¼ˆå¦‚OS-Atlas-7Bï¼‰ç›¸æ¯”ï¼ŒUI-R1-3Bè¡¨ç°å‡ºå…·æœ‰ç«äº‰åŠ›çš„æ€§èƒ½ã€‚è¿™äº›ç»“æœçªæ˜¾äº†åŸºäºè§„åˆ™çš„å¼ºåŒ–å­¦ä¹ åœ¨GUIç†è§£å’Œæ§åˆ¶æ–¹é¢çš„æ½œåŠ›ï¼Œä¸ºæœªæ¥çš„ç ”ç©¶é“ºå¹³äº†é“è·¯ã€‚ä»£ç ç½‘ç«™ï¼š<a target="_blank" rel="noopener" href="https://github.com/lll6gg/UI-R1%E3%80%82">https://github.com/lll6gg/UI-R1ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.21620v3">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†DeepSeek-R1å±•ç¤ºäº†å¤§è¯­è¨€æ¨¡å‹é€šè¿‡å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰å‡ºç°æ¨ç†èƒ½åŠ›çš„æ–°å…´è¶‹åŠ¿ã€‚ä¸ºåº”å¯¹åœ¨å›¾å½¢ç”¨æˆ·ç•Œé¢ï¼ˆGUIï¼‰ä»£ç†ä»»åŠ¡ä¸­å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰çš„åº”ç”¨ä¸è¶³é—®é¢˜ï¼Œé¦–æ¬¡æå‡ºUI-R1æ¡†æ¶ã€‚é€šè¿‡å¼•å…¥åŸºäºè§„åˆ™çš„è¡ŒåŠ¨å¥–åŠ±ï¼Œä¼˜åŒ–æ¨¡å‹é€šè¿‡åŸºäºç­–ç•¥ç®—æ³•å¦‚ç¾¤ä½“ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–ï¼ˆGRPOï¼‰ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œç›¸æ¯”åŸºå‡†æ¨¡å‹ï¼ŒUI-R1-3Båœ¨åŸŸå†…ï¼ˆIDï¼‰å’ŒåŸŸå¤–ï¼ˆOODï¼‰ä»»åŠ¡ä¸Šçš„è¡¨ç°å‡æœ‰æ˜¾è‘—æé«˜ï¼Œå¹³å‡å‡†ç¡®ç‡æå‡æ˜¾è‘—ã€‚æ­¤å¤–ï¼ŒUI-R1-3Båœ¨å¤§å‹æ¨¡å‹ä¸Šçš„è¡¨ç°åŒæ ·å…·æœ‰ç«äº‰åŠ›ã€‚è¿™è¡¨æ˜åŸºäºè§„åˆ™çš„å¼ºåŒ–å­¦ä¹ åœ¨GUIç†è§£å’Œæ§åˆ¶æ–¹é¢å…·æœ‰æ½œåŠ›ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>DeepSeek-R1å±•ç¤ºäº†å¤§å‹è¯­è¨€æ¨¡å‹é€šè¿‡å¼ºåŒ–å­¦ä¹ å±•ç°çš„æ¨ç†èƒ½åŠ›ã€‚</li>
<li>UI-R1æ¡†æ¶æ—¨åœ¨æ¢ç´¢è§„åˆ™åŸºç¡€å¼ºåŒ–å­¦ä¹ å¦‚ä½•å¢å¼ºå¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹åœ¨GUIè¡ŒåŠ¨é¢„æµ‹ä»»åŠ¡ä¸­çš„æ¨ç†èƒ½åŠ›ã€‚</li>
<li>UI-R1å¼•å…¥åŸºäºè¡ŒåŠ¨çš„è§„åˆ™å¥–åŠ±ï¼Œé€šè¿‡ç­–ç•¥å‹ç®—æ³•å¦‚GRPOè¿›è¡Œæ¨¡å‹ä¼˜åŒ–ã€‚</li>
<li>å®éªŒç»“æœæ˜¾ç¤ºï¼ŒUI-R1-3Båœ¨å¤šç§ä»»åŠ¡ä¸Šè¾ƒåŸºå‡†æ¨¡å‹è¡¨ç°æ˜¾è‘—æé«˜ï¼Œå¹¶è¡¨ç°å‡ºå¯¹å¤§å‹æ¨¡å‹çš„ç«äº‰åŠ›ã€‚</li>
<li>åŸºäºè§„åˆ™çš„å¼ºåŒ–å­¦ä¹ åœ¨GUIç†è§£å’Œæ§åˆ¶æ–¹é¢å±•ç°å‡ºæ½œåŠ›ã€‚</li>
<li>æ•°æ®é›†åŒ…å«136é¡¹å…·æœ‰æŒ‘æˆ˜æ€§çš„ä»»åŠ¡ï¼Œæ¶µç›–ç§»åŠ¨è®¾å¤‡ä¸Šçš„äº”ç§å¸¸è§åŠ¨ä½œç±»å‹ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.21620">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-57572e7a13f08dc88cf8256224ce8c37.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-759ab689c47377f1d5f7ec8d41fab7e2.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-7888ec58d54be02625496730e97f7c0e.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="SpiritSight-Agent-Advanced-GUI-Agent-with-One-Look"><a href="#SpiritSight-Agent-Advanced-GUI-Agent-with-One-Look" class="headerlink" title="SpiritSight Agent: Advanced GUI Agent with One Look"></a>SpiritSight Agent: Advanced GUI Agent with One Look</h2><p><strong>Authors:Zhiyuan Huang, Ziming Cheng, Junting Pan, Zhaohui Hou, Mingjie Zhan</strong></p>
<p>Graphical User Interface (GUI) agents show amazing abilities in assisting human-computer interaction, automating human userâ€™s navigation on digital devices. An ideal GUI agent is expected to achieve high accuracy, low latency, and compatibility for different GUI platforms. Recent vision-based approaches have shown promise by leveraging advanced Vision Language Models (VLMs). While they generally meet the requirements of compatibility and low latency, these vision-based GUI agents tend to have low accuracy due to their limitations in element grounding. To address this issue, we propose $\textbf{SpiritSight}$, a vision-based, end-to-end GUI agent that excels in GUI navigation tasks across various GUI platforms. First, we create a multi-level, large-scale, high-quality GUI dataset called $\textbf{GUI-Lasagne}$ using scalable methods, empowering SpiritSight with robust GUI understanding and grounding capabilities. Second, we introduce the $\textbf{Universal Block Parsing (UBP)}$ method to resolve the ambiguity problem in dynamic high-resolution of visual inputs, further enhancing SpiritSightâ€™s ability to ground GUI objects. Through these efforts, SpiritSight agent outperforms other advanced methods on diverse GUI benchmarks, demonstrating its superior capability and compatibility in GUI navigation tasks. Models and datasets are available at <a target="_blank" rel="noopener" href="https://hzhiyuan.github.io/SpiritSight-Agent">https://hzhiyuan.github.io/SpiritSight-Agent</a>. </p>
<blockquote>
<p>å›¾å½¢ç”¨æˆ·ç•Œé¢ï¼ˆGUIï¼‰ä»£ç†åœ¨è¾…åŠ©äººæœºäº¤äº’ã€è‡ªåŠ¨åŒ–äººç±»ç”¨æˆ·åœ¨æ•°å­—è®¾å¤‡ä¸Šçš„å¯¼èˆªæ–¹é¢è¡¨ç°å‡ºæƒŠäººçš„èƒ½åŠ›ã€‚ç†æƒ³çš„GUIä»£ç†åº”è¾¾åˆ°é«˜å‡†ç¡®æ€§ã€ä½å»¶è¿Ÿå’Œä¸åŒGUIå¹³å°çš„å…¼å®¹æ€§ã€‚æœ€è¿‘çš„åŸºäºè§†è§‰çš„æ–¹æ³•é€šè¿‡åˆ©ç”¨å…ˆè¿›çš„è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMsï¼‰æ˜¾ç¤ºå‡ºæ½œåŠ›ã€‚è™½ç„¶å®ƒä»¬é€šå¸¸æ»¡è¶³å…¼å®¹æ€§å’Œä½å»¶è¿Ÿçš„è¦æ±‚ï¼Œä½†è¿™äº›åŸºäºè§†è§‰çš„GUIä»£ç†å¾€å¾€ç”±äºå…ƒç´ å®šä½çš„é™åˆ¶è€Œå‡†ç¡®æ€§è¾ƒä½ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†åŸºäºè§†è§‰çš„ç«¯åˆ°ç«¯GUIä»£ç†â€”â€”SpiritSightï¼Œå®ƒåœ¨å„ç§GUIå¹³å°ä¸Šçš„GUIå¯¼èˆªä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬ä½¿ç”¨å¯æ‰©å±•çš„æ–¹æ³•åˆ›å»ºäº†ä¸€ä¸ªå¤šå±‚æ¬¡ã€å¤§è§„æ¨¡ã€é«˜è´¨é‡çš„GUIæ•°æ®é›†ï¼Œåä¸ºGUI-Lasagneï¼Œä¸ºSpiritSightæä¾›å¼ºå¤§çš„GUIç†è§£å’Œå®šä½èƒ½åŠ›ã€‚å…¶æ¬¡ï¼Œæˆ‘ä»¬å¼•å…¥äº†é€šç”¨å—è§£æï¼ˆUBPï¼‰æ–¹æ³•æ¥è§£å†³åŠ¨æ€é«˜åˆ†è¾¨ç‡è§†è§‰è¾“å…¥çš„æ­§ä¹‰é—®é¢˜ï¼Œè¿›ä¸€æ­¥å¢å¼ºäº†SpiritSightå¯¹GUIå¯¹è±¡çš„å®šä½èƒ½åŠ›ã€‚é€šè¿‡è¿™äº›åŠªåŠ›ï¼ŒSpiritSightä»£ç†åœ¨å¤šç§GUIåŸºå‡†æµ‹è¯•ä¸Šè¶…è¶Šäº†å…¶ä»–å…ˆè¿›æ–¹æ³•ï¼Œè¯æ˜äº†å…¶åœ¨GUIå¯¼èˆªä»»åŠ¡ä¸­çš„å“è¶Šèƒ½åŠ›å’Œå…¼å®¹æ€§ã€‚æ¨¡å‹å’Œæ•°æ®é›†å¯åœ¨<a target="_blank" rel="noopener" href="https://hzhiyuan.github.io/SpiritSight-Agent%E4%B8%8A%E6%89%BE%E5%88%B0%E3%80%82">https://hzhiyuan.github.io/SpiritSight-Agentä¸Šæ‰¾åˆ°ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.03196v2">PDF</a> Paper accepted to CVPR 2025</p>
<p><strong>Summary</strong><br>     è§†è§‰ç•Œé¢çš„å›¾å½¢ç”¨æˆ·ç•Œé¢ï¼ˆGUIï¼‰ä»£ç†åœ¨è¾…åŠ©äººæœºäº¤äº’ã€è‡ªåŠ¨åŒ–ç”¨æˆ·å¯¼èˆªæ–¹é¢å±•ç°å‡ºå¼ºå¤§èƒ½åŠ›ã€‚ä¸ºæ”¹è¿›ç°æœ‰è§†è§‰åŸºç¡€GUIä»£ç†çš„ç²¾åº¦é—®é¢˜ï¼Œæå‡ºäº†ä¸€æ¬¾åä¸ºSpiritSightçš„æ–°å‹GUIä»£ç†ï¼Œå…¶å€ŸåŠ©å¤§è§„æ¨¡GUIæ•°æ®é›†GUI-Lasagneä¸Universal Block Parsingï¼ˆUBPï¼‰æ–¹æ³•ï¼Œæå‡äº†å¯¹GUIå¯¼èˆªä»»åŠ¡çš„æŒæ¡èƒ½åŠ›ï¼Œå±•ç°å‡ºå“è¶Šçš„è·¨å¹³å°å…¼å®¹æ€§åŠé«˜ç²¾åº¦ã€ä½å»¶è¿Ÿç‰¹æ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>GUIä»£ç†åœ¨ååŠ©äººæœºäº¤äº’å’Œè‡ªåŠ¨åŒ–å¯¼èˆªæ–¹é¢è¡¨ç°çªå‡ºï¼Œéœ€è¦æ»¡è¶³é«˜å‡†ç¡®æ€§ã€ä½å»¶è¿Ÿå’Œä¸åŒGUIå¹³å°çš„å…¼å®¹æ€§ã€‚</li>
<li>ç°æœ‰è§†è§‰åŸºç¡€çš„GUIä»£ç†åœ¨å…ƒç´ å®šä½æ–¹é¢å­˜åœ¨å±€é™æ€§ï¼Œå¯¼è‡´å‡†ç¡®æ€§è¾ƒä½ã€‚</li>
<li>ä¸ºè§£å†³è¿™ä¸€é—®é¢˜ï¼Œæå‡ºäº†SpiritSightä»£ç†ï¼Œå…¶åœ¨å¤§è§„æ¨¡GUIæ•°æ®é›†GUI-Lasagneçš„æ”¯æŒä¸‹ï¼Œå…·å¤‡å¼ºå¤§çš„GUIç†è§£å’Œå®šä½èƒ½åŠ›ã€‚</li>
<li>Universal Block Parsingï¼ˆUBPï¼‰æ–¹æ³•è¢«å¼•å…¥ä»¥è§£å†³åŠ¨æ€é«˜åˆ†è¾¨ç‡è§†è§‰è¾“å…¥ä¸­çš„æ­§ä¹‰é—®é¢˜ï¼Œå¢å¼ºäº†SpiritSightå¯¹GUIå¯¹è±¡çš„å®šä½èƒ½åŠ›ã€‚</li>
<li>SpiritSightä»£ç†åœ¨å¤šç§GUIåŸºå‡†æµ‹è¯•ä¸Šè¡¨ç°å‡ºä¼˜å¼‚æ€§èƒ½ï¼Œå±•ç°å‡ºå…¶é«˜å…¼å®¹æ€§å’Œå¼ºå¤§èƒ½åŠ›ã€‚</li>
<li>SpiritSightä»£ç†å’Œç›¸å…³çš„æ•°æ®é›†å¯é€šè¿‡<a target="_blank" rel="noopener" href="https://hzhiyuan.github.io/SpiritSight-Agent%E8%8E%B7%E5%8F%96%E3%80%82">https://hzhiyuan.github.io/SpiritSight-Agentè·å–ã€‚</a></li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.03196">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-8054c49390024f9a1748660c63e9fa73.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-d18090c2f4997021579860d3403bf868.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-a91a3882533730dcae4a8638c1d08cd7.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-f68458d56c3be91a619301734787c3b3.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b82e0eded9c8aab04cb39465895301b2.jpg" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="TradingAgents-Multi-Agents-LLM-Financial-Trading-Framework"><a href="#TradingAgents-Multi-Agents-LLM-Financial-Trading-Framework" class="headerlink" title="TradingAgents: Multi-Agents LLM Financial Trading Framework"></a>TradingAgents: Multi-Agents LLM Financial Trading Framework</h2><p><strong>Authors:Yijia Xiao, Edward Sun, Di Luo, Wei Wang</strong></p>
<p>Significant progress has been made in automated problem-solving using societies of agents powered by large language models (LLMs). In finance, efforts have largely focused on single-agent systems handling specific tasks or multi-agent frameworks independently gathering data. However, multi-agent systemsâ€™ potential to replicate real-world trading firmsâ€™ collaborative dynamics remains underexplored. TradingAgents proposes a novel stock trading framework inspired by trading firms, featuring LLM-powered agents in specialized roles such as fundamental analysts, sentiment analysts, technical analysts, and traders with varied risk profiles. The framework includes Bull and Bear researcher agents assessing market conditions, a risk management team monitoring exposure, and traders synthesizing insights from debates and historical data to make informed decisions. By simulating a dynamic, collaborative trading environment, this framework aims to improve trading performance. Detailed architecture and extensive experiments reveal its superiority over baseline models, with notable improvements in cumulative returns, Sharpe ratio, and maximum drawdown, highlighting the potential of multi-agent LLM frameworks in financial trading. TradingAgents is available at <a target="_blank" rel="noopener" href="https://github.com/TauricResearch">https://github.com/TauricResearch</a>. </p>
<blockquote>
<p>åœ¨åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰é©±åŠ¨çš„æ™ºèƒ½ä½“ç¤¾ä¼šè§£å†³è‡ªåŠ¨åŒ–é—®é¢˜æ–¹é¢å–å¾—äº†é‡å¤§è¿›å±•ã€‚åœ¨é‡‘èé¢†åŸŸï¼Œç›¸å…³åŠªåŠ›ä¸»è¦é›†ä¸­åœ¨å¤„ç†ç‰¹å®šä»»åŠ¡çš„å•ä¸€æ™ºèƒ½ä½“ç³»ç»Ÿæˆ–ç‹¬ç«‹æ”¶é›†æ•°æ®çš„å¤šæ™ºèƒ½ä½“æ¡†æ¶ä¸Šã€‚ç„¶è€Œï¼Œå¤šæ™ºèƒ½ä½“ç³»ç»Ÿåœ¨å¤åˆ¶ç°å®ä¸–ç•Œäº¤æ˜“å…¬å¸çš„åä½œåŠ¨æ€æ–¹é¢çš„æ½œåŠ›å°šæœªå¾—åˆ°å……åˆ†æ¢ç´¢ã€‚ã€ŠTradingAgentsã€‹æå‡ºäº†ä¸€ç§å—äº¤æ˜“å…¬å¸å¯å‘çš„æ–°å‹è‚¡ç¥¨äº¤æ˜“æ¡†æ¶ï¼Œè¯¥æ¡†æ¶å…·æœ‰ä¸“é—¨çš„è§’è‰²æ™ºèƒ½ä½“ï¼Œä¾‹å¦‚åŸºç¡€åˆ†æå¸ˆã€æƒ…ç»ªåˆ†æå¸ˆã€æŠ€æœ¯åˆ†æå¸ˆå’Œä¸åŒé£é™©çŠ¶å†µçš„äº¤æ˜“å‘˜ç­‰ã€‚è¯¥æ¡†æ¶åŒ…æ‹¬è¯„ä¼°å¸‚åœºæ¡ä»¶çš„ç‰›å¸‚å’Œç†Šå¸‚ç ”ç©¶è€…æ™ºèƒ½ä½“ã€ç›‘æ§æ•å£çš„é£é™©ç®¡ç†å›¢é˜Ÿä»¥åŠä»è¾©è®ºå’Œå†å²æ•°æ®ä¸­æç‚¼è§è§£ä»¥åšå‡ºæ˜æ™ºå†³ç­–çš„äº¤æ˜“å‘˜ã€‚é€šè¿‡æ¨¡æ‹ŸåŠ¨æ€åä½œçš„äº¤æ˜“ç¯å¢ƒï¼Œè¯¥æ¡†æ¶æ—¨åœ¨æé«˜äº¤æ˜“æ€§èƒ½ã€‚è¯¦ç»†çš„æ¶æ„å’Œå¹¿æ³›çš„å®éªŒè¡¨æ˜å…¶åœ¨ç´¯è®¡å›æŠ¥ã€å¤æ™®æ¯”ç‡å’Œæœ€å¤§å›æ’¤æ–¹é¢ä¼˜äºåŸºå‡†æ¨¡å‹ï¼Œçªæ˜¾äº†å¤šæ™ºèƒ½ä½“LLMæ¡†æ¶åœ¨é‡‘èäº¤æ˜“ä¸­çš„æ½œåŠ›ã€‚ã€ŠTradingAgentsã€‹å¯é€šè¿‡ <a target="_blank" rel="noopener" href="https://github.com/TauricResearch">https://github.com/TauricResearch</a> è·å–ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.20138v6">PDF</a> Oral, Multi-Agent AI in the Real World @ AAAI 2025</p>
<p><strong>æ€»ç»“</strong></p>
<p>åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„ä»£ç†ç¤¾ä¼šåœ¨è‡ªåŠ¨åŒ–é—®é¢˜è§£å†³æ–¹é¢å–å¾—äº†æ˜¾è‘—è¿›å±•ã€‚åœ¨é‡‘èé¢†åŸŸï¼Œå°½ç®¡å•ä¸€ä»£ç†ç³»ç»Ÿå¤„ç†ç‰¹å®šä»»åŠ¡æˆ–å¤šä»£ç†æ¡†æ¶ç‹¬ç«‹æ”¶é›†æ•°æ®çš„å·¥ä½œå·²ç»å¤‡å—å…³æ³¨ï¼Œä½†å¤šä»£ç†ç³»ç»Ÿåœ¨æ¨¡æ‹Ÿç°å®ä¸–ç•Œäº¤æ˜“å…¬å¸åä½œåŠ¨æ€æ–¹é¢çš„æ½œåŠ›ä»è¢«ä½ä¼°ã€‚TradingAgentsæå‡ºä¸€ä¸ªå—äº¤æ˜“å…¬å¸å¯å‘çš„è‚¡ç¥¨äº¤æ˜“æ–°æ¡†æ¶ï¼Œè¯¥æ¡†æ¶é‡‡ç”¨LLMé©±åŠ¨çš„å¤šä»£ç†ç³»ç»Ÿï¼ŒåŒ…æ‹¬åŸºç¡€åˆ†æå¸ˆã€æƒ…ç»ªåˆ†æå¸ˆã€æŠ€æœ¯åˆ†æå¸ˆå’Œå…·æœ‰ä¸åŒé£é™©ç‰¹å¾çš„äº¤æ˜“å‘˜ç­‰ä¸“ä¸šåŒ–è§’è‰²ã€‚æ¡†æ¶åŒ…æ‹¬è¯„ä¼°å¸‚åœºçŠ¶å†µçš„Bullå’ŒBearç ”ç©¶å‘˜ä»£ç†ã€ç›‘æ§é£é™©çš„é£é™©ç®¡ç†å›¢é˜Ÿä»¥åŠåˆæˆè¾©è®ºå’Œå†å²æ•°æ®ä»¥åšå‡ºæ˜æ™ºå†³ç­–çš„äº¤æ˜“å‘˜ã€‚é€šè¿‡æ¨¡æ‹ŸåŠ¨æ€åä½œçš„äº¤æ˜“ç¯å¢ƒï¼Œè¯¥æ¡†æ¶æ—¨åœ¨æé«˜äº¤æ˜“æ€§èƒ½ã€‚è¯¦ç»†çš„æ¶æ„å’Œå¹¿æ³›çš„å®éªŒè¡¨æ˜ï¼Œå…¶åœ¨ç´¯ç§¯å›æŠ¥ã€å¤æ™®æ¯”ç‡å’Œæœ€å¤§å›æ’¤æ–¹é¢ä¼˜äºåŸºå‡†æ¨¡å‹ï¼Œçªæ˜¾äº†å¤šä»£ç†LLMæ¡†æ¶åœ¨é‡‘èäº¤æ˜“ä¸­çš„æ½œåŠ›ã€‚TradingAgentså¹³å°å¯é€šè¿‡<a target="_blank" rel="noopener" href="https://github.com/TauricResearch">https://github.com/TauricResearch</a>è®¿é—®ã€‚</p>
<p><strong>å…³é”®è§è§£</strong></p>
<ol>
<li>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰é©±åŠ¨çš„ä»£ç†ç¤¾ä¼šåœ¨è‡ªåŠ¨åŒ–é—®é¢˜è§£å†³æ–¹é¢å–å¾—æ˜¾è‘—è¿›æ­¥ã€‚</li>
<li>é‡‘èé¢†åŸŸä¸»è¦èšç„¦äºå•ä¸€ä»£ç†ç³»ç»Ÿå¤„ç†ç‰¹å®šä»»åŠ¡æˆ–å¤šä»£ç†æ¡†æ¶ç‹¬ç«‹æ”¶é›†æ•°æ®çš„åº”ç”¨åœºæ™¯ã€‚</li>
<li>å¤šä»£ç†ç³»ç»Ÿåœ¨æ¨¡æ‹Ÿç°å®ä¸–ç•Œäº¤æ˜“å…¬å¸çš„åä½œåŠ¨æ€æ–¹é¢å…·æœ‰æ½œåŠ›ã€‚</li>
<li>TradingAgentsæå‡ºä¸€ç§æ¨¡æ‹Ÿäº¤æ˜“å…¬å¸çš„æ–°å‹è‚¡ç¥¨äº¤æ˜“æ¡†æ¶ï¼Œé‡‡ç”¨å¤šä»£ç†ç³»ç»Ÿå¤„ç†å¤šç§é‡‘èè§’è‰²ã€‚</li>
<li>è¯¥æ¡†æ¶åŒ…å«å¸‚åœºçŠ¶å†µè¯„ä¼°ã€é£é™©ç®¡ç†ä»¥åŠåŸºäºè¾©è®ºå’Œå†å²æ•°æ®çš„å†³ç­–åˆ¶å®šç­‰è¦ç´ ã€‚</li>
<li>é€šè¿‡æ¨¡æ‹ŸåŠ¨æ€åä½œçš„äº¤æ˜“ç¯å¢ƒï¼Œè¯¥æ¡†æ¶å¯æé«˜äº¤æ˜“æ€§èƒ½ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.20138">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-4f5d35f3ebfc95f19bf9db6c88bf5c21.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-b30fff5ccc871c8eb463e0482df36120.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-25633305684d8ad1c87d09dcdbe8556b.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-d197b1f9955d8a4274d4868459c4e223.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-eba4b8a51ddba76a7d9ed986fefccd57.jpg" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1><h2 id="Enhancing-LLMs-for-Power-System-Simulations-A-Feedback-driven-Multi-agent-Framework"><a href="#Enhancing-LLMs-for-Power-System-Simulations-A-Feedback-driven-Multi-agent-Framework" class="headerlink" title="Enhancing LLMs for Power System Simulations: A Feedback-driven   Multi-agent Framework"></a>Enhancing LLMs for Power System Simulations: A Feedback-driven   Multi-agent Framework</h2><p><strong>Authors:Mengshuo Jia, Zeyu Cui, Gabriela Hug</strong></p>
<p>The integration of experimental technologies with large language models (LLMs) is transforming scientific research. It positions AI as a versatile research assistant rather than a mere problem-solving tool. In the field of power systems, however, managing simulations â€“ one of the essential experimental technologies â€“ remains a challenge for LLMs due to their limited domain-specific knowledge, restricted reasoning capabilities, and imprecise handling of simulation parameters. To address these limitations, this paper proposes a feedback-driven, multi-agent framework. It incorporates three proposed modules: an enhanced retrieval-augmented generation (RAG) module, an improved reasoning module, and a dynamic environmental acting module with an error-feedback mechanism. Validated on 69 diverse tasks from Daline and MATPOWER, this framework achieves success rates of 93.13% and 96.85%, respectively. It significantly outperforms ChatGPT 4o, o1-preview, and the fine-tuned GPT-4o, which all achieved a success rate lower than 30% on complex tasks. Additionally, the proposed framework also supports rapid, cost-effective task execution, completing each simulation in approximately 30 seconds at an average cost of 0.014 USD for tokens. Overall, this adaptable framework lays a foundation for developing intelligent LLM-based assistants for human researchers, facilitating power system research and beyond. </p>
<blockquote>
<p>å°†å®éªŒæŠ€æœ¯ä¸å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„ç»“åˆæ­£åœ¨æ”¹å˜ç§‘å­¦ç ”ç©¶çš„æ–¹å¼ã€‚å®ƒå°†äººå·¥æ™ºèƒ½å®šä½ä¸ºå¤šæ‰å¤šè‰ºçš„ç ”ç©¶åŠ©æ‰‹ï¼Œè€Œä¸ä»…ä»…æ˜¯è§£å†³é—®é¢˜çš„å·¥å…·ã€‚ç„¶è€Œï¼Œåœ¨ç”µåŠ›ç³»ç»Ÿé¢†åŸŸï¼Œç®¡ç†æ¨¡æ‹Ÿï¼ˆä¸€ç§é‡è¦çš„å®éªŒæŠ€æœ¯ï¼‰å¯¹LLMæ¥è¯´ä»ç„¶æ˜¯ä¸€ä¸ªæŒ‘æˆ˜ï¼Œå› ä¸ºå®ƒä»¬æœ‰é™çš„ç‰¹å®šé¢†åŸŸçŸ¥è¯†ã€æœ‰é™çš„æ¨ç†èƒ½åŠ›å’Œå¯¹æ¨¡æ‹Ÿå‚æ•°çš„ä¸ç²¾ç¡®å¤„ç†ã€‚ä¸ºäº†å…‹æœè¿™äº›å±€é™æ€§ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§åé¦ˆé©±åŠ¨çš„å¤šæ™ºèƒ½ä½“æ¡†æ¶ã€‚å®ƒç»“åˆäº†ä¸‰ä¸ªæå‡ºçš„æ¨¡å—ï¼šä¸€ä¸ªå¢å¼ºçš„æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰æ¨¡å—ï¼Œä¸€ä¸ªæ”¹è¿›çš„æ¨ç†æ¨¡å—ï¼Œä»¥åŠä¸€ä¸ªå¸¦æœ‰é”™è¯¯åé¦ˆæœºåˆ¶çš„åŠ¨åŠ›ç¯å¢ƒè¡Œä¸ºæ¨¡å—ã€‚åœ¨Dalineå’ŒMATPOWERçš„69ä¸ªä¸åŒä»»åŠ¡ä¸Šè¿›è¡ŒéªŒè¯ï¼Œè¯¥æ¡†æ¶çš„æˆåŠŸç‡åˆ†åˆ«ä¸º93.13%å’Œ96.85%ã€‚å®ƒæ˜¾è‘—ä¼˜äºChatGPT 4oã€o1é¢„è§ˆå’Œç»è¿‡å¾®è°ƒåçš„GPT-4oï¼Œè¿™äº›æ¨¡å‹åœ¨å¤æ‚ä»»åŠ¡ä¸Šçš„æˆåŠŸç‡éƒ½ä½äº30%ã€‚æ­¤å¤–ï¼Œè¯¥æ¡†æ¶è¿˜æ”¯æŒå¿«é€Ÿã€ç»æµçš„ä»»åŠ¡æ‰§è¡Œï¼Œå¹³å‡æ¯ä¸ªæ¨¡æ‹Ÿå¤§çº¦éœ€è¦30ç§’å®Œæˆï¼Œä»¤ç‰Œå¹³å‡æˆæœ¬ä¸º0.014ç¾å…ƒã€‚æ€»çš„æ¥è¯´ï¼Œè¿™ä¸ªçµæ´»å¤šå˜çš„æ¡†æ¶ä¸ºå¼€å‘åŸºäºLLMçš„æ™ºèƒ½åŠ©æ‰‹ä¸ºç ”ç©¶äººå‘˜å¥ å®šäº†åŸºç¡€ï¼Œä¿ƒè¿›äº†ç”µåŠ›ç³»ç»Ÿç ”ç©¶åŠå…¶ä»–é¢†åŸŸçš„ç ”ç©¶ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2411.16707v2">PDF</a> 15 pages</p>
<p><strong>Summary</strong><br>     å®éªŒæŠ€æœ¯ä¸å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„èåˆæ­£åœ¨æ¨åŠ¨ç§‘å­¦ç ”ç©¶çš„å‘å±•ã€‚äººå·¥æ™ºèƒ½å·²æˆä¸ºå¤šæ‰å¤šè‰ºçš„ç ”ç©¶åŠ©æ‰‹ï¼Œè€Œä¸ä»…ä»…æ˜¯è§£å†³é—®é¢˜çš„å·¥å…·ã€‚åœ¨ç”µåŠ›ç³»ç»Ÿé¢†åŸŸï¼Œç®¡ç†æ¨¡æ‹Ÿä½œä¸ºé‡è¦çš„å®éªŒæŠ€æœ¯ä¹‹ä¸€ä»ç„¶æ˜¯LLMçš„ä¸€ä¸ªæŒ‘æˆ˜ã€‚é’ˆå¯¹è¿™äº›æŒ‘æˆ˜ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§åé¦ˆé©±åŠ¨çš„å¤šæ™ºèƒ½ä½“æ¡†æ¶ï¼ŒåŒ…æ‹¬å¢å¼ºæ£€ç´¢å¢å¼ºç”Ÿæˆæ¨¡å—ã€æ”¹è¿›æ¨ç†æ¨¡å—å’Œå…·æœ‰é”™è¯¯åé¦ˆæœºåˆ¶åŠ¨æ€ç¯å¢ƒè¡Œä¸ºæ¨¡å—ã€‚è¯¥æ¡†æ¶åœ¨Dalineå’ŒMATPOWERçš„69é¡¹ä¸åŒä»»åŠ¡ä¸Šå–å¾—äº†é«˜è¾¾93.13%å’Œ96.85%çš„æˆåŠŸç‡ï¼Œæ˜¾è‘—ä¼˜äºChatGPT 4oã€o1é¢„è§ˆå’Œå¾®è°ƒåçš„GPT-4oã€‚æ­¤å¤–ï¼Œè¯¥æ¡†æ¶è¿˜æ”¯æŒå¿«é€Ÿã€ç»æµçš„ä»»åŠ¡æ‰§è¡Œï¼Œæ¯ä¸ªæ¨¡æ‹Ÿä»»åŠ¡å¤§çº¦éœ€è¦30ç§’ï¼Œå¹³å‡æ¯ä¸ªä»¤ç‰Œæˆæœ¬ä¸º0.014ç¾å…ƒã€‚æ€»ä½“è€Œè¨€ï¼Œè¿™ä¸€çµæ´»æ¡†æ¶ä¸ºå¼€å‘åŸºäºLLMçš„æ™ºèƒ½åŠ©ç†ç ”ç©¶å‘˜å¥ å®šäº†åŸºç¡€ï¼Œæ¨åŠ¨äº†ç”µåŠ›ç³»ç»Ÿç ”ç©¶åŠå…¶ä»–é¢†åŸŸçš„å‘å±•ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å®éªŒæŠ€æœ¯ä¸LLMçš„èåˆæ¨åŠ¨ç§‘å­¦ç ”ç©¶å‘å±•ã€‚</li>
<li>LLMåœ¨ç”µåŠ›ç³»ç»Ÿæ¨¡æ‹Ÿç®¡ç†ä¸Šä»é¢ä¸´æŒ‘æˆ˜ã€‚</li>
<li>æå‡ºäº†ä¸€ç§åé¦ˆé©±åŠ¨çš„å¤šæ™ºèƒ½ä½“æ¡†æ¶æ¥è§£å†³è¿™äº›æŒ‘æˆ˜ã€‚</li>
<li>è¯¥æ¡†æ¶åŒ…æ‹¬å¢å¼ºæ£€ç´¢å¢å¼ºç”Ÿæˆæ¨¡å—ã€æ”¹è¿›æ¨ç†æ¨¡å—å’ŒåŠ¨æ€ç¯å¢ƒè¡Œä¸ºæ¨¡å—ã€‚</li>
<li>è¯¥æ¡†æ¶åœ¨å¤šç§ä»»åŠ¡ä¸Šå–å¾—äº†è¾ƒé«˜çš„æˆåŠŸç‡ï¼Œæ˜¾è‘—ä¼˜äºå…¶ä»–æ¨¡å‹ã€‚</li>
<li>æ¡†æ¶æ”¯æŒå¿«é€Ÿã€ç»æµçš„ä»»åŠ¡æ‰§è¡Œã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2411.16707">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-aa5103527c439d5a335d11f1d69cdd17.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-5848cc20fa629353c26e9046ac47cda3.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-215d480ff020ceb604d7a66b7a664caa.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b917352c95393008711c226e6b2853e0.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-5e7716039a29c2be1fd1c21e05bf1afa.jpg" align="middle">
</details>


<h1 id="-9"><a href="#-9" class="headerlink" title=""></a></h1><h2 id="Agent-Security-Bench-ASB-Formalizing-and-Benchmarking-Attacks-and-Defenses-in-LLM-based-Agents"><a href="#Agent-Security-Bench-ASB-Formalizing-and-Benchmarking-Attacks-and-Defenses-in-LLM-based-Agents" class="headerlink" title="Agent Security Bench (ASB): Formalizing and Benchmarking Attacks and   Defenses in LLM-based Agents"></a>Agent Security Bench (ASB): Formalizing and Benchmarking Attacks and   Defenses in LLM-based Agents</h2><p><strong>Authors:Hanrong Zhang, Jingyuan Huang, Kai Mei, Yifei Yao, Zhenting Wang, Chenlu Zhan, Hongwei Wang, Yongfeng Zhang</strong></p>
<p>Although LLM-based agents, powered by Large Language Models (LLMs), can use external tools and memory mechanisms to solve complex real-world tasks, they may also introduce critical security vulnerabilities. However, the existing literature does not comprehensively evaluate attacks and defenses against LLM-based agents. To address this, we introduce Agent Security Bench (ASB), a comprehensive framework designed to formalize, benchmark, and evaluate the attacks and defenses of LLM-based agents, including 10 scenarios (e.g., e-commerce, autonomous driving, finance), 10 agents targeting the scenarios, over 400 tools, 27 different types of attack&#x2F;defense methods, and 7 evaluation metrics. Based on ASB, we benchmark 10 prompt injection attacks, a memory poisoning attack, a novel Plan-of-Thought backdoor attack, 4 mixed attacks, and 11 corresponding defenses across 13 LLM backbones. Our benchmark results reveal critical vulnerabilities in different stages of agent operation, including system prompt, user prompt handling, tool usage, and memory retrieval, with the highest average attack success rate of 84.30%, but limited effectiveness shown in current defenses, unveiling important works to be done in terms of agent security for the community. We also introduce a new metric to evaluate the agentsâ€™ capability to balance utility and security. Our code can be found at <a target="_blank" rel="noopener" href="https://github.com/agiresearch/ASB">https://github.com/agiresearch/ASB</a>. </p>
<blockquote>
<p>è™½ç„¶åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„ä»£ç†å¯ä»¥ä½¿ç”¨å¤–éƒ¨å·¥å…·å’Œè®°å¿†æœºåˆ¶æ¥è§£å†³å¤æ‚çš„ç°å®ä¸–ç•Œä»»åŠ¡ï¼Œä½†å®ƒä»¬ä¹Ÿå¯èƒ½å¼•å…¥å…³é”®çš„å®‰å…¨æ¼æ´ã€‚ç„¶è€Œï¼Œç°æœ‰æ–‡çŒ®å¹¶æ²¡æœ‰å…¨é¢è¯„ä¼°é’ˆå¯¹åŸºäºLLMçš„ä»£ç†çš„æ”»å‡»å’Œé˜²å¾¡æªæ–½ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬å¼•å…¥äº†Agent Security Benchï¼ˆASBï¼‰ï¼Œè¿™æ˜¯ä¸€ä¸ªæ—¨åœ¨è§„èŒƒã€åŸºå‡†æµ‹è¯•å’Œè¯„ä¼°åŸºäºLLMçš„ä»£ç†çš„æ”»å‡»å’Œé˜²å¾¡çš„ç»¼åˆæ¡†æ¶ï¼ŒåŒ…æ‹¬10ä¸ªåœºæ™¯ï¼ˆä¾‹å¦‚ç”µå­å•†åŠ¡ã€è‡ªåŠ¨é©¾é©¶ã€é‡‘èï¼‰ã€é’ˆå¯¹è¿™äº›åœºæ™¯çš„10ä¸ªä»£ç†ã€è¶…è¿‡400ç§å·¥å…·ã€27ç§ä¸åŒç±»å‹çš„æ”»å‡»&#x2F;é˜²å¾¡æ–¹æ³•ä»¥åŠ7ç§è¯„ä¼°æŒ‡æ ‡ã€‚åŸºäºASBï¼Œæˆ‘ä»¬å¯¹10ç§æç¤ºæ³¨å…¥æ”»å‡»ã€å†…å­˜ä¸­æ¯’æ”»å‡»ã€æ–°å‹è®¡åˆ’æ€ç»´åé—¨æ”»å‡»ã€4ç§æ··åˆæ”»å‡»ä»¥åŠé’ˆå¯¹13ç§LLMéª¨å¹²ç½‘çš„11ç§ç›¸åº”é˜²å¾¡æªæ–½è¿›è¡Œäº†åŸºå‡†æµ‹è¯•ã€‚æˆ‘ä»¬çš„åŸºå‡†æµ‹è¯•ç»“æœæ­ç¤ºäº†ä»£ç†æ“ä½œä¸åŒé˜¶æ®µçš„å…³é”®æ¼æ´ï¼ŒåŒ…æ‹¬ç³»ç»Ÿæç¤ºã€ç”¨æˆ·æç¤ºå¤„ç†ã€å·¥å…·ä½¿ç”¨å’Œè®°å¿†æ£€ç´¢ï¼Œå¹³å‡æ”»å‡»æˆåŠŸç‡æœ€é«˜è¾¾84.30%ï¼Œä½†å½“å‰é˜²å¾¡æªæ–½çš„æœ‰æ•ˆæ€§æœ‰é™ï¼Œè¿™æ­ç¤ºäº†ç¤¾åŒºåœ¨ä»£ç†å®‰å…¨æ–¹é¢è¿˜æœ‰é‡è¦å·¥ä½œè¦åšã€‚æˆ‘ä»¬è¿˜å¼•å…¥äº†ä¸€ä¸ªæ–°çš„æŒ‡æ ‡æ¥è¯„ä¼°ä»£ç†åœ¨å®ç”¨æ€§å’Œå®‰å…¨æ€§ä¹‹é—´çš„å¹³è¡¡èƒ½åŠ›ã€‚æˆ‘ä»¬çš„ä»£ç å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/agiresearch/ASB%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/agiresearch/ASBæ‰¾åˆ°ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2410.02644v3">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„ä»£ç†è™½ç„¶å¯ä»¥åˆ©ç”¨å¤–éƒ¨å·¥å…·å’Œè®°å¿†æœºåˆ¶æ¥è§£å†³å¤æ‚çš„ç°å®ä¸–ç•Œä»»åŠ¡ï¼Œä½†å®ƒä»¬ä¹Ÿå¯èƒ½å¼•å…¥å…³é”®çš„å®‰å…¨æ¼æ´ã€‚ä¸ºè§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†Agent Security Benchï¼ˆASBï¼‰æ¡†æ¶ï¼Œç”¨äºå¯¹LLMä»£ç†çš„æ”»å‡»å’Œé˜²å¾¡è¿›è¡Œå…¨é¢ã€åŸºå‡†æµ‹è¯•å’Œè¯„ä¼°ã€‚è¯¥æ¡†æ¶åŒ…æ‹¬å¤šç§åœºæ™¯ã€ä»£ç†ã€å·¥å…·ã€æ”»å‡»&#x2F;é˜²å¾¡æ–¹æ³•å’Œè¯„ä¼°æŒ‡æ ‡ã€‚æˆ‘ä»¬çš„åŸºå‡†æµ‹è¯•ç»“æœæ˜¾ç¤ºï¼Œä»£ç†æ“ä½œçš„ä¸åŒé˜¶æ®µå­˜åœ¨å…³é”®æ¼æ´ï¼Œè€Œç°æœ‰é˜²å¾¡æ‰‹æ®µçš„æœ‰æ•ˆæ€§æœ‰é™ã€‚æˆ‘ä»¬è¿˜å¼•å…¥äº†ä¸€ä¸ªæ–°æŒ‡æ ‡æ¥è¯„ä¼°ä»£ç†åœ¨æ•ˆç”¨å’Œå®‰å…¨æ–¹é¢çš„å¹³è¡¡èƒ½åŠ›ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>LLM-based agentsè™½å¯è¿ç”¨å¤–éƒ¨å·¥å…·å’Œè®°å¿†æœºåˆ¶å¤„ç†å¤æ‚ä»»åŠ¡ï¼Œä½†å­˜åœ¨å…³é”®å®‰å…¨æ¼æ´ã€‚</li>
<li>Agent Security Bench (ASB)æ¡†æ¶ç”¨äºå…¨é¢ã€åŸºå‡†æµ‹è¯•LLMä»£ç†çš„æ”»å‡»å’Œé˜²å¾¡ã€‚</li>
<li>ASBæ¡†æ¶åŒ…å«å¤šç§åœºæ™¯ã€ä»£ç†ã€å·¥å…·å’Œæ–¹æ³•ï¼Œæä¾›å…¨é¢çš„è¯„ä¼°æŒ‡æ ‡ã€‚</li>
<li>åŸºå‡†æµ‹è¯•æ­ç¤ºä»£ç†æ“ä½œä¸åŒé˜¶æ®µï¼ˆå¦‚ç³»ç»Ÿæç¤ºã€ç”¨æˆ·æç¤ºå¤„ç†ã€å·¥å…·ä½¿ç”¨å’Œè®°å¿†æ£€ç´¢ï¼‰å­˜åœ¨æ¼æ´ã€‚</li>
<li>æ”»å‡»æˆåŠŸç‡é«˜è¾¾84.30%ï¼Œè€Œç°æœ‰é˜²å¾¡æ‰‹æ®µæ•ˆæœæœ‰é™ã€‚</li>
<li>å¼•å…¥æ–°æŒ‡æ ‡è¯„ä¼°ä»£ç†åœ¨æ•ˆç”¨å’Œå®‰å…¨æ–¹é¢çš„å¹³è¡¡èƒ½åŠ›ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2410.02644">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-248047d61a373211dd2e8c2b184c89cf.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-93471f2f5bc0057346af104cbf07b944.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a6afad9b83c8d71ae6838eef48af202d.jpg" align="middle">
</details>


<h1 id="-10"><a href="#-10" class="headerlink" title=""></a></h1><h2 id="COMBO-Compositional-World-Models-for-Embodied-Multi-Agent-Cooperation"><a href="#COMBO-Compositional-World-Models-for-Embodied-Multi-Agent-Cooperation" class="headerlink" title="COMBO: Compositional World Models for Embodied Multi-Agent Cooperation"></a>COMBO: Compositional World Models for Embodied Multi-Agent Cooperation</h2><p><strong>Authors:Hongxin Zhang, Zeyuan Wang, Qiushi Lyu, Zheyuan Zhang, Sunli Chen, Tianmin Shu, Behzad Dariush, Kwonjoon Lee, Yilun Du, Chuang Gan</strong></p>
<p>In this paper, we investigate the problem of embodied multi-agent cooperation, where decentralized agents must cooperate given only egocentric views of the world. To effectively plan in this setting, in contrast to learning world dynamics in a single-agent scenario, we must simulate world dynamics conditioned on an arbitrary number of agentsâ€™ actions given only partial egocentric visual observations of the world. To address this issue of partial observability, we first train generative models to estimate the overall world state given partial egocentric observations. To enable accurate simulation of multiple sets of actions on this world state, we then propose to learn a compositional world model for multi-agent cooperation by factorizing the naturally composable joint actions of multiple agents and compositionally generating the video conditioned on the world state. By leveraging this compositional world model, in combination with Vision Language Models to infer the actions of other agents, we can use a tree search procedure to integrate these modules and facilitate online cooperative planning. We evaluate our methods on three challenging benchmarks with 2-4 agents. The results show our compositional world model is effective and the framework enables the embodied agents to cooperate efficiently with different agents across various tasks and an arbitrary number of agents, showing the promising future of our proposed methods. More videos can be found at <a target="_blank" rel="noopener" href="https://umass-embodied-agi.github.io/COMBO/">https://umass-embodied-agi.github.io/COMBO/</a>. </p>
<blockquote>
<p>æœ¬æ–‡ç ”ç©¶äº†å…·èº«å¤šæ™ºèƒ½ä½“åˆä½œé—®é¢˜ï¼Œå³åˆ†æ•£çš„æ™ºèƒ½ä½“ä»…å‡­ä»¥è‡ªæˆ‘ä¸ºä¸­å¿ƒçš„ä¸–ç•Œè§†å›¾è¿›è¡Œåä½œã€‚ä¸ºäº†åœ¨è¿™ç§ç¯å¢ƒä¸‹è¿›è¡Œæœ‰æ•ˆçš„è§„åˆ’ï¼Œä¸åœ¨å•æ™ºèƒ½ä½“åœºæ™¯ä¸­å­¦ä¹ ä¸–ç•ŒåŠ¨æ€ä¸åŒï¼Œæˆ‘ä»¬å¿…é¡»æ¨¡æ‹Ÿä»…æ ¹æ®ä¸–ç•Œéƒ¨åˆ†ä»¥è‡ªæˆ‘ä¸ºä¸­å¿ƒçš„è§†è§‰è§‚å¯Ÿä¸‹ä»»æ„æ•°é‡çš„æ™ºèƒ½ä½“çš„è¡ŒåŠ¨çš„ä¸–ç•ŒåŠ¨æ€ã€‚ä¸ºäº†è§£å†³éƒ¨åˆ†å¯è§‚å¯Ÿæ€§çš„é—®é¢˜ï¼Œæˆ‘ä»¬é¦–å…ˆè®­ç»ƒç”Ÿæˆæ¨¡å‹ä»¥æ ¹æ®éƒ¨åˆ†ä»¥è‡ªæˆ‘ä¸ºä¸­å¿ƒçš„è§‚å¯Ÿæ¥ä¼°è®¡æ•´ä½“ä¸–ç•ŒçŠ¶æ€ã€‚ä¸ºäº†èƒ½å¤Ÿå¯¹è¿™ä¸ªä¸–ç•ŒçŠ¶æ€ä¸Šçš„å¤šç»„è¡ŒåŠ¨è¿›è¡Œå‡†ç¡®çš„æ¨¡æ‹Ÿï¼Œç„¶åæˆ‘ä»¬æå‡ºäº†é€šè¿‡åˆ†è§£å¤šä¸ªæ™ºèƒ½ä½“çš„è‡ªç„¶å¯ç»„åˆè”åˆè¡ŒåŠ¨æ¥å­¦ä¹ ç”¨äºå¤šæ™ºèƒ½ä½“åˆä½œçš„å¯ç»„åˆä¸–ç•Œæ¨¡å‹ï¼Œå¹¶æ ¹æ®ä¸–ç•ŒçŠ¶æ€ç»„åˆç”Ÿæˆè§†é¢‘ã€‚é€šè¿‡åˆ©ç”¨è¿™ç§å¯ç»„åˆçš„ä¸–ç•Œæ¨¡å‹ï¼Œç»“åˆè§†è§‰è¯­è¨€æ¨¡å‹æ¥æ¨æ–­å…¶ä»–æ™ºèƒ½ä½“çš„è¡ŒåŠ¨ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨æ ‘æœç´¢ç¨‹åºæ¥æ•´åˆè¿™äº›æ¨¡å—ï¼Œä¿ƒè¿›åœ¨çº¿åä½œè§„åˆ’ã€‚æˆ‘ä»¬åœ¨å…·æœ‰2-4ä¸ªæ™ºèƒ½ä½“çš„ä¸‰ä¸ªå…·æœ‰æŒ‘æˆ˜æ€§çš„åŸºå‡†æµ‹è¯•ä¸Šè¯„ä¼°äº†æˆ‘ä»¬çš„æ–¹æ³•ã€‚ç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„å¯ç»„åˆä¸–ç•Œæ¨¡å‹æ˜¯æœ‰æ•ˆçš„ï¼Œè¯¥æ¡†æ¶ä½¿å…·èº«æ™ºèƒ½ä½“èƒ½å¤Ÿé«˜æ•ˆåœ°ä¸å„ç§ä»»åŠ¡ä¸­çš„ä¸åŒæ™ºèƒ½ä½“ä»¥åŠä»»æ„æ•°é‡çš„æ™ºèƒ½ä½“è¿›è¡Œåä½œï¼Œå±•ç¤ºäº†æˆ‘ä»¬æå‡ºæ–¹æ³•çš„æœªæ¥å‰æ™¯ã€‚æ›´å¤šè§†é¢‘å¯åœ¨<a target="_blank" rel="noopener" href="https://umass-embodied-agi.github.io/COMBO/%E6%89%BE%E5%88%B0%E3%80%82">https://umass-embodied-agi.github.io/COMBO/æ‰¾åˆ°ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2404.10775v3">PDF</a> Published at ICLR 2025. 24 pages. The first three authors contributed   equally</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ç ”ç©¶äº†å¤šæ™ºèƒ½ä½“åˆä½œçš„éš¾é¢˜ï¼Œå…¶ä¸­åˆ†æ•£çš„ä»£ç†åªèƒ½æ ¹æ®ä»¥è‡ªæˆ‘ä¸ºä¸­å¿ƒçš„è§†è§’è§‚å¯Ÿä¸–ç•Œæ¥è¿›è¡Œåˆä½œã€‚ä¸ºäº†åœ¨è¿™ç§ç¯å¢ƒä¸­è¿›è¡Œæœ‰æ•ˆçš„è§„åˆ’ï¼Œå¿…é¡»æ¨¡æ‹Ÿä¸–ç•ŒåŠ¨æ€ï¼Œä»¥é€‚åº”ä»»æ„æ•°é‡çš„ä»£ç†è¡ŒåŠ¨ï¼ŒåŒæ—¶ä»…æ ¹æ®éƒ¨åˆ†ä»¥è‡ªæˆ‘ä¸ºä¸­å¿ƒçš„è§‚å¯Ÿç»“æœã€‚ä¸ºè§£å†³éƒ¨åˆ†å¯è§‚å¯Ÿæ€§é—®é¢˜ï¼Œé¦–å…ˆè®­ç»ƒç”Ÿæˆæ¨¡å‹ä»¥æ ¹æ®éƒ¨åˆ†è‡ªæˆ‘è§‚å¯Ÿç»“æœä¼°è®¡æ•´ä½“ä¸–ç•ŒçŠ¶æ€ã€‚ç„¶åï¼Œä¸ºäº†å‡†ç¡®æ¨¡æ‹Ÿåœ¨æ­¤ä¸–ç•ŒçŠ¶æ€ä¸‹å¤šç»„è¡ŒåŠ¨çš„æ¨¡æ‹Ÿï¼Œæå‡ºé€šè¿‡åˆ†è§£å¤šä¸ªä»£ç†çš„è‡ªç„¶å¯ç»„åˆè”åˆè¡ŒåŠ¨å¹¶ç»„åˆç”Ÿæˆè§†é¢‘æ¥å­¦ä¹ ç”¨äºå¤šæ™ºèƒ½ä½“åˆä½œçš„ç»„åˆä¸–ç•Œæ¨¡å‹ã€‚é€šè¿‡åˆ©ç”¨ç»„åˆä¸–ç•Œæ¨¡å‹å’Œè§†è§‰è¯­è¨€æ¨¡å‹æ¥æ¨æ–­å…¶ä»–ä»£ç†çš„è¡ŒåŠ¨ï¼Œå¯ä»¥ä½¿ç”¨æ ‘æœç´¢ç¨‹åºæ¥æ•´åˆè¿™äº›æ¨¡å—å¹¶ä¿ƒè¿›åœ¨çº¿åˆä½œè§„åˆ’ã€‚åœ¨å…·æœ‰2-4ä¸ªä»£ç†çš„ä¸‰ä¸ªå…·æœ‰æŒ‘æˆ˜æ€§çš„åŸºå‡†æµ‹è¯•ä¸Šè¯„ä¼°äº†æˆ‘ä»¬çš„æ–¹æ³•ï¼Œè¯æ˜äº†ç»„åˆä¸–ç•Œæ¨¡å‹çš„æœ‰æ•ˆæ€§ï¼Œå¹¶ä¸”è¯¥æ–¹æ³•ä½¿æ™ºèƒ½ä½“èƒ½å¤Ÿé«˜æ•ˆåœ°åœ¨ä¸åŒä»»åŠ¡å’Œä»»æ„æ•°é‡çš„æ™ºèƒ½ä½“ä¹‹é—´è¿›è¡Œåˆä½œã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æœ¬æ–‡ç ”ç©¶äº†å¤šæ™ºèƒ½ä½“åˆä½œé—®é¢˜ï¼Œå…¶ä¸­æ™ºèƒ½ä½“ä»…é€šè¿‡è‡ªæˆ‘ä¸­å¿ƒçš„è§†è§’è§‚å¯Ÿä¸–ç•Œè¿›è¡Œåˆä½œã€‚</li>
<li>ä¸ºè§£å†³éƒ¨åˆ†å¯è§‚å¯Ÿæ€§é—®é¢˜ï¼Œè®­ç»ƒç”Ÿæˆæ¨¡å‹ä»¥æ ¹æ®éƒ¨åˆ†è‡ªæˆ‘è§‚å¯Ÿç»“æœä¼°è®¡æ•´ä½“ä¸–ç•ŒçŠ¶æ€ã€‚</li>
<li>æå‡ºå­¦ä¹ ç»„åˆä¸–ç•Œæ¨¡å‹ï¼Œä»¥æ¨¡æ‹Ÿå¤šä¸ªæ™ºèƒ½ä½“çš„è¡ŒåŠ¨å¯¹ä¸–ç•ŒçŠ¶æ€çš„å½±å“ã€‚</li>
<li>åˆ©ç”¨ç»„åˆä¸–ç•Œæ¨¡å‹å’Œè§†è§‰è¯­è¨€æ¨¡å‹è¿›è¡Œåœ¨çº¿åˆä½œè§„åˆ’ã€‚</li>
<li>æ–¹æ³•åœ¨å…·æœ‰æŒ‘æˆ˜æ€§çš„åŸºå‡†æµ‹è¯•ä¸Šè¡¨ç°è‰¯å¥½ï¼Œé€‚ç”¨äºä¸åŒä»»åŠ¡å’Œä»»æ„æ•°é‡çš„æ™ºèƒ½ä½“ã€‚</li>
<li>æ–¹æ³•å±•ç¤ºäº†åœ¨æ¨åŠ¨æ™ºèƒ½ä½“åˆä½œæ–¹é¢çš„æ½œåŠ›ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2404.10775">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-ead0585a3037ef33f4905c20ab146c44.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-036994c569d13aa0a7acc4ddc460b13c.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-9510b382527bf30d99cbc4256ed4637d.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-d84d47b7f2015bfbb48f2575678ef371.jpg" align="middle">
</details>


<h1 id="-11"><a href="#-11" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-04-18/Agent/">https://kedreamix.github.io/Talk2Paper/Paper/2025-04-18/Agent/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/Agent/">
                                    <span class="chip bg-color">Agent</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-04-18/Few-Shot/">
                    <div class="card-image">
                        
                        <img src="https://pica.zhimg.com/v2-75e61f7614c517d6ec749884c2652ad3.jpg" class="responsive-img" alt="Few-Shot">
                        
                        <span class="card-title">Few-Shot</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Few-Shot æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-04-18  Logits DeConfusion with CLIP for Few-Shot Learning
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-04-18
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Few-Shot/" class="post-category">
                                    Few-Shot
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Few-Shot/">
                        <span class="chip bg-color">Few-Shot</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-04-18/LLM/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-f50f71bd991c3c5db24d14612a62d5ec.jpg" class="responsive-img" alt="LLM">
                        
                        <span class="card-title">LLM</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            LLM æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-04-18  HLS-Eval A Benchmark and Framework for Evaluating LLMs on High-Level   Synthesis Design Tasks
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-04-18
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/LLM/" class="post-category">
                                    LLM
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/LLM/">
                        <span class="chip bg-color">LLM</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">18293.4k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
