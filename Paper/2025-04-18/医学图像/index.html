<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="åŒ»å­¦å›¾åƒ">
    <meta name="description" content="åŒ»å­¦å›¾åƒ æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-04-18  Comparative Evaluation of Radiomics and Deep Learning Models for Disease   Detection in Chest Radiography">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>åŒ»å­¦å›¾åƒ | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://picx.zhimg.com/v2-fa41f28c87761083ffb984a8d919b3d8.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">åŒ»å­¦å›¾åƒ</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/">
                                <span class="chip bg-color">åŒ»å­¦å›¾åƒ</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/" class="post-category">
                                åŒ»å­¦å›¾åƒ
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-04-18
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-05-14
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    13.5k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    55 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-04-18-æ›´æ–°"><a href="#2025-04-18-æ›´æ–°" class="headerlink" title="2025-04-18 æ›´æ–°"></a>2025-04-18 æ›´æ–°</h1><h2 id="Comparative-Evaluation-of-Radiomics-and-Deep-Learning-Models-for-Disease-Detection-in-Chest-Radiography"><a href="#Comparative-Evaluation-of-Radiomics-and-Deep-Learning-Models-for-Disease-Detection-in-Chest-Radiography" class="headerlink" title="Comparative Evaluation of Radiomics and Deep Learning Models for Disease   Detection in Chest Radiography"></a>Comparative Evaluation of Radiomics and Deep Learning Models for Disease   Detection in Chest Radiography</h2><p><strong>Authors:Zhijin He, Alan B. McMillan</strong></p>
<p>The application of artificial intelligence (AI) in medical imaging has revolutionized diagnostic practices, enabling advanced analysis and interpretation of radiological data. This study presents a comprehensive evaluation of radiomics-based and deep learning-based approaches for disease detection in chest radiography, focusing on COVID-19, lung opacity, and viral pneumonia. While deep learning models, particularly convolutional neural networks (CNNs) and vision transformers (ViTs), learn directly from image data, radiomics-based models extract and analyze quantitative features, potentially providing advantages in data-limited scenarios. This study systematically compares the diagnostic accuracy and robustness of various AI models, including Decision Trees, Gradient Boosting, Random Forests, Support Vector Machines (SVM), and Multi-Layer Perceptrons (MLP) for radiomics, against state-of-the-art computer vision deep learning architectures. Performance metrics across varying sample sizes reveal insights into each modelâ€™s efficacy, highlighting the contexts in which specific AI approaches may offer enhanced diagnostic capabilities. The results aim to inform the integration of AI-driven diagnostic tools in clinical practice, particularly in automated and high-throughput environments where timely, reliable diagnosis is critical. This comparative study addresses an essential gap, establishing guidance for the selection of AI models based on clinical and operational needs. </p>
<blockquote>
<p>äººå·¥æ™ºèƒ½ï¼ˆAIï¼‰åœ¨åŒ»å­¦æˆåƒé¢†åŸŸçš„åº”ç”¨å·²ç»å½»åº•æ”¹å˜äº†è¯Šæ–­å®è·µï¼Œä½¿æ”¾å°„å­¦æ•°æ®çš„å…ˆè¿›åˆ†æå’Œè§£é‡Šæˆä¸ºå¯èƒ½ã€‚æœ¬ç ”ç©¶å…¨é¢è¯„ä¼°äº†åŸºäºæ”¾å°„å­¦ç»„å’ŒåŸºäºæ·±åº¦å­¦ä¹ çš„æ–¹æ³•åœ¨èƒ¸éƒ¨æ”¾å°„æ‘„å½±ä¸­æ£€æµ‹ç–¾ç—…çš„æ€§èƒ½ï¼Œé‡ç‚¹å…³æ³¨COVID-19ã€è‚ºéƒ¨ä¸é€å…‰å’Œç—…æ¯’æ€§è‚ºç‚ã€‚æ·±åº¦å­¦ä¹ æ–¹æ³•ï¼Œç‰¹åˆ«æ˜¯å·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNï¼‰å’Œè§†è§‰è½¬æ¢å™¨ï¼ˆViTï¼‰ç›´æ¥ä»å›¾åƒæ•°æ®ä¸­å­¦ä¹ ï¼Œè€ŒåŸºäºæ”¾å°„å­¦çš„æ¨¡å‹åˆ™æå–å’Œåˆ†æå®šé‡ç‰¹å¾ï¼Œå¯èƒ½åœ¨æ•°æ®æœ‰é™çš„æƒ…å†µä¸‹å…·æœ‰æ½œåœ¨ä¼˜åŠ¿ã€‚æœ¬ç ”ç©¶ç³»ç»Ÿåœ°æ¯”è¾ƒäº†å„ç§äººå·¥æ™ºèƒ½æ¨¡å‹çš„è¯Šæ–­å‡†ç¡®æ€§å’Œç¨³å¥æ€§ï¼ŒåŒ…æ‹¬ç”¨äºæ”¾å°„å­¦å†³ç­–æ ‘ã€æ¢¯åº¦æå‡ã€éšæœºæ£®æ—ã€æ”¯æŒå‘é‡æœºï¼ˆSVMï¼‰å’Œå¤šå±‚æ„ŸçŸ¥å™¨ï¼ˆMLPï¼‰ä¸æœ€å…ˆè¿›çš„è®¡ç®—æœºè§†è§‰æ·±åº¦å­¦ä¹ æ¶æ„ä¹‹é—´çš„æ¯”è¾ƒã€‚ä¸åŒæ ·æœ¬é‡ä¸‹çš„æ€§èƒ½æŒ‡æ ‡æ­ç¤ºäº†æ¯ç§æ¨¡å‹çš„æœ‰æ•ˆæ€§ï¼Œå¹¶çªå‡ºäº†ç‰¹å®šäººå·¥æ™ºèƒ½æ–¹æ³•å¯èƒ½åœ¨ä½•ç§æƒ…å†µä¸‹æä¾›å¢å¼ºçš„è¯Šæ–­èƒ½åŠ›ã€‚ç ”ç©¶ç»“æœæ—¨åœ¨ä¸ºå°†AIé©±åŠ¨çš„è¯Šæ–­å·¥å…·æ•´åˆåˆ°ä¸´åºŠå®è·µæä¾›ä¿¡æ¯ï¼Œç‰¹åˆ«æ˜¯åœ¨åŠæ—¶å¯é çš„è¯Šæ–­è‡³å…³é‡è¦çš„è‡ªåŠ¨åŒ–å’Œé«˜é€šé‡ç¯å¢ƒä¸­ã€‚è¿™é¡¹æ¯”è¾ƒç ”ç©¶è§£å†³äº†å…³é”®ç©ºç™½ï¼Œæ ¹æ®ä¸´åºŠå’Œè¿è¥éœ€æ±‚ä¸ºé€‰æ‹©AIæ¨¡å‹æä¾›äº†æŒ‡å¯¼ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.12249v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>äººå·¥æ™ºèƒ½åœ¨åŒ»å­¦æˆåƒé¢†åŸŸçš„åº”ç”¨å·²ç»å½»åº•æ”¹å˜äº†è¯Šæ–­å®è·µï¼Œä½¿æ”¾å°„å­¦æ•°æ®çš„åˆ†æå’Œè§£è¯»æ›´ä¸ºå…ˆè¿›ã€‚æœ¬ç ”ç©¶å…¨é¢è¯„ä¼°äº†åŸºäºæ”¾å°„ç»„å­¦å’ŒåŸºäºæ·±åº¦å­¦ä¹ çš„æ–¹æ³•åœ¨èƒ¸éƒ¨æ”¾å°„å­¦ä¸­å¯¹ç–¾ç—…æ£€æµ‹ï¼ˆç‰¹åˆ«æ˜¯COVID-19ã€è‚ºéƒ¨ä¸é€æ˜åº¦å’Œç—…æ¯’æ€§è‚ºç‚ï¼‰çš„åº”ç”¨ã€‚ç ”ç©¶ç³»ç»Ÿåœ°æ¯”è¾ƒäº†å„ç§AIæ¨¡å‹çš„è¯Šæ–­å‡†ç¡®æ€§å’Œç¨³å¥æ€§ï¼ŒåŒ…æ‹¬ç”¨äºæ”¾å°„ç»„å­¦çš„å†³ç­–æ ‘ã€æ¢¯åº¦æå‡ã€éšæœºæ£®æ—ã€æ”¯æŒå‘é‡æœºï¼ˆSVMï¼‰å’Œå¤šå±‚æ„ŸçŸ¥å™¨ï¼ˆMLPï¼‰ä»¥åŠå…ˆè¿›çš„è®¡ç®—æœºè§†è§‰æ·±åº¦å­¦ä¹ æ¶æ„ã€‚ç ”ç©¶ç»“æœä¸ºæ•´åˆAIé©±åŠ¨çš„è¯Šæ–­å·¥å…·äºä¸´åºŠå®è·µæä¾›äº†ä¿¡æ¯ï¼Œç‰¹åˆ«æ˜¯åœ¨éœ€è¦è‡ªåŠ¨åŒ–å’Œå¤§è§„æ¨¡å¤„ç†çš„ç¯å¢ƒä¸­ï¼ŒåŠæ—¶çš„å¯é è¯Šæ–­è‡³å…³é‡è¦ã€‚è¿™é¡¹æ¯”è¾ƒç ”ç©¶å¡«è¡¥äº†é‡è¦ç©ºç™½ï¼Œä¸ºåŸºäºä¸´åºŠå’Œæ“ä½œéœ€æ±‚é€‰æ‹©AIæ¨¡å‹æä¾›äº†æŒ‡å¯¼ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>äººå·¥æ™ºèƒ½åœ¨åŒ»å­¦æˆåƒä¸­çš„åº”ç”¨å·²ç»æ”¹å˜äº†è¯Šæ–­å®è·µï¼Œä½¿æ”¾å°„æ•°æ®çš„åˆ†æå’Œè§£è¯»æ›´ä¸ºå…ˆè¿›ã€‚</li>
<li>æœ¬ç ”ç©¶æ¯”è¾ƒäº†åŸºäºæ”¾å°„ç»„å­¦å’ŒåŸºäºæ·±åº¦å­¦ä¹ çš„ç–¾ç—…æ£€æµ‹æ–¹æ³•ï¼Œç‰¹åˆ«æ˜¯åœ¨èƒ¸éƒ¨æ”¾å°„å­¦ä¸­é’ˆå¯¹COVID-19ã€è‚ºéƒ¨ä¸é€æ˜å’Œç—…æ¯’æ€§è‚ºç‚çš„åº”ç”¨ã€‚</li>
<li>æ·±åº¦å­¦ä¹ æ¨¡å‹ï¼Œå¦‚å·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNsï¼‰å’Œè§†è§‰è½¬æ¢å™¨ï¼ˆViTsï¼‰ï¼Œå¯ä»¥ç›´æ¥ä»å›¾åƒæ•°æ®ä¸­å­¦ä¹ ã€‚</li>
<li>æ”¾å°„ç»„å­¦æ¨¡å‹é€šè¿‡æå–å’Œåˆ†æå®šé‡ç‰¹å¾ï¼Œå¯èƒ½åœ¨æ•°æ®æœ‰é™çš„æƒ…å†µä¸‹å…·æœ‰ä¼˜åŠ¿ã€‚</li>
<li>ç ”ç©¶æ¯”è¾ƒäº†ä¸åŒAIæ¨¡å‹çš„è¯Šæ–­å‡†ç¡®æ€§å’Œç¨³å¥æ€§ï¼ŒåŒ…æ‹¬å†³ç­–æ ‘ã€æ¢¯åº¦æå‡ã€éšæœºæ£®æ—ã€SVMå’ŒMLPç­‰ï¼Œä»¥åŠä¸å…ˆè¿›çš„è®¡ç®—æœºè§†è§‰æ·±åº¦å­¦ä¹ æ¶æ„è¿›è¡Œäº†å¯¹æ¯”ã€‚</li>
<li>ç ”ç©¶ç»“æœæä¾›äº†å°†AIé©±åŠ¨çš„è¯Šæ–­å·¥å…·æ•´åˆåˆ°ä¸´åºŠå®è·µä¸­çš„ä¿¡æ¯ï¼Œç‰¹åˆ«æ˜¯åœ¨éœ€è¦è‡ªåŠ¨åŒ–å’Œå¤§è§„æ¨¡å¤„ç†çš„ç¯å¢ƒä¸­ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.12249">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-da6ca1480f70c8211e78f91f28089bea.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="Remote-sensing-colour-image-semantic-segmentation-of-trails-created-by-large-herbivorous-Mammals"><a href="#Remote-sensing-colour-image-semantic-segmentation-of-trails-created-by-large-herbivorous-Mammals" class="headerlink" title="Remote sensing colour image semantic segmentation of trails created by   large herbivorous Mammals"></a>Remote sensing colour image semantic segmentation of trails created by   large herbivorous Mammals</h2><p><strong>Authors:Jose Francisco Diez-Pastor, Francisco Javier Gonzalez-Moya, Pedro Latorre-Carmona, Francisco Javier Perez-BarberÃ­a, Ludmila I. Kuncheva, Antonio Canepa-Oneto, Alvar Arnaiz-GonzÃ¡lez, Cesar Garcia-Osorio</strong></p>
<p>Detection of spatial areas where biodiversity is at risk is of paramount importance for the conservation and monitoring of ecosystems. Large terrestrial mammalian herbivores are keystone species as their activity not only has deep effects on soils, plants, and animals, but also shapes landscapes, as large herbivores act as allogenic ecosystem engineers. One key landscape feature that indicates intense herbivore activity and potentially impacts biodiversity is the formation of grazing trails. Grazing trails are formed by the continuous trampling activity of large herbivores that can produce complex networks of tracks of bare soil. Here, we evaluated different algorithms based on machine learning techniques to identify grazing trails. Our goal is to automatically detect potential areas with intense herbivory activity, which might be beneficial for conservation and management plans.   We have applied five semantic segmentation methods combined with fourteen encoders aimed at mapping grazing trails on aerial images. Our results indicate that in most cases the chosen methodology successfully mapped the trails, although there were a few instances where the actual trail structure was underestimated. The UNet architecture with the MambaOut encoder was the best architecture for mapping trails. The proposed approach could be applied to develop tools for mapping and monitoring temporal changes in these landscape structures to support habitat conservation and land management programs. This is the first time, to the best of our knowledge, that competitive image segmentation results are obtained for the detection and delineation of trails of large herbivorous mammals. </p>
<blockquote>
<p>ç”Ÿç‰©å¤šæ ·æ€§æ˜“å—å½±å“çš„åŒºåŸŸæ£€æµ‹å¯¹äºç”Ÿæ€ç³»ç»Ÿçš„ä¿æŠ¤å’Œç›‘æµ‹è‡³å…³é‡è¦ã€‚å¤§å‹é™†åœ°å“ºä¹³åŠ¨ç‰©æ˜¯æ——èˆ°ç‰©ç§ï¼Œå…¶æ´»åŠ¨ä¸ä»…å¯¹åœŸå£¤ã€æ¤ç‰©å’ŒåŠ¨ç‰©äº§ç”Ÿæ·±è¿œå½±å“ï¼Œè¿˜å¡‘é€ åœ°å½¢åœ°è²Œï¼Œå› ä¸ºå¤§å‹è‰é£ŸåŠ¨ç‰©å……å½“ç€å¤–æ¥ç”Ÿæ€ç³»ç»Ÿå·¥ç¨‹å¸ˆçš„è§’è‰²ã€‚ä¸€ä¸ªå…³é”®åœ°å½¢ç‰¹å¾æ˜¯å‰§çƒˆçš„è‰é£ŸåŠ¨ç‰©æ´»åŠ¨ï¼Œè¿™å¯èƒ½å½±å“ç”Ÿç‰©å¤šæ ·æ€§å¹¶é€ æˆç‰§åœºè·¯å¾„çš„å½¢æˆã€‚ç‰§åœºè·¯å¾„æ˜¯ç”±å¤§å‹è‰é£ŸåŠ¨ç‰©æŒç»­è·µè¸æ´»åŠ¨å½¢æˆçš„ï¼Œä¼šäº§ç”Ÿè£¸éœ²åœŸå£¤çš„å¤æ‚è½¨è¿¹ç½‘ç»œã€‚åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬åŸºäºæœºå™¨å­¦ä¹ æŠ€æœ¯è¯„ä¼°äº†ä¸åŒçš„ç®—æ³•æ¥è¯†åˆ«ç‰§åœºè·¯å¾„ã€‚æˆ‘ä»¬çš„ç›®æ ‡æ˜¯è‡ªåŠ¨æ£€æµ‹å¯èƒ½å­˜åœ¨å¼ºçƒˆæ”¾ç‰§æ´»åŠ¨çš„åŒºåŸŸï¼Œè¿™å¯èƒ½å¯¹ä¿æŠ¤å’Œç®¡ç†è®¡åˆ’æœ‰ç›Šã€‚æˆ‘ä»¬é‡‡ç”¨äº†äº”ç§è¯­ä¹‰åˆ†å‰²æ–¹æ³•ä¸åå››ç§ç¼–ç å™¨ç›¸ç»“åˆçš„æ–¹æ³•ï¼Œæ—¨åœ¨å°†ç‰§åœºè·¯å¾„æ˜ å°„åˆ°ç©ºä¸­å›¾åƒä¸Šã€‚æˆ‘ä»¬çš„ç»“æœè¡¨æ˜ï¼Œåœ¨å¤§å¤šæ•°æƒ…å†µä¸‹ï¼Œæ‰€é€‰æ–¹æ³•æˆåŠŸåœ°ç»˜åˆ¶äº†è·¯å¾„ï¼Œå°½ç®¡åœ¨æŸäº›æƒ…å†µä¸‹å®é™…è·¯å¾„ç»“æ„è¢«ä½ä¼°äº†ã€‚ä½¿ç”¨MambaOutç¼–ç å™¨çš„UNetæ¶æ„æ˜¯ç»˜åˆ¶è·¯å¾„çš„æœ€ä½³æ¶æ„ã€‚æ‰€æå‡ºçš„æ–¹æ³•å¯åº”ç”¨äºå¼€å‘å·¥å…·å’Œç›‘æµ‹è¿™äº›åœ°å½¢ç»“æ„çš„ä¸´æ—¶å˜åŒ–ï¼Œä»¥æ”¯æŒæ –æ¯åœ°ä¿æŠ¤å’ŒåœŸåœ°ç®¡ç†è®¡åˆ’ã€‚æ®æˆ‘ä»¬æ‰€çŸ¥ï¼Œè¿™æ˜¯é¦–æ¬¡æˆåŠŸè·å¾—å¤§å‹è‰é£ŸåŠ¨ç‰©çš„è·¯å¾„æ£€æµ‹å’Œåˆ’ç•Œçš„ç«äº‰æ€§å›¾åƒåˆ†å‰²ç»“æœã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.12121v1">PDF</a> 24 pages, 6 figures. Submitted to Computers and Geosciences</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡åˆ©ç”¨æœºå™¨å­¦ä¹ ç®—æ³•å¯¹å¤§å‹è‰é£ŸåŠ¨ç‰©æ´»åŠ¨å½¢æˆçš„æ”¾ç‰§å°å¾„è¿›è¡Œè‡ªåŠ¨æ£€æµ‹ã€‚ç ”ç©¶è¯„ä»·äº†äº”ç§è¯­ä¹‰åˆ†å‰²æ–¹æ³•ä¸åå››ç§ç¼–ç å™¨åœ¨èˆªç©ºå›¾åƒä¸Šç»˜åˆ¶æ”¾ç‰§å°å¾„çš„æ•ˆæœã€‚ç»“æœæ˜¾ç¤ºï¼Œæ‰€é€‰æ–¹æ³•åœ¨å¤šæ•°æƒ…å†µä¸‹èƒ½æˆåŠŸç»˜åˆ¶å°å¾„ï¼Œä½†éƒ¨åˆ†å°å¾„ç»“æ„å¯èƒ½è¢«ä½ä¼°ã€‚ä»¥UNetæ¶æ„ç»“åˆMambaOutç¼–ç å™¨çš„æ•ˆæœæœ€ä½³ã€‚è¯¥æ–¹æ³•å¯ç”¨äºå¼€å‘å·¥å…·ï¼Œä»¥ç›‘æµ‹è¿™äº›æ™¯è§‚ç»“æ„çš„æ—¶ç©ºå˜åŒ–ï¼Œæ”¯æŒæ –æ¯åœ°ä¿æŠ¤å’ŒåœŸåœ°ç®¡ç†è®¡åˆ’ã€‚è¿™æ˜¯é¦–æ¬¡æˆåŠŸåˆ©ç”¨å›¾åƒåˆ†å‰²æŠ€æœ¯æ£€æµ‹ä¸æç»˜å¤§å‹è‰é£ŸåŠ¨ç‰©çš„æ”¾ç‰§å°å¾„ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æ£€æµ‹ç”Ÿç‰©å¤šæ ·æ€§å’Œç”Ÿæ€ç³»ç»Ÿå¥åº·çš„å…³é”®å› ç´ ä¹‹ä¸€ï¼Œæ˜¯æ£€æµ‹å¤§è§„æ¨¡é™†ç”Ÿè‰é£Ÿå“ºä¹³åŠ¨ç‰©æ”¾ç‰§åŒºåŸŸã€‚</li>
<li>ç ”ç©¶ä¸­é‡‡ç”¨æœºå™¨å­¦ä¹ æ–¹æ³•æ£€æµ‹æ”¾ç‰§å°å¾„ï¼ˆåŠ¨ç‰©ç»å¸¸æ´»åŠ¨çš„è·¯çº¿ï¼‰ï¼Œä¸ºåç»­ç ”ç©¶å’Œä¿æŠ¤æªæ–½æä¾›æ”¯æŒã€‚</li>
<li>å¯¹æ¯”ç ”ç©¶äº†äº”ç§è¯­ä¹‰åˆ†å‰²æ–¹æ³•ä¸åå››ç§ç¼–ç å™¨çš„æ€§èƒ½è¡¨ç°ã€‚å¤§éƒ¨åˆ†æ–¹æ³•åœ¨è¯„ä¼°ä¸­è¢«è®¤ä¸ºæˆåŠŸæ£€æµ‹åˆ°æ”¾ç‰§å°å¾„çš„å­˜åœ¨ï¼Œåªæœ‰å°éƒ¨åˆ†æƒ…å†µä¸‹å°å¾„ç»“æ„è¢«ä½ä¼°ã€‚</li>
<li>UNetæ¶æ„ç»“åˆMambaOutç¼–ç å™¨æ˜¯æœ€ä½³çš„æ£€æµ‹æ–¹æ³•ç»„åˆã€‚</li>
<li>æ–¹æ³•çš„è¿ç”¨å‰æ™¯åŒ…æ‹¬ä¸ºé•¿æœŸè·Ÿè¸ªæ¤è¢«ä¸ç”Ÿæ€ç³»ç»Ÿå¥åº·å»ºç«‹ç›¸å…³å·¥å…·å’Œç¨‹åºæä¾›ä¾¿åˆ©æ‰‹æ®µï¼Œé€šè¿‡ç›‘æµ‹æ”¾ç‰§å°å¾„çš„æ—¶ç©ºå˜åŒ–æ¥æ”¯æŒåœŸåœ°ç®¡ç†å’Œä¿æŠ¤è®¡åˆ’ã€‚</li>
<li>è¿™æ˜¯é¦–æ¬¡æˆåŠŸåˆ©ç”¨å›¾åƒåˆ†å‰²æŠ€æœ¯æ¥æ£€æµ‹å¤§å‹è‰é£ŸåŠ¨ç‰©çš„æ”¾ç‰§å°å¾„ã€‚æ­¤æŠ€æœ¯çš„çªç ´å¯èƒ½å¯¹ç”Ÿæ€ç³»ç»Ÿä¿æŠ¤å…·æœ‰æ·±è¿œå½±å“ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.12121">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-aa30c3a52c7f48a6307b7f9974c022eb.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="A-Diffusion-Based-Framework-for-Terrain-Aware-Remote-Sensing-Image-Reconstruction"><a href="#A-Diffusion-Based-Framework-for-Terrain-Aware-Remote-Sensing-Image-Reconstruction" class="headerlink" title="A Diffusion-Based Framework for Terrain-Aware Remote Sensing Image   Reconstruction"></a>A Diffusion-Based Framework for Terrain-Aware Remote Sensing Image   Reconstruction</h2><p><strong>Authors:Zhenyu Yu, Mohd Yamani Inda Idris, Pei Wang</strong></p>
<p>Remote sensing imagery is essential for environmental monitoring, agricultural management, and disaster response. However, data loss due to cloud cover, sensor failures, or incomplete acquisition-especially in high-resolution and high-frequency tasks-severely limits satellite imageryâ€™s effectiveness. Traditional interpolation methods struggle with large missing areas and complex structures. Remote sensing imagery consists of multiple bands, each with distinct meanings, and ensuring consistency across bands is critical to avoid anomalies in the combined images. This paper proposes SatelliteMaker, a diffusion-based method that reconstructs missing data across varying levels of data loss while maintaining spatial, spectral, and temporal consistency. We also propose Digital Elevation Model (DEM) as a conditioning input and use tailored prompts to generate realistic images, making diffusion models applicable to quantitative remote sensing tasks. Additionally, we propose a VGG-Adapter module based on Distribution Loss, which reduces distribution discrepancy and ensures style consistency. Extensive experiments show that SatelliteMaker achieves state-of-the-art performance across multiple tasks. </p>
<blockquote>
<p>é¥æ„Ÿå½±åƒåœ¨ç¯å¢ƒç›‘æµ‹ã€å†œä¸šç®¡ç†å’Œç¾å®³åº”å¯¹æ–¹é¢å‘æŒ¥ç€é‡è¦ä½œç”¨ã€‚ç„¶è€Œï¼Œç”±äºäº‘å±‚è¦†ç›–ã€ä¼ æ„Ÿå™¨æ•…éšœæˆ–é‡‡é›†ä¸å®Œå…¨ç­‰åŸå› å¯¼è‡´çš„æ•°æ®ä¸¢å¤±ï¼Œç‰¹åˆ«æ˜¯åœ¨é«˜åˆ†è¾¨ç‡å’Œé«˜é¢‘ç‡çš„ä»»åŠ¡ä¸­ï¼Œä¸¥é‡é™åˆ¶äº†å«æ˜Ÿå½±åƒçš„æœ‰æ•ˆæ€§ã€‚ä¼ ç»Ÿæ’å€¼æ–¹æ³•åœ¨å¤„ç†å¤§é¢ç§¯ç¼ºå¤±å’Œå¤æ‚ç»“æ„æ—¶é‡åˆ°äº†å›°éš¾ã€‚é¥æ„Ÿå½±åƒç”±å¤šä¸ªæ³¢æ®µç»„æˆï¼Œæ¯ä¸ªæ³¢æ®µéƒ½æœ‰ç‹¬ç‰¹çš„å«ä¹‰ï¼Œç¡®ä¿å„æ³¢æ®µä¹‹é—´çš„ä¸€è‡´æ€§å¯¹äºé¿å…åˆæˆå›¾åƒä¸­çš„å¼‚å¸¸è‡³å…³é‡è¦ã€‚æœ¬æ–‡æå‡ºäº†SatelliteMakerï¼Œè¿™æ˜¯ä¸€ç§åŸºäºæ‰©æ•£çš„æ–¹æ³•ï¼Œèƒ½å¤Ÿåœ¨ä¸åŒçº§åˆ«çš„æ•°æ®ä¸¢å¤±æƒ…å†µä¸‹é‡å»ºç¼ºå¤±æ•°æ®ï¼ŒåŒæ—¶ä¿æŒç©ºé—´ã€å…‰è°±å’Œæ—¶é—´çš„ä¸€è‡´æ€§ã€‚æˆ‘ä»¬è¿˜æå‡ºäº†æ•°å­—é«˜ç¨‹æ¨¡å‹ï¼ˆDEMï¼‰ä½œä¸ºæ¡ä»¶è¾“å…¥ï¼Œå¹¶ä½¿ç”¨å®šåˆ¶æç¤ºæ¥ç”Ÿæˆé€¼çœŸçš„å›¾åƒï¼Œä½¿æ‰©æ•£æ¨¡å‹é€‚ç”¨äºå®šé‡é¥æ„Ÿä»»åŠ¡ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æå‡ºäº†åŸºäºåˆ†å¸ƒæŸå¤±çš„VGGé€‚é…å™¨æ¨¡å—ï¼Œå®ƒå‡å°‘äº†åˆ†å¸ƒå·®å¼‚å¹¶ç¡®ä¿é£æ ¼ä¸€è‡´æ€§ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼ŒSatelliteMakeråœ¨å¤šä¸ªä»»åŠ¡ä¸Šè¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.12112v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>é¥æ„Ÿå½±åƒåœ¨ç¯å¢ƒç›‘æµ‹ã€å†œä¸šç®¡ç†å’Œç¾å®³å“åº”ä¸­è‡³å…³é‡è¦ã€‚ç„¶è€Œï¼Œå› äº‘å±‚è¦†ç›–ã€ä¼ æ„Ÿå™¨æ•…éšœæˆ–é‡‡é›†ä¸å®Œå…¨ç­‰åŸå› å¯¼è‡´çš„æ•°æ®ä¸¢å¤±ï¼Œç‰¹åˆ«æ˜¯åœ¨é«˜åˆ†è¾¨å’Œé«˜é¢‘ç‡çš„ä»»åŠ¡ä¸­ï¼Œä¸¥é‡é™åˆ¶äº†å«æ˜Ÿå½±åƒçš„æœ‰æ•ˆæ€§ã€‚ä¼ ç»Ÿæ’å€¼æ–¹æ³•åœ¨å¤„ç†å¤§é¢ç§¯ç¼ºå¤±å’Œå¤æ‚ç»“æ„æ—¶é¢ä¸´æŒ‘æˆ˜ã€‚æœ¬æ–‡æå‡ºä¸€ç§åŸºäºæ‰©æ•£çš„SatelliteMakeræ–¹æ³•ï¼Œèƒ½å¤Ÿåœ¨ä¸åŒçº§åˆ«çš„æ•°æ®ä¸¢å¤±æƒ…å†µä¸‹é‡å»ºæ•°æ®ï¼ŒåŒæ—¶ä¿æŒç©ºé—´ã€å…‰è°±å’Œæ—¶é—´çš„ä¸€è‡´æ€§ã€‚æ­¤å¤–ï¼Œè¿˜æå‡ºä½¿ç”¨æ•°å­—é«˜ç¨‹æ¨¡å‹ï¼ˆDEMï¼‰ä½œä¸ºæ¡ä»¶è¾“å…¥ï¼Œå¹¶ä½¿ç”¨å®šåˆ¶æç¤ºç”ŸæˆçœŸå®å›¾åƒï¼Œä½¿æ‰©æ•£æ¨¡å‹é€‚ç”¨äºå®šé‡é¥æ„Ÿä»»åŠ¡ã€‚åŸºäºåˆ†å¸ƒæŸå¤±çš„VGG-Adapteræ¨¡å—å‡å°‘äº†åˆ†å¸ƒå·®å¼‚ï¼Œç¡®ä¿äº†é£æ ¼çš„ä¸€è‡´æ€§ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼ŒSatelliteMakeråœ¨å¤šä¸ªä»»åŠ¡ä¸Šè¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>é¥æ„Ÿå½±åƒåœ¨å¤šä¸ªé¢†åŸŸå…·æœ‰åº”ç”¨ä»·å€¼ï¼Œä½†æ•°æ®ä¸¢å¤±é™åˆ¶äº†å…¶æœ‰æ•ˆæ€§ã€‚</li>
<li>ä¼ ç»Ÿæ’å€¼æ–¹æ³•åœ¨å¤„ç†å¤§é¢ç§¯ç¼ºå¤±å’Œå¤æ‚ç»“æ„æ—¶å­˜åœ¨æŒ‘æˆ˜ã€‚</li>
<li>SatelliteMakeræ–¹æ³•åŸºäºæ‰©æ•£ï¼Œèƒ½å¤Ÿåœ¨ä¸åŒçº§åˆ«çš„æ•°æ®ä¸¢å¤±æƒ…å†µä¸‹é‡å»ºæ•°æ®ã€‚</li>
<li>SatelliteMakeræ–¹æ³•ä¿æŒç©ºé—´ã€å…‰è°±å’Œæ—¶é—´çš„ä¸€è‡´æ€§ã€‚</li>
<li>æ•°å­—é«˜ç¨‹æ¨¡å‹ï¼ˆDEMï¼‰è¢«ç”¨ä½œæ¡ä»¶è¾“å…¥ï¼Œç»“åˆå®šåˆ¶æç¤ºï¼Œä½¿æ‰©æ•£æ¨¡å‹é€‚ç”¨äºé¥æ„Ÿä»»åŠ¡ã€‚</li>
<li>VGG-Adapteræ¨¡å—åŸºäºåˆ†å¸ƒæŸå¤±ï¼Œç¡®ä¿é£æ ¼ä¸€è‡´æ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.12112">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-424f45ad2d46dc139ad9acd54d735ebb.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c5ab5a347034d07053d2190c6d858cff.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-3a7027487dc54a5e521f4eb0a290a5bf.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a5f8b2c574f877835d9e5a9b65814719.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-95c7a27077fce7ecac6289a12df9e5e0.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="A-Category-Fragment-Segmentation-Framework-for-Pelvic-Fracture-Segmentation-in-X-ray-Images"><a href="#A-Category-Fragment-Segmentation-Framework-for-Pelvic-Fracture-Segmentation-in-X-ray-Images" class="headerlink" title="A Category-Fragment Segmentation Framework for Pelvic Fracture   Segmentation in X-ray Images"></a>A Category-Fragment Segmentation Framework for Pelvic Fracture   Segmentation in X-ray Images</h2><p><strong>Authors:Daiqi Liu, Fuxin Fan, Andreas Maier</strong></p>
<p>Pelvic fractures, often caused by high-impact trauma, frequently require surgical intervention. Imaging techniques such as CT and 2D X-ray imaging are used to transfer the surgical plan to the operating room through image registration, enabling quick intraoperative adjustments. Specifically, segmenting pelvic fractures from 2D X-ray imaging can assist in accurately positioning bone fragments and guiding the placement of screws or metal plates. In this study, we propose a novel deep learning-based category and fragment segmentation (CFS) framework for the automatic segmentation of pelvic bone fragments in 2D X-ray images. The framework consists of three consecutive steps: category segmentation, fragment segmentation, and post-processing. Our best model achieves an IoU of 0.91 for anatomical structures and 0.78 for fracture segmentation. Results demonstrate that the CFS framework is effective and accurate. </p>
<blockquote>
<p>éª¨ç›†éª¨æŠ˜é€šå¸¸æ˜¯ç”±é«˜å†²å‡»åŠ›åˆ›ä¼¤å¼•èµ·çš„ï¼Œç»å¸¸éœ€è¦æ‰‹æœ¯å¹²é¢„ã€‚ä¸ºäº†é€šè¿‡å›¾åƒé…å‡†å°†æ‰‹æœ¯è®¡åˆ’è½¬ç§»åˆ°æ‰‹æœ¯å®¤ï¼Œæˆ‘ä»¬é‡‡ç”¨äº†CTå’ŒäºŒç»´Xå°„çº¿æˆåƒç­‰æˆåƒæŠ€æœ¯ï¼Œä»è€Œå®ç°æœ¯ä¸­å¿«é€Ÿè°ƒæ•´ã€‚å…·ä½“æ¥è¯´ï¼Œé€šè¿‡äºŒç»´Xå°„çº¿æˆåƒå¯¹éª¨ç›†éª¨æŠ˜è¿›è¡Œåˆ†å‰²ï¼Œæœ‰åŠ©äºå‡†ç¡®å®šä½éª¨ç¢ç‰‡å¹¶æŒ‡å¯¼èºé’‰æˆ–é‡‘å±æ¿çš„æ”¾ç½®ã€‚æœ¬ç ”ç©¶æå‡ºäº†ä¸€ç§åŸºäºæ·±åº¦å­¦ä¹ çš„ç±»åˆ«å’Œç‰‡æ®µåˆ†å‰²ï¼ˆCFSï¼‰æ¡†æ¶ï¼Œç”¨äºè‡ªåŠ¨åˆ†å‰²äºŒç»´Xå°„çº¿å›¾åƒä¸­çš„éª¨ç›†éª¨ç¢ç‰‡ã€‚è¯¥æ¡†æ¶åŒ…æ‹¬ä¸‰ä¸ªè¿ç»­æ­¥éª¤ï¼šç±»åˆ«åˆ†å‰²ã€ç‰‡æ®µåˆ†å‰²å’Œåå¤„ç†ã€‚æˆ‘ä»¬çš„æœ€ä½³æ¨¡å‹åœ¨è§£å‰–ç»“æ„æ–¹é¢å®ç°äº†0.91çš„IoUå€¼ï¼Œåœ¨éª¨æŠ˜åˆ†å‰²æ–¹é¢å®ç°äº†0.78çš„IoUå€¼ã€‚ç»“æœè¡¨æ˜CFSæ¡†æ¶æ˜¯æœ‰æ•ˆä¸”å‡†ç¡®çš„ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.11872v1">PDF</a> 5 pages, 2 figures, 1 table</p>
<p><strong>Summary</strong><br>     æœ¬ç ”ç©¶åˆ©ç”¨æ·±åº¦å­¦ä¹ æŠ€æœ¯ï¼Œæå‡ºä¸€ç§æ–°å‹çš„åŸºäºäºŒç»´Xå°„çº¿å½±åƒçš„éª¨ç›†éª¨æŠ˜ç±»åˆ«å’Œç‰‡æ®µåˆ†å‰²ï¼ˆCFSï¼‰æ¡†æ¶ï¼Œå¯è‡ªåŠ¨åˆ†å‰²éª¨ç›†éª¨ç‰‡æ®µã€‚è¯¥ç ”ç©¶åˆ†ä¸ºä¸‰ä¸ªé˜¶æ®µï¼šç±»åˆ«åˆ†å‰²ã€ç‰‡æ®µåˆ†å‰²å’Œåå¤„ç†ã€‚æœ€ä½³æ¨¡å‹çš„IoUè¾¾åˆ°è§£å‰–ç»“æ„0.91å’Œéª¨æŠ˜åˆ†å‰²0.78ï¼Œè¯æ˜CFSæ¡†æ¶æœ‰æ•ˆä¸”å‡†ç¡®ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>éª¨ç›†éª¨æŠ˜é€šå¸¸ç”±é«˜å†²å‡»æ€§åˆ›ä¼¤å¼•èµ·ï¼Œå¸¸éœ€æ‰‹æœ¯æ²»ç–—ã€‚</li>
<li>å½±åƒæŠ€æœ¯å¦‚CTå’Œ2D Xå°„çº¿å½±åƒå¯ç”¨äºé€šè¿‡å›¾åƒé…å‡†å°†æ‰‹æœ¯è®¡åˆ’ä¼ è¾“åˆ°æ‰‹æœ¯å®¤ï¼Œå®ç°æœ¯ä¸­å¿«é€Ÿè°ƒæ•´ã€‚</li>
<li>åœ¨äºŒç»´Xå°„çº¿å½±åƒä¸­åˆ†å‰²éª¨ç›†éª¨æŠ˜å¯å¸®åŠ©å‡†ç¡®å®šä½éª¨ç¢ç‰‡ï¼ŒæŒ‡å¯¼èºé’‰æˆ–é‡‘å±æ¿çš„æ”¾ç½®ã€‚</li>
<li>æœ¬ç ”ç©¶æå‡ºäº†ä¸€ç§åŸºäºæ·±åº¦å­¦ä¹ çš„è‡ªåŠ¨åˆ†å‰²éª¨ç›†éª¨ç‰‡æ®µçš„CFSæ¡†æ¶ã€‚</li>
<li>è¯¥æ¡†æ¶åŒ…æ‹¬ç±»åˆ«åˆ†å‰²ã€ç‰‡æ®µåˆ†å‰²å’Œåå¤„ç†ä¸‰ä¸ªæ­¥éª¤ã€‚</li>
<li>æœ€ä½³æ¨¡å‹çš„IoUå€¼æ˜¾ç¤ºï¼Œè¯¥æ¡†æ¶åœ¨è§£å‰–ç»“æ„å’Œéª¨æŠ˜åˆ†å‰²æ–¹é¢è¡¨ç°å‡ºé«˜å‡†ç¡®æ€§å’Œæœ‰æ•ˆæ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.11872">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-cfc7a6778ea8f0399564b2fd8a7f51c9.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-5de719a606881edfd4b7e1e3c03e0f1c.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-0c52ea6806969fe91dfaea8dfefe93c9.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-22852059519e5379751cc2ca42c8a6fa.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="Cross-Frequency-Collaborative-Training-Network-and-Dataset-for-Semi-supervised-First-Molar-Root-Canal-Segmentation"><a href="#Cross-Frequency-Collaborative-Training-Network-and-Dataset-for-Semi-supervised-First-Molar-Root-Canal-Segmentation" class="headerlink" title="Cross-Frequency Collaborative Training Network and Dataset for   Semi-supervised First Molar Root Canal Segmentation"></a>Cross-Frequency Collaborative Training Network and Dataset for   Semi-supervised First Molar Root Canal Segmentation</h2><p><strong>Authors:Zhenhuan Zhou, Yuchen Zhang, Along He, Peng Wang, Xueshuo Xie, Tao Li</strong></p>
<p>Root canal (RC) treatment is a highly delicate and technically complex procedure in clinical practice, heavily influenced by the cliniciansâ€™ experience and subjective judgment. Deep learning has made significant advancements in the field of computer-aided diagnosis (CAD) because it can provide more objective and accurate diagnostic results. However, its application in RC treatment is still relatively rare, mainly due to the lack of public datasets in this field. To address this issue, in this paper, we established a First Molar Root Canal segmentation dataset called FMRC-2025. Additionally, to alleviate the workload of manual annotation for dentists and fully leverage the unlabeled data, we designed a Cross-Frequency Collaborative training semi-supervised learning (SSL) Network called CFC-Net. It consists of two components: (1) Cross-Frequency Collaborative Mean Teacher (CFC-MT), which introduces two specialized students (SS) and one comprehensive teacher (CT) for collaborative multi-frequency training. The CT and SS are trained on different frequency components while fully integrating multi-frequency knowledge through cross and full frequency consistency supervisions. (2) Uncertainty-guided Cross-Frequency Mix (UCF-Mix) mechanism enables the network to generate high-confidence pseudo-labels while learning to integrate multi-frequency information and maintaining the structural integrity of the targets. Extensive experiments on FMRC-2025 and three public dental datasets demonstrate that CFC-MT is effective for RC segmentation and can also exhibit strong generalizability on other dental segmentation tasks, outperforming state-of-the-art SSL medical image segmentation methods. Codes and dataset will be released. </p>
<blockquote>
<p>æ ¹ç®¡æ²»ç–—ï¼ˆRCï¼‰æ˜¯ä¸€ç§åœ¨ä¸´åºŠå®è·µä¸­éå¸¸ç²¾ç»†ä¸”æŠ€æœ¯å¤æ‚çš„ç¨‹åºï¼Œæ·±å—ä¸´åºŠåŒ»ç”Ÿç»éªŒå’Œä¸»è§‚åˆ¤æ–­çš„å½±å“ã€‚æ·±åº¦å­¦ä¹ åœ¨è®¡ç®—æœºè¾…åŠ©è¯Šæ–­ï¼ˆCADï¼‰é¢†åŸŸå–å¾—äº†æ˜¾è‘—è¿›å±•ï¼Œå› ä¸ºå®ƒå¯ä»¥æä¾›æ›´å®¢è§‚å’Œå‡†ç¡®çš„è¯Šæ–­ç»“æœã€‚ç„¶è€Œï¼Œå…¶åœ¨æ ¹ç®¡æ²»ç–—ä¸­çš„åº”ç”¨ä»ç„¶ç›¸å¯¹ç½•è§ï¼Œä¸»è¦æ˜¯ç”±äºè¯¥é¢†åŸŸç¼ºä¹å…¬å…±æ•°æ®é›†ã€‚ä¸ºè§£å†³æ­¤é—®é¢˜ï¼Œæœ¬æ–‡å»ºç«‹äº†ä¸€ä¸ªåä¸ºFMRC-2025çš„ç¬¬ä¸€ç£¨ç‰™æ ¹ç®¡ canal åˆ†å‰²æ•°æ®é›†ã€‚æ­¤å¤–ï¼Œä¸ºäº†å‡è½»ç‰™åŒ»æ‰‹åŠ¨æ ‡æ³¨çš„å·¥ä½œé‡å¹¶å……åˆ†åˆ©ç”¨æœªæ ‡è®°çš„æ•°æ®ï¼Œæˆ‘ä»¬è®¾è®¡äº†ä¸€ç§è·¨é¢‘ç‡ååŒè®­ç»ƒåŠç›‘ç£å­¦ä¹ ï¼ˆSSLï¼‰ç½‘ç»œï¼Œç§°ä¸ºCFC-Netã€‚å®ƒåŒ…å«ä¸¤ä¸ªç»„ä»¶ï¼šï¼ˆ1ï¼‰è·¨é¢‘ç‡ååŒå‡å€¼æ•™å¸ˆï¼ˆCFC-MTï¼‰ï¼Œå®ƒå¼•å…¥ä¸¤ä¸ªç‰¹æ®Šå­¦ç”Ÿï¼ˆSSï¼‰å’Œä¸€ä¸ªç»¼åˆæ•™å¸ˆï¼ˆCTï¼‰è¿›è¡ŒååŒå¤šé¢‘ç‡è®­ç»ƒã€‚CTå’ŒSSåœ¨ä¸åŒçš„é¢‘ç‡åˆ†é‡ä¸Šè¿›è¡Œè®­ç»ƒï¼ŒåŒæ—¶é€šè¿‡è·¨é¢‘ç‡å’Œå®Œå…¨é¢‘ç‡ä¸€è‡´æ€§ç›‘ç£æ¥å®Œå…¨æ•´åˆå¤šé¢‘ç‡çŸ¥è¯†ã€‚ï¼ˆ2ï¼‰ä¸ç¡®å®šæ€§å¼•å¯¼çš„è·¨é¢‘ç‡æ··åˆï¼ˆUCF-Mixï¼‰æœºåˆ¶ä½¿ç½‘ç»œèƒ½å¤Ÿç”Ÿæˆé«˜ç½®ä¿¡åº¦çš„ä¼ªæ ‡ç­¾ï¼ŒåŒæ—¶å­¦ä¹ æ•´åˆå¤šé¢‘ç‡ä¿¡æ¯å¹¶ä¿æŒç›®æ ‡çš„ç»“æ„å®Œæ•´æ€§ã€‚åœ¨FMRC-2025å’Œä¸‰ä¸ªå…¬å…±ç‰™ç§‘æ•°æ®é›†ä¸Šçš„å¤§é‡å®éªŒè¡¨æ˜ï¼ŒCFC-MTå¯¹äºæ ¹ç®¡æ²»ç–—åˆ†å‰²æ˜¯æœ‰æ•ˆçš„ï¼Œå¹¶ä¸”åœ¨å…¶ä»–ç‰™ç§‘åˆ†å‰²ä»»åŠ¡ä¸Šä¹Ÿè¡¨ç°å‡ºå¼ºå¤§çš„æ³›åŒ–èƒ½åŠ›ï¼Œè¶…è¶Šäº†æœ€å…ˆè¿›çš„SSLåŒ»å­¦å›¾åƒåˆ†å‰²æ–¹æ³•ã€‚ä»£ç å’Œæ•°æ®é›†å°†å‘å¸ƒã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.11856v1">PDF</a> 12 pages, Initial submission time 25 December 2024, Now Under Review</p>
<p><strong>Summary</strong></p>
<p>æœ¬ç ”ç©¶å»ºç«‹äº†é¦–ä¸ªç£¨ç‰™æ ¹ç®¡ï¼ˆFirst Molar Root Canalï¼‰åˆ†å‰²æ•°æ®é›†FMRC-2025ï¼Œå¹¶æå‡ºäº†ä¸€ç§åŸºäºè·¨é¢‘ååŒè®­ç»ƒåŠç›‘ç£å­¦ä¹ ç½‘ç»œçš„FCMæ¨¡å‹ï¼Œè¯¥æ¨¡å‹èƒ½å¤Ÿç¼“è§£ç‰™åŒ»æ‰‹åŠ¨æ ‡æ³¨çš„å·¥ä½œé‡ï¼Œå……åˆ†åˆ©ç”¨æ— æ ‡ç­¾æ•°æ®ï¼Œåœ¨ç£¨ç‰™æ ¹ç®¡æ²»ç–—å›¾åƒåˆ†å‰²ä¸Šå–å¾—äº†ä¼˜å¼‚è¡¨ç°ã€‚ç ”ç©¶è¯æ˜FCMæ¨¡å‹èƒ½å¤Ÿæœ‰æ•ˆæå‡åˆ†å‰²ç²¾åº¦å’Œæ³›åŒ–èƒ½åŠ›ã€‚æ•°æ®é›†å’Œä»£ç å°†å…¬å¼€å‘å¸ƒã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>ç ”ç©¶å»ºç«‹äº†é¦–ä¸ªç£¨ç‰™æ ¹ç®¡åˆ†å‰²æ•°æ®é›†FMRC-2025ï¼Œä»¥è§£å†³ç¼ºä¹å…¬å…±æ•°æ®é›†çš„é—®é¢˜ã€‚</li>
<li>æå‡ºäº†ä¸€ç§åä¸ºCFC-Netçš„è·¨é¢‘ååŒè®­ç»ƒåŠç›‘ç£å­¦ä¹ ç½‘ç»œï¼ŒåŒ…æ‹¬CFC-MTå’ŒUCF-Mixä¸¤ä¸ªå…³é”®ç»„ä»¶ã€‚</li>
<li>CFC-MTé€šè¿‡å¼•å…¥ä¸¤åä¸“ä¸šå­¦ç”Ÿå’Œä¸€åç»¼åˆæ•™å¸ˆå®ç°è·¨é¢‘ååŒè®­ç»ƒï¼Œæé«˜æ¨¡å‹æ€§èƒ½å’Œå¤šé¢‘çŸ¥è¯†æ•´åˆèƒ½åŠ›ã€‚</li>
<li>UCF-Mixæœºåˆ¶ä½¿ç½‘ç»œèƒ½å¤Ÿç”Ÿæˆé«˜ç½®ä¿¡åº¦çš„ä¼ªæ ‡ç­¾ï¼ŒåŒæ—¶å­¦ä¹ æ•´åˆå¤šé¢‘ä¿¡æ¯å¹¶ä¿æŒç›®æ ‡çš„ç»“æ„å®Œæ•´æ€§ã€‚</li>
<li>å®éªŒè¯æ˜ï¼ŒCFC-MTåœ¨FMRC-2025å’Œå…¶ä»–å…¬å…±ç‰™ç§‘æ•°æ®é›†ä¸Šè¡¨ç°å‡ºå¼ºå¤§çš„æ€§èƒ½ï¼Œä¼˜äºç°æœ‰çš„åŒ»å­¦å›¾åƒåˆ†å‰²SSLæ–¹æ³•ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.11856">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-5d3e4e0f7a1ab7874ea0a1e063ada703.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-8116ad2e42da6b17323e824bed16d383.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-316b6273e319ef222f2c5f5ca1700806.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="TextDiffSeg-Text-guided-Latent-Diffusion-Model-for-3d-Medical-Images-Segmentation"><a href="#TextDiffSeg-Text-guided-Latent-Diffusion-Model-for-3d-Medical-Images-Segmentation" class="headerlink" title="TextDiffSeg: Text-guided Latent Diffusion Model for 3d Medical Images   Segmentation"></a>TextDiffSeg: Text-guided Latent Diffusion Model for 3d Medical Images   Segmentation</h2><p><strong>Authors:Kangbo Ma</strong></p>
<p>Diffusion Probabilistic Models (DPMs) have demonstrated significant potential in 3D medical image segmentation tasks. However, their high computational cost and inability to fully capture global 3D contextual information limit their practical applications. To address these challenges, we propose a novel text-guided diffusion model framework, TextDiffSeg. This method leverages a conditional diffusion framework that integrates 3D volumetric data with natural language descriptions, enabling cross-modal embedding and establishing a shared semantic space between visual and textual modalities. By enhancing the modelâ€™s ability to recognize complex anatomical structures, TextDiffSeg incorporates innovative label embedding techniques and cross-modal attention mechanisms, effectively reducing computational complexity while preserving global 3D contextual integrity. Experimental results demonstrate that TextDiffSeg consistently outperforms existing methods in segmentation tasks involving kidney and pancreas tumors, as well as multi-organ segmentation scenarios. Ablation studies further validate the effectiveness of key components, highlighting the synergistic interaction between text fusion, image feature extractor, and label encoder. TextDiffSeg provides an efficient and accurate solution for 3D medical image segmentation, showcasing its broad applicability in clinical diagnosis and treatment planning. </p>
<blockquote>
<p>æ‰©æ•£æ¦‚ç‡æ¨¡å‹ï¼ˆDPMsï¼‰åœ¨3DåŒ»å­¦å›¾åƒåˆ†å‰²ä»»åŠ¡ä¸­æ˜¾ç¤ºå‡ºå·¨å¤§æ½œåŠ›ã€‚ç„¶è€Œï¼Œå…¶è¾ƒé«˜çš„è®¡ç®—æˆæœ¬å’Œæ— æ³•å®Œå…¨æ•è·å…¨å±€3Dä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œé™åˆ¶äº†å…¶å®é™…åº”ç”¨ã€‚ä¸ºäº†è§£å†³è¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°å‹çš„æ–‡æœ¬å¼•å¯¼æ‰©æ•£æ¨¡å‹æ¡†æ¶ï¼Œåä¸ºTextDiffSegã€‚è¯¥æ–¹æ³•åˆ©ç”¨æ¡ä»¶æ‰©æ•£æ¡†æ¶ï¼Œå°†3Dä½“ç§¯æ•°æ®ä¸è‡ªç„¶è¯­è¨€æè¿°ç›¸ç»“åˆï¼Œå®ç°è·¨æ¨¡æ€åµŒå…¥ï¼Œå»ºç«‹è§†è§‰å’Œæ–‡æœ¬æ¨¡æ€ä¹‹é—´çš„å…±äº«è¯­ä¹‰ç©ºé—´ã€‚é€šè¿‡å¢å¼ºæ¨¡å‹å¯¹å¤æ‚è§£å‰–ç»“æ„çš„è¯†åˆ«èƒ½åŠ›ï¼ŒTextDiffSegç»“åˆäº†åˆ›æ–°çš„æ ‡ç­¾åµŒå…¥æŠ€æœ¯å’Œè·¨æ¨¡æ€æ³¨æ„åŠ›æœºåˆ¶ï¼Œåœ¨é™ä½è®¡ç®—å¤æ‚æ€§çš„åŒæ—¶ï¼Œä¿æŒäº†å…¨å±€3Dä¸Šä¸‹æ–‡å®Œæ•´æ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒTextDiffSegåœ¨æ¶‰åŠè‚¾è„å’Œèƒ°è…ºè‚¿ç˜¤çš„åˆ†å‰²ä»»åŠ¡ä»¥åŠå¤šå™¨å®˜åˆ†å‰²åœºæ™¯ä¸­å§‹ç»ˆä¼˜äºç°æœ‰æ–¹æ³•ã€‚æ¶ˆèç ”ç©¶è¿›ä¸€æ­¥éªŒè¯äº†å…³é”®ç»„ä»¶çš„æœ‰æ•ˆæ€§ï¼Œçªå‡ºäº†æ–‡æœ¬èåˆã€å›¾åƒç‰¹å¾æå–å™¨å’Œæ ‡ç­¾ç¼–ç å™¨ä¹‹é—´çš„ååŒäº¤äº’ã€‚TextDiffSegä¸º3DåŒ»å­¦å›¾åƒåˆ†å‰²æä¾›äº†é«˜æ•ˆå‡†ç¡®çš„è§£å†³æ–¹æ¡ˆï¼Œå±•ç¤ºäº†å…¶åœ¨ä¸´åºŠè¯Šæ–­å’Œæ²»ç–—è®¡åˆ’ä¸­çš„å¹¿æ³›åº”ç”¨æ€§ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.11825v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>DPMsåœ¨3DåŒ»å­¦å›¾åƒåˆ†å‰²ä»»åŠ¡ä¸­å±•ç°å‡ºå·¨å¤§æ½œåŠ›ï¼Œä½†å…¶é«˜è®¡ç®—æˆæœ¬å’Œæ— æ³•å®Œå…¨æ•æ‰å…¨å±€3Dä¸Šä¸‹æ–‡ä¿¡æ¯é™åˆ¶äº†å®é™…åº”ç”¨ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬æå‡ºä¸€ç§æ–°å‹æ–‡æœ¬å¼•å¯¼æ‰©æ•£æ¨¡å‹æ¡†æ¶TextDiffSegã€‚è¯¥æ–¹æ³•ç»“åˆ3Dä½“ç§¯æ•°æ®ä¸è‡ªç„¶è¯­è¨€æè¿°ï¼Œå»ºç«‹è·¨æ¨¡æ€åµŒå…¥å’Œè§†è§‰ä¸æ–‡æœ¬æ¨¡æ€ä¹‹é—´çš„å…±äº«è¯­ä¹‰ç©ºé—´ï¼Œæé«˜æ¨¡å‹è¯†åˆ«å¤æ‚è§£å‰–ç»“æ„çš„èƒ½åŠ›ã€‚TextDiffSegèå…¥æ ‡ç­¾åµŒå…¥æŠ€æœ¯å’Œè·¨æ¨¡æ€æ³¨æ„åŠ›æœºåˆ¶ï¼Œåœ¨é™ä½è®¡ç®—å¤æ‚åº¦çš„åŒæ—¶ä¿æŒå…¨å±€3Dä¸Šä¸‹æ–‡å®Œæ•´æ€§ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒTextDiffSegåœ¨è‚¾è„ã€èƒ°è…ºè‚¿ç˜¤åˆ†å‰²ä»»åŠ¡ä»¥åŠå¤šå™¨å®˜åˆ†å‰²åœºæ™¯ä¸­å‡è¡¨ç°å‡ºä¼˜å¼‚æ€§èƒ½ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>DPMsåœ¨3DåŒ»å­¦å›¾åƒåˆ†å‰²ä¸­æ½œåŠ›å·¨å¤§ï¼Œä½†å­˜åœ¨è®¡ç®—æˆæœ¬é«˜å’Œ3Dä¸Šä¸‹æ–‡ä¿¡æ¯æ•æ‰ä¸è¶³çš„é—®é¢˜ã€‚</li>
<li>TextDiffSegæ˜¯ä¸€ç§æ–°å‹çš„æ–‡æœ¬å¼•å¯¼æ‰©æ•£æ¨¡å‹æ¡†æ¶ï¼Œç»“åˆäº†3Dä½“ç§¯æ•°æ®å’Œè‡ªç„¶è¯­è¨€æè¿°ã€‚</li>
<li>TextDiffSegé€šè¿‡è·¨æ¨¡æ€åµŒå…¥å»ºç«‹è§†è§‰å’Œæ–‡æœ¬æ¨¡æ€ä¹‹é—´çš„å…±äº«è¯­ä¹‰ç©ºé—´ã€‚</li>
<li>TextDiffSegæé«˜äº†æ¨¡å‹è¯†åˆ«å¤æ‚è§£å‰–ç»“æ„çš„èƒ½åŠ›ï¼Œå¹¶èå…¥äº†æ ‡ç­¾åµŒå…¥æŠ€æœ¯å’Œè·¨æ¨¡æ€æ³¨æ„åŠ›æœºåˆ¶ã€‚</li>
<li>TextDiffSegåœ¨è‚¾è„ã€èƒ°è…ºè‚¿ç˜¤åˆ†å‰²ä»»åŠ¡ä»¥åŠå¤šå™¨å®˜åˆ†å‰²åœºæ™¯ä¸­è¡¨ç°ä¼˜å¼‚ã€‚</li>
<li>æ¶ˆèç ”ç©¶éªŒè¯äº†TextDiffSegå…³é”®ç»„ä»¶çš„æœ‰æ•ˆæ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.11825">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-37b3fe4bca2d564dcf6d056355a8575a.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-976c87d19980198279c305d18f977e56.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-e4b723e9448318669ce67ea6d3f3f30a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b7623f857d2a0eef24db11ebf73833ea.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-f61c79d602c8dbdeb1e4e9d5ed42fc13.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="DART-Disease-aware-Image-Text-Alignment-and-Self-correcting-Re-alignment-for-Trustworthy-Radiology-Report-Generation"><a href="#DART-Disease-aware-Image-Text-Alignment-and-Self-correcting-Re-alignment-for-Trustworthy-Radiology-Report-Generation" class="headerlink" title="DART: Disease-aware Image-Text Alignment and Self-correcting   Re-alignment for Trustworthy Radiology Report Generation"></a>DART: Disease-aware Image-Text Alignment and Self-correcting   Re-alignment for Trustworthy Radiology Report Generation</h2><p><strong>Authors:Sang-Jun Park, Keun-Soo Heo, Dong-Hee Shin, Young-Han Son, Ji-Hye Oh, Tae-Eui Kam</strong></p>
<p>The automatic generation of radiology reports has emerged as a promising solution to reduce a time-consuming task and accurately capture critical disease-relevant findings in X-ray images. Previous approaches for radiology report generation have shown impressive performance. However, there remains significant potential to improve accuracy by ensuring that retrieved reports contain disease-relevant findings similar to those in the X-ray images and by refining generated reports. In this study, we propose a Disease-aware image-text Alignment and self-correcting Re-alignment for Trustworthy radiology report generation (DART) framework. In the first stage, we generate initial reports based on image-to-text retrieval with disease-matching, embedding both images and texts in a shared embedding space through contrastive learning. This approach ensures the retrieval of reports with similar disease-relevant findings that closely align with the input X-ray images. In the second stage, we further enhance the initial reports by introducing a self-correction module that re-aligns them with the X-ray images. Our proposed framework achieves state-of-the-art results on two widely used benchmarks, surpassing previous approaches in both report generation and clinical efficacy metrics, thereby enhancing the trustworthiness of radiology reports. </p>
<blockquote>
<p>æ”¾å°„å­¦æŠ¥å‘Šçš„è‡ªåŠ¨ç”Ÿæˆå·²æˆä¸ºå‡å°‘è€—æ—¶ä»»åŠ¡å¹¶å‡†ç¡®æ•æ‰Xå…‰ç‰‡ä¸­ä¸ç–¾ç—…ç›¸å…³çš„å…³é”®å‘ç°çš„ä¸€ç§æœ‰å‰é€”çš„è§£å†³æ–¹æ¡ˆã€‚ä¹‹å‰ç”¨äºç”Ÿæˆæ”¾å°„å­¦æŠ¥å‘Šçš„æ–¹æ³•å·²ç»è¡¨ç°å‡ºäº†ä»¤äººå°è±¡æ·±åˆ»çš„æ•ˆæœã€‚ç„¶è€Œï¼Œé€šè¿‡ç¡®ä¿æ£€ç´¢åˆ°çš„æŠ¥å‘ŠåŒ…å«ä¸Xå…‰å›¾åƒä¸­ç›¸ä¼¼çš„ç–¾ç—…ç›¸å…³å‘ç°ï¼Œå¹¶é€šè¿‡å®Œå–„ç”Ÿæˆçš„æŠ¥å‘Šï¼Œä»å­˜åœ¨æé«˜å‡†ç¡®æ€§çš„å·¨å¤§æ½œåŠ›ã€‚åœ¨è¿™é¡¹ç ”ç©¶ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªç–¾ç—…æ„ŸçŸ¥çš„å›¾åƒæ–‡æœ¬å¯¹é½å’Œè‡ªæ ¡æ­£é‡æ–°å¯¹é½çš„å¯ä¿¡æ”¾å°„å­¦æŠ¥å‘Šç”Ÿæˆï¼ˆDARTï¼‰æ¡†æ¶ã€‚åœ¨ç¬¬ä¸€é˜¶æ®µï¼Œæˆ‘ä»¬åŸºäºå›¾åƒåˆ°æ–‡æœ¬çš„æ£€ç´¢ç”Ÿæˆåˆæ­¥æŠ¥å‘Šï¼Œå¹¶è¿›è¡Œç–¾ç—…åŒ¹é…ï¼Œé€šè¿‡å¯¹æ¯”å­¦ä¹ å°†å›¾åƒå’Œæ–‡æœ¬åµŒå…¥åˆ°å…±äº«åµŒå…¥ç©ºé—´ä¸­ã€‚è¿™ç§æ–¹æ³•ç¡®ä¿æ£€ç´¢åˆ°çš„æŠ¥å‘ŠåŒ…å«ç›¸ä¼¼çš„ç–¾ç—…ç›¸å…³å‘ç°ï¼Œä¸è¾“å…¥çš„Xå…‰å›¾åƒç´§å¯†å¯¹é½ã€‚åœ¨ç¬¬äºŒé˜¶æ®µï¼Œæˆ‘ä»¬é€šè¿‡å¼•å…¥ä¸€ä¸ªè‡ªæˆ‘æ ¡æ­£æ¨¡å—æ¥è¿›ä¸€æ­¥æ”¹è¿›åˆæ­¥çš„æŠ¥å‘Šï¼Œè¯¥æ¨¡å—ä½¿å…¶ä¸Xå…‰å›¾åƒé‡æ–°å¯¹é½ã€‚æˆ‘ä»¬æå‡ºçš„æ¡†æ¶åœ¨ä¸¤ä¸ªå¹¿æ³›ä½¿ç”¨çš„åŸºå‡†æµ‹è¯•ä¸Šè¾¾åˆ°äº†æœ€æ–°ç»“æœï¼Œåœ¨æŠ¥å‘Šç”Ÿæˆå’Œä¸´åºŠæœ‰æ•ˆæ€§æŒ‡æ ‡ä¸Šå‡è¶…è¶Šäº†ä»¥å‰çš„æ–¹æ³•ï¼Œä»è€Œæé«˜äº†æ”¾å°„å­¦æŠ¥å‘Šçš„å¯ä¿¡åº¦ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.11786v1">PDF</a> The IEEE&#x2F;CVF Conference on Computer Vision and Pattern Recognition   (CVPR) 2025</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºç–¾ç—…æ„è¯†çš„å›¾åƒæ–‡æœ¬å¯¹é½å’Œè‡ªæ ¡æ­£é‡æ–°å¯¹é½çš„å¯é æ”¾å°„å­¦æŠ¥å‘Šç”Ÿæˆï¼ˆDARTï¼‰æ¡†æ¶ï¼Œæ—¨åœ¨æé«˜æ”¾å°„å­¦æŠ¥å‘Šçš„å‡†ç¡®æ€§å’Œæ•ˆç‡ã€‚è¯¥æ¡†æ¶é¦–å…ˆé€šè¿‡å›¾åƒåˆ°æ–‡æœ¬çš„æ£€ç´¢ç”Ÿæˆåˆæ­¥æŠ¥å‘Šï¼Œç¡®ä¿æ£€ç´¢åˆ°çš„æŠ¥å‘Šä¸Xå…‰å›¾åƒä¸­çš„ç–¾ç—…ç›¸å…³å‘ç°ç›¸ä¼¼å¹¶ç´§å¯†å¯¹é½ã€‚æ¥ç€å¼•å…¥è‡ªæ ¡æ­£æ¨¡å—è¿›ä¸€æ­¥ä¼˜åŒ–åˆæ­¥æŠ¥å‘Šï¼Œä½¿å…¶ä¸Xå…‰å›¾åƒé‡æ–°å¯¹é½ï¼Œä»è€Œæé«˜æŠ¥å‘Šçš„å¯é æ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æ”¾å°„å­¦æŠ¥å‘Šè‡ªåŠ¨ç”Ÿæˆæˆä¸ºå‡å°‘è€—æ—¶ä»»åŠ¡å¹¶å‡†ç¡®æ•æ‰Xå…‰å›¾åƒä¸­å…³é”®ç–¾ç—…ç›¸å…³å‘ç°çš„æœ‰å‰é€”çš„è§£å†³æ–¹æ¡ˆã€‚</li>
<li>ç°æœ‰æ–¹æ³•åœ¨æ”¾å°„å­¦æŠ¥å‘Šç”Ÿæˆæ–¹é¢å·²è¡¨ç°å‡ºä»¤äººå°è±¡æ·±åˆ»çš„è¡¨ç°ï¼Œä½†ä»æœ‰æ”¹è¿›å‡†ç¡®æ€§çš„æ½œåŠ›ã€‚</li>
<li>DARTæ¡†æ¶é€šè¿‡ç–¾ç—…æ„è¯†çš„å›¾åƒæ–‡æœ¬å¯¹é½ç¡®ä¿æ£€ç´¢åˆ°çš„æŠ¥å‘Šä¸Xå…‰å›¾åƒä¸­çš„ç–¾ç—…ç›¸å…³å‘ç°ç›¸ä¼¼ã€‚</li>
<li>åˆæ­¥æŠ¥å‘ŠåŸºäºå›¾åƒåˆ°æ–‡æœ¬çš„æ£€ç´¢ç”Ÿæˆï¼Œä½¿ç”¨å¯¹æ¯”å­¦ä¹ å°†å›¾åƒå’Œæ–‡æœ¬åµŒå…¥åˆ°å…±äº«åµŒå…¥ç©ºé—´ä¸­ã€‚</li>
<li>è‡ªæ ¡æ­£æ¨¡å—è¿›ä¸€æ­¥ä¼˜åŒ–åˆæ­¥æŠ¥å‘Šï¼Œä½¿å…¶ä¸Xå…‰å›¾åƒé‡æ–°å¯¹é½ï¼Œæé«˜æŠ¥å‘Šçš„å‡†ç¡®æ€§ã€‚</li>
<li>DARTæ¡†æ¶åœ¨ä¸¤ä¸ªå¹¿æ³›ä½¿ç”¨çš„åŸºå‡†æµ‹è¯•ä¸Šè¾¾åˆ°æœ€æ–°ç»“æœï¼Œåœ¨æŠ¥å‘Šç”Ÿæˆå’Œä¸´åºŠåŠŸæ•ˆæŒ‡æ ‡ä¸Šè¶…è¶Šä»¥å‰çš„æ–¹æ³•ã€‚</li>
<li>è¯¥æ¡†æ¶æé«˜äº†æ”¾å°„å­¦æŠ¥å‘Šçš„å¯é æ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.11786">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-fa41f28c87761083ffb984a8d919b3d8.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f0dcffa4fb9560ec442a4d41f1804c18.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ab49a1cec7a05a255362da3e39a880ce.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-5d4a3fc2911e92f09801d457b491417d.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="FACT-Foundation-Model-for-Assessing-Cancer-Tissue-Margins-with-Mass-Spectrometry"><a href="#FACT-Foundation-Model-for-Assessing-Cancer-Tissue-Margins-with-Mass-Spectrometry" class="headerlink" title="FACT: Foundation Model for Assessing Cancer Tissue Margins with Mass   Spectrometry"></a>FACT: Foundation Model for Assessing Cancer Tissue Margins with Mass   Spectrometry</h2><p><strong>Authors:Mohammad Farahmand, Amoon Jamzad, Fahimeh Fooladgar, Laura Connolly, Martin Kaufmann, Kevin Yi Mi Ren, John Rudan, Doug McKay, Gabor Fichtinger, Parvin Mousavi</strong></p>
<p>Purpose: Accurately classifying tissue margins during cancer surgeries is crucial for ensuring complete tumor removal. Rapid Evaporative Ionization Mass Spectrometry (REIMS), a tool for real-time intraoperative margin assessment, generates spectra that require machine learning models to support clinical decision-making. However, the scarcity of labeled data in surgical contexts presents a significant challenge. This study is the first to develop a foundation model tailored specifically for REIMS data, addressing this limitation and advancing real-time surgical margin assessment. Methods: We propose FACT, a Foundation model for Assessing Cancer Tissue margins. FACT is an adaptation of a foundation model originally designed for text-audio association, pretrained using our proposed supervised contrastive approach based on triplet loss. An ablation study is performed to compare our proposed model against other models and pretraining methods. Results: Our proposed model significantly improves the classification performance, achieving state-of-the-art performance with an AUROC of $82.4% \pm 0.8$. The results demonstrate the advantage of our proposed pretraining method and selected backbone over the self-supervised and semi-supervised baselines and alternative models. Conclusion: Our findings demonstrate that foundation models, adapted and pretrained using our novel approach, can effectively classify REIMS data even with limited labeled examples. This highlights the viability of foundation models for enhancing real-time surgical margin assessment, particularly in data-scarce clinical environments. </p>
<blockquote>
<p>ç›®çš„ï¼šåœ¨ç™Œç—‡æ‰‹æœ¯ä¸­ï¼Œå‡†ç¡®åˆ†ç±»ç»„ç»‡è¾¹ç•Œå¯¹äºç¡®ä¿è‚¿ç˜¤å®Œå…¨åˆ‡é™¤è‡³å…³é‡è¦ã€‚å¿«é€Ÿè’¸å‘ç”µç¦»è´¨è°±æ³•ï¼ˆREIMSï¼‰æ˜¯ä¸€ç§ç”¨äºå®æ—¶æœ¯ä¸­è¾¹ç•Œè¯„ä¼°çš„å·¥å…·ï¼Œèƒ½å¤Ÿäº§ç”Ÿå…‰è°±ï¼Œéœ€è¦æœºå™¨å­¦ä¹ æ¨¡å‹æ¥æ”¯æŒä¸´åºŠå†³ç­–ã€‚ç„¶è€Œï¼Œæ‰‹æœ¯ç¯å¢ƒä¸­æ ‡è®°æ•°æ®çš„ç¨€ç¼ºæ€§æ„æˆäº†é‡å¤§æŒ‘æˆ˜ã€‚æœ¬ç ”ç©¶é¦–æ¬¡é’ˆå¯¹REIMSæ•°æ®å¼€å‘åŸºç¡€æ¨¡å‹ï¼Œè§£å†³äº†è¿™ä¸€é™åˆ¶ï¼Œæ¨è¿›äº†å®æ—¶æ‰‹æœ¯è¾¹ç•Œè¯„ä¼°çš„å‘å±•ã€‚</p>
</blockquote>
<p>æ–¹æ³•ï¼šæˆ‘ä»¬æå‡ºäº†FACTï¼ˆç”¨äºè¯„ä¼°ç™Œç—‡ç»„ç»‡è¾¹ç•Œçš„åŸºç¡€æ¨¡å‹ï¼‰ã€‚FACTæ˜¯å¯¹æœ€åˆä¸ºæ–‡æœ¬-éŸ³é¢‘å…³è”è®¾è®¡çš„åŸºç¡€æ¨¡å‹çš„æ”¹ç¼–ï¼Œä½¿ç”¨æˆ‘ä»¬æå‡ºçš„æœ‰ç›‘ç£å¯¹æ¯”æ–¹æ³•åŸºäºä¸‰å…ƒæŸå¤±è¿›è¡Œé¢„è®­ç»ƒã€‚æˆ‘ä»¬è¿›è¡Œäº†ä¸€é¡¹æ¶ˆèç ”ç©¶ï¼Œå°†æ‰€æå‡ºçš„æ¨¡å‹ä¸å…¶ä»–æ¨¡å‹å’Œé¢„è®­ç»ƒæ–¹æ³•è¿›è¡Œæ¯”è¾ƒã€‚</p>
<p>ç»“æœï¼šæˆ‘ä»¬æå‡ºçš„æ¨¡å‹æ˜¾è‘—æé«˜äº†åˆ†ç±»æ€§èƒ½ï¼Œå®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œæ›²çº¿ä¸‹é¢ç§¯ï¼ˆAUROCï¼‰ä¸º82.4%Â±0.8ã€‚ç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„é¢„è®­ç»ƒæ–¹æ³•å’Œæ‰€é€‰ä¸»å¹²ç›¸å¯¹äºè‡ªç›‘ç£ã€åŠç›‘ç£å’Œæ›¿ä»£æ¨¡å‹çš„ä¼˜åŠ¿ã€‚</p>
<p>ç»“è®ºï¼šæˆ‘ä»¬çš„ç ”ç©¶ç»“æœè¡¨æ˜ï¼Œä½¿ç”¨æˆ‘ä»¬çš„æ–°å‹æ–¹æ³•é€‚åº”å’Œé¢„è®­ç»ƒçš„åŸºç¡€æ¨¡å‹ï¼Œå³ä½¿åœ¨æœ‰é™çš„æ ‡è®°ç¤ºä¾‹æƒ…å†µä¸‹ï¼Œä¹Ÿèƒ½æœ‰æ•ˆåœ°å¯¹REIMSæ•°æ®è¿›è¡Œåˆ†ç±»ã€‚è¿™çªå‡ºäº†åŸºç¡€æ¨¡å‹åœ¨æé«˜å®æ—¶æ‰‹æœ¯è¾¹ç•Œè¯„ä¼°æ–¹é¢çš„å¯è¡Œæ€§ï¼Œç‰¹åˆ«æ˜¯åœ¨æ•°æ®ç¨€ç¼ºçš„ä¸´åºŠç¯å¢ƒä¸­ã€‚</p>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.11519v1">PDF</a> </p>
<p><strong>æ‘˜è¦</strong></p>
<p>æœ¬æ–‡æ—¨åœ¨è§£å†³ç™Œç—‡æ‰‹æœ¯ä¸­å‡†ç¡®åˆ†ç±»ç»„ç»‡åˆ‡ç¼˜çš„å…³é”®é—®é¢˜ï¼Œå¯¹äºç¡®ä¿è‚¿ç˜¤å®Œå…¨åˆ‡é™¤è‡³å…³é‡è¦ã€‚ç ”ç©¶ä¸­ï¼Œæˆ‘ä»¬æå‡ºä½¿ç”¨å¿«é€Ÿè’¸å‘ç”µç¦»è´¨è°±æŠ€æœ¯ï¼ˆREIMSï¼‰è¿›è¡Œå®æ—¶æ‰‹æœ¯åˆ‡ç¼˜è¯„ä¼°ï¼Œå¹¶å¼€å‘äº†ä¸€ç§é’ˆå¯¹REIMSæ•°æ®çš„åŸºç¡€æ¨¡å‹FACTã€‚è¯¥æ¨¡å‹åŸºäºæ–‡æœ¬-éŸ³é¢‘å…³è”è®¾è®¡çš„åŸå§‹åŸºç¡€æ¨¡å‹è¿›è¡Œæ”¹ç¼–ï¼Œé‡‡ç”¨æˆ‘ä»¬æå‡ºçš„æœ‰ç›‘ç£å¯¹æ¯”æ–¹æ³•è¿›è¡Œé¢„è®­ç»ƒã€‚ç ”ç©¶ç»“æœæ˜¾ç¤ºï¼Œæˆ‘ä»¬çš„æ¨¡å‹åœ¨åˆ†ç±»æ€§èƒ½ä¸Šæ˜¾è‘—æé«˜ï¼Œè¾¾åˆ°äº†å…ˆè¿›çš„æ€§èƒ½æ°´å¹³ï¼ŒAUROCä¸º$82.4% \pm 0.8$ã€‚è¿™è¡¨æ˜æˆ‘ä»¬çš„é¢„è®­ç»ƒæ–¹æ³•å’Œæ‰€é€‰éª¨å¹²ç½‘ç»œçš„ä¼˜åŠ¿ï¼Œä¼˜äºè‡ªç›‘ç£ã€åŠç›‘ç£å’Œæ›¿ä»£æ¨¡å‹çš„åŸºçº¿æ°´å¹³ã€‚æˆ‘ä»¬çš„ç ”ç©¶ç»“æœè¡¨æ˜ï¼Œä½¿ç”¨æˆ‘ä»¬çš„æ–°æ–¹æ³•é€‚åº”å’Œé¢„è®­ç»ƒçš„åŸºç¡€æ¨¡å‹å¯ä»¥æœ‰æ•ˆåœ°åˆ†ç±»REIMSæ•°æ®ï¼Œå³ä½¿åœ¨æ ‡è®°æ ·æœ¬æœ‰é™çš„æƒ…å†µä¸‹ä¹Ÿæ˜¯å¦‚æ­¤ã€‚è¿™ä¸ºåœ¨æ•°æ®ç¨€ç¼ºçš„ä¸´åºŠç¯å¢ƒä¸­å¢å¼ºå®æ—¶æ‰‹æœ¯åˆ‡ç¼˜è¯„ä¼°æä¾›äº†å¯èƒ½æ€§ã€‚</p>
<p><strong>å…³é”®è§è§£</strong></p>
<ol>
<li>ç ”ç©¶å…³æ³¨ç™Œç—‡æ‰‹æœ¯ä¸­å‡†ç¡®åˆ†ç±»ç»„ç»‡åˆ‡ç¼˜çš„é‡è¦æ€§ï¼Œä»¥ç¡®ä¿è‚¿ç˜¤çš„å®Œå…¨åˆ‡é™¤ã€‚</li>
<li>æå‡ºä½¿ç”¨REIMSæŠ€æœ¯è¿›è¡Œå®æ—¶æ‰‹æœ¯åˆ‡ç¼˜è¯„ä¼°ã€‚</li>
<li>å¼€å‘äº†ä¸€ä¸ªåä¸ºFACTçš„åŸºç¡€æ¨¡å‹ï¼Œä¸“ä¸ºREIMSæ•°æ®è®¾è®¡ï¼Œè§£å†³æ•°æ®ç¨€ç¼ºçš„æŒ‘æˆ˜ã€‚</li>
<li>é‡‡ç”¨æœ‰ç›‘ç£å¯¹æ¯”æ–¹æ³•è¿›è¡Œé¢„è®­ç»ƒï¼Œæé«˜äº†æ¨¡å‹çš„æ€§èƒ½ã€‚</li>
<li>å¯¹æ¯”ç ”ç©¶ç»“æœæ˜¾ç¤ºï¼ŒFACTæ¨¡å‹åœ¨åˆ†ç±»æ€§èƒ½ä¸Šè¾¾åˆ°å…ˆè¿›æ°´å¹³ã€‚</li>
<li>æ¨¡å‹çš„é¢„è®­ç»ƒæ–¹æ³•å’Œéª¨å¹²ç½‘ç»œçš„é€‰æ‹©æ˜¾ç¤ºä¼˜åŠ¿ï¼Œä¼˜äºå…¶ä»–é¢„è®­ç»ƒæ–¹æ³•å’Œæ¨¡å‹ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.11519">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-6e476db879f794a70dd60e3763311ae2.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-10b6815e4a5530cf72d449f7b20d9027.jpg" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="snnTrans-DHZ-A-Lightweight-Spiking-Neural-Network-Architecture-for-Underwater-Image-Dehazing"><a href="#snnTrans-DHZ-A-Lightweight-Spiking-Neural-Network-Architecture-for-Underwater-Image-Dehazing" class="headerlink" title="snnTrans-DHZ: A Lightweight Spiking Neural Network Architecture for   Underwater Image Dehazing"></a>snnTrans-DHZ: A Lightweight Spiking Neural Network Architecture for   Underwater Image Dehazing</h2><p><strong>Authors:Vidya Sudevan, Fakhreddine Zayer, Rizwana Kausar, Sajid Javed, Hamad Karki, Giulia De Masi, Jorge Dias</strong></p>
<p>Underwater image dehazing is critical for vision-based marine operations because light scattering and absorption can severely reduce visibility. This paper introduces snnTrans-DHZ, a lightweight Spiking Neural Network (SNN) specifically designed for underwater dehazing. By leveraging the temporal dynamics of SNNs, snnTrans-DHZ efficiently processes time-dependent raw image sequences while maintaining low power consumption. Static underwater images are first converted into time-dependent sequences by repeatedly inputting the same image over user-defined timesteps. These RGB sequences are then transformed into LAB color space representations and processed concurrently. The architecture features three key modules: (i) a K estimator that extracts features from multiple color space representations; (ii) a Background Light Estimator that jointly infers the background light component from the RGB-LAB images; and (iii) a soft image reconstruction module that produces haze-free, visibility-enhanced outputs. The snnTrans-DHZ model is directly trained using a surrogate gradient-based backpropagation through time (BPTT) strategy alongside a novel combined loss function. Evaluated on the UIEB benchmark, snnTrans-DHZ achieves a PSNR of 21.68 dB and an SSIM of 0.8795, and on the EUVP dataset, it yields a PSNR of 23.46 dB and an SSIM of 0.8439. With only 0.5670 million network parameters, and requiring just 7.42 GSOPs and 0.0151 J of energy, the algorithm significantly outperforms existing state-of-the-art methods in terms of efficiency. These features make snnTrans-DHZ highly suitable for deployment in underwater robotics, marine exploration, and environmental monitoring. </p>
<blockquote>
<p>æ°´ä¸‹å›¾åƒå»é›¾å¯¹äºåŸºäºè§†è§‰çš„æµ·æ´‹æ“ä½œè‡³å…³é‡è¦ï¼Œå› ä¸ºå…‰çš„æ•£å°„å’Œå¸æ”¶ä¼šä¸¥é‡å½±å“èƒ½è§åº¦ã€‚æœ¬æ–‡ä»‹ç»äº†snnTrans-DHZï¼Œè¿™æ˜¯ä¸€ä¸ªä¸“é—¨ç”¨äºæ°´ä¸‹å»é›¾çš„è½»é‡çº§è„‰å†²ç¥ç»ç½‘ç»œï¼ˆSNNï¼‰ã€‚é€šè¿‡åˆ©ç”¨SNNçš„æ—¶ç©ºåŠ¨æ€ç‰¹æ€§ï¼ŒsnnTrans-DHZèƒ½å¤Ÿé«˜æ•ˆåœ°å¤„ç†æ—¶é—´ç›¸å…³çš„åŸå§‹å›¾åƒåºåˆ—ï¼ŒåŒæ—¶ä¿æŒä½åŠŸè€—ã€‚</p>
</blockquote>
<p>é¦–å…ˆï¼Œå°†é™æ€æ°´ä¸‹å›¾åƒè½¬æ¢ä¸ºæ—¶é—´ç›¸å…³çš„åºåˆ—ï¼Œé€šè¿‡ç”¨æˆ·å®šä¹‰çš„æ—¶åºåå¤è¾“å…¥ç›¸åŒçš„å›¾åƒã€‚ç„¶åï¼Œè¿™äº›RGBåºåˆ—è¢«è½¬æ¢ä¸ºLABé¢œè‰²ç©ºé—´è¡¨ç¤ºï¼Œå¹¶å¹¶è¡Œå¤„ç†ã€‚è¯¥æ¶æ„å…·æœ‰ä¸‰ä¸ªå…³é”®æ¨¡å—ï¼šï¼ˆiï¼‰Kä¼°è®¡å™¨ï¼Œä»å¤šä¸ªé¢œè‰²ç©ºé—´è¡¨ç¤ºä¸­æå–ç‰¹å¾ï¼›ï¼ˆiiï¼‰èƒŒæ™¯å…‰ä¼°è®¡å™¨ï¼Œä»RGB-LABå›¾åƒä¸­è”åˆæ¨æ–­èƒŒæ™¯å…‰æˆåˆ†ï¼›ï¼ˆiiiï¼‰è½¯å›¾åƒé‡å»ºæ¨¡å—ï¼Œç”Ÿæˆæ— é›¾ã€æé«˜å¯è§åº¦çš„è¾“å‡ºã€‚</p>
<p>snnTrans-DHZæ¨¡å‹ç›´æ¥ä½¿ç”¨åŸºäºæ›¿ä»£æ¢¯åº¦çš„åå‘ä¼ æ’­å’Œæ—¶é—´ï¼ˆBPTTï¼‰ç­–ç•¥ä»¥åŠä¸€ç§æ–°çš„ç»„åˆæŸå¤±å‡½æ•°è¿›è¡Œè®­ç»ƒã€‚åœ¨UIEBåŸºå‡†æµ‹è¯•ä¸­ï¼ŒsnnTrans-DHZè¾¾åˆ°21.68åˆ†è´çš„PSNRå’Œ0.8795çš„SSIMï¼›åœ¨EUVPæ•°æ®é›†ä¸Šï¼Œå®ƒè¾¾åˆ°23.46åˆ†è´çš„PSNRå’Œ0.8439çš„SSIMã€‚è¯¥ç®—æ³•åªæœ‰0.5670ç™¾ä¸‡ç½‘ç»œå‚æ•°ï¼Œä»…éœ€7.42 GSOPså’Œ0.0151ç„¦è€³çš„èƒ½é‡ï¼Œåœ¨æ•ˆç‡æ–¹é¢æ˜¾è‘—ä¼˜äºç°æœ‰çš„æœ€å…ˆè¿›æ–¹æ³•ã€‚è¿™äº›ç‰¹æ€§ä½¿snnTrans-DHZéå¸¸é€‚åˆç”¨äºæ°´ä¸‹æœºå™¨äººã€æµ·æ´‹æ¢ç´¢å’Œç¯å¢ƒç›‘æµ‹ã€‚</p>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.11482v1">PDF</a> </p>
<p><strong>æ‘˜è¦</strong></p>
<p>æ°´ä¸‹å›¾åƒå»é›¾å¯¹äºåŸºäºè§†è§‰çš„æµ·æ´‹æ“ä½œè‡³å…³é‡è¦ï¼Œå› ä¸ºå…‰çš„æ•£å°„å’Œå¸æ”¶ä¼šä¸¥é‡å½±å“èƒ½è§åº¦ã€‚æœ¬æ–‡ä»‹ç»äº†snnTrans-DHZï¼Œè¿™æ˜¯ä¸€ä¸ªä¸“ä¸ºæ°´ä¸‹å›¾åƒå»é›¾è®¾è®¡çš„è½»é‡çº§è„‰å†²ç¥ç»ç½‘ç»œï¼ˆSNNï¼‰ã€‚é€šè¿‡åˆ©ç”¨SNNçš„ä¸´æ—¶åŠ¨æ€ç‰¹æ€§ï¼ŒsnnTrans-DHZèƒ½å¤Ÿé«˜æ•ˆåœ°å¤„ç†æ—¶é—´ç›¸å…³çš„åŸå§‹å›¾åƒåºåˆ—ï¼ŒåŒæ—¶ä¿æŒä½åŠŸè€—ã€‚é¦–å…ˆï¼Œå°†é™æ€æ°´ä¸‹å›¾åƒè½¬æ¢ä¸ºæ—¶é—´ç›¸å…³çš„åºåˆ—ï¼Œç„¶åé€šè¿‡ç”¨æˆ·å®šä¹‰çš„æ—¶åºåå¤è¾“å…¥ç›¸åŒçš„å›¾åƒã€‚è¿™äº›RGBåºåˆ—éšåè¢«è½¬æ¢ä¸ºLABé¢œè‰²ç©ºé—´è¡¨ç¤ºå¹¶å¹¶è¡Œå¤„ç†ã€‚è¯¥æ¶æ„å…·æœ‰ä¸‰ä¸ªå…³é”®æ¨¡å—ï¼šï¼ˆiï¼‰ç‰¹å¾æå–å™¨Kï¼Œç”¨äºä»å¤šä¸ªé¢œè‰²ç©ºé—´è¡¨ç¤ºä¸­æå–ç‰¹å¾ï¼›ï¼ˆiiï¼‰èƒŒæ™¯å…‰ä¼°è®¡å™¨ï¼Œç”¨äºä»RGB-LABå›¾åƒä¸­è”åˆæ¨æ–­èƒŒæ™¯å…‰åˆ†é‡ï¼›ï¼ˆiiiï¼‰è½¯å›¾åƒé‡å»ºæ¨¡å—ï¼Œç”Ÿæˆæ— é›¾ã€æé«˜å¯è§åº¦çš„è¾“å‡ºã€‚snnTrans-DHZæ¨¡å‹ç›´æ¥ä½¿ç”¨æ›¿ä»£æ¢¯åº¦åŸºäºæ—¶é—´çš„åå‘ä¼ æ’­ï¼ˆBPTTï¼‰ç­–ç•¥å’Œæ–°é¢–çš„ç»„åˆæŸå¤±å‡½æ•°è¿›è¡Œè®­ç»ƒã€‚åœ¨UIEBåŸºå‡†æµ‹è¯•ä¸­ï¼ŒsnnTrans-DHZçš„PSNRè¾¾åˆ°21.68 dBï¼ŒSSIMä¸º0.8795ï¼›åœ¨EUVPæ•°æ®é›†ä¸Šï¼Œå…¶PSNRä¸º23.46 dBï¼ŒSSIMä¸º0.8439ã€‚è¯¥ç®—æ³•ä»…åŒ…å«0.5670ç™¾ä¸‡ä¸ªç½‘ç»œå‚æ•°ï¼Œéœ€è¦7.42 GSOPså’Œ0.0151 Jçš„èƒ½é‡ï¼Œåœ¨æ•ˆç‡ä¸Šæ˜¾è‘—ä¼˜äºç°æœ‰çš„æœ€æ–°æ–¹æ³•ã€‚è¿™äº›ç‰¹æ€§ä½¿snnTrans-DHZéå¸¸é€‚åˆç”¨äºæ°´ä¸‹æœºå™¨äººã€æµ·æ´‹å‹˜æ¢å’Œç¯å¢ƒç›‘æµ‹ã€‚</p>
<p><strong>è¦ç‚¹è§£æ</strong></p>
<ol>
<li>æ°´ä¸‹å›¾åƒå»é›¾å¯¹äºåŸºäºè§†è§‰çš„æµ·æ´‹æ“ä½œè‡³å…³é‡è¦ï¼Œå› ä¸ºå…‰çš„æ•£å°„å’Œå¸æ”¶ä¸¥é‡å½±å“èƒ½è§åº¦ã€‚</li>
<li>snnTrans-DHZæ˜¯ä¸€ä¸ªåŸºäºè„‰å†²ç¥ç»ç½‘ç»œï¼ˆSNNï¼‰çš„æ°´ä¸‹å›¾åƒå»é›¾æ¨¡å‹ã€‚</li>
<li>snnTrans-DHZèƒ½å¤Ÿå¤„ç†æ—¶é—´ç›¸å…³çš„åŸå§‹å›¾åƒåºåˆ—ï¼ŒåŒæ—¶å…·æœ‰ä½åŠŸè€—çš„ç‰¹æ€§ã€‚</li>
<li>è¯¥æ¨¡å‹é€šè¿‡å°†é™æ€æ°´ä¸‹å›¾åƒè½¬æ¢ä¸ºæ—¶é—´ç›¸å…³çš„åºåˆ—æ¥è¿›è¡Œå¤„ç†ã€‚</li>
<li>æ¨¡å‹æ¶æ„åŒ…å«ä¸‰ä¸ªå…³é”®æ¨¡å—ï¼šç‰¹å¾æå–ã€èƒŒæ™¯å…‰ä¼°è®¡å’Œè½¯å›¾åƒé‡å»ºã€‚</li>
<li>snnTrans-DHZåœ¨æ•ˆç‡ä¸Šä¼˜äºå…¶ä»–ç°æœ‰æ–¹æ³•ï¼Œå…·æœ‰è¾ƒä½çš„ç½‘ç»œå‚æ•°å’Œèƒ½é‡éœ€æ±‚ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.11482">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-a69279f6cb3a9dcc9d5a5f9776d208ca.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a1a4eae3f7ffb91aa3ae60cfa9a13191.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a5298f29cd065bb673e910f75d6ffefd.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-62b7a1d1455bb21bc7118a96cf21c1f8.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-e3ae8a5b617ea9623355ca5f9d442807.jpg" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1><h2 id="Shuffled-Linear-Regression-via-Spectral-Matching"><a href="#Shuffled-Linear-Regression-via-Spectral-Matching" class="headerlink" title="Shuffled Linear Regression via Spectral Matching"></a>Shuffled Linear Regression via Spectral Matching</h2><p><strong>Authors:Hang Liu, Anna Scaglione</strong></p>
<p>Shuffled linear regression (SLR) seeks to estimate latent features through a linear transformation, complicated by unknown permutations in the measurement dimensions. This problem extends traditional least-squares (LS) and Least Absolute Shrinkage and Selection Operator (LASSO) approaches by jointly estimating the permutation, resulting in shuffled LS and shuffled LASSO formulations. Existing methods, constrained by the combinatorial complexity of permutation recovery, often address small-scale cases with limited measurements. In contrast, we focus on large-scale SLR, particularly suited for environments with abundant measurement samples. We propose a spectral matching method that efficiently resolves permutations by aligning spectral components of the measurement and feature covariances. Rigorous theoretical analyses demonstrate that our method achieves accurate estimates in both shuffled LS and shuffled LASSO settings, given a sufficient number of samples. Furthermore, we extend our approach to address simultaneous pose and correspondence estimation in image registration tasks. Experiments on synthetic datasets and real-world image registration scenarios show that our method outperforms existing algorithms in both estimation accuracy and registration performance. </p>
<blockquote>
<p>æ‰“ä¹±çº¿æ€§å›å½’ï¼ˆSLRï¼‰è¯•å›¾é€šè¿‡çº¿æ€§å˜æ¢ä¼°è®¡æ½œåœ¨ç‰¹å¾ï¼Œä½†æµ‹é‡ç»´åº¦çš„æœªçŸ¥æ’åˆ—å¢åŠ äº†å…¶å¤æ‚æ€§ã€‚è¿™ä¸€é—®é¢˜é€šè¿‡è”åˆä¼°è®¡æ’åˆ—æ‰©å±•äº†ä¼ ç»Ÿçš„æœ€å°äºŒä¹˜ï¼ˆLSï¼‰å’Œæœ€å°ç»å¯¹æ”¶ç¼©å’Œé€‰æ‹©ç®—å­ï¼ˆLASSOï¼‰æ–¹æ³•ï¼Œäº§ç”Ÿäº†æ‰“ä¹±LSå’Œæ‰“ä¹±LASSOå…¬å¼ã€‚ç”±äºæ’åˆ—æ¢å¤çš„ç»„åˆå¤æ‚æ€§é™åˆ¶ï¼Œç°æœ‰æ–¹æ³•é€šå¸¸å¤„ç†æµ‹é‡æœ‰é™çš„å°è§„æ¨¡æ¡ˆä¾‹ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼Œæˆ‘ä»¬ä¸“æ³¨äºå¤§è§„æ¨¡SLRï¼Œå°¤å…¶é€‚ç”¨äºæµ‹é‡æ ·æœ¬ä¸°å¯Œçš„ç¯å¢ƒã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§è°±åŒ¹é…æ–¹æ³•ï¼Œé€šè¿‡å¯¹é½æµ‹é‡å’Œç‰¹å¾åæ–¹å·®è°±æˆåˆ†æ¥è§£å†³æ’åˆ—é—®é¢˜ã€‚ä¸¥æ ¼çš„ç†è®ºåˆ†æè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨å……è¶³çš„æ ·æœ¬ä¸‹ï¼Œåœ¨æ‰“ä¹±LSå’Œæ‰“ä¹±LASSOè®¾ç½®ä¸­éƒ½èƒ½å®ç°å‡†ç¡®çš„ä¼°è®¡ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å°†æˆ‘ä»¬çš„æ–¹æ³•æ‰©å±•åˆ°è§£å†³å›¾åƒé…å‡†ä»»åŠ¡ä¸­çš„å§¿æ€å’Œå¯¹åº”å…³ç³»ä¼°è®¡é—®é¢˜ã€‚åœ¨åˆæˆæ•°æ®é›†å’ŒçœŸå®ä¸–ç•Œå›¾åƒé…å‡†åœºæ™¯çš„å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨ä¼°è®¡å‡†ç¡®æ€§å’Œæ³¨å†Œæ€§èƒ½æ–¹é¢éƒ½ä¼˜äºç°æœ‰ç®—æ³•ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2410.00078v2">PDF</a> This work has been submitted to the IEEE for possible publication</p>
<p><strong>Summary</strong></p>
<p>é’ˆå¯¹æµ‹é‡ç»´åº¦ä¸­æœªçŸ¥æ’åˆ—çš„çº¿æ€§å›å½’é—®é¢˜ï¼Œæå‡ºè°±åŒ¹é…æ–¹æ³•æ¥è§£å†³å¤§è§„æ¨¡æ´—ç‰Œçº¿æ€§å›å½’ï¼ˆSLRï¼‰ã€‚è¯¥æ–¹æ³•é€šè¿‡å¯¹é½æµ‹é‡å’Œç‰¹å¾åæ–¹å·®è°±æˆåˆ†æ¥æœ‰æ•ˆè§£ææ’åˆ—é—®é¢˜ã€‚ç†è®ºåˆ†æè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨è¶³å¤Ÿæ ·æœ¬æ•°ä¸‹èƒ½åœ¨æ´—ç‰Œæœ€å°äºŒä¹˜ï¼ˆLSï¼‰å’Œæ´—ç‰ŒLASSOè®¾ç½®ä¸­å‡†ç¡®ä¼°è®¡ã€‚æ­¤å¤–ï¼Œå°†å…¶åº”ç”¨äºå›¾åƒæ³¨å†Œä»»åŠ¡ä¸­çš„å§¿æ€å’Œå¯¹åº”å…³ç³»ä¼°è®¡ã€‚åœ¨åˆæˆæ•°æ®é›†å’ŒçœŸå®ä¸–ç•Œå›¾åƒæ³¨å†Œåœºæ™¯çš„å®éªŒä¸­ï¼Œè¯¥æ–¹æ³•åœ¨ä¼°è®¡å‡†ç¡®æ€§å’Œæ³¨å†Œæ€§èƒ½æ–¹é¢ä¼˜äºç°æœ‰ç®—æ³•ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>SLRæ—¨åœ¨é€šè¿‡çº¿æ€§å˜æ¢ä¼°è®¡æ½œåœ¨ç‰¹å¾ï¼Œä½†é¢ä¸´æµ‹é‡ç»´åº¦ä¸­æœªçŸ¥æ’åˆ—çš„é—®é¢˜ã€‚</li>
<li>ç°æœ‰æ–¹æ³•ç”±äºæ’åˆ—æ¢å¤çš„ç»„åˆå¤æ‚æ€§ï¼Œé€šå¸¸åªå¤„ç†å°è§„æ¨¡æ¡ˆä¾‹ã€‚</li>
<li>æå‡ºè°±åŒ¹é…æ–¹æ³•ï¼Œé€šè¿‡å¯¹é½æµ‹é‡å’Œç‰¹å¾åæ–¹å·®çš„è°±æˆåˆ†æ¥æœ‰æ•ˆè§£å†³å¤§è§„æ¨¡SLRé—®é¢˜ã€‚</li>
<li>è°±åŒ¹é…æ–¹æ³•åœ¨ç†è®ºåˆ†æä¸­æ˜¾ç¤ºå‡ºåœ¨æ´—ç‰ŒLSå’Œæ´—ç‰ŒLASSOè®¾ç½®ä¸­çš„å‡†ç¡®ä¼°è®¡èƒ½åŠ›ã€‚</li>
<li>å°†è¯¥æ–¹æ³•æ‰©å±•åˆ°å›¾åƒæ³¨å†Œä»»åŠ¡ä¸­çš„å§¿æ€å’Œå¯¹åº”å…³ç³»ä¼°è®¡ã€‚</li>
<li>åœ¨åˆæˆæ•°æ®é›†å’ŒçœŸå®ä¸–ç•Œå›¾åƒæ³¨å†Œåœºæ™¯çš„å®éªŒä¸­ï¼Œè°±åŒ¹é…æ–¹æ³•è¡¨ç°ä¼˜äºç°æœ‰ç®—æ³•ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2410.00078">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-e1a129313c2a7392e748bfb2d2f9f017.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-cc699c618e34c9f658886f86b5b8b493.jpg" align="middle">
</details>


<h1 id="-9"><a href="#-9" class="headerlink" title=""></a></h1><h2 id="reBEN-Refined-BigEarthNet-Dataset-for-Remote-Sensing-Image-Analysis"><a href="#reBEN-Refined-BigEarthNet-Dataset-for-Remote-Sensing-Image-Analysis" class="headerlink" title="reBEN: Refined BigEarthNet Dataset for Remote Sensing Image Analysis"></a>reBEN: Refined BigEarthNet Dataset for Remote Sensing Image Analysis</h2><p><strong>Authors:Kai Norman Clasen, Leonard Hackel, Tom Burgert, Gencer Sumbul, BegÃ¼m Demir, Volker Markl</strong></p>
<p>This paper presents refined BigEarthNet (reBEN) that is a large-scale, multi-modal remote sensing dataset constructed to support deep learning (DL) studies for remote sensing image analysis. The reBEN dataset consists of 549,488 pairs of Sentinel-1 and Sentinel-2 image patches. To construct reBEN, we initially consider the Sentinel-1 and Sentinel-2 tiles used to construct the BigEarthNet dataset and then divide them into patches of size 1200 m x 1200 m. We apply atmospheric correction to the Sentinel-2 patches using the latest version of the sen2cor tool, resulting in higher-quality patches compared to those present in BigEarthNet. Each patch is then associated with a pixel-level reference map and scene-level multi-labels. This makes reBEN suitable for pixel- and scene-based learning tasks. The labels are derived from the most recent CORINE Land Cover (CLC) map of 2018 by utilizing the 19-class nomenclature as in BigEarthNet. The use of the most recent CLC map results in overcoming the label noise present in BigEarthNet. Furthermore, we introduce a new geographical-based split assignment algorithm that significantly reduces the spatial correlation among the train, validation, and test sets with respect to those present in BigEarthNet. This increases the reliability of the evaluation of DL models. To minimize the DL model training time, we introduce software tools that convert the reBEN dataset into a DL-optimized data format. In our experiments, we show the potential of reBEN for multi-modal multi-label image classification problems by considering several state-of-the-art DL models. The pre-trained model weights, associated code, and complete dataset are available at <a target="_blank" rel="noopener" href="https://bigearth.net/">https://bigearth.net</a>. </p>
<blockquote>
<p>æœ¬æ–‡ä»‹ç»äº†ç²¾ç»†åŒ–çš„BigEarthNetï¼ˆreBENï¼‰ï¼Œè¿™æ˜¯ä¸€ä¸ªä¸ºæ”¯æŒé¥æ„Ÿå›¾åƒåˆ†æçš„æ·±åº¦å­¦ä¹ ï¼ˆDLï¼‰ç ”ç©¶è€Œæ„å»ºçš„å¤§è§„æ¨¡ã€å¤šæ¨¡æ€é¥æ„Ÿæ•°æ®é›†ã€‚reBENæ•°æ®é›†åŒ…å«549,488å¯¹Sentinel-1å’ŒSentinel-2å›¾åƒè¡¥ä¸ã€‚ä¸ºäº†æ„å»ºreBENï¼Œæˆ‘ä»¬é¦–å…ˆè€ƒè™‘äº†ç”¨äºæ„å»ºBigEarthNetæ•°æ®é›†çš„Sentinel-1å’ŒSentinel-2ç“¦ç‰‡ï¼Œç„¶åå°†å…¶åˆ’åˆ†ä¸ºå¤§å°ä¸º1200ç±³x 1200ç±³çš„è¡¥ä¸ã€‚æˆ‘ä»¬å¯¹Sentinel-2è¡¥ä¸åº”ç”¨äº†ä½¿ç”¨sen2corå·¥å…·æœ€æ–°ç‰ˆæœ¬çš„å¤§æ°”æ ¡æ­£ï¼Œä¸BigEarthNetä¸­ç°æœ‰çš„è¡¥ä¸ç›¸æ¯”ï¼Œè¿™äº§ç”Ÿäº†æ›´é«˜è´¨é‡çš„è¡¥ä¸ã€‚ç„¶åï¼Œæ¯ä¸ªè¡¥ä¸éƒ½ä¸åƒç´ çº§å‚è€ƒå›¾å’Œåœºæ™¯çº§å¤šæ ‡ç­¾ç›¸å…³è”ã€‚è¿™ä½¿å¾—reBENé€‚åˆåŸºäºåƒç´ å’Œåœºæ™¯çš„å­¦ä¹ ä»»åŠ¡ã€‚æ ‡ç­¾æ˜¯é€šè¿‡ä½¿ç”¨ä¸BigEarthNetç›¸åŒçš„19ç±»å‘½åæ³•ï¼Œä»æœ€æ–°çš„2018å¹´CORINEåœŸåœ°è¦†ç›–ï¼ˆCLCï¼‰åœ°å›¾ä¸­å¾—å‡ºçš„ã€‚ä½¿ç”¨æœ€æ–°çš„CLCåœ°å›¾å…‹æœäº†BigEarthNetä¸­å­˜åœ¨çš„æ ‡ç­¾å™ªå£°ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§æ–°çš„åŸºäºåœ°ç†çš„åˆ†å‰²åˆ†é…ç®—æ³•ï¼Œè¯¥ç®—æ³•æ˜¾è‘—å‡å°‘äº†è®­ç»ƒé›†ã€éªŒè¯é›†å’Œæµ‹è¯•é›†ä¹‹é—´çš„ç©ºé—´ç›¸å…³æ€§ï¼Œä¸BigEarthNetä¸­çš„æƒ…å†µç›¸æ¯”ï¼Œè¿™å¢åŠ äº†æ·±åº¦å­¦ä¹ æ¨¡å‹è¯„ä¼°çš„å¯é æ€§ã€‚ä¸ºäº†æœ€å°åŒ–æ·±åº¦å­¦ä¹ æ¨¡å‹è®­ç»ƒæ—¶é—´ï¼Œæˆ‘ä»¬å¼•å…¥äº†å°†reBENæ•°æ®é›†è½¬æ¢ä¸ºæ·±åº¦å­¦ä¹ ä¼˜åŒ–æ•°æ®æ ¼å¼çš„è½¯ä»¶å·¥å…·ã€‚åœ¨æˆ‘ä»¬çš„å®éªŒä¸­ï¼Œæˆ‘ä»¬é€šè¿‡è€ƒè™‘ä¸€äº›æœ€å…ˆè¿›çš„æ·±åº¦å­¦ä¹ æ¨¡å‹ï¼Œå±•ç¤ºäº†reBENåœ¨å¤šæ¨¡æ€å¤šæ ‡ç­¾å›¾åƒåˆ†ç±»é—®é¢˜ä¸Šçš„æ½œåŠ›ã€‚é¢„è®­ç»ƒæ¨¡å‹æƒé‡ã€ç›¸å…³ä»£ç å’Œå®Œæ•´æ•°æ®é›†å¯åœ¨<a target="_blank" rel="noopener" href="https://bigearth.netä¸Šæ‰¾åˆ°./">https://bigearth.netä¸Šæ‰¾åˆ°ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2407.03653v4">PDF</a> Accepted at IEEE International Geoscience and Remote Sensing   Symposium (IGARSS) 2025. Our code is available at   <a target="_blank" rel="noopener" href="https://github.com/rsim-tu-berlin/bigearthnet-pipeline">https://github.com/rsim-tu-berlin/bigearthnet-pipeline</a></p>
<p><strong>æ‘˜è¦</strong></p>
<p>æœ¬è®ºæ–‡æ¨å‡ºç²¾ç»†åŒ–BigEarthNetï¼ˆreBENï¼‰ï¼Œè¿™æ˜¯ä¸€å¥—å¤§å‹ã€å¤šæ¨¡æ€é¥æ„Ÿæ•°æ®é›†ï¼Œä¸“ä¸ºæ”¯æŒé¥æ„Ÿå›¾åƒåˆ†æçš„æ·±åº¦å­¦ä¹ ç ”ç©¶è€Œæ„å»ºã€‚reBENæ•°æ®é›†åŒ…å«549488å¯¹Sentinel-1å’ŒSentinel-2å›¾åƒå—ã€‚reBENçš„æ„å»ºæ˜¯åœ¨BigEarthNetæ•°æ®é›†ä½¿ç”¨çš„Sentinel-1å’ŒSentinel-2ç“¦ç‰‡åŸºç¡€ä¸Šï¼Œå°†å…¶åˆ’åˆ†ä¸ºå¤§å°ä¸º1200mx1200mçš„å—ã€‚æˆ‘ä»¬å¯¹Sentinel-2å—åº”ç”¨å¤§æ°”æ ¡æ­£ï¼Œä½¿ç”¨æœ€æ–°ç‰ˆæœ¬çš„sen2corå·¥å…·ï¼Œå¾—åˆ°æ¯”BigEarthNetä¸­æ›´é«˜çš„è´¨é‡å—ã€‚æ¯ä¸ªå—éƒ½ä¸åƒç´ çº§å‚è€ƒåœ°å›¾å’Œåœºæ™¯çº§å¤šæ ‡ç­¾ç›¸å…³è”ï¼Œä½¿reBENé€‚åˆåŸºäºåƒç´ å’Œåœºæ™¯çš„å­¦ä¹ ä»»åŠ¡ã€‚æ ‡ç­¾æ˜¯é€šè¿‡åˆ©ç”¨æœ€æ–°çš„2018å¹´CORINEåœŸåœ°è¦†ç›–å›¾ï¼ˆCLCåœ°å›¾ï¼‰ä»¥åŠBigEarthNetä¸­çš„19ç±»å‘½åæ³•å¾—å‡ºçš„ï¼Œä»è€Œå…‹æœäº†BigEarthNetä¸­å­˜åœ¨çš„æ ‡ç­¾å™ªå£°é—®é¢˜ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§æ–°çš„åŸºäºåœ°ç†çš„åˆ†å‰²åˆ†é…ç®—æ³•ï¼Œè¯¥ç®—æ³•æ˜¾è‘—é™ä½äº†è®­ç»ƒé›†ã€éªŒè¯é›†å’Œæµ‹è¯•é›†ä¹‹é—´çš„ç©ºé—´ç›¸å…³æ€§ï¼Œæé«˜äº†æ·±åº¦å­¦ä¹ æ¨¡å‹è¯„ä¼°çš„å¯é æ€§ã€‚ä¸ºäº†ç¼©çŸ­æ·±åº¦å­¦ä¹ æ¨¡å‹çš„è®­ç»ƒæ—¶é—´ï¼Œæˆ‘ä»¬å¼•å…¥äº†å°†reBENæ•°æ®é›†è½¬æ¢ä¸ºæ·±åº¦å­¦ä¹ ä¼˜åŒ–æ•°æ®æ ¼å¼çš„è½¯ä»¶å·¥å…·ã€‚åœ¨å®éªŒéƒ¨åˆ†ï¼Œæˆ‘ä»¬é€šè¿‡è€ƒè™‘ä¸€äº›å…ˆè¿›çš„æ·±åº¦å­¦ä¹ æ¨¡å‹ï¼Œå±•ç¤ºäº†reBENåœ¨å¤šæ¨¡æ€å¤šæ ‡ç­¾å›¾åƒåˆ†ç±»é—®é¢˜ä¸Šçš„æ½œåŠ›ã€‚é¢„è®­ç»ƒæ¨¡å‹æƒé‡ã€ç›¸å…³ä»£ç å’Œå®Œæ•´æ•°æ®é›†å¯åœ¨<a target="_blank" rel="noopener" href="https://bigearth.net/">https://bigearth.net</a>è·å–ã€‚</p>
<p><strong>å…³é”®è§è§£</strong></p>
<ol>
<li>reBENæ˜¯ä¸€ä¸ªå¤§å‹ã€å¤šæ¨¡æ€çš„é¥æ„Ÿæ•°æ®é›†ï¼Œç”¨äºæ”¯æŒæ·±åº¦å­¦ä¹ åœ¨é¥æ„Ÿå›¾åƒåˆ†æé¢†åŸŸçš„ç ”ç©¶ã€‚</li>
<li>reBENåŒ…å«ç»è¿‡å¤§æ°”æ ¡æ­£çš„é«˜è´¨é‡Sentinel-1å’ŒSentinel-2å›¾åƒå—ï¼Œé€‚åˆåƒç´ å’Œåœºæ™¯çº§å­¦ä¹ ä»»åŠ¡ã€‚</li>
<li>åˆ©ç”¨æœ€æ–°çš„CORINEåœŸåœ°è¦†ç›–å›¾ï¼ˆCLCåœ°å›¾ï¼‰æ¥å…‹æœBigEarthNetä¸­çš„æ ‡ç­¾å™ªå£°é—®é¢˜ã€‚</li>
<li>å¼•å…¥æ–°çš„åœ°ç†åˆ†å‰²åˆ†é…ç®—æ³•ï¼Œé™ä½æ•°æ®é›†çš„ç©ºé—´ç›¸å…³æ€§ï¼Œæé«˜æ·±åº¦å­¦ä¹ æ¨¡å‹è¯„ä¼°çš„å¯é æ€§ã€‚</li>
<li>æä¾›è½¯ä»¶å·¥å…·å°†reBENæ•°æ®é›†è½¬æ¢ä¸ºæ·±åº¦å­¦ä¹ ä¼˜åŒ–æ•°æ®æ ¼å¼ï¼Œç¼©çŸ­æ¨¡å‹è®­ç»ƒæ—¶é—´ã€‚</li>
<li>é€šè¿‡å®éªŒå±•ç¤ºreBENåœ¨å¤šæ¨¡æ€å¤šæ ‡ç­¾å›¾åƒåˆ†ç±»é—®é¢˜ä¸Šçš„æ½œåŠ›ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2407.03653">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-92970a01238c43ca2dd6f3598cb348fa.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-80c3481a01281067a3e2b2d96adf9c9f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-5907d632d449e0b3f3852416e0868bf2.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-15cf0faee643cbfa1cbb75a0357ff760.jpg" align="middle">
</details>


<h1 id="-10"><a href="#-10" class="headerlink" title=""></a></h1><h2 id="Quantum-Generative-Learning-for-High-Resolution-Medical-Image-Generation"><a href="#Quantum-Generative-Learning-for-High-Resolution-Medical-Image-Generation" class="headerlink" title="Quantum Generative Learning for High-Resolution Medical Image Generation"></a>Quantum Generative Learning for High-Resolution Medical Image Generation</h2><p><strong>Authors:Amena Khatun, KÃ¼bra Yeter Aydeniz, Yaakov S. Weinstein, Muhammad Usman</strong></p>
<p>Integration of quantum computing in generative machine learning models has the potential to offer benefits such as training speed-up and superior feature extraction. However, the existing quantum generative adversarial networks (QGANs) fail to generate high-quality images due to their patch-based, pixel-wise learning approaches. These methods capture only local details, ignoring the global structure and semantic information of images. In this work, we address these challenges by proposing a quantum image generative learning (QIGL) approach for high-quality medical image generation. Our proposed quantum generator leverages variational quantum circuit approach addressing scalability issues by extracting principal components from the images instead of dividing them into patches. Additionally, we integrate the Wasserstein distance within the QIGL framework to generate a diverse set of medical samples. Through a systematic set of simulations on X-ray images from knee osteoarthritis and medical MNIST datasets, our model demonstrates superior performance, achieving the lowest Fr&#39;echet Inception Distance (FID) scores compared to its classical counterpart and advanced QGAN models reported in the literature. </p>
<blockquote>
<p>å°†é‡å­è®¡ç®—é›†æˆåˆ°ç”Ÿæˆå¼æœºå™¨å­¦ä¹ æ¨¡å‹ä¸­ï¼Œæœ‰å¯èƒ½å¸¦æ¥è®­ç»ƒåŠ é€Ÿå’Œå“è¶Šçš„ç‰¹å¾æå–ç­‰å¥½å¤„ã€‚ç„¶è€Œï¼Œç°æœ‰çš„é‡å­ç”Ÿæˆå¯¹æŠ—ç½‘ç»œï¼ˆQGANsï¼‰ç”±äºé‡‡ç”¨åŸºäºè¡¥ä¸çš„é€åƒç´ å­¦ä¹ æ–¹æ³•ï¼Œæ— æ³•ç”Ÿæˆé«˜è´¨é‡å›¾åƒã€‚è¿™äº›æ–¹æ³•åªèƒ½æ•æ‰å±€éƒ¨ç»†èŠ‚ï¼Œå¿½ç•¥äº†å›¾åƒçš„å…¨å±€ç»“æ„å’Œè¯­ä¹‰ä¿¡æ¯ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬é€šè¿‡æå‡ºä¸€ç§ç”¨äºé«˜è´¨é‡åŒ»å­¦å›¾åƒç”Ÿæˆçš„é‡å­å›¾åƒç”Ÿæˆå­¦ä¹ ï¼ˆQIGLï¼‰æ–¹æ³•æ¥è§£å†³è¿™äº›æŒ‘æˆ˜ã€‚æˆ‘ä»¬æå‡ºçš„é‡å­ç”Ÿæˆå™¨åˆ©ç”¨å˜åˆ†é‡å­ç”µè·¯æ–¹æ³•ï¼Œé€šè¿‡ä»å›¾åƒä¸­æå–ä¸»æˆåˆ†è€Œä¸æ˜¯å°†å…¶åˆ†æˆè¡¥ä¸æ¥è§£å†³å¯æ‰©å±•æ€§é—®é¢˜ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬åœ¨QIGLæ¡†æ¶ä¸­é›†æˆäº†Wassersteinè·ç¦»ï¼Œä»¥ç”Ÿæˆå¤šæ ·åŒ–çš„åŒ»å­¦æ ·æœ¬é›†ã€‚é€šè¿‡å¯¹æ¥è‡ªè†å…³èŠ‚éª¨å…³èŠ‚ç‚çš„Xå°„çº¿å›¾åƒå’ŒåŒ»å­¦MNISTæ•°æ®é›†çš„ç³»ç»Ÿæ¨¡æ‹Ÿï¼Œæˆ‘ä»¬çš„æ¨¡å‹è¡¨ç°å‡ºå“è¶Šçš„æ€§èƒ½ï¼Œå®ç°äº†ä¸ç»å…¸æ¨¡å‹å’Œæ–‡çŒ®ä¸­æŠ¥é“çš„é«˜çº§QGANæ¨¡å‹ç›¸æ¯”æœ€ä½çš„FrÃ©chetå…¥é—¨è·ç¦»ï¼ˆFIDï¼‰å¾—åˆ†ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2406.13196v2">PDF</a> </p>
<p><strong>Summary</strong><br>é‡å­è®¡ç®—é›†æˆåœ¨ç”Ÿæˆå¼æœºå™¨å­¦ä¹ æ¨¡å‹ä¸­ï¼Œå…·æœ‰è®­ç»ƒåŠ é€Ÿå’Œå“è¶Šç‰¹å¾æå–çš„æ½œåŠ›ã€‚ç„¶è€Œï¼Œç°æœ‰çš„é‡å­ç”Ÿæˆå¯¹æŠ—ç½‘ç»œï¼ˆQGANsï¼‰ç”±äºé‡‡ç”¨åŸºäºè¡¥ä¸çš„åƒç´ çº§å­¦ä¹ æ–¹æ³•ï¼Œæ— æ³•ç”Ÿæˆé«˜è´¨é‡å›¾åƒã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§é’ˆå¯¹é«˜è´¨é‡åŒ»å­¦å›¾åƒç”Ÿæˆçš„é‡å­å›¾åƒç”Ÿæˆå­¦ä¹ ï¼ˆQIGLï¼‰æ–¹æ³•ï¼Œåˆ©ç”¨å˜åˆ†é‡å­ç”µè·¯è§£å†³å¯æ‰©å±•æ€§é—®é¢˜ï¼Œä»å›¾åƒä¸­æå–ä¸»æˆåˆ†è€Œä¸æ˜¯å°†å…¶åˆ†æˆè¡¥ä¸ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬åœ¨QIGLæ¡†æ¶ä¸­é›†æˆäº†Wassersteinè·ç¦»ï¼Œä»¥ç”Ÿæˆå¤šæ ·åŒ–çš„åŒ»å­¦æ ·æœ¬ã€‚é€šè¿‡ä¸€ç³»åˆ—é’ˆå¯¹è†éª¨å…³èŠ‚ç‚Xå°„çº¿å’ŒåŒ»å­¦MNISTæ•°æ®é›†çš„æ¨¡æ‹Ÿï¼Œæˆ‘ä»¬çš„æ¨¡å‹è¡¨ç°å‡ºå“è¶Šæ€§èƒ½ï¼Œå®ç°äº†ä¸ç»å…¸æ¨¡å‹å’Œæ–‡çŒ®ä¸­æŠ¥é“çš„é«˜çº§QGANæ¨¡å‹ç›¸æ¯”æœ€ä½çš„FrÃ©chetå…¥é—¨è·ç¦»ï¼ˆFIDï¼‰å¾—åˆ†ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>é‡å­è®¡ç®—é›†æˆåœ¨ç”Ÿæˆå¼æœºå™¨å­¦ä¹ æ¨¡å‹ä¸­å¯æé«˜è®­ç»ƒé€Ÿåº¦å’Œç‰¹å¾æå–è´¨é‡ã€‚</li>
<li>ç°æœ‰QGANså› é‡‡ç”¨åŸºäºè¡¥ä¸çš„åƒç´ çº§å­¦ä¹ æ–¹æ³•ï¼Œæ— æ³•ç”Ÿæˆé«˜è´¨é‡å›¾åƒã€‚</li>
<li>æå‡ºçš„QIGLæ–¹æ³•åˆ©ç”¨å˜åˆ†é‡å­ç”µè·¯è§£å†³å¯æ‰©å±•æ€§é—®é¢˜ã€‚</li>
<li>QIGLæ–¹æ³•ä»å›¾åƒä¸­æå–ä¸»æˆåˆ†è€Œéåˆ†å‰²æˆè¡¥ä¸ï¼Œä»¥æé«˜å›¾åƒè´¨é‡ã€‚</li>
<li>QIGLæ¡†æ¶é›†æˆäº†Wassersteinè·ç¦»ï¼Œä»¥ç”Ÿæˆå¤šæ ·åŒ–çš„åŒ»å­¦æ ·æœ¬ã€‚</li>
<li>æ¨¡æ‹Ÿå®éªŒè¡¨æ˜ï¼ŒQIGLæ¨¡å‹åœ¨ç”Ÿæˆé«˜è´¨é‡åŒ»å­¦å›¾åƒæ–¹é¢è¡¨ç°å“è¶Šã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2406.13196">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-7a6461ef613ca25f396210aa20497b57.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-0b66b1ffefef3f05fe5795d3be40c253.jpg" align="middle">
</details>


<h1 id="-11"><a href="#-11" class="headerlink" title=""></a></h1><h2 id="Multi-modal-vision-language-model-for-generalizable-annotation-free-pathology-localization-and-clinical-diagnosis"><a href="#Multi-modal-vision-language-model-for-generalizable-annotation-free-pathology-localization-and-clinical-diagnosis" class="headerlink" title="Multi-modal vision-language model for generalizable annotation-free   pathology localization and clinical diagnosis"></a>Multi-modal vision-language model for generalizable annotation-free   pathology localization and clinical diagnosis</h2><p><strong>Authors:Hao Yang, Hong-Yu Zhou, Jiarun Liu, Weijian Huang, Zhihuan Li, Yuanxu Gao, Cheng Li, Qiegen Liu, Yong Liang, Qi Yang, Song Wu, Tao Tan, Hairong Zheng, Kang Zhang, Shanshan Wang</strong></p>
<p>Defining pathologies automatically from medical images aids the understanding of the emergence and progression of diseases, and such an ability is crucial in clinical diagnostics. However, existing deep learning models heavily rely on expert annotations and lack generalization capabilities in open clinical environments. In this study, we present a generalizable vision-language model for Annotation-Free pathology Localization (AFLoc). The core strength of AFLoc lies in its extensive multi-level semantic structure-based contrastive learning, which comprehensively aligns multi-granularity medical concepts from reports with abundant image features, to adapt to the diverse expressions of pathologies and unseen pathologies without the reliance on image annotations from experts. We conducted primary experiments on a dataset of 220K pairs of image-report chest X-ray images, and performed extensive validation across six external datasets encompassing 20 types of chest pathologies. The results demonstrate that AFLoc outperforms state-of-the-art methods in both annotation-free localization and classification tasks. Additionally, we assessed the generalizability of AFLoc on other modalities, including histopathology and retinal fundus images. Extensive experiments show that AFLoc exhibits robust generalization capabilities, even surpassing human benchmarks in localizing five different types of pathological images. These results highlight the potential of AFLoc in reducing annotation requirements and its applicability in complex clinical environments. </p>
<blockquote>
<p>ä»åŒ»å­¦å›¾åƒä¸­è‡ªåŠ¨å®šä¹‰ç—…ç†æœ‰åŠ©äºäº†è§£ç–¾ç—…çš„å‡ºç°å’Œè¿›å±•ï¼Œè¿™ç§èƒ½åŠ›åœ¨ä¸´åºŠè¯Šæ–­ä¸­è‡³å…³é‡è¦ã€‚ç„¶è€Œï¼Œç°æœ‰çš„æ·±åº¦å­¦ä¹ æ¨¡å‹ä¸¥é‡ä¾èµ–äºä¸“å®¶æ³¨é‡Šï¼Œç¼ºä¹å¼€æ”¾ä¸´åºŠç¯å¢ƒä¸­çš„æ³›åŒ–èƒ½åŠ›ã€‚åœ¨è¿™é¡¹ç ”ç©¶ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§é€šç”¨çš„è§†è§‰è¯­è¨€æ¨¡å‹ï¼Œç”¨äºæ— æ³¨é‡Šç—…ç†å®šä½ï¼ˆAFLocï¼‰ã€‚AFLocçš„æ ¸å¿ƒä¼˜åŠ¿åœ¨äºå…¶åŸºäºå¤šå±‚æ¬¡è¯­ä¹‰ç»“æ„çš„å¯¹æ¯”å­¦ä¹ ï¼Œè¯¥æ–¹æ³•å…¨é¢åœ°å¯¹é½æŠ¥å‘Šä¸­çš„å¤šç²’åº¦åŒ»å­¦æ¦‚å¿µä¸ä¸°å¯Œçš„å›¾åƒç‰¹å¾ï¼Œä»¥é€‚åº”å„ç§ç—…ç†è¡¨è¾¾å’Œæœªè§è¿‡çš„ç—…ç†ï¼Œæ— éœ€ä¾èµ–ä¸“å®¶çš„å›¾åƒæ³¨é‡Šã€‚æˆ‘ä»¬åœ¨ä¸€ç»„åŒ…å«22ä¸‡å¯¹å›¾åƒæŠ¥å‘Šèƒ¸éƒ¨Xå°„çº¿å›¾åƒçš„æ•°æ®é›†ä¸Šè¿›è¡Œäº†åˆæ­¥å®éªŒï¼Œå¹¶åœ¨åŒ…å«20ç§èƒ¸éƒ¨ç—…ç†çš„å…­ä¸ªå¤–éƒ¨æ•°æ®é›†ä¸Šè¿›è¡Œäº†å¹¿æ³›éªŒè¯ã€‚ç»“æœè¡¨æ˜ï¼ŒAFLocåœ¨æ— éœ€æ³¨é‡Šçš„å®šä½å’Œåˆ†ç±»ä»»åŠ¡ä¸Šå‡ä¼˜äºæœ€å…ˆè¿›çš„æ–¹æ³•ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜è¯„ä¼°äº†AFLocåœ¨å…¶ä»–æ¨¡æ€ï¼ˆåŒ…æ‹¬ç»„ç»‡ç—…ç†å­¦å’Œçœ¼åº•è§†ç½‘è†œå›¾åƒï¼‰ä¸Šçš„æ³›åŒ–èƒ½åŠ›ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼ŒAFLocè¡¨ç°å‡ºç¨³å¥çš„æ³›åŒ–èƒ½åŠ›ï¼Œç”šè‡³åœ¨å®šä½äº”ç§ä¸åŒç±»å‹çš„ç—…ç†å›¾åƒæ—¶è¶…è¶Šäº†äººç±»åŸºå‡†æµ‹è¯•ã€‚è¿™äº›ç»“æœçªå‡ºäº†AFLocåœ¨å‡å°‘æ³¨é‡Šè¦æ±‚åŠå…¶åœ¨å¤æ‚ä¸´åºŠç¯å¢ƒä¸­çš„é€‚ç”¨æ€§æ–¹é¢çš„æ½œåŠ›ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2401.02044v5">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†ä¸€ç§æ— éœ€æ ‡æ³¨çš„è‡ªåŠ¨ç—…ç†å®šä½æ¨¡å‹ï¼ˆAFLocï¼‰ï¼Œè¯¥æ¨¡å‹åŸºäºå¤šå±‚æ¬¡è¯­ä¹‰ç»“æ„å¯¹æ¯”å­¦ä¹ ï¼Œèƒ½å¤Ÿä»åŒ»å­¦å›¾åƒä¸­è¯†åˆ«å‡ºç—…ç†ç‰¹å¾ï¼Œæ— éœ€ä¸“å®¶æ ‡æ³¨ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒAFLocåœ¨æ— éœ€æ ‡æ³¨çš„å®šä½å’Œåˆ†ç±»ä»»åŠ¡ä¸Šå‡è¡¨ç°å‡ºå“è¶Šæ€§èƒ½ï¼Œå¹¶åœ¨å¤šç§æ¨¡æ€å›¾åƒä¸­å±•ç°å‡ºå¼ºå¤§çš„æ³›åŒ–èƒ½åŠ›ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>AFLocæ¨¡å‹åˆ©ç”¨å¤šå±‚æ¬¡è¯­ä¹‰ç»“æ„å¯¹æ¯”å­¦ä¹ ï¼Œå®ç°å¯¹åŒ»å­¦å›¾åƒä¸­ç—…ç†ç‰¹å¾çš„è‡ªåŠ¨è¯†åˆ«å’Œå®šä½ã€‚</li>
<li>è¯¥æ¨¡å‹æ— éœ€ä¸“å®¶æ ‡æ³¨ï¼Œèƒ½å¤Ÿè‡ªé€‚åº”ä¸åŒçš„ç—…ç†è¡¨è¾¾å½¢å¼ï¼Œå¹¶å¯¹æœªè§è¿‡çš„ç—…ç†æƒ…å†µè¿›è¡Œè¯†åˆ«ã€‚</li>
<li>å®éªŒç»“æœæ˜¾ç¤ºï¼ŒAFLocåœ¨èƒ¸éƒ¨ä½Xå…‰å›¾åƒçš„æ•°æ®é›†ä¸Šè¡¨ç°å‡ºå“è¶Šæ€§èƒ½ã€‚</li>
<li>AFLocåœ¨å…­ç§å¤–éƒ¨æ•°æ®é›†ã€æ¶µç›–20ç§èƒ¸éƒ¨ç—…ç†ç±»å‹çš„å¹¿æ³›éªŒè¯ä¸­ï¼Œä»è¡¨ç°å‡ºå¼ºå¤§çš„æ€§èƒ½ã€‚</li>
<li>AFLocåœ¨å…¶ä»–æ¨¡æ€å›¾åƒï¼ˆå¦‚ç»„ç»‡ç—…ç†å­¦å’Œè§†ç½‘è†œåŸºé‡‘å›¾åƒï¼‰ä¸­ä¹Ÿå±•ç°å‡ºè‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›ã€‚</li>
<li>AFLocåœ¨å®šä½äº”ç§ä¸åŒç±»å‹çš„ç—…ç†å›¾åƒæ—¶ï¼Œç”šè‡³è¶…è¶Šäº†äººç±»åŸºå‡†æµ‹è¯•çš„è¡¨ç°ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2401.02044">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-4a7fe48d1414b9be419cd4a21bf26b3a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f39818f487dc8d287d715381ba0109d8.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-45e1736a8bf432f91c5d981c918d4638.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-c6d7fdee7d5e0bda27fb0be12a28de1e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-eb79f3b1b791b4b8228dbfd0238a7ad1.jpg" align="middle">
</details>


<h1 id="-12"><a href="#-12" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-04-18/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/">https://kedreamix.github.io/Talk2Paper/Paper/2025-04-18/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/">
                                    <span class="chip bg-color">åŒ»å­¦å›¾åƒ</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-04-19/R1_Reasoning/">
                    <div class="card-image">
                        
                        <img src="https://pic1.zhimg.com/v2-a5ff509c118576b1dfc2567ebf0bef75.jpg" class="responsive-img" alt="R1_Reasoning">
                        
                        <span class="card-title">R1_Reasoning</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            R1_Reasoning æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-04-19  SkyReels-V2 Infinite-length Film Generative Model
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-04-19
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/R1-Reasoning/" class="post-category">
                                    R1_Reasoning
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/R1-Reasoning/">
                        <span class="chip bg-color">R1_Reasoning</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-04-18/%E7%89%99%E9%BD%BF%E4%BF%AE%E5%A4%8D/">
                    <div class="card-image">
                        
                        <img src="https://pica.zhimg.com/v2-316b6273e319ef222f2c5f5ca1700806.jpg" class="responsive-img" alt="ç‰™é½¿ä¿®å¤">
                        
                        <span class="card-title">ç‰™é½¿ä¿®å¤</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            ç‰™é½¿ä¿®å¤ æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-04-18  Cross-Frequency Collaborative Training Network and Dataset for   Semi-supervised First Molar Root Canal Segmentation
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-04-18
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/%E7%89%99%E9%BD%BF%E4%BF%AE%E5%A4%8D/" class="post-category">
                                    ç‰™é½¿ä¿®å¤
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/%E7%89%99%E9%BD%BF%E4%BF%AE%E5%A4%8D/">
                        <span class="chip bg-color">ç‰™é½¿ä¿®å¤</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">28879.4k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
