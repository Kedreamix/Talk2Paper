<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Agent">
    <meta name="description" content="Agent 方向最新论文已更新，请持续关注 Update in 2025-05-21  Synthesis of Communication Policies for Multi-Agent Systems Robust to   Communication Restrictions">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>Agent | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loader页面消失采用渐隐的方式*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logo出现动画 */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//使用渐隐的方法淡出loading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//强制显示loading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">嘘~  正在从服务器偷取页面 . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>首页</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>标签</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>分类</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>归档</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="搜索" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="深色/浅色模式" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			首页
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			标签
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			分类
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			归档
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://pic1.zhimg.com/v2-c09a172b44f945ea3cc9daf925f31981.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Agent</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/Agent/">
                                <span class="chip bg-color">Agent</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/Agent/" class="post-category">
                                Agent
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2025-05-21
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>更新日期:&nbsp;&nbsp;
                    2025-05-27
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp;
                    13.7k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp;
                    54 分
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>阅读次数:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>⚠️ 以下所有内容总结都来自于 大语言模型的能力，如有错误，仅供参考，谨慎使用<br>🔴 请注意：千万不要用于严肃的学术场景，只能用于论文阅读前的初筛！<br>💗 如果您觉得我们的项目对您有帮助 <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ，还请您给我们一些鼓励！⭐️ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFace免费体验</a></p>
</blockquote>
<h1 id="2025-05-21-更新"><a href="#2025-05-21-更新" class="headerlink" title="2025-05-21 更新"></a>2025-05-21 更新</h1><h2 id="Synthesis-of-Communication-Policies-for-Multi-Agent-Systems-Robust-to-Communication-Restrictions"><a href="#Synthesis-of-Communication-Policies-for-Multi-Agent-Systems-Robust-to-Communication-Restrictions" class="headerlink" title="Synthesis of Communication Policies for Multi-Agent Systems Robust to   Communication Restrictions"></a>Synthesis of Communication Policies for Multi-Agent Systems Robust to   Communication Restrictions</h2><p><strong>Authors:Saleh Soudijani, Rayna Dimitrova</strong></p>
<p>We study stochastic multi-agent systems in which agents must cooperate to maximize the probability of achieving a common reach-avoid objective. In many applications, during the execution of the system, the communication between the agents can be constrained by restrictions on the bandwidth currently available for exchanging local-state information between the agents.   In this paper, we propose a method for computing joint action and communication policies for the group of agents that aim to satisfy the communication restrictions as much as possible while achieving the optimal reach-avoid probability when communication is unconstrained. Our method synthesizes a pair of action and communication policies robust to restrictions on the number of agents allowed to communicate. To this end, we introduce a novel cost function that measures the amount of information exchanged beyond what the communication policy allows. We evaluate our approach experimentally on a range of benchmarks and demonstrate that it is capable of computing pairs of action and communication policies that satisfy the communication restrictions, if such exist. </p>
<blockquote>
<p>我们研究随机多智能体系统，在这个系统中，智能体需要协作以最大化实现共同达成避免目标的可能性。在许多应用中，系统执行过程中，智能体之间的通信可能会受到当前可用于交换局部状态信息带宽的限制。本文提出了一种计算智能体组联合行动和通信策略的方法，旨在在满足通信限制的同时，尽可能实现最优的达成避免概率，当通信不受限制时。我们的方法合成了一对行动和通信策略，对允许通信的智能体数量限制具有鲁棒性。为此，我们引入了一个新的成本函数，用于衡量超出通信策略允许的信息交换量。我们通过一系列基准测试对方法进行了实验评估，证明当存在通信限制时，它能够计算出满足限制的行动和通信策略组合。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.13311v1">PDF</a> This is the extended version of the paper accepted for publication at   IJCAI 2025</p>
<p><strong>Summary</strong><br>在具有通信带宽限制的多智能体系统中，必须计算智能体的联合行动和通信策略，以最大化达成共同达成目标的概率。本文提出了一种计算智能体组的联合行动和通信策略的方法，旨在在满足通信限制的同时，在不受约束的通信情况下实现最优的达成目标概率。通过引入新的成本函数来衡量超出通信策略允许的信息交换量，我们能够在实验基准测试中验证该方法的有效性。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>研究了多智能体系统中的随机性问题，智能体需要合作以实现共同的目标达成概率最大化。</li>
<li>考虑到通信带宽限制，提出一种计算智能体的联合行动和通信策略的方法。</li>
<li>方法旨在满足可能的通信限制，同时在无约束的通信情况下实现最优的目标达成概率。</li>
<li>通过引入新的成本函数来衡量超出通信策略允许的信息交换量。</li>
<li>实验评估证明了该方法在计算智能体的联合行动和通信策略方面的有效性。</li>
<li>该方法能够适应不同的通信限制条件。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.13311">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-bd2fcb45f78df941e97fde01ddd57996.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-16480dcf283a2cf9a5378df07984d061.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="When-a-Reinforcement-Learning-Agent-Encounters-Unknown-Unknowns"><a href="#When-a-Reinforcement-Learning-Agent-Encounters-Unknown-Unknowns" class="headerlink" title="When a Reinforcement Learning Agent Encounters Unknown Unknowns"></a>When a Reinforcement Learning Agent Encounters Unknown Unknowns</h2><p><strong>Authors:Juntian Zhu, Miguel de Carvalho, Zhouwang Yang, Fengxiang He</strong></p>
<p>An AI agent might surprisingly find she has reached an unknown state which she has never been aware of – an unknown unknown. We mathematically ground this scenario in reinforcement learning: an agent, after taking an action calculated from value functions $Q$ and $V$ defined on the {\it {aware domain}}, reaches a state out of the domain. To enable the agent to handle this scenario, we propose an {\it episodic Markov decision {process} with growing awareness} (EMDP-GA) model, taking a new {\it noninformative value expansion} (NIVE) approach to expand value functions to newly aware areas: when an agent arrives at an unknown unknown, value functions $Q$ and $V$ whereon are initialised by noninformative beliefs – the averaged values on the aware domain. This design is out of respect for the complete absence of knowledge in the newly discovered state. The upper confidence bound momentum Q-learning is then adapted to the growing awareness for training the EMDP-GA model. We prove that (1) the regret of our approach is asymptotically consistent with the state of the art (SOTA) without exposure to unknown unknowns in an extremely uncertain environment, and (2) our computational complexity and space complexity are comparable with the SOTA – these collectively suggest that though an unknown unknown is surprising, it will be asymptotically properly discovered with decent speed and an affordable cost. </p>
<blockquote>
<p>一个AI代理可能会意外地发现自己处于一个未知状态，这是她从未意识到的——未知中的未知。我们在强化学习中对这种情景进行数学建模：代理在计算出的动作（基于定义在“意识域”上的价值函数Q和V）之后，达到了域外的状态。为了能够让代理处理这种情景，我们提出了一个“带有意识增长的阶段性马尔可夫决策过程”（EMDP-GA）模型，采取一种新的“非信息价值扩张”（NIVE）方法，将价值函数扩张到新的意识领域：当代理遇到一个未知中的未知，价值函数Q和V将通过非信息信念进行初始化——即在意识域上的平均值。这种设计是为了尊重新发现状态中完全缺乏知识的情况。然后，将上界动量Q学习适应于增长意识，以训练EMDP-GA模型。我们证明（1）我们的方法在极端不确定的环境中，在没有遇到未知中的未知的情况下，其遗憾的渐进性与最新技术的一致性是一致的；（2）我们的计算复杂性和空间复杂度与最新技术相当——这些共同表明，尽管未知中的未知是令人惊讶的，但我们将以适中的速度和成本渐进地适当地发现它。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.13188v1">PDF</a> </p>
<p><strong>Summary</strong><br>在强化学习中，AI代理可能会意外进入未知状态，即所谓的“未知未知”。为解决这一问题，我们提出一种带有成长意识的片段式马尔可夫决策过程（EMDP-GA）模型，采用非信息价值扩展（NIVE）方法扩展价值函数至新意识领域。当代理遇到未知未知时，通过非信息信念（对已知领域平均值）初始化价值函数Q和V。然后适应乐观边界动量Q学习以支持增长意识训练EMDP-GA模型。我们的方法在保证计算复杂度和空间复杂度与现有技术相当的同时，证明了在极端不确定环境下即使遇到未知未知，我们的方法也能渐近一致地与前沿技术的后悔度保持接近。这意味着能够逐步有效地发现新知识而不丧失效率。</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>AI代理在强化学习中可能遇到未知状态（未知未知）。</li>
<li>为处理这种状态，提出EMDP-GA模型及NIVE方法，以扩展价值函数至新意识领域。</li>
<li>在遇到未知未知时，通过非信息信念初始化价值函数。</li>
<li>采用上界置信动量Q学习适应增长意识，用于训练EMDP-GA模型。</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.13188">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-0b09b991bdc00720d8fc00bef3d76ac8.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c926290a01803730865e11b68aff2e06.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-fa4adf1d6e2a2405c7b6e66b0d9c32f7.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e838a2fc2dc48f2705a4c9f9ca8efbda.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="CAIM-Development-and-Evaluation-of-a-Cognitive-AI-Memory-Framework-for-Long-Term-Interaction-with-Intelligent-Agents"><a href="#CAIM-Development-and-Evaluation-of-a-Cognitive-AI-Memory-Framework-for-Long-Term-Interaction-with-Intelligent-Agents" class="headerlink" title="CAIM: Development and Evaluation of a Cognitive AI Memory Framework for   Long-Term Interaction with Intelligent Agents"></a>CAIM: Development and Evaluation of a Cognitive AI Memory Framework for   Long-Term Interaction with Intelligent Agents</h2><p><strong>Authors:Rebecca Westhäußer, Frederik Berenz, Wolfgang Minker, Sebastian Zepf</strong></p>
<p>Large language models (LLMs) have advanced the field of artificial intelligence (AI) and are a powerful enabler for interactive systems. However, they still face challenges in long-term interactions that require adaptation towards the user as well as contextual knowledge and understanding of the ever-changing environment. To overcome these challenges, holistic memory modeling is required to efficiently retrieve and store relevant information across interaction sessions for suitable responses. Cognitive AI, which aims to simulate the human thought process in a computerized model, highlights interesting aspects, such as thoughts, memory mechanisms, and decision-making, that can contribute towards improved memory modeling for LLMs. Inspired by these cognitive AI principles, we propose our memory framework CAIM. CAIM consists of three modules: 1.) The Memory Controller as the central decision unit; 2.) the Memory Retrieval, which filters relevant data for interaction upon request; and 3.) the Post-Thinking, which maintains the memory storage. We compare CAIM against existing approaches, focusing on metrics such as retrieval accuracy, response correctness, contextual coherence, and memory storage. The results demonstrate that CAIM outperforms baseline frameworks across different metrics, highlighting its context-awareness and potential to improve long-term human-AI interactions. </p>
<blockquote>
<p>大型语言模型（LLM）推动了人工智能（AI）领域的发展，并成为交互式系统的强大助力。然而，在长期交互方面，它们仍然面临挑战，需要适应用户以及理解不断变化的环境的上下文知识。为了克服这些挑战，需要全面的记忆建模以在交互会话中有效地检索和存储相关信息以产生适当的响应。认知AI旨在模拟计算机化模型中的人类思维过程，突出了诸如思想、记忆机制和决策等有趣方面，这些方面可以为LLM的记忆建模做出贡献。受认知AI原理的启发，我们提出了我们的记忆框架CAIM。CAIM由三个模块组成：1)作为中央决策单元的Memory Controller（记忆控制器）；2)Memory Retrieval（记忆检索），它会在请求时过滤出相关的交互数据；以及3)Post-Thinking（后思考），它负责维护记忆存储。我们将CAIM与现有方法进行比较，关注诸如检索准确性、响应正确性、上下文一致性和记忆存储等指标。结果表明，CAIM在不同指标上的表现均优于基线框架，突出了其上下文感知能力，并有望改善长期人机交互。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.13044v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>大型语言模型（LLM）在人工智能领域具有重要地位，对于构建交互式系统具有重要作用。然而，在长期互动中，它们仍面临适应用户、理解不断变化的环境等挑战。为了克服这些挑战，需要全面的记忆建模以有效地检索和存储跨交互会话的相关信息以产生合适的响应。受认知AI（模拟人类思维过程的计算机化模型）的启发，本文提出了记忆框架CAIM，包括记忆控制器、记忆检索和后期思考三个模块。对比现有方法，CAIM在检索准确性、响应正确性、上下文连贯性和记忆存储等方面表现出色，凸显其语境意识和改善长期人机交互的潜力。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>大型语言模型（LLM）在人工智能领域有重要地位，对交互式系统构建具有重要作用。</li>
<li>LLM在长期互动中面临适应用户和理解环境变化等挑战。</li>
<li>全面记忆建模对于克服这些挑战并产生合适的响应是必要的。</li>
<li>认知AI模拟人类思维过程，为改进LLM的记忆建模提供启发。</li>
<li>CAIM记忆框架包括三个模块：记忆控制器、记忆检索和后期思考。</li>
<li>CAIM在多个指标上优于现有方法，包括检索准确性、响应正确性等。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.13044">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-71799079d8ad4c2aab60ca66e77e76c2.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-1036a6a1d2b26a88e94c433522d6e0e0.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-33301c05e417876eea113d544e3cf3d8.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-a1b0f50c7035d4d1b24cfbacb2097db5.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="GEM-Gaussian-Embedding-Modeling-for-Out-of-Distribution-Detection-in-GUI-Agents"><a href="#GEM-Gaussian-Embedding-Modeling-for-Out-of-Distribution-Detection-in-GUI-Agents" class="headerlink" title="GEM: Gaussian Embedding Modeling for Out-of-Distribution Detection in   GUI Agents"></a>GEM: Gaussian Embedding Modeling for Out-of-Distribution Detection in   GUI Agents</h2><p><strong>Authors:Zheng Wu, Pengzhou Cheng, Zongru Wu, Lingzhong Dong, Zhuosheng Zhang</strong></p>
<p>Graphical user interface (GUI) agents have recently emerged as an intriguing paradigm for human-computer interaction, capable of automatically executing user instructions to operate intelligent terminal devices. However, when encountering out-of-distribution (OOD) instructions that violate environmental constraints or exceed the current capabilities of agents, GUI agents may suffer task breakdowns or even pose security threats. Therefore, effective OOD detection for GUI agents is essential. Traditional OOD detection methods perform suboptimally in this domain due to the complex embedding space and evolving GUI environments. In this work, we observe that the in-distribution input semantic space of GUI agents exhibits a clustering pattern with respect to the distance from the centroid. Based on the finding, we propose GEM, a novel method based on fitting a Gaussian mixture model over input embedding distances extracted from the GUI Agent that reflect its capability boundary. Evaluated on eight datasets spanning smartphones, computers, and web browsers, our method achieves an average accuracy improvement of 23.70% over the best-performing baseline. Analysis verifies the generalization ability of our method through experiments on nine different backbones. The codes are available at <a target="_blank" rel="noopener" href="https://github.com/Wuzheng02/GEM-OODforGUIagents">https://github.com/Wuzheng02/GEM-OODforGUIagents</a>. </p>
<blockquote>
<p>图形用户界面（GUI）代理最近作为人机交互的一种引人入胜的模式而出现，能够自动执行用户指令来操作智能终端设备。然而，当遇到超出分布（OOD）的指令，这些指令违反环境约束或超出代理的当前能力时，GUI代理可能会出现任务故障，甚至构成安全威胁。因此，有效的GUI代理OOD检测至关重要。由于复杂的嵌入空间和不断变化的GUI环境，传统的OOD检测方法在此领域表现不佳。在这项工作中，我们观察到GUI代理的内部分布输入语义空间在距离质心方面呈现出聚类模式。基于此发现，我们提出了基于高斯混合模型拟合的GEM新方法，该方法通过对从GUI代理提取的输入嵌入距离进行拟合，反映其能力边界。在涵盖智能手机、计算机和网页浏览器的八个数据集上评估，我们的方法相较于表现最佳的基线模型，平均准确率提高了23.70%。分析实验在九个不同主干网络上进行了验证，证明了我们的方法的泛化能力。相关代码可通过以下链接获取：<a target="_blank" rel="noopener" href="https://github.com/Wuzheng02/GEM-OODforGUIagents">https://github.com/Wuzheng02/GEM-OODforGUIagents</a>。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.12842v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>GUI代理的OOD检测新方法：针对图形用户界面（GUI）代理在执行超出当前能力范围或违反环境约束的指令时可能出现的问题，提出了一种基于高斯混合模型（GEM）的OOD检测方法。该方法通过拟合GUI代理输入嵌入距离的高斯混合模型，有效识别OOD指令，并在智能手机、计算机和网页浏览器等多个数据集上实现了较高的准确性。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>GUI代理在面临超出其能力范围或违反环境约束的指令时，可能会出现任务故障或安全隐患。</li>
<li>传统OOD检测方法在GUI环境中表现不佳，因为GUI环境复杂且多变。</li>
<li>GUI代理的输入语义空间呈现聚类分布，距离中心越远越复杂。</li>
<li>基于这一发现，提出了一种名为GEM的新方法，利用高斯混合模型处理GUI代理的输入嵌入距离。</li>
<li>GEM方法可以有效识别OOD指令，并能在不同数据集上实现较高的准确性提升。</li>
<li>在智能手机、计算机和网页浏览器等多个数据集上的实验验证表明，GEM方法的平均准确度提高了23.70%。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.12842">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-923eb85a711faec3547ba019d230037d.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-2ffd6266a3d08a70a3bfec4c4a1980d5.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-e7d120bc2688b34fdf24d3b283b8cc5b.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-aba5673792c65496ce711d0d4e0c74d4.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-0192ad01f92f65d72329b796a4713c5d.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="REI-Bench-Can-Embodied-Agents-Understand-Vague-Human-Instructions-in-Task-Planning"><a href="#REI-Bench-Can-Embodied-Agents-Understand-Vague-Human-Instructions-in-Task-Planning" class="headerlink" title="REI-Bench: Can Embodied Agents Understand Vague Human Instructions in   Task Planning?"></a>REI-Bench: Can Embodied Agents Understand Vague Human Instructions in   Task Planning?</h2><p><strong>Authors:Chenxi Jiang, Chuhao Zhou, Jianfei Yang</strong></p>
<p>Robot task planning decomposes human instructions into executable action sequences that enable robots to complete a series of complex tasks. Although recent large language model (LLM)-based task planners achieve amazing performance, they assume that human instructions are clear and straightforward. However, real-world users are not experts, and their instructions to robots often contain significant vagueness. Linguists suggest that such vagueness frequently arises from referring expressions (REs), whose meanings depend heavily on dialogue context and environment. This vagueness is even more prevalent among the elderly and children, who robots should serve more. This paper studies how such vagueness in REs within human instructions affects LLM-based robot task planning and how to overcome this issue. To this end, we propose the first robot task planning benchmark with vague REs (REI-Bench), where we discover that the vagueness of REs can severely degrade robot planning performance, leading to success rate drops of up to 77.9%. We also observe that most failure cases stem from missing objects in planners. To mitigate the REs issue, we propose a simple yet effective approach: task-oriented context cognition, which generates clear instructions for robots, achieving state-of-the-art performance compared to aware prompt and chains of thought. This work contributes to the research community of human-robot interaction (HRI) by making robot task planning more practical, particularly for non-expert users, e.g., the elderly and children. </p>
<blockquote>
<p>机器人任务规划能够将人类指令分解为一系列可执行的行动序列，从而使机器人能够完成一系列复杂任务。尽管最近基于大型语言模型的任务规划器取得了惊人的性能，但它们假设人类指令是清晰直接的。然而，真实世界的用户并非都是专家，他们对机器人的指令通常包含相当大的模糊性。语言学家认为，这种模糊性经常来自于指代表达式（RE），其意义很大程度上取决于对话上下文和环境。这种模糊性在老年人和儿童中更为普遍，而机器人应该为他们提供更多的服务。本论文研究人类指令中的指代表达式（RE）中的这种模糊性如何影响基于大型语言模型的机器人任务规划，以及如何解决这一问题。为此，我们提出了带有模糊REs的第一个机器人任务规划基准（REI-Bench），我们发现REs的模糊性会严重降低机器人规划的性能，成功率下降高达77.9%。我们还观察到，大多数失败的情况源于规划器中缺少对象。为了缓解REs问题，我们提出了一种简单有效的方法：面向任务的上下文认知，为机器人生成清晰的指令，与有意识提示和思维链相比，取得了最先进的性能。这项工作使机器人任务规划更加实用，特别是对非专业用户（如老年人和儿童）而言，为人工智能与机器人交互研究社区做出了贡献。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.10872v2">PDF</a> Under Review</p>
<p><strong>Summary</strong>：<br>机器人任务规划能够将人类指令分解为可执行的动作序列，使机器人能够完成一系列复杂任务。尽管基于大型语言模型的任务规划器取得了惊人的性能，但它们假设人类指令是清晰直接的。然而，真实世界的用户并非专家，他们给机器人的指令常常包含相当的模糊性。本文研究了人类指令中的参照表达式（REs）的模糊性如何影响基于大型语言模型的机器人任务规划，并提出了如何解决这一问题的方法。为此，我们建立了首个含有模糊参照表达式的机器人任务规划基准测试（REI-Bench），发现参照表达式的模糊性会严重降低机器人规划的性能，成功率下降高达77.9%。我们还观察到大多数失败案例源于规划中的目标缺失。为了缓解参照表达式的问题，我们提出了一种简单有效的方法：面向任务的上下文认知，为机器人生成清晰的指令，实现了与意识提示和思考链相比的先进性能。这项工作对人类与机器人交互（HRI）研究群体做出了贡献，使机器人任务规划更加实用，尤其对于非专业用户如老年人和儿童而言。</p>
<p><strong>Key Takeaways</strong>：</p>
<ol>
<li>机器人任务规划能够将人类指令转化为可执行动作序列。</li>
<li>基于大型语言模型的机器人任务规划器在假设人类指令清晰直接的情况下表现出色。</li>
<li>真实世界中的用户指令通常包含模糊性，主要来源于参照表达式的使用。</li>
<li>参照表达式的模糊性可能导致机器人任务规划性能严重下降，成功率下降幅度达77.9%。</li>
<li>机器人任务规划中的失败案例主要源于目标缺失。</li>
<li>面向任务的上下文认知方法能够生成清晰指令，提高机器人任务规划性能。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.10872">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-a2abf10dd4a8a1d6fd576d8a39a3d284.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-85341f39acecd2dfced3750d1c918150.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-28d33e1a00fa5960962c37422748e9d2.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-bf5f4803a5cea43c0a09a64e58c1142e.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="TRAIL-Trace-Reasoning-and-Agentic-Issue-Localization"><a href="#TRAIL-Trace-Reasoning-and-Agentic-Issue-Localization" class="headerlink" title="TRAIL: Trace Reasoning and Agentic Issue Localization"></a>TRAIL: Trace Reasoning and Agentic Issue Localization</h2><p><strong>Authors:Darshan Deshpande, Varun Gangal, Hersh Mehta, Jitin Krishnan, Anand Kannappan, Rebecca Qian</strong></p>
<p>The increasing adoption of agentic workflows across diverse domains brings a critical need to scalably and systematically evaluate the complex traces these systems generate. Current evaluation methods depend on manual, domain-specific human analysis of lengthy workflow traces - an approach that does not scale with the growing complexity and volume of agentic outputs. Error analysis in these settings is further complicated by the interplay of external tool outputs and language model reasoning, making it more challenging than traditional software debugging. In this work, we (1) articulate the need for robust and dynamic evaluation methods for agentic workflow traces, (2) introduce a formal taxonomy of error types encountered in agentic systems, and (3) present a set of 148 large human-annotated traces (TRAIL) constructed using this taxonomy and grounded in established agentic benchmarks. To ensure ecological validity, we curate traces from both single and multi-agent systems, focusing on real-world applications such as software engineering and open-world information retrieval. Our evaluations reveal that modern long context LLMs perform poorly at trace debugging, with the best Gemini-2.5-pro model scoring a mere 11% on TRAIL. Our dataset and code are made publicly available to support and accelerate future research in scalable evaluation for agentic workflows. </p>
<blockquote>
<p>随着跨领域智能工作流的普及，对这些系统生成复杂轨迹进行可扩展和系统评价的需求愈发关键。当前的评价方法依赖于对冗长工作流轨迹进行手动、特定领域的分析——这一方法无法随着智能输出的复杂性和数量的增长而扩展。在这些场景中，外部工具输出和语言模型推理之间的相互作用进一步加剧了错误分析，使其比传统软件调试更具挑战性。在此工作中，我们（1）阐述了针对智能工作流轨迹的稳健性和动态性评价方法的必要性，（2）介绍了在智能系统中遇到的错误类型的正式分类，以及（3）根据这一分类和基于已建立的智能基准测试，展示了一组由人类注释的轨迹集（TRAIL），包含共 148 条大型轨迹集。为确保生态有效性，我们从单智能体系统和多智能体系统中整理轨迹，重点关注现实世界的应用，如软件工程和开放世界信息检索。我们的评估显示，现代长文本语境的大型语言模型在轨迹调试方面的表现不佳，最佳模型 Gemini-2.5 评分仅为 TRAIL 上的 11%。我们的数据集和代码已公开发布，以支持和加速未来针对智能工作流的可扩展性评价的研究。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.08638v2">PDF</a> Dataset: <a target="_blank" rel="noopener" href="https://huggingface.co/datasets/PatronusAI/TRAIL">https://huggingface.co/datasets/PatronusAI/TRAIL</a></p>
<p><strong>Summary</strong></p>
<p>该文本介绍了代理工作流程（agentic workflows）的应用与评估需求。现有评估方法依赖手动、针对特定领域的分析，难以应对日益增长的大规模代理输出。文中提出了对新型评估方法的需求，介绍了代理系统中遇到的错误类型分类，并构建了一个基于代理基准测试的大型人类注释跟踪集（TRAIL）。评价显示现代长语境LLM在跟踪调试方面表现不佳。数据集和代码已公开，以支持加速未来对代理工作流程的可扩展评估研究。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>代理工作流程的广泛应用使得对其生成的大规模复杂轨迹进行可扩展的系统评估变得至关重要。</li>
<li>当前评估方法过于依赖手动分析，不适应大规模和复杂的代理输出。</li>
<li>需要新型的动态评估方法来处理代理工作流的复杂性。</li>
<li>引入了代理系统中遇到的错误类型的正式分类。</li>
<li>构建了一个基于现有代理基准测试的大型人类注释跟踪集（TRAIL）。</li>
<li>数据集涵盖了单代理和多代理系统的真实应用场景，如软件工程和开放世界信息检索。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.08638">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-a3ee75834661a11290fd43e315b87018.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-7462c4ecedd4ce98e5f0213a4e4750ac.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-9bb85c0eb0e4c4a8f5e27ff312564ae5.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="SocialJax-An-Evaluation-Suite-for-Multi-agent-Reinforcement-Learning-in-Sequential-Social-Dilemmas"><a href="#SocialJax-An-Evaluation-Suite-for-Multi-agent-Reinforcement-Learning-in-Sequential-Social-Dilemmas" class="headerlink" title="SocialJax: An Evaluation Suite for Multi-agent Reinforcement Learning in   Sequential Social Dilemmas"></a>SocialJax: An Evaluation Suite for Multi-agent Reinforcement Learning in   Sequential Social Dilemmas</h2><p><strong>Authors:Zihao Guo, Shuqing Shi, Richard Willis, Tristan Tomilin, Joel Z. Leibo, Yali Du</strong></p>
<p>Sequential social dilemmas pose a significant challenge in the field of multi-agent reinforcement learning (MARL), requiring environments that accurately reflect the tension between individual and collective interests. Previous benchmarks and environments, such as Melting Pot, provide an evaluation protocol that measures generalization to new social partners in various test scenarios. However, running reinforcement learning algorithms in traditional environments requires substantial computational resources. In this paper, we introduce SocialJax, a suite of sequential social dilemma environments and algorithms implemented in JAX. JAX is a high-performance numerical computing library for Python that enables significant improvements in operational efficiency. Our experiments demonstrate that the SocialJax training pipeline achieves at least 50\texttimes{} speed-up in real-time performance compared to Melting Pot RLlib baselines. Additionally, we validate the effectiveness of baseline algorithms within SocialJax environments. Finally, we use Schelling diagrams to verify the social dilemma properties of these environments, ensuring that they accurately capture the dynamics of social dilemmas. </p>
<blockquote>
<p>多智能体强化学习（MARL）领域中的序列社会困境构成了一项重大挑战，要求环境能够准确反映个体与集体利益之间的张力。之前的基准测试和环境，如熔炉，提供了一个评估协议，该协议可以衡量在各种测试场景中与新社交伙伴的通用性。然而，在传统环境中运行强化学习算法需要大量的计算资源。在本文中，我们介绍了SocialJax，这是一套在JAX中实现的序列社会困境环境和算法。JAX是一个用于Python的高性能数值计算库，能够提高操作效率。我们的实验表明，与Melting Pot RLlib基准测试相比，SocialJax训练管道在实时性能上实现了至少50倍的速度提升。此外，我们在SocialJax环境中验证了基线算法的有效性。最后，我们使用舍林图验证了这些环境的社交困境属性，确保它们能准确捕捉社交困境的动态。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.14576v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>本文介绍了在Python中使用高性能数值计算库JAX实现的多智能体强化学习中的序列社会困境环境套件SocialJax。与现有的环境基准如Melting Pot相比，SocialJax能显著提高运行效率并实现对新社交伙伴的通用化评估。实验证明，SocialJax训练管道在实时性能方面实现了至少50倍的速度提升。同时，验证了基线算法在SocialJax环境中的有效性，并使用Schelling图验证了这些环境的社会困境属性。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>SocialJax是一个用于多智能体强化学习中的序列社会困境的环境套件。</li>
<li>SocialJax使用高性能数值计算库JAX实现，提高了操作效率。</li>
<li>与现有环境基准如Melting Pot相比，SocialJax能实现对新社交伙伴的通用化评估。</li>
<li>SocialJax训练管道在实时性能方面实现了至少50倍的速度提升。</li>
<li>在SocialJax环境中验证了基线算法的有效性。</li>
<li>SocialJax环境通过Schelling图验证了其社会困境属性。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.14576">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-6ff2edd3dbb5ff736f2f836e0416f5dc.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a8f85a2cf506d7a8fcb7714edc746649.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b2bd25aced68070fa8ace78f8f635e85.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="Revisiting-Communication-Efficiency-in-Multi-Agent-Reinforcement-Learning-from-the-Dimensional-Analysis-Perspective"><a href="#Revisiting-Communication-Efficiency-in-Multi-Agent-Reinforcement-Learning-from-the-Dimensional-Analysis-Perspective" class="headerlink" title="Revisiting Communication Efficiency in Multi-Agent Reinforcement   Learning from the Dimensional Analysis Perspective"></a>Revisiting Communication Efficiency in Multi-Agent Reinforcement   Learning from the Dimensional Analysis Perspective</h2><p><strong>Authors:Chuxiong Sun, Peng He, Rui Wang, Changwen Zheng</strong></p>
<p>In this work, we introduce a novel perspective, i.e., dimensional analysis, to address the challenge of communication efficiency in Multi-Agent Reinforcement Learning (MARL). Our findings reveal that simply optimizing the content and timing of communication at sending end is insufficient to fully resolve communication efficiency issues. Even after applying optimized and gated messages, dimensional redundancy and confounders still persist in the integrated message embeddings at receiving end, which negatively impact communication quality and decision-making. To address these challenges, we propose Dimensional Rational Multi-Agent Communication (DRMAC), designed to mitigate both dimensional redundancy and confounders in MARL. DRMAC incorporates a redundancy-reduction regularization term to encourage the decoupling of information across dimensions within the learned representations of integrated messages. Additionally, we introduce a dimensional mask that dynamically adjusts gradient weights during training to eliminate the influence of decision-irrelevant dimensions. We evaluate DRMAC across a diverse set of multi-agent tasks, demonstrating its superior performance over existing state-of-the-art methods in complex scenarios. Furthermore, the plug-and-play nature of DRMAC’s key modules highlights its generalizable performance, serving as a valuable complement rather than a replacement for existing multi-agent communication strategies. </p>
<blockquote>
<p>在这项工作中，我们引入了一个新的视角，即维度分析，来解决多智能体强化学习（MARL）中的通信效率挑战。我们的研究发现，仅仅优化发送端的通信内容和时机并不能完全解决通信效率问题。即使在应用了优化和门控消息后，接收端的集成消息嵌入中仍然存在维度冗余和混淆因素，这会对通信质量和决策产生负面影响。为了解决这些挑战，我们提出了维度理性多智能体通信（DRMAC），旨在减轻MARL中的维度冗余和混淆因素。DRMAC采用冗余减少正则化项，以鼓励集成消息学习表示中维度之间信息的解耦。此外，我们还引入了一个维度掩码，该掩码在训练过程中动态调整梯度权重，以消除决策无关维度的影响。我们在多种多智能体任务上评估了DRMAC的性能，结果表明它在复杂场景中的性能优于现有最先进的方法。此外，DRMAC关键模块的即插即用特性凸显了其通用性能，可作为现有多智能体通信策略的有价值补充，而非替代品。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.02888v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>本文引入维度分析的新视角，解决多智能体强化学习中的沟通效率问题。研究发现，仅优化发送端的通信内容和时机无法完全解决沟通效率问题。即使应用优化和门控消息，接收端的集成消息嵌入中仍存在维度冗余和混淆因素，这会对通信质量和决策产生负面影响。为解决这些问题，本文提出维度理性多智能体通信（DRMAC），旨在减少多智能体强化学习中的维度冗余和混淆因素。DRMAC采用冗余减少正则化项来鼓励集成消息的学习的表示中信息维度的解耦，并引入动态调整训练时梯度权重的维度掩码，以消除决策无关维度的影响。在多种多智能体任务上评估DRMAC，结果表明其在复杂场景中的性能优于现有最先进的策略。此外，DRMAC关键模块的即插即用特性凸显了其通用性能，可作为现有多智能体通信策略的有益补充。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>引入维度分析来解决多智能体强化学习中的沟通效率问题。</li>
<li>发现仅优化发送端的通信内容和时机无法解决所有沟通效率问题。</li>
<li>接收端的集成消息嵌入存在维度冗余和混淆因素。</li>
<li>提出DRMAC方法，旨在减少维度冗余和混淆。</li>
<li>DRMAC采用冗余减少正则化项和维度掩码来提升通信质量。</li>
<li>在多种多智能体任务上评估DRMAC，表现优于现有方法。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.02888">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-22da2940ff1dc7c3a4b4317de8be553e.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-0fe734a1c7fd87c1279ddcf175d4afd7.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-434338f84cede6f8ce66a7428bf06db6.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a7f216c6b19f97486513e2f5432fccd5.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-cd8b1838a9cf106514ab81e73a560f38.jpg" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="Multi-Agent-Sampling-Scaling-Inference-Compute-for-Data-Synthesis-with-Tree-Search-Based-Agentic-Collaboration"><a href="#Multi-Agent-Sampling-Scaling-Inference-Compute-for-Data-Synthesis-with-Tree-Search-Based-Agentic-Collaboration" class="headerlink" title="Multi-Agent Sampling: Scaling Inference Compute for Data Synthesis with   Tree Search-Based Agentic Collaboration"></a>Multi-Agent Sampling: Scaling Inference Compute for Data Synthesis with   Tree Search-Based Agentic Collaboration</h2><p><strong>Authors:Hai Ye, Mingbao Lin, Hwee Tou Ng, Shuicheng Yan</strong></p>
<p>Scaling laws for inference compute in multi-agent systems remain under-explored compared to single-agent scenarios. This work aims to bridge this gap by investigating the problem of data synthesis through multi-agent sampling, where synthetic responses are generated by sampling from multiple distinct language models. Effective model coordination is crucial for successful multi-agent collaboration. Unlike previous approaches that rely on fixed workflows, we treat model coordination as a multi-step decision-making process, optimizing generation structures dynamically for each input question. We introduce Tree Search-based Orchestrated Agents~(TOA), where the workflow evolves iteratively during the sequential sampling process. To achieve this, we leverage Monte Carlo Tree Search (MCTS), integrating a reward model to provide real-time feedback and accelerate exploration. Our experiments on alignment, machine translation, and mathematical reasoning demonstrate that multi-agent sampling significantly outperforms single-agent sampling as inference compute scales. TOA is the most compute-efficient approach, achieving SOTA performance on WMT and a 72.2% LC win rate on AlpacaEval. Moreover, fine-tuning with our synthesized alignment data surpasses strong preference learning methods on challenging benchmarks such as Arena-Hard and AlpacaEval. </p>
<blockquote>
<p>在多智能体系统的推理计算中，与单智能体场景相比，关于其规模定律的研究仍然不足。本研究旨在通过调查多智能体采样中的数据合成问题来填补这一空白，其中合成响应是通过从多个不同的语言模型中进行采样而生成的。有效的模型协调对于成功的多智能体合作至关重要。不同于以往依赖于固定工作流程的方法，我们将模型协调视为一个多步骤的决策过程，针对每个输入问题动态优化生成结构。我们引入了基于树搜索的协同智能体（TOA），其中工作流程在顺序采样过程中迭代发展。为实现这一点，我们利用蒙特卡洛树搜索（MCTS），并结合奖励模型提供实时反馈并加速探索。我们在对齐、机器翻译和数学推理方面的实验表明，随着推理计算规模的增长，多智能体采样显著优于单智能体采样。TOA是计算效率最高的方法，在WMT上实现了最先进的性能，并在AlpacaEval上的LC获胜率为72.2%。此外，使用我们合成的对齐数据进行微调，在具有挑战性的基准测试上超越了强大的偏好学习方法，如Arena-Hard和AlpacaEval。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.17061v2">PDF</a> In submission</p>
<p><strong>Summary</strong></p>
<p>在多智能体系统推理计算中的伸缩定律相较于单智能体场景的研究仍然不足。本研究旨在弥补这一空白，探究多智能体采样中的数据安全合成问题，其中合成回应是由多个不同的语言模型中抽样产生。有效的模型协调是实现智能体成功协作的关键。不同于以往依赖于固定工作流程的方法，我们将模型协调视为一个分步决策过程，针对每个输入问题动态优化生成结构。我们推出基于树搜索的协同智能体（TOA），其工作流程会在顺序抽样过程中不断迭代。为此，我们运用蒙特卡洛树搜索（MCTS），结合奖励模型提供实时反馈并加速探索过程。实验表明，随着推理计算规模的扩大，多智能体采样显著优于单智能体采样。TOA在推理计算上最为高效，在世界机器翻译（WMT）上表现卓越，且在AlpacaEval上的胜率为72.2%。此外，利用我们的合成数据微调超越了强大的偏好学习方法在诸如Arena-Hard和AlpacaEval等具有挑战性的基准测试上的表现。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>多智能体系统在推理计算中的伸缩定律研究仍然不足，与单智能体场景相比。</li>
<li>研究旨在探究多智能体采样中的数据合成问题，合成回应由多个语言模型抽样生成。</li>
<li>有效模型协调对多智能体成功协作至关重要。</li>
<li>不同于固定工作流程的方法，模型协调被视为一个分步决策过程。</li>
<li>引入基于树搜索的协同智能体（TOA），工作流程在顺序抽样过程中迭代。</li>
<li>使用蒙特卡洛树搜索（MCTS）结合奖励模型提供实时反馈并加速探索。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.17061">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-c4f4e4a0b9acc449d2351f9f63481a70.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-29657c649db2ce0a289304ce13bc6f21.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-d35e845685499375f8f29ca6de95323a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-dceed07f305c6c86af906004d8b195e7.jpg" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1><h2 id="Enhancing-LLMs-for-Power-System-Simulations-A-Feedback-driven-Multi-agent-Framework"><a href="#Enhancing-LLMs-for-Power-System-Simulations-A-Feedback-driven-Multi-agent-Framework" class="headerlink" title="Enhancing LLMs for Power System Simulations: A Feedback-driven   Multi-agent Framework"></a>Enhancing LLMs for Power System Simulations: A Feedback-driven   Multi-agent Framework</h2><p><strong>Authors:Mengshuo Jia, Zeyu Cui, Gabriela Hug</strong></p>
<p>The integration of experimental technologies with large language models (LLMs) is transforming scientific research. It positions AI as a versatile research assistant rather than a mere problem-solving tool. In the field of power systems, however, managing simulations – one of the essential experimental technologies – remains a challenge for LLMs due to their limited domain-specific knowledge, restricted reasoning capabilities, and imprecise handling of simulation parameters. To address these limitations, this paper proposes a feedback-driven, multi-agent framework. It incorporates three proposed modules: an enhanced retrieval-augmented generation (RAG) module, an improved reasoning module, and a dynamic environmental acting module with an error-feedback mechanism. Validated on 69 diverse tasks from Daline and MATPOWER, this framework achieves success rates of 93.13% and 96.85%, respectively. It significantly outperforms ChatGPT 4o, o1-preview, and the fine-tuned GPT-4o, which all achieved a success rate lower than 30% on complex tasks. Additionally, the proposed framework also supports rapid, cost-effective task execution, completing each simulation in approximately 30 seconds at an average cost of 0.014 USD for tokens. Overall, this adaptable framework lays a foundation for developing intelligent LLM-based assistants for human researchers, facilitating power system research and beyond. </p>
<blockquote>
<p>将实验技术与大型语言模型（LLM）的结合正在改变科学研究的方式。它将人工智能定位为多才多艺的研究助手，而不仅仅是解决问题的工具。然而，在电力系统领域，管理模拟（一项重要的实验技术）对LLM来说仍然是一个挑战，因为它们有限的特定领域知识、有限的推理能力和对模拟参数的不精确处理。为了克服这些局限性，本文提出了一种反馈驱动的多智能体框架。它结合了三个提出的模块：增强的检索增强生成（RAG）模块、改进的推理模块以及带有错误反馈机制的动力环境行为模块。在Daline和MATPOWER的69个不同任务上进行验证，该框架的成功率分别为93.13%和96.85%。它显著优于ChatGPT 4o、o1预览和经过微调后的GPT-4o，这些模型在复杂任务上的成功率均低于30%。此外，所提出的框架还支持快速、经济的任务执行，每个模拟大约需要30秒完成，令牌平均成本为0.014美元。总的来说，这个灵活多变的框架为开发基于LLM的智能助手为研究人员的科学研究奠定了基础，尤其是在电力系统研究方面。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2411.16707v3">PDF</a> 16 pages</p>
<p><strong>Summary</strong><br>     实验技术与大型语言模型（LLM）的融合正在推动科学研究变革。它将人工智能定位为多才多艺的研究助手，而不仅仅是问题解决工具。在电力系统领域，管理模拟作为关键实验技术之一仍然是LLM的一个挑战，LLM在特定领域知识、推理能力和参数处理方面存在局限性。针对这些局限性，本文提出一种反馈驱动的多智能体框架，包含增强检索辅助生成模块、改进推理模块以及带有错误反馈机制的动态环境行动模块。该框架在Daline和MATPOWER的69项不同任务上取得了高达93.13%和96.85%的成功率，显著优于ChatGPT 4o、o1预览和微调后的GPT-4o。此外，该框架还支持快速、经济的任务执行，每个模拟任务平均仅需约30秒即可完成，令牌平均成本为0.014美元。总体而言，该自适应框架为开发基于LLM的智能研究助手奠定了基础，有助于电力系统研究及其他领域的发展。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>实验技术与大型语言模型（LLM）的融合正在改变科学研究的方式，让人工智能成为多才多艺的研究助手。</li>
<li>在电力系统领域，管理模拟是LLM面临的一项挑战，存在领域知识、推理能力和参数处理方面的局限性。</li>
<li>提出了一种反馈驱动的多智能体框架，包含增强检索辅助生成、改进推理和带有错误反馈机制的动态环境行动三个模块。</li>
<li>该框架在69项不同任务上取得了高达93.13%和96.85%的成功率，显著优于其他模型。</li>
<li>框架支持快速、经济的任务执行，每个模拟任务平均完成时间短，成本低。</li>
<li>该框架具有自适应性质，为开发基于LLM的智能研究助手奠定了基础。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2411.16707">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-ffda936602400b75db1e9685d5316cfe.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-298c4f8497e3f167bd208997794737e0.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ae2085d27c92ceafe71be84cb3ea71e7.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-78e96bc42af5984a1f7e6b4701a9b93f.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-da71cd30f808cbc519da546a66764d4c.jpg" align="middle">
</details>


<h1 id="-9"><a href="#-9" class="headerlink" title=""></a></h1><h2 id="ST-WebAgentBench-A-Benchmark-for-Evaluating-Safety-and-Trustworthiness-in-Web-Agents"><a href="#ST-WebAgentBench-A-Benchmark-for-Evaluating-Safety-and-Trustworthiness-in-Web-Agents" class="headerlink" title="ST-WebAgentBench: A Benchmark for Evaluating Safety and Trustworthiness   in Web Agents"></a>ST-WebAgentBench: A Benchmark for Evaluating Safety and Trustworthiness   in Web Agents</h2><p><strong>Authors:Ido Levy, Ben Wiesel, Sami Marreed, Alon Oved, Avi Yaeli, Segev Shlomov</strong></p>
<p>Autonomous web agents solve complex browsing tasks, yet existing benchmarks measure only whether an agent finishes a task, ignoring whether it does so safely or in a way enterprises can trust. To integrate these agents into critical workflows, safety and trustworthiness (ST) are prerequisite conditions for adoption. We introduce \textbf{\textsc{ST-WebAgentBench}}, a configurable and easily extensible suite for evaluating web agent ST across realistic enterprise scenarios. Each of its 222 tasks is paired with ST policies, concise rules that encode constraints, and is scored along six orthogonal dimensions (e.g., user consent, robustness). Beyond raw task success, we propose the \textit{Completion Under Policy} (\textit{CuP}) metric, which credits only completions that respect all applicable policies, and the \textit{Risk Ratio}, which quantifies ST breaches across dimensions. Evaluating three open state-of-the-art agents reveals that their average CuP is less than two-thirds of their nominal completion rate, exposing critical safety gaps. By releasing code, evaluation templates, and a policy-authoring interface, \href{<a target="_blank" rel="noopener" href="https://sites.google.com/view/st-webagentbench/home%7D%7B/textsc%7BST-WebAgentBench%7D%7D">https://sites.google.com/view/st-webagentbench/home}{\textsc{ST-WebAgentBench}}</a> provides an actionable first step toward deploying trustworthy web agents at scale. </p>
<blockquote>
<p>自主Web代理可以解决复杂的浏览任务，但现有的基准测试只衡量代理是否完成任务，而忽略了它是否安全或企业能否信任它。为了将这些代理集成到关键工作流程中，安全和可信（ST）是采纳它们的前提条件。我们引入了<strong>ST-WebAgentBench</strong>，这是一套可配置且易于扩展的套件，用于评估Web代理在真实企业场景中的ST。其222个任务均配有ST策略，简洁的规则编码约束，并按六个正交维度（例如用户同意、稳健性）进行评分。除了原始任务成功之外，我们提出了“政策完成度”（CuP）指标，该指标仅对尊重所有适用政策的完成给予认可，以及“风险比率”，该指标量化各维度上的ST违规行为。评估三个开源的最先进代理显示，他们的平均CuP低于其名义完成率的三分之二，暴露出关键的安全差距。通过发布代码、评估模板和策略编写界面，ST-WebAgentBench（<a target="_blank" rel="noopener" href="https://sites.google.com/view/st-webagentbench/home%EF%BC%89%E4%B8%BA%E5%A4%A7%E8%A7%84%E6%A8%A1%E9%83%A8%E7%BD%B2%E5%8F%AF%E4%BF%A1Web%E4%BB%A3%E7%90%86%E6%8F%90%E4%BE%9B%E4%BA%86%E5%8F%AF%E8%A1%8C%E7%9A%84%E7%AC%AC%E4%B8%80%E6%AD%A5%E3%80%82">https://sites.google.com/view/st-webagentbench/home）为大规模部署可信Web代理提供了可行的第一步。</a></p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2410.06703v4">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>该文本介绍了现有的自主网络代理基准测试缺乏安全性与信任度的考量，而针对自主网络代理的测试需要考虑其安全性和信任度的问题。为解决此问题，研究者推出了一个新的评价体系——“ST-WebAgentBench”，这是一个用于评估网络代理的安全性和信任度的可扩展套件。通过真实的企业场景来评估网络代理的性能，其包括了多达六个正交维度以及严格的规定规则，对自主网络代理在真实环境下的安全执行提出更严格的评判标准。并提出了“Completion Under Policy”和“Risk Ratio”两种新评价指标来衡量自主网络代理的表现，暴露了当前开放的最先进的代理软件在安全性方面的差距。所提供的开源平台和评估模板可以帮助构建安全可靠的代理应用平台提供借鉴与解决方案。针对如何解决现存的问题提供了一种实际的手段与方式。可以此为出发点对可信赖的网络代理进行大规模部署与应用。同时也将提供更详细的评价标准促进相关领域的技术进步。这对于促进Web技术的持续进步以及商业价值的挖掘具有重要的意义。这套体系的引入也解决了现存网络的多种隐患和障碍提供了必要的指导方针和操作策略等意见保障工作成果的措施为公司的管理和流程完善打下基础为解决现代社会商业管理的矛盾做出更大的贡献具有十分重要的意义并为企业提供实质性的技术支持及经验分享以便帮助企业降低风险和加强自我管理与防御措施建立更高效可靠的决策支持体系具有巨大的商业价值和市场潜力未来可以推动互联网技术的进一步发展助力构建安全可信的网络环境具有重要的研究价值和应用前景推动未来科技的持续发展和商业应用的融合具有重要的社会意义和市场前景等各方面的积极影响推动了企业技术的更新换代和企业经营管理的数字化改革有着非常重要的现实意义和社会价值值得企业推广和使用<br>。（摘要）通过一套全新的评价体系（ST-WebAgentBench），对网络代理的安全性和信任度进行了深入的评估和考察，打破了原有的局限解决了真实环境下应用技术的实际问题成为了技术发展不可忽视的一部分评估手段的变革及方案的优化方向对促进自动化与智能交互的创新及持续稳定应用打下了坚实基础为推动产业的进一步发展带来了巨大商业价值的突破和商业决策的重大提升是创新技术与实用结合的典型案例该体系的成功运用和推广能够大幅推动相关企业健康快速发展满足现实场景中的多种应用需求增强了市场的适应能力和创新能力构建了开放的市场竞争环境具有重要的社会价值和经济价值对于行业和社会的发展具有深远影响值得进一步推广和应用。（简化版）该论文解决了现有的自主网络代理评价存在的问题和弊端满足了新时代的企业对自动化安全的依赖。评价新体系弥补了漏洞帮助企业解决现实需求为市场注入活力促进了行业的技术进步和发展。</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>现有的自主网络代理基准测试缺乏安全性和信任度的考量。</li>
<li>研究者推出了新的评价体系“ST-WebAgentBench”，用于评估网络代理的安全性和信任度。</li>
<li>该套件包括六个正交维度，以评估网络代理在现实企业场景中的表现。</li>
<li>提出了“Completion Under Policy”和“Risk Ratio”两种新评价指标来衡量自主网络代理的表现。</li>
<li>发现当前最先进的代理软件在安全性方面存在差距。</li>
<li>ST-WebAgentBench提供了开源平台和评估模板，有助于部署安全可靠的代理应用。</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2410.06703">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pica.zhimg.com/v2-20638066548ddb1692cbe8c972e92d21.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-5bbc2a49ff141044297626eac7a34903.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-65b8848017e2ae03a419e43f463ffaa6.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-dccc79692e3d905fc6943ce54fbbfb63.jpg" align="middle">
</details>


<h1 id="-10"><a href="#-10" class="headerlink" title=""></a></h1><h2 id="Asynchronous-Credit-Assignment-for-Multi-Agent-Reinforcement-Learning"><a href="#Asynchronous-Credit-Assignment-for-Multi-Agent-Reinforcement-Learning" class="headerlink" title="Asynchronous Credit Assignment for Multi-Agent Reinforcement Learning"></a>Asynchronous Credit Assignment for Multi-Agent Reinforcement Learning</h2><p><strong>Authors:Yongheng Liang, Hejun Wu, Haitao Wang, Hao Cai</strong></p>
<p>Credit assignment is a critical problem in multi-agent reinforcement learning (MARL), aiming to identify agents’ marginal contributions for optimizing cooperative policies. Current credit assignment methods typically assume synchronous decision-making among agents. However, many real-world scenarios require agents to act asynchronously without waiting for others. This asynchrony introduces conditional dependencies between actions, which pose great challenges to current methods. To address this issue, we propose an asynchronous credit assignment framework, incorporating a Virtual Synchrony Proxy (VSP) mechanism and a Multiplicative Value Decomposition (MVD) algorithm. VSP enables physically asynchronous actions to be virtually synchronized during credit assignment. We theoretically prove that VSP preserves both task equilibrium and algorithm convergence. Furthermore, MVD leverages multiplicative interactions to effectively model dependencies among asynchronous actions, offering theoretical advantages in handling asynchronous tasks. Extensive experiments show that our framework consistently outperforms state-of-the-art MARL methods on challenging tasks while providing improved interpretability for asynchronous cooperation. </p>
<blockquote>
<p>在多智能体强化学习（MARL）中，信用分配是一个关键问题，旨在识别智能体在优化合作策略中的边际贡献。当前的信用分配方法通常假设智能体之间的决策是同步的。然而，许多现实世界的情况要求智能体异步行动，无需等待他人。这种异步性引入了行动之间的条件依赖，给当前的方法带来了巨大的挑战。为了解决这一问题，我们提出了一种异步信用分配框架，该框架结合了虚拟同步代理（VSP）机制和乘法值分解（MVD）算法。VSP能够在信用分配时使物理异步行动在虚拟环境下同步。我们从理论上证明了VSP既保留了任务平衡性又保证了算法的收敛性。此外，MVD利用乘法交互有效地建模了异步行动之间的依赖关系，在理论上具有处理异步任务的优点。大量实验表明，我们的框架在具有挑战性的任务上始终优于最先进的MARL方法，同时提高了异步合作的解释性。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2408.03692v2">PDF</a> </p>
<p><strong>Summary</strong>：在多智能体强化学习（MARL）中，信用分配是一个关键问题，旨在识别智能体的边际贡献以优化合作策略。当前大多数信用分配方法基于智能体之间的同步决策假设，但在现实世界的许多场景中，智能体需要异步行动而不必等待彼此。异步性引入了行动之间的条件依赖性，给现有方法带来挑战。为此，我们提出了一个异步信用分配框架，包含虚拟同步代理（VSP）机制和乘法价值分解（MVD）算法。VSP能够在信用分配时实现物理异步行动的虚拟同步。我们从理论上证明了VSP既保持任务平衡又保证算法收敛。此外，MVD通过利用乘法交互有效地建模异步行动间的依赖性，在处理异步任务时具有理论优势。实验表明，我们的框架在具有挑战性的任务上始终优于最先进的MARL方法，同时为异步合作提供了更好的可解释性。</p>
<p><strong>Key Takeaways</strong>：</p>
<ol>
<li>多智能体强化学习中的信用分配旨在评估智能体在优化合作策略中的贡献。</li>
<li>当前信用分配方法主要基于同步决策假设，但现实世界中智能体常需异步行动。</li>
<li>异步性引入行动间的条件依赖性，对现有的信用分配方法构成挑战。</li>
<li>提出的异步信用分配框架包含虚拟同步代理（VSP）和乘法价值分解（MVD）。</li>
<li>VSP实现了物理异步行动的虚拟同步，并保持任务平衡和算法收敛。</li>
<li>MVD算法通过乘法交互建模异步行动依赖性，在理论上有优势。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2408.03692">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-2af440190dabeabfce050bff1d6ac842.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-95f74c20ff287d69893f6d790a09047d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ac11004b6a798023db454baaa96ee421.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-f83c44f4e54fa1b71ceb8d825e4b92d2.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-d5fe7477e26159fe8a42f11c49ad9096.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e7f9ca28e235f96f67aa4794234a6120.jpg" align="middle">
</details>


<h1 id="-11"><a href="#-11" class="headerlink" title=""></a></h1><h2 id="Agent-Performing-Autonomous-Stock-Trading-under-Good-and-Bad-Situations"><a href="#Agent-Performing-Autonomous-Stock-Trading-under-Good-and-Bad-Situations" class="headerlink" title="Agent Performing Autonomous Stock Trading under Good and Bad Situations"></a>Agent Performing Autonomous Stock Trading under Good and Bad Situations</h2><p><strong>Authors:Yunfei Luo, Zhangqi Duan</strong></p>
<p>Stock trading is one of the popular ways for financial management. However, the market and the environment of economy is unstable and usually not predictable. Furthermore, engaging in stock trading requires time and effort to analyze, create strategies, and make decisions. It would be convenient and effective if an agent could assist or even do the task of analyzing and modeling the past data and then generate a strategy for autonomous trading. Recently, reinforcement learning has been shown to be robust in various tasks that involve achieving a goal with a decision making strategy based on time-series data. In this project, we have developed a pipeline that simulates the stock trading environment and have trained an agent to automate the stock trading process with deep reinforcement learning methods, including deep Q-learning, deep SARSA, and the policy gradient method. We evaluate our platform during relatively good (before 2021) and bad (2021 - 2022) situations. The stocks we’ve evaluated on including Google, Apple, Tesla, Meta, Microsoft, and IBM. These stocks are among the popular ones, and the changes in trends are representative in terms of having good and bad situations. We showed that before 2021, the three reinforcement methods we have tried always provide promising profit returns with total annual rates around $70%$ to $90%$, while maintain a positive profit return after 2021 with total annual rates around 2% to 7%. </p>
<blockquote>
<p>股票交易是财务管理的一种流行方式。然而，市场和经济环境不稳定且通常不可预测。此外，参与股票交易需要时间和精力去分析、制定策略并做出决策。如果能有代理协助甚至完成分析、模拟过去数据并生成自主交易策略的任务，将会更加便捷高效。最近，强化学习在涉及基于时间序列数据的决策策略以实现目标的多种任务中显示出稳健性。在此项目中，我们开发了一个模拟股票交易环境的管道，并使用深度强化学习方法训练了一个代理来自动化股票交易过程，包括深度Q学习、深度SARSA和政策梯度方法。我们在相对良好的情况（2021年之前）和糟糕的情况（2021-2022年）下评估了我们的平台。我们评估的股票包括谷歌、苹果、特斯拉、Meta、微软和IBM。这些股票都很受欢迎，趋势变化代表了良好和糟糕的情况。我们的研究显示，在2021年之前，我们尝试的三种强化方法都提供了有希望的利润回报，总年利率约为70%至90%，而在2021年后仍能保持正利润回报，总年利率约为2%至7%。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2306.03985v2">PDF</a> Published as a workshop paper at ICLR 2023: AI for Agent Based   Modeling</p>
<p><strong>Summary</strong><br>     利用深度学习强化学习方法开发自动化股票交易代理管道，包含深度Q学习、深度SARSA和策略梯度法。在包括Google、Apple等流行股票上表现良好，于不同时期表现出良好与不同程度的收益回报。对于不同时期市场环境下的良好与坏结果有测试并显示具体回报百分比。对今后市场环境而言亦有不错表现。这是一个帮助快速分析与制定策略的强化学习自动化股票交易项目。</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>利用强化学习技术自动化股票交易分析过程。</li>
<li>开发了一种模拟股票交易环境的管道系统。</li>
<li>在多种流行股票上进行了测试，包括Google、Apple等。</li>
<li>在不同时期的市场环境下表现出良好的盈利表现，特别是在良好时期表现尤为突出。</li>
<li>在近年来的市场环境下依然能够保持盈利表现。</li>
<li>通过深度Q学习、深度SARSA和策略梯度法三种强化学习方法进行测试，并给出了具体的盈利百分比。</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2306.03985">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-c09a172b44f945ea3cc9daf925f31981.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-c3922197dd282eb0df92f05ad1ca5084.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-975280a3c6e9c11bbf30a0d997b31abb.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-672d8660fd847b40a216f6d20b906e8f.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-3967f213669dd215ec28e958349eceee.jpg" align="middle">
</details>


<h1 id="-12"><a href="#-12" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        文章作者:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        文章链接:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-05-21/Agent/">https://kedreamix.github.io/Talk2Paper/Paper/2025-05-21/Agent/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        版权声明:
                    </i>
                </span>
                <span class="reprint-info">
                    本博客所有文章除特別声明外，均采用
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    许可协议。转载请注明来源
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/Agent/">
                                    <span class="chip bg-color">Agent</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;上一篇</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-05-21/MMT/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-d3ec637713004f9dcd03966fd2af0c98.jpg" class="responsive-img" alt="MMT">
                        
                        <span class="card-title">MMT</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            MMT 方向最新论文已更新，请持续关注 Update in 2025-05-21  Unified Cross-modal Translation of Score Images, Symbolic Music, and   Performance Audio
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-05-21
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/MMT/" class="post-category">
                                    MMT
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/MMT/">
                        <span class="chip bg-color">MMT</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-05-21/LLM/">
                    <div class="card-image">
                        
                        <img src="https://pic1.zhimg.com/v2-1103a4e20d6934d949a1b818d06d3b19.jpg" class="responsive-img" alt="LLM">
                        
                        <span class="card-title">LLM</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            LLM 方向最新论文已更新，请持续关注 Update in 2025-05-21  Optimizing Anytime Reasoning via Budget Relative Policy Optimization
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-05-21
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/LLM/" class="post-category">
                                    LLM
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/LLM/">
                        <span class="chip bg-color">LLM</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- 代码语言 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span
                        class="white-color">19211.3k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- 运行天数提醒. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // 区分是否有年份.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = '本站已运行 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                daysTip = '本站已運行 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = '本站已运行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = '本站已運行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="关注我的知乎: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">知</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- 白天和黑夜主题 -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // 只在桌面版网页启用特效
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- 雪花特效 -->
    

    <!-- 鼠标星星特效 -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--腾讯兔小巢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- 动态标签 -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Σ(っ °Д °;)っ诶，页面崩溃了嘛？", clearTimeout(st)) : (document.title = "φ(゜▽゜*)♪咦，又好了！", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
