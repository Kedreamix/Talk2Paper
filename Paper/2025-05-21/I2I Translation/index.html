<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="I2I Translation">
    <meta name="description" content="I2I Translation æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-05-21  Unified Cross-modal Translation of Score Images, Symbolic Music, and   Performance Audio">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>I2I Translation | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://picx.zhimg.com/v2-0c0a12e0cc68f8d5a98251283187ccc4.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">I2I Translation</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/I2I-Translation/">
                                <span class="chip bg-color">I2I Translation</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/I2I-Translation/" class="post-category">
                                I2I Translation
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-05-21
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-05-27
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    6.4k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    26 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-05-21-æ›´æ–°"><a href="#2025-05-21-æ›´æ–°" class="headerlink" title="2025-05-21 æ›´æ–°"></a>2025-05-21 æ›´æ–°</h1><h2 id="Unified-Cross-modal-Translation-of-Score-Images-Symbolic-Music-and-Performance-Audio"><a href="#Unified-Cross-modal-Translation-of-Score-Images-Symbolic-Music-and-Performance-Audio" class="headerlink" title="Unified Cross-modal Translation of Score Images, Symbolic Music, and   Performance Audio"></a>Unified Cross-modal Translation of Score Images, Symbolic Music, and   Performance Audio</h2><p><strong>Authors:Jongmin Jung, Dongmin Kim, Sihun Lee, Seola Cho, Hyungjoon Soh, Irmak Bukey, Chris Donahue, Dasaem Jeong</strong></p>
<p>Music exists in various modalities, such as score images, symbolic scores, MIDI, and audio. Translations between each modality are established as core tasks of music information retrieval, such as automatic music transcription (audio-to-MIDI) and optical music recognition (score image to symbolic score). However, most past work on multimodal translation trains specialized models on individual translation tasks. In this paper, we propose a unified approach, where we train a general-purpose model on many translation tasks simultaneously. Two key factors make this unified approach viable: a new large-scale dataset and the tokenization of each modality. Firstly, we propose a new dataset that consists of more than 1,300 hours of paired audio-score image data collected from YouTube videos, which is an order of magnitude larger than any existing music modal translation datasets. Secondly, our unified tokenization framework discretizes score images, audio, MIDI, and MusicXML into a sequence of tokens, enabling a single encoder-decoder Transformer to tackle multiple cross-modal translation as one coherent sequence-to-sequence task. Experimental results confirm that our unified multitask model improves upon single-task baselines in several key areas, notably reducing the symbol error rate for optical music recognition from 24.58% to a state-of-the-art 13.67%, while similarly substantial improvements are observed across the other translation tasks. Notably, our approach achieves the first successful score-image-conditioned audio generation, marking a significant breakthrough in cross-modal music generation. </p>
<blockquote>
<p>éŸ³ä¹å­˜åœ¨äºå¤šç§æ¨¡æ€ä¸­ï¼Œå¦‚ä¹è°±å›¾åƒã€ç¬¦å·ä¹è°±ã€MIDIå’ŒéŸ³ä¹éŸ³é¢‘ã€‚å„ç§æ¨¡æ€ä¹‹é—´çš„ç¿»è¯‘è¢«ç¡®ç«‹ä¸ºéŸ³ä¹ä¿¡æ¯æ£€ç´¢çš„æ ¸å¿ƒä»»åŠ¡ï¼Œå¦‚è‡ªåŠ¨éŸ³ä¹è½¬å½•ï¼ˆéŸ³é¢‘åˆ°MIDIï¼‰å’Œä¹è°±è¯†åˆ«ï¼ˆä¹è°±å›¾åƒåˆ°ç¬¦å·ä¹è°±ï¼‰ã€‚ç„¶è€Œï¼Œè¿‡å»å¤§å¤šæ•°å…³äºå¤šæ¨¡æ€ç¿»è¯‘çš„å·¥ä½œéƒ½æ˜¯åœ¨å•ä¸ªç¿»è¯‘ä»»åŠ¡ä¸Šè®­ç»ƒç‰¹å®šæ¨¡å‹ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§é€šç”¨æ–¹æ³•ï¼Œå³åŒæ—¶è®­ç»ƒå¤šä¸ªç¿»è¯‘ä»»åŠ¡çš„é€šç”¨æ¨¡å‹ã€‚ä¸¤ä¸ªå…³é”®å› ç´ ä½¿è¿™ç§ç»Ÿä¸€çš„æ–¹æ³•å¯è¡Œï¼šä¸€æ˜¯æ–°çš„å¤§è§„æ¨¡æ•°æ®é›†å’Œæ¯ç§æ¨¡æ€çš„æ ‡è®°åŒ–ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªæ–°çš„æ•°æ®é›†ï¼Œè¯¥æ•°æ®é›†åŒ…å«ä»YouTubeè§†é¢‘æ”¶é›†çš„è¶…è¿‡1300å°æ—¶çš„é…å¯¹éŸ³é¢‘ä¹è°±å›¾åƒæ•°æ®ï¼Œå…¶è§„æ¨¡æ˜¯ç°æœ‰éŸ³ä¹æ¨¡æ€ç¿»è¯‘æ•°æ®é›†çš„åå€ã€‚å…¶æ¬¡ï¼Œæˆ‘ä»¬çš„ç»Ÿä¸€æ ‡è®°åŒ–æ¡†æ¶å°†ä¹è°±å›¾åƒã€éŸ³é¢‘ã€MIDIå’ŒMusicXMLç¦»æ•£æˆä¸€ç³»åˆ—æ ‡è®°ï¼Œä½¿å¾—å•ä¸ªç¼–ç å™¨-è§£ç å™¨è½¬æ¢å™¨èƒ½å¤Ÿä½œä¸ºä¸€ä¸ªè¿è´¯çš„åºåˆ—åˆ°åºåˆ—ä»»åŠ¡æ¥å¤„ç†å¤šä¸ªè·¨æ¨¡æ€ç¿»è¯‘ã€‚å®éªŒç»“æœè¯å®ï¼Œæˆ‘ä»¬çš„å¤šä»»åŠ¡ç»Ÿä¸€æ¨¡å‹åœ¨å‡ ä¸ªå…³é”®é¢†åŸŸä¼˜äºå•ä»»åŠ¡åŸºçº¿æ¨¡å‹ï¼Œç‰¹åˆ«æ˜¯å°†ä¹è°±è¯†åˆ«çš„ç¬¦å·é”™è¯¯ç‡ä»24.58%é™ä½åˆ°æœ€å…ˆè¿›çš„13.67%ï¼ŒåŒæ—¶åœ¨å…¶ä»–ç¿»è¯‘ä»»åŠ¡ä¸Šä¹Ÿè§‚å¯Ÿåˆ°äº†ç±»ä¼¼çš„æ˜¾è‘—æ”¹è¿›ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œæˆ‘ä»¬çš„æ–¹æ³•å®ç°äº†é¦–æ¬¡ä¹è°±å›¾åƒæ¡ä»¶ä¸‹çš„éŸ³é¢‘ç”Ÿæˆï¼Œæ ‡å¿—ç€è·¨æ¨¡æ€éŸ³ä¹ç”Ÿæˆæ–¹é¢çš„ä¸€ä¸ªé‡å¤§çªç ´ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.12863v1">PDF</a> Submitted to IEEE Transactions on Audio, Speech and Language   Processing (TASLPRO)</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºä¸€ç§ç»Ÿä¸€çš„å¤šæ¨¡æ€éŸ³ä¹ç¿»è¯‘æ–¹æ³•ï¼Œè¯¥æ–¹æ³•ä½¿ç”¨ä¸€ä¸ªé€šç”¨æ¨¡å‹åŒæ—¶å¤„ç†å¤šç§ç¿»è¯‘ä»»åŠ¡ï¼ŒåŒ…æ‹¬éŸ³é¢‘è½¬MIDIå’Œä¹è°±å›¾åƒè½¬ä¹è°±ç¬¦å·ç­‰ã€‚è¯¥ç ”ç©¶åˆ›æ–°ç‚¹åœ¨äºï¼šä¸€æ˜¯æ„å»ºäº†ä¸€ä¸ªå¤§è§„æ¨¡çš„å¤šæ¨¡æ€éŸ³ä¹ç¿»è¯‘æ•°æ®é›†ï¼ŒåŒ…å«è¶…è¿‡1300å°æ—¶çš„éŸ³é¢‘å’Œä¹è°±å›¾åƒé…å¯¹æ•°æ®ï¼›äºŒæ˜¯æå‡ºäº†ä¸€ä¸ªç»Ÿä¸€çš„ç¬¦å·åŒ–æ¡†æ¶ï¼Œå°†ä¹è°±å›¾åƒã€éŸ³é¢‘ã€MIDIå’ŒéŸ³ä¹XMLç­‰æ ¼å¼ç¦»æ•£åŒ–ä¸ºä¸€ç³»åˆ—ç¬¦å·åºåˆ—ï¼Œä½¿å¾—ä¸€ä¸ªå•ä¸€çš„ç¼–ç è§£ç å™¨å°±èƒ½å¤Ÿå¤„ç†å¤šä¸ªè·¨æ¨¡æ€ç¿»è¯‘ä»»åŠ¡ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥ç»Ÿä¸€å¤šä»»åŠ¡æ¨¡å‹åœ¨å¤šä¸ªå…³é”®é¢†åŸŸä¼˜äºå•ä»»åŠ¡åŸºå‡†æ¨¡å‹ï¼Œå¦‚å…‰å­¦éŸ³ä¹è¯†åˆ«çš„ç¬¦å·é”™è¯¯ç‡ä»24.58%é™ä½åˆ°æœ€æ–°çš„13.67%ã€‚æ­¤å¤–ï¼Œè¯¥ç ”ç©¶è¿˜é¦–æ¬¡å®ç°äº†åŸºäºä¹è°±å›¾åƒæ¡ä»¶çš„éŸ³é¢‘ç”Ÿæˆï¼Œæ ‡å¿—ç€è·¨æ¨¡æ€éŸ³ä¹ç”Ÿæˆé¢†åŸŸçš„ä¸€ä¸ªé‡å¤§çªç ´ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ç ”ç©¶æå‡ºäº†ä¸€ä¸ªç»Ÿä¸€çš„å¤šæ¨¡æ€éŸ³ä¹ç¿»è¯‘æ–¹æ³•ï¼Œæ¶µç›–å¤šç§éŸ³ä¹æ¨¡æ€ä¹‹é—´çš„ç¿»è¯‘ä»»åŠ¡ã€‚</li>
<li>æ„å»ºäº†ä¸€ä¸ªå¤§è§„æ¨¡çš„éŸ³ä¹æ¨¡æ€ç¿»è¯‘æ•°æ®é›†ï¼ŒåŒ…å«éŸ³é¢‘å’Œä¹è°±å›¾åƒé…å¯¹æ•°æ®ã€‚</li>
<li>æå‡ºäº†ä¸€ä¸ªç»Ÿä¸€çš„ç¬¦å·åŒ–æ¡†æ¶ï¼Œå°†ä¸åŒéŸ³ä¹æ¨¡æ€è½¬æ¢ä¸ºç¬¦å·åºåˆ—ï¼Œä¸ºç»Ÿä¸€æ¨¡å‹å¤„ç†å¤šæ¨¡æ€ç¿»è¯‘ä»»åŠ¡æä¾›äº†å¯èƒ½ã€‚</li>
<li>ç»Ÿä¸€å¤šä»»åŠ¡æ¨¡å‹åœ¨è·¨æ¨¡æ€éŸ³ä¹ç¿»è¯‘ä»»åŠ¡ä¸Šè¡¨ç°å‡ºä¼˜å¼‚æ€§èƒ½ï¼Œæ˜¾è‘—é™ä½äº†å…‰å­¦éŸ³ä¹è¯†åˆ«çš„ç¬¦å·é”™è¯¯ç‡ã€‚</li>
<li>ç ”ç©¶å®ç°äº†é¦–æ¬¡åŸºäºä¹è°±å›¾åƒæ¡ä»¶çš„éŸ³é¢‘ç”Ÿæˆï¼Œæ ‡å¿—ç€è·¨æ¨¡æ€éŸ³ä¹ç”Ÿæˆçš„é‡è¦è¿›å±•ã€‚</li>
<li>è¯¥ç ”ç©¶ä¸ºéŸ³ä¹ä¿¡æ¯æ£€ç´¢ä¸­çš„å¤šæ¨¡æ€ç¿»è¯‘ä»»åŠ¡æä¾›äº†æ–°çš„æ€è·¯å’Œæ–¹æ³•ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.12863">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-1a223183fb176ab81ab89175c9726687.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-3d5cadc55808ebc7fccd5cec3fe54c7d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-5dccfac73f319fc103a37e8dcb72563a.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-d3ec637713004f9dcd03966fd2af0c98.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-ef52a0d56c85acf174ea222360d85b3e.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="RoboFAC-A-Comprehensive-Framework-for-Robotic-Failure-Analysis-and-Correction"><a href="#RoboFAC-A-Comprehensive-Framework-for-Robotic-Failure-Analysis-and-Correction" class="headerlink" title="RoboFAC: A Comprehensive Framework for Robotic Failure Analysis and   Correction"></a>RoboFAC: A Comprehensive Framework for Robotic Failure Analysis and   Correction</h2><p><strong>Authors:Weifeng Lu, Minghao Ye, Zewei Ye, Ruihan Tao, Shuo Yang, Bo Zhao</strong></p>
<p>Vision-Language-Action (VLA) models have recently advanced robotic manipulation by translating natural-language instructions and image information into sequential control actions. However, these models often underperform in open-world scenarios, as they are predominantly trained on successful expert demonstrations and exhibit a limited capacity for failure recovery. In this work, we present a Robotic Failure Analysis and Correction (RoboFAC) framework to address this issue. Firstly, we construct RoboFAC dataset comprising 9,440 erroneous manipulation trajectories and 78,623 QA pairs across 16 diverse tasks and 53 scenes in both simulation and real-world environments. Leveraging our dataset, we develop RoboFAC model, which is capable of Task Understanding, Failure Analysis and Failure Correction. Experimental results demonstrate that the RoboFAC model outperforms GPT-4o by 34.1% on our evaluation benchmark. Furthermore, we integrate the RoboFAC model into a real-world VLA control pipeline as an external supervision providing correction instructions, yielding a 29.1% relative improvement on average on four real-world tasks. The results show that our RoboFAC framework effectively handles robotic failures and assists the VLA model in recovering from failures. </p>
<blockquote>
<p>è§†è§‰è¯­è¨€åŠ¨ä½œï¼ˆVLAï¼‰æ¨¡å‹æœ€è¿‘é€šè¿‡å°†è‡ªç„¶è¯­è¨€æŒ‡ä»¤å’Œå›¾åƒä¿¡æ¯ç¿»è¯‘æˆä¸€ç³»åˆ—æ§åˆ¶åŠ¨ä½œï¼Œæ¨åŠ¨äº†æœºå™¨äººæ“ä½œæŠ€æœ¯çš„å‘å±•ã€‚ç„¶è€Œï¼Œè¿™äº›æ¨¡å‹åœ¨å¼€æ”¾ä¸–ç•Œåœºæ™¯ä¸­å¾€å¾€è¡¨ç°ä¸ä½³ï¼Œå› ä¸ºå®ƒä»¬ä¸»è¦åŸºäºæˆåŠŸçš„ä¸“å®¶æ¼”ç¤ºï¼Œå¹¶ä¸”åœ¨æ•…éšœæ¢å¤æ–¹é¢èƒ½åŠ›æœ‰é™ã€‚é’ˆå¯¹è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬åœ¨å·¥ä½œä¸­æå‡ºäº†æœºå™¨äººæ•…éšœåˆ†æä¸çº æ­£ï¼ˆRoboFACï¼‰æ¡†æ¶ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬æ„å»ºäº†RoboFACæ•°æ®é›†ï¼Œå…¶ä¸­åŒ…å«9440æ¡é”™è¯¯çš„æ“ä½œè½¨è¿¹å’Œ78623å¯¹é—®ç­”ï¼Œæ¶‰åŠä»¿çœŸå’ŒçœŸå®ç¯å¢ƒä¸­çš„16ä¸ªä»»åŠ¡å’Œ53ä¸ªåœºæ™¯ã€‚åˆ©ç”¨æˆ‘ä»¬çš„æ•°æ®é›†ï¼Œæˆ‘ä»¬å¼€å‘äº†RoboFACæ¨¡å‹ï¼Œå…·å¤‡ä»»åŠ¡ç†è§£ã€æ•…éšœåˆ†æå’Œæ•…éšœçº æ­£èƒ½åŠ›ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒRoboFACæ¨¡å‹åœ¨æˆ‘ä»¬çš„è¯„ä¼°åŸºå‡†æµ‹è¯•ä¸Šçš„è¡¨ç°ä¼˜äºGPT-4oï¼Œè¾¾åˆ°34.1%ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å°†RoboFACæ¨¡å‹é›†æˆåˆ°ç°å®ä¸–ç•Œä¸­çš„VLAæ§åˆ¶ç®¡é“ä¸­ï¼Œä½œä¸ºå¤–éƒ¨ç›‘ç£æä¾›çº æ­£æŒ‡ä»¤ï¼Œåœ¨å››ä¸ªçœŸå®ä»»åŠ¡ä¸Šå¹³å‡æé«˜äº†29.1%çš„ç›¸å¯¹è¡¨ç°ã€‚ç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„RoboFACæ¡†æ¶æœ‰æ•ˆåœ°å¤„ç†äº†æœºå™¨äººæ•…éšœï¼Œå¹¶å¸®åŠ©VLAæ¨¡å‹ä»æ•…éšœä¸­æ¢å¤ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.12224v1">PDF</a> </p>
<p><strong>Summary</strong><br>     è¯¥ç ”ç©¶æå‡ºäº†Robotic Failure Analysis and Correctionï¼ˆRoboFACï¼‰æ¡†æ¶ï¼Œä»¥è§£å†³Vision-Language-Actionï¼ˆVLAï¼‰æ¨¡å‹åœ¨å¼€æ”¾ä¸–ç•Œåœºæ™¯ä¸‹æ€§èƒ½ä¸è¶³çš„é—®é¢˜ã€‚è¯¥æ¡†æ¶æ„å»ºäº†åŒ…å«é”™è¯¯æ“ä½œè½¨è¿¹å’Œé—®ç­”å¯¹çš„RoboFACæ•°æ®é›†ï¼Œå¹¶å¼€å‘äº†å…·å¤‡ä»»åŠ¡ç†è§£ã€æ•…éšœåˆ†æå’Œæ•…éšœçº æ­£èƒ½åŠ›çš„RoboFACæ¨¡å‹ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒRoboFACæ¨¡å‹åœ¨è¯„ä¼°åŸºå‡†æµ‹è¯•ä¸Šä¼˜äºGPT-4oè¾¾34.1%ï¼Œå¹¶ä¸”é›†æˆåˆ°çœŸå®ä¸–ç•Œçš„VLAæ§åˆ¶ç®¡é“ä¸­åï¼Œå¹³å‡ç›¸å¯¹æ”¹è¿›ç‡ä¸º29.1%ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>VLAæ¨¡å‹é€šè¿‡å°†è‡ªç„¶è¯­è¨€æŒ‡ä»¤å’Œå›¾åƒä¿¡æ¯ç¿»è¯‘ä¸ºè¿ç»­çš„æ§åˆ¶åŠ¨ä½œï¼Œæ¨åŠ¨äº†æœºå™¨äººæ“ä½œçš„å‘å±•ã€‚</li>
<li>VLAæ¨¡å‹åœ¨å¼€æ”¾ä¸–ç•Œåœºæ™¯ä¸­çš„æ€§èƒ½æœ‰å¾…æé«˜ï¼Œå°¤å…¶å¯¹äºé”™è¯¯æ¢å¤çš„èƒ½åŠ›æœ‰é™ã€‚</li>
<li>ç ”ç©¶äººå‘˜æ„å»ºäº†RoboFACæ•°æ®é›†ï¼ŒåŒ…å«é”™è¯¯æ“ä½œè½¨è¿¹å’Œè·¨ä¸åŒä»»åŠ¡å’Œåœºæ™¯çš„é—®ç­”å¯¹ã€‚</li>
<li>å¼€å‘å‡ºçš„RoboFACæ¨¡å‹å…·å¤‡ä»»åŠ¡ç†è§£ã€æ•…éšœåˆ†æå’Œçº æ­£åŠŸèƒ½ã€‚</li>
<li>å®éªŒæ˜¾ç¤ºï¼ŒRoboFACæ¨¡å‹åœ¨è¯„ä¼°åŸºå‡†æµ‹è¯•ä¸Šçš„æ€§èƒ½ä¼˜äºGPT-4oè¾¾34.1%ã€‚</li>
<li>åœ¨çœŸå®ä¸–ç•Œçš„VLAæ§åˆ¶ç®¡é“ä¸­é›†æˆRoboFACæ¨¡å‹åï¼Œå®ç°äº†å¹³å‡ç›¸å¯¹æ”¹è¿›ç‡29.1%ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.12224">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-eea799b80640e0aa70556c743e3ed253.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-d721beeab6efb78459f0508c77139380.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-0c0a12e0cc68f8d5a98251283187ccc4.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-28a9190085b1bad16da446f77f187593.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d20e377315da7bbbc9c0cd5ad31d1a81.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="Evaluation-and-optimization-of-deep-learning-models-for-enhanced-detection-of-brain-cancer-using-transmission-optical-microscopy-of-thin-brain-tissue-samples"><a href="#Evaluation-and-optimization-of-deep-learning-models-for-enhanced-detection-of-brain-cancer-using-transmission-optical-microscopy-of-thin-brain-tissue-samples" class="headerlink" title="Evaluation and optimization of deep learning models for enhanced   detection of brain cancer using transmission optical microscopy of thin brain   tissue samples"></a>Evaluation and optimization of deep learning models for enhanced   detection of brain cancer using transmission optical microscopy of thin brain   tissue samples</h2><p><strong>Authors:Mohnish Sao, Mousa Alrubayan, Prabhakar Pradhan</strong></p>
<p>Optical transmission spectroscopy is one method to understand brain tissue structural properties from brain tissue biopsy samples, yet manual interpretation is resource intensive and prone to inter observer variability. Deep convolutional neural networks (CNNs) offer automated feature learning directly from raw brightfield images. Here, we evaluate ResNet50 and DenseNet121 on a curated dataset of 2,931 bright-field transmission optical microscopy images of thin brain tissue, split into 1,996 for training, 437 for validation, and 498 for testing. Our two stage transfer learning protocol involves initial training of a classifier head on frozen pretrained feature extractors, followed by fine tuning of deeper convolutional blocks with extensive data augmentation (rotations, flips, intensity jitter) and early stopping. DenseNet121 achieves 88.35 percent test accuracy, 0.9614 precision, 0.8667 recall, and 0.9116 F1 score the best performance compared to ResNet50 (82.12 percent, 0.9035, 0.8142, 0.8563). Detailed analysis of confusion matrices, training and validation curves, and classwise prediction distributions illustrates robust convergence and minimal bias. These findings demonstrate the superior generalization of dense connectivity on limited medical datasets and outline future directions for multi-class tumor grading and clinical translation. </p>
<blockquote>
<p>å…‰å­¦ä¼ è¾“å…‰è°±æ³•æ˜¯ä¸€ç§é€šè¿‡è„‘ç»„ç»‡æ´»æ£€æ ·æœ¬äº†è§£è„‘ç»„ç»‡ç»“æ„æ€§è´¨çš„æ–¹æ³•ï¼Œä½†äººå·¥è§£è¯»éœ€è¦è€—è´¹å¤§é‡èµ„æºï¼Œå¹¶ä¸”å®¹æ˜“å› è§‚å¯Ÿè€…ä¹‹é—´å·®å¼‚è€Œå¯¼è‡´ç»“æœå·®å¼‚ã€‚æ·±åº¦å·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNï¼‰å¯ä»¥ç›´æ¥ä»åŸå§‹æ˜åœºå›¾åƒä¸­å®ç°è‡ªåŠ¨åŒ–ç‰¹å¾å­¦ä¹ ã€‚åœ¨æ­¤ï¼Œæˆ‘ä»¬å¯¹åŒ…å«æœ‰ç”¨äºè®­ç»ƒçš„1996å¼ å›¾åƒã€ç”¨äºéªŒè¯çš„437å¼ å›¾åƒä»¥åŠç”¨äºæµ‹è¯•çš„498å¼ å›¾åƒçš„ç²¾é€‰æ•°æ®é›†è¿›è¡Œäº†ResNet50å’ŒDenseNet121è¯„ä¼°ã€‚æˆ‘ä»¬çš„ä¸¤é˜¶æ®µè¿ç§»å­¦ä¹ åè®®æ¶‰åŠé¦–å…ˆåœ¨å†»ç»“çš„é¢„è®­ç»ƒç‰¹å¾æå–å™¨ä¸Šè®­ç»ƒåˆ†ç±»å™¨å¤´éƒ¨ï¼Œç„¶åé€šè¿‡ä¸°å¯Œçš„æ•°æ®å¢å¼ºï¼ˆæ—‹è½¬ã€ç¿»è½¬ã€å¼ºåº¦æŠ–åŠ¨ï¼‰è¿›è¡Œæ›´æ·±çš„å·ç§¯å—çš„å¾®è°ƒå¹¶ä½¿ç”¨æ—©æœŸåœæ­¢ç­–ç•¥ã€‚DenseNet121åœ¨æµ‹è¯•é›†ä¸Šå–å¾—äº†æœ€ä½³æ€§èƒ½ï¼Œæµ‹è¯•å‡†ç¡®åº¦ä¸º88.35%ï¼Œç²¾ç¡®åº¦ã€å¬å›ç‡å’ŒF1åˆ†æ•°åˆ†åˆ«ä¸º0.9614ã€0.8667å’Œ0.9116ã€‚ä¸ResNet50ï¼ˆæµ‹è¯•å‡†ç¡®åº¦ä¸º82.12%ï¼Œç²¾ç¡®åº¦ã€å¬å›ç‡å’ŒF1åˆ†æ•°åˆ†åˆ«ä¸º0.9035ã€0.8142å’Œ0.8563ï¼‰ç›¸æ¯”å…·æœ‰ä¼˜åŠ¿ã€‚é€šè¿‡å¯¹æ··æ·†çŸ©é˜µã€è®­ç»ƒå’ŒéªŒè¯æ›²çº¿ä»¥åŠç±»åˆ«é¢„æµ‹åˆ†å¸ƒè¿›è¡Œè¯¦ç»†åˆ†æï¼Œæ˜¾ç¤ºå‡ºç¨³å¥çš„æ”¶æ•›æ€§å’Œè¾ƒå°çš„åå·®ã€‚è¿™äº›ç»“æœè¡¨æ˜å¯†é›†è¿æ¥åœ¨æœ‰é™çš„åŒ»å­¦æ•°æ®é›†ä¸Šå…·æœ‰ä¼˜è¶Šçš„ä¸€èˆ¬åŒ–èƒ½åŠ›ï¼Œå¹¶æ¦‚è¿°äº†æœªæ¥å¤šç±»è‚¿ç˜¤åˆ†çº§å’Œä¸´åºŠè½¬åŒ–çš„æ–¹å‘ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.11735v1">PDF</a> 10 pages, 5 figures</p>
<p><strong>Summary</strong>ï¼šåˆ©ç”¨å…‰å­¦ä¼ è¾“å…‰è°±æ³•äº†è§£è„‘ç»„ç»‡æ´»æ£€æ ·æœ¬çš„ç»“æ„ç‰¹æ€§ï¼Œä½†æ‰‹åŠ¨è§£è¯»éœ€è¦å¤§é‡èµ„æºä¸”æ˜“å‡ºç°è§‚å¯Ÿè€…é—´å·®å¼‚ã€‚æœ¬ç ”ç©¶é‡‡ç”¨æ·±åº¦å·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNï¼‰ç›´æ¥ä»åŸå§‹æ˜åœºå›¾åƒä¸­å­¦ä¹ ç‰¹å¾ï¼Œå¯¹ResNet50å’ŒDenseNet121è¿›è¡Œè¯„ä¼°ã€‚åœ¨ç²¾é€‰çš„åŒ…å«2931å¼ è–„è„‘ç»„ç»‡æ˜åœºé€å°„å…‰å­¦æ˜¾å¾®é•œå›¾åƒçš„æ•°æ®é›†ä¸Šï¼Œåº”ç”¨ä¸¤é˜¶æ®µè¿ç§»å­¦ä¹ åè®®ï¼Œå®ç°åˆ†ç±»å™¨å¤´éƒ¨çš„åˆæ­¥è®­ç»ƒä»¥åŠå¯¹å†»ç»“çš„é¢„è®­ç»ƒç‰¹å¾æå–å™¨çš„ç²¾ç»†è°ƒæ•´ã€‚é€šè¿‡æ•°æ®å¢å¼ºï¼ˆæ—‹è½¬ã€ç¿»è½¬ã€å¼ºåº¦æŠ–åŠ¨ï¼‰å’Œæ—©æœŸåœæ­¢ç­–ç•¥ï¼ŒDenseNet121å–å¾—äº†æœ€ä½³æ€§èƒ½ï¼Œæµ‹è¯•å‡†ç¡®åº¦ä¸º88.35%ï¼Œç²¾ç¡®åº¦ã€å¬å›ç‡å’ŒF1åˆ†æ•°åˆ†åˆ«ä¸º0.9614ã€0.8667å’Œ0.9116ã€‚è€ŒResNet50çš„æ€§èƒ½ç¨é€Šï¼Œå‡†ç¡®ç‡ä¸º82.12%ã€‚ç ”ç©¶ç»“æœè¡¨æ˜DenseNetå…·æœ‰ä¼˜è¶Šçš„æ³›åŒ–èƒ½åŠ›ï¼Œæœªæ¥æœ‰æœ›åº”ç”¨äºå¤šç±»è‚¿ç˜¤åˆ†çº§å’Œä¸´åºŠè½¬åŒ–ç ”ç©¶ã€‚</p>
<p><strong>Key Takeaways</strong>:</p>
<ul>
<li>æœ¬ç ”ç©¶ä½¿ç”¨æ·±åº¦å·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNï¼‰ä»è–„è„‘ç»„ç»‡æ˜åœºé€å°„å…‰å­¦æ˜¾å¾®é•œå›¾åƒä¸­è‡ªåŠ¨å­¦ä¹ ç‰¹å¾ã€‚</li>
<li>é€šè¿‡ä¸¤é˜¶æ®µè¿ç§»å­¦ä¹ åè®®ï¼ŒDenseNet121åœ¨æ•°æ®é›†ä¸Šå–å¾—äº†æœ€ä½³æ€§èƒ½ã€‚</li>
<li>DenseNet121çš„æµ‹è¯•å‡†ç¡®åº¦è¾¾åˆ°88.35%ï¼Œå¹¶ä¸”å…·æœ‰è¾ƒé«˜çš„ç²¾ç¡®åº¦ã€å¬å›ç‡å’ŒF1åˆ†æ•°ã€‚</li>
<li>ç ”ç©¶è¡¨æ˜DenseNetå…·æœ‰ä¼˜è¶Šçš„æ³›åŒ–èƒ½åŠ›ï¼Œå°¤å…¶åœ¨æœ‰é™çš„åŒ»å­¦æ•°æ®é›†ä¸Šã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.11735">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-736b31df4f8ccfb8023b1def31398409.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-6f41c0c47b5fff1a002e3bf704b07e69.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-945dc21300ba24d5b54a51a28e85f3b4.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-a2a48cd6105529db4575d10a05a59f91.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b1d6409e5eb1888eee6f00e5afd70392.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="PrePrompt-Predictive-prompting-for-class-incremental-learning"><a href="#PrePrompt-Predictive-prompting-for-class-incremental-learning" class="headerlink" title="PrePrompt: Predictive prompting for class incremental learning"></a>PrePrompt: Predictive prompting for class incremental learning</h2><p><strong>Authors:Libo Huang, Zhulin An, Chuanguang Yang, Boyu Diao, Fei Wang, Yan Zeng, Zhifeng Hao, Yongjun Xu</strong></p>
<p>Class Incremental Learning (CIL) based on pre-trained models offers a promising direction for open-world continual learning. Existing methods typically rely on correlation-based strategies, where an imageâ€™s classification feature is used as a query to retrieve the most related key prompts and select the corresponding value prompts for training. However, these approaches face an inherent limitation: fitting the entire feature space of all tasks with only a few trainable prompts is fundamentally challenging. We propose Predictive Prompting (PrePrompt), a novel CIL framework that circumvents correlation-based limitations by leveraging pre-trained modelsâ€™ natural classification ability to predict task-specific prompts. Specifically, PrePrompt decomposes CIL into a two-stage prediction framework: task-specific prompt prediction followed by label prediction. While theoretically appealing, this framework risks bias toward recent classes due to missing historical data for older classifier calibration. PrePrompt then mitigates this by incorporating feature translation, dynamically balancing stability and plasticity. Experiments across multiple benchmarks demonstrate PrePromptâ€™s superiority over state-of-the-art prompt-based CIL methods. Code available at \href{github.com&#x2F;libo-huang&#x2F;preprompt}{github.com&#x2F;libo-huang&#x2F;preprompt}. </p>
<blockquote>
<p>åŸºäºé¢„è®­ç»ƒæ¨¡å‹çš„ç±»å¢é‡å­¦ä¹ ï¼ˆCILï¼‰ä¸ºå¼€æ”¾ä¸–ç•ŒæŒç»­å­¦ä¹ æä¾›äº†æœ‰å‰æ™¯çš„æ–¹å‘ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸ä¾èµ–äºåŸºäºå…³è”çš„ç­–ç•¥ï¼Œå…¶ä¸­ä½¿ç”¨å›¾åƒçš„åˆ†ç±»ç‰¹å¾ä½œä¸ºæŸ¥è¯¢æ¥æ£€ç´¢æœ€ç›¸å…³çš„å…³é”®æç¤ºï¼Œå¹¶é€‰æ‹©ç›¸åº”çš„å€¼æç¤ºè¿›è¡Œè®­ç»ƒã€‚ç„¶è€Œï¼Œè¿™äº›æ–¹æ³•é¢ä¸´ä¸€ä¸ªå›ºæœ‰çš„å±€é™æ€§ï¼šç”¨å°‘æ•°å¯è®­ç»ƒæç¤ºæ¥é€‚åº”æ‰€æœ‰ä»»åŠ¡çš„æ•´ä½“ç‰¹å¾ç©ºé—´å…·æœ‰æ ¹æœ¬æŒ‘æˆ˜æ€§ã€‚æˆ‘ä»¬æå‡ºäº†é¢„æµ‹æç¤ºï¼ˆPrePromptï¼‰ï¼Œè¿™æ˜¯ä¸€ç§æ–°å‹CILæ¡†æ¶ï¼Œå®ƒé€šè¿‡åˆ©ç”¨é¢„è®­ç»ƒæ¨¡å‹çš„å¤©ç„¶åˆ†ç±»èƒ½åŠ›æ¥é¢„æµ‹ç‰¹å®šä»»åŠ¡çš„æç¤ºï¼Œä»è€Œé¿å…äº†åŸºäºå…³è”çš„é™åˆ¶ã€‚å…·ä½“æ¥è¯´ï¼ŒPrePromptå°†CILåˆ†è§£ä¸ºä¸€ä¸ªä¸¤é˜¶æ®µé¢„æµ‹æ¡†æ¶ï¼šç‰¹å®šä»»åŠ¡çš„æç¤ºé¢„æµ‹ï¼Œç„¶åæ˜¯æ ‡ç­¾é¢„æµ‹ã€‚è™½ç„¶è¿™åœ¨ç†è®ºä¸Šå¾ˆæœ‰å¸å¼•åŠ›ï¼Œä½†ç”±äºç¼ºå°‘æ—§åˆ†ç±»å™¨çš„å†å²æ•°æ®è¿›è¡Œæ ¡å‡†ï¼Œè¿™ä¸ªæ¡†æ¶å¯èƒ½åå‘æœ€è¿‘çš„ç±»åˆ«ã€‚PrePrompté€šè¿‡ç»“åˆç‰¹å¾ç¿»è¯‘æ¥å‡è½»è¿™ä¸€é—®é¢˜ï¼ŒåŠ¨æ€å¹³è¡¡ç¨³å®šæ€§å’Œå¯å¡‘æ€§ã€‚åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒPrePromptä¼˜äºæœ€å…ˆè¿›çš„åŸºäºæç¤ºçš„CILæ–¹æ³•ã€‚ä»£ç å¯åœ¨<a href="github.com/libo-huang/preprompt">github.com&#x2F;libo-huang&#x2F;preprompt</a>æ‰¾åˆ°ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.08586v2">PDF</a> 16 pages, 29 figures, conference</p>
<p><strong>Summary</strong></p>
<p>åŸºäºé¢„è®­ç»ƒæ¨¡å‹çš„ç±»å¢é‡å­¦ä¹ ï¼ˆCILï¼‰ä¸ºå¼€æ”¾ä¸–ç•ŒæŒç»­å­¦ä¹ æä¾›äº†æœ‰å‰æ™¯çš„æ–¹å‘ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸ä¾èµ–äºåŸºäºå…³è”çš„ç­–ç•¥ï¼Œä½¿ç”¨å›¾åƒçš„è¯†åˆ«ç‰¹å¾ä½œä¸ºæŸ¥è¯¢æ¥æ£€ç´¢æœ€ç›¸å…³çš„å…³é”®æç¤ºï¼Œå¹¶é€‰æ‹©å¯¹åº”çš„å€¼æç¤ºè¿›è¡Œè®­ç»ƒã€‚ç„¶è€Œï¼Œè¿™äº›æ–¹æ³•é¢ä¸´å†…åœ¨å±€é™ï¼šç”¨å°‘é‡å¯è®­ç»ƒæç¤ºæ¥æ‹Ÿåˆæ‰€æœ‰ä»»åŠ¡çš„æ•´ä¸ªç‰¹å¾ç©ºé—´å…·æœ‰æ ¹æœ¬æŒ‘æˆ˜æ€§ã€‚æˆ‘ä»¬æå‡ºé¢„æµ‹æç¤ºï¼ˆPrePromptï¼‰è¿™ä¸€æ–°å‹CILæ¡†æ¶ï¼Œé€šè¿‡åˆ©ç”¨é¢„è®­ç»ƒæ¨¡å‹çš„å¤©ç„¶åˆ†ç±»èƒ½åŠ›æ¥é¢„æµ‹ä»»åŠ¡ç‰¹å®šæç¤ºï¼Œä»è€Œè§„é¿äº†åŸºäºå…³è”çš„é™åˆ¶ã€‚PrePromptå°†CILåˆ†è§£ä¸ºä¸¤ä¸ªé˜¶æ®µï¼šä»»åŠ¡ç‰¹å®šæç¤ºé¢„æµ‹å’Œæ ‡ç­¾é¢„æµ‹ã€‚å°½ç®¡ç†è®ºä¸Šå…·æœ‰å¸å¼•åŠ›ï¼Œä½†ç”±äºç¼ºå°‘å¯¹æ—§åˆ†ç±»å™¨çš„æ ¡å‡†å†å²æ•°æ®ï¼Œæ­¤æ¡†æ¶å¯èƒ½åå‘æœ€è¿‘çš„ç±»åˆ«ã€‚PrePrompté€šè¿‡å¼•å…¥ç‰¹å¾ç¿»è¯‘æ¥å¹³è¡¡ç¨³å®šæ€§å’Œå¯å¡‘æ€§ï¼Œä»è€Œç¼“è§£è¿™ä¸€é—®é¢˜ã€‚åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒPrePromptä¼˜äºæœ€æ–°çš„æç¤ºå¼CILæ–¹æ³•ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ç±»å¢é‡å­¦ä¹ (CIL)æ˜¯å¼€æ”¾ä¸–ç•ŒæŒç»­å­¦ä¹ çš„ä¸€ä¸ªæœ‰å‰é€”çš„æ–¹å‘ã€‚</li>
<li>ç°æœ‰æ–¹æ³•ä¸»è¦ä¾èµ–åŸºäºå…³è”çš„ç­–ç•¥ï¼Œä½¿ç”¨å›¾åƒåˆ†ç±»ç‰¹å¾ä½œä¸ºæŸ¥è¯¢æ¥æ£€ç´¢æç¤ºã€‚</li>
<li>åŸºäºé¢„è®­ç»ƒæ¨¡å‹çš„PrePromptæ¡†æ¶é€šè¿‡é¢„æµ‹ä»»åŠ¡ç‰¹å®šæç¤ºæ¥è§„é¿å…³è”é™åˆ¶ã€‚</li>
<li>PrePromptå°†CILåˆ†è§£ä¸ºä»»åŠ¡ç‰¹å®šæç¤ºé¢„æµ‹å’Œæ ‡ç­¾é¢„æµ‹ä¸¤ä¸ªé˜¶æ®µã€‚</li>
<li>PrePromptå¯èƒ½åå‘æœ€è¿‘çš„ç±»åˆ«ï¼Œå› ä¸ºç¼ºå°‘æ—§åˆ†ç±»å™¨çš„æ ¡å‡†å†å²æ•°æ®ã€‚</li>
<li>ç‰¹å¾ç¿»è¯‘è¢«å¼•å…¥åˆ°PrePromptä¸­ä»¥å¹³è¡¡ç¨³å®šæ€§å’Œå¯å¡‘æ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.08586">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-facf7fa48b38a06aa66f71fd02a3bf1d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-32b5978e59d577d95ac59b8206c7d5a2.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-071d91910c0f8c3c56f90fa0b44b737e.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="Origin-Identification-for-Text-Guided-Image-to-Image-Diffusion-Models"><a href="#Origin-Identification-for-Text-Guided-Image-to-Image-Diffusion-Models" class="headerlink" title="Origin Identification for Text-Guided Image-to-Image Diffusion Models"></a>Origin Identification for Text-Guided Image-to-Image Diffusion Models</h2><p><strong>Authors:Wenhao Wang, Yifan Sun, Zongxin Yang, Zhentao Tan, Zhengdong Hu, Yi Yang</strong></p>
<p>Text-guided image-to-image diffusion models excel in translating images based on textual prompts, allowing for precise and creative visual modifications. However, such a powerful technique can be misused for spreading misinformation, infringing on copyrights, and evading content tracing. This motivates us to introduce the task of origin IDentification for text-guided Image-to-image Diffusion models (ID$^2$), aiming to retrieve the original image of a given translated query. A straightforward solution to ID$^2$ involves training a specialized deep embedding model to extract and compare features from both query and reference images. However, due to visual discrepancy across generations produced by different diffusion models, this similarity-based approach fails when training on images from one model and testing on those from another, limiting its effectiveness in real-world applications. To solve this challenge of the proposed ID$^2$ task, we contribute the first dataset and a theoretically guaranteed method, both emphasizing generalizability. The curated dataset, OriPID, contains abundant Origins and guided Prompts, which can be used to train and test potential IDentification models across various diffusion models. In the method section, we first prove the existence of a linear transformation that minimizes the distance between the pre-trained Variational Autoencoder (VAE) embeddings of generated samples and their origins. Subsequently, it is demonstrated that such a simple linear transformation can be generalized across different diffusion models. Experimental results show that the proposed method achieves satisfying generalization performance, significantly surpassing similarity-based methods ($+31.6%$ mAP), even those with generalization designs. The project is available at <a target="_blank" rel="noopener" href="https://id2icml.github.io/">https://id2icml.github.io</a>. </p>
<blockquote>
<p>æ–‡æœ¬å¼•å¯¼çš„å›¾åƒåˆ°å›¾åƒæ‰©æ•£æ¨¡å‹åœ¨æ ¹æ®æ–‡æœ¬æç¤ºè¿›è¡Œå›¾åƒè½¬æ¢æ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œå¯ä»¥è¿›è¡Œç²¾ç¡®å’Œåˆ›é€ æ€§çš„è§†è§‰ä¿®æ”¹ã€‚ç„¶è€Œï¼Œè¿™ç§å¼ºå¤§çš„æŠ€æœ¯å¯èƒ½ä¼šè¢«è¯¯ç”¨ï¼Œç”¨äºä¼ æ’­é”™è¯¯ä¿¡æ¯ã€ä¾µçŠ¯ç‰ˆæƒå’Œè§„é¿å†…å®¹è¿½è¸ªã€‚è¿™ä¿ƒä½¿æˆ‘ä»¬å¼•å…¥é’ˆå¯¹æ–‡æœ¬å¼•å¯¼çš„å›¾åƒåˆ°å›¾åƒæ‰©æ•£æ¨¡å‹çš„èµ·æºè¯†åˆ«ä»»åŠ¡ï¼ˆID$^2$ï¼‰ï¼Œæ—¨åœ¨æ£€ç´¢ç»™å®šç¿»è¯‘æŸ¥è¯¢çš„åŸå§‹å›¾åƒã€‚ä¸€ç§è§£å†³ID$^2$çš„ç›´è§‚æ–¹æ³•æ˜¯é€šè¿‡è®­ç»ƒä¸“é—¨çš„æ·±åº¦åµŒå…¥æ¨¡å‹æ¥æå–å’Œæ¯”è¾ƒæŸ¥è¯¢å›¾åƒå’Œå‚è€ƒå›¾åƒçš„ç‰¹å¾ã€‚ç„¶è€Œï¼Œç”±äºä¸åŒæ‰©æ•£æ¨¡å‹äº§ç”Ÿçš„å„ä»£å›¾åƒä¹‹é—´çš„è§†è§‰å·®å¼‚ï¼Œè¿™ç§åŸºäºç›¸ä¼¼åº¦çš„æ–¹æ³•åœ¨ç”¨ä¸€ä¸ªæ¨¡å‹è®­ç»ƒè€Œåœ¨å¦ä¸€ä¸ªæ¨¡å‹æµ‹è¯•æ—¶ä¼šå¤±è´¥ï¼Œä»è€Œé™åˆ¶äº†å…¶åœ¨ç°å®ä¸–ç•Œåº”ç”¨ä¸­çš„æœ‰æ•ˆæ€§ã€‚ä¸ºäº†è§£å†³æ‰€æå‡ºçš„ID$^2$ä»»åŠ¡çš„è¿™ä¸€æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æä¾›äº†ç¬¬ä¸€ä¸ªæ•°æ®é›†å’Œä¸€ç§ç†è®ºä¸Šæœ‰ä¿è¯çš„æ–¹æ³•ï¼Œä¸¤è€…éƒ½å¼ºè°ƒé€šç”¨æ€§ã€‚æˆ‘ä»¬ç²¾å¿ƒåˆ¶ä½œçš„æ•°æ®é›†OriPIDåŒ…å«ä¸°å¯Œçš„èµ·æºå’Œå¼•å¯¼æç¤ºï¼Œå¯ç”¨äºè®­ç»ƒå’Œæµ‹è¯•å„ç§æ‰©æ•£æ¨¡å‹çš„æ½œåœ¨è¯†åˆ«æ¨¡å‹ã€‚åœ¨æ–¹æ³•éƒ¨åˆ†ï¼Œæˆ‘ä»¬é¦–å…ˆè¯æ˜å­˜åœ¨ä¸€ä¸ªçº¿æ€§å˜æ¢å¯ä»¥æœ€å°åŒ–é¢„è®­ç»ƒå˜åˆ†è‡ªç¼–ç å™¨ï¼ˆVAEï¼‰ç”Ÿæˆçš„æ ·æœ¬åµŒå…¥ä¸å…¶åŸå§‹æ ·æœ¬ä¹‹é—´çš„è·ç¦»ã€‚éšåï¼Œæ¼”ç¤ºäº†è¿™ç§ç®€å•çš„çº¿æ€§å˜æ¢å¯ä»¥åœ¨ä¸åŒçš„æ‰©æ•£æ¨¡å‹ä¹‹é—´è¿›è¡Œæ³›åŒ–ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œæ‰€æå‡ºçš„æ–¹æ³•è¾¾åˆ°äº†ä»¤äººæ»¡æ„çš„æ³›åŒ–æ€§èƒ½ï¼Œæ˜¾è‘—è¶…è¶Šäº†åŸºäºç›¸ä¼¼åº¦çš„æ–¹æ³•ï¼ˆæé«˜31.6%çš„mAPï¼‰ï¼Œç”šè‡³æ˜¯é‚£äº›å…·æœ‰æ³›åŒ–è®¾è®¡çš„æ–¹æ³•ã€‚è¯¥é¡¹ç›®åœ¨<a target="_blank" rel="noopener" href="https://id2icml.github.ioå¯ç”¨./">https://id2icml.github.ioå¯ç”¨ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.02376v2">PDF</a> Accepted by ICML 2025</p>
<p><strong>Summary</strong>ï¼šæ–‡æœ¬å¼•å¯¼çš„å›¾åƒåˆ°å›¾åƒæ‰©æ•£æ¨¡å‹èƒ½å¤Ÿæ ¹æ®æ–‡æœ¬æç¤ºè¿›è¡Œç²¾ç¡®è€Œå¯Œæœ‰åˆ›æ„çš„å›¾åƒä¿®æ”¹ã€‚ä½†è¯¥æŠ€æœ¯å¯èƒ½ä¼šè¢«è¯¯ç”¨ï¼Œå¦‚ä¼ æ’­è¯¯å¯¼ä¿¡æ¯ã€ä¾µçŠ¯ç‰ˆæƒå’Œè§„é¿å†…å®¹è¿½è¸ªã€‚ä¸ºæ­¤ï¼Œæå‡ºäº†é’ˆå¯¹æ–‡æœ¬å¼•å¯¼çš„å›¾åƒåˆ°å›¾åƒæ‰©æ•£æ¨¡å‹çš„èµ·æºè¯†åˆ«ä»»åŠ¡ï¼ˆID$^2$ï¼‰ï¼Œæ—¨åœ¨æ£€ç´¢ç»™å®šç¿»è¯‘æŸ¥è¯¢çš„åŸå§‹å›¾åƒã€‚æˆ‘ä»¬ä¸ºæ­¤ä»»åŠ¡è´¡çŒ®ç¬¬ä¸€ä¸ªæ•°æ®é›†å’Œä¸€ç§ç†è®ºä¸Šæœ‰ä¿è¯çš„æ–¹æ³•ï¼Œéƒ½å¼ºè°ƒé€šç”¨æ€§ã€‚æ•°æ®é›†åŒ…å«ä¸°å¯Œçš„èµ·æºå’Œå¼•å¯¼æç¤ºï¼Œå¯ç”¨äºè®­ç»ƒå’Œæµ‹è¯•è·¨å„ç§æ‰©æ•£æ¨¡å‹çš„æ½œåœ¨è¯†åˆ«æ¨¡å‹ã€‚æ–¹æ³•éƒ¨åˆ†è¯æ˜å­˜åœ¨ä¸€ä¸ªçº¿æ€§å˜æ¢å¯ä»¥æœ€å°åŒ–ç”Ÿæˆæ ·æœ¬çš„é¢„è®­ç»ƒå˜åˆ†è‡ªç¼–ç å™¨åµŒå…¥ä¸å…¶èµ·æºä¹‹é—´çš„è·ç¦»ï¼Œè¿™ç§ç®€å•çš„çº¿æ€§å˜æ¢å¯ä»¥åœ¨ä¸åŒçš„æ‰©æ•£æ¨¡å‹ä¸­è¿›è¡Œæ³›åŒ–ã€‚å®éªŒç»“æœéªŒè¯äº†è¯¥æ–¹æ³•çš„è‰¯å¥½æ³›åŒ–æ€§èƒ½ï¼Œæ˜¾è‘—ä¼˜äºåŸºäºç›¸ä¼¼åº¦çš„æ–¹æ³•ï¼ˆæé«˜31.6%çš„mAPï¼‰ã€‚</p>
<p><strong>Key Takeaways</strong>:</p>
<ol>
<li>æ–‡æœ¬å¼•å¯¼çš„å›¾åƒåˆ°å›¾åƒæ‰©æ•£æ¨¡å‹å¯ä»¥æ ¹æ®æ–‡æœ¬æç¤ºè¿›è¡Œç²¾ç¡®å’Œåˆ›æ„çš„å›¾åƒä¿®æ”¹ã€‚</li>
<li>è¿™ç§æŠ€æœ¯å¯èƒ½è¢«è¯¯ç”¨ï¼Œå¯¼è‡´ä¼ æ’­è¯¯å¯¼ä¿¡æ¯ã€ä¾µçŠ¯ç‰ˆæƒå’Œè§„é¿å†…å®¹è¿½è¸ªç­‰é—®é¢˜ã€‚</li>
<li>é’ˆå¯¹æ­¤é—®é¢˜ï¼Œæå‡ºäº†èµ·æºè¯†åˆ«ä»»åŠ¡ï¼ˆID$^2$ï¼‰ï¼Œæ—¨åœ¨æ£€ç´¢ç»™å®šç¿»è¯‘æŸ¥è¯¢çš„åŸå§‹å›¾åƒã€‚</li>
<li>è´¡çŒ®äº†ä¸€ä¸ªé’ˆå¯¹ID$^2$ä»»åŠ¡çš„æ•°æ®é›†ï¼ˆOriPIDï¼‰ï¼ŒåŒ…å«ç”¨äºè®­ç»ƒå’Œæµ‹è¯•çš„èµ·æºå’Œå¼•å¯¼æç¤ºã€‚</li>
<li>æå‡ºäº†ä¸€ç§ç†è®ºä¸Šæœ‰ä¿è¯çš„æ–¹æ³•ï¼Œé€šè¿‡çº¿æ€§å˜æ¢æ¥æœ€å°åŒ–ç”Ÿæˆæ ·æœ¬ä¸å…¶èµ·æºä¹‹é—´çš„è·ç¦»ï¼Œå¹¶åœ¨ä¸åŒçš„æ‰©æ•£æ¨¡å‹ä¸­è¿›è¡Œæ³›åŒ–ã€‚</li>
<li>å®éªŒç»“æœè¡¨æ˜è¯¥æ–¹æ³•å…·æœ‰è‰¯å¥½çš„æ³›åŒ–æ€§èƒ½ï¼Œæ˜¾è‘—ä¼˜äºåŸºäºç›¸ä¼¼åº¦çš„æ–¹æ³•ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.02376">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-d8de49df7a1812a7b7969949c4e739e1.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d46e2f2c3483dfcfba22c6eb6f9b28ee.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-6cab6ee8cc28c13a3e3261d7b12d8c9c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-953a8b3e2f7ad28187df1b032ed5b565.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f009329749a2fb68399d6a6e2105ddbf.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="Multi-modal-MRI-Translation-via-Evidential-Regression-and-Distribution-Calibration"><a href="#Multi-modal-MRI-Translation-via-Evidential-Regression-and-Distribution-Calibration" class="headerlink" title="Multi-modal MRI Translation via Evidential Regression and Distribution   Calibration"></a>Multi-modal MRI Translation via Evidential Regression and Distribution   Calibration</h2><p><strong>Authors:Jiyao Liu, Shangqi Gao, Yuxin Li, Lihao Liu, Xin Gao, Zhaohu Xing, Junzhi Ning, Yanzhou Su, Xiao-Yong Zhang, Junjun He, Ningsheng Xu, Xiahai Zhuang</strong></p>
<p>Multi-modal Magnetic Resonance Imaging (MRI) translation leverages information from source MRI sequences to generate target modalities, enabling comprehensive diagnosis while overcoming the limitations of acquiring all sequences. While existing deep-learning-based multi-modal MRI translation methods have shown promising potential, they still face two key challenges: 1) lack of reliable uncertainty quantification for synthesized images, and 2) limited robustness when deployed across different medical centers. To address these challenges, we propose a novel framework that reformulates multi-modal MRI translation as a multi-modal evidential regression problem with distribution calibration. Our approach incorporates two key components: 1) an evidential regression module that estimates uncertainties from different source modalities and an explicit distribution mixture strategy for transparent multi-modal fusion, and 2) a distribution calibration mechanism that adapts to source-target mapping shifts to ensure consistent performance across different medical centers. Extensive experiments on three datasets from the BraTS2023 challenge demonstrate that our framework achieves superior performance and robustness across domains. </p>
<blockquote>
<p>å¤šæ¨¡æ€ç£å…±æŒ¯æˆåƒï¼ˆMRIï¼‰ç¿»è¯‘æŠ€æœ¯åˆ©ç”¨æºMRIåºåˆ—çš„ä¿¡æ¯æ¥ç”Ÿæˆç›®æ ‡æ¨¡æ€ï¼Œä»è€Œå®ç°å…¨é¢è¯Šæ–­ï¼ŒåŒæ—¶å…‹æœäº†è·å–æ‰€æœ‰åºåˆ—çš„å±€é™æ€§ã€‚è™½ç„¶ç°æœ‰çš„åŸºäºæ·±åº¦å­¦ä¹ çš„å¤šæ¨¡æ€MRIç¿»è¯‘æ–¹æ³•å·²æ˜¾ç¤ºå‡ºæœ‰å‰é€”çš„æ½œåŠ›ï¼Œä½†å®ƒä»¬ä»é¢ä¸´ä¸¤ä¸ªå…³é”®æŒ‘æˆ˜ï¼šä¸€æ˜¯åˆæˆå›¾åƒç¼ºä¹å¯é çš„ä¸ç¡®å®šæ€§é‡åŒ–ï¼ŒäºŒæ˜¯åœ¨ä¸åŒåŒ»ç–—ä¸­å¿ƒéƒ¨ç½²æ—¶çš„ç¨³å¥æ€§æœ‰é™ã€‚ä¸ºäº†è§£å†³è¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°çš„æ¡†æ¶ï¼Œå®ƒå°†å¤šæ¨¡æ€MRIç¿»è¯‘é‡æ–°è¡¨è¿°ä¸ºä¸€ä¸ªå…·æœ‰åˆ†å¸ƒæ ¡å‡†çš„å¤šæ¨¡æ€è¯æ®å›å½’é—®é¢˜ã€‚æˆ‘ä»¬çš„æ–¹æ³•åŒ…å«ä¸¤ä¸ªå…³é”®ç»„æˆéƒ¨åˆ†ï¼šä¸€æ˜¯è¯æ®å›å½’æ¨¡å—ï¼Œç”¨äºä¼°è®¡æ¥è‡ªä¸åŒæºæ¨¡æ€çš„ä¸ç¡®å®šæ€§ï¼Œå¹¶ç»™å‡ºä¸€ä¸ªé€æ˜çš„å¤šæ¨¡æ€èåˆæ˜¾å¼åˆ†å¸ƒæ··åˆç­–ç•¥ï¼›äºŒæ˜¯åˆ†å¸ƒæ ¡å‡†æœºåˆ¶ï¼Œè¯¥æœºåˆ¶èƒ½å¤Ÿé€‚åº”æºç›®æ ‡æ˜ å°„å˜åŒ–ï¼Œä»¥ç¡®ä¿åœ¨ä¸åŒåŒ»ç–—ä¸­å¿ƒä¹‹é—´çš„æ€§èƒ½ä¸€è‡´æ€§ã€‚åœ¨BraTS2023æŒ‘æˆ˜çš„ä¸‰ä¸ªæ•°æ®é›†ä¸Šçš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ¡†æ¶åœ¨è·¨åŸŸæ€§èƒ½æ–¹é¢è¡¨ç°å‡ºå“è¶Šçš„æ€§èƒ½å’Œç¨³å¥æ€§ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2407.07372v2">PDF</a> Early accepted by MICCAI 2025</p>
<p><strong>Summary</strong></p>
<p>å¤šæ¨¡æ€ç£å…±æŒ¯æˆåƒï¼ˆMRIï¼‰è½¬æ¢åˆ©ç”¨æºMRIåºåˆ—çš„ä¿¡æ¯ç”Ÿæˆç›®æ ‡æ¨¡æ€ï¼Œå®ç°å…¨é¢è¯Šæ–­ï¼ŒåŒæ—¶å…‹æœè·å–æ‰€æœ‰åºåˆ—çš„é™åˆ¶ã€‚é’ˆå¯¹ç°æœ‰æ·±åº¦å­¦ä¹ å¤šæ¨¡æ€MRIè½¬æ¢æ–¹æ³•é¢ä¸´çš„æŒ‘æˆ˜ï¼ŒåŒ…æ‹¬åˆæˆå›¾åƒçš„ä¸ç¡®å®šæ€§é‡åŒ–ä¸è¶³å’Œä¸åŒåŒ»ç–—ä¸­å¿ƒéƒ¨ç½²çš„é²æ£’æ€§æœ‰é™ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°çš„æ¡†æ¶ã€‚è¯¥æ¡†æ¶å°†å¤šæ¨¡æ€MRIè½¬æ¢é‡æ–°æ„å»ºä¸ºå¤šæ¨¡æ€è¯æ®å›å½’é—®é¢˜ï¼Œå¹¶å¼•å…¥åˆ†å¸ƒæ ¡å‡†æœºåˆ¶ã€‚é€šè¿‡è¯æ®å›å½’æ¨¡å—ä¼°è®¡ä¸åŒæºæ¨¡æ€çš„ä¸ç¡®å®šæ€§ï¼Œå¹¶é‡‡ç”¨é€æ˜å¤šæ¨¡æ€èåˆç­–ç•¥è¿›è¡Œåˆ†å¸ƒæ ¡å‡†ã€‚å®éªŒè¡¨æ˜ï¼Œè¯¥æ¡†æ¶åœ¨BraTS2023æŒ‘æˆ˜èµ›çš„ä¸‰ä¸ªæ•°æ®é›†ä¸Šè¡¨ç°å‡ºå“è¶Šçš„æ€§èƒ½å’Œè·¨åŸŸé²æ£’æ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤šæ¨¡æ€MRIè½¬æ¢åˆ©ç”¨æºMRIåºåˆ—ä¿¡æ¯ç”Ÿæˆç›®æ ‡æ¨¡æ€ï¼Œä¿ƒè¿›å…¨é¢è¯Šæ–­ã€‚</li>
<li>ç°æœ‰æ·±åº¦å­¦ä¹ å¤šæ¨¡æ€MRIè½¬æ¢æ–¹æ³•é¢ä¸´ä¸¤ä¸ªä¸»è¦æŒ‘æˆ˜ï¼šç¼ºä¹åˆæˆå›¾åƒçš„ä¸ç¡®å®šæ€§é‡åŒ–ä»¥åŠè·¨ä¸åŒåŒ»ç–—ä¸­å¿ƒçš„é²æ£’æ€§æœ‰é™ã€‚</li>
<li>æ–°æ¡†æ¶å°†å¤šæ¨¡æ€MRIè½¬æ¢é‡æ–°æ„å»ºä¸ºå¤šæ¨¡æ€è¯æ®å›å½’é—®é¢˜ï¼Œä»¥å¤„ç†æºMRIåºåˆ—çš„ä¸ç¡®å®šæ€§ã€‚</li>
<li>æ–°æ¡†æ¶å¼•å…¥è¯æ®å›å½’æ¨¡å—ï¼Œä»å¤šç§æºæ¨¡æ€ä¼°è®¡ä¸ç¡®å®šæ€§ï¼Œå¹¶é‡‡ç”¨é€æ˜çš„å¤šæ¨¡æ€èåˆç­–ç•¥ã€‚</li>
<li>åˆ†å¸ƒæ ¡å‡†æœºåˆ¶èƒ½å¤Ÿé€‚åº”æº-ç›®æ ‡æ˜ å°„å˜åŒ–ï¼Œç¡®ä¿åœ¨ä¸åŒåŒ»ç–—ä¸­å¿ƒä¹‹é—´çš„ä¸€è‡´æ€§èƒ½ã€‚</li>
<li>åœ¨BraTS2023æŒ‘æˆ˜èµ›çš„æ•°æ®é›†ä¸Šè¿›è¡Œçš„å¤§é‡å®éªŒè¡¨æ˜ï¼Œæ–°æ¡†æ¶åœ¨æ€§èƒ½å’Œé²æ£’æ€§æ–¹é¢è¡¨ç°å‡ºä¼˜è¶Šæ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2407.07372">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-82e23d5d6d2149263417f04e91c3b4a1.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-96123a9c6798b777cb76890db439723d.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-614ca8371fabf46ed2c2cdee9ead7e35.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-05-21/I2I%20Translation/">https://kedreamix.github.io/Talk2Paper/Paper/2025-05-21/I2I%20Translation/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/I2I-Translation/">
                                    <span class="chip bg-color">I2I Translation</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-05-21/%E8%A7%86%E9%A2%91%E7%90%86%E8%A7%A3/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-4a51de098d53d08fbc73756f3b7da7ab.jpg" class="responsive-img" alt="è§†é¢‘ç†è§£">
                        
                        <span class="card-title">è§†é¢‘ç†è§£</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            è§†é¢‘ç†è§£ æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-05-21  HiERO understanding the hierarchy of human behavior enhances reasoning   on egocentric videos
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-05-21
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/%E8%A7%86%E9%A2%91%E7%90%86%E8%A7%A3/" class="post-category">
                                    è§†é¢‘ç†è§£
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/%E8%A7%86%E9%A2%91%E7%90%86%E8%A7%A3/">
                        <span class="chip bg-color">è§†é¢‘ç†è§£</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-05-21/Few-Shot/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-50811f3e0aeae9bea6f916af2905c28b.jpg" class="responsive-img" alt="Few-Shot">
                        
                        <span class="card-title">Few-Shot</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Few-Shot æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-05-21  GMM-Based Comprehensive Feature Extraction and Relative Distance   Preservation For Few-Shot Cross-Modal Retrieval
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-05-21
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Few-Shot/" class="post-category">
                                    Few-Shot
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Few-Shot/">
                        <span class="chip bg-color">Few-Shot</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">24417.1k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
