<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Agent">
    <meta name="description" content="Agent æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-08-15  RAGulating Compliance A Multi-Agent Knowledge Graph for Regulatory QA">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>Agent | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://picx.zhimg.com/v2-84bd85b3a4fa71e30770edb169a9c624.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Agent</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/Agent/">
                                <span class="chip bg-color">Agent</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/Agent/" class="post-category">
                                Agent
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-08-15
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-08-29
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    14.7k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    59 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-08-15-æ›´æ–°"><a href="#2025-08-15-æ›´æ–°" class="headerlink" title="2025-08-15 æ›´æ–°"></a>2025-08-15 æ›´æ–°</h1><h2 id="RAGulating-Compliance-A-Multi-Agent-Knowledge-Graph-for-Regulatory-QA"><a href="#RAGulating-Compliance-A-Multi-Agent-Knowledge-Graph-for-Regulatory-QA" class="headerlink" title="RAGulating Compliance: A Multi-Agent Knowledge Graph for Regulatory QA"></a>RAGulating Compliance: A Multi-Agent Knowledge Graph for Regulatory QA</h2><p><strong>Authors:Bhavik Agarwal, Hemant Sunil Jomraj, Simone Kaplunov, Jack Krolick, Viktoria Rojkova</strong></p>
<p>Regulatory compliance question answering (QA) requires precise, verifiable information, and domain-specific expertise, posing challenges for Large Language Models (LLMs). In this work, we present a novel multi-agent framework that integrates a Knowledge Graph (KG) of Regulatory triplets with Retrieval-Augmented Generation (RAG) to address these demands. First, agents build and maintain an ontology-free KG by extracting subjectâ€“predicateâ€“object (SPO) triplets from regulatory documents and systematically cleaning, normalizing, deduplicating, and updating them. Second, these triplets are embedded and stored along with their corresponding textual sections and metadata in a single enriched vector database, allowing for both graph-based reasoning and efficient information retrieval. Third, an orchestrated agent pipeline leverages triplet-level retrieval for question answering, ensuring high semantic alignment between user queries and the factual â€œwho-did-what-to-whomâ€ core captured by the graph. Our hybrid system outperforms conventional methods in complex regulatory queries, ensuring factual correctness with embedded triplets, enabling traceability through a unified vector database, and enhancing understanding through subgraph visualization, providing a robust foundation for compliance-driven and broader audit-focused applications. </p>
<blockquote>
<p>ç›‘ç®¡åˆè§„é—®ç­”ï¼ˆQAï¼‰éœ€è¦ç²¾ç¡®ã€å¯éªŒè¯çš„ä¿¡æ¯å’Œç‰¹å®šé¢†åŸŸçš„ä¸“ä¸šçŸ¥è¯†ï¼Œè¿™å¯¹å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æå‡ºäº†æŒ‘æˆ˜ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°å‹çš„å¤šä»£ç†æ¡†æ¶ï¼Œè¯¥æ¡†æ¶å°†ç›‘ç®¡ä¸‰å…ƒç»„çš„çŸ¥è¯†å›¾è°±ä¸æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰ç›¸ç»“åˆï¼Œä»¥æ»¡è¶³è¿™äº›éœ€æ±‚ã€‚é¦–å…ˆï¼Œä»£ç†é€šè¿‡ä»ç›‘ç®¡æ–‡æ¡£ä¸­æå–ä¸»ä½“-è°“è¯­-å¯¹è±¡ï¼ˆSPOï¼‰ä¸‰å…ƒç»„æ¥æ„å»ºå’Œç»´æŠ¤æ— æœ¬ä½“è®ºçŸ¥è¯†å›¾è°±ï¼Œå¹¶ç³»ç»Ÿåœ°å¯¹å…¶è¿›è¡Œæ¸…ç†ã€å½’ä¸€åŒ–ã€å»é‡å’Œæ›´æ–°ã€‚å…¶æ¬¡ï¼Œè¿™äº›ä¸‰å…ƒç»„åµŒå…¥å¹¶ä¸å…¶ç›¸åº”çš„æ–‡æœ¬æ®µè½å’Œå…ƒæ•°æ®ä¸€èµ·å­˜å‚¨åœ¨å•ä¸ªä¸°å¯Œçš„å‘é‡æ•°æ®åº“ä¸­ï¼Œå…è®¸åŸºäºå›¾çš„æ¨ç†å’Œé«˜æ•ˆçš„ä¿¡æ¯æ£€ç´¢ã€‚ç¬¬ä¸‰ï¼ŒååŒçš„ä»£ç†ç®¡é“åˆ©ç”¨ä¸‰å…ƒç»„çº§åˆ«çš„æ£€ç´¢æ¥è¿›è¡Œé—®ç­”ï¼Œç¡®ä¿ç”¨æˆ·æŸ¥è¯¢ä¸å›¾ä¸­æ•è·çš„â€œè°åšäº†å“ªäº›è¡Œä¸ºå¯¹è°â€çš„æ ¸å¿ƒå†…å®¹ä¹‹é—´å­˜åœ¨é«˜åº¦è¯­ä¹‰å¯¹é½ã€‚æˆ‘ä»¬çš„æ··åˆç³»ç»Ÿåœ¨å¤æ‚çš„ç›‘ç®¡æŸ¥è¯¢ä¸­ä¼˜äºä¼ ç»Ÿæ–¹æ³•ï¼Œé€šè¿‡åµŒå…¥çš„ä¸‰å…ƒç»„ç¡®ä¿äº‹å®æ­£ç¡®æ€§ï¼Œé€šè¿‡ç»Ÿä¸€çš„å‘é‡æ•°æ®åº“å®ç°å¯è¿½æº¯æ€§ï¼Œå¹¶é€šè¿‡å­å›¾å¯è§†åŒ–å¢å¼ºç†è§£ï¼Œä¸ºåˆè§„é©±åŠ¨å’Œæ›´å¹¿æ³›çš„å®¡è®¡é‡ç‚¹åº”ç”¨æä¾›äº†ç¨³å¥çš„åŸºç¡€ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.09893v1">PDF</a> </p>
<p><strong>Summary</strong><br>     æœ¬ç ”ç©¶æå‡ºäº†ä¸€ç§æ–°å‹å¤šæ™ºèƒ½ä½“æ¡†æ¶ï¼Œé€šè¿‡æ•´åˆç›‘ç®¡çŸ¥è¯†å›¾è°±å’Œæ£€ç´¢å¢å¼ºç”ŸæˆæŠ€æœ¯æ¥è§£å†³ç›‘ç®¡åˆè§„é—®ç­”çš„æŒ‘æˆ˜ã€‚æ™ºèƒ½ä½“æ„å»ºå¹¶ç»´æŠ¤ä¸€ä¸ªæœ¬ä½“è‡ªç”±çš„KGï¼Œé€šè¿‡ä»ç›‘ç®¡æ–‡ä»¶ä¸­æå–SPOä¸‰å…ƒç»„å¹¶è¿›è¡Œæ¸…æ´—ã€å½’ä¸€åŒ–ã€å»é‡å’Œæ›´æ–°ã€‚è¿™äº›ä¸‰å…ƒç»„åµŒå…¥å¹¶å­˜å‚¨åœ¨ä¸°å¯Œçš„å‘é‡æ•°æ®åº“ä¸­ï¼Œæ”¯æŒåŸºäºå›¾çš„æ¨ç†å’Œé«˜æ•ˆçš„ä¿¡æ¯æ£€ç´¢ã€‚é€šè¿‡åˆ©ç”¨ä¸‰å…ƒç»„çº§åˆ«çš„æ£€ç´¢è¿›è¡Œé—®ç­”ï¼Œç¡®ä¿ç”¨æˆ·æŸ¥è¯¢ä¸å›¾å½¢æ•è·çš„â€œè°å¯¹è°åšäº†ä½•äº‹â€æ ¸å¿ƒä¹‹é—´çš„é«˜è¯­ä¹‰ä¸€è‡´æ€§ã€‚è¯¥æ··åˆç³»ç»Ÿåœ¨å¤æ‚ç›‘ç®¡æŸ¥è¯¢æ–¹é¢çš„è¡¨ç°ä¼˜äºä¼ ç»Ÿæ–¹æ³•ï¼Œç¡®ä¿äº‹å®æ­£ç¡®æ€§ã€é€šè¿‡ç»Ÿä¸€çš„å‘é‡æ•°æ®åº“è¿›è¡Œå¯è¿½æº¯æ€§ï¼Œå¹¶é€šè¿‡å­å›¾å¯è§†åŒ–å¢å¼ºç†è§£ï¼Œä¸ºåˆè§„é©±åŠ¨å’Œæ›´å¹¿æ³›çš„å®¡è®¡é‡ç‚¹åº”ç”¨æä¾›äº†ç¨³å¥çš„åŸºç¡€ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æœ¬ç ”ç©¶æå‡ºäº†ä¸€ä¸ªæ–°å‹çš„å¤šæ™ºèƒ½ä½“æ¡†æ¶æ¥è§£å†³ç›‘ç®¡åˆè§„é—®ç­”çš„æŒ‘æˆ˜ã€‚</li>
<li>æ™ºèƒ½ä½“é€šè¿‡æ„å»ºå¹¶ç»´æŠ¤ä¸€ä¸ªæœ¬ä½“è‡ªç”±çš„KGæ¥æå–SPOä¸‰å…ƒç»„ä¿¡æ¯ã€‚</li>
<li>KGä¸­çš„ä¸‰å…ƒç»„è¢«åµŒå…¥å¹¶å­˜å‚¨åœ¨ä¸°å¯Œçš„å‘é‡æ•°æ®åº“ä¸­ï¼Œæ”¯æŒåŸºäºå›¾çš„æ¨ç†å’Œé«˜æ•ˆçš„ä¿¡æ¯æ£€ç´¢ã€‚</li>
<li>è¯¥æ¡†æ¶åˆ©ç”¨ä¸‰å…ƒç»„çº§åˆ«çš„æ£€ç´¢è¿›è¡Œé—®ç­”ï¼Œæé«˜äº†ç”¨æˆ·æŸ¥è¯¢ä¸å›¾å½¢æ ¸å¿ƒä¹‹é—´çš„è¯­ä¹‰ä¸€è‡´æ€§ã€‚</li>
<li>æ··åˆç³»ç»Ÿåœ¨å¤æ‚ç›‘ç®¡æŸ¥è¯¢æ–¹é¢çš„è¡¨ç°ä¼˜äºä¼ ç»Ÿæ–¹æ³•ï¼Œç¡®ä¿äº†äº‹å®çš„æ­£ç¡®æ€§å’Œå¯è¿½æº¯æ€§ã€‚</li>
<li>å­å›¾å¯è§†åŒ–å¢å¼ºäº†ç³»ç»Ÿå¯¹ç›‘ç®¡ä¿¡æ¯çš„ç†è§£ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.09893">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-568dfe93864ae0b9949c976db49d73ae.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-ee8f4947836bfc7c1842e4d8c98b21c0.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-f4e2cb7f0ea4b8fa4560d4eb0f7b235a.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-0604d1794ea3edc8354f76c872b60e7e.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="AWorld-Dynamic-Multi-Agent-System-with-Stable-Maneuvering-for-Robust-GAIA-Problem-Solving"><a href="#AWorld-Dynamic-Multi-Agent-System-with-Stable-Maneuvering-for-Robust-GAIA-Problem-Solving" class="headerlink" title="AWorld: Dynamic Multi-Agent System with Stable Maneuvering for Robust   GAIA Problem Solving"></a>AWorld: Dynamic Multi-Agent System with Stable Maneuvering for Robust   GAIA Problem Solving</h2><p><strong>Authors:Zhitian Xie, Qintong Wu, Chengyue Yu, Chenyi Zhuang, Jinjie Gu</strong></p>
<p>The rapid advancement of large language models (LLMs) has empowered intelligent agents to leverage diverse external tools for solving complex real-world problems. However, as agents increasingly depend on multiple tools, they encounter new challenges: extended contexts from disparate sources and noisy or irrelevant tool outputs can undermine system reliability and accuracy. These challenges underscore the necessity for enhanced stability in agent-based systems. To address this, we introduce dynamic supervision and maneuvering mechanisms, constructing a robust and dynamic Multi-Agent System (MAS) architecture within the AWorld framework. In our approach, the Execution Agent invokes the Guard Agent at critical steps to verify and correct the reasoning process, effectively reducing errors arising from noise and bolstering problem-solving robustness. Extensive experiments on the GAIA test dataset reveal that our dynamic maneuvering mechanism significantly improves both the effectiveness and stability of solutions, outperforming single-agent system (SAS) and standard tool-augmented systems. As a result, our dynamic MAS system achieved first place among open-source projects on the prestigious GAIA leaderboard. These findings highlight the practical value of collaborative agent roles in developing more reliable and trustworthy intelligent systems. </p>
<blockquote>
<p>éšç€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„å¿«é€Ÿå‘å±•ï¼Œæ™ºèƒ½ä»£ç†èƒ½å¤Ÿåˆ©ç”¨å¤šç§å¤–éƒ¨å·¥å…·è§£å†³å¤æ‚çš„ç°å®ä¸–ç•Œé—®é¢˜ã€‚ç„¶è€Œï¼Œéšç€ä»£ç†è¶Šæ¥è¶Šä¾èµ–äºå¤šç§å·¥å…·ï¼Œå®ƒä»¬é¢ä¸´ç€æ–°çš„æŒ‘æˆ˜ï¼šæ¥è‡ªä¸åŒæ¥æºçš„æ‰©å±•ä¸Šä¸‹æ–‡å’Œå˜ˆæ‚æˆ–æ— å…³çš„å·¥å…·è¾“å‡ºå¯èƒ½ä¼šç ´åç³»ç»Ÿå¯é æ€§å’Œå‡†ç¡®æ€§ã€‚è¿™äº›æŒ‘æˆ˜å¼ºè°ƒäº†åŸºäºä»£ç†çš„ç³»ç»Ÿä¸­å¢å¼ºç¨³å®šæ€§çš„å¿…è¦æ€§ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬å¼•å…¥äº†åŠ¨æ€ç›‘ç£å’Œæ“ä½œæœºåˆ¶ï¼Œåœ¨AWorldæ¡†æ¶å†…æ„å»ºäº†ä¸€ä¸ªç¨³å¥ä¸”åŠ¨æ€çš„å¤šä»£ç†ç³»ç»Ÿï¼ˆMASï¼‰æ¶æ„ã€‚åœ¨æˆ‘ä»¬çš„æ–¹æ³•ä¸­ï¼Œæ‰§è¡Œä»£ç†ä¼šåœ¨å…³é”®æ­¥éª¤è°ƒç”¨å®ˆå«ä»£ç†æ¥éªŒè¯å’Œçº æ­£æ¨ç†è¿‡ç¨‹ï¼Œæœ‰æ•ˆåœ°å‡å°‘ç”±å™ªå£°å¼•èµ·çš„é”™è¯¯å¹¶å¢å¼ºè§£å†³é—®é¢˜çš„ç¨³å¥æ€§ã€‚åœ¨GAIAæµ‹è¯•æ•°æ®é›†ä¸Šçš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„åŠ¨æ€æ“ä½œæœºåˆ¶æ˜¾è‘—æé«˜äº†è§£å†³æ–¹æ¡ˆçš„æœ‰æ•ˆæ€§å’Œç¨³å®šæ€§ï¼Œä¼˜äºå•ä»£ç†ç³»ç»Ÿï¼ˆSASï¼‰å’Œæ ‡å‡†å·¥å…·å¢å¼ºç³»ç»Ÿã€‚å› æ­¤ï¼Œæˆ‘ä»¬çš„åŠ¨æ€MASç³»ç»Ÿåœ¨è‘—åçš„GAIAæ’è¡Œæ¦œä¸Šè·å¾—äº†å¼€æºé¡¹ç›®ç¬¬ä¸€åã€‚è¿™äº›å‘ç°å‡¸æ˜¾äº†åä½œä»£ç†è§’è‰²åœ¨å¼€å‘æ›´å¯é ã€æ›´å€¼å¾—ä¿¡èµ–çš„æ™ºèƒ½ç³»ç»Ÿä¸­çš„å®é™…ä»·å€¼ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.09889v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>å¤§å‹è¯­è¨€æ¨¡å‹çš„å¿«é€Ÿå‘å±•ä½¿å¾—æ™ºèƒ½ä»£ç†èƒ½å¤Ÿåˆ©ç”¨å¤šç§å¤–éƒ¨å·¥å…·è§£å†³å¤æ‚çš„ç°å®ä¸–ç•Œé—®é¢˜ã€‚ç„¶è€Œï¼Œéšç€ä»£ç†è¶Šæ¥è¶Šä¾èµ–äºå¤šç§å·¥å…·ï¼Œä»–ä»¬é¢ä¸´æ–°çš„æŒ‘æˆ˜ï¼šæ¥è‡ªä¸åŒæ¥æºçš„æ‰©å±•ä¸Šä¸‹æ–‡å’Œå˜ˆæ‚æˆ–æ— å…³çš„å·¥å…·è¾“å‡ºå¯èƒ½ä¼šç ´åç³»ç»Ÿå¯é æ€§å’Œå‡†ç¡®æ€§ã€‚ä¸ºè§£å†³è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬å¼•å…¥äº†åŠ¨æ€ç›‘ç£å’Œæ“ä½œæœºåˆ¶ï¼Œåœ¨AWorldæ¡†æ¶å†…æ„å»ºäº†ä¸€ä¸ªç¨³å¥ä¸”åŠ¨æ€çš„å¤šä»£ç†ç³»ç»Ÿï¼ˆMASï¼‰æ¶æ„ã€‚æ‰§è¡Œä»£ç†åœ¨å…³é”®æ­¥éª¤ä¸­è°ƒç”¨å®ˆå«ä»£ç†è¿›è¡ŒéªŒè¯å’Œæ ¡æ­£æ¨ç†è¿‡ç¨‹ï¼Œæœ‰æ•ˆé™ä½å™ªå£°å¼•èµ·çš„é”™è¯¯å¹¶æå‡é—®é¢˜è§£å†³çš„ç¨³å¥æ€§ã€‚åœ¨GAIAæµ‹è¯•æ•°æ®é›†ä¸Šçš„å¤§é‡å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„åŠ¨æ€æ“ä½œæœºåˆ¶æ˜¾è‘—æé«˜äº†è§£æ–¹æ¡ˆçš„æœ‰æ•ˆæ€§å’Œç¨³å®šæ€§ï¼Œä¼˜äºå•ä»£ç†ç³»ç»Ÿï¼ˆSASï¼‰å’Œæ ‡å‡†å·¥å…·å¢å¼ºç³»ç»Ÿã€‚å› æ­¤ï¼Œæˆ‘ä»¬çš„åŠ¨æ€MASç³»ç»Ÿåœ¨è‘—åçš„GAIAæ’è¡Œæ¦œä¸Šè·å¾—å¼€æºé¡¹ç›®ç¬¬ä¸€åã€‚è¿™äº›å‘ç°å‡¸æ˜¾äº†åä½œä»£ç†è§’è‰²åœ¨å¼€å‘æ›´å¯é ã€æ›´å€¼å¾—ä¿¡èµ–çš„æ™ºèƒ½ç³»ç»Ÿä¸­çš„å®é™…ä»·å€¼ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤§å‹è¯­è¨€æ¨¡å‹çš„å¿«é€Ÿå‘å±•ä¿ƒè¿›äº†æ™ºèƒ½ä»£ç†åˆ©ç”¨å¤–éƒ¨å·¥å…·è§£å†³å¤æ‚é—®é¢˜çš„èƒ½åŠ›ã€‚</li>
<li>ä¾èµ–å¤šä¸ªå·¥å…·å¸¦æ¥æŒ‘æˆ˜ï¼Œå¦‚ä¸Šä¸‹æ–‡åˆ†æ•£ã€å·¥å…·è¾“å‡ºå˜ˆæ‚æˆ–æ— å…³ã€‚</li>
<li>éœ€è¦å¢å¼ºä»£ç†ç³»ç»Ÿçš„ç¨³å®šæ€§ã€‚</li>
<li>å¼•å…¥åŠ¨æ€ç›‘ç£å’Œæ“ä½œæœºåˆ¶ï¼Œæ„å»ºç¨³å¥çš„å¤šä»£ç†ç³»ç»Ÿï¼ˆMASï¼‰æ¶æ„ã€‚</li>
<li>æ‰§è¡Œä»£ç†è°ƒç”¨å®ˆå«ä»£ç†è¿›è¡ŒéªŒè¯å’Œæ ¡æ­£ï¼Œé™ä½å™ªå£°é”™è¯¯ï¼Œæé«˜é—®é¢˜è§£å†³çš„ç¨³å¥æ€§ã€‚</li>
<li>åœ¨GAIAæµ‹è¯•æ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒåŠ¨æ€æ“ä½œæœºåˆ¶æé«˜è§£æ–¹æ¡ˆçš„æœ‰æ•ˆæ€§å’Œç¨³å®šæ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.09889">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-80c73558791f10bca819428af1a25ef0.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-deddb3ea5996422094aeaf80bb4e909c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-4971518c8d91fbacbc933a3bb909cef4.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-fdacbd56ed7c3536c5c998d69ed7b66e.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-4afcabdb16ee890dd11da85902e3501b.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="HumanGenesis-Agent-Based-Geometric-and-Generative-Modeling-for-Synthetic-Human-Dynamics"><a href="#HumanGenesis-Agent-Based-Geometric-and-Generative-Modeling-for-Synthetic-Human-Dynamics" class="headerlink" title="HumanGenesis: Agent-Based Geometric and Generative Modeling for   Synthetic Human Dynamics"></a>HumanGenesis: Agent-Based Geometric and Generative Modeling for   Synthetic Human Dynamics</h2><p><strong>Authors:Weiqi Li, Zehao Zhang, Liang Lin, Guangrun Wang</strong></p>
<p>\textbf{Synthetic human dynamics} aims to generate photorealistic videos of human subjects performing expressive, intention-driven motions. However, current approaches face two core challenges: (1) \emph{geometric inconsistency} and \emph{coarse reconstruction}, due to limited 3D modeling and detail preservation; and (2) \emph{motion generalization limitations} and \emph{scene inharmonization}, stemming from weak generative capabilities. To address these, we present \textbf{HumanGenesis}, a framework that integrates geometric and generative modeling through four collaborative agents: (1) \textbf{Reconstructor} builds 3D-consistent human-scene representations from monocular video using 3D Gaussian Splatting and deformation decomposition. (2) \textbf{Critique Agent} enhances reconstruction fidelity by identifying and refining poor regions via multi-round MLLM-based reflection. (3) \textbf{Pose Guider} enables motion generalization by generating expressive pose sequences using time-aware parametric encoders. (4) \textbf{Video Harmonizer} synthesizes photorealistic, coherent video via a hybrid rendering pipeline with diffusion, refining the Reconstructor through a Back-to-4D feedback loop. HumanGenesis achieves state-of-the-art performance on tasks including text-guided synthesis, video reenactment, and novel-pose generalization, significantly improving expressiveness, geometric fidelity, and scene integration. </p>
<blockquote>
<p><strong>åˆæˆäººç±»åŠ¨åŠ›å­¦</strong>æ—¨åœ¨ç”Ÿæˆè¡¨è¾¾æƒ…æ„Ÿã€å—æ„å›¾é©±åŠ¨åŠ¨ä½œçš„äººçš„çœŸå®è§†é¢‘ã€‚ç„¶è€Œï¼Œå½“å‰çš„æ–¹æ³•é¢ä¸´ä¸¤å¤§æŒ‘æˆ˜ï¼š(1)ç”±äºæœ‰é™çš„3Då»ºæ¨¡å’Œç»†èŠ‚ä¿ç•™å¯¼è‡´çš„<strong>å‡ ä½•ä¸ä¸€è‡´æ€§</strong>å’Œ<strong>ç²—ç³™é‡å»º</strong>ï¼›(2)ç”±äºç”Ÿæˆèƒ½åŠ›è¾ƒå¼±å¯¼è‡´çš„<strong>è¿åŠ¨æ³›åŒ–é™åˆ¶</strong>å’Œ<strong>åœºæ™¯ä¸å’Œè°</strong>ã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†<strong>HumanGenesis</strong>ï¼Œè¿™æ˜¯ä¸€ä¸ªé€šè¿‡å››ä¸ªåä½œä»£ç†æ•´åˆå‡ ä½•å’Œç”Ÿæˆå»ºæ¨¡çš„æ¡†æ¶ï¼š(1)<strong>é‡å»ºå™¨</strong>ä½¿ç”¨å•ç›®è§†é¢‘é€šè¿‡ä¸‰ç»´é«˜æ–¯æ‘Šé“ºå’Œå˜å½¢åˆ†è§£æ„å»ºä¸€è‡´çš„ä¸‰ç»´äººä½“åœºæ™¯è¡¨ç¤ºï¼›(2)<strong>æ‰¹è¯„ä»£ç†</strong>é€šè¿‡åŸºäºå¤šè½®MLLMçš„åå°„æ¥è¯†åˆ«å’Œç»†åŒ–ä¸è‰¯åŒºåŸŸï¼Œæé«˜é‡å»ºçš„ä¿çœŸåº¦ï¼›(3)<strong>å§¿æ€å¼•å¯¼è€…</strong>é€šè¿‡ä½¿ç”¨æ—¶é—´æ„ŸçŸ¥å‚æ•°ç¼–ç å™¨ç”Ÿæˆè¡¨è¾¾æ€§å§¿æ€åºåˆ—ï¼Œå®ç°è¿åŠ¨æ³›åŒ–ï¼›(4)<strong>è§†é¢‘åè°ƒå™¨</strong>é€šè¿‡ä¸€ä¸ªæ··åˆæ¸²æŸ“ç®¡é“ä¸æ‰©æ•£åˆæˆç°å®ä¸”è¿è´¯çš„è§†é¢‘ï¼Œå¹¶é€šè¿‡åé¦ˆå¾ªç¯æ”¹è¿›é‡å»ºå™¨ã€‚HumanGenesisåœ¨æ–‡æœ¬å¼•å¯¼åˆæˆã€è§†é¢‘é‡æ”¾å’Œæ–°é¢–å§¿æ€æ³›åŒ–ç­‰ä»»åŠ¡ä¸Šå®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œåœ¨è¡¨è¾¾æ€§ã€å‡ ä½•ä¿çœŸå’Œåœºæ™¯é›†æˆæ–¹é¢éƒ½æœ‰æ˜¾è‘—æé«˜ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.09858v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†åˆæˆäººç±»åŠ¨åŠ›å­¦ï¼ˆSynthetic human dynamicsï¼‰çš„ç›®æ ‡å’ŒæŒ‘æˆ˜ï¼Œå¹¶é˜è¿°äº†HumanGenesisæ¡†æ¶é€šè¿‡æ•´åˆå‡ ä½•å’Œç”Ÿæˆå»ºæ¨¡æ¥è§£å†³è¿™äº›é—®é¢˜çš„æ–¹æ³•ã€‚è¯¥æ¡†æ¶åŒ…æ‹¬å››ä¸ªåä½œä»£ç†ï¼šReconstructorã€Critique Agentã€Pose Guiderå’ŒVideo Harmonizerã€‚HumanGenesisåœ¨æ–‡æœ¬å¼•å¯¼åˆæˆã€è§†é¢‘é‡æ¼”ç»å’Œæ–°é¢–å§¿æ€æ¨å¹¿ç­‰ä»»åŠ¡ä¸Šå–å¾—äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œæ˜¾è‘—æé«˜äº†è¡¨ç°åŠ›ã€å‡ ä½•ä¿çœŸåº¦å’Œåœºæ™¯é›†æˆèƒ½åŠ›ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li><strong>Synthetic human dynamicsçš„ç›®æ ‡</strong>ï¼šç”Ÿæˆè¡¨ç°äººç±»è¡¨è¾¾æ„å›¾çš„è§†é¢‘ã€‚</li>
<li><strong>ä¸»è¦æŒ‘æˆ˜</strong>ï¼šå‡ ä½•ä¸ä¸€è‡´æ€§å’Œç²—ç³™é‡å»ºã€è¿åŠ¨æ¨å¹¿çš„å±€é™æ€§ä»¥åŠåœºæ™¯ä¸å’Œè°ã€‚</li>
<li><strong>HumanGenesisæ¡†æ¶çš„åŠŸèƒ½</strong>ï¼šé€šè¿‡å››ä¸ªåä½œä»£ç†è§£å†³ä¸Šè¿°é—®é¢˜ï¼ŒåŒ…æ‹¬é‡å»ºã€è¯„ä¼°ã€å§¿æ€å¼•å¯¼å’Œè§†é¢‘å’Œè°åŒ–ã€‚</li>
<li><strong>Reconstructorçš„ä½œç”¨</strong>ï¼šåˆ©ç”¨3Dé«˜æ–¯å–·å°„å’Œå˜å½¢åˆ†è§£ä»å•ç›®è§†é¢‘ä¸­æ„å»ºä¸€è‡´çš„3Däººç±»åœºæ™¯è¡¨ç¤ºã€‚</li>
<li><strong>Critique Agentçš„åŠŸèƒ½</strong>ï¼šé€šè¿‡å¤šè½®MLLMåé¦ˆå¢å¼ºé‡å»ºçš„å¿ å®åº¦ã€‚</li>
<li><strong>Pose Guiderçš„é‡è¦æ€§</strong>ï¼šé€šè¿‡æ—¶é—´æ„ŸçŸ¥å‚æ•°ç¼–ç å™¨ç”Ÿæˆè¡¨è¾¾æ€§å§¿æ€åºåˆ—ï¼Œå®ç°è¿åŠ¨æ¨å¹¿ã€‚</li>
<li><strong>Video Harmonizerçš„ä½œç”¨</strong>ï¼šé€šè¿‡æ··åˆæ¸²æŸ“ç®¡é“ä¸æ‰©æ•£æŠ€æœ¯ï¼Œåˆæˆé€¼çœŸçš„è¿è´¯è§†é¢‘ï¼Œå¹¶é€šè¿‡Back-to-4Dåé¦ˆå¾ªç¯ä¼˜åŒ–é‡å»ºè¿‡ç¨‹ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.09858">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-bb06d1e0e3fb6ddcc349d6f69ff864b8.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f8dc2ff97445f89f928b14db25ffcef7.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-5a5a313c233c7a7298c0fca946898426.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-0acb34337ca1635ffc17bbc026b456d4.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-e24333e3a1d25bab6870e3e5485f23c3.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="Seeing-Listening-Remembering-and-Reasoning-A-Multimodal-Agent-with-Long-Term-Memory"><a href="#Seeing-Listening-Remembering-and-Reasoning-A-Multimodal-Agent-with-Long-Term-Memory" class="headerlink" title="Seeing, Listening, Remembering, and Reasoning: A Multimodal Agent with   Long-Term Memory"></a>Seeing, Listening, Remembering, and Reasoning: A Multimodal Agent with   Long-Term Memory</h2><p><strong>Authors:Lin Long, Yichen He, Wentao Ye, Yiyuan Pan, Yuan Lin, Hang Li, Junbo Zhao, Wei Li</strong></p>
<p>We introduce M3-Agent, a novel multimodal agent framework equipped with long-term memory. Like humans, M3-Agent can process real-time visual and auditory inputs to build and update its long-term memory. Beyond episodic memory, it also develops semantic memory, enabling it to accumulate world knowledge over time. Its memory is organized in an entity-centric, multimodal format, allowing deeper and more consistent understanding of the environment. Given an instruction, M3-Agent autonomously performs multi-turn, iterative reasoning and retrieves relevant information from memory to accomplish the task. To evaluate memory effectiveness and memory-based reasoning in multimodal agents, we develop M3-Bench, a new long-video question answering benchmark. M3-Bench comprises 100 newly recorded real-world videos captured from a robotâ€™s perspective (M3-Bench-robot) and 929 web-sourced videos across diverse scenarios (M3-Bench-web). We annotate question-answer pairs designed to test key capabilities essential for agent applications, such as human understanding, general knowledge extraction, and cross-modal reasoning. Experimental results show that M3-Agent, trained via reinforcement learning, outperforms the strongest baseline, a prompting agent using Gemini-1.5-pro and GPT-4o, achieving 6.7%, 7.7%, and 5.3% higher accuracy on M3-Bench-robot, M3-Bench-web and VideoMME-long, respectively. Our work advances the multimodal agents toward more human-like long-term memory and provides insights into their practical design. Model, code and data are available at <a target="_blank" rel="noopener" href="https://github.com/bytedance-seed/m3-agent">https://github.com/bytedance-seed/m3-agent</a> </p>
<blockquote>
<p>æˆ‘ä»¬ä»‹ç»äº†M3-Agentï¼Œè¿™æ˜¯ä¸€ç§é…å¤‡é•¿æœŸè®°å¿†çš„æ–°å‹å¤šæ¨¡æ€ä»£ç†æ¡†æ¶ã€‚ä¸äººç±»ç›¸ä¼¼ï¼ŒM3-Agentèƒ½å¤Ÿå¤„ç†å®æ—¶çš„è§†è§‰å’Œå¬è§‰è¾“å…¥ï¼Œä»¥æ„å»ºå’Œæ›´æ–°å…¶é•¿æœŸè®°å¿†ã€‚é™¤äº†æƒ…æ™¯è®°å¿†ä¹‹å¤–ï¼Œå®ƒè¿˜å‘å±•å‡ºè¯­ä¹‰è®°å¿†ï¼Œä½¿å…¶èƒ½å¤Ÿéšç€æ—¶é—´çš„æ¨ç§»ç§¯ç´¯ä¸–ç•ŒçŸ¥è¯†ã€‚å®ƒçš„è®°å¿†ä»¥å®ä½“ä¸ºä¸­å¿ƒã€å¤šæ¨¡æ€çš„æ–¹å¼ç»„ç»‡ï¼Œå…è®¸å¯¹ç¯å¢ƒçš„æ›´æ·±å±‚æ¬¡å’Œæ›´ä¸€è‡´çš„ç†è§£ã€‚æ¥å—æŒ‡ä»¤åï¼ŒM3-Agentèƒ½å¤Ÿè‡ªä¸»è¿›è¡Œå¤šè½®è¿­ä»£æ¨ç†ï¼Œä»è®°å¿†ä¸­æ£€ç´¢ç›¸å…³ä¿¡æ¯ä»¥å®Œæˆä»»åŠ¡ã€‚ä¸ºäº†è¯„ä¼°å¤šæ¨¡æ€ä»£ç†ä¸­çš„è®°å¿†æ•ˆæœå’ŒåŸºäºè®°å¿†æ¨ç†çš„èƒ½åŠ›ï¼Œæˆ‘ä»¬å¼€å‘äº†M3-Benchï¼Œè¿™æ˜¯ä¸€ä¸ªæ–°çš„é•¿è§†é¢‘é—®ç­”åŸºå‡†æµ‹è¯•ã€‚M3-BenchåŒ…æ‹¬ä»æœºå™¨äººè§†è§’æ•è·çš„100ä¸ªæ–°å½•åˆ¶ç°å®ä¸–ç•Œè§†é¢‘ï¼ˆM3-Bench-robotï¼‰å’Œæ¶µç›–ä¸åŒåœºæ™¯çš„929ä¸ªç½‘ç»œè§†é¢‘ï¼ˆM3-Bench-webï¼‰ã€‚æˆ‘ä»¬æ³¨é‡Šäº†é—®é¢˜ç­”æ¡ˆå¯¹ï¼Œæ—¨åœ¨æµ‹è¯•ä»£ç†åº”ç”¨ç¨‹åºæ‰€éœ€çš„å…³é”®èƒ½åŠ›ï¼Œä¾‹å¦‚äººç±»ç†è§£ã€ä¸€èˆ¬çŸ¥è¯†æå–å’Œè·¨æ¨¡æ€æ¨ç†ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œé€šè¿‡å¼ºåŒ–å­¦ä¹ è®­ç»ƒçš„M3-Agentè¶…è¶Šäº†æœ€å¼ºåŸºçº¿â€”â€”ä½¿ç”¨Gemini-1.5-proå’ŒGPT-4oçš„æç¤ºä»£ç†ï¼Œåœ¨M3-Bench-robotã€M3-Bench-webå’ŒVideoMME-longä¸Šçš„å‡†ç¡®ç‡åˆ†åˆ«æé«˜äº†6.7%ã€7.7%å’Œ5.3%ã€‚æˆ‘ä»¬çš„å·¥ä½œä½¿å¤šæ¨¡æ€ä»£ç†æœç€æ›´ç±»ä¼¼äºäººç±»çš„é•¿æ—¶è®°å¿†æ–¹å‘å‘å±•ï¼Œå¹¶ä¸ºå…¶å®ç”¨è®¾è®¡æä¾›äº†è§è§£ã€‚æ¨¡å‹ã€ä»£ç å’Œæ•°æ®å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/bytedance-seed/m3-agent%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/bytedance-seed/m3-agentæ‰¾åˆ°ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.09736v1">PDF</a> </p>
<p><strong>Summary</strong><br>     å¼•å…¥äº†ä¸€ç§é…å¤‡é•¿æœŸè®°å¿†çš„æ–°å‹å¤šæ¨¡æ€ä»£ç†æ¡†æ¶M3-Agentã€‚è¯¥æ¡†æ¶å¯ä»¥å¤„ç†å®æ—¶çš„è§†è§‰å’Œå¬è§‰è¾“å…¥æ¥æ„å»ºå’Œæ›´æ–°å…¶é•¿æœŸè®°å¿†ï¼Œå…·å¤‡ç§¯ç´¯ä¸–ç•ŒçŸ¥è¯†çš„èƒ½åŠ›ã€‚å…¶è®°å¿†ä»¥å®ä½“ä¸ºä¸­å¿ƒã€å¤šæ¨¡æ€çš„æ–¹å¼ç»„ç»‡ï¼Œä»è€Œå®ç°å¯¹ç¯å¢ƒçš„æ›´æ·±å’Œæ›´ä¸€è‡´çš„ç†è§£ã€‚å¼€å‘æ–°çš„è§†é¢‘é—®ç­”åŸºå‡†æµ‹è¯•M3-Benchï¼Œä»¥è¯„ä¼°å¤šæ¨¡æ€ä»£ç†çš„é•¿æœŸè®°å¿†æ•ˆæœå’ŒåŸºäºè®°å¿†æ¨ç†çš„èƒ½åŠ›ã€‚M3-Agentåœ¨æµ‹è¯•ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œè¶…è¶Šäº†æœ€å¼ºåŸºçº¿ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¼•å…¥äº†ä¸€ç§æ–°å‹çš„å¤šæ¨¡æ€ä»£ç†æ¡†æ¶M3-Agentï¼Œå…·å¤‡å¤„ç†å®æ—¶è§†è§‰å’Œå¬è§‰è¾“å…¥çš„èƒ½åŠ›ã€‚</li>
<li>M3-Agentæ‹¥æœ‰é•¿æœŸè®°å¿†ï¼Œå¯ä»¥ç§¯ç´¯ä¸–ç•ŒçŸ¥è¯†ã€‚</li>
<li>M3-Agentçš„è®°å¿†ä»¥å®ä½“ä¸ºä¸­å¿ƒã€å¤šæ¨¡æ€çš„æ–¹å¼ç»„ç»‡ã€‚</li>
<li>å¼€å‘äº†ä¸€ä¸ªæ–°çš„è§†é¢‘é—®ç­”åŸºå‡†æµ‹è¯•M3-Benchï¼Œç”¨äºè¯„ä¼°å¤šæ¨¡æ€ä»£ç†çš„è®°å¿†å’Œæ¨ç†èƒ½åŠ›ã€‚</li>
<li>M3-Agentåœ¨M3-Benchæµ‹è¯•ä¸­è¡¨ç°ä¼˜äºæœ€å¼ºçš„åŸºçº¿æ¨¡å‹ã€‚</li>
<li>M3-Agenté€šè¿‡å¼ºåŒ–å­¦ä¹ è¿›è¡Œè®­ç»ƒã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.09736">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-08ce0560c62f133bdd3256f0e3479d8a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-2e3d57b7970b35415912f02b69d3f5b9.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d402162a75b9869bddcc4fc2fa75e1a3.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-61cb5764a43a536769aa76a58f6c351b.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="ReqInOne-A-Large-Language-Model-Based-Agent-for-Software-Requirements-Specification-Generation"><a href="#ReqInOne-A-Large-Language-Model-Based-Agent-for-Software-Requirements-Specification-Generation" class="headerlink" title="ReqInOne: A Large Language Model-Based Agent for Software Requirements   Specification Generation"></a>ReqInOne: A Large Language Model-Based Agent for Software Requirements   Specification Generation</h2><p><strong>Authors:Taohong Zhu, Lucas C. Cordeiro, Youcheng Sun</strong></p>
<p>Software Requirements Specification (SRS) is one of the most important documents in software projects, but writing it manually is time-consuming and often leads to ambiguity. Existing automated methods rely heavily on manual analysis, while recent Large Language Model (LLM)-based approaches suffer from hallucinations and limited controllability. In this paper, we propose ReqInOne, an LLM-based agent that follows the common steps taken by human requirements engineers when writing an SRS to convert natural language into a structured SRS. ReqInOne adopts a modular architecture by decomposing SRS generation into three tasks: summary, requirement extraction, and requirement classification, each supported by tailored prompt templates to improve the quality and consistency of LLM outputs.   We evaluate ReqInOne using GPT-4o, LLaMA 3, and DeepSeek-R1, and compare the generated SRSs against those produced by the holistic GPT-4-based method from prior work as well as by entry-level requirements engineers. Expert evaluations show that ReqInOne produces more accurate and well-structured SRS documents. The performance advantage of ReqInOne benefits from its modular design, and experimental results further demonstrate that its requirement classification component achieves comparable or even better results than the state-of-the-art requirement classification model. </p>
<blockquote>
<p>è½¯ä»¶éœ€æ±‚è§„æ ¼è¯´æ˜ï¼ˆSRSï¼‰æ˜¯è½¯ä»¶é¡¹ç›®ä¸­æœ€é‡è¦çš„æ–‡æ¡£ä¹‹ä¸€ï¼Œä½†æ‰‹åŠ¨ç¼–å†™æ—¢è€—æ—¶åˆå®¹æ˜“å¯¼è‡´æ­§ä¹‰ã€‚ç°æœ‰çš„è‡ªåŠ¨åŒ–æ–¹æ³•å¾ˆå¤§ç¨‹åº¦ä¸Šä¾èµ–äºæ‰‹åŠ¨åˆ†æï¼Œè€Œæœ€è¿‘åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„æ–¹æ³•åˆ™å­˜åœ¨è™šæ„å’Œå¯æ§æ€§æœ‰é™çš„é—®é¢˜ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ReqInOneï¼Œè¿™æ˜¯ä¸€ä¸ªåŸºäºLLMçš„ä»£ç†ï¼Œå®ƒéµå¾ªäººç±»éœ€æ±‚å·¥ç¨‹å¸ˆåœ¨ç¼–å†™SRSæ—¶é‡‡å–çš„é€šç”¨æ­¥éª¤ï¼Œå°†è‡ªç„¶è¯­è¨€è½¬æ¢ä¸ºç»“æ„åŒ–çš„SRSã€‚ReqInOneé‡‡ç”¨æ¨¡å—åŒ–æ¶æ„ï¼Œå°†SRSç”Ÿæˆåˆ†è§£ä¸ºä¸‰ä¸ªä»»åŠ¡ï¼šæ‘˜è¦ã€éœ€æ±‚æå–å’Œéœ€æ±‚åˆ†ç±»ï¼Œæ¯ä¸ªä»»åŠ¡éƒ½ç”±ä¸“é—¨çš„æç¤ºæ¨¡æ¿æ”¯æŒï¼Œä»¥æé«˜LLMè¾“å‡ºçš„è´¨é‡å’Œä¸€è‡´æ€§ã€‚æˆ‘ä»¬ä½¿ç”¨GPT-4oã€LLaMA 3å’ŒDeepSeek-R1å¯¹ReqInOneè¿›è¡Œäº†è¯„ä¼°ï¼Œå¹¶å°†ç”Ÿæˆçš„SRSä¸ä¹‹å‰å·¥ä½œä¸­åŸºäºæ•´ä½“GPT-4çš„æ–¹æ³•ä»¥åŠå…¥é—¨çº§éœ€æ±‚å·¥ç¨‹å¸ˆäº§ç”Ÿçš„SRSè¿›è¡Œäº†æ¯”è¾ƒã€‚ä¸“å®¶è¯„ä¼°è¡¨æ˜ï¼ŒReqInOneäº§ç”Ÿçš„SRSæ–‡æ¡£æ›´å‡†ç¡®ã€ç»“æ„æ›´å¥½ã€‚ReqInOneçš„æ€§èƒ½ä¼˜åŠ¿å¾—ç›Šäºå…¶æ¨¡å—åŒ–è®¾è®¡ï¼Œè€Œä¸”å®éªŒç»“æœè¡¨æ˜ï¼Œå…¶åœ¨éœ€æ±‚åˆ†ç±»ç»„ä»¶æ–¹é¢è¾¾åˆ°äº†ä¸æœ€æ–°éœ€æ±‚åˆ†ç±»æ¨¡å‹ç›¸å½“ç”šè‡³æ›´å¥½çš„ç»“æœã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.09648v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†ReqInOneï¼Œä¸€ä¸ªåŸºäºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„è‡ªåŠ¨åŒ–å·¥å…·ï¼Œç”¨äºå°†è‡ªç„¶è¯­è¨€è½¬åŒ–ä¸ºç»“æ„åŒ–çš„è½¯ä»¶éœ€æ±‚è§„æ ¼ï¼ˆSRSï¼‰ã€‚ReqInOneé‡‡ç”¨æ¨¡å—åŒ–æ¶æ„ï¼Œå°†SRSç”Ÿæˆåˆ†è§£ä¸ºæ‘˜è¦ã€éœ€æ±‚æå–å’Œéœ€æ±‚åˆ†ç±»ä¸‰ä¸ªä»»åŠ¡ï¼Œå¹¶é€šè¿‡å®šåˆ¶æç¤ºæ¨¡æ¿æ¥æé«˜LLMè¾“å‡ºçš„è´¨é‡å’Œä¸€è‡´æ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒReqInOneç”Ÿæˆçš„SRSæ–‡æ¡£æ›´å‡†ç¡®ã€ç»“æ„æ›´å¥½ï¼Œå…¶æ€§èƒ½ä¼˜åŠ¿å¾—ç›Šäºæ¨¡å—åŒ–è®¾è®¡ï¼Œå¹¶ä¸”å…¶éœ€æ±‚åˆ†ç±»ç»„ä»¶çš„æ€§èƒ½ä¸æœ€å…ˆè¿›çš„æ¨¡å‹ç›¸å½“æˆ–æ›´å¥½ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ReqInOneæ˜¯ä¸€ä¸ªåŸºäºLLMçš„è‡ªåŠ¨åŒ–å·¥å…·ï¼Œç”¨äºç”Ÿæˆè½¯ä»¶éœ€æ±‚è§„æ ¼ï¼ˆSRSï¼‰ã€‚</li>
<li>ReqInOneé‡‡ç”¨æ¨¡å—åŒ–è®¾è®¡ï¼Œå°†SRSç”Ÿæˆåˆ†ä¸ºæ‘˜è¦ã€éœ€æ±‚æå–å’Œéœ€æ±‚åˆ†ç±»ä¸‰ä¸ªä»»åŠ¡ã€‚</li>
<li>ReqInOneä½¿ç”¨å®šåˆ¶æç¤ºæ¨¡æ¿æ¥æé«˜å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰è¾“å‡ºçš„è´¨é‡å’Œä¸€è‡´æ€§ã€‚</li>
<li>ReqInOneç”Ÿæˆçš„SRSæ–‡æ¡£æ›´å‡†ç¡®ã€ç»“æ„æ›´å¥½ã€‚</li>
<li>ReqInOneçš„æ€§èƒ½ä¼˜åŠ¿æºäºå…¶æ¨¡å—åŒ–è®¾è®¡ã€‚</li>
<li>ReqInOneçš„éœ€æ±‚åˆ†ç±»ç»„ä»¶æ€§èƒ½ä¸æœ€å…ˆè¿›çš„æ¨¡å‹ç›¸å½“æˆ–æ›´å¥½ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.09648">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-c30e9d7e4f84824442bfdce2b3c6a810.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-dcafb024df32cc69f22ada623c0e69d6.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f165529b325f01d23c3220a55ecb46a9.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-85067b77688d13174cdbfa941cf45216.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-530b4e2530f79dfe1e855c5648b21ade.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="Preacher-Paper-to-Video-Agentic-System"><a href="#Preacher-Paper-to-Video-Agentic-System" class="headerlink" title="Preacher: Paper-to-Video Agentic System"></a>Preacher: Paper-to-Video Agentic System</h2><p><strong>Authors:Jingwei Liu, Ling Yang, Hao Luo, Fan Wang, Hongyan Li, Mengdi Wang</strong></p>
<p>The paper-to-video task converts a research paper into a structured video abstract, distilling key concepts, methods, and conclusions into an accessible, well-organized format. While state-of-the-art video generation models demonstrate potential, they are constrained by limited context windows, rigid video duration constraints, limited stylistic diversity, and an inability to represent domain-specific knowledge. To address these limitations, we introduce Preacher, the first paper-to-video agentic system. Preacher employs a topdown approach to decompose, summarize, and reformulate the paper, followed by bottom-up video generation, synthesizing diverse video segments into a coherent abstract. To align cross-modal representations, we define key scenes and introduce a Progressive Chain of Thought (P-CoT) for granular, iterative planning. Preacher successfully generates high-quality video abstracts across five research fields, demonstrating expertise beyond current video generation models. Code will be released at: <a target="_blank" rel="noopener" href="https://github.com/GenVerse/Paper2Video">https://github.com/GenVerse/Paper2Video</a> </p>
<blockquote>
<p>è¿™ç¯‡è®ºæ–‡å°†ç ”ç©¶è®ºæ–‡è½¬åŒ–ä¸ºç»“æ„åŒ–çš„è§†é¢‘æ‘˜è¦ï¼Œæç‚¼å…³é”®æ¦‚å¿µã€æ–¹æ³•å’Œç»“è®ºï¼Œä½¿å…¶æ˜“äºç†è§£å¹¶ä»¥è‰¯å¥½çš„ç»„ç»‡æ–¹å¼å‘ˆç°ã€‚å°½ç®¡æœ€å…ˆè¿›çš„è§†é¢‘ç”Ÿæˆæ¨¡å‹æ˜¾ç¤ºå‡ºæ½œåŠ›ï¼Œä½†å®ƒä»¬å—é™äºæœ‰é™çš„ä¸Šä¸‹æ–‡çª—å£ã€ä¸¥æ ¼çš„è§†é¢‘æŒç»­æ—¶é—´é™åˆ¶ã€æœ‰é™çš„é£æ ¼å¤šæ ·æ€§å’Œæ— æ³•è¡¨ç¤ºç‰¹å®šé¢†åŸŸçŸ¥è¯†ã€‚ä¸ºäº†è§£å†³è¿™äº›å±€é™æ€§ï¼Œæˆ‘ä»¬å¼•å…¥äº†Preacherï¼Œè¿™æ˜¯ç¬¬ä¸€ä¸ªè®ºæ–‡åˆ°è§†é¢‘çš„æ™ºèƒ½ç³»ç»Ÿã€‚Preacheré‡‡ç”¨è‡ªä¸Šè€Œä¸‹çš„æ–¹æ³•åˆ†è§£ã€æ€»ç»“å’Œé‡æ„è®ºæ–‡ï¼Œç„¶åè¿›è¡Œè‡ªä¸‹è€Œä¸Šçš„è§†é¢‘ç”Ÿæˆï¼Œå°†å¤šæ ·åŒ–çš„è§†é¢‘ç‰‡æ®µåˆæˆä¸€ä¸ªè¿è´¯çš„æ‘˜è¦ã€‚ä¸ºäº†å¯¹é½è·¨æ¨¡æ€è¡¨ç¤ºï¼Œæˆ‘ä»¬å®šä¹‰äº†å…³é”®åœºæ™¯å¹¶å¼•å…¥äº†æ¸è¿›å¼æ€ç»´é“¾ï¼ˆP-CoTï¼‰è¿›è¡Œç²¾ç»†çš„è¿­ä»£è§„åˆ’ã€‚PreacheræˆåŠŸåœ°åœ¨äº”ä¸ªç ”ç©¶é¢†åŸŸç”Ÿæˆäº†é«˜è´¨é‡çš„è§†é¢‘æ‘˜è¦ï¼Œæ˜¾ç¤ºå‡ºè¶…è¶Šå½“å‰è§†é¢‘ç”Ÿæˆæ¨¡å‹çš„ä¸“é•¿ã€‚ä»£ç å°†åœ¨ä»¥ä¸‹ç½‘å€å‘å¸ƒï¼š<a target="_blank" rel="noopener" href="https://github.com/GenVerse/Paper2Video">https://github.com/GenVerse/Paper2Video</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.09632v2">PDF</a> </p>
<p><strong>Summary</strong><br>æ–‡æœ¬ä»‹ç»äº†ä¸€ç§å°†ç ”ç©¶è®ºæ–‡è½¬åŒ–ä¸ºç»“æ„åŒ–è§†é¢‘æ‘˜è¦çš„ä»»åŠ¡ï¼Œå…¶ä¸­å­˜åœ¨è§†é¢‘ç”Ÿæˆæ¨¡å‹çš„å±€é™æ€§ã€‚ä¸ºæ­¤ï¼Œå¼•å…¥Preacherä½œä¸ºé¦–ä¸ªè®ºæ–‡è½¬è§†é¢‘çš„ç³»ç»Ÿï¼Œé€šè¿‡è‡ªä¸Šè€Œä¸‹åˆ†è§£ã€æ€»ç»“å’Œé‡æ„è®ºæ–‡å†…å®¹ï¼Œå¹¶ç»“åˆè‡ªä¸‹è€Œä¸Šçš„è§†é¢‘ç”Ÿæˆï¼Œå°†å¤šæ ·åŒ–çš„è§†é¢‘ç‰‡æ®µåˆæˆä¸€ä¸ªè¿è´¯çš„æ‘˜è¦ã€‚ç³»ç»Ÿé‡‡ç”¨æ¸è¿›å¼æ€ç»´é“¾è¿›è¡Œç²¾ç»†è¿­ä»£è§„åˆ’ï¼ŒæˆåŠŸç”Ÿæˆé«˜è´¨é‡çš„è§†é¢‘æ‘˜è¦ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>è®ºæ–‡è½¬è§†é¢‘æ‘˜è¦ä»»åŠ¡æ—¨åœ¨å°†ç ”ç©¶è®ºæ–‡çš„å…³é”®æ¦‚å¿µã€æ–¹æ³•å’Œç»“è®ºè½¬åŒ–ä¸ºæ˜“äºç†è§£ã€ç»“æ„åŒ–çš„è§†é¢‘æ ¼å¼ã€‚</li>
<li>å½“å‰è§†é¢‘ç”Ÿæˆæ¨¡å‹å­˜åœ¨å±€é™æ€§ï¼Œå¦‚ä¸Šä¸‹æ–‡çª—å£æœ‰é™ã€è§†é¢‘æ—¶é•¿çº¦æŸã€é£æ ¼å•ä¸€ä»¥åŠæ— æ³•è¡¨è¾¾é¢†åŸŸç‰¹å®šçŸ¥è¯†ã€‚</li>
<li>Preacheræ˜¯é¦–ä¸ªè®ºæ–‡è½¬è§†é¢‘çš„æ™ºèƒ½åŒ–ç³»ç»Ÿï¼Œé‡‡ç”¨è‡ªä¸Šè€Œä¸‹ä¸è‡ªä¸‹è€Œä¸Šçš„æ–¹æ³•ï¼Œå®ç°å¯¹è®ºæ–‡çš„åˆ†è§£ã€æ€»ç»“å’Œé‡æ„ï¼Œä»¥åŠè§†é¢‘ç”Ÿæˆã€‚</li>
<li>Preacheré€šè¿‡å®šä¹‰å…³é”®åœºæ™¯å’Œå¼•å…¥æ¸è¿›å¼æ€ç»´é“¾ï¼ˆP-CoTï¼‰è¿›è¡Œç²¾ç»†è¿­ä»£è§„åˆ’ï¼Œå®ç°è·¨æ¨¡æ€è¡¨ç¤ºçš„å¯¹é½ã€‚</li>
<li>PreacheræˆåŠŸç”Ÿæˆé«˜è´¨é‡çš„è§†é¢‘æ‘˜è¦ï¼Œå¹¶å±•ç¤ºåœ¨äº”ä¸ªç ”ç©¶é¢†åŸŸçš„ä¸“ä¸šèƒ½åŠ›ã€‚</li>
<li>ç³»ç»Ÿå°†åœ¨GitHubä¸Šå‘å¸ƒä»£ç ä»¥ä¾›å…¬ä¼—ä½¿ç”¨ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.09632">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-50999c62775d2fc4a1c41938baa61249.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-2c35f78f977b7b562e643467f781ae79.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-aabd58efacb3021bc328b855ffb6879f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-796ef1f12ffd673831080a00b4094a7f.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="Distilling-LLM-Prior-to-Flow-Model-for-Generalizable-Agentâ€™s-Imagination-in-Object-Goal-Navigation"><a href="#Distilling-LLM-Prior-to-Flow-Model-for-Generalizable-Agentâ€™s-Imagination-in-Object-Goal-Navigation" class="headerlink" title="Distilling LLM Prior to Flow Model for Generalizable Agentâ€™s Imagination   in Object Goal Navigation"></a>Distilling LLM Prior to Flow Model for Generalizable Agentâ€™s Imagination   in Object Goal Navigation</h2><p><strong>Authors:Badi Li, Ren-jie Lu, Yu Zhou, Jingke Meng, Wei-shi Zheng</strong></p>
<p>The Object Goal Navigation (ObjectNav) task challenges agents to locate a specified object in an unseen environment by imagining unobserved regions of the scene. Prior approaches rely on deterministic and discriminative models to complete semantic maps, overlooking the inherent uncertainty in indoor layouts and limiting their ability to generalize to unseen environments. In this work, we propose GOAL, a generative flow-based framework that models the semantic distribution of indoor environments by bridging observed regions with LLM-enriched full-scene semantic maps. During training, spatial priors inferred from large language models (LLMs) are encoded as two-dimensional Gaussian fields and injected into target maps, distilling rich contextual knowledge into the flow model and enabling more generalizable completions. Extensive experiments demonstrate that GOAL achieves state-of-the-art performance on MP3D and Gibson, and shows strong generalization in transfer settings to HM3D. Codes and pretrained models are available at <a target="_blank" rel="noopener" href="https://github.com/Badi-Li/GOAL">https://github.com/Badi-Li/GOAL</a>. </p>
<blockquote>
<p>å¯¹è±¡ç›®æ ‡å¯¼èˆªï¼ˆObjectNavï¼‰ä»»åŠ¡æŒ‘æˆ˜æ™ºèƒ½ä½“é€šè¿‡åœ¨åœºæ™¯ä¸­æƒ³è±¡æœªè§‚å¯Ÿåˆ°çš„åŒºåŸŸï¼Œåœ¨æœªçŸ¥ç¯å¢ƒä¸­å®šä½æŒ‡å®šå¯¹è±¡ã€‚ä¹‹å‰çš„æ–¹æ³•ä¾èµ–äºç¡®å®šæ€§å’Œåˆ¤åˆ«æ¨¡å‹æ¥å®Œæˆè¯­ä¹‰åœ°å›¾ï¼Œå¿½ç•¥äº†å®¤å†…å¸ƒå±€çš„å†…åœ¨ä¸ç¡®å®šæ€§ï¼Œå¹¶é™åˆ¶äº†å®ƒä»¬åœ¨æœªçŸ¥ç¯å¢ƒä¸­çš„æ³›åŒ–èƒ½åŠ›ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†GOALï¼Œè¿™æ˜¯ä¸€ä¸ªåŸºäºç”Ÿæˆæµçš„æ¡†æ¶ï¼Œé€šè¿‡æ¡¥æ¥è§‚å¯ŸåŒºåŸŸå’Œä¸°å¯Œçš„è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„å…¨åœºæ™¯è¯­ä¹‰åœ°å›¾ï¼Œå¯¹å®¤å†…ç¯å¢ƒçš„è¯­ä¹‰åˆ†å¸ƒè¿›è¡Œå»ºæ¨¡ã€‚åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œä»å¤§å‹è¯­è¨€æ¨¡å‹æ¨æ–­å‡ºçš„ç©ºé—´å…ˆéªŒè¢«ç¼–ç ä¸ºäºŒç»´é«˜æ–¯åœºå¹¶æ³¨å…¥ç›®æ ‡åœ°å›¾ï¼Œå°†ä¸°å¯Œçš„ä¸Šä¸‹æ–‡çŸ¥è¯†è’¸é¦åˆ°æµæ¨¡å‹ä¸­ï¼Œä½¿æ¨¡å‹èƒ½å¤Ÿæ›´é€šç”¨åœ°å®Œæˆã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼ŒGOALåœ¨MP3Då’ŒGibsonä¸Šè¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½æ°´å¹³ï¼Œå¹¶åœ¨è½¬ç§»åˆ°HM3Dæ—¶æ˜¾ç¤ºå‡ºå¼ºå¤§çš„æ³›åŒ–èƒ½åŠ›ã€‚ä»£ç å’Œé¢„å…ˆè®­ç»ƒçš„æ¨¡å‹å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/Badi-Li/GOAL%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/Badi-Li/GOALæ‰¾åˆ°ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.09423v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>åŸºäºç›®æ ‡å¯¼èˆªï¼ˆObjectNavï¼‰ä»»åŠ¡æŒ‘æˆ˜ä»£ç†åœ¨æœªè§è¿‡çš„ç¯å¢ƒä¸­å¯»æ‰¾æŒ‡å®šå¯¹è±¡ï¼Œé€šè¿‡æƒ³è±¡åœºæ™¯çš„æœªè§‚æµ‹åŒºåŸŸæ¥å®Œæˆã€‚å…ˆå‰çš„æ–¹æ³•ä¾èµ–äºç¡®å®šæ€§å’Œåˆ¤åˆ«æ¨¡å‹æ¥å®Œæˆè¯­ä¹‰åœ°å›¾ï¼Œå¿½ç•¥äº†å®¤å†…å¸ƒå±€çš„å›ºæœ‰ä¸ç¡®å®šæ€§ï¼Œé™åˆ¶äº†å®ƒä»¬åœ¨æœªè§ç¯å¢ƒä¸­çš„æ³›åŒ–èƒ½åŠ›ã€‚æœ¬æ–‡æå‡ºäº†GOALï¼Œè¿™æ˜¯ä¸€ä¸ªåŸºäºç”Ÿæˆæµçš„æ¡†æ¶ï¼Œé€šè¿‡æ¡¥æ¥è§‚æµ‹åŒºåŸŸå’ŒLLMä¸°å¯Œçš„å…¨åœºæ™¯è¯­ä¹‰åœ°å›¾ï¼Œå¯¹å®¤å†…ç¯å¢ƒçš„è¯­ä¹‰åˆ†å¸ƒè¿›è¡Œå»ºæ¨¡ã€‚åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œä»å¤§è¯­è¨€æ¨¡å‹æ¨æ–­çš„ç©ºé—´å…ˆéªŒè¢«ç¼–ç ä¸ºäºŒç»´é«˜æ–¯åœºå¹¶æ³¨å…¥ç›®æ ‡åœ°å›¾ï¼Œå°†ä¸°å¯Œçš„ä¸Šä¸‹æ–‡çŸ¥è¯†è’¸é¦åˆ°æµæ¨¡å‹ä¸­ï¼Œä½¿å®Œæˆä»»åŠ¡æ›´å…·æ³›åŒ–æ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ObjectGoalNavä»»åŠ¡æŒ‘æˆ˜ä»£ç†åœ¨æœªè§è¿‡çš„ç¯å¢ƒä¸­å¯»æ‰¾æŒ‡å®šå¯¹è±¡ï¼Œéœ€è¦æƒ³è±¡æœªè§‚æµ‹çš„åŒºåŸŸæ¥å®Œæˆä»»åŠ¡ã€‚</li>
<li>ç°æœ‰æ–¹æ³•ä¸»è¦ä¾èµ–äºç¡®å®šæ€§å’Œåˆ¤åˆ«æ¨¡å‹å®Œæˆè¯­ä¹‰åœ°å›¾ï¼Œå­˜åœ¨å±€é™æ€§ã€‚</li>
<li>GOALæ¡†æ¶é‡‡ç”¨ç”Ÿæˆæµçš„æ–¹å¼å¯¹å®¤å†…ç¯å¢ƒçš„è¯­ä¹‰åˆ†å¸ƒè¿›è¡Œå»ºæ¨¡ï¼Œç»“åˆè§‚æµ‹åŒºåŸŸå’ŒLLMä¸°å¯Œçš„å…¨åœºæ™¯è¯­ä¹‰åœ°å›¾ã€‚</li>
<li>ç©ºé—´å…ˆéªŒè¢«ç¼–ç ä¸ºäºŒç»´é«˜æ–¯åœºå¹¶æ³¨å…¥ç›®æ ‡åœ°å›¾ï¼Œä¸°å¯Œä¸Šä¸‹æ–‡çŸ¥è¯†ã€‚</li>
<li>GOALåœ¨MP3Då’ŒGibsonæ•°æ®é›†ä¸Šè¾¾åˆ°æœ€ä½³æ€§èƒ½ã€‚</li>
<li>GOALåœ¨HM3Dçš„è½¬ç§»è®¾ç½®ä¸­ä¹Ÿè¡¨ç°å‡ºå¼ºå¤§çš„æ³›åŒ–èƒ½åŠ›ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.09423">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-a62d07f6d68e576315ad0cee128ac637.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-5b58aa2d7978847db9c79f95ad94e31b.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-f991e46a007b6daf921fd00a2aee8083.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="Waymo-3DSkelMo-A-Multi-Agent-3D-Skeletal-Motion-Dataset-for-Pedestrian-Interaction-Modeling-in-Autonomous-Driving"><a href="#Waymo-3DSkelMo-A-Multi-Agent-3D-Skeletal-Motion-Dataset-for-Pedestrian-Interaction-Modeling-in-Autonomous-Driving" class="headerlink" title="Waymo-3DSkelMo: A Multi-Agent 3D Skeletal Motion Dataset for Pedestrian   Interaction Modeling in Autonomous Driving"></a>Waymo-3DSkelMo: A Multi-Agent 3D Skeletal Motion Dataset for Pedestrian   Interaction Modeling in Autonomous Driving</h2><p><strong>Authors:Guangxun Zhu, Shiyu Fan, Hang Dai, Edmond S. L. Ho</strong></p>
<p>Large-scale high-quality 3D motion datasets with multi-person interactions are crucial for data-driven models in autonomous driving to achieve fine-grained pedestrian interaction understanding in dynamic urban environments. However, existing datasets mostly rely on estimating 3D poses from monocular RGB video frames, which suffer from occlusion and lack of temporal continuity, thus resulting in unrealistic and low-quality human motion. In this paper, we introduce Waymo-3DSkelMo, the first large-scale dataset providing high-quality, temporally coherent 3D skeletal motions with explicit interaction semantics, derived from the Waymo Perception dataset. Our key insight is to utilize 3D human body shape and motion priors to enhance the quality of the 3D pose sequences extracted from the raw LiDRA point clouds. The dataset covers over 14,000 seconds across more than 800 real driving scenarios, including rich interactions among an average of 27 agents per scene (with up to 250 agents in the largest scene). Furthermore, we establish 3D pose forecasting benchmarks under varying pedestrian densities, and the results demonstrate its value as a foundational resource for future research on fine-grained human behavior understanding in complex urban environments. The dataset and code will be available at <a target="_blank" rel="noopener" href="https://github.com/GuangxunZhu/Waymo-3DSkelMo">https://github.com/GuangxunZhu/Waymo-3DSkelMo</a> </p>
<blockquote>
<p>å¤§è§„æ¨¡é«˜è´¨é‡çš„ä¸‰ç»´åŠ¨ä½œæ•°æ®é›†å¯¹äºè‡ªåŠ¨é©¾é©¶ä¸­çš„æ•°æ®é©±åŠ¨æ¨¡å‹è‡³å…³é‡è¦ï¼Œæ—¨åœ¨å®ç°åœ¨åŠ¨æ€ç¯å¢ƒä¸­å¯¹è¡Œäººäº¤äº’çš„ç²¾ç»†ç†è§£ã€‚ç„¶è€Œï¼Œç°æœ‰çš„æ•°æ®é›†å¤§å¤šä¾èµ–äºä»å•ç›®RGBè§†é¢‘å¸§ä¸­ä¼°è®¡ä¸‰ç»´å§¿æ€ï¼Œè¿™äº›è§†é¢‘å­˜åœ¨é®æŒ¡é—®é¢˜å¹¶ä¸”ç¼ºä¹æ—¶é—´è¿ç»­æ€§ï¼Œå› æ­¤äº§ç”Ÿäº†ä¸çœŸå®å’Œä½è´¨é‡çš„äººç±»åŠ¨ä½œã€‚æœ¬æ–‡ä»‹ç»äº†Waymo-3DSkelMoæ•°æ®é›†ï¼Œå®ƒæ˜¯ç¬¬ä¸€ä¸ªå¤§è§„æ¨¡æ•°æ®é›†ï¼Œæä¾›é«˜è´¨é‡ã€æ—¶é—´è¿è´¯çš„ä¸‰ç»´éª¨éª¼è¿åŠ¨ä»¥åŠæ˜ç¡®çš„äº¤äº’è¯­ä¹‰ï¼Œæ¥æºäºWaymoæ„ŸçŸ¥æ•°æ®é›†ã€‚æˆ‘ä»¬çš„å…³é”®è§è§£æ˜¯åˆ©ç”¨ä¸‰ç»´äººä½“å½¢çŠ¶å’Œè¿åŠ¨å…ˆéªŒçŸ¥è¯†æ¥æé«˜ä»åŸå§‹æ¿€å…‰é›·è¾¾ç‚¹äº‘ä¸­æå–çš„ä¸‰ç»´å§¿æ€åºåˆ—çš„è´¨é‡ã€‚è¯¥æ•°æ®é›†è¦†ç›–äº†è¶…è¿‡14,000ç§’çš„æ—¶é—´ï¼Œæ¶µç›–è¶…è¿‡800ä¸ªçœŸå®é©¾é©¶åœºæ™¯ï¼ŒåŒ…æ‹¬å¹³å‡æ¯åœºæ™¯ä¸­æœ‰é«˜è¾¾27ä¸ªæ™ºèƒ½ä½“ä¹‹é—´çš„ä¸°å¯Œäº¤äº’ï¼ˆæœ€å¤§åœºæ™¯ä¸­æœ€å¤šå¯è¾¾250ä¸ªæ™ºèƒ½ä½“ï¼‰ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬åœ¨ä¸åŒçš„è¡Œäººå¯†åº¦ä¸‹å»ºç«‹äº†ä¸‰ç»´å§¿æ€é¢„æµ‹åŸºå‡†æµ‹è¯•ï¼Œç»“æœè¡¨æ˜å®ƒå¯¹äºæœªæ¥åœ¨å¤æ‚åŸå¸‚ç¯å¢ƒä¸­è¿›è¡Œç²¾ç»†äººç±»è¡Œä¸ºç†è§£ç ”ç©¶çš„åŸºç¡€èµ„æºå…·æœ‰é‡è¦æ„ä¹‰ã€‚æ•°æ®é›†å’Œä»£ç å°†åœ¨<a target="_blank" rel="noopener" href="https://github.com/GuangxunZhu/Waymo-3DSkelMo%E4%B8%8A%E6%8F%90%E4%BE%9B%E3%80%82">https://github.com/GuangxunZhu/Waymo-3DSkelMoä¸Šæä¾›ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.09404v1">PDF</a> ACM Multimedia 2025 (Dataset Track) Paper</p>
<p><strong>Summary</strong></p>
<p>Waymo-3DSkelMoæ•°æ®é›†å¯¹äºæ•°æ®é©±åŠ¨æ¨¡å‹åœ¨åŠ¨æ€åŸå¸‚ç¯å¢ƒä¸­å®ç°ç²¾ç»†çš„è¡Œäººäº¤äº’ç†è§£è‡³å…³é‡è¦ã€‚å®ƒæä¾›äº†é«˜è´¨é‡ã€æ—¶é—´è¿è´¯çš„3Déª¨éª¼è¿åŠ¨ï¼Œå…·æœ‰æ˜ç¡®çš„äº¤äº’è¯­ä¹‰ï¼Œå¹¶åˆ©ç”¨3Däººä½“å½¢çŠ¶å’Œè¿åŠ¨å…ˆéªŒçŸ¥è¯†æé«˜ä»LiDARç‚¹äº‘æå–çš„3Då§¿åŠ¿åºåˆ—çš„è´¨é‡ã€‚æ•°æ®é›†åŒ…å«è¶…è¿‡14,000ç§’çš„é©¾é©¶åœºæ™¯ï¼Œæ¶µç›–ä¸°å¯Œçš„è¡Œäººäº¤äº’ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>Waymo-3DSkelMoæ˜¯é¦–ä¸ªæä¾›é«˜è´¨é‡ã€æ—¶é—´è¿è´¯çš„3Déª¨éª¼è¿åŠ¨çš„å¤§å‹æ•°æ®é›†ï¼Œå…·æœ‰æ˜ç¡®çš„äº¤äº’è¯­ä¹‰ã€‚</li>
<li>æ•°æ®é›†åˆ©ç”¨3Däººä½“å½¢çŠ¶å’Œè¿åŠ¨å…ˆéªŒçŸ¥è¯†ï¼Œæé«˜ä»LiDARç‚¹äº‘æå–çš„3Då§¿åŠ¿åºåˆ—çš„è´¨é‡ã€‚</li>
<li>æ•°æ®é›†åŒ…å«è¶…è¿‡14,000ç§’çš„é©¾é©¶åœºæ™¯ï¼Œè¦†ç›–ä¸°å¯Œçš„è¡Œäººäº¤äº’ï¼Œåœºæ™¯ä¸­åŒ…å«å¹³å‡27ä¸ªè¡Œäººï¼ˆæœ€å¤§åœºæ™¯å¯è¾¾250ä¸ªè¡Œäººï¼‰ã€‚</li>
<li>Waymo-3DSkelMoæ•°æ®é›†å¯¹äºæ•°æ®é©±åŠ¨æ¨¡å‹åœ¨åŠ¨æ€åŸå¸‚ç¯å¢ƒä¸­å®ç°ç²¾ç»†çš„è¡Œäººäº¤äº’ç†è§£è‡³å…³é‡è¦ã€‚</li>
<li>æ•°æ®é›†å»ºç«‹äº†åœ¨ä¸åŒè¡Œäººå¯†åº¦ä¸‹çš„3Då§¿æ€é¢„æµ‹åŸºå‡†æµ‹è¯•ï¼Œè¯æ˜äº†å…¶åœ¨æœªæ¥å¤æ‚åŸå¸‚ç¯å¢ƒä¸­ç²¾ç»†äººç±»è¡Œä¸ºç†è§£ç ”ç©¶ä¸­çš„ä»·å€¼ã€‚</li>
<li>Waymo-3DSkelMoæ•°æ®é›†å’Œä»£ç å°†åœ¨<a target="_blank" rel="noopener" href="https://github.com/GuangxunZhu/Waymo-3DSkelMo%E4%B8%8A%E6%8F%90%E4%BE%9B%EF%BC%8C%E6%96%B9%E4%BE%BF%E6%9C%AA%E6%9D%A5%E7%A0%94%E7%A9%B6%E4%BD%BF%E7%94%A8%E3%80%82">https://github.com/GuangxunZhu/Waymo-3DSkelMoä¸Šæä¾›ï¼Œæ–¹ä¾¿æœªæ¥ç ”ç©¶ä½¿ç”¨ã€‚</a></li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.09404">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-7ac833fd19922b5383741f940d3967f7.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-43499667c3c51b6cb8f0981e9c0d10e5.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-cb0910bc69628b4da6287002da717f64.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c5e74a981f0ef639f48b301c3ee6f63e.jpg" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="Beyond-Ten-Turns-Unlocking-Long-Horizon-Agentic-Search-with-Large-Scale-Asynchronous-RL"><a href="#Beyond-Ten-Turns-Unlocking-Long-Horizon-Agentic-Search-with-Large-Scale-Asynchronous-RL" class="headerlink" title="Beyond Ten Turns: Unlocking Long-Horizon Agentic Search with Large-Scale   Asynchronous RL"></a>Beyond Ten Turns: Unlocking Long-Horizon Agentic Search with Large-Scale   Asynchronous RL</h2><p><strong>Authors:Jiaxuan Gao, Wei Fu, Minyang Xie, Shusheng Xu, Chuyi He, Zhiyu Mei, Banghua Zhu, Yi Wu</strong></p>
<p>Recent advancements in LLM-based agents have demonstrated remarkable capabilities in handling complex, knowledge-intensive tasks by integrating external tools. Among diverse choices of tools, search tools play a pivotal role in accessing vast external knowledge. However, open-source agents still fall short of achieving expert-level Search Intelligence, the ability to resolve ambiguous queries, generate precise searches, analyze results, and conduct thorough exploration. Existing approaches fall short in scalability, efficiency, and data quality. For example, small turn limits in existing online RL methods, e.g. &lt;&#x3D;10, restrict complex strategy learning. This paper introduces ASearcher, an open-source project for large-scale RL training of search agents. Our key contributions include: (1) Scalable fully asynchronous RL training that enables long-horizon search while maintaining high training efficiency. (2) A prompt-based LLM agent that autonomously synthesizes high-quality and challenging QAs, creating a large-scale QA dataset. Through RL training, our prompt-based QwQ-32B agent achieves substantial improvements, with 46.7% and 20.8% Avg@4 gains on xBench and GAIA, respectively. Notably, our agent exhibits extreme long-horizon search, with tool calls exceeding 40 turns and output tokens exceeding 150k during training time. With a simple agent design and no external LLMs, ASearcher-Web-QwQ achieves Avg@4 scores of 42.1 on xBench and 52.8 on GAIA, surpassing existing open-source 32B agents. We open-source our models, training data, and codes in <a target="_blank" rel="noopener" href="https://github.com/inclusionAI/ASearcher">https://github.com/inclusionAI/ASearcher</a>. </p>
<blockquote>
<p>æœ€è¿‘åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„ä»£ç†äººçš„è¿›å±•ï¼Œé€šè¿‡æ•´åˆå¤–éƒ¨å·¥å…·ï¼Œåœ¨å¤„ç†å¤æ‚ã€çŸ¥è¯†å¯†é›†å‹ä»»åŠ¡æ–¹é¢å±•ç°äº†æ˜¾è‘—çš„èƒ½åŠ›ã€‚åœ¨å¤šç§å·¥å…·é€‰æ‹©ä¸­ï¼Œæœç´¢å·¥å…·åœ¨è®¿é—®å¤§é‡å¤–éƒ¨çŸ¥è¯†æ–¹é¢å‘æŒ¥ç€è‡³å…³é‡è¦çš„ä½œç”¨ã€‚ç„¶è€Œï¼Œå¼€æºä»£ç†äººä»ç„¶ç¼ºä¹å®ç°ä¸“å®¶çº§çš„æœç´¢æ™ºèƒ½ï¼Œå³è§£å†³æ¨¡ç³ŠæŸ¥è¯¢ã€è¿›è¡Œç²¾ç¡®æœç´¢ã€åˆ†æç»“æœä»¥åŠè¿›è¡Œå…¨é¢æ¢ç´¢çš„èƒ½åŠ›ã€‚ç°æœ‰æ–¹æ³•åœ¨å¯æ‰©å±•æ€§ã€æ•ˆç‡å’Œæ•°æ®è´¨é‡æ–¹é¢å­˜åœ¨ä¸è¶³ã€‚ä¾‹å¦‚ï¼Œç°æœ‰åœ¨çº¿å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰æ–¹æ³•çš„å°å›åˆé™åˆ¶ï¼ˆä¾‹å¦‚&lt;&#x3D;10ï¼‰ï¼Œé™åˆ¶äº†å¤æ‚ç­–ç•¥çš„å­¦ä¹ ã€‚æœ¬æ–‡ä»‹ç»äº†ASearcherï¼Œä¸€ä¸ªç”¨äºå¤§è§„æ¨¡RLè®­ç»ƒçš„æœç´¢å¼•æ“ä»£ç†äººçš„å¼€æºé¡¹ç›®ã€‚æˆ‘ä»¬çš„ä¸»è¦è´¡çŒ®åŒ…æ‹¬ï¼šï¼ˆ1ï¼‰å¯æ‰©å±•çš„å®Œå…¨å¼‚æ­¥RLè®­ç»ƒï¼Œèƒ½å¤Ÿåœ¨ç»´æŒé«˜æ•ˆè®­ç»ƒçš„åŒæ—¶å®ç°é•¿æœŸæœç´¢ã€‚ï¼ˆ2ï¼‰åŸºäºæç¤ºçš„å¤§å‹è¯­è¨€æ¨¡å‹ä»£ç†äººèƒ½å¤Ÿè‡ªä¸»åˆæˆé«˜è´¨é‡ã€å…·æœ‰æŒ‘æˆ˜æ€§çš„é—®ç­”ï¼Œåˆ›å»ºå¤§è§„æ¨¡é—®ç­”æ•°æ®é›†ã€‚é€šè¿‡å¼ºåŒ–å­¦ä¹ è®­ç»ƒï¼Œæˆ‘ä»¬çš„åŸºäºæç¤ºçš„QwQ-32Bä»£ç†äººå®ç°äº†æ˜¾è‘—æ”¹è¿›ï¼Œåœ¨xBenchå’ŒGAIAä¸Šåˆ†åˆ«å®ç°äº†46.7%å’Œ20.8%çš„Avg@4å¢ç›Šã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œæˆ‘ä»¬çš„ä»£ç†äººå±•ç¤ºäº†æç«¯çš„é•¿æœŸæœç´¢ï¼Œåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­çš„å·¥å…·è°ƒç”¨è¶…è¿‡40å›åˆï¼Œè¾“å‡ºä»¤ç‰Œè¶…è¿‡15ä¸‡ã€‚é€šè¿‡ç®€å•çš„ä»£ç†äººè®¾è®¡å’Œä¸ä½¿ç”¨å¤–éƒ¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ŒASearcher-Web-QwQåœ¨xBenchä¸Šå®ç°äº†42.1çš„Avg@4åˆ†æ•°ï¼Œåœ¨GAIAä¸Šå®ç°äº†52.8çš„åˆ†æ•°ï¼Œè¶…è¶Šäº†ç°æœ‰çš„å¼€æº32Bä»£ç†äººã€‚æˆ‘ä»¬åœ¨<a target="_blank" rel="noopener" href="https://github.com/inclusionAI/ASearcher%E5%BC%80%E6%BA%90%E6%88%91%E4%BB%AC%E7%9A%84%E6%A8%A1%E5%9E%8B%E3%80%81%E8%AE%AD%E7%BB%83%E6%95%B0%E6%8D%AE%E5%92%8C%E4%BB%A3%E7%A0%81%E3%80%82">https://github.com/inclusionAI/ASearcherå¼€æºæˆ‘ä»¬çš„æ¨¡å‹ã€è®­ç»ƒæ•°æ®å’Œä»£ç ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.07976v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>LLM-basedä»£ç†çš„æ–°è¿›å±•é€šè¿‡æ•´åˆå¤–éƒ¨å·¥å…·å±•ç°äº†å¤„ç†å¤æ‚ã€çŸ¥è¯†å¯†é›†å‹ä»»åŠ¡çš„èƒ½åŠ›ã€‚æœç´¢å·¥å…·åœ¨è®¿é—®å¤§é‡å¤–éƒ¨çŸ¥è¯†ä¸­å‘æŒ¥ç€å…³é”®ä½œç”¨ã€‚ç„¶è€Œï¼Œå¼€æºä»£ç†ä»æœªèƒ½å®ç°ä¸“å®¶çº§çš„æœç´¢æ™ºèƒ½ï¼Œå­˜åœ¨è§£å†³æ¨¡ç³ŠæŸ¥è¯¢ã€ç”Ÿæˆç²¾ç¡®æœç´¢ã€åˆ†æç»“æœå’Œå…¨é¢æ¢ç´¢çš„èƒ½åŠ›ä¸è¶³çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•å­˜åœ¨å¯æ‰©å±•æ€§ã€æ•ˆç‡å’Œæ•°æ®è´¨é‡æ–¹é¢çš„ä¸è¶³ã€‚æœ¬æ–‡ä»‹ç»äº†ASearcherï¼Œä¸€ä¸ªç”¨äºå¤§è§„æ¨¡RLè®­ç»ƒçš„å¼€æºé¡¹ç›®ã€‚ä¸»è¦è´¡çŒ®åŒ…æ‹¬ï¼šå¯ä¼¸ç¼©çš„å®Œå…¨å¼‚æ­¥RLè®­ç»ƒï¼Œèƒ½å¤Ÿåœ¨ç»´æŒé«˜æ•ˆè®­ç»ƒçš„åŒæ—¶è¿›è¡Œé•¿æœŸæœç´¢ï¼›åŸºäºæç¤ºçš„LLMä»£ç†èƒ½å¤Ÿè‡ªä¸»åˆæˆé«˜è´¨é‡ã€å…·æŒ‘æˆ˜æ€§çš„é—®ç­”ï¼Œåˆ›å»ºå¤§è§„æ¨¡QAæ•°æ®é›†ã€‚é€šè¿‡RLè®­ç»ƒï¼Œæˆ‘ä»¬çš„åŸºäºæç¤ºçš„QwQ-32Bä»£ç†åœ¨xBenchå’ŒGAIAä¸Šåˆ†åˆ«å®ç°äº†46.7%å’Œ20.8%çš„Avg@4å¢ç›Šã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œæˆ‘ä»¬çš„ä»£ç†å±•ç°äº†æç«¯é•¿æœŸæœç´¢ï¼Œè®­ç»ƒè¿‡ç¨‹ä¸­çš„å·¥å…·è°ƒç”¨è¶…è¿‡40è½®ï¼Œè¾“å‡ºä»¤ç‰Œè¶…è¿‡150kã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>LLM-basedä»£ç†åœ¨æ•´åˆå¤–éƒ¨å·¥å…·æ–¹é¢å±•ç°å‡ºè‰²ï¼Œå°¤å…¶åœ¨å¤„ç†å¤æ‚ã€çŸ¥è¯†å¯†é›†å‹ä»»åŠ¡æ—¶è¡¨ç°çªå‡ºã€‚</li>
<li>æœç´¢å·¥å…·åœ¨è®¿é—®å¤–éƒ¨çŸ¥è¯†ä¸­èµ·å…³é”®ä½œç”¨ï¼Œä½†ç°æœ‰å¼€æºä»£ç†åœ¨æœç´¢æ™ºèƒ½æ–¹é¢ä»æœ‰æ‰€æ¬ ç¼ºã€‚</li>
<li>å½“å‰æ–¹æ³•å­˜åœ¨å¯æ‰©å±•æ€§ã€æ•ˆç‡å’Œæ•°æ®è´¨é‡æ–¹é¢çš„æŒ‘æˆ˜ã€‚</li>
<li>ASearcheré¡¹ç›®é€šè¿‡å¼•å…¥å¯ä¼¸ç¼©çš„å®Œå…¨å¼‚æ­¥RLè®­ç»ƒï¼Œæé«˜äº†é•¿æœŸæœç´¢çš„èƒ½åŠ›å¹¶ä¿æŒé«˜æ•ˆã€‚</li>
<li>åŸºäºæç¤ºçš„LLMä»£ç†èƒ½è‡ªä¸»åˆæˆé«˜è´¨é‡QAæ•°æ®é›†ï¼Œæ˜¯ASearcherçš„ä¸€å¤§è´¡çŒ®ã€‚</li>
<li>QwQ-32Bä»£ç†é€šè¿‡RLè®­ç»ƒåœ¨xBenchå’ŒGAIAä¸Šå–å¾—äº†æ˜¾è‘—æˆç»©ï¼Œå±•ç°äº†å…¶æœ‰æ•ˆæ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.07976">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-1b095ee9ac1a8fb1afe7903d337f2916.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-c836bbede69c8863e7b4fbacbf3545ea.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-760778ade6cb934839ce86ea2ff26424.jpg" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1><h2 id="ContestTrade-A-Multi-Agent-Trading-System-Based-on-Internal-Contest-Mechanism"><a href="#ContestTrade-A-Multi-Agent-Trading-System-Based-on-Internal-Contest-Mechanism" class="headerlink" title="ContestTrade: A Multi-Agent Trading System Based on Internal Contest   Mechanism"></a>ContestTrade: A Multi-Agent Trading System Based on Internal Contest   Mechanism</h2><p><strong>Authors:Li Zhao, Rui Sun, Zuoyou Jiang, Bo Yang, Yuxiao Bai, Mengting Chen, Xinyang Wang, Jing Li, Zuo Bai</strong></p>
<p>In financial trading, large language model (LLM)-based agents demonstrate significant potential. However, the high sensitivity to market noise undermines the performance of LLM-based trading systems. To address this limitation, we propose a novel multi-agent system featuring an internal competitive mechanism inspired by modern corporate management structures. The system consists of two specialized teams: (1) Data Team - responsible for processing and condensing massive market data into diversified text factors, ensuring they fit the modelâ€™s constrained context. (2) Research Team - tasked with making parallelized multipath trading decisions based on deep research methods. The core innovation lies in implementing a real-time evaluation and ranking mechanism within each team, driven by authentic market feedback. Each agentâ€™s performance undergoes continuous scoring and ranking, with only outputs from top-performing agents being adopted. The design enables the system to adaptively adjust to dynamic environment, enhances robustness against market noise and ultimately delivers superior trading performance. Experimental results demonstrate that our proposed system significantly outperforms prevailing multi-agent systems and traditional quantitative investment methods across diverse evaluation metrics. ContestTrade is open-sourced on GitHub at <a target="_blank" rel="noopener" href="https://github.com/FinStep-AI/ContestTrade">https://github.com/FinStep-AI/ContestTrade</a>. </p>
<blockquote>
<p>åœ¨é‡‘èäº¤æ˜“é¢†åŸŸï¼ŒåŸºäºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„ä»£ç†å±•ç°å‡ºå·¨å¤§çš„æ½œåŠ›ã€‚ç„¶è€Œï¼Œå¯¹å¸‚åœºå™ªå£°çš„é«˜åº¦æ•æ„Ÿæ€§å‰Šå¼±äº†LLMäº¤æ˜“ç³»ç»Ÿçš„æ€§èƒ½ã€‚ä¸ºäº†è§£å†³è¿™ä¸€å±€é™æ€§ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°å‹çš„å¤šä»£ç†ç³»ç»Ÿï¼Œè¯¥ç³»ç»Ÿä»¥ç°ä»£ä¼ä¸šç®¡ç†ç»“æ„ä¸ºçµæ„Ÿï¼Œå…·å¤‡å†…éƒ¨ç«äº‰æœºåˆ¶ã€‚è¯¥ç³»ç»Ÿç”±ä¸¤ä¸ªä¸“ä¸šå›¢é˜Ÿç»„æˆï¼šï¼ˆ1ï¼‰æ•°æ®å›¢é˜Ÿâ€”â€”è´Ÿè´£å¤„ç†å’Œå‹ç¼©å¤§é‡å¸‚åœºæ•°æ®ï¼Œå°†å…¶è½¬åŒ–ä¸ºå¤šæ ·åŒ–çš„æ–‡æœ¬å› ç´ ï¼Œç¡®ä¿å®ƒä»¬ç¬¦åˆæ¨¡å‹çš„çº¦æŸè¯­å¢ƒã€‚ï¼ˆ2ï¼‰ç ”ç©¶å›¢é˜Ÿâ€”â€”ä»»åŠ¡æ˜¯åŸºäºæ·±åº¦ç ”ç©¶æ–¹æ³•åšå‡ºå¹¶è¡Œå¤šè·¯å¾„äº¤æ˜“å†³ç­–ã€‚æ ¸å¿ƒåˆ›æ–°åœ¨äºåœ¨æ¯ä¸ªå›¢é˜Ÿå†…éƒ¨å®æ–½å®æ—¶è¯„ä¼°å’Œæ’åæœºåˆ¶ï¼Œä»¥çœŸå®çš„å¸‚åœºåé¦ˆä¸ºé©±åŠ¨ã€‚æ¯ä¸ªä»£ç†çš„è¡¨ç°éƒ½ä¼šè¿›è¡ŒæŒç»­æ‰“åˆ†å’Œæ’åï¼Œåªæœ‰è¡¨ç°æœ€ä½³çš„ä»£ç†çš„è¾“å‡ºæ‰ä¼šè¢«é‡‡ç”¨ã€‚è¿™ç§è®¾è®¡ä½¿ç³»ç»Ÿèƒ½å¤Ÿè‡ªé€‚åº”åœ°è°ƒæ•´åŠ¨æ€ç¯å¢ƒï¼Œå¢å¼ºå¯¹å¸‚åœºå™ªå£°çš„ç¨³å¥æ€§ï¼Œå¹¶æœ€ç»ˆå®ç°ä¼˜è¶Šçš„äº¤æ˜“æ€§èƒ½ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬æå‡ºçš„ç³»ç»Ÿåœ¨å¤šç§è¯„ä¼°æŒ‡æ ‡ä¸Šæ˜¾è‘—ä¼˜äºç°æœ‰çš„å¤šä»£ç†ç³»ç»Ÿå’Œä¼ ç»Ÿçš„é‡åŒ–æŠ•èµ„æ–¹æ³•ã€‚ContestTradeå·²åœ¨GitHubä¸Šå¼€æºï¼Œç½‘å€ä¸ºï¼š<a target="_blank" rel="noopener" href="https://github.com/FinStep-AI/ContestTrade%E3%80%82">https://github.com/FinStep-AI/ContestTradeã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.00554v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„é‡‘èäº¤æ˜“ä»£ç†å±•ç°å‡ºå·¨å¤§æ½œåŠ›ï¼Œä½†æ˜“å—å¸‚åœºå™ªéŸ³å½±å“ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬æå‡ºä¸€ç§æ–°å‹å¤šä»£ç†ç³»ç»Ÿï¼Œå€Ÿé‰´ç°ä»£ä¼ä¸šç®¡ç†åˆ¶åº¦ä¸­çš„ç«äº‰æœºåˆ¶ã€‚ç³»ç»Ÿåˆ†ä¸ºæ•°æ®å›¢é˜Ÿå’Œç ”ç©¶å›¢é˜Ÿï¼Œåˆ†åˆ«è´Ÿè´£æ•°æ®å¤„ç†ä¸æ·±åº¦ç ”ç©¶å†³ç­–ã€‚åˆ›æ–°ä¹‹å¤„åœ¨äºå¼•å…¥å®æ—¶è¯„ä»·å’Œæ’åæœºåˆ¶ï¼Œé€šè¿‡å¸‚åœºåé¦ˆæ¥è¯„ä¼°æ¯ä¸ªä»£ç†çš„è¡¨ç°ï¼Œå¹¶åªé‡‡ç”¨è¡¨ç°æœ€ä½³çš„ä»£ç†è¾“å‡ºã€‚è¯¥ç³»ç»Ÿèƒ½é€‚åº”ç¯å¢ƒå˜åŒ–ï¼Œå¢å¼ºå¯¹å™ªéŸ³çš„ç¨³å¥æ€§ï¼Œæœ€ç»ˆæä¾›å‡ºè‰²çš„äº¤æ˜“æ€§èƒ½ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥ç³»ç»Ÿåœ¨å¤šä¸ªè¯„ä¼°æŒ‡æ ‡ä¸Šæ˜¾è‘—ä¼˜äºç°æœ‰å¤šä»£ç†ç³»ç»Ÿå’Œä¼ ç»Ÿé‡åŒ–æŠ•èµ„æ–¹æ³•ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤§å‹è¯­è¨€æ¨¡å‹åœ¨é‡‘èäº¤æ˜“é¢†åŸŸå±•ç°å‡ºå·¨å¤§æ½œåŠ›ã€‚</li>
<li>å¸‚åœºå™ªéŸ³å¯¹åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹çš„äº¤æ˜“ç³»ç»Ÿæ€§èƒ½äº§ç”Ÿè´Ÿé¢å½±å“ã€‚</li>
<li>æå‡ºä¸€ç§æ–°å‹å¤šä»£ç†ç³»ç»Ÿï¼Œå€Ÿé‰´ç°ä»£ä¼ä¸šç®¡ç†åˆ¶åº¦ä¸­çš„ç«äº‰æœºåˆ¶ä»¥æå‡æ€§èƒ½ã€‚</li>
<li>ç³»ç»ŸåŒ…å«æ•°æ®å›¢é˜Ÿå’Œç ”ç©¶å›¢é˜Ÿï¼Œåˆ†åˆ«è´Ÿè´£æ•°æ®å¤„ç†å’Œæ·±åº¦ç ”ç©¶å†³ç­–ã€‚</li>
<li>å®æ—¶è¯„ä»·å’Œæ’åæœºåˆ¶ç”¨äºè¯„ä¼°æ¯ä¸ªä»£ç†çš„è¡¨ç°ï¼Œå¹¶ä»…é‡‡ç”¨æœ€ä½³è¡¨ç°ä»£ç†çš„è¾“å‡ºã€‚</li>
<li>ç³»ç»Ÿèƒ½å¤Ÿé€‚åº”ç¯å¢ƒå˜åŒ–ï¼Œå¢å¼ºç¨³å¥æ€§ï¼Œå¯¹æŠ—å¸‚åœºå™ªéŸ³ã€‚</li>
<li>å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥ç³»ç»Ÿåœ¨å¤šä¸ªè¯„ä¼°æŒ‡æ ‡ä¸Šä¼˜äºç°æœ‰æ–¹æ³•å’Œä¼ ç»Ÿé‡åŒ–æŠ•èµ„æ‰‹æ®µã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.00554">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-ae0c6d44f2f14285a15e41b75bcf0f11.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-63a2a4554b46987fe5bbee5dd238d79e.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-845f97c4ca49462c05ce2a5ee8a567bf.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-f9d6f4cdc1d825c2c7632a2518b983be.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-8a0c12f5c6cfba9d27a3d774b509d09a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-9f25eb3b5bb11a003a53aa98f905ffe3.jpg" align="middle">
</details>


<h1 id="-9"><a href="#-9" class="headerlink" title=""></a></h1><h2 id="WebArXiv-Evaluating-Multimodal-Agents-on-Time-Invariant-arXiv-Tasks"><a href="#WebArXiv-Evaluating-Multimodal-Agents-on-Time-Invariant-arXiv-Tasks" class="headerlink" title="WebArXiv: Evaluating Multimodal Agents on Time-Invariant arXiv Tasks"></a>WebArXiv: Evaluating Multimodal Agents on Time-Invariant arXiv Tasks</h2><p><strong>Authors:Zihao Sun, Ling Chen</strong></p>
<p>Recent progress in large language models (LLMs) has enabled the development of autonomous web agents capable of navigating and interacting with real websites. However, evaluating such agents remains challenging due to the instability and inconsistency of existing benchmarks, which often rely on dynamic content or oversimplified simulations. In this work, we introduce WebArXiv, a static and time-invariant benchmark comprising 275 web-based tasks grounded in the arXiv platform. WebArXiv ensures reproducible and reliable evaluation by anchoring tasks in fixed web snapshots with deterministic ground truths and standardized action trajectories. Through behavioral analysis, we identify a common failure mode, Rigid History Reflection, where agents over-rely on fixed interaction histories. To address this, we propose a lightweight dynamic reflection mechanism that allows agents to selectively retrieve relevant past steps during decision-making. We evaluate ten state-of-the-art web agents on WebArXiv. Results demonstrate clear performance differences across agents and validate the effectiveness of our proposed reflection strategy. </p>
<blockquote>
<p>æœ€è¿‘ï¼Œå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„è¿›å±•ä¸ºèƒ½å¤Ÿå¯¼èˆªå’Œä¸ç°å®ç½‘ç«™è¿›è¡Œäº¤äº’çš„è‡ªä¸»ç½‘ç»œä»£ç†çš„å‘å±•æä¾›äº†å¯èƒ½ã€‚ç„¶è€Œï¼Œç”±äºç°æœ‰åŸºå‡†æµ‹è¯•çš„ä¸ç¨³å®šæ€§å’Œä¸ä¸€è‡´æ€§ï¼Œè¯„ä¼°æ­¤ç±»ä»£ç†ä»ç„¶å…·æœ‰æŒ‘æˆ˜æ€§ï¼Œè¿™äº›åŸºå‡†æµ‹è¯•é€šå¸¸ä¾èµ–äºåŠ¨æ€å†…å®¹æˆ–è¿‡äºç®€åŒ–çš„æ¨¡æ‹Ÿã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬ä»‹ç»äº†WebArXivï¼Œè¿™æ˜¯ä¸€ä¸ªç”±åŸºäºarXivå¹³å°çš„275ä¸ªç½‘ç»œä»»åŠ¡ç»„æˆçš„é™æ€ä¸”æ—¶é—´ä¸å˜çš„åŸºå‡†æµ‹è¯•ã€‚WebArXivé€šè¿‡é”šå®šä»»åŠ¡åœ¨å›ºå®šçš„ç½‘ç»œå¿«ç…§ä¸­ï¼Œç¡®ä¿å…·æœ‰å¯é‡å¤æ€§å’Œå¯é æ€§çš„è¯„ä¼°ï¼Œå¹¶å…·æœ‰ç¡®å®šæ€§çš„çœŸå®ä¾æ®å’Œæ ‡å‡†åŒ–çš„è¡ŒåŠ¨è½¨è¿¹ã€‚é€šè¿‡è¡Œä¸ºåˆ†æï¼Œæˆ‘ä»¬å‘ç°äº†ä¸€ç§å¸¸è§çš„å¤±è´¥æ¨¡å¼ï¼Œå³åˆšæ€§å†å²åå°„ï¼Œä»£ç†è¿‡åº¦ä¾èµ–äºå›ºå®šçš„äº¤äº’å†å²è®°å½•ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§è½»é‡çº§çš„åŠ¨æ€åå°„æœºåˆ¶ï¼Œå…è®¸ä»£ç†åœ¨å†³ç­–è¿‡ç¨‹ä¸­æœ‰é€‰æ‹©åœ°æ£€ç´¢ç›¸å…³çš„è¿‡å»æ­¥éª¤ã€‚æˆ‘ä»¬åœ¨WebArXivä¸Šè¯„ä¼°äº†åä¸ªæœ€å…ˆè¿›çš„ç½‘ç»œä»£ç†ã€‚ç»“æœè¡¨æ˜ï¼Œå„ä»£ç†ä¹‹é—´çš„æ€§èƒ½å·®å¼‚æ˜¾è‘—ï¼Œå¹¶éªŒè¯äº†æˆ‘ä»¬æ‰€æå‡ºçš„åå°„ç­–ç•¥çš„æœ‰æ•ˆæ€§ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2507.00938v2">PDF</a> 10 pages, 9 figures, 4 tables</p>
<p><strong>Summary</strong></p>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„æœ€æ–°è¿›å±•ä½¿å¾—èƒ½å¤Ÿå¼€å‘å‡ºå¯ä»¥æµè§ˆå’Œä¸ç°å®ç½‘ç«™äº¤äº’çš„è‡ªä¸»ç½‘ç»œä»£ç†ã€‚ç„¶è€Œï¼Œç”±äºç°æœ‰åŸºå‡†æµ‹è¯•çš„ä¸ç¨³å®šæ€§å’Œä¸ä¸€è‡´æ€§ï¼Œè¯„ä¼°è¿™äº›ä»£ç†ä»ç„¶å…·æœ‰æŒ‘æˆ˜æ€§ã€‚è¿™é¡¹å·¥ä½œä»‹ç»äº†WebArXivï¼Œä¸€ä¸ªç”±åŸºäºarXivå¹³å°çš„ç½‘ç»œä»»åŠ¡ç»„æˆçš„é™æ€ä¸”æ—¶é—´ä¸å˜çš„åŸºå‡†æµ‹è¯•ã€‚WebArXivé€šè¿‡å°†ä»»åŠ¡é”šå®šåœ¨å…·æœ‰ç¡®å®šæ€§åœ°é¢çœŸç›¸å’Œæ ‡å‡†è¡ŒåŠ¨è½¨è¿¹çš„å›ºå®šç½‘é¡µå¿«ç…§ä¸Šï¼Œç¡®ä¿å¯é‡å¤å’Œå¯é çš„è¯„ä¼°ã€‚é€šè¿‡è¡Œä¸ºåˆ†æï¼Œæˆ‘ä»¬ç¡®å®šäº†å¸¸è§çš„å¤±è´¥æ¨¡å¼â€”â€”åˆšæ€§å†å²åå°„ï¼Œå³ä»£ç†è¿‡åº¦ä¾èµ–å›ºå®šçš„äº¤äº’å†å²ã€‚ä¸ºè§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§è½»é‡çº§çš„åŠ¨æ€åå°„æœºåˆ¶ï¼Œå…è®¸ä»£ç†åœ¨å†³ç­–è¿‡ç¨‹ä¸­æœ‰é€‰æ‹©åœ°æ£€ç´¢ç›¸å…³çš„è¿‡å»æ­¥éª¤ã€‚æˆ‘ä»¬å¯¹åä¸ªæœ€å…ˆè¿›çš„ç½‘ç»œä»£ç†è¿›è¡Œäº†WebArXivè¯„ä¼°ã€‚ç»“æœè¡¨æ˜å„ä»£ç†ä¹‹é—´çš„æ€§èƒ½å·®å¼‚æ˜¾è‘—ï¼Œå¹¶éªŒè¯äº†æˆ‘ä»¬æ‰€æå‡ºçš„åå°„ç­–ç•¥çš„æœ‰æ•ˆæ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„è¿›æ­¥ä¿ƒè¿›äº†è‡ªä¸»ç½‘ç»œä»£ç†çš„å‘å±•ï¼Œèƒ½å¤Ÿä¸ç°å®ç½‘ç«™äº¤äº’ã€‚</li>
<li>ç°æœ‰ä»£ç†è¯„ä¼°åŸºå‡†æµ‹è¯•å­˜åœ¨ä¸ç¨³å®šæ€§å’Œä¸ä¸€è‡´æ€§é—®é¢˜ã€‚</li>
<li>ä»‹ç»äº†WebArXivï¼Œä¸€ä¸ªé™æ€ä¸”æ—¶é—´ä¸å˜çš„åŸºå‡†æµ‹è¯•ï¼Œç”±åŸºäºarXivå¹³å°çš„ç½‘ç»œä»»åŠ¡ç»„æˆã€‚</li>
<li>WebArXivé€šè¿‡å›ºå®šç½‘é¡µå¿«ç…§ç¡®ä¿å¯é‡å¤å’Œå¯é çš„è¯„ä¼°ï¼Œå…·æœ‰ç¡®å®šæ€§åœ°é¢çœŸç›¸å’Œæ ‡å‡†è¡ŒåŠ¨è½¨è¿¹ã€‚</li>
<li>å‘ç°äº†ä»£ç†å¸¸è§çš„å¤±è´¥æ¨¡å¼â€”â€”åˆšæ€§å†å²åå°„ï¼Œå³è¿‡åº¦ä¾èµ–å›ºå®šäº¤äº’å†å²ã€‚</li>
<li>ä¸ºè§£å†³è¿™ä¸€é—®é¢˜ï¼Œæå‡ºäº†è½»é‡çº§çš„åŠ¨æ€åå°„æœºåˆ¶ï¼Œå…è®¸ä»£ç†åœ¨å†³ç­–æ—¶é€‰æ‹©æ€§æ£€ç´¢ç›¸å…³å†å²ä¿¡æ¯ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2507.00938">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-9955233532663f175fdee354a528fa5e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b82a1ef1172789c0a65cb29ab3c629f0.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-7e9df62d1c8d45d5cf792d50faae6ea1.jpg" align="middle">
</details>


<h1 id="-10"><a href="#-10" class="headerlink" title=""></a></h1><h2 id="MetaCipher-A-Time-Persistent-and-Universal-Multi-Agent-Framework-for-Cipher-Based-Jailbreak-Attacks-for-LLMs"><a href="#MetaCipher-A-Time-Persistent-and-Universal-Multi-Agent-Framework-for-Cipher-Based-Jailbreak-Attacks-for-LLMs" class="headerlink" title="MetaCipher: A Time-Persistent and Universal Multi-Agent Framework for   Cipher-Based Jailbreak Attacks for LLMs"></a>MetaCipher: A Time-Persistent and Universal Multi-Agent Framework for   Cipher-Based Jailbreak Attacks for LLMs</h2><p><strong>Authors:Boyuan Chen, Minghao Shao, Abdul Basit, Siddharth Garg, Muhammad Shafique</strong></p>
<p>As large language models (LLMs) grow more capable, they face growing vulnerability to sophisticated jailbreak attacks. While developers invest heavily in alignment finetuning and safety guardrails, researchers continue publishing novel attacks, driving progress through adversarial iteration. This dynamic mirrors a strategic game of continual evolution. However, two major challenges hinder jailbreak development: the high cost of querying top-tier LLMs and the short lifespan of effective attacks due to frequent safety updates. These factors limit cost-efficiency and practical impact of research in jailbreak attacks. To address this, we propose MetaCipher, a low-cost, multi-agent jailbreak framework that generalizes across LLMs with varying safety measures. Using reinforcement learning, MetaCipher is modular and adaptive, supporting extensibility to future strategies. Within as few as 10 queries, MetaCipher achieves state-of-the-art attack success rates on recent malicious prompt benchmarks, outperforming prior jailbreak methods. We conduct a large-scale empirical evaluation across diverse victim models and benchmarks, demonstrating its robustness and adaptability. Warning: This paper contains model outputs that may be offensive or harmful, shown solely to demonstrate jailbreak efficacy. </p>
<blockquote>
<p>éšç€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„èƒ½åŠ›è¶Šæ¥è¶Šå¼ºï¼Œå®ƒä»¬é¢ä¸´è¶Šæ¥è¶Šå¤æ‚çš„è¶Šç‹±æ”»å‡»ï¼ˆjailbreak attacksï¼‰çš„å¨èƒã€‚è™½ç„¶å¼€å‘è€…åœ¨å¾®è°ƒå¯¹é½å’Œå®‰å…¨é˜²æŠ¤æ–¹é¢æŠ•å…¥äº†å¤§é‡ç²¾åŠ›ï¼Œä½†ç ”ç©¶è€…ä»¬ä»åœ¨ä¸æ–­å‘å¸ƒæ–°å‹æ”»å‡»æ–¹æ³•ï¼Œé€šè¿‡å¯¹æŠ—è¿­ä»£æ¨åŠ¨æŠ€æœ¯è¿›æ­¥ã€‚è¿™ç§åŠ¨æ€åæ˜ äº†ä¸€ç§æŒç»­æ¼”åŒ–çš„æˆ˜ç•¥åšå¼ˆã€‚ç„¶è€Œï¼Œå­˜åœ¨ä¸¤å¤§æŒ‘æˆ˜é˜»ç¢è¶Šç‹±æ”»å‡»çš„å‘å±•ï¼šä¸€æ˜¯æŸ¥è¯¢é¡¶å°–LLMçš„æˆæœ¬é«˜æ˜‚ï¼ŒäºŒæ˜¯ç”±äºé¢‘ç¹çš„å®‰å…¨æ›´æ–°ï¼Œæœ‰æ•ˆæ”»å‡»çš„å¯¿å‘½çŸ­æš‚ã€‚è¿™äº›å› ç´ é™åˆ¶äº†è¶Šç‹±æ”»å‡»ç ”ç©¶ä¸­æˆæœ¬å’Œå®é™…å½±å“çš„æ•ˆç‡ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†MetaCipherï¼Œä¸€ä¸ªä½æˆæœ¬ã€å¤šä»£ç†çš„è¶Šç‹±æ¡†æ¶ï¼Œå¯è·¨å…·æœ‰ä¸åŒå®‰å…¨æªæ–½çš„LLMè¿›è¡Œé€šç”¨åŒ–ã€‚ä½¿ç”¨å¼ºåŒ–å­¦ä¹ ï¼ŒMetaCipherå…·æœ‰æ¨¡å—åŒ–å’Œè‡ªé€‚åº”çš„ç‰¹ç‚¹ï¼Œæ”¯æŒæœªæ¥ç­–ç•¥çš„æ‰©å±•æ€§ã€‚åœ¨ä»…10æ¬¡æŸ¥è¯¢å†…ï¼ŒMetaCipherè¾¾åˆ°äº†æœ€æ–°æ¶æ„æç¤ºåŸºå‡†æµ‹è¯•çš„æ”»å‡»æˆåŠŸç‡ä¹‹å·…ï¼Œè¶…è¶Šäº†å…ˆå‰çš„è¶Šç‹±æ–¹æ³•ã€‚æˆ‘ä»¬å¯¹å„ç§ä¸åŒçš„å—å®³è€…æ¨¡å‹å’ŒåŸºå‡†æµ‹è¯•è¿›è¡Œäº†å¤§è§„æ¨¡çš„ç»éªŒè¯„ä¼°ï¼Œè¯æ˜äº†å…¶ç¨³å¥æ€§å’Œé€‚åº”æ€§ã€‚è­¦å‘Šï¼šæœ¬è®ºæ–‡åŒ…å«å¯èƒ½å…·æœ‰æ”»å‡»æ€§æˆ–æœ‰å®³æ€§çš„æ¨¡å‹è¾“å‡ºï¼Œä»…ç”¨äºå±•ç¤ºè¶Šç‹±æ•ˆæœã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.22557v2">PDF</a> </p>
<p><strong>Summary</strong><br>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰éšç€åŠŸèƒ½ä¸æ–­å¢å¼ºï¼Œé¢ä¸´ç€æ—¥ç›Šå¢é•¿çš„å¤æ‚è¶Šç‹±æ”»å‡»é£é™©ã€‚å°½ç®¡å¼€å‘äººå‘˜åœ¨å®‰å…¨æ›´æ–°æ–¹é¢æŠ•å…¥äº†å¤§é‡åŠªåŠ›ï¼Œç ”ç©¶è€…ä»ä¸æ–­æ¨å‡ºæ–°å‹æ”»å‡»æ–¹æ³•ï¼Œé€šè¿‡å¯¹æŠ—æ€§è¿­ä»£æ¨åŠ¨æŠ€æœ¯è¿›æ­¥ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬æå‡ºäº†MetaCipherï¼Œä¸€ä¸ªä½æˆæœ¬ã€å¤šæ™ºèƒ½ä½“çš„è¶Šç‹±æ¡†æ¶ï¼Œèƒ½å¤Ÿåº”å¯¹ä¸åŒå®‰å…¨æªæ–½çš„LLMsã€‚MetaCipherä½¿ç”¨å¼ºåŒ–å­¦ä¹ ï¼Œå…·æœ‰æ¨¡å—åŒ–å’Œè‡ªé€‚åº”ç‰¹ç‚¹ï¼Œæœªæ¥ç­–ç•¥å…·æœ‰å¯æ‰©å±•æ€§ã€‚å®ƒåœ¨å°‘é‡æŸ¥è¯¢å†…è¾¾åˆ°äº†é’ˆå¯¹æœ€æ–°æ¶æ„æç¤ºåŸºå‡†æµ‹è¯•çš„æœ€å…ˆè¿›æ”»å‡»æˆåŠŸç‡ï¼Œè¶…è¶Šäº†ä¹‹å‰çš„è¶Šç‹±æ–¹æ³•ã€‚å¤§è§„æ¨¡å®è¯ç ”ç©¶è¯æ˜äº†å…¶ç¨³å¥æ€§å’Œé€‚åº”æ€§ã€‚è¯·æ³¨æ„ï¼Œæœ¬æ–‡ä¸­åŒ…å«çš„æ¨¡å‹è¾“å‡ºå¯èƒ½å…·æœ‰æ”»å‡»æ€§æˆ–æœ‰å®³æ€§ï¼Œä»…ç”¨äºå±•ç¤ºè¶Šç‹±æ•ˆæœã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰éšç€åŠŸèƒ½å¢å¼ºï¼Œé¢ä¸´æ›´å¤æ‚è¶Šç‹±æ”»å‡»é£é™©ã€‚</li>
<li>å¼€å‘è€…åœ¨å®‰å…¨é˜²æŠ¤æ–¹é¢æŠ•å…¥å¤§é‡åŠªåŠ›ï¼Œä½†ç ”ç©¶è€…ä»æ¨å‡ºæ–°å‹æ”»å‡»æ–¹æ³•ã€‚</li>
<li>MetaCipheræ˜¯ä¸€ä¸ªä½æˆæœ¬ã€å¤šæ™ºèƒ½ä½“çš„è¶Šç‹±æ¡†æ¶ï¼Œèƒ½å¤Ÿåº”å¯¹ä¸åŒå®‰å…¨æªæ–½çš„LLMsã€‚</li>
<li>MetaCipherä½¿ç”¨å¼ºåŒ–å­¦ä¹ ï¼Œå…·æœ‰æ¨¡å—åŒ–å’Œè‡ªé€‚åº”ç‰¹ç‚¹ã€‚</li>
<li>MetaCipheråœ¨å°‘é‡æŸ¥è¯¢å†…è¾¾åˆ°äº†é’ˆå¯¹æœ€æ–°æ¶æ„æç¤ºåŸºå‡†æµ‹è¯•çš„æœ€å…ˆè¿›æ”»å‡»æˆåŠŸç‡ã€‚</li>
<li>MetaCipherç»è¿‡å¤§è§„æ¨¡å®è¯ç ”ç©¶è¯æ˜å…¶ç¨³å¥æ€§å’Œé€‚åº”æ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.22557">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-9e2682585be26b15438b2303770c43ea.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-411d6c92d715a181d2bd8f075b0242e5.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-04df01b9a711fc44d67a8d103e3b5d39.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-e157b7208b1a53ace023057ac3841a4f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b1b0bb06a341eacd361ff525de4c4447.jpg" align="middle">
</details>


<h1 id="-11"><a href="#-11" class="headerlink" title=""></a></h1><h2 id="AgentOrchestra-A-Hierarchical-Multi-Agent-Framework-for-General-Purpose-Task-Solving"><a href="#AgentOrchestra-A-Hierarchical-Multi-Agent-Framework-for-General-Purpose-Task-Solving" class="headerlink" title="AgentOrchestra: A Hierarchical Multi-Agent Framework for General-Purpose   Task Solving"></a>AgentOrchestra: A Hierarchical Multi-Agent Framework for General-Purpose   Task Solving</h2><p><strong>Authors:Wentao Zhang, Liang Zeng, Yuzhen Xiao, Yongcong Li, Ce Cui, Yilei Zhao, Rui Hu, Yang Liu, Yahui Zhou, Bo An</strong></p>
<p>Recent advances in agent systems have demonstrated remarkable capabilities in solving both general-purpose and highly complex tasks. However, most current models lack mechanisms for coordinating specialized agents and have limited ability to generalize to new or diverse domains. To this end, we introduce AgentOrchestra, a hierarchical multi-agent framework for general-purpose task solving that integrates high-level planning with modular agent collaboration. Drawing inspiration from a conductor orchestrating a symphony, and grounded in the principles of extensibility, multimodality, modularity, and coordination, it features a central planning agent that decomposes complex objectives and delegates sub-tasks to a team of specialized agents. Each sub-agent is equipped with general programming tools, as well as abilities to tackle a wide range of real-world specific tasks, including data analysis, file operations, web navigation, and interactive reasoning in dynamic multimodal environments. Notably, AgentOrchestra introduces an MCP Manager Agent that enables intelligent evolution through dynamic tool creation, retrieval, and reuse mechanisms, significantly enhancing the systemâ€™s adaptability and scalability. AgentOrchestra supports flexible orchestration through explicit sub-goal formulation, inter-agent communication, and adaptive role allocation. We evaluate the framework on three widely used benchmarks for assessing LLM-based agent systems. Experimental results show that AgentOrchestra consistently outperforms flat-agent and monolithic baselines in terms of task success rate and adaptability. On the GAIA benchmark testing dataset, AgentOrchestra achieves an average score of 83.39%, ranking among the top general-purpose agents. These results highlight the effectiveness of hierarchical organization and role specialization in building scalable and general-purpose LLM-based agent systems. </p>
<blockquote>
<p>è¿‘æœŸä»£ç†ç³»ç»Ÿé¢†åŸŸçš„è¿›å±•åœ¨è§£å†³é€šç”¨å’Œé«˜å¤æ‚åº¦ä»»åŠ¡æ–¹é¢è¡¨ç°å‡ºäº†æ˜¾è‘—çš„èƒ½åŠ›ã€‚ç„¶è€Œï¼Œå½“å‰å¤§å¤šæ•°æ¨¡å‹ç¼ºä¹åè°ƒä¸“ä¸šä»£ç†çš„æœºåˆ¶ï¼Œä¸”åœ¨æ–°é¢†åŸŸæˆ–å¤šæ ·é¢†åŸŸçš„æ³›åŒ–èƒ½åŠ›æœ‰é™ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬å¼•å…¥äº†AgentOrchestraï¼Œè¿™æ˜¯ä¸€ä¸ªç”¨äºé€šç”¨ä»»åŠ¡è§£å†³çš„åˆ†å±‚å¤šä»£ç†æ¡†æ¶ï¼Œå®ƒå°†é«˜çº§è§„åˆ’ä¸æ¨¡å—åŒ–ä»£ç†åä½œé›†æˆåœ¨ä¸€èµ·ã€‚å®ƒå€Ÿé‰´äº†æŒ‡æŒ¥åè°ƒäº¤å“ä¹å›¢çš„çµæ„Ÿï¼Œå¹¶åŸºäºå¯æ‰©å±•æ€§ã€å¤šæ¨¡æ€æ€§ã€æ¨¡å—åŒ–å’Œåè°ƒçš„åŸåˆ™ï¼Œæ‹¥æœ‰ä¸€ä¸ªä¸­å¤®è§„åˆ’ä»£ç†ï¼Œå¯ä»¥åˆ†è§£å¤æ‚ç›®æ ‡å¹¶å°†å­ä»»åŠ¡å§”æ´¾ç»™ä¸€ç»„ä¸“ä¸šä»£ç†ã€‚æ¯ä¸ªå­ä»£ç†éƒ½é…å¤‡äº†é€šç”¨ç¼–ç¨‹å·¥å…·ï¼Œä»¥åŠå¤„ç†å„ç§ç°å®ä¸–ç•Œç‰¹å®šä»»åŠ¡çš„èƒ½åŠ›ï¼ŒåŒ…æ‹¬æ•°æ®åˆ†æã€æ–‡ä»¶æ“ä½œã€ç½‘ç»œå¯¼èˆªä»¥åŠåœ¨åŠ¨æ€å¤šæ¨¡å¼ç¯å¢ƒä¸­çš„äº¤äº’æ¨ç†ã€‚å€¼å¾—ä¸€æçš„æ˜¯ï¼ŒAgentOrchestraå¼•å…¥äº†ä¸€ä¸ªMCPç®¡ç†ä»£ç†ï¼Œé€šè¿‡åŠ¨æ€çš„å·¥å…·åˆ›å»ºã€æ£€ç´¢å’Œå†åˆ©ç”¨æœºåˆ¶ï¼Œå®ç°äº†æ™ºèƒ½è¿›åŒ–ï¼Œæ˜¾è‘—å¢å¼ºäº†ç³»ç»Ÿçš„é€‚åº”æ€§å’Œå¯æ‰©å±•æ€§ã€‚AgentOrchestraé€šè¿‡æ˜ç¡®çš„å­ç›®æ ‡åˆ¶å®šã€ä»£ç†é—´é€šä¿¡å’Œè‡ªé€‚åº”è§’è‰²åˆ†é…æ¥æ”¯æŒçµæ´»ç¼–æ’ã€‚æˆ‘ä»¬åœ¨ä¸‰ä¸ªå¹¿æ³›ä½¿ç”¨çš„è¯„ä¼°LLMåŸºäºä»£ç†ç³»ç»Ÿçš„åŸºå‡†æµ‹è¯•ä¸Šå¯¹æ¡†æ¶è¿›è¡Œäº†è¯„ä¼°ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œåœ¨ä»»åŠ¡æˆåŠŸç‡å’Œé€‚åº”æ€§æ–¹é¢ï¼ŒAgentOrchestraæŒç»­ä¼˜äºå¹³é¢ä»£ç†å’Œå•ä¸€åŸºå‡†æµ‹è¯•ã€‚åœ¨GAIAåŸºå‡†æµ‹è¯•æ•°æ®é›†ä¸Šï¼ŒAgentOrchestraçš„å¹³å‡å¾—åˆ†ä¸º8_ç™¾åˆ†ä¹‹ä¸‰åä¸‰ç‚¹ä¸‰ï¼ˆçº¦åˆç™¾åˆ†ä¹‹å…«åä¸‰ï¼‰ï¼Œä½å±…é€šç”¨ä»£ç†ä¹‹é¦–ã€‚è¿™äº›ç»“æœçªå‡ºäº†åˆ†å±‚ç»„ç»‡å’Œè§’è‰²ä¸“ä¸šåŒ–åœ¨æ„å»ºå¯æ‰©å±•å’Œé€šç”¨çš„LLMåŸºäºä»£ç†ç³»ç»Ÿæ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.12508v3">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>AgentOrchestraæ˜¯ä¸€ä¸ªç”¨äºé€šç”¨ä»»åŠ¡è§£å†³çš„å¤šå±‚æ¬¡å¤šæ™ºèƒ½ä½“æ¡†æ¶ï¼Œå®ƒèåˆäº†é«˜çº§è§„åˆ’ä¸æ¨¡å—åŒ–æ™ºèƒ½ä½“åä½œã€‚è¯¥æ¡†æ¶å€Ÿé‰´äº†æŒ‡æŒ¥äº¤å“ä¹çš„æ€ç»´ï¼Œå±•ç°å‡ºæ‰©å±•æ€§ã€å¤šæ¨¡æ€æ€§ã€æ¨¡å—åŒ–å’Œåè°ƒçš„åŸåˆ™ã€‚é€šè¿‡ä¸­å¤®è§„åˆ’æ™ºèƒ½ä½“åˆ†è§£å¤æ‚ç›®æ ‡å¹¶å§”æ´¾å­ä»»åŠ¡ç»™ä¸“ä¸šæ™ºèƒ½ä½“å›¢é˜Ÿï¼Œå®ç°äº†æ™ºèƒ½ååŒã€‚æ¯ä¸ªå­æ™ºèƒ½ä½“å…·å¤‡é€šç”¨ç¼–ç¨‹å·¥å…·ä»¥åŠåº”å¯¹å¤šç§ç°å®ç‰¹å®šä»»åŠ¡çš„èƒ½åŠ›ã€‚æ­¤å¤–ï¼ŒAgentOrchestraå¼•å…¥äº†MCPç®¡ç†æ™ºèƒ½ä½“ï¼Œé€šè¿‡åŠ¨æ€åˆ›å»ºã€æ£€ç´¢å’Œé‡ç”¨å·¥å…·å®ç°æ™ºèƒ½è¿›åŒ–ï¼Œå¢å¼ºäº†ç³»ç»Ÿçš„é€‚åº”æ€§å’Œå¯æ‰©å±•æ€§ã€‚è¯„ä¼°ç»“æœæ˜¾ç¤ºï¼ŒAgentOrchestraåœ¨ä»»åŠ¡æˆåŠŸç‡å’Œé€‚åº”æ€§æ–¹é¢è¶…è¶Šæ‰å¹³æ™ºèƒ½ä½“å’Œå•ä¸€åŸºå‡†æµ‹è¯•ï¼Œä¸”åœ¨GAIAåŸºå‡†æµ‹è¯•æ•°æ®é›†ä¸­å¹³å‡å¾—åˆ†è¾¾83.39%ï¼Œæˆä¸ºé¡¶å°–é€šç”¨æ™ºèƒ½ä½“ä¹‹ä¸€ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>AgentOrchestraæ˜¯ä¸€ä¸ªå¤šå±‚æ¬¡å¤šæ™ºèƒ½ä½“æ¡†æ¶ï¼Œç”¨äºè§£å†³é€šç”¨ä»»åŠ¡ã€‚</li>
<li>èåˆäº†é«˜çº§è§„åˆ’ä¸æ¨¡å—åŒ–æ™ºèƒ½ä½“åä½œï¼Œå€Ÿé‰´æŒ‡æŒ¥äº¤å“ä¹çš„æ€ç»´ã€‚</li>
<li>å±•ç°å‡ºæ‰©å±•æ€§ã€å¤šæ¨¡æ€æ€§ã€æ¨¡å—åŒ–å’Œåè°ƒçš„åŸåˆ™ã€‚</li>
<li>ä¸­å¤®è§„åˆ’æ™ºèƒ½ä½“è´Ÿè´£åˆ†è§£å¤æ‚ç›®æ ‡å¹¶å§”æ´¾å­ä»»åŠ¡ç»™ä¸“ä¸šæ™ºèƒ½ä½“å›¢é˜Ÿã€‚</li>
<li>æ¯ä¸ªå­æ™ºèƒ½ä½“å…·å¤‡é€šç”¨ç¼–ç¨‹å·¥å…·ä»¥åŠåº”å¯¹å¤šç§ç°å®ç‰¹å®šä»»åŠ¡çš„èƒ½åŠ›ã€‚</li>
<li>AgentOrchestraå¼•å…¥äº†MCPç®¡ç†æ™ºèƒ½ä½“ï¼Œå¢å¼ºäº†ç³»ç»Ÿçš„é€‚åº”æ€§å’Œå¯æ‰©å±•æ€§ã€‚</li>
<li>AgentOrchestraåœ¨ä»»åŠ¡æˆåŠŸç‡å’Œé€‚åº”æ€§æ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œä¸”åœ¨GAIAåŸºå‡†æµ‹è¯•ä¸­å¾—åˆ†é«˜ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.12508">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-20226e53d3c52c4aef04294f8755b5e9.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-6089fe933ce6f60df2807dba1c4447f9.jpg" align="middle">
</details>


<h1 id="-12"><a href="#-12" class="headerlink" title=""></a></h1><h2 id="DefenderBench-A-Toolkit-for-Evaluating-Language-Agents-in-Cybersecurity-Environments"><a href="#DefenderBench-A-Toolkit-for-Evaluating-Language-Agents-in-Cybersecurity-Environments" class="headerlink" title="DefenderBench: A Toolkit for Evaluating Language Agents in Cybersecurity   Environments"></a>DefenderBench: A Toolkit for Evaluating Language Agents in Cybersecurity   Environments</h2><p><strong>Authors:Chiyu Zhang, Marc-Alexandre Cote, Michael Albada, Anush Sankaran, Jack W. Stokes, Tong Wang, Amir Abdi, William Blum, Muhammad Abdul-Mageed</strong></p>
<p>Large language model (LLM) agents have shown impressive capabilities in human language comprehension and reasoning, yet their potential in cybersecurity remains underexplored. We introduce DefenderBench, a practical, open-source toolkit for evaluating language agents across offense, defense, and cybersecurity knowledge-based tasks. DefenderBench includes environments for network intrusion, malicious content detection, code vulnerability analysis, and cybersecurity knowledge assessment. It is intentionally designed to be affordable and easily accessible for researchers while providing fair and rigorous assessment. We benchmark several state-of-the-art (SoTA) and popular LLMs, including both open- and closed-weight models, using a standardized agentic framework. Our results show that Claude-3.7-sonnet performs best with a DefenderBench score of 81.65, followed by Claude-3.7-sonnet-think with 78.40, while the best open-weight model, Llama 3.3 70B, is not far behind with a DefenderBench score of 71.81. DefenderBenchâ€™s modular design allows seamless integration of custom LLMs and tasks, promoting reproducibility and fair comparisons. An anonymized version of DefenderBench is available at <a target="_blank" rel="noopener" href="https://github.com/microsoft/DefenderBench">https://github.com/microsoft/DefenderBench</a>. </p>
<blockquote>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä»£ç†åœ¨äººç±»è¯­è¨€ç†è§£å’Œæ¨ç†æ–¹é¢å±•ç¤ºäº†ä»¤äººå°è±¡æ·±åˆ»çš„èƒ½åŠ›ï¼Œç„¶è€Œå®ƒä»¬åœ¨ç½‘ç»œå®‰å…¨æ–¹é¢çš„æ½œåŠ›å°šæœªè¢«å……åˆ†æ¢ç´¢ã€‚æˆ‘ä»¬æ¨å‡ºäº†DefenderBenchï¼Œè¿™æ˜¯ä¸€ä¸ªå®ç”¨çš„å¼€æºå·¥å…·åŒ…ï¼Œå¯ä»¥åœ¨è¿›æ”»ã€é˜²å¾¡å’ŒåŸºäºç½‘ç»œå®‰å…¨çŸ¥è¯†çš„ä»»åŠ¡ä¸­è¯„ä¼°è¯­è¨€ä»£ç†ã€‚DefenderBenchåŒ…æ‹¬ç½‘ç»œå…¥ä¾µã€æ¶æ„å†…å®¹æ£€æµ‹ã€ä»£ç æ¼æ´åˆ†æå’Œç½‘ç»œå®‰å…¨çŸ¥è¯†è¯„ä¼°çš„ç¯å¢ƒã€‚å®ƒç‰¹æ„ä¸ºç ”ç©¶è€…ä»¬è®¾è®¡ï¼Œæ—¨åœ¨æä¾›å…¬å¹³ä¸¥æ ¼çš„è¯„ä¼°ï¼ŒåŒæ—¶ä¿æŒç»æµå®æƒ å’Œæ˜“äºè®¿é—®ã€‚æˆ‘ä»¬ä½¿ç”¨æ ‡å‡†åŒ–çš„ä»£ç†æ¡†æ¶ï¼Œå¯¹è‹¥å¹²æœ€æ–°æŠ€æœ¯å’Œæµè¡Œçš„LLMsè¿›è¡ŒåŸºå‡†æµ‹è¯•ï¼ŒåŒ…æ‹¬å¼€æ”¾å’Œå°é—­æƒé‡æ¨¡å‹ã€‚æˆ‘ä»¬çš„ç»“æœè¡¨æ˜ï¼ŒClaude-3.7-sonnetè¡¨ç°æœ€ä½³ï¼ŒDefenderBenchå¾—åˆ†ä¸º81.65ï¼Œå…¶æ¬¡æ˜¯Claude-3.7-sonnet-thinkï¼Œå¾—åˆ†ä¸º78.40ï¼Œè€Œæœ€å¥½çš„å¼€æ”¾æƒé‡æ¨¡å‹Llama 3.3 70Bç´§éšå…¶åï¼ŒDefenderBenchå¾—åˆ†ä¸º71.81ã€‚DefenderBenchçš„æ¨¡å—åŒ–è®¾è®¡å…è®¸æ— ç¼é›†æˆè‡ªå®šä¹‰LLMså’Œä»»åŠ¡ï¼Œä¿ƒè¿›ç»“æœå¯é‡å¤æ€§å’Œå…¬å¹³æ¯”è¾ƒã€‚DefenderBenchçš„åŒ¿åç‰ˆæœ¬å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/microsoft/DefenderBench%E4%B8%8A%E8%8E%B7%E5%BE%97%E3%80%82">https://github.com/microsoft/DefenderBenchä¸Šè·å¾—ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.00739v3">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨ç†è§£å’Œæ¨ç†äººç±»è¯­è¨€æ–¹é¢è¡¨ç°å‡ºå¼ºå¤§çš„èƒ½åŠ›ï¼Œä½†åœ¨ç½‘ç»œå®‰å…¨é¢†åŸŸçš„åº”ç”¨æ½œåŠ›å°šæœªå¾—åˆ°å……åˆ†æ¢ç´¢ã€‚æœ¬æ–‡ä»‹ç»äº†DefenderBenchï¼Œè¿™æ˜¯ä¸€ä¸ªç”¨äºè¯„ä¼°è¯­è¨€æ¨¡å‹åœ¨æ”»å‡»ã€é˜²å¾¡å’Œç½‘ç»œå®‰å…¨çŸ¥è¯†ä»»åŠ¡ä¸Šçš„å®ç”¨å¼€æºå·¥å…·åŒ…ã€‚DefenderBenchåŒ…å«ç½‘ç»œå…¥ä¾µã€æ¶æ„å†…å®¹æ£€æµ‹ã€ä»£ç æ¼æ´åˆ†æå’Œç½‘ç»œå®‰å…¨çŸ¥è¯†è¯„ä¼°çš„ç¯å¢ƒã€‚å…¶æ—¨åœ¨æˆä¸ºé¢å‘ç ”ç©¶äººå‘˜çš„è´Ÿæ‹…å¾—èµ·çš„æ˜“äºè®¿é—®çš„å·¥å…·ï¼Œæä¾›å…¬å¹³ä¸¥è°¨çš„è¯„ä»·æ–¹æ³•ã€‚æ–‡ç« é€šè¿‡æ ‡å‡†åŒ–çš„æ¡†æ¶è¯„ä¼°äº†ä¸€äº›å…ˆè¿›çš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼Œå‘ç°Claude-3.7-sonnetè¡¨ç°æœ€ä½³ï¼Œå¾—åˆ†81.65ï¼Œå…¶æ¬¡æ˜¯Claude-3.7-sonnet-thinkå¾—åˆ†78.40ï¼Œè€Œè¡¨ç°æœ€å¥½çš„å¼€æºæ¨¡å‹Llama 3.3 70Bå¾—åˆ†ç´§éšå…¶åä¸º71.81ã€‚DefenderBenchçš„æ¨¡å—åŒ–è®¾è®¡å…è®¸æ— ç¼é›†æˆè‡ªå®šä¹‰çš„å¤§å‹è¯­è¨€æ¨¡å‹å’Œä»»åŠ¡ï¼Œä¿ƒè¿›äº†ç ”ç©¶çš„å¯é‡å¤æ€§å’Œå…¬å¹³æ¯”è¾ƒã€‚åŒ¿åç‰ˆæœ¬çš„DefenderBenchå¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/microsoft/DefenderBench%E8%8E%B7%E5%BE%97%E3%80%82">https://github.com/microsoft/DefenderBenchè·å–ã€‚</a></p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨ç½‘ç»œå®‰å…¨é¢†åŸŸçš„åº”ç”¨æ½œåŠ›å°šæœªå……åˆ†æ¢ç´¢ã€‚</li>
<li>DefenderBenchæ˜¯ä¸€ä¸ªç”¨äºè¯„ä¼°è¯­è¨€æ¨¡å‹åœ¨ç½‘ç»œå®‰å…¨é¢†åŸŸçš„å®ç”¨å¼€æºå·¥å…·åŒ…ã€‚</li>
<li>DefenderBenchåŒ…å«ç½‘ç»œå…¥ä¾µã€æ¶æ„å†…å®¹æ£€æµ‹ã€ä»£ç æ¼æ´åˆ†æå’Œç½‘ç»œå®‰å…¨çŸ¥è¯†è¯„ä¼°çš„ç¯å¢ƒã€‚</li>
<li>DefenderBenchæ—¨åœ¨æˆä¸ºé¢å‘ç ”ç©¶äººå‘˜çš„è´Ÿæ‹…å¾—èµ·çš„æ˜“äºè®¿é—®çš„å·¥å…·ï¼Œæä¾›å…¬å¹³ä¸¥è°¨çš„è¯„ä»·æ–¹æ³•ã€‚</li>
<li>Claude-3.7-sonnetåœ¨DefenderBenchçš„è¯„ä¼°ä¸­è¡¨ç°æœ€ä½³ï¼Œå¾—åˆ†81.65ã€‚</li>
<li>DefenderBenchå…è®¸æ— ç¼é›†æˆè‡ªå®šä¹‰çš„å¤§å‹è¯­è¨€æ¨¡å‹å’Œä»»åŠ¡ï¼Œä¿ƒè¿›ç ”ç©¶çš„å¯é‡å¤æ€§å’Œå…¬å¹³æ¯”è¾ƒã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.00739">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-0a67556e6a11465719036bb51ab278f6.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-1bab7f4d11665b5e3feed5f17ce028c0.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-4ce477798b819c94cd5e4fe2f624ddee.jpg" align="middle">
</details>


<h1 id="-13"><a href="#-13" class="headerlink" title=""></a></h1><h2 id="CO-Bench-Benchmarking-Language-Model-Agents-in-Algorithm-Search-for-Combinatorial-Optimization"><a href="#CO-Bench-Benchmarking-Language-Model-Agents-in-Algorithm-Search-for-Combinatorial-Optimization" class="headerlink" title="CO-Bench: Benchmarking Language Model Agents in Algorithm Search for   Combinatorial Optimization"></a>CO-Bench: Benchmarking Language Model Agents in Algorithm Search for   Combinatorial Optimization</h2><p><strong>Authors:Weiwei Sun, Shengyu Feng, Shanda Li, Yiming Yang</strong></p>
<p>Although LLM-based agents have attracted significant attention in domains such as software engineering and machine learning research, their role in advancing combinatorial optimization (CO) remains relatively underexplored. This gap underscores the need for a deeper understanding of their potential in tackling structured, constraint-intensive problems â€“ a pursuit currently limited by the absence of comprehensive benchmarks for systematic investigation. To address this, we introduce CO-Bench, a benchmark suite featuring 36 real-world CO problems drawn from a broad range of domains and complexity levels. CO-Bench includes structured problem formulations and curated data to support rigorous investigation of LLM agents. We evaluate multiple agentic frameworks against established human-designed algorithms, revealing the strengths and limitations of existing LLM agents and identifying promising directions for future research. CO-Bench is publicly available at <a target="_blank" rel="noopener" href="https://github.com/sunnweiwei/CO-Bench">https://github.com/sunnweiwei/CO-Bench</a>. </p>
<blockquote>
<p>å°½ç®¡åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„ä»£ç†åœ¨è½¯ä»¶å·¥ç¨‹å’Œæœºå™¨å­¦ä¹ ç ”ç©¶ç­‰é¢†åŸŸå¼•èµ·äº†å¹¿æ³›å…³æ³¨ï¼Œä½†å®ƒä»¬åœ¨æ¨è¿›ç»„åˆä¼˜åŒ–ï¼ˆCOï¼‰æ–¹é¢çš„ä½œç”¨ä»ç„¶ç›¸å¯¹æœªè¢«å……åˆ†æ¢ç´¢ã€‚è¿™ä¸€å·®è·å‡¸æ˜¾äº†æ·±å…¥ç†è§£å®ƒä»¬è§£å†³ç»“æ„åŒ–ã€çº¦æŸå¯†é›†å‹é—®é¢˜çš„æ½œåŠ›çš„é‡è¦æ€§ï¼Œç„¶è€Œç›®å‰è¿™ä¸€è¿½æ±‚å—é™äºç¼ºä¹å…¨é¢çš„åŸºå‡†æµ‹è¯•æ¥è¿›è¡Œç³»ç»Ÿç ”ç©¶ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬å¼•å…¥äº†CO-Benchï¼Œè¿™æ˜¯ä¸€ä¸ªåŒ…å«36ä¸ªæ¥è‡ªå¹¿æ³›é¢†åŸŸå’Œå¤æ‚åº¦çº§åˆ«çš„å®é™…COé—®é¢˜çš„åŸºå‡†æµ‹è¯•å¥—ä»¶ã€‚CO-BenchåŒ…æ‹¬ç»“æ„åŒ–çš„é—®é¢˜è¡¨è¿°å’Œç»è¿‡ç­›é€‰çš„æ•°æ®ï¼Œä»¥æ”¯æŒå¯¹LLMä»£ç†çš„ä¸¥æ ¼è°ƒæŸ¥ã€‚æˆ‘ä»¬è¯„ä¼°äº†å¤šä¸ªä»£ç†æ¡†æ¶ä¸å·²å»ºç«‹çš„äººå·¥è®¾è®¡ç®—æ³•ï¼Œæ­ç¤ºäº†ç°æœ‰LLMä»£ç†çš„ä¼˜åŠ¿å’Œå±€é™æ€§ï¼Œå¹¶ç¡®å®šäº†æœªæ¥ç ”ç©¶çš„æœ‰å‰é€”çš„æ–¹å‘ã€‚CO-Benchå¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/sunnweiwei/CO-Bench%E5%85%AC%E5%BC%80%E8%AE%BF%E9%97%AE%E3%80%82">https://github.com/sunnweiwei/CO-Benchå…¬å¼€è®¿é—®ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.04310v2">PDF</a> </p>
<p><strong>Summary</strong><br>LLMåœ¨è½¯ä»¶å·¥ç¨‹å’Œæœºå™¨å­¦ä¹ ç­‰é¢†åŸŸå¤‡å—å…³æ³¨ï¼Œä½†åœ¨ç»„åˆä¼˜åŒ–é¢†åŸŸçš„åº”ç”¨ç›¸å¯¹ç¼ºä¹ç ”ç©¶ã€‚ä¸ºæ­¤ï¼Œæœ¬æ–‡æå‡ºCO-Benchï¼ŒåŒ…å«ä»å„ç§é¢†åŸŸå’Œå¤æ‚åº¦çº§åˆ«ä¸­æŠ½å–çš„36ä¸ªçœŸå®ä¸–ç•Œç»„åˆä¼˜åŒ–é—®é¢˜ï¼Œä»¥æ”¯æŒå¯¹LLMçš„å…¨é¢ç³»ç»Ÿç ”ç©¶ã€‚æ–‡ç« é€šè¿‡è¯„ä¼°å¤šä¸ªä»£ç†æ¡†æ¶ä¸å·²çŸ¥äººç±»è®¾è®¡ç®—æ³•ï¼Œæ­ç¤ºäº†ç°æœ‰LLMä»£ç†çš„ä¼˜åŠ¿å’Œå±€é™æ€§ï¼Œå¹¶æŒ‡å‡ºäº†æœªæ¥ç ”ç©¶çš„æœ‰å‰é€”çš„æ–¹å‘ã€‚CO-Benchå·²åœ¨GitHubä¸Šå…¬å¼€å¯ç”¨ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>LLMåœ¨ç»„åˆä¼˜åŒ–é¢†åŸŸçš„åº”ç”¨å—åˆ°å…³æ³¨ä½†ç›¸å¯¹ç¼ºä¹ç ”ç©¶ã€‚</li>
<li>CO-Benchæ˜¯ä¸€ä¸ªæ–°çš„åŸºå‡†æµ‹è¯•å¥—ä»¶ï¼ŒåŒ…å«çœŸå®ä¸–ç•Œçš„ç»„åˆä¼˜åŒ–é—®é¢˜ï¼Œæ—¨åœ¨æ”¯æŒå¯¹LLMçš„å…¨é¢ç³»ç»Ÿç ”ç©¶ã€‚</li>
<li>CO-BenchåŒ…å«ä»å„ç§é¢†åŸŸå’Œå¤æ‚åº¦çº§åˆ«ä¸­æŠ½å–çš„é—®é¢˜ã€‚</li>
<li>æ–‡ç« è¯„ä¼°äº†å¤šä¸ªä»£ç†æ¡†æ¶å’Œäººç±»è®¾è®¡ç®—æ³•ï¼Œæ­ç¤ºäº†LLMä»£ç†çš„ä¼˜ç¼ºç‚¹ã€‚</li>
<li>CO-Benchä¸ºæœªæ¥çš„ç ”ç©¶æŒ‡å‡ºäº†æœ‰å‰é€”çš„æ–¹å‘ã€‚</li>
<li>CO-Benchå·²åœ¨GitHubä¸Šå…¬å¼€å¯ç”¨ï¼Œä¾¿äºç ”ç©¶äººå‘˜ä½¿ç”¨ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.04310">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-ecdf4ff80a18f417ab3d81a4bd29bea1.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-e3e9dbbf6346259ecd59657681d74f48.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-4ea9651dd027f05dd2d7eaf013ba2538.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-84bd85b3a4fa71e30770edb169a9c624.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-109ab5cdd59876c3dcc03a8f7b1f46ee.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-3f97bf9cec1ac1890b290cb95f182e5f.jpg" align="middle">
</details>


<h1 id="-14"><a href="#-14" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-08-15/Agent/">https://kedreamix.github.io/Talk2Paper/Paper/2025-08-15/Agent/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/Agent/">
                                    <span class="chip bg-color">Agent</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-08-15/I2I%20Translation/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-3b468e9cc9767f15282c89dc41195453.jpg" class="responsive-img" alt="I2I Translation">
                        
                        <span class="card-title">I2I Translation</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            I2I Translation æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-08-15  Translation of Text Embedding via Delta Vector to Suppress Strongly   Entangled Content in Text-to-Image Diffusion Models
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-08-15
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/I2I-Translation/" class="post-category">
                                    I2I Translation
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/I2I-Translation/">
                        <span class="chip bg-color">I2I Translation</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-08-15/LLM/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-0604d1794ea3edc8354f76c872b60e7e.jpg" class="responsive-img" alt="LLM">
                        
                        <span class="card-title">LLM</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            LLM æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-08-15  Noise Hypernetworks Amortizing Test-Time Compute in Diffusion Models
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-08-15
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/LLM/" class="post-category">
                                    LLM
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/LLM/">
                        <span class="chip bg-color">LLM</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">26633.8k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
