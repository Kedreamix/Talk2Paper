<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Agent">
    <meta name="description" content="Agent æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-10-25  Co-Designing Quantum Codes with Transversal Diagonal Gates via   Multi-Agent Systems">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>Agent | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://picx.zhimg.com/v2-fa71f2937fc7f81fe63ca8dfe9263990')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Agent</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/Agent/">
                                <span class="chip bg-color">Agent</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/Agent/" class="post-category">
                                Agent
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-10-25
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-11-19
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    17.9k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    72 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-10-25-æ›´æ–°"><a href="#2025-10-25-æ›´æ–°" class="headerlink" title="2025-10-25 æ›´æ–°"></a>2025-10-25 æ›´æ–°</h1><h2 id="Co-Designing-Quantum-Codes-with-Transversal-Diagonal-Gates-via-Multi-Agent-Systems"><a href="#Co-Designing-Quantum-Codes-with-Transversal-Diagonal-Gates-via-Multi-Agent-Systems" class="headerlink" title="Co-Designing Quantum Codes with Transversal Diagonal Gates via   Multi-Agent Systems"></a>Co-Designing Quantum Codes with Transversal Diagonal Gates via   Multi-Agent Systems</h2><p><strong>Authors:Xi He, Sirui Lu, Bei Zeng</strong></p>
<p>We present a multi-agent, human-in-the-loop workflow that co-designs quantum codes with prescribed transversal diagonal gates. It builds on the Subset-Sum Linear Programming (SSLP) framework (arXiv:2504.20847), which partitions basis strings by modular residues and enforces $Z$-marginal Knill-Laflamme (KL) equalities via small LPs. The workflow is powered by GPT-5 and implemented within TeXRA (<a target="_blank" rel="noopener" href="https://texra.ai)-a/">https://texra.ai)-a</a> multi-agent research assistant platform that supports an iterative tool-use loop agent and a derivation-then-edit workflow reasoning agent. We work in a LaTeX-Python environment where agents reason, edit documents, execute code, and synchronize their work to Git&#x2F;Overleaf. Within this workspace, three roles collaborate: a Synthesis Agent formulates the problem; a Search Agent sweeps&#x2F;screens candidates and exactifies numerics into rationals; and an Audit Agent independently checks all KL equalities and the induced logical action. As a first step we focus on distance $d&#x3D;2$ with nondegenerate residues. For code dimension $K\in{2,3,4}$ and $n\le6$ qubits, systematic sweeps yield certificate-backed tables cataloging attainable cyclic logical groups-all realized by new codes-e.g., for $K&#x3D;3$ we obtain order $16$ at $n&#x3D;6$. From verified instances, Synthesis Agent abstracts recurring structures into closed-form families and proves they satisfy the KL equalities for all parameters. It further demonstrates that SSLP accommodates residue degeneracy by exhibiting a new $((6,4,2))$ code implementing the transversal controlled-phase $diag(1,1,1,i)$. Overall, the workflow recasts diagonal-transversal feasibility as an analytical pipeline executed at scale, combining systematic enumeration with exact analytical reconstruction. It yields reproducible code constructions, supports targeted extensions to larger $K$ and higher distances, and leads toward data-driven classification. </p>
<blockquote>
<p>æˆ‘ä»¬æå‡ºäº†ä¸€ç§å¤šæ™ºèƒ½ä½“ã€äººæœºå¾ªç¯çš„å·¥ä½œæµç¨‹ï¼Œè¯¥æµç¨‹ä¸è§„å®šçš„æ¨ªå‘å¯¹è§’é—¨å…±åŒè®¾è®¡é‡å­ä»£ç ã€‚å®ƒåŸºäºå­é›†å’Œçº¿æ€§è§„åˆ’ï¼ˆSSLPï¼‰æ¡†æ¶ï¼ˆarXiv:2504.20847ï¼‰ï¼Œè¯¥æ¡†æ¶é€šè¿‡æ¨¡ä½™æ•°åˆ’åˆ†åŸºå­—ç¬¦ä¸²ï¼Œå¹¶é€šè¿‡å°å‹çº¿æ€§è§„åˆ’å¼ºåˆ¶æ‰§è¡ŒZè¾¹ç•Œçš„Knill-Laflammeï¼ˆKLï¼‰ç­‰å¼ã€‚è¯¥å·¥ä½œæµç¨‹ç”±GPT-5é©±åŠ¨ï¼Œå¹¶åœ¨TeXRAï¼ˆ<a target="_blank" rel="noopener" href="https://texra.ai)ä¸­å®ç°,è¿™æ˜¯ä¸€ä¸ªå¤šæ™ºèƒ½ä½“ç ”ç©¶åŠ©ç†å¹³å°,æ”¯æŒè¿­ä»£å·¥å…·ä½¿ç”¨å¾ªç¯æ™ºèƒ½ä½“å’Œæ¨å¯¼ç„¶åç¼–è¾‘çš„å·¥ä½œæµæ¨ç†æ™ºèƒ½ä½“.æˆ‘ä»¬åœ¨latex-pythonç¯å¢ƒä¸­å·¥ä½œ,å…¶ä¸­çš„æ™ºèƒ½ä½“è¿›è¡Œæ¨ç†ã€ç¼–è¾‘æ–‡æ¡£ã€æ‰§è¡Œä»£ç ,å¹¶å°†ä»–ä»¬çš„å·¥ä½œåŒæ­¥åˆ°git/Overleaf%E3%80%82%E5%9C%A8%E8%BF%99%E4%B8%AA%E5%B7%A5%E4%BD%9C%E7%A9%BA%E9%97%B4%E4%B8%AD%EF%BC%8C%E4%B8%89%E4%B8%AA%E8%A7%92%E8%89%B2%E8%BF%9B%E8%A1%8C%E5%90%88%E4%BD%9C%EF%BC%9A%E5%90%88%E6%88%90%E6%99%BA%E8%83%BD%E4%BD%93%E6%8F%90%E5%87%BA%E9%97%AE%E9%A2%98%EF%BC%9B%E6%90%9C%E7%B4%A2%E6%99%BA%E8%83%BD%E4%BD%93%E6%89%AB%E6%8F%8F/%E7%AD%9B%E9%80%89%E5%80%99%E9%80%89%E4%BA%BA%EF%BC%8C%E5%B9%B6%E5%B0%86%E6%95%B0%E5%80%BC%E7%B2%BE%E7%A1%AE%E5%8C%96%E4%B8%BA%E6%9C%89%E7%90%86%E6%95%B0%EF%BC%9B%E5%AE%A1%E8%AE%A1%E6%99%BA%E8%83%BD%E4%BD%93%E7%8B%AC%E7%AB%8B%E6%A3%80%E6%9F%A5%E6%89%80%E6%9C%89KL%E7%AD%89%E5%BC%8F%E5%92%8C%E8%AF%B1%E5%AF%BC%E7%9A%84%E9%80%BB%E8%BE%91%E8%A1%8C%E5%8A%A8%E3%80%82%E4%BD%9C%E4%B8%BA%E7%AC%AC%E4%B8%80%E6%AD%A5%EF%BC%8C%E6%88%91%E4%BB%AC%E4%B8%93%E6%B3%A8%E4%BA%8E%E8%B7%9D%E7%A6%BBd=2%E7%9A%84%E9%9D%9E%E9%80%80%E5%8C%96%E6%AE%8B%E7%95%99%E7%89%A9%E3%80%82%E5%AF%B9%E4%BA%8E%E4%BB%A3%E7%A0%81%E7%BB%B4%E5%BA%A6K%E2%88%88%7B2,3,4%7D%E5%92%8Cn%E2%89%A46%E4%B8%AA%E9%87%8F%E5%AD%90%E4%BD%8D%EF%BC%8C%E7%B3%BB%E7%BB%9F%E6%89%AB%E6%8F%8F%E7%94%9F%E6%88%90%E4%BA%86%E6%9C%89%E8%AF%81%E4%B9%A6%E6%94%AF%E6%8C%81%E7%9A%84%E8%A1%A8%E6%A0%BC%EF%BC%8C%E5%88%97%E5%87%BA%E4%BA%86%E5%8F%AF%E5%AE%9E%E7%8E%B0%E7%9A%84%E5%BE%AA%E7%8E%AF%E9%80%BB%E8%BE%91%E7%BB%84%E2%80%94%E2%80%94%E8%BF%99%E4%BA%9B%E9%83%BD%E6%98%AF%E9%80%9A%E8%BF%87%E6%96%B0%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0%E7%9A%84%EF%BC%8C%E4%BE%8B%E5%A6%82%E5%AF%B9%E4%BA%8EK=3%EF%BC%8C%E6%88%91%E4%BB%AC%E5%9C%A8n=6%E6%97%B6%E8%8E%B7%E5%BE%97%E4%BA%8616%E9%98%B6%E3%80%82%E4%BB%8E%E9%AA%8C%E8%AF%81%E7%9A%84%E5%AE%9E%E4%BE%8B%E4%B8%AD%EF%BC%8C%E5%90%88%E6%88%90%E6%99%BA%E8%83%BD%E4%BD%93%E5%B0%86%E9%87%8D%E5%A4%8D%E7%9A%84%E7%BB%93%E6%9E%84%E6%8A%BD%E8%B1%A1%E4%B8%BA%E5%B0%81%E9%97%AD%E5%BD%A2%E5%BC%8F%E7%9A%84%E5%AE%B6%E6%97%8F%EF%BC%8C%E5%B9%B6%E8%AF%81%E6%98%8E%E5%AE%83%E4%BB%AC%E6%BB%A1%E8%B6%B3%E6%89%80%E6%9C%89%E5%8F%82%E6%95%B0%E7%9A%84KL%E7%AD%89%E5%BC%8F%E3%80%82%E5%AE%83%E8%BF%9B%E4%B8%80%E6%AD%A5%E8%AF%81%E6%98%8ESSLP%E5%8F%AF%E4%BB%A5%E9%80%9A%E8%BF%87%E5%B1%95%E7%A4%BA%E5%AE%9E%E7%8E%B0%E6%A8%AA%E5%90%91%E6%8E%A7%E5%88%B6%E7%9B%B8%E4%BD%8D%E7%9A%84%E6%96%B0%EF%BC%88%EF%BC%886,4,2%EF%BC%89%EF%BC%89%E4%BB%A3%E7%A0%81$diag(1,1,1,i)$%E6%9D%A5%E5%AE%B9%E7%BA%B3%E6%AE%8B%E7%95%99%E9%80%80%E5%8C%96%E3%80%82%E6%80%BB%E7%9A%84%E6%9D%A5%E8%AF%B4%EF%BC%8C%E8%AF%A5%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%A8%8B%E5%B0%86%E5%AF%B9%E8%A7%92%E6%A8%AA%E5%90%91%E5%8F%AF%E8%A1%8C%E6%80%A7%E9%87%8D%E6%96%B0%E6%9E%84%E5%BB%BA%E4%B8%BA%E6%89%A7%E8%A1%8C%E5%A4%A7%E8%A7%84%E6%A8%A1%E7%9A%84%E5%88%86%E6%9E%90%E7%AE%A1%E9%81%93%EF%BC%8C%E7%BB%93%E5%90%88%E7%B3%BB%E7%BB%9F%E6%9E%9A%E4%B8%BE%E5%92%8C%E7%B2%BE%E7%A1%AE%E7%9A%84%E5%88%86%E6%9E%90%E9%87%8D%E5%BB%BA%E3%80%82%E5%AE%83%E4%BA%A7%E7%94%9F%E4%BA%86%E5%8F%AF%E9%87%8D%E5%A4%8D%E7%9A%84%E4%BB%A3%E7%A0%81%E7%BB%93%E6%9E%84%EF%BC%8C%E6%94%AF%E6%8C%81%E9%92%88%E5%AF%B9%E6%9B%B4%E5%A4%A7%E7%9A%84K%E5%92%8C%E6%9B%B4%E9%AB%98%E7%9A%84%E8%B7%9D%E7%A6%BB%E8%BF%9B%E8%A1%8C%E6%9C%89%E9%92%88%E5%AF%B9%E6%80%A7%E7%9A%84%E6%89%A9%E5%B1%95%EF%BC%8C%E5%B9%B6%E6%9C%9D%E7%9D%80%E6%95%B0%E6%8D%AE%E9%A9%B1%E5%8A%A8%E7%9A%84%E5%88%86%E7%B1%BB%E6%96%B9%E5%90%91%E5%8F%91%E5%B1%95%E3%80%82">https://texra.aiï¼‰ä¸­å®ç°ï¼Œè¿™æ˜¯ä¸€ä¸ªå¤šæ™ºèƒ½ä½“ç ”ç©¶åŠ©ç†å¹³å°ï¼Œæ”¯æŒè¿­ä»£å·¥å…·ä½¿ç”¨å¾ªç¯æ™ºèƒ½ä½“å’Œæ¨å¯¼ç„¶åç¼–è¾‘çš„å·¥ä½œæµæ¨ç†æ™ºèƒ½ä½“ã€‚æˆ‘ä»¬åœ¨LaTeX-Pythonç¯å¢ƒä¸­å·¥ä½œï¼Œå…¶ä¸­çš„æ™ºèƒ½ä½“è¿›è¡Œæ¨ç†ã€ç¼–è¾‘æ–‡æ¡£ã€æ‰§è¡Œä»£ç ï¼Œå¹¶å°†ä»–ä»¬çš„å·¥ä½œåŒæ­¥åˆ°Git/Overleafã€‚åœ¨è¿™ä¸ªå·¥ä½œç©ºé—´ä¸­ï¼Œä¸‰ä¸ªè§’è‰²è¿›è¡Œåˆä½œï¼šåˆæˆæ™ºèƒ½ä½“æå‡ºé—®é¢˜ï¼›æœç´¢æ™ºèƒ½ä½“æ‰«æ/ç­›é€‰å€™é€‰äººï¼Œå¹¶å°†æ•°å€¼ç²¾ç¡®åŒ–ä¸ºæœ‰ç†æ•°ï¼›å®¡è®¡æ™ºèƒ½ä½“ç‹¬ç«‹æ£€æŸ¥æ‰€æœ‰KLç­‰å¼å’Œè¯±å¯¼çš„é€»è¾‘è¡ŒåŠ¨ã€‚ä½œä¸ºç¬¬ä¸€æ­¥ï¼Œæˆ‘ä»¬ä¸“æ³¨äºè·ç¦»d=2çš„éé€€åŒ–æ®‹ç•™ç‰©ã€‚å¯¹äºä»£ç ç»´åº¦Kâˆˆ{2,3,4}å’Œnâ‰¤6ä¸ªé‡å­ä½ï¼Œç³»ç»Ÿæ‰«æç”Ÿæˆäº†æœ‰è¯ä¹¦æ”¯æŒçš„è¡¨æ ¼ï¼Œåˆ—å‡ºäº†å¯å®ç°çš„å¾ªç¯é€»è¾‘ç»„â€”â€”è¿™äº›éƒ½æ˜¯é€šè¿‡æ–°ä»£ç å®ç°çš„ï¼Œä¾‹å¦‚å¯¹äºK=3ï¼Œæˆ‘ä»¬åœ¨n=6æ—¶è·å¾—äº†16é˜¶ã€‚ä»éªŒè¯çš„å®ä¾‹ä¸­ï¼Œåˆæˆæ™ºèƒ½ä½“å°†é‡å¤çš„ç»“æ„æŠ½è±¡ä¸ºå°é—­å½¢å¼çš„å®¶æ—ï¼Œå¹¶è¯æ˜å®ƒä»¬æ»¡è¶³æ‰€æœ‰å‚æ•°çš„KLç­‰å¼ã€‚å®ƒè¿›ä¸€æ­¥è¯æ˜SSLPå¯ä»¥é€šè¿‡å±•ç¤ºå®ç°æ¨ªå‘æ§åˆ¶ç›¸ä½çš„æ–°ï¼ˆï¼ˆ6,4,2ï¼‰ï¼‰ä»£ç $diag(1,1,1,i)$æ¥å®¹çº³æ®‹ç•™é€€åŒ–ã€‚æ€»çš„æ¥è¯´ï¼Œè¯¥å·¥ä½œæµç¨‹å°†å¯¹è§’æ¨ªå‘å¯è¡Œæ€§é‡æ–°æ„å»ºä¸ºæ‰§è¡Œå¤§è§„æ¨¡çš„åˆ†æç®¡é“ï¼Œç»“åˆç³»ç»Ÿæšä¸¾å’Œç²¾ç¡®çš„åˆ†æé‡å»ºã€‚å®ƒäº§ç”Ÿäº†å¯é‡å¤çš„ä»£ç ç»“æ„ï¼Œæ”¯æŒé’ˆå¯¹æ›´å¤§çš„Kå’Œæ›´é«˜çš„è·ç¦»è¿›è¡Œæœ‰é’ˆå¯¹æ€§çš„æ‰©å±•ï¼Œå¹¶æœç€æ•°æ®é©±åŠ¨çš„åˆ†ç±»æ–¹å‘å‘å±•ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.20728v1">PDF</a> 29 pages, 2 figures</p>
<p><strong>Summary</strong></p>
<p>è¯¥æ–‡æœ¬ä»‹ç»äº†ä¸€ç§å¤šæ™ºèƒ½ä½“å‚ä¸ã€æœ‰äººç±»ç”¨æˆ·å‚ä¸çš„å·¥ä½œæµç¨‹ï¼Œè¯¥æµç¨‹åˆ©ç”¨å­é›†å’Œçº¿æ€§è§„åˆ’æ¡†æ¶ï¼ˆSSLPï¼‰ååŒè®¾è®¡é‡å­ä»£ç ï¼Œå®ç°è§„å®šçš„æ¨ªå‘å¯¹è§’é—¨æ“ä½œã€‚é€šè¿‡ä½¿ç”¨GPT-5å’ŒTeXRAå¹³å°ï¼Œè¯¥æµç¨‹åœ¨LaTeX-Pythonç¯å¢ƒä¸­å®ç°äº†æ™ºèƒ½ä½“çš„åä½œå·¥ä½œï¼ŒåŒ…æ‹¬é—®é¢˜åˆæˆã€å€™é€‰æœç´¢ç­›é€‰ã€æ•°å€¼ç²¾ç¡®åŒ–ä»¥åŠé€»è¾‘åŠ¨ä½œéªŒè¯ç­‰æ­¥éª¤ã€‚é’ˆå¯¹è·ç¦»d&#x3D;2å’Œéé€€åŒ–æ®‹ç•™ç‰©çš„æƒ…å†µï¼Œç³»ç»Ÿæ‰«æå¾—åˆ°äº†è¯ä¹¦æ”¯æŒçš„è¡¨æ ¼ï¼Œåˆ—å‡ºäº†å¯å®ç°çš„å¾ªç¯é€»è¾‘ç»„ã€‚æ­¤å¤–ï¼Œè¯¥æµç¨‹è¿˜å±•ç¤ºäº†SSLPå¦‚ä½•å¤„ç†æ®‹ç•™ç‰©çš„é€€åŒ–é—®é¢˜ï¼Œå¹¶å±•ç¤ºäº†ä¸€ç§æ–°çš„ï¼ˆ6,4,2ï¼‰ä»£ç å®ç°æ¨ªå‘æ§åˆ¶ç›¸ä½é—¨æ“ä½œçš„å®ä¾‹ã€‚æ€»ä½“è€Œè¨€ï¼Œè¯¥å·¥ä½œæµç¨‹å°†æ¨ªå‘å¯¹è§’å¯è¡Œæ€§è½¬åŒ–ä¸ºå¤§è§„æ¨¡åˆ†æç®¡é“ï¼Œç»“åˆç³»ç»Ÿæšä¸¾å’Œç²¾ç¡®åˆ†æé‡å»ºï¼Œç”Ÿæˆå¯é‡å¤ä½¿ç”¨çš„ä»£ç ç»“æ„ï¼Œå¹¶æ”¯æŒæœ‰é’ˆå¯¹æ€§çš„æ‰©å±•åˆ°æ›´å¤§çš„Kå’Œæ›´é«˜çš„è·ç¦»ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æå‡ºäº†ä¸€ç§å¤šæ™ºèƒ½ä½“å‚ä¸ã€æœ‰äººç±»ç”¨æˆ·å‚ä¸çš„å·¥ä½œæµç¨‹è®¾è®¡é‡å­ä»£ç çš„æ–°æ–¹æ³•ã€‚</li>
<li>ä½¿ç”¨GPT-5å’ŒTeXRAå¹³å°çš„å¤šæ™ºèƒ½ä½“ç ”ç©¶åŠ©ç†æ”¯æŒå¤šç§è§’è‰²æ™ºèƒ½ä½“è¿›è¡ŒååŒå·¥ä½œã€‚</li>
<li>è¯¥å·¥ä½œæµç¨‹ä¾èµ–äºå­é›†å’Œçº¿æ€§è§„åˆ’æ¡†æ¶è¿›è¡Œé‡å­ä»£ç çš„ååŒè®¾è®¡ï¼Œå¹¶åˆ©ç”¨SSLPå®ç°è§„å®šçš„æ¨ªå‘å¯¹è§’é—¨æ“ä½œã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.20728">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-45455f3f6fb2dfc11867861751caf192" align="middle">
<img src="https://picx.zhimg.com/v2-3501601ff3c9c2c7aee8e2a12ebded77" align="middle">
<img src="https://picx.zhimg.com/v2-21203513e2a2a97e9add4df4fbcd4ee5" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="Beyond-Retrieval-Ranking-A-Multi-Agent-Cognitive-Decision-Framework-for-E-Commerce-Search"><a href="#Beyond-Retrieval-Ranking-A-Multi-Agent-Cognitive-Decision-Framework-for-E-Commerce-Search" class="headerlink" title="Beyond Retrieval-Ranking: A Multi-Agent Cognitive Decision Framework for   E-Commerce Search"></a>Beyond Retrieval-Ranking: A Multi-Agent Cognitive Decision Framework for   E-Commerce Search</h2><p><strong>Authors:Zhouwei Zhai, Mengxiang Chen, Haoyun Xia, Jin Li, Renquan Zhou, Min Yang</strong></p>
<p>The retrieval-ranking paradigm has long dominated e-commerce search, but its reliance on query-item matching fundamentally misaligns with multi-stage cognitive decision processes of platform users. This misalignment introduces critical limitations: semantic gaps in complex queries, high decision costs due to cross-platform information foraging, and the absence of professional shopping guidance. To address these issues, we propose a Multi-Agent Cognitive Decision Framework (MACDF), which shifts the paradigm from passive retrieval to proactive decision support. Extensive offline evaluations demonstrate MACDFâ€™s significant improvements in recommendation accuracy and user satisfaction, particularly for complex queries involving negation, multi-constraint, or reasoning demands. Online A&#x2F;B testing on JD search platform confirms its practical efficacy. This work highlights the transformative potential of multi-agent cognitive systems in redefining e-commerce search. </p>
<blockquote>
<p>æ£€ç´¢æ’åèŒƒå¼é•¿æœŸä»¥æ¥ä¸€ç›´ä¸»å¯¼ç€ç”µå­å•†åŠ¡æœç´¢ï¼Œä½†å…¶å¯¹æŸ¥è¯¢é¡¹ç›®çš„ä¾èµ–ä»æ ¹æœ¬ä¸Šä¸å¹³å°ç”¨æˆ·çš„å¤šé˜¶æ®µè®¤çŸ¥å†³ç­–è¿‡ç¨‹ä¸ç›¸ç¬¦ã€‚è¿™ç§ä¸åŒ¹é…å¸¦æ¥äº†å…³é”®çš„å±€é™æ€§ï¼šå¤æ‚æŸ¥è¯¢ä¸­çš„è¯­ä¹‰é¸¿æ²Ÿã€è·¨å¹³å°ä¿¡æ¯è§…é£Ÿå¯¼è‡´çš„é«˜å†³ç­–æˆæœ¬ä»¥åŠç¼ºä¹ä¸“ä¸šè´­ç‰©æŒ‡å¯¼ã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†å¤šæ™ºèƒ½ä½“è®¤çŸ¥å†³ç­–æ¡†æ¶ï¼ˆMACDFï¼‰ï¼Œå°†èŒƒå¼ä»è¢«åŠ¨æ£€ç´¢è½¬å˜ä¸ºç§¯æå†³ç­–æ”¯æŒã€‚å¤§é‡çš„ç¦»çº¿è¯„ä¼°è¡¨æ˜ï¼ŒMACDFåœ¨æ¨èå‡†ç¡®æ€§å’Œç”¨æˆ·æ»¡æ„åº¦æ–¹é¢æœ‰æ˜æ˜¾çš„æ”¹è¿›ï¼Œç‰¹åˆ«æ˜¯åœ¨æ¶‰åŠå¦å®šã€å¤šçº¦æŸæˆ–æ¨ç†éœ€æ±‚çš„å¤æ‚æŸ¥è¯¢ä¸­ã€‚åœ¨JDæœç´¢å¹³å°ä¸Šçš„åœ¨çº¿A&#x2F;Bæµ‹è¯•è¯å®äº†å…¶å®é™…æœ‰æ•ˆæ€§ã€‚è¿™é¡¹å·¥ä½œçªå‡ºäº†å¤šæ™ºèƒ½ä½“è®¤çŸ¥ç³»ç»Ÿåœ¨é‡æ–°å®šä¹‰ç”µå­å•†åŠ¡æœç´¢æ–¹é¢çš„æ½œåŠ›ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.20567v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>éšç€ç”µå­å•†åŠ¡æœç´¢çš„å‘å±•ï¼Œæ£€ç´¢æ’åæ¨¡å¼é•¿æœŸå æ®ä¸»å¯¼åœ°ä½ï¼Œä½†è¯¥æ¨¡å¼ä¾èµ–æŸ¥è¯¢é¡¹ç›®çš„åŒ¹é…æ–¹å¼ï¼Œä¸å¹³å°ç”¨æˆ·çš„å¤šé˜¶æ®µè®¤çŸ¥å†³ç­–è¿‡ç¨‹å­˜åœ¨æ ¹æœ¬æ€§ä¸åŒ¹é…ã€‚ä¸ºè§£å†³ç”±æ­¤å¼•å‘çš„é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†å¤šæ™ºèƒ½ä½“è®¤çŸ¥å†³ç­–æ¡†æ¶ï¼ˆMACDFï¼‰ï¼Œç”±è¢«åŠ¨æ£€ç´¢è½¬å˜ä¸ºç§¯æå†³ç­–æ”¯æŒã€‚ç»ç¦»çº¿è¯„ä¼°å’Œåœ¨çº¿A&#x2F;Bæµ‹è¯•ï¼Œè¯æ˜MACDFåœ¨æ¨èå‡†ç¡®æ€§å’Œç”¨æˆ·æ»¡æ„åº¦æ–¹é¢æœ‰æ˜æ˜¾æå‡ï¼Œç‰¹åˆ«æ˜¯åœ¨æ¶‰åŠå¦å®šã€å¤šçº¦æŸæˆ–æ¨ç†éœ€æ±‚çš„å¤æ‚æŸ¥è¯¢ä¸­è¡¨ç°ä¼˜å¼‚ã€‚æ­¤å·¥ä½œçªæ˜¾äº†å¤šæ™ºèƒ½ä½“è®¤çŸ¥ç³»ç»Ÿåœ¨é‡æ–°å®šä¹‰ç”µå­å•†åŠ¡æœç´¢ä¸­çš„å˜é©æ½œåŠ›ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æ£€ç´¢æ’åæ¨¡å¼åœ¨ç”µå­å•†åŠ¡æœç´¢ä¸­é•¿æœŸå æ®ä¸»å¯¼åœ°ä½ï¼Œä½†å­˜åœ¨ä¸ç”¨æˆ·çš„è®¤çŸ¥å†³ç­–è¿‡ç¨‹ä¸åŒ¹é…çš„æ ¹æœ¬é—®é¢˜ã€‚</li>
<li>è¿™ç§ä¸åŒ¹é…å¯¼è‡´è¯­ä¹‰å·®è·ã€é«˜å†³ç­–æˆæœ¬å’Œç¼ºä¹ä¸“ä¸šè´­ç‰©æŒ‡å¯¼ç­‰å…³é”®é™åˆ¶ã€‚</li>
<li>ä¸ºè§£å†³è¿™äº›é—®é¢˜ï¼Œæå‡ºäº†å¤šæ™ºèƒ½ä½“è®¤çŸ¥å†³ç­–æ¡†æ¶ï¼ˆMACDFï¼‰ï¼Œä»è¢«åŠ¨æ£€ç´¢è½¬å˜ä¸ºç§¯æå†³ç­–æ”¯æŒã€‚</li>
<li>MACDFé€šè¿‡ç¦»çº¿è¯„ä¼°å’Œåœ¨çº¿A&#x2F;Bæµ‹è¯•ï¼Œåœ¨æ¨èå‡†ç¡®æ€§å’Œç”¨æˆ·æ»¡æ„åº¦æ–¹é¢è¡¨ç°å‡ºæ˜¾è‘—æ”¹è¿›ã€‚</li>
<li>ç‰¹åˆ«åœ¨æ¶‰åŠå¤æ‚æŸ¥è¯¢ï¼ˆå¦‚å¦å®šã€å¤šçº¦æŸæˆ–æ¨ç†éœ€æ±‚ï¼‰çš„æƒ…å†µä¸‹ï¼ŒMACDFçš„è¡¨ç°å°¤ä¸ºä¼˜å¼‚ã€‚</li>
<li>MACDFçš„æå‡ºçªæ˜¾äº†å¤šæ™ºèƒ½ä½“è®¤çŸ¥ç³»ç»Ÿåœ¨é‡æ–°å®šä¹‰ç”µå­å•†åŠ¡æœç´¢ä¸­çš„é‡è¦ä½œç”¨ã€‚</li>
<li>è¯¥å·¥ä½œå±•ç¤ºäº†å¤šæ™ºèƒ½ä½“è®¤çŸ¥ç³»ç»Ÿçš„å˜é©æ½œåŠ›ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.20567">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-a214f58a86d01a01ca7ad70c0f6b14ac" align="middle">
<img src="https://picx.zhimg.com/v2-69b45e117c67f028fd9f7ed07bc5600d" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="GhostEI-Bench-Do-Mobile-Agents-Resilience-to-Environmental-Injection-in-Dynamic-On-Device-Environments"><a href="#GhostEI-Bench-Do-Mobile-Agents-Resilience-to-Environmental-Injection-in-Dynamic-On-Device-Environments" class="headerlink" title="GhostEI-Bench: Do Mobile Agents Resilience to Environmental Injection in   Dynamic On-Device Environments?"></a>GhostEI-Bench: Do Mobile Agents Resilience to Environmental Injection in   Dynamic On-Device Environments?</h2><p><strong>Authors:Chiyu Chen, Xinhao Song, Yunkai Chai, Yang Yao, Haodong Zhao, Lijun Li, Jie Li, Yan Teng, Gongshen Liu, Yingchun Wang</strong></p>
<p>Vision-Language Models (VLMs) are increasingly deployed as autonomous agents to navigate mobile graphical user interfaces (GUIs). Operating in dynamic on-device ecosystems, which include notifications, pop-ups, and inter-app interactions, exposes them to a unique and underexplored threat vector: environmental injection. Unlike prompt-based attacks that manipulate textual instructions, environmental injection corrupts an agentâ€™s visual perception by inserting adversarial UI elements (for example, deceptive overlays or spoofed notifications) directly into the GUI. This bypasses textual safeguards and can derail execution, causing privacy leakage, financial loss, or irreversible device compromise. To systematically evaluate this threat, we introduce GhostEI-Bench, the first benchmark for assessing mobile agents under environmental injection attacks within dynamic, executable environments. Moving beyond static image-based assessments, GhostEI-Bench injects adversarial events into realistic application workflows inside fully operational Android emulators and evaluates performance across critical risk scenarios. We further propose a judge-LLM protocol that conducts fine-grained failure analysis by reviewing the agentâ€™s action trajectory alongside the corresponding screenshot sequence, pinpointing failure in perception, recognition, or reasoning. Comprehensive experiments on state-of-the-art agents reveal pronounced vulnerability to deceptive environmental cues: current models systematically fail to perceive and reason about manipulated UIs. GhostEI-Bench provides a framework for quantifying and mitigating this emerging threat, paving the way toward more robust and secure embodied agents. </p>
<blockquote>
<p>è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMsï¼‰è¶Šæ¥è¶Šå¤šåœ°è¢«éƒ¨ç½²ä¸ºè‡ªä¸»ä»£ç†ï¼Œä»¥åœ¨ç§»åŠ¨å›¾å½¢ç”¨æˆ·ç•Œé¢ï¼ˆGUIï¼‰ä¸­è¿›è¡Œå¯¼èˆªã€‚å®ƒä»¬åœ¨åŠ¨æ€è®¾å¤‡ç”Ÿæ€ç³»ç»Ÿï¼ˆåŒ…æ‹¬é€šçŸ¥ã€å¼¹å‡ºçª—å£å’Œè·¨åº”ç”¨ç¨‹åºäº¤äº’ï¼‰ä¸­è¿è¡Œï¼Œé¢ä¸´ä¸€ä¸ªç‹¬ç‰¹ä¸”å°šæœªè¢«å……åˆ†ç ”ç©¶çš„å¨èƒå‘é‡ï¼šç¯å¢ƒæ³¨å…¥ã€‚ä¸åŸºäºæç¤ºçš„æ”»å‡»ä¸åŒï¼Œç¯å¢ƒæ³¨å…¥ä¸ä¼šæ“çºµæ–‡æœ¬æŒ‡ä»¤ï¼Œè€Œæ˜¯é€šè¿‡åœ¨GUIä¸­ç›´æ¥æ’å…¥å¯¹æŠ—æ€§UIå…ƒç´ ï¼ˆä¾‹å¦‚æ¬ºéª—æ€§è¦†ç›–å±‚æˆ–ä¼ªé€ é€šçŸ¥ï¼‰æ¥ç ´åä»£ç†çš„è§†è§‰æ„ŸçŸ¥ã€‚è¿™ç»•è¿‡äº†æ–‡æœ¬å®‰å…¨ä¿æŠ¤æªæ–½ï¼Œå¯èƒ½å¯¼è‡´æ‰§è¡Œå‡ºé”™ã€éšç§æ³„éœ²ã€è´¢åŠ¡æŸå¤±æˆ–è®¾å¤‡é­åˆ°ä¸å¯é€†æŸå®³ã€‚ä¸ºäº†ç³»ç»Ÿåœ°è¯„ä¼°è¿™ä¸€å¨èƒï¼Œæˆ‘ä»¬æ¨å‡ºäº†GhostEI-Benchï¼Œè¿™æ˜¯ç¬¬ä¸€ä¸ªåœ¨åŠ¨æ€å¯æ‰§è¡Œç¯å¢ƒä¸­è¯„ä¼°ç§»åŠ¨ä»£ç†é¢ä¸´ç¯å¢ƒæ³¨å…¥æ”»å‡»çš„åŸºå‡†æµ‹è¯•ã€‚GhostEI-Benchè¶…è¶Šäº†åŸºäºé™æ€å›¾åƒçš„è¯„ä¼°æ–¹æ³•ï¼Œå°†å¯¹æŠ—æ€§äº‹ä»¶æ³¨å…¥åˆ°æ“ä½œæ­£å¸¸çš„Androidæ¨¡æ‹Ÿå™¨ä¸­çš„å®é™…åº”ç”¨ç¨‹åºå·¥ä½œæµç¨‹ä¸­ï¼Œå¹¶è·¨å…³é”®é£é™©åœºæ™¯è¿›è¡Œè¯„ä¼°ã€‚æˆ‘ä»¬è¿˜æå‡ºäº†ä¸€ä¸ªjudge-LLMåè®®ï¼Œå®ƒé€šè¿‡å®¡æŸ¥ä»£ç†çš„è¡ŒåŠ¨è½¨è¿¹ä»¥åŠç›¸åº”çš„å±å¹•æˆªå›¾åºåˆ—æ¥ç²¾ç»†åœ°åˆ†ææ•…éšœåŸå› ï¼Œç¡®å®šæ„ŸçŸ¥ã€è¯†åˆ«æˆ–æ¨ç†æ–¹é¢çš„å¤±è´¥ä¹‹å¤„ã€‚å¯¹æœ€å…ˆè¿›çš„ä»£ç†è¿›è¡Œçš„ç»¼åˆå®éªŒè¡¨æ˜ï¼Œå®ƒä»¬å¯¹æ¬ºéª—æ€§ç¯å¢ƒçº¿ç´¢çš„æ˜æ˜¾è„†å¼±æ€§ï¼šå½“å‰æ¨¡å‹åœ¨æ„ŸçŸ¥å’Œæ¨ç†è¢«æ“çºµçš„UIæ—¶ç³»ç»Ÿæ€§åœ°å¤±è´¥ã€‚GhostEI-Benchæä¾›äº†ä¸€ä¸ªé‡åŒ–å¹¶å‡è½»è¿™ä¸€æ–°å…´å¨èƒçš„æ¡†æ¶ï¼Œä¸ºæ„å»ºæ›´å¼ºå¤§ã€æ›´å®‰å…¨çš„åµŒå…¥å¼ä»£ç†é“ºå¹³äº†é“è·¯ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.20333v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†ç§»åŠ¨å›¾å½¢ç”¨æˆ·ç•Œé¢ï¼ˆGUIï¼‰ä¸­çš„è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMï¼‰é¢ä¸´çš„ä¸€ä¸ªæ–°å…´å¨èƒâ€”â€”ç¯å¢ƒæ³¨å…¥æ”»å‡»ã€‚ç¯å¢ƒæ³¨å…¥æ”»å‡»é€šè¿‡åœ¨GUIä¸­ç›´æ¥æ’å…¥å¯¹æŠ—æ€§UIå…ƒç´ ï¼ˆå¦‚æ¬ºéª—æ€§å åŠ å±‚æˆ–ä¼ªè£…é€šçŸ¥ï¼‰æ¥ç»•è¿‡æ–‡æœ¬ä¿éšœï¼Œå¯èƒ½å¯¼è‡´éšç§æ³„éœ²ã€è´¢åŠ¡æŸå¤±æˆ–è®¾å¤‡ä¸å¯é€†æŸå®³ã€‚ä¸ºäº†ç³»ç»Ÿåœ°è¯„ä¼°è¿™ä¸€å¨èƒï¼Œæœ¬æ–‡å¼•å…¥äº†GhostEI-Benchï¼Œè¿™æ˜¯ä¸€ä¸ªåœ¨åŠ¨æ€ã€å¯æ‰§è¡Œç¯å¢ƒä¸­è¯„ä¼°ç§»åŠ¨ä»£ç†é¢ä¸´ç¯å¢ƒæ³¨å…¥æ”»å‡»çš„åŸºå‡†æµ‹è¯•å¹³å°ã€‚åŒæ—¶æå‡ºäº†ä¸€ä¸ªæ³•å®˜å¤§å‹è¯­è¨€æ¨¡å‹åè®®ï¼Œé€šè¿‡å®¡æŸ¥ä»£ç†çš„è¡ŒåŠ¨è½¨è¿¹å’Œç›¸åº”çš„æˆªå›¾åºåˆ—è¿›è¡Œç²¾ç»†çš„æ•…éšœåˆ†æã€‚å®éªŒè¡¨æ˜ï¼Œå½“å‰æ¨¡å‹å¯¹æ¬ºéª—æ€§ç¯å¢ƒçº¿ç´¢çš„æ˜¾è‘—è„†å¼±æ€§ï¼ŒGhostEI-Benchæä¾›äº†é‡åŒ–è¿™ä¸€æ–°å…´å¨èƒå¹¶å‡è½»å…¶å½±å“çš„æ¡†æ¶ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>VLMsåœ¨æ“ä½œç§»åŠ¨GUIæ—¶é¢ä¸´ç¯å¢ƒæ³¨å…¥æ”»å‡»çš„ç‹¬ç‰¹å¨èƒã€‚</li>
<li>ç¯å¢ƒæ³¨å…¥æ”»å‡»é€šè¿‡æ’å…¥å¯¹æŠ—æ€§UIå…ƒç´ ç›´æ¥è…èš€VLMçš„è§†è§‰æ„ŸçŸ¥ã€‚</li>
<li>GhostEI-Benchæ˜¯é¦–ä¸ªåœ¨åŠ¨æ€ã€å¯æ‰§è¡Œç¯å¢ƒä¸­è¯„ä¼°VLMé¢ä¸´ç¯å¢ƒæ³¨å…¥æ”»å‡»çš„åŸºå‡†æµ‹è¯•å¹³å°ã€‚</li>
<li>GhostEI-Benchæ³¨å…¥å¯¹æŠ—äº‹ä»¶åˆ°ç°å®åº”ç”¨å·¥ä½œæµç¨‹ä¸­ï¼Œå¹¶åœ¨å®Œå…¨æ“ä½œçš„Androidæ¨¡æ‹Ÿå™¨ä¸­è¯„ä¼°æ€§èƒ½ã€‚</li>
<li>æå‡ºæ³•å®˜å¤§å‹è¯­è¨€æ¨¡å‹åè®®è¿›è¡Œç²¾ç»†çš„æ•…éšœåˆ†æã€‚</li>
<li>å®éªŒæ˜¾ç¤ºå½“å‰æ¨¡å‹å¯¹æ¬ºéª—æ€§ç¯å¢ƒçº¿ç´¢æœ‰æ˜¾è‘—è„†å¼±æ€§ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.20333">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-f327fd3a8ef4bee86aad5eaf52d7ee9f" align="middle">
<img src="https://picx.zhimg.com/v2-2f5b1db7069bc724abbdb395e66f5a96" align="middle">
<img src="https://picx.zhimg.com/v2-17bb69b56f655d10ed86d897b85162d7" align="middle">
<img src="https://picx.zhimg.com/v2-a37aa4fe9b8e3c7d08f559b7e34fef5e" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="From-Generation-to-Attribution-Music-AI-Agent-Architectures-for-the-Post-Streaming-Era"><a href="#From-Generation-to-Attribution-Music-AI-Agent-Architectures-for-the-Post-Streaming-Era" class="headerlink" title="From Generation to Attribution: Music AI Agent Architectures for the   Post-Streaming Era"></a>From Generation to Attribution: Music AI Agent Architectures for the   Post-Streaming Era</h2><p><strong>Authors:Wonil Kim, Hyeongseok Wi, Seungsoon Park, Taejun Kim, Sangeun Keum, Keunhyoung Kim, Taewan Kim, Jongmin Jung, Taehyoung Kim, Gaetan Guerrero, Mael Le Goff, Julie Po, Dongjoo Moon, Juhan Nam, Jongpil Lee</strong></p>
<p>Generative AI is reshaping music creation, but its rapid growth exposes structural gaps in attribution, rights management, and economic models. Unlike past media shifts, from live performance to recordings, downloads, and streaming, AI transforms the entire lifecycle of music, collapsing boundaries between creation, distribution, and monetization. However, existing streaming systems, with opaque and concentrated royalty flows, are ill-equipped to handle the scale and complexity of AI-driven production. We propose a content-based Music AI Agent architecture that embeds attribution directly into the creative workflow through block-level retrieval and agentic orchestration. Designed for iterative, session-based interaction, the system organizes music into granular components (Blocks) stored in BlockDB; each use triggers an Attribution Layer event for transparent provenance and real-time settlement. This framework reframes AI from a generative tool into infrastructure for a Fair AI Media Platform. By enabling fine-grained attribution, equitable compensation, and participatory engagement, it points toward a post-streaming paradigm where music functions not as a static catalog but as a collaborative and adaptive ecosystem. </p>
<blockquote>
<p>ç”Ÿæˆå¼äººå·¥æ™ºèƒ½æ­£åœ¨é‡å¡‘éŸ³ä¹åˆ›ä½œï¼Œä½†å…¶å¿«é€Ÿå‘å±•æš´éœ²äº†å½’å±ã€æƒåˆ©ç®¡ç†å’Œç»æµæ¨¡å‹æ–¹é¢çš„ç»“æ„æ€§ç¼ºé™·ã€‚ä¸ä»ç°åœºè¡¨æ¼”åˆ°å½•éŸ³ã€ä¸‹è½½å’Œæµåª’ä½“ç­‰è¿‡å»çš„åª’ä½“è½¬å˜ä¸åŒï¼Œäººå·¥æ™ºèƒ½è½¬å˜äº†éŸ³ä¹çš„æ•´ä¸ªç”Ÿå‘½å‘¨æœŸï¼Œæ¨¡ç³Šäº†åˆ›ä½œã€å‘è¡Œå’Œè´§å¸åŒ–ä¹‹é—´çš„ç•Œé™ã€‚ç„¶è€Œï¼Œç°æœ‰çš„æµåª’ä½“ç³»ç»Ÿå­˜åœ¨ç‰ˆæƒæµä¸é€æ˜å’Œé›†ä¸­ç­‰é—®é¢˜ï¼Œéš¾ä»¥åº”å¯¹äººå·¥æ™ºèƒ½é©±åŠ¨ç”Ÿäº§æ‰€å¸¦æ¥çš„è§„æ¨¡å’Œå¤æ‚æ€§æŒ‘æˆ˜ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§åŸºäºå†…å®¹çš„éŸ³ä¹äººå·¥æ™ºèƒ½ä»£ç†æ¶æ„ï¼Œè¯¥æ¶æ„é€šè¿‡å—çº§æ£€ç´¢å’Œä»£ç†ç¼–æ’ç›´æ¥å°†å½’å±åµŒå…¥åˆ›æ„å·¥ä½œæµç¨‹ã€‚è¯¥ç³»ç»Ÿè®¾è®¡ç”¨äºè¿­ä»£ã€åŸºäºä¼šè¯çš„äº¤äº’ï¼Œå°†éŸ³ä¹ç»„ç»‡æˆå­˜å‚¨åœ¨BlockDBä¸­çš„é¢—ç²’çŠ¶ç»„ä»¶ï¼ˆå—ï¼‰ï¼›æ¯æ¬¡ä½¿ç”¨éƒ½ä¼šè§¦å‘ä¸€ä¸ªå½’å±å±‚äº‹ä»¶ï¼Œä»¥å®ç°é€æ˜çš„æ¥æºå’Œå®æ—¶ç»“ç®—ã€‚è¯¥æ¡†æ¶å°†äººå·¥æ™ºèƒ½ä»ç”Ÿæˆå·¥å…·é‡æ–°å®šä½ä¸ºå…¬å¹³äººå·¥æ™ºèƒ½åª’ä½“å¹³å°çš„åŸºç¡€è®¾æ–½ã€‚é€šè¿‡å®ç°ç»†ç²’åº¦å½’å±ã€å…¬å¹³è¡¥å¿å’Œå‚ä¸å¼å‚ä¸ï¼Œå®ƒæŒ‡å‘äº†ä¸€ä¸ªåæµåª’ä½“èŒƒå¼ï¼Œåœ¨è¿™ä¸ªèŒƒå¼ä¸­ï¼ŒéŸ³ä¹ä¸ä»…æ˜¯ä¸€ä¸ªé™æ€çš„ç›®å½•ï¼Œè€Œæ˜¯ä¸€ä¸ªåä½œå’Œè‡ªé€‚åº”çš„ç”Ÿæ€ç³»ç»Ÿã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.20276v1">PDF</a> Accepted to the NeurIPS 2025 AI4Music Workshop</p>
<p><strong>Summary</strong><br>     ç”Ÿæˆå¼äººå·¥æ™ºèƒ½æ­£åœ¨é‡å¡‘éŸ³ä¹åˆ›ä½œï¼Œä½†å…¶å¿«é€Ÿå‘å±•æš´éœ²äº†å½’å±ã€æƒåˆ©ç®¡ç†å’Œç»æµæ¨¡å‹çš„ç»“æ„æ€§ç¼ºé™·ã€‚éŸ³ä¹AIæå‡ºäº†ä¸€ä¸ªåŸºäºå†…å®¹çš„éŸ³ä¹äººå·¥æ™ºèƒ½ä»£ç†æ¶æ„ï¼Œæ—¨åœ¨é€šè¿‡å—çº§æ£€ç´¢å’Œä»£ç†ç¼–æ’ç›´æ¥åµŒå…¥å½’å±ä¿¡æ¯åˆ°åˆ›ä½œæµç¨‹ä¸­ã€‚é€šè¿‡ç²¾ç»†åŒ–çš„å½’å±è·Ÿè¸ªã€å®æ—¶ç»“ç®—å’Œç»„ç»‡éŸ³ä¹ç´ æå—ï¼Œè¯¥æ¶æ„ä¸ºå…¬å¹³çš„äººå·¥æ™ºèƒ½åª’ä½“å¹³å°æä¾›äº†åŸºç¡€è®¾æ–½ã€‚è¿™æ ‡å¿—ç€ä»æµåª’ä½“æ¨¡å¼å‘åä½œå’Œè‡ªé€‚åº”éŸ³ä¹ç”Ÿæ€ç³»ç»Ÿçš„è½¬å˜ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ç”Ÿæˆå¼äººå·¥æ™ºèƒ½æ­£åœ¨é‡å¡‘éŸ³ä¹åˆ›ä½œé¢†åŸŸã€‚</li>
<li>äººå·¥æ™ºèƒ½éŸ³ä¹çš„å¿«é€Ÿå‘å±•å¸¦æ¥äº†å½’å±ã€æƒåˆ©ç®¡ç†å’Œç»æµæ¨¡å‹æ–¹é¢çš„æŒ‘æˆ˜ã€‚</li>
<li>ä¼ ç»Ÿæµåª’ä½“ç³»ç»Ÿåœ¨å¤„ç†äººå·¥æ™ºèƒ½é©±åŠ¨çš„ç”Ÿäº§æ–¹é¢å­˜åœ¨å±€é™ã€‚</li>
<li>æå‡ºçš„éŸ³ä¹AIä»£ç†æ¶æ„æ—¨åœ¨ç›´æ¥åµŒå…¥å½’å±ä¿¡æ¯åˆ°åˆ›ä½œæµç¨‹ä¸­ã€‚</li>
<li>è¯¥æ¶æ„é€šè¿‡å—çº§æ£€ç´¢å’Œä»£ç†ç¼–æ’å®ç°ç²¾ç»†åŒ–çš„å½’å±è·Ÿè¸ªã€‚</li>
<li>è¯¥æ¶æ„ä¸ºå»ºç«‹å…¬å¹³çš„äººå·¥æ™ºèƒ½åª’ä½“å¹³å°æä¾›äº†åŸºç¡€è®¾æ–½ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.20276">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-7cd20cf78539039158ae14f8c64291a5" align="middle">
<img src="https://picx.zhimg.com/v2-fdb1a96c189b7f215393e457e3902be6" align="middle">
<img src="https://picx.zhimg.com/v2-f90aba56fe431b63762fd94f5c406ccf" align="middle">
<img src="https://picx.zhimg.com/v2-057b96026efc499bd0108af63df2800f" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="Automated-Cloud-Infrastructure-as-Code-Reconciliation-with-AI-Agents"><a href="#Automated-Cloud-Infrastructure-as-Code-Reconciliation-with-AI-Agents" class="headerlink" title="Automated Cloud Infrastructure-as-Code Reconciliation with AI Agents"></a>Automated Cloud Infrastructure-as-Code Reconciliation with AI Agents</h2><p><strong>Authors:Zhenning Yang, Hui Guan, Victor Nicolet, Brandon Paulsen, Joey Dodds, Daniel Kroening, Ang Chen</strong></p>
<p>Cloud infrastructure is managed through a mix of interfaces â€“ traditionally, cloud consoles, command-line interfaces (CLI), and SDKs are the tools of choice. Recently, Infrastructure-as-Code&#x2F;IaC frameworks (e.g., Terraform) have quickly gained popularity. Unlike conventional tools, IaC~frameworks encode the infrastructure in a â€œsource-of-truthâ€ configuration. They are capable of automatically carrying out modifications to the cloud â€“ deploying, updating, or destroying resources â€“ to bring the actual infrastructure into alignment with the IaC configuration. However, when IaC is used alongside consoles, CLIs, or SDKs, it loses visibility into external changes, causing infrastructure drift, where the configuration becomes outdated, and later IaC operations may undo valid updates or trigger errors.   We present NSync, an automated system for IaC reconciliation that propagates out-of-band changes back into the IaC program. Our key insight is that infrastructure changes eventually all occur via cloud API invocations â€“ the lowest layer for cloud management operations. NSync gleans insights from API traces to detect drift (i.e., non-IaC changes) and reconcile it (i.e., update the IaC configuration to capture the changes). It employs an agentic architecture that leverages LLMs to infer high-level intents from noisy API sequences, synthesize targeted IaC updates using specialized tools, and continually improve through a self-evolving knowledge base of past reconciliations. We further introduce a novel evaluation pipeline for injecting realistic drifts into cloud infrastructure and assessing reconciliation performance. Experiments across five real-world Terraform projects and 372 drift scenarios show that NSync outperforms the baseline both in terms of accuracy (from 0.71 to 0.97 pass@3) and token efficiency (1.47$\times$ improvement). </p>
<blockquote>
<p>äº‘åŸºç¡€è®¾æ–½é€šè¿‡ä¸€ç³»åˆ—æ¥å£è¿›è¡Œç®¡ç†â€”â€”ä¼ ç»Ÿä¸Šï¼Œäº‘æ§åˆ¶å°ã€å‘½ä»¤è¡Œç•Œé¢ï¼ˆCLIï¼‰å’ŒSDKæ˜¯é¦–é€‰å·¥å…·ã€‚æœ€è¿‘ï¼ŒåŸºç¡€è®¾æ–½å³ä»£ç ï¼ˆIaCï¼‰æ¡†æ¶ï¼ˆä¾‹å¦‚Terraformï¼‰è¿…é€Ÿæµè¡Œèµ·æ¥ã€‚ä¸ä¼ ç»Ÿçš„å·¥å…·ä¸åŒï¼ŒIaCæ¡†æ¶å°†åŸºç¡€è®¾æ–½ç¼–ç ä¸ºâ€œçœŸå®æ¥æºâ€é…ç½®ã€‚å®ƒä»¬èƒ½å¤Ÿè‡ªåŠ¨å¯¹äº‘è¿›è¡Œä¿®æ”¹ã€éƒ¨ç½²ã€æ›´æ–°æˆ–é”€æ¯èµ„æºï¼Œä»¥ä½¿å®é™…åŸºç¡€è®¾æ–½ä¸IaCé…ç½®ä¿æŒä¸€è‡´ã€‚ç„¶è€Œï¼Œå½“IaCä¸æ§åˆ¶å°ã€CLIæˆ–SDKä¸€èµ·ä½¿ç”¨æ—¶ï¼Œå®ƒä¼šå¤±å»å¯¹å¤–éƒ¨æ›´æ”¹çš„å¯è§æ€§ï¼Œå¯¼è‡´åŸºç¡€è®¾æ–½æ¼‚ç§»ï¼Œæ­¤æ—¶é…ç½®å˜å¾—è¿‡æ—¶ï¼Œéšåçš„IaCæ“ä½œå¯èƒ½ä¼šæ’¤é”€æœ‰æ•ˆæ›´æ–°æˆ–è§¦å‘é”™è¯¯ã€‚æˆ‘ä»¬æå‡ºäº†NSyncï¼Œè¿™æ˜¯ä¸€ä¸ªè‡ªåŠ¨åŒ–çš„IaCåè°ƒç³»ç»Ÿï¼Œèƒ½å¤Ÿå°†éå®æ—¶æ›´æ”¹ä¼ æ’­å›IaCç¨‹åºã€‚æˆ‘ä»¬çš„å…³é”®è§è§£æ˜¯ï¼Œæ‰€æœ‰åŸºç¡€è®¾æ–½æ›´æ”¹æœ€ç»ˆéƒ½æ˜¯é€šè¿‡äº‘APIè°ƒç”¨å‘ç”Ÿçš„â€”â€”è¿™æ˜¯äº‘ç®¡ç†æ“ä½œçš„æœ€åº•å±‚ã€‚NSyncä»APIè·Ÿè¸ªä¸­è·å–è§è§£ä»¥æ£€æµ‹æ¼‚ç§»ï¼ˆå³éIaCæ›´æ”¹ï¼‰å¹¶è¿›è¡Œåè°ƒï¼ˆå³æ›´æ–°IaCé…ç½®ä»¥æ•è·æ›´æ”¹ï¼‰ã€‚å®ƒé‡‡ç”¨äº†ä¸€ç§åŸºäºä»£ç†çš„æ¶æ„ï¼Œè¯¥æ¶æ„åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ä»å˜ˆæ‚çš„APIåºåˆ—ä¸­æ¨æ–­å‡ºé«˜çº§æ„å›¾ï¼Œå¹¶ä½¿ç”¨ä¸“ä¸šå·¥å…·åˆæˆæœ‰é’ˆå¯¹æ€§çš„IaCæ›´æ–°ï¼Œå¹¶é€šè¿‡ä¸æ–­è‡ªæˆ‘æ¼”åŒ–çš„ä»¥å¾€åè°ƒçŸ¥è¯†åº“è¿›è¡Œè‡ªæˆ‘æ”¹è¿›ã€‚æˆ‘ä»¬è¿˜å¼•å…¥äº†ä¸€ç§æ–°çš„è¯„ä¼°ç®¡é“ï¼Œç”¨äºå‘äº‘åŸºç¡€è®¾æ–½æ³¨å…¥ç°å®æ¼‚ç§»å¹¶è¯„ä¼°åè°ƒæ€§èƒ½ã€‚åœ¨äº”ä¸ªçœŸå®çš„Terraformé¡¹ç›®å’Œ372ä¸ªæ¼‚ç§»åœºæ™¯çš„å®éªŒä¸­ï¼ŒNSyncåœ¨å‡†ç¡®æ€§å’Œæ ‡è®°æ•ˆç‡æ–¹é¢éƒ½ä¼˜äºåŸºçº¿ï¼ˆå‡†ç¡®ç‡ä»0.71æé«˜åˆ°0.97 pass@3ï¼Œæ ‡è®°æ•ˆç‡æé«˜äº†1.47å€ï¼‰ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.20211v1">PDF</a> </p>
<p><strong>Summary</strong><br>    IaCæ¡†æ¶èƒ½å¤Ÿè‡ªåŠ¨åŒ–ç®¡ç†äº‘åŸºç¡€è®¾æ–½çš„å˜æ›´ï¼Œä½†å½“ä¸äº‘æ§åˆ¶å°ã€å‘½ä»¤è¡Œæ¥å£æˆ–SDKç»“åˆä½¿ç”¨æ—¶ï¼Œå¯èƒ½ä¼šå› ä¸ºå¿½ç•¥å¤–éƒ¨æ›´æ”¹è€Œå¯¼è‡´åŸºç¡€è®¾æ–½é…ç½®æ¼‚ç§»é—®é¢˜ã€‚ä¸ºè§£å†³è¿™ä¸€é—®é¢˜ï¼Œæå‡ºäº†NSyncç³»ç»Ÿï¼Œé€šè¿‡è‡ªåŠ¨æ•è·å’Œåˆ†æAPIè°ƒç”¨çš„æ•°æ®ï¼Œæ£€æµ‹å‡ºéIaCå˜æ›´å¹¶è¿›è¡Œåè°ƒå¤„ç†ï¼Œåˆ©ç”¨LLMsæŠ€æœ¯ä»æ··ä¹±çš„APIåºåˆ—ä¸­æ¨æ–­å‡ºé«˜çº§æ„å›¾ï¼Œåˆæˆé’ˆå¯¹æ€§çš„IaCæ›´æ–°ã€‚å®éªŒè¯æ˜ï¼ŒNSyncåœ¨å¤„ç†çœŸå®ä¸–ç•Œçš„Terraformé¡¹ç›®æ—¶ï¼Œå‡†ç¡®ç‡å¤§å¹…æå‡å¹¶æœ‰æ•ˆæé«˜æ ‡è®°æ•ˆç‡ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>IaCæ¡†æ¶é‡‡ç”¨ç¼–ç é…ç½®ä½œä¸ºåŸºç¡€è®¾æ–½çš„â€œå•ä¸€çœŸå®æ¥æºâ€ï¼Œèƒ½è‡ªåŠ¨æ‰§è¡Œäº‘èµ„æºçš„éƒ¨ç½²ã€æ›´æ–°å’Œé”€æ¯æ“ä½œã€‚</li>
<li>å½“ç»“åˆä½¿ç”¨ä¼ ç»Ÿå·¥å…·ï¼ˆå¦‚äº‘æ§åˆ¶å°ã€CLIå’ŒSDKï¼‰æ—¶ï¼ŒIaCä¼šé‡åˆ°åŸºç¡€è®¾æ–½é…ç½®æ¼‚ç§»é—®é¢˜ã€‚</li>
<li>NSyncç³»ç»Ÿé€šè¿‡æ•è·å’Œåˆ†æAPIæ•°æ®æ¥è§£å†³é…ç½®æ¼‚ç§»é—®é¢˜ï¼Œå‡†ç¡®æ£€æµ‹å‡ºéIaCå˜æ›´ã€‚</li>
<li>NSyncåˆ©ç”¨LLMsæŠ€æœ¯å¤„ç†æ··ä¹±çš„APIåºåˆ—ï¼Œä»APIè°ƒç”¨ä¸­æ¨æ–­å‡ºé«˜çº§æ„å›¾ï¼Œç„¶ååˆæˆé’ˆå¯¹æ€§çš„IaCæ›´æ–°ã€‚</li>
<li>NSyncé‡‡ç”¨è‡ªæˆ‘è¿›åŒ–çš„çŸ¥è¯†åº“æœºåˆ¶ï¼Œèƒ½å¤Ÿä¸æ–­ä»è¿‡å»çš„åè°ƒè¿‡ç¨‹ä¸­å­¦ä¹ å¹¶æ”¹è¿›ã€‚</li>
<li>å®éªŒç»“æœæ˜¾ç¤ºï¼ŒNSyncåœ¨å¤„ç†çœŸå®ä¸–ç•Œçš„Terraformé¡¹ç›®æ—¶è¡¨ç°å‡ºä¼˜å¼‚çš„æ€§èƒ½ï¼Œå‡†ç¡®ç‡å’Œæ•ˆç‡å‡æœ‰æ‰€æå‡ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.20211">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-3fdc276238b32efc12eed1c63fb9515b" align="middle">
<img src="https://picx.zhimg.com/v2-191f0f44233558b583b2c1f5150736c2" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="DeepWideSearch-Benchmarking-Depth-and-Width-in-Agentic-Information-Seeking"><a href="#DeepWideSearch-Benchmarking-Depth-and-Width-in-Agentic-Information-Seeking" class="headerlink" title="DeepWideSearch: Benchmarking Depth and Width in Agentic Information   Seeking"></a>DeepWideSearch: Benchmarking Depth and Width in Agentic Information   Seeking</h2><p><strong>Authors:Tian Lan, Bin Zhu, Qianghuai Jia, Junyang Ren, Haijun Li, Longyue Wang, Zhao Xu, Weihua Luo, Kaifu Zhang</strong></p>
<p>Current search agents fundamentally lack the ability to simultaneously perform \textit{deep} reasoning over multi-hop retrieval and \textit{wide}-scale information collection-a critical deficiency for real-world applications like comprehensive market analysis and business development. To bridge this gap, we introduce DeepWideSearch, the first benchmark explicitly designed to evaluate agents to integrate depth and width in information seeking. In DeepWideSearch, agents must process a large volume of data, each requiring deep reasoning over multi-hop retrieval paths. Specifically, we propose two methods to converse established datasets, resulting in a curated collection of 220 questions spanning 15 diverse domains. Extensive experiments demonstrate that even state-of-the-art agents achieve only 2.39% average success rate on DeepWideSearch, highlighting the substantial challenge of integrating depth and width search in information-seeking tasks. Furthermore, our error analysis reveals four failure modes: lack of reflection, overreliance on internal knowledge, insufficient retrieval, and context overflow-exposing key limitations in current agent architectures. We publicly release DeepWideSearch to catalyze future research on more capable and robust information-seeking agents. </p>
<blockquote>
<p>å½“å‰çš„ä¿¡æ¯æœç´¢ä»£ç†åœ¨æœ¬è´¨ä¸Šç¼ºä¹åœ¨å¤šè·³æ£€ç´¢ä¸­è¿›è¡Œæ·±åº¦æ¨ç†ä»¥åŠåœ¨å¹¿æ³›çš„ä¿¡æ¯æ”¶é›†ä¸­è¿›è¡Œå®½åº¦æœç´¢çš„èƒ½åŠ›ï¼Œè¿™å¯¹äºå…¨é¢çš„å¸‚åœºåˆ†æã€å•†ä¸šå‘å±•ç­‰ç°å®ä¸–ç•Œåº”ç”¨æ¥è¯´æ˜¯ä¸€ä¸ªå…³é”®çš„ç¼ºé™·ã€‚ä¸ºäº†å¼¥è¡¥è¿™ä¸€å·®è·ï¼Œæˆ‘ä»¬æ¨å‡ºäº†DeepWideSearchï¼Œè¿™æ˜¯ç¬¬ä¸€ä¸ªæ˜ç¡®è®¾è®¡ç”¨äºè¯„ä¼°ä»£ç†åœ¨ä¿¡æ¯æœç´¢ä¸­é›†æˆæ·±åº¦å’Œå¹¿åº¦èƒ½åŠ›çš„åŸºå‡†æµ‹è¯•ã€‚åœ¨DeepWideSearchä¸­ï¼Œä»£ç†å¿…é¡»å¤„ç†å¤§é‡æ•°æ®ï¼Œæ¯æ¡æ•°æ®éƒ½éœ€è¦åœ¨å¤šè·³æ£€ç´¢è·¯å¾„ä¸Šè¿›è¡Œæ·±åº¦æ¨ç†ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸¤ç§æ–¹æ³•æ¥è½¬æ¢ç°æœ‰çš„æ•°æ®é›†ï¼Œå¯¼è‡´ä¸€ä¸ªç²¾é€‰çš„é—®é¢˜é›†åˆï¼ŒåŒ…å«è·¨è¶Š15ä¸ªä¸åŒé¢†åŸŸçš„å…±220ä¸ªé—®é¢˜ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼Œå³ä½¿åœ¨DeepWideSearchä¸Šï¼Œæœ€å…ˆè¿›çš„ä¿¡æ¯ä»£ç†ä¹Ÿä»…èƒ½è¾¾åˆ°å¹³å‡æˆåŠŸç‡ä¸ºä»…çš„ä»…åªæœ‰å¹³å‡æˆåŠŸç‡ä¸ºä»…æœ‰ç™¾åˆ†ä¹‹ä¸€å·¦å³çš„æˆç»©è¿™è¯´æ˜åœ¨ä¿¡æ¯æŸ¥è¯¢ä»»åŠ¡ä¸­å°†æ·±åº¦å’Œå¹¿åº¦æœç´¢ç»“åˆèµ·æ¥å…·æœ‰å·¨å¤§çš„æŒ‘æˆ˜æ­¤å¤–æˆ‘ä»¬çš„é”™è¯¯åˆ†ææ­ç¤ºäº†å››ç§å¤±è´¥æ¨¡å¼ï¼šç¼ºä¹åæ€ã€è¿‡åº¦ä¾èµ–å†…éƒ¨çŸ¥è¯†ã€æ£€ç´¢ä¸è¶³ä»¥åŠä¸Šä¸‹æ–‡æº¢å‡ºæš´éœ²äº†å½“å‰ä»£ç†æ¶æ„çš„å…³é”®å±€é™æ€§æˆ‘ä»¬å…¬å¼€å‘å¸ƒDeepWideSearchä»¥ä¿ƒè¿›å¯¹åŠŸèƒ½æ›´å¼ºã€æ›´ç¨³å¥çš„ä¿¡æ¯æœç´¢ä»£ç†çš„è¿›ä¸€æ­¥ç ”ç©¶</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.20168v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>DeepWideSearchå¡«è¡¥äº†ç°æœ‰æœç´¢ä»£ç†åœ¨ä¿¡æ¯æ£€ç´¢ä¸­çš„æ·±åº¦æ¨ç†ä¸å¹¿åº¦æ”¶é›†ä¸Šçš„ç©ºç™½ï¼Œå°¤å…¶é€‚ç”¨äºå…¨é¢çš„å¸‚åœºåˆ†æä¸å•†ä¸šå‘å±•ç­‰å®é™…åº”ç”¨ã€‚é€šè¿‡æ·±åº¦å¤„ç†å¤§é‡æ•°æ®å’Œå¤šè·³æ£€ç´¢è·¯å¾„çš„æ·±åº¦æ¨ç†ï¼Œæå‡ºä¸¤ç§æ–¹æ³•æ¥æ„å»ºæ•°æ®é›†ï¼Œæ¶µç›–15ä¸ªä¸åŒé¢†åŸŸã€‚å®éªŒæ˜¾ç¤ºï¼Œå³ä½¿åœ¨DeepWideSearchä¸Šï¼Œæœ€å…ˆè¿›çš„ä»£ç†ä¹Ÿåªæœ‰2.39%çš„å¹³å‡æˆåŠŸç‡ï¼Œè¡¨æ˜åœ¨æ•´åˆæ·±åº¦ä¸å¹¿åº¦æœç´¢ä¸­ä»å­˜åœ¨å·¨å¤§æŒ‘æˆ˜ã€‚æˆ‘ä»¬å…¬å¼€å‘å¸ƒDeepWideSearchï¼Œä»¥æ¨åŠ¨æ›´å¼ºå¤§ã€æ›´ç¨³å¥çš„ä¿¡æ¯æœç´¢ä»£ç†çš„ç ”ç©¶ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å½“å‰æœç´¢ä»£ç†åœ¨æ·±åº¦æ¨ç†å’Œå¤§è§„æ¨¡ä¿¡æ¯æ”¶é›†æ–¹é¢å­˜åœ¨æ ¹æœ¬æ€§ç¼ºé™·ã€‚</li>
<li>DeepWideSearchæ˜¯ä¸ºäº†è¯„ä¼°ä»£ç†åœ¨ä¿¡æ¯æœç´¢ä¸­åŒæ—¶å®ç°æ·±åº¦å’Œå¹¿åº¦æœç´¢çš„èƒ½åŠ›è€Œé¦–æ¬¡è®¾è®¡çš„åŸºå‡†æµ‹è¯•ã€‚</li>
<li>DeepWideSearchè¦æ±‚å¤„ç†å¤§é‡æ•°æ®ï¼Œå¹¶éœ€è¦æ²¿ç€å¤šè·³æ£€ç´¢è·¯å¾„è¿›è¡Œæ·±åº¦æ¨ç†ã€‚</li>
<li>æå‡ºä¸¤ç§æ–¹æ³•æ¥æ„å»ºæ•°æ®é›†ï¼Œæ¶µç›–å¤šä¸ªé¢†åŸŸçš„é—®é¢˜ã€‚</li>
<li>å®éªŒæ˜¾ç¤ºï¼Œæœ€å…ˆè¿›çš„ä»£ç†åœ¨DeepWideSearchä¸Šçš„å¹³å‡æˆåŠŸç‡å¾ˆä½ï¼Œè¡¨æ˜æ•´åˆæ·±åº¦ä¸å¹¿åº¦æœç´¢çš„æŒ‘æˆ˜æ€§ã€‚</li>
<li>é”™è¯¯åˆ†ææ­ç¤ºäº†å››ç§å¤±è´¥æ¨¡å¼ï¼ŒåŒ…æ‹¬ç¼ºä¹åæ€ã€è¿‡åº¦ä¾èµ–å†…éƒ¨çŸ¥è¯†ã€æ£€ç´¢ä¸è¶³å’Œä¸Šä¸‹æ–‡æº¢å‡ºã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.20168">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-7ad9b6f32636a3bf88e03ed5b376b9c5" align="middle">
<img src="https://picx.zhimg.com/v2-b32c749bf79dcccae1a2cf888d4175f3" align="middle">
<img src="https://picx.zhimg.com/v2-fa71f2937fc7f81fe63ca8dfe9263990" align="middle">
<img src="https://picx.zhimg.com/v2-3055e5ebd3c2aa740058d037c4c67405" align="middle">
<img src="https://picx.zhimg.com/v2-5c9183481610b427bf334859e3f44727" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="Empirical-Study-on-Robustness-and-Resilience-in-Cooperative-Multi-Agent-Reinforcement-Learning"><a href="#Empirical-Study-on-Robustness-and-Resilience-in-Cooperative-Multi-Agent-Reinforcement-Learning" class="headerlink" title="Empirical Study on Robustness and Resilience in Cooperative Multi-Agent   Reinforcement Learning"></a>Empirical Study on Robustness and Resilience in Cooperative Multi-Agent   Reinforcement Learning</h2><p><strong>Authors:Simin Li, Zihao Mao, Hanxiao Li, Zonglei Jing, Zhuohang bian, Jun Guo, Li Wang, Zhuoran Han, Ruixiao Xu, Xin Yu, Chengdong Ma, Yuqing Ma, Bo An, Yaodong Yang, Weifeng Lv, Xianglong Liu</strong></p>
<p>In cooperative Multi-Agent Reinforcement Learning (MARL), it is a common practice to tune hyperparameters in ideal simulated environments to maximize cooperative performance. However, policies tuned for cooperation often fail to maintain robustness and resilience under real-world uncertainties. Building trustworthy MARL systems requires a deep understanding of robustness, which ensures stability under uncertainties, and resilience, the ability to recover from disruptionsâ€“a concept extensively studied in control systems but largely overlooked in MARL. In this paper, we present a large-scale empirical study comprising over 82,620 experiments to evaluate cooperation, robustness, and resilience in MARL across 4 real-world environments, 13 uncertainty types, and 15 hyperparameters. Our key findings are: (1) Under mild uncertainty, optimizing cooperation improves robustness and resilience, but this link weakens as perturbations intensify. Robustness and resilience also varies by algorithm and uncertainty type. (2) Robustness and resilience do not generalize across uncertainty modalities or agent scopes: policies robust to action noise for all agents may fail under observation noise on a single agent. (3) Hyperparameter tuning is critical for trustworthy MARL: surprisingly, standard practices like parameter sharing, GAE, and PopArt can hurt robustness, while early stopping, high critic learning rates, and Leaky ReLU consistently help. By optimizing hyperparameters only, we observe substantial improvement in cooperation, robustness and resilience across all MARL backbones, with the phenomenon also generalizing to robust MARL methods across these backbones. Code and results available at <a target="_blank" rel="noopener" href="https://github.com/BUAA-TrustworthyMARL/adv_marl_benchmark">https://github.com/BUAA-TrustworthyMARL/adv_marl_benchmark</a> . </p>
<blockquote>
<p>åœ¨å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ ï¼ˆMARLï¼‰çš„åˆä½œåœºæ™¯ä¸­ï¼Œé€šå¸¸ä¼šåœ¨ç†æƒ³çš„æ¨¡æ‹Ÿç¯å¢ƒä¸­è°ƒæ•´è¶…å‚æ•°ä»¥æœ€å¤§åŒ–åˆä½œæ€§èƒ½ã€‚ç„¶è€Œï¼Œé’ˆå¯¹åˆä½œè°ƒæ•´çš„ç­–ç•¥å¾€å¾€åœ¨å®é™…ä¸–ç•Œçš„ä¸ç¡®å®šæ€§ä¸‹æ— æ³•ä¿æŒå…¶ç¨³å¥æ€§å’Œé€‚åº”æ€§ã€‚å»ºç«‹å¯ä¿¡èµ–çš„MARLç³»ç»Ÿéœ€è¦æ·±å…¥äº†è§£ç¨³å¥æ€§å’Œé€‚åº”æ€§è¿™ä¸¤ä¸ªæ¦‚å¿µï¼Œå…¶ä¸­ç¨³å¥æ€§ç¡®ä¿åœ¨ä¸ç¡®å®šæ€§ä¸‹çš„ç¨³å®šæ€§ï¼Œè€Œé€‚åº”æ€§åˆ™æ˜¯ä»å¹²æ‰°ä¸­æ¢å¤çš„èƒ½åŠ›â€”â€”è¿™ä¸€æ¦‚å¿µåœ¨æ§åˆ¶ç³»ç»Ÿä¸­æœ‰å¹¿æ³›çš„ç ”ç©¶ï¼Œä½†åœ¨MARLä¸­å´è¢«å¤§å¤§å¿½è§†äº†ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬è¿›è¡Œäº†ä¸€é¡¹å¤§è§„æ¨¡å®è¯ç ”ç©¶ï¼ŒåŒ…æ‹¬è¶…è¿‡82,620ä¸ªå®éªŒï¼Œä»¥è¯„ä¼°MARLä¸­çš„åˆä½œã€ç¨³å¥æ€§å’Œé€‚åº”æ€§åœ¨å››ä¸ªçœŸå®ç¯å¢ƒä¸­çš„è¡¨ç°ï¼Œæ¶‰åŠ13ç§ä¸ç¡®å®šæ€§å’Œ15ä¸ªè¶…å‚æ•°ã€‚æˆ‘ä»¬çš„ä¸»è¦å‘ç°å¦‚ä¸‹ï¼šï¼ˆ1ï¼‰åœ¨è½»å¾®çš„ä¸ç¡®å®šæ€§ä¸‹ï¼Œä¼˜åŒ–åˆä½œå¯ä»¥æé«˜ç¨³å¥æ€§å’Œé€‚åº”æ€§ï¼Œä½†éšç€å¹²æ‰°çš„åŠ å‰§ï¼Œè¿™ç§è”ç³»ä¼šå‡å¼±ã€‚ç¨³å¥æ€§å’Œé€‚åº”æ€§ä¹Ÿä¼šå› ç®—æ³•å’Œä¸ç¡®å®šæ€§çš„ç±»å‹è€Œæœ‰æ‰€ä¸åŒã€‚ï¼ˆ2ï¼‰ç¨³å¥æ€§å’Œé€‚åº”æ€§ä¸ä¼šåœ¨ä¸åŒçš„ä¸ç¡®å®šæ€§æ¨¡å¼æˆ–æ™ºèƒ½ä½“èŒƒå›´å†…é€šç”¨ï¼šå¯¹æ‰€æœ‰æ™ºèƒ½ä½“çš„åŠ¨ä½œå™ªå£°å…·æœ‰ç¨³å¥æ€§çš„ç­–ç•¥å¯èƒ½ä¼šåœ¨å•ä¸ªæ™ºèƒ½ä½“çš„è§‚æµ‹å™ªå£°ä¸‹å¤±æ•ˆã€‚ï¼ˆ3ï¼‰è¶…å‚æ•°è°ƒæ•´å¯¹äºå¯ä¿¡èµ–çš„MARLè‡³å…³é‡è¦ï¼šä»¤äººæƒŠè®¶çš„æ˜¯ï¼Œæ ‡å‡†å®è·µå¦‚å‚æ•°å…±äº«ã€GAEå’ŒPopArtå¯èƒ½ä¼šæŸå®³ç¨³å¥æ€§ï¼Œè€Œæ—©åœã€é«˜è¯„è®ºå®¶å­¦ä¹ ç‡å’ŒLeaky ReLUåˆ™å§‹ç»ˆæœ‰æ‰€å¸®åŠ©ã€‚ä»…é€šè¿‡ä¼˜åŒ–è¶…å‚æ•°ï¼Œæˆ‘ä»¬è§‚å¯Ÿåˆ°æ‰€æœ‰MARLéª¨å¹²çš„åˆä½œã€ç¨³å¥æ€§å’Œé€‚åº”æ€§éƒ½æœ‰æ˜¾è‘—æ”¹å–„ï¼Œè¿™ä¸€ç°è±¡ä¹Ÿé€‚ç”¨äºè¿™äº›éª¨å¹²çš„ç¨³å¥MARLæ–¹æ³•ã€‚ä»£ç å’Œç»“æœå¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/BUAA-TrustworthyMARL/adv_marl_benchmark%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/BUAA-TrustworthyMARL/adv_marl_benchmarkæ‰¾åˆ°ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.11824v2">PDF</a> 44 pages, 16 figures, NeurIPS 2025</p>
<p><strong>Summary</strong><br>     åœ¨å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ ï¼ˆMARLï¼‰ä¸­ï¼Œé€šå¸¸åœ¨ç†æƒ³æ¨¡æ‹Ÿç¯å¢ƒä¸­è°ƒæ•´è¶…å‚æ•°ä»¥æœ€å¤§åŒ–åˆä½œæ€§èƒ½ã€‚ç„¶è€Œï¼Œé’ˆå¯¹åˆä½œçš„ç­–ç•¥åœ¨ç°å®ä¸–ç•Œçš„ä¸ç¡®å®šæ€§ä¸‹å¾€å¾€æ— æ³•ä¿æŒç¨³å¥æ€§å’Œæ¢å¤åŠ›ã€‚æœ¬æ–‡è¿›è¡Œäº†å¤§è§„æ¨¡å®è¯ç ”ç©¶ï¼Œæ¶µç›–4ä¸ªçœŸå®ç¯å¢ƒã€13ç§ä¸ç¡®å®šæ€§å’Œ15ä¸ªè¶…å‚æ•°ï¼Œå¯¹MARLä¸­çš„åˆä½œã€ç¨³å¥æ€§å’Œæ¢å¤åŠ›è¿›è¡Œè¯„ä¼°ã€‚ç ”ç©¶å‘ç°ï¼Œåœ¨è½»å¾®ä¸ç¡®å®šæ€§ä¸‹ï¼Œä¼˜åŒ–åˆä½œèƒ½æé«˜ç¨³å¥æ€§å’Œæ¢å¤æ€§ï¼Œä½†éšç€æ‰°åŠ¨å¢å¼ºï¼Œè¿™ç§è”ç³»å‡å¼±ã€‚ç¨³å¥æ€§å’Œæ¢å¤æ€§å› ç®—æ³•å’Œä¸ç¡®å®šæ€§ç±»å‹è€Œå¼‚ï¼›æ”¿ç­–å’Œé²æ£’æ€§ä¸ä¼šæ³›åŒ–åˆ°æ‰€æœ‰ä¸ç¡®å®šæ€§æ¨¡æ€æˆ–æ™ºèƒ½ä½“èŒƒå›´ï¼›å…³é”®è¶…å‚æ•°è°ƒæ•´å¯¹äºå¯é MARLè‡³å…³é‡è¦ã€‚ä»…é€šè¿‡ä¼˜åŒ–è¶…å‚æ•°ï¼Œå¯ä»¥æ˜¾è‘—æ”¹å–„æ‰€æœ‰MARLéª¨æ¶çš„åˆä½œã€ç¨³å¥æ€§å’Œæ¢å¤æ€§ï¼Œè¿™ä¸€ç°è±¡ä¹Ÿé€‚ç”¨äºè¿™äº›éª¨æ¶çš„ç¨³å¥MARLæ–¹æ³•ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>åœ¨å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ ï¼ˆMARLï¼‰ä¸­ï¼Œåˆä½œç­–ç•¥åœ¨æ¨¡æ‹Ÿç¯å¢ƒä¸­è°ƒæ•´è¶…å‚æ•°æ—¶å¾ˆé‡è¦ï¼Œä½†åœ¨ç°å®ä¸–ç•Œçš„å¤æ‚æ€§å’Œä¸ç¡®å®šæ€§æ¡ä»¶ä¸‹ï¼Œéœ€è¦æ›´å¤šè€ƒè™‘ç¨³å¥æ€§å’Œæ¢å¤åŠ›ã€‚</li>
<li>ç¨³å¥æ€§å’Œæ¢å¤æ€§åœ¨é¢ä¸´ä¸åŒç±»å‹çš„ä¸ç¡®å®šæ€§æ—¶ä¼šæœ‰æ‰€ä¸åŒï¼Œå¹¶ä¸”ä¾èµ–äºæ‰€ä½¿ç”¨çš„ç®—æ³•ã€‚</li>
<li>åœ¨è½»å¾®çš„ä¸ç¡®å®šæ€§ä¸‹ï¼Œä¼˜åŒ–åˆä½œå¯ä»¥æé«˜ç¨³å¥æ€§å’Œæ¢å¤æ€§ï¼Œä½†å½“ä¸ç¡®å®šæ€§å¢å¼ºæ—¶ï¼Œè¿™ç§å…³è”å‡å¼±ã€‚</li>
<li>é²æ£’æ€§ç­–ç•¥å¹¶ä¸æ€»æ˜¯é€‚ç”¨äºæ‰€æœ‰ç±»å‹çš„ä¸ç¡®å®šæ€§å’Œæ‰€æœ‰æ™ºèƒ½ä½“èŒƒå›´ã€‚ä¾‹å¦‚ï¼Œå¯¹æ‰€æœ‰æ™ºèƒ½ä½“çš„åŠ¨ä½œå™ªå£°æœ‰æ•ˆçš„é²æ£’ç­–ç•¥å¯èƒ½ä¼šåœ¨å•ä¸ªæ™ºèƒ½ä½“çš„è§‚æµ‹å™ªå£°ä¸‹å¤±æ•ˆã€‚</li>
<li>è¶…å‚æ•°è°ƒæ•´å¯¹æ„å»ºå¯é çš„MARLç³»ç»Ÿè‡³å…³é‡è¦ã€‚ä¸€äº›å¸¸è§çš„å®è·µï¼ˆå¦‚å‚æ•°å…±äº«ã€GAEå’ŒPopArtï¼‰å¯èƒ½ä¼šæŸå®³ç¨³å¥æ€§ï¼Œè€Œæ—©æœŸåœæ­¢è®­ç»ƒã€é«˜è¯„è®ºå®¶å­¦ä¹ ç‡å’ŒLeaky ReLUåˆ™æœ‰åŠ©äºå¢å¼ºç¨³å¥æ€§ã€‚</li>
<li>ä»…é€šè¿‡ä¼˜åŒ–è¶…å‚æ•°ï¼Œå¯ä»¥æ˜¾è‘—æé«˜æ‰€æœ‰MARLéª¨æ¶çš„åˆä½œã€ç¨³å¥æ€§å’Œæ¢å¤æ€§ã€‚è¿™ç§ç°è±¡ä¹Ÿé€‚ç”¨äºä¸åŒçš„ç¨³å¥MARLæ–¹æ³•ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.11824">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-3c3a1447a19918c10ad498d595e32614" align="middle">
<img src="https://picx.zhimg.com/v2-e46868dc690cef6f2a6d5354b620667b" align="middle">
<img src="https://picx.zhimg.com/v2-2931c3ac7ccdc373226e0c95ed1f9811" align="middle">
<img src="https://picx.zhimg.com/v2-84254d30f178eacfbc3e2edddfe1d0d4" align="middle">
<img src="https://picx.zhimg.com/v2-450669325b0e7fa9f335f72d22f44015" align="middle">
<img src="https://picx.zhimg.com/v2-54a43efe4023501bc8371de2eb9e08a8" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="A-Comprehensive-Survey-on-Benchmarks-and-Solutions-in-Software-Engineering-of-LLM-Empowered-Agentic-System"><a href="#A-Comprehensive-Survey-on-Benchmarks-and-Solutions-in-Software-Engineering-of-LLM-Empowered-Agentic-System" class="headerlink" title="A Comprehensive Survey on Benchmarks and Solutions in Software   Engineering of LLM-Empowered Agentic System"></a>A Comprehensive Survey on Benchmarks and Solutions in Software   Engineering of LLM-Empowered Agentic System</h2><p><strong>Authors:Jiale Guo, Suizhi Huang, Mei Li, Dong Huang, Xingsheng Chen, Regina Zhang, Zhijiang Guo, Han Yu, Siu-Ming Yiu, Pietro Lio, Kwok-Yan Lam</strong></p>
<p>The integration of Large Language Models (LLMs) into software engineering has driven a transition from traditional rule-based systems to autonomous agentic systems capable of solving complex problems. However, systematic progress is hindered by a lack of comprehensive understanding of how benchmarks and solutions interconnect. This survey addresses this gap by providing the first holistic analysis of LLM-powered software engineering, offering insights into evaluation methodologies and solution paradigms. We review over 150 recent papers and propose a taxonomy along two key dimensions: (1) Solutions, categorized into prompt-based, fine-tuning-based, and agent-based paradigms, and (2) Benchmarks, including tasks such as code generation, translation, and repair. Our analysis highlights the evolution from simple prompt engineering to sophisticated agentic systems incorporating capabilities like planning, reasoning, memory mechanisms, and tool augmentation. To contextualize this progress, we present a unified pipeline illustrating the workflow from task specification to deliverables, detailing how different solution paradigms address various complexity levels. Unlike prior surveys that focus narrowly on specific aspects, this work connects 50+ benchmarks to their corresponding solution strategies, enabling researchers to identify optimal approaches for diverse evaluation criteria. We also identify critical research gaps and propose future directions, including multi-agent collaboration, self-evolving systems, and formal verification integration. This survey serves as a foundational guide for advancing LLM-driven software engineering. We maintain a GitHub repository that continuously updates the reviewed and related papers at <a target="_blank" rel="noopener" href="https://github.com/lisaGuojl/LLM-Agent-SE-Survey">https://github.com/lisaGuojl/LLM-Agent-SE-Survey</a>. </p>
<blockquote>
<p>å°†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰é›†æˆåˆ°è½¯ä»¶å·¥ç¨‹ä¸­å·²ç»æ¨åŠ¨äº†ä»ä¼ ç»ŸåŸºäºè§„åˆ™çš„ç³»ç»Ÿå‘èƒ½å¤Ÿè§£å†³å¤æ‚é—®é¢˜çš„è‡ªä¸»ä»£ç†ç³»ç»Ÿçš„è½¬å˜ã€‚ç„¶è€Œï¼Œç”±äºç¼ºä¹å¯¹åŸºå‡†æµ‹è¯•å’Œè§£å†³æ–¹æ¡ˆä¹‹é—´ç›¸äº’è”ç³»çš„ç»¼åˆç†è§£ï¼Œç³»ç»Ÿçš„å‘å±•å—åˆ°äº†é˜»ç¢ã€‚æœ¬è°ƒæŸ¥é€šè¿‡æä¾›å¯¹LLMé©±åŠ¨çš„è½¯ä»¶å·¥ç¨‹çš„é¦–æ¬¡æ•´ä½“åˆ†ææ¥è§£å†³è¿™ä¸€å·®è·ï¼Œä¸ºè¯„ä¼°æ–¹æ³•å’Œè§£å†³æ–¹æ¡ˆèŒƒå¼æä¾›è§è§£ã€‚æˆ‘ä»¬å›é¡¾äº†150å¤šç¯‡è¿‘æœŸè®ºæ–‡ï¼Œå¹¶æå‡ºäº†ä¸¤ä¸ªå…³é”®ç»´åº¦çš„åˆ†ç±»ï¼šï¼ˆ1ï¼‰è§£å†³æ–¹æ¡ˆï¼Œåˆ†ä¸ºåŸºäºæç¤ºçš„ã€åŸºäºç²¾ç»†è°ƒæ•´çš„å’ŒåŸºäºä»£ç†çš„èŒƒå¼ï¼›ï¼ˆ2ï¼‰åŸºå‡†æµ‹è¯•ï¼ŒåŒ…æ‹¬ä»£ç ç”Ÿæˆã€ç¿»è¯‘å’Œä¿®å¤ç­‰ä»»åŠ¡ã€‚æˆ‘ä»¬çš„åˆ†æå¼ºè°ƒäº†ä»ç®€å•çš„æç¤ºå·¥ç¨‹åˆ°å¤æ‚çš„ä»£ç†ç³»ç»Ÿï¼ˆå¦‚è§„åˆ’ã€æ¨ç†ã€è®°å¿†æœºåˆ¶å’Œå·¥å…·å¢å¼ºåŠŸèƒ½ï¼‰çš„æ¼”å˜ã€‚ä¸ºäº†æƒ…å¢ƒåŒ–è¿™ç§è¿›å±•ï¼Œæˆ‘ä»¬å±•ç¤ºäº†ä¸€ä¸ªç»Ÿä¸€çš„å·¥ä½œæµç¨‹ç®¡é“ï¼Œè¯¦ç»†è¯´æ˜äº†ä»ä»»åŠ¡è¯´æ˜åˆ°äº¤ä»˜å“çš„æµç¨‹ï¼Œä»¥åŠä¸åŒçš„è§£å†³æ–¹æ¡ˆèŒƒå¼å¦‚ä½•å¤„ç†ä¸åŒçº§åˆ«çš„å¤æ‚æ€§ã€‚ä¸ä»¥å‰åªå…³æ³¨ç‰¹å®šæ–¹é¢çš„è°ƒæŸ¥ä¸åŒï¼Œè¿™é¡¹å·¥ä½œå°†50å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸å…¶ç›¸åº”çš„è§£å†³æ–¹æ¡ˆç­–ç•¥è”ç³»èµ·æ¥ï¼Œä½¿ç ”ç©¶äººå‘˜èƒ½å¤Ÿæ ¹æ®å„ç§è¯„ä¼°æ ‡å‡†ç¡®å®šæœ€ä½³æ–¹æ³•ã€‚æˆ‘ä»¬è¿˜ç¡®å®šäº†å…³é”®çš„ç ”ç©¶ç©ºç™½å¹¶æå‡ºäº†æœªæ¥çš„æ–¹å‘ï¼ŒåŒ…æ‹¬å¤šä»£ç†åä½œã€è‡ªæˆ‘è¿›åŒ–ç³»ç»Ÿå’Œå½¢å¼åŒ–éªŒè¯é›†æˆã€‚æœ¬è°ƒæŸ¥æ˜¯æ¨è¿›LLMé©±åŠ¨è½¯ä»¶å·¥ç¨‹çš„åŸºç¡€æŒ‡å—ã€‚æˆ‘ä»¬åœ¨GitHubä¸Šç»´æŠ¤äº†ä¸€ä¸ªæŒç»­æ›´æ–°æ‰€å®¡é˜…å’Œç›¸å…³è®ºæ–‡çš„ä»“åº“ï¼š<a target="_blank" rel="noopener" href="https://github.com/lisaGuojl/LLM-Agent-SE-Survey">https://github.com/lisaGuojl/LLM-Agent-SE-Survey</a> ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.09721v3">PDF</a> 22 pages</p>
<p><strong>Summary</strong>ï¼šå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰èå…¥è½¯ä»¶å·¥ç¨‹æ¨åŠ¨äº†ä»ä¼ ç»Ÿè§„åˆ™åŸºç¡€ç³»ç»Ÿå‘è‡ªä¸»ä»£ç†ç³»ç»Ÿçš„è½¬å˜ï¼Œèƒ½è§£å†³å¤æ‚é—®é¢˜ã€‚ä½†ç¼ºä¹åŸºå‡†æµ‹è¯•å’Œè§£å†³æ–¹æ¡ˆç›¸äº’è”ç³»çš„å…¨é¢ç†è§£é˜»ç¢äº†ç³»ç»Ÿæ€§è¿›å±•ã€‚æœ¬æ–‡é¦–æ¬¡å…¨é¢åˆ†æäº†LLMé©±åŠ¨çš„è½¯ä»¶å·¥ç¨‹ï¼Œæ·±å…¥æ¢è®¨äº†è¯„ä¼°æ–¹æ³•å’Œè§£å†³æ–¹æ¡ˆèŒƒå¼ï¼Œå¡«è¡¥äº†è¿™ä¸€ç©ºç™½ã€‚æˆ‘ä»¬å®¡æŸ¥äº†è¶…è¿‡150ç¯‡è¿‘æœŸè®ºæ–‡ï¼Œå¹¶ä¾æ®è§£å†³æ–¹æ¡ˆå’ŒåŸºå‡†æµ‹è¯•æå‡ºäº†åˆ†ç±»ã€‚æˆ‘ä»¬çš„åˆ†æå‡¸æ˜¾äº†ä»ç®€å•æç¤ºå·¥ç¨‹åˆ°èå…¥è§„åˆ’ã€æ¨ç†ã€è®°å¿†æœºåˆ¶å’Œå·¥å…·æ‰©å……ç­‰èƒ½åŠ›çš„å…ˆè¿›ä»£ç†ç³»ç»Ÿçš„æ¼”å˜ã€‚æˆ‘ä»¬æä¾›äº†ä¸€ä¸ªç»Ÿä¸€çš„å·¥ä½œæµç¨‹ç®¡é“ï¼Œä»¥é˜é‡Šå„ç§è§£å†³æ–¹æ¡ˆå¦‚ä½•åº”å¯¹ä¸åŒå¤æ‚åº¦çš„ä»»åŠ¡ã€‚æœ¬æ–‡ä¸åŒäºä»¥å¾€ä¾§é‡äºç‰¹å®šæ–¹é¢çš„è°ƒæŸ¥ï¼Œå°†50å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸å…¶ç›¸åº”çš„è§£å†³æ–¹æ¡ˆç­–ç•¥ç›¸è”ç³»ï¼Œå¹¶æŒ‡å‡ºäº†å…³é”®ç ”ç©¶ç©ºç™½å’Œæœªæ¥å‘å±•æ–¹å‘ï¼ŒåŒ…æ‹¬å¤šä»£ç†åä½œã€è‡ªæˆ‘è¿›åŒ–ç³»ç»Ÿå’Œå½¢å¼éªŒè¯é›†æˆã€‚æœ¬æ–‡ä¸ºæ¨è¿›LLMé©±åŠ¨çš„è½¯ä»¶å·¥ç¨‹æä¾›äº†åŸºç¡€æŒ‡å—ã€‚</p>
<p><strong>Key Takeaways</strong>:</p>
<ol>
<li>LLMèå…¥è½¯ä»¶å·¥ç¨‹å®ç°äº†ä»ä¼ ç»Ÿè§„åˆ™åŸºç¡€ç³»ç»Ÿåˆ°è‡ªä¸»ä»£ç†ç³»ç»Ÿçš„è½¬å˜ã€‚</li>
<li>ç¼ºä¹åŸºå‡†æµ‹è¯•å’Œè§£å†³æ–¹æ¡ˆç›¸äº’è”ç³»çš„å…¨é¢ç†è§£é˜»ç¢äº†ç³»ç»Ÿæ€§è¿›å±•ã€‚</li>
<li>æœ¬æ–‡é¦–æ¬¡å…¨é¢åˆ†æäº†LLMé©±åŠ¨çš„è½¯ä»¶å·¥ç¨‹ï¼Œæ¢è®¨äº†è¯„ä¼°æ–¹æ³•å’Œè§£å†³æ–¹æ¡ˆèŒƒå¼ã€‚</li>
<li>é€šè¿‡å¯¹è¶…è¿‡150ç¯‡è¿‘æœŸè®ºæ–‡çš„å®¡æŸ¥ï¼Œæå‡ºäº†åŸºäºè§£å†³æ–¹æ¡ˆå’ŒåŸºå‡†æµ‹è¯•çš„åˆ†ç±»æ–¹æ³•ã€‚</li>
<li>åˆ†æå¼ºè°ƒäº†ä»ç®€å•æç¤ºå·¥ç¨‹åˆ°å…ˆè¿›ä»£ç†ç³»ç»Ÿçš„æ¼”å˜ï¼Œèå…¥äº†å¤šç§èƒ½åŠ›å¦‚è§„åˆ’ã€æ¨ç†ã€è®°å¿†æœºåˆ¶ç­‰ã€‚</li>
<li>æä¾›äº†ç»Ÿä¸€çš„å·¥ä½œæµç¨‹ç®¡é“ï¼Œå±•ç¤ºä¸åŒè§£å†³æ–¹æ¡ˆå¦‚ä½•åº”å¯¹ä¸åŒå¤æ‚åº¦çš„ä»»åŠ¡ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.09721">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-9fbefafe15ad2a71dfb2132e5d424e7e" align="middle">
<img src="https://picx.zhimg.com/v2-21714c3e8f150fabab30df86a096f6e4" align="middle">
<img src="https://picx.zhimg.com/v2-1c3dcb9eab85b198b4c7a2f590f7d5bf" align="middle">
<img src="https://picx.zhimg.com/v2-9804aab8f7ed5a5cd1908df957eb48b8" align="middle">
<img src="https://picx.zhimg.com/v2-b9b4c873d83d093616ed910c4abd615b" align="middle">
<img src="https://picx.zhimg.com/v2-01f8de144c93a543b70d834f7ff063ef" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="RADAR-A-Risk-Aware-Dynamic-Multi-Agent-Framework-for-LLM-Safety-Evaluation-via-Role-Specialized-Collaboration"><a href="#RADAR-A-Risk-Aware-Dynamic-Multi-Agent-Framework-for-LLM-Safety-Evaluation-via-Role-Specialized-Collaboration" class="headerlink" title="RADAR: A Risk-Aware Dynamic Multi-Agent Framework for LLM Safety   Evaluation via Role-Specialized Collaboration"></a>RADAR: A Risk-Aware Dynamic Multi-Agent Framework for LLM Safety   Evaluation via Role-Specialized Collaboration</h2><p><strong>Authors:Xiuyuan Chen, Jian Zhao, Yuchen Yuan, Tianle Zhang, Huilin Zhou, Zheng Zhu, Ping Hu, Linghe Kong, Chi Zhang, Weiran Huang, Xuelong Li</strong></p>
<p>Existing safety evaluation methods for large language models (LLMs) suffer from inherent limitations, including evaluator bias and detection failures arising from model homogeneity, which collectively undermine the robustness of risk evaluation processes. This paper seeks to re-examine the risk evaluation paradigm by introducing a theoretical framework that reconstructs the underlying risk concept space. Specifically, we decompose the latent risk concept space into three mutually exclusive subspaces: the explicit risk subspace (encompassing direct violations of safety guidelines), the implicit risk subspace (capturing potential malicious content that requires contextual reasoning for identification), and the non-risk subspace. Furthermore, we propose RADAR, a multi-agent collaborative evaluation framework that leverages multi-round debate mechanisms through four specialized complementary roles and employs dynamic update mechanisms to achieve self-evolution of risk concept distributions. This approach enables comprehensive coverage of both explicit and implicit risks while mitigating evaluator bias. To validate the effectiveness of our framework, we construct an evaluation dataset comprising 800 challenging cases. Extensive experiments on our challenging testset and public benchmarks demonstrate that RADAR significantly outperforms baseline evaluation methods across multiple dimensions, including accuracy, stability, and self-evaluation risk sensitivity. Notably, RADAR achieves a 28.87% improvement in risk identification accuracy compared to the strongest baseline evaluation method. </p>
<blockquote>
<p>ç°æœ‰å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„å®‰å…¨è¯„ä¼°æ–¹æ³•å­˜åœ¨å›ºæœ‰çš„å±€é™æ€§ï¼ŒåŒ…æ‹¬è¯„ä¼°è€…åè§å’Œç”±æ¨¡å‹åŒè´¨æ€§å¼•èµ·çš„æ£€æµ‹å¤±è´¥ï¼Œè¿™äº›å…±åŒå‰Šå¼±äº†é£é™©è¯„ä¼°è¿‡ç¨‹çš„ç¨³å¥æ€§ã€‚æœ¬æ–‡æ—¨åœ¨é€šè¿‡å¼•å…¥ä¸€ä¸ªé‡å»ºåŸºç¡€é£é™©æ¦‚å¿µç©ºé—´çš„ç†è®ºæ¡†æ¶ï¼Œé‡æ–°å®¡è§†é£é™©è¯„ä¼°èŒƒå¼ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬å°†æ½œåœ¨é£é™©æ¦‚å¿µç©ºé—´åˆ†è§£ä¸ºä¸‰ä¸ªç›¸äº’æ’æ–¥çš„å­ç©ºé—´ï¼šæ˜¾å¼é£é™©å­ç©ºé—´ï¼ˆåŒ…å«ç›´æ¥è¿åå®‰å…¨æŒ‡å—çš„é£é™©ï¼‰ã€éšå¼é£é™©å­ç©ºé—´ï¼ˆæ•è·éœ€è¦ä¸Šä¸‹æ–‡æ¨ç†æ¥è¯†åˆ«çš„æ½œåœ¨æ¶æ„å†…å®¹ï¼‰ï¼Œä»¥åŠéé£é™©å­ç©ºé—´ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æå‡ºäº†RADARï¼Œè¿™æ˜¯ä¸€ä¸ªå¤šæ™ºèƒ½ä½“åä½œè¯„ä¼°æ¡†æ¶ï¼Œå®ƒé€šè¿‡å››ä¸ªä¸“ä¸šäº’è¡¥è§’è‰²åˆ©ç”¨å¤šè½®è¾©è®ºæœºåˆ¶ï¼Œå¹¶é‡‡ç”¨åŠ¨æ€æ›´æ–°æœºåˆ¶å®ç°é£é™©æ¦‚å¿µåˆ†å¸ƒçš„è‡ªæˆ‘è¿›åŒ–ã€‚è¿™ç§æ–¹æ³•èƒ½å¤Ÿå…¨é¢è¦†ç›–æ˜¾æ€§å’Œéšæ€§é£é™©ï¼ŒåŒæ—¶å‡è½»è¯„ä¼°è€…çš„åè§ã€‚ä¸ºäº†éªŒè¯æˆ‘ä»¬æ¡†æ¶çš„æœ‰æ•ˆæ€§ï¼Œæˆ‘ä»¬æ„å»ºäº†ä¸€ä¸ªåŒ…å«800ä¸ªæŒ‘æˆ˜æ¡ˆä¾‹çš„è¯„ä¼°æ•°æ®é›†ã€‚åœ¨æˆ‘ä»¬å…·æœ‰æŒ‘æˆ˜æ€§çš„æµ‹è¯•é›†å’Œå…¬å…±åŸºå‡†æµ‹è¯•ä¸Šçš„å¤§é‡å®éªŒè¡¨æ˜ï¼ŒRADARåœ¨å¤šä¸ªç»´åº¦ä¸Šæ˜¾è‘—ä¼˜äºåŸºçº¿è¯„ä¼°æ–¹æ³•ï¼ŒåŒ…æ‹¬å‡†ç¡®æ€§ã€ç¨³å®šæ€§å’Œè‡ªæˆ‘è¯„ä¼°é£é™©æ•æ„Ÿæ€§ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œä¸æœ€å¼ºçš„åŸºçº¿è¯„ä¼°æ–¹æ³•ç›¸æ¯”ï¼ŒRADARåœ¨é£é™©è¯†åˆ«å‡†ç¡®æ€§æ–¹é¢æé«˜äº†28.87%ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.25271v4">PDF</a> </p>
<p><strong>Summary</strong><br>å¤§å‹è¯­è¨€æ¨¡å‹çš„å®‰å…¨è¯„ä¼°æ–¹æ³•å­˜åœ¨å±€é™ï¼Œå¦‚è¯„ä¼°è€…åè§å’Œæ£€æµ‹å¤±è´¥ç­‰ã€‚æœ¬æ–‡æå‡ºä¸€ä¸ªç†è®ºæ¡†æ¶ï¼Œå°†æ½œåœ¨é£é™©æ¦‚å¿µç©ºé—´åˆ†è§£ä¸ºä¸‰ä¸ªç›¸äº’ç‹¬ç«‹çš„å­ç©ºé—´ï¼Œå¹¶å¼•å…¥RADARå¤šæ™ºèƒ½ä½“åä½œè¯„ä¼°æ¡†æ¶ï¼Œé€šè¿‡å››è½®äº’è¡¥è§’è‰²å’ŒåŠ¨æ€æ›´æ–°æœºåˆ¶å®ç°é£é™©æ¦‚å¿µåˆ†å¸ƒçš„è‡ªæˆ‘è¿›åŒ–ã€‚è¯¥æ¡†æ¶èƒ½å…¨é¢è¦†ç›–æ˜¾æ€§å’Œéšæ€§é£é™©ï¼Œå¹¶å‡è½»è¯„ä¼°è€…åè§ã€‚å®éªŒè¯æ˜ï¼ŒRADARåœ¨é£é™©è¯†åˆ«å‡†ç¡®æ€§æ–¹é¢è¾ƒæœ€å¼ºåŸºçº¿è¯„ä¼°æ–¹æ³•æé«˜äº†28.87%ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤§å‹è¯­è¨€æ¨¡å‹çš„å®‰å…¨è¯„ä¼°æ–¹æ³•å­˜åœ¨è¯„ä¼°è€…åè§å’Œæ£€æµ‹å¤±è´¥ç­‰å±€é™ã€‚</li>
<li>è®ºæ–‡æå‡ºä¸€ä¸ªç†è®ºæ¡†æ¶ï¼Œå°†é£é™©æ¦‚å¿µç©ºé—´åˆ†è§£ä¸ºä¸‰ä¸ªå­ç©ºé—´ï¼šæ˜¾å¼é£é™©å­ç©ºé—´ã€éšå¼é£é™©å­ç©ºé—´å’Œéé£é™©å­ç©ºé—´ã€‚</li>
<li>å¼•å…¥RADARå¤šæ™ºèƒ½ä½“åä½œè¯„ä¼°æ¡†æ¶ï¼Œé€šè¿‡å››è½®äº’è¡¥è§’è‰²å®ç°å…¨é¢é£é™©è¯„ä¼°ï¼Œå¹¶å‡è½»è¯„ä¼°è€…åè§ã€‚</li>
<li>RADARé‡‡ç”¨åŠ¨æ€æ›´æ–°æœºåˆ¶ï¼Œå®ç°é£é™©æ¦‚å¿µåˆ†å¸ƒçš„è‡ªæˆ‘è¿›åŒ–ã€‚</li>
<li>å®éªŒè¯æ˜ï¼ŒRADARåœ¨é£é™©è¯†åˆ«å‡†ç¡®æ€§æ–¹é¢æ˜¾è‘—æé«˜ã€‚</li>
<li>RADARæ¡†æ¶èƒ½å…¨é¢è¦†ç›–æ˜¾æ€§å’Œéšæ€§é£é™©ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.25271">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-e18ceb104d77808f8e6bcae4c9644d21" align="middle">
<img src="https://picx.zhimg.com/v2-fc0d8d20e8ef3aeff3399a76f7c7e24d" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1><h2 id="Adaptive-Learning-in-Spatial-Agent-Based-Models-for-Climate-Risk-Assessment-A-Geospatial-Framework-with-Evolutionary-Economic-Agents"><a href="#Adaptive-Learning-in-Spatial-Agent-Based-Models-for-Climate-Risk-Assessment-A-Geospatial-Framework-with-Evolutionary-Economic-Agents" class="headerlink" title="Adaptive Learning in Spatial Agent-Based Models for Climate Risk   Assessment: A Geospatial Framework with Evolutionary Economic Agents"></a>Adaptive Learning in Spatial Agent-Based Models for Climate Risk   Assessment: A Geospatial Framework with Evolutionary Economic Agents</h2><p><strong>Authors:Yara Mohajerani</strong></p>
<p>Climate risk assessment requires modelling complex interactions between spatially heterogeneous hazards and adaptive economic systems. We present a novel geospatial agent-based model that integrates climate hazard data with evolutionary learning for economic agents. Our framework combines Mesa-based spatial modelling with CLIMADA climate impact assessment, introducing adaptive learning behaviours that allow firms to evolve strategies for budget allocation, pricing, wages, and risk adaptation through fitness-based selection and mutation. We demonstrate the framework using riverine flood projections under RCP8.5 until 2100, showing that evolutionary adaptation enables firms to converge with baseline (no hazard) production levels after decades of disruption due to climate stress. Our results reveal systemic risks where even agents that are not directly exposed to floods face impacts through supply chain disruptions, with the end-of-century average price of goods 5.6% higher under RCP8.5 compared to the baseline in our illustrative economic network. This open-source framework provides financial institutions and companies with tools to quantify both direct and cascading climate risks while evaluating cost-effective adaptation strategies. </p>
<blockquote>
<p>æ°”å€™é£é™©è¯„ä¼°éœ€è¦æ¨¡æ‹Ÿç©ºé—´å¼‚è´¨å±é™©ä¸è‡ªé€‚åº”ç»æµç³»ç»Ÿä¹‹é—´çš„å¤æ‚äº¤äº’ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°å‹åœ°ç†ç©ºé—´åŸºäºä¸»ä½“çš„æ¨¡å‹ï¼Œè¯¥æ¨¡å‹ç»“åˆäº†æ°”å€™å±é™©æ•°æ®ä¸ç»æµä¸»ä½“çš„è¿›åŒ–å­¦ä¹ ã€‚æˆ‘ä»¬çš„æ¡†æ¶ç»“åˆäº†åŸºäºæ¢…è¨çš„ç©ºé—´å»ºæ¨¡ä¸CLIMADAæ°”å€™å½±å“è¯„ä¼°ï¼Œå¼•å…¥äº†è‡ªé€‚åº”å­¦ä¹ è¡Œä¸ºï¼Œä½¿å…¬å¸èƒ½å¤Ÿé€šè¿‡åŸºäºé€‚åº”åº¦çš„é€‰æ‹©å’Œçªå˜æ¥è¿›åŒ–ç­–ç•¥ï¼Œä¸ºé¢„ç®—åˆ†é…ã€å®šä»·ã€å·¥èµ„å’Œé£é™©é€‚åº”åˆ¶å®šç­–ç•¥ã€‚æˆ‘ä»¬ä»¥RCP8.5æƒ…æ™¯ä¸‹è‡³2100å¹´çš„æ²³æµæ´ªæ°´é¢„æµ‹ä¸ºä¾‹å±•ç¤ºäº†è¯¥æ¡†æ¶çš„åº”ç”¨ï¼Œè¡¨æ˜ç”±äºæ°”å€™å‹åŠ›é€ æˆçš„æ•°åå¹´çš„ç ´ååï¼Œè¿›åŒ–é€‚åº”ä½¿å…¬å¸èƒ½å¤Ÿæ¢å¤åŸºçº¿ï¼ˆæ— å±é™©ï¼‰ç”Ÿäº§æ°´å¹³ã€‚æˆ‘ä»¬çš„ç ”ç©¶ç»“æœæ­ç¤ºäº†ç³»ç»Ÿæ€§é£é™©ï¼Œå³å³ä½¿æœªç›´æ¥é¢ä¸´æ´ªæ°´å¨èƒçš„ä»£ç†äººä¹Ÿé¢ä¸´ç€ä¾›åº”é“¾ä¸­æ–­çš„å½±å“ï¼Œåœ¨æˆ‘ä»¬ä¾‹è¯çš„ç»æµç½‘ç»œä¸­ï¼Œä¸–çºªæœ«å•†å“å¹³å‡ä»·æ ¼ç›¸è¾ƒäºåŸºçº¿åœ¨RCP8.5æƒ…æ™¯ä¸‹é«˜å‡º5.6%ã€‚è¿™ä¸€å¼€æºæ¡†æ¶ä¸ºé‡‘èæœºæ„å’Œå…¬å¸æä¾›äº†å·¥å…·ï¼Œå¯é‡åŒ–ç›´æ¥å’Œè¿é”æ°”å€™é£é™©ï¼ŒåŒæ—¶è¯„ä¼°å…·æœ‰æˆæœ¬æ•ˆç›Šçš„é€‚åº”ç­–ç•¥ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.18633v2">PDF</a> Accepted to Tackling Climate Change with Machine Learning workshop at   NeurIPS 2025. 5 pages, 1 figure. Source code and documentation available at   <a target="_blank" rel="noopener" href="https://github.com/yaramohajerani/spatial-climate-ABM">https://github.com/yaramohajerani/spatial-climate-ABM</a></p>
<p><strong>Summary</strong><br>æ°”å€™é£é™©è¯„ä¼°éœ€è¦æ¨¡æ‹Ÿç©ºé—´å¼‚è´¨æ€§å±å®³ä¸è‡ªé€‚åº”ç»æµç³»ç»Ÿä¹‹é—´çš„å¤æ‚äº¤äº’ä½œç”¨ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°å‹çš„åœ°ç†ç©ºé—´åŸºäºä¸»ä½“çš„æ¨¡å‹ï¼Œè¯¥æ¨¡å‹ç»“åˆäº†æ°”å€™å±å®³æ•°æ®ä¸è¿›åŒ–å­¦ä¹ æœºåˆ¶ä¸ºç»æµä¸»ä½“æ‰€ç”¨ã€‚è¯¥æ¡†æ¶ç»“åˆäº†åŸºäºæ¢…è¨çš„ç©ºé—´æ¨¡å‹å’ŒCLIMADAæ°”å€™å½±å“è¯„ä¼°æŠ€æœ¯ï¼Œå¼•å…¥äº†è‡ªé€‚åº”å­¦ä¹ è¡Œä¸ºï¼Œä½¿å¾—ä¼ä¸šèƒ½å¤Ÿæ¼”åŒ–ç­–ç•¥è¿›è¡Œé¢„ç®—åˆ†é…ã€å®šä»·ã€å·¥èµ„å’Œé£é™©é€‚åº”ï¼Œé€šè¿‡åŸºäºé€‚åº”åº¦çš„é€‰æ‹©å’Œçªå˜æ¥å®ç°ã€‚æˆ‘ä»¬ä»¥RCP8.5æƒ…æ™¯ä¸‹çš„æ²³æµæ´ªæ°´é¢„æµ‹ä¸ºä¾‹ï¼Œå±•ç¤ºäº†è¿›åŒ–é€‚åº”ä½¿ä¼ä¸šåœ¨å‡ åå¹´çš„æ°”å€™å‹åŠ›å¹²æ‰°åèƒ½å¤Ÿæ¢å¤åŸºçº¿ï¼ˆæ— å±å®³ï¼‰ç”Ÿäº§æ°´å¹³çš„èƒ½åŠ›ã€‚æˆ‘ä»¬çš„ç ”ç©¶æ­ç¤ºäº†ç³»ç»Ÿæ€§é£é™©ï¼Œå³ä½¿åœ¨æ´ªæ°´æœªç›´æ¥å†²å‡»çš„å‚ä¸è€…ä¹Ÿä¼šå› ä¾›åº”é“¾ä¸­æ–­è€Œå—åˆ°å½±å“ï¼Œåˆ°æœ¬ä¸–çºªæœ«ï¼Œåœ¨æˆ‘ä»¬çš„æ¨¡æ‹Ÿç»æµç½‘ç»œä¸­ï¼Œå•†å“å¹³å‡ä»·æ ¼è¾ƒåŸºçº¿é«˜å‡º5.6%ã€‚è¿™ä¸€å¼€æºæ¡†æ¶ä¸ºé‡‘èæœºæ„å’Œä¼ä¸šæä¾›äº†é‡åŒ–ç›´æ¥å’Œè¿é”æ°”å€™é£é™©çš„å·¥å…·ï¼ŒåŒæ—¶è¯„ä¼°æˆæœ¬æ•ˆç›Šé«˜çš„é€‚åº”ç­–ç•¥ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æ°”å€™é£é™©è¯„ä¼°éœ€æ¨¡æ‹Ÿç©ºé—´å¼‚è´¨æ€§å±å®³ä¸è‡ªé€‚åº”ç»æµç³»ç»Ÿçš„å¤æ‚äº¤äº’ã€‚</li>
<li>æ–°å‹åœ°ç†ç©ºé—´åŸºäºä¸»ä½“çš„æ¨¡å‹ç»“åˆäº†æ°”å€™å±å®³æ•°æ®ä¸è¿›åŒ–å­¦ä¹ æœºåˆ¶ã€‚</li>
<li>æ¨¡å‹ç»“åˆäº†ç©ºé—´å»ºæ¨¡å’Œæ°”å€™å½±å“è¯„ä¼°æŠ€æœ¯ï¼Œå¼•å…¥è‡ªé€‚åº”å­¦ä¹ è¡Œä¸ºåŠ©ä¼ä¸šé€‚åº”é£é™©ã€‚</li>
<li>åœ¨æ´ªæ°´é¢„æµ‹æ¡ˆä¾‹ä¸­ï¼Œå±•ç¤ºè¿›åŒ–é€‚åº”ä½¿ä¼ä¸šåœ¨é•¿æœŸå¹²æ‰°åæ¢å¤ç”Ÿäº§æ°´å¹³çš„èƒ½åŠ›ã€‚</li>
<li>ç ”ç©¶æ­ç¤ºäº†ç³»ç»Ÿæ€§é£é™©çš„è¿é”ååº”ï¼Œéç›´æ¥å—å®³çš„å‚ä¸è€…ä¹Ÿå¯èƒ½å—å½±å“ã€‚</li>
<li>æ¨¡æ‹Ÿç½‘ç»œåˆ°æœ¬ä¸–çºªæœ«å•†å“å¹³å‡ä»·æ ¼è¾ƒåŸºçº¿ä¸Šå‡äº†5.6%ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.18633">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-297021c86eed5662ebc51ec3fd003f48" align="middle">
<img src="https://picx.zhimg.com/v2-20ed668ab016cd011921aa03d8a35a15" align="middle">
</details>


<h1 id="-9"><a href="#-9" class="headerlink" title=""></a></h1><h2 id="Multi-Agent-Reinforcement-Learning-for-Task-Offloading-in-Wireless-Edge-Networks"><a href="#Multi-Agent-Reinforcement-Learning-for-Task-Offloading-in-Wireless-Edge-Networks" class="headerlink" title="Multi-Agent Reinforcement Learning for Task Offloading in Wireless Edge   Networks"></a>Multi-Agent Reinforcement Learning for Task Offloading in Wireless Edge   Networks</h2><p><strong>Authors:Andrea Fox, Francesco De Pellegrini, Eitan Altman</strong></p>
<p>In edge computing systems, autonomous agents must make fast local decisions while competing for shared resources. Existing MARL methods often resume to centralized critics or frequent communication, which fail under limited observability and communication constraints. We propose a decentralized framework in which each agent solves a constrained Markov decision process (CMDP), coordinating implicitly through a shared constraint vector. For the specific case of offloading, e.g., constraints prevent overloading shared server resources. Coordination constraints are updated infrequently and act as a lightweight coordination mechanism. They enable agents to align with global resource usage objectives but require little direct communication. Using safe reinforcement learning, agents learn policies that meet both local and global goals. We establish theoretical guarantees under mild assumptions and validate our approach experimentally, showing improved performance over centralized and independent baselines, especially in large-scale settings. </p>
<blockquote>
<p>åœ¨è¾¹ç¼˜è®¡ç®—ç³»ç»Ÿä¸­ï¼Œè‡ªä¸»ä»£ç†å¿…é¡»å¿«é€Ÿåšå‡ºæœ¬åœ°å†³ç­–ï¼ŒåŒæ—¶ç«äº‰å…±äº«èµ„æºã€‚ç°æœ‰çš„å¤šä»£ç†å¼ºåŒ–å­¦ä¹ æ–¹æ³•é€šå¸¸ä¾èµ–äºé›†ä¸­è¯„è®ºå®¶æˆ–é¢‘ç¹é€šä¿¡ï¼Œè¿™åœ¨è§‚å¯Ÿæ€§å’Œé€šä¿¡çº¦æŸæœ‰é™çš„æƒ…å†µä¸‹ä¼šå¤±æ•ˆã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§åˆ†æ•£å¼æ¡†æ¶ï¼Œæ¯ä¸ªä»£ç†åœ¨è¯¥æ¡†æ¶ä¸­è§£å†³ä¸€ä¸ªçº¦æŸé©¬å°”å¯å¤«å†³ç­–è¿‡ç¨‹ï¼ˆCMDPï¼‰ï¼Œé€šè¿‡å…±äº«çº¦æŸå‘é‡è¿›è¡Œéšæ€§åè°ƒã€‚ä»¥ä»»åŠ¡å¸è½½ä¸ºä¾‹ï¼Œçº¦æŸå¯ä»¥é˜²æ­¢è¿‡è½½å…±äº«æœåŠ¡å™¨èµ„æºã€‚åè°ƒçº¦æŸæ›´æ–°ä¸é¢‘ç¹ï¼Œä½œä¸ºä¸€ç§è½»é‡çº§åè°ƒæœºåˆ¶å‘æŒ¥ä½œç”¨ã€‚å®ƒä»¬ä½¿ä»£ç†èƒ½å¤Ÿä¸å…¨å±€èµ„æºä½¿ç”¨ç›®æ ‡ä¿æŒä¸€è‡´ï¼Œä½†å‡ ä¹ä¸éœ€è¦ç›´æ¥é€šä¿¡ã€‚é€šè¿‡å®‰å…¨å¼ºåŒ–å­¦ä¹ ï¼Œä»£ç†å­¦ä¹ æ»¡è¶³æœ¬åœ°å’Œå…¨å±€ç›®æ ‡çš„ç­–ç•¥ã€‚æˆ‘ä»¬åœ¨æ¸©å’Œçš„å‡è®¾ä¸‹å»ºç«‹äº†ç†è®ºä¿è¯ï¼Œå¹¶é€šè¿‡å®éªŒéªŒè¯äº†æˆ‘ä»¬æ–¹æ³•çš„æœ‰æ•ˆæ€§ï¼Œç‰¹åˆ«æ˜¯åœ¨å¤§è§„æ¨¡è®¾ç½®ä¸­ç›¸æ¯”é›†ä¸­å¼å’Œç‹¬ç«‹åŸºçº¿æœ‰æ˜¾è‘—æ”¹è¿›è¡¨ç°ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.01257v2">PDF</a> Oral presentation at AI4NextG @ NeurIPSâ€™25 Workshop</p>
<p><strong>Summary</strong></p>
<p>åœ¨è¾¹ç¼˜è®¡ç®—ç³»ç»Ÿä¸­ï¼Œè‡ªä¸»ä»£ç†éœ€è¦å¿«é€Ÿåšå‡ºæœ¬åœ°å†³ç­–å¹¶ç«äº‰å…±äº«èµ„æºã€‚ç°æœ‰æ–¹æ³•å¾€å¾€ä¾èµ–äºé›†ä¸­æ‰¹è¯„æˆ–é¢‘ç¹é€šä¿¡ï¼Œè¿™åœ¨æœ‰é™çš„è§‚å¯ŸåŠ›å’Œé€šä¿¡çº¦æŸä¸‹ä¼šå¤±æ•ˆã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªå»ä¸­å¿ƒåŒ–çš„æ¡†æ¶ï¼Œå…¶ä¸­æ¯ä¸ªä»£ç†è§£å†³çº¦æŸé©¬å°”å¯å¤«å†³ç­–è¿‡ç¨‹ï¼ˆCMDPï¼‰ï¼Œå¹¶é€šè¿‡å…±äº«çº¦æŸå‘é‡è¿›è¡Œéšæ€§åè°ƒã€‚å¯¹äºå¸è½½ç­‰ç‰¹å®šæƒ…å†µï¼Œçº¦æŸå¯ä»¥é˜²æ­¢è¿‡è½½å…±äº«æœåŠ¡å™¨èµ„æºã€‚åè°ƒçº¦æŸæ›´æ–°ä¸é¢‘ç¹ï¼Œä½œä¸ºè½»é‡çº§åè°ƒæœºåˆ¶å‘æŒ¥ä½œç”¨ã€‚å®ƒä»¬ä½¿ä»£ç†èƒ½å¤Ÿä¸å…¨å±€èµ„æºä½¿ç”¨ç›®æ ‡ä¿æŒä¸€è‡´ï¼Œä½†éœ€è¦å¾ˆå°‘çš„ç›´æ¥é€šä¿¡ã€‚åˆ©ç”¨å®‰å…¨å¼ºåŒ–å­¦ä¹ ï¼Œä»£ç†å­¦ä¹ æ—¢æ»¡è¶³æœ¬åœ°åˆæ»¡è¶³å…¨çƒç›®æ ‡çš„ç­–ç•¥ã€‚åœ¨æ¸©å’Œçš„å‡è®¾ä¸‹ï¼Œæˆ‘ä»¬å»ºç«‹äº†ç†è®ºä¿è¯å¹¶é€šè¿‡å®éªŒéªŒè¯äº†æˆ‘ä»¬æ–¹æ³•çš„æœ‰æ•ˆæ€§ï¼Œç›¸è¾ƒäºé›†ä¸­å’Œç‹¬ç«‹åŸºçº¿åœ¨å¤§è§„æ¨¡ç¯å¢ƒä¸‹è¡¨ç°å‡ºæ›´å¥½çš„æ€§èƒ½ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>è¾¹ç¼˜è®¡ç®—ç³»ç»Ÿä¸­è‡ªä¸»ä»£ç†éœ€è¦å¿«é€Ÿåšå‡ºæœ¬åœ°å†³ç­–å¹¶ç«äº‰å…±äº«èµ„æºã€‚</li>
<li>ç°æœ‰æ–¹æ³•ä¾èµ–äºé›†ä¸­æ‰¹è¯„æˆ–é¢‘ç¹é€šä¿¡ï¼Œè¿™åœ¨æœ‰é™è§‚å¯ŸåŠ›å’Œé€šä¿¡çº¦æŸä¸‹ä¸é€‚ç”¨ã€‚</li>
<li>æå‡ºäº†ä¸€ç§å»ä¸­å¿ƒåŒ–çš„æ¡†æ¶ï¼Œå…¶ä¸­ä»£ç†é€šè¿‡è§£å†³çº¦æŸé©¬å°”å¯å¤«å†³ç­–è¿‡ç¨‹ï¼ˆCMDPï¼‰è¿›è¡Œéšæ€§åè°ƒã€‚</li>
<li>é€šè¿‡å…±äº«çº¦æŸå‘é‡ï¼Œä»£ç†å¯ä»¥åœ¨ä¸éœ€è¦é¢‘ç¹æ›´æ–°å’Œç›´æ¥é€šä¿¡çš„æƒ…å†µä¸‹åè°ƒè¡ŒåŠ¨ã€‚</li>
<li>çº¦æŸå¯ä»¥é˜²æ­¢è¿‡è½½å…±äº«æœåŠ¡å™¨èµ„æºï¼Œä¾‹å¦‚åœ¨å¸è½½åœºæ™¯ä¸­ã€‚</li>
<li>åˆ©ç”¨å®‰å…¨å¼ºåŒ–å­¦ä¹ ï¼Œä»£ç†å­¦ä¹ æ»¡è¶³æœ¬åœ°å’Œå…¨å±€ç›®æ ‡çš„ç­–ç•¥ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.01257">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-673be4102652521a77e4c91653a615a3" align="middle">
<img src="https://picx.zhimg.com/v2-ea07f66836e97d81373c6e864d40a8f7" align="middle">
</details>


<h1 id="-10"><a href="#-10" class="headerlink" title=""></a></h1><h2 id="Debate-or-Vote-Which-Yields-Better-Decisions-in-Multi-Agent-Large-Language-Models"><a href="#Debate-or-Vote-Which-Yields-Better-Decisions-in-Multi-Agent-Large-Language-Models" class="headerlink" title="Debate or Vote: Which Yields Better Decisions in Multi-Agent Large   Language Models?"></a>Debate or Vote: Which Yields Better Decisions in Multi-Agent Large   Language Models?</h2><p><strong>Authors:Hyeong Kyu Choi, Xiaojin Zhu, Sharon Li</strong></p>
<p>Multi-Agent Debate~(MAD) has emerged as a promising paradigm for improving the performance of large language models through collaborative reasoning. Despite recent advances, the key factors driving MADâ€™s effectiveness remain unclear. In this work, we disentangle MAD into two key componentsâ€“Majority Voting and inter-agent Debateâ€“and assess their respective contributions. Through extensive experiments across seven NLP benchmarks, we find that Majority Voting alone accounts for most of the performance gains typically attributed to MAD. To explain this, we propose a theoretical framework that models debate as a stochastic process. We prove that it induces a martingale over agentsâ€™ belief trajectories, implying that debate alone does not improve expected correctness. Guided by these insights, we demonstrate that targeted interventions, by biasing the belief update toward correction, can meaningfully enhance debate effectiveness. Overall, our findings suggest that while MAD has potential, simple ensembling methods remain strong and more reliable alternatives in many practical settings. Code is released in <a target="_blank" rel="noopener" href="https://github.com/deeplearning-wisc/debate-or-vote">https://github.com/deeplearning-wisc/debate-or-vote</a>. </p>
<blockquote>
<p>å¤šæ™ºèƒ½ä½“è¾©è®ºï¼ˆMADï¼‰ä½œä¸ºä¸€ç§é€šè¿‡åä½œæ¨ç†æé«˜å¤§å‹è¯­è¨€æ¨¡å‹æ€§èƒ½çš„èŒƒå¼ï¼Œå·²ç»å±•ç°å‡ºå·¨å¤§çš„æ½œåŠ›ã€‚å°½ç®¡æœ€è¿‘æœ‰æ‰€è¿›å±•ï¼Œä½†é©±åŠ¨MADæœ‰æ•ˆæ€§çš„å…³é”®å› ç´ ä»ç„¶ä¸æ¸…æ¥šã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬å°†MADåˆ†è§£ä¸ºä¸¤ä¸ªå…³é”®ç»„æˆéƒ¨åˆ†â€”â€”å¤šæ•°æŠ•ç¥¨å’Œæ™ºèƒ½ä½“é—´çš„è¾©è®ºï¼Œå¹¶è¯„ä¼°å„è‡ªçš„è´¡çŒ®ã€‚é€šè¿‡ä¸ƒä¸ªNLPåŸºå‡†çš„å¹¿æ³›å®éªŒï¼Œæˆ‘ä»¬å‘ç°ä»…å¤šæ•°æŠ•ç¥¨å°±å åˆ°äº†é€šå¸¸å½’å› äºMADçš„å¤§éƒ¨åˆ†æ€§èƒ½æå‡ã€‚ä¸ºäº†è§£é‡Šè¿™ä¸€ç‚¹ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªå°†è¾©è®ºå»ºæ¨¡ä¸ºéšæœºè¿‡ç¨‹çš„ç†è®ºæ¡†æ¶ã€‚æˆ‘ä»¬è¯æ˜äº†å®ƒåœ¨æ™ºèƒ½ä½“çš„ä¿¡å¿µè½¨è¿¹ä¸Šå¼•å‘äº†ä¸€ä¸ªéšæœºæ¼«æ­¥æ•ˆåº”ï¼Œè¿™æ„å‘³ç€è¾©è®ºæœ¬èº«ä¸ä¼šæé«˜é¢„æœŸçš„å‡†ç¡®æ€§ã€‚åœ¨è¿™äº›è§è§£çš„æŒ‡å¯¼ä¸‹ï¼Œæˆ‘ä»¬è¯æ˜é€šè¿‡æœç€ä¿®æ­£æ–¹å‘å¼•å¯¼ä¿¡å¿µæ›´æ–°å¯ä»¥æœ‰é’ˆå¯¹æ€§åœ°è¿›è¡Œå¹²é¢„ï¼Œè¿™å¯ä»¥æ˜¾è‘—å¢å¼ºè¾©è®ºçš„æœ‰æ•ˆæ€§ã€‚æ€»ä½“è€Œè¨€ï¼Œæˆ‘ä»¬çš„ç ”ç©¶ç»“æœè¡¨æ˜ï¼Œå°½ç®¡MADå…·æœ‰æ½œåŠ›ï¼Œä½†åœ¨è®¸å¤šå®é™…åº”ç”¨åœºæ™¯ä¸­ï¼Œç®€å•çš„é›†æˆæ–¹æ³•ä»ç„¶æ˜¯æ›´å¼ºå’Œæ›´å¯é çš„æ›¿ä»£æ–¹æ¡ˆã€‚ä»£ç å·²åœ¨ <a target="_blank" rel="noopener" href="https://github.com/deeplearning-wisc/debate-or-vote">https://github.com/deeplearning-wisc/debate-or-vote</a> ä¸­å‘å¸ƒã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.17536v2">PDF</a> NeurIPS 2025 Spotlight</p>
<p><strong>Summary</strong><br>å¤šæ™ºèƒ½ä½“è¾©è®ºï¼ˆMADï¼‰ä½œä¸ºæé«˜å¤§å‹è¯­è¨€æ¨¡å‹æ€§èƒ½çš„ä¸€ç§æœ‰å‰æ™¯çš„èŒƒå¼ï¼Œé€šè¿‡åä½œæ¨ç†å±•ç°å‡ºäº†å·¨å¤§çš„æ½œåŠ›ã€‚ç„¶è€Œï¼Œå°½ç®¡è¿‘æœŸæœ‰æ‰€è¿›å±•ï¼Œä½†MADçš„æœ‰æ•ˆå…³é”®å› ç´ ä»ä¸æ˜ç¡®ã€‚æœ¬ç ”ç©¶å°†MADåˆ†è§£ä¸ºä¸¤ä¸ªå…³é”®ç»„æˆéƒ¨åˆ†â€”â€”å¤šæ•°æŠ•ç¥¨å’Œæ™ºèƒ½ä½“é—´çš„è¾©è®ºï¼Œå¹¶è¯„ä¼°äº†å„è‡ªçš„è´¡çŒ®ã€‚é€šè¿‡ä¸ƒä¸ªNLPåŸºå‡†çš„å¹¿æ³›å®éªŒå‘ç°ï¼Œå¤šæ•°æŠ•ç¥¨æœ¬èº«å åˆ°äº†é€šå¸¸å½’äºMADçš„å¤§éƒ¨åˆ†æ€§èƒ½æå‡ã€‚ä¸ºè§£é‡Šæ­¤ç°è±¡ï¼Œæå‡ºäº†ä¸€ä¸ªå°†è¾©è®ºè§†ä¸ºéšæœºè¿‡ç¨‹çš„ç†è®ºæ¡†æ¶ã€‚è¯æ˜äº†è¾©è®ºä¼šå¼•å‘æ™ºèƒ½ä½“è½¨è¿¹ä¸Šçš„éšæœºæ¼«æ­¥æ•ˆåº”ï¼Œè¿™æ„å‘³ç€è¾©è®ºæœ¬èº«å¹¶ä¸æé«˜é¢„æœŸçš„å‡†ç¡®æ€§ã€‚åœ¨è¿™äº›è§è§£çš„æŒ‡å¯¼ä¸‹ï¼Œé€šè¿‡å¼•å¯¼ä¿¡å¿µæ›´æ–°åå‘æ ¡æ­£ï¼Œå¯ä»¥æ˜¾è‘—æé«˜è¾©è®ºçš„æœ‰æ•ˆæ€§ã€‚æ€»ä½“è€Œè¨€ï¼Œè™½ç„¶MADå…·æœ‰æ½œåŠ›ï¼Œä½†åœ¨è®¸å¤šå®é™…åº”ç”¨åœºæ™¯ä¸­ï¼Œç®€å•çš„é›†æˆæ–¹æ³•ä»ç„¶æ˜¯å¼ºå¤§ä¸”æ›´å¯é çš„æ›¿ä»£æ–¹æ¡ˆã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤šæ™ºèƒ½ä½“è¾©è®ºï¼ˆMADï¼‰æ˜¯ä¸€ç§æé«˜å¤§å‹è¯­è¨€æ¨¡å‹æ€§èƒ½çš„æ–¹æ³•ã€‚</li>
<li>MADçš„å…³é”®ç»„ä»¶åŒ…æ‹¬å¤šæ•°æŠ•ç¥¨å’Œæ™ºèƒ½ä½“é—´çš„è¾©è®ºã€‚</li>
<li>å¤šæ•°æŠ•ç¥¨æ˜¯æ€§èƒ½æå‡çš„ä¸»è¦æ¥æºã€‚</li>
<li>è¾©è®ºè¢«è§†ä¸ºéšæœºè¿‡ç¨‹ï¼Œè‡ªèº«å¹¶ä¸èƒ½æé«˜é¢„æœŸçš„å‡†ç¡®æ€§ã€‚</li>
<li>é€šè¿‡ç†è®ºæ¡†æ¶æ­ç¤ºäº†è¾©è®ºåœ¨æ™ºèƒ½ä½“è½¨è¿¹ä¸Šçš„éšæœºæ¼«æ­¥æ•ˆåº”ã€‚</li>
<li>é€šè¿‡å¼•å¯¼ä¿¡å¿µæ›´æ–°åå‘æ ¡æ­£ï¼Œå¯ä»¥æ˜¾è‘—æé«˜è¾©è®ºçš„æœ‰æ•ˆæ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.17536">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-9cfb646dbbc4edf6312387cd94143d93" align="middle">
<img src="https://picx.zhimg.com/v2-00dac86afa1515663eb80676f1875489" align="middle">
<img src="https://picx.zhimg.com/v2-02c6ab0a7e7dcf054e8b11a15b7cd892" align="middle">
<img src="https://picx.zhimg.com/v2-5457c90541af34a917882417c6c4dcca" align="middle">
<img src="https://picx.zhimg.com/v2-af2c40dbc2a8f463975706a682f9c48f" align="middle">
</details>


<h1 id="-11"><a href="#-11" class="headerlink" title=""></a></h1><h2 id="Prover-Agent-An-Agent-Based-Framework-for-Formal-Mathematical-Proofs"><a href="#Prover-Agent-An-Agent-Based-Framework-for-Formal-Mathematical-Proofs" class="headerlink" title="Prover Agent: An Agent-Based Framework for Formal Mathematical Proofs"></a>Prover Agent: An Agent-Based Framework for Formal Mathematical Proofs</h2><p><strong>Authors:Kaito Baba, Chaoran Liu, Shuhei Kurita, Akiyoshi Sannai</strong></p>
<p>We present Prover Agent, a novel AI agent for automated theorem proving that integrates large language models (LLMs) with a formal proof assistant, Lean. Prover Agent coordinates an informal reasoning LLM, a formal prover model, and feedback from Lean while also generating auxiliary lemmas. These auxiliary lemmas are not limited to subgoals in the formal proof but can also include special cases or potentially useful facts derived from the assumptions, which help in discovering a viable proof strategy. It achieves an 88.1% success rate on the MiniF2F benchmark, establishing a new state-of-the-art among methods using small language models (SLMs) with a much lower sample budget than previous approaches. We also present theoretical analyses and case studies that illustrate how these generated lemmas contribute to solving challenging problems. Our code is publicly available at: <a target="_blank" rel="noopener" href="https://github.com/kAIto47802/Prover-Agent">https://github.com/kAIto47802/Prover-Agent</a>. </p>
<blockquote>
<p>æˆ‘ä»¬ä»‹ç»äº†Prover Agentï¼Œè¿™æ˜¯ä¸€ä¸ªç”¨äºè‡ªåŠ¨åŒ–å®šç†è¯æ˜çš„æ–°å‹äººå·¥æ™ºèƒ½ä»£ç†ï¼Œå®ƒå°†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä¸å½¢å¼åŒ–è¯æ˜åŠ©æ‰‹Leanè¿›è¡Œäº†é›†æˆã€‚Prover Agentåè°ƒéæ­£å¼æ¨ç†LLMã€å½¢å¼åŒ–è¯æ˜æ¨¡å‹ä»¥åŠæ¥è‡ªLeançš„åé¦ˆï¼ŒåŒæ—¶ç”Ÿæˆè¾…åŠ©å¼•ç†ã€‚è¿™äº›è¾…åŠ©å¼•ç†ä¸ä»…é™äºå½¢å¼è¯æ˜ä¸­çš„å­ç›®æ ‡ï¼Œè¿˜å¯ä»¥åŒ…æ‹¬ä»å‡è®¾ä¸­å¾—å‡ºçš„ç‰¹æ®Šæƒ…å†µæˆ–å¯èƒ½æœ‰ç”¨çš„äº‹å®ï¼Œæœ‰åŠ©äºå‘ç°å¯è¡Œçš„è¯æ˜ç­–ç•¥ã€‚å®ƒåœ¨MiniF2FåŸºå‡†æµ‹è¯•ä¸Šè¾¾åˆ°äº†88.1%çš„æˆåŠŸç‡ï¼Œåœ¨é‡‡ç”¨å°å‹è¯­è¨€æ¨¡å‹ï¼ˆSLMï¼‰çš„æ–¹æ³•ä¸­å»ºç«‹äº†æœ€æ–° state-of-the-artï¼Œæ ·æœ¬é¢„ç®—è¿œä½äºä»¥å‰çš„æ–¹æ³•ã€‚æˆ‘ä»¬è¿˜é€šè¿‡ç†è®ºåˆ†æå’Œæ¡ˆä¾‹ç ”ç©¶æ¥è¯´æ˜è¿™äº›ç”Ÿæˆçš„å¼•ç†å¦‚ä½•è§£å†³å…·æœ‰æŒ‘æˆ˜æ€§çš„é—®é¢˜ã€‚æˆ‘ä»¬çš„ä»£ç å…¬å¼€å¯ç”¨ï¼š<a target="_blank" rel="noopener" href="https://github.com/kAIto47802/Prover-Agent%E3%80%82">https://github.com/kAIto47802/Prover-Agentã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.19923v4">PDF</a> 36 pages, 3 figures</p>
<p><strong>æ‘˜è¦</strong></p>
<p>æˆ‘ä»¬æ¨å‡ºäº†ä¸€æ¬¾åä¸ºProver Agentçš„æ–°å‹å®šç†è¯æ˜AIä»£ç†ï¼Œå®ƒå°†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä¸å½¢å¼åŒ–è¯æ˜åŠ©æ‰‹Leanè¿›è¡Œäº†é›†æˆã€‚Prover Agentåè°ƒéæ­£å¼æ¨ç†LLMã€å½¢å¼åŒ–è¯æ˜æ¨¡å‹ä»¥åŠæ¥è‡ªLeançš„åé¦ˆï¼ŒåŒæ—¶ç”Ÿæˆè¾…åŠ©å¼•ç†ã€‚è¿™äº›è¾…åŠ©å¼•ç†ä¸ä»…é™äºå½¢å¼è¯æ˜ä¸­çš„å­ç›®æ ‡ï¼Œè¿˜å¯ä»¥åŒ…æ‹¬ä»å‡è®¾ä¸­å¾—å‡ºçš„ç‰¹æ®Šæƒ…å†µæˆ–å¯èƒ½æœ‰ç”¨çš„äº‹å®ï¼Œæœ‰åŠ©äºå‘ç°å¯è¡Œçš„è¯æ˜ç­–ç•¥ã€‚åœ¨MiniF2FåŸºå‡†æµ‹è¯•ä¸­ï¼Œå®ƒè¾¾åˆ°äº†88.1%çš„æˆåŠŸç‡ï¼Œåœ¨é‡‡ç”¨å°å‹è¯­è¨€æ¨¡å‹ï¼ˆSLMï¼‰çš„æ–¹æ³•ä¸­å»ºç«‹äº†æœ€æ–° state-of-the-artï¼Œå¹¶ä¸”æ ·æœ¬é¢„ç®—è¿œä½äºä¹‹å‰çš„æ–¹æ³•ã€‚æˆ‘ä»¬è¿˜æä¾›äº†ç†è®ºåˆ†æå’Œæ¡ˆä¾‹ç ”ç©¶ï¼Œè¯´æ˜è¿™äº›ç”Ÿæˆçš„å¼•ç†å¦‚ä½•è§£å†³å¤æ‚é—®é¢˜ã€‚æˆ‘ä»¬çš„ä»£ç å¯åœ¨ï¼š<a target="_blank" rel="noopener" href="https://github.com/kAIto47802/Prover-Agent%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/kAIto47802/Prover-Agentæ‰¾åˆ°ã€‚</a></p>
<p><strong>è¦ç‚¹æŒæ¡</strong></p>
<ol>
<li>Prover Agentæ˜¯ä¸€ä¸ªç»“åˆäº†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å’Œå½¢å¼åŒ–è¯æ˜åŠ©æ‰‹Leançš„æ–°å‹å®šç†è¯æ˜AIä»£ç†ã€‚</li>
<li>Prover Agentèƒ½å¤Ÿåè°ƒéæ­£å¼æ¨ç†LLMã€å½¢å¼åŒ–è¯æ˜æ¨¡å‹ä»¥åŠæ¥è‡ªLeançš„åé¦ˆã€‚</li>
<li>Prover Agentèƒ½ç”Ÿæˆè¾…åŠ©å¼•ç†ï¼Œè¿™äº›å¼•ç†ä¸ä»…ç”¨äºè§£å†³å½¢å¼è¯æ˜ä¸­çš„å­ç›®æ ‡ï¼Œè¿˜èƒ½åŒ…æ‹¬ä»å‡è®¾ä¸­å¾—å‡ºçš„ç‰¹æ®Šæƒ…å†µæˆ–æ½œåœ¨æœ‰ç”¨çš„ä¿¡æ¯ï¼Œå¸®åŠ©å¯»æ‰¾å¯è¡Œçš„è¯æ˜ç­–ç•¥ã€‚</li>
<li>Prover Agentåœ¨MiniF2FåŸºå‡†æµ‹è¯•ä¸­çš„æˆåŠŸç‡ä¸º88.1%ï¼Œåœ¨é‡‡ç”¨å°å‹è¯­è¨€æ¨¡å‹çš„æ–¹æ³•ä¸­å…·æœ‰æœ€æ–° state-of-the-art æ€§èƒ½ã€‚</li>
<li>Prover Agentçš„æ ·æœ¬é¢„ç®—è¿œä½äºä¹‹å‰çš„æ–¹æ³•ã€‚</li>
<li>æä¾›äº†ç†è®ºåˆ†æå’Œæ¡ˆä¾‹ç ”ç©¶ï¼Œä»¥å±•ç¤ºç”Ÿæˆçš„å¼•ç†å¦‚ä½•å¸®åŠ©è§£å†³å¤æ‚é—®é¢˜ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.19923">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-16924d72ddd5452c4b6ed73e92f6f7d6" align="middle">
<img src="https://picx.zhimg.com/v2-758362019113818027b4a946656af50a" align="middle">
</details>


<h1 id="-12"><a href="#-12" class="headerlink" title=""></a></h1><h2 id="Lessons-Learned-A-Multi-Agent-Framework-for-Code-LLMs-to-Learn-and-Improve"><a href="#Lessons-Learned-A-Multi-Agent-Framework-for-Code-LLMs-to-Learn-and-Improve" class="headerlink" title="Lessons Learned: A Multi-Agent Framework for Code LLMs to Learn and   Improve"></a>Lessons Learned: A Multi-Agent Framework for Code LLMs to Learn and   Improve</h2><p><strong>Authors:Yuanzhe Liu, Ryan Deng, Tim Kaler, Xuhao Chen, Charles E. Leiserson, Yao Ma, Jie Chen</strong></p>
<p>Recent studies show that LLMs possess different skills and specialize in different tasks. In fact, we observe that their varied performance occur in several levels of granularity. For example, in the code optimization task, code LLMs excel at different optimization categories and no one dominates others. This observation prompts the question of how one leverages multiple LLM agents to solve a coding problem without knowing their complementary strengths a priori. We argue that a team of agents can learn from each otherâ€™s successes and failures so as to improve their own performance. Thus, a lesson is the knowledge produced by an agent and passed on to other agents in the collective solution process. We propose a lesson-based collaboration framework, design the lesson solicitationâ€“bankingâ€“selection mechanism, and demonstrate that a team of small LLMs with lessons learned can outperform a much larger LLM and other multi-LLM collaboration methods. </p>
<blockquote>
<p>æœ€è¿‘çš„ç ”ç©¶è¡¨æ˜ï¼Œå¤§å‹è¯­è¨€æ¨¡å‹æ‹¥æœ‰ä¸åŒçš„æŠ€èƒ½ï¼Œæ“…é•¿ä¸åŒçš„ä»»åŠ¡ã€‚å®é™…ä¸Šï¼Œæˆ‘ä»¬è§‚å¯Ÿåˆ°å®ƒä»¬åœ¨å¤šä¸ªç²’åº¦å±‚é¢æœ‰ä¸åŒçš„è¡¨ç°ã€‚ä¾‹å¦‚ï¼Œåœ¨ä»£ç ä¼˜åŒ–ä»»åŠ¡ä¸­ï¼Œä»£ç å¤§å‹è¯­è¨€æ¨¡å‹åœ¨ä¸åŒä¼˜åŒ–ç±»åˆ«ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œå¹¶æ²¡æœ‰ä¸€ä¸ªæ¨¡å‹èƒ½å¤Ÿå®Œå…¨è¶…è¶Šå…¶ä»–æ¨¡å‹ã€‚è¿™ä¸€è§‚å¯Ÿå¼•å‘äº†ä¸€ä¸ªé—®é¢˜ï¼šå¦‚ä½•åˆ©ç”¨å¤šä¸ªå¤§å‹è¯­è¨€æ¨¡å‹ä»£ç†æ¥è§£å†³ç¼–ç é—®é¢˜ï¼Œè€Œä¸äº‹å…ˆäº†è§£å®ƒä»¬çš„äº’è¡¥ä¼˜åŠ¿ã€‚æˆ‘ä»¬è®¤ä¸ºï¼Œä»£ç†å›¢é˜Ÿå¯ä»¥ä»å½¼æ­¤çš„æˆåŠŸå’Œå¤±è´¥ä¸­å­¦ä¹ ï¼Œä»¥æé«˜è‡ªå·±çš„è¡¨ç°ã€‚å› æ­¤ï¼Œä¸€è¯¾æ˜¯ä»£ç†åœ¨é›†ä½“è§£å†³æ–¹æ¡ˆè¿‡ç¨‹ä¸­äº§ç”Ÿçš„çŸ¥è¯†ï¼Œå¹¶ä¼ é€’ç»™å…¶ä»–ä»£ç†ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªåŸºäºè¯¾ç¨‹çš„åˆä½œæ¡†æ¶ï¼Œè®¾è®¡äº†è¯¾ç¨‹è¯·æ±‚-å­˜å‚¨-é€‰æ‹©æœºåˆ¶ï¼Œå¹¶è¯æ˜äº†ä¸€ä¸ªç”±å°å‹å¤§å‹è¯­è¨€æ¨¡å‹ç»„æˆçš„å›¢é˜Ÿï¼Œé€šè¿‡è¯¾ç¨‹å­¦ä¹ ï¼Œå¯ä»¥è¶…è¶Šä¸€ä¸ªæ›´å¤§çš„å¤§å‹è¯­è¨€æ¨¡å‹å’Œå…¶ä»–å¤šå¤§å‹è¯­è¨€æ¨¡å‹åä½œæ–¹æ³•çš„è¡¨ç°ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.23946v2">PDF</a> NeurIPS 2025. Code is available at   <a target="_blank" rel="noopener" href="https://github.com/MITIBM-FastCoder/LessonL">https://github.com/MITIBM-FastCoder/LessonL</a></p>
<p><strong>Summary</strong></p>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å¤šç§ä»»åŠ¡ä¸­å±•ç°å‡ºä¸åŒçš„æŠ€èƒ½å’Œä¸“é•¿ï¼Œä¸”å…¶è¡¨ç°å·®å¼‚åœ¨ä¸åŒå±‚çº§ä¸Šæœ‰æ‰€ä½“ç°ã€‚åœ¨ä»£ç ä¼˜åŒ–ä»»åŠ¡ä¸­ï¼Œå„LLMsæ“…é•¿ä¸åŒçš„ä¼˜åŒ–ç±»åˆ«ï¼Œä¸”æ²¡æœ‰ä¸€ç§æ¨¡å‹èƒ½å…¨é¢è¶…è¶Šå…¶ä»–æ¨¡å‹ã€‚ä¸ºåˆ©ç”¨å¤šä¸ªLLMè§£å†³ç¼–ç é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åŸºäºæ•™è®­çš„åˆä½œæ¡†æ¶ã€‚åœ¨è¯¥æ¡†æ¶ä¸­ï¼Œå„æ¨¡å‹å¯ä»å½¼æ­¤çš„æˆåŠŸå’Œå¤±è´¥ä¸­å­¦ä¹ ï¼Œä»è€Œæå‡è‡ªèº«æ€§èƒ½ã€‚å› æ­¤ï¼Œæ•™è®­æ˜¯æŒ‡ä»£ç†åœ¨é›†ä½“è§£å†³è¿‡ç¨‹ä¸­äº§ç”Ÿçš„çŸ¥è¯†ï¼Œå¹¶ä¼ é€’ç»™å…¶ä»–ä»£ç†ã€‚æˆ‘ä»¬çš„ç ”ç©¶è¯æ˜äº†åŸºäºæ•™è®­çš„å°å‹LLMå›¢é˜Ÿèƒ½å¤Ÿè¶…è¶Šå¤§å‹LLMä»¥åŠå…¶ä»–å¤šLLMåä½œæ–¹æ³•çš„è¡¨ç°ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>LLMsåœ¨ä¸åŒä»»åŠ¡ä¸­å±•ç°å‡ºä¸åŒçš„æŠ€èƒ½å’Œä¸“é•¿ã€‚</li>
<li>åœ¨ä»£ç ä¼˜åŒ–ä»»åŠ¡ä¸­ï¼Œå„LLMsæ“…é•¿ä¸åŒçš„ä¼˜åŒ–ç±»åˆ«ï¼Œæ²¡æœ‰å…¨é¢é¢†å…ˆçš„æ¨¡å‹ã€‚</li>
<li>åˆ©ç”¨å¤šä¸ªLLMè§£å†³ç¼–ç é—®é¢˜æ—¶ï¼Œå„æ¨¡å‹é—´çš„äº’è¡¥ä¼˜åŠ¿æ˜¯å…³é”®ã€‚</li>
<li>åŸºäºæ•™è®­çš„åˆä½œæ¡†æ¶æœ‰åŠ©äºå„LLMä»å½¼æ­¤çš„æˆåŠŸå’Œå¤±è´¥ä¸­å­¦ä¹ ã€‚</li>
<li>æ•™è®­æ˜¯ä»£ç†åœ¨é›†ä½“è§£å†³è¿‡ç¨‹ä¸­äº§ç”Ÿçš„çŸ¥è¯†ï¼Œå¹¶ä¼ é€’ç»™å…¶ä»–ä»£ç†ã€‚</li>
<li>åŸºäºæ•™è®­çš„å°å‹LLMå›¢é˜Ÿè¡¨ç°å¯è¶…è¶Šå¤§å‹LLMã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.23946">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-641a64f2e33197a0fa46db398ad6e07f" align="middle">
<img src="https://picx.zhimg.com/v2-252883c89e0dda42f31604faa61abfac" align="middle">
<img src="https://picx.zhimg.com/v2-6e73a3e38214e91c4435f6dc093f75ea" align="middle">
<img src="https://picx.zhimg.com/v2-90bfce80c95d771441d7f0a9a022ceb8" align="middle">
</details>


<h1 id="-13"><a href="#-13" class="headerlink" title=""></a></h1><h2 id="Embodied-Agents-Meet-Personalization-Investigating-Challenges-and-Solutions-Through-the-Lens-of-Memory-Utilization"><a href="#Embodied-Agents-Meet-Personalization-Investigating-Challenges-and-Solutions-Through-the-Lens-of-Memory-Utilization" class="headerlink" title="Embodied Agents Meet Personalization: Investigating Challenges and   Solutions Through the Lens of Memory Utilization"></a>Embodied Agents Meet Personalization: Investigating Challenges and   Solutions Through the Lens of Memory Utilization</h2><p><strong>Authors:Taeyoon Kwon, Dongwook Choi, Hyojun Kim, Sunghwan Kim, Seungjun Moon, Beong-woo Kwak, Kuan-Hao Huang, Jinyoung Yeo</strong></p>
<p>LLM-powered embodied agents have shown success on conventional object-rearrangement tasks, but providing personalized assistance that leverages user-specific knowledge from past interactions presents new challenges. We investigate these challenges through the lens of agentsâ€™ memory utilization along two critical dimensions: object semantics (identifying objects based on personal meaning) and user patterns (recalling sequences from behavioral routines). To assess these capabilities, we construct MEMENTO, an end-to-end two-stage evaluation framework comprising single-memory and joint-memory tasks. Our experiments reveal that current agents can recall simple object semantics but struggle to apply sequential user patterns to planning. Through in-depth analysis, we identify two critical bottlenecks: information overload and coordination failures when handling multiple memories. Based on these findings, we explore memory architectural approaches to address these challenges. Given our observation that episodic memory provides both personalized knowledge and in-context learning benefits, we design a hierarchical knowledge graph-based user-profile memory module that separately manages personalized knowledge, achieving substantial improvements on both single and joint-memory tasks. Project website: <a target="_blank" rel="noopener" href="https://connoriginal.github.io/MEMENTO">https://connoriginal.github.io/MEMENTO</a> </p>
<blockquote>
<p>åŸºäºLLMçš„å®ä½“ä»£ç†åœ¨å¸¸è§„çš„å¯¹è±¡é‡ç»„ä»»åŠ¡ä¸­å–å¾—äº†æˆåŠŸï¼Œä½†å¦‚ä½•åˆ©ç”¨è¿‡å»äº¤äº’ä¸­çš„ç”¨æˆ·ç‰¹å®šçŸ¥è¯†æä¾›ä¸ªæ€§åŒ–è¾…åŠ©å¸¦æ¥äº†æ–°çš„æŒ‘æˆ˜ã€‚æˆ‘ä»¬é€šè¿‡ä»£ç†çš„å†…å­˜åˆ©ç”¨æ¥ç ”ç©¶è¿™äº›æŒ‘æˆ˜ï¼Œä¸»è¦å…³æ³¨ä¸¤ä¸ªå…³é”®ç»´åº¦ï¼šå¯¹è±¡è¯­ä¹‰ï¼ˆåŸºäºä¸ªäººæ„ä¹‰è¯†åˆ«å¯¹è±¡ï¼‰å’Œç”¨æˆ·æ¨¡å¼ï¼ˆä»è¡Œä¸ºå¸¸è§„ä¸­å›å¿†åºåˆ—ï¼‰ã€‚ä¸ºäº†è¯„ä¼°è¿™äº›èƒ½åŠ›ï¼Œæˆ‘ä»¬æ„å»ºäº†MEMENTOï¼Œè¿™æ˜¯ä¸€ä¸ªç«¯åˆ°ç«¯çš„ä¸¤é˜¶æ®µè¯„ä¼°æ¡†æ¶ï¼ŒåŒ…æ‹¬å•è®°å¿†å’Œè”åˆè®°å¿†ä»»åŠ¡ã€‚æˆ‘ä»¬çš„å®éªŒè¡¨æ˜ï¼Œå½“å‰ä»£ç†èƒ½å¤Ÿå›å¿†ç®€å•çš„å¯¹è±¡è¯­ä¹‰ï¼Œä½†åœ¨å°†é¡ºåºç”¨æˆ·æ¨¡å¼åº”ç”¨äºè§„åˆ’æ—¶é‡åˆ°å›°éš¾ã€‚é€šè¿‡æ·±å…¥åˆ†æï¼Œæˆ‘ä»¬ç¡®å®šäº†ä¸¤ä¸ªå…³é”®ç“¶é¢ˆï¼šå¤„ç†å¤šä¸ªè®°å¿†æ—¶çš„ä¿¡æ¯è¿‡è½½å’Œåè°ƒå¤±è´¥ã€‚åŸºäºè¿™äº›å‘ç°ï¼Œæˆ‘ä»¬æ¢ç´¢äº†è§£å†³è¿™äº›æŒ‘æˆ˜çš„å†…å­˜æ¶æ„æ–¹æ³•ã€‚é‰´äºæˆ‘ä»¬å¯¹æƒ…æ™¯è®°å¿†æä¾›ä¸ªæ€§åŒ–çŸ¥è¯†å’Œä¸Šä¸‹æ–‡å­¦ä¹ å¥½å¤„çš„è§‚å¯Ÿï¼Œæˆ‘ä»¬è®¾è®¡äº†ä¸€ä¸ªåŸºäºåˆ†å±‚çŸ¥è¯†å›¾çš„ç”¨æˆ·é…ç½®æ–‡ä»¶å†…å­˜æ¨¡å—ï¼Œè¯¥æ¨¡å—å•ç‹¬ç®¡ç†ä¸ªæ€§åŒ–çŸ¥è¯†ï¼Œåœ¨å•è®°å¿†å’Œè”åˆè®°å¿†ä»»åŠ¡ä¸­éƒ½å–å¾—äº†é‡å¤§æ”¹è¿›ã€‚é¡¹ç›®ç½‘ç«™ï¼š<a target="_blank" rel="noopener" href="https://connoriginal.github.io/MEMENTO">https://connoriginal.github.io/MEMENTO</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.16348v2">PDF</a> Work in progress</p>
<p><strong>Summary</strong></p>
<p>LLMé©±åŠ¨çš„æ™ºèƒ½ä½“åœ¨ä¼ ç»Ÿç‰©ä½“æ•´ç†ä»»åŠ¡ä¸Šè¡¨ç°å‡ºæˆåŠŸï¼Œä½†åœ¨åˆ©ç”¨ç”¨æˆ·è¿‡å¾€äº’åŠ¨çš„ä¸ªäººç‰¹å®šçŸ¥è¯†æä¾›ä¸ªæ€§åŒ–ååŠ©æ–¹é¢å­˜åœ¨æŒ‘æˆ˜ã€‚ç ”ç©¶é€šè¿‡æ™ºèƒ½ä½“è®°å¿†åˆ©ç”¨çš„ä¸¤ä¸ªå…³é”®ç»´åº¦â€”â€”ç‰©ä½“è¯­ä¹‰å’Œç”¨æˆ·æ¨¡å¼æ¥å®¡è§†è¿™äº›æŒ‘æˆ˜ã€‚ä¸ºè¯„ä¼°è¿™äº›èƒ½åŠ›ï¼Œæ„å»ºäº†MEMENTOï¼Œä¸€ä¸ªç«¯åˆ°ç«¯çš„ä¸¤é˜¶æ®µè¯„ä¼°æ¡†æ¶ï¼ŒåŒ…æ‹¬å•è®°å¿†å’Œè”åˆè®°å¿†ä»»åŠ¡ã€‚å®éªŒå‘ç°å½“å‰æ™ºèƒ½ä½“èƒ½å¤Ÿå›å¿†ç®€å•çš„ç‰©ä½“è¯­ä¹‰ï¼Œä½†åœ¨å°†é¡ºåºç”¨æˆ·æ¨¡å¼åº”ç”¨äºè§„åˆ’æ—¶é‡åˆ°å›°éš¾ã€‚æ·±å…¥åˆ†æç¡®å®šäº†ä¸¤ä¸ªå…³é”®ç“¶é¢ˆï¼šå¤„ç†å¤šé‡è®°å¿†æ—¶çš„ä¿¡æ¯è¿‡è½½å’Œåè°ƒå¤±è´¥ã€‚åŸºäºè¿™äº›å‘ç°ï¼Œæ¢è®¨äº†è§£å†³è¿™äº›æŒ‘æˆ˜çš„è®°å¿†æ¶æ„æ–¹æ³•ã€‚è§‚å¯Ÿåˆ°æƒ…æ™¯è®°å¿†æ—¢å¯æä¾›ä¸ªæ€§åŒ–çŸ¥è¯†åˆæœ‰ä¸Šä¸‹æ–‡å­¦ä¹ ä¼˜åŠ¿ï¼Œè®¾è®¡äº†ä¸€ä¸ªåŸºäºåˆ†çº§çŸ¥è¯†å›¾è°±çš„ç”¨æˆ·æ¡£æ¡ˆè®°å¿†æ¨¡å—ï¼Œåˆ†åˆ«ç®¡ç†ä¸ªæ€§åŒ–çŸ¥è¯†ï¼Œåœ¨å•è®°å¿†å’Œè”åˆè®°å¿†ä»»åŠ¡ä¸Šéƒ½å–å¾—äº†æ˜¾è‘—æ”¹è¿›ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>LLMæ™ºèƒ½ä½“åœ¨ç‰©ä½“æ•´ç†ä»»åŠ¡ä¸Šè¡¨ç°è‰¯å¥½ï¼Œä½†åœ¨æä¾›ä¸ªæ€§åŒ–ååŠ©æ—¶é¢ä¸´æŒ‘æˆ˜ã€‚</li>
<li>æ™ºèƒ½ä½“è®°å¿†åˆ©ç”¨çš„ä¸¤ä¸ªå…³é”®ç»´åº¦æ˜¯ç‰©ä½“è¯­ä¹‰å’Œç”¨æˆ·æ¨¡å¼ã€‚</li>
<li>MEMENTOæ¡†æ¶ç”¨äºè¯„ä¼°æ™ºèƒ½ä½“çš„è®°å¿†èƒ½åŠ›ï¼ŒåŒ…æ‹¬å•è®°å¿†å’Œè”åˆè®°å¿†ä»»åŠ¡ã€‚</li>
<li>å½“å‰æ™ºèƒ½ä½“èƒ½å¤Ÿå›å¿†ç®€å•ç‰©ä½“è¯­ä¹‰ï¼Œä½†åœ¨å°†ç”¨æˆ·æ¨¡å¼åº”ç”¨äºè§„åˆ’æ—¶å­˜åœ¨å›°éš¾ã€‚</li>
<li>ä¿¡æ¯è¿‡è½½å’Œåè°ƒå¤±è´¥æ˜¯å¤„ç†å¤šé‡è®°å¿†æ—¶çš„ä¸¤ä¸ªå…³é”®ç“¶é¢ˆã€‚</li>
<li>æƒ…æ™¯è®°å¿†å¯¹æä¾›ä¸ªæ€§åŒ–çŸ¥è¯†å’Œä¸Šä¸‹æ–‡å­¦ä¹ æœ‰ç›Šã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.16348">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-7ac46f1d73e282898d0a59b5c3c45b31" align="middle">
<img src="https://picx.zhimg.com/v2-12ee3e98cd54e58543ed4c3b4320b000" align="middle">
<img src="https://picx.zhimg.com/v2-51a5beabd2412e89ce47e57786a2c70c" align="middle">
<img src="https://picx.zhimg.com/v2-a4be1e64c88e3eada8cb3fccacfbf7d9" align="middle">
<img src="https://picx.zhimg.com/v2-21942c9a132fb7e4df75003fbe881e7c" align="middle">
<img src="https://picx.zhimg.com/v2-d48e4ac7758870a913d112f97a47e613" align="middle">
</details>


<h1 id="-14"><a href="#-14" class="headerlink" title=""></a></h1><h2 id="Reinforcing-Multi-Turn-Reasoning-in-LLM-Agents-via-Turn-Level-Reward-Design"><a href="#Reinforcing-Multi-Turn-Reasoning-in-LLM-Agents-via-Turn-Level-Reward-Design" class="headerlink" title="Reinforcing Multi-Turn Reasoning in LLM Agents via Turn-Level Reward   Design"></a>Reinforcing Multi-Turn Reasoning in LLM Agents via Turn-Level Reward   Design</h2><p><strong>Authors:Quan Wei, Siliang Zeng, Chenliang Li, William Brown, Oana Frunza, Wei Deng, Anderson Schneider, Yuriy Nevmyvaka, Yang Katie Zhao, Alfredo Garcia, Mingyi Hong</strong></p>
<p>This paper investigates Reinforcement Learning (RL) approaches to enhance the reasoning capabilities of Large Language Model (LLM) agents in long-horizon, multi-turn scenarios. Although RL algorithms such as Group Relative Policy Optimization (GRPO) and Proximal Policy Optimization (PPO) have been widely applied to train multi-turn LLM agents, they typically rely only on sparse outcome rewards and lack dense intermediate signals across multiple decision steps, limiting their performance on complex reasoning tasks. To bridge this gap, we present the first systematic study of \textit{turn-level reward design} for multi-turn RL algorithms and agent applications. By integrating turn-level rewards, we extend GRPO and PPO to their respective multi-turn variants, enabling fine-grained credit assignment. We conduct case studies on multi-turn reasoning-augmented search agents, where we carefully design two types of turn-level rewards: verifiable and LLM-as-judge. Our experiments on multi-turn search tasks demonstrate that incorporating well-designed turn-level rewards enables RL algorithms to significantly outperform baseline methods with trajectory-level rewards. Both training and validation reward curves illustrate that our method achieves \textit{greater stability}, \textit{faster convergence}, and \textit{higher accuracy}. Numerical results across diverse question-answering datasets further show that our approach consistently delivers highest answer correctness and 100% format correctness. </p>
<blockquote>
<p>æœ¬æ–‡æ¢è®¨äº†å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰æ–¹æ³•ï¼Œä»¥æé«˜å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä»£ç†åœ¨é•¿å‘¨æœŸã€å¤šè½®æ¬¡åœºæ™¯ä¸­çš„æ¨ç†èƒ½åŠ›ã€‚å°½ç®¡è¯¸å¦‚ç¾¤ç»„ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–ï¼ˆGRPOï¼‰å’Œè¿‘ç«¯ç­–ç•¥ä¼˜åŒ–ï¼ˆPPOï¼‰ä¹‹ç±»çš„RLç®—æ³•å·²è¢«å¹¿æ³›åº”ç”¨äºè®­ç»ƒå¤šè½®LLMä»£ç†ï¼Œä½†å®ƒä»¬é€šå¸¸ä»…ä¾èµ–äºç¨€ç–çš„ç»“æœå¥–åŠ±ï¼Œå¹¶ä¸”åœ¨å¤šä¸ªå†³ç­–æ­¥éª¤ä¸­ç¼ºä¹å¯†é›†çš„ä¸­é—´ä¿¡å·ï¼Œè¿™åœ¨å¤æ‚æ¨ç†ä»»åŠ¡ä¸Šé™åˆ¶äº†å®ƒä»¬çš„æ€§èƒ½ã€‚ä¸ºäº†å¼¥è¡¥è¿™ä¸€å·®è·ï¼Œæˆ‘ä»¬å¯¹å¤šè½®RLç®—æ³•çš„â€œè½®çº§å¥–åŠ±è®¾è®¡â€è¿›è¡Œäº†ç¬¬ä¸€æ¬¡ç³»ç»Ÿç ”ç©¶ï¼Œå¹¶ä»‹ç»äº†å…¶åœ¨ä»£ç†åº”ç”¨ä¸­çš„ä½¿ç”¨ã€‚é€šè¿‡æ•´åˆè½®çº§å¥–åŠ±ï¼Œæˆ‘ä»¬å°†GRPOå’ŒPPOæ‰©å±•åˆ°å„è‡ªçš„å¤šè½®å˜ä½“ï¼Œå®ç°äº†ç²¾ç»†çš„ä¿¡ç”¨åˆ†é…ã€‚æˆ‘ä»¬åœ¨å¤šè½®æ¨ç†å¢å¼ºæœç´¢ä»£ç†çš„æ¡ˆä¾‹ç ”ç©¶ä¸­ï¼Œç²¾å¿ƒè®¾è®¡äº†ä¸¤ç§è½®çº§å¥–åŠ±ï¼šå¯éªŒè¯çš„å’ŒLLMåˆ¤æ–­ã€‚æˆ‘ä»¬åœ¨å¤šè½®æœç´¢ä»»åŠ¡ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œèå…¥ç²¾å¿ƒè®¾è®¡çš„è½®çº§å¥–åŠ±èƒ½å¤Ÿä½¿RLç®—æ³•æ˜¾è‘—ä¼˜äºå…·æœ‰è½¨è¿¹çº§å¥–åŠ±çš„åŸºçº¿æ–¹æ³•ã€‚è®­ç»ƒå’ŒéªŒè¯çš„å¥–åŠ±æ›²çº¿éƒ½è¯æ˜æˆ‘ä»¬çš„æ–¹æ³•å®ç°äº†æ›´é«˜çš„ç¨³å®šæ€§ã€æ›´å¿«çš„æ”¶æ•›é€Ÿåº¦å’Œæ›´é«˜çš„å‡†ç¡®æ€§ã€‚åœ¨ä¸åŒé—®ç­”æ•°æ®é›†ä¸Šçš„æ•°å€¼ç»“æœè¿›ä¸€æ­¥è¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•å§‹ç»ˆåœ¨ç­”æ¡ˆæ­£ç¡®ç‡å’Œæ ¼å¼æ­£ç¡®æ€§æ–¹é¢è¡¨ç°æœ€ä½³ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.11821v2">PDF</a> work in progress</p>
<p><strong>Summary</strong>ï¼š<br>å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰ç”¨äºæå‡å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä»£ç†åœ¨å¤šå›åˆåœºæ™¯ä¸­çš„æ¨ç†èƒ½åŠ›ã€‚æœ¬ç ”ç©¶é¦–æ¬¡ç³»ç»Ÿåœ°ç ”ç©¶äº†å¤šå›åˆRLç®—æ³•å’Œä»£ç†åº”ç”¨çš„å›åˆçº§åˆ«å¥–åŠ±è®¾è®¡ã€‚é€šè¿‡é›†æˆå›åˆçº§åˆ«å¥–åŠ±ï¼Œæ‰©å±•äº†Group Relative Policy Optimizationï¼ˆGRPOï¼‰å’ŒProximal Policy Optimizationï¼ˆPPOï¼‰è‡³å…¶å¤šå›åˆå˜ä½“ï¼Œå®ç°äº†ç²¾ç»†çš„ä¿¡ç”¨åˆ†é…ã€‚åœ¨å›åˆæ¨ç†è¾…åŠ©æœç´¢ä»£ç†çš„æ¡ˆä¾‹ç ”ç©¶ä¸­ï¼Œè®¾è®¡äº†ä¸¤ç§å›åˆçº§åˆ«å¥–åŠ±ï¼šå¯éªŒè¯å’ŒLLMä½œä¸ºè¯„åˆ¤å‘˜ã€‚å®éªŒè¡¨æ˜ï¼Œç»“åˆè‰¯å¥½çš„å›åˆçº§åˆ«å¥–åŠ±ï¼ŒRLç®—æ³•èƒ½æ˜¾è‘—ä¼˜äºè½¨è¿¹çº§åˆ«å¥–åŠ±çš„åŸºçº¿æ–¹æ³•ï¼Œå®ç°äº†æ›´é«˜çš„ç¨³å®šæ€§ã€æ›´å¿«çš„æ”¶æ•›é€Ÿåº¦å’Œæ›´é«˜çš„å‡†ç¡®æ€§ã€‚</p>
<p><strong>Key Takeaways</strong>ï¼š</p>
<ol>
<li>å¼ºåŒ–å­¦ä¹ ç”¨äºæå‡å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å¤šå›åˆåœºæ™¯ä¸­çš„æ¨ç†èƒ½åŠ›ã€‚</li>
<li>ç ”ç©¶é¦–æ¬¡ç³»ç»Ÿåœ°æ¢ç´¢äº†å›åˆçº§åˆ«å¥–åŠ±è®¾è®¡åœ¨å¤šå›åˆRLç®—æ³•å’Œä»£ç†åº”ç”¨ä¸­çš„é‡è¦æ€§ã€‚</li>
<li>é€šè¿‡é›†æˆå›åˆçº§åˆ«å¥–åŠ±ï¼Œæ‰©å±•äº†GRPOå’ŒPPOè‡³å…¶å¤šå›åˆå˜ä½“ã€‚</li>
<li>åœ¨å›åˆæ¨ç†è¾…åŠ©æœç´¢ä»£ç†çš„æ¡ˆä¾‹ç ”ç©¶ä¸­ï¼Œè®¾è®¡äº†ä¸¤ç§å›åˆçº§åˆ«å¥–åŠ±ï¼šå¯éªŒè¯å’ŒLLMä½œä¸ºè¯„åˆ¤å‘˜ã€‚</li>
<li>ç»“åˆè‰¯å¥½çš„å›åˆçº§åˆ«å¥–åŠ±ï¼ŒRLç®—æ³•èƒ½æ˜¾è‘—ä¼˜äºè½¨è¿¹çº§åˆ«å¥–åŠ±çš„åŸºçº¿æ–¹æ³•ã€‚</li>
<li>å®éªŒç»“æœå±•ç¤ºäº†ç»“åˆå›åˆçº§åˆ«å¥–åŠ±çš„æ–¹æ³•åœ¨ç¨³å®šæ€§ã€æ”¶æ•›é€Ÿåº¦å’Œå‡†ç¡®æ€§æ–¹é¢çš„ä¼˜åŠ¿ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.11821">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-c9edd6f78108b838dcf289e46bbb713e" align="middle">
<img src="https://picx.zhimg.com/v2-8161c815c24d7e93064da53fbdaa5742" align="middle">
<img src="https://picx.zhimg.com/v2-f3bf8e6458c1a50672f3ece084af4f09" align="middle">
<img src="https://picx.zhimg.com/v2-4c61d91860cec5693a386ab99d96dcf6" align="middle">
</details>


<h1 id="-15"><a href="#-15" class="headerlink" title=""></a></h1><h2 id="MindForge-Empowering-Embodied-Agents-with-Theory-of-Mind-for-Lifelong-Cultural-Learning"><a href="#MindForge-Empowering-Embodied-Agents-with-Theory-of-Mind-for-Lifelong-Cultural-Learning" class="headerlink" title="MindForge: Empowering Embodied Agents with Theory of Mind for Lifelong   Cultural Learning"></a>MindForge: Empowering Embodied Agents with Theory of Mind for Lifelong   Cultural Learning</h2><p><strong>Authors:Mircea LicÄƒ, Ojas Shirekar, Baptiste Colle, Chirag Raman</strong></p>
<p>Embodied agents powered by large language models (LLMs), such as Voyager, promise open-ended competence in worlds such as Minecraft. However, when powered by open-weight LLMs they still falter on elementary tasks after domain-specific fine-tuning. We propose MindForge, a generative-agent framework for cultural lifelong learning through explicit perspective taking. We introduce three key innovations: (1) a structured theory of mind representation linking percepts, beliefs, desires, and actions; (2) natural inter-agent communication; and (3) a multi-component memory system. Following the cultural learning framework, we test MindForge in both instructive and collaborative settings within Minecraft. In an instructive setting with GPT-4, MindForge agents powered by open-weight LLMs significantly outperform their Voyager counterparts in basic tasks yielding $3\times$ more tech-tree milestones and collecting $2.3\times$ more unique items than the Voyager baseline. Furthermore, in fully \textit{collaborative} settings, we find that the performance of two underachieving agents improves with more communication rounds, echoing the Condorcet Jury Theorem. MindForge agents demonstrate sophisticated behaviors, including expert-novice knowledge transfer, collaborative problem solving, and adaptation to out-of-distribution tasks through accumulated cultural experiences. </p>
<blockquote>
<p>ç”±å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰é©±åŠ¨çš„å®ä½“ä»£ç†ï¼Œå¦‚Voyagerï¼Œåœ¨Minecraftç­‰ä¸–ç•ŒèŒƒå›´å†…å±•ç°å‡ºæ— é™æ½œèƒ½ã€‚ç„¶è€Œï¼Œå½“ç”±å¼€æ”¾å¼æƒé‡LLMé©±åŠ¨æ—¶ï¼Œå®ƒä»¬åœ¨ç‰¹å®šé¢†åŸŸå¾®è°ƒåä»ç„¶ä¼šåœ¨åŸºç¡€ä»»åŠ¡ä¸Šé‡åˆ°å›°éš¾ã€‚æˆ‘ä»¬æå‡ºMindForgeï¼Œè¿™æ˜¯ä¸€ä¸ªé€šè¿‡æ˜ç¡®è§†è§’é‡‡å–æ–‡åŒ–ç»ˆèº«å­¦ä¹ çš„ç”Ÿæˆä»£ç†æ¡†æ¶ã€‚æˆ‘ä»¬å¼•å…¥äº†ä¸‰é¡¹å…³é”®åˆ›æ–°ï¼šï¼ˆ1ï¼‰ä¸€ç§ç»“æ„åŒ–çš„å¿ƒç†è¡¨å¾ç†è®ºï¼Œå°†æ„ŸçŸ¥ã€ä¿¡å¿µã€æ¬²æœ›å’Œè¡ŒåŠ¨è”ç³»èµ·æ¥ï¼›ï¼ˆ2ï¼‰è‡ªç„¶ä»£ç†é—´é€šä¿¡ï¼›ï¼ˆ3ï¼‰å¤šç»„ä»¶å†…å­˜ç³»ç»Ÿã€‚éµå¾ªæ–‡åŒ–å­¦ä¹ æ¡†æ¶ï¼Œæˆ‘ä»¬åœ¨Minecraftçš„æŒ‡ä»¤å’Œåä½œç¯å¢ƒä¸­æµ‹è¯•äº†MindForgeã€‚åœ¨å…·æœ‰GPT-4çš„æŒ‡ä»¤ç¯å¢ƒä¸­ï¼Œç”±å¼€æ”¾å¼æƒé‡LLMé©±åŠ¨çš„MindForgeä»£ç†åœ¨åŸºæœ¬ä»»åŠ¡ä¸Šæ˜¾è‘—ä¼˜äºVoyagerçš„å¯¹åº”ç‰©ï¼Œè¾¾åˆ°$3\times$ä»¥ä¸Šçš„ç§‘æŠ€æ ‘é‡Œç¨‹ç¢‘å’Œæ”¶é›†åˆ°æ¯”VoyageråŸºçº¿é«˜å‡º$2.3\times$çš„ç‹¬ç‰¹ç‰©å“ã€‚æ­¤å¤–ï¼Œåœ¨å®Œå…¨åä½œçš„ç¯å¢ƒä¸­ï¼Œæˆ‘ä»¬å‘ç°ä¸¤ä¸ªè¡¨ç°ä¸ä½³çš„ä»£ç†éšç€æ²Ÿé€šè½®æ¬¡çš„å¢åŠ è€Œæå‡æ€§èƒ½ï¼Œè¿™åæ˜ äº†å­”å¤šå¡é™ªå®¡å›¢å®šç†ã€‚MindForgeä»£ç†è¡¨ç°å‡ºé«˜çº§è¡Œä¸ºï¼ŒåŒ…æ‹¬ä¸“å®¶æ–°æ‰‹çŸ¥è¯†è½¬ç§»ã€åä½œè§£å†³é—®é¢˜ä»¥åŠé€šè¿‡ç´¯ç§¯çš„æ–‡åŒ–ç»éªŒé€‚åº”è¶…å‡ºåˆ†å¸ƒèŒƒå›´çš„ä»»åŠ¡ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2411.12977v5">PDF</a> Accepted to NeurIPS 2025 main track as poster</p>
<p><strong>Summary</strong></p>
<p>åœ¨Minecraftç­‰ä¸–ç•Œï¼Œå¤§å‹è¯­è¨€æ¨¡å‹é©±åŠ¨çš„å†…åŒ–ä»£ç†ï¼ˆå¦‚Voyagerï¼‰å±•ç°å‡ºæ— é™åˆ¶çš„æ½œåŠ›ï¼Œä½†åœ¨ç‰¹å®šé¢†åŸŸçš„ç²¾ç»†è°ƒæ•´åä»æ— æ³•å®ŒæˆåŸºç¡€ä»»åŠ¡ã€‚æˆ‘ä»¬æå‡ºMindForgeï¼Œä¸€ä¸ªæ–‡åŒ–ç»ˆèº«å­¦ä¹ çš„ç”Ÿæˆä»£ç†æ¡†æ¶ï¼Œé€šè¿‡æ˜ç¡®è§†è§’é‡‡å–ã€‚æˆ‘ä»¬å¼•å…¥ä¸‰ä¸ªå…³é”®åˆ›æ–°ç‚¹ï¼šä¸€æ˜¯ç»“æ„åŒ–å¿ƒæ™ºç†è®ºè¡¨ç°è¿æ¥æ„ŸçŸ¥ã€ä¿¡å¿µã€æ¬²æœ›å’Œè¡ŒåŠ¨ï¼›äºŒæ˜¯è‡ªç„¶åŒ–çš„ä»£ç†é—´é€šä¿¡ï¼›ä¸‰æ˜¯å¤šç»„ä»¶å†…å­˜ç³»ç»Ÿã€‚åœ¨Minecraftçš„æŒ‡ç¤ºæ€§å’Œåä½œç¯å¢ƒä¸­éµå¾ªæ–‡åŒ–å­¦ä¹ æ¡†æ¶æµ‹è¯•MindForgeã€‚åœ¨GPT-4æŒ‡ç¤ºçš„ç¯å¢ƒä¸­ï¼Œç”±å¼€æ”¾å¼é‡é‡å¤§å‹è¯­è¨€æ¨¡å‹é©±åŠ¨çš„MindForgeä»£ç†åœ¨åŸºç¡€ä»»åŠ¡ä¸Šæ˜¾è‘—ä¼˜äºVoyagerï¼ŒæŠ€æœ¯é‡Œç¨‹ç¢‘æ•°æ˜¯Voyagerçš„ä¸‰å€ï¼Œç‹¬ç‰¹ç‰©å“æ”¶é›†é‡æ˜¯Voyagerçš„2.3å€ã€‚æ­¤å¤–ï¼Œåœ¨å®Œå…¨åä½œçš„ç¯å¢ƒä¸­ï¼Œæˆ‘ä»¬å‘ç°ä¸¤ä¸ªè¡¨ç°ä¸ä½³çš„ä»£ç†éšç€é€šä¿¡è½®æ¬¡çš„å¢åŠ è€Œæå‡æ€§èƒ½ï¼Œè¿™åæ˜ äº†Condorceté™ªå®¡å›¢å®šç†ã€‚MindForgeä»£ç†è¡¨ç°å‡ºé«˜çº§è¡Œä¸ºï¼ŒåŒ…æ‹¬ä¸“å®¶æ–°æ‰‹çŸ¥è¯†è½¬ç§»ã€åä½œé—®é¢˜è§£å†³ä»¥åŠé€‚åº”ç¦»åˆ†å¸ƒä»»åŠ¡çš„æ–‡åŒ–ç»éªŒç§¯ç´¯ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>MindForgeæ˜¯ä¸€ä¸ªæ”¯æŒæ–‡åŒ–ç»ˆèº«å­¦ä¹ çš„ç”Ÿæˆä»£ç†æ¡†æ¶ï¼Œå¼•å…¥äº†ç»“æ„åŒ–çš„å¿ƒæ™ºç†è®ºè¡¨ç°æ¥å¼ºåŒ–ä»£ç†çš„èƒ½åŠ›å’Œè¡¨ç°ã€‚</li>
<li>MindForgeçš„å…³é”®åˆ›æ–°åŒ…æ‹¬ï¼šè‡ªç„¶åŒ–çš„ä»£ç†é—´é€šä¿¡å’Œå¤šç»„ä»¶å†…å­˜ç³»ç»Ÿç­‰æŠ€æœ¯ã€‚è¿™äº›æŠ€æœ¯èƒ½å¤ŸåŠ å¼ºä»£ç†åœ¨å­¦ä¹ å’Œç†è§£ä»»åŠ¡ä¸­çš„åä½œå’Œäº¤äº’èƒ½åŠ›ã€‚</li>
<li>åœ¨æŒ‡ä»¤æ€§ç¯å¢ƒä¸‹ä½¿ç”¨GPT-4çš„æµ‹è¯•ä¸­ï¼ŒMindForgeåœ¨åŸºæœ¬ä»»åŠ¡æ–¹é¢å±•ç°å‡ºæ¯”Voyageræ›´ä¼˜è¶Šçš„è¡¨ç°ï¼Œå…·æœ‰æ˜¾è‘—æ›´é«˜çš„æŠ€æœ¯é‡Œç¨‹ç¢‘ç‰©å“æ”¶é›†ç‡ã€‚è¿™æ˜¾ç¤ºäº†å…¶åœ¨å®Œæˆä»»åŠ¡å’Œå¯¼èˆªæ–¹é¢çš„å¼ºå¤§æ€§èƒ½ã€‚</li>
<li>åœ¨åä½œç¯å¢ƒä¸­ï¼Œä¸¤ä¸ªè¡¨ç°ä¸ä½³çš„ä»£ç†å¯ä»¥é€šè¿‡å¢åŠ é€šä¿¡è½®æ¬¡æé«˜æ€§èƒ½ï¼Œè¿™è¡¨æ˜äº†æ²Ÿé€šå’Œåä½œåœ¨å®Œæˆä»»åŠ¡ä¸­çš„é‡è¦æ€§ã€‚è¿™ä¹ŸéªŒè¯äº†Condorceté™ªå®¡å›¢å®šç†çš„åº”ç”¨ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2411.12977">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-c2603075bb7ebf7dcf4f7c523b3677bd" align="middle">
<img src="https://picx.zhimg.com/v2-6d9b831bbd926dd1eae952fc72d32d0c" align="middle">
<img src="https://picx.zhimg.com/v2-babdc11cf8a365e299818b4a8509d1f0" align="middle">
<img src="https://picx.zhimg.com/v2-9aacf598ef60131bc2a843c72e8b19ca" align="middle">
</details>


<h1 id="-16"><a href="#-16" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-10-25/Agent/">https://kedreamix.github.io/Talk2Paper/Paper/2025-10-25/Agent/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/Agent/">
                                    <span class="chip bg-color">Agent</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-10-25/Few-Shot/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-263f18abe5cae4cb9aaabb2353cdf736" class="responsive-img" alt="Few-Shot">
                        
                        <span class="card-title">Few-Shot</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Few-Shot æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-10-25  A Scalable, Causal, and Energy Efficient Framework for Neural Decoding   with Spiking Neural Networks
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-10-25
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Few-Shot/" class="post-category">
                                    Few-Shot
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Few-Shot/">
                        <span class="chip bg-color">Few-Shot</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-10-25/LLM/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-6ce5253c371246d6bc19de916eafe302" class="responsive-img" alt="LLM">
                        
                        <span class="card-title">LLM</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            LLM æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-10-25  ARGenSeg Image Segmentation with Autoregressive Image Generation Model
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-10-25
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/LLM/" class="post-category">
                                    LLM
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/LLM/">
                        <span class="chip bg-color">LLM</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">33125.9k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
