<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="TTS">
    <meta name="description" content="TTS æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-05-28  Zero-Shot Streaming Text to Speech Synthesis with Transducer and   Auto-Regressive Modeling">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>TTS | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://picx.zhimg.com/v2-f9fa5d40cacd81f3f87412b0f4b1980b.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">TTS</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/TTS/">
                                <span class="chip bg-color">TTS</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/TTS/" class="post-category">
                                TTS
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-05-28
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-06-24
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    8.4k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    34 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-05-28-æ›´æ–°"><a href="#2025-05-28-æ›´æ–°" class="headerlink" title="2025-05-28 æ›´æ–°"></a>2025-05-28 æ›´æ–°</h1><h2 id="Zero-Shot-Streaming-Text-to-Speech-Synthesis-with-Transducer-and-Auto-Regressive-Modeling"><a href="#Zero-Shot-Streaming-Text-to-Speech-Synthesis-with-Transducer-and-Auto-Regressive-Modeling" class="headerlink" title="Zero-Shot Streaming Text to Speech Synthesis with Transducer and   Auto-Regressive Modeling"></a>Zero-Shot Streaming Text to Speech Synthesis with Transducer and   Auto-Regressive Modeling</h2><p><strong>Authors:Haiyang Sun, Shujie Hu, Shujie Liu, Lingwei Meng, Hui Wang, Bing Han, Yifan Yang, Yanqing Liu, Sheng Zhao, Yan Lu, Yanmin Qian</strong></p>
<p>Zero-shot streaming text-to-speech is an important research topic in human-computer interaction. Existing methods primarily use a lookahead mechanism, relying on future text to achieve natural streaming speech synthesis, which introduces high processing latency. To address this issue, we propose SMLLE, a streaming framework for generating high-quality speech frame-by-frame. SMLLE employs a Transducer to convert text into semantic tokens in real time while simultaneously obtaining duration alignment information. The combined outputs are then fed into a fully autoregressive (AR) streaming model to reconstruct mel-spectrograms. To further stabilize the generation process, we design a Delete &lt; Bos &gt; Mechanism that allows the AR model to access future text introducing as minimal delay as possible. Experimental results suggest that the SMLLE outperforms current streaming TTS methods and achieves comparable performance over sentence-level TTS systems. Samples are available on <a target="_blank" rel="noopener" href="https://anonymous.4open.science/w/demo_page-48B7/">https://anonymous.4open.science/w/demo_page-48B7/</a>. </p>
<blockquote>
<p>é›¶æ ·æœ¬æµå¼æ–‡æœ¬åˆ°è¯­éŸ³è½¬æ¢æ˜¯è®¡ç®—æœºäººæœºäº¤äº’é¢†åŸŸçš„ä¸€ä¸ªé‡è¦ç ”ç©¶è¯¾é¢˜ã€‚ç°æœ‰çš„æ–¹æ³•ä¸»è¦ä½¿ç”¨å‰è§†æœºåˆ¶ï¼Œä¾é æœªæ¥çš„æ–‡æœ¬å®ç°è‡ªç„¶çš„æµå¼è¯­éŸ³åˆæˆï¼Œè¿™å¼•å…¥äº†å¾ˆé«˜çš„å¤„ç†å»¶è¿Ÿã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†SMLLEï¼Œè¿™æ˜¯ä¸€ä¸ªç”¨äºé€å¸§ç”Ÿæˆé«˜è´¨é‡è¯­éŸ³çš„æµå¼æ¡†æ¶ã€‚SMLLEä½¿ç”¨è½¬æ¢å™¨å°†æ–‡æœ¬å®æ—¶è½¬æ¢ä¸ºè¯­ä¹‰ä»¤ç‰Œï¼ŒåŒæ—¶è·å¾—æŒç»­æ—¶é—´å¯¹é½ä¿¡æ¯ã€‚ç„¶åå°†è¿™äº›ç»„åˆè¾“å‡ºé¦ˆå…¥å®Œå…¨è‡ªå›å½’ï¼ˆARï¼‰æµå¼æ¨¡å‹ï¼Œä»¥é‡å»ºæ¢…å°”é¢‘è°±å›¾ã€‚ä¸ºäº†è¿›ä¸€æ­¥ç¨³å®šç”Ÿæˆè¿‡ç¨‹ï¼Œæˆ‘ä»¬è®¾è®¡äº†ä¸€ç§åˆ é™¤<Bos>æœºåˆ¶ï¼Œå…è®¸ARæ¨¡å‹è®¿é—®æœªæ¥çš„æ–‡æœ¬ï¼Œå¹¶å°½é‡å‡å°‘å»¶è¿Ÿã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒSMLLEä¼˜äºå½“å‰çš„æµå¼TTSæ–¹æ³•ï¼Œå¹¶åœ¨å¥å­çº§TTSç³»ç»Ÿä¸Šå–å¾—äº†ç›¸å½“çš„æ€§èƒ½ã€‚æ ·æœ¬å¯é€šè¿‡<a target="_blank" rel="noopener" href="https://anonymous.4open.science/w/demo_page-48B7/%E8%AE%BF%E9%97%AE%E3%80%82">https://anonymous.4open.science/w/demo_page-48B7/è®¿é—®ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.19669v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºä¸€ç§åä¸ºSMLLEçš„é›¶æ ·æœ¬æµå¼æ–‡æœ¬è½¬è¯­éŸ³ç”Ÿæˆæ¡†æ¶ï¼Œè§£å†³äº†ç°æœ‰æ–¹æ³•å¤„ç†å»¶è¿Ÿé«˜çš„é—®é¢˜ã€‚é€šè¿‡å®æ—¶å°†æ–‡æœ¬è½¬æ¢ä¸ºè¯­ä¹‰æ ‡è®°å¹¶è·å–æ—¶é•¿å¯¹é½ä¿¡æ¯ï¼Œå†è¾“å…¥å…¨è‡ªå›å½’ï¼ˆARï¼‰æµå¼æ¨¡å‹é‡å»ºæ¢…å°”é¢‘è°±å›¾ï¼Œå®ç°é«˜è´¨é‡è¯­éŸ³å¸§ç”Ÿæˆã€‚è®¾è®¡åˆ é™¤<Bos>æœºåˆ¶ä»¥è¿›ä¸€æ­¥ç¨³å®šç”Ÿæˆè¿‡ç¨‹ï¼Œå‡å°‘æœªæ¥æ–‡æœ¬å¼•å…¥çš„å»¶è¿Ÿã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒSMLLEåœ¨æµå¼TTSæ–¹æ³•ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œä¸å¥å­çº§TTSç³»ç»Ÿæ€§èƒ½ç›¸å½“ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>SMLLEæ˜¯ä¸€ä¸ªç”¨äºç”Ÿæˆé«˜è´¨é‡è¯­éŸ³çš„é›¶æ ·æœ¬æµå¼æ–‡æœ¬è½¬è¯­éŸ³æ¡†æ¶ã€‚</li>
<li>é‡‡ç”¨Transducerå®æ—¶å°†æ–‡æœ¬è½¬æ¢ä¸ºè¯­ä¹‰æ ‡è®°å¹¶è·å–æ—¶é•¿å¯¹é½ä¿¡æ¯ã€‚</li>
<li>ç»“åˆè¯­ä¹‰æ ‡è®°å’Œæ—¶é•¿å¯¹é½ä¿¡æ¯è¾“å…¥å…¨è‡ªå›å½’ï¼ˆARï¼‰æµå¼æ¨¡å‹ã€‚</li>
<li>é€šè¿‡é‡å»ºæ¢…å°”é¢‘è°±å›¾å®ç°é«˜è´¨é‡è¯­éŸ³å¸§ç”Ÿæˆã€‚</li>
<li>è®¾è®¡åˆ é™¤<Bos>æœºåˆ¶ä»¥ç¨³å®šç”Ÿæˆè¿‡ç¨‹å¹¶å‡å°‘å»¶è¿Ÿã€‚</li>
<li>å®éªŒç»“æœè¡¨æ˜ï¼ŒSMLLEåœ¨æµå¼TTSæ–¹æ³•ä¸­è¡¨ç°ä¼˜å¼‚ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.19669">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-a16b6c187c1a80a3555a1b251a3c2fea.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ac85b5d00b85bfd04fc781af2e01efa1.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-624ee28d8c6c16670ea64fde61dfc4ca.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ae8b672898fa672e2e6c8d4804e8340f.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-6ab7cd7db3d39a98ef74fcf43b056641.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-4feefe0e383fe21e443a7da5a256caf2.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="Faster-and-Better-LLMs-via-Latency-Aware-Test-Time-Scaling"><a href="#Faster-and-Better-LLMs-via-Latency-Aware-Test-Time-Scaling" class="headerlink" title="Faster and Better LLMs via Latency-Aware Test-Time Scaling"></a>Faster and Better LLMs via Latency-Aware Test-Time Scaling</h2><p><strong>Authors:Zili Wang, Tianyu Zhang, Haoli Bai, Lu Hou, Xianzhi Yu, Wulong Liu, Shiming Xiang, Lei Zhu</strong></p>
<p>Test-Time Scaling (TTS) has proven effective in improving the performance of Large Language Models (LLMs) during inference. However, existing research has overlooked the efficiency of TTS from a latency-sensitive perspective. Through a latency-aware evaluation of representative TTS methods, we demonstrate that a compute-optimal TTS does not always result in the lowest latency in scenarios where latency is critical. To address this gap and achieve latency-optimal TTS, we propose two key approaches by optimizing the concurrency configurations: (1) branch-wise parallelism, which leverages multiple concurrent inference branches, and (2) sequence-wise parallelism, enabled by speculative decoding. By integrating these two approaches and allocating computational resources properly to each, our latency-optimal TTS enables a 32B model to reach 82.3% accuracy on MATH-500 within 1 minute and a smaller 3B model to achieve 72.4% within 10 seconds. Our work emphasizes the importance of latency-aware TTS and demonstrates its ability to deliver both speed and accuracy in latency-sensitive scenarios. </p>
<blockquote>
<p>æµ‹è¯•æ—¶é—´ç¼©æ”¾ï¼ˆTTSï¼‰å·²è¢«è¯æ˜å¯ä»¥æœ‰æ•ˆæé«˜å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨æ¨ç†è¿‡ç¨‹ä¸­çš„æ€§èƒ½ã€‚ç„¶è€Œï¼Œç°æœ‰ç ”ç©¶ä»å»¶è¿Ÿæ•æ„Ÿçš„è§’åº¦å¿½è§†äº†TTSçš„æ•ˆç‡ã€‚é€šè¿‡å¯¹ä»£è¡¨æ€§TTSæ–¹æ³•è¿›è¡Œå»¶è¿Ÿæ„ŸçŸ¥è¯„ä¼°ï¼Œæˆ‘ä»¬è¯æ˜è®¡ç®—æœ€ä¼˜çš„TTSå¹¶ä¸æ€»æ˜¯å¯¼è‡´æœ€ä½å»¶è¿Ÿï¼Œè¿™åœ¨å»¶è¿Ÿè‡³å…³é‡è¦çš„åœºæ™¯ä¸­å°¤ä¸ºé‡è¦ã€‚ä¸ºäº†è§£å†³è¿™ä¸€å·®è·å¹¶å®ç°å»¶è¿Ÿæœ€ä¼˜çš„TTSï¼Œæˆ‘ä»¬æå‡ºäº†ä¸¤ç§é€šè¿‡ä¼˜åŒ–å¹¶å‘é…ç½®çš„å…³é”®æ–¹æ³•ï¼šï¼ˆ1ï¼‰åˆ†æ”¯å¹¶è¡Œæ€§ï¼Œåˆ©ç”¨å¤šä¸ªå¹¶å‘æ¨ç†åˆ†æ”¯ï¼›ï¼ˆ2ï¼‰åºåˆ—å¹¶è¡Œæ€§ï¼Œé€šè¿‡æŠ•æœºè§£ç å®ç°ã€‚é€šè¿‡æ•´åˆè¿™ä¸¤ç§æ–¹æ³•å¹¶ä¸ºæ¯ç§æ–¹æ³•é€‚å½“åˆ†é…è®¡ç®—èµ„æºï¼Œæˆ‘ä»¬çš„å»¶è¿Ÿæœ€ä¼˜TTSä½¿32Bæ¨¡å‹åœ¨MATH-500ä¸Š1åˆ†é’Ÿå†…è¾¾åˆ°82.3%çš„å‡†ç¡®ç‡ï¼Œè¾ƒå°çš„3Bæ¨¡å‹åœ¨10ç§’å†…è¾¾åˆ°72.4%çš„å‡†ç¡®ç‡ã€‚æˆ‘ä»¬çš„å·¥ä½œå¼ºè°ƒäº†å»¶è¿Ÿæ„ŸçŸ¥TTSçš„é‡è¦æ€§ï¼Œå¹¶å±•ç¤ºäº†å…¶åœ¨å»¶è¿Ÿæ•æ„Ÿåœºæ™¯ä¸­å®ç°é€Ÿåº¦å’Œå‡†ç¡®æ€§çš„èƒ½åŠ›ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.19634v1">PDF</a> </p>
<p><strong>Summary</strong><br>     æµ‹è¯•æ—¶é—´ç¼©æ”¾ï¼ˆTTSï¼‰åœ¨æå‡å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ¨ç†æ€§èƒ½ä¸Šæ•ˆæœæ˜¾è‘—ã€‚ç„¶è€Œï¼Œç°æœ‰ç ”ç©¶ä»å»¶è¿Ÿæ•æ„Ÿçš„è§’åº¦å¿½è§†äº†TTSçš„æ•ˆç‡ã€‚æˆ‘ä»¬é€šè¿‡å»¶è¿Ÿæ„ŸçŸ¥çš„ä»£è¡¨æ€§TTSæ–¹æ³•è¯„ä¼°ï¼Œè¯æ˜äº†è®¡ç®—æœ€ä¼˜çš„TTSå¹¶ä¸æ€»æ˜¯å¯¼è‡´æœ€ä½å»¶è¿Ÿï¼Œè¿™åœ¨å»¶è¿Ÿè‡³å…³é‡è¦çš„æƒ…å†µä¸‹å°¤ä¸ºå¦‚æ­¤ã€‚ä¸ºäº†å¼¥è¡¥è¿™ä¸€å·®è·å¹¶å®ç°å»¶è¿Ÿæœ€ä¼˜çš„TTSï¼Œæˆ‘ä»¬æå‡ºäº†ä¸¤ç§é€šè¿‡ä¼˜åŒ–å¹¶å‘é…ç½®çš„å…³é”®æ–¹æ³•ï¼šï¼ˆ1ï¼‰åˆ†æ”¯å¹¶è¡Œæ€§ï¼Œåˆ©ç”¨å¤šä¸ªå¹¶å‘æ¨ç†åˆ†æ”¯ï¼›ï¼ˆ2ï¼‰åºåˆ—å¹¶è¡Œæ€§ï¼Œé€šè¿‡æŠ•æœºè§£ç å®ç°ã€‚é€šè¿‡æ•´åˆè¿™ä¸¤ç§æ–¹æ³•å¹¶ä¸ºæ¯ç§æ–¹æ³•é€‚å½“åˆ†é…è®¡ç®—èµ„æºï¼Œæˆ‘ä»¬çš„å»¶è¿Ÿæœ€ä¼˜TTSä½¿32Bæ¨¡å‹åœ¨MATH-500ä¸Š1åˆ†é’Ÿå†…è¾¾åˆ°82.3%çš„å‡†ç¡®ç‡ï¼Œè¾ƒå°çš„3Bæ¨¡å‹åœ¨10ç§’å†…è¾¾åˆ°72.4%çš„å‡†ç¡®ç‡ã€‚æˆ‘ä»¬çš„å·¥ä½œå¼ºè°ƒäº†å»¶è¿Ÿæ„ŸçŸ¥TTSçš„é‡è¦æ€§ï¼Œå¹¶å±•ç¤ºäº†å…¶åœ¨å»¶è¿Ÿæ•æ„Ÿåœºæ™¯ä¸­å®ç°é€Ÿåº¦å’Œå‡†ç¡®æ€§çš„èƒ½åŠ›ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>TTSåœ¨æé«˜LLMæ¨ç†æ€§èƒ½ä¸Šæœ‰æ•ˆï¼Œä½†ç°æœ‰ç ”ç©¶æœªå……åˆ†å…³æ³¨å…¶å»¶è¿Ÿæ•ˆç‡ã€‚</li>
<li>è®¡ç®—æœ€ä¼˜çš„TTSå¹¶ä¸æ€»æ˜¯å¯¼è‡´æœ€ä½å»¶è¿Ÿï¼Œç‰¹åˆ«æ˜¯åœ¨å»¶è¿Ÿæ•æ„Ÿçš„æƒ…å†µä¸‹ã€‚</li>
<li>æå‡ºä¸¤ç§ä¼˜åŒ–TTSå¹¶å‘é…ç½®çš„æ–¹æ³•ï¼šåˆ†æ”¯å¹¶è¡Œæ€§å’Œåºåˆ—å¹¶è¡Œæ€§ã€‚</li>
<li>åˆ†æ”¯å¹¶è¡Œæ€§åˆ©ç”¨å¤šä¸ªå¹¶å‘æ¨ç†åˆ†æ”¯ã€‚</li>
<li>åºåˆ—å¹¶è¡Œæ€§é€šè¿‡æŠ•æœºè§£ç å®ç°ã€‚</li>
<li>æ•´åˆè¿™ä¸¤ç§æ–¹æ³•å¹¶é€‚å½“åˆ†é…è®¡ç®—èµ„æºï¼Œå¯å®ç°å»¶è¿Ÿæœ€ä¼˜çš„TTSã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.19634">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-b2d016ab7b0cf554ded9888b2dd58f5c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-235616815750083229d9ac47ab79bf1a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-bc11049b2a067213003b77acf7e59eda.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-1fa7f64c34abc1a76feb38474c46ef11.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-1cb2ab025abe0288742ee07fedafd092.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-5c9a08d1815a39687e6ed039c7f59d70.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="Accelerating-Diffusion-based-Text-to-Speech-Model-Training-with-Dual-Modality-Alignment"><a href="#Accelerating-Diffusion-based-Text-to-Speech-Model-Training-with-Dual-Modality-Alignment" class="headerlink" title="Accelerating Diffusion-based Text-to-Speech Model Training with Dual   Modality Alignment"></a>Accelerating Diffusion-based Text-to-Speech Model Training with Dual   Modality Alignment</h2><p><strong>Authors:Jeongsoo Choi, Zhikang Niu, Ji-Hoon Kim, Chunhui Wang, Joon Son Chung, Chen Xie</strong></p>
<p>The goal of this paper is to optimize the training process of diffusion-based text-to-speech models. While recent studies have achieved remarkable advancements, their training demands substantial time and computational costs, largely due to the implicit guidance of diffusion models in learning complex intermediate representations. To address this, we propose A-DMA, an effective strategy for Accelerating training with Dual Modality Alignment. Our method introduces a novel alignment pipeline leveraging both text and speech modalities: text-guided alignment, which incorporates contextual representations, and speech-guided alignment, which refines semantic representations. By aligning hidden states with discriminative features, our training scheme reduces the reliance on diffusion models for learning complex representations. Extensive experiments demonstrate that A-DMA doubles the convergence speed while achieving superior performance over baselines. Code and demo samples are available at: <a target="_blank" rel="noopener" href="https://github.com/ZhikangNiu/A-DMA">https://github.com/ZhikangNiu/A-DMA</a> </p>
<blockquote>
<p>æœ¬æ–‡çš„ç›®æ ‡æ˜¯ä¼˜åŒ–åŸºäºæ‰©æ•£çš„æ–‡æœ¬åˆ°è¯­éŸ³æ¨¡å‹çš„è®­ç»ƒè¿‡ç¨‹ã€‚è™½ç„¶æœ€è¿‘çš„ç ”ç©¶å–å¾—äº†æ˜¾è‘—çš„è¿›æ­¥ï¼Œä½†å®ƒä»¬çš„è®­ç»ƒéœ€è¦å¤§é‡çš„æ—¶é—´å’Œè®¡ç®—æˆæœ¬ï¼Œè¿™ä¸»è¦æ˜¯å› ä¸ºæ‰©æ•£æ¨¡å‹åœ¨å­¦ä¹ å¤æ‚ä¸­é—´è¡¨ç¤ºæ—¶çš„éšå¼æŒ‡å¯¼ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†A-DMAï¼Œä¸€ç§åˆ©ç”¨åŒæ¨¡æ€å¯¹é½åŠ é€Ÿè®­ç»ƒçš„æœ‰æ•ˆç­–ç•¥ã€‚æˆ‘ä»¬çš„æ–¹æ³•å¼•å…¥äº†ä¸€ä¸ªæ–°çš„å¯¹é½ç®¡é“ï¼Œåˆ©ç”¨æ–‡æœ¬å’Œè¯­éŸ³ä¸¤ç§æ¨¡å¼ï¼šæ–‡æœ¬å¼•å¯¼å¯¹é½ï¼Œå®ƒç»“åˆäº†ä¸Šä¸‹æ–‡è¡¨ç¤ºï¼›è¯­éŸ³å¼•å¯¼å¯¹é½ï¼Œå®ƒæ”¹è¿›äº†è¯­ä¹‰è¡¨ç¤ºã€‚é€šè¿‡éšè—çŠ¶æ€ä¸åˆ¤åˆ«ç‰¹å¾çš„å¯¹é½ï¼Œæˆ‘ä»¬çš„è®­ç»ƒæ–¹æ¡ˆå‡å°‘äº†æ‰©æ•£æ¨¡å‹åœ¨å­¦ä¹ å¤æ‚è¡¨ç¤ºä¸Šçš„ä¾èµ–ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼ŒA-DMAçš„æ”¶æ•›é€Ÿåº¦æé«˜äº†ä¸€å€ï¼ŒåŒæ—¶ç›¸å¯¹äºåŸºçº¿è¾¾åˆ°äº†å“è¶Šçš„æ€§èƒ½ã€‚ä»£ç å’Œæ¼”ç¤ºæ ·æœ¬å¯åœ¨ï¼š&lt;<a target="_blank" rel="noopener" href="https://github.com/ZhikangNiu/A-DMA">https://github.com/ZhikangNiu/A-DMA</a> è§‚çœ‹ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.19595v1">PDF</a> Interspeech 2025</p>
<p><strong>Summary</strong><br>æ–‡æœ¬ä¸»è¦ä»‹ç»äº†å¦‚ä½•ä¼˜åŒ–åŸºäºæ‰©æ•£çš„æ–‡æœ¬åˆ°è¯­éŸ³æ¨¡å‹çš„è®­ç»ƒè¿‡ç¨‹ã€‚ä¸ºäº†è§£å†³æ‰©æ•£æ¨¡å‹è®­ç»ƒæ—¶é—´é•¿ã€è®¡ç®—æˆæœ¬é«˜çš„ç—›ç‚¹ï¼Œæå‡ºäº†ä¸€ç§æ–°çš„åŠ é€Ÿè®­ç»ƒç­–ç•¥A-DMAã€‚é€šè¿‡èåˆæ–‡æœ¬å’Œè¯­éŸ³æ¨¡æ€çš„åŒæ¨¡æ€å¯¹é½æ–¹å¼ï¼ŒåŠ å¿«æ¨¡å‹æ”¶æ•›é€Ÿåº¦å¹¶æå‡æ€§èƒ½ã€‚å®éªŒç»“æœè¯æ˜ï¼Œä½¿ç”¨A-DMAç­–ç•¥çš„æ¨¡å‹è®­ç»ƒé€Ÿåº¦ç¿»å€ï¼Œæ€§èƒ½ä¼˜äºåŸºçº¿æ¨¡å‹ã€‚ç›¸å…³ä»£ç å’Œæ¼”ç¤ºæ ·æœ¬å·²ä¸Šä¼ è‡³GitHubã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>è¯¥è®ºæ–‡æ—¨åœ¨ä¼˜åŒ–åŸºäºæ‰©æ•£çš„æ–‡æœ¬åˆ°è¯­éŸ³æ¨¡å‹çš„è®­ç»ƒè¿‡ç¨‹ã€‚</li>
<li>è®­ç»ƒè¿‡ç¨‹ä¸­å­˜åœ¨æ—¶é—´é•¿å’Œè®¡ç®—æˆæœ¬é«˜çš„ç—›ç‚¹ã€‚</li>
<li>æå‡ºäº†ä¸€ç§æ–°çš„åŠ é€Ÿè®­ç»ƒç­–ç•¥A-DMAï¼Œé€šè¿‡åŒæ¨¡æ€å¯¹é½æ–¹å¼èåˆæ–‡æœ¬å’Œè¯­éŸ³æ¨¡æ€ã€‚</li>
<li>A-DMAç­–ç•¥åŒ…æ‹¬æ–‡æœ¬å¼•å¯¼å¯¹é½å’Œè¯­éŸ³å¼•å¯¼å¯¹é½ä¸¤ç§æ–¹å¼ã€‚</li>
<li>é€šè¿‡ä¸åŸºçº¿æ¨¡å‹å¯¹æ¯”å®éªŒï¼Œè¯æ˜ä½¿ç”¨A-DMAç­–ç•¥çš„æ¨¡å‹è®­ç»ƒé€Ÿåº¦ç¿»å€ä¸”æ€§èƒ½æ›´ä¼˜ã€‚</li>
<li>A-DMAç­–ç•¥é€šè¿‡å‡å°‘æ‰©æ•£æ¨¡å‹å¯¹å¤æ‚è¡¨ç¤ºçš„ä¾èµ–ï¼Œæé«˜äº†æ¨¡å‹çš„æ”¶æ•›é€Ÿåº¦å’Œæ€§èƒ½ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.19595">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-be4196815080104956016de557bd5edc.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-dbc0a1f0dd1a2401ce44e38ebe87d555.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-f66c2a08392fed4658d3d0bf370e0087.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-0fbdfc50b69995f2063ece097ae9aa3d.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="VoiceStar-Robust-Zero-Shot-Autoregressive-TTS-with-Duration-Control-and-Extrapolation"><a href="#VoiceStar-Robust-Zero-Shot-Autoregressive-TTS-with-Duration-Control-and-Extrapolation" class="headerlink" title="VoiceStar: Robust Zero-Shot Autoregressive TTS with Duration Control and   Extrapolation"></a>VoiceStar: Robust Zero-Shot Autoregressive TTS with Duration Control and   Extrapolation</h2><p><strong>Authors:Puyuan Peng, Shang-Wen Li, Abdelrahman Mohamed, David Harwath</strong></p>
<p>We present VoiceStar, the first zero-shot TTS model that achieves both output duration control and extrapolation. VoiceStar is an autoregressive encoder-decoder neural codec language model, that leverages a novel Progress-Monitoring Rotary Position Embedding (PM-RoPE) and is trained with Continuation-Prompt Mixed (CPM) training. PM-RoPE enables the model to better align text and speech tokens, indicates the target duration for the generated speech, and also allows the model to generate speech waveforms much longer in duration than those seen during. CPM training also helps to mitigate the training&#x2F;inference mismatch, and significantly improves the quality of the generated speech in terms of speaker similarity and intelligibility. VoiceStar outperforms or is on par with current state-of-the-art models on short-form benchmarks such as Librispeech and Seed-TTS, and significantly outperforms these models on long-form&#x2F;extrapolation benchmarks (20-50s) in terms of intelligibility and naturalness. Code and model weights: <a target="_blank" rel="noopener" href="https://github.com/jasonppy/VoiceStar">https://github.com/jasonppy/VoiceStar</a> </p>
<blockquote>
<p>æˆ‘ä»¬æ¨å‡ºäº†VoiceStarï¼Œè¿™æ˜¯ç¬¬ä¸€ä¸ªå®ç°è¾“å‡ºæ—¶é•¿æ§åˆ¶å’Œå¤–æ¨åŠŸèƒ½çš„é›¶æ ·æœ¬TTSæ¨¡å‹ã€‚VoiceStaræ˜¯ä¸€ç§åŸºäºè‡ªå›å½’ç¼–ç å™¨-è§£ç å™¨ç¥ç»ç½‘ç»œçš„è¯­è¨€æ¨¡å‹ï¼Œå®ƒé‡‡ç”¨æ–°å‹è¿›åº¦ç›‘æ§æ—‹è½¬ä½ç½®åµŒå…¥ï¼ˆPM-RoPEï¼‰ï¼Œå¹¶é€šè¿‡è¿ç»­æç¤ºæ··åˆï¼ˆCPMï¼‰è¿›è¡Œè®­ç»ƒã€‚PM-RoPEä½¿æ¨¡å‹èƒ½å¤Ÿæ›´å¥½åœ°å¯¹é½æ–‡æœ¬å’Œè¯­éŸ³æ ‡è®°ï¼ŒæŒ‡ç¤ºç”Ÿæˆè¯­éŸ³çš„ç›®æ ‡æ—¶é•¿ï¼Œå¹¶å…è®¸æ¨¡å‹ç”Ÿæˆæ¯”è®­ç»ƒè¿‡ç¨‹ä¸­æ›´é•¿çš„è¯­éŸ³æ³¢å½¢ã€‚CPMè®­ç»ƒä¹Ÿæœ‰åŠ©äºå‡è½»è®­ç»ƒ&#x2F;æ¨æ–­ä¸åŒ¹é…çš„é—®é¢˜ï¼Œå¹¶æ˜¾è‘—æé«˜ç”Ÿæˆè¯­éŸ³çš„è¯´è¯äººç›¸ä¼¼åº¦å’Œæ¸…æ™°åº¦ã€‚VoiceStaråœ¨è¯¸å¦‚Librispeechå’ŒSeed-TTSç­‰çŸ­æœŸåŸºå‡†æµ‹è¯•ä¸Šçš„è¡¨ç°ä¼˜äºæˆ–ç›¸å½“äºå½“å‰çš„æœ€å…ˆè¿›æ¨¡å‹ï¼Œåœ¨é•¿æœŸ&#x2F;å¤–æ¨åŸºå‡†æµ‹è¯•ï¼ˆ20-50ç§’ï¼‰çš„æ¸…æ™°åº¦å’Œè‡ªç„¶åº¦æ–¹é¢åˆ™å¤§å¤§ä¼˜äºè¿™äº›æ¨¡å‹ã€‚ä»£ç å’Œæ¨¡å‹æƒé‡ï¼š<a target="_blank" rel="noopener" href="https://github.com/jasonppy/VoiceStar">https://github.com/jasonppy/VoiceStar</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.19462v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>VoiceStaræ˜¯ä¸€æ¬¾é›¶æ ·æœ¬TTSæ¨¡å‹ï¼Œå…·å¤‡è¾“å‡ºæ—¶é•¿æ§åˆ¶ä¸å¤–æ¨èƒ½åŠ›ã€‚å®ƒé‡‡ç”¨è‡ªå›å½’ç¼–ç è§£ç å™¨ç¥ç»ç½‘ç»œæ¨¡å‹ç»“æ„ï¼Œå¹¶è¿ç”¨æ–°å‹Progress-Monitoring Rotary Position Embeddingï¼ˆPM-RoPEï¼‰æŠ€æœ¯ä¸Continuation-Prompt Mixedï¼ˆCPMï¼‰è®­ç»ƒæ–¹æ³•ã€‚PM-RoPEä½¿æ¨¡å‹èƒ½æ›´å¥½åœ°å¯¹é½æ–‡æœ¬ä¸è¯­éŸ³æ ‡è®°ï¼Œå¹¶æŒ‡ç¤ºç”Ÿæˆè¯­éŸ³çš„ç›®æ ‡æ—¶é•¿ï¼ŒåŒæ—¶èƒ½ç”Ÿæˆæ¯”è®­ç»ƒè¿‡ç¨‹ä¸­æ›´é•¿çš„è¯­éŸ³æ³¢å½¢ã€‚CPMè®­ç»ƒæœ‰åŠ©äºå‡è½»è®­ç»ƒ&#x2F;æ¨ç†ä¸åŒ¹é…é—®é¢˜ï¼Œå¹¶æ˜¾è‘—æé«˜ç”Ÿæˆè¯­éŸ³çš„è¯´è¯äººç›¸ä¼¼åº¦ä¸æ¸…æ™°åº¦ã€‚VoiceStaråœ¨çŸ­å½¢å¼åŸºå‡†æµ‹è¯•ï¼ˆå¦‚Librispeechå’ŒSeed-TTSï¼‰ä¸Šè¡¨ç°ä¼˜å¼‚æˆ–ç›¸å½“ï¼Œå¹¶åœ¨é•¿å½¢å¼&#x2F;å¤–æ¨åŸºå‡†æµ‹è¯•ï¼ˆ20-50ç§’ï¼‰ä¸Šæ˜¾è‘—ä¼˜äºå…¶ä»–æ¨¡å‹ï¼Œåœ¨æ¸…æ™°åº¦å’Œè‡ªç„¶åº¦æ–¹é¢å°¤ä¸ºçªå‡ºã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>VoiceStaræ˜¯é¦–æ¬¾å®ç°è¾“å‡ºæ—¶é•¿æ§åˆ¶ä¸å¤–æ¨çš„é›¶æ ·æœ¬TTSæ¨¡å‹ã€‚</li>
<li>é‡‡ç”¨è‡ªå›å½’ç¼–ç è§£ç å™¨ç¥ç»ç½‘ç»œæ¨¡å‹ç»“æ„ã€‚</li>
<li>å¼•å…¥Progress-Monitoring Rotary Position Embeddingï¼ˆPM-RoPEï¼‰æŠ€æœ¯ï¼Œæ”¹å–„æ–‡æœ¬ä¸è¯­éŸ³æ ‡è®°çš„å¯¹é½ï¼Œå¹¶æŒ‡ç¤ºç›®æ ‡æ—¶é•¿ã€‚</li>
<li>ä½¿ç”¨Continuation-Prompt Mixedï¼ˆCPMï¼‰è®­ç»ƒæ–¹æ³•ï¼Œæé«˜ç”Ÿæˆè¯­éŸ³è´¨é‡ï¼Œå¹¶ç¼“è§£è®­ç»ƒ&#x2F;æ¨ç†ä¸åŒ¹é…é—®é¢˜ã€‚</li>
<li>VoiceStaråœ¨çŸ­å½¢å¼åŸºå‡†æµ‹è¯•ä¸Šè¡¨ç°ä¼˜ç§€ï¼ŒåŒæ—¶åœ¨é•¿å½¢å¼åŸºå‡†æµ‹è¯•ä¸Šæ˜¾è‘—ä¼˜äºå…¶ä»–æ¨¡å‹ã€‚</li>
<li>æ¨¡å‹ä»“åº“ä¸æƒé‡å…¬å¼€ï¼Œä¾¿äºç ”ç©¶ä¸åº”ç”¨ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.19462">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-3e81b9e1cc6132d357daec19f21617d9.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-67589cfc4a2288a24068acd9be72cdbe.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-8b32e4dc01e1610a6c97e5f17873e1dd.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="SpeakStream-Streaming-Text-to-Speech-with-Interleaved-Data"><a href="#SpeakStream-Streaming-Text-to-Speech-with-Interleaved-Data" class="headerlink" title="SpeakStream: Streaming Text-to-Speech with Interleaved Data"></a>SpeakStream: Streaming Text-to-Speech with Interleaved Data</h2><p><strong>Authors:Richard He Bai, Zijin Gu, Tatiana Likhomanenko, Navdeep Jaitly</strong></p>
<p>The latency bottleneck of traditional text-to-speech (TTS) systems fundamentally hinders the potential of streaming large language models (LLMs) in conversational AI. These TTS systems, typically trained and inferenced on complete utterances, introduce unacceptable delays, even with optimized inference speeds, when coupled with streaming LLM outputs. This is particularly problematic for creating responsive conversational agents where low first-token latency is critical. In this paper, we present SpeakStream, a streaming TTS system that generates audio incrementally from streaming text using a decoder-only architecture. SpeakStream is trained using a next-step prediction loss on interleaved text-speech data. During inference, it generates speech incrementally while absorbing streaming input text, making it particularly suitable for cascaded conversational AI agents where an LLM streams text to a TTS system. Our experiments demonstrate that SpeakStream achieves state-of-the-art latency results in terms of first-token latency while maintaining the quality of non-streaming TTS systems. </p>
<blockquote>
<p>ä¼ ç»Ÿæ–‡æœ¬è½¬è¯­éŸ³ï¼ˆTTSï¼‰ç³»ç»Ÿçš„å»¶è¿Ÿç“¶é¢ˆä»æ ¹æœ¬ä¸Šé˜»ç¢äº†æµå¼å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨å¯¹è¯å¼äººå·¥æ™ºèƒ½ä¸­çš„æ½œåŠ›ã€‚è¿™äº›TTSç³»ç»Ÿé€šå¸¸åœ¨å¯¹å®Œæ•´çš„å‘è¨€è¿›è¡Œè®­ç»ƒå’Œæ¨ç†ï¼Œå½“ä¸æµå¼LLMè¾“å‡ºç›¸ç»“åˆæ—¶ï¼Œå³ä½¿ä»¥ä¼˜åŒ–çš„æ¨ç†é€Ÿåº¦ï¼Œä¹Ÿä¼šå¼•å…¥ä¸å¯æ¥å—çš„å»¶è¿Ÿã€‚è¿™å¯¹äºåˆ›å»ºå“åº”å¼çš„å¯¹è¯ä»£ç†æ¥è¯´ç‰¹åˆ«æˆé—®é¢˜ï¼Œå…¶ä¸­ä½é¦–å­—å»¶è¿Ÿè‡³å…³é‡è¦ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†SpeakStreamï¼Œè¿™æ˜¯ä¸€ä¸ªæµå¼TTSç³»ç»Ÿï¼Œå®ƒä½¿ç”¨ä»…è§£ç å™¨æ¶æ„ä»æµå¼æ–‡æœ¬ä¸­å¢é‡ç”ŸæˆéŸ³é¢‘ã€‚SpeakStreamä½¿ç”¨äº¤æ›¿çš„æ–‡æœ¬-è¯­éŸ³æ•°æ®ä¸Šçš„ä¸‹ä¸€æ­¥é¢„æµ‹æŸå¤±è¿›è¡Œè®­ç»ƒã€‚åœ¨æ¨ç†è¿‡ç¨‹ä¸­ï¼Œå®ƒåœ¨å¸æ”¶æµå¼è¾“å…¥æ–‡æœ¬çš„åŒæ—¶å¢é‡ç”Ÿæˆè¯­éŸ³ï¼Œå› æ­¤ç‰¹åˆ«é€‚åˆç”¨äºçº§è”å¯¹è¯AIä»£ç†ï¼Œå…¶ä¸­LLMå°†æ–‡æœ¬æµå¼ä¼ è¾“åˆ°TTSç³»ç»Ÿã€‚æˆ‘ä»¬çš„å®éªŒè¡¨æ˜ï¼ŒSpeakStreamåœ¨é¦–å­—å»¶è¿Ÿæ–¹é¢è¾¾åˆ°äº†æœ€å…ˆè¿›çš„å»¶è¿Ÿç»“æœï¼ŒåŒæ—¶ä¿æŒäº†éæµå¼TTSç³»ç»Ÿçš„è´¨é‡ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.19206v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†SpeakStreamè¿™ä¸€æµå¼æ–‡æœ¬è½¬è¯­éŸ³ï¼ˆTTSï¼‰ç³»ç»Ÿï¼Œå®ƒèƒ½ä»æµå¼æ–‡æœ¬ä¸­å¢é‡ç”ŸæˆéŸ³é¢‘ã€‚ä¸ä¼ ç»Ÿçš„TTSç³»ç»Ÿç›¸æ¯”ï¼ŒSpeakStreamåœ¨ç”Ÿæˆè¯­éŸ³æ—¶èƒ½å¤Ÿå¤„ç†æµå¼è¾“å…¥æ–‡æœ¬ï¼Œè§£å†³äº†ä¼ ç»ŸTTSç³»ç»Ÿå»¶è¿Ÿçš„é—®é¢˜ï¼Œå°¤å…¶é€‚ç”¨äºçº§è”å¯¹è¯å¼AIä»£ç†ã€‚å®éªŒè¡¨æ˜ï¼ŒSpeakStreamåœ¨é¦–å­—å»¶è¿Ÿæ–¹é¢è¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼ŒåŒæ—¶ä¿æŒäº†éæµå¼TTSç³»ç»Ÿçš„è´¨é‡ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ä¼ ç»ŸTTSç³»ç»Ÿçš„å»¶è¿Ÿé—®é¢˜é™åˆ¶äº†å…¶åœ¨å¯¹è¯å¼AIä¸­æµå¼å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„æ½œåŠ›ã€‚</li>
<li>SpeakStreamæ˜¯ä¸€ç§æµå¼TTSç³»ç»Ÿï¼Œèƒ½ä»æµå¼æ–‡æœ¬ä¸­å¢é‡ç”ŸæˆéŸ³é¢‘ï¼Œè§£å†³äº†å»¶è¿Ÿé—®é¢˜ã€‚</li>
<li>SpeakStreamé‡‡ç”¨è§£ç å™¨ä»…æ¶æ„ï¼Œä½¿ç”¨ä¸‹ä¸€æ­¥é¢„æµ‹æŸå¤±å¯¹äº¤æ›¿çš„æ–‡æœ¬-è¯­éŸ³æ•°æ®è¿›è¡Œè®­ç»ƒã€‚</li>
<li>åœ¨æ¨ç†è¿‡ç¨‹ä¸­ï¼ŒSpeakStreamèƒ½å¢é‡ç”Ÿæˆè¯­éŸ³ï¼ŒåŒæ—¶å¸æ”¶æµå¼è¾“å…¥æ–‡æœ¬ã€‚</li>
<li>SpeakStreamç‰¹åˆ«é€‚ç”¨äºçº§è”å¯¹è¯å¼AIä»£ç†ï¼Œå…¶ä¸­LLMå°†æ–‡æœ¬æµå¼ä¼ è¾“åˆ°TTSç³»ç»Ÿã€‚</li>
<li>å®éªŒè¡¨æ˜ï¼ŒSpeakStreamåœ¨é¦–å­—å»¶è¿Ÿæ–¹é¢è¾¾åˆ°æœ€æ–°æŠ€æœ¯çŠ¶æ€ï¼ŒåŒæ—¶ä¿æŒè¯­éŸ³è´¨é‡ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.19206">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-ad4baf697890303a2310e74e98a4100f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-abcd1ee3b7f478b228e3fbaf03a72b0b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d704f14462fef0cbce57c578b9fa63d1.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-31815a3d5d371b3752fdc1a834bf0bdd.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-2ee136e5a4697d21377c6cb46ff6610f.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-983d8e16e0f3e7142b9bf933fdef95e6.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="CloneShield-A-Framework-for-Universal-Perturbation-Against-Zero-Shot-Voice-Cloning"><a href="#CloneShield-A-Framework-for-Universal-Perturbation-Against-Zero-Shot-Voice-Cloning" class="headerlink" title="CloneShield: A Framework for Universal Perturbation Against Zero-Shot   Voice Cloning"></a>CloneShield: A Framework for Universal Perturbation Against Zero-Shot   Voice Cloning</h2><p><strong>Authors:Renyuan Li, Zhibo Liang, Haichuan Zhang, Tianyu Shi, Zhiyuan Cheng, Jia Shi, Carl Yang, Mingjie Tang</strong></p>
<p>Recent breakthroughs in text-to-speech (TTS) voice cloning have raised serious privacy concerns, allowing highly accurate vocal identity replication from just a few seconds of reference audio, while retaining the speakerâ€™s vocal authenticity. In this paper, we introduce CloneShield, a universal time-domain adversarial perturbation framework specifically designed to defend against zero-shot voice cloning. Our method provides protection that is robust across speakers and utterances, without requiring any prior knowledge of the synthesized text. We formulate perturbation generation as a multi-objective optimization problem, and propose Multi-Gradient Descent Algorithm (MGDA) to ensure the robust protection across diverse utterances. To preserve natural auditory perception for users, we decompose the adversarial perturbation via Mel-spectrogram representations and fine-tune it for each sample. This design ensures imperceptibility while maintaining strong degradation effects on zero-shot cloned outputs. Experiments on three state-of-the-art zero-shot TTS systems, five benchmark datasets and evaluations from 60 human listeners demonstrate that our method preserves near-original audio quality in protected inputs (PESQ &#x3D; 3.90, SRS &#x3D; 0.93) while substantially degrading both speaker similarity and speech quality in cloned samples (PESQ &#x3D; 1.07, SRS &#x3D; 0.08). </p>
<blockquote>
<p>åœ¨æ–‡æœ¬è½¬è¯­éŸ³ï¼ˆTTSï¼‰å£°éŸ³å…‹éš†æ–¹é¢çš„æœ€æ–°çªç ´å¼•å‘äº†ä¸¥é‡çš„éšç§æ‹…å¿§ã€‚ç°åœ¨åªéœ€å‡ ç§’é’Ÿçš„å‚è€ƒéŸ³é¢‘ï¼Œå°±å¯ä»¥å®ç°é«˜åº¦ç²¾ç¡®çš„å—“éŸ³èº«ä»½å¤åˆ¶ï¼ŒåŒæ—¶ä¿ç•™è¯´è¯è€…çš„å—“éŸ³çœŸå®æ€§ã€‚æœ¬æ–‡ä»‹ç»äº†CloneShieldï¼Œè¿™æ˜¯ä¸€ä¸ªä¸“é—¨è®¾è®¡ç”¨äºé˜²èŒƒé›¶æ ·æœ¬å£°éŸ³å…‹éš†çš„é€šç”¨æ—¶é—´åŸŸå¯¹æŠ—æ€§æ‰°åŠ¨æ¡†æ¶ã€‚æˆ‘ä»¬çš„æ–¹æ³•ä¸ºè·¨è¯´è¯è€…å’Œè¯è¯­æä¾›äº†ä¿æŠ¤ï¼Œæ— éœ€å¯¹åˆæˆæ–‡æœ¬æœ‰ä»»ä½•å…ˆéªŒçŸ¥è¯†ã€‚æˆ‘ä»¬å°†æ‰°åŠ¨ç”Ÿæˆåˆ¶å®šä¸ºä¸€ä¸ªå¤šç›®æ ‡ä¼˜åŒ–é—®é¢˜ï¼Œå¹¶æå‡ºå¤šæ¢¯åº¦ä¸‹é™ç®—æ³•ï¼ˆMGDAï¼‰ï¼Œä»¥ç¡®ä¿åœ¨ä¸åŒçš„è¯è¯­ä¸­æä¾›ç¨³å¥çš„ä¿æŠ¤ã€‚ä¸ºäº†ä¿æŒç”¨æˆ·è‡ªç„¶çš„å¬è§‰æ„ŸçŸ¥ï¼Œæˆ‘ä»¬é€šè¿‡æ¢…å°”é¢‘è°±è¡¨ç¤ºæ³•åˆ†è§£å¯¹æŠ—æ€§æ‰°åŠ¨ï¼Œå¹¶é’ˆå¯¹æ¯ä¸ªæ ·æœ¬è¿›è¡Œå¾®è°ƒã€‚è¿™ç§è®¾è®¡ç¡®ä¿äº†ä¸å¯å¯Ÿè§‰æ€§ï¼ŒåŒæ—¶åœ¨å¯¹é›¶æ ·æœ¬å…‹éš†è¾“å‡ºè¿›è¡Œå¼ºçƒˆé™è§£æ—¶ä¿æŒå¼ºå¤§çš„ä¿æŠ¤æ•ˆæœã€‚åœ¨ä¸‰ä¸ªæœ€å…ˆè¿›çš„é›¶æ ·æœ¬TTSç³»ç»Ÿã€äº”ä¸ªåŸºå‡†æ•°æ®é›†ä»¥åŠ60åäººç±»å¬è€…çš„è¯„ä¼°ä¸­è¿›è¡Œçš„å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨ä¿è¯å—ä¿æŠ¤è¾“å…¥æ¥è¿‘åŸå§‹éŸ³é¢‘è´¨é‡çš„åŒæ—¶ï¼ˆPESQ &#x3D; 3.90ï¼ŒSRS &#x3D; 0.93ï¼‰ï¼Œå¤§å¹…åº¦é™ä½äº†å…‹éš†æ ·æœ¬ä¸­çš„è¯´è¯äººç›¸ä¼¼åº¦å’Œè¯­éŸ³è´¨é‡ï¼ˆPESQ &#x3D; 1.07ï¼ŒSRS &#x3D; 0.08ï¼‰ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.19119v1">PDF</a> 10pages, 4figures</p>
<p><strong>Summary</strong><br>     æœ€æ–°æ–‡æœ¬è½¬è¯­éŸ³ï¼ˆTTSï¼‰è¯­éŸ³å…‹éš†æŠ€æœ¯çš„çªç ´å¼•å‘äº†ä¸¥é‡çš„éšç§æ‹…å¿§ï¼Œè¯¥æŠ€æœ¯ä»…éœ€å‡ ç§’çš„å‚è€ƒéŸ³é¢‘å³å¯å®ç°é«˜åº¦å‡†ç¡®çš„è¯­éŸ³èº«ä»½å¤åˆ¶ï¼ŒåŒæ—¶ä¿ç•™è¯´è¯è€…çš„è¯­éŸ³çœŸå®æ€§ã€‚æœ¬æ–‡ä»‹ç»CloneShieldï¼Œä¸€ç§ä¸“é—¨é’ˆå¯¹é›¶æ ·æœ¬è¯­éŸ³å…‹éš†çš„é€šç”¨æ—¶é—´åŸŸå¯¹æŠ—æ€§æ‰°åŠ¨æ¡†æ¶ã€‚è¯¥æ–¹æ³•æä¾›è·¨è¯´è¯è€…å’Œä¸åŒè¯è¯­çš„é²æ£’ä¿æŠ¤ï¼Œæ— éœ€äº†è§£åˆæˆæ–‡æœ¬çš„èƒŒæ™¯çŸ¥è¯†ã€‚é€šè¿‡åˆ¶å®šå¤šç›®æ ‡ä¼˜åŒ–é—®é¢˜ï¼Œæå‡ºäº†å¤šæ¢¯åº¦ä¸‹é™ç®—æ³•ï¼ˆMGDAï¼‰ï¼Œä»¥ç¡®ä¿åœ¨ä¸åŒè¯è¯­ä¹‹é—´çš„å¼ºå¤§ä¿æŠ¤èƒ½åŠ›ã€‚ä¸ºäº†ä¿ç•™ç”¨æˆ·å¬è§‰çš„è‡ªç„¶æ„ŸçŸ¥æ•ˆæœå¹¶ä¿ç•™æ¯ä¸ªæ ·æœ¬çš„ç‹¬ç‰¹æ€§ï¼Œæˆ‘ä»¬é€šè¿‡æ¢…å°”é¢‘è°±å›¾è¡¨ç¤ºæ³•åˆ†è§£å¯¹æŠ—æ€§æ‰°åŠ¨å¹¶è¿›è¡Œå¾®è°ƒã€‚å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨ä¿æŠ¤è¾“å…¥éŸ³é¢‘è´¨é‡çš„åŒæ—¶ï¼Œå¯¹é›¶æ ·æœ¬å…‹éš†è¾“å‡ºäº§ç”Ÿäº†æ˜¾è‘—çš„å¹²æ‰°æ•ˆæœã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æœ€æ–°TTSè¯­éŸ³å…‹éš†æŠ€æœ¯å¼•å‘éšç§æ‹…å¿§ï¼Œèƒ½ä»…é€šè¿‡å‡ ç§’å‚è€ƒéŸ³é¢‘å®ç°é«˜åº¦å‡†ç¡®çš„è¯­éŸ³èº«ä»½å¤åˆ¶ã€‚</li>
<li>CloneShieldæ˜¯ä¸€ä¸ªå¯¹æŠ—æ€§æ‰°åŠ¨æ¡†æ¶ï¼Œæ—¨åœ¨é˜²å¾¡é›¶æ ·æœ¬è¯­éŸ³å…‹éš†ï¼Œæä¾›è·¨è¯´è¯è€…å’Œè¯è¯­çš„é²æ£’ä¿æŠ¤ã€‚</li>
<li>CloneShieldä¸éœ€è¦äº†è§£åˆæˆæ–‡æœ¬çš„èƒŒæ™¯çŸ¥è¯†ã€‚</li>
<li>é€šè¿‡å¤šç›®æ ‡ä¼˜åŒ–é—®é¢˜åˆ¶å®šæ‰°åŠ¨ç”Ÿæˆï¼Œå¹¶æå‡ºå¤šæ¢¯åº¦ä¸‹é™ç®—æ³•ï¼ˆMGDAï¼‰ç¡®ä¿ä¿æŠ¤æ•ˆæœã€‚</li>
<li>ä¸ºä¿ç•™è‡ªç„¶å¬è§‰æ„ŸçŸ¥å’Œç”¨æˆ·ä½“éªŒï¼Œé€šè¿‡æ¢…å°”é¢‘è°±å›¾è¡¨ç¤ºæ³•åˆ†è§£å¹¶å¾®è°ƒå¯¹æŠ—æ€§æ‰°åŠ¨ã€‚</li>
<li>å®éªŒè¯æ˜CloneShieldèƒ½æœ‰æ•ˆä¿æŠ¤è¾“å…¥éŸ³é¢‘è´¨é‡ï¼ŒåŒæ—¶æ˜¾è‘—å¹²æ‰°é›¶æ ·æœ¬å…‹éš†è¾“å‡ºã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.19119">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-f9fa5d40cacd81f3f87412b0f4b1980b.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-f48159884e007271b45a6d7ef31becb6.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-77d5ab548076a2a7d472a31acfc84848.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-1b4dfc995d63dd1d5b5448a7a7a4384b.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="MPE-TTS-Customized-Emotion-Zero-Shot-Text-To-Speech-Using-Multi-Modal-Prompt"><a href="#MPE-TTS-Customized-Emotion-Zero-Shot-Text-To-Speech-Using-Multi-Modal-Prompt" class="headerlink" title="MPE-TTS: Customized Emotion Zero-Shot Text-To-Speech Using Multi-Modal   Prompt"></a>MPE-TTS: Customized Emotion Zero-Shot Text-To-Speech Using Multi-Modal   Prompt</h2><p><strong>Authors:Zhichao Wu, Yueteng Kang, Songjun Cao, Long Ma, Qiulin Li, Qun Yang</strong></p>
<p>Most existing Zero-Shot Text-To-Speech(ZS-TTS) systems generate the unseen speech based on single prompt, such as reference speech or text descriptions, which limits their flexibility. We propose a customized emotion ZS-TTS system based on multi-modal prompt. The system disentangles speech into the content, timbre, emotion and prosody, allowing emotion prompts to be provided as text, image or speech. To extract emotion information from different prompts, we propose a multi-modal prompt emotion encoder. Additionally, we introduce an prosody predictor to fit the distribution of prosody and propose an emotion consistency loss to preserve emotion information in the predicted prosody. A diffusion-based acoustic model is employed to generate the target mel-spectrogram. Both objective and subjective experiments demonstrate that our system outperforms existing systems in terms of naturalness and similarity. The samples are available at <a target="_blank" rel="noopener" href="https://mpetts-demo.github.io/mpetts_demo/">https://mpetts-demo.github.io/mpetts_demo/</a>. </p>
<blockquote>
<p>ç°æœ‰çš„å¤§å¤šæ•°é›¶æ ·æœ¬æ–‡æœ¬è½¬è¯­éŸ³ï¼ˆZS-TTSï¼‰ç³»ç»Ÿéƒ½æ˜¯åŸºäºå•ä¸€æç¤ºï¼ˆå¦‚å‚è€ƒè¯­éŸ³æˆ–æ–‡æœ¬æè¿°ï¼‰æ¥ç”Ÿæˆæœªè§è¿‡çš„è¯­éŸ³ï¼Œè¿™é™åˆ¶äº†å®ƒä»¬çš„çµæ´»æ€§ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§åŸºäºå¤šæ¨¡æ€æç¤ºçš„å®šåˆ¶æƒ…æ„ŸZS-TTSç³»ç»Ÿã€‚è¯¥ç³»ç»Ÿå°†è¯­éŸ³åˆ†è§£ä¸ºå†…å®¹ã€éŸ³è‰²ã€æƒ…æ„Ÿå’ŒéŸµå¾‹ï¼Œå…è®¸ä»¥æ–‡æœ¬ã€å›¾åƒæˆ–è¯­éŸ³çš„å½¢å¼æä¾›æƒ…æ„Ÿæç¤ºã€‚ä¸ºäº†ä»ä¸åŒæç¤ºä¸­æå–æƒ…æ„Ÿä¿¡æ¯ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§å¤šæ¨¡æ€æç¤ºæƒ…æ„Ÿç¼–ç å™¨ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ä¸ªéŸµå¾‹é¢„æµ‹å™¨ä»¥é€‚åº”éŸµå¾‹åˆ†å¸ƒï¼Œå¹¶æå‡ºäº†ä¸€ç§æƒ…æ„Ÿä¸€è‡´æ€§æŸå¤±ï¼Œä»¥åœ¨é¢„æµ‹çš„éŸµå¾‹ä¸­ä¿ç•™æƒ…æ„Ÿä¿¡æ¯ã€‚é‡‡ç”¨åŸºäºæ‰©æ•£çš„å£°å­¦æ¨¡å‹æ¥ç”Ÿæˆç›®æ ‡æ¢…å°”é¢‘è°±å›¾ã€‚å®¢è§‚å’Œä¸»è§‚å®éªŒå‡è¡¨æ˜ï¼Œæˆ‘ä»¬çš„ç³»ç»Ÿåœ¨è‡ªç„¶åº¦å’Œç›¸ä¼¼æ€§æ–¹é¢ä¼˜äºç°æœ‰ç³»ç»Ÿã€‚æ ·æœ¬å¯é€šè¿‡é“¾æ¥<a target="_blank" rel="noopener" href="https://mpetts-demo.github.io/mpetts">https://mpetts-demo.github.io/mpetts</a> ç§‘æ™®å°éªŒDemoè¯•ç”¨ç‰ˆ. ä¸‹è½½æŸ¥çœ‹ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.18453v1">PDF</a> Accepted by InterSpeech</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºä¸€ç§åŸºäºå¤šæ¨¡æ€æç¤ºçš„å®šåˆ¶æƒ…æ„ŸZero-Shot Text-To-Speechï¼ˆZS-TTSï¼‰ç³»ç»Ÿã€‚è¯¥ç³»ç»Ÿå°†è¯­éŸ³åˆ†è§£ä¸ºå†…å®¹ã€éŸ³è´¨ã€æƒ…æ„Ÿå’Œè¯­è°ƒï¼Œå…è®¸ä»¥æ–‡æœ¬ã€å›¾åƒæˆ–è¯­éŸ³çš„å½¢å¼æä¾›æƒ…æ„Ÿæç¤ºã€‚é€šè¿‡å¤šæ¨¡æ€æç¤ºæƒ…æ„Ÿç¼–ç å™¨å’Œæƒ…æ„Ÿä¸€è‡´æ€§æŸå¤±ç­‰æŠ€æœ¯ï¼Œæé«˜äº†ç³»ç»Ÿçš„æƒ…æ„Ÿè¡¨è¾¾èƒ½åŠ›å’Œè‡ªç„¶åº¦ã€‚é‡‡ç”¨æ‰©æ•£å£°å­¦æ¨¡å‹ç”Ÿæˆç›®æ ‡æ¢…å°”é¢‘è°±å›¾ï¼Œåœ¨å®¢è§‚å’Œä¸»è§‚å®éªŒä¸­è¡¨ç°å‡ºä¼˜å¼‚æ€§èƒ½ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ZS-TTSç³»ç»Ÿé€šå¸¸åŸºäºå•ä¸€æç¤ºç”Ÿæˆæœªè§è¯­éŸ³ï¼Œé™åˆ¶äº†å…¶çµæ´»æ€§ã€‚</li>
<li>æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºå¤šæ¨¡æ€æç¤ºçš„å®šåˆ¶æƒ…æ„ŸZS-TTSç³»ç»Ÿï¼Œå¯æ¥æ”¶å¤šç§å½¢å¼çš„æƒ…æ„Ÿæç¤ºï¼ˆå¦‚æ–‡æœ¬ã€å›¾åƒæˆ–è¯­éŸ³ï¼‰ã€‚</li>
<li>ç³»ç»Ÿå°†è¯­éŸ³åˆ†è§£ä¸ºå†…å®¹ã€éŸ³è´¨ã€æƒ…æ„Ÿå’Œè¯­è°ƒï¼Œæé«˜äº†æƒ…æ„Ÿè¡¨è¾¾çš„ä¸°å¯Œæ€§ã€‚</li>
<li>å¼•å…¥å¤šæ¨¡æ€æç¤ºæƒ…æ„Ÿç¼–ç å™¨ï¼Œç”¨äºä»ä¸åŒæç¤ºä¸­æå–æƒ…æ„Ÿä¿¡æ¯ã€‚</li>
<li>å¼•å…¥è¯­è°ƒé¢„æµ‹å™¨ï¼Œä»¥æ‹Ÿåˆè¯­è°ƒåˆ†å¸ƒã€‚</li>
<li>é€šè¿‡æƒ…æ„Ÿä¸€è‡´æ€§æŸå¤±æŠ€æœ¯ï¼Œä¿ç•™é¢„æµ‹è¯­è°ƒä¸­çš„æƒ…æ„Ÿä¿¡æ¯ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.18453">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-b4666f75b86335808f947b1012a1c8d6.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-13cfbff8c4ae704addf722e6005ca63c.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-054686241ca34c4fac9a0d598f54e6f3.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-33ef319d09b325e3f34d8353e754d4cb.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="OpenOmni-Advancing-Open-Source-Omnimodal-Large-Language-Models-with-Progressive-Multimodal-Alignment-and-Real-Time-Self-Aware-Emotional-Speech-Synthesis"><a href="#OpenOmni-Advancing-Open-Source-Omnimodal-Large-Language-Models-with-Progressive-Multimodal-Alignment-and-Real-Time-Self-Aware-Emotional-Speech-Synthesis" class="headerlink" title="OpenOmni: Advancing Open-Source Omnimodal Large Language Models with   Progressive Multimodal Alignment and Real-Time Self-Aware Emotional Speech   Synthesis"></a>OpenOmni: Advancing Open-Source Omnimodal Large Language Models with   Progressive Multimodal Alignment and Real-Time Self-Aware Emotional Speech   Synthesis</h2><p><strong>Authors:Run Luo, Ting-En Lin, Haonan Zhang, Yuchuan Wu, Xiong Liu, Min Yang, Yongbin Li, Longze Chen, Jiaming Li, Lei Zhang, Yangyi Chen, Xiaobo Xia, Hamid Alinejad-Rokny, Fei Huang</strong></p>
<p>Recent advancements in omnimodal learning have significantly improved understanding and generation across images, text, and speech, yet these developments remain predominantly confined to proprietary models. The lack of high-quality omnimodal datasets and the challenges of real-time emotional speech synthesis have notably hindered progress in open-source research. To address these limitations, we introduce \name, a two-stage training framework that integrates omnimodal alignment and speech generation to develop a state-of-the-art omnimodal large language model. In the alignment phase, a pre-trained speech model undergoes further training on text-image tasks, enabling (near) zero-shot generalization from vision to speech, outperforming models trained on tri-modal datasets. In the speech generation phase, a lightweight decoder is trained on speech tasks with direct preference optimization, enabling real-time emotional speech synthesis with high fidelity. Experiments show that \name surpasses state-of-the-art models across omnimodal, vision-language, and speech-language benchmarks. It achieves a 4-point absolute improvement on OmniBench over the leading open-source model VITA, despite using 5x fewer training samples and a smaller model size (7B vs. 7x8B). Additionally, \name achieves real-time speech generation with &lt;1s latency at non-autoregressive mode, reducing inference time by 5x compared to autoregressive methods, and improves emotion classification accuracy by 7.7% </p>
<blockquote>
<p>è™½ç„¶è¿‘æœŸå¤šæ¨¡æ€å­¦ä¹ çš„è¿›å±•åœ¨å›¾åƒã€æ–‡æœ¬å’Œè¯­éŸ³çš„ç†è§£ä¸ç”Ÿæˆæ–¹é¢æœ‰äº†æ˜¾è‘—æå‡ï¼Œä½†è¿™äº›å‘å±•ä¸»è¦å±€é™äºä¸“æœ‰æ¨¡å‹ã€‚ç¼ºä¹é«˜è´¨é‡çš„å¤šæ¨¡æ€æ•°æ®é›†ä»¥åŠå®æ—¶æƒ…æ„Ÿè¯­éŸ³åˆæˆçš„æŒ‘æˆ˜ï¼Œæ˜¾è‘—é˜»ç¢äº†å¼€æºç ”ç©¶çš„è¿›å±•ã€‚ä¸ºäº†è§£å†³è¿™äº›é™åˆ¶ï¼Œæˆ‘ä»¬å¼•å…¥äº†åä¸ºâ€œXXâ€çš„ä¸¤é˜¶æ®µè®­ç»ƒæ¡†æ¶ï¼Œè¯¥æ¡†æ¶èåˆäº†å¤šæ¨¡æ€å¯¹é½å’Œè¯­éŸ³ç”Ÿæˆï¼Œä»¥å¼€å‘å…ˆè¿›çš„å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ã€‚åœ¨å¯¹é½é˜¶æ®µï¼Œé¢„è®­ç»ƒçš„è¯­éŸ³æ¨¡å‹åœ¨æ–‡æœ¬-å›¾åƒä»»åŠ¡ä¸Šæ¥å—è¿›ä¸€æ­¥è®­ç»ƒï¼Œå®ç°äº†ä»è§†è§‰åˆ°è¯­éŸ³çš„ï¼ˆæ¥è¿‘ï¼‰é›¶æ ·æœ¬æ³›åŒ–ï¼Œè¶…è¶Šäº†é‚£äº›åœ¨ä¸‰å…ƒæ¨¡æ€æ•°æ®é›†ä¸Šè®­ç»ƒçš„æ¨¡å‹ã€‚åœ¨è¯­éŸ³ç”Ÿæˆé˜¶æ®µï¼Œä¸€ä¸ªè½»é‡çº§çš„è§£ç å™¨åœ¨è¯­éŸ³ä»»åŠ¡ä¸Šè¿›è¡Œç›´æ¥åå¥½ä¼˜åŒ–è®­ç»ƒï¼Œèƒ½å¤Ÿå®ç°é«˜ä¿çœŸåº¦çš„å®æ—¶æƒ…æ„Ÿè¯­éŸ³åˆæˆã€‚å®éªŒè¡¨æ˜ï¼Œâ€œXXâ€åœ¨å¤šæ¨¡æ€ã€è§†è§‰è¯­è¨€å’Œè¯­éŸ³è¯­è¨€åŸºå‡†æµ‹è¯•ä¸­è¶…è¶Šäº†æœ€å…ˆè¿›çš„æ¨¡å‹ã€‚å°½ç®¡ä½¿ç”¨äº†è¾ƒå°‘çš„è®­ç»ƒæ ·æœ¬å’Œè¾ƒå°çš„æ¨¡å‹è§„æ¨¡ï¼ˆ7B vs. 7x8Bï¼‰ï¼Œä½†åœ¨OmniBenchä¸Šç›¸å¯¹äºé¢†å…ˆçš„å¼€æºæ¨¡å‹VITAä»æœ‰4ä¸ªç»å¯¹ç‚¹çš„æ”¹è¿›ã€‚æ­¤å¤–ï¼Œâ€œXXâ€åœ¨éè‡ªå›å½’æ¨¡å¼ä¸‹å®ç°äº†å®æ—¶è¯­éŸ³ç”Ÿæˆï¼Œå»¶è¿Ÿæ—¶é—´å°äº1ç§’ï¼Œä¸è‡ªå›å½’æ–¹æ³•ç›¸æ¯”å‡å°‘äº†5å€çš„æ¨ç†æ—¶é—´ï¼Œå¹¶æé«˜äº†æƒ…æ„Ÿåˆ†ç±»å‡†ç¡®ç‡7. é™¤æ­¤ä¹‹å¤–ï¼Œâ€œXXâ€åœ¨éè‡ªå›å½’æ¨¡å¼ä¸‹å®ç°äº†å®æ—¶è¯­éŸ³ç”Ÿæˆï¼Œå»¶è¿Ÿæ—¶é—´ä½äºæ¯ç§’ä¸€å¸§ï¼ˆå°äº1ç§’ï¼‰ï¼Œç›¸è¾ƒäºè‡ªå›å½’æ–¹æ³•å‡å°‘äº†äº”å€çš„æ¨ç†æ—¶é—´ï¼Œå¹¶æå‡äº†æƒ…æ„Ÿåˆ†ç±»å‡†ç¡®ç‡è‡³ç™¾åˆ†ä¹‹ä¸ƒç‚¹ä¸ƒã€‚è¿™æ˜¯ä¸€ä¸ªåœ¨å¤šæ¨¡æ€èåˆé¢†åŸŸçš„é‡è¦çªç ´ï¼Œæœ‰æœ›ä¸ºæœªæ¥çš„ç ”ç©¶å’Œåº”ç”¨å¼€è¾Ÿæ–°çš„é“è·¯ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.04561v5">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>è¿‘æœŸå¤šæ¨¡æ€å­¦ä¹ é¢†åŸŸçš„è¿›å±•åœ¨å›¾åƒã€æ–‡æœ¬å’Œè¯­éŸ³çš„ç†è§£ä¸ç”Ÿæˆæ–¹é¢å–å¾—äº†æ˜¾è‘—æˆæœï¼Œä½†ä¸»è¦å±€é™äºä¸“æœ‰æ¨¡å‹ã€‚ç¼ºä¹é«˜è´¨é‡çš„å¤šæ¨¡æ€æ•°æ®é›†ä»¥åŠå®æ—¶æƒ…æ„Ÿè¯­éŸ³åˆæˆçš„æŒ‘æˆ˜é™åˆ¶äº†å¼€æºç ”ç©¶çš„è¿›å±•ã€‚ä¸ºè§£å†³è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬æ¨å‡ºäº†åä¸ºâ€œåç§°â€çš„ä¸¤é˜¶æ®µè®­ç»ƒæ¡†æ¶ï¼Œå®ƒèåˆäº†å¤šæ¨¡æ€å¯¹é½å’Œè¯­éŸ³ç”Ÿæˆï¼Œä»¥å¼€å‘å…ˆè¿›çš„å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ã€‚â€œåç§°â€åŒ…å«å¯¹é½é˜¶æ®µå’Œè¯­éŸ³ç”Ÿæˆé˜¶æ®µï¼Œé€šè¿‡å¯¹é¢„è®­ç»ƒè¯­éŸ³æ¨¡å‹è¿›è¡Œæ–‡æœ¬-å›¾åƒä»»åŠ¡çš„è¿›ä¸€æ­¥è®­ç»ƒï¼Œå®ç°äº†ä»è§†è§‰åˆ°è¯­éŸ³çš„é›¶æ ·æœ¬æˆ–è¿‘ä¼¼é›¶æ ·æœ¬æ³›åŒ–ï¼Œå¹¶åœ¨ä¸‰æ¨¡æ€æ•°æ®é›†ä¸Šè¡¨ç°å‡ºä¼˜è¶Šæ€§èƒ½ã€‚åœ¨è¯­éŸ³ç”Ÿæˆé˜¶æ®µï¼Œä½¿ç”¨è½»é‡çº§è§£ç å™¨è¿›è¡Œè¯­éŸ³ä»»åŠ¡çš„ç›´æ¥åå¥½ä¼˜åŒ–è®­ç»ƒï¼Œå®ç°äº†é«˜ä¿çœŸåº¦çš„å®æ—¶æƒ…æ„Ÿè¯­éŸ³åˆæˆã€‚å®éªŒè¡¨æ˜ï¼Œâ€œåç§°â€åœ¨å¤šæ¨¡æ€ã€è§†è§‰è¯­è¨€å’Œè¯­éŸ³è¯­è¨€åŸºå‡†æµ‹è¯•ä¸­è¶…è¶Šäº†ç°æœ‰æŠ€æœ¯æœ€å…ˆè¿›çš„æ¨¡å‹ã€‚ç›¸è¾ƒäºé¢†å…ˆçš„å¼€æºæ¨¡å‹VITAï¼Œâ€œåç§°â€åœ¨OmniBenchä¸Šå®ç°äº†4ä¸ªç‚¹çš„ç»å¯¹æ”¹è¿›ï¼Œå°½ç®¡å…¶ä½¿ç”¨çš„è®­ç»ƒæ ·æœ¬æ•°é‡æ›´å°‘ï¼ˆ5å€ï¼‰ï¼Œæ¨¡å‹è§„æ¨¡ä¹Ÿæ›´å°ï¼ˆ7Bå¯¹7x8Bï¼‰ã€‚æ­¤å¤–ï¼Œâ€œåç§°â€å®ç°äº†éè‡ªå›å½’æ¨¡å¼ä¸‹çš„å®æ—¶è¯­éŸ³ç”Ÿæˆï¼Œå»¶è¿Ÿæ—¶é—´å°äº1ç§’ï¼Œä¸è‡ªå›å½’æ–¹æ³•ç›¸æ¯”ï¼Œæ¨ç†æ—¶é—´ç¼©çŸ­äº†5å€ï¼Œæƒ…æ„Ÿåˆ†ç±»å‡†ç¡®ç‡æé«˜äº†7.7%ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>â€œåç§°â€æ˜¯ä¸€ä¸ªä¸¤é˜¶æ®µçš„å¤šæ¨¡æ€è®­ç»ƒæ¡†æ¶ï¼Œç”¨äºå¼€å‘å…ˆè¿›çš„å¤§å‹è¯­è¨€æ¨¡å‹ã€‚</li>
<li>å¯¹é½é˜¶æ®µé€šè¿‡æ–‡æœ¬-å›¾åƒä»»åŠ¡è¿›ä¸€æ­¥è®­ç»ƒé¢„è®­ç»ƒè¯­éŸ³æ¨¡å‹ï¼Œå®ç°è§†è§‰åˆ°è¯­éŸ³çš„æ³›åŒ–ã€‚</li>
<li>åœ¨å¯¹é½é˜¶æ®µï¼Œâ€œåç§°â€è¡¨ç°ä¼˜äºä¸‰æ¨¡æ€æ•°æ®é›†ä¸Šçš„æ¨¡å‹ã€‚</li>
<li>è¯­éŸ³ç”Ÿæˆé˜¶æ®µä½¿ç”¨è½»é‡çº§è§£ç å™¨è¿›è¡Œç›´æ¥åå¥½ä¼˜åŒ–è®­ç»ƒï¼Œå®ç°å®æ—¶æƒ…æ„Ÿè¯­éŸ³åˆæˆã€‚</li>
<li>â€œåç§°â€åœ¨å¤šæ¨¡æ€åŸºå‡†æµ‹è¯•ä¸­è¡¨ç°å‡ºå“è¶Šæ€§èƒ½ï¼Œè¶…è¶Šäº†ç°æœ‰æŠ€æœ¯æœ€å…ˆè¿›çš„æ¨¡å‹ã€‚</li>
<li>â€œåç§°â€ç›¸è¾ƒäºå…¶ä»–æ¨¡å‹ä½¿ç”¨æ›´å°‘çš„è®­ç»ƒæ ·æœ¬å’Œæ›´å°çš„æ¨¡å‹è§„æ¨¡å–å¾—äº†ä¼˜è¶Šçš„æ€§èƒ½ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.04561">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-16c81dab5d028e236ea1e0b0150e022d.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-690a783941b225a014971a58607274a4.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-d06601ddbc306c7eb36f84b79e6c22f3.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-595bb46727c5f970cd56721b57c8389d.jpg" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="vec2wav-2-0-Advancing-Voice-Conversion-via-Discrete-Token-Vocoders"><a href="#vec2wav-2-0-Advancing-Voice-Conversion-via-Discrete-Token-Vocoders" class="headerlink" title="vec2wav 2.0: Advancing Voice Conversion via Discrete Token Vocoders"></a>vec2wav 2.0: Advancing Voice Conversion via Discrete Token Vocoders</h2><p><strong>Authors:Yiwei Guo, Zhihan Li, Junjie Li, Chenpeng Du, Hankun Wang, Shuai Wang, Xie Chen, Kai Yu</strong></p>
<p>We propose a new speech discrete token vocoder, vec2wav 2.0, which advances voice conversion (VC). We use discrete tokens from speech self-supervised models as the content features of source speech, and treat VC as a prompted vocoding task. To amend the loss of speaker timbre in the content tokens, vec2wav 2.0 utilizes the WavLM features to provide strong timbre-dependent information. A novel adaptive Snake activation function is proposed to better incorporate timbre into the waveform reconstruction process. In this way, vec2wav 2.0 learns to alter the speaker timbre appropriately given different reference prompts. Also, no supervised data is required for vec2wav 2.0 to be effectively trained. Experimental results demonstrate that vec2wav 2.0 outperforms all other baselines to a considerable margin in terms of audio quality and speaker similarity in any-to-any VC. Ablation studies verify the effects made by the proposed techniques. Moreover, vec2wav 2.0 achieves competitive cross-lingual VC even only trained on monolingual corpus. Thus, vec2wav 2.0 shows timbre can potentially be manipulated only by speech token vocoders, pushing the frontiers of VC and speech synthesis. </p>
<blockquote>
<p>æˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°çš„è¯­éŸ³ç¦»æ•£ä»¤ç‰Œç¼–ç å™¨ï¼Œvec2wav 2.0ï¼Œå®ƒæ¨è¿›äº†è¯­éŸ³è½¬æ¢ï¼ˆVCï¼‰çš„æŠ€æœ¯ã€‚æˆ‘ä»¬ä½¿ç”¨è¯­éŸ³è‡ªç›‘ç£æ¨¡å‹çš„ç¦»æ•£ä»¤ç‰Œä½œä¸ºæºè¯­éŸ³çš„å†…å®¹ç‰¹å¾ï¼Œå¹¶å°†VCè§†ä¸ºä¸€ä¸ªæç¤ºæ€§çš„ç¼–ç ä»»åŠ¡ã€‚ä¸ºäº†å¼¥è¡¥å†…å®¹ä»¤ç‰Œä¸­è¯´è¯è€…éŸ³è‰²çš„æŸå¤±ï¼Œvec2wav 2.0åˆ©ç”¨WavLMç‰¹å¾æä¾›å¼ºå¤§çš„éŸ³è‰²ç›¸å…³ä¿¡æ¯ã€‚æå‡ºäº†ä¸€ç§æ–°å‹çš„è‡ªé€‚åº”Snakeæ¿€æ´»å‡½æ•°ï¼Œä»¥æ›´å¥½åœ°å°†éŸ³è‰²èå…¥æ³¢å½¢é‡å»ºè¿‡ç¨‹ã€‚é€šè¿‡è¿™ç§æ–¹å¼ï¼Œvec2wav 2.0èƒ½å¤Ÿåœ¨ç»™å®šä¸åŒçš„å‚è€ƒæç¤ºçš„æƒ…å†µä¸‹ï¼Œå­¦ä¼šé€‚å½“åœ°æ”¹å˜è¯´è¯è€…çš„éŸ³è‰²ã€‚æ­¤å¤–ï¼Œä¸éœ€è¦ç›‘ç£æ•°æ®æ¥æœ‰æ•ˆåœ°è®­ç»ƒvec2wav 2.0ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œåœ¨ä»»æ„åˆ°ä»»æ„çš„VCä¸­ï¼Œvec2wav 2.0åœ¨éŸ³é¢‘è´¨é‡å’Œè¯´è¯è€…ç›¸ä¼¼æ€§æ–¹é¢å¤§å¤§ä¼˜äºæ‰€æœ‰å…¶ä»–åŸºçº¿ã€‚æ¶ˆèç ”ç©¶éªŒè¯äº†æ‰€æå‡ºæŠ€æœ¯çš„æ•ˆæœã€‚æ­¤å¤–ï¼Œvec2wav 2.0å³ä½¿åœ¨ä»…ä½¿ç”¨å•è¯­è¯­æ–™åº“è¿›è¡Œè®­ç»ƒçš„æƒ…å†µä¸‹ï¼Œä¹Ÿå®ç°äº†å…·æœ‰ç«äº‰åŠ›çš„è·¨è¯­è¨€VCã€‚å› æ­¤ï¼Œvec2wav 2.0è¡¨æ˜ï¼ŒéŸ³è‰²å¯èƒ½ä»…é€šè¿‡è¯­éŸ³ä»¤ç‰Œç¼–ç å™¨è¿›è¡Œæ“çºµï¼Œä»è€Œæ¨åŠ¨äº†VCå’Œè¯­éŸ³åˆæˆçš„è¾¹ç•Œã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2409.01995v4">PDF</a> 5 pages, 3 figures, 2 tables. Demo page:   <a target="_blank" rel="noopener" href="https://cantabile-kwok.github.io/vec2wav2/">https://cantabile-kwok.github.io/vec2wav2/</a></p>
<p><strong>Summary</strong></p>
<p>åŸºäºç¦»æ•£ä»¤ç‰Œçš„æ–°è¯­éŸ³ç¦»æ•£ä»¤ç‰Œç¼–è§£ç å™¨vec2wav 2.0çš„æå‡ºæ¨åŠ¨äº†è¯­éŸ³è½¬æ¢ï¼ˆVCï¼‰çš„è¿›æ­¥ã€‚è¯¥ç¼–è§£ç å™¨ä½¿ç”¨è¯­éŸ³è‡ªç›‘ç£æ¨¡å‹çš„ç¦»æ•£ä»¤ç‰Œä½œä¸ºæºè¯­éŸ³çš„å†…å®¹ç‰¹å¾ï¼Œå¹¶å°†VCè§†ä¸ºæç¤ºç¼–è§£ç ä»»åŠ¡ã€‚ä¸ºäº†å¼¥è¡¥å†…å®¹ä»¤ç‰Œä¸­çš„è¯´è¯è€…éŸ³è‰²æŸå¤±ï¼Œvec2wav 2.0åˆ©ç”¨WavLMç‰¹å¾æä¾›å¼ºå¤§çš„éŸ³è‰²ç›¸å…³ä¿¡æ¯ã€‚æ­¤å¤–ï¼Œæå‡ºäº†ä¸€ç§æ–°çš„è‡ªé€‚åº”Snakeæ¿€æ´»å‡½æ•°ï¼Œä»¥æ›´å¥½åœ°å°†éŸ³è‰²èå…¥æ³¢å½¢é‡å»ºè¿‡ç¨‹ã€‚å› æ­¤ï¼Œvec2wav 2.0èƒ½å¤Ÿåœ¨ç»™å®šä¸åŒå‚è€ƒæç¤ºçš„æƒ…å†µä¸‹å­¦ä¹ é€‚å½“åœ°æ”¹å˜è¯´è¯è€…çš„éŸ³è‰²ã€‚æ­¤å¤–ï¼Œè®­ç»ƒvec2wav 2.0æ— éœ€ç›‘ç£æ•°æ®ã€‚å®éªŒç»“æœè¯æ˜ï¼Œåœ¨ä»»æ„åˆ°ä»»æ„çš„VCä¸­ï¼Œvec2wav 2.0åœ¨éŸ³é¢‘è´¨é‡å’Œè¯´è¯è€…ç›¸ä¼¼æ€§æ–¹é¢éƒ½å¤§å¤§ä¼˜äºæ‰€æœ‰å…¶ä»–åŸºçº¿ã€‚æ¶ˆèç ”ç©¶éªŒè¯äº†æ‰€æå‡ºæŠ€æœ¯çš„æ•ˆæœã€‚è€Œä¸”ï¼Œå³ä½¿åœ¨ä»…ä½¿ç”¨å•è¯­è¯­æ–™åº“è¿›è¡Œè®­ç»ƒçš„æƒ…å†µä¸‹ï¼Œvec2wav 2.0ä¹Ÿèƒ½å®ç°è·¨è¯­è¨€VCçš„ç«äº‰æ€§èƒ½ã€‚å› æ­¤ï¼Œvec2wav 2.0æ˜¾ç¤ºäº†éŸ³è‰²ä»…é€šè¿‡è¯­éŸ³ä»¤ç‰Œç¼–è§£ç å™¨è¿›è¡Œæ“ä½œçš„å¯èƒ½æ€§ï¼Œæ¨åŠ¨äº†VCå’Œè¯­éŸ³åˆæˆçš„å‰æ²¿ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>vec2wav 2.0æ˜¯ä¸€ç§æ–°çš„è¯­éŸ³ç¦»æ•£ä»¤ç‰Œç¼–è§£ç å™¨ï¼Œç”¨äºæ¨åŠ¨è¯­éŸ³è½¬æ¢çš„è¿›æ­¥ã€‚</li>
<li>å®ƒä½¿ç”¨è¯­éŸ³è‡ªç›‘ç£æ¨¡å‹çš„ç¦»æ•£ä»¤ç‰Œä½œä¸ºæºè¯­éŸ³çš„å†…å®¹ç‰¹å¾ï¼Œå¹¶å°†è¯­éŸ³è½¬æ¢è§†ä¸ºæç¤ºç¼–è§£ç ä»»åŠ¡ã€‚</li>
<li>WavLMç‰¹å¾ç”¨äºæä¾›å¼ºå¤§çš„éŸ³è‰²ç›¸å…³ä¿¡æ¯ï¼Œä»¥å¼¥è¡¥å†…å®¹ä»¤ç‰Œä¸­çš„éŸ³è‰²æŸå¤±ã€‚</li>
<li>å¼•å…¥äº†ä¸€ç§æ–°çš„è‡ªé€‚åº”Snakeæ¿€æ´»å‡½æ•°ï¼Œä»¥æ”¹å–„éŸ³è‰²åœ¨æ³¢å½¢é‡å»ºè¿‡ç¨‹ä¸­çš„èå…¥ã€‚</li>
<li>vec2wav 2.0èƒ½å¤Ÿåœ¨ç»™å®šä¸åŒå‚è€ƒæç¤ºçš„æƒ…å†µä¸‹å­¦ä¹ æ”¹å˜è¯´è¯è€…çš„éŸ³è‰²ï¼Œä¸”æ— éœ€ç›‘ç£æ•°æ®ã€‚</li>
<li>åœ¨éŸ³é¢‘è´¨é‡å’Œè¯´è¯è€…ç›¸ä¼¼æ€§æ–¹é¢ï¼Œvec2wav 2.0æ˜¾è‘—ä¼˜äºå…¶ä»–æ–¹æ³•ï¼Œå®ç°äº†æœ‰ç«äº‰åŠ›çš„è·¨è¯­è¨€è¯­éŸ³è½¬æ¢æ€§èƒ½ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2409.01995">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-e78a920ce223f857f99cd837f97b6e22.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-0dfbfcbfff0492ae7e8ff36449502800.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-73a8dbd51459bb3ece0c9e06d1c5fa46.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c347f8ab3f3ce7bc6cbfd7bb007d8826.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-851ed10c7811817f3a679b63f4c422bb.jpg" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-05-28/TTS/">https://kedreamix.github.io/Talk2Paper/Paper/2025-05-28/TTS/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/TTS/">
                                    <span class="chip bg-color">TTS</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-05-28/Interactive/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-05a2bb620386588e4b17c42f9dcfe475.jpg" class="responsive-img" alt="Interactive">
                        
                        <span class="card-title">Interactive</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Interactive æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-05-28  LeCoDe A Benchmark Dataset for Interactive Legal Consultation Dialogue   Evaluation
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-05-28
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Interactive/" class="post-category">
                                    Interactive
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Interactive/">
                        <span class="chip bg-color">Interactive</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-05-28/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-008555b808d4437acca293ee2013d487.jpg" class="responsive-img" alt="åŒ»å­¦å›¾åƒ">
                        
                        <span class="card-title">åŒ»å­¦å›¾åƒ</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            åŒ»å­¦å›¾åƒ æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-05-28  Deep Spectral Prior
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-05-28
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/" class="post-category">
                                    åŒ»å­¦å›¾åƒ
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/">
                        <span class="chip bg-color">åŒ»å­¦å›¾åƒ</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">26384.1k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
