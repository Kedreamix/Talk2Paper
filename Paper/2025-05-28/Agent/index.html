<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Agent">
    <meta name="description" content="Agent æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-05-28  Iterative Self-Incentivization Empowers Large Language Models as Agentic   Searchers">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>Agent | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://picx.zhimg.com/v2-f7c9531ab7a4ed8d9c82292f41ece53a.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Agent</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/Agent/">
                                <span class="chip bg-color">Agent</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/Agent/" class="post-category">
                                Agent
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-05-28
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-06-24
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    15.1k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    61 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-05-28-æ›´æ–°"><a href="#2025-05-28-æ›´æ–°" class="headerlink" title="2025-05-28 æ›´æ–°"></a>2025-05-28 æ›´æ–°</h1><h2 id="Iterative-Self-Incentivization-Empowers-Large-Language-Models-as-Agentic-Searchers"><a href="#Iterative-Self-Incentivization-Empowers-Large-Language-Models-as-Agentic-Searchers" class="headerlink" title="Iterative Self-Incentivization Empowers Large Language Models as Agentic   Searchers"></a>Iterative Self-Incentivization Empowers Large Language Models as Agentic   Searchers</h2><p><strong>Authors:Zhengliang Shi, Lingyong Yan, Dawei Yin, Suzan Verberne, Maarten de Rijke, Zhaochun Ren</strong></p>
<p>Large language models (LLMs) have been widely integrated into information retrieval to advance traditional techniques. However, effectively enabling LLMs to seek accurate knowledge in complex tasks remains a challenge due to the complexity of multi-hop queries as well as the irrelevant retrieved content. To address these limitations, we propose EXSEARCH, an agentic search framework, where the LLM learns to retrieve useful information as the reasoning unfolds through a self-incentivized process. At each step, the LLM decides what to retrieve (thinking), triggers an external retriever (search), and extracts fine-grained evidence (recording) to support next-step reasoning. To enable LLM with this capability, EXSEARCH adopts a Generalized Expectation-Maximization algorithm. In the E-step, the LLM generates multiple search trajectories and assigns an importance weight to each; the M-step trains the LLM on them with a re-weighted loss function. This creates a self-incentivized loop, where the LLM iteratively learns from its own generated data, progressively improving itself for search. We further theoretically analyze this training process, establishing convergence guarantees. Extensive experiments on four knowledge-intensive benchmarks show that EXSEARCH substantially outperforms baselines, e.g., +7.8% improvement on exact match score. Motivated by these promising results, we introduce EXSEARCH-Zoo, an extension that extends our method to broader scenarios, to facilitate future work. </p>
<blockquote>
<p>å¤§è§„æ¨¡è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å·²ç»å¹¿æ³›åº”ç”¨äºä¿¡æ¯æ£€ç´¢ï¼Œä»¥æ¨åŠ¨ä¼ ç»ŸæŠ€æœ¯çš„å‘å±•ã€‚ç„¶è€Œï¼Œç”±äºå¤šè·³æŸ¥è¯¢çš„å¤æ‚æ€§å’Œæ£€ç´¢å†…å®¹çš„æ— å…³æ€§ï¼Œæœ‰æ•ˆåœ°ä½¿LLMåœ¨å¤æ‚ä»»åŠ¡ä¸­å¯»æ‰¾å‡†ç¡®çŸ¥è¯†ä»ç„¶æ˜¯ä¸€ä¸ªæŒ‘æˆ˜ã€‚ä¸ºäº†è§£å†³è¿™äº›å±€é™æ€§ï¼Œæˆ‘ä»¬æå‡ºäº†EXSEARCHï¼Œä¸€ä¸ªæ™ºèƒ½æœç´¢æ¡†æ¶ï¼ŒLLMåœ¨æ­¤æ¡†æ¶ä¸­å­¦ä¹ æ£€ç´¢ä¸æ¨ç†è¿‡ç¨‹ä¸­å±•å¼€çš„æœ‰ç”¨ä¿¡æ¯ï¼Œè¿™é€šè¿‡è‡ªæˆ‘æ¿€åŠ±çš„è¿‡ç¨‹å®ç°ã€‚åœ¨æ¯ä¸ªæ­¥éª¤ä¸­ï¼ŒLLMå†³å®šè¦æ£€ç´¢ä»€ä¹ˆï¼ˆæ€è€ƒï¼‰ï¼Œè§¦å‘å¤–éƒ¨æ£€ç´¢å™¨ï¼ˆæœç´¢ï¼‰ï¼Œå¹¶æå–ç²¾ç»†çš„è¯æ®ï¼ˆè®°å½•ï¼‰ä»¥æ”¯æŒä¸‹ä¸€æ­¥çš„æ¨ç†ã€‚ä¸ºäº†å®ç°LLMçš„è¿™ä¸€èƒ½åŠ›ï¼ŒEXSEARCHé‡‡ç”¨äº†å¹¿ä¹‰æœŸæœ›æœ€å¤§åŒ–ç®—æ³•ã€‚åœ¨Eæ­¥ä¸­ï¼ŒLLMç”Ÿæˆå¤šä¸ªæœç´¢è½¨è¿¹å¹¶ä¸ºæ¯ä¸ªè½¨è¿¹åˆ†é…é‡è¦æ€§æƒé‡ï¼›åœ¨Mæ­¥ä¸­ï¼Œä½¿ç”¨åŠ æƒæŸå¤±å‡½æ•°å¯¹LLMè¿›è¡Œè®­ç»ƒã€‚è¿™åˆ›å»ºäº†ä¸€ä¸ªè‡ªæˆ‘æ¿€åŠ±çš„å¾ªç¯ï¼ŒLLMä»ä¸­ä¸æ–­è‡ªæˆ‘ç”Ÿæˆçš„æ•°æ®ä¸­å­¦ä¹ ï¼Œé€æ­¥æ”¹è¿›è‡ªèº«çš„æœç´¢èƒ½åŠ›ã€‚æˆ‘ä»¬è¿›ä¸€æ­¥ä»ç†è®ºä¸Šåˆ†æäº†è¿™ä¸€è®­ç»ƒè¿‡ç¨‹ï¼Œå»ºç«‹äº†æ”¶æ•›æ€§ä¿è¯ã€‚åœ¨å››ä¸ªçŸ¥è¯†å¯†é›†å‹åŸºå‡†æµ‹è¯•ä¸Šçš„å¤§é‡å®éªŒè¡¨æ˜ï¼ŒEXSEARCHæ˜¾è‘—ä¼˜äºåŸºçº¿æ–¹æ³•ï¼Œä¾‹å¦‚åœ¨ç²¾ç¡®åŒ¹é…å¾—åˆ†ä¸Šæœ‰+7.8%çš„æ”¹è¿›ã€‚å—è¿™äº›ä»¤äººé¼“èˆçš„ç»“æœçš„é©±åŠ¨ï¼Œæˆ‘ä»¬å°†EXSEARCH-Zooä½œä¸ºæˆ‘ä»¬æ–¹æ³•çš„æ‰©å±•ä»‹ç»ç»™æ›´å¹¿æ³›çš„åœºæ™¯ï¼Œä»¥ä¿ƒè¿›æœªæ¥çš„å·¥ä½œã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.20128v1">PDF</a> Working in process</p>
<p><strong>Summary</strong></p>
<p>å¤§å‹è¯­è¨€æ¨¡å‹åœ¨ä¿¡æ¯æ£€ç´¢é¢†åŸŸçš„åº”ç”¨è™½å¹¿æ³›ï¼Œä½†åœ¨å¤æ‚ä»»åŠ¡ä¸­å‡†ç¡®å¯»æ‰¾çŸ¥è¯†ä»å­˜åœ¨æŒ‘æˆ˜ï¼Œå¦‚å¤šè·³æŸ¥è¯¢çš„å¤æ‚æ€§å’Œæ£€ç´¢å†…å®¹çš„æ— å…³æ€§ã€‚ä¸ºè§£å†³è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºEXSEARCHï¼Œä¸€ç§ä»£ç†æœç´¢æ¡†æ¶ï¼Œè®©è¯­è¨€æ¨¡å‹åœ¨æ¨ç†è¿‡ç¨‹ä¸­å­¦ä¹ æ£€ç´¢æœ‰ç”¨ä¿¡æ¯ï¼Œå½¢æˆè‡ªæˆ‘æ¿€åŠ±å¾ªç¯ã€‚EXSEARCHé‡‡ç”¨å¹¿ä¹‰æœŸæœ›æœ€å¤§åŒ–ç®—æ³•ï¼Œåœ¨Eæ­¥ç”Ÿæˆå¤šä¸ªæœç´¢è½¨è¿¹å¹¶èµ‹äºˆæƒé‡ï¼ŒMæ­¥ç”¨åŠ æƒæŸå¤±å‡½æ•°è®­ç»ƒæ¨¡å‹ã€‚æ­¤è¿‡ç¨‹ç†è®ºä¸Šæœ‰æ”¶æ•›ä¿éšœï¼Œåœ¨å››ä¸ªçŸ¥è¯†å¯†é›†å‹åŸºå‡†æµ‹è¯•ä¸Šçš„å®éªŒæ˜¾ç¤ºï¼ŒEXSEARCHå¤§å¹…ä¼˜äºåŸºçº¿æ–¹æ³•ï¼Œå¦‚ç²¾ç¡®åŒ¹é…å¾—åˆ†æé«˜7.8%ã€‚æˆ‘ä»¬åŸºäºæ­¤æˆæœæ¨å‡ºEXSEARCH-Zooï¼Œä»¥åº”å¯¹æ›´å¹¿æ³›åœºæ™¯ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤§å‹è¯­è¨€æ¨¡å‹åœ¨ä¿¡æ¯æ£€ç´¢ä¸­é¢ä¸´å¤šè·³æŸ¥è¯¢å¤æ‚æ€§å’Œæ£€ç´¢å†…å®¹æ— å…³æ€§çš„æŒ‘æˆ˜ã€‚</li>
<li>EXSEARCHæ˜¯ä¸€ç§ä»£ç†æœç´¢æ¡†æ¶ï¼Œé€šè¿‡è‡ªæˆ‘æ¿€åŠ±å¾ªç¯ä½¿è¯­è¨€æ¨¡å‹åœ¨æ¨ç†è¿‡ç¨‹ä¸­å­¦ä¹ æ£€ç´¢ä¿¡æ¯ã€‚</li>
<li>EXSEARCHé‡‡ç”¨å¹¿ä¹‰æœŸæœ›æœ€å¤§åŒ–ç®—æ³•ï¼ŒåŒ…æ‹¬ç”Ÿæˆæœç´¢è½¨è¿¹å’ŒåŠ æƒæŸå¤±å‡½æ•°è®­ç»ƒæ¨¡å‹ä¸¤ä¸ªä¸»è¦æ­¥éª¤ã€‚</li>
<li>EXSEARCHæœ‰ç†è®ºæ”¶æ•›ä¿éšœã€‚</li>
<li>åœ¨å››ä¸ªçŸ¥è¯†å¯†é›†å‹åŸºå‡†æµ‹è¯•ä¸Šï¼ŒEXSEARCHæ˜¾è‘—ä¼˜äºåŸºçº¿æ–¹æ³•ã€‚</li>
<li>EXSEARCH-Zooæ˜¯EXSEARCHçš„æ‰©å±•ï¼Œæ—¨åœ¨åº”å¯¹æ›´å¹¿æ³›çš„åœºæ™¯ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.20128">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-86669b1a9d305d6d6611c5913c886363.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b2772622b5e9865c5ff754058111d224.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-53695c74c404b00395e4e6fd90e061eb.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-52b04106ae4b967add0cc62d44008da5.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="MA-RAG-Multi-Agent-Retrieval-Augmented-Generation-via-Collaborative-Chain-of-Thought-Reasoning"><a href="#MA-RAG-Multi-Agent-Retrieval-Augmented-Generation-via-Collaborative-Chain-of-Thought-Reasoning" class="headerlink" title="MA-RAG: Multi-Agent Retrieval-Augmented Generation via Collaborative   Chain-of-Thought Reasoning"></a>MA-RAG: Multi-Agent Retrieval-Augmented Generation via Collaborative   Chain-of-Thought Reasoning</h2><p><strong>Authors:Thang Nguyen, Peter Chin, Yu-Wing Tai</strong></p>
<p>We present MA-RAG, a Multi-Agent framework for Retrieval-Augmented Generation (RAG) that addresses the inherent ambiguities and reasoning challenges in complex information-seeking tasks. Unlike conventional RAG methods that rely on either end-to-end fine-tuning or isolated component enhancements, MA-RAG orchestrates a collaborative set of specialized AI agents: Planner, Step Definer, Extractor, and QA Agents, to tackle each stage of the RAG pipeline with task-aware reasoning. Ambiguities may arise from underspecified queries, sparse or indirect evidence in retrieved documents, or the need to integrate information scattered across multiple sources. MA-RAG mitigates these challenges by decomposing the problem into subtasks, such as query disambiguation, evidence extraction, and answer synthesis, and dispatching them to dedicated agents equipped with chain-of-thought prompting. These agents communicate intermediate reasoning and progressively refine the retrieval and synthesis process. Our design allows fine-grained control over information flow without any model fine-tuning. Crucially, agents are invoked on demand, enabling a dynamic and efficient workflow that avoids unnecessary computation. This modular and reasoning-driven architecture enables MA-RAG to deliver robust, interpretable results. Experiments on multi-hop and ambiguous QA benchmarks demonstrate that MA-RAG outperforms state-of-the-art training-free baselines and rivals fine-tuned systems, validating the effectiveness of collaborative agent-based reasoning in RAG. </p>
<blockquote>
<p>æˆ‘ä»¬æå‡ºMA-RAGï¼Œè¿™æ˜¯ä¸€ä¸ªç”¨äºå¢å¼ºæ£€ç´¢ç”Ÿæˆï¼ˆRAGï¼‰çš„å¤šä»£ç†æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³å¤æ‚ä¿¡æ¯æ£€ç´¢ä»»åŠ¡ä¸­å›ºæœ‰çš„æ¨¡ç³Šæ€§å’Œæ¨ç†æŒ‘æˆ˜ã€‚ä¸åŒäºä¼ ç»Ÿçš„RAGæ–¹æ³•ï¼Œå®ƒä»¬ä¾èµ–äºç«¯åˆ°ç«¯çš„å¾®è°ƒæˆ–å­¤ç«‹çš„ç»„ä»¶å¢å¼ºï¼ŒMA-RAGååŒå·¥ä½œä¸€ç»„ä¸“ä¸šçš„AIä»£ç†ï¼šè®¡åˆ’ä»£ç†ã€æ­¥éª¤å®šä¹‰ä»£ç†ã€æå–ä»£ç†å’Œé—®ç­”ä»£ç†ï¼Œä»¥ä»»åŠ¡æ„ŸçŸ¥æ¨ç†è§£å†³RAGç®¡é“çš„æ¯ä¸ªé˜¶æ®µã€‚æ¨¡ç³Šæ€§å¯èƒ½æ¥è‡ªæœªæŒ‡å®šçš„æŸ¥è¯¢ã€æ£€ç´¢åˆ°çš„æ–‡æ¡£ä¸­çš„ç¨€ç–æˆ–é—´æ¥è¯æ®ï¼Œæˆ–éœ€è¦æ•´åˆæ¥è‡ªå¤šä¸ªæ¥æºçš„ä¿¡æ¯ã€‚MA-RAGé€šè¿‡å°†é—®é¢˜åˆ†è§£ä¸ºå­ä»»åŠ¡ï¼ˆå¦‚æŸ¥è¯¢æ¶ˆæ­§ã€è¯æ®æå–å’Œç­”æ¡ˆåˆæˆï¼‰ï¼Œå¹¶æ´¾é£å®ƒä»¬åˆ°é…å¤‡æ€ç»´é“¾æç¤ºçš„ä¸“ç”¨ä»£ç†æ¥ç¼“è§£è¿™äº›æŒ‘æˆ˜ã€‚è¿™äº›ä»£ç†æ²Ÿé€šä¸­é—´æ¨ç†å¹¶é€æ­¥æ”¹è¿›æ£€ç´¢å’Œåˆæˆè¿‡ç¨‹ã€‚æˆ‘ä»¬çš„è®¾è®¡å…è®¸å¯¹ä¿¡æ¯æµè¿›è¡Œç²¾ç»†æ§åˆ¶ï¼Œæ— éœ€ä»»ä½•æ¨¡å‹å¾®è°ƒã€‚æœ€é‡è¦çš„æ˜¯ï¼Œä»£ç†æ˜¯æŒ‰éœ€è°ƒç”¨çš„ï¼Œè¿™é¿å…äº†ä¸å¿…è¦è®¡ç®—çš„åŒæ—¶ï¼Œå®ç°äº†åŠ¨æ€é«˜æ•ˆçš„å·¥ä½œæµç¨‹ã€‚è¿™ç§æ¨¡å—åŒ–å’Œä»¥æ¨ç†é©±åŠ¨çš„ç»“æ„ä½¿å¾—MA-RAGèƒ½å¤Ÿæä¾›æ›´ç¨³å¥ã€å¯è§£é‡Šçš„ç»“æœã€‚åœ¨å¤šè·³å’Œæ¨¡ç³Šé—®ç­”åŸºå‡†æµ‹è¯•ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒMA-RAGä¼˜äºæœ€æ–°çš„æ— è®­ç»ƒåŸºå‡†çº¿å¹¶å¯ä¸å¾®è°ƒç³»ç»Ÿç›¸åª²ç¾ï¼Œè¿™éªŒè¯äº†åŸºäºä»£ç†çš„åä½œæ¨ç†åœ¨RAGä¸­çš„æœ‰æ•ˆæ€§ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.20096v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>MA-RAGæ˜¯ä¸€ä¸ªå¤šä»£ç†æ¡†æ¶ï¼Œç”¨äºå¢å¼ºæ£€ç´¢ç”Ÿæˆï¼ˆRAGï¼‰ï¼Œè§£å†³å¤æ‚ä¿¡æ¯æ£€ç´¢ä»»åŠ¡ä¸­çš„å›ºæœ‰æ¨¡ç³Šæ€§å’Œæ¨ç†æŒ‘æˆ˜ã€‚å®ƒé€šè¿‡åˆ†è§£é—®é¢˜ï¼Œå¹¶è°ƒåº¦ä¸“ä¸šä»£ç†å¤„ç†æ¯ä¸ªé˜¶æ®µçš„ä»»åŠ¡æ„ŸçŸ¥æ¨ç†ï¼Œä»è€Œè§£å†³äº†å¸¸è§„RAGæ–¹æ³•çš„é—®é¢˜ã€‚å®éªŒè¯æ˜ï¼ŒMA-RAGåœ¨å¤šè·³å’Œæ¨¡ç³Šé—®ç­”åŸºå‡†æµ‹è¯•ä¸­è¡¨ç°å‡ºè‰²ï¼ŒéªŒè¯äº†åŸºäºåä½œä»£ç†çš„æ¨ç†åœ¨RAGä¸­çš„æœ‰æ•ˆæ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>MA-RAGæ˜¯ä¸€ä¸ªå¤šä»£ç†æ¡†æ¶ï¼Œç”¨äºè§£å†³å¤æ‚ä¿¡æ¯æ£€ç´¢ä»»åŠ¡ä¸­çš„æ¨¡ç³Šæ€§å’Œæ¨ç†æŒ‘æˆ˜ã€‚</li>
<li>å®ƒé€šè¿‡åˆ†è§£é—®é¢˜ä¸ºå­ä»»åŠ¡ï¼Œå¦‚æŸ¥è¯¢å»æ¨¡ç³Šã€è¯æ®æå–å’Œç­”æ¡ˆåˆæˆï¼Œå¹¶æ´¾é£ä¸“ä¸šä»£ç†å¤„ç†ã€‚</li>
<li>MA-RAGé‡‡ç”¨é“¾å¼æ€ç»´æç¤ºï¼Œä»£ç†ä¹‹é—´è¿›è¡Œæ²Ÿé€šï¼Œé€æ­¥ä¼˜åŒ–æ£€ç´¢å’Œåˆæˆè¿‡ç¨‹ã€‚</li>
<li>è¯¥è®¾è®¡å…è®¸å¯¹ä¿¡æ¯æµè¿›è¡Œç²¾ç»†æ§åˆ¶ï¼Œæ— éœ€æ¨¡å‹å¾®è°ƒã€‚</li>
<li>ä»£ç†æŒ‰éœ€è°ƒç”¨ï¼Œå®ç°åŠ¨æ€é«˜æ•ˆçš„å·¥ä½œæµï¼Œé¿å…ä¸å¿…è¦çš„è®¡ç®—ã€‚</li>
<li>MA-RAGåœ¨å¤šäººè·³å’Œæ¨¡ç³Šé—®ç­”åŸºå‡†æµ‹è¯•ä¸­è¡¨ç°å‡ºè‰²ï¼Œè¯æ˜å…¶åœ¨RAGä¸­çš„æœ‰æ•ˆæ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.20096">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-133f097e14a6911446e88b95a5c2ffda.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b3a870ec682e45cc69ff848013d886c1.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-0b57f68a91fc9cd78c8efb0ccc19bea7.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-19709e05e98f05a442b726501b8a946e.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="WebCoT-Enhancing-Web-Agent-Reasoning-by-Reconstructing-Chain-of-Thought-in-Reflection-Branching-and-Rollback"><a href="#WebCoT-Enhancing-Web-Agent-Reasoning-by-Reconstructing-Chain-of-Thought-in-Reflection-Branching-and-Rollback" class="headerlink" title="WebCoT: Enhancing Web Agent Reasoning by Reconstructing Chain-of-Thought   in Reflection, Branching, and Rollback"></a>WebCoT: Enhancing Web Agent Reasoning by Reconstructing Chain-of-Thought   in Reflection, Branching, and Rollback</h2><p><strong>Authors:Minda Hu, Tianqing Fang, Jianshu Zhang, Junyu Ma, Zhisong Zhang, Jingyan Zhou, Hongming Zhang, Haitao Mi, Dong Yu, Irwin King</strong></p>
<p>Web agents powered by Large Language Models (LLMs) show promise for next-generation AI, but their limited reasoning in uncertain, dynamic web environments hinders robust deployment. In this paper, we identify key reasoning skills essential for effective web agents, i.e., reflection &amp; lookahead, branching, and rollback, and curate trajectory data that exemplifies these abilities by reconstructing the agentâ€™s (inference-time) reasoning algorithms into chain-of-thought rationales. We conduct experiments in the agent self-improving benchmark, OpenWebVoyager, and demonstrate that distilling salient reasoning patterns into the backbone LLM via simple fine-tuning can substantially enhance its performance. Our approach yields significant improvements across multiple benchmarks, including WebVoyager, Mind2web-live, and SimpleQA (web search), highlighting the potential of targeted reasoning skill enhancement for web agents. </p>
<blockquote>
<p>åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„Webä»£ç†å¯¹ä¸‹ä¸€ä»£äººå·¥æ™ºèƒ½æ˜¾ç¤ºå‡ºæ½œåŠ›ï¼Œä½†å®ƒä»¬åœ¨ä¸ç¡®å®šã€åŠ¨æ€ç½‘ç»œç¯å¢ƒä¸­æœ‰é™çš„æ¨ç†èƒ½åŠ›é˜»ç¢äº†å…¶ç¨³å¥éƒ¨ç½²ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬ç¡®å®šäº†å¯¹äºæœ‰æ•ˆWebä»£ç†è‡³å…³é‡è¦çš„å…³é”®æ¨ç†æŠ€èƒ½ï¼Œå³åæ€ä¸å‰ç»æ€§ã€åˆ†æ”¯å’Œå›æ»šï¼Œå¹¶é€šè¿‡é‡å»ºä»£ç†ï¼ˆæ¨ç†æ—¶é—´ï¼‰çš„æ¨ç†ç®—æ³•æ¥æç‚¼ä½“ç°è¿™äº›èƒ½åŠ›çš„è½¨è¿¹æ•°æ®ï¼Œå½¢æˆä¸€ç³»åˆ—æ€è€ƒç†ç”±ã€‚æˆ‘ä»¬åœ¨ä»£ç†è‡ªæˆ‘æ”¹è¿›åŸºå‡†æµ‹è¯•OpenWebVoyagerä¸­è¿›è¡Œäº†å®éªŒï¼Œå¹¶è¯æ˜é€šè¿‡ç®€å•å¾®è°ƒå°†æ˜¾è‘—çš„æ¨ç†æ¨¡å¼è’¸é¦åˆ°ä¸»å¹²LLMä¸­ï¼Œå¯ä»¥æå¤§åœ°æé«˜å…¶æ€§èƒ½ã€‚æˆ‘ä»¬çš„æ–¹æ³•åœ¨å¤šåŸºå‡†æµ‹è¯•ä¸­äº§ç”Ÿäº†æ˜¾è‘—æ”¹è¿›ï¼ŒåŒ…æ‹¬WebVoyagerã€Mind2web-liveå’ŒSimpleQAï¼ˆç½‘ç»œæœç´¢ï¼‰ï¼Œçªå‡ºäº†é’ˆå¯¹Webä»£ç†è¿›è¡Œé’ˆå¯¹æ€§æ¨ç†æŠ€èƒ½å¢å¼ºçš„æ½œåŠ›ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.20013v1">PDF</a> 18 pages</p>
<p><strong>Summary</strong></p>
<p>åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹çš„ç½‘ç»œä»£ç†å±•ç°å‡ºä¸‹ä¸€ä»£äººå·¥æ™ºèƒ½çš„æ½œåŠ›ï¼Œä½†åœ¨ä¸ç¡®å®šçš„åŠ¨æ€ç½‘ç»œç¯å¢ƒä¸­å…¶æ¨ç†èƒ½åŠ›æœ‰é™ï¼Œé˜»ç¢äº†å…¶ç¨³å¥éƒ¨ç½²ã€‚æœ¬æ–‡è¯†åˆ«å‡ºç½‘ç»œä»£ç†æœ‰æ•ˆçš„å…³é”®æ¨ç†æŠ€èƒ½ï¼ŒåŒ…æ‹¬åæ€ä¸å‰ç»ã€åˆ†æ”¯å’Œå›æ»šï¼Œå¹¶é€šè¿‡é‡å»ºä»£ç†ï¼ˆæ¨ç†æ—¶é—´ï¼‰çš„æ¨ç†ç®—æ³•æ¥è¯ é‡Šè¿™äº›èƒ½åŠ›çš„è½¨è¿¹æ•°æ®ã€‚åœ¨è‡ªæˆ‘æ”¹è¿›åŸºå‡†æµ‹è¯•OpenWebVoyagerä¸­è¿›è¡Œäº†å®éªŒï¼Œè¯æ˜äº†é€šè¿‡ç®€å•å¾®è°ƒå°†é‡è¦çš„æ¨ç†æ¨¡å¼è’¸é¦åˆ°åŸºæœ¬çš„å¤§å‹è¯­è¨€æ¨¡å‹ä¸­ï¼Œå¯ä»¥æå¤§åœ°æé«˜å…¶æ€§èƒ½ã€‚è¯¥æ–¹æ³•åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­å–å¾—äº†æ˜¾è‘—æ”¹è¿›ï¼ŒåŒ…æ‹¬WebVoyagerã€Mind2web-liveå’ŒSimpleQAï¼ˆç½‘ç»œæœç´¢ï¼‰ï¼Œçªæ˜¾äº†é’ˆå¯¹ç½‘ç»œä»£ç†è¿›è¡Œæœ‰é’ˆå¯¹æ€§çš„æ¨ç†æŠ€èƒ½å¢å¼ºçš„é‡è¦æ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ç½‘ç»œä»£ç†åœ¨ä¸ç¡®å®šçš„åŠ¨æ€ç½‘ç»œç¯å¢ƒä¸­å­˜åœ¨æ¨ç†èƒ½åŠ›é™åˆ¶ã€‚</li>
<li>æœ¬æ–‡è¯†åˆ«äº†ç½‘ç»œä»£ç†æœ‰æ•ˆçš„å…³é”®æ¨ç†æŠ€èƒ½ï¼ŒåŒ…æ‹¬åæ€ä¸å‰ç»ã€åˆ†æ”¯å’Œå›æ»šã€‚</li>
<li>é€šè¿‡é‡å»ºä»£ç†çš„æ¨ç†ç®—æ³•è½¨è¿¹æ•°æ®ï¼Œå±•ç¤ºäº†è¿™äº›èƒ½åŠ›çš„å…·ä½“è¡¨ç°ã€‚</li>
<li>åœ¨è‡ªæˆ‘æ”¹è¿›åŸºå‡†æµ‹è¯•OpenWebVoyagerä¸­è¿›è¡Œäº†å®éªŒéªŒè¯ã€‚</li>
<li>ç®€å•å¾®è°ƒå°†é‡è¦çš„æ¨ç†æ¨¡å¼è’¸é¦åˆ°åŸºç¡€çš„å¤§å‹è¯­è¨€æ¨¡å‹ä¸­ï¼Œå¯ä»¥æ˜¾è‘—æé«˜ä»£ç†æ€§èƒ½ã€‚</li>
<li>è¯¥æ–¹æ³•åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­å–å¾—äº†æ˜¾è‘—æ”¹è¿›ï¼Œçªæ˜¾äº†å¢å¼ºç½‘ç»œä»£ç†æ¨ç†æŠ€èƒ½çš„é‡è¦æ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.20013">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-63406a02c500d7588dca48c66f8f64a0.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d40c966d83b8576537fcb83fac07759f.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-ae6eb6cfc29b4a8abb0ba4f5e3fc940f.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="Embracing-Imperfection-Simulating-Students-with-Diverse-Cognitive-Levels-Using-LLM-based-Agents"><a href="#Embracing-Imperfection-Simulating-Students-with-Diverse-Cognitive-Levels-Using-LLM-based-Agents" class="headerlink" title="Embracing Imperfection: Simulating Students with Diverse Cognitive   Levels Using LLM-based Agents"></a>Embracing Imperfection: Simulating Students with Diverse Cognitive   Levels Using LLM-based Agents</h2><p><strong>Authors:Tao Wu, Jingyuan Chen, Wang Lin, Mengze Li, Yumeng Zhu, Ang Li, Kun Kuang, Fei Wu</strong></p>
<p>Large language models (LLMs) are revolutionizing education, with LLM-based agents playing a key role in simulating student behavior. A major challenge in student simulation is modeling the diverse learning patterns of students at various cognitive levels. However, current LLMs, typically trained as &#96;&#96;helpful assistantsâ€™â€™, target at generating perfect responses. As a result, they struggle to simulate students with diverse cognitive abilities, as they often produce overly advanced answers, missing the natural imperfections that characterize student learning and resulting in unrealistic simulations. To address this issue, we propose a training-free framework for student simulation. We begin by constructing a cognitive prototype for each student using a knowledge graph, which captures their understanding of concepts from past learning records. This prototype is then mapped to new tasks to predict student performance. Next, we simulate student solutions based on these predictions and iteratively refine them using a beam search method to better replicate realistic mistakes. To validate our approach, we construct the \texttt{Student_100} dataset, consisting of $100$ students working on Python programming and $5,000$ learning records. Experimental results show that our method consistently outperforms baseline models, achieving $100%$ improvement in simulation accuracy. </p>
<blockquote>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ­£åœ¨æ¨åŠ¨æ•™è‚²çš„é©æ–°ï¼ŒåŸºäºLLMçš„ä»£ç†åœ¨å­¦ç”Ÿè¡Œä¸ºæ¨¡æ‹Ÿä¸­æ‰®æ¼”ç€å…³é”®è§’è‰²ã€‚å­¦ç”Ÿæ¨¡æ‹Ÿé¢ä¸´çš„ä¸€ä¸ªä¸»è¦æŒ‘æˆ˜æ˜¯æ¨¡æ‹Ÿå­¦ç”Ÿåœ¨å„ç§è®¤çŸ¥æ°´å¹³çš„å„ç§å­¦ä¹ æ¨¡å¼ã€‚ç„¶è€Œï¼Œå½“å‰çš„å¤§å‹è¯­è¨€æ¨¡å‹é€šå¸¸è¢«è®­ç»ƒæˆâ€œæœ‰ç”¨çš„åŠ©æ‰‹â€ï¼Œæ—¨åœ¨ç”Ÿæˆå®Œç¾çš„å›åº”ã€‚å› æ­¤ï¼Œä»–ä»¬åœ¨æ¨¡æ‹Ÿå…·æœ‰ä¸åŒè®¤çŸ¥èƒ½åŠ›çš„å­¦ç”Ÿæ—¶é‡åˆ°äº†å›°éš¾ï¼Œå› ä¸ºè¿™äº›æ¨¡å‹å¾€å¾€äº§ç”Ÿè¿‡äºé«˜çº§çš„ç­”æ¡ˆï¼Œå¿½ç•¥äº†å­¦ç”Ÿåœ¨å­¦ä¹ è¿‡ç¨‹ä¸­è¡¨ç°å‡ºçš„è‡ªç„¶ç¼ºé™·ï¼Œå¯¼è‡´æ¨¡æ‹Ÿç»“æœä¸çœŸå®ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ— éœ€è®­ç»ƒçš„ç”¨äºå­¦ç”Ÿæ¨¡æ‹Ÿçš„æ¡†æ¶ã€‚æˆ‘ä»¬é¦–å…ˆä½¿ç”¨çŸ¥è¯†å›¾è°±ä¸ºæ¯ä¸ªå­¦ç”Ÿæ„å»ºè®¤çŸ¥åŸå‹ï¼Œè¯¥å›¾è°±æ•æ‰äº†ä»–ä»¬å¯¹è¿‡å»å­¦ä¹ å†…å®¹çš„ç†è§£ã€‚ç„¶åï¼Œæˆ‘ä»¬å°†è¿™ä¸ªåŸå‹æ˜ å°„åˆ°æ–°çš„ä»»åŠ¡æ¥é¢„æµ‹å­¦ç”Ÿçš„è¡¨ç°ã€‚æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬åŸºäºè¿™äº›é¢„æµ‹æ¥æ¨¡æ‹Ÿå­¦ç”Ÿçš„è§£å†³æ–¹æ¡ˆï¼Œå¹¶ä½¿ç”¨ä¸€ç§è´ªå¿ƒæœç´¢æ–¹æ³•æ¥è¿­ä»£åœ°æ”¹è¿›æ¨¡æ‹Ÿç»“æœï¼Œä»¥æ›´å¥½åœ°é‡ç°çœŸå®çš„é”™è¯¯ã€‚ä¸ºäº†éªŒè¯æˆ‘ä»¬çš„æ–¹æ³•ï¼Œæˆ‘ä»¬æ„å»ºäº†<code>Student_100</code>æ•°æ®é›†ï¼ŒåŒ…å«100åå­¦ä¹ Pythonç¼–ç¨‹çš„å­¦ç”Ÿå’Œ5000æ¡å­¦ä¹ è®°å½•ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•å§‹ç»ˆä¼˜äºåŸºçº¿æ¨¡å‹ï¼Œåœ¨æ¨¡æ‹Ÿç²¾åº¦ä¸Šæé«˜äº†100%ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.19997v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ­£åœ¨æ”¹å˜æ•™è‚²æ–¹å¼ï¼ŒLLMé©±åŠ¨çš„ä»£ç†åœ¨æ¨¡æ‹Ÿå­¦ç”Ÿè¡Œä¸ºæ–¹é¢å‘æŒ¥å…³é”®ä½œç”¨ã€‚å½“å‰LLMä¸»è¦é¢ä¸´æŒ‘æˆ˜æ˜¯æ¨¡æ‹Ÿä¸åŒè®¤çŸ¥å±‚æ¬¡çš„å­¦ç”Ÿå­¦ä¹ æ¨¡å¼æ—¶å­˜åœ¨ç¼ºé™·ï¼Œé€šå¸¸ç”Ÿæˆè¿‡äºå®Œç¾çš„ç­”æ¡ˆï¼Œæ— æ³•åæ˜ å­¦ç”Ÿå­¦ä¹ ä¸­çš„è‡ªç„¶ç¼ºé™·ï¼Œå¯¼è‡´æ¨¡æ‹Ÿä¸çœŸå®ã€‚æœ¬ç ”ç©¶æå‡ºäº†ä¸€ç§æ— éœ€è®­ç»ƒçš„æ¨¡æ‹Ÿå­¦ç”Ÿè¡Œä¸ºæ¡†æ¶ï¼Œé€šè¿‡æ„å»ºçŸ¥è¯†å›¾è°±ä¸­çš„å­¦ç”Ÿè®¤çŸ¥åŸå‹ï¼Œé¢„æµ‹å­¦ç”Ÿè¡¨ç°ï¼Œå¹¶æ¨¡æ‹Ÿå­¦ç”Ÿç­”æ¡ˆã€‚é€šè¿‡è¿­ä»£ä¼˜åŒ–ï¼Œè¯¥æ¡†æ¶èƒ½æ›´å¥½åœ°å¤åˆ¶çœŸå®é”™è¯¯ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•åœ¨æ¨¡æ‹Ÿå‡†ç¡®æ€§ä¸Šæ˜æ˜¾ä¼˜äºåŸºçº¿æ¨¡å‹ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ­£åœ¨æ•™è‚²é¢†åŸŸä¸­å‘æŒ¥ä½œç”¨ï¼Œå°¤å…¶æ˜¯åœ¨æ¨¡æ‹Ÿå­¦ç”Ÿè¡Œä¸ºæ–¹é¢ã€‚</li>
<li>å½“å‰LLMåœ¨æ¨¡æ‹Ÿä¸åŒè®¤çŸ¥å±‚æ¬¡çš„å­¦ç”Ÿæ—¶å­˜åœ¨æŒ‘æˆ˜ï¼Œå€¾å‘äºç”Ÿæˆè¿‡äºå®Œç¾çš„ç­”æ¡ˆã€‚</li>
<li>ç ”ç©¶æå‡ºäº†ä¸€ç§æ— éœ€è®­ç»ƒçš„æ¨¡æ‹Ÿå­¦ç”Ÿè¡Œä¸ºæ¡†æ¶ï¼Œé€šè¿‡æ„å»ºçŸ¥è¯†å›¾è°±ä¸­çš„å­¦ç”Ÿè®¤çŸ¥åŸå‹æ¥é¢„æµ‹å­¦ç”Ÿè¡¨ç°ã€‚</li>
<li>è¯¥æ¡†æ¶èƒ½å¤Ÿæ¨¡æ‹Ÿå­¦ç”Ÿçš„ç­”æ¡ˆï¼Œå¹¶è¿­ä»£ä¼˜åŒ–ä»¥æ›´å¥½åœ°å¤åˆ¶çœŸå®é”™è¯¯ã€‚</li>
<li>ä¸ºäº†éªŒè¯æ–¹æ³•çš„æœ‰æ•ˆæ€§ï¼Œæ„å»ºäº†åŒ…å«100åå­¦ç”Ÿå’Œ5000æ¡å­¦ä¹ è®°å½•çš„Student_100æ•°æ®é›†ã€‚</li>
<li>å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨æ¨¡æ‹Ÿå‡†ç¡®æ€§ä¸Šæ˜¾è‘—ä¼˜äºåŸºçº¿æ¨¡å‹ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.19997">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-a3ac0dc0002d5d2db56b68c544b6de0d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-95660c78d5bc9c7701482bbdd216cd55.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-3499c3a528165b568bd3a25e745b9dd2.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-5ea9a9c4ce76350847b80996d781bdf2.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-8583f939b90a600c26362d7d5aac6f16.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="ScienceBoard-Evaluating-Multimodal-Autonomous-Agents-in-Realistic-Scientific-Workflows"><a href="#ScienceBoard-Evaluating-Multimodal-Autonomous-Agents-in-Realistic-Scientific-Workflows" class="headerlink" title="ScienceBoard: Evaluating Multimodal Autonomous Agents in Realistic   Scientific Workflows"></a>ScienceBoard: Evaluating Multimodal Autonomous Agents in Realistic   Scientific Workflows</h2><p><strong>Authors:Qiushi Sun, Zhoumianze Liu, Chang Ma, Zichen Ding, Fangzhi Xu, Zhangyue Yin, Haiteng Zhao, Zhenyu Wu, Kanzhi Cheng, Zhaoyang Liu, Jianing Wang, Qintong Li, Xiangru Tang, Tianbao Xie, Xiachong Feng, Xiang Li, Ben Kao, Wenhai Wang, Biqing Qi, Lingpeng Kong, Zhiyong Wu</strong></p>
<p>Large Language Models (LLMs) have extended their impact beyond Natural Language Processing, substantially fostering the development of interdisciplinary research. Recently, various LLM-based agents have been developed to assist scientific discovery progress across multiple aspects and domains. Among these, computer-using agents, capable of interacting with operating systems as humans do, are paving the way to automated scientific problem-solving and addressing routines in researchersâ€™ workflows. Recognizing the transformative potential of these agents, we introduce ScienceBoard, which encompasses two complementary contributions: (i) a realistic, multi-domain environment featuring dynamic and visually rich scientific workflows with integrated professional software, where agents can autonomously interact via different interfaces to accelerate complex research tasks and experiments; and (ii) a challenging benchmark of 169 high-quality, rigorously validated real-world tasks curated by humans, spanning scientific-discovery workflows in domains such as biochemistry, astronomy, and geoinformatics. Extensive evaluations of agents with state-of-the-art backbones (e.g., GPT-4o, Claude 3.7, UI-TARS) show that, despite some promising results, they still fall short of reliably assisting scientists in complex workflows, achieving only a 15% overall success rate. In-depth analysis further provides valuable insights for addressing current agent limitations and more effective design principles, paving the way to build more capable agents for scientific discovery. Our code, environment, and benchmark are at <a target="_blank" rel="noopener" href="https://qiushisun.github.io/ScienceBoard-Home/">https://qiushisun.github.io/ScienceBoard-Home/</a>. </p>
<blockquote>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å·²ç»å°†å…¶å½±å“åŠ›æ‰©å±•åˆ°äº†è‡ªç„¶è¯­è¨€å¤„ç†é¢†åŸŸä¹‹å¤–ï¼Œæå¤§åœ°ä¿ƒè¿›äº†è·¨å­¦ç§‘ç ”ç©¶çš„å‘å±•ã€‚æœ€è¿‘ï¼Œå·²ç»å¼€å‘äº†å„ç§åŸºäºLLMçš„ä»£ç†ï¼Œä»¥ååŠ©å¤šä¸ªæ–¹é¢å’Œé¢†åŸŸçš„ç§‘å­¦å‘ç°è¿›å±•ã€‚å…¶ä¸­ï¼Œèƒ½å¤Ÿä¸äººç±»ä¸€æ ·ä¸æ“ä½œç³»ç»Ÿäº¤äº’çš„è®¡ç®—æœºä½¿ç”¨ä»£ç†æ­£åœ¨ä¸ºè‡ªåŠ¨åŒ–ç§‘å­¦é—®é¢˜è§£å†³å’Œç ”ç©¶äººå‘˜å·¥ä½œæµç¨‹ä¸­çš„ä¾‹è¡Œå…¬äº‹é“ºå¹³é“è·¯ã€‚æˆ‘ä»¬è®¤è¯†åˆ°äº†è¿™äº›ä»£ç†çš„å˜é©æ½œåŠ›ï¼Œå› æ­¤æ¨å‡ºäº†ScienceBoardï¼Œå®ƒåŒ…æ‹¬ä¸¤ä¸ªäº’è¡¥çš„è´¡çŒ®ï¼šé¦–å…ˆï¼Œä¸€ä¸ªç°å®çš„å¤šé¢†åŸŸç¯å¢ƒï¼Œæ‹¥æœ‰åŠ¨æ€ä¸”è§†è§‰ä¸°å¯Œçš„ç§‘å­¦å·¥ä½œæµç¨‹ä»¥åŠé›†æˆä¸“ä¸šè½¯ä»¶ï¼Œä»£ç†å¯ä»¥è‡ªä¸»é€šè¿‡ä¸åŒçš„æ¥å£è¿›è¡Œäº¤äº’ï¼Œä»¥åŠ é€Ÿå¤æ‚çš„ç§‘ç ”ä»»åŠ¡å’Œå®éªŒï¼›å…¶æ¬¡ï¼Œä¸€ä¸ªç”±äººç±»ç­–åˆ’çš„åŒ…å«169ä¸ªé«˜è´¨é‡ã€ç»è¿‡ä¸¥æ ¼éªŒè¯çš„ç°å®ä¸–ç•Œä»»åŠ¡çš„æŒ‘æˆ˜æ€§åŸºå‡†æµ‹è¯•ï¼Œè¿™äº›ä»»åŠ¡æ¶µç›–äº†ç”Ÿç‰©åŒ–å­¦ã€å¤©æ–‡å­¦å’Œåœ°ç†ä¿¡æ¯ç§‘å­¦ç­‰é¢†åŸŸçš„ç§‘å­¦å‘ç°å·¥ä½œæµç¨‹ã€‚å¯¹å…·æœ‰æœ€æ–°æŠ€æœ¯åæ´ï¼ˆå¦‚GPT-4oã€Claude 3.7ã€UI-TARSï¼‰çš„ä»£ç†è¿›è¡Œå…¨é¢è¯„ä¼°è¡¨æ˜ï¼Œå°½ç®¡æœ‰ä¸€äº›ä»¤äººé¼“èˆçš„ç»“æœï¼Œä½†å®ƒä»¬ä»ç„¶æ— æ³•å¯é åœ°ååŠ©ç§‘å­¦å®¶è¿›è¡Œå¤æ‚çš„å·¥ä½œæµç¨‹ï¼Œæ€»ä½“æˆåŠŸç‡ä»…ä¸º15%ã€‚æ·±å…¥åˆ†æè¿˜æä¾›äº†æœ‰å…³è§£å†³å½“å‰ä»£ç†å±€é™æ€§ä»¥åŠæ›´æœ‰æ•ˆè®¾è®¡åŸåˆ™çš„æœ‰ä»·å€¼è§è§£ï¼Œä¸ºæ„å»ºæ›´å…·èƒ½åŠ›çš„ç§‘å­¦å‘ç°ä»£ç†é“ºå¹³äº†é“è·¯ã€‚æˆ‘ä»¬çš„ä»£ç ã€ç¯å¢ƒå’ŒåŸºå‡†æµ‹è¯•ä½äº<a target="_blank" rel="noopener" href="https://qiushisun.github.io/ScienceBoard-Home/%E3%80%82">https://qiushisun.github.io/ScienceBoard-Home/ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.19897v1">PDF</a> work in progress</p>
<p><strong>Summary</strong></p>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å·²è¶…è¶Šè‡ªç„¶è¯­è¨€å¤„ç†é¢†åŸŸï¼Œæå¤§åœ°ä¿ƒè¿›äº†è·¨å­¦ç§‘ç ”ç©¶çš„å‘å±•ã€‚åŸºäºLLMçš„ç§‘ç ”åŠ©ç†å‹æ™ºèƒ½ä½“åœ¨å¤šä¸ªé¢†åŸŸå’Œæ–¹é¢æ¨åŠ¨äº†ç§‘å­¦å‘ç°çš„è¿›æ­¥ã€‚å…¶ä¸­ï¼Œèƒ½åƒäººä¸€æ ·ä¸æ“ä½œç³»ç»Ÿäº¤äº’çš„è®¡ç®—æœºä½¿ç”¨æ™ºèƒ½ä½“ï¼Œä¸ºè‡ªåŠ¨åŒ–è§£å†³ç§‘å­¦é—®é¢˜å’Œåº”å¯¹ç ”ç©¶è€…å·¥ä½œæµç¨‹ä¸­çš„å¸¸è§„ä»»åŠ¡å¼€è¾Ÿäº†é“è·¯ã€‚ä¸ºåº”å¯¹è¿™ä¸€å˜é©æ½œåŠ›ï¼Œæˆ‘ä»¬æ¨å‡ºäº†ScienceBoardï¼ŒåŒ…å«ä¸¤ä¸ªäº’è¡¥çš„ç»„æˆéƒ¨åˆ†ï¼šï¼ˆä¸€ï¼‰ä¸€ä¸ªç°å®ã€è·¨é¢†åŸŸçš„ç¯å¢ƒï¼Œæ‹¥æœ‰åŠ¨æ€ã€è§†è§‰ä¸°å¯Œçš„ç§‘ç ”å·¥ä½œæµç¨‹åŠé›†æˆä¸“ä¸šè½¯ä»¶ï¼Œæ™ºèƒ½ä½“èƒ½åœ¨æ­¤ç¯å¢ƒä¸­é€šè¿‡ä¸åŒæ¥å£è‡ªä¸»äº¤äº’ï¼Œä»¥åŠ é€Ÿå¤æ‚çš„ç§‘ç ”ä»»åŠ¡å’Œå®éªŒï¼›ï¼ˆäºŒï¼‰ä¸€ä¸ªåŒ…å«äººç±»ç²¾å¿ƒæŒ‘é€‰çš„169ä¸ªé«˜è´¨é‡ã€ç»è¿‡ä¸¥æ ¼éªŒè¯çš„ç°å®ä»»åŠ¡çš„æŒ‘æˆ˜åŸºå‡†æµ‹è¯•ï¼Œæ¶µç›–ç”Ÿç‰©åŒ–å­¦ã€å¤©æ–‡å­¦å’Œåœ°ç†ä¿¡æ¯ç§‘å­¦ç­‰é¢†åŸŸçš„ç§‘å­¦å‘ç°æµç¨‹ã€‚å¯¹æ™ºèƒ½ä½“çš„å¹¿æ³›è¯„ä¼°è¡¨æ˜ï¼Œå°½ç®¡å–å¾—äº†ä¸€äº›ä»¤äººé¼“èˆçš„ç»“æœï¼Œä½†å®ƒä»¬ä»æ— æ³•å¯é åœ°ååŠ©ç§‘å­¦å®¶å®Œæˆå¤æ‚çš„å·¥ä½œæµç¨‹ï¼Œæ•´ä½“æˆåŠŸç‡ä»…ä¸º15%ã€‚æˆ‘ä»¬çš„ä»£ç ã€ç¯å¢ƒå’ŒåŸºå‡†æµ‹è¯•ä½äº<a target="_blank" rel="noopener" href="https://qiushisun.github.io/ScienceBoard-Home/">https://qiushisun.github.io/ScienceBoard-Home/</a>ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å·²å¯¹è·¨å­¦ç§‘ç ”ç©¶äº§ç”Ÿæ·±è¿œå½±å“ã€‚</li>
<li>åŸºäºLLMçš„ç§‘ç ”åŠ©ç†å‹æ™ºèƒ½ä½“åœ¨å¤šä¸ªé¢†åŸŸæ¨åŠ¨äº†ç§‘å­¦å‘ç°è¿›æ­¥ã€‚</li>
<li>è®¡ç®—æœºä½¿ç”¨æ™ºèƒ½ä½“èƒ½è‡ªä¸»ä¸æ“ä½œç³»ç»Ÿäº¤äº’ï¼ŒåŠ©åŠ›è‡ªåŠ¨åŒ–è§£å†³ç§‘å­¦é—®é¢˜ã€‚</li>
<li>ScienceBoardåŒ…å«ç°å®è·¨é¢†åŸŸç¯å¢ƒä¸æŒ‘æˆ˜åŸºå‡†æµ‹è¯•ã€‚</li>
<li>æ™ºèƒ½ä½“åœ¨å¤æ‚ç§‘ç ”å·¥ä½œæµç¨‹ä¸­çš„æ•´ä½“æˆåŠŸç‡ä»…ä¸º15%ï¼Œä»æœ‰æå‡ç©ºé—´ã€‚</li>
<li>å¯¹æ™ºèƒ½ä½“çš„æ·±å…¥è¯„ä¼°æä¾›äº†æœ‰ä»·å€¼çš„è§è§£ï¼Œä»¥åº”å¯¹å½“å‰æ™ºèƒ½ä½“çš„å±€é™æ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.19897">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-4e6ae2be74cc41f7ac98d11343cf7b9f.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-de5ff0b49b2fe11eff68c77059654861.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-15e3ef883524122bfb99a5e7db9decc7.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-1856fb0df7b64b38bafe508302aa9011.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-ac5ae11e80a3d8539035746d60d54a92.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="T-2Agent-A-Tool-augmented-Multimodal-Misinformation-Detection-Agent-with-Monte-Carlo-Tree-Search"><a href="#T-2Agent-A-Tool-augmented-Multimodal-Misinformation-Detection-Agent-with-Monte-Carlo-Tree-Search" class="headerlink" title="T^2Agent A Tool-augmented Multimodal Misinformation Detection Agent with   Monte Carlo Tree Search"></a>T^2Agent A Tool-augmented Multimodal Misinformation Detection Agent with   Monte Carlo Tree Search</h2><p><strong>Authors:Xing Cui, Yueying Zou, Zekun Li, Peipei Li, Xinyuan Xu, Xuannan Liu, Huaibo Huang, Ran He</strong></p>
<p>Real-world multimodal misinformation often arises from mixed forgery sources, requiring dynamic reasoning and adaptive verification. However, existing methods mainly rely on static pipelines and limited tool usage, limiting their ability to handle such complexity and diversity. To address this challenge, we propose T2Agent, a novel misinformation detection agent that incorporates an extensible toolkit with Monte Carlo Tree Search (MCTS). The toolkit consists of modular tools such as web search, forgery detection, and consistency analysis. Each tool is described using standardized templates, enabling seamless integration and future expansion. To avoid inefficiency from using all tools simultaneously, a Bayesian optimization-based selector is proposed to identify a task-relevant subset. This subset then serves as the action space for MCTS to dynamically collect evidence and perform multi-source verification. To better align MCTS with the multi-source nature of misinformation detection, T2Agent extends traditional MCTS with multi-source verification, which decomposes the task into coordinated subtasks targeting different forgery sources. A dual reward mechanism containing a reasoning trajectory score and a confidence score is further proposed to encourage a balance between exploration across mixed forgery sources and exploitation for more reliable evidence. We conduct ablation studies to confirm the effectiveness of the tree search mechanism and tool usage. Extensive experiments further show that T2Agent consistently outperforms existing baselines on challenging mixed-source multimodal misinformation benchmarks, demonstrating its strong potential as a training-free approach for enhancing detection accuracy. The code will be released. </p>
<blockquote>
<p>ç°å®ä¸–ç•Œä¸­çš„å¤šæ¨¡æ€é”™è¯¯ä¿¡æ¯å¾€å¾€æºäºæ··åˆçš„ä¼ªé€ æºï¼Œè¿™éœ€è¦åŠ¨æ€æ¨ç†å’Œè‡ªé€‚åº”éªŒè¯ã€‚ç„¶è€Œï¼Œç°æœ‰æ–¹æ³•ä¸»è¦ä¾èµ–äºé™æ€ç®¡é“å’Œæœ‰é™çš„å·¥å…·ä½¿ç”¨ï¼Œè¿™é™åˆ¶äº†å®ƒä»¬å¤„ç†è¿™ç§å¤æ‚æ€§å’Œå¤šæ ·æ€§çš„èƒ½åŠ›ã€‚ä¸ºäº†åº”å¯¹è¿™ä¸€æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†T2Agentï¼Œè¿™æ˜¯ä¸€ç§æ–°å‹çš„é”™è¯¯ä¿¡æ¯æ£€æµ‹ä»£ç†ï¼Œå®ƒç»“åˆäº†å¯æ‰©å±•çš„å·¥å…·åŒ…å’Œè’™ç‰¹å¡æ´›æ ‘æœç´¢ï¼ˆMCTSï¼‰ã€‚è¯¥å·¥å…·åŒ…ç”±æ¨¡å—åŒ–å·¥å…·ç»„æˆï¼Œå¦‚ç½‘ç»œæœç´¢ã€ä¼ªé€ æ£€æµ‹ã€ä¸€è‡´æ€§åˆ†æç­‰ã€‚æ¯ä¸ªå·¥å…·éƒ½ä½¿ç”¨æ ‡å‡†æ¨¡æ¿è¿›è¡Œæè¿°ï¼Œä»¥å®ç°æ— ç¼é›†æˆå’Œæœªæ¥æ‰©å±•ã€‚ä¸ºäº†é¿å…åŒæ—¶ä½¿ç”¨æ‰€æœ‰å·¥å…·æ‰€å¸¦æ¥çš„ä½æ•ˆæ€§ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åŸºäºè´å¶æ–¯ä¼˜åŒ–çš„é€‰æ‹©å™¨æ¥è¯†åˆ«ä¸ä»»åŠ¡ç›¸å…³çš„å­é›†ã€‚ç„¶åï¼Œè¿™ä¸ªå­é›†ä½œä¸ºè¡ŒåŠ¨ç©ºé—´ï¼Œä¸ºMCTSåŠ¨æ€æ”¶é›†è¯æ®å’Œè¿›è¡Œå¤šæºéªŒè¯æä¾›æ”¯æ’‘ã€‚ä¸ºäº†æ›´å¥½åœ°å°†MCTSä¸é”™è¯¯ä¿¡æ¯çš„å¤šæºæ€§è´¨ç›¸ç»“åˆï¼ŒT2Agentå¯¹ä¼ ç»Ÿçš„MCTSè¿›è¡Œäº†æ‰©å±•ï¼Œå®ç°å¤šæºéªŒè¯ï¼Œå°†ä»»åŠ¡åˆ†è§£ä¸ºé’ˆå¯¹ä¸åŒä¼ªé€ æºåè°ƒçš„å­ä»»åŠ¡ã€‚è¿›ä¸€æ­¥æå‡ºäº†ä¸€ç§åŒ…å«æ¨ç†è½¨è¿¹å¾—åˆ†å’Œç½®ä¿¡å¾—åˆ†çš„åŒé‡å¥–åŠ±æœºåˆ¶ï¼Œä»¥é¼“åŠ±åœ¨æ··åˆä¼ªé€ æºä¹‹é—´è¿›è¡Œæ¢ç´¢ä¸åˆ©ç”¨æ›´å¯é çš„è¯æ®ä¹‹é—´ä¿æŒå¹³è¡¡ã€‚æˆ‘ä»¬é€šè¿‡æ¶ˆèç ”ç©¶è¯å®äº†æ ‘æœç´¢æœºåˆ¶å’Œå·¥å…·ä½¿ç”¨çš„æœ‰æ•ˆæ€§ã€‚å¤§é‡å®éªŒè¿›ä¸€æ­¥è¡¨æ˜ï¼ŒT2Agentåœ¨å…·æœ‰æŒ‘æˆ˜æ€§çš„æ··åˆæºå¤šæ¨¡æ€é”™è¯¯ä¿¡æ¯åŸºå‡†æµ‹è¯•ä¸Šå§‹ç»ˆä¼˜äºç°æœ‰åŸºçº¿ï¼Œæ˜¾ç¤ºå‡ºå…¶ä½œä¸ºæ— è®­ç»ƒæ–¹æ³•æé«˜æ£€æµ‹ç²¾åº¦çš„å¼ºå¤§æ½œåŠ›ã€‚ä»£ç å°†è¢«å‘å¸ƒã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.19768v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºä¸€ç§åä¸ºT2Agentçš„æ–°å‹ä¿¡æ¯æ£€æµ‹æ™ºèƒ½ä½“ï¼Œé’ˆå¯¹ç°å®ä¸–ç•Œä¸­ç”±æ··åˆä¼ªé€ æºå¼•å‘çš„å¤šæ¨¡å¼é”™è¯¯ä¿¡æ¯æŒ‘æˆ˜ã€‚é€šè¿‡é‡‡ç”¨å¯æ‹“å±•çš„å·¥å…·åŒ…å’Œè’™ç‰¹å¡æ´›æ ‘æœç´¢ï¼ˆMCTSï¼‰ï¼Œå®ç°äº†é«˜æ•ˆçš„å¤šæºéªŒè¯å’ŒåŠ¨æ€æ¨ç†ã€‚è¯¥å·¥å…·åŒ…åŒ…æ‹¬ç½‘é¡µæœç´¢ã€ä¼ªé€ æ£€æµ‹å’Œä¸€è‡´æ€§åˆ†æç­‰æ¨¡å—åŒ–å·¥å…·ï¼Œå¹¶ä½¿ç”¨æ ‡å‡†åŒ–æ¨¡æ¿è¿›è¡Œæè¿°ï¼Œç¡®ä¿æ— ç¼é›†æˆå’Œæœªæ¥æ‰©å±•æ€§ã€‚ä¸ºäº†é¿å…åŒæ—¶ä½¿ç”¨çš„æ‰€æœ‰å·¥å…·çš„ä½æ•ˆæ€§ï¼Œæå‡ºäº†åŸºäºè´å¶æ–¯ä¼˜åŒ–çš„é€‰æ‹©å™¨æ¥ç¡®å®šä¸ä»»åŠ¡ç›¸å…³çš„å·¥å…·å­é›†ï¼Œä½œä¸ºMCTSçš„è¡ŒåŠ¨ç©ºé—´ã€‚æ­¤å¤–ï¼Œå¯¹MCTSè¿›è¡Œäº†é’ˆå¯¹å¤šæºä¿¡æ¯æ£€æµ‹ä»»åŠ¡çš„æ‰©å±•ï¼Œå°†ä»»åŠ¡åˆ†è§£ä¸ºé’ˆå¯¹ä¸åŒä¼ªé€ æºåè°ƒçš„å­ä»»åŠ¡ã€‚é€šè¿‡åŒé‡å¥–åŠ±æœºåˆ¶å¹³è¡¡æ¢ç´¢ä¸åŒä¼ªé€ æºå’Œå¯é è¯æ®çš„å¼€å‘ã€‚å®éªŒè¡¨æ˜ï¼ŒT2Agentåœ¨æ··åˆæºå¤šæ¨¡å¼é”™è¯¯ä¿¡æ¯æ£€æµ‹åŸºå‡†æµ‹è¯•ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œå…·æœ‰å¼ºå¤§çš„æ½œåŠ›æˆä¸ºä¸€ç§æ— éœ€è®­ç»ƒå³å¯æé«˜æ£€æµ‹å‡†ç¡®æ€§çš„æ–¹æ³•ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>T2Agentæå‡ºä¸€ç§æ–°å‹ä¿¡æ¯æ£€æµ‹æ™ºèƒ½ä½“ç”¨äºå¤„ç†å¤šæ¨¡æ€è¯¯å¯¼ä¿¡æ¯ã€‚</li>
<li>é‡‡ç”¨åŒ…å«å¤šç§æ¨¡å—åŒ–å·¥å…·çš„å·¥å…·ä½“ç³»ç»“æ„åº”å¯¹å¤æ‚æ€§å’Œå¤šæ ·æ€§ã€‚</li>
<li>åˆ©ç”¨è’™ç‰¹å¡æ´›æ ‘æœç´¢è¿›è¡ŒåŠ¨æ€è¯æ®æ”¶é›†å’Œä»»åŠ¡åˆ†è§£ã€‚</li>
<li>æå‡ºåŸºäºè´å¶æ–¯ä¼˜åŒ–çš„é€‰æ‹©å™¨ä»¥æé«˜æ•ˆç‡ã€‚</li>
<li>é€šè¿‡åŒé‡å¥–åŠ±æœºåˆ¶å¹³è¡¡æ¢ç´¢ä¸å¼€å‘ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.19768">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-749190b1befa137fb27c90aade81ca3c.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-c278df6b210ff8c15fdd42cc9e7aa7b5.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-2d3fa43d8d9a8bc799a12d8a94644bf4.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="RFTF-Reinforcement-Fine-tuning-for-Embodied-Agents-with-Temporal-Feedback"><a href="#RFTF-Reinforcement-Fine-tuning-for-Embodied-Agents-with-Temporal-Feedback" class="headerlink" title="RFTF: Reinforcement Fine-tuning for Embodied Agents with Temporal   Feedback"></a>RFTF: Reinforcement Fine-tuning for Embodied Agents with Temporal   Feedback</h2><p><strong>Authors:Junyang Shu, Zhiwei Lin, Yongtao Wang</strong></p>
<p>Vision-Language-Action (VLA) models have demonstrated significant potential in the field of embodied intelligence, enabling agents to follow human instructions to complete complex tasks in physical environments. Existing embodied agents are often trained through behavior cloning, which requires expensive data and computational resources and is constrained by human demonstrations. To address this issue, many researchers explore the application of reinforcement fine-tuning to embodied agents. However, typical reinforcement fine-tuning methods for embodied agents usually rely on sparse, outcome-based rewards, which struggle to provide fine-grained feedback for specific actions within an episode, thus limiting the modelâ€™s manipulation capabilities and generalization performance. In this paper, we propose RFTF, a novel reinforcement fine-tuning method that leverages a value model to generate dense rewards in embodied scenarios. Specifically, our value model is trained using temporal information, eliminating the need for costly robot action labels. In addition, RFTF incorporates a range of techniques, such as GAE and sample balance to enhance the effectiveness of the fine-tuning process. By addressing the sparse reward problem in reinforcement fine-tuning, our method significantly improves the performance of embodied agents, delivering superior generalization and adaptation capabilities across diverse embodied tasks. Experimental results show that embodied agents fine-tuned with RFTF achieve new state-of-the-art performance on the challenging CALVIN ABC-D with an average success length of 4.296. Moreover, RFTF enables rapid adaptation to new environments. After fine-tuning in the D environment of CALVIN for a few episodes, RFTF achieved an average success length of 4.301 in this new environment. </p>
<blockquote>
<p>è§†è§‰è¯­è¨€åŠ¨ä½œï¼ˆVLAï¼‰æ¨¡å‹åœ¨æ™ºèƒ½ä½“é¢†åŸŸè¡¨ç°å‡ºäº†å·¨å¤§çš„æ½œåŠ›ï¼Œä½¿æ™ºèƒ½ä½“èƒ½å¤Ÿéµå¾ªäººç±»çš„æŒ‡ä»¤åœ¨ç‰©ç†ç¯å¢ƒä¸­å®Œæˆå¤æ‚çš„ä»»åŠ¡ã€‚ç°æœ‰çš„æ™ºèƒ½ä½“é€šå¸¸é€šè¿‡è¡Œä¸ºå…‹éš†è¿›è¡Œè®­ç»ƒï¼Œè¿™éœ€è¦å¤§é‡çš„æ•°æ®å’Œè®¡ç®—èµ„æºï¼Œå¹¶å—åˆ°äººç±»æ¼”ç¤ºçš„é™åˆ¶ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œè®¸å¤šç ”ç©¶è€…æ¢ç´¢å°†å¼ºåŒ–å¾®è°ƒåº”ç”¨äºæ™ºèƒ½ä½“ã€‚ç„¶è€Œï¼Œå…¸å‹çš„æ™ºèƒ½ä½“å¼ºåŒ–å¾®è°ƒæ–¹æ³•é€šå¸¸ä¾èµ–äºç¨€ç–çš„ç»“æœå‹å¥–åŠ±ï¼Œè¿™å¾ˆéš¾ä¸ºå•æ¬¡è¡ŒåŠ¨æä¾›ç²¾ç»†çš„åé¦ˆï¼Œä»è€Œé™åˆ¶äº†æ¨¡å‹çš„æ“æ§èƒ½åŠ›å’Œæ³›åŒ–æ€§èƒ½ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°å‹çš„å¼ºåŒ–å¾®è°ƒæ–¹æ³•RFTFï¼Œå®ƒåˆ©ç”¨ä»·å€¼æ¨¡å‹åœ¨æ™ºèƒ½åœºæ™¯ä¸­ç”Ÿæˆå¯†é›†å¥–åŠ±ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬çš„ä»·å€¼æ¨¡å‹ä½¿ç”¨æ—¶åºä¿¡æ¯è¿›è¡Œè®­ç»ƒï¼Œæ— éœ€æ˜‚è´µçš„æœºå™¨äººåŠ¨ä½œæ ‡ç­¾ã€‚æ­¤å¤–ï¼ŒRFTFè¿˜é‡‡ç”¨äº†ä¸€ç³»åˆ—æŠ€æœ¯ï¼Œå¦‚GAEå’Œæ ·æœ¬å¹³è¡¡ï¼Œä»¥å¢å¼ºå¾®è°ƒè¿‡ç¨‹çš„æœ‰æ•ˆæ€§ã€‚é€šè¿‡è§£å†³å¼ºåŒ–å¾®è°ƒä¸­çš„ç¨€ç–å¥–åŠ±é—®é¢˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•æ˜¾è‘—æé«˜äº†æ™ºèƒ½ä½“çš„æ€§èƒ½ï¼Œåœ¨å¤šç§æ™ºèƒ½ä»»åŠ¡ä¸Šå±•ç°äº†å“è¶Šçš„æ³›åŒ–å’Œé€‚åº”èƒ½åŠ›ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œä½¿ç”¨RFTFè¿›è¡Œå¾®è°ƒçš„æ™ºèƒ½ä½“åœ¨å…·æœ‰æŒ‘æˆ˜æ€§çš„CALVIN ABC-Dä»»åŠ¡ä¸Šè¾¾åˆ°äº†æœ€æ–°çš„æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œå¹³å‡æˆåŠŸé•¿åº¦ä¸º4.296ã€‚æ­¤å¤–ï¼ŒRFTFèƒ½å¤Ÿè¿…é€Ÿé€‚åº”æ–°ç¯å¢ƒã€‚åœ¨CALVINçš„Dç¯å¢ƒä¸­è¿›è¡Œå‡ è½®å¾®è°ƒåï¼ŒRFTFåœ¨è¿™ä¸ªæ–°ç¯å¢ƒä¸­çš„å¹³å‡æˆåŠŸé•¿åº¦è¾¾åˆ°äº†4.301ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.19767v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>åœ¨ä½“æ™ºèƒ½é¢†åŸŸï¼Œç°æœ‰çš„ä½“ä»£ç†äººé€šå¸¸é€šè¿‡è¡Œä¸ºå…‹éš†è¿›è¡Œè®­ç»ƒï¼Œè¿™éœ€è¦å¤§é‡çš„æ•°æ®å’Œè®¡ç®—èµ„æºï¼Œå¹¶å—é™äºäººç±»æ¼”ç¤ºã€‚ä¸ºè§£å†³æ­¤é—®é¢˜ï¼Œç ”ç©¶è€…å°è¯•åº”ç”¨å¼ºåŒ–ç²¾ç»†è°ƒæ•´æ–¹æ³•ã€‚ç„¶è€Œï¼Œä¼ ç»Ÿå¼ºåŒ–ç²¾ç»†è°ƒæ•´æ–¹æ³•é€šå¸¸ä¾èµ–äºç¨€ç–çš„ç»“æœå‹å¥–åŠ±ï¼Œéš¾ä»¥åœ¨å•é›†å†…ä¸ºç‰¹å®šè¡ŒåŠ¨æä¾›ç²¾ç»†åé¦ˆï¼Œä»è€Œé™åˆ¶äº†æ¨¡å‹çš„æ“æ§èƒ½åŠ›å’Œæ³›åŒ–æ€§èƒ½ã€‚æœ¬æ–‡æå‡ºä¸€ç§æ–°å‹å¼ºåŒ–ç²¾ç»†è°ƒæ•´æ–¹æ³•RFTFï¼Œåˆ©ç”¨å€¼æ¨¡å‹åœ¨ä½“åœºæ™¯ä¸­ç”Ÿæˆå¯†é›†å¥–åŠ±ã€‚å€¼æ¨¡å‹é€šè¿‡æ—¶é—´ä¿¡æ¯è®­ç»ƒï¼Œæ— éœ€æ˜‚è´µçš„æœºå™¨äººåŠ¨ä½œæ ‡ç­¾ã€‚æ­¤å¤–ï¼ŒRFTFç»“åˆå¤šç§æŠ€æœ¯å¢å¼ºç²¾ç»†è°ƒæ•´è¿‡ç¨‹çš„æœ‰æ•ˆæ€§ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œä½¿ç”¨RFTFç²¾ç»†è°ƒæ•´çš„ä½“ä»£ç†åœ¨å…·æœ‰æŒ‘æˆ˜æ€§çš„CALVIN ABC-Dä¸Šå–å¾—æœ€æ–°æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œå¹³å‡æˆåŠŸé•¿åº¦ä¸º4.296ï¼Œä¸”åœ¨æ–°ç¯å¢ƒä¸‹èƒ½å¿«é€Ÿé€‚åº”ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>VLAæ¨¡å‹åœ¨ä½“æ™ºèƒ½é¢†åŸŸæœ‰å·¨å¤§æ½œåŠ›ï¼Œèƒ½è®©ä»£ç†éµå¾ªäººç±»æŒ‡ä»¤å®Œæˆç‰©ç†ç¯å¢ƒä¸­çš„å¤æ‚ä»»åŠ¡ã€‚</li>
<li>å½“å‰ä½“ä»£ç†äººä¸»è¦é€šè¿‡è¡Œä¸ºå…‹éš†è®­ç»ƒï¼Œè¿™è¦æ±‚å¤§é‡æ•°æ®å’Œè®¡ç®—èµ„æºï¼Œå¹¶å—é™äºäººç±»æ¼”ç¤ºã€‚</li>
<li>å¼ºåŒ–ç²¾ç»†è°ƒæ•´æ˜¯è§£å†³æ­¤é—®é¢˜çš„ä¸€ç§æ–¹æ³•ï¼Œä½†ä¼ ç»Ÿæ–¹æ³•ä¾èµ–ç¨€ç–çš„ç»“æœå‹å¥–åŠ±ï¼Œéš¾ä»¥æä¾›å…·ä½“è¡ŒåŠ¨çš„ç²¾ç»†åé¦ˆã€‚</li>
<li>æœ¬æ–‡æå‡ºRFTFæ–¹æ³•ï¼Œåˆ©ç”¨å€¼æ¨¡å‹ç”Ÿæˆå¯†é›†å¥–åŠ±ï¼Œé€šè¿‡æ—¶é—´ä¿¡æ¯è®­ç»ƒå€¼æ¨¡å‹ï¼Œå‡å°‘æœºå™¨äººåŠ¨ä½œæ ‡ç­¾æˆæœ¬ã€‚</li>
<li>RFTFç»“åˆå¤šç§æŠ€æœ¯æå‡ç²¾ç»†è°ƒæ•´æ•ˆæœï¼Œå¦‚GAEå’Œæ ·æœ¬å¹³è¡¡ã€‚</li>
<li>å®éªŒæ˜¾ç¤ºï¼Œä½¿ç”¨RFTFçš„ä½“ä»£ç†åœ¨CALVIN ABC-Dä»»åŠ¡ä¸Šå–å¾—å“è¶Šæ€§èƒ½ï¼Œå¹³å‡æˆåŠŸé•¿åº¦è¾¾4.296ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.19767">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-19026cb80cdbaa41d6e73534e2373d0f.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-58c92aa8d72be9d168598bfe9fffe4c6.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-1fcaf4d1f1476845b1998c77fda12709.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-08a4e590754a150ab9db071af7785495.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="Agentic-Predictor-Performance-Prediction-for-Agentic-Workflows-via-Multi-View-Encoding"><a href="#Agentic-Predictor-Performance-Prediction-for-Agentic-Workflows-via-Multi-View-Encoding" class="headerlink" title="Agentic Predictor: Performance Prediction for Agentic Workflows via   Multi-View Encoding"></a>Agentic Predictor: Performance Prediction for Agentic Workflows via   Multi-View Encoding</h2><p><strong>Authors:Patara Trirat, Wonyong Jeong, Sung Ju Hwang</strong></p>
<p>Large language models (LLMs) have demonstrated remarkable capabilities across diverse tasks, but optimizing LLM-based agentic systems remains challenging due to the vast search space of agent configurations, prompting strategies, and communication patterns. Existing approaches often rely on heuristic-based tuning or exhaustive evaluation, which can be computationally expensive and suboptimal. This paper proposes Agentic Predictor, a lightweight predictor for efficient agentic workflow evaluation. Agentic Predictor is equipped with a multi-view workflow encoding technique that leverages multi-view representation learning of agentic systems by incorporating code architecture, textual prompts, and interaction graph features. To achieve high predictive accuracy while significantly reducing the number of required workflow evaluations for training a predictor, Agentic Predictor employs cross-domain unsupervised pretraining. By learning to approximate task success rates, Agentic Predictor enables fast and accurate selection of optimal agentic workflow configurations for a given task, significantly reducing the need for expensive trial-and-error evaluations. Experiments on a carefully curated benchmark spanning three domains show that our predictor outperforms state-of-the-art methods in both predictive accuracy and workflow utility, highlighting the potential of performance predictors in streamlining the design of LLM-based agentic workflows. </p>
<blockquote>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨å„ç§ä»»åŠ¡ä¸­è¡¨ç°å‡ºäº†æ˜¾è‘—çš„èƒ½åŠ›ï¼Œä½†ç”±äºä»£ç†é…ç½®ã€æç¤ºç­–ç•¥å’Œé€šä¿¡æ¨¡å¼çš„åºå¤§æœç´¢ç©ºé—´ï¼Œä¼˜åŒ–åŸºäºLLMçš„ä»£ç†ç³»ç»Ÿä»ç„¶æ˜¯ä¸€ä¸ªæŒ‘æˆ˜ã€‚ç°æœ‰æ–¹æ³•å¸¸å¸¸ä¾èµ–äºåŸºäºå¯å‘å¼çš„æ–¹æ³•æˆ–å…¨é¢è¯„ä¼°ï¼Œè¿™å¯èƒ½ä¼šè®¡ç®—é‡å¤§ä¸”ä¸å¤Ÿç†æƒ³ã€‚æœ¬æ–‡æå‡ºäº†Agentic Predictorï¼Œè¿™æ˜¯ä¸€ç§ç”¨äºé«˜æ•ˆä»£ç†å·¥ä½œæµç¨‹è¯„ä¼°çš„è½»é‡çº§é¢„æµ‹å™¨ã€‚Agentic Predictoré…å¤‡äº†ä¸€ç§å¤šè§†è§’å·¥ä½œæµç¨‹ç¼–ç æŠ€æœ¯ï¼Œè¯¥æŠ€æœ¯é€šè¿‡ç»“åˆä»£ç æ¶æ„ã€æ–‡æœ¬æç¤ºå’Œäº¤äº’å›¾ç‰¹å¾ï¼Œåˆ©ç”¨ä»£ç†ç³»ç»Ÿçš„å¤šè§†è§’è¡¨ç¤ºå­¦ä¹ ã€‚ä¸ºäº†å®ç°é«˜é¢„æµ‹ç²¾åº¦ï¼ŒåŒæ—¶å¤§å¤§å‡å°‘è®­ç»ƒé¢„æµ‹å™¨æ‰€éœ€çš„å·¥ä½œæµç¨‹è¯„ä¼°æ¬¡æ•°ï¼ŒAgentic Predictoré‡‡ç”¨äº†è·¨åŸŸæ— ç›‘ç£é¢„è®­ç»ƒã€‚é€šè¿‡å­¦ä¹ è¿‘ä¼¼ä»»åŠ¡æˆåŠŸç‡ï¼ŒAgentic Predictorèƒ½å¤Ÿå¿«é€Ÿå‡†ç¡®åœ°ä¸ºç»™å®šä»»åŠ¡é€‰æ‹©æœ€ä½³ä»£ç†å·¥ä½œæµç¨‹é…ç½®ï¼Œå¤§å¤§é™ä½äº†æ˜‚è´µçš„è¯•é”™è¯„ä¼°çš„éœ€æ±‚ã€‚åœ¨ç²¾å¿ƒç­–åˆ’çš„æ¶µç›–ä¸‰ä¸ªé¢†åŸŸçš„åŸºå‡†æµ‹è¯•ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„é¢„æµ‹å™¨åœ¨é¢„æµ‹ç²¾åº¦å’Œæµç¨‹å®ç”¨æ€§æ–¹é¢éƒ½ä¼˜äºæœ€æ–°æ–¹æ³•ï¼Œçªæ˜¾äº†æ€§èƒ½é¢„æµ‹å™¨åœ¨ç®€åŒ–åŸºäºLLMçš„ä»£ç†å·¥ä½œæµç¨‹è®¾è®¡æ–¹é¢çš„æ½œåŠ›ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.19764v1">PDF</a> Code will be available at   <a target="_blank" rel="noopener" href="https://github.com/DeepAuto-AI/agentic-predictor">https://github.com/DeepAuto-AI/agentic-predictor</a></p>
<p><strong>Summary</strong></p>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨å„ç§ä»»åŠ¡ä¸­å±•ç°å‡ºå“è¶Šçš„èƒ½åŠ›ï¼Œä½†ä¼˜åŒ–LLMä¸ºåŸºç¡€çš„æ™ºèƒ½ä½“ç³»ç»Ÿä»ç„¶é¢ä¸´æŒ‘æˆ˜ã€‚ç°æœ‰æ–¹æ³•å¾€å¾€ä¾èµ–å¯å‘å¼è°ƒæ•´æˆ–å…¨é¢è¯„ä¼°ï¼Œè®¡ç®—æˆæœ¬é«˜ä¸”å¯èƒ½ä¸å¤Ÿç†æƒ³ã€‚æœ¬æ–‡æå‡ºAgentic Predictorï¼Œä¸€ç§ç”¨äºé«˜æ•ˆæ™ºèƒ½ä½“å·¥ä½œæµè¯„ä¼°çš„è½»é‡çº§é¢„æµ‹å™¨ã€‚Agentic Predictorå…·å¤‡å¤šè§†è§’å·¥ä½œæµç¼–ç æŠ€æœ¯ï¼Œé€šè¿‡ç»“åˆä»£ç æ¶æ„ã€æ–‡æœ¬æç¤ºå’Œäº¤äº’å›¾ç‰¹å¾ï¼Œè¿›è¡Œæ™ºèƒ½ä½“ç³»ç»Ÿçš„å¤šè§†è§’è¡¨ç¤ºå­¦ä¹ ã€‚ä¸ºåœ¨è®­ç»ƒé¢„æµ‹å™¨æ—¶å®ç°é«˜é¢„æµ‹ç²¾åº¦å¹¶å¤§å¤§å‡å°‘æ‰€éœ€çš„å·¥ä½œæµè¯„ä¼°æ¬¡æ•°ï¼ŒAgentic Predictoré‡‡ç”¨è·¨åŸŸæ— ç›‘ç£é¢„è®­ç»ƒã€‚é€šè¿‡å­¦ä¹ ä¼°ç®—ä»»åŠ¡æˆåŠŸç‡ï¼ŒAgentic Predictorå¯ä»¥å¿«é€Ÿå‡†ç¡®åœ°ä¸ºç›®æ ‡ä»»åŠ¡é€‰æ‹©æœ€ä½³æ™ºèƒ½ä½“å·¥ä½œæµé…ç½®ï¼Œå¤§å¤§å‡å°‘æ˜‚è´µçš„è¯•é”™è¯„ä¼°çš„éœ€æ±‚ã€‚åœ¨è·¨è¶Šä¸‰ä¸ªé¢†åŸŸçš„ç²¾å¿ƒæŒ‘é€‰çš„åŸºå‡†æµ‹è¯•ä¸Šè¿›è¡Œçš„å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„é¢„æµ‹å™¨åœ¨é¢„æµ‹ç²¾åº¦å’Œå·¥ä½œæµå®ç”¨æ€§æ–¹é¢å‡ä¼˜äºæœ€æ–°æ–¹æ³•ï¼Œçªæ˜¾äº†æ€§èƒ½é¢„æµ‹å™¨åœ¨ç®€åŒ–LLMä¸ºåŸºç¡€çš„æ™ºèƒ½ä½“ç³»ç»Ÿè®¾è®¡æ–¹é¢çš„æ½œåŠ›ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨å¤šç§ä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ï¼Œä½†ä¼˜åŒ–LLMä¸ºåŸºç¡€çš„æ™ºèƒ½ä½“ç³»ç»Ÿå…·æœ‰æŒ‘æˆ˜ã€‚</li>
<li>ç°æœ‰æ–¹æ³•å¦‚å¯å‘å¼è°ƒæ•´å’Œå…¨é¢è¯„ä¼°å­˜åœ¨è®¡ç®—æˆæœ¬é«˜å’Œä¸å¤Ÿç†æƒ³çš„é—®é¢˜ã€‚</li>
<li>Agentic Predictoræ˜¯ä¸€ç§è½»é‡çº§é¢„æµ‹å™¨ï¼Œèƒ½é«˜æ•ˆè¯„ä¼°æ™ºèƒ½ä½“å·¥ä½œæµã€‚</li>
<li>Agentic Predictoré‡‡ç”¨å¤šè§†è§’ç¼–ç æŠ€æœ¯å’Œè·¨åŸŸæ— ç›‘ç£é¢„è®­ç»ƒï¼Œæé«˜é¢„æµ‹ç²¾åº¦å¹¶å‡å°‘è¯„ä¼°æ¬¡æ•°ã€‚</li>
<li>Agentic Predictorèƒ½ä¼°ç®—ä»»åŠ¡æˆåŠŸç‡ï¼Œä¸ºä»»åŠ¡é€‰æ‹©æœ€ä½³æ™ºèƒ½ä½“å·¥ä½œæµé…ç½®ã€‚</li>
<li>åœ¨å¤šä¸ªé¢†åŸŸçš„å®éªŒè¡¨æ˜ï¼ŒAgentic Predictoråœ¨é¢„æµ‹ç²¾åº¦å’Œå·¥ä½œæµå®ç”¨æ€§ä¸Šä¼˜äºå…¶ä»–æœ€æ–°æ–¹æ³•ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.19764">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-2a86f87ea4bc481dc52c83e28d524393.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-41629a9510d9efe5417cb8b5a104fddc.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b4ef921592903f6a7496e08ea0fc7aa2.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-0f05ca1411522eb4bc144194e4426c42.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-cae72c87249d8b67bd1f55db5508e3be.jpg" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="Divide-and-Conquer-Grounding-LLMs-as-Efficient-Decision-Making-Agents-via-Offline-Hierarchical-Reinforcement-Learning"><a href="#Divide-and-Conquer-Grounding-LLMs-as-Efficient-Decision-Making-Agents-via-Offline-Hierarchical-Reinforcement-Learning" class="headerlink" title="Divide and Conquer: Grounding LLMs as Efficient Decision-Making Agents   via Offline Hierarchical Reinforcement Learning"></a>Divide and Conquer: Grounding LLMs as Efficient Decision-Making Agents   via Offline Hierarchical Reinforcement Learning</h2><p><strong>Authors:Zican Hu, Wei Liu, Xiaoye Qu, Xiangyu Yue, Chunlin Chen, Zhi Wang, Yu Cheng</strong></p>
<p>While showing sophisticated reasoning abilities, large language models (LLMs) still struggle with long-horizon decision-making tasks due to deficient exploration and long-term credit assignment, especially in sparse-reward scenarios. Inspired by the divide-and-conquer principle, we propose an innovative framework <strong>GLIDER</strong> (<strong>G</strong>rounding <strong>L</strong>anguage Models as Eff<strong>I</strong>cient <strong>D</strong>ecision-Making Agents via Offline Hi<strong>E</strong>rarchical <strong>R</strong>einforcement Learning) that introduces a parameter-efficient and generally applicable hierarchy to LLM policies. We develop a scheme where the low-level controller is supervised with abstract, step-by-step plans that are learned and instructed by the high-level policy. This design decomposes complicated problems into a series of coherent chain-of-thought reasoning sub-tasks, providing flexible temporal abstraction to significantly enhance exploration and learning for long-horizon tasks. Furthermore, GLIDER facilitates fast online adaptation to non-stationary environments owing to the strong transferability of its task-agnostic low-level skills. Experiments on ScienceWorld and ALFWorld benchmarks show that GLIDER achieves consistent performance gains, along with enhanced generalization capabilities. </p>
<blockquote>
<p>åœ¨å±•ç°å‡ºå¤æ‚æ¨ç†èƒ½åŠ›çš„åŒæ—¶ï¼Œå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä»ç„¶é¢ä¸´ç€é•¿æœŸå†³ç­–ä»»åŠ¡çš„æŒ‘æˆ˜ï¼Œè¿™ä¸»è¦æ˜¯å› ä¸ºç¼ºä¹æ¢ç´¢å’Œé•¿æœŸä¿¡ç”¨åˆ†é…ï¼Œç‰¹åˆ«æ˜¯åœ¨ç¨€ç–å¥–åŠ±åœºæ™¯ä¸­ã€‚å—â€œåˆ†è€Œæ²»ä¹‹â€åŸåˆ™çš„å¯å‘ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åˆ›æ–°æ¡†æ¶<strong>GLIDER</strong>ï¼ˆé€šè¿‡ç¦»çº¿åˆ†å±‚å¼ºåŒ–å­¦ä¹ å°†<strong>G</strong>rounding <strong>L</strong>anguageæ¨¡å‹ä½œä¸ºé«˜æ•ˆå†³ç­–ä»£ç†<strong>I</strong>ï¼‰ã€‚å®ƒå¼•å…¥äº†å¯¹LLMç­–ç•¥å…·æœ‰é€šç”¨é€‚ç”¨æ€§çš„å‚æ•°é«˜æ•ˆçš„åˆ†å±‚ç»“æ„ã€‚æˆ‘ä»¬å¼€å‘äº†ä¸€ç§æ–¹æ¡ˆï¼Œå…¶ä¸­ä½çº§æ§åˆ¶å™¨å—åˆ°æŠ½è±¡ã€é€æ­¥è®¡åˆ’çš„ç›‘ç£ï¼Œè¿™äº›è®¡åˆ’æ˜¯ç”±é«˜çº§ç­–ç•¥å­¦ä¹ å’ŒæŒ‡å¯¼çš„ã€‚è¿™ç§è®¾è®¡å°†å¤æ‚çš„é—®é¢˜åˆ†è§£ä¸ºä¸€ç³»åˆ—è¿è´¯çš„é“¾å¼æ€ç»´æ¨ç†å­ä»»åŠ¡ï¼Œæä¾›äº†çµæ´»çš„æ—¶åºæŠ½è±¡ï¼Œæ˜¾è‘—å¢å¼ºäº†é•¿æœŸä»»åŠ¡çš„æ¢ç´¢å’Œå­¦ä¹ èƒ½åŠ›ã€‚æ­¤å¤–ï¼Œç”±äºéç‰¹å®šä»»åŠ¡çš„ä½çº§æŠ€èƒ½å…·æœ‰å¼ºå¤§çš„è¿ç§»èƒ½åŠ›ï¼ŒGLIDERèƒ½å¤Ÿå¿«é€Ÿé€‚åº”éé™æ€ç¯å¢ƒã€‚åœ¨ScienceWorldå’ŒALFWorldåŸºå‡†æµ‹è¯•ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒGLIDERå®ç°äº†æ€§èƒ½çš„ä¸€è‡´æ€§æå‡ï¼Œå¹¶å¢å¼ºäº†æ³›åŒ–èƒ½åŠ›ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.19761v1">PDF</a> Accepted by ICML 2025, 21 pages</p>
<p><strong>Summary</strong></p>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨å¤„ç†é•¿æœŸå†³ç­–ä»»åŠ¡æ—¶é¢ä¸´æ¢ç´¢å’Œé•¿æœŸä¿¡ç”¨åˆ†é…çš„é—®é¢˜ï¼Œå°¤å…¶åœ¨ç¨€ç–å¥–åŠ±åœºæ™¯ä¸­è¡¨ç°æ›´ä¸ºçªå‡ºã€‚æœ¬æ–‡æå‡ºä¸€ç§åŸºäºåˆ†è€Œæ²»ä¹‹åŸåˆ™çš„åˆ›æ–°æ¡†æ¶GLIDERï¼Œä¸ºLLMç­–ç•¥å¼•å…¥å‚æ•°é«˜æ•ˆä¸”æ™®éé€‚ç”¨çš„å±‚æ¬¡ç»“æ„ã€‚GLIDERè®¾è®¡ä½å±‚æ¬¡æ§åˆ¶å™¨ï¼Œé€šè¿‡é«˜å±‚æ¬¡ç­–ç•¥çš„æŒ‡å¯¼å’Œå­¦ä¹ ï¼Œä»¥æŠ½è±¡ã€åˆ†æ­¥è®¡åˆ’è¿›è¡Œç›‘ç£ã€‚è¿™åˆ†è§£äº†å¤æ‚é—®é¢˜ï¼Œæä¾›çµæ´»çš„æ—¶é—´æŠ½è±¡ï¼Œæ˜¾è‘—å¢å¼ºäº†é•¿æœŸä»»åŠ¡çš„æ¢ç´¢å’Œå­¦ä¹ èƒ½åŠ›ã€‚æ­¤å¤–ï¼ŒGLIDERè¿˜ä¾¿äºå¯¹éç¨³å®šç¯å¢ƒçš„å¿«é€Ÿåœ¨çº¿é€‚åº”ã€‚åœ¨ScienceWorldå’ŒALFWorldåŸºå‡†æµ‹è¯•ä¸Šï¼ŒGLIDERå®ç°äº†æ€§èƒ½ä¸Šçš„æŒç»­æå‡ï¼Œå¹¶å¢å¼ºäº†æ³›åŒ–èƒ½åŠ›ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨å¤„ç†é•¿æœŸå†³ç­–ä»»åŠ¡æ—¶å­˜åœ¨æ¢ç´¢å’Œé•¿æœŸä¿¡ç”¨åˆ†é…çš„é—®é¢˜ã€‚</li>
<li>GLIDERæ¡†æ¶å¼•å…¥å‚æ•°é«˜æ•ˆä¸”æ™®éé€‚ç”¨çš„å±‚æ¬¡ç»“æ„æ¥è§£å†³LLMçš„ç­–ç•¥é—®é¢˜ã€‚</li>
<li>GLIDERè®¾è®¡ä½å±‚æ¬¡æ§åˆ¶å™¨ï¼Œé€šè¿‡é«˜å±‚æ¬¡ç­–ç•¥çš„æŒ‡å¯¼å’Œå­¦ä¹ ï¼Œä»¥æŠ½è±¡ã€åˆ†æ­¥è®¡åˆ’è¿›è¡Œç›‘ç£ã€‚</li>
<li>GLIDERå°†å¤æ‚é—®é¢˜åˆ†è§£ä¸ºä¸€ç³»åˆ—è¿è´¯çš„å­ä»»åŠ¡ï¼Œæä¾›çµæ´»çš„æ—¶é—´æŠ½è±¡ï¼Œå¢å¼ºé•¿æœŸä»»åŠ¡çš„æ¢ç´¢å’Œå­¦ä¹ èƒ½åŠ›ã€‚</li>
<li>GLIDERæ¡†æ¶æœ‰åŠ©äºå¿«é€Ÿé€‚åº”éç¨³å®šç¯å¢ƒã€‚</li>
<li>åœ¨ScienceWorldå’ŒALFWorldæµ‹è¯•ä¸­ï¼ŒGLIDERå®ç°äº†æ€§èƒ½æå‡ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.19761">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-a2fa000c33cda83395d18e76af4f6ef1.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-9bcd953fb8217d52ce1dc2e4bc877dc8.jpg" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1><h2 id="JEDI-Latent-End-to-end-Diffusion-Mitigates-Agent-Human-Performance-Asymmetry-in-Model-Based-Reinforcement-Learning"><a href="#JEDI-Latent-End-to-end-Diffusion-Mitigates-Agent-Human-Performance-Asymmetry-in-Model-Based-Reinforcement-Learning" class="headerlink" title="JEDI: Latent End-to-end Diffusion Mitigates Agent-Human Performance   Asymmetry in Model-Based Reinforcement Learning"></a>JEDI: Latent End-to-end Diffusion Mitigates Agent-Human Performance   Asymmetry in Model-Based Reinforcement Learning</h2><p><strong>Authors:Jing Yu Lim, Zarif Ikram, Samson Yu, Haozhe Ma, Tze-Yun Leong, Dianbo Liu</strong></p>
<p>Recent advances in model-based reinforcement learning (MBRL) have achieved super-human level performance on the Atari100k benchmark, driven by reinforcement learning agents trained on powerful diffusion world models. However, we identify that the current aggregates mask a major performance asymmetry: MBRL agents dramatically outperform humans in some tasks despite drastically underperforming in others, with the former inflating the aggregate metrics. This is especially pronounced in pixel-based agents trained with diffusion world models. In this work, we address the pronounced asymmetry observed in pixel-based agents as an initial attempt to reverse the worrying upward trend observed in them. We address the problematic aggregates by delineating all tasks as Agent-Optimal or Human-Optimal and advocate for equal importance on metrics from both sets. Next, we hypothesize this pronounced asymmetry is due to the lack of temporally-structured latent space trained with the World Model objective in pixel-based methods. Lastly, to address this issue, we propose Joint Embedding DIffusion (JEDI), a novel latent diffusion world model trained end-to-end with the self-consistency objective. JEDI outperforms SOTA models in human-optimal tasks while staying competitive across the Atari100k benchmark, and runs 3 times faster with 43% lower memory than the latest pixel-based diffusion baseline. Overall, our work rethinks what it truly means to cross human-level performance in Atari100k. </p>
<blockquote>
<p>è¿‘æœŸåŸºäºæ¨¡å‹çš„å¼ºåŒ–å­¦ä¹ ï¼ˆMBRLï¼‰çš„è¿›å±•å·²ç»åœ¨Atari100kåŸºå‡†æµ‹è¯•ä¸Šè¾¾åˆ°äº†è¶…äººç±»æ°´å¹³çš„æ€§èƒ½ï¼Œå…¶é©±åŠ¨å› ç´ æ˜¯ç»è¿‡å¼ºå¤§çš„æ‰©æ•£ä¸–ç•Œæ¨¡å‹è®­ç»ƒçš„å¼ºåŒ–å­¦ä¹ æ™ºèƒ½ä½“ã€‚ç„¶è€Œï¼Œæˆ‘ä»¬å‘ç°å½“å‰çš„æ±‡æ€»æ•°æ®æ©ç›–äº†ä¸»è¦çš„æ€§èƒ½ä¸å¯¹ç§°ï¼šåœ¨æŸäº›ä»»åŠ¡ä¸­ï¼ŒMBRLæ™ºèƒ½ä½“çš„è¡¨ç°è¿œè¿œè¶…è¿‡äº†äººç±»ï¼Œå°½ç®¡åœ¨å…¶ä»–ä»»åŠ¡ä¸­å…¶è¡¨ç°è¿œä¸å¦‚äººç±»ï¼Œè€Œå‰è€…å¾€å¾€ä¼šæŠ¬é«˜æ±‡æ€»æŒ‡æ ‡ã€‚è¿™åœ¨åŸºäºåƒç´ çš„ä»£ç†è®­ç»ƒä¸­å°¤ä¸ºæ˜æ˜¾ï¼Œè¿™äº›ä»£ç†æ˜¯ä½¿ç”¨æ‰©æ•£ä¸–ç•Œæ¨¡å‹è¿›è¡Œè®­ç»ƒçš„ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬å…³æ³¨åœ¨åŸºäºåƒç´ çš„ä»£ç†ä¸­è§‚å¯Ÿåˆ°çš„æ˜æ˜¾ä¸å¯¹ç§°ç°è±¡ï¼Œä½œä¸ºåˆæ­¥å°è¯•æ¥æ‰­è½¬è¿™ç§ä»¤äººæ‹…å¿§çš„ä¸Šå‡è¶‹åŠ¿ã€‚æˆ‘ä»¬é€šè¿‡å°†ä»»åŠ¡åˆ’åˆ†ä¸ºä»¥æ™ºèƒ½ä½“ä¸ºä¸­å¿ƒçš„æœ€ä¼˜ä»»åŠ¡æˆ–ä»¥äººç±»ä¸ºä¸­å¿ƒçš„æœ€ä¼˜ä»»åŠ¡æ¥è§£å†³å­˜åœ¨é—®é¢˜çš„æ±‡æ€»æ•°æ®é—®é¢˜ï¼Œå¹¶ä¸»å¼ å¯¹ä¸¤ç»„æŒ‡æ ‡ç»™äºˆåŒç­‰é‡è§†ã€‚æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å‡è®¾è¿™ç§æ˜æ˜¾çš„ä¸å¯¹ç§°æ€§æ˜¯ç”±äºåŸºäºåƒç´ çš„æ–¹æ³•åœ¨ç¼ºä¹ä¸ä¸–ç•Œæ¨¡å‹ç›®æ ‡ç»“æ„åŒ–çš„æ—¶é—´ç»“æ„æ½œåœ¨ç©ºé—´è®­ç»ƒæ‰€å¯¼è‡´çš„ã€‚æœ€åï¼Œä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†è”åˆåµŒå…¥æ‰©æ•£ï¼ˆJEDIï¼‰ï¼Œè¿™æ˜¯ä¸€ç§æ–°å‹æ½œåœ¨æ‰©æ•£ä¸–ç•Œæ¨¡å‹ï¼Œé€šè¿‡ç«¯åˆ°ç«¯çš„è‡ªä¸€è‡´æ€§ç›®æ ‡è¿›è¡Œè®­ç»ƒã€‚JEDIåœ¨äººç±»æœ€ä¼˜ä»»åŠ¡ä¸­è¶…è¶Šäº†æœ€æ–°æŠ€æœ¯æ°´å¹³çš„æ¨¡å‹ï¼ŒåŒæ—¶åœ¨Atari100kåŸºå‡†æµ‹è¯•ä¸­ä¿æŒç«äº‰åŠ›ï¼Œå¹¶ä¸”ä¸æœ€æ–°çš„åŸºäºåƒç´ çš„æ‰©æ•£åŸºå‡†ç›¸æ¯”ï¼Œè¿è¡Œé€Ÿåº¦å¿«ä¸‰å€ï¼Œå†…å­˜é™ä½äº†43%ã€‚æ€»çš„æ¥è¯´ï¼Œæˆ‘ä»¬çš„å·¥ä½œé‡æ–°æ€è€ƒäº†åœ¨Atari100kåŸºå‡†æµ‹è¯•ä¸­è¾¾åˆ°è¶…è¶Šäººç±»æ°´å¹³æ€§èƒ½çš„çœŸæ­£å«ä¹‰ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.19698v1">PDF</a> Preprint</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æ¢è®¨äº†åŸºäºæ¨¡å‹çš„å¼ºåŒ–å­¦ä¹ ï¼ˆMBRLï¼‰åœ¨Atari100kåŸºå‡†æµ‹è¯•ä¸Šçš„æ€§èƒ½é—®é¢˜ã€‚å°½ç®¡MBRLåœ¨æŸäº›ä»»åŠ¡ä¸Šè¡¨ç°è¶…å¸¸ï¼Œä½†åœ¨å…¶ä»–ä»»åŠ¡ä¸Šå´è¿œè¿œè½åäºäººç±»ã€‚æ–‡ç« æå‡ºå¯¹åƒç´ çº§ä»£ç†ä¸­è§‚å¯Ÿåˆ°çš„æ˜æ˜¾ä¸å¯¹ç§°æ€§è¿›è¡Œåˆæ­¥è§£å†³ï¼Œé€šè¿‡æå‡ºè”åˆåµŒå…¥æ‰©æ•£ï¼ˆJEDIï¼‰æ¨¡å‹æ¥æ”¹å–„äººç±»æœ€ä¼˜ä»»åŠ¡ä¸­çš„æ€§èƒ½ï¼ŒåŒæ—¶åœ¨æ•´ä¸ªAtari100kåŸºå‡†æµ‹è¯•ä¸­ä¿æŒç«äº‰åŠ›ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>MBRLåœ¨æŸäº›ä»»åŠ¡ä¸Šçš„è¡¨ç°è¿œè¶…äººç±»ï¼Œä½†åœ¨å…¶ä»–ä»»åŠ¡ä¸Šå´è¿œè¿œè½åï¼Œå¯¼è‡´æ•´ä½“æ€§èƒ½æŒ‡æ ‡å­˜åœ¨åå·®ã€‚</li>
<li>ç°æœ‰èšåˆæŒ‡æ ‡æ©ç›–äº†æ€§èƒ½ä¸å¯¹ç§°çš„é—®é¢˜ï¼Œç‰¹åˆ«æ˜¯åœ¨åƒç´ çº§ä»£ç†ä¸Šè®­ç»ƒçš„æ‰©æ•£ä¸–ç•Œæ¨¡å‹ä¸­è¡¨ç°æ›´ä¸ºçªå‡ºã€‚</li>
<li>æ–‡ç« æå‡ºäº†ä¸€ç§è§£å†³åƒç´ çº§ä»£ç†ä¸­æ˜æ˜¾ä¸å¯¹ç§°æ€§çš„æ–¹æ³•ï¼Œå³é€šè¿‡æå‡ºè”åˆåµŒå…¥æ‰©æ•£ï¼ˆJEDIï¼‰æ¨¡å‹æ¥æ”¹å–„äººç±»æœ€ä¼˜ä»»åŠ¡ä¸­çš„æ€§èƒ½ã€‚</li>
<li>JEDIæ¨¡å‹é€šè¿‡ç«¯åˆ°ç«¯è®­ç»ƒå’Œè‡ªä¸€è‡´æ€§ç›®æ ‡æ¥è®­ç»ƒæ½œä¼æ‰©æ•£ä¸–ç•Œæ¨¡å‹ï¼Œæ˜¾è‘—æé«˜äº†æ€§èƒ½ã€‚</li>
<li>JEDIæ¨¡å‹åœ¨ä¿æŒç«äº‰åŠ›çš„åŒæ—¶ï¼Œè¿è¡Œé€Ÿåº¦æ¯”æœ€æ–°çš„åƒç´ çº§æ‰©æ•£åŸºçº¿å¿«ä¸‰å€ï¼ŒåŒæ—¶å†…å­˜å ç”¨å‡å°‘43%ã€‚</li>
<li>æ–‡ç« é‡æ–°å®¡è§†äº†åœ¨Atari100kåŸºå‡†æµ‹è¯•ä¸­è¾¾åˆ°äººç±»æ°´å¹³çš„çœŸæ­£å«ä¹‰ã€‚å¼ºè°ƒæ—¢è¦å…³æ³¨ä»»åŠ¡çš„ä»£ç†æœ€ä¼˜æŒ‡æ ‡ï¼Œä¹Ÿè¦å…³æ³¨äººç±»æœ€ä¼˜æŒ‡æ ‡çš„é‡è¦æ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.19698">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-7d195b0d06e50867028c989bd6a1c520.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-9b2fa6709b3beaf6921e39d823f452bb.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-50e011d23cda612b2a31df7cdd1924bc.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-6960958586b6893fb95331e62f80e769.jpg" align="middle">
</details>


<h1 id="-9"><a href="#-9" class="headerlink" title=""></a></h1><h2 id="O-2-Searcher-A-Searching-based-Agent-Model-for-Open-Domain-Open-Ended-Question-Answering"><a href="#O-2-Searcher-A-Searching-based-Agent-Model-for-Open-Domain-Open-Ended-Question-Answering" class="headerlink" title="O$^2$-Searcher: A Searching-based Agent Model for Open-Domain Open-Ended   Question Answering"></a>O$^2$-Searcher: A Searching-based Agent Model for Open-Domain Open-Ended   Question Answering</h2><p><strong>Authors:Jianbiao Mei, Tao Hu, Daocheng Fu, Licheng Wen, Xuemeng Yang, Rong Wu, Pinlong Cai, Xinyu Cai, Xing Gao, Yu Yang, Chengjun Xie, Botian Shi, Yong Liu, Yu Qiao</strong></p>
<p>Large Language Models (LLMs), despite their advancements, are fundamentally limited by their static parametric knowledge, hindering performance on tasks requiring open-domain up-to-date information. While enabling LLMs to interact with external knowledge environments is a promising solution, current efforts primarily address closed-end problems. Open-ended questions, which characterized by lacking a standard answer or providing non-unique and diverse answers, remain underexplored. To bridge this gap, we present O$^2$-Searcher, a novel search agent leveraging reinforcement learning to effectively tackle both open-ended and closed-ended questions in the open domain. O$^2$-Searcher leverages an efficient, locally simulated search environment for dynamic knowledge acquisition, effectively decoupling the external world knowledge from modelâ€™s sophisticated reasoning processes. It employs a unified training mechanism with meticulously designed reward functions, enabling the agent to identify problem types and adapt different answer generation strategies. Furthermore, to evaluate performance on complex open-ended tasks, we construct O$^2$-QA, a high-quality benchmark featuring 300 manually curated, multi-domain open-ended questions with associated web page caches. Extensive experiments show that O$^2$-Searcher, using only a 3B model, significantly surpasses leading LLM agents on O$^2$-QA. It also achieves SOTA results on various closed-ended QA benchmarks against similarly-sized models, while performing on par with much larger ones. </p>
<blockquote>
<p>å°½ç®¡å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å–å¾—äº†è¿›å±•ï¼Œä½†å®ƒä»¬ä»ç„¶å—åˆ°é™æ€å‚æ•°çŸ¥è¯†çš„æ ¹æœ¬é™åˆ¶ï¼Œè¿™é˜»ç¢äº†å®ƒä»¬åœ¨éœ€è¦å¼€æ”¾é¢†åŸŸæœ€æ–°ä¿¡æ¯çš„ä»»åŠ¡ä¸Šçš„è¡¨ç°ã€‚è™½ç„¶è®©LLMsä¸å¤–éƒ¨ç¯å¢ƒè¿›è¡Œäº¤äº’æ˜¯ä¸€ä¸ªæœ‰å‰æ™¯çš„è§£å†³æ–¹æ¡ˆï¼Œä½†ç›®å‰çš„åŠªåŠ›ä¸»è¦é›†ä¸­äºè§£å†³å°é—­å¼é—®é¢˜ã€‚å¼€æ”¾å¼é—®é¢˜ï¼ˆå…¶ç‰¹ç‚¹æ˜¯ç¼ºä¹æ ‡å‡†ç­”æ¡ˆæˆ–æä¾›éå”¯ä¸€å’Œå¤šæ ·åŒ–çš„ç­”æ¡ˆï¼‰ä»ç„¶è¢«æ¢ç´¢å¾—å¾ˆå°‘ã€‚ä¸ºäº†å¼¥è¡¥è¿™ä¸€å·®è·ï¼Œæˆ‘ä»¬æå‡ºäº†O$^2$-Searcherï¼Œè¿™æ˜¯ä¸€ä¸ªæ–°å‹æœç´¢ä»£ç†ï¼Œåˆ©ç”¨å¼ºåŒ–å­¦ä¹ æœ‰æ•ˆåœ°è§£å†³å¼€æ”¾å¼å’Œå°é—­å¼é—®é¢˜ã€‚O$^2$-Searcheråˆ©ç”¨é«˜æ•ˆã€å±€éƒ¨æ¨¡æ‹Ÿçš„æœç´¢ç¯å¢ƒè¿›è¡ŒåŠ¨æ€çŸ¥è¯†è·å–ï¼Œæœ‰æ•ˆåœ°å°†å¤–éƒ¨ä¸–ç•ŒçŸ¥è¯†ä¸æ¨¡å‹çš„å¤æ‚æ¨ç†è¿‡ç¨‹è§£è€¦ã€‚å®ƒé‡‡ç”¨ç»Ÿä¸€çš„è®­ç»ƒæœºåˆ¶å’Œç²¾å¿ƒè®¾è®¡çš„å¥–åŠ±å‡½æ•°ï¼Œä½¿ä»£ç†èƒ½å¤Ÿè¯†åˆ«é—®é¢˜ç±»å‹å¹¶é‡‡ç”¨ä¸åŒçš„ç­”æ¡ˆç”Ÿæˆç­–ç•¥ã€‚æ­¤å¤–ï¼Œä¸ºäº†è¯„ä¼°åœ¨å¤æ‚å¼€æ”¾å¼ä»»åŠ¡ä¸Šçš„æ€§èƒ½ï¼Œæˆ‘ä»¬æ„å»ºäº†O$^2$-QAï¼Œè¿™æ˜¯ä¸€ä¸ªé«˜è´¨é‡åŸºå‡†æµ‹è¯•ï¼ŒåŒ…å«300ä¸ªæ‰‹åŠ¨æ•´ç†çš„å¤šé¢†åŸŸå¼€æ”¾å¼é—®é¢˜åŠå…¶ç›¸å…³ç½‘é¡µç¼“å­˜ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼Œä»…ä½¿ç”¨3Bæ¨¡å‹çš„O$^2$-Searcheråœ¨O$^2$-QAä¸Šæ˜¾è‘—è¶…è¶Šäº†é¢†å…ˆçš„å¤§å‹è¯­è¨€æ¨¡å‹ä»£ç†ã€‚å®ƒåœ¨å„ç§å°é—­å¼é—®ç­”åŸºå‡†æµ‹è¯•ä¸Šä¹Ÿå–å¾—äº†æœ€æ–°ç»“æœï¼ŒåŒæ—¶ä¸æ›´å¤§çš„æ¨¡å‹è¡¨ç°ç›¸å½“ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.16582v2">PDF</a> 25 pages, 9 figures</p>
<p><strong>Summary</strong></p>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨åº”å¯¹éœ€è¦å¼€æ”¾é¢†åŸŸå³æ—¶ä¿¡æ¯çš„ä»»åŠ¡ä¸Šå­˜åœ¨å±€é™ï¼Œå°½ç®¡æœ‰æ‰€è¿›å±•ï¼Œä½†å…¶é™æ€å‚æ•°çŸ¥è¯†ä»æ˜¯æ ¹æœ¬é™åˆ¶ã€‚ä¸ºè§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†O$^2$-Searcherï¼Œä¸€ä¸ªåˆ©ç”¨å¼ºåŒ–å­¦ä¹ æœ‰æ•ˆåº”å¯¹å¼€æ”¾å’Œå°é—­é—®é¢˜çš„æ–°å‹æœç´¢ä»£ç†ã€‚å®ƒé€šè¿‡é«˜æ•ˆçš„æœ¬åœ°æ¨¡æ‹Ÿæœç´¢ç¯å¢ƒå®ç°åŠ¨æ€çŸ¥è¯†è·å–ï¼Œå°†å¤–éƒ¨ä¸–ç•ŒçŸ¥è¯†ä¸æ¨¡å‹çš„å¤æ‚æ¨ç†è¿‡ç¨‹åˆ†ç¦»ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æ„å»ºäº†O$^2$-QAåŸºå‡†æµ‹è¯•ï¼Œä»¥è¯„ä¼°åœ¨å¤æ‚å¼€æ”¾ä»»åŠ¡ä¸Šçš„æ€§èƒ½ã€‚å®éªŒè¡¨æ˜ï¼ŒO$^2$-Searcheråœ¨O$^2$-QAä¸Šçš„è¡¨ç°æ˜¾è‘—ä¼˜äºé¢†å…ˆçš„å¤§å‹è¯­è¨€æ¨¡å‹ä»£ç†ï¼ŒåŒæ—¶åœ¨å„ç§å°é—­é—®ç­”åŸºå‡†æµ‹è¯•ä¸­å®ç°äº†æœ€ä½³ç»“æœã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>LLMså—é™äºé™æ€å‚æ•°çŸ¥è¯†ï¼Œéš¾ä»¥å¤„ç†éœ€è¦å¼€æ”¾é¢†åŸŸå³æ—¶ä¿¡æ¯çš„ä»»åŠ¡ã€‚</li>
<li>O$^2$-Searcheræ˜¯ä¸€ä¸ªæ–°å‹æœç´¢ä»£ç†ï¼Œåˆ©ç”¨å¼ºåŒ–å­¦ä¹ åº”å¯¹å¼€æ”¾å’Œå°é—­é—®é¢˜ã€‚</li>
<li>O$^2$-Searcheré€šè¿‡æœ¬åœ°æ¨¡æ‹Ÿæœç´¢ç¯å¢ƒå®ç°åŠ¨æ€çŸ¥è¯†è·å–ï¼Œåˆ†ç¦»å¤–éƒ¨ä¸–ç•ŒçŸ¥è¯†ä¸æ¨¡å‹æ¨ç†è¿‡ç¨‹ã€‚</li>
<li>O$^2$-Searcherä½¿ç”¨ç»Ÿä¸€çš„è®­ç»ƒæœºåˆ¶å’Œç²¾å¿ƒè®¾è®¡çš„å¥–åŠ±å‡½æ•°ï¼Œèƒ½è¯†åˆ«é—®é¢˜ç±»å‹å¹¶é€‚åº”ä¸åŒçš„ç­”æ¡ˆç”Ÿæˆç­–ç•¥ã€‚</li>
<li>O$^2$-QAåŸºå‡†æµ‹è¯•ç”¨äºè¯„ä¼°åœ¨å¤æ‚å¼€æ”¾ä»»åŠ¡ä¸Šçš„æ€§èƒ½ã€‚</li>
<li>O$^2$-Searcheråœ¨O$^2$-QAä¸Šçš„è¡¨ç°ä¼˜äºå…¶ä»–LLMä»£ç†ï¼ŒåŒæ—¶åœ¨å°é—­é—®ç­”åŸºå‡†æµ‹è¯•ä¸­å®ç°æœ€ä½³ç»“æœã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.16582">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-f7c9531ab7a4ed8d9c82292f41ece53a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-4b8a2a3bec0c619d0bd283c919a14b9d.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-1d14ba5cf04f2b87a3c074368134e999.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-b8577460e43a987c0b9ce0ecd0bcf8e4.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-36c9a2ec9ca7826a16f52102bac095ff.jpg" align="middle">
</details>


<h1 id="-10"><a href="#-10" class="headerlink" title=""></a></h1><h2 id="Mobile-Bench-v2-A-More-Realistic-and-Comprehensive-Benchmark-for-VLM-based-Mobile-Agents"><a href="#Mobile-Bench-v2-A-More-Realistic-and-Comprehensive-Benchmark-for-VLM-based-Mobile-Agents" class="headerlink" title="Mobile-Bench-v2: A More Realistic and Comprehensive Benchmark for   VLM-based Mobile Agents"></a>Mobile-Bench-v2: A More Realistic and Comprehensive Benchmark for   VLM-based Mobile Agents</h2><p><strong>Authors:Weikai Xu, Zhizheng Jiang, Yuxuan Liu, Pengzhi Gao, Wei Liu, Jian Luan, Yuanchun Li, Yunxin Liu, Bin Wang, Bo An</strong></p>
<p>VLM-based mobile agents are increasingly popular due to their capabilities to interact with smartphone GUIs and XML-structured texts and to complete daily tasks. However, existing online benchmarks struggle with obtaining stable reward signals due to dynamic environmental changes. Offline benchmarks evaluate the agents through single-path trajectories, which stands in contrast to the inherently multi-solution characteristics of GUI tasks. Additionally, both types of benchmarks fail to assess whether mobile agents can handle noise or engage in proactive interactions due to a lack of noisy apps or overly full instructions during the evaluation process. To address these limitations, we use a slot-based instruction generation method to construct a more realistic and comprehensive benchmark named Mobile-Bench-v2. Mobile-Bench-v2 includes a common task split, with offline multi-path evaluation to assess the agentâ€™s ability to obtain step rewards during task execution. It contains a noisy split based on pop-ups and ads apps, and a contaminated split named AITZ-Noise to formulate a real noisy environment. Furthermore, an ambiguous instruction split with preset Q&amp;A interactions is released to evaluate the agentâ€™s proactive interaction capabilities. We conduct evaluations on these splits using the single-agent framework AppAgent-v1, the multi-agent framework Mobile-Agent-v2, as well as other mobile agents such as UI-Tars and OS-Atlas. Code and data are available at <a target="_blank" rel="noopener" href="https://huggingface.co/datasets/xwk123/MobileBench-v2">https://huggingface.co/datasets/xwk123/MobileBench-v2</a>. </p>
<blockquote>
<p>åŸºäºVLMçš„ç§»åŠ¨æ™ºèƒ½ä½“å› å…¶èƒ½å¤Ÿä¸æ™ºèƒ½æ‰‹æœºGUIå’ŒXMLç»“æ„æ–‡æœ¬è¿›è¡Œäº¤äº’å¹¶å®Œæˆæ—¥å¸¸ä»»åŠ¡è€Œè¶Šæ¥è¶Šå—æ¬¢è¿ã€‚ç„¶è€Œï¼Œç°æœ‰çš„åœ¨çº¿åŸºå‡†æµ‹è¯•å› åŠ¨æ€ç¯å¢ƒå˜åŒ–è€Œæ— æ³•è·å¾—ç¨³å®šçš„å¥–åŠ±ä¿¡å·ã€‚ç¦»çº¿åŸºå‡†æµ‹è¯•é€šè¿‡å•ä¸€è·¯å¾„è½¨è¿¹è¯„ä¼°æ™ºèƒ½ä½“ï¼Œè¿™ä¸GUIä»»åŠ¡å›ºæœ‰çš„å¤šè§£å†³æ–¹æ¡ˆç‰¹æ€§å½¢æˆé²œæ˜å¯¹æ¯”ã€‚æ­¤å¤–ï¼Œä¸¤ç§ç±»å‹çš„åŸºå‡†æµ‹è¯•éƒ½æœªèƒ½è¯„ä¼°ç§»åŠ¨æ™ºèƒ½ä½“æ˜¯å¦èƒ½å¤Ÿå¤„ç†å™ªå£°æˆ–è¿›è¡Œä¸»åŠ¨äº¤äº’ï¼Œå› ä¸ºåœ¨è¯„ä¼°è¿‡ç¨‹ä¸­ç¼ºä¹å™ªå£°åº”ç”¨ç¨‹åºæˆ–è¿‡äºå®Œæ•´çš„æŒ‡ä»¤ã€‚ä¸ºäº†è§£å†³è¿™äº›å±€é™æ€§ï¼Œæˆ‘ä»¬ä½¿ç”¨åŸºäºæ’æ§½çš„æŒ‡ä»¤ç”Ÿæˆæ–¹æ³•æ¥æ„å»ºæ›´çœŸå®ã€æ›´å…¨é¢çš„åä¸ºMobile-Bench-v2çš„åŸºå‡†æµ‹è¯•ã€‚Mobile-Bench-v2åŒ…æ‹¬ä»»åŠ¡åˆ†å‰²ï¼Œå…·æœ‰ç¦»çº¿å¤šè·¯å¾„è¯„ä¼°ï¼Œä»¥è¯„ä¼°æ™ºèƒ½ä½“åœ¨æ‰§è¡Œä»»åŠ¡è¿‡ç¨‹ä¸­è·å¾—é˜¶æ®µæ€§å¥–åŠ±çš„èƒ½åŠ›ã€‚å®ƒåŒ…å«åŸºäºå¼¹å‡ºçª—å£å’Œå¹¿å‘Šåº”ç”¨ç¨‹åºçš„å™ªå£°åˆ†å‰²ï¼Œä»¥åŠåä¸ºAITZ-Noiseçš„æ±¡æŸ“åˆ†å‰²ï¼Œä»¥å½¢æˆçœŸå®å™ªå£°ç¯å¢ƒã€‚æ­¤å¤–ï¼Œè¿˜å‘å¸ƒäº†ä¸€ä¸ªå¸¦æœ‰é¢„è®¾é—®ç­”äº’åŠ¨çš„æ¨¡ç³ŠæŒ‡ä»¤åˆ†å‰²ï¼Œä»¥è¯„ä¼°æ™ºèƒ½ä½“çš„ä¸»åŠ¨äº¤äº’èƒ½åŠ›ã€‚æˆ‘ä»¬ä½¿ç”¨å•æ™ºèƒ½ä½“æ¡†æ¶AppAgent-v1ã€å¤šæ™ºèƒ½ä½“æ¡†æ¶Mobile-Agent-v2ä»¥åŠå…¶ä»–ç§»åŠ¨æ™ºèƒ½ä½“å¦‚UI-Tarså’ŒOS-Atlaså¯¹è¿™äº›åˆ†å‰²è¿›è¡Œäº†è¯„ä¼°ã€‚ä»£ç å’Œæ•°æ®å¯åœ¨<a target="_blank" rel="noopener" href="https://huggingface.co/datasets/xwk123/MobileBench-v2%E4%B8%8A%E6%89%BE%E5%88%B0%E3%80%82">https://huggingface.co/datasets/xwk123/MobileBench-v2ä¸Šæ‰¾åˆ°ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.11891v2">PDF</a> </p>
<p><strong>æ€»ç»“</strong><br>    åŸºäºVLMçš„ç§»åŠ¨ä»£ç†å› èƒ½ä¸æ™ºèƒ½æ‰‹æœºGUIå’ŒXMLç»“æ„æ–‡æœ¬äº¤äº’å¹¶å®Œæˆæ—¥å¸¸ä»»åŠ¡è€Œæ—¥ç›Šæ™®åŠã€‚ç„¶è€Œï¼Œç°æœ‰çº¿ä¸Šè¯„ä¼°æ ‡å‡†åœ¨åŠ¨æ€ç¯å¢ƒå˜åŒ–ä¸­éš¾ä»¥è·å¾—ç¨³å®šçš„å¥–åŠ±ä¿¡å·ã€‚çº¿ä¸‹è¯„ä¼°æ ‡å‡†åˆ™é€šè¿‡å•ä¸€è·¯å¾„è½¨è¿¹æ¥è¯„ä¼°ä»£ç†ï¼Œè¿™ä¸GUIä»»åŠ¡æœ¬è´¨ä¸Šå¤šè§£çš„ç‰¹ç‚¹ç›¸æ‚–ã€‚ä¸ºè§£å†³è¿™äº›å±€é™ï¼Œé‡‡ç”¨åŸºäºæ’æ§½çš„æŒ‡ä»¤ç”Ÿæˆæ–¹æ³•æ„å»ºäº†ä¸€ä¸ªæ›´çœŸå®ã€å…¨é¢çš„MobileBench-v2è¯„ä¼°æ ‡å‡†ã€‚å®ƒåŒ…æ‹¬é€šç”¨ä»»åŠ¡åˆ†å‰²ã€ç¦»çº¿å¤šè·¯å¾„è¯„ä¼°ä»¥è¯„ä¼°ä»£ç†åœ¨æ‰§è¡Œä»»åŠ¡è¿‡ç¨‹ä¸­è·å¾—é˜¶æ®µæ€§å¥–åŠ±çš„èƒ½åŠ›ã€‚è¿˜åŒ…æ‹¬åŸºäºå¼¹çª—å’Œå¹¿å‘Šåº”ç”¨çš„å™ªå£°åˆ†å‰²ä»¥åŠç”¨äºå½¢æˆçœŸå®å™ªå£°ç¯å¢ƒçš„AITZå™ªå£°åˆ†å‰²ã€‚æ­¤å¤–ï¼Œè¿˜å‘å¸ƒäº†å¸¦æœ‰é¢„è®¾é—®ç­”äº’åŠ¨çš„æ¨¡ç³ŠæŒ‡ä»¤åˆ†å‰²ï¼Œä»¥è¯„ä¼°ä»£ç†çš„ä¸»åŠ¨äº’åŠ¨èƒ½åŠ›ã€‚æˆ‘ä»¬ä½¿ç”¨äº†AppAgent-v1å•ä»£ç†æ¡†æ¶ã€Mobile-Agent-v2å¤šä»£ç†æ¡†æ¶ä»¥åŠå…¶ä»–ç§»åŠ¨ä»£ç†å¦‚UI-Tarså’ŒOS-Atlasè¿›è¡Œäº†è¯„ä¼°ã€‚ç›¸å…³ä»£ç å’Œæ•°æ®å¯åœ¨<a target="_blank" rel="noopener" href="https://huggingface.co/datasets/xwk123/MobileBench-v2%E8%8E%B7%E5%8F%96%E3%80%82">https://huggingface.co/datasets/xwk123/MobileBench-v2è·å–ã€‚</a></p>
<p><strong>å…³é”®è§è§£</strong></p>
<ol>
<li>VLMç§»åŠ¨ä»£ç†å…·æœ‰ä¸æ™ºèƒ½æ‰‹æœºGUIå’ŒXMLæ–‡æœ¬äº¤äº’çš„èƒ½åŠ›ï¼Œå¯å®Œæˆæ—¥å¸¸ä»»åŠ¡ï¼Œå› æ­¤è¶Šæ¥è¶Šå—æ¬¢è¿ã€‚</li>
<li>ç°æœ‰çº¿ä¸Šå’Œçº¿ä¸‹è¯„ä¼°æ ‡å‡†å­˜åœ¨å±€é™æ€§ï¼Œæ— æ³•ç¨³å®šè¯„ä¼°åŠ¨æ€ç¯å¢ƒä¸­çš„å¥–åŠ±ä¿¡å·æˆ–åæ˜ GUIä»»åŠ¡çš„å¤šè§£ç‰¹æ€§ã€‚</li>
<li>MobileBench-v2é€šè¿‡æ›´ç°å®çš„è¯„ä¼°æ ‡å‡†è§£å†³äº†è¿™äº›é™åˆ¶ï¼ŒåŒ…æ‹¬å¤šè·¯å¾„è¯„ä¼°ã€å™ªå£°åˆ†å‰²ä»¥æ¨¡æ‹ŸçœŸå®å™ªå£°ç¯å¢ƒï¼Œä»¥åŠæ¨¡ç³ŠæŒ‡ä»¤åˆ†å‰²ä»¥è¯„ä¼°ä»£ç†çš„ä¸»åŠ¨äº’åŠ¨èƒ½åŠ›ã€‚</li>
<li>MobileBench-v2åŒ…æ‹¬é€šç”¨ä»»åŠ¡åˆ†å‰²ï¼Œæ—¨åœ¨å…¨é¢è¯„ä¼°ä»£ç†åœ¨å®Œæˆä»»åŠ¡è¿‡ç¨‹ä¸­çš„èƒ½åŠ›ï¼ŒåŒ…æ‹¬è·å¾—é˜¶æ®µæ€§å¥–åŠ±çš„èƒ½åŠ›ã€‚</li>
<li>MobileBench-v2è¯„ä¼°å’Œæµ‹è¯•æ¡†æ¶å¯ç”¨äºå¤šç§ç§»åŠ¨ä»£ç†ï¼Œå¦‚AppAgent-v1ã€Mobile-Agent-v2ã€UI-Tarså’ŒOS-Atlasç­‰ã€‚</li>
<li>MobileBench-v2çš„ä»£ç å’Œæ•°æ®å¯åœ¨æŒ‡å®šç½‘ç«™è·å–ï¼Œä¾¿äºç ”ç©¶äººå‘˜ä½¿ç”¨å’Œæ”¹è¿›ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.11891">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-b90ed7fa4be4cfe03518719c8e2d6592.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-d5f08521a62c01b4680ea7e8aedab7a1.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a3505ea308f672033006888f548f4853.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ab5938b847661b60140dd45055f6a5de.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-2e362320e60a2715ac42d59bbda51a94.jpg" align="middle">
</details>


<h1 id="-11"><a href="#-11" class="headerlink" title=""></a></h1><h2 id="Single-Agent-vs-Multi-Agent-LLM-Strategies-for-Automated-Student-Reflection-Assessment"><a href="#Single-Agent-vs-Multi-Agent-LLM-Strategies-for-Automated-Student-Reflection-Assessment" class="headerlink" title="Single-Agent vs. Multi-Agent LLM Strategies for Automated Student   Reflection Assessment"></a>Single-Agent vs. Multi-Agent LLM Strategies for Automated Student   Reflection Assessment</h2><p><strong>Authors:Gen Li, Li Chen, Cheng Tang, Valdemar Å vÃ¡benskÃ½, Daisuke Deguchi, Takayoshi Yamashita, Atsushi Shimada</strong></p>
<p>We explore the use of Large Language Models (LLMs) for automated assessment of open-text student reflections and prediction of academic performance. Traditional methods for evaluating reflections are time-consuming and may not scale effectively in educational settings. In this work, we employ LLMs to transform student reflections into quantitative scores using two assessment strategies (single-agent and multi-agent) and two prompting techniques (zero-shot and few-shot). Our experiments, conducted on a dataset of 5,278 reflections from 377 students over three academic terms, demonstrate that the single-agent with few-shot strategy achieves the highest match rate with human evaluations. Furthermore, models utilizing LLM-assessed reflection scores outperform baselines in both at-risk student identification and grade prediction tasks. These findings suggest that LLMs can effectively automate reflection assessment, reduce educatorsâ€™ workload, and enable timely support for students who may need additional assistance. Our work emphasizes the potential of integrating advanced generative AI technologies into educational practices to enhance student engagement and academic success. </p>
<blockquote>
<p>æˆ‘ä»¬æ¢ç´¢äº†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨è‡ªåŠ¨è¯„ä¼°å­¦ç”Ÿå¼€æ”¾æ€§åæ€å’Œé¢„æµ‹å­¦ä¸šè¡¨ç°æ–¹é¢çš„åº”ç”¨ã€‚ä¼ ç»Ÿçš„åæ€è¯„ä¼°æ–¹æ³•è€—æ—¶ä¸”å¯èƒ½æ— æ³•åœ¨æ•™è‚²ç¯å¢ƒä¸­æœ‰æ•ˆåœ°æ‰©å±•ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬é‡‡ç”¨LLMï¼Œä½¿ç”¨ä¸¤ç§è¯„ä¼°ç­–ç•¥ï¼ˆå•æ™ºèƒ½ä½“å’Œå¤šæ™ºèƒ½ä½“ï¼‰å’Œä¸¤ç§æç¤ºæŠ€æœ¯ï¼ˆé›¶æ ·æœ¬å’Œå°‘é‡æ ·æœ¬ï¼‰ï¼Œå°†å­¦ç”Ÿåæ€è½¬åŒ–ä¸ºé‡åŒ–åˆ†æ•°ã€‚æˆ‘ä»¬åœ¨åŒ…å«æ¥è‡ª377åå­¦ç”Ÿåœ¨ä¸‰ä¸ªå­¦æœ¯å­¦æœŸå†…çš„5,278ç¯‡åæ€çš„æ•°æ®é›†ä¸Šè¿›è¡Œçš„å®éªŒè¡¨æ˜ï¼Œé‡‡ç”¨å°‘é‡æ ·æœ¬çš„å•æ™ºèƒ½ä½“ç­–ç•¥ä¸äººç±»è¯„ä¼°çš„åŒ¹é…ç‡æœ€é«˜ã€‚æ­¤å¤–ï¼Œä½¿ç”¨LLMè¯„ä¼°çš„åæ€åˆ†æ•°çš„æ¨¡å‹åœ¨å¤„äºé£é™©çš„å­¦ç”Ÿè¯†åˆ«å’Œæˆç»©é¢„æµ‹ä»»åŠ¡ä¸­çš„è¡¨ç°éƒ½ä¼˜äºåŸºçº¿ã€‚è¿™äº›ç»“æœè¡¨æ˜ï¼ŒLLMå¯ä»¥æœ‰æ•ˆåœ°è‡ªåŠ¨è¿›è¡Œåæ€è¯„ä¼°ï¼Œå‡å°‘æ•™è‚²å·¥ä½œè€…çš„å·¥ä½œé‡ï¼Œå¹¶ä¸ºå¯èƒ½éœ€è¦é¢å¤–å¸®åŠ©çš„å­¦ç”Ÿæä¾›åŠæ—¶çš„æ”¯æŒã€‚æˆ‘ä»¬çš„å·¥ä½œå¼ºè°ƒäº†å°†å…ˆè¿›çš„ç”Ÿæˆå¼äººå·¥æ™ºèƒ½æŠ€æœ¯ä¸æ•™è‚²å®è·µç›¸ç»“åˆï¼Œä»¥æé«˜å­¦ç”Ÿå‚ä¸åº¦å’Œå­¦ä¸šæˆåŠŸçš„æ½œåŠ›ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.05716v2">PDF</a> Published in Proceedings of the 29th Pacific-Asia Conference on   Knowledge Discovery and Data Mining (PAKDD 2025)</p>
<p><strong>Summary</strong></p>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨è‡ªåŠ¨è¯„ä¼°å­¦ç”Ÿå¼€æ”¾æ–‡æœ¬åæ€å’Œé¢„æµ‹å­¦ä¸šè¡¨ç°æ–¹é¢çš„åº”ç”¨ã€‚ä¼ ç»Ÿè¯„ä¼°æ–¹æ³•è€—æ—¶ä¸”éš¾ä»¥åœ¨æ•™è‚²ç¯å¢ƒä¸­æœ‰æ•ˆæ‰©å±•ã€‚æœ¬ç ”ç©¶ä½¿ç”¨LLMså°†å­¦ç”Ÿçš„åæ€è½¬åŒ–ä¸ºé‡åŒ–åˆ†æ•°ï¼Œé‡‡ç”¨ä¸¤ç§è¯„ä¼°ç­–ç•¥å’Œä¸¤ç§æç¤ºæŠ€æœ¯ã€‚å®éªŒè¡¨æ˜ï¼Œä½¿ç”¨å°‘æ•°æ ·æœ¬çš„å•æ™ºèƒ½ä½“ç­–ç•¥ä¸äººå·¥è¯„ä»·çš„åŒ¹é…ç‡æœ€é«˜ã€‚æ­¤å¤–ï¼Œä½¿ç”¨LLMè¯„ä¼°çš„åæ€åˆ†æ•°æ¨¡å‹åœ¨é«˜é£é™©å­¦ç”Ÿè¯†åˆ«å’Œæˆç»©é¢„æµ‹ä»»åŠ¡ä¸­çš„è¡¨ç°ä¼˜äºåŸºçº¿æ¨¡å‹ã€‚è¿™æ˜¾ç¤ºLLMså¯æœ‰æ•ˆåœ°è‡ªåŠ¨è¿›è¡Œåæ€è¯„ä¼°ï¼Œå‡è½»æ•™è‚²è€…çš„å·¥ä½œé‡ï¼Œå¹¶åŠæ—¶ä¸ºå¯èƒ½éœ€è¦é¢å¤–å¸®åŠ©çš„å­¦ç”Ÿæä¾›æ”¯æŒã€‚æœ¬ç ”ç©¶å¼ºè°ƒäº†å°†é«˜çº§ç”Ÿæˆå¼AIæŠ€æœ¯èå…¥æ•™è‚²å®è·µä»¥æé«˜å­¦ç”Ÿå‚ä¸åº¦å’Œå­¦ä¸šæˆåŠŸçš„æ½œåŠ›ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰è¢«ç”¨äºè‡ªåŠ¨è¯„ä¼°å­¦ç”Ÿçš„å¼€æ”¾æ–‡æœ¬åæ€ã€‚</li>
<li>ä¼ ç»Ÿè¯„ä¼°æ–¹æ³•åœ¨æ•™è‚²ç¯å¢ƒä¸­å­˜åœ¨è€—æ—¶ä¸”éš¾ä»¥æœ‰æ•ˆæ‰©å±•çš„é—®é¢˜ã€‚</li>
<li>é‡‡ç”¨ä¸¤ç§è¯„ä¼°ç­–ç•¥å’Œä¸¤ç§æç¤ºæŠ€æœ¯è¿›è¡Œå¤„ç†ï¼Œå³å•æ™ºèƒ½ä½“å’Œå¤šæ™ºèƒ½ä½“ç­–ç•¥ï¼Œä»¥åŠé›¶æ ·æœ¬å’Œå°‘æ•°æ ·æœ¬æç¤ºæŠ€æœ¯ã€‚</li>
<li>å®éªŒç»“æœæ˜¾ç¤ºï¼Œä½¿ç”¨å°‘æ•°æ ·æœ¬çš„å•æ™ºèƒ½ä½“ç­–ç•¥ä¸äººå·¥è¯„ä»·çš„åŒ¹é…ç‡æœ€é«˜ã€‚</li>
<li>LLMsåœ¨åæ€è¯„ä¼°ä¸­çš„è¡¨ç°ä¼˜äºåŸºçº¿æ¨¡å‹ï¼Œå°¤å…¶æ˜¯åœ¨é«˜é£é™©å­¦ç”Ÿè¯†åˆ«å’Œæˆç»©é¢„æµ‹ä»»åŠ¡ä¸­ã€‚</li>
<li>LLMsçš„è‡ªåŠ¨è¯„ä¼°å¯ä»¥æœ‰æ•ˆå‡è½»æ•™è‚²è€…çš„å·¥ä½œé‡ï¼Œå¹¶ä¸ºéœ€è¦é¢å¤–å¸®åŠ©çš„å­¦ç”Ÿæä¾›åŠæ—¶çš„åé¦ˆä¸æ”¯æŒã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.05716">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-741679233d151bf4b93641dce6c81b5b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-9f36f8bc2ee799fda8b05d31568d376e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a1e58fb5bda2006bfef3be73859d505f.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-0ff0799879c85a715d451fa0ee35b3a8.jpg" align="middle">
</details>


<h1 id="-12"><a href="#-12" class="headerlink" title=""></a></h1><h2 id="Semantic-Aware-Resource-Management-for-C-V2X-Platooning-via-Multi-Agent-Reinforcement-Learning"><a href="#Semantic-Aware-Resource-Management-for-C-V2X-Platooning-via-Multi-Agent-Reinforcement-Learning" class="headerlink" title="Semantic-Aware Resource Management for C-V2X Platooning via Multi-Agent   Reinforcement Learning"></a>Semantic-Aware Resource Management for C-V2X Platooning via Multi-Agent   Reinforcement Learning</h2><p><strong>Authors:Wenjun Zhang, Qiong Wu, Pingyi Fan, Kezhi Wang, Nan Cheng, Wen Chen, Khaled B. Letaief</strong></p>
<p>Semantic communication transmits the extracted features of information rather than raw data, significantly reducing redundancy, which is crucial for addressing spectrum and energy challenges in 6G networks. In this paper, we introduce semantic communication into a cellular vehicle-to-everything (C-V2X)- based autonomous vehicle platoon system for the first time, aiming to achieve efficient management of communication resources in a dynamic environment. Firstly, we construct a mathematical model for semantic communication in platoon systems, in which the DeepSC model and MU-DeepSC model are used to semantically encode and decode unimodal and multi-modal data, respectively. Then, we propose the quality of experience (QoE) metric based on semantic similarity and semantic rate. Meanwhile, we consider the success rate of semantic information transmission (SRS) metric to ensure the fairness of channel resource allocation. Next, the optimization problem is posed with the aim of maximizing the QoE in vehicle-to-vehicle (V2V) links while improving SRS. To solve this mixed integer nonlinear programming problem (MINLP) and adapt to time-varying channel conditions, the paper proposes a distributed semantic-aware multi-modal resource allocation (SAMRA) algorithm based on multi-agent reinforcement learning (MARL), referred to as SAMRAMARL. The algorithm can dynamically allocate channels and power and determine semantic symbol length based on the contextual importance of the transmitted information, ensuring efficient resource utilization. Finally, extensive simulations have demonstrated that SAMRAMARL outperforms existing methods, achieving significant gains in QoE, SRS, and communication delay in C-V2X platooning scenarios. </p>
<blockquote>
<p>è¯­ä¹‰é€šä¿¡ä¼ è¾“çš„æ˜¯ä¿¡æ¯çš„ç‰¹å¾æå–è€ŒéåŸå§‹æ•°æ®ï¼Œè¿™å¤§å¤§é™ä½äº†å†—ä½™æ€§ï¼Œå¯¹äºåº”å¯¹6Gç½‘ç»œä¸­çš„é¢‘è°±å’Œèƒ½æºæŒ‘æˆ˜è‡³å…³é‡è¦ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬é¦–æ¬¡å°†è¯­ä¹‰é€šä¿¡å¼•å…¥åŸºäºèœ‚çªçŠ¶è½¦è¾†å¯¹ä¸€åˆ‡ï¼ˆC-V2Xï¼‰çš„è‡ªåŠ¨é©¾é©¶è½¦é˜Ÿç³»ç»Ÿï¼Œæ—¨åœ¨å®ç°åŠ¨æ€ç¯å¢ƒä¸­é€šä¿¡èµ„æºçš„é«˜æ•ˆç®¡ç†ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬æ„å»ºäº†è½¦é˜Ÿç³»ç»Ÿä¸­è¯­ä¹‰é€šä¿¡çš„æ•°å­¦æ¨¡å‹ï¼Œå…¶ä¸­DeepSCæ¨¡å‹å’ŒMU-DeepSCæ¨¡å‹åˆ†åˆ«ç”¨äºå•æ¨¡æ€å’Œå¤šæ¨¡æ€æ•°æ®çš„è¯­ä¹‰ç¼–ç å’Œè§£ç ã€‚å…¶æ¬¡ï¼Œæˆ‘ä»¬æå‡ºäº†åŸºäºè¯­ä¹‰ç›¸ä¼¼æ€§å’Œè¯­ä¹‰é€Ÿç‡çš„ç”¨æˆ·ä½“éªŒï¼ˆQoEï¼‰æŒ‡æ ‡ã€‚åŒæ—¶ï¼Œæˆ‘ä»¬è€ƒè™‘è¯­ä¹‰ä¿¡æ¯ä¼ è¾“æˆåŠŸç‡ï¼ˆSRSï¼‰æŒ‡æ ‡ï¼Œä»¥ç¡®ä¿ä¿¡é“èµ„æºåˆ†é…çš„å…¬å¹³æ€§ã€‚æ¥ä¸‹æ¥ï¼Œä»¥è§£å†³æ··åˆæ•´æ•°éçº¿æ€§è§„åˆ’ï¼ˆMINLPï¼‰é—®é¢˜å¹¶é€‚åº”æ—¶å˜ä¿¡é“æ¡ä»¶ä¸ºç›®æ ‡ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºå¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ ï¼ˆMARLï¼‰çš„åˆ†å¸ƒå¼è¯­ä¹‰æ„ŸçŸ¥å¤šæ¨¡æ€èµ„æºåˆ†é…ï¼ˆSAMRAï¼‰ç®—æ³•ï¼Œå³SAMRAMARLç®—æ³•ã€‚è¯¥ç®—æ³•å¯æ ¹æ®ä¼ è¾“ä¿¡æ¯ä¸Šä¸‹æ–‡çš„é‡è¦æ€§åŠ¨æ€åˆ†é…ä¿¡é“å’ŒåŠŸç‡ï¼Œå¹¶ç¡®å®šè¯­ä¹‰ç¬¦å·é•¿åº¦ï¼Œç¡®ä¿èµ„æºçš„é«˜æ•ˆåˆ©ç”¨ã€‚æœ€åï¼Œå¤§é‡çš„æ¨¡æ‹Ÿç»“æœè¡¨æ˜ï¼ŒSAMRAMARLç®—æ³•åœ¨QoEã€SRSå’ŒC-V2Xè½¦é˜Ÿåœºæ™¯ä¸­çš„é€šä¿¡å»¶è¿Ÿæ–¹é¢å‡ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œå–å¾—äº†æ˜¾è‘—çš„æ”¶ç›Šã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2411.04672v2">PDF</a> This paper has been submitted to IEEE Journal. The source code has   been released   at:<a target="_blank" rel="noopener" href="https://github.com/qiongwu86/Semantic-Aware-Resource-Management-for-C-V2X-Platooning-via-Multi-Agent-Reinforcement-Learning">https://github.com/qiongwu86/Semantic-Aware-Resource-Management-for-C-V2X-Platooning-via-Multi-Agent-Reinforcement-Learning</a></p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä¸»è¦ä»‹ç»äº†è¯­ä¹‰é€šä¿¡åœ¨è§£å†³6Gç½‘ç»œçš„é¢‘è°±å’Œèƒ½æºæŒ‘æˆ˜æ–¹é¢çš„ä¼˜åŠ¿ï¼Œå¹¶å°†å…¶é¦–æ¬¡å¼•å…¥åŸºäºèœ‚çªè½¦è”ç½‘ï¼ˆC-V2Xï¼‰çš„è‡ªåŠ¨é©¾é©¶è½¦é˜Ÿç³»ç»Ÿã€‚æ–‡ç« æ„å»ºäº†è¯­ä¹‰é€šä¿¡çš„æ•°å­¦æ¨¡å‹ï¼Œå¹¶æå‡ºäº†åŸºäºè¯­ä¹‰ç›¸ä¼¼æ€§å’Œè¯­ä¹‰é€Ÿç‡çš„ç”¨æˆ·ä½“éªŒï¼ˆQoEï¼‰æŒ‡æ ‡ã€‚åŒæ—¶ï¼Œä¸ºç¡®ä¿ä¿¡é“èµ„æºåˆ†é…çš„å…¬å¹³æ€§ï¼Œè€ƒè™‘äº†è¯­ä¹‰ä¿¡æ¯ä¼ è¾“æˆåŠŸç‡ï¼ˆSRSï¼‰æŒ‡æ ‡ã€‚æ–‡ç« æ—¨åœ¨è§£å†³ä¸€ä¸ªæ··åˆæ•´æ•°éçº¿æ€§è§„åˆ’ï¼ˆMINLPï¼‰é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åŸºäºå¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ ï¼ˆMARLï¼‰çš„åˆ†å¸ƒå¼è¯­ä¹‰æ„ŸçŸ¥å¤šæ¨¡æ€èµ„æºåˆ†é…ï¼ˆSAMRAï¼‰ç®—æ³•ï¼Œå¯æ ¹æ®ä¼ è¾“ä¿¡æ¯çš„é‡è¦æ€§åŠ¨æ€åˆ†é…ä¿¡é“å’ŒåŠŸç‡ï¼Œå¹¶ç¡®å®šè¯­ä¹‰ç¬¦å·é•¿åº¦ã€‚æ¨¡æ‹Ÿç»“æœè¡¨æ˜ï¼ŒSAMRAç®—æ³•åœ¨C-V2Xè½¦é˜Ÿåœºæ™¯ä¸­æé«˜äº†QoEã€SRSå¹¶é™ä½äº†é€šä¿¡å»¶è¿Ÿã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>è¯­ä¹‰é€šä¿¡èƒ½å‡å°‘å†—ä½™ä¿¡æ¯ï¼Œæœ‰åŠ©äºè§£å†³6Gç½‘ç»œçš„é¢‘è°±å’Œèƒ½æºæŒ‘æˆ˜ã€‚</li>
<li>æ–‡ç« é¦–æ¬¡å°†è¯­ä¹‰é€šä¿¡å¼•å…¥èœ‚çªè½¦è”ç½‘ï¼ˆC-V2Xï¼‰çš„è‡ªåŠ¨é©¾é©¶è½¦é˜Ÿç³»ç»Ÿï¼Œæ—¨åœ¨æé«˜é€šä¿¡èµ„æºçš„ç®¡ç†æ•ˆç‡ã€‚</li>
<li>æ„å»ºäº†è¯­ä¹‰é€šä¿¡çš„æ•°å­¦æ¨¡å‹ï¼Œå¹¶ä½¿ç”¨DeepSCæ¨¡å‹å’ŒMU-DeepSCæ¨¡å‹è¿›è¡Œå•æ¨¡æ€å’Œå¤šæ¨¡æ€æ•°æ®çš„è¯­ä¹‰ç¼–ç å’Œè§£ç ã€‚</li>
<li>æå‡ºäº†åŸºäºè¯­ä¹‰ç›¸ä¼¼æ€§å’Œè¯­ä¹‰é€Ÿç‡çš„ç”¨æˆ·ä½“éªŒï¼ˆQoEï¼‰æŒ‡æ ‡ä»¥åŠè¯­ä¹‰ä¿¡æ¯ä¼ è¾“æˆåŠŸç‡ï¼ˆSRSï¼‰æŒ‡æ ‡ã€‚</li>
<li>è§£å†³äº†ä¸€ä¸ªæ··åˆæ•´æ•°éçº¿æ€§è§„åˆ’ï¼ˆMINLPï¼‰é—®é¢˜ï¼Œæ—¨åœ¨æœ€å¤§åŒ–è½¦è¾†é—´ï¼ˆV2Vï¼‰é“¾æ¥çš„QoEå¹¶æ”¹å–„SRSã€‚</li>
<li>æå‡ºäº†ä¸€ç§åŸºäºå¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ ï¼ˆMARLï¼‰çš„åˆ†å¸ƒå¼è¯­ä¹‰æ„ŸçŸ¥å¤šæ¨¡æ€èµ„æºåˆ†é…ï¼ˆSAMRAï¼‰ç®—æ³•ï¼Œå¯æ ¹æ®ä¿¡æ¯çš„é‡è¦æ€§åŠ¨æ€åˆ†é…èµ„æºå’Œç¡®å®šè¯­ä¹‰ç¬¦å·é•¿åº¦ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2411.04672">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-3814ce008cbf72b92d7da928e05bc1ee.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ce0887019b7edd3528edc8a380caf5cf.jpg" align="middle">
</details>


<h1 id="-13"><a href="#-13" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-05-28/Agent/">https://kedreamix.github.io/Talk2Paper/Paper/2025-05-28/Agent/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/Agent/">
                                    <span class="chip bg-color">Agent</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-05-28/MMT/">
                    <div class="card-image">
                        
                        <img src="https://pica.zhimg.com/v2-686f51f5a4b71e473c7ac974fb376f57.jpg" class="responsive-img" alt="MMT">
                        
                        <span class="card-title">MMT</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            MMT æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-05-28  MT$^{3}$ Scaling MLLM-based Text Image Machine Translation via   Multi-Task Reinforcement Learning
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-05-28
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/MMT/" class="post-category">
                                    MMT
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/MMT/">
                        <span class="chip bg-color">MMT</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-05-28/LLM/">
                    <div class="card-image">
                        
                        <img src="https://pic1.zhimg.com/v2-ca768b8bb8003dfc3cec794ae8f9eb01.jpg" class="responsive-img" alt="LLM">
                        
                        <span class="card-title">LLM</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            LLM æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-05-28  KnowTrace Bootstrapping Iterative Retrieval-Augmented Generation with   Structured Knowledge Tracing
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-05-28
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/LLM/" class="post-category">
                                    LLM
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/LLM/">
                        <span class="chip bg-color">LLM</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">31086.8k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
