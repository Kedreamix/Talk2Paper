<!DOCTYPE HTML><html lang="zh-CN"><head><meta charset="utf-8"><meta name="keywords" content="Talking Head Generation"><meta name="description" content="Talking Head Generation 方向最新论文已更新，请持续关注 Update in 2024-05-06  CoVoMix Advancing Zero-Shot Speech Generation for Human-like   Multi-talker Conversations"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1,user-scalable=no"><meta name="renderer" content="webkit|ie-stand|ie-comp"><meta name="mobile-web-app-capable" content="yes"><meta name="format-detection" content="telephone=no"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="black-translucent"><meta name="referrer" content="no-referrer-when-downgrade"><title>Talking Head Generation | Talk2Paper</title><link rel="icon" type="image/png" href="/Talk2Paper/favicon.png"><style>body{background-image:url(/Talk2Paper/background.jpg);background-repeat:no-repeat;background-size:100% 100%;background-attachment:fixed}</style><link rel="stylesheet" href="/Talk2Paper/libs/awesome/css/all.min.css"><link rel="stylesheet" href="/Talk2Paper/libs/materialize/materialize.min.css"><link rel="stylesheet" href="/Talk2Paper/libs/aos/aos.css"><link rel="stylesheet" href="/Talk2Paper/libs/animate/animate.min.css"><link rel="stylesheet" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css"><link rel="stylesheet" href="/Talk2Paper/css/matery.css"><link rel="stylesheet" href="/Talk2Paper/css/my.css"><link rel="stylesheet" href="/Talk2Paper/css/dark.css" media="none" onload='"all"!=media&&(media="all")'><link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css"><link rel="stylesheet" href="/Talk2Paper/css/post.css"><script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script><meta name="generator" content="Hexo 7.3.0"></head><body><header class="navbar-fixed"><nav id="headNav" class="bg-color nav-transparent"><div id="navContainer" class="nav-wrapper container"><div class="brand-logo"><a href="/Talk2Paper/" class="waves-effect waves-light"><img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO"> <span class="logo-span">Talk2Paper</span></a></div><a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a><ul class="right nav-menu"><li class="hide-on-med-and-down nav-item"><a href="/Talk2Paper/" class="waves-effect waves-light"><i class="fas fa-home" style="zoom:0.6"></i> <span>首页</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/Talk2Paper/tags" class="waves-effect waves-light"><i class="fas fa-tags" style="zoom:0.6"></i> <span>标签</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/Talk2Paper/categories" class="waves-effect waves-light"><i class="fas fa-bookmark" style="zoom:0.6"></i> <span>分类</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/Talk2Paper/archives" class="waves-effect waves-light"><i class="fas fa-archive" style="zoom:0.6"></i> <span>归档</span></a></li><li><a href="#searchModal" class="modal-trigger waves-effect waves-light"><i id="searchIcon" class="fas fa-search" title="搜索" style="zoom:0.85"></i></a></li><li><a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="深色/浅色模式"><i id="sum-moon-icon" class="fas fa-sun" style="zoom:0.85"></i></a></li></ul><div id="mobile-nav" class="side-nav sidenav"><div class="mobile-head bg-color"><img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img"><div class="logo-name">Talk2Paper</div><div class="logo-desc">Never really desperate, only the lost of the soul.</div></div><ul class="menu-list mobile-menu-list"><li class="m-nav-item"><a href="/Talk2Paper/" class="waves-effect waves-light"><i class="fa-fw fas fa-home"></i> 首页</a></li><li class="m-nav-item"><a href="/Talk2Paper/tags" class="waves-effect waves-light"><i class="fa-fw fas fa-tags"></i> 标签</a></li><li class="m-nav-item"><a href="/Talk2Paper/categories" class="waves-effect waves-light"><i class="fa-fw fas fa-bookmark"></i> 分类</a></li><li class="m-nav-item"><a href="/Talk2Paper/archives" class="waves-effect waves-light"><i class="fa-fw fas fa-archive"></i> 归档</a></li><li><div class="divider"></div></li><li><a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank"><i class="fab fa-github-square fa-fw"></i> Fork Me</a></li></ul></div></div><style>.nav-transparent .github-corner{display:none!important}.github-corner{position:absolute;z-index:10;top:0;right:0;border:0;transform:scale(1.1)}.github-corner svg{color:#0f9d58;fill:#fff;height:64px;width:64px}.github-corner:hover .octo-arm{animation:a .56s ease-in-out}.github-corner .octo-arm{animation:none}@keyframes a{0%,to{transform:rotate(0)}20%,60%{transform:rotate(-25deg)}40%,80%{transform:rotate(10deg)}}</style><a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank" data-tooltip="Fork Me" data-position="left" data-delay="50"><svg viewBox="0 0 250 250" aria-hidden="true"><path d="M0 0 115 115 130 115 142 142 250 250 250 0Z"></path><path d="M128.3 109C113.8 99.7 119 89.6 119 89.6 122 82.7 120.5 78.6 120.5 78.6 119.2 72 123.4 76.3 123.4 76.3 127.3 80.9 125.5 87.3 125.5 87.3 122.9 97.6 130.6 101.9 134.4 103.2" fill="currentColor" style="transform-origin:130px 106px" class="octo-arm"></path><path d="M115 115C114.9 115.1 118.7 116.5 119.8 115.4L133.7 101.6C136.9 99.2 139.9 98.4 142.2 98.6 133.8 88 127.5 74.4 143.8 58 148.5 53.4 154 51.2 159.7 51 160.3 49.4 163.2 43.6 171.4 40.1 171.4 40.1 176.1 42.5 178.8 56.2 183.1 58.6 187.2 61.8 190.9 65.4 194.5 69 197.7 73.2 200.1 77.6 213.8 80.2 216.3 84.9 216.3 84.9 212.7 93.1 206.9 96 205.4 96.6 205.1 102.4 203 107.8 198.3 112.5 181.9 128.9 168.3 122.5 157.7 114.1 157.9 116.9 156.7 120.9 152.7 124.9L141 136.5C139.8 137.7 141.6 141.9 141.8 141.8Z" fill="currentColor" class="octo-body"></path></svg></a></nav></header><div class="bg-cover pd-header post-cover" style="background-image:url('https://picx.zhimg.com/v2-848d816930200060ec067527f2cd2e66.jpg')"><div class="container" style="right:0;left:0"><div class="row"><div class="col s12 m12 l12"><div class="brand"><h1 class="description center-align post-title">Talking Head Generation</h1></div></div></div></div></div><main class="post-container content"><div class="row"><div id="main-content" class="col s12 m12 l9"><div id="artDetail"><div class="card"><div class="card-content article-info"><div class="row tag-cate"><div class="col s7"><div class="article-tag"><a href="/Talk2Paper/tags/Talking-Head-Generation/"><span class="chip bg-color">Talking Head Generation</span></a></div></div><div class="col s5 right-align"><div class="post-cate"><i class="fas fa-bookmark fa-fw icon-category"></i> <a href="/Talk2Paper/categories/Talking-Head-Generation/" class="post-category">Talking Head Generation</a></div></div></div><div class="post-info"><div class="post-date info-break-policy"><i class="far fa-calendar-minus fa-fw"></i> 发布日期:&nbsp;&nbsp; 2024-05-06</div><div class="post-date info-break-policy"><i class="far fa-calendar-check fa-fw"></i> 更新日期:&nbsp;&nbsp; 2024-12-10</div><div class="info-break-policy"><i class="far fa-file-word fa-fw"></i> 文章字数:&nbsp;&nbsp; 2.7k</div><div class="info-break-policy"><i class="far fa-clock fa-fw"></i> 阅读时长:&nbsp;&nbsp; 10 分</div><div id="busuanzi_container_page_pv" class="info-break-policy"><i class="far fa-eye fa-fw"></i> 阅读次数:&nbsp;&nbsp;<span id="busuanzi_value_page_pv"></span></div></div></div><hr class="clearfix"><div class="card-content article-card-content"><div id="articleContent"><blockquote><p>⚠️ 以下所有内容总结都来自于 Google的大语言模型<a target="_blank" rel="noopener" href="https://ai.google.dev/">Gemini-Pro</a>的能力，如有错误，仅供参考，谨慎使用<br>🔴 请注意：千万不要用于严肃的学术场景，只能用于论文阅读前的初筛！<br>💗 如果您觉得我们的项目对您有帮助 <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ，还请您给我们一些鼓励！⭐️ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFace免费体验</a></p></blockquote><h1 id="2024-05-06-更新"><a href="#2024-05-06-更新" class="headerlink" title="2024-05-06 更新"></a>2024-05-06 更新</h1><h2 id="CoVoMix-Advancing-Zero-Shot-Speech-Generation-for-Human-like-Multi-talker-Conversations"><a href="#CoVoMix-Advancing-Zero-Shot-Speech-Generation-for-Human-like-Multi-talker-Conversations" class="headerlink" title="CoVoMix: Advancing Zero-Shot Speech Generation for Human-like   Multi-talker Conversations"></a>CoVoMix: Advancing Zero-Shot Speech Generation for Human-like Multi-talker Conversations</h2><p><strong>Authors:Leying Zhang, Yao Qian, Long Zhou, Shujie Liu, Dongmei Wang, Xiaofei Wang, Midia Yousefi, Yanmin Qian, Jinyu Li, Lei He, Sheng Zhao, Michael Zeng</strong></p><p>Recent advancements in zero-shot text-to-speech (TTS) modeling have led to significant strides in generating high-fidelity and diverse speech. However, dialogue generation, along with achieving human-like naturalness in speech, continues to be a challenge in the field. In this paper, we introduce CoVoMix: Conversational Voice Mixture Generation, a novel model for zero-shot, human-like, multi-speaker, multi-round dialogue speech generation. CoVoMix is capable of first converting dialogue text into multiple streams of discrete tokens, with each token stream representing semantic information for individual talkers. These token streams are then fed into a flow-matching based acoustic model to generate mixed mel-spectrograms. Finally, the speech waveforms are produced using a HiFi-GAN model. Furthermore, we devise a comprehensive set of metrics for measuring the effectiveness of dialogue modeling and generation. Our experimental results show that CoVoMix can generate dialogues that are not only human-like in their naturalness and coherence but also involve multiple talkers engaging in multiple rounds of conversation. These dialogues, generated within a single channel, are characterized by seamless speech transitions, including overlapping speech, and appropriate paralinguistic behaviors such as laughter. Audio samples are available at <a target="_blank" rel="noopener" href="https://aka.ms/covomix">https://aka.ms/covomix</a>.</p><p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2404.06690v1">PDF</a></p><p><strong>Summary</strong><br>利用CoVoMix，一种零样本对话语音合成模型，可以生成逼真、连贯且多回合的多人对话语音。</p><p><strong>Key Takeaways</strong></p><ul><li>CoVoMix是一款零样本对话语音合成模型。</li><li>CoVoMix能够将对话文本转换为离散标记流，表示各个说话者的语义信息。</li><li>流匹配声学模型将标记流转换成混合的梅尔频谱图。</li><li>HiFi-GAN模型将梅尔频谱图转换为语音波形。</li><li>CoVoMix采用了一套综合的指标来衡量对话建模和生成的有效性。</li><li>实验结果表明，CoVoMix生成的对话具有逼真的自然性和连贯性，并且涉及多个说话者参与多轮对话。</li><li>生成的对话在单个通道内，具有无缝的语音转换（包括重叠语音）和适当的副语言行为（例如笑声）。</li></ul><p><strong><a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p><ol><li><p>Title: CoVoMix: 推进零样本语音生成以实现类人多说话者对话</p></li><li><p>Authors: Leying Zhang, Yao Qian, Long Zhou, Shujie Liu, Dongmei Wang, Xiaofei Wang, Midia Yousefi, Yanmin Qian, Jinyu Li, Lei He, Sheng Zhao, Michael Zeng</p></li><li><p>Affiliation: 上海交通大学</p></li><li><p>Keywords: 零样本语音生成，多说话者对话，语音合成，自然语言处理</p></li><li><p>Urls: Paper: https://arxiv.org/abs/2404.06690 , Github: None</p></li><li><p>Summary:</p></li></ol><p>(1): 研究背景：近年来，零样本文本到语音 (TTS) 建模取得了重大进展，在生成高保真和多样化的语音方面取得了显著进展。然而，对话生成以及在语音中实现类人的自然性仍然是该领域的挑战。</p><p>(2): 过去的方法：过去的方法通常使用单流文本到语音模型，无法生成多说话者对话。此外，这些方法通常需要大量标记数据，这在对话场景中可能不可用。</p><p>(3): 本文提出的研究方法：本文提出了一种名为 CoVoMix 的模型，用于零样本、类人、多说话者、多轮对话语音生成。CoVoMix 能够首先将对话文本转换为多个离散令牌流，每个令牌流表示单个说话者的语义信息。然后将这些令牌流馈送到基于流匹配的声学模型中以生成混合梅尔谱图。最后，使用 HiFi-GAN 模型生成语音波形。</p><p>(4): 实验结果：实验结果表明，CoVoMix 可以生成不仅在自然性和连贯性上类似人类的对话，而且还涉及多个说话者进行多轮对话。这些在单个通道内生成的对话具有无缝的语音转换，包括重叠语音和适当的副语言行为，例如笑声。</p><ol><li>研究方法：</li></ol><p>（1）：多流文本到语义模型：基于编码器-解码器架构，将文本标记序列转换为多个离散标记流，每个标记流表示单个说话者的语义信息。</p><p>（2）：声学模型：基于流匹配的变压器编码器，将语义序列转换为混合梅尔谱图。</p><p>（3）：声码器：使用 HiFi-GAN 模型从梅尔谱图生成语音波形。</p><ol><li>结论：</li></ol><p>（1）：本文提出的 CoVoMix 模型在零样本、类人、多说话者、多轮对话语音生成方面取得了显著进展，为该领域的研究提供了新的思路和方法。</p><p>（2）：创新点：提出了一种基于流匹配的多流文本到语义模型，能够将对话文本转换为多个离散令牌流，表示单个说话者的语义信息；设计了一种基于流匹配的声学模型，将语义序列转换为混合梅尔谱图；采用 HiFi-GAN 模型生成语音波形，实现了高保真语音合成。</p><p>性能：实验结果表明，CoVoMix 生成的对话在自然性和连贯性上类似人类，涉及多个说话者进行多轮对话，具有无缝的语音转换和适当的副语言行为。</p><p>工作量：CoVoMix 模型的训练和部署需要大量的数据和计算资源，这可能会限制其在实际应用中的可行性。</p><details><summary>点此查看论文截图</summary><img src="https://picx.zhimg.com/v2-271fa2d3d54bc8eac1b4ebb4afb68b5f.jpg" align="middle"></details><h2 id="Beyond-Talking-–-Generating-Holistic-3D-Human-Dyadic-Motion-for-Communication"><a href="#Beyond-Talking-–-Generating-Holistic-3D-Human-Dyadic-Motion-for-Communication" class="headerlink" title="Beyond Talking – Generating Holistic 3D Human Dyadic Motion for   Communication"></a>Beyond Talking – Generating Holistic 3D Human Dyadic Motion for Communication</h2><p><strong>Authors:Mingze Sun, Chao Xu, Xinyu Jiang, Yang Liu, Baigui Sun, Ruqi Huang</strong></p><p>In this paper, we introduce an innovative task focused on human communication, aiming to generate 3D holistic human motions for both speakers and listeners. Central to our approach is the incorporation of factorization to decouple audio features and the combination of textual semantic information, thereby facilitating the creation of more realistic and coordinated movements. We separately train VQ-VAEs with respect to the holistic motions of both speaker and listener. We consider the real-time mutual influence between the speaker and the listener and propose a novel chain-like transformer-based auto-regressive model specifically designed to characterize real-world communication scenarios effectively which can generate the motions of both the speaker and the listener simultaneously. These designs ensure that the results we generate are both coordinated and diverse. Our approach demonstrates state-of-the-art performance on two benchmark datasets. Furthermore, we introduce the HoCo holistic communication dataset, which is a valuable resource for future research. Our HoCo dataset and code will be released for research purposes upon acceptance.</p><p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2403.19467v1">PDF</a></p><p><strong>Summary</strong><br>通过音频特征和文本语义相结合的方式，实现说话人和倾听者3D逼真且协调的动作生成。</p><p><strong>Key Takeaways</strong></p><ul><li>提出音频特征与文本语义信息解耦合的创新任务，生成说话人和倾听者的3D动作。</li><li>分别训练说话人和倾听者的整体动作VQ-VAE。</li><li>考虑说话人和倾听者之间的实时相互影响，提出自回归模型，同时生成说话人和倾听者的动作。</li><li>链式Transformer模型，有效表征现实世界的沟通场景。</li><li>该方法在两个基准数据集上表现出最先进的性能。</li><li>引入HoCo整体沟通数据集，为未来研究提供宝贵资源。</li><li>接受后将HoCo数据集和代码发布用于研究目的。</li></ul><p><strong><a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p><ol><li><p>标题：超越说话——生成用于交流的整体 3D 人类双人运动</p></li><li><p>作者：Mingze Sun · Chao Xu · Xinyu Jiang · Yang Liu · Baigui Sun · Ruqi Huang</p></li><li><p>单位：清华大学深圳国际研究生院</p></li><li><p>关键词：Dyadic Motion, Holistic Human Mesh, Communication</p></li><li><p>论文链接：None, Github：None</p></li><li><p>摘要：</p></li></ol><p>（1）：研究背景： 近年来，基于大规模人类说话视频的语音生成运动任务取得了显著进展，即从言语线索（如音频片段或转录）中生成谈话中的非语言信号（如面部表情或身体动作），例如人类面部表情、身体姿势和手势。然而，这些方法仅关注说话者，而忽略了听众的反应。</p><p>（2）：过去方法及其问题： 以往方法主要集中在生成说话者的头部、手势或全身运动，而忽略了听众的反应。此外，这些方法通常需要大量标记数据，这限制了它们的实用性。</p><p>（3）：本文提出的研究方法： 本文提出了一种新的任务，专注于人类交流，旨在为说话者和听众生成 3D 整体人类动作。该方法的核心是将分解因子化与文本语义信息的结合，从而促进创建更逼真和协调的动作。我们分别针对说话者和听众的整体动作训练 VQ-VAE。我们考虑了说话者和听众之间的实时相互影响，并提出了一种新颖的链式基于 Transformer 的自回归模型，该模型专门设计用于有效表征现实世界中的交流场景，可以同时生成说话者和听众的动作。这些设计确保了我们生成的结果既协调又多样。</p><p>（4）：方法的性能： 我们的方法在两个基准数据集上展示了最先进的性能。此外，我们引入了 HoCo 整体交流数据集，这是一个对未来研究有价值的资源。我们的 HoCo 数据集和代码将在被接受后发布以供研究使用。</p><ol><li>方法：</li></ol><p>（1）：针对说话者和听众的整体动作，分别训练 VQ-VAE；</p><p>（2）：提出了一种基于 Transformer 的自回归模型，用于有效表征现实世界中的交流场景，可以同时生成说话者和听众的动作；</p><p>（3）：利用分解因子化与文本语义信息的结合，促进创建更逼真和协调的动作；</p><p>（4）：在两个基准数据集上展示了最先进的性能；</p><p>（5）：引入了 HoCo 整体交流数据集，为未来研究提供了宝贵的资源。</p><ol><li>结论：</li></ol><p>（1）：本工作将交流纳入人机交互中，提出了一项新颖的任务，为说话者和听众生成 3D 整体人类动作。为此，我们在数据集和模型设计上均做出了贡献。前者方面，我们提供了 HoCo 通信数据集，以供未来沿着此任务进行探索。后者方面，我们提出了一个针对我们任务量身定制的模型，该模型包含新颖的设计，包括 1）用于解耦音频特征的分解，增强了生成更真实和协调的动作；2）用于表征非语言交流的链式自回归模型。此外，我们在两个基准上取得了最先进的性能。</p><p>（2）：创新点：提出了一种新的任务，专注于生成说话者和听众的 3D 整体人类动作，并设计了一个针对该任务量身定制的模型。 性能：在两个基准数据集上展示了最先进的性能。 工作量：引入了 HoCo 整体交流数据集，为未来研究提供了宝贵的资源。</p><details><summary>点此查看论文截图</summary><img src="https://pic1.zhimg.com/v2-8dd55a7f4757f4ae1f9d71880b4c6479.jpg" align="middle"> <img src="https://picx.zhimg.com/v2-848d816930200060ec067527f2cd2e66.jpg" align="middle"> <img src="https://picx.zhimg.com/v2-90bdfdaba5b0a3b62088d04ae352d6de.jpg" align="middle"> <img src="https://picx.zhimg.com/v2-95a401074128a34e072805c4fda00e11.jpg" align="middle"></details></div><hr><div class="reprint" id="reprint-statement"><div class="reprint__author"><span class="reprint-meta" style="font-weight:700"><i class="fas fa-user">文章作者:</i></span> <span class="reprint-info"><a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a></span></div><div class="reprint__type"><span class="reprint-meta" style="font-weight:700"><i class="fas fa-link">文章链接:</i></span> <span class="reprint-info"><a href="https://kedreamix.github.io/Talk2Paper/Paper/2024-05-06/Talking%20Head%20Generation/">https://kedreamix.github.io/Talk2Paper/Paper/2024-05-06/Talking%20Head%20Generation/</a></span></div><div class="reprint__notice"><span class="reprint-meta" style="font-weight:700"><i class="fas fa-copyright">版权声明:</i></span> <span class="reprint-info">本博客所有文章除特別声明外，均采用 <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a> 许可协议。转载请注明来源 <a href="/Talk2Paper/about" target="_blank">Kedreamix</a> !</span></div></div><script async defer>function navToReprintStatement(){$("html, body").animate({scrollTop:$("#reprint-statement").offset().top-80},800)}document.addEventListener("copy",(function(t){M.toast({html:'<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>'})}))</script><div class="tag_share" style="display:block"><div class="post-meta__tag-list" style="display:inline-block"><div class="article-tag"><a href="/Talk2Paper/tags/Talking-Head-Generation/"><span class="chip bg-color">Talking Head Generation</span></a></div></div><div class="post_share" style="zoom:80%;width:fit-content;display:inline-block;float:right;margin:-.15rem 0"><link rel="stylesheet" href="/Talk2Paper/libs/share/css/share.min.css"><div id="article-share"><div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div><script src="/Talk2Paper/libs/share/js/social-share.min.js"></script></div></div></div></div></div><article id="prenext-posts" class="prev-next articles"><div class="row article-row"><div class="article col s12 m6" data-aos="fade-up"><div class="article-badge left-badge text-color"><i class="fas fa-chevron-left"></i> &nbsp;上一篇</div><div class="card"><a href="/Talk2Paper/Paper/2024-05-06/3DGS/"><div class="card-image"><img src="/Talk2Paper/None" class="responsive-img" alt="3DGS"> <span class="card-title">3DGS</span></div></a><div class="card-content article-content"><div class="summary block-with-text">3DGS 方向最新论文已更新，请持续关注 Update in 2024-05-06</div><div class="publish-info"><span class="publish-date"><i class="far fa-clock fa-fw icon-date"></i> 2024-05-06</span><span class="publish-author"><i class="fas fa-bookmark fa-fw icon-category"></i> <a href="/Talk2Paper/categories/3DGS/" class="post-category">3DGS</a></span></div></div><div class="card-action article-tags"><a href="/Talk2Paper/tags/3DGS/"><span class="chip bg-color">3DGS</span></a></div></div></div><div class="article col s12 m6" data-aos="fade-up"><div class="article-badge right-badge text-color">下一篇&nbsp;<i class="fas fa-chevron-right"></i></div><div class="card"><a href="/Talk2Paper/Paper/2024-05-06/Diffusion%20Models/"><div class="card-image"><img src="https://pic1.zhimg.com/v2-d3231e3375af2b14c1e49248519eaebd.jpg" class="responsive-img" alt="Diffusion Models"> <span class="card-title">Diffusion Models</span></div></a><div class="card-content article-content"><div class="summary block-with-text">Diffusion Models 方向最新论文已更新，请持续关注 Update in 2024-05-06 Defect Image Sample Generation With Diffusion Prior for Steel Surface Defect Recognition</div><div class="publish-info"><span class="publish-date"><i class="far fa-clock fa-fw icon-date"></i> 2024-05-06</span><span class="publish-author"><i class="fas fa-bookmark fa-fw icon-category"></i> <a href="/Talk2Paper/categories/Diffusion-Models/" class="post-category">Diffusion Models</a></span></div></div><div class="card-action article-tags"><a href="/Talk2Paper/tags/Diffusion-Models/"><span class="chip bg-color">Diffusion Models</span></a></div></div></div></div></article></div><script src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script><script src="/Talk2Paper/libs/codeBlock/codeLang.js"></script><script src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script><script src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script></div><div id="toc-aside" class="expanded col l3 hide-on-med-and-down"><div class="toc-widget card" style="background-color:#fff"><div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div><div id="toc-content"></div></div></div></div><div id="floating-toc-btn" class="hide-on-med-and-down"><a class="btn-floating btn-large bg-color"><i class="fas fa-list-ul"></i></a></div><script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script><script>$((function(){tocbot.init({tocSelector:"#toc-content",contentSelector:"#articleContent",headingsOffset:-(.4*$(window).height()-45),collapseDepth:Number("0"),headingSelector:"h2, h3, h4"});let t=parseInt(.4*$(window).height()-64),e=$(".toc-widget");$(window).scroll((function(){$(window).scrollTop()>t?e.addClass("toc-fixed"):e.removeClass("toc-fixed")}));const o="expanded";let n=$("#toc-aside"),i=$("#main-content");$("#floating-toc-btn .btn-floating").click((function(){n.hasClass(o)?(n.removeClass(o).hide(),i.removeClass("l9")):(n.addClass(o).show(),i.addClass("l9")),function(t,e){let o=$("#"+t);if(0===o.length)return;let n=o.width();n+=n>=450?21:n>=350&&n<450?18:n>=300&&n<350?16:14,$("#"+e).width(n)}("artDetail","prenext-posts")}))}))</script></main><footer class="page-footer bg-color"><link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css"><style>.aplayer .aplayer-lrc p{display:none;font-size:12px;font-weight:700;line-height:16px!important}.aplayer .aplayer-lrc p.aplayer-lrc-current{display:none;font-size:15px;color:#42b983}.aplayer.aplayer-fixed.aplayer-narrow .aplayer-body{left:-66px!important}.aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover{left:0!important}</style><div><div class="row"><meting-js class="col l8 offset-l2 m10 offset-m1 s12" server="netease" type="playlist" id="503838841" fixed="true" autoplay theme="#42b983" loop order="random" preload="auto" volume="0.7" list-folded="true"></meting-js></div></div><script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script><script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script><div class="container row center-align" style="margin-bottom:15px!important"><div class="col s12 m8 l8 copy-right">Copyright&nbsp;&copy; <span id="year">2024</span> <a href="/Talk2Paper/about" target="_blank">Kedreamix</a> |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a> |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a><br>&nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span class="white-color">4610.5k</span> <span id="busuanzi_container_site_pv">&nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;<span id="busuanzi_value_site_pv" class="white-color"></span></span> <span id="busuanzi_container_site_uv">&nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;<span id="busuanzi_value_site_uv" class="white-color"></span></span><br><span id="sitetime">Loading ...</span><script>var calcSiteTime=function(){var e=864e5,t=new Date,n="2024",i=t.getFullYear(),a=t.getMonth()+1,r=t.getDate(),s=t.getHours(),o=t.getMinutes(),g=t.getSeconds(),d=Date.UTC(n,"1","1","0","0","0"),m=Date.UTC(i,a,r,s,o,g)-d,l=Math.floor(m/31536e6),c=Math.floor(m/e-365*l);if(n===String(i)){document.getElementById("year").innerHTML=i;var u="This site has been running for "+c+" days";u="本站已运行 "+c+" 天",document.getElementById("sitetime").innerHTML=u}else{document.getElementById("year").innerHTML=n+" - "+i;var T="This site has been running for "+l+" years and "+c+" days";T="本站已运行 "+l+" 年 "+c+" 天",document.getElementById("sitetime").innerHTML=T}};calcSiteTime()</script><br></div><div class="col s12 m4 l4 social-link social-statis"><a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50"><i class="fab fa-github"></i></a><a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50"><i class="fas fa-envelope-open"></i></a> <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="关注我的知乎: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50"><i class="fab fa-zhihu1">知</i></a></div></div></footer><div class="progress-bar"></div><div id="searchModal" class="modal"><div class="modal-content"><div class="search-header"><span class="title"><i class="fas fa-search"></i> &nbsp;&nbsp;搜索</span> <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字" class="search-input"></div><div id="searchResult"></div></div></div><script>$((function(){!function(t,e,r){"use strict";$.ajax({url:t,dataType:"xml",success:function(t){var n=$("entry",t).map((function(){return{title:$("title",this).text(),content:$("content",this).text(),url:$("url",this).text()}})).get(),a=document.getElementById(e),s=document.getElementById(r);a.addEventListener("input",(function(){var t='<ul class="search-result-list">',e=this.value.trim().toLowerCase().split(/[\s\-]+/);s.innerHTML="",this.value.trim().length<=0||(n.forEach((function(r){var n=!0,a=r.title.trim().toLowerCase(),s=r.content.trim().replace(/<[^>]+>/g,"").toLowerCase(),i=r.url;i=0===i.indexOf("/")?r.url:"/"+i;var l=-1,c=-1,u=-1;if(""!==a&&""!==s&&e.forEach((function(t,e){l=a.indexOf(t),c=s.indexOf(t),l<0&&c<0?n=!1:(c<0&&(c=0),0===e&&(u=c))})),n){t+="<li><a href='"+i+"' class='search-result-title'>"+a+"</a>";var o=r.content.trim().replace(/<[^>]+>/g,"");if(u>=0){var h=u-20,f=u+80;h<0&&(h=0),0===h&&(f=100),f>o.length&&(f=o.length);var m=o.substr(h,f);e.forEach((function(t){var e=new RegExp(t,"gi");m=m.replace(e,'<em class="search-keyword">'+t+"</em>")})),t+='<p class="search-result">'+m+"...</p>"}t+="</li>"}})),t+="</ul>",s.innerHTML=t)}))}})}("/Talk2Paper/search.xml","searchInput","searchResult")}))</script><div class="stars-con"><div id="stars"></div><div id="stars2"></div><div id="stars3"></div></div><script>function switchNightMode(){$('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($("body")),setTimeout((function(){$("body").hasClass("DarkMode")?($("body").removeClass("DarkMode"),localStorage.setItem("isDark","0"),$("#sum-moon-icon").removeClass("fa-sun").addClass("fa-moon")):($("body").addClass("DarkMode"),localStorage.setItem("isDark","1"),$("#sum-moon-icon").addClass("fa-sun").removeClass("fa-moon")),setTimeout((function(){$(".Cuteen_DarkSky").fadeOut(1e3,(function(){$(this).remove()}))}),2e3)}))}</script><div id="backTop" class="top-scroll"><a class="btn-floating btn-large waves-effect waves-light" href="#!"><i class="fas fa-arrow-up"></i></a></div><script src="/Talk2Paper/libs/materialize/materialize.min.js"></script><script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script><script src="/Talk2Paper/libs/aos/aos.js"></script><script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script><script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script><script src="/Talk2Paper/js/matery.js"></script><script>var windowWidth=$(window).width();windowWidth>768&&document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>')</script><script src="https://ssl.captcha.qq.com/TCaptcha.js"></script><script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script><button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button><script>!function(){var t=document.createElement("script"),e=window.location.protocol.split(":")[0];t.src="https"===e?"https://zz.bdstatic.com/linksubmit/push.js":"http://push.zhanzhang.baidu.com/push.js";var s=document.getElementsByTagName("script")[0];s.parentNode.insertBefore(t,s)}()</script><script src="/Talk2Paper/libs/others/clicklove.js" async></script><script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script><script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script><script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({log:!1,pluginJsPath:"lib/",pluginModelPath:"assets/",pluginRootPath:"live2dw/",tagMode:!1})</script></body></html><script>var st,OriginTitile=document.title;document.addEventListener("visibilitychange",(function(){document.hidden?(document.title="Σ(っ °Д °;)っ诶，页面崩溃了嘛？",clearTimeout(st)):(document.title="φ(゜▽゜*)♪咦，又好了！",st=setTimeout((function(){document.title=OriginTitile}),3e3))}))</script>