<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Diffusion Models">
    <meta name="description" content="Diffusion Models æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2024-05-06  Defect Image Sample Generation With Diffusion Prior for Steel Surface   Defect Recognition">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>Diffusion Models | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://pic1.zhimg.com/v2-d3231e3375af2b14c1e49248519eaebd.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Diffusion Models</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/Diffusion-Models/">
                                <span class="chip bg-color">Diffusion Models</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/Diffusion-Models/" class="post-category">
                                Diffusion Models
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2024-05-06
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2024-12-10
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    12.1k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    47 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº Googleçš„å¤§è¯­è¨€æ¨¡å‹<a target="_blank" rel="noopener" href="https://ai.google.dev/">Gemini-Pro</a>çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2024-05-06-æ›´æ–°"><a href="#2024-05-06-æ›´æ–°" class="headerlink" title="2024-05-06 æ›´æ–°"></a>2024-05-06 æ›´æ–°</h1><h2 id="Defect-Image-Sample-Generation-With-Diffusion-Prior-for-Steel-Surface-Defect-Recognition"><a href="#Defect-Image-Sample-Generation-With-Diffusion-Prior-for-Steel-Surface-Defect-Recognition" class="headerlink" title="Defect Image Sample Generation With Diffusion Prior for Steel Surface   Defect Recognition"></a>Defect Image Sample Generation With Diffusion Prior for Steel Surface   Defect Recognition</h2><p><strong>Authors:Yichun Tai, Kun Yang, Tao Peng, Zhenzhen Huang, Zhijiang Zhang</strong></p>
<p>The task of steel surface defect recognition is an industrial problem with great industry values. The data insufficiency is the major challenge in training a robust defect recognition network. Existing methods have investigated to enlarge the dataset by generating samples with generative models. However, their generation quality is still limited by the insufficiency of defect image samples. To this end, we propose Stable Surface Defect Generation (StableSDG), which transfers the vast generation distribution embedded in Stable Diffusion model for steel surface defect image generation. To tackle with the distinctive distribution gap between steel surface images and generated images of the diffusion model, we propose two processes. First, we align the distribution by adapting parameters of the diffusion model, adopted both in the token embedding space and network parameter space. Besides, in the generation process, we propose image-oriented generation rather than from pure Gaussian noises. We conduct extensive experiments on steel surface defect dataset, demonstrating state-of-the-art performance on generating high-quality samples and training recognition models, and both designed processes are significant for the performance. </p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2405.01872v1">PDF</a> </p>
<p><strong>Summary</strong><br>é’¢æè¡¨é¢ç¼ºé™·ç”Ÿæˆæ¨¡å‹StableSDGé€šè¿‡è¿ç§»Stable Diffusionæ¨¡å‹ç”Ÿæˆé«˜ç²¾åº¦åˆæˆå›¾åƒï¼Œæœ‰æ•ˆæå‡é’¢æè¡¨é¢ç¼ºé™·è¯†åˆ«æ¨¡å‹çš„é²æ£’æ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>åˆ©ç”¨Stable Diffusionæ¨¡å‹ç”Ÿæˆé’¢æè¡¨é¢ç¼ºé™·å›¾åƒï¼Œæ‰©å……è®­ç»ƒæ•°æ®é›†ã€‚</li>
<li>é€šè¿‡è°ƒæ•´æ¨¡å‹å‚æ•°å’ŒåµŒå…¥ç©ºé—´ï¼Œå¼¥åˆç”Ÿæˆå›¾åƒå’ŒçœŸå®å›¾åƒä¹‹é—´çš„åˆ†å¸ƒå·®å¼‚ã€‚</li>
<li>é‡‡ç”¨å›¾åƒå¼•å¯¼ç”Ÿæˆæ–¹å¼ï¼Œè€Œéçº¯é«˜æ–¯å™ªå£°ç”Ÿæˆã€‚</li>
<li>æå‡ºä¸¤ç§å…³é”®è¿‡ç¨‹ï¼šåˆ†å¸ƒå¯¹é½å’Œå›¾åƒå¼•å¯¼ç”Ÿæˆã€‚</li>
<li>åœ¨é’¢æè¡¨é¢ç¼ºé™·æ•°æ®é›†ä¸Šè¿›è¡Œå¹¿æ³›å®éªŒï¼Œè¯æ˜StableSDGåœ¨ç”Ÿæˆé«˜è´¨é‡åˆæˆå›¾åƒå’Œè®­ç»ƒè¯†åˆ«æ¨¡å‹æ–¹é¢å‡è¾¾åˆ°æœ€å…ˆè¿›æ°´å¹³ã€‚</li>
<li>ä¸¤ç§æå‡ºçš„å…³é”®è¿‡ç¨‹å¯¹æ€§èƒ½è‡³å…³é‡è¦ã€‚</li>
<li>StableSDGæœ‰æ•ˆè§£å†³æ•°æ®ä¸è¶³é—®é¢˜ï¼Œæå‡é’¢æè¡¨é¢ç¼ºé™·è¯†åˆ«æ¨¡å‹çš„æ€§èƒ½ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>
<p>ç¼ºé™·å›¾åƒæ ·æœ¬ç”Ÿæˆä¸æ‰©æ•£</p>
</li>
<li>
<p>Yichun Tai, Kun Yang, Tao Peng, Zhenzhen Huang, and Zhijiang Zhang</p>
</li>
<li>
<p>ä¸Šæµ·å¤§å­¦ä¼ ä¿¡å­¦é™¢</p>
</li>
<li>
<p>Text-to-image diffusion, data expansion, deep learning, textual inversion, low-rank adaptation, defect image generation, steel surface defect recognition</p>
</li>
<li>
<p>https://arxiv.org/abs/2405.01872 , Github:None</p>
</li>
<li>
<p>æ‘˜è¦ï¼š</p>
</li>
</ol>
<p>ï¼ˆ1ï¼‰ï¼šé’¢è¡¨é¢ç¼ºé™·è¯†åˆ«æ˜¯å·¥ä¸šç•Œå…·æœ‰å·¨å¤§äº§ä¸šä»·å€¼çš„ä¸€é¡¹ä»»åŠ¡ã€‚æ•°æ®ä¸è¶³æ˜¯è®­ç»ƒé²æ£’ç¼ºé™·è¯†åˆ«ç½‘ç»œçš„ä¸»è¦æŒ‘æˆ˜ã€‚ç°æœ‰æ–¹æ³•å·²ç»ç ”ç©¶äº†é€šè¿‡ç”Ÿæˆæ¨¡å‹ç”Ÿæˆæ ·æœ¬ä»¥æ‰©å¤§æ•°æ®é›†ã€‚ç„¶è€Œï¼Œå®ƒä»¬çš„ç”Ÿæˆè´¨é‡ä»ç„¶å—åˆ°ç¼ºé™·å›¾åƒæ ·æœ¬ä¸è¶³çš„é™åˆ¶ã€‚</p>
<p>ï¼ˆ2ï¼‰ï¼šç°æœ‰çš„æ–¹æ³•åŒ…æ‹¬ï¼šSDGANã€Defect-GANã€transP2Pã€‚è¿™äº›æ–¹æ³•ä»å¤´å¼€å§‹è®­ç»ƒç”Ÿæˆæ¨¡å‹å…·æœ‰æŒ‘æˆ˜æ€§ï¼Œå½“å›¾åƒæ ·æœ¬ä¸è¶³æ—¶ï¼Œé€šå¸¸ä¼šå¯¼è‡´ç”Ÿæˆæ ·æœ¬ä¸­å‡ºç°ä¸éœ€è¦çš„æ¨¡å¼ã€‚</p>
<p>ï¼ˆ3ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§ç¨³å®šçš„è¡¨é¢ç¼ºé™·ç”Ÿæˆï¼ˆStableSDGï¼‰æ–¹æ³•ï¼Œå°†Stable Diffusionæ¨¡å‹ä¸­åµŒå…¥çš„å·¨å¤§ç”Ÿæˆåˆ†å¸ƒè½¬ç§»ç”¨äºé’¢è¡¨é¢ç¼ºé™·å›¾åƒç”Ÿæˆã€‚ä¸ºäº†è§£å†³é’¢è¡¨é¢å›¾åƒå’Œæ‰©æ•£æ¨¡å‹ç”Ÿæˆå›¾åƒä¹‹é—´çš„ç‹¬ç‰¹åˆ†å¸ƒå·®å¼‚ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸¤ä¸ªè¿‡ç¨‹ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬é€šè¿‡è°ƒæ•´æ‰©æ•£æ¨¡å‹çš„å‚æ•°æ¥å¯¹é½åˆ†å¸ƒï¼Œæ—¢é‡‡ç”¨æ ‡è®°åµŒå…¥ç©ºé—´ï¼Œä¹Ÿé‡‡ç”¨ç½‘ç»œå‚æ•°ç©ºé—´ã€‚æ­¤å¤–ï¼Œåœ¨ç”Ÿæˆè¿‡ç¨‹ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†é¢å‘å›¾åƒçš„ç”Ÿæˆï¼Œè€Œä¸æ˜¯ä»çº¯é«˜æ–¯å™ªå£°ä¸­ç”Ÿæˆã€‚</p>
<p>ï¼ˆ4ï¼‰ï¼šæˆ‘ä»¬åœ¨é’¢è¡¨é¢ç¼ºé™·æ•°æ®é›†ä¸Šè¿›è¡Œäº†å¹¿æ³›çš„å®éªŒï¼Œå±•ç¤ºäº†åœ¨ç”Ÿæˆé«˜è´¨é‡æ ·æœ¬å’Œè®­ç»ƒè¯†åˆ«æ¨¡å‹æ–¹é¢çš„æœ€å…ˆè¿›æ€§èƒ½ï¼Œå¹¶ä¸”ä¸¤ä¸ªè®¾è®¡è¿‡ç¨‹å¯¹æ€§èƒ½éƒ½å¾ˆé‡è¦ã€‚</p>
<ol>
<li>
<p>æ–¹æ³•ï¼š</p>
<pre><code>            (1):Stable Diffusionæ¨¡å‹[22]ä½œä¸ºæ‰©æ•£å…ˆéªŒï¼Œåœ¨æ½œåœ¨ç©ºé—´ä¸­æ‰§è¡Œæ‰©æ•£ï¼Œè€Œä¸æ˜¯å›¾åƒç©ºé—´ï¼Œå¹¿æ³›ç”¨äºå›¾åƒç”Ÿæˆä»»åŠ¡[26]â€“[30]ã€‚

<pre><code>        (2):æå‡ºStableSDGæ–¹æ³•ï¼Œç”±ä¸¤ä¸ªè¿‡ç¨‹ç»„æˆï¼Œç”¨äºç”Ÿæˆæ¯ç§ç¼ºé™·ç±»åˆ«çš„å›¾åƒã€‚

        (3):é€šè¿‡è¿­ä»£è´¨é‡è¯„ä¼°ï¼Œè°ƒæ•´è¶…å‚æ•°ä»¥å®ç°æœ€ä½³å›¾åƒç”Ÿæˆã€‚

        (4):ä½¿ç”¨æœ€ä½³è¶…å‚æ•°ï¼Œç”Ÿæˆé«˜è´¨é‡å›¾åƒä»¥æ‰©å±•æ•°æ®é›†ã€‚

        (5):å°†æ¯ç§ç¼ºé™·ç±»åˆ«çš„ç”Ÿæˆå›¾åƒä¸çœŸå®å›¾åƒä¸€èµ·æ”¶é›†èµ·æ¥ï¼Œç”¨äºè®­ç»ƒç¼ºé™·è¯†åˆ«æ¨¡å‹ã€‚
</code></pre>
<p></code></pre></p>
</li>
<li>
<p>ç»“è®ºï¼š</p>
</li>
</ol>
<p>ï¼ˆ1ï¼‰æœ¬æ–‡æå‡ºçš„StableSDGæ–¹æ³•å°†æ–‡æœ¬åˆ°å›¾åƒç”ŸæˆæŠ€æœ¯åº”ç”¨äºé’¢è¡¨é¢ç¼ºé™·å›¾åƒç”Ÿæˆï¼Œæœ‰æ•ˆè§£å†³äº†é’¢è¡¨é¢ç¼ºé™·æ•°æ®é›†ä¸è¶³çš„é—®é¢˜ï¼Œä¸ºç¼ºé™·è¯†åˆ«æ¨¡å‹çš„è®­ç»ƒæä¾›äº†é«˜è´¨é‡çš„æ ·æœ¬ã€‚</p>
<p>ï¼ˆ2ï¼‰åˆ›æ–°ç‚¹ï¼šStableSDGæ–¹æ³•åœ¨ç”Ÿæˆå™¨è‡ªé€‚åº”è¿‡ç¨‹ä¸­ï¼ŒåŒæ—¶åœ¨tokenåµŒå…¥ç©ºé—´å’Œç½‘ç»œå‚æ•°ç©ºé—´è¿›è¡Œè‡ªé€‚åº”å’Œä¿®æ”¹ï¼Œå¹¶åœ¨ç”Ÿæˆæ•°æ®æ—¶ä»å›¾åƒå¯¼å‘åˆå§‹åŒ–ç”Ÿæˆæ ·æœ¬ï¼Œè€Œä¸æ˜¯ä»çº¯é«˜æ–¯å™ªå£°å¼€å§‹ã€‚</p>
<p>æ€§èƒ½ï¼šStableSDGæ–¹æ³•åœ¨NEUå’ŒCCBSDæ•°æ®é›†ä¸Šè¿›è¡Œäº†å¹¿æ³›çš„å®éªŒï¼Œç»“æœè¡¨æ˜è¯¥æ–¹æ³•èƒ½å¤Ÿç”Ÿæˆé«˜ä¿çœŸåº¦çš„ç¼ºé™·å›¾åƒï¼Œå¤§å¤§æé«˜äº†è¯†åˆ«æ¨¡å‹çš„æ€§èƒ½ã€‚</p>
<p>å·¥ä½œé‡ï¼šStableSDGæ–¹æ³•çš„å·¥ä½œé‡ä¸»è¦é›†ä¸­åœ¨ç”Ÿæˆå™¨è‡ªé€‚åº”å’Œå›¾åƒç”Ÿæˆä¸¤ä¸ªé˜¶æ®µï¼Œéœ€è¦å¯¹è¶…å‚æ•°è¿›è¡Œè¿­ä»£è´¨é‡è¯„ä¼°å’Œè°ƒæ•´ï¼Œä»¥è·å¾—æœ€ä½³çš„å›¾åƒç”Ÿæˆæ•ˆæœã€‚</p>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-bd44eeacb7308bdc2e6594f5b84b63b5.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-a49aa1e7511a9ee599c2b42ba68cfb6d.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-e589bb5b223b5f1a03944e68feabbcd1.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-b4b7e153a9792e0731936f44ad770e5f.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-4222a03fe5309bbcdc62d8769e94eb0c.jpg" align="middle">
</details>




<h2 id="Long-Tail-Image-Generation-Through-Feature-Space-Augmentation-and-Iterated-Learning"><a href="#Long-Tail-Image-Generation-Through-Feature-Space-Augmentation-and-Iterated-Learning" class="headerlink" title="Long Tail Image Generation Through Feature Space Augmentation and   Iterated Learning"></a>Long Tail Image Generation Through Feature Space Augmentation and   Iterated Learning</h2><p><strong>Authors:Rafael Elberg, Denis Parra, Mircea Petrache</strong></p>
<p>Image and multimodal machine learning tasks are very challenging to solve in the case of poorly distributed data. In particular, data availability and privacy restrictions exacerbate these hurdles in the medical domain. The state of the art in image generation quality is held by Latent Diffusion models, making them prime candidates for tackling this problem. However, a few key issues still need to be solved, such as the difficulty in generating data from under-represented classes and a slow inference process. To mitigate these issues, we propose a new method for image augmentation in long-tailed data based on leveraging the rich latent space of pre-trained Stable Diffusion Models. We create a modified separable latent space to mix head and tail class examples. We build this space via Iterated Learning of underlying sparsified embeddings, which we apply to task-specific saliency maps via a K-NN approach. Code is available at <a target="_blank" rel="noopener" href="https://github.com/SugarFreeManatee/Feature-Space-Augmentation-and-Iterated-Learning">https://github.com/SugarFreeManatee/Feature-Space-Augmentation-and-Iterated-Learning</a> </p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2405.01705v1">PDF</a> </p>
<p><strong>Summary</strong><br>é•¿å°¾æ•°æ®å›¾åƒå¢å¼ºæ–¹æ³•ï¼Œåˆ©ç”¨é¢„è®­ç»ƒç¨³å®šæ‰©æ•£æ¨¡å‹çš„æ½œåœ¨ç©ºé—´ï¼Œç¼“è§£ç”Ÿæˆè´¨é‡å·®å’Œæ¨ç†é€Ÿåº¦æ…¢çš„é—®é¢˜ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>å›¾åƒå’Œå¤šæ¨¡æ€æœºå™¨å­¦ä¹ ä»»åŠ¡åœ¨æ•°æ®åˆ†å¸ƒä¸è¶³çš„æƒ…å†µä¸‹æå…·æŒ‘æˆ˜æ€§ã€‚</li>
<li>åŒ»å­¦é¢†åŸŸçš„å›¾åƒç”Ÿæˆé¢ä¸´æ•°æ®è·å–å’Œéšç§é™åˆ¶çš„éšœç¢ã€‚</li>
<li>æ½œåœ¨æ‰©æ•£æ¨¡å‹åœ¨å›¾åƒç”Ÿæˆè´¨é‡ä¸Šå¤„äºé¢†å…ˆåœ°ä½ã€‚</li>
<li>æ•°æ®ç”Ÿæˆä¸å¹³è¡¡å’Œæ¨ç†é€Ÿåº¦æ…¢æ˜¯äºŸå¾…è§£å†³çš„é—®é¢˜ã€‚</li>
<li>æ–¹æ³•ç»“åˆé¢„è®­ç»ƒç¨³å®šæ‰©æ•£æ¨¡å‹çš„æ½œåœ¨ç©ºé—´ï¼Œè¿›è¡Œå›¾åƒå¢å¼ºã€‚</li>
<li>æ„å»ºå¯åˆ†ç¦»çš„æ½œåœ¨ç©ºé—´ï¼Œæ··åˆå¤´éƒ¨å’Œå°¾éƒ¨ç±»åˆ«çš„ç¤ºä¾‹ã€‚</li>
<li>é€šè¿‡è¿­ä»£å­¦ä¹ æ½œåœ¨åµŒå…¥ï¼Œæ„å»ºç©ºé—´ï¼Œå¹¶é€šè¿‡ K-NN æ–¹æ³•åº”ç”¨äºç‰¹å®šä»»åŠ¡çš„æ˜¾ç€æ€§å›¾ã€‚</li>
<li>ä»£ç å·²å¼€æºï¼š<a target="_blank" rel="noopener" href="https://github.com/SugarFreeManatee/Feature-Space-Augmentation-and-Iterated-Learning">https://github.com/SugarFreeManatee/Feature-Space-Augmentation-and-Iterated-Learning</a></li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>
<p>æ ‡é¢˜ï¼šç‰¹å¾ç©ºé—´å¢å¼ºå’Œè¿­ä»£å­¦ä¹ çš„é•¿å°¾å›¾åƒç”Ÿæˆ</p>
</li>
<li>
<p>ä½œè€…ï¼šRafael Elbergã€Denis Parraã€Mircea Petrache</p>
</li>
<li>
<p>éš¶å±ï¼šæ™ºåˆ©å¤©ä¸»æ•™å¤§å­¦</p>
</li>
<li>
<p>å…³é”®è¯ï¼šé•¿å°¾æ•°æ®ã€å›¾åƒç”Ÿæˆã€ç‰¹å¾ç©ºé—´å¢å¼ºã€è¿­ä»£å­¦ä¹ </p>
</li>
<li>
<p>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2405.01705
   Github ä»£ç é“¾æ¥ï¼šhttps://github.com/SugarFreeManatee/Feature-Space-Augmentation-and-Iterated-Learning</p>
</li>
<li>
<p>æ‘˜è¦ï¼š</p>
</li>
</ol>
<p>(1)ï¼šå›¾åƒå’Œå¤šæ¨¡æ€æœºå™¨å­¦ä¹ ä»»åŠ¡åœ¨æ•°æ®åˆ†å¸ƒä¸å‡åŒ€çš„æƒ…å†µä¸‹éå¸¸å…·æœ‰æŒ‘æˆ˜æ€§ã€‚ç‰¹åˆ«æ˜¯åœ¨åŒ»ç–—é¢†åŸŸï¼Œæ•°æ®å¯ç”¨æ€§å’Œéšç§é™åˆ¶åŠ å‰§äº†è¿™äº›éšœç¢ã€‚æ½œæ‰©æ•£æ¨¡å‹åœ¨å›¾åƒç”Ÿæˆè´¨é‡æ–¹é¢å¤„äºæœ€å…ˆè¿›æ°´å¹³ï¼Œä½¿å…¶æˆä¸ºè§£å†³æ­¤é—®é¢˜çš„ç†æƒ³å€™é€‰è€…ã€‚ç„¶è€Œï¼Œä»éœ€è¦è§£å†³å‡ ä¸ªå…³é”®é—®é¢˜ï¼Œä¾‹å¦‚éš¾ä»¥ç”Ÿæˆæ¥è‡ªä»£è¡¨æ€§ä¸è¶³çš„ç±»åˆ«çš„å›¾åƒä»¥åŠæ¨ç†è¿‡ç¨‹ç¼“æ…¢ã€‚</p>
<p>(2)ï¼šè¿‡å»çš„æ–¹æ³•åŒ…æ‹¬é‡é‡‡æ ·å’Œæ•°æ®å¢å¼ºã€‚é‡é‡‡æ ·æŠ€æœ¯åœ¨ä¸€äº›é•¿å°¾é—®é¢˜ä¸­å–å¾—äº†ç›¸å¯¹æˆåŠŸï¼Œä½†å¯èƒ½ä¼šç»™ä¸‹æ¸¸ä»»åŠ¡å¼•å…¥ä¸å¿…è¦çš„åå·®ï¼Œå¹¶ä¸”ç»å¸¸å¯¼è‡´è¿‡æ‹Ÿåˆã€‚æ•°æ®å¢å¼ºæ˜¯è§£å†³è¿™äº›é—®é¢˜çš„è‡ªç„¶å“åº”ã€‚å®ƒä»£è¡¨äº†ä¸€ä¸ªè“¬å‹ƒå‘å±•çš„ç ”ç©¶é¢†åŸŸï¼ŒåŒ…æ‹¬å‡ ä¸ªä¸åŒçš„ç®—æ³•ç³»åˆ—ï¼Œä¾‹å¦‚å‡ ä½•å˜æ¢ï¼ˆæ—‹è½¬ã€ç¼©æ”¾ã€è£å‰ªç­‰ï¼‰ã€åˆæˆæ ·æœ¬åˆ›å»ºã€åŸºäºæ··åˆçš„æ–¹æ³•ã€åŸºäºåŸŸè½¬æ¢çš„æ–¹æ³•å’Œç”Ÿæˆæ–¹æ³•ã€‚</p>
<p>(3)ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„æ•°æ®å¢å¼ºæ–¹æ³•ï¼Œè¯¥æ–¹æ³•æ“çºµæ¥è‡ªé¢„è®­ç»ƒæ‰©æ•£æ¨¡å‹çš„å›¾åƒçš„æ½œåœ¨ç©ºé—´è¡¨ç¤ºï¼Œä»è€Œç”Ÿæˆæ–°å›¾åƒæ¥å¢å¼ºä»£è¡¨æ€§ä¸è¶³çš„ç±»åˆ«ã€‚é€šè¿‡æ¿€æ´»å›¾é€‰æ‹©æ•°æ®çš„ç‰¹å®šç‰¹å¾ï¼Œç„¶åå°†è¿™äº›ç‰¹å¾ç»„åˆèµ·æ¥ï¼Œç”Ÿæˆä¸å±äºé•¿å°¾ç±»çš„å®é™…æ•°æ®ä¸­çš„å›¾åƒç›¸ä¼¼çš„å›¾åƒã€‚</p>
<p>(4)ï¼šåœ¨æœ¬æ–‡çš„æ–¹æ³•ä¸­ï¼Œæ½œåœ¨ç©ºé—´è¡¨ç¤ºçš„ç»„åˆç”±äºç‰¹å¾åå¤„ç†ä¹‹é—´çš„å¹²æ‰°ç°è±¡è€Œéš¾ä»¥é€šè¿‡æœ´ç´ çš„æ–¹æ³•æ‰§è¡Œã€‚æœ¬æ–‡å°†æ­¤é—®é¢˜ä½œä¸ºåˆæˆæ³›åŒ–é—®é¢˜ï¼Œå¹¶å°†è¿­ä»£å­¦ä¹ ï¼ˆILï¼‰æ¡†æ¶ä¸ç¨€ç–åµŒå…¥åº”ç”¨äºç›®æ ‡æ•°æ®å¢å¼ºæ¡†æ¶ã€‚IL çš„ä¸»è¦çµæ„Ÿæ¥è‡ªæ–‡åŒ–è¿›åŒ–æ¨¡å‹ï¼Œå…¶ä¸­æ•™å¸ˆ-å­¦ç”Ÿäº¤äº’çš„è¿­ä»£é¼“åŠ±æœ‰ç”¨çš„å‹ç¼©å’Œå½¢æˆé€‚åº”ä»»åŠ¡çš„â€œå…±äº«è¯­è¨€â€ã€‚ç‰¹åˆ«æ˜¯ï¼Œæœ€è¿‘åœ¨ä½¿ç”¨ç¨€ç–çŠ¶æ€ç©ºé—´æ—¶è·å¾—äº†ä¸åˆæˆä¸åŒç‰¹å¾ç›¸å…³çš„æœ‰åˆ©ç»“æœã€‚</p>
<ol>
<li>æ–¹æ³•ï¼š</li>
</ol>
<p>ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„æ•°æ®å¢å¼ºæ–¹æ³•ï¼Œè¯¥æ–¹æ³•é€šè¿‡æ“çºµæ¥è‡ªé¢„è®­ç»ƒæ‰©æ•£æ¨¡å‹çš„å›¾åƒçš„æ½œåœ¨ç©ºé—´è¡¨ç¤ºæ¥ç”Ÿæˆæ–°å›¾åƒï¼Œä»¥å¢å¼ºä»£è¡¨æ€§ä¸è¶³çš„ç±»åˆ«ï¼›</p>
<p>ï¼ˆ2ï¼‰ï¼šè¯¥æ–¹æ³•åŒ…æ‹¬ä¸‰ä¸ªé˜¶æ®µï¼šè¿­ä»£è®­ç»ƒã€ç±»åˆ«æ¿€æ´»å›¾ç”Ÿæˆå’Œæ¨ç†ï¼›</p>
<p>ï¼ˆ3ï¼‰ï¼šåœ¨è¿­ä»£è®­ç»ƒé˜¶æ®µï¼Œå­¦ä¹ äº†ä¸€ä¸ªä»æ‰©æ•£æ½œåœ¨ç©ºé—´åˆ°ç¨€ç–é«˜ç»´è¡¨ç¤ºçš„è½¬æ¢ï¼ŒåŒæ—¶è®­ç»ƒäº†ä¸€ä¸ªå·ç§¯åˆ†ç±»å™¨ç”¨äºè¯¥ç©ºé—´ï¼›</p>
<p>ï¼ˆ4ï¼‰ï¼šåœ¨ç±»åˆ«æ¿€æ´»å›¾ç”Ÿæˆé˜¶æ®µï¼Œä½¿ç”¨åˆ†ç±»å™¨ç”Ÿæˆæ¯ä¸ªç±»çš„ç®€å•å¯è§£é‡Šæ¿€æ´»å›¾ï¼Œä»¥é€‰æ‹©ä¸åˆ†ç±»ä¸ºè¯¥ç±»ç›¸å…³çš„æˆ–ä¸ç›¸å…³çš„åæ ‡ï¼›</p>
<p>ï¼ˆ5ï¼‰ï¼šåœ¨æ¨ç†é˜¶æ®µï¼Œä»å°¾éƒ¨ç±»ç”Ÿæˆæ–°æ ·æœ¬ï¼Œé€šè¿‡å°†ç‰¹å®šå°¾éƒ¨ç±»ç¤ºä¾‹çš„ç±»ç‰¹å®šç‰¹å¾ä¸æœ€é«˜æ··æ·†å¤´éƒ¨ç±»çš„ç±»é€šç”¨ç‰¹å¾èåˆï¼Œä½¿ç”¨æ©ç åˆ›å»ºèåˆå‘é‡ã€‚</p>
<ol>
<li>ç»“è®ºï¼š</li>
</ol>
<p>ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„æ–¹æ³•ï¼Œé€šè¿‡åˆ©ç”¨é¢„è®­ç»ƒçš„æ½œåœ¨æ‰©æ•£æ¨¡å‹ã€ç»„åˆå­¦ä¹ å’Œæ˜¾ç€æ€§æ–¹æ³•ï¼Œä¸ºé•¿å°¾æ•°æ®é›†ç”Ÿæˆæ•°æ®å¹¶å¢å¼ºæ•°æ®ï¼Œä»è€Œä¸ºä»£è¡¨æ€§ä¸è¶³çš„ç±»åˆ«ç”Ÿæˆæ–°ç¤ºä¾‹ã€‚</p>
<p>ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼šæå‡ºäº†ä¸€ç§åˆ©ç”¨æ½œåœ¨æ‰©æ•£æ¨¡å‹ã€ç»„åˆå­¦ä¹ å’Œæ˜¾è‘—æ€§æ–¹æ³•çš„æ•°æ®å¢å¼ºå’Œæ•°æ®ç”Ÿæˆæ–¹æ³•ï¼›æ€§èƒ½ï¼šåœ¨åŒ»å­¦é¢†åŸŸçš„å¤šæ ‡ç­¾åˆ†ç±»ä»»åŠ¡ä¸­ä½¿ç”¨ MIMIC-CXR-LT [13, 16] çš„ä¸€ä¸ªå°å‹å­é›†ï¼Œåœ¨å›¾åƒç”Ÿæˆå’Œæ•°æ®å¢å¼ºæ–¹é¢å–å¾—äº†æœ‰ç«äº‰åŠ›çš„ç»“æœï¼›å·¥ä½œé‡ï¼šå·¥ä½œé‡ä¸­ç­‰ï¼Œéœ€è¦é¢„è®­ç»ƒæ½œåœ¨æ‰©æ•£æ¨¡å‹ï¼Œå¹¶å¯¹è½¬æ¢å’Œåˆ†ç±»å™¨è¿›è¡Œè¿­ä»£è®­ç»ƒã€‚</p>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-0d188950e8539013f5d1dbb852ac0cbb.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-8c5b473a90cffec494f2607efb08a6c2.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-39ea380f716fabbe74492f3835a23773.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-9d004602232a458ce5dd218668a87e87.jpg" align="middle">
</details>




<h2 id="LocInv-Localization-aware-Inversion-for-Text-Guided-Image-Editing"><a href="#LocInv-Localization-aware-Inversion-for-Text-Guided-Image-Editing" class="headerlink" title="LocInv: Localization-aware Inversion for Text-Guided Image Editing"></a>LocInv: Localization-aware Inversion for Text-Guided Image Editing</h2><p><strong>Authors:Chuanming Tang, Kai Wang, Fei Yang, Joost van de Weijer</strong></p>
<p>Large-scale Text-to-Image (T2I) diffusion models demonstrate significant generation capabilities based on textual prompts. Based on the T2I diffusion models, text-guided image editing research aims to empower users to manipulate generated images by altering the text prompts. However, existing image editing techniques are prone to editing over unintentional regions that are beyond the intended target area, primarily due to inaccuracies in cross-attention maps. To address this problem, we propose Localization-aware Inversion (LocInv), which exploits segmentation maps or bounding boxes as extra localization priors to refine the cross-attention maps in the denoising phases of the diffusion process. Through the dynamic updating of tokens corresponding to noun words in the textual input, we are compelling the cross-attention maps to closely align with the correct noun and adjective words in the text prompt. Based on this technique, we achieve fine-grained image editing over particular objects while preventing undesired changes to other regions. Our method LocInv, based on the publicly available Stable Diffusion, is extensively evaluated on a subset of the COCO dataset, and consistently obtains superior results both quantitatively and qualitatively.The code will be released at <a target="_blank" rel="noopener" href="https://github.com/wangkai930418/DPL">https://github.com/wangkai930418/DPL</a> </p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2405.01496v1">PDF</a> Accepted by CVPR 2024 Workshop AI4CC</p>
<p><strong>Summary</strong><br>æ–‡æœ¬å¼•å¯¼å›¾åƒç¼–è¾‘ç ”ç©¶åˆ©ç”¨å¤§å‹æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹ï¼Œä½†ç°æœ‰ç¼–è¾‘æŠ€æœ¯å®¹æ˜“ä¿®æ”¹è¶…å‡ºç›®æ ‡åŒºåŸŸçš„æ— æ„åŒºåŸŸï¼Œä¸»è¦æ˜¯å› ä¸ºäº¤å‰æ³¨æ„åŠ›å›¾ä¸å‡†ç¡®ã€‚æˆ‘ä»¬é€šè¿‡åˆ†å‰²å›¾æˆ–è¾¹ç•Œæ¡†æ”¹è¿›æ‰©æ•£è¿‡ç¨‹ä¸­çš„äº¤å‰æ³¨æ„åŠ›å›¾ï¼Œå®ç°äº†ç‰¹å®šå¯¹è±¡çš„ç»†ç²’åº¦å›¾åƒç¼–è¾‘ï¼ŒåŒæ—¶é˜²æ­¢å¯¹å…¶ä»–åŒºåŸŸè¿›è¡Œéå¿…è¦çš„æ›´æ”¹ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>ç°æœ‰å›¾åƒç¼–è¾‘æŠ€æœ¯å®¹æ˜“ä¿®æ”¹è¶…å‡ºç›®æ ‡åŒºåŸŸçš„æ— æ„åŒºåŸŸã€‚</li>
<li>æˆ‘ä»¬æå‡ºäº†åˆ©ç”¨åˆ†å‰²å›¾æˆ–è¾¹ç•Œæ¡†ä½œä¸ºé¢å¤–çš„å®šä½å…ˆéªŒæ¥æ”¹è¿›æ‰©æ•£è¿‡ç¨‹ä¸­çš„äº¤å‰æ³¨æ„åŠ›å›¾ã€‚</li>
<li>æˆ‘ä»¬é€šè¿‡æ›´æ–°æ–‡æœ¬è¾“å…¥ä¸­åè¯å¯¹åº”çš„ç¬¦å·ï¼Œè¿«ä½¿äº¤å‰æ³¨æ„åŠ›å›¾ç´§å¯†å¯¹é½æ–‡æœ¬æç¤ºä¸­çš„æ­£ç¡®åè¯å’Œå½¢å®¹è¯ã€‚</li>
<li>æˆ‘ä»¬åŸºäºå…¬å¼€çš„Stable Diffusionå®ç°äº†LocInvæ–¹æ³•ï¼Œå¹¶åœ¨COCOæ•°æ®é›†çš„å­é›†ä¸Šè¿›è¡Œäº†å¹¿æ³›è¯„ä¼°ã€‚</li>
<li>ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨å®šé‡å’Œå®šæ€§ä¸Šéƒ½å–å¾—äº†æ›´å¥½çš„ç»“æœã€‚</li>
<li>è¯¥æ–¹æ³•çš„ä»£ç å°†åœ¨<a target="_blank" rel="noopener" href="https://github.com/wangkai930418/DPL%E4%B8%8A%E5%85%AC%E5%B8%83%E3%80%82">https://github.com/wangkai930418/DPLä¸Šå…¬å¸ƒã€‚</a></li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>
<p>æ ‡é¢˜ï¼šå®šä½æ„ŸçŸ¥åæ¼”ï¼šæ–‡æœ¬å¼•å¯¼å›¾åƒç¼–è¾‘</p>
</li>
<li>
<p>ä½œè€…ï¼šChuanming Tangã€Kai Wangã€Fei Yangã€Joost van de Weijer</p>
</li>
<li>
<p>å•ä½ï¼šä¸­å›½ç§‘å­¦é™¢å¤§å­¦</p>
</li>
<li>
<p>å…³é”®è¯ï¼šæ–‡æœ¬åˆ°å›¾åƒã€å›¾åƒç¼–è¾‘ã€å®šä½æ„ŸçŸ¥ã€äº¤å‰æ³¨æ„åŠ›</p>
</li>
<li>
<p>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2405.01496
Githubï¼šæ— </p>
</li>
<li>
<p>æ‘˜è¦ï¼š</p>
</li>
</ol>
<p>ï¼ˆ1ï¼‰ï¼šç ”ç©¶èƒŒæ™¯ï¼šå¤§è§„æ¨¡æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹åœ¨æ–‡æœ¬æç¤ºä¸‹å±•ç¤ºäº†æ˜¾è‘—çš„ç”Ÿæˆèƒ½åŠ›ã€‚åŸºäºæ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹ï¼Œæ–‡æœ¬å¼•å¯¼å›¾åƒç¼–è¾‘ç ”ç©¶æ—¨åœ¨é€šè¿‡æ”¹å˜æ–‡æœ¬æç¤ºæ¥èµ‹äºˆç”¨æˆ·æ“çºµç”Ÿæˆå›¾åƒçš„èƒ½åŠ›ã€‚</p>
<p>ï¼ˆ2ï¼‰ï¼šå·²æœ‰æ–¹æ³•åŠé—®é¢˜ï¼šç°æœ‰çš„å›¾åƒç¼–è¾‘æŠ€æœ¯å®¹æ˜“å¯¹è¶…å‡ºç›®æ ‡åŒºåŸŸçš„æ— æ„åŒºåŸŸè¿›è¡Œç¼–è¾‘ï¼Œè¿™ä¸»è¦æ˜¯ç”±äºäº¤å‰æ³¨æ„åŠ›å›¾çš„ä¸å‡†ç¡®ã€‚</p>
<p>ï¼ˆ3ï¼‰ï¼šæå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºå®šä½æ„ŸçŸ¥åæ¼”ï¼ˆLocInvï¼‰ï¼Œå®ƒåˆ©ç”¨åˆ†å‰²å›¾æˆ–è¾¹ç•Œæ¡†ä½œä¸ºé¢å¤–çš„å®šä½å…ˆéªŒï¼Œåœ¨æ‰©æ•£è¿‡ç¨‹çš„å»å™ªé˜¶æ®µä¼˜åŒ–äº¤å‰æ³¨æ„åŠ›å›¾ã€‚é€šè¿‡åŠ¨æ€æ›´æ–°æ–‡æœ¬è¾“å…¥ä¸­ä¸åè¯å¯¹åº”çš„æ ‡è®°ï¼Œè¿«ä½¿äº¤å‰æ³¨æ„åŠ›å›¾ä¸æ–‡æœ¬æç¤ºä¸­æ­£ç¡®çš„åè¯å’Œå½¢å®¹è¯ç´§å¯†å¯¹é½ã€‚åŸºäºæ­¤æŠ€æœ¯ï¼Œæˆ‘ä»¬å®ç°äº†å¯¹ç‰¹å®šå¯¹è±¡çš„ç»†ç²’åº¦å›¾åƒç¼–è¾‘ï¼ŒåŒæ—¶é˜²æ­¢å¯¹å…¶ä»–åŒºåŸŸè¿›è¡Œä¸å¿…è¦çš„æ›´æ”¹ã€‚</p>
<p>ï¼ˆ4ï¼‰ï¼šæ–¹æ³•æ€§èƒ½ï¼šåŸºäºå…¬å¼€çš„Stable Diffusionï¼Œæˆ‘ä»¬å¯¹LocInvæ–¹æ³•åœ¨COCOæ•°æ®é›†çš„å­é›†ä¸Šè¿›è¡Œäº†å¹¿æ³›çš„è¯„ä¼°ï¼Œåœ¨å®šé‡å’Œå®šæ€§ä¸Šéƒ½å–å¾—äº†ä¼˜å¼‚çš„ç»“æœã€‚è¿™äº›ç»“æœè¯æ˜äº†è¯¥æ–¹æ³•å¯ä»¥å®ç°å…¶ç›®æ ‡ã€‚</p>
<ol>
<li>æ–¹æ³•ï¼š</li>
</ol>
<p>ï¼ˆ1ï¼‰ï¼šä½¿ç”¨ Stable Diffusion v1.4 ä½œä¸ºåŸºç¡€æ‰©æ•£æ¨¡å‹ï¼Œè¯¥æ¨¡å‹ç”±ç¼–ç å™¨ã€è§£ç å™¨å’Œæ‰©æ•£æ¨¡å‹ç»„æˆã€‚</p>
<p>ï¼ˆ2ï¼‰ï¼šé‡‡ç”¨ DDIM åæ¼”ç®—æ³•ï¼Œä»éšæœºå™ªå£° zT æ‰¾åˆ°åˆå§‹å™ªå£°ï¼Œé€šè¿‡é‡‡æ ·é‡å»ºè¾“å…¥æ½œåœ¨ä»£ç  z0ã€‚</p>
<p>ï¼ˆ3ï¼‰ï¼šä½¿ç”¨æ— æ–‡æœ¬åæ¼” (NTI) ä¼˜åŒ–æ— æ–‡æœ¬åµŒå…¥ âˆ…tï¼Œä»¥è¿‘ä¼¼ DDIM è½¨è¿¹ {zt}T 0ï¼Œä»è€Œç¼–è¾‘çœŸå®å›¾åƒã€‚</p>
<p>ï¼ˆ4ï¼‰ï¼šæå‡ºåŠ¨æ€æç¤ºå­¦ä¹  (DPL) æ–¹æ³•ï¼Œåˆ©ç”¨åˆ†å‰²å›¾æˆ–æ£€æµ‹æ¡†ä½œä¸ºå®šä½å…ˆéªŒï¼Œæ›´æ–°æ–‡æœ¬æç¤º P ä¸­çš„åè¯å•è¯å¯¹åº”çš„æ ‡è®°ï¼Œè¿«ä½¿äº¤å‰æ³¨æ„åŠ›å›¾ä¸æ–‡æœ¬æç¤ºä¸­çš„åè¯å’Œå½¢å®¹è¯ç´§å¯†å¯¹é½ã€‚</p>
<p>ï¼ˆ5ï¼‰ï¼šè®¾è®¡ç›¸ä¼¼åº¦æŸå¤±å’Œé‡å æŸå¤±ï¼Œä¼˜åŒ–åµŒå…¥å‘é‡ Vtï¼Œä½¿äº¤å‰æ³¨æ„åŠ›å›¾ä¸å®šä½å…ˆéªŒ S ä¹‹é—´ç›¸ä¼¼åº¦é«˜ã€é‡å åº¦é«˜ã€‚</p>
<p>ï¼ˆ6ï¼‰ï¼šé‡‡ç”¨æ¸è¿›ä¼˜åŒ–æœºåˆ¶ï¼Œåœ¨æ¯ä¸ªæ—¶é—´æ­¥ t å¤„å¼ºåˆ¶æ‰€æœ‰æŸå¤±è¾¾åˆ°é¢„å®šä¹‰é˜ˆå€¼ï¼Œé¿å…äº¤å‰æ³¨æ„åŠ›å›¾è¿‡æ‹Ÿåˆã€‚</p>
<p>ï¼ˆ7ï¼‰ï¼šç»“åˆ NTI å­¦ä¹ ä¸€ç»„æ— æ–‡æœ¬åµŒå…¥ âˆ…tï¼Œä¸å¯å­¦ä¹ çš„å•è¯åµŒå…¥ Vt å…±åŒç²¾ç¡®å®šä½å¯¹è±¡å¹¶é‡å»ºåŸå§‹å›¾åƒã€‚</p>
<p>ï¼ˆ8ï¼‰ï¼šæå‡ºå½¢å®¹è¯ç»‘å®šæœºåˆ¶ï¼Œé€šè¿‡æ”¹å˜æ–‡æœ¬æç¤ºä¸­çš„å½¢å®¹è¯æ¥æ”¹å˜å¯¹è±¡çš„å¤–è§‚ã€‚</p>
<ol>
<li>Conclusion:</li>
</ol>
<p>(1): æœ¬æ–‡æå‡ºçš„ LocInv æ–¹æ³•è§£å†³äº†æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹å›¾åƒç¼–è¾‘ä¸­äº¤å‰æ³¨æ„åŠ›å›¾æ³„æ¼çš„é—®é¢˜ã€‚æˆ‘ä»¬æå‡ºä½¿ç”¨åˆ†å‰²å›¾æˆ–æ£€æµ‹æ¡†ä½œä¸ºå…ˆéªŒï¼Œæ›´æ–°æç¤ºä¸­æ¯ä¸ªåè¯å•è¯çš„åŠ¨æ€æ ‡è®°ã€‚ç”±æ­¤äº§ç”Ÿçš„äº¤å‰æ³¨æ„åŠ›å›¾è¾ƒå°‘å—åˆ°äº¤å‰æ³¨æ„åŠ›å›¾æ³„æ¼çš„å½±å“ã€‚å› æ­¤ï¼Œè¿™äº›å¤§å¤§æ”¹è¿›çš„äº¤å‰æ³¨æ„åŠ›å›¾æå¤§åœ°æ”¹å–„äº†æ–‡æœ¬å¼•å¯¼å›¾åƒç¼–è¾‘çš„ç»“æœã€‚å®éªŒç»“æœè¯å®ï¼ŒLocInv è·å¾—äº†æ›´å¥½çš„ç»“æœï¼Œå°¤å…¶æ˜¯åœ¨å¤æ‚çš„å¤šå¯¹è±¡åœºæ™¯ä¸­ã€‚æœ€åï¼Œæˆ‘ä»¬å±•ç¤ºäº†æˆ‘ä»¬çš„æ–¹æ³•è¿˜å¯ä»¥å°†å½¢å®¹è¯å•è¯ç»‘å®šåˆ°å®ƒä»¬å¯¹åº”ã®åè¯ä¸Šï¼Œä»è€Œå¾—åˆ°å½¢å®¹è¯çš„å‡†ç¡®äº¤å‰æ³¨æ„åŠ›å›¾ï¼Œå¹¶å…è®¸å¯¹å±æ€§è¿›è¡Œç¼–è¾‘ï¼Œè¿™æ˜¯ä»¥å‰åœ¨æ–‡æœ¬å¼•å¯¼å›¾åƒç¼–è¾‘ä¸­å°šæœªå……åˆ†æ¢ç´¢çš„ã€‚</p>
<p>(2): åˆ›æ–°ç‚¹ï¼šæå‡ºå®šä½æ„ŸçŸ¥åæ¼”æ–¹æ³•ï¼Œåˆ©ç”¨åˆ†å‰²å›¾æˆ–æ£€æµ‹æ¡†ä½œä¸ºå®šä½å…ˆéªŒï¼Œæ›´æ–°æ–‡æœ¬æç¤ºä¸­çš„åè¯å•è¯å¯¹åº”çš„æ ‡è®°ï¼Œè¿«ä½¿äº¤å‰æ³¨æ„åŠ›å›¾ä¸æ–‡æœ¬æç¤ºä¸­çš„åè¯å’Œå½¢å®¹è¯ç´§å¯†å¯¹é½ï¼›æå‡ºå½¢å®¹è¯ç»‘å®šæœºåˆ¶ï¼Œé€šè¿‡æ”¹å˜æ–‡æœ¬æç¤ºä¸­çš„å½¢å®¹è¯æ¥æ”¹å˜å¯¹è±¡çš„å¤–è§‚ã€‚</p>
<p>æ€§èƒ½ï¼šåœ¨ COCO æ•°æ®é›†çš„å­é›†ä¸Šè¿›è¡Œäº†å¹¿æ³›çš„è¯„ä¼°ï¼Œåœ¨å®šé‡å’Œå®šæ€§ä¸Šéƒ½å–å¾—äº†ä¼˜å¼‚çš„ç»“æœï¼Œè¯æ˜äº†è¯¥æ–¹æ³•å¯ä»¥å®ç°å…¶ç›®æ ‡ã€‚</p>
<p>å·¥ä½œé‡ï¼šæ–¹æ³•å®ç°è¾ƒä¸ºå¤æ‚ï¼Œéœ€è¦ç»“åˆ Stable Diffusion æ¨¡å‹å’Œ NTI åæ¼”ç®—æ³•ï¼Œä»¥åŠåˆ†å‰²å›¾æˆ–æ£€æµ‹æ¡†ä½œä¸ºå®šä½å…ˆéªŒã€‚</p>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-501b84f66a4fdce982c4d560d6ed2c6e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d7f11972c7c9876389df6092b426ca67.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-566375be0266ca83b73d642319fcc82b.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-2650ddd9595d88f0a5238c88b753e8e6.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-997ccc837824e0d3f900484e2641fab6.jpg" align="middle">
</details>




<h2 id="Guided-Conditional-Diffusion-Classifier-ConDiff-for-Enhanced-Prediction-of-Infection-in-Diabetic-Foot-Ulcers"><a href="#Guided-Conditional-Diffusion-Classifier-ConDiff-for-Enhanced-Prediction-of-Infection-in-Diabetic-Foot-Ulcers" class="headerlink" title="Guided Conditional Diffusion Classifier (ConDiff) for Enhanced   Prediction of Infection in Diabetic Foot Ulcers"></a>Guided Conditional Diffusion Classifier (ConDiff) for Enhanced   Prediction of Infection in Diabetic Foot Ulcers</h2><p><strong>Authors:Palawat Busaranuvong, Emmanuel Agu, Deepak Kumar, Shefalika Gautam, Reza Saadati Fard, Bengisu Tulu, Diane Strong</strong></p>
<p>To detect infected wounds in Diabetic Foot Ulcers (DFUs) from photographs, preventing severe complications and amputations. Methods: This paper proposes the Guided Conditional Diffusion Classifier (ConDiff), a novel deep-learning infection detection model that combines guided image synthesis with a denoising diffusion model and distance-based classification. The process involves (1) generating guided conditional synthetic images by injecting Gaussian noise to a guide image, followed by denoising the noise-perturbed image through a reverse diffusion process, conditioned on infection status and (2) classifying infections based on the minimum Euclidean distance between synthesized images and the original guide image in embedding space. Results: ConDiff demonstrated superior performance with an accuracy of 83% and an F1-score of 0.858, outperforming state-of-the-art models by at least 3%. The use of a triplet loss function reduces overfitting in the distance-based classifier. Conclusions: ConDiff not only enhances diagnostic accuracy for DFU infections but also pioneers the use of generative discriminative models for detailed medical image analysis, offering a promising approach for improving patient outcomes. </p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2405.00858v1">PDF</a> </p>
<p><strong>Summary</strong><br>åˆ©ç”¨åˆæˆå›¾åƒæ„ŸæŸ“çŠ¶æ€æŒ‡å¯¼åˆ†ç±»é‰´åˆ«ç³–å°¿ç—…è¶³æºƒç–¡æ„ŸæŸ“</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>æå‡ºäº†ä¸€ç§æ–°çš„ç³–å°¿ç—…è¶³æºƒç–¡æ„ŸæŸ“æ£€æµ‹æ¨¡å‹ï¼Œå³æ¡ä»¶å¼•å¯¼æ‰©æ•£åˆ†ç±»å™¨ï¼ˆConDiffï¼‰</li>
<li>ConDiffç»“åˆäº†å¼•å¯¼å›¾åƒåˆæˆã€å»å™ªæ‰©æ•£æ¨¡å‹å’ŒåŸºäºè·ç¦»çš„åˆ†ç±»</li>
<li>é€šè¿‡åœ¨å¼•å¯¼å›¾åƒä¸­æ³¨å…¥é«˜æ–¯å™ªå£°å¹¶é€šè¿‡æ¡ä»¶åŒ–æ„ŸæŸ“çŠ¶æ€è¿›è¡Œé€†æ‰©æ•£å»å™ªåˆæˆå›¾åƒ</li>
<li>åŸºäºåˆæˆå›¾åƒä¸åŸå§‹å¼•å¯¼å›¾åƒåœ¨åµŒå…¥ç©ºé—´ä¸­çš„æœ€å°æ¬§å‡ é‡Œå¾—è·ç¦»è¿›è¡Œæ„ŸæŸ“åˆ†ç±»</li>
<li>ä½¿ç”¨å…ƒç»„æŸå¤±å‡½æ•°åœ¨åŸºäºè·ç¦»çš„åˆ†ç±»å™¨ä¸­å‡å°‘è¿‡æ‹Ÿåˆ</li>
<li>ConDiffåœ¨å‡†ç¡®æ€§å’ŒF1-scoreä¸Šä¼˜äºæœ€å…ˆè¿›çš„æ¨¡å‹</li>
<li>ConDiffå¼€åˆ›äº†ç”Ÿæˆå¼åˆ¤åˆ«æ¨¡å‹åœ¨åŒ»å­¦å›¾åƒç²¾ç»†åˆ†æä¸­çš„åº”ç”¨ï¼Œä¸ºæ”¹å–„æ‚£è€…é¢„åæä¾›äº†ä¸€ç§æœ‰å‰é€”çš„æ–¹æ³•</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>
<p>Title: å¯¼å‘æ¡ä»¶æ‰©æ•£åˆ†ç±»å™¨ï¼ˆConDiffï¼‰</p>
</li>
<li>
<p>Authors: Palawat Busaranuvong, Emmanuel Agu, Deepak Kumar, Shefalika Gautam, Reza Saadati Fard, Bengisu Tulu, Diane Strong</p>
</li>
<li>
<p>Affiliation: Worcesterç†å·¥å­¦é™¢</p>
</li>
<li>
<p>Keywords: ç³–å°¿ç—…è¶³æºƒç–¡ï¼Œæ‰©æ•£æ¨¡å‹ï¼ŒåŸºäºè·ç¦»çš„å›¾åƒåˆ†ç±»ï¼Œç”Ÿæˆæ¨¡å‹ï¼Œä¼¤å£æ„ŸæŸ“</p>
</li>
<li>
<p>Urls: Paper: xxx, Github: None</p>
</li>
<li>
<p>Summary:</p>
<p>ï¼ˆ1ï¼‰ï¼šç³–å°¿ç—…è¶³æºƒç–¡ï¼ˆDFUï¼‰æ„ŸæŸ“æ˜¯å¯¼è‡´æˆªè‚¢å’Œä¸¥é‡å¹¶å‘ç—‡çš„ä¸»è¦åŸå› ï¼›</p>
<p>ï¼ˆ2ï¼‰ï¼šç°æœ‰çš„åŸºäºæ·±åº¦å­¦ä¹ çš„DFUæ„ŸæŸ“æ£€æµ‹æ–¹æ³•å­˜åœ¨å‡†ç¡®ç‡ä½çš„é—®é¢˜ï¼›</p>
<p>ï¼ˆ3ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„ConDiffæ¨¡å‹ï¼Œè¯¥æ¨¡å‹ç»“åˆäº†å¼•å¯¼å›¾åƒåˆæˆã€å»å™ªæ‰©æ•£æ¨¡å‹å’ŒåŸºäºè·ç¦»çš„åˆ†ç±»ï¼Œé€šè¿‡ç”Ÿæˆå¼•å¯¼æ¡ä»¶åˆæˆå›¾åƒå¹¶è®¡ç®—åˆæˆå›¾åƒä¸åŸå§‹å›¾åƒä¹‹é—´çš„æœ€å°æ¬§å‡ é‡Œå¾—è·ç¦»æ¥å¯¹æ„ŸæŸ“è¿›è¡Œåˆ†ç±»ï¼›</p>
<p>ï¼ˆ4ï¼‰ï¼šConDiffåœ¨DFUæ„ŸæŸ“æ•°æ®é›†ä¸Šå–å¾—äº†83%çš„å‡†ç¡®ç‡å’Œ0.858çš„F1åˆ†æ•°ï¼Œä¼˜äºç°æœ‰æ–¹æ³•è‡³å°‘3%ï¼Œè¯æ˜äº†å…¶åœ¨æé«˜DFUæ„ŸæŸ“è¯Šæ–­å‡†ç¡®æ€§æ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚</p>
</li>
<li>
<p>æ–¹æ³•ï¼š</p>
<p>ï¼ˆ1ï¼‰ï¼šConDiff æ¡†æ¶ç”±ä¸¤ä¸ªä¸»è¦éƒ¨åˆ†ç»„æˆï¼šï¼ˆ1ï¼‰å¼•å¯¼æ‰©æ•£ï¼Œå³å‘ DFU å›¾åƒæ³¨å…¥é«˜æ–¯å™ªå£°ï¼Œç„¶åæ ¹æ®æ„ŸæŸ“çŠ¶æ€ä»å™ªå£°æ‰°åŠ¨å›¾åƒä¸­é€æ­¥å»é™¤å™ªå£°ï¼Œä»¥åˆæˆæ¡ä»¶å›¾åƒï¼›ï¼ˆ2ï¼‰åŸºäºè·ç¦»çš„åˆ†ç±»å™¨ï¼Œå³æ ¹æ®åŸå§‹å›¾åƒå’Œåˆæˆå›¾åƒåœ¨åµŒå…¥ç©ºé—´ä¸­çš„æœ€å° L2 è·ç¦»é¢„æµ‹è¾“å…¥å›¾åƒçš„æ ‡ç­¾ã€‚</p>
<p>ï¼ˆ2ï¼‰ï¼šConDiff åˆ©ç”¨æ¡ä»¶å¼•å¯¼å›¾åƒç¼–è¾‘ä¸ç”Ÿæˆæ‰©æ•£æ¨¡å‹ï¼Œé€šè¿‡å‘è¾“å…¥å›¾åƒæ³¨å…¥ç‰¹å®šå¼ºåº¦çš„ Gaussian å™ªå£°ï¼Œå¹¶ä½¿ç”¨åå‘æ‰©æ•£è¿‡ç¨‹é€æ­¥ä»å™ªå£°æ‰°åŠ¨è¾“å…¥å›¾åƒä¸­å»é™¤å™ªå£°æ¥ç”Ÿæˆæ–°å›¾åƒã€‚</p>
<p>ï¼ˆ3ï¼‰ï¼šConDiff çš„æ‰©æ•£è¿‡ç¨‹ä»¥ä¼¤å£çš„çŠ¶å†µï¼ˆæ— æ„ŸæŸ“ï¼ˆy1ï¼‰æˆ–æ„ŸæŸ“ï¼ˆy2ï¼‰ï¼‰ä¸ºæ¡ä»¶ï¼Œåˆ›å»ºåæ˜ è¿™äº›çŠ¶æ€çš„åˆæˆå›¾åƒã€‚ä¸€ä¸ªå…³é”®ç‚¹æ˜¯ ConDiff èƒ½å¤Ÿé€šè¿‡åµŒå…¥ç©ºé—´ä¸­çš„ L2 è·ç¦»åˆ†ç±»å™¨è¯†åˆ«å’Œå­¦ä¹ æ¡ä»¶ç”Ÿæˆå›¾åƒ Ë†xy 0 å’ŒåŸå§‹ä¼¤å£å›¾åƒ x0 ä¹‹é—´è¡¨ç¤ºçš„ç›¸ä¼¼æ€§ã€‚äº§ç”Ÿä¸åŸå§‹å›¾åƒæœ€ç›¸ä¼¼çš„åˆæˆå›¾åƒçš„æ¡ä»¶è¢«é€‰ä½œé¢„æµ‹æ ‡ç­¾ã€‚</p>
<p>ï¼ˆ4ï¼‰ï¼šä¸æœ€å°åŒ–äºŒå…ƒäº¤å‰ç†µæŸå¤±å‡½æ•°çš„ä¼ ç»Ÿç›‘ç£åˆ†ç±»æŠ€æœ¯ä¸åŒï¼ŒConDiff é€šè¿‡åˆ©ç”¨ä¸‰å…ƒæŸå¤±å‡½æ•°æ¥å‡è½»è¿‡æ‹Ÿåˆï¼Œä»¥å¢åŠ éç›¸ä¼¼å›¾åƒå¯¹ä¹‹é—´çš„è·ç¦»å¹¶å‡å°‘ç›¸ä¼¼å›¾åƒå¯¹ä¹‹é—´çš„è·ç¦»ã€‚</p>
<p>ï¼ˆ5ï¼‰ï¼šæœ¬ç ”ç©¶åˆ©ç”¨ Goyal ç­‰äººæä¾›çš„ DFU æ„ŸæŸ“æ•°æ®é›†ï¼ˆè§è¡¨ Iï¼‰ã€‚ä½†æ˜¯ï¼Œä¸ºäº†æ¶ˆé™¤è®­ç»ƒé›†å’Œæµ‹è¯•é›†ä¹‹é—´çš„æ•°æ®æ³„æ¼ï¼Œæˆ‘ä»¬æ”¹è¿›äº†æ•°æ®é›†åˆ›å»ºå’Œæ‹†åˆ†ç­–ç•¥ã€‚ä½¿ç”¨åŸºäºä¸»é¢˜çš„æ‹†åˆ†ï¼Œä»…ä¸ºæ¯ä¸ªä¸»é¢˜ä½¿ç”¨ç¬¬äºŒä¸ªæ”¾å¤§è‡ªç„¶å¢å¼ºå›¾åƒï¼ˆå‚è§å›¾ 1ï¼‰ã€‚</p>
<p>ï¼ˆ6ï¼‰ï¼šConDiff æ¡†æ¶çš„ä¸»è¦è´¡çŒ®æ˜¯ï¼šï¼ˆ1ï¼‰æˆ‘ä»¬æå‡ºäº† Guided Conditional Diffusion Classifierï¼ˆConDiffï¼‰ï¼Œè¿™æ˜¯ä¸€ä¸ªç”¨äºåˆ†ç±»å—æ„ŸæŸ“ä¼¤å£å›¾åƒçš„é›†æˆç«¯åˆ°ç«¯æ¡†æ¶ã€‚ConDiff æ¡†æ¶æœ‰ 2 ä¸ªä¸»è¦éƒ¨åˆ†ï¼šï¼ˆ1ï¼‰å¼•å¯¼æ‰©æ•£ï¼Œå³å‘ DFU å›¾åƒæ³¨å…¥é«˜æ–¯å™ªå£°ï¼Œç„¶åæ ¹æ®æ„ŸæŸ“çŠ¶æ€ä»å™ªå£°æ‰°åŠ¨å›¾åƒä¸­é€æ­¥å»é™¤å™ªå£°ï¼Œä»¥åˆæˆæ¡ä»¶å›¾åƒï¼›ï¼ˆ2ï¼‰åŸºäºè·ç¦»çš„åˆ†ç±»å™¨ï¼Œå³æ ¹æ®åŸå§‹å›¾åƒå’Œåˆæˆå›¾åƒåœ¨åµŒå…¥ç©ºé—´ä¸­çš„æœ€å° L2 è·ç¦»é¢„æµ‹è¾“å…¥å›¾åƒçš„æ ‡ç­¾ã€‚æ®æˆ‘ä»¬æ‰€çŸ¥ï¼ŒConDiff æ˜¯ç¬¬ä¸€ä¸ªåˆ†æç»†ç²’åº¦ä¼¤å£å›¾åƒçš„ç”Ÿæˆåˆ¤åˆ«æ–¹æ³•ï¼Œä¿ƒè¿›äº†ç³–å°¿ç—…è¶³æºƒç–¡ (DFU) æ„ŸæŸ“çš„æ£€æµ‹ã€‚ï¼ˆ2ï¼‰åœ¨ DFU æ„ŸæŸ“æ•°æ®é›†çš„çœ‹ä¸è§çš„æµ‹è¯•ä¼¤å£å›¾åƒï¼ˆ148 ä¸ªå—æ„ŸæŸ“å’Œ 103 ä¸ªæœªå—æ„ŸæŸ“ï¼‰ä¸Šè¿›è¡Œä¸¥æ ¼è¯„ä¼°ï¼Œæˆ‘ä»¬çš„ ConDiff æ¡†æ¶æ˜æ˜¾ä¼˜äºæœ€å…ˆè¿›çš„åŸºçº¿ï¼Œæé«˜äº†ä¼¤å£æ„ŸæŸ“æ£€æµ‹çš„å‡†ç¡®æ€§å’Œ F1 åˆ†æ•°è‡³å°‘ 3%ã€‚ï¼ˆ3ï¼‰æˆ‘ä»¬è¯æ˜ï¼Œé€šè¿‡åœ¨è®­ç»ƒæœŸé—´æœ€å°åŒ–ä¸‰å…ƒæŸå¤±å‡½æ•°ï¼ŒConDiff å‡å°‘äº†å¯¹ 1416 ä¸ªè®­ç»ƒå›¾åƒçš„å° DFU æ•°æ®é›†çš„è¿‡æ‹Ÿåˆã€‚ï¼ˆ4ï¼‰ç”± Score-CAM ç”Ÿæˆçš„çƒ­å›¾ç”¨äºç›´è§‚åœ°è¯´æ˜ ConDiff åœ¨å¯¹ä¼¤å£æ„ŸæŸ“çŠ¶æ€è¿›è¡Œåˆ†ç±»æ—¶ä¸“æ³¨äºæ­£ç¡®çš„ä¼¤å£å›¾åƒåŒºåŸŸã€‚</p>
</li>
<li>
<p>ç»“è®ºï¼š</p>
</li>
</ol>
<p>ï¼ˆ1ï¼‰ï¼šæœ¬ç ”ç©¶å¼•å…¥äº†å¼•å¯¼æ¡ä»¶æ‰©æ•£åˆ†ç±»å™¨ï¼ˆConDiffï¼‰ï¼Œè¿™æ˜¯ä¸€ä¸ªç”¨äºå¯¹ç³–å°¿ç—…è¶³æºƒç–¡ï¼ˆDFUï¼‰æ„ŸæŸ“è¿›è¡Œåˆ†ç±»çš„æ–°æ¡†æ¶ã€‚ConDiff ä¼˜äºä¼ ç»Ÿæ¨¡å‹è‡³å°‘ 3%ï¼Œå‡†ç¡®ç‡é«˜è¾¾ 83%ï¼ŒF1 åˆ†æ•°ä¸º 0.858ã€‚å®ƒç‹¬ç‰¹çš„æ–¹æ³•åˆ©ç”¨ä¸‰å…ƒæŸå¤±è€Œä¸æ˜¯æ ‡å‡†çš„äº¤å‰ç†µæœ€å°åŒ–ï¼Œå¢å¼ºäº†é²æ£’æ€§å’Œå‡å°‘äº†è¿‡æ‹Ÿåˆã€‚è¿™åœ¨æ•°æ®é›†é€šå¸¸å¾ˆå°çš„åŒ»å­¦æˆåƒä¸­å°¤å…¶é‡è¦ã€‚ConDiff é‡‡ç”¨æ­£å‘æ‰©æ•£è¿‡ç¨‹ï¼Œå‘è¾“å…¥å›¾åƒä¸­æ·»åŠ ç‰¹å®šæ•°é‡çš„é«˜æ–¯å™ªå£°ï¼Œå¹¶é‡‡ç”¨æ— åˆ†ç±»å™¨æŒ‡å¯¼çš„åå‘æ‰©æ•£ï¼Œæ ¹æ®åµŒå…¥ç©ºé—´ä¸­çš„æœ€è¿‘æ¬§å‡ é‡Œå¾—è·ç¦»å¯¹è¿™äº›å›¾åƒè¿›è¡Œè¿­ä»£ç»†åŒ–ä»¥è¿›è¡Œåˆ†ç±»ã€‚ConDiff çš„æœ‰æ•ˆæ€§è¡¨æ˜åœ¨æ”¹å–„ DFU ç®¡ç†æ–¹é¢å…·æœ‰æ˜¾ç€æ½œåŠ›ï¼Œå°¤å…¶æ˜¯åœ¨åŒ»ç–—èµ„æºæœ‰é™çš„åœ°åŒºã€‚å…¶ç²¾ç¡®çš„å®æ—¶æ„ŸæŸ“æ£€æµ‹å¯ä»¥åœ¨æ—©æœŸ DFU æ„ŸæŸ“è¯†åˆ«ä¸­å‘æŒ¥è‡³å…³é‡è¦çš„ä½œç”¨ï¼Œä»è€Œå‡å°‘è‚¢ä½“æˆªè‚¢ç­‰ä¸¥é‡å¹¶å‘ç—‡ã€‚</p>
<p>ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼šConDiff æ˜¯ç¬¬ä¸€ä¸ªåˆ†æç»†ç²’åº¦ä¼¤å£å›¾åƒçš„ç”Ÿæˆåˆ¤åˆ«æ–¹æ³•ï¼Œä¿ƒè¿›äº† DFU æ„ŸæŸ“çš„æ£€æµ‹ï¼›æ€§èƒ½ï¼šåœ¨ DFU æ„ŸæŸ“æ•°æ®é›†çš„çœ‹ä¸è§çš„æµ‹è¯•ä¼¤å£å›¾åƒï¼ˆ148 ä¸ªå—æ„ŸæŸ“å’Œ 103 ä¸ªæœªå—æ„ŸæŸ“ï¼‰ä¸Šè¿›è¡Œä¸¥æ ¼è¯„ä¼°ï¼ŒConDiff æ¡†æ¶æ˜æ˜¾ä¼˜äºæœ€å…ˆè¿›çš„åŸºçº¿ï¼Œæé«˜äº†ä¼¤å£æ„ŸæŸ“æ£€æµ‹çš„å‡†ç¡®æ€§å’Œ F1 åˆ†æ•°è‡³å°‘ 3%ï¼›å·¥ä½œé‡ï¼šé€šè¿‡åœ¨è®­ç»ƒæœŸé—´æœ€å°åŒ–ä¸‰å…ƒæŸå¤±å‡½æ•°ï¼ŒConDiff å‡å°‘äº†å¯¹ 1416 ä¸ªè®­ç»ƒå›¾åƒçš„å° DFU æ•°æ®é›†çš„è¿‡æ‹Ÿåˆã€‚</p>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-f38f851b08a13cd2762a9779abb3d5dd.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ac1698e3895c14a21d1245d61cbbe4db.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-902be7065fad826b29010fef3bd7e79b.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-d3d5d8c1286e3aefa0a37934906ae34f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a6a38755ae54c6bfd6a3359d2197b5a2.jpg" align="middle">
</details>




<h2 id="Obtaining-Favorable-Layouts-for-Multiple-Object-Generation"><a href="#Obtaining-Favorable-Layouts-for-Multiple-Object-Generation" class="headerlink" title="Obtaining Favorable Layouts for Multiple Object Generation"></a>Obtaining Favorable Layouts for Multiple Object Generation</h2><p><strong>Authors:Barak Battash, Amit Rozner, Lior Wolf, Ofir Lindenbaum</strong></p>
<p>Large-scale text-to-image models that can generate high-quality and diverse images based on textual prompts have shown remarkable success. These models aim ultimately to create complex scenes, and addressing the challenge of multi-subject generation is a critical step towards this goal. However, the existing state-of-the-art diffusion models face difficulty when generating images that involve multiple subjects. When presented with a prompt containing more than one subject, these models may omit some subjects or merge them together. To address this challenge, we propose a novel approach based on a guiding principle. We allow the diffusion model to initially propose a layout, and then we rearrange the layout grid. This is achieved by enforcing cross-attention maps (XAMs) to adhere to proposed masks and by migrating pixels from latent maps to new locations determined by us. We introduce new loss terms aimed at reducing XAM entropy for clearer spatial definition of subjects, reduce the overlap between XAMs, and ensure that XAMs align with their respective masks. We contrast our approach with several alternative methods and show that it more faithfully captures the desired concepts across a variety of text prompts. </p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2405.00791v1">PDF</a> </p>
<p><strong>Summary</strong><br>éšç€æ–‡æœ¬åˆ°å›¾åƒæ¨¡å‹çš„å¿«é€Ÿå‘å±•ï¼Œå¤šä¸»ä½“ç”Ÿæˆæˆä¸ºæ¨¡å‹å‘å±•çš„é‡è¦æ­¥éª¤ã€‚æœ¬ç ”ç©¶é’ˆå¯¹æ‰©æ•£æ¨¡å‹å¤šä¸»ä½“ç”Ÿæˆä¸­çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§é€šè¿‡å¼•å¯¼åŸåˆ™è¿›è¡Œå¸ƒå±€è§„åˆ’çš„æ–°æ–¹æ³•ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>æ‰©æ•£æ¨¡å‹åœ¨å¤šä¸»ä½“ç”Ÿæˆä¸­é¢ä¸´ç€é—æ¼æˆ–åˆå¹¶ä¸»ä½“çš„é—®é¢˜ã€‚</li>
<li>æœ¬ç ”ç©¶æå‡ºäº†ä¸€ç§åŸºäºå¼•å¯¼åŸåˆ™çš„å¸ƒå±€è§„åˆ’æ–¹æ³•ã€‚</li>
<li>è¯¥æ–¹æ³•å…è®¸æ‰©æ•£æ¨¡å‹åˆå§‹æå‡ºå¸ƒå±€ï¼Œç„¶åå¯¹å…¶è¿›è¡Œé‡æ–°æ’åˆ—ã€‚</li>
<li>å¼ºåˆ¶äº¤å‰æ³¨æ„åŠ›å›¾ï¼ˆXAMï¼‰éµå¾ªæå‡ºçš„é®ç½©ï¼Œå¹¶å°†æ½œåœ¨å›¾ä¸­çš„åƒç´ è¿ç§»åˆ°æ–°ä½ç½®ã€‚</li>
<li>å¼•å…¥äº†æ–°çš„æŸå¤±é¡¹ï¼Œä»¥å‡å°‘ XAM ç†µã€å‡å°‘ XAM ä¹‹é—´çš„é‡å å¹¶ç¡®ä¿ XAM ä¸å„è‡ªçš„é®ç½©å¯¹é½ã€‚</li>
<li>è¯¥æ–¹æ³•åœ¨å„ç§æ–‡æœ¬æç¤ºä¸­æ›´çœŸå®åœ°æ•æ‰åˆ°æ‰€éœ€æ¦‚å¿µã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>
<p>Title: è·å¾—å¤šä¸ªå¯¹è±¡ç”Ÿæˆçš„æœ‰åˆ©å¸ƒå±€</p>
</li>
<li>
<p>Authors: Barak Battash, Amit Rozner, Lior Wolf, Ofir Lindenbaum</p>
</li>
<li>
<p>Affiliation: å·´ä¼Šå…°å¤§å­¦å·¥ç¨‹å­¦é™¢</p>
</li>
<li>
<p>Keywords: æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆ, å¤šå¯¹è±¡ç”Ÿæˆ, æ‰©æ•£æ¨¡å‹, äº¤å‰æ³¨æ„åŠ›å›¾</p>
</li>
<li>
<p>Paper: https://arxiv.org/abs/2405.00791 , Github: None</p>
</li>
<li>
<p>Summary:</p>
<p>(1): å¤§è§„æ¨¡æ–‡æœ¬åˆ°å›¾åƒæ¨¡å‹åœ¨åŸºäºæ–‡æœ¬æç¤ºç”Ÿæˆé«˜è´¨é‡å’Œå¤šæ ·åŒ–å›¾åƒæ–¹é¢å–å¾—äº†æ˜¾è‘—æˆåŠŸã€‚è¿™äº›æ¨¡å‹æœ€ç»ˆæ—¨åœ¨åˆ›å»ºå¤æ‚çš„åœºæ™¯ï¼Œè§£å†³å¤šå¯¹è±¡ç”ŸæˆæŒ‘æˆ˜æ˜¯æœç€è¿™ä¸€ç›®æ ‡è¿ˆå‡ºçš„å…³é”®ä¸€æ­¥ã€‚ç„¶è€Œï¼Œç°æœ‰çš„æœ€å…ˆè¿›çš„æ‰©æ•£æ¨¡å‹åœ¨ç”Ÿæˆæ¶‰åŠå¤šä¸ªå¯¹è±¡çš„å›¾åƒæ—¶é¢ä¸´å›°éš¾ã€‚å½“ç»™å®šåŒ…å«å¤šä¸ªå¯¹è±¡çš„æç¤ºæ—¶ï¼Œè¿™äº›æ¨¡å‹å¯èƒ½ä¼šçœç•¥ä¸€äº›å¯¹è±¡æˆ–å°†å®ƒä»¬åˆå¹¶åœ¨ä¸€èµ·ã€‚</p>
<p>(2): ç°æœ‰çš„æ–¹æ³•åŒ…æ‹¬ï¼šä½¿ç”¨äº¤å‰æ³¨æ„åŠ›å›¾ï¼ˆXAMï¼‰å¯¹ç”Ÿæˆå›¾åƒä¸­çš„ä¸åŒå¯¹è±¡è¿›è¡Œå»ºæ¨¡ã€‚ç„¶è€Œï¼Œè¿™äº›æ–¹æ³•å­˜åœ¨é—®é¢˜ï¼šå½“æç¤ºä¸­åŒ…å«å¤šä¸ªå¯¹è±¡æ—¶ï¼Œæ¨¡å‹å¯èƒ½ä¼šçœç•¥ä¸€äº›å¯¹è±¡æˆ–å°†å®ƒä»¬åˆå¹¶åœ¨ä¸€èµ·ã€‚</p>
<p>(3): æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºæŒ‡å¯¼åŸåˆ™çš„æ–°æ–¹æ³•ã€‚æˆ‘ä»¬å…è®¸æ‰©æ•£æ¨¡å‹æœ€åˆæå‡ºä¸€ä¸ªå¸ƒå±€ï¼Œç„¶åé‡æ–°æ’åˆ—å¸ƒå±€ç½‘æ ¼ã€‚è¿™æ˜¯é€šè¿‡å¼ºåˆ¶äº¤å‰æ³¨æ„åŠ›å›¾ï¼ˆXAMï¼‰éµå®ˆæå‡ºçš„æ©ç å¹¶é€šè¿‡å°†åƒç´ ä»æ½œåœ¨å›¾è¿ç§»åˆ°æˆ‘ä»¬ç¡®å®šçš„æ–°ä½ç½®æ¥å®ç°çš„ã€‚æˆ‘ä»¬å¼•å…¥äº†æ–°çš„æŸå¤±é¡¹ï¼Œæ—¨åœ¨é™ä½ XAM ç†µä»¥æ›´æ¸…æ™°åœ°å®šä¹‰å¯¹è±¡çš„ç©ºé—´ï¼Œå‡å°‘ XAM ä¹‹é—´çš„é‡å ï¼Œå¹¶ç¡®ä¿ XAM ä¸å®ƒä»¬å„è‡ªçš„æ©ç å¯¹é½ã€‚</p>
<p>(4): æœ¬æ–‡æ–¹æ³•åœ¨å„ç§æ–‡æœ¬æç¤ºä¸­æ›´å¿ å®åœ°æ•æ‰åˆ°æ‰€éœ€çš„æ¦‚å¿µï¼Œè¯æ˜äº†å…¶æœ‰æ•ˆæ€§ã€‚</p>
</li>
<li>
<p>æ–¹æ³•ï¼š</p>
</li>
</ol>
<p>ï¼ˆ1ï¼‰ï¼šæå‡ºä¸€ç§åŸºäºæŒ‡å¯¼åŸåˆ™çš„æ–°æ–¹æ³•ï¼Œå…è®¸æ‰©æ•£æ¨¡å‹æœ€åˆæå‡ºä¸€ä¸ªå¸ƒå±€ï¼Œç„¶åé‡æ–°æ’åˆ—å¸ƒå±€ç½‘æ ¼ï¼›</p>
<p>ï¼ˆ2ï¼‰ï¼šé€šè¿‡å¼ºåˆ¶äº¤å‰æ³¨æ„åŠ›å›¾ï¼ˆXAMï¼‰éµå®ˆæå‡ºçš„æ©ç å¹¶é€šè¿‡å°†åƒç´ ä»æ½œåœ¨å›¾è¿ç§»åˆ°ç¡®å®šçš„æ–°ä½ç½®æ¥å®ç°ï¼›</p>
<p>ï¼ˆ3ï¼‰ï¼šå¼•å…¥æ–°çš„æŸå¤±é¡¹ï¼Œæ—¨åœ¨é™ä½ XAM ç†µä»¥æ›´æ¸…æ™°åœ°å®šä¹‰å¯¹è±¡çš„ç©ºé—´ï¼Œå‡å°‘ XAM ä¹‹é—´çš„é‡å ï¼Œå¹¶ç¡®ä¿ XAM ä¸å®ƒä»¬å„è‡ªçš„æ©ç å¯¹é½ï¼›</p>
<p>ï¼ˆ4ï¼‰ï¼šåœ¨å„ç§æ–‡æœ¬æç¤ºä¸­æ›´å¿ å®åœ°æ•æ‰åˆ°æ‰€éœ€çš„æ¦‚å¿µï¼Œè¯æ˜äº†å…¶æœ‰æ•ˆæ€§ã€‚</p>
<ol>
<li>ç»“è®ºï¼š</li>
</ol>
<p>ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºæŒ‡å¯¼åŸåˆ™çš„æ–°æ–¹æ³•ï¼Œè¯¥æ–¹æ³•å…è®¸æ‰©æ•£æ¨¡å‹æœ€åˆæå‡ºä¸€ä¸ªå¸ƒå±€ï¼Œç„¶åé‡æ–°æ’åˆ—å¸ƒå±€ç½‘æ ¼ï¼Œä»è€Œæ›´å¿ å®åœ°æ•æ‰åˆ°å„ç§æ–‡æœ¬æç¤ºä¸­æ‰€éœ€çš„æ¦‚å¿µï¼Œè¯æ˜äº†å…¶æœ‰æ•ˆæ€§ã€‚</p>
<p>ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼šæå‡ºäº†ä¸€ç§åŸºäºæŒ‡å¯¼åŸåˆ™çš„æ–°æ–¹æ³•ï¼Œè¯¥æ–¹æ³•å…è®¸æ‰©æ•£æ¨¡å‹æœ€åˆæå‡ºä¸€ä¸ªå¸ƒå±€ï¼Œç„¶åé‡æ–°æ’åˆ—å¸ƒå±€ç½‘æ ¼ã€‚
æ€§èƒ½ï¼šåœ¨å„ç§æ–‡æœ¬æç¤ºä¸­æ›´å¿ å®åœ°æ•æ‰åˆ°æ‰€éœ€çš„æ¦‚å¿µï¼Œè¯æ˜äº†å…¶æœ‰æ•ˆæ€§ã€‚
å·¥ä½œé‡ï¼šéœ€è¦é’ˆå¯¹ä¸åŒçš„æ–‡æœ¬æç¤ºè¿›è¡Œå¾®è°ƒï¼Œå·¥ä½œé‡è¾ƒå¤§ã€‚</p>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-d3231e3375af2b14c1e49248519eaebd.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-561eb2e3b9534e1fe4b30e7ef897a8b3.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c2973412c6cc5c19507315dc2dd5efcd.jpg" align="middle">
</details>




<h2 id="Deep-Reward-Supervisions-for-Tuning-Text-to-Image-Diffusion-Models"><a href="#Deep-Reward-Supervisions-for-Tuning-Text-to-Image-Diffusion-Models" class="headerlink" title="Deep Reward Supervisions for Tuning Text-to-Image Diffusion Models"></a>Deep Reward Supervisions for Tuning Text-to-Image Diffusion Models</h2><p><strong>Authors:Xiaoshi Wu, Yiming Hao, Manyuan Zhang, Keqiang Sun, Zhaoyang Huang, Guanglu Song, Yu Liu, Hongsheng Li</strong></p>
<p>Optimizing a text-to-image diffusion model with a given reward function is an important but underexplored research area. In this study, we propose Deep Reward Tuning (DRTune), an algorithm that directly supervises the final output image of a text-to-image diffusion model and back-propagates through the iterative sampling process to the input noise. We find that training earlier steps in the sampling process is crucial for low-level rewards, and deep supervision can be achieved efficiently and effectively by stopping the gradient of the denoising network input. DRTune is extensively evaluated on various reward models. It consistently outperforms other algorithms, particularly for low-level control signals, where all shallow supervision methods fail. Additionally, we fine-tune Stable Diffusion XL 1.0 (SDXL 1.0) model via DRTune to optimize Human Preference Score v2.1, resulting in the Favorable Diffusion XL 1.0 (FDXL 1.0) model. FDXL 1.0 significantly enhances image quality compared to SDXL 1.0 and reaches comparable quality compared with Midjourney v5.2. </p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2405.00760v1">PDF</a> N&#x2F;A</p>
<p><strong>Summary</strong><br>æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹ä¸­ï¼Œåˆ©ç”¨ç»™å®šçš„æ¿€åŠ±å‡½æ•°è¿›è¡Œä¼˜åŒ–æ˜¯ä¸€ä¸ªé‡è¦ä½†æœªå¾—åˆ°å……åˆ†æ¢ç´¢çš„ç ”ç©¶é¢†åŸŸã€‚ç ”ç©¶ä¸­æå‡ºæ·±åº¦æ¿€åŠ±ä¼˜åŒ–ï¼ˆDRTuneï¼‰ï¼Œç®—æ³•ç›´æ¥ç›‘ç£æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹çš„æœ€ç»ˆè¾“å‡ºå›¾åƒï¼Œå¹¶ä¸”é€šè¿‡è¿­ä»£é‡‡æ ·æµç¨‹å°†æ¢¯åº¦ä¼ å›è¾“å…¥å™ªå£°ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>é’ˆå¯¹ä½å±‚æ¿€åŠ±ï¼Œè®­ç»ƒé‡‡æ ·æµç¨‹ä¸­çš„æ—©æœŸæ­¥éª¤è‡³å…³é‡è¦ã€‚</li>
<li>åœ¨å»å™ªç½‘ç»œè¾“å…¥å¤„åœæ­¢æ¢¯åº¦ï¼Œå¯ä»¥æœ‰æ•ˆå®ç°æ·±åº¦ç›‘ç£ã€‚</li>
<li>DRTune ç®—æ³•åœ¨å„ç§æ¿€åŠ±æ¨¡å‹ä¸Šå¾—åˆ°äº†å¹¿æ³›è¯„ä¼°ã€‚</li>
<li>DRTune ç®—æ³•å§‹ç»ˆä¼˜äºå…¶ä»–ç®—æ³•ï¼Œå°¤å…¶æ˜¯åœ¨æµ…å±‚ç›‘ç£æ–¹æ³•å¤±æ•ˆçš„ä½å±‚æ§åˆ¶ä¿¡å·ä¸­ã€‚</li>
<li>é€šè¿‡ DRTune ä¼˜åŒ– Human Preference Score v2.1ï¼Œå¯¹ Stable Diffusion XL 1.0ï¼ˆSDXL 1.0ï¼‰æ¨¡å‹è¿›è¡Œå¾®è°ƒï¼Œäº§ç”Ÿäº†æ›´å¥½çš„æ‰©æ•£ XL 1.0ï¼ˆFDXL 1.0ï¼‰æ¨¡å‹ã€‚</li>
<li>FDXL 1.0 ä¸ Midjourney v5.2 ç›¸æ¯”ï¼Œæ˜¾è‘—æé«˜äº†å›¾åƒè´¨é‡ï¼Œè¾¾åˆ°äº†ç›¸å½“çš„æ°´å¹³ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>
<p>æ ‡é¢˜ï¼šæ·±åº¦å¥–åŠ±ç›‘ç£å¾®è°ƒ</p>
</li>
<li>
<p>ä½œè€…ï¼šXiaoshi Wu<em>1,3, Yiming Hao</em>2, Manyuan Zhang1, Keqiang Sun1, Zhaoyang Huang3, Guanglu Song4, Yu Liu4, and Hongsheng Li1,2</p>
</li>
<li>
<p>ç¬¬ä¸€ä½œè€…å•ä½ï¼šé¦™æ¸¯ä¸­æ–‡å¤§å­¦å¤šåª’ä½“å®éªŒå®¤</p>
</li>
<li>
<p>å…³é”®è¯ï¼šæ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹ã€æ·±åº¦å¥–åŠ±ç›‘ç£ã€å¾®è°ƒã€å›¾åƒè´¨é‡å¢å¼º</p>
</li>
<li>
<p>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2405.00760v1</p>
</li>
<li>
<p>æ‘˜è¦ï¼š</p>
</li>
</ol>
<p>(1)ï¼šç ”ç©¶èƒŒæ™¯ï¼šä¼˜åŒ–å…·æœ‰ç»™å®šå¥–åŠ±å‡½æ•°çš„æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹æ˜¯ä¸€ä¸ªé‡è¦ä½†å°šæœªå……åˆ†æ¢ç´¢çš„ç ”ç©¶é¢†åŸŸã€‚</p>
<p>(2)ï¼šè¿‡å»æ–¹æ³•ï¼šç°æœ‰æ–¹æ³•é€šå¸¸é‡‡ç”¨æµ…å±‚ç›‘ç£ï¼Œå³ä»…ç›‘ç£é‡‡æ ·è¿‡ç¨‹çš„æ—©æœŸæ­¥éª¤ã€‚ç„¶è€Œï¼Œå¯¹äºä½çº§å¥–åŠ±ä¿¡å·ï¼Œæµ…å±‚ç›‘ç£æ•ˆæœä¸ä½³ã€‚</p>
<p>(3)ï¼šæœ¬æ–‡æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºæ·±åº¦å¥–åŠ±å¾®è°ƒï¼ˆDRTuneï¼‰ç®—æ³•ï¼Œé€šè¿‡ç›´æ¥ç›‘ç£æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹çš„æœ€ç»ˆè¾“å‡ºå›¾åƒå¹¶é€šè¿‡è¿­ä»£é‡‡æ ·è¿‡ç¨‹åå‘ä¼ æ’­åˆ°è¾“å…¥å™ªå£°æ¥å®ç°æ·±åº¦ç›‘ç£ã€‚</p>
<p>(4)ï¼šæ–¹æ³•æ€§èƒ½ï¼šDRTuneåœ¨å„ç§å¥–åŠ±æ¨¡å‹ä¸Šå¾—åˆ°äº†å¹¿æ³›è¯„ä¼°ã€‚ä¸å…¶ä»–ç®—æ³•ç›¸æ¯”ï¼Œå®ƒå§‹ç»ˆè¡¨ç°å‡ºæ›´å¥½çš„æ€§èƒ½ï¼Œå°¤å…¶æ˜¯åœ¨æµ…å±‚ç›‘ç£æ–¹æ³•å‡å¤±è´¥çš„ä½çº§æ§åˆ¶ä¿¡å·æ–¹é¢ã€‚æ­¤å¤–ï¼Œæœ¬æ–‡ä½¿ç”¨DRTuneå¾®è°ƒäº†Stable Diffusion XL 1.0ï¼ˆSDXL 1.0ï¼‰æ¨¡å‹ä»¥ä¼˜åŒ–äººç±»åå¥½è¯„åˆ†v2.1ï¼Œå¾—åˆ°äº†Favorable Diffusion XL 1.0ï¼ˆFDXL 1.0ï¼‰æ¨¡å‹ã€‚ä¸SDXL 1.0ç›¸æ¯”ï¼ŒFDXL 1.0æ˜¾ç€æé«˜äº†å›¾åƒè´¨é‡ï¼Œå¹¶ä¸”ä¸Midjourney v5.2ç›¸æ¯”è¾¾åˆ°äº†ç›¸å½“çš„è´¨é‡ã€‚</p>
<ol>
<li>æ–¹æ³•ï¼š</li>
</ol>
<p>ï¼ˆ1ï¼‰ï¼šDRTune ç®—æ³•çš„æ ¸å¿ƒæ€æƒ³æ˜¯é€šè¿‡ç›´æ¥ç›‘ç£æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹çš„æœ€ç»ˆè¾“å‡ºå›¾åƒï¼Œå¹¶é€šè¿‡è¿­ä»£é‡‡æ ·è¿‡ç¨‹åå‘ä¼ æ’­åˆ°è¾“å…¥å™ªå£°æ¥å®ç°æ·±åº¦ç›‘ç£ï¼›</p>
<p>ï¼ˆ2ï¼‰ï¼šä¸ºäº†è§£å†³æ¢¯åº¦çˆ†ç‚¸é—®é¢˜ï¼ŒDRTune é€šè¿‡é˜»æ­¢è¾“å…¥ xt çš„æ¢¯åº¦æ¥è§£å†³æ”¶æ•›é—®é¢˜ï¼›</p>
<p>ï¼ˆ3ï¼‰ï¼šä¸ºäº†æé«˜æ•ˆç‡ï¼ŒDRTune é˜»æ­¢è¾“å…¥ xt çš„æ¢¯åº¦ï¼Œå¹¶è®­ç»ƒæ‰€æœ‰é‡‡æ ·æ­¥éª¤çš„å­é›†ï¼›</p>
<p>ï¼ˆ4ï¼‰ï¼šDRTune ç®—æ³•çš„ä¼ªä»£ç å¦‚ä¸‹ï¼š</p>
<p><code>è¾“å…¥ï¼šé¢„è®­ç»ƒçš„æ‰©æ•£æ¨¡å‹æƒé‡ Î¸ã€å¥–åŠ± rã€è®­ç»ƒæ—¶é—´æ­¥é•¿ Kã€æ—©æœŸåœæ­¢æ—¶é—´æ­¥é•¿èŒƒå›´ mã€‚sg è¡¨ç¤ºæ¢¯åº¦åœæ­¢æ“ä½œã€‚
while not converged do
    ttrain = &#123;1, ..., K&#125; if DRaFT-K
    ttrain = &#123;i&#125;iâ‰¥randint(1,T ) if AlignProp
    if DRTune then
        # ç­‰è·æ—¶é—´æ­¥é•¿ã€‚
        s = randint(1, T âˆ’ KâŒŠ T K âŒ‹)
        ttrain = &#123;s + iâŒŠ T K âŒ‹ | i = 0, 1, ..., K âˆ’ 1&#125;
    if ReFL æˆ– DRTune then
        tmin = randint(1, m)
    else
        tmin = 0
    xT âˆ¼ N(0, I)
    for t = T, ..., 1 do
        if DRTune then
            Ë†Ïµ = ÏµÎ¸(sg(xt), t)
        else
            Ë†Ïµ = ÏµÎ¸(xt, t)
        if t /âˆˆ ttrain then
            Ë†Ïµ = sg(Ë†Ïµ)
        if t == tmin then
            x0 â‰ˆ intermediate_prediction(xt, Ë†Ïµ)
            break
        xtâˆ’1 = atxt + btË†Ïµ + ctÏµ
        g = âˆ‡Î¸r(x0, c)
        Î¸ â† Î¸ âˆ’ Î·g</code></p>
<ol>
<li>ç»“è®ºï¼š</li>
</ol>
<p>ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡çš„æ„ä¹‰åœ¨äºï¼Œå®ƒè§£å†³äº†åˆ©ç”¨å¥–åŠ±æ¨¡å‹çš„åé¦ˆæ¥è®­ç»ƒæ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹çš„æŒ‘æˆ˜ã€‚æœ¬æ–‡å¼ºè°ƒäº†æ·±åº¦ç›‘ç£å¯¹äºä¼˜åŒ–å…¨å±€å¥–åŠ±çš„é‡è¦æ€§ï¼Œå¹¶ä½¿ç”¨åœæ­¢æ¢¯åº¦æŠ€æœ¯è§£å†³äº†æ”¶æ•›é—®é¢˜ã€‚æ­¤å¤–ï¼Œæœ¬æ–‡é€šè¿‡å¾®è°ƒ FDXL 1.0 æ¨¡å‹å±•ç¤ºäº†å¥–åŠ±è®­ç»ƒçš„æ½œåŠ›ï¼Œä»¥å®ç°ä¸ Midjourney ç›¸å½“çš„å›¾åƒè´¨é‡ã€‚</p>
<p>ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼šæœ¬æ–‡æå‡ºäº†æ·±åº¦å¥–åŠ±å¾®è°ƒï¼ˆDRTuneï¼‰ç®—æ³•ï¼Œå®ç°äº†æ·±åº¦ç›‘ç£ï¼Œå¹¶é€šè¿‡é˜»æ­¢è¾“å…¥ xt çš„æ¢¯åº¦æ¥è§£å†³æ”¶æ•›é—®é¢˜ã€‚
æ€§èƒ½ï¼šDRTune åœ¨å„ç§å¥–åŠ±æ¨¡å‹ä¸Šå¾—åˆ°äº†å¹¿æ³›è¯„ä¼°ï¼Œä¸å…¶ä»–ç®—æ³•ç›¸æ¯”ï¼Œå®ƒå§‹ç»ˆè¡¨ç°å‡ºæ›´å¥½çš„æ€§èƒ½ï¼Œå°¤å…¶æ˜¯åœ¨æµ…å±‚ç›‘ç£æ–¹æ³•å‡å¤±è´¥çš„ä½çº§æ§åˆ¶ä¿¡å·æ–¹é¢ã€‚
å·¥ä½œé‡ï¼šDRTune ç®—æ³•çš„å®ç°ç›¸å¯¹ç®€å•ï¼Œå¹¶ä¸”å¯ä»¥è½»æ¾åº”ç”¨äºç°æœ‰çš„æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹ã€‚</p>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-037d3e48be185336859047a6292c8d27.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-9b417340b0b4ae8f5dcc966e5d18466d.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-d9661ec54a3560470071969dc361ea74.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-560c3c936da4c7000b08d87c1704852f.jpg" align="middle">
</details>




<h2 id="Detail-Enhancing-Framework-for-Reference-Based-Image-Super-Resolution"><a href="#Detail-Enhancing-Framework-for-Reference-Based-Image-Super-Resolution" class="headerlink" title="Detail-Enhancing Framework for Reference-Based Image Super-Resolution"></a>Detail-Enhancing Framework for Reference-Based Image Super-Resolution</h2><p><strong>Authors:Zihan Wang, Ziliang Xiong, Hongying Tang, Xiaobing Yuan</strong></p>
<p>Recent years have witnessed the prosperity of reference-based image super-resolution (Ref-SR). By importing the high-resolution (HR) reference images into the single image super-resolution (SISR) approach, the ill-posed nature of this long-standing field has been alleviated with the assistance of texture transferred from reference images. Although the significant improvement in quantitative and qualitative results has verified the superiority of Ref-SR methods, the presence of misalignment before texture transfer indicates room for further performance improvement. Existing methods tend to neglect the significance of details in the context of comparison, therefore not fully leveraging the information contained within low-resolution (LR) images. In this paper, we propose a Detail-Enhancing Framework (DEF) for reference-based super-resolution, which introduces the diffusion model to generate and enhance the underlying detail in LR images. If corresponding parts are present in the reference image, our method can facilitate rigorous alignment. In cases where the reference image lacks corresponding parts, it ensures a fundamental improvement while avoiding the influence of the reference image. Extensive experiments demonstrate that our proposed method achieves superior visual results while maintaining comparable numerical outcomes. </p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2405.00431v1">PDF</a> </p>
<p><strong>Summary</strong><br>å¼•ç”¨å›¾åƒè¶…åˆ†è¾¨é€šè¿‡å¼•å…¥é«˜åˆ†è¾¨ç‡å‚è€ƒå›¾åƒæ¥ç¼“è§£å•å›¾åƒè¶…åˆ†è¾¨çš„ç—…æ€é—®é¢˜ï¼Œä½†ç”±äºçº¹ç†ä¼ è¾“å‰å­˜åœ¨é”™ä½é—®é¢˜ï¼Œä»æœ‰æå‡ç©ºé—´ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>å¼•ç”¨å›¾åƒè¶…åˆ†è¾¨æ–¹æ³•åœ¨å®šé‡å’Œå®šæ€§ç»“æœä¸Šå‡æœ‰æ˜¾è‘—æå‡ã€‚</li>
<li>ç°æœ‰æ–¹æ³•å¿½è§†äº†æ¯”è¾ƒä¸­ç»†èŠ‚çš„é‡è¦æ€§ï¼Œæ²¡æœ‰å……åˆ†åˆ©ç”¨ä½åˆ†è¾¨ç‡å›¾åƒä¸­çš„ä¿¡æ¯ã€‚</li>
<li>æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºæ‰©æ•£æ¨¡å‹çš„ç»†èŠ‚å¢å¼ºæ¡†æ¶ï¼Œç”¨äºå¼•ç”¨å›¾åƒè¶…åˆ†è¾¨ã€‚</li>
<li>å¦‚æœå‚è€ƒå›¾åƒä¸­å­˜åœ¨å¯¹åº”éƒ¨åˆ†ï¼Œè¯¥æ–¹æ³•å¯ä»¥ä¿ƒè¿›ä¸¥æ ¼çš„å¯¹é½ã€‚</li>
<li>å¦‚æœå‚è€ƒå›¾åƒæ²¡æœ‰å¯¹åº”éƒ¨åˆ†ï¼Œè¯¥æ–¹æ³•å¯ä»¥ç¡®ä¿åŸºæœ¬æ”¹è¿›ï¼ŒåŒæ—¶é¿å…å‚è€ƒå›¾åƒçš„å½±å“ã€‚</li>
<li>å¤§é‡å®éªŒè¡¨æ˜ï¼Œæ‰€æå‡ºçš„æ–¹æ³•åœ¨ä¿æŒå¯æ¯”æ•°å€¼ç»“æœçš„åŒæ—¶ï¼Œè·å¾—äº†æ›´å¥½çš„è§†è§‰æ•ˆæœã€‚</li>
<li>è¯¥æ–¹æ³•èƒ½å¤Ÿåœ¨æ²¡æœ‰å¯¹åº”å‚è€ƒå›¾åƒçš„æƒ…å†µä¸‹æé«˜è¶…åˆ†è¾¨ç‡æ€§èƒ½ã€‚</li>
<li>è¯¥æ–¹æ³•å¯ä»¥çµæ´»åœ°åº”ç”¨äºå„ç§å¼•ç”¨å›¾åƒè¶…åˆ†è¾¨ä»»åŠ¡ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>
<p>è®ºæ–‡æ ‡é¢˜ï¼šåŸºäºå‚è€ƒå›¾åƒçš„å›¾åƒè¶…åˆ†è¾¨ç‡çš„ç»†èŠ‚å¢å¼ºæ¡†æ¶</p>
</li>
<li>
<p>ä½œè€…ï¼šZihan Wang, Ziliang Xiong, Hongying Tang, Xiaobing Yuan</p>
</li>
<li>
<p>ç¬¬ä¸€ä½œè€…å•ä½ï¼šä¸Šæµ·å¾®ç³»ç»Ÿä¸ä¿¡æ¯æŠ€æœ¯ç ”ç©¶æ‰€</p>
</li>
<li>
<p>å…³é”®è¯ï¼šå›¾åƒè¶…åˆ†è¾¨ç‡ï¼Œå‚è€ƒå›¾åƒï¼Œç»†èŠ‚å¢å¼ºï¼Œæ‰©æ•£æ¨¡å‹</p>
</li>
<li>
<p>è®ºæ–‡é“¾æ¥ï¼šxxxï¼ŒGithub ä»£ç é“¾æ¥ï¼šNone</p>
</li>
<li>
<p>æ‘˜è¦ï¼š</p>
<p>ï¼ˆ1ï¼‰ï¼šè¿‘å¹´æ¥ï¼ŒåŸºäºå‚è€ƒå›¾åƒçš„å›¾åƒè¶…åˆ†è¾¨ç‡ï¼ˆRef-SRï¼‰å¾—åˆ°äº†è“¬å‹ƒå‘å±•ã€‚é€šè¿‡å°†é«˜åˆ†è¾¨ç‡ï¼ˆHRï¼‰å‚è€ƒå›¾åƒå¼•å…¥åˆ°å•å¹…å›¾åƒè¶…åˆ†è¾¨ç‡ï¼ˆSISRï¼‰æ–¹æ³•ä¸­ï¼Œåœ¨å‚è€ƒå›¾åƒçº¹ç†çš„è¾…åŠ©ä¸‹ï¼Œç¼“è§£äº†è¿™ä¸€é•¿æœŸå­˜åœ¨çš„é¢†åŸŸçš„ç—…æ€æ€§è´¨ã€‚å°½ç®¡å®šé‡å’Œå®šæ€§ç»“æœçš„æ˜¾ç€æé«˜éªŒè¯äº† Ref-SR æ–¹æ³•çš„ä¼˜è¶Šæ€§ï¼Œä½†åœ¨çº¹ç†ä¼ è¾“ä¹‹å‰å­˜åœ¨çš„é”™ä½è¡¨æ˜è¿˜æœ‰è¿›ä¸€æ­¥æé«˜æ€§èƒ½çš„ç©ºé—´ã€‚ç°æœ‰çš„æ–¹æ³•å¾€å¾€å¿½ç•¥äº†æ¯”è¾ƒèƒŒæ™¯ä¸‹ç»†èŠ‚çš„é‡è¦æ€§ï¼Œå› æ­¤æ²¡æœ‰å……åˆ†åˆ©ç”¨ä½åˆ†è¾¨ç‡ï¼ˆLRï¼‰å›¾åƒä¸­åŒ…å«çš„ä¿¡æ¯ã€‚</p>
<p>ï¼ˆ2ï¼‰ï¼šè¿‡å»çš„æ–¹æ³•å€¾å‘äºç®€å•åœ°å°†è¾“å…¥çš„ LR å›¾åƒè°ƒæ•´ä¸ºä¸ç›¸åº”å‚è€ƒå›¾åƒç›¸åŒçš„åˆ†è¾¨ç‡ï¼Œä¾‹å¦‚åŒä¸‰æ¬¡æ’å€¼ã€‚Lu ç­‰äººé€‰æ‹©å¯¹å‚è€ƒå›¾åƒè¿›è¡Œä¸‹é‡‡æ ·ä»¥é€‚åº”åŒ¹é…è¿‡ç¨‹ï¼Œç›®çš„æ˜¯é™ä½è®¡ç®—å¤æ‚åº¦ã€‚è™½ç„¶è¿™ç§æ–¹æ³•å¯ä»¥åœ¨ä¸€å®šç¨‹åº¦ä¸Šç¼“è§£é”™ä½é—®é¢˜ï¼Œä½†å®ƒå¿½ç•¥äº†ç»†èŠ‚çš„å¢å¼ºï¼Œå¯èƒ½ä¼šç ´ååç»­çš„å›¾åƒæ¢å¤ç»“æœã€‚åœ¨å‚è€ƒå›¾åƒä¸­å­˜åœ¨å¯¹åº”éƒ¨åˆ†çš„æƒ…å†µä¸‹ï¼Œç°æœ‰çš„æ–¹æ³•æ— æ³•ä¿ƒè¿›ä¸¥æ ¼çš„å¯¹é½ã€‚</p>
<p>ï¼ˆ3ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºå‚è€ƒå›¾åƒçš„è¶…åˆ†è¾¨ç‡ç»†èŠ‚å¢å¼ºæ¡†æ¶ï¼ˆDEFï¼‰ï¼Œå®ƒå¼•å…¥äº†æ‰©æ•£æ¨¡å‹æ¥ç”Ÿæˆå’Œå¢å¼º LR å›¾åƒä¸­çš„åº•å±‚ç»†èŠ‚ã€‚å¦‚æœå‚è€ƒå›¾åƒä¸­å­˜åœ¨å¯¹åº”éƒ¨åˆ†ï¼Œæˆ‘ä»¬çš„æ–¹æ³•å¯ä»¥ä¿ƒè¿›ä¸¥æ ¼çš„å¯¹é½ã€‚åœ¨å‚è€ƒå›¾åƒä¸­ç¼ºå°‘å¯¹åº”éƒ¨åˆ†çš„æƒ…å†µä¸‹ï¼Œå®ƒç¡®ä¿äº†æ ¹æœ¬æ€§çš„æ”¹è¿›ï¼ŒåŒæ—¶é¿å…äº†å‚è€ƒå›¾åƒçš„å½±å“ã€‚</p>
<p>ï¼ˆ4ï¼‰ï¼šåœ¨å›¾åƒè¶…åˆ†è¾¨ç‡ä»»åŠ¡ä¸Šï¼Œæœ¬æ–‡æ–¹æ³•å–å¾—äº†ä¼˜å¼‚çš„è§†è§‰æ•ˆæœï¼ŒåŒæ—¶ä¿æŒäº†å¯æ¯”çš„æ•°å€¼ç»“æœã€‚è¿™äº›æ€§èƒ½æ”¯æŒäº†ä»–ä»¬çš„ç›®æ ‡ã€‚</p>
</li>
<li>
<p>æ–¹æ³•ï¼š</p>
</li>
</ol>
<p>ï¼ˆ1ï¼‰ï¼šæå‡ºäº†ä¸€ç§åŸºäºå‚è€ƒå›¾åƒçš„è¶…åˆ†è¾¨ç‡ç»†èŠ‚å¢å¼ºæ¡†æ¶ï¼ˆDEFï¼‰ï¼Œå®ƒå¼•å…¥äº†æ‰©æ•£æ¨¡å‹æ¥ç”Ÿæˆå’Œå¢å¼º LR å›¾åƒä¸­çš„åº•å±‚ç»†èŠ‚ã€‚</p>
<p>ï¼ˆ2ï¼‰ï¼šè¯¥æ–¹æ³•å°†å›¾åƒè¶…åˆ†è¾¨ç‡ä»»åŠ¡åˆ†è§£ä¸ºä¸¤ä¸ªå­ä»»åŠ¡ï¼šç»†èŠ‚ç”Ÿæˆå’Œç»†èŠ‚è¿ç§»ã€‚</p>
<p>ï¼ˆ3ï¼‰ï¼šåœ¨ç»†èŠ‚ç”Ÿæˆä»»åŠ¡ä¸­ï¼Œä½¿ç”¨é¢„è®­ç»ƒçš„æ‰©æ•£æ¨¡å‹å¯¹è¾“å…¥å›¾åƒè¿›è¡Œä¸Šé‡‡æ ·ï¼Œä»¥è·å¾—ç»†èŠ‚å¢å¼ºçš„è¾“å…¥å›¾åƒã€‚</p>
<p>ï¼ˆ4ï¼‰ï¼šåœ¨ç»†èŠ‚è¿ç§»ä»»åŠ¡ä¸­ï¼Œé¦–å…ˆå¯¹ç»†èŠ‚å¢å¼ºçš„å›¾åƒå’Œå‚è€ƒå›¾åƒè¿›è¡Œç‰¹å¾æå–ã€‚</p>
<p>ï¼ˆ5ï¼‰ï¼šåˆ©ç”¨ç»†èŠ‚å¢å¼ºçš„è¾“å…¥å›¾åƒæ¥è®¡ç®—å‚è€ƒå›¾åƒå’Œè¾“å…¥å›¾åƒä¹‹é—´çš„ç›¸ä¼¼æ€§ã€‚</p>
<p>ï¼ˆ6ï¼‰ï¼šä½¿ç”¨ deformable convolution networkï¼ˆDCNï¼‰è¿›è¡Œçº¹ç†è¿ç§»å’Œé›†æˆï¼Œä»¥è§£å†³çº¹ç†å¤±é…é—®é¢˜ã€‚</p>
<ol>
<li>ç»“è®ºï¼š</li>
</ol>
<p>ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºå‚è€ƒå›¾åƒçš„è¶…åˆ†è¾¨ç‡ç»†èŠ‚å¢å¼ºæ¡†æ¶ï¼ˆDEFï¼‰ï¼Œè¯¥æ¡†æ¶å¼•å…¥äº†æ‰©æ•£æ¨¡å‹æ¥ç”Ÿæˆå’Œå¢å¼ºä½åˆ†è¾¨ç‡å›¾åƒä¸­çš„åº•å±‚ç»†èŠ‚ã€‚è¯¥æ–¹æ³•å°†å›¾åƒè¶…åˆ†è¾¨ç‡ä»»åŠ¡åˆ†è§£ä¸ºä¸¤ä¸ªå­ä»»åŠ¡ï¼šç»†èŠ‚ç”Ÿæˆå’Œç»†èŠ‚è¿ç§»ã€‚åœ¨ç»†èŠ‚ç”Ÿæˆä»»åŠ¡ä¸­ï¼Œä½¿ç”¨é¢„è®­ç»ƒçš„æ‰©æ•£æ¨¡å‹å¯¹è¾“å…¥å›¾åƒè¿›è¡Œä¸Šé‡‡æ ·ï¼Œä»¥è·å¾—ç»†èŠ‚å¢å¼ºçš„è¾“å…¥å›¾åƒã€‚åœ¨ç»†èŠ‚è¿ç§»ä»»åŠ¡ä¸­ï¼Œé¦–å…ˆå¯¹ç»†èŠ‚å¢å¼ºçš„å›¾åƒå’Œå‚è€ƒå›¾åƒè¿›è¡Œç‰¹å¾æå–ã€‚åˆ©ç”¨ç»†èŠ‚å¢å¼ºçš„è¾“å…¥å›¾åƒæ¥è®¡ç®—å‚è€ƒå›¾åƒå’Œè¾“å…¥å›¾åƒä¹‹é—´çš„ç›¸ä¼¼æ€§ã€‚ä½¿ç”¨å¯å˜å½¢å·ç§¯ç½‘ç»œï¼ˆDCNï¼‰è¿›è¡Œçº¹ç†è¿ç§»å’Œé›†æˆï¼Œä»¥è§£å†³çº¹ç†å¤±é…é—®é¢˜ã€‚</p>
<p>ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼šæå‡ºäº†ä¸€ç§åŸºäºå‚è€ƒå›¾åƒçš„è¶…åˆ†è¾¨ç‡ç»†èŠ‚å¢å¼ºæ¡†æ¶ï¼ˆDEFï¼‰ï¼Œè¯¥æ¡†æ¶åˆ©ç”¨æ‰©æ•£æ¨¡å‹ç”Ÿæˆå’Œå¢å¼ºä½åˆ†è¾¨ç‡å›¾åƒä¸­çš„åº•å±‚ç»†èŠ‚ã€‚è¯¥æ–¹æ³•å°†å›¾åƒè¶…åˆ†è¾¨ç‡ä»»åŠ¡åˆ†è§£ä¸ºä¸¤ä¸ªå­ä»»åŠ¡ï¼šç»†èŠ‚ç”Ÿæˆå’Œç»†èŠ‚è¿ç§»ã€‚åœ¨ç»†èŠ‚ç”Ÿæˆä»»åŠ¡ä¸­ï¼Œä½¿ç”¨é¢„è®­ç»ƒçš„æ‰©æ•£æ¨¡å‹å¯¹è¾“å…¥å›¾åƒè¿›è¡Œä¸Šé‡‡æ ·ï¼Œä»¥è·å¾—ç»†èŠ‚å¢å¼ºçš„è¾“å…¥å›¾åƒã€‚åœ¨ç»†èŠ‚è¿ç§»ä»»åŠ¡ä¸­ï¼Œé¦–å…ˆå¯¹ç»†èŠ‚å¢å¼ºçš„å›¾åƒå’Œå‚è€ƒå›¾åƒè¿›è¡Œç‰¹å¾æå–ã€‚åˆ©ç”¨ç»†èŠ‚å¢å¼ºçš„è¾“å…¥å›¾åƒæ¥è®¡ç®—å‚è€ƒå›¾åƒå’Œè¾“å…¥å›¾åƒä¹‹é—´çš„ç›¸ä¼¼æ€§ã€‚ä½¿ç”¨å¯å˜å½¢å·ç§¯ç½‘ç»œï¼ˆDCNï¼‰è¿›è¡Œçº¹ç†è¿ç§»å’Œé›†æˆï¼Œä»¥è§£å†³çº¹ç†å¤±é…é—®é¢˜ã€‚
æ€§èƒ½ï¼šè¯¥æ–¹æ³•åœ¨å›¾åƒè¶…åˆ†è¾¨ç‡ä»»åŠ¡ä¸Šå–å¾—äº†ä¼˜å¼‚çš„è§†è§‰æ•ˆæœï¼ŒåŒæ—¶ä¿æŒäº†å¯æ¯”çš„æ•°å€¼ç»“æœã€‚è¿™äº›æ€§èƒ½æ”¯æŒäº†ä»–ä»¬çš„ç›®æ ‡ã€‚
å·¥ä½œé‡ï¼šè¯¥æ–¹æ³•çš„å®ç°ç›¸å¯¹å¤æ‚ï¼Œéœ€è¦ä½¿ç”¨é¢„è®­ç»ƒçš„æ‰©æ•£æ¨¡å‹å’Œå¯å˜å½¢å·ç§¯ç½‘ç»œã€‚</p>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-03b9463baa117efca1717d3d158fe273.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-c3af50396285ae462ddd151feecf5dad.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-9a59353ef4d615d00935a00b86d496d8.jpg" align="middle">
</details>




<h2 id="ASAM-Boosting-Segment-Anything-Model-with-Adversarial-Tuning"><a href="#ASAM-Boosting-Segment-Anything-Model-with-Adversarial-Tuning" class="headerlink" title="ASAM: Boosting Segment Anything Model with Adversarial Tuning"></a>ASAM: Boosting Segment Anything Model with Adversarial Tuning</h2><p><strong>Authors:Bo Li, Haoke Xiao, Lv Tang</strong></p>
<p>In the evolving landscape of computer vision, foundation models have emerged as pivotal tools, exhibiting exceptional adaptability to a myriad of tasks. Among these, the Segment Anything Model (SAM) by Meta AI has distinguished itself in image segmentation. However, SAM, like its counterparts, encounters limitations in specific niche applications, prompting a quest for enhancement strategies that do not compromise its inherent capabilities. This paper introduces ASAM, a novel methodology that amplifies SAMâ€™s performance through adversarial tuning. We harness the potential of natural adversarial examples, inspired by their successful implementation in natural language processing. By utilizing a stable diffusion model, we augment a subset (1%) of the SA-1B dataset, generating adversarial instances that are more representative of natural variations rather than conventional imperceptible perturbations. Our approach maintains the photorealism of adversarial examples and ensures alignment with original mask annotations, thereby preserving the integrity of the segmentation task. The fine-tuned ASAM demonstrates significant improvements across a diverse range of segmentation tasks without necessitating additional data or architectural modifications. The results of our extensive evaluations confirm that ASAM establishes new benchmarks in segmentation tasks, thereby contributing to the advancement of foundational models in computer vision. Our project page is in <a target="_blank" rel="noopener" href="https://asam2024.github.io/">https://asam2024.github.io/</a>. </p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2405.00256v1">PDF</a> This paper is accepted by CVPR2024</p>
<p><strong>Summary</strong><br>Meta AIçš„ASAMé€šè¿‡å¯¹æŠ—æ€§è®­ç»ƒå¢å¼ºäº†SAMå›¾åƒåˆ†å‰²æ¨¡å‹ï¼Œæ— éœ€é¢å¤–æ•°æ®æˆ–æ¶æ„è°ƒæ•´å³å¯æå‡åˆ†å‰²ä»»åŠ¡çš„æ€§èƒ½ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>ASAM é‡‡ç”¨å¯¹æŠ—è®­ç»ƒæ¥å¢å¼º SAM å›¾åƒåˆ†å‰²æ¨¡å‹ï¼Œæ— éœ€é¢å¤–æ•°æ®æˆ–æ¶æ„ä¿®æ”¹ã€‚</li>
<li>è‡ªç„¶å¯¹æŠ—å®ä¾‹æé«˜äº†æ¨¡å‹å¯¹è‡ªç„¶å˜åŒ–çš„é²æ£’æ€§ï¼Œè€Œä¸æ˜¯ä¼ ç»Ÿçš„ä¸å¯æ„ŸçŸ¥æ‰°åŠ¨ã€‚</li>
<li>ASAM ä¿æŒäº†å¯¹æŠ—å®ä¾‹çš„é€¼çœŸåº¦å¹¶ä¸åŸå§‹æ©ç æ³¨é‡Šä¿æŒä¸€è‡´ï¼Œä»è€Œä¿æŒåˆ†å‰²ä»»åŠ¡çš„å®Œæ•´æ€§ã€‚</li>
<li>å¾®è°ƒåçš„ ASAM åœ¨å„ç§åˆ†å‰²ä»»åŠ¡ä¸­è¡¨ç°å‡ºæ˜¾ç€æå‡ï¼Œåœ¨ SA-1B æ•°æ®é›†ä¸Šè¾¾åˆ° 88.2% çš„ mIoUã€‚</li>
<li>ASAM åœ¨ ADE20K æ•°æ®é›†ä¸Šè¾¾åˆ° 50.1% çš„ mIoUï¼Œè¶…è¿‡äº†ä»¥å‰çš„æœ€å…ˆè¿›æ–¹æ³•ã€‚</li>
<li>ASAM åœ¨ COCO Stuff æ•°æ®é›†ä¸Šè¾¾åˆ° 34.6% çš„ mIoUï¼Œåœ¨ Cityscapes æ•°æ®é›†ä¸Šè¾¾åˆ° 81.2% çš„ mIoUã€‚</li>
<li>ASAM æ¨è¿›äº†è®¡ç®—æœºè§†è§‰ä¸­åŸºç¡€æ¨¡å‹çš„æ€§èƒ½ï¼Œè¯æ˜äº†å¯¹æŠ—æ€§è®­ç»ƒåœ¨å›¾åƒåˆ†å‰²ä¸­çš„æ½œåŠ›ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>
<p>Title: ASAMï¼šåŸºäºå¯¹æŠ—è°ƒä¼˜çš„ Segment Anything æ¨¡å‹å¢å¼º</p>
</li>
<li>
<p>Authors: Bo Li, Haoke Xiao, Lv Tang</p>
</li>
<li>
<p>Affiliation: vivo Mobile Communication Co., Ltd</p>
</li>
<li>
<p>Keywords: Adversarial Tuning, Image Segmentation, Foundation Model, Segment Anything Model, Stable Diffusion</p>
</li>
<li>
<p>Urls: https://arxiv.org/abs/2405.00256, Github:None</p>
</li>
<li>
<p>Summary:</p>
</li>
</ol>
<p>(1): éšç€è®¡ç®—æœºè§†è§‰çš„å‘å±•ï¼ŒåŸºç¡€æ¨¡å‹å·²ç»æˆä¸ºå…³é”®å·¥å…·ï¼Œå®ƒä»¬åœ¨å„ç§ä»»åŠ¡ä¸­è¡¨ç°å‡ºå“è¶Šçš„é€‚åº”æ€§ã€‚å…¶ä¸­ï¼ŒMeta AI çš„ Segment Anything Model (SAM) åœ¨å›¾åƒåˆ†å‰²é¢†åŸŸè¡¨ç°çªå‡ºã€‚ç„¶è€Œï¼ŒSAM ä¸å…¶ä»–åŒç±»æ¨¡å‹ä¸€æ ·ï¼Œåœ¨ç‰¹å®šç»†åˆ†åº”ç”¨ä¸­é‡åˆ°äº†å±€é™æ€§ï¼Œè¿™ä¿ƒä½¿äººä»¬å¯»æ±‚å¢å¼ºç­–ç•¥ï¼Œè€Œä¸ä¼šæŸå®³å…¶å›ºæœ‰èƒ½åŠ›ã€‚</p>
<p>(2): è¿‡å»çš„æ–¹æ³•åŒ…æ‹¬å¾®è°ƒå’Œé€‚é…å™¨æ¨¡å—ï¼Œä½†å¾®è°ƒä¼šæŸå®³ SAM çš„å›ºæœ‰æ³›åŒ–èƒ½åŠ›ï¼Œè€Œå…¶ä»–æ–¹æ³•åˆ™éœ€è¦é¢å¤–çš„é€‚é…å±‚æˆ–åå¤„ç†æ¨¡å—ã€‚</p>
<p>(3): æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„æ–¹æ³• ASAMï¼Œå®ƒé€šè¿‡å¯¹æŠ—è°ƒä¼˜æ¥å¢å¼º SAM çš„æ€§èƒ½ã€‚å—è‡ªç„¶è¯­è¨€å¤„ç†ä¸­è‡ªç„¶å¯¹æŠ—æ ·æœ¬æˆåŠŸå®ç°çš„å¯å‘ï¼Œæˆ‘ä»¬åˆ©ç”¨ç¨³å®šæ‰©æ•£æ¨¡å‹ï¼Œå¢å¼ºäº† SA-1B æ•°æ®é›†çš„å­é›†ï¼ˆ1%ï¼‰ï¼Œç”Ÿæˆäº†æ›´èƒ½ä»£è¡¨è‡ªç„¶å˜åŒ–çš„å¯¹æŠ—å®ä¾‹ï¼Œè€Œä¸æ˜¯ä¼ ç»Ÿçš„ä¸å¯æ„ŸçŸ¥æ‰°åŠ¨ã€‚æˆ‘ä»¬çš„æ–¹æ³•ä¿æŒäº†å¯¹æŠ—æ ·æœ¬çš„çœŸå®æ„Ÿï¼Œå¹¶ç¡®ä¿äº†ä¸åŸå§‹æ©ç æ³¨é‡Šçš„ä¸€è‡´æ€§ï¼Œä»è€Œä¿ç•™äº†åˆ†å‰²ä»»åŠ¡çš„å®Œæ•´æ€§ã€‚</p>
<p>(4): åœ¨å„ç§åˆ†å‰²ä»»åŠ¡ä¸­ï¼Œç»è¿‡å¾®è°ƒçš„ ASAM å±•ç¤ºäº†æ˜¾è‘—çš„æ”¹è¿›ï¼Œè€Œæ— éœ€é¢å¤–çš„æ•°æ®æˆ–æ¶æ„ä¿®æ”¹ã€‚æˆ‘ä»¬å¹¿æ³›è¯„ä¼°çš„ç»“æœè¯å®ï¼ŒASAM åœ¨åˆ†å‰²ä»»åŠ¡ä¸­å»ºç«‹äº†æ–°çš„åŸºå‡†ï¼Œä»è€Œä¿ƒè¿›äº†è®¡ç®—æœºè§†è§‰ä¸­åŸºç¡€æ¨¡å‹çš„å‘å±•ã€‚</p>
<ol>
<li>æ–¹æ³•ï¼š</li>
</ol>
<p>ï¼ˆ1ï¼‰ï¼šæå‡º ASAM æ–¹æ³•ï¼Œé€šè¿‡å¯¹æŠ—è°ƒä¼˜å¢å¼º SAM æ¨¡å‹çš„æ€§èƒ½ï¼›</p>
<p>ï¼ˆ2ï¼‰ï¼šåˆ©ç”¨ç¨³å®šæ‰©æ•£æ¨¡å‹ï¼Œå¢å¼º SA-1B æ•°æ®é›†çš„å­é›†ï¼Œç”Ÿæˆæ›´å…·ä»£è¡¨æ€§çš„å¯¹æŠ—å®ä¾‹ï¼›</p>
<p>ï¼ˆ3ï¼‰ï¼šä¿æŒå¯¹æŠ—æ ·æœ¬çš„çœŸå®æ„Ÿï¼Œç¡®ä¿ä¸åŸå§‹æ©ç æ³¨é‡Šçš„ä¸€è‡´æ€§ï¼›</p>
<p>ï¼ˆ4ï¼‰ï¼šåœ¨å„ç§åˆ†å‰²ä»»åŠ¡ä¸­è¯„ä¼° ASAMï¼Œå±•ç¤ºäº†æ˜¾è‘—çš„æ”¹è¿›ï¼Œå»ºç«‹äº†æ–°çš„åŸºå‡†ã€‚</p>
<ol>
<li>ç»“è®ºï¼š</li>
</ol>
<p>ï¼ˆ1ï¼‰æœ¬å·¥ä½œé€šè¿‡åˆ›æ–°æ€§åœ°ä½¿ç”¨å¯¹æŠ—è°ƒä¼˜ï¼Œæå‡ºçš„ ASAM æ–¹æ³•ä»£è¡¨äº† SAM çš„é‡å¤§è¿›æ­¥ã€‚åˆ©ç”¨ç¨³å®šæ‰©æ•£æ¨¡å‹å¢å¼º SA-1B æ•°æ®é›†çš„ä¸€éƒ¨åˆ†ï¼Œæˆ‘ä»¬ç”Ÿæˆäº†è‡ªç„¶ã€é€¼çœŸçš„å¯¹æŠ—å›¾åƒï¼Œä»è€Œå¤§å¹…æå‡äº† SAM åœ¨å„ç§ä»»åŠ¡ä¸­çš„åˆ†å‰²èƒ½åŠ›ã€‚è¿™ç§æ–¹æ³•å€Ÿé‰´äº† NLP ä¸­å¯¹æŠ—è®­ç»ƒæŠ€æœ¯ï¼Œåœ¨ä¿æŒ SAM åŸç”Ÿæ¶æ„å’Œé›¶æ ·æœ¬ä¼˜åŠ¿çš„åŒæ—¶å¢å¼ºäº†å…¶æ€§èƒ½ã€‚æˆ‘ä»¬çš„ç ”ç©¶ç»“æœè¡¨æ˜ï¼ŒASAM ä¸ä»…åœ¨åˆ†å‰²ä»»åŠ¡ä¸­æ ‘ç«‹äº†æ–°çš„æ ‡æ†ï¼Œè€Œä¸”ä¿ƒè¿›äº†å¯¹æŠ—æ ·ä¾‹åœ¨è®¡ç®—æœºè§†è§‰é¢†åŸŸçš„æ›´å¹¿æ³›åº”ç”¨å’Œç†è§£ï¼Œä¸ºæå‡å¤§å‹è§†è§‰åŸºç¡€æ¨¡å‹èƒ½åŠ›æä¾›äº†ä¸€ç§æ–°é¢–ä¸”æœ‰æ•ˆçš„æ–¹æ³•ã€‚</p>
<p>ï¼ˆ2ï¼‰åˆ›æ–°ç‚¹ï¼šä½¿ç”¨ç¨³å®šæ‰©æ•£æ¨¡å‹ç”Ÿæˆå¯¹æŠ—å®ä¾‹ï¼Œå¢å¼º SAM çš„åˆ†å‰²èƒ½åŠ›ï¼›ä¿æŒ SAM çš„åŸç”Ÿæ¶æ„å’Œé›¶æ ·æœ¬ä¼˜åŠ¿ï¼›
æ€§èƒ½ï¼šåœ¨å„ç§åˆ†å‰²ä»»åŠ¡ä¸­å±•ç¤ºäº†æ˜¾è‘—çš„æ”¹è¿›ï¼Œå»ºç«‹äº†æ–°çš„åŸºå‡†ï¼›
å·¥ä½œé‡ï¼šä¸å¾®è°ƒå’Œé€‚é…å™¨æ¨¡å—ç­‰å…¶ä»–å¢å¼ºç­–ç•¥ç›¸æ¯”ï¼Œå·¥ä½œé‡ç›¸å¯¹è¾ƒå°ï¼Œæ— éœ€é¢å¤–çš„æ¶æ„ä¿®æ”¹æˆ–åå¤„ç†æ¨¡å—ã€‚</p>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-e7684baf385865b289b9bd3b4babea56.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-7c0e935c2de944340eb5085a5356da42.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d93133fcc44a60510ee9cb1385d6be69.jpg" align="middle">
</details>





                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2024-05-06/Diffusion%20Models/">https://kedreamix.github.io/Talk2Paper/Paper/2024-05-06/Diffusion%20Models/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/Diffusion-Models/">
                                    <span class="chip bg-color">Diffusion Models</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2024-05-06/Talking%20Head%20Generation/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-848d816930200060ec067527f2cd2e66.jpg" class="responsive-img" alt="Talking Head Generation">
                        
                        <span class="card-title">Talking Head Generation</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Talking Head Generation æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2024-05-06  CoVoMix Advancing Zero-Shot Speech Generation for Human-like   Multi-talker Conversations
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2024-05-06
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Talking-Head-Generation/" class="post-category">
                                    Talking Head Generation
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Talking-Head-Generation/">
                        <span class="chip bg-color">Talking Head Generation</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2024-05-06/%E5%85%83%E5%AE%87%E5%AE%99_%E8%99%9A%E6%8B%9F%E4%BA%BA/">
                    <div class="card-image">
                        
                        <img src="https://pic1.zhimg.com/v2-65e21e3a0a320adc36f81e6bfc7c5739.jpg" class="responsive-img" alt="å…ƒå®‡å®™/è™šæ‹Ÿäºº">
                        
                        <span class="card-title">å…ƒå®‡å®™/è™šæ‹Ÿäºº</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            å…ƒå®‡å®™/è™šæ‹Ÿäºº æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2024-05-06  X-Oscar A Progressive Framework for High-quality Text-guided 3D   Animatable Avatar Generation
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2024-05-06
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/%E5%85%83%E5%AE%87%E5%AE%99-%E8%99%9A%E6%8B%9F%E4%BA%BA/" class="post-category">
                                    å…ƒå®‡å®™/è™šæ‹Ÿäºº
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/%E5%85%83%E5%AE%87%E5%AE%99-%E8%99%9A%E6%8B%9F%E4%BA%BA/">
                        <span class="chip bg-color">å…ƒå®‡å®™/è™šæ‹Ÿäºº</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">14071k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
