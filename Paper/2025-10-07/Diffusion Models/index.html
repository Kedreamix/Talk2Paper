<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Diffusion Models">
    <meta name="description" content="Diffusion Models æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-10-07  Product-Quantised Image Representation for High-Quality Image Synthesis">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>Diffusion Models | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://picx.zhimg.com/v2-5dd7309b3a8b9b771cfaf09a2084da7d')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Diffusion Models</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/Diffusion-Models/">
                                <span class="chip bg-color">Diffusion Models</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/Diffusion-Models/" class="post-category">
                                Diffusion Models
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-10-07
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-11-13
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    7.8k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    31 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-10-07-æ›´æ–°"><a href="#2025-10-07-æ›´æ–°" class="headerlink" title="2025-10-07 æ›´æ–°"></a>2025-10-07 æ›´æ–°</h1><h2 id="Product-Quantised-Image-Representation-for-High-Quality-Image-Synthesis"><a href="#Product-Quantised-Image-Representation-for-High-Quality-Image-Synthesis" class="headerlink" title="Product-Quantised Image Representation for High-Quality Image Synthesis"></a>Product-Quantised Image Representation for High-Quality Image Synthesis</h2><p><strong>Authors:Denis Zavadski, Nikita Philip Tatsch, Carsten Rother</strong></p>
<p>Product quantisation (PQ) is a classical method for scalable vector encoding, yet it has seen limited usage for latent representations in high-fidelity image generation. In this work, we introduce PQGAN, a quantised image autoencoder that integrates PQ into the well-known vector quantisation (VQ) framework of VQGAN. PQGAN achieves a noticeable improvement over state-of-the-art methods in terms of reconstruction performance, including both quantisation methods and their continuous counterparts. We achieve a PSNR score of 37dB, where prior work achieves 27dB, and are able to reduce the FID, LPIPS, and CMMD score by up to 96%. Our key to success is a thorough analysis of the interaction between codebook size, embedding dimensionality, and subspace factorisation, with vector and scalar quantisation as special cases. We obtain novel findings, such that the performance of VQ and PQ behaves in opposite ways when scaling the embedding dimension. Furthermore, our analysis shows performance trends for PQ that help guide optimal hyperparameter selection. Finally, we demonstrate that PQGAN can be seamlessly integrated into pre-trained diffusion models. This enables either a significantly faster and more compute-efficient generation, or a doubling of the output resolution at no additional cost, positioning PQ as a strong extension for discrete latent representation in image synthesis. </p>
<blockquote>
<p>äº§å“é‡åŒ–ï¼ˆPQï¼‰æ˜¯ä¸€ç§ç”¨äºå¯æ‰©å±•å‘é‡ç¼–ç çš„ç»å…¸æ–¹æ³•ï¼Œä½†åœ¨é«˜ä¿çœŸå›¾åƒç”Ÿæˆä¸­çš„æ½œåœ¨è¡¨ç¤ºåº”ç”¨æœ‰é™ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬ä»‹ç»äº†PQGANï¼Œè¿™æ˜¯ä¸€ä¸ªå°†PQé›†æˆåˆ°ä¼—æ‰€å‘¨çŸ¥çš„VQGANçš„å‘é‡é‡åŒ–ï¼ˆVQï¼‰æ¡†æ¶ä¸­çš„é‡åŒ–å›¾åƒè‡ªç¼–ç å™¨ã€‚PQGANåœ¨é‡å»ºæ€§èƒ½ä¸Šå®ç°äº†å¯¹æœ€å…ˆè¿›æ–¹æ³•çš„æ˜¾è‘—æ”¹è¿›ï¼ŒåŒ…æ‹¬é‡åŒ–æ–¹æ³•å’Œå®ƒä»¬çš„è¿ç»­å¯¹åº”ç‰©ã€‚æˆ‘ä»¬è¾¾åˆ°çš„PSNRåˆ†æ•°ä¸º37dBï¼Œè€Œå…ˆå‰çš„å·¥ä½œåªè¾¾åˆ°27dBï¼Œå¹¶ä¸”èƒ½å¤Ÿå°†FIDã€LPIPSå’ŒCMMDåˆ†æ•°é™ä½é«˜è¾¾96%ã€‚æˆ‘ä»¬æˆåŠŸçš„å…³é”®æ˜¯å…¨é¢åˆ†æäº†ç æœ¬å¤§å°ã€åµŒå…¥ç»´åº¦å’Œå­ç©ºé—´åˆ†è§£ä¹‹é—´çš„ç›¸äº’ä½œç”¨ï¼Œä»¥å‘é‡å’Œæ ‡é‡é‡åŒ–ä½œä¸ºç‰¹æ®Šæƒ…å†µã€‚æˆ‘ä»¬è·å¾—äº†æ–°çš„å‘ç°ï¼Œå³åœ¨ç¼©æ”¾åµŒå…¥ç»´åº¦æ—¶ï¼ŒVQå’ŒPQçš„æ€§èƒ½è¡¨ç°ç›¸åã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬çš„åˆ†ææ˜¾ç¤ºäº†PQçš„æ€§èƒ½è¶‹åŠ¿ï¼Œæœ‰åŠ©äºé€‰æ‹©æœ€ä½³è¶…å‚æ•°ã€‚æœ€åï¼Œæˆ‘ä»¬è¯æ˜PQGANå¯ä»¥æ— ç¼é›†æˆåˆ°é¢„è®­ç»ƒçš„æ‰©æ•£æ¨¡å‹ä¸­ã€‚è¿™ä½¿å¾—è¦ä¹ˆç”Ÿæˆè¿‡ç¨‹æ›´å¿«ã€æ›´èŠ‚çœè®¡ç®—èµ„æºï¼Œè¦ä¹ˆåœ¨ä¸å¢åŠ æˆæœ¬çš„æƒ…å†µä¸‹å°†è¾“å‡ºåˆ†è¾¨ç‡ç¿»å€ï¼Œä»è€Œå®šä½PQä½œä¸ºå›¾åƒåˆæˆä¸­ç¦»æ•£æ½œåœ¨è¡¨ç¤ºçš„å¼ºå¤§æ‰©å±•ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.03191v1">PDF</a> </p>
<p><strong>Summary</strong><br>     æœ¬æ–‡ä»‹ç»äº†PQGANï¼Œä¸€ç§å°†äº§å“é‡åŒ–ï¼ˆPQï¼‰èå…¥VQGANçš„å‘é‡é‡åŒ–æ¡†æ¶çš„é‡åŒ–å›¾åƒè‡ªç¼–ç å™¨ã€‚PQGANåœ¨é‡å»ºæ€§èƒ½ä¸Šè¾ƒç°æœ‰æ–¹æ³•æœ‰æ˜æ˜¾æ”¹è¿›ï¼Œå®ç°äº†37dBçš„PSNRåˆ†æ•°ï¼Œå¹¶é™ä½äº†FIDã€LPIPSå’ŒCMMDåˆ†æ•°é«˜è¾¾96%ã€‚å…¶æˆåŠŸçš„å…³é”®åœ¨äºå¯¹ä»£ç æœ¬å¤§å°ã€åµŒå…¥ç»´åº¦å’Œå­ç©ºé—´åˆ†è§£ä¹‹é—´çš„ç›¸äº’ä½œç”¨è¿›è¡Œäº†æ·±å…¥åˆ†æã€‚æ­¤å¤–ï¼ŒPQGANå¯æ— ç¼é›†æˆåˆ°é¢„è®­ç»ƒçš„æ‰©æ•£æ¨¡å‹ä¸­ï¼Œå¯å®ç°æ›´å¿«ã€æ›´é«˜æ•ˆçš„ç”Ÿæˆæˆ–è¾“å‡ºåˆ†è¾¨ç‡ç¿»å€è€Œæ— éœ€é¢å¤–æˆæœ¬ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>PQGANç»“åˆäº†äº§å“é‡åŒ–ï¼ˆPQï¼‰å’Œå‘é‡é‡åŒ–ï¼ˆVQï¼‰æ¡†æ¶ï¼Œå®ç°äº†é«˜ä¿çœŸå›¾åƒç”Ÿæˆä¸­çš„æ½œè¡¨ç¤ºã€‚</li>
<li>PQGANåœ¨é‡å»ºæ€§èƒ½ä¸Šè¾ƒç°æœ‰æ–¹æ³•æœ‰æ˜æ˜¾æ”¹è¿›ï¼ŒPSNRåˆ†æ•°è¾¾åˆ°37dBã€‚</li>
<li>PQGANé™ä½äº†FIDã€LPIPSå’ŒCMMDåˆ†æ•°é«˜è¾¾96%ã€‚</li>
<li>é€šè¿‡åˆ†æä»£ç æœ¬å¤§å°ã€åµŒå…¥ç»´åº¦å’Œå­ç©ºé—´åˆ†è§£çš„ç›¸äº’ä½œç”¨ï¼ŒPQGANå–å¾—äº†æˆåŠŸã€‚</li>
<li>VQå’ŒPQåœ¨æ‰©å¤§åµŒå…¥ç»´åº¦æ—¶è¡¨ç°ç›¸åï¼Œè¿™æ˜¯PQGANçš„æ–°å‘ç°ã€‚</li>
<li>PQGANçš„åˆ†æå±•ç¤ºäº†PQçš„æ€§èƒ½è¶‹åŠ¿ï¼Œæœ‰åŠ©äºé€‰æ‹©æœ€ä½³è¶…å‚æ•°ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.03191">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-6dfccbd83297c60e6950d81240c8431c" align="middle">
<img src="https://pica.zhimg.com/v2-732389776851c44379334d0e689a65bc.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ca5724cd56fb2eb28ca673adc2128bb5" align="middle">
<img src="https://picx.zhimg.com/v2-dfcc14f874dc033cc7ef4c9663d9dcf1" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="HAVIR-HierArchical-Vision-to-Image-Reconstruction-using-CLIP-Guided-Versatile-Diffusion"><a href="#HAVIR-HierArchical-Vision-to-Image-Reconstruction-using-CLIP-Guided-Versatile-Diffusion" class="headerlink" title="HAVIR: HierArchical Vision to Image Reconstruction using CLIP-Guided   Versatile Diffusion"></a>HAVIR: HierArchical Vision to Image Reconstruction using CLIP-Guided   Versatile Diffusion</h2><p><strong>Authors:Shiyi Zhang, Dong Liang, Hairong Zheng, Yihang Zhou</strong></p>
<p>The reconstruction of visual information from brain activity fosters interdisciplinary integration between neuroscience and computer vision. However, existing methods still face challenges in accurately recovering highly complex visual stimuli. This difficulty stems from the characteristics of natural scenes: low-level features exhibit heterogeneity, while high-level features show semantic entanglement due to contextual overlaps. Inspired by the hierarchical representation theory of the visual cortex, we propose the HAVIR model, which separates the visual cortex into two hierarchical regions and extracts distinct features from each. Specifically, the Structural Generator extracts structural information from spatial processing voxels and converts it into latent diffusion priors, while the Semantic Extractor converts semantic processing voxels into CLIP embeddings. These components are integrated via the Versatile Diffusion model to synthesize the final image. Experimental results demonstrate that HAVIR enhances both the structural and semantic quality of reconstructions, even in complex scenes, and outperforms existing models. </p>
<blockquote>
<p>ä»è„‘æ´»åŠ¨ä¸­é‡å»ºè§†è§‰ä¿¡æ¯ä¿ƒè¿›äº†ç¥ç»ç§‘å­¦å’Œè®¡ç®—æœºè§†è§‰ä¹‹é—´çš„è·¨å­¦ç§‘èåˆã€‚ç„¶è€Œï¼Œç°æœ‰æ–¹æ³•ä»ç„¶é¢ä¸´ç€åœ¨å¤æ‚è§†è§‰åˆºæ¿€ä¸­å‡†ç¡®æ¢å¤æ–¹é¢çš„æŒ‘æˆ˜ã€‚è¿™ä¸€éš¾é¢˜æºäºè‡ªç„¶åœºæ™¯çš„ç‰¹æ€§ï¼šä½çº§ç‰¹å¾è¡¨ç°å‡ºå¼‚è´¨æ€§ï¼Œè€Œé«˜çº§ç‰¹å¾åˆ™å› ä¸Šä¸‹æ–‡é‡å è€Œæ˜¾ç¤ºå‡ºè¯­ä¹‰çº ç¼ ã€‚å—è§†è§‰çš®å±‚å±‚æ¬¡è¡¨ç¤ºç†è®ºçš„å¯å‘ï¼Œæˆ‘ä»¬æå‡ºäº†HAVIRæ¨¡å‹ï¼Œè¯¥æ¨¡å‹å°†è§†è§‰çš®å±‚åˆ†ä¸ºä¸¤ä¸ªå±‚æ¬¡åŒºåŸŸï¼Œå¹¶ä»æ¯ä¸ªåŒºåŸŸä¸­æå–ä¸åŒçš„ç‰¹å¾ã€‚å…·ä½“æ¥è¯´ï¼Œç»“æ„ç”Ÿæˆå™¨ä»ç©ºé—´å¤„ç†ä½“ç´ ä¸­æå–ç»“æ„ä¿¡æ¯å¹¶å°†å…¶è½¬æ¢ä¸ºæ½œåœ¨æ‰©æ•£å…ˆéªŒä¿¡æ¯ï¼Œè€Œè¯­ä¹‰æå–å™¨å°†è¯­ä¹‰å¤„ç†ä½“ç´ è½¬æ¢ä¸ºCLIPåµŒå…¥ã€‚è¿™äº›ç»„ä»¶é€šè¿‡é€šç”¨æ‰©æ•£æ¨¡å‹è¿›è¡Œé›†æˆï¼Œä»¥åˆæˆæœ€ç»ˆå›¾åƒã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œå³ä½¿åœ¨å¤æ‚åœºæ™¯ä¸­ï¼ŒHAVIRä¹Ÿèƒ½æé«˜é‡å»ºçš„ç»“æ„å’Œè¯­ä¹‰è´¨é‡ï¼Œå¹¶ä¸”ä¼˜äºç°æœ‰æ¨¡å‹ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.03122v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºä¸€ç§åŸºäºè§†è§‰çš®å±‚å±‚æ¬¡è¡¨ç¤ºç†è®ºçš„HAVIRæ¨¡å‹ï¼Œè¯¥æ¨¡å‹å°†è§†è§‰çš®å±‚åˆ†ä¸ºä¸¤ä¸ªå±‚æ¬¡åŒºåŸŸï¼Œåˆ†åˆ«æå–ä¸åŒç‰¹å¾ã€‚é€šè¿‡ç»“æ„ç”Ÿæˆå™¨æå–ç©ºé—´å¤„ç†ä½“ç´ çš„ç»“æ„ä¿¡æ¯å¹¶è½¬æ¢ä¸ºæ½œåœ¨æ‰©æ•£å…ˆéªŒï¼Œè¯­ä¹‰æå–å™¨åˆ™å°†è¯­ä¹‰å¤„ç†ä½“ç´ è½¬æ¢ä¸ºCLIPåµŒå…¥ã€‚é€šè¿‡é€šç”¨æ‰©æ•£æ¨¡å‹é›†æˆè¿™äº›ç»„ä»¶ä»¥åˆæˆæœ€ç»ˆå›¾åƒã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒHAVIRæ¨¡å‹åœ¨å¤æ‚åœºæ™¯ä¸‹èƒ½æå‡é‡å»ºå›¾åƒçš„ç»“æ„å’Œè¯­ä¹‰è´¨é‡ï¼Œå¹¶ä¼˜äºç°æœ‰æ¨¡å‹ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>é‡å»ºè§†è§‰ä¿¡æ¯é¢ä¸´æŒ‘æˆ˜ï¼šç°æœ‰æ–¹æ³•éš¾ä»¥å‡†ç¡®æ¢å¤é«˜åº¦å¤æ‚çš„è§†è§‰åˆºæ¿€ï¼Œæºäºè‡ªç„¶åœºæ™¯çš„ç‰¹æ€§ï¼Œå³ä½çº§åˆ«ç‰¹å¾çš„å¼‚è´¨æ€§å’Œé«˜çº§åˆ«ç‰¹å¾çš„è¯­ä¹‰çº ç¼ ã€‚</li>
<li>HAVIRæ¨¡å‹æå‡ºåŸºäºè§†è§‰çš®å±‚å±‚æ¬¡è¡¨ç¤ºç†è®ºï¼šè¯¥æ¨¡å‹çµæ„Ÿæ¥æºäºè§†è§‰çš®å±‚çš„å±‚æ¬¡è¡¨ç¤ºç†è®ºï¼Œå°†è§†è§‰çš®å±‚åˆ†ä¸ºä¸¤ä¸ªå±‚æ¬¡åŒºåŸŸè¿›è¡Œç‰¹å¾æå–ã€‚</li>
<li>ç»“æ„ç”Ÿæˆå™¨å’Œè¯­ä¹‰æå–å™¨çš„åŠŸèƒ½ï¼šç»“æ„ç”Ÿæˆå™¨ä»ç©ºé—´å¤„ç†ä½“ç´ ä¸­æå–ç»“æ„ä¿¡æ¯å¹¶è½¬æ¢ä¸ºæ½œåœ¨æ‰©æ•£å…ˆéªŒï¼Œè€Œè¯­ä¹‰æå–å™¨åˆ™å°†è¯­ä¹‰å¤„ç†ä½“ç´ è½¬æ¢ä¸ºCLIPåµŒå…¥ã€‚</li>
<li>Versatile Diffusionæ¨¡å‹çš„é›†æˆä½œç”¨ï¼šé€šè¿‡é€šç”¨æ‰©æ•£æ¨¡å‹é›†æˆç»“æ„ç”Ÿæˆå™¨å’Œè¯­ä¹‰æå–å™¨çš„è¾“å‡ºï¼Œä»¥åˆæˆæœ€ç»ˆå›¾åƒã€‚</li>
<li>HAVIRæ¨¡å‹çš„ä¼˜åŠ¿ï¼šå®éªŒç»“æœè¡¨æ˜ï¼ŒHAVIRæ¨¡å‹åœ¨å¤æ‚åœºæ™¯ä¸‹èƒ½æå‡é‡å»ºå›¾åƒçš„ç»“æ„å’Œè¯­ä¹‰è´¨é‡ã€‚</li>
<li>HAVIRæ¨¡å‹æ€§èƒ½è¶…è¶Šç°æœ‰æ–¹æ³•ï¼šç›¸æ¯”å…¶ä»–æ¨¡å‹ï¼ŒHAVIRè¡¨ç°å‡ºæ›´å¥½çš„æ€§èƒ½ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.03122">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-1cfd2e61c79af339471288ba4fcfad07.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-fb0693ea58fdb813f086fc69380a43da" align="middle">
<img src="https://picx.zhimg.com/v2-5dd7309b3a8b9b771cfaf09a2084da7d" align="middle">
<img src="https://picx.zhimg.com/v2-aabffc6dbdc9e9ede5a3b1612c981351" align="middle">
<img src="https://picx.zhimg.com/v2-a38c148322e282ea16103ddd06658a6b" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="Latent-Diffusion-Unlearning-Protecting-Against-Unauthorized-Personalization-Through-Trajectory-Shifted-Perturbations"><a href="#Latent-Diffusion-Unlearning-Protecting-Against-Unauthorized-Personalization-Through-Trajectory-Shifted-Perturbations" class="headerlink" title="Latent Diffusion Unlearning: Protecting Against Unauthorized   Personalization Through Trajectory Shifted Perturbations"></a>Latent Diffusion Unlearning: Protecting Against Unauthorized   Personalization Through Trajectory Shifted Perturbations</h2><p><strong>Authors:Naresh Kumar Devulapally, Shruti Agarwal, Tejas Gokhale, Vishnu Suresh Lokhande</strong></p>
<p>Text-to-image diffusion models have demonstrated remarkable effectiveness in rapid and high-fidelity personalization, even when provided with only a few user images. However, the effectiveness of personalization techniques has lead to concerns regarding data privacy, intellectual property protection, and unauthorized usage. To mitigate such unauthorized usage and model replication, the idea of generating &#96;&#96;unlearnableâ€™â€™ training samples utilizing image poisoning techniques has emerged. Existing methods for this have limited imperceptibility as they operate in the pixel space which results in images with noise and artifacts. In this work, we propose a novel model-based perturbation strategy that operates within the latent space of diffusion models. Our method alternates between denoising and inversion while modifying the starting point of the denoising trajectory: of diffusion models. This trajectory-shifted sampling ensures that the perturbed images maintain high visual fidelity to the original inputs while being resistant to inversion and personalization by downstream generative models. This approach integrates unlearnability into the framework of Latent Diffusion Models (LDMs), enabling a practical and imperceptible defense against unauthorized model adaptation. We validate our approach on four benchmark datasets to demonstrate robustness against state-of-the-art inversion attacks. Results demonstrate that our method achieves significant improvements in imperceptibility ($\sim 8 % -10%$ on perceptual metrics including PSNR, SSIM, and FID) and robustness ( $\sim 10%$ on average across five adversarial settings), highlighting its effectiveness in safeguarding sensitive data. </p>
<blockquote>
<p>æ–‡æœ¬åˆ°å›¾åƒçš„æ‰©æ•£æ¨¡å‹åœ¨å¿«é€Ÿé«˜ä¿çœŸä¸ªæ€§åŒ–æ–¹é¢è¡¨ç°å‡ºæ˜¾è‘—çš„æœ‰æ•ˆæ€§ï¼Œå³ä½¿åªæä¾›å°‘é‡ç”¨æˆ·å›¾åƒä¹Ÿæ˜¯å¦‚æ­¤ã€‚ç„¶è€Œï¼Œä¸ªæ€§åŒ–æŠ€æœ¯çš„æœ‰æ•ˆæ€§å¼•å‘äº†æœ‰å…³æ•°æ®éšç§ã€çŸ¥è¯†äº§æƒä¿æŠ¤å’Œæœªç»æˆæƒä½¿ç”¨ç­‰é—®é¢˜çš„æ‹…å¿§ã€‚ä¸ºäº†ç¼“è§£æœªç»æˆæƒçš„ä½¿ç”¨å’Œæ¨¡å‹å¤åˆ¶é—®é¢˜ï¼Œåˆ©ç”¨å›¾åƒä¸­æ¯’æŠ€æœ¯ç”Ÿæˆâ€œä¸å¯å­¦ä¹ â€è®­ç»ƒæ ·æœ¬çš„æƒ³æ³•åº”è¿è€Œç”Ÿã€‚ç°æœ‰çš„æ–¹æ³•æœ‰é™çš„éšè”½æ€§æ˜¯å› ä¸ºå®ƒä»¬åœ¨åƒç´ ç©ºé—´æ“ä½œï¼Œå¯¼è‡´å›¾åƒå‡ºç°å™ªå£°å’Œä¼ªå½±ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åŸºäºæ¨¡å‹çš„æ–°å‹æ‰°åŠ¨ç­–ç•¥ï¼Œè¯¥ç­–ç•¥åœ¨æ‰©æ•£æ¨¡å‹çš„æ½œåœ¨ç©ºé—´å†…è¿è¡Œã€‚æˆ‘ä»¬çš„æ–¹æ³•äº¤æ›¿è¿›è¡Œå»å™ªå’Œåæ¼”ï¼ŒåŒæ—¶æ”¹å˜å»å™ªè½¨è¿¹çš„èµ·ç‚¹ï¼šæ‰©æ•£æ¨¡å‹ã€‚è¿™ç§è½¨è¿¹åç§»é‡‡æ ·ç¡®ä¿æ‰°åŠ¨å›¾åƒåœ¨ä¿æŒå¯¹åŸå§‹è¾“å…¥é«˜è§†è§‰ä¿çœŸåº¦çš„åŒæ—¶ï¼ŒæŠµæŠ—ä¸‹æ¸¸ç”Ÿæˆæ¨¡å‹çš„åæ¼”å’Œä¸ªæ€§åŒ–ã€‚è¿™ç§æ–¹æ³•å°†ä¸å¯å­¦ä¹ æ€§é›†æˆåˆ°æ½œåœ¨æ‰©æ•£æ¨¡å‹ï¼ˆLDMï¼‰çš„æ¡†æ¶ä¸­ï¼Œä¸ºå¯¹æŠ—æœªç»æˆæƒçš„æ¨¡å‹é€‚åº”æä¾›äº†å®ç”¨ä¸”éšè”½çš„é˜²å¾¡æ‰‹æ®µã€‚æˆ‘ä»¬åœ¨å››ä¸ªåŸºå‡†æ•°æ®é›†ä¸ŠéªŒè¯äº†æˆ‘ä»¬çš„æ–¹æ³•ï¼Œä»¥å±•ç¤ºå…¶å¯¹æŠ—æœ€å…ˆè¿›åæ¼”æ”»å‡»çš„ç¨³å¥æ€§ã€‚ç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨æ„ŸçŸ¥åº¦é‡ï¼ˆåŒ…æ‹¬PSNRã€SSIMå’ŒFIDï¼‰ä¸Šå®ç°äº†æ˜¾è‘—çš„å¯è§‰å¯Ÿæ€§æ”¹è¿›ï¼ˆçº¦8%-10%ï¼‰ï¼Œå¹¶åœ¨äº”ç§å¯¹æŠ—è®¾ç½®ä¸Šå¹³å‡æé«˜äº†çº¦10%çš„ç¨³å¥æ€§ï¼Œè¿™çªæ˜¾äº†å…¶åœ¨ä¿æŠ¤æ•æ„Ÿæ•°æ®æ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.03089v1">PDF</a> </p>
<p><strong>Summary</strong>ï¼šæœ¬æ–‡æå‡ºä¸€ç§åŸºäºæ¨¡å‹æ‰°åŠ¨ç­–ç•¥çš„é˜²æœªæˆæƒä½¿ç”¨ç­–ç•¥ï¼Œé€šè¿‡ä¿®æ”¹æ‰©æ•£æ¨¡å‹çš„å»å™ªè½¨è¿¹èµ·ç‚¹æ¥ç”Ÿæˆä¸å¯å­¦ä¹ çš„è®­ç»ƒæ ·æœ¬ï¼Œèƒ½å¤Ÿåœ¨ä¿æŒå›¾åƒé«˜ä¿çœŸåº¦çš„åŒæ—¶æŠµæŠ—ä¸‹æ¸¸ç”Ÿæˆæ¨¡å‹çš„é€†å‘å·¥ç¨‹å’Œä¸ªæ€§åŒ–æ“ä½œã€‚è¯¥ç­–ç•¥é›†æˆåœ¨æ½œåœ¨æ‰©æ•£æ¨¡å‹ï¼ˆLatent Diffusion Modelsï¼Œç®€ç§°LDMï¼‰æ¡†æ¶ä¸­ï¼Œé€šè¿‡éªŒè¯æ˜¾ç¤ºï¼Œå…¶åœ¨ä¿æŠ¤æ•æ„Ÿæ•°æ®æ–¹é¢å…·æœ‰è‰¯å¥½çš„å®ç”¨æ€§å’Œéšè”½æ€§ä¼˜åŠ¿ã€‚æ­¤æ–¹æ³•èƒ½æ˜¾è‘—æå‡é˜²æŠ¤éšè”½æ€§æ„ŸçŸ¥åº¦é‡æ ‡å‡†ï¼ˆå¦‚PSNRã€SSIMå’ŒFIDç­‰ï¼‰çº¦8%-10%ï¼Œå¹¶åœ¨äº”ç§å¯¹æŠ—ç¯å¢ƒä¸­å¹³å‡æé«˜çº¦10%çš„ç¨³å¥æ€§ã€‚</p>
<p><strong>Key Takeaways</strong>ï¼š</p>
<ol>
<li>æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹çš„é«˜æ•ˆä¸ªæ€§åŒ–èƒ½åŠ›å¼•å‘å…³äºæ•°æ®éšç§å’ŒçŸ¥è¯†äº§æƒçš„æ‹…å¿§ã€‚</li>
<li>ä¸ºåº”å¯¹æœªç»æˆæƒçš„ä½¿ç”¨å’Œæ¨¡å‹å¤åˆ¶é—®é¢˜ï¼Œæå‡ºåˆ©ç”¨å›¾åƒä¸­æ¯’æŠ€æœ¯ç”Ÿæˆä¸å¯å­¦ä¹ çš„è®­ç»ƒæ ·æœ¬ã€‚</li>
<li>ç°æœ‰æ–¹æ³•å› åœ¨åƒç´ ç©ºé—´æ“ä½œè€Œå­˜åœ¨å¯è§å™ªå£°å’Œä¼ªå½±çš„é—®é¢˜ã€‚</li>
<li>æå‡ºä¸€ç§æ–°å‹åŸºäºæ¨¡å‹æ‰°åŠ¨çš„ç­–ç•¥ï¼Œåœ¨æ‰©æ•£æ¨¡å‹çš„æ½œåœ¨ç©ºé—´å†…æ“ä½œã€‚</li>
<li>é€šè¿‡äº¤æ›¿å»å™ªå’Œåè½¬æ“ä½œï¼Œä¿®æ”¹å»å™ªè½¨è¿¹èµ·ç‚¹ä»¥ç”Ÿæˆå…·æœ‰é«˜è´¨é‡ä¸”å¯¹ä¸‹æ¸¸ç”Ÿæˆæ¨¡å‹é€†å‘å·¥ç¨‹å’Œä¸ªæ€§åŒ–æŠµæŠ—çš„å›¾åƒã€‚</li>
<li>è¯¥ç­–ç•¥é›†æˆåœ¨æ½œåœ¨æ‰©æ•£æ¨¡å‹æ¡†æ¶ä¸­ï¼Œæå‡äº†é˜²å¾¡ç­–ç•¥åœ¨å®é™…åº”ç”¨ä¸­çš„å®ç”¨æ€§å’Œéšè”½æ€§ä¼˜åŠ¿ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.03089">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-9bffd78992c0d64df37b905f9a0104ee" align="middle">
<img src="https://picx.zhimg.com/v2-559da5ba9ab9b20ab77e7a0834f7ef59" align="middle">
<img src="https://picx.zhimg.com/v2-a4f394bd8bbf009d3046a0e0986d7383" align="middle">
<img src="https://pica.zhimg.com/v2-4509cdf4acf699173f9d2d8895913a10.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="PEO-Training-Free-Aesthetic-Quality-Enhancement-in-Pre-Trained-Text-to-Image-Diffusion-Models-with-Prompt-Embedding-Optimization"><a href="#PEO-Training-Free-Aesthetic-Quality-Enhancement-in-Pre-Trained-Text-to-Image-Diffusion-Models-with-Prompt-Embedding-Optimization" class="headerlink" title="PEO: Training-Free Aesthetic Quality Enhancement in Pre-Trained   Text-to-Image Diffusion Models with Prompt Embedding Optimization"></a>PEO: Training-Free Aesthetic Quality Enhancement in Pre-Trained   Text-to-Image Diffusion Models with Prompt Embedding Optimization</h2><p><strong>Authors:Hovhannes Margaryan, Bo Wan, Tinne Tuytelaars</strong></p>
<p>This paper introduces a novel approach to aesthetic quality improvement in pre-trained text-to-image diffusion models when given a simple prompt. Our method, dubbed Prompt Embedding Optimization (PEO), leverages a pre-trained text-to-image diffusion model as a backbone and optimizes the text embedding of a given simple and uncurated prompt to enhance the visual quality of the generated image. We achieve this by a tripartite objective function that improves the aesthetic fidelity of the generated image, ensures adherence to the optimized text embedding, and minimal divergence from the initial prompt. The latter is accomplished through a prompt preservation term. Additionally, PEO is training-free and backbone-independent. Quantitative and qualitative evaluations confirm the effectiveness of the proposed method, exceeding or equating the performance of state-of-the-art text-to-image and prompt adaptation methods. </p>
<blockquote>
<p>æœ¬æ–‡ä»‹ç»äº†ä¸€ç§åœ¨ç»™å®šç®€å•æç¤ºæ—¶ï¼Œæé«˜é¢„è®­ç»ƒæ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹ç¾å­¦è´¨é‡çš„æ–°æ–¹æ³•ã€‚æˆ‘ä»¬çš„æ–¹æ³•è¢«ç§°ä¸ºæç¤ºåµŒå…¥ä¼˜åŒ–ï¼ˆPEOï¼‰ï¼Œå®ƒåˆ©ç”¨é¢„è®­ç»ƒçš„æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹ä½œä¸ºéª¨å¹²ï¼Œå¹¶é€šè¿‡ä¼˜åŒ–ç»™å®šç®€å•æœªæ•´ç†çš„æç¤ºçš„æ–‡æœ¬åµŒå…¥æ¥å¢å¼ºç”Ÿæˆå›¾åƒçš„å¯è§†è´¨é‡ã€‚æˆ‘ä»¬é€šè¿‡ä¸‰æ–¹ç›®æ ‡å‡½æ•°å®ç°è¿™ä¸€ç‚¹ï¼Œè¯¥å‡½æ•°æé«˜äº†ç”Ÿæˆå›¾åƒçš„ç¾å­¦ä¿çœŸåº¦ï¼Œç¡®ä¿éµå¾ªä¼˜åŒ–åçš„æ–‡æœ¬åµŒå…¥ï¼Œå¹¶ä¸”ä¸åˆå§‹æç¤ºçš„åå·®æœ€å°ã€‚åè€…æ˜¯é€šè¿‡æç¤ºä¿ç•™é¡¹æ¥å®ç°çš„ã€‚æ­¤å¤–ï¼ŒPEOæ— éœ€è®­ç»ƒä¸”ç‹¬ç«‹äºéª¨å¹²ç½‘ã€‚å®šé‡å’Œå®šæ€§è¯„ä¼°è¯å®äº†æ‰€æå‡ºæ–¹æ³•çš„æœ‰æ•ˆæ€§ï¼Œå…¶æ€§èƒ½è¶…è¿‡äº†æˆ–ç­‰åŒäºæœ€å…ˆè¿›çš„æ–‡æœ¬åˆ°å›¾åƒå’Œæç¤ºé€‚åº”æ–¹æ³•ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.02599v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ç§æ”¹è¿›é¢„è®­ç»ƒæ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹ç¾å­¦è´¨é‡çš„æ–°æ–¹æ³•ï¼Œç§°ä¸ºPrompt Embedding Optimizationï¼ˆPEOï¼‰ã€‚è¯¥æ–¹æ³•åˆ©ç”¨é¢„è®­ç»ƒçš„æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹ä½œä¸ºéª¨å¹²ï¼Œä¼˜åŒ–ç»™å®šç®€å•æœªæ•´ç†æç¤ºçš„æ–‡æœ¬åµŒå…¥ï¼Œä»¥æé«˜ç”Ÿæˆå›¾åƒçš„å¯è§†è´¨é‡ã€‚é€šè¿‡ä¸‰æ–¹ç›®æ ‡å‡½æ•°å®ç°ï¼Œæ—¨åœ¨æé«˜ç”Ÿæˆå›¾åƒçš„ç¾å­¦ä¿çœŸåº¦ï¼Œç¡®ä¿ä¼˜åŒ–æ–‡æœ¬åµŒå…¥çš„éµå¾ªï¼Œå¹¶å°½é‡å‡å°‘ä¸åˆå§‹æç¤ºçš„åå·®ã€‚æ­¤å¤–ï¼ŒPEOå…·æœ‰æ— è®­ç»ƒå’Œç‹¬ç«‹äºéª¨å¹²çš„ç‰¹ç‚¹ã€‚å®šé‡å’Œå®šæ€§è¯„ä¼°è¯æ˜äº†è¯¥æ–¹æ³•çš„æœ‰æ•ˆæ€§ï¼Œè¶…è¶Šäº†æˆ–ç­‰åŒäºæœ€å…ˆè¿›æ–‡æœ¬åˆ°å›¾åƒå’Œæç¤ºé€‚åº”æ–¹æ³•çš„è¡¨ç°ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¼•å…¥äº†ä¸€ç§åä¸ºPrompt Embedding Optimization (PEO)çš„æ–°æ–¹æ³•ï¼Œç”¨äºæ”¹è¿›é¢„è®­ç»ƒæ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹çš„ç¾å­¦è´¨é‡ã€‚</li>
<li>PEOåˆ©ç”¨é¢„è®­ç»ƒçš„æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹ä½œä¸ºéª¨å¹²ï¼Œä¼˜åŒ–ç»™å®šæç¤ºçš„æ–‡æœ¬åµŒå…¥ã€‚</li>
<li>é€šè¿‡ä¸‰æ–¹ç›®æ ‡å‡½æ•°æé«˜ç”Ÿæˆå›¾åƒçš„ç¾å­¦è´¨é‡ï¼Œç¡®ä¿éµå¾ªä¼˜åŒ–åçš„æ–‡æœ¬åµŒå…¥ï¼Œå¹¶å°½é‡å‡å°‘ä¸åˆå§‹æç¤ºçš„åå·®ã€‚</li>
<li>PEOå…·æœ‰æ— è®­ç»ƒçš„ç‰¹ç‚¹ï¼Œæ„å‘³ç€å®ƒä¸éœ€è¦é¢å¤–çš„è®­ç»ƒè¿‡ç¨‹ã€‚</li>
<li>PEOç‹¬ç«‹äºéª¨å¹²ï¼Œæ„å‘³ç€å®ƒå¯ä»¥åº”ç”¨äºä¸åŒçš„é¢„è®­ç»ƒæ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹ã€‚</li>
<li>å®šé‡å’Œå®šæ€§è¯„ä¼°è¡¨æ˜PEOçš„æœ‰æ•ˆæ€§ï¼Œåœ¨æŸäº›æ–¹é¢ç”šè‡³è¶…è¶Šäº†å½“å‰æœ€å…ˆè¿›çš„æ–¹æ³•ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.02599">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-cdf901f97302d7cf868c0d2382ac9d8f" align="middle">
<img src="https://picx.zhimg.com/v2-49e56f5b198027d55e9415667e3ebd8b" align="middle">
<img src="https://picx.zhimg.com/v2-73d168a8727330789daf8871f6858da8" align="middle">
<img src="https://picx.zhimg.com/v2-d22b372bec6aa3acb54c14f2de7f8881.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ebf170f4ac189c5a9912555733c4acd3" align="middle">
<img src="https://pic1.zhimg.com/v2-1abfd9fa4e2d34752ba9fa7d9d3a8fa5.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="Learning-a-distance-measure-from-the-information-estimation-geometry-of-data"><a href="#Learning-a-distance-measure-from-the-information-estimation-geometry-of-data" class="headerlink" title="Learning a distance measure from the information-estimation geometry of   data"></a>Learning a distance measure from the information-estimation geometry of   data</h2><p><strong>Authors:Guy Ohayon, Pierre-Etienne H. Fiquet, Florentin Guth, Jona BallÃ©, Eero P. Simoncelli</strong></p>
<p>We introduce the Information-Estimation Metric (IEM), a novel form of distance function derived from an underlying continuous probability density over a domain of signals. The IEM is rooted in a fundamental relationship between information theory and estimation theory, which links the log-probability of a signal with the errors of an optimal denoiser, applied to noisy observations of the signal. In particular, the IEM between a pair of signals is obtained by comparing their denoising error vectors over a range of noise amplitudes. Geometrically, this amounts to comparing the score vector fields of the blurred density around the signals over a range of blur levels. We prove that the IEM is a valid global metric and derive a closed-form expression for its local second-order approximation, which yields a Riemannian metric. For Gaussian-distributed signals, the IEM coincides with the Mahalanobis distance. But for more complex distributions, it adapts, both locally and globally, to the geometry of the distribution. In practice, the IEM can be computed using a learned denoiser (analogous to generative diffusion models) and solving a one-dimensional integral. To demonstrate the value of our framework, we learn an IEM on the ImageNet database. Experiments show that this IEM is competitive with or outperforms state-of-the-art supervised image quality metrics in predicting human perceptual judgments. </p>
<blockquote>
<p>æˆ‘ä»¬ä»‹ç»äº†ä¿¡æ¯ä¼°è®¡åº¦é‡ï¼ˆIEMï¼‰ï¼Œè¿™æ˜¯ä¸€ç§æ–°çš„è·ç¦»å‡½æ•°å½¢å¼ï¼Œå®ƒæºäºä¿¡å·åŸŸä¸Šæ½œåœ¨è¿ç»­æ¦‚ç‡å¯†åº¦çš„åˆ†å¸ƒã€‚IEM æºäºä¿¡æ¯è®ºå’Œä¼°è®¡è®ºä¹‹é—´çš„åŸºæœ¬å…³ç³»ï¼Œå®ƒè”ç³»äº†ä¸€ä¸ªä¿¡å·çš„å¯¹æ•°æ¦‚ç‡ä¸åº”ç”¨äºè¯¥ä¿¡å·çš„å¸¦å™ªå£°è§‚æµ‹çš„æœ€ä½³å»å™ªå™¨çš„è¯¯å·®ã€‚ç‰¹åˆ«åœ°ï¼Œä¸€å¯¹ä¿¡å·ä¹‹é—´çš„ IEM æ˜¯é€šè¿‡æ¯”è¾ƒå®ƒä»¬åœ¨ä¸€ç³»åˆ—å™ªå£°å¹…åº¦ä¸‹çš„å»å™ªè¯¯å·®å‘é‡è€Œè·å¾—çš„ã€‚ä»å‡ ä½•è§’åº¦ä¸Šè®²ï¼Œè¿™ç›¸å½“äºåœ¨ä¸€ç³»åˆ—æ¨¡ç³Šçº§åˆ«ä¸‹æ¯”è¾ƒå›´ç»•ä¿¡å·çš„æ¨¡ç³Šå¯†åº¦å¾—åˆ†å‘é‡åœºã€‚æˆ‘ä»¬è¯æ˜äº† IEM æ˜¯ä¸€ä¸ªæœ‰æ•ˆçš„å…¨å±€åº¦é‡ï¼Œå¹¶æ¨å¯¼å‡ºäº†å…¶å±€éƒ¨äºŒé˜¶è¿‘ä¼¼çš„é—­å¼è¡¨è¾¾å¼ï¼Œè¿™äº§ç”Ÿäº†ä¸€ä¸ªé»æ›¼åº¦é‡ã€‚å¯¹äºé«˜æ–¯åˆ†å¸ƒçš„ä¿¡å·ï¼ŒIEM ä¸é©¬æ°è·ç¦»ç›¸ç¬¦ã€‚ä½†å¯¹äºæ›´å¤æ‚çš„åˆ†å¸ƒï¼Œå®ƒä¼šåœ¨å±€éƒ¨å’Œå…¨å±€é€‚åº”åˆ†å¸ƒå‡ ä½•ã€‚åœ¨å®è·µä¸­ï¼Œå¯ä»¥ä½¿ç”¨å­¦ä¹ åˆ°çš„å»å™ªå™¨ï¼ˆç±»ä¼¼äºç”Ÿæˆæ‰©æ•£æ¨¡å‹ï¼‰å¹¶æ±‚è§£ä¸€ç»´ç§¯åˆ†æ¥è®¡ç®— IEMã€‚ä¸ºäº†è¯æ˜æˆ‘ä»¬æ¡†æ¶çš„ä»·å€¼ï¼Œæˆ‘ä»¬åœ¨ ImageNet æ•°æ®åº“ä¸Šå­¦ä¹ äº† IEMã€‚å®éªŒè¡¨æ˜ï¼Œè¯¥ IEM åœ¨é¢„æµ‹äººç±»æ„ŸçŸ¥åˆ¤æ–­æ–¹é¢ä¸æœ€å…ˆè¿›çš„ç›‘ç£å›¾åƒè´¨é‡æŒ‡æ ‡ç«äº‰æˆ–ä¼˜äºåè€…ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.02514v1">PDF</a> Code available at   <a target="_blank" rel="noopener" href="https://github.com/ohayonguy/information-estimation-metric">https://github.com/ohayonguy/information-estimation-metric</a></p>
<p><strong>Summary</strong><br>     ä¿¡æ¯ä¼°è®¡åº¦é‡ï¼ˆIEMï¼‰æ˜¯ä¸€ç§æ–°å‹çš„è·ç¦»å‡½æ•°ï¼Œå®ƒåŸºäºä¿¡å·åŸŸä¸Šçš„è¿ç»­æ¦‚ç‡å¯†åº¦åˆ†å¸ƒã€‚IEM æºäºä¿¡æ¯è®ºä¸ä¼°è®¡è®ºä¹‹é—´çš„åŸºæœ¬å…³ç³»ï¼Œå®ƒå°†ä¿¡å·çš„æ—¥å¿—æ¦‚ç‡ä¸åº”ç”¨äºå™ªå£°è§‚æµ‹ä¿¡å·çš„æœ€ä½³å»å™ªå™¨çš„è¯¯å·®è”ç³»èµ·æ¥ã€‚é€šè¿‡å¯¹ä¸€ç³»åˆ—å™ªå£°å¹…åº¦ä¸‹çš„å»å™ªè¯¯å·®å‘é‡è¿›è¡Œæ¯”è¾ƒï¼Œè·å¾—ä¸¤ä¸ªä¿¡å·ä¹‹é—´çš„ IEMã€‚ä»å‡ ä½•è§’åº¦æ¥çœ‹ï¼Œç›¸å½“äºæ¯”è¾ƒä¸€ç³»åˆ—æ¨¡ç³Šåº¦ä¸‹çš„å›´ç»•ä¿¡å·çš„æ¨¡ç³Šå¯†åº¦å¾—åˆ†å‘é‡åœºã€‚è¯æ˜ IEM æ˜¯ä¸€ç§æœ‰æ•ˆçš„å…¨å±€åº¦é‡ï¼Œå¹¶æ¨å¯¼å‡ºå…¶å±€éƒ¨äºŒé˜¶è¿‘ä¼¼çš„å°é—­å½¢å¼è¡¨è¾¾å¼ï¼Œä»è€Œäº§ç”Ÿé»æ›¼åº¦é‡ã€‚å¯¹äºé«˜æ–¯åˆ†å¸ƒçš„ä¿¡å·ï¼ŒIEM ä¸é©¬æ°è·ç¦»ç›¸ç¬¦ï¼›è€Œå¯¹äºæ›´å¤æ‚çš„åˆ†å¸ƒï¼ŒIEM å¯é€‚åº”åˆ†å¸ƒçš„å±€éƒ¨å’Œå…¨å±€å‡ ä½•ç‰¹æ€§ã€‚å®è·µä¸­ï¼Œå¯ä½¿ç”¨å­¦ä¹ åˆ°çš„å»å™ªå™¨ï¼ˆç±»ä¼¼äºç”Ÿæˆæ‰©æ•£æ¨¡å‹ï¼‰å¹¶æ±‚è§£ä¸€ç»´ç§¯åˆ†æ¥è®¡ç®— IEMã€‚åœ¨ ImageNet æ•°æ®åº“ä¸Šå­¦ä¹ çš„ IEM è¡¨æ˜ï¼Œå®ƒåœ¨é¢„æµ‹äººç±»æ„ŸçŸ¥åˆ¤æ–­æ–¹é¢è¡¨ç°å‡ºç«äº‰åŠ›ï¼Œç”šè‡³è¶…è¿‡ç°æœ‰çš„æœ€å…ˆè¿›çš„ç›‘ç£å›¾åƒè´¨é‡åº¦é‡ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ä¿¡æ¯ä¼°è®¡åº¦é‡ï¼ˆIEMï¼‰æ˜¯ä¸€ç§æ–°å‹è·ç¦»å‡½æ•°ï¼ŒåŸºäºä¿¡å·åŸŸä¸Šçš„è¿ç»­æ¦‚ç‡å¯†åº¦åˆ†å¸ƒã€‚</li>
<li>IEM æºäºä¿¡æ¯è®ºä¸ä¼°è®¡è®ºçš„ç»“åˆï¼Œå…³è”ä¿¡å·çš„æ—¥å¿—æ¦‚ç‡ä¸å»å™ªå™¨è¯¯å·®ã€‚</li>
<li>é€šè¿‡æ¯”è¾ƒä¸åŒå™ªå£°å¹…åº¦ä¸‹çš„å»å™ªè¯¯å·®å‘é‡ï¼Œè®¡ç®—ä¸¤ä¸ªä¿¡å·ä¹‹é—´çš„ IEMã€‚</li>
<li>IEM åœ¨å‡ ä½•ä¸Šè¡¨ç°ä¸ºæ¯”è¾ƒæ¨¡ç³Šå¯†åº¦å¾—åˆ†å‘é‡åœºã€‚</li>
<li>IEM è¢«è¯æ˜æ˜¯ä¸€ç§æœ‰æ•ˆçš„å…¨å±€åº¦é‡ï¼Œå¹¶å…·å¤‡é»æ›¼åº¦é‡çš„å±€éƒ¨äºŒé˜¶è¿‘ä¼¼å½¢å¼ã€‚</li>
<li>å¯¹äºä¸åŒåˆ†å¸ƒçš„ä¿¡å·ï¼ŒIEM èƒ½è‡ªé€‚åº”è°ƒæ•´ï¼Œå°¤å…¶å¯¹äºå¤æ‚åˆ†å¸ƒã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.02514">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-c42ee7948574418b46a79aebf7fcf8e4.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-fb2d0711af70b6cacbb5ef08312826c1" align="middle">
<img src="https://picx.zhimg.com/v2-80674e346482949e4408e286ad5f7eab" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="UniVerse-Unleashing-the-Scene-Prior-of-Video-Diffusion-Models-for-Robust-Radiance-Field-Reconstruction"><a href="#UniVerse-Unleashing-the-Scene-Prior-of-Video-Diffusion-Models-for-Robust-Radiance-Field-Reconstruction" class="headerlink" title="UniVerse: Unleashing the Scene Prior of Video Diffusion Models for   Robust Radiance Field Reconstruction"></a>UniVerse: Unleashing the Scene Prior of Video Diffusion Models for   Robust Radiance Field Reconstruction</h2><p><strong>Authors:Jin Cao, Hongrui Wu, Ziyong Feng, Hujun Bao, Xiaowei Zhou, Sida Peng</strong></p>
<p>This paper tackles the challenge of robust reconstruction, i.e., the task of reconstructing a 3D scene from a set of inconsistent multi-view images. Some recent works have attempted to simultaneously remove image inconsistencies and perform reconstruction by integrating image degradation modeling into neural 3D scene representations. However, these methods rely heavily on dense observations for robustly optimizing model parameters. To address this issue, we propose to decouple robust reconstruction into two subtasks: restoration and reconstruction, which naturally simplifies the optimization process. To this end, we introduce UniVerse, a unified framework for robust reconstruction based on a video diffusion model. Specifically, UniVerse first converts inconsistent images into initial videos, then uses a specially designed video diffusion model to restore them into consistent images, and finally reconstructs the 3D scenes from these restored images. Compared with case-by-case per-view degradation modeling, the diffusion model learns a general scene prior from large-scale data, making it applicable to diverse image inconsistencies. Extensive experiments on both synthetic and real-world datasets demonstrate the strong generalization capability and superior performance of our method in robust reconstruction. Moreover, UniVerse can control the style of the reconstructed 3D scene. Project page: <a target="_blank" rel="noopener" href="https://jin-cao-tma.github.io/UniVerse.github.io/">https://jin-cao-tma.github.io/UniVerse.github.io/</a> </p>
<blockquote>
<p>æœ¬æ–‡è§£å†³äº†ç¨³å¥é‡å»ºçš„æŒ‘æˆ˜ï¼Œå³ä»ä¸€ä¸ªä¸ä¸€è‡´çš„å¤šè§†è§’å›¾åƒé›†ä¸­é‡å»ºä¸€ä¸ªä¸‰ç»´åœºæ™¯çš„ä»»åŠ¡ã€‚ä¸€äº›è¿‘æœŸçš„å·¥ä½œå°è¯•é€šè¿‡æ•´åˆå›¾åƒé€€åŒ–å»ºæ¨¡åˆ°ç¥ç»ä¸‰ç»´åœºæ™¯è¡¨ç¤ºä¸­æ¥åŒæ—¶ç§»é™¤å›¾åƒçš„ä¸ä¸€è‡´æ€§å’Œè¿›è¡Œé‡å»ºã€‚ç„¶è€Œï¼Œè¿™äº›æ–¹æ³•ä¸¥é‡ä¾èµ–äºå¯†é›†çš„è§‚æµ‹ç»“æœä»¥ç¨³å¥åœ°ä¼˜åŒ–æ¨¡å‹å‚æ•°ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬æè®®å°†ç¨³å¥é‡å»ºåˆ†è§£æˆä¸¤ä¸ªå­ä»»åŠ¡ï¼šæ¢å¤å’Œé‡å»ºï¼Œè¿™è‡ªç„¶åœ°ç®€åŒ–äº†ä¼˜åŒ–è¿‡ç¨‹ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬å¼•å…¥äº†UniVerseï¼Œè¿™æ˜¯ä¸€ä¸ªåŸºäºè§†é¢‘æ‰©æ•£æ¨¡å‹çš„ç¨³å¥é‡å»ºçš„ç»Ÿä¸€æ¡†æ¶ã€‚å…·ä½“æ¥è¯´ï¼ŒUniVerseé¦–å…ˆæŠŠä¸ä¸€è‡´çš„å›¾åƒè½¬æ¢æˆåˆå§‹è§†é¢‘ï¼Œç„¶åä½¿ç”¨ä¸“é—¨è®¾è®¡çš„è§†é¢‘æ‰©æ•£æ¨¡å‹å°†å®ƒä»¬æ¢å¤æˆä¸€è‡´çš„å›¾åƒï¼Œå¹¶æœ€ç»ˆä»è¿™äº›æ¢å¤çš„å›¾åƒä¸­é‡å»ºä¸‰ç»´åœºæ™¯ã€‚ä¸é’ˆå¯¹æ¯ä¸ªè§†å›¾çš„é€€åŒ–å»ºæ¨¡ç›¸æ¯”ï¼Œæ‰©æ•£æ¨¡å‹ä»å¤§è§„æ¨¡æ•°æ®ä¸­å­¦ä¹ ä¸€èˆ¬çš„åœºæ™¯å…ˆéªŒï¼Œä½¿å…¶é€‚ç”¨äºå¤šç§å›¾åƒä¸ä¸€è‡´æ€§ã€‚åœ¨åˆæˆå’ŒçœŸå®ä¸–ç•Œæ•°æ®é›†ä¸Šçš„å¤§é‡å®éªŒè¯æ˜äº†æˆ‘ä»¬çš„æ–¹æ³•åœ¨ç¨³å¥é‡å»ºä¸­çš„å¼ºå¤§é€šç”¨æ€§å’Œå“è¶Šæ€§èƒ½ã€‚æ­¤å¤–ï¼ŒUniVerseå¯ä»¥æ§åˆ¶é‡å»ºçš„ä¸‰ç»´åœºæ™¯çš„é£æ ¼ã€‚é¡¹ç›®é¡µé¢ï¼š<a target="_blank" rel="noopener" href="https://jin-cao-tma.github.io/UniVerse.github.io/">https://jin-cao-tma.github.io/UniVerse.github.io/</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.01669v2">PDF</a> page: <a target="_blank" rel="noopener" href="https://jin-cao-tma.github.io/UniVerse.github.io/">https://jin-cao-tma.github.io/UniVerse.github.io/</a> code:   <a target="_blank" rel="noopener" href="https://github.com/zju3dv/UniVerse">https://github.com/zju3dv/UniVerse</a></p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºä¸€ç§åŸºäºè§†é¢‘æ‰©æ•£æ¨¡å‹çš„ç¨³å¥é‡å»ºæ–¹æ³•UniVerseï¼Œç”¨äºä»ä¸€ç»„ä¸ä¸€è‡´çš„å¤šè§†è§’å›¾åƒé‡å»º3Dåœºæ™¯ã€‚è¯¥æ–¹æ³•å°†é‡å»ºè¿‡ç¨‹åˆ†è§£ä¸ºä¸¤ä¸ªå­ä»»åŠ¡ï¼šä¿®å¤å’Œé‡å»ºï¼Œç®€åŒ–äº†ä¼˜åŒ–è¿‡ç¨‹ã€‚å®ƒé€šè¿‡è§†é¢‘æ‰©æ•£æ¨¡å‹å°†ä¸ä¸€è‡´çš„å›¾åƒè½¬æ¢ä¸ºåˆå§‹è§†é¢‘ï¼Œå†æ¢å¤æˆä¸€è‡´å›¾åƒï¼Œå¹¶ä»è¿™äº›æ¢å¤åçš„å›¾åƒé‡å»º3Dåœºæ™¯ã€‚æ­¤æ–¹æ³•å…·æœ‰å¼ºå¤§çš„æ³›åŒ–èƒ½åŠ›å’Œå“è¶Šæ€§èƒ½ï¼Œå¹¶ä¸”å¯ä»¥æ§åˆ¶é‡å»º3Dåœºæ™¯çš„é£æ ¼ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æœ¬æ–‡è§£å†³äº†ä»å¤šä¸ªä¸ä¸€è‡´çš„è§†è§’å›¾åƒä¸­é‡å»º3Dåœºæ™¯çš„éš¾é¢˜ã€‚</li>
<li>æå‡ºä¸€ç§åŸºäºè§†é¢‘æ‰©æ•£æ¨¡å‹çš„ç¨³å¥é‡å»ºæ–¹æ³•â€”â€”UniVerseã€‚</li>
<li>UniVerseå°†é‡å»ºè¿‡ç¨‹åˆ†è§£ä¸ºä¿®å¤å’Œé‡å»ºä¸¤ä¸ªå­ä»»åŠ¡ï¼Œç®€åŒ–äº†ä¼˜åŒ–æµç¨‹ã€‚</li>
<li>UniVerseä½¿ç”¨è§†é¢‘æ‰©æ•£æ¨¡å‹å°†ä¸ä¸€è‡´çš„å›¾åƒè½¬æ¢ä¸ºåˆå§‹è§†é¢‘ï¼Œç„¶åæ¢å¤æˆä¸€è‡´å›¾åƒã€‚</li>
<li>è¯¥æ–¹æ³•å…·æœ‰å¼ºå¤§çš„æ³›åŒ–èƒ½åŠ›ï¼Œå¯åœ¨åˆæˆå’ŒçœŸå®ä¸–ç•Œæ•°æ®é›†ä¸Šè¡¨ç°å‡ºå“è¶Šæ€§èƒ½ã€‚</li>
<li>UniVerseèƒ½å¤„ç†å¤šç§å›¾åƒä¸ä¸€è‡´æ€§ï¼Œå› ä¸ºæ‰©æ•£æ¨¡å‹ä»å¤§è§„æ¨¡æ•°æ®ä¸­å­¦ä¹ åœºæ™¯çš„ä¸€èˆ¬å…ˆéªŒã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.01669">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-724373b69b7a18ea1670905f4450b13d" align="middle">
<img src="https://picx.zhimg.com/v2-5501dfb87dc50804467653c7e96b4c1c" align="middle">
<img src="https://picx.zhimg.com/v2-ab4ce4622f5a6100842c5ee32d7cbe5e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a4e918d3000208f12a9d78ed9099a266" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="RichControl-Structure-and-Appearance-Rich-Training-Free-Spatial-Control-for-Text-to-Image-Generation"><a href="#RichControl-Structure-and-Appearance-Rich-Training-Free-Spatial-Control-for-Text-to-Image-Generation" class="headerlink" title="RichControl: Structure- and Appearance-Rich Training-Free Spatial   Control for Text-to-Image Generation"></a>RichControl: Structure- and Appearance-Rich Training-Free Spatial   Control for Text-to-Image Generation</h2><p><strong>Authors:Liheng Zhang, Lexi Pang, Hang Ye, Xiaoxuan Ma, Yizhou Wang</strong></p>
<p>Text-to-image (T2I) diffusion models have shown remarkable success in generating high-quality images from text prompts. Recent efforts extend these models to incorporate conditional images (e.g., canny edge) for fine-grained spatial control. Among them, feature injection methods have emerged as a training-free alternative to traditional fine-tuning-based approaches. However, they often suffer from structural misalignment, condition leakage, and visual artifacts, especially when the condition image diverges significantly from natural RGB distributions. Through an empirical analysis of existing methods, we identify a key limitation: the sampling schedule of condition features, previously unexplored, fails to account for the evolving interplay between structure preservation and domain alignment throughout diffusion steps. Inspired by this observation, we propose a flexible training-free framework that decouples the sampling schedule of condition features from the denoising process, and systematically investigate the spectrum of feature injection schedules for a higher-quality structure guidance in the feature space. Specifically, we find that condition features sampled from a single timestep are sufficient, yielding a simple yet efficient schedule that balances structure alignment and appearance quality. We further enhance the sampling process by introducing a restart refinement schedule, and improve the visual quality with an appearance-rich prompting strategy. Together, these designs enable training-free generation that is both structure-rich and appearance-rich. Extensive experiments show that our approach achieves state-of-the-art results across diverse zero-shot conditioning scenarios. </p>
<blockquote>
<p>æ–‡æœ¬åˆ°å›¾åƒï¼ˆT2Iï¼‰æ‰©æ•£æ¨¡å‹åœ¨æ ¹æ®æ–‡æœ¬æç¤ºç”Ÿæˆé«˜è´¨é‡å›¾åƒæ–¹é¢å–å¾—äº†æ˜¾è‘—çš„æˆåŠŸã€‚æœ€è¿‘çš„ç ”ç©¶åŠªåŠ›å°†è¿™äº›æ¨¡å‹æ‰©å±•åˆ°ç»“åˆæ¡ä»¶å›¾åƒï¼ˆä¾‹å¦‚ï¼ŒCannyè¾¹ç¼˜ï¼‰è¿›è¡Œç²¾ç»†çš„ç©ºé—´æ§åˆ¶ã€‚å…¶ä¸­ï¼Œç‰¹å¾æ³¨å…¥æ–¹æ³•ä½œä¸ºä¸€ç§æ— éœ€è®­ç»ƒçš„ä¼ ç»Ÿå¾®è°ƒæ–¹æ³•çš„æ›¿ä»£æ–¹æ¡ˆè€Œå‡ºç°ã€‚ç„¶è€Œï¼Œå®ƒä»¬ç»å¸¸é­å—ç»“æ„é”™ä½ã€æ¡ä»¶æ³„æ¼å’Œè§†è§‰ä¼ªå½±çš„é—®é¢˜ï¼Œå°¤å…¶æ˜¯å½“æ¡ä»¶å›¾åƒä¸è‡ªç„¶çš„RGBåˆ†å¸ƒç›¸å·®å¾ˆå¤§æ—¶ã€‚é€šè¿‡å¯¹ç°æœ‰æ–¹æ³•çš„å®è¯åˆ†æï¼Œæˆ‘ä»¬ç¡®å®šäº†ä¸€ä¸ªå…³é”®é™åˆ¶ï¼šä¹‹å‰æœªè¢«æ¢ç´¢çš„æ¡ä»¶ç‰¹å¾çš„é‡‡æ ·æ—¶é—´è¡¨æœªèƒ½è€ƒè™‘åˆ°ç»“æ„ä¿å­˜åœ¨æ‰©æ•£æ­¥éª¤ä¸­çš„ä¸æ–­æ¼”å˜å’Œé¢†åŸŸå¯¹é½çš„äº¤äº’ä½œç”¨ã€‚å—æ­¤è§‚å¯Ÿçš„å¯å‘ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªçµæ´»çš„æ— éœ€è®­ç»ƒæ¡†æ¶ï¼Œè¯¥æ¡†æ¶å°†æ¡ä»¶ç‰¹å¾çš„é‡‡æ ·æ—¶é—´è¡¨ä¸å»å™ªè¿‡ç¨‹è§£è€¦ï¼Œå¹¶ç³»ç»Ÿåœ°ç ”ç©¶äº†ç‰¹å¾æ³¨å…¥æ—¶é—´è¡¨çš„é¢‘è°±ï¼Œä»¥åœ¨ç‰¹å¾ç©ºé—´ä¸­å®ç°æ›´é«˜è´¨é‡çš„ç»“æ„å¼•å¯¼ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬å‘ç°ä»å•ä¸€æ—¶é—´æ­¥é•¿é‡‡æ ·çš„æ¡ä»¶ç‰¹å¾å°±è¶³å¤Ÿäº†ï¼Œä»è€Œäº§ç”Ÿäº†ä¸€ä¸ªç®€å•è€Œé«˜æ•ˆçš„æ—¶é—´è¡¨ï¼Œå¹³è¡¡äº†ç»“æ„å¯¹é½å’Œå¤–è§‚è´¨é‡ã€‚æˆ‘ä»¬è¿›ä¸€æ­¥é€šè¿‡å¼•å…¥é‡å¯ç»†åŒ–æ—¶é—´è¡¨æ¥å¢å¼ºé‡‡æ ·è¿‡ç¨‹ï¼Œå¹¶ä½¿ç”¨ä¸°å¯Œçš„å¤–è§‚æç¤ºç­–ç•¥æé«˜äº†è§†è§‰è´¨é‡ã€‚è¿™äº›è®¾è®¡å…±åŒå®ç°äº†æ— éœ€è®­ç»ƒçš„ç”Ÿæˆï¼Œæ—¢ä¸°å¯Œç»“æ„åˆä¸°å¯Œå¤–è§‚ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨å¤šç§é›¶æ ·æœ¬æ¡ä»¶åœºæ™¯ä¸‹é¢å®ç°äº†æœ€ä½³ç»“æœã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2507.02792v3">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æ–‡æœ¬åˆ°å›¾åƒï¼ˆT2Iï¼‰æ‰©æ•£æ¨¡å‹å·²æˆåŠŸå®ç°æ ¹æ®æ–‡æœ¬æç¤ºç”Ÿæˆé«˜è´¨é‡å›¾åƒã€‚è¿‘æœŸç ”ç©¶å°è¯•å°†æ¡ä»¶å›¾åƒçº³å…¥å…¶ä¸­ä»¥å®ç°ç²¾ç»†çš„ç©ºé—´æ§åˆ¶ã€‚ç‰¹å¾æ³¨å…¥æ–¹æ³•ä½œä¸ºä¸€ç§æ— è®­ç»ƒçš„æ–¹æ³•ï¼Œè¢«æå‡ºä»¥è§£å†³ä¼ ç»Ÿå¾®è°ƒæ–¹æ³•æ‰€é‡åˆ°çš„è®¸å¤šé—®é¢˜ï¼Œä¾‹å¦‚ç»“æ„ä¸å¯¹é½ã€æ¡ä»¶æ³„æ¼å’Œè§†è§‰ä¼ªå½±ç­‰ã€‚æœ¬æ–‡åˆ†æäº†ç°æœ‰æ–¹æ³•çš„é‡‡æ ·æ—¶é—´è¡¨ï¼Œå‘ç°å…¶å¯¹æ‰©æ•£æ­¥éª¤ä¸­çš„ç»“æ„ä¿æŒå’Œé¢†åŸŸå¯¹é½çš„ç›¸äº’ä½œç”¨è€ƒè™‘ä¸è¶³ã€‚å› æ­¤ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ä¸ªçµæ´»çš„æ— è®­ç»ƒæ¡†æ¶ï¼Œå°†æ¡ä»¶ç‰¹å¾çš„é‡‡æ ·æ—¶é—´è¡¨ä¸å»å™ªè¿‡ç¨‹åˆ†ç¦»ï¼Œå¹¶ç³»ç»Ÿåœ°ç ”ç©¶äº†ç‰¹å¾æ³¨å…¥çš„æ—¶é—´è¡¨ï¼Œä»¥åœ¨ç‰¹å¾ç©ºé—´ä¸­å®ç°æ›´é«˜è´¨é‡çš„ç»“æ„å¼•å¯¼ã€‚å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨é›¶æ ·æœ¬æ¡ä»¶åœºæ™¯ä¸‹çš„ç»“æœè¾¾åˆ°é¢†å…ˆæ°´å¹³ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æ–‡æœ¬åˆ°å›¾åƒï¼ˆT2Iï¼‰æ‰©æ•£æ¨¡å‹å¯æ ¹æ®æ–‡æœ¬æç¤ºç”Ÿæˆé«˜è´¨é‡å›¾åƒã€‚</li>
<li>æ¡ä»¶å›¾åƒçº³å…¥æ¨¡å‹å¯å®ç°æ›´ç²¾ç»†çš„ç©ºé—´æ§åˆ¶ã€‚</li>
<li>ç‰¹å¾æ³¨å…¥æ–¹æ³•ä½œä¸ºä¸€ç§æ— è®­ç»ƒæ–¹æ¡ˆè§£å†³äº†ä¼ ç»Ÿå¾®è°ƒæ–¹æ³•çš„é—®é¢˜ï¼Œä½†ä»é¢ä¸´ç»“æ„ä¸å¯¹é½ç­‰é—®é¢˜ã€‚</li>
<li>æœ¬æ–‡å‘ç°äº†ç°æœ‰æ–¹æ³•é‡‡æ ·æ—¶é—´è¡¨çš„ä¸è¶³ï¼Œæå‡ºäº†çµæ´»çš„æ¡†æ¶è¿›è¡Œç³»ç»Ÿæ€§çš„ç ”ç©¶ã€‚</li>
<li>å•æ­¥é‡‡æ ·æ¡ä»¶ç‰¹å¾ç­–ç•¥æ‰¾åˆ°äº†ç»“æ„å¯¹é½å’Œå¤–è§‚è´¨é‡ä¹‹é—´çš„å¹³è¡¡ã€‚</li>
<li>é€šè¿‡å¼•å…¥é‡å¯ä¼˜åŒ–é‡‡æ ·è¿‡ç¨‹å’Œå¤–è§‚ä¸°å¯Œçš„æç¤ºç­–ç•¥ï¼Œè¿›ä¸€æ­¥æé«˜äº†è§†è§‰è´¨é‡å’Œç»“æ„ä¸°å¯Œæ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2507.02792">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-c45788f3da04c35c0fd852a7f7612657" align="middle">
<img src="https://picx.zhimg.com/v2-78e1b3e6ac1cce4c521df78bdc662461" align="middle">
<img src="https://picx.zhimg.com/v2-064daca12f72582d450ea7a4e53d8893" align="middle">
<img src="https://picx.zhimg.com/v2-0f6d62a7a2a3d2448f3ffeffcd73f9bc" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="Rethinking-the-Vulnerability-of-Concept-Erasure-and-a-New-Method"><a href="#Rethinking-the-Vulnerability-of-Concept-Erasure-and-a-New-Method" class="headerlink" title="Rethinking the Vulnerability of Concept Erasure and a New Method"></a>Rethinking the Vulnerability of Concept Erasure and a New Method</h2><p><strong>Authors:Alex D. Richardson, Kaicheng Zhang, Lucas Beerens, Dongdong Chen</strong></p>
<p>The proliferation of text-to-image diffusion models has raised significant privacy and security concerns, particularly regarding the generation of copyrighted or harmful images. In response, concept erasure (defense) methods have been developed to â€œunlearnâ€ specific concepts through post-hoc finetuning. However, recent concept restoration (attack) methods have demonstrated that these supposedly erased concepts can be recovered using adversarially crafted prompts, revealing a critical vulnerability in current defense mechanisms. In this work, we first investigate the fundamental sources of adversarial vulnerability and reveal that vulnerabilities are pervasive in the prompt embedding space of concept-erased models, a characteristic inherited from the original pre-unlearned model. Furthermore, we introduce <strong>RECORD</strong>, a novel coordinate-descent-based restoration algorithm that consistently outperforms existing restoration methods by up to 17.8 times. We conduct extensive experiments to assess its compute-performance tradeoff and propose acceleration strategies. </p>
<blockquote>
<p>æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹çš„æ™®åŠå¼•å‘äº†é‡å¤§éšç§å’Œå®‰å…¨é—®é¢˜ï¼Œå°¤å…¶æ˜¯å…³äºç”Ÿæˆç‰ˆæƒæˆ–æœ‰å®³å›¾åƒçš„é—®é¢˜ã€‚ä½œä¸ºå›åº”ï¼Œå·²ç»å¼€å‘äº†æ¦‚å¿µæ¶ˆé™¤ï¼ˆé˜²å¾¡ï¼‰æ–¹æ³•ï¼Œé€šè¿‡äº‹åå¾®è°ƒæ¥â€œé—å¿˜â€ç‰¹å®šæ¦‚å¿µã€‚ç„¶è€Œï¼Œæœ€æ–°çš„æ¦‚å¿µæ¢å¤ï¼ˆæ”»å‡»ï¼‰æ–¹æ³•å·²ç»è¯æ˜ï¼Œè¿™äº›è¢«è®¤ä¸ºå·²ç»è¢«åˆ é™¤çš„æ¦‚å¿µå¯ä»¥ä½¿ç”¨å¯¹æŠ—æ€§æ„å»ºçš„æç¤ºè¿›è¡Œæ¢å¤ï¼Œè¿™æ­ç¤ºäº†å½“å‰é˜²å¾¡æœºåˆ¶ä¸­çš„å…³é”®æ¼æ´ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬é¦–å…ˆç ”ç©¶å¯¹æŠ—æ€§æ¼æ´çš„æ ¹æœ¬æ¥æºï¼Œå¹¶æ­ç¤ºæ¦‚å¿µæ¶ˆé™¤æ¨¡å‹çš„æç¤ºåµŒå…¥ç©ºé—´ä¸­æ™®éå­˜åœ¨æ¼æ´ï¼Œè¿™æ˜¯ä»åŸå§‹æœªå­¦ä¹ æ¨¡å‹ç»§æ‰¿çš„ç‰¹å¾ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å¼•å…¥äº†åŸºäºåæ ‡ä¸‹é™çš„æ–°æ¢å¤ç®—æ³•<strong>RECORD</strong>ï¼Œå®ƒå§‹ç»ˆä¼˜äºç°æœ‰æ¢å¤æ–¹æ³•ï¼Œæœ€é«˜å¯è¾¾1.7å€ã€‚æˆ‘ä»¬è¿›è¡Œäº†å¤§é‡å®éªŒæ¥è¯„ä¼°å…¶è®¡ç®—æ€§èƒ½æŠ˜è¡·ï¼Œå¹¶æå‡ºäº†åŠ é€Ÿç­–ç•¥ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.17537v3">PDF</a> </p>
<p><strong>Summary</strong><br>     æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹çš„æ™®åŠå¼•å‘äº†å…³äºç”Ÿæˆç‰ˆæƒæˆ–æœ‰å®³å›¾åƒçš„éšç§å’Œå®‰å…¨æ‹…å¿§ã€‚ä¸ºæ­¤ï¼Œå¼€å‘äº†æ¦‚å¿µæ¶ˆé™¤ï¼ˆé˜²å¾¡ï¼‰æ–¹æ³•ï¼Œé€šè¿‡å¾®è°ƒåçš„æ¨¡å‹è¿›è¡Œç‰¹å®šçš„æ¦‚å¿µé—å¿˜ã€‚ç„¶è€Œï¼Œæœ€æ–°çš„æ¦‚å¿µæ¢å¤ï¼ˆæ”»å‡»ï¼‰æ–¹æ³•è¯æ˜ï¼Œè¿™äº›è¢«æ¶ˆé™¤çš„æ¦‚å¿µå¯ä»¥é€šè¿‡å¯¹æŠ—æ€§æ„é€ çš„æç¤ºè¿›è¡Œæ¢å¤ï¼Œæ­ç¤ºäº†å½“å‰é˜²å¾¡æœºåˆ¶çš„é‡å¤§æ¼æ´ã€‚æœ¬ç ”ç©¶æ·±å…¥æ¢è®¨äº†å¯¹æŠ—æ€§æ¼æ´çš„æ ¹æœ¬æ¥æºï¼Œæ­ç¤ºäº†æ¦‚å¿µæ¶ˆé™¤æ¨¡å‹çš„æç¤ºåµŒå…¥ç©ºé—´ä¸­æ™®éå­˜åœ¨æ¼æ´ï¼Œè¿™ä¸€ç‰¹æ€§ç»§æ‰¿äº†æœªå­¦ä¹ å‰çš„åŸå§‹æ¨¡å‹çš„ç‰¹ç‚¹ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å¼•å…¥äº†æ–°å‹çš„åŸºäºåæ ‡ä¸‹é™çš„æ¢å¤ç®—æ³•RECORDï¼Œè¯¥ç®—æ³•åœ¨æ€§èƒ½ä¸Šä¸€ç›´ä¼˜äºç°æœ‰æ¢å¤æ–¹æ³•ï¼Œæœ€é«˜æå‡äº†è¾¾17.8å€ã€‚æˆ‘ä»¬è¿›è¡Œäº†å¤§é‡å®éªŒæ¥è¯„ä¼°å…¶è®¡ç®—æ€§èƒ½æƒè¡¡å¹¶æå‡ºäº†åŠ é€Ÿç­–ç•¥ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹çš„æ™®åŠå¼•å‘äº†å…³äºç”Ÿæˆç‰ˆæƒæˆ–æœ‰å®³å›¾åƒçš„éšç§å’Œå®‰å…¨æ‹…å¿§ã€‚</li>
<li>æ¦‚å¿µæ¶ˆé™¤ï¼ˆé˜²å¾¡ï¼‰æ–¹æ³•æ—¨åœ¨é€šè¿‡å¾®è°ƒæ¨¡å‹æ¥é—å¿˜ç‰¹å®šæ¦‚å¿µã€‚</li>
<li>ç°æœ‰çš„æ¦‚å¿µæ¶ˆé™¤æ–¹æ³•å­˜åœ¨é‡å¤§æ¼æ´ï¼Œå¯ä»¥è¢«æ¦‚å¿µæ¢å¤ï¼ˆæ”»å‡»ï¼‰æ–¹æ³•åˆ©ç”¨ã€‚</li>
<li>å¯¹æŠ—æ€§æ„é€ çš„æç¤ºå¯ç”¨äºæ¢å¤è¢«æ¶ˆé™¤çš„æ¦‚å¿µã€‚</li>
<li>æ¦‚å¿µæ¶ˆé™¤æ¨¡å‹çš„æç¤ºåµŒå…¥ç©ºé—´æ™®éå­˜åœ¨æ¼æ´ï¼Œè¿™ä¸€ç‰¹æ€§ç»§æ‰¿è‡ªåŸå§‹æ¨¡å‹ã€‚</li>
<li>å¼•å…¥äº†æ–°å‹çš„åŸºäºåæ ‡ä¸‹é™çš„æ¢å¤ç®—æ³•RECORDï¼Œå…¶æ€§èƒ½æ˜¾è‘—ä¼˜äºç°æœ‰æ¢å¤æ–¹æ³•ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.17537">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-b3d0f91645e5e18a6f4cefe3b8393ee7" align="middle">
<img src="https://picx.zhimg.com/v2-c643f7e64cfbf237f41a337bbdf2892b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-679c81a8e796b3f0d9e8aff57d4cbe7e" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-10-07/Diffusion%20Models/">https://kedreamix.github.io/Talk2Paper/Paper/2025-10-07/Diffusion%20Models/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/Diffusion-Models/">
                                    <span class="chip bg-color">Diffusion Models</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-10-07/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-b144204b970c44b83070e0ed2780eb32" class="responsive-img" alt="åŒ»å­¦å›¾åƒ">
                        
                        <span class="card-title">åŒ»å­¦å›¾åƒ</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            åŒ»å­¦å›¾åƒ æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-10-07  Wave-GMS Lightweight Multi-Scale Generative Model for Medical Image   Segmentation
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-10-07
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/" class="post-category">
                                    åŒ»å­¦å›¾åƒ
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/">
                        <span class="chip bg-color">åŒ»å­¦å›¾åƒ</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-10-07/NeRF/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-408eb3e041df5b2193760a92cbca85a4" class="responsive-img" alt="NeRF">
                        
                        <span class="card-title">NeRF</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            NeRF æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-10-07  ROGR Relightable 3D Objects using Generative Relighting
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-10-07
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/NeRF/" class="post-category">
                                    NeRF
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/NeRF/">
                        <span class="chip bg-color">NeRF</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">32298.5k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
