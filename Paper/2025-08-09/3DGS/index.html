<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="3DGS">
    <meta name="description" content="3DGS 方向最新论文已更新，请持续关注 Update in 2025-08-09  GAP Gaussianize Any Point Clouds with Text Guidance">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>3DGS | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loader页面消失采用渐隐的方式*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logo出现动画 */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//使用渐隐的方法淡出loading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//强制显示loading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">嘘~  正在从服务器偷取页面 . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>首页</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>标签</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>分类</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>归档</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="搜索" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="深色/浅色模式" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			首页
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			标签
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			分类
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			归档
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://picx.zhimg.com/v2-d5e95aa75528b2c9bf49197c9b615d9e.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">3DGS</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/3DGS/">
                                <span class="chip bg-color">3DGS</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/3DGS/" class="post-category">
                                3DGS
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2025-08-09
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>更新日期:&nbsp;&nbsp;
                    2025-08-20
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp;
                    9.8k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp;
                    39 分
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>阅读次数:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>⚠️ 以下所有内容总结都来自于 大语言模型的能力，如有错误，仅供参考，谨慎使用<br>🔴 请注意：千万不要用于严肃的学术场景，只能用于论文阅读前的初筛！<br>💗 如果您觉得我们的项目对您有帮助 <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ，还请您给我们一些鼓励！⭐️ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFace免费体验</a></p>
</blockquote>
<h1 id="2025-08-09-更新"><a href="#2025-08-09-更新" class="headerlink" title="2025-08-09 更新"></a>2025-08-09 更新</h1><h2 id="GAP-Gaussianize-Any-Point-Clouds-with-Text-Guidance"><a href="#GAP-Gaussianize-Any-Point-Clouds-with-Text-Guidance" class="headerlink" title="GAP: Gaussianize Any Point Clouds with Text Guidance"></a>GAP: Gaussianize Any Point Clouds with Text Guidance</h2><p><strong>Authors:Weiqi Zhang, Junsheng Zhou, Haotian Geng, Wenyuan Zhang, Yu-Shen Liu</strong></p>
<p>3D Gaussian Splatting (3DGS) has demonstrated its advantages in achieving fast and high-quality rendering. As point clouds serve as a widely-used and easily accessible form of 3D representation, bridging the gap between point clouds and Gaussians becomes increasingly important. Recent studies have explored how to convert the colored points into Gaussians, but directly generating Gaussians from colorless 3D point clouds remains an unsolved challenge. In this paper, we propose GAP, a novel approach that gaussianizes raw point clouds into high-fidelity 3D Gaussians with text guidance. Our key idea is to design a multi-view optimization framework that leverages a depth-aware image diffusion model to synthesize consistent appearances across different viewpoints. To ensure geometric accuracy, we introduce a surface-anchoring mechanism that effectively constrains Gaussians to lie on the surfaces of 3D shapes during optimization. Furthermore, GAP incorporates a diffuse-based inpainting strategy that specifically targets at completing hard-to-observe regions. We evaluate GAP on the Point-to-Gaussian generation task across varying complexity levels, from synthetic point clouds to challenging real-world scans, and even large-scale scenes. Project Page: <a target="_blank" rel="noopener" href="https://weiqi-zhang.github.io/GAP">https://weiqi-zhang.github.io/GAP</a>. </p>
<blockquote>
<p>3D高斯混合技术（3DGS）已经展现出其在实现快速高质量渲染方面的优势。点云作为一种广泛使用和易于获取的三维表示形式，填补其与高斯之间的差距变得越来越重要。近期的研究已经探讨了如何将彩色点转换为高斯，但直接从无彩色三维点云生成高斯仍是一个未解决的难题。在本文中，我们提出了GAP，这是一种将原始点云转化为高保真度三维高斯的新型方法，有文本指导。我们的关键想法是设计一个多角度优化框架，利用深度感知图像扩散模型合成不同视角下的连续外观。为确保几何精度，我们引入了一种表面锚定机制，有效地约束高斯在优化过程中位于三维形状的表面上。此外，GAP还采用了一种基于扩散的填充策略，特别适用于难以观察到的区域的填充。我们在不同复杂程度的点云到高斯生成任务上评估了GAP的性能，包括合成点云、具有挑战性的真实世界扫描以及大规模场景。项目页面：<a target="_blank" rel="noopener" href="https://weiqi-zhang.github.io/GAP">https://weiqi-zhang.github.io/GAP</a> 。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.05631v1">PDF</a> ICCV 2025. Project page: <a target="_blank" rel="noopener" href="https://weiqi-zhang.github.io/GAP">https://weiqi-zhang.github.io/GAP</a></p>
<p><strong>Summary</strong></p>
<p>本文提出了一种新的方法GAP，能够将原始的点云数据转化为高保真度的三维高斯数据，并通过文本引导进行渲染。该研究利用多视角优化框架，结合深度感知图像扩散模型，合成不同视角下的连续外观。为确保几何精度，引入了表面锚定机制，约束高斯在三维形状表面进行优化。此外，GAP还采用了基于扩散的填充策略，专门用于完成难以观测的区域。此技术在不同复杂度的点云转高斯生成任务上进行了评估，包括合成点云、具有挑战性的真实世界扫描以及大规模场景。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>3DGS在快速高质量渲染方面的优势。</li>
<li>点云作为广泛使用和易于获取的三维表现形式，将其转化为高斯数据的重要性。</li>
<li>当前研究中如何将彩色点转化为高斯数据的探索，以及从无色三维点云中直接生成高斯数据的挑战。</li>
<li>GAP方法：将原始点云转化为高保真三维高斯数据的新方法，通过文本引导进行渲染。</li>
<li>利用多视角优化框架和深度感知图像扩散模型合成不同视角下的连续外观。</li>
<li>引入表面锚定机制确保几何精度。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.05631">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-bbcee14eae3b7461df6d8051e911ecd8.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-efbdd389f59a1471b99c91361224584d.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-833d1aa7f103783e2049dec955678fa3.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="3DGabSplat-3D-Gabor-Splatting-for-Frequency-adaptive-Radiance-Field-Rendering"><a href="#3DGabSplat-3D-Gabor-Splatting-for-Frequency-adaptive-Radiance-Field-Rendering" class="headerlink" title="3DGabSplat: 3D Gabor Splatting for Frequency-adaptive Radiance Field   Rendering"></a>3DGabSplat: 3D Gabor Splatting for Frequency-adaptive Radiance Field   Rendering</h2><p><strong>Authors:Junyu Zhou, Yuyang Huang, Wenrui Dai, Junni Zou, Ziyang Zheng, Nuowen Kan, Chenglin Li, Hongkai Xiong</strong></p>
<p>Recent prominence in 3D Gaussian Splatting (3DGS) has enabled real-time rendering while maintaining high-fidelity novel view synthesis. However, 3DGS resorts to the Gaussian function that is low-pass by nature and is restricted in representing high-frequency details in 3D scenes. Moreover, it causes redundant primitives with degraded training and rendering efficiency and excessive memory overhead. To overcome these limitations, we propose 3D Gabor Splatting (3DGabSplat) that leverages a novel 3D Gabor-based primitive with multiple directional 3D frequency responses for radiance field representation supervised by multi-view images. The proposed 3D Gabor-based primitive forms a filter bank incorporating multiple 3D Gabor kernels at different frequencies to enhance flexibility and efficiency in capturing fine 3D details. Furthermore, to achieve novel view rendering, an efficient CUDA-based rasterizer is developed to project the multiple directional 3D frequency components characterized by 3D Gabor-based primitives onto the 2D image plane, and a frequency-adaptive mechanism is presented for adaptive joint optimization of primitives. 3DGabSplat is scalable to be a plug-and-play kernel for seamless integration into existing 3DGS paradigms to enhance both efficiency and quality of novel view synthesis. Extensive experiments demonstrate that 3DGabSplat outperforms 3DGS and its variants using alternative primitives, and achieves state-of-the-art rendering quality across both real-world and synthetic scenes. Remarkably, we achieve up to 1.35 dB PSNR gain over 3DGS with simultaneously reduced number of primitives and memory consumption. </p>
<blockquote>
<p>近期三维高斯融合（3DGS）的突出发展能够在保持高保真度的同时实现实时渲染和新颖视图合成。然而，3DGS依赖于本质上为低通的Gaussian函数，在表示三维场景中的高频细节方面存在局限性。此外，它会产生退化训练和渲染效率以及过多内存消耗的冗余基本元素。为了克服这些局限性，我们提出了基于三维 Gabor 的融合（3DGabSplat），它利用了一种新型的三维 Gabor 基基本元素，具有多个方向的三维频率响应，用于辐射场表示，并由多视角图像进行监督。所提出的三维 Gabor 基基本元素形成滤波器组，结合了不同频率的多个三维 Gabor 内核，提高了捕捉三维精细细节的灵活性和效率。此外，为了实现新颖的视图渲染，开发了一个基于 CUDA 的高效光栅化器，将三维 Gabor 基基本元素表征的多个方向的三维频率分量投影到二维图像平面上，并提出了一种频率自适应机制，用于对基本元素进行自适应联合优化。3DGabSplat 可扩展为即插即用的内核，无缝集成到现有的 3DGS 模式中，以提高视图合成的效率和质量。大量实验表明，3DGabSplat 优于 3DGS 及其使用替代基本元素的变体，并在真实和合成场景上实现了最先进的渲染质量。值得注意的是，我们在减少了基本元素数量和内存消耗的同时，实现了高达 1.35 dB 的峰值信噪比增益。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.05343v1">PDF</a> Accepted by ACM MM’25</p>
<p><strong>Summary</strong></p>
<p>基于高斯函数本身的低通特性，传统三维高斯绘制技术（3DGS）在处理高频细节方面存在局限性，影响训练和渲染效率，且占用大量内存。为突破这些局限，本文提出一种全新的三维纹理映射技术——三维Gabor绘制（3DGabSplat）。该技术利用多方向三维频率响应的3D Gabor基元表示辐射场，并通过多视角图像进行监控。创新的滤波器组集成了不同频率的多个三维Gabor内核，从而更有效地捕捉精细的三维细节。实验证明，该技术相较于传统的三维高斯绘制技术及其变体，性能更优，实现了真实和合成场景的高质量渲染。显著提升了渲染质量，减少了基元数量和内存消耗。</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>3DGS受限于传统高斯函数的低通特性，难以处理高频细节。</li>
<li>提出的3DGabSplat技术使用基于三维Gabor的基元表示辐射场，具有多方向三维频率响应。</li>
<li>创新滤波器组集成了不同频率的三维Gabor内核，提高了捕捉精细三维细节的效率。</li>
<li>开发了基于CUDA的高效光栅化器，用于将多维频率成分投影到二维图像平面上。</li>
<li>引入频率自适应机制进行基元的联合优化。</li>
<li>3DGabSplat技术易于集成到现有3DGS框架中，显著提升渲染效率和质量。</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.05343">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-77a7d13f4eae8abd4f4d3a3619d2229d.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-d7996ad8da668b6807e077ab1f0f9f13.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-7f8d77c9f547a6fd9e9be8a4deba42d9.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e663fdfb025e0c6f1eb1de2b0d3170bd.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-64b91e1e42e853a92fb8106a4d60153e.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="CF3-Compact-and-Fast-3D-Feature-Fields"><a href="#CF3-Compact-and-Fast-3D-Feature-Fields" class="headerlink" title="CF3: Compact and Fast 3D Feature Fields"></a>CF3: Compact and Fast 3D Feature Fields</h2><p><strong>Authors:Hyunjoon Lee, Joonkyu Min, Jaesik Park</strong></p>
<p>3D Gaussian Splatting (3DGS) has begun incorporating rich information from 2D foundation models. However, most approaches rely on a bottom-up optimization process that treats raw 2D features as ground truth, incurring increased computational costs. We propose a top-down pipeline for constructing compact and fast 3D Gaussian feature fields, namely, CF3. We first perform a fast weighted fusion of multi-view 2D features with pre-trained Gaussians. This approach enables training a per-Gaussian autoencoder directly on the lifted features, instead of training autoencoders in the 2D domain. As a result, the autoencoder better aligns with the feature distribution. More importantly, we introduce an adaptive sparsification method that optimizes the Gaussian attributes of the feature field while pruning and merging the redundant Gaussians, constructing an efficient representation with preserved geometric details. Our approach achieves a competitive 3D feature field using as little as 5% of the Gaussians compared to Feature-3DGS. </p>
<blockquote>
<p>3D高斯摊铺（3DGS）已经开始从2D基础模型中融入丰富的信息。然而，大多数方法依赖于自下而上的优化过程，将原始2D特征视为真实值，导致计算成本增加。我们提出了一种构建紧凑快速的3D高斯特征场的自上而下的流水线，即CF3。我们首先执行使用预训练高斯对多视角2D特征的快速加权融合。这种方法使得直接在提取的特征上训练每个高斯自编码器成为可能，而不是在二维域中训练自编码器。因此，自编码器与特征分布更加匹配。更重要的是，我们引入了一种自适应稀疏化方法，在优化特征场的高斯属性的同时删减和合并冗余高斯，构建了一个有效的表示形式，保留了几何细节。与Feature-3DGS相比，我们的方法仅使用其高斯分布的5%，即可获得具有竞争力的三维特征场表现。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.05254v1">PDF</a> ICCV 2025</p>
<p><strong>Summary</strong></p>
<p>该摘要介绍了一种基于3D高斯特征融合的方法，通过快速加权融合多视角的二维特征，构建紧凑且快速的3D高斯特征场。该方法采用顶向下的流程设计，可直接在提升的特征上训练高斯自编码器，与直接在二维域训练相比，能更好地对齐特征分布。此外，还引入了一种自适应稀疏化方法，在优化特征场的高斯属性的同时，删除并合并冗余的高斯分布，实现高效表示并保留几何细节。相较于Feature-3DGS，该方法使用的高斯分布数量仅占其5%，即可达到竞争性的三维特征场效果。</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>3DGS开始融入二维基础模型的丰富信息。</li>
<li>大多数方法采用自下而上的优化过程，将原始二维特征视为真实值，导致计算成本增加。</li>
<li>提出了一种顶向下的流程构建紧凑且快速的3D高斯特征场。</li>
<li>通过快速加权融合多视角的二维特征，实现高效的特征融合。</li>
<li>直接在提升的特征上训练高斯自编码器，更好地对齐特征分布。</li>
<li>引入自适应稀疏化方法，优化高斯属性并删除冗余的高斯分布。</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.05254">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-a120640c23c8e845a0920c057e72e6fb.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-6c341ffeddc7c87f0fcd8450a2024e39.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-3f1a44a443dbd154b23d0222fb4c7865.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-50ffd272e1efeb95596ff3470d57589e.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-0d8d462d95d6e0dcde2e01f737af5d8f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-bfde4cab5189d6a547dbc8ec9cff4eeb.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="UGOD-Uncertainty-Guided-Differentiable-Opacity-and-Soft-Dropout-for-Enhanced-Sparse-View-3DGS"><a href="#UGOD-Uncertainty-Guided-Differentiable-Opacity-and-Soft-Dropout-for-Enhanced-Sparse-View-3DGS" class="headerlink" title="UGOD: Uncertainty-Guided Differentiable Opacity and Soft Dropout for   Enhanced Sparse-View 3DGS"></a>UGOD: Uncertainty-Guided Differentiable Opacity and Soft Dropout for   Enhanced Sparse-View 3DGS</h2><p><strong>Authors:Zhihao Guo, Peng Wang, Zidong Chen, Xiangyu Kong, Yan Lyu, Guanyu Gao, Liangxiu Han</strong></p>
<p>3D Gaussian Splatting (3DGS) has become a competitive approach for novel view synthesis (NVS) due to its advanced rendering efficiency through 3D Gaussian projection and blending. However, Gaussians are treated equally weighted for rendering in most 3DGS methods, making them prone to overfitting, which is particularly the case in sparse-view scenarios. To address this, we investigate how adaptive weighting of Gaussians affects rendering quality, which is characterised by learned uncertainties proposed. This learned uncertainty serves two key purposes: first, it guides the differentiable update of Gaussian opacity while preserving the 3DGS pipeline integrity; second, the uncertainty undergoes soft differentiable dropout regularisation, which strategically transforms the original uncertainty into continuous drop probabilities that govern the final Gaussian projection and blending process for rendering. Extensive experimental results over widely adopted datasets demonstrate that our method outperforms rivals in sparse-view 3D synthesis, achieving higher quality reconstruction with fewer Gaussians in most datasets compared to existing sparse-view approaches, e.g., compared to DropGaussian, our method achieves 3.27% PSNR improvements on the MipNeRF 360 dataset. </p>
<blockquote>
<p>三维高斯映射（3DGS）已成为新型视图合成（NVS）的一种具有竞争力的方法，其通过三维高斯投影和混合技术实现了先进的渲染效率。然而，在大多数3DGS方法中，高斯被平等对待用于渲染，导致它们容易过度拟合，这在稀疏视图场景中尤为明显。为了解决这个问题，我们研究了自适应加权高斯对渲染质量的影响，这是通过提出的学得不确定性来表征的。这种学得的不确定性有两个关键目的：首先，它引导高斯不透明度的可微更新，同时保持3DGS管道完整性；其次，不确定性经历了软可微dropout正则化，这将原始不确定性战略性地转化为连续的丢弃概率，这些丢弃概率控制最终的高斯投影和混合过程以进行渲染。在广泛采用的数据集上的大量实验结果表明，我们的方法在稀疏视图三维合成中优于竞争对手，在大多数数据集上实现了更高质量的重建，使用更少的高斯。与现有的稀疏视图方法相比，例如与DropGaussian相比，我们的方法在MipNeRF 360数据集上实现了3.27%的峰值信噪比（PSNR）改进。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.04968v1">PDF</a> 11 pages, 5 figures</p>
<p><strong>Summary</strong></p>
<p>本文介绍了基于自适应权重高斯技术的三维高斯投影融合方法，该方法通过引入学习不确定性来解决稀疏视角下的过度拟合问题。不确定性用于指导高斯透明度可微更新并保持三维高斯拼贴（3DGS）流程完整性。通过软可微Dropout正则化技术，不确定性可转换为连续Dropout概率，为最终的合成视图提供更高质量的三维渲染效果。实验结果在主流数据集上表现优越，特别是在稀疏视角下与现有方法相比优势明显。相较于DropGaussian方法，本文方法在MipNeRF 360数据集上实现了高达3.27%的PSNR提升。</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>3DGS已成为新型视角合成（NVS）领域的竞争方法，因其高效的三维高斯投影和融合技术。</li>
<li>当前多数3DGS方法在处理高斯时采用等权重方式，导致在稀疏视角下容易过度拟合。</li>
<li>通过引入学习不确定性解决此问题，不仅可指导高斯透明度进行可微更新，且能保留原始的渲染完整性。</li>
<li>利用软可微Dropout正则化技术将不确定性转化为连续Dropout概率，用于控制最终的渲染过程。</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.04968">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-c7f72cbc4978376c5ffec29c43b5551c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-df9aa1b7474a7dbcb2b2c42c3ade21fe.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d5e95aa75528b2c9bf49197c9b615d9e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-2d2eaae406b8a2eb470104a9a760a3f6.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b475e92d0a75f426861f2cb7dfb80a21.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="Laplacian-Analysis-Meets-Dynamics-Modelling-Gaussian-Splatting-for-4D-Reconstruction"><a href="#Laplacian-Analysis-Meets-Dynamics-Modelling-Gaussian-Splatting-for-4D-Reconstruction" class="headerlink" title="Laplacian Analysis Meets Dynamics Modelling: Gaussian Splatting for 4D   Reconstruction"></a>Laplacian Analysis Meets Dynamics Modelling: Gaussian Splatting for 4D   Reconstruction</h2><p><strong>Authors:Yifan Zhou, Beizhen Zhao, Pengcheng Wu, Hao Wang</strong></p>
<p>While 3D Gaussian Splatting (3DGS) excels in static scene modeling, its extension to dynamic scenes introduces significant challenges. Existing dynamic 3DGS methods suffer from either over-smoothing due to low-rank decomposition or feature collision from high-dimensional grid sampling. This is because of the inherent spectral conflicts between preserving motion details and maintaining deformation consistency at different frequency. To address these challenges, we propose a novel dynamic 3DGS framework with hybrid explicit-implicit functions. Our approach contains three key innovations: a spectral-aware Laplacian encoding architecture which merges Hash encoding and Laplacian-based module for flexible frequency motion control, an enhanced Gaussian dynamics attribute that compensates for photometric distortions caused by geometric deformation, and an adaptive Gaussian split strategy guided by KDTree-based primitive control to efficiently query and optimize dynamic areas. Through extensive experiments, our method demonstrates state-of-the-art performance in reconstructing complex dynamic scenes, achieving better reconstruction fidelity. </p>
<blockquote>
<p>关于三维高斯贴合（3DGS），其在静态场景建模上表现出卓越的性能，然而，当将其扩展到动态场景时却面临着诸多挑战。现有的动态3DGS方法由于受低阶分解的影响而导致过度平滑，或因高维网格采样导致特征碰撞。这是由于在不同频率下保留运动细节和保持变形一致性之间存在固有的光谱冲突。为了解决这些挑战，我们提出了一种新型动态3DGS框架，采用混合显式隐式函数。我们的方法包含三项关键创新：一种光谱感知拉普拉斯编码架构，融合了哈希编码和基于拉普拉斯的模块以实现灵活频率运动控制；一种增强型高斯动力学属性，用于补偿由几何变形引起的光度失真；以及一种由KDTree基元控制引导的自适应高斯分割策略，以有效地查询和优化动态区域。通过大量实验，我们的方法在重建复杂动态场景方面表现出卓越性能，实现了更高的重建保真度。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.04966v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>本文指出，尽管静态场景建模中三维高斯映射（3DGS）表现出色，但在动态场景的应用中面临重大挑战。现有动态3DGS方法存在过度平滑和高维网格采样引起的特征碰撞问题。为解决这些问题，本文提出了一种基于混合显式隐式函数的新型动态三维高斯映射框架。该框架包含三项关键创新：频域感知拉普拉斯编码架构，用于灵活控制频率运动；增强型高斯动态属性，用于补偿几何变形引起的光度失真；以及基于KD树的自适应高斯分割策略，以高效查询和优化动态区域。实验证明，该方法在重建复杂动态场景方面具有最佳性能，实现了较高的重建保真度。</p>
<p><strong>Key Takeaways</strong></p>
<p>一、现有动态场景下的三维高斯映射（3DGS）技术面临的挑战包括过度平滑与特征碰撞问题。</p>
<p>二、面临的挑战来源于保持运动细节和维持变形一致性之间的频谱冲突。</p>
<p>三、本文提出了一种基于混合显式隐式函数的新型动态三维高斯映射框架来解决这些问题。其中包含频域感知拉普拉斯编码架构用于灵活控制频率运动。</p>
<p>四、增强型高斯动态属性被用来补偿几何变形引起的光度失真。</p>
<p>五、基于KD树的自适应高斯分割策略用于高效查询和优化动态区域。</p>
<p>六、本文方法通过广泛实验验证，在重建复杂动态场景方面表现出卓越性能。</p>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.04966">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-63223c7b17b3029de2adc19036316517.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-f9f903b191910cadfa7ec773d22109c9.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-bebb9e148b3532b2213c6f0fc2320653.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="Part-Segmentation-and-Motion-Estimation-for-Articulated-Objects-with-Dynamic-3D-Gaussians"><a href="#Part-Segmentation-and-Motion-Estimation-for-Articulated-Objects-with-Dynamic-3D-Gaussians" class="headerlink" title="Part Segmentation and Motion Estimation for Articulated Objects with   Dynamic 3D Gaussians"></a>Part Segmentation and Motion Estimation for Articulated Objects with   Dynamic 3D Gaussians</h2><p><strong>Authors:Jun-Jee Chao, Qingyuan Jiang, Volkan Isler</strong></p>
<p>Part segmentation and motion estimation are two fundamental problems for articulated object motion analysis. In this paper, we present a method to solve these two problems jointly from a sequence of observed point clouds of a single articulated object. The main challenge in our problem setting is that the point clouds are not assumed to be generated by a fixed set of moving points. Instead, each point cloud in the sequence could be an arbitrary sampling of the object surface at that particular time step. Such scenarios occur when the object undergoes major occlusions, or if the dataset is collected using measurements from multiple sensors asynchronously. In these scenarios, methods that rely on tracking point correspondences are not appropriate. We present an alternative approach based on a compact but effective representation where we represent the object as a collection of simple building blocks modeled as 3D Gaussians. We parameterize the Gaussians with time-dependent rotations, translations, and scales that are shared across all time steps. With our representation, part segmentation can be achieved by building correspondences between the observed points and the Gaussians. Moreover, the transformation of each point across time can be obtained by following the poses of the assigned Gaussian (even when the point is not observed). Experiments show that our method outperforms existing methods that solely rely on finding point correspondences. Additionally, we extend existing datasets to emulate real-world scenarios by considering viewpoint occlusions. We further demonstrate that our method is more robust to missing points as compared to existing approaches on these challenging datasets, even when some parts are completely occluded in some time-steps. Notably, our part segmentation performance outperforms the state-of-the-art method by 13% on point clouds with occlusions. </p>
<blockquote>
<p>点云分割和运动估计是关节对象运动分析中的两个基本问题。本文提出了一种方法，可以从单个关节对象的观察到的点云序列中联合解决这两个问题。我们的问题设置中的主要挑战在于，假设点云不是由一组固定的移动点生成的。相反，序列中的每个点云都可能是该对象在特定时间步长的表面上的任意采样。当对象遭受主要遮挡或数据集是使用多个异步传感器进行收集时，这种情况就会发生。在这种情况下，依赖跟踪点对应的方法并不适用。我们提出了一种基于紧凑而有效的表示方法的替代方案，我们将对象表示为作为高斯模型的简单构建块的集合。我们用随时间变化的旋转、平移和尺度参数化高斯模型，这些参数在所有时间步长中都是共享的。通过我们的表示方法，可以通过建立观察到的点和高斯之间的对应关系来实现部分分割。此外，每个点随时间变化的变化可以通过跟随指定的高斯姿态来获得（即使点没有被观察到）。实验表明，我们的方法在仅依赖于找到点对应的方法上表现更好。此外，我们通过考虑视角遮挡来模拟现实世界场景，对现有数据集进行了扩展。我们进一步证明，我们的方法在缺失点的处理上比这些具有挑战性的数据集上的现有方法更稳健，即使在某些时间步长中某些部分被完全遮挡也是如此。值得注意的是，在有遮挡的点云上，我们的部分分割性能优于最新技术方法达13%。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.22718v2">PDF</a> </p>
<p><strong>摘要</strong><br>    本文提出一种方法，从单一关节对象的点云序列中联合解决部分分割和运动估计两个基本问题。该方法不假定点云由固定的一组移动点生成，而是认为每个点云是对象表面在该时间步的任意采样。当对象遭受主要遮挡或使用多个异步传感器收集数据时，依赖跟踪点对应的方法不适用。相反，本文采用紧凑有效的表示方法，将对象表示为一系列简单的建筑模块，用三维高斯建模。参数化高斯与时间相关的旋转、平移和尺度共享在所有时间步骤中。通过这种表示，部分分割可以通过观察点与高斯之间的对应关系来实现。此外，即使点未被观察，也可以通过跟随指定高斯的时间变换来获得每个点的时间变换。实验表明，该方法优于仅依赖寻找点对应的方法。此外，通过考虑视点遮挡来模拟现实世界场景扩展现有数据集。进一步证明该方法对于缺失点的鲁棒性优于现有方法，即使某些部分在某些时间步骤中被完全遮挡。特别是在存在遮挡的点云上，本文的部分分割性能优于最新技术方法，提高了13%。</p>
<p><strong>关键见解</strong></p>
<ol>
<li>本文提出了一种联合解决部分分割和运动估计的方法，适用于单一关节对象的点云序列。</li>
<li>该方法不依赖于固定的点对应跟踪，能够处理对象表面的任意采样。</li>
<li>使用三维高斯建模对象的简单建筑模块，并参数化其与时间相关的变换。</li>
<li>部分分割是通过观察点与高斯之间的对应关系实现的。</li>
<li>该方法能够预测每个点的时间变换，即使点在某个时刻未被观察。</li>
<li>实验表明，该方法在性能上优于现有的仅依赖点对应的方法。</li>
<li>在模拟现实世界场景（考虑视点遮挡）的现有数据集上进行了扩展实验，证明了该方法对于缺失点的鲁棒性。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.22718">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-89ba4516a4e74331701647061dd8bae3.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-f051019ec97253788601498c69e65c11.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-e88254f58f781eff238dfaf2cec0d48b.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="CountingFruit-Language-Guided-3D-Fruit-Counting-with-Semantic-Gaussian-Splatting"><a href="#CountingFruit-Language-Guided-3D-Fruit-Counting-with-Semantic-Gaussian-Splatting" class="headerlink" title="CountingFruit: Language-Guided 3D Fruit Counting with Semantic Gaussian   Splatting"></a>CountingFruit: Language-Guided 3D Fruit Counting with Semantic Gaussian   Splatting</h2><p><strong>Authors:Fengze Li, Yangle Liu, Jieming Ma, Hai-Ning Liang, Yaochun Shen, Huangxiang Li, Zhijing Wu</strong></p>
<p>Accurate 3D fruit counting in orchards is challenging due to heavy occlusion, semantic ambiguity between fruits and surrounding structures, and the high computational cost of volumetric reconstruction. Existing pipelines often rely on multi-view 2D segmentation and dense volumetric sampling, which lead to accumulated fusion errors and slow inference. We introduce FruitLangGS, a language-guided 3D fruit counting framework that reconstructs orchard-scale scenes using an adaptive-density Gaussian Splatting pipeline with radius-aware pruning and tile-based rasterization, enabling scalable 3D representation. During inference, compressed CLIP-aligned semantic vectors embedded in each Gaussian are filtered via a dual-threshold cosine similarity mechanism, retrieving Gaussians relevant to target prompts while suppressing common distractors (e.g., foliage), without requiring retraining or image-space masks. The selected Gaussians are then sampled into dense point clouds and clustered geometrically to estimate fruit instances, remaining robust under severe occlusion and viewpoint variation. Experiments on nine different orchard-scale datasets demonstrate that FruitLangGS consistently outperforms existing pipelines in instance counting recall, avoiding multi-view segmentation fusion errors and achieving up to 99.7% recall on Pfuji-Size_Orch2018 orchard dataset. Ablation studies further confirm that language-conditioned semantic embedding and dual-threshold prompt filtering are essential for suppressing distractors and improving counting accuracy under heavy occlusion. Beyond fruit counting, the same framework enables prompt-driven 3D semantic retrieval without retraining, highlighting the potential of language-guided 3D perception for scalable agricultural scene understanding. </p>
<blockquote>
<p>在果园中进行精确的3D水果计数是一项具有挑战性的任务，因为存在严重的遮挡、水果与周围结构之间的语义模糊以及体积重建的高计算成本。现有的流程通常依赖于多视角2D分割和密集的体积采样，这会导致累积的融合误差和缓慢的推理速度。我们引入了FruitLangGS，这是一种语言指导的3D水果计数框架，它使用自适应密度的高斯Splatting管道，结合半径感知修剪和基于瓦片的栅格化，重建果园规模场景，从而实现可扩展的3D表示。在推理过程中，嵌入在每个高斯中的压缩CLIP对齐语义向量通过双阈值余弦相似度机制进行过滤，检索与目标提示相关的高斯，同时抑制常见的干扰因素（例如叶子），而无需进行再训练或图像空间掩膜。然后，所选的高斯被采样为密集的点云，并进行几何聚类以估计水果实例，即使在严重的遮挡和视角变化下也能保持稳健。在九个不同的果园数据集上的实验表明，FruitLangGS在实例计数召回方面始终优于现有流程，避免了多视角分割融合误差，并在Pfuji-Size_Orch2018果园数据集上实现了高达99.7%的召回率。消融研究进一步证实，语言调节的语义嵌入和双阈值提示过滤对于抑制干扰因素和提高遮挡下的计数精度至关重要。除了水果计数之外，同一框架还实现了提示驱动的3D语义检索而无需重新训练，突显了语言指导的3D感知在可扩展的农业场景理解中的潜力。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.01109v3">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>本文介绍了一种名为FruitLangGS的语言引导三维水果计数框架，适用于果园场景。它通过自适应密度的高斯Splatting管道进行果园规模场景的重建，并采用基于瓦片的渲染技术，实现了可扩展的三维表示。使用双重阈值余弦相似度机制过滤嵌套的CLIP语义向量，能够准确识别目标提示相关的Gaussians，同时抑制常见的干扰物（如叶子），无需重新训练和图像空间遮罩。在九个不同的果园数据集上的实验表明，FruitLangGS在实例计数召回方面表现出色，避免了多视角分割融合错误，并在Pfuji-Size_Orch2018果园数据集上实现了高达99.7%的召回率。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>FruitLangGS是一个语言引导的三维水果计数框架，适用于果园场景的三维感知。</li>
<li>通过自适应密度的高斯Splatting管道和基于瓦片的渲染技术，实现了果园规模场景的重建和可扩展的三维表示。</li>
<li>使用双重阈值余弦相似度机制过滤嵌套的CLIP语义向量，能够准确识别目标水果，同时抑制干扰物的影响。</li>
<li>在多个果园数据集上的实验表明，FruitLangGS在实例计数召回方面优于现有管道，避免了多视角分割融合错误。</li>
<li>FruitLangGS在Pfuji-Size_Orch2018数据集上实现了高达99.7%的召回率。</li>
<li>框架中的语言条件语义嵌入和双重阈值提示过滤对于抑制干扰物和提高计数准确性至关重要。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.01109">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-385b6d1fdcd4b0be9019b62887424a5f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-61d849ce2c577ff2a0283971bdd5f8dd.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-5bbbf82de34330b7cd3a915cbfaf466d.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-464019c7d6345d7f09eaab3ce02b3ce2.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-a84c39707d35e0a59c86355d8137a5f1.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-5b97f57f79d639054d91c41801500411.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="GaSLight-Gaussian-Splats-for-Spatially-Varying-Lighting-in-HDR"><a href="#GaSLight-Gaussian-Splats-for-Spatially-Varying-Lighting-in-HDR" class="headerlink" title="GaSLight: Gaussian Splats for Spatially-Varying Lighting in HDR"></a>GaSLight: Gaussian Splats for Spatially-Varying Lighting in HDR</h2><p><strong>Authors:Christophe Bolduc, Yannick Hold-Geoffroy, Zhixin Shu, Jean-François Lalonde</strong></p>
<p>We present GaSLight, a method that generates spatially-varying lighting from regular images. Our method proposes using HDR Gaussian Splats as light source representation, marking the first time regular images can serve as light sources in a 3D renderer. Our two-stage process first enhances the dynamic range of images plausibly and accurately by leveraging the priors embedded in diffusion models. Next, we employ Gaussian Splats to model 3D lighting, achieving spatially variant lighting. Our approach yields state-of-the-art results on HDR estimations and their applications in illuminating virtual objects and scenes. To facilitate the benchmarking of images as light sources, we introduce a novel dataset of calibrated and unsaturated HDR to evaluate images as light sources. We assess our method using a combination of this novel dataset and an existing dataset from the literature. Project page: <a target="_blank" rel="noopener" href="https://lvsn.github.io/gaslight/">https://lvsn.github.io/gaslight/</a> </p>
<blockquote>
<p>我们提出了GaSLight方法，该方法可以从常规图像生成空间变化的照明。我们的方法建议使用HDR高斯斑点作为光源表示，这是首次使得常规图像可以在3D渲染器中作为光源使用。我们的两阶段过程首先通过利用扩散模型中嵌入的先验知识来增强图像的动态范围，从而以合理和准确的方式实现这一目标。接下来，我们使用高斯斑点对3D照明进行建模，实现空间变化照明。我们的方法在HDR估算及其在虚拟对象和场景的照明应用方面产生了最先进的结果。为了对图像作为光源进行基准测试，我们引入了一个新型校准和不饱和HDR数据集来评估图像作为光源。我们使用这个新数据集和文献中的现有数据集来评估我们的方法。项目页面：<a target="_blank" rel="noopener" href="https://lvsn.github.io/gaslight/">https://lvsn.github.io/gaslight/</a></p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.10809v3">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>GaSLight方法能够通过常规图像生成空间变化的光照。该方法首次提出使用HDR高斯Splats作为光源表示，利用扩散模型的先验知识增强图像动态范围，并通过高斯Splats对三维光照进行建模，实现空间变化的光照效果。该方法在HDR估算及其虚拟对象和场景的照明应用方面达到了最新水平。为了评估图像作为光源的基准测试，我们引入了一个新型校准不饱和HDR数据集。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>GaSLight方法利用常规图像生成空间变化的光照。</li>
<li>首次使用HDR高斯Splats作为光源表示。</li>
<li>利用扩散模型的先验知识增强图像动态范围。</li>
<li>通过高斯Splats对三维光照进行建模。</li>
<li>方法在HDR估算方面达到最新水平。</li>
<li>引入了新型校准不饱和HDR数据集，用于评估图像作为光源的效果。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.10809">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-06e1091965dc47bb66020a46fd9753d5.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-a9c7a000655e37ae9119ea49d8a00238.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-16a1d1f424ea7d80a1e1fed27f8ee113.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-6b170d43e190ff1f4d2e5e50705814a6.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-237b280e3a6af7ce6e29d6143c2b51d5.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-6cb1c392fedec80e5ec99173df203178.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-df8be25bcee09780fccfbb3e5c2e0bcb.jpg" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="Repurposing-2D-Diffusion-Models-with-Gaussian-Atlas-for-3D-Generation"><a href="#Repurposing-2D-Diffusion-Models-with-Gaussian-Atlas-for-3D-Generation" class="headerlink" title="Repurposing 2D Diffusion Models with Gaussian Atlas for 3D Generation"></a>Repurposing 2D Diffusion Models with Gaussian Atlas for 3D Generation</h2><p><strong>Authors:Tiange Xiang, Kai Li, Chengjiang Long, Christian Häne, Peihong Guo, Scott Delp, Ehsan Adeli, Li Fei-Fei</strong></p>
<p>Recent advances in text-to-image diffusion models have been driven by the increasing availability of paired 2D data. However, the development of 3D diffusion models has been hindered by the scarcity of high-quality 3D data, resulting in less competitive performance compared to their 2D counterparts. To address this challenge, we propose repurposing pre-trained 2D diffusion models for 3D object generation. We introduce Gaussian Atlas, a novel representation that utilizes dense 2D grids, enabling the fine-tuning of 2D diffusion models to generate 3D Gaussians. Our approach demonstrates successful transfer learning from a pre-trained 2D diffusion model to a 2D manifold flattened from 3D structures. To support model training, we compile GaussianVerse, a large-scale dataset comprising 205K high-quality 3D Gaussian fittings of various 3D objects. Our experimental results show that text-to-image diffusion models can be effectively adapted for 3D content generation, bridging the gap between 2D and 3D modeling. </p>
<blockquote>
<p>最近文本到图像扩散模型的进步得益于二维数据配对的日益普及。然而，由于缺乏高质量的三维数据，三维扩散模型的发展受到了阻碍，导致其性能不如二维模型具有竞争力。为了应对这一挑战，我们提出将预训练的二维扩散模型重新用于三维对象生成。我们引入了高斯地图（Gaussian Atlas），这是一种新型表示方法，它利用密集二维网格，实现对二维扩散模型的微调以生成三维高斯数据。我们的方法成功实现了从预训练的二维扩散模型到由三维结构展平的二维流形上的迁移学习。为了支持模型训练，我们编译了GaussianVerse数据集，该数据集包含20万多个高质量的三维高斯拟合的各类三维物体样本。我们的实验结果表明，文本到图像的扩散模型可以有效地适应三维内容生成，弥合了二维和三维建模之间的差距。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.15877v2">PDF</a> ICCV 2025</p>
<p><strong>Summary</strong><br>     针对三维扩散模型发展受限于高质量三维数据稀缺的问题，提出利用预训练的二维扩散模型进行三维物体生成。引入高斯图谱表示方法，利用密集二维网格实现二维扩散模型的微调以生成三维高斯数据。为支持模型训练，编译大规模数据集GaussianVerse，包含20.5万高质量三维高斯拟合数据。实验结果显示，文本到图像扩散模型可有效地适应三维内容生成，缩小了二维和三维建模之间的差距。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>高质量三维数据的稀缺限制了三维扩散模型的发展。</li>
<li>提出利用预训练的二维扩散模型进行三维物体生成的方法。</li>
<li>引入高斯图谱作为新的表示方法，利用密集二维网格实现模型微调。</li>
<li>编译大规模数据集GaussianVerse以支持模型训练。</li>
<li>实验证明文本到图像扩散模型可适应三维内容生成。</li>
<li>这种方法成功实现了从二维到三维建模的过渡。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.15877">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-472b07681422acc4f9ee884eae0da3a6.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-cd21da48977960e929021bb05551b527.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-bc07a13017aaa5aa86c0f05b64a9a49f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e928d55124778316396f58a05f1bea4a.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-3513a298984a882e6d6a7522941a914d.jpg" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1><h2 id="Reality-Fusion-Robust-Real-time-Immersive-Mobile-Robot-Teleoperation-with-Volumetric-Visual-Data-Fusion"><a href="#Reality-Fusion-Robust-Real-time-Immersive-Mobile-Robot-Teleoperation-with-Volumetric-Visual-Data-Fusion" class="headerlink" title="Reality Fusion: Robust Real-time Immersive Mobile Robot Teleoperation   with Volumetric Visual Data Fusion"></a>Reality Fusion: Robust Real-time Immersive Mobile Robot Teleoperation   with Volumetric Visual Data Fusion</h2><p><strong>Authors:Ke Li, Reinhard Bacher, Susanne Schmidt, Wim Leemans, Frank Steinicke</strong></p>
<p>We introduce Reality Fusion, a novel robot teleoperation system that localizes, streams, projects, and merges a typical onboard depth sensor with a photorealistic, high resolution, high framerate, and wide field of view (FoV) rendering of the complex remote environment represented as 3D Gaussian splats (3DGS). Our framework enables robust egocentric and exocentric robot teleoperation in immersive VR, with the 3DGS effectively extending spatial information of a depth sensor with limited FoV and balancing the trade-off between data streaming costs and data visual quality. We evaluated our framework through a user study with 24 participants, which revealed that Reality Fusion leads to significantly better user performance, situation awareness, and user preferences. To support further research and development, we provide an open-source implementation with an easy-to-replicate custom-made telepresence robot, a high-performance virtual reality 3DGS renderer, and an immersive robot control package. (Source code: <a target="_blank" rel="noopener" href="https://github.com/uhhhci/RealityFusion">https://github.com/uhhhci/RealityFusion</a>) </p>
<blockquote>
<p>我们介绍了 Reality Fusion，这是一个新型机器人遥操作系系统，它能定位、传输、投影，并将典型的机载深度传感器与复杂远程环境的以高斯三元分布渲染出的超现实主义、高分辨率、高帧率和大视野图像合并。我们的框架能够在沉浸式虚拟现实中进行稳健的自我中心和非自我中心的机器人遥操作，以三元分布有效地扩展具有有限视野的深度传感器的空间信息，并平衡数据流成本和数据视觉质量之间的权衡。我们通过一项有 24 名参与者进行的研究评估发现，Realty Fusion 能够显著提高用户性能、情境意识和用户偏好。为了支持进一步的研究和开发，我们提供了一个开源实现方案，包括易于复制的定制遥控机器人、高性能虚拟现实三元分布渲染器以及沉浸式机器人控制套件。（源代码：<a target="_blank" rel="noopener" href="https://github.com/uhhhci/RealtyFusion%EF%BC%89">https://github.com/uhhhci/RealtyFusion）</a></p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2408.01225v2">PDF</a> Accepted at IROS 2024</p>
<p><strong>Summary</strong></p>
<p>本文介绍了名为“现实融合”的新型机器人遥控系统，该系统结合了车载深度传感器与复杂远程环境的三维高斯斑点渲染技术，实现了在虚拟现实中的稳健自主式和异向式机器人遥控操作。现实融合系统扩展了深度传感器的空间信息，平衡了数据流成本和视觉质量，提高了用户性能、情境感知和用户偏好。系统提供开源实现，包含易于复制的遥现场机器人、高性能虚拟现实三维高斯斑点渲染器和沉浸式机器人控制包。</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>Reality Fusion是一个新型机器人遥控系统，结合了深度传感器与三维高斯斑点渲染技术。</li>
<li>系统能够实现自主式和异向式机器人遥控操作，扩展了深度传感器的空间信息。</li>
<li>现实融合系统平衡数据流成本和视觉质量，提高用户性能、情境感知和用户偏好。</li>
<li>系统支持开源实现，包含易于复制的遥现场机器人和虚拟现实渲染器。</li>
<li>通过用户研究验证了系统的有效性和优势。</li>
<li>系统包含高性能的虚拟现实三维高斯斑点渲染器。</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2408.01225">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-74f9f6e1f984c84bd40e8cc34521c921.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-9e72345c06bfe4391ec8fbe00035cdaa.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-c159fbfd87393fd8620f1b0d9202676e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b5d4250d2cb7e9dd4d4abed42b477cd3.jpg" align="middle">
</details>


<h1 id="-9"><a href="#-9" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        文章作者:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        文章链接:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-08-09/3DGS/">https://kedreamix.github.io/Talk2Paper/Paper/2025-08-09/3DGS/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        版权声明:
                    </i>
                </span>
                <span class="reprint-info">
                    本博客所有文章除特別声明外，均采用
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    许可协议。转载请注明来源
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/3DGS/">
                                    <span class="chip bg-color">3DGS</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;上一篇</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-08-09/NeRF/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-538c718c7f7a929afedcd2bc3a7dafb4.jpg" class="responsive-img" alt="NeRF">
                        
                        <span class="card-title">NeRF</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            NeRF 方向最新论文已更新，请持续关注 Update in 2025-08-09  GTR Improving Large 3D Reconstruction Models through Geometry and   Texture Refinement
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-08-09
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/NeRF/" class="post-category">
                                    NeRF
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/NeRF/">
                        <span class="chip bg-color">NeRF</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-08-09/GAN/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-c8bee61fbd138c40ce5dfeed7b6a32d4.jpg" class="responsive-img" alt="GAN">
                        
                        <span class="card-title">GAN</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            GAN 方向最新论文已更新，请持续关注 Update in 2025-08-09  FLUX-Makeup High-Fidelity, Identity-Consistent, and Robust Makeup   Transfer via Diffusion Transformer
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-08-09
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/GAN/" class="post-category">
                                    GAN
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/GAN/">
                        <span class="chip bg-color">GAN</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- 代码语言 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span
                        class="white-color">26024.5k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- 运行天数提醒. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // 区分是否有年份.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = '本站已运行 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                daysTip = '本站已運行 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = '本站已运行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = '本站已運行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="关注我的知乎: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">知</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- 白天和黑夜主题 -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // 只在桌面版网页启用特效
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- 雪花特效 -->
    

    <!-- 鼠标星星特效 -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--腾讯兔小巢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- 动态标签 -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Σ(っ °Д °;)っ诶，页面崩溃了嘛？", clearTimeout(st)) : (document.title = "φ(゜▽゜*)♪咦，又好了！", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
