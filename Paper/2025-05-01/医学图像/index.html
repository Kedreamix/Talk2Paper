<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="åŒ»å­¦å›¾åƒ">
    <meta name="description" content="åŒ»å­¦å›¾åƒ æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-05-01  SVD Based Least Squares for X-Ray Pneumonia Classification Using Deep   Features">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>åŒ»å­¦å›¾åƒ | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://pic1.zhimg.com/v2-224fdbd6db02405895f63495f1389d12.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">åŒ»å­¦å›¾åƒ</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/">
                                <span class="chip bg-color">åŒ»å­¦å›¾åƒ</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/" class="post-category">
                                åŒ»å­¦å›¾åƒ
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-05-01
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-05-25
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    13.5k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    56 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-05-01-æ›´æ–°"><a href="#2025-05-01-æ›´æ–°" class="headerlink" title="2025-05-01 æ›´æ–°"></a>2025-05-01 æ›´æ–°</h1><h2 id="SVD-Based-Least-Squares-for-X-Ray-Pneumonia-Classification-Using-Deep-Features"><a href="#SVD-Based-Least-Squares-for-X-Ray-Pneumonia-Classification-Using-Deep-Features" class="headerlink" title="SVD Based Least Squares for X-Ray Pneumonia Classification Using Deep   Features"></a>SVD Based Least Squares for X-Ray Pneumonia Classification Using Deep   Features</h2><p><strong>Authors:Mete Erdogan, Sebnem Demirtas</strong></p>
<p>Accurate and early diagnosis of pneumonia through X-ray imaging is essential for effective treatment and improved patient outcomes. Recent advancements in machine learning have enabled automated diagnostic tools that assist radiologists in making more reliable and efficient decisions. In this work, we propose a Singular Value Decomposition-based Least Squares (SVD-LS) framework for multi-class pneumonia classification, leveraging powerful feature representations from state-of-the-art self-supervised and transfer learning models. Rather than relying on computationally expensive gradient based fine-tuning, we employ a closed-form, non-iterative classification approach that ensures efficiency without compromising accuracy. Experimental results demonstrate that SVD-LS achieves competitive performance while offering significantly reduced computational costs, making it a viable alternative for real-time medical imaging applications. </p>
<blockquote>
<p>é€šè¿‡Xå°„çº¿æˆåƒå¯¹è‚ºç‚è¿›è¡Œå‡†ç¡®å’Œæ—©æœŸçš„è¯Šæ–­å¯¹äºæœ‰æ•ˆæ²»ç–—å’Œæ”¹å–„æ‚£è€…é¢„åè‡³å…³é‡è¦ã€‚æœ€è¿‘æœºå™¨å­¦ä¹ çš„å‘å±•å·²ç»å‚¬ç”Ÿäº†è‡ªåŠ¨è¯Šæ–­å·¥å…·ï¼Œè¿™äº›å·¥å…·å¯å¸®åŠ©æ”¾å°„ç§‘åŒ»ç”Ÿåšå‡ºæ›´å¯é ã€æ›´é«˜æ•ˆçš„å†³ç­–ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åŸºäºå¥‡å¼‚å€¼åˆ†è§£çš„æœ€å°äºŒä¹˜ï¼ˆSVD-LSï¼‰æ¡†æ¶ï¼Œç”¨äºå¤šç±»è‚ºç‚åˆ†ç±»ï¼Œåˆ©ç”¨æœ€å…ˆè¿›çš„è‡ªç›‘ç£å’Œè¿ç§»å­¦ä¹ æ¨¡å‹çš„å¼ºå¤§ç‰¹å¾è¡¨ç¤ºã€‚æˆ‘ä»¬æ²¡æœ‰ä¾èµ–è®¡ç®—æˆæœ¬è¾ƒé«˜çš„åŸºäºæ¢¯åº¦çš„å¾®è°ƒï¼Œè€Œæ˜¯é‡‡ç”¨äº†ä¸€ç§å°é—­å½¢å¼çš„éè¿­ä»£åˆ†ç±»æ–¹æ³•ï¼Œç¡®ä¿äº†æ•ˆç‡è€Œä¸ä¼šå½±å“å‡†ç¡®æ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒSVD-LSåœ¨å–å¾—ç«äº‰æ€§èƒ½çš„åŒæ—¶å¤§å¤§å‡å°‘äº†è®¡ç®—æˆæœ¬ï¼Œä½¿å…¶æˆä¸ºå®æ—¶åŒ»ç–—æˆåƒåº”ç”¨çš„ä¸€ç§å¯è¡Œçš„æ›¿ä»£æ–¹æ¡ˆã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.20970v1">PDF</a> Preprint submitted to IEEE International Workshop on Machine Learning   for Signal Processing (MLSP), 2025</p>
<p><strong>Summary</strong><br>     å€ŸåŠ©æœºå™¨å­¦ä¹ çš„æœ€æ–°è¿›å±•ï¼Œåˆ©ç”¨å¥‡å¼‚å€¼åˆ†è§£ï¼ˆSVDï¼‰çš„åŸºäºæœ€å°äºŒä¹˜çš„åˆ†ç±»æ¡†æ¶ï¼Œé€šè¿‡å…ˆè¿›çš„è‡ªç›‘ç£å­¦ä¹ å’Œè¿ç§»å­¦ä¹ æ¨¡å‹è¿›è¡Œå¤šç±»è‚ºç‚åˆ†ç±»ï¼Œå®ç°å‡†ç¡®å’Œæ—©æœŸçš„è‚ºç‚è¯Šæ–­ã€‚æˆ‘ä»¬é‡‡ç”¨ä¸€ç§é—­å¼ã€éè¿­ä»£åˆ†ç±»æ–¹æ³•ï¼Œåœ¨ä¿è¯æ•ˆç‡çš„åŒæ—¶ä¸æŸå¤±å‡†ç¡®æ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒSVD-LSæ–¹æ³•å…·æœ‰ç«äº‰åŠ›ï¼ŒåŒæ—¶å¤§å¤§é™ä½äº†è®¡ç®—æˆæœ¬ï¼Œæ˜¯å®æ—¶åŒ»å­¦æˆåƒåº”ç”¨çš„å¯è¡Œé€‰æ‹©ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å‡†ç¡®å’Œæ—©æœŸçš„è‚ºç‚è¯Šæ–­å¯¹æœ‰æ•ˆæ²»ç–—å’Œæ”¹å–„æ‚£è€…é¢„åè‡³å…³é‡è¦ã€‚</li>
<li>æœºå™¨å­¦ä¹ æŠ€æœ¯çš„æœ€æ–°è¿›å±•ä¸ºè‡ªåŠ¨åŒ–è¯Šæ–­å·¥å…·æä¾›äº†æ”¯æŒï¼Œå¸®åŠ©æ”¾å°„ç§‘åŒ»ç”Ÿåšå‡ºæ›´å¯é å’Œé«˜æ•ˆçš„å†³ç­–ã€‚</li>
<li>æå‡ºäº†ä¸€ç§åŸºäºå¥‡å¼‚å€¼åˆ†è§£ï¼ˆSVDï¼‰çš„æœ€å°äºŒä¹˜ï¼ˆLSï¼‰æ¡†æ¶ï¼Œç”¨äºå¤šç±»è‚ºç‚åˆ†ç±»ã€‚</li>
<li>åˆ©ç”¨å…ˆè¿›çš„è‡ªç›‘ç£å­¦ä¹ å’Œè¿ç§»å­¦ä¹ æ¨¡å‹è¿›è¡Œç‰¹å¾è¡¨ç¤ºï¼Œæé«˜åˆ†ç±»æ€§èƒ½ã€‚</li>
<li>é‡‡ç”¨é—­å¼ã€éè¿­ä»£åˆ†ç±»æ–¹æ³•ï¼Œåœ¨ä¿è¯å‡†ç¡®æ€§çš„åŒæ—¶æé«˜æ•ˆç‡ã€‚</li>
<li>SVD-LSæ–¹æ³•å…·æœ‰ç«äº‰åŠ›çš„æ€§èƒ½è¡¨ç°ï¼Œå¹¶ä¸”è®¡ç®—æˆæœ¬æ˜¾è‘—é™ä½ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.20970">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-15dbb07ae8cb1315a06d4bc80bebb3cd.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-599e8c4bc0df68bd4bd68edf034c7789.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-7d5d9fdaf689f4e4e810edb934f87d1c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f3df5506e36a26f1a44e484c88a6223c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c5ae479312e369a08d84f6abd5d33c7f.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="ChestX-Reasoner-Advancing-Radiology-Foundation-Models-with-Reasoning-through-Step-by-Step-Verification"><a href="#ChestX-Reasoner-Advancing-Radiology-Foundation-Models-with-Reasoning-through-Step-by-Step-Verification" class="headerlink" title="ChestX-Reasoner: Advancing Radiology Foundation Models with Reasoning   through Step-by-Step Verification"></a>ChestX-Reasoner: Advancing Radiology Foundation Models with Reasoning   through Step-by-Step Verification</h2><p><strong>Authors:Ziqing Fan, Cheng Liang, Chaoyi Wu, Ya Zhang, Yanfeng Wang, Weidi Xie</strong></p>
<p>Recent advances in reasoning-enhanced large language models (LLMs) and multimodal LLMs (MLLMs) have significantly improved performance in complex tasks, yet medical AI models often overlook the structured reasoning processes inherent in clinical practice. In this work, we present ChestX-Reasoner, a radiology diagnosis MLLM designed to leverage process supervision mined directly from clinical reports, reflecting the step-by-step reasoning followed by radiologists. We construct a large dataset by extracting and refining reasoning chains from routine radiology reports. Our two-stage training framework combines supervised fine-tuning and reinforcement learning guided by process rewards to better align model reasoning with clinical standards. We introduce RadRBench-CXR, a comprehensive benchmark featuring 59K visual question answering samples with 301K clinically validated reasoning steps, and propose RadRScore, a metric evaluating reasoning factuality, completeness, and effectiveness. ChestX-Reasoner outperforms existing medical and general-domain MLLMs in both diagnostic accuracy and reasoning ability, achieving 16%, 5.9%, and 18% improvements in reasoning ability compared to the best medical MLLM, the best general MLLM, and its base model, respectively, as well as 3.3%, 24%, and 27% improvements in outcome accuracy. All resources are open-sourced to facilitate further research in medical reasoning MLLMs. </p>
<blockquote>
<p>è¿‘æœŸåœ¨æ¨ç†å¢å¼ºå‹å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å’Œå¤šæ¨¡æ€LLMï¼ˆMLLMsï¼‰æ–¹é¢çš„è¿›å±•ï¼Œå·²åœ¨å¤æ‚ä»»åŠ¡æ€§èƒ½ä¸Šå–å¾—äº†æ˜¾è‘—çš„æå‡ã€‚ç„¶è€Œï¼ŒåŒ»ç–—AIæ¨¡å‹å¾€å¾€ä¼šå¿½ç•¥ä¸´åºŠå®è·µä¸­çš„ç»“æ„åŒ–æ¨ç†è¿‡ç¨‹ã€‚åœ¨æ­¤å·¥ä½œä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ChestX-Reasonerï¼Œè¿™æ˜¯ä¸€ä¸ªä¸“ä¸ºæ”¾å°„å­¦è¯Šæ–­è®¾è®¡çš„MLLMï¼Œå®ƒèƒ½å¤Ÿåˆ©ç”¨ç›´æ¥ä»ä¸´åºŠæŠ¥å‘Šä¸­æŒ–æ˜å‡ºçš„è¿‡ç¨‹ç›‘ç£ï¼Œåæ˜ æ”¾å°„åŒ»å¸ˆéµå¾ªçš„é€æ­¥æ¨ç†ã€‚æˆ‘ä»¬é€šè¿‡ä»å¸¸è§„æ”¾å°„æŠ¥å‘Šä¸­æå–å¹¶ä¼˜åŒ–æ¨ç†é“¾ï¼Œæ„å»ºäº†ä¸€ä¸ªå¤§å‹æ•°æ®é›†ã€‚æˆ‘ä»¬çš„ä¸¤é˜¶æ®µè®­ç»ƒæ¡†æ¶ç»“åˆäº†ç›‘ç£å¾®è°ƒæ³•å’Œç”±è¿‡ç¨‹å¥–åŠ±å¼•å¯¼çš„æ›´å¼ºåŒ–å­¦ä¹ ï¼Œä»¥æ›´å¥½åœ°ä½¿æ¨¡å‹æ¨ç†ä¸ä¸´åºŠæ ‡å‡†ç›¸ç¬¦ã€‚æˆ‘ä»¬å¼•å…¥äº†RadRBench-CXRï¼Œè¿™æ˜¯ä¸€ä¸ªåŒ…å«59Kè§†è§‰é—®ç­”æ ·æœ¬å’Œ301Kä¸´åºŠéªŒè¯æ¨ç†æ­¥éª¤çš„ç»¼åˆåŸºå‡†æµ‹è¯•ï¼Œå¹¶æå‡ºäº†RadRScoreï¼Œä¸€ä¸ªè¯„ä¼°æ¨ç†çœŸå®æ€§ã€å®Œæ•´æ€§å’Œæœ‰æ•ˆæ€§çš„æŒ‡æ ‡ã€‚ChestX-Reasoneråœ¨è¯Šæ–­å’Œæ²»ç–—å‡†ç¡®æ€§æ–¹é¢å‡ä¼˜äºç°æœ‰çš„åŒ»ç–—å’Œé€šç”¨é¢†åŸŸMLLMsï¼Œåœ¨æ¨ç†èƒ½åŠ›æ–¹é¢ç›¸æ¯”æœ€ä½³çš„åŒ»ç–—MLLMã€æœ€ä½³é€šç”¨MLLMåŠå…¶åŸºç¡€æ¨¡å‹åˆ†åˆ«æé«˜äº†16%ã€5.9%å’Œ18%ï¼Œå¹¶ä¸”åœ¨ç»“æœå‡†ç¡®æ€§æ–¹é¢åˆ†åˆ«æé«˜äº†3.3%ã€24%å’Œ27%ã€‚æ‰€æœ‰èµ„æºå‡å·²å¼€æºï¼Œä»¥ä¿ƒè¿›åŒ»ç–—æ¨ç†MLLMçš„è¿›ä¸€æ­¥ç ”ç©¶ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.20930v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†ChestX-Reasonerè¿™ä¸€åŸºäºåŒ»å­¦å›¾åƒçš„å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰åœ¨æ”¾å°„è¯Šæ–­æ–¹é¢çš„åº”ç”¨ã€‚è¯¥æ¨¡å‹é€šè¿‡ä»ä¸´åºŠæŠ¥å‘Šä¸­æŒ–æ˜è¿‡ç¨‹ç›‘ç£ä¿¡æ¯ï¼Œç»“åˆæ”¾å°„ç§‘åŒ»ç”Ÿé€æ­¥æ¨ç†çš„è¿‡ç¨‹ï¼Œè®¾è®¡äº†ä¸€ç§ä¸¤é˜¶æ®µè®­ç»ƒæ¡†æ¶ï¼Œå¹¶å¼•å…¥äº†RadRBench-CXRåŸºå‡†æµ‹è¯•å’ŒRadRScoreè¯„ä¼°æŒ‡æ ‡ã€‚åœ¨è¯Šæ–­å’Œæ¨ç†èƒ½åŠ›æ–¹é¢ï¼ŒChestX-Reasonerç›¸è¾ƒäºç°æœ‰çš„åŒ»ç–—å’Œé€šç”¨é¢†åŸŸMLLMsè¡¨ç°å‡ºæ›´é«˜çš„æ€§èƒ½ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ChestX-Reasoneræ˜¯ä¸€ä¸ªé’ˆå¯¹æ”¾å°„è¯Šæ–­çš„å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆMLLMï¼‰ã€‚</li>
<li>è¯¥æ¨¡å‹é€šè¿‡æŒ–æ˜ä¸´åºŠæŠ¥å‘Šä¸­çš„è¿‡ç¨‹ç›‘ç£ä¿¡æ¯ï¼Œåæ˜ æ”¾å°„ç§‘åŒ»ç”Ÿçš„é€æ­¥æ¨ç†è¿‡ç¨‹ã€‚</li>
<li>ChestX-Reasoneré‡‡ç”¨ä¸¤é˜¶æ®µè®­ç»ƒæ¡†æ¶ï¼Œç»“åˆç›‘ç£å¾®è°ƒä¸å¼ºåŒ–å­¦ä¹ ï¼Œä»¥æ›´å¥½åœ°ç¬¦åˆä¸´åºŠæ ‡å‡†ã€‚</li>
<li>å¼•å…¥äº†RadRBench-CXRåŸºå‡†æµ‹è¯•å’ŒRadRScoreè¯„ä¼°æŒ‡æ ‡ï¼Œç”¨äºè¯„ä¼°æ¨¡å‹çš„æ¨ç†èƒ½åŠ›ã€‚</li>
<li>ChestX-Reasoneråœ¨è¯Šæ–­å’Œæ¨ç†èƒ½åŠ›æ–¹é¢ä¼˜äºç°æœ‰çš„åŒ»ç–—å’Œé€šç”¨é¢†åŸŸMLLMsã€‚</li>
<li>è¯¥æ¨¡å‹å®ç°äº†è¯Šæ–­å‡†ç¡®ç‡çš„æå‡ï¼Œå¹¶åœ¨æ¨ç†èƒ½åŠ›æ–¹é¢ç›¸è¾ƒäºæœ€ä½³åŒ»ç–—MLLMã€æœ€ä½³é€šç”¨MLLMåŠå…¶åŸºç¡€æ¨¡å‹åˆ†åˆ«æœ‰16%ã€5.9%å’Œ18%çš„æ”¹è¿›ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.20930">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-c13dd6b3d9288c7e374ba6efd6851d26.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-dfdb228ad3ba663f2bf723febf3e77d9.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-aca356da45c1ced05c918a5559a74dcb.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-5845baf023f841852911dad79ae8ef7b.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="RadSAM-Segmenting-3D-radiological-images-with-a-2D-promptable-model"><a href="#RadSAM-Segmenting-3D-radiological-images-with-a-2D-promptable-model" class="headerlink" title="RadSAM: Segmenting 3D radiological images with a 2D promptable model"></a>RadSAM: Segmenting 3D radiological images with a 2D promptable model</h2><p><strong>Authors:Julien Khlaut, Elodie Ferreres, Daniel Tordjman, HÃ©lÃ¨ne Philippe, Tom Boeken, Pierre Manceron, Corentin Dancette</strong></p>
<p>Medical image segmentation is a crucial and time-consuming task in clinical care, where mask precision is extremely important. The Segment Anything Model (SAM) offers a promising approach, as it provides an interactive interface based on visual prompting and edition to refine an initial segmentation. This model has strong generalization capabilities, does not rely on predefined classes, and adapts to diverse objects; however, it is pre-trained on natural images and lacks the ability to process medical data effectively. In addition, this model is built for 2D images, whereas a whole medical domain is based on 3D images, such as CT and MRI. Recent adaptations of SAM for medical imaging are based on 2D models, thus requiring one prompt per slice to segment 3D objects, making the segmentation process tedious. They also lack important features such as editing. To bridge this gap, we propose RadSAM, a novel method for segmenting 3D objects with a 2D model from a single prompt. In practice, we train a 2D model using noisy masks as initial prompts, in addition to bounding boxes and points. We then use this novel prompt type with an iterative inference pipeline to reconstruct the 3D mask slice-by-slice. We introduce a benchmark to evaluate the modelâ€™s ability to segment 3D objects in CT images from a single prompt and evaluate the modelsâ€™ out-of-domain transfer and edition capabilities. We demonstrate the effectiveness of our approach against state-of-the-art models on this benchmark using the AMOS abdominal organ segmentation dataset. </p>
<blockquote>
<p>åŒ»å­¦å›¾åƒåˆ†å‰²æ˜¯ä¸´åºŠæŠ¤ç†ä¸­ä¸€ä¸ªå…³é”®ä¸”è€—æ—¶çš„ä»»åŠ¡ï¼Œå…¶ä¸­é®ç½©ç²¾åº¦æä¸ºé‡è¦ã€‚Segment Anything Modelï¼ˆSAMï¼‰æä¾›äº†ä¸€ç§æœ‰å‰é€”çš„æ–¹æ³•ï¼Œå› ä¸ºå®ƒæä¾›äº†ä¸€ä¸ªåŸºäºè§†è§‰æç¤ºå’Œç¼–è¾‘çš„äº¤äº’å¼ç•Œé¢ï¼Œä»¥ä¼˜åŒ–åˆå§‹åˆ†å‰²ã€‚è¯¥æ¨¡å‹å…·æœ‰å¾ˆå¼ºçš„æ³›åŒ–èƒ½åŠ›ï¼Œä¸ä¾èµ–äºé¢„å®šä¹‰çš„ç±»åˆ«ï¼Œå¹¶èƒ½é€‚åº”ä¸åŒçš„å¯¹è±¡ï¼›ç„¶è€Œï¼Œå®ƒæ˜¯åŸºäºè‡ªç„¶å›¾åƒè¿›è¡Œé¢„è®­ç»ƒçš„ï¼Œç¼ºä¹æœ‰æ•ˆå¤„ç†åŒ»ç–—æ•°æ®çš„èƒ½åŠ›ã€‚æ­¤å¤–ï¼Œè¯¥æ¨¡å‹æ˜¯ä¸ºäºŒç»´å›¾åƒæ„å»ºçš„ï¼Œè€Œæ•´ä¸ªåŒ»å­¦é¢†åŸŸéƒ½æ˜¯åŸºäºä¸‰ç»´å›¾åƒï¼Œå¦‚CTå’ŒMRIã€‚æœ€è¿‘å¯¹SAMçš„åŒ»å­¦æˆåƒé€‚åº”éƒ½æ˜¯åŸºäºäºŒç»´æ¨¡å‹çš„ï¼Œå› æ­¤éœ€è¦å¯¹æ¯ä¸ªåˆ‡ç‰‡è¿›è¡Œæç¤ºä»¥åˆ†å‰²ä¸‰ç»´å¯¹è±¡ï¼Œä½¿å¾—åˆ†å‰²è¿‡ç¨‹å˜å¾—ä¹å‘³ã€‚å®ƒä»¬è¿˜ç¼ºå°‘é‡è¦çš„åŠŸèƒ½ï¼Œå¦‚ç¼–è¾‘åŠŸèƒ½ã€‚ä¸ºäº†å¼¥è¡¥è¿™ä¸€å·®è·ï¼Œæˆ‘ä»¬æå‡ºäº†RadSAMï¼Œè¿™æ˜¯ä¸€ç§ç”¨å•ä¸ªæç¤ºåˆ†å‰²äºŒç»´æ¨¡å‹ä¸­çš„ä¸‰ç»´å¯¹è±¡çš„æ–°æ–¹æ³•ã€‚åœ¨å®è·µä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨å¸¦æœ‰å™ªå£°é®ç½©ä½œä¸ºåˆå§‹æç¤ºè®­ç»ƒäºŒç»´æ¨¡å‹ï¼Œæ­¤å¤–è¿˜ä½¿ç”¨è¾¹ç•Œæ¡†å’Œç‚¹ã€‚ç„¶åï¼Œæˆ‘ä»¬ä½¿ç”¨è¿™ç§æ–°å‹æç¤ºä¸è¿­ä»£æ¨ç†ç®¡é“æ¥é€å±‚é‡å»ºä¸‰ç»´é®ç½©ã€‚æˆ‘ä»¬å¼•å…¥äº†ä¸€ä¸ªåŸºå‡†æµ‹è¯•æ¥è¯„ä¼°æ¨¡å‹ä»å•ä¸ªæç¤ºåœ¨CTå›¾åƒä¸­åˆ†å‰²ä¸‰ç»´å¯¹è±¡çš„èƒ½åŠ›ï¼Œå¹¶è¯„ä¼°æ¨¡å‹çš„è·¨åŸŸè¿ç§»å’Œç¼–è¾‘èƒ½åŠ›ã€‚æˆ‘ä»¬åœ¨AMOSè…¹éƒ¨å™¨å®˜åˆ†å‰²æ•°æ®é›†ä¸Šå±•ç¤ºäº†æˆ‘ä»¬çš„æ–¹æ³•ä¸æœ€å…ˆè¿›æ¨¡å‹ç›¸æ¯”çš„æœ‰æ•ˆæ€§ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.20837v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†åŒ»å­¦å›¾åƒåˆ†å‰²çš„é‡è¦æ€§åŠæ—¶é—´æˆæœ¬ï¼Œé‡ç‚¹ä»‹ç»äº†Segment Anything Modelï¼ˆSAMï¼‰çš„äº¤äº’å¼ç•Œé¢åŠå…¶åœ¨åˆå§‹åˆ†å‰²åŸºç¡€ä¸Šçš„è§†è§‰æç¤ºå’Œç¼–è¾‘åŠŸèƒ½ã€‚ç„¶è€Œï¼ŒSAMåœ¨è‡ªç„¶å›¾åƒä¸Šçš„é¢„è®­ç»ƒä½¿å…¶åœ¨å¤„ç†åŒ»ç–—æ•°æ®æ–¹é¢å­˜åœ¨ç¼ºé™·ã€‚é’ˆå¯¹è¿™ä¸€é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†RadSAMï¼Œè¿™æ˜¯ä¸€ç§ä½¿ç”¨å•ä¸ªæç¤ºå¯¹3Då¯¹è±¡è¿›è¡Œåˆ†å‰²çš„æ–°æ–¹æ³•ï¼Œé‡‡ç”¨2Dæ¨¡å‹è¿›è¡Œå®è·µã€‚é€šè¿‡è®­ç»ƒä½¿ç”¨å¸¦æœ‰å™ªå£°æ©ç çš„åˆå§‹æç¤ºã€è¾¹ç•Œæ¡†å’Œç‚¹ï¼Œç„¶åä½¿ç”¨è¿­ä»£æ¨ç†ç®¡é“é‡å»º3Dæ©ç åˆ‡ç‰‡ã€‚æœ€åï¼Œé€šè¿‡AMOSè…¹éƒ¨å™¨å®˜åˆ†å‰²æ•°æ®é›†è¯„ä¼°äº†è¯¥æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>åŒ»ç–—å›¾åƒåˆ†å‰²æ˜¯ä¸´åºŠå…³æ€€ä¸­çš„é‡è¦ä»»åŠ¡ï¼Œä¸”è€—æ—¶è¾ƒé•¿ï¼Œè¦æ±‚ç²¾ç¡®åº¦é«˜ã€‚</li>
<li>Segment Anything Modelï¼ˆSAMï¼‰æä¾›äº†ä¸€ä¸ªäº¤äº’å¼ç•Œé¢æ¥åŸºäºè§†è§‰æç¤ºè¿›è¡Œåˆå§‹åˆ†å‰²çš„ç²¾ç»†åŒ–ç¼–è¾‘ã€‚ä½†å…¶åœ¨å¤„ç†åŒ»ç–—æ•°æ®æ–¹é¢å­˜åœ¨ç¼ºé™·ã€‚</li>
<li>RadSAMæ˜¯æ–°çš„åŒ»å­¦å›¾åƒåˆ†å‰²æ–¹æ³•ï¼Œé€šè¿‡ä½¿ç”¨å•ä¸ªæç¤ºå¯¹3Då¯¹è±¡è¿›è¡Œåˆ†å‰²ï¼Œé‡‡ç”¨2Dæ¨¡å‹å®è·µã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.20837">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-6246d50ba875424ea8c03a6b12392d09.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-952bb8d7d944917b0521766c9024b79b.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-b8220c1bd13d045bbc2c80b6dd1eb119.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-40d4e86d4ebfcb273687f041baaf55ff.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-f9a9247a51392ce552c74bc5ff5ebeec.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b54066a7e0f754c4aed879d9cbb92f04.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="CMT-A-Cascade-MAR-with-Topology-Predictor-for-Multimodal-Conditional-CAD-Generation"><a href="#CMT-A-Cascade-MAR-with-Topology-Predictor-for-Multimodal-Conditional-CAD-Generation" class="headerlink" title="CMT: A Cascade MAR with Topology Predictor for Multimodal Conditional   CAD Generation"></a>CMT: A Cascade MAR with Topology Predictor for Multimodal Conditional   CAD Generation</h2><p><strong>Authors:Jianyu Wu, Yizhou Wang, Xiangyu Yue, Xinzhu Ma, Jingyang Guo, Dongzhan Zhou, Wanli Ouyang, Shixiang Tang</strong></p>
<p>While accurate and user-friendly Computer-Aided Design (CAD) is crucial for industrial design and manufacturing, existing methods still struggle to achieve this due to their over-simplified representations or architectures incapable of supporting multimodal design requirements. In this paper, we attempt to tackle this problem from both methods and datasets aspects. First, we propose a cascade MAR with topology predictor (CMT), the first multimodal framework for CAD generation based on Boundary Representation (B-Rep). Specifically, the cascade MAR can effectively capture the &#96;&#96;edge-counters-surfaceâ€™â€™ priors that are essential in B-Reps, while the topology predictor directly estimates topology in B-Reps from the compact tokens in MAR. Second, to facilitate large-scale training, we develop a large-scale multimodal CAD dataset, mmABC, which includes over 1.3 million B-Rep models with multimodal annotations, including point clouds, text descriptions, and multi-view images. Extensive experiments show the superior of CMT in both conditional and unconditional CAD generation tasks. For example, we improve Coverage and Valid ratio by +10.68% and +10.3%, respectively, compared to state-of-the-art methods on ABC in unconditional generation. CMT also improves +4.01 Chamfer on image conditioned CAD generation on mmABC. The dataset, code and pretrained network shall be released. </p>
<blockquote>
<p>åœ¨è®¡ç®—æœºè¾…åŠ©è®¾è®¡ï¼ˆCADï¼‰ä¸­ï¼Œå‡†ç¡®ä¸”ç”¨æˆ·å‹å¥½çš„è®¾è®¡å¯¹äºå·¥ä¸šè®¾è®¡å’Œåˆ¶é€ è‡³å…³é‡è¦ã€‚ç„¶è€Œï¼Œç°æœ‰çš„æ–¹æ³•ä»éš¾ä»¥è¾¾åˆ°è¿™ä¸€ç›®æ ‡ï¼Œå› ä¸ºå®ƒä»¬è¿‡äºç®€åŒ–çš„è¡¨ç¤ºå½¢å¼æˆ–æ¶æ„æ— æ³•æ”¯æŒå¤šæ¨¡å¼è®¾è®¡çš„è¦æ±‚ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬å°è¯•ä»æ–¹æ³•å’Œæ•°æ®é›†ä¸¤æ–¹é¢æ¥è§£å†³è¿™ä¸ªé—®é¢˜ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åŸºäºè¾¹ç•Œè¡¨ç¤ºï¼ˆB-Repï¼‰çš„çº§è”å¤šæ¨¡æ€è‡ªåŠ¨å›å½’ï¼ˆCascade MARï¼‰ä¸æ‹“æ‰‘é¢„æµ‹å™¨ï¼ˆTopology Predictorï¼‰çš„å¤šæ¨¡æ€æ¡†æ¶ï¼ˆCMTï¼‰ã€‚å…·ä½“è€Œè¨€ï¼Œçº§è”å¤šæ¨¡æ€è‡ªåŠ¨å›å½’å¯ä»¥æœ‰æ•ˆåœ°æ•æ‰åœ¨B-Repä¸­è‡³å…³é‡è¦çš„â€œè¾¹ç¼˜è¡¨é¢å…ˆéªŒâ€ä¿¡æ¯ï¼Œè€Œæ‹“æ‰‘é¢„æµ‹å™¨åˆ™ç›´æ¥ä»MARä¸­çš„ç´§å‡‘æ ‡è®°ä¼°è®¡B-Repä¸­çš„æ‹“æ‰‘ç»“æ„ã€‚å…¶æ¬¡ï¼Œä¸ºäº†ä¿ƒè¿›å¤§è§„æ¨¡è®­ç»ƒï¼Œæˆ‘ä»¬å¼€å‘äº†ä¸€ä¸ªå¤§è§„æ¨¡çš„å¤šæ¨¡å¼CADæ•°æ®é›†mmABCï¼ŒåŒ…å«è¶…è¿‡130ä¸‡ä¸ªå…·æœ‰å¤šæ¨¡å¼æ³¨é‡Šçš„B-Repæ¨¡å‹ï¼ŒåŒ…æ‹¬ç‚¹äº‘ã€æ–‡æœ¬æè¿°å’Œå¤šå…ƒå›¾åƒè§†å›¾ã€‚å¤§é‡çš„å®éªŒè¡¨æ˜ï¼ŒCMTåœ¨æœ‰æ¡ä»¶å’Œæ— æ¡ä»¶çš„CADç”Ÿæˆä»»åŠ¡ä¸­éƒ½è¡¨ç°å‡ºå“è¶Šçš„æ€§èƒ½ã€‚ä¾‹å¦‚ï¼Œåœ¨æ— æ¡ä»¶ç”Ÿæˆä¸­ï¼Œä¸æœ€æ–°æŠ€æœ¯ç›¸æ¯”ï¼Œæˆ‘ä»¬çš„è¦†ç›–ç‡æé«˜äº†+10.68%ï¼Œæœ‰æ•ˆæ¯”ä¾‹æé«˜äº†+10.3%ã€‚æ­¤å¤–ï¼Œåœ¨mmABCçš„å›¾åƒæ¡ä»¶CADç”Ÿæˆä¸­ï¼ŒCMTçš„ChamferæŒ‡æ ‡æé«˜äº†+4.01ã€‚æ•°æ®é›†ã€ä»£ç å’Œé¢„è®­ç»ƒç½‘ç»œå°†å…¬å¼€å‘å¸ƒã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.20830v1">PDF</a> </p>
<p><strong>Summary</strong><br>     æœ¬æ–‡æå‡ºä¸€ç§åŸºäºè¾¹ç•Œè¡¨ç¤ºï¼ˆB-Repï¼‰çš„å¤šæ¨¡æ€è®¡ç®—æœºè¾…åŠ©è®¾è®¡ï¼ˆCADï¼‰ç”Ÿæˆæ¡†æ¶â€”â€”çº§è”MARæ‹“æ‰‘é¢„æµ‹å™¨ï¼ˆCMTï¼‰ã€‚åŒæ—¶ï¼Œä¸ºäº†æ”¯æŒå¤§è§„æ¨¡è®­ç»ƒï¼Œä½œè€…æ„å»ºäº†ä¸€ä¸ªå¤§å‹å¤šæ¨¡æ€CADæ•°æ®é›†mmABCã€‚CMTåœ¨æ¡ä»¶å’Œæ— æ¡ä»¶CADç”Ÿæˆä»»åŠ¡ä¸­è¡¨ç°ä¼˜è¶Šï¼Œç›¸æ¯”ç°æœ‰æ–¹æ³•æ˜¾è‘—æé«˜è¦†ç›–ç‡ã€æœ‰æ•ˆæ€§å’ŒChamferæŒ‡æ ‡ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ç°æœ‰è®¡ç®—æœºè¾…åŠ©è®¾è®¡ï¼ˆCADï¼‰æ–¹æ³•éš¾ä»¥å…¼é¡¾å‡†ç¡®æ€§å’Œç”¨æˆ·å‹å¥½æ€§ï¼Œéœ€è¦æ”¹è¿›æ–¹æ³•å’Œæ•°æ®é›†ä»¥æ”¯æŒå¤šæ¨¡æ€è®¾è®¡éœ€æ±‚ã€‚</li>
<li>æœ¬æ–‡æå‡ºä¸€ç§åŸºäºè¾¹ç•Œè¡¨ç¤ºï¼ˆB-Repï¼‰çš„å¤šæ¨¡æ€æ¡†æ¶â€”â€”çº§è”MARæ‹“æ‰‘é¢„æµ‹å™¨ï¼ˆCMTï¼‰ï¼Œå¯æœ‰æ•ˆæ•æ‰CADç”Ÿæˆä¸­çš„â€œè¾¹ç¼˜è®¡æ•°è¡¨é¢â€å…ˆéªŒä¿¡æ¯ã€‚</li>
<li>ä¸ºæ”¯æŒå¤§è§„æ¨¡è®­ç»ƒï¼Œä½œè€…æ„å»ºäº†ä¸€ä¸ªå¤§å‹å¤šæ¨¡æ€CADæ•°æ®é›†mmABCï¼ŒåŒ…å«è¶…è¿‡130ä¸‡B-Repæ¨¡å‹å’Œå¤šæ¨¡æ€æ³¨é‡Šã€‚</li>
<li>CMTåœ¨æ— æ¡ä»¶ç”Ÿæˆä¸­ç›¸æ¯”ç°æœ‰æ–¹æ³•æé«˜äº†è¦†ç›–ç‡ï¼ˆ+10.68%ï¼‰å’Œæœ‰æ•ˆæ€§ï¼ˆ+10.3%ï¼‰ã€‚</li>
<li>CMTåœ¨å›¾åƒæ¡ä»¶CADç”Ÿæˆä»»åŠ¡ä¸Šæé«˜äº†ChamferæŒ‡æ ‡ï¼ˆ+4.01ï¼‰ã€‚</li>
<li>ä½œè€…è®¡åˆ’å…¬å¼€æ•°æ®é›†ã€ä»£ç å’Œé¢„è®­ç»ƒç½‘ç»œã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.20830">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-9db00bfe0c61466277addf416c670d98.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-2936671fa0355c5c627dcddb597a9b71.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-ebabf71c915f3a2d002000ac57078350.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-529e224112a58816d56628dae200be6e.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="Multiwavelength-correlation-studies-in-the-era-of-CTAO"><a href="#Multiwavelength-correlation-studies-in-the-era-of-CTAO" class="headerlink" title="Multiwavelength correlation studies in the era of CTAO"></a>Multiwavelength correlation studies in the era of CTAO</h2><p><strong>Authors:Michael Zacharias, Elina Lindfors, Patrizia Romano, Daniela Dorner, Stefano Vercellone, Matteo Cerruti, Jonathan Biteau</strong></p>
<p>Correlations between various multiwavelength (MWL) bands are an intermittent feature in blazar light curves; that is, they are observed in some instances but not in others. With the CTAO we will obtain detailed very-high-energy (VHE) gamma-ray light curves for many sources also during their low states, enabling detailed MWL correlation studies. For two blazars, the HBL Mrk,421 and the FSRQ PKS,1510-089, the long-term X-ray and optical light curves are used to induce variations in input parameters of the lepto-hadronic one-zone code OneHaLe. We show light curves in the CTA energy range for three different energy thresholds. The results are: 1) the presence of relativistic protons has a significant effect on the correlation of the light curves as the emerging pair cascade prolongs flaring states at the highest energies; and 2) comparison of the theoretical light curves with existing VHE gamma-ray data shows that both leptonic and hadronic models can only partially reproduce the data. </p>
<blockquote>
<p>å¤šæ³¢é•¿ï¼ˆMWLï¼‰æ³¢æ®µä¹‹é—´çš„ç›¸å…³æ€§åœ¨Blazarå…‰å˜æ›²çº¿ä¸­æ˜¯é—´æ­‡æ€§ç‰¹å¾ï¼›ä¹Ÿå°±æ˜¯è¯´ï¼Œåœ¨æŸäº›æƒ…å†µä¸‹å¯ä»¥è§‚å¯Ÿåˆ°ï¼Œä½†åœ¨å…¶ä»–æƒ…å†µä¸‹åˆ™ä¸èƒ½ã€‚é€šè¿‡CTAOï¼Œæˆ‘ä»¬å°†è·å¾—è®¸å¤šæºåœ¨ä½çŠ¶æ€ä¸‹çš„è¯¦ç»†çš„ç”šé«˜èƒ½ï¼ˆVHEï¼‰ä¼½é©¬å°„çº¿å…‰å˜æ›²çº¿ï¼Œä»è€Œèƒ½å¤Ÿè¿›è¡Œè¯¦ç»†çš„MWLç›¸å…³æ€§ç ”ç©¶ã€‚å¯¹äºä¸¤ä¸ªBlazarsï¼Œå³HBL Mrk 421å’ŒFSRQ PKS 1510-089ï¼Œæˆ‘ä»¬ä½¿ç”¨äº†é•¿æœŸXå°„çº¿å’Œå…‰å­¦å…‰å˜æ›²çº¿æ¥å¼•å¯¼lepto-hadronicå•åŒºä»£ç OneHaLeçš„è¾“å…¥å‚æ•°å˜åŒ–ã€‚æˆ‘ä»¬å±•ç¤ºäº†ä¸‰ä¸ªä¸åŒèƒ½é‡é˜ˆå€¼åœ¨CTAèƒ½é‡èŒƒå›´å†…çš„å…‰å˜æ›²çº¿ã€‚ç»“æœæ˜¯ï¼š1ï¼‰ç›¸å¯¹è®ºè´¨å­çš„å­˜åœ¨å¯¹å…‰å˜æ›²çº¿çš„ç›¸å…³æ€§æœ‰é‡å¤§å½±å“ï¼Œå› ä¸ºæ–°å…´çš„å¯¹çº§è”å»¶é•¿äº†æœ€é«˜èƒ½é‡çš„è€€å‘çŠ¶æ€ï¼›2ï¼‰å°†ç†è®ºå…‰å˜æ›²çº¿ä¸ç°æœ‰çš„VHEä¼½é©¬å°„çº¿æ•°æ®è¿›è¡Œæ¯”è¾ƒè¡¨æ˜ï¼Œæ— è®ºæ˜¯ç”µå­å‹è¿˜æ˜¯å¼ºå­å‹æ¨¡å‹éƒ½åªèƒ½éƒ¨åˆ†åœ°å†ç°æ•°æ®ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.20731v1">PDF</a> Conference proceedings paper of the GAMMA 2024; to be published in   Memorie della Societ`a Astronomica Italiana</p>
<p><strong>Summary</strong><br>     å¤šæ³¢é•¿æ³¢æ®µé—´çš„ç›¸å…³æ€§åœ¨Blazarå…‰å˜æ›²çº¿ä¸­æ˜¯é—´æ­‡æ€§ç‰¹å¾ï¼Œæœ‰æ—¶è§‚å¯Ÿåˆ°ï¼Œæœ‰æ—¶ä¸è§‚å¯Ÿåˆ°ã€‚ä½¿ç”¨CTAOï¼Œæˆ‘ä»¬å°†åœ¨è®¸å¤šæºçš„ä½çŠ¶æ€ä¸‹è·å¾—è¯¦ç»†çš„ç”šé«˜èƒ½ä¼½é©¬å°„çº¿å…‰å˜æ›²çº¿ï¼Œä»è€Œè¿›è¡Œè¯¦ç»†çš„å¤šæ³¢é•¿ç›¸å…³æ€§ç ”ç©¶ã€‚å¯¹äºä¸¤ä¸ªBlazarsï¼Œå³HBL Mrk 421å’ŒFSRQ PKS 1510-089ï¼Œé•¿æœŸXå°„çº¿å’Œå…‰å­¦å…‰å˜æ›²çº¿è¢«ç”¨äºè¯±å¯¼lepto-hadronicä¸€åŒºä»£ç OneHaLeçš„è¾“å…¥å‚æ•°çš„å˜åŒ–ã€‚æˆ‘ä»¬å±•ç¤ºäº†åœ¨CTAèƒ½é‡èŒƒå›´å†…ä¸‰ç§ä¸åŒèƒ½é‡é˜ˆå€¼çš„å…‰å˜æ›²çº¿ã€‚ç»“æœæ˜¾ç¤ºï¼š1ï¼‰ç›¸å¯¹è®ºè´¨å­çš„å­˜åœ¨å¯¹å…‰å˜æ›²çº¿çš„ç›¸å…³æ€§æœ‰æ˜¾è‘—å½±å“ï¼Œå› ä¸ºäº§ç”Ÿçš„æ­£è´Ÿç”µå­çº§è”å»¶é•¿äº†æœ€é«˜èƒ½é‡çš„è€€å‘çŠ¶æ€ï¼›2ï¼‰ç†è®ºå…‰å˜æ›²çº¿ä¸ç°æœ‰çš„ç”šé«˜èƒ½ä¼½é©¬å°„çº¿æ•°æ®çš„æ¯”è¾ƒè¡¨æ˜ï¼Œæ— è®ºæ˜¯è½»å­æ¨¡å‹è¿˜æ˜¯å¼ºå­æ¨¡å‹éƒ½åªèƒ½éƒ¨åˆ†åœ°å†ç°æ•°æ®ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤šæ³¢é•¿æ³¢æ®µç›¸å…³æ€§åœ¨Blazarå…‰å˜æ›²çº¿ä¸­æ˜¯é—´æ­‡æ€§ç‰¹å¾ã€‚</li>
<li>CTAOå°†å…è®¸æˆ‘ä»¬è·å¾—è¯¦ç»†çš„ç”šé«˜èƒ½ä¼½é©¬å°„çº¿å…‰å˜æ›²çº¿ï¼ŒåŒ…æ‹¬æºçš„ä½çŠ¶æ€ã€‚</li>
<li>å¯¹äºMrk 421å’ŒPKS 1510-089è¿™ä¸¤ä¸ªBlazarsï¼Œé•¿æœŸXå°„çº¿å’Œå…‰å­¦å…‰å˜æ›²çº¿è¢«ç”¨äºç ”ç©¶è¾“å…¥å‚æ•°å˜åŒ–å¯¹lepto-hadronicæ¨¡å‹çš„å½±å“ã€‚</li>
<li>ç›¸å¯¹è®ºè´¨å­çš„å­˜åœ¨å¯¹å…‰å˜æ›²çº¿çš„ç›¸å…³æ€§æœ‰æ˜¾è‘—å½±å“ï¼Œäº§ç”Ÿçš„æ­£è´Ÿç”µå­çº§è”å»¶é•¿äº†æœ€é«˜èƒ½é‡çš„è€€å‘çŠ¶æ€ã€‚</li>
<li>ç†è®ºå…‰å˜æ›²çº¿ä¸ç°æœ‰ç”šé«˜èƒ½ä¼½é©¬å°„çº¿æ•°æ®çš„æ¯”è¾ƒæ˜¾ç¤ºï¼Œå½“å‰æ¨¡å‹åªèƒ½éƒ¨åˆ†åœ°è§£é‡Šè§‚æµ‹æ•°æ®ã€‚</li>
<li>åœ¨CTAèƒ½é‡èŒƒå›´å†…ï¼Œä¸åŒçš„èƒ½é‡é˜ˆå€¼ä¼šå½±å“å…‰å˜æ›²çº¿çš„è¡¨ç°ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.20731">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-6cf750e44c8ea5358ca01bca34ca0421.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-36569f9d7efb3d6112b2dd71cc336f40.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ec0e8f2ab25af6477b1dfa4786eb1acf.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="Modeling-of-the-time-resolved-spectral-energy-distribution-of-blazar-OJ-287-from-2008-to-2023-a-comprehensive-multi-epoch-study"><a href="#Modeling-of-the-time-resolved-spectral-energy-distribution-of-blazar-OJ-287-from-2008-to-2023-a-comprehensive-multi-epoch-study" class="headerlink" title="Modeling of the time-resolved spectral energy distribution of blazar OJ   287 from 2008 to 2023: a comprehensive multi-epoch study"></a>Modeling of the time-resolved spectral energy distribution of blazar OJ   287 from 2008 to 2023: a comprehensive multi-epoch study</h2><p><strong>Authors:G. Harutyunyan, N. Sahakyan, D. BÃ©guÃ©</strong></p>
<p>We present a comprehensive analysis of the time-resolved spectral energy distributions (SEDs) of the blazar OJ 287 over a 15-year period (2008-2023), using multi-wavelength data. In the $\gamma$-ray band, multiple flaring episodes were observed, with the strongest flare reaching a peak flux of $(5.60\pm1.11)\times10^{-7}:{\rm photons:cm^{-2}:s^{-1}}$ on MJD 55869.03 (04 November 2011). In the optical&#x2F;UV band, the source was in an active state between MJD 57360 (04 December 2015) and 57960 (26 July 2017), during which the highest flux of $(1.07\pm0.02)\times10^{-10}:{\rm erg:cm^{-2}:s^{-1}}$ was observed on MJD 57681.23 (20 October 2016). In the X-ray band, both the flux and spectral index exhibit variability. To investigate the origin of the broadband emission from OJ 287, we systematically modeled 739 quasi-simultaneous SEDs using a leptonic model that self-consistently accounts for particle injection and cooling. This analysis is possible thanks to the recent development of a surrogate neural-network-based model, trained on kinetic simulations. This innovative, time-resolved, neural network-based approach overcomes the limitations of traditional single-epoch SED modeling, enabling to explore the temporal evolution of key model parameters, such as the magnetic field strength, Doppler factor, and electron injection distribution, across different states of the source. We identified distinct emission states characterized by unique combinations of magnetic field $ B $, electron index $ p $, and Doppler boost $ \delta $, associated to different underlying mechanisms such as varying acceleration processes (e.g., shocks, turbulence) and magnetic confinement. The analysis provides insights into the jet physics processes, including particle acceleration mechanisms and dynamic changes in the jet structure. </p>
<blockquote>
<p>æˆ‘ä»¬å¯¹OJ 287çš„ä¸ºæœŸ15å¹´ï¼ˆ2008å¹´è‡³2023å¹´ï¼‰çš„æ—¶åŸŸå…‰è°±èƒ½é‡åˆ†å¸ƒï¼ˆSEDsï¼‰è¿›è¡Œäº†ç»¼åˆåˆ†æï¼Œå¹¶åˆ©ç”¨å¤šæ³¢é•¿æ•°æ®å¯¹å…¶è¿›è¡Œç ”ç©¶ã€‚åœ¨ä¼½é©¬å°„çº¿æ³¢æ®µï¼Œè§‚å¯Ÿåˆ°å¤šæ¬¡è€€æ–‘çˆ†å‘äº‹ä»¶ï¼Œå…¶ä¸­æœ€å¼ºçƒˆçš„è€€æ–‘åœ¨ä¿®æ­£å„’ç•¥æ—¥ï¼ˆMJDï¼‰ä¸º55869.03ï¼ˆå³æ ¼æ—å°¼æ²»æ ‡å‡†æ—¶é—´ï¼‰æ—¶è¾¾åˆ°å³°å€¼æµé‡ï¼ˆæ¯å¹³æ–¹å˜ç±³æ¯ç§’æœ‰å…‰å­ï¼‰ã€‚åœ¨å…‰å­¦&#x2F;ç´«å¤–æ³¢æ®µï¼Œæºå¤„äºæ´»è·ƒçŠ¶æ€ï¼Œèµ·å§‹äºä¿®æ­£å„’ç•¥æ—¥ï¼ˆMJDï¼‰ä¸º57360ï¼ˆå³æ ¼æ—å°¼æ²»æ ‡å‡†æ—¶é—´ï¼‰ï¼Œç»“æŸäºä¿®æ­£å„’ç•¥æ—¥ï¼ˆMJDï¼‰ä¸º57960ï¼Œå…¶ä¸­æœ€é«˜æµé‡ä¸ºæ¯å¹³æ–¹å˜ç±³æ¯ç§’è§‚æµ‹åˆ°å…‰å­èƒ½é‡ä¸º*ï¼ˆè¿™é‡Œæ— æ³•è½¬æ¢æ•°å­¦ç¬¦å·çš„è¡¨è¾¾ï¼‰ã€‚åœ¨åˆ†æè¿‡ç¨‹ä¸­å‘ç°äº†ä¸€ç§ç‰¹æ®Šçš„å…‰å­¦ç°è±¡ã€‚ä¸ºäº†ç ”ç©¶OJ 287çš„å®½å¸¦å‘å°„çš„æ¥æºï¼Œæˆ‘ä»¬ç³»ç»Ÿåœ°ä½¿ç”¨äº†ç”µå­æ¨¡å‹å¯¹è·å¾—çš„åå°„å…‰åº¦è°±è¿›è¡Œå»ºæ¨¡åˆ†æï¼Œè¯¥æ¨¡å‹èƒ½å¤Ÿè‡ªæ´½åœ°è§£é‡Šç²’å­æ³¨å…¥å’Œå†·å´è¿‡ç¨‹ã€‚è¿™ä¸€åˆ†æå¾—ç›ŠäºåŸºäºåŠ¨åŠ›å­¦çš„æ¨¡æ‹Ÿè®­ç»ƒè€Œå¼€å‘å‡ºçš„æ›¿ä»£ç¥ç»ç½‘ç»œæ¨¡å‹çš„å‘å±•ã€‚è¿™ç§åˆ›æ–°çš„ã€åŸºäºæ—¶é—´çš„ç¥ç»ç½‘ç»œæ–¹æ³•å…‹æœäº†ä¼ ç»Ÿå•æ—¶ä»£åå°„å…‰åº¦è°±å»ºæ¨¡æ–¹æ³•çš„å±€é™æ€§ï¼Œèƒ½å¤Ÿæ¢ç´¢å…³é”®æ¨¡å‹å‚æ•°çš„æ—¶é—´æ¼”å˜ï¼Œå¦‚ç£åœºå¼ºåº¦ã€å¤šæ™®å‹’å› å­å’Œç”µå­æ³¨å…¥åˆ†å¸ƒç­‰åœ¨ä¸åŒæºçŠ¶æ€ä¸‹çš„å˜åŒ–ã€‚æˆ‘ä»¬ç¡®å®šäº†ä¸åŒçš„å‘å°„çŠ¶æ€ï¼Œè¿™äº›çŠ¶æ€ç”±ç‹¬ç‰¹çš„ç£åœºå¼ºåº¦ã€ç”µå­æŒ‡æ•°å’Œå¤šæ™®å‹’å¢å¼ºå› å­ç»„åˆè€Œæˆï¼Œå¹¶ä¸ä¸åŒçš„æ½œåœ¨æœºåˆ¶ç›¸å…³ï¼Œå¦‚å˜åŒ–çš„åŠ é€Ÿè¿‡ç¨‹ï¼ˆä¾‹å¦‚å†²å‡»ã€æ¹æµï¼‰å’Œç£çº¦æŸã€‚åˆ†ææä¾›äº†å¯¹å°„æµç‰©ç†è¿‡ç¨‹çš„è§è§£ï¼ŒåŒ…æ‹¬ç²’å­åŠ é€Ÿæœºåˆ¶å’Œå°„æµç»“æ„çš„åŠ¨æ€å˜åŒ–ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.20627v1">PDF</a> Accepted for publication in MNRAS</p>
<p><strong>Summary</strong><br>     ç»¼åˆåˆ†æäº†OJ 287åäº”å¹´æœŸé—´çš„æ—¶åŸŸå…‰è°±èƒ½é‡åˆ†å¸ƒï¼ˆSEDsï¼‰ã€‚ç ”ç©¶ç»“æœæ˜¾ç¤ºï¼Œåœ¨Î³å°„çº¿æ³¢æ®µå­˜åœ¨å¤šæ¬¡è€€æ–‘çˆ†å‘äº‹ä»¶ï¼Œæœ€å¼ºè€€æ–‘åœ¨ç‰¹å®šæ—¥æœŸè¾¾åˆ°é«˜å³°æµé‡ã€‚åœ¨å…‰å­¦&#x2F;ç´«å¤–çº¿æ³¢æ®µï¼Œæºå¤„äºæ´»è·ƒçŠ¶æ€å¹¶è§‚å¯Ÿåˆ°æœ€é«˜æµé‡ã€‚ä½¿ç”¨è±æ™®é¡¿æ¨¡å‹ç³»ç»Ÿåœ°æ¨¡æ‹Ÿäº†SEDsï¼Œå¹¶é€šè¿‡åŸºäºç¥ç»ç½‘ç»œçš„æ¨¡æ‹Ÿæ¨¡å‹å…‹æœä¼ ç»Ÿå•çºªå…ƒSEDå»ºæ¨¡çš„é™åˆ¶ï¼Œæ¢ç´¢å…³é”®æ¨¡å‹å‚æ•°çš„æ—¶ç©ºæ¼”å˜ã€‚åˆ†ææ­ç¤ºäº†ä¸åŒçš„å‘å°„çŠ¶æ€ä¸ç‹¬ç‰¹çš„ç£åœºã€ç”µå­æŒ‡æ•°å’Œå¤šæ™®å‹’å¢å¼ºç›¸å…³è”ï¼Œåæ˜ äº†ä¸åŒçš„åŠ é€Ÿæœºåˆ¶å’ŒåŠ¨æ€å˜åŒ–çš„å–·æµç»“æ„ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>OJ 287åœ¨é•¿è¾¾15å¹´çš„æœŸé—´è¡¨ç°å‡ºæ˜¾è‘—çš„å¤šæ³¢é•¿æ´»åŠ¨ï¼Œç‰¹åˆ«æ˜¯åœ¨Î³å°„çº¿æ³¢æ®µçš„è€€æ–‘äº‹ä»¶å’Œåœ¨å…‰å­¦&#x2F;ç´«å¤–çº¿æ³¢æ®µçš„æ´»è·ƒçŠ¶æ€ã€‚</li>
<li>æœ€å¼ºÎ³å°„çº¿è€€æ–‘çš„å³°å€¼æµé‡å’Œåœ¨å…‰å­¦&#x2F;ç´«å¤–çº¿æ³¢æ®µçš„æœ€é«˜æµé‡å·²è¢«è®°å½•ã€‚</li>
<li>åˆ©ç”¨è±æ™®é¡¿æ¨¡å‹ç³»ç»Ÿåœ°æ¨¡æ‹Ÿäº†OJ 287çš„å®½å¸¦å‘å°„ï¼Œæ­ç¤ºäº†å…¶å¤æ‚çš„ç‰©ç†è¿‡ç¨‹ã€‚</li>
<li>åŸºäºç¥ç»ç½‘ç»œçš„æ¨¡æ‹Ÿæ¨¡å‹å…‹æœäº†ä¼ ç»ŸSEDå»ºæ¨¡çš„é™åˆ¶ï¼Œä¸ºæ¢ç´¢å…³é”®æ¨¡å‹å‚æ•°çš„æ—¶ç©ºæ¼”å˜æä¾›äº†å¯èƒ½ã€‚</li>
<li>åˆ†ææ˜¾ç¤ºï¼Œä¸åŒçš„å‘å°„çŠ¶æ€ä¸ç‹¬ç‰¹çš„ç£åœºã€ç”µå­æŒ‡æ•°å’Œå¤šæ™®å‹’å¢å¼ºæœ‰å…³ï¼Œè¿™äº›å¯èƒ½ä¸ä¸åŒçš„åŠ é€Ÿæœºåˆ¶ï¼ˆå¦‚å†²å‡»ã€æ¹æµï¼‰å’Œå–·æµç»“æ„çš„åŠ¨æ€å˜åŒ–æœ‰å…³ã€‚</li>
<li>è¯¥ç ”ç©¶ä¸ºç†è§£OJ 287çš„å–·æµç‰©ç†è¿‡ç¨‹å’Œç²’å­åŠ é€Ÿæœºåˆ¶æä¾›äº†æ·±å…¥è§è§£ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.20627">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-32f7e0a21e662ebaf0c8a105eed73801.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-f2bc5f3143db6bf5ab0e202f9d3d16f1.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="SAM-Guided-Robust-Representation-Learning-for-One-Shot-3D-Medical-Image-Segmentation"><a href="#SAM-Guided-Robust-Representation-Learning-for-One-Shot-3D-Medical-Image-Segmentation" class="headerlink" title="SAM-Guided Robust Representation Learning for One-Shot 3D Medical Image   Segmentation"></a>SAM-Guided Robust Representation Learning for One-Shot 3D Medical Image   Segmentation</h2><p><strong>Authors:Jia Wang, Yunan Mei, Jiarui Liu, Xin Fan</strong></p>
<p>One-shot medical image segmentation (MIS) is crucial for medical analysis due to the burden of medical experts on manual annotation. The recent emergence of the segment anything model (SAM) has demonstrated remarkable adaptation in MIS but cannot be directly applied to one-shot medical image segmentation (MIS) due to its reliance on labor-intensive user interactions and the high computational cost. To cope with these limitations, we propose a novel SAM-guided robust representation learning framework, named RRL-MedSAM, to adapt SAM to one-shot 3D MIS, which exploits the strong generalization capabilities of the SAM encoder to learn better feature representation. We devise a dual-stage knowledge distillation (DSKD) strategy to distill general knowledge between natural and medical images from the foundation model to train a lightweight encoder, and then adopt a mutual exponential moving average (mutual-EMA) to update the weights of the general lightweight encoder and medical-specific encoder. Specifically, pseudo labels from the registration network are used to perform mutual supervision for such two encoders. Moreover, we introduce an auto-prompting (AP) segmentation decoder which adopts the mask generated from the general lightweight model as a prompt to assist the medical-specific model in boosting the final segmentation performance. Extensive experiments conducted on three public datasets, i.e., OASIS, CT-lung demonstrate that the proposed RRL-MedSAM outperforms state-of-the-art one-shot MIS methods for both segmentation and registration tasks. Especially, our lightweight encoder uses only 3% of the parameters compared to the encoder of SAM-Base. </p>
<blockquote>
<p>ä¸€æ¬¡æ€§åŒ»å­¦å½±åƒåˆ†å‰²ï¼ˆMISï¼‰å¯¹äºåŒ»å­¦åˆ†æè‡³å…³é‡è¦ï¼Œå› ä¸ºåŒ»å­¦ä¸“å®¶æ‰‹åŠ¨æ ‡æ³¨çš„è´Ÿæ‹…å¾ˆé‡ã€‚æœ€è¿‘å‡ºç°çš„ä»»ä½•åˆ†å‰²æ¨¡å‹ï¼ˆSAMï¼‰åœ¨MISä¸­è¡¨ç°å‡ºäº†æ˜¾è‘—çš„é€‚åº”æ€§ï¼Œä½†ç”±äºå…¶ä¾èµ–åŠ³åŠ¨å¯†é›†å‹çš„ç”¨æˆ·äº¤äº’å’Œé«˜è®¡ç®—æˆæœ¬ï¼Œä¸èƒ½ç›´æ¥åº”ç”¨äºä¸€æ¬¡æ€§åŒ»å­¦å½±åƒåˆ†å‰²ï¼ˆMISï¼‰ã€‚ä¸ºäº†åº”å¯¹è¿™äº›å±€é™æ€§ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°å‹çš„SAMå¼•å¯¼ç¨³å¥è¡¨ç¤ºå­¦ä¹ æ¡†æ¶ï¼Œåä¸ºRRL-MedSAMï¼Œä»¥é€‚åº”ä¸€æ¬¡æ€§3DMISã€‚è¯¥æ¡†æ¶åˆ©ç”¨SAMç¼–ç å™¨çš„å¼ºå¤§æ³›åŒ–èƒ½åŠ›æ¥å­¦ä¹ æ›´å¥½çš„ç‰¹å¾è¡¨ç¤ºã€‚æˆ‘ä»¬è®¾è®¡äº†ä¸€ç§åŒé˜¶æ®µçŸ¥è¯†è’¸é¦ï¼ˆDSKDï¼‰ç­–ç•¥ï¼Œä»åŸºç¡€æ¨¡å‹ä¸­æç‚¼è‡ªç„¶åŒ»å­¦å›¾åƒä¹‹é—´çš„é€šç”¨çŸ¥è¯†ï¼Œä»¥è®­ç»ƒä¸€ä¸ªè½»é‡çº§ç¼–ç å™¨ï¼Œç„¶åé‡‡ç”¨ç›¸äº’æŒ‡æ•°ç§»åŠ¨å¹³å‡ï¼ˆmutual-EMAï¼‰æ¥æ›´æ–°é€šç”¨è½»é‡çº§ç¼–ç å™¨å’ŒåŒ»å­¦ä¸“ç”¨ç¼–ç å™¨çš„æƒé‡ã€‚å…·ä½“æ¥è¯´ï¼Œæ¥è‡ªæ³¨å†Œç½‘ç»œçš„ä¼ªæ ‡ç­¾è¢«ç”¨æ¥å¯¹è¿™ä¸¤ç§ç¼–ç å™¨è¿›è¡Œç›¸äº’ç›‘ç£ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§è‡ªåŠ¨æç¤ºï¼ˆAPï¼‰åˆ†å‰²è§£ç å™¨ï¼Œè¯¥è§£ç å™¨é‡‡ç”¨é€šç”¨è½»é‡çº§æ¨¡å‹ç”Ÿæˆçš„æ©è†œä½œä¸ºæç¤ºï¼Œè¾…åŠ©åŒ»å­¦ä¸“ç”¨æ¨¡å‹æé«˜æœ€ç»ˆçš„åˆ†å‰²æ€§èƒ½ã€‚åœ¨OASISã€CT-lungä¸‰ä¸ªå…¬å…±æ•°æ®é›†ä¸Šè¿›è¡Œçš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼Œæ‰€æå‡ºçš„RRL-MedSAMåœ¨åˆ†å‰²å’Œæ³¨å†Œä»»åŠ¡ä¸Šçš„æ€§èƒ½å‡ä¼˜äºæœ€æ–°çš„å•æ¬¡MISæ–¹æ³•ã€‚å°¤å…¶æ˜¯ï¼Œæˆ‘ä»¬çš„è½»é‡çº§ç¼–ç å™¨ä»…ä½¿ç”¨SAM-Baseç¼–ç å™¨çš„3%å‚æ•°ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.20501v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†ä¸€ç§åä¸ºRRL-MedSAMçš„æ–°æ¡†æ¶ï¼Œç”¨äºå°†SAMæ¨¡å‹é€‚åº”äºä¸€æ¬¡æ‹æ‘„çš„ä¸‰ç»´åŒ»å­¦å›¾åƒåˆ†å‰²ï¼ˆMISï¼‰ã€‚è¯¥æ¡†æ¶é€šè¿‡åˆ©ç”¨SAMç¼–ç å™¨çš„å¼ºå¤§æ³›åŒ–èƒ½åŠ›æ¥å­¦ä¹ æ›´å¥½çš„ç‰¹å¾è¡¨ç¤ºï¼Œå¹¶é€šè¿‡åŒé˜¶æ®µçŸ¥è¯†è’¸é¦ç­–ç•¥å’Œäº’æŒ‡æ•°ç§»åŠ¨å¹³å‡æŠ€æœ¯æ¥ä¼˜åŒ–ç¼–ç å™¨æƒé‡ã€‚æ­¤å¤–ï¼Œè¿˜å¼•å…¥äº†ä¸€ç§è‡ªåŠ¨æç¤ºåˆ†å‰²è§£ç å™¨ï¼Œä»¥æé«˜æœ€ç»ˆåˆ†å‰²æ€§èƒ½ã€‚åœ¨å¤šä¸ªå…¬å…±æ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒRRL-MedSAMåœ¨å•æ¬¡æ‹æ‘„MISçš„åˆ†å‰²å’Œæ³¨å†Œä»»åŠ¡ä¸Šä¼˜äºç°æœ‰æŠ€æœ¯ï¼Œä¸”å…¶è½»é‡åŒ–ç¼–ç å™¨ä½¿ç”¨çš„å‚æ•°ä»…ä¸ºSAM-Baseç¼–ç å™¨çš„3%ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>ä¸€æ¬¡æ‹æ‘„åŒ»å­¦å›¾åƒåˆ†å‰²ï¼ˆMISï¼‰å¯¹äºåŒ»å­¦åˆ†æè‡³å…³é‡è¦ï¼Œå› ä¸ºåŒ»å­¦ä¸“å®¶æ‰‹åŠ¨æ ‡æ³¨çš„è´Ÿæ‹…å¾ˆé‡ã€‚</li>
<li>SAMæ¨¡å‹è™½åœ¨MISä¸­è¡¨ç°å‡ºè‰¯å¥½çš„é€‚åº”æ€§ï¼Œä½†ç”±äºå…¶ä¾èµ–åŠ³åŠ¨å¯†é›†å‹çš„ç”¨æˆ·äº¤äº’å’Œé«˜è®¡ç®—æˆæœ¬ï¼Œæ— æ³•ç›´æ¥åº”ç”¨äºä¸€æ¬¡æ‹æ‘„MISã€‚</li>
<li>RRL-MedSAMæ¡†æ¶é€šè¿‡åˆ©ç”¨SAMçš„æ³›åŒ–èƒ½åŠ›ï¼Œé€‚åº”äº†å•æ¬¡æ‹æ‘„çš„ä¸‰ç»´åŒ»å­¦å›¾åƒåˆ†å‰²ã€‚</li>
<li>é‡‡ç”¨åŒé˜¶æ®µçŸ¥è¯†è’¸é¦ç­–ç•¥æ¥æç‚¼åŸºç¡€æ¨¡å‹ä¸­çš„é€šç”¨çŸ¥è¯†ï¼Œå¹¶ç”¨äºè®­ç»ƒè½»é‡åŒ–ç¼–ç å™¨ã€‚</li>
<li>é‡‡ç”¨äº’æŒ‡æ•°ç§»åŠ¨å¹³å‡æŠ€æœ¯æ›´æ–°é€šç”¨è½»é‡åŒ–ç¼–ç å™¨å’ŒåŒ»ç–—ä¸“ç”¨ç¼–ç å™¨çš„æƒé‡ã€‚</li>
<li>é€šè¿‡å¼•å…¥ä¼ªæ ‡ç­¾å’Œè‡ªåŠ¨æç¤ºåˆ†å‰²è§£ç å™¨æ¥æé«˜æœ€ç»ˆåˆ†å‰²æ€§èƒ½ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.20501">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-d5643f2ff1bc1ca2354dfb3319224813.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-224fdbd6db02405895f63495f1389d12.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-faf3f2b5ea9b539e10c1cb3dfd06b480.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-730e5cc703a527462c15f1b7cef4d3ac.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="LymphAtlas-A-Unified-Multimodal-Lymphoma-Imaging-Repository-Delivering-AI-Enhanced-Diagnostic-Insight"><a href="#LymphAtlas-A-Unified-Multimodal-Lymphoma-Imaging-Repository-Delivering-AI-Enhanced-Diagnostic-Insight" class="headerlink" title="LymphAtlas- A Unified Multimodal Lymphoma Imaging Repository Delivering   AI-Enhanced Diagnostic Insight"></a>LymphAtlas- A Unified Multimodal Lymphoma Imaging Repository Delivering   AI-Enhanced Diagnostic Insight</h2><p><strong>Authors:Jiajun Ding, Beiyao Zhu, Xiaosheng Liu, Lishen Zhang, Zhao Liu</strong></p>
<p>This study integrates PET metabolic information with CT anatomical structures to establish a 3D multimodal segmentation dataset for lymphoma based on whole-body FDG PET&#x2F;CT examinations, which bridges the gap of the lack of standardised multimodal segmentation datasets in the field of haematological malignancies. We retrospectively collected 483 examination datasets acquired between March 2011 and May 2024, involving 220 patients (106 non-Hodgkin lymphoma, 42 Hodgkin lymphoma); all data underwent ethical review and were rigorously de-identified. Complete 3D structural information was preserved during data acquisition, preprocessing and annotation, and a high-quality dataset was constructed based on the nnUNet format. By systematic technical validation and evaluation of the preprocessing process, annotation quality and automatic segmentation algorithm, the deep learning model trained based on this dataset is verified to achieve accurate segmentation of lymphoma lesions in PET&#x2F;CT images with high accuracy, good robustness and reproducibility, which proves the applicability and stability of this dataset in accurate segmentation and quantitative analysis. The deep fusion of PET&#x2F;CT images achieved with this dataset not only significantly improves the accurate portrayal of the morphology, location and metabolic features of tumour lesions, but also provides solid data support for early diagnosis, clinical staging and personalized treatment, and promotes the development of automated image segmentation and precision medicine based on deep learning. The dataset and related resources are available at <a target="_blank" rel="noopener" href="https://github.com/SuperD0122/LymphAtlas-">https://github.com/SuperD0122/LymphAtlas-</a>. </p>
<blockquote>
<p>æœ¬ç ”ç©¶ç»“åˆäº†PETä»£è°¢ä¿¡æ¯ä¸CTè§£å‰–ç»“æ„ï¼ŒåŸºäºå…¨èº«FDG PET&#x2F;CTæ£€æŸ¥ï¼Œå»ºç«‹äº†æ·‹å·´ç˜¤çš„3Då¤šæ¨¡æ€åˆ†å‰²æ•°æ®é›†ã€‚è¿™ä¸€ç ”ç©¶å¡«è¡¥äº†è¡€æ¶²æ¶æ€§è‚¿ç˜¤é¢†åŸŸæ ‡å‡†åŒ–å¤šæ¨¡æ€åˆ†å‰²æ•°æ®é›†ç¼ºä¹çš„ç©ºç™½ã€‚æˆ‘ä»¬å›é¡¾æ€§åœ°æ”¶é›†äº†2011å¹´3æœˆè‡³2024å¹´5æœˆæœŸé—´é‡‡é›†çš„483ä¸ªæ£€æŸ¥æ•°æ®é›†ï¼Œæ¶‰åŠ220åæ‚£è€…ï¼ˆå…¶ä¸­106ä¾‹ä¸ºééœå¥‡é‡‘æ·‹å·´ç˜¤ï¼Œ42ä¾‹ä¸ºéœå¥‡é‡‘æ·‹å·´ç˜¤ï¼‰ï¼›æ‰€æœ‰æ•°æ®å‡ç»è¿‡ä¼¦ç†å®¡æŸ¥ï¼Œå¹¶è¿›è¡Œäº†ä¸¥æ ¼çš„åŒ¿åå¤„ç†ã€‚åœ¨æ•°æ®é‡‡é›†ã€é¢„å¤„ç†å’Œæ ‡æ³¨è¿‡ç¨‹ä¸­ï¼Œå®Œæ•´çš„3Dç»“æ„ä¿¡æ¯è¢«ä¿ç•™ä¸‹æ¥ï¼ŒåŸºäºnnUNetæ ¼å¼æ„å»ºäº†é«˜è´¨é‡çš„æ•°æ®é›†ã€‚é€šè¿‡å¯¹é¢„å¤„ç†è¿‡ç¨‹ã€æ ‡æ³¨è´¨é‡å’Œè‡ªåŠ¨åˆ†å‰²ç®—æ³•çš„ç³»ç»ŸæŠ€æœ¯éªŒè¯å’Œè¯„ä¼°ï¼ŒéªŒè¯äº†åœ¨æ­¤æ•°æ®é›†ä¸Šè®­ç»ƒçš„æ·±åº¦å­¦ä¹ æ¨¡å‹ï¼Œèƒ½å¤Ÿå®ç°PET&#x2F;CTå›¾åƒä¸­æ·‹å·´ç˜¤ç—…å˜çš„å‡†ç¡®åˆ†å‰²ï¼Œå…·æœ‰è¾ƒé«˜çš„å‡†ç¡®æ€§ã€è‰¯å¥½çš„ç¨³å¥æ€§å’Œå¯é‡å¤æ€§ï¼Œè¯æ˜äº†è¯¥æ•°æ®é›†åœ¨å‡†ç¡®åˆ†å‰²å’Œå®šé‡åˆ†æä¸­çš„é€‚ç”¨æ€§å’Œç¨³å®šæ€§ã€‚é€šè¿‡è¯¥æ•°æ®é›†å®ç°çš„PET&#x2F;CTå›¾åƒçš„æ·±åº¦èåˆï¼Œä¸ä»…æ˜¾è‘—æé«˜äº†è‚¿ç˜¤ç—…å˜å½¢æ€ã€ä½ç½®å’Œä»£è°¢ç‰¹å¾çš„å‡†ç¡®æè¿°ï¼Œè€Œä¸”ä¸ºæ—©æœŸè¯Šç–—ã€ä¸´åºŠåˆ†æœŸå’Œä¸ªæ€§åŒ–æ²»ç–—æä¾›äº†åšå®çš„æ•°æ®æ”¯æŒï¼Œä¿ƒè¿›äº†åŸºäºæ·±åº¦å­¦ä¹ çš„è‡ªåŠ¨å›¾åƒåˆ†å‰²å’Œç²¾å‡†åŒ»å­¦çš„å‘å±•ã€‚è¯¥æ•°æ®é›†åŠç›¸å…³èµ„æºå¯é€šè¿‡<a target="_blank" rel="noopener" href="https://github.com/SuperD0122/LymphAtlas-%E8%8E%B7%E5%8F%96%E3%80%82">https://github.com/SuperD0122/LymphAtlas-è·å–ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.20454v1">PDF</a> 17pages,4 figures</p>
<p><strong>Summary</strong>ï¼šè¯¥ç ”ç©¶å°†PETä»£è°¢ä¿¡æ¯ä¸CTè§£å‰–ç»“æ„ç›¸ç»“åˆï¼Œåˆ›å»ºäº†åŸºäºå…¨èº«æ°Ÿè„±æ°§è‘¡è„ç³–PET&#x2F;CTæ£€æŸ¥çš„æ·‹å·´ç˜¤3Då¤šæ¨¡æ€åˆ†å‰²æ•°æ®é›†ï¼Œå¡«è¡¥äº†è¡€æ¶²ç³»ç»Ÿæ¶æ€§è‚¿ç˜¤æ ‡å‡†åŒ–å¤šæ¨¡æ€åˆ†å‰²æ•°æ®é›†çš„ç©ºç™½ã€‚é€šè¿‡æ·±åº¦å­¦ä¹ æ¨¡å‹è®­ç»ƒï¼ŒéªŒè¯äº†è¯¥æ•°æ®é›†åœ¨PET&#x2F;CTå›¾åƒä¸­å‡†ç¡®åˆ†å‰²æ·‹å·´ç˜¤ç—…å˜çš„å¯è¡Œæ€§ã€ç¨³å®šæ€§å’Œå¯é æ€§ã€‚è¯¥æ•°æ®é›†çš„æ·±åº¦èåˆä¸ä»…æé«˜äº†è‚¿ç˜¤ç—…å˜å½¢æ€ã€ä½ç½®å’Œä»£è°¢ç‰¹å¾çš„å‡†ç¡®æè¿°ï¼Œè¿˜ä¸ºæ—©æœŸè¯Šæ–­ã€ä¸´åºŠåˆ†æœŸå’Œä¸ªæ€§åŒ–æ²»ç–—æä¾›äº†åšå®çš„æ•°æ®æ”¯æŒï¼Œä¿ƒè¿›äº†åŸºäºæ·±åº¦å­¦ä¹ çš„è‡ªåŠ¨å›¾åƒåˆ†å‰²å’Œç²¾å‡†åŒ»å­¦çš„å‘å±•ã€‚</p>
<p><strong>Key Takeaways</strong>:</p>
<ul>
<li>è¯¥ç ”ç©¶å»ºç«‹äº†åŸºäºå…¨èº«æ°Ÿè„±æ°§è‘¡è„ç³–PET&#x2F;CTæ£€æŸ¥çš„æ·‹å·´ç˜¤3Då¤šæ¨¡æ€åˆ†å‰²æ•°æ®é›†ï¼Œå¡«è¡¥äº†æ ‡å‡†åŒ–å¤šæ¨¡æ€åˆ†å‰²æ•°æ®é›†çš„ç©ºç™½ã€‚</li>
<li>æ•°æ®é›†åŒ…å«äº†æ¥è‡ª220åæ‚£è€…çš„483ä¸ªæ£€æŸ¥æ•°æ®é›†ï¼Œæ¶‰åŠééœå¥‡é‡‘æ·‹å·´ç˜¤å’Œéœå¥‡é‡‘æ·‹å·´ç˜¤ã€‚</li>
<li>æ•°æ®é›†ç»è¿‡ä¼¦ç†å®¡æŸ¥å¹¶ä¸¥æ ¼åŒ¿ååŒ–å¤„ç†ï¼Œä¿è¯äº†æ•°æ®çš„è´¨é‡å’Œéšç§ã€‚</li>
<li>é€šè¿‡æ·±åº¦å­¦ä¹ æ¨¡å‹è®­ç»ƒï¼ŒéªŒè¯äº†æ•°æ®é›†çš„å‡†ç¡®æ€§ã€ç¨³å®šæ€§å’Œå¯é æ€§ã€‚</li>
<li>æ•°æ®é›†çš„æ·±åº¦èåˆæé«˜äº†è‚¿ç˜¤ç—…å˜çš„å½¢æ€ã€ä½ç½®å’Œä»£è°¢ç‰¹å¾çš„æè¿°å‡†ç¡®æ€§ã€‚</li>
<li>è¯¥æ•°æ®é›†ä¸ºæ—©æœŸè¯Šæ–­ã€ä¸´åºŠåˆ†æœŸå’Œä¸ªæ€§åŒ–æ²»ç–—æä¾›äº†æ•°æ®æ”¯æŒã€‚</li>
<li>è¯¥æ•°æ®é›†ä¿ƒè¿›äº†åŸºäºæ·±åº¦å­¦ä¹ çš„è‡ªåŠ¨å›¾åƒåˆ†å‰²å’Œç²¾å‡†åŒ»å­¦çš„å‘å±•ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.20454">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-29d13cb3550604a8e2edfc4f9493222c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-51bfa3dbabd98ae5ac879538596ad91e.jpg" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="Consensus-Recommendations-for-Hyperpolarized-1-13C-pyruvate-MRI-Multi-center-Human-Studies"><a href="#Consensus-Recommendations-for-Hyperpolarized-1-13C-pyruvate-MRI-Multi-center-Human-Studies" class="headerlink" title="Consensus Recommendations for Hyperpolarized [1-13C]pyruvate MRI   Multi-center Human Studies"></a>Consensus Recommendations for Hyperpolarized [1-13C]pyruvate MRI   Multi-center Human Studies</h2><p><strong>Authors:Shonit Punwani, Peder EZ Larson, Christoffer Laustsen, Jan VanderMeulen, Jan Henrik ArdenkjÃ¦r-Larsen, Adam W. Autry, James A. Bankson, Jenna Bernard, Robert Bok, Lotte Bonde Bertelsen, Jenny Che, Albert P. Chen, Rafat Chowdhury, Arnaud Comment, Charles H. Cunningham, Duy Dang, Ferdia A Gallagher, Adam Gaunt, Yangcan Gong, Jeremy W. Gordon, Ashley Grimmer, James Grist, Esben SÃ¸vsÃ¸ Szocska Hansen, Mathilde Hauge Lerche, Richard L. Hesketh, Jan-Bernd Hoevener, Ching-Yi Hsieh, Kayvan R. Keshari, Sebastian Kozerke, Titus Lanz, Dirk Mayer, Mary McLean, Jae Mo Park, Jim Slater, Damian Tyler, Jean-Luc Vanderheyden, Daniel Vigneron, Cornelius von Morze, Duan Xu, Fulvio Zaccagna, Vlad Zaha, the HP 13C MRI Consensus Group</strong></p>
<p>Magnetic resonance imaging of hyperpolarized (HP) [1-13C]pyruvate allows in-vivo assessment of metabolism and has translated into human studies across diseases at 15 centers worldwide. Consensus on best practice for multi-center studies is required to develop clinical applications. This paper presents the results of a 2-round formal consensus building exercise carried out by experts with HP [1-13C]pyruvate human study experience. Twenty-nine participants from 13 sites brought together expertise in pharmacy methods, MR physics, translational imaging, and data-analysis; with the goal of providing recommendations and best practice statements on conduct of multi-center human studies of HP [1-13C]pyruvate MRI.   Overall, the group reached consensus on approximately two-thirds of 246 statements in the questionnaire, covering â€˜HP 13C-Pyruvate Preparationâ€™, â€˜MRI System Setup, Calibration, and Phantomsâ€™, â€˜Acquisition and Reconstructionâ€™, and â€˜Data Analysis and Quantificationâ€™.   Consensus was present across categories, examples include that: (i) different HP pyruvate preparation methods could be used in human studies, but that the same release criteria have to be followed; (ii) site qualification and quality assurance must be performed with phantoms and that the same field strength must be used, but that the rest of the system setup and calibration methods could be determined by individual sites; (iii) the same pulse sequence and reconstruction methods were preferable, but the exact choice should be governed by the anatomical target; (iv) normalized metabolite area-under-curve (AUC) values and metabolite AUC were the preferred metabolism metrics.   The work confirmed areas of consensus for multi-center study conduct and identified where further research is required to ascertain best practice. </p>
<blockquote>
<p>æåŒ–ï¼ˆHPï¼‰[1-13C]ä¸™é…®é…¸ç›çš„ç£å…±æŒ¯æˆåƒå…è®¸å¯¹ä½“å†…ä»£è°¢è¿›è¡Œè¯„ä¼°ï¼Œå¹¶å·²åœ¨å…¨çƒèŒƒå›´å†…15ä¸ªä¸­å¿ƒè¿›è¡Œç–¾ç—…ç›¸å…³çš„ä¸´åºŠç ”ç©¶ã€‚ä¸ºäº†å¼€å‘ä¸´åºŠåº”ç”¨ï¼Œéœ€è¦å¯¹å¤šä¸­å¿ƒç ”ç©¶è¾¾æˆæœ€ä½³å®è·µçš„å…±è¯†ã€‚æœ¬æ–‡ä»‹ç»äº†å…·æœ‰æåŒ–ï¼ˆHPï¼‰[1-13C]ä¸™é…®é…¸ç›äººä½“ç ”ç©¶ç»éªŒçš„ä¸“å®¶æ‰€å¼€å±•çš„ä¸ºæœŸä¸¤è½®çš„å½¢å¼åŒ–å…±è¯†å»ºè®¾çš„æˆæœã€‚æ¥è‡ª13ä¸ªä¸åŒç«™ç‚¹çš„29åå‚ä¸è€…æ±‡èšäº†è¯ç‰©æ–¹æ³•ã€MRç‰©ç†å­¦ã€è½¬åŒ–æˆåƒå’Œæ•°æ®åˆ†ææ–¹é¢çš„ä¸“ä¸šçŸ¥è¯†ï¼Œæ—¨åœ¨å°±æåŒ–ï¼ˆHPï¼‰[1-13C]ä¸™é…®é…¸ç›MRIå¤šä¸­å¿ƒäººä½“ç ”ç©¶æä¾›å»ºè®®å’Œæœ€ä½³å®è·µå£°æ˜ã€‚æ€»ä½“è€Œè¨€ï¼Œè¯¥ç»„å¯¹é—®å·ä¸­çš„å¤§çº¦ä¸‰åˆ†ä¹‹äºŒçš„246ä¸ªé™ˆè¿°è¾¾æˆäº†å…±è¯†ï¼Œæ¶µç›–äº†â€œHP 13Cä¸™é…®é…¸ç›åˆ¶å¤‡â€ã€â€œMRIç³»ç»Ÿå®‰è£…ã€æ ¡å‡†å’Œå¹»å½±â€ã€â€œé‡‡é›†å’Œé‡å»ºâ€ä»¥åŠâ€œæ•°æ®åˆ†æå’Œé‡åŒ–â€ã€‚å„åˆ†ç±»ä¸­éƒ½å­˜åœ¨å…±è¯†ï¼Œä¾‹å¦‚ï¼šï¼ˆiï¼‰äººä½“ç ”ç©¶ä¸­å¯ä»¥ä½¿ç”¨ä¸åŒçš„HPä¸™é…®é…¸ç›åˆ¶å¤‡æ–¹æ³•ï¼Œä½†å¿…é¡»éµå¾ªç›¸åŒçš„é‡Šæ”¾æ ‡å‡†ï¼›ï¼ˆiiï¼‰å¿…é¡»ä½¿ç”¨å¹»å½±è¿›è¡Œç«™ç‚¹èµ„æ ¼è®¤è¯å’Œè´¨é‡ä¿è¯ï¼Œå¹¶ä¸”å¿…é¡»ä½¿ç”¨ç›¸åŒçš„ç£åœºå¼ºåº¦ï¼Œè€Œç³»ç»Ÿçš„å…¶ä½™è®¾ç½®å’Œæ ¡å‡†æ–¹æ³•å¯ç”±å„ä¸ªç«™ç‚¹è‡ªè¡Œå†³å®šï¼›ï¼ˆiiiï¼‰ç›¸åŒçš„è„‰å†²åºåˆ—å’Œé‡å»ºæ–¹æ³•è¾ƒä¸ºç†æƒ³ï¼Œä½†ç¡®åˆ‡é€‰æ‹©åº”ç”±è§£å‰–ç›®æ ‡æ¥å†³å®šï¼›ï¼ˆivï¼‰å½’ä¸€åŒ–çš„ä»£è°¢äº§ç‰©æ›²çº¿ä¸‹é¢ç§¯ï¼ˆAUCï¼‰å€¼å’Œä»£è°¢äº§ç‰©AUCæ˜¯é¦–é€‰çš„ä»£è°¢æŒ‡æ ‡ã€‚è¿™é¡¹å·¥ä½œç¡®è®¤äº†å¤šä¸­å¿ƒç ”ç©¶å¼€å±•çš„å…±è¯†é¢†åŸŸï¼Œå¹¶ç¡®å®šäº†éœ€è¦è¿›ä¸€æ­¥ç ”ç©¶çš„é¢†åŸŸä»¥ç¡®å®šæœ€ä½³å®è·µã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.20440v1">PDF</a> </p>
<p><strong>Summary</strong><br>    æœ¬æ–‡ä»‹ç»äº†åˆ©ç”¨è¶…æåŒ–[Â¹Â³C]ä¸™é…®é…¸ç›ç£å…±æŒ¯æˆåƒè¿›è¡Œäººä½“ä»£è°¢è¯„ä¼°çš„ç ”ç©¶ç°çŠ¶ã€‚ä¸“å®¶é€šè¿‡ä¸¤è½®å…±è¯†å»ºè®¾æ´»åŠ¨ï¼Œå°±è¶…æåŒ–[Â¹Â³C]ä¸™é…®é…¸ç›ç£å…±æŒ¯æˆåƒçš„å¤šä¸­å¿ƒäººä½“ç ”ç©¶æä¾›äº†å»ºè®®å’Œæœ€ä½³å®è·µå£°æ˜ã€‚å…±è¯†æ¶‰åŠHP 1Â³C-ä¸™é…®é…¸ç›åˆ¶å¤‡ã€MRIç³»ç»Ÿè®¾å®šã€æ ¡å‡†å’Œå¹»ä½“ã€é‡‡é›†å’Œé‡å»ºã€æ•°æ®åˆ†æå’Œé‡åŒ–ç­‰æ–¹é¢ã€‚æ­¤å¤–ï¼Œæœ¬æ–‡ç¡®å®šäº†éœ€è¦è¿›ä¸€æ­¥ç ”ç©¶çš„é¢†åŸŸï¼Œä»¥æ˜ç¡®æœ€ä½³å®è·µã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>ç£æŒ¯æˆåƒæŠ€æœ¯é€šè¿‡è¶…æåŒ–ï¼ˆHPï¼‰[Â¹Â³C]ä¸™é…®é…¸ç›ï¼Œèƒ½å¤Ÿè¿›è¡Œäººä½“ä»£è°¢è¯„ä¼°ï¼Œç›®å‰å…¨çƒæœ‰åäº”ä¸ªç ”ç©¶ä¸­å¿ƒåº”ç”¨è¯¥æŠ€æœ¯è¿›è¡Œç–¾ç—…ç ”ç©¶ã€‚</li>
<li>ä¸“å®¶é€šè¿‡ä¸¤è½®å…±è¯†å»ºè®¾æ´»åŠ¨ï¼Œå°±å¦‚ä½•å¼€å±•å¤šä¸­å¿ƒäººä½“ç ”ç©¶è¾¾æˆäº†å…±è¯†ã€‚å‚ä¸è€…æ¥è‡ªå…¨çƒåä¸‰ä¸ªç ”ç©¶ä¸­å¿ƒï¼Œæ¶µç›–äº†è¯å­¦æ–¹æ³•ã€ç£å…±æŒ¯ç‰©ç†ã€ç¿»è¯‘æˆåƒå’Œæ•°æ®åˆ†æç­‰é¢†åŸŸçš„ä¸“å®¶ã€‚</li>
<li>å…±è¯†æ¶µç›–äº†HP [Â¹Â³C]ä¸™é…®é…¸ç›åˆ¶å¤‡ã€MRIç³»ç»Ÿè®¾ç½®ä¸æ ¡å‡†ã€æ•°æ®é‡‡é›†ä¸é‡å»ºä»¥åŠæ•°æ®åˆ†æä¸é‡åŒ–ç­‰æ–¹é¢ã€‚åœ¨å‡†å¤‡é˜¶æ®µï¼Œè¾¾æˆäº†å…±è¯†è®¤ä¸ºå¯ä»¥ä½¿ç”¨ä¸åŒçš„è¶…æåŒ–ä¸™é…®é…¸ç›åˆ¶å¤‡æ–¹æ³•ï¼Œä½†å¿…é¡»éµå¾ªç›¸åŒçš„é‡Šæ”¾æ ‡å‡†ï¼›å¯¹äºMRç³»ç»Ÿçš„è®¾ç½®ä¸æ ¡å‡†æ–¹æ³•ä¸Šæ‹¥æœ‰æ›´å¤§çš„çµæ´»æ€§ã€‚å…³äºå½±åƒè·å–åŠé‡å»ºé˜¶æ®µçš„ç ”ç©¶è¾¾æˆäº†å¹¿æ³›çš„å…±è¯†ï¼Œæ¨èä½¿ç”¨ç›¸åŒçš„è„‰å†²åºåˆ—å’Œé‡å»ºæ–¹æ³•ï¼Œå¹¶æ ¹æ®è§£å‰–ç›®æ ‡è¿›è¡Œç²¾ç¡®é€‰æ‹©ã€‚æ­¤å¤–åœ¨æ•°æ®è§£æé˜¶æ®µå¯¹äºæ ‡å‡†åŒ–ä»£è°¢ç‰©é¢ç§¯æ›²çº¿ä¸‹ç§¯åˆ†å€¼ï¼ˆAUCï¼‰å’Œä»£è°¢ç‰©æµ“åº¦çš„æ ‡å‡†åŒ–æ•°æ®ä¸€è‡´åŒæ„æ¥å—åº¦æœ€é«˜ä½œä¸ºååº”ä»£è°¢çš„æœ‰æ•ˆæ•°æ®ã€‚æŒ‡å‡ºå¼€å±•è¿™ä¸€å·¥ä½œæ‰€éœ€åç»­è¿›ä¸€æ­¥çš„è°ƒæŸ¥é¢†åŸŸåŠå‘å±•æ–¹å‘å¦‚æŒç»­çš„å‰‚å‹æ”¹å–„ä»¥é€‚åº”ç—…äººç‰¹å¼‚éœ€æ±‚ä»¥åŠå¯¹ä½“è´¨å½±åƒçš„æ ‡å‡†æµ‹è¯•é‡åŒ–ä»¥å®šä¹‰é€‚åº”ç—‡ï¼›å®šæ€§å½±å“ä¸´åºŠåº”ç”¨è¿›ä¸€æ­¥æ¨å¹¿åˆ°ä¸åŒåœ°åŒºæ¶‰åŠä¸åŒç–¾ç—…é¢†åŸŸç­‰æ–¹å‘ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.20440">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-ae4a19b2ade45e459d2f5945442495cf.jpg" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1><h2 id="MicarVLMoE-A-Modern-Gated-Cross-Aligned-Vision-Language-Mixture-of-Experts-Model-for-Medical-Image-Captioning-and-Report-Generation"><a href="#MicarVLMoE-A-Modern-Gated-Cross-Aligned-Vision-Language-Mixture-of-Experts-Model-for-Medical-Image-Captioning-and-Report-Generation" class="headerlink" title="MicarVLMoE: A Modern Gated Cross-Aligned Vision-Language Mixture of   Experts Model for Medical Image Captioning and Report Generation"></a>MicarVLMoE: A Modern Gated Cross-Aligned Vision-Language Mixture of   Experts Model for Medical Image Captioning and Report Generation</h2><p><strong>Authors:Amaan Izhar, Nurul Japar, Norisma Idris, Ting Dang</strong></p>
<p>Medical image reporting (MIR) aims to generate structured clinical descriptions from radiological images. Existing methods struggle with fine-grained feature extraction, multimodal alignment, and generalization across diverse imaging types, often relying on vanilla transformers and focusing primarily on chest X-rays. We propose MicarVLMoE, a vision-language mixture-of-experts model with gated cross-aligned fusion, designed to address these limitations. Our architecture includes: (i) a multiscale vision encoder (MSVE) for capturing anatomical details at varying resolutions, (ii) a multihead dual-branch latent attention (MDLA) module for vision-language alignment through latent bottleneck representations, and (iii) a modulated mixture-of-experts (MoE) decoder for adaptive expert specialization. We extend MIR to CT scans, retinal imaging, MRI scans, and gross pathology images, reporting state-of-the-art results on COVCTR, MMR, PGROSS, and ROCO datasets. Extensive experiments and ablations confirm improved clinical accuracy, cross-modal alignment, and model interpretability. Code is available at <a target="_blank" rel="noopener" href="https://github.com/AI-14/micar-vl-moe">https://github.com/AI-14/micar-vl-moe</a>. </p>
<blockquote>
<p>åŒ»å­¦å›¾åƒæŠ¥å‘Šï¼ˆMIRï¼‰æ—¨åœ¨ä»æ”¾å°„å­¦å›¾åƒä¸­ç”Ÿæˆç»“æ„åŒ–ä¸´åºŠæè¿°ã€‚ç°æœ‰æ–¹æ³•åœ¨è¿›è¡Œç²¾ç»†ç‰¹å¾æå–ã€å¤šæ¨¡å¼å¯¹é½ä»¥åŠåœ¨å¤šç§æˆåƒç±»å‹ä¸Šçš„é€šç”¨åŒ–æ–¹é¢å­˜åœ¨å›°éš¾ï¼Œé€šå¸¸ä¾èµ–äºæ™®é€šå˜å‹å™¨ï¼Œå¹¶ä¸”ä¸»è¦å…³æ³¨èƒ¸éƒ¨Xå…‰ç‰‡ã€‚æˆ‘ä»¬æå‡ºäº†MicarVLMoEï¼Œè¿™æ˜¯ä¸€ç§å¸¦æœ‰é—¨æ§äº¤å‰å¯¹é½èåˆçš„è§†è§‰è¯­è¨€æ··åˆä¸“å®¶æ¨¡å‹ï¼Œæ—¨åœ¨è§£å†³è¿™äº›å±€é™æ€§ã€‚æˆ‘ä»¬çš„æ¶æ„åŒ…æ‹¬ï¼šï¼ˆiï¼‰ç”¨äºåœ¨ä¸åŒåˆ†è¾¨ç‡ä¸‹æ•è·è§£å‰–ç»†èŠ‚çš„å¤šå°ºåº¦è§†è§‰ç¼–ç å™¨ï¼ˆMSVEï¼‰ï¼Œï¼ˆiiï¼‰ç”¨äºé€šè¿‡æ½œåœ¨ç“¶é¢ˆè¡¨ç¤ºè¿›è¡Œè§†è§‰è¯­è¨€å¯¹é½çš„å¤šå¤´åŒåˆ†æ”¯æ½œåœ¨æ³¨æ„åŠ›ï¼ˆMDLAï¼‰æ¨¡å—ï¼Œï¼ˆiiiï¼‰ç”¨äºè‡ªé€‚åº”ä¸“å®¶ç‰¹åŒ–çš„è°ƒåˆ¶æ··åˆä¸“å®¶ï¼ˆMoEï¼‰è§£ç å™¨ã€‚æˆ‘ä»¬å°†MIRæ‰©å±•åˆ°CTæ‰«æã€è§†ç½‘è†œæˆåƒã€MRIæ‰«æå’Œå¤§ä½“ç—…ç†å›¾åƒï¼Œåœ¨COVCTRã€MMRã€PGROSSå’ŒROCOæ•°æ®é›†ä¸ŠæŠ¥å‘Šäº†æœ€æ–°ç»“æœã€‚å¤§é‡å®éªŒå’Œæ¶ˆèç ”ç©¶è¯å®äº†å…¶åœ¨ä¸´åºŠå‡†ç¡®æ€§ã€è·¨æ¨¡æ€å¯¹é½å’Œæ¨¡å‹å¯è§£é‡Šæ€§æ–¹é¢çš„æ”¹è¿›ã€‚ä»£ç å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/AI-14/micar-vl-moe%E8%8E%B7%E5%8F%96%E3%80%82">https://github.com/AI-14/micar-vl-moeè·å–ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.20343v1">PDF</a> Accepted by IJCNN 2025, 8 pages, 8 figures, 3 tables</p>
<p><strong>æ‘˜è¦</strong><br>åŒ»å­¦å›¾åƒæŠ¥å‘Šï¼ˆMIRï¼‰æ—¨åœ¨ä»æ”¾å°„å­¦å›¾åƒç”Ÿæˆç»“æ„åŒ–ä¸´åºŠæè¿°ã€‚ç°æœ‰æ–¹æ³•éš¾ä»¥è¿›è¡Œç²¾ç»†ç‰¹å¾æå–ã€å¤šæ¨¡æ€å¯¹é½ï¼Œä»¥åŠåœ¨å¤šç§æˆåƒç±»å‹ä¸­çš„é€šç”¨åŒ–ã€‚æˆ‘ä»¬æå‡ºäº†MicarVLMoEï¼Œè¿™æ˜¯ä¸€ç§å¸¦æœ‰é—¨æ§äº¤å‰å¯¹é½èåˆçš„è§†å¬æ··åˆä¸“å®¶æ¨¡å‹ï¼Œæ—¨åœ¨è§£å†³è¿™äº›å±€é™æ€§ã€‚æˆ‘ä»¬çš„æ¶æ„åŒ…æ‹¬ï¼šå¤šå°ºåº¦è§†è§‰ç¼–ç å™¨ï¼ˆMSVEï¼‰ï¼Œç”¨äºåœ¨ä¸åŒåˆ†è¾¨ç‡æ•æ‰è§£å‰–ç»†èŠ‚ï¼›å¤šå¤´åŒåˆ†æ”¯æ½œåœ¨æ³¨æ„åŠ›ï¼ˆMDLAï¼‰æ¨¡å—ï¼Œé€šè¿‡æ½œåœ¨ç“¶é¢ˆè¡¨ç¤ºå®ç°è§†å¬å¯¹é½ï¼›ä»¥åŠè°ƒåˆ¶æ··åˆä¸“å®¶ï¼ˆMoEï¼‰è§£ç å™¨ï¼Œç”¨äºè‡ªé€‚åº”ä¸“å®¶ä¸“ä¸šåŒ–ã€‚æˆ‘ä»¬å°†MIRæ‰©å±•åˆ°CTæ‰«æã€è§†ç½‘è†œæˆåƒã€MRIæ‰«æå’Œå¤§ä½“ç—…ç†å›¾åƒï¼Œåœ¨COVCTRã€MMRã€PGROSSå’ŒROCOæ•°æ®é›†ä¸ŠæŠ¥å‘Šäº†æœ€æ–°çš„ç»“æœã€‚</p>
<p><strong>è¦ç‚¹</strong></p>
<ol>
<li>åŒ»å­¦å›¾åƒæŠ¥å‘Šï¼ˆMIRï¼‰æ˜¯ä»æ”¾å°„å­¦å›¾åƒç”Ÿæˆç»“æ„åŒ–ä¸´åºŠæè¿°çš„ä»»åŠ¡ã€‚</li>
<li>ç°æœ‰æ–¹æ³•åœ¨é¢å¯¹ç²¾ç»†ç‰¹å¾æå–ã€å¤šæ¨¡æ€å¯¹é½å’Œè·¨æˆåƒç±»å‹é€šç”¨åŒ–æ–¹é¢å­˜åœ¨æŒ‘æˆ˜ã€‚</li>
<li>æå‡ºäº†ä¸€ç§è§†å¬æ··åˆä¸“å®¶æ¨¡å‹MicarVLMoEï¼Œå…·æœ‰é—¨æ§äº¤å‰å¯¹é½èåˆæœºåˆ¶ã€‚</li>
<li>æ¶æ„åŒ…æ‹¬å¤šå°ºåº¦è§†è§‰ç¼–ç å™¨ã€å¤šå¤´åŒåˆ†æ”¯æ½œåœ¨æ³¨æ„åŠ›æ¨¡å—å’Œè°ƒåˆ¶æ··åˆä¸“å®¶è§£ç å™¨ã€‚</li>
<li>æˆåŠŸå°†MIRæ‰©å±•åˆ°å¤šç§åŒ»å­¦å›¾åƒç±»å‹ï¼ŒåŒ…æ‹¬CTæ‰«æã€è§†ç½‘è†œæˆåƒã€MRIæ‰«æå’Œå¤§ä½“ç—…ç†å›¾åƒã€‚</li>
<li>åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šå–å¾—äº†æœ€æ–°ç»“æœï¼Œè¯æ˜äº†ä¸´åºŠå‡†ç¡®æ€§ã€è·¨æ¨¡æ€å¯¹é½å’Œæ¨¡å‹è§£é‡Šæ€§çš„æå‡ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.20343">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-cb13a5c727e28bb9fabd9d07a8e0e247.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-06d03d5ec03d5b518d284f972931575e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-7b101b809ff80c543ecb38dbc7c5d3df.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-72bd99faa66efc268531c813685b2e82.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-1d94da1eb4b1d659ef3b60413e0e294b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-46a54e14a0663c79c0ff31feb9461499.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b533c4d195c9d81bbcd43bab4536dfd5.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-bbde63adca541ae685d6a85e2d7e4bcd.jpg" align="middle">
</details>


<h1 id="-9"><a href="#-9" class="headerlink" title=""></a></h1><h2 id="Towards-Accurate-and-Interpretable-Neuroblastoma-Diagnosis-via-Contrastive-Multi-scale-Pathological-Image-Analysis"><a href="#Towards-Accurate-and-Interpretable-Neuroblastoma-Diagnosis-via-Contrastive-Multi-scale-Pathological-Image-Analysis" class="headerlink" title="Towards Accurate and Interpretable Neuroblastoma Diagnosis via   Contrastive Multi-scale Pathological Image Analysis"></a>Towards Accurate and Interpretable Neuroblastoma Diagnosis via   Contrastive Multi-scale Pathological Image Analysis</h2><p><strong>Authors:Zhu Zhu, Shuo Jiang, Jingyuan Zheng, Yawen Li, Yifei Chen, Manli Zhao, Weizhong Gu, Feiwei Qin, Jinhu Wang, Gang Yu</strong></p>
<p>Neuroblastoma, adrenal-derived, is among the most common pediatric solid malignancies, characterized by significant clinical heterogeneity. Timely and accurate pathological diagnosis from hematoxylin and eosin-stained whole slide images is critical for patient prognosis. However, current diagnostic practices primarily rely on subjective manual examination by pathologists, leading to inconsistent accuracy. Existing automated whole slide image classification methods encounter challenges such as poor interpretability, limited feature extraction capabilities, and high computational costs, restricting their practical clinical deployment. To overcome these limitations, we propose CMSwinKAN, a contrastive-learning-based multi-scale feature fusion model tailored for pathological image classification, which enhances the Swin Transformer architecture by integrating a Kernel Activation Network within its multilayer perceptron and classification head modules, significantly improving both interpretability and accuracy. By fusing multi-scale features and leveraging contrastive learning strategies, CMSwinKAN mimics cliniciansâ€™ comprehensive approach, effectively capturing global and local tissue characteristics. Additionally, we introduce a heuristic soft voting mechanism guided by clinical insights to seamlessly bridge patch-level predictions to whole slide image-level classifications. We validate CMSwinKAN on the PpNTs dataset, which was collaboratively established with our partner hospital and the publicly accessible BreakHis dataset. Results demonstrate that CMSwinKAN performs better than existing state-of-the-art pathology-specific models pre-trained on large datasets. Our source code is available at <a target="_blank" rel="noopener" href="https://github.com/JSLiam94/CMSwinKAN">https://github.com/JSLiam94/CMSwinKAN</a>. </p>
<blockquote>
<p>ç¥ç»æ¯ç»†èƒç˜¤æ˜¯è‚¾ä¸Šè…ºèµ·æºçš„ä¸€ç§æœ€å¸¸è§çš„å„¿ç«¥å®ä½“æ¶æ€§è‚¿ç˜¤ï¼Œå…·æœ‰æ˜¾è‘—çš„ä¸´åºŠå¼‚è´¨æ€§ã€‚ä»è‹æœ¨ç²¾å’Œä¼Šçº¢æŸ“è‰²çš„å…¨åˆ‡ç‰‡å›¾åƒä¸­åŠæ—¶è¿›è¡Œå‡†ç¡®çš„ç—…ç†è¯Šæ–­å¯¹æ‚£è€…çš„é¢„åè‡³å…³é‡è¦ã€‚ç„¶è€Œï¼Œç›®å‰çš„è¯Šæ–­æ–¹æ³•ä¸»è¦ä¾èµ–äºç—…ç†åŒ»å¸ˆçš„ä¸»è§‚è‚‰çœ¼æ£€æŸ¥ï¼Œå¯¼è‡´è¯Šæ–­å‡†ç¡®æ€§ä¸ä¸€è‡´ã€‚ç°æœ‰çš„å…¨è‡ªåŠ¨åˆ‡ç‰‡å›¾åƒåˆ†ç±»æ–¹æ³•é¢ä¸´å¯è§£é‡Šæ€§å·®ã€ç‰¹å¾æå–èƒ½åŠ›æœ‰é™å’Œè®¡ç®—æˆæœ¬é«˜çš„æŒ‘æˆ˜ï¼Œé™åˆ¶äº†å…¶åœ¨ä¸´åºŠå®è·µä¸­çš„éƒ¨ç½²åº”ç”¨ã€‚ä¸ºäº†å…‹æœè¿™äº›å±€é™æ€§ï¼Œæˆ‘ä»¬æå‡ºäº†CMSwinKANï¼Œè¿™æ˜¯ä¸€ç§åŸºäºå¯¹æ¯”å­¦ä¹ çš„å¤šå°ºåº¦ç‰¹å¾èåˆæ¨¡å‹ï¼Œç”¨äºç—…ç†å›¾åƒåˆ†ç±»ã€‚æˆ‘ä»¬å¯¹Swin Transformeræ¶æ„è¿›è¡Œäº†æ”¹è¿›ï¼Œé€šè¿‡åœ¨å…¶å¤šå±‚æ„ŸçŸ¥å™¨å’Œåˆ†ç±»å¤´æ¨¡å—ä¸­é›†æˆKernel Activation Networkï¼Œå¢å¼ºäº†CMSwinKANçš„å¯è§£é‡Šæ€§å’Œå‡†ç¡®æ€§ã€‚é€šè¿‡èåˆå¤šå°ºåº¦ç‰¹å¾å’Œåˆ©ç”¨å¯¹æ¯”å­¦ä¹ ç­–ç•¥ï¼ŒCMSwinKANæ¨¡ä»¿äº†åŒ»ç”Ÿçš„å…¨é¢æ–¹æ³•ï¼Œæœ‰æ•ˆåœ°æ•æ‰äº†å…¨å±€å’Œå±€éƒ¨ç»„ç»‡ç‰¹å¾ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜å¼•å…¥äº†ä¸€ç§å—ä¸´åºŠè§è§£å¯å‘å¼çš„è½¯æŠ•ç¥¨æœºåˆ¶ï¼Œæ— ç¼åœ°å°†è¡¥ä¸çº§åˆ«çš„é¢„æµ‹ä¸å…¨åˆ‡ç‰‡å›¾åƒçº§åˆ«çš„åˆ†ç±»è”ç³»èµ·æ¥ã€‚æˆ‘ä»¬åœ¨ä¸åˆä½œä¼™ä¼´åŒ»é™¢å…±åŒå»ºç«‹çš„PpNTsæ•°æ®é›†å’Œå¯å…¬å¼€è®¿é—®çš„BreakHisæ•°æ®é›†ä¸ŠéªŒè¯äº†CMSwinKANã€‚ç»“æœè¡¨æ˜ï¼ŒCMSwinKANçš„æ€§èƒ½ä¼˜äºå…¶ä»–åœ¨å¤§å‹æ•°æ®é›†ä¸Šé¢„è®­ç»ƒçš„ç—…ç†å­¦ä¸“ç”¨æ¨¡å‹ã€‚æˆ‘ä»¬çš„æºä»£ç å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/JSLiam94/CMSwinKAN%E4%B8%8A%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/JSLiam94/CMSwinKANä¸Šæ‰¾åˆ°ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.13754v2">PDF</a> 10pages, 8 figures</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†ä¸€ç§åŸºäºå¯¹æ¯”å­¦ä¹ çš„å¤šå°ºåº¦ç‰¹å¾èåˆæ¨¡å‹CMSwinKANï¼Œç”¨äºç¥ç»æ¯ç»†èƒç˜¤ç­‰è‚¾ä¸Šè…ºè¡ç”Ÿè‚¿ç˜¤çš„ç—…ç†å›¾åƒåˆ†ç±»ã€‚è¯¥æ¨¡å‹æ”¹è¿›äº†Swin Transformeræ¶æ„ï¼Œé€šè¿‡é›†æˆKernel Activation Networkï¼Œæé«˜äº†æ¨¡å‹çš„è§£é‡Šæ€§å’Œå‡†ç¡®æ€§ã€‚CMSwinKANé‡‡ç”¨å¤šå°ºåº¦ç‰¹å¾èåˆå’Œå¯¹æ¯”å­¦ä¹ ç­–ç•¥ï¼Œæ¨¡æ‹ŸåŒ»ç”Ÿå…¨é¢çš„è¯Šæ–­æ–¹æ³•ï¼Œæœ‰æ•ˆæ•æ‰å…¨å±€å’Œå±€éƒ¨ç»„ç»‡ç‰¹å¾ã€‚æ­¤å¤–ï¼Œè¿˜å¼•å…¥äº†ä¸€ç§åŸºäºä¸´åºŠè§è§£çš„å¯å‘å¼è½¯æŠ•ç¥¨æœºåˆ¶ï¼Œå°†è¡¥ä¸çº§åˆ«çš„é¢„æµ‹æ— ç¼æ¡¥æ¥åˆ°æ•´ä¸ªå¹»ç¯ç‰‡å›¾åƒçº§åˆ«çš„åˆ†ç±»ã€‚åœ¨PpNTså’ŒBreakHisæ•°æ®é›†ä¸Šçš„éªŒè¯ç»“æœè¡¨æ˜ï¼ŒCMSwinKANçš„æ€§èƒ½ä¼˜äºç°æœ‰çš„æœ€å…ˆè¿›çš„ç—…ç†å­¦ä¸“ç”¨æ¨¡å‹ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ç¥ç»æ¯ç»†èƒç˜¤æ˜¯å¸¸è§çš„å„¿ç«¥å®ä½“æ¶æ€§è‚¿ç˜¤ï¼ŒåŠæ—¶å‡†ç¡®çš„ç—…ç†è¯Šæ–­å¯¹é¢„åè‡³å…³é‡è¦ã€‚</li>
<li>å½“å‰è¯Šæ–­å®è·µä¸»è¦ä¾èµ–ç—…ç†åŒ»å¸ˆçš„ä¸»è§‚æ‰‹åŠ¨æ£€æŸ¥ï¼Œå­˜åœ¨è¯Šæ–­å‡†ç¡®æ€§ä¸ä¸€è‡´çš„é—®é¢˜ã€‚</li>
<li>CMSwinKANæ¨¡å‹æ˜¯åŸºäºå¯¹æ¯”å­¦ä¹ çš„å¤šå°ºåº¦ç‰¹å¾èåˆæ¨¡å‹ï¼Œæ—¨åœ¨æé«˜ç—…ç†å›¾åƒåˆ†ç±»çš„å‡†ç¡®æ€§ã€‚</li>
<li>CMSwinKANé€šè¿‡é›†æˆKernel Activation Networkåˆ°Swin Transformeræ¶æ„ä¸­ï¼Œå¢å¼ºäº†æ¨¡å‹çš„è§£é‡Šæ€§å’Œå‡†ç¡®æ€§ã€‚</li>
<li>å¤šå°ºåº¦ç‰¹å¾èåˆå’Œå¯¹æ¯”å­¦ä¹ ç­–ç•¥ä½¿CMSwinKANèƒ½å¤Ÿæ•æ‰å…¨å±€å’Œå±€éƒ¨ç»„ç»‡ç‰¹å¾ï¼Œæ¨¡æ‹ŸåŒ»ç”Ÿçš„å…¨é¢è¯Šæ–­æ–¹æ³•ã€‚</li>
<li>å¼•å…¥å¯å‘å¼è½¯æŠ•ç¥¨æœºåˆ¶ï¼Œå°†è¡¥ä¸çº§åˆ«çš„é¢„æµ‹æ— ç¼æ¡¥æ¥åˆ°æ•´ä¸ªå¹»ç¯ç‰‡å›¾åƒçº§åˆ«çš„åˆ†ç±»ï¼Œæé«˜äº†æ¨¡å‹çš„è¯Šæ–­èƒ½åŠ›ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.13754">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-df7349d0c6ac14c0675939fe90bfbc5b.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-5728caeb68be85c517b9cd6f4143dbcc.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-6d214216c00cfc191bea492759d2ef60.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-90c9357fe4979a191912cd4ded1f41e6.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ce85806f90fbc30636ef0a49a71ba0f0.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-8bd4b02c25a30c3cc5a38c94f547b27c.jpg" align="middle">
</details>


<h1 id="-10"><a href="#-10" class="headerlink" title=""></a></h1><h2 id="Momentum-dependent-electron-phonon-coupling-in-cuprates-by-RIXS-the-roles-of-phonon-symmetry-and-electronic-structure"><a href="#Momentum-dependent-electron-phonon-coupling-in-cuprates-by-RIXS-the-roles-of-phonon-symmetry-and-electronic-structure" class="headerlink" title="Momentum-dependent electron-phonon coupling in cuprates by RIXS: the   roles of phonon symmetry and electronic structure"></a>Momentum-dependent electron-phonon coupling in cuprates by RIXS: the   roles of phonon symmetry and electronic structure</h2><p><strong>Authors:Maryia Zinouyeva, Rolf Heid, Giacomo Merzoni, Riccardo Arpaia, Nikolai Andreev, Marco Biagi, Nicholas B. Brookes, Daniele Di Castro, Alexei Kalaboukhov, Kurt Kummer, Floriana Lombardi, Leonardo Martinelli, Francesco Rosa, Flora Yakhou-Harris, Lucio Braicovich, Marco Moretti Sala, Paolo G. Radaelli, Giacomo Ghiringhelli</strong></p>
<p>The experimental determination of the magnitude and momentum dependence of electron-phonon coupling (EPC) is an outstanding problem in condensed matter physics. Resonant inelastic x-ray scattering (RIXS) has been previously employed to determine the EPC, since the intensity of phonon peaks in RIXS spectra has been directly related to the underlying EPC strength. In order to assess the limits of validity of such a relation, we compare experimental results and theoretical predictions for several high-T$<em>c$ superconducting cuprates. Namely, we investigate the intensity of the bond-stretching phonon mode in CaCuO$<em>2$, La$<em>2$CuO$</em>{4+\delta}$, La$</em>{1.84}$Sr$</em>{0.16}$CuO$_4$ and YBa$_2$Cu$<em>3$O$</em>{7-\delta}$ along the high symmetry ($\zeta$,0), ($\zeta$,$\zeta$) directions and as a function of the azimuthal angle $\phi$ at fixed modulus of the in-plane momentum $\mathbf{q_\parallel}$. Using two different theoretical approaches for the description of the RIXS scattering from phonons, we find that the $\mathbf{q_\parallel}$-dependence of the RIXS intensity can be largely ascribed to the symmetry of the phonon mode, and that satisfactory prediction of the experimental results cannot be obtained without including realistic details of the electronic structure in the calculations. Regardless of the theoretical model, RIXS provides a reliable momentum dependence of EPC in cuprates and can be used to test advanced theoretical predictions. </p>
<blockquote>
<p>å®éªŒç¡®å®šç”µå­-å£°å­è€¦åˆï¼ˆEPCï¼‰çš„å¤§å°å’ŒåŠ¨é‡ä¾èµ–æ€§æ˜¯å‡èšæ€ç‰©ç†ä¸­çš„ä¸€ä¸ªçªå‡ºé—®é¢˜ã€‚ä»¥å¾€æ›¾ç”¨å…±æŒ¯éå¼¹æ€§Xå°„çº¿æ•£å°„ï¼ˆRIXSï¼‰æ¥ç¡®å®šEPCï¼Œå› ä¸ºRIXSå…‰è°±ä¸­å£°å­å³°çš„å¼ºåº¦ä¸åŸºæœ¬çš„EPCå¼ºåº¦ç›´æ¥ç›¸å…³ã€‚ä¸ºäº†è¯„ä¼°è¿™ç§å…³ç³»çš„æœ‰æ•ˆæ€§èŒƒå›´ï¼Œæˆ‘ä»¬å¯¹æ¯”äº†å‡ ç§é«˜æ¸©è¶…å¯¼é“œæ°§åŒ–ç‰©çš„å®éªŒç»“æœå’Œç†è®ºé¢„æµ‹ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬ç ”ç©¶äº†CaCuO2ã€La2CuO4+Î´ã€La1.84Sr0.16CuO4å’ŒYBa2Cu3O7âˆ’Î´ä¸­é”®æ‹‰ä¼¸å£°å­æ¨¡å¼çš„å¼ºåº¦ï¼Œæ²¿ç€é«˜å¯¹ç§°ï¼ˆÎ¶ï¼Œ0ï¼‰ã€ï¼ˆÎ¶ï¼ŒÎ¶ï¼‰æ–¹å‘ï¼Œå¹¶ä½œä¸ºæ–¹ä½è§’Ï†çš„å‡½æ•°ï¼Œåœ¨å¹³é¢åŠ¨é‡å›ºå®šæ¨¡é‡qâˆ¥ä¸‹ã€‚ä½¿ç”¨ä¸¤ç§ä¸åŒçš„ç†è®ºæ–¹æ³•æ¥æè¿°å£°å­çš„RIXSæ•£å°„ï¼Œæˆ‘ä»¬å‘ç°RIXSå¼ºåº¦çš„qâˆ¥ä¾èµ–æ€§åœ¨å¾ˆå¤§ç¨‹åº¦ä¸Šå¯ä»¥å½’å› äºå£°å­æ¨¡å¼çš„å¯¹ç§°æ€§ï¼Œå¦‚æœä¸å°†ç”µå­ç»“æ„çš„ç°å®ç»†èŠ‚åŒ…æ‹¬åœ¨è®¡ç®—ä¸­ï¼Œå°±æ— æ³•å¯¹å®éªŒç»“æœè¿›è¡Œä»¤äººæ»¡æ„çš„é¢„æµ‹ã€‚æ— è®ºé‡‡ç”¨å“ªç§ç†è®ºæ¨¡å‹ï¼ŒRIXSéƒ½èƒ½å¯é åœ°æä¾›é“œæ°§åŒ–ç‰©ä¸­EPCçš„åŠ¨é‡ä¾èµ–æ€§ï¼Œå¯ç”¨äºæ£€éªŒé«˜çº§ç†è®ºé¢„æµ‹ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.12089v2">PDF</a> 17 pages, 9 figures</p>
<p><strong>æ‘˜è¦</strong><br>     è¯¥å®éªŒç ”ç©¶äº†ç”µå­-å£°å­è€¦åˆï¼ˆEPCï¼‰çš„å¤§å°åŠå…¶åŠ¨é‡ä¾èµ–æ€§ï¼Œè¿™æ˜¯å‡èšæ€ç‰©ç†ä¸­çš„ä¸€ä¸ªçªå‡ºé—®é¢˜ã€‚ä»¥å¾€åˆ©ç”¨å…±æŒ¯éå¼¹æ€§Xå°„çº¿æ•£å°„ï¼ˆRIXSï¼‰æ¥ç¡®å®šEPCï¼Œå› ä¸ºRIXSå…‰è°±ä¸­çš„å£°å­å³°å¼ºåº¦ä¸EPCå¼ºåº¦ç›´æ¥ç›¸å…³ã€‚ä¸ºäº†è¯„ä¼°è¿™ç§å…³ç³»çš„æœ‰æ•ˆæ€§é™åˆ¶ï¼Œæˆ‘ä»¬æ¯”è¾ƒäº†å‡ ç§é«˜æ¸©è¶…å¯¼é“œæ°§åŒ–ç‰©çš„å®éªŒç»“æœå’Œç†è®ºé¢„æµ‹ï¼Œå¦‚CaCuO2ã€La2CuO4+Î´ã€La1.84Sr0.16CuO4å’ŒYBa2Cu3O7âˆ’Î´ã€‚æˆ‘ä»¬ç ”ç©¶äº†æ²¿é«˜å¯¹ç§°ï¼ˆÎ¶ï¼Œ0ï¼‰ã€ï¼ˆÎ¶ï¼ŒÎ¶ï¼‰æ–¹å‘çš„é”®æ‹‰ä¼¸å£°å­æ¨¡å¼çš„å¼ºåº¦ï¼Œå¹¶ä½œä¸ºæ–¹ä½è§’Ï•çš„å‡½æ•°ï¼Œåœ¨å›ºå®šçš„å¹³é¢å†…åŠ¨é‡æ¨¡æ•°qâˆ¥ã€‚ä½¿ç”¨ä¸¤ç§ä¸åŒçš„ç†è®ºæ–¹æ³•æ¥æè¿°RIXSæ•£å°„å£°å­ï¼Œæˆ‘ä»¬å‘ç°RIXSå¼ºåº¦çš„qâˆ¥ä¾èµ–æ€§å¯ä»¥å¾ˆå¤§ç¨‹åº¦ä¸Šå½’å› äºå£°å­æ¨¡å¼çš„å¯¹ç§°æ€§ï¼Œå¹¶ä¸”åœ¨è®¡ç®—ä¸­å¦‚æœä¸åŒ…å«ç”µå­ç»“æ„çš„ç°å®ç»†èŠ‚ï¼Œåˆ™æ— æ³•å¯¹å®éªŒç»“æœè¿›è¡Œä»¤äººæ»¡æ„çš„é¢„æµ‹ã€‚æ— è®ºç†è®ºæ¨¡å‹å¦‚ä½•ï¼ŒRIXSéƒ½æä¾›äº†å¯é çš„EPCåŠ¨é‡ä¾èµ–æ€§ï¼Œå¹¶å¯ç”¨æ¥æ£€éªŒé«˜çº§ç†è®ºé¢„æµ‹ã€‚</p>
<p><strong>å…³é”®è§è§£</strong></p>
<ol>
<li>ç”µå­-å£°å­è€¦åˆï¼ˆEPCï¼‰çš„åŠ¨é‡å’Œå¼ºåº¦åœ¨å‡èšæ€ç‰©ç†ä¸­ä»æ˜¯å¾…è§£å†³çš„é—®é¢˜ã€‚</li>
<li>å…±æŒ¯éå¼¹æ€§Xå°„çº¿æ•£å°„ï¼ˆRIXSï¼‰å·²è¢«ç”¨äºç¡®å®šEPCã€‚</li>
<li>RIXSå…‰è°±ä¸­çš„å£°å­å³°å¼ºåº¦ä¸EPCå¼ºåº¦æœ‰ç›´æ¥å…³è”ã€‚</li>
<li>å¯¹å‡ ç§é«˜æ¸©è¶…å¯¼é“œæ°§åŒ–ç‰©çš„å®éªŒå’Œç†è®ºç»“æœè¿›è¡Œäº†æ¯”è¾ƒã€‚</li>
<li>RIXSå¼ºåº¦çš„åŠ¨é‡ä¾èµ–æ€§ä¸»è¦å½’å› äºå£°å­æ¨¡å¼çš„å¯¹ç§°æ€§ã€‚</li>
<li>ç°å®ç”µå­ç»“æ„çš„ç»†èŠ‚åœ¨è®¡ç®—EPCæ—¶è‡³å…³é‡è¦ï¼Œå¦åˆ™æ— æ³•å‡†ç¡®é¢„æµ‹å®éªŒç»“æœã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.12089">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-56a7b4ef02e22e9841b054172b1670c1.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-b4da326b0754681750c1e72f88c00720.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-ad96f13aacf851cd6478d4f8b0329a28.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-e20eccb21bfa2426503904df9377c33c.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-5b0d3708e38a5df00a97639692cad346.jpg" align="middle">
</details>


<h1 id="-11"><a href="#-11" class="headerlink" title=""></a></h1><h2 id="Exploring-AI-based-System-Design-for-Pixel-level-Protected-Health-Information-Detection-in-Medical-Images"><a href="#Exploring-AI-based-System-Design-for-Pixel-level-Protected-Health-Information-Detection-in-Medical-Images" class="headerlink" title="Exploring AI-based System Design for Pixel-level Protected Health   Information Detection in Medical Images"></a>Exploring AI-based System Design for Pixel-level Protected Health   Information Detection in Medical Images</h2><p><strong>Authors:Tuan Truong, Ivo M. Baltruschat, Mark Klemens, Grit Werner, Matthias Lenga</strong></p>
<p>De-identification of medical images is a critical step to ensure privacy during data sharing in research and clinical settings. The initial step in this process involves detecting Protected Health Information (PHI), which can be found in image metadata or imprinted within image pixels. Despite the importance of such systems, there has been limited evaluation of existing AI-based solutions, creating barriers to the development of reliable and robust tools. In this study, we present an AI-based pipeline for PHI detection, comprising three key components: text detection, text extraction, and text analysis. We benchmark three models, YOLOv11, EasyOCR, and GPT-4o, across different setups corresponding to these components, evaluating the performance based on precision, recall, F1 score, and accuracy. All setups demonstrate excellent PHI detection, with all metrics exceeding 0.9. The combination of YOLOv11 for text localization and GPT-4o for extraction and analysis yields the best results. However, this setup incurs higher costs due to GPT-4oâ€™s token generation. Conversely, an end-to-end pipeline that relies solely on GPT-4o shows lower performance but highlights the potential of multimodal models for complex tasks. We recommend fine-tuning a dedicated object detection model and utilizing built-in OCR tools to achieve optimal performance and cost-effectiveness. Additionally, leveraging language models such as GPT-4o can facilitate thorough and flexible analysis of text content. </p>
<blockquote>
<p>åŒ»å­¦å›¾åƒçš„åŒ¿ååŒ–æ˜¯åœ¨ç ”ç©¶å’Œä¸´åºŠç¯å¢ƒä¸­è¿›è¡Œæ•°æ®å…±äº«æ—¶ç¡®ä¿éšç§çš„å…³é”®æ­¥éª¤ã€‚è¯¥è¿‡ç¨‹çš„åˆå§‹æ­¥éª¤æ˜¯æ£€æµ‹å›¾åƒä¸­çš„å—ä¿æŠ¤å¥åº·ä¿¡æ¯ï¼ˆPHIï¼‰ï¼Œè¿™äº›ä¿¡æ¯å¯èƒ½å­˜åœ¨äºå›¾åƒå…ƒæ•°æ®æˆ–åƒç´ ä¸­ã€‚å°½ç®¡æ­¤ç±»ç³»ç»Ÿå¾ˆé‡è¦ï¼Œä½†å¯¹ç°æœ‰çš„åŸºäºäººå·¥æ™ºèƒ½çš„è§£å†³æ–¹æ¡ˆçš„è¯„ä¼°ä»ç„¶æœ‰é™ï¼Œè¿™æˆä¸ºå¼€å‘å¯é å’Œç¨³å¥çš„å·¥å…·çš„éšœç¢ã€‚åœ¨ç ”ç©¶ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åŸºäºäººå·¥æ™ºèƒ½çš„PHIæ£€æµ‹ç®¡é“ï¼ŒåŒ…æ‹¬ä¸‰ä¸ªå…³é”®ç»„ä»¶ï¼šæ–‡æœ¬æ£€æµ‹ã€æ–‡æœ¬æå–å’Œæ–‡æœ¬åˆ†æã€‚æˆ‘ä»¬é’ˆå¯¹è¿™ä¸‰ä¸ªç»„ä»¶åˆ†åˆ«è¯„ä¼°äº†YOLOv11ã€EasyOCRå’ŒGPT-4oä¸‰ä¸ªæ¨¡å‹ï¼Œå¹¶æ ¹æ®ç²¾ç¡®åº¦ã€å¬å›ç‡ã€F1åˆ†æ•°å’Œå‡†ç¡®åº¦è¯„ä¼°æ€§èƒ½ã€‚æ‰€æœ‰è®¾ç½®éƒ½è¡¨ç°å‡ºå‡ºè‰²çš„PHIæ£€æµ‹èƒ½åŠ›ï¼Œæ‰€æœ‰æŒ‡æ ‡å‡è¶…è¿‡0.9ã€‚YOLOv11ç”¨äºæ–‡æœ¬å®šä½å’ŒGPT-4oç”¨äºæå–å’Œåˆ†æçš„ç»„åˆå–å¾—äº†æœ€ä½³ç»“æœï¼Œä½†è¿™ä¸€ç»„åˆç”±äºGPT-4oçš„ä»¤ç‰Œç”Ÿæˆè€Œæˆæœ¬è¾ƒé«˜ã€‚ç›¸åï¼Œå®Œå…¨ä¾èµ–äºGPT-4oçš„ç«¯åˆ°ç«¯ç®¡é“æ€§èƒ½è¾ƒä½ï¼Œä½†çªæ˜¾äº†å¤šæ¨¡å¼æ¨¡å‹åœ¨å¤„ç†å¤æ‚ä»»åŠ¡æ—¶çš„æ½œåŠ›ã€‚æˆ‘ä»¬å»ºè®®å¯¹ä¸“ç”¨ç›®æ ‡æ£€æµ‹æ¨¡å‹è¿›è¡Œå¾®è°ƒï¼Œå¹¶åˆ©ç”¨å†…ç½®OCRå·¥å…·æ¥å®ç°æœ€ä½³æ€§èƒ½å’Œæˆæœ¬æ•ˆç›Šã€‚æ­¤å¤–ï¼Œåˆ©ç”¨å¦‚GPT-4oç­‰è¯­è¨€æ¨¡å‹å¯ä»¥ä¿ƒè¿›æ–‡æœ¬å†…å®¹çš„å…¨é¢å’Œçµæ´»åˆ†æã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.09552v3">PDF</a> In progress</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†ä¸€ç§åŸºäºäººå·¥æ™ºèƒ½çš„åŒ»å­¦å›¾åƒéšç§ä¿¡æ¯æ£€æµ‹ç³»ç»Ÿï¼ŒåŒ…æ‹¬æ–‡æœ¬æ£€æµ‹ã€æå–å’Œåˆ†æä¸‰ä¸ªå…³é”®æ­¥éª¤ã€‚é€šè¿‡å¯¹YOLOv11ã€EasyOCRå’ŒGPT-4oä¸‰ç§æ¨¡å‹çš„è¯„ä¼°ï¼Œå‘ç°å®ƒä»¬åœ¨PHIæ£€æµ‹æ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œå…¶ä¸­YOLOv11ä¸GPT-4oç»“åˆçš„æ•ˆæœæœ€ä½³ã€‚ç ”ç©¶è¿˜æ¢è®¨äº†æˆæœ¬ä¸æ€§èƒ½ä¹‹é—´çš„å¹³è¡¡ï¼Œå¹¶æ¨èäº†ä¼˜åŒ–æ€§èƒ½å’Œæˆæœ¬æ•ˆç›Šçš„æ–¹æ¡ˆã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>åŒ»å­¦å›¾åƒå»æ ‡è¯†åŒ–æ˜¯ç¡®ä¿æ•°æ®å…±äº«è¿‡ç¨‹ä¸­éšç§çš„å…³é”®æ­¥éª¤ã€‚</li>
<li>ä¿æŠ¤å¥åº·ä¿¡æ¯ï¼ˆPHIï¼‰å¯å­˜åœ¨äºå›¾åƒå…ƒæ•°æ®æˆ–åƒç´ ä¸­ã€‚</li>
<li>æå‡ºäº†ä¸€ä¸ªåŸºäºAIçš„PHIæ£€æµ‹æµç¨‹ï¼ŒåŒ…æ‹¬æ–‡æœ¬æ£€æµ‹ã€æå–å’Œåˆ†æã€‚</li>
<li>è¯„ä¼°äº†YOLOv11ã€EasyOCRå’ŒGPT-4oä¸‰ä¸ªæ¨¡å‹ï¼Œåœ¨PHIæ£€æµ‹æ–¹é¢è¡¨ç°å‡ºè‰²ã€‚</li>
<li>YOLOv11ä¸GPT-4oç»“åˆä½¿ç”¨æ•ˆæœæœ€ä½³ï¼Œä½†æˆæœ¬è¾ƒé«˜ã€‚</li>
<li>æ¢è®¨äº†æˆæœ¬ä¸æ€§èƒ½ä¹‹é—´çš„å¹³è¡¡ï¼Œæ¨èäº†ä¼˜åŒ–æ–¹æ¡ˆã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.09552">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-b6f2188f9dfd49188a218dd1e55e7a76.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-4df178e2398643b03b9c302981a242d9.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-0042609f3eb451058cd6c3252311b121.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-e53d8da247120b4e639d0b47bc5b645e.jpg" align="middle">
</details>


<h1 id="-12"><a href="#-12" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-05-01/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/">https://kedreamix.github.io/Talk2Paper/Paper/2025-05-01/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/">
                                    <span class="chip bg-color">åŒ»å­¦å›¾åƒ</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-05-01/TTS/">
                    <div class="card-image">
                        
                        <img src="https://pic1.zhimg.com/v2-c4ba61bcf69291623ace4d51f62e447a.jpg" class="responsive-img" alt="TTS">
                        
                        <span class="card-title">TTS</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            TTS æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-05-01  AlignDiT Multimodal Aligned Diffusion Transformer for Synchronized   Speech Generation
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-05-01
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/TTS/" class="post-category">
                                    TTS
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/TTS/">
                        <span class="chip bg-color">TTS</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-05-01/Diffusion%20Models/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-21950de2b5b2e07066fd3abf8159ca34.jpg" class="responsive-img" alt="Diffusion Models">
                        
                        <span class="card-title">Diffusion Models</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Diffusion Models æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-05-01  AI-GenBench A New Ongoing Benchmark for AI-Generated Image Detection
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-05-01
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Diffusion-Models/" class="post-category">
                                    Diffusion Models
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Diffusion-Models/">
                        <span class="chip bg-color">Diffusion Models</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">26384.1k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
