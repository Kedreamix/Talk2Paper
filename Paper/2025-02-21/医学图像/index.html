<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="åŒ»å­¦å›¾åƒ">
    <meta name="description" content="åŒ»å­¦å›¾åƒ æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-02-21  MGFI-Net A Multi-Grained Feature Integration Network for Enhanced   Medical Image Segmentation">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>åŒ»å­¦å›¾åƒ | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://picx.zhimg.com/v2-dc7f5a85a37c6456a0323059b9394121.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">åŒ»å­¦å›¾åƒ</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/">
                                <span class="chip bg-color">åŒ»å­¦å›¾åƒ</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/" class="post-category">
                                åŒ»å­¦å›¾åƒ
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-02-21
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-02-21
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    11.1k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    46 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-02-21-æ›´æ–°"><a href="#2025-02-21-æ›´æ–°" class="headerlink" title="2025-02-21 æ›´æ–°"></a>2025-02-21 æ›´æ–°</h1><h2 id="MGFI-Net-A-Multi-Grained-Feature-Integration-Network-for-Enhanced-Medical-Image-Segmentation"><a href="#MGFI-Net-A-Multi-Grained-Feature-Integration-Network-for-Enhanced-Medical-Image-Segmentation" class="headerlink" title="MGFI-Net: A Multi-Grained Feature Integration Network for Enhanced   Medical Image Segmentation"></a>MGFI-Net: A Multi-Grained Feature Integration Network for Enhanced   Medical Image Segmentation</h2><p><strong>Authors:Yucheng Zeng</strong></p>
<p>Medical image segmentation plays a crucial role in various clinical applications. A major challenge in medical image segmentation is achieving accurate delineation of regions of interest in the presence of noise, low contrast, or complex anatomical structures. Existing segmentation models often neglect the integration of multi-grained information and fail to preserve edge details, which are critical for precise segmentation. To address these challenges, we propose a novel image semantic segmentation model called the Multi-Grained Feature Integration Network (MGFI-Net). Our MGFI-Net is designed with two dedicated modules to tackle these issues. First, to enhance segmentation accuracy, we introduce a Multi-Grained Feature Extraction Module, which leverages hierarchical relationships between different feature scales to selectively focus on the most relevant information. Second, to preserve edge details, we incorporate an Edge Enhancement Module that effectively retains and integrates boundary information to refine segmentation results. Extensive experiments demonstrate that MGFI-Net not only outperforms state-of-the-art methods in terms of segmentation accuracy but also achieves superior time efficiency, establishing it as a leading solution for real-time medical image segmentation. </p>
<blockquote>
<p>åŒ»å­¦å›¾åƒåˆ†å‰²åœ¨å„ç§ä¸´åºŠåº”ç”¨ä¸­éƒ½æ‰®æ¼”ç€è‡³å…³é‡è¦çš„è§’è‰²ã€‚åŒ»å­¦å›¾åƒåˆ†å‰²é¢ä¸´çš„ä¸€ä¸ªä¸»è¦æŒ‘æˆ˜æ˜¯åœ¨å™ªå£°ã€ä½å¯¹æ¯”åº¦æˆ–å¤æ‚è§£å‰–ç»“æ„å­˜åœ¨çš„æƒ…å†µä¸‹ï¼Œå®ç°å¯¹æ„Ÿå…´è¶£åŒºåŸŸçš„å‡†ç¡®è½®å»“æç»˜ã€‚ç°æœ‰çš„åˆ†å‰²æ¨¡å‹å¾€å¾€å¿½è§†äº†å¤šç²’åº¦ä¿¡æ¯çš„èåˆï¼Œä¸”æ— æ³•ä¿ç•™å¯¹ç²¾ç¡®åˆ†å‰²è‡³å…³é‡è¦çš„è¾¹ç¼˜ç»†èŠ‚ã€‚ä¸ºäº†è§£å†³è¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°å‹çš„å›¾åƒè¯­ä¹‰åˆ†å‰²æ¨¡å‹ï¼Œç§°ä¸ºå¤šç²’åº¦ç‰¹å¾èåˆç½‘ç»œï¼ˆMGFI-Netï¼‰ã€‚æˆ‘ä»¬çš„MGFI-Netè®¾è®¡äº†ä¸¤ä¸ªä¸“ç”¨æ¨¡å—æ¥è§£å†³è¿™äº›é—®é¢˜ã€‚é¦–å…ˆï¼Œä¸ºäº†æé«˜åˆ†å‰²ç²¾åº¦ï¼Œæˆ‘ä»¬å¼•å…¥äº†å¤šç²’åº¦ç‰¹å¾æå–æ¨¡å—ï¼Œè¯¥æ¨¡å—åˆ©ç”¨ä¸åŒç‰¹å¾å°ºåº¦ä¹‹é—´çš„å±‚æ¬¡å…³ç³»ï¼Œæœ‰é€‰æ‹©åœ°å…³æ³¨æœ€ç›¸å…³çš„ä¿¡æ¯ã€‚å…¶æ¬¡ï¼Œä¸ºäº†ä¿ç•™è¾¹ç¼˜ç»†èŠ‚ï¼Œæˆ‘ä»¬èå…¥äº†ä¸€ä¸ªè¾¹ç¼˜å¢å¼ºæ¨¡å—ï¼Œè¯¥æ¨¡å—èƒ½å¤Ÿæœ‰æ•ˆåœ°ä¿ç•™å’Œèåˆè¾¹ç•Œä¿¡æ¯ï¼Œä»¥ä¼˜åŒ–åˆ†å‰²ç»“æœã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼ŒMGFI-Netä¸ä»…åœ¨åˆ†å‰²ç²¾åº¦ä¸Šè¶…è¶Šäº†æœ€å…ˆè¿›çš„æ–¹æ³•ï¼Œè€Œä¸”åœ¨æ—¶é—´æ•ˆç‡ä¸Šä¹Ÿè¡¨ç°å‡ºå“è¶Šçš„æ€§èƒ½ï¼Œä½¿å…¶æˆä¸ºå®æ—¶åŒ»å­¦å›¾åƒåˆ†å‰²çš„é¢†å…ˆè§£å†³æ–¹æ¡ˆã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.13808v1">PDF</a> </p>
<p><strong>æ‘˜è¦</strong></p>
<p>åŒ»ç–—å›¾åƒåˆ†å‰²åœ¨ä¸´åºŠåº”ç”¨ä¸­æ‰®æ¼”ç€é‡è¦è§’è‰²ã€‚ç°æœ‰åˆ†å‰²æ¨¡å‹åœ¨é¢ä¸´å™ªå£°ã€ä½å¯¹æ¯”åº¦æˆ–å¤æ‚è§£å‰–ç»“æ„ç­‰é—®é¢˜æ—¶ï¼Œéš¾ä»¥å®ç°å…´è¶£åŒºåŸŸçš„å‡†ç¡®åˆ†å‰²ã€‚ä¸ºè§£å†³æ­¤æŒ‘æˆ˜ï¼Œæå‡ºäº†ä¸€ç§åä¸ºMulti-Grained Feature Integration Networkï¼ˆMGFI-Netï¼‰çš„æ–°å‹å›¾åƒè¯­ä¹‰åˆ†å‰²æ¨¡å‹ã€‚MGFI-Neté€šè¿‡ä¸¤ä¸ªä¸“ç”¨æ¨¡å—æ¥è§£å†³è¿™äº›é—®é¢˜ï¼šä¸€æ˜¯å¼•å…¥Multi-Grainedç‰¹å¾æå–æ¨¡å—ï¼Œåˆ©ç”¨ä¸åŒç‰¹å¾å°ºåº¦é—´çš„å±‚æ¬¡å…³ç³»ï¼Œé€‰æ‹©æ€§å…³æ³¨æœ€ç›¸å…³ä¿¡æ¯ï¼Œæé«˜åˆ†å‰²ç²¾åº¦ï¼›äºŒæ˜¯èå…¥è¾¹ç¼˜å¢å¼ºæ¨¡å—ï¼Œæœ‰æ•ˆä¿ç•™å’Œæ•´åˆè¾¹ç•Œä¿¡æ¯ï¼Œä¼˜åŒ–åˆ†å‰²ç»“æœã€‚å®éªŒè¯æ˜ï¼ŒMGFI-Netä¸ä»…åœ¨åˆ†å‰²ç²¾åº¦ä¸Šè¶…è¶Šäº†ç°æœ‰å…ˆè¿›æ–¹æ³•ï¼Œè€Œä¸”åœ¨æ—¶é—´æ•ˆç‡ä¸Šä¹Ÿè¡¨ç°å‡ºä¼˜åŠ¿ï¼Œæˆä¸ºå®æ—¶åŒ»ç–—å›¾åƒåˆ†å‰²çš„é¢†å…ˆè§£å†³æ–¹æ¡ˆã€‚</p>
<p><strong>å…³é”®è§è§£</strong></p>
<ol>
<li>åŒ»ç–—å›¾åƒåˆ†å‰²åœ¨ä¸´åºŠåº”ç”¨ä¸­çš„é‡è¦æ€§åŠå…¶æ‰€é¢ä¸´çš„æŒ‘æˆ˜ã€‚</li>
<li>ç°æœ‰åˆ†å‰²æ¨¡å‹åœ¨é¢ä¸´å™ªå£°ã€ä½å¯¹æ¯”åº¦æˆ–å¤æ‚è§£å‰–ç»“æ„æ—¶çš„å±€é™æ€§ã€‚</li>
<li>æå‡ºçš„Multi-Grained Feature Integration Networkï¼ˆMGFI-Netï¼‰æ¨¡å‹é€šè¿‡ä¸¤ä¸ªä¸“ç”¨æ¨¡å—è§£å†³è¿™äº›æŒ‘æˆ˜ã€‚</li>
<li>Multi-Grainedç‰¹å¾æå–æ¨¡å—åˆ©ç”¨ä¸åŒç‰¹å¾å°ºåº¦é—´çš„å±‚æ¬¡å…³ç³»æé«˜åˆ†å‰²ç²¾åº¦ã€‚</li>
<li>è¾¹ç¼˜å¢å¼ºæ¨¡å—ä¿ç•™å’Œæ•´åˆè¾¹ç•Œä¿¡æ¯ï¼Œä¼˜åŒ–åˆ†å‰²ç»“æœã€‚</li>
<li>MGFI-Netåœ¨åˆ†å‰²ç²¾åº¦å’Œæ—¶é—´æ•ˆç‡ä¸Šçš„ä¼˜è¶Šæ€§èƒ½ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.13808">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-b98be27e100a07bb875cc004ac47bf94.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-067f896faa5e3949c85ca826ab948488.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-27f3b4a19c9c4948b9a6a31883763223.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-401bf3ab75319e67e63def3a694211ac.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-92cb151be844913daca9208bb3e849f5.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-55c978ab5872dcd76c02a726aa97ef86.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="Medical-Image-Classification-with-KAN-Integrated-Transformers-and-Dilated-Neighborhood-Attention"><a href="#Medical-Image-Classification-with-KAN-Integrated-Transformers-and-Dilated-Neighborhood-Attention" class="headerlink" title="Medical Image Classification with KAN-Integrated Transformers and   Dilated Neighborhood Attention"></a>Medical Image Classification with KAN-Integrated Transformers and   Dilated Neighborhood Attention</h2><p><strong>Authors:Omid Nejati Manzari, Hojat Asgariandehkordi, Taha Koleilat, Yiming Xiao, Hassan Rivaz</strong></p>
<p>Convolutional networks, transformers, hybrid models, and Mamba-based architectures have demonstrated strong performance across various medical image classification tasks. However, these methods were primarily designed to classify clean images using labeled data. In contrast, real-world clinical data often involve image corruptions that are unique to multi-center studies and stem from variations in imaging equipment across manufacturers. In this paper, we introduce the Medical Vision Transformer (MedViTV2), a novel architecture incorporating Kolmogorov-Arnold Network (KAN) layers into the transformer architecture for the first time, aiming for generalized medical image classification. We have developed an efficient KAN block to reduce computational load while enhancing the accuracy of the original MedViT. Additionally, to counteract the fragility of our MedViT when scaled up, we propose an enhanced Dilated Neighborhood Attention (DiNA), an adaptation of the efficient fused dot-product attention kernel capable of capturing global context and expanding receptive fields to scale the model effectively and addressing feature collapse issues. Moreover, a hierarchical hybrid strategy is introduced to stack our Local Feature Perception and Global Feature Perception blocks in an efficient manner, which balances local and global feature perceptions to boost performance. Extensive experiments on 17 medical image classification datasets and 12 corrupted medical image datasets demonstrate that MedViTV2 achieved state-of-the-art results in 27 out of 29 experiments with reduced computational complexity. MedViTV2 is 44% more computationally efficient than the previous version and significantly enhances accuracy, achieving improvements of 4.6% on MedMNIST, 5.8% on NonMNIST, and 13.4% on the MedMNIST-C benchmark. </p>
<blockquote>
<p>å·ç§¯ç½‘ç»œã€å˜å‹å™¨ã€æ··åˆæ¨¡å‹å’ŒåŸºäºMambaçš„æ¶æ„å·²åœ¨å„ç§åŒ»å­¦å›¾åƒåˆ†ç±»ä»»åŠ¡ä¸­è¡¨ç°å‡ºå¼ºå¤§çš„æ€§èƒ½ã€‚ç„¶è€Œï¼Œè¿™äº›æ–¹æ³•ä¸»è¦æ˜¯ä¸ºä½¿ç”¨å¸¦æ ‡ç­¾æ•°æ®å¯¹å¹²å‡€å›¾åƒè¿›è¡Œåˆ†ç±»è€Œè®¾è®¡çš„ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼Œç°å®ä¸–ç•Œçš„ä¸´åºŠæ•°æ®é€šå¸¸æ¶‰åŠå¤šä¸­å¿ƒç ”ç©¶ç‹¬æœ‰çš„å›¾åƒæŸåé—®é¢˜ï¼Œä»¥åŠæ¥è‡ªä¸åŒåˆ¶é€ å•†çš„æˆåƒè®¾å¤‡æ‰€äº§ç”Ÿçš„å·®å¼‚ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬ä»‹ç»äº†åŒ»ç–—è§†è§‰è½¬æ¢å™¨ï¼ˆMedViTV2ï¼‰ï¼Œè¿™æ˜¯ä¸€ç§æ–°å‹æ¶æ„ï¼Œé¦–æ¬¡å°†Kolmogorov-Arnoldç½‘ç»œï¼ˆKANï¼‰å±‚èå…¥å˜å‹å™¨æ¶æ„ä¸­ï¼Œæ—¨åœ¨å®ç°é€šç”¨åŒ»å­¦å›¾åƒåˆ†ç±»ã€‚æˆ‘ä»¬å¼€å‘äº†ä¸€ä¸ªé«˜æ•ˆçš„KANå—ï¼Œä»¥å‡å°‘è®¡ç®—è´Ÿè½½å¹¶æé«˜åŸå§‹MedViTçš„å‡†ç¡®æ€§ã€‚æ­¤å¤–ï¼Œä¸ºäº†æŠµæ¶ˆæˆ‘ä»¬MedViTåœ¨æ‰©å¤§è§„æ¨¡æ—¶çš„è„†å¼±æ€§ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§å¢å¼ºçš„è†¨èƒ€é‚»åŸŸæ³¨æ„åŠ›ï¼ˆDiNAï¼‰ï¼Œè¿™æ˜¯å¯¹é«˜æ•ˆèåˆç‚¹ç§¯æ³¨æ„åŠ›æ ¸çš„é€‚åº”ï¼Œèƒ½å¤Ÿæ•è·å…¨å±€ä¸Šä¸‹æ–‡å¹¶æ‰©å±•æ¥æ”¶åœºï¼Œä»¥æœ‰æ•ˆåœ°æ‰©å±•æ¨¡å‹å¹¶è§£å†³ç‰¹å¾å´©æºƒé—®é¢˜ã€‚æ­¤å¤–ï¼Œè¿˜å¼•å…¥äº†ä¸€ç§åˆ†å±‚æ··åˆç­–ç•¥ï¼Œä»¥æœ‰æ•ˆçš„æ–¹å¼å †å æˆ‘ä»¬çš„å±€éƒ¨ç‰¹å¾æ„ŸçŸ¥å’Œå…¨å±€ç‰¹å¾æ„ŸçŸ¥å—ï¼Œè¿™å¯ä»¥å¹³è¡¡å±€éƒ¨å’Œå…¨å±€ç‰¹å¾æ„ŸçŸ¥ä»¥æé«˜æ€§èƒ½ã€‚åœ¨17ä¸ªåŒ»å­¦å›¾åƒåˆ†ç±»æ•°æ®é›†å’Œ12ä¸ªæŸååŒ»å­¦å›¾åƒæ•°æ®é›†ä¸Šçš„å¤§é‡å®éªŒè¡¨æ˜ï¼ŒMedViTV2åœ¨29æ¬¡å®éªŒä¸­çš„27æ¬¡è·å¾—äº†æœ€å…ˆè¿›çš„æˆæœï¼Œä¸”è®¡ç®—å¤æ‚åº¦æœ‰æ‰€é™ä½ã€‚MedViTV2çš„è®¡ç®—æ•ˆç‡æ¯”å‰ä¸€ä¸ªç‰ˆæœ¬æé«˜äº†44%ï¼Œå¹¶ä¸”åœ¨MedMNISTä¸Šæé«˜äº†4.6%çš„å‡†ç¡®ç‡ï¼Œåœ¨NonMNISTä¸Šæé«˜äº†5.8%ï¼Œåœ¨MedMNIST-CåŸºå‡†æµ‹è¯•ä¸Šæé«˜äº†13.4%ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.13693v1">PDF</a> </p>
<p><strong>æ‘˜è¦</strong><br>    æœ¬æ–‡ä»‹ç»äº†Medical Vision Transformer V2ï¼ˆMedViTV2ï¼‰æ¶æ„ï¼Œè¯¥æ¶æ„é¦–æ¬¡å°†Kolmogorov-Arnoldç½‘ç»œï¼ˆKANï¼‰å±‚èå…¥transformeræ¶æ„ä¸­ï¼Œæ—¨åœ¨å®ç°é€šç”¨çš„åŒ»å­¦å›¾åƒåˆ†ç±»ã€‚é€šè¿‡å¼€å‘é«˜æ•ˆçš„KANå—ï¼Œå‡å°‘äº†è®¡ç®—è´Ÿè½½ï¼Œæé«˜äº†åŸå§‹MedViTçš„å‡†ç¡®æ€§ã€‚ä¸ºåº”å¯¹å¤§å‹MedViTçš„è„†å¼±æ€§ï¼Œæå‡ºäº†å¢å¼ºçš„è†¨èƒ€é‚»åŸŸæ³¨æ„åŠ›ï¼ˆDiNAï¼‰ï¼Œèƒ½æ•æ‰å…¨å±€ä¸Šä¸‹æ–‡å¹¶æ‰©å±•æ„Ÿå—é‡ï¼Œæœ‰æ•ˆæ‰©å±•æ¨¡å‹å¹¶è§£å†³ç‰¹å¾å´©æºƒé—®é¢˜ã€‚æ­¤å¤–ï¼Œè¿˜ä»‹ç»äº†åˆ†å±‚æ··åˆç­–ç•¥ï¼Œä»¥å¹³è¡¡å±€éƒ¨å’Œå…¨å±€ç‰¹å¾æ„ŸçŸ¥å—ï¼Œæé«˜æ€§èƒ½ã€‚åœ¨17ä¸ªåŒ»å­¦å›¾åƒåˆ†ç±»æ•°æ®é›†å’Œ12ä¸ªè…èš€åŒ»å­¦å›¾åƒæ•°æ®é›†ä¸Šçš„å¤§é‡å®éªŒè¡¨æ˜ï¼ŒMedViTV2åœ¨27æ¬¡å®éªŒä¸­è·å¾—æœ€ä½³ç»“æœï¼Œè®¡ç®—å¤æ‚åº¦é™ä½ã€‚ä¸å‰ä¸€ç‰ˆæœ¬ç›¸æ¯”ï¼ŒMedViTV2è®¡ç®—æ•ˆç‡æé«˜44%ï¼Œåœ¨MedMNISTã€NonMNISTå’ŒMedMNIST-CåŸºå‡†æµ‹è¯•ä¸Šçš„å‡†ç¡®ç‡åˆ†åˆ«æé«˜4.6%ã€5.8%å’Œ13.4%ã€‚</p>
<p><strong>å…³é”®è§è§£</strong></p>
<ol>
<li>MedViTV2ç»“åˆäº†Kolmogorov-Arnoldç½‘ç»œï¼ˆKANï¼‰å±‚ä¸transformeræ¶æ„ï¼Œä¸ºåŒ»å­¦å›¾åƒåˆ†ç±»æä¾›äº†æ–°é¢–çš„è§£å†³æ–¹æ¡ˆã€‚</li>
<li>é€šè¿‡å¼•å…¥é«˜æ•ˆçš„KANå—ï¼Œæé«˜äº†åŸå§‹MedViTçš„å‡†ç¡®æ€§å¹¶é™ä½äº†è®¡ç®—è´Ÿè½½ã€‚</li>
<li>æå‡ºçš„å¢å¼ºDilated Neighborhood Attentionï¼ˆDiNAï¼‰èƒ½å¤Ÿæ•æ‰å…¨å±€ä¸Šä¸‹æ–‡å¹¶æ‰©å±•æ„Ÿå—é‡ï¼Œä»è€Œæœ‰æ•ˆæ‰©å±•æ¨¡å‹è§„æ¨¡å¹¶è§£å†³ç‰¹å¾å´©æºƒé—®é¢˜ã€‚</li>
<li>é‡‡ç”¨äº†åˆ†å±‚æ··åˆç­–ç•¥æ¥å¹³è¡¡å±€éƒ¨å’Œå…¨å±€ç‰¹å¾æ„ŸçŸ¥å—ï¼Œè¿›ä¸€æ­¥æå‡äº†æ€§èƒ½ã€‚</li>
<li>åœ¨å¤šä¸ªåŒ»å­¦å›¾åƒåˆ†ç±»æ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒMedViTV2åœ¨è®¡ç®—æ•ˆç‡æé«˜çš„åŒæ—¶ï¼Œå®ç°äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚</li>
<li>MedViTV2åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸Šè¾¾åˆ°äº†ä¸šç•Œæœ€ä½³æ€§èƒ½ï¼ŒåŒ…æ‹¬åœ¨MedMNISTã€NonMNISTå’ŒMedMNIST-Cä¸Šçš„å‡†ç¡®ç‡æ˜¾è‘—æé«˜ã€‚</li>
<li>MedViTV2æ¶æ„å±•ç°å‡ºåœ¨åº”å¯¹çœŸå®ä¸–ç•Œä¸´åºŠæ•°æ®ä¸­ç‹¬ç‰¹çš„å¤šä¸­å¿ƒç ”ç©¶å›¾åƒè…èš€é—®é¢˜çš„æ½œåŠ›ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.13693">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-81896e600f040ab82142fa4fdc162a05.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-87ef7c213bc8251ae28558a2f9ed90f8.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a125441db26833802fa272ba56ec384d.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-9a2eeb32eb8cac77b34308440cd56739.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-4725b8d1770df0430664a9a673701871.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="MobileViM-A-Light-weight-and-Dimension-independent-Vision-Mamba-for-3D-Medical-Image-Analysis"><a href="#MobileViM-A-Light-weight-and-Dimension-independent-Vision-Mamba-for-3D-Medical-Image-Analysis" class="headerlink" title="MobileViM: A Light-weight and Dimension-independent Vision Mamba for 3D   Medical Image Analysis"></a>MobileViM: A Light-weight and Dimension-independent Vision Mamba for 3D   Medical Image Analysis</h2><p><strong>Authors:Wei Dai, Steven Wang, Jun Liu</strong></p>
<p>Efficient evaluation of three-dimensional (3D) medical images is crucial for diagnostic and therapeutic practices in healthcare. Recent years have seen a substantial uptake in applying deep learning and computer vision to analyse and interpret medical images. Traditional approaches, such as convolutional neural networks (CNNs) and vision transformers (ViTs), face significant computational challenges, prompting the need for architectural advancements. Recent efforts have led to the introduction of novel architectures like the &#96;&#96;Mambaâ€™â€™ model as alternative solutions to traditional CNNs or ViTs. The Mamba model excels in the linear processing of one-dimensional data with low computational demands. However, Mambaâ€™s potential for 3D medical image analysis remains underexplored and could face significant computational challenges as the dimension increases. This manuscript presents MobileViM, a streamlined architecture for efficient segmentation of 3D medical images. In the MobileViM network, we invent a new dimension-independent mechanism and a dual-direction traversing approach to incorporate with a vision-Mamba-based framework. MobileViM also features a cross-scale bridging technique to improve efficiency and accuracy across various medical imaging modalities. With these enhancements, MobileViM achieves segmentation speeds exceeding 90 frames per second (FPS) on a single graphics processing unit (i.e., NVIDIA RTX 4090). This performance is over 24 FPS faster than the state-of-the-art deep learning models for processing 3D images with the same computational resources. In addition, experimental evaluations demonstrate that MobileViM delivers superior performance, with Dice similarity scores reaching 92.72%, 86.69%, 80.46%, and 77.43% for PENGWIN, BraTS2024, ATLAS, and Toothfairy2 datasets, respectively, which significantly surpasses existing models. </p>
<blockquote>
<p>åœ¨åŒ»ç–—ä¿å¥é¢†åŸŸï¼Œå¯¹ä¸‰ç»´ï¼ˆ3Dï¼‰åŒ»å­¦å›¾åƒçš„æœ‰æ•ˆè¯„ä¼°å¯¹äºè¯Šæ–­å’Œæ²»ç–—å®è·µè‡³å…³é‡è¦ã€‚è¿‘å¹´æ¥ï¼Œæ·±åº¦å­¦ä¹ å’Œè®¡ç®—æœºè§†è§‰åœ¨åŒ»å­¦å›¾åƒåˆ†æå’Œè§£é‡Šæ–¹é¢çš„åº”ç”¨æ˜¾è‘—å¢åŠ ã€‚ä¼ ç»Ÿæ–¹æ³•ï¼Œå¦‚å·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNsï¼‰å’Œè§†è§‰è½¬æ¢å™¨ï¼ˆViTsï¼‰ï¼Œé¢ä¸´é‡å¤§çš„è®¡ç®—æŒ‘æˆ˜ï¼Œè¿™ä¿ƒä½¿äº†æ¶æ„å‘å±•çš„éœ€æ±‚ã€‚æœ€è¿‘çš„åŠªåŠ›å¯¼è‡´äº†â€œMambaâ€æ¨¡å‹ç­‰æ–°å…´æ¶æ„çš„å‡ºç°ï¼Œä½œä¸ºä¼ ç»ŸCNNæˆ–ViTsçš„æ›¿ä»£è§£å†³æ–¹æ¡ˆã€‚Mambaæ¨¡å‹åœ¨å¤„ç†ä¸€ç»´æ•°æ®çš„çº¿æ€§å¤„ç†æ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œè®¡ç®—éœ€æ±‚è¾ƒä½ã€‚ç„¶è€Œï¼ŒMambaåœ¨3DåŒ»å­¦å›¾åƒåˆ†ææ–¹é¢çš„æ½œåŠ›å°šæœªå¾—åˆ°å……åˆ†æ¢ç´¢ï¼Œéšç€ç»´åº¦çš„å¢åŠ ï¼Œå¯èƒ½ä¼šé¢ä¸´é‡å¤§çš„è®¡ç®—æŒ‘æˆ˜ã€‚æœ¬æ‰‹ç¨¿æå‡ºäº†MobileViMï¼Œè¿™æ˜¯ä¸€ä¸ªç”¨äºé«˜æ•ˆåˆ†å‰²3DåŒ»å­¦å›¾åƒçš„æµçº¿åŒ–æ¶æ„ã€‚åœ¨MobileViMç½‘ç»œä¸­ï¼Œæˆ‘ä»¬å‘æ˜äº†ä¸€ç§æ–°çš„ç»´åº¦ç‹¬ç«‹æœºåˆ¶å’Œä¸€ç§åŒå‘éå†æ–¹æ³•ï¼Œå°†å…¶èå…¥åŸºäºè§†è§‰Mambaçš„æ¡†æ¶ä¸­ã€‚MobileViMè¿˜é‡‡ç”¨è·¨å°ºåº¦æ¡¥æ¢æŠ€æœ¯ï¼Œä»¥æé«˜ä¸åŒåŒ»å­¦æˆåƒæ¨¡å¼çš„æ•ˆç‡å’Œå‡†ç¡®æ€§ã€‚é€šè¿‡è¿™äº›å¢å¼ºåŠŸèƒ½ï¼ŒMobileViMåœ¨å•ä¸ªå›¾å½¢å¤„ç†å•å…ƒï¼ˆå³NVIDIA RTX 4090ï¼‰ä¸Šå®ç°äº†è¶…è¿‡æ¯ç§’90å¸§ï¼ˆFPSï¼‰çš„åˆ†å‰²é€Ÿåº¦ã€‚æ­¤æ€§èƒ½æ¯”ä½¿ç”¨ç›¸åŒè®¡ç®—èµ„æºçš„å¤„ç†3Då›¾åƒçš„æœ€å…ˆè¿›æ·±åº¦å­¦ä¹ æ¨¡å‹çš„æ€§èƒ½å¿«24 FPSä»¥ä¸Šã€‚æ­¤å¤–ï¼Œå®éªŒè¯„ä¼°è¡¨æ˜ï¼ŒMobileViMçš„æ€§èƒ½å“è¶Šï¼Œåœ¨PENGWINã€BraTS2024ã€ATLASå’ŒToothfairy2æ•°æ®é›†ä¸Šçš„Diceç›¸ä¼¼åº¦å¾—åˆ†åˆ†åˆ«ä¸º92.72%ã€86.69%ã€80.46%å’Œ77.43%ï¼Œæ˜¾è‘—è¶…è¶Šäº†ç°æœ‰æ¨¡å‹ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.13524v1">PDF</a> The code is accessible through:   <a target="_blank" rel="noopener" href="https://github.com/anthonyweidai/MobileViM_3D/">https://github.com/anthonyweidai/MobileViM_3D/</a></p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°å‹çš„é’ˆå¯¹ä¸‰ç»´åŒ»å­¦å›¾åƒåˆ†æçš„æ¨¡å‹MobileViMï¼Œè¯¥æ¨¡å‹é‡‡ç”¨ç»´åº¦ç‹¬ç«‹æœºåˆ¶ã€åŒå‘éå†æ–¹æ³•å’Œè·¨å°ºåº¦æ¡¥æ¥æŠ€æœ¯ï¼Œæ—¨åœ¨æé«˜è®¡ç®—æ•ˆç‡å’Œå‡†ç¡®æ€§ã€‚åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šçš„å®éªŒè¯„ä¼°è¡¨æ˜ï¼ŒMobileViMçš„æ€§èƒ½ä¼˜äºç°æœ‰æ¨¡å‹ï¼Œå®ç°äº†é«˜æ•ˆçš„åŒ»å­¦å›¾åƒåˆ†å‰²ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>MobileViMæ˜¯ä¸€ä¸ªé’ˆå¯¹ä¸‰ç»´åŒ»å­¦å›¾åƒåˆ†æçš„æ¨¡å‹ï¼Œæ—¨åœ¨æé«˜è®¡ç®—æ•ˆç‡å’Œå‡†ç¡®æ€§ã€‚</li>
<li>MobileViMå¼•å…¥äº†ç»´åº¦ç‹¬ç«‹æœºåˆ¶å’ŒåŒå‘éå†æ–¹æ³•æ¥å¤„ç†åŒ»å­¦å›¾åƒã€‚</li>
<li>è·¨å°ºåº¦æ¡¥æ¥æŠ€æœ¯è¢«ç”¨äºæ”¹å–„ä¸åŒæˆåƒæ¨¡æ€çš„æ•ˆç‡ä¸å‡†ç¡®æ€§ã€‚</li>
<li>MobileViMå®ç°äº†è¶…è¿‡90å¸§æ¯ç§’çš„åˆ†å‰²é€Ÿåº¦ï¼Œæ¯”ç°æœ‰æ¨¡å‹å¿«24å¸§ä»¥ä¸Šã€‚</li>
<li>åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šçš„å®éªŒè¯„ä¼°æ˜¾ç¤ºï¼ŒMobileViMçš„æ€§èƒ½æ˜¾è‘—è¶…è¿‡ç°æœ‰æ¨¡å‹ï¼ŒDiceç›¸ä¼¼åº¦å¾—åˆ†é«˜ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.13524">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-478c4a069cb045964697c54dfba709cc.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-ce4cf8702947ea6ba2c02dc49aa37123.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-e42796ec18c7321bee4b45d36a1c3825.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-9cd6b470a040419562bc91eea89ac5f1.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-5a5f77b8f330ea05bdd1df377c514ad9.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="Enhancing-Chest-X-ray-Classification-through-Knowledge-Injection-in-Cross-Modality-Learning"><a href="#Enhancing-Chest-X-ray-Classification-through-Knowledge-Injection-in-Cross-Modality-Learning" class="headerlink" title="Enhancing Chest X-ray Classification through Knowledge Injection in   Cross-Modality Learning"></a>Enhancing Chest X-ray Classification through Knowledge Injection in   Cross-Modality Learning</h2><p><strong>Authors:Yang Yan, Bingqing Yue, Qiaxuan Li, Man Huang, Jingyu Chen, Zhenzhong Lan</strong></p>
<p>The integration of artificial intelligence in medical imaging has shown tremendous potential, yet the relationship between pre-trained knowledge and performance in cross-modality learning remains unclear. This study investigates how explicitly injecting medical knowledge into the learning process affects the performance of cross-modality classification, focusing on Chest X-ray (CXR) images. We introduce a novel Set Theory-based knowledge injection framework that generates captions for CXR images with controllable knowledge granularity. Using this framework, we fine-tune CLIP model on captions with varying levels of medical information. We evaluate the modelâ€™s performance through zero-shot classification on the CheXpert dataset, a benchmark for CXR classification. Our results demonstrate that injecting fine-grained medical knowledge substantially improves classification accuracy, achieving 72.5% compared to 49.9% when using human-generated captions. This highlights the crucial role of domain-specific knowledge in medical cross-modality learning. Furthermore, we explore the influence of knowledge density and the use of domain-specific Large Language Models (LLMs) for caption generation, finding that denser knowledge and specialized LLMs contribute to enhanced performance. This research advances medical image analysis by demonstrating the effectiveness of knowledge injection for improving automated CXR classification, paving the way for more accurate and reliable diagnostic tools. </p>
<blockquote>
<p>äººå·¥æ™ºèƒ½åœ¨åŒ»å­¦æˆåƒæ–¹é¢çš„åº”ç”¨å…·æœ‰å·¨å¤§çš„æ½œåŠ›ï¼Œç„¶è€Œé¢„è®­ç»ƒçŸ¥è¯†ä¸è·¨æ¨¡æ€å­¦ä¹ æ€§èƒ½ä¹‹é—´çš„å…³ç³»ä»ä¸æ˜ç¡®ã€‚æœ¬ç ”ç©¶è°ƒæŸ¥äº†å°†åŒ»å­¦çŸ¥è¯†æ˜ç¡®æ³¨å…¥å­¦ä¹ è¿‡ç¨‹å¦‚ä½•å½±å“è·¨æ¨¡æ€åˆ†ç±»çš„æ€§èƒ½ï¼Œé‡ç‚¹å…³æ³¨èƒ¸éƒ¨Xå°„çº¿ï¼ˆCXRï¼‰å›¾åƒã€‚æˆ‘ä»¬å¼•å…¥äº†ä¸€ç§åŸºäºé›†åˆç†è®ºçš„æ–°å‹çŸ¥è¯†æ³¨å…¥æ¡†æ¶ï¼Œè¯¥æ¡†æ¶å¯æ§çŸ¥è¯†ç²’åº¦ï¼Œä¸ºCXRå›¾åƒç”Ÿæˆæè¿°ã€‚åˆ©ç”¨æ­¤æ¡†æ¶ï¼Œæˆ‘ä»¬åœ¨ä¸åŒæ°´å¹³çš„åŒ»ç–—ä¿¡æ¯æè¿°ä¸Šå¯¹CLIPæ¨¡å‹è¿›è¡Œå¾®è°ƒã€‚æˆ‘ä»¬åœ¨CheXpertæ•°æ®é›†ä¸Šé€šè¿‡é›¶æ ·æœ¬åˆ†ç±»è¯„ä¼°æ¨¡å‹æ€§èƒ½ï¼Œè¿™æ˜¯CXRåˆ†ç±»çš„åŸºå‡†æµ‹è¯•ã€‚æˆ‘ä»¬çš„ç»“æœè¡¨æ˜ï¼Œæ³¨å…¥ç²¾ç»†åŒ»å­¦çŸ¥è¯†èƒ½æ˜¾è‘—æé«˜åˆ†ç±»å‡†ç¡®ç‡ï¼Œè¾¾åˆ°72.5%ï¼Œè€Œä½¿ç”¨äººå·¥ç”Ÿæˆçš„æè¿°æ—¶ä»…ä¸º49.9%ã€‚è¿™çªæ˜¾äº†é¢†åŸŸç‰¹å®šçŸ¥è¯†åœ¨åŒ»å­¦è·¨æ¨¡æ€å­¦ä¹ ä¸­çš„å…³é”®ä½œç”¨ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜æ¢è®¨äº†çŸ¥è¯†å¯†åº¦ä»¥åŠä¸“ç”¨é¢†åŸŸå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨æè¿°ç”Ÿæˆä¸­çš„å½±å“ï¼Œå‘ç°æ›´å¯†é›†çš„çŸ¥è¯†å’Œä¸“ç”¨çš„LLMæœ‰åŠ©äºæå‡æ€§èƒ½ã€‚æœ¬ç ”ç©¶é€šè¿‡å±•ç¤ºçŸ¥è¯†æ³¨å…¥åœ¨æé«˜è‡ªåŠ¨CXRåˆ†ç±»æ–¹é¢çš„æœ‰æ•ˆæ€§ï¼Œæ¨åŠ¨äº†åŒ»å­¦å›¾åƒåˆ†æçš„å‘å±•ï¼Œä¸ºæ›´å‡†ç¡®ã€æ›´å¯é çš„è¯Šæ–­å·¥å…·é“ºå¹³äº†é“è·¯ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.13447v1">PDF</a> Accepted by ICASSPâ€™25</p>
<p><strong>Summary</strong><br>     äººå·¥æ™ºèƒ½åœ¨åŒ»å­¦æˆåƒä¸­çš„èåˆå±•ç°å‡ºå·¨å¤§æ½œåŠ›ï¼Œä½†é¢„è®­ç»ƒçŸ¥è¯†ä¸è·¨æ¨¡æ€å­¦ä¹ æ€§èƒ½ä¹‹é—´çš„å…³ç³»å°šä¸æ¸…æ¥šã€‚æœ¬ç ”ç©¶è°ƒæŸ¥äº†å°†åŒ»å­¦çŸ¥è¯†æ˜ç¡®æ³¨å…¥å­¦ä¹ è¿‡ç¨‹å¦‚ä½•å½±å“è·¨æ¨¡æ€åˆ†ç±»çš„æ€§èƒ½ï¼Œé‡ç‚¹å…³æ³¨èƒ¸éƒ¨Xå…‰ï¼ˆCXRï¼‰å›¾åƒã€‚å¼•å…¥åŸºäºé›†åˆç†è®ºçš„çŸ¥è¯†æ³¨å…¥æ¡†æ¶ï¼Œä¸ºCXRå›¾åƒç”Ÿæˆå¯æ§çŸ¥è¯†ç²’åº¦çš„å­—å¹•ã€‚ä½¿ç”¨æ­¤æ¡†æ¶å¯¹CLIPæ¨¡å‹è¿›è¡Œå¾®è°ƒï¼Œå¹¶ä½¿ç”¨ä¸åŒæ°´å¹³çš„åŒ»ç–—ä¿¡æ¯è¿›è¡Œè¯„ä¼°ã€‚åœ¨CXRåˆ†ç±»çš„åŸºå‡†æ•°æ®é›†CheXpertä¸Šè¿›è¡Œé›¶æ ·æœ¬åˆ†ç±»ï¼Œç»“æœæ˜¾ç¤ºæ³¨å…¥ç²¾ç»†åŒ»å­¦çŸ¥è¯†å¯æ˜¾è‘—æé«˜åˆ†ç±»ç²¾åº¦ï¼Œè¾¾åˆ°72.5%ï¼Œè€Œä½¿ç”¨äººç±»ç”Ÿæˆå­—å¹•æ—¶ä¸º49.9%ã€‚è¿™è¡¨æ˜ç‰¹å®šé¢†åŸŸçš„ä¸“ä¸šçŸ¥è¯†åœ¨åŒ»å­¦è·¨æ¨¡æ€å­¦ä¹ ä¸­èµ·ç€è‡³å…³é‡è¦çš„ä½œç”¨ã€‚æ­¤å¤–ï¼Œæœ¬ç ”ç©¶è¿˜æ¢è®¨äº†çŸ¥è¯†å¯†åº¦å’Œç”¨äºå­—å¹•ç”Ÿæˆçš„ç‰¹å®šé¢†åŸŸå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„å½±å“ï¼Œå‘ç°æ›´å¯†é›†çš„çŸ¥è¯†å’Œä¸“é—¨çš„LLMæœ‰åŠ©äºæå‡æ€§èƒ½ã€‚æœ¬ç ”ç©¶é€šè¿‡å±•ç¤ºçŸ¥è¯†æ³¨å…¥åœ¨æé«˜è‡ªåŠ¨åŒ–CXRåˆ†ç±»ä¸­çš„æœ‰æ•ˆæ€§ï¼Œä¸ºåŒ»å­¦å›¾åƒåˆ†æçš„å‘å±•é“ºå¹³äº†é“è·¯ï¼Œä¸ºæ›´å‡†ç¡®å¯é çš„è¯Šæ–­å·¥å…·æ‰“ä¸‹åŸºç¡€ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>äººå·¥æ™ºèƒ½åœ¨åŒ»å­¦æˆåƒä¸­å…·æœ‰å·¨å¤§æ½œåŠ›ã€‚</li>
<li>é¢„è®­ç»ƒçŸ¥è¯†ä¸è·¨æ¨¡æ€å­¦ä¹ æ€§èƒ½ä¹‹é—´çš„å…³ç³»å°šä¸æ¸…æ¥šã€‚</li>
<li>å°†åŒ»å­¦çŸ¥è¯†æ³¨å…¥å­¦ä¹ è¿‡ç¨‹å¯å½±å“è·¨æ¨¡æ€åˆ†ç±»æ€§èƒ½ã€‚</li>
<li>åŸºäºé›†åˆç†è®ºçš„çŸ¥è¯†æ³¨å…¥æ¡†æ¶ç”ŸæˆCXRå›¾åƒå­—å¹•ã€‚</li>
<li>æ³¨å…¥ç²¾ç»†åŒ»å­¦çŸ¥è¯†æ˜¾è‘—æé«˜CXRå›¾åƒåˆ†ç±»ç²¾åº¦ã€‚</li>
<li>çŸ¥è¯†å¯†åº¦å’Œç‰¹å®šé¢†åŸŸçš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å¯¹æ€§èƒ½æœ‰ç§¯æå½±å“ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.13447">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-2ccbc9e51f2b6fa927b64d8b7ff716a5.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-669f7b681c892270c797db543bd28ce0.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-143f4e64cbccda3015e5c5911ca4c37a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-291fe24541a5b4389ef55e4532a5a7a5.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="Timing-characterization-of-MALTA-and-MALTA2-pixel-detectors-using-Micro-X-ray-source"><a href="#Timing-characterization-of-MALTA-and-MALTA2-pixel-detectors-using-Micro-X-ray-source" class="headerlink" title="Timing characterization of MALTA and MALTA2 pixel detectors using Micro   X-ray source"></a>Timing characterization of MALTA and MALTA2 pixel detectors using Micro   X-ray source</h2><p><strong>Authors:G. Dash, P. Allport, I. Asensi Tortajada, P. Behera, D. V. Berlea, D. Bortoletto, C. Buttar, V. Dao, L. Fasselt, L. Flores Sanz de Acedo, M. Gazi, L. Gonella, V. Gonzalez, G. Gustavino, S. Haberl, T. Inada, P. Jana, L. Li, H. Pernegger, P. Riedler, W. Snoeys, C. A Solans Sanchez, M. van Rijnbach, M. Vazquez Nunez, A. Vijay, J. Weick, S. Worm</strong></p>
<p>The MALTA monolithic active pixel detector is developed to address the challenges anticipated in future high-energy physics detectors. As part of its characterization, we conducted fast-timing studies necessary to provide a figure of merit for this family of monolithic pixel detectors. MALTA has a metal layer in front-end electronics, and the conventional laser technique is not suitable for fast timing studies due to the reflection of the laser from the metallic surface. X-rays have been employed as a more effective alternative for penetration through these layers. The triggered X-ray set-up is designed to study timing measurements of monolithic detectors. The timing response of the X-ray set-up is characterized using an LGAD. The timing response of the MALTA and MALTA2 pixel detectors is studied, and the best response time of MALTA2 pixel detectors is measured at about 2 ns. </p>
<blockquote>
<p>MALTAå•ç‰‡æœ‰æºåƒç´ æ¢æµ‹å™¨æ˜¯ä¸ºäº†åº”å¯¹æœªæ¥é«˜èƒ½ç‰©ç†æ¢æµ‹å™¨é¢„æœŸé¢ä¸´çš„æŒ‘æˆ˜è€Œå¼€å‘çš„ã€‚ä½œä¸ºè¡¨å¾çš„ä¸€éƒ¨åˆ†ï¼Œæˆ‘ä»¬è¿›è¡Œäº†å¿«é€Ÿæ—¶é—´ç ”ç©¶ï¼Œä¸ºè¿™ç±»å•ç‰‡åƒç´ æ¢æµ‹å™¨æä¾›æ€§èƒ½æŒ‡æ ‡ã€‚MALTAå‰ç«¯ç”µå­å™¨ä»¶ä¸­æœ‰ä¸€å±‚é‡‘å±ï¼Œä¼ ç»Ÿçš„æ¿€å…‰æŠ€æœ¯ç”±äºæ¿€å…‰åœ¨é‡‘å±è¡¨é¢çš„åå°„è€Œä¸é€‚ç”¨äºå¿«é€Ÿæ—¶é—´ç ”ç©¶ã€‚Xå°„çº¿å·²è¢«ç”¨ä½œç©¿é€è¿™äº›å±‚æ›´æœ‰æ•ˆçš„æ›¿ä»£æ–¹æ³•ã€‚è§¦å‘å¼Xå°„çº¿è£…ç½®æ—¨åœ¨ç ”ç©¶å•ç‰‡æ¢æµ‹å™¨çš„å®šæ—¶æµ‹é‡ã€‚Xå°„çº¿è£…ç½®çš„å®šæ—¶å“åº”ä½¿ç”¨LGADè¿›è¡Œè¡¨å¾ã€‚ç ”ç©¶äº†MALTAå’ŒMALTA2åƒç´ æ¢æµ‹å™¨çš„å®šæ—¶å“åº”ï¼Œå¹¶æµ‹å¾—MALTA2åƒç´ æ¢æµ‹å™¨çš„æœ€ä½³å“åº”æ—¶é—´ä¸ºçº¦2çº³ç§’ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.13330v1">PDF</a> 13 pages, 11 figures, To be submitted to JINST</p>
<p><strong>Summary</strong><br>     é©¬è€³ä»–å•ç‰‡ä¸»åŠ¨åƒç´ æ¢æµ‹å™¨ä¸“ä¸ºåº”å¯¹æœªæ¥é«˜èƒ½ç‰©ç†æ¢æµ‹å™¨é¢ä¸´çš„æŒ‘æˆ˜è€Œå¼€å‘ã€‚ä¸ºè¯„ä¼°æ­¤ç±»å•ç‰‡åƒç´ æ¢æµ‹å™¨çš„æ€§èƒ½ï¼Œæˆ‘ä»¬è¿›è¡Œäº†å¿«é€Ÿæ—¶é—´æµ‹å®šç ”ç©¶ã€‚ç”±äºè¯¥æ¢æµ‹å™¨å‰ç«¯ç”µå­å™¨ä»¶ä¸­å­˜åœ¨é‡‘å±å±‚ï¼Œä¼ ç»Ÿæ¿€å…‰æŠ€æœ¯ä¸é€‚ç”¨äºå¿«é€Ÿæ—¶é—´æµ‹å®šã€‚å› æ­¤ï¼Œé‡‡ç”¨Xå°„çº¿ä½œä¸ºæ›´æœ‰æ•ˆçš„æ›¿ä»£æ–¹æ¡ˆï¼Œä»¥ç©¿é€è¿™äº›é‡‘å±å±‚ã€‚è§¦å‘å¼Xå°„çº¿è£…ç½®ç”¨äºç ”ç©¶å•ç‰‡æ¢æµ‹å™¨çš„å®šæ—¶æµ‹é‡ã€‚åˆ©ç”¨LGADå¯¹Xå°„çº¿è£…ç½®çš„å®šæ—¶å“åº”è¿›è¡Œäº†è¡¨å¾ï¼Œå¹¶å¯¹é©¬è€³ä»–å’Œé©¬è€³ä»–2å·åƒç´ æ¢æµ‹å™¨çš„å“åº”æ—¶é—´è¿›è¡Œäº†ç ”ç©¶ï¼Œå…¶ä¸­é©¬è€³ä»–2å·åƒç´ æ¢æµ‹å™¨çš„æœ€ä½³å“åº”æ—¶é—´çº¦ä¸º2çº³ç§’ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>MALTAå•ç‰‡ä¸»åŠ¨åƒç´ æ¢æµ‹å™¨æ˜¯ä¸ºäº†åº”å¯¹æœªæ¥é«˜èƒ½ç‰©ç†æ¢æµ‹å™¨é¢ä¸´çš„æŒ‘æˆ˜è€Œå¼€å‘çš„ã€‚</li>
<li>å¿«é€Ÿæ—¶é—´æµ‹å®šç ”ç©¶æ˜¯ä¸ºäº†è¯„ä¼°æ­¤ç±»å•ç‰‡åƒç´ æ¢æµ‹å™¨çš„æ€§èƒ½ã€‚</li>
<li>ç”±äºæ¢æµ‹å™¨ä¸­çš„é‡‘å±å±‚ï¼Œä¼ ç»Ÿæ¿€å…‰æŠ€æœ¯ä¸é€‚ç”¨äºå¿«é€Ÿæ—¶é—´æµ‹å®šã€‚</li>
<li>Xå°„çº¿è¢«ç”¨ä½œæ›´æœ‰æ•ˆçš„æ›¿ä»£æ–¹æ¡ˆï¼Œä»¥ç©¿é€é‡‘å±å±‚ã€‚</li>
<li>è§¦å‘å¼Xå°„çº¿è£…ç½®ç”¨äºç ”ç©¶å•ç‰‡æ¢æµ‹å™¨çš„å®šæ—¶æµ‹é‡ã€‚</li>
<li>LGADè¢«ç”¨æ¥è¡¨å¾Xå°„çº¿è£…ç½®çš„å®šæ—¶å“åº”ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.13330">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-59999f15c0f67f9fb2a847eef4e83c65.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-7d36f55489d548fcbc7b75c3064f4efa.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-937464f96675c4a3f848e5f4749b8081.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-ed4d642adf982282f84046363e8321a0.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-44d27bcb144f56410d02d6300c18fdb4.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="Data-Efficient-Limited-Angle-CT-Using-Deep-Priors-and-Regularization"><a href="#Data-Efficient-Limited-Angle-CT-Using-Deep-Priors-and-Regularization" class="headerlink" title="Data-Efficient Limited-Angle CT Using Deep Priors and Regularization"></a>Data-Efficient Limited-Angle CT Using Deep Priors and Regularization</h2><p><strong>Authors:Ilmari Vahteristo, Zhi-Song Liu, Andreas Rupp</strong></p>
<p>Reconstructing an image from its Radon transform is a fundamental computed tomography (CT) task arising in applications such as X-ray scans. In many practical scenarios, a full 180-degree scan is not feasible, or there is a desire to reduce radiation exposure. In these limited-angle settings, the problem becomes ill-posed, and methods designed for full-view data often leave significant artifacts. We propose a very low-data approach to reconstruct the original image from its Radon transform under severe angle limitations. Because the inverse problem is ill-posed, we combine multiple regularization methods, including Total Variation, a sinogram filter, Deep Image Prior, and a patch-level autoencoder. We use a differentiable implementation of the Radon transform, which allows us to use gradient-based techniques to solve the inverse problem. Our method is evaluated on a dataset from the Helsinki Tomography Challenge 2022, where the goal is to reconstruct a binary disk from its limited-angle sinogram. We only use a total of 12 data pointsâ€“eight for learning a prior and four for hyperparameter selectionâ€“and achieve results comparable to the best synthetic data-driven approaches. </p>
<blockquote>
<p>ä»Radonå˜æ¢é‡å»ºå›¾åƒæ˜¯è®¡ç®—æœºæ–­å±‚æ‰«æï¼ˆCTï¼‰ä¸­çš„ä¸€ä¸ªåŸºæœ¬ä»»åŠ¡ï¼Œå‡ºç°åœ¨Xå°„çº¿æ‰«æç­‰åº”ç”¨ä¸­ã€‚åœ¨è®¸å¤šå®é™…åœºæ™¯ä¸­ï¼Œå®Œæ•´çš„180åº¦æ‰«æå¹¶ä¸å¯è¡Œï¼Œæˆ–è€…å¸Œæœ›å‡å°‘è¾å°„æš´éœ²ã€‚åœ¨è¿™äº›æœ‰é™è§’åº¦è®¾ç½®ä¸­ï¼Œé—®é¢˜å˜å¾—ä¸é€‚å®šï¼Œä¸“ä¸ºå…¨è§†å›¾æ•°æ®è®¾è®¡çš„æ–¹æ³•é€šå¸¸ä¼šäº§ç”Ÿæ˜æ˜¾çš„ä¼ªå½±ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§åœ¨ä¸¥é‡è§’åº¦é™åˆ¶ä¸‹ä»Radonå˜æ¢é‡å»ºåŸå§‹å›¾åƒçš„ä½æ•°æ®æ–¹æ³•ã€‚ç”±äºåé—®é¢˜æ˜¯ä¸é€‚å®šçš„ï¼Œæˆ‘ä»¬å°†å¤šç§æ­£åˆ™åŒ–æ–¹æ³•ç»“åˆèµ·æ¥ï¼ŒåŒ…æ‹¬æ€»å˜å·®ã€è¾›è¯ºå›¾æ»¤æ³¢å™¨ã€æ·±åº¦å›¾åƒå…ˆéªŒå’Œè¡¥ä¸çº§åˆ«çš„è‡ªåŠ¨ç¼–ç å™¨ã€‚æˆ‘ä»¬ä½¿ç”¨Radonå˜æ¢çš„å¯å¾®å®ç°ï¼Œè¿™ä½¿æˆ‘ä»¬èƒ½å¤Ÿä½¿ç”¨åŸºäºæ¢¯åº¦çš„æ–¹æ³•æ¥è§£å†³åé—®é¢˜ã€‚æˆ‘ä»¬çš„æ–¹æ³•åœ¨èµ«å°”è¾›åŸºæ–­å±‚æ‰«ææŒ‘æˆ˜èµ›2022çš„æ•°æ®é›†ä¸Šè¿›è¡Œäº†è¯„ä¼°ï¼Œè¯¥æ¯”èµ›çš„ç›®æ ‡æ˜¯ä»æœ‰é™çš„è§’åº¦è¾›è¯ºå›¾ä¸­é‡å»ºäºŒè¿›åˆ¶ç£ç›˜ã€‚æˆ‘ä»¬ä»…ä½¿ç”¨æ€»å…±12ä¸ªæ•°æ®ç‚¹ï¼ˆ8ä¸ªç”¨äºå­¦ä¹ å…ˆéªŒçŸ¥è¯†ï¼Œ4ä¸ªç”¨äºè¶…å‚æ•°é€‰æ‹©ï¼‰ï¼Œå¹¶å–å¾—äº†ä¸æœ€ä½³åˆæˆæ•°æ®é©±åŠ¨æ–¹æ³•ç›¸å½“çš„ç»“æœã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.12293v2">PDF</a> 12 pages, 2 reference pages, 5 figures</p>
<p><strong>Summary</strong></p>
<p>æ–‡ç« è®¨è®ºäº†CTä¸­çš„å›¾åƒé‡å»ºé—®é¢˜ï¼Œç‰¹åˆ«æ˜¯åœ¨æœ‰é™è§’åº¦æ‰«æçš„åœºæ™¯ä¸‹ã€‚ç”±äºé€†é—®é¢˜çš„ä¸é€‚å®šæ€§ï¼Œç»“åˆå¤šç§æ­£åˆ™åŒ–æ–¹æ³•ï¼ˆå¦‚å…¨å˜åˆ†ã€è¾›æ ¼æ‹‰å§†æ»¤æ³¢å™¨ã€æ·±åº¦å›¾åƒå…ˆéªŒå’Œæ–‘å—çº§è‡ªç¼–ç å™¨ï¼‰è¿›è¡Œå›¾åƒé‡å»ºã€‚é‡‡ç”¨å¯å¾®åˆ†çš„Radonå˜æ¢å®ç°æ–¹å¼ï¼Œå¹¶åˆ©ç”¨æ¢¯åº¦æŠ€æœ¯è§£å†³é€†é—®é¢˜ã€‚åœ¨èµ«å°”è¾›åŸºæ–­å±‚æ‰«ææŒ‘æˆ˜èµ›2022çš„æ•°æ®é›†ä¸Šè¿›è¡Œè¯„ä¼°ï¼Œä½¿ç”¨å°‘é‡æ•°æ®ç‚¹å³å¯å®ç°ä¸æœ€ä½³åˆæˆæ•°æ®é©±åŠ¨æ–¹æ³•ç›¸å½“çš„ç»“æœã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æ–‡ç« è®¨è®ºäº†è®¡ç®—æœºæ–­å±‚æ‰«æï¼ˆCTï¼‰ä¸­çš„å›¾åƒé‡å»ºé—®é¢˜ï¼Œç‰¹åˆ«æ˜¯åœ¨æœ‰é™è§’åº¦æ‰«æçš„åœºæ™¯ä¸‹ã€‚</li>
<li>åœ¨æœ‰é™è§’åº¦è®¾ç½®ä¸‹ï¼Œé—®é¢˜å˜å¾—ä¸é€‚å®šï¼Œä¸“ä¸ºå…¨è§†è§’æ•°æ®è®¾è®¡çš„æ–¹æ³•é€šå¸¸ä¼šäº§ç”Ÿæ˜¾è‘—ä¼ªå½±ã€‚</li>
<li>æå‡ºäº†ä¸€ç§åœ¨ä¸¥é‡è§’åº¦é™åˆ¶ä¸‹ä»Radonå˜æ¢é‡å»ºåŸå§‹å›¾åƒçš„ä½æ•°æ®æ–¹æ³•ã€‚</li>
<li>ç”±äºé€†é—®é¢˜çš„ä¸é€‚å®šæ€§ï¼Œç»“åˆäº†å¤šç§æ­£åˆ™åŒ–æ–¹æ³•ï¼ŒåŒ…æ‹¬å…¨å˜åˆ†ã€è¾›æ ¼æ‹‰å§†æ»¤æ³¢å™¨ã€æ·±åº¦å›¾åƒå…ˆéªŒå’Œæ–‘å—çº§è‡ªç¼–ç å™¨ã€‚</li>
<li>é‡‡ç”¨å¯å¾®åˆ†çš„Radonå˜æ¢å®ç°æ–¹å¼ï¼Œä»¥ä¾¿ä½¿ç”¨æ¢¯åº¦æŠ€æœ¯è§£å†³é€†é—®é¢˜ã€‚</li>
<li>åœ¨èµ«å°”è¾›åŸºæ–­å±‚æ‰«ææŒ‘æˆ˜èµ›2022çš„æ•°æ®é›†ä¸Šè¿›è¡Œäº†è¯„ä¼°ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.12293">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-7d2957f15548bbd1a95421990d34445d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-5610d74ba60455e0339750a7a8e1e81e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-9fd78d7f9622c23b9e99204ebecdb88c.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="HDCompression-Hybrid-Diffusion-Image-Compression-for-Ultra-Low-Bitrates"><a href="#HDCompression-Hybrid-Diffusion-Image-Compression-for-Ultra-Low-Bitrates" class="headerlink" title="HDCompression: Hybrid-Diffusion Image Compression for Ultra-Low Bitrates"></a>HDCompression: Hybrid-Diffusion Image Compression for Ultra-Low Bitrates</h2><p><strong>Authors:Lei Lu, Yize Li, Yanzhi Wang, Wei Wang, Wei Jiang</strong></p>
<p>Image compression under ultra-low bitrates remains challenging for both conventional learned image compression (LIC) and generative vector-quantized (VQ) modeling. Conventional LIC suffers from severe artifacts due to heavy quantization, while generative VQ modeling gives poor fidelity due to the mismatch between learned generative priors and specific inputs. In this work, we propose Hybrid-Diffusion Image Compression (HDCompression), a dual-stream framework that utilizes both generative VQ-modeling and diffusion models, as well as conventional LIC, to achieve both high fidelity and high perceptual quality. Different from previous hybrid methods that directly use pre-trained LIC models to generate low-quality fidelity-preserving information from heavily quantized latent, we use diffusion models to extract high-quality complimentary fidelity information from the ground-truth input, which can enhance the system performance in several aspects: improving indices map prediction, enhancing the fidelity-preserving output of the LIC stream, and refining conditioned image reconstruction with VQ-latent correction. In addition, our diffusion model is based on a dense representative vector (DRV), which is lightweight with very simple sampling schedulers. Extensive experiments demonstrate that our HDCompression outperforms the previous conventional LIC, generative VQ-modeling, and hybrid frameworks in both quantitative metrics and qualitative visualization, providing balanced robust compression performance at ultra-low bitrates. </p>
<blockquote>
<p>åœ¨è¶…ä½æ¯”ç‰¹ç‡ä¸‹ï¼Œå›¾åƒå‹ç¼©å¯¹äºä¼ ç»Ÿçš„å›¾åƒå‹ç¼©å­¦ä¹ ï¼ˆLICï¼‰å’Œç”Ÿæˆå‘é‡é‡åŒ–ï¼ˆVQï¼‰å»ºæ¨¡ä»ç„¶å…·æœ‰æŒ‘æˆ˜æ€§ã€‚ä¼ ç»ŸLICç”±äºé‡åº¦é‡åŒ–è€Œäº§ç”Ÿä¸¥é‡ä¼ªå½±ï¼Œè€Œç”ŸæˆVQå»ºæ¨¡ç”±äºå­¦ä¹ åˆ°çš„ç”Ÿæˆå…ˆéªŒä¸ç‰¹å®šè¾“å…¥ä¹‹é—´çš„ä¸åŒ¹é…è€Œå¯¼è‡´ä¿çœŸåº¦è¾ƒä½ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†æ··åˆæ‰©æ•£å›¾åƒå‹ç¼©ï¼ˆHDCompressionï¼‰ï¼Œè¿™æ˜¯ä¸€ä¸ªåŒæµä¼ è¾“æ¡†æ¶ï¼Œå®ƒç»“åˆäº†ç”ŸæˆVQå»ºæ¨¡å’Œæ‰©æ•£æ¨¡å‹ä»¥åŠä¼ ç»Ÿçš„LICï¼Œä»¥å®ç°é«˜ä¿çœŸå’Œé«˜æ„ŸçŸ¥è´¨é‡ã€‚ä¸ä¹‹å‰ç›´æ¥ä½¿ç”¨é¢„è®­ç»ƒçš„LICæ¨¡å‹ä»é‡åº¦é‡åŒ–çš„æ½œåœ¨ä¿¡æ¯ä¸­äº§ç”Ÿä½è´¨é‡ä¿çœŸä¿æŒä¿¡æ¯çš„æ··åˆæ–¹æ³•ä¸åŒï¼Œæˆ‘ä»¬ä½¿ç”¨æ‰©æ•£æ¨¡å‹ä»åŸå§‹çœŸå®è¾“å…¥ä¸­æå–é«˜è´¨é‡è¡¥å……ä¿çœŸä¿¡æ¯ï¼Œè¿™å¯ä»¥åœ¨å¤šä¸ªæ–¹é¢æé«˜ç³»ç»Ÿæ€§èƒ½ï¼šæ”¹è¿›ç´¢å¼•å›¾é¢„æµ‹ï¼Œæé«˜LICæµçš„ä¿çœŸä¿æŒè¾“å‡ºï¼Œå¹¶é€šè¿‡å¯¹VQæ½œåœ¨æ ¡æ­£è¿›è¡Œæ¡ä»¶å›¾åƒé‡å»ºã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬çš„æ‰©æ•£æ¨¡å‹åŸºäºå¯†é›†ä»£è¡¨æ€§å‘é‡ï¼ˆDRVï¼‰ï¼Œå®ƒè½»ä¾¿ä¸”å…·æœ‰éå¸¸ç®€å•çš„é‡‡æ ·è°ƒåº¦å™¨ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„HDCompressionåœ¨å®šé‡æŒ‡æ ‡å’Œå®šæ€§å¯è§†åŒ–æ–¹é¢å‡ä¼˜äºä»¥å‰çš„ä¼ ç»ŸLICã€ç”ŸæˆVQå»ºæ¨¡å’Œæ··åˆæ¡†æ¶ï¼Œåœ¨è¶…ä½æ¯”ç‰¹ç‡ä¸‹æä¾›äº†å¹³è¡¡çš„ç¨³å¥å‹ç¼©æ€§èƒ½ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.07160v2">PDF</a> Under Review</p>
<p><strong>Summary</strong></p>
<p>è¿™ç¯‡è®ºæ–‡æå‡ºäº†ä¸€ç§åä¸ºHybrid-Diffusion Image Compressionï¼ˆHDCompressionï¼‰çš„æ–°çš„å›¾åƒå‹ç¼©æ–¹æ³•ã€‚è¯¥æ–¹æ³•ç»“åˆäº†ç”Ÿæˆå¼VQå»ºæ¨¡ã€ä¼ ç»Ÿçš„å­¦ä¹ å›¾åƒå‹ç¼©å’Œæ‰©æ•£æ¨¡å‹ï¼Œæ—¨åœ¨å®ç°é«˜ä¿çœŸå’Œé«˜æ„ŸçŸ¥è´¨é‡ã€‚ä¸å…¶ä»–æ··åˆæ–¹æ³•ä¸åŒï¼Œå®ƒä½¿ç”¨æ‰©æ•£æ¨¡å‹ä»åŸå§‹å›¾åƒä¸­æå–é«˜è´¨é‡ä¿¡æ¯ï¼Œä»¥æ”¹è¿›ç³»ç»Ÿæ€§èƒ½ã€‚å®éªŒç»“æœè¯æ˜ï¼Œè¯¥æ–¹æ³•åœ¨è¶…ä½æ¯”ç‰¹ç‡ä¸‹åœ¨å®šé‡æŒ‡æ ‡å’Œå®šæ€§å¯è§†åŒ–æ–¹é¢å‡ä¼˜äºä¼ ç»Ÿçš„LICã€ç”Ÿæˆå¼VQå»ºæ¨¡å’Œæ··åˆæ¡†æ¶ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>HDCompressionæ˜¯ä¸€ç§æ–°çš„å›¾åƒå‹ç¼©æ–¹æ³•ï¼Œç»“åˆäº†ç”Ÿæˆå¼VQå»ºæ¨¡ã€ä¼ ç»Ÿçš„å­¦ä¹ å›¾åƒå‹ç¼©å’Œæ‰©æ•£æ¨¡å‹ã€‚</li>
<li>ä¸å…¶ä»–æ··åˆæ–¹æ³•ä¸åŒï¼ŒHDCompressionä½¿ç”¨æ‰©æ•£æ¨¡å‹ä»åŸå§‹å›¾åƒä¸­æå–é«˜è´¨é‡ä¿¡æ¯ï¼Œä»¥æé«˜ç³»ç»Ÿæ€§èƒ½ã€‚</li>
<li>HDCompressionèƒ½æé«˜ç´¢å¼•å›¾é¢„æµ‹çš„å‡†ç¡®æ€§ã€‚</li>
<li>å®ƒèƒ½å¢å¼ºå­¦ä¹ å›¾åƒå‹ç¼©æµçš„ä¿çœŸåº¦ä¿ç•™è¾“å‡ºã€‚</li>
<li>HDCompressionèƒ½ç»†åŒ–æœ‰æ¡ä»¶çš„å›¾åƒé‡å»ºï¼Œå¹¶è¿›è¡ŒVQæ½œä¼æ ¡æ­£ã€‚</li>
<li>è¯¥æ–¹æ³•ä½¿ç”¨åŸºäºå¯†é›†ä»£è¡¨å‘é‡ï¼ˆDRVï¼‰çš„æ‰©æ•£æ¨¡å‹ï¼Œå…·æœ‰è½»é‡çº§å’Œéå¸¸ç®€å•çš„é‡‡æ ·è°ƒåº¦å™¨ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.07160">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-db750e019fc28828643d3500bf9dca90.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-4a46c4a4b63e6126703b406339e85cb8.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-839ebbafb28640c5cd2d041eb04adec9.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-88b7851930ad7fc7f390c7fc29ef87d6.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-b4f26c7faad21302a27a4ae71a9f54c2.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="A-New-Logic-For-Pediatric-Brain-Tumor-Segmentation"><a href="#A-New-Logic-For-Pediatric-Brain-Tumor-Segmentation" class="headerlink" title="A New Logic For Pediatric Brain Tumor Segmentation"></a>A New Logic For Pediatric Brain Tumor Segmentation</h2><p><strong>Authors:Max Bengtsson, Elif Keles, Gorkem Durak, Syed Anwar, Yuri S. Velichko, Marius G. Linguraru, Angela J. Waanders, Ulas Bagci</strong></p>
<p>In this paper, we present a novel approach for segmenting pediatric brain tumors using a deep learning architecture, inspired by expert radiologistsâ€™ segmentation strategies. Our model delineates four distinct tumor labels and is benchmarked on a held-out PED BraTS 2024 test set (i.e., pediatric brain tumor datasets introduced by BraTS). Furthermore, we evaluate our modelâ€™s performance against the state-of-the-art (SOTA) model using a new external dataset of 30 patients from CBTN (Childrenâ€™s Brain Tumor Network), labeled in accordance with the PED BraTS 2024 guidelines and 2023 BraTS Adult Glioma dataset. We compare segmentation outcomes with the winning algorithm from the PED BraTS 2023 challenge as the SOTA model. Our proposed algorithm achieved an average Dice score of 0.642 and an HD95 of 73.0 mm on the CBTN test data, outperforming the SOTA model, which achieved a Dice score of 0.626 and an HD95 of 84.0 mm. Moreover, our model exhibits strong generalizability, attaining a 0.877 Dice score in whole tumor segmentation on the BraTS 2023 Adult Glioma dataset, surpassing existing SOTA. Our results indicate that the proposed model is a step towards providing more accurate segmentation for pediatric brain tumors, which is essential for evaluating therapy response and monitoring patient progress. Our source code is available at <a target="_blank" rel="noopener" href="https://github.com/NUBagciLab/Pediatric-Brain-Tumor-Segmentation-Model">https://github.com/NUBagciLab/Pediatric-Brain-Tumor-Segmentation-Model</a>. </p>
<blockquote>
<p>æœ¬æ–‡ä»‹ç»äº†ä¸€ç§å—ä¸“å®¶æ”¾å°„ç§‘åŒ»ç”Ÿåˆ†å‰²ç­–ç•¥å¯å‘çš„æ–°å‹æ·±åº¦å­¦ä¹ æ¶æ„ï¼Œç”¨äºåˆ†å‰²å„¿ç«¥è„‘è‚¿ç˜¤ã€‚æˆ‘ä»¬çš„æ¨¡å‹èƒ½å¤ŸåŒºåˆ†å››ç§ä¸åŒçš„è‚¿ç˜¤æ ‡ç­¾ï¼Œå¹¶åœ¨PED BraTS 2024æµ‹è¯•é›†ï¼ˆå³BraTSå¼•å…¥çš„å„¿ç«¥è„‘è‚¿ç˜¤æ•°æ®é›†ï¼‰ä¸Šè¿›è¡ŒåŸºå‡†æµ‹è¯•ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬ä½¿ç”¨ç¬¦åˆPED BraTS 2024æŒ‡å—å’Œ2023å¹´BraTSæˆäººèƒ¶è´¨ç˜¤æ•°æ®é›†çš„CBTNï¼ˆå„¿ç«¥è„‘è‚¿ç˜¤ç½‘ç»œï¼‰æ–°å¤–éƒ¨æ•°æ®é›†30åæ‚£è€…çš„æ•°æ®æ¥è¯„ä¼°æˆ‘ä»¬æ¨¡å‹çš„è¡¨ç°ã€‚æˆ‘ä»¬å°†åˆ†å‰²ç»“æœä¸PED BraTS 2023æŒ‘æˆ˜çš„è·èƒœç®—æ³•ä½œä¸ºæœ€å…ˆè¿›çš„æ¨¡å‹è¿›è¡Œæ¯”è¾ƒã€‚æˆ‘ä»¬æå‡ºçš„ç®—æ³•åœ¨CBTNæµ‹è¯•æ•°æ®ä¸Šå®ç°äº†å¹³å‡Diceç³»æ•°ä¸º0.642å’ŒHD95ä¸º73.0æ¯«ç±³ï¼Œä¼˜äºæœ€å…ˆè¿›çš„æ¨¡å‹ï¼ˆå…¶Diceç³»æ•°ä¸º0.626ï¼ŒHD95ä¸º84.0æ¯«ç±³ï¼‰ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬çš„æ¨¡å‹å…·æœ‰å¾ˆå¼ºçš„æ³›åŒ–èƒ½åŠ›ï¼Œåœ¨BraTS 2023æˆäººèƒ¶è´¨ç˜¤æ•°æ®é›†çš„å…¨è‚¿ç˜¤åˆ†å‰²ä¸Šè·å¾—äº†0.877çš„Diceç³»æ•°ï¼Œè¶…è¶Šäº†ç°æœ‰çš„æœ€å…ˆè¿›æ¨¡å‹ã€‚æˆ‘ä»¬çš„ç»“æœè¡¨æ˜ï¼Œæ‰€æå‡ºçš„æ¨¡å‹æ˜¯æœç€ä¸ºå„¿ç«¥è„‘è‚¿ç˜¤æä¾›æ›´ç²¾ç¡®åˆ†å‰²çš„æ–¹å‘è¿ˆå‡ºçš„ä¸€æ­¥ï¼Œè¿™å¯¹äºè¯„ä¼°æ²»ç–—ååº”å’Œç›‘æµ‹æ‚£è€…è¿›å±•è‡³å…³é‡è¦ã€‚æˆ‘ä»¬çš„æºä»£ç å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/NUBagciLab/Pediatric-Brain-Tumor-Segmentation-Model">https://github.com/NUBagciLab/Pediatric-Brain-Tumor-Segmentation-Model</a>å¤„è·å¾—ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2411.01390v3">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†ä¸€ç§åŸºäºæ·±åº¦å­¦ä¹ çš„æ–°æ–¹æ³•ï¼Œç”¨äºåˆ†å‰²å„¿ç«¥è„‘è‚¿ç˜¤ã€‚è¯¥æ–¹æ³•å—åˆ°ä¸“å®¶æ”¾å°„ç§‘åŒ»ç”Ÿåˆ†å‰²ç­–ç•¥çš„å¯å‘ï¼Œèƒ½æ˜ç¡®åŒºåˆ†å››ç§ä¸åŒçš„è‚¿ç˜¤æ ‡ç­¾ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•åœ¨å„¿ç«¥è„‘è‚¿ç˜¤æ•°æ®é›†ä¸Šçš„æ€§èƒ½ä¼˜äºç°æœ‰æœ€å…ˆè¿›çš„æ¨¡å‹ï¼Œå…·å¤‡æ›´å¼ºçš„æ³›åŒ–èƒ½åŠ›ã€‚æ­¤å¤–ï¼Œè¯¥æ¨¡å‹æºä»£ç å·²å…¬å¼€ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æœ¬æ–‡æå‡ºäº†ä¸€ç§ç”¨äºåˆ†å‰²å„¿ç«¥è„‘è‚¿ç˜¤çš„æ–°æ–¹æ³•ï¼ŒåŸºäºæ·±åº¦å­¦ä¹ æ¶æ„ã€‚</li>
<li>è¯¥æ–¹æ³•å—åˆ°ä¸“å®¶æ”¾å°„ç§‘åŒ»ç”Ÿåˆ†å‰²ç­–ç•¥çš„å¯å‘ï¼Œå¯åŒºåˆ†å››ç§ä¸åŒçš„è‚¿ç˜¤æ ‡ç­¾ã€‚</li>
<li>åœ¨PED BraTS 2024æµ‹è¯•é›†ä¸Šçš„æ€§èƒ½è¯„ä¼°æ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•ä¼˜äºç°æœ‰æœ€å…ˆè¿›çš„æ¨¡å‹ã€‚</li>
<li>è¯¥æ¨¡å‹åœ¨CBTNæµ‹è¯•æ•°æ®ä¸Šçš„å¹³å‡Diceå¾—åˆ†ä¸º0.642ï¼ŒHD95ä¸º73.0mmï¼Œè€Œæœ€å…ˆè¿›çš„æ¨¡å‹çš„Diceå¾—åˆ†ä¸º0.626ï¼ŒHD95ä¸º84.0mmã€‚</li>
<li>è¯¥æ¨¡å‹å…·æœ‰è‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›ï¼Œåœ¨BraTS 2023æˆäººèƒ¶è´¨ç˜¤æ•°æ®é›†ä¸Šçš„æ•´ä½“è‚¿ç˜¤åˆ†å‰²Diceå¾—åˆ†è¾¾åˆ°0.877ï¼Œè¶…è¿‡äº†ç°æœ‰æœ€å…ˆè¿›çš„æ¨¡å‹ã€‚</li>
<li>è¯¥æ¨¡å‹ä¸ºæ›´å‡†ç¡®åœ°åˆ†å‰²å„¿ç«¥è„‘è‚¿ç˜¤æä¾›äº†å¯èƒ½ï¼Œè¿™å¯¹è¯„ä¼°æ²»ç–—æ•ˆæœå’Œç›‘æµ‹æ‚£è€…è¿›å±•è‡³å…³é‡è¦ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2411.01390">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-fb4f878d83b1b9e6aa694ee51c66c186.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-9bfd45c3337d2d055d98833864277115.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-8f5af341952c17f1aa07ed17c6653830.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-02-21\./crop_åŒ»å­¦å›¾åƒ/2411.01390v3/page_2_1.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d5e764afa3bab82c2c05f9aff9ebfb21.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-8599962d65e5a97846d830e0089be95a.jpg" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="MedIAnomaly-A-comparative-study-of-anomaly-detection-in-medical-images"><a href="#MedIAnomaly-A-comparative-study-of-anomaly-detection-in-medical-images" class="headerlink" title="MedIAnomaly: A comparative study of anomaly detection in medical images"></a>MedIAnomaly: A comparative study of anomaly detection in medical images</h2><p><strong>Authors:Yu Cai, Weiwen Zhang, Hao Chen, Kwang-Ting Cheng</strong></p>
<p>Anomaly detection (AD) aims at detecting abnormal samples that deviate from the expected normal patterns. Generally, it can be trained merely on normal data, without a requirement for abnormal samples, and thereby plays an important role in rare disease recognition and health screening in the medical domain. Despite the emergence of numerous methods for medical AD, the lack of a fair and comprehensive evaluation causes ambiguous conclusions and hinders the development of this field. To address this problem, this paper builds a benchmark with unified comparison. Seven medical datasets with five image modalities, including chest X-rays, brain MRIs, retinal fundus images, dermatoscopic images, and histopathology images, are curated for extensive evaluation. Thirty typical AD methods, including reconstruction and self-supervised learning-based methods, are involved in comparison of image-level anomaly classification and pixel-level anomaly segmentation. Furthermore, for the first time, we systematically investigate the effect of key components in existing methods, revealing unresolved challenges and potential future directions. The datasets and code are available at <a target="_blank" rel="noopener" href="https://github.com/caiyu6666/MedIAnomaly">https://github.com/caiyu6666/MedIAnomaly</a>. </p>
<blockquote>
<p>å¼‚å¸¸æ£€æµ‹ï¼ˆADï¼‰æ—¨åœ¨æ£€æµ‹åç¦»é¢„æœŸæ­£å¸¸æ¨¡å¼çš„å¼‚å¸¸æ ·æœ¬ã€‚é€šå¸¸ï¼Œå®ƒä»…èƒ½åœ¨æ­£å¸¸æ•°æ®ä¸Šè¿›è¡Œè®­ç»ƒï¼Œæ— éœ€å¼‚å¸¸æ ·æœ¬ï¼Œå› æ­¤åœ¨åŒ»å­¦é¢†åŸŸçš„ç½•è§ç–¾ç—…è¯†åˆ«å’Œå¥åº·ç­›æŸ¥ä¸­å‘æŒ¥ç€é‡è¦ä½œç”¨ã€‚å°½ç®¡å‡ºç°äº†è®¸å¤šåŒ»å­¦å¼‚å¸¸æ£€æµ‹æ–¹æ³•ï¼Œä½†ç”±äºç¼ºä¹å…¬å¹³å’Œå…¨é¢çš„è¯„ä¼°ï¼Œå¯¼è‡´ç»“è®ºæ¨¡ç³Šå¹¶é˜»ç¢äº†è¯¥é¢†åŸŸçš„å‘å±•ã€‚é’ˆå¯¹è¿™ä¸€é—®é¢˜ï¼Œæœ¬æ–‡å»ºç«‹äº†ä¸€ä¸ªç»Ÿä¸€çš„æ¯”è¾ƒåŸºå‡†ã€‚ä¸ºè¿›è¡Œå¹¿æ³›è¯„ä¼°ï¼Œæ•´ç†äº†ä¸ƒä¸ªåŒ»å­¦æ•°æ®é›†ï¼ŒåŒ…å«äº”ç§å›¾åƒæ¨¡æ€ï¼ŒåŒ…æ‹¬èƒ¸éƒ¨Xå°„çº¿ã€è„‘éƒ¨MRIã€çœ¼åº•è§†ç½‘è†œå›¾åƒã€çš®è‚¤é•œå›¾åƒå’Œç—…ç†å›¾åƒã€‚ä¸‰åç§å…¸å‹çš„å¼‚å¸¸æ£€æµ‹æ–¹æ³•ï¼ŒåŒ…æ‹¬é‡å»ºå’ŒåŸºäºè‡ªç›‘ç£å­¦ä¹ çš„æ–¹æ³•ï¼Œéƒ½å‚ä¸äº†å›¾åƒçº§å¼‚å¸¸åˆ†ç±»å’Œåƒç´ çº§å¼‚å¸¸åˆ†å‰²çš„æ¯”è¾ƒã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬é¦–æ¬¡ç³»ç»Ÿåœ°ç ”ç©¶äº†ç°æœ‰æ–¹æ³•ä¸­çš„å…³é”®ç»„ä»¶çš„å½±å“ï¼Œæ­ç¤ºäº†æœªè§£å†³çš„æŒ‘æˆ˜å’Œæ½œåœ¨çš„æœªæ¥æ–¹å‘ã€‚æ•°æ®é›†å’Œä»£ç å¯é€šè¿‡ä»¥ä¸‹é“¾æ¥è·å–ï¼š&lt;<a target="_blank" rel="noopener" href="https://github.com/caiyu666">https://github.com/caiyu666</a> æ‚¨çš„æ–‡æœ¬ç¿»è¯‘å®Œæ¯•ã€‚è¯·ç»§ç»­æé—®ä»¥è·å–æ›´å¤šå¸®åŠ©ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2404.04518v4">PDF</a> Accepted to Medical Image Analysis, 2025</p>
<p><strong>Summary</strong><br>åŒ»å­¦å¼‚å¸¸æ£€æµ‹ï¼ˆADï¼‰å¯¹äºæ£€æµ‹åç¦»é¢„æœŸæ­£å¸¸æ¨¡å¼çš„å¼‚å¸¸æ ·æœ¬è‡³å…³é‡è¦ã€‚æœ¬æ–‡å»ºç«‹äº†ä¸€ä¸ªç»Ÿä¸€çš„åŸºå‡†æµ‹è¯•ï¼ŒåŒ…å«ä¸ƒä¸ªåŒ»å­¦æ•°æ®é›†å’Œäº”ç§å›¾åƒæ¨¡æ€ï¼Œç”¨äºå…¨é¢è¯„ä¼°å¼‚å¸¸æ£€æµ‹æ–¹æ³•ã€‚æ¶‰åŠå›¾åƒçº§åˆ«çš„å¼‚å¸¸åˆ†ç±»å’Œåƒç´ çº§åˆ«çš„å¼‚å¸¸åˆ†å‰²çš„ä¸‰åç§å…¸å‹ADæ–¹æ³•è¢«è¿›è¡Œæ¯”è¾ƒã€‚æ­¤å¤–ï¼Œæœ¬æ–‡é¦–æ¬¡ç³»ç»Ÿåœ°æ¢è®¨äº†ç°æœ‰æ–¹æ³•ä¸­çš„å…³é”®ç»„æˆéƒ¨åˆ†ï¼Œæ­ç¤ºäº†æœªè§£å†³çš„æŒ‘æˆ˜å’Œæ½œåœ¨çš„æœªæ¥æ–¹å‘ã€‚æ•°æ®é›†å’Œä»£ç å¯åœ¨GitHubä¸Šè·å–ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¼‚å¸¸æ£€æµ‹ï¼ˆADï¼‰åœ¨åŒ»å­¦é¢†åŸŸå¯¹äºè¯†åˆ«ç½•è§ç–¾ç—…å’Œå¥åº·ç­›æŸ¥å…·æœ‰é‡è¦æ„ä¹‰ï¼Œèƒ½å¤Ÿæ£€æµ‹åç¦»é¢„æœŸæ­£å¸¸æ¨¡å¼çš„å¼‚å¸¸æ ·æœ¬ã€‚</li>
<li>æ–‡ç« å»ºç«‹äº†ä¸€ä¸ªç»Ÿä¸€çš„åŸºå‡†æµ‹è¯•ï¼ŒåŒ…å«ä¸ƒä¸ªåŒ»å­¦æ•°æ®é›†å’Œäº”ç§å›¾åƒæ¨¡æ€ï¼Œä¸ºè§£å†³åŒ»å­¦ADé¢†åŸŸç¼ºä¹å…¬å¹³ã€å…¨é¢çš„è¯„ä¼°æä¾›äº†æ–¹æ¡ˆã€‚</li>
<li>æ¶‰åŠå›¾åƒçº§åˆ«çš„å¼‚å¸¸åˆ†ç±»å’Œåƒç´ çº§åˆ«çš„å¼‚å¸¸åˆ†å‰²çš„ä¸‰åç§å…¸å‹ADæ–¹æ³•è¢«æ¯”è¾ƒå’Œè¯„ä¼°ã€‚</li>
<li>æ–‡ç« é¦–æ¬¡ç³»ç»Ÿåœ°æ¢è®¨äº†ç°æœ‰ADæ–¹æ³•ä¸­çš„å…³é”®ç»„æˆéƒ¨åˆ†ï¼Œåˆ†æå„æ–¹æ³•çš„ä¼˜åŠ¿å’ŒåŠ£åŠ¿ã€‚</li>
<li>æ–‡ç« æ­ç¤ºäº†åŒ»å­¦ADé¢†åŸŸå­˜åœ¨çš„æœªè§£å†³æŒ‘æˆ˜å’Œæ½œåœ¨æœªæ¥æ–¹å‘ï¼Œä¸ºç ”ç©¶è€…æä¾›äº†æ–¹å‘æŒ‡å¼•ã€‚</li>
<li>æ•°æ®é›†å’Œä»£ç å·²å…¬å¼€ï¼Œä¾¿äºå…¶ä»–ç ”ç©¶è€…ä½¿ç”¨å’Œæ”¹è¿›ã€‚</li>
<li>è¯¥ç ”ç©¶ä¸ºåŒ»å­¦å¼‚å¸¸æ£€æµ‹çš„è¿›ä¸€æ­¥å‘å±•å¥ å®šäº†åŸºç¡€ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2404.04518">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-86b7035ec75457573e210d051731f85f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-7a67476137f268c4786ae862f8b48361.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-7fe445d8de1f208b1d0f28fbf997279e.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-deaccb322f740aef11c46f4bc08f54f1.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-4c32cf16e8fe551268bf4785007c7b89.jpg" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1><h2 id="E2ENet-Dynamic-Sparse-Feature-Fusion-for-Accurate-and-Efficient-3D-Medical-Image-Segmentation"><a href="#E2ENet-Dynamic-Sparse-Feature-Fusion-for-Accurate-and-Efficient-3D-Medical-Image-Segmentation" class="headerlink" title="E2ENet: Dynamic Sparse Feature Fusion for Accurate and Efficient 3D   Medical Image Segmentation"></a>E2ENet: Dynamic Sparse Feature Fusion for Accurate and Efficient 3D   Medical Image Segmentation</h2><p><strong>Authors:Boqian Wu, Qiao Xiao, Shiwei Liu, Lu Yin, Mykola Pechenizkiy, Decebal Constantin Mocanu, Maurice Van Keulen, Elena Mocanu</strong></p>
<p>Deep neural networks have evolved as the leading approach in 3D medical image segmentation due to their outstanding performance. However, the ever-increasing model size and computation cost of deep neural networks have become the primary barrier to deploying them on real-world resource-limited hardware. In pursuit of improving performance and efficiency, we propose a 3D medical image segmentation model, named Efficient to Efficient Network (E2ENet), incorporating two parametrically and computationally efficient designs. i. Dynamic sparse feature fusion (DSFF) mechanism: it adaptively learns to fuse informative multi-scale features while reducing redundancy. ii. Restricted depth-shift in 3D convolution: it leverages the 3D spatial information while keeping the model and computational complexity as 2D-based methods. We conduct extensive experiments on BTCV, AMOS-CT and Brain Tumor Segmentation Challenge, demonstrating that E2ENet consistently achieves a superior trade-off between accuracy and efficiency than prior arts across various resource constraints. E2ENet achieves comparable accuracy on the large-scale challenge AMOS-CT, while saving over 68% parameter count and 29% FLOPs in the inference phase, compared with the previous best-performing method. Our code has been made available at: <a target="_blank" rel="noopener" href="https://github.com/boqian333/E2ENet-Medical">https://github.com/boqian333/E2ENet-Medical</a>. </p>
<blockquote>
<p>æ·±åº¦ç¥ç»ç½‘ç»œå› å…¶å“è¶Šæ€§èƒ½è€Œé€æ¸æ¼”å˜ä¸º3DåŒ»å­¦å›¾åƒåˆ†å‰²é¢†åŸŸçš„ä¸»è¦æ–¹æ³•ã€‚ç„¶è€Œï¼Œæ·±åº¦ç¥ç»ç½‘ç»œä¸æ–­å¢é•¿çš„æ¨¡å‹å¤§å°å’Œè®¡ç®—æˆæœ¬å·²æˆä¸ºå°†å…¶éƒ¨ç½²åœ¨ç°å®ä¸–ç•Œèµ„æºå—é™çš„ç¡¬ä»¶ä¸Šçš„ä¸»è¦éšœç¢ã€‚ä¸ºäº†æå‡æ€§èƒ½å’Œæ•ˆç‡ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åä¸ºEfficient to Efficient Network (E2ENet)çš„3DåŒ»å­¦å›¾åƒåˆ†å‰²æ¨¡å‹ï¼Œå®ƒèåˆäº†ä¸¤ç§å‚æ•°å’Œè®¡ç®—æ•ˆç‡é«˜çš„è®¾è®¡ã€‚ä¸€æ˜¯åŠ¨æ€ç¨€ç–ç‰¹å¾èåˆï¼ˆDSFFï¼‰æœºåˆ¶ï¼šå®ƒè‡ªé€‚åº”åœ°å­¦ä¹ èåˆä¿¡æ¯ä¸°å¯Œçš„å¤šå°ºåº¦ç‰¹å¾ï¼ŒåŒæ—¶å‡å°‘å†—ä½™ã€‚äºŒæ˜¯3Då·ç§¯ä¸­çš„å—é™æ·±åº¦ç§»ä½ï¼šå®ƒåœ¨åˆ©ç”¨3Dç©ºé—´ä¿¡æ¯çš„åŒæ—¶ï¼Œä¿æŒæ¨¡å‹ä¸è®¡ç®—å¤æ‚åº¦ç±»ä¼¼äºåŸºäºäºŒç»´çš„æ–¹æ³•ã€‚æˆ‘ä»¬åœ¨BTCVã€AMOS-CTå’Œè„‘è‚¿ç˜¤åˆ†å‰²æŒ‘æˆ˜ç­‰æ•°æ®é›†ä¸Šè¿›è¡Œäº†å¤§é‡å®éªŒï¼Œè¯æ˜E2ENetåœ¨å„ç§èµ„æºé™åˆ¶ä¸‹å§‹ç»ˆåœ¨ç²¾åº¦å’Œæ•ˆç‡ä¹‹é—´è¾¾åˆ°ä¼˜äºå…ˆå‰æŠ€æœ¯çš„æƒè¡¡ã€‚åœ¨å¤§å‹æŒ‘æˆ˜AMOS-CTä¸Šï¼ŒE2ENetçš„å‡†ç¡®åº¦ä¸ä¹‹å‰çš„æœ€ä½³æ–¹æ³•ç›¸å½“ï¼ŒåŒæ—¶åœ¨æ¨ç†é˜¶æ®µèŠ‚çœäº†è¶…è¿‡68%çš„å‚æ•°è®¡æ•°å’Œ29%çš„æµ®ç‚¹è¿ç®—æ¬¡æ•°ã€‚æˆ‘ä»¬çš„ä»£ç å·²åœ¨ä»¥ä¸‹ç½‘å€å…¬å¼€ï¼š<a target="_blank" rel="noopener" href="https://github.com/boqian333/E2ENet-Medical%E3%80%82">https://github.com/boqian333/E2ENet-Medicalã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2312.04727v2">PDF</a> Accepted at NeurIPS 2024</p>
<p><strong>Summary</strong><br>     é«˜æ•ˆç¥ç»ç½‘ç»œï¼ˆEfficient to Efficient Networkï¼ŒE2ENetï¼‰åœ¨åŒ»å­¦å›¾åƒä¸‰ç»´åˆ†å‰²é¢†åŸŸè¡¨ç°å‡ºå“è¶Šæ€§èƒ½ï¼Œé‡‡ç”¨åŠ¨æ€ç¨€ç–ç‰¹å¾èåˆå’Œå—é™æ·±åº¦ä½ç§»è®¾è®¡ä»¥æé«˜æ•ˆç‡å’Œå‡†ç¡®æ€§ã€‚è¯¥æ¨¡å‹åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šå®ç°ä¼˜å¼‚æ€§èƒ½ï¼Œå‡å°‘å‚æ•°æ•°é‡å’Œè®¡ç®—é‡ï¼Œç›¸è¾ƒäºå…ˆå‰æŠ€æœ¯å…·æœ‰æ›´ä½³çš„å‡†ç¡®æ€§å’Œæ•ˆç‡æƒè¡¡ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æ·±åº¦ç¥ç»ç½‘ç»œåœ¨åŒ»å­¦å›¾åƒä¸‰ç»´åˆ†å‰²é¢†åŸŸå æ®é¢†å…ˆåœ°ä½ï¼Œä½†æ¨¡å‹ä½“ç§¯å’Œè®¡ç®—æˆæœ¬æ—¥ç›Šå¢åŠ ï¼Œæˆä¸ºèµ„æºå—é™ç¡¬ä»¶ä¸Šéƒ¨ç½²çš„éšœç¢ã€‚</li>
<li>æå‡ºåä¸ºEfficient to Efficient Network (E2ENet)çš„åŒ»å­¦å›¾åƒä¸‰ç»´åˆ†å‰²æ¨¡å‹ï¼Œæ—¨åœ¨æé«˜æ€§èƒ½å’Œæ•ˆç‡ã€‚</li>
<li>E2ENeté‡‡ç”¨åŠ¨æ€ç¨€ç–ç‰¹å¾èåˆï¼ˆDSFFï¼‰æœºåˆ¶ï¼Œå¯è‡ªé€‚åº”åœ°èåˆä¿¡æ¯å¤šå°ºåº¦ç‰¹å¾å¹¶å‡å°‘å†—ä½™ã€‚</li>
<li>E2ENetå¼•å…¥å—é™æ·±åº¦ä½ç§»çš„3Då·ç§¯ï¼Œåˆ©ç”¨3Dç©ºé—´ä¿¡æ¯åŒæ—¶ä¿æŒæ¨¡å‹åŠè®¡ç®—å¤æ‚åº¦ç±»ä¼¼äº2Dæ–¹æ³•ã€‚</li>
<li>å¹¿æ³›å®éªŒè¡¨æ˜ï¼ŒE2ENetåœ¨å„ç§èµ„æºçº¦æŸä¸‹è¾ƒå…ˆå‰æŠ€æœ¯å®ç°äº†æ›´é«˜çš„å‡†ç¡®æ€§å’Œæ•ˆç‡ä¹‹é—´çš„å¹³è¡¡ã€‚</li>
<li>åœ¨å¤§è§„æ¨¡æŒ‘æˆ˜AMOS-CTä¸Šï¼ŒE2ENetå®ç°äº†ä¸æœ€ä½³è¡¨ç°æ–¹æ³•ç›¸å½“çš„å‡†ç¡®åº¦ï¼ŒåŒæ—¶åœ¨æ¨ç†é˜¶æ®µèŠ‚çœäº†è¶…è¿‡68%çš„å‚æ•°è®¡æ•°å’Œ29%çš„FLOPsã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2312.04727">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-8d999c5e6af3f87ab67b8a808fccb1c3.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-567b9787ed58c386b16789a35384473b.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-c08653bb4134ec3360d46487843f958e.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-72fb9a32c0b3dd7dcc13d5128acbda0c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-dc7f5a85a37c6456a0323059b9394121.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-9bf08072c5e593c34766c9810dcdd1f2.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-3702b3c0f5935ec0f8b6ba1577348917.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f9f5911f7ff3f63bb61d925eaf4d274d.jpg" align="middle">
</details>


<h1 id="-9"><a href="#-9" class="headerlink" title=""></a></h1><h2 id="On-undesired-emergent-behaviors-in-compound-prostate-cancer-detection-systems"><a href="#On-undesired-emergent-behaviors-in-compound-prostate-cancer-detection-systems" class="headerlink" title="On undesired emergent behaviors in compound prostate cancer detection   systems"></a>On undesired emergent behaviors in compound prostate cancer detection   systems</h2><p><strong>Authors:Erlend Sortland Rolfsnes, Philip Thangngat, Trygve EftestÃ¸l, Tobias NordstrÃ¶m, Fredrik JÃ¤derling, Martin Eklund, Alvaro Fernandez-Quilez</strong></p>
<p>Artificial intelligence systems show promise to aid in the di- agnostic pathway of prostate cancer (PC), by supporting radiologists in interpreting magnetic resonance images (MRI) of the prostate. Most MRI-based systems are designed to detect clinically significant PC le- sions, with the main objective of preventing over-diagnosis. Typically, these systems involve an automatic prostate segmentation component and a clinically significant PC lesion detection component. In spite of the compound nature of the systems, evaluations are presented assum- ing a standalone clinically significant PC detection component. That is, they are evaluated in an idealized scenario and under the assumption that a highly accurate prostate segmentation is available at test time. In this work, we aim to evaluate a clinically significant PC lesion de- tection system accounting for its compound nature. For that purpose, we simulate a realistic deployment scenario and evaluate the effect of two non-ideal and previously validated prostate segmentation modules on the PC detection ability of the compound system. Following, we com- pare them with an idealized setting, where prostate segmentations are assumed to have no faults. We observe significant differences in the de- tection ability of the compound system in a realistic scenario and in the presence of the highest-performing prostate segmentation module (DSC: 90.07+-0.74), when compared to the idealized one (AUC: 77.93 +- 3.06 and 84.30+- 4.07, P&lt;.001). Our results depict the relevance of holistic evalu- ations for PC detection compound systems, where interactions between system components can lead to decreased performance and degradation at deployment time. </p>
<blockquote>
<p>äººå·¥æ™ºèƒ½ç³»ç»Ÿåœ¨å‰åˆ—è…ºç™Œï¼ˆPCï¼‰è¯Šæ–­è·¯å¾„ä¸­æ˜¾ç¤ºå‡ºå·¨å¤§æ½œåŠ›ï¼Œæ”¯æŒæ”¾å°„ç§‘åŒ»ç”Ÿè§£é‡Šå‰åˆ—è…ºçš„ç£å…±æŒ¯å›¾åƒï¼ˆMRIï¼‰ã€‚å¤§å¤šæ•°åŸºäºMRIçš„ç³»ç»Ÿæ—¨åœ¨æ£€æµ‹ä¸´åºŠé‡è¦çš„PCç—…å˜ï¼Œä¸»è¦ç›®çš„æ˜¯é˜²æ­¢è¿‡åº¦è¯Šæ–­ã€‚è¿™äº›ç³»ç»Ÿé€šå¸¸åŒ…æ‹¬ä¸€ä¸ªè‡ªåŠ¨å‰åˆ—è…ºåˆ†å‰²ç»„ä»¶å’Œä¸€ä¸ªä¸´åºŠé‡è¦çš„PCç—…å˜æ£€æµ‹ç»„ä»¶ã€‚å°½ç®¡è¿™äº›ç³»ç»Ÿçš„å¤åˆæ€§è´¨ï¼Œä½†è¯„ä¼°æ˜¯åŸºäºä¸€ä¸ªç‹¬ç«‹çš„ä¸´åºŠé‡è¦PCæ£€æµ‹ç»„ä»¶è¿›è¡Œçš„ã€‚ä¹Ÿå°±æ˜¯è¯´ï¼Œå®ƒä»¬åœ¨ç†æƒ³åŒ–çš„åœºæ™¯ä¸­è¿›è¡Œäº†è¯„ä¼°ï¼Œå¹¶å‡è®¾æµ‹è¯•æ—¶å­˜åœ¨é«˜åº¦å‡†ç¡®çš„å‰åˆ—è…ºåˆ†å‰²ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬æ—¨åœ¨è¯„ä¼°ä¸´åºŠé‡è¦çš„PCç—…å˜æ£€æµ‹ç³»ç»Ÿï¼Œå¹¶è€ƒè™‘åˆ°å…¶å¤åˆæ€§è´¨ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬æ¨¡æ‹Ÿäº†ä¸€ä¸ªç°å®éƒ¨ç½²åœºæ™¯ï¼Œå¹¶è¯„ä¼°äº†ä¸¤ä¸ªç»è¿‡éªŒè¯çš„éç†æƒ³å‰åˆ—è…ºåˆ†å‰²æ¨¡å—å¯¹å¤åˆç³»ç»Ÿæ£€æµ‹PCèƒ½åŠ›çš„å½±å“ã€‚ä¹‹åï¼Œæˆ‘ä»¬å°†å®ƒä»¬ä¸ç†æƒ³åŒ–è®¾ç½®è¿›è¡Œæ¯”è¾ƒï¼Œå…¶ä¸­å‡è®¾å‰åˆ—è…ºåˆ†æ®µæ²¡æœ‰æ•…éšœã€‚æˆ‘ä»¬è§‚å¯Ÿåˆ°ï¼Œåœ¨ç°å®åœºæ™¯ä¸­ä»¥åŠåœ¨æœ€é«˜æ€§èƒ½çš„å‰åˆ—è…ºåˆ†å‰²æ¨¡å—ï¼ˆDSCï¼š90.07Â±0.74ï¼‰çš„å­˜åœ¨ä¸‹ï¼Œå¤åˆç³»ç»Ÿçš„æ£€æµ‹èƒ½åŠ›ä¸ç†æƒ³æƒ…å†µä¸‹çš„æ£€æµ‹èƒ½åŠ›ç›¸æ¯”å­˜åœ¨æ˜¾è‘—å·®å¼‚ï¼ˆAUCï¼š77.93Â±3.06å’Œ84.30Â±4.07ï¼ŒP&lt;.001ï¼‰ã€‚æˆ‘ä»¬çš„ç»“æœæç»˜äº†å…¨é¢è¯„ä¼°PCæ£€æµ‹å¤åˆç³»ç»Ÿçš„é‡è¦æ€§ï¼Œç³»ç»Ÿç»„ä»¶ä¹‹é—´çš„ç›¸äº’ä½œç”¨å¯èƒ½å¯¼è‡´æ€§èƒ½ä¸‹é™å¹¶åœ¨éƒ¨ç½²æ—¶å‘ç”Ÿé€€åŒ–ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08381v2">PDF</a> Accepted in MICCAI 2025, CapTiON</p>
<p><strong>æ‘˜è¦</strong><br>     äººå·¥æ™ºèƒ½ç³»ç»Ÿæœ‰æœ›è¾…åŠ©å‰åˆ—è…ºç™Œçš„è¯Šæ–­è¿‡ç¨‹ï¼Œé€šè¿‡æ”¯æŒæ”¾å°„ç§‘åŒ»ç”Ÿè§£è¯»å‰åˆ—è…ºç£å…±æŒ¯æˆåƒã€‚å¤šæ•°åŸºäºMRIçš„ç³»ç»Ÿæ—¨åœ¨æ£€æµ‹å…·æœ‰ä¸´åºŠæ„ä¹‰çš„å‰åˆ—è…ºç—…ç¶ï¼Œä¸»è¦ç›®çš„æ˜¯é˜²æ­¢è¿‡åº¦è¯Šæ–­ã€‚è¿™äº›ç³»ç»Ÿé€šå¸¸åŒ…æ‹¬è‡ªåŠ¨å‰åˆ—è…ºåˆ†å‰²ç»„ä»¶å’Œæ£€æµ‹å…·æœ‰ä¸´åºŠæ„ä¹‰çš„å‰åˆ—è…ºç—…ç¶ç»„ä»¶ã€‚å°½ç®¡è¿™äº›ç³»ç»Ÿçš„å¤åˆæ€§è´¨ï¼Œä½†è¯„ä¼°æ˜¯åœ¨å‡è®¾ä¸€ä¸ªç‹¬ç«‹çš„å‰åˆ—è…ºç™Œæ£€æµ‹ç»„ä»¶çš„æƒ…å†µä¸‹è¿›è¡Œçš„ã€‚ä¹Ÿå°±æ˜¯è¯´ï¼Œå®ƒä»¬åœ¨ç†æƒ³åŒ–çš„åœºæ™¯å’Œå‡è®¾é«˜åº¦å‡†ç¡®çš„å‰åˆ—è…ºåˆ†å‰²åœ¨æµ‹è¯•æ—¶å¯ç”¨çš„æƒ…å†µä¸‹è¿›è¡Œè¯„ä¼°ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬æ—¨åœ¨è¯„ä¼°ä¸€ä¸ªè€ƒè™‘åˆ°å…¶å¤åˆæ€§è´¨çš„å‰åˆ—è…ºç™Œæ£€æµ‹ç³»ç»Ÿã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬æ¨¡æ‹Ÿäº†ä¸€ä¸ªçœŸå®çš„éƒ¨ç½²åœºæ™¯ï¼Œå¹¶è¯„ä¼°äº†ä¸¤ä¸ªå…ˆå‰éªŒè¯çš„éç†æƒ³å‰åˆ—è…ºåˆ†å‰²æ¨¡å—å¯¹å¤åˆç³»ç»Ÿæ£€æµ‹å‰åˆ—è…ºç™Œèƒ½åŠ›çš„å½±å“ã€‚ä¹‹åï¼Œæˆ‘ä»¬å°†å®ƒä»¬ä¸ç†æƒ³åŒ–çš„è®¾ç½®è¿›è¡Œæ¯”è¾ƒï¼Œå…¶ä¸­å‡è®¾å‰åˆ—è…ºåˆ†æ®µæ²¡æœ‰æ•…éšœã€‚æˆ‘ä»¬è§‚å¯Ÿåˆ°å¤åˆç³»ç»Ÿåœ¨ç°å®åœºæ™¯ä¸­çš„æ£€æµ‹èƒ½åŠ›ä¸è¡¨ç°æœ€ä½³çš„å‰åˆ—è…ºåˆ†å‰²æ¨¡å—å­˜åœ¨æ˜¾è‘—å·®å¼‚ï¼ˆDSCï¼š90.07Â±0.74ï¼‰ï¼Œä¸ç†æƒ³åŒ–æƒ…å†µç›¸æ¯”ï¼ˆAUCï¼š77.93Â±3.06å’Œ84.30Â±4.07ï¼ŒP&lt;.001ï¼‰ã€‚æˆ‘ä»¬çš„ç»“æœè¡¨æ˜ï¼Œå¯¹å‰åˆ—è…ºç™Œæ£€æµ‹å¤åˆç³»ç»Ÿè¿›è¡Œæ•´ä½“è¯„ä¼°å…·æœ‰é‡è¦æ„ä¹‰ï¼Œç³»ç»Ÿç»„ä»¶ä¹‹é—´çš„ç›¸äº’ä½œç”¨å¯èƒ½å¯¼è‡´æ€§èƒ½ä¸‹é™å’Œéƒ¨ç½²æ—¶çš„é€€åŒ–ã€‚ </p>
<p> <strong>å…³é”®è§è§£</strong></p>
<ol>
<li>äººå·¥æ™ºèƒ½ç³»ç»Ÿåœ¨è§£è¯»å‰åˆ—è…ºç£å…±æŒ¯æˆåƒæ–¹é¢è¡¨ç°å‡ºè¾…åŠ©è¯Šæ–­å‰åˆ—è…ºç™Œçš„æ½œåŠ›ã€‚</li>
<li>åŸºäºMRIçš„ç³»ç»Ÿä¸»è¦ç›®æ ‡æ˜¯æ£€æµ‹å…·æœ‰ä¸´åºŠæ„ä¹‰çš„å‰åˆ—è…ºç—…ç¶ï¼Œæ—¨åœ¨é¿å…è¿‡åº¦è¯Šæ–­ã€‚</li>
<li>è¿™äº›ç³»ç»ŸåŒ…æ‹¬è‡ªåŠ¨å‰åˆ—è…ºåˆ†å‰²å’Œæ£€æµ‹ç»„ä»¶ï¼Œä½†ä¹‹å‰çš„è¯„ä¼°å¤§å¤šå‡è®¾äº†ç‹¬ç«‹çš„å‰åˆ—è…ºç™Œæ£€æµ‹ç»„ä»¶ã€‚</li>
<li>åœ¨æ¨¡æ‹Ÿçš„å®é™…éƒ¨ç½²åœºæ™¯ä¸­è¯„ä¼°äº†å¤åˆç³»ç»Ÿçš„å‰åˆ—è…ºç™Œæ£€æµ‹èƒ½åŠ›ï¼Œè€ƒè™‘äº†éç†æƒ³çš„å‰åˆ—è…ºåˆ†å‰²æ¨¡å—çš„å½±å“ã€‚</li>
<li>ä¸ç†æƒ³åŒ–è®¾ç½®ç›¸æ¯”ï¼Œç°å®åœºæ™¯ä¸­çš„ç³»ç»Ÿæ£€æµ‹æ€§èƒ½å­˜åœ¨æ˜¾è‘—å·®å¼‚ã€‚</li>
<li>æœ€å¥½çš„å‰åˆ—è…ºåˆ†å‰²æ¨¡å—å¯¹å¤åˆç³»ç»Ÿçš„æ£€æµ‹èƒ½åŠ›æœ‰æ˜¾è‘—å½±å“ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2309.08381">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-684acd64eae009a0135f5fdf2cbdbc02.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-155e1a1a2184c91b1c1d3ad8c159d84f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-fb9f1d2738fcdc32e71b6db19148331c.jpg" align="middle">
</details>


<h1 id="-10"><a href="#-10" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-02-21/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/">https://kedreamix.github.io/Talk2Paper/Paper/2025-02-21/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/">
                                    <span class="chip bg-color">åŒ»å­¦å›¾åƒ</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-02-21/TTS/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-51ac9d309d1f16be825a0b4c92719973.jpg" class="responsive-img" alt="TTS">
                        
                        <span class="card-title">TTS</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            TTS æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-02-21  A Survey on Bridging EEG Signals and Generative AI From Image and Text   to Beyond
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-02-21
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/TTS/" class="post-category">
                                    TTS
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/TTS/">
                        <span class="chip bg-color">TTS</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-02-21/Diffusion%20Models/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-a79161c4df0531e7c72cec0b3bfecb1f.jpg" class="responsive-img" alt="Diffusion Models">
                        
                        <span class="card-title">Diffusion Models</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Diffusion Models æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-02-21  Secure and Efficient Watermarking for Latent Diffusion Models in Model   Distribution Scenarios
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-02-21
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Diffusion-Models/" class="post-category">
                                    Diffusion Models
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Diffusion-Models/">
                        <span class="chip bg-color">Diffusion Models</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">11676k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
