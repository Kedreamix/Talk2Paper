<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Diffusion Models">
    <meta name="description" content="Diffusion Models æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2024-05-28  DiffCalib Reformulating Monocular Camera Calibration as Diffusion-Based   Dense Incident Map Generation">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>Diffusion Models | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


<body>
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://pic1.zhimg.com/v2-36a0effe69414b2ffa084f4cd6a69d06.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Diffusion Models</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/Diffusion-Models/">
                                <span class="chip bg-color">Diffusion Models</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/Diffusion-Models/" class="post-category">
                                Diffusion Models
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2024-05-28
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2024-12-10
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    6.2k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    25 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº Googleçš„å¤§è¯­è¨€æ¨¡å‹<a target="_blank" rel="noopener" href="https://ai.google.dev/">Gemini-Pro</a>çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2024-05-28-æ›´æ–°"><a href="#2024-05-28-æ›´æ–°" class="headerlink" title="2024-05-28 æ›´æ–°"></a>2024-05-28 æ›´æ–°</h1><h2 id="DiffCalib-Reformulating-Monocular-Camera-Calibration-as-Diffusion-Based-Dense-Incident-Map-Generation"><a href="#DiffCalib-Reformulating-Monocular-Camera-Calibration-as-Diffusion-Based-Dense-Incident-Map-Generation" class="headerlink" title="DiffCalib: Reformulating Monocular Camera Calibration as Diffusion-Based   Dense Incident Map Generation"></a>DiffCalib: Reformulating Monocular Camera Calibration as Diffusion-Based   Dense Incident Map Generation</h2><p><strong>Authors:Xiankang He, Guangkai Xu, Bo Zhang, Hao Chen, Ying Cui, Dongyan Guo</strong></p>
<p>Monocular camera calibration is a key precondition for numerous 3D vision applications. Despite considerable advancements, existing methods often hinge on specific assumptions and struggle to generalize across varied real-world scenarios, and the performance is limited by insufficient training data. Recently, diffusion models trained on expansive datasets have been confirmed to maintain the capability to generate diverse, high-quality images. This success suggests a strong potential of the models to effectively understand varied visual information. In this work, we leverage the comprehensive visual knowledge embedded in pre-trained diffusion models to enable more robust and accurate monocular camera intrinsic estimation. Specifically, we reformulate the problem of estimating the four degrees of freedom (4-DoF) of camera intrinsic parameters as a dense incident map generation task. The map details the angle of incidence for each pixel in the RGB image, and its format aligns well with the paradigm of diffusion models. The camera intrinsic then can be derived from the incident map with a simple non-learning RANSAC algorithm during inference. Moreover, to further enhance the performance, we jointly estimate a depth map to provide extra geometric information for the incident map estimation. Extensive experiments on multiple testing datasets demonstrate that our model achieves state-of-the-art performance, gaining up to a 40% reduction in prediction errors. Besides, the experiments also show that the precise camera intrinsic and depth maps estimated by our pipeline can greatly benefit practical applications such as 3D reconstruction from a single in-the-wild image. </p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2405.15619v1">PDF</a> </p>
<p><strong>Summary</strong><br>å•ç›®ç›¸æœºæ ¡å‡†æ˜¯ä¼—å¤š3Dè§†è§‰åº”ç”¨çš„å…³é”®å…ˆå†³æ¡ä»¶ã€‚æœ€è¿‘ï¼ŒåŸºäºå¤§è§„æ¨¡æ•°æ®é›†è®­ç»ƒçš„æ‰©æ•£æ¨¡å‹è¢«è¯å®èƒ½å¤Ÿç”Ÿæˆå¤šæ ·ä¸”é«˜è´¨é‡çš„å›¾åƒï¼Œä¸ºå•ç›®ç›¸æœºå†…åœ¨ä¼°è®¡æä¾›æ›´å¼ºå¤§å’Œå‡†ç¡®çš„æ”¯æŒã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>å•ç›®ç›¸æœºæ ¡å‡†å¯¹äºå¤šç§3Dè§†è§‰åº”ç”¨è‡³å…³é‡è¦</li>
<li>æ‰©æ•£æ¨¡å‹èƒ½å¤Ÿç”Ÿæˆå¤šæ ·ä¸”é«˜è´¨é‡çš„å›¾åƒ</li>
<li>é€šè¿‡åˆ©ç”¨æ‰©æ•£æ¨¡å‹ä¸­çš„è§†è§‰çŸ¥è¯†ï¼Œèƒ½å¤Ÿå®ç°æ›´ç¨³å¥å’Œå‡†ç¡®çš„å•ç›®ç›¸æœºå†…åœ¨ä¼°è®¡</li>
<li>é€šè¿‡å°†ä¼°è®¡ç›¸æœºå†…åœ¨å‚æ•°çš„é—®é¢˜é‡æ–°æ„å»ºä¸ºå¯†é›†å…¥å°„å›¾ç”Ÿæˆä»»åŠ¡ï¼Œèƒ½å¤Ÿå®ç°æ›´ç®€å•çš„æ¨æ–­è¿‡ç¨‹</li>
<li>è”åˆä¼°è®¡æ·±åº¦å›¾èƒ½å¤Ÿè¿›ä¸€æ­¥æå‡æ€§èƒ½</li>
<li>å®éªŒè¯æ˜è¯¥æ¨¡å‹è¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œé¢„æµ‹è¯¯å·®é™ä½äº†40%</li>
<li>ç²¾ç¡®çš„ç›¸æœºå†…åœ¨å’Œæ·±åº¦å›¾èƒ½å¤Ÿæå¤§åœ°ä¿ƒè¿›ä»å•å¼ é‡å¤–å›¾åƒè¿›è¡Œçš„3Dé‡å»ºç­‰å®é™…åº”ç”¨</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>
<p>Title: DiffCalib: Reformulating Monocular Camera Calibration as Diffusion-Based Dense Incident Map Generation (DiffCalibï¼šå°†å•ç›®æ‘„åƒæœºæ ¡å‡†é‡æ„ä¸ºåŸºäºæ‰©æ•£çš„å¯†é›†å…¥å°„å›¾ç”Ÿæˆ)</p>
</li>
<li>
<p>Authors: Xiankang He, Guangkai Xu, Bo Zhang, Hao Chen, Ying Cui, Dongyan Guo</p>
</li>
<li>
<p>Affiliation: æµ™æ±Ÿå·¥ä¸šå¤§å­¦</p>
</li>
<li>
<p>Keywords: monocular camera calibration, diffusion models, incident map generation</p>
</li>
<li>
<p>Urls: arXiv:2405.15619v1, Github:None</p>
</li>
<li>
<p>Summary:</p>
</li>
<li>
<p>(1):æœ¬æ–‡çš„ç ”ç©¶èƒŒæ™¯æ˜¯å•ç›®æ‘„åƒæœºæ ¡å‡†ï¼Œè¿™æ˜¯è®¸å¤šä¸‰ç»´è§†è§‰åº”ç”¨çš„å…³é”®å‰ææ¡ä»¶ã€‚</p>
</li>
<li>
<p>(2):è¿‡å»çš„æ–¹æ³•å­˜åœ¨ä¸€äº›å‡è®¾å’Œé™åˆ¶ï¼Œæ— æ³•åœ¨ä¸åŒçš„çœŸå®ä¸–ç•Œåœºæ™¯ä¸­æ³›åŒ–ï¼Œå¹¶ä¸”å—é™äºè®­ç»ƒæ•°æ®çš„ä¸è¶³ã€‚æœ€è¿‘ï¼Œæ‰©æ•£æ¨¡å‹åœ¨ç”Ÿæˆé«˜è´¨é‡å›¾åƒæ–¹é¢å–å¾—äº†æˆåŠŸï¼Œè¿™å¯å‘äº†æˆ‘ä»¬ä½¿ç”¨æ‰©æ•£æ¨¡å‹æ¥å®ç°æ›´é²æ£’å’Œå‡†ç¡®çš„å•ç›®æ‘„åƒæœºæ ¡å‡†ã€‚</p>
</li>
<li>
<p>(3):æœ¬æ–‡æå‡ºçš„ç ”ç©¶æ–¹æ³•æ˜¯å°†å•ç›®æ‘„åƒæœºæ ¡å‡†é—®é¢˜é‡æ„ä¸ºåŸºäºæ‰©æ•£çš„å¯†é›†å…¥å°„å›¾ç”Ÿæˆä»»åŠ¡ï¼Œä½¿ç”¨é¢„è®­ç»ƒçš„æ‰©æ•£æ¨¡å‹ç”Ÿæˆå…¥å°„å›¾ï¼Œç„¶åä½¿ç”¨RANSACç®—æ³•æ¨æ–­æ‘„åƒæœºå‚ã€‚</p>
</li>
<li>
<p>(4):æœ¬æ–‡çš„æ–¹æ³•åœ¨å•ç›®æ‘„åƒæœºæ ¡å‡†ä»»åŠ¡ä¸Šå–å¾—äº†å¾ˆå¥½çš„æ€§èƒ½ï¼Œè¯æ˜äº†æ‰©æ•£æ¨¡å‹åœ¨ç†è§£è§†è§‰ä¿¡æ¯æ–¹é¢çš„æ½œåŠ›ï¼Œå¹¶ä¸”å¯ä»¥ç”¨äºåœ¨é‡ä¸‰ç»´é‡å»ºä»»åŠ¡ä¸­ã€‚</p>
</li>
<li>
<p>æ–¹æ³•ï¼š</p>
</li>
<li>
<p>(1)ï¼šå°†å•ç›®æ‘„åƒæœºæ ¡å‡†é—®é¢˜é‡æ„ä¸ºåŸºäºæ‰©æ•£çš„å¯†é›†å…¥å°„å›¾ç”Ÿæˆä»»åŠ¡ï¼Œä»¥ä¾¿èƒ½å¤Ÿåˆ©ç”¨é¢„è®­ç»ƒçš„æ‰©æ•£æ¨¡å‹ç”Ÿæˆå…¥å°„å›¾ã€‚</p>
</li>
<li>
<p>(2)ï¼šä½¿ç”¨Stable Diffusion v2.1æ¨¡å‹å¯¹å…¥å°„å›¾è¿›è¡Œç¼–ç å’Œè§£ç ï¼Œç”Ÿæˆå™ªå£°åçš„å…¥å°„å›¾latent codesï¼Œå¹¶è®­ç»ƒU-Netæ¨¡å‹æ¥é¢„æµ‹å™ªå£°ã€‚</p>
</li>
<li>
<p>(3)ï¼šå°†æ·±åº¦å›¾å’Œå…¥å°„å›¾è”åˆå­¦ä¹ ï¼Œä»¥æé«˜å…¥å°„å›¾ç”Ÿæˆçš„å‡†ç¡®æ€§å’Œé²æ£’æ€§ã€‚</p>
</li>
<li>
<p>(4)ï¼šä½¿ç”¨RANSACç®—æ³•ä»ç”Ÿæˆçš„å…¥å°„å›¾ä¸­æ¢å¤æ‘„åƒæœºçš„å†…å‚æ•°çŸ©é˜µKã€‚</p>
</li>
<li>
<p>(5)ï¼šä½¿ç”¨ensembleæ–¹æ³•æ¥æé«˜å…¥å°„å›¾ç”Ÿæˆçš„å‡†ç¡®æ€§å’Œç¨³å®šæ€§ã€‚</p>
</li>
<li>
<p>(6)ï¼šä½¿ç”¨æ¢å¤çš„æ‘„åƒæœºå†…å‚æ•°çŸ©é˜µKæ¥è¿›è¡Œå•ç›®æ‘„åƒæœºæ ¡å‡†ã€‚</p>
</li>
<li>
<p>Conclusion: </p>
</li>
<li>
<p>(1): è¿™ç¯‡æ–‡ç« çš„æ„ä¹‰åœ¨äºæå‡ºäº†å¯¹äº[é¢†åŸŸ]çš„æ–°æ€è·¯ï¼Œä¸ºè¯¥é¢†åŸŸçš„ç ”ç©¶å’Œå‘å±•å¸¦æ¥äº†æ–°çš„å¯å‘å’Œæ–¹å‘ï¼›</p>
</li>
<li>(2): Innovation point: è¯¥æ–‡ç« çš„åˆ›æ–°ç‚¹åœ¨äºæå‡ºäº†ä¸€ç§å…¨æ–°çš„[åˆ›æ–°ç‚¹]ï¼Œçªç ´äº†ä¼ ç»Ÿçš„[åˆ›æ–°ç‚¹]æ–¹å¼ï¼› Performance: è¯¥æ–‡ç« åœ¨å®éªŒè¡¨ç°æ–¹é¢å±•ç°å‡ºäº†è¾ƒé«˜çš„å‡†ç¡®æ€§å’Œç¨³å®šæ€§ï¼Œä½†ä»æœ‰å¾…è¿›ä¸€æ­¥æå‡ï¼› Workload: è¯¥æ–‡ç« çš„å·¥ä½œé‡è¾ƒå¤§ï¼Œéœ€è¦æ›´å¤šçš„å®éªŒæ•°æ®å’Œåˆ†ææ¥æ”¯æ’‘å…¶ç»“è®ºã€‚</li>
</ol>



<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-02a306a749ab4f7167af1ae9e9bd38f3.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://pic1.zhimg.com/v2-3354b1c0f182b11d7a2fe0d1f53745ed.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-a3bcd389775a3247ad6697fadd1fd9cd.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://pic1.zhimg.com/v2-8a6244aa42d8f424a5319ca260b17f35.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://pic1.zhimg.com/v2-36a0effe69414b2ffa084f4cd6a69d06.jpg" align="middle">
</details>




<h2 id="Defensive-Unlearning-with-Adversarial-Training-for-Robust-Concept-Erasure-in-Diffusion-Models"><a href="#Defensive-Unlearning-with-Adversarial-Training-for-Robust-Concept-Erasure-in-Diffusion-Models" class="headerlink" title="Defensive Unlearning with Adversarial Training for Robust Concept   Erasure in Diffusion Models"></a>Defensive Unlearning with Adversarial Training for Robust Concept   Erasure in Diffusion Models</h2><p><strong>Authors:Yimeng Zhang, Xin Chen, Jinghan Jia, Yihua Zhang, Chongyu Fan, Jiancheng Liu, Mingyi Hong, Ke Ding, Sijia Liu</strong></p>
<p>Diffusion models (DMs) have achieved remarkable success in text-to-image generation, but they also pose safety risks, such as the potential generation of harmful content and copyright violations. The techniques of machine unlearning, also known as concept erasing, have been developed to address these risks. However, these techniques remain vulnerable to adversarial prompt attacks, which can prompt DMs post-unlearning to regenerate undesired images containing concepts (such as nudity) meant to be erased. This work aims to enhance the robustness of concept erasing by integrating the principle of adversarial training (AT) into machine unlearning, resulting in the robust unlearning framework referred to as AdvUnlearn. However, achieving this effectively and efficiently is highly nontrivial. First, we find that a straightforward implementation of AT compromises DMsâ€™ image generation quality post-unlearning. To address this, we develop a utility-retaining regularization on an additional retain set, optimizing the trade-off between concept erasure robustness and model utility in AdvUnlearn. Moreover, we identify the text encoder as a more suitable module for robustification compared to UNet, ensuring unlearning effectiveness. And the acquired text encoder can serve as a plug-and-play robust unlearner for various DM types. Empirically, we perform extensive experiments to demonstrate the robustness advantage of AdvUnlearn across various DM unlearning scenarios, including the erasure of nudity, objects, and style concepts. In addition to robustness, AdvUnlearn also achieves a balanced tradeoff with model utility. To our knowledge, this is the first work to systematically explore robust DM unlearning through AT, setting it apart from existing methods that overlook robustness in concept erasing. Codes are available at: <a target="_blank" rel="noopener" href="https://github.com/OPTML-Group/AdvUnlearn">https://github.com/OPTML-Group/AdvUnlearn</a> </p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2405.15234v1">PDF</a> Codes are available at <a target="_blank" rel="noopener" href="https://github.com/OPTML-Group/AdvUnlearn">https://github.com/OPTML-Group/AdvUnlearn</a></p>
<p><strong>Summary</strong><br>åŸºäºå¯¹æŠ—è®­ç»ƒå¢å¼ºæœºå™¨unlearningï¼Œæå‡ºAdvUnlearnæ¡†æ¶ï¼Œä»¥æé«˜æ¦‚å¿µæ“¦é™¤çš„é²æ£’æ€§ã€‚</p>
<p><strong>Key Takeaways</strong><br>â€¢  Diffusionæ¨¡å‹åœ¨æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆä¸­å–å¾—äº†æ˜¾è‘—æˆåŠŸï¼Œä½†ä¹Ÿå­˜åœ¨å®‰å…¨é£é™©ï¼Œå¦‚ç”Ÿæˆæœ‰å®³å†…å®¹å’Œç‰ˆæƒè¿è§„ã€‚<br>â€¢  æœºå™¨unlearningæŠ€æœ¯å¯ä»¥è§£å†³è¿™äº›é£é™©ï¼Œä½†æ˜“å—åˆ°å¯¹æŠ—promptæ”»å‡»ã€‚<br>â€¢  æœ¬å·¥ä½œæå‡ºAdvUnlearnæ¡†æ¶ï¼Œé€šè¿‡å°†å¯¹æŠ—è®­ç»ƒåŸåˆ™é›†æˆåˆ°æœºå™¨unlearningä¸­ï¼Œä»¥æé«˜æ¦‚å¿µæ“¦é™¤çš„é²æ£’æ€§ã€‚<br>â€¢ AdvUnlearnæ¡†æ¶ä½¿ç”¨utility-retaining regularizationæ¥å¹³è¡¡æ¦‚å¿µæ“¦é™¤é²æ£’æ€§å’Œæ¨¡å‹å®ç”¨æ€§ã€‚<br>â€¢  æ–‡æœ¬ç¼–ç å™¨æ˜¯å®ç°æœºå™¨unlearningçš„æ›´é€‚åˆæ¨¡å—ã€‚<br>â€¢  AdvUnlearnæ¡†æ¶å¯ä»¥åœ¨å„ç§Diffusionæ¨¡å‹unlearningåœºæ™¯ä¸‹å®ç°é²æ£’çš„æ¦‚å¿µæ“¦é™¤ã€‚<br>â€¢  æœ¬å·¥ä½œæ˜¯é¦–æ¬¡ç³»ç»Ÿåœ°æ¢ç´¢é€šè¿‡å¯¹æŠ—è®­ç»ƒå®ç°é²æ£’çš„Diffusionæ¨¡å‹unlearningã€‚</p>
<p><strong><a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>
<p>Title: AdvUnlearn: Robust Unlearning for Diffusion Models (Diffusionæ¨¡å‹çš„é²æ£’unlearning)</p>
</li>
<li>
<p>Authors: (no authors listed)</p>
</li>
<li>
<p>Affiliation: æ— </p>
</li>
<li>
<p>Keywords: Diffusion Models, Machine Unlearning, Adversarial Training, Text-to-Image Generation</p>
</li>
<li>
<p>Urls: https://github.com/OPTML-Group/AdvUnlearn</p>
</li>
<li>
<p>Summary:</p>
<ul>
<li>
<p>(1):éšç€Diffusionæ¨¡å‹åœ¨æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆä»»åŠ¡ä¸­çš„æˆåŠŸï¼Œå®ƒä»¬ä¹Ÿå¸¦æ¥äº†å®‰å…¨é£é™©ï¼Œå¦‚ç”Ÿæˆæœ‰å®³å†…å®¹å’Œç‰ˆæƒè¿åã€‚ä¸ºè§£å†³è¿™äº›é£é™©ï¼Œæœºå™¨unlearningæŠ€æœ¯è¢«å¼€å‘å‡ºæ¥ï¼Œä½†æ˜¯è¿™äº›æŠ€æœ¯ä»æ˜“å—å¯¹æŠ—æ€§promptæ”»å‡»çš„å½±å“ã€‚</p>
</li>
<li>
<p>(2):è¿‡å»çš„æ–¹æ³•ï¼Œå¦‚ScissorHandså’ŒEraseDiffï¼Œè™½ç„¶å¯ä»¥å®ç°é«˜çš„unlearning robustnessï¼Œä½†æ˜¯å®ƒä»¬å›¾åƒç”Ÿæˆè´¨é‡ä¸‹é™æ˜æ˜¾ã€‚è¿™äº›æ–¹æ³•çš„motivationä¸è¶³ï¼Œæ— æ³•è§£å†³æœºå™¨unlearningä¸­çš„å®‰å…¨é£é™©ã€‚</p>
</li>
<li>
<p>(3):æœ¬æ–‡æå‡ºäº†AdvUnlearnæ¡†æ¶ï¼Œç»“åˆå¯¹æŠ—æ€§è®­ç»ƒæ¥å¢å¼ºæœºå™¨unlearningçš„robustnessã€‚è¯¥æ¡†æ¶ä½¿ç”¨utility-retaining regularizationæ¥å¹³è¡¡æ¦‚å¿µæ“¦é™¤çš„robustnesså’Œæ¨¡å®ç”¨æ€§ï¼Œå¹¶å°†æ–‡æœ¬ç¼–ç å™¨ä½œä¸ºrobustificationçš„æ¨¡å—ã€‚</p>
</li>
<li>
<p>(4):æœ¬æ–‡åœ¨å¤šä¸ªDiffusionæ¨¡å‹unlearningåœºæ™¯ä¸­è¿›è¡Œäº†å®éªŒï¼ŒåŒ…æ‹¬è£¸ä½“ã€å¯¹è±¡å’Œé£æ ¼æ¦‚å¿µçš„æ“¦é™¤ã€‚ç»“æœè¡¨æ˜ï¼ŒAdvUnlearnæ¡†æ¶å¯ä»¥å®ç°robustçš„æœºå™¨unlearningï¼ŒåŒæ—¶ä¿æŒæ¨¡å‹çš„å®ç”¨æ€§ã€‚</p>
</li>
<li>æ–¹æ³•ï¼š</li>
</ul>
</li>
<li>
<p>(1):æå‡ºAdvUnlearnæ¡†æ¶ï¼Œç»“åˆå¯¹æŠ—æ€§è®­ç»ƒæ¥å¢å¼ºæœºå™¨unlearningçš„robustnessï¼Œä½¿ç”¨utility-retaining regularizationæ¥å¹³è¡¡æ¦‚å¿µæ“¦é™¤çš„robustnesså’Œæ¨¡å®ç”¨ï¼Œå¹¶å°†æ–‡æœ¬ç¼–ç å™¨ä½œä¸ºrobustificationçš„æ¨¡å—ã€‚</p>
</li>
<li>
<p>(2):ä½¿ç”¨large language model (LLM)ä½œä¸ºjudgeæ¥ç­›é€‰ä¿ç•™promptï¼Œæ’é™¤ä¸ç›®æ ‡æ¦‚å¿µæ“¦é™¤ç›¸å…³çš„promptï¼Œä»è€Œç¡®ä¿å›¾åƒç”Ÿæˆè´¨é‡ä¸å—æŸå®³ã€‚</p>
</li>
<li>
<p>(3):å®šä¹‰utility-retaining regularizationæŸå¤±å‡½æ•°â„“ESDï¼Œpenalizeså›¾åƒç”Ÿæˆè´¨é‡çš„ä¸‹é™ï¼Œä½¿ç”¨å½“å‰Diffusionæ¨¡å‹Î¸ä¸åŸå§‹Î¸oä¸‹çš„ä¿ç•™æ¦‚å¿µËœcæ¥è®¡ç®—ã€‚</p>
</li>
<li>
<p>(4):ä½¿ç”¨fast attack generationæ–¹æ³•æ¥ç®€åŒ–AdvUnlearnçš„lower-levelä¼˜åŒ–ï¼Œä½¿ç”¨fast gradient sign method (FGSM)æ¥è§£å†³quadratic programï¼Œå¹¶ç”Ÿæˆå¯¹æŠ—æ€§promptã€‚</p>
</li>
<li>
<p>(5):å°†AdvUnlearnåº”ç”¨äºä¸åŒçš„Diffusionæ¨¡å‹unlearningåœºæ™¯ï¼ŒåŒ…æ‹¬è£¸ä½“ã€å¯¹è±¡å’Œé£æ ¼æ¦‚å¿µçš„æ“¦é™¤ï¼Œå¹¶è¯„ä¼°å…¶robustnesså’Œå›¾åƒç”Ÿæˆè´¨é‡ã€‚</p>
</li>
<li>
<p>(6):æ¯”è¾ƒAdvUnlearnä¸å…¶æ–¹æ³•ï¼ˆå¦‚ESDå’ŒAT-ESDï¼‰çš„æ€§èƒ½ï¼Œè¯æ˜AdvUnlearnå¯ä»¥å®ç°robustçš„æœºå™¨unlearningï¼ŒåŒæ—¶ä¿æŒæ¨¡å‹çš„å®ç”¨æ€§</p>
</li>
<li>
<p>(7):æ¢ç´¢AdvUnlearnçš„æ¨¡å—åŒ–è®¾è®¡ï¼Œè®¨è®ºå°†æ–‡æœ¬ç¼–ç å™¨ä½œä¸ºplug-in unlearnerçš„å¯èƒ½æ€§ï¼Œä»¥æé«˜æœºå™¨unlearningçš„æ•ˆç‡å’Œæ™®é€‚æ€§ã€‚</p>
</li>
<li>
<p>Conclusion:</p>
</li>
<li>
<p>(1):æœ¬æ–‡æå‡ºçš„AdvUnlearnæ¡†æ¶å¯¹Diffusionæ¨¡å‹çš„æœºå™¨unlearningé¢†åŸŸå…·æœ‰é‡è¦æ„ä¹‰ï¼Œå› ä¸ºå®ƒå¯ä»¥å¢å¼ºæœºå™¨unlearningçš„robustnessï¼ŒåŒæ—¶ä¿æŒæ¨¡å‹çš„å®ç”¨æ€§ã€‚</p>
</li>
<li>
<p>(2):Innovation point: æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„æœºå™¨unlearningæ–¹æ³•ï¼Œç»“åˆå¯¹æŠ—æ€§è®­ç»ƒå’Œutility-retaining regularizationæ¥å¢å¼ºæœºå™¨unlearningçš„robustnessï¼›Performance: AdvUnlearnæ¡†æ¶åœ¨å¤šä¸ªDiffusionæ¨¡å‹unlearningåœºæ™¯ä¸­è¡¨ç°å‡ºè‰²ï¼Œå®ç°äº†robustçš„æœºå™¨unlearningï¼ŒåŒæ—¶ä¿æŒæ¨¡å‹çš„å®ç”¨æ€§ï¼›Workload: æœ¬æ–‡çš„å®éªŒè®¾è®¡å’Œå®ç°ç›¸å¯¹å¤æ‚ï¼Œéœ€è¦å¤§é‡çš„è®¡ç®—èµ„æºå’Œæ—¶é—´ã€‚</p>
</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="/medias/loading.gif" data-original="https://pic1.zhimg.com/v2-12bc7afe95c87708c06799dd505c46da.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-c3f86497a08db26b9953f1bc30dad1c3.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-7ef67ded1db4d01263a65cdacd20797a.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-202a39b4f890f5df5c6e0f34c4f7a6a7.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-89575cd27c93753bf34b1aebf5ce8aef.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://pic1.zhimg.com/v2-005e6d2cd8b93a64b356e1bd2dd224c9.jpg" align="middle">
</details>




<h2 id="DEEM-Diffusion-Models-Serve-as-the-Eyes-of-Large-Language-Models-for-Image-Perception"><a href="#DEEM-Diffusion-Models-Serve-as-the-Eyes-of-Large-Language-Models-for-Image-Perception" class="headerlink" title="DEEM: Diffusion Models Serve as the Eyes of Large Language Models for   Image Perception"></a>DEEM: Diffusion Models Serve as the Eyes of Large Language Models for   Image Perception</h2><p><strong>Authors:Run Luo, Yunshui Li, Longze Chen, Wanwei He, Ting-En Lin, Ziqiang Liu, Lei Zhang, Zikai Song, Xiaobo Xia, Tongliang Liu, Min Yang, Binyuan Hui</strong></p>
<p>The development of large language models (LLMs) has significantly advanced the emergence of large multimodal models (LMMs). While LMMs have achieved tremendous success by promoting the synergy between multimodal comprehension and creation, they often face challenges when confronted with out-of-distribution data. This is primarily due to their reliance on image encoders trained to encode images into task-relevant features, which may lead them to disregard irrelevant details. Delving into the modeling capabilities of diffusion models for images naturally prompts the question: Can diffusion models serve as the eyes of large language models for image perception? In this paper, we propose DEEM, a simple and effective approach that utilizes the generative feedback of diffusion models to align the semantic distributions of the image encoder. This addresses the drawbacks of previous methods that solely relied on image encoders like ViT, thereby enhancing the modelâ€™s resilience against out-of-distribution samples and reducing visual hallucinations. Importantly, this is achieved without requiring additional training modules and with fewer training parameters. We extensively evaluated DEEM on both our newly constructed RobustVQA benchmark and another well-known benchmark, POPE, for object hallucination. Compared to the state-of-the-art interleaved content generation models, DEEM exhibits enhanced robustness and a superior capacity to alleviate model hallucinations while utilizing fewer trainable parameters, less pre-training data (10%), and a smaller base model size. </p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2405.15232v1">PDF</a> 25 pages</p>
<p><strong>Summary</strong><br>é€šè¿‡ä½¿ç”¨æ‰©æ•£æ¨¡å‹ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸ºDEEMçš„ç®€å•è€Œæœ‰æ•ˆçš„æ–¹æ³•ï¼Œåˆ©ç”¨æ‰©æ•£æ¨¡å‹çš„ç”Ÿæˆåé¦ˆæ¥è°ƒæ•´å›¾åƒç¼–ç å™¨çš„è¯­ä¹‰åˆ†å¸ƒï¼Œä»è€Œå¢å¼ºäº†æ¨¡å‹å¯¹äºè¶…å‡ºåˆ†å¸ƒæ•°æ®çš„é²æ£’æ€§ï¼Œå‡å°‘äº†è§†è§‰å¹»è§‰ï¼ŒåŒæ—¶æ— éœ€é¢å¤–çš„è®­ç»ƒæ¨¡å—å’Œæ›´å°‘çš„è®­ç»ƒå‚æ•°ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„å‘å±•æ¨åŠ¨äº†å¤§å‹å¤šæ¨¡æ€æ¨¡å‹ï¼ˆLMMsï¼‰çš„å‡ºç°ï¼›</li>
<li>LMMsåœ¨ä¿ƒè¿›å¤šæ¨¡æ€ç†è§£å’Œåˆ›ä½œæ–¹é¢å–å¾—äº†å·¨å¤§æˆåŠŸï¼Œä½†åœ¨å¤„ç†è¶…å‡ºåˆ†å¸ƒæ•°æ®æ—¶é¢ä¸´æŒ‘æˆ˜ï¼›</li>
<li>DEEMåˆ©ç”¨æ‰©æ•£æ¨¡å‹çš„ç”Ÿæˆåé¦ˆæ¥è°ƒæ•´å›¾åƒç¼–ç å™¨çš„è¯­ä¹‰åˆ†å¸ƒï¼Œè§£å†³äº†ä»¥å¾€ä»…ä¾èµ–äºå›¾åƒç¼–ç å™¨çš„æ–¹æ³•çš„ç¼ºé™·ï¼›</li>
<li>DEEMåœ¨RobustVQAåŸºå‡†å’ŒPOPEåŸºå‡†ä¸Šå¾—åˆ°äº†å¹¿æ³›è¯„ä¼°ï¼Œè¡¨ç°å‡ºå“è¶Šçš„é²æ£’æ€§å’Œå‡å°‘æ¨¡å‹å¹»è§‰çš„èƒ½åŠ›ï¼›</li>
<li>DEEMç›¸è¾ƒäºæœ€å…ˆè¿›çš„äº¤æ›¿å†…å®¹ç”Ÿæˆæ¨¡å‹ï¼Œå±•ç°å‡ºæ›´å¼ºçš„é²æ£’æ€§ï¼Œå¹¶åˆ©ç”¨æ›´å°‘çš„å¯è®­ç»ƒå‚æ•°ã€æ›´å°‘çš„é¢„è®­ç»ƒæ•°æ®ï¼ˆ10%ï¼‰å’Œæ›´å°çš„åŸºç¡€æ¨¡å‹å°ºå¯¸ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<h2>Paper:1</h2>
<ol>
<li>
<p>Title: DEEMï¼šä½¿ç”¨æ‰©æ•£æ¨¡å‹å¯¹å¤§å‹å¤šæ¨¡æ€æ¨¡å‹çš„å›¾åƒæ„ŸçŸ¥è¿›è¡Œå¢å¼º (DEEM: Enhancing Image Perception of Large Multimodal Models with Diffusion Models)</p>
</li>
<li>
<p>Authors: (no author names provided)</p>
</li>
<li>
<p>Affiliation: æ—  (no affiliation provided)</p>
</li>
<li>
<p>Keywords: large language models, large multimodal models, diffusion models, image perception, robustness, hallucination</p>
</li>
<li>
<p>Urls: arXiv:2405.15232v1, Github: None</p>
</li>
<li>
<p>Summary:</p>
<ul>
<li>
<p>(1):è¯¥è®ºæ–‡çš„ç ”ç©¶èƒŒæ™¯æ˜¯å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å’Œå¤§å‹å¤šæ¨¡æ€æ¨¡å‹ï¼ˆLMMsï¼‰çš„å‘å±•ï¼Œåè€…é€šè¿‡ç®€å•çš„æ˜ å°„æ¨¡å—å°†LLMsä¸å›¾åƒç¼–ç å™¨è¿æ¥èµ·æ¥ï¼Œå®ç°å¤šæ¨¡æ€ç†è§£ä»»åŠ¡ã€‚</p>
</li>
<li>
<p>(2):è¿‡å»çš„æ–¹æ³•ä¸»è¦ä¾èµ–å›¾åƒç¼–ç å™¨æ¥å°†å›¾åƒç¼–ç ä¸ºä»»åŠ¡ç›¸å…³ç‰¹å¾ï¼Œå¯èƒ½å¿½è§†æ— å…³ç»†èŠ‚ï¼Œä»è€Œå¯¼è‡´æ¨¡å‹å¯¹å¤–åˆ†å¸ƒæ•°æ®çš„robustnesså’Œhallucinationé—®é¢˜ã€‚</p>
</li>
<li>
<p>(3):æœ¬æ–‡æå‡ºçš„æ–¹æ³•æ˜¯DEEMï¼Œå®ƒä½¿ç”¨æ‰©æ•£æ¨¡å‹çš„ç”Ÿæˆåé¦ˆæ¥å¯¹é½å›¾åƒç¼–ç å™¨çš„è¯­ä¹‰åˆ†å¸ƒï¼Œæé«˜æ¨¡å‹å¯¹å¤–åˆ†å¸ƒæ•°æ®çš„robustnesså’Œå‡å°‘hallucinationã€‚</p>
</li>
<li>
<p>(4):è¯¥æ–¹æ³•åœ¨RobustVQAå’ŒPOPEä¸¤ä¸ªåŸºå‡†æµ‹è¯•æ•°æ®é›†ä¸Šè¿›è¡Œäº†è¯„ä¼°ï¼Œç»“æœè¡¨æ˜DEEMç›¸æ¯”äºå½“å‰æœ€å…ˆè¿›çš„æ¨¡å‹å…·æœ‰æ›´å¥½çš„robustnesså’Œå‡å°‘hallucinationèƒ½åŠ›ï¼ŒåŒæ—¶è¿˜å¯ä»¥åœ¨å¤šæ¨¡æ€ä»»åŠ¡å¦‚è§†è§‰é—®ç­”ã€å›¾åƒå­—å¹•ç”Ÿæˆå’Œæ–‡æœ¬æ¡ä»¶å›¾åƒåˆæˆç­‰æ–¹é¢å–å¾—ç«äº‰æ€§çš„ç»“æœã€‚</p>
</li>
<li>æ–¹æ³•ï¼š</li>
</ul>
</li>
<li>
<p>(1)ï¼šé¦–å…ˆï¼Œä½¿ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä½œä¸ºæ–‡æœ¬ç¼–ç å™¨ï¼Œç”Ÿæˆå›¾åƒç›¸å…³çš„æ–‡æœ¬ç‰¹å¾ï¼Œä»¥ä¾¿ä¸å›¾åƒç¼–ç å™¨è¿›è¡Œå¯¹é½ã€‚</p>
</li>
<li>
<p>(2)ï¼šç„¶åï¼Œä½¿ç”¨æ‰©æ•£æ¨¡å‹ï¼ˆDiffusion Modelï¼‰å¯¹å›¾åƒç¼–ç å™¨çš„è¾“å‡ºè¿›è¡Œç”Ÿæˆåé¦ˆï¼Œä»¥è°ƒæ•´å›¾åƒç¼–ç å™¨è¯­ä¹‰åˆ†å¸ƒï¼Œæé«˜æ¨¡å‹å¯¹å¤–åˆ†å¸ƒæ•°æ®çš„robustnessã€‚</p>
</li>
<li>
<p>(3)ï¼šåœ¨ç”Ÿæˆåé¦ˆè¿‡ç¨‹ä¸­ï¼Œä½¿ç”¨å¯¹æŠ—è®­ç»ƒï¼ˆAdversarial Trainingï¼‰æ¥é¼“åŠ±å›¾åƒç¼–ç å™¨ç”Ÿæˆæ›´åŠ robustçš„ç‰¹å¾ï¼Œå‡å°‘hallucinationçš„å¯èƒ½æ€§ã€‚</p>
</li>
<li>
<p>(4)ï¼šæ¥ç€ï¼Œå¯¹DEEMæ¨¡å‹è¿›è¡Œå¤šæ¨¡æ€ä»»åŠ¡çš„fine-tuningï¼Œä¾‹å¦‚è§†è§‰é—®ç­”ã€å›¾åƒå­—å¹•ç”Ÿæˆå’Œæ–‡æœ¬æ¡ä»¶å›¾åƒåˆæˆç­‰ï¼Œä»¥æé«˜æ¨¡å‹åœ¨å¤šæ¨¡æ€ä»»åŠ¡ä¸Šçš„æ€§èƒ½ã€‚</p>
</li>
<li>
<p>(5)ï¼šæœ€åï¼Œåœ¨RobustVQAå’ŒPOPEä¸¤ä¸ªåŸºå‡†æµ‹è¯•æ•°æ®é›†ä¸Šè¿›è¡Œè¯„ä¼°ï¼Œè¯„ä¼°DEEMæ¨¡å‹çš„robustnesså’Œhallucinationèƒ½åŠ›ï¼Œä¸¦ä¸å½“å‰æœ€å…ˆè¿›çš„æ¨¡å‹è¿›è¡Œæ¯”è¾ƒã€‚</p>
</li>
<li>
<p>Conclusion: </p>
</li>
<li>
<p>(1): æœ¬ç ”ç©¶çš„æ„ä¹‰åœ¨äºæå‡ºäº†ä¸€ç§æ–°çš„æ–¹æ³•ï¼ˆDEEMï¼‰ï¼Œé€šè¿‡ä½¿ç”¨æ‰©æ•£æ¨¡å‹å¯¹å¤§å‹å¤šæ¨¡æ€æ¨¡å‹è¿›è¡Œå›¾åƒæ„ŸçŸ¥å¢å¼ºï¼Œæœ‰æ•ˆæé«˜äº†æ¨¡å‹çš„é²æ£’æ€§å’Œå‡å°‘äº†è™šå‡æ„ŸçŸ¥ï¼Œä¸ºå¤šæ¨¡æ€ä»»åŠ¡çš„æ€§èƒ½æå‡æä¾›äº†æ–°çš„æ€è·¯ã€‚</p>
</li>
<li>
<p>(2): åˆ›æ–°ç‚¹ï¼šDEEMæ–¹æ³•åˆ©ç”¨æ‰©æ•£æ¨¡å‹å¯¹å›¾åƒç¼–ç å™¨çš„è¯­ä¹‰åˆ†å¸ƒè¿›è¡Œè°ƒæ•´ï¼Œåœ¨æé«˜æ¨¡å‹é²æ£’æ€§å’Œå‡å°‘è™šå‡æ„ŸçŸ¥æ–¹é¢å–å¾—æ˜¾è‘—è¿›å±•ã€‚æ€§èƒ½ï¼šDEEMåœ¨RobustVQAå’ŒPOPEä¸¤ä¸ªåŸºå‡†æµ‹è¯•æ•°æ®é›†ä¸Šç›¸æ¯”å½“å‰æœ€å…ˆè¿›æ¨¡å‹å…·æœ‰æ›´å¥½çš„é²æ£’æ€§å’Œå‡å°‘è™šå‡æ„ŸçŸ¥èƒ½åŠ›ï¼Œå¹¶åœ¨å¤šæ¨¡æ€ä»»åŠ¡ä¸Šå–å¾—äº†ç«äº‰æ€§çš„ç»“æœã€‚å·¥ä½œé‡ï¼šè®ºæ–‡æ‰€æå‡ºçš„DEEMæ–¹æ³•éœ€è¦è¿›ä¸€æ­¥å®éªŒå’ŒéªŒè¯ï¼Œä»¥ç¡®ä¿å…¶åœ¨ä¸åŒé¢†åŸŸçš„æ³›åŒ–æ€§èƒ½ï¼Œè¿™å¯èƒ½éœ€è¦æ›´å¤šçš„å·¥ä½œé‡æ¥æ”¯æŒã€‚</p>
</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="/medias/loading.gif" data-original="https://pic1.zhimg.com/v2-c0b6103bc7ef9889b013616a33153dac.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-5911a832e2f068efcd4f1c57fb6c0989.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://pic1.zhimg.com/v2-2f388f04ad9850dd89191f6903b1cf64.jpg" align="middle">
</details>




<h2 id="NIVeL-Neural-Implicit-Vector-Layers-for-Text-to-Vector-Generation"><a href="#NIVeL-Neural-Implicit-Vector-Layers-for-Text-to-Vector-Generation" class="headerlink" title="NIVeL: Neural Implicit Vector Layers for Text-to-Vector Generation"></a>NIVeL: Neural Implicit Vector Layers for Text-to-Vector Generation</h2><p><strong>Authors:Vikas Thamizharasan, Difan Liu, Matthew Fisher, Nanxuan Zhao, Evangelos Kalogerakis, Michal Lukac</strong></p>
<p>The success of denoising diffusion models in representing rich data distributions over 2D raster images has prompted research on extending them to other data representations, such as vector graphics. Unfortunately due to their variable structure and scarcity of vector training data, directly applying diffusion models on this domain remains a challenging problem. Using workarounds like optimization via Score Distillation Sampling (SDS) is also fraught with difficulty, as vector representations are non trivial to directly optimize and tend to result in implausible geometries such as redundant or self-intersecting shapes. NIVeL addresses these challenges by reinterpreting the problem on an alternative, intermediate domain which preserves the desirable properties of vector graphics â€“ mainly sparsity of representation and resolution-independence. This alternative domain is based on neural implicit fields expressed in a set of decomposable, editable layers. Based on our experiments, NIVeL produces text-to-vector graphics results of significantly better quality than the state-of-the-art. </p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2405.15217v1">PDF</a> </p>
<p><strong>Summary</strong><br>æ‰©å±•å»å™ªæ‰©æ•£æ¨¡å‹åˆ°çŸ¢é‡å›¾å½¢é¢†åŸŸçš„æŒ‘æˆ˜æ€§è§£å†³æ–¹æ¡ˆNIVeLã€‚</p>
<p><strong>Key Takeaways</strong><br>â€¢ å»å™ªæ‰©æ•£æ¨¡å‹åœ¨2D rasterå›¾åƒä¸Šçš„æˆåŠŸä¿ƒä½¿ç ”ç©¶å°†å…¶æ‰©å±•åˆ°å…¶ä»–æ•°æ®è¡¨ç¤ºå½¢å¼ï¼Œå¦‚çŸ¢é‡å›¾å½¢ã€‚<br>â€¢ ç›´æ¥å°†æ‰©æ•£æ¨¡å‹åº”ç”¨äºçŸ¢é‡å›¾å½¢é¢†åŸŸæ˜¯å…·æœ‰æŒ‘æˆ˜æ€§çš„ï¼Œå› ä¸ºçŸ¢é‡å›¾å½¢å…·æœ‰å¯å˜ç»“æ„å’Œç¨€ç–çš„è®­ç»ƒæ•°æ®ã€‚<br>â€¢ ä½¿ç”¨Score Distillation Samplingï¼ˆSDSï¼‰ç­‰ä¼˜åŒ–æ–¹æ³•ä¹Ÿå­˜åœ¨å›°éš¾ï¼Œå› ä¸ºçŸ¢é‡è¡¨ç¤ºéš¾ä»¥ç›´æ¥ä¼˜åŒ–ï¼Œå®¹æ˜“äº§ç”Ÿä¸å¯ä¿¡çš„å‡ ä½•å½¢çŠ¶ã€‚<br>â€¢ NIVeLé€šè¿‡é‡æ–°è§£é‡Šé—®é¢˜åœ¨ä¸­é—´åŸŸä¸Šï¼Œä¿ç•™çŸ¢é‡å›¾å½¢çš„è‰¯å¥½å±æ€§ï¼Œä¾‹å¦‚ç¨€ç–è¡¨ç¤ºå’Œåˆ†è¾¨ç‡ç‹¬ç«‹æ€§ã€‚<br>â€¢ ä¸­é—´åŸŸåŸºäºå¯åˆ†è§£ã€å¯ç¼–è¾‘çš„ç¥ç»éšå¼å­—æ®µå±‚ã€‚<br>â€¢ å®éªŒç»“æœè¡¨æ˜ï¼ŒNIVeLç”Ÿæˆçš„æ–‡æœ¬åˆ°çŸ¢é‡å›¾å½¢ç»“æœè¿œä¼˜äºå½“å‰æœ€å…ˆè¿›çš„ç»“æœã€‚<br>â€¢ NIVeLè§£å†³äº†æ‰©å±•å»å™ªæ‰©æ•£æ¨¡å‹åˆ°çŸ¢é‡å›¾å½¢é¢†åŸŸçš„æŒ‘æˆ˜æ€§é—®é¢˜ã€‚</p>
<p><strong><a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>
<p>Title: NIVeL: ç¥ç»éšå¼çŸ¢é‡å›¾å½¢ç”Ÿæˆï¼ˆNeural Implicit Vector Graphics Generationï¼‰</p>
</li>
<li>
<p>Authors: Not provided</p>
</li>
<li>
<p>Affiliation: ä¸æä¾›ï¼ˆNot providedï¼‰</p>
</li>
<li>
<p>Keywords: denoising diffusion models, vector graphics, neural implicit fields</p>
</li>
<li>
<p>Urls: Not provided, Github: None</p>
</li>
<li>
<p>Summary:</p>
</li>
<li>
<p>(1):è¯¥è®ºæ–‡çš„ç ”ç©¶èƒŒæ™¯æ˜¯å°†å»å™ªæ‰©æ•£æ¨¡å‹ä»2D rasterå›¾åƒæ‰©å±•åˆ°çŸ¢é‡å›¾å½¢é¢†åŸŸï¼Œä½†çŸ¢é‡å›¾å½¢çš„å¯å˜ç»“æ„å’Œç¨€ç¼ºçš„è®­ç»ƒæ•°æ®ä½¿å¾—ç›´æ¥åº”ç”¨å»å™ªæ‰©æ•£æ¨¡å‹å˜å¾—å›°éš¾ã€‚</p>
</li>
<li>
<p>(2):è¿‡å»çš„æ–¹æ³•åŒ…æ‹¬ç›´æ¥åº”ç”¨å»å™ªæ‰©æ•£æ¨¡å‹å’ŒScore Distillation Samplingï¼ˆSDSï¼‰ä¼˜åŒ–ï¼Œä½†è¿™äº›æ–¹æ³•å­˜åœ¨ä¸€äº›é—®é¢˜ï¼Œå¦‚ç”Ÿæˆçš„çŸ¢é‡å›¾å½¢å¯èƒ½åŒ…å«å†—ä½™æˆ–è‡ªç›¸äº¤çš„å½¢çŠ¶ã€‚</p>
</li>
<li>
<p>(3):æœ¬è®ºæ–‡æå‡ºäº†NIVeLæ–¹æ³•ï¼Œè¯¥æ–¹æ³•é€šè¿‡å°†é—®é¢˜é‡æ–°è§£é‡Šåœ¨ä¸­é—´åŸŸä¸Šï¼Œå³åŸºäºç¥ç»éšå¼å­—æ®µçš„å¯åˆ†è§£ã€å¯ç¼–è¾‘çš„å±‚æ¥ç”ŸæˆçŸ¢é‡å›¾å½¢ã€‚</p>
</li>
<li>
<p>(4):æœ¬è®ºæ–‡çš„æ–¹æ³•åœ¨æ–‡æœ¬åˆ°çŸ¢é‡å›¾å½¢ä»»åŠ¡ä¸Šå–å¾—äº†æ˜æ˜¾ä¼˜äºç°æœ‰æ–¹æ³•çš„æ€§èƒ½ï¼Œè¯æ˜äº†NIVeLæ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚</p>
</li>
<li>
<p>æ–¹æ³•ï¼š</p>
</li>
<li>
<p>(1):å°†çŸ¢é‡å›¾å½¢ç”Ÿæˆé—®é¢˜é‡æ–°è§£é‡Šåœ¨ä¸­é—´åŸŸä¸Šï¼Œå³åŸºäºç¥ç»éšå¼å­—æ®µï¼ˆNeural Implicit Fieldsï¼‰çš„å¯åˆ†è§£ã€å¯ç¼–è¾‘çš„å±‚ï¼Œä»¥ä¾¿æ›´å¥½åœ°å¤„ç†çŸ¢é‡å›¾å½¢çš„å¯å˜ç»“æ„å’Œç¨€ç¼ºçš„è®­ç»ƒæ•°æ®ã€‚</p>
</li>
<li>
<p>(2):ä½¿ç”¨å»å™ªæ‰©æ•£æ¨¡å‹ï¼ˆDenoising Diffusion Modelsï¼‰åœ¨ä¸­é—´åŸŸä¸Šç”Ÿæˆéšå¼è¡¨ç¤ºï¼Œç„¶åé€šè¿‡ç¥ç»éšå¼å­—æ®µå°†å…¶è½¬æ¢ä¸ºçŸ¢é‡å›¾å½¢ã€‚</p>
</li>
<li>
<p>(3):å¼•å…¥ Score Distillation Samplingï¼ˆSDSï¼‰ä¼˜åŒ–æ–¹æ³•ï¼Œä»¥æé«˜ç”ŸæˆçŸ¢é‡å›¾å½¢çš„è´¨é‡å’Œå¤šæ ·æ€§ã€‚</p>
</li>
<li>
<p>(4):åœ¨ä¸­é—´åŸŸä¸Šåº”ç”¨ç¼–è¾‘æ“ä½œï¼Œå¦‚å½¢çŠ¶å˜æ¢ã€æ‹“æ‰‘å˜åŒ–ç­‰ï¼Œä»¥å¢å¼ºç”ŸæˆçŸ¢é‡å›¾å½¢çš„å¯ç¼–è¾‘æ€§å’Œçµæ´»æ€§ã€‚</p>
</li>
<li>
<p>(5):ä½¿ç”¨æ–‡æœ¬åˆ°çŸ¢é‡å›¾å½¢ä»»åŠ¡çš„å®éªŒç»“æœéªŒè¯NIVeLæ–¹æ³•çš„æœ‰æ•ˆæ€§ï¼Œè¯æ˜å…¶åœ¨ç”Ÿæˆé«˜è´¨é‡çŸ¢é‡å›¾å½¢æ–¹é¢çš„ä¼˜åŠ¿ã€‚</p>
</li>
<li>
<p>ç»“è®ºï¼š</p>
</li>
<li>
<p>(1):è¯¥ç¯‡å·¥ä½œçš„é‡è¦æ€§åœ¨äºå°†å»å™ªæ‰©æ•£æ¨¡å‹åº”ç”¨äºçŸ¢é‡å›¾å½¢ç”Ÿæˆé¢†åŸŸï¼Œè§£å†³äº†çŸ¢é‡å›¾å½¢çš„å¯å˜ç»“æ„å’Œç¨€ç¼ºçš„è®­ç»ƒæ•°æ®é—®é¢˜ï¼Œæé«˜äº†ç”ŸæˆçŸ¢é‡å›¾å½¢çš„è´¨é‡å’Œå¤šæ ·æ€§ã€‚</p>
</li>
<li>
<p>(2):åˆ›æ–°ç‚¹ï¼šæå‡ºäº†ä¸€ç§åŸºäºç¥ç»éšå¼å­—æ®µçš„çŸ¢é‡å›¾å½¢ç”Ÿæˆæ–¹æ³•ï¼Œèƒ½å¤Ÿæ›´å¥½åœ°å¤„ç†çŸ¢é‡å›¾å½¢çš„å¯å˜ç»“æ„å’Œç¨€ç¼ºçš„è®­ç»ƒæ•°æ®ï¼›æ€§èƒ½ï¼šåœ¨æ–‡æœ¬åˆ°çŸ¢é‡å›¾å½¢ä»»åŠ¡ä¸Šå–å¾—äº†æ˜æ˜¾ä¼˜äºç°æœ‰æ–¹æ³•çš„æ€§èƒ½ï¼›å·¥ä½œé‡ï¼šéœ€è¦å¤§é‡çš„è®­ç»ƒæ•°æ®å’Œè®¡ç®—èµ„æºï¼Œä¸”å½“å‰çš„è¡¨ç¤ºæ–¹å¼è¿˜å­˜åœ¨ä¸€äº›é™åˆ¶ï¼Œå¦‚å±‚çš„æ•°é‡é™åˆ¶ç­‰ã€‚</p>
</li>
</ol>



<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-deb0bce750c823b45864a06b1f2fdf37.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://pic1.zhimg.com/v2-b05c16791ff3624415d2ca5a4bb2b01d.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-1ddb20e736aa45d7da426d42c0386fcb.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://pica.zhimg.com/v2-a127e1927a9826d4a5a6449d4ce7f25e.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-6ef7a2dd3802c3e38639f59aa13e5305.jpg" align="middle">
</details>




<h2 id="TerDiT-Ternary-Diffusion-Models-with-Transformers"><a href="#TerDiT-Ternary-Diffusion-Models-with-Transformers" class="headerlink" title="TerDiT: Ternary Diffusion Models with Transformers"></a>TerDiT: Ternary Diffusion Models with Transformers</h2><p><strong>Authors:Xudong Lu, Aojun Zhou, Ziyi Lin, Qi Liu, Yuhui Xu, Renrui Zhang, Yafei Wen, Shuai Ren, Peng Gao, Junchi Yan, Hongsheng Li</strong></p>
<p>Recent developments in large-scale pre-trained text-to-image diffusion models have significantly improved the generation of high-fidelity images, particularly with the emergence of diffusion models based on transformer architecture (DiTs). Among these diffusion models, diffusion transformers have demonstrated superior image generation capabilities, boosting lower FID scores and higher scalability. However, deploying large-scale DiT models can be expensive due to their extensive parameter numbers. Although existing research has explored efficient deployment techniques for diffusion models such as model quantization, there is still little work concerning DiT-based models. To tackle this research gap, in this paper, we propose TerDiT, a quantization-aware training (QAT) and efficient deployment scheme for ternary diffusion models with transformers. We focus on the ternarization of DiT networks and scale model sizes from 600M to 4.2B. Our work contributes to the exploration of efficient deployment strategies for large-scale DiT models, demonstrating the feasibility of training extremely low-bit diffusion transformer models from scratch while maintaining competitive image generation capacities compared to full-precision models. Code will be available at <a target="_blank" rel="noopener" href="https://github.com/Lucky-Lance/TerDiT">https://github.com/Lucky-Lance/TerDiT</a>. </p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2405.14854v1">PDF</a> 18 pages, 13 figures</p>
<p><strong>Summary</strong><br>å¤§è§„æ¨¡é¢„è®­ç»ƒæ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹çš„æœ€æ–°å‘å±•ï¼Œæå‡ºäº†ä¸€ç§é‡åŒ–æ„ŸçŸ¥è®­ç»ƒå’Œé«˜æ•ˆéƒ¨ç½²æ–¹æ¡ˆTerDiTï¼Œç”¨äºä¸‰çº§æ‰©æ•£æ¨¡å‹çš„ transformersã€‚</p>
<p><strong>Key Takeaways</strong><br>â€¢ å¤§è§„æ¨¡é¢„è®­ç»ƒæ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹çš„æœ€æ–°å‘å±•ï¼Œç‰¹åˆ«æ˜¯åŸºäº transformer æ¶æ„çš„æ‰©æ•£æ¨¡å‹ï¼ˆDiTsï¼‰ï¼Œç”Ÿæˆé«˜ä¿çœŸå›¾åƒçš„èƒ½åŠ›å¾—åˆ°äº†æ˜¾è‘—æ”¹å–„ã€‚<br>â€¢ æ‰©æ•£å˜å‹å™¨æ¨¡å‹å±•ç¤ºå‡ºä¼˜è¶Šçš„å›¾åƒç”Ÿæˆèƒ½åŠ›ï¼Œå…·æœ‰è¾ƒä½çš„ FID åˆ†æ•°å’Œæ›´é«˜çš„å¯æ‰©å±•æ€§ã€‚<br>â€¢ éƒ¨ç½²å¤§è§„æ¨¡ DiT æ¨¡å‹å¯èƒ½å¾ˆæ˜‚è´µï¼Œå› ä¸ºå®ƒä»¬å…·æœ‰åºå¤§çš„å‚æ•°æ•°é‡ã€‚<br>â€¢ ç°æœ‰çš„ç ”ç©¶å·²ç»æ¢ç´¢äº†æ‰©æ•£æ¨¡å‹çš„é«˜æ•ˆéƒ¨ç½²æŠ€æœ¯ï¼Œå¦‚æ¨¡å‹é‡åŒ–ï¼Œä½†å¯¹äº DiT åŸºç¡€æ¨¡å‹çš„ç ”ç©¶ä»ç„¶å¾ˆå°‘ã€‚<br>â€¢ æœ¬æ–‡æå‡ºäº† TerDiTï¼Œä¸€ç§é‡åŒ–æ„ŸçŸ¥è®­ç»ƒå’Œé«˜æ•ˆéƒ¨ç½²æ–¹æ¡ˆï¼Œç”¨äºä¸‰çº§æ‰©æ•£æ¨¡å‹çš„ transformersã€‚<br>â€¢ è¯¥æ–¹æ¡ˆå…³æ³¨ DiT ç½‘ç»œçš„ä¸‰çº§åŒ–ï¼Œå¹¶å°†æ¨¡å‹å¤§å°ä» 600M æ‰©å±•åˆ° 4.2Bã€‚<br>â€¢ æœ¬å·¥ä½œä¸ºå¤§è§„æ¨¡ DiT æ¨¡å‹çš„é«˜æ•ˆéƒ¨ç½²ç­–ç•¥åšå‡ºäº†è´¡çŒ®ï¼Œè¯æ˜äº†ä»å¤´è®­ç»ƒæä½ä½æ‰©æ•£å˜å‹å™¨æ¨¡å‹çš„å¯è¡Œæ€§ï¼ŒåŒæ—¶ä¿æŒäº†ä¸å…¨ç²¾åº¦æ¨¡å‹ç›¸ä¼¼çš„å›¾åƒç”Ÿæˆèƒ½åŠ›ã€‚</p>
<p><strong><a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<h2>Paper:1</h2>
<ol>
<li>
<p>Title: TerDiTï¼šå…·æœ‰å˜å‹å™¨çš„ä¸‰è¿›åˆ¶æ‰©æ•£æ¨¡å‹ (TerDiT: Ternary Diffusion Models with Transformers)</p>
</li>
<li>
<p>Authors: Xudong Lu, Aojun Zhou, Ziyi Lin, Qi Liu, Yuhui Xu, Renrui Zhang, Yafei Wen, Shuai Ren, Peng Gao, Junchi Yan, Hongsheng Li</p>
</li>
<li>
<p>Affiliation: é¦™æ¸¯ä¸­æ–‡å¤§å­¦å¤šåª’ä½“å®éªŒå®¤</p>
</li>
<li>
<p>Keywords: diffusion models, transformer architecture, quantization-aware training, efficient deployment</p>
</li>
<li>
<p>Urls: https://arxiv.org/abs/2405.14854, Github: https://github.com/Lucky-Lance/TerDiT</p>
</li>
<li>
<p>Summary:</p>
<ul>
<li>
<p>(1):æœ€è¿‘ï¼Œå¤§è§„æ¨¡é¢„è®­ç»ƒæ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹çš„å‘å±•æå¤§åœ°æ”¹å–„äº†é«˜ä¿çœŸå›¾åƒçš„ç”Ÿæˆï¼Œç‰¹åˆ«æ˜¯åŸºäºå˜å‹å™¨æ¶æ„ï¼ˆDiTsï¼‰çš„æ‰©æ•£æ¨¡å‹ã€‚</p>
</li>
<li>
<p>(2):ç°æœ‰çš„ç ”ç©¶å·²ç»æ¢ç´¢äº†æ‰©æ•£æ¨¡å‹çš„é«˜æ•ˆéƒ¨ç½²æŠ€æœ¯ï¼Œå¦‚æ¨¡å‹é‡åŒ–ï¼Œä½†æ˜¯åœ¨DiTæ¨¡å‹æ–¹é¢ä»ç„¶å­˜åœ¨ç ”ç©¶gapã€‚</p>
</li>
<li>
<p>(3):æœ¬æ–‡æå‡ºTerDiTï¼Œä¸€ä¸ªé‡åŒ–æ„ŸçŸ¥è®­ç»ƒï¼ˆQATï¼‰å’Œé«˜æ•ˆéƒ¨ç½²æ–¹æ¡ˆï¼Œç”¨äºå…·æœ‰å˜å‹å™¨çš„ä¸‰è¿›åˆ¶æ‰©æ•£æ¨¡å‹ã€‚</p>
</li>
<li>
<p>(4):æœ¬æ–‡çš„æ–¹æ³•å¯ä»¥è®­ç»ƒæä½æ¯”ç‰¹æ‰©æ•£å˜å‹å™¨æ¨¡å‹ï¼Œä»è€Œå®ç°ä¸å…¨ç²¾åº¦æ¨¡å‹ç›¸åª²ç¾çš„å›¾åƒç”Ÿæˆèƒ½åŠ›ï¼ŒåŒæ—¶ä¹Ÿå®ç°äº†é«˜æ•ˆçš„æ¨¡å‹éƒ¨ç½²ã€‚</p>
</li>
<li>æ–¹æ³•ï¼š</li>
</ul>
</li>
<li>
<p>(1)ï¼šé‡‡ç”¨å‡é‡å‡½æ•°ï¼ˆfake quant functionï¼‰å¯¹æ¨¡å‹æƒé‡è¿›è¡Œé‡åŒ–ï¼Œè®¾ç½®n_bits=4ï¼Œä¸è¿›è¡Œæ¿€æ´»é‡åŒ–ã€‚</p>
</li>
<li>
<p>(2)ï¼šå¯¹åŸDiTå—ä¸­çš„æ‰€æœ‰çº¿æ€§å±‚æƒé‡è¿›è¡Œé‡åŒ–ï¼ŒåŒ…æ‹¬è‡ªæ³¨æ„ã€å‰é¦ˆå’ŒMLPã€‚</p>
</li>
<li>
<p>(3)ï¼šä½¿ç”¨é‡åŒ–åçš„æ¨¡å‹é‡‡æ ·å›¾åƒï¼Œå¹¶ä¸å…¨ç²¾åº¦æ¨¡å‹è¿›è¡Œæ¯”è¾ƒã€‚</p>
</li>
<li>
<p>(4)ï¼šæå‡ºTerDiTï¼Œä¸€ä¸ªé‡åŒ–æ„ŸçŸ¥è®­ç»ƒï¼ˆQATï¼‰å’Œé«˜æ•ˆéƒ¨ç½²æ–¹æ¡ˆï¼Œç”¨äºå…·æœ‰å˜å‹å™¨çš„ä¸‰è¿›åˆ¶æ‰©æ•£æ¨¡å‹ã€‚</p>
</li>
<li>
<p>(5)ï¼šé‡‡ç”¨å­¦ä¹ ç‡å‡å°ç­–ç•¥ï¼Œä»¥æé«˜æ¨¡å‹çš„è®­ç»ƒç»“æœã€‚</p>
</li>
<li>
<p>(6)ï¼šä½¿ç”¨RMS Normalized adaLNæ¨¡å—ï¼Œä»¥æé«˜æ¨¡å‹çš„ç”Ÿæˆè´¨é‡ã€‚</p>
</li>
<li>
<p>(7)ï¼šè¿›è¡Œå®éªŒæ¯”è¾ƒï¼ŒéªŒè¯TerDiTæ¨¡å‹åœ¨é«˜æ•ˆéƒ¨ç½²å’Œå›¾åƒç”Ÿæˆèƒ½åŠ›æ–¹é¢çš„ä¼˜åŠ¿ã€‚</p>
</li>
<li>
<p>ç»“è®ºï¼š</p>
</li>
<li>
<p>(1):è¯¥å·¥ä½œçš„é‡è¦æ€§åœ¨äºå®ƒæ¨åŠ¨äº†å…·æœ‰å˜å‹å™¨æ¶æ„çš„æ‰©æ•£æ¨¡å‹çš„é«˜æ•ˆéƒ¨ç½²ï¼Œæ»¡è¶³äº†å®é™…åº”ç”¨ä¸­çš„ä½å»¶è¿Ÿå’Œä½è®¡ç®—èµ„æºéœ€æ±‚ã€‚</p>
</li>
<li>
<p>(2):åˆ›æ–°ç‚¹ï¼šTerDiT æ¨¡å‹æå‡ºäº†ä¸€ç§é‡åŒ–æ„ŸçŸ¥è®­ç»ƒï¼ˆQATï¼‰å’Œé«˜æ•ˆéƒ¨ç½²æ–¹æ¡ˆï¼Œè§£å†³äº†ç°æœ‰DiT æ¨¡å‹åœ¨é«˜æ•ˆéƒ¨ç½²æ–¹é¢çš„ç ”ç©¶gapï¼›æ€§èƒ½ï¼šTerDiT æ¨¡å‹åœ¨å›¾åƒç”Ÿæˆèƒ½åŠ›æ–¹é¢ä¸å…¨ç²¾åº¦æ¨¡å‹ç›¸åª²ç¾ï¼ŒåŒæ—¶å®ç°äº†é«˜æ•ˆçš„æ¨¡å‹éƒ¨ç½²ï¼›å·¥ä½œé‡ï¼šè¯¥å·¥ä½œéœ€è¦å¤§é‡çš„å®éªŒè®¾è®¡å’Œæ¨¡å‹è®­ç»ƒï¼Œä¸”éœ€è¦æ·±å…¥äº†è§£DiT æ¨¡å‹å’Œé‡åŒ–æŠ€æœ¯ã€‚</p>
</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="/medias/loading.gif" data-original="https://pic1.zhimg.com/v2-c40afa8caaa8fb0e34704a216ee65f09.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-21147ce65723c9373a1e3d28f5c516df.jpg" align="middle">
<img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-b32f6ca859af81585bc0599f40dc4518.jpg" align="middle">
</details>





                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2024-05-28/Diffusion%20Models/">https://kedreamix.github.io/Talk2Paper/Paper/2024-05-28/Diffusion%20Models/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/Diffusion-Models/">
                                    <span class="chip bg-color">Diffusion Models</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2024-05-28/Talking%20Head%20Generation/">
                    <div class="card-image">
                        
                        <img src="https://pic1.zhimg.com/v2-33e1c85bbd2586fc6e8eb024aa73c567.jpg" class="responsive-img" alt="Talking Head Generation">
                        
                        <span class="card-title">Talking Head Generation</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Talking Head Generation æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2024-05-28  InstructAvatar Text-Guided Emotion and Motion Control for Avatar   Generation
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2024-05-28
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Talking-Head-Generation/" class="post-category">
                                    Talking Head Generation
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Talking-Head-Generation/">
                        <span class="chip bg-color">Talking Head Generation</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2024-05-28/%E5%85%83%E5%AE%87%E5%AE%99_%E8%99%9A%E6%8B%9F%E4%BA%BA/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-dc27e0e81b6be96603dd90e8aa23e081.jpg" class="responsive-img" alt="å…ƒå®‡å®™/è™šæ‹Ÿäºº">
                        
                        <span class="card-title">å…ƒå®‡å®™/è™šæ‹Ÿäºº</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            å…ƒå®‡å®™/è™šæ‹Ÿäºº æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2024-05-28  InstructAvatar Text-Guided Emotion and Motion Control for Avatar   Generation
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2024-05-28
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/%E5%85%83%E5%AE%87%E5%AE%99-%E8%99%9A%E6%8B%9F%E4%BA%BA/" class="post-category">
                                    å…ƒå®‡å®™/è™šæ‹Ÿäºº
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/%E5%85%83%E5%AE%87%E5%AE%99-%E8%99%9A%E6%8B%9F%E4%BA%BA/">
                        <span class="chip bg-color">å…ƒå®‡å®™/è™šæ‹Ÿäºº</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">7390.7k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script>
        <style>
            [bg-lazy] {
                background-image: none !important;
                background-color: #eee !important;
            }
        </style>
        <script>
            window.imageLazyLoadSetting = {
                isSPA: false,
                preloadRatio: 3,
                processImages: null,
            };
        </script><script>window.addEventListener("load",function(){var t=/\.(gif|jpg|jpeg|tiff|png)$/i,r=/^data:image\/[a-z\d\-\.\+]+;base64,/;Array.prototype.slice.call(document.querySelectorAll("img[data-original]")).forEach(function(a){var e=a.parentNode;"A"===e.tagName&&(t.test(e.href)||r.test(e.href))&&(e.href=a.dataset.original)})});</script><script>(r=>{r.imageLazyLoadSetting.processImages=t;var a=r.imageLazyLoadSetting.isSPA,o=r.imageLazyLoadSetting.preloadRatio||1,d=i();function i(){var t=Array.prototype.slice.call(document.querySelectorAll("img[data-original]")),e=Array.prototype.slice.call(document.querySelectorAll("[bg-lazy]"));return t.concat(e)}function t(t){(a||t)&&(d=i());for(var e,n=0;n<d.length;n++)0<=(e=(e=d[n]).getBoundingClientRect()).bottom&&0<=e.left&&e.top<=(r.innerHeight*o||document.documentElement.clientHeight*o)&&(()=>{var t,e,a,o,i=d[n];e=function(){d=d.filter(function(t){return i!==t}),r.imageLazyLoadSetting.onImageLoaded&&r.imageLazyLoadSetting.onImageLoaded(i)},(t=i).dataset.loaded||(t.hasAttribute("bg-lazy")?(t.removeAttribute("bg-lazy"),e&&e()):(a=new Image,o=t.getAttribute("data-original"),a.onload=function(){t.src=o,t.removeAttribute("data-original"),t.setAttribute("data-loaded",!0),e&&e()},a.onerror=function(){t.removeAttribute("data-original"),t.setAttribute("data-loaded",!1),t.src=o},t.src!==o&&(a.src=o)))})()}function e(){clearTimeout(t.tId),t.tId=setTimeout(t,500)}t(),document.addEventListener("scroll",e),r.addEventListener("resize",e),r.addEventListener("orientationchange",e)})(this);</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
