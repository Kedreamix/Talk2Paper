<!DOCTYPE HTML><html lang="zh-CN"><head><meta charset="utf-8"><meta name="keywords" content="NeRF"><meta name="description" content="NeRF æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2024-05-28  NeRF-Casting Improved View-Dependent Appearance with Consistent   Reflections"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1,user-scalable=no"><meta name="renderer" content="webkit|ie-stand|ie-comp"><meta name="mobile-web-app-capable" content="yes"><meta name="format-detection" content="telephone=no"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="black-translucent"><meta name="referrer" content="no-referrer-when-downgrade"><title>NeRF | Talk2Paper</title><link rel="icon" type="image/png" href="/Talk2Paper/favicon.png"><style>body{background-image:url(/Talk2Paper/background.jpg);background-repeat:no-repeat;background-size:100% 100%;background-attachment:fixed}</style><link rel="stylesheet" href="/Talk2Paper/libs/awesome/css/all.min.css"><link rel="stylesheet" href="/Talk2Paper/libs/materialize/materialize.min.css"><link rel="stylesheet" href="/Talk2Paper/libs/aos/aos.css"><link rel="stylesheet" href="/Talk2Paper/libs/animate/animate.min.css"><link rel="stylesheet" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css"><link rel="stylesheet" href="/Talk2Paper/css/matery.css"><link rel="stylesheet" href="/Talk2Paper/css/my.css"><link rel="stylesheet" href="/Talk2Paper/css/dark.css" media="none" onload='"all"!=media&&(media="all")'><link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css"><link rel="stylesheet" href="/Talk2Paper/css/post.css"><script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script><meta name="generator" content="Hexo 7.3.0"></head><body><header class="navbar-fixed"><nav id="headNav" class="bg-color nav-transparent"><div id="navContainer" class="nav-wrapper container"><div class="brand-logo"><a href="/Talk2Paper/" class="waves-effect waves-light"><img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO"> <span class="logo-span">Talk2Paper</span></a></div><a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a><ul class="right nav-menu"><li class="hide-on-med-and-down nav-item"><a href="/Talk2Paper/" class="waves-effect waves-light"><i class="fas fa-home" style="zoom:0.6"></i> <span>é¦–é¡µ</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/Talk2Paper/tags" class="waves-effect waves-light"><i class="fas fa-tags" style="zoom:0.6"></i> <span>æ ‡ç­¾</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/Talk2Paper/categories" class="waves-effect waves-light"><i class="fas fa-bookmark" style="zoom:0.6"></i> <span>åˆ†ç±»</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/Talk2Paper/archives" class="waves-effect waves-light"><i class="fas fa-archive" style="zoom:0.6"></i> <span>å½’æ¡£</span></a></li><li><a href="#searchModal" class="modal-trigger waves-effect waves-light"><i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom:0.85"></i></a></li><li><a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼"><i id="sum-moon-icon" class="fas fa-sun" style="zoom:0.85"></i></a></li></ul><div id="mobile-nav" class="side-nav sidenav"><div class="mobile-head bg-color"><img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img"><div class="logo-name">Talk2Paper</div><div class="logo-desc">Never really desperate, only the lost of the soul.</div></div><ul class="menu-list mobile-menu-list"><li class="m-nav-item"><a href="/Talk2Paper/" class="waves-effect waves-light"><i class="fa-fw fas fa-home"></i> é¦–é¡µ</a></li><li class="m-nav-item"><a href="/Talk2Paper/tags" class="waves-effect waves-light"><i class="fa-fw fas fa-tags"></i> æ ‡ç­¾</a></li><li class="m-nav-item"><a href="/Talk2Paper/categories" class="waves-effect waves-light"><i class="fa-fw fas fa-bookmark"></i> åˆ†ç±»</a></li><li class="m-nav-item"><a href="/Talk2Paper/archives" class="waves-effect waves-light"><i class="fa-fw fas fa-archive"></i> å½’æ¡£</a></li><li><div class="divider"></div></li><li><a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank"><i class="fab fa-github-square fa-fw"></i> Fork Me</a></li></ul></div></div><style>.nav-transparent .github-corner{display:none!important}.github-corner{position:absolute;z-index:10;top:0;right:0;border:0;transform:scale(1.1)}.github-corner svg{color:#0f9d58;fill:#fff;height:64px;width:64px}.github-corner:hover .octo-arm{animation:a .56s ease-in-out}.github-corner .octo-arm{animation:none}@keyframes a{0%,to{transform:rotate(0)}20%,60%{transform:rotate(-25deg)}40%,80%{transform:rotate(10deg)}}</style><a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank" data-tooltip="Fork Me" data-position="left" data-delay="50"><svg viewBox="0 0 250 250" aria-hidden="true"><path d="M0 0 115 115 130 115 142 142 250 250 250 0Z"></path><path d="M128.3 109C113.8 99.7 119 89.6 119 89.6 122 82.7 120.5 78.6 120.5 78.6 119.2 72 123.4 76.3 123.4 76.3 127.3 80.9 125.5 87.3 125.5 87.3 122.9 97.6 130.6 101.9 134.4 103.2" fill="currentColor" style="transform-origin:130px 106px" class="octo-arm"></path><path d="M115 115C114.9 115.1 118.7 116.5 119.8 115.4L133.7 101.6C136.9 99.2 139.9 98.4 142.2 98.6 133.8 88 127.5 74.4 143.8 58 148.5 53.4 154 51.2 159.7 51 160.3 49.4 163.2 43.6 171.4 40.1 171.4 40.1 176.1 42.5 178.8 56.2 183.1 58.6 187.2 61.8 190.9 65.4 194.5 69 197.7 73.2 200.1 77.6 213.8 80.2 216.3 84.9 216.3 84.9 212.7 93.1 206.9 96 205.4 96.6 205.1 102.4 203 107.8 198.3 112.5 181.9 128.9 168.3 122.5 157.7 114.1 157.9 116.9 156.7 120.9 152.7 124.9L141 136.5C139.8 137.7 141.6 141.9 141.8 141.8Z" fill="currentColor" class="octo-body"></path></svg></a></nav></header><div class="bg-cover pd-header post-cover" style="background-image:url('https://picx.zhimg.com/v2-46b90894aa28846d98c1eef5c5a89f0c.jpg')"><div class="container" style="right:0;left:0"><div class="row"><div class="col s12 m12 l12"><div class="brand"><h1 class="description center-align post-title">NeRF</h1></div></div></div></div></div><main class="post-container content"><div class="row"><div id="main-content" class="col s12 m12 l9"><div id="artDetail"><div class="card"><div class="card-content article-info"><div class="row tag-cate"><div class="col s7"><div class="article-tag"><a href="/Talk2Paper/tags/NeRF/"><span class="chip bg-color">NeRF</span></a></div></div><div class="col s5 right-align"><div class="post-cate"><i class="fas fa-bookmark fa-fw icon-category"></i> <a href="/Talk2Paper/categories/NeRF/" class="post-category">NeRF</a></div></div></div><div class="post-info"><div class="post-date info-break-policy"><i class="far fa-calendar-minus fa-fw"></i> å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp; 2024-05-28</div><div class="post-date info-break-policy"><i class="far fa-calendar-check fa-fw"></i> æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp; 2024-12-10</div><div class="info-break-policy"><i class="far fa-file-word fa-fw"></i> æ–‡ç« å­—æ•°:&nbsp;&nbsp; 3.4k</div><div class="info-break-policy"><i class="far fa-clock fa-fw"></i> é˜…è¯»æ—¶é•¿:&nbsp;&nbsp; 14 åˆ†</div><div id="busuanzi_container_page_pv" class="info-break-policy"><i class="far fa-eye fa-fw"></i> é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;<span id="busuanzi_value_page_pv"></span></div></div></div><hr class="clearfix"><div class="card-content article-card-content"><div id="articleContent"><blockquote><p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº Googleçš„å¤§è¯­è¨€æ¨¡å‹<a target="_blank" rel="noopener" href="https://ai.google.dev/">Gemini-Pro</a>çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p></blockquote><h1 id="2024-05-28-æ›´æ–°"><a href="#2024-05-28-æ›´æ–°" class="headerlink" title="2024-05-28 æ›´æ–°"></a>2024-05-28 æ›´æ–°</h1><h2 id="NeRF-Casting-Improved-View-Dependent-Appearance-with-Consistent-Reflections"><a href="#NeRF-Casting-Improved-View-Dependent-Appearance-with-Consistent-Reflections" class="headerlink" title="NeRF-Casting: Improved View-Dependent Appearance with Consistent   Reflections"></a>NeRF-Casting: Improved View-Dependent Appearance with Consistent Reflections</h2><p><strong>Authors:Dor Verbin, Pratul P. Srinivasan, Peter Hedman, Ben Mildenhall, Benjamin Attal, Richard Szeliski, Jonathan T. Barron</strong></p><p>Neural Radiance Fields (NeRFs) typically struggle to reconstruct and render highly specular objects, whose appearance varies quickly with changes in viewpoint. Recent works have improved NeRFâ€™s ability to render detailed specular appearance of distant environment illumination, but are unable to synthesize consistent reflections of closer content. Moreover, these techniques rely on large computationally-expensive neural networks to model outgoing radiance, which severely limits optimization and rendering speed. We address these issues with an approach based on ray tracing: instead of querying an expensive neural network for the outgoing view-dependent radiance at points along each camera ray, our model casts reflection rays from these points and traces them through the NeRF representation to render feature vectors which are decoded into color using a small inexpensive network. We demonstrate that our model outperforms prior methods for view synthesis of scenes containing shiny objects, and that it is the only existing NeRF method that can synthesize photorealistic specular appearance and reflections in real-world scenes, while requiring comparable optimization time to current state-of-the-art view synthesis models.</p><p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2405.14871v1">PDF</a> Project page: <a target="_blank" rel="noopener" href="http://nerf-casting.github.io/">http://nerf-casting.github.io</a></p><p><strong>Summary</strong><br>NeRFæ–¹æ³•é€šè¿‡å…‰çº¿è¿½è¸ªæŠ€æœ¯è§£å†³äº†é«˜åº¦å…‰æ»‘ç‰©ä½“çš„æ¸²æŸ“é—®é¢˜ï¼Œå®ç°äº†é€¼çœŸçš„é•œé¢æ•ˆæœå’Œåå°„ã€‚</p><p><strong>Key Takeaways</strong></p><ul><li>NeRFæ–¹æ³•æ”¹è¿›äº†æ¸²æŸ“è¿œå¤„ç¯å¢ƒå…‰ç…§ç»†èŠ‚çš„èƒ½åŠ›ï¼Œä½†æ— æ³•åˆæˆè¾ƒè¿‘å†…å®¹çš„ä¸€è‡´åå°„ã€‚</li><li>é‡‡ç”¨å…‰çº¿è¿½è¸ªæŠ€æœ¯ï¼Œä»ç‚¹ä¸ŠæŠ•å°„åå°„å…‰çº¿å¹¶è·Ÿè¸ªå®ƒä»¬é€šè¿‡NeRFè¡¨ç¤ºï¼Œä»¥å‘ˆç°ç‰¹å¾å‘é‡ï¼Œå¹¶ä½¿ç”¨å°å‹å»‰ä»·ç½‘ç»œå°†å…¶è§£ç ä¸ºé¢œè‰²ï¼Œè§£å†³äº†å¤§è§„æ¨¡ç¥ç»ç½‘ç»œçš„ä¼˜åŒ–å’Œæ¸²æŸ“é€Ÿåº¦å—é™çš„é—®é¢˜ã€‚</li><li>è¯¥æ¨¡å‹åœ¨åˆæˆå«æœ‰å…‰äº®ç‰©ä½“åœºæ™¯çš„è§†å›¾åˆæˆæ–¹é¢ä¼˜äºå…ˆå‰æ–¹æ³•ï¼Œæ˜¯å”¯ä¸€å¯ä»¥åœ¨ç°å®åœºæ™¯ä¸­åˆæˆé€¼çœŸçš„é•œé¢æ•ˆæœå’Œåå°„çš„NeRFæ–¹æ³•ï¼Œä¸”æ‰€éœ€ä¼˜åŒ–æ—¶é—´ä¸å½“å‰æœ€å…ˆè¿›çš„è§†å›¾åˆæˆæ¨¡å‹ç›¸å½“ã€‚</li></ul><p><strong><a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p><ol><li><p>Title: NeRF-Castingï¼šImproved View-Dependent Appearance with Consistent Reflectionsï¼ˆNeRF-Castingï¼šå…·æœ‰consistentåå°„çš„è§†å›¾ç›¸å…³å¤–è§‚æ”¹è¿›ï¼‰</p></li><li><p>Authors: DOR VERBIN, PRATUL P. SRINIVASAN, PETER HEDMAN, BEN MILDENHALL, BENJAMIN ATTAL, RICHARD SZELISKI, JONATHAN T. BARRON</p></li><li><p>Affiliation: è°·æ­Œç¾å›½</p></li><li><p>Keywords: View synthesis, neural radiance fields, reflections</p></li><li><p>Urls: <a target="_blank" rel="noopener" href="https://nerf-casting.github.io/">https://nerf-casting.github.io</a>, Github:None</p></li><li><p>Summary:</p></li></ol><ul><li><p>(1):è¯¥è®ºæ–‡çš„ç ”ç©¶èƒŒæ™¯æ˜¯Neural Radiance Fieldsï¼ˆNeRFï¼‰åœ¨è§†å›¾åˆæˆä»»åŠ¡ä¸­çš„åº”ç”¨ï¼Œç‰¹åˆ«æ˜¯å¤„ç†å…·æœ‰é«˜é¢‘è§†å›¾ç›¸å…³å¤–è§‚çš„é•œé¢å¯¹è±¡ã€‚</p></li><li><p>(2):è¿‡å»çš„æ–¹æ³•ä½¿ç”¨å¤§å‹ç¥ç»ç½‘ç»œæ¥æ¨¡æ‹Ÿè§†å›¾ç›¸å…³çš„radianceï¼Œä½†æ˜¯è¿™äº›æ–¹æ³•å­˜åœ¨ä¸¤ä¸ªé—®é¢˜ï¼šä¸€æ˜¯åªèƒ½åˆæˆè¿œè·ç¦»ç¯å¢ƒç…§æ˜çš„åå°„ï¼ŒäºŒæ˜¯è®¡ç®—å¼€é”€å¾ˆå¤§ã€‚æœ¬æ–‡çš„æ–¹æ³•motivated byè¿™äº›é—®é¢˜ã€‚</p></li><li><p>(3):æœ¬æ–‡æå‡ºçš„æ–¹æ³•æ˜¯åŸºäºray tracingçš„NeRF-Castingï¼Œé€šè¿‡castingåå°„å…‰çº¿å¹¶å°†å…¶è¿½è¸ªåˆ°NeRFè¡¨ç¤ºä¸­ï¼Œç”Ÿæˆç‰¹å¾å‘é‡ï¼Œç„¶åä½¿ç”¨å°å‹ç¥ç»ç½‘ç»œè§£ç æˆé¢œè‰²ã€‚</p></li><li><p>(4):æœ¬æ–‡çš„æ–¹æ³•åœ¨è§†å›¾åˆæˆä»»åŠ¡ä¸­å–å¾—äº†state-of-the-artçš„æ€§èƒ½ï¼Œèƒ½å¤Ÿåˆæˆå…·æœ‰é«˜é¢‘è§†å›¾ç›¸å…³å¤–è§‚çš„é•œé¢å¯¹è±¡çš„åå°„ï¼Œä¸”è®¡ç®—å¼€é”€ä¸å½“å‰æœ€å…ˆè¿›çš„è§†å›¾åˆæˆæ¨¡å‹ç›¸å½“ã€‚</p></li></ul><ol start="8"><li>Conclusion:</li></ol><ul><li><p>(1):è¯¥ç¯‡å·¥ä½œçš„æ„ä¹‰åœ¨äºè§£å†³äº†Neural Radiance Fieldsï¼ˆNeRFï¼‰åœ¨è§†å›¾åˆæˆä»»åŠ¡ä¸­çš„åå°„é—®é¢˜ï¼Œæé«˜äº†è§†å›¾ç›¸å…³å¤–è§‚çš„åˆæˆè´¨é‡å’Œæ•ˆç‡ã€‚</p></li><li><p>(2):åˆ›æ–°ç‚¹ï¼šæå‡ºäº†ä¸€ç§åŸºäºray tracingçš„NeRF-Castingæ–¹æ³•ï¼Œèƒ½å¤Ÿç”Ÿæˆé«˜é¢‘è§†å›¾ç›¸å…³å¤–è§‚çš„é•œé¢å¯¹è±¡åå°„ï¼›æ€§èƒ½ï¼šå–å¾—äº†state-of-the-artçš„è§†å›¾åˆæˆæ€§èƒ½ï¼Œèƒ½å¤Ÿåˆæˆå…·æœ‰é«˜é¢‘è§†å›¾ç›¸å…³å¤–è§‚çš„é•œé¢å¯¹è±¡åå°„ï¼›å·¥ä½œè´Ÿè½½ï¼šè®¡ç®—å¼€é”€ä¸å½“å‰æœ€å…ˆè¿›çš„è§†å›¾åˆæˆæ¨¡å‹ç›¸å½“ï¼Œå…·æœ‰è‰¯å¥½çš„å®æ—¶æ€§å’Œå¯æ‰©å±•æ€§ã€‚</p></li></ul><details><summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary><img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-323e45f3162c2c7c913df9dc30275d1a.jpg" align="middle"> <img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-7da742d6de299d161600adf6fdb2df43.jpg" align="middle"> <img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-46b90894aa28846d98c1eef5c5a89f0c.jpg" align="middle"> <img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-2faaf26739f0521731fa46fe33bfa637.jpg" align="middle"></details><h2 id="Neural-Directional-Encoding-for-Efficient-and-Accurate-View-Dependent-Appearance-Modeling"><a href="#Neural-Directional-Encoding-for-Efficient-and-Accurate-View-Dependent-Appearance-Modeling" class="headerlink" title="Neural Directional Encoding for Efficient and Accurate View-Dependent   Appearance Modeling"></a>Neural Directional Encoding for Efficient and Accurate View-Dependent Appearance Modeling</h2><p><strong>Authors:Liwen Wu, Sai Bi, Zexiang Xu, Fujun Luan, Kai Zhang, Iliyan Georgiev, Kalyan Sunkavalli, Ravi Ramamoorthi</strong></p><p>Novel-view synthesis of specular objects like shiny metals or glossy paints remains a significant challenge. Not only the glossy appearance but also global illumination effects, including reflections of other objects in the environment, are critical components to faithfully reproduce a scene. In this paper, we present Neural Directional Encoding (NDE), a view-dependent appearance encoding of neural radiance fields (NeRF) for rendering specular objects. NDE transfers the concept of feature-grid-based spatial encoding to the angular domain, significantly improving the ability to model high-frequency angular signals. In contrast to previous methods that use encoding functions with only angular input, we additionally cone-trace spatial features to obtain a spatially varying directional encoding, which addresses the challenging interreflection effects. Extensive experiments on both synthetic and real datasets show that a NeRF model with NDE (1) outperforms the state of the art on view synthesis of specular objects, and (2) works with small networks to allow fast (real-time) inference. The project webpage and source code are available at: \url{<a target="_blank" rel="noopener" href="https://lwwu2.github.io/nde/%7D">https://lwwu2.github.io/nde/}</a>.</p><p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2405.14847v1">PDF</a> Accepted to CVPR 2024</p><p><strong>Summary</strong><br>æå‡ºäº†ä¸€ç§åä¸ºNeural Directional Encodingï¼ˆNDEï¼‰çš„è§†å›¾ç›¸å…³å¤–è§‚ç¼–ç æ–¹æ³•ï¼Œç”¨äºç¥ç»è¾å°„åœºï¼ˆNeRFï¼‰æ¸²æŸ“é•œé¢å¯¹è±¡ï¼Œæé«˜äº†å¯¹é«˜é¢‘è§’ä¿¡å·çš„å»ºæ¨¡èƒ½åŠ›ã€‚</p><p><strong>Key Takeaways</strong><br>â€¢ é•œé¢å¯¹è±¡çš„æ–°è§†å›¾åˆæˆä»ç„¶æ˜¯ä¸€ä¸ªæŒ‘æˆ˜æ€§çš„é—®é¢˜ï¼Œéœ€è¦è€ƒè™‘å…¨çƒç…§æ˜æ•ˆæœå’Œå…¶ä»–å¯¹è±¡çš„åå°„ã€‚<br>â€¢ æå‡ºäº†Neural Directional Encodingï¼ˆNDEï¼‰ï¼Œä¸€ç§è§†å›¾ç›¸å…³çš„å¤–è§‚ç¼–ç æ–¹æ³•ï¼Œç”¨äºNeRFæ¸²æŸ“é•œé¢å¯¹è±¡ã€‚<br>â€¢ NDEå°†ç‰¹å¾ç½‘æ ¼åŸºäºçš„ç©ºé—´ç¼–ç æ¦‚å¿µè½¬ç§»åˆ°è§’åŸŸï¼Œæé«˜äº†å¯¹é«˜é¢‘è§’ä¿¡å·çš„å»ºæ¨¡èƒ½åŠ›ã€‚<br>â€¢ NDEä½¿ç”¨è§’è¾“å…¥å’Œç©ºé—´ç‰¹å¾æ¥è·å¾—ç©ºé—´å˜åŒ–çš„æ–¹å‘ç¼–ç ï¼Œè§£å†³äº†æŒ‘æˆ˜æ€§çš„äº¤å‰åå°„æ•ˆæœã€‚<br>â€¢ å®éªŒç»“æœè¡¨æ˜ï¼Œä½¿ç”¨NDEçš„NeRFæ¨¡å‹åœ¨é•œé¢å¯¹è±¡çš„è§†å›¾åˆæˆæ–¹é¢ä¼˜äºå½“å‰æœ€å…ˆè¿›çš„æ–¹æ³•ã€‚<br>â€¢ ä½¿ç”¨å°ç½‘ç»œå¯ä»¥å®ç°å¿«é€Ÿï¼ˆå®æ—¶ï¼‰æ¨ç†ã€‚<br>â€¢ é¡¹ç›®ç½‘é¡µå’Œæºä»£ç å·²ç»å…¬å¼€ï¼Œç½‘å€ä¸º<a target="_blank" rel="noopener" href="https://lwwu2.github.io/nde/%E3%80%82">https://lwwu2.github.io/nde/ã€‚</a></p><p><strong><a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p><ol><li><p>Title: ç¥ç»æ–¹å‘ç¼–ç ï¼ˆNeural Directional Encodingï¼‰</p></li><li><p>Authors: Liwen Wu, Sai Bi, Zexiang Xu, Fujun Luan, Kai Zhang, Iliyan Georgiev, Kalyan Sunkavalli, Ravi Ramamoorthi</p></li><li><p>Affiliation: åŠ å·å¤§å­¦åœ£åœ°äºšå“¥åˆ†æ ¡ï¼ˆUC San Diegoï¼‰</p></li><li><p>Keywords: Neural Radiance Fields, View-Dependent Appearance, Specular Objects, Novel-View Synthesis</p></li><li><p>Urls: <a target="_blank" rel="noopener" href="https://lwwu2.github.io/nde/">https://lwwu2.github.io/nde/</a>, Github:None</p></li><li><p>Summary:</p></li></ol><ul><li><p>(1):æœ¬æ–‡ç ”ç©¶èƒŒæ™¯æ˜¯æ–°è§†å›¾åˆæˆé¢†åŸŸï¼Œç‰¹åˆ«æ˜¯ specular å¯¹è±¡çš„æ–°è§†å›¾åˆæˆï¼Œæ—¨åœ¨æ¢å¤ç‰©ä½“çš„é«˜é¢‘è§†å›¾ä¾èµ–å¤–è§‚å’Œå…¨çƒç…§æ˜æ•ˆæœã€‚</p></li><li><p>(2):è¿‡å»çš„æ–¹æ³•ä½¿ç”¨åˆ†æå‡½æ•°å¯¹è§†å›¾æ–¹å‘è¿›è¡Œç¼–ç ï¼Œéœ€è¦å¤§å‹å¤šå±‚æ„ŸçŸ¥å™¨ï¼ˆMLPï¼‰ï¼Œæ”¶æ•›é€Ÿåº¦æ…¢ï¼Œæ— æ³•æ¨¡æ‹Ÿå¤æ‚çš„åå°„æ•ˆæœã€‚è¿™äº›æ–¹æ³•ä¹Ÿå¿½è§†äº†ç©ºé—´ç‰¹å¾å¯¹è§†å›¾ä¾èµ–å¤–è§‚çš„å½±å“ã€‚</p></li><li><p>(3):æœ¬æ–‡æå‡ºäº†ä¸€ç§ç¥ç»æ–¹å‘ç¼–ç ï¼ˆNDEï¼‰æ–¹æ³•ï¼Œå°†ç‰¹å¾ç½‘æ ¼ç¼–ç æ¦‚å¿µåº”ç”¨äºè§’åº¦åŸŸï¼Œé€šè¿‡ Ù…Ø®Ø±ÙˆØ·è¿½è¸ªç©ºé—´ç‰¹å¾è·å–ç©ºé—´å˜åŒ–çš„æ–¹å‘ç¼–ç ï¼Œè§£å†³äº† interreflection æ•ˆæœçš„æŒ‘æˆ˜ã€‚</p></li><li><p>(4):æœ¬æ–‡æ–¹æ³•åœ¨åˆæˆ specular å¯¹è±¡çš„æ–°è§†å›¾ä»»åŠ¡ä¸Šå–å¾—äº† state-of-the-art çš„æ€§èƒ½ï¼Œå¹¶ä¸”å¯ä»¥ä½¿ç”¨å°å‹ç½‘ç»œå®ç°å®æ—¶æ¨ç†ï¼Œæ»¡è¶³äº†å¿«é€Ÿåˆæˆçš„éœ€æ±‚ã€‚</p></li></ul><ol start="7"><li><p>Methods:</p><ul><li><p>(1): è¯¥æ–¹æ³•ä½¿ç”¨ç¥ç»æ–¹å‘ç¼–ç ï¼ˆNDEï¼‰æ¥å¯¹ç‰¹å¾ç½‘æ ¼è¿›è¡Œè§’åº¦åŸŸçš„ç¼–ç ï¼Œé€šè¿‡Ù…Ø®Ø±ÙˆØ·è¿½è¸ªç©ºé—´ç‰¹å¾è·å–ç©ºé—´å˜åŒ–çš„æ–¹å‘ç¼–ç ã€‚</p></li><li><p>(2): NDEæ–¹æ³•èƒ½å¤Ÿæœ‰æ•ˆè§£å†³interreflectionæ•ˆæœçš„æŒ‘æˆ˜ï¼Œæ¢å¤ç‰©ä½“çš„é«˜é¢‘è§†å›¾ä¾èµ–å¤–è§‚å’Œå…¨çƒç…§æ˜æ•ˆæœï¼Œè€Œæ— éœ€ä½¿ç”¨å¤§å‹å¤šå±‚æ„ŸçŸ¥å™¨ï¼ˆMLPï¼‰ã€‚</p></li><li><p>(3): è¯¥æ–¹æ³•å…·æœ‰å®æ—¶æ¨ç†çš„èƒ½åŠ›ï¼Œå¯ä»¥ä½¿ç”¨å°å‹ç½‘ç»œå®ç°å¿«é€Ÿåˆæˆï¼Œå¹¶åœ¨åˆæˆspecularå¯¹è±¡çš„æ–°è§†å›¾ä»»åŠ¡ä¸Šå–å¾—äº†state-of-the-artçš„æ€§èƒ½ã€‚</p></li></ul></li><li><p>Conclusion:</p><ul><li><p>(1):This piece of work is significant in advancing the field of novel-view synthesis, particularly in the synthesis of specular objects, by introducing a novel method, Neural Directional Encoding (NDE), which efficiently models complex reflections and achieves state-of-the-art performance.</p></li><li><p>(2):Innovation point: The article innovatively introduces the NDE method to efficiently model complex reflections for novel-view synthesis, addressing the limitations of previous methods.<br>Performance: The proposed method achieves state-of-the-art performance in synthesizing specular objects with the ability for real-time inference using a small network.<br>Workload: The workload is reduced as the method eliminates the need for large multi-layer perceptrons and enables real-time synthesis.</p></li></ul></li></ol><details><summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary><img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-b069231775fc8a2bd10f93cb80d839ec.jpg" align="middle"> <img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-75b217587db527ee5663a4499270caf9.jpg" align="middle"> <img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-abc9cca95d286eab225c623b7babb05b.jpg" align="middle"> <img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-2fce7139aa953d9627454cfadef62958.jpg" align="middle"> <img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-87061bf3e19ae720c7a849195745380a.jpg" align="middle"></details><h2 id="Camera-Relocalization-in-Shadow-free-Neural-Radiance-Fields"><a href="#Camera-Relocalization-in-Shadow-free-Neural-Radiance-Fields" class="headerlink" title="Camera Relocalization in Shadow-free Neural Radiance Fields"></a>Camera Relocalization in Shadow-free Neural Radiance Fields</h2><p><strong>Authors:Shiyao Xu, Caiyun Liu, Yuantao Chen, Zhenxin Zhu, Zike Yan, Yongliang Shi, Hao Zhao, Guyue Zhou</strong></p><p>Camera relocalization is a crucial problem in computer vision and robotics. Recent advancements in neural radiance fields (NeRFs) have shown promise in synthesizing photo-realistic images. Several works have utilized NeRFs for refining camera poses, but they do not account for lighting changes that can affect scene appearance and shadow regions, causing a degraded pose optimization process. In this paper, we propose a two-staged pipeline that normalizes images with varying lighting and shadow conditions to improve camera relocalization. We implement our scene representation upon a hash-encoded NeRF which significantly boosts up the pose optimization process. To account for the noisy image gradient computing problem in grid-based NeRFs, we further propose a re-devised truncated dynamic low-pass filter (TDLF) and a numerical gradient averaging technique to smoothen the process. Experimental results on several datasets with varying lighting conditions demonstrate that our method achieves state-of-the-art results in camera relocalization under varying lighting conditions. Code and data will be made publicly available.</p><p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2405.14824v1">PDF</a> Accepted by ICRA 2024. 8 pages, 5 figures, 3 tables. Codes and dataset: <a target="_blank" rel="noopener" href="https://github.com/hnrna/ShadowfreeNeRF-CameraReloc">https://github.com/hnrna/ShadowfreeNeRF-CameraReloc</a></p><p><strong>Summary</strong><br>æœ¬æ–‡æå‡ºäº†ä¸€ç§ä¸¤é˜¶æ®µæµæ°´çº¿ï¼Œç”¨äºè§„èŒƒå…·æœ‰ä¸åŒå…‰ç…§å’Œé˜´å½±æ¡ä»¶çš„å›¾åƒï¼Œä»¥æ”¹å–„ç›¸æœºé‡å®šä½ï¼Œå®ç°äº†åœ¨ä¸åŒå…‰ç…§æ¡ä»¶ä¸‹ç›¸æœºé‡å®šä½çš„æœ€æ–°æˆæœã€‚</p><p><strong>Key Takeaways</strong></p><ul><li>ç›¸æœºé‡å®šä½åœ¨è®¡ç®—æœºè§†è§‰å’Œæœºå™¨äººé¢†åŸŸæ˜¯ä¸€ä¸ªå…³é”®é—®é¢˜ã€‚</li><li>è¿‘æœŸå…³äºç¥ç»è¾å°„åœºï¼ˆNeRFsï¼‰çš„è¿›å±•æ˜¾ç¤ºå‡ºåˆæˆé€¼çœŸå›¾åƒçš„æ½œåŠ›ã€‚</li><li>ä¹‹å‰çš„å·¥ä½œåˆ©ç”¨NeRFsä¼˜åŒ–ç›¸æœºå§¿æ€ï¼Œä½†æœªè€ƒè™‘å¯èƒ½å½±å“åœºæ™¯å¤–è§‚å’Œé˜´å½±åŒºåŸŸçš„å…‰ç…§å˜åŒ–ï¼Œå¯¼è‡´å§¿æ€ä¼˜åŒ–è¿‡ç¨‹ä¸‹é™ã€‚</li><li>è¯¥è®ºæ–‡æå‡ºäº†ä¸€ç§åŸºäºå“ˆå¸Œç¼–ç çš„NeRFæ¥å®ç°åœºæ™¯è¡¨ç¤ºï¼Œæ˜¾è‘—æå‡äº†å§¿æ€ä¼˜åŒ–è¿‡ç¨‹ã€‚</li><li>ä¸ºè§£å†³ç½‘æ ¼å‹NeRFä¸­çš„å™ªå£°å›¾åƒæ¢¯åº¦è®¡ç®—é—®é¢˜ï¼Œè¿›ä¸€æ­¥æå‡ºäº†é‡æ–°è®¾è®¡çš„æˆªæ–­åŠ¨æ€ä½é€šæ»¤æ³¢å™¨ï¼ˆTDLFï¼‰å’Œæ•°å€¼æ¢¯åº¦å¹³å‡æŠ€æœ¯æ¥å¹³æ»‘å¤„ç†ã€‚</li><li>åœ¨å¤šä¸ªå…·æœ‰ä¸åŒå…‰ç…§æ¡ä»¶çš„æ•°æ®é›†ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨ä¸åŒå…‰ç…§æ¡ä»¶ä¸‹çš„ç›¸æœºé‡å®šä½ä¸­å–å¾—äº†æœ€æ–°çš„æˆæœã€‚</li><li>ä»£ç å’Œæ•°æ®å°†å…¬å¼€å‘å¸ƒã€‚</li></ul><p><strong><a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p><ol><li><p>Title: ç›¸æœºé‡å®šä½åœ¨æ— é˜´å½±ç¥ç»è¾å°„åœºä¸­ï¼ˆCamera Relocalization in Shadow-free Neural Radiance Fieldsï¼‰</p></li><li><p>Authors: Shiyao Xu, Caiyun Liu, Yuantao Chen, Zhenxin Zhu, Zike Yan, Yongliang Shi, Hao Zhao, Guyue Zhou</p></li><li><p>Affiliation: æ¸…åå¤§å­¦äººå·¥æ™ºèƒ½äº§ä¸šç ”ç©¶é™¢</p></li><li><p>Keywords: Camera Relocalization, Neural Radiance Fields, Shadow Removal</p></li><li><p>Urls: arXiv:2405.14824v1, Github: None</p></li><li><p>Summary:</p><ul><li><p>(1):æœ¬æ–‡ç ”ç©¶çš„èƒŒæ™¯æ˜¯è®¡ç®—æœºè§†è§‰å’Œæœºå™¨äººå­¦é¢†åŸŸä¸­çš„ç›¸æœºé‡å®šä½é—®é¢˜ï¼Œç›®æ ‡æ˜¯ä»ç»™å®šçš„å›¾åƒä¸­æ¢å¤æ‘„åƒæœºçš„ä½å§¿ã€‚</p></li><li><p>(2):è¿‡å»çš„æ–¹æ³•ä½¿ç”¨åˆ¤åˆ«ç½‘ç»œæˆ–NeRFæ¥refineæ‘„åƒæœºä½å§¿ï¼Œä½†æ˜¯è¿™äº›æ–¹æ³•ä¸èƒ½å¤„ç†å…‰ç…§å˜åŒ–å’Œé˜´å½±åŒºåŸŸå¯¹åœºæ™¯å¤–è§‚çš„å½±å“ï¼Œå¯¼è‡´ä½å§¿ä¼˜åŒ–è¿‡ç¨‹ä¸ç¨³å®šã€‚</p></li><li><p>(3):æœ¬æ–‡æå‡ºçš„æ–¹æ³•æ˜¯ä¸€ä¸ªä¸¤é˜¶æ®µçš„pipelineï¼Œé¦–å…ˆä½¿ç”¨é˜´å½±ç§»é™¤ç½‘ç»œå¯¹å›¾åƒè¿›è¡Œ normalizationï¼Œç„¶åä½¿ç”¨hashç¼–ç çš„NeRFæ¥refineæ‘„åƒæœºä½å§¿ï¼Œå¹¶æå‡ºäº†ä¸€ç§æ”¹è¿›çš„æ¢¯åº¦è®¡ç®—æ–¹æ³•æ¥å¹³æ»‘ä¼˜åŒ–è¿‡ç¨‹ã€‚</p></li><li><p>(4):å®éªŒç»“æœè¡¨æ˜ï¼Œæœ¬æ–‡çš„æ–¹æ³•åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šå–å¾—äº† state-of-the-art çš„ç»“æœï¼Œè¯æ˜äº†å…¶åœ¨ç›¸æœºé‡å®šä½ä»»åŠ¡ä¸­çš„æœ‰æ•ˆæ€§ã€‚</p></li></ul></li><li><p>æ–¹æ³•ï¼š</p></li></ol><ul><li><p>(1)ï¼šæœ¬æ–‡æå‡ºçš„æ–¹æ³•æ˜¯ä¸€ä¸ªä¸¤é˜¶æ®µçš„pipelineï¼Œé¦–å…ˆä½¿ç”¨é˜´å½±ç§»é™¤ç½‘ç»œï¼ˆShadow Removal Networkï¼ŒNshadowï¼‰å¯¹å›¾åƒè¿›è¡Œ normalizationï¼Œå¾—åˆ°é˜´å½±-freeå›¾åƒI(l0)ã€‚</p></li><li><p>(2)ï¼šç„¶åï¼Œä½¿ç”¨hashç¼–ç çš„NeRFï¼ˆNeural Radiance Fieldsï¼‰æ¨¡å‹å¯¹é˜´å½±-freeå›¾åƒI(l0)è¿›è¡Œåœºæ™¯é‡å»ºï¼Œå¾—åˆ°ä¸‰ç»´ç¥ç»åœºæ™¯å›¾Fã€‚</p></li><li><p>(3)ï¼šåœ¨poseä¼˜åŒ–é˜¶æ®µï¼Œä½¿ç”¨åŒæ ·çš„é˜´å½±ç§»é™¤ç½‘ç»œNshadowå¯¹æµ‹è¯•å›¾åƒè¿›è¡Œé˜´å½±ç§»é™¤ï¼Œå¾—åˆ°é˜´å½±-freeæµ‹è¯•å›¾åƒI(l0)ï¼Œç„¶åä½¿ç”¨æ¢¯åº¦ä¸‹é™ç®—æ³•ä¼˜åŒ–æ‘„åƒæœºposeï¼Œç›´åˆ°æ¸²æŸ“å›¾åƒË†I(l0)ä¸é˜´å½±-freeæµ‹è¯•å›¾åƒI(l0)ä¹‹é—´çš„å…‰åº¦lossè¾¾åˆ°æœ€å°ã€‚</p></li><li><p>(4)ï¼šä¸ºäº†æé«˜poseä¼˜åŒ–çš„ç¨³å®šæ€§ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§æ”¹è¿›çš„æ¢¯åº¦è®¡ç®—æ–¹æ³•ï¼Œä½¿ç”¨numerical gradient averagingæŠ€æœ¯æ¥å¹³æ»‘ä¼˜åŒ–è¿‡ç¨‹ã€‚</p></li><li><p>(5)ï¼šåœ¨poseä¼˜åŒ–è¿‡ç¨‹ä¸­ï¼Œæ–‡è¿˜ä½¿ç”¨äº†ä¸€ç§ç²—åˆ°ç»†çš„ä¼˜åŒ–ç­–ç•¥ï¼Œä½¿ç”¨truncated dynamic low-pass filterï¼ˆTDLFï¼‰æ¥åˆ†ç¦»é«˜é¢‘å’Œä½é¢‘å›¾åƒç»„ä»¶ï¼Œå¹¶é€æ¸å¢åŠ é«˜é¢‘ç»„ä»¶çš„æƒé‡ï¼Œä»¥é¿å…å±€éƒ¨æœ€ä¼˜è§£ã€‚</p></li><li><p>(6)ï¼šå®éªŒç»“æœè¡¨æ˜ï¼Œæœ¬æ–‡çš„æ–¹æ³•åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šå–å¾—äº†state-of-the-artçš„ç»“æœï¼Œè¯æ˜äº†å…¶åœ¨ç›¸æœºé‡å®šä½ä»»åŠ¡ä¸­çš„æœ‰æ•ˆæ€§ã€‚</p></li></ul><ol start="8"><li>Conclusion:</li></ol><ul><li><p>(1):æœ¬æ–‡çš„å·¥ä½œå¯¹äºè®¡ç®—æœºè§†è§‰å’Œæœºå™¨äººå­¦é¢†åŸŸä¸­çš„ç›¸æœºé‡å®šä½é—®é¢˜å…·æœ‰é‡è¦æ„ä¹‰ï¼Œå› ä¸ºå®ƒèƒ½å¤Ÿåœ¨æ— é˜´å½±ç¥ç»è¾å°„åœºä¸­å®ç°é«˜ç²¾åº¦çš„æ‘„åƒæœºé‡å®šä½ï¼Œä»è€Œæé«˜æœºå™¨äººçš„å¯¼èˆªå’Œå®šä½èƒ½åŠ›ã€‚</p></li><li><p>(2):Innovation point: æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„ä¸¤é˜¶æ®µpipelineï¼Œé¦–å…ˆä½¿ç”¨é˜´å½±ç§»é™¤ç½‘ç»œå¯¹å›¾åƒè¿›è¡Œ normalizationï¼Œç„¶åä½¿ç”¨hashç¼–ç çš„NeRFæ¨¡å‹å¯¹é˜´å½±-freeå›¾åƒè¿›è¡Œåœºæ™¯é‡å»ºï¼Œè¿™ç§æ–¹æ³•èƒ½å¤Ÿæœ‰æ•ˆåœ°å¤„ç†å…‰ç…§å˜åŒ–å’Œé˜´å½±åŒºåŸŸå¯¹åœºæ™¯å¤–è§‚çš„å½±å“Performance: å®éªŒç»“æœè¡¨æ˜ï¼Œæœ¬æ–‡çš„æ–¹æ³•åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šå–å¾—äº† state-of-the-art çš„ç»“æœï¼Œè¯æ˜äº†å…¶åœ¨ç›¸æœºé‡å®šä½ä»»åŠ¡ä¸­çš„æœ‰æ•ˆæ€§ï¼›Workload: æœ¬æ–‡çš„æ–¹æ³•éœ€è¦åœ¨è®­ç»ƒå’Œæµ‹è¯•é˜¶æ®µè¿›è¡Œå¤§é‡çš„è®¡ç®—å’Œä¼˜åŒ–ï¼Œéœ€è¦é«˜æ€§èƒ½çš„è®¡ç®—è®¾å¤‡å’Œå¤§é‡çš„æ•°æ®é›†æ”¯æŒã€‚</p></li></ul><details><summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary><img src="/medias/loading.gif" data-original="https://pica.zhimg.com/v2-6d260d5b744a5039554f8c6aaee9bc01.jpg" align="middle"> <img src="/medias/loading.gif" data-original="https://pic1.zhimg.com/v2-0ac90b20b3733ad747ec11650e963cf5.jpg" align="middle"> <img src="/medias/loading.gif" data-original="https://pic1.zhimg.com/v2-5a7748ef501582a143e2301b2e39f951.jpg" align="middle"> <img src="/medias/loading.gif" data-original="https://picx.zhimg.com/v2-0770bb34500dd5dd1e4632f197e96d71.jpg" align="middle"> <img src="/medias/loading.gif" data-original="https://pic1.zhimg.com/v2-9fdb4265248fa23783d77c10c673a037.jpg" align="middle"> <img src="/medias/loading.gif" data-original="https://pic1.zhimg.com/v2-1113a2498657772fa4f4f86d7876ebfc.jpg" align="middle"></details></div><hr><div class="reprint" id="reprint-statement"><div class="reprint__author"><span class="reprint-meta" style="font-weight:700"><i class="fas fa-user">æ–‡ç« ä½œè€…:</i></span> <span class="reprint-info"><a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a></span></div><div class="reprint__type"><span class="reprint-meta" style="font-weight:700"><i class="fas fa-link">æ–‡ç« é“¾æ¥:</i></span> <span class="reprint-info"><a href="https://kedreamix.github.io/Talk2Paper/Paper/2024-05-28/NeRF/">https://kedreamix.github.io/Talk2Paper/Paper/2024-05-28/NeRF/</a></span></div><div class="reprint__notice"><span class="reprint-meta" style="font-weight:700"><i class="fas fa-copyright">ç‰ˆæƒå£°æ˜:</i></span> <span class="reprint-info">æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨ <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a> è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº <a href="/Talk2Paper/about" target="_blank">Kedreamix</a> !</span></div></div><script async defer>function navToReprintStatement(){$("html, body").animate({scrollTop:$("#reprint-statement").offset().top-80},800)}document.addEventListener("copy",(function(t){M.toast({html:'<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>'})}))</script><div class="tag_share" style="display:block"><div class="post-meta__tag-list" style="display:inline-block"><div class="article-tag"><a href="/Talk2Paper/tags/NeRF/"><span class="chip bg-color">NeRF</span></a></div></div><div class="post_share" style="zoom:80%;width:fit-content;display:inline-block;float:right;margin:-.15rem 0"><link rel="stylesheet" href="/Talk2Paper/libs/share/css/share.min.css"><div id="article-share"><div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div><script src="/Talk2Paper/libs/share/js/social-share.min.js"></script></div></div></div></div></div><article id="prenext-posts" class="prev-next articles"><div class="row article-row"><div class="article col s12 m6" data-aos="fade-up"><div class="article-badge left-badge text-color"><i class="fas fa-chevron-left"></i> &nbsp;ä¸Šä¸€ç¯‡</div><div class="card"><a href="/Talk2Paper/Paper/2024-06-14/%E5%85%83%E5%AE%87%E5%AE%99_%E8%99%9A%E6%8B%9F%E4%BA%BA/"><div class="card-image"><img src="https://pic1.zhimg.com/v2-3afa9e67f614d591989be2744ada9ff8.jpg" class="responsive-img" alt="å…ƒå®‡å®™/è™šæ‹Ÿäºº"> <span class="card-title">å…ƒå®‡å®™/è™šæ‹Ÿäºº</span></div></a><div class="card-content article-content"><div class="summary block-with-text">å…ƒå®‡å®™/è™šæ‹Ÿäºº æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2024-06-14 Human 3Diffusion Realistic Avatar Creation via Explicit 3D Consistent Diffusion Models</div><div class="publish-info"><span class="publish-date"><i class="far fa-clock fa-fw icon-date"></i> 2024-06-14</span><span class="publish-author"><i class="fas fa-bookmark fa-fw icon-category"></i> <a href="/Talk2Paper/categories/%E5%85%83%E5%AE%87%E5%AE%99-%E8%99%9A%E6%8B%9F%E4%BA%BA/" class="post-category">å…ƒå®‡å®™/è™šæ‹Ÿäºº</a></span></div></div><div class="card-action article-tags"><a href="/Talk2Paper/tags/%E5%85%83%E5%AE%87%E5%AE%99-%E8%99%9A%E6%8B%9F%E4%BA%BA/"><span class="chip bg-color">å…ƒå®‡å®™/è™šæ‹Ÿäºº</span></a></div></div></div><div class="article col s12 m6" data-aos="fade-up"><div class="article-badge right-badge text-color">ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i></div><div class="card"><a href="/Talk2Paper/Paper/2024-05-28/3DGS/"><div class="card-image"><img src="https://pic1.zhimg.com/v2-8db132ec3c58c945a06898a8758b7480.jpg" class="responsive-img" alt="3DGS"> <span class="card-title">3DGS</span></div></a><div class="card-content article-content"><div class="summary block-with-text">3DGS æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2024-05-28 Feature Splatting for Better Novel View Synthesis with Low Overlap</div><div class="publish-info"><span class="publish-date"><i class="far fa-clock fa-fw icon-date"></i> 2024-05-28</span><span class="publish-author"><i class="fas fa-bookmark fa-fw icon-category"></i> <a href="/Talk2Paper/categories/3DGS/" class="post-category">3DGS</a></span></div></div><div class="card-action article-tags"><a href="/Talk2Paper/tags/3DGS/"><span class="chip bg-color">3DGS</span></a></div></div></div></div></article></div><script src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script><script src="/Talk2Paper/libs/codeBlock/codeLang.js"></script><script src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script><script src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script></div><div id="toc-aside" class="expanded col l3 hide-on-med-and-down"><div class="toc-widget card" style="background-color:#fff"><div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div><div id="toc-content"></div></div></div></div><div id="floating-toc-btn" class="hide-on-med-and-down"><a class="btn-floating btn-large bg-color"><i class="fas fa-list-ul"></i></a></div><script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script><script>$((function(){tocbot.init({tocSelector:"#toc-content",contentSelector:"#articleContent",headingsOffset:-(.4*$(window).height()-45),collapseDepth:Number("0"),headingSelector:"h2, h3, h4"});let t=parseInt(.4*$(window).height()-64),e=$(".toc-widget");$(window).scroll((function(){$(window).scrollTop()>t?e.addClass("toc-fixed"):e.removeClass("toc-fixed")}));const o="expanded";let n=$("#toc-aside"),i=$("#main-content");$("#floating-toc-btn .btn-floating").click((function(){n.hasClass(o)?(n.removeClass(o).hide(),i.removeClass("l9")):(n.addClass(o).show(),i.addClass("l9")),function(t,e){let o=$("#"+t);if(0===o.length)return;let n=o.width();n+=n>=450?21:n>=350&&n<450?18:n>=300&&n<350?16:14,$("#"+e).width(n)}("artDetail","prenext-posts")}))}))</script></main><footer class="page-footer bg-color"><link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css"><style>.aplayer .aplayer-lrc p{display:none;font-size:12px;font-weight:700;line-height:16px!important}.aplayer .aplayer-lrc p.aplayer-lrc-current{display:none;font-size:15px;color:#42b983}.aplayer.aplayer-fixed.aplayer-narrow .aplayer-body{left:-66px!important}.aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover{left:0!important}</style><div><div class="row"><meting-js class="col l8 offset-l2 m10 offset-m1 s12" server="netease" type="playlist" id="503838841" fixed="true" autoplay theme="#42b983" loop order="random" preload="auto" volume="0.7" list-folded="true"></meting-js></div></div><script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script><script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script><div class="container row center-align" style="margin-bottom:15px!important"><div class="col s12 m8 l8 copy-right">Copyright&nbsp;&copy; <span id="year">2024</span> <a href="/Talk2Paper/about" target="_blank">Kedreamix</a> |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a> |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a><br>&nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span class="white-color">5755.3k</span> <span id="busuanzi_container_site_pv">&nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;<span id="busuanzi_value_site_pv" class="white-color"></span></span> <span id="busuanzi_container_site_uv">&nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;<span id="busuanzi_value_site_uv" class="white-color"></span></span><br><span id="sitetime">Loading ...</span><script>var calcSiteTime=function(){var e=864e5,t=new Date,n="2024",i=t.getFullYear(),a=t.getMonth()+1,r=t.getDate(),s=t.getHours(),o=t.getMinutes(),g=t.getSeconds(),d=Date.UTC(n,"1","1","0","0","0"),m=Date.UTC(i,a,r,s,o,g)-d,l=Math.floor(m/31536e6),c=Math.floor(m/e-365*l);if(n===String(i)){document.getElementById("year").innerHTML=i;var u="This site has been running for "+c+" days";u="æœ¬ç«™å·²è¿è¡Œ "+c+" å¤©",document.getElementById("sitetime").innerHTML=u}else{document.getElementById("year").innerHTML=n+" - "+i;var T="This site has been running for "+l+" years and "+c+" days";T="æœ¬ç«™å·²è¿è¡Œ "+l+" å¹´ "+c+" å¤©",document.getElementById("sitetime").innerHTML=T}};calcSiteTime()</script><br></div><div class="col s12 m4 l4 social-link social-statis"><a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50"><i class="fab fa-github"></i></a><a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50"><i class="fas fa-envelope-open"></i></a> <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50"><i class="fab fa-zhihu1">çŸ¥</i></a></div></div></footer><div class="progress-bar"></div><div id="searchModal" class="modal"><div class="modal-content"><div class="search-header"><span class="title"><i class="fas fa-search"></i> &nbsp;&nbsp;æœç´¢</span> <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—" class="search-input"></div><div id="searchResult"></div></div></div><script>$((function(){!function(t,e,r){"use strict";$.ajax({url:t,dataType:"xml",success:function(t){var n=$("entry",t).map((function(){return{title:$("title",this).text(),content:$("content",this).text(),url:$("url",this).text()}})).get(),a=document.getElementById(e),s=document.getElementById(r);a.addEventListener("input",(function(){var t='<ul class="search-result-list">',e=this.value.trim().toLowerCase().split(/[\s\-]+/);s.innerHTML="",this.value.trim().length<=0||(n.forEach((function(r){var n=!0,a=r.title.trim().toLowerCase(),s=r.content.trim().replace(/<[^>]+>/g,"").toLowerCase(),i=r.url;i=0===i.indexOf("/")?r.url:"/"+i;var l=-1,c=-1,u=-1;if(""!==a&&""!==s&&e.forEach((function(t,e){l=a.indexOf(t),c=s.indexOf(t),l<0&&c<0?n=!1:(c<0&&(c=0),0===e&&(u=c))})),n){t+="<li><a href='"+i+"' class='search-result-title'>"+a+"</a>";var o=r.content.trim().replace(/<[^>]+>/g,"");if(u>=0){var h=u-20,f=u+80;h<0&&(h=0),0===h&&(f=100),f>o.length&&(f=o.length);var m=o.substr(h,f);e.forEach((function(t){var e=new RegExp(t,"gi");m=m.replace(e,'<em class="search-keyword">'+t+"</em>")})),t+='<p class="search-result">'+m+"...</p>"}t+="</li>"}})),t+="</ul>",s.innerHTML=t)}))}})}("/Talk2Paper/search.xml","searchInput","searchResult")}))</script><div class="stars-con"><div id="stars"></div><div id="stars2"></div><div id="stars3"></div></div><script>function switchNightMode(){$('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($("body")),setTimeout((function(){$("body").hasClass("DarkMode")?($("body").removeClass("DarkMode"),localStorage.setItem("isDark","0"),$("#sum-moon-icon").removeClass("fa-sun").addClass("fa-moon")):($("body").addClass("DarkMode"),localStorage.setItem("isDark","1"),$("#sum-moon-icon").addClass("fa-sun").removeClass("fa-moon")),setTimeout((function(){$(".Cuteen_DarkSky").fadeOut(1e3,(function(){$(this).remove()}))}),2e3)}))}</script><div id="backTop" class="top-scroll"><a class="btn-floating btn-large waves-effect waves-light" href="#!"><i class="fas fa-arrow-up"></i></a></div><script src="/Talk2Paper/libs/materialize/materialize.min.js"></script><script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script><script src="/Talk2Paper/libs/aos/aos.js"></script><script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script><script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script><script src="/Talk2Paper/js/matery.js"></script><script>var windowWidth=$(window).width();windowWidth>768&&document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>')</script><script src="https://ssl.captcha.qq.com/TCaptcha.js"></script><script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script><button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button><script>!function(){var t=document.createElement("script"),e=window.location.protocol.split(":")[0];t.src="https"===e?"https://zz.bdstatic.com/linksubmit/push.js":"http://push.zhanzhang.baidu.com/push.js";var s=document.getElementsByTagName("script")[0];s.parentNode.insertBefore(t,s)}()</script><script src="/Talk2Paper/libs/others/clicklove.js" async></script><script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script><script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script><script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({log:!1,pluginJsPath:"lib/",pluginModelPath:"assets/",pluginRootPath:"live2dw/",tagMode:!1})</script><style>[bg-lazy]{background-image:none!important;background-color:#eee!important}</style><script>window.imageLazyLoadSetting={isSPA:!1,preloadRatio:3,processImages:null}</script><script>window.addEventListener("load",(function(){var a=/\.(gif|jpg|jpeg|tiff|png)$/i,e=/^data:image\/[a-z\d\-\.\+]+;base64,/;Array.prototype.slice.call(document.querySelectorAll("img[data-original]")).forEach((function(t){var r=t.parentNode;"A"===r.tagName&&(a.test(r.href)||e.test(r.href))&&(r.href=t.dataset.original)}))}))</script><script>(t=>{t.imageLazyLoadSetting.processImages=n;var e=t.imageLazyLoadSetting.isSPA,a=t.imageLazyLoadSetting.preloadRatio||1,o=i();function i(){var t=Array.prototype.slice.call(document.querySelectorAll("img[data-original]")),e=Array.prototype.slice.call(document.querySelectorAll("[bg-lazy]"));return t.concat(e)}function n(n){(e||n)&&(o=i());for(var r,d=0;d<o.length;d++)0<=(r=(r=o[d]).getBoundingClientRect()).bottom&&0<=r.left&&r.top<=(t.innerHeight*a||document.documentElement.clientHeight*a)&&(()=>{var e,a,i,n,r=o[d];a=function(){o=o.filter((function(t){return r!==t})),t.imageLazyLoadSetting.onImageLoaded&&t.imageLazyLoadSetting.onImageLoaded(r)},(e=r).dataset.loaded||(e.hasAttribute("bg-lazy")?(e.removeAttribute("bg-lazy"),a&&a()):(i=new Image,n=e.getAttribute("data-original"),i.onload=function(){e.src=n,e.removeAttribute("data-original"),e.setAttribute("data-loaded",!0),a&&a()},i.onerror=function(){e.removeAttribute("data-original"),e.setAttribute("data-loaded",!1),e.src=n},e.src!==n&&(i.src=n)))})()}function r(){clearTimeout(n.tId),n.tId=setTimeout(n,500)}n(),document.addEventListener("scroll",r),t.addEventListener("resize",r),t.addEventListener("orientationchange",r)})(this)</script></body></html><script>var st,OriginTitile=document.title;document.addEventListener("visibilitychange",(function(){document.hidden?(document.title="Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ",clearTimeout(st)):(document.title="Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼",st=setTimeout((function(){document.title=OriginTitile}),3e3))}))</script>