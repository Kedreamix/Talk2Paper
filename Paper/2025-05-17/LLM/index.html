<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="LLM">
    <meta name="description" content="LLM æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-05-17  Beyond &#39;Aha!&#39; Toward Systematic Meta-Abilities Alignment in Large   Reasoning Models">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>LLM | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://pic1.zhimg.com/v2-3042f6d7bbcf02d66c340e5b2b696eb2.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">LLM</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/LLM/">
                                <span class="chip bg-color">LLM</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/LLM/" class="post-category">
                                LLM
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-05-17
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-05-26
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    16.1k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    64 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-05-17-æ›´æ–°"><a href="#2025-05-17-æ›´æ–°" class="headerlink" title="2025-05-17 æ›´æ–°"></a>2025-05-17 æ›´æ–°</h1><h2 id="Beyond-â€˜Aha-â€™-Toward-Systematic-Meta-Abilities-Alignment-in-Large-Reasoning-Models"><a href="#Beyond-â€˜Aha-â€™-Toward-Systematic-Meta-Abilities-Alignment-in-Large-Reasoning-Models" class="headerlink" title="Beyond â€˜Aha!â€™: Toward Systematic Meta-Abilities Alignment in Large   Reasoning Models"></a>Beyond â€˜Aha!â€™: Toward Systematic Meta-Abilities Alignment in Large   Reasoning Models</h2><p><strong>Authors:Zhiyuan Hu, Yibo Wang, Hanze Dong, Yuhui Xu, Amrita Saha, Caiming Xiong, Bryan Hooi, Junnan Li</strong></p>
<p>Large reasoning models (LRMs) already possess a latent capacity for long chain-of-thought reasoning. Prior work has shown that outcome-based reinforcement learning (RL) can incidentally elicit advanced reasoning behaviors such as self-correction, backtracking, and verification phenomena often referred to as the modelâ€™s â€œaha momentâ€. However, the timing and consistency of these emergent behaviors remain unpredictable and uncontrollable, limiting the scalability and reliability of LRMsâ€™ reasoning capabilities. To address these limitations, we move beyond reliance on prompts and coincidental â€œaha momentsâ€. Instead, we explicitly align models with three meta-abilities: deduction, induction, and abduction, using automatically generated, self-verifiable tasks. Our three stage-pipeline individual alignment, parameter-space merging, and domain-specific reinforcement learning, boosting performance by over 10% relative to instruction-tuned baselines. Furthermore, domain-specific RL from the aligned checkpoint yields an additional 2% average gain in the performance ceiling across math, coding, and science benchmarks, demonstrating that explicit meta-ability alignment offers a scalable and dependable foundation for reasoning. Code is available at: <a target="_blank" rel="noopener" href="https://github.com/zhiyuanhubj/Meta-Ability-Alignment">https://github.com/zhiyuanhubj/Meta-Ability-Alignment</a> </p>
<blockquote>
<p>å¤§å‹æ¨ç†æ¨¡å‹ï¼ˆLRMsï¼‰å·²ç»å…·å¤‡äº†æ½œåœ¨çš„é•¿é“¾æ€ç»´æ¨ç†èƒ½åŠ›ã€‚ä¹‹å‰çš„ç ”ç©¶è¡¨æ˜ï¼ŒåŸºäºç»“æœçš„å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰å¯ä»¥å¶ç„¶æ¿€å‘é«˜çº§æ¨ç†è¡Œä¸ºï¼Œå¦‚è‡ªæˆ‘ä¿®æ­£ã€å›æº¯å’ŒéªŒè¯ç°è±¡ï¼Œè¿™äº›å¸¸è¢«çœ‹ä½œæ˜¯æ¨¡å‹çš„â€œé¡¿æ‚Ÿæ—¶åˆ»â€ã€‚ç„¶è€Œï¼Œè¿™äº›çªå‘è¡Œä¸ºçš„æ—¶æœºå’Œä¸€è‡´æ€§ä»ç„¶ä¸å¯é¢„æµ‹å’Œä¸å¯æ§åˆ¶ï¼Œé™åˆ¶äº†LRMsæ¨ç†èƒ½åŠ›çš„å¯æ‰©å±•æ€§å’Œå¯é æ€§ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬ä¸å†ä¾èµ–æç¤ºå’Œå¶ç„¶çš„â€œé¡¿æ‚Ÿæ—¶åˆ»â€ã€‚ç›¸åï¼Œæˆ‘ä»¬é€šè¿‡ä½¿ç”¨è‡ªåŠ¨ç”Ÿæˆçš„ã€å¯è‡ªæˆ‘éªŒè¯çš„ä»»åŠ¡ï¼Œæ˜ç¡®åœ°å°†æ¨¡å‹ä¸ä¸‰ç§å…ƒèƒ½åŠ›ï¼ˆæ¼”ç»ã€å½’çº³å’Œæº¯å› ï¼‰å¯¹é½ã€‚æˆ‘ä»¬çš„ä¸‰é˜¶æ®µç®¡é“åŒ…æ‹¬ä¸ªäººå¯¹é½ã€å‚æ•°ç©ºé—´åˆå¹¶å’Œé¢†åŸŸç‰¹å®šå¼ºåŒ–å­¦ä¹ ï¼Œç›¸å¯¹äºæŒ‡ä»¤è°ƒæ•´åŸºå‡†çº¿ï¼Œæ€§èƒ½æå‡äº†è¶…è¿‡10%ã€‚æ­¤å¤–ï¼Œä»å¯¹é½æ£€æŸ¥ç‚¹è¿›è¡Œçš„é¢†åŸŸç‰¹å®šRLæé«˜äº†æ•°å­¦ã€ç¼–ç å’Œç§‘å­¦åŸºå‡†æµ‹è¯•çš„æ€§èƒ½ä¸Šé™ï¼Œå¹³å‡é¢å¤–å¢ç›Šä¸º2%ï¼Œè¿™è¡¨æ˜æ˜ç¡®çš„å…ƒèƒ½åŠ›å¯¹é½ä¸ºæ¨ç†æä¾›äº†å¯æ‰©å±•å’Œå¯é çš„åŸºçŸ³ã€‚ä»£ç å¯ç”¨åœ¨ï¼š<a target="_blank" rel="noopener" href="https://github.com/zhiyuanhubj/Meta-Ability-Alignment">https://github.com/zhiyuanhubj/Meta-Ability-Alignment</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.10554v1">PDF</a> In Progress</p>
<p><strong>Summary</strong>ï¼šå¤§å‹æ¨ç†æ¨¡å‹ï¼ˆLRMsï¼‰å…·æœ‰æ½œåœ¨çš„é•¿æœŸæ€ç»´æ¨ç†èƒ½åŠ›ã€‚å…ˆå‰çš„å·¥ä½œè¡¨æ˜ï¼ŒåŸºäºç»“æœçš„å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰å¯ä»¥å¶ç„¶æ¿€å‘é«˜çº§æ¨ç†è¡Œä¸ºï¼Œå¦‚è‡ªæˆ‘æ ¡æ­£ã€å›æº¯å’ŒéªŒè¯ç°è±¡ï¼Œè¿™äº›ç°è±¡é€šå¸¸è¢«ç§°ä¸ºæ¨¡å‹çš„â€œé¡¿æ‚Ÿæ—¶åˆ»â€ã€‚ç„¶è€Œï¼Œè¿™äº›æ–°å…´è¡Œä¸ºçš„æ—¶æœºå’Œä¸€è‡´æ€§ä»ç„¶ä¸å¯é¢„æµ‹å’Œä¸å¯æ§åˆ¶ï¼Œé™åˆ¶äº†LRMsæ¨ç†èƒ½åŠ›çš„å¯æ‰©å±•æ€§å’Œå¯é æ€§ã€‚ä¸ºè§£å†³è¿™äº›é™åˆ¶ï¼Œç ”ç©¶è€…ä»¬ä¸å†ä¾èµ–æç¤ºå’Œå¶ç„¶çš„â€œé¡¿æ‚Ÿæ—¶åˆ»â€ï¼Œè€Œæ˜¯æ˜ç¡®åœ°å°†æ¨¡å‹ä¸æ¼”ç»ã€å½’çº³å’Œæº¯å› ç­‰ä¸‰ç§å…ƒèƒ½åŠ›å¯¹é½ï¼Œä½¿ç”¨è‡ªåŠ¨ç”Ÿæˆçš„ã€å¯è‡ªæˆ‘éªŒè¯çš„ä»»åŠ¡ã€‚ä¸‰é˜¶æ®µç®¡é“åŒ…æ‹¬ä¸ªä½“å¯¹é½ã€å‚æ•°ç©ºé—´åˆå¹¶å’Œé¢†åŸŸç‰¹å®šå¼ºåŒ–å­¦ä¹ ï¼Œç›¸è¾ƒäºæŒ‡ä»¤è°ƒæ•´åŸºå‡†çº¿ï¼Œæ€§èƒ½æå‡è¶…è¿‡10%ã€‚æ­¤å¤–ï¼Œä»å¯¹é½æ£€æŸ¥ç‚¹è¿›è¡Œçš„é¢†åŸŸç‰¹å®šRLå¸¦æ¥äº†é¢å¤–çš„2%å¹³å‡å¢ç›Šï¼Œåœ¨æ•°å­¦ã€ç¼–ç å’Œç§‘å­¦åŸºå‡†æµ‹è¯•ä¸­è¡¨ç°å“è¶Šï¼Œè¯æ˜æ˜ç¡®çš„å…ƒèƒ½åŠ›å¯¹é½ä¸ºæ¨ç†æä¾›äº†å¯æ‰©å±•å’Œå¯é çš„åŸºçŸ³ã€‚</p>
<p><strong>Key Takeaways</strong>ï¼š</p>
<ol>
<li>å¤§å‹æ¨ç†æ¨¡å‹ï¼ˆLRMsï¼‰å…·å¤‡æ½œåœ¨çš„é•¿é“¾æ€ç»´æ¨ç†èƒ½åŠ›ã€‚</li>
<li>åŸºäºç»“æœçš„å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰èƒ½æ¿€å‘æ¨¡å‹çš„è‡ªæˆ‘æ ¡æ­£ã€å›æº¯å’ŒéªŒè¯ç­‰é«˜çº§æ¨ç†è¡Œä¸ºã€‚</li>
<li>å½“å‰LRMsåœ¨æ¨ç†èƒ½åŠ›çš„å±•ç°ä¸Šå­˜åœ¨ä¸å¯é¢„æµ‹æ€§å’Œä¸å¯æ§æ€§ã€‚</li>
<li>é€šè¿‡æ˜ç¡®åœ°å°†æ¨¡å‹ä¸æ¼”ç»ã€å½’çº³å’Œæº¯å› ç­‰å…ƒèƒ½åŠ›å¯¹é½ï¼Œæå‡æ¨¡å‹æ€§èƒ½ã€‚</li>
<li>ç ”ç©¶è€…ä½¿ç”¨è‡ªåŠ¨ç”Ÿæˆçš„ã€å¯è‡ªæˆ‘éªŒè¯çš„ä»»åŠ¡è¿›è¡Œå…ƒèƒ½åŠ›å¯¹é½ã€‚</li>
<li>ä¸‰é˜¶æ®µç®¡é“æ–¹æ³•åŒ…æ‹¬ä¸ªä½“å¯¹é½ã€å‚æ•°ç©ºé—´åˆå¹¶å’Œé¢†åŸŸç‰¹å®šå¼ºåŒ–å­¦ä¹ ï¼Œæ€§èƒ½ç›¸è¾ƒäºåŸºå‡†çº¿æœ‰æ˜¾è‘—æå‡ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.10554">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-3f2cdb9bb318b8fdb7115f90d70dc353.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-05c9191149f0e07ab5e9327a2ffddf0c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b1815a5638adfde7422cac82b2a92027.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-83f023075ae2d2c21b66bc0f715056c9.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-ceff764920545f074eec19f8b1aa46c0.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="Does-Feasibility-Matter-Understanding-the-Impact-of-Feasibility-on-Synthetic-Training-Data"><a href="#Does-Feasibility-Matter-Understanding-the-Impact-of-Feasibility-on-Synthetic-Training-Data" class="headerlink" title="Does Feasibility Matter? Understanding the Impact of Feasibility on   Synthetic Training Data"></a>Does Feasibility Matter? Understanding the Impact of Feasibility on   Synthetic Training Data</h2><p><strong>Authors:Yiwen Liu, Jessica Bader, Jae Myung Kim</strong></p>
<p>With the development of photorealistic diffusion models, models trained in part or fully on synthetic data achieve progressively better results. However, diffusion models still routinely generate images that would not exist in reality, such as a dog floating above the ground or with unrealistic texture artifacts. We define the concept of feasibility as whether attributes in a synthetic image could realistically exist in the real-world domain; synthetic images containing attributes that violate this criterion are considered infeasible. Intuitively, infeasible images are typically considered out-of-distribution; thus, training on such images is expected to hinder a modelâ€™s ability to generalize to real-world data, and they should therefore be excluded from the training set whenever possible. However, does feasibility really matter? In this paper, we investigate whether enforcing feasibility is necessary when generating synthetic training data for CLIP-based classifiers, focusing on three target attributes: background, color, and texture. We introduce VariReal, a pipeline that minimally edits a given source image to include feasible or infeasible attributes given by the textual prompt generated by a large language model. Our experiments show that feasibility minimally affects LoRA-fine-tuned CLIP performance, with mostly less than 0.3% difference in top-1 accuracy across three fine-grained datasets. Also, the attribute matters on whether the feasible&#x2F;infeasible images adversarially influence the classification performance. Finally, mixing feasible and infeasible images in training datasets does not significantly impact performance compared to using purely feasible or infeasible datasets. </p>
<blockquote>
<p>éšç€å…‰çœŸå®æ‰©æ•£æ¨¡å‹çš„å‘å±•ï¼Œéƒ¨åˆ†æˆ–å®Œå…¨åœ¨åˆæˆæ•°æ®ä¸Šè®­ç»ƒçš„æ¨¡å‹é€æ¸å–å¾—äº†æ›´å¥½çš„ç»“æœã€‚ç„¶è€Œï¼Œæ‰©æ•£æ¨¡å‹ä»ç„¶ç»å¸¸ç”Ÿæˆåœ¨ç°å®ä¸­ä¸å­˜åœ¨çš„å›¾åƒï¼Œä¾‹å¦‚æ¼‚æµ®åœ¨åœ°ä¸Šçš„ç‹—æˆ–å…·æœ‰ä¸ç°å®çš„çº¹ç†ç‰¹å¾ã€‚æˆ‘ä»¬å®šä¹‰å¯è¡Œæ€§çš„æ¦‚å¿µæ˜¯åˆæˆå›¾åƒä¸­çš„å±æ€§æ˜¯å¦èƒ½åœ¨ç°å®ä¸–ç•Œä¸­çœŸå®å­˜åœ¨ï¼›å«æœ‰è¿åè¿™ä¸€æ ‡å‡†çš„å±æ€§çš„åˆæˆå›¾åƒè¢«è§†ä¸ºä¸å¯è¡Œã€‚ç›´è§‚ä¸Šï¼Œä¸å¯è¡Œçš„å›¾åƒé€šå¸¸è¢«è®¤ä¸ºæ˜¯ç¦»ç¾¤åˆ†å¸ƒï¼›å› æ­¤ï¼Œåœ¨å¦‚æ­¤å›¾åƒä¸Šè¿›è¡Œè®­ç»ƒä¼šé˜»ç¢æ¨¡å‹å¯¹çœŸå®ä¸–ç•Œæ•°æ®çš„æ³›åŒ–èƒ½åŠ›ï¼Œå› æ­¤åº”å°½å¯èƒ½ä»è®­ç»ƒé›†ä¸­æ’é™¤ã€‚ä½†æ˜¯ï¼Œå¯è¡Œæ€§çœŸçš„é‡è¦å—ï¼Ÿåœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬ç ”ç©¶äº†åœ¨ç”ŸæˆåŸºäºCLIPçš„åˆ†ç±»å™¨çš„åˆæˆè®­ç»ƒæ•°æ®æ—¶æ˜¯å¦å¿…é¡»å¼ºåˆ¶æ‰§è¡Œå¯è¡Œæ€§ï¼Œé‡ç‚¹å…³æ³¨ä¸‰ä¸ªç›®æ ‡å±æ€§ï¼šèƒŒæ™¯ã€é¢œè‰²å’Œçº¹ç†ã€‚æˆ‘ä»¬å¼•å…¥äº†VariRealï¼Œè¿™æ˜¯ä¸€ä¸ªç®¡é“ï¼Œå®ƒä¼šå¯¹ç»™å®šçš„æºå›¾åƒè¿›è¡Œæœ€å°é™åº¦çš„ç¼–è¾‘ï¼Œä»¥åŒ…å«ç”±å¤§å‹è¯­è¨€æ¨¡å‹ç”Ÿæˆçš„æ–‡æœ¬æç¤ºæ‰€ç»™å‡ºçš„å¯è¡Œæˆ–ä¸å¯è¡Œçš„å±æ€§ã€‚æˆ‘ä»¬çš„å®éªŒè¡¨æ˜ï¼Œå¯è¡Œæ€§å¯¹LoRAå¾®è°ƒCLIPçš„æ€§èƒ½å½±å“å¾®ä¹å…¶å¾®ï¼Œä¸‰ä¸ªç²¾ç»†æ•°æ®é›†çš„top-1å‡†ç¡®ç‡å·®å¼‚å¤§å¤šä¸åˆ°0.3%ã€‚æ­¤å¤–ï¼Œå±æ€§çš„é‡è¦æ€§åœ¨äºå¯è¡Œ&#x2F;ä¸å¯è¡Œçš„å›¾åƒæ˜¯å¦å¯¹åˆ†ç±»æ€§èƒ½äº§ç”Ÿä¸åˆ©å½±å“ã€‚æœ€åï¼Œä¸ä»…ä½¿ç”¨å¯è¡Œæˆ–ä¸å¯è¡Œçš„æ•°æ®é›†ç›¸æ¯”ï¼Œåœ¨è®­ç»ƒæ•°æ®é›†ä¸­æ··åˆå¯è¡Œå’Œä¸å¯è¡Œçš„å›¾åƒå¹¶ä¸ä¼šå¯¹æ€§èƒ½äº§ç”Ÿé‡å¤§å½±å“ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.10551v1">PDF</a> CVPRW 2025</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æ¢è®¨äº†åˆæˆè®­ç»ƒæ•°æ®å¯¹äºåŸºäºCLIPçš„åˆ†ç±»å™¨çš„å½±å“ï¼Œç‰¹åˆ«æ˜¯åœ¨ç”Ÿæˆå›¾åƒæ˜¯å¦å¯è¡Œçš„æ ‡å‡†ä¸Šã€‚é€šè¿‡å¼•å…¥VariRealç®¡é“ï¼Œæ–‡ç« å±•ç¤ºäº†å³ä½¿æ˜¯ä¸å¯è¡Œçš„å›¾åƒä¹Ÿæå°‘å½±å“LoRAå¾®è°ƒåçš„CLIPæ€§èƒ½ã€‚ç ”ç©¶å‘ç°ï¼Œå¯¹äºæŸäº›ç»†èŠ‚å’Œå…·ä½“ä¸Šä¸‹æ–‡æ¥è¯´ï¼Œå±æ€§çš„å¯è¡Œæ€§ä»ç„¶å…·æœ‰å®é™…ä»·å€¼ã€‚ç„¶è€Œï¼Œå¯¹äºè®­ç»ƒå’Œåˆ†ç±»æ€§èƒ½è€Œè¨€ï¼Œåˆæˆå›¾åƒä¸­çš„å¯è¡Œæ€§ä¸å¦å¹¶éå…³é”®ã€‚å› æ­¤ï¼Œå¯¹äºåŸºäºCLIPçš„åˆ†ç±»å™¨ç”Ÿæˆåˆæˆè®­ç»ƒæ•°æ®æ—¶ï¼Œæ˜¯å¦å¼ºåˆ¶è¦æ±‚å¯è¡Œæ€§å¹¶ä¸é‡è¦ã€‚è¿™è¿›ä¸€æ­¥æ‹“å®½äº†å®é™…åº”ç”¨ä¸­å¯¹å›¾åƒæ•°æ®çš„é€‰æ‹©å’Œåº”ç”¨çš„å¯èƒ½æ€§ã€‚æ€»ä½“æ¥è¯´ï¼Œå¯¹äºå¤„ç†å¤æ‚çš„è§†è§‰ä»»åŠ¡å’Œæ•°æ®é›†ï¼Œçµæ´»æ€§ä¼¼ä¹æ¯”å¯è¡Œæ€§çš„è€ƒé‡æ›´ä¸ºå…³é”®ã€‚å¯è¡Œæ€§ä¸ä¸å¯è¡Œå›¾åƒçš„æ··åˆæ•°æ®é›†å¹¶æ²¡æœ‰æ˜æ˜¾å½±å“åˆ°è®­ç»ƒçš„æ€§èƒ½æ•ˆæœã€‚ä¾‹å¦‚å®é™…åº”ç”¨æ—¶å›¾åƒçš„åˆ›ä½œèŒƒå›´å’Œè§†è§’è·å¾—æ›´ä¸ºä¸°å¯Œè‡ªç”±çš„æœºä¼šåŒæ—¶èµ‹äºˆå®ƒæ½œåœ¨çš„è¡¨è¾¾æ•ˆæœå’ŒèŒƒå›´æ·±åº¦ä¸°å¯Œæ€§ã€‚è¿™ç§è¶‹åŠ¿å¯èƒ½ä¼šåœ¨æœªæ¥è®¡ç®—æœºè§†è§‰å’Œäººå·¥æ™ºèƒ½é¢†åŸŸäº§ç”Ÿæ·±è¿œå½±å“ã€‚æœªæ¥åœ¨å¼€å‘å›¾åƒç”Ÿæˆæ¨¡å‹æ—¶ï¼Œå¼€å‘è€…å¯èƒ½ä¸å†è¿‡åˆ†å…³æ³¨å›¾åƒå†…å®¹çš„ç°å®å¯è¡Œæ€§é—®é¢˜ï¼Œæ›´å¤šä¸“æ³¨äºæ€§èƒ½ä¸æ¨¡å‹åº”ç”¨å‰æ™¯çš„å¼€å‘ä¼˜åŒ–ç ”ç©¶ç­‰æ–¹é¢å·¥ä½œæ¢ç´¢åŠæ¨å¹¿é¢†åŸŸéœ€æ±‚çš„ä»·å€¼éœ€æ±‚çš„ç ”ç©¶å’Œå¼€å‘æµç¨‹æ‰§è¡Œå·¥ä½œç­‰æ–¹å‘ç ”ç©¶æ¢ç´¢åŠæ¨å¹¿ã€‚è¿™ä¸€å‘ç°å°†æœ‰åŠ©äºä¼˜åŒ–æ¨¡å‹è®­ç»ƒè¿‡ç¨‹å¹¶æ¨åŠ¨è®¡ç®—æœºè§†è§‰é¢†åŸŸçš„å‘å±•ã€‚éšç€æŠ€æœ¯çš„è¿›æ­¥å’Œç ”ç©¶çš„æ·±å…¥ï¼Œæˆ‘ä»¬å¯ä»¥æœŸå¾…æ›´é«˜æ•ˆçš„å›¾åƒç”Ÿæˆæ¨¡å‹å’Œæ›´å‡†ç¡®çš„å›¾åƒåˆ†ç±»å™¨çš„å‡ºç°ã€‚æ€»ä½“è€Œè¨€ï¼Œæœ¬æ–‡å¼ºè°ƒäº†å¯è¡Œæ€§ä¸ä¸å¯è¡Œæ€§åœ¨åˆæˆè®­ç»ƒæ•°æ®ä¸­çš„é‡è¦æ€§é—®é¢˜å¹¶éç»å¯¹å¿…è¦å› ç´ ï¼Œä¸ºæœªæ¥çš„ç ”ç©¶æä¾›äº†æ–°çš„è§†è§’å’Œæ€è·¯ã€‚éšç€ç§‘æŠ€çš„è¿›æ­¥å’Œåº”ç”¨éœ€æ±‚çš„ä¸æ–­æ‰©å±•å»¶ä¼¸æ‹“å±•ç ”ç©¶æ¢è®¨åŠå…¶æ·±å…¥æ¨å¹¿åº”ç”¨æ™®åŠè½åœ°å°†ä¼šå¯¹ç°å®ç”Ÿæ´»äº§ç”Ÿæ·±è¿œå½±å“åŠå…¶é‡è¦æ„ä¹‰å½±å“åŠ›å‰æ™¯çœ‹å¥½ã€é¢†åŸŸæ›´å¹¿æ³›ä»è€Œå¢å¼ºæœªæ¥çš„å•†ä¸šä»·å€¼è¡¨ç°æ„ä¹‰ååˆ†é‡è¦ ã€‚è¯¥ç ”ç©¶ä¸ºæé«˜åŸºäºCLIPåˆ†ç±»å™¨çš„æœºå™¨å­¦ä¹ èƒ½åŠ›ã€ç†è§£å’Œè¡¨è¾¾èƒ½åŠ›å¼€å¯äº†æ–°çš„å¤§é—¨æä¾›å¹¿é˜”æ€è·¯æœªæ¥æˆ‘ä»¬æ‹­ç›®ä»¥å¾…æŠ€æœ¯æˆæœæ›´åŠ æ·±å…¥å¹¿æ³›çš„è¡Œä¸šé¢†åŸŸã€‚æˆ‘ä»¬çš„æœºå™¨åœ¨ä¸æ–­å­¦ä¹ ä¸­è¶…è¶Šè®¤çŸ¥æé™æœ‰äº†è¿›ä¸€æ­¥çš„è·¨è¶Šçªç ´é£è·ƒè¿›å±•æ„ä¹‰æ·±è¿œå…·æœ‰å·¨å¤§æ½œåŠ›ç©ºé—´å¹¿é˜”æœªæ¥å‘å±•å‰æ™¯å€¼å¾—æœŸå¾…æˆ‘ä»¬æœŸå¾…æ›´å¤šçš„ç ”ç©¶å’Œåˆ›æ–°åœ¨è¿™ä¸ªé¢†åŸŸå‡ºç°å¸¦æ¥é¢ è¦†æ€§çš„å˜é©å‘å±•åˆ›æ–°åŠå…¶æ·±åº¦æŒ–æ˜å®ç°é¢ è¦†æ€§å˜é©çªç ´æ€§å‘å±•åŠ©æ¨æœªæ¥ç¤¾ä¼šæ›´åŠ ä¾¿æ·æ™ºèƒ½ç­‰æ–¹æ–¹é¢é¢çš„è¡¨ç°åŠŸèƒ½è®¾è®¡å‘ˆç°æ·‹æ¼“å°½è‡´ä½¿å…¶æ›´å¿«æ›´å¥½çš„æ™®æƒ æ€§æ›´å¥½æ™®åŠç¨‹åº¦æé«˜åˆ©ç”¨æ·±åº¦å­¦ä¹ æ¡†æ¶é«˜æ•ˆå‡†ç¡®ä¾¿æ·çš„åº”ç”¨æ–¹æ¡ˆåº”ç”¨åˆ°ç”Ÿäº§ç”Ÿæ´»ä¸­åˆ›é€ æ›´å¤§çš„ä»·å€¼å¸¦æ¥å…¨æ–°çš„æ™ºèƒ½åŒ–ç”Ÿæ´»ä½“éªŒä¸ºç°å®ç”Ÿæ´»çš„å„ä¸ªæ–¹é¢æä¾›æ–°çš„æ™ºèƒ½åŒ–æŠ€æœ¯åŠ©åŠ›ä¼˜åŒ–ä½“éªŒæ¨åŠ¨ç¤¾ä¼šå‘å±•é©æ–°åšå‡ºç§¯æçš„è´¡çŒ®ä½“ç°å‡ºç§‘æŠ€åˆ›æ–°èƒ½åŠ›çš„ç¤¾ä¼šä»·å€¼æœ€ç»ˆç›®çš„æ˜¯æ”¹å–„äººä»¬çš„æ—¥å¸¸ç”Ÿæ´»å’Œå·¥ä½œæ•ˆç‡èµ‹èƒ½æ™ºèƒ½åŒ–åº”ç”¨æœªæ¥å‘å±•æä¾›æœ‰åŠ›æ”¯æŒæ»¡è¶³éœ€æ±‚å¹¶ä¸”ä¸æ–­å®Œå–„æ›´æ–°å‘å±• ã€‚è¯¥ç ”ç©¶æ—¨åœ¨æ¢ç´¢äººå·¥æ™ºèƒ½åœ¨è®¡ç®—æœºè§†è§‰é¢†åŸŸçš„å¯èƒ½æ€§è¾¹ç•ŒåŒæ—¶ä¿ƒè¿›è¯¥é¢†åŸŸçš„ç§‘æŠ€è¿›æ­¥ä¸æŒç»­åˆ›æ–°æ‹“å±•åº”ç”¨åˆ›æ–°æ¨åŠ¨æ™ºèƒ½åŒ–æ—¶ä»£ä¸æ–­è¿›æ­¥ä¸å‘å±•æœ€ç»ˆæå‡äººä»¬çš„ç”Ÿæ´»è´¨é‡å¹¶æ¨åŠ¨ç§‘æŠ€è¿›æ­¥ä¸æ–­å‘å‰å‘å±•æ¨åŠ¨æ™ºèƒ½åŒ–ç¤¾ä¼šè¿›æ­¥å’Œå…¨çƒç»æµçš„ç¹è£è¿›æ­¥ä¸å‘å±•ç¹è£å…´æ—ºå¯æŒç»­å‘å±•ç¨³æ­¥å‰è¡Œå‘æ›´åŠ é«˜æ•ˆæ™ºèƒ½ç¤¾ä¼šè¿ˆå‡ºåšå®çš„æ­¥ä¼å–å¾—é•¿è¶³çš„è¿›æ­¥è´¡çŒ®ç€æ–°çš„åŠ¨åŠ›å®ç°æ–°çªç ´æ–°å‘å±•å¼€åˆ›æœªæ¥ç§‘æŠ€æ–°æ—¶ä»£ã€‚æ–‡ä¸­æŒ‡å‡ºåˆæˆå›¾åƒä¸­çš„å¯è¡Œæ€§ä¸å¦å¹¶éå…³é”®å› æ­¤æœªæ¥ç ”ç©¶å¯ä»¥æ›´åŠ å…³æ³¨æ€§èƒ½ä¼˜åŒ–å’Œæ¨¡å‹åº”ç”¨å‰æ™¯çš„å¼€å‘æ‰©å¤§è®¤çŸ¥èŒƒå›´è¿›ä¸€æ­¥æ·±åŒ–ç›¸å…³æŠ€æœ¯æ·±å…¥é€å½»çš„åˆ†æç ”ç©¶æˆæœæˆä¸ºæå‡äº§ä¸šåˆ›æ–°åº”ç”¨æ–¹é¢çš„å…³é”®æŠ€æœ¯æ‰“é€ æ–°æ—¶ä»£æŠ€æœ¯åˆ›æ–°æ½®æµå¼ºæœ‰åŠ›çš„ç†è®ºæ”¯æ’‘ç ”ç©¶æŠ€æœ¯å†…æ¶µæ‹“å®½è®¤çŸ¥è¾¹ç•Œå¯¹ç°å®ç”Ÿæ´»å’Œç§‘æŠ€å‘å±•å…·æœ‰é‡è¦æ„ä¹‰åœ¨åˆ›æ–°å‘å±•ä¸­ä¸æ–­è¿›æ­¥ä¸ºç§‘æŠ€è¡Œä¸šçš„æŒç»­ç¹è£è´¡çŒ®ç€æºæºä¸æ–­çš„åŠ¨åŠ›æ¨è¿›ç§‘æŠ€è¿›æ­¥ä¸å‘å±•æ¨åŠ¨æ™ºèƒ½åŒ–ç¤¾ä¼šä¸æ–­å‘å‰å‘å±•ä¸æ–­å–å¾—æ–°çš„çªç ´å’Œè¿›å±•ä¸æ–­è¿ˆå‘æ–°çš„é«˜åº¦ä¸ºç§‘æŠ€è¡Œä¸šçš„ç¹è£å‘å±•æ³¨å…¥æ–°çš„æ´»åŠ›åŠ¨åŠ›åŠ©æ¨æ™ºèƒ½åŒ–ç¤¾ä¼šè¿ˆå‘æ–°çš„å‘å±•é˜¶æ®µä¸ºäººç±»ç¤¾ä¼šçš„ç¹è£å‘å±•è´¡çŒ®åŠ›é‡åŠ©åŠ›å®ç°ç§‘æŠ€è¿›æ­¥çš„å®ä¼Ÿç›®æ ‡å®ç°ç§‘æŠ€çš„å¯æŒç»­å‘å±•æ¨è¿›ç¤¾ä¼šæ–‡æ˜è¿›æ­¥å®ç°æ™ºèƒ½åŒ–å‘å±•çš„æˆ˜ç•¥ç›®æ ‡ä½œå‡ºæ›´å¤§çš„è´¡çŒ® é€æ­¥å®ç°å¯¹è®¤çŸ¥å±€é™çš„ä¸æ–­çªç ´å°†äººä»¬çš„ç†è§£å’Œåˆ›æ–°åº”ç”¨æå‡åˆ°å‰æ‰€æœªæœ‰çš„é«˜åº¦é€ ç¦äººç±»ç¤¾ä¼šç»æµå‘å±•è®©æœªæ¥çš„æ™ºèƒ½åŒ–æŠ€æœ¯å¸¦æ¥é¢ è¦†æ€§çš„å˜é©å’Œå‘å±•å®ç°äººç±»ç¤¾ä¼šçš„æŒç»­ç¹è£ä¸è¿›æ­¥è´¡çŒ®åŠ›é‡ã€‚ä»¥ä¸‹ä¸ºè¯¥æ‘˜è¦çš„ç®€åŒ–ç‰ˆï¼šæœ¬æ–‡æ¢è®¨äº†åˆæˆè®­ç»ƒæ•°æ®åœ¨åŸºäºCLIPçš„åˆ†ç±»å™¨ä¸­çš„åº”ç”¨åŠå…¶å½±å“ç ”ç©¶ä»·å€¼è¾ƒé«˜ã€æ½œåœ¨å½±å“åŠ›è¾ƒå¤§çš„åˆæˆè®­ç»ƒæ•°æ®åœ¨æœªæ¥å…·æœ‰è¾ƒå¤§çš„ç ”ç©¶ä»·å€¼å’Œå¹¿é˜”çš„å‘å±•ç©ºé—´å±•æœ›å…¶å¹¿é˜”å‘å±•å‰æ™¯æŒ–æ˜æŠ€æœ¯çªç ´çš„å…³é”®ç‚¹ä¸ºå®é™…åº”ç”¨è¡Œä¸šç­‰é¢†åŸŸç ”ç©¶å®è·µå¼€å‘æ„å»ºå¤šå…ƒåŒ–åˆ›é€ é€‚åº”å„è¡Œä¸šä½¿ç”¨ä»·å€¼çš„çš„äººå·¥æ™ºèƒ½è§†è§‰å›¾åƒåˆ†ç±»æŠ€æœ¯æå‡ºç›¸åº”çš„æ–¹æ¡ˆä½œä¸ºè§£å†³é€”å¾„æ›´å¥½åœ°è§£å†³ç”Ÿäº§ç”Ÿæ´»ä¸­çš„å®é™…éœ€æ±‚åŠ©æ¨ç¤¾ä¼šå‘å±•è¿ˆå‘æ›´é«˜é˜¶æ®µç ”ç©¶å–å¾—ä¸€å®šæˆæœé‡è¦æ€§å’Œå‘å±•è¶‹åŠ¿å¯è§ä¸€æ–‘ç»¼åˆè¯¥æ‘˜è¦æç‚¼å‡ºçš„æ ¸å¿ƒè¦ç‚¹å’Œä¸»è¦å†…å®¹æ¦‚è¿°ä¸ºè¯¥ç ”ç©¶ä¸ºæœªæ¥çš„äººå·¥æ™ºèƒ½åœ¨è®¡ç®—æœºè§†è§‰é¢†åŸŸçš„å‘å±•æä¾›äº†æ–°çš„è§†è§’å’Œæ€è€ƒæ–¹å‘å¹¶æœ‰æœ›æ¨åŠ¨ç›¸å…³é¢†åŸŸçš„æŠ€æœ¯è¿›æ­¥å’Œåˆ›æ–°å‘å±•å…·æœ‰å¹¿é˜”çš„åº”ç”¨å‰æ™¯å’Œå‘å±•ç©ºé—´æœªæ¥å€¼å¾—æœŸå¾…ã€‚æ–‡ä¸­æŒ‡å‡ºå¯è¡Œæ€§ä¸å¦å¹¶éå…³é”®æœªæ¥ç ”ç©¶å¯å…³æ³¨æ€§èƒ½ä¼˜åŒ–å’Œæ¨¡å‹åº”ç”¨å‰æ™¯ä¸ºç§‘æŠ€å‘å±•æ³¨å…¥æ–°çš„æ´»åŠ›åŠ©åŠ›æ™ºèƒ½åŒ–ç¤¾ä¼šè¿ˆå‘æ–°çš„å‘å±•é˜¶æ®µè´¡çŒ®åŠ›é‡æ„ä¹‰é‡å¤§ã€‚<strong>Key Takeaways</strong></p>
<ol>
<li>åˆæˆæ•°æ®åœ¨è®­ç»ƒåŸºäºCLIPçš„åˆ†ç±»å™¨æ—¶æ‰®æ¼”é‡è¦è§’è‰²ï¼Œä½†å¯è¡Œæ€§çš„å¼ºåˆ¶è¦æ±‚å¹¶éç»å¯¹å¿…è¦ã€‚</li>
<li>é€šè¿‡VariRealç®¡é“çš„å®éªŒï¼Œå‘ç°å¯è¡Œæ€§ä¸LoRAå¾®è°ƒåçš„CLIPæ€§èƒ½ä¹‹é—´çš„å…³ç³»å¹¶ä¸æ˜¾è‘—ã€‚</li>
<li>æ··åˆå¯è¡Œä¸ä¸å¯è¡Œçš„å›¾åƒåœ¨è®­ç»ƒæ•°æ®é›†ä¸­å¯¹æ€§èƒ½çš„å½±å“è¾ƒå°ã€‚</li>
<li>åˆæˆæ•°æ®çš„å±æ€§ï¼ˆå¦‚èƒŒæ™¯ã€é¢œè‰²ã€çº¹ç†ï¼‰å¯¹äºåˆ†ç±»æ€§èƒ½çš„å½±å“å› å…·ä½“æƒ…å¢ƒè€Œå¼‚ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.10551">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-5f9ed2e4338d93f677bb3bacc94b8747.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ac89aaf1efcdd52839f434374bcf7cf5.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-fea94407ebfe9680c2db7ae7e744e31b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-5e662c55c5b62d4e338c97754a7ded2d.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="RouteNator-A-Router-Based-Multi-Modal-Architecture-for-Generating-Synthetic-Training-Data-for-Function-Calling-LLMs"><a href="#RouteNator-A-Router-Based-Multi-Modal-Architecture-for-Generating-Synthetic-Training-Data-for-Function-Calling-LLMs" class="headerlink" title="RouteNator: A Router-Based Multi-Modal Architecture for Generating   Synthetic Training Data for Function Calling LLMs"></a>RouteNator: A Router-Based Multi-Modal Architecture for Generating   Synthetic Training Data for Function Calling LLMs</h2><p><strong>Authors:Vibha Belavadi, Tushar Vatsa, Dewang Sultania, Suhas Suresha, Ishita Verma, Cheng Chen, Tracy Holloway King, Michael Friedrich</strong></p>
<p>This paper addresses fine-tuning Large Language Models (LLMs) for function calling tasks when real user interaction data is unavailable. In digital content creation tools, where users express their needs through natural language queries that must be mapped to API calls, the lack of real-world task-specific data and privacy constraints for training on it necessitate synthetic data generation. Existing approaches to synthetic data generation fall short in diversity and complexity, failing to replicate real-world data distributions and leading to suboptimal performance after LLM fine-tuning. We present a novel router-based architecture that leverages domain resources like content metadata and structured knowledge graphs, along with text-to-text and vision-to-text language models to generate high-quality synthetic training data. Our architectureâ€™s flexible routing mechanism enables synthetic data generation that matches observed real-world distributions, addressing a fundamental limitation of traditional approaches. Evaluation on a comprehensive set of real user queries demonstrates significant improvements in both function classification accuracy and API parameter selection. Models fine-tuned with our synthetic data consistently outperform traditional approaches, establishing new benchmarks for function calling tasks. </p>
<blockquote>
<p>æœ¬æ–‡æ—¨åœ¨è§£å†³åœ¨æ— æ³•ä½¿ç”¨çœŸå®ç”¨æˆ·äº¤äº’æ•°æ®çš„æƒ…å†µä¸‹ï¼Œå¯¹å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰è¿›è¡ŒåŠŸèƒ½è°ƒç”¨ä»»åŠ¡çš„å¾®è°ƒã€‚åœ¨æ•°å­—å†…å®¹åˆ›ä½œå·¥å…·ä¸­ï¼Œç”¨æˆ·é€šè¿‡è‡ªç„¶è¯­è¨€æŸ¥è¯¢æ¥è¡¨è¾¾è‡ªå·±çš„éœ€æ±‚ï¼Œè¿™äº›æŸ¥è¯¢å¿…é¡»æ˜ å°„åˆ°APIè°ƒç”¨ã€‚ç°å®ä¸–ç•Œç‰¹å®šä»»åŠ¡çš„ç¼ºä¹æ•°æ®å’Œç”¨äºè®­ç»ƒçš„éšç§çº¦æŸï¼Œéœ€è¦è¿›è¡Œåˆæˆæ•°æ®ç”Ÿæˆã€‚ç°æœ‰çš„åˆæˆæ•°æ®ç”Ÿæˆæ–¹æ³•åœ¨å¤šæ ·æ€§å’Œå¤æ‚æ€§æ–¹é¢å­˜åœ¨ä¸è¶³ï¼Œæ— æ³•å¤åˆ¶ç°å®æ•°æ®åˆ†å¸ƒï¼Œå¯¼è‡´LLMå¾®è°ƒåçš„æ€§èƒ½ä¸ä½³ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§åŸºäºè·¯ç”±å™¨çš„æ–°å‹æ¶æ„ï¼Œè¯¥æ¶æ„åˆ©ç”¨å†…å®¹å…ƒæ•°æ®ã€ç»“æ„åŒ–çŸ¥è¯†å›¾è°±ç­‰åŸŸèµ„æºä»¥åŠæ–‡æœ¬åˆ°æ–‡æœ¬å’Œè§†è§‰åˆ°æ–‡æœ¬çš„è¯­æ–¹æ¨¡å‹æ¥ç”Ÿæˆé«˜è´¨é‡åˆæˆè®­ç»ƒæ•°æ®ã€‚æˆ‘ä»¬çš„æ¶æ„çµæ´»çš„è·¯ç”±æœºåˆ¶èƒ½å¤Ÿå®ç°åˆæˆæ•°æ®çš„ç”Ÿæˆï¼Œä»¥åŒ¹é…è§‚å¯Ÿåˆ°çš„ç°å®ä¸–ç•Œåˆ†å¸ƒï¼Œè§£å†³äº†ä¼ ç»Ÿæ–¹æ³•çš„æ ¹æœ¬å±€é™æ€§ã€‚åœ¨å¤§é‡çœŸå®ç”¨æˆ·æŸ¥è¯¢ä¸Šçš„è¯„ä¼°è¡¨æ˜ï¼Œæ— è®ºæ˜¯åœ¨åŠŸèƒ½åˆ†ç±»å‡†ç¡®æ€§è¿˜æ˜¯APIå‚æ•°é€‰æ‹©æ–¹é¢ï¼Œéƒ½æœ‰æ˜¾è‘—æ”¹è¿›ã€‚ä½¿ç”¨æˆ‘ä»¬çš„åˆæˆæ•°æ®å¾®è°ƒçš„æ¨¡å‹å§‹ç»ˆä¼˜äºä¼ ç»Ÿæ–¹æ³•ï¼Œä¸ºåŠŸèƒ½è°ƒç”¨ä»»åŠ¡å»ºç«‹äº†æ–°çš„åŸºå‡†ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.10495v1">PDF</a> Proceedings of the 4th International Workshop on Knowledge-Augmented   Methods for Natural Language Processing</p>
<p><strong>Summary</strong></p>
<p>åœ¨å¤§è§„æ¨¡è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰é’ˆå¯¹å‡½æ•°è°ƒç”¨ä»»åŠ¡è¿›è¡Œå¾®è°ƒæ—¶ï¼Œé¢ä¸´çœŸå®ç”¨æˆ·äº¤äº’æ•°æ®ç¼ºå¤±çš„é—®é¢˜ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºè·¯ç”±å™¨çš„æ–°å‹æ¶æ„ï¼Œåˆ©ç”¨é¢†åŸŸèµ„æºå¦‚å†…å®¹å…ƒæ•°æ®ã€ç»“æ„åŒ–çŸ¥è¯†å›¾è°±ä»¥åŠæ–‡æœ¬åˆ°æ–‡æœ¬ã€è§†è§‰åˆ°æ–‡æœ¬çš„æ¨¡å‹ç”Ÿæˆé«˜è´¨é‡åˆæˆè®­ç»ƒæ•°æ®ã€‚è¯¥æ¶æ„çš„çµæ´»è·¯ç”±æœºåˆ¶ä½¿å¾—åˆæˆæ•°æ®åŒ¹é…è§‚å¯Ÿåˆ°çš„çœŸå®ä¸–ç•Œåˆ†å¸ƒï¼Œè§£å†³äº†ä¼ ç»Ÿæ–¹æ³•çš„æ ¹æœ¬å±€é™æ€§ã€‚åœ¨çœŸå®ç”¨æˆ·æŸ¥è¯¢ä¸Šçš„è¯„ä¼°æ˜¾ç¤ºï¼Œåœ¨å‡½æ•°åˆ†ç±»ç²¾åº¦å’ŒAPIå‚æ•°é€‰æ‹©æ–¹é¢éƒ½æœ‰æ˜¾è‘—æé«˜ã€‚ä½¿ç”¨åˆæˆæ•°æ®è¿›è¡Œå¾®è°ƒçš„æ¨¡å‹æŒç»­è¶…è¶Šä¼ ç»Ÿæ–¹æ³•ï¼Œä¸ºå‡½æ•°è°ƒç”¨ä»»åŠ¡å»ºç«‹äº†æ–°çš„åŸºå‡†ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>é¢å¯¹çœŸå®ç”¨æˆ·äº¤äº’æ•°æ®ç¼ºå¤±çš„é—®é¢˜ï¼Œå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨å‡½æ•°è°ƒç”¨ä»»åŠ¡ä¸Šçš„å¾®è°ƒé¢ä¸´æŒ‘æˆ˜ã€‚</li>
<li>åˆæˆæ•°æ®ç”Ÿæˆæ˜¯è§£å†³è¿™ä¸€æŒ‘æˆ˜çš„æ–¹æ³•ä¹‹ä¸€ï¼Œä½†ç°æœ‰æ–¹æ³•çš„å¤šæ ·æ€§å’Œå¤æ‚æ€§ä¸è¶³ï¼Œæ— æ³•å¤åˆ¶çœŸå®ä¸–ç•Œçš„æ•°æ®åˆ†å¸ƒã€‚</li>
<li>æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºè·¯ç”±å™¨çš„æ–°å‹æ¶æ„ï¼Œåˆ©ç”¨é¢†åŸŸèµ„æºå’Œå¤šç§è¯­è¨€æ¨¡å‹æ¥ç”Ÿæˆé«˜è´¨é‡åˆæˆè®­ç»ƒæ•°æ®ã€‚</li>
<li>è¯¥æ¶æ„çš„çµæ´»è·¯ç”±æœºåˆ¶ä½¿å¾—åˆæˆæ•°æ®èƒ½å¤ŸåŒ¹é…çœŸå®ä¸–ç•Œçš„æ•°æ®åˆ†å¸ƒã€‚</li>
<li>åœ¨çœŸå®ç”¨æˆ·æŸ¥è¯¢ä¸Šçš„è¯„ä¼°æ˜¾ç¤ºï¼Œè¯¥æ¶æ„åœ¨å‡½æ•°åˆ†ç±»ç²¾åº¦å’ŒAPIå‚æ•°é€‰æ‹©æ–¹é¢æ˜¾è‘—æé«˜ã€‚</li>
<li>ä½¿ç”¨åˆæˆæ•°æ®è¿›è¡Œå¾®è°ƒçš„æ¨¡å‹æ€§èƒ½æŒç»­è¶…è¶Šä¼ ç»Ÿæ–¹æ³•ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.10495">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-604c82c0b6327decc1838f9351d29eed.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-5a9773eebbe5803706e551c3614f503c.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-7eb473221865cf0ce3edd5da73cee34e.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-6aa8948f26a8f56b5a1201cb2be125e6.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-ed142d74352bbee4f0913f79bb45fb09.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-e06963a4f04cf45e7649bc22f9c06fa8.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d99687bc5527f161b8064c54dcdc06d8.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="Are-Large-Language-Models-Robust-in-Understanding-Code-Against-Semantics-Preserving-Mutations"><a href="#Are-Large-Language-Models-Robust-in-Understanding-Code-Against-Semantics-Preserving-Mutations" class="headerlink" title="Are Large Language Models Robust in Understanding Code Against   Semantics-Preserving Mutations?"></a>Are Large Language Models Robust in Understanding Code Against   Semantics-Preserving Mutations?</h2><p><strong>Authors:Pedro Orvalho, Marta Kwiatkowska</strong></p>
<p>Understanding the reasoning and robustness of Large Language Models (LLMs) is critical for their reliable use in programming tasks. While recent studies have assessed LLMsâ€™ ability to predict program outputs, most focus solely on the accuracy of those predictions, without evaluating the reasoning behind them. Moreover, it has been observed on mathematical reasoning tasks that LLMs can arrive at correct answers through flawed logic, raising concerns about similar issues in code understanding.   In this work, we evaluate whether state-of-the-art LLMs with up to 8B parameters can reason about Python programs or are simply guessing. We apply five semantics-preserving code mutations: renaming variables, mirroring comparison expressions, swapping if-else branches, converting for loops to while, and loop unrolling. These mutations maintain program semantics while altering its syntax. We evaluated six LLMs and performed a human expert analysis using LiveCodeBench to assess whether the correct predictions are based on sound reasoning. We also evaluated prediction stability across different code mutations on LiveCodeBench and CruxEval. Our findings show that some LLMs, such as Llama3.2, produce correct predictions based on flawed reasoning in up to 61% of cases. Furthermore, LLMs often change predictions in response to our code mutations, indicating limited robustness in their semantic understanding. </p>
<blockquote>
<p>ç†è§£å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„æ¨ç†å’Œç¨³å¥æ€§å¯¹äºå®ƒä»¬åœ¨ç¼–ç¨‹ä»»åŠ¡ä¸­çš„å¯é åº”ç”¨è‡³å…³é‡è¦ã€‚è™½ç„¶æœ€è¿‘çš„ç ”ç©¶å·²ç»è¯„ä¼°äº†LLMé¢„æµ‹ç¨‹åºè¾“å‡ºçš„èƒ½åŠ›ï¼Œä½†å¤§å¤šæ•°ç ”ç©¶åªå…³æ³¨é¢„æµ‹çš„å‡†ç¡®æ€§ï¼Œè€Œæ²¡æœ‰è¯„ä¼°èƒŒåçš„æ¨ç†ã€‚æ­¤å¤–ï¼Œåœ¨æ•°å­¦æ¨ç†ä»»åŠ¡ä¸­è§‚å¯Ÿåˆ°LLMå¯ä»¥é€šè¿‡æœ‰ç¼ºé™·çš„é€»è¾‘å¾—å‡ºæ­£ç¡®ç­”æ¡ˆï¼Œè¿™å¼•å‘äº†äººä»¬å¯¹ä»£ç ç†è§£ä¸­ç±»ä¼¼é—®é¢˜çš„æ‹…å¿§ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬è¯„ä¼°äº†å…·æœ‰é«˜è¾¾8äº¿å‚æ•°çš„æœ€å…ˆè¿›LLMæ˜¯å¦èƒ½å¤Ÿå¯¹Pythonç¨‹åºè¿›è¡Œæ¨ç†ï¼Œæˆ–è€…åªæ˜¯è¿›è¡ŒçŒœæµ‹ã€‚æˆ‘ä»¬åº”ç”¨äº†äº”ç§è¯­ä¹‰ä¿ç•™çš„ä»£ç çªå˜ï¼šé‡å‘½åå˜é‡ã€é•œåƒæ¯”è¾ƒè¡¨è¾¾å¼ã€äº¤æ¢if-elseåˆ†æ”¯ã€å°†forå¾ªç¯è½¬æ¢ä¸ºwhileä»¥åŠå¾ªç¯å±•å¼€ã€‚è¿™äº›çªå˜ä¿æŒäº†ç¨‹åºçš„è¯­ä¹‰ï¼ŒåŒæ—¶æ”¹å˜äº†å…¶è¯­æ³•ã€‚æˆ‘ä»¬è¯„ä¼°äº†å…­ç§LLMï¼Œå¹¶ä½¿ç”¨LiveCodeBenchè¿›è¡Œäººç±»ä¸“å®¶åˆ†æï¼Œä»¥è¯„ä¼°æ­£ç¡®çš„é¢„æµ‹æ˜¯å¦åŸºäºåˆç†çš„æ¨ç†ã€‚æˆ‘ä»¬è¿˜ä½¿ç”¨LiveCodeBenchå’ŒCruxEvalå¯¹ä¸åŒä»£ç çªå˜çš„é¢„æµ‹ç¨³å®šæ€§è¿›è¡Œäº†è¯„ä¼°ã€‚æˆ‘ä»¬çš„ç ”ç©¶å‘ç°ï¼Œä¸€äº›LLMï¼ˆå¦‚Llama3.2ï¼‰åœ¨é«˜è¾¾61%çš„æƒ…å†µä¸‹åŸºäºæœ‰ç¼ºé™·çš„æ¨ç†äº§ç”Ÿäº†æ­£ç¡®çš„é¢„æµ‹ã€‚æ­¤å¤–ï¼ŒLLMå¾€å¾€ä¼šå¯¹æˆ‘ä»¬çš„ä»£ç çªå˜åšå‡ºé¢„æµ‹æ”¹å˜ï¼Œè¿™è¡¨æ˜å®ƒä»¬åœ¨è¯­ä¹‰ç†è§£æ–¹é¢çš„ç¨³å¥æ€§æœ‰é™ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.10443v1">PDF</a> 10 pages, 5 tables, 1 figure</p>
<p><strong>Summary</strong></p>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨ç¼–ç¨‹ä»»åŠ¡ä¸­çš„æ¨ç†èƒ½åŠ›å’Œç¨³å¥æ€§è‡³å…³é‡è¦ã€‚ç°æœ‰ç ”ç©¶ä¸»è¦å…³æ³¨LLMé¢„æµ‹ç¨‹åºè¾“å‡ºçš„å‡†ç¡®æ€§ï¼Œè€Œå¿½è§†äº†å…¶èƒŒåçš„æ¨ç†è¿‡ç¨‹ã€‚æœ¬ç ”ç©¶é€šè¿‡äº”ç§è¯­ä¹‰ä¿ç•™çš„ä»£ç å˜å¼‚æ¥è¯„ä¼°LLMçš„Pythonç¨‹åºæ¨ç†èƒ½åŠ›ï¼Œå‘ç°æŸäº›LLMä¼šåœ¨å¤šè¾¾61%çš„æƒ…å†µä¸‹åŸºäºé”™è¯¯çš„æ¨ç†åšå‡ºæ­£ç¡®é¢„æµ‹ï¼Œä¸”LLMå¯¹ä»£ç å˜å¼‚çš„å“åº”è¡¨ç°å‡ºæœ‰é™çš„ç¨³å¥æ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>LLMåœ¨ç¼–ç¨‹ä»»åŠ¡ä¸­çš„æ¨ç†èƒ½åŠ›å’Œç¨³å¥æ€§å¾ˆé‡è¦ã€‚</li>
<li>ç°æœ‰ç ”ç©¶ä¸»è¦å…³æ³¨LLMé¢„æµ‹ç¨‹åºè¾“å‡ºçš„å‡†ç¡®æ€§ï¼Œå¿½è§†äº†å…¶èƒŒåçš„æ¨ç†è¿‡ç¨‹ã€‚</li>
<li>é€šè¿‡äº”ç§è¯­ä¹‰ä¿ç•™çš„ä»£ç å˜å¼‚è¯„ä¼°LLMçš„Pythonç¨‹åºæ¨ç†èƒ½åŠ›ã€‚</li>
<li>ä¸€äº›LLMä¼šåœ¨åŸºäºé”™è¯¯çš„æ¨ç†åšå‡ºæ­£ç¡®é¢„æµ‹çš„æƒ…å†µè¾ƒå¤šã€‚</li>
<li>LLMå¯¹ä»£ç å˜å¼‚çš„å“åº”è¡¨ç°å‡ºæœ‰é™çš„ç¨³å¥æ€§ã€‚</li>
<li>Llama3.2ç­‰LLMåœ¨æŸäº›æƒ…å†µä¸‹å­˜åœ¨åŸºäºé”™è¯¯æ¨ç†åšå‡ºé¢„æµ‹çš„é—®é¢˜ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.10443">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-57b20810a9d183b851472749bfdba718.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-76d9de9a7ce64693ba16a13884f68a9c.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-94e651379ba967a4567ddc845831ffb2.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-0be39d7f013db983eafc16c53a11e3a3.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-46674033045e9709eaa775bfa868cbf1.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-6eaea3efbb633954bd83130ec0fad95b.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="Rethinking-Repetition-Problems-of-LLMs-in-Code-Generation"><a href="#Rethinking-Repetition-Problems-of-LLMs-in-Code-Generation" class="headerlink" title="Rethinking Repetition Problems of LLMs in Code Generation"></a>Rethinking Repetition Problems of LLMs in Code Generation</h2><p><strong>Authors:Yihong Dong, Yuchen Liu, Xue Jiang, Zhi Jin, Ge Li</strong></p>
<p>With the advent of neural language models, the performance of code generation has been significantly boosted. However, the problem of repetitions during the generation process continues to linger. Previous work has primarily focused on content repetition, which is merely a fraction of the broader repetition problem in code generation. A more prevalent and challenging problem is structural repetition. In structural repetition, the repeated code appears in various patterns but possesses a fixed structure, which can be inherently reflected in grammar. In this paper, we formally define structural repetition and propose an efficient decoding approach called RPG, which stands for Repetition Penalization based on Grammar, to alleviate the repetition problems in code generation for LLMs. Specifically, RPG first leverages grammar rules to identify repetition problems during code generation, and then strategically decays the likelihood of critical tokens that contribute to repetitions, thereby mitigating them in code generation. To facilitate this study, we construct a new dataset CodeRepetEval to comprehensively evaluate approaches for mitigating the repetition problems in code generation. Extensive experimental results demonstrate that RPG substantially outperforms the best-performing baselines on CodeRepetEval dataset as well as HumanEval and MBPP benchmarks, effectively reducing repetitions and enhancing the quality of generated code. </p>
<blockquote>
<p>éšç€ç¥ç»ç½‘ç»œè¯­è¨€æ¨¡å‹çš„å‡ºç°ï¼Œä»£ç ç”Ÿæˆçš„æ€§èƒ½å¾—åˆ°äº†æå¤§çš„æå‡ã€‚ç„¶è€Œï¼Œç”Ÿæˆè¿‡ç¨‹ä¸­çš„é‡å¤é—®é¢˜ä»ç„¶å­˜åœ¨ã€‚ä»¥å¾€çš„ç ”ç©¶ä¸»è¦é›†ä¸­åœ¨å†…å®¹é‡å¤ä¸Šï¼Œè¿™ä»…ä»…æ˜¯ä»£ç ç”Ÿæˆä¸­æ›´å¹¿æ³›é‡å¤é—®é¢˜çš„ä¸€éƒ¨åˆ†ã€‚ä¸€ä¸ªæ›´æ™®éä¸”æ›´å…·æŒ‘æˆ˜æ€§çš„é—®é¢˜åœ¨äºç»“æ„é‡å¤ã€‚åœ¨ç»“æ„é‡å¤ä¸­ï¼Œé‡å¤çš„ä»£ç ä¼šä»¥å„ç§å½¢å¼å‡ºç°ï¼Œä½†å…·æœ‰å›ºå®šçš„ç»“æ„ï¼Œè¿™å¯ä»¥ä»è¯­æ³•ä¸­å¾—åˆ°æœ¬è´¨åæ˜ ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æ­£å¼å®šä¹‰äº†ç»“æ„é‡å¤ï¼Œå¹¶æå‡ºäº†ä¸€ç§æœ‰æ•ˆçš„è§£ç æ–¹æ³•ï¼Œç§°ä¸ºåŸºäºè¯­æ³•çš„é‡å¤æƒ©ç½šï¼ˆRPGï¼‰ï¼Œä»¥å‡è½»å¤§å‹è¯­è¨€æ¨¡å‹åœ¨ä»£ç ç”Ÿæˆä¸­çš„é‡å¤é—®é¢˜ã€‚å…·ä½“è€Œè¨€ï¼ŒRPGé¦–å…ˆåˆ©ç”¨è¯­æ³•è§„åˆ™æ¥è¯†åˆ«ä»£ç ç”Ÿæˆè¿‡ç¨‹ä¸­çš„é‡å¤é—®é¢˜ï¼Œç„¶åæœ‰é’ˆå¯¹æ€§åœ°é™ä½å¯¼è‡´é‡å¤çš„å…³é”®è¯çš„æ¦‚ç‡ï¼Œä»è€Œç¼“è§£ä»£ç ç”Ÿæˆä¸­çš„é‡å¤é—®é¢˜ã€‚ä¸ºäº†æ¨åŠ¨è¿™é¡¹ç ”ç©¶ï¼Œæˆ‘ä»¬æ„å»ºäº†ä¸€ä¸ªæ–°çš„æ•°æ®é›†CodeRepetEvalï¼Œä»¥å…¨é¢è¯„ä¼°ç¼“è§£ä»£ç ç”Ÿæˆä¸­é‡å¤é—®é¢˜çš„æ–¹æ³•ã€‚å¤§é‡çš„å®éªŒç»“æœè¡¨æ˜ï¼ŒRPGåœ¨CodeRepetEvalæ•°æ®é›†ä»¥åŠHumanEvalå’ŒMBPPåŸºå‡†æµ‹è¯•ä¸Šçš„è¡¨ç°å‡æ˜¾è‘—ä¼˜äºæœ€ä½³åŸºçº¿æ–¹æ³•ï¼Œæœ‰æ•ˆåœ°å‡å°‘äº†é‡å¤ï¼Œæé«˜äº†ç”Ÿæˆä»£ç çš„è´¨é‡ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.10402v1">PDF</a> Accepted to ACL 2025 (main)</p>
<p><strong>Summary</strong></p>
<p>éšç€ç¥ç»ç½‘ç»œè¯­è¨€æ¨¡å‹çš„å‡ºç°ï¼Œä»£ç ç”Ÿæˆæ€§èƒ½å¾—åˆ°æ˜¾è‘—æå‡ï¼Œä½†ç”Ÿæˆè¿‡ç¨‹ä¸­çš„é‡å¤é—®é¢˜ä»ç„¶å­˜åœ¨ã€‚æœ¬æ–‡ä¸»è¦å…³æ³¨ç»“æ„é‡å¤é—®é¢˜ï¼Œå¹¶æå‡ºä¸€ç§æœ‰æ•ˆçš„è§£ç æ–¹æ³•RPGï¼ˆåŸºäºè¯­æ³•çš„é‡å¤æƒ©ç½šï¼‰ï¼Œä»¥å‡è½»LLMä»£ç ç”Ÿæˆä¸­çš„é‡å¤é—®é¢˜ã€‚RPGåˆ©ç”¨è¯­æ³•è§„åˆ™è¯†åˆ«ä»£ç ç”Ÿæˆä¸­çš„é‡å¤é—®é¢˜ï¼Œå¹¶æˆ˜ç•¥æ€§åœ°é™ä½å¯¼è‡´é‡å¤çš„å…³é”®è¯çš„å¯èƒ½æ€§ï¼Œä»è€Œå‡è½»ä»£ç ç”Ÿæˆä¸­çš„é‡å¤é—®é¢˜ã€‚ä¸ºäº†æ”¯æŒè¯¥ç ”ç©¶ï¼Œæ„å»ºäº†ä¸€ä¸ªæ–°çš„æ•°æ®é›†CodeRepetEvalï¼Œä»¥å…¨é¢è¯„ä¼°å‡è½»ä»£ç ç”Ÿæˆä¸­é‡å¤é—®é¢˜çš„æ–¹æ³•ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒRPGåœ¨CodeRepetEvalæ•°æ®é›†ä»¥åŠHumanEvalå’ŒMBPPåŸºå‡†æµ‹è¯•ä¸Šçš„è¡¨ç°å‡ä¼˜äºæœ€ä½³åŸºçº¿æ–¹æ³•ï¼Œèƒ½å¤Ÿæœ‰æ•ˆå‡å°‘é‡å¤å¹¶æå‡ç”Ÿæˆä»£ç çš„è´¨é‡ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ç¥ç»ç½‘ç»œè¯­è¨€æ¨¡å‹æå‡äº†ä»£ç ç”Ÿæˆæ€§èƒ½ï¼Œä½†é‡å¤é—®é¢˜ä¾ç„¶çªå‡ºã€‚</li>
<li>ä»£ç é‡å¤åˆ†ä¸ºå†…å®¹é‡å¤å’Œç»“æ„é‡å¤ï¼Œå…¶ä¸­ç»“æ„é‡å¤æ›´ä¸ºæ™®éä¸”å…·æŒ‘æˆ˜æ€§ã€‚</li>
<li>ç»“æ„é‡å¤æŒ‡å…·æœ‰å›ºå®šç»“æ„çš„é‡å¤ä»£ç ï¼Œå¯å†…åœ¨åæ˜ äºè¯­æ³•ä¸­ã€‚</li>
<li>RPGæ–¹æ³•åˆ©ç”¨è¯­æ³•è§„åˆ™è¯†åˆ«ä»£ç ç”Ÿæˆä¸­çš„é‡å¤é—®é¢˜ï¼Œå¹¶é™ä½å¯¼è‡´é‡å¤çš„å…³é”®è¯å¯èƒ½æ€§ã€‚</li>
<li>ä¸ºæ”¯æŒç ”ç©¶ï¼Œæ„å»ºäº†æ–°çš„æ•°æ®é›†CodeRepetEvalï¼Œä»¥å…¨é¢è¯„ä¼°å‡è½»ä»£ç é‡å¤é—®é¢˜çš„æ–¹æ³•ã€‚</li>
<li>å®éªŒç»“æœæ˜¾ç¤ºï¼ŒRPGåœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸Šè¡¨ç°ä¼˜å¼‚ï¼Œèƒ½æœ‰æ•ˆå‡å°‘é‡å¤å¹¶æé«˜ç”Ÿæˆä»£ç è´¨é‡ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.10402">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-0048283ae20e30efde7f7b716740cea5.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-63a93cbc3f49af8e05025dd42cba5927.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-d194fa0a5029e72056457eb2f1bbada9.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-3042f6d7bbcf02d66c340e5b2b696eb2.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="BizChat-Scaffolding-AI-Powered-Business-Planning-for-Small-Business-Owners-Across-Digital-Skill-Levels"><a href="#BizChat-Scaffolding-AI-Powered-Business-Planning-for-Small-Business-Owners-Across-Digital-Skill-Levels" class="headerlink" title="BizChat: Scaffolding AI-Powered Business Planning for Small Business   Owners Across Digital Skill Levels"></a>BizChat: Scaffolding AI-Powered Business Planning for Small Business   Owners Across Digital Skill Levels</h2><p><strong>Authors:Quentin Romero Lauro, Aakash Gautam, Yasmine Kotturi</strong></p>
<p>Generative AI can help small business owners automate tasks, increase efficiency, and improve their bottom line. However, despite the seemingly intuitive design of systems like ChatGPT, significant barriers remain for those less comfortable with technology. To address these disparities, prior work highlights accessory skills â€“ beyond prompt engineering â€“ users must master to successfully adopt generative AI including keyboard shortcuts, editing skills, file conversions, and browser literacy. Building on a design workshop series and 15 interviews with small businesses, we introduce BizChat, a large language model (LLM)-powered web application that helps business owners across digital skills levels write their business plan â€“ an essential but often neglected document. To do so, BizChatâ€™s interface embodies three design considerations inspired by learning sciences: ensuring accessibility to users with less digital skills while maintaining extensibility to power users (â€œlow-floor-high-ceilingâ€), providing in situ micro-learning to support entrepreneurial education (â€œjust-in-time learningâ€), and framing interaction around business activities (â€œcontextualized technology introductionâ€). We conclude with plans for a future BizChat deployment. </p>
<blockquote>
<p>ç”Ÿæˆå¼äººå·¥æ™ºèƒ½å¯ä»¥å¸®åŠ©å°ä¼ä¸šä¸»è‡ªåŠ¨åŒ–ä»»åŠ¡ã€æé«˜æ•ˆç‡å¹¶æ”¹å–„è´¢åŠ¡çŠ¶å†µã€‚ç„¶è€Œï¼Œå°½ç®¡ChatGPTç­‰ç³»ç»Ÿçš„è®¾è®¡çœ‹ä¼¼ç›´è§‚ï¼Œä½†å¯¹äºé‚£äº›å¯¹æŠ€æœ¯ä¸å¤ªé€‚åº”çš„äººæ¥è¯´ï¼Œä»ç„¶å­˜åœ¨é‡å¤§éšœç¢ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæ—©æœŸçš„ç ”ç©¶å¼ºè°ƒäº†è¾…åŠ©æŠ€èƒ½çš„é‡è¦æ€§â€”â€”é™¤äº†æç¤ºå·¥ç¨‹å¤–ï¼Œç”¨æˆ·å¿…é¡»æŒæ¡æˆåŠŸé‡‡ç”¨ç”Ÿæˆå¼äººå·¥æ™ºèƒ½æ‰€éœ€çš„å…¶ä»–æŠ€èƒ½ï¼ŒåŒ…æ‹¬é”®ç›˜å¿«æ·é”®ã€ç¼–è¾‘æŠ€èƒ½ã€æ–‡ä»¶è½¬æ¢å’Œæµè§ˆå™¨ç´ å…»ã€‚åŸºäºè®¾è®¡ç ”è®¨ä¼šç³»åˆ—å’Œä¸15å®¶å°ä¼ä¸šçš„è®¿è°ˆï¼Œæˆ‘ä»¬æ¨å‡ºäº†BizChatï¼Œè¿™æ˜¯ä¸€æ¬¾ç”±å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰é©±åŠ¨çš„ç½‘ç»œåº”ç”¨ç¨‹åºï¼Œæ—¨åœ¨å¸®åŠ©å„çº§æ•°å­—åŒ–æŠ€èƒ½çš„ä¼ä¸šå®¶æ’°å†™ä»–ä»¬çš„å•†ä¸šè®¡åˆ’â€”â€”è¿™æ˜¯ä¸€ä»½è‡³å…³é‡è¦çš„ä½†å¸¸è¢«å¿½è§†çš„æ–‡ä»¶ã€‚ä¸ºæ­¤ï¼ŒBizChatçš„ç•Œé¢ä½“ç°äº†ä¸‰ä¸ªå—å­¦ä¹ ç§‘å­¦å¯å‘çš„è®¾è®¡è€ƒé‡ï¼šç¡®ä¿å¯¹æ•°å­—åŒ–æŠ€èƒ½è¾ƒä½çš„ç”¨æˆ·å…·æœ‰å¯åŠæ€§ï¼ŒåŒæ—¶ä¸ºé«˜çº§ç”¨æˆ·æä¾›å¯æ‰©å±•æ€§ï¼ˆâ€œä½é—¨æ§›-é«˜ä¸Šé™â€ï¼‰ï¼Œæä¾›å³æ—¶å¾®å‹å­¦ä¹ ä»¥æ”¯æŒåˆ›ä¸šæ•™è‚²ï¼ˆâ€œå³æ—¶å­¦ä¹ â€ï¼‰ï¼Œä»¥åŠå›´ç»•å•†ä¸šæ´»åŠ¨è¿›è¡Œäº’åŠ¨ï¼ˆâ€œæƒ…å¢ƒåŒ–æŠ€æœ¯ä»‹ç»â€ï¼‰ã€‚æœ€åï¼Œæˆ‘ä»¬æå‡ºäº†æœªæ¥BizChatçš„éƒ¨ç½²è®¡åˆ’ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.08493v2">PDF</a> 4 pages, 1 figure, CHIWORK â€˜25 Adjunct, June 23-25, 2025, Amsterdam,   Netherlands</p>
<p><strong>Summary</strong></p>
<p>æ–°ä¸€ä»£ç”Ÿæˆå¼äººå·¥æ™ºèƒ½å¯åŠ©åŠ›å°ä¼ä¸šä¸»è‡ªåŠ¨åŒ–ä»»åŠ¡ã€æé«˜æ•ˆç‡å¹¶æ”¹å–„ç»è¥æˆæœã€‚ç„¶è€Œï¼Œå¯¹äºä¸ç†Ÿæ‚‰æŠ€æœ¯çš„ç”¨æˆ·æ¥è¯´ï¼Œä»å­˜åœ¨æ˜¾è‘—éšœç¢ã€‚é™¤æç¤ºå·¥ç¨‹å¤–ï¼Œç”¨æˆ·è¿˜éœ€æŒæ¡é™„åŠ æŠ€èƒ½æ‰èƒ½æˆåŠŸé‡‡ç”¨ç”Ÿæˆå¼äººå·¥æ™ºèƒ½ï¼ŒåŒ…æ‹¬é”®ç›˜å¿«æ·é”®ã€ç¼–è¾‘æŠ€èƒ½ã€æ–‡ä»¶è½¬æ¢å’Œæµè§ˆå™¨ç´ å…»ç­‰ã€‚åŸºäºè®¾è®¡ç ”è®¨ä¼šç³»åˆ—å’Œä¸15å®¶å°ä¼ä¸šä¸»çš„è®¿è°ˆï¼Œæˆ‘ä»¬æ¨å‡ºBizChatâ€”â€”ä¸€æ¬¾åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„Webåº”ç”¨ç¨‹åºï¼Œæ—¨åœ¨å¸®åŠ©å„çº§æ•°å­—æŠ€èƒ½çš„ä¼ä¸šä¸»æ’°å†™å•†ä¸šè®¡åˆ’â€”â€”è¿™æ˜¯ä¸€ä»½è‡³å…³é‡è¦çš„ä½†å¸¸è¢«å¿½è§†çš„æ–‡ä»¶ã€‚BizChatçš„ç•Œé¢èåˆäº†å­¦ä¹ ç§‘å­¦çš„ä¸‰ä¸ªè®¾è®¡è¦ç‚¹ï¼šç¡®ä¿å¯¹æ•°å­—æŠ€èƒ½è¾ƒå°‘çš„ç”¨æˆ·çš„å¯åŠæ€§å¹¶å…¼é¡¾é«˜çº§ç”¨æˆ·çš„æ‰©å±•æ€§ï¼ˆâ€œä½é—¨æ§›é«˜å¤©èŠ±æ¿â€ï¼‰ï¼Œæä¾›å³æ—¶å¾®å‹å­¦ä¹ æ”¯æŒåˆ›ä¸šæ•™è‚²ï¼ˆâ€œå³æ—¶å­¦ä¹ â€ï¼‰ï¼Œå¹¶ä»¥å•†ä¸šæ´»åŠ¨ä¸ºä¸­å¿ƒè®¾è®¡äº’åŠ¨ï¼ˆâ€œæƒ…å¢ƒåŒ–æŠ€æœ¯ä»‹ç»â€ï¼‰ã€‚æˆ‘ä»¬ä»¥æ­¤å¾—å‡ºç»“è®ºå¹¶è®¡åˆ’æœªæ¥éƒ¨ç½²BizChatã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ç”Ÿæˆå¼AIå¯ä»¥å¸®åŠ©å°ä¼ä¸šä¸»æé«˜æ•ˆç‡å’Œæ”¶ç›Šï¼Œä½†å­˜åœ¨æŠ€æœ¯éšœç¢ã€‚</li>
<li>ç”¨æˆ·éœ€è¦æŒæ¡é™„åŠ æŠ€èƒ½ï¼Œå¦‚é”®ç›˜å¿«æ·é”®ã€ç¼–è¾‘ç­‰ï¼Œä»¥å……åˆ†åˆ©ç”¨ç”Ÿæˆå¼AIã€‚</li>
<li>BizChatæ˜¯ä¸€æ¬¾åŸºäºLLMçš„Webåº”ç”¨ç¨‹åºï¼Œæ—¨åœ¨å¸®åŠ©å°ä¼ä¸šä¸»æ’°å†™å•†ä¸šè®¡åˆ’ã€‚</li>
<li>BizChatç•Œé¢è®¾è®¡è€ƒè™‘äº†å­¦ä¹ ç§‘å­¦çš„åŸåˆ™ï¼ŒåŒ…æ‹¬ä½é—¨æ§›é«˜å¤©èŠ±æ¿ã€å³æ—¶å­¦ä¹ å’Œæƒ…å¢ƒåŒ–æŠ€æœ¯ä»‹ç»ã€‚</li>
<li>BizChatå…·æœ‰å¹¿æ³›é€‚åº”æ€§ï¼Œå¯æ»¡è¶³ä¸åŒæ•°å­—æŠ€èƒ½æ°´å¹³çš„ä¼ä¸šä¸»çš„éœ€æ±‚ã€‚</li>
<li>é€šè¿‡è®¾è®¡ç ”è®¨ä¼šå’Œè®¿è°ˆï¼Œäº†è§£äº†å°ä¼ä¸šä¸»çš„éœ€æ±‚å’Œéšœç¢ï¼Œä¸ºBizChatçš„å¼€å‘æä¾›äº†åŸºç¡€ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.08493">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-96a6046aa241a68564121d4ccd7fe0ad.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="Healthy-LLMs-Benchmarking-LLM-Knowledge-of-UK-Government-Public-Health-Information"><a href="#Healthy-LLMs-Benchmarking-LLM-Knowledge-of-UK-Government-Public-Health-Information" class="headerlink" title="Healthy LLMs? Benchmarking LLM Knowledge of UK Government Public Health   Information"></a>Healthy LLMs? Benchmarking LLM Knowledge of UK Government Public Health   Information</h2><p><strong>Authors:Joshua Harris, Fan Grayson, Felix Feldman, Timothy Laurence, Toby Nonnenmacher, Oliver Higgins, Leo Loman, Selina Patel, Thomas Finnie, Samuel Collins, Michael Borowitz</strong></p>
<p>As Large Language Models (LLMs) become widely accessible, a detailed understanding of their knowledge within specific domains becomes necessary for successful real world use. This is particularly critical in public health, where failure to retrieve relevant, accurate, and current information could significantly impact UK residents. However, currently little is known about LLM knowledge of UK Government public health information. To address this issue, this paper introduces a new benchmark, PubHealthBench, with over 8000 questions for evaluating LLMsâ€™ Multiple Choice Question Answering (MCQA) and free form responses to public health queries. To create PubHealthBench we extract free text from 687 current UK government guidance documents and implement an automated pipeline for generating MCQA samples. Assessing 24 LLMs on PubHealthBench we find the latest private LLMs (GPT-4.5, GPT-4.1 and o1) have a high degree of knowledge, achieving &gt;90% accuracy in the MCQA setup, and outperform humans with cursory search engine use. However, in the free form setup we see lower performance with no model scoring &gt;75%. Importantly we find in both setups LLMs have higher accuracy on guidance intended for the general public. Therefore, there are promising signs that state of the art (SOTA) LLMs are an increasingly accurate source of public health information, but additional safeguards or tools may still be needed when providing free form responses on public health topics. </p>
<blockquote>
<p>éšç€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„æ™®åŠï¼Œå¯¹äºå…¶åœ¨ç‰¹å®šé¢†åŸŸå†…çš„çŸ¥è¯†æœ‰è¯¦ç»†çš„äº†è§£å¯¹äºå…¶åœ¨ç°å®ä¸–ç•Œçš„æˆåŠŸåº”ç”¨å˜å¾—è‡³å…³é‡è¦ã€‚è¿™åœ¨å…¬å…±å«ç”Ÿé¢†åŸŸå°¤ä¸ºå…³é”®ï¼Œå› ä¸ºæ— æ³•æ£€ç´¢åˆ°ç›¸å…³ã€å‡†ç¡®å’Œæœ€æ–°çš„ä¿¡æ¯å¯èƒ½ä¼šæ˜¾è‘—å½±å“è‹±å›½å±…æ°‘ã€‚ç„¶è€Œï¼Œç›®å‰å¯¹äºLLMå¯¹è‹±å›½æ”¿åºœå…¬å…±å«ç”Ÿä¿¡æ¯çš„äº†è§£çŸ¥ä¹‹ç”šå°‘ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæœ¬æ–‡ä»‹ç»äº†ä¸€ä¸ªæ–°çš„åŸºå‡†æµ‹è¯•â€”â€”PubHealthBenchï¼Œå®ƒåŒ…å«è¶…è¿‡8000ä¸ªé—®é¢˜ï¼Œç”¨äºè¯„ä¼°LLMçš„å¤šé¡¹é€‰æ‹©é¢˜ç­”é¢˜ï¼ˆMCQAï¼‰å’Œé’ˆå¯¹å…¬å…±å«ç”ŸæŸ¥è¯¢çš„è‡ªç”±å½¢å¼å“åº”ã€‚ä¸ºäº†åˆ›å»ºPubHealthBenchï¼Œæˆ‘ä»¬ä»687ä»½å½“å‰çš„è‹±å›½æ”¿åºœæŒ‡å¯¼æ–‡ä»¶ä¸­æå–äº†è‡ªç”±æ–‡æœ¬ï¼Œå¹¶å®æ–½äº†è‡ªåŠ¨åŒ–ç®¡é“ä»¥ç”ŸæˆMCQAæ ·æœ¬ã€‚åœ¨PubHealthBenchä¸Šè¯„ä¼°äº†24ä¸ªLLMï¼Œæˆ‘ä»¬å‘ç°æœ€æ–°çš„ç§æœ‰LLMï¼ˆGPT-4.5ã€GPT-4.1å’Œo1ï¼‰æ‹¥æœ‰å¾ˆé«˜çš„çŸ¥è¯†é‡ï¼Œåœ¨MCQAè®¾ç½®ä¸­è¾¾åˆ°äº†&gt; 90%çš„å‡†ç¡®ç‡ï¼Œå¹¶ä¸”è¡¨ç°ä¼˜äºéšæ„ä½¿ç”¨æœç´¢å¼•æ“çš„äººç±»ã€‚ç„¶è€Œï¼Œåœ¨è‡ªç”±å½¢å¼è®¾ç½®ä¸­ï¼Œæˆ‘ä»¬çœ‹åˆ°æ€§èƒ½è¾ƒä½ï¼Œæ²¡æœ‰ä»»ä½•æ¨¡å‹çš„å¾—åˆ†è¶…è¿‡75%ã€‚é‡è¦çš„æ˜¯ï¼Œæˆ‘ä»¬åœ¨ä¸¤ç§è®¾ç½®ä¸­éƒ½å‘ç°LLMå¯¹é¢å‘å…¬ä¼—çš„æŒ‡å¯¼çš„å‡†ç¡®ç‡æ›´é«˜ã€‚å› æ­¤ï¼Œæœ‰è¿¹è±¡è¡¨æ˜ï¼Œæœ€å…ˆè¿›çš„å¤§å‹è¯­è¨€æ¨¡å‹æ˜¯è¶Šæ¥è¶Šå‡†ç¡®çš„å…¬å…±å«ç”Ÿä¿¡æ¯æ¥æºï¼Œä½†åœ¨æä¾›å…¬å…±å«ç”Ÿè¯é¢˜çš„è‡ªç”±å½¢å¼å“åº”æ—¶ï¼Œå¯èƒ½ä»éœ€è¦é¢å¤–çš„ä¿éšœæªæ–½æˆ–å·¥å…·ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.06046v2">PDF</a> 24 pages, 10 pages main text</p>
<p><strong>Summary</strong></p>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨ç‰¹å®šé¢†åŸŸçš„äº†è§£å¯¹å…¶å®ä¸–ç•Œåº”ç”¨çš„æˆåŠŸè‡³å…³é‡è¦ï¼Œå°¤å…¶æ˜¯åœ¨å…¬å…±å«ç”Ÿé¢†åŸŸã€‚ä¸€é¡¹ç ”ç©¶ä¸ºè¯„ä¼°LLMå¯¹è‹±å›½æ”¿åºœå…¬å…±å«ç”Ÿä¿¡æ¯çš„äº†è§£å¼•å…¥äº†æ–°çš„åŸºå‡†æµ‹è¯•PubHealthBenchã€‚é€šè¿‡è¯„ä¼°å‘ç°ï¼Œæœ€æ–°ç§æœ‰LLMåœ¨é€‰æ‹©é¢˜é—®ç­”ï¼ˆMCQAï¼‰è®¾ç½®ä¸­è¡¨ç°è‰¯å¥½ï¼Œå‡†ç¡®æ€§è¶…è¿‡äººç±»ï¼Œä½†åœ¨è‡ªç”±å½¢å¼å“åº”ä¸­è¡¨ç°è¾ƒå·®ã€‚åœ¨ä¸¤ç§è®¾ç½®ä¸­ï¼ŒLLMå¯¹é¢å‘å…¬ä¼—çš„æŒ‡å¯¼æ€§ä¿¡æ¯çš„å‡†ç¡®æ€§éƒ½è¾ƒé«˜ã€‚è¿™è¡¨æ˜å…ˆè¿›çš„å¤§å‹è¯­è¨€æ¨¡å‹æˆä¸ºå…¬å…±å«ç”Ÿçš„å‡†ç¡®ä¿¡æ¯æºå±•ç°å‡ºå¸Œæœ›ï¼Œä½†åœ¨æä¾›å…¬å…±å¥åº·è¯é¢˜çš„è‡ªç”±å½¢å¼å“åº”æ—¶å¯èƒ½éœ€è¦é¢å¤–çš„å®‰å…¨æªæ–½æˆ–å·¥å…·ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>LLMåœ¨ç‰¹å®šé¢†åŸŸçš„äº†è§£å¯¹å…¶å®ä¸–ç•Œåº”ç”¨è‡³å…³é‡è¦ï¼Œç‰¹åˆ«æ˜¯åœ¨å…¬å…±å«ç”Ÿé¢†åŸŸã€‚</li>
<li>ç ”ç©¶å¼•å…¥äº†æ–°çš„åŸºå‡†æµ‹è¯•PubHealthBenchæ¥è¯„ä¼°LLMå¯¹è‹±å›½æ”¿åºœå…¬å…±å«ç”Ÿä¿¡æ¯çš„äº†è§£ã€‚</li>
<li>æœ€æ–°ç§æœ‰LLMåœ¨é€‰æ‹©é¢˜é—®ç­”ï¼ˆMCQAï¼‰è®¾ç½®ä¸­è¡¨ç°è‰¯å¥½ï¼Œå‡†ç¡®æ€§é«˜ã€‚</li>
<li>åœ¨è‡ªç”±å½¢å¼å“åº”ä¸­ï¼ŒLLMçš„è¡¨ç°è¾ƒå·®ï¼Œæ²¡æœ‰æ¨¡å‹çš„å‡†ç¡®ç‡è¶…è¿‡75%ã€‚</li>
<li>LLMå¯¹é¢å‘å…¬ä¼—çš„æŒ‡å¯¼æ€§ä¿¡æ¯çš„å‡†ç¡®æ€§è¾ƒé«˜ã€‚</li>
<li>æœ€å…ˆè¿›çš„å¤§å‹è¯­è¨€æ¨¡å‹æˆä¸ºå…¬å…±å«ç”Ÿçš„å‡†ç¡®ä¿¡æ¯æºå±•ç°å‡ºå¸Œæœ›ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.06046">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-424e75dbc3b64adb643ee3392c03e019.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f1b680973ed8a941c3f76d59e51f86aa.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d60d3cb9818635a5219ec50325959622.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-01ff3d9a5841217d6c48324968786cd8.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="QWENDY-Gene-Regulatory-Network-Inference-Enhanced-by-Large-Language-Model-and-Transformer"><a href="#QWENDY-Gene-Regulatory-Network-Inference-Enhanced-by-Large-Language-Model-and-Transformer" class="headerlink" title="QWENDY: Gene Regulatory Network Inference Enhanced by Large Language   Model and Transformer"></a>QWENDY: Gene Regulatory Network Inference Enhanced by Large Language   Model and Transformer</h2><p><strong>Authors:Yue Wang, Xueying Tian</strong></p>
<p>Knowing gene regulatory networks (GRNs) is important for understanding various biological mechanisms. In this paper, we present a method, QWENDY, that uses single-cell gene expression data measured at four time points to infer GRNs. Based on a linear gene expression model, it solves the transformation for the covariance matrices. Unlike its predecessor WENDY, QWENDY avoids solving a non-convex optimization problem and produces a unique solution. Then we enhance QWENDY by the transformer neural networks and large language models to obtain two variants: TEQWENDY and LEQWENDY. We test the performance of these methods on two experimental data sets and two synthetic data sets. TEQWENDY has the best overall performance, while QWENDY ranks the first on experimental data sets. </p>
<blockquote>
<p>äº†è§£åŸºå› è°ƒæ§ç½‘ç»œï¼ˆGRNsï¼‰å¯¹äºç†è§£å„ç§ç”Ÿç‰©æœºåˆ¶éå¸¸é‡è¦ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–¹æ³•ï¼Œåä¸ºQWENDYï¼Œå®ƒåˆ©ç”¨åœ¨å››ä¸ªæ—¶é—´ç‚¹æµ‹é‡çš„å•ç»†èƒåŸºå› è¡¨è¾¾æ•°æ®æ¥æ¨æ–­GRNsã€‚åŸºäºçº¿æ€§åŸºå› è¡¨è¾¾æ¨¡å‹ï¼Œå®ƒè§£å†³äº†åæ–¹å·®çŸ©é˜µçš„è½¬æ¢é—®é¢˜ã€‚ä¸å…¶å‰èº«WENDYä¸åŒï¼ŒQWENDYé¿å…äº†è§£å†³éå‡¸ä¼˜åŒ–é—®é¢˜ï¼Œå¹¶äº§ç”Ÿäº†å”¯ä¸€è§£ã€‚ç„¶åï¼Œæˆ‘ä»¬é€šè¿‡å˜å‹å™¨ç¥ç»ç½‘ç»œå’Œå¤§å‹è¯­è¨€æ¨¡å‹å¢å¼ºäº†QWENDYï¼Œè·å¾—äº†ä¸¤ä¸ªå˜ä½“ï¼šTEQWENDYå’ŒLEQWENDYã€‚æˆ‘ä»¬åœ¨ä¸¤ä¸ªå®éªŒæ•°æ®é›†å’Œä¸¤ä¸ªåˆæˆæ•°æ®é›†ä¸Šæµ‹è¯•äº†è¿™äº›æ–¹æ³•çš„è¡¨ç°ã€‚TEQWENDYçš„æ€»ä½“æ€§èƒ½æœ€ä½³ï¼Œè€ŒQWENDYåœ¨å®éªŒæ•°æ®é›†ä¸Šæ’åç¬¬ä¸€ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.09605v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†ä¸€ç§åä¸ºQWENDYçš„æ–¹æ³•ï¼Œåˆ©ç”¨å•ç»†èƒåŸºå› åœ¨å››ä¸ªæ—¶é—´ç‚¹çš„è¡¨è¾¾æ•°æ®æ¥æ¨æ–­åŸºå› è°ƒæ§ç½‘ç»œã€‚è¯¥æ–¹æ³•åŸºäºçº¿æ€§åŸºå› è¡¨è¾¾æ¨¡å‹ï¼Œè§£å†³äº†åæ–¹å·®çŸ©é˜µçš„è½¬æ¢é—®é¢˜ï¼Œé¿å…äº†è§£å†³éå‡¸ä¼˜åŒ–é—®é¢˜ï¼Œå¹¶èƒ½äº§ç”Ÿå”¯ä¸€è§£ã€‚æ­¤å¤–ï¼Œé€šè¿‡å¼•å…¥å˜å‹å™¨ç¥ç»ç½‘ç»œå’Œå¤§å‹è¯­è¨€æ¨¡å‹ï¼Œè¿›ä¸€æ­¥å¢å¼ºäº†QWENDYï¼Œå¾—åˆ°äº†ä¸¤ä¸ªå˜ä½“ï¼šTEQWENDYå’ŒLEQWENDYã€‚åœ¨å®éªŒä¸­ï¼ŒTEQWENDYçš„æ€»ä½“æ€§èƒ½æœ€ä½³ï¼Œè€ŒQWENDYåœ¨å®éªŒæ•°æ®é›†ä¸Šæ’åé¦–ä½ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>QWENDYæ–¹æ³•åˆ©ç”¨å•ç»†èƒåŸºå› åœ¨å››ä¸ªæ—¶é—´ç‚¹çš„è¡¨è¾¾æ•°æ®æ¨æ–­åŸºå› è°ƒæ§ç½‘ç»œã€‚</li>
<li>åŸºäºçº¿æ€§åŸºå› è¡¨è¾¾æ¨¡å‹ï¼Œè§£å†³åæ–¹å·®çŸ©é˜µè½¬æ¢é—®é¢˜ã€‚</li>
<li>QWENDYé¿å…äº†éå‡¸ä¼˜åŒ–é—®é¢˜çš„æ±‚è§£ï¼Œå¹¶æä¾›å”¯ä¸€è§£ã€‚</li>
<li>å¼•å…¥å˜å‹å™¨ç¥ç»ç½‘ç»œå’Œå¤§å‹è¯­è¨€æ¨¡å‹å¢å¼ºäº†QWENDYï¼Œäº§ç”ŸTEQWENDYå’ŒLEQWENDYä¸¤ä¸ªå˜ä½“ã€‚</li>
<li>TEQWENDYæ€»ä½“æ€§èƒ½æœ€ä½³ï¼Œè€ŒQWENDYåœ¨å®éªŒæ•°æ®é›†ä¸Šè¡¨ç°ä¼˜ç§€ã€‚</li>
<li>æ­¤æ–¹æ³•æœ‰åŠ©äºæ›´æ·±å…¥åœ°äº†è§£å„ç§ç”Ÿç‰©æœºåˆ¶ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.09605">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-29fca2aa73ef8e487c36a6e759128aa7.jpg" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="The-Lazy-Studentâ€™s-Dream-ChatGPT-Passing-an-Engineering-Course-on-Its-Own"><a href="#The-Lazy-Studentâ€™s-Dream-ChatGPT-Passing-an-Engineering-Course-on-Its-Own" class="headerlink" title="The Lazy Studentâ€™s Dream: ChatGPT Passing an Engineering Course on Its   Own"></a>The Lazy Studentâ€™s Dream: ChatGPT Passing an Engineering Course on Its   Own</h2><p><strong>Authors:Gokul Puthumanaillam, Melkior Ornik</strong></p>
<p>This paper presents a comprehensive investigation into the capability of Large Language Models (LLMs) to successfully complete a semester-long undergraduate control systems course. Through evaluation of 115 course deliverables, we assess LLM performance using ChatGPT under a â€œminimal effortâ€ protocol that simulates realistic student usage patterns. The investigation employs a rigorous testing methodology across multiple assessment formats, from auto-graded multiple choice questions to complex Python programming tasks and long-form analytical writing. Our analysis provides quantitative insights into AIâ€™s strengths and limitations in handling mathematical formulations, coding challenges, and theoretical concepts in control systems engineering. The LLM achieved a B-grade performance (82.24%), approaching but not exceeding the class average (84.99%), with strongest results in structured assignments and greatest limitations in open-ended projects. The findings inform discussions about course design adaptation in response to AI advancement, moving beyond simple prohibition towards thoughtful integration of these tools in engineering education. Additional materials including syllabus, examination papers, design projects, and example responses can be found at the project website: <a target="_blank" rel="noopener" href="https://gradegpt.github.io/">https://gradegpt.github.io</a>. </p>
<blockquote>
<p>æœ¬æ–‡å…¨é¢æ¢è®¨äº†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æˆåŠŸå®Œæˆä¸€å­¦æœŸæœ¬ç§‘æ§åˆ¶ç³»ç»Ÿè¯¾ç¨‹çš„èƒ½åŠ›ã€‚é€šè¿‡å¯¹115ä»½è¯¾ç¨‹äº¤ä»˜æˆæœçš„è¯„ä»·ï¼Œæˆ‘ä»¬é‡‡ç”¨ChatGPTè¯„ä¼°LLMæ€§èƒ½ï¼Œéµå¾ªæ¨¡æ‹Ÿç°å®å­¦ç”Ÿä½¿ç”¨æ¨¡å¼çš„â€œæœ€å°åŠªåŠ›â€åè®®ã€‚è°ƒæŸ¥é‡‡ç”¨ä¸¥æ ¼çš„æµ‹è¯•æ–¹æ³•ï¼Œæ¶µç›–å¤šç§è¯„ä¼°å½¢å¼ï¼Œä»è‡ªåŠ¨è¯„åˆ†çš„å¤šé¡¹é€‰æ‹©é¢˜åˆ°å¤æ‚çš„Pythonç¼–ç¨‹ä»»åŠ¡å’Œé•¿ç¯‡åˆ†æå†™ä½œã€‚æˆ‘ä»¬çš„åˆ†ææä¾›äº†å…³äºAIåœ¨å¤„ç†æ§åˆ¶ç³»ç»Ÿå·¥ç¨‹ä¸­çš„æ•°å­¦å…¬å¼ã€ç¼–ç¨‹æŒ‘æˆ˜å’Œç†è®ºæ¦‚å¿µçš„ä¼˜ç‚¹å’Œå±€é™æ€§çš„å®šé‡è§è§£ã€‚LLMå–å¾—äº†Bçº§è¡¨ç°ï¼ˆ82.24%ï¼‰ï¼Œæ¥è¿‘ä½†æœªè¶…è¿‡ç­çº§å¹³å‡æ°´å¹³ï¼ˆ84.99%ï¼‰ï¼Œåœ¨ç»“æ„åŒ–ä½œä¸šæ–¹é¢è¡¨ç°æœ€ä½³ï¼Œåœ¨å¼€æ”¾å¼é¡¹ç›®ä¸­å±€é™æ€§æœ€å¤§ã€‚ç ”ç©¶ç»“æœå¯¹è¯¾ç¨‹è®¾è®¡çš„é€‚åº”æ€§è¿›è¡Œäº†è®¨è®ºï¼Œä»¥é€‚åº”äººå·¥æ™ºèƒ½çš„è¿›æ­¥ï¼Œä»ç®€å•çš„ç¦æ­¢èµ°å‘å¯¹è¿™äº›å·¥å…·åœ¨å·¥ç¨‹æ•™è‚²ä¸­çš„æ·±æ€ç†Ÿè™‘çš„æ•´åˆã€‚å…¶ä»–ææ–™åŒ…æ‹¬æ•™å­¦å¤§çº²ã€è€ƒè¯•è¯•å·ã€è®¾è®¡é¡¹ç›®å’Œç¤ºä¾‹ç­”æ¡ˆå¯åœ¨é¡¹ç›®ç½‘ç«™æ‰¾åˆ°ï¼š<a target="_blank" rel="noopener" href="https://gradegpt.github.io/">https://gradegpt.github.io</a>ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.05760v3">PDF</a> </p>
<p><strong>æ‘˜è¦</strong></p>
<p>æœ¬æ–‡å…¨é¢æ¢è®¨äº†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å®Œæˆä¸€é—¨ä¸ºæœŸåŠä¸ªå­¦æœŸçš„æ§åˆ¶ä½“ç³»è¯¾ç¨‹çš„æ½œåŠ›ã€‚é€šè¿‡å¯¹115ä»½è¯¾ç¨‹äº¤ä»˜å“çš„è¯„ä¼°ï¼Œæˆ‘ä»¬é‡‡ç”¨ChatGPTåœ¨æ¨¡æ‹ŸçœŸå®å­¦ç”Ÿä½¿ç”¨æ¨¡å¼çš„â€œæœ€å°åŠªåŠ›â€åè®®ä¸‹è¯„ä¼°LLMæ€§èƒ½ã€‚ç ”ç©¶é‡‡ç”¨ä¸¥æ ¼çš„æµ‹è¯•æ–¹æ³•ï¼ŒåŒ…æ‹¬å¤šç§è¯„ä¼°å½¢å¼ï¼Œä»è‡ªåŠ¨æ‰¹åˆ†çš„å¤šé¡¹é€‰æ‹©é¢˜åˆ°å¤æ‚çš„Pythonç¼–ç¨‹ä»»åŠ¡å’Œé•¿ç¯‡åˆ†æå†™ä½œã€‚æˆ‘ä»¬çš„åˆ†ææä¾›äº†å…³äºAIåœ¨å¤„ç†æ§åˆ¶ä½“ç³»å·¥ç¨‹ä¸­çš„æ•°å­¦å…¬å¼ã€ç¼–ç¨‹æŒ‘æˆ˜å’Œç†è®ºæ¦‚å¿µçš„ä¼˜ç‚¹å’Œå±€é™æ€§çš„å®šé‡è§è§£ã€‚LLMçš„æˆç»©è¾¾åˆ°äº†Bçº§ï¼ˆ82.24%ï¼‰ï¼Œæ¥è¿‘ä½†æœªè¶…è¿‡ç­çº§å¹³å‡æ°´å¹³ï¼ˆ84.99%ï¼‰ï¼Œåœ¨ç»“æ„åŒ–ä½œä¸šä¸­çš„è¡¨ç°æœ€ä½³ï¼Œè€Œåœ¨å¼€æ”¾å¼é¡¹ç›®ä¸­çš„è¡¨ç°æœ€ä¸ºå—é™ã€‚è¿™äº›å‘ç°å¼•å‘äº†å…³äºé€‚åº”AIå‘å±•çš„è¯¾ç¨‹è®¾è®¡çš„è®¨è®ºï¼Œå‘¼åäººä»¬è¶…è¶Šç®€å•çš„ç¦ä»¤ï¼Œæ€è€ƒå¦‚ä½•å°†è¿™äº›å·¥å…·èå…¥å·¥ç¨‹æ•™è‚²ä¸­ã€‚é™„åŠ ææ–™åŒ…æ‹¬æ•™å­¦å¤§çº²ã€è€ƒè¯•è¯•å·ã€è®¾è®¡é¡¹ç›®å’Œç¤ºä¾‹ç­”æ¡ˆï¼Œå¯åœ¨é¡¹ç›®ç½‘ç«™æ‰¾åˆ°ï¼š<a target="_blank" rel="noopener" href="https://gradegpt.github.io/">https://gradegpt.github.io</a>ã€‚</p>
<p><strong>å…³é”®è§è§£</strong></p>
<ol>
<li>LLMèƒ½å¤Ÿå®Œæˆæ§åˆ¶ä½“ç³»è¯¾ç¨‹çš„å¤šç§è¯„ä¼°å½¢å¼ï¼ŒåŒ…æ‹¬å¤šé¡¹é€‰æ‹©é¢˜ã€Pythonç¼–ç¨‹ä»»åŠ¡å’Œåˆ†æå†™ä½œã€‚</li>
<li>LLMåœ¨æ§åˆ¶ä½“ç³»å·¥ç¨‹ä¸­çš„è¡¨ç°æ¥è¿‘ç­çº§å¹³å‡æ°´å¹³ï¼Œå°¤å…¶åœ¨ç»“æ„åŒ–ä½œä¸šä¸­è¡¨ç°è‰¯å¥½ã€‚</li>
<li>LLMåœ¨å¤„ç†æ•°å­¦å…¬å¼å’Œç†è®ºæ¦‚å¿µæ–¹é¢æœ‰ä¸€å®šçš„å±€é™æ€§ï¼Œç‰¹åˆ«æ˜¯åœ¨å¼€æ”¾å¼é¡¹ç›®ä¸­ã€‚</li>
<li>ç ”ç©¶ç»“æœæç¤ºé€‚åº”AIå‘å±•çš„è¯¾ç¨‹è®¾è®¡éœ€è€ƒè™‘å¦‚ä½•æ•´åˆè¿™äº›å·¥å…·ï¼Œè€Œéç®€å•ç¦æ­¢ã€‚</li>
<li>è¯¥ç ”ç©¶ä¸ºæˆ‘ä»¬æä¾›äº†å…³äºLLMåœ¨æ§åˆ¶ä½“ç³»å·¥ç¨‹é¢†åŸŸæ€§èƒ½çš„å®šé‡è§è§£ã€‚</li>
<li>é¡¹ç›®ç½‘ç«™æä¾›äº†ä¸°å¯Œçš„é™„åŠ ææ–™ï¼ŒåŒ…æ‹¬æ•™å­¦å¤§çº²ã€è€ƒè¯•è¯•å·å’Œè®¾è®¡é¡¹ç›®ç­‰ã€‚</li>
<li>æ­¤ç ”ç©¶ä¸ºæœªæ¥çš„å·¥ç¨‹æ•™è‚²æä¾›äº†æ–°çš„è§†è§’ï¼Œå…³äºå¦‚ä½•æ›´å¥½åœ°åˆ©ç”¨AIå·¥å…·æé«˜å­¦ç”Ÿçš„å­¦æœ¯è¡¨ç°ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.05760">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-3e5a6de0758fa0702738c9f221b29a59.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-67bdee915f3f1854ce7502388fdf0d0e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d89ff0a65bdd64b9f97d6185862a6f43.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-a3b91291511b7b3b642c59b7d5279932.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-5e8ab861defd4399182b8ef0f4a9ae66.jpg" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1><h2 id="Harnessing-Multiple-Large-Language-Models-A-Survey-on-LLM-Ensemble"><a href="#Harnessing-Multiple-Large-Language-Models-A-Survey-on-LLM-Ensemble" class="headerlink" title="Harnessing Multiple Large Language Models: A Survey on LLM Ensemble"></a>Harnessing Multiple Large Language Models: A Survey on LLM Ensemble</h2><p><strong>Authors:Zhijun Chen, Jingzheng Li, Pengpeng Chen, Zhuoran Li, Kai Sun, Yuankai Luo, Qianren Mao, Dingqi Yang, Hailong Sun, Philip S. Yu</strong></p>
<p>LLM Ensemble â€“ which involves the comprehensive use of multiple large language models (LLMs), each aimed at handling user queries during downstream inference, to benefit from their individual strengths â€“ has gained substantial attention recently. The widespread availability of LLMs, coupled with their varying strengths and out-of-the-box usability, has profoundly advanced the field of LLM Ensemble. This paper presents the first systematic review of recent developments in LLM Ensemble. First, we introduce our taxonomy of LLM Ensemble and discuss several related research problems. Then, we provide a more in-depth classification of the methods under the broad categories of â€œensemble-before-inference, ensemble-during-inference, ensemble-after-inferenceâ€™â€™, and review all relevant methods. Finally, we introduce related benchmarks and applications, summarize existing studies, and suggest several future research directions. A curated list of papers on LLM Ensemble is available at <a target="_blank" rel="noopener" href="https://github.com/junchenzhi/Awesome-LLM-Ensemble">https://github.com/junchenzhi/Awesome-LLM-Ensemble</a>. </p>
<blockquote>
<p>LLMé›†åˆï¼ˆLLM Ensembleï¼‰â€”â€”æ¶‰åŠå…¨é¢ä½¿ç”¨å¤šä¸ªå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ï¼Œæ¯ä¸ªæ¨¡å‹æ—¨åœ¨åœ¨ä¸‹æ¸¸æ¨ç†è¿‡ç¨‹ä¸­å¤„ç†ç”¨æˆ·æŸ¥è¯¢ï¼Œä»¥å—ç›Šäºå„è‡ªçš„ä¼˜åŠ¿â€”â€”æœ€è¿‘å¼•èµ·äº†å¹¿æ³›å…³æ³¨ã€‚å¤§å‹è¯­è¨€æ¨¡å‹çš„å¹¿æ³›å¯ç”¨æ€§ï¼Œä»¥åŠå®ƒä»¬å„è‡ªçš„æ€§èƒ½ä¼˜åŠ¿å’Œå¼€ç®±å³ç”¨æ€§ï¼Œæå¤§åœ°æ¨åŠ¨äº†LLMé›†åˆé¢†åŸŸçš„å‘å±•ã€‚æœ¬æ–‡é¦–æ¬¡å¯¹LLMé›†åˆçš„æœ€æ–°å‘å±•è¿›è¡Œäº†ç³»ç»Ÿå›é¡¾ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬ä»‹ç»äº†LLMé›†åˆçš„åˆ†ç±»å­¦ï¼Œå¹¶è®¨è®ºäº†å‡ ä¸ªç›¸å…³çš„ç ”ç©¶é—®é¢˜ã€‚ç„¶åï¼Œæˆ‘ä»¬åœ¨â€œæ¨ç†å‰é›†åˆâ€ã€â€œæ¨ç†ä¸­é›†åˆâ€ã€â€œæ¨ç†åé›†åˆâ€çš„å¹¿ä¹‰ç±»åˆ«ä¸‹ï¼Œæ·±å…¥å‰–æäº†ç›¸å…³æ–¹æ³•ï¼Œå¹¶å¯¹æ‰€æœ‰ç›¸å…³æ–¹æ³•è¿›è¡Œäº†è¯„è¿°ã€‚æœ€åï¼Œæˆ‘ä»¬ä»‹ç»äº†ç›¸å…³çš„åŸºå‡†æµ‹è¯•å’Œåº”ç”¨ç¨‹åºï¼Œæ€»ç»“äº†ç°æœ‰ç ”ç©¶ï¼Œå¹¶æå‡ºäº†å‡ ä¸ªæœªæ¥çš„ç ”ç©¶æ–¹å‘ã€‚å…³äºLLMé›†åˆçš„è®ºæ–‡åˆ—è¡¨å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/junchenzhi/Awesome-LLM-Ensemble%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/junchenzhi/Awesome-LLM-Ensembleæ‰¾åˆ°ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.18036v4">PDF</a> 9 pages, 2 figures, codebase:   <a target="_blank" rel="noopener" href="https://github.com/junchenzhi/Awesome-LLM-Ensemble">https://github.com/junchenzhi/Awesome-LLM-Ensemble</a></p>
<p><strong>Summary</strong>ï¼šå¤šè¯­è¨€æ¨¡å‹é›†åˆï¼ˆLLM Ensembleï¼‰æ–¹æ³•é€šè¿‡ç»¼åˆè¿ç”¨å¤šä¸ªå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ï¼Œä»¥åœ¨ä¸‹æ¸¸æ¨ç†è¿‡ç¨‹ä¸­å¤„ç†ç”¨æˆ·æŸ¥è¯¢å¹¶å—ç›Šäºå„è‡ªçš„ç‹¬ç‰¹ä¼˜åŠ¿ï¼Œè·å¾—äº†å¹¿æ³›å…³æ³¨ã€‚æœ¬æ–‡ç³»ç»Ÿåœ°ç»¼è¿°äº†LLM Ensembleçš„æœ€æ–°å‘å±•ï¼Œä»‹ç»äº†åˆ†ç±»ã€ç›¸å…³è¯¾é¢˜ã€æ–¹æ³•å’Œåº”ç”¨ç­‰ï¼Œæ€»ç»“ç°æœ‰ç ”ç©¶å¹¶æå‡ºæœªæ¥ç ”ç©¶æ–¹å‘ã€‚ç›¸å…³è®ºæ–‡åˆ—è¡¨å¯å‚è§é“¾æ¥ã€‚</p>
<p><strong>Key Takeaways</strong>ï¼š</p>
<ol>
<li>LLM Ensembleæ¶‰åŠå¤šä¸ªå¤§å‹è¯­è¨€æ¨¡å‹çš„ç»¼åˆè¿ç”¨ï¼Œä»¥åœ¨ä¸‹æ¸¸æ¨ç†è¿‡ç¨‹ä¸­å¤„ç†ç”¨æˆ·æŸ¥è¯¢ã€‚</li>
<li>LLMçš„å¹¿æ³›å¯ç”¨æ€§åŠå…¶ä¸åŒçš„ä¼˜åŠ¿å’Œå¼€ç®±å³ç”¨æ€§æ¨åŠ¨äº†LLM Ensembleçš„å‘å±•ã€‚</li>
<li>æœ¬æ–‡é¦–æ¬¡å¯¹LLM Ensembleçš„æœ€æ–°å‘å±•è¿›è¡Œç³»ç»Ÿç»¼è¿°ã€‚</li>
<li>æ–‡ç« ä»‹ç»äº†LLM Ensembleçš„åˆ†ç±»å’Œç›¸å…³è¯¾é¢˜ï¼Œæ·±å…¥æ¢è®¨äº†â€œæ¨ç†å‰é›†åˆâ€ã€â€œæ¨ç†ä¸­é›†åˆâ€ã€â€œæ¨ç†åé›†åˆâ€ç­‰æ–¹æ³•ã€‚</li>
<li>æ–‡ç« è¿˜ä»‹ç»äº†ç›¸å…³çš„åŸºå‡†æµ‹è¯•å’Œåº”ç”¨ç¨‹åºï¼Œæ€»ç»“äº†ç°æœ‰ç ”ç©¶ï¼Œå¹¶æå‡ºäº†æœªæ¥çš„ç ”ç©¶æ–¹å‘ã€‚</li>
<li>å¯ä»¥é€šè¿‡æä¾›çš„é“¾æ¥æ‰¾åˆ°å…³äºLLM Ensembleçš„ç²¾é€‰è®ºæ–‡åˆ—è¡¨ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.18036">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-406f43aea2eb8ee99f6a1c08801348bf.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-6aa3bd5ad1f7ce31d1428f8fb445debe.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-adfa1344e7ea3569ccbd22206385bf49.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b42799ab173b0f2dd9ba73405322970a.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-55451f3b8ad073a1e81d13e236a437f2.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-99b68cc24bcbdaa3f13a86c1d21fe707.jpg" align="middle">
</details>


<h1 id="-9"><a href="#-9" class="headerlink" title=""></a></h1><h2 id="ARR-Question-Answering-with-Large-Language-Models-via-Analyzing-Retrieving-and-Reasoning"><a href="#ARR-Question-Answering-with-Large-Language-Models-via-Analyzing-Retrieving-and-Reasoning" class="headerlink" title="ARR: Question Answering with Large Language Models via Analyzing,   Retrieving, and Reasoning"></a>ARR: Question Answering with Large Language Models via Analyzing,   Retrieving, and Reasoning</h2><p><strong>Authors:Yuwei Yin, Giuseppe Carenini</strong></p>
<p>Large language models (LLMs) have demonstrated impressive capabilities on complex evaluation benchmarks, many of which are formulated as question-answering (QA) tasks. Enhancing the performance of LLMs in QA contexts is becoming increasingly vital for advancing their development and applicability. This paper introduces ARR, an intuitive, effective, and general QA solving method that explicitly incorporates three key steps: analyzing the intent of the question, retrieving relevant information, and reasoning step by step. Notably, this paper is the first to introduce intent analysis in QA, which plays a vital role in ARR. Comprehensive evaluations across 10 diverse QA tasks demonstrate that ARR consistently outperforms the baseline methods. Ablation and case studies further validate the positive contributions of each ARR component. Furthermore, experiments involving variations in prompt design indicate that ARR maintains its effectiveness regardless of the specific prompt formulation. Additionally, extensive evaluations across various model sizes, LLM series, and generation settings solidify the effectiveness, robustness, and generalizability of ARR. </p>
<blockquote>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨å¤æ‚çš„è¯„ä¼°åŸºå‡†æµ‹è¯•ä¸­è¡¨ç°å‡ºäº†ä»¤äººå°è±¡æ·±åˆ»çš„èƒ½åŠ›ï¼Œå…¶ä¸­è®¸å¤šè¢«åˆ¶å®šä¸ºé—®ç­”ï¼ˆQAï¼‰ä»»åŠ¡ã€‚æé«˜LLMåœ¨é—®ç­”è¯­å¢ƒä¸­çš„æ€§èƒ½å¯¹äºæ¨åŠ¨å…¶å‘å±•å’Œåº”ç”¨è‡³å…³é‡è¦ã€‚æœ¬æ–‡ä»‹ç»äº†ä¸€ç§ç›´è§‚ã€æœ‰æ•ˆä¸”é€šç”¨çš„é—®ç­”æ±‚è§£æ–¹æ³•ARRï¼Œå®ƒæ˜ç¡®åŒ…å«äº†ä¸‰ä¸ªå…³é”®æ­¥éª¤ï¼šåˆ†æé—®é¢˜çš„æ„å›¾ã€æ£€ç´¢ç›¸å…³ä¿¡æ¯ã€é€æ­¥æ¨ç†ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œæœ¬æ–‡æ˜¯é¦–æ¬¡åœ¨é—®ç­”ä¸­å¼•å…¥æ„å›¾åˆ†æï¼Œè¿™åœ¨ARRä¸­èµ·åˆ°äº†è‡³å…³é‡è¦çš„ä½œç”¨ã€‚åœ¨10ä¸ªä¸åŒé—®ç­”ä»»åŠ¡ä¸Šçš„ç»¼åˆè¯„ä¼°è¡¨æ˜ï¼ŒARRå§‹ç»ˆä¼˜äºåŸºçº¿æ–¹æ³•ã€‚æ¶ˆèç ”ç©¶å’Œæ¡ˆä¾‹ç ”ç©¶è¿›ä¸€æ­¥éªŒè¯äº†ARRæ¯ä¸ªç»„ä»¶çš„ç§¯æè´¡çŒ®ã€‚æ­¤å¤–ï¼Œæ¶‰åŠæç¤ºè®¾è®¡å˜åŒ–çš„å®éªŒè¡¨æ˜ï¼Œæ— è®ºæç¤ºè¡¨è¿°å¦‚ä½•ï¼ŒARRéƒ½èƒ½ä¿æŒå…¶æœ‰æ•ˆæ€§ã€‚åŒæ—¶ï¼Œåœ¨ä¸åŒæ¨¡å‹å¤§å°ã€LLMç³»åˆ—å’Œç”Ÿæˆè®¾ç½®ä¸Šçš„å¹¿æ³›è¯„ä¼°ï¼Œè¿›ä¸€æ­¥è¯æ˜äº†ARRçš„æœ‰æ•ˆæ€§ã€ç¨³å®šæ€§å’Œæ³›åŒ–èƒ½åŠ›ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.04689v3">PDF</a> 21 pages. Code: <a target="_blank" rel="noopener" href="https://github.com/YuweiYin/ARR">https://github.com/YuweiYin/ARR</a></p>
<p><strong>Summary</strong><br>LLMså±•ç°å‡ºä»¤äººå°è±¡æ·±åˆ»çš„é—®ç­”ä»»åŠ¡èƒ½åŠ›ã€‚è¯¥è®ºæ–‡å¼•å…¥ä¸€ç§åä¸ºARRçš„æ–°å‹é€šç”¨é—®ç­”è§£å†³æ–¹æ³•ï¼Œå…¶æ˜¾è‘—ä¼˜åŠ¿åœ¨äºåˆ†æé—®é¢˜çš„æ„å›¾ã€æ£€ç´¢ç›¸å…³ä¿¡æ¯å¹¶é€æ­¥æ¨ç†ã€‚è¯¥è®ºæ–‡é¦–æ¬¡å¼•å…¥æ„å›¾åˆ†æï¼Œå¯¹æå‡é—®ç­”ç³»ç»Ÿçš„æ€§èƒ½èµ·åˆ°äº†å…³é”®ä½œç”¨ã€‚å®éªŒè¡¨æ˜ï¼Œåœ¨å„ç§ä¸åŒä»»åŠ¡ä¸Šï¼ŒARRçš„æ€§èƒ½å§‹ç»ˆä¼˜äºåŸºå‡†æ–¹æ³•ã€‚ç ”ç©¶éªŒè¯äº†å…¶æœ‰æ•ˆæ€§ã€é²æ£’æ€§å’Œæ³›åŒ–æ€§ã€‚ </p>
<p><strong>Key Takeaways</strong> </p>
<ul>
<li>LLMåœ¨å¤æ‚è¯„ä¼°åŸºå‡†æµ‹è¯•ä¸­è¡¨ç°å‡ºå¼ºå¤§çš„èƒ½åŠ›ï¼Œå°¤å…¶åœ¨é—®ç­”ä»»åŠ¡æ–¹é¢ã€‚ </li>
<li>ARRæ˜¯ä¸€ç§æ–°å‹é—®ç­”è§£å†³æ–¹æ³•ï¼ŒåŒ…æ‹¬åˆ†æé—®é¢˜çš„æ„å›¾ã€æ£€ç´¢ç›¸å…³ä¿¡æ¯å’Œé€æ­¥æ¨ç†ä¸‰ä¸ªå…³é”®æ­¥éª¤ã€‚ </li>
<li>è¯¥è®ºæ–‡é¦–æ¬¡å¼•å…¥æ„å›¾åˆ†æåœ¨é—®ç­”ä¸­çš„é‡è¦æ€§ã€‚ </li>
<li>ARRåœ¨å„ç§ä¸åŒçš„é—®ç­”ä»»åŠ¡ä¸Šè¡¨ç°å‡ºä¼˜å¼‚çš„æ€§èƒ½ï¼Œä¸”å…¶æœ‰æ•ˆæ€§å¾—åˆ°å¹¿æ³›çš„å®éªŒéªŒè¯ã€‚ </li>
<li>ARRå…·æœ‰æ˜¾è‘—çš„æœ‰æ•ˆæ€§ã€é²æ£’æ€§å’Œæ³›åŒ–æ€§ï¼Œé€‚åº”ä¸åŒçš„æ¨¡å‹å¤§å°ã€LLMç³»åˆ—å’Œç”Ÿæˆè®¾ç½®ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.04689">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-38a669fa64b41ebea05b0d85dcb7a2e3.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-24e824e4791ef7f69f91ad63effbb042.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-6dd77e4075c3d91a7770accac46956d9.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a1a31f72bc1f52fda28b288e66a7694e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c57b9a738570ea921686503b266201e0.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-30f3272adf6daa9ca47b7dff91fc0c1e.jpg" align="middle">
</details>


<h1 id="-10"><a href="#-10" class="headerlink" title=""></a></h1><h2 id="Benchmarking-Generative-AI-for-Scoring-Medical-Student-Interviews-in-Objective-Structured-Clinical-Examinations-OSCEs"><a href="#Benchmarking-Generative-AI-for-Scoring-Medical-Student-Interviews-in-Objective-Structured-Clinical-Examinations-OSCEs" class="headerlink" title="Benchmarking Generative AI for Scoring Medical Student Interviews in   Objective Structured Clinical Examinations (OSCEs)"></a>Benchmarking Generative AI for Scoring Medical Student Interviews in   Objective Structured Clinical Examinations (OSCEs)</h2><p><strong>Authors:Jadon Geathers, Yann Hicke, Colleen Chan, Niroop Rajashekar, Justin Sewell, Susannah Cornes, Rene F. Kizilcec, Dennis Shung</strong></p>
<p>Objective Structured Clinical Examinations (OSCEs) are widely used to assess medical studentsâ€™ communication skills, but scoring interview-based assessments is time-consuming and potentially subject to human bias. This study explored the potential of large language models (LLMs) to automate OSCE evaluations using the Master Interview Rating Scale (MIRS). We compared the performance of four state-of-the-art LLMs (GPT-4o, Claude 3.5, Llama 3.1, and Gemini 1.5 Pro) in evaluating OSCE transcripts across all 28 items of the MIRS under the conditions of zero-shot, chain-of-thought (CoT), few-shot, and multi-step prompting. The models were benchmarked against a dataset of 10 OSCE cases with 174 expert consensus scores available. Model performance was measured using three accuracy metrics (exact, off-by-one, thresholded). Averaging across all MIRS items and OSCE cases, LLMs performed with low exact accuracy (0.27 to 0.44), and moderate to high off-by-one accuracy (0.67 to 0.87) and thresholded accuracy (0.75 to 0.88). A zero temperature parameter ensured high intra-rater reliability ({\alpha} &#x3D; 0.98 for GPT-4o). CoT, few-shot, and multi-step techniques proved valuable when tailored to specific assessment items. The performance was consistent across MIRS items, independent of encounter phases and communication domains. We demonstrated the feasibility of AI-assisted OSCE evaluation and provided benchmarking of multiple LLMs across multiple prompt techniques. Our work provides a baseline performance assessment for LLMs that lays a foundation for future research into automated assessment of clinical communication skills. </p>
<blockquote>
<p>å®¢è§‚ç»“æ„åŒ–ä¸´åºŠè€ƒè¯•ï¼ˆOSCEsï¼‰è¢«å¹¿æ³›ç”¨äºè¯„ä¼°åŒ»å­¦ç”Ÿçš„æ²Ÿé€šæŠ€å·§ï¼Œä½†æ˜¯åŸºäºé¢è¯•çš„è¯„ä¼°æ‰“åˆ†è€—æ—¶ä¸”å¯èƒ½å—åˆ°äººä¸ºåè§çš„å½±å“ã€‚æœ¬ç ”ç©¶æ¢è®¨äº†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä½¿ç”¨å¤§å¸ˆé¢è¯•è¯„åˆ†é‡è¡¨ï¼ˆMIRSï¼‰è‡ªåŠ¨åŒ–OSCEè¯„ä¼°çš„æ½œåŠ›ã€‚æˆ‘ä»¬æ¯”è¾ƒäº†å››ç§æœ€æ–°LLMï¼ˆGPT-4oã€Claude 3.5ã€Llama 3.1å’ŒGemini 1.5 Proï¼‰åœ¨è¯„ä¼°OSCEè½¬å½•æ—¶çš„è¡¨ç°ï¼Œæ¶µç›–äº†MIRSæ‰€æœ‰28é¡¹æŒ‡æ ‡ï¼ŒåŒ…æ‹¬é›¶æ ·æœ¬ã€æ€ç»´é“¾ï¼ˆCoTï¼‰ã€å°‘æ ·æœ¬å’Œå¤šæ­¥æç¤ºçš„æƒ…å†µã€‚è¿™äº›æ¨¡å‹æ˜¯ä»¥10ä¸ªOSCEç—…ä¾‹çš„æ•°æ®é›†ä¸ºåŸºå‡†ï¼Œå…±æœ‰174ä¸ªä¸“å®¶å…±è¯†åˆ†æ•°å¯ä¾›ä½¿ç”¨ã€‚æ¨¡å‹æ€§èƒ½é‡‡ç”¨ä¸‰ç§å‡†ç¡®æ€§æŒ‡æ ‡ï¼ˆç²¾ç¡®ã€ç¦»ä¸€ã€é˜ˆå€¼ï¼‰è¿›è¡Œæµ‹é‡ã€‚åœ¨æ‰€æœ‰MIRSé¡¹ç›®å’ŒOSCEç—…ä¾‹ä¸Šçš„å¹³å‡æ˜¾ç¤ºï¼ŒLLMçš„ç²¾ç¡®å‡†ç¡®æ€§è¾ƒä½ï¼ˆ0.27è‡³0.44ï¼‰ï¼Œç¦»ä¸€å‡†ç¡®æ€§å’Œé˜ˆå€¼å‡†ç¡®æ€§ä¸ºä¸­ç­‰è‡³é«˜ï¼ˆ0.67è‡³0.87å’Œ0.75è‡³0.88ï¼‰ã€‚é›¶æ¸©åº¦å‚æ•°ç¡®ä¿äº†é«˜å†…éƒ¨ä¸€è‡´æ€§ï¼ˆGPT-4oçš„Î±&#x3D;0.98ï¼‰ã€‚æ€ç»´é“¾ã€å°‘æ ·æœ¬å’Œå¤šæ­¥æŠ€æœ¯å¯¹äºç‰¹å®šçš„è¯„ä¼°é¡¹ç›®éå¸¸æœ‰ä»·å€¼ã€‚æ€§èƒ½åœ¨MIRSé¡¹ç›®ä¸Šè¡¨ç°ä¸€è‡´ï¼Œä¸é­é‡é˜¶æ®µå’Œæ²Ÿé€šé¢†åŸŸæ— å…³ã€‚æˆ‘ä»¬è¯æ˜äº†AIè¾…åŠ©OSCEè¯„ä¼°çš„å¯è¡Œæ€§ï¼Œå¹¶æä¾›äº†å¤šç§LLMåœ¨å¤šç§æç¤ºæŠ€æœ¯ä¸Šçš„åŸºå‡†æµ‹è¯•ã€‚æˆ‘ä»¬çš„å·¥ä½œä¸ºLLMæä¾›äº†åŸºçº¿æ€§èƒ½è¯„ä¼°ï¼Œä¸ºæœªæ¥çš„ä¸´åºŠæ²Ÿé€šæŠ€èƒ½è‡ªåŠ¨åŒ–è¯„ä¼°ç ”ç©¶å¥ å®šäº†åŸºç¡€ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.13957v2">PDF</a> 12 pages + 3 pages of references, 4 figures</p>
<p><strong>Summary</strong>ï¼šè¯¥ç ”ç©¶æ¢ç´¢äº†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨åŒ»ç–—å­¦ç”Ÿä¸´åºŠæ²Ÿé€šæŠ€èƒ½è¯„ä¼°ä¸­çš„è‡ªåŠ¨åŒ–æ½œåŠ›ã€‚é€šè¿‡ä½¿ç”¨ä¸»é¢è¯•è¯„åˆ†é‡è¡¨ï¼ˆMIRSï¼‰ï¼Œå¯¹æ¯”äº†å››ç§æœ€æ–°LLMsåœ¨OSCEè¯„ä¼°ä¸­çš„è¡¨ç°ã€‚ç ”ç©¶ç»“æœè¡¨æ˜ï¼ŒLLMsåœ¨OSCEè¯„ä¼°ä¸­çš„å‡†ç¡®æ€§è¾ƒä½ï¼Œä½†åœ¨ä¸€å®šæ¡ä»¶ä¸‹ï¼Œå¦‚é“¾å¼æ€ç»´ï¼ˆCoTï¼‰ã€å°‘æ ·æœ¬å’Œå¤šæ­¥æç¤ºç­‰æŠ€æœ¯å¯ä»¥æé«˜å…¶è¡¨ç°ã€‚è¯¥ç ”ç©¶ä¸ºAIè¾…åŠ©OSCEè¯„ä¼°æä¾›äº†å¯è¡Œæ€§è¯æ˜ï¼Œå¹¶ä¸ºæœªæ¥ä¸´åºŠæ²Ÿé€šæŠ€èƒ½è‡ªåŠ¨åŒ–è¯„ä¼°çš„ç ”ç©¶æä¾›äº†åŸºå‡†æ€§èƒ½è¯„ä¼°ã€‚</p>
<p><strong>Key Takeaways</strong>ï¼š</p>
<ol>
<li>LLMsè¢«æ¢ç´¢ç”¨äºè‡ªåŠ¨åŒ–è¯„ä¼°åŒ»ç–—å­¦ç”Ÿçš„ä¸´åºŠæ²Ÿé€šæŠ€èƒ½ã€‚</li>
<li>ç ”ç©¶ä½¿ç”¨äº†ä¸»é¢è¯•è¯„åˆ†é‡è¡¨ï¼ˆMIRSï¼‰æ¥è¯„ä¼°OSCEè¡¨ç°ã€‚</li>
<li>å››ç§LLMsåœ¨OSCEè¯„ä¼°ä¸­çš„å‡†ç¡®æ€§è¾ƒä½ï¼Œä½†CoTã€å°‘æ ·æœ¬å’Œå¤šæ­¥æç¤ºç­‰æŠ€æœ¯å¯ä»¥æé«˜å…¶è¡¨ç°ã€‚</li>
<li>LLMsçš„è¡¨ç°ä¸MIRSé¡¹ç›®ä¸€è‡´ï¼Œä¸å—é‡åˆ°é˜¶æ®µå’Œæ²Ÿé€šé¢†åŸŸçš„å½±å“ã€‚</li>
<li>ç ”ç©¶è¯æ˜äº†AIè¾…åŠ©OSCEè¯„ä»·çš„å¯è¡Œæ€§ã€‚</li>
<li>æ­¤ç ”ç©¶ä¸ºLLMsåœ¨è‡ªåŠ¨åŒ–è¯„ä¼°ä¸­çš„æ€§èƒ½æä¾›äº†åŸºå‡†è¯„ä¼°ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.13957">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-ca6c052861388ba8c775f57591bb3430.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-37d999fe25a9b28cbf80444b6a8d9e3a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-be5bdb139597be05965c655ef571aa72.jpg" align="middle">
</details>


<h1 id="-11"><a href="#-11" class="headerlink" title=""></a></h1><h2 id="Disentangling-Memory-and-Reasoning-Ability-in-Large-Language-Models"><a href="#Disentangling-Memory-and-Reasoning-Ability-in-Large-Language-Models" class="headerlink" title="Disentangling Memory and Reasoning Ability in Large Language Models"></a>Disentangling Memory and Reasoning Ability in Large Language Models</h2><p><strong>Authors:Mingyu Jin, Weidi Luo, Sitao Cheng, Xinyi Wang, Wenyue Hua, Ruixiang Tang, William Yang Wang, Yongfeng Zhang</strong></p>
<p>Large Language Models (LLMs) have demonstrated strong performance in handling complex tasks requiring both extensive knowledge and reasoning abilities. However, the existing LLM inference pipeline operates as an opaque process without explicit separation between knowledge retrieval and reasoning steps, making the modelâ€™s decision-making process unclear and disorganized. This ambiguity can lead to issues such as hallucinations and knowledge forgetting, which significantly impact the reliability of LLMs in high-stakes domains. In this paper, we propose a new inference paradigm that decomposes the complex inference process into two distinct and clear actions: (1) memory recall: which retrieves relevant knowledge, and (2) reasoning: which performs logical steps based on the recalled knowledge. To facilitate this decomposition, we introduce two special tokens memory and reason, guiding the model to distinguish between steps that require knowledge retrieval and those that involve reasoning. Our experiment results show that this decomposition not only improves model performance but also enhances the interpretability of the inference process, enabling users to identify sources of error and refine model responses effectively. The code is available at <a target="_blank" rel="noopener" href="https://github.com/MingyuJ666/Disentangling-Memory-and-Reasoning">https://github.com/MingyuJ666/Disentangling-Memory-and-Reasoning</a>. </p>
<blockquote>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨å¤„ç†éœ€è¦å¹¿æ³›çŸ¥è¯†å’Œæ¨ç†èƒ½åŠ›çš„å¤æ‚ä»»åŠ¡æ—¶è¡¨ç°å‡ºå¼ºå¤§çš„æ€§èƒ½ã€‚ç„¶è€Œï¼Œç°æœ‰çš„LLMæ¨ç†ç®¡é“ä½œä¸ºä¸€ä¸ªä¸é€æ˜çš„è¿‡ç¨‹ï¼Œæ²¡æœ‰æ˜ç¡®åœ°åˆ†ç¦»çŸ¥è¯†æ£€ç´¢å’Œæ¨ç†æ­¥éª¤ï¼Œå¯¼è‡´æ¨¡å‹çš„å†³ç­–è¿‡ç¨‹å˜å¾—æ¨¡ç³Šä¸”æ— åºã€‚è¿™ç§æ¨¡ç³Šæ€§å¯èƒ½å¯¼è‡´å¹»æƒ³å’ŒçŸ¥è¯†é—å¿˜ç­‰é—®é¢˜ï¼Œè¿™åœ¨é«˜é£é™©é¢†åŸŸæ˜¾è‘—å½±å“LLMçš„å¯é æ€§ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°çš„æ¨ç†èŒƒå¼ï¼Œå°†å¤æ‚çš„æ¨ç†è¿‡ç¨‹åˆ†è§£ä¸ºä¸¤ä¸ªæ˜ç¡®ä¸”ä¸åŒçš„åŠ¨ä½œï¼šï¼ˆ1ï¼‰è®°å¿†å›å¿†ï¼šæ£€ç´¢ç›¸å…³çŸ¥è¯†ï¼›ï¼ˆ2ï¼‰æ¨ç†ï¼šåŸºäºå›å¿†çš„çŸ¥è¯†è¿›è¡Œé€»è¾‘æ­¥éª¤ã€‚ä¸ºäº†ä¿ƒè¿›è¿™ç§åˆ†è§£ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸¤ä¸ªç‰¹æ®Šç¬¦å·â€œè®°å¿†â€å’Œâ€œæ¨ç†â€ï¼Œå¼•å¯¼æ¨¡å‹åŒºåˆ†éœ€è¦çŸ¥è¯†æ£€ç´¢çš„æ­¥éª¤å’Œæ¶‰åŠæ¨ç†çš„æ­¥éª¤ã€‚æˆ‘ä»¬çš„å®éªŒç»“æœè¡¨æ˜ï¼Œè¿™ç§åˆ†è§£ä¸ä»…æé«˜äº†æ¨¡å‹æ€§èƒ½ï¼Œè¿˜æé«˜äº†æ¨ç†è¿‡ç¨‹çš„å¯è§£é‡Šæ€§ï¼Œä½¿ç”¨æˆ·èƒ½å¤Ÿè¯†åˆ«é”™è¯¯æ¥æºå¹¶æœ‰æ•ˆåœ°æ”¹è¿›æ¨¡å‹å“åº”ã€‚ä»£ç å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/MingyuJ666/Disentangling-Memory-and-Reasoning%E4%B8%8A%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/MingyuJ666/Disentangling-Memory-and-Reasoningä¸Šæ‰¾åˆ°ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2411.13504v3">PDF</a> Accepted by ACL 2025</p>
<p><strong>Summary</strong></p>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨å¤„ç†éœ€è¦å¹¿æ³›çŸ¥è¯†å’Œæ¨ç†èƒ½åŠ›çš„å¤æ‚ä»»åŠ¡æ—¶è¡¨ç°å‡ºå¼ºå¤§çš„æ€§èƒ½ã€‚ç„¶è€Œï¼Œç°æœ‰LLMçš„æ¨ç†è¿‡ç¨‹ä¸å¤Ÿæ¸…æ™°ï¼Œç¼ºä¹æ˜ç¡®çš„å°†çŸ¥è¯†æ£€ç´¢å’Œæ¨ç†æ­¥éª¤åˆ†å¼€çš„æœºåˆ¶ï¼Œå¯¼è‡´æ¨¡å‹å†³ç­–è¿‡ç¨‹æ¨¡ç³Šå’Œæ··ä¹±ã€‚è¿™ç§æ¨¡ç³Šæ€§å¯èƒ½å¯¼è‡´çŸ¥è¯†é—å¿˜å’Œå¹»æƒ³ç­‰é—®é¢˜ï¼Œä¸¥é‡å½±å“LLMåœ¨é«˜é£é™©é¢†åŸŸçš„å¯é æ€§ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„æ¨ç†èŒƒå¼ï¼Œå°†å¤æ‚çš„æ¨ç†è¿‡ç¨‹åˆ†è§£ä¸ºä¸¤ä¸ªæ˜ç¡®ä¸”æ¸…æ™°çš„åŠ¨ä½œï¼šè®°å¿†å›å¿†å’Œæ¨ç†ã€‚è®°å¿†å›å¿†ç”¨äºæ£€ç´¢ç›¸å…³çŸ¥è¯†ï¼Œè€Œæ¨ç†åˆ™åŸºäºæ‰€å›å¿†çš„çŸ¥è¯†è¿›è¡Œé€»è¾‘æ­¥éª¤ã€‚é€šè¿‡å¼•å…¥è®°å¿†å’Œæ¨ç†ä¸¤ä¸ªç‰¹æ®Šä»¤ç‰Œæ¥æŒ‡å¯¼æ¨¡å‹åŒºåˆ†éœ€è¦çŸ¥è¯†æ£€ç´¢çš„æ­¥éª¤å’Œæ¶‰åŠæ¨ç†çš„æ­¥éª¤ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¿™ç§åˆ†è§£ä¸ä»…æé«˜äº†æ¨¡å‹æ€§èƒ½ï¼Œè¿˜æé«˜äº†æ¨ç†è¿‡ç¨‹çš„å¯è§£é‡Šæ€§ï¼Œä½¿ç”¨æˆ·èƒ½å¤Ÿè¯†åˆ«é”™è¯¯æ¥æºå¹¶æœ‰æ•ˆåœ°æ”¹è¿›æ¨¡å‹å“åº”ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>LLMåœ¨å¤„ç†å¤æ‚ä»»åŠ¡æ—¶è¡¨ç°å‡ºå¼ºå¤§çš„æ€§èƒ½ï¼Œä½†éœ€è¦æ”¹è¿›å…¶æ¨ç†è¿‡ç¨‹çš„æ¸…æ™°åº¦å’Œå¯è§£é‡Šæ€§ã€‚</li>
<li>ç°æœ‰LLMçš„æ¨ç†è¿‡ç¨‹ç¼ºä¹æ˜ç¡®çš„çŸ¥è¯†æ£€ç´¢å’Œæ¨ç†æ­¥éª¤åˆ†ç¦»ï¼Œå¯¼è‡´å†³ç­–è¿‡ç¨‹æ¨¡ç³Šã€‚</li>
<li>çŸ¥è¯†é—å¿˜å’Œå¹»æƒ³ç­‰é—®é¢˜å¯èƒ½å½±å“LLMåœ¨é«˜é£é™©é¢†åŸŸçš„å¯é æ€§ã€‚</li>
<li>æ–°çš„æ¨ç†èŒƒå¼å°†å¤æ‚çš„æ¨ç†è¿‡ç¨‹åˆ†è§£ä¸ºè®°å¿†å›å¿†å’Œæ¨ç†ä¸¤ä¸ªæ˜ç¡®åŠ¨ä½œã€‚</li>
<li>è®°å¿†å›å¿†è´Ÿè´£æ£€ç´¢ç›¸å…³çŸ¥è¯†ï¼Œè€Œæ¨ç†åˆ™åŸºäºæ‰€å›å¿†çš„çŸ¥è¯†è¿›è¡Œé€»è¾‘æ¨å¯¼ã€‚</li>
<li>é€šè¿‡å¼•å…¥è®°å¿†å’Œæ¨ç†ä¸¤ä¸ªç‰¹æ®Šä»¤ç‰Œï¼Œæ¨¡å‹èƒ½å¤ŸåŒºåˆ†éœ€è¦çŸ¥è¯†æ£€ç´¢çš„æ­¥éª¤å’Œæ¶‰åŠæ¨ç†çš„æ­¥éª¤ã€‚</li>
<li>å®éªŒç»“æœè¡¨æ˜ï¼Œè¿™ç§åˆ†è§£æé«˜äº†æ¨¡å‹æ€§èƒ½å’Œæ¨ç†è¿‡ç¨‹çš„å¯è§£é‡Šæ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2411.13504">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-824bbc11c404360746aed9df11067239.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f9b2c2e2e9755d0abd9ee244cd07afb0.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-41c87767ef8186eefe6d8f5f32b86322.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-e3887f499a45f3a715dfea3973df18fb.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-7321b1ff27e9a25c8574516d474a9199.jpg" align="middle">
</details>


<h1 id="-12"><a href="#-12" class="headerlink" title=""></a></h1><h2 id="SceneGenAgent-Precise-Industrial-Scene-Generation-with-Coding-Agent"><a href="#SceneGenAgent-Precise-Industrial-Scene-Generation-with-Coding-Agent" class="headerlink" title="SceneGenAgent: Precise Industrial Scene Generation with Coding Agent"></a>SceneGenAgent: Precise Industrial Scene Generation with Coding Agent</h2><p><strong>Authors:Xiao Xia, Dan Zhang, Zibo Liao, Zhenyu Hou, Tianrui Sun, Jing Li, Ling Fu, Yuxiao Dong</strong></p>
<p>The modeling of industrial scenes is essential for simulations in industrial manufacturing. While large language models (LLMs) have shown significant progress in generating general 3D scenes from textual descriptions, generating industrial scenes with LLMs poses a unique challenge due to their demand for precise measurements and positioning, requiring complex planning over spatial arrangement. To address this challenge, we introduce SceneGenAgent, an LLM-based agent for generating industrial scenes through C# code. SceneGenAgent ensures precise layout planning through a structured and calculable format, layout verification, and iterative refinement to meet the quantitative requirements of industrial scenarios. Experiment results demonstrate that LLMs powered by SceneGenAgent exceed their original performance, reaching up to 81.0% success rate in real-world industrial scene generation tasks and effectively meeting most scene generation requirements. To further enhance accessibility, we construct SceneInstruct, a dataset designed for fine-tuning open-source LLMs to integrate into SceneGenAgent. Experiments show that fine-tuning open-source LLMs on SceneInstruct yields significant performance improvements, with Llama3.1-70B approaching the capabilities of GPT-4o. Our code and data are available at <a target="_blank" rel="noopener" href="https://github.com/THUDM/SceneGenAgent">https://github.com/THUDM/SceneGenAgent</a> . </p>
<blockquote>
<p>å·¥ä¸šåœºæ™¯çš„å»ºæ¨¡å¯¹äºå·¥ä¸šåˆ¶é€ ä¸­çš„æ¨¡æ‹Ÿè‡³å…³é‡è¦ã€‚è™½ç„¶å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨æ ¹æ®æ–‡æœ¬æè¿°ç”Ÿæˆä¸€èˆ¬çš„3Dåœºæ™¯æ–¹é¢å–å¾—äº†æ˜¾è‘—è¿›å±•ï¼Œä½†ä½¿ç”¨LLMç”Ÿæˆå·¥ä¸šåœºæ™¯å´æ„æˆäº†ä¸€é¡¹ç‹¬ç‰¹æŒ‘æˆ˜ï¼Œå› ä¸ºå·¥ä¸šåœºæ™¯éœ€è¦ç²¾ç¡®çš„æµ‹é‡å’Œå®šä½ï¼Œå¹¶è¦æ±‚è¿›è¡Œå¤æ‚çš„ç©ºé—´å¸ƒå±€è§„åˆ’ã€‚ä¸ºäº†åº”å¯¹è¿™ä¸€æŒ‘æˆ˜ï¼Œæˆ‘ä»¬å¼•å…¥äº†SceneGenAgentï¼Œè¿™æ˜¯ä¸€ä¸ªåŸºäºLLMçš„ä»£ç†ï¼Œé€šè¿‡C#ä»£ç ç”Ÿæˆå·¥ä¸šåœºæ™¯ã€‚SceneGenAgenté€šè¿‡ç»“æ„åŒ–å’Œå¯è®¡ç®—æ ¼å¼ã€å¸ƒå±€éªŒè¯ä»¥åŠè¿­ä»£ä¼˜åŒ–ç¡®ä¿ç²¾ç¡®å¸ƒå±€è§„åˆ’ï¼Œä»¥æ»¡è¶³å·¥ä¸šåœºæ™¯çš„å®šé‡è¦æ±‚ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œç”±SceneGenAgentæ”¯æŒçš„LLMè¶…è¶Šäº†å…¶åŸå§‹æ€§èƒ½ï¼Œåœ¨ç°å®ä¸–ç•Œå·¥ä¸šåœºæ™¯ç”Ÿæˆä»»åŠ¡ä¸­çš„æˆåŠŸç‡é«˜è¾¾8 ç»“ä½™ä»¥ä¸Šï¼Œå¹¶æœ‰æ•ˆåœ°æ»¡è¶³äº†å¤§å¤šæ•°åœºæ™¯ç”Ÿæˆè¦æ±‚ã€‚ä¸ºäº†è¿›ä¸€æ­¥æé«˜å¯åŠæ€§ï¼Œæˆ‘ä»¬æ„å»ºäº†SceneInstructæ•°æ®é›†ï¼Œç”¨äºå¾®è°ƒå¼€æºLLMä»¥é›†æˆåˆ°SceneGenAgentä¸­ã€‚å®éªŒè¡¨æ˜ï¼Œåœ¨SceneInstructä¸Šå¾®è°ƒå¼€æºLLMä¼šæ˜¾è‘—æé«˜æ€§èƒ½ï¼ŒLlama3.1-70Bæ¥è¿‘GPT-4oçš„èƒ½åŠ›ã€‚æˆ‘ä»¬çš„ä»£ç å’Œæ•°æ®é›†å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/THUDM/SceneGenAgent%E4%B8%8A%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/THUDM/SceneGenAgentä¸Šæ‰¾åˆ°ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2410.21909v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„SceneGenAgentåœ¨æ¨¡æ‹Ÿå·¥ä¸šåˆ¶é€ ä¸­çš„å·¥ä¸šåœºæ™¯å»ºæ¨¡æ–¹é¢å…·æœ‰å…³é”®ä½œç”¨ã€‚é€šè¿‡C#ä»£ç ï¼ŒSceneGenAgentèƒ½å¤Ÿç¡®ä¿ç²¾ç¡®å¸ƒå±€è§„åˆ’ï¼Œæ»¡è¶³å·¥ä¸šåœºæ™¯çš„å®šé‡è¦æ±‚ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒSceneGenAgentä½¿LLMçš„æ€§èƒ½è¶…è¶Šäº†åŸå§‹æ°´å¹³ï¼Œåœ¨ç°å®ä¸–ç•Œçš„å·¥ä¸šåœºæ™¯ç”Ÿæˆä»»åŠ¡ä¸­è¾¾åˆ°äº†81.0%çš„æˆåŠŸç‡ã€‚ä¸ºè¿›ä¸€æ­¥æé«˜å¯ç”¨æ€§ï¼Œç ”ç©¶è€…æ„å»ºäº†SceneInstructæ•°æ®é›†ï¼Œç”¨äºå¾®è°ƒå¼€æºLLMä»¥é›†æˆåˆ°SceneGenAgentä¸­ã€‚ç»è¿‡SceneInstructæ•°æ®é›†è®­ç»ƒçš„LLMè¡¨ç°å‡ºæ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚ç›¸å…³ä»£ç å’Œæ•°æ®å·²ä¸Šä¼ è‡³GitHubä»“åº“ï¼š<a target="_blank" rel="noopener" href="https://github.com/THUDM/SceneGenAgent">https://github.com/THUDM/SceneGenAgent</a> ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å·¥ä¸šåœºæ™¯å»ºæ¨¡å¯¹äºå·¥ä¸šåˆ¶é€ ä»¿çœŸè‡³å…³é‡è¦ã€‚</li>
<li>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨ç”Ÿæˆå·¥ä¸šåœºæ™¯æ—¶é¢ä¸´ç²¾ç¡®æµ‹é‡å’Œå®šä½çš„æŒ‘æˆ˜ã€‚</li>
<li>SceneGenAgentæ˜¯ä¸€ä¸ªåŸºäºLLMçš„ä»£ç†ï¼Œèƒ½å¤Ÿé€šè¿‡C#ä»£ç ç”Ÿæˆå·¥ä¸šåœºæ™¯ï¼Œç¡®ä¿ç²¾ç¡®å¸ƒå±€è§„åˆ’ã€‚</li>
<li>SceneGenAgentæˆåŠŸè§£å†³äº†å·¥ä¸šåœºæ™¯ç”Ÿæˆä»»åŠ¡ä¸­çš„æŒ‘æˆ˜ï¼Œè¾¾åˆ°äº†é«˜è¾¾81.0%çš„æˆåŠŸç‡ã€‚</li>
<li>SceneInstructæ•°æ®é›†æ—¨åœ¨å¾®è°ƒå¼€æºLLMä»¥æé«˜æ€§èƒ½å¹¶é›†æˆåˆ°SceneGenAgentä¸­ã€‚</li>
<li>ä½¿ç”¨SceneInstructæ•°æ®é›†è¿›è¡Œå¾®è°ƒçš„LLMè¡¨ç°å‡ºæ˜¾è‘—æ€§èƒ½æå‡ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2410.21909">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-d72c9b73aa31a85f264c24a2f8949036.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-627eef0e7a3732794dd28d8a4a5db50a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b839fc2203096ac75572c50df0b8facf.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-894f6287bdacbcbc19a7219298033b98.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-5dcabc9e7d5e2016dfebbff14da52587.jpg" align="middle">
</details>


<h1 id="-13"><a href="#-13" class="headerlink" title=""></a></h1><h2 id="PyramidKV-Dynamic-KV-Cache-Compression-based-on-Pyramidal-Information-Funneling"><a href="#PyramidKV-Dynamic-KV-Cache-Compression-based-on-Pyramidal-Information-Funneling" class="headerlink" title="PyramidKV: Dynamic KV Cache Compression based on Pyramidal Information   Funneling"></a>PyramidKV: Dynamic KV Cache Compression based on Pyramidal Information   Funneling</h2><p><strong>Authors:Zefan Cai, Yichi Zhang, Bofei Gao, Yuliang Liu, Yucheng Li, Tianyu Liu, Keming Lu, Wayne Xiong, Yue Dong, Junjie Hu, Wen Xiao</strong></p>
<p>In this study, we investigate whether attention-based information flow inside large language models (LLMs) is aggregated through noticeable patterns for long context processing. Our observations reveal that LLMs aggregate information through Pyramidal Information Funneling where attention is scattering widely in lower layers, progressively consolidating within specific contexts, and ultimately focusing on critical tokens (a.k.a massive activation or attention sink) in higher layers. Motivated by these insights, we developed PyramidKV, a novel and effective KV cache compression method. This approach dynamically adjusts the KV cache size across different layers, allocating more cache in lower layers and less in higher ones, diverging from traditional methods that maintain a uniform KV cache size. Our experimental evaluations, utilizing the LongBench benchmark, show that PyramidKV matches the performance of models with a full KV cache while retaining only 12% of the KV cache, thus significantly reducing memory usage. In scenarios emphasizing memory efficiency, where only 0.7% of the KV cache is maintained, PyramidKV surpasses other KV cache compression techniques, achieving up to a 20.5 absolute accuracy improvement on TREC dataset. In the Needle-in-a-Haystack experiment, PyramidKV outperforms competing methods in maintaining long-context comprehension in LLMs; notably, retaining just 128 KV cache entries enables the LLAMA-3-70B model to achieve 100.0 Acc. performance. </p>
<blockquote>
<p>åœ¨è¿™é¡¹ç ”ç©¶ä¸­ï¼Œæˆ‘ä»¬æ¢ç©¶å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä¸­çš„åŸºäºæ³¨æ„åŠ›çš„ä¿¡æ¯æµæ˜¯å¦é€šè¿‡æ˜¾è‘—æ¨¡å¼è¿›è¡Œé•¿æœŸä¸Šä¸‹æ–‡å¤„ç†ã€‚æˆ‘ä»¬çš„è§‚å¯Ÿå‘ç°ï¼ŒLLMé€šè¿‡é‡‘å­—å¡”ä¿¡æ¯æ±‡é›†æ¥æ•´åˆä¿¡æ¯ï¼Œå…¶ä¸­æ³¨æ„åŠ›åœ¨ä¸‹å±‚å¹¿æ³›åˆ†æ•£ï¼Œç‰¹å®šä¸Šä¸‹æ–‡ä¸­é€æ­¥å·©å›ºï¼Œå¹¶æœ€ç»ˆèšç„¦äºé«˜å±‚çš„å…³é”®ä»¤ç‰Œï¼ˆä¹Ÿç§°ä¸ºå¤§é‡æ¿€æ´»æˆ–æ³¨æ„åŠ›æ±‡ï¼‰ã€‚å—è¿™äº›è§è§£çš„å¯å‘ï¼Œæˆ‘ä»¬å¼€å‘äº†ä¸€ç§æ–°å‹æœ‰æ•ˆçš„KVç¼“å­˜å‹ç¼©æ–¹æ³•â€”â€”PyramidKVã€‚è¯¥æ–¹æ³•åŠ¨æ€è°ƒæ•´ä¸åŒå±‚çš„KVç¼“å­˜å¤§å°ï¼Œåœ¨ä¸‹å±‚åˆ†é…æ›´å¤šç¼“å­˜ï¼Œä¸Šå±‚åˆ†é…è¾ƒå°‘ï¼Œè¿™ä¸ä¼ ç»Ÿæ–¹æ³•ä¿æŒç»Ÿä¸€çš„KVç¼“å­˜å¤§å°ä¸åŒã€‚æˆ‘ä»¬çš„å®éªŒè¯„ä¼°ï¼Œåˆ©ç”¨LongBenchåŸºå‡†æµ‹è¯•ï¼Œæ˜¾ç¤ºPyramidKVåœ¨ä»…ä¿ç•™KVç¼“å­˜çš„12%çš„æƒ…å†µä¸‹ï¼Œå°±èƒ½è¾¾åˆ°å…¨KVç¼“å­˜æ¨¡å‹çš„æ€§èƒ½ï¼Œä»è€Œæ˜¾è‘—å‡å°‘å†…å­˜ä½¿ç”¨ã€‚åœ¨å¼ºè°ƒå†…å­˜æ•ˆç‡çš„æƒ…å¢ƒä¸­ï¼Œä»…ç»´æŒ0.7%çš„KVç¼“å­˜ï¼ŒPyramidKvè¶…è¶Šå…¶ä»–KVç¼“å­˜å‹ç¼©æŠ€æœ¯ï¼Œåœ¨TRECæ•°æ®é›†ä¸Šå®ç°é«˜è¾¾20.5çš„ç»å¯¹ç²¾åº¦æå‡ã€‚åœ¨â€œå¤§æµ·æé’ˆâ€å®éªŒä¸­ï¼ŒPyramidKVåœ¨ä¿æŒLLMçš„é•¿æœŸä¸Šä¸‹æ–‡ç†è§£æ–¹é¢è¡¨ç°ä¼˜äºå…¶ä»–æ–¹æ³•ï¼Œå€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œä»…ä¿ç•™128ä¸ªKVç¼“å­˜æ¡ç›®å°±èƒ½ä½¿LLAMA-3-70Bæ¨¡å‹è¾¾åˆ°100.0%çš„å‡†ç¡®ç‡æ€§èƒ½ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2406.02069v4">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬ç ”ç©¶æ¢è®¨äº†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä¸­åŸºäºæ³¨æ„åŠ›çš„ä¿¡æ¯æµæ˜¯å¦é€šè¿‡æ˜¾è‘—æ¨¡å¼è¿›è¡Œé•¿æœŸä¸Šä¸‹æ–‡å¤„ç†ã€‚ç ”ç©¶å‘ç°LLMé€šè¿‡é‡‘å­—å¡”ä¿¡æ¯æ±‡èšæ¥æ•´åˆä¿¡æ¯ï¼Œæ³¨æ„åŠ›åœ¨ä½å±‚å¹¿æ³›åˆ†å¸ƒï¼Œç„¶ååœ¨ç‰¹å®šä¸Šä¸‹æ–‡ä¸­é€æ¸å·©å›ºï¼Œå¹¶æœ€ç»ˆèšç„¦äºé«˜å±‚çš„å…³é”®æ ‡è®°ï¼ˆå³å¤§è§„æ¨¡æ¿€æ´»æˆ–æ³¨æ„åŠ›æ±‡ï¼‰ã€‚åŸºäºæ­¤ï¼Œç ”ç©¶å›¢é˜Ÿå¼€å‘äº†ä¸€ç§æ–°å‹çš„KVç¼“å­˜å‹ç¼©æ–¹æ³•â€”â€”PyramidKVã€‚è¯¥æ–¹æ³•åŠ¨æ€è°ƒæ•´ä¸åŒå±‚çš„KVç¼“å­˜å¤§å°ï¼Œåœ¨ä½å±‚åˆ†é…æ›´å¤šç¼“å­˜ï¼Œé«˜å±‚åˆ™åˆ†é…è¾ƒå°‘ï¼Œä¸ä¼ ç»Ÿç»´æŒç»Ÿä¸€KVç¼“å­˜å¤§å°çš„æ–¹æ³•ä¸åŒã€‚å®éªŒè¯„ä¼°æ˜¾ç¤ºï¼ŒPyramidKVåœ¨ä»…ä¿ç•™KVç¼“å­˜çš„12%æ—¶ï¼Œæ€§èƒ½ä¸å…¨KVç¼“å­˜æ¨¡å‹ç›¸åŒ¹é…ï¼Œæ˜¾è‘—é™ä½äº†å†…å­˜ä½¿ç”¨ã€‚åœ¨å¼ºè°ƒå†…å­˜æ•ˆç‡çš„æƒ…å¢ƒä¸­ï¼Œä»…ç»´æŠ¤0.7%çš„KVç¼“å­˜æ—¶ï¼ŒPyramidKVè¶…è¶Šå…¶ä»–KVç¼“å­˜å‹ç¼©æŠ€æœ¯ï¼Œåœ¨TRECæ•°æ®é›†ä¸Šå®ç°äº†é«˜è¾¾20.5çš„ç»å¯¹ç²¾åº¦æå‡ã€‚åœ¨Haystackå®éªŒä¸­çš„â€œæ²™é‡Œæ·˜é‡‘â€ä»»åŠ¡ä¸­ï¼ŒPyramidKVåœ¨ä¿æŒLLMçš„é•¿æœŸä¸Šä¸‹æ–‡ç†è§£èƒ½åŠ›æ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œä»…ä¿ç•™128ä¸ªKVç¼“å­˜æ¡ç›®ï¼Œä½¿LLAMA-3-70Bæ¨¡å‹è¾¾åˆ°100.0%çš„å‡†ç¡®ç‡ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰é€šè¿‡é‡‘å­—å¡”ä¿¡æ¯æ±‡èšæ•´åˆä¿¡æ¯ï¼Œæ³¨æ„åŠ›åœ¨ä¸åŒå±‚çº§æœ‰ç‰¹å®šçš„åˆ†å¸ƒæ¨¡å¼ã€‚</li>
<li>PyramidKVæ˜¯ä¸€ç§æ–°å‹çš„KVç¼“å­˜å‹ç¼©æ–¹æ³•ï¼ŒåŠ¨æ€è°ƒæ•´ä¸åŒå±‚çš„KVç¼“å­˜å¤§å°ã€‚</li>
<li>PyramidKVåœ¨å†…å­˜ä½¿ç”¨æ–¹é¢è¡¨ç°å‡ºæ˜¾è‘—ä¼˜åŠ¿ï¼Œå¯ä»¥åœ¨ä¿ç•™è¾ƒå°‘çš„KVç¼“å­˜æ—¶ä»ä¿æŒè‰¯å¥½çš„æ€§èƒ½ã€‚</li>
<li>åœ¨å¼ºè°ƒå†…å­˜æ•ˆç‡çš„æƒ…å¢ƒä¸­ï¼ŒPyramidKVè¾ƒå…¶ä»–KVç¼“å­˜å‹ç¼©æŠ€æœ¯æœ‰æ›´é«˜çš„ç²¾åº¦è¡¨ç°ã€‚</li>
<li>PyramidKVæœ‰åŠ©äºLLMåœ¨é•¿æœŸä¸Šä¸‹æ–‡å¤„ç†ä¸­ä¿æŒé«˜æ€§èƒ½ã€‚</li>
<li>åœ¨ç‰¹å®šçš„å®éªŒä¸­ï¼ŒPyramidKVä½¿LLAMA-3-70Bæ¨¡å‹è¾¾åˆ°100%çš„å‡†ç¡®ç‡ï¼Œæ˜¾ç¤ºå‡ºå…¶æœ‰æ•ˆæ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2406.02069">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-e43311cd731c7206d189d8347bac2619.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-81576edb6bcb83188d7b3c01f6a4b125.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-bd4943877ccae5f5917cd8035ce3b14a.jpg" align="middle">
</details>


<h1 id="-14"><a href="#-14" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-05-17/LLM/">https://kedreamix.github.io/Talk2Paper/Paper/2025-05-17/LLM/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/LLM/">
                                    <span class="chip bg-color">LLM</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-05-17/Agent/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-d72c9b73aa31a85f264c24a2f8949036.jpg" class="responsive-img" alt="Agent">
                        
                        <span class="card-title">Agent</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Agent æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-05-17  AutoPentest Enhancing Vulnerability Management With Autonomous LLM   Agents
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-05-17
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Agent/" class="post-category">
                                    Agent
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Agent/">
                        <span class="chip bg-color">Agent</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-05-17/R1_Reasoning/">
                    <div class="card-image">
                        
                        <img src="https://pic1.zhimg.com/v2-5500fd3be27b12fed78b895cb32542d0.jpg" class="responsive-img" alt="R1_Reasoning">
                        
                        <span class="card-title">R1_Reasoning</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            R1_Reasoning æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-05-17  MathCoder-VL Bridging Vision and Code for Enhanced Multimodal   Mathematical Reasoning
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-05-17
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/R1-Reasoning/" class="post-category">
                                    R1_Reasoning
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/R1-Reasoning/">
                        <span class="chip bg-color">R1_Reasoning</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">30166.1k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
