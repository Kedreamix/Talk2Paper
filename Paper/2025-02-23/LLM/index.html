<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="LLM">
    <meta name="description" content="LLM æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-02-23  OpenCharacter Training Customizable Role-Playing LLMs with Large-Scale   Synthetic Personas">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>LLM | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://pic1.zhimg.com/v2-a47f2f13235fbbbaee0fbc6127180b0e.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">LLM</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/LLM/">
                                <span class="chip bg-color">LLM</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/LLM/" class="post-category">
                                LLM
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-02-23
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-05-14
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    12.8k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    52 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-02-23-æ›´æ–°"><a href="#2025-02-23-æ›´æ–°" class="headerlink" title="2025-02-23 æ›´æ–°"></a>2025-02-23 æ›´æ–°</h1><h2 id="OpenCharacter-Training-Customizable-Role-Playing-LLMs-with-Large-Scale-Synthetic-Personas"><a href="#OpenCharacter-Training-Customizable-Role-Playing-LLMs-with-Large-Scale-Synthetic-Personas" class="headerlink" title="OpenCharacter: Training Customizable Role-Playing LLMs with Large-Scale   Synthetic Personas"></a>OpenCharacter: Training Customizable Role-Playing LLMs with Large-Scale   Synthetic Personas</h2><p><strong>Authors:Xiaoyang Wang, Hongming Zhang, Tao Ge, Wenhao Yu, Dian Yu, Dong Yu</strong></p>
<p>Customizable role-playing in large language models (LLMs), also known as character generalization, is gaining increasing attention for its versatility and cost-efficiency in developing and deploying role-playing dialogue agents. This study explores a large-scale data synthesis approach to equip LLMs with character generalization capabilities. We begin by synthesizing large-scale character profiles using personas from Persona Hub and then explore two strategies: response rewriting and response generation, to create character-aligned instructional responses. To validate the effectiveness of our synthetic instruction tuning data for character generalization, we perform supervised fine-tuning (SFT) using the LLaMA-3 8B model. Our best-performing model strengthens the original LLaMA-3 8B Instruct model and achieves performance comparable to GPT-4o models on role-playing dialogue. We release our synthetic characters and instruction-tuning dialogues to support public research. </p>
<blockquote>
<p>åœ¨å¤§è§„æ¨¡è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä¸­çš„è§’è‰²å®šåˆ¶ï¼Œä¹Ÿè¢«ç§°ä¸ºè§’è‰²æ³›åŒ–ï¼Œå› å…¶è§’è‰²æ‰®æ¼”å¯¹è¯ä»£ç†çš„å¼€å‘å’Œéƒ¨ç½²ä¸­çš„çµæ´»æ€§å’Œæˆæœ¬æ•ˆç›Šè€Œå—åˆ°è¶Šæ¥è¶Šå¤šçš„å…³æ³¨ã€‚æœ¬ç ”ç©¶æ¢ç´¢äº†ä¸€ç§å¤§è§„æ¨¡æ•°æ®åˆæˆæ–¹æ³•æ¥ä¸ºLLMæä¾›è§’è‰²æ³›åŒ–èƒ½åŠ›ã€‚æˆ‘ä»¬é¦–å…ˆä½¿ç”¨Persona Hubä¸­çš„äººç‰©æ¥åˆæˆå¤§è§„æ¨¡çš„è§’è‰²ç‰¹å¾ï¼Œç„¶åæ¢ç´¢ä¸¤ç§ç­–ç•¥ï¼šå“åº”é‡å†™å’Œå“åº”ç”Ÿæˆï¼Œæ¥åˆ›å»ºä¸è§’è‰²å¯¹é½çš„æŒ‡ä»¤å“åº”ã€‚ä¸ºäº†éªŒè¯æˆ‘ä»¬åˆæˆæŒ‡ä»¤è°ƒæ•´æ•°æ®å¯¹äºè§’è‰²æ³›åŒ–çš„æœ‰æ•ˆæ€§ï¼Œæˆ‘ä»¬ä½¿ç”¨LLaMA-3 8Bæ¨¡å‹è¿›è¡Œæœ‰ç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰ã€‚æˆ‘ä»¬è¡¨ç°æœ€å¥½çš„æ¨¡å‹å¼ºåŒ–äº†åŸå§‹çš„LLaMA-3 8BæŒ‡ä»¤æ¨¡å‹ï¼Œå¹¶åœ¨è§’è‰²æ‰®æ¼”å¯¹è¯æ–¹é¢è¾¾åˆ°äº†ä¸GPT-4oæ¨¡å‹ç›¸å½“çš„æ€§èƒ½ã€‚æˆ‘ä»¬å‘å¸ƒæˆ‘ä»¬çš„åˆæˆè§’è‰²å’ŒæŒ‡ä»¤è°ƒæ•´å¯¹è¯ä»¥æ”¯æŒå…¬å¼€ç ”ç©¶ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.15427v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä¸­çš„è§’è‰²å®šåˆ¶èƒ½åŠ›ï¼Œå³è§’è‰²æ³›åŒ–èƒ½åŠ›ï¼Œå› å…¶çµæ´»æ€§å’Œå¼€å‘éƒ¨ç½²æˆæœ¬æ•ˆç›Šè€Œå—åˆ°è¶Šæ¥è¶Šå¤šçš„å…³æ³¨ã€‚æœ¬ç ”ç©¶æ¢ç´¢äº†ä¸€ç§å¤§è§„æ¨¡æ•°æ®åˆæˆæ–¹æ³•æ¥ä¸ºLLMæä¾›è§’è‰²æ³›åŒ–èƒ½åŠ›ã€‚é€šè¿‡åˆæˆå¤§è§„æ¨¡è§’è‰²é…ç½®æ–‡ä»¶å¹¶ä½¿ç”¨Persona Hubä¸­çš„ä¸ªæ€§è¿›è¡Œåˆæ­¥ç ”ç©¶ï¼Œæˆ‘ä»¬æ¢ç´¢äº†ä¸¤ç§ç­–ç•¥ï¼šå“åº”é‡å†™å’Œå“åº”ç”Ÿæˆï¼Œä»¥åˆ›å»ºä¸è§’è‰²å¯¹é½çš„æŒ‡ä»¤å“åº”ã€‚ä¸ºäº†éªŒè¯æˆ‘ä»¬çš„åˆæˆæŒ‡ä»¤å¾®è°ƒæ•°æ®å¯¹è§’è‰²æ³›åŒ–çš„æœ‰æ•ˆæ€§ï¼Œæˆ‘ä»¬ä½¿ç”¨LLaMA-3 8Bæ¨¡å‹è¿›è¡Œæœ‰ç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰ã€‚æˆ‘ä»¬è¡¨ç°æœ€ä½³çš„æ¨¡å‹å¢å¼ºäº†åŸå§‹çš„LLaMA-3 8BæŒ‡ä»¤æ¨¡å‹åœ¨è§’è‰²æ‰®æ¼”å¯¹è¯ä¸Šçš„è¡¨ç°ï¼Œè¾¾åˆ°äº†GPT-4oæ¨¡å‹çš„æ€§èƒ½æ°´å¹³ã€‚æˆ‘ä»¬å‘å¸ƒæˆ‘ä»¬çš„åˆæˆè§’è‰²å’ŒæŒ‡ä»¤è°ƒæ•´å¯¹è¯ä»¥æ”¯æŒå…¬å¼€ç ”ç©¶ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„è§’è‰²å®šåˆ¶èƒ½åŠ›å› å…¶çµæ´»æ€§å’Œæˆæœ¬æ•ˆç›Šè€Œå—åˆ°å…³æ³¨ã€‚</li>
<li>ç ”ç©¶è€…é€šè¿‡åˆæˆå¤§è§„æ¨¡è§’è‰²é…ç½®æ–‡ä»¶æ¥èµ‹äºˆLLMè§’è‰²æ³›åŒ–èƒ½åŠ›ã€‚</li>
<li>ä½¿ç”¨Persona Hubä¸­çš„ä¸ªæ€§è¿›è¡Œåˆæ­¥ç ”ç©¶ï¼Œæ¢ç´¢äº†å“åº”é‡å†™å’Œå“åº”ç”Ÿæˆä¸¤ç§ç­–ç•¥æ¥åˆ›å»ºä¸è§’è‰²å¯¹é½çš„æŒ‡ä»¤å“åº”ã€‚</li>
<li>é€šè¿‡æœ‰ç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰éªŒè¯äº†åˆæˆæŒ‡ä»¤å¾®è°ƒæ•°æ®çš„æœ‰æ•ˆæ€§ã€‚</li>
<li>æœ€ä½³æ¨¡å‹çš„æ€§èƒ½ä¸GPT-4oæ¨¡å‹åœ¨è§’è‰²æ‰®æ¼”å¯¹è¯ä¸Šçš„è¡¨ç°ç›¸å½“ã€‚</li>
<li>ç ”ç©¶è€…å‘å¸ƒäº†åˆæˆè§’è‰²å’ŒæŒ‡ä»¤è°ƒæ•´å¯¹è¯ä»¥æ”¯æŒå…¬å¼€ç ”ç©¶ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.15427">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-7d36fdd01cf33ef39caa45b2ab2d3b5d.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-4932b18bf311842a7de635f677db8e99.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-7647264287bb7eda0c1b6aa99caea2a4.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-457ab20813c063a0001592a1adf9fc34.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="LinguaLIFT-An-Effective-Two-stage-Instruction-Tuning-Framework-for-Low-Resource-Language-Reasoning"><a href="#LinguaLIFT-An-Effective-Two-stage-Instruction-Tuning-Framework-for-Low-Resource-Language-Reasoning" class="headerlink" title="LinguaLIFT: An Effective Two-stage Instruction Tuning Framework for   Low-Resource Language Reasoning"></a>LinguaLIFT: An Effective Two-stage Instruction Tuning Framework for   Low-Resource Language Reasoning</h2><p><strong>Authors:Hongbin Zhang, Kehai Chen, Xuefeng Bai, Yang Xiang, Min Zhang</strong></p>
<p>Large language models (LLMs) have exhibited impressive multilingual reasoning capabilities, driven by extensive multilingual pre-training corpora and instruction fine-tuning data. However, a performance gap exists between high- and low-resource language reasoning tasks due to the language imbalance in the pre-training corpus, which is exacerbated by evaluation bias in existing reasoning benchmarks lacking low-resource language coverage. To alleviate this issue, we propose LinguaLIFT, a two-stage instruction tuning framework for advancing low-resource language reasoning. LinguaLIFT employs a language alignment layer to capture multilingual alignment in a code-switched tuning way without requiring multilingual instruction or parallel data, thereby transferring the cross-lingual reasoning capabilities to low-resource languages through English-only instruction tuning data. To comprehensively evaluate the multilingual reasoning capabilities, we introduce the Multilingual Math World Problem (MMWP) benchmark, which spans 21 low-resource, 17 medium-resource, and 10 high-resource languages. Experimental results show that LinguaLIFT outperforms several competitive baselines across MMWP and four widely used benchmarks. </p>
<blockquote>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰è¡¨ç°å‡ºäº†ä»¤äººå°è±¡æ·±åˆ»çš„è·¨è¯­è¨€æ¨ç†èƒ½åŠ›ï¼Œè¿™å¾—ç›Šäºå¤§é‡çš„è·¨è¯­è¨€é¢„è®­ç»ƒè¯­æ–™åº“å’ŒæŒ‡ä»¤å¾®è°ƒæ•°æ®ã€‚ç„¶è€Œï¼Œç”±äºé¢„è®­ç»ƒè¯­æ–™åº“ä¸­çš„è¯­è¨€ä¸å¹³è¡¡ï¼Œé«˜èµ„æºè¯­è¨€æ¨ç†ä»»åŠ¡ä¸ä½èµ„æºè¯­è¨€æ¨ç†ä»»åŠ¡ä¹‹é—´å­˜åœ¨æ€§èƒ½å·®è·ï¼Œè€Œç°æœ‰æ¨ç†åŸºå‡†æµ‹è¯•ä¸­çš„è¯„ä¼°åè§ç¼ºä¹ä½èµ„æºè¯­è¨€è¦†ç›–ï¼Œè¿™ä¸€å·®è·è¿›ä¸€æ­¥åŠ å‰§ã€‚ä¸ºäº†ç¼“è§£è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†LinguaLIFTï¼Œè¿™æ˜¯ä¸€ä¸ªä¸¤é˜¶æ®µçš„æŒ‡ä»¤è°ƒæ•´æ¡†æ¶ï¼Œç”¨äºæå‡ä½èµ„æºè¯­è¨€æ¨ç†ã€‚LinguaLIFTé‡‡ç”¨è¯­è¨€å¯¹é½å±‚æ¥æ•æ‰ä»£ç åˆ‡æ¢è°ƒæ•´æ–¹å¼ä¸­çš„å¤šè¯­è¨€å¯¹é½ï¼Œæ— éœ€å¤šè¯­è¨€æŒ‡ä»¤æˆ–å¹³è¡Œæ•°æ®ï¼Œä»è€Œé€šè¿‡ä»…è‹±è¯­æŒ‡ä»¤è°ƒæ•´æ•°æ®è½¬ç§»è·¨è¯­è¨€æ¨ç†èƒ½åŠ›åˆ°ä½èµ„æºè¯­è¨€ã€‚ä¸ºäº†å…¨é¢è¯„ä¼°å¤šè¯­è¨€æ¨ç†èƒ½åŠ›ï¼Œæˆ‘ä»¬å¼•å…¥äº†å¤šè¯­è¨€æ•°å­¦ä¸–ç•Œé—®é¢˜ï¼ˆMMWPï¼‰åŸºå‡†æµ‹è¯•ï¼Œå®ƒæ¶µç›–21ç§ä½èµ„æºè¯­è¨€ã€17ç§ä¸­èµ„æºè¯­è¨€å’Œ1.0ç§é«˜èµ„æºè¯­è¨€ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒLinguaLIFTåœ¨MMWPå’Œå››ä¸ªå¹¿æ³›ä½¿ç”¨çš„åŸºå‡†æµ‹è¯•ä¸­è¶…è¶Šäº†å‡ ä¸ªç«äº‰åŸºçº¿ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.12499v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å…·å¤‡å¼ºå¤§çš„è·¨è¯­è¨€æ¨ç†èƒ½åŠ›ï¼Œå¾—ç›Šäºä¸°å¯Œçš„è·¨è¯­è¨€é¢„è®­ç»ƒè¯­æ–™åº“å’ŒæŒ‡ä»¤å¾®è°ƒæ•°æ®ã€‚ç„¶è€Œï¼Œç”±äºé¢„è®­ç»ƒè¯­æ–™åº“ä¸­çš„è¯­è¨€ä¸å¹³è¡¡å’Œç°æœ‰æ¨ç†åŸºå‡†æµ‹è¯•å¯¹ä½èµ„æºè¯­è¨€çš„è¦†ç›–ä¸è¶³ï¼Œé«˜èµ„æºè¯­è¨€ä¸ä½èµ„æºè¯­è¨€ä¹‹é—´çš„æ¨ç†ä»»åŠ¡å­˜åœ¨æ€§èƒ½å·®è·ã€‚ä¸ºè§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºLinguaLIFTï¼Œè¿™æ˜¯ä¸€ä¸ªä¸¤é˜¶æ®µçš„æŒ‡ä»¤è°ƒæ•´æ¡†æ¶ï¼Œæ—¨åœ¨æå‡ä½èµ„æºè¯­è¨€çš„æ¨ç†èƒ½åŠ›ã€‚LinguaLIFTé‡‡ç”¨è¯­è¨€å¯¹é½å±‚ï¼Œä»¥ä»£ç åˆ‡æ¢çš„æ–¹å¼æ•æ‰å¤šè¯­è¨€å¯¹é½ï¼Œæ— éœ€å¤šè¯­è¨€æŒ‡ä»¤æˆ–å¹³è¡Œæ•°æ®ï¼Œé€šè¿‡ä»…ä½¿ç”¨è‹±è¯­æŒ‡ä»¤è°ƒæ•´æ•°æ®ï¼Œå°†è·¨è¯­è¨€æ¨ç†èƒ½åŠ›è½¬ç§»åˆ°ä½èµ„æºè¯­è¨€ã€‚ä¸ºå…¨é¢è¯„ä¼°å¤šè¯­è¨€æ¨ç†èƒ½åŠ›ï¼Œæˆ‘ä»¬å¼•å…¥äº†è·¨å¤šç§è¯­è¨€çš„æ•°å­¦ä¸–ç•Œé—®é¢˜ï¼ˆMMWPï¼‰åŸºå‡†æµ‹è¯•ï¼Œæ¶µç›–21ç§ä½èµ„æºã€17ç§ä¸­ç­‰èµ„æºå’Œ10ç§é«˜èµ„æºè¯­è¨€ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒLinguaLIFTåœ¨MMWPå’Œå››ä¸ªå¹¿æ³›ä½¿ç”¨çš„åŸºå‡†æµ‹è¯•ä¸­è¶…è¶Šäº†å‡ ä¸ªç«äº‰å¯¹æ‰‹ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>LLMå…·å¤‡å¼ºå¤§çš„è·¨è¯­è¨€æ¨ç†èƒ½åŠ›ï¼Œå¾—ç›Šäºé¢„è®­ç»ƒè¯­æ–™åº“å’ŒæŒ‡ä»¤å¾®è°ƒæ•°æ®ã€‚</li>
<li>é«˜èµ„æºè¯­è¨€ä¸ä½èµ„æºè¯­è¨€ä¹‹é—´çš„æ¨ç†ä»»åŠ¡å­˜åœ¨æ€§èƒ½å·®è·ï¼Œä¸»è¦ç”±äºé¢„è®­ç»ƒè¯­æ–™åº“ä¸­çš„è¯­è¨€ä¸å¹³è¡¡å’Œç°æœ‰æ¨ç†åŸºå‡†æµ‹è¯•å¯¹ä½èµ„æºè¯­è¨€çš„è¦†ç›–ä¸è¶³ã€‚</li>
<li>LinguaLIFTæ˜¯ä¸€ä¸ªä¸¤é˜¶æ®µçš„æŒ‡ä»¤è°ƒæ•´æ¡†æ¶ï¼Œæ—¨åœ¨æå‡ä½èµ„æºè¯­è¨€çš„æ¨ç†èƒ½åŠ›ï¼Œé‡‡ç”¨è¯­è¨€å¯¹é½å±‚ä»¥ä»£ç åˆ‡æ¢æ–¹å¼æ•æ‰å¤šè¯­è¨€å¯¹é½ã€‚</li>
<li>LinguaLIFTæ— éœ€å¤šè¯­è¨€æŒ‡ä»¤æˆ–å¹³è¡Œæ•°æ®ï¼Œé€šè¿‡è‹±è¯­æŒ‡ä»¤è°ƒæ•´æ•°æ®è½¬ç§»è·¨è¯­è¨€æ¨ç†èƒ½åŠ›åˆ°ä½èµ„æºè¯­è¨€ã€‚</li>
<li>MMWPåŸºå‡†æµ‹è¯•ç”¨äºå…¨é¢è¯„ä¼°å¤šè¯­è¨€æ¨ç†èƒ½åŠ›ï¼Œæ¶µç›–å¤šç§ä¸åŒèµ„æºçš„è¯­è¨€ã€‚</li>
<li>å®éªŒè¡¨æ˜ï¼ŒLinguaLIFTåœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­æ€§èƒ½ä¼˜è¶Šã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.12499">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-f8feef172a6c8f5c1600a192e3e87023.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-69fd76cc1314fbd48ea80fa111caee50.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-53251d00ec390c9cd2e158ad6fc19c43.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-aa9f0814077b26adea978ded1f0a4aea.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-e56073a1ca89c1cafb838e804e04b8a9.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="MaLei-at-the-PLABA-Track-of-TREC-2024-RoBERTa-for-Term-Replacement-â€“-LLaMA3-1-and-GPT-4o-for-Complete-Abstract-Adaptation"><a href="#MaLei-at-the-PLABA-Track-of-TREC-2024-RoBERTa-for-Term-Replacement-â€“-LLaMA3-1-and-GPT-4o-for-Complete-Abstract-Adaptation" class="headerlink" title="MaLei at the PLABA Track of TREC 2024: RoBERTa for Term Replacement â€“   LLaMA3.1 and GPT-4o for Complete Abstract Adaptation"></a>MaLei at the PLABA Track of TREC 2024: RoBERTa for Term Replacement â€“   LLaMA3.1 and GPT-4o for Complete Abstract Adaptation</h2><p><strong>Authors:Zhidong Ling, Zihao Li, Pablo Romero, Lifeng Han, Goran Nenadic</strong></p>
<p>This report is the system description of the MaLei team (Manchester and Leiden) for the shared task Plain Language Adaptation of Biomedical Abstracts (PLABA) 2024 (we had an earlier name BeeManc following last year), affiliated with TREC2024 (33rd Text REtrieval Conference <a target="_blank" rel="noopener" href="https://ir.nist.gov/evalbase/conf/trec-2024">https://ir.nist.gov/evalbase/conf/trec-2024</a>). This report contains two sections corresponding to the two sub-tasks in PLABA-2024. In task one (term replacement), we applied fine-tuned ReBERTa-Base models to identify and classify the difficult terms, jargon, and acronyms in the biomedical abstracts and reported the F1 score (Task 1A and 1B). In task two (complete abstract adaptation), we leveraged Llamma3.1-70B-Instruct and GPT-4o with the one-shot prompts to complete the abstract adaptation and reported the scores in BLEU, SARI, BERTScore, LENS, and SALSA. From the official Evaluation from PLABA-2024 on Task 1A and 1B, our much smaller fine-tuned RoBERTa-Base model ranked 3rd and 2nd respectively on the two sub-tasks, and the 1st on averaged F1 scores across the two tasks from 9 evaluated systems. Our LLaMA-3.1-70B-instructed model achieved the highest Completeness score for Task 2. We share our source codes, fine-tuned models, and related resources at <a target="_blank" rel="noopener" href="https://github.com/HECTA-UoM/PLABA2024">https://github.com/HECTA-UoM/PLABA2024</a> </p>
<blockquote>
<p>è¿™ä»½æŠ¥å‘Šæ˜¯MaLeiå›¢é˜Ÿï¼ˆæ›¼å½»æ–¯ç‰¹ä¸è±é¡¿ï¼‰å…³äº2024å¹´ç”Ÿç‰©åŒ»å­¦æ‘˜è¦çš„å¹³è¯­é€‚åº”ï¼ˆPLABAï¼‰å…±äº«ä»»åŠ¡çš„ä½“ç³»æè¿°ï¼ˆæˆ‘ä»¬å»å¹´ä½¿ç”¨äº†ä¸€ä¸ªè¾ƒæ—©çš„åå­—BeeMancï¼‰ï¼Œè¯¥ä»»åŠ¡ä¸TREC2024ï¼ˆç¬¬33æ¬¡æ–‡æœ¬æ£€ç´¢ä¼šè®®ï¼‰ç›¸å…³è”ã€‚æœ¬æŠ¥å‘ŠåŒ…å«ä¸¤ä¸ªéƒ¨åˆ†ï¼Œåˆ†åˆ«å¯¹åº”PLABA-2024çš„ä¸¤ä¸ªå­ä»»åŠ¡ã€‚åœ¨ä»»åŠ¡ä¸€ï¼ˆæœ¯è¯­æ›¿æ¢ï¼‰ä¸­ï¼Œæˆ‘ä»¬åº”ç”¨äº†ç»è¿‡å¾®è°ƒè¿‡çš„ReBERTa-Baseæ¨¡å‹æ¥è¯†åˆ«å’Œåˆ†ç±»ç”Ÿç‰©åŒ»å­¦æ‘˜è¦ä¸­çš„éš¾è¯ã€æœ¯è¯­å’Œç¼©å†™è¯ï¼Œå¹¶æŠ¥å‘Šäº†F1åˆ†æ•°ï¼ˆä»»åŠ¡1Aå’Œ1Bï¼‰ã€‚åœ¨ä»»åŠ¡äºŒï¼ˆå®Œæ•´æ‘˜è¦é€‚åº”ï¼‰ä¸­ï¼Œæˆ‘ä»¬åˆ©ç”¨Llamma3.1-70B-Instructå’ŒGPT-4oçš„ä¸€æ¬¡æ€§æç¤ºæ¥å®Œæˆæ‘˜è¦çš„é€‚åº”ï¼Œå¹¶åœ¨BLEUã€SARIã€BERTScoreã€LENSå’ŒSALSAä¸­æŠ¥å‘Šäº†å¾—åˆ†ã€‚æ ¹æ®PLABA-2024çš„å®˜æ–¹è¯„ä¼°ç»“æœï¼Œæˆ‘ä»¬çš„è¾ƒå°çš„å¾®è°ƒRoBERTa-Baseæ¨¡å‹åœ¨ä¸¤ä¸ªå­ä»»åŠ¡ä¸­åˆ†åˆ«æ’åç¬¬3å’Œç¬¬2ï¼Œè€Œåœ¨ä¸¤ä¸ªä»»åŠ¡çš„å¹³å‡F1åˆ†æ•°ä¸Šæ’åç¬¬1ï¼ˆå…±è¯„ä»·äº†9ä¸ªç³»ç»Ÿï¼‰ã€‚æˆ‘ä»¬çš„LLaMA-3.1-70B-Instructæ¨¡å‹åœ¨ä»»åŠ¡2ä¸­è·å¾—äº†æœ€é«˜çš„å®Œæ•´æ€§å¾—åˆ†ã€‚æˆ‘ä»¬åœ¨<a target="_blank" rel="noopener" href="https://github.com/HECTA-UoM/PLABA2024">https://github.com/HECTA-UoM/PLABA2024</a>åˆ†äº«äº†æˆ‘ä»¬çš„æºä»£ç ã€å¾®è°ƒæ¨¡å‹å’Œç›¸å…³èµ„æºã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2411.07381v4">PDF</a> ongoing work - system report for PLABA2024 with TREC-2024</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†MaLeiå›¢é˜Ÿåœ¨PLABA 2024ä»»åŠ¡ä¸­çš„ç³»ç»Ÿæè¿°ï¼Œè¯¥ä»»åŠ¡åŒ…æ‹¬ä¸¤ä¸ªå­ä»»åŠ¡ï¼šæœ¯è¯­æ›¿æ¢å’Œå®Œæ•´æ‘˜è¦æ”¹ç¼–ã€‚å›¢é˜Ÿä½¿ç”¨äº†fine-tuned ReBERTa-Baseæ¨¡å‹å’ŒLlamma3.1-70B-Instructä¸GPT-4oç­‰å·¥å…·è¿›è¡Œä»»åŠ¡å¤„ç†ï¼Œå¹¶åœ¨ä¸¤ä¸ªå­ä»»åŠ¡ä¸­å–å¾—äº†ä¼˜å¼‚çš„æˆç»©ã€‚å›¢é˜Ÿè¿˜åˆ†äº«äº†æºä»£ç ã€fine-tunedæ¨¡å‹å’Œæœ‰å…³èµ„æºã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>MaLeiå›¢é˜Ÿå‚ä¸äº†PLABA 2024ä»»åŠ¡ï¼Œè¯¥ä»»åŠ¡æ—¨åœ¨å®ç°ç”Ÿç‰©åŒ»å­¦æ‘˜è¦çš„é€šä¿—åŒ–æ”¹ç¼–ã€‚</li>
<li>ä»»åŠ¡åˆ†ä¸ºä¸¤ä¸ªå­ä»»åŠ¡ï¼šæœ¯è¯­æ›¿æ¢å’Œå®Œæ•´æ‘˜è¦æ”¹ç¼–ã€‚</li>
<li>å›¢é˜Ÿä½¿ç”¨äº†fine-tuned ReBERTa-Baseæ¨¡å‹æ¥è¯†åˆ«å’Œåˆ†ç±»ç”Ÿç‰©åŒ»å­¦æ‘˜è¦ä¸­çš„å›°éš¾æœ¯è¯­ã€è¡Œè¯å’Œç¼©å†™ã€‚</li>
<li>åœ¨ä»»åŠ¡äºŒä¸­ä½¿ç”¨Llamma3.1-70B-Instructå’ŒGPT-4oç­‰å·¥å…·è¿›è¡Œå®Œæ•´æ‘˜è¦æ”¹ç¼–ã€‚</li>
<li>MaLeiå›¢é˜Ÿåœ¨ä¸¤ä¸ªå­ä»»åŠ¡ä¸­å‡å–å¾—äº†ä¼˜å¼‚çš„æˆç»©ï¼Œå¹³å‡F1å¾—åˆ†åœ¨æ‰€æœ‰è¯„ä»·çš„ç³»ç»Ÿä¸­æ’åç¬¬äºŒå’Œç¬¬ä¸‰ï¼Œä¸”åœ¨ä»»åŠ¡äºŒçš„å®Œæ•´æ€§å¾—åˆ†ä¸Šæ’åç¬¬ä¸€ã€‚</li>
<li>MaLeiå›¢é˜Ÿåˆ†äº«äº†æºä»£ç ã€fine-tunedæ¨¡å‹å’Œæœ‰å…³èµ„æºã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2411.07381">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-4cfa7d27f1eac6f4701ade77ba2b468f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-3f31701651d208c73cbaf232881b42c0.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-9ae377ab16483abdb04881154e5da346.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d6b0d06097d79a72c4260b77379adcdb.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b425be18f56947587819315e665ed486.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-82d5c175d739c60b42b44a8d58d3929f.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="A-distributional-simplicity-bias-in-the-learning-dynamics-of-transformers"><a href="#A-distributional-simplicity-bias-in-the-learning-dynamics-of-transformers" class="headerlink" title="A distributional simplicity bias in the learning dynamics of   transformers"></a>A distributional simplicity bias in the learning dynamics of   transformers</h2><p><strong>Authors:Riccardo Rende, Federica Gerace, Alessandro Laio, Sebastian Goldt</strong></p>
<p>The remarkable capability of over-parameterised neural networks to generalise effectively has been explained by invoking a &#96;&#96;simplicity biasâ€™â€™: neural networks prevent overfitting by initially learning simple classifiers before progressing to more complex, non-linear functions. While simplicity biases have been described theoretically and experimentally in feed-forward networks for supervised learning, the extent to which they also explain the remarkable success of transformers trained with self-supervised techniques remains unclear. In our study, we demonstrate that transformers, trained on natural language data, also display a simplicity bias. Specifically, they sequentially learn many-body interactions among input tokens, reaching a saturation point in the prediction error for low-degree interactions while continuing to learn high-degree interactions. To conduct this analysis, we develop a procedure to generate \textit{clones} of a given natural language data set, which rigorously capture the interactions between tokens up to a specified order. This approach opens up the possibilities of studying how interactions of different orders in the data affect learning, in natural language processing and beyond. </p>
<blockquote>
<p>ç¥ç»ç½‘ç»œåœ¨è¿‡åº¦å‚æ•°åŒ–åä»èƒ½æœ‰æ•ˆæ³›åŒ–çš„æ˜¾è‘—èƒ½åŠ›ï¼Œå¯ä»¥é€šè¿‡å¼•å…¥â€œç®€æ´æ€§åè§â€æ¥è§£é‡Šï¼šç¥ç»ç½‘ç»œé€šè¿‡é¦–å…ˆå­¦ä¹ ç®€å•çš„åˆ†ç±»å™¨ï¼Œç„¶åé€æ¸è½¬å‘æ›´å¤æ‚ã€éçº¿æ€§çš„å‡½æ•°ï¼Œä»è€Œé˜²æ­¢è¿‡åº¦æ‹Ÿåˆã€‚è™½ç„¶ç®€æ´åè§åœ¨ç†è®ºä¸Šå’Œå®éªŒä¸Šå·²åœ¨ç”¨äºç›‘ç£å­¦ä¹ çš„å‰é¦ˆç½‘ç»œä¸­å¾—åˆ°äº†æè¿°ï¼Œä½†å®ƒä»¬æ˜¯å¦ä¹Ÿèƒ½è§£é‡Šä½¿ç”¨è‡ªç›‘ç£æŠ€æœ¯è®­ç»ƒçš„å˜å‹å™¨çš„æ˜¾è‘—æˆåŠŸç¨‹åº¦ä»ç„¶ä¸æ¸…æ¥šã€‚åœ¨æˆ‘ä»¬çš„ç ”ç©¶ä¸­ï¼Œæˆ‘ä»¬è¯æ˜äº†åœ¨è‡ªç„¶è¯­è¨€æ•°æ®ä¸Šè®­ç»ƒçš„å˜å‹å™¨ä¹Ÿè¡¨ç°å‡ºç®€æ´åè§ã€‚å…·ä½“æ¥è¯´ï¼Œå®ƒä»¬ä¼šæŒ‰é¡ºåºå­¦ä¹ è¾“å…¥æ ‡è®°ä¹‹é—´çš„å¤šä½“äº¤äº’ä½œç”¨ï¼Œåœ¨é¢„æµ‹ä½é˜¶äº¤äº’çš„é”™è¯¯æ—¶è¾¾åˆ°é¥±å’Œç‚¹ï¼ŒåŒæ—¶ç»§ç»­å­¦ä¹ é«˜é˜¶äº¤äº’ã€‚ä¸ºäº†è¿›è¡Œè¿™ç§åˆ†æï¼Œæˆ‘ä»¬å¼€å‘äº†ä¸€ç§ç¨‹åºæ¥ç”Ÿæˆç»™å®šè‡ªç„¶è¯­è¨€æ•°æ®é›†çš„å‰¯æœ¬ï¼Œè¿™äº›å‰¯æœ¬ä¸¥æ ¼æ•è·æ ‡è®°ä¹‹é—´çš„äº¤äº’ä½œç”¨åˆ°æŒ‡å®šçš„é¡ºåºã€‚è¿™ç§æ–¹æ³•å¼€è¾Ÿäº†ç ”ç©¶ä¸åŒé¡ºåºçš„äº¤äº’å¦‚ä½•å½±å“è‡ªç„¶è¯­è¨€å¤„ç†å’Œå…¶ä»–é¢†åŸŸå­¦ä¹ çš„å¯èƒ½æ€§ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2410.19637v2">PDF</a> 10 pages, 5 figures, NeurIPS 2024</p>
<p><strong>Summary</strong></p>
<p>ç¥ç»ç½‘ç»œé€šè¿‡å¼•å…¥â€œç®€æ´æ€§åè§â€æ¥è§£é‡Šå…¶æœ‰æ•ˆçš„æ³›åŒ–èƒ½åŠ›ï¼šç¥ç»ç½‘ç»œé€šè¿‡é¦–å…ˆå­¦ä¹ ç®€å•çš„åˆ†ç±»å™¨æ¥é˜²æ­¢è¿‡æ‹Ÿåˆï¼Œç„¶åå†é€æ­¥å­¦ä¹ æ›´å¤æ‚çš„éçº¿æ€§å‡½æ•°ã€‚æœ¬ç ”ç©¶è¯æ˜ï¼Œä½¿ç”¨è‡ªç„¶è¯­è¨€æ•°æ®è®­ç»ƒçš„å˜å‹å™¨ä¹Ÿè¡¨ç°å‡ºç®€æ´æ€§åè§ã€‚ç‰¹åˆ«æ˜¯ï¼Œä»–ä»¬æŒ‰é¡ºåºå­¦ä¹ è¾“å…¥æ ‡è®°ä¹‹é—´çš„å¤šä½“äº¤äº’ä½œç”¨ï¼Œåœ¨é¢„æµ‹ä½é˜¶äº¤äº’çš„é”™è¯¯æ—¶è¾¾åˆ°é¥±å’Œç‚¹ï¼ŒåŒæ—¶ç»§ç»­å­¦ä¹ é«˜é˜¶äº¤äº’ã€‚ä¸ºæ­¤åˆ†æï¼Œæˆ‘ä»¬å¼€å‘äº†ä¸€ç§ç”Ÿæˆç»™å®šè‡ªç„¶è¯­è¨€æ•°æ®é›†çš„â€œå…‹éš†â€çš„ç¨‹åºï¼Œè¯¥ç¨‹åºä¸¥æ ¼æ•è·äº†æ ‡è®°ä¹‹é—´çš„äº¤äº’ä½œç”¨ç›´åˆ°æŒ‡å®šçš„é¡ºåºã€‚è¿™ä¸ºç ”ç©¶ä¸åŒé¡ºåºçš„äº¤äº’ä½œç”¨å¦‚ä½•å½±å“è‡ªç„¶è¯­è¨€å¤„ç†ç­‰é¢†åŸŸçš„å­¦ä¹ æä¾›äº†å¯èƒ½æ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ç¥ç»ç½‘ç»œé€šè¿‡å¼•å…¥â€œç®€æ´æ€§åè§â€æ¥è§£é‡Šå…¶æ³›åŒ–èƒ½åŠ›ï¼Œå³é€šè¿‡å­¦ä¹ ç®€å•çš„åˆ†ç±»å™¨æ¥é˜²æ­¢è¿‡æ‹Ÿåˆã€‚</li>
<li>å˜å‹å™¨æ¨¡å‹åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ä¹Ÿæ˜¾ç¤ºå‡ºç®€æ´æ€§åè§ï¼Œå³å…ˆå­¦ä¹ ä½é˜¶äº¤äº’ï¼Œå†é€æ¸å­¦ä¹ é«˜é˜¶äº¤äº’ã€‚</li>
<li>æœ¬ç ”ç©¶å¼€å‘äº†ä¸€ç§ç”Ÿæˆè‡ªç„¶è¯­è¨€æ•°æ®é›†å…‹éš†çš„ç¨‹åºï¼Œç”¨äºæ•è·æ ‡è®°ä¹‹é—´çš„äº¤äº’ä½œç”¨ã€‚</li>
<li>è¯¥ç¨‹åºå¯ä»¥ä¸¥æ ¼åœ°ç ”ç©¶ä¸åŒé˜¶æ•°çš„äº¤äº’ä½œç”¨å¯¹æ•°æ®å­¦ä¹ çš„å½±å“ã€‚</li>
<li>æ­¤æ–¹æ³•å¯¹äºç ”ç©¶è‡ªç„¶è¯­è¨€å¤„ç†é¢†åŸŸçš„å­¦ä¹ å…·æœ‰åº”ç”¨ä»·å€¼ã€‚</li>
<li>å˜å‹å™¨æ¨¡å‹åœ¨è‡ªæˆ‘ç›‘ç£æŠ€æœ¯è®­ç»ƒä¸‹çš„æˆåŠŸéƒ¨åˆ†å½’å› äºç®€æ´æ€§åè§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2410.19637">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-743613dcf83e41e74b6b4b107ff2853c.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-81bc88c2433b905990886048b2d2a0f2.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-f365ca2ce72c3037ee52c0cfa1dd2f95.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="Text2Chart31-Instruction-Tuning-for-Chart-Generation-with-Automatic-Feedback"><a href="#Text2Chart31-Instruction-Tuning-for-Chart-Generation-with-Automatic-Feedback" class="headerlink" title="Text2Chart31: Instruction Tuning for Chart Generation with Automatic   Feedback"></a>Text2Chart31: Instruction Tuning for Chart Generation with Automatic   Feedback</h2><p><strong>Authors:Fatemeh Pesaran Zadeh, Juyeon Kim, Jin-Hwa Kim, Gunhee Kim</strong></p>
<p>Large language models (LLMs) have demonstrated strong capabilities across various language tasks, notably through instruction-tuning methods. However, LLMs face challenges in visualizing complex, real-world data through charts and plots. Firstly, existing datasets rarely cover a full range of chart types, such as 3D, volumetric, and gridded charts. Secondly, supervised fine-tuning methods do not fully leverage the intricate relationships within rich datasets, including text, code, and figures. To address these challenges, we propose a hierarchical pipeline and a new dataset for chart generation. Our dataset, Text2Chart31, includes 31 unique plot types referring to the Matplotlib library, with 11.1K tuples of descriptions, code, data tables, and plots. Moreover, we introduce a reinforcement learning-based instruction tuning technique for chart generation tasks without requiring human feedback. Our experiments show that this approach significantly enhances the model performance, enabling smaller models to outperform larger open-source models and be comparable to state-of-the-art proprietary models in data visualization tasks. We make the code and dataset available at <a target="_blank" rel="noopener" href="https://github.com/fatemehpesaran310/Text2Chart31">https://github.com/fatemehpesaran310/Text2Chart31</a>. </p>
<blockquote>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨å„ç§è¯­è¨€ä»»åŠ¡ä¸­è¡¨ç°å‡ºäº†å¼ºå¤§çš„èƒ½åŠ›ï¼Œå°¤å…¶æ˜¯æŒ‡ä»¤è°ƒæ•´æ–¹æ³•ã€‚ç„¶è€Œï¼ŒLLMåœ¨é€šè¿‡å›¾è¡¨å¯è§†åŒ–å¤æ‚ã€ç°å®ä¸–ç•Œæ•°æ®æ–¹é¢é¢ä¸´æŒ‘æˆ˜ã€‚é¦–å…ˆï¼Œç°æœ‰æ•°æ®é›†å¾ˆå°‘æ¶µç›–å…¨æ–¹ä½çš„å›¾è¡¨ç±»å‹ï¼Œå¦‚3Dã€ä½“ç§¯å’Œç½‘æ ¼å›¾è¡¨ã€‚å…¶æ¬¡ï¼Œç›‘ç£å¾®è°ƒæ–¹æ³•å¹¶æ²¡æœ‰å……åˆ†åˆ©ç”¨ä¸°å¯Œæ•°æ®é›†ä¸­çš„å¤æ‚å…³ç³»ï¼ŒåŒ…æ‹¬æ–‡æœ¬ã€ä»£ç å’Œå›¾è¡¨ã€‚ä¸ºäº†è§£å†³è¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªåˆ†å±‚çš„ç®¡é“å’Œä¸€ä¸ªæ–°çš„æ•°æ®é›†æ¥è¿›è¡Œå›¾è¡¨ç”Ÿæˆã€‚æˆ‘ä»¬çš„æ•°æ®é›†Text2Chart31åŒ…æ‹¬Matplotlibåº“ä¸­å¼•ç”¨çš„31ç§ç‹¬ç‰¹å›¾è¡¨ç±»å‹ï¼ŒåŒ…å«11.1Kä¸ªæè¿°ã€ä»£ç ã€æ•°æ®è¡¨å’Œå›¾è¡¨çš„å…ƒç»„ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§åŸºäºå¼ºåŒ–å­¦ä¹ çš„æŒ‡ä»¤è°ƒæ•´æŠ€æœ¯ï¼Œç”¨äºå›¾è¡¨ç”Ÿæˆä»»åŠ¡ï¼Œæ— éœ€äººå·¥åé¦ˆã€‚æˆ‘ä»¬çš„å®éªŒè¡¨æ˜ï¼Œè¿™ç§æ–¹æ³•æ˜¾è‘—æé«˜äº†æ¨¡å‹æ€§èƒ½ï¼Œä½¿å°å‹æ¨¡å‹åœ¨æ•°æ®å¯è§†åŒ–ä»»åŠ¡ä¸­è¶…è¶Šå¤§å‹å¼€æºæ¨¡å‹ï¼Œå¹¶ä¸æœ€å…ˆè¿›çš„ä¸“æœ‰æ¨¡å‹ç›¸å½“ã€‚æˆ‘ä»¬åœ¨<a target="_blank" rel="noopener" href="https://github.com/fatemehpesaran310/Text2Chart31">https://github.com/fatemehpesaran310/Text2Chart31</a>æä¾›äº†ä»£ç å’Œæ•°æ®é›†ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2410.04064v2">PDF</a> EMNLP 2024 Main Oral. Code and dataset are released at   <a target="_blank" rel="noopener" href="https://github.com/fatemehpesaran310/Text2Chart31">https://github.com/fatemehpesaran310/Text2Chart31</a></p>
<p><strong>Summary</strong><br>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨å„ç±»è¯­è¨€ä»»åŠ¡ä¸­å±•ç°å‡ºå¼ºå¤§çš„èƒ½åŠ›ï¼Œå°¤å…¶åœ¨æŒ‡ä»¤å¾®è°ƒæ–¹æ³•æ–¹é¢å°¤ä¸ºçªå‡ºã€‚ç„¶è€Œï¼ŒLLMåœ¨å¯è§†åŒ–å¤æ‚ã€ç°å®ä¸–ç•Œæ•°æ®æ–¹é¢å­˜åœ¨æŒ‘æˆ˜ï¼Œå¦‚å¤„ç†3Dã€ä½“ç§¯å’Œç½‘æ ¼å›¾è¡¨ç­‰ç±»å‹çš„æ•°æ®ã€‚ä¸ºè§£å†³è¿™äº›é—®é¢˜ï¼Œæœ¬ç ”ç©¶æå‡ºäº†ä¸€ç§å±‚æ¬¡åŒ–ç®¡é“å’Œæ–°çš„æ•°æ®é›†Text2Chart31ï¼Œç”¨äºå›¾è¡¨ç”Ÿæˆã€‚è¯¥æ•°æ®é›†åŒ…å«Matplotlibåº“ä¸­æ¶‰åŠçš„31ç§ç‹¬ç‰¹å›¾è¡¨ç±»å‹ï¼Œå…±è®¡11.1Kä¸ªæè¿°ã€ä»£ç ã€æ•°æ®è¡¨å’Œå›¾è¡¨çš„ç»„åˆã€‚æ­¤å¤–ï¼Œç ”ç©¶å¼•å…¥äº†åŸºäºå¼ºåŒ–å­¦ä¹ çš„æŒ‡ä»¤å¾®è°ƒæŠ€æœ¯ï¼Œç”¨äºå›¾è¡¨ç”Ÿæˆä»»åŠ¡ï¼Œæ— éœ€äººå·¥åé¦ˆã€‚å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•æ˜¾è‘—æé«˜äº†æ¨¡å‹æ€§èƒ½ï¼Œä½¿å¾—å°å‹æ¨¡å‹åœ¨æ•°æ®å¯è§†åŒ–ä»»åŠ¡ä¸Šçš„è¡¨ç°ä¼˜äºå¤§å‹å¼€æºæ¨¡å‹ï¼Œå¹¶ä¸ä¸šç•Œé¡¶å°–æ¨¡å‹ç›¸åª²ç¾ã€‚æˆ‘ä»¬å·²å°†ä»£ç å’Œæ•°æ®é›†å‘å¸ƒåœ¨<a target="_blank" rel="noopener" href="https://github.com/fatemehpesaran310/Text2Chart31%E3%80%82">https://github.com/fatemehpesaran310/Text2Chart31ã€‚</a></p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨å¤šç§è¯­è¨€ä»»åŠ¡ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œå°¤å…¶æ“…é•¿æŒ‡ä»¤å¾®è°ƒæ–¹æ³•ã€‚</li>
<li>LLMåœ¨å¯è§†åŒ–å¤æ‚ã€ç°å®ä¸–ç•Œæ•°æ®æ–¹é¢é¢ä¸´æŒ‘æˆ˜ï¼Œå¦‚å¤„ç†å¤šç§å›¾è¡¨ç±»å‹ã€‚</li>
<li>ç°æœ‰æ•°æ®é›†å¾ˆå°‘è¦†ç›–å…¨é¢çš„å›¾è¡¨ç±»å‹ï¼Œå¦‚3Dã€ä½“ç§¯å’Œç½‘æ ¼å›¾è¡¨ã€‚</li>
<li>æå‡ºäº†ä¸€ä¸ªæ–°çš„æ•°æ®é›†Text2Chart31ï¼ŒåŒ…å«å¤šç§å›¾è¡¨ç±»å‹ï¼Œä»¥æ”¯æŒæ›´å¹¿æ³›çš„å›¾è¡¨ç”Ÿæˆä»»åŠ¡ã€‚</li>
<li>å¼•å…¥äº†ä¸€ç§åŸºäºå¼ºåŒ–å­¦ä¹ çš„æŒ‡ä»¤å¾®è°ƒæŠ€æœ¯ï¼Œç”¨äºå›¾è¡¨ç”Ÿæˆä»»åŠ¡ï¼Œæé«˜äº†æ¨¡å‹æ€§èƒ½ã€‚</li>
<li>è¯¥æ–¹æ³•ä½¿å¾—å°å‹æ¨¡å‹åœ¨æ•°æ®å¯è§†åŒ–ä»»åŠ¡ä¸Šçš„è¡¨ç°ä¼˜äºæŸäº›å¤§å‹å¼€æºæ¨¡å‹ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2410.04064">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-8b0e8b940e4acae3b35aa321ed6bc9f3.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-b867d81b662c28ad1cf9e991d9417d4f.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-365043a9318f6d3fb281efaa8e096d69.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-10c8f001250a2878477634aeef4d9c55.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="Robin3D-Improving-3D-Large-Language-Model-via-Robust-Instruction-Tuning"><a href="#Robin3D-Improving-3D-Large-Language-Model-via-Robust-Instruction-Tuning" class="headerlink" title="Robin3D: Improving 3D Large Language Model via Robust Instruction Tuning"></a>Robin3D: Improving 3D Large Language Model via Robust Instruction Tuning</h2><p><strong>Authors:Weitai Kang, Haifeng Huang, Yuzhang Shang, Mubarak Shah, Yan Yan</strong></p>
<p>Recent advancements in 3D Large Language Models (3DLLMs) have highlighted their potential in building general-purpose agents in the 3D real world, yet challenges remain due to the lack of high-quality robust instruction-following data, leading to limited discriminative power and generalization of 3DLLMs. In this paper, we introduce Robin3D, a powerful 3DLLM trained on large-scale instruction-following data generated by our novel data engine, Robust Instruction Generation (RIG) engine. RIG generates two key instruction data: 1) the Adversarial Instruction-following data, which features mixed negative and positive samples to enhance the modelâ€™s discriminative understanding. 2) the Diverse Instruction-following data, which contains various instruction styles to enhance modelâ€™s generalization. As a result, we construct 1 million instruction-following data, consisting of 344K Adversarial samples, 508K Diverse samples, and 165K benchmark training set samples. To better handle these complex instructions, Robin3D first incorporates Relation-Augmented Projector to enhance spatial understanding, and then strengthens the object referring and grounding ability through ID-Feature Bonding. Robin3D consistently outperforms previous methods across five widely-used 3D multimodal learning benchmarks, without the need for task-specific fine-tuning. Notably, we achieve a 7.8% improvement in the grounding task (Multi3DRefer) and a 6.9% improvement in the captioning task (Scan2Cap). </p>
<blockquote>
<p>è¿‘å¹´æ¥ï¼Œ3Då¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆ3DLLMï¼‰çš„è¿›æ­¥å‡¸æ˜¾äº†å…¶åœ¨æ„å»º3Dç°å®ä¸–ç•Œé€šç”¨ä»£ç†çš„æ½œåŠ›ï¼Œä½†ç”±äºç¼ºä¹é«˜è´¨é‡ã€ç¨³å¥çš„æŒ‡ä»¤éµå¾ªæ•°æ®ï¼Œä»å­˜åœ¨æŒ‘æˆ˜ï¼Œå¯¼è‡´3DLLMçš„è¾¨åˆ«åŠ›å’Œæ³›åŒ–èƒ½åŠ›æœ‰é™ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬ä»‹ç»äº†Robin3Dï¼Œè¿™æ˜¯ä¸€ç§ç”±æˆ‘ä»¬çš„æ–°å‹æ•°æ®å¼•æ“â€”â€”Robust Instruction Generationï¼ˆRIGï¼‰å¼•æ“ç”Ÿæˆçš„å¤§è§„æ¨¡æŒ‡ä»¤éµå¾ªæ•°æ®è®­ç»ƒå‡ºæ¥çš„å¼ºå¤§3DLLMã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2410.00255v2">PDF</a> 8 pages</p>
<p><strong>æ‘˜è¦</strong></p>
<p>æœ€è¿‘3Då¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆ3DLLMï¼‰çš„è¿›å±•çªæ˜¾äº†å…¶åœ¨æ„å»ºç°å®ä¸–ç•Œä¸­é€šç”¨ä»£ç†çš„æ½œåŠ›ï¼Œä½†ä»é¢ä¸´ç¼ºä¹é«˜è´¨é‡ç¨³å¥æŒ‡ä»¤è·Ÿè¸ªæ•°æ®çš„æŒ‘æˆ˜ï¼Œé™åˆ¶äº†å…¶é‰´åˆ«åŠ›å’Œæ³›åŒ–èƒ½åŠ›ã€‚æœ¬æ–‡ä»‹ç»äº†Robin3Dï¼Œè¿™æ˜¯ä¸€ç§å¼ºå¤§çš„ç”±æˆ‘ä»¬æ–°å‹æ•°æ®å¼•æ“Robust Instruction Generationï¼ˆRIGï¼‰ç”Ÿæˆå¤§è§„æ¨¡æŒ‡ä»¤è·Ÿè¸ªæ•°æ®è®­ç»ƒçš„3DLLMã€‚RIGç”Ÿæˆä¸¤ç§å…³é”®æŒ‡ä»¤æ•°æ®ï¼šå¯¹æŠ—æ€§æŒ‡ä»¤è·Ÿè¸ªæ•°æ®å’Œå¤šæ ·æ€§æŒ‡ä»¤è·Ÿè¸ªæ•°æ®ï¼Œåˆ†åˆ«ç”¨äºå¢å¼ºæ¨¡å‹çš„é‰´åˆ«ç†è§£å’Œæé«˜æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚å› æ­¤ï¼Œæˆ‘ä»¬æ„å»ºäº†åŒ…å«å¯¹æŠ—æ€§æ ·æœ¬ã€å¤šæ ·æ€§æ ·æœ¬å’ŒåŸºå‡†è®­ç»ƒé›†æ ·æœ¬çš„å„ä¸€ç™¾ä¸‡æ¡æŒ‡ä»¤è·Ÿè¸ªæ•°æ®ã€‚Robin3Dé‡‡ç”¨Relation-Augmented Projectorä»¥å¢å¼ºç©ºé—´ç†è§£åŠ›ï¼Œé€šè¿‡ID-Feature Bondingå¼ºåŒ–å¯¹è±¡æŒ‡ä»£å’Œå®šä½èƒ½åŠ›ã€‚åœ¨äº”ä¸ªå¹¿æ³›ä½¿ç”¨çš„3Då¤šåª’ä½“å­¦ä¹ åŸºå‡†æµ‹è¯•ä¸­ï¼ŒRobin3Då‡è¡¨ç°ä¼˜äºå…ˆå‰çš„æ–¹æ³•ï¼Œæ— éœ€ç‰¹å®šä»»åŠ¡çš„å¾®è°ƒã€‚ç‰¹åˆ«æ˜¯åœ¨å®šä½ä»»åŠ¡ï¼ˆMulti3DReferï¼‰ä¸Šå®ç°äº†7.8%çš„æå‡å’Œæè¿°ä»»åŠ¡ï¼ˆScan2Capï¼‰ä¸Šå®ç°äº†6.9%çš„æå‡ã€‚</p>
<p><strong>å…³é”®è§è§£</strong></p>
<ol>
<li>Robin3Dæ¨¡å‹æ˜¯ç”±å¤§è§„æ¨¡æŒ‡ä»¤è·Ÿè¸ªæ•°æ®è®­ç»ƒçš„å¼ºå¤§æ¨¡å‹ï¼Œä½¿ç”¨äº†åˆ›æ–°çš„Robust Instruction Generationå¼•æ“æ¥åˆ›å»ºæ•°æ®é›†ã€‚è¯¥æ¨¡å‹å¯¹æ­£é¢å’Œè´Ÿé¢æ ·æœ¬è¿›è¡Œæ··åˆï¼Œå¢å¼ºäº†æ¨¡å‹çš„é‰´åˆ«èƒ½åŠ›ã€‚</li>
<li>Robin3Dé€šè¿‡åŒ…å«å¤šç§æŒ‡ä»¤é£æ ¼çš„æ•°æ®è®­ç»ƒï¼Œå¢å¼ºäº†æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚å¯¹æŠ—æ€§å’Œå¤šæ ·æ€§çš„æ•°æ®ç­–ç•¥æ˜¯æå‡å…¶æ€§èƒ½çš„å…³é”®å› ç´ ã€‚</li>
<li>Robin3DæˆåŠŸç»“åˆä½¿ç”¨Relation-Augmented Projectorå’ŒID-Feature BondingæŠ€æœ¯ï¼Œæé«˜äº†ç©ºé—´ç†è§£åŠ›å’Œå¯¹è±¡æŒ‡ä»£åŠå®šä½èƒ½åŠ›ã€‚è¿™ä½¿å¾—æ¨¡å‹åœ¨å„ç§å¤æ‚çš„æŒ‡ä»¤ç¯å¢ƒä¸‹è¡¨ç°å‡ºå“è¶Šçš„æ€§èƒ½ã€‚</li>
<li>Robin3Dåœ¨äº”ä¸ªå¹¿æ³›çš„3Då¤šåª’ä½“å­¦ä¹ åŸºå‡†æµ‹è¯•ä¸­è¡¨ç°ä¼˜äºå…¶ä»–æ–¹æ³•ï¼Œæ— éœ€ç‰¹å®šä»»åŠ¡çš„å¾®è°ƒã€‚è¿™è¡¨æ˜å…¶å…·æœ‰è‰¯å¥½çš„é€šç”¨æ€§å’Œé€‚åº”æ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2410.00255">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-c5758c1dfaa2d29d446604a4288bb88a.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-8f57c2e649e7e861f8caf88c51095ddc.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e32735a7e48225d3093d227d508879e1.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-31453f6295406b26f846b67904af69f8.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-80a9a8395bc05a6b5e62d1efdac9530b.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="Relation-Also-Knows-Rethinking-the-Recall-and-Editing-of-Factual-Associations-in-Auto-Regressive-Transformer-Language-Models"><a href="#Relation-Also-Knows-Rethinking-the-Recall-and-Editing-of-Factual-Associations-in-Auto-Regressive-Transformer-Language-Models" class="headerlink" title="Relation Also Knows: Rethinking the Recall and Editing of Factual   Associations in Auto-Regressive Transformer Language Models"></a>Relation Also Knows: Rethinking the Recall and Editing of Factual   Associations in Auto-Regressive Transformer Language Models</h2><p><strong>Authors:Xiyu Liu, Zhengxiao Liu, Naibin Gu, Zheng Lin, Wanli Ma, Ji Xiang, Weiping Wang</strong></p>
<p>The storage and recall of factual associations in auto-regressive transformer language models (LMs) have drawn a great deal of attention, inspiring knowledge editing by directly modifying the located model weights. Most editing works achieve knowledge editing under the guidance of existing interpretations of knowledge recall that mainly focus on subject knowledge. However, these interpretations are seriously flawed, neglecting relation information and leading to the over-generalizing problem for editing. In this work, we discover a novel relation-focused perspective to interpret the knowledge recall of transformer LMs during inference and apply it on single knowledge editing to avoid over-generalizing. Experimental results on the dataset supplemented with a new R-Specificity criterion demonstrate that our editing approach significantly alleviates over-generalizing while remaining competitive on other criteria, breaking the domination of subject-focused editing for future research. </p>
<blockquote>
<p>åœ¨è‡ªå›å½’transformerè¯­è¨€æ¨¡å‹ï¼ˆLMsï¼‰ä¸­ï¼Œäº‹å®å…³è”å­˜å‚¨å’Œå›å¿†å¼•èµ·äº†å¹¿æ³›å…³æ³¨ï¼Œæ¿€å‘äº†é€šè¿‡ç›´æ¥ä¿®æ”¹å®šä½æ¨¡å‹æƒé‡è¿›è¡ŒçŸ¥è¯†ç¼–è¾‘çš„çµæ„Ÿã€‚å¤§å¤šæ•°ç¼–è¾‘å·¥ä½œåœ¨çŸ¥è¯†å›å¿†çš„ç°æœ‰è§£é‡ŠæŒ‡å¯¼ä¸‹è¿›è¡ŒçŸ¥è¯†ç¼–è¾‘ï¼Œè¿™äº›è§£é‡Šä¸»è¦é›†ä¸­åœ¨ä¸»é¢˜çŸ¥è¯†ä¸Šã€‚ç„¶è€Œï¼Œè¿™äº›è§£é‡Šå­˜åœ¨ä¸¥é‡ç¼ºé™·ï¼Œå¿½ç•¥äº†å…³ç³»ä¿¡æ¯ï¼Œå¯¼è‡´ç¼–è¾‘è¿‡åº¦æ¦‚æ‹¬ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬å‘ç°äº†ä¸€ç§æ–°å‹çš„ä»¥å…³ç³»ä¸ºä¸­å¿ƒçš„è§’åº¦æ¥è§£é‡Šæ¨ç†è¿‡ç¨‹ä¸­transformer LMsçš„çŸ¥è¯†å›å¿†ï¼Œå¹¶å°†å…¶åº”ç”¨äºå•ä¸€çŸ¥è¯†ç¼–è¾‘ä¸­ä»¥é¿å…è¿‡åº¦æ¦‚æ‹¬ã€‚åœ¨æ–°å¢æ•°æ®é›†ä¸Šè¿›è¡Œçš„å®éªŒé‡‡ç”¨äº†æ–°çš„R-ç‰¹å¼‚æ€§æ ‡å‡†ä½œä¸ºè¯„ä»·æŒ‡æ ‡ï¼Œç»“æœè¡¨æ˜æˆ‘ä»¬çš„ç¼–è¾‘æ–¹æ³•æ˜¾è‘—å‡è½»äº†è¿‡åº¦æ¦‚æ‹¬çš„é—®é¢˜ï¼ŒåŒæ—¶åœ¨å…¶ä»–æ ‡å‡†ä¸Šä»å…·æœ‰ç«äº‰åŠ›ï¼Œæ‰“ç ´äº†æœªæ¥ç ”ç©¶ä¸­ä»¥ä¸»é¢˜ä¸ºä¸­å¿ƒçš„ç¼–è¾‘çš„ä¸»å¯¼åœ°ä½ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2408.15091v2">PDF</a> Accepted by AAAI25</p>
<p><strong>Summary</strong>ï¼š<br>åœ¨è‡ªå›å½’Transformerè¯­è¨€æ¨¡å‹ä¸­ï¼ŒçŸ¥è¯†å…³è”å­˜å‚¨å’Œå›å¿†çš„é—®é¢˜å·²å¼•èµ·å¹¿æ³›å…³æ³¨ï¼Œæ¿€å‘äº†é€šè¿‡ç›´æ¥ä¿®æ”¹æ¨¡å‹æƒé‡è¿›è¡ŒçŸ¥è¯†ç¼–è¾‘çš„æ–¹æ³•ã€‚ç„¶è€Œï¼Œç°æœ‰çŸ¥è¯†å›å¿†çš„è§£é‡Šä¸»è¦é›†ä¸­åœ¨ä¸»é¢˜çŸ¥è¯†ä¸Šï¼Œå¿½è§†äº†å…³ç³»ä¿¡æ¯ï¼Œå¯¼è‡´ç¼–è¾‘æ—¶å‡ºç°è¿‡åº¦æ³›åŒ–é—®é¢˜ã€‚æœ¬ç ”ç©¶ä»å…³ç³»è§†è§’å‡ºå‘ï¼Œè§£è¯»Transformeræ¨¡å‹åœ¨æ¨ç†è¿‡ç¨‹ä¸­çš„çŸ¥è¯†å›å¿†ï¼Œå¹¶å°†å…¶åº”ç”¨äºå•ä¸€çŸ¥è¯†ç¼–è¾‘ä¸­ä»¥é¿å…è¿‡åº¦æ³›åŒ–ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œæ–°çš„ç¼–è¾‘æ–¹æ³•æ˜¾è‘—å‡è½»äº†è¿‡åº¦æ³›åŒ–é—®é¢˜ï¼ŒåŒæ—¶åœ¨å…¶ä»–æ ‡å‡†ä¸Šä»å…·æœ‰ç«äº‰åŠ›ï¼Œæ‰“ç ´äº†ä¸»é¢˜å¯¼å‘ç¼–è¾‘çš„å±€é™ã€‚</p>
<p><strong>Key Takeaways</strong>ï¼š</p>
<ol>
<li>Transformerè¯­è¨€æ¨¡å‹ä¸­çš„çŸ¥è¯†å…³è”å­˜å‚¨å’Œå›å¿†å·²å—åˆ°å…³æ³¨ã€‚</li>
<li>ç›´æ¥ä¿®æ”¹æ¨¡å‹æƒé‡è¿›è¡ŒçŸ¥è¯†ç¼–è¾‘çš„æ–¹æ³•å·²è¢«æå‡ºã€‚</li>
<li>ç°æœ‰çŸ¥è¯†å›å¿†çš„è§£é‡Šä¸»è¦é›†ä¸­åœ¨ä¸»é¢˜çŸ¥è¯†ä¸Šï¼Œå¿½ç•¥äº†å…³ç³»ä¿¡æ¯ã€‚</li>
<li>å…³ç³»è§†è§’å¯¹ç†è§£Transformeræ¨¡å‹åœ¨æ¨ç†è¿‡ç¨‹ä¸­çš„çŸ¥è¯†å›å¿†è‡³å…³é‡è¦ã€‚</li>
<li>åŸºäºå…³ç³»è§†è§’çš„çŸ¥è¯†ç¼–è¾‘æ–¹æ³•æœ‰åŠ©äºé¿å…è¿‡åº¦æ³›åŒ–é—®é¢˜ã€‚</li>
<li>å®éªŒç»“æœè¡¨æ˜ï¼Œæ–°çš„ç¼–è¾‘æ–¹æ³•åœ¨ç¼“è§£è¿‡åº¦æ³›åŒ–é—®é¢˜ä¸Šæ•ˆæœæ˜¾è‘—ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2408.15091">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-12d926a2ce9fa543703a66c90bd4fd23.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-fee26da49c8313c3a8a21f5bd19957cc.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-e06b9499c65bd09299f422a231a90e5b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f7921d748106a0e5f66f5d9927ee0f1f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-66c99ab4449455656b7406c5c36e6740.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-37119858d85dc16b28481b9945634f7c.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="Triple-Preference-Optimization-Achieving-Better-Alignment-using-a-Single-Step-Optimization"><a href="#Triple-Preference-Optimization-Achieving-Better-Alignment-using-a-Single-Step-Optimization" class="headerlink" title="Triple Preference Optimization: Achieving Better Alignment using a   Single Step Optimization"></a>Triple Preference Optimization: Achieving Better Alignment using a   Single Step Optimization</h2><p><strong>Authors:Amir Saeidi, Shivanshu Verma, Aswin RRV, Kashif Rasul, Chitta Baral</strong></p>
<p>Reinforcement Learning with Human Feedback (RLHF) enhances the alignment of Large Language Models (LLMs). However, its limitations have led to the development of Direct Preference Optimization (DPO), an RL-free approach designed to overcome these shortcomings. While studies have shown that DPO improves instruction-following capabilities, it negatively impacts the reasoning ability of LLMs. Additionally, DPO is highly sensitive to judgment noise in preference datasets and the size of the training set. Although several modifications to DPO have been proposed, they still fail to fully resolve these issues. To address these limitations, we propose Triple Preference Optimization (TPO), a new preference learning method designed to enhance both reasoning and instruction-following abilities through one-step optimization. We compare TPO against DPO and its recent variants using state-of-the-art training setups, including both base and instruction-tuned models such as Mistral and Llama 3. Our evaluation covers a comprehensive range of chat-based and reasoning benchmarks. The results demonstrate that TPO achieves significant improvements over existing methods without substantially increasing response length across different dataset sizes. Specifically, TPO outperforms DPO and SimPO by up to 7.0% and 7.3% points on Arena-Hard, 12.2% and 13.3% points on MixEval-Hard, 10.4% and 10.1% points on MMLU-Pro, and 19.0% and 19.2% points on GSM8K, respectively. Furthermore, TPO achieves these improvements while requiring less data than DPO. </p>
<blockquote>
<p>å¼ºåŒ–å­¦ä¹ ç»“åˆäººç±»åé¦ˆï¼ˆRLHFï¼‰å¢å¼ºäº†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„ä¸€è‡´æ€§ã€‚ç„¶è€Œï¼Œå…¶å±€é™æ€§ä¿ƒä½¿äº†æ— å¼ºåŒ–å­¦ä¹ çš„ç›´æ¥åå¥½ä¼˜åŒ–ï¼ˆDPOï¼‰æ–¹æ³•çš„å‘å±•ï¼Œæ—¨åœ¨å…‹æœè¿™äº›ä¸è¶³ã€‚ç ”ç©¶è¡¨æ˜ï¼Œå°½ç®¡DPOæé«˜äº†æŒ‡ä»¤æ‰§è¡Œèƒ½åŠ›ï¼Œä½†å®ƒå¯¹LLMçš„æ¨ç†èƒ½åŠ›äº§ç”Ÿäº†è´Ÿé¢å½±å“ã€‚æ­¤å¤–ï¼ŒDPOå¯¹åå¥½æ•°æ®é›†ä¸­çš„åˆ¤æ–­å™ªå£°å’Œè®­ç»ƒé›†å¤§å°é«˜åº¦æ•æ„Ÿã€‚å°½ç®¡å·²ç»æå‡ºäº†å¯¹DPOçš„å‡ é¡¹ä¿®æ”¹ï¼Œä½†å®ƒä»¬ä»ç„¶æœªèƒ½å®Œå…¨è§£å†³è¿™äº›é—®é¢˜ã€‚ä¸ºäº†è§£å†³è¿™äº›å±€é™æ€§ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸‰é‡åå¥½ä¼˜åŒ–ï¼ˆTPOï¼‰è¿™ä¸€æ–°çš„åå¥½å­¦ä¹ æ–¹æ³•ï¼Œæ—¨åœ¨é€šè¿‡ä¸€æ­¥ä¼˜åŒ–æé«˜æ¨ç†å’ŒæŒ‡ä»¤æ‰§è¡Œèƒ½åŠ›ã€‚æˆ‘ä»¬å°†TPOä¸DPOåŠå…¶æœ€è¿‘å˜ç§è¿›è¡Œäº†æ¯”è¾ƒï¼Œä½¿ç”¨çš„æ˜¯æœ€å…ˆè¿›çš„è®­ç»ƒè®¾ç½®ï¼ŒåŒ…æ‹¬åŸºç¡€æ¨¡å‹å’ŒæŒ‡ä»¤è°ƒæ•´æ¨¡å‹ï¼Œå¦‚Mistralå’ŒLlama 3ã€‚æˆ‘ä»¬çš„è¯„ä¼°æ¶µç›–äº†åŸºäºèŠå¤©çš„ç»¼åˆèŒƒå›´å’Œæ¨ç†åŸºå‡†æµ‹è¯•ã€‚ç»“æœè¡¨æ˜ï¼ŒTPOåœ¨ä¸åŒçš„æ•°æ®é›†å¤§å°ä¸Šå®ç°äº†å¯¹ç°æœ‰æ–¹æ³•çš„æ˜¾è‘—æ”¹è¿›ï¼Œè€Œå“åº”é•¿åº¦æ²¡æœ‰å¤§å¹…å¢åŠ ã€‚å…·ä½“æ¥è¯´ï¼ŒTPOåœ¨Arena-Hardä¸Šè¶…è¶Šäº†DPOå’ŒSimPOé«˜è¾¾7.0%å’Œ7.3%ç‚¹ï¼Œåœ¨MixEval-Hardä¸Šåˆ†åˆ«æé«˜äº†12.2%å’Œ13.3%ç‚¹ï¼Œåœ¨MMLU-Proä¸Šåˆ†åˆ«æé«˜äº†10.4%å’Œ10.1%ç‚¹ï¼Œåœ¨GSM8Kä¸Šåˆ†åˆ«æé«˜äº†19.0%å’Œ19.2%ç‚¹ã€‚æ­¤å¤–ï¼ŒTPOåœ¨éœ€è¦çš„æ•°æ®é‡ä¸Šå°‘äºDPOå°±å®ç°äº†è¿™äº›æ”¹è¿›ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2405.16681v2">PDF</a> </p>
<p><strong>æ‘˜è¦</strong><br>å¼ºåŒ–å­¦ä¹ ç»“åˆäººç±»åé¦ˆï¼ˆRLHFï¼‰æé«˜äº†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„å¯¹é½ç¨‹åº¦ã€‚ä½†å…¶å±€é™æ€§ä¿ƒä½¿äº†æ— éœ€å¼ºåŒ–å­¦ä¹ çš„ç›´æ¥åå¥½ä¼˜åŒ–ï¼ˆDPOï¼‰æ–¹æ³•çš„å¼€å‘ã€‚å°½ç®¡DPOæ”¹å–„äº†æŒ‡ä»¤éµå¾ªèƒ½åŠ›ï¼Œä½†å®ƒå¯¹LLMçš„æ¨ç†èƒ½åŠ›äº§ç”Ÿè´Ÿé¢å½±å“ï¼Œå¹¶ä¸”å¯¹åå¥½æ•°æ®é›†é‡Œçš„åˆ¤æ–­å™ªå£°å’Œè®­ç»ƒé›†å¤§å°é«˜åº¦æ•æ„Ÿã€‚ä¸ºè§£å†³è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸‰é‡åå¥½ä¼˜åŒ–ï¼ˆTPOï¼‰è¿™ä¸€æ–°çš„åå¥½å­¦ä¹ æ–¹æ³•ï¼Œæ—¨åœ¨é€šè¿‡ä¸€æ­¥ä¼˜åŒ–å¢å¼ºæ¨ç†å’ŒæŒ‡ä»¤éµå¾ªèƒ½åŠ›ã€‚å¯¹æ¯”DPOåŠå…¶æœ€æ–°å˜ä½“ï¼ŒTPOåœ¨åŒ…æ‹¬Mistralå’ŒLlama 3ç­‰åŸºç¡€åŠæŒ‡ä»¤è°ƒä¼˜æ¨¡å‹åœ¨å†…çš„æœ€å…ˆè¿›çš„è®­ç»ƒè®¾ç½®ä¸­è¡¨ç°ä¼˜å¼‚ã€‚è¯„ä¼°æ¶µç›–å¹¿æ³›çš„èŠå¤©å’Œæ¨ç†åŸºå‡†æµ‹è¯•ï¼Œç»“æœè¡¨æ˜TPOåœ¨Arena-Hardã€MixEval-Hardã€MMLU-Proå’ŒGSM8Kç­‰æ•°æ®é›†ä¸Šåˆ†åˆ«æ¯”DPOå’ŒSimPOé«˜å‡º7.0%å’Œ7.3%ã€12.2%å’Œ13.3%ã€10.4%å’Œ10.1%ã€ä»¥åŠ19.0%å’Œ19.2%çš„å‡†ç¡®åº¦ã€‚æ­¤å¤–ï¼ŒTPOåœ¨éœ€è¦æ›´å°‘æ•°æ®çš„æƒ…å†µä¸‹å®ç°äº†è¿™äº›æ”¹è¿›ã€‚</p>
<p><strong>å…³é”®è§è§£</strong></p>
<ol>
<li>RLHFæé«˜äº†LLMçš„å¯¹é½ç¨‹åº¦ï¼Œä½†å…¶å±€é™æ€§ä¿ƒä½¿äº†DPOæ–¹æ³•çš„å¼€å‘ã€‚</li>
<li>DPOåœ¨æ”¹å–„æŒ‡ä»¤éµå¾ªèƒ½åŠ›çš„åŒæ—¶ï¼Œå¯¹LLMçš„æ¨ç†èƒ½åŠ›äº§ç”Ÿè´Ÿé¢å½±å“ã€‚</li>
<li>DPOå¯¹åå¥½æ•°æ®é›†ä¸­çš„åˆ¤æ–­å™ªå£°å’Œè®­ç»ƒé›†å¤§å°é«˜åº¦æ•æ„Ÿã€‚</li>
<li>æå‡ºçš„TPOæ–¹æ³•æ—¨åœ¨é€šè¿‡ä¸€æ­¥ä¼˜åŒ–åŒæ—¶æé«˜æ¨ç†å’ŒæŒ‡ä»¤éµå¾ªèƒ½åŠ›ã€‚</li>
<li>TPOåœ¨å¤šç§åŸºå‡†æµ‹è¯•ä¸­è¡¨ç°ä¼˜äºDPOåŠå…¶å˜ä½“ã€‚</li>
<li>TPOåœ¨ä¸åŒæ•°æ®é›†ä¸Šå®ç°äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ï¼Œå¹¶ä¸”åœ¨éœ€è¦æ›´å°‘æ•°æ®çš„æƒ…å†µä¸‹åšåˆ°è¿™ä¸€ç‚¹ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2405.16681">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-d80909c0f50ee4b4837f988bf6eab0ba.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-ced7c39a59aaa5319b98a0a5cba1528d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-45b366f343853ff74731d0b600df3040.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-0aa61fc4647c646a9db4f9bf4f3f3c07.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-a47f2f13235fbbbaee0fbc6127180b0e.jpg" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="DP-DyLoRA-Fine-Tuning-Transformer-Based-Models-On-Device-under-Differentially-Private-Federated-Learning-using-Dynamic-Low-Rank-Adaptation"><a href="#DP-DyLoRA-Fine-Tuning-Transformer-Based-Models-On-Device-under-Differentially-Private-Federated-Learning-using-Dynamic-Low-Rank-Adaptation" class="headerlink" title="DP-DyLoRA: Fine-Tuning Transformer-Based Models On-Device under   Differentially Private Federated Learning using Dynamic Low-Rank Adaptation"></a>DP-DyLoRA: Fine-Tuning Transformer-Based Models On-Device under   Differentially Private Federated Learning using Dynamic Low-Rank Adaptation</h2><p><strong>Authors:Jie Xu, Karthikeyan Saravanan, Rogier van Dalen, Haaris Mehmood, David Tuckey, Mete Ozay</strong></p>
<p>Federated learning (FL) allows clients to collaboratively train a global model without sharing their local data with a server. However, clientsâ€™ contributions to the server can still leak sensitive information. Differential privacy (DP) addresses such leakage by providing formal privacy guarantees, with mechanisms that add randomness to the clientsâ€™ contributions. The randomness makes it infeasible to train large transformer-based models, common in modern federated learning systems. In this work, we empirically evaluate the practicality of fine-tuning large scale on-device transformer-based models with differential privacy in a federated learning system. We conduct comprehensive experiments on various system properties for tasks spanning a multitude of domains: speech recognition, computer vision (CV) and natural language understanding (NLU). Our results show that full fine-tuning under differentially private federated learning (DP-FL) generally leads to huge performance degradation which can be alleviated by reducing the dimensionality of contributions through parameter-efficient fine-tuning (PEFT). Our benchmarks of existing DP-PEFT methods show that DP-Low-Rank Adaptation (DP-LoRA) consistently outperforms other methods. An even more promising approach, DyLoRA, which makes the low rank variable, when naively combined with FL would straightforwardly break differential privacy. We therefore propose an adaptation method that can be combined with differential privacy and call it DP-DyLoRA. Finally, we are able to reduce the accuracy degradation and word error rate (WER) increase due to DP to less than 2% and 7% respectively with 1 million clients and a stringent privacy budget of $\epsilon&#x3D;2$. </p>
<blockquote>
<p>è”é‚¦å­¦ä¹ ï¼ˆFLï¼‰å…è®¸å®¢æˆ·ç«¯åœ¨æ²¡æœ‰å°†æ•°æ®å…±äº«ç»™æœåŠ¡å™¨çš„æƒ…å†µä¸‹å…±åŒè®­ç»ƒå…¨å±€æ¨¡å‹ã€‚ç„¶è€Œï¼Œå®¢æˆ·ç«¯å¯¹æœåŠ¡å™¨çš„è´¡çŒ®ä»ç„¶å¯èƒ½æ³„éœ²æ•æ„Ÿä¿¡æ¯ã€‚å·®åˆ†éšç§ï¼ˆDPï¼‰é€šè¿‡æä¾›æ­£å¼çš„éšç§ä¿è¯æ¥è§£å†³æ­¤ç±»æ³„éœ²é—®é¢˜ï¼Œå…¶ä¸­åŒ…å«å‘å®¢æˆ·ç«¯çš„è´¡çŒ®å¢åŠ éšæœºæ€§çš„æœºåˆ¶ã€‚è¿™ç§éšæœºæ€§ä½¿å¾—åœ¨è”é‚¦å­¦ä¹ ç³»ç»Ÿä¸­å¯¹åŸºäºå¤§å‹å˜æ¢çš„æ¨¡å‹è¿›è¡Œå¾®è°ƒå˜å¾—ä¸åˆ‡å®é™…ï¼Œè¿™ç§æ¨¡å‹åœ¨ç°ä»£è”é‚¦å­¦ä¹ ç³»ç»Ÿä¸­å¾ˆå¸¸è§ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬å®è¯è¯„ä¼°äº†åœ¨è”é‚¦å­¦ä¹ ç³»ç»Ÿä¸­å¯¹åŸºäºå¤§å‹å˜æ¢çš„æ¨¡å‹è¿›è¡Œå·®åˆ†éšç§å¾®è°ƒçš„å®é™…å¯è¡Œæ€§ã€‚æˆ‘ä»¬åœ¨æ¶µç›–å¤šä¸ªé¢†åŸŸçš„ä»»åŠ¡ä¸Šå¯¹å„ç§ç³»ç»Ÿå±æ€§è¿›è¡Œäº†å…¨é¢çš„å®éªŒï¼ŒåŒ…æ‹¬è¯­éŸ³è¯†åˆ«ã€è®¡ç®—æœºè§†è§‰ï¼ˆCVï¼‰å’Œè‡ªç„¶è¯­è¨€ç†è§£ï¼ˆNLUï¼‰ã€‚æˆ‘ä»¬çš„ç»“æœè¡¨æ˜ï¼Œåœ¨å·®åˆ†ç§æœ‰è”é‚¦å­¦ä¹ ï¼ˆDP-FLï¼‰ä¸‹è¿›è¡Œå…¨é¢å¾®è°ƒé€šå¸¸ä¼šå¯¼è‡´å·¨å¤§çš„æ€§èƒ½ä¸‹é™ï¼Œè¿™å¯ä»¥é€šè¿‡é€šè¿‡å‚æ•°é«˜æ•ˆå¾®è°ƒï¼ˆPEFTï¼‰å‡å°‘è´¡çŒ®çš„ç»´åº¦æ¥ç¼“è§£ã€‚æˆ‘ä»¬å¯¹ç°æœ‰çš„DP-PEFTæ–¹æ³•çš„åŸºå‡†æµ‹è¯•è¡¨æ˜ï¼ŒDP-LoRAæŒç»­ä¼˜äºå…¶ä»–æ–¹æ³•ã€‚ä¸€ä¸ªæ›´æœ‰å‰é€”çš„æ–¹æ³•æ˜¯DyLoRAï¼Œå®ƒä½¿ä½é˜¶å˜é‡å‘ç”Ÿå˜åŒ–ï¼Œä½†å½“å®ƒä¸FLç®€å•ç»“åˆæ—¶ï¼Œå°†ç›´æ¥ç ´åå·®åˆ†éšç§ã€‚å› æ­¤ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§å¯ä»¥ä¸å·®åˆ†éšç§ç›¸ç»“åˆçš„è‡ªé€‚åº”æ–¹æ³•ï¼Œæˆ‘ä»¬ç§°ä¹‹ä¸ºDP-DyLoRAã€‚æœ€åï¼Œæˆ‘ä»¬èƒ½å¤Ÿå°†ç”±äºDPå¯¼è‡´çš„å‡†ç¡®åº¦ä¸‹é™å’Œè¯é”™è¯¯ç‡ï¼ˆWERï¼‰å¢åŠ å‡å°‘åˆ°ä½äº2%å’Œ7%ï¼ŒåŒæ—¶æ‹¥æœ‰1ç™¾ä¸‡å®¢æˆ·ç«¯å’Œä¸¥æ ¼çš„éšç§é¢„ç®—Îµ&#x3D;2ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2405.06368v4">PDF</a> 16 pages, 10 figures, 5 tables</p>
<p><strong>Summary</strong><br>    æœ¬æ–‡æ¢è®¨äº†å·®åˆ†éšç§ä¸è”é‚¦å­¦ä¹ ç»“åˆçš„é—®é¢˜ï¼ŒæŒ‡å‡ºäº†åœ¨ä½¿ç”¨å·®åˆ†éšç§è¿›è¡Œè”é‚¦å­¦ä¹ æ—¶é¢ä¸´çš„æŒ‘æˆ˜ã€‚é€šè¿‡å¯¹å¤§è§„æ¨¡è®¾å¤‡ä¸ŠåŸºäºè½¬æ¢å™¨çš„æ¨¡å‹è¿›è¡Œå¾®è°ƒå®éªŒï¼Œå‘ç°å·®åˆ†éšç§ä¸‹çš„è”é‚¦å­¦ä¹ ä¼šå¯¼è‡´æ€§èƒ½ä¸‹é™ã€‚é€šè¿‡å‚æ•°é«˜æ•ˆçš„å¾®è°ƒæ–¹æ³•å¯ä»¥ç¼“è§£è¿™ä¸€é—®é¢˜ï¼Œå…¶ä¸­DP-LoRAæ–¹æ³•è¡¨ç°æœ€ä½³ã€‚ä¸ºè¿›ä¸€æ­¥æé«˜æ€§èƒ½ï¼Œæœ¬æ–‡æå‡ºäº†ç»“åˆå·®åˆ†éšç§çš„DP-DyLoRAæ–¹æ³•ï¼Œèƒ½åœ¨ä¿æŒéšç§çš„åŒæ—¶å‡å°‘æ€§èƒ½æŸå¤±ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>è”é‚¦å­¦ä¹ å…è®¸å®¢æˆ·ç«¯åœ¨æ²¡æœ‰å°†æ•°æ®å‘é€ç»™æœåŠ¡å™¨çš„æƒ…å†µä¸‹å…±åŒè®­ç»ƒå…¨å±€æ¨¡å‹ã€‚</li>
<li>å®¢æˆ·ç«¯å¯¹æœåŠ¡å™¨çš„è´¡çŒ®å¯èƒ½æ³„éœ²æ•æ„Ÿä¿¡æ¯ï¼Œå·®åˆ†éšç§å¯æä¾›æ­£å¼çš„éšç§ä¿éšœæ¥è§£å†³è¿™ä¸€é—®é¢˜ã€‚</li>
<li>åœ¨è”é‚¦å­¦ä¹ ç³»ç»Ÿä¸­å¯¹å¤§è§„æ¨¡è½¬æ¢å™¨æ¨¡å‹è¿›è¡Œå¾®è°ƒæ—¶ï¼Œå·®åˆ†éšç§çš„éšæœºæ€§ä¼šå¯¼è‡´æ€§èƒ½å¤§å¹…ä¸‹é™ã€‚</li>
<li>é€šè¿‡å‚æ•°é«˜æ•ˆçš„å¾®è°ƒæ–¹æ³•ï¼ˆå¦‚DP-LoRAï¼‰å¯ä»¥ç¼“è§£å·®åˆ†éšç§å¸¦æ¥çš„æ€§èƒ½ä¸‹é™é—®é¢˜ã€‚</li>
<li>DP-DyLoRAæ˜¯ä¸€ç§æ–°çš„ç»“åˆå·®åˆ†éšç§çš„æ–¹æ³•ï¼Œèƒ½å¤Ÿåœ¨ä¿æŒéšç§çš„åŒæ—¶æé«˜æ€§èƒ½ã€‚</li>
<li>å®éªŒç»“æœè¡¨æ˜ï¼Œåœ¨ä¸¥æ ¼çš„éšç§é¢„ç®—ä¸‹ï¼Œä½¿ç”¨DP-DyLoRAæ–¹æ³•å¯ä»¥å°†ç”±äºå·®åˆ†éšç§å¯¼è‡´çš„å‡†ç¡®ç‡ä¸‹é™å’Œè¯é”™è¯¯ç‡å¢åŠ å‡å°‘åˆ°ä¸åˆ°2%å’Œ7%ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2405.06368">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-02b124820ae35e0a04bbe7641a8bdc8b.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-7942df17f1929358b40f2197af4e94fe.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-58aafe448f1b218e1be4f4a4d0c54d94.jpg" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1><h2 id="A-Heterogeneous-Chiplet-Architecture-for-Accelerating-End-to-End-Transformer-Models"><a href="#A-Heterogeneous-Chiplet-Architecture-for-Accelerating-End-to-End-Transformer-Models" class="headerlink" title="A Heterogeneous Chiplet Architecture for Accelerating End-to-End   Transformer Models"></a>A Heterogeneous Chiplet Architecture for Accelerating End-to-End   Transformer Models</h2><p><strong>Authors:Harsh Sharma, Pratyush Dhingra, Janardhan Rao Doppa, Umit Ogras, Partha Pratim Pande</strong></p>
<p>Transformers have revolutionized deep learning and generative modeling, enabling advancements in natural language processing tasks. However, the size of transformer models is increasing continuously, driven by enhanced capabilities across various deep learning tasks. This trend of ever-increasing model size has given rise to new challenges in terms of memory and compute requirements. Conventional computing platforms, including GPUs, suffer from suboptimal performance due to the memory demands imposed by models with millions&#x2F;billions of parameters. The emerging chiplet-based platforms provide a new avenue for compute- and data-intensive machine learning (ML) applications enabled by a Network-on-Interposer (NoI). However, designing suitable hardware accelerators for executing Transformer inference workloads is challenging due to a wide variety of complex computing kernels in the Transformer architecture. In this paper, we leverage chiplet-based heterogeneous integration (HI) to design a high-performance and energy-efficient multi-chiplet platform to accelerate transformer workloads. We demonstrate that the proposed NoI architecture caters to the data access patterns inherent in a transformer model. The optimized placement of the chiplets and the associated NoI links and routers enable superior performance compared to the state-of-the-art hardware accelerators. The proposed NoI-based architecture demonstrates scalability across varying transformer models and improves latency and energy efficiency by up to 11.8x and 2.36x, respectively when compared with the existing state-of-the-art architecture HAIMA. </p>
<blockquote>
<p>è½¬æ¢å™¨ï¼ˆTransformersï¼‰å·²ç»æ·±åˆ»åœ°æ”¹å˜äº†æ·±åº¦å­¦ä¹ å’Œç”Ÿæˆå»ºæ¨¡ï¼Œå¹¶ä¿ƒè¿›äº†è‡ªç„¶è¯­è¨€å¤„ç†ä»»åŠ¡çš„è¿›æ­¥ã€‚ç„¶è€Œï¼Œç”±äºå„é¡¹æ·±åº¦å­¦ä¹ ä»»åŠ¡çš„æ€§èƒ½æå‡ï¼Œè½¬æ¢å™¨æ¨¡å‹çš„å¤§å°ä¹Ÿåœ¨æŒç»­å¢é•¿ã€‚è¿™ç§æ¨¡å‹è§„æ¨¡ä¸æ–­å¢å¤§çš„è¶‹åŠ¿ç»™å†…å­˜å’Œè®¡ç®—éœ€æ±‚å¸¦æ¥äº†æ–°çš„æŒ‘æˆ˜ã€‚ä¼ ç»Ÿçš„è®¡ç®—å¹³å°ï¼ŒåŒ…æ‹¬GPUï¼Œç”±äºæ¨¡å‹å‚æ•°åºå¤§ï¼ˆè¾¾æ•°ç™¾ä¸‡æˆ–æ•°åäº¿ï¼‰ï¼Œå¯¹å†…å­˜çš„éœ€æ±‚ä½¿å¾—å…¶æ€§èƒ½å—åˆ°é™åˆ¶ã€‚åŸºäºèŠ¯ç‰‡ç‰‡çš„å¹³å°ï¼ˆchiplet-based platformsï¼‰é€šè¿‡æ•´åˆç½‘ç»œèŠ¯ç‰‡é—´è¿æ¥å™¨ï¼ˆNetwork-on-Interposerï¼ŒNoIï¼‰ä¸ºè®¡ç®—å’Œæ•°æ®å¯†é›†å‹æœºå™¨å­¦ä¹ ï¼ˆMLï¼‰åº”ç”¨æä¾›äº†æ–°çš„æœºä¼šã€‚ç„¶è€Œï¼Œè®¾è®¡é€‚åˆæ‰§è¡ŒTransformeræ¨ç†å·¥ä½œè´Ÿè½½çš„ç¡¬ä»¶åŠ é€Ÿå™¨æ˜¯ä¸€é¡¹æŒ‘æˆ˜ï¼Œå› ä¸ºTransformeræ¶æ„ä¸­çš„è®¡ç®—æ ¸å¿ƒç§ç±»ç¹å¤šä¸”å¤æ‚ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬åˆ©ç”¨åŸºäºèŠ¯ç‰‡ç‰‡çš„å¼‚æ„é›†æˆï¼ˆHeterogeneous Integrationï¼ŒHIï¼‰è®¾è®¡äº†ä¸€ä¸ªé«˜æ€§èƒ½å’Œèƒ½æ•ˆçš„å¤šèŠ¯ç‰‡ç‰‡å¹³å°ï¼Œä»¥åŠ é€ŸTransformerå·¥ä½œè´Ÿè½½ã€‚æˆ‘ä»¬è¯æ˜æ‰€æå‡ºçš„NoIæ¶æ„å¯ä»¥æ»¡è¶³Transformeræ¨¡å‹ä¸­å›ºæœ‰çš„æ•°æ®è®¿é—®æ¨¡å¼ã€‚èŠ¯ç‰‡ç‰‡çš„ä¼˜åŒ–æ”¾ç½®ä»¥åŠç›¸å…³NoIé“¾æ¥å’Œè·¯ç”±å™¨ä½¿å¾—å…¶æ€§èƒ½è¶…è¶Šæœ€æ–°çš„ç¡¬ä»¶åŠ é€Ÿå™¨ã€‚ä¸å…¶ä»–ç°æœ‰æœ€å…ˆè¿›çš„æ¶æ„HAIMAç›¸æ¯”ï¼Œæ‰€æå‡ºçš„åŸºäºNoIçš„æ¶æ„åœ¨ä¸åŒçš„Transformeræ¨¡å‹ä¸­è¡¨ç°å‡ºå¯æ‰©å±•æ€§ï¼Œåœ¨å»¶è¿Ÿå’Œèƒ½æ•ˆæ–¹é¢åˆ†åˆ«æé«˜äº†é«˜è¾¾11.8å€å’Œ2.36å€ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2312.11750v2">PDF</a> To appear in ACM Transactions on Design Automation of Electronic   Systems, 2025</p>
<p><strong>Summary</strong><br>     éšç€Transformeræ¨¡å‹åœ¨è‡ªç„¶è¯­è¨€å¤„ç†ä»»åŠ¡ä¸­åº”ç”¨çš„å¿«é€Ÿå‘å±•ï¼Œæ¨¡å‹è§„æ¨¡æŒç»­å¢å¤§ï¼Œå¯¹è®¡ç®—å’Œå†…å­˜çš„éœ€æ±‚ä¹Ÿéšä¹‹å¢åŠ ã€‚ä¼ ç»Ÿçš„è®¡ç®—å¹³å°å¦‚GPUéš¾ä»¥æ»¡è¶³è¿™äº›éœ€æ±‚ã€‚æ–°å…´çš„åŸºäºèŠ¯ç‰‡å°ç‰‡çš„å¹³å°é€šè¿‡ç‰‡ä¸Šç½‘ç»œæä¾›æ–°çš„è§£å†³æ–¹æ¡ˆï¼Œä½†åœ¨Transformeræ¶æ„çš„å¤æ‚è®¡ç®—å†…æ ¸ä¸­è®¾è®¡åˆé€‚çš„ç¡¬ä»¶åŠ é€Ÿå™¨ä»å…·æŒ‘æˆ˜ã€‚æœ¬ç ”ç©¶åˆ©ç”¨åŸºäºèŠ¯ç‰‡å°ç‰‡çš„å¼‚æ„é›†æˆæŠ€æœ¯ï¼Œè®¾è®¡äº†ä¸€ä¸ªé«˜æ€§èƒ½ã€ä½èƒ½è€—çš„è·¨èŠ¯ç‰‡å°ç‰‡å¹³å°ä»¥åŠ é€ŸTransformeræ¨ç†å·¥ä½œè´Ÿè½½ã€‚ç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ¡ˆèƒ½æœ‰æ•ˆæ»¡è¶³Transformeræ¨¡å‹çš„æ•°æ®è®¿é—®éœ€æ±‚ï¼Œåœ¨å…ˆè¿›çš„ç¡¬ä»¶åŠ é€Ÿå™¨ä¸­è¡¨ç°ä¼˜è¶Šï¼Œåœ¨ä¸åŒTransformeræ¨¡å‹ä¸­å…·æœ‰å¯æ‰©å±•æ€§ï¼Œä¸ç°æœ‰æœ€å…ˆè¿›çš„æ¶æ„ç›¸æ¯”ï¼Œå»¶è¿Ÿå’Œèƒ½æ•ˆåˆ†åˆ«æé«˜äº†æœ€å¤šè¾¾11.8å€å’Œ2.36å€ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>Transformeræ¨¡å‹çš„åº”ç”¨å¸¦åŠ¨äº†è‡ªç„¶è¯­è¨€å¤„ç†ä»»åŠ¡çš„è¿›æ­¥ï¼Œä½†æ¨¡å‹è§„æ¨¡çš„å¢å¤§å¸¦æ¥äº†è®¡ç®—å’Œå†…å­˜éœ€æ±‚çš„æŒ‘æˆ˜ã€‚</li>
<li>ä¼ ç»Ÿè®¡ç®—å¹³å°å¦‚GPUéš¾ä»¥æ»¡è¶³å¤§è§„æ¨¡Transformeræ¨¡å‹çš„å†…å­˜å’Œè®¡ç®—éœ€æ±‚ã€‚</li>
<li>åŸºäºèŠ¯ç‰‡å°ç‰‡çš„å¹³å°é€šè¿‡ç‰‡ä¸Šç½‘ç»œä¸ºè®¡ç®—å¯†é›†å‹å’Œæ•°æ®å¯†é›†å‹æœºå™¨å­¦ä¹ åº”ç”¨æä¾›äº†æ–°çš„è§£å†³æ–¹æ¡ˆã€‚</li>
<li>è®¾è®¡é€‚åˆTransformeræ¶æ„çš„ç¡¬ä»¶åŠ é€Ÿå™¨æ˜¯ä¸€é¡¹æŒ‘æˆ˜ï¼Œå› ä¸ºè¯¥æ¶æ„åŒ…å«å¤šç§å¤æ‚çš„è®¡ç®—å†…æ ¸ã€‚</li>
<li>ç ”ç©¶æå‡ºäº†ä¸€ç§åŸºäºèŠ¯ç‰‡å°ç‰‡çš„å¼‚æ„é›†æˆæŠ€æœ¯çš„é«˜æ€§èƒ½ã€ä½èƒ½è€—è·¨èŠ¯ç‰‡å°ç‰‡å¹³å°ï¼Œç”¨äºåŠ é€ŸTransformeræ¨ç†å·¥ä½œè´Ÿè½½ã€‚</li>
<li>è¯¥æ–¹æ¡ˆèƒ½æœ‰æ•ˆæ»¡è¶³Transformeræ¨¡å‹çš„æ•°æ®è®¿é—®éœ€æ±‚ï¼Œè¡¨ç°ä¼˜äºå…ˆè¿›çš„ç¡¬ä»¶åŠ é€Ÿå™¨ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2312.11750">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-0c1e78baaa22a3efb429d5087a9bde47.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-b7cc5a3b0f20417a102b66b0cc3793c5.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-4d5aa28db4c39b33b1a20895483f1325.jpg" align="middle">
</details>


<h1 id="-9"><a href="#-9" class="headerlink" title=""></a></h1><h2 id="NetPanorama-A-Declarative-Grammar-for-Network-Construction-Transformation-and-Visualization"><a href="#NetPanorama-A-Declarative-Grammar-for-Network-Construction-Transformation-and-Visualization" class="headerlink" title="NetPanorama: A Declarative Grammar for Network Construction,   Transformation, and Visualization"></a>NetPanorama: A Declarative Grammar for Network Construction,   Transformation, and Visualization</h2><p><strong>Authors:James Scott-Brown, Alexis Pister, Benjamin Bach</strong></p>
<p>This paper introduces NetPanorama, a domain-specific language and declarative grammar for interactive network visualization design that supports multivariate, temporal, and geographic networks. NetPanorama allows users to specify network visualizations as combinations of primitives and building blocks. These support network creation and transformation, including computing metrics; orderings, seriations and layouts; visual encodings, including glyphs, faceting, and label visibility; and interaction for exploration and modifying styling. This approach allows the creation of a range of visualizations including many types of node-link diagrams, adjacency matrices using diverse cell encodings and node orderings, arc diagrams, PivotGraph, small multiples, time-arcs, geographic map visualizations, and hybrid techniques such as NodeTrix. NetPanorama aims to remove the need to use multiple libraries for analysis, wrangling, and visualization. Consequently, NetPanorama supports the agile development of applications for visual exploration of networks and data-driven storytelling. Documentation, source code, further examples, and an interactive online editor can be found online: <a target="_blank" rel="noopener" href="https://netpanorama.netlify.app/">https://netpanorama.netlify.app/</a>. </p>
<blockquote>
<p>æœ¬æ–‡ä»‹ç»äº†NetPanoramaï¼Œè¿™æ˜¯ä¸€ç§é’ˆå¯¹äº¤äº’å¼ç½‘ç»œå¯è§†åŒ–è®¾è®¡çš„é¢†åŸŸç‰¹å®šè¯­è¨€å’Œå£°æ˜æ€§è¯­æ³•ï¼Œæ”¯æŒå¤šå…ƒã€æ—¶é—´å’Œåœ°ç†ç½‘ç»œã€‚NetPanoramaå…è®¸ç”¨æˆ·å°†ç½‘ç»œå¯è§†åŒ–æŒ‡å®šä¸ºåŸå§‹å…ƒç´ å’Œæ„å»ºå—çš„ç»„åˆã€‚è¿™äº›æ”¯æŒç½‘ç»œåˆ›å»ºå’Œè½¬æ¢ï¼ŒåŒ…æ‹¬è®¡ç®—æŒ‡æ ‡ï¼›æ’åºã€ç³»åˆ—å¸ƒå±€ï¼›è§†è§‰ç¼–ç ï¼ŒåŒ…æ‹¬å­—å½¢ã€åˆ†é¢å’Œæ ‡ç­¾å¯è§æ€§ï¼›ä»¥åŠç”¨äºæ¢ç´¢å’Œä¿®æ”¹æ ·å¼çš„äº¤äº’ã€‚è¿™ç§æ–¹æ³•å¯ä»¥åˆ›å»ºå„ç§å¯è§†åŒ–æ•ˆæœï¼ŒåŒ…æ‹¬å¤šç§ç±»å‹çš„èŠ‚ç‚¹é“¾æ¥å›¾ã€ä½¿ç”¨å„ç§å•å…ƒæ ¼ç¼–ç å’ŒèŠ‚ç‚¹æ’åºçš„é‚»æ¥çŸ©é˜µã€å¼§å›¾ã€PivotGraphã€å°å‹å¤åˆ¶å“ã€æ—¶é—´å¼§ã€åœ°ç†åœ°å›¾å¯è§†åŒ–ä»¥åŠè¯¸å¦‚NodeTrixä¹‹ç±»çš„æ··åˆæŠ€æœ¯ã€‚NetPanoramaçš„ç›®æ ‡æ˜¯æ¶ˆé™¤åœ¨åˆ†æã€æ•´ç†å’Œå¯è§†åŒ–è¿‡ç¨‹ä¸­éœ€è¦ä½¿ç”¨å¤šä¸ªåº“çš„éœ€æ±‚ã€‚å› æ­¤ï¼ŒNetPanoramaæ”¯æŒç½‘ç»œå¯è§†åŒ–æ¢ç´¢åº”ç”¨ç¨‹åºçš„æ•æ·å¼€å‘å’Œæ•°æ®é©±åŠ¨çš„æ•…äº‹è®²è¿°ã€‚æ–‡æ¡£ã€æºä»£ç ã€æ›´å¤šç¤ºä¾‹ä»¥åŠåœ¨çº¿äº¤äº’å¼ç¼–è¾‘å™¨å¯ä»¥åœ¨çº¿æ‰¾åˆ°ï¼š<a target="_blank" rel="noopener" href="https://netpanorama.netlify.app/">https://netpanorama.netlify.app/</a>ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18902v2">PDF</a> </p>
<p><strong>Summary</strong><br>    æœ¬æ–‡ä»‹ç»äº†NetPanoramaï¼Œè¿™æ˜¯ä¸€ç§é’ˆå¯¹äº¤äº’å¼ç½‘ç»œå¯è§†åŒ–è®¾è®¡çš„é¢†åŸŸç‰¹å®šè¯­è¨€å’Œå£°æ˜æ€§è¯­æ³•ã€‚å®ƒæ”¯æŒå¤šå…ƒã€æ—¶æ€å’Œåœ°ç†ç½‘ç»œçš„å¯è§†åŒ–ï¼Œå…è®¸ç”¨æˆ·å°†ç½‘ç»œå¯è§†åŒ–æŒ‡å®šä¸ºåŸå§‹å…ƒç´ å’Œæ„å»ºå—çš„ç»„åˆï¼Œæ”¯æŒç½‘ç»œåˆ›å»ºå’Œè½¬æ¢ï¼ŒåŒ…æ‹¬è®¡ç®—æŒ‡æ ‡ã€æ’åºã€åºåˆ—åŒ–ã€å¸ƒå±€ã€è§†è§‰ç¼–ç ä»¥åŠæ¢ç´¢å’Œä¿®æ”¹æ ·å¼çš„äº¤äº’ã€‚NetPanoramaæ—¨åœ¨æ¶ˆé™¤åœ¨åˆ†æã€æ•°æ®æ•´ç†å’Œå¯è§†åŒ–è¿‡ç¨‹ä¸­ä½¿ç”¨å¤šä¸ªåº“çš„éœ€æ±‚ï¼Œæ”¯æŒç½‘ç»œå¯è§†åŒ–åº”ç”¨ç¨‹åºçš„æ•æ·å¼€å‘å’Œæ•°æ®é©±åŠ¨çš„æ•…äº‹å™è¿°ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>NetPanoramaæ˜¯ä¸€ç§ç”¨äºäº¤äº’å¼ç½‘ç»œå¯è§†åŒ–è®¾è®¡çš„é¢†åŸŸç‰¹å®šè¯­è¨€å’Œå£°æ˜æ€§è¯­æ³•ã€‚</li>
<li>å®ƒæ”¯æŒå¤šå…ƒã€æ—¶æ€å’Œåœ°ç†ç½‘ç»œçš„å¯è§†åŒ–ã€‚</li>
<li>NetPanoramaå…è®¸ç”¨æˆ·é€šè¿‡ç»„åˆåŸå§‹å…ƒç´ å’Œæ„å»ºå—æ¥åˆ›å»ºå„ç§ç½‘ç»œå¯è§†åŒ–ã€‚</li>
<li>è¯¥æ–¹æ³•æ¶µç›–äº†ç½‘ç»œçš„åˆ›å»ºå’Œè½¬æ¢ï¼ŒåŒ…æ‹¬è®¡ç®—æŒ‡æ ‡ã€æ’åºã€å¸ƒå±€å’Œè§†è§‰ç¼–ç ç­‰æ–¹é¢ã€‚</li>
<li>NetPanoramaæ”¯æŒäº¤äº’æ¢ç´¢å’Œç½‘ç»œå¯è§†åŒ–çš„æ•æ·åº”ç”¨ç¨‹åºå¼€å‘ã€‚</li>
<li>NetPanoramaæ—¨åœ¨æ¶ˆé™¤åœ¨åˆ†æã€æ•°æ®æ•´ç†å’Œå¯è§†åŒ–è¿‡ç¨‹ä¸­ä½¿ç”¨å¤šä¸ªåº“çš„éœ€æ±‚ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2310.18902">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-179a2180271de8ed7a5eac95441c0710.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-90d199d68a6c006291fa9c6f12cb7a01.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-481822f6e81a7b7809a1465b85112859.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-5ae268e97afa4b443c449509c3f94c5c.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-d271c75ab9ed1e355d519c9915a252f2.jpg" align="middle">
</details>


<h1 id="-10"><a href="#-10" class="headerlink" title=""></a></h1><h2 id="Differentially-Private-Optimization-for-Non-Decomposable-Objective-Functions"><a href="#Differentially-Private-Optimization-for-Non-Decomposable-Objective-Functions" class="headerlink" title="Differentially Private Optimization for Non-Decomposable Objective   Functions"></a>Differentially Private Optimization for Non-Decomposable Objective   Functions</h2><p><strong>Authors:Weiwei Kong, AndrÃ©s MuÃ±oz Medina, MÃ³nica Ribero</strong></p>
<p>Unsupervised pre-training is a common step in developing computer vision models and large language models. In this setting, the absence of labels requires the use of similarity-based loss functions, such as contrastive loss, that favor minimizing the distance between similar inputs and maximizing the distance between distinct inputs. As privacy concerns mount, training these models using differential privacy has become more important. However, due to how inputs are generated for these losses, one of their undesirable properties is that their $L_2$ sensitivity grows with the batch size. This property is particularly disadvantageous for differentially private training methods, such as DP-SGD. To overcome this issue, we develop a new DP-SGD variant for similarity based loss functions â€“ in particular, the commonly-used contrastive loss â€“ that manipulates gradients of the objective function in a novel way to obtain a sensitivity of the summed gradient that is $O(1)$ for batch size $n$. We test our DP-SGD variant on some CIFAR-10 pre-training and CIFAR-100 finetuning tasks and show that, in both tasks, our methodâ€™s performance comes close to that of a non-private model and generally outperforms DP-SGD applied directly to the contrastive loss. </p>
<blockquote>
<p>æ— ç›‘ç£é¢„è®­ç»ƒæ˜¯è®¡ç®—æœºè§†è§‰æ¨¡å‹å’Œå¤§è¯­è¨€æ¨¡å‹å¼€å‘ä¸­çš„å¸¸è§æ­¥éª¤ã€‚åœ¨è¿™ç§èƒŒæ™¯ä¸‹ï¼Œç”±äºæ²¡æœ‰æ ‡ç­¾ï¼Œéœ€è¦ä½¿ç”¨åŸºäºç›¸ä¼¼åº¦çš„æŸå¤±å‡½æ•°ï¼Œå¦‚å¯¹æ¯”æŸå¤±ï¼Œè¿™äº›å‡½æ•°æœ‰åˆ©äºç¼©å°ç›¸ä¼¼è¾“å…¥ä¹‹é—´çš„è·ç¦»å¹¶æœ€å¤§åŒ–ä¸åŒè¾“å…¥ä¹‹é—´çš„è·ç¦»ã€‚éšç€å¯¹éšç§çš„æ‹…å¿§æ—¥ç›Šå¢åŠ ï¼Œä½¿ç”¨å·®åˆ†éšç§è®­ç»ƒè¿™äº›æ¨¡å‹å˜å¾—è¶Šæ¥è¶Šé‡è¦ã€‚ç„¶è€Œï¼Œç”±äºè¿™äº›æŸå¤±å¦‚ä½•ç”Ÿæˆè¾“å…¥ï¼Œå…¶ä¸å¸Œæœ›æœ‰çš„å±æ€§ä¹‹ä¸€æ˜¯å®ƒä»¬çš„L2æ•æ„Ÿæ€§éšæ‰¹æ¬¡å¤§å°çš„å¢é•¿è€Œå¢é•¿ã€‚è¿™ä¸€å±æ€§å¯¹äºå·®åˆ†ç§æœ‰è®­ç»ƒæ–¹æ³•ï¼ˆå¦‚DP-SGDï¼‰å°¤å…¶ä¸åˆ©ã€‚ä¸ºäº†å…‹æœè¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬ä¸ºåŸºäºç›¸ä¼¼æ€§çš„æŸå¤±å‡½æ•°å¼€å‘äº†ä¸€ç§æ–°å‹çš„DP-SGDå˜ä½“â€”â€”ç‰¹åˆ«æ˜¯å¸¸ç”¨çš„å¯¹æ¯”æŸå¤±â€”â€”ä»¥æ–°é¢–çš„æ–¹å¼æ“ä½œç›®æ ‡å‡½æ•°çš„æ¢¯åº¦ï¼Œä»¥è·å¾—å¯¹æ‰¹æ¬¡å¤§å°ä¸ºnçš„æ¢¯åº¦æ€»å’Œçš„Oï¼ˆ1ï¼‰çµæ•åº¦ã€‚æˆ‘ä»¬åœ¨CIFAR-10çš„é¢„è®­ç»ƒå’ŒCIFAR-100çš„å¾®è°ƒä»»åŠ¡ä¸Šæµ‹è¯•äº†æˆ‘ä»¬çš„DP-SGDå˜ä½“ï¼Œå¹¶æ˜¾ç¤ºåœ¨è¿™ä¸¤ä¸ªä»»åŠ¡ä¸­ï¼Œæˆ‘ä»¬çš„æ–¹æ³•çš„æ€§èƒ½æ¥è¿‘éç§æœ‰æ¨¡å‹ï¼Œå¹¶ä¸”é€šå¸¸ä¼˜äºç›´æ¥åº”ç”¨äºå¯¹æ¯”æŸå¤±çš„DP-SGDã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.03104v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†æ— ç›‘ç£é¢„è®­ç»ƒåœ¨è®¡ç®—æœºè§†è§‰æ¨¡å‹å’Œå¤§å‹è¯­è¨€æ¨¡å‹ä¸­çš„åº”ç”¨ï¼Œä»¥åŠåœ¨è¿™ç§è®¾ç½®ä¸‹ä½¿ç”¨åŸºäºç›¸ä¼¼æ€§çš„æŸå¤±å‡½æ•°ï¼ˆå¦‚å¯¹æ¯”æŸå¤±ï¼‰è¿›è¡Œè®­ç»ƒçš„é‡è¦æ€§ã€‚éšç€éšç§é—®é¢˜çš„æ—¥ç›Šçªå‡ºï¼Œä½¿ç”¨å·®åˆ†éšç§è¿›è¡Œæ¨¡å‹è®­ç»ƒå˜å¾—æ›´ä¸ºé‡è¦ã€‚ç„¶è€Œï¼Œç”±äºè¿™äº›æŸå¤±å‡½æ•°ç”Ÿæˆè¾“å…¥çš„æ–¹å¼ï¼Œå…¶L2æ•æ„Ÿæ€§ä¼šéšç€æ‰¹æ¬¡å¤§å°çš„å¢é•¿è€Œå¢é•¿ï¼Œè¿™å¯¹äºå·®åˆ†ç§æœ‰è®­ç»ƒæ–¹æ³•ï¼ˆå¦‚DP-SGDï¼‰å°¤ä¸ºä¸åˆ©ã€‚ä¸ºè§£å†³è¿™ä¸€é—®é¢˜ï¼Œç ”ç©¶è€…å¼€å‘äº†ä¸€ç§æ–°çš„é’ˆå¯¹åŸºäºç›¸ä¼¼æ€§æŸå¤±å‡½æ•°çš„DP-SGDå˜ä½“ï¼Œé€šè¿‡ä»¥æ–°é¢–çš„æ–¹å¼æ“ä½œç›®æ ‡å‡½æ•°çš„æ¢¯åº¦ï¼Œä½¿æ‰¹æ¬¡å¤§å°ä¸ºnæ—¶çš„æ¢¯åº¦æ•æ„Ÿåº¦ä¸ºO(1)ã€‚æµ‹è¯•è¡¨æ˜ï¼Œåœ¨æ–°çš„DP-SGDå˜ä½“åœ¨CIFAR-10é¢„è®­ç»ƒå’ŒCIFAR-100å¾®è°ƒä»»åŠ¡ä¸­çš„æ€§èƒ½æ¥è¿‘éç§æœ‰æ¨¡å‹ï¼Œå¹¶ä¸”é€šå¸¸ä¼˜äºç›´æ¥åº”ç”¨äºå¯¹æ¯”æŸå¤±çš„DP-SGDã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æ— ç›‘ç£é¢„è®­ç»ƒåœ¨è®¡ç®—æœºè§†è§‰æ¨¡å‹å’Œå¤§å‹è¯­è¨€æ¨¡å‹ä¸­å¹¿æ³›åº”ç”¨ï¼Œä½¿ç”¨åŸºäºç›¸ä¼¼æ€§çš„æŸå¤±å‡½æ•°å¦‚å¯¹æ¯”æŸå¤±è¿›è¡Œè®­ç»ƒæ˜¯å…³é”®æ­¥éª¤ã€‚</li>
<li>éšç€éšç§é—®é¢˜çš„é‡è§†ï¼Œå·®åˆ†éšç§åœ¨æ¨¡å‹è®­ç»ƒä¸­çš„åº”ç”¨å˜å¾—é‡è¦ã€‚</li>
<li>åŸºäºç›¸ä¼¼æ€§æŸå¤±å‡½æ•°çš„L2æ•æ„Ÿæ€§éšæ‰¹æ¬¡å¤§å°å¢é•¿çš„é—®é¢˜å¯¹äºå·®åˆ†ç§æœ‰è®­ç»ƒæ–¹æ³•ä¸åˆ©ã€‚</li>
<li>ç ”ç©¶è€…å¼€å‘äº†ä¸€ç§æ–°çš„é’ˆå¯¹åŸºäºç›¸ä¼¼æ€§æŸå¤±å‡½æ•°çš„DP-SGDå˜ä½“ï¼Œé€šè¿‡æ“ä½œç›®æ ‡å‡½æ•°çš„æ¢¯åº¦æ¥è§£å†³ä¸Šè¿°é—®é¢˜ã€‚</li>
<li>æ–°çš„DP-SGDå˜ä½“åœ¨CIFAR-10é¢„è®­ç»ƒå’ŒCIFAR-100å¾®è°ƒä»»åŠ¡ä¸­çš„æ€§èƒ½æ¥è¿‘éç§æœ‰æ¨¡å‹ã€‚</li>
<li>æ–°çš„DP-SGDå˜ä½“é€šå¸¸ä¼˜äºç›´æ¥åº”ç”¨äºå¯¹æ¯”æŸå¤±çš„DP-SGDã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2310.03104">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-7bf6b81d8bd8fb520153a9623e008677.jpg" align="middle">
</details>


<h1 id="-11"><a href="#-11" class="headerlink" title=""></a></h1><h2 id="Detecting-Phishing-Sites-Using-ChatGPT"><a href="#Detecting-Phishing-Sites-Using-ChatGPT" class="headerlink" title="Detecting Phishing Sites Using ChatGPT"></a>Detecting Phishing Sites Using ChatGPT</h2><p><strong>Authors:Takashi Koide, Naoki Fukushi, Hiroki Nakano, Daiki Chiba</strong></p>
<p>The emergence of Large Language Models (LLMs), including ChatGPT, is having a significant impact on a wide range of fields. While LLMs have been extensively researched for tasks such as code generation and text synthesis, their application in detecting malicious web content, particularly phishing sites, has been largely unexplored. To combat the rising tide of cyber attacks due to the misuse of LLMs, it is important to automate detection by leveraging the advanced capabilities of LLMs.   In this paper, we propose a novel system called ChatPhishDetector that utilizes LLMs to detect phishing sites. Our system involves leveraging a web crawler to gather information from websites, generating prompts for LLMs based on the crawled data, and then retrieving the detection results from the responses generated by the LLMs. The system enables us to detect multilingual phishing sites with high accuracy by identifying impersonated brands and social engineering techniques in the context of the entire website, without the need to train machine learning models. To evaluate the performance of our system, we conducted experiments on our own dataset and compared it with baseline systems and several LLMs. The experimental results using GPT-4V demonstrated outstanding performance, with a precision of 98.7% and a recall of 99.6%, outperforming the detection results of other LLMs and existing systems. These findings highlight the potential of LLMs for protecting users from online fraudulent activities and have important implications for enhancing cybersecurity measures. </p>
<blockquote>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„å‡ºç°ï¼ŒåŒ…æ‹¬ChatGPTï¼Œå¯¹å¹¿æ³›é¢†åŸŸäº§ç”Ÿäº†é‡å¤§å½±å“ã€‚è™½ç„¶LLMåœ¨ä»£ç ç”Ÿæˆå’Œæ–‡æœ¬åˆæˆç­‰ä»»åŠ¡ä¸Šå·²ç»è¢«å¹¿æ³›ç ”ç©¶ï¼Œä½†å®ƒä»¬åœ¨æ£€æµ‹æ¶æ„ç½‘é¡µå†…å®¹ï¼Œå°¤å…¶æ˜¯é’“é±¼ç½‘ç«™æ–¹é¢çš„åº”ç”¨å´è¢«å¤§å¤§å¿½è§†äº†ã€‚ä¸ºäº†åº”å¯¹å› LLMçš„è¯¯ç”¨è€Œæ—¥ç›Šå¢å¤šçš„ç½‘ç»œæ”»å‡»æµªæ½®ï¼Œåˆ©ç”¨LLMçš„å…ˆè¿›åŠŸèƒ½æ¥è‡ªåŠ¨åŒ–æ£€æµ‹è‡³å…³é‡è¦ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åä¸ºChatPhishDetectorçš„æ–°å‹ç³»ç»Ÿï¼Œè¯¥ç³»ç»Ÿåˆ©ç”¨LLMæ£€æµ‹é’“é±¼ç½‘ç«™ã€‚æˆ‘ä»¬çš„ç³»ç»Ÿé€šè¿‡ç½‘é¡µçˆ¬è™«ä»ç½‘ç«™ä¸Šæ”¶é›†ä¿¡æ¯ï¼Œæ ¹æ®çˆ¬å–çš„æ•°æ®ä¸ºLLMç”Ÿæˆæç¤ºï¼Œç„¶åä»LLMç”Ÿæˆçš„å“åº”ä¸­æ£€ç´¢æ£€æµ‹ç»“æœã€‚è¯¥ç³»ç»Ÿä½¿æˆ‘ä»¬èƒ½å¤Ÿåœ¨ä¸è®­ç»ƒæœºå™¨å­¦ä¹ æ¨¡å‹çš„æƒ…å†µä¸‹ï¼Œé€šè¿‡è¯†åˆ«å‡å†’å“ç‰Œå’Œç½‘ç«™æ•´ä½“ä¸Šä¸‹æ–‡ä¸­çš„ç¤¾ä¼šå·¥ç¨‹æŠ€æœ¯ï¼Œä»¥é«˜ç²¾ç¡®åº¦æ£€æµ‹å¤šè¯­è¨€é’“é±¼ç½‘ç«™ã€‚ä¸ºäº†è¯„ä¼°æˆ‘ä»¬ç³»ç»Ÿçš„æ€§èƒ½ï¼Œæˆ‘ä»¬åœ¨è‡ªå·±çš„æ•°æ®é›†ä¸Šè¿›è¡Œäº†å®éªŒï¼Œå¹¶ä¸åŸºçº¿ç³»ç»Ÿå’Œå‡ ç§LLMè¿›è¡Œäº†æ¯”è¾ƒã€‚ä½¿ç”¨GPT-4Vçš„å®éªŒç»“æœè¡¨ç°å‡ºè‰²ï¼Œç²¾ç¡®åº¦ä¸º98.7%ï¼Œå¬å›ç‡ä¸º99.6%ï¼Œä¼˜äºå…¶ä»–LLMå’Œç°æœ‰ç³»ç»Ÿçš„æ£€æµ‹ç»“æœã€‚è¿™äº›å‘ç°å‡¸æ˜¾äº†LLMåœ¨ä¿æŠ¤ç”¨æˆ·å…å—åœ¨çº¿æ¬ºè¯ˆæ´»åŠ¨æ–¹é¢çš„æ½œåŠ›ï¼Œå¯¹äºå¢å¼ºç½‘ç»œå®‰å…¨æªæ–½å…·æœ‰é‡è¦çš„å¯ç¤ºæ„ä¹‰ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2306.05816v3">PDF</a> </p>
<p><strong>Summary</strong>ï¼šå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å¦‚ChatGPTçš„å‡ºç°ï¼Œå¯¹å¤šä¸ªé¢†åŸŸäº§ç”Ÿäº†æ·±è¿œå½±å“ã€‚å°½ç®¡LLMåœ¨ä»£ç ç”Ÿæˆå’Œæ–‡æœ¬åˆæˆç­‰æ–¹é¢å·²æœ‰å¹¿æ³›ç ”ç©¶ï¼Œä½†å…¶åœ¨æ£€æµ‹æ¶æ„ç½‘é¡µå†…å®¹ï¼Œå°¤å…¶æ˜¯é’“é±¼ç½‘ç«™æ–¹é¢çš„åº”ç”¨å´è¢«å¿½è§†ã€‚ä¸ºåº”å¯¹å› LLMè¯¯ç”¨è€Œå¼•å‘çš„ç½‘ç»œæ”»å‡»æ½®ï¼Œåˆ©ç”¨LLMçš„å…ˆè¿›åŠŸèƒ½è¿›è¡Œè‡ªåŠ¨åŒ–æ£€æµ‹è‡³å…³é‡è¦ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸ºChatPhishDetectorçš„æ–°ç³»ç»Ÿï¼Œè¯¥ç³»ç»Ÿåˆ©ç”¨LLMæ£€æµ‹é’“é±¼ç½‘ç«™ã€‚è¯¥ç³»ç»Ÿé€šè¿‡ç½‘é¡µçˆ¬è™«æ”¶é›†ç½‘ç«™ä¿¡æ¯ï¼ŒåŸºäºçˆ¬å–æ•°æ®ä¸ºLLMç”Ÿæˆæç¤ºï¼Œå¹¶ä»LLMç”Ÿæˆçš„å“åº”ä¸­æ£€ç´¢æ£€æµ‹ç»“æœã€‚è¯¥ç³»ç»Ÿèƒ½å¤Ÿå‡†ç¡®æ£€æµ‹å¤šè¯­è¨€é’“é±¼ç½‘ç«™ï¼Œé€šè¿‡è¯†åˆ«å‡å†’å“ç‰Œå’Œç½‘ç«™ä¸Šä¸‹æ–‡ä¸­çš„ç¤¾ä¼šå·¥ç¨‹æŠ€æœ¯ï¼Œæ— éœ€è®­ç»ƒæœºå™¨å­¦ä¹ æ¨¡å‹ã€‚ä½¿ç”¨GPT-4Vè¿›è¡Œçš„å®éªŒè¡¨æ˜ï¼Œè¯¥ç³»ç»Ÿè¡¨ç°ä¼˜å¼‚ï¼Œç²¾ç¡®åº¦ä¸º98.7%ï¼Œå¬å›ç‡ä¸º99.6%ï¼Œä¼˜äºå…¶ä»–LLMå’Œç°æœ‰ç³»ç»Ÿã€‚è¿™äº›å‘ç°çªæ˜¾äº†LLMåœ¨ä¿æŠ¤ç”¨æˆ·å…å—åœ¨çº¿æ¬ºè¯ˆæ´»åŠ¨æ–¹é¢çš„æ½œåŠ›ï¼Œå¯¹åŠ å¼ºç½‘ç»œå®‰å…¨æªæ–½å…·æœ‰é‡è¦æ„ä¹‰ã€‚</p>
<p><strong>Key Takeaways</strong>ï¼š</p>
<ol>
<li>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å¯¹å¤šä¸ªé¢†åŸŸäº§ç”Ÿå½±å“ï¼Œä½†åœ¨æ£€æµ‹æ¶æ„ç½‘é¡µå†…å®¹æ–¹é¢çš„åº”ç”¨å°šæœªè¢«å……åˆ†æ¢ç´¢ã€‚</li>
<li>é’“é±¼ç½‘ç«™æ£€æµ‹é¢ä¸´æŒ‘æˆ˜ï¼Œéœ€è¦æ–°çš„è§£å†³æ–¹æ¡ˆæ¥åº”å¯¹ã€‚</li>
<li>ChatPhishDetectorç³»ç»Ÿåˆ©ç”¨LLMè¿›è¡Œé’“é±¼ç½‘ç«™æ£€æµ‹ï¼Œé€šè¿‡ç½‘é¡µçˆ¬è™«æ”¶é›†ä¿¡æ¯å¹¶ç”Ÿæˆé’ˆå¯¹LLMçš„æç¤ºã€‚</li>
<li>ç³»ç»Ÿèƒ½å¤Ÿåœ¨æ— éœ€è®­ç»ƒæœºå™¨å­¦ä¹ æ¨¡å‹çš„æƒ…å†µä¸‹ï¼Œå‡†ç¡®æ£€æµ‹å¤šè¯­è¨€é’“é±¼ç½‘ç«™ã€‚</li>
<li>ChatPhishDetectorç³»ç»Ÿé€šè¿‡è¯†åˆ«å‡å†’å“ç‰Œå’Œç½‘ç«™ä¸Šä¸‹æ–‡ä¸­çš„ç¤¾ä¼šå·¥ç¨‹æŠ€æœ¯æ¥æ£€æµ‹é’“é±¼ç½‘ç«™ã€‚</li>
<li>ä½¿ç”¨GPT-4Vçš„å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥ç³»ç»Ÿè¡¨ç°ä¼˜å¼‚ï¼Œç²¾ç¡®åº¦å’Œå¬å›ç‡å‡å¾ˆé«˜ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2306.05816">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-5b04c4e96e3592eba11a344eb47e137d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e85fc94c559d9c60f8805952ee8bc3ec.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-df9703d66c2c769bf0d9ec7f6fde9bdf.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-8d356e5c56189dfe3ab156a3748b7a63.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-fd5aec823d569921f8b6ee8fb99a03af.jpg" align="middle">
</details>


<h1 id="-12"><a href="#-12" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-02-23/LLM/">https://kedreamix.github.io/Talk2Paper/Paper/2025-02-23/LLM/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/LLM/">
                                    <span class="chip bg-color">LLM</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-02-26/LLM/">
                    <div class="card-image">
                        
                        <img src="https://pic1.zhimg.com/v2-1dad80a4c1a092eeeaa1fdaccf907497.jpg" class="responsive-img" alt="LLM">
                        
                        <span class="card-title">LLM</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            LLM æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-02-26  Introducing Visual Perception Token into Multimodal Large Language Model
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-02-26
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/LLM/" class="post-category">
                                    LLM
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/LLM/">
                        <span class="chip bg-color">LLM</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-02-22/Talking%20Head%20Generation/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-be6d752ce401869c5e645a63c25c02e9.jpg" class="responsive-img" alt="Talking Head Generation">
                        
                        <span class="card-title">Talking Head Generation</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Talking Head Generation æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-02-22  NeRF-3DTalker Neural Radiance Field with 3D Prior Aided Audio   Disentanglement for Talking Head Synthesis
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-02-22
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Talking-Head-Generation/" class="post-category">
                                    Talking Head Generation
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Talking-Head-Generation/">
                        <span class="chip bg-color">Talking Head Generation</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">19758k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
