<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="NeRF">
    <meta name="description" content="NeRF 方向最新论文已更新，请持续关注 Update in 2025-10-01  Triangle Splatting+ Differentiable Rendering with Opaque Triangles">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>NeRF | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loader页面消失采用渐隐的方式*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logo出现动画 */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//使用渐隐的方法淡出loading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//强制显示loading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">嘘~  正在从服务器偷取页面 . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>首页</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>标签</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>分类</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>归档</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="搜索" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="深色/浅色模式" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			首页
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			标签
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			分类
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			归档
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://pic1.zhimg.com/v2-4085ada383e57ca40ad86b2e077ab791.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">NeRF</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/NeRF/">
                                <span class="chip bg-color">NeRF</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/NeRF/" class="post-category">
                                NeRF
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2025-10-01
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>更新日期:&nbsp;&nbsp;
                    2025-10-09
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp;
                    7.5k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp;
                    30 分
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>阅读次数:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>⚠️ 以下所有内容总结都来自于 大语言模型的能力，如有错误，仅供参考，谨慎使用<br>🔴 请注意：千万不要用于严肃的学术场景，只能用于论文阅读前的初筛！<br>💗 如果您觉得我们的项目对您有帮助 <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ，还请您给我们一些鼓励！⭐️ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFace免费体验</a></p>
</blockquote>
<h1 id="2025-10-01-更新"><a href="#2025-10-01-更新" class="headerlink" title="2025-10-01 更新"></a>2025-10-01 更新</h1><h2 id="Triangle-Splatting-Differentiable-Rendering-with-Opaque-Triangles"><a href="#Triangle-Splatting-Differentiable-Rendering-with-Opaque-Triangles" class="headerlink" title="Triangle Splatting+: Differentiable Rendering with Opaque Triangles"></a>Triangle Splatting+: Differentiable Rendering with Opaque Triangles</h2><p><strong>Authors:Jan Held, Renaud Vandeghen, Sanghyun Son, Daniel Rebain, Matheus Gadelha, Yi Zhou, Ming C. Lin, Marc Van Droogenbroeck, Andrea Tagliasacchi</strong></p>
<p>Reconstructing 3D scenes and synthesizing novel views has seen rapid progress in recent years. Neural Radiance Fields demonstrated that continuous volumetric radiance fields can achieve high-quality image synthesis, but their long training and rendering times limit practicality. 3D Gaussian Splatting (3DGS) addressed these issues by representing scenes with millions of Gaussians, enabling real-time rendering and fast optimization. However, Gaussian primitives are not natively compatible with the mesh-based pipelines used in VR headsets, and real-time graphics applications. Existing solutions attempt to convert Gaussians into meshes through post-processing or two-stage pipelines, which increases complexity and degrades visual quality. In this work, we introduce Triangle Splatting+, which directly optimizes triangles, the fundamental primitive of computer graphics, within a differentiable splatting framework. We formulate triangle parametrization to enable connectivity through shared vertices, and we design a training strategy that enforces opaque triangles. The final output is immediately usable in standard graphics engines without post-processing. Experiments on the Mip-NeRF360 and Tanks &amp; Temples datasets show that Triangle Splatting+achieves state-of-the-art performance in mesh-based novel view synthesis. Our method surpasses prior splatting approaches in visual fidelity while remaining efficient and fast to training. Moreover, the resulting semi-connected meshes support downstream applications such as physics-based simulation or interactive walkthroughs. The project page is <a target="_blank" rel="noopener" href="https://trianglesplatting2.github.io/trianglesplatting2/">https://trianglesplatting2.github.io/trianglesplatting2/</a>. </p>
<blockquote>
<p>近年来，重建三维场景和合成新视角的技术取得了快速发展。神经辐射场证明连续体积辐射场可以实现高质量图像合成，但其漫长的训练和渲染时间限制了实用性。3D高斯贴合（3DGS）通过用数百万个高斯表示场景解决了这些问题，实现了实时渲染和快速优化。然而，高斯原始数据并不兼容VR头盔和实时图形应用程序所使用的基于网格的管道。现有解决方案尝试通过后期处理或两阶段管道将高斯转换为网格，这增加了复杂性并降低了视觉质量。在这项工作中，我们引入了Triangle Splatting+，它在可微分的贴合框架内直接优化计算机图形的基本原始元素——三角形。我们制定三角形参数化，通过共享顶点实现连接，并设计了一种训练策略，强制实施不透明三角形。最终输出物可立即在标准图形引擎中使用，无需后期处理。在Mip-NeRF360和Tanks &amp; Temples数据集上的实验表明，Triangle Splatting+在基于网格的新视角合成中达到了最新技术水平。我们的方法在视觉保真度上超越了先前的贴合方法，同时保持了高效和快速的训练。此外，所得的半连接网格支持下游应用，如基于物理的模拟或交互式浏览。项目页面为<a target="_blank" rel="noopener" href="https://trianglesplatting2.github.io/trianglesplatting2/%E3%80%82">https://trianglesplatting2.github.io/trianglesplatting2/。</a></p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.25122v1">PDF</a> 9 pages, 6 figures, 2 tables</p>
<p><strong>Summary</strong><br>     神经网络辐射场在三维场景重建和合成新视角方面取得了进展，但其训练与渲染时间较长限制了实际应用。为解决这个问题，研究者提出使用三维高斯贴图技术表示场景，实现实时渲染和快速优化。然而，高斯原始数据并不兼容VR头盔和实时图形应用中的网格基础管道。现有解决方案尝试将高斯转换为网格，但增加了复杂性和降低了视觉质量。本研究引入Triangle Splatting+，直接在可微分的贴图框架内优化计算机图形的基本原始元素——三角形。我们制定了三角形参数化公式以实现通过共享顶点进行连接，并设计了一种训练策略以强制执行不透明的三角形。最终输出可以直接在标准图形引擎中使用，无需后处理。实验结果展示了该方法在基于网格的新型视图合成中的卓越性能，超越先前的贴图方法，同时保持高效和快速的训练过程。此外，所得半连接网格支持下游应用如物理模拟或交互式漫游等。项目页面为：<a target="_blank" rel="noopener" href="https://trianglesplatting2.github.io/trianglesplatting2/">链接地址</a>。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>神经网络辐射场在三维场景重建和图像合成方面取得了重要进展，但存在训练和渲染时间较长的问题。</li>
<li>三维高斯贴图技术为解决这一问题提供了新的思路，实现了实时渲染和快速优化。</li>
<li>当前方法面临高斯原始数据与VR头盔和实时图形应用中网格基础管道的不兼容问题。</li>
<li>Triangle Splatting+方法直接优化计算机图形的基本元素——三角形，实现了高效且高质量的渲染结果。</li>
<li>Triangle Splatting+通过共享顶点实现三角形连接，同时设计训练策略以生成不透明三角形，增强了视觉质量。</li>
<li>最终输出可以直接在标准图形引擎中使用，无需后处理步骤。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.25122">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic-private.zhihu.com/v2-79e7471e12407ef33b5a74f20a1762f5~resize:0:q75.jpg?source=1f5c5e47&expiration=1759930399&auth_key=1759930399-0-0-f371948bfb637c7ca75ae1ab31600e59&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-aced2ec14cce54803edf23b5e5e6b2e7~resize:0:q75.jpg?source=1f5c5e47&expiration=1759930407&auth_key=1759930407-0-0-ced24cbf99d249565afa55b24ac00805&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://picx.zhimg.com/v2-b1e9ff6a08bae476f3ec7ed58181ec8a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-04e63a5e35859c9a12ad1157bc3f21c6.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="GEM-3D-Gaussian-Splatting-for-Efficient-and-Accurate-Cryo-EM-Reconstruction"><a href="#GEM-3D-Gaussian-Splatting-for-Efficient-and-Accurate-Cryo-EM-Reconstruction" class="headerlink" title="GEM: 3D Gaussian Splatting for Efficient and Accurate Cryo-EM   Reconstruction"></a>GEM: 3D Gaussian Splatting for Efficient and Accurate Cryo-EM   Reconstruction</h2><p><strong>Authors:Huaizhi Qu, Xiao Wang, Gengwei Zhang, Jie Peng, Tianlong Chen</strong></p>
<p>Cryo-electron microscopy (cryo-EM) has become a central tool for high-resolution structural biology, yet the massive scale of datasets (often exceeding 100k particle images) renders 3D reconstruction both computationally expensive and memory intensive. Traditional Fourier-space methods are efficient but lose fidelity due to repeated transforms, while recent real-space approaches based on neural radiance fields (NeRFs) improve accuracy but incur cubic memory and computation overhead. Therefore, we introduce GEM, a novel cryo-EM reconstruction framework built on 3D Gaussian Splatting (3DGS) that operates directly in real-space while maintaining high efficiency. Instead of modeling the entire density volume, GEM represents proteins with compact 3D Gaussians, each parameterized by only 11 values. To further improve the training efficiency, we designed a novel gradient computation to 3D Gaussians that contribute to each voxel. This design substantially reduced both memory footprint and training cost. On standard cryo-EM benchmarks, GEM achieves up to 48% faster training and 12% lower memory usage compared to state-of-the-art methods, while improving local resolution by as much as 38.8%. These results establish GEM as a practical and scalable paradigm for cryo-EM reconstruction, unifying speed, efficiency, and high-resolution accuracy. Our code is available at <a target="_blank" rel="noopener" href="https://github.com/UNITES-Lab/GEM">https://github.com/UNITES-Lab/GEM</a>. </p>
<blockquote>
<p>冷冻电子显微镜（cryo-EM）已成为高分辨率结构生物学的重要工具，但数据集的大规模（通常超过10万张粒子图像）使得3D重建在计算和内存方面都很昂贵。传统的傅里叶空间方法虽然效率高，但由于重复变换而失去精度，而最近基于神经辐射场（NeRFs）的实空间方法提高了准确性，但产生了立方级的内存和计算开销。因此，我们引入了GEM，这是一个新的冷冻电镜重建框架，它基于三维高斯拼贴（3DGS）技术，直接在实空间中运行，同时保持高效率。GEM不是对整个密度体积进行建模，而是用紧凑的三维高斯来表示蛋白质，每个高斯仅由11个值参数化。为了进一步改进训练效率，我们设计了一种新型的三维高斯梯度计算，为每个体素做出贡献。这一设计大大减少了内存占用和训练成本。在标准的冷冻电镜基准测试中，与最新方法相比，GEM实现了最多达48%更快的训练和12%更低的内存使用率，同时局部分辨率提高了高达38.8%。这些结果证明了GEM作为冷冻电镜重建实用且可扩展的范式，统一了速度、效率和高分辨率的准确性。我们的代码可在<a target="_blank" rel="noopener" href="https://github.com/UNITES-Lab/GEM%E8%8E%B7%E5%8F%96%E3%80%82">https://github.com/UNITES-Lab/GEM获取。</a></p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.25075v1">PDF</a> </p>
<p><strong>Summary</strong><br>     神经辐射场（NeRF）在冷冻电子显微镜（cryo-EM）重建中展现出高精度，但计算量大且内存密集。本研究提出一种新型框架GEM，采用三维高斯拼贴（3DGS）直接在实空间操作并保持高效率。通过用紧凑的三维高斯代表蛋白质而非模拟整个密度体积，并利用一种新型的梯度计算方法提高训练效率，达到提升训练速度和内存使用效率的目的。在标准冷冻电镜基准测试中，与现有顶尖方法相比，GEM训练速度提升48%，内存使用率降低12%，同时局部分辨率提高高达38.8%。本研究表明GEM是一个实用、可伸缩的冷冻电镜重建范式。</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>研究提出一种新的冷冻电子显微镜（cryo-EM）重建框架GEM，结合了实空间方法和神经辐射场（NeRF）的优势。</li>
<li>GEM采用三维高斯拼贴（3DGS）技术，通过紧凑的三维高斯代表蛋白质，减少计算量和内存需求。</li>
<li>GEM设计了一种新颖的梯度计算方法，提高了训练效率。</li>
<li>与现有顶尖方法相比，GEM在标准冷冻电镜基准测试中表现出更高的效率和更高的局部分辨率。</li>
<li>GEM训练速度提升显著，达到最快48%，内存使用效率也得到提升。</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.25075">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic-private.zhihu.com/v2-fa956f22c3340b883943b312c465da53~resize:0:q75.jpg?source=1f5c5e47&expiration=1759930431&auth_key=1759930431-0-0-cecd2418f547b3070b9a7236d7dfc7f2&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://picx.zhimg.com/v2-74b768627ac4f35c3403590f587b28f4.jpg" align="middle">
<img src="https://pic-private.zhihu.com/v2-ef9e5ded2397c81ab2dc9802bb61d4c6~resize:0:q75.jpg?source=1f5c5e47&expiration=1759930445&auth_key=1759930445-0-0-1fbbc87c567b67d2f418592714c36bf4&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pica.zhimg.com/v2-1557ad8b97ce29fc80efc04215960b43.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-4eb0fd7fa9cc595187d1910a39d8a9d1.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="Scalable-GANs-with-Transformers"><a href="#Scalable-GANs-with-Transformers" class="headerlink" title="Scalable GANs with Transformers"></a>Scalable GANs with Transformers</h2><p><strong>Authors:Sangeek Hyun, MinKyu Lee, Jae-Pil Heo</strong></p>
<p>Scalability has driven recent advances in generative modeling, yet its principles remain underexplored for adversarial learning. We investigate the scalability of Generative Adversarial Networks (GANs) through two design choices that have proven to be effective in other types of generative models: training in a compact Variational Autoencoder latent space and adopting purely transformer-based generators and discriminators. Training in latent space enables efficient computation while preserving perceptual fidelity, and this efficiency pairs naturally with plain transformers, whose performance scales with computational budget. Building on these choices, we analyze failure modes that emerge when naively scaling GANs. Specifically, we find issues as underutilization of early layers in the generator and optimization instability as the network scales. Accordingly, we provide simple and scale-friendly solutions as lightweight intermediate supervision and width-aware learning-rate adjustment. Our experiments show that GAT, a purely transformer-based and latent-space GANs, can be easily trained reliably across a wide range of capacities (S through XL). Moreover, GAT-XL&#x2F;2 achieves state-of-the-art single-step, class-conditional generation performance (FID of 2.96) on ImageNet-256 in just 40 epochs, 6x fewer epochs than strong baselines. </p>
<blockquote>
<p>可扩展性推动了生成模型的最新发展，但对于对抗性学习，其原理仍未得到充分探索。我们通过两项在其他类型的生成模型中证明有效的设计选择来研究生成对抗网络（GANs）的可扩展性：在紧凑的变分自动编码器潜在空间中进行训练，并采用纯基于变压器的生成器和鉴别器。在潜在空间中进行训练既提高了计算效率又保持了感知保真度，这种效率与普通的变压器自然地结合在一起，其性能随计算预算而扩展。基于这些选择，我们分析了在简单扩展GAN时出现的失败模式。具体来说，我们发现生成器前几层利用不足以及网络扩展时的优化不稳定等问题。因此，我们提供了简单且适合规模的解决方案，如轻量级中间监督和宽度感知学习率调整。我们的实验表明，GAT是一种纯基于变压器和潜在空间的GANs，可以轻松地跨广泛的能力范围（S到XL）进行可靠训练。此外，GAT-XL&#x2F;2在仅40个周期内就在ImageNet-256上实现了最先进的单步、有条件生成性能（FID为2.96），这是基线模型的六分之一周期。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.24935v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>这篇论文研究了生成对抗网络（GANs）的可扩展性，通过采用其他生成模型证明有效的两种设计选择：在紧凑的变分自动编码器潜在空间中进行训练以及采用纯基于变换器的生成器和鉴别器。论文分析了在扩大GAN规模时出现的失败模式，并提供了简单的可扩展解决方案。实验表明，GAT能够在广泛的容量范围内可靠地进行训练，并在ImageNet-256上实现了最先进的单步类条件生成性能。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>论文探讨了生成对抗网络（GANs）的可扩展性，并分析了其面临的挑战。</li>
<li>通过在变分自动编码器的潜在空间中进行训练，提高了GANs的计算效率和感知保真度。</li>
<li>采用纯基于变换器的生成器和鉴别器，与潜在空间训练相结合，增强了GANs的性能。</li>
<li>在扩大GAN规模时，出现了如生成器早期层利用不足和优化不稳定等问题。</li>
<li>论文提供了针对这些问题的简单且可扩展的解决方案，如轻量级中间监督和宽度感知的学习率调整。</li>
<li>实验表明，GAT在广泛的容量范围内能够可靠地进行训练，并在ImageNet-256上实现了卓越的单步类条件生成性能。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.24935">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-45045c7252a7dc708d1e88f2cdad775e.jpg" align="middle">
<img src="https://pic-private.zhihu.com/v2-678c07cbe18d86649c78535e6657667f~resize:0:q75.jpg?source=1f5c5e47&expiration=1759930472&auth_key=1759930472-0-0-dfb133fc96f7786b923b1eb629d40947&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-eb33326ba6678b4dc89e9fc12bd07bed~resize:0:q75.jpg?source=1f5c5e47&expiration=1759930479&auth_key=1759930479-0-0-b1d6f8bcb8526f234f2838e68567d008&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="OracleGS-Grounding-Generative-Priors-for-Sparse-View-Gaussian-Splatting"><a href="#OracleGS-Grounding-Generative-Priors-for-Sparse-View-Gaussian-Splatting" class="headerlink" title="OracleGS: Grounding Generative Priors for Sparse-View Gaussian Splatting"></a>OracleGS: Grounding Generative Priors for Sparse-View Gaussian Splatting</h2><p><strong>Authors:Atakan Topaloglu, Kunyi Li, Michael Niemeyer, Nassir Navab, A. Murat Tekalp, Federico Tombari</strong></p>
<p>Sparse-view novel view synthesis is fundamentally ill-posed due to severe geometric ambiguity. Current methods are caught in a trade-off: regressive models are geometrically faithful but incomplete, whereas generative models can complete scenes but often introduce structural inconsistencies. We propose OracleGS, a novel framework that reconciles generative completeness with regressive fidelity for sparse view Gaussian Splatting. Instead of using generative models to patch incomplete reconstructions, our “propose-and-validate” framework first leverages a pre-trained 3D-aware diffusion model to synthesize novel views to propose a complete scene. We then repurpose a multi-view stereo (MVS) model as a 3D-aware oracle to validate the 3D uncertainties of generated views, using its attention maps to reveal regions where the generated views are well-supported by multi-view evidence versus where they fall into regions of high uncertainty due to occlusion, lack of texture, or direct inconsistency. This uncertainty signal directly guides the optimization of a 3D Gaussian Splatting model via an uncertainty-weighted loss. Our approach conditions the powerful generative prior on multi-view geometric evidence, filtering hallucinatory artifacts while preserving plausible completions in under-constrained regions, outperforming state-of-the-art methods on datasets including Mip-NeRF 360 and NeRF Synthetic. </p>
<blockquote>
<p>稀疏视角的新视角合成（Novel View Synthesis）因严重的几何模糊性而根本不适定。当前的方法陷入了权衡困境：回归模型在几何上忠实但不完整，而生成模型虽然能完成场景但经常引入结构不一致性。我们提出了OracleGS这一新型框架，旨在调和生成模型的完整性与回归模型的忠实性，用于稀疏视角的高斯拼贴（Gaussian Splatting）。与其他方法不同，我们并不使用生成模型来修复不完整的重建结果，而是采用“提出并验证”的框架。首先，我们利用预训练的3D感知扩散模型（diffusion model）来合成新视角以提出一个完整的场景。然后，我们将多视角立体（MVS）模型重新定位为一个3D感知的验证器，以验证生成视角的3D不确定性，利用其注意力图来揭示哪些区域受到多视角证据的有力支持，以及哪些区域因遮挡、缺乏纹理或直接不一致而陷入高度不确定性的区域。这种不确定性信号直接指导了通过不确定性加权损失优化的3D高斯拼贴模型。我们的方法将强大的生成先验条件与多视角几何证据相结合，在过滤幻觉伪影的同时保留可能完成的无约束区域，在Mip-NeRF 360和NeRF Synthetic等数据集上的表现优于最先进的方法。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.23258v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>本文提出一种名为OracleGS的新框架，旨在解决稀疏视图下的新颖视角合成问题。该方法结合了生成模型的完整性与回归模型的忠实性，采用“提出并验证”的方式，利用预训练的3D感知扩散模型合成新颖视图以提出完整场景，再使用多视角立体（MVS）模型作为3D感知的顾问，验证生成视图的3D不确定性。这种方法利用注意力地图揭示哪些区域的多视角证据支持生成视图，哪些区域因遮挡、缺乏纹理或直接不一致而具有不确定性。这种不确定性信号直接指导了基于3D高斯拼贴模型的不确定性加权损失优化。此方法在包括Mip-NeRF 360和NeRF Synthetic在内的数据集上表现优于其他先进技术。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>OracleGS框架结合了生成模型的完整性与回归模型的忠实性，解决了稀疏视图下的新颖视角合成问题的根本难题。</li>
<li>提出并验证的方法首先利用预训练的3D感知扩散模型合成完整场景的新颖视图。</li>
<li>多视角立体（MVS）模型作为3D感知的顾问，用于验证生成视图的3D不确定性。</li>
<li>注意力地图用于揭示哪些区域的多视角证据支持生成视图，哪些区域存在不确定性。</li>
<li>不确定性信号直接指导了基于3D高斯拼贴模型的不确定性加权损失优化。</li>
<li>该方法利用生成模型的强大先验知识，结合多视角几何证据，能够在过滤掉幻觉伪影的同时，保留在约束不足区域的合理完成。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.23258">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic-private.zhihu.com/v2-1dd8249d1e6922d84b93b320d3f9a5da~resize:0:q75.jpg?source=1f5c5e47&expiration=1759930487&auth_key=1759930487-0-0-27048c2eff548ade010bfef1cf2e03a8&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-21090328a2b5b6ea458ec253a1247bb9~resize:0:q75.jpg?source=1f5c5e47&expiration=1759930495&auth_key=1759930495-0-0-04d81f77c8b348df1930a5ca57c2563b&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-fa794c0d0af6b17a06cafe9084a461a3~resize:0:q75.jpg?source=1f5c5e47&expiration=1759930502&auth_key=1759930502-0-0-f02f0dfde80e7bdd12dff44ad2229023&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-367441bcab795e72f6f6bb0db1f8356a~resize:0:q75.jpg?source=1f5c5e47&expiration=1759930509&auth_key=1759930509-0-0-af480eeeba01dfbbd10ef0f12b1130ed&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://picx.zhimg.com/v2-6ddfa89b953479a371b0872ea4600326.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="Seeing-Isn’t-Believing-Context-Aware-Adversarial-Patch-Synthesis-via-Conditional-GAN"><a href="#Seeing-Isn’t-Believing-Context-Aware-Adversarial-Patch-Synthesis-via-Conditional-GAN" class="headerlink" title="Seeing Isn’t Believing: Context-Aware Adversarial Patch Synthesis via   Conditional GAN"></a>Seeing Isn’t Believing: Context-Aware Adversarial Patch Synthesis via   Conditional GAN</h2><p><strong>Authors:Roie Kazoom, Alon Goldberg, Hodaya Cohen, Ofer Hadar</strong></p>
<p>Adversarial patch attacks pose a severe threat to deep neural networks, yet most existing approaches rely on unrealistic white-box assumptions, untargeted objectives, or produce visually conspicuous patches that limit real-world applicability. In this work, we introduce a novel framework for fully controllable adversarial patch generation, where the attacker can freely choose both the input image x and the target class y target, thereby dictating the exact misclassification outcome. Our method combines a generative U-Net design with Grad-CAM-guided patch placement, enabling semantic-aware localization that maximizes attack effectiveness while preserving visual realism. Extensive experiments across convolutional networks (DenseNet-121, ResNet-50) and vision transformers (ViT-B&#x2F;16, Swin-B&#x2F;16, among others) demonstrate that our approach achieves state-of-the-art performance across all settings, with attack success rates (ASR) and target-class success (TCS) consistently exceeding 99%.   Importantly, we show that our method not only outperforms prior white-box attacks and untargeted baselines, but also surpasses existing non-realistic approaches that produce detectable artifacts. By simultaneously ensuring realism, targeted control, and black-box applicability-the three most challenging dimensions of patch-based attacks-our framework establishes a new benchmark for adversarial robustness research, bridging the gap between theoretical attack strength and practical stealthiness. </p>
<blockquote>
<p>对抗性补丁攻击对深度神经网络构成了严重威胁，但大多数现有方法依赖于不切实际的白色盒子假设、非目标性目标，或产生视觉显著的补丁，限制了其在现实世界中的应用性。在这项工作中，我们引入了一个全新的可控对抗性补丁生成框架，攻击者可以自由选择输入图像x和目标类别y target，从而决定确切的误分类结果。我们的方法结合了生成式U-Net设计和由Grad-CAM引导的补丁放置，实现了语义感知的定位，最大化攻击效果的同时保持视觉真实性。在卷积网络（DenseNet-121、ResNet-50）和视觉转换器（ViT-B&#x2F;16、Swin-B&#x2F;16等）上的广泛实验表明，我们的方法在所有设置中都实现了最先进的性能，攻击成功率（ASR）和目标类别成功率（TCS）均超过99%。重要的是，我们证明我们的方法不仅优于先前的白色盒子攻击和非目标基线，而且超越了现有产生可检测伪影的非现实方法。通过同时确保真实性、目标控制和黑色盒子适用性——补丁攻击的三大最具挑战性的维度，我们的框架为对抗性稳健性研究建立了新的基准，缩小了理论攻击强度与实际隐蔽性之间的差距。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.22836v1">PDF</a> </p>
<p><strong>摘要</strong><br>深度神经网络面临着对抗性补丁攻击的巨大威胁。但现有方法依赖不合理的假设或未涵盖现实攻击场景中特定的目标类别选择。本研究引入了一种全新的可控对抗性补丁生成框架，攻击者可以自由选择输入图像和目标类别，从而精确控制误分类结果。结合生成式U-Net设计和基于Grad-CAM的补丁放置策略，实现了语义感知的定位，在保持视觉真实性的同时最大化攻击效果。实验证明，该方法在所有场景下均表现优异，攻击成功率和目标类别成功率均超过99%。该方法不仅优于先前的白盒攻击和非目标基线，还超越了产生可检测伪影的非现实攻击方法。同时确保现实性、目标控制及黑盒应用的三重挑战为基于补丁的攻击开辟了新方向，为我们的框架建立了新的基准点，弥合了理论攻击强度和实际应用隐秘性之间的差距。</p>
<p><strong>关键见解</strong></p>
<ol>
<li>介绍了对抗性补丁攻击对深度神经网络构成严重威胁的现状。</li>
<li>当前多数方法存在局限性，依赖于白盒假设或缺乏实际应用的现实攻击场景目标类别选择能力。</li>
<li>提出了一种全新的可控对抗性补丁生成框架，能够自由选择输入图像和目标类别，精确控制误分类结果。</li>
<li>结合生成式U-Net设计和Grad-CAM指导的补丁放置策略，实现了攻击效果最大化并保持视觉真实性的能力。</li>
<li>实验证明该方法在所有场景下均表现优异，攻击成功率和目标类别成功率超过99%。</li>
<li>方法优于先前的白盒和非目标基线攻击，并能超越现有产生可检测伪影的非现实攻击方法。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.22836">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic-private.zhihu.com/v2-e626b67d9b24d40afec8ec8bdc84d80b~resize:0:q75.jpg?source=1f5c5e47&expiration=1759930524&auth_key=1759930524-0-0-a62556e3003ae86b040bab01da078f0a&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-06b3ea019e393a36ed3c8a8e3e15dbc5~resize:0:q75.jpg?source=1f5c5e47&expiration=1759930531&auth_key=1759930531-0-0-9f04e3fb12047225c8240b4b1d105b65&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://picx.zhimg.com/v2-c4a7fb7801c37b791246efe37453894b.jpg" align="middle">
<img src="https://pic-private.zhihu.com/v2-667c820d65a6db43089c6964a3602669~resize:0:q75.jpg?source=1f5c5e47&expiration=1759930545&auth_key=1759930545-0-0-10a9537367dbb75089ccd8e9e391175d&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="Advances-in-Feed-Forward-3D-Reconstruction-and-View-Synthesis-A-Survey"><a href="#Advances-in-Feed-Forward-3D-Reconstruction-and-View-Synthesis-A-Survey" class="headerlink" title="Advances in Feed-Forward 3D Reconstruction and View Synthesis: A Survey"></a>Advances in Feed-Forward 3D Reconstruction and View Synthesis: A Survey</h2><p><strong>Authors:Jiahui Zhang, Yuelei Li, Anpei Chen, Muyu Xu, Kunhao Liu, Jianyuan Wang, Xiao-Xiao Long, Hanxue Liang, Zexiang Xu, Hao Su, Christian Theobalt, Christian Rupprecht, Andrea Vedaldi, Kaichen Zhou, Paul Pu Liang, Shijian Lu, Fangneng Zhan</strong></p>
<p>3D reconstruction and view synthesis are foundational problems in computer vision, graphics, and immersive technologies such as augmented reality (AR), virtual reality (VR), and digital twins. Traditional methods rely on computationally intensive iterative optimization in a complex chain, limiting their applicability in real-world scenarios. Recent advances in feed-forward approaches, driven by deep learning, have revolutionized this field by enabling fast and generalizable 3D reconstruction and view synthesis. This survey offers a comprehensive review of feed-forward techniques for 3D reconstruction and view synthesis, with a taxonomy according to the underlying representation architectures including point cloud, 3D Gaussian Splatting (3DGS), Neural Radiance Fields (NeRF), etc. We examine key tasks such as pose-free reconstruction, dynamic 3D reconstruction, and 3D-aware image and video synthesis, highlighting their applications in digital humans, SLAM, robotics, and beyond. In addition, we review commonly used datasets with detailed statistics, along with evaluation protocols for various downstream tasks. We conclude by discussing open research challenges and promising directions for future work, emphasizing the potential of feed-forward approaches to advance the state of the art in 3D vision. </p>
<blockquote>
<p>3D重建和视图合成是计算机视觉、图形学和沉浸式技术（如增强现实AR、虚拟现实VR和数字孪生）中的基础问题。传统方法依赖于复杂链中的计算密集型迭代优化，这在现实场景的应用中存在一定的局限性。最近，以深度学习为驱动的前馈方法的进步，已经彻底改变了这一领域，实现了快速和通用的3D重建和视图合成。这篇综述对前馈技术在3D重建和视图合成方面的应用进行了全面的回顾，并根据基础表示架构进行了分类，包括点云、3D高斯贴片（3DGS）、神经辐射场（NeRF）等。我们研究了姿势无关重建、动态3D重建和3D感知图像和视频合成等关键任务，并强调了它们在数字人类、SLAM、机器人技术等领域的应用。此外，我们还回顾了常用数据集及其详细统计数据，以及用于各种下游任务的评估协议。最后，我们讨论了当前研究的开放挑战和未来工作的有前途的方向，并强调了前馈方法在推动计算机视觉前沿方面的潜力。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2507.14501v3">PDF</a> A project page associated with this survey is available at   <a target="_blank" rel="noopener" href="https://fnzhan.com/projects/Feed-Forward-3D">https://fnzhan.com/projects/Feed-Forward-3D</a></p>
<p><strong>Summary</strong><br>神经网络辐射场（NeRF）等前沿技术为三维重建和视图合成领域带来了革命性的变革。这篇综述全面回顾了基于前馈技术的三维重建和视图合成的研究，从底层结构角度介绍了点云、三维高斯展开等。重点讨论了姿势自由重建、动态三维重建以及用于数字人、SLAM等场景的三维感知图像和视频合成等关键任务。此外，还介绍了常用的数据集和评估协议，并探讨了开放的研究挑战和未来研究方向的潜力。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>前馈技术已改变三维重建和视图合成领域，实现快速通用化。</li>
<li>神经网络辐射场（NeRF）等新技术在此领域有广泛应用。</li>
<li>综述涵盖了包括点云、三维高斯展开在内的多种底层结构。</li>
<li>关键任务包括姿势自由重建、动态三维重建以及三维感知图像和视频合成等。</li>
<li>这些技术在数字人、SLAM、机器人等领域有实际应用。</li>
<li>文章提供了详细的常用数据集和评估协议介绍。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2507.14501">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic-private.zhihu.com/v2-77a63beb68a83dbe0d10b03d98c06c58~resize:0:q75.jpg?source=1f5c5e47&expiration=1759930554&auth_key=1759930554-0-0-09e1aa6f61bf66773856024ddc8ffb91&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pica.zhimg.com/v2-bfe7b9b6f744bafc8db7bcd6687997ed.jpg" align="middle">
<img src="https://pic-private.zhihu.com/v2-a1a060beb79b28f7f67d6aae73d749ba~resize:0:q75.jpg?source=1f5c5e47&expiration=1759930569&auth_key=1759930569-0-0-26b1f2d816045acb2bdbc38b38ee816a&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-d670e872f8768c9521ab7472ea23c260~resize:0:q75.jpg?source=1f5c5e47&expiration=1759930576&auth_key=1759930576-0-0-4ff28478c2702a47431cfd8363c4132e&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://picx.zhimg.com/v2-15de065c4b201fe5fd3c35f7bc69c497.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="PoI-A-Filter-to-Extract-Pixel-of-Interest-from-Novel-View-Synthesis-for-Scene-Coordinate-Regression"><a href="#PoI-A-Filter-to-Extract-Pixel-of-Interest-from-Novel-View-Synthesis-for-Scene-Coordinate-Regression" class="headerlink" title="PoI: A Filter to Extract Pixel of Interest from Novel View Synthesis for   Scene Coordinate Regression"></a>PoI: A Filter to Extract Pixel of Interest from Novel View Synthesis for   Scene Coordinate Regression</h2><p><strong>Authors:Feifei Li, Qi Song, Chi Zhang, Hui Shuai, Rui Huang</strong></p>
<p>Novel View synthesis (NVS) techniques, notably Neural Radiance Fields (NeRF) and 3D Gaussian Splatting (3DGS), can augment camera pose estimation by extending training data with rendered images. However, the images rendered by these methods are often plagued by blurring, undermining their reliability as training data for camera pose estimation. This limitation is particularly critical for Scene Coordinate Regression (SCR) methods, which aim at pixel-level 3D coordinate estimation, because rendering artifacts directly lead to estimation inaccuracies. To address this challenge, we propose a dual-criteria filtering mechanism that dynamically identifies and discards suboptimal pixels during training. The dual-criteria filter evaluates two concurrent metrics: (1) real-time SCR reprojection error, and (2) gradient threshold, across the coordinate regression domain. In addition, for visual localization problems in sparse input scenarios, it will be even more necessary to use data generated by NVS to assist the localization task. We design a coarse-to-fine PoI variant using sparse input NVS to solve this problem. Experiments across indoor and outdoor benchmarks confirm our method’s efficacy. It achieves state-of-the-art localization accuracy while maintaining computational efficiency. </p>
<blockquote>
<p>新型视图合成（NVS）技术，特别是神经辐射场（NeRF）和3D高斯喷涂（3DGS）技术，可以通过使用渲染图像扩展训练数据来增强相机姿态估计。然而，这些方法渲染的图像往往受到模糊的影响，降低了它们作为相机姿态估计训练数据的可靠性。这一局限性对于场景坐标回归（SCR）方法尤为关键，因为SCR方法旨在进行像素级3D坐标估计，而渲染伪影直接导致估计不准确。为了解决这一挑战，我们提出了一种基于双标准的过滤机制，该机制能够在训练过程中动态识别并丢弃次优像素。双标准过滤器评估两个并行指标：（1）实时SCR重投影误差和（2）坐标回归域中的梯度阈值。此外，在稀疏输入的视觉定位问题中，使用NVS生成的数据辅助定位任务将更为必要。我们设计了一种使用稀疏输入NVS的由粗到细的PoI变体来解决这个问题。室内和室外基准测试的实验结果证实了我们的方法的有效性。它在保持计算效率的同时实现了最先进的定位精度。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.04843v4">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>本文介绍了如何利用神经辐射场（NeRF）和三维高斯描影（3DGS）等新型视图合成（NVS）技术增强相机姿态估计。然而，NVS渲染的图像常存在模糊问题，影响了其作为相机姿态估计训练数据的可靠性。针对场景坐标回归（SCR）方法中的这一问题，本文提出了一种基于双重标准的过滤机制，该机制能在训练过程中动态识别并丢弃不符合要求的像素。同时，针对稀疏输入场景下的视觉定位问题，本文设计了一种由粗到细的感兴趣点变体，利用稀疏输入的NVS数据辅助定位任务。实验证明，该方法在室内外基准测试中都取得了卓越的效果，实现了高定位精度与计算效率。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>NVS技术如NeRF和3DGS能增强相机姿态估计，通过扩展训练数据使用渲染图像。</li>
<li>NVS渲染的图像常存在模糊问题，影响作为相机姿态估计训练数据的可靠性。</li>
<li>针对SCR方法，提出了一种基于双重标准的过滤机制，能动态识别并丢弃训练中的不符合要求的像素。</li>
<li>该双重标准包括实时SCR重投影误差和坐标回归域内的梯度阈值。</li>
<li>对于稀疏输入场景下的视觉定位问题，设计了一种利用稀疏输入NVS数据的粗到细PoI变体解决方案。</li>
<li>实验证明该方法在室内外基准测试中实现高定位精度与计算效率。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.04843">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-4085ada383e57ca40ad86b2e077ab791.jpg" align="middle">
<img src="https://pic-private.zhihu.com/v2-77cf7e02c4d0b2c361452fb21a3bd08e~resize:0:q75.jpg?source=1f5c5e47&expiration=1759930597&auth_key=1759930597-0-0-93f1778ef12aded24c9ac56775d694e4&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-986f4980b8d00c18d186c16678604798~resize:0:q75.jpg?source=1f5c5e47&expiration=1759930604&auth_key=1759930604-0-0-59e40ac18a4aa3aa69c78ef9d811568f&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pica.zhimg.com/v2-613f1b53c4bcb69a375ccde5bac6f51f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-8950ff5bbe779c91dee353b39686cae5.jpg" align="middle">
<img src="https://pic-private.zhihu.com/v2-c0997ddf3af0a3159f13ff8d5374aee4~resize:0:q75.jpg?source=1f5c5e47&expiration=1759930623&auth_key=1759930623-0-0-de6eb57873b0c32577386f0db61238be&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        文章作者:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        文章链接:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-10-01/NeRF/">https://kedreamix.github.io/Talk2Paper/Paper/2025-10-01/NeRF/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        版权声明:
                    </i>
                </span>
                <span class="reprint-info">
                    本博客所有文章除特別声明外，均采用
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    许可协议。转载请注明来源
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/NeRF/">
                                    <span class="chip bg-color">NeRF</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;上一篇</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-10-01/Diffusion%20Models/">
                    <div class="card-image">
                        
                        <img src="https://pic-private.zhihu.com/v2-eced55fcc4237184017a848e99237130~resize:0:q75.jpg?source=1f5c5e47&expiration=1759930630&auth_key=1759930630-0-0-9a791dba09b3113af20bd0dc1a470e11&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" class="responsive-img" alt="Diffusion Models">
                        
                        <span class="card-title">Diffusion Models</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Diffusion Models 方向最新论文已更新，请持续关注 Update in 2025-10-01  UniLat3D Geometry-Appearance Unified Latents for Single-Stage 3D   Generation
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-10-01
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Diffusion-Models/" class="post-category">
                                    Diffusion Models
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Diffusion-Models/">
                        <span class="chip bg-color">Diffusion Models</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-10-01/3DGS/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-a64933e04bbd3934c6b99595e92319f6.jpg" class="responsive-img" alt="3DGS">
                        
                        <span class="card-title">3DGS</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            3DGS 方向最新论文已更新，请持续关注 Update in 2025-10-01  Triangle Splatting+ Differentiable Rendering with Opaque Triangles
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-10-01
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/3DGS/" class="post-category">
                                    3DGS
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/3DGS/">
                        <span class="chip bg-color">3DGS</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- 代码语言 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span
                        class="white-color">29997.2k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- 运行天数提醒. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // 区分是否有年份.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = '本站已运行 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                daysTip = '本站已運行 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = '本站已运行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = '本站已運行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="关注我的知乎: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">知</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- 白天和黑夜主题 -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // 只在桌面版网页启用特效
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- 雪花特效 -->
    

    <!-- 鼠标星星特效 -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--腾讯兔小巢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- 动态标签 -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Σ(っ °Д °;)っ诶，页面崩溃了嘛？", clearTimeout(st)) : (document.title = "φ(゜▽゜*)♪咦，又好了！", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
