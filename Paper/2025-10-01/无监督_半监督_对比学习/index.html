<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="æ— ç›‘ç£/åŠç›‘ç£/å¯¹æ¯”å­¦ä¹ ">
    <meta name="description" content="æ— ç›‘ç£/åŠç›‘ç£/å¯¹æ¯”å­¦ä¹  æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-10-01  Vision At Night Exploring Biologically Inspired Preprocessing For   Improved Robustness Via Color And Contrast Transformations">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>æ— ç›‘ç£/åŠç›‘ç£/å¯¹æ¯”å­¦ä¹  | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://picx.zhimg.com/v2-fba12c6bf221a464a43bdf56db8dcbf2.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">æ— ç›‘ç£/åŠç›‘ç£/å¯¹æ¯”å­¦ä¹ </h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/%E6%97%A0%E7%9B%91%E7%9D%A3-%E5%8D%8A%E7%9B%91%E7%9D%A3-%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0/">
                                <span class="chip bg-color">æ— ç›‘ç£/åŠç›‘ç£/å¯¹æ¯”å­¦ä¹ </span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/%E6%97%A0%E7%9B%91%E7%9D%A3-%E5%8D%8A%E7%9B%91%E7%9D%A3-%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0/" class="post-category">
                                æ— ç›‘ç£/åŠç›‘ç£/å¯¹æ¯”å­¦ä¹ 
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-10-01
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-10-18
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    9k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    36 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-10-01-æ›´æ–°"><a href="#2025-10-01-æ›´æ–°" class="headerlink" title="2025-10-01 æ›´æ–°"></a>2025-10-01 æ›´æ–°</h1><h2 id="Vision-At-Night-Exploring-Biologically-Inspired-Preprocessing-For-Improved-Robustness-Via-Color-And-Contrast-Transformations"><a href="#Vision-At-Night-Exploring-Biologically-Inspired-Preprocessing-For-Improved-Robustness-Via-Color-And-Contrast-Transformations" class="headerlink" title="Vision At Night: Exploring Biologically Inspired Preprocessing For   Improved Robustness Via Color And Contrast Transformations"></a>Vision At Night: Exploring Biologically Inspired Preprocessing For   Improved Robustness Via Color And Contrast Transformations</h2><p><strong>Authors:Lorena Stracke, Lia Nimmermann, Shashank Agnihotri, Margret Keuper, Volker Blanz</strong></p>
<p>Inspired by the human visual systemâ€™s mechanisms for contrast enhancement and color-opponency, we explore biologically motivated input preprocessing for robust semantic segmentation. By applying Difference-of-Gaussians (DoG) filtering to RGB, grayscale, and opponent-color channels, we enhance local contrast without modifying model architecture or training. Evaluations on Cityscapes, ACDC, and Dark Zurich show that such preprocessing maintains in-distribution performance while improving robustness to adverse conditions like night, fog, and snow. As this processing is model-agnostic and lightweight, it holds potential for integration into imaging pipelines, enabling imaging systems to deliver task-ready, robust inputs for downstream vision models in safety-critical environments. </p>
<blockquote>
<p>å—äººç±»è§†è§‰ç³»ç»Ÿå¯¹æ¯”å¢å¼ºå’Œé¢œè‰²å¯¹ç«‹æœºåˆ¶çš„å¯å‘ï¼Œæˆ‘ä»¬æ¢ç´¢äº†ç”¨äºç¨³å¥è¯­ä¹‰åˆ†å‰²çš„ç”Ÿç‰©æ¿€åŠ±è¾“å…¥é¢„å¤„ç†ã€‚é€šè¿‡å¯¹RGBã€ç°åº¦å›¾å’Œé¢œè‰²å¯¹ç«‹é€šé“åº”ç”¨é«˜æ–¯å·®åˆ†ï¼ˆDoGï¼‰æ»¤æ³¢ï¼Œæˆ‘ä»¬åœ¨ä¸ä¿®æ”¹æ¨¡å‹æ¶æ„æˆ–è®­ç»ƒçš„æƒ…å†µä¸‹å¢å¼ºäº†å±€éƒ¨å¯¹æ¯”ã€‚åœ¨Cityscapesã€ACDCå’Œé»‘æš—è‹é»ä¸–ä¸Šçš„è¯„ä¼°è¡¨æ˜ï¼Œè¿™ç§é¢„å¤„ç†åœ¨ä¿æŒå†…éƒ¨æ€§èƒ½çš„åŒæ—¶ï¼Œæé«˜äº†å¯¹å¤œé—´ã€é›¾å¤©å’Œé›ªå¤©ç­‰ä¸åˆ©æ¡ä»¶çš„ç¨³å¥æ€§ã€‚ç”±äºè¿™ç§å¤„ç†å…·æœ‰æ¨¡å‹æ— å…³æ€§å’Œè½»é‡åŒ–ç‰¹ç‚¹ï¼Œå› æ­¤æœ‰æ½œåŠ›é›†æˆåˆ°æˆåƒæµæ°´çº¿ä¸­ï¼Œä½¿æˆåƒç³»ç»Ÿèƒ½å¤Ÿä¸ºå®‰å…¨å…³é”®ç¯å¢ƒä¸­çš„ä¸‹æ¸¸è§†è§‰æ¨¡å‹æä¾›ä»»åŠ¡å°±ç»ªçš„ç¨³å¥è¾“å…¥ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.24863v1">PDF</a> Accepted at the ICCV 2025 Workshop on Responsible Imaging</p>
<p><strong>Summary</strong><br>     è¯¥ç ”ç©¶å—äººç±»è§†è§‰ç³»ç»Ÿå¯¹æ¯”å¢å¼ºå’Œé¢œè‰²å¯¹æŠ—æœºåˆ¶çš„å¯å‘ï¼Œæ¢ç´¢äº†ç”¨äºç¨³å¥è¯­ä¹‰åˆ†å‰²çš„ç”Ÿç‰©åŠ¨æœºè¾“å…¥é¢„å¤„ç†ã€‚é€šè¿‡åº”ç”¨Difference-of-Gaussiansï¼ˆDoGï¼‰æ»¤æ³¢å¯¹RGBã€ç°åº¦å›¾å’Œå¯¹æ‰‹è‰²é€šé“è¿›è¡Œå¤„ç†ï¼Œå¯åœ¨ä¸ä¿®æ”¹æ¨¡å‹æ¶æ„æˆ–è®­ç»ƒçš„æƒ…å†µä¸‹å¢å¼ºå±€éƒ¨å¯¹æ¯”ã€‚åœ¨Cityscapesã€ACDCå’ŒDark Zurichä¸Šçš„è¯„ä¼°è¡¨æ˜ï¼Œè¿™ç§é¢„å¤„ç†åœ¨ä¿æŒå†…éƒ¨åˆ†å¸ƒæ€§èƒ½çš„åŒæ—¶ï¼Œæé«˜äº†å¯¹å¤œæ™šã€é›¾å’Œé›ªç­‰ä¸åˆ©æ¡ä»¶çš„é²æ£’æ€§ã€‚è¯¥å¤„ç†å…·æœ‰æ¨¡å‹é€šç”¨æ€§å’Œè½»é‡çº§ç‰¹ç‚¹ï¼Œå…·æœ‰æ½œåŠ›èå…¥æˆåƒæµæ°´çº¿ï¼Œä½¿æˆåƒç³»ç»Ÿä¸ºå®‰å…¨å…³é”®ç¯å¢ƒä¸­çš„ä¸‹æ¸¸è§†è§‰æ¨¡å‹æä¾›ä»»åŠ¡å°±ç»ªçš„ç¨³å¥è¾“å…¥ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ç ”ç©¶å—äººç±»è§†è§‰ç³»ç»Ÿå¯å‘ï¼Œæ¢ç´¢äº†ç”Ÿç‰©åŠ¨æœºè¾“å…¥é¢„å¤„ç†ä»¥å¢å¼ºè¯­ä¹‰åˆ†å‰²çš„ç¨³å¥æ€§ã€‚</li>
<li>åº”ç”¨Difference-of-Gaussiansï¼ˆDoGï¼‰æ»¤æ³¢å¤„ç†å›¾åƒï¼Œå¢å¼ºå±€éƒ¨å¯¹æ¯”ã€‚</li>
<li>å¤„ç†è¿‡ç¨‹ä¸ä¿®æ”¹æ¨¡å‹æ¶æ„æˆ–è®­ç»ƒï¼Œå…·æœ‰é€šç”¨æ€§å’Œè½»é‡çº§ç‰¹ç‚¹ã€‚</li>
<li>è¯„ä¼°æ˜¾ç¤ºï¼Œè¯¥é¢„å¤„ç†åœ¨å¤šç§æ•°æ®é›†ä¸Šæé«˜äº†æ¨¡å‹å¯¹ä¸åˆ©æ¡ä»¶çš„é²æ£’æ€§ã€‚</li>
<li>é¢„å¤„ç†æœ‰åŠ©äºåœ¨ä¿æŒæ€§èƒ½çš„åŒæ—¶ï¼Œæé«˜æ¨¡å‹åœ¨ä¸åŒç¯å¢ƒæ¡ä»¶ä¸‹çš„é€‚ç”¨æ€§ã€‚</li>
<li>è¯¥æ–¹æ³•å…·æœ‰æ½œåŠ›èå…¥æˆåƒæµæ°´çº¿ï¼Œä¸ºä¸‹æ¸¸è§†è§‰æ¨¡å‹æä¾›ä¼˜åŒ–è¾“å…¥ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.24863">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-47bff7eb1509fe4b8bdb165b86225037~resize:0:q75.jpg?source=1f5c5e47&expiration=1759928974&auth_key=1759928974-0-0-08196c98e48f49f14c0cc7edadc1c50a&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic1.zhimg.com/v2-06f393ce506973342167b3bb1baf79fa.jpg" align="middle">
<img src="https://pic-private.zhihu.com/v2-ce4ca412c4921ce809266efbfda007dc~resize:0:q75.jpg?source=1f5c5e47&expiration=1759928987&auth_key=1759928987-0-0-9622cf85c56fd25c55897b6714d16967&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://picx.zhimg.com/v2-e9cf34848dcaa70de9b0769414934eb9.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="An-Efficient-3D-Latent-Diffusion-Model-for-T1-contrast-Enhanced-MRI-Generation"><a href="#An-Efficient-3D-Latent-Diffusion-Model-for-T1-contrast-Enhanced-MRI-Generation" class="headerlink" title="An Efficient 3D Latent Diffusion Model for T1-contrast Enhanced MRI   Generation"></a>An Efficient 3D Latent Diffusion Model for T1-contrast Enhanced MRI   Generation</h2><p><strong>Authors:Zach Eidex, Mojtaba Safari, Jie Ding, Richard Qiu, Justin Roper, David Yu, Hui-Kuo Shu, Zhen Tian, Hui Mao, Xiaofeng Yang</strong></p>
<p>Objective: Gadolinium-based contrast agents (GBCAs) are commonly employed with T1w MRI to enhance lesion visualization but are restricted in patients at risk of nephrogenic systemic fibrosis and variations in GBCA administration can introduce imaging inconsistencies. This study develops an efficient 3D deep-learning framework to generate T1-contrast enhanced images (T1C) from pre-contrast multiparametric MRI. Approach: We propose the 3D latent rectified flow (T1C-RFlow) model for generating high-quality T1C images. First, T1w and T2-FLAIR images are input into a pretrained autoencoder to acquire an efficient latent space representation. A rectified flow diffusion model is then trained in this latent space representation. The T1C-RFlow model was trained on a curated dataset comprised of the BraTS 2024 glioma (GLI; 1480 patients), meningioma (MEN; 1141 patients), and metastases (MET; 1475 patients) datasets. Selected patients were split into train (N&#x3D;2860), validation (N&#x3D;612), and test (N&#x3D;614) sets. Results: Both qualitative and quantitative results demonstrate that the T1C-RFlow model outperforms benchmark 3D models (pix2pix, DDPM, Diffusion Transformers (DiT-3D)) trained in the same latent space. T1C-RFlow achieved the following metrics - GLI: NMSE 0.044 +&#x2F;- 0.047, SSIM 0.935 +&#x2F;- 0.025; MEN: NMSE 0.046 +&#x2F;- 0.029, SSIM 0.937 +&#x2F;- 0.021; MET: NMSE 0.098 +&#x2F;- 0.088, SSIM 0.905 +&#x2F;- 0.082. T1C-RFlow had the best tumor reconstruction performance and significantly faster denoising times (6.9 s&#x2F;volume, 200 steps) than conventional DDPM models in both latent space (37.7s, 1000 steps) and patch-based in image space (4.3 hr&#x2F;volume). Significance: Our proposed method generates synthetic T1C images that closely resemble ground truth T1C in much less time than previous diffusion models. Further development may permit a practical method for contrast-agent-free MRI for brain tumors. </p>
<blockquote>
<p>ç›®æ ‡ï¼šé’†ç±»é€ å½±å‰‚ï¼ˆGBCAsï¼‰å¸¸ä¸T1åŠ æƒMRIä¸€èµ·ä½¿ç”¨ï¼Œä»¥å¢å¼ºç—…å˜çš„å¯è§æ€§ï¼Œä½†å…¶åœ¨æœ‰å‘ç”Ÿè‚¾æºæ€§ç³»ç»Ÿæ€§çº¤ç»´åŒ–é£é™©çš„æ‚£è€…ä¸­å—åˆ°é™åˆ¶ï¼Œå¹¶ä¸”GBCAç®¡ç†çš„å˜åŒ–å¯èƒ½ä¼šå¼•å…¥æˆåƒä¸ä¸€è‡´æ€§ã€‚æœ¬ç ”ç©¶å¼€å‘äº†ä¸€ç§é«˜æ•ˆçš„3Dæ·±åº¦å­¦ä¹ æ¡†æ¶ï¼Œç”¨äºä»é¢„é€ å½±å¤šå‚æ•°MRIç”ŸæˆT1åŠ æƒé€ å½±å¢å¼ºå›¾åƒï¼ˆT1Cï¼‰ã€‚æ–¹æ³•ï¼šæˆ‘ä»¬æå‡ºäº†ç”¨äºç”Ÿæˆé«˜è´¨é‡T1Cå›¾åƒçš„3Dæ½œåœ¨æ ¡æ­£æµï¼ˆT1C-RFlowï¼‰æ¨¡å‹ã€‚é¦–å…ˆï¼Œå°†T1åŠ æƒå’ŒT2-FLAIRå›¾åƒè¾“å…¥é¢„è®­ç»ƒçš„è‡ªç¼–ç å™¨ï¼Œä»¥è·å¾—æœ‰æ•ˆçš„æ½œåœ¨ç©ºé—´è¡¨ç¤ºã€‚ç„¶ååœ¨æ­¤æ½œåœ¨ç©ºé—´è¡¨ç¤ºä¸­è®­ç»ƒæ ¡æ­£æµæ‰©æ•£æ¨¡å‹ã€‚T1C-RFlowæ¨¡å‹æ˜¯åœ¨ç²¾é€‰æ•°æ®é›†ä¸Šè®­ç»ƒçš„ï¼Œè¯¥æ•°æ®é›†åŒ…å«BraTS 2024èƒ¶è´¨ç»†èƒç˜¤ï¼ˆGLIï¼›1480ä¾‹æ‚£è€…ï¼‰ã€è„‘è†œç˜¤ï¼ˆMENï¼›1141ä¾‹æ‚£è€…ï¼‰å’Œè½¬ç§»ç˜¤ï¼ˆMETï¼›1475ä¾‹æ‚£è€…ï¼‰æ•°æ®é›†ã€‚å°†é€‰å®šæ‚£è€…åˆ†ä¸ºè®­ç»ƒç»„ï¼ˆN&#x3D;2860ï¼‰ã€éªŒè¯ç»„ï¼ˆN&#x3D;612ï¼‰å’Œæµ‹è¯•ç»„ï¼ˆN&#x3D;614ï¼‰ã€‚ç»“æœï¼šå®šæ€§å’Œå®šé‡ç»“æœå‡è¡¨æ˜ï¼ŒT1C-RFlowæ¨¡å‹åœ¨ç›¸åŒçš„æ½œåœ¨ç©ºé—´ä¸­è¶…è¶Šäº†åŸºå‡†3Dæ¨¡å‹ï¼ˆpix2pixã€DDPMã€Diffusion Transformersï¼ˆDiT-3Dï¼‰ï¼‰çš„è¡¨ç°ã€‚åœ¨GLIä¸­ï¼ŒT1C-RFlowå®ç°äº†ä»¥ä¸‹æŒ‡æ ‡ï¼šNMSE 0.044Â±0.047ï¼ŒSSIM 0.935Â±0.025ï¼›åœ¨MENä¸­ï¼šNMSE 0.046Â±0.029ï¼ŒSSIM 0.937Â±0.021ï¼›åœ¨METä¸­ï¼šNMSE 0.098Â±0.088ï¼ŒSSIM 0.905Â±0.082ã€‚T1C-RFlowå…·æœ‰æœ€ä½³çš„è‚¿ç˜¤é‡å»ºæ€§èƒ½ï¼Œå¹¶ä¸”å»å™ªæ—¶é—´æ˜¾è‘—æ›´å¿«ï¼ˆ6.9ç§’&#x2F;ä½“ç§¯ï¼Œ200æ­¥ï¼‰ï¼Œä¸ä¼ ç»Ÿçš„æ½œåœ¨ç©ºé—´DDPMæ¨¡å‹ï¼ˆ37.7ç§’ï¼Œ1000æ­¥ï¼‰å’ŒåŸºäºå›¾åƒçš„å›¾åƒç©ºé—´è¡¥ä¸ï¼ˆ4.3å°æ—¶&#x2F;ä½“ç§¯ï¼‰ç›¸æ¯”ã€‚æ„ä¹‰ï¼šæˆ‘ä»¬æå‡ºçš„æ–¹æ³•èƒ½å¤Ÿåœ¨æ¯”ä»¥å‰çš„æ‰©æ•£æ¨¡å‹å°‘å¾—å¤šçš„æ—¶é—´å†…ç”Ÿæˆæ¨¡æ‹ŸçœŸå®T1Cçš„T1Cå›¾åƒã€‚è¿›ä¸€æ­¥çš„å¼€å‘å¯èƒ½ä¼šæä¾›ä¸€ç§æ— éœ€é€ å½±å‰‚çš„è„‘éƒ¨è‚¿ç˜¤MRIæ£€æµ‹æ–¹æ³•ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.24194v1">PDF</a> </p>
<p><strong>æ‘˜è¦</strong></p>
<p>æœ¬ç ”ç©¶å¼€å‘äº†ä¸€ç§é«˜æ•ˆçš„3Dæ·±åº¦å­¦ä¹ æ¡†æ¶ï¼Œç”¨äºä»é¢„å¯¹æ¯”çš„å¤šå‚æ•°MRIç”ŸæˆT1å¯¹æ¯”å¢å¼ºå›¾åƒï¼ˆT1Cï¼‰ã€‚è¯¥ç ”ç©¶ä½¿ç”¨T1åŠ æƒå’ŒT2æµæ¶²å€’ç½®æ¢å¤å›¾åƒè¾“å…¥é¢„è®­ç»ƒçš„è‡ªç¼–ç å™¨ï¼Œè·å–æœ‰æ•ˆçš„æ½œåœ¨ç©ºé—´è¡¨ç¤ºã€‚åœ¨æ­¤æ½œåœ¨ç©ºé—´è¡¨ç¤ºä¸­è®­ç»ƒäº†æ ¡æ­£æµæ‰©æ•£æ¨¡å‹ã€‚è¯¥æ¨¡å‹åœ¨åŒ…æ‹¬èƒ¶è´¨ç»†èƒç˜¤ã€è„‘è†œç˜¤å’Œè½¬ç§»ç˜¤çš„æ•°æ®é›†ä¸Šè¿›è¡Œè®­ç»ƒï¼Œå¹¶åœ¨è¿™äº›ç–¾ç—…ä¸­è¡¨ç°å‡ºä¼˜å¼‚çš„æ€§èƒ½ã€‚ä¸åœ¨åŒä¸€æ½œåœ¨ç©ºé—´ä¸­è®­ç»ƒçš„åŸºå‡†3Dæ¨¡å‹ç›¸æ¯”ï¼ŒT1C-RFlowæ¨¡å‹å…·æœ‰æ›´é«˜çš„æ€§èƒ½ï¼Œå¹¶ä¸”è‚¿ç˜¤é‡å»ºæ€§èƒ½æœ€ä½³ï¼Œå»å™ªæ—¶é—´æ˜¾è‘—æ›´å¿«ã€‚æœ¬ç ”ç©¶ä¸ºç”ŸæˆåˆæˆT1Cå›¾åƒæä¾›äº†ä¸€ç§æ–°æ–¹æ³•ï¼Œè¿™äº›å›¾åƒåœ¨æ—¶é—´ä¸Šæ›´æ¥è¿‘äºçœŸå®T1Cï¼Œä¸ºæœªæ¥å®ç°æ— é€ å½±å‰‚MRIæä¾›äº†å¯èƒ½ã€‚</p>
<p><strong>å…³é”®è§è§£</strong></p>
<ol>
<li>ç ”ç©¶æå‡ºäº†ä¸€ç§åä¸ºT1C-RFlowçš„3Dæ·±åº¦å­¦ä¹ æ¡†æ¶ï¼Œç”¨äºä»é¢„å¯¹æ¯”çš„å¤šå‚æ•°MRIç”ŸæˆT1å¯¹æ¯”å¢å¼ºå›¾åƒï¼ˆT1Cï¼‰ã€‚</li>
<li>è¯¥æ¡†æ¶ä½¿ç”¨è‡ªç¼–ç å™¨å’Œæ ¡æ­£æµæ‰©æ•£æ¨¡å‹ï¼Œåœ¨æ½œåœ¨ç©ºé—´è¡¨ç¤ºä¸­ç”Ÿæˆé«˜è´¨é‡çš„T1Cå›¾åƒã€‚</li>
<li>T1C-RFlowåœ¨å¤šç§ç±»å‹çš„è„‘éƒ¨è‚¿ç˜¤æ•°æ®é›†ä¸Šè¿›è¡Œäº†è®­ç»ƒå¹¶è¡¨ç°å‡ºè‰¯å¥½çš„æ€§èƒ½ã€‚</li>
<li>T1C-RFlowæ¨¡å‹ç›¸è¾ƒäºå…¶ä»–åœ¨ç›¸åŒæ½œåœ¨ç©ºé—´ä¸­è®­ç»ƒçš„æ¨¡å‹æœ‰æ›´å¥½çš„æ€§èƒ½è¡¨ç°ã€‚</li>
<li>T1C-RFlowæ¨¡å‹çš„è‚¿ç˜¤é‡å»ºæ€§èƒ½æœ€ä½³ï¼Œå»å™ªæ—¶é—´æ˜¾è‘—æ›´å¿«ã€‚</li>
<li>è¯¥ç ”ç©¶ä¸ºæ— é€ å½±å‰‚MRIçš„å®ç°æä¾›äº†å¯èƒ½ï¼Œä¸ºæœªæ¥çš„åŒ»å­¦æˆåƒæŠ€æœ¯æä¾›äº†æ–°çš„è§†è§’ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.24194">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-3444a172b2cea0585f06be75ed38e0da.jpg" align="middle">
<img src="https://pic-private.zhihu.com/v2-dbabea21c0f0464f457481cca0dec9fd~resize:0:q75.jpg?source=1f5c5e47&expiration=1759929009&auth_key=1759929009-0-0-e4424a9b515effa98a858ce063c75229&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="A-Modality-Tailored-Graph-Modeling-Framework-for-Urban-Region-Representation-via-Contrastive-Learning"><a href="#A-Modality-Tailored-Graph-Modeling-Framework-for-Urban-Region-Representation-via-Contrastive-Learning" class="headerlink" title="A Modality-Tailored Graph Modeling Framework for Urban Region   Representation via Contrastive Learning"></a>A Modality-Tailored Graph Modeling Framework for Urban Region   Representation via Contrastive Learning</h2><p><strong>Authors:Yaya Zhao, Kaiqi Zhao, Zixuan Tang, Zhiyuan Liu, Xiaoling Lu, Yalei Du</strong></p>
<p>Graph-based models have emerged as a powerful paradigm for modeling multimodal urban data and learning region representations for various downstream tasks. However, existing approaches face two major limitations. (1) They typically employ identical graph neural network architectures across all modalities, failing to capture modality-specific structures and characteristics. (2) During the fusion stage, they often neglect spatial heterogeneity by assuming that the aggregation weights of different modalities remain invariant across regions, resulting in suboptimal representations. To address these issues, we propose MTGRR, a modality-tailored graph modeling framework for urban region representation, built upon a multimodal dataset comprising point of interest (POI), taxi mobility, land use, road element, remote sensing, and street view images. (1) MTGRR categorizes modalities into two groups based on spatial density and data characteristics: aggregated-level and point-level modalities. For aggregated-level modalities, MTGRR employs a mixture-of-experts (MoE) graph architecture, where each modality is processed by a dedicated expert GNN to capture distinct modality-specific characteristics. For the point-level modality, a dual-level GNN is constructed to extract fine-grained visual semantic features. (2) To obtain effective region representations under spatial heterogeneity, a spatially-aware multimodal fusion mechanism is designed to dynamically infer region-specific modality fusion weights. Building on this graph modeling framework, MTGRR further employs a joint contrastive learning strategy that integrates region aggregated-level, point-level, and fusion-level objectives to optimize region representations. Experiments on two real-world datasets across six modalities and three tasks demonstrate that MTGRR consistently outperforms state-of-the-art baselines, validating its effectiveness. </p>
<blockquote>
<p>åŸºäºå›¾æ¨¡å‹çš„æ¡†æ¶å·²æˆä¸ºå¤„ç†å¤šæ¨¡æ€åŸå¸‚æ•°æ®çš„æœ‰åŠ›å·¥å…·ï¼Œå¹¶èƒ½å¤Ÿç”¨äºå­¦ä¹ åŒºåŸŸè¡¨ç¤ºä¸ºå¤šç§ä¸‹æ¸¸ä»»åŠ¡æä¾›æœåŠ¡ã€‚ç„¶è€Œï¼Œç°æœ‰æ–¹æ³•é¢ä¸´ä¸¤å¤§å±€é™ã€‚ï¼ˆ1ï¼‰å®ƒä»¬é€šå¸¸ä½¿ç”¨æ‰€æœ‰æ¨¡æ€çš„ç›¸åŒå›¾ç¥ç»ç½‘ç»œæ¶æ„ï¼Œæ— æ³•æ•æ‰æ¨¡æ€ç‰¹å®šçš„ç»“æ„å’Œç‰¹å¾ã€‚ï¼ˆ2ï¼‰åœ¨èåˆé˜¶æ®µï¼Œå®ƒä»¬å¾€å¾€ä¼šå¿½ç•¥ç©ºé—´å¼‚è´¨æ€§ï¼Œå‡è®¾ä¸åŒæ¨¡æ€çš„èšåˆæƒé‡åœ¨å„ä¸ªåŒºåŸŸä¿æŒä¸å˜ï¼Œä»è€Œå¯¼è‡´æ¬¡ä¼˜è¡¨ç¤ºã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†MTGRRï¼Œè¿™æ˜¯ä¸€ç§é’ˆå¯¹åŸå¸‚åŒºåŸŸè¡¨ç¤ºçš„æ¨¡æ€å®šåˆ¶çš„å›¾å»ºæ¨¡æ¡†æ¶ï¼Œå»ºç«‹åœ¨åŒ…å«å…´è¶£ç‚¹ï¼ˆPOIï¼‰ã€å‡ºç§Ÿè½¦æµåŠ¨æ€§ã€åœŸåœ°åˆ©ç”¨ã€é“è·¯å…ƒç´ ã€é¥æ„Ÿå’Œè¡—é“è§†å›¾å›¾åƒçš„å¤šæ¨¡æ€æ•°æ®é›†ä¹‹ä¸Šã€‚ï¼ˆ1ï¼‰MTGRRæ ¹æ®ç©ºé—´å¯†åº¦å’Œæ•°æ®ç‰¹æ€§å°†æ¨¡æ€åˆ†ä¸ºä¸¤ç»„ï¼šèšåˆçº§å’Œç‚¹çº§æ¨¡æ€ã€‚å¯¹äºèšåˆçº§æ¨¡æ€ï¼ŒMTGRRé‡‡ç”¨æ··åˆä¸“å®¶ï¼ˆMoEï¼‰å›¾æ¶æ„ï¼Œå…¶ä¸­æ¯ä¸ªæ¨¡æ€ç”±ä¸“é—¨çš„ä¸“å®¶GNNå¤„ç†ä»¥æ•è·ä¸åŒçš„æ¨¡æ€ç‰¹å®šç‰¹å¾ã€‚å¯¹äºç‚¹çº§æ¨¡æ€ï¼Œæ„å»ºåŒçº§GNNä»¥æå–ç²¾ç»†ç²’åº¦çš„è§†è§‰è¯­ä¹‰ç‰¹å¾ã€‚ï¼ˆ2ï¼‰ä¸ºäº†åœ¨ç©ºé—´å¼‚è´¨æ€§ä¸‹è·å¾—æœ‰æ•ˆçš„åŒºåŸŸè¡¨ç¤ºï¼Œè®¾è®¡äº†ä¸€ç§ç©ºé—´æ„ŸçŸ¥çš„å¤šæ¨¡æ€èåˆæœºåˆ¶ï¼Œä»¥åŠ¨æ€æ¨æ–­ç‰¹å®šåŒºåŸŸçš„æ¨¡æ€èåˆæƒé‡ã€‚åŸºäºè¿™ä¸ªå›¾å»ºæ¨¡æ¡†æ¶ï¼ŒMTGRRè¿›ä¸€æ­¥é‡‡ç”¨è”åˆå¯¹æ¯”å­¦ä¹ ç­–ç•¥ï¼Œè¯¥ç­–ç•¥ç»“åˆäº†åŒºåŸŸèšåˆçº§ã€ç‚¹çº§å’Œèåˆçº§ç›®æ ‡æ¥ä¼˜åŒ–åŒºåŸŸè¡¨ç¤ºã€‚åœ¨ä¸¤ä¸ªçœŸå®ä¸–ç•Œæ•°æ®é›†ä¸Šçš„å®éªŒè¯æ˜äº†MTGRRåœ¨å…­ä¸ªæ¨¡æ€å’Œä¸‰ä¸ªä»»åŠ¡ä¸Šå§‹ç»ˆä¼˜äºæœ€æ–°åŸºçº¿ï¼ŒéªŒè¯äº†å…¶æœ‰æ•ˆæ€§ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.23772v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ç§é’ˆå¯¹åŸå¸‚åŒºåŸŸè¡¨ç¤ºçš„æ¨¡æ€å®šåˆ¶å›¾å»ºæ¨¡æ¡†æ¶MTGRRï¼Œç”¨äºå¤„ç†å¤šæ¨¡æ€åŸå¸‚æ•°æ®ã€‚è¯¥æ¡†æ¶è§£å†³äº†ç°æœ‰æ–¹æ³•çš„ä¸¤å¤§å±€é™æ€§ï¼šä¸€æ˜¯æœªèƒ½æ•æ‰æ¨¡æ€ç‰¹å®šç»“æ„å’Œç‰¹æ€§ï¼ŒäºŒæ˜¯åœ¨èåˆé˜¶æ®µå¿½ç•¥äº†ç©ºé—´å¼‚è´¨æ€§ã€‚MTGRRåˆ©ç”¨ä¸“é—¨çš„å›¾ç¥ç»ç½‘ç»œæ¶æ„æ•æ‰ä¸åŒæ¨¡æ€çš„ç‰¹æ€§ï¼Œå¹¶è®¾è®¡äº†ä¸€ç§ç©ºé—´æ„ŸçŸ¥çš„å¤šæ¨¡æ€èåˆæœºåˆ¶ï¼Œä»¥è·å–æœ‰æ•ˆçš„åŒºåŸŸè¡¨ç¤ºã€‚é€šè¿‡è”åˆå¯¹æ¯”å­¦ä¹ ç­–ç•¥ä¼˜åŒ–åŒºåŸŸè¡¨ç¤ºï¼Œå®éªŒè¯æ˜MTGRRåœ¨çœŸå®ä¸–ç•Œæ•°æ®é›†ä¸Šçš„è¡¨ç°ä¼˜äºæœ€æ–°åŸºçº¿ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ç°æœ‰å›¾æ¨¡å‹åœ¨å¤„ç†å¤šæ¨¡æ€åŸå¸‚æ•°æ®æ—¶é¢ä¸´ä¸¤å¤§æŒ‘æˆ˜ï¼šç¼ºä¹æ¨¡æ€ç‰¹å®šç»“æ„ç‰¹æ€§çš„æ•æ‰å’Œåœ¨èåˆé˜¶æ®µå¿½ç•¥ç©ºé—´å¼‚è´¨æ€§ã€‚</li>
<li>MTGRRæ¡†æ¶é€šè¿‡å¯¹æ¨¡æ€è¿›è¡Œåˆ†ç±»ï¼Œä½¿ç”¨ä¸“é—¨çš„å›¾ç¥ç»ç½‘ç»œæ¶æ„æ¥æ•æ‰ä¸åŒæ¨¡æ€çš„ç‰¹æ€§ã€‚</li>
<li>å¯¹äºèšåˆçº§åˆ«çš„æ¨¡æ€ï¼ŒMTGRRé‡‡ç”¨æ··åˆä¸“å®¶å›¾æ¶æ„ï¼Œæ¯ä¸ªæ¨¡æ€ç”±ä¸“é—¨çš„ä¸“å®¶GNNå¤„ç†ï¼Œä»¥æ•æ‰ä¸åŒçš„æ¨¡æ€ç‰¹æ€§ã€‚</li>
<li>å¯¹äºç‚¹çº§åˆ«æ¨¡æ€ï¼ŒMTGRRæ„å»ºäº†åŒçº§åˆ«GNNä»¥æå–ç²¾ç»†çš„è§†è§‰è¯­ä¹‰ç‰¹å¾ã€‚</li>
<li>MTGRRè®¾è®¡äº†ä¸€ç§ç©ºé—´æ„ŸçŸ¥çš„å¤šæ¨¡æ€èåˆæœºåˆ¶ï¼Œä»¥è·å–æœ‰æ•ˆçš„åŒºåŸŸè¡¨ç¤ºï¼Œè¯¥æœºåˆ¶å¯ä»¥åŠ¨æ€æ¨æ–­ç‰¹å®šåŒºåŸŸçš„æ¨¡æ€èåˆæƒé‡ã€‚</li>
<li>MTGRRé‡‡ç”¨è”åˆå¯¹æ¯”å­¦ä¹ ç­–ç•¥ï¼Œç»“åˆåŒºåŸŸèšåˆçº§åˆ«ã€ç‚¹çº§åˆ«å’Œèåˆçº§åˆ«çš„ç›®æ ‡æ¥ä¼˜åŒ–åŒºåŸŸè¡¨ç¤ºã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.23772">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-d033cf4a3b8fb034af1c2489c7926f71~resize:0:q75.jpg?source=1f5c5e47&expiration=1759929016&auth_key=1759929016-0-0-1bc623e999034604b16b867c0e335427&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-20817ae07959a683a99ca554be8739b0~resize:0:q75.jpg?source=1f5c5e47&expiration=1759929024&auth_key=1759929024-0-0-a884a16ef6f5e0c76122ab1938efe8d0&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://picx.zhimg.com/v2-2b410e03aed638e428749cf321c4b92f.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="GenView-Unifying-Adaptive-View-Generation-and-Quality-Driven-Supervision-for-Contrastive-Representation-Learning"><a href="#GenView-Unifying-Adaptive-View-Generation-and-Quality-Driven-Supervision-for-Contrastive-Representation-Learning" class="headerlink" title="GenView++: Unifying Adaptive View Generation and Quality-Driven   Supervision for Contrastive Representation Learning"></a>GenView++: Unifying Adaptive View Generation and Quality-Driven   Supervision for Contrastive Representation Learning</h2><p><strong>Authors:Xiaojie Li, Bei Wang, Jianlong Wu, Yue Yu, Liqiang Nie, Min Zhang</strong></p>
<p>The success of contrastive learning depends on the construction and utilization of high-quality positive pairs. However, current methods face critical limitations on two fronts: on the construction side, both handcrafted and generative augmentations often suffer from limited diversity and risk semantic corruption; on the learning side, the absence of a quality assessment mechanism leads to suboptimal supervision where all pairs are treated equally. To tackle these challenges, we propose GenView++, a unified framework that addresses both fronts by introducing two synergistic innovations. To improve pair construction, GenView++ introduces a multi-source adaptive view generation mechanism to synthesize diverse yet semantically coherent views by dynamically modulating generative parameters across image-conditioned, text-conditioned, and image-text-conditioned strategies. Second, a quality-driven contrastive learning mechanism assesses each pairâ€™s semantic alignment and diversity to dynamically reweight their training contribution, prioritizing high-quality pairs while suppressing redundant or misaligned pairs. Extensive experiments demonstrate the effectiveness of GenView++ across both vision and vision-language tasks. For vision representation learning, it improves MoCov2 by +2.5% on ImageNet linear classification. For vision-language learning, it raises the average zero-shot classification accuracy by +12.31% over CLIP and +5.31% over SLIP across ten datasets, and further improves Flickr30k text retrieval R@5 by +3.2%. The code is available at <a target="_blank" rel="noopener" href="https://github.com/xiaojieli0903/GenViewPlusPlus">https://github.com/xiaojieli0903/GenViewPlusPlus</a>. </p>
<blockquote>
<p>å¯¹æ¯”å­¦ä¹ çš„æˆåŠŸå–å†³äºé«˜è´¨é‡æ­£å¯¹çš„æ„å»ºå’Œåˆ©ç”¨ã€‚ç„¶è€Œï¼Œå½“å‰çš„æ–¹æ³•åœ¨ä¸¤ä¸ªæ–¹é¢éƒ½é¢ä¸´ç€å…³é”®çš„å±€é™æ€§ï¼šåœ¨æ„å»ºæ–¹é¢ï¼Œæ‰‹å·¥åˆ¶ä½œå’Œç”Ÿæˆå¼å¢å¼ºé€šå¸¸å—é™äºæœ‰é™çš„å¤šæ ·æ€§ï¼Œå¹¶å­˜åœ¨è¯­ä¹‰æŸåçš„é£é™©ï¼›åœ¨å­¦ä¹ æ–¹é¢ï¼Œç”±äºç¼ºä¹è´¨é‡è¯„ä¼°æœºåˆ¶ï¼Œæ‰€æœ‰å¯¹éƒ½è¢«å¹³ç­‰å¯¹å¾…ï¼Œå¯¼è‡´ç›‘ç£æ•ˆæœä¸ä½³ã€‚ä¸ºäº†è§£å†³è¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†GenView++ï¼Œè¿™æ˜¯ä¸€ä¸ªé€šè¿‡å¼•å…¥ä¸¤é¡¹ååŒåˆ›æ–°æ¥è§£å†³è¿™äº›é—®é¢˜çš„ç»Ÿä¸€æ¡†æ¶ã€‚ä¸ºæé«˜é…å¯¹æ„å»ºï¼ŒGenView++å¼•å…¥äº†ä¸€ç§å¤šæºè‡ªé€‚åº”è§†å›¾ç”Ÿæˆæœºåˆ¶ï¼Œé€šè¿‡åŠ¨æ€è°ƒåˆ¶å›¾åƒæ¡ä»¶ã€æ–‡æœ¬æ¡ä»¶å’Œå›¾åƒæ–‡æœ¬æ··åˆæ¡ä»¶ä¸‹çš„ç”Ÿæˆå‚æ•°ï¼Œåˆæˆå¤šæ ·ä½†è¯­ä¹‰è¿è´¯çš„è§†å›¾ã€‚å…¶æ¬¡ï¼Œè´¨é‡é©±åŠ¨å¯¹æ¯”å­¦ä¹ æœºåˆ¶è¯„ä¼°æ¯å¯¹è¯­ä¹‰å¯¹é½å’Œå¤šæ ·æ€§ï¼Œä»¥åŠ¨æ€è°ƒæ•´å…¶è®­ç»ƒè´¡çŒ®çš„æƒé‡ï¼Œä¼˜å…ˆé«˜è´¨é‡é…å¯¹ï¼ŒåŒæ—¶æŠ‘åˆ¶å†—ä½™æˆ–é”™ä½é…å¯¹ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼ŒGenView++åœ¨è§†è§‰å’Œè§†è§‰è¯­è¨€ä»»åŠ¡ä¸­å‡æœ‰æ•ˆã€‚åœ¨è§†è§‰è¡¨ç¤ºå­¦ä¹ ä¸­ï¼Œå®ƒåœ¨ImageNetçº¿æ€§åˆ†ç±»ä¸Šæé«˜äº†MoCov2çš„æ€§èƒ½+2.5%ã€‚åœ¨è§†è§‰è¯­è¨€å­¦ä¹ ä¸­ï¼Œä¸CLIPç›¸æ¯”æé«˜äº†é›¶æ ·æœ¬åˆ†ç±»å¹³å‡å‡†ç¡®åº¦+12.31%ï¼Œä¸SLIPç›¸æ¯”æé«˜äº†+5.31%ï¼Œè·¨åä¸ªæ•°æ®é›†ï¼›åŒæ—¶æé«˜äº†Flickr30kæ–‡æœ¬æ£€ç´¢çš„R@5æŒ‡æ ‡+3.2%ã€‚ä»£ç å¯ç”¨åœ¨<a target="_blank" rel="noopener" href="https://github.com/xiaojieli0903/GenViewPlusPlus%E3%80%82">https://github.com/xiaojieli0903/GenViewPlusPlusã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.23770v1">PDF</a> The code is available at   \url{<a target="_blank" rel="noopener" href="https://github.com/xiaojieli0903/GenViewPlusPlus%7D">https://github.com/xiaojieli0903/GenViewPlusPlus}</a></p>
<p><strong>Summary</strong></p>
<p>è¯¥è®ºæ–‡æ¢è®¨äº†å¯¹æ¯”å­¦ä¹ ä¸­é«˜è´¨é‡æ­£æ ·æœ¬å¯¹çš„é‡è¦æ€§åŠå…¶æ„å»ºå’Œåˆ©ç”¨çš„æŒ‘æˆ˜ã€‚é’ˆå¯¹å½“å‰æ–¹æ³•çš„å±€é™æ€§ï¼Œæå‡ºäº†ä¸€ç§åä¸ºGenView++çš„ç»Ÿä¸€æ¡†æ¶ï¼Œé€šè¿‡ä¸¤é¡¹ååŒåˆ›æ–°æ¥è§£å†³è¿™äº›é—®é¢˜ã€‚ä¸€æ˜¯æ”¹è¿›å¯¹æ ·æœ¬å¯¹çš„æ„å»ºï¼Œé€šè¿‡å¤šæºè‡ªé€‚åº”è§†å›¾ç”Ÿæˆæœºåˆ¶ï¼ŒåŠ¨æ€è°ƒæ•´ç”Ÿæˆå‚æ•°ï¼Œåˆæˆå¤šæ ·ä¸”è¯­ä¹‰è¿è´¯çš„è§†å›¾ï¼›äºŒæ˜¯å¼•å…¥è´¨é‡é©±åŠ¨å¯¹æ¯”å­¦ä¹ æœºåˆ¶ï¼Œæ ¹æ®æ¯å¯¹æ ·æœ¬çš„è¯­ä¹‰å¯¹é½ç¨‹åº¦å’Œå¤šæ ·æ€§æ¥åŠ¨æ€è°ƒæ•´è®­ç»ƒè´¡çŒ®çš„æƒé‡ï¼Œä¼˜å…ˆé«˜è´¨é‡æ ·æœ¬å¯¹ï¼ŒæŠ‘åˆ¶å†—ä½™æˆ–è¯¯å¯¹é½æ ·æœ¬å¯¹ã€‚å®éªŒè¡¨æ˜ï¼ŒGenView++åœ¨è§†è§‰å’Œè§†è§‰è¯­è¨€ä»»åŠ¡ä¸­éƒ½å–å¾—äº†æ˜¾è‘—æ•ˆæœã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¯¹æ¯”å­¦ä¹ çš„æˆåŠŸå–å†³äºé«˜è´¨é‡æ­£æ ·æœ¬å¯¹çš„æ„å»ºå’Œåˆ©ç”¨ã€‚</li>
<li>å½“å‰æ–¹æ³•åœ¨æ ·æœ¬å¯¹æ„å»ºå’Œå­¦ä¹ æ–¹é¢å­˜åœ¨å±€é™æ€§ã€‚</li>
<li>GenView++é€šè¿‡ä¸¤é¡¹ååŒåˆ›æ–°è§£å†³è¿™äº›é—®é¢˜ï¼šæ”¹è¿›æ ·æœ¬å¯¹æ„å»ºå’Œæé«˜å­¦ä¹ è´¨é‡ã€‚</li>
<li>GenView++é‡‡ç”¨å¤šæºè‡ªé€‚åº”è§†å›¾ç”Ÿæˆæœºåˆ¶ï¼Œåˆæˆå¤šæ ·ä¸”è¯­ä¹‰è¿è´¯çš„è§†å›¾ã€‚</li>
<li>GenView++é€šè¿‡è´¨é‡é©±åŠ¨å¯¹æ¯”å­¦ä¹ æœºåˆ¶ï¼Œä¼˜å…ˆé«˜è´¨é‡æ ·æœ¬å¯¹ï¼ŒæŠ‘åˆ¶å†—ä½™æˆ–è¯¯å¯¹é½æ ·æœ¬å¯¹ã€‚</li>
<li>GenView++åœ¨è§†è§‰å’Œè§†è§‰è¯­è¨€ä»»åŠ¡ä¸­å–å¾—äº†æ˜¾è‘—æ•ˆæœï¼Œå¦‚MoCov2åœ¨ImageNetä¸Šçš„çº¿æ€§åˆ†ç±»æé«˜äº†+2.5%ï¼ŒCLIPå’ŒSLIPåœ¨å¤šä¸ªæ•°æ®é›†ä¸Šçš„é›¶å°„å‡»åˆ†ç±»å‡†ç¡®ç‡åˆ†åˆ«æé«˜äº†+12.31%å’Œ+5.31%ï¼ŒFlickr30kæ–‡æœ¬æ£€ç´¢R@5æé«˜äº†+3.2%ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.23770">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-bba62e609720766c10f86677926b3439.jpg" align="middle">
<img src="https://pic-private.zhihu.com/v2-fba12c6bf221a464a43bdf56db8dcbf2~resize:0:q75.jpg?source=1f5c5e47&expiration=1759929048&auth_key=1759929048-0-0-4da600e5dde52abb18335484310128dd&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-730f34286895d806f4ae61a4b70395d3~resize:0:q75.jpg?source=1f5c5e47&expiration=1759929055&auth_key=1759929055-0-0-1428cf62473889652aaffd81c78314bf&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://picx.zhimg.com/v2-4bcf83faedf74898861267fb294e6221.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="CCD-Mitigating-Hallucinations-in-Radiology-MLLMs-via-Clinical-Contrastive-Decoding"><a href="#CCD-Mitigating-Hallucinations-in-Radiology-MLLMs-via-Clinical-Contrastive-Decoding" class="headerlink" title="CCD: Mitigating Hallucinations in Radiology MLLMs via Clinical   Contrastive Decoding"></a>CCD: Mitigating Hallucinations in Radiology MLLMs via Clinical   Contrastive Decoding</h2><p><strong>Authors:Xi Zhang, Zaiqiao Meng, Jake Lever, Edmond S. L. Ho</strong></p>
<p>Multimodal large language models (MLLMs) have recently achieved remarkable progress in radiology by integrating visual perception with natural language understanding. However, they often generate clinically unsupported descriptions, known as medical hallucinations, which pose serious risks in medical applications that demand accuracy and image-grounded outputs. Through empirical analysis, we find that prompt-induced hallucinations remain prevalent in radiology MLLMs, largely due to over-sensitivity to clinical sections. To address this, we introduce Clinical Contrastive Cecoding (CCD), a training-free and retrieval-free inference framework that integrates structured clinical signals from task-specific radiology expert models. CCD introduces a dual-stage contrastive mechanism to refine token-level logits during generation, thereby enhancing clinical fidelity without modifying the base MLLM. Experiments on three datasets and multiple models demonstrate that CCD consistently improves overall performance on radiology report generation (RRG). On the MIMIC-CXR dataset, it yields up to a 17% improvement in RadGraph-F1 when applied to state-of-the-art RRG models. Our approach provides a lightweight and generalisable solution for mitigating medical hallucinations, effectively bridging expert models and MLLMs in radiology. </p>
<blockquote>
<p>å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰æœ€è¿‘é€šè¿‡æ•´åˆè§†è§‰æ„ŸçŸ¥ä¸è‡ªç„¶è¯­è¨€ç†è§£åœ¨æ”¾å°„å­¦é¢†åŸŸå–å¾—äº†æ˜¾è‘—è¿›å±•ã€‚ç„¶è€Œï¼Œå®ƒä»¬ç»å¸¸äº§ç”Ÿä¸´åºŠä¸Šä¸æ”¯æŒçš„æè¿°ï¼Œè¢«ç§°ä¸ºåŒ»å­¦å¹»è§‰ï¼Œè¿™åœ¨éœ€è¦å‡†ç¡®æ€§å’Œå›¾åƒåŸºç¡€è¾“å‡ºçš„åŒ»å­¦åº”ç”¨ä¸­å¸¦æ¥äº†ä¸¥é‡çš„é£é™©ã€‚é€šè¿‡å®è¯åˆ†æï¼Œæˆ‘ä»¬å‘ç°æç¤ºè¯±å¯¼çš„å¹»è§‰åœ¨æ”¾å°„å­¦MLLMä¸­ä»ç„¶æ™®éå­˜åœ¨ï¼Œä¸»è¦æ˜¯ç”±äºå¯¹ä¸´åºŠéƒ¨åˆ†çš„è¿‡åº¦æ•æ„Ÿã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸´åºŠå¯¹æ¯”ç¼–ç ï¼ˆCCDï¼‰ï¼Œè¿™æ˜¯ä¸€ç§æ— éœ€è®­ç»ƒå’Œæ£€ç´¢çš„æ¨ç†æ¡†æ¶ï¼Œå®ƒæ•´åˆäº†ç‰¹å®šä»»åŠ¡æ”¾å°„å­¦ä¸“å®¶æ¨¡å‹çš„ç»“æ„åŒ–ä¸´åºŠä¿¡å·ã€‚CCDå¼•å…¥äº†ä¸€ç§åŒé˜¶æ®µå¯¹æ¯”æœºåˆ¶ï¼Œåœ¨ç”Ÿæˆè¿‡ç¨‹ä¸­ç»†åŒ–ä»¤ç‰Œçº§åˆ«çš„é€»è¾‘ï¼Œä»è€Œæé«˜ä¸´åºŠä¿çœŸåº¦ï¼Œè€Œä¸ä¼šä¿®æ”¹åŸºç¡€MLLMã€‚åœ¨ä¸‰ä¸ªæ•°æ®é›†å’Œå¤šä¸ªæ¨¡å‹ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒCCDåœ¨æ”¾å°„å­¦æŠ¥å‘Šç”Ÿæˆï¼ˆRRGï¼‰æ–¹é¢å§‹ç»ˆæé«˜æ€»ä½“æ€§èƒ½ã€‚åœ¨MIMIC-CXRæ•°æ®é›†ä¸Šï¼Œå½“åº”ç”¨äºæœ€å…ˆè¿›çš„RRGæ¨¡å‹æ—¶ï¼Œå®ƒåœ¨RadGraph-F1ä¸Šæé«˜äº†é«˜è¾¾17%ã€‚æˆ‘ä»¬çš„æ–¹æ³•æä¾›äº†ä¸€ç§è½»ä¾¿ä¸”é€šç”¨çš„è§£å†³æ–¹æ¡ˆæ¥ç¼“è§£åŒ»å­¦å¹»è§‰é—®é¢˜ï¼Œæœ‰æ•ˆåœ°æ¡¥æ¥äº†ä¸“å®¶æ¨¡å‹å’ŒMLLMåœ¨æ”¾å°„å­¦é¢†åŸŸçš„åº”ç”¨ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.23379v1">PDF</a> Preprint</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰åœ¨æ”¾å°„å­¦é¢†åŸŸçš„æœ€æ–°è¿›å±•ï¼Œå®ƒä»¬é€šè¿‡èåˆè§†è§‰æ„ŸçŸ¥å’Œè‡ªç„¶è¯­è¨€ç†è§£å–å¾—äº†æ˜¾è‘—æˆæ•ˆã€‚ç„¶è€Œï¼ŒMLLMså¸¸å¸¸äº§ç”Ÿæœªç»ä¸´åºŠæ”¯æŒçš„æè¿°ï¼Œå³æ‰€è°“çš„åŒ»å­¦å¹»è§‰ï¼Œè¿™åœ¨éœ€è¦ç²¾ç¡®æ€§å’Œå›¾åƒåŸºç¡€è¾“å‡ºçš„åŒ»å­¦åº”ç”¨ä¸­å¸¦æ¥äº†ä¸¥é‡é£é™©ã€‚ç ”ç©¶å‘ç°ï¼Œæç¤ºè¯±å¯¼çš„å¹»è§‰åœ¨æ”¾å°„å­¦MLLMsä¸­æ™®éå­˜åœ¨ï¼Œä¸»è¦æ˜¯ç”±äºå¯¹ä¸´åºŠéƒ¨åˆ†çš„è¿‡åº¦æ•æ„Ÿã€‚ä¸ºè§£å†³è¿™ä¸€é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†ä¸´åºŠå¯¹æ¯”ç¼–ç ï¼ˆCCDï¼‰æŠ€æœ¯ï¼Œè¿™æ˜¯ä¸€ç§æ— éœ€è®­ç»ƒå’Œæ£€ç´¢çš„æ¨æ–­æ¡†æ¶ï¼Œå®ƒæ•´åˆäº†æ¥è‡ªç‰¹å®šä»»åŠ¡æ”¾å°„å­¦ä¸“å®¶æ¨¡å‹çš„ç»“æ„åŒ–ä¸´åºŠä¿¡å·ã€‚CCDå¼•å…¥äº†ä¸€ç§åŒé˜¶æ®µå¯¹æ¯”æœºåˆ¶ï¼Œåœ¨ç”Ÿæˆè¿‡ç¨‹ä¸­ä¼˜åŒ–ä»¤ç‰Œçº§åˆ«çš„é€»è¾‘ï¼Œä»è€Œæé«˜ä¸´åºŠä¿çœŸåº¦ï¼ŒåŒæ—¶ä¸ä¿®æ”¹åŸºç¡€MLLMã€‚å®éªŒè¡¨æ˜ï¼ŒCCDåœ¨æ”¾å°„å­¦æŠ¥å‘Šç”Ÿæˆæ–¹é¢è¡¨ç°ä¼˜å¼‚ï¼Œç‰¹åˆ«æ˜¯åœ¨MIMIC-CXRæ•°æ®é›†ä¸Šåº”ç”¨æœ€å…ˆè¿›çš„RRGæ¨¡å‹æ—¶ï¼ŒRadGraph-F1å¾—åˆ†æé«˜äº†17%ã€‚è¯¥æ–¹æ³•ä¸ºç¼“è§£åŒ»å­¦å¹»è§‰é—®é¢˜æä¾›äº†ä¸€ç§è½»ä¾¿ä¸”é€šç”¨çš„è§£å†³æ–¹æ¡ˆï¼Œæœ‰æ•ˆåœ°æ¶èµ·äº†ä¸“å®¶æ¨¡å‹å’ŒMLLMsä¹‹é—´çš„æ¡¥æ¢ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰åœ¨æ”¾å°„å­¦é¢†åŸŸé€šè¿‡èåˆè§†è§‰æ„ŸçŸ¥å’Œè‡ªç„¶è¯­è¨€ç†è§£å–å¾—äº†è¿›å±•ã€‚</li>
<li>MLLMså¸¸äº§ç”Ÿæœªç»ä¸´åºŠæ”¯æŒçš„æè¿°ï¼ˆåŒ»å­¦å¹»è§‰ï¼‰ï¼Œå­˜åœ¨ä¸´åºŠé£é™©ã€‚</li>
<li>åŒ»å­¦å¹»è§‰åœ¨æ”¾å°„å­¦MLLMsä¸­æ™®éå­˜åœ¨çš„åŸå› æ˜¯è¿‡åº¦æ•æ„Ÿäºä¸´åºŠéƒ¨åˆ†ã€‚</li>
<li>ä¸ºè§£å†³ä¸Šè¿°é—®é¢˜ï¼Œæå‡ºäº†ä¸´åºŠå¯¹æ¯”ç¼–ç ï¼ˆCCDï¼‰æŠ€æœ¯ã€‚</li>
<li>CCDæ˜¯ä¸€ç§æ— éœ€è®­ç»ƒå’Œæ£€ç´¢çš„æ¨æ–­æ¡†æ¶ï¼Œæ•´åˆäº†ç‰¹å®šä»»åŠ¡æ”¾å°„å­¦ä¸“å®¶æ¨¡å‹çš„ç»“æ„åŒ–ä¸´åºŠä¿¡å·ã€‚</li>
<li>CCDé€šè¿‡åŒé˜¶æ®µå¯¹æ¯”æœºåˆ¶ä¼˜åŒ–ç”Ÿæˆè¿‡ç¨‹ä¸­çš„ä»¤ç‰Œçº§åˆ«é€»è¾‘ï¼Œæé«˜ä¸´åºŠä¿çœŸåº¦ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.23379">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-37875193aa0b2021b77baebf70a1d78c~resize:0:q75.jpg?source=1f5c5e47&expiration=1759929070&auth_key=1759929070-0-0-5f31cc381d9c48e86fc8e6f79456d33a&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic1.zhimg.com/v2-3412e7b58bfccebaa5bc45f58e0bd04c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-0d2c1c62f194a8d3cd92f88de510f6d0.jpg" align="middle">
<img src="https://pic-private.zhihu.com/v2-93aa9c93345d9824f91974d4dc0cf83b~resize:0:q75.jpg?source=1f5c5e47&expiration=1759929091&auth_key=1759929091-0-0-18eeb472219afa7a88b6dcf6673565c1&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="Benchmarking-DINOv3-for-Multi-Task-Stroke-Analysis-on-Non-Contrast-CT"><a href="#Benchmarking-DINOv3-for-Multi-Task-Stroke-Analysis-on-Non-Contrast-CT" class="headerlink" title="Benchmarking DINOv3 for Multi-Task Stroke Analysis on Non-Contrast CT"></a>Benchmarking DINOv3 for Multi-Task Stroke Analysis on Non-Contrast CT</h2><p><strong>Authors:Donghao Zhang, Yimin Chen, KauÃª TN Duarte, Taha Aslan, Mohamed AlShamrani, Brij Karmur, Yan Wan, Shengcai Chen, Bo Hu, Bijoy K Menon, Wu Qiu</strong></p>
<p>Non-contrast computed tomography (NCCT) is essential for rapid stroke diagnosis but is limited by low image contrast and signal to noise ratio. We address this challenge by leveraging DINOv3, a state-of-the-art self-supervised vision transformer, to generate powerful feature representations for a comprehensive set of stroke analysis tasks. Our evaluation encompasses infarct and hemorrhage segmentation, anomaly classification (normal vs. stroke and normal vs. infarct vs. hemorrhage), hemorrhage subtype classification (EDH, SDH, SAH, IPH, IVH), and dichotomized ASPECTS classification (&lt;&#x3D;6 vs. &gt;6) on multiple public and private datasets. This study establishes strong benchmarks for these tasks and demonstrates the potential of advanced self-supervised models to improve automated stroke diagnosis from NCCT, providing a clear analysis of both the advantages and current constraints of the approach. The code is available at <a target="_blank" rel="noopener" href="https://github.com/Zzz0251/DINOv3-stroke">https://github.com/Zzz0251/DINOv3-stroke</a>. </p>
<blockquote>
<p>éå¯¹æ¯”è®¡ç®—æœºæ–­å±‚æ‰«æï¼ˆNCCTï¼‰å¯¹äºå¿«é€Ÿä¸­é£è¯Šæ–­è‡³å…³é‡è¦ï¼Œä½†ç”±äºå›¾åƒå¯¹æ¯”åº¦å’Œä¿¡å™ªæ¯”ä½è€Œå—åˆ°é™åˆ¶ã€‚æˆ‘ä»¬é€šè¿‡åˆ©ç”¨æœ€å…ˆè¿›çš„è‡ªç›‘ç£è§†è§‰è½¬æ¢å™¨DINOv3æ¥è§£å†³è¿™ä¸€æŒ‘æˆ˜ï¼Œä¸ºä¸€ç³»åˆ—ä¸­é£åˆ†æä»»åŠ¡ç”Ÿæˆå¼ºå¤§çš„ç‰¹å¾è¡¨ç¤ºã€‚æˆ‘ä»¬çš„è¯„ä¼°æ¶µç›–äº†æ¢—æ­»å’Œå‡ºè¡€åˆ†å‰²ã€å¼‚å¸¸åˆ†ç±»ï¼ˆæ­£å¸¸ä¸ä¸­é£ã€æ­£å¸¸ä¸æ¢—æ­»ä¸å‡ºè¡€ï¼‰ã€å‡ºè¡€äºšå‹åˆ†ç±»ï¼ˆEDHã€SDHã€SAHã€IPHã€IVHï¼‰ï¼Œä»¥åŠåœ¨å¤šä¸ªå…¬å…±å’Œç§æœ‰æ•°æ®é›†ä¸Šè¿›è¡ŒäºŒåˆ†åŒ–çš„ASPECTSåˆ†ç±»ï¼ˆ&lt;&#x3D;6ä¸&gt;6ï¼‰ã€‚æœ¬ç ”ç©¶ä¸ºè¿™äº›ä»»åŠ¡å»ºç«‹äº†å¼ºå¤§çš„åŸºå‡†æµ‹è¯•ï¼Œè¯æ˜äº†å…ˆè¿›çš„è‡ªç›‘ç£æ¨¡å‹åœ¨æé«˜éå¯¹æ¯”è®¡ç®—æœºæ–­å±‚æ‰«æï¼ˆNCCTï¼‰è‡ªåŠ¨åŒ–ä¸­é£è¯Šæ–­æ–¹é¢çš„æ½œåŠ›ï¼ŒåŒæ—¶æä¾›äº†è¯¥æ–¹æ³•çš„ä¼˜åŠ¿å’Œå½“å‰å±€é™æ€§çš„æ¸…æ™°åˆ†æã€‚ä»£ç å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/Zzz0251/DINOv3-stroke%E8%8E%B7%E5%8F%96%E3%80%82">https://github.com/Zzz0251/DINOv3-strokeè·å–ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.23132v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>åŸºäºéå¯¹æ¯”è®¡ç®—å±‚ææˆåƒï¼ˆNCCTï¼‰åœ¨å¿«é€Ÿå’ä¸­è¯Šæ–­ä¸­çš„é‡è¦æ€§ï¼Œä½†å—é™äºå›¾åƒå¯¹æ¯”åº¦å’Œä¿¡å™ªæ¯”çš„é—®é¢˜ï¼Œç ”ç©¶å›¢é˜Ÿåˆ©ç”¨å…ˆè¿›çš„è‡ªç›‘ç£è§†è§‰è½¬æ¢å™¨DINOv3ç”Ÿæˆå¼ºå¤§çš„ç‰¹å¾è¡¨ç¤ºï¼Œä»¥è§£å†³è¿™ä¸€é—®é¢˜ã€‚è¯¥ç ”ç©¶åœ¨æ¢—æ­»ã€å‡ºè¡€åˆ†å‰²ã€å¼‚å¸¸åˆ†ç±»ï¼ˆæ­£å¸¸ä¸å’ä¸­ã€æ­£å¸¸ä¸æ¢—æ­»ä¸å‡ºè¡€ï¼‰ã€å‡ºè¡€äºšå‹åˆ†ç±»ï¼ˆEDHã€SDHã€SAHã€IPHã€IVHï¼‰ä»¥åŠåˆ†çº§çš„ASPECTSåˆ†ç±»ï¼ˆ&lt;&#x3D;6ä¸&gt; 6ï¼‰ç­‰å¤šä¸ªå…¬å…±å’Œç§æœ‰æ•°æ®é›†ä¸Šè¿›è¡Œäº†è¯„ä¼°ã€‚ç ”ç©¶ç¡®ç«‹äº†å¼ºæœ‰åŠ›çš„åŸºå‡†çº¿ï¼Œè¯æ˜äº†å…ˆè¿›çš„è‡ªç›‘ç£æ¨¡å‹åœ¨æé«˜NCCTè‡ªåŠ¨åŒ–å’ä¸­è¯Šæ–­æ–¹é¢çš„æ½œåŠ›ï¼Œå¹¶å¯¹è¯¥æ–¹æ³•çš„ä¼˜ç‚¹å’Œå½“å‰é™åˆ¶è¿›è¡Œäº†æ¸…æ™°åˆ†æã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>éå¯¹æ¯”è®¡ç®—å±‚ææˆåƒï¼ˆNCCTï¼‰åœ¨å¿«é€Ÿå’ä¸­è¯Šæ–­ä¸­æ‰®æ¼”é‡è¦è§’è‰²ï¼Œä½†å­˜åœ¨å›¾åƒå¯¹æ¯”åº¦å’Œä¿¡å™ªæ¯”çš„é—®é¢˜ã€‚</li>
<li>ç ”ç©¶ä½¿ç”¨DINOv3è¿™ä¸€å…ˆè¿›çš„è‡ªç›‘ç£è§†è§‰è½¬æ¢å™¨æ¥è§£å†³ä¸Šè¿°é—®é¢˜ï¼Œç”Ÿæˆå¼ºå¤§çš„ç‰¹å¾è¡¨ç¤ºã€‚</li>
<li>ç ”ç©¶æ¶µç›–äº†æ¢—æ­»å’Œå‡ºè¡€åˆ†å‰²ã€å¼‚å¸¸åˆ†ç±»ã€å‡ºè¡€äºšå‹åˆ†ç±»ç­‰å¤šä¸ªå’ä¸­åˆ†æä»»åŠ¡ã€‚</li>
<li>åœ¨å¤šä¸ªå…¬å…±å’Œç§æœ‰æ•°æ®é›†ä¸Šè¿›è¡Œäº†è¯„ä¼°ï¼Œç¡®ç«‹äº†å¼ºæœ‰åŠ›çš„åŸºå‡†çº¿ã€‚</li>
<li>å…ˆè¿›è‡ªç›‘ç£æ¨¡å‹åœ¨æ”¹å–„NCCTè‡ªåŠ¨åŒ–å’ä¸­è¯Šæ–­æ–¹é¢çš„æ½œåŠ›å¾—åˆ°äº†éªŒè¯ã€‚</li>
<li>ç ”ç©¶æä¾›äº†å…³äºè¯¥æ–¹æ³•çš„ä¼˜ç‚¹å’Œé™åˆ¶çš„æ¸…æ™°åˆ†æã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.23132">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-f826d3c1ebf8dd1236c94fb2c8711b1a~resize:0:q75.jpg?source=1f5c5e47&expiration=1759929098&auth_key=1759929098-0-0-8ca1b1f2f6e1a7aa4d06c024812d759c&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-767558bf210a2c44c02461d9508ec07f~resize:0:q75.jpg?source=1f5c5e47&expiration=1759929105&auth_key=1759929105-0-0-0d2974683af7ea10149931e46fe162b1&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-978a2955f5aad223db43ae52e33d009a~resize:0:q75.jpg?source=1f5c5e47&expiration=1759929112&auth_key=1759929112-0-0-a427911aedcdd5242edc2eddc08a60c1&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="A-Survey-on-Self-supervised-Contrastive-Learning-for-Multimodal-Text-Image-Analysis"><a href="#A-Survey-on-Self-supervised-Contrastive-Learning-for-Multimodal-Text-Image-Analysis" class="headerlink" title="A Survey on Self-supervised Contrastive Learning for Multimodal   Text-Image Analysis"></a>A Survey on Self-supervised Contrastive Learning for Multimodal   Text-Image Analysis</h2><p><strong>Authors:Asifullah Khan, Laiba Asmatullah, Anza Malik, Shahzaib Khan, Hamna Asif</strong></p>
<p>Self-supervised learning is a machine learning approach that generates implicit labels by learning underlined patterns and extracting discriminative features from unlabeled data without manual labelling. Contrastive learning introduces the concept of â€œpositiveâ€ and â€œnegativeâ€ samples, where positive pairs (e.g., variation of the same image&#x2F;object) are brought together in the embedding space, and negative pairs (e.g., views from different images&#x2F;objects) are pushed farther away. This methodology has shown significant improvements in image understanding and image text analysis without much reliance on labeled data. In this paper, we comprehensively discuss the terminologies, recent developments and applications of contrastive learning with respect to text-image models. Specifically, we provide an overview of the approaches of contrastive learning in text-image models in recent years. Secondly, we categorize the approaches based on different model structures. Thirdly, we further introduce and discuss the latest advances of the techniques used in the process such as pretext tasks for both images and text, architectural structures, and key trends. Lastly, we discuss the recent state-of-art applications of self-supervised contrastive learning Text-Image based models. </p>
<blockquote>
<p>è‡ªç›‘ç£å­¦ä¹ æ˜¯ä¸€ç§æœºå™¨å­¦ä¹ çš„æ–¹æ³•ï¼Œå®ƒé€šè¿‡å­¦ä¹ å’Œè¯†åˆ«æ½œåœ¨çš„æ¨¡å¼ï¼Œå¹¶ä»æ— æ ‡ç­¾çš„æ•°æ®ä¸­æå–è¾¨åˆ«ç‰¹å¾ï¼Œç”Ÿæˆéšå«çš„æ ‡ç­¾ï¼Œæ— éœ€äººå·¥æ ‡æ³¨ã€‚å¯¹æ¯”å­¦ä¹ å¼•å…¥äº†â€œæ­£æ ·æœ¬â€å’Œâ€œè´Ÿæ ·æœ¬â€çš„æ¦‚å¿µï¼Œå…¶ä¸­æ­£æ ·æœ¬å¯¹ï¼ˆä¾‹å¦‚ï¼ŒåŒä¸€å›¾åƒ&#x2F;å¯¹è±¡çš„å˜ä½“ï¼‰è¢«æ±‡é›†åˆ°åµŒå…¥ç©ºé—´ä¸­ï¼Œè€Œè´Ÿæ ·æœ¬å¯¹ï¼ˆä¾‹å¦‚ï¼Œæ¥è‡ªä¸åŒå›¾åƒ&#x2F;å¯¹è±¡çš„è§†å›¾ï¼‰åˆ™è¢«æ¨å¼€å¾—æ›´è¿œã€‚è¿™ç§æ–¹æ³•åœ¨å›¾åƒç†è§£å’Œå›¾åƒæ–‡æœ¬åˆ†ææ–¹é¢å–å¾—äº†æ˜¾è‘—çš„æ”¹è¿›ï¼Œæ— éœ€å¤§é‡ä¾èµ–æ ‡è®°æ•°æ®ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬å…¨é¢æ¢è®¨äº†ä¸æ–‡æœ¬å›¾åƒæ¨¡å‹ç›¸å…³çš„å¯¹æ¯”å­¦ä¹ çš„æœ¯è¯­ã€æœ€æ–°å‘å±•ä»¥åŠåº”ç”¨ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬æ¦‚è¿°äº†è¿‘å¹´æ¥æ–‡æœ¬å›¾åƒæ¨¡å‹ä¸­å¯¹æ¯”å­¦ä¹ çš„æ–¹æ³•ã€‚å…¶æ¬¡ï¼Œæˆ‘ä»¬æ ¹æ®ä¸åŒçš„æ¨¡å‹ç»“æ„å¯¹è¿™äº›æ–¹æ³•è¿›è¡Œäº†åˆ†ç±»ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜è¿›ä¸€æ­¥ä»‹ç»äº†å¯¹æ¯”å­¦ä¹ è¿‡ç¨‹ä¸­çš„æœ€æ–°æŠ€æœ¯è¿›å±•ï¼Œå¦‚å›¾åƒå’Œæ–‡æœ¬çš„é¢„è®­ç»ƒä»»åŠ¡ã€æ¶æ„ç»“æ„å’Œå…³é”®è¶‹åŠ¿ã€‚æœ€åï¼Œæˆ‘ä»¬è®¨è®ºäº†åŸºäºæ–‡æœ¬å›¾åƒçš„æœ€æ–°å…ˆè¿›çš„è‡ªç›‘ç£å¯¹æ¯”å­¦ä¹ çš„åº”ç”¨ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.11101v4">PDF</a> 38 pages, 8 figures, survey paper</p>
<p><strong>Summary</strong><br>è‡ªæˆ‘ç›‘ç£å­¦ä¹ æ˜¯ä¸€ç§æœºå™¨å­¦ä¹ çš„æ–¹æ³•ï¼Œé€šè¿‡éšå¼æ ‡ç­¾ç”Ÿæˆå­¦ä¹ åº•å±‚æ¨¡å¼å¹¶ä»æ— æ ‡ç­¾æ•°æ®ä¸­æå–åˆ¤åˆ«ç‰¹å¾ï¼Œæ— éœ€æ‰‹åŠ¨æ ‡æ³¨ã€‚å¯¹æ¯”å­¦ä¹ å¼•å…¥äº†â€œæ­£æ ·æœ¬â€å’Œâ€œè´Ÿæ ·æœ¬â€çš„æ¦‚å¿µï¼Œé€šè¿‡å°†åŒä¸€å›¾åƒæˆ–å¯¹è±¡çš„ä¸åŒå˜åŒ–ä½œä¸ºæ­£æ ·æœ¬åœ¨åµŒå…¥ç©ºé—´ä¸­èšåˆï¼Œè€Œå°†ä¸åŒå›¾åƒæˆ–å¯¹è±¡çš„è§†å›¾ä½œä¸ºè´Ÿæ ·æœ¬æ¨å¼€ï¼Œå–å¾—äº†æ˜¾è‘—æˆæ•ˆã€‚æœ¬æ–‡å…¨é¢æ¢è®¨äº†å¯¹æ¯”å­¦ä¹ çš„æœ¯è¯­ã€æœ€æ–°è¿›å±•åŠå…¶åœ¨æ–‡æœ¬å›¾åƒæ¨¡å‹ä¸­çš„åº”ç”¨ã€‚æ–‡ç« æ¦‚è¿°äº†è¿‘å¹´æ¥çš„æ–‡æœ¬å›¾åƒæ¨¡å‹å¯¹æ¯”å­¦ä¹ æ–¹æ³•ï¼ŒæŒ‰æ¨¡å‹ç»“æ„åˆ†ç±»ï¼Œå¹¶ä»‹ç»äº†æœ€æ–°çš„æŠ€æœ¯è¿›å±•ï¼Œå¦‚å›¾åƒå’Œæ–‡æœ¬çš„é¢„è®­ç»ƒä»»åŠ¡ã€æ¶æ„ç»“æ„å’Œå…³é”®è¶‹åŠ¿ç­‰ã€‚æœ€åè®¨è®ºäº†åŸºäºæ–‡æœ¬å›¾åƒçš„è‡ªæˆ‘ç›‘ç£å¯¹æ¯”å­¦ä¹ çš„æœ€æ–°åº”ç”¨ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>è‡ªæˆ‘ç›‘ç£å­¦ä¹ é€šè¿‡éšå¼æ ‡ç­¾å­¦ä¹ åº•å±‚æ¨¡å¼å¹¶ä»æ— æ ‡ç­¾æ•°æ®ä¸­æå–åˆ¤åˆ«ç‰¹å¾ã€‚</li>
<li>å¯¹æ¯”å­¦ä¹ æ˜¯è‡ªæˆ‘ç›‘ç£å­¦ä¹ çš„ä¸€ç§å½¢å¼ï¼Œå¼•å…¥æ­£æ ·æœ¬å’Œè´Ÿæ ·æœ¬çš„æ¦‚å¿µï¼Œä»¥æå‡å­¦ä¹ æ•ˆæœã€‚</li>
<li>æ­£æ ·æœ¬æŒ‡çš„æ˜¯åŒä¸€å›¾åƒæˆ–å¯¹è±¡çš„ä¸åŒå˜åŒ–ï¼Œåœ¨åµŒå…¥ç©ºé—´ä¸­èšåˆï¼›è´Ÿæ ·æœ¬åˆ™æ˜¯ä¸åŒå›¾åƒæˆ–å¯¹è±¡çš„è§†å›¾ï¼Œè¢«æ¨å¼€ã€‚</li>
<li>å¯¹æ¯”å­¦ä¹ æ–¹æ³•åœ¨å›¾åƒç†è§£å’Œæ–‡æœ¬åˆ†ææ–¹é¢è¡¨ç°å‡ºæ˜¾è‘—çš„æ”¹è¿›ï¼Œå‡å°‘äº†å¯¹æ ‡æ³¨æ•°æ®çš„ä¾èµ–ã€‚</li>
<li>æ–‡ç« æä¾›äº†å…³äºæ–‡æœ¬å›¾åƒæ¨¡å‹å¯¹æ¯”å­¦ä¹ çš„å…¨é¢æ¦‚è¿°ï¼ŒåŒ…æ‹¬è¿‘å¹´æ¥çš„æ–¹æ³•å’ŒæŒ‰æ¨¡å‹ç»“æ„çš„åˆ†ç±»ã€‚</li>
<li>ä»‹ç»äº†æœ€æ–°çš„æŠ€æœ¯è¿›å±•ï¼ŒåŒ…æ‹¬å›¾åƒå’Œæ–‡æœ¬çš„é¢„è®­ç»ƒä»»åŠ¡ã€æ¶æ„ç»“æ„å’Œå…³é”®è¶‹åŠ¿ç­‰ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.11101">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-35b9b4a11f71855bba70d7517f93a159.jpg" align="middle">
<img src="https://pic-private.zhihu.com/v2-2313a47b591bc59ade6a1c8862ed1fe2~resize:0:q75.jpg?source=1f5c5e47&expiration=1759929126&auth_key=1759929126-0-0-e676857e3181018f07acbd9213c0ad91&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="LoRACLR-Contrastive-Adaptation-for-Customization-of-Diffusion-Models"><a href="#LoRACLR-Contrastive-Adaptation-for-Customization-of-Diffusion-Models" class="headerlink" title="LoRACLR: Contrastive Adaptation for Customization of Diffusion Models"></a>LoRACLR: Contrastive Adaptation for Customization of Diffusion Models</h2><p><strong>Authors:Enis Simsar, Thomas Hofmann, Federico Tombari, Pinar Yanardag</strong></p>
<p>Recent advances in text-to-image customization have enabled high-fidelity, context-rich generation of personalized images, allowing specific concepts to appear in a variety of scenarios. However, current methods struggle with combining multiple personalized models, often leading to attribute entanglement or requiring separate training to preserve concept distinctiveness. We present LoRACLR, a novel approach for multi-concept image generation that merges multiple LoRA models, each fine-tuned for a distinct concept, into a single, unified model without additional individual fine-tuning. LoRACLR uses a contrastive objective to align and merge the weight spaces of these models, ensuring compatibility while minimizing interference. By enforcing distinct yet cohesive representations for each concept, LoRACLR enables efficient, scalable model composition for high-quality, multi-concept image synthesis. Our results highlight the effectiveness of LoRACLR in accurately merging multiple concepts, advancing the capabilities of personalized image generation. </p>
<blockquote>
<p>æ–‡æœ¬åˆ°å›¾åƒçš„å®šåˆ¶æŠ€æœ¯çš„æœ€æ–°è¿›å±•å·²ç»å®ç°äº†é«˜ä¿çœŸã€å¯Œå«è¯­å¢ƒçš„ä¸ªæ€§åŒ–å›¾åƒç”Ÿæˆï¼Œå…è®¸ç‰¹å®šæ¦‚å¿µå‡ºç°åœ¨å¤šç§åœºæ™¯ä¸­ã€‚ç„¶è€Œï¼Œå½“å‰çš„æ–¹æ³•åœ¨ç»“åˆå¤šä¸ªä¸ªæ€§åŒ–æ¨¡å‹æ—¶é‡åˆ°äº†å›°éš¾ï¼Œç»å¸¸å¯¼è‡´å±æ€§çº ç¼ ï¼Œæˆ–è€…éœ€è¦å•ç‹¬çš„åŸ¹è®­æ¥ä¿æŒæ¦‚å¿µçš„ç‹¬ç‰¹æ€§ã€‚æˆ‘ä»¬æå‡ºäº†LoRACLRï¼Œè¿™æ˜¯ä¸€ç§æ–°çš„å¤šæ¦‚å¿µå›¾åƒç”Ÿæˆæ–¹æ³•ï¼Œå®ƒå°†å¤šä¸ªé’ˆå¯¹ç‰¹å®šæ¦‚å¿µè¿›è¡Œå¾®è°ƒLoRAæ¨¡å‹åˆå¹¶ä¸ºä¸€ä¸ªå•ä¸€ã€ç»Ÿä¸€çš„æ¨¡å‹ï¼Œè€Œæ— éœ€é¢å¤–çš„ä¸ªåˆ«å¾®è°ƒã€‚LoRACLRä½¿ç”¨å¯¹æ¯”ç›®æ ‡æ¥å¯¹é½å’Œåˆå¹¶è¿™äº›æ¨¡å‹çš„æƒé‡ç©ºé—´ï¼Œç¡®ä¿å…¼å®¹æ€§åŒæ—¶æœ€å°åŒ–å¹²æ‰°ã€‚é€šè¿‡å®æ–½æ¸…æ™°è€Œè¿è´¯çš„è¡¨ç¤ºï¼Œæ¯ä¸ªæ¦‚å¿µéƒ½æœ‰è‡ªå·±çš„ç‰¹ç‚¹ï¼ŒLoRACLRèƒ½å¤Ÿå®ç°é«˜æ•ˆã€å¯æ‰©å±•çš„æ¨¡å‹ç»„åˆï¼Œç”¨äºé«˜è´¨é‡çš„å¤šæ¦‚å¿µå›¾åƒåˆæˆã€‚æˆ‘ä»¬çš„ç»“æœçªå‡ºäº†LoRACLRåœ¨å‡†ç¡®åˆå¹¶å¤šä¸ªæ¦‚å¿µæ–¹é¢çš„æœ‰æ•ˆæ€§ï¼Œæé«˜äº†ä¸ªæ€§åŒ–å›¾åƒç”Ÿæˆçš„èƒ½åŠ›ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.09622v2">PDF</a> Accepted to CVPRâ€™25. Project page: <a target="_blank" rel="noopener" href="https://loraclr.github.io/">https://loraclr.github.io/</a></p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†LoRACLRæ–¹æ³•ï¼Œè¿™æ˜¯ä¸€ç§å°†å¤šä¸ªé’ˆå¯¹ç‰¹å®šæ¦‚å¿µè¿›è¡Œå¾®è°ƒï¼ˆfine-tunedï¼‰çš„LoRAæ¨¡å‹åˆå¹¶ä¸ºä¸€ä¸ªç»Ÿä¸€æ¨¡å‹çš„æŠ€æœ¯ã€‚è¯¥æ–¹æ³•ä½¿ç”¨å¯¹æ¯”ç›®æ ‡ï¼ˆcontrastive objectiveï¼‰æ¥å¯¹é½å’Œåˆå¹¶è¿™äº›æ¨¡å‹çš„æƒé‡ç©ºé—´ï¼Œç¡®ä¿å®ƒä»¬ä¹‹é—´çš„å…¼å®¹æ€§å¹¶æœ€å°åŒ–å¹²æ‰°ã€‚é€šè¿‡ä¸ºæ¯ä¸ªæ¦‚å¿µå¼ºåˆ¶å®æ–½ç‹¬ç‰¹è€Œè¿è´¯çš„è¡¨ç¤ºï¼ŒLoRACLRå®ç°äº†é«˜æ•ˆã€å¯æ‰©å±•çš„æ¨¡å‹ç»„åˆï¼Œç”¨äºé«˜è´¨é‡çš„å¤šæ¦‚å¿µå›¾åƒåˆæˆã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>LoRACLRæ˜¯ä¸€ç§ç”¨äºå¤šæ¦‚å¿µå›¾åƒç”Ÿæˆçš„æ–°æ–¹æ³•ï¼Œå¯ä»¥åˆå¹¶å¤šä¸ªLoRAæ¨¡å‹ï¼Œæ¯ä¸ªæ¨¡å‹é’ˆå¯¹ä¸€ä¸ªç‰¹å®šæ¦‚å¿µè¿›è¡Œå¾®è°ƒã€‚</li>
<li>LoRACLRä½¿ç”¨å¯¹æ¯”ç›®æ ‡æ¥å¯¹é½å’Œåˆå¹¶è¿™äº›æ¨¡å‹çš„æƒé‡ç©ºé—´ï¼Œç¡®ä¿å®ƒä»¬åœ¨åˆå¹¶è¿‡ç¨‹ä¸­çš„å…¼å®¹æ€§å’Œç¨³å®šæ€§ã€‚</li>
<li>è¯¥æ–¹æ³•é€šè¿‡å¼ºåˆ¶å®æ–½ç‹¬ç‰¹ä¸”è¿è´¯çš„è¡¨ç¤ºå½¢å¼ï¼Œä¸ºæ¯ä¸ªæ¦‚å¿µåœ¨å›¾åƒåˆæˆä¸­æä¾›æ¸…æ™°çš„å®šä¹‰å’Œè¡¨ç°ã€‚</li>
<li>LoRACLRä¸éœ€è¦å¯¹æ¯ä¸ªæ¨¡å‹è¿›è¡Œå•ç‹¬çš„å¾®è°ƒï¼Œä»è€Œæé«˜äº†æ•ˆç‡ï¼Œå¹¶ç®€åŒ–äº†å¤šæ¦‚å¿µå›¾åƒåˆæˆçš„è¿‡ç¨‹ã€‚</li>
<li>è¯¥æ–¹æ³•å®ç°äº†é«˜æ•ˆã€å¯æ‰©å±•çš„æ¨¡å‹ç»„åˆï¼Œå¯ä»¥åº”ç”¨äºé«˜è´¨é‡ã€å¤šæ¦‚å¿µçš„å›¾åƒåˆæˆã€‚</li>
<li>LoRACLRåœ¨å‡†ç¡®åˆå¹¶å¤šä¸ªæ¦‚å¿µæ–¹é¢è¡¨ç°å‡ºè‰¯å¥½çš„æ•ˆæœï¼Œè¿›ä¸€æ­¥æé«˜äº†ä¸ªæ€§åŒ–å›¾åƒç”Ÿæˆçš„èƒ½åŠ›ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.09622">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-4968eb8eece4002896f21748b3823798~resize:0:q75.jpg?source=1f5c5e47&expiration=1759929134&auth_key=1759929134-0-0-a7e118da9c7ae72fdfc9326002d1e03d&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic1.zhimg.com/v2-479d7c88d7ae4e7f6419306107da324f.jpg" align="middle">
<img src="https://pic-private.zhihu.com/v2-4a269170193560a8faffa405e778c2eb~resize:0:q75.jpg?source=1f5c5e47&expiration=1759929149&auth_key=1759929149-0-0-aa21fe1ecde81345143c298a5fdc3e08&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pica.zhimg.com/v2-3fe3c18a3179948bcefb4103f7dd56c5.jpg" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="Similarity-Dissimilarity-Loss-for-Multi-label-Supervised-Contrastive-Learning"><a href="#Similarity-Dissimilarity-Loss-for-Multi-label-Supervised-Contrastive-Learning" class="headerlink" title="Similarity-Dissimilarity Loss for Multi-label Supervised Contrastive   Learning"></a>Similarity-Dissimilarity Loss for Multi-label Supervised Contrastive   Learning</h2><p><strong>Authors:Guangming Huang, Yunfei Long, Cunjin Luo</strong></p>
<p>Supervised contrastive learning has achieved remarkable success by leveraging label information; however, determining positive samples in multi-label scenarios remains a critical challenge. In multi-label supervised contrastive learning (MSCL), multi-label relations are not yet fully defined, leading to ambiguity in identifying positive samples and formulating contrastive loss functions to construct the representation space. To address these challenges, we: (i) systematically formulate multi-label relations in MSCL, (ii) propose a novel Similarity-Dissimilarity Loss, which dynamically re-weights samples based on similarity and dissimilarity factors, (iii) further provide theoretical grounded proofs for our method through rigorous mathematical analysis that supports the formulation and effectiveness, and (iv) offer a unified form and paradigm for both single-label and multi-label supervised contrastive loss. We conduct experiments on both image and text modalities and further extend the evaluation to the medical domain. The results show that our method consistently outperforms baselines in comprehensive evaluations, demonstrating its effectiveness and robustness. Moreover, the proposed approach achieves state-of-the-art performance on MIMIC-III-Full. </p>
<blockquote>
<p>ç›‘ç£å¯¹æ¯”å­¦ä¹ é€šè¿‡åˆ©ç”¨æ ‡ç­¾ä¿¡æ¯å–å¾—äº†æ˜¾è‘—çš„æˆåŠŸï¼›ç„¶è€Œï¼Œåœ¨å¤šæ ‡ç­¾åœºæ™¯ä¸­ç¡®å®šæ­£æ ·æœ¬ä»ç„¶æ˜¯ä¸€ä¸ªå…³é”®æŒ‘æˆ˜ã€‚åœ¨å¤šæ ‡ç­¾ç›‘ç£å¯¹æ¯”å­¦ä¹ ï¼ˆMSCLï¼‰ä¸­ï¼Œå¤šæ ‡ç­¾å…³ç³»å°šæœªå¾—åˆ°å……åˆ†å®šä¹‰ï¼Œå¯¼è‡´åœ¨è¯†åˆ«æ­£æ ·æœ¬å’Œåˆ¶å®šå¯¹æ¯”æŸå¤±å‡½æ•°ä»¥æ„å»ºè¡¨ç¤ºç©ºé—´æ—¶å­˜åœ¨æ¨¡ç³Šæ€§ã€‚ä¸ºäº†åº”å¯¹è¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬ï¼šï¼ˆiï¼‰ç³»ç»Ÿåœ°åˆ¶å®šäº†MSCLä¸­çš„å¤šæ ‡ç­¾å…³ç³»ï¼Œï¼ˆiiï¼‰æå‡ºäº†ä¸€ç§æ–°çš„ç›¸ä¼¼æ€§-å·®å¼‚æ€§æŸå¤±ï¼Œè¯¥æŸå¤±æ ¹æ®ç›¸ä¼¼æ€§å’Œå·®å¼‚æ€§å› ç´ åŠ¨æ€åœ°é‡æ–°åŠ æƒæ ·æœ¬ï¼Œï¼ˆiiiï¼‰é€šè¿‡ä¸¥æ ¼çš„æ•°å­¦åˆ†æè¿›ä¸€æ­¥ä¸ºæˆ‘ä»¬çš„æ–¹æ³•æä¾›äº†ç†è®ºè¯æ˜ï¼Œæ”¯æŒå…¶åˆ¶å®šå’Œæœ‰æ•ˆæ€§ï¼Œï¼ˆivï¼‰ä¸ºå•æ ‡ç­¾å’Œå¤šæ ‡ç­¾ç›‘ç£å¯¹æ¯”æŸå¤±æä¾›äº†ç»Ÿä¸€çš„å½¢å¼å’ŒèŒƒå¼ã€‚æˆ‘ä»¬åœ¨å›¾åƒå’Œæ–‡æœ¬æ¨¡å¼ä¸Šè¿›è¡Œäº†å®éªŒï¼Œå¹¶å°†è¯„ä¼°æ‰©å±•åˆ°äº†åŒ»ç–—é¢†åŸŸã€‚ç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨ç»¼åˆè¯„ä¼°ä¸­å§‹ç»ˆä¼˜äºåŸºçº¿ï¼Œè¯æ˜äº†å…¶æœ‰æ•ˆæ€§å’Œç¨³å¥æ€§ã€‚æ­¤å¤–ï¼Œæ‰€æå‡ºçš„æ–¹æ³•åœ¨MIMIC-III-Fullä¸Šè¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2410.13439v5">PDF</a> </p>
<p><strong>Summary</strong><br>æ— ç›‘ç£å¯¹æ¯”å­¦ä¹ å–å¾—äº†æ˜¾è‘—çš„æˆåŠŸï¼Œä½†åœ¨å¤šæ ‡ç­¾åœºæ™¯ä¸­ç¡®å®šæ­£æ ·æœ¬æ˜¯ä¸€ä¸ªæŒ‘æˆ˜ã€‚åœ¨å¤šæ ‡ç­¾ç›‘ç£å¯¹æ¯”å­¦ä¹ ï¼ˆMSCLï¼‰ä¸­ï¼Œç”±äºå¤šæ ‡ç­¾å…³ç³»å°šæœªæ˜ç¡®ç•Œå®šï¼Œå¯¼è‡´éš¾ä»¥ç¡®å®šæ­£æ ·æœ¬å¹¶æ„å»ºå¯¹æ¯”æŸå¤±å‡½æ•°ä»¥æ„å»ºè¡¨ç¤ºç©ºé—´ã€‚ä¸ºè§£å†³è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬ç³»ç»Ÿåœ°æå‡ºäº†å¤šæ ‡ç­¾å…³ç³»çš„ç•Œå®šã€æ–°çš„ç›¸ä¼¼æ€§-å·®å¼‚æ€§æŸå¤±å‡½æ•°è®¾è®¡ï¼Œæä¾›äº†ç†è®ºæ”¯æ’‘ä¸æ•°å­¦åˆ†æè¯æ˜å…¶æœ‰æ•ˆæ€§ï¼Œå¹¶ç»™å‡ºäº†ç»Ÿä¸€çš„å¤šæ ‡ç­¾å’Œå•æ ‡ç­¾ç›‘ç£å¯¹æ¯”æŸå¤±èŒƒå¼ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨å›¾åƒå’Œæ–‡æœ¬æ¨¡æ€ä¸Šçš„è¡¨ç°å‡ä¼˜äºåŸºçº¿æ–¹æ³•ï¼Œä¸”åœ¨åŒ»ç–—é¢†åŸŸçš„è¡¨ç°å°¤å…¶çªå‡ºã€‚æˆ‘ä»¬çš„æ–¹æ³•åœ¨MIMIC-III-Fullæ•°æ®é›†ä¸Šå–å¾—äº†æœ€ä¼˜çš„æ€§èƒ½è¡¨ç°ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤šæ ‡ç­¾ç›‘ç£å¯¹æ¯”å­¦ä¹ ï¼ˆMSCLï¼‰åœ¨ç¡®å®šæ­£æ ·æœ¬æ–¹é¢å­˜åœ¨æŒ‘æˆ˜ï¼Œå› ä¸ºå¤šæ ‡ç­¾å…³ç³»å°šæœªæ˜ç¡®ç•Œå®šã€‚</li>
<li>æå‡ºäº†ä¸€ç§æ–°çš„ç›¸ä¼¼æ€§-å·®å¼‚æ€§æŸå¤±å‡½æ•°ï¼Œæ ¹æ®ç›¸ä¼¼æ€§å’Œå·®å¼‚æ€§å› ç´ åŠ¨æ€åœ°é‡æ–°åŠ æƒæ ·æœ¬ã€‚</li>
<li>é€šè¿‡ä¸¥æ ¼çš„æ•°å­¦åˆ†æè¯æ˜äº†æˆ‘ä»¬æ–¹æ³•çš„æœ‰æ•ˆæ€§å’Œç†è®ºæ”¯æ’‘ã€‚</li>
<li>æä¾›äº†ç»Ÿä¸€çš„å¤šæ ‡ç­¾å’Œå•æ ‡ç­¾ç›‘ç£å¯¹æ¯”æŸå¤±èŒƒå¼ã€‚</li>
<li>å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å›¾åƒå’Œæ–‡æœ¬æ¨¡æ€ä¸Šçš„è¡¨ç°å‡ä¼˜äºåŸºçº¿æ–¹æ³•ã€‚</li>
<li>åœ¨åŒ»ç–—é¢†åŸŸçš„è¯„ä¼°ä¸­ï¼Œè¯¥æ–¹æ³•è¡¨ç°å‡ºå¼ºå¤§çš„æ€§èƒ½è¡¨ç°ï¼Œå°¤å…¶åœ¨MIMIC-III-Fullæ•°æ®é›†ä¸Šå–å¾—äº†æœ€ä¼˜è¡¨ç°ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2410.13439">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-c37097d8c7c0fe13d117059bd9df2408~resize:0:q75.jpg?source=1f5c5e47&expiration=1759929166&auth_key=1759929166-0-0-845f26574d3d1813988b7327d19acda4&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-e46d0be79e6af45377b46fb5bad8c26f~resize:0:q75.jpg?source=1f5c5e47&expiration=1759929173&auth_key=1759929173-0-0-b355ae2ba58ffd3880122170303c341d&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-10-01/%E6%97%A0%E7%9B%91%E7%9D%A3_%E5%8D%8A%E7%9B%91%E7%9D%A3_%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0/">https://kedreamix.github.io/Talk2Paper/Paper/2025-10-01/%E6%97%A0%E7%9B%91%E7%9D%A3_%E5%8D%8A%E7%9B%91%E7%9D%A3_%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/%E6%97%A0%E7%9B%91%E7%9D%A3-%E5%8D%8A%E7%9B%91%E7%9D%A3-%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0/">
                                    <span class="chip bg-color">æ— ç›‘ç£/åŠç›‘ç£/å¯¹æ¯”å­¦ä¹ </span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-10-01/%E5%8C%BB%E5%AD%A6%E5%BD%B1%E5%83%8F_Breast%20Ultrasound/">
                    <div class="card-image">
                        
                        <img src="https://pic-private.zhihu.com/v2-efb5bf9e1a25adeb0b4768bf6937bbf3~resize:0:q75.jpg?source=1f5c5e47&expiration=1759929179&auth_key=1759929179-0-0-834736eed384594b750d5807e4eed1ec&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" class="responsive-img" alt="åŒ»å­¦å½±åƒ/Breast Ultrasound">
                        
                        <span class="card-title">åŒ»å­¦å½±åƒ/Breast Ultrasound</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            åŒ»å­¦å½±åƒ/Breast Ultrasound æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-10-01  UESA-Net U-Shaped Embedded Multidirectional Shrinkage Attention Network   for Ultrasound Nodule Segmentation
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-10-01
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/%E5%8C%BB%E5%AD%A6%E5%BD%B1%E5%83%8F-Breast-Ultrasound/" class="post-category">
                                    åŒ»å­¦å½±åƒ/Breast Ultrasound
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/%E5%8C%BB%E5%AD%A6%E5%BD%B1%E5%83%8F-Breast-Ultrasound/">
                        <span class="chip bg-color">åŒ»å­¦å½±åƒ/Breast Ultrasound</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-10-01/%E6%A3%80%E6%B5%8B_%E5%88%86%E5%89%B2_%E8%B7%9F%E8%B8%AA/">
                    <div class="card-image">
                        
                        <img src="https://pic-private.zhihu.com/v2-e91ca0fa49ab6cc348f37002c35a8f86~resize:0:q75.jpg?source=1f5c5e47&expiration=1759928787&auth_key=1759928787-0-0-ea09183c4f71c2c90149e679abd400d5&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" class="responsive-img" alt="æ£€æµ‹/åˆ†å‰²/è·Ÿè¸ª">
                        
                        <span class="card-title">æ£€æµ‹/åˆ†å‰²/è·Ÿè¸ª</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            æ£€æµ‹/åˆ†å‰²/è·Ÿè¸ª æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-10-01  Evaluation of Polarimetric Fusion for Semantic Segmentation in Aquatic   Environments
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-10-01
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/%E6%A3%80%E6%B5%8B-%E5%88%86%E5%89%B2-%E8%B7%9F%E8%B8%AA/" class="post-category">
                                    æ£€æµ‹/åˆ†å‰²/è·Ÿè¸ª
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/%E6%A3%80%E6%B5%8B-%E5%88%86%E5%89%B2-%E8%B7%9F%E8%B8%AA/">
                        <span class="chip bg-color">æ£€æµ‹/åˆ†å‰²/è·Ÿè¸ª</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">30666.7k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
