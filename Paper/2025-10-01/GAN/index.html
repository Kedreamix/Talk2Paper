<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="GAN">
    <meta name="description" content="GAN 方向最新论文已更新，请持续关注 Update in 2025-10-01  ThermalGen Style-Disentangled Flow-Based Generative Models for   RGB-to-Thermal Image Translation">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>GAN | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loader页面消失采用渐隐的方式*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logo出现动画 */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//使用渐隐的方法淡出loading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//强制显示loading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">嘘~  正在从服务器偷取页面 . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>首页</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>标签</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>分类</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>归档</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="搜索" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="深色/浅色模式" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			首页
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			标签
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			分类
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			归档
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('D:\MyBlog\AutoFX\arxiv\2025-10-01\./crop_GAN/2509.24878v1/page_3_0.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">GAN</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/GAN/">
                                <span class="chip bg-color">GAN</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/GAN/" class="post-category">
                                GAN
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2025-10-01
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>更新日期:&nbsp;&nbsp;
                    2025-10-06
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp;
                    7.1k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp;
                    29 分
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>阅读次数:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>⚠️ 以下所有内容总结都来自于 大语言模型的能力，如有错误，仅供参考，谨慎使用<br>🔴 请注意：千万不要用于严肃的学术场景，只能用于论文阅读前的初筛！<br>💗 如果您觉得我们的项目对您有帮助 <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ，还请您给我们一些鼓励！⭐️ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFace免费体验</a></p>
</blockquote>
<h1 id="2025-10-01-更新"><a href="#2025-10-01-更新" class="headerlink" title="2025-10-01 更新"></a>2025-10-01 更新</h1><h2 id="ThermalGen-Style-Disentangled-Flow-Based-Generative-Models-for-RGB-to-Thermal-Image-Translation"><a href="#ThermalGen-Style-Disentangled-Flow-Based-Generative-Models-for-RGB-to-Thermal-Image-Translation" class="headerlink" title="ThermalGen: Style-Disentangled Flow-Based Generative Models for   RGB-to-Thermal Image Translation"></a>ThermalGen: Style-Disentangled Flow-Based Generative Models for   RGB-to-Thermal Image Translation</h2><p><strong>Authors:Jiuhong Xiao, Roshan Nayak, Ning Zhang, Daniel Tortei, Giuseppe Loianno</strong></p>
<p>Paired RGB-thermal data is crucial for visual-thermal sensor fusion and cross-modality tasks, including important applications such as multi-modal image alignment and retrieval. However, the scarcity of synchronized and calibrated RGB-thermal image pairs presents a major obstacle to progress in these areas. To overcome this challenge, RGB-to-Thermal (RGB-T) image translation has emerged as a promising solution, enabling the synthesis of thermal images from abundant RGB datasets for training purposes. In this study, we propose ThermalGen, an adaptive flow-based generative model for RGB-T image translation, incorporating an RGB image conditioning architecture and a style-disentangled mechanism. To support large-scale training, we curated eight public satellite-aerial, aerial, and ground RGB-T paired datasets, and introduced three new large-scale satellite-aerial RGB-T datasets–DJI-day, Bosonplus-day, and Bosonplus-night–captured across diverse times, sensor types, and geographic regions. Extensive evaluations across multiple RGB-T benchmarks demonstrate that ThermalGen achieves comparable or superior translation performance compared to existing GAN-based and diffusion-based methods. To our knowledge, ThermalGen is the first RGB-T image translation model capable of synthesizing thermal images that reflect significant variations in viewpoints, sensor characteristics, and environmental conditions. Project page: <a target="_blank" rel="noopener" href="http://xjh19971.github.io/ThermalGen">http://xjh19971.github.io/ThermalGen</a> </p>
<blockquote>
<p>配对RGB-热数据对于视觉-热传感器融合和跨模态任务至关重要，包括多模态图像对齐和检索等重要应用。然而，同步且校准过的RGB-热图像对的稀缺性成为这些领域发展的主要障碍。为了克服这一挑战，RGB-到热（RGB-T）图像翻译作为一种有前景的解决方案应运而生，它能够从丰富的RGB数据集中合成热图像，用于训练目的。在这项研究中，我们提出了ThermalGen，这是一种基于自适应流的RGB-T图像翻译生成模型，它结合了RGB图像条件架构和风格分离机制。为了支持大规模训练，我们整理了八个公共卫星航空、航空和地面RGB-T配对数据集，并引入了三个新的大规模卫星航空RGB-T数据集——DJI日间、博森加日间和博森加夜间，这些数据集是在不同的时间、传感器类型和地理区域捕获的。在多个RGB-T基准测试上的广泛评估表明，与现有的基于GAN和基于扩散的方法相比，ThermalGen实现了相当的或更优越的翻译性能。据我们所知，ThermalGen是首个能够合成反映视点、传感器特性和环境条件等重大变化的热图像的RGB-T图像翻译模型。项目页面：<a target="_blank" rel="noopener" href="http://xjh19971.github.io/ThermalGen">http://xjh19971.github.io/ThermalGen</a></p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.24878v1">PDF</a> 23 pages including the checklist and appendix. Accepted at NeurIPS   2025</p>
<p><strong>Summary</strong></p>
<p>本文提出一种基于自适应流生成模型的RGB-T图像翻译方法——ThermalGen，用于合成训练所需的热图像。该方法结合了RGB图像条件架构和风格分离机制，实现了多样化的RGB-热图像配对数据的合成。通过引入三个新的大规模卫星航空RGB-T数据集，ThermalGen展现出卓越的性能，能够合成反映视角、传感器特性和环境条件差异的热图像。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>RGB-热数据配对对于视觉-热传感器融合和跨模态任务至关重要。</li>
<li>缺乏同步和校准的RGB-热图像配对是主要的研究挑战。</li>
<li>RGB-T图像翻译作为一种解决方案，能够从丰富的RGB数据集中合成热图像用于训练目的。</li>
<li>提出的ThermalGen模型是一种自适应流生成模型，用于RGB-T图像翻译。</li>
<li>ThermalGen结合了RGB图像条件架构和风格分离机制，实现更好的性能。</li>
<li>引入了三个新的大规模卫星航空RGB-T数据集，支持大规模训练。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.24878">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-10-01\./crop_GAN/2509.24878v1/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-10-01\./crop_GAN/2509.24878v1/page_1_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-10-01\./crop_GAN/2509.24878v1/page_3_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-10-01\./crop_GAN/2509.24878v1/page_4_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-10-01\./crop_GAN/2509.24878v1/page_5_0.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="From-Satellite-to-Street-A-Hybrid-Framework-Integrating-Stable-Diffusion-and-PanoGAN-for-Consistent-Cross-View-Synthesis"><a href="#From-Satellite-to-Street-A-Hybrid-Framework-Integrating-Stable-Diffusion-and-PanoGAN-for-Consistent-Cross-View-Synthesis" class="headerlink" title="From Satellite to Street: A Hybrid Framework Integrating Stable   Diffusion and PanoGAN for Consistent Cross-View Synthesis"></a>From Satellite to Street: A Hybrid Framework Integrating Stable   Diffusion and PanoGAN for Consistent Cross-View Synthesis</h2><p><strong>Authors:Khawlah Bajbaa, Abbas Anwar, Muhammad Saqib, Hafeez Anwar, Nabin Sharma, Muhammad Usman</strong></p>
<p>Street view imagery has become an essential source for geospatial data collection and urban analytics, enabling the extraction of valuable insights that support informed decision-making. However, synthesizing street-view images from corresponding satellite imagery presents significant challenges due to substantial differences in appearance and viewing perspective between these two domains. This paper presents a hybrid framework that integrates diffusion-based models and conditional generative adversarial networks to generate geographically consistent street-view images from satellite imagery. Our approach uses a multi-stage training strategy that incorporates Stable Diffusion as the core component within a dual-branch architecture. To enhance the framework’s capabilities, we integrate a conditional Generative Adversarial Network (GAN) that enables the generation of geographically consistent panoramic street views. Furthermore, we implement a fusion strategy that leverages the strengths of both models to create robust representations, thereby improving the geometric consistency and visual quality of the generated street-view images. The proposed framework is evaluated on the challenging Cross-View USA (CVUSA) dataset, a standard benchmark for cross-view image synthesis. Experimental results demonstrate that our hybrid approach outperforms diffusion-only methods across multiple evaluation metrics and achieves competitive performance compared to state-of-the-art GAN-based methods. The framework successfully generates realistic and geometrically consistent street-view images while preserving fine-grained local details, including street markings, secondary roads, and atmospheric elements such as clouds. </p>
<blockquote>
<p>街道景观图像已成为地理空间数据采集和城市分析的重要来源，能够提取有价值的见解，支持基于信息的决策制定。然而，从相应的卫星图像合成街道景观图像存在重大挑战，因为这两个领域在外观和观看角度上存在显著差异。本文提出了一个混合框架，该框架结合了基于扩散的模型和条件生成对抗网络，从卫星图像生成地理一致的街道景观图像。我们的方法采用多阶段训练策略，将Stable Diffusion作为双分支架构的核心组件。为了提高框架的能力，我们集成了一个条件生成对抗网络（GAN），能够生成地理上一致的全景街道景观。此外，我们实施了一种融合策略，利用两种模型的优势来创建稳健的表示，从而提高了生成街道景观图像的几何一致性和视觉质量。所提出的框架在具有挑战性的Cross-View USA（CVUSA）数据集上进行了评估，该数据集是跨视图图像合成的标准基准。实验结果表明，我们的混合方法在多个评估指标上优于仅使用扩散的方法，并与最先进的基于GAN的方法实现竞争性能。该框架能够成功生成逼真且几何一致的街道景观图像，同时保留精细的局部细节，包括街道标记、次要道路和大气要素，如云层。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.24369v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>本文提出一种混合框架，该框架结合了扩散模型和条件生成对抗网络，用于从卫星图像生成地理上一致的街道视图图像。该框架采用多阶段训练策略，以稳定扩散为核心组件，在双分支架构中实现。此外，还整合了条件生成对抗网络（GAN），以提高框架生成地理上一致的全景街道视图的能力。实验结果表明，该混合方法在多个评价指标上优于仅使用扩散的方法，与最新的GAN方法相比也具有竞争力。它能成功生成逼真的、几何上一致的街道视图图像，同时保留细致的局部细节，如街道标记、次要道路和大气元素如云。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>街道视图图像已成为地理空间数据收集和城市分析的重要来源，支持决策制定。</li>
<li>从卫星图像合成街道视图图像面临外观和观看角度上的重大挑战。</li>
<li>本文提出一种混合框架，结合扩散模型和条件生成对抗网络（GAN）来解决这一问题。</li>
<li>框架的核心是稳定扩散，在一个双分支架构中采用多阶段训练策略。</li>
<li>整合条件GAN以生成地理上一致的全景街道视图。</li>
<li>实验结果表明，该框架在多个评价指标上表现出色，与最新技术相比具有竞争力。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.24369">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-10-01\./crop_GAN/2509.24369v1/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-10-01\./crop_GAN/2509.24369v1/page_3_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-10-01\./crop_GAN/2509.24369v1/page_3_1.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-10-01\./crop_GAN/2509.24369v1/page_4_0.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="Tumor-Synthesis-conditioned-on-Radiomics"><a href="#Tumor-Synthesis-conditioned-on-Radiomics" class="headerlink" title="Tumor Synthesis conditioned on Radiomics"></a>Tumor Synthesis conditioned on Radiomics</h2><p><strong>Authors:Jonghun Kim, Inye Na, Eun Sook Ko, Hyunjin Park</strong></p>
<p>Due to privacy concerns, obtaining large datasets is challenging in medical image analysis, especially with 3D modalities like Computed Tomography (CT) and Magnetic Resonance Imaging (MRI). Existing generative models, developed to address this issue, often face limitations in output diversity and thus cannot accurately represent 3D medical images. We propose a tumor-generation model that utilizes radiomics features as generative conditions. Radiomics features are high-dimensional handcrafted semantic features that are biologically well-grounded and thus are good candidates for conditioning. Our model employs a GAN-based model to generate tumor masks and a diffusion-based approach to generate tumor texture conditioned on radiomics features. Our method allows the user to generate tumor images according to user-specified radiomics features such as size, shape, and texture at an arbitrary location. This enables the physicians to easily visualize tumor images to better understand tumors according to changing radiomics features. Our approach allows for the removal, manipulation, and repositioning of tumors, generating various tumor types in different scenarios. The model has been tested on tumors in four different organs (kidney, lung, breast, and brain) across CT and MRI. The synthesized images are shown to effectively aid in training for downstream tasks and their authenticity was also evaluated through expert evaluations. Our method has potential usage in treatment planning with diverse synthesized tumors. </p>
<blockquote>
<p>在医学图像分析中，由于隐私问题，获取大型数据集具有挑战性，特别是在使用计算机断层扫描（CT）和磁共振成像（MRI）等3D模态时更是如此。为解决此问题而开发的现有生成模型通常面临输出多样性方面的局限，因此无法准确表示3D医学图像。我们提出了一种肿瘤生成模型，该模型利用放射学特征作为生成条件。放射学特征是生物上具有良好依据的高维手工语义特征，因此是条件选择的不错候选。我们的模型采用基于GAN的模型来生成肿瘤掩膜，并使用基于扩散的方法根据放射学特征生成肿瘤纹理。我们的方法允许用户根据用户指定的放射学特征（如大小、形状和纹理）在任意位置生成肿瘤图像。这使得医生能够轻松根据变化的放射学特征可视化肿瘤图像，从而更好地理解肿瘤。我们的方法允许删除、操作和重新定位肿瘤，在不同场景下生成各种肿瘤类型。该模型已在CT和MRI中的四个不同器官（肾脏、肺部、乳房和大脑）的肿瘤上进行了测试。合成的图像已证明可有效辅助下游任务训练，其真实性也通过专家评估得到了评价。我们的方法在治疗规划中具有使用多种合成肿瘤的潜力。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.24182v1">PDF</a> WACV’25</p>
<p><strong>Summary</strong></p>
<p>本文提出一种基于放射学特征的肿瘤生成模型，利用GAN生成肿瘤掩膜，并采用扩散方法根据放射学特征生成肿瘤纹理。该模型可根据用户指定的放射学特征生成肿瘤图像，如大小、形状和纹理等，有助于医生更好地了解肿瘤情况。该模型已在四种不同器官的肿瘤（肾脏、肺部、乳房和大脑）中进行了测试，合成的图像可有效辅助下游任务训练，并经过专家评估验证其真实性。此模型在治疗规划中具有潜在应用价值。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>医学图像分析中，获取大型数据集具有挑战性，特别是3D模态如CT和MRI。</li>
<li>现有生成模型在输出多样性方面存在局限，无法准确代表3D医学图像。</li>
<li>提出的肿瘤生成模型利用放射学特征作为生成条件，这些特征是生物上合理的高维手工语义特征。</li>
<li>模型采用GAN生成肿瘤掩膜，并采用扩散方法根据放射学特征生成肿瘤纹理。</li>
<li>该模型可根据用户指定的放射学特征生成肿瘤图像，如大小、形状和纹理，有助于医生更好地理解肿瘤情况。</li>
<li>模型在多种器官（肾脏、肺部、乳房和大脑）的肿瘤中进行了测试，合成的图像有助于下游任务训练。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.24182">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-10-01\./crop_GAN/2509.24182v1/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-10-01\./crop_GAN/2509.24182v1/page_2_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-10-01\./crop_GAN/2509.24182v1/page_3_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-10-01\./crop_GAN/2509.24182v1/page_4_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-10-01\./crop_GAN/2509.24182v1/page_5_0.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="LatXGen-Towards-Radiation-Free-and-Accurate-Quantitative-Analysis-of-Sagittal-Spinal-Alignment-Via-Cross-Modal-Radiographic-View-Synthesis"><a href="#LatXGen-Towards-Radiation-Free-and-Accurate-Quantitative-Analysis-of-Sagittal-Spinal-Alignment-Via-Cross-Modal-Radiographic-View-Synthesis" class="headerlink" title="LatXGen: Towards Radiation-Free and Accurate Quantitative Analysis of   Sagittal Spinal Alignment Via Cross-Modal Radiographic View Synthesis"></a>LatXGen: Towards Radiation-Free and Accurate Quantitative Analysis of   Sagittal Spinal Alignment Via Cross-Modal Radiographic View Synthesis</h2><p><strong>Authors:Moxin Zhao, Nan Meng, Jason Pui Yin Cheung, Chris Yuk Kwan Tang, Chenxi Yu, Wenting Zhong, Pengyu Lu, Chang Shi, Yipeng Zhuang, Teng Zhang</strong></p>
<p>Adolescent Idiopathic Scoliosis (AIS) is a complex three-dimensional spinal deformity, and accurate morphological assessment requires evaluating both coronal and sagittal alignment. While previous research has made significant progress in developing radiation-free methods for coronal plane assessment, reliable and accurate evaluation of sagittal alignment without ionizing radiation remains largely underexplored. To address this gap, we propose LatXGen, a novel generative framework that synthesizes realistic lateral spinal radiographs from posterior Red-Green-Blue and Depth (RGBD) images of unclothed backs. This enables accurate, radiation-free estimation of sagittal spinal alignment. LatXGen tackles two core challenges: (1) inferring sagittal spinal morphology changes from a lateral perspective based on posteroanterior surface geometry, and (2) performing cross-modality translation from RGBD input to the radiographic domain. The framework adopts a dual-stage architecture that progressively estimates lateral spinal structure and synthesizes corresponding radiographs. To enhance anatomical consistency, we introduce an attention-based Fast Fourier Convolution (FFC) module for integrating anatomical features from RGBD images and 3D landmarks, and a Spatial Deformation Network (SDN) to model morphological variations in the lateral view. Additionally, we construct the first large-scale paired dataset for this task, comprising 3,264 RGBD and lateral radiograph pairs. Experimental results demonstrate that LatXGen produces anatomically accurate radiographs and outperforms existing GAN-based methods in both visual fidelity and quantitative metrics. This study offers a promising, radiation-free solution for sagittal spine assessment and advances comprehensive AIS evaluation. </p>
<blockquote>
<p>青少年特发性脊柱侧弯（AIS）是一种复杂的三维脊柱畸形，准确的形态评估需要评估冠状面和矢状面的对齐情况。虽然之前的研究在开发无辐射的冠状面评估方法方面取得了重大进展，但无电离辐射的矢状面对齐的可靠和准确评估仍然很大程度上被忽视。为了弥补这一空白，我们提出了LatXGen，这是一种新的生成框架，它可以从裸露背部的后侧红绿蓝深度（RGBD）图像中合成逼真的侧位脊柱放射线照片。这为实现准确的无辐射矢状脊柱对齐估计提供了可能。LatXGen解决了两个核心挑战：（1）基于前后表面几何的从侧位角度推断矢状脊柱形态变化；（2）执行从RGBD输入到放射线照相领域的跨模态翻译。该框架采用双阶段架构，逐步估计侧位脊柱结构并合成相应的放射线照片。为了提高解剖一致性，我们引入了一个基于注意力的快速傅里叶卷积（FFC）模块，用于集成RGBD图像和3D地标的解剖特征，以及一个空间变形网络（SDN）来模拟侧视图中的形态变化。此外，我们构建了针对此任务的第一大规模配对数据集，包含3264个RGBD和侧位放射线照片对。实验结果表明，LatXGen产生的放射线照片解剖准确，在视觉保真度和定量指标上均优于现有的基于GAN的方法。这项研究为矢状脊柱评估和全面的AIS评估提供了有前景的无辐射解决方案。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.24165v1">PDF</a> 8 pages, 6 figures</p>
<p><strong>Summary</strong><br>    提出了一种新型生成框架LatXGen，可从后背的红绿蓝深度（RGBD）图像合成逼真的侧面脊柱放射图像，从而实现无需辐射的脊柱侧弯矢状面排列准确评估。该框架解决了从侧面角度推断矢状面脊柱形态变化和跨模态从RGBD图像到放射影像领域的转换两个核心挑战。通过引入基于注意力的快速傅立叶卷积（FFC）模块和空间变形网络（SDN），提高了解构脊柱结构和放射影像合成的准确性。本研究为矢状面脊柱评估和青少年特发性脊柱侧弯的全面评估提供了无需辐射的潜在解决方案。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>LatXGen是一种新型的生成框架，能够从RGBD图像合成侧面脊柱放射图像。</li>
<li>该框架解决了从侧面角度推断矢状面脊柱形态变化和跨模态转换的核心挑战。</li>
<li>LatXGen通过引入FFC模块和空间变形网络，提高了合成放射影像的准确性和解剖一致性。</li>
<li>构建了包含3,264个RGBD和侧面放射影像对的大型配对数据集。</li>
<li>实验结果表明，LatXGen在视觉逼真度和定量指标上均优于现有的GAN方法。</li>
<li>LatXGen为实现无需辐射的脊柱侧弯矢状面评估提供了可能。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.24165">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-10-01\./crop_GAN/2509.24165v1/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-10-01\./crop_GAN/2509.24165v1/page_3_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-10-01\./crop_GAN/2509.24165v1/page_4_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-10-01\./crop_GAN/2509.24165v1/page_5_0.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="GANji-A-Framework-for-Introductory-AI-Image-Generation"><a href="#GANji-A-Framework-for-Introductory-AI-Image-Generation" class="headerlink" title="GANji: A Framework for Introductory AI Image Generation"></a>GANji: A Framework for Introductory AI Image Generation</h2><p><strong>Authors:Chandon Hamel, Mike Busch</strong></p>
<p>The comparative study of generative models often requires significant computational resources, creating a barrier for researchers and practitioners. This paper introduces GANji, a lightweight framework for benchmarking foundational AI image generation techniques using a dataset of 10,314 Japanese Kanji characters. It systematically compares the performance of a Variational Autoencoder (VAE), a Generative Adversarial Network (GAN), and a Denoising Diffusion Probabilistic Model (DDPM). The results demonstrate that while the DDPM achieves the highest image fidelity, with a Fr&#39;echet Inception Distance (FID) score of 26.2, its sampling time is over 2,000 times slower than the other models. The GANji framework is an effective and accessible tool for revealing the fundamental trade-offs between model architecture, computational cost, and visual quality, making it ideal for both educational and research purposes. </p>
<blockquote>
<p>生成模型的比较研究通常需要大量的计算资源，这成为了研究者和实践者的障碍。本文介绍了GANji，这是一个使用10,314个日语汉字字符数据集对基础AI图像生成技术进行基准测试的轻量级框架。它系统地比较了变分自编码器（VAE）、生成对抗网络（GAN）和去噪扩散概率模型（DDPM）的性能。结果表明，虽然DDPM的图像保真度最高，其Fréchet Inception Distance（FID）得分为26.2，但其采样时间是其他模型的2000倍以上。GANji框架是一个有效且易于使用的工具，能够揭示模型结构、计算成本和视觉质量之间的基本权衡，因此非常适合教育和研究目的。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.24128v1">PDF</a> </p>
<p><strong>Summary</strong><br>该论文提出了一种名为GANji的轻量级框架，用于评估基于人工智能的图像生成技术。该框架使用包含10,314个日本汉字字符的数据集，对变分自编码器（VAE）、生成对抗网络（GAN）和去噪扩散概率模型（DDPM）的性能进行了系统比较。研究结果表明，虽然DDPM在图像保真度方面表现最佳，但其采样时间是其他模型超过2,000倍。GANji框架是揭示模型架构、计算成本和视觉质量之间基本权衡的有效且易于使用的工具，适合教育和研究目的。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>GANji框架用于评估人工智能图像生成技术的性能。</li>
<li>该研究比较了VAE、GAN和DDPM三种模型的性能。</li>
<li>DDPM在图像保真度上表现最佳，但采样时间极长。</li>
<li>GANji框架可有效地揭示模型架构、计算成本和视觉质量之间的权衡。</li>
<li>GANji框架对于教育和研究目的均具理想性。</li>
<li>该研究使用了包含10,314个日本汉字字符的数据集。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.24128">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-10-01\./crop_GAN/2509.24128v1/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-10-01\./crop_GAN/2509.24128v1/page_1_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-10-01\./crop_GAN/2509.24128v1/page_2_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-10-01\./crop_GAN/2509.24128v1/page_2_1.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-10-01\./crop_GAN/2509.24128v1/page_2_2.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-10-01\./crop_GAN/2509.24128v1/page_3_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-10-01\./crop_GAN/2509.24128v1/page_3_1.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="MAN-Latent-Diffusion-Enhanced-Multistage-Anti-Noise-Network-for-Efficient-and-High-Quality-Low-Dose-CT-Image-Denoising"><a href="#MAN-Latent-Diffusion-Enhanced-Multistage-Anti-Noise-Network-for-Efficient-and-High-Quality-Low-Dose-CT-Image-Denoising" class="headerlink" title="MAN: Latent Diffusion Enhanced Multistage Anti-Noise Network for   Efficient and High-Quality Low-Dose CT Image Denoising"></a>MAN: Latent Diffusion Enhanced Multistage Anti-Noise Network for   Efficient and High-Quality Low-Dose CT Image Denoising</h2><p><strong>Authors:Tangtangfang Fang, Jingxi Hu, Xiangjian He, Jiaqi Yang</strong></p>
<p>While diffusion models have set a new benchmark for quality in Low-Dose Computed Tomography (LDCT) denoising, their clinical adoption is critically hindered by extreme computational costs, with inference times often exceeding thousands of seconds per scan. To overcome this barrier, we introduce MAN, a Latent Diffusion Enhanced Multistage Anti-Noise Network for Efficient and High-Quality Low-Dose CT Image Denoising task. Our method operates in a compressed latent space via a perceptually-optimized autoencoder, enabling an attention-based conditional U-Net to perform the fast, deterministic conditional denoising diffusion process with drastically reduced overhead. On the LDCT and Projection dataset, our model achieves superior perceptual quality, surpassing CNN&#x2F;GAN-based methods while rivaling the reconstruction fidelity of computationally heavy diffusion models like DDPM and Dn-Dp. Most critically, in the inference stage, our model is over 60x faster than representative pixel space diffusion denoisers, while remaining competitive on PSNR&#x2F;SSIM scores. By bridging the gap between high fidelity and clinical viability, our work demonstrates a practical path forward for advanced generative models in medical imaging. </p>
<blockquote>
<p>虽然扩散模型已经为低剂量计算机断层扫描（LDCT）去噪的质量设定了新的基准，但其临床采用受到极端计算成本的严重阻碍，推理时间通常每次扫描超过数千秒。为了克服这一障碍，我们引入了MAN，这是一个用于高效和高品质低剂量CT图像去噪任务的潜在扩散增强多阶段抗噪声网络。我们的方法在感知优化自编码器提供的压缩潜在空间内运行，使基于注意力的条件U-Net能够执行快速确定性条件去噪扩散过程，大幅降低开销。在LDCT和投影数据集上，我们的模型达到了优越的主观质量，超越了基于CNN&#x2F;GAN的方法，同时在重建保真度方面与计算密集型的扩散模型（如DDPM和Dn-Dp）相匹敌。最关键的是，在推理阶段，我们的模型是代表性像素空间扩散去噪器的60倍以上，同时在峰值信噪比（PSNR）&#x2F;结构相似性（SSIM）得分上保持竞争力。通过弥合高保真与临床可行性之间的差距，我们的工作展示了先进生成模型在未来医学影像中的实用发展路径。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.23603v1">PDF</a> Submitted to ICASSP 2026</p>
<p><strong>Summary</strong></p>
<p>本文介绍了一种名为MAN的潜扩散增强多阶段抗噪声网络，用于高效高质量的低剂量CT图像去噪任务。MAN在压缩的潜在空间内工作，通过感知优化的自编码器，使基于注意力的U-Net能够进行快速、确定的条件去噪扩散过程，大大降低了开销。在LDCT和投影数据集上，MAN模型实现了超越CNN&#x2F;GAN方法的高感知质量，同时与计算繁重的扩散模型如DDPM和Dn-Dp在重建保真度上竞争。最关键的在于推理阶段，与其他像素空间扩散去噪器相比，MAN模型速度超过60倍，同时在PSNR&#x2F;SSIM得分上保持竞争力。该研究缩小了高保真与临床可行性之间的差距，为医学影像中的高级生成模型展示了一条实际可行的道路。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>MAN网络用于低剂量CT图像去噪任务，旨在解决扩散模型的高计算成本问题。</li>
<li>MAN在压缩的潜在空间内操作，通过感知优化的自编码器实现快速、确定的条件去噪扩散过程。</li>
<li>MAN模型实现了超越CNN&#x2F;GAN方法的高感知质量，同时在重建保真度上与计算繁重的扩散模型竞争。</li>
<li>与其他像素空间扩散去噪器相比，MAN模型的推理速度显著提高。</li>
<li>MAN模型在保证去噪质量的同时降低了计算成本，有助于其临床应用的实现。</li>
<li>该研究为医学影像中的高级生成模型提供了一种实际可行的道路。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.23603">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-10-01\./crop_GAN/2509.23603v1/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-10-01\./crop_GAN/2509.23603v1/page_1_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-10-01\./crop_GAN/2509.23603v1/page_2_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-10-01\./crop_GAN/2509.23603v1/page_3_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-10-01\./crop_GAN/2509.23603v1/page_3_1.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="Soft-Di-M-O-Improving-One-Step-Discrete-Image-Generation-with-Soft-Embeddings"><a href="#Soft-Di-M-O-Improving-One-Step-Discrete-Image-Generation-with-Soft-Embeddings" class="headerlink" title="Soft-Di[M]O: Improving One-Step Discrete Image Generation with Soft   Embeddings"></a>Soft-Di[M]O: Improving One-Step Discrete Image Generation with Soft   Embeddings</h2><p><strong>Authors:Yuanzhi Zhu, Xi Wang, Stéphane Lathuilière, Vicky Kalogeiton</strong></p>
<p>One-step generators distilled from Masked Diffusion Models (MDMs) compress multiple sampling steps into a single forward pass, enabling efficient text and image synthesis. However, they suffer two key limitations: they inherit modeling bias from the teacher, and their discrete token outputs block gradient flow, preventing post-distillation refinements such as adversarial training, reward-based fine-tuning, and Test-Time Embedding Optimization (TTEO). In this work, we introduce soft embeddings, a simple relaxation that replaces discrete tokens with the expected embeddings under the generator’s output distribution. Soft embeddings preserve representation fidelity for one-step discrete generator while providing a fully differentiable continuous surrogate that is compatible with teacher backbones and tokenizer decoders. Integrating soft embeddings into the Di[M]O distillation framework (denoted Soft-Di[M]O) makes one-step generators end-to-end trainable and enables straightforward application of GAN-based refinement, differentiable reward fine-tuning, and TTEO. Empirically, across multiple MDM teachers (e.g., MaskBit, MaskGen), Soft-Di[M]O achieves state-of-the-art one-step results: improved class-to-image performance, a one-step FID of 1.56 on ImageNet-256 with GAN-based refinement, along with higher GenEval and HPS scores on text-to-image with reward fine-tuning, and further gains from TTEO. </p>
<blockquote>
<p>从Masked Diffusion Models（MDMs）提炼出的一步生成器将多个采样步骤压缩成一次前向传递，实现了高效的文本和图像合成。然而，它们存在两个主要局限性：它们继承了教师的建模偏见，并且它们的离散令牌输出阻止了梯度流，阻止了如对抗性训练、基于奖励的微调以及测试时间嵌入优化（TTEO）等提炼后的改进。在这项工作中，我们引入了软嵌入，这是一种简单的松弛方法，它用生成器输出分布下的预期嵌入来替换离散令牌。软嵌入保留了一步离散生成器的表示保真度，同时提供了一个与教师主干和分词器解码器兼容的全可微分的连续替代方案。将软嵌入集成到Di[M]O提炼框架（表示为Soft-Di[M]O）中，使得一步生成器端对端可训练，并便于应用基于GAN的改进、可微分的奖励微调以及TTEO。经验上，跨多个MDM教师（例如MaskBit、MaskGen），Soft-Di[M]O达到了最先进的单步结果：提高了类到图像的性能，在ImageNet-256上的单步FID为1.56，使用基于GAN的改进，以及在文本到图像上使用奖励微调时的GenEval和HPS分数更高，并且从TTEO中获得了进一步的收益。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.22925v1">PDF</a> </p>
<p><strong>Summary</strong><br>文本介绍了基于Masked Diffusion Models（MDM）的一步生成器（one-step generator），它能在一次前向传递中实现高效的文本和图像合成。然而，它存在两个主要局限性：继承自教师的建模偏见和离散标记输出阻碍了梯度流，使得无法进行对抗训练、基于奖励的微调以及测试时间嵌入优化（TTEO）。为解决这些问题，本文引入了软嵌入（soft embeddings），它是一种简单的松弛方法，用生成器输出分布下的预期嵌入替换离散标记。软嵌入保留了一步离散生成器的表示保真度，并提供了一个与教师和分词器解码器兼容的全微分连续替代方案。将软嵌入集成到Di[M]O蒸馏框架中（称为Soft-Di[M]O），使得一步生成器可以进行端到端的训练，并能直接应用基于GAN的细化、可微分的奖励微调以及TTEO。实验结果表明，在多个MDM教师模型上，Soft-Di[M]O取得了最先进的单步结果。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>一步生成器从Masked Diffusion Models（MDM）中蒸馏出多个采样步骤到一个前向传递中，实现文本和图像的高效合成。</li>
<li>一步生成器存在两个主要局限性：继承自教师的建模偏见和离散标记输出导致的梯度流阻碍。</li>
<li>软嵌入作为一种简单的松弛方法被引入，以预期嵌入替换离散标记，改善一步生成器的局限性。</li>
<li>软嵌入保留了一阶离散生成器的表示保真度，并提供了一个全微分连续替代方案，与教师和分词器解码器兼容。</li>
<li>Soft-Di[M]O框架集成了软嵌入技术，使得一步生成器可以进行端到端的训练，并能应用基于GAN的细化、奖励微调以及测试时间嵌入优化（TTEO）。</li>
<li>Soft-Di[M]O在多个MDM教师模型上取得了最先进的单步结果，包括改进类到图像的性能、更低的FID分数以及更高的GenEval和HPS分数等。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.22925">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-10-01\./crop_GAN/2509.22925v1/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-10-01\./crop_GAN/2509.22925v1/page_1_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-10-01\./crop_GAN/2509.22925v1/page_3_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-10-01\./crop_GAN/2509.22925v1/page_5_0.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        文章作者:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        文章链接:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-10-01/GAN/">https://kedreamix.github.io/Talk2Paper/Paper/2025-10-01/GAN/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        版权声明:
                    </i>
                </span>
                <span class="reprint-info">
                    本博客所有文章除特別声明外，均采用
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    许可协议。转载请注明来源
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/GAN/">
                                    <span class="chip bg-color">GAN</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;上一篇</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-10-01/%E5%85%83%E5%AE%87%E5%AE%99_%E8%99%9A%E6%8B%9F%E4%BA%BA/">
                    <div class="card-image">
                        
                        <img src="D:\MyBlog\AutoFX\arxiv\2025-10-01\./crop_元宇宙_虚拟人/2509.24004v1/page_2_0.jpg" class="responsive-img" alt="元宇宙/虚拟人">
                        
                        <span class="card-title">元宇宙/虚拟人</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            元宇宙/虚拟人 方向最新论文已更新，请持续关注 Update in 2025-10-01  SIE3D Single-image Expressive 3D Avatar generation via Semantic   Embedding and Perceptual Expression Loss
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-10-01
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/%E5%85%83%E5%AE%87%E5%AE%99-%E8%99%9A%E6%8B%9F%E4%BA%BA/" class="post-category">
                                    元宇宙/虚拟人
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/%E5%85%83%E5%AE%87%E5%AE%99-%E8%99%9A%E6%8B%9F%E4%BA%BA/">
                        <span class="chip bg-color">元宇宙/虚拟人</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-10-01/Face%20Swapping/">
                    <div class="card-image">
                        
                        <img src="D:\MyBlog\AutoFX\arxiv\2025-10-01\./crop_Face Swapping/2509.24850v1/page_2_0.jpg" class="responsive-img" alt="Face Swapping">
                        
                        <span class="card-title">Face Swapping</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Face Swapping 方向最新论文已更新，请持续关注 Update in 2025-10-01  PHASE-Net Physics-Grounded Harmonic Attention System for Efficient   Remote Photoplethysmography Measurement
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-10-01
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Face-Swapping/" class="post-category">
                                    Face Swapping
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Face-Swapping/">
                        <span class="chip bg-color">Face Swapping</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- 代码语言 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span
                        class="white-color">29774.4k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- 运行天数提醒. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // 区分是否有年份.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = '本站已运行 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                daysTip = '本站已運行 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = '本站已运行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = '本站已運行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="关注我的知乎: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">知</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- 白天和黑夜主题 -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // 只在桌面版网页启用特效
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- 雪花特效 -->
    

    <!-- 鼠标星星特效 -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--腾讯兔小巢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- 动态标签 -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Σ(っ °Д °;)っ诶，页面崩溃了嘛？", clearTimeout(st)) : (document.title = "φ(゜▽゜*)♪咦，又好了！", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
