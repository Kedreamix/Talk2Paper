<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="3DGS">
    <meta name="description" content="3DGS æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-10-01  Triangle Splatting+ Differentiable Rendering with Opaque Triangles">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>3DGS | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://picx.zhimg.com/v2-a64933e04bbd3934c6b99595e92319f6.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">3DGS</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/3DGS/">
                                <span class="chip bg-color">3DGS</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/3DGS/" class="post-category">
                                3DGS
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-10-01
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-11-15
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    19.3k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    78 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-10-01-æ›´æ–°"><a href="#2025-10-01-æ›´æ–°" class="headerlink" title="2025-10-01 æ›´æ–°"></a>2025-10-01 æ›´æ–°</h1><h2 id="Triangle-Splatting-Differentiable-Rendering-with-Opaque-Triangles"><a href="#Triangle-Splatting-Differentiable-Rendering-with-Opaque-Triangles" class="headerlink" title="Triangle Splatting+: Differentiable Rendering with Opaque Triangles"></a>Triangle Splatting+: Differentiable Rendering with Opaque Triangles</h2><p><strong>Authors:Jan Held, Renaud Vandeghen, Sanghyun Son, Daniel Rebain, Matheus Gadelha, Yi Zhou, Ming C. Lin, Marc Van Droogenbroeck, Andrea Tagliasacchi</strong></p>
<p>Reconstructing 3D scenes and synthesizing novel views has seen rapid progress in recent years. Neural Radiance Fields demonstrated that continuous volumetric radiance fields can achieve high-quality image synthesis, but their long training and rendering times limit practicality. 3D Gaussian Splatting (3DGS) addressed these issues by representing scenes with millions of Gaussians, enabling real-time rendering and fast optimization. However, Gaussian primitives are not natively compatible with the mesh-based pipelines used in VR headsets, and real-time graphics applications. Existing solutions attempt to convert Gaussians into meshes through post-processing or two-stage pipelines, which increases complexity and degrades visual quality. In this work, we introduce Triangle Splatting+, which directly optimizes triangles, the fundamental primitive of computer graphics, within a differentiable splatting framework. We formulate triangle parametrization to enable connectivity through shared vertices, and we design a training strategy that enforces opaque triangles. The final output is immediately usable in standard graphics engines without post-processing. Experiments on the Mip-NeRF360 and Tanks &amp; Temples datasets show that Triangle Splatting+achieves state-of-the-art performance in mesh-based novel view synthesis. Our method surpasses prior splatting approaches in visual fidelity while remaining efficient and fast to training. Moreover, the resulting semi-connected meshes support downstream applications such as physics-based simulation or interactive walkthroughs. The project page is <a target="_blank" rel="noopener" href="https://trianglesplatting2.github.io/trianglesplatting2/">https://trianglesplatting2.github.io/trianglesplatting2/</a>. </p>
<blockquote>
<p>é‡å»ºä¸‰ç»´åœºæ™¯å’Œåˆæˆæ–°é¢–è§†è§’çš„æŠ€æœ¯è¿‘å¹´æ¥å–å¾—äº†å¿«é€Ÿå‘å±•ã€‚ç¥ç»è¾å°„åœºï¼ˆNeural Radiance Fieldsï¼‰è¯æ˜äº†è¿ç»­ä½“ç§¯è¾å°„åœºå¯ä»¥å®ç°é«˜è´¨é‡å›¾åƒåˆæˆï¼Œä½†å…¶è¾ƒé•¿çš„è®­ç»ƒå’Œæ¸²æŸ“æ—¶é—´é™åˆ¶äº†å…¶å®ç”¨æ€§ã€‚ä¸‰ç»´é«˜æ–¯è´´ç‰‡ï¼ˆ3DGSï¼‰é€šè¿‡ç”¨æ•°ç™¾ä¸‡ä¸ªé«˜æ–¯å‡½æ•°è¡¨ç¤ºåœºæ™¯è§£å†³äº†è¿™äº›é—®é¢˜ï¼Œå®ç°äº†å®æ—¶æ¸²æŸ“å’Œå¿«é€Ÿä¼˜åŒ–ã€‚ç„¶è€Œï¼Œé«˜æ–¯åŸºæœ¬å®ä½“ä¸è™šæ‹Ÿç°å®å¤´ç›”å’Œå®æ—¶å›¾å½¢åº”ç”¨ç¨‹åºä¸­ä½¿ç”¨çš„åŸºäºç½‘æ ¼çš„ç®¡é“åŸç”Ÿä¸å…¼å®¹ã€‚ç°æœ‰è§£å†³æ–¹æ¡ˆå°è¯•é€šè¿‡åæœŸå¤„ç†æˆ–ä¸¤é˜¶æ®µç®¡é“å°†é«˜æ–¯è½¬æ¢ä¸ºç½‘æ ¼ï¼Œè¿™å¢åŠ äº†å¤æ‚æ€§å¹¶é™ä½äº†è§†è§‰è´¨é‡ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸‰è§’å½¢è´´ç‰‡+ï¼ˆTriangle Splatting+ï¼‰ï¼Œå®ƒç›´æ¥åœ¨å¯å¾®åˆ†çš„è´´ç‰‡æ¡†æ¶å†…ä¼˜åŒ–è®¡ç®—æœºå›¾å½¢çš„åŸºæœ¬åŸå§‹å®ä½“â€”â€”ä¸‰è§’å½¢ã€‚æˆ‘ä»¬åˆ¶å®šä¸‰è§’å½¢å‚æ•°åŒ–ï¼Œä»¥é€šè¿‡å…±äº«é¡¶ç‚¹å®ç°è¿æ¥ï¼Œå¹¶è®¾è®¡ä¸€ç§è®­ç»ƒç­–ç•¥æ¥å¼ºåˆ¶æ‰§è¡Œä¸é€æ˜ä¸‰è§’å½¢ã€‚æœ€ç»ˆè¾“å‡ºå¯ç«‹å³åœ¨æ ‡å‡†å›¾å½¢å¼•æ“ä¸­ä½¿ç”¨ï¼Œæ— éœ€åæœŸå¤„ç†ã€‚åœ¨Mip-NeRF360å’ŒTanks &amp; Templesæ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œä¸‰è§’å½¢è´´ç‰‡+åœ¨åŸºäºç½‘æ ¼çš„æ–°é¢–è§†å›¾åˆæˆä¸­è¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚æˆ‘ä»¬çš„æ–¹æ³•åœ¨è§†è§‰ä¿çœŸåº¦ä¸Šè¶…è¶Šäº†å…ˆå‰çš„è´´ç‰‡æ–¹æ³•ï¼ŒåŒæ—¶ä¿æŒäº†é«˜æ•ˆå’Œå¿«é€Ÿçš„è®­ç»ƒã€‚æ­¤å¤–ï¼Œæ‰€å¾—çš„åŠè¿æ¥ç½‘æ ¼æ”¯æŒä¸‹æ¸¸åº”ç”¨ï¼Œå¦‚åŸºäºç‰©ç†çš„æ¨¡æ‹Ÿæˆ–äº¤äº’å¼æ¼«æ¸¸ã€‚é¡¹ç›®é¡µé¢æ˜¯<a target="_blank" rel="noopener" href="https://trianglesplatting2.github.io/trianglesplatting2/%E3%80%82">https://trianglesplatting2.github.io/trianglesplatting2/ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.25122v1">PDF</a> 9 pages, 6 figures, 2 tables</p>
<p><strong>Summary</strong></p>
<p>è¯¥æ–‡æœ¬ä»‹ç»äº†ä¸‰ç»´åœºæ™¯é‡å»ºå’Œåˆæˆæ–°è§†è§’çš„è¿›å±•ã€‚Neural Radiance Fieldsè™½ç„¶å¯ä»¥å®ç°é«˜è´¨é‡å›¾åƒåˆæˆï¼Œä½†å…¶è®­ç»ƒå’Œæ¸²æŸ“æ—¶é—´è¾ƒé•¿ï¼Œé™åˆ¶äº†å®é™…åº”ç”¨ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæå‡ºäº†ä¸‰ç»´é«˜æ–¯æ¸²æŸ“ï¼ˆ3DGSï¼‰æŠ€æœ¯ï¼Œé‡‡ç”¨é«˜æ–¯åŸºå…ƒæ¥è¡¨ç¤ºåœºæ™¯ä»¥å®ç°å®æ—¶æ¸²æŸ“å’Œå¿«é€Ÿä¼˜åŒ–ã€‚ä½†é«˜æ–¯åŸºå…ƒä¸VRå¤´ç›”å’Œå®æ—¶å›¾å½¢åº”ç”¨ç¨‹åºä¸­çš„ç½‘æ ¼åŸºç®¡é“ä¸å…¼å®¹ã€‚æœ¬æ–‡æå‡ºäº†Triangle Splatting+æŠ€æœ¯ï¼Œç›´æ¥åœ¨å¯å¾®åˆ†çš„æ¸²æŸ“æ¡†æ¶å†…ä¼˜åŒ–è®¡ç®—æœºå›¾å½¢çš„åŸºæœ¬åŸºå…ƒä¸‰è§’å½¢ï¼Œå¹¶è®¾è®¡äº†ä¸€ç§è®­ç»ƒç­–ç•¥æ¥å¼ºåˆ¶æ‰§è¡Œä¸é€æ˜çš„ä¸‰è§’å½¢ã€‚å®éªŒç»“æœè¯æ˜äº†è¯¥æ–¹æ³•åœ¨åŸºäºç½‘æ ¼çš„æ–°è§†è§’åˆæˆä¸­è¾¾åˆ°äº†æœ€æ–°æ°´å¹³çš„æŠ€æœ¯æ€§èƒ½ï¼Œæé«˜äº†è§†è§‰ä¿çœŸåº¦ï¼ŒåŒæ—¶ä¿æŒäº†é«˜æ•ˆå¿«é€Ÿçš„è®­ç»ƒè¿‡ç¨‹ã€‚é¡¹ç›®é¡µé¢æä¾›äº†æ›´å¤šä¿¡æ¯ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>Neural Radiance Fieldså®ç°äº†é«˜è´¨é‡å›¾åƒåˆæˆï¼Œä½†è®­ç»ƒå’Œæ¸²æŸ“æ—¶é—´è¾ƒé•¿ã€‚</li>
<li>3DGSæŠ€æœ¯é‡‡ç”¨é«˜æ–¯åŸºå…ƒè¡¨ç¤ºåœºæ™¯ä»¥å®ç°å®æ—¶æ¸²æŸ“å’Œå¿«é€Ÿä¼˜åŒ–ã€‚</li>
<li>é«˜æ–¯åŸºå…ƒä¸VRå¤´ç›”å’Œå®æ—¶å›¾å½¢åº”ç”¨ç¨‹åºä¸­çš„ç½‘æ ¼åŸºç®¡é“ä¸å…¼å®¹ã€‚</li>
<li>Triangle Splatting+ç›´æ¥åœ¨å¯å¾®åˆ†çš„æ¸²æŸ“æ¡†æ¶å†…ä¼˜åŒ–ä¸‰è§’å½¢åŸºå…ƒã€‚</li>
<li>Triangle Splatting+å®ç°äº†å¼ºåˆ¶ä¸é€æ˜çš„ä¸‰è§’å½¢è®­ç»ƒç­–ç•¥ã€‚</li>
<li>è¯¥æ–¹æ³•åœ¨åŸºäºç½‘æ ¼çš„æ–°è§†è§’åˆæˆä¸­è¾¾åˆ°äº†æœ€æ–°æŠ€æœ¯æ€§èƒ½ã€‚</li>
<li>Triangle Splatting+æŠ€æœ¯æé«˜äº†è§†è§‰ä¿çœŸåº¦ï¼ŒåŒæ—¶ä¿æŒé«˜æ•ˆå¿«é€Ÿçš„è®­ç»ƒè¿‡ç¨‹ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.25122">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-79e7471e12407ef33b5a74f20a1762f5" align="middle">
<img src="https://pica.zhimg.com/v2-aced2ec14cce54803edf23b5e5e6b2e7.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b1e9ff6a08bae476f3ec7ed58181ec8a" align="middle">
<img src="https://picx.zhimg.com/v2-04e63a5e35859c9a12ad1157bc3f21c6" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="UniLat3D-Geometry-Appearance-Unified-Latents-for-Single-Stage-3D-Generation"><a href="#UniLat3D-Geometry-Appearance-Unified-Latents-for-Single-Stage-3D-Generation" class="headerlink" title="UniLat3D: Geometry-Appearance Unified Latents for Single-Stage 3D   Generation"></a>UniLat3D: Geometry-Appearance Unified Latents for Single-Stage 3D   Generation</h2><p><strong>Authors:Guanjun Wu, Jiemin Fang, Chen Yang, Sikuang Li, Taoran Yi, Jia Lu, Zanwei Zhou, Jiazhong Cen, Lingxi Xie, Xiaopeng Zhang, Wei Wei, Wenyu Liu, Xinggang Wang, Qi Tian</strong></p>
<p>High-fidelity 3D asset generation is crucial for various industries. While recent 3D pretrained models show strong capability in producing realistic content, most are built upon diffusion models and follow a two-stage pipeline that first generates geometry and then synthesizes appearance. Such a decoupled design tends to produce geometry-texture misalignment and non-negligible cost. In this paper, we propose UniLat3D, a unified framework that encodes geometry and appearance in a single latent space, enabling direct single-stage generation. Our key contribution is a geometry-appearance Unified VAE, which compresses high-resolution sparse features into a compact latent representation â€“ UniLat. UniLat integrates structural and visual information into a dense low-resolution latent, which can be efficiently decoded into diverse 3D formats, e.g., 3D Gaussians and meshes. Based on this unified representation, we train a single flow-matching model to map Gaussian noise directly into UniLat, eliminating redundant stages. Trained solely on public datasets, UniLat3D produces high-quality 3D assets in seconds from a single image, achieving superior appearance fidelity and geometric quality. More demos &amp; code are available at <a target="_blank" rel="noopener" href="https://unilat3d.github.io/">https://unilat3d.github.io/</a> </p>
<blockquote>
<p>é«˜ä¿çœŸä¸‰ç»´èµ„äº§ç”Ÿæˆå¯¹äºå„è¡Œå„ä¸šæ¥è¯´è‡³å…³é‡è¦ã€‚è™½ç„¶æœ€æ–°çš„ä¸‰ç»´é¢„è®­ç»ƒæ¨¡å‹åœ¨ç”ŸæˆçœŸå®å†…å®¹æ–¹é¢è¡¨ç°å‡ºå¼ºå¤§çš„èƒ½åŠ›ï¼Œä½†å®ƒä»¬å¤§å¤šåŸºäºæ‰©æ•£æ¨¡å‹ï¼Œéµå¾ªä¸€ä¸ªä¸¤é˜¶æ®µæµç¨‹ï¼Œå³é¦–å…ˆç”Ÿæˆå‡ ä½•ç»“æ„ï¼Œç„¶ååˆæˆå¤–è§‚ã€‚è¿™ç§åˆ†ç¦»è®¾è®¡å¾€å¾€å¯¼è‡´å‡ ä½•çº¹ç†ä¸åŒ¹é…å’Œæˆæœ¬é«˜æ˜‚ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†UniLat3Dï¼Œè¿™æ˜¯ä¸€ä¸ªç»Ÿä¸€æ¡†æ¶ï¼Œåœ¨ä¸€ä¸ªå•ä¸€æ½œåœ¨ç©ºé—´ä¸­ç¼–ç å‡ ä½•å’Œå¤–è§‚ä¿¡æ¯ï¼Œå®ç°äº†ç›´æ¥çš„å•é˜¶æ®µç”Ÿæˆã€‚æˆ‘ä»¬çš„å…³é”®è´¡çŒ®æ˜¯å‡ ä½•å¤–è§‚ç»Ÿä¸€å˜åˆ†è‡ªç¼–ç å™¨ï¼ˆVAEï¼‰ï¼Œå®ƒå°†é«˜åˆ†è¾¨ç‡ç¨€ç–ç‰¹å¾å‹ç¼©æˆç´§å‡‘çš„æ½œåœ¨è¡¨ç¤ºâ€”â€”UniLatã€‚UniLatå°†ç»“æ„å’Œè§†è§‰ä¿¡æ¯é›†æˆåˆ°ä¸€ä¸ªå¯†é›†çš„ä½åˆ†è¾¨ç‡æ½œåœ¨ç©ºé—´ä¸­ï¼Œå¯ä»¥é«˜æ•ˆåœ°è§£ç ä¸ºå¤šç§ä¸‰ç»´æ ¼å¼ï¼Œå¦‚ä¸‰ç»´é«˜æ–¯å’Œç½‘æ ¼ã€‚åŸºäºè¿™ç§ç»Ÿä¸€è¡¨ç¤ºï¼Œæˆ‘ä»¬è®­ç»ƒäº†ä¸€ä¸ªå•ä¸€æµåŒ¹é…æ¨¡å‹ï¼Œç›´æ¥å°†é«˜æ–¯å™ªå£°æ˜ å°„åˆ°UniLatï¼Œæ¶ˆé™¤äº†å†—ä½™é˜¶æ®µã€‚ä»…é€šè¿‡å…¬å…±æ•°æ®é›†è¿›è¡Œè®­ç»ƒï¼ŒUniLat3Dèƒ½å¤Ÿåœ¨å‡ ç§’å†…ç”Ÿæˆé«˜è´¨é‡çš„ä¸‰ç»´èµ„äº§ï¼Œå®ç°å“è¶Šçš„å¤–è§‚ä¿çœŸåº¦å’Œå‡ ä½•è´¨é‡ã€‚æ›´å¤šæ¼”ç¤ºå’Œä»£ç è¯·è®¿é—®ï¼š[<a target="_blank" rel="noopener" href="https://unilat3d.github.io/]">https://unilat3d.github.io/]</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.25079v1">PDF</a> Project page: <a target="_blank" rel="noopener" href="https://unilat3d.github.io/">https://unilat3d.github.io/</a></p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºä¸€ç§åä¸ºUniLat3Dçš„ç»Ÿä¸€æ¡†æ¶ï¼Œç”¨äºé«˜ä¿çœŸ3Dèµ„äº§ç”Ÿæˆã€‚è¯¥æ¡†æ¶åœ¨å•ä¸€æ½œåœ¨ç©ºé—´ä¸­ç¼–ç å‡ ä½•å’Œå¤–è§‚ï¼Œå®ç°ç›´æ¥çš„å•é˜¶æ®µç”Ÿæˆï¼Œè§£å†³äº†å‡ ä½•çº¹ç†ä¸åŒ¹é…å’Œéå¾®ä¸è¶³é“çš„æˆæœ¬é—®é¢˜ã€‚å…¶æ ¸å¿ƒè´¡çŒ®æ˜¯å‡ ä½•å¤–è§‚ç»Ÿä¸€VAEï¼Œå¯å°†é«˜åˆ†è¾¨ç‡ç¨€ç–ç‰¹å¾å‹ç¼©æˆç´§å‡‘çš„æ½œåœ¨è¡¨ç¤ºâ€”â€”UniLatã€‚è¿™ç§ç»Ÿä¸€è¡¨ç¤ºå¯ç›´æ¥å°†é«˜æ–¯å™ªå£°æ˜ å°„åˆ°UniLatï¼Œæ¶ˆé™¤å†—ä½™é˜¶æ®µï¼Œä»è€Œå¿«é€Ÿç”Ÿæˆé«˜è´¨é‡3Dèµ„äº§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>UniLat3Dæ˜¯ä¸€ç§ç»Ÿä¸€æ¡†æ¶ï¼Œç”¨äºåœ¨å•ä¸€æ½œåœ¨ç©ºé—´ä¸­ç¼–ç å‡ ä½•å’Œå¤–è§‚ï¼Œå®ç°ç›´æ¥çš„å•é˜¶æ®µ3Dèµ„äº§ç”Ÿæˆã€‚</li>
<li>è¯¥æ¡†æ¶è§£å†³äº†ä¼ ç»Ÿä¸¤é˜¶æ®µç®¡é“è®¾è®¡å¯¼è‡´çš„å‡ ä½•çº¹ç†ä¸åŒ¹é…é—®é¢˜ã€‚</li>
<li>UniLatæ˜¯æ ¸å¿ƒè´¡çŒ®ï¼Œå°†é«˜åˆ†è¾¨ç‡ç¨€ç–ç‰¹å¾å‹ç¼©æˆç´§å‡‘çš„æ½œåœ¨è¡¨ç¤ºã€‚</li>
<li>UniLatèƒ½å¤Ÿæ•´åˆç»“æ„å’Œè§†è§‰ä¿¡æ¯ï¼Œå¹¶å¯ä»¥é«˜æ•ˆåœ°è§£ç ä¸ºå¤šç§3Dæ ¼å¼ã€‚</li>
<li>UniLat3Dä½¿ç”¨ä¸€ä¸ªæµåŒ¹é…æ¨¡å‹ï¼Œç›´æ¥å°†é«˜æ–¯å™ªå£°æ˜ å°„åˆ°UniLatæ½œåœ¨ç©ºé—´ï¼Œæ¶ˆé™¤äº†å†—ä½™é˜¶æ®µã€‚</li>
<li>è¯¥æ¡†æ¶å¯åœ¨å…¬å…±æ•°æ®é›†ä¸Šè®­ç»ƒï¼Œå¹¶èƒ½ä»å•ä¸ªå›¾åƒåœ¨å‡ ç§’å†…ç”Ÿæˆé«˜è´¨é‡3Dèµ„äº§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.25079">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-c303915045f5a5163ee396e617e22a3b" align="middle">
<img src="https://picx.zhimg.com/v2-31ef34c882dbd83d6ff8e68861d37153" align="middle">
<img src="https://pic1.zhimg.com/v2-f542e5833bd50246643af21db7ac0ad3.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-162cd654412d64b1cc62e3a51962b6f2" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="GEM-3D-Gaussian-Splatting-for-Efficient-and-Accurate-Cryo-EM-Reconstruction"><a href="#GEM-3D-Gaussian-Splatting-for-Efficient-and-Accurate-Cryo-EM-Reconstruction" class="headerlink" title="GEM: 3D Gaussian Splatting for Efficient and Accurate Cryo-EM   Reconstruction"></a>GEM: 3D Gaussian Splatting for Efficient and Accurate Cryo-EM   Reconstruction</h2><p><strong>Authors:Huaizhi Qu, Xiao Wang, Gengwei Zhang, Jie Peng, Tianlong Chen</strong></p>
<p>Cryo-electron microscopy (cryo-EM) has become a central tool for high-resolution structural biology, yet the massive scale of datasets (often exceeding 100k particle images) renders 3D reconstruction both computationally expensive and memory intensive. Traditional Fourier-space methods are efficient but lose fidelity due to repeated transforms, while recent real-space approaches based on neural radiance fields (NeRFs) improve accuracy but incur cubic memory and computation overhead. Therefore, we introduce GEM, a novel cryo-EM reconstruction framework built on 3D Gaussian Splatting (3DGS) that operates directly in real-space while maintaining high efficiency. Instead of modeling the entire density volume, GEM represents proteins with compact 3D Gaussians, each parameterized by only 11 values. To further improve the training efficiency, we designed a novel gradient computation to 3D Gaussians that contribute to each voxel. This design substantially reduced both memory footprint and training cost. On standard cryo-EM benchmarks, GEM achieves up to 48% faster training and 12% lower memory usage compared to state-of-the-art methods, while improving local resolution by as much as 38.8%. These results establish GEM as a practical and scalable paradigm for cryo-EM reconstruction, unifying speed, efficiency, and high-resolution accuracy. Our code is available at <a target="_blank" rel="noopener" href="https://github.com/UNITES-Lab/GEM">https://github.com/UNITES-Lab/GEM</a>. </p>
<blockquote>
<p>å†·å†»ç”µå­æ˜¾å¾®é•œï¼ˆcryo-EMï¼‰å·²æˆä¸ºé«˜åˆ†è¾¨ç‡ç»“æ„ç”Ÿç‰©å­¦çš„é‡è¦å·¥å…·ï¼Œä½†æ•°æ®é›†è§„æ¨¡åºå¤§ï¼ˆé€šå¸¸è¶…è¿‡10ä¸‡å¼ ç²’å­å›¾åƒï¼‰ï¼Œä½¿å¾—3Dé‡å»ºåœ¨è®¡ç®—ä¸Šæ—¢æ˜‚è´µåˆå†…å­˜å¯†é›†ã€‚ä¼ ç»Ÿçš„å‚…é‡Œå¶ç©ºé—´æ–¹æ³•è™½ç„¶æ•ˆç‡é«˜ï¼Œä½†ç”±äºé‡å¤å˜æ¢è€ŒæŸå¤±ä¿çœŸåº¦ï¼Œè€Œæœ€è¿‘åŸºäºç¥ç»è¾å°„åœºï¼ˆNeRFsï¼‰çš„å®ç©ºé—´æ–¹æ³•è™½ç„¶æé«˜äº†ç²¾åº¦ï¼Œä½†å¸¦æ¥äº†ç«‹æ–¹çº§çš„å†…å­˜å’Œè®¡ç®—å¼€é”€ã€‚å› æ­¤ï¼Œæˆ‘ä»¬å¼•å…¥äº†GEMï¼Œè¿™æ˜¯ä¸€ç§æ–°å‹çš„å†·å†»ç”µé•œé‡å»ºæ¡†æ¶ï¼Œå®ƒåŸºäºä¸‰ç»´é«˜æ–¯æ‹¼è´´ï¼ˆ3DGSï¼‰æ„å»ºï¼Œç›´æ¥åœ¨å®ç©ºé—´æ“ä½œï¼ŒåŒæ—¶ä¿æŒé«˜æ•ˆç‡ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.25075v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†ä¸€ç§åŸºäº3Dé«˜æ–¯æ‹¼è´´ï¼ˆ3DGSï¼‰çš„æ–°å‹å†·å†»ç”µå­æ˜¾å¾®é•œï¼ˆcryo-EMï¼‰é‡å»ºæ¡†æ¶â€”â€”GEMã€‚ä¸ä¼ ç»Ÿçš„å‚…é‡Œå¶ç©ºé—´æ–¹æ³•ç›¸æ¯”ï¼ŒGEMç›´æ¥åœ¨å®ç©ºé—´æ“ä½œï¼Œå¯é«˜æ•ˆè¡¨è¾¾è›‹ç™½è´¨ç»“æ„ã€‚é€šè¿‡é‡‡ç”¨ç´§å‡‘çš„3Dé«˜æ–¯è¡¨ç¤ºæ³•å¹¶è®¾è®¡æ–°é¢–çš„æ¢¯åº¦è®¡ç®—ï¼ŒGEMæé«˜äº†è®­ç»ƒæ•ˆç‡å’Œå†…å­˜ä½¿ç”¨ç‡ã€‚åœ¨æ ‡å‡†cryo-EMåŸºå‡†æµ‹è¯•ä¸­ï¼ŒGEMç›¸è¾ƒäºå…¶ä»–å…ˆè¿›æ–¹æ³•å®ç°äº†æ›´å¿«çš„è®­ç»ƒå’Œæ›´ä½çš„å†…å­˜å ç”¨ï¼ŒåŒæ—¶æé«˜äº†å±€éƒ¨åˆ†è¾¨ç‡ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>GEMæ˜¯ä¸€ç§åŸºäº3Dé«˜æ–¯æ‹¼è´´ï¼ˆ3DGSï¼‰çš„å†·å†»ç”µå­æ˜¾å¾®é•œï¼ˆcryo-EMï¼‰é‡å»ºæ¡†æ¶ã€‚</li>
<li>GEMç›´æ¥åœ¨å®ç©ºé—´æ“ä½œï¼Œæ”¹è¿›äº†ä¼ ç»Ÿçš„å‚…é‡Œå¶ç©ºé—´æ–¹æ³•åœ¨æŸäº›æƒ…å†µä¸‹çš„ä¿çœŸåº¦é—®é¢˜ã€‚</li>
<li>GEMé‡‡ç”¨ç´§å‡‘çš„3Dé«˜æ–¯è¡¨ç¤ºæ³•è¡¨è¾¾è›‹ç™½è´¨ç»“æ„ï¼Œé€šè¿‡å‚æ•°ä¼˜åŒ–æé«˜è®¡ç®—æ•ˆç‡ã€‚</li>
<li>è®¾è®¡äº†æ–°é¢–çš„æ¢¯åº¦è®¡ç®—ï¼Œæœ‰åŠ©äºæé«˜è®­ç»ƒæ•ˆç‡å’Œå†…å­˜ä½¿ç”¨ç‡ã€‚</li>
<li>ä¸å…¶ä»–å…ˆè¿›æ–¹æ³•ç›¸æ¯”ï¼ŒGEMåœ¨cryo-EMåŸºå‡†æµ‹è¯•ä¸­å®ç°äº†æ›´å¿«çš„è®­ç»ƒå’Œæ›´ä½çš„å†…å­˜å ç”¨ã€‚</li>
<li>GEMæé«˜äº†å±€éƒ¨åˆ†è¾¨ç‡ï¼Œå±•ç°å‡ºå…¶å®ç”¨æ€§å’Œå¯æ‰©å±•æ€§ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.25075">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-fa956f22c3340b883943b312c465da53" align="middle">
<img src="https://picx.zhimg.com/v2-74b768627ac4f35c3403590f587b28f4" align="middle">
<img src="https://picx.zhimg.com/v2-ef9e5ded2397c81ab2dc9802bb61d4c6" align="middle">
<img src="https://picx.zhimg.com/v2-1557ad8b97ce29fc80efc04215960b43" align="middle">
<img src="https://picx.zhimg.com/v2-4eb0fd7fa9cc595187d1910a39d8a9d1" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="LVT-Large-Scale-Scene-Reconstruction-via-Local-View-Transformers"><a href="#LVT-Large-Scale-Scene-Reconstruction-via-Local-View-Transformers" class="headerlink" title="LVT: Large-Scale Scene Reconstruction via Local View Transformers"></a>LVT: Large-Scale Scene Reconstruction via Local View Transformers</h2><p><strong>Authors:Tooba Imtiaz, Lucy Chai, Kathryn Heal, Xuan Luo, Jungyeon Park, Jennifer Dy, John Flynn</strong></p>
<p>Large transformer models are proving to be a powerful tool for 3D vision and novel view synthesis. However, the standard Transformerâ€™s well-known quadratic complexity makes it difficult to scale these methods to large scenes. To address this challenge, we propose the Local View Transformer (LVT), a large-scale scene reconstruction and novel view synthesis architecture that circumvents the need for the quadratic attention operation. Motivated by the insight that spatially nearby views provide more useful signal about the local scene composition than distant views, our model processes all information in a local neighborhood around each view. To attend to tokens in nearby views, we leverage a novel positional encoding that conditions on the relative geometric transformation between the query and nearby views. We decode the output of our model into a 3D Gaussian Splat scene representation that includes both color and opacity view-dependence. Taken together, the Local View Transformer enables reconstruction of arbitrarily large, high-resolution scenes in a single forward pass. See our project page for results and interactive demos <a target="_blank" rel="noopener" href="https://toobaimt.github.io/lvt/">https://toobaimt.github.io/lvt/</a>. </p>
<blockquote>
<p>å¤§å‹Transformeræ¨¡å‹è¢«è¯æ˜æ˜¯3Dè§†è§‰å’Œæ–°å‹è§†è§’åˆæˆçš„å¼ºå¤§å·¥å…·ã€‚ç„¶è€Œï¼Œæ ‡å‡†Transformerä¼—æ‰€å‘¨çŸ¥çš„äºŒæ¬¡å¤æ‚åº¦ä½¿å¾—å°†è¿™äº›æ–¹æ³•æ‰©å±•åˆ°å¤§å‹åœºæ™¯å˜å¾—å›°éš¾ã€‚ä¸ºäº†åº”å¯¹è¿™ä¸€æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†å±€éƒ¨è§†å›¾Transformerï¼ˆLVTï¼‰ï¼Œè¿™æ˜¯ä¸€ç§å¤§è§„æ¨¡åœºæ™¯é‡å»ºå’Œæ–°å‹è§†è§’åˆæˆæ¶æ„ï¼Œå®ƒé¿å…äº†äºŒæ¬¡æ³¨æ„åŠ›æ“ä½œçš„éœ€è¦ã€‚æˆ‘ä»¬çš„è§è§£æ˜¯ï¼Œç©ºé—´ä¸Šçš„é‚»è¿‘è§†å›¾æä¾›äº†å…³äºå±€éƒ¨åœºæ™¯ç»„æˆçš„æ›´æœ‰ç”¨çš„ä¿¡å·ï¼Œè€Œä¸æ˜¯è¿œå¤„çš„è§†å›¾ã€‚æˆ‘ä»¬çš„æ¨¡å‹å¤„ç†æ¯ä¸ªè§†å›¾å‘¨å›´å±€éƒ¨åŒºåŸŸçš„æ‰€æœ‰ä¿¡æ¯ã€‚ä¸ºäº†å…³æ³¨é‚»è¿‘è§†å›¾çš„æ ‡è®°ï¼Œæˆ‘ä»¬åˆ©ç”¨äº†ä¸€ç§æ–°å‹çš„ä½ç½®ç¼–ç ï¼Œè¯¥ç¼–ç ä»¥æŸ¥è¯¢å’Œé‚»è¿‘è§†å›¾ä¹‹é—´çš„ç›¸å¯¹å‡ ä½•å˜æ¢ä¸ºæ¡ä»¶ã€‚æˆ‘ä»¬å°†æ¨¡å‹çš„è¾“å‡ºè§£ç ä¸º3Dé«˜æ–¯Splatåœºæ™¯è¡¨ç¤ºï¼Œå…¶ä¸­åŒ…æ‹¬é¢œè‰²å’Œé€æ˜åº¦è§†å·®ä¾èµ–æ€§ã€‚ç»¼ä¸Šæ‰€è¿°ï¼Œå±€éƒ¨è§†å›¾Transformerèƒ½å¤Ÿåœ¨å•æ¬¡å‰å‘ä¼ é€’ä¸­è¿›è¡Œä»»æ„å¤§å°ã€é«˜åˆ†è¾¨ç‡åœºæ™¯çš„é‡å»ºã€‚æœ‰å…³ç»“æœå’Œäº¤äº’æ¼”ç¤ºï¼Œè¯·è®¿é—®æˆ‘ä»¬çš„é¡¹ç›®é¡µé¢ï¼š<a target="_blank" rel="noopener" href="https://toobaimt.github.io/lvt%E3%80%82">https://toobaimt.github.io/lvt/ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.25001v1">PDF</a> SIGGRAPH Asia 2025 camera-ready version; project page   <a target="_blank" rel="noopener" href="https://toobaimt.github.io/lvt/">https://toobaimt.github.io/lvt/</a></p>
<p><strong>æ‘˜è¦</strong></p>
<p>å¤§å‹Transformeræ¨¡å‹åœ¨3Dè§†è§‰å’Œæ–°é¢–è§†è§’åˆæˆæ–¹é¢å±•ç°å‡ºå¼ºå¤§çš„èƒ½åŠ›ã€‚ç„¶è€Œï¼Œå…¶å›ºæœ‰çš„äºŒæ¬¡å¤æ‚åº¦ä½¿å¾—éš¾ä»¥å°†è¿™äº›æ–¹æ³•æ‰©å±•åˆ°å¤§å‹åœºæ™¯ã€‚ä¸ºåº”å¯¹è¿™ä¸€æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†å±€éƒ¨è§†å›¾Transformerï¼ˆLVTï¼‰ï¼Œè¿™æ˜¯ä¸€ç§ç”¨äºå¤§è§„æ¨¡åœºæ™¯é‡å»ºå’Œæ–°é¢–è§†è§’åˆæˆçš„æ¶æ„ï¼Œå®ƒç»•è¿‡äº†äºŒæ¬¡æ³¨æ„åŠ›æ“ä½œçš„éœ€æ±‚ã€‚æˆ‘ä»¬çš„æ¨¡å‹å—åˆ°å¯å‘ï¼Œå³ç©ºé—´é‚»è¿‘çš„è§†å›¾ä¸ºå±€éƒ¨åœºæ™¯ç»„åˆæä¾›äº†æ›´æœ‰ç”¨çš„ä¿¡å·ï¼Œè€Œéè¿œè·ç¦»è§†å›¾ã€‚è¯¥æ¨¡å‹å¤„ç†æ¯ä¸ªè§†å›¾å‘¨å›´å±€éƒ¨é‚»åŸŸçš„æ‰€æœ‰ä¿¡æ¯ã€‚ä¸ºäº†å…³æ³¨é‚»è¿‘è§†å›¾çš„æ ‡è®°ï¼Œæˆ‘ä»¬åˆ©ç”¨äº†ä¸€ç§æ–°å‹çš„ä½ç½®ç¼–ç ï¼Œè¯¥ç¼–ç ä»¥æŸ¥è¯¢å’Œé‚»è¿‘è§†å›¾ä¹‹é—´çš„ç›¸å¯¹å‡ ä½•å˜æ¢ä¸ºæ¡ä»¶ã€‚æˆ‘ä»¬å°†æ¨¡å‹çš„è¾“å‡ºè§£ç ä¸ºåŒ…å«é¢œè‰²å’Œé€æ˜åº¦è§†å·®ä¾èµ–æ€§çš„3Dé«˜æ–¯Splatåœºæ™¯è¡¨ç¤ºã€‚æ€»çš„æ¥è¯´ï¼ŒLocal View Transformerèƒ½å¤Ÿåœ¨å•æ¬¡å‰å‘ä¼ é€’ä¸­å®ç°ä»»æ„å¤§è§„æ¨¡é«˜åˆ†è¾¨ç‡åœºæ™¯çš„é‡å»ºã€‚æœ‰å…³ç»“æœå’Œäº¤äº’å¼æ¼”ç¤ºï¼Œè¯·è®¿é—®æˆ‘ä»¬çš„é¡¹ç›®é¡µé¢ <a target="_blank" rel="noopener" href="https://toobaimt.github.io/lvt/%E3%80%82">https://toobaimt.github.io/lvt/ã€‚</a></p>
<p><strong>è¦ç‚¹</strong></p>
<ol>
<li>å¤§å‹Transformeræ¨¡å‹åœ¨3Dè§†è§‰å’Œæ–°é¢–è§†è§’åˆæˆä¸­å…·æœ‰å¼ºå¤§èƒ½åŠ›ã€‚</li>
<li>æ ‡å‡†Transformerçš„äºŒæ¬¡å¤æ‚åº¦é™åˆ¶äº†å…¶åœ¨å¤§å‹åœºæ™¯ä¸­çš„åº”ç”¨ã€‚</li>
<li>æå‡ºäº†å±€éƒ¨è§†å›¾Transformerï¼ˆLVTï¼‰æ¶æ„ï¼Œä»¥è§„é¿äºŒæ¬¡æ³¨æ„åŠ›æ“ä½œã€‚</li>
<li>LVTåˆ©ç”¨ç©ºé—´é‚»è¿‘è§†å›¾çš„ä¿¡æ¯ï¼Œå¤„ç†æ¯ä¸ªè§†å›¾çš„å±€éƒ¨é‚»åŸŸæ•°æ®ã€‚</li>
<li>é€šè¿‡æ–°å‹ä½ç½®ç¼–ç å…³æ³¨é‚»è¿‘è§†å›¾çš„æ ‡è®°ã€‚</li>
<li>å°†æ¨¡å‹è¾“å‡ºè§£ç ä¸ºåŒ…å«é¢œè‰²å’Œé€æ˜åº¦è§†å·®ä¾èµ–æ€§çš„3Dé«˜æ–¯Splatåœºæ™¯è¡¨ç¤ºã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.25001">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-db8e0022fd8d8271ec799bfb93395af8.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-61cfad152ebba616b6ea323073e6ec5f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-cdba2a5c876d223f4c90b7bd9dc642fb" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="DWGS-Enhancing-Sparse-View-Gaussian-Splatting-with-Hybrid-Loss-Depth-Estimation-and-Bidirectional-Warping"><a href="#DWGS-Enhancing-Sparse-View-Gaussian-Splatting-with-Hybrid-Loss-Depth-Estimation-and-Bidirectional-Warping" class="headerlink" title="DWGS: Enhancing Sparse-View Gaussian Splatting with Hybrid-Loss Depth   Estimation and Bidirectional Warping"></a>DWGS: Enhancing Sparse-View Gaussian Splatting with Hybrid-Loss Depth   Estimation and Bidirectional Warping</h2><p><strong>Authors:Yu Ma, Guoliang Wei, Yue Cheng</strong></p>
<p>Novel View Synthesis (NVS) from sparse views remains a core challenge in 3D reconstruction, typically suffering from overfitting, geometric distortion, and incomplete scene recovery due to limited multi-view constraints. Although 3D Gaussian Splatting (3DGS) enables real-time, high-fidelity rendering, it suffers from floating artifacts and structural inconsistencies under sparse-input settings. To address these issues, we propose DWGS, a novel unified framework that enhances 3DGS for sparse-view synthesis by integrating robust structural cues, virtual view constraints, and occluded region completion. Our approach introduces three principal contributions: a Hybrid-Loss Depth Estimation module that leverages dense matching priors with reprojection, point propagation, and smoothness constraints to enforce multi-view consistency; a Bidirectional Warping Virtual View Synthesis method generates virtual training views to impose stronger geometric and photometric constraints; and an Occlusion-Aware Reconstruction component that utilizes depth-difference mask and a learning-based inpainting model to recover obscured regions. Extensive experiments on standard benchmarks (LLFF, Blender, and DTU) show that DWGS achieves a new state-of-the-art, achieving up to 21.13 dB PSNR and 0.189 LPIPS, while retaining real-time inference capabilities. </p>
<blockquote>
<p>é’ˆå¯¹ç¨€ç–è§†è§’è¿›è¡Œçš„æ–°è§†è§’åˆæˆï¼ˆNVSï¼‰ä»ç„¶æ˜¯ä¸‰ç»´é‡å»ºä¸­çš„æ ¸å¿ƒæŒ‘æˆ˜ã€‚è¿™é€šå¸¸ç”±äºæœ‰é™çš„å¤šè§’åº¦çº¦æŸè€Œé­å—è¿‡æ‹Ÿåˆã€å‡ ä½•å¤±çœŸå’Œåœºæ™¯æ¢å¤ä¸å®Œæ•´ç­‰é—®é¢˜ã€‚è™½ç„¶ä¸‰ç»´é«˜æ–¯å»¶å±•ï¼ˆ3DGSï¼‰èƒ½å¤Ÿå®ç°å®æ—¶é«˜ä¿çœŸæ¸²æŸ“ï¼Œä½†åœ¨ç¨€ç–è¾“å…¥è®¾ç½®ä¸‹ä¼šå‡ºç°æµ®åŠ¨ä¼ªå½±å’Œç»“æ„ä¸ä¸€è‡´çš„é—®é¢˜ã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†DWGSï¼Œè¿™æ˜¯ä¸€ç§æ–°å‹ç»Ÿä¸€æ¡†æ¶ï¼Œå®ƒé€šè¿‡é›†æˆç¨³å¥çš„ç»“æ„çº¿ç´¢ã€è™šæ‹Ÿè§†å›¾çº¦æŸå’Œé®æŒ¡åŒºåŸŸå®Œæˆæ¥å¢å¼º3DGSçš„ç¨€ç–è§†å›¾åˆæˆåŠŸèƒ½ã€‚æˆ‘ä»¬çš„æ–¹æ³•å¼•å…¥äº†ä¸‰ä¸ªä¸»è¦è´¡çŒ®ï¼šä¸€ä¸ªæ··åˆæŸå¤±æ·±åº¦ä¼°è®¡æ¨¡å—ï¼Œå®ƒåˆ©ç”¨å¯†é›†åŒ¹é…å…ˆéªŒä¸é‡æŠ•å½±ã€ç‚¹ä¼ æ’­å’Œå¹³æ»‘çº¦æŸæ¥å¼ºåˆ¶æ‰§è¡Œå¤šè§†è§’ä¸€è‡´æ€§ï¼›ä¸€ç§åŒå‘æ‰­æ›²è™šæ‹Ÿè§†å›¾åˆæˆæ–¹æ³•ï¼Œç”Ÿæˆè™šæ‹Ÿè®­ç»ƒè§†å›¾ä»¥æ–½åŠ æ›´å¼ºçš„å‡ ä½•å’Œå…‰åº¦çº¦æŸï¼›ä¸€ä¸ªåˆ©ç”¨æ·±åº¦å·®å¼‚æ©è†œå’Œå­¦ä¹ å‹è¡¥å…¨æ¨¡å‹çš„é®æŒ¡æ„ŸçŸ¥é‡å»ºç»„ä»¶ï¼Œä»¥æ¢å¤é®æŒ¡åŒºåŸŸã€‚åœ¨æ ‡å‡†åŸºå‡†æµ‹è¯•ï¼ˆLLFFã€Blenderå’ŒDTUï¼‰ä¸Šçš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼ŒDWGSè¾¾åˆ°äº†æœ€æ–°æ°´å¹³çš„æŠ€æœ¯æ•ˆæœï¼ŒPSNRè¾¾åˆ°äº†æœ€é«˜å¯è¾¾21.13åˆ†è´ï¼ŒLPIPSä¸º0.189ï¼ŒåŒæ—¶ä¿æŒäº†å®æ—¶æ¨ç†èƒ½åŠ›ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.24893v1">PDF</a> 14 pages, 21 figures</p>
<p><strong>Summary</strong></p>
<p>åŸºäºç¨€ç–è§†è§’è¿›è¡Œæ–°å‹è§†å›¾åˆæˆï¼ˆNVSï¼‰æ˜¯3Dé‡å»ºä¸­çš„æ ¸å¿ƒæŒ‘æˆ˜ä¹‹ä¸€ï¼Œé¢ä¸´è¿‡æ‹Ÿåˆã€å‡ ä½•å¤±çœŸå’Œåœºæ™¯æ¢å¤ä¸å®Œå…¨ç­‰é—®é¢˜ã€‚è™½ç„¶3Dé«˜æ–¯å±•å¸ƒï¼ˆ3DGSï¼‰èƒ½å¤Ÿå®ç°å®æ—¶é«˜ä¿çœŸæ¸²æŸ“ï¼Œä½†åœ¨ç¨€ç–è¾“å…¥è®¾ç½®ä¸‹ä¼šå‡ºç°æµ®åŠ¨ä¼ªå½±å’Œç»“æ„ä¸ä¸€è‡´ç­‰é—®é¢˜ã€‚ä¸ºè§£å†³è¿™äº›é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†DWGSï¼Œä¸€ç§å¢å¼º3DGSç”¨äºç¨€ç–è§†å›¾åˆæˆçš„ç»Ÿä¸€æ¡†æ¶ï¼Œé€šè¿‡é›†æˆç¨³å¥çš„ç»“æ„çº¿ç´¢ã€è™šæ‹Ÿè§†å›¾çº¦æŸå’Œé®æŒ¡åŒºåŸŸå®Œæˆç­‰æŠ€æœ¯ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>NVSåœ¨3Dé‡å»ºä¸­é¢ä¸´æŒ‘æˆ˜ï¼Œå¦‚è¿‡æ‹Ÿåˆã€å‡ ä½•å¤±çœŸå’Œåœºæ™¯æ¢å¤ä¸å®Œå…¨ã€‚</li>
<li>3DGSèƒ½å¤Ÿå®ç°å®æ—¶é«˜ä¿çœŸæ¸²æŸ“ï¼Œä½†åœ¨ç¨€ç–è¾“å…¥ä¸‹å­˜åœ¨æµ®åŠ¨ä¼ªå½±å’Œç»“æ„ä¸ä¸€è‡´é—®é¢˜ã€‚</li>
<li>DWGSæ¡†æ¶é€šè¿‡é›†æˆç»“æ„çº¿ç´¢ã€è™šæ‹Ÿè§†å›¾çº¦æŸå’Œé®æŒ¡åŒºåŸŸå®ŒæˆæŠ€æœ¯ï¼Œå¢å¼ºäº†3DGSåœ¨ç¨€ç–è§†å›¾åˆæˆä¸­çš„æ€§èƒ½ã€‚</li>
<li>DWGSå¼•å…¥äº†Hybrid-Lossæ·±åº¦ä¼°è®¡æ¨¡å—ï¼Œåˆ©ç”¨å¯†é›†åŒ¹é…å…ˆéªŒå’Œé‡æŠ•å½±æŠ€æœ¯ï¼Œå®ç°å¤šè§†è§’ä¸€è‡´æ€§ã€‚</li>
<li>Bidirectional Warping Virtual View Synthesisæ–¹æ³•ç”Ÿæˆè™šæ‹Ÿè®­ç»ƒè§†å›¾ï¼Œä»¥åŠ å¼ºå‡ ä½•å’Œå…‰åº¦çº¦æŸã€‚</li>
<li>DWGSå…·æœ‰é®æŒ¡æ„ŸçŸ¥é‡å»ºç»„ä»¶ï¼Œåˆ©ç”¨æ·±åº¦å·®å¼‚æ©è†œå’Œå­¦ä¹ å‹å¡«å……æ¨¡å‹æ¥æ¢å¤é®æŒ¡åŒºåŸŸã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.24893">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-8ac5643ce3ec03ab25fcc7f3b2a70609.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-92a0ada21c91d99a295c63b3a99737cc" align="middle">
<img src="https://picx.zhimg.com/v2-56a70c888dba8986675bea9abfe5d32d" align="middle">
<img src="https://picx.zhimg.com/v2-fe3e179cb2b29487bc294a4b02f0bc78" align="middle">
<img src="https://picx.zhimg.com/v2-e663a3fb6d8b84d24ee40a2c5809be14" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="ExGS-Extreme-3D-Gaussian-Compression-with-Diffusion-Priors"><a href="#ExGS-Extreme-3D-Gaussian-Compression-with-Diffusion-Priors" class="headerlink" title="ExGS: Extreme 3D Gaussian Compression with Diffusion Priors"></a>ExGS: Extreme 3D Gaussian Compression with Diffusion Priors</h2><p><strong>Authors:Jiaqi Chen, Xinhao Ji, Yuanyuan Gao, Hao Li, Yuning Gong, Yifei Liu, Dan Xu, Zhihang Zhong, Dingwen Zhang, Xiao Sun</strong></p>
<p>Neural scene representations, such as 3D Gaussian Splatting (3DGS), have enabled high-quality neural rendering; however, their large storage and transmission costs hinder deployment in resource-constrained environments. Existing compression methods either rely on costly optimization, which is slow and scene-specific, or adopt training-free pruning and quantization, which degrade rendering quality under high compression ratios. In contrast, recent data-driven approaches provide a promising direction to overcome this trade-off, enabling efficient compression while preserving high rendering quality. We introduce \textbf{ExGS}, a novel feed-forward framework that unifies \textbf{Universal Gaussian Compression} (UGC) with \textbf{GaussPainter} for \textbf{Ex}treme 3D\textbf{GS} compression. \textbf{UGC} performs re-optimization-free pruning to aggressively reduce Gaussian primitives while retaining only essential information, whereas \textbf{GaussPainter} leverages powerful diffusion priors with mask-guided refinement to restore high-quality renderings from heavily pruned Gaussian scenes. Unlike conventional inpainting, GaussPainter not only fills in missing regions but also enhances visible pixels, yielding substantial improvements in degraded renderings. To ensure practicality, it adopts a lightweight VAE and a one-step diffusion design, enabling real-time restoration. Our framework can even achieve over $100\times$ compression (reducing a typical 354.77 MB model to about 3.31 MB) while preserving fidelity and significantly improving image quality under challenging conditions. These results highlight the central role of diffusion priors in bridging the gap between extreme compression and high-quality neural rendering. Our code repository will be released at \href{<a target="_blank" rel="noopener" href="https://github.com/chenttt2001/ExGS%7D%7Bhere%7D">https://github.com/chenttt2001/ExGS}{here}</a>. </p>
<blockquote>
<p>ç¥ç»åœºæ™¯è¡¨ç¤ºï¼Œå¦‚3Dé«˜æ–¯æ‹¼è´´ï¼ˆ3DGSï¼‰ï¼Œå·²ç»å®ç°äº†é«˜è´¨é‡çš„ç¥çº§æ¸²æŸ“ï¼›ç„¶è€Œï¼Œå…¶å·¨å¤§çš„å­˜å‚¨å’Œä¼ è¾“æˆæœ¬é˜»ç¢äº†å…¶åœ¨èµ„æºå—é™ç¯å¢ƒä¸­çš„éƒ¨ç½²ã€‚ç°æœ‰çš„å‹ç¼©æ–¹æ³•è¦ä¹ˆä¾èµ–äºæ˜‚è´µçš„ä¼˜åŒ–ï¼Œè¿™æ—¢ç¼“æ…¢åˆé’ˆå¯¹ç‰¹å®šåœºæ™¯ï¼Œè¦ä¹ˆé‡‡ç”¨æ— è®­ç»ƒè£å‰ªå’Œé‡åŒ–ï¼Œè¿™åœ¨é«˜å‹ç¼©æ¯”çš„æƒ…å†µä¸‹ä¼šé™ä½æ¸²æŸ“è´¨é‡ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼Œæœ€è¿‘çš„æ•°æ®é©±åŠ¨æ–¹æ³•æä¾›äº†ä¸€ä¸ªå…‹æœè¿™ç§æƒè¡¡çš„æœ‰å‰é€”çš„æ–¹å‘ï¼Œèƒ½å¤Ÿåœ¨ä¿æŒé«˜æ¸²æŸ“è´¨é‡çš„åŒæ—¶å®ç°é«˜æ•ˆå‹ç¼©ã€‚æˆ‘ä»¬ä»‹ç»äº†ExGSï¼Œè¿™æ˜¯ä¸€ç§æ–°é¢–çš„å‰é¦ˆæ¡†æ¶ï¼Œå®ƒå°†é€šç”¨é«˜æ–¯å‹ç¼©ï¼ˆUGCï¼‰ä¸GaussPainterç›¸ç»“åˆï¼Œç”¨äºæç«¯3DGSå‹ç¼©ã€‚UGCé€šè¿‡æ— ä¼˜åŒ–é‡æ–°è£å‰ªçš„æ–¹å¼ï¼Œå¤§å¹…å‡å°‘é«˜æ–¯åŸºæœ¬ä½“ï¼ŒåŒæ—¶ä»…ä¿ç•™å¿…è¦ä¿¡æ¯ï¼Œè€ŒGaussPainteråˆ™åˆ©ç”¨å¼ºå¤§çš„æ‰©æ•£å…ˆéªŒå’Œæ©è†œå¯¼å‘ç»†åŒ–ï¼Œä»å¤§é‡è£å‰ªçš„é«˜æ–¯åœºæ™¯ä¸­æ¢å¤é«˜è´¨é‡æ¸²æŸ“ã€‚ä¸å¸¸è§„è¡¥å…¨ä¸åŒï¼ŒGaussPainterä¸ä»…å¡«å……ç¼ºå¤±åŒºåŸŸï¼Œè¿˜å¢å¼ºå¯è§åƒç´ ï¼Œå¤§å¤§æ”¹å–„é€€åŒ–æ¸²æŸ“çš„æ•ˆæœã€‚ä¸ºä¿è¯å®ç”¨æ€§ï¼Œå®ƒé‡‡ç”¨è½»é‡çº§VAEå’Œä¸€æ­¥æ‰©æ•£è®¾è®¡ï¼Œå®ç°å®æ—¶æ¢å¤ã€‚æˆ‘ä»¬çš„æ¡†æ¶ç”šè‡³å¯ä»¥å®ç°è¶…è¿‡100å€çš„å‹ç¼©ï¼ˆå°†ä¸€ä¸ªå…¸å‹çš„354.77 MBæ¨¡å‹å‹ç¼©åˆ°çº¦3.31 MBï¼‰ï¼ŒåŒæ—¶ä¿æŒä¿çœŸåº¦å¹¶åœ¨å…·æœ‰æŒ‘æˆ˜æ€§çš„æ¡ä»¶ä¸‹æ˜¾è‘—æé«˜å›¾åƒè´¨é‡ã€‚è¿™äº›ç»“æœå‡¸æ˜¾äº†æ‰©æ•£å…ˆéªŒåœ¨å¼¥åˆæç«¯å‹ç¼©ä¸é«˜è´¨é‡ç¥ç»æ¸²æŸ“ä¹‹é—´çš„å·®è·ä¸­çš„æ ¸å¿ƒä½œç”¨ã€‚æˆ‘ä»¬çš„ä»£ç ä»“åº“å°†å‘å¸ƒåœ¨[<a target="_blank" rel="noopener" href="https://github.com/chenttt2001/ExGS]%EF%BC%88%E7%82%B9%E5%87%BB%E6%AD%A4%E5%A4%84%EF%BC%89%E3%80%82">https://github.com/chenttt2001/ExGS]ï¼ˆç‚¹å‡»æ­¤å¤„ï¼‰ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.24758v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>åŸºäºç¥ç»ç½‘ç»œåœºæ™¯è¡¨ç¤ºï¼ˆå¦‚3DGSï¼‰çš„é«˜è´¨é‡ç¥ç»æ¸²æŸ“å·²ç»å®ç°ï¼Œä½†å…¶å­˜å‚¨å’Œä¼ è¾“æˆæœ¬è¾ƒé«˜ï¼Œä¸é€‚ç”¨äºèµ„æºå—é™çš„ç¯å¢ƒã€‚ç°æœ‰å‹ç¼©æ–¹æ³•å­˜åœ¨ä¼˜åŒ–æˆæœ¬é«˜æˆ–å‹ç¼©è´¨é‡ä¸‹é™çš„é—®é¢˜ã€‚æœ¬æ–‡æå‡ºä¸€ç§æ–°é¢–çš„å‰é¦ˆæ¡†æ¶ExGSï¼Œç»“åˆé€šç”¨é«˜æ–¯å‹ç¼©ï¼ˆUGCï¼‰ä¸GaussPainteræŠ€æœ¯å®ç°æç«¯3DGSå‹ç¼©ï¼Œå¯åœ¨ä¿ç•™é‡è¦ä¿¡æ¯çš„åŒæ—¶è¿›è¡Œå¤§å¹…åº¦çš„é«˜æ–¯åŸå§‹æ•°æ®ç¼©å‡ï¼Œå¹¶åˆ©ç”¨æ‰©æ•£å…ˆéªŒä¸æ©è†œå¯¼å‘çš„ç»†åŒ–æŠ€æœ¯æ¢å¤é«˜è´¨é‡æ¸²æŸ“ã€‚ExGSå®ç°äº†è¶…è¿‡$100\times$çš„å‹ç¼©ç‡ï¼ŒåŒæ—¶åœ¨å…·æœ‰æŒ‘æˆ˜æ€§çš„æ¡ä»¶ä¸‹ä¿æŒäº†ä¿çœŸåº¦å’Œå›¾åƒè´¨é‡çš„æ˜¾è‘—æé«˜ã€‚ä»£ç åº“å·²å‘å¸ƒåœ¨<a target="_blank" rel="noopener" href="https://github.com/chenttt2001/ExGS%E3%80%82">https://github.com/chenttt2001/ExGSã€‚</a></p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ç¥ç»ç½‘ç»œåœºæ™¯è¡¨ç¤ºï¼ˆå¦‚3DGSï¼‰å¯å®ç°é«˜è´¨é‡ç¥ç»æ¸²æŸ“ï¼Œä½†å­˜å‚¨å’Œä¼ è¾“æˆæœ¬è¾ƒé«˜ã€‚</li>
<li>ç°æœ‰å‹ç¼©æ–¹æ³•å­˜åœ¨ä¼˜åŒ–æˆæœ¬é«˜æ˜‚æˆ–å‹ç¼©è´¨é‡ä¸‹é™çš„é—®é¢˜ã€‚</li>
<li>æœ¬æ–‡æå‡ºçš„å‰é¦ˆæ¡†æ¶ExGSç»“åˆäº†é€šç”¨é«˜æ–¯å‹ç¼©ï¼ˆUGCï¼‰ä¸GaussPainteræŠ€æœ¯ã€‚</li>
<li>UGCå¯è¿›è¡Œæ— ä¼˜åŒ–é‡æ„çš„ä¿®å‰ªï¼Œå¤§å¹…åº¦å‡å°‘é«˜æ–¯åŸå§‹æ•°æ®åŒæ—¶ä¿ç•™é‡è¦ä¿¡æ¯ã€‚</li>
<li>GaussPainteråˆ©ç”¨æ‰©æ•£å…ˆéªŒå’Œæ©è†œå¯¼å‘ç»†åŒ–æŠ€æœ¯æ¢å¤é«˜è´¨é‡æ¸²æŸ“ã€‚</li>
<li>ExGSå®ç°äº†è¶…è¿‡$100\times$çš„å‹ç¼©ç‡ï¼Œæ˜¾è‘—é™ä½å­˜å‚¨å’Œä¼ è¾“æˆæœ¬ã€‚</li>
<li>ExGSåœ¨ä¿æŒå›¾åƒè´¨é‡çš„åŒæ—¶ï¼Œå®ç°äº†é«˜å‹ç¼©ç‡ï¼Œä»£ç åº“å·²å…¬å¼€å‘å¸ƒã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.24758">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-e8b33413045360d304ed93e0a93240ee" align="middle">
<img src="https://picx.zhimg.com/v2-6529708a509e023a787c68d2b7c1600d.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-58c8c2375758fc99b6352ca92e698ffb.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-c88ffa60e1b77e3bc2c14f7f135ced27.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="OMeGa-Joint-Optimization-of-Explicit-Meshes-and-Gaussian-Splats-for-Robust-Scene-Level-Surface-Reconstruction"><a href="#OMeGa-Joint-Optimization-of-Explicit-Meshes-and-Gaussian-Splats-for-Robust-Scene-Level-Surface-Reconstruction" class="headerlink" title="OMeGa: Joint Optimization of Explicit Meshes and Gaussian Splats for   Robust Scene-Level Surface Reconstruction"></a>OMeGa: Joint Optimization of Explicit Meshes and Gaussian Splats for   Robust Scene-Level Surface Reconstruction</h2><p><strong>Authors:Yuhang Cao, Haojun Yan, Danya Yao</strong></p>
<p>Neural rendering with Gaussian splatting has advanced novel view synthesis, and most methods reconstruct surfaces via post-hoc mesh extraction. However, existing methods suffer from two limitations: (i) inaccurate geometry in texture-less indoor regions, and (ii) the decoupling of mesh extraction from optimization, thereby missing the opportunity to leverage mesh geometry to guide splat optimization. In this paper, we present OMeGa, an end-to-end framework that jointly optimizes an explicit triangle mesh and 2D Gaussian splats via a flexible binding strategy, where spatial attributes of Gaussian Splats are expressed in the mesh frame and texture attributes are retained on splats. To further improve reconstruction accuracy, we integrate mesh constraints and monocular normal supervision into the optimization, thereby regularizing geometry learning. In addition, we propose a heuristic, iterative mesh-refinement strategy that splits high-error faces and prunes unreliable ones to further improve the detail and accuracy of the reconstructed mesh. OMeGa achieves state-of-the-art performance on challenging indoor reconstruction benchmarks, reducing Chamfer-$L_1$ by 47.3% over the 2DGS baseline while maintaining competitive novel-view rendering quality. The experimental results demonstrate that OMeGa effectively addresses prior limitations in indoor texture-less reconstruction. </p>
<blockquote>
<p>ç¥ç»æ¸²æŸ“ä¸é«˜æ–¯å¹³é“ºæŠ€æœ¯å·²ç»æ¨åŠ¨äº†æ–°å‹è§†å›¾åˆæˆçš„è¿›æ­¥ï¼Œå¤§å¤šæ•°æ–¹æ³•é€šè¿‡äº‹åç½‘æ ¼æå–è¿›è¡Œè¡¨é¢é‡å»ºã€‚ç„¶è€Œï¼Œç°æœ‰æ–¹æ³•å­˜åœ¨ä¸¤ä¸ªå±€é™æ€§ï¼šï¼ˆiï¼‰åœ¨çº¹ç†è¾ƒå°‘çš„å®¤å†…åŒºåŸŸå‡ ä½•å½¢çŠ¶ä¸å‡†ç¡®ï¼›ï¼ˆiiï¼‰ç½‘æ ¼æå–ä¸ä¼˜åŒ–ä¹‹é—´çš„è§£è€¦ï¼Œä»è€Œå¤±å»äº†åˆ©ç”¨ç½‘æ ¼å‡ ä½•æ¥å¼•å¯¼å¹³é“ºä¼˜åŒ–çš„æœºä¼šã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬ä»‹ç»äº†OMeGaï¼Œè¿™æ˜¯ä¸€ä¸ªç«¯åˆ°ç«¯çš„æ¡†æ¶ï¼Œå®ƒé€šè¿‡çµæ´»çš„ç»‘å®šç­–ç•¥è”åˆä¼˜åŒ–æ˜ç¡®çš„ä¸‰è§’å½¢ç½‘æ ¼å’ŒäºŒç»´é«˜æ–¯å¹³é“ºï¼Œå…¶ä¸­é«˜æ–¯å¹³é“ºçš„ç©ºé—´å±æ€§åœ¨ç½‘æ ¼æ¡†æ¶ä¸­è¡¨ç¤ºï¼Œçº¹ç†å±æ€§ä¿ç•™åœ¨å¹³é“ºä¸Šã€‚ä¸ºäº†è¿›ä¸€æ­¥æé«˜é‡å»ºç²¾åº¦ï¼Œæˆ‘ä»¬å°†ç½‘æ ¼çº¦æŸå’Œå•ç›®æ³•çº¿ç›‘ç£é›†æˆåˆ°ä¼˜åŒ–ä¸­ï¼Œä»è€Œè§„èŒƒå‡ ä½•å­¦ä¹ ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§å¯å‘å¼è¿­ä»£ç½‘æ ¼ç»†åŒ–ç­–ç•¥ï¼Œåˆ†è£‚é«˜è¯¯å·®é¢å¹¶åˆ é™¤ä¸å¯é çš„é¢ï¼Œä»¥è¿›ä¸€æ­¥æé«˜é‡å»ºç½‘æ ¼çš„ç»†èŠ‚å’Œå‡†ç¡®æ€§ã€‚OMeGaåœ¨å…·æœ‰æŒ‘æˆ˜æ€§çš„å®¤å†…é‡å»ºåŸºå‡†æµ‹è¯•ä¸­å®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œåœ¨ä¿æŒç«äº‰åŠ›æ–°é¢–è§†å›¾æ¸²æŸ“è´¨é‡çš„åŒæ—¶ï¼Œç›¸å¯¹äºäºŒç»´é«˜æ–¯å¹³é“ºåŸºçº¿å‡å°‘äº†Chamfer-$L_1$çš„è¯¯å·®ç™¾åˆ†æ¯”è¾¾47.3%ã€‚å®éªŒç»“æœè¯æ˜ï¼ŒOMeGaæœ‰æ•ˆåœ°è§£å†³äº†å…ˆå‰åœ¨å®¤å†…æ— çº¹ç†é‡å»ºä¸­çš„å±€é™æ€§ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.24308v1">PDF</a> 12 pages, 9 figures</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸ºOMeGaçš„ç«¯åˆ°ç«¯æ¡†æ¶ï¼Œè¯¥æ¡†æ¶é€šè¿‡çµæ´»çš„ç»‘å®šç­–ç•¥è”åˆä¼˜åŒ–æ˜¾å¼ä¸‰è§’ç½‘æ ¼å’Œ2Dé«˜æ–¯è´´ç‰‡ã€‚OMeGaåœ¨ç½‘æ ¼æ¡†æ¶ä¸­è¡¨è¾¾é«˜æ–¯è´´ç‰‡çš„ç©ºé—´å±æ€§ï¼ŒåŒæ—¶ä¿ç•™è´´å›¾çš„çº¹ç†å±æ€§ï¼Œä»¥æé«˜é‡å»ºç²¾åº¦ã€‚é€šè¿‡æ•´åˆç½‘æ ¼çº¦æŸå’Œå•çœ¼æ­£å¸¸ç›‘ç£åˆ°ä¼˜åŒ–è¿‡ç¨‹ä¸­ï¼Œå®ç°äº†å‡ ä½•å­¦ä¹ çš„è§„èŒƒåŒ–ã€‚æ­¤å¤–ï¼ŒOMeGaè¿˜æå‡ºäº†ä¸€ç§å¯å‘å¼è¿­ä»£ç½‘æ ¼ç»†åŒ–ç­–ç•¥ï¼Œé€šè¿‡åˆ†è£‚é«˜è¯¯å·®é¢å’Œå‰”é™¤ä¸å¯é é¢ï¼Œè¿›ä¸€æ­¥æé«˜é‡å»ºç½‘æ ¼çš„ç»†èŠ‚å’Œç²¾åº¦ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒOMeGaåœ¨å…·æœ‰æŒ‘æˆ˜æ€§çš„å®¤å†…é‡å»ºåŸºå‡†æµ‹è¯•ä¸­å–å¾—äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œç›¸è¾ƒäº2DGSåŸºçº¿ï¼ŒChamfer-L1é™ä½äº†47.3%ï¼ŒåŒæ—¶ä¿æŒäº†å…·æœ‰ç«äº‰åŠ›çš„æ–°å‹è§†å›¾æ¸²æŸ“è´¨é‡ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>OMeGaæ˜¯ä¸€ä¸ªç«¯åˆ°ç«¯çš„æ¡†æ¶ï¼Œè”åˆä¼˜åŒ–ä¸‰è§’ç½‘æ ¼å’Œ2Dé«˜æ–¯è´´ç‰‡ï¼Œè§£å†³ç°æœ‰æ–¹æ³•çš„ä¸¤ä¸ªé™åˆ¶ã€‚</li>
<li>é€šè¿‡çµæ´»çš„ç»‘å®šç­–ç•¥ï¼ŒOMeGaåœ¨ç½‘æ ¼æ¡†æ¶ä¸­è¡¨è¾¾é«˜æ–¯è´´ç‰‡çš„ç©ºé—´å±æ€§ï¼ŒåŒæ—¶ä¿ç•™è´´å›¾çš„çº¹ç†å±æ€§ã€‚</li>
<li>æ•´åˆç½‘æ ¼çº¦æŸå’Œå•çœ¼æ­£å¸¸ç›‘ç£åˆ°ä¼˜åŒ–è¿‡ç¨‹ä¸­ï¼Œå®ç°äº†å‡ ä½•å­¦ä¹ çš„è§„èŒƒåŒ–ï¼Œæé«˜é‡å»ºç²¾åº¦ã€‚</li>
<li>OMeGaé‡‡ç”¨å¯å‘å¼è¿­ä»£ç½‘æ ¼ç»†åŒ–ç­–ç•¥ï¼Œé€šè¿‡åˆ†è£‚é«˜è¯¯å·®é¢å’Œå‰”é™¤ä¸å¯é é¢ï¼Œè¿›ä¸€æ­¥æé«˜é‡å»ºç½‘æ ¼çš„è´¨é‡ã€‚</li>
<li>OMeGaåœ¨å…·æœ‰æŒ‘æˆ˜æ€§çš„å®¤å†…é‡å»ºåŸºå‡†æµ‹è¯•ä¸­å–å¾—äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚</li>
<li>ç›¸è¾ƒäº2DGSåŸºçº¿ï¼ŒOMeGaçš„Chamfer-L1é™ä½äº†47.3%ï¼Œæ˜¾ç¤ºå‡ºå…¶ä¼˜ç§€çš„æ€§èƒ½ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.24308">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-173d5942141d12230e2eee120c22eb0a" align="middle">
<img src="https://picx.zhimg.com/v2-66098da7b2b2430df626d3f395c09f39" align="middle">
<img src="https://pic1.zhimg.com/v2-9d13557faf969d4ca8fdc27409fcbfef.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="Forge4D-Feed-Forward-4D-Human-Reconstruction-and-Interpolation-from-Uncalibrated-Sparse-view-Videos"><a href="#Forge4D-Feed-Forward-4D-Human-Reconstruction-and-Interpolation-from-Uncalibrated-Sparse-view-Videos" class="headerlink" title="Forge4D: Feed-Forward 4D Human Reconstruction and Interpolation from   Uncalibrated Sparse-view Videos"></a>Forge4D: Feed-Forward 4D Human Reconstruction and Interpolation from   Uncalibrated Sparse-view Videos</h2><p><strong>Authors:Yingdong Hu, Yisheng He, Jinnan Chen, Weihao Yuan, Kejie Qiu, Zehong Lin, Siyu Zhu, Zilong Dong, Jun Zhang</strong></p>
<p>Instant reconstruction of dynamic 3D humans from uncalibrated sparse-view videos is critical for numerous downstream applications. Existing methods, however, are either limited by the slow reconstruction speeds or incapable of generating novel-time representations. To address these challenges, we propose Forge4D, a feed-forward 4D human reconstruction and interpolation model that efficiently reconstructs temporally aligned representations from uncalibrated sparse-view videos, enabling both novel view and novel time synthesis. Our model simplifies the 4D reconstruction and interpolation problem as a joint task of streaming 3D Gaussian reconstruction and dense motion prediction. For the task of streaming 3D Gaussian reconstruction, we first reconstruct static 3D Gaussians from uncalibrated sparse-view images and then introduce learnable state tokens to enforce temporal consistency in a memory-friendly manner by interactively updating shared information across different timestamps. For novel time synthesis, we design a novel motion prediction module to predict dense motions for each 3D Gaussian between two adjacent frames, coupled with an occlusion-aware Gaussian fusion process to interpolate 3D Gaussians at arbitrary timestamps. To overcome the lack of the ground truth for dense motion supervision, we formulate dense motion prediction as a dense point matching task and introduce a self-supervised retargeting loss to optimize this module. An additional occlusion-aware optical flow loss is introduced to ensure motion consistency with plausible human movement, providing stronger regularization. Extensive experiments demonstrate the effectiveness of our model on both in-domain and out-of-domain datasets. Project page and code at: <a target="_blank" rel="noopener" href="https://zhenliuzju.github.io/huyingdong/Forge4D">https://zhenliuzju.github.io/huyingdong/Forge4D</a>. </p>
<blockquote>
<p>ä»æœªæ ¡å‡†çš„ç¨€ç–è§†è§’è§†é¢‘å³æ—¶é‡å»ºåŠ¨æ€3Däººä½“å¯¹äºè®¸å¤šä¸‹æ¸¸åº”ç”¨è‡³å…³é‡è¦ã€‚ç„¶è€Œï¼Œç°æœ‰æ–¹æ³•è¦ä¹ˆé‡å»ºé€Ÿåº¦æ…¢ï¼Œè¦ä¹ˆæ— æ³•ç”Ÿæˆæ–°é¢–çš„æ—¶é—´è¡¨ç¤ºã€‚ä¸ºäº†è§£å†³è¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†Forge4Dï¼Œä¸€ä¸ªå‰é¦ˆçš„4Däººä½“é‡å»ºå’Œæ’å€¼æ¨¡å‹ï¼Œå®ƒå¯ä»¥ä»æœªæ ¡å‡†çš„ç¨€ç–è§†è§’è§†é¢‘æœ‰æ•ˆåœ°é‡å»ºæ—¶é—´å¯¹é½çš„è¡¨ç¤ºï¼Œä»è€Œå®ç°æ–°é¢–è§†å›¾å’Œæ–°é¢–æ—¶é—´çš„åˆæˆã€‚æˆ‘ä»¬çš„æ¨¡å‹å°†4Dé‡å»ºå’Œæ’å€¼é—®é¢˜ç®€åŒ–ä¸ºæµå¼3Dé«˜æ–¯é‡å»ºå’Œå¯†é›†è¿åŠ¨é¢„æµ‹çš„å…±åŒä»»åŠ¡ã€‚å¯¹äºæµå¼3Dé«˜æ–¯é‡å»ºä»»åŠ¡ï¼Œæˆ‘ä»¬é¦–å…ˆä»æœªæ ¡å‡†çš„ç¨€ç–è§†è§’å›¾åƒé‡å»ºé™æ€3Dé«˜æ–¯ï¼Œç„¶åå¼•å…¥å¯å­¦ä¹ çš„çŠ¶æ€ä»¤ç‰Œï¼Œä»¥äº¤äº’æ–¹å¼æ›´æ–°ä¸åŒæ—¶é—´æˆ³ä¹‹é—´çš„å…±äº«ä¿¡æ¯ï¼Œä»¥å†…å­˜å‹å¥½çš„æ–¹å¼å¼ºåˆ¶æ‰§è¡Œæ—¶é—´ä¸€è‡´æ€§ã€‚å¯¹äºæ–°é¢–çš„æ—¶é—´åˆæˆï¼Œæˆ‘ä»¬è®¾è®¡äº†ä¸€ä¸ªæ–°é¢–çš„è¿åŠ¨é¢„æµ‹æ¨¡å—ï¼Œç”¨äºé¢„æµ‹ç›¸é‚»ä¸¤å¸§ä¹‹é—´æ¯ä¸ª3Dé«˜æ–¯å¯†é›†è¿åŠ¨ï¼Œç»“åˆä¸€ä¸ªé®æŒ¡æ„ŸçŸ¥çš„é«˜æ–¯èåˆè¿‡ç¨‹ï¼Œä»¥åœ¨ä»»æ„æ—¶é—´æˆ³æ’å€¼3Dé«˜æ–¯ã€‚ä¸ºäº†å…‹æœç¼ºä¹å¯†é›†è¿åŠ¨ç›‘ç£çš„åœ°é¢çœŸå®æ•°æ®ï¼Œæˆ‘ä»¬å°†å¯†é›†è¿åŠ¨é¢„æµ‹åˆ¶å®šä¸ºå¯†é›†ç‚¹åŒ¹é…ä»»åŠ¡ï¼Œå¹¶å¼•å…¥è‡ªç›‘ç£é‡å®šä½æŸå¤±æ¥ä¼˜åŒ–æ­¤æ¨¡å—ã€‚è¿˜å¼•å…¥äº†é¢å¤–çš„é®æŒ¡æ„ŸçŸ¥å…‰æµæŸå¤±ï¼Œä»¥ç¡®ä¿ä¸åˆç†çš„äººç±»è¿åŠ¨ä¸€è‡´çš„è¿åŠ¨ä¸€è‡´æ€§ï¼Œæä¾›æ›´å¼ºçš„æ­£åˆ™åŒ–ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ¨¡å‹åœ¨åŸŸå†…å’ŒåŸŸå¤–æ•°æ®é›†ä¸Šå‡æœ‰æ•ˆã€‚é¡¹ç›®é¡µé¢å’Œä»£ç åœ°å€ä¸ºï¼š<a target="_blank" rel="noopener" href="https://zhenliuzju.github.io/huyingdong/Forge4D%E3%80%82">https://zhenliuzju.github.io/huyingdong/Forge4Dã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.24209v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºä¸€ç§åä¸ºForge4Dçš„å‰é¦ˆ4Däººä½“é‡å»ºä¸æ’å€¼æ¨¡å‹ï¼Œå¯ä»æœªæ ¡å‡†çš„ç¨€ç–è§†è§’è§†é¢‘é«˜æ•ˆé‡å»ºæ—¶é—´å¯¹é½çš„è¡¨ç¤ºï¼Œå®ç°æ–°é¢–è§†è§’å’Œæ—¶é—´åˆæˆã€‚è¯¥æ¨¡å‹ç®€åŒ–äº†4Dé‡å»ºå’Œæ’å€¼é—®é¢˜ï¼Œå°†å…¶è§†ä¸ºæµå¼3Dé«˜æ–¯é‡å»ºå’Œå¯†é›†è¿åŠ¨é¢„æµ‹çš„å…±åŒä»»åŠ¡ã€‚é’ˆå¯¹æµå¼3Dé«˜æ–¯é‡å»ºä»»åŠ¡ï¼Œå…ˆä»æœªæ ¡å‡†çš„ç¨€ç–è§†è§’å›¾åƒé‡å»ºé™æ€3Dé«˜æ–¯ï¼Œç„¶åå¼•å…¥å¯å­¦ä¹ çŠ¶æ€ä»¤ç‰Œï¼Œä»¥äº¤äº’æ–¹å¼æ›´æ–°ä¸åŒæ—¶é—´æˆ³ä¹‹é—´çš„å…±äº«ä¿¡æ¯ï¼Œä»¥å†…å­˜å‹å¥½çš„æ–¹å¼å¼ºåˆ¶æ‰§è¡Œæ—¶é—´ä¸€è‡´æ€§ã€‚å¯¹äºæ–°é¢–æ—¶é—´åˆæˆï¼Œè®¾è®¡äº†ä¸€ç§æ–°é¢–çš„è¿åŠ¨é¢„æµ‹æ¨¡å—ï¼Œç”¨äºé¢„æµ‹ç›¸é‚»ä¸¤å¸§ä¹‹é—´æ¯ä¸ª3Dé«˜æ–¯å¯†é›†è¿åŠ¨ï¼Œå¹¶ç»“åˆé®æŒ¡æ„ŸçŸ¥é«˜æ–¯èåˆè¿‡ç¨‹ï¼Œå¯¹ä»»æ„æ—¶é—´æˆ³è¿›è¡Œ3Dé«˜æ–¯æ’å€¼ã€‚ä¸ºäº†è§£å†³ç¼ºä¹å¯†é›†è¿åŠ¨ç›‘ç£çš„åœ°é¢çœŸå®é—®é¢˜ï¼Œå°†å¯†é›†è¿åŠ¨é¢„æµ‹å…¬å¼åŒ–ä¸ºå¯†é›†ç‚¹åŒ¹é…ä»»åŠ¡ï¼Œå¹¶å¼•å…¥è‡ªæˆ‘ç›‘ç£çš„é‡æ–°å®šä½æŸå¤±æ¥ä¼˜åŒ–æ­¤æ¨¡å—ã€‚å¦å¤–ï¼Œå¼•å…¥äº†é®æŒ¡æ„ŸçŸ¥çš„å…‰æµæŸå¤±ï¼Œä»¥ç¡®ä¿ä¸åˆç†çš„äººç±»è¿åŠ¨ä¸€è‡´çš„è¿åŠ¨ä¸€è‡´æ€§ï¼Œæä¾›æ›´å¼ºå¤§çš„æ­£åˆ™åŒ–ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>Forge4Dæ˜¯ä¸€ä¸ªå‰é¦ˆ4Däººä½“é‡å»ºä¸æ’å€¼æ¨¡å‹ï¼Œç”¨äºä»ç¨€ç–è§†è§’è§†é¢‘é‡å»ºåŠ¨æ€3Däººä½“ã€‚</li>
<li>æ¨¡å‹èƒ½é«˜æ•ˆé‡å»ºæ—¶é—´å¯¹é½çš„è¡¨ç¤ºï¼Œå®ç°æ–°é¢–è§†è§’å’Œæ—¶é—´åˆæˆã€‚</li>
<li>æ¨¡å‹ç®€åŒ–4Dé‡å»ºå’Œæ’å€¼ä¸ºæµå¼3Dé«˜æ–¯é‡å»ºå’Œå¯†é›†è¿åŠ¨é¢„æµ‹ä»»åŠ¡ã€‚</li>
<li>å¼•å…¥å¯å­¦ä¹ çŠ¶æ€ä»¤ç‰Œä»¥å¼ºåˆ¶æ‰§è¡Œæ—¶é—´ä¸€è‡´æ€§ã€‚</li>
<li>è®¾è®¡æ–°é¢–è¿åŠ¨é¢„æµ‹æ¨¡å—ï¼Œé¢„æµ‹æ¯ä¸ª3Dé«˜æ–¯åœ¨ç›¸é‚»å¸§ä¹‹é—´çš„å¯†é›†è¿åŠ¨ã€‚</li>
<li>å¯†é›†è¿åŠ¨é¢„æµ‹è¢«å…¬å¼åŒ–ä¸ºå¯†é›†ç‚¹åŒ¹é…ä»»åŠ¡ï¼Œé€šè¿‡è‡ªæˆ‘ç›‘ç£çš„é‡æ–°å®šä½æŸå¤±è¿›è¡Œä¼˜åŒ–ã€‚</li>
<li>å¼•å…¥é®æŒ¡æ„ŸçŸ¥çš„å…‰æµæŸå¤±ä»¥ç¡®ä¿è¿åŠ¨ä¸€è‡´æ€§ï¼Œæä¾›æ›´å¼ºæ­£åˆ™åŒ–ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.24209">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-3154ae918df5c7176c3aef5249baf6e4" align="middle">
<img src="https://picx.zhimg.com/v2-577eb56c796256d8b4dc21cc785def2b" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="CrashSplat-2D-to-3D-Vehicle-Damage-Segmentation-in-Gaussian-Splatting"><a href="#CrashSplat-2D-to-3D-Vehicle-Damage-Segmentation-in-Gaussian-Splatting" class="headerlink" title="CrashSplat: 2D to 3D Vehicle Damage Segmentation in Gaussian Splatting"></a>CrashSplat: 2D to 3D Vehicle Damage Segmentation in Gaussian Splatting</h2><p><strong>Authors:DragoÅŸ-Andrei Chileban, Andrei-Åtefan Bulzan, Cosmin CernÇzanu-GlÇvan</strong></p>
<p>Automatic car damage detection has been a topic of significant interest for the auto insurance industry as it promises faster, accurate, and cost-effective damage assessments. However, few works have gone beyond 2D image analysis to leverage 3D reconstruction methods, which have the potential to provide a more comprehensive and geometrically accurate representation of the damage. Moreover, recent methods employing 3D representations for novel view synthesis, particularly 3D Gaussian Splatting (3D-GS), have demonstrated the ability to generate accurate and coherent 3D reconstructions from a limited number of views. In this work we introduce an automatic car damage detection pipeline that performs 3D damage segmentation by up-lifting 2D masks. Additionally, we propose a simple yet effective learning-free approach for single-view 3D-GS segmentation. Specifically, Gaussians are projected onto the image plane using camera parameters obtained via Structure from Motion (SfM). They are then filtered through an algorithm that utilizes Z-buffering along with a normal distribution model of depth and opacities. Through experiments we found that this method is particularly effective for challenging scenarios like car damage detection, where target objects (e.g., scratches, small dents) may only be clearly visible in a single view, making multi-view consistency approaches impractical or impossible. The code is publicly available at: <a target="_blank" rel="noopener" href="https://github.com/DragosChileban/CrashSplat">https://github.com/DragosChileban/CrashSplat</a>. </p>
<blockquote>
<p>è‡ªåŠ¨è½¦è¾†æŸä¼¤æ£€æµ‹å·²æˆä¸ºè½¦é™©è¡Œä¸šå…³æ³¨çš„ç„¦ç‚¹è¯é¢˜ï¼Œå› ä¸ºå®ƒèƒ½å¸¦æ¥æ›´å¿«é€Ÿã€å‡†ç¡®ã€ä¸”ç»æµçš„æŸä¼¤è¯„ä¼°æ–¹æ³•ã€‚ç„¶è€Œï¼Œå¾ˆå°‘æœ‰ç ”ç©¶è¶…è¶ŠäºŒç»´å›¾åƒåˆ†æï¼Œåˆ©ç”¨ä¸‰ç»´é‡å»ºæ–¹æ³•ï¼Œè¿™äº›æ–¹æ³•å…·æœ‰æä¾›æ›´å…¨é¢å’Œå‡ ä½•ä¸Šæ›´å‡†ç¡®çš„æŸä¼¤è¡¨å¾çš„æ½œåŠ›ã€‚æ­¤å¤–ï¼Œæœ€è¿‘é‡‡ç”¨ä¸‰ç»´è¡¨ç¤ºè¿›è¡Œæ–°é¢–è§†å›¾åˆæˆçš„æ–¹æ³•ï¼Œç‰¹åˆ«æ˜¯ä¸‰ç»´é«˜æ–¯è´´å›¾ï¼ˆ3D-GSï¼‰ï¼Œå·²ç»è¯æ˜èƒ½å¤Ÿä»æœ‰é™çš„è§†è§’ç”Ÿæˆå‡†ç¡®ä¸”è¿è´¯çš„ä¸‰ç»´é‡å»ºã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ä¸ªè‡ªåŠ¨è½¦è¾†æŸä¼¤æ£€æµ‹æµç¨‹ï¼Œé€šè¿‡æå‡äºŒç»´è’™ç‰ˆæ¥å®ç°ä¸‰ç»´æŸä¼¤åˆ†å‰²ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§ç®€å•æœ‰æ•ˆçš„æ— å­¦ä¹ å•è§†å›¾3D-GSåˆ†å‰²æ–¹æ³•ã€‚å…·ä½“æ¥è¯´ï¼Œé€šè¿‡ä½¿ç”¨é€šè¿‡è¿åŠ¨ç»“æ„ï¼ˆSfMï¼‰è·å¾—çš„ç›¸æœºå‚æ•°å°†é«˜æ–¯æŠ•å½±åˆ°å›¾åƒå¹³é¢ä¸Šã€‚ç„¶åï¼Œé€šè¿‡ä¸€ä¸ªåˆ©ç”¨æ·±åº¦å’Œä¸é€æ˜åº¦æ­£æ€åˆ†å¸ƒæ¨¡å‹çš„Zç¼“å†²ç®—æ³•è¿›è¡Œè¿‡æ»¤ã€‚é€šè¿‡å®éªŒæˆ‘ä»¬å‘ç°ï¼Œè¯¥æ–¹æ³•å¯¹äºè½¦è¾†æŸä¼¤æ£€æµ‹ç­‰å…·æœ‰æŒ‘æˆ˜æ€§çš„åœºæ™¯ç‰¹åˆ«æœ‰æ•ˆï¼Œåœ¨è¿™äº›åœºæ™¯ä¸­ï¼Œç›®æ ‡å¯¹è±¡ï¼ˆä¾‹å¦‚åˆ’ç—•ã€å°å‡¹é™·ï¼‰å¯èƒ½ä»…åœ¨å•ä¸ªè§†å›¾ä¸­æ¸…æ™°å¯è§ï¼Œä½¿å¾—å¤šè§†å›¾ä¸€è‡´æ€§æ–¹æ³•ä¸åˆ‡å®é™…æˆ–ä¸å¯èƒ½ã€‚ä»£ç å…¬å¼€åœ¨ï¼š<a target="_blank" rel="noopener" href="https://github.com/DragosChileban/CrashSplat%E3%80%82">https://github.com/DragosChileban/CrashSplatã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.23947v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†ä¸€ç§åŸºäº3Dé‡å»ºæ–¹æ³•çš„è‡ªåŠ¨æ±½è½¦æŸä¼¤æ£€æµ‹ç®¡é“ï¼Œé€šè¿‡æå‡2Dæ©è†œå®ç°3DæŸä¼¤åˆ†å‰²ï¼Œå¹¶æå‡ºäº†ä¸€ç§ç®€å•æœ‰æ•ˆçš„å­¦ä¹ æ— å…³çš„å•è§†å›¾3D-GSåˆ†å‰²æ–¹æ³•ã€‚è¯¥æ–¹æ³•åˆ©ç”¨SfMè·å¾—çš„ç›¸æœºå‚æ•°å°†é«˜æ–¯æŠ•å½±åˆ°å›¾åƒå¹³é¢ä¸Šï¼Œå¹¶é€šè¿‡ç»“åˆæ·±åº¦å’Œä¸é€æ˜åº¦çš„æ­£æ€åˆ†å¸ƒæ¨¡å‹çš„Zç¼“å†²ç®—æ³•è¿›è¡Œè¿‡æ»¤ã€‚æ­¤æ–¹æ³•å¯¹äºæ±½è½¦æŸä¼¤æ£€æµ‹ç­‰æŒ‘æˆ˜åœºæ™¯ç‰¹åˆ«æœ‰æ•ˆï¼Œç›®æ ‡ç‰©ä½“å¯èƒ½ä»…åœ¨å•ä¸€è§†å›¾ä¸­å¯è§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>è‡ªåŠ¨æ±½è½¦æŸä¼¤æ£€æµ‹å·²æˆä¸ºè½¦é™©è¡Œä¸šçš„å…³æ³¨ç„¦ç‚¹ï¼Œè¿½æ±‚æ›´å¿«ã€æ›´å‡†ç¡®ã€æ›´ç»æµçš„æŸä¼¤è¯„ä¼°ã€‚</li>
<li>ç°æœ‰å·¥ä½œå¤šå±€é™äº2Då›¾åƒåˆ†æï¼Œæœ¬æ–‡æ¢ç´¢äº†3Dé‡å»ºæ–¹æ³•åœ¨æŸä¼¤æ£€æµ‹ä¸­çš„åº”ç”¨æ½œåŠ›ã€‚</li>
<li>å¼•å…¥äº†ä¸€ç§åŸºäº3Dé‡å»ºçš„æŸä¼¤æ£€æµ‹ç®¡é“ï¼Œé€šè¿‡æå‡2Dæ©è†œå®ç°3DæŸä¼¤åˆ†å‰²ã€‚</li>
<li>æå‡ºäº†ä¸€ç§ç®€å•æœ‰æ•ˆçš„å­¦ä¹ æ— å…³çš„å•è§†å›¾3D-GSåˆ†å‰²æ–¹æ³•ï¼Œåˆ©ç”¨SfMè·å¾—çš„ç›¸æœºå‚æ•°è¿›è¡Œé«˜æ–¯æŠ•å½±ã€‚</li>
<li>é€šè¿‡Zç¼“å†²ç®—æ³•ç»“åˆæ·±åº¦å’Œä¸é€æ˜åº¦çš„æ­£æ€åˆ†å¸ƒæ¨¡å‹è¿›è¡Œè¿‡æ»¤ï¼Œæå‡äº†æ£€æµ‹æ–¹æ³•çš„æ•ˆæœã€‚</li>
<li>æ–¹æ³•ç‰¹åˆ«é€‚ç”¨äºæ±½è½¦æŸä¼¤æ£€æµ‹ç­‰æŒ‘æˆ˜åœºæ™¯ï¼Œç›®æ ‡ç‰©ä½“å¯èƒ½ä»…åœ¨å•ä¸€è§†å›¾ä¸­å¯è§ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.23947">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-a213635483df3af098588583f9be4960" align="middle">
<img src="https://picx.zhimg.com/v2-fe9139af111b436d1f0053381a1bab24" align="middle">
<img src="https://picx.zhimg.com/v2-e5dae2059ad6208d8177732ff84b0a89" align="middle">
<img src="https://picx.zhimg.com/v2-4b2e04b6f4369bd024d5c194ff37feff.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-1a3cd5ee23fbd470a847f2038b4c84a7" align="middle">
<img src="https://pic1.zhimg.com/v2-19c77ece06a41d7d6b1dce63155c57fd.jpg" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1><h2 id="Orientation-anchored-Hyper-Gaussian-for-4D-Reconstruction-from-Casual-Videos"><a href="#Orientation-anchored-Hyper-Gaussian-for-4D-Reconstruction-from-Casual-Videos" class="headerlink" title="Orientation-anchored Hyper-Gaussian for 4D Reconstruction from Casual   Videos"></a>Orientation-anchored Hyper-Gaussian for 4D Reconstruction from Casual   Videos</h2><p><strong>Authors:Junyi Wu, Jiachen Tao, Haoxuan Wang, Gaowen Liu, Ramana Rao Kompella, Yan Yan</strong></p>
<p>We present Orientation-anchored Gaussian Splatting (OriGS), a novel framework for high-quality 4D reconstruction from casually captured monocular videos. While recent advances extend 3D Gaussian Splatting to dynamic scenes via various motion anchors, such as graph nodes or spline control points, they often rely on low-rank assumptions and fall short in modeling complex, region-specific deformations inherent to unconstrained dynamics. OriGS addresses this by introducing a hyperdimensional representation grounded in scene orientation. We first estimate a Global Orientation Field that propagates principal forward directions across space and time, serving as stable structural guidance for dynamic modeling. Built upon this, we propose Orientation-aware Hyper-Gaussian, a unified formulation that embeds time, space, geometry, and orientation into a coherent probabilistic state. This enables inferring region-specific deformation through principled conditioned slicing, adaptively capturing diverse local dynamics in alignment with global motion intent. Experiments demonstrate the superior reconstruction fidelity of OriGS over mainstream methods in challenging real-world dynamic scenes. </p>
<blockquote>
<p>æˆ‘ä»¬æå‡ºäº†åŸºäºæ–¹å‘é”šå®šçš„é«˜æ–¯å»¶å±•ï¼ˆOriGSï¼‰æ–¹æ³•ï¼Œè¿™æ˜¯ä¸€ç§ä»éšæ„æ•æ‰çš„å•ç›®è§†é¢‘ä¸­å®ç°é«˜è´¨é‡4Dé‡å»ºçš„æ–°å‹æ¡†æ¶ã€‚è™½ç„¶æœ€è¿‘çš„è¿›å±•é€šè¿‡å°†3Dé«˜æ–¯å»¶å±•æ‰©å±•åˆ°åŠ¨æ€åœºæ™¯ï¼Œåˆ©ç”¨å„ç§è¿åŠ¨é”šç‚¹ï¼ˆå¦‚å›¾èŠ‚ç‚¹æˆ–æŠ˜çº¿æ§åˆ¶ç‚¹ï¼‰ç­‰æ–¹æ³•ï¼Œä½†å®ƒä»¬ç»å¸¸ä¾èµ–äºä½é˜¶å‡è®¾ï¼Œå¹¶ä¸”åœ¨å»ºæ¨¡æ— çº¦æŸåŠ¨æ€æ‰€å›ºæœ‰çš„å¤æ‚ã€åŒºåŸŸç‰¹å®šå˜å½¢æ–¹é¢è¡¨ç°ä¸è¶³ã€‚OriGSé€šè¿‡å¼•å…¥åŸºäºåœºæ™¯æ–¹å‘çš„é«˜ç»´è¡¨ç¤ºæ¥è§£å†³è¿™ä¸€é—®é¢˜ã€‚æˆ‘ä»¬é¦–å…ˆä¼°è®¡å…¨å±€æ–¹å‘åœºï¼Œè¯¥æ–¹å‘åœºåœ¨ç©ºé—´å’Œæ—¶é—´ä¸Šä¼ æ’­ä¸»è¦å‰å‘æ–¹å‘ï¼Œä¸ºåŠ¨æ€å»ºæ¨¡æä¾›ç¨³å®šçš„ç»“æ„æŒ‡å¯¼ã€‚åœ¨æ­¤åŸºç¡€ä¸Šï¼Œæˆ‘ä»¬æå‡ºäº†åŸºäºæ–¹å‘çš„è¶…é«˜æ–¯å…¬å¼ï¼Œå°†æ—¶é—´ã€ç©ºé—´ã€å‡ ä½•å’Œæ–¹å‘åµŒå…¥åˆ°ä¸€ä¸ªè¿è´¯çš„æ¦‚ç‡çŠ¶æ€ä¸­ã€‚è¿™ä½¿å¾—æˆ‘ä»¬èƒ½å¤Ÿé€šè¿‡åŸºäºåŸç†çš„æ¡ä»¶åˆ‡ç‰‡æ¨æ–­åŒºåŸŸç‰¹å®šçš„å˜å½¢ï¼Œè‡ªé€‚åº”åœ°æ•æ‰ä¸å…¨å±€è¿åŠ¨æ„å›¾ä¸€è‡´çš„å¤šæ ·å±€éƒ¨åŠ¨æ€ã€‚å®éªŒè¯æ˜ï¼Œåœ¨å…·æœ‰æŒ‘æˆ˜æ€§çš„çœŸå®ä¸–ç•ŒåŠ¨æ€åœºæ™¯ä¸­ï¼ŒOriGSçš„é‡å»ºä¿çœŸåº¦ä¼˜äºä¸»æµæ–¹æ³•ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.23492v1">PDF</a> NeurIPS 2025. Code: \href{<a target="_blank" rel="noopener" href="https://github.com/adreamwu/OriGS%7D%7BOriGS%7D">https://github.com/adreamwu/OriGS}{OriGS}</a></p>
<p><strong>æ‘˜è¦</strong></p>
<p>æœ¬æ–‡æå‡ºäº†åŸºäºæ–¹å‘é”šå®šçš„é«˜æ–¯ç‚¹äº‘æ³•ï¼ˆOriGSï¼‰ï¼Œè¿™æ˜¯ä¸€ç§ä»éšæ„æ•æ‰çš„å•ç›®è§†é¢‘ä¸­å®ç°é«˜è´¨é‡4Dé‡å»ºçš„æ–°å‹æ¡†æ¶ã€‚è™½ç„¶æœ€è¿‘çš„è¿›å±•é€šè¿‡å°†ä¸‰ç»´é«˜æ–¯ç‚¹äº‘æ³•æ‰©å±•åˆ°åŠ¨æ€åœºæ™¯ï¼Œåˆ©ç”¨å„ç§è¿åŠ¨é”šï¼ˆå¦‚å›¾èŠ‚ç‚¹æˆ–æ ·æ¡æ§åˆ¶ç‚¹ï¼‰å–å¾—äº†ä¸€å®šæˆæœï¼Œä½†å®ƒä»¬é€šå¸¸ä¾èµ–äºä½ç§©å‡è®¾ï¼Œéš¾ä»¥æ¨¡æ‹Ÿæ— çº¦æŸåŠ¨æ€ä¸­å›ºæœ‰çš„å¤æ‚åŒºåŸŸç‰¹å®šå˜å½¢ã€‚OriGSé€šè¿‡å¼•å…¥åŸºäºåœºæ™¯æ–¹å‘çš„é«˜ç»´è¡¨ç¤ºæ¥è§£å†³è¿™ä¸€é—®é¢˜ã€‚é¦–å…ˆä¼°è®¡å…¨å±€æ–¹å‘åœºï¼Œè¯¥åœºåœ¨ç©ºé—´å’Œæ—¶é—´ä¸Šä¼ æ’­ä¸»è¦å‰è¿›æ–¹å‘ï¼Œä¸ºåŠ¨æ€å»ºæ¨¡æä¾›ç¨³å®šçš„ç»“æ„æŒ‡å¯¼ã€‚åœ¨æ­¤åŸºç¡€ä¸Šï¼Œæˆ‘ä»¬æå‡ºäº†åŸºäºæ–¹å‘çš„è¶…é«˜æ–¯å…¬å¼ï¼Œå°†æ—¶é—´ã€ç©ºé—´ã€å‡ ä½•å’Œæ–¹å‘åµŒå…¥åˆ°ä¸€ä¸ªè¿è´¯çš„æ¦‚ç‡çŠ¶æ€ä¸­ã€‚è¿™ä½¿å¾—æˆ‘ä»¬èƒ½å¤Ÿé€šè¿‡åŸåˆ™æ€§æ¡ä»¶åˆ‡ç‰‡æ¨æ–­åŒºåŸŸç‰¹å®šå˜å½¢ï¼Œè‡ªé€‚åº”åœ°æ•æ‰ä¸å…¨å±€è¿åŠ¨æ„å›¾ç›¸ç¬¦çš„å¤šæ ·å±€éƒ¨åŠ¨æ€ã€‚å®éªŒè¯æ˜ï¼Œåœ¨å…·æœ‰æŒ‘æˆ˜æ€§çš„çœŸå®ä¸–ç•ŒåŠ¨æ€åœºæ™¯ä¸­ï¼ŒOriGSçš„é‡å»ºä¿çœŸåº¦ä¼˜äºä¸»æµæ–¹æ³•ã€‚</p>
<p><strong>è¦ç‚¹</strong></p>
<ol>
<li>OriGSæ˜¯ä¸€ç§æ–°å‹æ¡†æ¶ï¼Œç”¨äºä»å•ç›®è§†é¢‘ä¸­å®ç°é«˜è´¨é‡4Dé‡å»ºã€‚</li>
<li>å¼•å…¥åŸºäºåœºæ™¯æ–¹å‘çš„é«˜ç»´è¡¨ç¤ºæ¥è§£å†³å¤æ‚åŒºåŸŸç‰¹å®šå˜å½¢å»ºæ¨¡é—®é¢˜ã€‚</li>
<li>é€šè¿‡ä¼°è®¡å…¨å±€æ–¹å‘åœºä¼ æ’­ä¸»è¦å‰è¿›æ–¹å‘ï¼Œä¸ºåŠ¨æ€å»ºæ¨¡æä¾›ç¨³å®šç»“æ„æŒ‡å¯¼ã€‚</li>
<li>æå‡ºåŸºäºæ–¹å‘çš„è¶…é«˜æ–¯å…¬å¼ï¼Œæ•´åˆæ—¶é—´ã€ç©ºé—´ã€å‡ ä½•å’Œæ–¹å‘äºä¸€ä¸ªè¿è´¯çš„æ¦‚ç‡çŠ¶æ€ä¸­ã€‚</li>
<li>é€šè¿‡åŸåˆ™æ€§æ¡ä»¶åˆ‡ç‰‡æ¨æ–­åŒºåŸŸç‰¹å®šå˜å½¢ï¼Œè‡ªé€‚åº”æ•æ‰å±€éƒ¨åŠ¨æ€ã€‚</li>
<li>å®éªŒè¯æ˜ï¼ŒOriGSåœ¨æŒ‘æˆ˜æ€§çœŸå®ä¸–ç•ŒåŠ¨æ€åœºæ™¯ä¸­å…·æœ‰ä¼˜è¶Šé‡å»ºæ€§èƒ½ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.23492">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-dfffeae3764aef47474e6ea1b11f46de.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ff9e1b3af5896379e4975c1e489609d8" align="middle">
<img src="https://picx.zhimg.com/v2-5a2d8cba7680aadcb3a178410a4af8f0.jpg" align="middle">
</details>


<h1 id="-9"><a href="#-9" class="headerlink" title=""></a></h1><h2 id="OracleGS-Grounding-Generative-Priors-for-Sparse-View-Gaussian-Splatting"><a href="#OracleGS-Grounding-Generative-Priors-for-Sparse-View-Gaussian-Splatting" class="headerlink" title="OracleGS: Grounding Generative Priors for Sparse-View Gaussian Splatting"></a>OracleGS: Grounding Generative Priors for Sparse-View Gaussian Splatting</h2><p><strong>Authors:Atakan Topaloglu, Kunyi Li, Michael Niemeyer, Nassir Navab, A. Murat Tekalp, Federico Tombari</strong></p>
<p>Sparse-view novel view synthesis is fundamentally ill-posed due to severe geometric ambiguity. Current methods are caught in a trade-off: regressive models are geometrically faithful but incomplete, whereas generative models can complete scenes but often introduce structural inconsistencies. We propose OracleGS, a novel framework that reconciles generative completeness with regressive fidelity for sparse view Gaussian Splatting. Instead of using generative models to patch incomplete reconstructions, our â€œpropose-and-validateâ€ framework first leverages a pre-trained 3D-aware diffusion model to synthesize novel views to propose a complete scene. We then repurpose a multi-view stereo (MVS) model as a 3D-aware oracle to validate the 3D uncertainties of generated views, using its attention maps to reveal regions where the generated views are well-supported by multi-view evidence versus where they fall into regions of high uncertainty due to occlusion, lack of texture, or direct inconsistency. This uncertainty signal directly guides the optimization of a 3D Gaussian Splatting model via an uncertainty-weighted loss. Our approach conditions the powerful generative prior on multi-view geometric evidence, filtering hallucinatory artifacts while preserving plausible completions in under-constrained regions, outperforming state-of-the-art methods on datasets including Mip-NeRF 360 and NeRF Synthetic. </p>
<blockquote>
<p>ç¨€ç–è§†è§’çš„æ–°è§†è§’åˆæˆä»æ ¹æœ¬ä¸Šæ¥è¯´æ˜¯ä¸é€‚å®šçš„ï¼Œå› ä¸ºå­˜åœ¨ä¸¥é‡çš„å‡ ä½•æ­§ä¹‰ã€‚å½“å‰çš„æ–¹æ³•é™·å…¥äº†æƒè¡¡ä¹‹ä¸­ï¼šå›å½’æ¨¡å‹åœ¨å‡ ä½•ä¸Šå¿ å®ä½†ä¸å¤Ÿå®Œæ•´ï¼Œè€Œç”Ÿæˆæ¨¡å‹è™½ç„¶èƒ½å®Œæˆåœºæ™¯ä½†å¾€å¾€å¼•å…¥ç»“æ„ä¸ä¸€è‡´æ€§ã€‚æˆ‘ä»¬æå‡ºäº†OracleGSï¼Œè¿™æ˜¯ä¸€ä¸ªæ–°çš„æ¡†æ¶ï¼Œæ—¨åœ¨è°ƒå’Œç”Ÿæˆæ¨¡å‹çš„å®Œæ•´æ€§ä¸å›å½’æ¨¡å‹çš„å¿ å®æ€§ï¼Œç”¨äºç¨€ç–è§†è§’çš„é«˜æ–¯æ‹¼è´´ã€‚æˆ‘ä»¬å¹¶ä¸ä½¿ç”¨ç”Ÿæˆæ¨¡å‹æ¥ä¿®è¡¥ä¸å®Œæ•´çš„é‡å»ºï¼Œè€Œæ˜¯é‡‡ç”¨â€œæå‡ºå¹¶éªŒè¯â€çš„æ¡†æ¶ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬åˆ©ç”¨é¢„è®­ç»ƒçš„3Dæ„ŸçŸ¥æ‰©æ•£æ¨¡å‹åˆæˆæ–°è§†è§’ï¼Œä»¥æå‡ºä¸€ä¸ªå®Œæ•´çš„åœºæ™¯ã€‚ç„¶åï¼Œæˆ‘ä»¬å°†å¤šè§†å›¾ç«‹ä½“ï¼ˆMVSï¼‰æ¨¡å‹é‡æ–°ç”¨ä½œ3Dæ„ŸçŸ¥çš„è¯„åˆ¤æ ‡å‡†ï¼Œä»¥éªŒè¯ç”Ÿæˆè§†è§’çš„3Dä¸ç¡®å®šæ€§ã€‚æˆ‘ä»¬ä½¿ç”¨å…¶æ³¨æ„åŠ›å›¾æ¥æ­ç¤ºå“ªäº›åŒºåŸŸç”±å¤šè§†è§’è¯æ®æ”¯æŒè‰¯å¥½ï¼Œå“ªäº›åŒºåŸŸç”±äºé®æŒ¡ã€ç¼ºå°‘çº¹ç†æˆ–ç›´æ¥ä¸ä¸€è‡´è€Œé™·å…¥é«˜åº¦ä¸ç¡®å®šæ€§çš„åŒºåŸŸã€‚è¿™ç§ä¸ç¡®å®šæ€§ä¿¡å·ç›´æ¥æŒ‡å¯¼äº†é€šè¿‡ä¸ç¡®å®šæ€§åŠ æƒæŸå¤±ä¼˜åŒ–3Dé«˜æ–¯æ‹¼è´´æ¨¡å‹ã€‚æˆ‘ä»¬çš„æ–¹æ³•åœ¨å¤šè§†è§’å‡ ä½•è¯æ®çš„åŸºç¡€ä¸Šï¼Œä»¥å¼ºå¤§çš„ç”Ÿæˆå…ˆéªŒä¸ºæ¡ä»¶ï¼Œè¿‡æ»¤äº†å¹»æƒ³äº§ç”Ÿçš„ä¼ªå½±ï¼ŒåŒæ—¶ä¿ç•™äº†ç¼ºä¹çº¦æŸåŒºåŸŸçš„åˆç†å®Œæˆåº¦ï¼Œåœ¨Mip-NeRF 360å’ŒNeRF Syntheticç­‰æ•°æ®é›†ä¸Šçš„è¡¨ç°ä¼˜äºæœ€å…ˆè¿›çš„æ–¹æ³•ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.23258v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºä¸€ç§åä¸ºOracleGSçš„æ–°å‹æ¡†æ¶ï¼Œç”¨äºç¨€ç–è§†å›¾ä¸‹çš„é«˜æ–¯è´´å›¾æŠ€æœ¯ã€‚å®ƒç»“åˆäº†ç”Ÿæˆæ¨¡å‹çš„å®Œæ•´æ€§ä¸å›å½’æ¨¡å‹çš„ä¿çœŸåº¦ã€‚é€šè¿‡åˆ©ç”¨é¢„è®­ç»ƒçš„3Dæ„ŸçŸ¥æ‰©æ•£æ¨¡å‹åˆæˆæ–°è§†å›¾æ¥æå‡ºå®Œæ•´åœºæ™¯ï¼Œç„¶åä½¿ç”¨å¤šè§†å›¾ç«‹ä½“ï¼ˆMVSï¼‰æ¨¡å‹ä½œä¸º3Dæ„ŸçŸ¥çš„Oracleæ¥éªŒè¯ç”Ÿæˆçš„è§†å›¾çš„3Dä¸ç¡®å®šæ€§ã€‚è¯¥ä¸ç¡®å®šæ€§ä¿¡å·ç›´æ¥æŒ‡å¯¼äº†é€šè¿‡ä¸ç¡®å®šæ€§åŠ æƒæŸå¤±ä¼˜åŒ–çš„3Dé«˜æ–¯è´´å›¾æ¨¡å‹çš„ä¼˜åŒ–ã€‚è¯¥æ–¹æ³•åœ¨Mip-NeRF 360å’ŒNeRFåˆæˆç­‰æ•°æ®é›†ä¸Šä¼˜äºæœ€æ–°æ–¹æ³•ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>ç¨€ç–è§†å›¾ä¸‹çš„æ–°é¢–è§†è§’åˆæˆå…·æœ‰ä¸¥é‡çš„å‡ ä½•æ¨¡ç³Šæ€§ï¼Œå› æ­¤æ˜¯æ ¹æœ¬ä¸é€‚å®šçš„ã€‚</li>
<li>å½“å‰æ–¹æ³•é¢ä¸´å›å½’æ¨¡å‹å’Œç”Ÿæˆæ¨¡å‹çš„æƒè¡¡ï¼šå›å½’æ¨¡å‹å‡ ä½•ä¿çœŸä½†ä¸å®Œå…¨ï¼Œè€Œç”Ÿæˆæ¨¡å‹èƒ½å®Œæˆåœºæ™¯ä½†ç»å¸¸å¼•å…¥ç»“æ„ä¸ä¸€è‡´æ€§ã€‚</li>
<li>OracleGSæ¡†æ¶ç»“åˆäº†ç”Ÿæˆæ¨¡å‹çš„å®Œæ•´æ€§ä¸å›å½’æ¨¡å‹çš„ä¿çœŸåº¦ã€‚</li>
<li>ä½¿ç”¨é¢„è®­ç»ƒçš„3Dæ„ŸçŸ¥æ‰©æ•£æ¨¡å‹åˆæˆæ–°è§†å›¾ä»¥æå‡ºå®Œæ•´åœºæ™¯ã€‚</li>
<li>åˆ©ç”¨å¤šè§†å›¾ç«‹ä½“ï¼ˆMVSï¼‰æ¨¡å‹éªŒè¯ç”Ÿæˆçš„è§†å›¾çš„3Dä¸ç¡®å®šæ€§ï¼Œå¹¶é€šè¿‡å…¶æ³¨æ„åŠ›å›¾æ­ç¤ºå“ªäº›åŒºåŸŸå—å¤šè§†å›¾è¯æ®æ”¯æŒï¼Œå“ªäº›åŒºåŸŸå› é®æŒ¡ã€ç¼ºä¹çº¹ç†æˆ–ç›´æ¥ä¸ä¸€è‡´è€Œå…·æœ‰é«˜ä¸ç¡®å®šæ€§ã€‚</li>
<li>ä¸ç¡®å®šæ€§ä¿¡å·ç›´æ¥æŒ‡å¯¼äº†é€šè¿‡ä¸ç¡®å®šæ€§åŠ æƒæŸå¤±ä¼˜åŒ–çš„3Dé«˜æ–¯è´´å›¾æ¨¡å‹çš„ä¼˜åŒ–ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.23258">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-1dd8249d1e6922d84b93b320d3f9a5da" align="middle">
<img src="https://picx.zhimg.com/v2-21090328a2b5b6ea458ec253a1247bb9" align="middle">
<img src="https://picx.zhimg.com/v2-fa794c0d0af6b17a06cafe9084a461a3" align="middle">
<img src="https://picx.zhimg.com/v2-367441bcab795e72f6f6bb0db1f8356a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-6ddfa89b953479a371b0872ea4600326.jpg" align="middle">
</details>


<h1 id="-10"><a href="#-10" class="headerlink" title=""></a></h1><h2 id="T2Bs-Text-to-Character-Blendshapes-via-Video-Generation"><a href="#T2Bs-Text-to-Character-Blendshapes-via-Video-Generation" class="headerlink" title="T2Bs: Text-to-Character Blendshapes via Video Generation"></a>T2Bs: Text-to-Character Blendshapes via Video Generation</h2><p><strong>Authors:Jiahao Luo, Chaoyang Wang, Michael Vasilkovsky, Vladislav Shakhrai, Di Liu, Peiye Zhuang, Sergey Tulyakov, Peter Wonka, Hsin-Ying Lee, James Davis, Jian Wang</strong></p>
<p>We present T2Bs, a framework for generating high-quality, animatable character head morphable models from text by combining static text-to-3D generation with video diffusion. Text-to-3D models produce detailed static geometry but lack motion synthesis, while video diffusion models generate motion with temporal and multi-view geometric inconsistencies. T2Bs bridges this gap by leveraging deformable 3D Gaussian splatting to align static 3D assets with video outputs. By constraining motion with static geometry and employing a view-dependent deformation MLP, T2Bs (i) outperforms existing 4D generation methods in accuracy and expressiveness while reducing video artifacts and view inconsistencies, and (ii) reconstructs smooth, coherent, fully registered 3D geometries designed to scale for building morphable models with diverse, realistic facial motions. This enables synthesizing expressive, animatable character heads that surpass current 4D generation techniques. </p>
<blockquote>
<p>æˆ‘ä»¬æå‡ºäº†T2Bsæ¡†æ¶ï¼Œå®ƒé€šè¿‡ç»“åˆé™æ€æ–‡æœ¬åˆ°3Dç”Ÿæˆå’Œè§†é¢‘æ‰©æ•£æŠ€æœ¯ï¼Œä»æ–‡æœ¬ç”Ÿæˆé«˜è´¨é‡çš„å¯åŠ¨ç”»è§’è‰²å¤´éƒ¨å¯å˜å½¢æ¨¡å‹ã€‚æ–‡æœ¬åˆ°3Dæ¨¡å‹å¯ä»¥ç”Ÿæˆè¯¦ç»†çš„é™æ€å‡ ä½•ç»“æ„ï¼Œä½†ç¼ºä¹è¿åŠ¨åˆæˆï¼Œè€Œè§†é¢‘æ‰©æ•£æ¨¡å‹è™½ç„¶å¯ä»¥ç”Ÿæˆè¿åŠ¨ï¼Œä½†å­˜åœ¨æ—¶é—´å’Œå¤šè§†è§’å‡ ä½•ä¸ä¸€è‡´çš„é—®é¢˜ã€‚T2Bsé€šè¿‡åˆ©ç”¨å¯å˜å½¢3Dé«˜æ–¯è´´å›¾æŠ€æœ¯ï¼Œå°†é™æ€3Dèµ„äº§ä¸è§†é¢‘è¾“å‡ºå¯¹é½ï¼Œä»è€Œå¼¥è¡¥äº†è¿™ä¸€ç©ºç™½ã€‚é€šè¿‡ç”¨é™æ€å‡ ä½•ç»“æ„çº¦æŸè¿åŠ¨å¹¶é‡‡ç”¨è§†è§’ç›¸å…³å˜å½¢å¤šå±‚æ„ŸçŸ¥å™¨ï¼ŒT2Bsï¼ˆiï¼‰åœ¨å‡†ç¡®æ€§å’Œè¡¨ç°åŠ›æ–¹é¢ä¼˜äºç°æœ‰çš„4Dç”Ÿæˆæ–¹æ³•ï¼ŒåŒæ—¶å‡å°‘äº†è§†é¢‘ä¼ªå½±å’Œè§†è§’ä¸ä¸€è‡´é—®é¢˜ï¼›ï¼ˆiiï¼‰é‡å»ºäº†å¹³æ»‘ã€è¿è´¯ã€å®Œå…¨é…å‡†çš„3Då‡ ä½•ç»“æ„ï¼Œæ—¨åœ¨æ„å»ºå…·æœ‰å¤šæ ·åŒ–å’Œç°å®æ„Ÿçš„é¢éƒ¨è¿åŠ¨çš„å¯å˜å½¢æ¨¡å‹ã€‚è¿™èƒ½å¤Ÿåˆæˆå‡ºè¶…è¶Šå½“å‰4Dç”ŸæˆæŠ€æœ¯çš„ç”ŸåŠ¨å¯åŠ¨ç”»è§’è‰²å¤´éƒ¨ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.10678v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†T2Bsæ¡†æ¶ï¼Œè¯¥æ¡†æ¶ç»“åˆäº†é™æ€æ–‡æœ¬åˆ°3Dç”Ÿæˆå’Œè§†é¢‘æ‰©æ•£æŠ€æœ¯ï¼Œç”¨äºä»æ–‡æœ¬ç”Ÿæˆé«˜è´¨é‡ã€å¯åŠ¨ç”»çš„è§’è‰²å¤´éƒ¨å¯å˜å½¢æ¨¡å‹ã€‚T2Bsé€šè¿‡åˆ©ç”¨å¯å˜å½¢çš„3Dé«˜æ–¯å–·ç»˜æŠ€æœ¯ï¼Œå°†é™æ€3Dèµ„äº§ä¸è§†é¢‘è¾“å‡ºå¯¹é½ï¼Œè§£å†³äº†æ–‡æœ¬åˆ°3Dæ¨¡å‹ç¼ºä¹åŠ¨ä½œåˆæˆçš„é—®é¢˜ä»¥åŠè§†é¢‘æ‰©æ•£æ¨¡å‹å­˜åœ¨çš„æ—¶åºå’Œå¤šè§†è§’å‡ ä½•ä¸ä¸€è‡´çš„é—®é¢˜ã€‚T2Bsæé«˜äº†å‡†ç¡®æ€§å’Œè¡¨ç°åŠ›ï¼Œå‡å°‘äº†è§†é¢‘ä¼ªå½±å’Œè§†è§’ä¸ä¸€è‡´ï¼Œé‡å»ºäº†å¹³æ»‘ã€è¿è´¯ã€å®Œå…¨æ³¨å†Œçš„3Då‡ ä½•ï¼Œç”¨äºæ„å»ºå…·æœ‰å¤šæ ·åŒ–å’Œç°å®æ„Ÿçš„é¢éƒ¨è¿åŠ¨çš„å¯å˜å½¢æ¨¡å‹ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>T2Bsæ¡†æ¶ç»“åˆäº†é™æ€æ–‡æœ¬åˆ°3Dç”Ÿæˆä¸è§†é¢‘æ‰©æ•£æŠ€æœ¯ã€‚</li>
<li>æ–‡æœ¬åˆ°3Dæ¨¡å‹äº§ç”Ÿé™æ€å‡ ä½•ï¼Œä½†ç¼ºä¹åŠ¨ä½œåˆæˆã€‚</li>
<li>è§†é¢‘æ‰©æ•£æ¨¡å‹äº§ç”ŸåŠ¨ä½œï¼Œä½†å­˜åœ¨æ—¶åºå’Œå¤šè§†è§’å‡ ä½•ä¸ä¸€è‡´çš„é—®é¢˜ã€‚</li>
<li>T2Bsåˆ©ç”¨å¯å˜å½¢3Dé«˜æ–¯å–·ç»˜æŠ€æœ¯ï¼Œå°†é™æ€3Dèµ„äº§ä¸è§†é¢‘è¾“å‡ºå¯¹é½ã€‚</li>
<li>T2Bsé€šè¿‡çº¦æŸåŠ¨ä½œå’Œé™æ€å‡ ä½•ï¼Œæé«˜äº†å‡†ç¡®æ€§ã€è¡¨ç°åŠ›ã€‚</li>
<li>T2Bså‡å°‘äº†è§†é¢‘ä¼ªå½±å’Œè§†è§’ä¸ä¸€è‡´ã€‚</li>
<li>T2Bsèƒ½å¤Ÿé‡å»ºå¹³æ»‘ã€è¿è´¯ã€å®Œå…¨æ³¨å†Œçš„3Då‡ ä½•ï¼Œç”¨äºæ„å»ºå…·æœ‰å¤šæ ·åŒ–å’Œç°å®æ„Ÿçš„é¢éƒ¨è¿åŠ¨çš„å¯å˜å½¢æ¨¡å‹ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.10678">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-eccf18383c5fa0fd044ab72f2f6d5281" align="middle">
<img src="https://pic1.zhimg.com/v2-8b4714c2ebd58c234843d4ea7b214765.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c112528e422be3bcf7c71601972ee186.jpg" align="middle">
</details>


<h1 id="-11"><a href="#-11" class="headerlink" title=""></a></h1><h2 id="GeoSplat-A-Deep-Dive-into-Geometry-Constrained-Gaussian-Splatting"><a href="#GeoSplat-A-Deep-Dive-into-Geometry-Constrained-Gaussian-Splatting" class="headerlink" title="GeoSplat: A Deep Dive into Geometry-Constrained Gaussian Splatting"></a>GeoSplat: A Deep Dive into Geometry-Constrained Gaussian Splatting</h2><p><strong>Authors:Yangming Li, Chaoyu Liu, Lihao Liu, Simon Masnou, Carola-Bibiane SchÃ¶nlieb</strong></p>
<p>A few recent works explored incorporating geometric priors to regularize the optimization of Gaussian splatting, further improving its performance. However, those early studies mainly focused on the use of low-order geometric priors (e.g., normal vector), and they might also be unreliably estimated by noise-sensitive methods, like local principal component analysis. To address their limitations, we first present GeoSplat, a general geometry-constrained optimization framework that exploits both first-order and second-order geometric quantities to improve the entire training pipeline of Gaussian splatting, including Gaussian initialization, gradient update, and densification. As an example, we initialize the scales of 3D Gaussian primitives in terms of principal curvatures, leading to a better coverage of the object surface than random initialization. Secondly, based on certain geometric structures (e.g., local manifold), we introduce efficient and noise-robust estimation methods that provide dynamic geometric priors for our framework. We conduct extensive experiments on multiple datasets for novel view synthesis, showing that our framework, GeoSplat, significantly improves the performance of Gaussian splatting and outperforms previous baselines. </p>
<blockquote>
<p>è¿‘æœŸæœ‰ä¸€äº›ç ”ç©¶å°è¯•å°†å‡ ä½•å…ˆéªŒçŸ¥è¯†å¼•å…¥é«˜æ–¯æ‘Šé“ºçš„ä¼˜åŒ–è¿‡ç¨‹ä¸­ï¼Œä»¥è¿›ä¸€æ­¥æé«˜å…¶æ€§èƒ½ã€‚ç„¶è€Œï¼Œæ—©æœŸçš„ç ”ç©¶ä¸»è¦é›†ä¸­åœ¨ä½é˜¶å‡ ä½•å…ˆéªŒçš„ä½¿ç”¨ä¸Šï¼ˆå¦‚æ³•å‘é‡ï¼‰ï¼Œè¿™äº›æ–¹æ³•å¯èƒ½é€šè¿‡å™ªå£°æ•æ„Ÿçš„æ–¹æ³•ï¼ˆå¦‚å±€éƒ¨ä¸»æˆåˆ†åˆ†æï¼‰è¿›è¡Œä¼°ç®—ï¼Œä½†ä¼°ç®—ç»“æœå¯èƒ½ä¸å¯é ã€‚ä¸ºäº†å…‹æœè¿™äº›å±€é™æ€§ï¼Œæˆ‘ä»¬é¦–å…ˆæå‡ºäº†GeoSplatï¼Œè¿™æ˜¯ä¸€ä¸ªé€šç”¨çš„å‡ ä½•çº¦æŸä¼˜åŒ–æ¡†æ¶ï¼Œå®ƒåˆ©ç”¨ä¸€é˜¶å’ŒäºŒé˜¶å‡ ä½•é‡æ¥æé«˜é«˜æ–¯æ‘Šé“ºçš„æ•´ä¸ªè®­ç»ƒæµç¨‹ï¼ŒåŒ…æ‹¬é«˜æ–¯åˆå§‹åŒ–ã€æ¢¯åº¦æ›´æ–°å’Œå¯†é›†åŒ–ã€‚ä¾‹å¦‚ï¼Œæˆ‘ä»¬æ ¹æ®ä¸»æ›²ç‡åˆå§‹åŒ–3Dé«˜æ–¯åŸå§‹æ•°æ®çš„å°ºåº¦ï¼Œç›¸å¯¹äºéšæœºåˆå§‹åŒ–è€Œè¨€ï¼Œè¿™èƒ½æ›´å¥½åœ°è¦†ç›–å¯¹è±¡è¡¨é¢ã€‚å…¶æ¬¡ï¼ŒåŸºäºæŸäº›å‡ ä½•ç»“æ„ï¼ˆå¦‚å±€éƒ¨æµå½¢ï¼‰ï¼Œæˆ‘ä»¬å¼•å…¥äº†é«˜æ•ˆä¸”å™ªå£°é²æ£’çš„ä¼°è®¡æ–¹æ³•ï¼Œä¸ºæˆ‘ä»¬çš„æ¡†æ¶æä¾›åŠ¨æ€å‡ ä½•å…ˆéªŒã€‚æˆ‘ä»¬åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šè¿›è¡Œäº†æ–°é¢–è§†å›¾åˆæˆçš„å¹¿æ³›å®éªŒï¼Œç»“æœè¡¨æ˜æˆ‘ä»¬çš„æ¡†æ¶GeoSplatæ˜¾è‘—æé«˜äº†é«˜æ–¯æ‘Šé“ºçš„æ€§èƒ½ï¼Œå¹¶è¶…è¿‡äº†ä»¥å‰çš„åŸºçº¿æ°´å¹³ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.05075v3">PDF</a> </p>
<p><strong>æ‘˜è¦</strong><br>    æœ¬æ–‡æå‡ºäº†GeoSplatï¼Œä¸€ä¸ªé€šç”¨çš„å‡ ä½•çº¦æŸä¼˜åŒ–æ¡†æ¶ï¼Œå®ƒåˆ©ç”¨ä¸€é˜¶å’ŒäºŒé˜¶å‡ ä½•é‡æ”¹è¿›äº†é«˜æ–¯è´´å›¾çš„æ•´ä¸ªè®­ç»ƒæµç¨‹ï¼ŒåŒ…æ‹¬é«˜æ–¯åˆå§‹åŒ–ã€æ¢¯åº¦æ›´æ–°å’Œç¨ å¯†åŒ–ã€‚é€šè¿‡åŸºäºä¸»æ›²ç‡çš„åˆå§‹åŒ–æ–¹æ³•ï¼Œå®ç°äº†æ¯”éšæœºåˆå§‹åŒ–æ›´å¥½çš„å¯¹è±¡è¡¨é¢è¦†ç›–ã€‚æ­¤å¤–ï¼ŒåŸºäºæŸäº›å‡ ä½•ç»“æ„ï¼ˆå¦‚å±€éƒ¨æµå½¢ï¼‰ï¼Œå¼•å…¥äº†é«˜æ•ˆä¸”å™ªå£°é²æ£’çš„ä¼°è®¡æ–¹æ³•ï¼Œä¸ºæˆ‘ä»¬çš„æ¡†æ¶æä¾›åŠ¨æ€å‡ ä½•å…ˆéªŒã€‚åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šè¿›è¡Œçš„æ–°è§†è§’åˆæˆå®éªŒè¡¨æ˜ï¼ŒGeoSplatæ˜¾è‘—æé«˜äº†é«˜æ–¯è´´å›¾æ€§èƒ½å¹¶è¶…è¶Šäº†å…ˆå‰åŸºçº¿ã€‚</p>
<p><strong>å…³é”®è§è§£</strong></p>
<ol>
<li>å¼•å…¥äº†GeoSplatï¼Œä¸€ä¸ªç»“åˆå‡ ä½•å…ˆéªŒçš„é€šç”¨ä¼˜åŒ–æ¡†æ¶ï¼Œç”¨äºæ”¹è¿›é«˜æ–¯è´´å›¾çš„æ€§èƒ½ã€‚</li>
<li>åˆ©ç”¨ä¸€é˜¶å’ŒäºŒé˜¶å‡ ä½•é‡æå‡é«˜æ–¯è´´å›¾çš„æ•´ä¸ªè®­ç»ƒæµç¨‹ã€‚</li>
<li>é€šè¿‡åŸºäºä¸»æ›²ç‡çš„åˆå§‹åŒ–æ–¹æ³•ï¼Œå®ç°äº†å¯¹è±¡è¡¨é¢è¦†ç›–çš„æ”¹è¿›ã€‚</li>
<li>æå‡ºäº†åŸºäºæŸäº›å‡ ä½•ç»“æ„çš„åŠ¨æ€å‡ ä½•å…ˆéªŒä¼°è®¡æ–¹æ³•ï¼Œæé«˜äº†æ–¹æ³•çš„æ•ˆç‡å’Œå™ªå£°é²æ£’æ€§ã€‚</li>
<li>æ–¹æ³•åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šè¿›è¡Œäº†æ–°è§†è§’åˆæˆçš„å®éªŒéªŒè¯ã€‚</li>
<li>GeoSplatæ˜¾è‘—æé«˜äº†é«˜æ–¯è´´å›¾æ€§èƒ½å¹¶è¶…è¶Šå…ˆå‰åŸºçº¿ã€‚</li>
<li>è¯¥æ¡†æ¶ä¸ºç»“åˆå‡ ä½•å…ˆéªŒä»¥æ”¹è¿›ä¼˜åŒ–æä¾›äº†ä¸€ç§é€šç”¨ä¸”é«˜æ•ˆçš„æ–¹æ³•ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.05075">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-297e77ba30a42f8c788c3052d85a13db.jpg" align="middle">
</details>


<h1 id="-12"><a href="#-12" class="headerlink" title=""></a></h1><h2 id="Advances-in-Feed-Forward-3D-Reconstruction-and-View-Synthesis-A-Survey"><a href="#Advances-in-Feed-Forward-3D-Reconstruction-and-View-Synthesis-A-Survey" class="headerlink" title="Advances in Feed-Forward 3D Reconstruction and View Synthesis: A Survey"></a>Advances in Feed-Forward 3D Reconstruction and View Synthesis: A Survey</h2><p><strong>Authors:Jiahui Zhang, Yuelei Li, Anpei Chen, Muyu Xu, Kunhao Liu, Jianyuan Wang, Xiao-Xiao Long, Hanxue Liang, Zexiang Xu, Hao Su, Christian Theobalt, Christian Rupprecht, Andrea Vedaldi, Kaichen Zhou, Paul Pu Liang, Shijian Lu, Fangneng Zhan</strong></p>
<p>3D reconstruction and view synthesis are foundational problems in computer vision, graphics, and immersive technologies such as augmented reality (AR), virtual reality (VR), and digital twins. Traditional methods rely on computationally intensive iterative optimization in a complex chain, limiting their applicability in real-world scenarios. Recent advances in feed-forward approaches, driven by deep learning, have revolutionized this field by enabling fast and generalizable 3D reconstruction and view synthesis. This survey offers a comprehensive review of feed-forward techniques for 3D reconstruction and view synthesis, with a taxonomy according to the underlying representation architectures including point cloud, 3D Gaussian Splatting (3DGS), Neural Radiance Fields (NeRF), etc. We examine key tasks such as pose-free reconstruction, dynamic 3D reconstruction, and 3D-aware image and video synthesis, highlighting their applications in digital humans, SLAM, robotics, and beyond. In addition, we review commonly used datasets with detailed statistics, along with evaluation protocols for various downstream tasks. We conclude by discussing open research challenges and promising directions for future work, emphasizing the potential of feed-forward approaches to advance the state of the art in 3D vision. </p>
<blockquote>
<p>3Dé‡å»ºå’Œè§†å›¾åˆæˆæ˜¯è®¡ç®—æœºè§†è§‰ã€å›¾å½¢å­¦ä»¥åŠå¢å¼ºç°å®ï¼ˆARï¼‰ã€è™šæ‹Ÿç°å®ï¼ˆVRï¼‰å’Œæ•°å­—å­ªç”Ÿç­‰æ²‰æµ¸å¼æŠ€æœ¯ä¸­çš„åŸºç¡€é—®é¢˜ã€‚ä¼ ç»Ÿæ–¹æ³•ä¾èµ–äºå¤æ‚é“¾ä¸­çš„è®¡ç®—å¯†é›†å‹è¿­ä»£ä¼˜åŒ–ï¼Œé™åˆ¶äº†å®ƒä»¬åœ¨ç°å®åœºæ™¯ä¸­çš„åº”ç”¨ã€‚æœ€è¿‘ï¼Œæ·±åº¦å­¦ä¹ é©±åŠ¨çš„å‰é¦ˆæ–¹æ³•çš„è¿›æ­¥å·²ç»å½»åº•æ”¹å˜äº†è¿™ä¸€é¢†åŸŸï¼Œå®ç°äº†å¿«é€Ÿå’Œé€šç”¨çš„3Dé‡å»ºå’Œè§†å›¾åˆæˆã€‚è¿™ç¯‡ç»¼è¿°å¯¹å‰é¦ˆæŠ€æœ¯åœ¨3Dé‡å»ºå’Œè§†å›¾åˆæˆæ–¹é¢çš„åº”ç”¨è¿›è¡Œäº†å…¨é¢å›é¡¾ï¼Œå¹¶æ ¹æ®åº•å±‚è¡¨ç¤ºæ¶æ„è¿›è¡Œäº†åˆ†ç±»ï¼ŒåŒ…æ‹¬ç‚¹äº‘ã€3Dé«˜æ–¯å–·æ¶‚ï¼ˆ3DGSï¼‰ã€ç¥ç»è¾å°„åœºï¼ˆNeRFï¼‰ç­‰ã€‚æˆ‘ä»¬ç ”ç©¶äº†å…³é”®ä»»åŠ¡ï¼Œå¦‚å§¿åŠ¿æ— å…³é‡å»ºã€åŠ¨æ€3Dé‡å»ºå’Œ3Dæ„ŸçŸ¥å›¾åƒå’Œè§†é¢‘åˆæˆç­‰ï¼Œå¹¶å¼ºè°ƒäº†å®ƒä»¬åœ¨æ•°å­—äººç±»ã€SLAMã€æœºå™¨äººæŠ€æœ¯ç­‰é¢†åŸŸçš„åº”ç”¨ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜å›é¡¾äº†å¸¸ç”¨æ•°æ®é›†åŠå…¶è¯¦ç»†ç»Ÿè®¡æ•°æ®ï¼Œä»¥åŠå„ç§ä¸‹æ¸¸ä»»åŠ¡çš„è¯„ä¼°åè®®ã€‚æœ€åï¼Œæˆ‘ä»¬è®¨è®ºäº†å½“å‰çš„ç ”ç©¶æŒ‘æˆ˜ä»¥åŠæœªæ¥å·¥ä½œçš„æœ‰å‰é€”çš„æ–¹å‘ï¼Œå¼ºè°ƒäº†å‰é¦ˆæ–¹æ³•åœ¨æ¨åŠ¨3Dè§†è§‰æŠ€æœ¯å‰æ²¿çš„æ½œåŠ›ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2507.14501v3">PDF</a> A project page associated with this survey is available at   <a target="_blank" rel="noopener" href="https://fnzhan.com/projects/Feed-Forward-3D">https://fnzhan.com/projects/Feed-Forward-3D</a></p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ç»¼è¿°äº†åŸºäºæ·±åº¦å­¦ä¹ çš„feed-forwardæŠ€æœ¯åœ¨3Dé‡å»ºå’Œè§†å›¾åˆæˆæ–¹é¢çš„æœ€æ–°è¿›å±•ï¼Œä»‹ç»äº†å…¶åœ¨è®¡ç®—æœºè§†è§‰ã€å›¾å½¢å­¦å’Œæ²‰æµ¸å¼æŠ€æœ¯ç­‰é¢†åŸŸçš„åº”ç”¨ã€‚æ–‡ç« è¯¦ç»†é˜è¿°äº†åŒ…æ‹¬ç‚¹äº‘ã€3Dé«˜æ–¯æº…å°„ï¼ˆ3DGSï¼‰ã€ç¥ç»è¾å°„åœºï¼ˆNeRFï¼‰ç­‰åœ¨å†…çš„åŸºç¡€æ¶æ„çš„ç¨æ”¶åˆ†ç±»ï¼Œå¹¶å¼ºè°ƒäº†å§¿æ€è‡ªç”±é‡å»ºã€åŠ¨æ€3Dé‡å»ºå’Œ3Dæ„ŸçŸ¥å›¾åƒå’Œè§†é¢‘åˆæˆç­‰å…³é”®ä»»åŠ¡åœ¨æ•°å­—äººç±»ã€SLAMã€æœºå™¨äººç­‰é¢†åŸŸçš„åº”ç”¨ã€‚åŒæ—¶ï¼Œæœ¬æ–‡è¿˜ä»‹ç»äº†å¸¸ç”¨çš„æ•°æ®é›†å’Œè¯„ä¼°åè®®ï¼Œæœ€åè®¨è®ºäº†å½“å‰çš„ç ”ç©¶æŒ‘æˆ˜å’Œæœªæ¥æœ‰å‰æ™¯çš„ç ”ç©¶æ–¹å‘ï¼Œå¼ºè°ƒäº†feed-forwardæŠ€æœ¯çš„æ½œåŠ›ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>3Dé‡å»ºå’Œè§†å›¾åˆæˆæ˜¯è®¡ç®—æœºè§†è§‰ã€å›¾å½¢å­¦å’Œæ²‰æµ¸å¼æŠ€æœ¯çš„åŸºç¡€é—®é¢˜ï¼Œæ¶‰åŠARã€VRå’Œæ•°å­—å­ªç”Ÿç­‰æŠ€æœ¯ã€‚</li>
<li>ä¼ ç»Ÿæ–¹æ³•å—é™äºè®¡ç®—å¯†é›†å‹çš„è¿­ä»£ä¼˜åŒ–å’Œå¤æ‚çš„é“¾æ¡ï¼Œåœ¨çœŸå®åœºæ™¯ä¸­çš„åº”ç”¨æœ‰é™ã€‚</li>
<li>åŸºäºæ·±åº¦å­¦ä¹ çš„feed-forwardæ–¹æ³•å·²ç»é©å‘½åŒ–äº†3Dé‡å»ºå’Œè§†å›¾åˆæˆé¢†åŸŸï¼Œå®ç°äº†å¿«é€Ÿå’Œé€šç”¨çš„3Dé‡å»ºå’Œè§†å›¾åˆæˆã€‚</li>
<li>æ–‡ç« ä»‹ç»äº†åŒ…æ‹¬ç‚¹äº‘ã€3DGSã€NeRFç­‰åœ¨å†…çš„åŸºç¡€æ¶æ„çš„ç¨æ”¶åˆ†ç±»ï¼Œå¹¶è¯¦ç»†é˜è¿°äº†å…³é”®ä»»åŠ¡å¦‚å§¿æ€è‡ªç”±é‡å»ºã€åŠ¨æ€3Dé‡å»ºå’Œ3Dæ„ŸçŸ¥å›¾åƒå’Œè§†é¢‘åˆæˆç­‰ã€‚</li>
<li>æ–‡ç« è¿˜è®¨è®ºäº†æ•°å­—äººç±»ã€SLAMã€æœºå™¨äººç­‰é¢†åŸŸçš„åº”ç”¨ï¼Œå¹¶ä»‹ç»äº†å¸¸ç”¨çš„æ•°æ®é›†å’Œè¯„ä¼°åè®®ã€‚</li>
<li>å½“å‰çš„ç ”ç©¶æŒ‘æˆ˜å’Œæœªæ¥ç ”ç©¶æ–¹å‘è¢«å¼ºè°ƒï¼Œå°¤å…¶æ˜¯feed-forwardæŠ€æœ¯çš„æ½œåŠ›ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2507.14501">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-77a63beb68a83dbe0d10b03d98c06c58.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-bfe7b9b6f744bafc8db7bcd6687997ed.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a1a060beb79b28f7f67d6aae73d749ba" align="middle">
<img src="https://picx.zhimg.com/v2-d670e872f8768c9521ab7472ea23c260" align="middle">
<img src="https://pic1.zhimg.com/v2-15de065c4b201fe5fd3c35f7bc69c497.jpg" align="middle">
</details>


<h1 id="-13"><a href="#-13" class="headerlink" title=""></a></h1><h2 id="3DGAA-Realistic-and-Robust-3D-Gaussian-based-Adversarial-Attack-for-Autonomous-Driving"><a href="#3DGAA-Realistic-and-Robust-3D-Gaussian-based-Adversarial-Attack-for-Autonomous-Driving" class="headerlink" title="3DGAA: Realistic and Robust 3D Gaussian-based Adversarial Attack for   Autonomous Driving"></a>3DGAA: Realistic and Robust 3D Gaussian-based Adversarial Attack for   Autonomous Driving</h2><p><strong>Authors:Yixun Zhang, Lizhi Wang, Junjun Zhao, Wending Zhao, Feng Zhou, Yonghao Dang, Jianqin Yin</strong></p>
<p>Camera-based object detection systems play a vital role in autonomous driving, yet they remain vulnerable to adversarial threats in real-world environments. Existing 2D and 3D physical attacks, due to their focus on texture optimization, often struggle to balance physical realism and attack robustness. In this work, we propose 3D Gaussian-based Adversarial Attack (3DGAA), a novel adversarial object generation framework that leverages the full 14-dimensional parameterization of 3D Gaussian Splatting (3DGS) to jointly optimize geometry and appearance in physically realizable ways. Unlike prior works that rely on patches or texture optimization, 3DGAA jointly perturbs both geometric attributes (shape, scale, rotation) and appearance attributes (color, opacity) to produce physically realistic and transferable adversarial objects. We further introduce a physical filtering module that filters outliers to preserve geometric fidelity, and a physical augmentation module that simulates complex physical scenarios to enhance attack generalization under real-world conditions. We evaluate 3DGAA on both virtual benchmarks and physical-world setups using miniature vehicle models. Experimental results show that 3DGAA achieves to reduce the detection mAP from 87.21% to 7.38%, significantly outperforming existing 3D physical attacks. Moreover, our method maintains high transferability across different physical conditions, demonstrating a new state-of-the-art in physically realizable adversarial attacks. </p>
<blockquote>
<p>åŸºäºæ‘„åƒå¤´çš„ç‰©ä½“æ£€æµ‹ç³»ç»Ÿå¯¹äºè‡ªåŠ¨é©¾é©¶è‡³å…³é‡è¦ï¼Œä½†åœ¨çœŸå®ä¸–ç•Œç¯å¢ƒä¸­ï¼Œå®ƒä»¬ä»ç„¶å®¹æ˜“å—åˆ°å¯¹æŠ—æ€§å¨èƒçš„å½±å“ã€‚ç°æœ‰çš„äºŒç»´å’Œä¸‰ç»´ç‰©ç†æ”»å‡»ç”±äºä¾§é‡äºçº¹ç†ä¼˜åŒ–ï¼Œåœ¨å¹³è¡¡ç‰©ç†çœŸå®æ€§å’Œæ”»å‡»ç¨³å¥æ€§æ–¹é¢å¾€å¾€é¢ä¸´æŒ‘æˆ˜ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†åŸºäºä¸‰ç»´é«˜æ–¯çš„å¯¹æŠ—æ”»å‡»ï¼ˆ3DGAAï¼‰ï¼Œè¿™æ˜¯ä¸€ç§æ–°å‹çš„å¯¹æŠ—æ€§ç‰©ä½“ç”Ÿæˆæ¡†æ¶ï¼Œå®ƒåˆ©ç”¨ä¸‰ç»´é«˜æ–¯æ¨¡ç³Šï¼ˆ3DGSï¼‰çš„å®Œæ•´çš„14ç»´å‚æ•°åŒ–ï¼Œä»¥ç‰©ç†å¯å®ç°çš„æ–¹å¼è”åˆä¼˜åŒ–å‡ ä½•å’Œå¤–è§‚ã€‚ä¸ä»¥å¾€ä¾èµ–è¡¥ä¸æˆ–çº¹ç†ä¼˜åŒ–çš„å·¥ä½œä¸åŒï¼Œ3DGAAè”åˆæ‰°åŠ¨å‡ ä½•å±æ€§ï¼ˆå½¢çŠ¶ã€å°ºåº¦ã€æ—‹è½¬ï¼‰å’Œå¤–è§‚å±æ€§ï¼ˆé¢œè‰²ã€é€æ˜åº¦ï¼‰ï¼Œä»¥äº§ç”Ÿç‰©ç†çœŸå®æ€§å’Œå¯è½¬ç§»æ€§çš„å¯¹æŠ—æ€§ç‰©ä½“ã€‚æˆ‘ä»¬è¿˜è¿›ä¸€æ­¥å¼•å…¥äº†ä¸€ä¸ªç‰©ç†æ»¤æ³¢æ¨¡å—ï¼Œç”¨äºè¿‡æ»¤å¼‚å¸¸å€¼ä»¥ä¿æŒå‡ ä½•ä¿çœŸåº¦ï¼Œä»¥åŠä¸€ä¸ªç‰©ç†å¢å¼ºæ¨¡å—ï¼Œç”¨äºæ¨¡æ‹Ÿå¤æ‚çš„ç‰©ç†åœºæ™¯ï¼Œä»¥å¢å¼ºåœ¨ç°å®æ¡ä»¶ä¸‹çš„æ”»å‡»é€šç”¨æ€§ã€‚æˆ‘ä»¬åœ¨è™šæ‹ŸåŸºå‡†æµ‹è¯•å’Œç‰©ç†ç¯å¢ƒè®¾ç½®ä¸­éƒ½ä½¿ç”¨äº†å¾®å‹è½¦è¾†æ¨¡å‹æ¥è¯„ä¼°3DGAAã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œ3DGAAå°†æ£€æµ‹mAPä»87.21%é™ä½åˆ°7.38%ï¼Œæ˜¾è‘—ä¼˜äºç°æœ‰çš„ä¸‰ç»´ç‰©ç†æ”»å‡»ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨ä¸åŒçš„ç‰©ç†æ¡ä»¶ä¸‹ä¿æŒäº†é«˜å¯è½¬ç§»æ€§ï¼Œåœ¨ç‰©ç†å¯å®ç°çš„å¯¹æŠ—æ”»å‡»ä¸­è¾¾åˆ°äº†æœ€æ–°æ°´å¹³ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2507.09993v3">PDF</a> Submitted to WACV 2026</p>
<p><strong>æ‘˜è¦</strong></p>
<p>ç›¸æœºåŸºäºç‰©ä½“æ£€æµ‹ç³»ç»Ÿåœ¨è‡ªåŠ¨é©¾é©¶ä¸­èµ·åˆ°é‡è¦ä½œç”¨ï¼Œä½†åœ¨ç°å®ç¯å¢ƒä¸­æ˜“å—å¯¹æŠ—æ€§å¨èƒå½±å“ã€‚ç°æœ‰çš„äºŒç»´å’Œä¸‰ç»´ç‰©ç†æ”»å‡»ä¸»è¦å…³æ³¨çº¹ç†ä¼˜åŒ–ï¼Œéš¾ä»¥å¹³è¡¡ç‰©ç†çœŸå®æ€§å’Œæ”»å‡»ç¨³å¥æ€§ã€‚æœ¬æ–‡æå‡ºåŸºäºä¸‰ç»´é«˜æ–¯çš„æ–°å‹å¯¹æŠ—æ€§ç‰©ä½“ç”Ÿæˆæ¡†æ¶â€”â€”ä¸‰ç»´é«˜æ–¯å¯¹æŠ—æ”»å‡»ï¼ˆ3DGAAï¼‰ã€‚è¯¥æ–¹æ³•åˆ©ç”¨ä¸‰ç»´é«˜æ–¯æ’å€¼ï¼ˆ3DGSï¼‰çš„14ç»´å‚æ•°åŒ–è¿›è¡Œå‡ ä½•å’Œå¤–è§‚çš„è”åˆä¼˜åŒ–ï¼Œå®ç°äº†ç‰©ç†å¯å®ç°çš„ä¼˜åŒ–æ–¹å¼ã€‚ä¸åŒäºä¾èµ–è¡¥ä¸æˆ–çº¹ç†ä¼˜åŒ–çš„å…ˆå‰æ–¹æ³•ï¼Œ3DGAAè”åˆæ‰°åŠ¨å‡ ä½•å±æ€§ï¼ˆå½¢çŠ¶ã€å°ºåº¦ã€æ—‹è½¬ï¼‰å’Œå¤–è§‚å±æ€§ï¼ˆé¢œè‰²ã€é€æ˜åº¦ï¼‰ï¼Œç”Ÿæˆå…·æœ‰ç‰©ç†çœŸå®æ€§å’Œå¯è½¬ç§»æ€§çš„å¯¹æŠ—æ€§ç‰©ä½“ã€‚æ­¤å¤–ï¼Œå¼•å…¥ç‰©ç†æ»¤æ³¢æ¨¡å—è¿‡æ»¤å¼‚å¸¸å€¼ä»¥ä¿æŒå‡ ä½•ä¿çœŸåº¦ï¼Œå¹¶å¼•å…¥ç‰©ç†å¢å¼ºæ¨¡å—æ¨¡æ‹Ÿå¤æ‚ç‰©ç†åœºæ™¯ä»¥å¢å¼ºåœ¨ç°å®æ¡ä»¶ä¸‹çš„æ”»å‡»é€šç”¨æ€§ã€‚åœ¨è™šæ‹ŸåŸºå‡†æµ‹è¯•å’Œç‰©ç†ç¯å¢ƒè®¾ç½®ä¸­ï¼Œä½¿ç”¨å¾®å‹è½¦è¾†æ¨¡å‹å¯¹3DGAAè¿›è¡Œè¯„ä¼°ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œ3DGAAå°†æ£€æµ‹mAPä»87.21%é™ä½åˆ°7.38%ï¼Œæ˜¾è‘—ä¼˜äºç°æœ‰ä¸‰ç»´ç‰©ç†æ”»å‡»ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•åœ¨ä¸åŒç‰©ç†æ¡ä»¶ä¸‹ä¿æŒé«˜å¯è½¬ç§»æ€§ï¼Œæˆä¸ºç‰©ç†å¯å®ç°å¯¹æŠ—æ”»å‡»çš„æœ€æ–°é¡¶å°–æŠ€æœ¯ã€‚</p>
<p><strong>å…³é”®è¦ç‚¹</strong></p>
<p>ä¸€ã€æ–°å‹å¯¹æŠ—æ€§ç‰©ä½“ç”Ÿæˆæ¡†æ¶ï¼šæå‡ºäº†ä¸€ç§åŸºäºä¸‰ç»´é«˜æ–¯çš„æ–°å‹å¯¹æŠ—æ”»å‡»æ–¹æ³•â€”â€”ä¸‰ç»´é«˜æ–¯å¯¹æŠ—æ”»å‡»ï¼ˆ3DGAAï¼‰ã€‚</p>
<p>äºŒã€ä¼˜åŒ–æ–¹å¼ï¼šåˆ©ç”¨ä¸‰ç»´é«˜æ–¯æ’å€¼ï¼ˆ3DGSï¼‰çš„14ç»´å‚æ•°åŒ–è¿›è¡Œå‡ ä½•å’Œå¤–è§‚çš„è”åˆä¼˜åŒ–ï¼Œå®ç°ç‰©ç†å¯å®ç°çš„ä¼˜åŒ–æ‰‹æ®µã€‚</p>
<p>ä¸‰ã€ä¸ä¼ ç»Ÿæ–¹æ³•çš„åŒºåˆ«ï¼šä¸ä¼ ç»Ÿçš„ä¾èµ–äºè¡¥ä¸æˆ–çº¹ç†ä¼˜åŒ–çš„æ–¹æ³•ä¸åŒï¼Œ3DGAAåŒæ—¶æ‰°åŠ¨å‡ ä½•å’Œå¤–è§‚å±æ€§ã€‚</p>
<p>å››ã€ç‰©ç†æ»¤æ³¢å’Œå¢å¼ºæ¨¡å—ï¼šå¼•å…¥ç‰©ç†æ»¤æ³¢æ¨¡å—ä¿æŒå‡ ä½•çœŸå®æ€§ï¼Œå¼•å…¥ç‰©ç†å¢å¼ºæ¨¡å—ä»¥å¢å¼ºæ”»å‡»åœ¨ç°å®æ¡ä»¶ä¸‹çš„é€šç”¨æ€§ã€‚</p>
<p>äº”ã€å®éªŒéªŒè¯ï¼šåœ¨è™šæ‹ŸåŸºå‡†å’Œç‰©ç†ç¯å¢ƒè®¾ç½®ä¸­çš„è¯„ä¼°æ˜¾ç¤ºï¼Œ3DGAAæ˜¾è‘—é™ä½äº†ç‰©ä½“æ£€æµ‹ç²¾åº¦ï¼Œå¹¶è¡¨ç°å‡ºä¼˜ç§€çš„è·¨ç‰©ç†æ¡ä»¶å¯è½¬ç§»æ€§ã€‚</p>
<p>å…­ã€æ€§èƒ½è¶…è¶Šï¼šç›¸è¾ƒäºç°æœ‰ä¸‰ç»´ç‰©ç†æ”»å‡»ï¼Œ3DGAAå–å¾—äº†æ˜¾è‘—çš„ä¼˜åŠ¿ã€‚</p>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2507.09993">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-0b37211a7f205593ce6c45b05ce3ce14.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-8e466725d1214028944ecd6f6408ad65.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-41273987c8c24b2f2c2c97cf6727f0f5" align="middle">
<img src="https://picx.zhimg.com/v2-340c3ee84b8a0616eda229eb7d1b8f3b" align="middle">
<img src="https://picx.zhimg.com/v2-a64933e04bbd3934c6b99595e92319f6" align="middle">
</details>


<h1 id="-14"><a href="#-14" class="headerlink" title=""></a></h1><h2 id="ODE-GS-Latent-ODEs-for-Dynamic-Scene-Extrapolation-with-3D-Gaussian-Splatting"><a href="#ODE-GS-Latent-ODEs-for-Dynamic-Scene-Extrapolation-with-3D-Gaussian-Splatting" class="headerlink" title="ODE-GS: Latent ODEs for Dynamic Scene Extrapolation with 3D Gaussian   Splatting"></a>ODE-GS: Latent ODEs for Dynamic Scene Extrapolation with 3D Gaussian   Splatting</h2><p><strong>Authors:Daniel Wang, Patrick Rim, Tian Tian, Alex Wong, Ganesh Sundaramoorthi</strong></p>
<p>We introduce ODE-GS, a novel approach that integrates 3D Gaussian Splatting with latent neural ordinary differential equations (ODEs) to enable future extrapolation of dynamic 3D scenes. Unlike existing dynamic scene reconstruction methods, which rely on time-conditioned deformation networks and are limited to interpolation within a fixed time window, ODE-GS eliminates timestamp dependency by modeling Gaussian parameter trajectories as continuous-time latent dynamics. Our approach first learns an interpolation model to generate accurate Gaussian trajectories within the observed window, then trains a Transformer encoder to aggregate past trajectories into a latent state evolved via a neural ODE. Finally, numerical integration produces smooth, physically plausible future Gaussian trajectories, enabling rendering at arbitrary future timestamps. On the D-NeRF, NVFi, and HyperNeRF benchmarks, ODE-GS achieves state-of-the-art extrapolation performance, improving metrics by 19.8% compared to leading baselines, demonstrating its ability to accurately represent and predict 3D scene dynamics. </p>
<blockquote>
<p>æˆ‘ä»¬ä»‹ç»äº†ODE-GSï¼Œè¿™æ˜¯ä¸€ç§å°†3Dé«˜æ–¯Splattingä¸æ½œåœ¨ç¥ç»å¸¸å¾®åˆ†æ–¹ç¨‹ï¼ˆODEsï¼‰ç›¸ç»“åˆçš„æ–°å‹æ–¹æ³•ï¼Œèƒ½å¤Ÿå¯¹åŠ¨æ€3Dåœºæ™¯è¿›è¡Œæœªæ¥å¤–æ¨ã€‚ä¸ç°æœ‰çš„ä¾èµ–äºæ—¶é—´æ¡ä»¶å˜å½¢ç½‘ç»œä¸”ä»…é™äºå›ºå®šæ—¶é—´çª—å£å†…æ’å€¼çš„åŠ¨æ€åœºæ™¯é‡å»ºæ–¹æ³•ä¸åŒï¼ŒODE-GSé€šè¿‡æ¨¡æ‹Ÿé«˜æ–¯å‚æ•°è½¨è¿¹ä½œä¸ºè¿ç»­æ—¶é—´çš„æ½œåœ¨åŠ¨æ€æ€§ï¼Œæ¶ˆé™¤äº†æ—¶é—´æˆ³ä¾èµ–ã€‚æˆ‘ä»¬çš„æ–¹æ³•é¦–å…ˆå­¦ä¹ ä¸€ä¸ªæ’å€¼æ¨¡å‹ï¼Œåœ¨è§‚å¯Ÿçª—å£å†…ç”Ÿæˆå‡†ç¡®çš„é«˜æ–¯è½¨è¿¹ï¼Œç„¶åè®­ç»ƒä¸€ä¸ªTransformerç¼–ç å™¨ï¼Œå°†è¿‡å»è½¨è¿¹èšåˆæˆä¸€ä¸ªé€šè¿‡ç¥ç»ODEæ¼”åŒ–çš„æ½œåœ¨çŠ¶æ€ã€‚æœ€åï¼Œæ•°å€¼ç§¯åˆ†ç”Ÿæˆå¹³æ»‘ä¸”ç‰©ç†ä¸Šåˆç†çš„æœªæ¥é«˜æ–¯è½¨è¿¹ï¼Œèƒ½å¤Ÿåœ¨ä»»æ„æœªæ¥æ—¶é—´æˆ³è¿›è¡Œæ¸²æŸ“ã€‚åœ¨D-NeRFã€NVFiå’ŒHyperNeRFåŸºå‡†æµ‹è¯•ä¸­ï¼ŒODE-GSå®ç°äº†æœ€æ–°çš„å¤–æ¨æ€§èƒ½ï¼Œä¸é¢†å…ˆçš„åŸºçº¿ç›¸æ¯”ï¼ŒæŒ‡æ ‡æé«˜äº†19.8%ï¼Œè¯æ˜äº†å…¶å‡†ç¡®è¡¨ç¤ºå’Œé¢„æµ‹3Dåœºæ™¯åŠ¨æ€çš„èƒ½åŠ›ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.05480v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>ODE-GSæ–¹æ³•ç»“åˆ3Dé«˜æ–¯èåˆä¸æ½œåœ¨ç¥ç»å¸¸å¾®åˆ†æ–¹ç¨‹ï¼ˆODEsï¼‰ï¼Œå®ç°äº†åŠ¨æ€3Dåœºæ™¯çš„é¢„æµ‹å¤–æ¨ã€‚ä¸åŒäºä¾èµ–æ—¶é—´æ¡ä»¶å˜å½¢ç½‘ç»œçš„ç°æœ‰åŠ¨æ€åœºæ™¯é‡å»ºæ–¹æ³•ï¼ŒODE-GSé€šè¿‡æ¨¡æ‹Ÿé«˜æ–¯å‚æ•°è½¨è¿¹çš„è¿ç»­æ—¶é—´æ½œåœ¨åŠ¨æ€ï¼Œæ¶ˆé™¤äº†æ—¶é—´æˆ³çš„ä¾èµ–ï¼Œå¹¶èƒ½åœ¨è§‚å¯Ÿåˆ°çš„çª—å£å†…ç”Ÿæˆå‡†ç¡®çš„é«˜æ–¯è½¨è¿¹ã€‚ç„¶åé€šè¿‡ç¥ç»ç½‘ç»œå°†è¿‡å»çš„è½¨è¿¹æ•°æ®åµŒå…¥åˆ°ä¸€ä¸ªæ½œåœ¨çŠ¶æ€ï¼Œæœ€åé€šè¿‡æ•°å€¼ç§¯åˆ†ç”Ÿæˆå¹³æ»‘çš„æœªæ¥é«˜æ–¯è½¨è¿¹ï¼Œå¯åœ¨ä»»æ„æœªæ¥æ—¶é—´æˆ³è¿›è¡Œæ¸²æŸ“ã€‚åœ¨D-NeRFã€NVFiå’ŒHyperNeRFåŸºå‡†æµ‹è¯•ä¸­ï¼ŒODE-GSå®ç°äº†æœ€å…ˆè¿›çš„é¢„æµ‹æ€§èƒ½ï¼Œä¸ç°æœ‰æŠ€æœ¯ç›¸æ¯”æé«˜äº†19.8%ï¼Œå±•ç°äº†å…¶åœ¨é¢„æµ‹å¤æ‚åœºæ™¯åŠ¨æ€æ–¹é¢çš„å¼ºå¤§èƒ½åŠ›ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>ODE-GSç»“åˆäº†3Dé«˜æ–¯èåˆä¸æ½œåœ¨ç¥ç»å¸¸å¾®åˆ†æ–¹ç¨‹ï¼ˆODEsï¼‰ï¼Œå®ç°äº†åŠ¨æ€åœºæ™¯çš„å¤–æ¨é¢„æµ‹ã€‚</li>
<li>è¯¥æ–¹æ³•æ¶ˆé™¤äº†æ—¶é—´æˆ³ä¾èµ–ï¼Œé€šè¿‡æ¨¡æ‹Ÿé«˜æ–¯å‚æ•°è½¨è¿¹çš„è¿ç»­æ—¶é—´æ½œåœ¨åŠ¨æ€æ¥è¿›è¡Œé¢„æµ‹ã€‚</li>
<li>ODE-GSèƒ½åœ¨è§‚å¯Ÿçª—å£å†…ç”Ÿæˆå‡†ç¡®çš„é«˜æ–¯è½¨è¿¹ã€‚</li>
<li>è¯¥æ–¹æ³•é€šè¿‡ç¥ç»ç½‘ç»œåµŒå…¥è¿‡å»è½¨è¿¹æ•°æ®åˆ°ä¸€ä¸ªæ½œåœ¨çŠ¶æ€ï¼Œå¹¶åˆ©ç”¨æ•°å€¼ç§¯åˆ†ç”Ÿæˆæœªæ¥è½¨è¿¹ã€‚</li>
<li>ODE-GSåœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­å®ç°äº†æœ€å…ˆè¿›çš„é¢„æµ‹æ€§èƒ½ã€‚</li>
<li>ä¸ç°æœ‰æŠ€æœ¯ç›¸æ¯”ï¼ŒODE-GSæé«˜äº†é¢„æµ‹æ€§èƒ½ï¼Œæ”¹è¿›å¹…åº¦è¾¾åˆ°19.8%ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.05480">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-f2db1f5f7d52a934fa0e116ba077a28a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d79df23e9b32369928717167c04061cf" align="middle">
<img src="https://picx.zhimg.com/v2-4a46e42365f2ace226e090016a8b3486" align="middle">
</details>


<h1 id="-15"><a href="#-15" class="headerlink" title=""></a></h1><h2 id="In-2-4D-Inbetweening-from-Two-Single-View-Images-to-4D-Generation"><a href="#In-2-4D-Inbetweening-from-Two-Single-View-Images-to-4D-Generation" class="headerlink" title="In-2-4D: Inbetweening from Two Single-View Images to 4D Generation"></a>In-2-4D: Inbetweening from Two Single-View Images to 4D Generation</h2><p><strong>Authors:Sauradip Nag, Daniel Cohen-Or, Hao Zhang, Ali Mahdavi-Amiri</strong></p>
<p>We pose a new problem, In-2-4D, for generative 4D (i.e., 3D + motion) inbetweening to interpolate two single-view images. In contrast to video&#x2F;4D generation from only text or a single image, our interpolative task can leverage more precise motion control to better constrain the generation. Given two monocular RGB images representing the start and end states of an object in motion, our goal is to generate and reconstruct the motion in 4D, without making assumptions on the object category, motion type, length, or complexity. To handle such arbitrary and diverse motions, we utilize a foundational video interpolation model for motion prediction. However, large frame-to-frame motion gaps can lead to ambiguous interpretations. To this end, we employ a hierarchical approach to identify keyframes that are visually close to the input states while exhibiting significant motions, then generate smooth fragments between them. For each fragment, we construct a 3D representation of the keyframe using Gaussian Splatting (3DGS). The temporal frames within the fragment guide the motion, enabling their transformation into dynamic 3DGS through a deformation field. To improve temporal consistency and refine the 3D motion, we expand the self-attention of multi-view diffusion across timesteps and apply rigid transformation regularization. Finally, we merge the independently generated 3D motion segments by interpolating boundary deformation fields and optimizing them to align with the guiding video, ensuring smooth and flicker-free transitions. Through extensive qualitative and quantitive experiments as well as a user study, we demonstrate the effectiveness of our method and design choices. </p>
<blockquote>
<p>æˆ‘ä»¬é’ˆå¯¹ç”Ÿæˆå¼4Dï¼ˆå³3D+è¿åŠ¨ï¼‰æ’å€¼æå‡ºä¸€ä¸ªæ–°é—®é¢˜ï¼Œå³In-2-4Dï¼Œç”¨ä»¥æ’å€¼ä¸¤ä¸ªå•è§†å›¾å›¾åƒã€‚ä¸ä»…ä»æ–‡æœ¬æˆ–å•å¹…å›¾åƒç”Ÿæˆè§†é¢‘&#x2F;4Då†…å®¹ä¸åŒï¼Œæˆ‘ä»¬çš„æ’å€¼ä»»åŠ¡å¯ä»¥åˆ©ç”¨æ›´ç²¾ç¡®çš„è¿åŠ¨æ§åˆ¶æ¥æ›´å¥½åœ°çº¦æŸç”Ÿæˆã€‚ç»™å®šä¸¤ä¸ªè¡¨ç¤ºè¿åŠ¨ç‰©ä½“èµ·å§‹å’Œç»“æŸçŠ¶æ€çš„å•ç›®RGBå›¾åƒï¼Œæˆ‘ä»¬çš„ç›®æ ‡æ˜¯ç”Ÿæˆå’Œé‡å»º4Dä¸­çš„è¿åŠ¨ï¼Œè€Œä¸å¯¹ç‰©ä½“ç±»åˆ«ã€è¿åŠ¨ç±»å‹ã€é•¿åº¦æˆ–å¤æ‚æ€§åšå‡ºå‡è®¾ã€‚ä¸ºäº†å¤„ç†è¿™ç§ä»»æ„å’Œå¤šæ ·çš„è¿åŠ¨ï¼Œæˆ‘ä»¬é‡‡ç”¨åŸºç¡€è§†é¢‘æ’å€¼æ¨¡å‹è¿›è¡Œè¿åŠ¨é¢„æµ‹ã€‚ç„¶è€Œï¼Œå¸§åˆ°å¸§çš„è¿åŠ¨é—´éš™è¿‡å¤§å¯èƒ½ä¼šå¯¼è‡´è§£é‡Šæ¨¡ç³Šã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬é‡‡ç”¨åˆ†å±‚æ–¹æ³•è¯†åˆ«è§†è§‰ä¸Šæ¥è¿‘è¾“å…¥çŠ¶æ€ä¸”è¿åŠ¨æ˜¾è‘—çš„å…³é”®å¸§ï¼Œç„¶ååœ¨å®ƒä»¬ä¹‹é—´ç”Ÿæˆå¹³æ»‘ç‰‡æ®µã€‚å¯¹äºæ¯ä¸ªç‰‡æ®µï¼Œæˆ‘ä»¬ä½¿ç”¨é«˜æ–¯æ‹¼è´´ï¼ˆ3DGSï¼‰æ„å»ºå…³é”®å¸§çš„3Dè¡¨ç¤ºã€‚ç‰‡æ®µå†…çš„ä¸´æ—¶å¸§æŒ‡å¯¼è¿åŠ¨ï¼Œé€šè¿‡å˜å½¢åœºå°†å…¶è½¬æ¢ä¸ºåŠ¨æ€3DGSã€‚ä¸ºäº†æé«˜æ—¶é—´ä¸€è‡´æ€§å’Œä¼˜åŒ–3Dè¿åŠ¨ï¼Œæˆ‘ä»¬æ‰©å¤§äº†è·¨æ—¶é—´æ­¥çš„å¤šè§†å›¾æ‰©æ•£çš„è‡ªæ³¨æ„åŠ›ï¼Œå¹¶åº”ç”¨äº†åˆšæ€§å˜æ¢æ­£åˆ™åŒ–ã€‚æœ€åï¼Œæˆ‘ä»¬é€šè¿‡æ’å€¼è¾¹ç•Œå˜å½¢åœºå¹¶å¯¹å…¶è¿›è¡Œä¼˜åŒ–ä»¥ä¸æŒ‡å¯¼è§†é¢‘å¯¹é½ï¼Œåˆå¹¶ç‹¬ç«‹ç”Ÿæˆçš„3Dè¿åŠ¨ç‰‡æ®µï¼Œç¡®ä¿å¹³æ»‘æ— é—ªçƒçš„è¿‡æ¸¡ã€‚é€šè¿‡å¹¿æ³›çš„å®šæ€§å’Œå®šé‡å®éªŒä»¥åŠç”¨æˆ·ç ”ç©¶ï¼Œæˆ‘ä»¬éªŒè¯äº†æˆ‘ä»¬çš„æ–¹æ³•å’Œè®¾è®¡é€‰æ‹©çš„æœ‰æ•ˆæ€§ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.08366v3">PDF</a> SIGGRAPH ASIA 2025; Project page at <a target="_blank" rel="noopener" href="https://in-2-4d.github.io/">https://in-2-4d.github.io/</a></p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºä¸€ä¸ªæ–°çš„ç”Ÿæˆé—®é¢˜ï¼Œå³In-2-4Dé—®é¢˜ï¼Œç”¨äºåœ¨äºŒç»´å›¾åƒä¹‹é—´è¿›è¡Œå››ç»´ï¼ˆå³ä¸‰ç»´åŠ è¿åŠ¨ï¼‰æ’å€¼ã€‚æœ¬æ–‡çš„ç›®æ ‡æ˜¯åœ¨ç»™å®šçš„ä¸¤ä¸ªè¡¨ç¤ºç‰©ä½“è¿åŠ¨èµ·å§‹å’Œç»“æŸçŠ¶æ€çš„å•è§†å›¾å›¾åƒä¹‹é—´ç”Ÿæˆå’Œé‡å»ºå››ç»´è¿åŠ¨ï¼Œæ— éœ€å‡è®¾ç‰©ä½“ç±»åˆ«ã€è¿åŠ¨ç±»å‹ã€é•¿åº¦æˆ–å¤æ‚æ€§ã€‚é€šè¿‡é‡‡ç”¨åˆ†å±‚æ–¹æ³•è¯†åˆ«è§†è§‰ä¸Šæ¥è¿‘è¾“å…¥çŠ¶æ€ä¸”è¿åŠ¨æ˜¾è‘—çš„å…³é”®å¸§ï¼Œç„¶ååœ¨å®ƒä»¬ä¹‹é—´ç”Ÿæˆå¹³æ»‘ç‰‡æ®µï¼Œå¹¶ä½¿ç”¨é«˜æ–¯æ‹¼è´´æŠ€æœ¯ï¼ˆ3DGSï¼‰æ„å»ºæ¯ä¸ªç‰‡æ®µçš„3Dè¡¨ç¤ºã€‚æ—¶é—´å¸§æŒ‡å¯¼è¿åŠ¨ï¼Œå°†å…¶è½¬åŒ–ä¸ºåŠ¨æ€3DGSã€‚é€šè¿‡æ‰©å±•è·¨æ—¶é—´æ­¥çš„å¤šè§†å›¾æ‰©æ•£çš„è‡ªæ³¨æ„åŠ›å¹¶åº”ç”¨åˆšæ€§å˜æ¢æ­£åˆ™åŒ–ï¼Œæé«˜æ—¶é—´ä¸€è‡´æ€§å’Œæ”¹è¿›3Dè¿åŠ¨ã€‚æœ€åï¼Œé€šè¿‡æ’å€¼è¾¹ç•Œå˜å½¢åœºå¹¶è¿›è¡Œä¼˜åŒ–ä¸æŒ‡å¯¼è§†é¢‘å¯¹é½ï¼Œç¡®ä¿å¹³æ»‘ä¸”æ— é—ªçƒçš„è¿‡æ¸¡ã€‚é€šè¿‡å®šæ€§å’Œå®šé‡å®éªŒä»¥åŠç”¨æˆ·ç ”ç©¶è¯æ˜äº†æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æå‡ºæ–°çš„ç”Ÿæˆé—®é¢˜In-2-4Dï¼Œç”¨äºåœ¨äºŒç»´å›¾åƒä¹‹é—´è¿›è¡Œå››ç»´æ’å€¼ã€‚</li>
<li>ç›®æ ‡æ˜¯ä»ä¸¤ä¸ªå•è§†å›¾å›¾åƒç”Ÿæˆå’Œé‡å»ºç‰©ä½“çš„å››ç»´è¿åŠ¨ï¼Œæ— éœ€å¯¹ç‰©ä½“ç±»åˆ«ã€è¿åŠ¨ç±»å‹ç­‰åšå‡ºå‡è®¾ã€‚</li>
<li>é‡‡ç”¨åˆ†å±‚æ–¹æ³•è¯†åˆ«å…³é”®å¸§ï¼Œå¹¶ä½¿ç”¨é«˜æ–¯æ‹¼è´´æŠ€æœ¯æ„å»ºæ¯ä¸ªç‰‡æ®µçš„3Dè¡¨ç¤ºã€‚</li>
<li>æ—¶é—´å¸§æŒ‡å¯¼è¿åŠ¨ï¼Œè½¬åŒ–ä¸ºåŠ¨æ€3DGSã€‚</li>
<li>é€šè¿‡æ‰©å±•è‡ªæ³¨æ„åŠ›å’Œåº”ç”¨åˆšæ€§å˜æ¢æ­£åˆ™åŒ–ï¼Œæé«˜æ—¶é—´ä¸€è‡´æ€§å’Œæ”¹è¿›3Dè¿åŠ¨ã€‚</li>
<li>é€šè¿‡æ’å€¼è¾¹ç•Œå˜å½¢åœºå¹¶è¿›è¡Œä¼˜åŒ–ï¼Œç¡®ä¿å¹³æ»‘ä¸”æ— é—ªçƒçš„è¿‡æ¸¡ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.08366">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-c5f9d2a6522df5cf4e22be693342bd52" align="middle">
<img src="https://picx.zhimg.com/v2-f07ad18c8caba3e7caae453d327c55cb" align="middle">
<img src="https://picx.zhimg.com/v2-e3cec158986cd1f3bbabc3f55ccc1ef6" align="middle">
<img src="https://picx.zhimg.com/v2-0b58601bd601c84dab19b41790adb76b" align="middle">
<img src="https://picx.zhimg.com/v2-1b8f0c144aff19e8b8dc9d86ca74d32f" align="middle">
<img src="https://picx.zhimg.com/v2-915d8dd4def5fc09a7c993a529da6302" align="middle">
</details>


<h1 id="-16"><a href="#-16" class="headerlink" title=""></a></h1><h2 id="PoI-A-Filter-to-Extract-Pixel-of-Interest-from-Novel-View-Synthesis-for-Scene-Coordinate-Regression"><a href="#PoI-A-Filter-to-Extract-Pixel-of-Interest-from-Novel-View-Synthesis-for-Scene-Coordinate-Regression" class="headerlink" title="PoI: A Filter to Extract Pixel of Interest from Novel View Synthesis for   Scene Coordinate Regression"></a>PoI: A Filter to Extract Pixel of Interest from Novel View Synthesis for   Scene Coordinate Regression</h2><p><strong>Authors:Feifei Li, Qi Song, Chi Zhang, Hui Shuai, Rui Huang</strong></p>
<p>Novel View synthesis (NVS) techniques, notably Neural Radiance Fields (NeRF) and 3D Gaussian Splatting (3DGS), can augment camera pose estimation by extending training data with rendered images. However, the images rendered by these methods are often plagued by blurring, undermining their reliability as training data for camera pose estimation. This limitation is particularly critical for Scene Coordinate Regression (SCR) methods, which aim at pixel-level 3D coordinate estimation, because rendering artifacts directly lead to estimation inaccuracies. To address this challenge, we propose a dual-criteria filtering mechanism that dynamically identifies and discards suboptimal pixels during training. The dual-criteria filter evaluates two concurrent metrics: (1) real-time SCR reprojection error, and (2) gradient threshold, across the coordinate regression domain. In addition, for visual localization problems in sparse input scenarios, it will be even more necessary to use data generated by NVS to assist the localization task. We design a coarse-to-fine PoI variant using sparse input NVS to solve this problem. Experiments across indoor and outdoor benchmarks confirm our methodâ€™s efficacy. It achieves state-of-the-art localization accuracy while maintaining computational efficiency. </p>
<blockquote>
<p>æ–°å‹è§†å›¾åˆæˆï¼ˆNVSï¼‰æŠ€æœ¯ï¼Œç‰¹åˆ«æ˜¯ç¥ç»è¾å°„åœºï¼ˆNeRFï¼‰å’Œ3Dé«˜æ–¯å–·å°„ï¼ˆ3DGSï¼‰ï¼Œå¯ä»¥é€šè¿‡ä½¿ç”¨æ¸²æŸ“å›¾åƒæ‰©å±•è®­ç»ƒæ•°æ®æ¥å¢å¼ºç›¸æœºå§¿æ€ä¼°è®¡ã€‚ç„¶è€Œï¼Œè¿™äº›æ–¹æ³•å‘ˆç°çš„æ¸²æŸ“å›¾åƒå¸¸å¸¸å—åˆ°æ¨¡ç³Šçš„å½±å“ï¼Œè¿™ä½¿å¾—å®ƒä»¬ä½œä¸ºç›¸æœºå§¿æ€ä¼°è®¡çš„è®­ç»ƒæ•°æ®çš„å¯é æ€§é™ä½ã€‚è¿™ä¸€å±€é™æ€§å¯¹äºåœºæ™¯åæ ‡å›å½’ï¼ˆSCRï¼‰æ–¹æ³•å°¤ä¸ºé‡è¦ï¼Œå› ä¸ºSCRæ–¹æ³•æ—¨åœ¨è¿›è¡Œåƒç´ çº§çš„3Dåæ ‡ä¼°è®¡ï¼Œæ¸²æŸ“ä¼ªå½±ç›´æ¥å¯¼è‡´ä¼°è®¡ä¸å‡†ç¡®ã€‚ä¸ºäº†åº”å¯¹è¿™ä¸€æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åŒæ ‡å‡†è¿‡æ»¤æœºåˆ¶ï¼Œè¯¥æœºåˆ¶åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­åŠ¨æ€è¯†åˆ«å¹¶ä¸¢å¼ƒæ¬¡ä¼˜åƒç´ ã€‚åŒæ ‡å‡†è¿‡æ»¤å™¨è¯„ä¼°ä¸¤ä¸ªå¹¶è¡ŒæŒ‡æ ‡ï¼šï¼ˆ1ï¼‰å®æ—¶SCRé‡æŠ•å½±è¯¯å·®å’Œï¼ˆ2ï¼‰åæ ‡å›å½’åŸŸå†…çš„æ¢¯åº¦é˜ˆå€¼ã€‚æ­¤å¤–ï¼Œåœ¨ç¨€ç–è¾“å…¥çš„è§†è§‰å®šä½é—®é¢˜ä¸­ï¼Œä½¿ç”¨NVSç”Ÿæˆçš„æ•°æ®è¾…åŠ©å®šä½ä»»åŠ¡å°†å˜å¾—æ›´åŠ å¿…è¦ã€‚æˆ‘ä»¬è®¾è®¡äº†ä¸€ç§ä½¿ç”¨ç¨€ç–è¾“å…¥NVSçš„ç”±ç²—åˆ°ç»†çš„PoIå˜ä½“æ¥è§£å†³è¿™ä¸ªé—®é¢˜ã€‚å®¤å†…å’Œå®¤å¤–åŸºå‡†æµ‹è¯•çš„å®éªŒç»“æœè¯å®äº†æˆ‘ä»¬çš„æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚å®ƒåœ¨ä¿æŒè®¡ç®—æ•ˆç‡çš„åŒæ—¶å®ç°äº†æœ€å…ˆè¿›çš„å®šä½ç²¾åº¦ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.04843v4">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>NeRFå’Œ3DGSç­‰æ–°å‹è§†å›¾åˆæˆæŠ€æœ¯å¯ä»¥é€šè¿‡ç”Ÿæˆæ¸²æŸ“å›¾åƒæ¥æ‰©å……è®­ç»ƒæ•°æ®ï¼Œä»è€Œæå‡ç›¸æœºå§¿æ€ä¼°è®¡çš„å‡†ç¡®åº¦ã€‚ç„¶è€Œï¼Œè¿™äº›æŠ€æœ¯ç”Ÿæˆçš„å›¾åƒå¸¸å¸¸å­˜åœ¨æ¨¡ç³Šé—®é¢˜ï¼Œè¿™ä¼šå¯¹ä½œä¸ºç›¸æœºå§¿æ€ä¼°è®¡è®­ç»ƒæ•°æ®çš„å¯é æ€§é€ æˆå½±å“ã€‚é’ˆå¯¹è¿™ä¸€é—®é¢˜ï¼Œæ–‡ç« æå‡ºäº†ä¸€ç§åŸºäºåŒé‡æ ‡å‡†çš„è¿‡æ»¤æœºåˆ¶ï¼Œè¯¥æœºåˆ¶èƒ½åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­åŠ¨æ€è¯†åˆ«å¹¶å‰”é™¤è¡¨ç°ä¸ä½³çš„åƒç´ ç‚¹ã€‚åŒé‡æ ‡å‡†è¿‡æ»¤å™¨åŒæ—¶è¯„ä¼°å®æ—¶åœºæ™¯åæ ‡å›å½’é‡æŠ•å½±è¯¯å·®å’Œæ¢¯åº¦é˜ˆå€¼ä¸¤ä¸ªæŒ‡æ ‡ï¼Œä»¥æé«˜åæ ‡å›å½’é¢†åŸŸçš„ä¼°è®¡ç²¾åº¦ã€‚æ­¤å¤–ï¼Œå¯¹äºç¨€ç–è¾“å…¥æƒ…å†µä¸‹çš„è§†è§‰å®šä½é—®é¢˜ï¼Œä½¿ç”¨æ–°å‹è§†å›¾åˆæˆæŠ€æœ¯è¾…åŠ©å®šä½ä»»åŠ¡å°¤ä¸ºå¿…è¦ã€‚è®¾è®¡äº†ä¸€ç§åŸºäºç¨€ç–è¾“å…¥çš„ç²—åˆ°ç»†çš„PoIå˜ä½“æ–¹æ³•æ¥è§£å†³è¿™ä¸€é—®é¢˜ï¼Œå¹¶åœ¨å®¤å†…å’Œå®¤å¤–åŸºå‡†æµ‹è¯•ä¸Šè¿›è¡Œäº†å®éªŒéªŒè¯ï¼Œè¯¥æ–¹æ³•åœ¨è®¡ç®—æ•ˆç‡çš„åŒæ—¶å®ç°äº†æœ€å…ˆè¿›çš„å®šä½ç²¾åº¦ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>NVSæŠ€æœ¯å¦‚NeRFå’Œ3DGSèƒ½å¤Ÿç”Ÿæˆæ¸²æŸ“å›¾åƒæ¥ä¸°å¯Œè®­ç»ƒæ•°æ®ï¼Œè¿›è€Œæ”¹è¿›ç›¸æœºå§¿æ€ä¼°è®¡ã€‚</li>
<li>æ¸²æŸ“å›¾åƒä¸­å¸¸è§çš„æ¨¡ç³Šé—®é¢˜ä¼šå½±å“è®­ç»ƒæ•°æ®ä½œä¸ºç›¸æœºå§¿æ€ä¼°è®¡çš„å¯é æ€§ã€‚</li>
<li>åŒé‡æ ‡å‡†çš„è¿‡æ»¤æœºåˆ¶èƒ½åŠ¨æ€å‰”é™¤è¡¨ç°ä¸ä½³çš„åƒç´ ç‚¹ï¼ŒåŒæ—¶è€ƒè™‘å®æ—¶åœºæ™¯åæ ‡å›å½’é‡æŠ•å½±è¯¯å·®å’Œæ¢¯åº¦é˜ˆå€¼ä¸¤ä¸ªæŒ‡æ ‡ã€‚</li>
<li>æå‡ºçš„æœºåˆ¶æé«˜äº†åæ ‡å›å½’é¢†åŸŸçš„ä¼°è®¡ç²¾åº¦ã€‚</li>
<li>åœ¨ç¨€ç–è¾“å…¥æƒ…å†µä¸‹ï¼Œä½¿ç”¨NVSæŠ€æœ¯è¾…åŠ©è§†è§‰å®šä½ä»»åŠ¡ååˆ†é‡è¦ã€‚</li>
<li>è®¾è®¡çš„ç²—åˆ°ç»†çš„PoIæ–¹æ³•åŸºäºç¨€ç–è¾“å…¥ï¼Œæ—¨åœ¨è§£å†³è§†è§‰å®šä½é—®é¢˜ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.04843">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-4085ada383e57ca40ad86b2e077ab791" align="middle">
<img src="https://picx.zhimg.com/v2-77cf7e02c4d0b2c361452fb21a3bd08e" align="middle">
<img src="https://picx.zhimg.com/v2-986f4980b8d00c18d186c16678604798.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-613f1b53c4bcb69a375ccde5bac6f51f" align="middle">
<img src="https://picx.zhimg.com/v2-8950ff5bbe779c91dee353b39686cae5" align="middle">
<img src="https://picx.zhimg.com/v2-c0997ddf3af0a3159f13ff8d5374aee4.jpg" align="middle">
</details>


<h1 id="-17"><a href="#-17" class="headerlink" title=""></a></h1><h2 id="PERSE-Personalized-3D-Generative-Avatars-from-A-Single-Portrait"><a href="#PERSE-Personalized-3D-Generative-Avatars-from-A-Single-Portrait" class="headerlink" title="PERSE: Personalized 3D Generative Avatars from A Single Portrait"></a>PERSE: Personalized 3D Generative Avatars from A Single Portrait</h2><p><strong>Authors:Hyunsoo Cha, Inhee Lee, Hanbyul Joo</strong></p>
<p>We present PERSE, a method for building a personalized 3D generative avatar from a reference portrait. Our avatar enables facial attribute editing in a continuous and disentangled latent space to control each facial attribute, while preserving the individualâ€™s identity. To achieve this, our method begins by synthesizing large-scale synthetic 2D video datasets, where each video contains consistent changes in facial expression and viewpoint, along with variations in a specific facial attribute from the original input. We propose a novel pipeline to produce high-quality, photorealistic 2D videos with facial attribute editing. Leveraging this synthetic attribute dataset, we present a personalized avatar creation method based on 3D Gaussian Splatting, learning a continuous and disentangled latent space for intuitive facial attribute manipulation. To enforce smooth transitions in this latent space, we introduce a latent space regularization technique by using interpolated 2D faces as supervision. Compared to previous approaches, we demonstrate that PERSE generates high-quality avatars with interpolated attributes while preserving the identity of the reference individual. </p>
<blockquote>
<p>æˆ‘ä»¬æå‡ºäº†PERSEæ–¹æ³•ï¼Œè¯¥æ–¹æ³•å¯ä»¥ä»å‚è€ƒè‚–åƒæ„å»ºä¸ªæ€§åŒ–çš„3Dç”Ÿæˆå¤´åƒã€‚æˆ‘ä»¬çš„å¤´åƒèƒ½å¤Ÿåœ¨è¿ç»­ä¸”åˆ†ç¦»çš„ç‰¹å¾ç©ºé—´ä¸­å¯¹é¢éƒ¨ç‰¹å¾è¿›è¡Œç¼–è¾‘ï¼Œä»¥æ§åˆ¶æ¯ä¸ªé¢éƒ¨ç‰¹å¾ï¼ŒåŒæ—¶ä¿ç•™ä¸ªäººçš„èº«ä»½ç‰¹å¾ã€‚ä¸ºäº†å®ç°è¿™ä¸€ç‚¹ï¼Œæˆ‘ä»¬çš„æ–¹æ³•é¦–å…ˆåˆæˆå¤§è§„æ¨¡åˆæˆäºŒç»´è§†é¢‘æ•°æ®é›†ï¼Œæ¯ä¸ªè§†é¢‘éƒ½åŒ…å«é¢éƒ¨è¡¨æƒ…å’Œè§†è§’çš„ä¸€è‡´å˜åŒ–ï¼Œä»¥åŠåŸå§‹è¾“å…¥ä¸­ç‰¹å®šé¢éƒ¨ç‰¹å¾çš„å˜åŒ–ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°çš„æµç¨‹æ¥ç”Ÿæˆé«˜è´¨é‡ã€é€¼çœŸçš„äºŒç»´è§†é¢‘ï¼Œå¹¶è¿›è¡Œé¢éƒ¨ç‰¹å¾ç¼–è¾‘ã€‚åˆ©ç”¨è¿™ä¸ªåˆæˆå±æ€§æ•°æ®é›†ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åŸºäºä¸ªæ€§åŒ–å¤´åƒåˆ›å»ºæ–¹æ³•çš„ä¸‰ç»´é«˜æ–¯æ‹¼è´´æŠ€æœ¯ï¼Œå­¦ä¹ ä¸€ä¸ªè¿ç»­ä¸”åˆ†ç¦»çš„ç‰¹å¾ç©ºé—´ï¼Œä»¥ä¾¿äºç›´è§‚åœ°è¿›è¡Œé¢éƒ¨ç‰¹å¾æ“ä½œã€‚ä¸ºäº†åœ¨è¿™ä¸ªç‰¹å¾ç©ºé—´ä¸­å®ç°å¹³æ»‘è¿‡æ¸¡ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§ç‰¹å¾ç©ºé—´æ­£åˆ™åŒ–æŠ€æœ¯ï¼Œä½¿ç”¨æ’å€¼äºŒç»´é¢éƒ¨ä½œä¸ºç›‘ç£ã€‚ä¸ä»¥å‰çš„æ–¹æ³•ç›¸æ¯”ï¼Œæˆ‘ä»¬è¯æ˜PERSEå¯ä»¥ç”Ÿæˆé«˜è´¨é‡å¤´åƒï¼Œå…·æœ‰æ’å€¼å±æ€§ï¼ŒåŒæ—¶ä¿ç•™å‚è€ƒä¸ªä½“çš„èº«ä»½ç‰¹å¾ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.21206v2">PDF</a> Accepted to CVPR 2025, Project Page:   <a target="_blank" rel="noopener" href="https://hyunsoocha.github.io/perse/">https://hyunsoocha.github.io/perse/</a></p>
<p><strong>Summary</strong></p>
<p>è¯¥é¡¹ç›®æå‡ºäº†ä¸€ç§åŸºäºå‚è€ƒè‚–åƒæ„å»ºä¸ªæ€§åŒ–3Dç”Ÿæˆå¤´åƒçš„æ–¹æ³•PERSEã€‚è¯¥æ–¹æ³•èƒ½å¤Ÿåœ¨è¿ç»­çš„ã€åˆ†ç¦»çš„æ½œåœ¨ç©ºé—´ä¸­å¯¹å¤´åƒçš„é¢éƒ¨å±æ€§è¿›è¡Œç¼–è¾‘ï¼ŒåŒæ—¶ä¿æŒä¸ªä½“èº«ä»½çš„è¯†åˆ«ã€‚å®ƒé€šè¿‡åˆæˆå¤§è§„æ¨¡äºŒç»´è§†é¢‘æ•°æ®é›†å¼€å§‹ï¼Œæ¯ä¸ªè§†é¢‘åŒ…å«é¢éƒ¨è¡¨æƒ…å’Œè§†è§’çš„ä¸€è‡´å˜åŒ–ï¼Œä»¥åŠæ¥è‡ªåŸå§‹è¾“å…¥çš„ç‰¹å®šé¢éƒ¨å±æ€§çš„å˜åŒ–ã€‚åŸºäºæ­¤åˆæˆå±æ€§æ•°æ®é›†ï¼Œç ”ç©¶æå‡ºäº†ä¸€ç§åŸºäº3Dé«˜æ–¯æ‹¼è´´çš„ä¸ªäººåŒ–å¤´åƒåˆ›å»ºæ–¹æ³•ï¼Œå­¦ä¹ ä¸€ä¸ªè¿ç»­çš„ã€åˆ†ç¦»çš„æ½œåœ¨ç©ºé—´ä»¥è¿›è¡Œç›´è§‚çš„é¢éƒ¨å±æ€§æ“ä½œã€‚é€šè¿‡æ’å€¼äºŒç»´é¢å­”ä½œä¸ºç›‘ç£å¼•å…¥æ½œåœ¨ç©ºé—´çš„æ­£åˆ™åŒ–æŠ€æœ¯ï¼Œä»¥ç¡®ä¿åœ¨æ­¤æ½œåœ¨ç©ºé—´ä¸­å®ç°å¹³æ»‘è¿‡æ¸¡ã€‚ä¸ä»¥å‰çš„æ–¹æ³•ç›¸æ¯”ï¼ŒPERSEç”Ÿæˆçš„å¤´åƒè´¨é‡æ›´é«˜ï¼Œå±æ€§æ’å€¼è‡ªç„¶ï¼ŒåŒæ—¶ä¿æŒäº†å‚è€ƒä¸ªä½“çš„èº«ä»½ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>PERSEæ–¹æ³•èƒ½å¤ŸåŸºäºå‚è€ƒè‚–åƒæ„å»ºä¸ªæ€§åŒ–3Dç”Ÿæˆå¤´åƒã€‚</li>
<li>å®ƒåœ¨è¿ç»­çš„ã€åˆ†ç¦»çš„æ½œåœ¨ç©ºé—´ä¸­å¯¹å¤´åƒçš„é¢éƒ¨å±æ€§è¿›è¡Œç¼–è¾‘ã€‚</li>
<li>è¯¥æ–¹æ³•é€šè¿‡åˆæˆå¤§è§„æ¨¡äºŒç»´è§†é¢‘æ•°æ®é›†å¼€å§‹ï¼ŒåŒ…å«é¢éƒ¨è¡¨æƒ…ã€è§†è§’ä»¥åŠç‰¹å®šé¢éƒ¨å±æ€§çš„å˜åŒ–ã€‚</li>
<li>åˆ©ç”¨åˆæˆå±æ€§æ•°æ®é›†ï¼Œé‡‡ç”¨åŸºäº3Dé«˜æ–¯æ‹¼è´´çš„æ–¹æ³•åˆ›å»ºä¸ªæ€§åŒ–å¤´åƒã€‚</li>
<li>å­¦ä¹ äº†ä¸€ä¸ªè¿ç»­çš„ã€åˆ†ç¦»çš„æ½œåœ¨ç©ºé—´ä»¥è¿›è¡Œç›´è§‚çš„é¢éƒ¨å±æ€§æ“ä½œã€‚</li>
<li>é€šè¿‡æ’å€¼äºŒç»´é¢å­”ä½œä¸ºç›‘ç£å¼•å…¥æ½œåœ¨ç©ºé—´çš„æ­£åˆ™åŒ–æŠ€æœ¯ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.21206">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-e8032777091b408b8f3b3a73981aea28" align="middle">
<img src="https://picx.zhimg.com/v2-474b98a9988f8a5141c213ab4b7fbfd6" align="middle">
<img src="https://picx.zhimg.com/v2-5220ae1fa2269d4988462bd2b3251389" align="middle">
<img src="https://picx.zhimg.com/v2-ef61ae7b9a79d00fcc5234d9c9b25a4b" align="middle">
<img src="https://picx.zhimg.com/v2-bebebabc18087cf22d4fb980fbf44b5a.jpg" align="middle">
</details>


<h1 id="-18"><a href="#-18" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-10-01/3DGS/">https://kedreamix.github.io/Talk2Paper/Paper/2025-10-01/3DGS/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/3DGS/">
                                    <span class="chip bg-color">3DGS</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-10-01/NeRF/">
                    <div class="card-image">
                        
                        <img src="https://pic1.zhimg.com/v2-4085ada383e57ca40ad86b2e077ab791.jpg" class="responsive-img" alt="NeRF">
                        
                        <span class="card-title">NeRF</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            NeRF æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-10-01  Triangle Splatting+ Differentiable Rendering with Opaque Triangles
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-10-01
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/NeRF/" class="post-category">
                                    NeRF
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/NeRF/">
                        <span class="chip bg-color">NeRF</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-10-01/%E5%85%83%E5%AE%87%E5%AE%99_%E8%99%9A%E6%8B%9F%E4%BA%BA/">
                    <div class="card-image">
                        
                        <img src="https://pic1.zhimg.com/v2-789fa7bb29889924cc2d064ef6ef8521.jpg" class="responsive-img" alt="å…ƒå®‡å®™/è™šæ‹Ÿäºº">
                        
                        <span class="card-title">å…ƒå®‡å®™/è™šæ‹Ÿäºº</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            å…ƒå®‡å®™/è™šæ‹Ÿäºº æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-10-01  SIE3D Single-image Expressive 3D Avatar generation via Semantic   Embedding and Perceptual Expression Loss
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-10-01
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/%E5%85%83%E5%AE%87%E5%AE%99-%E8%99%9A%E6%8B%9F%E4%BA%BA/" class="post-category">
                                    å…ƒå®‡å®™/è™šæ‹Ÿäºº
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/%E5%85%83%E5%AE%87%E5%AE%99-%E8%99%9A%E6%8B%9F%E4%BA%BA/">
                        <span class="chip bg-color">å…ƒå®‡å®™/è™šæ‹Ÿäºº</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">32306k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
