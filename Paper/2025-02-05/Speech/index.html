<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Speech">
    <meta name="description" content="Speech æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-02-05  SELMA A Speech-Enabled Language Model for Virtual Assistant   Interactions">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>Speech | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://picx.zhimg.com/v2-021237d826480c29139f3dc0970fc579.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Speech</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/Speech/">
                                <span class="chip bg-color">Speech</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/Speech/" class="post-category">
                                Speech
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-02-05
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-05-14
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    7.3k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    29 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-02-05-æ›´æ–°"><a href="#2025-02-05-æ›´æ–°" class="headerlink" title="2025-02-05 æ›´æ–°"></a>2025-02-05 æ›´æ–°</h1><h2 id="SELMA-A-Speech-Enabled-Language-Model-for-Virtual-Assistant-Interactions"><a href="#SELMA-A-Speech-Enabled-Language-Model-for-Virtual-Assistant-Interactions" class="headerlink" title="SELMA: A Speech-Enabled Language Model for Virtual Assistant   Interactions"></a>SELMA: A Speech-Enabled Language Model for Virtual Assistant   Interactions</h2><p><strong>Authors:Dominik Wagner, Alexander Churchill, Siddharth Sigtia, Erik Marchi</strong></p>
<p>In this work, we present and evaluate SELMA, a Speech-Enabled Language Model for virtual Assistant interactions that integrates audio and text as inputs to a Large Language Model (LLM). SELMA is designed to handle three primary and two auxiliary tasks related to interactions with virtual assistants simultaneously within a single end-to-end model. We employ low-rank adaptation modules for parameter-efficient training of both the audio encoder and the LLM. Additionally, we implement a feature pooling strategy enabling the system to recognize global patterns and improve accuracy on tasks less reliant on individual sequence elements. Experimental results on Voice Trigger (VT) detection, Device-Directed Speech Detection (DDSD), and Automatic Speech Recognition (ASR), demonstrate that our approach both simplifies the typical input processing pipeline of virtual assistants significantly and also improves performance compared to dedicated models for each individual task. SELMA yields relative Equal-Error Rate improvements of 64% on the VT detection task, and 22% on DDSD, while also achieving word error rates close to the baseline. </p>
<blockquote>
<p>åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬ä»‹ç»å¹¶è¯„ä¼°äº†SELMAï¼Œè¿™æ˜¯ä¸€ä¸ªç”¨äºè™šæ‹ŸåŠ©ç†äº¤äº’çš„è¯­éŸ³èµ‹èƒ½è¯­è¨€æ¨¡å‹ï¼Œå®ƒå°†éŸ³é¢‘å’Œæ–‡æœ¬ä½œä¸ºè¾“å…¥é›†æˆåˆ°å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä¸­ã€‚SELMAè¢«è®¾è®¡ç”¨äºåœ¨ä¸€ä¸ªç«¯åˆ°ç«¯çš„æ¨¡å‹ä¸­åŒæ—¶å¤„ç†ä¸è™šæ‹ŸåŠ©ç†äº¤äº’ç›¸å…³çš„ä¸‰ä¸ªä¸»è¦ä»»åŠ¡å’Œä¸¤ä¸ªè¾…åŠ©ä»»åŠ¡ã€‚æˆ‘ä»¬é‡‡ç”¨ä½é˜¶é€‚åº”æ¨¡å—ï¼Œå®ç°éŸ³é¢‘ç¼–ç å™¨å’Œå¤§è¯­è¨€æ¨¡å‹çš„å‚æ•°é«˜æ•ˆè®­ç»ƒã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å®æ–½äº†ä¸€ç§ç‰¹å¾æ± ç­–ç•¥ï¼Œä½¿ç³»ç»Ÿèƒ½å¤Ÿè¯†åˆ«å…¨å±€æ¨¡å¼ï¼Œæé«˜å¯¹ä¸ä¾èµ–ä¸ªåˆ«åºåˆ—å…ƒç´ çš„ä»»åŠ¡çš„å‡†ç¡®æ€§ã€‚åœ¨è¯­éŸ³è§¦å‘ï¼ˆVTï¼‰æ£€æµ‹ã€å®šå‘è®¾å¤‡è¯­éŸ³æ£€æµ‹ï¼ˆDDSDï¼‰å’Œè‡ªåŠ¨è¯­éŸ³è¯†åˆ«ï¼ˆASRï¼‰æ–¹é¢çš„å®éªŒç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•å¤§å¤§ç®€åŒ–äº†è™šæ‹ŸåŠ©ç†çš„å…¸å‹è¾“å…¥å¤„ç†ç®¡é“ï¼Œä¸ä¸ºæ¯ä¸ªå•ç‹¬ä»»åŠ¡è®¾è®¡çš„æ¨¡å‹ç›¸æ¯”ï¼Œè¿˜æé«˜äº†æ€§èƒ½ã€‚åœ¨VTæ£€æµ‹ä»»åŠ¡ä¸Šï¼ŒSELMAçš„ç›¸å¯¹ç­‰é”™è¯¯ç‡æé«˜äº†64%ï¼Œåœ¨DDSDä¸Šæé«˜äº†22%ï¼ŒåŒæ—¶å®ç°äº†æ¥è¿‘åŸºå‡†å€¼çš„è¯é”™è¯¯ç‡ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.19377v2">PDF</a> Accepted at ICASSP 2025</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†SELMAï¼Œä¸€ä¸ªç”¨äºè™šæ‹ŸåŠ©ç†äº¤äº’çš„è¯­éŸ³é©±åŠ¨è¯­è¨€æ¨¡å‹ã€‚å®ƒé€šè¿‡æ•´åˆéŸ³é¢‘å’Œæ–‡æœ¬è¾“å…¥åˆ°å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä¸­ï¼Œå¯åŒæ—¶å¤„ç†ä¸‰é¡¹ä¸»è¦ä»»åŠ¡å’Œä¸¤é¡¹è¾…åŠ©ä»»åŠ¡ã€‚ä½¿ç”¨ä½ç§©è‡ªé€‚åº”æ¨¡å—å®ç°éŸ³é¢‘ç¼–ç å™¨å’ŒLLMçš„å‚æ•°æœ‰æ•ˆè®­ç»ƒã€‚é‡‡ç”¨ç‰¹å¾æ± ç­–ç•¥æé«˜ç³»ç»Ÿå¯¹å…¨å±€æ¨¡å¼çš„è¯†åˆ«èƒ½åŠ›ï¼Œå¹¶åœ¨ä¾èµ–å•ä¸ªåºåˆ—å…ƒç´ è¾ƒå°‘çš„ä»»åŠ¡ä¸Šæé«˜å‡†ç¡®æ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œåœ¨è¯­éŸ³è§¦å‘æ£€æµ‹ã€è®¾å¤‡å®šå‘è¯­éŸ³è¯†åˆ«å’Œè‡ªåŠ¨è¯­éŸ³è¯†åˆ«ä»»åŠ¡ä¸Šï¼Œä¸ä¸ºæ¯ä¸ªå•ç‹¬ä»»åŠ¡è®¾è®¡çš„æ¨¡å‹ç›¸æ¯”ï¼Œæ­¤æ–¹æ³•æ˜¾è‘—ç®€åŒ–äº†è™šæ‹ŸåŠ©ç†çš„è¾“å…¥å¤„ç†æµç¨‹å¹¶æé«˜äº†æ€§èƒ½ã€‚SELMAåœ¨è¯­éŸ³è§¦å‘æ£€æµ‹ä»»åŠ¡ä¸Šçš„ç­‰ä»·è¯¯å·®ç‡ç›¸å¯¹æé«˜äº†64%ï¼Œåœ¨è®¾å¤‡å®šå‘è¯­éŸ³è¯†åˆ«ä»»åŠ¡ä¸Šæé«˜äº†22%ï¼ŒåŒæ—¶å­—è¯é”™è¯¯ç‡æ¥è¿‘åŸºçº¿æ°´å¹³ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>SELMAæ˜¯ä¸€ä¸ªç”¨äºè™šæ‹ŸåŠ©ç†äº¤äº’çš„è¯­éŸ³é©±åŠ¨è¯­è¨€æ¨¡å‹ï¼Œæ•´åˆéŸ³é¢‘å’Œæ–‡æœ¬ä½œä¸ºè¾“å…¥ã€‚</li>
<li>SELMAè®¾è®¡ç”¨äºåŒæ—¶å¤„ç†ä¸‰é¡¹ä¸»è¦ä»»åŠ¡å’Œä¸¤é¡¹è¾…åŠ©ä»»åŠ¡ã€‚</li>
<li>é‡‡ç”¨ä½ç§©è‡ªé€‚åº”æ¨¡å—å®ç°å‚æ•°é«˜æ•ˆè®­ç»ƒï¼ŒåŒ…æ‹¬éŸ³é¢‘ç¼–ç å™¨å’ŒLLMã€‚</li>
<li>ç‰¹å¾æ± ç­–ç•¥ç”¨äºè¯†åˆ«å…¨å±€æ¨¡å¼ï¼Œæé«˜åœ¨ä¾èµ–å•ä¸ªåºåˆ—å…ƒç´ è¾ƒå°‘çš„ä»»åŠ¡ä¸Šçš„å‡†ç¡®æ€§ã€‚</li>
<li>å®éªŒç»“æœæ˜¾ç¤ºï¼ŒSELMAåœ¨è¯­éŸ³è§¦å‘æ£€æµ‹ã€è®¾å¤‡å®šå‘è¯­éŸ³è¯†åˆ«å’Œè‡ªåŠ¨è¯­éŸ³è¯†åˆ«ä»»åŠ¡ä¸Šè¡¨ç°å‡ºä¼˜è¶Šæ€§èƒ½ã€‚</li>
<li>ä¸ä¼ ç»Ÿä¸ºæ¯ä¸ªä»»åŠ¡å•ç‹¬è®¾è®¡çš„æ¨¡å‹ç›¸æ¯”ï¼ŒSELMAç®€åŒ–äº†è™šæ‹ŸåŠ©ç†çš„è¾“å…¥å¤„ç†æµç¨‹ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.19377">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-196e96ad81d0532652e3493cf0628bc8.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-0db57738db4b74506d952e632b10ea7d.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-fa31cdf212845cb639ed901b1b96b390.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-cd9a5f5ac7e58c0b88df01738e094dab.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="VisualSpeech-Enhance-Prosody-with-Visual-Context-in-TTS"><a href="#VisualSpeech-Enhance-Prosody-with-Visual-Context-in-TTS" class="headerlink" title="VisualSpeech: Enhance Prosody with Visual Context in TTS"></a>VisualSpeech: Enhance Prosody with Visual Context in TTS</h2><p><strong>Authors:Shumin Que, Anton Ragni</strong></p>
<p>Text-to-Speech (TTS) synthesis faces the inherent challenge of producing multiple speech outputs with varying prosody from a single text input. While previous research has addressed this by predicting prosodic information from both text and speech, additional contextual information, such as visual features, remains underutilized. This paper investigates the potential of integrating visual context to enhance prosody prediction. We propose a novel model, VisualSpeech, which incorporates both visual and textual information for improved prosody generation. Empirical results demonstrate that visual features provide valuable prosodic cues beyond the textual input, significantly enhancing the naturalness and accuracy of the synthesized speech. Audio samples are available at <a target="_blank" rel="noopener" href="https://ariameetgit.github.io/VISUALSPEECH-SAMPLES/">https://ariameetgit.github.io/VISUALSPEECH-SAMPLES/</a>. </p>
<blockquote>
<p>æ–‡æœ¬è½¬è¯­éŸ³ï¼ˆTTSï¼‰åˆæˆé¢ä¸´ç€ä¸€ä¸ªå›ºæœ‰æŒ‘æˆ˜ï¼Œå³å¦‚ä½•ä»å•ä¸ªæ–‡æœ¬è¾“å…¥ç”Ÿæˆå…·æœ‰ä¸åŒéŸµå¾‹çš„å¤šä¸ªè¯­éŸ³è¾“å‡ºã€‚è™½ç„¶ä¹‹å‰çš„ç ”ç©¶å·²ç»é€šè¿‡ä»æ–‡æœ¬å’Œè¯­éŸ³é¢„æµ‹éŸµå¾‹ä¿¡æ¯æ¥è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œä½†é¢å¤–çš„ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œå¦‚è§†è§‰ç‰¹å¾ï¼Œä»ç„¶è¢«ä½ä¼°å’Œå¿½ç•¥ã€‚æœ¬æ–‡æ¢è®¨äº†æ•´åˆè§†è§‰ä¸Šä¸‹æ–‡ä»¥å¢å¼ºéŸµå¾‹é¢„æµ‹çš„å¯èƒ½æ€§ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°å‹æ¨¡å‹VisualSpeechï¼Œè¯¥æ¨¡å‹ç»“åˆäº†è§†è§‰å’Œæ–‡æœ¬ä¿¡æ¯ï¼Œä»¥æ”¹è¿›éŸµå¾‹ç”Ÿæˆã€‚ç»éªŒç»“æœè¡¨æ˜ï¼Œè§†è§‰ç‰¹å¾æä¾›äº†è¶…è¶Šæ–‡æœ¬è¾“å…¥çš„å®è´µéŸµå¾‹çº¿ç´¢ï¼Œæ˜¾è‘—å¢å¼ºäº†åˆæˆè¯­éŸ³çš„è‡ªç„¶åº¦å’Œå‡†ç¡®æ€§ã€‚éŸ³é¢‘æ ·æœ¬å¯åœ¨<a target="_blank" rel="noopener" href="https://ariameetgit.github.io/VISUALSPEECH-SAMPLES%E6%9%E6%9F%A5%E6%89%BE%E3%80%82">https://ariameetgit.github.io/VISUALSPEECH-SAMPLES/æ‰¾åˆ°ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.19258v1">PDF</a> </p>
<p><strong>æ€»ç»“</strong></p>
<p>æœ¬æ–‡ç ”ç©¶äº†å°†è§†è§‰ä¸Šä¸‹æ–‡èå…¥è¯­éŸ³åˆæˆä¸­çš„æ½œåŠ›ï¼Œä»¥å¢å¼ºè¯­è°ƒé¢„æµ‹ã€‚æå‡ºäº†ä¸€ç§æ–°çš„æ¨¡å‹VisualSpeechï¼Œè¯¥æ¨¡å‹ç»“åˆäº†è§†è§‰å’Œæ–‡æœ¬ä¿¡æ¯ï¼Œä»¥æ”¹è¿›è¯­è°ƒç”Ÿæˆã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè§†è§‰ç‰¹å¾æä¾›äº†æ–‡æœ¬è¾“å…¥ä¹‹å¤–çš„å®è´µè¯­è°ƒçº¿ç´¢ï¼Œæ˜¾è‘—å¢å¼ºäº†åˆæˆè¯­éŸ³çš„è‡ªç„¶åº¦å’Œå‡†ç¡®æ€§ã€‚</p>
<p><strong>å…³é”®è§è§£</strong></p>
<ol>
<li>æ–‡æœ¬è½¬è¯­éŸ³ï¼ˆTTSï¼‰åˆæˆé¢ä¸´ä»å•ä¸€æ–‡æœ¬è¾“å…¥äº§ç”Ÿå¤šç§è¯­éŸ³è¾“å‡ºçš„å›ºæœ‰æŒ‘æˆ˜ã€‚</li>
<li>å°½ç®¡å…ˆå‰çš„ç ”ç©¶é€šè¿‡é¢„æµ‹æ–‡æœ¬å’Œè¯­éŸ³çš„è¯­è°ƒä¿¡æ¯æ¥è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œä½†è§†è§‰ç‰¹å¾ç­‰é¢å¤–ä¸Šä¸‹æ–‡ä¿¡æ¯ä»æœªå¾—åˆ°å……åˆ†åˆ©ç”¨ã€‚</li>
<li>æœ¬æ–‡æ¢ç´¢äº†æ•´åˆè§†è§‰ä¸Šä¸‹æ–‡ä»¥å¢å¼ºè¯­è°ƒé¢„æµ‹çš„å¯èƒ½æ€§ã€‚</li>
<li>æå‡ºäº†ä¸€ä¸ªæ–°çš„æ¨¡å‹VisualSpeechï¼Œè¯¥æ¨¡å‹ç»“åˆäº†è§†è§‰å’Œæ–‡æœ¬ä¿¡æ¯ï¼Œä»¥æ”¹è¿›è¯­è°ƒç”Ÿæˆã€‚</li>
<li>å®è¯ç»“æœè¡¨æ˜ï¼Œè§†è§‰ç‰¹å¾åœ¨æä¾›è¯­è°ƒçº¿ç´¢æ–¹é¢å…·æœ‰é‡è¦ä»·å€¼ï¼Œè¶…è¶Šäº†æ–‡æœ¬è¾“å…¥ã€‚</li>
<li>VisualSpeechæ¨¡å‹èƒ½æ˜¾è‘—å¢å¼ºåˆæˆè¯­éŸ³çš„è‡ªç„¶åº¦å’Œå‡†ç¡®æ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.19258">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-0888f2df01bc18733ce5757dd39538df.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-5ae00a9f374f7f4f37e9c1a314c6196f.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-f87fa7e9e6eff76e3521125eedfccb16.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-9b0b41a015816f98a2beabba7447e4f8.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-1b8a2afa9dcbb93ecfdc3af58bded0a6.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="DyPCL-Dynamic-Phoneme-level-Contrastive-Learning-for-Dysarthric-Speech-Recognition"><a href="#DyPCL-Dynamic-Phoneme-level-Contrastive-Learning-for-Dysarthric-Speech-Recognition" class="headerlink" title="DyPCL: Dynamic Phoneme-level Contrastive Learning for Dysarthric Speech   Recognition"></a>DyPCL: Dynamic Phoneme-level Contrastive Learning for Dysarthric Speech   Recognition</h2><p><strong>Authors:Wonjun Lee, Solee Im, Heejin Do, Yunsu Kim, Jungseul Ok, Gary Geunbae Lee</strong></p>
<p>Dysarthric speech recognition often suffers from performance degradation due to the intrinsic diversity of dysarthric severity and extrinsic disparity from normal speech. To bridge these gaps, we propose a Dynamic Phoneme-level Contrastive Learning (DyPCL) method, which leads to obtaining invariant representations across diverse speakers. We decompose the speech utterance into phoneme segments for phoneme-level contrastive learning, leveraging dynamic connectionist temporal classification alignment. Unlike prior studies focusing on utterance-level embeddings, our granular learning allows discrimination of subtle parts of speech. In addition, we introduce dynamic curriculum learning, which progressively transitions from easy negative samples to difficult-to-distinguishable negative samples based on phonetic similarity of phoneme. Our approach to training by difficulty levels alleviates the inherent variability of speakers, better identifying challenging speeches. Evaluated on the UASpeech dataset, DyPCL outperforms baseline models, achieving an average 22.10% relative reduction in word error rate (WER) across the overall dysarthria group. </p>
<blockquote>
<p>æ„éŸ³éšœç¢è¯­éŸ³è¯†åˆ«å¸¸å¸¸å› ä¸ºæ„éŸ³éšœç¢çš„å›ºæœ‰å¤šæ ·æ€§å’Œä¸æ­£å¸¸è¯­éŸ³çš„å¤–åœ¨å·®å¼‚è€Œæ€§èƒ½ä¸‹é™ã€‚ä¸ºäº†å¼¥è¡¥è¿™äº›å·®è·ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åŠ¨æ€éŸ³ç´ çº§å¯¹æ¯”å­¦ä¹ ï¼ˆDyPCLï¼‰æ–¹æ³•ï¼Œè¯¥æ–¹æ³•å¯ä»¥è·å¾—ä¸åŒè¯´è¯è€…çš„ä¸å˜è¡¨ç¤ºã€‚æˆ‘ä»¬å°†è¯­éŸ³å‘éŸ³åˆ†è§£æˆéŸ³ç´ ç‰‡æ®µè¿›è¡ŒéŸ³ç´ çº§å¯¹æ¯”å­¦ä¹ ï¼Œåˆ©ç”¨åŠ¨æ€è¿æ¥æ—¶æ€åˆ†ç±»å¯¹é½ã€‚ä¸ä»¥å¾€ç ”ç©¶ä¸“æ³¨äºå¥å­çº§åµŒå…¥ä¸åŒï¼Œæˆ‘ä»¬çš„ç²’åº¦å­¦ä¹ å¯ä»¥åŒºåˆ†è¯­éŸ³çš„ç»†å¾®éƒ¨åˆ†ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å¼•å…¥äº†åŠ¨æ€è¯¾ç¨‹å­¦ä¹ ï¼Œå®ƒæ ¹æ®éŸ³ç´ çš„è¯­éŸ³ç›¸ä¼¼æ€§ï¼Œä»å®¹æ˜“åŒºåˆ†çš„è´Ÿæ ·æœ¬é€æ¸è¿‡æ¸¡åˆ°éš¾ä»¥åŒºåˆ†çš„è´Ÿæ ·æœ¬ã€‚æˆ‘ä»¬æŒ‰éš¾åº¦çº§åˆ«è¿›è¡ŒåŸ¹è®­çš„æ–¹æ³•å‡è½»äº†è¯´è¯è€…çš„å†…åœ¨å˜åŒ–ï¼Œæ›´å¥½åœ°è¯†åˆ«äº†å…·æœ‰æŒ‘æˆ˜æ€§çš„è¯­éŸ³ã€‚åœ¨UASpeechæ•°æ®é›†ä¸Šè¯„ä¼°ï¼ŒDyPCLä¼˜äºåŸºçº¿æ¨¡å‹ï¼Œåœ¨æ•´ä¸ªæ„éŸ³éšœç¢ç»„ä¸­å¹³å‡é™ä½äº†22.10%çš„å­—é”™è¯¯ç‡ï¼ˆWERï¼‰ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.19010v2">PDF</a> NAACL 2025 main conference, 9pages, 1 page appendix</p>
<p><strong>æ€»ç»“</strong></p>
<p>æœ¬æ–‡æå‡ºä¸€ç§åŠ¨æ€éŸ³ç´ çº§å¯¹æ¯”å­¦ä¹ ï¼ˆDyPCLï¼‰æ–¹æ³•ï¼Œç”¨äºæ”¹å–„å‘éŸ³éšœç¢è¯­éŸ³è¯†åˆ«æ€§èƒ½ã€‚é’ˆå¯¹å‘éŸ³éšœç¢å¤šæ ·æ€§å’Œä¸æ­£å¸¸è¯­éŸ³çš„å·®å¼‚æ€§ï¼ŒDyPCLé€šè¿‡éŸ³ç´ çº§å¯¹æ¯”å­¦ä¹ è·å¾—è·¨ä¸åŒè¯´è¯è€…çš„ä¸å˜è¡¨ç¤ºã€‚è¯¥æ–¹æ³•é‡‡ç”¨åŠ¨æ€è¿æ¥æ—¶é—´åˆ†ç±»å¯¹é½æŠ€æœ¯ï¼Œå°†è¯­éŸ³ç‰‡æ®µåˆ†è§£ä¸ºéŸ³ç´ ç‰‡æ®µè¿›è¡Œå­¦ä¹ ã€‚ä¸ä¼ ç»Ÿçš„åŸºäºå¥å­çº§åˆ«çš„åµŒå…¥æ–¹æ³•ä¸åŒï¼ŒDyPCLçš„ç²¾ç»†å­¦ä¹ èƒ½å¤ŸåŒºåˆ†è¯­éŸ³çš„ç»†å¾®éƒ¨åˆ†ã€‚æ­¤å¤–ï¼Œè¿˜å¼•å…¥äº†åŠ¨æ€è¯¾ç¨‹å­¦ä¹ ï¼Œæ ¹æ®éŸ³ç´ çš„è¯­éŸ³ç›¸ä¼¼æ€§ï¼Œä»æ˜“äºåŒºåˆ†çš„è´Ÿæ ·æœ¬é€æ¸è¿‡æ¸¡åˆ°éš¾ä»¥åŒºåˆ†çš„è´Ÿæ ·æœ¬ã€‚è¯¥æ–¹æ³•é€šè¿‡æŒ‰éš¾åº¦çº§åˆ«è¿›è¡ŒåŸ¹è®­ï¼Œå‡è½»äº†è¯´è¯äººçš„å†…åœ¨å˜åŒ–ï¼Œæ›´å¥½åœ°è¯†åˆ«äº†å…·æœ‰æŒ‘æˆ˜æ€§çš„è¯­éŸ³ã€‚åœ¨UASpeechæ•°æ®é›†ä¸Šçš„è¯„ä¼°ç»“æœè¡¨æ˜ï¼ŒDyPCLç›¸è¾ƒäºåŸºçº¿æ¨¡å‹è¡¨ç°å‡ºè‰²ï¼Œæ•´ä½“å‘éŸ³éšœç¢ç»„çš„å¹³å‡è¯é”™è¯¯ç‡ï¼ˆWERï¼‰é™ä½äº†22.10%ã€‚</p>
<p><strong>å…³é”®è§è§£</strong></p>
<ol>
<li>DyPCLæ–¹æ³•æ—¨åœ¨è§£å†³å‘éŸ³éšœç¢è¯­éŸ³è¯†åˆ«çš„æ€§èƒ½ä¸‹é™é—®é¢˜ï¼Œé¢å¯¹å‘éŸ³éšœç¢çš„å¤šæ ·æ€§å’Œä¸æ­£å¸¸è¯­éŸ³çš„å·®å¼‚ã€‚</li>
<li>é€šè¿‡éŸ³ç´ çº§å¯¹æ¯”å­¦ä¹ è·å¾—è·¨ä¸åŒè¯´è¯è€…çš„ä¸å˜è¡¨ç¤ºã€‚</li>
<li>é‡‡ç”¨åŠ¨æ€è¿æ¥æ—¶é—´åˆ†ç±»å¯¹é½æŠ€æœ¯åˆ†è§£è¯­éŸ³ç‰‡æ®µè¿›è¡Œæ›´ç²¾ç»†çš„å­¦ä¹ ã€‚</li>
<li>å¼•å…¥åŠ¨æ€è¯¾ç¨‹å­¦ä¹ ï¼ŒæŒ‰è¯­éŸ³ç›¸ä¼¼æ€§é€æ¸è¿‡æ¸¡å­¦ä¹ éš¾åº¦ã€‚</li>
<li>æŒ‰éš¾åº¦çº§åˆ«åŸ¹è®­çš„æ–¹æ³•å‡è½»äº†è¯´è¯äººçš„å†…åœ¨å˜åŒ–ï¼Œæ›´å¥½åœ°è¯†åˆ«å…·æœ‰æŒ‘æˆ˜æ€§çš„è¯­éŸ³ã€‚</li>
<li>åœ¨UASpeechæ•°æ®é›†ä¸Šçš„è¯„ä¼°æ˜¾ç¤ºï¼ŒDyPCLç›¸è¾ƒäºåŸºçº¿æ¨¡å‹æ˜¾è‘—é™ä½äº†è¯é”™è¯¯ç‡ï¼ˆWERï¼‰ã€‚</li>
<li>DyPCLæ–¹æ³•å®ç°äº†å¹³å‡22.10%çš„ç›¸å¯¹å‡å°‘è¯é”™è¯¯ç‡ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.19010">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-b3bba646d4843209eaf58de3d61e4001.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-5f9219882919c39fe5bbb9aa0373bb23.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-3cbb6babce0998bebad625e9b29115da.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e2445f2bfebc11200cd36af1ca203f3c.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-f88283304830805ff996dd7df017fc82.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-7cfbf0a1a3a9d6d338f2ec314a55f6bd.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="Image-Text-and-Speech-Data-Augmentation-using-Multimodal-LLMs-for-Deep-Learning-A-Survey"><a href="#Image-Text-and-Speech-Data-Augmentation-using-Multimodal-LLMs-for-Deep-Learning-A-Survey" class="headerlink" title="Image, Text, and Speech Data Augmentation using Multimodal LLMs for Deep   Learning: A Survey"></a>Image, Text, and Speech Data Augmentation using Multimodal LLMs for Deep   Learning: A Survey</h2><p><strong>Authors:Ranjan Sapkota, Shaina Raza, Maged Shoman, Achyut Paudel, Manoj Karkee</strong></p>
<p>In the past five years, research has shifted from traditional Machine Learning (ML) and Deep Learning (DL) approaches to leveraging Large Language Models (LLMs) , including multimodality, for data augmentation to enhance generalization, and combat overfitting in training deep convolutional neural networks. However, while existing surveys predominantly focus on ML and DL techniques or limited modalities (text or images), a gap remains in addressing the latest advancements and multi-modal applications of LLM-based methods. This survey fills that gap by exploring recent literature utilizing multimodal LLMs to augment image, text, and audio data, offering a comprehensive understanding of these processes. We outlined various methods employed in the LLM-based image, text and speech augmentation, and discussed the limitations identified in current approaches. Additionally, we identified potential solutions to these limitations from the literature to enhance the efficacy of data augmentation practices using multimodal LLMs. This survey serves as a foundation for future research, aiming to refine and expand the use of multimodal LLMs in enhancing dataset quality and diversity for deep learning applications. (Surveyed Paper GitHub Repo: <a target="_blank" rel="noopener" href="https://github.com/WSUAgRobotics/data-aug-multi-modal-llm">https://github.com/WSUAgRobotics/data-aug-multi-modal-llm</a>. Keywords: LLM data augmentation, LLM text data augmentation, LLM image data augmentation, LLM speech data augmentation, audio augmentation, voice augmentation, chatGPT for data augmentation, DeepSeek R1 text data augmentation, DeepSeek R1 image augmentation, Image Augmentation using LLM, Text Augmentation using LLM, LLM data augmentation for deep learning applications) </p>
<blockquote>
<p>è¿‡å»äº”å¹´ï¼Œç ”ç©¶å·²ä»ä¼ ç»Ÿçš„æœºå™¨å­¦ä¹ å’Œæ·±åº¦å­¦ä¹ æ–¹æ³•è½¬å‘åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ï¼ŒåŒ…æ‹¬å¤šæ¨¡æ€ï¼Œè¿›è¡Œæ•°æ®å¢å¼ºä»¥æé«˜æ³›åŒ–èƒ½åŠ›ï¼Œå¹¶åº”å¯¹è®­ç»ƒæ·±åº¦å·ç§¯ç¥ç»ç½‘ç»œæ—¶çš„è¿‡æ‹Ÿåˆé—®é¢˜ã€‚ç„¶è€Œï¼Œå°½ç®¡ç°æœ‰çš„è°ƒæŸ¥ä¸»è¦é›†ä¸­åœ¨MLå’ŒDLæŠ€æœ¯æˆ–æœ‰é™æ¨¡å¼ï¼ˆæ–‡æœ¬æˆ–å›¾åƒï¼‰ä¸Šï¼Œä½†åœ¨è§£å†³åŸºäºLLMçš„æ–¹æ³•çš„æœ€æ–°è¿›å±•å’Œå¤šæ¨¡æ€åº”ç”¨æ–¹é¢ä»å­˜åœ¨å·®è·ã€‚æœ¬è°ƒæŸ¥é€šè¿‡æ¢ç´¢åˆ©ç”¨å¤šæ¨¡æ€LLMå¢å¼ºå›¾åƒã€æ–‡æœ¬å’ŒéŸ³é¢‘æ•°æ®çš„æœ€æ–°æ–‡çŒ®æ¥å¡«è¡¥è¿™ä¸€ç©ºç™½ï¼Œä¸ºè¿™äº›è¿‡ç¨‹æä¾›å…¨é¢çš„ç†è§£ã€‚æˆ‘ä»¬æ¦‚è¿°äº†åŸºäºLLMçš„å›¾åƒã€æ–‡æœ¬å’Œè¯­éŸ³å¢å¼ºæ‰€é‡‡ç”¨çš„å„ç§æ–¹æ³•ï¼Œå¹¶è®¨è®ºäº†å½“å‰æ–¹æ³•ä¸­æ‰€è¯†åˆ«çš„å±€é™æ€§ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬ä»æ–‡çŒ®ä¸­ç¡®å®šäº†è§£å†³è¿™äº›å±€é™æ€§çš„æ½œåœ¨è§£å†³æ–¹æ¡ˆï¼Œä»¥æé«˜ä½¿ç”¨å¤šæ¨¡æ€LLMçš„æ•°æ®å¢å¼ºå®è·µçš„æœ‰æ•ˆæ€§ã€‚æœ¬è°ƒæŸ¥ä¸ºæœªæ¥ç ”ç©¶å¥ å®šäº†åŸºç¡€ï¼Œæ—¨åœ¨å®Œå–„å’Œå‘å±•å¤šæ¨¡æ€LLMåœ¨æ·±åº¦å­¦ä¹ åº”ç”¨ä¸­çš„ä½¿ç”¨å’Œå¢å¼ºæ•°æ®é›†è´¨é‡å’Œå¤šæ ·æ€§çš„æ–¹æ³•ã€‚ï¼ˆæ‰€è°ƒæŸ¥è®ºæ–‡GitHubä»“åº“ï¼š<a target="_blank" rel="noopener" href="https://github.com/WSUAgRobotics/data-aug-multi-modal-llm%E3%80%82%E5%85%B3%E9%94%AE%E8%AF%8D%EF%BC%9ALLM%E6%95%B0%E6%8D%AE%E5%A2%9E%E5%BC%BA%E3%80%81LLM%E6%96%87%E6%9C%AC%E6%95%B0%E6%8D%AE%E5%A2%9E%E5%BC%BA%E3%80%81LLM%E5%9B%BE%E5%83%8F%E6%95%B0%E6%8D%AE%E5%A2%9E%E5%BC%BA%E3%80%81LLM%E8%AF%AD%E9%9F%B3%E6%95%B0%E6%8D%AE%E5%A2%9E%E5%BC%BA%E3%80%81%E9%9F%B3%E9%A2%91%E5%A2%9E%E5%BC%BA%E3%80%81%E8%AF%AD%E9%9F%B3%E5%A2%9E%E5%BC%BA%E3%80%81ChatGPT%E7%94%A8%E4%BA%8E%E6%95%B0%E6%8D%AE%E5%A2%9E%E5%BC%BA%E3%80%81DeepSeek">https://github.com/WSUAgRobotics/data-aug-multi-modal-llmã€‚å…³é”®è¯ï¼šLLMæ•°æ®å¢å¼ºã€LLMæ–‡æœ¬æ•°æ®å¢å¼ºã€LLMå›¾åƒæ•°æ®å¢å¼ºã€LLMè¯­éŸ³æ•°æ®å¢å¼ºã€éŸ³é¢‘å¢å¼ºã€è¯­éŸ³å¢å¼ºã€ChatGPTç”¨äºæ•°æ®å¢å¼ºã€DeepSeek</a> R1æ–‡æœ¬æ•°æ®å¢å¼ºã€DeepSeek R1å›¾åƒå¢å¼ºã€ä½¿ç”¨LLMçš„å›¾åƒå¢å¼ºã€ä½¿ç”¨LLMçš„æ–‡æœ¬å¢å¼ºã€LLMæ•°æ®å¢å¼ºåœ¨æ·±åº¦å­¦ä¹ åº”ç”¨ï¼‰</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.18648v1">PDF</a> </p>
<p><strong>æ‘˜è¦</strong></p>
<p>è¿™ç¯‡è°ƒç ”è®ºæ–‡å¡«è¡¥äº†å…³äºå¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ•°æ®å¢å¼ºçš„ç ”ç©¶ç©ºç™½ã€‚æ–‡ç« æ·±å…¥æ¢è®¨äº†ä½¿ç”¨å¤šæ¨¡æ€LLMå¢å¼ºå›¾åƒã€æ–‡æœ¬å’ŒéŸ³é¢‘æ•°æ®çš„æœ€æ–°æ–‡çŒ®ï¼Œå¹¶æ¦‚è¿°äº†LLMåœ¨å›¾åƒã€æ–‡æœ¬å’Œè¯­éŸ³å¢å¼ºä¸­çš„åº”ç”¨æ–¹æ³•ã€‚æ­¤å¤–ï¼Œè®ºæ–‡è®¨è®ºäº†å½“å‰æ–¹æ³•çš„å±€é™æ€§ï¼Œå¹¶ä»æ–‡çŒ®ä¸­æå‡ºäº†é’ˆå¯¹è¿™äº›å±€é™æ€§çš„æ½œåœ¨è§£å†³æ–¹æ¡ˆï¼Œä»¥æé«˜ä½¿ç”¨å¤šæ¨¡æ€LLMçš„æ•°æ®å¢å¼ºå®è·µæ•ˆæœã€‚æ­¤è°ƒç ”ä¸ºæœªæ¥çš„ç ”ç©¶å¥ å®šäº†åŸºç¡€ï¼Œæ—¨åœ¨å®Œå–„å¹¶æ‰©å±•å¤šæ¨¡æ€LLMåœ¨æ·±åº¦å­¦ä¹ åº”ç”¨ä¸­çš„ä½¿ç”¨ï¼Œä»¥æé«˜æ•°æ®é›†çš„è´¨é‡å’Œå¤šæ ·æ€§ã€‚</p>
<p><strong>å…³é”®è§è§£</strong></p>
<ol>
<li>è°ƒç ”è®ºæ–‡æ¦‚è¿°äº†å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨æ•°æ®å¢å¼ºæ–¹é¢çš„æœ€æ–°è¿›å±•ã€‚</li>
<li>æ–‡ç« è¯¦ç»†æ¢è®¨äº†LLMåœ¨å›¾åƒã€æ–‡æœ¬å’Œè¯­éŸ³å¢å¼ºä¸­çš„åº”ç”¨æ–¹æ³•ã€‚</li>
<li>è®ºæ–‡æŒ‡å‡ºäº†ç°æœ‰LLMæ•°æ®å¢å¼ºæ–¹æ³•çš„å±€é™æ€§ã€‚</li>
<li>ä»æ–‡çŒ®ä¸­æå‡ºäº†é’ˆå¯¹è¿™äº›å±€é™æ€§çš„æ½œåœ¨è§£å†³æ–¹æ¡ˆï¼Œä»¥æé«˜æ•°æ®å¢å¼ºå®è·µçš„æ•ˆæœã€‚</li>
<li>è°ƒç ”å¼ºè°ƒäº†å¤šæ¨¡æ€LLMåœ¨æé«˜æ•°æ®é›†è´¨é‡å’Œå¤šæ ·æ€§æ–¹é¢çš„ä½œç”¨ã€‚</li>
<li>æ–‡ç« æåˆ°çš„å…³é”®è¯åŒ…æ‹¬LLMæ•°æ®å¢å¼ºã€éŸ³é¢‘å¢å¼ºã€è¯­éŸ³å¢å¼ºä»¥åŠç‰¹å®šå·¥å…·å¦‚ChatGPTç”¨äºæ•°æ®å¢å¼ºç­‰ã€‚</li>
<li>æ­¤è°ƒç ”ä¸ºæœªæ¥çš„ç ”ç©¶æä¾›äº†åŸºç¡€ï¼Œæ—¨åœ¨æ‰©å±•å’Œå®Œå–„å¤šæ¨¡æ€LLMåœ¨æ·±åº¦å­¦ä¹ é¢†åŸŸçš„åº”ç”¨ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.18648">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-cf7688673a137114d94fa9ad19f96200.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-10f6c3e5f7df1eb8112a3060693596f7.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-bb37708e4ce94b0baf260c789a28432d.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="Efficient-Event-based-Delay-Learning-in-Spiking-Neural-Networks"><a href="#Efficient-Event-based-Delay-Learning-in-Spiking-Neural-Networks" class="headerlink" title="Efficient Event-based Delay Learning in Spiking Neural Networks"></a>Efficient Event-based Delay Learning in Spiking Neural Networks</h2><p><strong>Authors:BalÃ¡zs MÃ©szÃ¡ros, James C. Knight, Thomas Nowotny</strong></p>
<p>Spiking Neural Networks (SNNs) are attracting increased attention as a more energy-efficient alternative to traditional Artificial Neural Networks. Spiking neurons are stateful and intrinsically recurrent, making them well-suited for spatio-temporal tasks. However, this intrinsic memory is limited by synaptic and membrane time constants. A powerful additional mechanism are delays. In this paper, we propose a novel event-based training method for SNNs with delays, grounded in the EventProp formalism and enabling the calculation of exact gradients with respect to weights and delays. Our method supports multiple spikes per neuron and, to our best knowledge, is the first delay learning algorithm to be applied to recurrent SNNs. We evaluate our method on a simple sequence detection task, and the Yin-Yang, Spiking Heidelberg Digits and Spiking Speech Commands datasets, demonstrating that our algorithm can optimize delays from suboptimal initial conditions and enhance classification accuracy compared to architectures without delays. Finally, we show that our approach uses less than half the memory of the current state-of-the-art delay-learning method and is up to 26x faster. </p>
<blockquote>
<p>è„‰å†²ç¥ç»ç½‘ç»œï¼ˆSpiking Neural Networksï¼Œç®€ç§°SNNsï¼‰ä½œä¸ºä¸€ç§æ¯”ä¼ ç»Ÿäººå·¥ç¥ç»ç½‘ç»œæ›´èŠ‚èƒ½çš„æ›¿ä»£æ–¹æ¡ˆï¼Œæ­£è¶Šæ¥è¶Šå—åˆ°å…³æ³¨ã€‚è„‰å†²ç¥ç»å…ƒå…·æœ‰çŠ¶æ€å’Œå†…åœ¨å¤å‘çš„ç‰¹æ€§ï¼Œä½¿å…¶éå¸¸é€‚åˆæ—¶ç©ºä»»åŠ¡ã€‚ç„¶è€Œï¼Œè¿™ç§å†…åœ¨çš„è®°å¿†å—åˆ°çªè§¦å’Œè†œæ—¶é—´å¸¸æ•°çš„é™åˆ¶ã€‚ä¸€ç§å¼ºå¤§çš„é™„åŠ æœºåˆ¶æ˜¯å»¶è¿Ÿã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åŸºäºäº‹ä»¶çš„æ–°å‹è„‰å†²ç¥ç»ç½‘ç»œè®­ç»ƒæ–¹æ³•ï¼Œè¯¥æ–¹æ³•ä»¥EventPropå½¢å¼ä¸ºåŸºç¡€ï¼Œèƒ½å¤Ÿè®¡ç®—å…³äºæƒé‡å’Œå»¶è¿Ÿçš„ç²¾ç¡®æ¢¯åº¦ã€‚æˆ‘ä»¬çš„æ–¹æ³•æ”¯æŒæ¯ä¸ªç¥ç»å…ƒçš„å¤šä¸ªè„‰å†²ï¼Œå¹¶ä¸”æ®æˆ‘ä»¬æ‰€çŸ¥ï¼Œæ˜¯ç¬¬ä¸€ä¸ªåº”ç”¨äºå¤å‘è„‰å†²ç¥ç»ç½‘ç»œçš„å»¶è¿Ÿå­¦ä¹ ç®—æ³•ã€‚æˆ‘ä»¬åœ¨ç®€å•çš„åºåˆ—æ£€æµ‹ä»»åŠ¡ä»¥åŠé˜´é˜³ã€è„‰å†²æµ·å¾·å ¡æ•°å­—å’Œè„‰å†²è¯­éŸ³å‘½ä»¤æ•°æ®é›†ä¸Šè¯„ä¼°äº†æˆ‘ä»¬çš„æ–¹æ³•ï¼Œè¯æ˜æˆ‘ä»¬çš„ç®—æ³•å¯ä»¥ä»ä¸ä½³çš„åˆå§‹æ¡ä»¶ä¼˜åŒ–å»¶è¿Ÿå¹¶æé«˜åˆ†ç±»å‡†ç¡®ç‡ï¼Œä¸æ²¡æœ‰å»¶è¿Ÿçš„æ¶æ„ç›¸æ¯”å…·æœ‰ä¼˜åŠ¿ã€‚æœ€åï¼Œæˆ‘ä»¬è¯æ˜æˆ‘ä»¬çš„æ–¹æ³•ä½¿ç”¨çš„å†…å­˜ä¸åˆ°å½“å‰æœ€å…ˆè¿›çš„å»¶è¿Ÿå­¦ä¹ æ–¹æ³•çš„ä¸€åŠï¼Œå¹¶ä¸”é€Ÿåº¦æœ€å¿«å¯æé«˜26å€ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.07331v2">PDF</a> </p>
<p><strong>Summary</strong><br>     è„‰å†²ç¥ç»ç½‘ç»œï¼ˆSNNsï¼‰ä½œä¸ºæ›´èŠ‚èƒ½çš„ä¼ ç»Ÿäººå·¥ç¥ç»ç½‘ç»œæ›¿ä»£å“è€Œå¤‡å—å…³æ³¨ã€‚è„‰å†²ç¥ç»å…ƒå…·æœ‰çŠ¶æ€å’Œå†…åœ¨å¤å‘æ€§ï¼Œä½¿å…¶é€‚åˆæ—¶ç©ºä»»åŠ¡ã€‚ç„¶è€Œï¼Œè¿™ç§å†…åœ¨è®°å¿†å—åˆ°çªè§¦å’Œè†œæ—¶é—´å¸¸æ•°çš„é™åˆ¶ã€‚å»¶è¿Ÿæ˜¯ä¸€ç§å¼ºå¤§çš„é™„åŠ æœºåˆ¶ã€‚æœ¬æ–‡æå‡ºä¸€ç§åŸºäºEventPropå½¢å¼ä¸»ä¹‰çš„å¸¦æœ‰å»¶è¿Ÿçš„SNNsçš„æ–°å‹äº‹ä»¶é©±åŠ¨è®­ç»ƒæ–¹æ³•ï¼Œèƒ½å¤Ÿè®¡ç®—å…³äºæƒé‡å’Œå»¶è¿Ÿçš„ç¡®åˆ‡æ¢¯åº¦ã€‚æˆ‘ä»¬çš„æ–¹æ³•æ”¯æŒæ¯ä¸ªç¥ç»å…ƒçš„å¤šä¸ªè„‰å†²ï¼Œæ®æˆ‘ä»¬æ‰€çŸ¥ï¼Œæ˜¯é¦–ä¸ªåº”ç”¨äºé€’å½’SNNsçš„å»¶è¿Ÿå­¦ä¹ ç®—æ³•ã€‚æˆ‘ä»¬åœ¨ç®€å•çš„åºåˆ—æ£€æµ‹ä»»åŠ¡ä»¥åŠé˜´é˜³ã€è„‰å†²æµ·å¾·å ¡æ•°å­—å’Œè„‰å†²è¯­éŸ³å‘½ä»¤æ•°æ®é›†ä¸Šè¯„ä¼°äº†æˆ‘ä»¬çš„æ–¹æ³•ï¼Œè¯æ˜æˆ‘ä»¬çš„ç®—æ³•å¯ä»¥ä¼˜åŒ–ä»æ¬¡ä¼˜åˆå§‹æ¡ä»¶å¼€å§‹çš„å»¶è¿Ÿï¼Œå¹¶æé«˜åˆ†ç±»ç²¾åº¦ï¼Œä¸æ²¡æœ‰å»¶è¿Ÿçš„æ¶æ„ç›¸æ¯”ã€‚æœ€åï¼Œæˆ‘ä»¬è¯æ˜æˆ‘ä»¬çš„æ–¹æ³•ä½¿ç”¨çš„å†…å­˜ä¸åˆ°å½“å‰æœ€å…ˆè¿›çš„å»¶è¿Ÿå­¦ä¹ æ–¹æ³•çš„ä¸€åŠï¼Œå¹¶ä¸”é€Ÿåº¦æœ€å¿«å¯è¾¾26å€ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>Spiking Neural Networks (SNNs) ä½œä¸ºä¸€ç§æ›´èŠ‚èƒ½çš„ç¥ç»ç½‘ç»œå½¢å¼å—åˆ°å…³æ³¨ã€‚</li>
<li>è„‰å†²ç¥ç»å…ƒå…·æœ‰çŠ¶æ€å’Œå†…åœ¨å¤å‘æ€§ï¼Œé€‚åˆå¤„ç†æ—¶ç©ºä»»åŠ¡ã€‚</li>
<li>å»¶è¿Ÿæ˜¯SNNsä¸­å¼ºå¤§çš„é™„åŠ æœºåˆ¶ï¼Œç”¨äºä¼˜åŒ–æ€§èƒ½ã€‚</li>
<li>æå‡ºäº†ä¸€ç§æ–°å‹äº‹ä»¶é©±åŠ¨è®­ç»ƒæ–¹æ³•ï¼Œç»“åˆEventPropå½¢å¼ä¸»ä¹‰ï¼Œå¯è®¡ç®—æƒé‡å’Œå»¶è¿Ÿçš„ç¡®åˆ‡æ¢¯åº¦ã€‚</li>
<li>è¯¥æ–¹æ³•æ”¯æŒå¤šä¸ªè„‰å†²ï¼Œå¹¶é¦–æ¬¡åº”ç”¨äºé€’å½’SNNsçš„å»¶è¿Ÿå­¦ä¹ ã€‚</li>
<li>åœ¨åºåˆ—æ£€æµ‹ä»»åŠ¡åŠå¤šä¸ªæ•°æ®é›†ä¸Šè¯„ä¼°ï¼Œè¯æ˜ç®—æ³•èƒ½ä¼˜åŒ–å»¶è¿Ÿå¹¶æå‡åˆ†ç±»ç²¾åº¦ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.07331">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-fb5487d1b523d19084184b1e596c7e73.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-985974598a650db595f2e82aee117459.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-eb9b02ac2bbea6ac68b241cdf29c6b21.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-a9dd79f1fc8a708d9639de21b95b99de.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="On-Creating-A-Brain-To-Text-Decoder"><a href="#On-Creating-A-Brain-To-Text-Decoder" class="headerlink" title="On Creating A Brain-To-Text Decoder"></a>On Creating A Brain-To-Text Decoder</h2><p><strong>Authors:Zenon Lamprou, Yashar Moshfeghi</strong></p>
<p>Brain decoding has emerged as a rapidly advancing and extensively utilized technique within neuroscience. This paper centers on the application of raw electroencephalogram (EEG) signals for decoding human brain activity, offering a more expedited and efficient methodology for enhancing our understanding of the human brain. The investigation specifically scrutinizes the efficacy of brain-computer interfaces (BCI) in deciphering neural signals associated with speech production, with particular emphasis on the impact of vocabulary size, electrode density, and training data on the frameworkâ€™s performance. The study reveals the competitive word error rates (WERs) achievable on the Librispeech benchmark through pre-training on unlabelled data for speech processing. Furthermore, the study evaluates the efficacy of voice recognition under configurations with limited labeled data, surpassing previous state-of-the-art techniques while utilizing significantly fewer labels. Additionally, the research provides a comprehensive analysis of error patterns in voice recognition and the influence of model size and unlabelled training data. It underscores the significance of factors such as vocabulary size and electrode density in enhancing BCI performance, advocating for an increase in microelectrodes and refinement of language models. </p>
<blockquote>
<p>è„‘è§£ç ä½œä¸ºç¥ç»ç§‘å­¦é¢†åŸŸçš„ä¸€ç§å¿«é€Ÿè¿›æ­¥ä¸”å¹¿æ³›åº”ç”¨çš„æŠ€æœ¯å·²ç»å´­éœ²å¤´è§’ã€‚æœ¬æ–‡é‡ç‚¹ç ”ç©¶åŸå§‹è„‘ç”µå›¾ï¼ˆEEGï¼‰ä¿¡å·åœ¨è§£ç äººè„‘æ´»åŠ¨ä¸­çš„åº”ç”¨ï¼Œä¸ºå¢å¼ºæˆ‘ä»¬å¯¹äººè„‘çš„ç†è§£æä¾›äº†ä¸€ç§æ›´å¿«ã€æ›´é«˜æ•ˆçš„æ–¹æ³•ã€‚ç ”ç©¶ç‰¹åˆ«ç»†è‡´åœ°å®¡è§†äº†è„‘æœºæ¥å£ï¼ˆBCIï¼‰åœ¨è§£æä¸è¨€è¯­äº§ç”Ÿç›¸å…³çš„ç¥ç»ä¿¡å·æ–¹é¢çš„æœ‰æ•ˆæ€§ï¼Œç‰¹åˆ«å¼ºè°ƒäº†è¯æ±‡é‡ã€ç”µæå¯†åº¦å’Œè®­ç»ƒæ•°æ®å¯¹æ¡†æ¶æ€§èƒ½çš„å½±å“ã€‚è¯¥ç ”ç©¶é€šè¿‡åœ¨æ— æ ‡ç­¾æ•°æ®ä¸Šè¿›è¡Œé¢„è®­ç»ƒï¼Œæ­ç¤ºäº†LibrispeechåŸºå‡†æµ‹è¯•ä¸Šå¯å®ç°çš„ç«äº‰è¯é”™è¯¯ç‡ï¼ˆWERsï¼‰ã€‚æ­¤å¤–ï¼Œè¯¥ç ”ç©¶åœ¨æœ‰é™æ ‡è®°æ•°æ®é…ç½®ä¸‹å¯¹è¯­éŸ³è¯†åˆ«çš„æœ‰æ•ˆæ€§è¿›è¡Œäº†è¯„ä¼°ï¼Œåœ¨åˆ©ç”¨æ˜æ˜¾æ›´å°‘çš„æ ‡ç­¾çš„æƒ…å†µä¸‹ï¼Œè¶…è¶Šäº†ä»¥å‰æœ€å…ˆè¿›çš„æŠ€æœ¯ã€‚æ­¤å¤–ï¼Œè¯¥ç ”ç©¶è¿˜å…¨é¢åˆ†æäº†è¯­éŸ³è¯†åˆ«ä¸­çš„é”™è¯¯æ¨¡å¼ä»¥åŠæ¨¡å‹å¤§å°å’Œæœªæ ‡è®°è®­ç»ƒæ•°æ®çš„å½±å“ã€‚å®ƒå¼ºè°ƒäº†å¢åŠ è¯æ±‡é‡å’Œæé«˜ç”µæå¯†åº¦ç­‰è¦ç´ åœ¨æé«˜BCIæ€§èƒ½ä¸­çš„é‡è¦æ€§ï¼Œæå€¡å¢åŠ å¾®ç”µææ•°é‡å’Œå®Œå–„è¯­è¨€æ¨¡å‹ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.06326v2">PDF</a> </p>
<p><strong>Summary</strong><br>è„‘è§£ç æ˜¯ç¥ç»ç§‘å­¦ä¸­å‘å±•è¿…é€Ÿä¸”å¹¿æ³›åº”ç”¨çš„æŠ€æœ¯ã€‚æœ¬æ–‡å…³æ³¨åŸå§‹è„‘ç”µå›¾ä¿¡å·åœ¨è§£ç äººç±»è„‘æ´»åŠ¨ä¸­çš„åº”ç”¨ï¼Œæä¾›ä¸€ç§æ›´å¿«ã€æ›´é«˜æ•ˆçš„æ–¹æ³•ï¼Œä»¥æé«˜å¯¹å¤§è„‘çš„ç†è§£ã€‚ç ”ç©¶é‡ç‚¹æ¢è®¨äº†è„‘æœºæ¥å£åœ¨è§£æä¸è¨€è¯­äº§ç”Ÿç›¸å…³çš„ç¥ç»ä¿¡å·æ–¹é¢çš„æœ‰æ•ˆæ€§ï¼Œç‰¹åˆ«å…³æ³¨è¯æ±‡é‡ã€ç”µæå¯†åº¦å’Œè®­ç»ƒæ•°æ®å¯¹ç³»ç»Ÿæ€§èƒ½çš„å½±å“ã€‚ç ”ç©¶è¿˜é€šè¿‡é¢„è®­ç»ƒæœªæ ‡è®°æ•°æ®ï¼Œæ­ç¤ºäº†LibrispeechåŸºå‡†æµ‹è¯•ä¸Šå¯è¾¾åˆ°çš„ç«äº‰è¯é”™è¯¯ç‡ï¼Œå¹¶åœ¨æœ‰é™æ ‡è®°æ•°æ®é…ç½®ä¸‹è¯„ä¼°äº†è¯­éŸ³è¯†åˆ«çš„æœ‰æ•ˆæ€§ï¼ŒåŒæ—¶åˆ†æäº†è¯­éŸ³è¯†åˆ«çš„é”™è¯¯æ¨¡å¼ä»¥åŠæ¨¡å‹å¤§å°å’Œæœªæ ‡è®°è®­ç»ƒæ•°æ®çš„å½±å“ã€‚å¼ºè°ƒäº†å¢åŠ å¾®ç”µæå’Œæ”¹è¿›è¯­è¨€æ¨¡å‹çš„é‡è¦æ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>è„‘è§£ç æŠ€æœ¯å·²æˆä¸ºç¥ç»ç§‘å­¦ä¸­çš„æ ¸å¿ƒæ–¹æ³•ï¼Œåˆ©ç”¨åŸå§‹è„‘ç”µå›¾ä¿¡å·è§£ç äººç±»è„‘æ´»åŠ¨ï¼Œæé«˜æˆ‘ä»¬å¯¹å¤§è„‘çš„ç†è§£ã€‚</li>
<li>ç ”ç©¶å…³æ³¨è„‘æœºæ¥å£åœ¨è§£æä¸è¨€è¯­äº§ç”Ÿç›¸å…³çš„ç¥ç»ä¿¡å·æ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚</li>
<li>è¯æ±‡é‡ã€ç”µæå¯†åº¦å’Œè®­ç»ƒæ•°æ®æ˜¯å½±å“è„‘æœºæ¥å£æ€§èƒ½çš„å…³é”®å› ç´ ã€‚</li>
<li>é€šè¿‡é¢„è®­ç»ƒæœªæ ‡è®°æ•°æ®ï¼Œå¯ä»¥åœ¨LibrispeechåŸºå‡†æµ‹è¯•ä¸Šå®ç°è¾ƒä½çš„è¯é”™è¯¯ç‡ã€‚</li>
<li>åœ¨æœ‰é™æ ‡è®°æ•°æ®é…ç½®ä¸‹ï¼Œç ”ç©¶æå‡ºçš„è¯­éŸ³è¯†åˆ«æ–¹æ³•ä¼˜äºç°æœ‰æŠ€æœ¯ã€‚</li>
<li>ç ”ç©¶åˆ†æäº†è¯­éŸ³è¯†åˆ«çš„é”™è¯¯æ¨¡å¼ï¼Œå¹¶æ¢è®¨äº†æ¨¡å‹å¤§å°å’Œæœªæ ‡è®°è®­ç»ƒæ•°æ®çš„å½±å“ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.06326">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-8df5733bc61e92075cd497fedf3aa89a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-021237d826480c29139f3dc0970fc579.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="Wave-U-Mamba-An-End-To-End-Framework-For-High-Quality-And-Efficient-Speech-Super-Resolution"><a href="#Wave-U-Mamba-An-End-To-End-Framework-For-High-Quality-And-Efficient-Speech-Super-Resolution" class="headerlink" title="Wave-U-Mamba: An End-To-End Framework For High-Quality And Efficient   Speech Super Resolution"></a>Wave-U-Mamba: An End-To-End Framework For High-Quality And Efficient   Speech Super Resolution</h2><p><strong>Authors:Yongjoon Lee, Chanwoo Kim</strong></p>
<p>Speech Super-Resolution (SSR) is a task of enhancing low-resolution speech signals by restoring missing high-frequency components. Conventional approaches typically reconstruct log-mel features, followed by a vocoder that generates high-resolution speech in the waveform domain. However, as mel features lack phase information, this can result in performance degradation during the reconstruction phase. Motivated by recent advances with Selective State Spaces Models (SSMs), we propose a method, referred to as Wave-U-Mamba that directly performs SSR in time domain. In our comparative study, including models such as WSRGlow, NU-Wave 2, and AudioSR, Wave-U-Mamba demonstrates superior performance, achieving the lowest Log-Spectral Distance (LSD) across various low-resolution sampling rates, ranging from 8 to 24 kHz. Additionally, subjective human evaluations, scored using Mean Opinion Score (MOS) reveal that our method produces SSR with natural and human-like quality. Furthermore, Wave-U-Mamba achieves these results while generating high-resolution speech over nine times faster than baseline models on a single A100 GPU, with parameter sizes less than 2% of those in the baseline models. </p>
<blockquote>
<p>è¯­éŸ³è¶…åˆ†è¾¨ç‡ï¼ˆSSRï¼‰æ˜¯é€šè¿‡æ¢å¤ç¼ºå¤±çš„é«˜é¢‘æˆåˆ†æ¥æé«˜ä½åˆ†è¾¨ç‡è¯­éŸ³ä¿¡å·çš„ä»»åŠ¡ã€‚ä¼ ç»Ÿæ–¹æ³•é€šå¸¸é‡å»ºå¯¹æ•°æ¢…å°”ç‰¹å¾ï¼Œç„¶åé€šè¿‡å£°ç å™¨åœ¨æ³¢å½¢åŸŸç”Ÿæˆé«˜åˆ†è¾¨ç‡è¯­éŸ³ã€‚ç„¶è€Œï¼Œç”±äºæ¢…å°”ç‰¹å¾ç¼ºä¹ç›¸ä½ä¿¡æ¯ï¼Œè¿™å¯èƒ½å¯¼è‡´é‡å»ºé˜¶æ®µçš„æ€§èƒ½ä¸‹é™ã€‚å—æœ€è¿‘é€‰æ‹©æ€§çŠ¶æ€ç©ºé—´æ¨¡å‹ï¼ˆSSMï¼‰è¿›å±•çš„å¯å‘ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§ç§°ä¸ºWave-U-Mambaçš„æ–¹æ³•ï¼Œç›´æ¥åœ¨æ—¶é—´åŸŸæ‰§è¡ŒSSRã€‚åœ¨æˆ‘ä»¬çš„æ¯”è¾ƒç ”ç©¶ä¸­ï¼ŒåŒ…æ‹¬WSRGlowã€NU-Wave 2å’ŒAudioSRç­‰æ¨¡å‹ï¼ŒWave-U-Mambaå±•ç¤ºäº†å‡ºè‰²çš„æ€§èƒ½ï¼Œåœ¨å„ç§ä½åˆ†è¾¨ç‡é‡‡æ ·ç‡ï¼ˆä»8åˆ°24 kHzï¼‰ä¸‹å®ç°äº†æœ€ä½çš„å¯¹æ•°è°±è·ç¦»ï¼ˆLSDï¼‰ã€‚æ­¤å¤–ï¼Œä½¿ç”¨å¹³å‡æ„è§å¾—åˆ†ï¼ˆMOSï¼‰è¿›è¡Œçš„ä¸»è§‚äººç±»è¯„ä¼°è¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•äº§ç”Ÿçš„SSRå…·æœ‰è‡ªç„¶å’Œäººæ€§åŒ–è´¨é‡ã€‚è€Œä¸”ï¼ŒWave-U-Mambaåœ¨å•ä¸ªA100 GPUä¸Šç”Ÿæˆé«˜åˆ†è¾¨ç‡è¯­éŸ³çš„é€Ÿåº¦æ˜¯åŸºçº¿æ¨¡å‹çš„9å€ï¼Œå‚æ•°å¤§å°ä¸åˆ°åŸºçº¿æ¨¡å‹çš„2%ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2409.09337v3">PDF</a> Accepted to ICASSP 2025</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†è¯­éŸ³è¶…åˆ†è¾¨ç‡ï¼ˆSSRï¼‰çš„ä»»åŠ¡ï¼Œå³é€šè¿‡å¯¹ç¼ºå¤±çš„é«˜é¢‘æˆåˆ†è¿›è¡Œæ¢å¤æ¥æé«˜ä½åˆ†è¾¨ç‡è¯­éŸ³ä¿¡å·çš„è´¨é‡ã€‚æ–‡ç« æå‡ºäº†ä¸€ç§åŸºäºé€‰æ‹©æ€§çŠ¶æ€ç©ºé—´æ¨¡å‹ï¼ˆSSMsï¼‰çš„æ–¹æ³•â€”â€”Wave-U-Mambaï¼Œç›´æ¥åœ¨æ—¶é—´åŸŸè¿›è¡ŒSSRã€‚ç›¸è¾ƒäºå…¶ä»–æ¨¡å‹ï¼Œå¦‚WSRGlowã€NU-Wave 2å’ŒAudioSRï¼ŒWave-U-Mambaåœ¨å„é¡¹ä½åˆ†è¾¨ç‡é‡‡æ ·ç‡ä¸‹çš„Log-Spectral Distanceï¼ˆLSDï¼‰æŒ‡æ ‡è¡¨ç°æ›´ä¼˜ï¼Œä¸”ç”Ÿæˆçš„è¯­éŸ³è´¨é‡è‡ªç„¶ã€é€¼çœŸã€‚åŒæ—¶ï¼ŒWave-U-Mambaåœ¨å•A100 GPUä¸Šçš„è¿è¡Œé€Ÿåº¦æ˜¯åŸºçº¿æ¨¡å‹çš„ä¹å€ï¼Œå‚æ•°å¤§å°ä»…ä¸ºåŸºçº¿æ¨¡å‹çš„ä¸åˆ°2%ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>è¯­éŸ³è¶…åˆ†è¾¨ç‡ï¼ˆSSRï¼‰æ—¨åœ¨æé«˜ä½åˆ†è¾¨ç‡è¯­éŸ³ä¿¡å·çš„è´¨é‡ï¼Œé€šè¿‡æ¢å¤ç¼ºå¤±çš„é«˜é¢‘æˆåˆ†æ¥å®ç°ã€‚</li>
<li>ä¼ ç»Ÿæ–¹æ³•é€šå¸¸é€šè¿‡é‡å»ºlog-melç‰¹å¾ï¼Œç„¶ååˆ©ç”¨vocoderç”Ÿæˆé«˜åˆ†è¾¨ç‡è¯­éŸ³æ³¢å½¢ã€‚</li>
<li>log-melç‰¹å¾ç¼ºä¹ç›¸ä½ä¿¡æ¯ï¼Œå¯èƒ½å¯¼è‡´é‡å»ºé˜¶æ®µæ€§èƒ½ä¸‹é™ã€‚</li>
<li>åŸºäºé€‰æ‹©æ€§çŠ¶æ€ç©ºé—´æ¨¡å‹ï¼ˆSSMsï¼‰çš„Wave-U-Mambaæ–¹æ³•ç›´æ¥åœ¨æ—¶é—´åŸŸè¿›è¡ŒSSRã€‚</li>
<li>åœ¨å„ç§ä½åˆ†è¾¨ç‡é‡‡æ ·ç‡ä¸‹ï¼ŒWave-U-Mambaçš„Log-Spectral Distanceï¼ˆLSDï¼‰è¡¨ç°ä¼˜äºå…¶ä»–æ¨¡å‹ã€‚</li>
<li>äººç±»ä¸»è§‚è¯„ä»·æ˜¾ç¤ºï¼ŒWave-U-Mambaç”Ÿæˆçš„è¯­éŸ³è´¨é‡è‡ªç„¶ã€é€¼çœŸã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2409.09337">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-0a1db6dfe62eb8580a65a6a5bb57ecfa.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-0c605b7b85e62a59426ea1e89f147081.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-3110bda44b5dc88da52cef986e8a6d2e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c55e38e14f89ca1e3009420a35d10a96.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="MS-HuBERT-Mitigating-Pre-training-and-Inference-Mismatch-in-Masked-Language-Modelling-methods-for-learning-Speech-Representations"><a href="#MS-HuBERT-Mitigating-Pre-training-and-Inference-Mismatch-in-Masked-Language-Modelling-methods-for-learning-Speech-Representations" class="headerlink" title="MS-HuBERT: Mitigating Pre-training and Inference Mismatch in Masked   Language Modelling methods for learning Speech Representations"></a>MS-HuBERT: Mitigating Pre-training and Inference Mismatch in Masked   Language Modelling methods for learning Speech Representations</h2><p><strong>Authors:Hemant Yadav, Sunayana Sitaram, Rajiv Ratn Shah</strong></p>
<p>In recent years, self-supervised pre-training methods have gained significant traction in learning high-level information from raw speech. Among these methods, HuBERT has demonstrated SOTA performance in automatic speech recognition (ASR). However, HuBERTâ€™s performance lags behind data2vec due to disparities in pre-training strategies. In this paper, we propose (i) a Swap method to address pre-training and inference mismatch observed in HuBERT and (ii) incorporates Multicluster masked prediction loss for more effective utilization of the models capacity. The resulting method is, MS-HuBERT, an end-to-end self-supervised pre-training method for learning robust speech representations. It beats vanilla HuBERT on the ASR Librispeech benchmark on average by a 5% margin when evaluated on different finetuning splits. Additionally, we demonstrate that the learned embeddings obtained during pre-training encode essential information for improving performance of content based tasks such as ASR. </p>
<blockquote>
<p>è¿‘å¹´æ¥ï¼Œè‡ªç›‘ç£é¢„è®­ç»ƒæ–¹æ³•åœ¨ä»åŸå§‹è¯­éŸ³ä¸­å­¦ä¹ é«˜çº§ä¿¡æ¯æ–¹é¢è·å¾—äº†å¾ˆå¤§çš„å…³æ³¨ã€‚åœ¨è¿™äº›æ–¹æ³•ä¸­ï¼ŒHuBERTåœ¨è‡ªåŠ¨è¯­éŸ³è¯†åˆ«ï¼ˆASRï¼‰æ–¹é¢è¡¨ç°å‡ºäº†å“è¶Šçš„æ€§èƒ½ã€‚ç„¶è€Œï¼Œç”±äºé¢„è®­ç»ƒç­–ç•¥çš„å·®å¼‚ï¼ŒHuBERTçš„æ€§èƒ½è½åäºdata2vecã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ï¼ˆiï¼‰ä¸€ç§Swapæ–¹æ³•æ¥è§£å†³HuBERTä¸­è§‚å¯Ÿåˆ°çš„é¢„è®­ç»ƒå’Œæ¨ç†ä¸åŒ¹é…çš„é—®é¢˜ï¼Œï¼ˆiiï¼‰å¹¶èå…¥äº†å¤šé›†ç¾¤æ©ç é¢„æµ‹æŸå¤±ï¼Œä»¥æ›´æœ‰æ•ˆåœ°åˆ©ç”¨æ¨¡å‹å®¹é‡ã€‚ç”±æ­¤äº§ç”Ÿçš„æ–¹æ³•ä¸ºMS-HuBERTï¼Œæ˜¯ä¸€ç§ç«¯åˆ°ç«¯çš„è‡ªç›‘ç£é¢„è®­ç»ƒæ–¹æ³•ï¼Œç”¨äºå­¦ä¹ ç¨³å¥çš„è¯­éŸ³è¡¨ç¤ºã€‚åœ¨å¹³å‡æ„ä¹‰ä¸Šï¼Œå½“åœ¨ä¸åŒå¾®è°ƒåˆ†å‰²ä¸Šè¯„ä¼°æ—¶ï¼Œå®ƒåœ¨ASR LibrispeechåŸºå‡†æµ‹è¯•ä¸Šçš„è¡¨ç°ä¼˜äºåŸç‰ˆHuBERTï¼Œå¹³å‡æé«˜äº†5%çš„å‡†ç¡®ç‡ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¯æ˜äº†åœ¨é¢„è®­ç»ƒè¿‡ç¨‹ä¸­è·å¾—çš„å­¦ä¹ åµŒå…¥ç¼–ç äº†å¯¹æ”¹è¿›åŸºäºå†…å®¹ä»»åŠ¡çš„æ€§èƒ½è‡³å…³é‡è¦çš„ä¿¡æ¯ï¼Œä¾‹å¦‚è‡ªåŠ¨è¯­éŸ³è¯†åˆ«ç­‰ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2406.05661v3">PDF</a> 4 pages, submitted to interspeech2024</p>
<p><strong>æ€»ç»“</strong></p>
<p>è¿‘å¹´æ¥ï¼Œè‡ªç›‘ç£é¢„è®­ç»ƒæ–¹æ³•å·²ä»åŸå§‹è¯­éŸ³ä¸­å­¦ä¹ é«˜çº§ä¿¡æ¯è·å¾—äº†æ˜¾è‘—è¿›å±•ã€‚HuBERTç­‰æ–¹æ³•åœ¨è‡ªåŠ¨è¯­éŸ³è¯†åˆ«ï¼ˆASRï¼‰æ–¹é¢è¡¨ç°å‡ºå“è¶Šæ€§èƒ½ã€‚ç„¶è€Œï¼Œç”±äºé¢„è®­ç»ƒç­–ç•¥çš„å·®å¼‚ï¼ŒHuBERTçš„æ€§èƒ½è½åäºdata2vecã€‚æœ¬æ–‡æå‡ºäº†ï¼ˆiï¼‰è§£å†³HuBERTåœ¨é¢„è®­ç»ƒå’Œæ¨ç†è¿‡ç¨‹ä¸­ä¸åŒ¹é…é—®é¢˜çš„Swapæ–¹æ³•ï¼Œä»¥åŠï¼ˆiiï¼‰ç»“åˆå¤šé›†ç¾¤æ©ç é¢„æµ‹æŸå¤±ï¼Œæ›´æœ‰æ•ˆåœ°åˆ©ç”¨æ¨¡å‹å®¹é‡ã€‚ç”±æ­¤äº§ç”Ÿçš„æ–¹æ³•ç§°ä¸ºMS-HuBERTï¼Œæ˜¯ä¸€ç§ç«¯åˆ°ç«¯çš„è‡ªç›‘ç£é¢„è®­ç»ƒæ–¹æ³•ï¼Œç”¨äºå­¦ä¹ ç¨³å¥çš„è¯­éŸ³è¡¨ç¤ºã€‚åœ¨ASR LibrispeechåŸºå‡†æµ‹è¯•ä¸­ï¼Œä¸vanilla HuBERTç›¸æ¯”ï¼ŒMS-HuBERTåœ¨å¾®è°ƒçš„ä¸åŒåˆ†å‰²ç‚¹ä¸Šå¹³å‡æé«˜äº†5%çš„æ€§èƒ½ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜è¯æ˜ï¼Œåœ¨é¢„è®­ç»ƒè¿‡ç¨‹ä¸­è·å¾—çš„åµŒå…¥ç¼–ç å¯¹äºæ”¹è¿›åŸºäºå†…å®¹çš„ä»»åŠ¡ï¼ˆå¦‚ASRï¼‰çš„æ€§èƒ½è‡³å…³é‡è¦ã€‚</p>
<p><strong>å…³é”®è§è§£</strong></p>
<ol>
<li>è‡ªç›‘ç£é¢„è®­ç»ƒæ–¹æ³•å·²ç”¨äºä»åŸå§‹è¯­éŸ³ä¸­å­¦ä¹ é«˜çº§ä¿¡æ¯ã€‚</li>
<li>HuBERTåœ¨è‡ªåŠ¨è¯­éŸ³è¯†åˆ«ï¼ˆASRï¼‰æ–¹é¢è¡¨ç°å‡ºå“è¶Šæ€§èƒ½ï¼Œä½†é¢„è®­ç»ƒç­–ç•¥çš„å·®å¼‚å¯¼è‡´å…¶åœ¨æŸäº›æ–¹é¢è½åäºdata2vecã€‚</li>
<li>æœ¬æ–‡æå‡ºäº†Swapæ–¹æ³•æ¥è§£å†³HuBERTåœ¨é¢„è®­ç»ƒå’Œæ¨ç†è¿‡ç¨‹ä¸­çš„ä¸åŒ¹é…é—®é¢˜ã€‚</li>
<li>å¤šé›†ç¾¤æ©ç é¢„æµ‹æŸå¤±è¢«å¼•å…¥ä»¥æé«˜æ¨¡å‹æ•ˆç‡ã€‚</li>
<li>MS-HuBERTæ˜¯ä¸€ç§æ–°çš„è‡ªç›‘ç£é¢„è®­ç»ƒæ–¹æ³•ï¼Œæ—¨åœ¨å­¦ä¹ ç¨³å¥çš„è¯­éŸ³è¡¨ç¤ºã€‚</li>
<li>MS-HuBERTåœ¨ASR LibrispeechåŸºå‡†æµ‹è¯•ä¸­ä¼˜äºåŸç‰ˆHuBERTã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2406.05661">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-e73eac2fa02ccc1cb25e101ccb52550c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f6ed15cb4238f8dee78bec52cc55256c.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-cd85e2c2e729e486d20bdae5b3635c76.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-2857e337797ec8a87ce31155d7353a94.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-8daf29d02907ddf910f53299020b37ce.jpg" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-02-05/Speech/">https://kedreamix.github.io/Talk2Paper/Paper/2025-02-05/Speech/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/Speech/">
                                    <span class="chip bg-color">Speech</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-02-05/GAN/">
                    <div class="card-image">
                        
                        <img src="https://pic1.zhimg.com/v2-4f141bc5650c59804d3f9a2085de1663.jpg" class="responsive-img" alt="GAN">
                        
                        <span class="card-title">GAN</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            GAN æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-02-05  Ambient Denoising Diffusion Generative Adversarial Networks for   Establishing Stochastic Object Models from Noisy Image Data
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-02-05
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/GAN/" class="post-category">
                                    GAN
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/GAN/">
                        <span class="chip bg-color">GAN</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-02-05/%E6%97%A0%E7%9B%91%E7%9D%A3_%E5%8D%8A%E7%9B%91%E7%9D%A3_%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0/">
                    <div class="card-image">
                        
                        <img src="https://pica.zhimg.com/v2-a9bb2a5ae7ed8d00afc2eefdb3258681.jpg" class="responsive-img" alt="æ— ç›‘ç£/åŠç›‘ç£/å¯¹æ¯”å­¦ä¹ ">
                        
                        <span class="card-title">æ— ç›‘ç£/åŠç›‘ç£/å¯¹æ¯”å­¦ä¹ </span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            æ— ç›‘ç£/åŠç›‘ç£/å¯¹æ¯”å­¦ä¹  æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-02-05  Improving Multi-Label Contrastive Learning by Leveraging Label   Distribution
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-02-05
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/%E6%97%A0%E7%9B%91%E7%9D%A3-%E5%8D%8A%E7%9B%91%E7%9D%A3-%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0/" class="post-category">
                                    æ— ç›‘ç£/åŠç›‘ç£/å¯¹æ¯”å­¦ä¹ 
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/%E6%97%A0%E7%9B%91%E7%9D%A3-%E5%8D%8A%E7%9B%91%E7%9D%A3-%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0/">
                        <span class="chip bg-color">æ— ç›‘ç£/åŠç›‘ç£/å¯¹æ¯”å­¦ä¹ </span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">18588k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
