<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Agent">
    <meta name="description" content="Agent æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-02-05  Multi-agent Multi-armed Bandit with Fully Heavy-tailed Dynamics">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>Agent | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://pic1.zhimg.com/v2-7f7e8b593b1b5e007bf2ad4307af4d54.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Agent</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/Agent/">
                                <span class="chip bg-color">Agent</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/Agent/" class="post-category">
                                Agent
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-02-05
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-02-12
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    19.5k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    80 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-02-05-æ›´æ–°"><a href="#2025-02-05-æ›´æ–°" class="headerlink" title="2025-02-05 æ›´æ–°"></a>2025-02-05 æ›´æ–°</h1><h2 id="Multi-agent-Multi-armed-Bandit-with-Fully-Heavy-tailed-Dynamics"><a href="#Multi-agent-Multi-armed-Bandit-with-Fully-Heavy-tailed-Dynamics" class="headerlink" title="Multi-agent Multi-armed Bandit with Fully Heavy-tailed Dynamics"></a>Multi-agent Multi-armed Bandit with Fully Heavy-tailed Dynamics</h2><p><strong>Authors:Xingyu Wang, Mengfan Xu</strong></p>
<p>We study decentralized multi-agent multi-armed bandits in fully heavy-tailed settings, where clients communicate over sparse random graphs with heavy-tailed degree distributions and observe heavy-tailed (homogeneous or heterogeneous) reward distributions with potentially infinite variance. The objective is to maximize system performance by pulling the globally optimal arm with the highest global reward mean across all clients. We are the first to address such fully heavy-tailed scenarios, which capture the dynamics and challenges in communication and inference among multiple clients in real-world systems. In homogeneous settings, our algorithmic framework exploits hub-like structures unique to heavy-tailed graphs, allowing clients to aggregate rewards and reduce noises via hub estimators when constructing UCB indices; under $M$ clients and degree distributions with power-law index $\alpha &gt; 1$, our algorithm attains a regret bound (almost) of order $O(M^{1 -\frac{1}{\alpha}} \log{T})$. Under heterogeneous rewards, clients synchronize by communicating with neighbors, aggregating exchanged estimators in UCB indices; With our newly established information delay bounds on sparse random graphs, we prove a regret bound of $O(M \log{T})$. Our results improve upon existing work, which only address time-invariant connected graphs, or light-tailed dynamics in dense graphs and rewards. </p>
<blockquote>
<p>æˆ‘ä»¬ç ”ç©¶åœ¨å®Œå…¨é‡å°¾ç¯å¢ƒä¸­åˆ†æ•£çš„å¤šæ™ºèƒ½ä½“å¤šè‡‚èµŒåšé—®é¢˜ã€‚åœ¨æ­¤ç¯å¢ƒä¸­ï¼Œå®¢æˆ·ç«¯é€šè¿‡ç¨€ç–éšæœºå›¾è¿›è¡Œé€šä¿¡ï¼Œè¿™äº›å›¾çš„åº¦åˆ†å¸ƒå…·æœ‰é‡å°¾ç‰¹æ€§ï¼Œå¹¶ä¸”è§‚å¯Ÿåˆ°é‡å°¾ï¼ˆåŒè´¨æˆ–å¼‚è´¨ï¼‰çš„å¥–åŠ±åˆ†å¸ƒï¼Œå¯èƒ½å­˜åœ¨æ— é™æ–¹å·®ã€‚æˆ‘ä»¬çš„ç›®æ ‡æ˜¯æœ€å¤§åŒ–ç³»ç»Ÿæ€§èƒ½ï¼Œé€šè¿‡æ‹‰åŠ¨æ‰€æœ‰å®¢æˆ·ä¸­å…·æœ‰æœ€é«˜å…¨å±€å¥–åŠ±å‡å€¼çš„æœ€ä½³å…¨å±€æ‰‹è‡‚ã€‚æˆ‘ä»¬æ˜¯ç¬¬ä¸€ä¸ªè§£å†³è¿™ç§å®Œå…¨é‡å°¾åœºæ™¯çš„ç ”ç©¶å›¢é˜Ÿï¼Œè¿™æ•æ‰äº†ç°å®ä¸–ç•Œä¸­å¤šä¸ªå®¢æˆ·ç«¯ä¹‹é—´çš„é€šä¿¡å’Œæ¨æ–­çš„åŠ¨åŠ›å­¦å’ŒæŒ‘æˆ˜ã€‚åœ¨åŒè´¨ç¯å¢ƒä¸­ï¼Œæˆ‘ä»¬çš„ç®—æ³•æ¡†æ¶åˆ©ç”¨é‡å°¾å›¾ä¸­ç‹¬æœ‰çš„ä¸­å¿ƒç»“æ„ï¼Œå…è®¸å®¢æˆ·ç«¯åœ¨æ„å»ºUCBæŒ‡æ•°æ—¶é€šè¿‡ä¸­å¿ƒä¼°è®¡å™¨æ¥èšåˆå¥–åŠ±å¹¶å‡å°‘å™ªå£°ï¼›åœ¨æ‹¥æœ‰å¹‚å¾‹æŒ‡æ•°Î±&gt; 1çš„Mä¸ªå®¢æˆ·ç«¯å’Œåº¦åˆ†å¸ƒçš„æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬çš„ç®—æ³•è¾¾åˆ°äº†å‡ ä¹ä¸ºO(M^{1 -\frac{1}{\alpha}} log{T})çš„åæ‚”ç•Œã€‚åœ¨å¼‚è´¨å¥–åŠ±ä¸‹ï¼Œå®¢æˆ·ç«¯é€šè¿‡ä¸é‚»å±…é€šä¿¡è¿›è¡ŒåŒæ­¥ï¼Œåœ¨UCBæŒ‡æ•°ä¸­èšåˆäº¤æ¢çš„ä¼°è®¡å™¨ï¼›æ ¹æ®æˆ‘ä»¬åœ¨ç¨€ç–éšæœºå›¾ä¸Šæ–°å»ºç«‹çš„ä¿¡æ¯å»¶è¿Ÿç•Œé™ï¼Œæˆ‘ä»¬è¯æ˜äº†O(M log{T})çš„åæ‚”ç•Œã€‚æˆ‘ä»¬çš„ç ”ç©¶ç»“æœæ”¹è¿›äº†ç°æœ‰å·¥ä½œï¼Œè¿™äº›å·¥ä½œä»…é’ˆå¯¹æ—¶é—´ä¸å˜çš„è¿é€šå›¾æˆ–å¯†é›†å›¾ä¸­çš„è½»å°¾åŠ¨æ€å’Œå¥–åŠ±è¿›è¡Œç ”ç©¶ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.19239v1">PDF</a> 40 pages</p>
<p><strong>Summary</strong>ï¼š<br>åœ¨å®Œå…¨é‡å°¾åˆ†å¸ƒçš„ç¯å¢ƒä¸­ï¼Œç ”ç©¶äº†åˆ†æ•£å¼å¤šæ™ºèƒ½ä½“å¤šè‡‚è€è™æœºé—®é¢˜ã€‚åœ¨ç¨€ç–éšæœºå›¾ä¸­é€šä¿¡æ—¶ï¼Œé€šä¿¡å®¢æˆ·ä¹‹é—´çš„èŠ‚ç‚¹åº¦æ•°åˆ†å¸ƒå’Œå¥–åŠ±åˆ†å¸ƒå‘ˆç°é‡å°¾ç‰¹æ€§ã€‚ç›®æ ‡æ˜¯æœ€å¤§åŒ–ç³»ç»Ÿæ€§èƒ½ï¼Œé€šè¿‡æ‹‰åŠ¨å…¨å±€æœ€ä¼˜è‡‚è·å¾—æœ€é«˜å…¨å±€å¹³å‡å¥–åŠ±ã€‚é¦–æ¬¡è§£å†³æ­¤ç±»å®Œå…¨é‡å°¾åœºæ™¯é—®é¢˜ï¼Œæ•æ‰äº†ç°å®ç³»ç»Ÿä¸­å¤šä¸ªå®¢æˆ·ç«¯ä¹‹é—´çš„é€šä¿¡å’Œæ¨æ–­åŠ¨æ€å’ŒæŒ‘æˆ˜ã€‚åœ¨å¥–åŠ±åˆ†å¸ƒå‡åŒ€çš„ç¯å¢ƒä¸‹ï¼Œç®—æ³•æ¡†æ¶åˆ©ç”¨é‡å°¾å›¾çš„ä¸­å¿ƒç»“æ„ç‰¹ç‚¹ï¼Œæ„å»ºUCBæŒ‡æ•°æ—¶é€šè¿‡ä¸­å¿ƒä¼°è®¡å™¨èšåˆå¥–åŠ±å¹¶å‡å°‘å™ªå£°ï¼›åœ¨Mä¸ªå®¢æˆ·ç«¯å’Œå¹‚å¾‹æŒ‡æ•°Î±&gt;1çš„æƒ…å†µä¸‹ï¼Œç®—æ³•è¾¾åˆ°å‡ ä¹ä¸ºO(M^{1-\frac{1}{\alpha}} log{T})çš„åæ‚”ç•Œã€‚åœ¨å¥–åŠ±åˆ†å¸ƒä¸å‡çš„ç¯å¢ƒä¸‹ï¼Œå®¢æˆ·ç«¯é€šè¿‡ä¸é‚»å±…åŒæ­¥é€šä¿¡å¹¶åœ¨UCBæŒ‡æ•°ä¸­èšåˆä¼°è®¡å™¨ï¼›æ ¹æ®æ–°å»ºç«‹çš„ä¿¡æ¯å»¶è¿Ÿè¾¹ç•Œåœ¨ç¨€ç–éšæœºå›¾ä¸Šï¼Œæˆ‘ä»¬è¯æ˜äº†åæ‚”ç•Œä¸ºO(M log{T})ã€‚ç»“æœä¼˜äºç°æœ‰åªå¤„ç†æ—¶é—´ä¸å˜è¿é€šå›¾æˆ–å¯†é›†å›¾ä¸­è½»å°¾åŠ¨åŠ›å­¦çš„è§£å†³æ–¹æ¡ˆã€‚</p>
<p><strong>Key Takeaways</strong>:</p>
<ol>
<li>ç ”ç©¶äº†åˆ†æ•£å¼å¤šæ™ºèƒ½ä½“å¤šè‡‚è€è™æœºåœ¨å®Œå…¨é‡å°¾åˆ†å¸ƒç¯å¢ƒä¸‹çš„è¡¨ç°ã€‚</li>
<li>åœ¨ç¨€ç–éšæœºå›¾ä¸­é€šä¿¡æ—¶ï¼ŒèŠ‚ç‚¹åº¦æ•°åˆ†å¸ƒå’Œå¥–åŠ±åˆ†å¸ƒå‘ˆç°é‡å°¾ç‰¹æ€§ã€‚</li>
<li>ç›®æ ‡æ˜¯é€šè¿‡æœ€å¤§åŒ–ç³»ç»Ÿæ€§èƒ½æ¥æ‹‰åŠ¨å…¨å±€æœ€ä¼˜è‡‚ä»¥è·å–æœ€é«˜å…¨å±€å¹³å‡å¥–åŠ±ã€‚</li>
<li>è¯¥ç ”ç©¶é¦–æ¬¡è§£å†³æ­¤ç±»å®Œå…¨é‡å°¾åœºæ™¯é—®é¢˜ï¼Œåæ˜ ç°å®ç³»ç»Ÿä¸­å¤šä¸ªå®¢æˆ·ç«¯é—´çš„é€šä¿¡å’Œæ¨æ–­åŠ¨æ€å’ŒæŒ‘æˆ˜ã€‚</li>
<li>åœ¨å‡åŒ€å¥–åŠ±ç¯å¢ƒä¸‹ï¼Œç®—æ³•åˆ©ç”¨é‡å°¾å›¾çš„ä¸­å¿ƒç»“æ„ç‰¹ç‚¹æ¥ä¼˜åŒ–æ€§èƒ½ã€‚</li>
<li>åœ¨ä¸åŒç¯å¢ƒä¸‹ï¼Œç®—æ³•æœ‰ä¸åŒçš„åæ‚”ç•Œè¡¨ç°ã€‚åœ¨Mä¸ªå®¢æˆ·ç«¯å’Œç‰¹å®šå¹‚å¾‹æŒ‡æ•°ä¸‹ï¼Œç®—æ³•è¾¾åˆ°ç‰¹å®šçš„åæ‚”ç•Œã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.19239">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-17b0c921e9e81a98b9d8447b95408cbf.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="An-Empirical-Game-Theoretic-Analysis-of-Autonomous-Cyber-Defence-Agents"><a href="#An-Empirical-Game-Theoretic-Analysis-of-Autonomous-Cyber-Defence-Agents" class="headerlink" title="An Empirical Game-Theoretic Analysis of Autonomous Cyber-Defence Agents"></a>An Empirical Game-Theoretic Analysis of Autonomous Cyber-Defence Agents</h2><p><strong>Authors:Gregory Palmer, Luke Swaby, Daniel J. B. Harrold, Matthew Stewart, Alex Hiles, Chris Willis, Ian Miles, Sara Farmer</strong></p>
<p>The recent rise in increasingly sophisticated cyber-attacks raises the need for robust and resilient autonomous cyber-defence (ACD) agents. Given the variety of cyber-attack tactics, techniques and procedures (TTPs) employed, learning approaches that can return generalisable policies are desirable. Meanwhile, the assurance of ACD agents remains an open challenge. We address both challenges via an empirical game-theoretic analysis of deep reinforcement learning (DRL) approaches for ACD using the principled double oracle (DO) algorithm. This algorithm relies on adversaries iteratively learning (approximate) best responses against each othersâ€™ policies; a computationally expensive endeavour for autonomous cyber operations agents. In this work we introduce and evaluate a theoretically-sound, potential-based reward shaping approach to expedite this process. In addition, given the increasing number of open-source ACD-DRL approaches, we extend the DO formulation to allow for multiple response oracles (MRO), providing a framework for a holistic evaluation of ACD approaches. </p>
<blockquote>
<p>è¿‘æœŸæ—¥ç›Šå¤æ‚çš„ç½‘ç»œæ”»å‡»çš„å¢åŠ ï¼Œä½¿å¾—å¯¹å¼ºå¤§ä¸”åšéŸ§çš„è‡ªä¸»ç½‘ç»œå®‰å…¨é˜²å¾¡ï¼ˆACDï¼‰ä»£ç†çš„éœ€æ±‚æ„ˆå‘è¿«åˆ‡ã€‚è€ƒè™‘åˆ°æ‰€ä½¿ç”¨çš„ç½‘ç»œæ”»å‡»ç­–ç•¥ã€æŠ€æœ¯å’Œç¨‹åºï¼ˆTTPsï¼‰çš„å¤šæ ·æ€§ï¼Œå­¦ä¹ èƒ½å¤Ÿå›å½’é€šç”¨ç­–ç•¥çš„æ–¹æ³•æ˜¯éå¸¸ç†æƒ³çš„ã€‚åŒæ—¶ï¼ŒACDä»£ç†çš„ä¿è¯ä»ç„¶æ˜¯ä¸€ä¸ªå¼€æ”¾æ€§çš„æŒ‘æˆ˜ã€‚æˆ‘ä»¬é€šè¿‡æ·±åº¦å¼ºåŒ–å­¦ä¹ ï¼ˆDRLï¼‰æ–¹æ³•æ¥è§£å†³è¿™ä¸¤ä¸ªæŒ‘æˆ˜ï¼Œå¹¶å¯¹ACDè¿›è¡Œå®è¯åšå¼ˆè®ºåˆ†æï¼Œé‡‡ç”¨æœ‰åŸåˆ™çš„Double Oracleï¼ˆDOï¼‰ç®—æ³•ã€‚è¯¥ç®—æ³•ä¾èµ–äºå¯¹æ‰‹ä¹‹é—´é’ˆå¯¹å½¼æ­¤çš„å†³ç­–è¿›è¡Œè¿­ä»£å­¦ä¹ ï¼ˆè¿‘ä¼¼ï¼‰æœ€ä½³å“åº”ï¼Œå¯¹äºè‡ªä¸»ç½‘ç»œæ“ä½œä»£ç†æ¥è¯´æ˜¯ä¸€é¡¹è®¡ç®—æˆæœ¬é«˜æ˜‚çš„å·¥ä½œã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬å¼•å…¥å¹¶è¯„ä¼°äº†ä¸€ç§åŸºäºç†è®ºçš„å¥–åŠ±å¡‘å½¢æ–¹æ³•ï¼Œä»¥åŠ å¿«è¿™ä¸€è¿‡ç¨‹ã€‚æ­¤å¤–ï¼Œé‰´äºå¼€æºACD-DRLæ–¹æ³•çš„æ•°é‡ä¸æ–­å¢åŠ ï¼Œæˆ‘ä»¬å°†DOå…¬å¼æ‰©å±•åˆ°å…è®¸å¤šé‡å“åº”Oracleï¼ˆMROï¼‰ï¼Œä¸ºå…¨é¢è¯„ä¼°ACDæ–¹æ³•æä¾›äº†ä¸€ä¸ªæ¡†æ¶ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.19206v1">PDF</a> 21 pages, 17 figures, 10 tables</p>
<p><strong>Summary</strong></p>
<p>éšç€ç½‘ç»œæ”»å‡»æ‰‹æ®µæ—¥ç›Šå¤æ‚ï¼Œå¯¹è‡ªä¸»ç½‘ç»œå®‰å…¨é˜²å¾¡ï¼ˆACDï¼‰æ™ºèƒ½ä½“çš„éœ€æ±‚æ„ˆå‘è¿«åˆ‡ã€‚ç”±äºç½‘ç»œæ”»å‡»æˆ˜æœ¯ã€æŠ€æœ¯å’Œç¨‹åºï¼ˆTTPsï¼‰çš„ç§ç±»å¤šæ ·ï¼Œå­¦ä¹ é€šç”¨åŒ–ç­–ç•¥è‡³å…³é‡è¦ã€‚é’ˆå¯¹ACDæ™ºèƒ½ä½“çš„å¯ä¿¡åº¦é—®é¢˜ä»¥åŠå­¦ä¹ ç­–ç•¥çš„æ³›åŒ–é—®é¢˜ï¼Œæœ¬ç ”ç©¶é‡‡ç”¨åŸºäºåšå¼ˆè®ºæ·±åº¦å¼ºåŒ–å­¦ä¹ ï¼ˆDRLï¼‰çš„æ–¹æ³•ï¼Œåˆ©ç”¨åŸåˆ™æ€§åŒç›²ç®—æ³•ï¼ˆDOç®—æ³•ï¼‰è¿›è¡Œåˆ†æã€‚ä¸ºæé«˜è®¡ç®—æ•ˆç‡ï¼Œæœ¬ç ”ç©¶å¼•å…¥äº†ä¸€ç§åŸºäºç†è®ºçš„å¥–åŠ±å¡‘é€ æ–¹æ³•ã€‚æ­¤å¤–ï¼Œè€ƒè™‘åˆ°å¼€æºACD-DRLæ–¹æ³•çš„æ•°é‡ä¸æ–­å¢åŠ ï¼Œæœ¬ç ”ç©¶å°†DOç®—æ³•æ‰©å±•åˆ°å¤šé‡å“åº”åŒç›²ï¼ˆMROï¼‰ï¼Œä¸ºå…¨é¢è¯„ä¼°ACDæ–¹æ³•æä¾›æ¡†æ¶ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>è‡ªä¸»ç½‘ç»œå®‰å…¨é˜²å¾¡ï¼ˆACDï¼‰æ™ºèƒ½ä½“å› ç½‘ç»œæ”»å‡»å¤æ‚æ€§è€Œè¶Šå‘é‡è¦ã€‚</li>
<li>éœ€è¦å¼€å‘å¯å­¦ä¹ é€šç”¨åŒ–ç­–ç•¥çš„ç½‘ç»œå®‰å…¨é˜²å¾¡ç­–ç•¥ã€‚</li>
<li>ç ”ç©¶é€šè¿‡æ·±åº¦å¼ºåŒ–å­¦ä¹ çš„åšå¼ˆè®ºåˆ†ææ¥è§£å†³ç­–ç•¥æ³›åŒ–é—®é¢˜ã€‚</li>
<li>é‡‡ç”¨åŸåˆ™æ€§åŒç›²ç®—æ³•ï¼ˆDOç®—æ³•ï¼‰è¿›è¡Œåˆ†æã€‚</li>
<li>ä¸ºæé«˜è®¡ç®—æ•ˆç‡ï¼Œå¼•å…¥åŸºäºç†è®ºçš„å¥–åŠ±å¡‘é€ æ–¹æ³•ã€‚</li>
<li>é’ˆå¯¹æ—¥ç›Šå¢é•¿çš„å¼€æºACDæ–¹æ³•ï¼Œæ‰©å±•äº†å¤šé‡å“åº”åŒç›²ç®—æ³•æ¡†æ¶ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.19206">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-f5cea58dd7c10a1b00bc350c4f3678bb.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-7f7e8b593b1b5e007bf2ad4307af4d54.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-3d69826a6b4a05e8f6e7674604344e01.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="Autonomous-Legacy-Web-Application-Upgrades-Using-a-Multi-Agent-System"><a href="#Autonomous-Legacy-Web-Application-Upgrades-Using-a-Multi-Agent-System" class="headerlink" title="Autonomous Legacy Web Application Upgrades Using a Multi-Agent System"></a>Autonomous Legacy Web Application Upgrades Using a Multi-Agent System</h2><p><strong>Authors:Valtteri Ala-Salmi, Zeeshan Rasheed, Abdul Malik Sami, Zheying Zhang, Kai-Kristian Kemell, Jussi Rasku, Shahbaz Siddeeq, Mika Saari, Pekka Abrahamsson</strong></p>
<p>The use of Large Language Models (LLMs) for autonomous code generation is gaining attention in emerging technologies. As LLM capabilities expand, they offer new possibilities such as code refactoring, security enhancements, and legacy application upgrades. Many outdated web applications pose security and reliability challenges, yet companies continue using them due to the complexity and cost of upgrades. To address this, we propose an LLM-based multi-agent system that autonomously upgrades legacy web applications to the latest versions. The system distributes tasks across multiple phases, updating all relevant files. To evaluate its effectiveness, we employed Zero-Shot Learning (ZSL) and One-Shot Learning (OSL) prompts, applying identical instructions in both cases. The evaluation involved updating view files and measuring the number and types of errors in the output. For complex tasks, we counted the successfully met requirements. The experiments compared the proposed system with standalone LLM execution, repeated multiple times to account for stochastic behavior. Results indicate that our system maintains context across tasks and agents, improving solution quality over the base model in some cases. This study provides a foundation for future model implementations in legacy code updates. Additionally, findings highlight LLMsâ€™ ability to update small outdated files with high precision, even with basic prompts. The source code is publicly available on GitHub: <a target="_blank" rel="noopener" href="https://github.com/alasalm1/Multi-agent-pipeline">https://github.com/alasalm1/Multi-agent-pipeline</a>. </p>
<blockquote>
<p>ä½¿ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰è¿›è¡Œè‡ªä¸»ä»£ç ç”Ÿæˆæ­£å—åˆ°æ–°å…´æŠ€æœ¯çš„å…³æ³¨ã€‚éšç€LLMèƒ½åŠ›çš„æ‰©å±•ï¼Œå®ƒä»¬æä¾›äº†æ–°çš„å¯èƒ½æ€§ï¼Œä¾‹å¦‚ä»£ç é‡æ„ã€å®‰å…¨å¢å¼ºå’Œé—ç•™åº”ç”¨ç¨‹åºå‡çº§ã€‚è®¸å¤šè¿‡æ—¶çš„webåº”ç”¨ç¨‹åºå¸¦æ¥äº†å®‰å…¨å’Œå¯é æ€§æŒ‘æˆ˜ï¼Œä½†ç”±äºå‡çº§å¤æ‚æ€§å’Œæˆæœ¬ï¼Œå…¬å¸ä»ç»§ç»­ä½¿ç”¨å®ƒä»¬ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åŸºäºLLMçš„å¤šæ™ºèƒ½ä½“ç³»ç»Ÿï¼Œè¯¥ç³»ç»Ÿå¯è‡ªä¸»å°†é—ç•™webåº”ç”¨ç¨‹åºå‡çº§åˆ°æœ€æ–°ç‰ˆæœ¬ã€‚è¯¥ç³»ç»Ÿå°†ä»»åŠ¡åˆ†å¸ƒåˆ°å¤šä¸ªé˜¶æ®µï¼Œå¹¶æ›´æ–°æ‰€æœ‰ç›¸å…³æ–‡ä»¶ã€‚ä¸ºäº†è¯„ä¼°å…¶æœ‰æ•ˆæ€§ï¼Œæˆ‘ä»¬é‡‡ç”¨äº†é›¶æ ·æœ¬å­¦ä¹ ï¼ˆZSLï¼‰å’Œå•æ ·æœ¬å­¦ä¹ ï¼ˆOSLï¼‰æç¤ºï¼Œåœ¨ä¸¤ç§æƒ…å†µä¸‹å‡åº”ç”¨ç›¸åŒçš„æŒ‡ä»¤ã€‚è¯„ä¼°è¿‡ç¨‹åŒ…æ‹¬æ›´æ–°è§†å›¾æ–‡ä»¶å¹¶æµ‹é‡è¾“å‡ºä¸­çš„é”™è¯¯æ•°é‡å’Œç±»å‹ã€‚å¯¹äºå¤æ‚ä»»åŠ¡ï¼Œæˆ‘ä»¬è®¡ç®—æˆåŠŸæ»¡è¶³çš„è¦æ±‚æ•°é‡ã€‚å®éªŒå°†æ‰€æå‡ºç³»ç»Ÿä¸ç‹¬ç«‹LLMæ‰§è¡Œè¿›è¡Œäº†æ¯”è¾ƒï¼Œå¤šæ¬¡é‡å¤ä»¥è€ƒè™‘éšæœºè¡Œä¸ºã€‚ç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„ç³»ç»Ÿåœ¨ä»»åŠ¡å’Œæ™ºèƒ½ä½“ä¹‹é—´ä¿æŒäº†ä¸Šä¸‹æ–‡ï¼Œåœ¨æŸäº›æƒ…å†µä¸‹æé«˜äº†è§£å†³æ–¹æ¡ˆçš„è´¨é‡ã€‚è¿™é¡¹ç ”ç©¶ä¸ºæœªæ¥æ¨¡å‹åœ¨é—ç•™ä»£ç æ›´æ–°ä¸­çš„å®ç°æä¾›äº†åŸºç¡€ã€‚æ­¤å¤–ï¼Œç ”ç©¶ç»“æœè¿˜å¼ºè°ƒäº†LLMæ›´æ–°å°è¿‡æ—¶æ–‡ä»¶çš„é«˜ç²¾åº¦èƒ½åŠ›ï¼Œå³ä½¿ä½¿ç”¨åŸºæœ¬çš„æç¤ºä¹Ÿèƒ½å®ç°ã€‚æºä»£ç å·²åœ¨GitHubä¸Šå…¬å¼€å¯ç”¨ï¼š<a target="_blank" rel="noopener" href="https://github.com/alasalm1/Multi-agent-pipeline%E3%80%82">https://github.com/alasalm1/Multi-agent-pipelineã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.19204v1">PDF</a> 13 pages, 2 figures</p>
<p><strong>Summary</strong></p>
<p>åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„è‡ªä¸»ä»£ç ç”ŸæˆæŠ€æœ¯æ­£å—åˆ°æ–°å…´æŠ€æœ¯çš„å…³æ³¨ã€‚éšç€LLMèƒ½åŠ›çš„æ‰©å±•ï¼Œå®ƒä»¬ä¸ºä»£ç é‡æ„ã€å®‰å…¨å¢å¼ºå’Œé—ç•™åº”ç”¨å‡çº§ç­‰æä¾›äº†æ–°çš„å¯èƒ½æ€§ã€‚ä¸ºåº”å¯¹é—ç•™webåº”ç”¨å­˜åœ¨çš„å®‰å…¨å’Œå¯é æ€§æŒ‘æˆ˜ï¼Œæå‡ºäº†ä¸€ç§åŸºäºLLMçš„å¤šæ™ºèƒ½ä½“ç³»ç»Ÿï¼Œå¯è‡ªä¸»å°†é—ç•™webåº”ç”¨å‡çº§åˆ°æœ€æ–°ç‰ˆæœ¬ã€‚é€šè¿‡åˆ†å¸ƒä»»åŠ¡åœ¨å¤šé˜¶æ®µæ›´æ–°æ‰€æœ‰ç›¸å…³æ–‡ä»¶ã€‚å®éªŒè¡¨æ˜ï¼Œè¯¥ç³»ç»Ÿåœ¨ç»´æŒè¯­å¢ƒè·¨ä»»åŠ¡å’Œæ™ºèƒ½ä½“çš„æƒ…å†µä¸‹ï¼Œåœ¨æŸäº›æƒ…å†µä¸‹æé«˜äº†è§£å†³æ–¹æ¡ˆçš„è´¨é‡ã€‚æ­¤ç ”ç©¶ä¸ºæœªæ¥æ¨¡å‹åœ¨é—ç•™ä»£ç æ›´æ–°ä¸­çš„åº”ç”¨æä¾›äº†åŸºç¡€ã€‚LLMå³ä½¿ä½¿ç”¨åŸºæœ¬æç¤ºï¼Œä¹Ÿèƒ½é«˜ç²¾åº¦åœ°æ›´æ–°å°å‹è¿‡æ—¶æ–‡ä»¶ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ­£è¢«ç”¨äºè‡ªä¸»ä»£ç ç”Ÿæˆï¼Œä¸ºä»£ç é‡æ„ã€å®‰å…¨å¢å¼ºå’Œé—ç•™åº”ç”¨å‡çº§æä¾›æ–°å¯èƒ½æ€§ã€‚</li>
<li>é—ç•™webåº”ç”¨å­˜åœ¨å®‰å…¨å’Œå¯é æ€§æŒ‘æˆ˜ï¼Œå…¬å¸å› å‡çº§å¤æ‚æ€§å’Œæˆæœ¬è€Œç»§ç»­ä½¿ç”¨ã€‚</li>
<li>æå‡ºä¸€ç§åŸºäºLLMçš„å¤šæ™ºèƒ½ä½“ç³»ç»Ÿï¼Œå¯è‡ªä¸»å‡çº§é—ç•™webåº”ç”¨åˆ°æœ€æ–°ç‰ˆæœ¬ï¼Œé€šè¿‡åˆ†å¸ƒä»»åŠ¡åœ¨å¤šé˜¶æ®µæ›´æ–°æ–‡ä»¶ã€‚</li>
<li>é€šè¿‡Zero-Shot Learningï¼ˆZSLï¼‰å’ŒOne-Shot Learningï¼ˆOSLï¼‰æç¤ºè¯„ä¼°ç³»ç»Ÿæœ‰æ•ˆæ€§ã€‚</li>
<li>å®éªŒè¡¨æ˜ï¼Œè¯¥ç³»ç»Ÿåœ¨ç»´æŒè¯­å¢ƒè·¨ä»»åŠ¡å’Œæ™ºèƒ½ä½“çš„æƒ…å†µä¸‹ï¼Œæé«˜è§£å†³æ–¹æ¡ˆè´¨é‡ã€‚</li>
<li>LLMsèƒ½å¤Ÿæ›´æ–°å°å‹è¿‡æ—¶æ–‡ä»¶ï¼Œä¸”ç²¾åº¦é«˜ï¼Œå³ä½¿ä½¿ç”¨åŸºæœ¬æç¤ºä¹Ÿèƒ½å®ç°ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.19204">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-893be34ad8d104c4b041f0725b4a295f.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-b5104042522cf6da29d53beb73e4cfc2.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ae6b0157d7a32c04f34839a372f5d852.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="O-MAPL-Offline-Multi-agent-Preference-Learning"><a href="#O-MAPL-Offline-Multi-agent-Preference-Learning" class="headerlink" title="O-MAPL: Offline Multi-agent Preference Learning"></a>O-MAPL: Offline Multi-agent Preference Learning</h2><p><strong>Authors:The Viet Bui, Tien Mai, Hong Thanh Nguyen</strong></p>
<p>Inferring reward functions from demonstrations is a key challenge in reinforcement learning (RL), particularly in multi-agent RL (MARL), where large joint state-action spaces and complex inter-agent interactions complicate the task. While prior single-agent studies have explored recovering reward functions and policies from human preferences, similar work in MARL is limited. Existing methods often involve separate stages of supervised reward learning and MARL algorithms, leading to unstable training. In this work, we introduce a novel end-to-end preference-based learning framework for cooperative MARL, leveraging the underlying connection between reward functions and soft Q-functions. Our approach uses a carefully-designed multi-agent value decomposition strategy to improve training efficiency. Extensive experiments on SMAC and MAMuJoCo benchmarks show that our algorithm outperforms existing methods across various tasks. </p>
<blockquote>
<p>ä»æ¼”ç¤ºä¸­æ¨æ–­å¥–åŠ±å‡½æ•°æ˜¯å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰ä¸­çš„ä¸€é¡¹å…³é”®æŒ‘æˆ˜ï¼Œç‰¹åˆ«æ˜¯åœ¨å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ ï¼ˆMARLï¼‰ä¸­ï¼Œè”åˆçŠ¶æ€åŠ¨ä½œç©ºé—´çš„å¤§è§„æ¨¡å’Œæ™ºèƒ½ä½“é—´çš„å¤æ‚äº¤äº’ä½¿ä»»åŠ¡å¤æ‚åŒ–ã€‚è™½ç„¶ä¹‹å‰çš„å•æ™ºèƒ½ä½“ç ”ç©¶å·²ç»æ¢ç´¢äº†ä»äººç±»åå¥½ä¸­æ¢å¤å¥–åŠ±å‡½æ•°å’Œæ”¿ç­–ï¼Œä½†ç±»ä¼¼çš„å¤šæ™ºèƒ½ä½“ç ”ç©¶å—åˆ°é™åˆ¶ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸æ¶‰åŠç›‘ç£å¥–åŠ±å­¦ä¹ å’ŒMARLç®—æ³•çš„ç‹¬ç«‹é˜¶æ®µï¼Œå¯¼è‡´è®­ç»ƒä¸ç¨³å®šã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬ä¸ºåˆä½œå‹å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ å¼•å…¥äº†ä¸€ç§æ–°å‹ç«¯åˆ°ç«¯çš„åŸºäºåå¥½çš„å­¦ä¹ æ¡†æ¶ï¼Œåˆ©ç”¨å¥–åŠ±å‡½æ•°å’Œè½¯Qå‡½æ•°ä¹‹é—´çš„å†…åœ¨è”ç³»ã€‚æˆ‘ä»¬çš„æ–¹æ³•é‡‡ç”¨ç²¾å¿ƒè®¾è®¡çš„å¤šæ™ºèƒ½ä½“ä»·å€¼åˆ†è§£ç­–ç•¥æ¥æé«˜è®­ç»ƒæ•ˆç‡ã€‚åœ¨SMACå’ŒMAMuJoCoåŸºå‡†æµ‹è¯•ä¸Šçš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„ç®—æ³•åœ¨å„ç§ä»»åŠ¡ä¸Šçš„è¡¨ç°ä¼˜äºç°æœ‰æ–¹æ³•ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.18944v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>è¯¥æ–‡æœ¬ä»‹ç»äº†å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰ä¸­çš„å…³é”®æŒ‘æˆ˜â€”â€”ä»æ¼”ç¤ºä¸­æ¨æ–­å¥–åŠ±å‡½æ•°ï¼Œç‰¹åˆ«æ˜¯åœ¨å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ ï¼ˆMARLï¼‰ä¸­ã€‚ç”±äºè”åˆçŠ¶æ€åŠ¨ä½œç©ºé—´åºå¤§å’Œæ™ºèƒ½ä½“é—´å¤æ‚äº¤äº’ï¼Œè¿™é¡¹å·¥ä½œæ›´å…·æŒ‘æˆ˜æ€§ã€‚å°½ç®¡å…ˆå‰å•æ™ºèƒ½ä½“ç ”ç©¶å·²æ¢ç´¢ä»äººç±»åå¥½ä¸­æ¢å¤å¥–åŠ±å‡½æ•°å’Œç­–ç•¥ï¼Œä½†å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ ä¸­çš„ç±»ä¼¼å·¥ä½œä»æœ‰é™ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸æ¶‰åŠç›‘ç£å¥–åŠ±å­¦ä¹ å’ŒMARLç®—æ³•çš„å•ç‹¬é˜¶æ®µï¼Œå¯¼è‡´è®­ç»ƒä¸ç¨³å®šã€‚æœ¬ç ”ç©¶ä»‹ç»äº†ä¸€ç§æ–°å‹åŸºäºåå¥½çš„ç«¯åˆ°ç«¯å­¦ä¹ æ¡†æ¶ï¼Œç”¨äºåˆä½œå‹MARLï¼Œåˆ©ç”¨å¥–åŠ±å‡½æ•°å’Œè½¯Qå‡½æ•°ä¹‹é—´çš„å†…åœ¨è”ç³»ã€‚é€šè¿‡ç²¾å¿ƒè®¾è®¡çš„å¤šæ™ºèƒ½ä½“å€¼åˆ†è§£ç­–ç•¥ï¼Œæé«˜äº†è®­ç»ƒæ•ˆç‡ã€‚åœ¨SMACå’ŒMAMuJoCoåŸºå‡†æµ‹è¯•ä¸Šçš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„ç®—æ³•åœ¨å„é¡¹ä»»åŠ¡ä¸­çš„è¡¨ç°å‡ä¼˜äºç°æœ‰æ–¹æ³•ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ ï¼ˆMARLï¼‰åœ¨æ¨æ–­å¥–åŠ±å‡½æ•°æ–¹é¢é¢ä¸´æŒ‘æˆ˜ï¼Œä¸»è¦ç”±äºè”åˆçŠ¶æ€åŠ¨ä½œç©ºé—´åºå¤§å’Œæ™ºèƒ½ä½“é—´çš„å¤æ‚äº¤äº’ã€‚</li>
<li>ç°æœ‰æ–¹æ³•åœ¨ç›‘ç£å¥–åŠ±å­¦ä¹ å’ŒMARLç®—æ³•åˆ†ç¦»é˜¶æ®µå­˜åœ¨è®­ç»ƒä¸ç¨³å®šçš„é—®é¢˜ã€‚</li>
<li>ç ”ç©¶æå‡ºäº†ä¸€ç§æ–°å‹çš„åŸºäºåå¥½çš„ç«¯åˆ°ç«¯å­¦ä¹ æ¡†æ¶ï¼Œè¯¥æ¡†æ¶é’ˆå¯¹åˆä½œå‹MARLï¼Œå¹¶èåˆäº†å¥–åŠ±å‡½æ•°å’Œè½¯Qå‡½æ•°ä¹‹é—´çš„è”ç³»ã€‚</li>
<li>é€šè¿‡ç²¾å¿ƒè®¾è®¡çš„å¤šæ™ºèƒ½ä½“å€¼åˆ†è§£ç­–ç•¥ï¼Œæé«˜äº†è®­ç»ƒæ•ˆç‡ã€‚</li>
<li>åœ¨SMACå’ŒMAMuJoCoåŸºå‡†æµ‹è¯•ä¸Šè¿›è¡Œçš„å®éªŒè¡¨æ˜ï¼Œè¯¥ç®—æ³•åœ¨å¤šç§ä»»åŠ¡ä¸­çš„è¡¨ç°å‡ä¼˜äºç°æœ‰æ–¹æ³•ã€‚</li>
<li>è¯¥æ¡†æ¶å¯èƒ½ä¸ºè§£å†³å¤šæ™ºèƒ½ä½“ç³»ç»Ÿä¸­çš„å¥–åŠ±å‡½æ•°æ¨æ–­é—®é¢˜æä¾›æ–°çš„æ€è·¯å’Œæ–¹æ³•ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.18944">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-bf8ef703ef3f4490b3c085182b0fa0d7.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="KBQA-o1-Agentic-Knowledge-Base-Question-Answering-with-Monte-Carlo-Tree-Search"><a href="#KBQA-o1-Agentic-Knowledge-Base-Question-Answering-with-Monte-Carlo-Tree-Search" class="headerlink" title="KBQA-o1: Agentic Knowledge Base Question Answering with Monte Carlo Tree   Search"></a>KBQA-o1: Agentic Knowledge Base Question Answering with Monte Carlo Tree   Search</h2><p><strong>Authors:Haoran Luo, Haihong E, Yikai Guo, Qika Lin, Xiaobao Wu, Xinyu Mu, Wenhao Liu, Meina Song, Yifan Zhu, Luu Anh Tuan</strong></p>
<p>Knowledge Base Question Answering (KBQA) aims to answer natural language questions with a large-scale structured knowledge base (KB). Despite advancements with large language models (LLMs), KBQA still faces challenges in weak KB awareness, imbalance between effectiveness and efficiency, and high reliance on annotated data. To address these challenges, we propose KBQA-o1, a novel agentic KBQA method with Monte Carlo Tree Search (MCTS). It introduces a ReAct-based agent process for stepwise logical form generation with KB environment exploration. Moreover, it employs MCTS, a heuristic search method driven by policy and reward models, to balance agentic explorationâ€™s performance and search space. With heuristic exploration, KBQA-o1 generates high-quality annotations for further improvement by incremental fine-tuning. Experimental results show that KBQA-o1 outperforms previous low-resource KBQA methods with limited annotated data, boosting Llama-3.1-8B modelâ€™s GrailQA F1 performance to 78.5% compared to 48.5% of the previous sota method with GPT-3.5-turbo. </p>
<blockquote>
<p>çŸ¥è¯†åº“é—®ç­”ï¼ˆKBQAï¼‰æ—¨åœ¨åˆ©ç”¨å¤§è§„æ¨¡ç»“æ„åŒ–çŸ¥è¯†åº“ï¼ˆKBï¼‰å›ç­”è‡ªç„¶è¯­è¨€é—®é¢˜ã€‚å°½ç®¡å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æœ‰æ‰€è¿›æ­¥ï¼Œä½†KBQAä»ç„¶é¢ä¸´å¯¹çŸ¥è¯†åº“äº†è§£ä¸è¶³ã€æ•ˆç‡å’Œæ•ˆæœä¹‹é—´çš„ä¸å¹³è¡¡ä»¥åŠé«˜åº¦ä¾èµ–æ ‡æ³¨æ•°æ®çš„æŒ‘æˆ˜ã€‚ä¸ºäº†åº”å¯¹è¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†KBQA-o1ï¼Œè¿™æ˜¯ä¸€ç§æ–°å‹çš„åŸºäºè’™ç‰¹å¡æ´›æ ‘æœç´¢ï¼ˆMCTSï¼‰çš„æ™ºèƒ½KBQAæ–¹æ³•ã€‚å®ƒå¼•å…¥äº†ä¸€ç§åŸºäºReActçš„ä»£ç†è¿‡ç¨‹ï¼Œç”¨äºé€æ­¥ç”Ÿæˆé€»è¾‘å½¢å¼å¹¶è¿›è¡ŒçŸ¥è¯†åº“ç¯å¢ƒæ¢ç´¢ã€‚æ­¤å¤–ï¼Œå®ƒé‡‡ç”¨MCTSï¼ˆä¸€ç§å—ç­–ç•¥å’Œå¥–åŠ±æ¨¡å‹é©±åŠ¨çš„è‡ªé€‚åº”æœç´¢æ–¹æ³•ï¼‰æ¥å¹³è¡¡æ™ºèƒ½æ¢ç´¢çš„æ€§èƒ½å’Œæœç´¢ç©ºé—´ã€‚é€šè¿‡å¯å‘å¼æ¢ç´¢ï¼ŒKBQA-o1å¯ä»¥ç”Ÿæˆé«˜è´¨é‡æ ‡æ³¨ï¼Œé€šè¿‡å¢é‡å¾®è°ƒè¿›ä¸€æ­¥æ”¹è¿›ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒKBQA-o1ä¼˜äºä¹‹å‰ä½èµ„æºKBQAæ–¹æ³•ï¼Œè¿™äº›æ–¹æ³•ä¾èµ–äºæœ‰é™çš„æ ‡æ³¨æ•°æ®ï¼Œå®ƒä½¿å¾—Llama-3.1-8Bæ¨¡å‹çš„GrailQA F1æ€§èƒ½æå‡åˆ°78.5%ï¼Œè€Œä¹‹å‰æœ€ä½³æ–¹æ³•GPT-3.5-turboçš„è¯¥æŒ‡æ ‡ä¸º48.5%ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.18922v1">PDF</a> Preprint</p>
<p><strong>Summary</strong><br>KBQAç³»ç»Ÿæ—¨åœ¨é€šè¿‡å¤§è§„æ¨¡ç»“æ„åŒ–çŸ¥è¯†åº“å›ç­”è‡ªç„¶è¯­è¨€é—®é¢˜ã€‚ä¸ºåº”å¯¹KBQAçš„æŒ‘æˆ˜ï¼Œå¦‚å¼±çŸ¥è¯†åº“æ„è¯†ã€æ•ˆç‡å’Œæœ‰æ•ˆæ€§ä¹‹é—´çš„ä¸å¹³è¡¡ä»¥åŠé«˜åº¦ä¾èµ–æ ‡æ³¨æ•°æ®çš„é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†KBQA-o1è¿™ä¸€æ–°å‹æ™ºèƒ½ä½“çŸ¥è¯†åº“é—®ç­”æ–¹æ³•ï¼Œç»“åˆè’™ç‰¹å¡æ´›æ ‘æœç´¢ï¼ˆMCTSï¼‰ã€‚å®ƒå¼•å…¥åŸºäºReActçš„æ™ºèƒ½ä½“è¿‡ç¨‹ï¼Œè¿›è¡Œé€æ­¥é€»è¾‘å½¢å¼ç”Ÿæˆå’ŒçŸ¥è¯†åº“ç¯å¢ƒæ¢ç´¢ã€‚æ­¤å¤–ï¼Œåˆ©ç”¨MCTSè¿™ä¸€å—æ”¿ç­–å’Œå¥–åŠ±æ¨¡å‹é©±åŠ¨çš„ç­–ç•¥æ€§æœç´¢æ–¹æ³•ï¼Œå®ç°æ™ºèƒ½ä½“æ¢ç´¢æ€§èƒ½ä¸æœç´¢ç©ºé—´çš„å¹³è¡¡ã€‚é€šè¿‡å¯å‘å¼æ¢ç´¢ï¼ŒKBQA-o1å¯ç”Ÿæˆé«˜è´¨é‡æ ‡æ³¨ç”¨äºè¿›ä¸€æ­¥å¢é‡å¾®è°ƒã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒKBQA-o1åœ¨æœ‰é™æ ‡æ³¨æ•°æ®çš„æƒ…å†µä¸‹ï¼Œä¼˜äºå…ˆå‰ä½èµ„æºKBQAæ–¹æ³•ï¼Œå°†Llama-3.1-8Bæ¨¡å‹çš„GrailQA F1æ€§èƒ½æå‡è‡³78.5%ï¼Œè¿œè¶…å…ˆå‰æœ€ä½³æ–¹æ³•GPT-3.5-turboçš„48.5%ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>KBQAç³»ç»Ÿé€šè¿‡å¤§è§„æ¨¡ç»“æ„åŒ–çŸ¥è¯†åº“å›ç­”è‡ªç„¶è¯­è¨€é—®é¢˜ã€‚</li>
<li>KBQAé¢ä¸´å¼±çŸ¥è¯†åº“æ„è¯†ã€æ•ˆç‡å’Œæœ‰æ•ˆæ€§ä¹‹é—´çš„ä¸å¹³è¡¡ä»¥åŠä¾èµ–æ ‡æ³¨æ•°æ®ç­‰æŒ‘æˆ˜ã€‚</li>
<li>KBQA-o1æ˜¯åº”å¯¹è¿™äº›æŒ‘æˆ˜çš„æ–°å‹æ™ºèƒ½ä½“çŸ¥è¯†åº“é—®ç­”æ–¹æ³•ï¼Œç»“åˆäº†è’™ç‰¹å¡æ´›æ ‘æœç´¢ï¼ˆMCTSï¼‰ã€‚</li>
<li>KBQA-o1é€šè¿‡åŸºäºReActçš„æ™ºèƒ½ä½“è¿‡ç¨‹è¿›è¡Œé€æ­¥é€»è¾‘å½¢å¼ç”Ÿæˆå’ŒçŸ¥è¯†åº“ç¯å¢ƒæ¢ç´¢ã€‚</li>
<li>MCTSå¹³è¡¡äº†æ™ºèƒ½ä½“æ¢ç´¢çš„æ€§èƒ½å’Œæœç´¢ç©ºé—´ã€‚</li>
<li>KBQA-o1èƒ½ç”Ÿæˆé«˜è´¨é‡æ ‡æ³¨ç”¨äºå¢é‡å¾®è°ƒã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.18922">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-f3d588ec96b1eb5ee38958dfa48a9b98.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-eaf997481d34e0a06d1d6109110f86fc.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f613419b707245de6415f437be40c24c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-94d85a678797b37aa1bc87a4bae3f0e4.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-69ba8d082e5d4040e1aa68da06ed3009.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="UP-VLA-A-Unified-Understanding-and-Prediction-Model-for-Embodied-Agent"><a href="#UP-VLA-A-Unified-Understanding-and-Prediction-Model-for-Embodied-Agent" class="headerlink" title="UP-VLA: A Unified Understanding and Prediction Model for Embodied Agent"></a>UP-VLA: A Unified Understanding and Prediction Model for Embodied Agent</h2><p><strong>Authors:Jianke Zhang, Yanjiang Guo, Yucheng Hu, Xiaoyu Chen, Xiang Zhu, Jianyu Chen</strong></p>
<p>Recent advancements in Vision-Language-Action (VLA) models have leveraged pre-trained Vision-Language Models (VLMs) to improve the generalization capabilities. VLMs, typically pre-trained on vision-language understanding tasks, provide rich semantic knowledge and reasoning abilities. However, prior research has shown that VLMs often focus on high-level semantic content and neglect low-level features, limiting their ability to capture detailed spatial information and understand physical dynamics. These aspects, which are crucial for embodied control tasks, remain underexplored in existing pre-training paradigms. In this paper, we investigate the training paradigm for VLAs, and introduce \textbf{UP-VLA}, a \textbf{U}nified VLA model training with both multi-modal \textbf{U}nderstanding and future \textbf{P}rediction objectives, enhancing both high-level semantic comprehension and low-level spatial understanding. Experimental results show that UP-VLA achieves a 33% improvement on the Calvin ABC-D benchmark compared to the previous state-of-the-art method. Additionally, UP-VLA demonstrates improved success rates in real-world manipulation tasks, particularly those requiring precise spatial information. </p>
<blockquote>
<p>æœ€è¿‘ï¼ŒVision-Language-Actionï¼ˆVLAï¼‰æ¨¡å‹çš„è¿›æ­¥åˆ©ç”¨äº†é¢„è®­ç»ƒçš„Vision-Language Modelsï¼ˆVLMsï¼‰æ¥æé«˜æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚é€šå¸¸ï¼ŒVLMsåœ¨è§†è§‰è¯­è¨€ç†è§£ä»»åŠ¡ä¸Šè¿›è¡Œé¢„è®­ç»ƒï¼Œæä¾›äº†ä¸°å¯Œçš„è¯­ä¹‰çŸ¥è¯†å’Œæ¨ç†èƒ½åŠ›ã€‚ç„¶è€Œï¼Œå…ˆå‰çš„ç ”ç©¶è¡¨æ˜ï¼ŒVLMså¾€å¾€å…³æ³¨é«˜çº§è¯­ä¹‰å†…å®¹è€Œå¿½è§†ä½çº§ç‰¹å¾ï¼Œé™åˆ¶äº†å®ƒä»¬åœ¨æ•æ‰è¯¦ç»†çš„ç©ºé—´ä¿¡æ¯å’Œç†è§£ç‰©ç†åŠ¨æ€æ–¹é¢çš„èƒ½åŠ›ã€‚å¯¹äºå®ä½“æ§åˆ¶ä»»åŠ¡æ¥è¯´ï¼Œè¿™äº›æ–¹é¢è‡³å…³é‡è¦ï¼Œä½†åœ¨ç°æœ‰çš„é¢„è®­ç»ƒèŒƒå¼ä¸­ä»ç„¶æ¢ç´¢ä¸è¶³ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬ç ”ç©¶äº†VLAçš„è®­ç»ƒèŒƒå¼ï¼Œå¹¶å¼•å…¥äº†UP-VLAï¼Œè¿™æ˜¯ä¸€ä¸ªç»Ÿä¸€çš„VLAæ¨¡å‹è®­ç»ƒï¼Œå…·æœ‰å¤šæ¨¡å¼ç†è§£ï¼ˆmulti-modal understandingï¼‰å’Œæœªæ¥é¢„æµ‹ï¼ˆfuture predictionï¼‰ç›®æ ‡ï¼Œå¢å¼ºäº†é«˜çº§è¯­ä¹‰ç†è§£å’Œä½çº§ç©ºé—´ç†è§£ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œä¸å…ˆå‰æœ€å…ˆè¿›çš„æ–¹æ³•ç›¸æ¯”ï¼ŒUP-VLAåœ¨Calvin ABC-DåŸºå‡†æµ‹è¯•ä¸Šå®ç°äº†33%çš„æ”¹è¿›ã€‚æ­¤å¤–ï¼ŒUP-VLAåœ¨ç°å®ä¸–ç•Œæ“ä½œä»»åŠ¡ä¸Šçš„æˆåŠŸç‡ä¹Ÿæœ‰æ‰€æé«˜ï¼Œå°¤å…¶æ˜¯é‚£äº›éœ€è¦ç²¾ç¡®ç©ºé—´ä¿¡æ¯çš„ä»»åŠ¡ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.18867v2">PDF</a> </p>
<p><strong>Summary</strong><br>åŸºäºæœ€æ–°è§†è§‰è¯­è¨€åŠ¨ä½œï¼ˆVLAï¼‰æ¨¡å‹çš„è¿›å±•ï¼Œç ”ç©¶å¼•å…¥äº†é¢„è®­ç»ƒè§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMï¼‰ä»¥æå‡æ³›åŒ–èƒ½åŠ›ã€‚ç„¶è€Œï¼Œç°æœ‰ç ”ç©¶æŒ‡å‡ºVLMæ¨¡å‹å¸¸å¸¸å¿½ç•¥ä½å±‚æ¬¡ç‰¹å¾ï¼Œé™åˆ¶äº†æ•æ‰è¯¦ç»†ç©ºé—´ä¿¡æ¯å’Œç†è§£ç‰©ç†åŠ¨æ€çš„èƒ½åŠ›ã€‚æœ¬ç ”ç©¶è°ƒæŸ¥äº†VLAçš„è®­ç»ƒæ¨¡å¼ï¼Œå¹¶æå‡ºäº†ç»Ÿä¸€VLAæ¨¡å‹è®­ç»ƒèŒƒä¾‹UP-VLAï¼Œæ—¨åœ¨æé«˜å¤šæ¨¡æ€ç†è§£ä¸æœªæ¥é¢„æµ‹ç›®æ ‡ï¼Œä»¥å¢å¼ºé«˜å±‚æ¬¡è¯­ä¹‰ç†è§£å’Œä½å±‚æ¬¡ç©ºé—´ç†è§£ã€‚åœ¨Calvin ABC-DåŸºå‡†æµ‹è¯•ä¸­ï¼ŒUP-VLAç›¸æ¯”ä¹‹å‰çš„æ–¹æ³•å–å¾—äº†33%çš„æ”¹è¿›ï¼Œå¹¶åœ¨ç°å®æ“ä½œä»»åŠ¡ä¸­æ˜¾ç¤ºå‡ºæ›´é«˜çš„æˆåŠŸç‡ï¼Œç‰¹åˆ«æ˜¯åœ¨éœ€è¦ç²¾ç¡®ç©ºé—´ä¿¡æ¯çš„ä»»åŠ¡ä¸­ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>VLMsè™½èƒ½æä¾›ä¸°å¯Œçš„è¯­ä¹‰çŸ¥è¯†å’Œæ¨ç†èƒ½åŠ›ï¼Œä½†å¸¸å¸¸å¿½ç•¥ä½å±‚æ¬¡ç‰¹å¾ï¼Œé™åˆ¶äº†ç©ºé—´ä¿¡æ¯å’Œç‰©ç†åŠ¨æ€çš„ç†è§£ã€‚</li>
<li>æœ¬ç ”ç©¶è°ƒæŸ¥äº†VLAæ¨¡å‹çš„è®­ç»ƒèŒƒå¼ï¼Œå¹¶å¼•å…¥äº†UP-VLAæ¨¡å‹ï¼Œè¯¥æ¨¡å‹ç»“åˆäº†å¤šæ¨¡æ€ç†è§£å’Œæœªæ¥é¢„æµ‹ç›®æ ‡ã€‚</li>
<li>UP-VLAæ¨¡å‹æ—¨åœ¨å¢å¼ºé«˜å±‚æ¬¡è¯­ä¹‰ç†è§£å’Œä½å±‚æ¬¡ç©ºé—´ç†è§£ã€‚</li>
<li>åœ¨Calvin ABC-DåŸºå‡†æµ‹è¯•ä¸­ï¼ŒUP-VLAæ¨¡å‹ç›¸æ¯”ä¹‹å‰çš„æ–¹æ³•æœ‰æ˜¾è‘—æ”¹è¿›ã€‚</li>
<li>UP-VLAæ¨¡å‹åœ¨ç°å®æ“ä½œä»»åŠ¡ä¸­è¡¨ç°å‡ºæ›´é«˜çš„æˆåŠŸç‡ï¼Œç‰¹åˆ«æ˜¯åœ¨éœ€è¦ç²¾ç¡®ç©ºé—´ä¿¡æ¯çš„ä»»åŠ¡ä¸­ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.18867">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-d68736e9356b84d4e88f96afab4c48af.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-7c3018d1b33a2c60a22bd069feede1bb.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-48559e3e0d07c1a74fef1c1185645ecb.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-2707d558f22a4073b49954cfd764bc26.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="RepoAudit-An-Autonomous-LLM-Agent-for-Repository-Level-Code-Auditing"><a href="#RepoAudit-An-Autonomous-LLM-Agent-for-Repository-Level-Code-Auditing" class="headerlink" title="RepoAudit: An Autonomous LLM-Agent for Repository-Level Code Auditing"></a>RepoAudit: An Autonomous LLM-Agent for Repository-Level Code Auditing</h2><p><strong>Authors:Jinyao Guo, Chengpeng Wang, Xiangzhe Xu, Zian Su, Xiangyu Zhang</strong></p>
<p>Code auditing is a code review process with the goal of finding bugs. Large Language Models (LLMs) have shown substantial potential in this task, offering the ability to analyze programs without compilation and enabling customized bug detection following specified prompts. However, applying LLMs to repository-level code auditing presents notable challenges. The inherent context limits and hallucinations of LLMs can lead to the low quality of bug reports. Meanwhile, the large size of software repositories introduces substantial time and token costs, hindering efficiency and scalability in real-world scenarios. This work introduces an autonomous LLM-agent, RepoAudit, designed to enable precise and efficient repository-level code auditing. Equipped with the agent memory, RepoAudit explores the code repository on demand, analyzing data-flow facts along different feasible program paths in individual functions. It also introduces the validator to check the data-flow facts for hallucination mitigation and examine the satisfiability of path conditions of potential buggy paths, which enables RepoAudit to discard false positives in the code auditing. Our experiment shows that RepoAudit powered by Claude 3.5 Sonnet successfully finds 38 true bugs in 15 real-world systems, consuming 0.44 hours and $2.54 per project on average. </p>
<blockquote>
<p>ä»£ç å®¡è®¡æ˜¯ä¸€ç§å¯»æ‰¾é”™è¯¯çš„ä»£ç å®¡æŸ¥è¿‡ç¨‹ã€‚å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨è¿™ä¸€ä»»åŠ¡ä¸­è¡¨ç°å‡ºäº†å·¨å¤§çš„æ½œåŠ›ï¼Œå®ƒä»¬èƒ½å¤Ÿåœ¨ä¸ç¼–è¯‘çš„æƒ…å†µä¸‹åˆ†æç¨‹åºï¼Œå¹¶æ ¹æ®ç‰¹å®šæç¤ºè¿›è¡Œå®šåˆ¶åŒ–çš„é”™è¯¯æ£€æµ‹ã€‚ç„¶è€Œï¼Œå°†LLMåº”ç”¨äºä»“åº“çº§åˆ«çš„ä»£ç å®¡è®¡å­˜åœ¨æ˜¾è‘—çš„æŒ‘æˆ˜ã€‚LLMçš„å›ºæœ‰ä¸Šä¸‹æ–‡é™åˆ¶å’Œå¹»è§‰å¯èƒ½å¯¼è‡´é”™è¯¯æŠ¥å‘Šçš„è´¨é‡ä½ä¸‹ã€‚åŒæ—¶ï¼Œè½¯ä»¶ä»“åº“çš„å¤§è§„æ¨¡æ€§å¼•å…¥äº†å¤§é‡çš„æ—¶é—´å’Œä»¤ç‰Œæˆæœ¬ï¼Œé˜»ç¢äº†ç°å®ä¸–ç•Œåœºæ™¯ä¸­çš„æ•ˆç‡å’Œå¯æ‰©å±•æ€§ã€‚è¿™é¡¹å·¥ä½œå¼•å…¥äº†ä¸€ä¸ªè‡ªä¸»çš„è¯­è¨€æ¨¡å‹ä»£ç†RepoAuditï¼Œæ—¨åœ¨å®ç°ç²¾ç¡®é«˜æ•ˆçš„ä»“åº“çº§ä»£ç å®¡è®¡ã€‚é…å¤‡æœ‰ä»£ç†å†…å­˜çš„RepoAuditæŒ‰éœ€æ¢ç´¢ä»£ç ä»“åº“ï¼Œåˆ†æå•ä¸ªå‡½æ•°ä¸­ä¸åŒå¯è¡Œç¨‹åºè·¯å¾„çš„æ•°æ®æµäº‹å®ã€‚å®ƒè¿˜å¼•å…¥äº†éªŒè¯å™¨ï¼Œä»¥å‡è½»å¹»è§‰å¹¶æ£€æŸ¥æ•°æ®æµäº‹å®ï¼Œå¹¶æ£€æŸ¥æ½œåœ¨é”™è¯¯è·¯å¾„çš„è·¯å¾„æ¡ä»¶çš„å¯æ»¡è¶³æ€§ï¼Œè¿™ä½¿å¾—RepoAuditèƒ½å¤Ÿåœ¨ä»£ç å®¡è®¡ä¸­å‰”é™¤è¯¯æŠ¥ã€‚æˆ‘ä»¬çš„å®éªŒè¡¨æ˜ï¼Œç”±Claude 3.5 Sonneté©±åŠ¨çš„RepoAuditæˆåŠŸåœ¨15ä¸ªçœŸå®ç³»ç»Ÿä¸­æ‰¾åˆ°äº†38ä¸ªçœŸå®é”™è¯¯ï¼Œå¹³å‡æ¯ä¸ªé¡¹ç›®æ¶ˆè€—0.44å°æ—¶å’Œ2.54ç¾å…ƒã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.18160v2">PDF</a> 19 pages, 8 tables, 5 figures, 3 listings</p>
<p><strong>Summary</strong></p>
<p>ä»£ç å®¡è®¡æ—¨åœ¨å‘ç°é”™è¯¯ï¼Œå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨æ­¤ä»»åŠ¡ä¸­æ˜¾ç¤ºå‡ºå·¨å¤§æ½œåŠ›ï¼Œå¯åˆ†æç¨‹åºè€Œæ— éœ€ç¼–è¯‘ï¼Œå¹¶èƒ½æ ¹æ®ç‰¹å®šæç¤ºè¿›è¡Œå®šåˆ¶åŒ–çš„é”™è¯¯æ£€æµ‹ã€‚ç„¶è€Œï¼Œå°†LLMåº”ç”¨äºä»“åº“çº§ä»£ç å®¡è®¡å­˜åœ¨æŒ‘æˆ˜ã€‚LLMçš„å›ºæœ‰ä¸Šä¸‹æ–‡é™åˆ¶å’Œå¹»æƒ³å¯èƒ½å¯¼è‡´é”™è¯¯æŠ¥å‘Šè´¨é‡ä½ä¸‹ã€‚åŒæ—¶ï¼Œè½¯ä»¶ä»“åº“çš„å¤§è§„æ¨¡å¼•å…¥äº†å¤§é‡æ—¶é—´å’Œä»¤ç‰Œæˆæœ¬ï¼Œé˜»ç¢äº†ç°å®ä¸–ç•Œåœºæ™¯ä¸­çš„æ•ˆç‡å’Œå¯æ‰©å±•æ€§ã€‚æœ¬ç ”ç©¶å¼•å…¥äº†ä¸€ç§è‡ªä¸»LLMä»£ç†RepoAuditï¼Œæ—¨åœ¨å®ç°ç²¾ç¡®é«˜æ•ˆçš„ä»“åº“çº§ä»£ç å®¡è®¡ã€‚RepoAudité…å¤‡äº†ä»£ç†å†…å­˜ï¼Œå¯æŒ‰éœ€æ¢ç´¢ä»£ç ä»“åº“ï¼Œåˆ†æå•ä¸ªå‡½æ•°ä¸­ä¸åŒå¯è¡Œç¨‹åºè·¯å¾„çš„æ•°æ®æµäº‹å®ã€‚å®ƒè¿˜å¼•å…¥äº†éªŒè¯å™¨ï¼Œä»¥å‡è½»å¹»æƒ³å¹¶æ£€æŸ¥æ•°æ®æµäº‹å®ï¼Œå¹¶æ£€æŸ¥æ½œåœ¨é”™è¯¯è·¯å¾„çš„æ»¡è¶³æ€§ï¼Œä½¿RepoAuditèƒ½å¤Ÿåœ¨ä»£ç å®¡è®¡ä¸­å‰”é™¤è¯¯æŠ¥ã€‚å®éªŒè¡¨æ˜ï¼Œç”±Claude 3.5 Sonneté©±åŠ¨çš„RepoAuditæˆåŠŸåœ¨15ä¸ªçœŸå®ç³»ç»Ÿä¸­æ‰¾åˆ°38ä¸ªçœŸå®é”™è¯¯ï¼Œå¹³å‡æ¯ä¸ªé¡¹ç›®æ¶ˆè€—0.44å°æ—¶å’Œ2.54ç¾å…ƒã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ä»£ç å®¡è®¡ç›®æ ‡æ˜¯å‘ç°é”™è¯¯ï¼Œå¤§å‹è¯­è¨€æ¨¡å‹åœ¨æ­¤ä»»åŠ¡ä¸­æ˜¾ç¤ºå‡ºæ½œåŠ›ã€‚</li>
<li>LLMåº”ç”¨äºä»“åº“çº§ä»£ç å®¡è®¡å­˜åœ¨æŒ‘æˆ˜ï¼Œå¦‚ä¸Šä¸‹æ–‡é™åˆ¶å’Œå¹»æƒ³é—®é¢˜ã€‚</li>
<li>RepoAuditæ˜¯ä¸€ä¸ªè‡ªä¸»LLMä»£ç†ï¼Œå¯å®ç°ç²¾ç¡®é«˜æ•ˆçš„ä»“åº“çº§ä»£ç å®¡è®¡ã€‚</li>
<li>RepoAudité…å¤‡äº†ä»£ç†å†…å­˜ï¼Œå¯æŒ‰éœ€æ¢ç´¢ä»£ç ä»“åº“ï¼Œå¹¶åˆ†ææ•°æ®æµäº‹å®ã€‚</li>
<li>éªŒè¯å™¨çš„å¼•å…¥ç”¨äºæ£€æŸ¥æ•°æ®æµäº‹å®å¹¶å‡å°‘å¹»æƒ³ï¼ŒåŒæ—¶æ£€æŸ¥æ½œåœ¨é”™è¯¯è·¯å¾„çš„æ»¡è¶³æ€§ã€‚</li>
<li>å®éªŒæ˜¾ç¤ºRepoAuditæˆåŠŸåœ¨å¤šä¸ªçœŸå®ç³»ç»Ÿä¸­å‘ç°çœŸå®é”™è¯¯ï¼Œä¸”æ•ˆç‡è¾ƒé«˜ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.18160">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-19b0901ae3271e79208026b5578aa8aa.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a3c5cf8733e2ffc7645a20994d7c9034.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b444555ee30ab25234be1035ab2fb62e.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-cba0fe6becab38b01c669d770b1bedb9.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="B3C-A-Minimalist-Approach-to-Offline-Multi-Agent-Reinforcement-Learning"><a href="#B3C-A-Minimalist-Approach-to-Offline-Multi-Agent-Reinforcement-Learning" class="headerlink" title="B3C: A Minimalist Approach to Offline Multi-Agent Reinforcement Learning"></a>B3C: A Minimalist Approach to Offline Multi-Agent Reinforcement Learning</h2><p><strong>Authors:Woojun Kim, Katia Sycara</strong></p>
<p>Overestimation arising from selecting unseen actions during policy evaluation is a major challenge in offline reinforcement learning (RL). A minimalist approach in the single-agent setting â€“ adding behavior cloning (BC) regularization to existing online RL algorithms â€“ has been shown to be effective; however, this approach is understudied in multi-agent settings. In particular, overestimation becomes worse in multi-agent settings due to the presence of multiple actions, resulting in the BC regularization-based approach easily suffering from either over-regularization or critic divergence. To address this, we propose a simple yet effective method, Behavior Cloning regularization with Critic Clipping (B3C), which clips the target critic value in policy evaluation based on the maximum return in the dataset and pushes the limit of the weight on the RL objective over BC regularization, thereby improving performance. Additionally, we leverage existing value factorization techniques, particularly non-linear factorization, which is understudied in offline settings. Integrated with non-linear value factorization, B3C outperforms state-of-the-art algorithms on various offline multi-agent benchmarks. </p>
<blockquote>
<p>åœ¨ç¦»çº¿å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰ä¸­ï¼Œç”±äºåœ¨ç­–ç•¥è¯„ä¼°æ—¶é€‰æ‹©æœªè§‚å¯Ÿåˆ°çš„åŠ¨ä½œè€Œå¯¼è‡´çš„è¿‡åº¦ä¼°è®¡æ˜¯ä¸»è¦æŒ‘æˆ˜ã€‚åœ¨å•æ™ºèƒ½ä½“ç¯å¢ƒä¸­ï¼Œä¸€ç§æç®€ä¸»ä¹‰çš„æ–¹æ³•â€”â€”å‘ç°æœ‰çš„åœ¨çº¿RLç®—æ³•æ·»åŠ è¡Œä¸ºå…‹éš†ï¼ˆBCï¼‰æ­£åˆ™åŒ–å·²è¢«è¯æ˜æ˜¯æœ‰æ•ˆçš„ï¼›ç„¶è€Œï¼Œåœ¨å¤šæ™ºèƒ½ä½“ç¯å¢ƒä¸­ï¼Œè¿™ç§æ–¹æ³•çš„ç ”ç©¶è¿˜ä¸å¤Ÿã€‚ç‰¹åˆ«æ˜¯åœ¨å¤šæ™ºèƒ½ä½“ç¯å¢ƒä¸­ï¼Œç”±äºå­˜åœ¨å¤šç§åŠ¨ä½œï¼Œè¿‡åº¦ä¼°è®¡çš„æƒ…å†µå˜å¾—æ›´ç³Ÿï¼Œå¯¼è‡´åŸºäºBCæ­£åˆ™åŒ–çš„æ–¹æ³•å¾ˆå®¹æ˜“å—åˆ°è¿‡åº¦æ­£åˆ™åŒ–æˆ–è¯„è®ºå®¶å‘æ•£çš„å½±å“ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§ç®€å•æœ‰æ•ˆçš„æ–¹æ³•ï¼Œå³å¸¦æœ‰è¯„è®ºå®¶è£å‰ªçš„è¡Œä¸ºå…‹éš†æ­£åˆ™åŒ–ï¼ˆB3Cï¼‰ï¼Œè¯¥æ–¹æ³•åŸºäºæ•°æ®é›†çš„æœ€å¤§å›æŠ¥æ¥è£å‰ªç›®æ ‡è¯„è®ºå®¶å€¼ï¼Œå¹¶æé«˜äº†åœ¨ç­–ç•¥è¯„ä¼°ä¸­RLç›®æ ‡ä¸Šæƒé‡çš„é™åˆ¶ï¼Œä»è€Œæé«˜äº†æ€§èƒ½ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬åˆ©ç”¨ç°æœ‰çš„å€¼åˆ†è§£æŠ€æœ¯ï¼Œç‰¹åˆ«æ˜¯åœ¨ç¦»çº¿ç¯å¢ƒä¸­å°šæœªå……åˆ†ç ”ç©¶çš„éçº¿æ€§åˆ†è§£æŠ€æœ¯ã€‚ä¸éçº¿æ€§å€¼åˆ†è§£ç›¸ç»“åˆï¼ŒB3Cåœ¨å„ç§ç¦»çº¿å¤šæ™ºèƒ½ä½“åŸºå‡†æµ‹è¯•ä¸Šä¼˜äºæœ€æ–°ç®—æ³•ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.18138v2">PDF</a> </p>
<p><strong>æ€»ç»“</strong></p>
<p>ç¦»çº¿å¼ºåŒ–å­¦ä¹ ä¸­çš„ä¸»è¦æŒ‘æˆ˜åœ¨äºé€‰æ‹©æœªçŸ¥åŠ¨ä½œæ—¶äº§ç”Ÿçš„è¿‡ä¼°è®¡é—®é¢˜ã€‚åœ¨å•æ™ºèƒ½ä½“ç¯å¢ƒä¸­ï¼Œé€šè¿‡å‘ç°æœ‰åœ¨çº¿å¼ºåŒ–å­¦ä¹ ç®—æ³•æ·»åŠ è¡Œä¸ºå…‹éš†ï¼ˆBCï¼‰æ­£åˆ™åŒ–è¿™ç§æç®€æ–¹æ¡ˆå·²è¢«è¯æ˜æ˜¯æœ‰æ•ˆçš„ã€‚ç„¶è€Œï¼Œåœ¨å¤šæ™ºèƒ½ä½“ç¯å¢ƒä¸­ï¼Œè¯¥æ–¹æ¡ˆçš„ç ”ç©¶ç›¸å¯¹è¾ƒå°‘ã€‚ç‰¹åˆ«æ˜¯ç”±äºå­˜åœ¨å¤šä¸ªåŠ¨ä½œï¼Œè¿‡ä¼°è®¡é—®é¢˜åœ¨å¤šæ™ºèƒ½ä½“ç¯å¢ƒä¸­å˜å¾—æ›´åŠ ä¸¥é‡ï¼Œå¯¼è‡´åŸºäºBCæ­£åˆ™åŒ–çš„æ–¹æ³•å®¹æ˜“é­å—è¿‡åº¦æ­£åˆ™åŒ–æˆ–è¯„è®ºå®¶å‘æ•£çš„é—®é¢˜ã€‚ä¸ºè§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§ç®€å•æœ‰æ•ˆçš„æ–¹æ³•â€”â€”è¡Œä¸ºå…‹éš†æ­£åˆ™åŒ–ä¸è¯„è®ºå®¶è£å‰ªï¼ˆB3Cï¼‰ã€‚è¯¥æ–¹æ³•åŸºäºæ•°æ®é›†çš„æœ€å¤§å›æŠ¥æ¥è£å‰ªç›®æ ‡è¯„è®ºå®¶å€¼ï¼Œå¹¶åœ¨æ”¿ç­–è¯„ä¼°ä¸­æ”¹è¿›æ€§èƒ½ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬åˆ©ç”¨ç°æœ‰çš„ä»·å€¼åˆ†è§£æŠ€æœ¯ï¼Œç‰¹åˆ«æ˜¯ç¦»çº¿ç¯å¢ƒä¸­ç ”ç©¶è¾ƒå°‘çš„éçº¿æ€§åˆ†è§£æŠ€æœ¯ã€‚ç»“åˆéçº¿æ€§ä»·å€¼åˆ†è§£ï¼ŒB3Cåœ¨å¤šç§ç¦»çº¿å¤šæ™ºèƒ½ä½“åŸºå‡†æµ‹è¯•ä¸Šè¶…è¶Šäº†ç°æœ‰ç®—æ³•ã€‚</p>
<p><strong>å…³é”®è§è§£</strong></p>
<ol>
<li>ç¦»çº¿å¼ºåŒ–å­¦ä¹ é¢ä¸´çš„ä¸»è¦æŒ‘æˆ˜æ˜¯é€‰æ‹©æœªçŸ¥åŠ¨ä½œæ—¶å¯¼è‡´çš„è¿‡ä¼°è®¡é—®é¢˜ã€‚</li>
<li>åœ¨å¤šæ™ºèƒ½ä½“ç¯å¢ƒä¸­ï¼Œç”±äºå¤šä¸ªåŠ¨ä½œçš„å­˜åœ¨ï¼Œè¿‡ä¼°è®¡é—®é¢˜å˜å¾—æ›´åŠ ä¸¥é‡ã€‚</li>
<li>è¡Œä¸ºå…‹éš†ï¼ˆBCï¼‰æ­£åˆ™åŒ–æ˜¯ä¸€ç§æœ‰æ•ˆçš„å•æ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ ä¼˜åŒ–æ–¹æ³•ï¼Œä½†åœ¨å¤šæ™ºèƒ½ä½“ç¯å¢ƒä¸­å…¶æ•ˆæœæœ‰å¾…æé«˜ã€‚</li>
<li>è¡Œä¸ºå…‹éš†æ­£åˆ™åŒ–ä¸è¯„è®ºå®¶è£å‰ªï¼ˆB3Cï¼‰æ–¹æ³•æ—¨åœ¨è§£å†³å¤šæ™ºèƒ½ä½“ç¯å¢ƒä¸­çš„è¿‡ä¼°è®¡é—®é¢˜ï¼Œé€šè¿‡è£å‰ªç›®æ ‡è¯„è®ºå®¶å€¼æ¥æ”¹å–„æ€§èƒ½ã€‚</li>
<li>B3Cæ–¹æ³•ç»“åˆäº†éçº¿æ€§ä»·å€¼åˆ†è§£æŠ€æœ¯ï¼Œä»¥æé«˜åœ¨ç¦»çº¿å¤šæ™ºèƒ½ä½“ç¯å¢ƒä¸­çš„æ€§èƒ½ã€‚</li>
<li>B3Cåœ¨å„ç§ç¦»çº¿å¤šæ™ºèƒ½ä½“åŸºå‡†æµ‹è¯•ä¸Šçš„è¡¨ç°è¶…è¶Šäº†ç°æœ‰ç®—æ³•ã€‚</li>
<li>è¯¥ç ”ç©¶ä¸ºå¤šæ™ºèƒ½ä½“ç¦»çº¿å¼ºåŒ–å­¦ä¹ æä¾›äº†ä¸€ä¸ªæ–°çš„ã€æœ‰æ•ˆçš„è§£å†³æ–¹æ¡ˆã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.18138">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-0faaace700df26cb9d78f3117ac40ad9.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-a5805cf636a2823ed774b902936a2fad.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-1ef52ff26a04fe0ec706b837184daf39.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-76f0c5ef7e22dbb2d45ce72e6a1ce532.jpg" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="Fortran2CPP-Automating-Fortran-to-C-Translation-using-LLMs-via-Multi-Turn-Dialogue-and-Dual-Agent-Integration"><a href="#Fortran2CPP-Automating-Fortran-to-C-Translation-using-LLMs-via-Multi-Turn-Dialogue-and-Dual-Agent-Integration" class="headerlink" title="Fortran2CPP: Automating Fortran-to-C++ Translation using LLMs via   Multi-Turn Dialogue and Dual-Agent Integration"></a>Fortran2CPP: Automating Fortran-to-C++ Translation using LLMs via   Multi-Turn Dialogue and Dual-Agent Integration</h2><p><strong>Authors:Le Chen, Bin Lei, Dunzhi Zhou, Pei-Hung Lin, Chunhua Liao, Caiwen Ding, Ali Jannesari</strong></p>
<p>Translating legacy Fortran code into C++ is a crucial step in modernizing high-performance computing (HPC) applications. However, the scarcity of high-quality, parallel Fortran-to-C++ datasets and the limited domain-specific expertise in large language models (LLMs) present significant challenges for automated translation. In this paper, we introduce Fortran2CPP, a multi-turn dialogue dataset generated by a novel LLM agent-based approach that integrates a dual-LLM Questioner-Solver module to enhance translation accuracy. Our dataset comprises 11.7k dialogues capturing iterative feedback-decision workflows including code translation, compilation, execution, unit testing, and error-fixing. Using this dataset, we fine-tune several open-weight LLMs and achieve up to a 3.31x improvement in CodeBLEU scores and a 92% increase in compilation success rate, demonstrating enhanced syntactic accuracy and functional reliability. Our findings highlight the value of dialogue-based LLM training for complex code translation tasks. The dataset and model have been open-sourced and are available on our public GitHub repository\footnote{\url{<a target="_blank" rel="noopener" href="https://github.com/HPC-Fortran2CPP/Fortran2Cpp%7D%7D">https://github.com/HPC-Fortran2CPP/Fortran2Cpp}}</a>. </p>
<blockquote>
<p>å°†ä¼ ç»ŸFortranä»£ç è½¬æ¢ä¸ºC++ä»£ç æ˜¯ç°ä»£é«˜æ€§èƒ½è®¡ç®—ï¼ˆHPCï¼‰åº”ç”¨ç°ä»£åŒ–è¿‡ç¨‹ä¸­çš„å…³é”®æ­¥éª¤ã€‚ç„¶è€Œï¼Œé«˜è´¨é‡å¹¶è¡ŒFortranåˆ°C++æ•°æ®é›†ç¼ºä¹ä»¥åŠå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä¸­ç‰¹å®šé¢†åŸŸçš„ä¸“ä¸šçŸ¥è¯†æœ‰é™ï¼Œç»™è‡ªåŠ¨åŒ–ç¿»è¯‘å¸¦æ¥äº†é‡å¤§æŒ‘æˆ˜ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬ä»‹ç»äº†Fortran2CPPï¼Œè¿™æ˜¯ä¸€ä¸ªé€šè¿‡åŸºäºæ–°å‹LLMä»£ç†çš„æ–¹æ³•ç”Ÿæˆçš„å¤šè½®å¯¹è¯æ•°æ®é›†ï¼Œé›†æˆäº†åŒLLMé—®ç­”è§£å†³æ¨¡å—ï¼Œä»¥æé«˜ç¿»è¯‘å‡†ç¡®æ€§ã€‚æˆ‘ä»¬çš„æ•°æ®é›†åŒ…å«11.7kä¸ªå¯¹è¯ï¼Œæ•æ‰äº†åŒ…æ‹¬ä»£ç ç¿»è¯‘ã€ç¼–è¯‘ã€æ‰§è¡Œã€å•å…ƒæµ‹è¯•å’Œé”™è¯¯ä¿®å¤åœ¨å†…çš„è¿­ä»£åé¦ˆå†³ç­–å·¥ä½œæµç¨‹ã€‚ä½¿ç”¨è¯¥æ•°æ®é›†ï¼Œæˆ‘ä»¬å¯¹å‡ ä¸ªå¼€æºLLMè¿›è¡Œäº†å¾®è°ƒï¼Œå®ç°äº†é«˜è¾¾3.31å€çš„CodeBLEUå¾—åˆ†æå‡å’Œ92%çš„ç¼–è¯‘æˆåŠŸç‡æå‡ï¼Œè¯æ˜äº†å…¶åœ¨è¯­æ³•å‡†ç¡®æ€§å’ŒåŠŸèƒ½å¯é æ€§æ–¹é¢çš„æå‡ã€‚æˆ‘ä»¬çš„ç ”ç©¶çªå‡ºäº†åŸºäºå¯¹è¯çš„LLMè®­ç»ƒåœ¨å¤æ‚ä»£ç ç¿»è¯‘ä»»åŠ¡ä¸­çš„ä»·å€¼ã€‚æ•°æ®é›†å’Œæ¨¡å‹å·²å¼€æºï¼Œå¯åœ¨æˆ‘ä»¬çš„GitHubå…¬å…±å­˜å‚¨åº“ä¸­æ‰¾åˆ°ï¼ˆ<a target="_blank" rel="noopener" href="https://github.com/HPC-Fortran2CPP/Fortran2Cpp%EF%BC%89%E3%80%82">https://github.com/HPC-Fortran2CPP/Fortran2Cppï¼‰ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.19770v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†å°†æ—§ç‰ˆFortranä»£ç ç¿»è¯‘æˆC++çš„é‡è¦æ€§ï¼Œå¹¶æŒ‡å‡ºç”±äºç¼ºä¹é«˜è´¨é‡å¹¶è¡ŒFortranåˆ°C++çš„æ•°æ®é›†ä»¥åŠå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„ç‰¹å®šé¢†åŸŸä¸“ä¸šçŸ¥è¯†æ‰€å¸¦æ¥çš„æŒ‘æˆ˜ã€‚ä¸ºæ­¤ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºå¤šè½®å¯¹è¯çš„æ–°æ–¹æ³•Fortran2CPPï¼Œè¯¥æ–¹æ³•é›†æˆäº†åŒLLMé—®ç­”è§£å†³æ¨¡å—ä»¥æé«˜ç¿»è¯‘å‡†ç¡®æ€§ã€‚æ•°æ®é›†åŒ…å«æ•è·è¿­ä»£åé¦ˆå†³ç­–å·¥ä½œæµçš„å¯¹è¯ï¼ŒåŒ…æ‹¬ä»£ç ç¿»è¯‘ã€ç¼–è¯‘ã€æ‰§è¡Œã€å•å…ƒæµ‹è¯•å’Œé”™è¯¯ä¿®å¤ã€‚ä½¿ç”¨æ­¤æ•°æ®é›†å¾®è°ƒå¼€æ”¾æƒé‡LLMï¼Œå¯æé«˜ä»£ç BLEUå¾—åˆ†å¹¶å¢åŠ ç¼–è¯‘æˆåŠŸç‡ï¼Œæ˜¾ç¤ºå‡ºå¢å¼ºçš„è¯­æ³•å‡†ç¡®æ€§å’ŒåŠŸèƒ½å¯é æ€§ã€‚ç ”ç©¶ç»“æœè¡¨æ˜å¯¹è¯å¼LLMè®­ç»ƒå¯¹äºå¤æ‚çš„ä»£ç ç¿»è¯‘ä»»åŠ¡çš„ä»·å€¼ã€‚æ•°æ®é›†å’Œæ¨¡å‹å·²å¼€æºï¼Œå¯åœ¨å…¬å…±GitHubå­˜å‚¨åº“ä¸­æ‰¾åˆ°ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>Fortranä»£ç å‘C++çš„è½¬æ¢æ˜¯é«˜æ€§èƒ½è®¡ç®—åº”ç”¨ç°ä»£åŒ–çš„é‡è¦æ­¥éª¤ã€‚</li>
<li>ç¼ºä¹é«˜è´¨é‡å¹¶è¡ŒFortranåˆ°C++çš„æ•°æ®é›†ä»¥åŠå¤§å‹è¯­è¨€æ¨¡å‹çš„ç‰¹å®šé¢†åŸŸä¸“ä¸šçŸ¥è¯†ç»™è‡ªåŠ¨åŒ–ç¿»è¯‘å¸¦æ¥äº†æŒ‘æˆ˜ã€‚</li>
<li>ä»‹ç»äº†Fortran2CPPæ–¹æ³•ï¼Œè¿™æ˜¯ä¸€ç§åŸºäºå¤šè½®å¯¹è¯çš„æ–¹æ³•ï¼Œé›†æˆäº†åŒLLMé—®ç­”è§£å†³æ¨¡å—ä»¥æé«˜ç¿»è¯‘å‡†ç¡®æ€§ã€‚</li>
<li>Fortran2CPPæ•°æ®é›†åŒ…å«ç”¨äºä»£ç ç¿»è¯‘ä»»åŠ¡çš„è¿­ä»£åé¦ˆå†³ç­–å·¥ä½œæµå¯¹è¯ã€‚</li>
<li>ä½¿ç”¨æ­¤æ•°æ®é›†å¯¹å¼€æ”¾æƒé‡LLMè¿›è¡Œå¾®è°ƒï¼Œæé«˜äº†è¯­æ³•å‡†ç¡®æ€§å’ŒåŠŸèƒ½å¯é æ€§ã€‚</li>
<li>Fortran2CPPæ–¹æ³•å®ç°äº†é«˜è¾¾3.31å€çš„ä»£ç BLEUå¾—åˆ†æ”¹è¿›å’Œ92%çš„ç¼–è¯‘æˆåŠŸç‡å¢åŠ ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.19770">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-5f4ca5ae820d1405e3f7f4ca095f44ac.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ae68d02bd8067997f177146114fe19f1.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-8227e17589f566c7495106653c0af8f7.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-7bebac2fa21a7f930132a5aa05ebb3bb.jpg" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1><h2 id="Multi-modal-Agent-Tuning-Building-a-VLM-Driven-Agent-for-Efficient-Tool-Usage"><a href="#Multi-modal-Agent-Tuning-Building-a-VLM-Driven-Agent-for-Efficient-Tool-Usage" class="headerlink" title="Multi-modal Agent Tuning: Building a VLM-Driven Agent for Efficient Tool   Usage"></a>Multi-modal Agent Tuning: Building a VLM-Driven Agent for Efficient Tool   Usage</h2><p><strong>Authors:Zhi Gao, Bofei Zhang, Pengxiang Li, Xiaojian Ma, Tao Yuan, Yue Fan, Yuwei Wu, Yunde Jia, Song-Chun Zhu, Qing Li</strong></p>
<p>The advancement of large language models (LLMs) prompts the development of multi-modal agents, which are used as a controller to call external tools, providing a feasible way to solve practical tasks. In this paper, we propose a multi-modal agent tuning method that automatically generates multi-modal tool-usage data and tunes a vision-language model (VLM) as the controller for powerful tool-usage reasoning. To preserve the data quality, we prompt the GPT-4o mini model to generate queries, files, and trajectories, followed by query-file and trajectory verifiers. Based on the data synthesis pipeline, we collect the MM-Traj dataset that contains 20K tasks with trajectories of tool usage. Then, we develop the T3-Agent via \underline{T}rajectory \underline{T}uning on VLMs for \underline{T}ool usage using MM-Traj. Evaluations on the GTA and GAIA benchmarks show that the T3-Agent consistently achieves improvements on two popular VLMs: MiniCPM-V-8.5B and {Qwen2-VL-7B}, which outperforms untrained VLMs by $20%$, showing the effectiveness of the proposed data synthesis pipeline, leading to high-quality data for tool-usage capabilities. </p>
<blockquote>
<p>éšç€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„è¿›å±•ï¼Œå¤šæ¨¡æ€ä»£ç†çš„å‘å±•å¾—åˆ°äº†æ¨åŠ¨ï¼Œè¿™äº›ä»£ç†è¢«ç”¨ä½œæ§åˆ¶å™¨æ¥è°ƒç”¨å¤–éƒ¨å·¥å…·ï¼Œä¸ºè§£å†³å®é™…ä»»åŠ¡æä¾›äº†å¯è¡Œçš„æ–¹æ³•ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§å¤šæ¨¡æ€ä»£ç†è°ƒæ•´æ–¹æ³•ï¼Œè¯¥æ–¹æ³•å¯è‡ªåŠ¨ç”Ÿæˆå¤šæ¨¡æ€å·¥å…·ä½¿ç”¨æ•°æ®ï¼Œå¹¶è°ƒæ•´è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMï¼‰ä½œä¸ºæ§åˆ¶å™¨ï¼Œä»¥å®ç°å¼ºå¤§çš„å·¥å…·ä½¿ç”¨æ¨ç†ã€‚ä¸ºäº†ä¿æŒæ•°æ®è´¨é‡ï¼Œæˆ‘ä»¬æç¤ºGPT-4oå°å‹æ¨¡å‹ç”ŸæˆæŸ¥è¯¢ã€æ–‡ä»¶å’Œè½¨è¿¹ï¼Œéšåè¿›è¡ŒæŸ¥è¯¢æ–‡ä»¶éªŒè¯å™¨å’Œè½¨è¿¹éªŒè¯å™¨ã€‚åŸºäºæ•°æ®åˆæˆç®¡é“ï¼Œæˆ‘ä»¬æ”¶é›†äº†åŒ…å«2ä¸‡ä¸ªä»»åŠ¡ä½¿ç”¨è½¨è¿¹çš„MM-Trajæ•°æ®é›†ã€‚ç„¶åï¼Œæˆ‘ä»¬é€šè¿‡ä½¿ç”¨MM-Trajçš„è½¨è¿¹è°ƒæ•´VLMæ¥å¼€å‘T3ä»£ç†ã€‚åœ¨GTAå’ŒGAIAåŸºå‡†æµ‹è¯•ä¸Šçš„è¯„ä¼°è¡¨æ˜ï¼ŒT3ä»£ç†åœ¨ä¸¤æ¬¾æµè¡Œçš„VLMï¼ˆMiniCPM-V-8.5Bå’ŒQwen2-VL-7Bï¼‰ä¸Šå‡å®ç°äº†æŒç»­æ”¹è¿›ï¼Œå…¶æ€§èƒ½æ¯”æœªè®­ç»ƒçš„VLMé«˜å‡º20%ï¼Œè¯æ˜äº†æ‰€æå‡ºçš„æ•°æ®åˆæˆç®¡é“çš„æœ‰æ•ˆæ€§ï¼Œä¸ºå·¥å…·ä½¿ç”¨èƒ½åŠ›æä¾›äº†é«˜è´¨é‡çš„æ•°æ®ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.15606v2">PDF</a> ICLR 2025, <a target="_blank" rel="noopener" href="https://mat-agent.github.io/">https://mat-agent.github.io/</a></p>
<p><strong>Summary</strong></p>
<p>å¤§å‹è¯­è¨€æ¨¡å‹çš„è¿›æ­¥æ¨åŠ¨äº†å¤šæ¨¡æ€ä»£ç†çš„å‘å±•ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§å¤šæ¨¡æ€ä»£ç†è°ƒèŠ‚æ–¹æ³•ï¼Œè¯¥æ–¹æ³•å¯è‡ªåŠ¨ç”Ÿæˆå¤šæ¨¡æ€å·¥å…·ä½¿ç”¨æ•°æ®ï¼Œå¹¶è°ƒèŠ‚è§†è§‰è¯­è¨€æ¨¡å‹ä½œä¸ºæ§åˆ¶å™¨æ¥è¿›è¡Œå·¥å…·ä½¿ç”¨æ¨ç†ã€‚é€šè¿‡æ•°æ®åˆæˆç®¡é“ï¼Œæˆ‘ä»¬æ”¶é›†äº†MM-Trajæ•°æ®é›†ï¼Œå¹¶åœ¨æ­¤åŸºç¡€ä¸Šå¼€å‘äº†T3-Agentã€‚è¯„ä¼°è¡¨æ˜ï¼ŒT3-Agentåœ¨ä¸¤ç§æµè¡Œçš„VLMä¸Šå®ç°äº†æ”¹è¿›ï¼Œå¹¶ä¼˜äºæœªè®­ç»ƒçš„VLMï¼Œè¯æ˜äº†æ•°æ®åˆæˆç®¡é“çš„æœ‰æ•ˆæ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤§å‹è¯­è¨€æ¨¡å‹çš„è¿›æ­¥ä¿ƒè¿›äº†å¤šæ¨¡æ€ä»£ç†çš„å‘å±•ï¼Œå¤šæ¨¡æ€ä»£ç†èƒ½å¤Ÿä½œä¸ºæ§åˆ¶å™¨è°ƒç”¨å¤–éƒ¨å·¥å…·ï¼Œä¸ºè§£å†³å®é™…ä»»åŠ¡æä¾›äº†å¯è¡Œæ–¹æ³•ã€‚</li>
<li>æœ¬æ–‡æå‡ºäº†ä¸€ç§å¤šæ¨¡æ€ä»£ç†è°ƒèŠ‚æ–¹æ³•ï¼Œå¯ä»¥è‡ªåŠ¨ç”Ÿæˆå¤šæ¨¡æ€å·¥å…·ä½¿ç”¨æ•°æ®ã€‚</li>
<li>é‡‡ç”¨äº†æ•°æ®åˆæˆç®¡é“æ¥æ”¶é›†MM-Trajæ•°æ®é›†ï¼Œè¯¥æ•°æ®é›†åŒ…å«2ä¸‡é¡¹ä»»åŠ¡åŠå·¥å…·ä½¿ç”¨è½¨è¿¹ã€‚</li>
<li>å¼€å‘äº†ä¸€ç§åŸºäºMM-Trajçš„T3-Agentï¼Œé€šè¿‡è½¨è¿¹è°ƒèŠ‚è§†è§‰è¯­è¨€æ¨¡å‹è¿›è¡Œå·¥å…·ä½¿ç”¨ã€‚</li>
<li>è¯„ä¼°ç»“æœæ˜¾ç¤ºT3-Agentåœ¨ä¸¤ç§æµè¡Œçš„VLMä¸Šè¡¨ç°ä¼˜å¼‚ï¼Œä¼˜äºæœªè®­ç»ƒçš„VLMã€‚</li>
<li>æ•°æ®åˆæˆç®¡é“çš„æœ‰æ•ˆæ€§å¾—åˆ°äº†éªŒè¯ï¼Œèƒ½å¤Ÿç”Ÿæˆé«˜è´¨é‡çš„å·¥å…·ä½¿ç”¨æ•°æ®ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.15606">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-963b18445f42c73720c6ca81034c8c5c.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-167386209c58998672452da9d496a130.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-037e35ae237c29563089361fce834dbd.jpg" align="middle">
</details>


<h1 id="-9"><a href="#-9" class="headerlink" title=""></a></h1><h2 id="Large-Language-Model-Brained-GUI-Agents-A-Survey"><a href="#Large-Language-Model-Brained-GUI-Agents-A-Survey" class="headerlink" title="Large Language Model-Brained GUI Agents: A Survey"></a>Large Language Model-Brained GUI Agents: A Survey</h2><p><strong>Authors:Chaoyun Zhang, Shilin He, Jiaxu Qian, Bowen Li, Liqun Li, Si Qin, Yu Kang, Minghua Ma, Guyue Liu, Qingwei Lin, Saravan Rajmohan, Dongmei Zhang, Qi Zhang</strong></p>
<p>GUIs have long been central to human-computer interaction, providing an intuitive and visually-driven way to access and interact with digital systems. The advent of LLMs, particularly multimodal models, has ushered in a new era of GUI automation. They have demonstrated exceptional capabilities in natural language understanding, code generation, and visual processing. This has paved the way for a new generation of LLM-brained GUI agents capable of interpreting complex GUI elements and autonomously executing actions based on natural language instructions. These agents represent a paradigm shift, enabling users to perform intricate, multi-step tasks through simple conversational commands. Their applications span across web navigation, mobile app interactions, and desktop automation, offering a transformative user experience that revolutionizes how individuals interact with software. This emerging field is rapidly advancing, with significant progress in both research and industry.   To provide a structured understanding of this trend, this paper presents a comprehensive survey of LLM-brained GUI agents, exploring their historical evolution, core components, and advanced techniques. We address research questions such as existing GUI agent frameworks, the collection and utilization of data for training specialized GUI agents, the development of large action models tailored for GUI tasks, and the evaluation metrics and benchmarks necessary to assess their effectiveness. Additionally, we examine emerging applications powered by these agents. Through a detailed analysis, this survey identifies key research gaps and outlines a roadmap for future advancements in the field. By consolidating foundational knowledge and state-of-the-art developments, this work aims to guide both researchers and practitioners in overcoming challenges and unlocking the full potential of LLM-brained GUI agents. </p>
<blockquote>
<p>å›¾å½¢ç”¨æˆ·ç•Œé¢ï¼ˆGUIsï¼‰é•¿æœŸä»¥æ¥ä¸€ç›´æ˜¯äººæœºäº¤äº’çš„æ ¸å¿ƒï¼Œæä¾›äº†ä¸€ç§ç›´è§‚ä¸”è§†è§‰é©±åŠ¨çš„æ–¹å¼æ¥è®¿é—®å’Œä¸æ•°å­—ç³»ç»Ÿäº¤äº’ã€‚å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„å‡ºç°ï¼Œç‰¹åˆ«æ˜¯å¤šæ¨¡æ€æ¨¡å‹ï¼Œå·²ç»å¼€å¯äº†GUIè‡ªåŠ¨åŒ–çš„æ–°æ—¶ä»£ã€‚å®ƒä»¬åœ¨è‡ªç„¶è¯­è¨€ç†è§£ã€ä»£ç ç”Ÿæˆå’Œè§†è§‰å¤„ç†æ–¹é¢è¡¨ç°å‡ºäº†å“è¶Šçš„èƒ½åŠ›ã€‚è¿™ä¸ºæ–°ä¸€ä»£åŸºäºLLMçš„GUIä»£ç†é“ºå¹³äº†é“è·¯ï¼Œè¿™äº›ä»£ç†èƒ½å¤Ÿè§£é‡Šå¤æ‚çš„GUIå…ƒç´ ï¼Œå¹¶åŸºäºè‡ªç„¶è¯­è¨€æŒ‡ä»¤è‡ªä¸»æ‰§è¡Œæ“ä½œã€‚è¿™äº›ä»£ç†ä»£è¡¨äº†èŒƒå¼è½¬å˜ï¼Œä½¿ç”¨æˆ·èƒ½å¤Ÿé€šè¿‡ç®€å•çš„å‘½ä»¤æ‰§è¡Œå¤æ‚çš„å¤šæ­¥éª¤ä»»åŠ¡ã€‚å®ƒä»¬çš„åº”ç”¨èŒƒå›´æ¶µç›–ç½‘é¡µå¯¼èˆªã€ç§»åŠ¨åº”ç”¨äº¤äº’å’Œæ¡Œé¢è‡ªåŠ¨åŒ–ï¼Œæä¾›å˜é©æ€§çš„ç”¨æˆ·ä½“éªŒï¼Œå½»åº•æ”¹å˜ä¸ªäººä¸è½¯ä»¶çš„äº¤äº’æ–¹å¼ã€‚è¿™ä¸ªæ–°å…´é¢†åŸŸæ­£åœ¨è¿…é€Ÿå‘å±•ï¼Œåœ¨ç ”ç©¶å’Œå·¥ä¸šæ–¹é¢éƒ½å–å¾—äº†é‡å¤§è¿›å±•ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2411.18279v8">PDF</a> The collection of papers reviewed in this survey will be hosted and   regularly updated on the GitHub repository:   <a target="_blank" rel="noopener" href="https://github.com/vyokky/LLM-Brained-GUI-Agents-Survey">https://github.com/vyokky/LLM-Brained-GUI-Agents-Survey</a> Additionally, a   searchable webpage is available at <a target="_blank" rel="noopener" href="https://aka.ms/gui-agent">https://aka.ms/gui-agent</a> for easier access   and exploration</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†GUIåœ¨äººæœºäº¤äº’ä¸­çš„é•¿æœŸé‡è¦åœ°ä½ï¼Œä»¥åŠå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ç‰¹åˆ«æ˜¯å¤šæ¨¡æ€æ¨¡å‹çš„å‡ºç°æ‰€å¸¦æ¥çš„GUIè‡ªåŠ¨åŒ–æ–°æ—¶ä»£ã€‚LLMå±•ç°å‡ºåœ¨ç†è§£è‡ªç„¶è¯­è¨€ã€ç”Ÿæˆä»£ç å’Œè§†è§‰å¤„ç†æ–¹é¢çš„å“è¶Šèƒ½åŠ›ï¼Œä¸ºæ–°ä¸€ä»£åŸºäºLLMçš„GUIä»£ç†çš„å‘å±•é“ºå¹³äº†é“è·¯ã€‚è¿™äº›ä»£ç†å¯ä»¥è§£é‡Šå¤æ‚çš„GUIå…ƒç´ å¹¶æ ¹æ®è‡ªç„¶è¯­è¨€æŒ‡ä»¤è‡ªä¸»æ‰§è¡Œæ“ä½œã€‚å®ƒä»¬çš„åº”ç”¨èŒƒå›´å¹¿æ³›ï¼ŒåŒ…æ‹¬ç½‘é¡µå¯¼èˆªã€ç§»åŠ¨åº”ç”¨äº¤äº’å’Œæ¡Œé¢è‡ªåŠ¨åŒ–ï¼Œä¸ºç”¨æˆ·æä¾›äº†ä¸€ç§å˜é©æ€§çš„ä½“éªŒï¼Œå½»åº•æ”¹å˜äº†ä¸ªäººä¸è½¯ä»¶çš„äº¤äº’æ–¹å¼ã€‚æœ¬æ–‡å…¨é¢æ¦‚è¿°äº†åŸºäºLLMçš„GUIä»£ç†çš„å†å²æ¼”å˜ã€æ ¸å¿ƒç»„ä»¶å’Œå…ˆè¿›æŠ€æœ¯ï¼Œå¹¶æ¢è®¨äº†è¯¥é¢†åŸŸçš„å…³é”®ç ”ç©¶é—®é¢˜ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>GUIåœ¨äººæœºäº¤äº’ä¸­å æ®é‡è¦åœ°ä½ï¼Œå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„å¼•å…¥ä¸ºGUIè‡ªåŠ¨åŒ–å¸¦æ¥äº†æ–°çš„å‘å±•æœºä¼šã€‚</li>
<li>LLMåœ¨ç†è§£è‡ªç„¶è¯­è¨€ã€ç”Ÿæˆä»£ç å’Œè§†è§‰å¤„ç†æ–¹é¢è¡¨ç°å‡ºå“è¶Šèƒ½åŠ›ã€‚</li>
<li>åŸºäºLLMçš„GUIä»£ç†èƒ½å¤Ÿè§£é‡Šå¤æ‚çš„GUIå…ƒç´ å¹¶æ ¹æ®è‡ªç„¶è¯­è¨€æŒ‡ä»¤è‡ªä¸»æ‰§è¡Œæ“ä½œã€‚</li>
<li>è¿™äº›ä»£ç†çš„åº”ç”¨èŒƒå›´å¹¿æ³›ï¼ŒåŒ…æ‹¬ç½‘é¡µå¯¼èˆªã€ç§»åŠ¨åº”ç”¨äº¤äº’å’Œæ¡Œé¢è‡ªåŠ¨åŒ–ã€‚</li>
<li>åŸºäºLLMçš„GUIä»£ç†ä»£è¡¨äº†ç”¨æˆ·ä¸è½¯ä»¶äº¤äº’æ–¹å¼çš„é‡å¤§è½¬å˜ã€‚</li>
<li>å½“å‰ç ”ç©¶é—®é¢˜åŒ…æ‹¬GUIä»£ç†æ¡†æ¶ã€æ•°æ®æ”¶é›†å’Œåˆ©ç”¨ã€é’ˆå¯¹GUIä»»åŠ¡çš„ç‰¹æ®ŠåŠ¨ä½œæ¨¡å‹å¼€å‘ç­‰ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2411.18279">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-ac9fb2875712cb27583503f3f8465f38.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e6a4be3fb98a0b63af42b7b053140fa6.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-58397a39ca33d56b26bd204d67f82c65.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-0d89366ba73b064043f371d52faf01a6.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-9fea2d287475388eff773cf68ce228c9.jpg" align="middle">
</details>


<h1 id="-10"><a href="#-10" class="headerlink" title=""></a></h1><h2 id="LLM-Consensus-Multi-Agent-Debate-for-Visual-Misinformation-Detection"><a href="#LLM-Consensus-Multi-Agent-Debate-for-Visual-Misinformation-Detection" class="headerlink" title="LLM-Consensus: Multi-Agent Debate for Visual Misinformation Detection"></a>LLM-Consensus: Multi-Agent Debate for Visual Misinformation Detection</h2><p><strong>Authors:Kumud Lakara, Georgia Channing, Juil Sock, Christian Rupprecht, Philip Torr, John Collomosse, Christian Schroeder de Witt</strong></p>
<p>One of the most challenging forms of misinformation involves the out-of-context (OOC) use of images paired with misleading text, creating false narratives. Existing AI-driven detection systems lack explainability and require expensive finetuning. We address these issues with LLM-Consensus, a multi-agent debate system for OOC misinformation detection. LLM-Consensus introduces a novel multi-agent debate framework where multimodal agents collaborate to assess contextual consistency and request external information to enhance cross-context reasoning and decision-making. Our framework enables explainable detection with state-of-the-art accuracy even without domain-specific fine-tuning. Extensive ablation studies confirm that external retrieval significantly improves detection accuracy, and user studies demonstrate that LLM-Consensus boosts performance for both experts and non-experts. These results position LLM-Consensus as a powerful tool for autonomous and citizen intelligence applications. </p>
<blockquote>
<p>è¯¯è§£ä¿¡æ¯æœ€å…·æŒ‘æˆ˜æ€§çš„å½¢å¼ä¹‹ä¸€æ¶‰åŠè„±ç¦»ä¸Šä¸‹æ–‡ï¼ˆOOCï¼‰ä½¿ç”¨ä¸è¯¯å¯¼æ€§æ–‡æœ¬é…å¯¹çš„å›¾åƒï¼Œä»è€Œåˆ›é€ é”™è¯¯çš„å™äº‹ã€‚ç°æœ‰çš„AIé©±åŠ¨çš„æ£€æµ‹ç³»ç»Ÿç¼ºä¹è§£é‡Šæ€§ï¼Œå¹¶éœ€è¦æ˜‚è´µçš„å¾®è°ƒã€‚æˆ‘ä»¬é€šè¿‡LLM-Consensusè§£å†³è¿™äº›é—®é¢˜ï¼Œè¿™æ˜¯ä¸€ç§ç”¨äºOOCè¯¯è§£ä¿¡æ¯æ£€æµ‹çš„åŸºäºå¤šæ™ºèƒ½ä½“çš„è¾©è®ºç³»ç»Ÿã€‚LLM-Consensuså¼•å…¥äº†ä¸€ç§æ–°å‹çš„å¤šæ™ºèƒ½ä½“è¾©è®ºæ¡†æ¶ï¼Œå…¶ä¸­å¤šæ¨¡æ€æ™ºèƒ½ä½“ç›¸äº’åä½œä»¥è¯„ä¼°ä¸Šä¸‹æ–‡ä¸€è‡´æ€§å¹¶è¯·æ±‚å¤–éƒ¨ä¿¡æ¯ä»¥å¢å¼ºè·¨ä¸Šä¸‹æ–‡æ¨ç†å’Œå†³ç­–åˆ¶å®šã€‚æˆ‘ä»¬çš„æ¡†æ¶åœ¨æ— éœ€ç‰¹å®šé¢†åŸŸå¾®è°ƒçš„æƒ…å†µä¸‹ï¼Œå³å¯å®ç°å…·æœ‰å‰æ²¿å‡†ç¡®æ€§çš„å¯è§£é‡Šæ£€æµ‹ã€‚å¹¿æ³›çš„æ¶ˆèç ”ç©¶è¯å®ï¼Œå¤–éƒ¨æ£€ç´¢æ˜¾ç€æé«˜äº†æ£€æµ‹å‡†ç¡®æ€§ï¼Œç”¨æˆ·ç ”ç©¶ä¹Ÿè¡¨æ˜LLM-Consensuså¯æå‡ä¸“å®¶å’Œéä¸“å®¶çš„æ€§èƒ½ã€‚è¿™äº›ç»“æœå°†LLM-Consensuså®šä½ä¸ºè‡ªä¸»å’Œå…¬æ°‘æ™ºèƒ½åº”ç”¨çš„å¼ºå¤§å·¥å…·ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2410.20140v2">PDF</a> </p>
<p><strong>Summary</strong><br>æ–‡æœ¬æå‡ºäº†ä¸€ç§åŸºäºå¤šæ¨¡æ€å¯¹è¯æ¡†æ¶çš„OOCè™šå‡ä¿¡æ¯æ£€æµ‹æ¨¡å‹LLM-Consensusã€‚è¯¥æ¨¡å‹é€šè¿‡å¼•å…¥å¤–éƒ¨ä¿¡æ¯æé«˜è·¨ä¸Šä¸‹æ–‡æ¨ç†å’Œå†³ç­–åˆ¶å®šèƒ½åŠ›ï¼Œæ”¯æŒå¯è§£é‡Šæ€§æ£€æµ‹å¹¶å®ç°äº†è¾ƒé«˜å‡†ç¡®åº¦ï¼Œæ— éœ€ç‰¹å®šé¢†åŸŸå¾®è°ƒã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>LLM-Consensusè§£å†³äº†ç°æœ‰AIé©±åŠ¨æ£€æµ‹ç³»ç»Ÿä¸­å­˜åœ¨çš„è§£é‡Šæ€§ä¸è¶³å’Œæ˜‚è´µå¾®è°ƒæˆæœ¬çš„é—®é¢˜ã€‚</li>
<li>LLM-Consensusé‡‡ç”¨å¤šæ¨¡æ€å¯¹è¯æ¡†æ¶ï¼Œå®ç°è·¨ä¸Šä¸‹æ–‡æ¨ç†å’Œå†³ç­–åˆ¶å®šã€‚</li>
<li>è¯¥æ¨¡å‹å¼•å…¥å¤–éƒ¨ä¿¡æ¯æ£€ç´¢åŠŸèƒ½ï¼Œæ˜¾è‘—æé«˜æ£€æµ‹å‡†ç¡®æ€§ã€‚</li>
<li>LLM-Consensusçš„æ£€æµ‹å…·æœ‰å¯è§£é‡Šæ€§ï¼Œå¹¶è¾¾åˆ°ä¸šç•Œé¢†å…ˆæ°´å¹³ã€‚</li>
<li>ç”¨æˆ·ç ”ç©¶è¡¨æ˜ï¼ŒLLM-Consensuså¯¹äºä¸“å®¶å’Œéä¸“å®¶ç”¨æˆ·éƒ½æœ‰æ€§èƒ½æå‡ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2410.20140">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-e36c5a16c8ef7de074086def01e1443d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-0a88743f99f8cdacc999bb3b5fcabaf0.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-2bdc559403dfe18679a699ec261cd043.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-2e9b2946381f99885a86058580f6e4cf.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-5e36047926c7227ed84d8c665397a4b5.jpg" align="middle">
</details>


<h1 id="-11"><a href="#-11" class="headerlink" title=""></a></h1><h2 id="GraphTeam-Facilitating-Large-Language-Model-based-Graph-Analysis-via-Multi-Agent-Collaboration"><a href="#GraphTeam-Facilitating-Large-Language-Model-based-Graph-Analysis-via-Multi-Agent-Collaboration" class="headerlink" title="GraphTeam: Facilitating Large Language Model-based Graph Analysis via   Multi-Agent Collaboration"></a>GraphTeam: Facilitating Large Language Model-based Graph Analysis via   Multi-Agent Collaboration</h2><p><strong>Authors:Xin Li, Qizhi Chu, Yubin Chen, Yang Liu, Yaoqi Liu, Zekai Yu, Weize Chen, Chen Qian, Chuan Shi, Cheng Yang</strong></p>
<p>Graphs are widely used for modeling relational data in real-world scenarios, such as social networks and urban computing. Existing LLM-based graph analysis approaches either integrate graph neural networks (GNNs) for specific machine learning tasks, limiting their transferability, or rely solely on LLMsâ€™ internal reasoning ability, resulting in suboptimal performance. To address these limitations, we take advantage of recent advances in LLM-based agents, which have shown capabilities of utilizing external knowledge or tools for problem solving. By simulating human problem-solving strategies such as analogy and collaboration, we propose a multi-agent system based on LLMs named GraphTeam, for graph analysis. GraphTeam consists of five LLM-based agents from three modules, and the agents with different specialities can collaborate with each other to address complex problems. Specifically, (1) input-output normalization module: the question agent extracts and refines four key arguments from the original question, facilitating the problem understanding, and the answer agent organizes the results to meet the output requirement; (2) external knowledge retrieval module: we first build a knowledge base consisting of relevant documentation and experience information, and then the search agent retrieves the most relevant entries for each question. (3) problem-solving module: given the retrieved information from search agent, the coding agent uses established algorithms via programming to generate solutions, and in case the coding agent does not work, the reasoning agent will directly compute the results without programming. Extensive experiments on six graph analysis benchmarks demonstrate that GraphTeam achieves state-of-the-art performance with an average 25.85% improvement over the best baseline in terms of accuracy. The code and data are available at <a target="_blank" rel="noopener" href="https://github.com/BUPT-GAMMA/GraphTeam">https://github.com/BUPT-GAMMA/GraphTeam</a>. </p>
<blockquote>
<p>å›¾è¢«å¹¿æ³›ç”¨äºç°å®åœºæ™¯ä¸­çš„å…³ç³»æ•°æ®å»ºæ¨¡ï¼Œå¦‚ç¤¾äº¤ç½‘ç»œå’ŒåŸå¸‚è®¡ç®—ã€‚ç°æœ‰çš„åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„å›¾åˆ†ææ–¹æ³•çš„ä¸è¶³ä¹‹å¤„åœ¨äºï¼Œå®ƒä»¬è¦ä¹ˆå°†å›¾ç¥ç»ç½‘ç»œï¼ˆGNNsï¼‰é›†æˆåˆ°ç‰¹å®šçš„æœºå™¨å­¦ä¹ ä»»åŠ¡ä¸­ï¼Œé™åˆ¶äº†å…¶å¯è¿ç§»æ€§ï¼Œè¦ä¹ˆä»…ä¾èµ–äºLLMsçš„å†…éƒ¨æ¨ç†èƒ½åŠ›ï¼Œå¯¼è‡´æ€§èƒ½ä¸ä½³ã€‚ä¸ºäº†è§£å†³è¿™äº›å±€é™æ€§ï¼Œæˆ‘ä»¬åˆ©ç”¨åŸºäºLLMçš„ä»£ç†çš„æœ€æ–°è¿›å±•ï¼Œè¿™äº›ä»£ç†å·²æ˜¾ç¤ºå‡ºåˆ©ç”¨å¤–éƒ¨çŸ¥è¯†æˆ–å·¥å…·è§£å†³é—®é¢˜çš„èƒ½åŠ›ã€‚é€šè¿‡æ¨¡æ‹Ÿäººç±»çš„è§£å†³é—®é¢˜ç­–ç•¥ï¼Œå¦‚ç±»æ¯”å’Œåä½œï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åŸºäºLLMçš„å¤šä»£ç†ç³»ç»Ÿï¼Œåä¸ºGraphTeamï¼Œç”¨äºå›¾åˆ†æã€‚GraphTeamç”±ä¸‰ä¸ªæ¨¡å—ä¸­çš„äº”ä¸ªåŸºäºLLMçš„ä»£ç†ç»„æˆï¼Œä¸åŒä¸“ä¸šçš„ä»£ç†å¯ä»¥ç›¸äº’åä½œæ¥è§£å†³å¤æ‚é—®é¢˜ã€‚å…·ä½“æ¥è¯´ï¼Œï¼ˆ1ï¼‰è¾“å…¥è¾“å‡ºå½’ä¸€åŒ–æ¨¡å—ï¼šé—®é¢˜ä»£ç†ä»åŸå§‹é—®é¢˜ä¸­æå–å¹¶ä¼˜åŒ–å››ä¸ªå…³é”®å‚æ•°ï¼Œä¿ƒè¿›å¯¹é—®é¢˜çš„ç†è§£ï¼Œç­”æ¡ˆä»£ç†åˆ™è´Ÿè´£æŒ‰è¾“å‡ºè¦æ±‚ç»„ç»‡ç»“æœï¼›ï¼ˆ2ï¼‰å¤–éƒ¨çŸ¥è¯†æ£€ç´¢æ¨¡å—ï¼šæˆ‘ä»¬é¦–å…ˆå»ºç«‹ä¸€ä¸ªåŒ…å«ç›¸å…³æ–‡æ¡£å’Œç»éªŒä¿¡æ¯çš„çŸ¥è¯†åº“ï¼Œç„¶åæœç´¢ä»£ç†æ ¹æ®æ¯ä¸ªé—®é¢˜æ£€ç´¢æœ€ç›¸å…³çš„æ¡ç›®ã€‚ï¼ˆ3ï¼‰é—®é¢˜è§£å†³æ¨¡å—ï¼šç»™å®šæ¥è‡ªæœç´¢ä»£ç†çš„æ£€ç´¢ä¿¡æ¯ï¼Œç¼–ç ä»£ç†é€šè¿‡ç¼–ç¨‹ä½¿ç”¨æ—¢å®šç®—æ³•æ¥ç”Ÿæˆè§£å†³æ–¹æ¡ˆï¼›å¦‚æœç¼–ç ä»£ç†æ— æ³•å·¥ä½œï¼Œæ¨ç†ä»£ç†å°†ç›´æ¥è¿›è¡Œè®¡ç®—ä»¥å¾—å‡ºç»“æœã€‚åœ¨å…­ä¸ªå›¾åˆ†æåŸºå‡†æµ‹è¯•ä¸Šçš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼ŒGraphTeamåœ¨å‡†ç¡®åº¦æ–¹é¢è¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œä¸æœ€ä½³åŸºçº¿ç›¸æ¯”å¹³å‡æé«˜äº†25.85%ã€‚ç›¸å…³ä»£ç å’Œæ•°æ®å¯ä»¥åœ¨<a target="_blank" rel="noopener" href="https://github.com/BUPT-GAMMA/GraphTeam%E8%8E%B7%E5%BE%97%E3%80%82">https://github.com/BUPT-GAMMA/GraphTeamè·å¾—ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2410.18032v3">PDF</a> </p>
<p><strong>Summary</strong><br>    åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ„å»ºåä¸ºGraphTeamçš„å¤šæ™ºèƒ½ä½“ç³»ç»Ÿï¼Œç”¨äºå›¾åˆ†æã€‚è¯¥ç³»ç»Ÿç”±ä¸‰ä¸ªæ¨¡å—ç»„æˆï¼ŒåŒ…å«è¾“å…¥è¾“å‡ºçš„è§„èŒƒå¤„ç†ã€å¤–éƒ¨çŸ¥è¯†çš„æ£€ç´¢ã€é—®é¢˜æ±‚è§£ã€‚è¯¥ç³»ç»Ÿçš„æ™ºèƒ½ä½“èƒ½é€šè¿‡ååŒåˆä½œè§£å†³å¤æ‚é—®é¢˜ï¼Œå¯¹å…­ç§å›¾åˆ†æåŸºå‡†æµ‹è¯•çš„å®éªŒç»“æœè¡¨æ˜ï¼ŒGraphTeamå®ç°äº†å“è¶Šçš„æ€§èƒ½ï¼Œå¹³å‡å‡†ç¡®ç‡ç›¸è¾ƒäºæœ€ä½³åŸºçº¿æé«˜äº†25.85%ã€‚ç›¸å…³ä»£ç å’Œæ•°æ®åœ¨GitHubä¸Šå…¬å¼€ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>GraphTeamæ˜¯ä¸€ä¸ªåŸºäºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„å¤šæ™ºèƒ½ä½“ç³»ç»Ÿï¼Œç”¨äºå›¾åˆ†æã€‚</li>
<li>GraphTeamè§£å†³äº†ç°æœ‰LLM-basedå›¾åˆ†ææ–¹æ³•çš„å±€é™æ€§ï¼Œå¦‚ç¼ºä¹è½¬ç§»æ€§å’Œæ€§èƒ½ä¸è¶³ã€‚</li>
<li>GraphTeamåŒ…å«ä¸‰ä¸ªæ¨¡å—ï¼šè¾“å…¥è¾“å‡ºçš„è§„èŒƒå¤„ç†ã€å¤–éƒ¨çŸ¥è¯†çš„æ£€ç´¢å’Œé—®é¢˜æ±‚è§£ã€‚</li>
<li>è¾“å…¥è¾“å‡ºè§„èŒƒå¤„ç†æ¨¡å—åŒ…å«é—®é¢˜ç†è§£å’Œç»“æœç»„ç»‡ã€‚</li>
<li>å¤–éƒ¨çŸ¥è¯†æ£€ç´¢æ¨¡å—å»ºç«‹äº†åŒ…å«ç›¸å…³æ–‡æ¡£å’Œç»éªŒä¿¡æ¯çš„çŸ¥è¯†åº“ï¼Œå¹¶èƒ½å¤Ÿé€šè¿‡æœç´¢æ™ºèƒ½ä½“æ£€ç´¢æœ€ç›¸å…³çš„ä¿¡æ¯ã€‚</li>
<li>é—®é¢˜æ±‚è§£æ¨¡å—èƒ½å¤Ÿé€šè¿‡ç¼–ç¨‹æ™ºèƒ½ä½“åˆ©ç”¨å·²å»ºç«‹çš„ç®—æ³•ç”Ÿæˆè§£å†³æ–¹æ¡ˆï¼Œå¦‚æœä¸é€‚ç”¨ç¼–ç¨‹æ–¹å¼ï¼Œæ¨ç†æ™ºèƒ½ä½“ä¼šç›´æ¥è®¡ç®—ç»“æœã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2410.18032">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-a3604c982b8bed75f44f10e4023e70f6.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-6174aaec6b371137dfce026a2e408e6c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-cd6e32e390d7e1a502518465cfd21472.jpg" align="middle">
</details>


<h1 id="-12"><a href="#-12" class="headerlink" title=""></a></h1><h2 id="Improving-Parallel-Program-Performance-with-LLM-Optimizers-via-Agent-System-Interface"><a href="#Improving-Parallel-Program-Performance-with-LLM-Optimizers-via-Agent-System-Interface" class="headerlink" title="Improving Parallel Program Performance with LLM Optimizers via   Agent-System Interface"></a>Improving Parallel Program Performance with LLM Optimizers via   Agent-System Interface</h2><p><strong>Authors:Anjiang Wei, Allen Nie, Thiago S. F. X. Teixeira, Rohan Yadav, Wonchan Lee, Ke Wang, Alex Aiken</strong></p>
<p>Modern scientific discovery increasingly relies on high-performance computing for complex modeling and simulation. A key challenge in improving parallel program performance is efficiently mapping tasks to processors and data to memory, a process dictated by intricate, low-level system code known as mappers. Developing high-performance mappers demands days of manual tuning, posing a significant barrier for domain scientists without systems expertise. We introduce a framework that automates mapper development with generative optimization, leveraging richer feedback beyond scalar performance metrics. Our approach features the Agent-System Interface, which includes a Domain-Specific Language (DSL) to abstract away low-level complexity of system code and define a structured search space, as well as AutoGuide, a mechanism that interprets raw execution output into actionable feedback. Unlike traditional reinforcement learning methods such as OpenTuner, which rely solely on scalar feedback, our method finds superior mappers in far fewer iterations. With just 10 iterations, it outperforms OpenTuner even after 1000 iterations, achieving 3.8X faster performance. Our approach finds mappers that surpass expert-written mappers by up to 1.34X speedup across nine benchmarks while reducing tuning time from days to minutes. </p>
<blockquote>
<p>ç°ä»£ç§‘å­¦å‘ç°è¶Šæ¥è¶Šä¾èµ–äºé«˜æ€§èƒ½è®¡ç®—è¿›è¡Œå¤æ‚çš„å»ºæ¨¡å’Œæ¨¡æ‹Ÿã€‚æé«˜å¹¶è¡Œç¨‹åºæ€§èƒ½çš„å…³é”®æŒ‘æˆ˜åœ¨äºæœ‰æ•ˆåœ°å°†ä»»åŠ¡æ˜ å°„åˆ°å¤„ç†å™¨å¹¶å°†æ•°æ®æ˜ å°„åˆ°å†…å­˜ï¼Œè¿™ä¸€è¿‡ç¨‹ç”±å¤æ‚çš„ä½çº§ç³»ç»Ÿä»£ç ï¼ˆç§°ä¸ºæ˜ å°„å™¨ï¼‰å†³å®šã€‚å¼€å‘é«˜æ€§èƒ½æ˜ å°„å™¨éœ€è¦æ•°å¤©çš„æ‰‹åŠ¨è°ƒæ•´ï¼Œè¿™å¯¹æ²¡æœ‰ç³»ç»Ÿä¸“ä¸šçŸ¥è¯†çš„é¢†åŸŸç§‘å­¦å®¶æ¥è¯´æ˜¯ä¸€ä¸ªé‡å¤§éšœç¢ã€‚æˆ‘ä»¬å¼•å…¥äº†ä¸€ä¸ªæ¡†æ¶ï¼Œè¯¥æ¡†æ¶ä½¿ç”¨ç”Ÿæˆä¼˜åŒ–æ¥è‡ªåŠ¨è¿›è¡Œæ˜ å°„å™¨å¼€å‘ï¼Œå¹¶åˆ©ç”¨æ ‡é‡æ€§èƒ½æŒ‡æ ‡ä¹‹å¤–çš„æ›´ä¸°å¯Œåé¦ˆã€‚æˆ‘ä»¬çš„æ–¹æ³•å…·æœ‰Agent-Systemæ¥å£ï¼Œå®ƒåŒ…æ‹¬ä¸€ä¸ªé¢†åŸŸç‰¹å®šè¯­è¨€ï¼ˆDSLï¼‰ï¼Œä»¥æ¶ˆé™¤ç³»ç»Ÿä»£ç çš„åº•å±‚å¤æ‚æ€§å¹¶å®šä¹‰ç»“æ„åŒ–çš„æœç´¢ç©ºé—´ï¼Œä»¥åŠAutoGuideï¼Œå®ƒæ˜¯ä¸€ç§è§£é‡ŠåŸå§‹æ‰§è¡Œè¾“å‡ºä¸ºå¯æ“ä½œåé¦ˆçš„æœºåˆ¶ã€‚ä¸ä¼ ç»Ÿçš„å¼ºåŒ–å­¦ä¹ æ–¹æ³•ï¼ˆå¦‚OpenTunerï¼‰ä¸åŒï¼Œåè€…ä»…ä¾èµ–äºæ ‡é‡åé¦ˆï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨è¾ƒå°‘çš„è¿­ä»£æ¬¡æ•°ä¸­æ‰¾åˆ°æ›´ä¼˜çš„æ˜ å°„å™¨ã€‚ä»…éœ€10æ¬¡è¿­ä»£ï¼Œå³ä½¿åœ¨1000æ¬¡è¿­ä»£åï¼Œå®ƒçš„æ€§èƒ½ä¹Ÿä¼˜äºOpenTunerï¼Œè¾¾åˆ°äº†3.8å€çš„é€Ÿåº¦æå‡ã€‚æˆ‘ä»¬çš„æ–¹æ³•æ‰¾åˆ°çš„æ˜ å°„å™¨åœ¨ä¹ä¸ªåŸºå‡†æµ‹è¯•ä¸­å®ç°äº†é«˜è¾¾1.34å€çš„é€Ÿåº¦æå‡ï¼Œå¹¶å°†è°ƒæ•´æ—¶é—´ä»æ•°å¤©ç¼©çŸ­åˆ°æ•°åˆ†é’Ÿã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2410.15625v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†ç°ä»£ç§‘å­¦å‘ç°ä¸­é«˜æ€§èƒ½è®¡ç®—åœ¨å¤æ‚å»ºæ¨¡å’Œä»¿çœŸä¸­çš„é‡è¦ä½œç”¨ã€‚ä¸ºæé«˜å¹¶è¡Œç¨‹åºæ€§èƒ½çš„å…³é”®æŒ‘æˆ˜æ˜¯æœ‰æ•ˆæ˜ å°„ä»»åŠ¡åˆ°å¤„ç†å™¨å’Œæ•°æ®åˆ°å†…å­˜ï¼Œè¿™ä¸€è¿‡ç¨‹ç”±ç§°ä¸ºæ˜ å°„å™¨çš„ä½çº§ç³»ç»Ÿä»£ç æ§åˆ¶ã€‚å¼€å‘é«˜æ€§èƒ½æ˜ å°„å™¨éœ€è¦æ•°å¤©çš„æ‰‹åŠ¨è°ƒæ•´ï¼Œå¯¹æ²¡æœ‰ç³»ç»Ÿä¸“ä¸šçŸ¥è¯†çš„é¢†åŸŸç§‘å­¦å®¶æ„æˆé‡å¤§éšœç¢ã€‚æœ¬æ–‡å¼•å…¥äº†ä¸€ä¸ªä½¿ç”¨ç”Ÿæˆä¼˜åŒ–è‡ªåŠ¨æ˜ å°„å™¨å¼€å‘çš„æ¡†æ¶ï¼Œè¯¥æ¡†æ¶åˆ©ç”¨ä¸°å¯Œçš„åé¦ˆè¶…è¶Šäº†æ ‡é‡æ€§èƒ½åº¦é‡ã€‚å…¶ç‰¹ç‚¹åŒ…æ‹¬Agent-Systemæ¥å£å’ŒAutoGuideæœºåˆ¶ï¼Œåˆ†åˆ«é€šè¿‡é¢†åŸŸç‰¹å®šè¯­è¨€ï¼ˆDSLï¼‰æŠ½è±¡ç³»ç»Ÿä»£ç çš„ä½çº§å¤æ‚æ€§å¹¶å®šä¹‰ç»“æ„åŒ–æœç´¢ç©ºé—´ï¼Œä»¥åŠå°†åŸå§‹æ‰§è¡Œè¾“å‡ºè§£é‡Šä¸ºå¯æ“ä½œçš„åé¦ˆã€‚è¯¥æ–¹æ³•åœ¨è¾ƒå°‘çš„è¿­ä»£æ¬¡æ•°ä¸­æ‰¾åˆ°é«˜æ€§èƒ½æ˜ å°„å™¨ï¼Œä¼˜äºä»…ä¾èµ–æ ‡é‡åé¦ˆçš„ä¼ ç»Ÿå¼ºåŒ–å­¦ä¹ æ–¹æ³•ï¼ˆå¦‚OpenTunerï¼‰ï¼Œå¹¶åœ¨ä»…10æ¬¡è¿­ä»£ä¸­å®ç°äº†é«˜è¾¾3.8å€çš„æ€§èƒ½æå‡ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•æ‰¾åˆ°äº†è¶…è¿‡ä¸“å®¶ç¼–å†™çš„æ˜ å°„å™¨åœ¨ä¹ä¸ªåŸºå‡†æµ‹è¯•ä¸­çš„é€Ÿåº¦æå‡é«˜è¾¾1.34å€ï¼Œå¹¶å°†è°ƒæ•´æ—¶é—´ä»æ•°å¤©ç¼©çŸ­åˆ°æ•°åˆ†é’Ÿã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ç°ä»£ç§‘å­¦å‘ç°ä¾èµ–äºé«˜æ€§èƒ½è®¡ç®—è¿›è¡Œå¤æ‚å»ºæ¨¡å’Œä»¿çœŸã€‚</li>
<li>å¼€å‘é«˜æ€§èƒ½æ˜ å°„å™¨æ˜¯ä¸€é¡¹æŒ‘æˆ˜ï¼Œéœ€è¦æ•°å¤©çš„æ‰‹åŠ¨è°ƒæ•´ï¼Œå¯¹æ²¡æœ‰ç³»ç»Ÿä¸“ä¸šçŸ¥è¯†çš„é¢†åŸŸç§‘å­¦å®¶æ„æˆæŒ‘æˆ˜ã€‚</li>
<li>ä»‹ç»äº†ä¸€ç§ä½¿ç”¨ç”Ÿæˆä¼˜åŒ–è‡ªåŠ¨æ˜ å°„å™¨å¼€å‘çš„æ¡†æ¶ã€‚</li>
<li>è¯¥æ¡†æ¶åˆ©ç”¨ä¸°å¯Œçš„åé¦ˆè¶…è¶Šäº†æ ‡é‡æ€§èƒ½åº¦é‡ï¼Œé€šè¿‡Agent-Systemæ¥å£å’ŒAutoGuideæœºåˆ¶å®ç°äº†é«˜æ•ˆæ˜ å°„å™¨çš„å¼€å‘ã€‚</li>
<li>Agent-Systemæ¥å£åŒ…æ‹¬ä¸€ä¸ªé¢†åŸŸç‰¹å®šè¯­è¨€ï¼ˆDSLï¼‰ï¼Œå¯ä»¥æŠ½è±¡ç³»ç»Ÿä»£ç çš„ä½çº§å¤æ‚æ€§å¹¶å®šä¹‰ç»“æ„åŒ–æœç´¢ç©ºé—´ã€‚</li>
<li>è¯¥æ–¹æ³•åœ¨è¾ƒå°‘çš„è¿­ä»£æ¬¡æ•°ä¸­æ‰¾åˆ°é«˜æ€§èƒ½æ˜ å°„å™¨ï¼Œä¼˜äºä¼ ç»Ÿå¼ºåŒ–å­¦ä¹ æ–¹æ³•ï¼ˆå¦‚OpenTunerï¼‰ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2410.15625">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-57a203442bb2fbcfbbcdcd1b81d1cea8.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-b31d30a3c2bf87ecd0b09ed66571f077.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-9fcb1d601ab0cab8c85e9b54146ee0e2.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-8f8fa1ec0b0ec3855774e11d92c766a0.jpg" align="middle">
</details>


<h1 id="-13"><a href="#-13" class="headerlink" title=""></a></h1><h2 id="Breaking-the-Curse-of-Multiagency-in-Robust-Multi-Agent-Reinforcement-Learning"><a href="#Breaking-the-Curse-of-Multiagency-in-Robust-Multi-Agent-Reinforcement-Learning" class="headerlink" title="Breaking the Curse of Multiagency in Robust Multi-Agent Reinforcement   Learning"></a>Breaking the Curse of Multiagency in Robust Multi-Agent Reinforcement   Learning</h2><p><strong>Authors:Laixi Shi, Jingchu Gai, Eric Mazumdar, Yuejie Chi, Adam Wierman</strong></p>
<p>Standard multi-agent reinforcement learning (MARL) algorithms are vulnerable to sim-to-real gaps. To address this, distributionally robust Markov games (RMGs) have been proposed to enhance robustness in MARL by optimizing the worst-case performance when game dynamics shift within a prescribed uncertainty set. RMGs remains under-explored, from reasonable problem formulation to the development of sample-efficient algorithms. Two notorious and open challenges are the formulation of the uncertainty set and whether the corresponding RMGs can overcome the curse of multiagency, where the sample complexity scales exponentially with the number of agents. In this work, we propose a natural class of RMGs inspired by behavioral economics, where each agentâ€™s uncertainty set is shaped by both the environment and the integrated behavior of other agents. We first establish the well-posedness of this class of RMGs by proving the existence of game-theoretic solutions such as robust Nash equilibria and coarse correlated equilibria (CCE). Assuming access to a generative model, we then introduce a sample-efficient algorithm for learning the CCE whose sample complexity scales polynomially with all relevant parameters. To the best of our knowledge, this is the first algorithm to break the curse of multiagency for RMGs, regardless of the uncertainty set formulation. </p>
<blockquote>
<p>æ ‡å‡†çš„å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ ï¼ˆMARLï¼‰ç®—æ³•å®¹æ˜“å—åˆ°ä»¿çœŸåˆ°ç°å®çš„å·®è·å½±å“ã€‚ä¸ºè§£å†³è¿™ä¸€é—®é¢˜ï¼Œæå‡ºäº†åˆ†å¸ƒé²æ£’é©¬å°”å¯å¤«åšå¼ˆï¼ˆRMGsï¼‰ï¼Œé€šè¿‡ä¼˜åŒ–åœ¨è§„å®šçš„ä¸ç¡®å®šæ€§é›†å†…æ¸¸æˆåŠ¨æ€å˜åŒ–æ—¶çš„æœ€åæƒ…å†µæ€§èƒ½ï¼Œå¢å¼ºMARLä¸­çš„ç¨³å¥æ€§ã€‚RMGsçš„ç ”ç©¶ä»ç„¶ä¸è¶³ï¼Œä»åˆç†çš„é—®é¢˜å…¬å¼åŒ–åˆ°æ ·æœ¬é«˜æ•ˆç®—æ³•çš„å¼€å‘éƒ½æ˜¯å¦‚æ­¤ã€‚ä¸¤ä¸ªè‘—åä¸”å…¬å¼€çš„æŒ‘æˆ˜æ˜¯ä¸ç¡®å®šæ€§é›†åˆçš„å…¬å¼åŒ–ä»¥åŠç›¸åº”çš„RMGsæ˜¯å¦èƒ½å¤Ÿå…‹æœå¤šæ™ºèƒ½ä½“çš„è¯…å’’ï¼Œå³æ ·æœ¬å¤æ‚åº¦éšæ™ºèƒ½ä½“æ•°é‡çš„å¢åŠ è€Œå‘ˆæŒ‡æ•°çº§å¢é•¿ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§å—è¡Œä¸ºç»æµå­¦å¯å‘çš„è‡ªç„¶RMGsç±»åˆ«ï¼Œå…¶ä¸­æ¯ä¸ªæ™ºèƒ½ä½“çš„ä¸ç¡®å®šæ€§é›†æ˜¯ç”±ç¯å¢ƒå’Œå…¶å®ƒæ™ºèƒ½ä½“çš„ç»¼åˆè¡Œä¸ºå…±åŒå¡‘é€ çš„ã€‚æˆ‘ä»¬é¦–å…ˆé€šè¿‡å»ºç«‹è¿™ç±»RMGsçš„é€‚å®šæ€§æ¥è¯æ˜åšå¼ˆè®ºè§£çš„å­˜åœ¨æ€§ï¼Œå¦‚é²æ£’çº³ä»€å‡è¡¡å’Œç²—ç³™ç›¸å…³å‡è¡¡ï¼ˆCCEï¼‰ã€‚å‡è®¾èƒ½å¤Ÿè®¿é—®ç”Ÿæˆæ¨¡å‹ï¼Œæˆ‘ä»¬ç„¶åä»‹ç»äº†ä¸€ç§å­¦ä¹ CCEçš„æ ·æœ¬é«˜æ•ˆç®—æ³•ï¼Œå…¶æ ·æœ¬å¤æ‚åº¦ä¸æ‰€æœ‰ç›¸å…³å‚æ•°å‘ˆå¤šé¡¹å¼å¢é•¿ã€‚æ®æˆ‘ä»¬æ‰€çŸ¥ï¼Œè¿™æ˜¯ç¬¬ä¸€ä¸ªæ‰“ç ´äº†RMGsçš„å¤šæ™ºèƒ½ä½“è¯…å’’çš„ç®—æ³•ï¼Œæ— è®ºä¸ç¡®å®šæ€§é›†çš„å…¬å¼åŒ–å¦‚ä½•ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2409.20067v3">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºä¸€ç±»å—è¡Œä¸ºç»æµå­¦å¯å‘çš„åˆ†å¸ƒç¨³å¥æ€§é©¬å°”å¯å¤«æ¸¸æˆï¼ˆRMGsï¼‰ï¼Œæ—¨åœ¨å¢å¼ºå¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ ï¼ˆMARLï¼‰çš„ç¨³å¥æ€§ã€‚é€šè¿‡è€ƒè™‘ç¯å¢ƒå’Œå…¶ä»–æ™ºèƒ½ä½“çš„ç»¼åˆè¡Œä¸ºæ¥æ„å»ºæ¯ä¸ªæ™ºèƒ½ä½“çš„ä¸ç¡®å®šæ€§é›†ï¼Œè¿›è€Œä¼˜åŒ–æœ€åæƒ…å†µä¸‹çš„æ€§èƒ½ã€‚æœ¬æ–‡è¯æ˜äº†è¿™ç±»RMGsçš„æ¸¸æˆç†è®ºè§£çš„å­˜åœ¨æ€§ï¼Œå¦‚ç¨³å¥çš„çº³ä»€å‡è¡¡å’Œç²—ç³™ç›¸å…³å‡è¡¡ã€‚åœ¨å‡è®¾æœ‰ç”Ÿæˆæ¨¡å‹çš„æƒ…å†µä¸‹ï¼Œæå‡ºäº†ä¸€ç§æ ·æœ¬æ•ˆç‡é«˜çš„å­¦ä¹ CCEçš„ç®—æ³•ï¼Œå…¶æ ·æœ¬å¤æ‚åº¦ä¸æ‰€æœ‰ç›¸å…³å‚æ•°å‘ˆå¤šé¡¹å¼å¢é•¿ï¼Œæ‰“ç ´äº†RMGsä¸­çš„å¤šæ™ºèƒ½ä½“è¯…å’’ï¼Œæ— è®ºä¸ç¡®å®šæ€§é›†çš„å½¢å¼å¦‚ä½•ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>RMGsæ—¨åœ¨å¢å¼ºMARLçš„ç¨³å¥æ€§ï¼Œå¯¹æŠ—æ¨¡æ‹Ÿåˆ°å®é™…çš„å·®è·ã€‚</li>
<li>æœ¬æ–‡æå‡ºäº†å—è¡Œä¸ºç»æµå­¦å¯å‘çš„RMGsï¼Œæ„å»ºæ™ºèƒ½ä½“çš„ä¸ç¡®å®šæ€§é›†æ—¶è€ƒè™‘äº†ç¯å¢ƒå’Œå…¶ä»–æ™ºèƒ½ä½“çš„è¡Œä¸ºã€‚</li>
<li>è¯æ˜äº†è¿™ç±»RMGsçš„æ¸¸æˆç†è®ºè§£çš„å­˜åœ¨æ€§ï¼Œå¦‚ç¨³å¥çš„çº³ä»€å‡è¡¡å’ŒCCEã€‚</li>
<li>å¼•å…¥äº†ä¸€ç§æ ·æœ¬æ•ˆç‡é«˜çš„ç®—æ³•æ¥å­¦ä¹ CCEï¼Œå…¶æ ·æœ¬å¤æ‚åº¦ä¸æ‰€æœ‰ç›¸å…³å‚æ•°å‘ˆå¤šé¡¹å¼å¢é•¿ã€‚</li>
<li>è¯¥ç®—æ³•æ‰“ç ´äº†RMGsä¸­çš„å¤šæ™ºèƒ½ä½“è¯…å’’ï¼Œå³æ ·æœ¬å¤æ‚åº¦ä¸ä¼šéšç€æ™ºèƒ½ä½“æ•°é‡çš„å¢åŠ è€ŒæŒ‡æ•°å¢é•¿ã€‚</li>
<li>è¯¥ç®—æ³•å¯¹ä¸ç¡®å®šæ€§é›†çš„å…·ä½“å½¢å¼å…·æœ‰é²æ£’æ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2409.20067">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-612b85517245a1b4f9a3cb0445f2e829.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-4d72ece8302284ea9bd3fbb5c026b138.jpg" align="middle">
</details>


<h1 id="-14"><a href="#-14" class="headerlink" title=""></a></h1><h2 id="InvAgent-A-Large-Language-Model-based-Multi-Agent-System-for-Inventory-Management-in-Supply-Chains"><a href="#InvAgent-A-Large-Language-Model-based-Multi-Agent-System-for-Inventory-Management-in-Supply-Chains" class="headerlink" title="InvAgent: A Large Language Model based Multi-Agent System for Inventory   Management in Supply Chains"></a>InvAgent: A Large Language Model based Multi-Agent System for Inventory   Management in Supply Chains</h2><p><strong>Authors:Yinzhu Quan, Zefang Liu</strong></p>
<p>Supply chain management (SCM) involves coordinating the flow of goods, information, and finances across various entities to deliver products efficiently. Effective inventory management is crucial in todayâ€™s volatile and uncertain world. Previous research has demonstrated the superiority of heuristic methods and reinforcement learning applications in inventory management. However, the application of large language models (LLMs) as autonomous agents in multi-agent systems for inventory management remains underexplored. This study introduces a novel approach using LLMs to manage multi-agent inventory systems. Leveraging their zero-shot learning capabilities, our model, InvAgent, enhances resilience and improves efficiency across the supply chain network. Our contributions include utilizing LLMs for zero-shot learning to enable adaptive and informed decision-making without prior training, providing explainability and clarity through chain-of-thought, and demonstrating dynamic adaptability to varying demand scenarios while reducing costs and preventing stockouts. Extensive evaluations across different scenarios highlight the efficiency of our model in SCM. </p>
<blockquote>
<p>ä¾›åº”é“¾ç®¡ç†ï¼ˆSCMï¼‰æ¶‰åŠåè°ƒå„å®ä½“ä¹‹é—´çš„è´§ç‰©ã€ä¿¡æ¯å’Œè´¢åŠ¡æµåŠ¨ï¼Œä»¥å®ç°é«˜æ•ˆçš„äº§å“äº¤ä»˜ã€‚åœ¨å¦‚ä»Šè¿™ä¸ªæ³¢åŠ¨å’Œä¸ç¡®å®šçš„ä¸–ç•Œä¸­ï¼Œæœ‰æ•ˆçš„åº“å­˜ç®¡ç†è‡³å…³é‡è¦ã€‚å…ˆå‰çš„ç ”ç©¶å·²ç»è¯æ˜äº†å¯å‘å¼æ–¹æ³•å’Œå¼ºåŒ–å­¦ä¹ åº”ç”¨åœ¨åº“å­˜ç®¡ç†ä¸­çš„ä¼˜è¶Šæ€§ã€‚ç„¶è€Œï¼Œå°†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä½œä¸ºå¤šæ™ºèƒ½ä½“ç³»ç»Ÿä¸­çš„è‡ªä¸»æ™ºèƒ½ä½“åº”ç”¨äºåº“å­˜ç®¡ç†ä»ç„¶æœªè¢«å……åˆ†æ¢ç´¢ã€‚æœ¬ç ”ç©¶ä»‹ç»äº†ä¸€ç§ä½¿ç”¨LLMç®¡ç†å¤šæ™ºèƒ½ä½“åº“å­˜ç³»ç»Ÿçš„æ–°æ–¹æ³•ã€‚åˆ©ç”¨ä»–ä»¬çš„é›¶æ ·æœ¬å­¦ä¹ èƒ½åŠ›ï¼Œæˆ‘ä»¬çš„æ¨¡å‹InvAgentå¢å¼ºäº†ä¾›åº”é“¾çš„å¼¹æ€§å¹¶æé«˜äº†æ•ˆç‡ã€‚æˆ‘ä»¬çš„è´¡çŒ®åŒ…æ‹¬åˆ©ç”¨LLMè¿›è¡Œé›¶æ ·æœ¬å­¦ä¹ ï¼Œä»¥å®ç°æœªç»è®­ç»ƒçš„è‡ªé€‚åº”å’ŒåŸºäºä¿¡æ¯çš„å†³ç­–åˆ¶å®šï¼Œé€šè¿‡æ€ç»´é“¾æä¾›è§£é‡Šæ€§å’Œæ¸…æ™°åº¦ï¼Œå¹¶å±•ç¤ºå¯¹ä¸æ–­å˜åŒ–çš„éœ€æ±‚åœºæ™¯çš„åŠ¨æ€é€‚åº”æ€§ï¼ŒåŒæ—¶é™ä½æˆæœ¬å¹¶é˜²æ­¢ç¼ºè´§ã€‚åœ¨ä¸åŒåœºæ™¯ä¸‹çš„å¹¿æ³›è¯„ä¼°çªå‡ºäº†æˆ‘ä»¬æ¨¡å‹åœ¨ä¾›åº”é“¾ç®¡ç†ä¸­çš„æ•ˆç‡ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2407.11384v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>åŸºäºä¾›åº”é“¾ç®¡ç†çš„æœ‰æ•ˆåº“å­˜ç®¡ç†åœ¨ç°ä»£åŠ¨è¡å’Œä¸ç¡®å®šçš„ä¸–ç•Œä¸­å°¤ä¸ºå…³é”®ã€‚è¿‡å»çš„ç ”ç©¶å·²æ˜¾ç¤ºå¯å‘å¼æ–¹æ³•å’Œå¼ºåŒ–å­¦ä¹ åœ¨åº“å­˜ç®¡ç†ä¸­çš„åº”ç”¨ä¼˜åŠ¿ã€‚ç„¶è€Œï¼Œå…³äºåœ¨å¤šæ™ºèƒ½ä½“ç³»ç»Ÿä¸­ä½¿ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰è¿›è¡Œåº“å­˜ç®¡ç†çš„è‡ªä¸»æ€§æ™ºèƒ½ä½“çš„åº”ç”¨ä»ç„¶é²œæœ‰ç ”ç©¶ã€‚æœ¬ç ”ç©¶é‡‡ç”¨äº†ä¸€ç§æ–°å‹æ–¹æ³•ï¼Œå³åˆ©ç”¨LLMç®¡ç†å¤šæ™ºèƒ½ä½“åº“å­˜ç³»ç»Ÿã€‚å€ŸåŠ©å…¶é›¶æ ·æœ¬å­¦ä¹ èƒ½åŠ›ï¼Œæˆ‘ä»¬çš„æ¨¡å‹InvAgentæé«˜äº†ä¾›åº”é“¾ç½‘ç»œçš„å¼¹æ€§å’Œæ•ˆç‡ã€‚å…¶è´¡çŒ®åŒ…æ‹¬åˆ©ç”¨LLMè¿›è¡Œé›¶æ ·æœ¬å­¦ä¹ ä»¥å®ç°æ— éœ€é¢„å…ˆè®­ç»ƒçš„é€‚åº”æ€§å’Œæ™ºèƒ½å†³ç­–åˆ¶å®šï¼Œé€šè¿‡æ€ç»´é“¾æä¾›è§£é‡Šæ€§å’Œæ¸…æ™°åº¦ï¼Œå¹¶å±•ç¤ºå¯¹ä¸æ–­å˜åŒ–çš„éœ€æ±‚åœºæ™¯çš„é€‚åº”åŠ›ï¼ŒåŒæ—¶é™ä½æˆæœ¬å¹¶é¿å…ç¼ºè´§æƒ…å†µã€‚åœ¨ä¸åŒåœºæ™¯ä¸‹çš„å¹¿æ³›è¯„ä¼°å‡¸æ˜¾äº†æˆ‘ä»¬çš„æ¨¡å‹åœ¨ä¾›åº”é“¾ç®¡ç†ä¸­çš„æ•ˆç‡ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ä¾›åº”é“¾ç®¡ç†ä¸­æœ‰æ•ˆçš„åº“å­˜ç®¡ç†å¯¹äºç°ä»£ä¸ç¨³å®šç¯å¢ƒä¸­çš„ä¼ä¸šè‡³å…³é‡è¦ã€‚</li>
<li>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨å¤šæ™ºèƒ½ä½“ç³»ç»Ÿä¸­çš„åº“å­˜ç®¡ç†åº”ç”¨å°šæœªå¾—åˆ°å……åˆ†æ¢ç´¢ã€‚</li>
<li>æœ¬ç ”ç©¶æå‡ºäº†ä¸€ç§ä½¿ç”¨LLMç®¡ç†å¤šæ™ºèƒ½ä½“åº“å­˜ç³»ç»Ÿçš„åˆ›æ–°æ–¹æ³•ã€‚</li>
<li>LLMçš„é›¶æ ·æœ¬å­¦ä¹ èƒ½åŠ›å¢å¼ºäº†ä¾›åº”é“¾ç½‘ç»œçš„å¼¹æ€§å’Œæ•ˆç‡ã€‚</li>
<li>æ¨¡å‹InvAgentå®ç°äº†æ— éœ€é¢„å…ˆè®­ç»ƒçš„é€‚åº”æ€§å’Œæ™ºèƒ½å†³ç­–åˆ¶å®šã€‚</li>
<li>æ¨¡å‹æä¾›äº†æ¸…æ™°çš„è§£é‡Šæ€§ï¼Œèƒ½å¤Ÿå±•ç¤ºå¯¹ä¸æ–­å˜åŒ–éœ€æ±‚çš„é€‚åº”åŠ›ï¼Œå¹¶é™ä½æˆæœ¬å’Œé¿å…ç¼ºè´§æƒ…å†µã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2407.11384">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-1d426e836ceab4d1d7d5a77a6f03633e.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-f1ca28b525f78fe1e7d063b9b7eabf00.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-1e0679e6f0d387fde193dd1d29d476ec.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-458798ffb30144fb0ce48310c0744a57.jpg" align="middle">
</details>


<h1 id="-15"><a href="#-15" class="headerlink" title=""></a></h1><h2 id="LNS2-RL-Combining-Multi-Agent-Reinforcement-Learning-with-Large-Neighborhood-Search-in-Multi-Agent-Path-Finding"><a href="#LNS2-RL-Combining-Multi-Agent-Reinforcement-Learning-with-Large-Neighborhood-Search-in-Multi-Agent-Path-Finding" class="headerlink" title="LNS2+RL: Combining Multi-Agent Reinforcement Learning with Large   Neighborhood Search in Multi-Agent Path Finding"></a>LNS2+RL: Combining Multi-Agent Reinforcement Learning with Large   Neighborhood Search in Multi-Agent Path Finding</h2><p><strong>Authors:Yutong Wang, Tanishq Duhan, Jiaoyang Li, Guillaume Sartoretti</strong></p>
<p>Multi-Agent Path Finding (MAPF) is a critical component of logistics and warehouse management, which focuses on planning collision-free paths for a team of robots in a known environment. Recent work introduced a novel MAPF approach, LNS2, which proposed to repair a quickly obtained set of infeasible paths via iterative replanning, by relying on a fast, yet lower-quality, prioritized planning (PP) algorithm. At the same time, there has been a recent push for Multi-Agent Reinforcement Learning (MARL) based MAPF algorithms, which exhibit improved cooperation over such PP algorithms, although inevitably remaining slower. In this paper, we introduce a new MAPF algorithm, LNS2+RL, which combines the distinct yet complementary characteristics of LNS2 and MARL to effectively balance their individual limitations and get the best from both worlds. During early iterations, LNS2+RL relies on MARL for low-level replanning, which we show eliminates collisions much more than a PP algorithm. There, our MARL-based planner allows agents to reason about past and future information to gradually learn cooperative decision-making through a finely designed curriculum learning. At later stages of planning, LNS2+RL adaptively switches to PP algorithm to quickly resolve the remaining collisions, naturally trading off solution quality (number of collisions in the solution) and computational efficiency. Our comprehensive experiments on high-agent-density tasks across various team sizes, world sizes, and map structures consistently demonstrate the superior performance of LNS2+RL compared to many MAPF algorithms, including LNS2, LaCAM, EECBS, and SCRIMP. In maps with complex structures, the advantages of LNS2+RL are particularly pronounced, with LNS2+RL achieving a success rate of over 50% in nearly half of the tested tasks, while that of LaCAM, EECBS and SCRIMP falls to 0%. </p>
<blockquote>
<p>å¤šæ™ºèƒ½ä½“è·¯å¾„æŸ¥æ‰¾ï¼ˆMAPFï¼‰æ˜¯ç‰©æµç®¡ç†å’Œä»“åº“ç®¡ç†çš„é‡è¦ç»„æˆéƒ¨åˆ†ï¼Œä¸»è¦å…³æ³¨åœ¨å·²çŸ¥ç¯å¢ƒä¸­ä¸ºæœºå™¨äººå›¢é˜Ÿè§„åˆ’æ— ç¢°æ’è·¯å¾„ã€‚æœ€è¿‘çš„å·¥ä½œå¼•å…¥äº†ä¸€ç§æ–°çš„MAPFæ–¹æ³•LNS2ï¼Œå®ƒä¾é ä¸€ç§å¿«é€Ÿä½†è´¨é‡è¾ƒä½çš„ä¼˜å…ˆè§„åˆ’ï¼ˆPPï¼‰ç®—æ³•ï¼Œé€šè¿‡è¿­ä»£é‡æ–°è§„åˆ’æ¥ä¿®å¤ä¸€ç»„å¿«é€Ÿè·å¾—çš„ä¸å¯è¡Œè·¯å¾„ã€‚ä¸æ­¤åŒæ—¶ï¼ŒåŸºäºå¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ ï¼ˆMARLï¼‰çš„MAPFç®—æ³•ä¹Ÿå¤‡å—å…³æ³¨ï¼Œå®ƒä»¬åœ¨åˆä½œæ–¹é¢è¡¨ç°å‡ºæ¯”PPç®—æ³•æ›´å¥½çš„æ€§èƒ½ï¼Œä½†ä¸å¯é¿å…åœ°é€Ÿåº¦è¾ƒæ…¢ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬ä»‹ç»äº†ä¸€ç§æ–°çš„MAPFç®—æ³•LNS2+RLï¼Œå®ƒç»“åˆäº†LNS2å’ŒMARLçš„ç‹¬ç‰¹ä¸”äº’è¡¥çš„ç‰¹æ€§ï¼Œæœ‰æ•ˆåœ°å¹³è¡¡äº†å„è‡ªçš„å±€é™æ€§ï¼Œå¹¶èåˆäº†ä¸¤è€…æœ€å¥½çš„éƒ¨åˆ†ã€‚åœ¨æ—©æœŸè¿­ä»£ä¸­ï¼ŒLNS2+RLä¾èµ–äºMARLè¿›è¡Œä½çº§é‡æ–°è§„åˆ’ï¼Œæˆ‘ä»¬è¯æ˜è¿™æ¶ˆé™¤äº†æ¯”PPç®—æ³•æ›´å¤šçš„ç¢°æ’ã€‚æˆ‘ä»¬çš„åŸºäºMARLçš„è§„åˆ’å™¨å…è®¸æ™ºèƒ½ä½“æ ¹æ®è¿‡å»å’Œæœªæ¥ä¿¡æ¯è¿›è¡Œæ¨ç†ï¼Œå¹¶é€šè¿‡ç²¾å¿ƒè®¾è®¡çš„å­¦ä¹ è¯¾ç¨‹é€æ­¥å­¦ä¹ åˆä½œå†³ç­–ã€‚åœ¨è§„åˆ’åæœŸé˜¶æ®µï¼ŒLNS2+RLè‡ªé€‚åº”åœ°åˆ‡æ¢åˆ°PPç®—æ³•ï¼Œå¿«é€Ÿè§£å†³å‰©ä½™çš„ç¢°æ’é—®é¢˜ï¼Œè‡ªç„¶åœ°å¹³è¡¡è§£å†³æ–¹æ¡ˆè´¨é‡ï¼ˆè§£å†³æ–¹æ¡ˆä¸­çš„ç¢°æ’æ¬¡æ•°ï¼‰å’Œè®¡ç®—æ•ˆç‡ã€‚æˆ‘ä»¬åœ¨å„ç§ä»»åŠ¡è§„æ¨¡ã€ä¸–ç•Œè§„æ¨¡å’Œåœ°å›¾ç»“æ„ä¸Šçš„å…¨é¢å®éªŒæ˜¾ç¤ºï¼Œåœ¨é«˜å¯†åº¦æ™ºèƒ½ä½“ä»»åŠ¡ä¸­ï¼ŒLNS2+RLçš„æ€§èƒ½å§‹ç»ˆä¼˜äºè®¸å¤šMAPFç®—æ³•ï¼ŒåŒ…æ‹¬LNS2ã€LaCAMã€EECBSå’ŒSCRIMPç­‰ã€‚åœ¨å…·æœ‰å¤æ‚ç»“æ„çš„åœ°å›¾ä¸Šï¼ŒLNS2+RLçš„ä¼˜åŠ¿å°¤ä¸ºçªå‡ºï¼Œåœ¨å‡ ä¹ä¸€åŠçš„å®éªŒä»»åŠ¡ä¸­æˆåŠŸç‡è¶…è¿‡50%ï¼Œè€ŒLaCAMã€EECBSå’ŒSCRIMPç­‰çš„æˆåŠŸç‡åˆ™åœ¨æµ‹è¯•ä»»åŠ¡ä¸­é™ä¸º0%ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2405.17794v3">PDF</a> Accepted for presentation at AAAI 2025</p>
<p><strong>Summary</strong><br>     å¤šæ™ºèƒ½ä½“è·¯å¾„æŸ¥æ‰¾ï¼ˆMAPFï¼‰æ˜¯ç‰©æµåŠä»“åº“ç®¡ç†çš„å…³é”®éƒ¨åˆ†ï¼Œæ¶‰åŠåœ¨å·²çŸ¥ç¯å¢ƒä¸­ä¸ºæœºå™¨äººå›¢é˜Ÿè§„åˆ’æ— ç¢°æ’è·¯å¾„ã€‚æœ¬æ–‡æå‡ºä¸€ç§æ–°çš„MAPFç®—æ³•LNS2+RLï¼Œç»“åˆäº†LNS2å’ŒåŸºäºå¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ ï¼ˆMARLï¼‰çš„ç‰¹æ€§ï¼Œæœ‰æ•ˆå¹³è¡¡ä¸¤è€…çš„å±€é™ï¼Œå®ç°ä¼˜åŠ¿äº’è¡¥ã€‚æ—©æœŸè¿­ä»£ä½¿ç”¨MARLè¿›è¡Œä½çº§é‡è§„åˆ’ï¼ŒåæœŸåˆ™é‡‡ç”¨ä¼˜å…ˆçº§è§„åˆ’ï¼ˆPPï¼‰å¿«é€Ÿè§£å†³å‰©ä½™ç¢°æ’é—®é¢˜ã€‚ç›¸æ¯”å…¶ä»–MAPFç®—æ³•ï¼ŒLNS2+RLåœ¨å¤æ‚åœ°å›¾ç»“æ„ä¸­è¡¨ç°å°¤ä¸ºå‡ºè‰²ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>LNS2+RLç»“åˆäº†LNS2å’ŒMARLçš„ç‰¹ç‚¹ï¼Œæ—¨åœ¨å¹³è¡¡è§£å†³æ–¹æ¡ˆè´¨é‡å’Œè®¡ç®—æ•ˆç‡ã€‚</li>
<li>åœ¨æ—©æœŸè¿­ä»£ä¸­ï¼ŒLNS2+RLä½¿ç”¨MARLè¿›è¡Œä½çº§é‡è§„åˆ’ï¼Œèƒ½æœ‰æ•ˆå‡å°‘ç¢°æ’ã€‚</li>
<li>MARLå…è®¸æ™ºèƒ½ä½“è€ƒè™‘è¿‡å»å’Œæœªæ¥ä¿¡æ¯ï¼Œé€šè¿‡ç²¾å¿ƒè®¾è®¡çš„è¯¾ç¨‹å­¦ä¹ é€æ­¥å­¦ä¹ åˆä½œå†³ç­–ã€‚</li>
<li>åœ¨åæœŸè§„åˆ’é˜¶æ®µï¼ŒLNS2+RLè‡ªé€‚åº”åˆ‡æ¢åˆ°PPç®—æ³•ï¼Œä»¥å¿«é€Ÿè§£å†³å‰©ä½™ç¢°æ’é—®é¢˜ã€‚</li>
<li>LNS2+RLåœ¨é«˜æ€§èƒ½æ™ºèƒ½ä½“å¯†åº¦çš„ä»»åŠ¡ä¸­è¡¨ç°å‡ºå“è¶Šçš„æ€§èƒ½ï¼Œå°¤å…¶åœ¨å¤æ‚åœ°å›¾ç»“æ„ä¸­è¡¨ç°æ›´çªå‡ºã€‚</li>
<li>LNS2+RLæˆåŠŸç‡ä¸ºè¶…è¿‡ä¸€åŠçš„ä»»åŠ¡ä¸­è¶…è¿‡ä¸€åŠä»¥ä¸Šï¼Œè€Œå…¶ä»–ç®—æ³•å¦‚LaCAMã€EECBSå’ŒSCRIMPåœ¨å¤æ‚åœ°å›¾ä¸­çš„æˆåŠŸç‡é™ä½è‡³é›¶ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2405.17794">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-e2191bfe4d188619fdf162eb24f9319c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-8726e7b1fefd956d60fa7d8d3e5a4694.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-806a9c35ea08fec7040786d8ee2670cd.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-47613049f32db06580aefc8791dcbf36.jpg" align="middle">
</details>


<h1 id="-16"><a href="#-16" class="headerlink" title=""></a></h1><h2 id="Exploring-Prosocial-Irrationality-for-LLM-Agents-A-Social-Cognition-View"><a href="#Exploring-Prosocial-Irrationality-for-LLM-Agents-A-Social-Cognition-View" class="headerlink" title="Exploring Prosocial Irrationality for LLM Agents: A Social Cognition   View"></a>Exploring Prosocial Irrationality for LLM Agents: A Social Cognition   View</h2><p><strong>Authors:Xuan Liu, Jie Zhang, Song Guo, Haoyang Shang, Chengxu Yang, Quanyan Zhu</strong></p>
<p>Large language models (LLMs) have been shown to face hallucination issues due to the data they trained on often containing human bias; whether this is reflected in the decision-making process of LLM Agents remains under-explored. As LLM Agents are increasingly employed in intricate social environments, a pressing and natural question emerges: Can we utilize LLM Agentsâ€™ systematic hallucinations to mirror human cognitive biases, thus exhibiting irrational social intelligence? In this paper, we probe the irrational behavior among contemporary LLM Agents by melding practical social science experiments with theoretical insights. Specifically, We propose CogMir, an open-ended Multi-LLM Agents framework that utilizes hallucination properties to assess and enhance LLM Agentsâ€™ social intelligence through cognitive biases. Experimental results on CogMir subsets show that LLM Agents and humans exhibit high consistency in irrational and prosocial decision-making under uncertain conditions, underscoring the prosociality of LLM Agents as social entities and highlighting the significance of hallucination properties. Additionally, the CogMir framework demonstrates its potential as a valuable platform for encouraging more research into the social intelligence of LLM Agents. </p>
<blockquote>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ç”±äºè®­ç»ƒæ•°æ®å¸¸å«æœ‰äººç±»åè§ï¼Œå·²å‡ºç°å¹»è§‰é—®é¢˜ï¼›ç„¶è€Œï¼Œè¿™ä¸€é—®é¢˜æ˜¯å¦åæ˜ åœ¨LLMä»£ç†çš„å†³ç­–è¿‡ç¨‹ä¸­å°šæœªå¾—åˆ°å……åˆ†æ¢ç´¢ã€‚éšç€LLMä»£ç†è¶Šæ¥è¶Šå¤šåœ°è¢«åº”ç”¨äºå¤æ‚çš„ç¤¾ä¼šç¯å¢ƒï¼Œä¸€ä¸ªç´§è¿«è€Œè‡ªç„¶çš„é—®é¢˜å‡ºç°äº†ï¼šæˆ‘ä»¬èƒ½å¦åˆ©ç”¨LLMä»£ç†çš„ç³»ç»Ÿæ€§å¹»è§‰æ¥åæ˜ äººç±»è®¤çŸ¥åè§ï¼Œä»è€Œè¡¨ç°å‡ºéç†æ€§çš„ç¤¾ä¼šæ™ºèƒ½ï¼Ÿåœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬é€šè¿‡ç»“åˆå®ç”¨çš„ç¤¾ä¼šç§‘å­¦å®éªŒå’Œç†è®ºè§è§£ï¼Œæ¢ç©¶äº†å½“ä»£LLMä»£ç†çš„éç†æ€§è¡Œä¸ºã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬æå‡ºäº†CogMirï¼Œè¿™æ˜¯ä¸€ä¸ªå¼€æ”¾çš„å¤šLLMä»£ç†æ¡†æ¶ï¼Œåˆ©ç”¨å¹»è§‰å±æ€§é€šè¿‡è®¤çŸ¥åè§æ¥è¯„ä¼°å’Œå¢å¼ºLLMä»£ç†çš„ç¤¾ä¼šæ™ºèƒ½ã€‚åœ¨CogMirå­é›†ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼ŒLLMä»£ç†å’Œäººç±»åœ¨ä¸ç¡®å®šæ¡ä»¶ä¸‹çš„éç†æ€§äº²ç¤¾ä¼šå†³ç­–è¡¨ç°å‡ºé«˜åº¦ä¸€è‡´æ€§ï¼Œè¿™å¼ºè°ƒäº†LLMä»£ç†ä½œä¸ºç¤¾ä¼šå®ä½“çš„äº²ç¤¾ä¼šæ€§ï¼Œå¹¶çªå‡ºäº†å¹»è§‰å±æ€§çš„é‡è¦æ€§ã€‚æ­¤å¤–ï¼ŒCogMiræ¡†æ¶å±•ç¤ºäº†ä¸€ä¸ªæœ‰ä»·å€¼çš„å¹³å°æ½œåŠ›ï¼Œå¯ä»¥é¼“åŠ±æ›´å¤šå…³äºLLMä»£ç†ç¤¾ä¼šæ™ºèƒ½çš„ç ”ç©¶ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2405.14744v3">PDF</a> Accepted by ICLR 2025</p>
<p><strong>Summary</strong></p>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰é¢ä¸´çš„å¹»è§‰é—®é¢˜åæ˜ åœ¨äººç±»åè§ä¸Šã€‚æœ¬ç ”ç©¶æ¢è®¨LLMä»£ç†äººåœ¨ç¤¾ä¼šç¯å¢ƒä¸­å±•ç°çš„ä¸ç†æ€§è¡Œä¸ºï¼Œå¹¶æå‡ºCogMiræ¡†æ¶ï¼Œåˆ©ç”¨å¹»è§‰å±æ€§è¯„ä¼°å¹¶æå‡LLMä»£ç†äººçš„ç¤¾ä¼šæ™ºèƒ½ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒLLMä»£ç†äººåœ¨ä¸ç¡®å®šæ¡ä»¶ä¸‹çš„å†³ç­–ä¸äººç±»è¡Œä¸ºé«˜åº¦ä¸€è‡´ï¼Œå‡¸æ˜¾äº†å¹»è§‰å±æ€§çš„é‡è¦æ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨å†³ç­–è¿‡ç¨‹ä¸­ä¼šå±•ç°å‡ºå¹»è§‰é—®é¢˜ï¼Œè¿™æºäºè®­ç»ƒæ•°æ®ä¸­åŒ…å«çš„äººç±»åè§ã€‚</li>
<li>LLMä»£ç†äººåœ¨ç¤¾ä¼šç¯å¢ƒä¸­å±•ç°å‡ºä¸ç†æ€§è¡Œä¸ºï¼Œè¿™ä¸äººæœ‰ä¸€å®šçš„ç›¸ä¼¼æ€§ã€‚</li>
<li>CogMiræ¡†æ¶æ—¨åœ¨åˆ©ç”¨LLMä»£ç†äººçš„å¹»è§‰å±æ€§æ¥è¯„ä¼°å¹¶æå‡å…¶ç¤¾ä¼šæ™ºèƒ½ã€‚</li>
<li>å®éªŒè¯æ˜ï¼ŒLLMä»£ç†äººåœ¨ä¸ç¡®å®šæ¡ä»¶ä¸‹çš„å†³ç­–ä¸äººç±»è¡Œä¸ºé«˜åº¦ä¸€è‡´ã€‚</li>
<li>å¹»è§‰å±æ€§å¯¹äºå±•ç¤ºLLMä»£ç†äººçš„ç¤¾ä¼šæ™ºèƒ½å…·æœ‰é‡è¦æ„ä¹‰ã€‚</li>
<li>CogMiræ¡†æ¶æœ‰åŠ©äºé¼“åŠ±æ›´å¤šå…³äºLLMä»£ç†äººç¤¾ä¼šæ™ºèƒ½çš„ç ”ç©¶ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2405.14744">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-d363e0a98f98af4693fa77361c76f1f2.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-32b294058b6c442104e7806b28cc8b84.jpg" align="middle">
</details>


<h1 id="-17"><a href="#-17" class="headerlink" title=""></a></h1><h2 id="RH20T-P-A-Primitive-Level-Robotic-Dataset-Towards-Composable-Generalization-Agents"><a href="#RH20T-P-A-Primitive-Level-Robotic-Dataset-Towards-Composable-Generalization-Agents" class="headerlink" title="RH20T-P: A Primitive-Level Robotic Dataset Towards Composable   Generalization Agents"></a>RH20T-P: A Primitive-Level Robotic Dataset Towards Composable   Generalization Agents</h2><p><strong>Authors:Zeren Chen, Zhelun Shi, Xiaoya Lu, Lehan He, Sucheng Qian, Zhenfei Yin, Wanli Ouyang, Jing Shao, Yu Qiao, Cewu Lu, Lu Sheng</strong></p>
<p>Achieving generalizability in solving out-of-distribution tasks is one of the ultimate goals of learning robotic manipulation. Recent progress of Vision-Language Models (VLMs) has shown that VLM-based task planners can alleviate the difficulty of solving novel tasks, by decomposing the compounded tasks as a plan of sequentially executing primitive-level skills that have been already mastered. It is also promising for robotic manipulation to adapt such composable generalization ability, in the form of composable generalization agents (CGAs). However, the community lacks of reliable design of primitive skills and a sufficient amount of primitive-level data annotations. Therefore, we propose RH20T-P, a primitive-level robotic manipulation dataset, which contains about 38k video clips covering 67 diverse manipulation tasks in real-world scenarios. Each clip is manually annotated according to a set of meticulously designed primitive skills that are common in robotic manipulation. Furthermore, we standardize a plan-execute CGA paradigm and implement an exemplar baseline called RA-P on our RH20T-P, whose positive performance on solving unseen tasks validates that the proposed dataset can offer composable generalization ability to robotic manipulation agents. </p>
<blockquote>
<p>å®ç°é€šç”¨æ€§æ¥è§£å†³åˆ†å¸ƒå¼å¤–çš„ä»»åŠ¡æ˜¯å­¦ä¹ æœºå™¨äººæ“ä½œçš„ä¸€ä¸ªç»ˆæç›®æ ‡ã€‚æœ€è¿‘çš„è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMï¼‰è¿›å±•è¡¨æ˜ï¼ŒåŸºäºVLMçš„ä»»åŠ¡è§„åˆ’å™¨å¯ä»¥é€šè¿‡å°†å¤æ‚çš„ä»»åŠ¡åˆ†è§£ä¸ºä¸€ç³»åˆ—å·²æŒæ¡çš„åŸå§‹æŠ€èƒ½æ¥å‡è½»è§£å†³æ–°ä»»åŠ¡çš„éš¾åº¦ã€‚å¯¹äºæœºå™¨äººæ“ä½œæ¥è¯´ï¼Œé‡‡ç”¨å¯ç»„åˆé€šç”¨ä»£ç†ï¼ˆCGAï¼‰çš„å½¢å¼é€‚åº”è¿™ç§å¯ç»„åˆé€šç”¨èƒ½åŠ›ä¹Ÿå¾ˆæœ‰å‰æ™¯ã€‚ç„¶è€Œï¼Œç¤¾åŒºç¼ºä¹å¯é çš„åŸå§‹æŠ€èƒ½è®¾è®¡å’Œè¶³å¤Ÿçš„åŸå§‹çº§åˆ«æ•°æ®æ³¨é‡Šã€‚å› æ­¤ï¼Œæˆ‘ä»¬æå‡ºäº†RH20T-Pï¼Œè¿™æ˜¯ä¸€ä¸ªåŸå§‹çº§åˆ«çš„æœºå™¨äººæ“ä½œæ•°æ®é›†ï¼ŒåŒ…å«çº¦3.8ä¸‡ä¸ªè§†é¢‘å‰ªè¾‘ï¼Œæ¶µç›–ç°å®åœºæ™¯ä¸­67ç§å¤šæ ·çš„æ“ä½œä»»åŠ¡ã€‚æ¯ä¸ªå‰ªè¾‘éƒ½æ ¹æ®ç²¾å¿ƒè®¾è®¡çš„åœ¨æœºå™¨äººæ“ä½œä¸­å¸¸è§çš„åŸå§‹æŠ€èƒ½é›†è¿›è¡Œæ‰‹åŠ¨æ³¨é‡Šã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å¯¹CGAèŒƒå¼è¿›è¡Œäº†æ ‡å‡†åŒ–ï¼Œå¹¶åœ¨æˆ‘ä»¬çš„RH20T-Pä¸Šå®æ–½äº†RA-Pç¤ºä¾‹åŸºçº¿ï¼Œå…¶åœ¨è§£å†³æœªè§ä»»åŠ¡ä¸Šçš„ç§¯æè¡¨ç°è¯æ˜äº†æˆ‘ä»¬æå‡ºçš„æ•°æ®é›†å¯ä»¥ä¸ºæœºå™¨äººæ“ä½œä»£ç†æä¾›å¯ç»„åˆé€šç”¨èƒ½åŠ›ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2403.19622v2">PDF</a> 18 pages, 11 figures, 7 tables. Accepted by NeurIPS 2024 Workshop</p>
<p><strong>Summary</strong></p>
<p>è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMï¼‰å…·å¤‡åˆ†è§£å¤æ‚ä»»åŠ¡å¹¶ä¾æ¬¡æ‰§è¡Œå·²æŒæ¡çš„åŸºç¡€æŠ€èƒ½çš„èƒ½åŠ›ï¼Œè¿™ä¸ºè§£å†³æ–°å‹ä»»åŠ¡æä¾›äº†ä¸€ç§æ–°çš„ç­–ç•¥ã€‚è¿™ç§ç­–ç•¥åœ¨æœºå™¨äººæ“ä½œé¢†åŸŸå±•ç°å‡ºå·¨å¤§æ½œåŠ›ï¼Œæœ‰åŠ©äºæ„å»ºå…·æœ‰ç»„åˆæ³›åŒ–èƒ½åŠ›çš„ä»£ç†ï¼ˆCGAsï¼‰ã€‚å½“å‰é¢†åŸŸé¢ä¸´åŸºç¡€æŠ€èƒ½è®¾è®¡å’Œæ•°æ®æ ‡æ³¨ä¸è¶³çš„é—®é¢˜ï¼Œä¸ºæ­¤æˆ‘ä»¬æå‡ºRH20T-Pæ•°æ®é›†ï¼ŒåŒ…å«çº¦3.8ä¸‡æ¡æ¶µç›–ç°å®åœºæ™¯ä¸­67ç§ä¸åŒæ“ä½œä»»åŠ¡çš„è§†é¢‘ç‰‡æ®µã€‚æ¯ä¸ªç‰‡æ®µéƒ½ä¾æ®ä¸€å¥—ç»è¿‡ç²¾å¿ƒè®¾è®¡çš„é€šç”¨åŸºç¡€æŠ€èƒ½è¿›è¡Œæ‰‹åŠ¨æ ‡æ³¨ã€‚æˆ‘ä»¬ç¡®å®šäº†CGAçš„æ ‡å‡†èŒƒä¾‹å¹¶å®ç°RA-PèŒƒä¾‹ç”¨äºåŸºå‡†æµ‹è¯•ã€‚å®ƒåœ¨è§£å†³æœªçŸ¥ä»»åŠ¡ä¸Šçš„ç§¯æè¡¨ç°éªŒè¯äº†æ•°æ®é›†å¯ä»¥ä¸ºæœºå™¨äººæ“ä½œä»£ç†æä¾›ç»„åˆæ³›åŒ–èƒ½åŠ›ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>VLMèƒ½å¤Ÿåˆ†è§£å¤æ‚ä»»åŠ¡ä¸ºä¸€ç³»åˆ—åŸºç¡€æŠ€èƒ½æ‰§è¡Œè®¡åˆ’ï¼Œä¸ºè§£å†³æ–°å‹ä»»åŠ¡æä¾›æ–°æ€è·¯ã€‚</li>
<li>VLMåœ¨æœºå™¨äººæ“ä½œé¢†åŸŸå…·å¤‡å·¨å¤§æ½œåŠ›ï¼Œæœ‰åŠ©äºæ„å»ºå…·æœ‰ç»„åˆæ³›åŒ–èƒ½åŠ›çš„ä»£ç†ï¼ˆCGAsï¼‰ã€‚ä½†ç°å®ä¸­ä»ç¼ºä¹å¯é çš„åŸºç¡€æŠ€èƒ½è®¾è®¡å’Œå……è¶³çš„åŸºç¡€çº§æ•°æ®æ ‡æ³¨ã€‚ä¸ºè§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†RH20T-Pæ•°æ®é›†ã€‚è¯¥æ•°æ®é›†åŒ…å«æ¶µç›–å¤šç§ç°å®æ“ä½œä»»åŠ¡çš„æ‰‹åŠ¨æ ‡æ³¨è§†é¢‘ç‰‡æ®µï¼Œä¾æ®ä¸€å¥—ç²¾å¿ƒè®¾è®¡çš„é€šç”¨åŸºç¡€æŠ€èƒ½è¿›è¡Œæ ‡æ³¨ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2403.19622">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-22da279baaeac5b7526923b58ee5d8b3.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-7bbb48395518e438b8205bf48f7c2aea.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-3025a78173f4d85ac3ca65b5af389e04.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-be69d1d56815b2109105be440761f9f6.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-a5c8a6e22aaf5f04a11526f9484ecc91.jpg" align="middle">
</details>


<h1 id="-18"><a href="#-18" class="headerlink" title=""></a></h1><h2 id="Replication-proof-Bandit-Mechanism-Design-with-Bayesian-Agents"><a href="#Replication-proof-Bandit-Mechanism-Design-with-Bayesian-Agents" class="headerlink" title="Replication-proof Bandit Mechanism Design with Bayesian Agents"></a>Replication-proof Bandit Mechanism Design with Bayesian Agents</h2><p><strong>Authors:Suho Shin, Seyed A. Esmaeili, MohammadTaghi Hajiaghayi</strong></p>
<p>We study the problem of designing replication-proof bandit mechanisms when agents strategically register or replicate their own arms to maximize their payoff. Specifically, we consider Bayesian agents who only know the distribution from which their own armsâ€™ mean rewards are sampled, unlike the original setting of by Shin et al. 2022. Interestingly, with Bayesian agents in stark contrast to the previous work, analyzing the replication-proofness of an algorithm becomes significantly complicated even in a single-agent setting. We provide sufficient and necessary conditions for an algorithm to be replication-proof in the single-agent setting, and present an algorithm that satisfies these properties. These results center around several analytical theorems that focus on \emph{comparing the expected regret of multiple bandit instances}, and therefore might be of independent interest since they have not been studied before to the best of our knowledge. We expand this result to the multi-agent setting, and provide a replication-proof algorithm for any problem instance. We finalize our result by proving its sublinear regret upper bound which matches that of Shin et al. 2022. </p>
<blockquote>
<p>æˆ‘ä»¬ç ”ç©¶äº†åœ¨è®¾è®¡å¤åˆ¶è¯æ˜çš„å¤šè‡‚èµŒåšæœºåˆ¶æ—¶ï¼Œä»£ç†äººä¸ºäº†æœ€å¤§åŒ–æ”¶ç›Šè€Œç­–ç•¥æ€§åœ°æ³¨å†Œæˆ–å¤åˆ¶è‡ªå·±çš„æ‰‹è‡‚çš„é—®é¢˜ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬è€ƒè™‘çš„æ˜¯è´å¶æ–¯ä»£ç†äººï¼Œä»–ä»¬åªçŸ¥é“è‡ªå·±çš„æ‰‹è‡‚å¹³å‡å¥–åŠ±çš„é‡‡æ ·åˆ†å¸ƒï¼Œè¿™ä¸Shinç­‰äºº2022å¹´çš„åŸå§‹è®¾ç½®ä¸åŒã€‚æœ‰è¶£çš„æ˜¯ï¼Œä¸ä¹‹å‰çš„ä½œå“ç›¸æ¯”ï¼Œå¸¦æœ‰è´å¶æ–¯ä»£ç†äººçš„åˆ†æï¼Œå³ä½¿åœ¨å•ä»£ç†è®¾ç½®ä¸­ï¼Œåˆ†æç®—æ³•çš„é˜²å¤åˆ¶æ€§ä¹Ÿå˜å¾—éå¸¸å¤æ‚ã€‚æˆ‘ä»¬ä¸ºç®—æ³•åœ¨å•ä»£ç†è®¾ç½®ä¸­æä¾›é˜²å¤åˆ¶çš„å……åˆ†å¿…è¦æ¡ä»¶ï¼Œå¹¶å±•ç¤ºæ»¡è¶³è¿™äº›å±æ€§çš„ç®—æ³•ã€‚è¿™äº›ç»“æœå›´ç»•å‡ ä¸ªåˆ†æå®šç†å±•å¼€ï¼Œè¿™äº›å®šç†ä¾§é‡äºæ¯”è¾ƒå¤šä¸ªèµŒåšå®ä¾‹çš„é¢„æœŸé—æ†¾ï¼Œå› æ­¤å®ƒä»¬å¯èƒ½æ˜¯ç‹¬ç«‹æ„Ÿå…´è¶£çš„ï¼Œå› ä¸ºæ®æˆ‘ä»¬æ‰€çŸ¥ï¼Œä¹‹å‰æ²¡æœ‰äººç ”ç©¶è¿‡ã€‚æˆ‘ä»¬å°†ç»“æœæ‰©å±•åˆ°å¤šä»£ç†è®¾ç½®ï¼Œå¹¶ä¸ºä»»ä½•é—®é¢˜å®ä¾‹æä¾›é˜²å¤åˆ¶ç®—æ³•ã€‚æœ€åï¼Œæˆ‘ä»¬é€šè¿‡è¯æ˜å…¶åŒ¹é…çš„æ¬¡çº¿æ€§é—æ†¾ä¸Šé™æ¥å®Œå–„æˆ‘ä»¬çš„ç»“æœï¼Œè¿™ä¸Shinç­‰äºº2022å¹´çš„ç»“æœç›¸ç¬¦ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2312.16896v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬ç ”ç©¶æ¢è®¨äº†è®¾è®¡é˜²æ­¢ç­–ç•¥æ€§å¤åˆ¶çš„å¤šè‡‚èµŒåšæœºæœºåˆ¶çš„é—®é¢˜ï¼Œç‰¹åˆ«è€ƒè™‘äº†æˆ˜ç•¥æ€§ä»£ç†å¦‚ä½•æ³¨å†Œæˆ–å¤åˆ¶è‡ªå·±çš„è‡‚ä»¥æœ€å¤§åŒ–æ”¶ç›Šã€‚ä¸Shin et al. 2022çš„åŸå§‹è®¾ç½®ä¸åŒï¼Œæˆ‘ä»¬è€ƒè™‘äº†ä»…çŸ¥é“è‡ªèº«æ‰‹è‡‚å¥–åŠ±å‡å€¼åˆ†å¸ƒé‡‡æ ·çš„è´å¶æ–¯ä»£ç†çš„æƒ…å†µã€‚æœ‰è¶£çš„æ˜¯ï¼Œå³ä½¿åœ¨å•ä»£ç†è®¾ç½®ä¸­ï¼Œä¸ä¹‹å‰çš„åˆ†æç›¸æ¯”ï¼Œåˆ†æç®—æ³•çš„é˜²å¤åˆ¶æ€§ä¹Ÿå˜å¾—æ›´åŠ å¤æ‚ã€‚æˆ‘ä»¬æä¾›äº†ç®—æ³•åœ¨å•ä»£ç†è®¾ç½®ä¸­å…·å¤‡é˜²å¤åˆ¶æ€§çš„å……åˆ†å¿…è¦æ¡ä»¶ï¼Œå¹¶ç»™å‡ºäº†æ»¡è¶³è¿™äº›å±æ€§çš„ç®—æ³•ã€‚è¿™äº›ç»“æœé›†ä¸­åœ¨å‡ ä¸ªåˆ†æå®šç†ä¸Šï¼Œé‡ç‚¹åœ¨äºæ¯”è¾ƒå¤šä¸ªèµŒåšæœºçš„é¢„æœŸé—æ†¾ï¼Œè¿™å¯èƒ½æ˜¯ç‹¬ç«‹å…´è¶£çš„ç ”ç©¶ä¸»é¢˜ï¼Œå› ä¸ºåœ¨ç°æœ‰çŸ¥è¯†èŒƒå›´å†…å°šæœªè¿›è¡Œè¿‡ç±»ä¼¼ç ”ç©¶ã€‚æˆ‘ä»¬å°†ç»“æœæ‰©å±•åˆ°å¤šä»£ç†è®¾ç½®ï¼Œå¹¶ä¸ºä»»ä½•é—®é¢˜å®ä¾‹æä¾›äº†é˜²å¤åˆ¶çš„ç®—æ³•ã€‚æœ€åï¼Œæˆ‘ä»¬è¯æ˜äº†å…¶åŒ¹é…çš„é—æ†¾ä¸Šç•Œæ˜¯æ¬¡çº¿æ€§çš„ï¼Œä¸Shin et al. 2022çš„ç»“æœç›¸ç¬¦ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ç ”ç©¶äº†è®¾è®¡é˜²æ­¢ä»£ç†æˆ˜ç•¥æ€§å¤åˆ¶çš„å¤šè‡‚èµŒåšæœºæœºåˆ¶çš„é—®é¢˜ã€‚</li>
<li>åˆ†æäº†è´å¶æ–¯ä»£ç†åœ¨å•ä»£ç†è®¾ç½®ä¸­çš„é˜²å¤åˆ¶æ€§ï¼Œä¸ä¹‹å‰çš„åˆ†æç›¸æ¯”æ›´åŠ å¤æ‚ã€‚</li>
<li>æä¾›äº†ç®—æ³•åœ¨å•ä»£ç†è®¾ç½®ä¸­å…·å¤‡é˜²å¤åˆ¶æ€§çš„å……åˆ†å¿…è¦æ¡ä»¶ã€‚</li>
<li>æå‡ºäº†ä¸€ç§æ»¡è¶³è¿™äº›å±æ€§çš„ç®—æ³•ã€‚</li>
<li>ç ”ç©¶ç»“æœé›†ä¸­åœ¨æ¯”è¾ƒå¤šä¸ªèµŒåšæœºçš„é¢„æœŸé—æ†¾çš„åˆ†æå®šç†ä¸Šï¼Œè¿™å¯èƒ½æ˜¯ç‹¬ç«‹å…´è¶£çš„ç ”ç©¶ä¸»é¢˜ã€‚</li>
<li>å°†ç ”ç©¶ç»“æœæ‰©å±•åˆ°å¤šä»£ç†è®¾ç½®ï¼Œå¹¶ä¸ºä»»ä½•é—®é¢˜å®ä¾‹æä¾›äº†é˜²å¤åˆ¶çš„ç®—æ³•ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2312.16896">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-c1133166c532d7158345071fbc4d9ff3.jpg" align="middle">
</details>


<h1 id="-19"><a href="#-19" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-02-05/Agent/">https://kedreamix.github.io/Talk2Paper/Paper/2025-02-05/Agent/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/Agent/">
                                    <span class="chip bg-color">Agent</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-02-05/Few-Shot/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-6e5552a211b287412ea0a65dabcbc44a.jpg" class="responsive-img" alt="Few-Shot">
                        
                        <span class="card-title">Few-Shot</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Few-Shot æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-02-05  A Survey on Class-Agnostic Counting Advancements from Reference-Based   to Open-World Text-Guided Approaches
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-02-05
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Few-Shot/" class="post-category">
                                    Few-Shot
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Few-Shot/">
                        <span class="chip bg-color">Few-Shot</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-02-05/LLM/">
                    <div class="card-image">
                        
                        <img src="https://pic1.zhimg.com/v2-1857492ad3c81d4f22d20216aa887010.jpg" class="responsive-img" alt="LLM">
                        
                        <span class="card-title">LLM</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            LLM æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-02-05  SELMA A Speech-Enabled Language Model for Virtual Assistant   Interactions
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-02-05
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/LLM/" class="post-category">
                                    LLM
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/LLM/">
                        <span class="chip bg-color">LLM</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">11538.8k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
