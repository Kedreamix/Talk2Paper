<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Few-Shot">
    <meta name="description" content="Few-Shot æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-02-05  A Survey on Class-Agnostic Counting Advancements from Reference-Based   to Open-World Text-Guided Approaches">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>Few-Shot | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://picx.zhimg.com/v2-6e5552a211b287412ea0a65dabcbc44a.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Few-Shot</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/Few-Shot/">
                                <span class="chip bg-color">Few-Shot</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/Few-Shot/" class="post-category">
                                Few-Shot
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-02-05
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-02-05
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    11.3k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    46 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-02-05-æ›´æ–°"><a href="#2025-02-05-æ›´æ–°" class="headerlink" title="2025-02-05 æ›´æ–°"></a>2025-02-05 æ›´æ–°</h1><h2 id="A-Survey-on-Class-Agnostic-Counting-Advancements-from-Reference-Based-to-Open-World-Text-Guided-Approaches"><a href="#A-Survey-on-Class-Agnostic-Counting-Advancements-from-Reference-Based-to-Open-World-Text-Guided-Approaches" class="headerlink" title="A Survey on Class-Agnostic Counting: Advancements from Reference-Based   to Open-World Text-Guided Approaches"></a>A Survey on Class-Agnostic Counting: Advancements from Reference-Based   to Open-World Text-Guided Approaches</h2><p><strong>Authors:Luca Ciampi, Ali Azmoudeh, Elif Ecem Akbaba, Erdi SarÄ±taÅŸ, Ziya Ata YazÄ±cÄ±, HazÄ±m Kemal Ekenel, Giuseppe Amato, Fabrizio Falchi</strong></p>
<p>Object counting has recently shifted towards class-agnostic counting (CAC), which addresses the challenge of counting objects across arbitrary categories, tackling a critical need in versatile counting systems. While humans effortlessly identify and count objects from diverse categories without prior knowledge, most counting methods remain restricted to enumerating instances of known classes, requiring extensive labeled datasets for training, and struggling under open-vocabulary settings. Conversely, CAC aims to count objects belonging to classes never seen during training, typically operating in a few-shot setting. In this paper, for the first time, we review advancements in CAC methodologies, categorizing them into three paradigms based on how target object classes can be specified: reference-based, reference-less, and open-world text-guided. Reference-based approaches have set performance benchmarks using exemplar-guided mechanisms. Reference-less methods eliminate exemplar dependency by leveraging inherent image patterns. Finally, open-world text-guided methods utilize vision-language models, enabling object class descriptions through textual prompts, representing a flexible and appealing solution. We analyze state-of-the-art techniques and we report their results on existing gold standard benchmarks, comparing their performance and identifying and discussing their strengths and limitations. Persistent challenges â€“ such as annotation dependency, scalability, and generalization â€“ are discussed, alongside future directions. We believe this survey serves as a valuable resource for researchers to understand the progressive developments and contributions over time and the current state-of-the-art of CAC, suggesting insights for future directions and challenges to be addressed. </p>
<blockquote>
<p>å¯¹è±¡è®¡æ•°æœ€è¿‘å·²ç»è½¬å‘ç±»åˆ«æœªçŸ¥è®¡æ•°ï¼ˆCACï¼‰ï¼Œè¿™è§£å†³äº†è·¨ä»»æ„ç±»åˆ«è®¡æ•°å¯¹è±¡çš„æŒ‘æˆ˜ï¼Œæ»¡è¶³äº†é€šç”¨è®¡æ•°ç³»ç»Ÿçš„è¿«åˆ‡éœ€æ±‚ã€‚è™½ç„¶äººç±»èƒ½å¤Ÿæ¯«ä¸è´¹åŠ›åœ°è¯†åˆ«å¹¶è®¡ç®—æ¥è‡ªä¸åŒç±»åˆ«çš„å¯¹è±¡æ•°é‡ï¼Œè€Œæ— éœ€äº‹å…ˆçŸ¥è¯†ï¼Œä½†å¤§å¤šæ•°è®¡æ•°æ–¹æ³•ä»ç„¶ä»…é™äºè®¡ç®—å·²çŸ¥ç±»åˆ«çš„å®ä¾‹æ•°é‡ï¼Œéœ€è¦å¹¿æ³›çš„æœ‰æ ‡ç­¾æ•°æ®é›†è¿›è¡Œè®­ç»ƒï¼Œå¹¶ä¸”åœ¨å¼€æ”¾è¯æ±‡è®¾ç½®ä¸‹é‡åˆ°æŒ‘æˆ˜ã€‚ç›¸åï¼ŒCACæ—¨åœ¨è®¡ç®—å±äºåœ¨è®­ç»ƒæœŸé—´æœªè§è¿‡çš„ç±»åˆ«çš„å¯¹è±¡æ•°é‡ï¼Œé€šå¸¸è¿è¡Œåœ¨å°‘é‡æ ·æœ¬è®¾ç½®ä¸‹ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬é¦–æ¬¡å›é¡¾äº†CACæ–¹æ³•çš„å‘å±•ï¼Œæ ¹æ®ç›®æ ‡å¯¹è±¡ç±»åˆ«çš„æŒ‡å®šæ–¹å¼å°†å®ƒä»¬åˆ†ä¸ºä¸‰ç§èŒƒå¼ï¼šåŸºäºå‚è€ƒã€æ— å‚è€ƒå’Œå¼€æ”¾ä¸–ç•Œæ–‡æœ¬å¼•å¯¼ã€‚åŸºäºå‚è€ƒçš„æ–¹æ³•ä½¿ç”¨ç¤ºä¾‹å¼•å¯¼æœºåˆ¶è®¾å®šäº†æ€§èƒ½åŸºå‡†ã€‚æ— å‚è€ƒæ–¹æ³•é€šè¿‡åˆ©ç”¨å›ºæœ‰çš„å›¾åƒæ¨¡å¼æ¥æ¶ˆé™¤å¯¹ç¤ºä¾‹çš„ä¾èµ–ã€‚æœ€åï¼Œå¼€æ”¾ä¸–ç•Œæ–‡æœ¬å¼•å¯¼çš„æ–¹æ³•åˆ©ç”¨è§†è§‰è¯­è¨€æ¨¡å‹ï¼Œé€šè¿‡æ–‡æœ¬æç¤ºå®ç°å¯¹è±¡ç±»åˆ«æè¿°ï¼Œä»£è¡¨äº†ä¸€ç§çµæ´»ä¸”æœ‰å¸å¼•åŠ›çš„è§£å†³æ–¹æ¡ˆã€‚æˆ‘ä»¬åˆ†æäº†æœ€æ–°æŠ€æœ¯ï¼Œå¹¶åœ¨ç°æœ‰çš„é»„é‡‘æ ‡å‡†åŸºå‡†æµ‹è¯•ä¸ŠæŠ¥å‘Šäº†å®ƒä»¬çš„æˆæœï¼Œæ¯”è¾ƒäº†å®ƒä»¬çš„æ€§èƒ½ï¼Œå¹¶è®¨è®ºå’Œåˆ†æäº†å®ƒä»¬çš„ä¼˜ç¼ºç‚¹ã€‚è¿˜è®¨è®ºäº†æŒç»­çš„æŒ‘æˆ˜ï¼Œå¦‚æ³¨é‡Šä¾èµ–æ€§ã€å¯æ‰©å±•æ€§å’Œæ³›åŒ–æ€§ï¼Œä»¥åŠæœªæ¥çš„ç ”ç©¶æ–¹å‘ã€‚æˆ‘ä»¬ç›¸ä¿¡è¿™ä»½ç»¼è¿°å¯¹äºç ”ç©¶äººå‘˜äº†è§£CACçš„æ¸è¿›å‘å±•ã€è´¡çŒ®å’Œå½“å‰æœ€æ–°çŠ¶æ€éå¸¸æœ‰ä»·å€¼ï¼Œå¹¶ä¸ºæœªæ¥çš„ç ”ç©¶æ–¹å‘å’ŒæŒ‘æˆ˜æä¾›äº†è§è§£ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.19184v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ç»¼è¿°äº†ç±»æœªçŸ¥è®¡æ•°ï¼ˆCACï¼‰æ–¹æ³•çš„æœ€æ–°è¿›å±•ï¼Œå°†å…¶åˆ†ä¸ºä¸‰ç§åŸºäºç›®æ ‡ç±»åˆ«æŒ‡å®šæ–¹å¼çš„èŒƒå¼ï¼šåŸºäºå‚è€ƒçš„ã€æ— å‚è€ƒçš„å’Œå¼€æ”¾ä¸–ç•Œæ–‡æœ¬å¼•å¯¼çš„æ–¹æ³•ã€‚åŸºäºå‚è€ƒçš„æ–¹æ³•ä½¿ç”¨èŒƒä¾‹å¼•å¯¼æœºåˆ¶è®¾å®šæ€§èƒ½åŸºå‡†ï¼Œæ— å‚è€ƒæ–¹æ³•åˆ™åˆ©ç”¨å›¾åƒå†…åœ¨æ¨¡å¼æ¶ˆé™¤èŒƒä¾‹ä¾èµ–æ€§ï¼Œè€Œå¼€æ”¾ä¸–ç•Œæ–‡æœ¬å¼•å¯¼çš„æ–¹æ³•åˆ™åˆ©ç”¨è§†è§‰è¯­è¨€æ¨¡å‹ï¼Œé€šè¿‡æ–‡æœ¬æç¤ºå®ç°ç›®æ ‡ç±»åˆ«æè¿°ï¼Œä¸ºCACæä¾›äº†ä¸€ä¸ªçµæ´»ä¸”å…·å¸å¼•åŠ›çš„è§£å†³æ–¹æ¡ˆã€‚æ–‡ç« åˆ†æäº†æœ€æ–°æŠ€æœ¯å¹¶åœ¨ç°æœ‰æ ‡å‡†åŸºå‡†ä¸ŠæŠ¥å‘Šäº†ç»“æœï¼Œæ¯”è¾ƒäº†æ€§èƒ½ï¼ŒåŒæ—¶è®¨è®ºå’Œè¯†åˆ«äº†å„è‡ªçš„ä¼˜ç¼ºç‚¹ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ç±»æœªçŸ¥è®¡æ•°ï¼ˆCACï¼‰æ˜¯å¯¹è±¡è®¡æ•°é¢†åŸŸçš„æ–°è¶‹åŠ¿ï¼Œæ—¨åœ¨è§£å†³è·¨ä»»æ„ç±»åˆ«è®¡æ•°å¯¹è±¡çš„æŒ‘æˆ˜ã€‚</li>
<li>CACæ–¹æ³•åˆ†ä¸ºä¸‰ä¸ªåŸºäºç›®æ ‡ç±»åˆ«æŒ‡å®šæ–¹å¼çš„èŒƒå¼ï¼šåŸºäºå‚è€ƒã€æ— å‚è€ƒå’Œå¼€æ”¾ä¸–ç•Œæ–‡æœ¬å¼•å¯¼ã€‚</li>
<li>åŸºäºå‚è€ƒçš„æ–¹æ³•ä½¿ç”¨èŒƒä¾‹å¼•å¯¼æœºåˆ¶ï¼Œè®¾å®šäº†æ€§èƒ½åŸºå‡†ã€‚</li>
<li>æ— å‚è€ƒæ–¹æ³•åˆ©ç”¨å›¾åƒå†…åœ¨æ¨¡å¼ï¼Œæ¶ˆé™¤å¯¹èŒƒä¾‹çš„ä¾èµ–ã€‚</li>
<li>å¼€æ”¾ä¸–ç•Œæ–‡æœ¬å¼•å¯¼çš„æ–¹æ³•ä½¿ç”¨è§†è§‰è¯­è¨€æ¨¡å‹ï¼Œé€šè¿‡æ–‡æœ¬æç¤ºå®ç°ç›®æ ‡ç±»åˆ«æè¿°ï¼Œä¸ºCACæä¾›çµæ´»è§£å†³æ–¹æ¡ˆã€‚</li>
<li>ç°æœ‰æŠ€æœ¯é¢ä¸´æŒç»­æŒ‘æˆ˜ï¼Œå¦‚æ³¨é‡Šä¾èµ–æ€§ã€å¯æ‰©å±•æ€§å’Œæ³›åŒ–èƒ½åŠ›ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.19184">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-145f23e1925289060febbd5617b9acf3.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-491a1286959ee4ea224240df29efa28b.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-e267e207e324da9d3db85497c61affba.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-0932c7d84192b291dc3282be33cf9edc.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="Enhancing-Code-Generation-for-Low-Resource-Languages-No-Silver-Bullet"><a href="#Enhancing-Code-Generation-for-Low-Resource-Languages-No-Silver-Bullet" class="headerlink" title="Enhancing Code Generation for Low-Resource Languages: No Silver Bullet"></a>Enhancing Code Generation for Low-Resource Languages: No Silver Bullet</h2><p><strong>Authors:Alessandro Giagnorio, Alberto Martin-Lopez, Gabriele Bavota</strong></p>
<p>The advent of Large Language Models (LLMs) has significantly advanced the field of automated code generation. LLMs rely on large and diverse datasets to learn syntax, semantics, and usage patterns of programming languages. For low-resource languages (i.e., niche programming languages characterized by the scarcity of training data), the limited availability of such data hampers the modelsâ€™ ability to generalize effectively, resulting in poorer code generation performance as compared to high-resource languages. For this reason, there is a quest for techniques able to close this performance gap. We present an empirical study investigating the effectiveness of several approaches for boosting LLMsâ€™ performance on low-resource languages, namely: (i) a classic fine-tuning, which is however capped in size by the scarcity of training data; (ii) three variants of in-context learning, with prompts crafted to provide the LLM with additional information about the low-resource language (e.g., few-shot examples showcasing features of the targeted language); and (iii) a pre-training objective teaching the model how to translate between high- and low-resource languages. The context of our study are two low-resource languages (R and Racket) and six LLMs having different architectures and sizes. Our findings reveal that a fine-tuning is usually the best choice for smaller LLMs, possibly due to the fact that even a small dataset is sufficient to train their limited number of parameters. With the increase in size of the models, in-context learning becomes more and more effective, representing a safe and cheap bet (i.e., it always helps, but with different magnitudes). Differently, very large LLMs may deteriorate their performance on low-resource languages when fine-tuning is performed, possibly due to the lack of enough data needed to effectively update their weights. </p>
<blockquote>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„å‡ºç°ï¼Œæå¤§åœ°æ¨åŠ¨äº†è‡ªåŠ¨åŒ–ä»£ç ç”Ÿæˆé¢†åŸŸçš„å‘å±•ã€‚LLMä¾èµ–äºå¤§å‹å’Œå¤šæ ·åŒ–çš„æ•°æ®é›†æ¥å­¦ä¹ ç¼–ç¨‹è¯­è¨€çš„è¯­æ³•ã€è¯­ä¹‰å’Œä½¿ç”¨æ¨¡å¼ã€‚å¯¹äºèµ„æºåŒ®ä¹çš„è¯­è¨€ï¼ˆå³è®­ç»ƒæ•°æ®ç¨€ç¼ºçš„ä¸“æœ‰ç¼–ç¨‹è¯­è¨€ï¼‰ï¼Œæ­¤ç±»æ•°æ®çš„æœ‰é™å¯ç”¨æ€§é˜»ç¢äº†æ¨¡å‹æœ‰æ•ˆåœ°æ¨å¹¿ï¼Œä¸èµ„æºä¸°å¯Œçš„è¯­è¨€ç›¸æ¯”ï¼Œå¯¼è‡´è¾ƒå·®çš„ä»£ç ç”Ÿæˆæ€§èƒ½ã€‚å› æ­¤ï¼Œäººä»¬æ­£åœ¨å¯»æ‰¾èƒ½å¤Ÿç¼©å°è¿™ä¸€æ€§èƒ½å·®è·çš„æŠ€æœ¯ã€‚æˆ‘ä»¬è¿›è¡Œäº†ä¸€é¡¹å®è¯ç ”ç©¶ï¼Œæ¢è®¨äº†æé«˜LLMåœ¨èµ„æºåŒ®ä¹çš„è¯­è¨€ä¸Šçš„æ€§èƒ½çš„å‡ ç§æ–¹æ³•çš„æœ‰æ•ˆæ€§ï¼Œå³ï¼šï¼ˆiï¼‰ç»å…¸çš„å¾®è°ƒï¼Œä½†å—é™äºè®­ç»ƒæ•°æ®çš„ç¨€ç¼ºæ€§ï¼›ï¼ˆiiï¼‰ä¸‰ç§ä¸Šä¸‹æ–‡å­¦ä¹ å˜ä½“ï¼Œé€šè¿‡æç¤ºä¸ºLLMæä¾›æœ‰å…³ä½èµ„æºè¯­è¨€çš„é¢å¤–ä¿¡æ¯ï¼ˆä¾‹å¦‚ï¼Œå±•ç¤ºç›®æ ‡è¯­è¨€ç‰¹å¾çš„å‡ ä¸ªç¤ºä¾‹ï¼‰ï¼›ï¼ˆiiiï¼‰ä¸€ä¸ªé¢„è®­ç»ƒç›®æ ‡ï¼Œæ•™ä¼šæ¨¡å‹å¦‚ä½•åœ¨é«˜èµ„æºå’Œä½èµ„æºè¯­è¨€ä¹‹é—´è¿›è¡Œç¿»è¯‘ã€‚æˆ‘ä»¬ç ”ç©¶çš„èƒŒæ™¯æ˜¯ä¸¤ç§èµ„æºåŒ®ä¹çš„è¯­è¨€ï¼ˆRå’ŒRacketï¼‰å’Œå…­ç§å…·æœ‰ä¸åŒæ¶æ„å’Œè§„æ¨¡çš„LLMã€‚æˆ‘ä»¬çš„ç ”ç©¶ç»“æœè¡¨æ˜ï¼Œå¯¹äºè¾ƒå°çš„LLMï¼Œå¾®è°ƒé€šå¸¸æ˜¯æœ€ä½³é€‰æ‹©ï¼Œè¿™å¯èƒ½æ˜¯ç”±äºå³ä½¿å°æ•°æ®é›†ä¹Ÿè¶³ä»¥è®­ç»ƒå…¶æœ‰é™æ•°é‡çš„å‚æ•°ã€‚éšç€æ¨¡å‹è§„æ¨¡çš„å¢åŠ ï¼Œä¸Šä¸‹æ–‡å­¦ä¹ å˜å¾—è¶Šæ¥è¶Šæœ‰æ•ˆï¼Œæ˜¯ä¸€ä¸ªå®‰å…¨ä¸”ç»æµçš„é€‰æ‹©ï¼ˆå³å®ƒæ€»æ˜¯æœ‰å¸®åŠ©ï¼Œä½†ç¨‹åº¦ä¸åŒï¼‰ã€‚ä¸åŒçš„æ˜¯ï¼Œå¯¹äºéå¸¸å¤§çš„LLMï¼Œå½“è¿›è¡Œå¾®è°ƒæ—¶ï¼Œå…¶åœ¨èµ„æºåŒ®ä¹çš„è¯­è¨€ä¸Šçš„æ€§èƒ½å¯èƒ½ä¼šä¸‹é™ï¼Œè¿™å¯èƒ½æ˜¯ç”±äºç¼ºä¹è¶³å¤Ÿçš„æ•°æ®æ¥æœ‰æ•ˆåœ°æ›´æ–°å…¶æƒé‡ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.19085v1">PDF</a> Accepted at ICPCâ€™25</p>
<p><strong>Summary</strong></p>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨è‡ªåŠ¨ä»£ç ç”Ÿæˆé¢†åŸŸå–å¾—äº†æ˜¾è‘—è¿›å±•ï¼Œä½†åœ¨å¤„ç†ä½èµ„æºè¯­è¨€æ—¶é¢ä¸´æŒ‘æˆ˜ã€‚é’ˆå¯¹è¿™ä¸€é—®é¢˜ï¼Œæœ¬æ–‡æ¢è®¨äº†æå‡LLMåœ¨ä½èµ„æºè¯­è¨€ä¸Šæ€§èƒ½çš„æ–¹æ³•ï¼ŒåŒ…æ‹¬å¾®è°ƒã€ä¸Šä¸‹æ–‡å­¦ä¹ å’Œé¢„è®­ç»ƒç›®æ ‡ç­‰ç­–ç•¥ã€‚ç ”ç©¶å‘ç°ï¼Œå¯¹äºå°å‹LLMï¼Œå¾®è°ƒé€šå¸¸æ˜¯æœ€ä½³é€‰æ‹©ï¼›éšç€æ¨¡å‹è§„æ¨¡çš„å¢åŠ ï¼Œä¸Šä¸‹æ–‡å­¦ä¹ å˜å¾—æ›´åŠ æœ‰æ•ˆï¼›è€Œå¯¹äºéå¸¸å¤§çš„LLMï¼Œè¿‡åº¦å¾®è°ƒå¯èƒ½å¯¼è‡´æ€§èƒ½ä¸‹é™ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨è‡ªåŠ¨ä»£ç ç”Ÿæˆä¸Šè¡¨ç°å“è¶Šï¼Œä½†åœ¨å¤„ç†ä½èµ„æºè¯­è¨€æ—¶é¢ä¸´æŒ‘æˆ˜ã€‚</li>
<li>æœ‰é™çš„è®­ç»ƒæ•°æ®é™åˆ¶äº†LLMåœ¨ä½èµ„æºè¯­è¨€ä¸Šçš„æ€§èƒ½ã€‚</li>
<li>ç»å…¸å¾®è°ƒå—é™äºè®­ç»ƒæ•°æ®çš„ç¨€ç¼ºæ€§ï¼Œä½†å¯¹äºå°å‹LLMå¯èƒ½ä»æ˜¯æœ€ä¼˜é€‰æ‹©ã€‚</li>
<li>éšç€æ¨¡å‹è§„æ¨¡çš„å¢åŠ ï¼Œä¸Šä¸‹æ–‡å­¦ä¹ å˜å¾—æ›´åŠ æœ‰æ•ˆã€‚</li>
<li>é¢„è®­ç»ƒç›®æ ‡å¯ä»¥å¸®åŠ©æ¨¡å‹åœ¨ä½èµ„æºè¯­è¨€ä¸Šè¿›è¡Œç¿»è¯‘ã€‚</li>
<li>å¯¹äºéå¸¸å¤§çš„LLMï¼Œè¿‡åº¦å¾®è°ƒå¯èƒ½å¯¼è‡´æ€§èƒ½ä¸‹é™ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.19085">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-a9297ff527b475a1b96824d4e1b89c76.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-eb7c113e531204aad160fc9d5c3dc5c7.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-2c7b484fc65ea24d2fa2634289945db1.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="Memory-Efficient-Fine-Tuning-of-Transformers-via-Token-Selection"><a href="#Memory-Efficient-Fine-Tuning-of-Transformers-via-Token-Selection" class="headerlink" title="Memory-Efficient Fine-Tuning of Transformers via Token Selection"></a>Memory-Efficient Fine-Tuning of Transformers via Token Selection</h2><p><strong>Authors:Antoine Simoulin, Namyong Park, Xiaoyi Liu, Grey Yang</strong></p>
<p>Fine-tuning provides an effective means to specialize pre-trained models for various downstream tasks. However, fine-tuning often incurs high memory overhead, especially for large transformer-based models, such as LLMs. While existing methods may reduce certain parts of the memory required for fine-tuning, they still require caching all intermediate activations computed in the forward pass to update weights during the backward pass. In this work, we develop TokenTune, a method to reduce memory usage, specifically the memory to store intermediate activations, in the fine-tuning of transformer-based models. During the backward pass, TokenTune approximates the gradient computation by backpropagating through just a subset of input tokens. Thus, with TokenTune, only a subset of intermediate activations are cached during the forward pass. Also, TokenTune can be easily combined with existing methods like LoRA, further reducing the memory cost. We evaluate our approach on pre-trained transformer models with up to billions of parameters, considering the performance on multiple downstream tasks such as text classification and question answering in a few-shot learning setup. Overall, TokenTune achieves performance on par with full fine-tuning or representative memory-efficient fine-tuning methods, while greatly reducing the memory footprint, especially when combined with other methods with complementary memory reduction mechanisms. We hope that our approach will facilitate the fine-tuning of large transformers, in specializing them for specific domains or co-training them with other neural components from a larger system. Our code is available at <a target="_blank" rel="noopener" href="https://github.com/facebookresearch/tokentune">https://github.com/facebookresearch/tokentune</a>. </p>
<blockquote>
<p>å¾®è°ƒï¼ˆFine-tuningï¼‰ä¸ºé’ˆå¯¹å„ç§ä¸‹æ¸¸ä»»åŠ¡çš„ä¸“ä¸šåŒ–é¢„è®­ç»ƒæ¨¡å‹æä¾›äº†æœ‰æ•ˆçš„æ‰‹æ®µã€‚ç„¶è€Œï¼Œå¾®è°ƒé€šå¸¸ä¼šå¼•èµ·è¾ƒé«˜çš„å†…å­˜å¼€é”€ï¼Œå°¤å…¶æ˜¯å¯¹äºåŸºäºå¤§å‹å˜æ¢æ¨¡å‹çš„é¢„è®­ç»ƒæ¨¡å‹ï¼ˆå¦‚å¤§å‹è¯­è¨€æ¨¡å‹ï¼‰ã€‚å°½ç®¡ç°æœ‰æ–¹æ³•å¯èƒ½å‡å°‘äº†å¾®è°ƒæ‰€éœ€çš„æŸäº›å†…å­˜éƒ¨åˆ†ï¼Œä½†å®ƒä»¬ä»ç„¶éœ€è¦åœ¨å‰å‘ä¼ æ’­è¿‡ç¨‹ä¸­ç¼“å­˜æ‰€æœ‰ä¸­é—´æ¿€æ´»çš„è®¡ç®—ç»“æœï¼Œä»¥åœ¨åå‘ä¼ æ’­è¿‡ç¨‹ä¸­æ›´æ–°æƒé‡ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬å¼€å‘äº†TokenTuneï¼Œä¸€ç§æ—¨åœ¨å‡å°‘åŸºäºå˜æ¢æ¨¡å‹çš„å¾®è°ƒè¿‡ç¨‹ä¸­çš„å†…å­˜ä½¿ç”¨é‡çš„æ–¹æ³•ï¼Œç‰¹åˆ«æ˜¯ç”¨äºå­˜å‚¨ä¸­é—´æ¿€æ´»å€¼çš„å†…å­˜ã€‚åœ¨åå‘ä¼ æ’­è¿‡ç¨‹ä¸­ï¼ŒTokenTuneé€šè¿‡ä»…é€šè¿‡è¾“å…¥ä»¤ç‰Œçš„ä¸€ä¸ªå­é›†è¿›è¡Œåå‘ä¼ æ’­æ¥è¿‘ä¼¼æ¢¯åº¦è®¡ç®—ã€‚å› æ­¤ï¼Œä½¿ç”¨TokenTuneæ—¶ï¼Œä»…åœ¨æ­£å‘ä¼ æ’­è¿‡ç¨‹ä¸­ç¼“å­˜ä¸€å°éƒ¨åˆ†ä¸­é—´æ¿€æ´»å€¼ã€‚æ­¤å¤–ï¼ŒTokenTuneè¿˜å¯ä»¥è½»æ¾åœ°ä¸LoRAç­‰ç°æœ‰æ–¹æ³•ç›¸ç»“åˆï¼Œè¿›ä¸€æ­¥é™ä½å†…å­˜æˆæœ¬ã€‚æˆ‘ä»¬åœ¨å…·æœ‰æ•°åäº¿å‚æ•°çš„é¢„è®­ç»ƒå˜æ¢æ¨¡å‹ä¸Šè¯„ä¼°äº†æˆ‘ä»¬çš„æ–¹æ³•ï¼Œå¹¶è€ƒè™‘äº†å…¶åœ¨å¤šä¸ªä¸‹æ¸¸ä»»åŠ¡ï¼ˆå¦‚æ–‡æœ¬åˆ†ç±»å’Œé—®é¢˜å›ç­”ï¼‰ä¸Šçš„æ€§èƒ½è¡¨ç°ã€‚æ€»ä½“è€Œè¨€ï¼ŒTokenTuneçš„æ€§èƒ½ä¸å®Œå…¨å¾®è°ƒæˆ–ä»£è¡¨æ€§å†…å­˜é«˜æ•ˆçš„å¾®è°ƒæ–¹æ³•ç›¸å½“ï¼ŒåŒæ—¶å¤§å¤§é™ä½äº†å†…å­˜å ç”¨ç©ºé—´ï¼Œå°¤å…¶æ˜¯ä¸å…¶ä»–å…·æœ‰äº’è¡¥å†…å­˜å‡å°‘æœºåˆ¶çš„æ–¹æ³•ç›¸ç»“åˆæ—¶ã€‚æˆ‘ä»¬å¸Œæœ›æˆ‘ä»¬çš„æ–¹æ³•èƒ½å¤Ÿä¿ƒè¿›å¤§å‹è½¬æ¢å™¨çš„å¾®è°ƒå·¥ä½œï¼Œåœ¨ç‰¹å®šé¢†åŸŸå¯¹å…¶è¿›è¡Œä¸“ä¸šåŒ–å¤„ç†æˆ–ä¸å…¶ä»–ç¥ç»ç½‘ç»œç»„ä»¶ä»æ›´å¤§çš„ç³»ç»Ÿè¿›è¡ŒååŒè®­ç»ƒã€‚æˆ‘ä»¬çš„ä»£ç å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/facebookresearch/tokentune%E8%8E%B7%E5%8F%96%E3%80%82">https://github.com/facebookresearch/tokentuneè·å–ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.18824v1">PDF</a> EMNLP 2024</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºäº†TokenTuneæ–¹æ³•ï¼Œç”¨äºå‡å°‘å¾®è°ƒåŸºäºè½¬æ¢å™¨æ¨¡å‹æ—¶çš„å†…å­˜ä½¿ç”¨ã€‚é€šè¿‡ä»…ç¼“å­˜è¾“å…¥ä»¤ç‰Œå­é›†çš„éƒ¨åˆ†ä¸­é—´æ¿€æ´»å€¼ï¼ŒTokenTuneèƒ½å¤Ÿåœ¨å¾®è°ƒè¿‡ç¨‹ä¸­é™ä½å†…å­˜æ¶ˆè€—ã€‚æ­¤æ–¹æ³•å¯ä¸ç°æœ‰æ–¹æ³•ï¼ˆå¦‚LoRAï¼‰ç»“åˆä½¿ç”¨ï¼Œè¿›ä¸€æ­¥é™ä½å†…å­˜æˆæœ¬ã€‚åœ¨å¤šé¡¹ä¸‹æ¸¸ä»»åŠ¡ï¼ˆå¦‚æ–‡æœ¬åˆ†ç±»å’Œé—®ç­”ï¼‰çš„å°‘é‡å­¦ä¹ è®¾ç½®ä¸­ï¼ŒTokenTuneå®ç°äº†ä¸å®Œå…¨å¾®è°ƒæˆ–ä»£è¡¨æ€§å†…å­˜é«˜æ•ˆå¾®è°ƒæ–¹æ³•ç›¸å½“çš„æ€§èƒ½ï¼ŒåŒæ—¶å¤§å¤§å‡å°‘äº†å†…å­˜å ç”¨ã€‚æˆ‘ä»¬çš„ä»£ç å·²åœ¨GitHubä¸Šå…¬å¼€ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>TokenTuneæ–¹æ³•ä¸“æ³¨äºå‡å°‘å¾®è°ƒåŸºäºè½¬æ¢å™¨æ¨¡å‹æ—¶çš„å†…å­˜ä½¿ç”¨ã€‚</li>
<li>é€šè¿‡ä»…ç¼“å­˜è¾“å…¥ä»¤ç‰Œå­é›†çš„éƒ¨åˆ†ä¸­é—´æ¿€æ´»å€¼ï¼Œé™ä½äº†å†…å­˜æ¶ˆè€—ã€‚</li>
<li>TokenTuneå¯ä»¥ä¸ç°æœ‰æ–¹æ³•ï¼ˆå¦‚LoRAï¼‰ç»“åˆä½¿ç”¨ï¼Œä»¥è¿›ä¸€æ­¥æé«˜å†…å­˜æ•ˆç‡ã€‚</li>
<li>åœ¨å¤šé¡¹ä¸‹æ¸¸ä»»åŠ¡ä¸­ï¼ŒTokenTuneå®ç°äº†ä¸å®Œå…¨å¾®è°ƒæˆ–å†…å­˜é«˜æ•ˆå¾®è°ƒæ–¹æ³•ç›¸å½“çš„æ€§èƒ½ã€‚</li>
<li>TokenTuneç‰¹åˆ«é€‚ç”¨äºå¤§å‹è½¬æ¢æ¨¡å‹çš„å¾®è°ƒã€‚</li>
<li>TokenTuneæœ‰åŠ©äºåœ¨å°‘é‡å­¦ä¹ è®¾ç½®ä¸­è¿›è¡Œæ¨¡å‹å¾®è°ƒã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.18824">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-1e1c487c55b8a6062c9ffb1e4484fe20.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-5b6cb4b39d2d1e275deb8d539c58d398.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-cbde7ae77eaef35e3dbb34bee1ab0457.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c416cc18ef2326782798ac2f2b0649f7.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="Divergent-Emotional-Patterns-in-Disinformation-on-Social-Media-An-Analysis-of-Tweets-and-TikToks-about-the-DANA-in-Valencia"><a href="#Divergent-Emotional-Patterns-in-Disinformation-on-Social-Media-An-Analysis-of-Tweets-and-TikToks-about-the-DANA-in-Valencia" class="headerlink" title="Divergent Emotional Patterns in Disinformation on Social Media? An   Analysis of Tweets and TikToks about the DANA in Valencia"></a>Divergent Emotional Patterns in Disinformation on Social Media? An   Analysis of Tweets and TikToks about the DANA in Valencia</h2><p><strong>Authors:IvÃ¡n Arcos, Paolo Rosso, RamÃ³n SalaverrÃ­a</strong></p>
<p>This study investigates the dissemination of disinformation on social media platforms during the DANA event (DANA is a Spanish acronym for Depresion Aislada en Niveles Altos, translating to high-altitude isolated depression) that resulted in extremely heavy rainfall and devastating floods in Valencia, Spain, on October 29, 2024. We created a novel dataset of 650 TikTok and X posts, which was manually annotated to differentiate between disinformation and trustworthy content. Additionally, a Few-Shot annotation approach with GPT-4o achieved substantial agreement (Cohenâ€™s kappa of 0.684) with manual labels. Emotion analysis revealed that disinformation on X is mainly associated with increased sadness and fear, while on TikTok, it correlates with higher levels of anger and disgust. Linguistic analysis using the LIWC dictionary showed that trustworthy content utilizes more articulate and factual language, whereas disinformation employs negations, perceptual words, and personal anecdotes to appear credible. Audio analysis of TikTok posts highlighted distinct patterns: trustworthy audios featured brighter tones and robotic or monotone narration, promoting clarity and credibility, while disinformation audios leveraged tonal variation, emotional depth, and manipulative musical elements to amplify engagement. In detection models, SVM+TF-IDF achieved the highest F1-Score, excelling with limited data. Incorporating audio features into roberta-large-bne improved both Accuracy and F1-Score, surpassing its text-only counterpart and SVM in Accuracy. GPT-4o Few-Shot also performed well, showcasing the potential of large language models for automated disinformation detection. These findings demonstrate the importance of leveraging both textual and audio features for improved disinformation detection on multimodal platforms like TikTok. </p>
<blockquote>
<p>æœ¬ç ”ç©¶è°ƒæŸ¥äº†åœ¨DANAäº‹ä»¶ï¼ˆDANAæ˜¯è¥¿ç­ç‰™è¯­ä¸­Depresion Aislada en Niveles Altosçš„ç¼©å†™ï¼Œæ„ä¸ºé«˜æµ·æ‹”å­¤ç«‹æ€§æŠ‘éƒç—‡ï¼‰æœŸé—´ç¤¾äº¤åª’ä½“å¹³å°ä¸Šä¼ æ’­çš„é”™è¯¯ä¿¡æ¯ã€‚è¯¥äº‹ä»¶å¯¼è‡´2024å¹´10æœˆ29æ—¥è¥¿ç­ç‰™ç“¦ä¼¦è¥¿äºšå‡ºç°æç«¯å¼ºé™é›¨å’Œç ´åæ€§æ´ªæ°´ã€‚æˆ‘ä»¬åˆ›å»ºäº†åŒ…å«650ä¸ªTikTokå’ŒXå¸–å­çš„æ–°å‹æ•°æ®é›†ï¼Œå¹¶è¿›è¡Œäº†æ‰‹åŠ¨æ³¨é‡Šï¼Œä»¥åŒºåˆ†é”™è¯¯ä¿¡æ¯å’Œå¯é å†…å®¹ã€‚å¦å¤–ï¼Œä½¿ç”¨GPT-4oçš„Few-Shotæ ‡æ³¨æ–¹æ³•è¾¾åˆ°äº†ä¸æ‰‹åŠ¨æ ‡ç­¾çš„å®è´¨ä¸€è‡´æ€§ï¼ˆCohençš„kappaå€¼ä¸º0.684ï¼‰ã€‚æƒ…ç»ªåˆ†ææ˜¾ç¤ºï¼ŒXä¸Šçš„é”™è¯¯ä¿¡æ¯ä¸»è¦ä¸æ‚²ä¼¤å’Œææƒ§æ„Ÿå¢åŠ æœ‰å…³ï¼Œè€Œåœ¨TikTokä¸Šï¼Œå®ƒä¸æ„¤æ€’å’ŒåŒæ¶ç¨‹åº¦è¾ƒé«˜ç›¸å…³ã€‚ä½¿ç”¨LIWCè¯å…¸è¿›è¡Œçš„è¯­è¨€åˆ†æè¡¨æ˜ï¼Œå¯é çš„å†…å®¹ä½¿ç”¨æ›´è‰ºæœ¯å’Œäº‹å®æ€§çš„è¯­è¨€ï¼Œè€Œé”™è¯¯ä¿¡æ¯åˆ™ä½¿ç”¨å¦å®šè¯ã€æ„ŸçŸ¥è¯æ±‡å’Œä¸ªäººè½¶äº‹æ¥æ˜¾å¾—å¯ä¿¡ã€‚å¯¹TikTokå¸–å­çš„éŸ³é¢‘åˆ†æçªæ˜¾äº†æ˜æ˜¾çš„æ¨¡å¼ï¼šå¯é éŸ³é¢‘çš„éŸ³è°ƒæ›´æ˜äº®ï¼Œé‡‡ç”¨æœºå™¨äººæˆ–å•è°ƒçš„å™è¿°ï¼Œä»¥ä¿ƒè¿›æ¸…æ™°åº¦å’Œå¯ä¿¡åº¦ï¼›è€Œé”™è¯¯ä¿¡æ¯çš„éŸ³é¢‘åˆ™åˆ©ç”¨éŸ³è°ƒå˜åŒ–ã€æƒ…æ„Ÿæ·±åº¦å’Œæ“çºµæ€§çš„éŸ³ä¹å…ƒç´ æ¥å¢å¼ºå‚ä¸åº¦ã€‚åœ¨æ£€æµ‹æ¨¡å‹ä¸­ï¼ŒSVM+TF-IDFè·å¾—äº†æœ€é«˜çš„F1åˆ†æ•°ï¼Œåœ¨æœ‰é™çš„æ•°æ®ä¸‹è¡¨ç°å“è¶Šã€‚å°†éŸ³é¢‘ç‰¹æ€§èå…¥roberta-large-bneä¸­æé«˜äº†å‡†ç¡®ç‡å’ŒF1åˆ†æ•°ï¼Œè¶…è¶Šäº†å…¶çº¯æ–‡æœ¬å¯¹åº”æ¨¡å‹å’ŒSVMçš„å‡†ç¡®ç‡ã€‚GPT-4oçš„Few-Shotè¡¨ç°ä¹Ÿç›¸å½“ä¸é”™ï¼Œå±•ç¤ºäº†å¤§å‹è¯­è¨€æ¨¡å‹åœ¨è‡ªåŠ¨é”™è¯¯ä¿¡æ¯æ£€æµ‹ä¸­çš„æ½œåŠ›ã€‚è¿™äº›å‘ç°è¡¨æ˜ï¼Œåˆ©ç”¨æ–‡æœ¬å’ŒéŸ³é¢‘ç‰¹å¾å¯¹äºæ”¹è¿›TikTokç­‰å¤šæ¨¡å¼å¹³å°ä¸Šçš„é”™è¯¯ä¿¡æ¯æ£€æµ‹è‡³å…³é‡è¦ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.18640v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>è¯¥ç ”ç©¶æ¢è®¨äº†DANAäº‹ä»¶ï¼ˆé«˜æµ·æ‹”å­¤ç«‹æ€§æŠ‘éƒç—‡çš„ç¼©å†™ï¼Œè¯¥äº‹ä»¶å¯¼è‡´è¥¿ç­ç‰™ç“¦ä¼¦è¥¿äºšäº2024å¹´10æœˆ29æ—¥å‘ç”Ÿæç«¯å¼ºé™é›¨å’Œç ´åæ€§æ´ªæ°´ï¼‰æœŸé—´ç¤¾äº¤åª’ä½“å¹³å°ä¸Šå‡æ¶ˆæ¯çš„æ‰©æ•£ã€‚ç ”ç©¶è€…åˆ›å»ºäº†ä¸€ä¸ªåŒ…å«650ç¯‡TikTokå’ŒXå¹³å°çš„å¸–å­çš„æ•°æ®é›†ï¼Œå¹¶è¿›è¡Œæ‰‹åŠ¨æ ‡æ³¨ä»¥åŒºåˆ†å‡æ¶ˆæ¯å’Œå¯é å†…å®¹ã€‚æƒ…æ„Ÿåˆ†æå‘ç°ï¼ŒXå¹³å°ä¸Šçš„å‡æ¶ˆæ¯ä¸»è¦ä¸æ‚²ä¼¤å’Œææƒ§æ„Ÿå¢åŠ æœ‰å…³ï¼Œè€ŒTikTokä¸Šçš„å‡æ¶ˆæ¯åˆ™ä¸æ„¤æ€’å’ŒåŒæ¶æƒ…ç»ªæ›´é«˜ç›¸å…³ã€‚è¯­è¨€åˆ†ææ˜¾ç¤ºï¼Œå¯é å†…å®¹ä½¿ç”¨æ›´è‰ºæœ¯å’Œäº‹å®æ€§çš„è¯­è¨€ï¼Œè€Œå‡æ¶ˆæ¯åˆ™ä½¿ç”¨å¦å®šè¯ã€æ„ŸçŸ¥è¯æ±‡å’Œä¸ªäººè½¶äº‹æ¥æ˜¾å¾—å¯ä¿¡ã€‚éŸ³é¢‘åˆ†æè¡¨æ˜ï¼Œå¯ä¿¡çš„éŸ³é¢‘å…·æœ‰æ›´æ˜äº®çš„éŸ³è°ƒå’Œæœºå™¨äººæˆ–å•è°ƒçš„å™è¿°ï¼Œè€Œå‡æ¶ˆæ¯çš„éŸ³é¢‘åˆ™åˆ©ç”¨éŸ³è°ƒå˜åŒ–å’Œæ“çºµæ€§éŸ³ä¹å…ƒç´ æ¥å¢åŠ å‚ä¸åº¦ã€‚æ£€æµ‹æ¨¡å‹ä¸­ï¼ŒSVM+TF-IDFè¾¾åˆ°æœ€é«˜F1åˆ†æ•°ï¼Œç»“åˆéŸ³é¢‘ç‰¹å¾çš„roberta-large-bneåœ¨å‡†ç¡®ç‡å’ŒF1åˆ†æ•°ä¸Šæœ‰æ‰€æå‡ã€‚GPT-4oçš„Few-Shotè¡¨ç°ä¹Ÿè‰¯å¥½ï¼Œçªæ˜¾å¤§å‹è¯­è¨€æ¨¡å‹åœ¨è‡ªåŠ¨å‡æ¶ˆæ¯æ£€æµ‹ä¸­çš„æ½œåŠ›ã€‚ç ”ç©¶ç»“æœè¡¨æ˜ï¼Œåˆ©ç”¨æ–‡æœ¬å’ŒéŸ³é¢‘ç‰¹å¾å¯¹äºæ”¹è¿›TikTokç­‰å¤šæ¨¡å¼å¹³å°ä¸Šçš„å‡æ¶ˆæ¯æ£€æµ‹è‡³å…³é‡è¦ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ç ”ç©¶èšç„¦äºDANAäº‹ä»¶æœŸé—´ç¤¾äº¤åª’ä½“ä¸Šçš„å‡æ¶ˆæ¯ä¼ æ’­ã€‚</li>
<li>åˆ›å»ºäº†åŒ…å«TikTokå’ŒXå¹³å°å¸–å­çš„æ•°æ®é›†ï¼Œå¹¶è¿›è¡Œæ‰‹åŠ¨æ ‡æ³¨ã€‚</li>
<li>æƒ…æ„Ÿåˆ†ææ˜¾ç¤ºä¸åŒå¹³å°ä¸Šå‡æ¶ˆæ¯ä¸ä¸åŒæƒ…ç»ªçš„ç›¸å…³æ€§ã€‚</li>
<li>è¯­è¨€åˆ†ææ­ç¤ºå¯é å†…å®¹å’Œå‡æ¶ˆæ¯åœ¨è¯­è¨€ä½¿ç”¨ä¸Šçš„å·®å¼‚ã€‚</li>
<li>éŸ³é¢‘åˆ†ææ˜¾ç¤ºï¼Œå‡æ¶ˆæ¯çš„éŸ³é¢‘å…·æœ‰ç‰¹å®šçš„ç‰¹å¾å’Œæ¨¡å¼ã€‚</li>
<li>SVM+TF-IDFå’Œç»“åˆéŸ³é¢‘ç‰¹å¾çš„roberta-large-bneåœ¨æ£€æµ‹æ¨¡å‹ä¸­è¡¨ç°æœ€ä½³ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.18640">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-477b838eafa0b4ac2b6e6d4c5037b922.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-f396db46548f0da08690d8e3c93c6ef0.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-6e5552a211b287412ea0a65dabcbc44a.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-64cee2bcb1496e62434fe9b45128e222.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-7aa006c3c0eea4f753016d7a3abdb734.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-c0395d2e25df8372c64803ef96f5d25e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-8ca162cc9c5c6f210867d310788dcaf1.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-adbc311e336567736e20ce409dd8a3ee.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="DWTNeRF-Boosting-Few-shot-Neural-Radiance-Fields-via-Discrete-Wavelet-Transform"><a href="#DWTNeRF-Boosting-Few-shot-Neural-Radiance-Fields-via-Discrete-Wavelet-Transform" class="headerlink" title="DWTNeRF: Boosting Few-shot Neural Radiance Fields via Discrete Wavelet   Transform"></a>DWTNeRF: Boosting Few-shot Neural Radiance Fields via Discrete Wavelet   Transform</h2><p><strong>Authors:Hung Nguyen, Blark Runfa Li, Truong Nguyen</strong></p>
<p>Neural Radiance Fields (NeRF) has achieved superior performance in novel view synthesis and 3D scene representation, but its practical applications are hindered by slow convergence and reliance on dense training views. To this end, we present DWTNeRF, a unified framework based on Instant-NGPâ€™s fast-training hash encoding. It is coupled with regularization terms designed for few-shot NeRF, which operates on sparse training views. Our DWTNeRF additionally includes a novel Discrete Wavelet loss that allows explicit prioritization of low frequencies directly in the training objective, reducing few-shot NeRFâ€™s overfitting on high frequencies in earlier training stages. We also introduce a model-based approach, based on multi-head attention, that is compatible with INGP, which are sensitive to architectural changes. On the 3-shot LLFF benchmark, DWTNeRF outperforms Vanilla INGP by 15.07% in PSNR, 24.45% in SSIM and 36.30% in LPIPS. Our approach encourages a re-thinking of current few-shot approaches for fast-converging implicit representations like INGP or 3DGS. </p>
<blockquote>
<p>ç¥ç»è¾å°„åœºï¼ˆNeRFï¼‰åœ¨æ–°å‹è§†å›¾åˆæˆå’Œ3Dåœºæ™¯è¡¨ç¤ºæ–¹é¢å–å¾—äº†å“è¶Šçš„æ€§èƒ½ï¼Œä½†å…¶å®é™…åº”ç”¨å—åˆ°äº†æ”¶æ•›é€Ÿåº¦æ…¢å’Œä¾èµ–å¯†é›†è®­ç»ƒè§†å›¾çš„å½±å“ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬æå‡ºäº†DWTNeRFï¼Œè¿™æ˜¯ä¸€ä¸ªåŸºäºInstant-NGPå¿«é€Ÿè®­ç»ƒå“ˆå¸Œç¼–ç çš„ç»Ÿä¸€æ¡†æ¶ã€‚å®ƒä¸é’ˆå¯¹å°‘é‡å°„å‡»NeRFè®¾è®¡çš„æ­£åˆ™åŒ–æœ¯è¯­ç›¸ç»“åˆï¼Œåœ¨ç¨€ç–è®­ç»ƒè§†å›¾ä¸Šè¿è¡Œã€‚æˆ‘ä»¬çš„DWTNeRFè¿˜åŒ…æ‹¬ä¸€ç§æ–°å‹ç¦»æ•£å°æ³¢æŸå¤±ï¼Œå…è®¸åœ¨è®­ç»ƒç›®æ ‡ä¸­ç›´æ¥æ˜ç¡®ä¼˜å…ˆå¤„ç†ä½é¢‘ï¼Œä»è€Œå‡å°‘æ—©æœŸè®­ç»ƒé˜¶æ®µä¸­å°‘é‡å°„å‡»NeRFå¯¹é«˜é¢‘çš„è¿‡æ‹Ÿåˆã€‚æˆ‘ä»¬è¿˜ä»‹ç»äº†ä¸€ç§åŸºäºå¤šå¤´æ³¨æ„åŠ›çš„æ¨¡å‹æ–¹æ³•ï¼Œè¯¥æ–¹æ³•ä¸INGPå…¼å®¹ï¼Œå¯¹æ¶æ„å˜åŒ–æ•æ„Ÿã€‚åœ¨3æ¬¡æ‹æ‘„çš„LLFFåŸºå‡†æµ‹è¯•ä¸­ï¼ŒDWTNeRFåœ¨PSNRä¸Šæ¯”Vanilla INGPé«˜å‡º15.07%ï¼Œåœ¨SSIMä¸Šé«˜å‡º24.45%ï¼Œåœ¨LPIPSä¸Šé«˜å‡º36.30%ã€‚æˆ‘ä»¬çš„æ–¹æ³•é¼“åŠ±é‡æ–°æ€è€ƒå½“å‰çš„å°‘é‡å°„å‡»æ–¹æ³•ï¼Œä»¥å¿«é€Ÿæ”¶æ•›éšå¼è¡¨ç¤ºå½¢å¼ï¼Œå¦‚INGPæˆ–3DGSã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.12637v2">PDF</a> 17 pages, 13 figures, 8 tables</p>
<p><strong>Summary</strong></p>
<p>NeRFæŠ€æœ¯åœ¨æ–°è§†è§’åˆæˆå’Œä¸‰ç»´åœºæ™¯è¡¨ç¤ºæ–¹é¢è¡¨ç°å‡ºå“è¶Šæ€§èƒ½ï¼Œä½†å…¶å®é™…åº”ç”¨å—åˆ°ç¼“æ…¢æ”¶æ•›å’Œä¾èµ–å¯†é›†è®­ç»ƒè§†å›¾çš„é™åˆ¶ã€‚ä¸ºè§£å†³è¿™äº›é—®é¢˜ï¼Œæå‡ºäº†DWTNeRFç»Ÿä¸€æ¡†æ¶ï¼Œç»“åˆInstant-NGPçš„å¿«é€Ÿè®­ç»ƒå“ˆå¸Œç¼–ç ï¼Œè®¾è®¡ç”¨äºå°‘é‡å°„å‡»NeRFçš„æ­£åˆ™åŒ–æœ¯è¯­ï¼Œå¹¶åœ¨ç¨€ç–è®­ç»ƒè§†å›¾ä¸Šè¿è¡Œã€‚DWTNeRFè¿˜åŒ…æ‹¬ä¸€ç§æ–°çš„ç¦»æ•£å°æ³¢æŸå¤±ï¼Œå…è®¸åœ¨è®­ç»ƒç›®æ ‡ä¸­æ˜¾å¼ä¼˜å…ˆè€ƒè™‘ä½é¢‘ä¿¡æ¯ï¼Œå‡å°‘æ—©æœŸè®­ç»ƒé˜¶æ®µå¯¹é«˜é¢‘çš„è¿‡æ‹Ÿåˆã€‚åœ¨3æ¬¡æ‹æ‘„çš„LLFFåŸºå‡†æµ‹è¯•ä¸­ï¼ŒDWTNeRFåœ¨PSNRä¸Šè¾ƒVanilla INGPé«˜å‡º15.07%ï¼Œåœ¨SSIMä¸Šé«˜å‡º24.45%ï¼Œåœ¨LPIPSä¸Šé«˜å‡º36.30%ã€‚DWTNeRFä¸ºå½“å‰å°‘é‡æ‹æ‘„éšå¼è¡¨ç¤ºæ–¹æ³•çš„å¿«é€Ÿæ”¶æ•›æä¾›äº†ä¸€ä¸ªæ–°çš„æ€è€ƒæ–¹å‘ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>NeRFæŠ€æœ¯åœ¨å¤„ç†å’Œå±•ç¤ºä¸‰ç»´åœºæ™¯ä¸Šå…·æœ‰ä¼˜è¶Šæ€§èƒ½ï¼Œä½†å­˜åœ¨æ”¶æ•›æ…¢å’Œä¾èµ–å¯†é›†è®­ç»ƒè§†å›¾çš„é—®é¢˜ã€‚</li>
<li>DWTNeRFæ˜¯ä¸€ä¸ªåŸºäºInstant-NGPçš„å¿«é€Ÿè®­ç»ƒå“ˆå¸Œç¼–ç çš„ç»Ÿä¸€æ¡†æ¶ï¼Œè§£å†³äº†NeRFæŠ€æœ¯çš„æ”¶æ•›é—®é¢˜ã€‚å®ƒèƒ½åœ¨ç¨€ç–çš„è®­ç»ƒè§†å›¾ä¸Šè¿è¡Œã€‚</li>
<li>DWTNeRFæ¡†æ¶åŒ…æ‹¬ä¸€ç§æ–°é¢–çš„ç¦»æ•£å°æ³¢æŸå¤±æŠ€æœ¯ï¼Œèƒ½å¤Ÿåœ¨è®­ç»ƒç›®æ ‡ä¸­æ˜¾å¼ä¼˜å…ˆè€ƒè™‘ä½é¢‘ä¿¡æ¯ï¼Œå‡å°‘äº†æ—©æœŸè®­ç»ƒé˜¶æ®µå¯¹é«˜é¢‘çš„è¿‡æ‹Ÿåˆã€‚</li>
<li>åœ¨åŸºå‡†æµ‹è¯•ä¸­ï¼ŒDWTNeRFçš„æ€§èƒ½æ˜¾è‘—ä¼˜äºä¼ ç»Ÿçš„NeRFæŠ€æœ¯ã€‚å…·ä½“æ¥è¯´ï¼Œå®ƒåœ¨PSNRã€SSIMå’ŒLPIPSç­‰å…³é”®æŒ‡æ ‡ä¸Šå–å¾—äº†æ˜¾è‘—çš„æå‡ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.12637">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-322630a2fc4fa86cd69f3f8b10e5c9b4.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-1944b6685006aa1cd5980d9714859fa7.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-bc499b0fb467fba02fd43e2a14a45bb3.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-776a01eb9971f1504f3874ddaffc5062.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a1448d40ba7d1e67623aadd084d03038.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="Self-Instruct-Few-Shot-Jailbreaking-Decompose-the-Attack-into-Pattern-and-Behavior-Learning"><a href="#Self-Instruct-Few-Shot-Jailbreaking-Decompose-the-Attack-into-Pattern-and-Behavior-Learning" class="headerlink" title="Self-Instruct Few-Shot Jailbreaking: Decompose the Attack into Pattern   and Behavior Learning"></a>Self-Instruct Few-Shot Jailbreaking: Decompose the Attack into Pattern   and Behavior Learning</h2><p><strong>Authors:Jiaqi Hua, Wanxu Wei</strong></p>
<p>Recently, several works have been conducted on jailbreaking Large Language Models (LLMs) with few-shot malicious demos. In particular, Zheng et al. focus on improving the efficiency of Few-Shot Jailbreaking (FSJ) by injecting special tokens into the demos and employing demo-level random search, known as Improved Few-Shot Jailbreaking (I-FSJ). Nevertheless, we notice that this method may still require a long context to jailbreak advanced models e.g. 32 shots of demos for Meta-Llama-3-8B-Instruct (Llama-3) \cite{llama3modelcard}. In this paper, we discuss the limitations of I-FSJ and propose Self-Instruct Few-Shot Jailbreaking (Self-Instruct-FSJ) facilitated with the demo-level greedy search. This framework decomposes the FSJ attack into pattern and behavior learning to exploit the modelâ€™s vulnerabilities in a more generalized and efficient way. We conduct elaborate experiments to evaluate our method on common open-source models and compare it with baseline algorithms. Our code is available at <a target="_blank" rel="noopener" href="https://github.com/iphosi/Self-Instruct-FSJ">https://github.com/iphosi/Self-Instruct-FSJ</a>. </p>
<blockquote>
<p>æœ€è¿‘ï¼Œæœ‰è‹¥å¹²ç ”ç©¶åˆ©ç”¨å°‘é‡æ¶æ„æ¼”ç¤ºæ¥ç ´è§£å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ã€‚ç‰¹åˆ«æ˜¯ï¼ŒZhengç­‰äººä¸“æ³¨äºé€šè¿‡å‘æ¼”ç¤ºä¸­æ³¨å…¥ç‰¹æ®Šä»¤ç‰Œå¹¶é‡‡ç”¨æ¼”ç¤ºçº§éšæœºæœç´¢æ¥æé«˜å°‘é‡æ¼”ç¤ºç ´è§£ï¼ˆFSJï¼‰çš„æ•ˆç‡ï¼Œè¿™è¢«ç§°ä¸ºæ”¹è¿›å‹å°‘é‡æ¼”ç¤ºç ´è§£ï¼ˆI-FSJï¼‰ã€‚ç„¶è€Œï¼Œæˆ‘ä»¬æ³¨æ„åˆ°æ­¤æ–¹æ³•å¯èƒ½ä»éœ€è¦è¾ƒé•¿çš„ä¸Šä¸‹æ–‡æ¥ç ´è§£é«˜çº§æ¨¡å‹ï¼Œä¾‹å¦‚åœ¨Meta-Llama-3-8B-Instructï¼ˆLlama-3ï¼‰ä¸­éœ€è¦32ä¸ªæ¼”ç¤ºé•œå¤´ \cite{llama3modelcard}ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬è®¨è®ºäº†I-FSJçš„å±€é™æ€§ï¼Œå¹¶æå‡ºäº†å€ŸåŠ©æ¼”ç¤ºçº§è´ªå¿ƒæœç´¢çš„è¾…åŠ©è‡ªæˆ‘æŒ‡ä»¤å°‘é‡æ¼”ç¤ºç ´è§£ï¼ˆSelf-Instruct-FSJï¼‰æ¡†æ¶ã€‚æ­¤æ¡†æ¶å°†FSJæ”»å‡»åˆ†è§£ä¸ºæ¨¡å¼å­¦ä¹ å’Œè¡Œä¸ºå­¦ä¹ ï¼Œä»¥æ›´é€šç”¨å’Œé«˜æ•ˆçš„æ–¹å¼åˆ©ç”¨æ¨¡å‹çš„æ¼æ´ã€‚æˆ‘ä»¬è¿›è¡Œäº†ç²¾å¿ƒè®¾è®¡çš„å®éªŒï¼Œä»¥è¯„ä¼°æˆ‘ä»¬çš„æ–¹æ³•åœ¨å¸¸ç”¨å¼€æºæ¨¡å‹ä¸Šçš„è¡¨ç°ï¼Œå¹¶ä¸åŸºçº¿ç®—æ³•è¿›è¡Œäº†æ¯”è¾ƒã€‚æˆ‘ä»¬çš„ä»£ç ä½äº <a target="_blank" rel="noopener" href="https://github.com/iphosi/Self-Instruct-FSJ%E3%80%82">https://github.com/iphosi/Self-Instruct-FSJã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.07959v2">PDF</a> </p>
<p><strong>Summary</strong><br>æ–‡æœ¬èšç„¦äºå¦‚ä½•é€šè¿‡ç ´è§£å¤§å‹è¯­è¨€æ¨¡å‹æ¥æå‡æ¨¡å‹æ•ˆç‡çš„é—®é¢˜ã€‚æ–‡ç« è®¨è®ºäº†ç°æœ‰çš„Improved Few-Shot Jailbreakingæ–¹æ³•åœ¨æŸäº›é«˜çº§æ¨¡å‹ä¸Šçš„å±€é™æ€§ï¼Œå¹¶ä»‹ç»äº†Self-Instruct Few-Shot Jailbreakingæ¡†æ¶ï¼Œè¯¥æ¡†æ¶é€šè¿‡åˆ†è§£FSJæ”»å‡»çš„æ¨¡å¼å’Œè¡Œä¸ºå­¦ä¹ ï¼Œä»¥æ›´é€šç”¨å’Œé«˜æ•ˆçš„æ–¹å¼åˆ©ç”¨æ¨¡å‹çš„æ¼æ´ã€‚é€šè¿‡å®éªŒéªŒè¯è¯¥æ–¹æ³•çš„æ€§èƒ½å¹¶å…¬å¼€äº†æºä»£ç ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>Large Language Models (LLMs)çš„ç ´è§£æ–¹æ³•ä¸€ç›´æ˜¯ç ”ç©¶çƒ­ç‚¹ï¼Œä½†ç°æœ‰çš„Improved Few-Shot Jailbreakingæ–¹æ³•åœ¨ç ´è§£é«˜çº§æ¨¡å‹æ—¶ä»æœ‰å±€é™æ€§ã€‚</li>
<li>Self-Instruct Few-Shot Jailbreakingæ¡†æ¶è¢«æå‡ºï¼Œé€šè¿‡åˆ†è§£FSJæ”»å‡»çš„æ¨¡å¼å’Œè¡Œä¸ºå­¦ä¹ ï¼Œä»¥æ›´é€šç”¨å’Œé«˜æ•ˆçš„æ–¹å¼åˆ©ç”¨æ¨¡å‹çš„æ¼æ´ã€‚</li>
<li>è¯¥æ¡†æ¶åŒ…æ‹¬åœ¨æ¼”ç¤ºä¸­æ³¨å…¥ç‰¹æ®Šä»¤ç‰Œå¹¶é‡‡ç”¨æ¼”ç¤ºçº§åˆ«çš„è´ªå©ªæœç´¢æ¥æé«˜æ•ˆç‡ã€‚</li>
<li>å®éªŒéªŒè¯äº†è¯¥æ¡†æ¶åœ¨å…¬å…±å¼€æºæ¨¡å‹ä¸Šçš„æ€§èƒ½ï¼Œå¹¶ä¸åŸºçº¿ç®—æ³•è¿›è¡Œäº†æ¯”è¾ƒã€‚</li>
<li>æ–‡ç« çš„æºä»£ç å·²å…¬å¼€ï¼Œå¯ä¾›è¿›ä¸€æ­¥ç ”ç©¶å’Œå‚è€ƒã€‚</li>
<li>Self-Instruct Few-Shot Jailbreakingå¯èƒ½æœ‰åŠ©äºæå‡å¤§å‹è¯­è¨€æ¨¡å‹çš„æ•ˆç‡å’Œå®‰å…¨æ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.07959">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-9aff4786b83449cfffcb835e599c1838.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-239d4c4889fb269a2d731a757422bfaf.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-1ad6362e32a52bd94f6aebe45ef7a9bf.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-3b6f252c9c6ff95b63182db19deb1791.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-c03cfcdff2bcbaf223bacefc80cb6654.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="Transforming-Role-Classification-in-Scientific-Teams-Using-LLMs-and-Advanced-Predictive-Analytics"><a href="#Transforming-Role-Classification-in-Scientific-Teams-Using-LLMs-and-Advanced-Predictive-Analytics" class="headerlink" title="Transforming Role Classification in Scientific Teams Using LLMs and   Advanced Predictive Analytics"></a>Transforming Role Classification in Scientific Teams Using LLMs and   Advanced Predictive Analytics</h2><p><strong>Authors:Wonduk Seo, Yi Bu</strong></p>
<p>Scientific team dynamics are critical in determining the nature and impact of research outputs. However, existing methods for classifying author roles based on self-reports and clustering lack comprehensive contextual analysis of contributions. Thus, we present a transformative approach to classifying author roles in scientific teams using advanced large language models (LLMs), which offers a more refined analysis compared to traditional clustering methods. Specifically, we seek to complement and enhance these traditional methods by utilizing open source and proprietary LLMs, such as GPT-4, Llama3 70B, Llama2 70B, and Mistral 7x8B, for role classification. Utilizing few-shot prompting, we categorize author roles and demonstrate that GPT-4 outperforms other models across multiple categories, surpassing traditional approaches such as XGBoost and BERT. Our methodology also includes building a predictive deep learning model using 10 features. By training this model on a dataset derived from the OpenAlex database, which provides detailed metadata on academic publications â€“ such as author-publication history, author affiliation, research topics, and citation counts â€“ we achieve an F1 score of 0.76, demonstrating robust classification of author roles. </p>
<blockquote>
<p>ç§‘ç ”å›¢é˜Ÿçš„åŠ¨æ€åœ¨å†³å®šç ”ç©¶æˆæœçš„æ€§è´¨å’Œå½±å“æ–¹é¢è‡³å…³é‡è¦ã€‚ç„¶è€Œï¼Œç°æœ‰çš„åŸºäºè‡ªæˆ‘æŠ¥å‘Šå’Œèšç±»çš„ä½œè€…è§’è‰²åˆ†ç±»æ–¹æ³•ç¼ºä¹å¯¹è´¡çŒ®çš„å…¨é¢ä¸Šä¸‹æ–‡åˆ†æã€‚å› æ­¤ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åˆ©ç”¨å…ˆè¿›çš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å¯¹ç§‘ç ”å›¢é˜Ÿä¸­çš„ä½œè€…è§’è‰²è¿›è¡Œåˆ†ç±»çš„å˜é©æ€§æ–¹æ³•ï¼Œä¸ä¼ ç»Ÿèšç±»æ–¹æ³•ç›¸æ¯”ï¼Œå®ƒæä¾›äº†æ›´ç²¾ç»†çš„åˆ†æã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬å¸Œæœ›é€šè¿‡åˆ©ç”¨å¼€æºå’Œä¸“æœ‰çš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆå¦‚GPT-4ã€Llama 3 70Bã€Llama 2 70Bå’ŒMistral 7x8Bï¼‰æ¥åˆ†ç±»è§’è‰²ï¼Œä»¥è¡¥å……å’Œå¢å¼ºè¿™äº›æ–¹æ³•ã€‚é€šè¿‡å°‘é‡çš„æç¤ºï¼Œæˆ‘ä»¬å¯¹ä½œè€…è§’è‰²è¿›è¡Œäº†åˆ†ç±»ï¼Œå¹¶è¯æ˜GPT-4åœ¨å¤šä¸ªç±»åˆ«ä¸­ä¼˜äºå…¶ä»–æ¨¡å‹ï¼Œè¶…è¶Šäº†ä¼ ç»Ÿçš„XGBoostå’ŒBERTç­‰æ–¹æ³•ã€‚æˆ‘ä»¬çš„æ–¹æ³•è¿˜åŒ…æ‹¬å»ºç«‹ä¸€ä¸ªä½¿ç”¨10ä¸ªç‰¹å¾çš„é¢„æµ‹æ·±åº¦å­¦ä¹ æ¨¡å‹ã€‚é€šè¿‡åœ¨OpenAlexæ•°æ®åº“è¡ç”Ÿçš„æ•°æ®é›†ä¸Šè®­ç»ƒæ¨¡å‹ï¼ˆè¯¥æ•°æ®åº“æä¾›æœ‰å…³å­¦æœ¯å‡ºç‰ˆç‰©ï¼ˆå¦‚ä½œè€…å‡ºç‰ˆå†å²ã€ä½œè€…å½’å±å…³ç³»ã€ç ”ç©¶ä¸»é¢˜å’Œå¼•ç”¨è®¡æ•°ï¼‰çš„è¯¦ç»†å…ƒæ•°æ®ï¼‰ï¼Œæˆ‘ä»¬å®ç°äº†F1åˆ†æ•°ä¸º0.76ï¼Œè¯æ˜äº†ä½œè€…è§’è‰²åˆ†ç±»çš„ç¨³å¥æ€§ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.07267v2">PDF</a> 16 pages, 5 figures, 3 tables</p>
<p><strong>æ‘˜è¦</strong></p>
<p>ç§‘ç ”å›¢é˜Ÿå†…éƒ¨çš„åŠ¨æ€å¯¹ç ”ç©¶äº§å‡ºçš„æ€§è´¨å’Œå½±å“åŠ›èµ·å…³é”®ä½œç”¨ã€‚ç°æœ‰çš„åŸºäºè‡ªæˆ‘æŠ¥å‘Šå’Œèšç±»çš„ä½œè€…è§’è‰²åˆ†ç±»æ–¹æ³•ç¼ºä¹å…¨é¢çš„è´¡çŒ®ä¸Šä¸‹æ–‡åˆ†æã€‚å› æ­¤ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åˆ©ç”¨å…ˆè¿›çš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å¯¹ç§‘ç ”å›¢é˜Ÿä¸­çš„ä½œè€…è§’è‰²è¿›è¡Œåˆ†ç±»çš„å˜é©æ€§æ–¹æ³•ï¼Œç›¸æ¯”ä¼ ç»Ÿçš„èšç±»æ–¹æ³•ï¼Œå®ƒæä¾›äº†æ›´ä¸ºç²¾ç»†çš„åˆ†æã€‚æˆ‘ä»¬æ—¨åœ¨ç»“åˆå¹¶ä¼˜åŒ–è¿™äº›ä¼ ç»Ÿæ–¹æ³•ï¼Œåˆ©ç”¨å¼€æºå’Œä¸“æœ‰LLMï¼ˆå¦‚GPT-4ã€Llama3 70Bã€Llama2 70Bå’ŒMistral 7x8Bï¼‰è¿›è¡Œè§’è‰²åˆ†ç±»ã€‚é€šè¿‡å°æ ·æœ¬æç¤ºçš„æ–¹æ³•ï¼Œæˆ‘ä»¬å¯¹ä½œè€…è§’è‰²è¿›è¡Œäº†åˆ†ç±»ï¼Œå¹¶è¯æ˜GPT-4åœ¨å¤šä¸ªç±»åˆ«ä¸­è¡¨ç°ä¼˜äºå…¶ä»–æ¨¡å‹ï¼Œè¶…è¶Šäº†ä¼ ç»Ÿçš„å¦‚XGBoostå’ŒBERTçš„æ–¹æ³•ã€‚æˆ‘ä»¬çš„æ–¹æ³•è¿˜åŒ…æ‹¬åˆ©ç”¨OpenAlexæ•°æ®åº“æä¾›çš„è¯¦ç»†å…ƒæ•°æ®æ„å»ºé¢„æµ‹æ·±åº¦å­¦ä¹ æ¨¡å‹ï¼Œå¯¹ä½œè€…è§’è‰²è¿›è¡Œåˆ†ç±»ï¼Œå®ç°äº†F1åˆ†æ•°ä¸º0.76ã€‚è¯¥æ¨¡å‹è®­ç»ƒæ•°æ®é›†åŒ…å«ä½œè€…å‡ºç‰ˆå†å²ã€ä½œè€…éš¶å±å…³ç³»ã€ç ”ç©¶ä¸»é¢˜å’Œå¼•ç”¨è®¡æ•°ç­‰ç‰¹å¾ã€‚</p>
<p><strong>å…³é”®è§è§£</strong></p>
<ol>
<li>ç§‘ç ”å›¢é˜ŸåŠ¨æ€å¯¹ç ”ç©¶è¾“å‡ºçš„æ€§è´¨å’Œå½±å“åŠ›è‡³å…³é‡è¦ã€‚</li>
<li>ç°æœ‰ä½œè€…è§’è‰²åˆ†ç±»æ–¹æ³•ä¸»è¦åŸºäºè‡ªæˆ‘æŠ¥å‘Šå’Œèšç±»ï¼Œç¼ºä¹å…¨é¢çš„è´¡çŒ®ä¸Šä¸‹æ–‡åˆ†æã€‚</li>
<li>åˆ©ç”¨å…ˆè¿›çš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰è¿›è¡Œä½œè€…è§’è‰²åˆ†ç±»æ˜¯ä¸€ç§æ›´ç²¾ç»†çš„æ–¹æ³•ã€‚</li>
<li>GPT-4åœ¨å¤šä¸ªç±»åˆ«ä¸­è¡¨ç°ä¼˜äºå…¶ä»–æ¨¡å‹ï¼Œç”¨äºè§’è‰²åˆ†ç±»ã€‚</li>
<li>GPT-4çš„ä¼˜è¶Šæ€§èƒ½è¶…è¶Šäº†ä¼ ç»Ÿçš„å¦‚XGBoostå’ŒBERTçš„æ–¹æ³•ã€‚</li>
<li>åˆ©ç”¨OpenAlexæ•°æ®åº“çš„è¯¦ç»†å…ƒæ•°æ®æ„å»ºäº†é¢„æµ‹æ·±åº¦å­¦ä¹ æ¨¡å‹ï¼Œå®ç°äº†F1åˆ†æ•°ä¸º0.76çš„ä½œè€…è§’è‰²åˆ†ç±»ã€‚</li>
<li>æ¨¡å‹è®­ç»ƒæ•°æ®é›†åŒ…å«ä¸°å¯Œçš„ç‰¹å¾ï¼Œå¦‚ä½œè€…å‡ºç‰ˆå†å²ã€ä½œè€…éš¶å±å…³ç³»ã€ç ”ç©¶ä¸»é¢˜å’Œå¼•ç”¨è®¡æ•°ç­‰ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.07267">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-e8a299164449d30c742d0b21507a37ff.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-6a6688da5e0d419e2d4d3d259c337d2e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-0b02efb3fc36694be89eef2cb2d49fd4.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="SEED4D-A-Synthetic-Egoâ€“Exo-Dynamic-4D-Data-Generator-Driving-Dataset-and-Benchmark"><a href="#SEED4D-A-Synthetic-Egoâ€“Exo-Dynamic-4D-Data-Generator-Driving-Dataset-and-Benchmark" class="headerlink" title="SEED4D: A Synthetic Egoâ€“Exo Dynamic 4D Data Generator, Driving Dataset   and Benchmark"></a>SEED4D: A Synthetic Egoâ€“Exo Dynamic 4D Data Generator, Driving Dataset   and Benchmark</h2><p><strong>Authors:Marius KÃ¤stingschÃ¤fer, ThÃ©o Gieruc, Sebastian Bernhard, Dylan Campbell, Eldar Insafutdinov, Eyvaz Najafli, Thomas Brox</strong></p>
<p>Models for egocentric 3D and 4D reconstruction, including few-shot interpolation and extrapolation settings, can benefit from having images from exocentric viewpoints as supervision signals. No existing dataset provides the necessary mixture of complex, dynamic, and multi-view data. To facilitate the development of 3D and 4D reconstruction methods in the autonomous driving context, we propose a Synthetic Egoâ€“Exo Dynamic 4D (SEED4D) data generator and dataset. We present a customizable, easy-to-use data generator for spatio-temporal multi-view data creation. Our open-source data generator allows the creation of synthetic data for camera setups commonly used in the NuScenes, KITTI360, and Waymo datasets. Additionally, SEED4D encompasses two large-scale multi-view synthetic urban scene datasets. Our static (3D) dataset encompasses 212k inward- and outward-facing vehicle images from 2k scenes, while our dynamic (4D) dataset contains 16.8M images from 10k trajectories, each sampled at 100 points in time with egocentric images, exocentric images, and LiDAR data. The datasets and the data generator can be found at <a target="_blank" rel="noopener" href="https://seed4d.github.io/">https://seed4d.github.io/</a>. </p>
<blockquote>
<p>å¯¹äºä»¥è‡ªæˆ‘ä¸ºä¸­å¿ƒï¼ˆegocentricï¼‰çš„3Då’Œ4Dé‡å»ºæ¨¡å‹ï¼ŒåŒ…æ‹¬å°æ ·æœ¬æ’å€¼å’Œå¤–æ¨è®¾ç½®ï¼Œå¯ä»¥ä»å¼‚ä½è§†è§’çš„å›¾åƒä¸­è·å¾—ç›‘ç£ä¿¡å·ï¼Œä»è€Œå—ç›Šã€‚ç›®å‰æ²¡æœ‰æ•°æ®é›†èƒ½å¤Ÿæä¾›å¤æ‚ã€åŠ¨æ€å’Œå¤šè§†è§’æ•°æ®æ‰€å¿…éœ€çš„æ··åˆã€‚ä¸ºäº†ä¿ƒè¿›åœ¨è‡ªåŠ¨é©¾é©¶èƒŒæ™¯ä¸‹3Då’Œ4Dé‡å»ºæ–¹æ³•çš„å‘å±•ï¼Œæˆ‘ä»¬æå‡ºäº†åˆæˆè‡ªæˆ‘å¼‚ä½åŠ¨æ€å››ç»´ï¼ˆSEED4Dï¼‰æ•°æ®ç”Ÿæˆå™¨å’Œæ•°æ®é›†ã€‚æˆ‘ä»¬å±•ç¤ºäº†ä¸€ä¸ªå¯å®šåˆ¶çš„ã€æ˜“äºä½¿ç”¨çš„å¤šè§†è§’æ—¶ç©ºæ•°æ®ç”Ÿæˆå™¨ã€‚æˆ‘ä»¬çš„å¼€æºæ•°æ®ç”Ÿæˆå™¨å¯ä»¥åˆ›å»ºå¸¸ç”¨äºNuScenesã€KITTI360å’ŒWaymoæ•°æ®é›†çš„ç›¸æœºè®¾ç½®åˆæˆæ•°æ®ã€‚æ­¤å¤–ï¼ŒSEED4DåŒ…å«ä¸¤ä¸ªå¤§è§„æ¨¡çš„å¤šè§†è§’åˆæˆåŸå¸‚åœºæ™¯æ•°æ®é›†ã€‚æˆ‘ä»¬çš„é™æ€ï¼ˆ3Dï¼‰æ•°æ®é›†åŒ…å«æ¥è‡ª2kåœºæ™¯çš„21.2ä¸‡å¼ è½¦å†…å’Œè½¦å¤–è½¦è¾†å›¾åƒï¼Œè€Œæˆ‘ä»¬çš„åŠ¨æ€ï¼ˆ4Dï¼‰æ•°æ®é›†åŒ…å«æ¥è‡ª10kè½¨è¿¹çš„1680ä¸‡å¼ å›¾åƒï¼Œæ¯æ¡è½¨è¿¹åœ¨æ—¶é—´ä¸Šé‡‡æ ·100ä¸ªç‚¹ï¼ŒåŒ…æ‹¬ä»¥è‡ªæˆ‘ä¸ºä¸­å¿ƒçš„å›¾åƒã€ä»¥å¼‚ä½ä¸ºä¸­å¿ƒçš„å›¾åƒå’Œæ¿€å…‰é›·è¾¾æ•°æ®ã€‚æ•°æ®é›†å’Œæ•°æ®ç”Ÿæˆå™¨å¯åœ¨<a target="_blank" rel="noopener" href="https://seed4d.github.io/%E6%89%BE%E5%88%B0%E3%80%82">https://seed4d.github.io/æ‰¾åˆ°ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.00730v2">PDF</a> WACV 2025. Project page: <a target="_blank" rel="noopener" href="https://seed4d.github.io/">https://seed4d.github.io/</a>. Code:   <a target="_blank" rel="noopener" href="https://github.com/continental/seed4d">https://github.com/continental/seed4d</a></p>
<p><strong>Summary</strong></p>
<p>è¯¥æ–‡æœ¬ä»‹ç»äº†ä¸€ä¸ªåä¸ºSEED4Dçš„åˆæˆæ•°æ®é›†ç”Ÿæˆå™¨ï¼Œå®ƒèƒ½ç”Ÿæˆé€‚ç”¨äºè‡ªåŠ¨é©¾é©¶åœºæ™¯çš„egocentric 3Då’Œ4Dé‡å»ºæ¨¡å‹æ‰€éœ€çš„åˆæˆæ•°æ®ã€‚è¯¥ç”Ÿæˆå™¨å¯ä»¥ä¸ºå¤æ‚çš„åŠ¨æ€å¤šè§†è§’æ•°æ®åˆ›å»ºæ··åˆä½“ï¼Œä»è€Œä¿ƒè¿›æ¨¡å‹çš„è®­ç»ƒå’Œå‘å±•ã€‚SEED4DåŒ…å«ä¸¤ä¸ªå¤§è§„æ¨¡çš„å¤šè§†è§’åˆæˆåŸå¸‚åœºæ™¯æ•°æ®é›†ï¼Œæ¶µç›–äº†é™æ€çš„3Dæ•°æ®é›†å’ŒåŠ¨æ€çš„4Dæ•°æ®é›†ã€‚æ­¤å¤–ï¼Œæ•°æ®ç”Ÿæˆå™¨æ˜“äºä½¿ç”¨ä¸”å¯å®šåˆ¶ï¼Œé€‚ç”¨äºNuScenesã€KITTI360å’ŒWaymoç­‰å¸¸ç”¨çš„ç›¸æœºè®¾ç½®ã€‚æ•°æ®é›†å’Œç”Ÿæˆå™¨å¯åœ¨SEED4Då®˜æ–¹ç½‘ç«™ä¸‹è½½å’Œä½¿ç”¨ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>SEED4Dæ˜¯ä¸€ä¸ªåˆæˆæ•°æ®é›†ç”Ÿæˆå™¨ï¼Œç”¨äºç”Ÿæˆé€‚ç”¨äºè‡ªåŠ¨é©¾é©¶åœºæ™¯çš„egocentric 3Då’Œ4Dé‡å»ºæ¨¡å‹çš„æ•°æ®ã€‚</li>
<li>ç”Ÿæˆçš„æ•°æ®åŒ…æ‹¬å¤æ‚çš„åŠ¨æ€å¤šè§†è§’æ•°æ®ï¼Œæœ‰åŠ©äºæé«˜æ¨¡å‹çš„è®­ç»ƒæ•ˆæœã€‚</li>
<li>SEED4DåŒ…å«é™æ€çš„3Dæ•°æ®é›†å’ŒåŠ¨æ€çš„4Dæ•°æ®é›†ï¼Œæ¶µç›–å¤§è§„æ¨¡çš„å¤šè§†è§’åˆæˆåŸå¸‚åœºæ™¯ã€‚</li>
<li>æ•°æ®ç”Ÿæˆå™¨é€‚ç”¨äºå¸¸è§çš„ç›¸æœºè®¾ç½®ï¼Œå¦‚NuScenesã€KITTI360å’ŒWaymoã€‚</li>
<li>æ•°æ®ç”Ÿæˆå™¨å…·æœ‰å¯å®šåˆ¶æ€§å’Œæ˜“ç”¨æ€§ã€‚</li>
<li>SEED4Då®˜ç½‘æä¾›æ•°æ®é›†å’Œç”Ÿæˆå™¨çš„ä¸‹è½½å’Œä½¿ç”¨ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.00730">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-2b5d474f6113ca437186996097352132.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-31bc860111de28b14927ccbc01ca476a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-62c4109857afd76eb0c52894f945bd89.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-61c0f73e3087fc9adf3f9e09868913d2.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-113f6947b4114b0c044331657c5c1594.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-427617f414311408ffd5e945e1ab662c.jpg" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="Reinforced-Prompt-Personalization-for-Recommendation-with-Large-Language-Models"><a href="#Reinforced-Prompt-Personalization-for-Recommendation-with-Large-Language-Models" class="headerlink" title="Reinforced Prompt Personalization for Recommendation with Large Language   Models"></a>Reinforced Prompt Personalization for Recommendation with Large Language   Models</h2><p><strong>Authors:Wenyu Mao, Jiancan Wu, Weijian Chen, Chongming Gao, Xiang Wang, Xiangnan He</strong></p>
<p>Designing effective prompts can empower LLMs to understand user preferences and provide recommendations with intent comprehension and knowledge utilization capabilities. Nevertheless, recent studies predominantly concentrate on task-wise prompting, developing fixed prompt templates shared across all users in a given recommendation task (e.g., rating or ranking). Although convenient, task-wise prompting overlooks individual user differences, leading to inaccurate analysis of user interests. In this work, we introduce the concept of instance-wise prompting, aiming at personalizing discrete prompts for individual users. Toward this end, we propose Reinforced Prompt Personalization (RPP) to realize it automatically. To improve efficiency and quality, RPP personalizes prompts at the sentence level rather than searching in the vast vocabulary word-by-word. Specifically, RPP breaks down the prompt into four patterns, tailoring patterns based on multi-agent and combining them. Then the personalized prompts interact with LLMs (environment) iteratively, to boost LLMsâ€™ recommending performance (reward). In addition to RPP, to improve the scalability of action space, our proposal of RPP+ dynamically refines the selected actions with LLMs throughout the iterative process. Extensive experiments on various datasets demonstrate the superiority of RPP&#x2F;RPP+ over traditional recommender models, few-shot methods, and other prompt-based methods, underscoring the significance of instance-wise prompting in LLMs for recommendation. Our code is available at <a target="_blank" rel="noopener" href="https://github.com/maowenyu-11/RPP">https://github.com/maowenyu-11/RPP</a>. </p>
<blockquote>
<p>è®¾è®¡æœ‰æ•ˆçš„æç¤ºå¯ä»¥èµ‹èƒ½å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ï¼Œä½¿å…¶èƒ½å¤Ÿç†è§£ç”¨æˆ·åå¥½ï¼Œå¹¶æä¾›å…·æœ‰æ„å›¾ç†è§£å’ŒçŸ¥è¯†åˆ©ç”¨èƒ½åŠ›çš„æ¨èã€‚ç„¶è€Œï¼Œæœ€è¿‘çš„ç ”ç©¶ä¸»è¦é›†ä¸­åœ¨ä»»åŠ¡å¼çš„æç¤ºä¸Šï¼Œå³åœ¨ç»™å®šçš„æ¨èä»»åŠ¡ï¼ˆå¦‚è¯„åˆ†æˆ–æ’åï¼‰ä¸­ï¼Œä¸ºæ‰€æœ‰ç”¨æˆ·å¼€å‘å›ºå®šçš„æç¤ºæ¨¡æ¿ã€‚è™½ç„¶æ–¹ä¾¿ï¼Œä½†ä»»åŠ¡å¼çš„æç¤ºå¿½è§†äº†å•ä¸ªç”¨æˆ·ä¹‹é—´çš„å·®å¼‚ï¼Œå¯¼è‡´å¯¹ç”¨æˆ·å…´è¶£çš„ä¸å‡†ç¡®åˆ†æã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬å¼•å…¥äº†å®ä¾‹çº§æç¤ºçš„æ¦‚å¿µï¼Œæ—¨åœ¨é’ˆå¯¹å•ä¸ªç”¨æˆ·è¿›è¡Œä¸ªæ€§åŒ–çš„ç¦»æ•£æç¤ºã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬æå‡ºäº†å¼ºåŒ–æç¤ºä¸ªæ€§åŒ–ï¼ˆRPPï¼‰çš„æ–¹æ³•æ¥å®ç°å…¶è‡ªåŠ¨åŒ–ã€‚ä¸ºäº†æé«˜æ•ˆç‡å’Œè´¨é‡ï¼ŒRPPåœ¨å¥å­çº§åˆ«ä¸ªæ€§åŒ–æç¤ºï¼Œè€Œä¸æ˜¯åœ¨åºå¤§çš„è¯æ±‡è¡¨ä¸­é€å­—æœç´¢ã€‚å…·ä½“æ¥è¯´ï¼ŒRPPå°†æç¤ºåˆ†è§£ä¸ºå››ç§æ¨¡å¼ï¼ŒåŸºäºå¤šä»£ç†å®šåˆ¶æ¨¡å¼å¹¶å°†å…¶ç»„åˆã€‚ç„¶åï¼Œä¸ªæ€§åŒ–çš„æç¤ºä¸LLMsï¼ˆç¯å¢ƒï¼‰è¿›è¡Œè¿­ä»£äº¤äº’ï¼Œä»¥æé«˜LLMsçš„æ¨èæ€§èƒ½ï¼ˆå¥–åŠ±ï¼‰ã€‚é™¤äº†RPPä¹‹å¤–ï¼Œä¸ºäº†æé«˜åŠ¨ä½œç©ºé—´çš„å¯æ‰©å±•æ€§ï¼Œæˆ‘ä»¬æå‡ºçš„RPP+åœ¨è¿­ä»£è¿‡ç¨‹ä¸­åŠ¨æ€ä¼˜åŒ–æ‰€é€‰åŠ¨ä½œä¸LLMsçš„é…åˆã€‚åœ¨å¤šç§æ•°æ®é›†ä¸Šçš„å¤§é‡å®éªŒè¡¨æ˜ï¼ŒRPP&#x2F;RPP+ä¼˜äºä¼ ç»Ÿæ¨èæ¨¡å‹ã€å°‘æ ·æœ¬æ–¹æ³•å’Œå…¶ä»–åŸºäºæç¤ºçš„æ–¹æ³•ï¼Œçªæ˜¾äº†å®ä¾‹çº§æç¤ºåœ¨LLMsæ¨èä¸­çš„é‡è¦æ€§ã€‚æˆ‘ä»¬çš„ä»£ç å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/maowenyu-11/RPP">https://github.com/maowenyu-11/RPP</a>è·å–ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2407.17115v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†è®¾è®¡æœ‰æ•ˆæç¤ºè¯­å¯ä»¥èµ‹èƒ½å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ä»¥ç†è§£ç”¨æˆ·åå¥½å¹¶æä¾›ä¸ªæ€§åŒ–æ¨èçš„èƒ½åŠ›ã€‚é’ˆå¯¹å½“å‰ä¸»è¦ç ”ç©¶çš„ä»»åŠ¡å¼æç¤ºæ–¹æ³•å¿½ç•¥ç”¨æˆ·ä¸ªä½“å·®å¼‚çš„é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†å®ä¾‹å¼æç¤ºçš„æ¦‚å¿µï¼Œæ—¨åœ¨é’ˆå¯¹æ¯ä¸ªç”¨æˆ·ä¸ªæ€§åŒ–å®šåˆ¶æç¤ºè¯­ã€‚ä¸ºæ­¤ï¼Œæœ¬æ–‡æå‡ºäº†å¼ºåŒ–æç¤ºä¸ªæ€§åŒ–ï¼ˆRPPï¼‰æ–¹æ³•ï¼Œå¯ä»¥åœ¨å¥å­çº§åˆ«ä¸ªæ€§åŒ–æç¤ºè¯­ï¼Œæé«˜æ•ˆç‡å’Œè´¨é‡ã€‚æ­¤å¤–ï¼Œä¸ºäº†æ”¹å–„è¡ŒåŠ¨ç©ºé—´çš„æ‰©å±•æ€§ï¼Œè¿˜æå‡ºäº†RPP+æ–¹æ³•ï¼Œåœ¨è¿­ä»£è¿‡ç¨‹ä¸­åŠ¨æ€ä¼˜åŒ–æ‰€é€‰è¡ŒåŠ¨ã€‚å®éªŒè¯æ˜ï¼ŒRPPå’ŒRPP+åœ¨æ¨èæ€§èƒ½ä¸Šä¼˜äºä¼ ç»Ÿæ¨èæ¨¡å‹ã€å°‘æ ·æœ¬æ–¹æ³•å’Œå…¶å®ƒæç¤ºè¯­æ–¹æ³•ï¼Œçªæ˜¾å®ä¾‹å¼æç¤ºåœ¨LLMsæ¨èä¸­çš„é‡è¦æ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>è®¾è®¡æœ‰æ•ˆæç¤ºè¯­èƒ½å¢å¼ºLLMsç†è§£ç”¨æˆ·åå¥½å¹¶æä¾›ä¸ªæ€§åŒ–æ¨èçš„èƒ½åŠ›ã€‚</li>
<li>å½“å‰ä»»åŠ¡å¼æç¤ºæ–¹æ³•å¿½ç•¥ç”¨æˆ·ä¸ªä½“å·®å¼‚ï¼Œå¯¼è‡´å¯¹ç”¨æˆ·å…´è¶£åˆ†æä¸å‡†ç¡®ã€‚</li>
<li>å®ä¾‹å¼æç¤ºæ—¨åœ¨é’ˆå¯¹æ¯ä¸ªç”¨æˆ·ä¸ªæ€§åŒ–å®šåˆ¶æç¤ºè¯­ã€‚</li>
<li>å¼ºåŒ–æç¤ºä¸ªæ€§åŒ–ï¼ˆRPPï¼‰æ–¹æ³•èƒ½åœ¨å¥å­çº§åˆ«ä¸ªæ€§åŒ–æç¤ºè¯­ï¼Œæé«˜æ•ˆç‡ã€‚</li>
<li>RPP+æ–¹æ³•åŠ¨æ€ä¼˜åŒ–æ‰€é€‰è¡ŒåŠ¨ï¼Œæ”¹å–„è¡ŒåŠ¨ç©ºé—´çš„æ‰©å±•æ€§ã€‚</li>
<li>å®éªŒè¯æ˜RPPå’ŒRPP+åœ¨æ¨èæ€§èƒ½ä¸Šä¼˜äºä¼ ç»Ÿå’Œå…¶å®ƒæ–¹æ³•ã€‚</li>
<li>å®ä¾‹å¼æç¤ºåœ¨LLMsæ¨èä¸­å…·æœ‰é‡è¦æ„ä¹‰ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2407.17115">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-b4b945cbd194ba89aad4e56a170614b2.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-26b7a5473d333b70f1280cc06d3c51a1.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-8e53e3e838f19baf73d39755b645389e.jpg" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1><h2 id="VL-ICL-Bench-The-Devil-in-the-Details-of-Multimodal-In-Context-Learning"><a href="#VL-ICL-Bench-The-Devil-in-the-Details-of-Multimodal-In-Context-Learning" class="headerlink" title="VL-ICL Bench: The Devil in the Details of Multimodal In-Context Learning"></a>VL-ICL Bench: The Devil in the Details of Multimodal In-Context Learning</h2><p><strong>Authors:Yongshuo Zong, Ondrej Bohdal, Timothy Hospedales</strong></p>
<p>Large language models (LLMs) famously exhibit emergent in-context learning (ICL) â€“ the ability to rapidly adapt to new tasks using few-shot examples provided as a prompt, without updating the modelâ€™s weights. Built on top of LLMs, vision large language models (VLLMs) have advanced significantly in areas such as recognition, reasoning, and grounding. However, investigations into \emph{multimodal ICL} have predominantly focused on few-shot visual question answering (VQA), and image captioning, which we will show neither exploit the strengths of ICL, nor test its limitations. The broader capabilities and limitations of multimodal ICL remain under-explored. In this study, we introduce a comprehensive benchmark VL-ICL Bench for multimodal in-context learning, encompassing a broad spectrum of tasks that involve both images and text as inputs and outputs, and different types of challenges, from {perception to reasoning and long context length}. We evaluate the abilities of state-of-the-art VLLMs against this benchmark suite, revealing their diverse strengths and weaknesses, and showing that even the most advanced models, such as GPT-4, find the tasks challenging. By highlighting a range of new ICL tasks, and the associated strengths and limitations of existing models, we hope that our dataset will inspire future work on enhancing the in-context learning capabilities of VLLMs, as well as inspire new applications that leverage VLLM ICL. The code and dataset are available at <a target="_blank" rel="noopener" href="https://github.com/ys-zong/VL-ICL">https://github.com/ys-zong/VL-ICL</a>. </p>
<blockquote>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å±•ç°å‡ºäº†çªå‡ºçš„ä¸Šä¸‹æ–‡çªå‘å­¦ä¹ ï¼ˆICLï¼‰èƒ½åŠ›â€”â€”å³ä½¿ç”¨å°‘é‡ç¤ºä¾‹è¿›è¡Œæç¤ºå³å¯å¿«é€Ÿé€‚åº”æ–°ä»»åŠ¡ï¼Œè€Œæ— éœ€æ›´æ–°æ¨¡å‹æƒé‡ã€‚å»ºç«‹åœ¨å¤§å‹è¯­è¨€æ¨¡å‹ä¹‹ä¸Šçš„è§†è§‰å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆVLLMï¼‰åœ¨è¯†åˆ«ã€æ¨ç†å’Œæ¥åœ°ç­‰é¢†åŸŸå–å¾—äº†æ˜¾è‘—è¿›å±•ã€‚ç„¶è€Œï¼Œå¯¹äºå¤šæ¨¡å¼ICLçš„ç ”ç©¶ä¸»è¦é›†ä¸­åœ¨åŸºäºè§†è§‰çš„å°‘é‡é—®ç­”ï¼ˆVQAï¼‰å’Œå›¾åƒæè¿°ä¸Šï¼Œæˆ‘ä»¬å°†å±•ç¤ºå®ƒä»¬éƒ½æ²¡æœ‰å……åˆ†åˆ©ç”¨ICLçš„ä¼˜åŠ¿ï¼Œä¹Ÿæ²¡æœ‰æµ‹è¯•å…¶å±€é™æ€§ã€‚å¤šæ¨¡å¼ICLçš„æ›´å¹¿æ³›çš„èƒ½åŠ›å’Œå±€é™æ€§å°šæœªå¾—åˆ°å……åˆ†æ¢ç´¢ã€‚æœ¬ç ”ç©¶ä¸­ï¼Œæˆ‘ä»¬å¼•å…¥äº†å…¨é¢çš„åŸºå‡†æµ‹è¯•VL-ICL Benchï¼Œç”¨äºå¤šæ¨¡å¼ä¸Šä¸‹æ–‡å­¦ä¹ ï¼Œæ¶µç›–äº†ä¸€ç³»åˆ—æ¶‰åŠå›¾åƒå’Œæ–‡æœ¬ä½œä¸ºè¾“å…¥å’Œè¾“å‡ºçš„ä»»åŠ¡ï¼Œæ¶µç›–äº†ä»æ„ŸçŸ¥åˆ°æ¨ç†å’Œé•¿ä¸Šä¸‹æ–‡é•¿åº¦çš„ä¸åŒç±»å‹æŒ‘æˆ˜ã€‚æˆ‘ä»¬é’ˆå¯¹è¿™ä¸ªåŸºå‡†æµ‹è¯•å¥—ä»¶è¯„ä¼°äº†æœ€å…ˆè¿›çš„å¤§å‹è§†è§‰è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œæ­ç¤ºäº†å®ƒä»¬çš„å„ç§ä¼˜åŠ¿å’ŒåŠ£åŠ¿ï¼Œå¹¶è¡¨æ˜å³ä½¿æ˜¯æœ€å…ˆè¿›çš„æ¨¡å‹ï¼Œå¦‚GPT-4ï¼Œä¹Ÿå‘ç°è¿™äº›ä»»åŠ¡å…·æœ‰æŒ‘æˆ˜æ€§ã€‚é€šè¿‡çªå‡ºä¸€ç³»åˆ—æ–°çš„ICLä»»åŠ¡ä»¥åŠç°æœ‰æ¨¡å‹çš„å…³è”ä¼˜åŠ¿å’Œå±€é™æ€§ï¼Œæˆ‘ä»¬å¸Œæœ›æˆ‘ä»¬çš„æ•°æ®é›†èƒ½å¤Ÿæ¿€å‘æœªæ¥å…³äºå¢å¼ºå¤§å‹è§†è§‰è¯­è¨€æ¨¡å‹çš„ä¸Šä¸‹æ–‡å­¦ä¹ èƒ½åŠ›çš„ç›¸å…³å·¥ä½œï¼Œå¹¶æ¿€å‘åˆ©ç”¨å¤§å‹è§†è§‰è¯­è¨€æ¨¡å‹ICLçš„æ–°åº”ç”¨ã€‚ä»£ç å’Œæ•°æ®é›†å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/ys-zong/VL-ICL%E4%B8%8A%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/ys-zong/VL-ICLä¸Šæ‰¾åˆ°ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2403.13164v3">PDF</a> ICLR 2025</p>
<p><strong>Summary</strong></p>
<p>å¤§å‹è¯­è¨€æ¨¡å‹å±•ç°å‡ºåŸºäºä¸Šä¸‹æ–‡çš„å¿«é€Ÿå­¦ä¹ èƒ½åŠ›ï¼Œè€Œè§†è§‰å¤§å‹è¯­è¨€æ¨¡å‹åœ¨è¯†åˆ«ã€æ¨ç†å’Œå®šä½ç­‰é¢†åŸŸæœ‰äº†æ˜¾è‘—è¿›å±•ã€‚ç„¶è€Œï¼Œå¯¹äºå¤šæ¨¡æ€çš„åŸºäºä¸Šä¸‹æ–‡çš„å­¦ä¹ çš„ç ”ç©¶ä¸»è¦é›†ä¸­åœ¨è§†è§‰é—®ç­”å’Œå›¾åƒæè¿°ç”Ÿæˆä¸Šï¼Œå…¶æœªèƒ½å……åˆ†åˆ©ç”¨å’Œæµ‹è¯•è¿™ç§å­¦ä¹ çš„ä¼˜åŠ¿ã€‚æœ¬ç ”ç©¶å¼•å…¥äº†ä¸€ä¸ªå…¨é¢çš„å¤šæ¨¡æ€åŸºäºä¸Šä¸‹æ–‡å­¦ä¹ çš„åŸºå‡†æµ‹è¯•VL-ICL Benchï¼Œæ¶µç›–ä¸€ç³»åˆ—ä»»åŠ¡å’ŒæŒ‘æˆ˜ï¼Œä»æ„ŸçŸ¥åˆ°æ¨ç†å’Œé•¿æ–‡æœ¬ä¸Šä¸‹æ–‡ã€‚æˆ‘ä»¬è¯„ä¼°äº†æœ€å…ˆè¿›çš„è§†è§‰å¤§å‹è¯­è¨€æ¨¡å‹åœ¨è¯¥åŸºå‡†æµ‹è¯•ä¸Šçš„è¡¨ç°ï¼Œæ­ç¤ºäº†å…¶å¤šæ ·åŒ–çš„ä¼˜åŠ¿å’Œå¼±ç‚¹ï¼Œå¹¶æ˜¾ç¤ºå³ä½¿æ˜¯æœ€å…ˆè¿›çš„æ¨¡å‹å¦‚GPT-4ä¹Ÿé¢ä¸´æŒ‘æˆ˜ã€‚æˆ‘ä»¬å¸Œæœ›è¿™ä¸€æ•°æ®é›†èƒ½æ¿€åŠ±æœªæ¥å¢å¼ºè§†è§‰å¤§å‹è¯­è¨€æ¨¡å‹çš„åŸºäºä¸Šä¸‹æ–‡çš„å­¦ä¹ èƒ½åŠ›çš„ç ”ç©¶ï¼Œå¹¶æ¿€å‘åˆ©ç”¨è¿™ç§å­¦ä¹ èƒ½åŠ›çš„æ–°åº”ç”¨ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤§å‹è¯­è¨€æ¨¡å‹å±•ç°å‡ºåŸºäºä¸Šä¸‹æ–‡çš„å¿«é€Ÿå­¦ä¹ èƒ½åŠ›ã€‚</li>
<li>è§†è§‰å¤§å‹è¯­è¨€æ¨¡å‹åœ¨è¯†åˆ«ã€æ¨ç†å’Œå®šä½ç­‰é¢†åŸŸæœ‰æ˜¾è‘—è¿›å±•ã€‚</li>
<li>å½“å‰å¤šæ¨¡æ€åŸºäºä¸Šä¸‹æ–‡çš„å­¦ä¹ ç ”ç©¶ä¸»è¦é›†ä¸­åœ¨è§†è§‰é—®ç­”å’Œå›¾åƒæè¿°ç”Ÿæˆï¼Œæœªèƒ½å……åˆ†åˆ©ç”¨å’Œæµ‹è¯•è¿™ç§å­¦ä¹ çš„ä¼˜åŠ¿ã€‚</li>
<li>å¼•å…¥äº†ä¸€ä¸ªå…¨é¢çš„å¤šæ¨¡æ€åŸºäºä¸Šä¸‹æ–‡å­¦ä¹ çš„åŸºå‡†æµ‹è¯•VL-ICL Benchã€‚</li>
<li>è¯„ä¼°äº†æœ€å…ˆè¿›çš„è§†è§‰å¤§å‹è¯­è¨€æ¨¡å‹åœ¨è¯¥åŸºå‡†æµ‹è¯•ä¸Šçš„è¡¨ç°ã€‚</li>
<li>æ­ç¤ºäº†è§†è§‰å¤§å‹è¯­è¨€æ¨¡å‹åœ¨åŸºäºä¸Šä¸‹æ–‡å­¦ä¹ ä¸Šçš„å¤šæ ·åŒ–ä¼˜åŠ¿å’Œå¼±ç‚¹ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2403.13164">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-c3f4ce0658459c27973abf3167e64210.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-615437abc2988c94e3bfd80abd3eedc5.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-75bfc5198c7b62621bde4c7858123edc.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-02ef11c2143c9259c5c08e36eac8cbab.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-1e860e2d71c7734fe3e5ee796c28356f.jpg" align="middle">
</details>


<h1 id="-9"><a href="#-9" class="headerlink" title=""></a></h1><h2 id="Implicit-Shape-and-Appearance-Priors-for-Few-Shot-Full-Head-Reconstruction"><a href="#Implicit-Shape-and-Appearance-Priors-for-Few-Shot-Full-Head-Reconstruction" class="headerlink" title="Implicit Shape and Appearance Priors for Few-Shot Full Head   Reconstruction"></a>Implicit Shape and Appearance Priors for Few-Shot Full Head   Reconstruction</h2><p><strong>Authors:Pol Caselles, Eduard Ramon, Jaime Garcia, Gil Triginer, Francesc Moreno-Noguer</strong></p>
<p>Recent advancements in learning techniques that employ coordinate-based neural representations have yielded remarkable results in multi-view 3D reconstruction tasks. However, these approaches often require a substantial number of input views (typically several tens) and computationally intensive optimization procedures to achieve their effectiveness. In this paper, we address these limitations specifically for the problem of few-shot full 3D head reconstruction. We accomplish this by incorporating a probabilistic shape and appearance prior into coordinate-based representations, enabling faster convergence and improved generalization when working with only a few input images (even as low as a single image). During testing, we leverage this prior to guide the fitting process of a signed distance function using a differentiable renderer. By incorporating the statistical prior alongside parallelizable ray tracing and dynamic caching strategies, we achieve an efficient and accurate approach to few-shot full 3D head reconstruction. Moreover, we extend the H3DS dataset, which now comprises 60 high-resolution 3D full head scans and their corresponding posed images and masks, which we use for evaluation purposes. By leveraging this dataset, we demonstrate the remarkable capabilities of our approach in achieving state-of-the-art results in geometry reconstruction while being an order of magnitude faster than previous approaches. </p>
<blockquote>
<p>è¿‘æœŸï¼Œé‡‡ç”¨åæ ‡åŸºç¥ç»ç½‘ç»œè¡¨ç¤ºçš„å­¦ä¹ æŠ€æœ¯åœ¨å¤šè§†è§’3Dé‡å»ºä»»åŠ¡ä¸­å–å¾—äº†æ˜¾è‘—æˆæœã€‚ç„¶è€Œï¼Œè¿™äº›æ–¹æ³•é€šå¸¸éœ€è¦å¤§é‡çš„è¾“å…¥è§†è§’ï¼ˆé€šå¸¸æ˜¯æ•°åä¸ªï¼‰å’Œè®¡ç®—å¯†é›†å‹çš„ä¼˜åŒ–ç¨‹åºæ‰èƒ½å‘æŒ¥å…¶ä½œç”¨ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬é’ˆå¯¹å°‘æ ·æœ¬å…¨3Då¤´éƒ¨é‡å»ºé—®é¢˜è§£å†³äº†è¿™äº›é™åˆ¶ã€‚æˆ‘ä»¬é€šè¿‡å°†æ¦‚ç‡å½¢çŠ¶å’Œå¤–è§‚å…ˆéªŒçŸ¥è¯†èå…¥åæ ‡åŸºè¡¨ç¤ºï¼Œä»…ä½¿ç”¨å°‘é‡è¾“å…¥å›¾åƒï¼ˆç”šè‡³ä½è‡³å•å¼ å›¾åƒï¼‰å³å¯å®ç°æ›´å¿«çš„æ”¶æ•›å’Œæ›´å¥½çš„æ³›åŒ–èƒ½åŠ›ã€‚åœ¨æµ‹è¯•è¿‡ç¨‹ä¸­ï¼Œæˆ‘ä»¬åˆ©ç”¨æ­¤å…ˆéªŒçŸ¥è¯†ï¼Œé€šè¿‡å¯å¾®åˆ†æ¸²æŸ“å™¨å¼•å¯¼æœ‰ç¬¦å·è·ç¦»å‡½æ•°çš„æ‹Ÿåˆè¿‡ç¨‹ã€‚é€šè¿‡å°†ç»Ÿè®¡å…ˆéªŒçŸ¥è¯†ä¸å¯å¹¶è¡ŒåŒ–çš„å…‰çº¿è¿½è¸ªå’ŒåŠ¨æ€ç¼“å­˜ç­–ç•¥ç›¸ç»“åˆï¼Œæˆ‘ä»¬å®ç°äº†é«˜æ•ˆä¸”ç²¾å‡†çš„å°‘æ ·æœ¬å…¨3Då¤´éƒ¨é‡å»ºæ–¹æ³•ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æ‰©å±•äº†H3DSæ•°æ®é›†ï¼Œç°åœ¨åŒ…å«60ä¸ªé«˜åˆ†è¾¨ç‡çš„3Då…¨å¤´æ‰«æåŠå…¶ç›¸åº”çš„å§¿æ€å›¾åƒå’Œè’™ç‰ˆï¼Œç”¨äºè¯„ä¼°ç›®çš„ã€‚æˆ‘ä»¬åˆ©ç”¨æ­¤æ•°æ®é›†ï¼Œå±•ç¤ºäº†æˆ‘ä»¬çš„æ–¹æ³•åœ¨å‡ ä½•é‡å»ºæ–¹é¢è¾¾åˆ°æœ€æ–°æŠ€æœ¯æˆæœï¼ŒåŒæ—¶æ¯”ä»¥å‰çš„æ–¹æ³•å¿«ä¸€ä¸ªæ•°é‡çº§ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.08784v2">PDF</a> Accepted at IEEE Transactions on Pattern Analysis and Machine   Intelligence (TPAMI) 2025</p>
<p><strong>Summary</strong></p>
<p>è¿‘æœŸåŸºäºåæ ‡çš„ç¥ç»ç½‘ç»œè¡¨ç¤ºå­¦ä¹ æ–¹æ³•åœ¨å¤šè§†è§’3Dé‡å»ºä»»åŠ¡ä¸­å–å¾—äº†æ˜¾è‘—æˆæœï¼Œä½†åœ¨å¤„ç†å°‘é‡è¾“å…¥å›¾åƒæ—¶é¢ä¸´æŒ‘æˆ˜ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§é’ˆå¯¹å°‘è§†è§’å¤´éƒ¨é‡å»ºçš„æ–¹æ³•ï¼Œé€šè¿‡å¼•å…¥æ¦‚ç‡å½¢çŠ¶å’Œå¤–è§‚å…ˆéªŒä¿¡æ¯ï¼Œæé«˜äº†æ”¶æ•›é€Ÿåº¦å’Œæ³›åŒ–èƒ½åŠ›ã€‚æ­¤å¤–ï¼Œåˆ©ç”¨å¹¶è¡Œå…‰çº¿è¿½è¸ªå’ŒåŠ¨æ€ç¼“å­˜ç­–ç•¥å®ç°äº†é«˜æ•ˆå‡†ç¡®çš„é‡å»ºæ–¹æ³•ã€‚æœ¬æ–‡è¿˜æ‰©å±•äº†H3DSæ•°æ®é›†ï¼Œç”¨äºè¯„ä¼°é‡å»ºæ•ˆæœã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¼•å…¥æ¦‚ç‡å½¢çŠ¶å’Œå¤–è§‚å…ˆéªŒä¿¡æ¯ï¼Œæé«˜å°‘è§†è§’å¤´éƒ¨é‡å»ºçš„æ”¶æ•›é€Ÿåº¦å’Œæ³›åŒ–èƒ½åŠ›ã€‚</li>
<li>åˆ©ç”¨å¯å¾®åˆ†çš„æ¸²æŸ“å™¨å°†å…ˆéªŒä¿¡æ¯åº”ç”¨äºç¬¦å·è·ç¦»å‡½æ•°çš„æ‹Ÿåˆè¿‡ç¨‹ã€‚</li>
<li>é€šè¿‡å¹¶è¡Œå…‰çº¿è¿½è¸ªå’ŒåŠ¨æ€ç¼“å­˜ç­–ç•¥å®ç°é«˜æ•ˆå‡†ç¡®çš„é‡å»ºæ–¹æ³•ã€‚</li>
<li>æ‰©å±•äº†H3DSæ•°æ®é›†ï¼ŒåŒ…å«60ä¸ªé«˜åˆ†è¾¨ç‡çš„3Då¤´éƒ¨æ‰«ææ•°æ®åŠå…¶å¯¹åº”çš„å§¿æ€å›¾åƒå’Œæ©ç ã€‚</li>
<li>æ–¹æ³•åœ¨å‡ ä½•é‡å»ºæ–¹é¢å–å¾—äº†æœ€æ–°æˆæœï¼Œä¸”è¿è¡Œé€Ÿåº¦æ¯”å…ˆå‰çš„æ–¹æ³•å¿«ä¸€ä¸ªæ•°é‡çº§ã€‚</li>
<li>æ–¹æ³•åœ¨å°‘è§†è§’æˆ–å•è§†è§’çš„è¾“å…¥æ¡ä»¶ä¸‹ä»ç„¶è¡¨ç°å‡ºè‰¯å¥½çš„æ€§èƒ½ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2310.08784">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-02-05\./crop_Few-Shot/2310.08784v2/page_0_0.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c524a2ed3d0ef17a09c22544f82dfb30.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-14661a0a06f2f66a4fa5b20080b01f8c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ea1820582e340a1fe4438a51866dc5ca.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f867cb1e9782e78db8ed398656876695.jpg" align="middle">
</details>


<h1 id="-10"><a href="#-10" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-02-05/Few-Shot/">https://kedreamix.github.io/Talk2Paper/Paper/2025-02-05/Few-Shot/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/Few-Shot/">
                                    <span class="chip bg-color">Few-Shot</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-02-05/I2I%20Translation/">
                    <div class="card-image">
                        
                        <img src="https://pic1.zhimg.com/v2-847b0980c97dd5e32d48301827133346.jpg" class="responsive-img" alt="I2I Translation">
                        
                        <span class="card-title">I2I Translation</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            I2I Translation æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-02-05  BLens Contrastive Captioning of Binary Functions using Ensemble   Embedding
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-02-05
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/I2I-Translation/" class="post-category">
                                    I2I Translation
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/I2I-Translation/">
                        <span class="chip bg-color">I2I Translation</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-02-05/Agent/">
                    <div class="card-image">
                        
                        <img src="https://pic1.zhimg.com/v2-7f7e8b593b1b5e007bf2ad4307af4d54.jpg" class="responsive-img" alt="Agent">
                        
                        <span class="card-title">Agent</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Agent æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-02-05  Multi-agent Multi-armed Bandit with Fully Heavy-tailed Dynamics
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-02-05
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Agent/" class="post-category">
                                    Agent
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Agent/">
                        <span class="chip bg-color">Agent</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">10254.9k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
