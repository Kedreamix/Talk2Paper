<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Agent">
    <meta name="description" content="Agent æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-03-27  A Multi-Agent Framework Integrating Large Language Models and Generative   AI for Accelerated Metamaterial Design">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>Agent | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://picx.zhimg.com/v2-eb2d3837ceb875cc8b1fa18ed3ab8601.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Agent</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/Agent/">
                                <span class="chip bg-color">Agent</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/Agent/" class="post-category">
                                Agent
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-03-27
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-05-14
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    18.5k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    75 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-03-27-æ›´æ–°"><a href="#2025-03-27-æ›´æ–°" class="headerlink" title="2025-03-27 æ›´æ–°"></a>2025-03-27 æ›´æ–°</h1><h2 id="A-Multi-Agent-Framework-Integrating-Large-Language-Models-and-Generative-AI-for-Accelerated-Metamaterial-Design"><a href="#A-Multi-Agent-Framework-Integrating-Large-Language-Models-and-Generative-AI-for-Accelerated-Metamaterial-Design" class="headerlink" title="A Multi-Agent Framework Integrating Large Language Models and Generative   AI for Accelerated Metamaterial Design"></a>A Multi-Agent Framework Integrating Large Language Models and Generative   AI for Accelerated Metamaterial Design</h2><p><strong>Authors:Jie Tian, Martin Taylor Sobczak, Dhanush Patil, Jixin Hou, Lin Pang, Arunachalam Ramanathan, Libin Yang, Xianyan Chen, Yuval Golan, Hongyue Sun, Kenan Song, Xianqiao Wang</strong></p>
<p>Metamaterials, renowned for their exceptional mechanical, electromagnetic, and thermal properties, hold transformative potential across diverse applications, yet their design remains constrained by labor-intensive trial-and-error methods and limited data interoperability. Here, we introduce CrossMatAgentâ€“a novel multi-agent framework that synergistically integrates large language models with state-of-the-art generative AI to revolutionize metamaterial design. By orchestrating a hierarchical team of agentsâ€“each specializing in tasks such as pattern analysis, architectural synthesis, prompt engineering, and supervisory feedbackâ€“our system leverages the multimodal reasoning of GPT-4o alongside the generative precision of DALL-E 3 and a fine-tuned Stable Diffusion XL model. This integrated approach automates data augmentation, enhances design fidelity, and produces simulation- and 3D printing-ready metamaterial patterns. Comprehensive evaluations, including CLIP-based alignment, SHAP interpretability analyses, and mechanical simulations under varied load conditions, demonstrate the frameworkâ€™s ability to generate diverse, reproducible, and application-ready designs. CrossMatAgent thus establishes a scalable, AI-driven paradigm that bridges the gap between conceptual innovation and practical realization, paving the way for accelerated metamaterial development. </p>
<blockquote>
<p>è¶…ææ–™ä»¥å…¶å‡ºè‰²çš„æœºæ¢°ã€ç”µç£å’Œçƒ­æ€§èƒ½è€Œé—»åï¼Œåœ¨å¤šç§åº”ç”¨ä¸­å…·æœ‰å˜é©æ€§æ½œåŠ›ã€‚ç„¶è€Œï¼Œå…¶è®¾è®¡ä»å—åˆ°åŠ³åŠ¨å¯†é›†å‹çš„è¯•é”™æ–¹æ³•å’Œæœ‰é™æ•°æ®äº’æ“ä½œæ€§çš„é™åˆ¶ã€‚åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬ä»‹ç»äº†CrossMatAgentâ€”â€”ä¸€ç§æ–°å‹å¤šæ™ºèƒ½ä½“æ¡†æ¶ï¼Œå®ƒé€šè¿‡ååŒæ•´åˆå¤§å‹è¯­è¨€æ¨¡å‹ä¸æœ€æ–°ç”Ÿæˆå¼äººå·¥æ™ºèƒ½ï¼Œä»è€Œé©æ–°è¶…ææ–™è®¾è®¡ã€‚é€šè¿‡åè°ƒåˆ†å±‚çš„æ™ºèƒ½ä½“å›¢é˜Ÿâ€”â€”æ¯ä¸ªæ™ºèƒ½ä½“ä¸“é—¨æ‰§è¡Œæ¨¡å¼åˆ†æã€æ¶æ„ç»¼åˆã€æç¤ºå·¥ç¨‹å’Œç›‘ç®¡åé¦ˆç­‰ä»»åŠ¡â€”â€”æˆ‘ä»¬çš„ç³»ç»Ÿåˆ©ç”¨GPT-4oçš„å¤šæ¨¡æ€æ¨ç†èƒ½åŠ›ï¼Œç»“åˆDALL-E 3çš„ç”Ÿæˆç²¾åº¦å’Œç»è¿‡ç²¾ç»†è°ƒæ•´çš„Stable Diffusion XLæ¨¡å‹ã€‚è¿™ç§ç»¼åˆæ–¹æ³•è‡ªåŠ¨åŒ–æ•°æ®å¢å¼ºï¼Œæé«˜è®¾è®¡ä¿çœŸåº¦ï¼Œå¹¶äº§ç”Ÿå¯ç”¨äºæ¨¡æ‹Ÿå’Œ3Dæ‰“å°çš„è¶…ææ–™å›¾æ¡ˆã€‚ç»¼åˆè¯„ä¼°ï¼ŒåŒ…æ‹¬åŸºäºCLIPçš„å¯¹é½ã€SHAPè§£é‡Šæ€§åˆ†æå’Œå„ç§è´Ÿè½½æ¡ä»¶ä¸‹çš„æœºæ¢°æ¨¡æ‹Ÿï¼Œè¯æ˜äº†è¯¥æ¡†æ¶åœ¨ç”Ÿæˆå¤šæ ·åŒ–ã€å¯é‡å¤å’Œé€‚ç”¨äºåº”ç”¨çš„è¶…ææ–™è®¾è®¡æ–¹é¢çš„èƒ½åŠ›ã€‚å› æ­¤ï¼ŒCrossMatAgentå»ºç«‹äº†ä¸€ä¸ªå¯æ‰©å±•çš„ã€äººå·¥æ™ºèƒ½é©±åŠ¨çš„æ¨¡å¼ï¼Œè¯¥æ¨¡å¼å¼¥åˆäº†æ¦‚å¿µåˆ›æ–°ä¸å®è·µå®ç°ä¹‹é—´çš„é¸¿æ²Ÿï¼Œä¸ºè¶…ææ–™çš„åŠ é€Ÿå‘å±•é“ºå¹³äº†é“è·¯ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.19889v1">PDF</a> </p>
<p><strong>Summary</strong><br>æ–°ä¸€ä»£å¤šæ™ºèƒ½ä½“æ¡†æ¶CrossMatAgentèåˆäº†å¤§å‹è¯­è¨€æ¨¡å‹å’Œå…ˆè¿›çš„ç”Ÿæˆå¼äººå·¥æ™ºèƒ½ï¼Œå®ç°å˜é©æ€§çš„è¶…ææ–™è®¾è®¡ã€‚è¯¥ç³»ç»Ÿåˆ©ç”¨æ¨¡æ€æ¨ç†ã€æ•°æ®æ‰©å……åŠç²¾ç»†åŒ–æ¨¡æ‹Ÿç­‰æŠ€æœ¯ï¼Œæé«˜è®¾è®¡ä¿çœŸåº¦å’Œè¶…ææ–™å›¾æ¡ˆçš„å®ç”¨æ€§ã€‚è¿™ä¸€åˆ›æ–°æ¡†æ¶åŠ é€Ÿè¶…ææ–™å‘å±•ï¼Œå®ç°æ¦‚å¿µåˆ›æ–°ä¸å®é™…åº”ç”¨ä¹‹é—´çš„æ¡¥æ¢æ„å»ºã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>CrossMatAgentæ˜¯ä¸€ä¸ªå¤šæ™ºèƒ½ä½“æ¡†æ¶ï¼Œç”¨äºé©å‘½æ€§è¶…ææ–™è®¾è®¡ã€‚</li>
<li>é›†æˆå¤§å‹è¯­è¨€æ¨¡å‹å’Œå…ˆè¿›ç”Ÿæˆå¼AIæŠ€æœ¯ï¼Œå®ç°æ™ºèƒ½åŒ–è®¾è®¡ã€‚</li>
<li>é€šè¿‡æ¨¡æ€æ¨ç†å’Œæ™ºèƒ½ååŒå·¥ä½œï¼Œæé«˜è®¾è®¡è´¨é‡å’Œå®ç”¨æ€§ã€‚</li>
<li>ç³»ç»Ÿé‡‡ç”¨æ•°æ®æ‰©å……æŠ€æœ¯ï¼Œå¢å¼ºè®¾è®¡çš„å¤šæ ·æ€§å’Œå¯æ‰©å±•æ€§ã€‚</li>
<li>é€šè¿‡ç²¾ç»†åŒ–æ¨¡æ‹ŸæŠ€æœ¯ï¼Œç¡®ä¿è®¾è®¡çš„å¯è¡Œæ€§å’Œæ€§èƒ½ã€‚</li>
<li>æ¡†æ¶å…·æœ‰å¯è§£é‡Šæ€§å’Œå¯é‡å¤æ€§ï¼Œä¾¿äºè®¾è®¡ä¼˜åŒ–å’ŒéªŒè¯ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.19889">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-f3cc487016c76d545640673386d01f1c.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="Thinking-agents-for-zero-shot-generalization-to-qualitatively-novel-tasks"><a href="#Thinking-agents-for-zero-shot-generalization-to-qualitatively-novel-tasks" class="headerlink" title="Thinking agents for zero-shot generalization to qualitatively novel   tasks"></a>Thinking agents for zero-shot generalization to qualitatively novel   tasks</h2><p><strong>Authors:Thomas Miconi, Kevin McKee, Yicong Zheng, Jed McCaleb</strong></p>
<p>Intelligent organisms can solve truly novel problems which they have never encountered before, either in their lifetime or their evolution. An important component of this capacity is the ability to &#96;&#96;thinkâ€™â€™, that is, to mentally manipulate objects, concepts and behaviors in order to plan and evaluate possible solutions to novel problems, even without environment interaction. To generate problems that are truly qualitatively novel, while still solvable zero-shot (by mental simulation), we use the combinatorial nature of environments: we train the agent while withholding a specific combination of the environmentâ€™s elements. The novel test task, based on this combination, is thus guaranteed to be truly novel, while still mentally simulable since the agent has been exposed to each individual element (and their pairwise interactions) during training. We propose a method to train agents endowed with world models to make use their mental simulation abilities, by selecting tasks based on the difference between the agentâ€™s pre-thinking and post-thinking performance. When tested on the novel, withheld problem, the resulting agent successfully simulated alternative scenarios and used the resulting information to guide its behavior in the actual environment, solving the novel task in a single real-environment trial (zero-shot). </p>
<blockquote>
<p>æ™ºèƒ½ç”Ÿç‰©èƒ½å¤Ÿè§£å†³å®ƒä»¬åœ¨å…¶ç”Ÿå‘½å‘¨æœŸæˆ–è¿›åŒ–è¿‡ç¨‹ä¸­ä»æœªé‡åˆ°è¿‡çš„æ–°å‹é—®é¢˜ã€‚è¿™ç§èƒ½åŠ›çš„ä¸€ä¸ªé‡è¦ç»„æˆéƒ¨åˆ†å°±æ˜¯â€œæ€è€ƒâ€çš„èƒ½åŠ›ï¼Œå³èƒ½å¤Ÿåœ¨å¿ƒç†ä¸Šæ“ä½œç‰©ä½“ã€æ¦‚å¿µå’Œè¡Œä¸ºï¼Œä»¥è§„åˆ’å’Œè¯„ä¼°æ–°å‹é—®é¢˜çš„å¯èƒ½è§£å†³æ–¹æ¡ˆï¼Œå³ä½¿ä¸ä¸ç¯å¢ƒè¿›è¡Œäº’åŠ¨ã€‚ä¸ºäº†ç”ŸæˆçœŸæ­£è´¨æ–°å‹çš„é—®é¢˜ï¼ŒåŒæ—¶ä»ç„¶å¯ä»¥åœ¨é›¶å°„å‡»çŠ¶æ€ä¸‹è§£å†³ï¼ˆé€šè¿‡å¿ƒç†æ¨¡æ‹Ÿï¼‰ï¼Œæˆ‘ä»¬åˆ©ç”¨ç¯å¢ƒçš„ç»„åˆæ€§è´¨ï¼šåœ¨è®­ç»ƒä»£ç†æ—¶éšè—ç¯å¢ƒå…ƒç´ çš„ç‰¹å®šç»„åˆã€‚åŸºäºè¿™ç§ç»„åˆçš„æ–°å‹æµ‹è¯•ä»»åŠ¡å› æ­¤æ˜¯çœŸæ­£æ–°å‹çš„ï¼ŒåŒæ—¶åœ¨å¿ƒç†ä¸Šæ˜¯å¯ä»¥æ¨¡æ‹Ÿçš„ï¼Œå› ä¸ºä»£ç†åœ¨è®­ç»ƒæœŸé—´å·²ç»æ¥è§¦äº†æ¯ä¸ªå•ç‹¬çš„å…ƒç´ ï¼ˆä»¥åŠå®ƒä»¬çš„ä¸¤ä¸¤äº’åŠ¨ï¼‰ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–¹æ³•æ¥è®­ç»ƒæ‹¥æœ‰ä¸–ç•Œæ¨¡å‹çš„ä»£ç†ï¼Œåˆ©ç”¨å…¶å¿ƒç†æ¨¡æ‹Ÿèƒ½åŠ›ï¼Œé€šè¿‡æ ¹æ®ä»£ç†åœ¨æ€è€ƒå‰å’Œæ€è€ƒåçš„è¡¨ç°å·®å¼‚æ¥é€‰æ‹©ä»»åŠ¡ã€‚å½“åœ¨ä¸€ä¸ªæ–°é¢–çš„è¢«ä¿ç•™é—®é¢˜ä¸Šè¿›è¡Œæµ‹è¯•æ—¶ï¼Œæ‰€å¾—çš„ä»£ç†æˆåŠŸåœ°æ¨¡æ‹Ÿäº†æ›¿ä»£åœºæ™¯ï¼Œå¹¶åˆ©ç”¨æ‰€å¾—ä¿¡æ¯åœ¨å®é™…ç¯å¢ƒä¸­æŒ‡å¯¼å…¶è¡Œä¸ºï¼Œåœ¨ä¸€æ¬¡çœŸå®ç¯å¢ƒè¯•éªŒï¼ˆé›¶å°„å‡»ï¼‰ä¸­è§£å†³äº†æ–°å‹é—®é¢˜ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.19815v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æœ¬æè¿°äº†æ™ºèƒ½ç”Ÿç‰©å¦‚ä½•è§£å†³å…¨æ–°çš„é—®é¢˜ï¼Œå³ä½¿è¿™äº›é—®é¢˜åœ¨å…¶ç”Ÿå‘½å‘¨æœŸæˆ–è¿›åŒ–ä¸­ä»æœªé‡åˆ°è¿‡ã€‚æ™ºèƒ½ç”Ÿç‰©å…·å¤‡â€œæ€è€ƒâ€èƒ½åŠ›ï¼Œå³èƒ½å¤Ÿåœ¨ä¸ä¸ç¯å¢ƒäº’åŠ¨çš„æƒ…å†µä¸‹ï¼Œé€šè¿‡å¿ƒç†æ¨¡æ‹Ÿæ¥è®¡åˆ’å’Œè¯„ä¼°æ–°é—®é¢˜çš„å¯èƒ½è§£å†³æ–¹æ¡ˆã€‚ä¸ºäº†ç”ŸæˆçœŸæ­£å…¨æ–°ä¸”å¯é€šè¿‡å¿ƒç†æ¨¡æ‹Ÿè§£å†³çš„é—®é¢˜ï¼Œä½œè€…åˆ©ç”¨ç¯å¢ƒçš„ç»„åˆç‰¹æ€§æ¥è®­ç»ƒæ™ºèƒ½ä½“ï¼Œå³åœ¨è®­ç»ƒæ—¶éšè—ç¯å¢ƒå…ƒç´ çš„ç‰¹å®šç»„åˆã€‚åŸºäºè¿™ç§ç»„åˆçš„æ–°æµ‹è¯•ä»»åŠ¡ä¿è¯äº†å…¶å…¨æ–°æ€§ï¼ŒåŒæ—¶ç”±äºå…¶å·²æ¥è§¦è¿‡æ¯ä¸ªå•ç‹¬å…ƒç´ ï¼ˆåŠå…¶ä¸¤ä¸¤äº’åŠ¨ï¼‰è€Œå¯åœ¨å¿ƒç†ä¸Šæ¨¡æ‹Ÿã€‚ä½œè€…æå‡ºäº†ä¸€ç§è®­ç»ƒæ™ºèƒ½ä½“çš„æ–¹æ³•ï¼Œé€šè¿‡é€‰æ‹©åŸºäºæ™ºèƒ½ä½“é¢„æ€è€ƒå’Œåæ€è€ƒè¡¨ç°å·®å¼‚çš„ä»»åŠ¡æ¥åˆ©ç”¨ä»–ä»¬çš„å¿ƒç†æ¨¡æ‹Ÿèƒ½åŠ›ã€‚åœ¨æ–°å‹é—®é¢˜ä¸Šè¿›è¡Œæµ‹è¯•æ—¶ï¼Œè®­ç»ƒå‡ºçš„æ™ºèƒ½ä½“èƒ½æˆåŠŸæ¨¡æ‹Ÿæ›¿ä»£åœºæ™¯ï¼Œå¹¶åˆ©ç”¨è¿™äº›ä¿¡æ¯åœ¨å®é™…ç¯å¢ƒä¸­æŒ‡å¯¼å…¶è¡Œä¸ºï¼Œä¸€æ¬¡çœŸå®ç¯å¢ƒè¯•éªŒï¼ˆé›¶å°„ï¼‰å°±èƒ½è§£å†³æ–°é—®é¢˜ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æ™ºèƒ½ç”Ÿç‰©å…·å¤‡è§£å†³å…¨æ–°é—®é¢˜çš„èƒ½åŠ›ï¼Œè¿™äº›èƒ½åŠ›åŒ…æ‹¬â€œæ€è€ƒâ€ï¼Œå³åœ¨ä¸ä¸ç¯å¢ƒäº’åŠ¨çš„æƒ…å†µä¸‹è¿›è¡Œå¿ƒç†æ¨¡æ‹Ÿã€‚</li>
<li>ç¯å¢ƒçš„ç»„åˆç‰¹æ€§è¢«ç”¨æ¥ç”ŸæˆçœŸæ­£å…¨æ–°ä¸”å¯é€šè¿‡å¿ƒç†æ¨¡æ‹Ÿè§£å†³çš„é—®é¢˜ã€‚</li>
<li>åœ¨è®­ç»ƒæ™ºèƒ½ä½“æ—¶ï¼Œéšè—ç¯å¢ƒå…ƒç´ çš„ç‰¹å®šç»„åˆæ¥ä¿è¯å…¶é‡åˆ°é—®é¢˜çš„å…¨æ–°æ€§ã€‚</li>
<li>æ™ºèƒ½ä½“å·²ç»æ¥è§¦è¿‡æ¯ä¸ªå•ç‹¬çš„ç¯å¢ƒå…ƒç´ åŠå…¶ä¸¤ä¸¤äº’åŠ¨ï¼Œä½¿å¾—æ–°é—®é¢˜åœ¨å¿ƒç†ä¸Šå¯æ¨¡æ‹Ÿã€‚</li>
<li>ä½œè€…æå‡ºäº†ä¸€ç§åˆ©ç”¨æ™ºèƒ½ä½“çš„å¿ƒç†æ¨¡æ‹Ÿèƒ½åŠ›çš„æ–¹æ³•ï¼Œé€šè¿‡é€‰æ‹©åŸºäºé¢„æ€è€ƒå’Œåæ€è€ƒè¡¨ç°å·®å¼‚çš„ä»»åŠ¡æ¥è®­ç»ƒæ™ºèƒ½ä½“ã€‚</li>
<li>è®­ç»ƒå‡ºçš„æ™ºèƒ½ä½“å¯ä»¥æˆåŠŸæ¨¡æ‹Ÿæ›¿ä»£åœºæ™¯å¹¶ç”¨äºè§£å†³æ–°å‹é—®é¢˜ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.19815">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-e12f9e3412879a48233b93f55f3e286a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c31a38b240a5f1f5eb6cfec4df676569.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-900b5426a8dfc038114d05a915957fcc.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="Inducing-Personality-in-LLM-Based-Honeypot-Agents-Measuring-the-Effect-on-Human-Like-Agenda-Generation"><a href="#Inducing-Personality-in-LLM-Based-Honeypot-Agents-Measuring-the-Effect-on-Human-Like-Agenda-Generation" class="headerlink" title="Inducing Personality in LLM-Based Honeypot Agents: Measuring the Effect   on Human-Like Agenda Generation"></a>Inducing Personality in LLM-Based Honeypot Agents: Measuring the Effect   on Human-Like Agenda Generation</h2><p><strong>Authors:Lewis Newsham, Ryan Hyland, Daniel Prince</strong></p>
<p>This paper presents SANDMAN, an architecture for cyber deception that leverages Language Agents to emulate convincing human simulacra. Our â€˜Deceptive Agentsâ€™ serve as advanced cyber decoys, designed for high-fidelity engagement with attackers by extending the observation period of attack behaviours. Through experimentation, measurement, and analysis, we demonstrate how a prompt schema based on the five-factor model of personality systematically induces distinct â€˜personalitiesâ€™ in Large Language Models. Our results highlight the feasibility of persona-driven Language Agents for generating diverse, realistic behaviours, ultimately improving cyber deception strategies. </p>
<blockquote>
<p>æœ¬æ–‡ä»‹ç»äº†SANDMANï¼Œä¸€ç§åˆ©ç”¨è¯­è¨€ä»£ç†æ¥æ¨¡æ‹Ÿä»¤äººä¿¡æœçš„äººç±»æ¨¡æ‹Ÿç‰©çš„ç½‘ç»œæ¬ºéª—æ¶æ„ã€‚æˆ‘ä»¬çš„â€œæ¬ºéª—æ€§ä»£ç†â€å……å½“é«˜çº§ç½‘ç»œè¯±é¥µï¼Œé€šè¿‡å»¶é•¿æ”»å‡»è¡Œä¸ºçš„è§‚å¯ŸæœŸï¼Œä»¥é«˜ä¿çœŸæ–¹å¼ä¸æ”»å‡»è€…äº’åŠ¨ã€‚é€šè¿‡å®éªŒã€æµ‹é‡å’Œåˆ†æï¼Œæˆ‘ä»¬å±•ç¤ºäº†åŸºäºäº”å› ç´ äººæ ¼æ¨¡å‹çš„æç¤ºæ¨¡å¼å¦‚ä½•åœ¨å¤§å‹è¯­è¨€æ¨¡å‹ä¸­ç³»ç»Ÿåœ°å¼•å‘ä¸åŒçš„äººæ ¼ã€‚æˆ‘ä»¬çš„ç»“æœçªå‡ºäº†äººæ ¼é©±åŠ¨çš„è¯­è¨€ä»£ç†ç”Ÿæˆå¤šæ ·ã€ç°å®è¡Œä¸ºçš„å¯è¡Œæ€§ï¼Œæœ€ç»ˆæ”¹è¿›äº†ç½‘ç»œæ¬ºéª—ç­–ç•¥ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.19752v1">PDF</a> 11 pages, 1 figure, 6 tables. Accepted to NLPAICS 2024</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†SANDMANæ¶æ„ï¼Œè¿™æ˜¯ä¸€ç§åˆ©ç”¨è¯­è¨€ä»£ç†æ¨¡æ‹Ÿä»¤äººä¿¡æœçš„äººç±»å‡è±¡çš„ç½‘ç»œå®‰å…¨æ¬ºéª—æŠ€æœ¯ã€‚å…¶é€šè¿‡æ‰©å±•æ”»å‡»è¡Œä¸ºçš„è§‚å¯ŸæœŸï¼Œé‡‡ç”¨å…ˆè¿›çš„ç½‘ç»œè¯±é¥µæŠ€æœ¯å¸å¼•æ”»å‡»è€…ã€‚å®éªŒè¡¨æ˜ï¼ŒåŸºäºäº”å› ç´ äººæ ¼æ¨¡å‹çš„æç¤ºæ¶æ„èƒ½å¤Ÿå¼•å¯¼å¤§å‹è¯­è¨€æ¨¡å‹äº§ç”Ÿä¸åŒçš„ä¸ªæ€§ï¼Œå±•ç°äº†äººæ ¼é©±åŠ¨è¯­è¨€ä»£ç†åœ¨å®é™…è¡Œä¸ºç”Ÿæˆæ–¹é¢çš„æ½œåŠ›å’Œæ•ˆæœã€‚è¿™æå¤§åœ°æé«˜äº†ç½‘ç»œå®‰å…¨æ¬ºéª—ç­–ç•¥çš„å¯è¡Œæ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>SANDMANæ¶æ„åˆ©ç”¨è¯­è¨€ä»£ç†æŠ€æœ¯å®ç°ç½‘ç»œå®‰å…¨æ¬ºéª—ã€‚</li>
<li>è¯¥æ¶æ„é€šè¿‡æ¨¡æ‹Ÿé€¼çœŸçš„äººç±»å‡è±¡ï¼Œè®¾è®¡é«˜çº§ç½‘ç»œè¯±é¥µå¸å¼•æ”»å‡»è€…ã€‚</li>
<li>åŸºäºäº”å› ç´ äººæ ¼æ¨¡å‹çš„æç¤ºæ¶æ„å¯å¼•å¯¼å¤§å‹è¯­è¨€æ¨¡å‹äº§ç”Ÿä¸åŒä¸ªæ€§ã€‚</li>
<li>å®éªŒè¯æ˜äººæ ¼é©±åŠ¨è¯­è¨€ä»£ç†åœ¨å®é™…è¡Œä¸ºç”Ÿæˆæ–¹é¢çš„æ½œåŠ›ã€‚</li>
<li>è¿™ç§æŠ€æœ¯èƒ½å¤Ÿæ˜¾è‘—æé«˜ç½‘ç»œå®‰å…¨æ¬ºéª—ç­–ç•¥çš„å¯è¡Œæ€§ã€‚</li>
<li>é€šè¿‡å»¶é•¿è§‚å¯Ÿæ”»å‡»è¡Œä¸ºçš„å‘¨æœŸæ¥æé«˜ç½‘ç»œå®‰å…¨é˜²æŠ¤çš„æ•ˆç‡ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.19752">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-b9df469b3378ecc6b58645386da66434.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-f2cc7650f6a671578509111ffe9c84f3.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-e8b820845909bfabac55b6442ae95863.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-9fcc4a81229ea58dbeced767d93ba5ba.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-1e63e255451c76e409ab48eae0354dba.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="Multi-agent-Application-System-in-Office-Collaboration-Scenarios"><a href="#Multi-agent-Application-System-in-Office-Collaboration-Scenarios" class="headerlink" title="Multi-agent Application System in Office Collaboration Scenarios"></a>Multi-agent Application System in Office Collaboration Scenarios</h2><p><strong>Authors:Songtao Sun, Jingyi Li, Yuanfei Dong, Haoguang Liu, Chenxin Xu, Fuyang Li, Qiang Liu</strong></p>
<p>This paper introduces a multi-agent application system designed to enhance office collaboration efficiency and work quality. The system integrates artificial intelligence, machine learning, and natural language processing technologies, achieving functionalities such as task allocation, progress monitoring, and information sharing. The agents within the system are capable of providing personalized collaboration support based on team membersâ€™ needs and incorporate data analysis tools to improve decision-making quality. The paper also proposes an intelligent agent architecture that separates Plan and Solver, and through techniques such as multi-turn query rewriting and business tool retrieval, it enhances the agentâ€™s multi-intent and multi-turn dialogue capabilities. Furthermore, the paper details the design of tools and multi-turn dialogue in the context of office collaboration scenarios, and validates the systemâ€™s effectiveness through experiments and evaluations. Ultimately, the system has demonstrated outstanding performance in real business applications, particularly in query understanding, task planning, and tool calling. Looking forward, the system is expected to play a more significant role in addressing complex interaction issues within dynamic environments and large-scale multi-agent systems. </p>
<blockquote>
<p>æœ¬æ–‡ä»‹ç»äº†ä¸€ä¸ªå¤šæ™ºèƒ½ä½“åº”ç”¨ç³»ç»Ÿï¼Œæ—¨åœ¨æé«˜åŠå…¬å®¤åä½œæ•ˆç‡å’Œå·¥ä½œè´¨é‡ã€‚è¯¥ç³»ç»Ÿé›†æˆäº†äººå·¥æ™ºèƒ½ã€æœºå™¨å­¦ä¹ å’Œè‡ªç„¶è¯­è¨€å¤„ç†æŠ€æœ¯ï¼Œå®ç°äº†ä»»åŠ¡åˆ†é…ã€è¿›åº¦ç›‘æ§å’Œä¿¡æ¯å…±äº«ç­‰åŠŸèƒ½ã€‚ç³»ç»Ÿå†…çš„æ™ºèƒ½ä½“èƒ½æ ¹æ®å›¢é˜Ÿæˆå‘˜çš„éœ€æ±‚æä¾›ä¸ªæ€§åŒ–çš„åä½œæ”¯æŒï¼Œå¹¶èå…¥æ•°æ®åˆ†æå·¥å…·ï¼Œæé«˜å†³ç­–è´¨é‡ã€‚è®ºæ–‡è¿˜æå‡ºäº†ä¸€ç§æ™ºèƒ½ä½“æ¶æ„ï¼Œå°†è®¡åˆ’å’Œæ±‚è§£å™¨åˆ†å¼€ï¼Œå¹¶é€šè¿‡å¤šè½®æŸ¥è¯¢é‡å†™å’Œä¸šåŠ¡å·¥å…·æ£€ç´¢ç­‰æŠ€æœ¯ï¼Œæé«˜äº†æ™ºèƒ½ä½“çš„å¤šæ„å›¾å’Œå¤šè½®å¯¹è¯èƒ½åŠ›ã€‚æ­¤å¤–ï¼Œæœ¬æ–‡è¿˜è¯¦ç»†ä»‹ç»äº†åœ¨åŠå…¬å®¤åä½œåœºæ™¯ä¸‹å·¥å…·å’Œå¤šè½®å¯¹è¯çš„è®¾è®¡ï¼Œå¹¶é€šè¿‡å®éªŒå’Œè¯„ä¼°éªŒè¯äº†ç³»ç»Ÿçš„æœ‰æ•ˆæ€§ã€‚æœ€ç»ˆï¼Œè¯¥ç³»ç»Ÿåœ¨çœŸå®ä¸šåŠ¡åº”ç”¨ä¸­è¡¨ç°å‡ºå“è¶Šçš„æ€§èƒ½ï¼Œå°¤å…¶åœ¨æŸ¥è¯¢ç†è§£ã€ä»»åŠ¡è§„åˆ’å’Œå·¥å…·è°ƒç”¨æ–¹é¢ã€‚å±•æœ›æœªæ¥ï¼Œè¯¥ç³»ç»Ÿæœ‰æœ›åœ¨å¤„ç†åŠ¨æ€ç¯å¢ƒå’Œå¤§è§„æ¨¡å¤šæ™ºèƒ½ä½“ç³»ç»Ÿå†…çš„å¤æ‚äº¤äº’é—®é¢˜æ–¹é¢å‘æŒ¥æ›´é‡è¦çš„ä½œç”¨ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.19584v1">PDF</a> Technical report</p>
<p><strong>Summary</strong><br>ç³»ç»Ÿåˆ©ç”¨äººå·¥æ™ºèƒ½ã€æœºå™¨å­¦ä¹ å’Œè‡ªç„¶è¯­è¨€å¤„ç†æŠ€æœ¯ï¼Œè®¾è®¡äº†ä¸€ä¸ªå¤šæ™ºèƒ½ä½“åº”ç”¨ç³»ç»Ÿï¼Œæ—¨åœ¨æé«˜åŠå…¬å®¤åä½œæ•ˆç‡å’Œå·¥ä½œè´¨é‡ã€‚è¯¥ç³»ç»Ÿå…·æœ‰ä»»åŠ¡åˆ†é…ã€è¿›åº¦ç›‘æ§ã€ä¿¡æ¯å…±äº«ç­‰åŠŸèƒ½ï¼Œå¯ä¸ºå›¢é˜Ÿæˆå‘˜æä¾›ä¸ªæ€§åŒ–åä½œæ”¯æŒï¼Œå¹¶å¯é€šè¿‡æ•°æ®åˆ†æå·¥å…·æé«˜å†³ç­–è´¨é‡ã€‚æ­¤å¤–ï¼Œç³»ç»Ÿé‡‡ç”¨æ™ºèƒ½ä»£ç†æ¶æ„ï¼Œå¢å¼ºå¤šæ„å›¾å’Œå¤šè½®å¯¹è¯èƒ½åŠ›ã€‚å®éªŒå’Œè¯„ä¼°éªŒè¯äº†ç³»ç»Ÿåœ¨å®é™…å•†ä¸šåº”ç”¨ä¸­çš„å‡ºè‰²è¡¨ç°ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ç³»ç»Ÿé›†æˆäº†äººå·¥æ™ºèƒ½ã€æœºå™¨å­¦ä¹ å’Œè‡ªç„¶è¯­è¨€å¤„ç†æŠ€æœ¯ï¼Œç”¨äºæé«˜åŠå…¬å®¤åä½œæ•ˆç‡å’Œå·¥ä½œè´¨é‡ã€‚</li>
<li>ç³»ç»Ÿé€šè¿‡ä»»åŠ¡åˆ†é…ã€è¿›åº¦ç›‘æ§å’Œä¿¡æ¯å…±äº«ç­‰åŠŸèƒ½ï¼Œä¸ºå›¢é˜Ÿæˆå‘˜æä¾›ä¸ªæ€§åŒ–åä½œæ”¯æŒã€‚</li>
<li>ç³»ç»Ÿé‡‡ç”¨æ™ºèƒ½ä»£ç†æ¶æ„ï¼Œå®ç°Planå’ŒSolverçš„åˆ†ç¦»ï¼Œå¢å¼ºå¤šæ„å›¾å’Œå¤šè½®å¯¹è¯èƒ½åŠ›ã€‚</li>
<li>é€šè¿‡å®éªŒå’Œè¯„ä¼°éªŒè¯äº†ç³»ç»Ÿåœ¨å®é™…å•†ä¸šåº”ç”¨ä¸­çš„æœ‰æ•ˆæ€§ã€‚</li>
<li>ç³»ç»Ÿåœ¨æŸ¥è¯¢ç†è§£ã€ä»»åŠ¡è§„åˆ’å’Œå·¥å…·è°ƒç”¨æ–¹é¢è¡¨ç°å‡ºè‰²ã€‚</li>
<li>æœªæ¥ï¼Œè¯¥ç³»ç»Ÿæœ‰æœ›åœ¨è§£å†³å¤æ‚äº¤äº’é—®é¢˜å’Œå¤§è§„æ¨¡å¤šæ™ºèƒ½ä½“ç³»ç»Ÿä¸­å‘æŒ¥æ›´å¤§ä½œç”¨ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.19584">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-741b6551a2e06da10b5745a106140b20.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-cdd9ba10f23bebf6a768e0fa9f8c4243.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-aadb6feb62015f4c42cbf174f886c950.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-d224bc75dd2320bc3ca4fda6f8a14fb7.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-c93b2e2865625c3c5dbe711d56c90253.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a61ca48d8110de073b66143ab926c89d.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="Multi-Agent-Deep-Reinforcement-Learning-for-Safe-Autonomous-Driving-with-RICS-Assisted-MEC"><a href="#Multi-Agent-Deep-Reinforcement-Learning-for-Safe-Autonomous-Driving-with-RICS-Assisted-MEC" class="headerlink" title="Multi-Agent Deep Reinforcement Learning for Safe Autonomous Driving with   RICS-Assisted MEC"></a>Multi-Agent Deep Reinforcement Learning for Safe Autonomous Driving with   RICS-Assisted MEC</h2><p><strong>Authors:Xueyao Zhang, Bo Yang, Xuelin Cao, Zhiwen Yu, George C. Alexandropoulos, Yan Zhang, Merouane Debbah, Chau Yuen</strong></p>
<p>Environment sensing and fusion via onboard sensors are envisioned to be widely applied in future autonomous driving networks. This paper considers a vehicular system with multiple self-driving vehicles that is assisted by multi-access edge computing (MEC), where image data collected by the sensors is offloaded from cellular vehicles to the MEC server using vehicle-to-infrastructure (V2I) links. Sensory data can also be shared among surrounding vehicles via vehicle-to-vehicle (V2V) communication links. To improve spectrum utilization, the V2V links may reuse the same frequency spectrum with V2I links, which may cause severe interference. To tackle this issue, we leverage reconfigurable intelligent computational surfaces (RICSs) to jointly enable V2I reflective links and mitigate interference appearing at the V2V links. Considering the limitations of traditional algorithms in addressing this problem, such as the assumption for quasi-static channel state information, which restricts their ability to adapt to dynamic environmental changes and leads to poor performance under frequently varying channel conditions, in this paper, we formulate the problem at hand as a Markov game. Our novel formulation is applied to time-varying channels subject to multi-user interference and introduces a collaborative learning mechanism among users. The considered optimization problem is solved via a driving safety-enabled multi-agent deep reinforcement learning (DS-MADRL) approach that capitalizes on the RICS presence. Our extensive numerical investigations showcase that the proposed reinforcement learning approach achieves faster convergence and significant enhancements in both data rate and driving safety, as compared to various state-of-the-art benchmarks. </p>
<blockquote>
<p>é€šè¿‡è½¦è½½ä¼ æ„Ÿå™¨è¿›è¡Œç¯å¢ƒæ„ŸçŸ¥å’Œèåˆï¼Œè¢«å¹¿æ³›åº”ç”¨äºæœªæ¥çš„è‡ªåŠ¨é©¾é©¶ç½‘ç»œã€‚æœ¬æ–‡è€ƒè™‘äº†ä¸€ç§ç”±å¤šè¾†è‡ªåŠ¨é©¾é©¶æ±½è½¦ç»„æˆçš„è½¦è¾†ç³»ç»Ÿï¼Œè¯¥ç³»ç»Ÿç”±å¤šæ¥å…¥è¾¹ç¼˜è®¡ç®—ï¼ˆMECï¼‰è¾…åŠ©ï¼Œä¼ æ„Ÿå™¨æ”¶é›†çš„å›¾åƒæ•°æ®é€šè¿‡è½¦åˆ°åŸºç¡€è®¾æ–½ï¼ˆV2Iï¼‰é“¾æ¥ä»è½¦è½½è½¦è¾†å¸è½½åˆ°MECæœåŠ¡å™¨ã€‚æ„Ÿå®˜æ•°æ®ä¹Ÿå¯ä»¥é€šè¿‡è½¦è¾†åˆ°è½¦è¾†ï¼ˆV2Vï¼‰é€šä¿¡é“¾æ¥åœ¨å‘¨å›´è½¦è¾†ä¹‹é—´å…±äº«ã€‚ä¸ºäº†æé«˜é¢‘è°±åˆ©ç”¨ç‡ï¼ŒV2Vé“¾æ¥å¯èƒ½é‡ç”¨ä¸V2Ié“¾æ¥ç›¸åŒçš„é¢‘è°±ï¼Œè¿™å¯èƒ½å¯¼è‡´ä¸¥é‡çš„å¹²æ‰°ã€‚ä¸ºè§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬åˆ©ç”¨å¯é‡æ„æ™ºèƒ½è®¡ç®—è¡¨é¢ï¼ˆRICSsï¼‰æ¥å…±åŒå®ç°V2Iåå°„é“¾æ¥ï¼Œå¹¶å‡è½»V2Vé“¾æ¥ä¸­å‡ºç°çš„å¹²æ‰°ã€‚è€ƒè™‘åˆ°ä¼ ç»Ÿç®—æ³•åœ¨å¤„ç†è¿™ä¸ªé—®é¢˜æ—¶çš„å±€é™æ€§ï¼Œæ¯”å¦‚å‡†é™æ€ä¿¡é“çŠ¶æ€ä¿¡æ¯çš„å‡è®¾ï¼Œè¿™é™åˆ¶äº†å®ƒä»¬é€‚åº”åŠ¨æ€ç¯å¢ƒå˜åŒ–çš„èƒ½åŠ›ï¼Œå¹¶ä¸”åœ¨é¢‘ç¹å˜åŒ–çš„ä¿¡é“æ¡ä»¶ä¸‹æ€§èƒ½è¾ƒå·®ã€‚å› æ­¤ï¼Œæœ¬æ–‡å°†æ‰€é¢ä¸´çš„é—®é¢˜åˆ¶å®šä¸ºé©¬å°”å¯å¤«åšå¼ˆã€‚æˆ‘ä»¬çš„æ–°åˆ¶å®šæ–¹æ¡ˆé€‚ç”¨äºæ—¶å˜ä¿¡é“çš„å¤šç”¨æˆ·å¹²æ‰°ï¼Œå¹¶åœ¨ç”¨æˆ·ä¹‹é—´å¼•å…¥äº†åä½œå­¦ä¹ æœºåˆ¶ã€‚æ‰€è€ƒè™‘çš„ä¼˜åŒ–é—®é¢˜æ˜¯é€šè¿‡å¯ç”¨é©¾é©¶å®‰å…¨çš„å¤šæ™ºèƒ½ä½“æ·±åº¦å¼ºåŒ–å­¦ä¹ ï¼ˆDS-MADRLï¼‰æ–¹æ³•è§£å†³çš„ï¼Œè¯¥æ–¹æ³•åˆ©ç”¨äº†RICSçš„å­˜åœ¨ã€‚æˆ‘ä»¬å¤§é‡çš„æ•°å€¼è°ƒæŸ¥è¡¨æ˜ï¼Œä¸å„ç§æœ€æ–°æŠ€æœ¯åŸºå‡†ç›¸æ¯”ï¼Œæ‰€æå‡ºçš„å¼ºåŒ–å­¦ä¹ æ–¹æ³•å®ç°äº†æ›´å¿«çš„æ”¶æ•›é€Ÿåº¦ï¼Œå¹¶åœ¨æ•°æ®é€Ÿç‡å’Œé©¾é©¶å®‰å…¨æ€§æ–¹é¢å–å¾—äº†æ˜¾è‘—çš„æ”¹è¿›ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.19418v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æ¢è®¨äº†åœ¨æœªæ¥çš„è‡ªåŠ¨é©¾é©¶ç½‘ç»œä¸­ï¼Œé€šè¿‡è½¦è½½ä¼ æ„Ÿå™¨è¿›è¡Œç¯å¢ƒæ„ŸçŸ¥ä¸èåˆçš„åº”ç”¨ã€‚æ–‡ç« èšç„¦äºä¸€ä¸ªç”±å¤šè¾†è‡ªåŠ¨é©¾é©¶æ±½è½¦ç»„æˆçš„è½¦è¾†ç³»ç»Ÿï¼Œè¯¥ç³»ç»Ÿå€ŸåŠ©å¤šæ¥å…¥è¾¹ç¼˜è®¡ç®—ï¼ˆMECï¼‰è¾…åŠ©ã€‚ä¼ æ„Ÿå™¨æ”¶é›†çš„å›¾åƒæ•°æ®é€šè¿‡è½¦ä¸åŸºç¡€è®¾æ–½ï¼ˆV2Iï¼‰é“¾æ¥å¸è½½åˆ°MECæœåŠ¡å™¨ï¼ŒåŒæ—¶ä¹Ÿå¯ä»¥é€šè¿‡è½¦ä¸è½¦ï¼ˆV2Vï¼‰é€šä¿¡é“¾æ¥åœ¨å‘¨å›´è½¦è¾†ä¹‹é—´å…±äº«ã€‚ä¸ºæé«˜é¢‘è°±åˆ©ç”¨ç‡ï¼ŒV2Vé“¾æ¥å¯èƒ½å¤ç”¨ä¸V2Ié“¾æ¥çš„ç›¸åŒé¢‘è°±ï¼Œå¯¼è‡´å¹²æ‰°é—®é¢˜ã€‚ä¸ºè§£å†³è¿™ä¸€é—®é¢˜ï¼Œæœ¬æ–‡åˆ©ç”¨å¯é‡æ„æ™ºèƒ½è®¡ç®—è¡¨é¢ï¼ˆRICSsï¼‰å»ºç«‹V2Iåå°„é“¾æ¥ï¼Œå¹¶ç¼“è§£V2Vé“¾æ¥ä¸­å‡ºç°çš„å¹²æ‰°ã€‚é’ˆå¯¹ä¼ ç»Ÿç®—æ³•åœ¨å¤„ç†æ­¤é—®é¢˜æ—¶çš„å±€é™æ€§ï¼Œå¦‚å‡è®¾ä¿¡é“çŠ¶æ€ä¿¡æ¯ä¸ºé™æ€ï¼Œæ— æ³•é€‚åº”åŠ¨æ€ç¯å¢ƒå˜åŒ–ï¼Œä»¥åŠåœ¨é¢‘ç¹å˜åŒ–çš„ä¿¡é“æ¡ä»¶ä¸‹è¡¨ç°ä¸ä½³ç­‰é—®é¢˜ï¼Œæœ¬æ–‡å°†é—®é¢˜è¡¨è¿°ä¸ºé©¬å°”å¯å¤«åšå¼ˆï¼Œåº”ç”¨äºæ—¶å˜ä¿¡é“å’Œå¤šç”¨æˆ·å¹²æ‰°åœºæ™¯ï¼Œå¹¶å¼•å…¥ç”¨æˆ·é—´çš„åä½œå­¦ä¹ æœºåˆ¶ã€‚é€šè¿‡åŸºäºé©¾é©¶å®‰å…¨çš„å¤šæ™ºèƒ½ä½“æ·±åº¦å¼ºåŒ–å­¦ä¹ ï¼ˆDS-MADRLï¼‰æ–¹æ³•è§£å†³æ‰€è€ƒè™‘çš„ä¼˜åŒ–é—®é¢˜ï¼Œå¹¶åˆ©ç”¨RICSså®ç°ã€‚æ•°å€¼ç»“æœè¡¨æ˜ï¼Œæ‰€æå‡ºçš„å¼ºåŒ–å­¦ä¹ æ–¹æ³•åœ¨æ•°æ®ç‡å’Œé©¾é©¶å®‰å…¨æ€§æ–¹é¢å®ç°äº†å¿«é€Ÿæ”¶æ•›å’Œæ˜¾è‘—æ”¹è¿›ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ç¯å¢ƒæ„ŸçŸ¥å’Œèåˆé€šè¿‡è½¦è½½ä¼ æ„Ÿå™¨åœ¨æœªæ¥è‡ªåŠ¨é©¾é©¶ç½‘ç»œä¸­æœ‰å¹¿æ³›åº”ç”¨ã€‚</li>
<li>å¤šæ¥å…¥è¾¹ç¼˜è®¡ç®—ï¼ˆMECï¼‰åœ¨è‡ªåŠ¨é©¾é©¶ç³»ç»Ÿä¸­èµ·åˆ°è¾…åŠ©ä½œç”¨ï¼Œæ”¯æŒå›¾åƒæ•°æ®ä»è½¦è¾†åˆ°åŸºç¡€è®¾æ–½ï¼ˆV2Iï¼‰çš„ä¼ è¾“ã€‚</li>
<li>V2Vé€šä¿¡å’ŒV2Ié€šä¿¡å¯èƒ½å¤ç”¨ç›¸åŒçš„é¢‘è°±ï¼Œå¯¼è‡´å¹²æ‰°é—®é¢˜ã€‚</li>
<li>å¯é‡æ„æ™ºèƒ½è®¡ç®—è¡¨é¢ï¼ˆRICSsï¼‰ç”¨äºå»ºç«‹V2Iåå°„é“¾æ¥å¹¶ç¼“è§£V2Vå¹²æ‰°ã€‚</li>
<li>ä¼ ç»Ÿç®—æ³•åœ¨å¤„ç†åŠ¨æ€ç¯å¢ƒå˜åŒ–å’Œå¤šç”¨æˆ·å¹²æ‰°æ—¶å­˜åœ¨å±€é™æ€§ã€‚</li>
<li>æœ¬æ–‡å°†é—®é¢˜è¡¨è¿°ä¸ºé©¬å°”å¯å¤«åšå¼ˆï¼Œå¹¶å¼•å…¥åä½œå­¦ä¹ æœºåˆ¶æ¥è§£å†³ä¼˜åŒ–é—®é¢˜ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.19418">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-6ddb2238752409d2a04a07880a689eef.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-3c4058f8705f7b5946dd6733a89742fd.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-bf2a3f71b1cd03514f96735dae25c005.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-fd470a3f6def2a25c2188f3427c39585.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="TraF-Align-Trajectory-aware-Feature-Alignment-for-Asynchronous-Multi-agent-Perception"><a href="#TraF-Align-Trajectory-aware-Feature-Alignment-for-Asynchronous-Multi-agent-Perception" class="headerlink" title="TraF-Align: Trajectory-aware Feature Alignment for Asynchronous   Multi-agent Perception"></a>TraF-Align: Trajectory-aware Feature Alignment for Asynchronous   Multi-agent Perception</h2><p><strong>Authors:Zhiying Song, Lei Yang, Fuxi Wen, Jun Li</strong></p>
<p>Cooperative perception presents significant potential for enhancing the sensing capabilities of individual vehicles, however, inter-agent latency remains a critical challenge. Latencies cause misalignments in both spatial and semantic features, complicating the fusion of real-time observations from the ego vehicle with delayed data from others. To address these issues, we propose TraF-Align, a novel framework that learns the flow path of features by predicting the feature-level trajectory of objects from past observations up to the ego vehicleâ€™s current time. By generating temporally ordered sampling points along these paths, TraF-Align directs attention from the current-time query to relevant historical features along each trajectory, supporting the reconstruction of current-time features and promoting semantic interaction across multiple frames. This approach corrects spatial misalignment and ensures semantic consistency across agents, effectively compensating for motion and achieving coherent feature fusion. Experiments on two real-world datasets, V2V4Real and DAIR-V2X-Seq, show that TraF-Align sets a new benchmark for asynchronous cooperative perception. </p>
<blockquote>
<p>ååŒæ„ŸçŸ¥åœ¨æå‡å•ä¸ªè½¦è¾†çš„æ„ŸçŸ¥èƒ½åŠ›æ–¹é¢å…·æœ‰å·¨å¤§æ½œåŠ›ï¼Œç„¶è€Œï¼Œå¤šæ™ºèƒ½ä½“ä¹‹é—´çš„å»¶è¿Ÿä»ç„¶æ˜¯ä¸€ä¸ªå…³é”®é—®é¢˜ã€‚å»¶è¿Ÿä¼šå¯¼è‡´ç©ºé—´å’Œè¯­ä¹‰ç‰¹å¾çš„é”™ä½ï¼Œä½¿å¾—å°†å®æ—¶è§‚æµ‹æ•°æ®ä¸æ¥è‡ªå…¶ä»–è½¦è¾†çš„å»¶è¿Ÿæ•°æ®è¿›è¡Œèåˆå˜å¾—å¤æ‚ã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†TraF-Alignè¿™ä¸€æ–°å‹æ¡†æ¶ã€‚å®ƒé€šè¿‡é¢„æµ‹è¿‡å»è§‚æµ‹åˆ°çš„ç‰©ä½“çš„ç‰¹å¾çº§è½¨è¿¹åˆ°å½“å‰è½¦è¾†æ—¶é—´çš„æ–¹å¼ï¼Œå­¦ä¹ ç‰¹å¾è·¯å¾„ã€‚é€šè¿‡åœ¨è¿™äº›è·¯å¾„ä¸Šç”ŸæˆæŒ‰æ—¶é—´é¡ºåºæ’åˆ—çš„é‡‡æ ·ç‚¹ï¼ŒTraF-Alignå°†æ³¨æ„åŠ›ä»å½“å‰æ—¶é—´çš„æŸ¥è¯¢å¼•å¯¼åˆ°æ¯æ¡è½¨è¿¹ä¸Šçš„ç›¸å…³å†å²ç‰¹å¾ï¼Œæ”¯æŒå½“å‰æ—¶é—´ç‰¹å¾çš„é‡å»ºå’Œè·¨å¤šå¸§çš„è¯­ä¹‰äº¤äº’ã€‚è¿™ç§æ–¹æ³•æ ¡æ­£äº†ç©ºé—´é”™ä½ï¼Œç¡®ä¿äº†è·¨æ™ºèƒ½ä½“çš„è¯­ä¹‰ä¸€è‡´æ€§ï¼Œæœ‰æ•ˆåœ°è¡¥å¿äº†è¿åŠ¨å½±å“å¹¶å®ç°äº†è¿è´¯çš„ç‰¹å¾èåˆã€‚åœ¨V2V4Realå’ŒDAIR-V2X-Seqä¸¤ä¸ªçœŸå®æ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒTraF-Alignä¸ºå¼‚æ­¥ååŒæ„ŸçŸ¥è®¾å®šäº†æ–°çš„åŸºå‡†ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.19391v1">PDF</a> Accepted to CVPR 2025</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†åˆä½œæ„ŸçŸ¥åœ¨æå‡è½¦è¾†æ„ŸçŸ¥èƒ½åŠ›æ–¹é¢çš„å·¨å¤§æ½œåŠ›ï¼Œå¹¶æŒ‡å‡ºè·¨æ™ºèƒ½ä½“å»¶è¿Ÿæ˜¯ä¸€ä¸ªå…³é”®é—®é¢˜ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæå‡ºäº†TraF-Alignæ¡†æ¶ï¼Œé€šè¿‡é¢„æµ‹è¿‡å»è§‚å¯Ÿåˆ°å¯¹è±¡çš„ç‰¹å¾çº§è½¨è¿¹å¹¶ç”Ÿæˆæ—¶åºé‡‡æ ·ç‚¹æ¥æŒ‡å¯¼æ³¨æ„åŠ›ï¼Œå®ç°å¯¹æ—¶ç©ºä¸å¯¹é½çš„ä¿®æ­£å’Œè¯­ä¹‰ä¸€è‡´æ€§ã€‚å®éªŒè¯æ˜TraF-Alignåœ¨å¼‚æ­¥åˆä½œæ„ŸçŸ¥æ–¹é¢è¾¾åˆ°äº†æ–°çš„æ°´å¹³ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>åˆä½œæ„ŸçŸ¥å…·æœ‰æé«˜è½¦è¾†æ„ŸçŸ¥èƒ½åŠ›çš„æ½œåŠ›ï¼Œä½†è·¨æ™ºèƒ½ä½“å»¶è¿Ÿæ˜¯æ ¸å¿ƒæŒ‘æˆ˜ã€‚</li>
<li>TraF-Alignæ¡†æ¶é€šè¿‡å­¦ä¹ ç‰¹å¾æµè·¯å¾„æ¥è§£å†³è¿™ä¸€é—®é¢˜ã€‚</li>
<li>TraF-Aligné€šè¿‡é¢„æµ‹å¯¹è±¡ç‰¹å¾çº§è½¨è¿¹ç”Ÿæˆæ—¶åºé‡‡æ ·ç‚¹ï¼Œå®ç°æ³¨æ„åŠ›å¼•å¯¼ã€‚</li>
<li>è¯¥æ¡†æ¶èƒ½å¤Ÿçº æ­£ç©ºé—´ä¸å¯¹é½å¹¶ç¡®ä¿è·¨æ™ºèƒ½ä½“çš„è¯­ä¹‰ä¸€è‡´æ€§ã€‚</li>
<li>TraF-Alignæ¡†æ¶åœ¨å¼‚æ­¥åˆä½œæ„ŸçŸ¥æ–¹é¢å–å¾—äº†æ˜¾è‘—æˆæœã€‚</li>
<li>å®éªŒåœ¨ä¸¤ä¸ªçœŸå®æ•°æ®é›†V2V4Realå’ŒDAIR-V2X-Seqä¸ŠéªŒè¯äº†TraF-Alignçš„æœ‰æ•ˆæ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.19391">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-33d0ad571c245ef909f6d1103954d55c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-5b6445aa041ffb982879f27977365a18.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-5d8908f76a29334d00b68a5f48d335cf.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d61e35b0d4c9a56c56349fc27d6129d7.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-ff46ca33e5cf7f5e3c4c85dfee7e5b15.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="CoMAC-Conversational-Agent-for-Multi-Source-Auxiliary-Context-with-Sparse-and-Symmetric-Latent-Interactions"><a href="#CoMAC-Conversational-Agent-for-Multi-Source-Auxiliary-Context-with-Sparse-and-Symmetric-Latent-Interactions" class="headerlink" title="CoMAC: Conversational Agent for Multi-Source Auxiliary Context with   Sparse and Symmetric Latent Interactions"></a>CoMAC: Conversational Agent for Multi-Source Auxiliary Context with   Sparse and Symmetric Latent Interactions</h2><p><strong>Authors:Junfeng Liu, Christopher T. Symons, Ranga Raju Vatsavai</strong></p>
<p>Recent advancements in AI-driven conversational agents have exhibited immense potential of AI applications. Effective response generation is crucial to the success of these agents. While extensive research has focused on leveraging multiple auxiliary data sources (e.g., knowledge bases and personas) to enhance response generation, existing methods often struggle to efficiently extract relevant information from these sources. There are still clear limitations in the ability to combine versatile conversational capabilities with adherence to known facts and adaptation to large variations in user preferences and belief systems, which continues to hinder the wide adoption of conversational AI tools. This paper introduces a novel method, Conversational Agent for Multi-Source Auxiliary Context with Sparse and Symmetric Latent Interactions (CoMAC), for conversation generation, which employs specialized encoding streams and post-fusion grounding networks for multiple data sources to identify relevant persona and knowledge information for the conversation. CoMAC also leverages a novel text similarity metric that allows bi-directional information sharing among multiple sources and focuses on a selective subset of meaningful words. Our experiments show that CoMAC improves the relevant persona and knowledge prediction accuracies and response generation quality significantly over two state-of-the-art methods. </p>
<blockquote>
<p>è¿‘æœŸäººå·¥æ™ºèƒ½é©±åŠ¨çš„å¯¹è¯ä»£ç†äººçš„è¿›å±•å±•ç°äº†äººå·¥æ™ºèƒ½åº”ç”¨çš„å·¨å¤§æ½œåŠ›ã€‚æœ‰æ•ˆçš„å“åº”ç”Ÿæˆå¯¹è¿™äº›ä»£ç†äººçš„æˆåŠŸè‡³å…³é‡è¦ã€‚è™½ç„¶å¤§é‡ç ”ç©¶èšç„¦äºåˆ©ç”¨å¤šç§è¾…åŠ©æ•°æ®æºï¼ˆå¦‚çŸ¥è¯†åº“å’Œäººç‰©ç‰¹å¾ï¼‰æ¥æå‡å“åº”ç”Ÿæˆï¼Œä½†ç°æœ‰æ–¹æ³•å¾€å¾€éš¾ä»¥ä»è¿™äº›æ•°æ®æºä¸­é«˜æ•ˆåœ°æå–ç›¸å…³ä¿¡æ¯ã€‚åœ¨ç»“åˆå¤šåŠŸèƒ½å¯¹è¯èƒ½åŠ›ä¸éµå®ˆå·²çŸ¥äº‹å®ï¼Œä»¥åŠé€‚åº”ç”¨æˆ·åå¥½å’Œä¿¡ä»°ç³»ç»Ÿçš„å·¨å¤§å˜åŒ–æ–¹é¢ï¼Œä»å­˜åœ¨æ˜ç¡®å±€é™ï¼Œè¿™ç»§ç»­é˜»ç¢å¯¹è¯å¼äººå·¥æ™ºèƒ½å·¥å…·çš„å¹¿æ³›é‡‡ç”¨ã€‚æœ¬æ–‡ä»‹ç»äº†ä¸€ç§ç”¨äºå¯¹è¯ç”Ÿæˆçš„æ–°å‹æ–¹æ³•â€”â€”å…·æœ‰ç¨€ç–å’Œå¯¹ç§°æ½œåœ¨äº¤äº’çš„å¤šæºè¾…åŠ©ä¸Šä¸‹æ–‡å¯¹è¯ä»£ç†äººï¼ˆCoMACï¼‰ã€‚CoMACé‡‡ç”¨ä¸“é—¨ç¼–ç æµå’Œç”¨äºå¤šä¸ªæ•°æ®æºçš„åæœŸèåˆå®šä½ç½‘ç»œï¼Œä»¥è¯†åˆ«ä¸å¯¹è¯ç›¸å…³çš„è§’è‰²å’ŒçŸ¥è¯†ä¿¡æ¯ã€‚CoMACè¿˜åˆ©ç”¨ä¸€ç§æ–°å‹æ–‡æœ¬ç›¸ä¼¼åº¦åº¦é‡ï¼Œå…è®¸å¤šä¸ªæ•°æ®æºä¹‹é—´çš„åŒå‘ä¿¡æ¯å…±äº«ï¼Œå¹¶ä¾§é‡äºæœ‰æ„ä¹‰çš„å•è¯çš„å­é›†ã€‚æˆ‘ä»¬çš„å®éªŒè¡¨æ˜ï¼Œä¸ä¸¤ç§æœ€å…ˆè¿›çš„æ–¹æ³•ç›¸æ¯”ï¼ŒCoMACåœ¨ç›¸å…³äººç‰©å’ŒçŸ¥è¯†é¢„æµ‹å‡†ç¡®æ€§ä»¥åŠå“åº”ç”Ÿæˆè´¨é‡æ–¹é¢éƒ½æœ‰æ˜¾è‘—æé«˜ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.19274v1">PDF</a> The 29th Pacific-Asia Conference on Knowledge Discovery and Data   Mining (PAKDD2025)</p>
<p><strong>Summary</strong><br>     è¿‘æœŸAIé©±åŠ¨å¯¹è¯ä»£ç†äººçš„è¿›å±•å±•ç°äº†AIåº”ç”¨çš„å·¨å¤§æ½œåŠ›ã€‚æœ‰æ•ˆå“åº”ç”Ÿæˆå¯¹äºå¯¹è¯ä»£ç†äººçš„æˆåŠŸè‡³å…³é‡è¦ã€‚å°½ç®¡å·²æœ‰å¤§é‡ç ”ç©¶è‡´åŠ›äºåˆ©ç”¨å¤šç§è¾…åŠ©æ•°æ®æºï¼ˆå¦‚çŸ¥è¯†åº“å’Œäººç‰©ï¼‰æ¥æå‡å“åº”ç”Ÿæˆï¼Œä½†ç°æœ‰æ–¹æ³•å¾€å¾€éš¾ä»¥ä»è¿™äº›æ•°æ®æºä¸­æœ‰æ•ˆæå–ç›¸å…³ä¿¡æ¯ã€‚æœ¬æ–‡ä»‹ç»äº†ä¸€ç§æ–°çš„å¯¹è¯ç”Ÿæˆæ–¹æ³•â€”â€”åŸºäºå¤šæºè¾…åŠ©è¯­å¢ƒçš„å¯¹è¯ä»£ç†CoMACï¼Œå®ƒé‡‡ç”¨ä¸“é—¨çš„ç¼–ç æµå’Œåèåˆå®šä½ç½‘ç»œæ¥å¤„ç†å¤šä¸ªæ•°æ®æºï¼Œä»¥è¯†åˆ«ä¸å¯¹è¯ç›¸å…³çš„ä¸ªæ€§åŒ–å’ŒçŸ¥è¯†ä¿¡æ¯ã€‚CoMACè¿˜åˆ©ç”¨ä¸€ç§æ–°å‹æ–‡æœ¬ç›¸ä¼¼åº¦åº¦é‡ï¼Œå®ç°å¤šæºä¹‹é—´çš„åŒå‘ä¿¡æ¯å…±äº«ï¼Œå¹¶ä¸“æ³¨äºæœ‰æ„ä¹‰çš„å•è¯å­é›†ã€‚å®éªŒè¡¨æ˜ï¼Œç›¸è¾ƒäºä¸¤ç§æœ€æ–°æŠ€æœ¯ï¼ŒCoMACåœ¨ç›¸å…³ä¸ªæ€§åŒ–çŸ¥è¯†é¢„æµ‹å‡†ç¡®æ€§å’Œå“åº”ç”Ÿæˆè´¨é‡ä¸Šæœ‰äº†æ˜¾è‘—æå‡ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>AIé©±åŠ¨å¯¹è¯ä»£ç†äººçš„å‘å±•å±•ç°äº†å·¨å¤§çš„æ½œåŠ›ã€‚</li>
<li>æœ‰æ•ˆå“åº”ç”Ÿæˆå¯¹äºå¯¹è¯ä»£ç†äººçš„æˆåŠŸè‡³å…³é‡è¦ã€‚</li>
<li>å½“å‰æ–¹æ³•éš¾ä»¥ä»å¤šä¸ªè¾…åŠ©æ•°æ®æºä¸­æå–ç›¸å…³ä¿¡æ¯ã€‚</li>
<li>CoMACæ˜¯ä¸€ç§æ–°çš„å¯¹è¯ç”Ÿæˆæ–¹æ³•ï¼Œé‡‡ç”¨ä¸“é—¨çš„ç¼–ç æµå’Œåèåˆå®šä½ç½‘ç»œå¤„ç†å¤šä¸ªæ•°æ®æºã€‚</li>
<li>CoMACèƒ½è¯†åˆ«ä¸å¯¹è¯ç›¸å…³çš„ä¸ªæ€§åŒ–å’ŒçŸ¥è¯†ä¿¡æ¯ã€‚</li>
<li>CoMACåˆ©ç”¨æ–°å‹æ–‡æœ¬ç›¸ä¼¼åº¦åº¦é‡å®ç°å¤šæºä¹‹é—´çš„åŒå‘ä¿¡æ¯å…±äº«ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.19274">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-05ee97b3754a05aadf036c7619615647.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="AgentDropout-Dynamic-Agent-Elimination-for-Token-Efficient-and-High-Performance-LLM-Based-Multi-Agent-Collaboration"><a href="#AgentDropout-Dynamic-Agent-Elimination-for-Token-Efficient-and-High-Performance-LLM-Based-Multi-Agent-Collaboration" class="headerlink" title="AgentDropout: Dynamic Agent Elimination for Token-Efficient and   High-Performance LLM-Based Multi-Agent Collaboration"></a>AgentDropout: Dynamic Agent Elimination for Token-Efficient and   High-Performance LLM-Based Multi-Agent Collaboration</h2><p><strong>Authors:Zhexuan Wang, Yutong Wang, Xuebo Liu, Liang Ding, Miao Zhang, Jie Liu, Min Zhang</strong></p>
<p>Multi-agent systems (MAS) based on large language models (LLMs) have demonstrated significant potential in collaborative problem-solving. However, they still face substantial challenges of low communication efficiency and suboptimal task performance, making the careful design of the agentsâ€™ communication topologies particularly important. Inspired by the management theory that roles in an efficient team are often dynamically adjusted, we propose AgentDropout, which identifies redundant agents and communication across different communication rounds by optimizing the adjacency matrices of the communication graphs and eliminates them to enhance both token efficiency and task performance. Compared to state-of-the-art methods, AgentDropout achieves an average reduction of 21.6% in prompt token consumption and 18.4% in completion token consumption, along with a performance improvement of 1.14 on the tasks. Furthermore, the extended experiments demonstrate that AgentDropout achieves notable domain transferability and structure robustness, revealing its reliability and effectiveness. We release our code at <a target="_blank" rel="noopener" href="https://github.com/wangzx1219/AgentDropout">https://github.com/wangzx1219/AgentDropout</a>. </p>
<blockquote>
<p>åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„å¤šæ™ºèƒ½ä½“ç³»ç»Ÿï¼ˆMASï¼‰åœ¨åä½œè§£å†³é—®é¢˜æ–¹é¢æ˜¾ç¤ºå‡ºå·¨å¤§çš„æ½œåŠ›ã€‚ç„¶è€Œï¼Œå®ƒä»¬ä»ç„¶é¢ä¸´é€šä¿¡æ•ˆç‡ä½å’Œä»»åŠ¡æ€§èƒ½ä¸ä½³çš„é‡å¤§æŒ‘æˆ˜ï¼Œè¿™ä½¿å¾—ç²¾å¿ƒè®¾è®¡æ™ºèƒ½ä½“çš„é€šä¿¡æ‹“æ‰‘å°¤ä¸ºé‡è¦ã€‚å—ç®¡ç†ç†è®ºçš„å¯å‘ï¼Œé«˜æ•ˆå›¢é˜Ÿä¸­çš„è§’è‰²å¾€å¾€åŠ¨æ€è°ƒæ•´ï¼Œæˆ‘ä»¬æå‡ºAgentDropoutï¼Œå®ƒé€šè¿‡ä¼˜åŒ–é€šä¿¡å›¾çš„é‚»æ¥çŸ©é˜µï¼Œè¯†åˆ«å†—ä½™çš„æ™ºèƒ½ä½“ä»¥åŠä¸åŒé€šä¿¡è½®æ¬¡ä¹‹é—´çš„é€šä¿¡ï¼Œå¹¶æ¶ˆé™¤å®ƒä»¬ï¼Œä»¥æé«˜ä»¤ç‰Œæ•ˆç‡å’Œä»»åŠ¡æ€§èƒ½ã€‚ä¸æœ€å…ˆè¿›çš„æ–¹æ³•ç›¸æ¯”ï¼ŒAgentDropoutå¹³å‡å‡å°‘äº†21.6%çš„æç¤ºä»¤ç‰Œæ¶ˆè€—å’Œ18.4%çš„å®Œæˆä»¤ç‰Œæ¶ˆè€—ï¼Œä»»åŠ¡æ€§èƒ½æé«˜äº†1.14ã€‚æ­¤å¤–ï¼Œæ‰©å±•å®éªŒè¡¨æ˜ï¼ŒAgentDropoutå…·æœ‰æ˜¾è‘—çš„é¢†åŸŸå¯è½¬ç§»æ€§å’Œç»“æ„ç¨³å¥æ€§ï¼Œè¯æ˜äº†å…¶å¯é æ€§å’Œæœ‰æ•ˆæ€§ã€‚æˆ‘ä»¬å·²å°†ä»£ç å‘å¸ƒåœ¨<a target="_blank" rel="noopener" href="https://github.com/wangzx1219/AgentDropout%E3%80%82">https://github.com/wangzx1219/AgentDropoutã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.18891v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹çš„å¤šæ™ºèƒ½ä½“ç³»ç»Ÿå·²ç»åœ¨ååŒè§£å†³é—®é¢˜æ–¹é¢å±•ç°å‡ºå·¨å¤§æ½œåŠ›ï¼Œä½†ä»é¢ä¸´æ²Ÿé€šæ•ˆç‡ä½ä¸‹å’Œä»»åŠ¡æ€§èƒ½ä¸ä½³çš„æŒ‘æˆ˜ã€‚æœ¬æ–‡æå‡ºçš„AgentDropouté€šè¿‡ä¼˜åŒ–é€šä¿¡å›¾çš„é‚»æ¥çŸ©é˜µï¼Œè¯†åˆ«å†—ä½™æ™ºèƒ½ä½“å’Œé€šä¿¡è½®æ¬¡ä¸­çš„é€šä¿¡ï¼Œæ¶ˆé™¤å®ƒä»¬ä»¥æé«˜ä»¤ç‰Œæ•ˆç‡å’Œä»»åŠ¡æ€§èƒ½ã€‚ç›¸æ¯”æœ€æ–°æ–¹æ³•ï¼ŒAgentDropoutå¹³å‡å‡å°‘21.6%çš„æç¤ºä»¤ç‰Œæ¶ˆè€—å’Œ18.4%çš„å®Œæˆä»¤ç‰Œæ¶ˆè€—ï¼Œä»»åŠ¡æ€§èƒ½æå‡1.14ã€‚æ­¤å¤–ï¼Œæ‰©å±•å®éªŒè¡¨æ˜AgentDropoutå…·æœ‰æ˜¾è‘—é¢†åŸŸå¯è½¬ç§»æ€§å’Œç»“æ„ç¨³å¥æ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤šæ™ºèƒ½ä½“ç³»ç»ŸåŸºäºå¤§å‹è¯­è¨€æ¨¡å‹åœ¨ååŒè§£å†³é—®é¢˜æ–¹é¢å…·æœ‰å·¨å¤§æ½œåŠ›ã€‚</li>
<li>é¢ä¸´æ²Ÿé€šæ•ˆç‡ä½ä¸‹å’Œä»»åŠ¡æ€§èƒ½ä¸ä½³çš„æŒ‘æˆ˜ã€‚</li>
<li>AgentDropouté€šè¿‡ä¼˜åŒ–é€šä¿¡å›¾çš„é‚»æ¥çŸ©é˜µè¯†åˆ«å¹¶æ¶ˆé™¤å†—ä½™æ™ºèƒ½ä½“å’Œé€šä¿¡ï¼Œæé«˜ä»¤ç‰Œæ•ˆç‡å’Œä»»åŠ¡æ€§èƒ½ã€‚</li>
<li>AgentDropoutç›¸æ¯”æœ€æ–°æ–¹æ³•å¹³å‡å‡å°‘æç¤ºä»¤ç‰Œå’Œå®Œæˆä»¤ç‰Œçš„æ¶ˆè€—ï¼ŒåŒæ—¶æé«˜ä»»åŠ¡æ€§èƒ½ã€‚</li>
<li>AgentDropoutå…·æœ‰æ˜¾è‘—é¢†åŸŸå¯è½¬ç§»æ€§ï¼Œèƒ½å¤Ÿé€‚åº”ä¸åŒçš„é¢†åŸŸä»»åŠ¡ã€‚</li>
<li>AgentDropoutå…·æœ‰ç»“æ„ç¨³å¥æ€§ï¼Œåœ¨ä¸åŒé€šä¿¡ç»“æ„ä¸‹è¡¨ç°ç¨³å®šã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.18891">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-560c763fba6aa97e68dd6e3651683ed2.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-80b6200c549259a8021a43694350ccf4.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e7ceb5fe4d447fa268fadb814a42b210.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-266158819f233b2a5e04c54aea11ead9.jpg" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="Learning-Multi-Robot-Coordination-through-Locality-Based-Factorized-Multi-Agent-Actor-Critic-Algorithm"><a href="#Learning-Multi-Robot-Coordination-through-Locality-Based-Factorized-Multi-Agent-Actor-Critic-Algorithm" class="headerlink" title="Learning Multi-Robot Coordination through Locality-Based Factorized   Multi-Agent Actor-Critic Algorithm"></a>Learning Multi-Robot Coordination through Locality-Based Factorized   Multi-Agent Actor-Critic Algorithm</h2><p><strong>Authors:Chak Lam Shek, Amrit Singh Bedi, Anjon Basak, Ellen Novoseller, Nick Waytowich, Priya Narayanan, Dinesh Manocha, Pratap Tokekar</strong></p>
<p>In this work, we present a novel cooperative multi-agent reinforcement learning method called \textbf{Loc}ality based \textbf{Fac}torized \textbf{M}ulti-Agent \textbf{A}ctor-\textbf{C}ritic (Loc-FACMAC). Existing state-of-the-art algorithms, such as FACMAC, rely on global reward information, which may not accurately reflect the quality of individual robotsâ€™ actions in decentralized systems. We integrate the concept of locality into critic learning, where strongly related robots form partitions during training. Robots within the same partition have a greater impact on each other, leading to more precise policy evaluation. Additionally, we construct a dependency graph to capture the relationships between robots, facilitating the partitioning process. This approach mitigates the curse of dimensionality and prevents robots from using irrelevant information. Our method improves existing algorithms by focusing on local rewards and leveraging partition-based learning to enhance training efficiency and performance. We evaluate the performance of Loc-FACMAC in three environments: Hallway, Multi-cartpole, and Bounded-Cooperative-Navigation. We explore the impact of partition sizes on the performance and compare the result with baseline MARL algorithms such as LOMAQ, FACMAC, and QMIX. The experiments reveal that, if the locality structure is defined properly, Loc-FACMAC outperforms these baseline algorithms up to 108%, indicating that exploiting the locality structure in the actor-critic framework improves the MARL performance. </p>
<blockquote>
<p>åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°çš„åˆä½œå¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ æ–¹æ³•ï¼Œç§°ä¸ºåŸºäºå±€éƒ¨æ€§å› å­çš„åˆ†è§£å¤šæ™ºèƒ½ä½“æ¼”å‘˜è¯„è®ºå®¶æ–¹æ³•ï¼ˆLoc-FACMACï¼‰ã€‚ç°æœ‰æœ€å…ˆè¿›çš„ç®—æ³•ï¼Œå¦‚FACMACï¼Œä¾èµ–äºå…¨å±€å¥–åŠ±ä¿¡æ¯ï¼Œè¿™å¯èƒ½æ— æ³•å‡†ç¡®åæ˜ åˆ†æ•£ç³»ç»Ÿä¸­å•ä¸ªæœºå™¨äººçš„è¡ŒåŠ¨è´¨é‡ã€‚æˆ‘ä»¬å°†å±€éƒ¨æ€§çš„æ¦‚å¿µæ•´åˆåˆ°è¯„è®ºå®¶å­¦ä¹ ä¸­ï¼Œåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œç´§å¯†ç›¸å…³çš„æœºå™¨äººå½¢æˆåˆ†åŒºã€‚åŒä¸€åˆ†åŒºå†…çš„æœºå™¨äººå½¼æ­¤é—´çš„å½±å“æ›´å¤§ï¼Œä»è€Œå¯¼è‡´æ›´ç²¾ç¡®çš„ç­–ç•¥è¯„ä¼°ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æ„å»ºäº†ä¸€ä¸ªä¾èµ–å›¾æ¥æ•æ‰æœºå™¨äººä¹‹é—´çš„å…³ç³»ï¼Œä»è€Œå¸®åŠ©åˆ†åŒºè¿‡ç¨‹ã€‚è¿™ç§æ–¹æ³•å‡è½»äº†ç»´åº¦è¯…å’’ï¼Œå¹¶é˜²æ­¢æœºå™¨äººä½¿ç”¨æ— å…³ä¿¡æ¯ã€‚æˆ‘ä»¬çš„æ–¹æ³•é€šè¿‡å…³æ³¨å±€éƒ¨å¥–åŠ±å¹¶åˆ©ç”¨åŸºäºåˆ†åŒºçš„å­¦ä¹ æ¥æé«˜è®­ç»ƒæ•ˆç‡å’Œæ€§èƒ½ï¼Œæ”¹è¿›äº†ç°æœ‰ç®—æ³•ã€‚æˆ‘ä»¬åœ¨èµ°å»Šã€å¤šæ‘†æ†å’Œæœ‰é™åˆä½œå¯¼èˆªä¸‰ä¸ªç¯å¢ƒä¸­è¯„ä¼°äº†Loc-FACMACçš„æ€§èƒ½ã€‚æˆ‘ä»¬æ¢è®¨äº†åˆ†åŒºå¤§å°å¯¹æ€§èƒ½çš„å½±å“ï¼Œå¹¶å°†ç»“æœä¸LOMAQã€FACMACå’ŒQMIXç­‰åŸºçº¿MARLç®—æ³•çš„ç»“æœè¿›è¡Œæ¯”è¾ƒã€‚å®éªŒè¡¨æ˜ï¼Œå¦‚æœå±€éƒ¨ç»“æ„å®šä¹‰å¾—å½“ï¼ŒLoc-FACMACçš„æ€§èƒ½æœ€å¤šå¯æé«˜108%ï¼Œè¿™è¡¨æ˜åœ¨æ¼”å‘˜è¯„è®ºå®¶æ¡†æ¶ä¸­åˆ©ç”¨å±€éƒ¨ç»“æ„å¯ä»¥æé«˜MARLçš„æ€§èƒ½ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.18816v1">PDF</a> </p>
<p><strong>Summary</strong><br>     æœ¬ç ”ç©¶æå‡ºäº†ä¸€ç§åŸºäºå±€éƒ¨æ€§çš„ååŒå¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ æ–°æ–¹æ³•â€”â€”å±€éƒ¨å› å­åŒ–å¤šæ™ºèƒ½ä½“è¡ŒåŠ¨è€…è¯„è®ºå®¶ï¼ˆLoc-FACMACï¼‰ã€‚ç°æœ‰é¡¶å°–ç®—æ³•å¦‚FACMACä¾èµ–å…¨å±€å¥–åŠ±ä¿¡æ¯ï¼Œåœ¨åˆ†å¸ƒå¼ç³»ç»Ÿä¸­å¯èƒ½æ— æ³•å‡†ç¡®åæ˜ ä¸ªä½“æœºå™¨äººçš„è¡ŒåŠ¨è´¨é‡ã€‚æœ¬ç ”ç©¶å°†å±€éƒ¨æ€§æ¦‚å¿µèå…¥è¯„è®ºå®¶å­¦ä¹ ï¼Œåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­è®©ç´§å¯†ç›¸å…³çš„æœºå™¨äººå½¢æˆåˆ†åŒºã€‚åŒä¸€åˆ†åŒºå†…çš„æœºå™¨äººç›¸äº’é—´å½±å“æ›´å¤§ï¼Œä»è€Œå®ç°æ›´ç²¾ç¡®çš„ç­–ç•¥è¯„ä¼°ã€‚æ­¤å¤–ï¼Œç ”ç©¶æ„å»ºäº†ä¾èµ–å›¾æ¥æ•æ‰æœºå™¨äººä¹‹é—´çš„å…³ç³»ï¼Œä¿ƒè¿›åˆ†åŒºè¿‡ç¨‹ã€‚æ­¤æ–¹æ³•å‡è½»äº†ç»´åº¦è¯…å’’ï¼Œé˜²æ­¢æœºå™¨äººä½¿ç”¨æ— å…³ä¿¡æ¯ã€‚é€šè¿‡ä¸“æ³¨äºå±€éƒ¨å¥–åŠ±å’ŒåŸºäºåˆ†åŒºçš„å­¦ä¹ ï¼Œæˆ‘ä»¬çš„æ–¹æ³•æ”¹è¿›äº†ç°æœ‰ç®—æ³•ï¼Œæé«˜äº†è®­ç»ƒæ•ˆç‡å’Œæ€§èƒ½ã€‚åœ¨èµ°å»Šã€å¤šæ‘†æ†å’Œæœ‰é™åˆä½œå¯¼èˆªä¸‰ä¸ªç¯å¢ƒä¸­è¯„ä¼°äº†Loc-FACMACçš„æ€§èƒ½ï¼Œå¹¶æ¢ç´¢äº†åˆ†åŒºå¤§å°å¯¹æ€§èƒ½çš„å½±å“ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œå¦‚æœå®šä¹‰é€‚å½“çš„å±€éƒ¨ç»“æ„ï¼ŒLoc-FACMACçš„æ€§èƒ½è¾ƒåŸºçº¿MARLç®—æ³•å¯æé«˜è‡³108%ï¼Œè¡¨æ˜åœ¨è¡ŒåŠ¨è€…è¯„è®ºå®¶æ¡†æ¶ä¸­åˆ©ç”¨å±€éƒ¨ç»“æ„èƒ½æé«˜MARLæ€§èƒ½ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>Loc-FACMACæ˜¯ä¸€ç§æ–°å‹çš„åˆä½œå¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ æ–¹æ³•ï¼Œè€ƒè™‘äº†å±€éƒ¨æ€§ç‰¹ç‚¹ã€‚</li>
<li>ä¸ä¾èµ–å…¨å±€å¥–åŠ±ä¿¡æ¯çš„ç°æœ‰é¡¶å°–ç®—æ³•ç›¸æ¯”ï¼ŒLoc-FACMACæ›´èƒ½ç²¾ç¡®åæ˜ ä¸ªä½“æœºå™¨äººçš„è¡ŒåŠ¨è´¨é‡ã€‚</li>
<li>Loc-FACMACé€šè¿‡å½¢æˆæœºå™¨äººåˆ†åŒºæ¥ä¼˜åŒ–è®­ç»ƒè¿‡ç¨‹ï¼Œæé«˜ç­–ç•¥è¯„ä¼°çš„ç²¾ç¡®åº¦ã€‚</li>
<li>ä¾èµ–å›¾çš„æ„å»ºæœ‰åŠ©äºæ•æ‰æœºå™¨äººé—´çš„å¤æ‚å…³ç³»ï¼Œæ¨åŠ¨åˆ†åŒºè¿‡ç¨‹è¿›è¡Œã€‚</li>
<li>Loc-FACMACè§£å†³äº†ç»´åº¦è¯…å’’é—®é¢˜ï¼Œé¿å…äº†æ— å…³ä¿¡æ¯çš„å¹²æ‰°ã€‚</li>
<li>Loc-FACMACé€šè¿‡åœ¨å±€éƒ¨å¥–åŠ±å’Œåˆ†åŒºå­¦ä¹ æ–¹é¢çš„ä¼˜åŒ–æ”¹è¿›äº†ç°æœ‰ç®—æ³•ï¼Œæå‡äº†è®­ç»ƒæ•ˆç‡å’Œæ€§èƒ½ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.18816">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-3ec6d05ad7c39cde6d61243478925060.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-6de9abfbd690b11fd0992e85a6086280.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-fe570f016824898fefb87fd926cba1e7.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ed47ce7e90bf3404a0f716d07fe09479.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-589ce16cb62dc4e97d21ad33c5bb4f90.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-40c3426a5179d376007f3e8077f9f83d.jpg" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1><h2 id="AgentSpec-Customizable-Runtime-Enforcement-for-Safe-and-Reliable-LLM-Agents"><a href="#AgentSpec-Customizable-Runtime-Enforcement-for-Safe-and-Reliable-LLM-Agents" class="headerlink" title="AgentSpec: Customizable Runtime Enforcement for Safe and Reliable LLM   Agents"></a>AgentSpec: Customizable Runtime Enforcement for Safe and Reliable LLM   Agents</h2><p><strong>Authors:Haoyu Wang, Christopher M. Poskitt, Jun Sun</strong></p>
<p>Agents built on LLMs are increasingly deployed across diverse domains, automating complex decision-making and task execution. However, their autonomy introduces safety risks, including security vulnerabilities, legal violations, and unintended harmful actions. Existing mitigation methods, such as model-based safeguards and early enforcement strategies, fall short in robustness, interpretability, and adaptability. To address these challenges, we propose AgentSpec, a lightweight domain-specific language for specifying and enforcing runtime constraints on LLM agents. With AgentSpec, users define structured rules that incorporate triggers, predicates, and enforcement mechanisms, ensuring agents operate within predefined safety boundaries. We implement AgentSpec across multiple domains, including code execution, embodied agents, and autonomous driving, demonstrating its adaptability and effectiveness. Our evaluation shows that AgentSpec successfully prevents unsafe executions in over 90% of code agent cases, eliminates all hazardous actions in embodied agent tasks, and enforces 100% compliance by autonomous vehicles (AVs). Despite its strong safety guarantees, AgentSpec remains computationally lightweight, with overheads in milliseconds. By combining interpretability, modularity, and efficiency, AgentSpec provides a practical and scalable solution for enforcing LLM agent safety across diverse applications. We also automate the generation of rules using LLMs and assess their effectiveness. Our evaluation shows that the rules generated by OpenAI o1 achieve a precision of 95.56% and recall of 70.96% for embodied agents, successfully identifying 87.26% of the risky code, and prevent AVs from breaking laws in 5 out of 8 scenarios. </p>
<blockquote>
<p>åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„ä»£ç†æ­£è¶Šæ¥è¶Šå¤šåœ°éƒ¨ç½²åœ¨å„ä¸ªé¢†åŸŸï¼Œè‡ªåŠ¨åŒ–å¤æ‚çš„å†³ç­–å’Œä»»åŠ¡æ‰§è¡Œã€‚ç„¶è€Œï¼Œå®ƒä»¬çš„è‡ªä¸»æ€§å¸¦æ¥äº†å®‰å…¨é£é™©ï¼ŒåŒ…æ‹¬å®‰å…¨æ¼æ´ã€æ³•å¾‹è¿è§„å’Œæ„å¤–çš„æœ‰å®³è¡Œä¸ºã€‚ç°æœ‰çš„ç¼“è§£æ–¹æ³•ï¼Œå¦‚åŸºäºæ¨¡å‹çš„ä¿éšœå’Œæ—©æœŸæ‰§è¡Œç­–ç•¥ï¼Œåœ¨ç¨³å¥æ€§ã€å¯è§£é‡Šæ€§å’Œé€‚åº”æ€§æ–¹é¢å­˜åœ¨ä¸è¶³ã€‚ä¸ºäº†è§£å†³è¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†AgentSpecï¼Œä¸€ç§ç”¨äºå¯¹LLMä»£ç†æŒ‡å®šå’Œæ‰§è¡Œè¿è¡Œæ—¶çº¦æŸçš„è½»é‡çº§é¢†åŸŸç‰¹å®šè¯­è¨€ã€‚é€šè¿‡AgentSpecï¼Œç”¨æˆ·å®šä¹‰åŒ…å«è§¦å‘å™¨ã€è°“è¯å’Œæ‰§è¡Œæœºåˆ¶çš„ç»“æ„åŒ–è§„åˆ™ï¼Œç¡®ä¿ä»£ç†åœ¨é¢„å®šçš„å®‰å…¨è¾¹ç•Œå†…è¿è¡Œã€‚æˆ‘ä»¬åœ¨å¤šä¸ªé¢†åŸŸå®ç°äº†AgentSpecï¼ŒåŒ…æ‹¬ä»£ç æ‰§è¡Œã€å®ä½“ä»£ç†å’Œè‡ªåŠ¨é©¾é©¶ï¼Œå±•ç¤ºäº†å…¶é€‚åº”æ€§å’Œæœ‰æ•ˆæ€§ã€‚æˆ‘ä»¬çš„è¯„ä¼°æ˜¾ç¤ºï¼ŒAgentSpecæˆåŠŸé˜²æ­¢äº†è¶…è¿‡90%çš„ä»£ç ä»£ç†æ¡ˆä¾‹ä¸­çš„ä¸å®‰å…¨æ‰§è¡Œï¼Œæ¶ˆé™¤äº†å®ä½“ä»£ç†ä»»åŠ¡ä¸­çš„æ‰€æœ‰å±é™©è¡Œä¸ºï¼Œå¹¶ä½¿è‡ªåŠ¨é©¾é©¶æ±½è½¦è¾¾åˆ°100%çš„åˆè§„æ€§ã€‚å°½ç®¡AgentSpecæä¾›äº†å¼ºå¤§çš„å®‰å…¨ä¿è¯ï¼Œä½†å®ƒçš„è®¡ç®—ä»ç„¶å¾ˆè½»é‡çº§ï¼Œå¼€é”€ä»…ä¸ºæ¯«ç§’çº§ã€‚é€šè¿‡ç»“åˆå¯è§£é‡Šæ€§ã€æ¨¡å—åŒ–å’Œæ•ˆç‡ï¼ŒAgentSpecä¸ºåœ¨å¤šç§åº”ç”¨ä¸­å¼ºåˆ¶å®æ–½LLMä»£ç†å®‰å…¨æä¾›äº†å®ç”¨ä¸”å¯æ‰©å±•çš„è§£å†³æ–¹æ¡ˆã€‚æˆ‘ä»¬è¿˜ä½¿ç”¨LLMè‡ªåŠ¨åŒ–ç”Ÿæˆè§„åˆ™å¹¶è¯„ä¼°äº†å…¶æœ‰æ•ˆæ€§ã€‚æˆ‘ä»¬çš„è¯„ä¼°æ˜¾ç¤ºï¼ŒOpenAI o1ç”Ÿæˆçš„è§„åˆ™åœ¨å®ä½“ä»£ç†ä¸Šè¾¾åˆ°äº†95.56%çš„ç²¾åº¦å’Œ70.96%çš„å¬å›ç‡ï¼ŒæˆåŠŸè¯†åˆ«äº†87.26%çš„é£é™©ä»£ç ï¼Œå¹¶åœ¨5ä¸ªåœºæ™¯çš„8ä¸ªè‡ªåŠ¨é©¾é©¶è½¦è¾†ä¸­é˜²æ­¢äº†è¿è§„è¡Œä¸ºã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.18666v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>åŸºäºLLMæ„å»ºçš„æ™ºèƒ½ä»£ç†åœ¨ä¼—å¤šé¢†åŸŸå¾—åˆ°å¹¿æ³›åº”ç”¨ï¼Œå®ç°äº†å¤æ‚çš„å†³ç­–å’Œä»»åŠ¡è‡ªåŠ¨åŒ–ã€‚ç„¶è€Œï¼Œå…¶è‡ªä¸»æ€§å¸¦æ¥äº†å®‰å…¨é£é™©ï¼ŒåŒ…æ‹¬å®‰å…¨æ¼æ´ã€æ³•å¾‹è¿è§„å’Œæ„å¤–æœ‰å®³è¡Œä¸ºã€‚ç°æœ‰çš„ç¼“è§£æ–¹æ³•å¦‚æ¨¡å‹åŸºç¡€ä¿éšœå’Œæ—©æœŸæ‰§è¡Œç­–ç•¥åœ¨ç¨³å¥æ€§ã€å¯è§£é‡Šæ€§å’Œé€‚åº”æ€§æ–¹é¢å­˜åœ¨ä¸è¶³ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬æå‡ºAgentSpecï¼Œä¸€ç§ç”¨äºæŒ‡å®šå’Œæ‰§è¡ŒLLMæ™ºèƒ½ä»£ç†è¿è¡Œæ—¶çº¦æŸçš„è½»é‡çº§é¢†åŸŸç‰¹å®šè¯­è¨€ã€‚é€šè¿‡AgentSpecï¼Œç”¨æˆ·å¯å®šä¹‰åŒ…å«è§¦å‘å™¨ã€è°“è¯å’Œæ‰§è¡Œæœºåˆ¶çš„ç»“æ„åŒ–è§„åˆ™ï¼Œç¡®ä¿æ™ºèƒ½ä»£ç†åœ¨é¢„è®¾çš„å®‰å…¨è¾¹ç•Œå†…è¿è¡Œã€‚AgentSpecåœ¨å¤šé¢†åŸŸå±•ç¤ºå…¶é€‚åº”æ€§å’Œæœ‰æ•ˆæ€§ï¼ŒåŒ…æ‹¬ä»£ç æ‰§è¡Œã€å®ä½“ä»£ç†å’Œè‡ªåŠ¨é©¾é©¶ã€‚è¯„ä¼°ç»“æœæ˜¾ç¤ºï¼ŒAgentSpecæˆåŠŸé˜»æ­¢è¶…è¿‡90%çš„ä»£ç ä»£ç†ä¸å®‰å…¨æ‰§è¡Œï¼Œæ¶ˆé™¤æ‰€æœ‰å®ä½“ä»£ç†ä»»åŠ¡ä¸­çš„å±é™©è¡Œä¸ºï¼Œå¹¶å¼ºåˆ¶è‡ªåŠ¨é©¾é©¶è½¦è¾†100%åˆè§„ã€‚å°½ç®¡å…·æœ‰å¼ºå¤§çš„å®‰å…¨ä¿è¯ï¼ŒAgentSpecçš„è®¡ç®—ä»ç„¶éå¸¸è½»é‡çº§ï¼Œå¼€é”€ä»…ä¸ºæ¯«ç§’çº§ã€‚é€šè¿‡ç»“åˆå¯è§£é‡Šæ€§ã€æ¨¡å—åŒ–å’Œæ•ˆç‡ï¼ŒAgentSpecä¸ºåœ¨å¤šç§åº”ç”¨ç¨‹åºä¸­å®æ–½LLMæ™ºèƒ½ä»£ç†å®‰å…¨æä¾›äº†å®ç”¨ä¸”å¯æ‰©å±•çš„è§£å†³æ–¹æ¡ˆã€‚æˆ‘ä»¬è¿˜ä½¿ç”¨LLMsè‡ªåŠ¨ç”Ÿæˆè§„åˆ™å¹¶è¯„ä¼°å…¶æœ‰æ•ˆæ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>LLMsæ„å»ºçš„ä»£ç†åœ¨å†³ç­–è‡ªåŠ¨åŒ–ä¸­è¡¨ç°çªå‡ºï¼Œä½†åœ¨å®‰å…¨å’Œé£é™©æ–¹é¢å­˜åœ¨é—®é¢˜ã€‚</li>
<li>å­˜åœ¨ä¸€äº›ä¼ ç»Ÿæ–¹æ³•ç”¨äºç¼“è§£è¿™äº›é—®é¢˜ï¼Œä½†å®ƒä»¬åœ¨æŸäº›æ–¹é¢å­˜åœ¨å±€é™æ€§ã€‚</li>
<li>AgentSpecæ˜¯ä¸€ç§é’ˆå¯¹LLMä»£ç†çš„æ–°å‹å®‰å…¨æ¡†æ¶ï¼Œç”¨äºå®šä¹‰å’Œæ‰§è¡Œè¿è¡Œæ—¶çº¦æŸã€‚</li>
<li>AgentSpecå…·å¤‡ç»“æ„åŒ–è§„åˆ™ã€è§¦å‘å™¨å’Œæ‰§è¡Œæœºåˆ¶ç­‰ç‰¹æ€§ï¼Œç¡®ä¿ä»£ç†åœ¨å®‰å…¨èŒƒå›´å†…è¿è¡Œã€‚</li>
<li>AgentSpecåœ¨å¤šé¢†åŸŸåº”ç”¨æœ‰æ•ˆï¼ŒåŒ…æ‹¬ä»£ç æ‰§è¡Œã€å®ä½“ä»£ç†å’Œè‡ªåŠ¨é©¾é©¶ã€‚</li>
<li>AgentSpecåœ¨å®‰å…¨æ€§ä¸Šå…·æœ‰æ˜¾è‘—æ•ˆæœï¼ŒåŒæ—¶ä¿æŒè®¡ç®—è½»é‡çº§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.18666">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-2f286db9099132e8b2263e599500cafd.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-aaf6443797eeb211e335424747ad1679.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-1b4faac94b3b8137811eb809614f21ed.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-9dedae3110aa3afbd347dd30ef016739.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-dd8b08971f27fa6b808b8b62e6a424da.jpg" align="middle">
</details>


<h1 id="-9"><a href="#-9" class="headerlink" title=""></a></h1><h2 id="Boosting-Virtual-Agent-Learning-and-Reasoning-A-Step-wise-Multi-dimensional-and-Generalist-Reward-Model-with-Benchmark"><a href="#Boosting-Virtual-Agent-Learning-and-Reasoning-A-Step-wise-Multi-dimensional-and-Generalist-Reward-Model-with-Benchmark" class="headerlink" title="Boosting Virtual Agent Learning and Reasoning: A Step-wise,   Multi-dimensional, and Generalist Reward Model with Benchmark"></a>Boosting Virtual Agent Learning and Reasoning: A Step-wise,   Multi-dimensional, and Generalist Reward Model with Benchmark</h2><p><strong>Authors:Bingchen Miao, Yang Wu, Minghe Gao, Qifan Yu, Wendong Bu, Wenqiao Zhang, Yunfei Li, Siliang Tang, Tat-Seng Chua, Juncheng Li</strong></p>
<p>The development of Generalist Virtual Agents (GVAs) powered by Multimodal Large Language Models (MLLMs) has shown significant promise in autonomous task execution. However, current training paradigms face critical limitations, including reliance on outcome supervision and labor-intensive human annotations. To address these challenges, we propose Similar, a Step-wise Multi-dimensional Generalist Reward Model, which offers fine-grained signals for agent training and can choose better action for inference-time scaling. Specifically, we begin by systematically defining five dimensions for evaluating agent actions. Building on this framework, we design an MCTS-P algorithm to automatically collect and annotate step-wise, five-dimensional agent execution data. Using this data, we train Similar with the Triple-M strategy. Furthermore, we introduce the first benchmark in the virtual agent domain for step-wise, multi-dimensional reward model training and evaluation, named SRM. This benchmark consists of two components: SRMTrain, which serves as the training set for Similar, and SRMEval, a manually selected test set for evaluating the reward model. Experimental results demonstrate that Similar, through its step-wise, multi-dimensional assessment and synergistic gain, provides GVAs with effective intermediate signals during both training and inference-time scaling. The code is available at <a target="_blank" rel="noopener" href="https://github.com/Galery23/Similar-v1">https://github.com/Galery23/Similar-v1</a>. </p>
<blockquote>
<p>é€šç”¨è™šæ‹Ÿæ™ºèƒ½ä½“ï¼ˆGVAsï¼‰çš„å‘å±•å¾—ç›Šäºå¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰çš„æ¨åŠ¨ï¼Œåœ¨è‡ªä¸»ä»»åŠ¡æ‰§è¡Œæ–¹é¢æ˜¾ç¤ºå‡ºå·¨å¤§æ½œåŠ›ã€‚ç„¶è€Œï¼Œå½“å‰è®­ç»ƒæ¨¡å¼é¢ä¸´å…³é”®å±€é™ï¼ŒåŒ…æ‹¬ä¾èµ–ç»“æœç›‘ç£å’ŒåŠ³åŠ¨å¯†é›†å‹äººå·¥æ ‡æ³¨ã€‚ä¸ºäº†åº”å¯¹è¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†åä¸ºâ€œSimilarâ€çš„é€æ­¥å¤šç»´é€šç”¨å¥–åŠ±æ¨¡å‹ï¼Œè¯¥æ¨¡å‹ä¸ºæ™ºèƒ½ä½“è®­ç»ƒæä¾›ç²¾ç»†ä¿¡å·ï¼Œå¹¶èƒ½å¤Ÿé€‰æ‹©æ›´å¥½çš„æ¨ç†æ—¶é—´å°ºåº¦ä¸‹çš„è¡ŒåŠ¨ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬é¦–å…ˆç³»ç»Ÿåœ°å®šä¹‰äº†äº”ä¸ªç»´åº¦æ¥è¯„ä¼°æ™ºèƒ½ä½“çš„è¡ŒåŠ¨ã€‚åœ¨è¿™ä¸ªæ¡†æ¶çš„åŸºç¡€ä¸Šï¼Œæˆ‘ä»¬è®¾è®¡äº†ä¸€ç§MCTS-Pç®—æ³•ï¼Œè¯¥ç®—æ³•èƒ½å¤Ÿè‡ªåŠ¨æ”¶é›†å’Œæ ‡æ³¨é€æ­¥çš„ã€äº”ç»´æ™ºèƒ½ä½“æ‰§è¡Œæ•°æ®ã€‚æˆ‘ä»¬ä½¿ç”¨è¿™äº›æ•°æ®å¹¶ç”¨Triple-Mç­–ç•¥è®­ç»ƒSimilaræ¨¡å‹ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å¼•å…¥äº†è™šæ‹Ÿæ™ºèƒ½ä½“é¢†åŸŸé¦–ä¸ªç”¨äºé€æ­¥å¤šç»´å¥–åŠ±æ¨¡å‹è®­ç»ƒå’Œè¯„ä¼°çš„åŸºå‡†æµ‹è¯•ï¼Œåä¸ºSRMã€‚è¯¥åŸºå‡†æµ‹è¯•åŒ…å«ä¸¤ä¸ªç»„æˆéƒ¨åˆ†ï¼šç”¨äºè®­ç»ƒSimilarçš„SRMTrainè®­ç»ƒé›†å’Œç”¨äºè¯„ä¼°å¥–åŠ±æ¨¡å‹çš„SRMEvalæ‰‹åŠ¨é€‰æ‹©æµ‹è¯•é›†ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒSimilaré€šè¿‡é€æ­¥å¤šç»´è¯„ä¼°å’ŒååŒå¢ç›Šï¼Œä¸ºGVAsåœ¨è®­ç»ƒå’Œæ¨ç†æ—¶é—´å°ºåº¦ä¸‹æä¾›äº†æœ‰æ•ˆçš„ä¸­é—´ä¿¡å·ã€‚ä»£ç å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/Galery23/Similar-v1%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/Galery23/Similar-v1æ‰¾åˆ°ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.18665v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†é€šç”¨è™šæ‹Ÿä»£ç†äººï¼ˆGVAsï¼‰çš„å‘å±•ä»¥åŠé¢ä¸´çš„æŒ‘æˆ˜ï¼ŒåŒ…æ‹¬å½“å‰è®­ç»ƒæ¨¡å¼çš„å±€é™æ€§ã€‚ä¸ºè§£å†³è¿™äº›é—®é¢˜ï¼Œç ”ç©¶è€…æå‡ºäº†ä¸€ç§åä¸ºâ€œSimilarâ€çš„æ­¥é•¿å¤šç»´é€šç”¨å¥–åŠ±æ¨¡å‹ï¼Œä¸ºä»£ç†è®­ç»ƒæä¾›ç²¾ç»†ä¿¡å·ï¼Œå¹¶åœ¨æ¨ç†æ—¶é€‰æ‹©æ›´å¥½çš„åŠ¨ä½œã€‚åŒæ—¶ï¼Œç ”ç©¶è€…æ„å»ºäº†åä¸ºSRMçš„åŸºå‡†æµ‹è¯•ï¼Œç”¨äºè¯„ä»·æ­¥é•¿å¤šç»´å¥–åŠ±æ¨¡å‹çš„è®­ç»ƒå’Œè¯„ä¼°ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥å¥–åŠ±æ¨¡å‹ä¸ºGVAsåœ¨è®­ç»ƒå’Œæ¨ç†è¿‡ç¨‹ä¸­æä¾›äº†æœ‰æ•ˆçš„ä¸­é—´ä¿¡å·ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>Generalist Virtual Agents (GVAs) é¢ä¸´è®­ç»ƒéš¾é¢˜ï¼Œéœ€è¦æ›´ç²¾ç»†çš„å¥–åŠ±æ¨¡å‹ã€‚</li>
<li>å½“å‰è®­ç»ƒæ¨¡å¼ä¾èµ–äºç»“æœç›‘ç£å’ŒåŠ³åŠ¨å¯†é›†å‹äººå·¥æ ‡æ³¨ï¼Œå­˜åœ¨å±€é™æ€§ã€‚</li>
<li>ç ”ç©¶è€…æå‡ºäº†åä¸ºâ€œSimilarâ€çš„æ­¥é•¿å¤šç»´é€šç”¨å¥–åŠ±æ¨¡å‹ï¼Œç”¨äºè§£å†³è¿™äº›é—®é¢˜ã€‚</li>
<li>Similaræ¨¡å‹é€šè¿‡äº”ä¸ªç»´åº¦è¯„ä¼°ä»£ç†è¡Œä¸ºï¼Œä¸ºä»£ç†è®­ç»ƒæä¾›ç²¾ç»†ä¿¡å·å¹¶åœ¨æ¨ç†æ—¶é€‰æ‹©æœ€ä½³è¡ŒåŠ¨ã€‚</li>
<li>ç ”ç©¶è€…è®¾è®¡äº†åŸºäºMonte Carloæ ‘æœç´¢ï¼ˆMCTSï¼‰ç®—æ³•çš„MCTS-Pç®—æ³•æ¥è‡ªåŠ¨æ”¶é›†å’Œæ ‡æ³¨ä»£ç†æ‰§è¡Œæ•°æ®ã€‚</li>
<li>å¼•å…¥åä¸ºSRMçš„åŸºå‡†æµ‹è¯•ï¼Œç”¨äºè¯„ä¼°æ­¥é•¿å¤šç»´å¥–åŠ±æ¨¡å‹çš„è®­ç»ƒå’Œè¯„ä¼°ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.18665">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-a931af52e2894d497c517a1a841f3cb3.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-9f739315c21c403e2ca7d1a01e417fe7.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-ce07ac3e319f12b147d3084fdf28bcb8.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-4ab38ff767563a24153349f862b6f2f9.jpg" align="middle">
</details>


<h1 id="-10"><a href="#-10" class="headerlink" title=""></a></h1><h2 id="Unified-Uncertainty-Aware-Diffusion-for-Multi-Agent-Trajectory-Modeling"><a href="#Unified-Uncertainty-Aware-Diffusion-for-Multi-Agent-Trajectory-Modeling" class="headerlink" title="Unified Uncertainty-Aware Diffusion for Multi-Agent Trajectory Modeling"></a>Unified Uncertainty-Aware Diffusion for Multi-Agent Trajectory Modeling</h2><p><strong>Authors:Guillem Capellera, Antonio Rubio, Luis Ferraz, Antonio Agudo</strong></p>
<p>Multi-agent trajectory modeling has primarily focused on forecasting future states, often overlooking broader tasks like trajectory completion, which are crucial for real-world applications such as correcting tracking data. Existing methods also generally predict agentsâ€™ states without offering any state-wise measure of uncertainty. Moreover, popular multi-modal sampling methods lack any error probability estimates for each generated scene under the same prior observations, making it difficult to rank the predictions during inference time. We introduce U2Diff, a \textbf{unified} diffusion model designed to handle trajectory completion while providing state-wise \textbf{uncertainty} estimates jointly. This uncertainty estimation is achieved by augmenting the simple denoising loss with the negative log-likelihood of the predicted noise and propagating latent space uncertainty to the real state space. Additionally, we incorporate a Rank Neural Network in post-processing to enable \textbf{error probability} estimation for each generated mode, demonstrating a strong correlation with the error relative to ground truth. Our method outperforms the state-of-the-art solutions in trajectory completion and forecasting across four challenging sports datasets (NBA, Basketball-U, Football-U, Soccer-U), highlighting the effectiveness of uncertainty and error probability estimation. Video at <a target="_blank" rel="noopener" href="https://youtu.be/ngw4D4eJToE">https://youtu.be/ngw4D4eJToE</a> </p>
<blockquote>
<p>å¤šæ™ºèƒ½ä½“è½¨è¿¹å»ºæ¨¡ä¸»è¦å…³æ³¨æœªæ¥çŠ¶æ€çš„é¢„æµ‹ï¼Œå¾€å¾€å¿½è§†äº†å¦‚è½¨è¿¹å®Œæˆç­‰æ›´é‡è¦çš„ä»»åŠ¡ï¼Œè¿™å¯¹äºç°å®ä¸–ç•Œçš„åº”ç”¨ï¼ˆå¦‚ä¿®æ­£è·Ÿè¸ªæ•°æ®ï¼‰è‡³å…³é‡è¦ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸é¢„æµ‹æ™ºèƒ½ä½“çš„çŠ¶æ€ï¼Œè€Œæ²¡æœ‰æä¾›ä»»ä½•çŠ¶æ€çº§çš„ä¸ç¡®å®šæ€§åº¦é‡ã€‚æ­¤å¤–ï¼Œæµè¡Œå¾—å¤šæ¨¡æ€é‡‡æ ·æ–¹æ³•ç¼ºä¹å¯¹åŒä¸€å…ˆéªŒè§‚æµ‹ä¸‹ç”Ÿæˆåœºæ™¯çš„è¯¯å·®æ¦‚ç‡ä¼°è®¡ï¼Œä½¿å¾—åœ¨æ¨ç†æ—¶é—´å¯¹é¢„æµ‹è¿›è¡Œæ’åå˜å¾—å›°éš¾ã€‚æˆ‘ä»¬å¼•å…¥äº†U2Diffï¼Œè¿™æ˜¯ä¸€ä¸ªç»Ÿä¸€æ‰©æ•£æ¨¡å‹ï¼Œæ—¨åœ¨å¤„ç†è½¨è¿¹å®Œæˆçš„åŒæ—¶æä¾›çŠ¶æ€çº§çš„ä¸ç¡®å®šæ€§ä¼°è®¡ã€‚è¿™ç§ä¸ç¡®å®šæ€§ä¼°è®¡æ˜¯é€šè¿‡å¢å¼ºç®€å•çš„å»å™ªæŸå¤±ä¸é¢„æµ‹å™ªå£°çš„è´Ÿå¯¹æ•°ä¼¼ç„¶ï¼Œå¹¶å°†æ½œåœ¨ç©ºé—´çš„ä¸ç¡®å®šæ€§ä¼ æ’­åˆ°çœŸå®çŠ¶æ€ç©ºé—´æ¥å®ç°çš„ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬åœ¨åå¤„ç†ä¸­åŠ å…¥äº†æ’åç¥ç»ç½‘ç»œï¼Œä»¥å®ç°å¯¹æ¯ä¸ªç”Ÿæˆæ¨¡å¼çš„è¯¯å·®æ¦‚ç‡ä¼°è®¡ï¼Œè¿™æ˜¾ç¤ºå‡ºä¸çœŸå®è¯¯å·®çš„å¼ºçƒˆç›¸å…³æ€§ã€‚æˆ‘ä»¬çš„æ–¹æ³•åœ¨å››ä¸ªå…·æœ‰æŒ‘æˆ˜æ€§çš„ä½“è‚²æ•°æ®é›†ï¼ˆNBAã€ç¯®çƒUã€è¶³çƒUã€è¶³çƒèµ›Uï¼‰ä¸Šçš„è½¨è¿¹å®Œæˆå’Œé¢„æµ‹æ–¹é¢ä¼˜äºç°æœ‰æŠ€æœ¯è§£å†³æ–¹æ¡ˆï¼Œçªå‡ºäº†ä¸ç¡®å®šæ€§å’Œè¯¯å·®æ¦‚ç‡ä¼°è®¡çš„æœ‰æ•ˆæ€§ã€‚è§†é¢‘é“¾æ¥ï¼š<a target="_blank" rel="noopener" href="https://youtu.be/ngw4D4eJToE">è§†é¢‘é“¾æ¥</a>ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.18589v1">PDF</a> Accepted to CVPR 2025 conference</p>
<p><strong>Summary</strong></p>
<p>å¤šä»£ç†è½¨è¿¹å»ºæ¨¡ä¸»è¦å…³æ³¨æœªæ¥çŠ¶æ€çš„é¢„æµ‹ï¼Œå¿½ç•¥äº†è½¨è¿¹å®Œæˆç­‰æ›´é‡è¦çš„ç°å®åº”ç”¨ä»»åŠ¡ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸åªé¢„æµ‹ä»£ç†çŠ¶æ€ï¼Œä¸æä¾›çŠ¶æ€çº§çš„ä¸ç¡®å®šæ€§åº¦é‡ã€‚æˆ‘ä»¬æå‡ºU2Diffæ¨¡å‹ï¼Œèƒ½å¤Ÿå¤„ç†è½¨è¿¹å®Œæˆå¹¶æä¾›çŠ¶æ€çº§çš„ä¸ç¡®å®šæ€§ä¼°è®¡ã€‚é€šè¿‡å¢åŠ å™ªå£°å»å™ªæŸå¤±å’Œé¢„æµ‹å™ªå£°çš„è´Ÿå¯¹æ•°å¯èƒ½æ€§ï¼Œå¹¶å°†æ½œåœ¨ç©ºé—´çš„ä¸ç¡®å®šæ€§ä¼ æ’­åˆ°çœŸå®çŠ¶æ€ç©ºé—´æ¥å®ç°ä¸ç¡®å®šæ€§ä¼°è®¡ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬åœ¨åå¤„ç†ä¸­å¼•å…¥äº†æ’åç¥ç»ç½‘ç»œï¼Œèƒ½å¤Ÿå¯¹æ¯ç§ç”Ÿæˆæ¨¡å¼è¿›è¡Œè¯¯å·®æ¦‚ç‡ä¼°è®¡ï¼Œä¸çœŸå®è¯¯å·®é«˜åº¦ç›¸å…³ã€‚æˆ‘ä»¬çš„æ–¹æ³•åœ¨å››ä¸ªå…·æœ‰æŒ‘æˆ˜æ€§çš„ä½“è‚²æ•°æ®é›†ä¸Šçš„è½¨è¿¹å®Œæˆå’Œé¢„æµ‹æ€§èƒ½å‡ä¼˜äºç°æœ‰æœ€ä½³è§£å†³æ–¹æ¡ˆï¼Œå‡¸æ˜¾äº†ä¸ç¡®å®šæ€§å’Œè¯¯å·®æ¦‚ç‡ä¼°è®¡çš„æœ‰æ•ˆæ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤šä»£ç†è½¨è¿¹å»ºæ¨¡ä¸ä»…å…³æ³¨æœªæ¥çŠ¶æ€é¢„æµ‹ï¼Œè¿˜éœ€é‡è§†è½¨è¿¹å®Œæˆç­‰ç°å®ä»»åŠ¡ã€‚</li>
<li>ç°æœ‰æ–¹æ³•é¢„æµ‹ä»£ç†çŠ¶æ€æ—¶ï¼Œç¼ºä¹çŠ¶æ€çº§çš„ä¸ç¡®å®šæ€§åº¦é‡ã€‚</li>
<li>U2Diffæ¨¡å‹èƒ½å¤Ÿå¤„ç†è½¨è¿¹å®Œæˆï¼ŒåŒæ—¶æä¾›çŠ¶æ€çº§çš„ä¸ç¡®å®šæ€§ä¼°è®¡ã€‚</li>
<li>U2Diffé€šè¿‡å¢åŠ å™ªå£°å»å™ªæŸå¤±å’Œé¢„æµ‹å™ªå£°çš„è´Ÿå¯¹æ•°å¯èƒ½æ€§æ¥å®ç°ä¸ç¡®å®šæ€§ä¼°è®¡ã€‚</li>
<li>æ½œåœ¨ç©ºé—´çš„ä¸ç¡®å®šæ€§è¢«ä¼ æ’­åˆ°çœŸå®çŠ¶æ€ç©ºé—´ã€‚</li>
<li>åå¤„ç†ä¸­å¼•å…¥æ’åç¥ç»ç½‘ç»œï¼Œå®ç°æ¯ç§ç”Ÿæˆæ¨¡å¼çš„è¯¯å·®æ¦‚ç‡ä¼°è®¡ï¼Œä¸çœŸå®è¯¯å·®é«˜åº¦ç›¸å…³ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.18589">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-d6318620bfd818ca5b973d1cace4de7d.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-a25805fac10022ec9aab03de3c190393.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-eb2d3837ceb875cc8b1fa18ed3ab8601.jpg" align="middle">
</details>


<h1 id="-11"><a href="#-11" class="headerlink" title=""></a></h1><h2 id="Multi-agent-coordination-for-data-gathering-with-periodic-requests-and-deliveries"><a href="#Multi-agent-coordination-for-data-gathering-with-periodic-requests-and-deliveries" class="headerlink" title="Multi-agent coordination for data gathering with periodic requests and   deliveries"></a>Multi-agent coordination for data gathering with periodic requests and   deliveries</h2><p><strong>Authors:Yaroslav Marchukov, Luis Montano</strong></p>
<p>In this demo work we develop a method to plan and coordinate a multi-agent team to gather information on demand. The data is periodically requested by a static Operation Center (OC) from changeable goals locations. The mission of the team is to reach these locations, taking measurements and delivering the data to the OC. Due to the limited communication range as well as signal attenuation because of the obstacles, the agents must travel to the OC, to upload the data. The agents can play two roles: ones as workers gathering data, the others as collectors traveling invariant paths for collecting the data of the workers to re-transmit it to the OC. The refreshing time of the delivered information depends on the number of available agents as well as of the scenario. The proposed algorithm finds out the best balance between the number of collectors-workers and the partition of the scenario into working areas in the planning phase, which provides the minimum refreshing time and will be the one executed by the agents. </p>
<blockquote>
<p>åœ¨è¿™ä¸ªæ¼”ç¤ºå·¥ä½œä¸­ï¼Œæˆ‘ä»¬å¼€å‘äº†ä¸€ç§æ–¹æ³•æ¥è§„åˆ’å’Œåè°ƒå¤šæ™ºèƒ½ä½“å›¢é˜Ÿï¼Œä»¥æŒ‰éœ€æ”¶é›†ä¿¡æ¯ã€‚é™æ€è¿è¥ä¸­å¿ƒï¼ˆOCï¼‰ä¼šå®šæœŸä»å¯å˜ç›®æ ‡ä½ç½®è¯·æ±‚æ•°æ®ã€‚å›¢é˜Ÿçš„ä»»åŠ¡æ˜¯åˆ°è¾¾è¿™äº›ä½ç½®ï¼Œè¿›è¡Œæµ‹é‡å¹¶å°†æ•°æ®äº¤ä»˜ç»™OCã€‚ç”±äºé€šä¿¡èŒƒå›´çš„é™åˆ¶ä»¥åŠéšœç¢å¯¼è‡´çš„ä¿¡å·è¡°å‡ï¼Œæ™ºèƒ½ä½“å¿…é¡»å‰å¾€OCä¸Šä¼ æ•°æ®ã€‚æ™ºèƒ½ä½“å¯ä»¥æ‰®æ¼”ä¸¤ç§è§’è‰²ï¼šä¸€äº›ä½œä¸ºæ”¶é›†æ•°æ®çš„å·¥äººï¼Œå¦ä¸€äº›ä½œä¸ºæ”¶é›†å·¥äººæ•°æ®çš„æ”¶é›†è€…ï¼Œæ²¿å›ºå®šè·¯å¾„æ—…è¡Œï¼Œå°†æ•°æ®é‡æ–°ä¼ è¾“åˆ°OCã€‚æ‰€äº¤ä»˜ä¿¡æ¯çš„åˆ·æ–°æ—¶é—´å–å†³äºå¯ç”¨æ™ºèƒ½ä½“çš„æ•°é‡ä»¥åŠåœºæ™¯çš„æƒ…å†µã€‚æ‰€æå‡ºçš„ç®—æ³•åœ¨è§„åˆ’é˜¶æ®µæ‰¾åˆ°äº†æœ€ä½³å¹³è¡¡ï¼Œå³ç¡®å®šæ”¶é›†è€…-å·¥ä½œè€…çš„æ•°é‡å’Œå°†åœºæ™¯åˆ’åˆ†ä¸ºå·¥ä½œåŒºåŸŸçš„æ–¹å¼ï¼Œä»¥æä¾›æœ€å°çš„åˆ·æ–°æ—¶é—´ï¼Œå¹¶å°†ç”±æ™ºèƒ½ä½“æ‰§è¡Œã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.18546v1">PDF</a> </p>
<p><strong>æ€»ç»“</strong><br>ï¼šåœ¨æ¼”ç¤ºå·¥ä½œä¸­ï¼Œæˆ‘ä»¬å¼€å‘äº†ä¸€ç§æ–¹æ³•ï¼Œç”¨äºè§„åˆ’å’Œåè°ƒå¤šæ™ºèƒ½ä½“å›¢é˜ŸæŒ‰éœ€æ”¶é›†ä¿¡æ¯ã€‚æ•°æ®ç”±é™æ€è¿è¥ä¸­å¿ƒå®šæœŸä»å¯å˜ç›®æ ‡ä½ç½®è¯·æ±‚ã€‚å›¢é˜Ÿçš„ä½¿å‘½æ˜¯åˆ°è¾¾è¿™äº›ä½ç½®è¿›è¡Œæµ‹é‡å¹¶å°†æ•°æ®äº¤ä»˜ç»™è¿è¥ä¸­å¿ƒã€‚ç”±äºé€šä¿¡èŒƒå›´çš„é™åˆ¶ä»¥åŠç”±äºéšœç¢é€ æˆçš„ä¿¡å·è¡°å‡ï¼Œæ™ºèƒ½ä½“å¿…é¡»å‰å¾€è¿è¥ä¸­å¿ƒä¸Šä¼ æ•°æ®ã€‚æ™ºèƒ½ä½“å¯ä»¥æ‰®æ¼”ä¸¤ä¸ªè§’è‰²ï¼šä¸€éƒ¨åˆ†ä½œä¸ºæ”¶é›†æ•°æ®çš„å·¥äººï¼Œå¦ä¸€éƒ¨åˆ†ä½œä¸ºæ²¿å›ºå®šè·¯å¾„æ—…è¡Œçš„æ”¶é›†è€…ï¼Œä»¥æ”¶é›†å·¥äººçš„æ•°æ®å¹¶å°†å…¶é‡æ–°ä¼ è¾“åˆ°è¿è¥ä¸­å¿ƒã€‚äº¤ä»˜ä¿¡æ¯çš„åˆ·æ–°æ—¶é—´å–å†³äºå¯ç”¨æ™ºèƒ½ä½“çš„æ•°é‡ä»¥åŠåœºæ™¯çš„æƒ…å†µã€‚æ‰€æå‡ºçš„ç®—æ³•åœ¨è§„åˆ’é˜¶æ®µæ‰¾åˆ°äº†æœ€ä½³å¹³è¡¡ï¼Œå³æ”¶é›†è€…å·¥ä½œè€…æ•°é‡å’Œåœºæ™¯å·¥ä½œåŒºåŸŸçš„åˆ’åˆ†ï¼Œæä¾›æœ€çŸ­åˆ·æ–°æ—¶é—´å¹¶ä¼šè¢«æ™ºèƒ½ä½“æ‰§è¡Œã€‚</p>
<p><strong>è¦ç‚¹</strong></p>
<ol>
<li>å¼€å‘äº†ä¸€ç§å¤šæ™ºèƒ½ä½“å›¢é˜Ÿè§„åˆ’å’Œåè°ƒæ–¹æ³•ï¼Œç”¨äºæŒ‰éœ€æ”¶é›†ä¿¡æ¯ã€‚</li>
<li>æ•°æ®ç”±é™æ€è¿è¥ä¸­å¿ƒå®šæœŸä»å¯å˜ç›®æ ‡ä½ç½®è¯·æ±‚ã€‚</li>
<li>æ™ºèƒ½ä½“çš„ä½¿å‘½æ˜¯åˆ°è¾¾ç›®æ ‡ä½ç½®è¿›è¡Œæµ‹é‡å¹¶å°†æ•°æ®ä¼ é€åˆ°è¿è¥ä¸­å¿ƒã€‚</li>
<li>ç”±äºé€šä¿¡èŒƒå›´é™åˆ¶å’Œä¿¡å·è¡°å‡ï¼Œæ™ºèƒ½ä½“éœ€äº²è‡ªä¸Šä¼ æ•°æ®ã€‚</li>
<li>æ™ºèƒ½ä½“æœ‰ä¸¤ç§è§’è‰²ï¼šä½œä¸ºæ”¶é›†æ•°æ®çš„å·¥äººå’Œæ”¶é›†å·¥äººæ•°æ®çš„æ”¶é›†è€…ã€‚</li>
<li>äº¤ä»˜ä¿¡æ¯çš„åˆ·æ–°æ—¶é—´å—æ™ºèƒ½ä½“æ•°é‡å’Œåœºæ™¯æƒ…å†µçš„å½±å“ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.18546">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-0ffc57fb01f3c022ac89aaca585e5858.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-b4585e31d1a53e2cdd46b1139d7375f7.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-5f8af8f9c703030f8bce79d2c1d843c6.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-6e73cd6420e5b57e4814ac1e0fa09603.jpg" align="middle">
</details>


<h1 id="-12"><a href="#-12" class="headerlink" title=""></a></h1><h2 id="STEVE-A-Step-Verification-Pipeline-for-Computer-use-Agent-Training"><a href="#STEVE-A-Step-Verification-Pipeline-for-Computer-use-Agent-Training" class="headerlink" title="STEVE: A Step Verification Pipeline for Computer-use Agent Training"></a>STEVE: A Step Verification Pipeline for Computer-use Agent Training</h2><p><strong>Authors:Fanbin Lu, Zhisheng Zhong, Ziqin Wei, Shu Liu, Chi-Wing Fu, Jiaya Jia</strong></p>
<p>Developing AI agents to autonomously manipulate graphical user interfaces is a long challenging task. Recent advances in data scaling law inspire us to train computer-use agents with a scaled instruction set, yet using behavior cloning to train agents still requires immense high-quality trajectories. To meet the scalability need, we designed STEVE, a step verification pipeline for computer-use agent training. First, we establish a large instruction set for computer-use agents and collect trajectory data with some suboptimal agents. GPT-4o is used to verify the correctness of each step in the trajectories based on the screens before and after the action execution, assigning each step with a binary label. Last, we adopt the Kahneman and Tversky Optimization to optimize the agent from the binary stepwise labels. Extensive experiments manifest that our agent outperforms supervised finetuning by leveraging both positive and negative actions within a trajectory. Also, STEVE enables us to train a 7B vision-language model as a computer-use agent, achieving leading performance in the challenging live desktop environment WinAgentArena with great efficiency at a reduced cost. Code and data: <a target="_blank" rel="noopener" href="https://github.com/FanbinLu/STEVE">https://github.com/FanbinLu/STEVE</a>. </p>
<blockquote>
<p>å¼€å‘èƒ½å¤Ÿè‡ªä¸»æ“ä½œå›¾å½¢ç”¨æˆ·ç•Œé¢çš„AIä»£ç†æ˜¯ä¸€é¡¹é•¿æœŸä¸”å……æ»¡æŒ‘æˆ˜çš„ä»»åŠ¡ã€‚æœ€è¿‘æ•°æ®è§„æ¨¡å®šå¾‹çš„è¿›æ­¥å¯å‘æˆ‘ä»¬ï¼Œä½¿ç”¨è§„æ¨¡åŒ–æŒ‡ä»¤é›†æ¥è®­ç»ƒè®¡ç®—æœºä½¿ç”¨ä»£ç†ï¼Œç„¶è€Œï¼Œä½¿ç”¨è¡Œä¸ºå…‹éš†æ¥è®­ç»ƒä»£ç†ä»éœ€è¦å·¨å¤§çš„é«˜è´¨é‡è½¨è¿¹ã€‚ä¸ºäº†æ»¡è¶³å¯æ‰©å±•æ€§çš„éœ€æ±‚ï¼Œæˆ‘ä»¬è®¾è®¡äº†STEVEï¼Œè¿™æ˜¯ä¸€ä¸ªç”¨äºè®¡ç®—æœºä½¿ç”¨ä»£ç†è®­ç»ƒçš„æ­¥éª¤éªŒè¯æµç¨‹ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬ä¸ºè®¡ç®—æœºä½¿ç”¨ä»£ç†å»ºç«‹äº†ä¸€å¥—å¤§å‹æŒ‡ä»¤é›†ï¼Œå¹¶ä½¿ç”¨ä¸€äº›æ¬¡ä¼˜ä»£ç†æ”¶é›†è½¨è¿¹æ•°æ®ã€‚GPT-4oæ ¹æ®æ‰§è¡ŒåŠ¨ä½œå‰åçš„å±å¹•æ¥éªŒè¯è½¨è¿¹ä¸­æ¯ä¸€æ­¥çš„æ­£ç¡®æ€§ï¼Œå¹¶ä¸ºæ¯ä¸€æ­¥åˆ†é…ä¸€ä¸ªäºŒè¿›åˆ¶æ ‡ç­¾ã€‚æœ€åï¼Œæˆ‘ä»¬é‡‡ç”¨å¡å†…æ›¼å’Œç‰¹ç»´å°”æ–¯åŸºä¼˜åŒ–æ³•ï¼Œæ ¹æ®äºŒè¿›åˆ¶çš„æ­¥éª¤æ ‡ç­¾æ¥ä¼˜åŒ–ä»£ç†ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„ä»£ç†é€šè¿‡åˆ©ç”¨è½¨è¿¹å†…çš„ç§¯æå’Œæ¶ˆæåŠ¨ä½œï¼Œåœ¨ç›‘ç£å¾®è°ƒæ–¹é¢çš„è¡¨ç°æ›´åŠ å‡ºè‰²ã€‚æ­¤å¤–ï¼ŒSTEVEè¿˜ä½¿æˆ‘ä»¬èƒ½å¤Ÿè®­ç»ƒä¸€ä¸ª70äº¿çš„è§†è§‰è¯­è¨€æ¨¡å‹ä½œä¸ºè®¡ç®—æœºä½¿ç”¨ä»£ç†ï¼Œåœ¨å…·æœ‰æŒ‘æˆ˜æ€§çš„å®æ—¶æ¡Œé¢ç¯å¢ƒWinAgentArenaä¸­å®ç°äº†å“è¶Šçš„æ€§èƒ½ï¼ŒåŒæ—¶æé«˜äº†æ•ˆç‡å’Œé™ä½äº†æˆæœ¬ã€‚[ä»£ç å’Œæ•°æ®ï¼š<a target="_blank" rel="noopener" href="https://github.com/FanbinLu/STEVE]">https://github.com/FanbinLu/STEVE]</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.12532v2">PDF</a> </p>
<p><strong>Summary</strong><br>     è¿‘æœŸå¼€å‘èƒ½è‡ªä¸»æ“ä½œå›¾å½¢ç”¨æˆ·ç•Œé¢çš„AIä»£ç†é¢ä¸´æŒ‘æˆ˜ã€‚ç ”ç©¶å›¢é˜Ÿä¸ºåº”å¯¹æ­¤æŒ‘æˆ˜æå‡ºSTEVEè®­ç»ƒæµç¨‹ï¼Œåˆ©ç”¨å¤§è§„æ¨¡æŒ‡ä»¤é›†æ”¶é›†è½¨è¿¹æ•°æ®ï¼Œä½¿ç”¨GPT-4oåŸºäºè¡ŒåŠ¨æ‰§è¡Œå‰åå±å¹•éªŒè¯è½¨è¿¹æ¯ä¸€æ­¥çš„æ­£ç¡®æ€§å¹¶èµ‹äºˆæ ‡ç­¾ã€‚ç»“åˆå¡å†…æ›¼å’Œç‰¹ç»´å°”æ–¯åŸºä¼˜åŒ–æ³•è®­ç»ƒä»£ç†ï¼Œèƒ½åˆ©ç”¨è½¨è¿¹ä¸­çš„ç§¯æä¸æ¶ˆæè¡ŒåŠ¨ã€‚å®éªŒè¯æ˜ï¼Œè¯¥ä»£ç†åœ¨WinAgentArenaç¯å¢ƒä¸­è¡¨ç°å‡ºå“è¶Šæ€§èƒ½ä¸é«˜æ•ˆç‡ä½æˆæœ¬ä¼˜åŠ¿ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¼€å‘èƒ½è‡ªä¸»æ“ä½œå›¾å½¢ç”¨æˆ·ç•Œé¢çš„AIä»£ç†æ˜¯ä¸€é¡¹å…·æœ‰æŒ‘æˆ˜æ€§çš„ä»»åŠ¡ã€‚</li>
<li>ç ”ç©¶å›¢é˜Ÿè®¾è®¡äº†STEVEè®­ç»ƒæµç¨‹ä»¥åº”å¯¹è¿™ä¸€æŒ‘æˆ˜ã€‚</li>
<li>STEVEæµç¨‹åŒ…æ‹¬å»ºç«‹å¤§è§„æ¨¡æŒ‡ä»¤é›†ã€æ”¶é›†è½¨è¿¹æ•°æ®å’Œä½¿ç”¨GPT-4oéªŒè¯è½¨è¿¹æ­£ç¡®æ€§ã€‚</li>
<li>åˆ©ç”¨å¡å†…æ›¼å’Œç‰¹ç»´å°”æ–¯åŸºä¼˜åŒ–æ³•è®­ç»ƒä»£ç†ï¼Œèƒ½åˆ©ç”¨è½¨è¿¹ä¸­çš„ç§¯æä¸æ¶ˆæè¡ŒåŠ¨ã€‚</li>
<li>è¯¥ä»£ç†åœ¨WinAgentArenaç¯å¢ƒä¸­è¡¨ç°å‡ºå“è¶Šæ€§èƒ½ã€‚</li>
<li>STEVEè®­ç»ƒæµç¨‹æé«˜äº†æ•ˆç‡å¹¶é™ä½äº†æˆæœ¬ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.12532">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-31a918e7b022fdc993b8cb65ced5ae67.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b22ba356b4d26102231611a52f168494.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-b074ac374bcc2acc1cc2cce2ff6130e3.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-333d9bcf2eacc550853eaeb957cff10d.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-6bfa2e5bfc0df5cbf733e6885de25237.jpg" align="middle">
</details>


<h1 id="-13"><a href="#-13" class="headerlink" title=""></a></h1><h2 id="QualityFlow-An-Agentic-Workflow-for-Program-Synthesis-Controlled-by-LLM-Quality-Checks"><a href="#QualityFlow-An-Agentic-Workflow-for-Program-Synthesis-Controlled-by-LLM-Quality-Checks" class="headerlink" title="QualityFlow: An Agentic Workflow for Program Synthesis Controlled by LLM   Quality Checks"></a>QualityFlow: An Agentic Workflow for Program Synthesis Controlled by LLM   Quality Checks</h2><p><strong>Authors:Yaojie Hu, Qiang Zhou, Qihong Chen, Xiaopeng Li, Linbo Liu, Dejiao Zhang, Amit Kachroo, Talha Oz, Omer Tripp</strong></p>
<p>We introduce QualityFlow, a dynamic agentic workflow for program synthesis. Given the English description of a programming problem and a set of unit tests, the modelâ€™s goal is to synthesize the correct program that solves the problem and passes the tests. QualityFlow includes large language model (LLM) agents resembling a software development team, including code generation, testing, and self-debugging. We propose the LLM Quality Checker, which explicitly â€œimaginesâ€ whether the synthesized programsâ€™ execution would conform to the unit tests. The Quality Checks dynamically control the workflow, including actions to submit the final answer, clarify the problem statement, and revert previous workflow steps. Our experiments show that the Quality Checker can precisely accept any correct program, mitigate faulty synthesized tests, and prevent potential workflow deviation. QualityFlow establishes the state-of-the-art results on four program synthesis benchmarks: MBPP, HumanEval, and stricter evaluations from MBPP-EvalPlus and HumanEval-EvalPlus. </p>
<blockquote>
<p>æˆ‘ä»¬ä»‹ç»äº†QualityFlowï¼Œè¿™æ˜¯ä¸€ä¸ªç”¨äºç¨‹åºåˆæˆçš„åŠ¨æ€æ™ºèƒ½å·¥ä½œæµç¨‹ã€‚ç»™å®šç¼–ç¨‹é—®é¢˜çš„è‹±æ–‡æè¿°å’Œä¸€ç»„å•å…ƒæµ‹è¯•ï¼Œè¯¥æ¨¡å‹çš„ç›®æ ‡æ˜¯è¦åˆæˆèƒ½å¤Ÿè§£å†³é—®é¢˜å¹¶é€šè¿‡æµ‹è¯•çš„æ­£ç¡®ç¨‹åºã€‚QualityFlowåŒ…æ‹¬ç±»ä¼¼è½¯ä»¶å¼€å‘å›¢é˜Ÿçš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ™ºèƒ½ä½“ï¼ŒåŒ…æ‹¬ä»£ç ç”Ÿæˆã€æµ‹è¯•å’Œè‡ªåŠ¨è°ƒè¯•ã€‚æˆ‘ä»¬æå‡ºäº†LLMè´¨é‡æ£€æµ‹å™¨ï¼Œå®ƒæ˜ç¡®åœ°â€œæƒ³è±¡â€åˆæˆç¨‹åºçš„æ‰§è¡Œæ˜¯å¦ç¬¦åˆå•å…ƒæµ‹è¯•ã€‚è´¨é‡æ£€æµ‹å™¨åŠ¨æ€æ§åˆ¶å·¥ä½œæµç¨‹ï¼ŒåŒ…æ‹¬æäº¤æœ€ç»ˆç­”æ¡ˆã€æ¾„æ¸…é—®é¢˜é™ˆè¿°å’Œæ’¤é”€å…ˆå‰çš„å·¥ä½œæµç¨‹æ­¥éª¤ç­‰æ“ä½œã€‚æˆ‘ä»¬çš„å®éªŒè¡¨æ˜ï¼Œè´¨é‡æ£€æµ‹å™¨å¯ä»¥ç²¾ç¡®åœ°æ¥å—ä»»ä½•æ­£ç¡®çš„ç¨‹åºï¼Œå‡è½»é”™è¯¯çš„åˆæˆæµ‹è¯•ï¼Œå¹¶é˜²æ­¢æ½œåœ¨çš„å·¥ä½œæµç¨‹åå·®ã€‚QualityFlowåœ¨å››é¡¹ç¨‹åºåˆæˆåŸºå‡†æµ‹è¯•ä¸­å»ºç«‹äº†æœ€æ–°çš„æˆæœï¼šMBPPã€HumanEvalä»¥åŠæ›´ä¸¥æ ¼çš„MBPP-EvalPluså’ŒHumanEval-EvalPlusè¯„ä¼°ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.17167v2">PDF</a> </p>
<p><strong>Summary</strong>ï¼š<br>æˆ‘ä»¬æå‡ºäº†QualityFlowï¼Œè¿™æ˜¯ä¸€ç§åŠ¨æ€çš„æ™ºèƒ½å·¥ä½œæµç¨‹ï¼Œç”¨äºç¨‹åºåˆæˆã€‚ç»™å®šç¼–ç¨‹é—®é¢˜çš„è‹±æ–‡æè¿°å’Œä¸€ç»„å•å…ƒæµ‹è¯•ï¼Œè¯¥æ¨¡å‹çš„ç›®æ ‡æ˜¯åˆæˆæ­£ç¡®çš„ç¨‹åºæ¥è§£å†³é—®é¢˜å¹¶é€šè¿‡æµ‹è¯•ã€‚QualityFlowåŒ…æ‹¬å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„æ™ºèƒ½ä½“ï¼Œç±»ä¼¼äºè½¯ä»¶å¼€å‘å›¢é˜Ÿï¼ŒåŒ…æ‹¬ä»£ç ç”Ÿæˆã€æµ‹è¯•å’Œè‡ªåŠ¨è°ƒè¯•ã€‚æˆ‘ä»¬æå‡ºäº†LLMè´¨é‡æ£€æŸ¥å™¨ï¼Œå®ƒå¯ä»¥æ˜ç¡®åœ°â€œæƒ³è±¡â€åˆæˆç¨‹åºçš„æ‰§è¡Œæ˜¯å¦ç¬¦åˆå•å…ƒæµ‹è¯•ã€‚è´¨é‡æ£€æŸ¥å¯ä»¥åŠ¨æ€æ§åˆ¶å·¥ä½œæµç¨‹ï¼ŒåŒ…æ‹¬æäº¤æœ€ç»ˆç­”æ¡ˆã€æ¾„æ¸…é—®é¢˜é™ˆè¿°å’Œæ’¤é”€å…ˆå‰çš„å·¥ä½œæµç¨‹æ­¥éª¤ã€‚å®éªŒè¡¨æ˜ï¼Œè´¨é‡æ£€æŸ¥å™¨å¯ä»¥ç²¾ç¡®æ¥å—ä»»ä½•æ­£ç¡®çš„ç¨‹åºï¼Œç¼“è§£åˆæˆæµ‹è¯•ä¸­çš„é”™è¯¯å¹¶é˜²æ­¢æ½œåœ¨çš„å·¥ä½œæµç¨‹åå·®ã€‚QualityFlowåœ¨å››ä¸ªç¨‹åºåˆæˆåŸºå‡†æµ‹è¯•ä¸Šå»ºç«‹äº†æœ€æ–°ç»“æœï¼šMBPPã€HumanEvalä»¥åŠæ›´ä¸¥æ ¼çš„MBPP-EvalPluså’ŒHumanEval-EvalPlusè¯„ä»·ã€‚</p>
<p><strong>Key Takeaways</strong>ï¼š</p>
<ol>
<li>QualityFlowæ˜¯ä¸€ä¸ªåŠ¨æ€çš„æ™ºèƒ½å·¥ä½œæµç¨‹ï¼Œæ—¨åœ¨åˆæˆè§£å†³ç¼–ç¨‹é—®é¢˜çš„æ­£ç¡®ç¨‹åºï¼Œå¹¶é€šè¿‡å•å…ƒæµ‹è¯•éªŒè¯ã€‚</li>
<li>LLMæ™ºèƒ½ä½“åœ¨QualityFlowä¸­æ‰®æ¼”é‡è¦è§’è‰²ï¼ŒåŒ…æ‹¬ä»£ç ç”Ÿæˆã€æµ‹è¯•å’Œè‡ªåŠ¨è°ƒè¯•ç­‰ã€‚</li>
<li>LLMè´¨é‡æ£€æŸ¥å™¨èƒ½å¤Ÿæ˜ç¡®åˆ¤æ–­åˆæˆç¨‹åºçš„æ‰§è¡Œæ˜¯å¦ç¬¦åˆå•å…ƒæµ‹è¯•è¦æ±‚ã€‚</li>
<li>è´¨é‡æ£€æŸ¥å¯åŠ¨æ€æ§åˆ¶å·¥ä½œæµç¨‹ï¼ŒåŒ…æ‹¬æäº¤ç­”æ¡ˆã€æ¾„æ¸…é—®é¢˜é™ˆè¿°å’Œæ’¤é”€æ­¥éª¤ç­‰åŠŸèƒ½ã€‚</li>
<li>è´¨é‡æ£€æŸ¥å™¨å…·æœ‰ç²¾ç¡®æ¥å—æ­£ç¡®ç¨‹åºçš„èƒ½åŠ›ï¼Œå¹¶å¯ä»¥æœ‰æ•ˆç¼“è§£æµ‹è¯•ä¸­çš„é”™è¯¯å’Œé˜²æ­¢å·¥ä½œæµç¨‹åå·®ã€‚</li>
<li>QualityFlowåœ¨å¤šä¸ªç¨‹åºåˆæˆåŸºå‡†æµ‹è¯•ä¸Šå–å¾—äº†æœ€æ–°æˆæœï¼Œå±•ç°äº†å…¶æœ‰æ•ˆæ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.17167">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-feb33599a82afff511cd8e05a8ddabb4.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-b058bd74756b9d480df6af5e4a890f9c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-099909c78dc7e4a7207ef2680865cc5d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-efc973604a0fca85aeb7a6f4a653c65e.jpg" align="middle">
</details>


<h1 id="-14"><a href="#-14" class="headerlink" title=""></a></h1><h2 id="RL-RC-DoT-A-Block-level-RL-agent-for-Task-Aware-Video-Compression"><a href="#RL-RC-DoT-A-Block-level-RL-agent-for-Task-Aware-Video-Compression" class="headerlink" title="RL-RC-DoT: A Block-level RL agent for Task-Aware Video Compression"></a>RL-RC-DoT: A Block-level RL agent for Task-Aware Video Compression</h2><p><strong>Authors:Uri Gadot, Assaf Shocher, Shie Mannor, Gal Chechik, Assaf Hallak</strong></p>
<p>Video encoders optimize compression for human perception by minimizing reconstruction error under bit-rate constraints. In many modern applications such as autonomous driving, an overwhelming majority of videos serve as input for AI systems performing tasks like object recognition or segmentation, rather than being watched by humans. It is therefore useful to optimize the encoder for a downstream task instead of for perceptual image quality. However, a major challenge is how to combine such downstream optimization with existing standard video encoders, which are highly efficient and popular. Here, we address this challenge by controlling the Quantization Parameters (QPs) at the macro-block level to optimize the downstream task. This granular control allows us to prioritize encoding for task-relevant regions within each frame. We formulate this optimization problem as a Reinforcement Learning (RL) task, where the agent learns to balance long-term implications of choosing QPs on both task performance and bit-rate constraints. Notably, our policy does not require the downstream task as an input during inference, making it suitable for streaming applications and edge devices such as vehicles. We demonstrate significant improvements in two tasks, car detection, and ROI (saliency) encoding. Our approach improves task performance for a given bit rate compared to traditional task agnostic encoding methods, paving the way for more efficient task-aware video compression. </p>
<blockquote>
<p>è§†é¢‘ç¼–ç å™¨é€šè¿‡æœ€å°åŒ–æ¯”ç‰¹ç‡çº¦æŸä¸‹çš„é‡å»ºè¯¯å·®ï¼Œé’ˆå¯¹äººç±»æ„ŸçŸ¥è¿›è¡Œä¼˜åŒ–å‹ç¼©ã€‚åœ¨è®¸å¤šç°ä»£åº”ç”¨ï¼ˆå¦‚è‡ªåŠ¨é©¾é©¶ï¼‰ä¸­ï¼Œç»å¤§å¤šæ•°è§†é¢‘æ˜¯ä½œä¸ºæ‰§è¡Œå¯¹è±¡è¯†åˆ«æˆ–åˆ†å‰²ç­‰ä»»åŠ¡çš„AIç³»ç»Ÿçš„è¾“å…¥ï¼Œè€Œä¸æ˜¯ç”±äººç±»è§‚çœ‹ã€‚å› æ­¤ï¼Œä¼˜åŒ–ç¼–ç å™¨ä»¥é€‚åº”ä¸‹æ¸¸ä»»åŠ¡è€Œéæ„ŸçŸ¥å›¾åƒè´¨é‡æ˜¯æœ‰ç”¨çš„ã€‚ç„¶è€Œï¼Œä¸€ä¸ªä¸»è¦æŒ‘æˆ˜æ˜¯å¦‚ä½•å°†è¿™ç§ä¸‹æ¸¸ä¼˜åŒ–ä¸ç°æœ‰çš„æ ‡å‡†è§†é¢‘ç¼–ç å™¨ç›¸ç»“åˆï¼Œåè€…æ•ˆç‡é«˜ä¸”å—æ¬¢è¿ã€‚åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬é€šè¿‡æ§åˆ¶å®å—çº§çš„é‡åŒ–å‚æ•°ï¼ˆQPï¼‰æ¥è§£å†³è¿™ä¸€æŒ‘æˆ˜ï¼Œä»¥ä¼˜åŒ–ä¸‹æ¸¸ä»»åŠ¡ã€‚è¿™ç§ç²¾ç»†æ§åˆ¶å…è®¸æˆ‘ä»¬ä¼˜å…ˆå¯¹æ¯ä¸€å¸§ä¸­çš„ä»»åŠ¡ç›¸å…³åŒºåŸŸè¿›è¡Œç¼–ç ã€‚æˆ‘ä»¬å°†è¿™ä¸ªä¼˜åŒ–é—®é¢˜è¡¨è¿°ä¸ºå¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰ä»»åŠ¡ï¼Œå…¶ä¸­ä»£ç†å­¦ä¹ åœ¨é€‰æ‹©é‡åŒ–å‚æ•°æ—¶å¹³è¡¡å…¶å¯¹ä»»åŠ¡æ€§èƒ½å’Œæ¯”ç‰¹ç‡çº¦æŸçš„é•¿æœŸå½±å“ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œæˆ‘ä»¬çš„ç­–ç•¥åœ¨æ¨ç†è¿‡ç¨‹ä¸­ä¸éœ€è¦ä¸‹æ¸¸ä»»åŠ¡ä½œä¸ºè¾“å…¥ï¼Œä½¿å…¶é€‚ç”¨äºæµåª’ä½“åº”ç”¨å’Œè¾¹ç¼˜è®¾å¤‡ï¼ˆå¦‚è½¦è¾†ï¼‰ã€‚æˆ‘ä»¬åœ¨æ±½è½¦æ£€æµ‹å’ŒROIï¼ˆæ˜¾è‘—æ€§ï¼‰ç¼–ç ä¸¤ä¸ªä»»åŠ¡ä¸­å±•ç¤ºäº†æ˜¾è‘—æ”¹è¿›ã€‚ä¸ä¼ ç»Ÿçš„ä»»åŠ¡æ— å…³ç¼–ç æ–¹æ³•ç›¸æ¯”ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨ç»™å®šæ¯”ç‰¹ç‡ä¸‹æé«˜äº†ä»»åŠ¡æ€§èƒ½ï¼Œä¸ºæ›´é«˜æ•ˆçš„ä»»åŠ¡æ„ŸçŸ¥è§†é¢‘å‹ç¼©é“ºå¹³äº†é“è·¯ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.12216v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æ¢è®¨äº†è§†é¢‘ç¼–ç å™¨åœ¨è‡ªåŠ¨é©¾é©¶ç­‰ç°ä»£åº”ç”¨ä¸­çš„ä¼˜åŒ–é—®é¢˜ã€‚é’ˆå¯¹AIç³»ç»Ÿæ‰§è¡Œç›®æ ‡è¯†åˆ«æˆ–åˆ†å‰²ç­‰ä»»åŠ¡è€Œéäººç±»è§‚çœ‹çš„æƒ…å†µï¼Œæå‡ºä¼˜åŒ–ç¼–ç å™¨ä»¥é€‚åˆä¸‹æ¸¸ä»»åŠ¡è€Œéæ„ŸçŸ¥å›¾åƒè´¨é‡çš„æ–¹æ³•ã€‚é€šè¿‡æ§åˆ¶å®å—çº§åˆ«çš„é‡åŒ–å‚æ•°ï¼ˆQPsï¼‰æ¥è§£å†³ä¸‹æ¸¸ä¼˜åŒ–ä¸ç°æœ‰æ ‡å‡†è§†é¢‘ç¼–ç å™¨çš„ç»“åˆé—®é¢˜ã€‚åˆ©ç”¨å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰æ¥å¹³è¡¡ä»»åŠ¡æ€§èƒ½ä¸æ¯”ç‰¹ç‡çº¦æŸä¹‹é—´çš„é•¿æœŸå½±å“ï¼Œå¹¶åœ¨ä»»åŠ¡ç›¸å…³åŒºåŸŸè¿›è¡Œä¼˜å…ˆçº§ç¼–ç ã€‚è¯¥æ–¹æ³•åœ¨è½¦è¾†æ£€æµ‹ä¸ROIï¼ˆæ˜¾è‘—æ€§ï¼‰ç¼–ç ä»»åŠ¡ä¸­è¡¨ç°å‡ºæ˜¾è‘—æ”¹è¿›ï¼Œä¸ºä»»åŠ¡æ„ŸçŸ¥è§†é¢‘å‹ç¼©æä¾›äº†æ›´é«˜æ•ˆçš„é€”å¾„ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>è§†é¢‘ç¼–ç å™¨ä¼˜åŒ–å‹ç¼©ä»¥é€‚åˆäººç±»æ„ŸçŸ¥ï¼Œä½†åœ¨ç°ä»£åº”ç”¨å¦‚è‡ªåŠ¨é©¾é©¶ä¸­ï¼Œè§†é¢‘ä¸»è¦ç”¨äºAIç³»ç»Ÿæ‰§è¡Œä»»åŠ¡ã€‚</li>
<li>ä¼˜åŒ–ç¼–ç å™¨ä»¥é€‚åº”ä¸‹æ¸¸ä»»åŠ¡è€Œéä»…å…³æ³¨æ„ŸçŸ¥å›¾åƒè´¨é‡ã€‚</li>
<li>é€šè¿‡æ§åˆ¶å®å—çº§åˆ«çš„é‡åŒ–å‚æ•°ï¼ˆQPsï¼‰æ¥è§£å†³ä¸‹æ¸¸ä¼˜åŒ–ä¸æ ‡å‡†è§†é¢‘ç¼–ç å™¨çš„ç»“åˆé—®é¢˜ã€‚</li>
<li>åˆ©ç”¨å¼ºåŒ–å­¦ä¹ å¹³è¡¡ä»»åŠ¡æ€§èƒ½ä¸æ¯”ç‰¹ç‡çº¦æŸä¹‹é—´çš„é•¿æœŸå½±å“ã€‚</li>
<li>ç¼–ç å™¨ç­–ç•¥é€‚åˆæµå¼ä¼ è¾“åº”ç”¨å’Œè¾¹ç¼˜è®¾å¤‡ï¼Œå¦‚è½¦è¾†ã€‚</li>
<li>æ–¹æ³•åœ¨è½¦è¾†æ£€æµ‹å’ŒROIç¼–ç ä»»åŠ¡ä¸­è¡¨ç°å‡ºæ˜¾è‘—æ”¹è¿›ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.12216">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-46a0127e3f5da69aaa00c7e4cd6e92ad.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-257901de0f26303d50a9f5308b1e7bdd.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a0fc2ec956f3daeb5f9cd9ad13cedefc.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-1ed4358b9bda0c389ca796f7cf2f7ada.jpg" align="middle">
</details>


<h1 id="-15"><a href="#-15" class="headerlink" title=""></a></h1><h2 id="UAVs-Meet-LLMs-Overviews-and-Perspectives-Toward-Agentic-Low-Altitude-Mobility"><a href="#UAVs-Meet-LLMs-Overviews-and-Perspectives-Toward-Agentic-Low-Altitude-Mobility" class="headerlink" title="UAVs Meet LLMs: Overviews and Perspectives Toward Agentic Low-Altitude   Mobility"></a>UAVs Meet LLMs: Overviews and Perspectives Toward Agentic Low-Altitude   Mobility</h2><p><strong>Authors:Yonglin Tian, Fei Lin, Yiduo Li, Tengchao Zhang, Qiyao Zhang, Xuan Fu, Jun Huang, Xingyuan Dai, Yutong Wang, Chunwei Tian, Bai Li, Yisheng Lv, Levente KovÃ¡cs, Fei-Yue Wang</strong></p>
<p>Low-altitude mobility, exemplified by unmanned aerial vehicles (UAVs), has introduced transformative advancements across various domains, like transportation, logistics, and agriculture. Leveraging flexible perspectives and rapid maneuverability, UAVs extend traditional systemsâ€™ perception and action capabilities, garnering widespread attention from academia and industry. However, current UAV operations primarily depend on human control, with only limited autonomy in simple scenarios, and lack the intelligence and adaptability needed for more complex environments and tasks. The emergence of large language models (LLMs) demonstrates remarkable problem-solving and generalization capabilities, offering a promising pathway for advancing UAV intelligence. This paper explores the integration of LLMs and UAVs, beginning with an overview of UAV systemsâ€™ fundamental components and functionalities, followed by an overview of the state-of-the-art in LLM technology. Subsequently, it systematically highlights the multimodal data resources available for UAVs, which provide critical support for training and evaluation. Furthermore, it categorizes and analyzes key tasks and application scenarios where UAVs and LLMs converge. Finally, a reference roadmap towards agentic UAVs is proposed, aiming to enable UAVs to achieve agentic intelligence through autonomous perception, memory, reasoning, and tool utilization. Related resources are available at <a target="_blank" rel="noopener" href="https://github.com/Hub-Tian/UAVs_Meet_LLMs">https://github.com/Hub-Tian/UAVs_Meet_LLMs</a>. </p>
<blockquote>
<p>ä½ç©ºæœºåŠ¨æ€§ä»¥æ— äººæœºï¼ˆUAVsï¼‰ä¸ºä»£è¡¨ï¼Œä¸ºäº¤é€šã€ç‰©æµã€å†œä¸šç­‰å„ä¸ªé¢†åŸŸå¸¦æ¥äº†é©å‘½æ€§çš„è¿›æ­¥ã€‚æ— äººæœºå‡­å€Ÿå…¶çµæ´»çš„è§†è§’å’Œå¿«é€ŸæœºåŠ¨èƒ½åŠ›ï¼Œæ‰©å±•äº†ä¼ ç»Ÿç³»ç»Ÿçš„æ„ŸçŸ¥å’Œè¡ŒåŠ¨èƒ½åŠ›ï¼Œå¼•èµ·äº†å­¦æœ¯ç•Œå’Œå·¥ä¸šç•Œçš„å¹¿æ³›å…³æ³¨ã€‚ç„¶è€Œï¼Œå½“å‰æ— äººæœºçš„æ“ä½œä¸»è¦ä¾èµ–äºäººä¸ºæ§åˆ¶ï¼Œä»…åœ¨ç®€å•åœºæ™¯ä¸‹æœ‰æœ‰é™çš„è‡ªä¸»æ€§ï¼Œç¼ºä¹åœ¨å¤æ‚ç¯å¢ƒå’Œä»»åŠ¡æ‰€éœ€çš„æ™ºèƒ½å’Œé€‚åº”æ€§ã€‚å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„å‡ºç°è¡¨ç°å‡ºäº†æ˜¾è‘—çš„é—®é¢˜è§£å†³å’Œæ³›åŒ–èƒ½åŠ›ï¼Œä¸ºæå‡æ— äººæœºæ™ºèƒ½æä¾›äº†å¯Œæœ‰å¸Œæœ›çš„é“è·¯ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.02341v2">PDF</a> </p>
<p><strong>Summary</strong><br>æ— äººæœºä½œä¸ºä½ç©ºç§»åŠ¨æ€§çš„ä»£è¡¨ï¼Œå·²ç»åœ¨äº¤é€šã€ç‰©æµã€å†œä¸šç­‰é¢†åŸŸå¸¦æ¥äº†é©å‘½æ€§çš„è¿›å±•ã€‚ç„¶è€Œï¼Œå½“å‰çš„æ— äººæœºæ“ä½œä¸»è¦ä¾èµ–äººä¸ºæ§åˆ¶ï¼Œç¼ºä¹åœ¨å¤æ‚ç¯å¢ƒå’Œä»»åŠ¡ä¸­çš„æ™ºèƒ½é€‚åº”æ€§ã€‚å¤§å‹è¯­è¨€æ¨¡å‹çš„å‡ºç°æä¾›äº†æ¨è¿›æ— äººæœºæ™ºèƒ½çš„æ½œåœ¨è·¯å¾„ã€‚æœ¬æ–‡æ¢è®¨äº†å°†å¤§å‹è¯­è¨€æ¨¡å‹ä¸æ— äººæœºç»“åˆçš„å¯èƒ½æ€§ï¼ŒåŒ…æ‹¬æ¦‚è¿°æ— äººæœºç³»ç»Ÿçš„åŸºæœ¬ç»„ä»¶å’ŒåŠŸèƒ½ã€ä»‹ç»æœ€æ–°çš„å¤§å‹è¯­è¨€æŠ€æœ¯ï¼Œå¹¶å¼ºè°ƒä¸ºæ— äººæœºè®­ç»ƒè¯„ä¼°æä¾›å…³é”®æ”¯æŒçš„å¤šæ¨¡å¼æ•°æ®èµ„æºã€‚æ­¤å¤–ï¼Œè¿˜ä»‹ç»äº†æ— äººæœºå’Œå¤§å‹è¯­è¨€æ¨¡å‹èåˆçš„å…³é”®ä»»åŠ¡å’Œåº”ç”¨åœºæ™¯ã€‚æœ€åï¼Œæå‡ºäº†å®ç°è‡ªä¸»æ„ŸçŸ¥ã€è®°å¿†ã€æ¨ç†å’Œå·¥å…·åˆ©ç”¨çš„æ™ºèƒ½æ— äººæœºçš„å‚è€ƒè·¯çº¿å›¾ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æ— äººæœºå·²å¹¿æ³›åº”ç”¨äºäº¤é€šã€ç‰©æµã€å†œä¸šç­‰é¢†åŸŸï¼Œå¹¶å±•ç°å‡ºå˜é©æ€§è¿›å±•ã€‚</li>
<li>å½“å‰æ— äººæœºæ“ä½œä¸»è¦ä¾èµ–äººä¸ºæ§åˆ¶ï¼Œç¼ºä¹åœ¨å¤æ‚ç¯å¢ƒå’Œä»»åŠ¡ä¸­çš„æ™ºèƒ½é€‚åº”æ€§ã€‚</li>
<li>å¤§å‹è¯­è¨€æ¨¡å‹çš„å‡ºç°ä¸ºæ¨è¿›æ— äººæœºæ™ºèƒ½æä¾›äº†æ½œåœ¨è·¯å¾„ã€‚</li>
<li>æ— äººæœºä¸å¤§å‹è¯­è¨€æ¨¡å‹çš„ç»“åˆå¯å¢å¼ºæ— äººæœºçš„æ™ºèƒ½å¤„ç†èƒ½åŠ›ï¼Œé€‚åº”å¤æ‚ç¯å¢ƒå’Œä»»åŠ¡ã€‚</li>
<li>å¤šæ¨¡å¼æ•°æ®èµ„æºå¯¹æ— äººæœºçš„è®­ç»ƒè¯„ä¼°è‡³å…³é‡è¦ã€‚</li>
<li>æ— äººæœºå’Œå¤§å‹è¯­è¨€æ¨¡å‹èåˆçš„å…³é”®ä»»åŠ¡åŒ…æ‹¬æ™ºèƒ½å¯¼èˆªã€ç¯å¢ƒæ„ŸçŸ¥ã€è‡ªä¸»å†³ç­–ç­‰ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.02341">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-012188a63cd95ef8f6ea9f87c56beffc.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-24e6e621dc50fd2ae7aafd2a3d85592c.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-f634789696ddeee7cf936e3bbe6b3790.jpg" align="middle">
</details>


<h1 id="-16"><a href="#-16" class="headerlink" title=""></a></h1><h2 id="Large-Language-Models-Empowered-Personalized-Web-Agents"><a href="#Large-Language-Models-Empowered-Personalized-Web-Agents" class="headerlink" title="Large Language Models Empowered Personalized Web Agents"></a>Large Language Models Empowered Personalized Web Agents</h2><p><strong>Authors:Hongru Cai, Yongqi Li, Wenjie Wang, Fengbin Zhu, Xiaoyu Shen, Wenjie Li, Tat-Seng Chua</strong></p>
<p>Web agents have emerged as a promising direction to automate Web task completion based on user instructions, significantly enhancing user experience. Recently, Web agents have evolved from traditional agents to Large Language Models (LLMs)-based Web agents. Despite their success, existing LLM-based Web agents overlook the importance of personalized data (e.g., user profiles and historical Web behaviors) in assisting the understanding of usersâ€™ personalized instructions and executing customized actions. To overcome the limitation, we first formulate the task of LLM-empowered personalized Web agents, which integrate personalized data and user instructions to personalize instruction comprehension and action execution. To address the absence of a comprehensive evaluation benchmark, we construct a Personalized Web Agent Benchmark (PersonalWAB), featuring user instructions, personalized user data, Web functions, and two evaluation paradigms across three personalized Web tasks. Moreover, we propose a Personalized User Memory-enhanced Alignment (PUMA) framework to adapt LLMs to the personalized Web agent task. PUMA utilizes a memory bank with a task-specific retrieval strategy to filter relevant historical Web behaviors. Based on the behaviors, PUMA then aligns LLMs for personalized action execution through fine-tuning and direct preference optimization. Extensive experiments validate the superiority of PUMA over existing Web agents on PersonalWAB. </p>
<blockquote>
<p>ç½‘ç»œä»£ç†å·²ç»å´­éœ²å¤´è§’ï¼Œæˆä¸ºæ ¹æ®ç”¨æˆ·æŒ‡ä»¤è‡ªåŠ¨åŒ–å®Œæˆç½‘ç»œä»»åŠ¡çš„ä¸€ä¸ªå‰æ™¯æ–¹å‘ï¼Œæ˜¾è‘—æå‡äº†ç”¨æˆ·ä½“éªŒã€‚æœ€è¿‘ï¼Œç½‘ç»œä»£ç†å·²ç»ç”±ä¼ ç»Ÿä»£ç†å‘å±•åˆ°åŸºäºå¤§è¯­è¨€æ¨¡å‹çš„ç½‘ç»œä»£ç†ã€‚å°½ç®¡å–å¾—äº†æˆåŠŸï¼Œç°æœ‰çš„åŸºäºå¤§è¯­è¨€æ¨¡å‹çš„çš„ç½‘ç»œä»£ç†å¿½è§†äº†ä¸ªæ€§åŒ–æ•°æ®ï¼ˆå¦‚ç”¨æˆ·é…ç½®æ–‡ä»¶å’Œå†å²ç½‘ç»œè¡Œä¸ºï¼‰åœ¨è¾…åŠ©ç†è§£ç”¨æˆ·ä¸ªæ€§åŒ–æŒ‡ä»¤å’Œæ‰§è¡Œå®šåˆ¶æ“ä½œä¸­çš„é‡è¦æ€§ã€‚ä¸ºäº†å…‹æœè¿™ä¸€å±€é™æ€§ï¼Œæˆ‘ä»¬é¦–å…ˆåˆ¶å®šäº†åŸºäºå¤§è¯­è¨€æ¨¡å‹çš„ä¸ªæ€§åŒ–ç½‘ç»œä»£ç†ä»»åŠ¡ï¼Œè¯¥ä»»åŠ¡æ•´åˆä¸ªæ€§åŒ–æ•°æ®å’Œç”¨æˆ·æŒ‡ä»¤ï¼Œä»¥ä¸ªæ€§åŒ–æŒ‡ä»¤ç†è§£è¡ŒåŠ¨æ‰§è¡Œã€‚ä¸ºäº†è§£å†³ç¼ºä¹å…¨é¢è¯„ä¼°åŸºå‡†çš„é—®é¢˜ï¼Œæˆ‘ä»¬å»ºç«‹äº†ä¸ªæ€§åŒ–ç½‘ç»œä»£ç†åŸºå‡†æµ‹è¯•ï¼ˆPersonalWABï¼‰ï¼Œå®ƒåŒ…å«ç”¨æˆ·æŒ‡ä»¤ã€ä¸ªæ€§åŒ–ç”¨æˆ·æ•°æ®ã€ç½‘ç»œåŠŸèƒ½ä»¥åŠä¸‰ä¸ªä¸ªæ€§åŒ–ç½‘ç»œä»»åŠ¡çš„ä¸¤ç§è¯„ä¼°æ¨¡å¼ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸ªæ€§åŒ–ç”¨æˆ·è®°å¿†å¢å¼ºå¯¹é½ï¼ˆPUMAï¼‰æ¡†æ¶ï¼Œä»¥é€‚åº”ä¸ªæ€§åŒ–ç½‘ç»œä»£ç†ä»»åŠ¡ã€‚PUMAåˆ©ç”¨å¸¦æœ‰ä»»åŠ¡ç‰¹å®šæ£€ç´¢ç­–ç•¥çš„è®°å¿†åº“æ¥ç­›é€‰ç›¸å…³çš„å†å²ç½‘ç»œè¡Œä¸ºã€‚åŸºäºè¿™äº›è¡Œä¸ºï¼ŒPUMAé€šè¿‡å¯¹é½å¤§è¯­è¨€æ¨¡å‹è¿›è¡Œå¾®è°ƒä»¥åŠç›´æ¥åå¥½ä¼˜åŒ–æ¥æ‰§è¡Œä¸ªæ€§åŒ–çš„åŠ¨ä½œã€‚å¤§é‡çš„å®éªŒéªŒè¯äº†åœ¨PersonalWABä¸Šï¼ŒPUMAç›¸è¾ƒäºç°æœ‰ç½‘ç»œä»£ç†çš„ä¼˜è¶Šæ€§ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2410.17236v2">PDF</a> Accepted to WWW 2025. The code and data are available on the project   website <a target="_blank" rel="noopener" href="https://hongrucai.github.io/PersonalWAB/">https://hongrucai.github.io/PersonalWAB/</a></p>
<p><strong>Summary</strong></p>
<p>åŸºäºç”¨æˆ·æŒ‡ä»¤è‡ªåŠ¨åŒ–å®ŒæˆWebä»»åŠ¡çš„æ–°å‹Webä»£ç†è¡¨ç°å‡ºå¹¿é˜”å‰æ™¯ï¼Œè¿‘æœŸå·²ä»ä¼ ç»Ÿä»£ç†å‘å±•åˆ°åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹çš„Webä»£ç†ã€‚ç„¶è€Œï¼Œç°æœ‰ä»£ç†åœ¨ç†è§£ä¸ªæ€§åŒ–æŒ‡ä»¤å’Œæ‰§è¡Œå®šåˆ¶åŠ¨ä½œæ—¶å¿½è§†äº†ä¸ªæ€§åŒ–æ•°æ®çš„é‡è¦æ€§ã€‚ä¸ºè§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºèåˆä¸ªæ€§åŒ–æ•°æ®å’Œç”¨æˆ·æŒ‡ä»¤çš„LLMèµ‹èƒ½ä¸ªæ€§åŒ–Webä»£ç†ä»»åŠ¡ï¼Œå¹¶å»ºç«‹åŒ…å«ç”¨æˆ·æŒ‡ä»¤ã€ä¸ªæ€§åŒ–æ•°æ®ã€WebåŠŸèƒ½åŠä¸‰ä¸ªä¸ªæ€§åŒ–Webä»»åŠ¡çš„ä¸¤é¡¹è¯„ä¼°æ ‡å‡†çš„PersonalWABåŸºå‡†æµ‹è¯•ã€‚åŒæ—¶ï¼Œæˆ‘ä»¬æå‡ºäº†èåˆä¸ªæ€§åŒ–ç”¨æˆ·è®°å¿†å¢å¼ºçš„å¯¹é½æ¡†æ¶PUMAï¼Œå®ƒé‡‡ç”¨ä»»åŠ¡ç‰¹å®šæ£€ç´¢ç­–ç•¥çš„è®°å¿†åº“è¿‡æ»¤ç›¸å…³çš„å†å²Webè¡Œä¸ºï¼Œå¹¶å¯¹LLMsè¿›è¡Œå¾®è°ƒåŠåå¥½ä¼˜åŒ–ï¼Œä»¥æ‰§è¡Œä¸ªæ€§åŒ–åŠ¨ä½œã€‚å®éªŒè¯æ˜PUMAåœ¨PersonalWABä¸Šçš„è¡¨ç°ä¼˜äºç°æœ‰Webä»£ç†ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>Webä»£ç†æ­£æœè‡ªåŠ¨åŒ–å®Œæˆä»»åŠ¡çš„æ–¹å‘å‘å±•ï¼Œå·²ä»ä¼ ç»Ÿä»£ç†è¿›åŒ–åˆ°åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹çš„Webä»£ç†ã€‚</li>
<li>ç°æœ‰åŸºäºLLMçš„Webä»£ç†åœ¨ç†è§£å¹¶æ‰§è¡Œä¸ªæ€§åŒ–æŒ‡ä»¤æ–¹é¢å­˜åœ¨å±€é™æ€§ï¼Œå¿½è§†äº†ä¸ªæ€§åŒ–æ•°æ®çš„é‡è¦æ€§ã€‚</li>
<li>æå‡ºLLMèµ‹èƒ½ä¸ªæ€§åŒ–Webä»£ç†ä»»åŠ¡ï¼Œæ•´åˆä¸ªæ€§åŒ–æ•°æ®å’Œç”¨æˆ·æŒ‡ä»¤ã€‚</li>
<li>å»ºç«‹PersonalWABåŸºå‡†æµ‹è¯•ï¼ŒåŒ…å«ç”¨æˆ·æŒ‡ä»¤ã€ä¸ªæ€§åŒ–æ•°æ®ç­‰ï¼Œä¸ºè¯„ä¼°ä¸ªæ€§åŒ–Webä»£ç†æä¾›å…¨é¢è¯„ä»·èŒƒå¼ã€‚</li>
<li>å¼•å…¥PUMAæ¡†æ¶ï¼Œåˆ©ç”¨è®°å¿†åº“å¢å¼ºLLMå¯¹ä¸ªæ€§åŒ–Webä»»åŠ¡çš„å¯¹é½èƒ½åŠ›ï¼Œé€šè¿‡å†å²Webè¡Œä¸ºä¼˜åŒ–åŠ¨ä½œæ‰§è¡Œã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2410.17236">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-d4efe31941ace00929d2029c3ac2e3a6.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c6d14bdb75cb965bf1d7663e7b30fe9d.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-4d6e725ab529f4f0f4b87826f473f3ac.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-632c36db05686ffd142ccb79d5db93c9.jpg" align="middle">
</details>


<h1 id="-17"><a href="#-17" class="headerlink" title=""></a></h1><h2 id="Physics-Informed-Multi-Agent-Reinforcement-Learning-for-Distributed-Multi-Robot-Problems"><a href="#Physics-Informed-Multi-Agent-Reinforcement-Learning-for-Distributed-Multi-Robot-Problems" class="headerlink" title="Physics-Informed Multi-Agent Reinforcement Learning for Distributed   Multi-Robot Problems"></a>Physics-Informed Multi-Agent Reinforcement Learning for Distributed   Multi-Robot Problems</h2><p><strong>Authors:Eduardo Sebastian, Thai Duong, Nikolay Atanasov, Eduardo Montijano, Carlos Sagues</strong></p>
<p>The networked nature of multi-robot systems presents challenges in the context of multi-agent reinforcement learning. Centralized control policies do not scale with increasing numbers of robots, whereas independent control policies do not exploit the information provided by other robots, exhibiting poor performance in cooperative-competitive tasks. In this work we propose a physics-informed reinforcement learning approach able to learn distributed multi-robot control policies that are both scalable and make use of all the available information to each robot. Our approach has three key characteristics. First, it imposes a port-Hamiltonian structure on the policy representation, respecting energy conservation properties of physical robot systems and the networked nature of robot team interactions. Second, it uses self-attention to ensure a sparse policy representation able to handle time-varying information at each robot from the interaction graph. Third, we present a soft actor-critic reinforcement learning algorithm parameterized by our self-attention port-Hamiltonian control policy, which accounts for the correlation among robots during training while overcoming the need of value function factorization. Extensive simulations in different multi-robot scenarios demonstrate the success of the proposed approach, surpassing previous multi-robot reinforcement learning solutions in scalability, while achieving similar or superior performance (with averaged cumulative reward up to x2 greater than the state-of-the-art with robot teams x6 larger than the number of robots at training time). We also validate our approach on multiple real robots in the Georgia Tech Robotarium under imperfect communication, demonstrating zero-shot sim-to-real transfer and scalability across number of robots. </p>
<blockquote>
<p>å¤šæœºå™¨äººç³»ç»Ÿçš„ç½‘ç»œæ€§è´¨ç»™å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ å¸¦æ¥äº†æŒ‘æˆ˜ã€‚éšç€æœºå™¨äººæ•°é‡çš„å¢åŠ ï¼Œé›†ä¸­æ§åˆ¶ç­–ç•¥æ— æ³•æ‰©å±•ï¼Œè€Œç‹¬ç«‹æ§åˆ¶ç­–ç•¥åˆ™æ— æ³•åˆ©ç”¨å…¶ä»–æœºå™¨äººæä¾›çš„ä¿¡æ¯ï¼Œåœ¨åˆä½œç«äº‰ä»»åŠ¡ä¸­è¡¨ç°ä¸ä½³ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åŸºäºç‰©ç†çš„å¼ºåŒ–å­¦ä¹ çš„æ–¹æ³•ï¼Œèƒ½å¤Ÿå­¦ä¹ åˆ†å¸ƒå¼çš„å¤šæœºå™¨äººæ§åˆ¶ç­–ç•¥ï¼Œè¿™äº›ç­–ç•¥æ—¢å¯æ‰©å±•ï¼Œåˆèƒ½åˆ©ç”¨æ¯ä¸ªæœºå™¨äººçš„æ‰€æœ‰å¯ç”¨ä¿¡æ¯ã€‚æˆ‘ä»¬çš„æ–¹æ³•æœ‰ä¸‰ä¸ªå…³é”®ç‰¹ç‚¹ã€‚é¦–å…ˆï¼Œå®ƒå¯¹ç­–ç•¥è¡¨ç¤ºæ–½åŠ ç«¯å£å“ˆå¯†é¡¿ç»“æ„ï¼Œå°Šé‡ç‰©ç†æœºå™¨äººç³»ç»Ÿçš„èƒ½é‡å®ˆæ’å±æ€§å’Œæœºå™¨äººå›¢é˜Ÿäº¤äº’çš„ç½‘ç»œæ€§è´¨ã€‚å…¶æ¬¡ï¼Œå®ƒä½¿ç”¨è‡ªæ³¨æ„åŠ›æ¥ç¡®ä¿ç­–ç•¥è¡¨ç¤ºæ˜¯ç¨€ç–çš„ï¼Œèƒ½å¤Ÿå¤„ç†æ¥è‡ªäº¤äº’å›¾çš„æ¯ä¸ªæœºå™¨äººçš„æ—¶å˜ä¿¡æ¯ã€‚ç¬¬ä¸‰ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§ç”±è‡ªæ³¨æ„åŠ›ç«¯å£å“ˆå¯†é¡¿æ§åˆ¶ç­–ç•¥å‚æ•°åŒ–çš„è½¯Actor-Criticå¼ºåŒ–å­¦ä¹ ç®—æ³•ï¼Œè¯¥ç®—æ³•åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­è€ƒè™‘äº†æœºå™¨äººä¹‹é—´çš„ç›¸å…³æ€§ï¼ŒåŒæ—¶å…‹æœäº†ä»·å€¼å‡½æ•°åˆ†è§£çš„éœ€æ±‚ã€‚åœ¨ä¸åŒå¤šæœºå™¨äººåœºæ™¯ä¸‹çš„å¹¿æ³›æ¨¡æ‹Ÿè¡¨æ˜ï¼Œæ‰€æå‡ºçš„æ–¹æ³•å–å¾—äº†æˆåŠŸï¼Œåœ¨å¯æ‰©å±•æ€§æ–¹é¢è¶…è¶Šäº†ä»¥å‰çš„å¤šæœºå™¨äººå¼ºåŒ–å­¦ä¹ è§£å†³æ–¹æ¡ˆï¼ŒåŒæ—¶åœ¨æ€§èƒ½ä¸Šå–å¾—äº†ç›¸ä¼¼æˆ–æ›´ä¼˜è¶Šçš„è¡¨ç°ï¼ˆå¹³å‡ç´¯ç§¯å¥–åŠ±é«˜è¾¾ç°æœ‰æŠ€æœ¯çš„ä¸¤å€ä»¥ä¸Šï¼Œæœºå™¨äººå›¢é˜Ÿæ•°é‡æ˜¯è®­ç»ƒæ—¶çš„å…­å€ï¼‰ã€‚æˆ‘ä»¬è¿˜é€šè¿‡ä¸å®Œç¾çš„é€šä¿¡åœ¨ä½æ²»äºšç†å·¥å­¦é™¢æœºå™¨äººå®éªŒå®¤çš„å¤šä¸ªçœŸå®æœºå™¨äººä¸ŠéªŒè¯äº†æˆ‘ä»¬çš„æ–¹æ³•ï¼Œè¯æ˜äº†ä»æ¨¡æ‹Ÿåˆ°çœŸå®çš„é›¶å°„å‡»è½¬ç§»ä»¥åŠè·¨æœºå™¨äººæ•°é‡çš„å¯æ‰©å±•æ€§ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2401.00212v3">PDF</a> This paper is under review at IEEE T-RO</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºä¸€ç§ç‰©ç†ä¿¡æ¯å¢å¼ºçš„å¼ºåŒ–å­¦ä¹ æ–¹æ¡ˆï¼Œè¯¥æ–¹æ¡ˆå¯å­¦ä¹ åˆ†å¸ƒå¼çš„å¤šæœºå™¨äººæ§åˆ¶ç­–ç•¥ï¼Œæ—¢å…·å¤‡å¯æ‰©å±•æ€§ï¼Œåˆèƒ½åˆ©ç”¨æ¯ä¸ªæœºå™¨äººçš„æ‰€æœ‰å¯ç”¨ä¿¡æ¯ã€‚è¯¥æ–¹æ¡ˆæœ‰ä¸‰ä¸ªå…³é”®ç‰¹ç‚¹ï¼šä¸€æ˜¯é‡‡ç”¨ç«¯å£å“ˆå¯†é¡¿ç»“æ„ï¼Œå°Šé‡ç‰©ç†æœºå™¨äººç³»ç»Ÿçš„èƒ½é‡å®ˆæ’å±æ€§å’Œæœºå™¨äººå›¢é˜Ÿçš„äº¤äº’ç½‘ç»œæ€§è´¨ï¼›äºŒæ˜¯ä½¿ç”¨è‡ªæ³¨æ„åŠ›æœºåˆ¶ç¡®ä¿ç­–ç•¥è¡¨ç¤ºç¨€ç–ï¼Œèƒ½å¤„ç†æ¥è‡ªäº¤äº’å›¾çš„æ—¶å˜ä¿¡æ¯ï¼›ä¸‰æ˜¯æå‡ºä¸€ç§è½¯åŠ¨ä½œè¯„è®ºå®¶å¼ºåŒ–å­¦ä¹ ç®—æ³•ï¼Œè¯¥ç®—æ³•ä»¥è‡ªæ³¨æ„åŠ›ç«¯å£å“ˆå¯†é¡¿æ§åˆ¶ç­–ç•¥ä¸ºåŸºç¡€ï¼Œè§£å†³æœºå™¨äººé—´çš„ç›¸å…³æ€§é—®é¢˜ï¼Œæé«˜è®­ç»ƒçš„å¯æ‰©å±•æ€§ã€‚ä»¿çœŸå®éªŒæ˜¾ç¤ºè¯¥æ–¹æ¡ˆæˆåŠŸè¶…è¶Šå…ˆå‰çš„å¤šæœºå™¨äººå¼ºåŒ–å­¦ä¹ è§£å†³æ–¹æ¡ˆï¼Œåœ¨å¯æ‰©å±•æ€§æ–¹é¢è¡¨ç°ä¼˜å¼‚ï¼Œä¸”æ€§èƒ½ä¸æœ€æ–°æŠ€æœ¯ç›¸å½“æˆ–æ›´ä¼˜ã€‚åœ¨çœŸå®æœºå™¨äººä¸Šè¿›è¡Œå®éªŒä¹ŸéªŒè¯äº†è¯¥æ–¹æ¡ˆçš„æœ‰æ•ˆæ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>é’ˆå¯¹å¤šæœºå™¨äººç³»ç»Ÿçš„ç½‘ç»œç‰¹æ€§ï¼Œæå‡ºäº†ç‰©ç†ä¿¡æ¯å¢å¼ºçš„å¼ºåŒ–å­¦ä¹ æ–¹æ¡ˆï¼Œç”¨äºå­¦ä¹ åˆ†å¸ƒå¼çš„å¤šæœºå™¨äººæ§åˆ¶ç­–ç•¥ã€‚</li>
<li>è¯¥æ–¹æ¡ˆå…·å¤‡å¯æ‰©å±•æ€§ï¼Œå¹¶èƒ½åˆ©ç”¨æ¯ä¸ªæœºå™¨äººçš„æ‰€æœ‰å¯ç”¨ä¿¡æ¯ã€‚</li>
<li>é‡‡ç”¨ç«¯å£å“ˆå¯†é¡¿ç»“æ„ï¼Œå°Šé‡ç‰©ç†æœºå™¨äººç³»ç»Ÿçš„èƒ½é‡å®ˆæ’å±æ€§å’Œæœºå™¨äººå›¢é˜Ÿçš„äº¤äº’ç½‘ç»œæ€§è´¨ã€‚</li>
<li>ä½¿ç”¨è‡ªæ³¨æ„åŠ›æœºåˆ¶å¤„ç†ç¨€ç–ç­–ç•¥è¡¨ç¤ºå’Œæ—¶å˜ä¿¡æ¯ã€‚</li>
<li>æå‡ºä¸€ç§è½¯åŠ¨ä½œè¯„è®ºå®¶å¼ºåŒ–å­¦ä¹ ç®—æ³•ï¼Œè§£å†³æœºå™¨äººé—´çš„ç›¸å…³æ€§é—®é¢˜ï¼Œæé«˜è®­ç»ƒçš„å¯æ‰©å±•æ€§ã€‚</li>
<li>ä»¿çœŸå®éªŒè¡¨æ˜è¯¥æ–¹æ¡ˆåœ¨å¤šç§å¤šæœºå™¨äººåœºæ™¯ä¸‹è¡¨ç°ä¼˜å¼‚ï¼Œè¶…è¶Šä¹‹å‰çš„è§£å†³æ–¹æ¡ˆã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2401.00212">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-140982ed0acaf9908eeadac670ab0d54.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a538361cf8a02aaee2572789667f1c8c.jpg" align="middle">
</details>


<h1 id="-18"><a href="#-18" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-03-27/Agent/">https://kedreamix.github.io/Talk2Paper/Paper/2025-03-27/Agent/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/Agent/">
                                    <span class="chip bg-color">Agent</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-03-27/Few-Shot/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-b9a423886f9f0e59e16c6b1f850b2916.jpg" class="responsive-img" alt="Few-Shot">
                        
                        <span class="card-title">Few-Shot</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Few-Shot æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-03-27  Show or Tell? Effectively prompting Vision-Language Models for semantic   segmentation
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-03-27
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Few-Shot/" class="post-category">
                                    Few-Shot
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Few-Shot/">
                        <span class="chip bg-color">Few-Shot</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-03-27/LLM/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-1fd0df86edf04907f3a27458febd4eb5.jpg" class="responsive-img" alt="LLM">
                        
                        <span class="card-title">LLM</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            LLM æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-03-27  CoLLM A Large Language Model for Composed Image Retrieval
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-03-27
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/LLM/" class="post-category">
                                    LLM
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/LLM/">
                        <span class="chip bg-color">LLM</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">32562k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
