<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="å…ƒå®‡å®™/è™šæ‹Ÿäºº">
    <meta name="description" content="å…ƒå®‡å®™/è™šæ‹Ÿäºº æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-03-27  AvatarArtist Open-Domain 4D Avatarization">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>å…ƒå®‡å®™/è™šæ‹Ÿäºº | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://picx.zhimg.com/v2-d14a0d7f6781e1438a3a78de39f33397.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">å…ƒå®‡å®™/è™šæ‹Ÿäºº</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/%E5%85%83%E5%AE%87%E5%AE%99-%E8%99%9A%E6%8B%9F%E4%BA%BA/">
                                <span class="chip bg-color">å…ƒå®‡å®™/è™šæ‹Ÿäºº</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/%E5%85%83%E5%AE%87%E5%AE%99-%E8%99%9A%E6%8B%9F%E4%BA%BA/" class="post-category">
                                å…ƒå®‡å®™/è™šæ‹Ÿäºº
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-03-27
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-05-14
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    7.7k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    31 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-03-27-æ›´æ–°"><a href="#2025-03-27-æ›´æ–°" class="headerlink" title="2025-03-27 æ›´æ–°"></a>2025-03-27 æ›´æ–°</h1><h2 id="AvatarArtist-Open-Domain-4D-Avatarization"><a href="#AvatarArtist-Open-Domain-4D-Avatarization" class="headerlink" title="AvatarArtist: Open-Domain 4D Avatarization"></a>AvatarArtist: Open-Domain 4D Avatarization</h2><p><strong>Authors:Hongyu Liu, Xuan Wang, Ziyu Wan, Yue Ma, Jingye Chen, Yanbo Fan, Yujun Shen, Yibing Song, Qifeng Chen</strong></p>
<p>This work focuses on open-domain 4D avatarization, with the purpose of creating a 4D avatar from a portrait image in an arbitrary style. We select parametric triplanes as the intermediate 4D representation and propose a practical training paradigm that takes advantage of both generative adversarial networks (GANs) and diffusion models. Our design stems from the observation that 4D GANs excel at bridging images and triplanes without supervision yet usually face challenges in handling diverse data distributions. A robust 2D diffusion prior emerges as the solution, assisting the GAN in transferring its expertise across various domains. The synergy between these experts permits the construction of a multi-domain image-triplane dataset, which drives the development of a general 4D avatar creator. Extensive experiments suggest that our model, AvatarArtist, is capable of producing high-quality 4D avatars with strong robustness to various source image domains. The code, the data, and the models will be made publicly available to facilitate future studies.. </p>
<blockquote>
<p>æœ¬æ–‡é‡ç‚¹å…³æ³¨å¼€æ”¾åŸŸ4DåŒ–èº«æŠ€æœ¯ï¼Œæ—¨åœ¨ä»ä»»æ„é£æ ¼çš„è‚–åƒå›¾åƒä¸­åˆ›å»º4DåŒ–èº«ã€‚æˆ‘ä»¬é€‰æ‹©å‚æ•°åŒ–ä¸‰å¹³é¢ä½œä¸ºä¸­é—´4Dè¡¨ç¤ºï¼Œå¹¶æå‡ºäº†ä¸€ç§å®ç”¨çš„è®­ç»ƒèŒƒå¼ï¼Œè¯¥èŒƒå¼ç»“åˆäº†ç”Ÿæˆå¯¹æŠ—ç½‘ç»œï¼ˆGANsï¼‰å’Œæ‰©æ•£æ¨¡å‹ã€‚æˆ‘ä»¬çš„è®¾è®¡çµæ„Ÿæ¥è‡ªäºä¸€ä¸ªè§‚å¯Ÿç»“æœï¼Œå³4D GANsåœ¨æ— ç›‘ç£çš„æƒ…å†µä¸‹åœ¨æ¡¥æ¥å›¾åƒå’Œä¸‰å¹³é¢æ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œä½†åœ¨å¤„ç†å¤šæ ·æ•°æ®åˆ†å¸ƒæ—¶é€šå¸¸é¢ä¸´æŒ‘æˆ˜ã€‚ä¸€ä¸ªç¨³å¥çš„2Dæ‰©æ•£å…ˆéªŒä½œä¸ºä¸€ä¸ªè§£å†³æ–¹æ¡ˆå‡ºç°ï¼Œå®ƒå¯ä»¥å¸®åŠ©GANåœ¨ä¸åŒçš„é¢†åŸŸä¹‹é—´è½¬ç§»å…¶ä¸“ä¸šçŸ¥è¯†ã€‚è¿™äº›ä¸“å®¶ä¹‹é—´çš„ååŒä½œç”¨ä½¿å¾—æ„å»ºå¤šåŸŸå›¾åƒ-ä¸‰å¹³é¢æ•°æ®é›†æˆä¸ºå¯èƒ½ï¼Œä»è€Œæ¨åŠ¨äº†é€šç”¨4DåŒ–èº«åˆ›ä½œè€…çš„å‘å±•ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ¨¡å‹AvatarArtistèƒ½å¤Ÿç”Ÿæˆé«˜è´¨é‡çš„4DåŒ–èº«ï¼Œå¯¹å„ç§æºå›¾åƒé¢†åŸŸå…·æœ‰å¾ˆå¼ºçš„ç¨³å¥æ€§ã€‚ä»£ç ã€æ•°æ®å’Œæ¨¡å‹å°†å…¬å¼€æä¾›ï¼Œä»¥æ–¹ä¾¿æœªæ¥ç ”ç©¶ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.19906v1">PDF</a> Accepted to CVPR 2025</p>
<p><strong>æ‘˜è¦</strong></p>
<p>æœ¬æ–‡å…³æ³¨å¼€æ”¾åŸŸ4DåŠ¨æ€ä¸ªæ€§åŒ–è§’è‰²çš„åˆ›å»ºï¼Œæ—¨åœ¨ä»ä»»æ„é£æ ¼çš„è‚–åƒå›¾ç‰‡ç”Ÿæˆ4DåŠ¨æ€ä¸ªæ€§åŒ–è§’è‰²ã€‚ç ”ç©¶é‡‡ç”¨å‚æ•°åŒ–triplanesä½œä¸ºä¸­é—´4Dè¡¨ç¤ºå½¢å¼ï¼Œå¹¶æå‡ºä¸€ç§ç»“åˆç”Ÿæˆå¯¹æŠ—ç½‘ç»œï¼ˆGANsï¼‰å’Œæ‰©æ•£æ¨¡å‹çš„å®ç”¨è®­ç»ƒèŒƒå¼ã€‚è®¾è®¡çµæ„Ÿæ¥æºäºå¯¹GANsçš„è§‚å¯Ÿï¼Œå®ƒèƒ½æ— ç›‘ç£åœ°å®ç°å›¾åƒå’Œtriplanesä¹‹é—´çš„æ¡¥æ¢ä½œç”¨ï¼Œä½†åœ¨å¤„ç†å¤šæ ·æ•°æ®åˆ†å¸ƒæ—¶é¢ä¸´æŒ‘æˆ˜ã€‚ä¸€ä¸ªç¨³å¥çš„äºŒç»´æ‰©æ•£å…ˆéªŒæˆä¸ºè§£å†³æ–¹æ¡ˆï¼Œå¸®åŠ©GANåœ¨ä¸åŒé¢†åŸŸä¹‹é—´è½¬ç§»çŸ¥è¯†ã€‚è¿™äº›ä¸“å®¶ä¹‹é—´çš„ååŒä½œç”¨ä½¿å¾—æ„å»ºå¤šåŸŸå›¾åƒ-triplaneæ•°æ®é›†æˆä¸ºå¯èƒ½ï¼Œä»è€Œæ¨åŠ¨äº†é€šç”¨4DåŠ¨æ€ä¸ªæ€§åŒ–è§’è‰²åˆ›å»ºå™¨çš„å‘å±•ã€‚å®éªŒè¡¨æ˜ï¼ŒAvatarArtistæ¨¡å‹èƒ½å¤Ÿç”Ÿæˆé«˜è´¨é‡çš„4DåŠ¨æ€ä¸ªæ€§åŒ–è§’è‰²ï¼Œå¯¹å„ç§æºå›¾åƒé¢†åŸŸå…·æœ‰è¾ƒå¼ºçš„é²æ£’æ€§ã€‚ä»£ç ã€æ•°æ®å’Œæ¨¡å‹å°†å…¬å¼€æä¾›ï¼Œä»¥ä¾¿äºåç»­ç ”ç©¶ã€‚</p>
<p><strong>å…³é”®è§è§£</strong></p>
<ol>
<li>æœ¬ç ”ç©¶å…³æ³¨å¼€æ”¾åŸŸ4DåŠ¨æ€ä¸ªæ€§åŒ–è§’è‰²çš„åˆ›å»ºï¼Œæ—¨åœ¨ä»è‚–åƒå›¾ç‰‡ç”Ÿæˆ4Dè§’è‰²ã€‚</li>
<li>ç ”ç©¶é‡‡ç”¨å‚æ•°åŒ–triplanesä½œä¸ºä¸­é—´å½¢å¼è¿›è¡Œè¡¨ç¤ºã€‚</li>
<li>ç ”ç©¶ç»“åˆäº†ç”Ÿæˆå¯¹æŠ—ç½‘ç»œï¼ˆGANsï¼‰å’Œæ‰©æ•£æ¨¡å‹æ¥æ„å»ºè®­ç»ƒèŒƒå¼ã€‚</li>
<li>GANåœ¨å¤„ç†å¤šæ ·æ•°æ®åˆ†å¸ƒæ—¶å­˜åœ¨æŒ‘æˆ˜ï¼Œæå‡ºåˆ©ç”¨ç¨³å¥çš„äºŒç»´æ‰©æ•£å…ˆéªŒæ¥å¸®åŠ©æé«˜æ¨¡å‹æ€§èƒ½ã€‚</li>
<li>å®ç°äº†ä¸åŒé¢†åŸŸçš„å›¾åƒå’Œtriplanesä¹‹é—´çš„ååŒä½œç”¨ï¼Œæ¨åŠ¨äº†å¤šåŸŸå›¾åƒ-triplaneæ•°æ®é›†çš„æ„å»ºã€‚</li>
<li>ç ”ç©¶å¼€å‘äº†åä¸ºAvatarArtistçš„æ¨¡å‹ï¼Œèƒ½å¤Ÿç”Ÿæˆé«˜è´¨é‡çš„4DåŠ¨æ€ä¸ªæ€§åŒ–è§’è‰²ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.19906">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-c44b9fac00940094057255e461b9d913.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-ea16d6a700d3d7ab1b01cea39a78f1f4.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-f846e42e4d2905e2771588ee66b27a5b.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-e29711d534a981fd7ac40ac11f5578c9.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-4b3014ffdb5e751ad6bd3b845ec67cf6.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="FRESA-Feedforward-Reconstruction-of-Personalized-Skinned-Avatars-from-Few-Images"><a href="#FRESA-Feedforward-Reconstruction-of-Personalized-Skinned-Avatars-from-Few-Images" class="headerlink" title="FRESA:Feedforward Reconstruction of Personalized Skinned Avatars from   Few Images"></a>FRESA:Feedforward Reconstruction of Personalized Skinned Avatars from   Few Images</h2><p><strong>Authors:Rong Wang, Fabian Prada, Ziyan Wang, Zhongshi Jiang, Chengxiang Yin, Junxuan Li, Shunsuke Saito, Igor Santesteban, Javier Romero, Rohan Joshi, Hongdong Li, Jason Saragih, Yaser Sheikh</strong></p>
<p>We present a novel method for reconstructing personalized 3D human avatars with realistic animation from only a few images. Due to the large variations in body shapes, poses, and cloth types, existing methods mostly require hours of per-subject optimization during inference, which limits their practical applications. In contrast, we learn a universal prior from over a thousand clothed humans to achieve instant feedforward generation and zero-shot generalization. Specifically, instead of rigging the avatar with shared skinning weights, we jointly infer personalized avatar shape, skinning weights, and pose-dependent deformations, which effectively improves overall geometric fidelity and reduces deformation artifacts. Moreover, to normalize pose variations and resolve coupled ambiguity between canonical shapes and skinning weights, we design a 3D canonicalization process to produce pixel-aligned initial conditions, which helps to reconstruct fine-grained geometric details. We then propose a multi-frame feature aggregation to robustly reduce artifacts introduced in canonicalization and fuse a plausible avatar preserving person-specific identities. Finally, we train the model in an end-to-end framework on a large-scale capture dataset, which contains diverse human subjects paired with high-quality 3D scans. Extensive experiments show that our method generates more authentic reconstruction and animation than state-of-the-arts, and can be directly generalized to inputs from casually taken phone photos. Project page and code is available at <a target="_blank" rel="noopener" href="https://github.com/rongakowang/FRESA">https://github.com/rongakowang/FRESA</a>. </p>
<blockquote>
<p>æˆ‘ä»¬æå‡ºäº†ä¸€ç§ä»…é€šè¿‡å‡ å¼ å›¾ç‰‡é‡å»ºå…·æœ‰çœŸå®åŠ¨ç”»æ•ˆæœçš„ä¸ªæ€§åŒ–3Däººç±»åŒ–èº«çš„æ–°æ–¹æ³•ã€‚ç”±äºäººä½“å½¢çŠ¶ã€å§¿åŠ¿å’Œæœè£…ç±»å‹çš„å·¨å¤§å·®å¼‚ï¼Œç°æœ‰æ–¹æ³•å¤§å¤šéœ€è¦åœ¨æ¨ç†è¿‡ç¨‹ä¸­å¯¹æ¯ä¸ªä¸»é¢˜è¿›è¡Œæ•°å°æ—¶çš„ä¼˜åŒ–ï¼Œè¿™é™åˆ¶äº†å®ƒä»¬çš„å®é™…åº”ç”¨ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼Œæˆ‘ä»¬ä»æ•°åƒåç©¿è¡£è€…èº«ä¸Šå­¦ä¹ é€šç”¨å…ˆéªŒçŸ¥è¯†ï¼Œä»¥å®ç°å³æ—¶å‰é¦ˆç”Ÿæˆå’Œé›¶æ ·æœ¬æ³›åŒ–ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬ä¸æ˜¯ç”¨å…±äº«çš„è’™çš®æƒé‡æ¥æ­å»ºåŒ–èº«ï¼Œè€Œæ˜¯è”åˆæ¨æ–­ä¸ªæ€§åŒ–çš„åŒ–èº«å½¢çŠ¶ã€è’™çš®æƒé‡å’Œå§¿åŠ¿ç›¸å…³çš„å˜å½¢ï¼Œè¿™æœ‰æ•ˆåœ°æé«˜äº†æ•´ä½“å‡ ä½•ä¿çœŸåº¦å¹¶å‡å°‘äº†å˜å½¢ä¼ªå½±ã€‚æ­¤å¤–ï¼Œä¸ºäº†å½’ä¸€åŒ–å§¿åŠ¿å˜åŒ–å’Œè§£å†³è§„èŒƒå½¢çŠ¶å’Œè’™çš®æƒé‡ä¹‹é—´çš„è€¦åˆæ¨¡ç³Šæ€§ï¼Œæˆ‘ä»¬è®¾è®¡äº†ä¸€ä¸ª3Dè§„èŒƒåŒ–è¿‡ç¨‹æ¥ç”Ÿæˆåƒç´ å¯¹é½çš„åˆå§‹æ¡ä»¶ï¼Œè¿™æœ‰åŠ©äºé‡å»ºç²¾ç»†çš„å‡ ä½•ç»†èŠ‚ã€‚ç„¶åï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§å¤šå¸§ç‰¹å¾èšåˆæ–¹æ³•ï¼Œä»¥ç¨³å¥åœ°å‡å°‘è§„èŒƒåŒ–è¿‡ç¨‹ä¸­äº§ç”Ÿçš„ä¼ªå½±ï¼Œå¹¶èåˆä¿ç•™ä¸ªäººç‰¹å®šèº«ä»½çš„å¯è¡ŒåŒ–èº«ã€‚æœ€åï¼Œæˆ‘ä»¬åœ¨ä¸€ä¸ªå¤§è§„æ¨¡æ•è·æ•°æ®é›†ä¸Šé‡‡ç”¨ç«¯åˆ°ç«¯æ¡†æ¶è¿›è¡Œæ¨¡å‹è®­ç»ƒï¼Œè¯¥æ•°æ®é›†åŒ…å«ä¸é«˜è´¨é‡3Dæ‰«æé…å¯¹çš„å¤šæ ·åŒ–äººç±»ä¸»é¢˜ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•æ¯”æœ€å…ˆè¿›çš„æŠ€æœ¯ç”Ÿæˆæ›´çœŸå®çš„é‡å»ºå’ŒåŠ¨ç”»ï¼Œå¹¶ä¸”å¯ä»¥ç›´è§‚åœ°æ¨å¹¿åˆ°æ¥è‡ªéšæ„æ‹æ‘„çš„æ‰‹æœºç…§ç‰‡è¾“å…¥ã€‚é¡¹ç›®é¡µé¢å’Œä»£ç ä½äº<a target="_blank" rel="noopener" href="https://github.com/rongakowang/FRESA%E3%80%82">https://github.com/rongakowang/FRESAã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.19207v1">PDF</a> Published in CVPR 2025</p>
<p><strong>Summary</strong><br>æ–°ä¸€ä»£ä¸ªæ€§åŒ–ä¸‰ç»´äººç±»è™šæ‹Ÿè§’è‰²é‡å»ºæ–¹æ³•ï¼šé‡‡ç”¨æ·±åº¦å­¦ä¹ æŠ€æœ¯ï¼Œä»å°‘é‡å›¾ç‰‡ä¸­é‡å»ºå‡ºå…·æœ‰é«˜åº¦çœŸå®æ„Ÿçš„åŠ¨ç”»è§’è‰²ã€‚è¯¥æ–¹æ³•é€šè¿‡é€šç”¨å…ˆéªŒå­¦ä¹ ï¼Œå®ç°äº†å³æ—¶å‰é¦ˆç”Ÿæˆä¸é›¶æ ·æœ¬æ³›åŒ–ï¼Œä¼˜åŒ–äº†è§’è‰²å½¢çŠ¶ã€çš®è‚¤è´´åˆæƒé‡å’Œå§¿æ€å˜å½¢è”åˆæ¨æ–­ï¼Œæé«˜äº†å‡ ä½•ç²¾åº¦å¹¶é™ä½äº†å˜å½¢å¤±çœŸã€‚é€šè¿‡è®¾è®¡3Dæ ‡å‡†åŒ–æµç¨‹è§£å†³å§¿æ€å˜åŒ–å’Œè€¦åˆæ¨¡ç³Šé—®é¢˜ï¼Œç”Ÿæˆç²¾ç»†å‡ ä½•ç»†èŠ‚ã€‚ä½¿ç”¨å¤šå¸§ç‰¹å¾èšåˆæŠ€æœ¯é™ä½æ ‡å‡†åŒ–äº§ç”Ÿçš„ä¼ªå½±ï¼Œå¹¶ä¿æŒä¸ªæ€§åŒ–èº«ä»½ã€‚åœ¨å¤§å‹æ•æ‰æ•°æ®é›†ä¸Šè¿›è¡Œç«¯åˆ°ç«¯æ¡†æ¶è®­ç»ƒï¼Œä¸ç°æœ‰æŠ€æœ¯ç›¸æ¯”ç”Ÿæˆæ›´çœŸå®çš„ä¸‰ç»´äººç±»åŠ¨ç”»ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æå‡ºäº†ä¸€ç§æ–°çš„ä¸ªæ€§åŒ–ä¸‰ç»´äººç±»è™šæ‹Ÿè§’è‰²é‡å»ºæ–¹æ³•ï¼Œèƒ½ä»å°‘é‡å›¾ç‰‡ä¸­é‡å»ºå‡ºçœŸå®æ„ŸåŠ¨ç”»è§’è‰²ã€‚</li>
<li>é€šè¿‡é€šç”¨å…ˆéªŒå­¦ä¹ å®ç°å³æ—¶å‰é¦ˆç”Ÿæˆä¸é›¶æ ·æœ¬æ³›åŒ–ï¼Œæé«˜äº†é‡å»ºæ•ˆç‡ã€‚</li>
<li>ä¼˜åŒ–äº†è§’è‰²å½¢çŠ¶ã€çš®è‚¤è´´åˆæƒé‡å’Œå§¿æ€å˜å½¢çš„è”åˆæ¨æ–­ï¼Œæé«˜äº†å‡ ä½•ç²¾åº¦ã€‚</li>
<li>è®¾è®¡çš„3Dæ ‡å‡†åŒ–æµç¨‹èƒ½è§£å†³å§¿æ€å˜åŒ–å’Œè€¦åˆæ¨¡ç³Šé—®é¢˜ï¼Œç”Ÿæˆç²¾ç»†å‡ ä½•ç»†èŠ‚ã€‚</li>
<li>é‡‡ç”¨å¤šå¸§ç‰¹å¾èšåˆæŠ€æœ¯é™ä½æ ‡å‡†åŒ–äº§ç”Ÿçš„ä¼ªå½±ï¼Œä¿æŒä¸ªæ€§åŒ–èº«ä»½ã€‚</li>
<li>åœ¨å¤§å‹æ•æ‰æ•°æ®é›†ä¸Šè¿›è¡Œç«¯åˆ°ç«¯æ¡†æ¶è®­ç»ƒï¼Œç¡®ä¿æ¨¡å‹çš„å‡†ç¡®æ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.19207">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-6836aeb555f598f7167e011d4788b25d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-1b015e489b3d7e78163a2c17b2048d4e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-bc991e939e499f783d3edf435c625b70.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="MetaSpatial-Reinforcing-3D-Spatial-Reasoning-in-VLMs-for-the-Metaverse"><a href="#MetaSpatial-Reinforcing-3D-Spatial-Reasoning-in-VLMs-for-the-Metaverse" class="headerlink" title="MetaSpatial: Reinforcing 3D Spatial Reasoning in VLMs for the Metaverse"></a>MetaSpatial: Reinforcing 3D Spatial Reasoning in VLMs for the Metaverse</h2><p><strong>Authors:Zhenyu Pan, Han Liu</strong></p>
<p>We present MetaSpatial, the first reinforcement learning (RL)-based framework designed to enhance 3D spatial reasoning in vision-language models (VLMs), enabling real-time 3D scene generation without the need for hard-coded optimizations. MetaSpatial addresses two core challenges: (i) the lack of internalized 3D spatial reasoning in VLMs, which limits their ability to generate realistic layouts, and (ii) the inefficiency of traditional supervised fine-tuning (SFT) for layout generation tasks, as perfect ground truth annotations are unavailable. Our key innovation is a multi-turn RL-based optimization mechanism that integrates physics-aware constraints and rendered image evaluations, ensuring generated 3D layouts are coherent, physically plausible, and aesthetically consistent. Methodologically, MetaSpatial introduces an adaptive, iterative reasoning process, where the VLM refines spatial arrangements over multiple turns by analyzing rendered outputs, improving scene coherence progressively. Empirical evaluations demonstrate that MetaSpatial significantly enhances the spatial consistency and formatting stability of various scale models. Post-training, object placements are more realistic, aligned, and functionally coherent, validating the effectiveness of RL for 3D spatial reasoning in metaverse, AR&#x2F;VR, digital twins, and game development applications. Our code, data, and training pipeline are publicly available at <a target="_blank" rel="noopener" href="https://github.com/PzySeere/MetaSpatial">https://github.com/PzySeere/MetaSpatial</a>. </p>
<blockquote>
<p>æˆ‘ä»¬æ¨å‡ºMetaSpatialï¼Œè¿™æ˜¯é¦–ä¸ªåŸºäºå¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰çš„æ¡†æ¶ï¼Œæ—¨åœ¨å¢å¼ºè§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMsï¼‰çš„3Dç©ºé—´æ¨ç†èƒ½åŠ›ï¼Œå®ç°æ— éœ€ç¡¬ç¼–ç ä¼˜åŒ–çš„å®æ—¶3Dåœºæ™¯ç”Ÿæˆã€‚MetaSpatialè§£å†³äº†ä¸¤ä¸ªæ ¸å¿ƒæŒ‘æˆ˜ï¼šï¼ˆiï¼‰VLMså†…éƒ¨ç¼ºä¹3Dç©ºé—´æ¨ç†èƒ½åŠ›ï¼Œé™åˆ¶äº†å…¶ç”ŸæˆçœŸå®å¸ƒå±€çš„èƒ½åŠ›ï¼›ï¼ˆiiï¼‰å¯¹äºå¸ƒå±€ç”Ÿæˆä»»åŠ¡ï¼Œä¼ ç»Ÿçš„ç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰æ•ˆç‡ä½ä¸‹ï¼Œå› ä¸ºå®Œç¾çš„çœŸå®æ ‡æ³¨ä¸å¯ç”¨ã€‚æˆ‘ä»¬çš„å…³é”®åˆ›æ–°åœ¨äºé‡‡ç”¨åŸºäºå¤šå›åˆçš„å¼ºåŒ–å­¦ä¹ ä¼˜åŒ–æœºåˆ¶ï¼Œè¯¥æœºåˆ¶ç»“åˆäº†ç‰©ç†æ„ŸçŸ¥çº¦æŸå’Œæ¸²æŸ“å›¾åƒè¯„ä¼°ï¼Œç¡®ä¿ç”Ÿæˆçš„3Då¸ƒå±€è¿è´¯ã€ç‰©ç†ä¸Šåˆç†ä¸”å®¡ç¾ä¸Šä¸€è‡´ã€‚æ–¹æ³•ä¸Šï¼ŒMetaSpatialå¼•å…¥äº†ä¸€ç§è‡ªé€‚åº”çš„è¿­ä»£æ¨ç†è¿‡ç¨‹ï¼ŒVLMé€šè¿‡åˆ†ææ¸²æŸ“è¾“å‡ºæ¥å®Œå–„ç©ºé—´å¸ƒå±€ï¼Œé€æ­¥æ”¹è¿›åœºæ™¯çš„ä¸€è‡´æ€§ã€‚ç»éªŒè¯„ä¼°è¡¨æ˜ï¼ŒMetaSpatialæ˜¾è‘—æé«˜äº†å„ç§è§„æ¨¡æ¨¡å‹çš„ç©ºé—´ä¸€è‡´æ€§å’Œæ ¼å¼ç¨³å®šæ€§ã€‚è®­ç»ƒåï¼Œå¯¹è±¡æ”¾ç½®æ›´åŠ çœŸå®ã€å¯¹é½ä¸”åŠŸèƒ½è¿è´¯ï¼ŒéªŒè¯äº†å¼ºåŒ–å­¦ä¹ åœ¨å…ƒå®‡å®™ã€AR&#x2F;VRã€æ•°å­—å­ªç”Ÿå’Œæ¸¸æˆå¼€å‘åº”ç”¨ç¨‹åºä¸­çš„3Dç©ºé—´æ¨ç†çš„æœ‰æ•ˆæ€§ã€‚æˆ‘ä»¬çš„ä»£ç ã€æ•°æ®å’Œè®­ç»ƒç®¡é“å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/PzySeere/MetaSpatial%E5%85%AC%E5%BC%80%E8%8E%B7%E5%8F%96%E3%80%82">https://github.com/PzySeere/MetaSpatialå…¬å¼€è·å–ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.18470v1">PDF</a> Working Paper</p>
<p><strong>Summary</strong>ï¼š</p>
<p>MetaSpatialæ˜¯ä¸€ä¸ªåŸºäºå¼ºåŒ–å­¦ä¹ çš„æ¡†æ¶ï¼Œæ—¨åœ¨æé«˜è§†è§‰è¯­è¨€æ¨¡å‹åœ¨å…ƒå®‡å®™ä¸­çš„ä¸‰ç»´ç©ºé—´æ¨ç†èƒ½åŠ›ï¼Œå®ç°å®æ—¶ä¸‰ç»´åœºæ™¯ç”Ÿæˆï¼Œæ— éœ€ç¡¬ç¼–ç ä¼˜åŒ–ã€‚å®ƒé€šè¿‡å¼•å…¥å¤šå›åˆçš„å¼ºåŒ–å­¦ä¹ ä¼˜åŒ–æœºåˆ¶è§£å†³äº†ä¸¤å¤§éš¾é¢˜ï¼Œä½¿å¾—ç”Ÿæˆçš„ä¸‰ç»´å¸ƒå±€æ›´ä¸ºè¿è´¯ã€ç‰©ç†å¯è¡Œä¸”ç¾å­¦ä¸€è‡´ã€‚è¿™ä¸€æ¡†æ¶åœ¨å¤šç§åº”ç”¨åœºæ™¯ä¸‹å‡è¡¨ç°å‡ºå“è¶Šæ•ˆæœã€‚</p>
<p><strong>Key Takeaways</strong>:</p>
<ol>
<li>MetaSpatialæ˜¯é¦–ä¸ªåŸºäºå¼ºåŒ–å­¦ä¹ çš„æ¡†æ¶ï¼Œæ—¨åœ¨å¢å¼ºè§†è§‰è¯­è¨€æ¨¡å‹çš„ä¸‰ç»´ç©ºé—´æ¨ç†èƒ½åŠ›ã€‚</li>
<li>è¯¥æ¡†æ¶èƒ½å¤Ÿå®ç°å®æ—¶ä¸‰ç»´åœºæ™¯ç”Ÿæˆï¼Œæ— éœ€ç¡¬ç¼–ç ä¼˜åŒ–ã€‚</li>
<li>MetaSpatialè§£å†³äº†ä¼ ç»Ÿç›‘ç£å¾®è°ƒæ–¹æ³•åœ¨å¤„ç†å¸ƒå±€ç”Ÿæˆä»»åŠ¡æ—¶çš„ä¸¤å¤§éš¾é¢˜ã€‚</li>
<li>å¼ºåŒ–å­¦ä¹ ä¼˜åŒ–æœºåˆ¶ç¡®ä¿äº†ç”Ÿæˆçš„ä¸‰ç»´å¸ƒå±€çš„è¿è´¯æ€§ã€ç‰©ç†å¯è¡Œæ€§å’Œç¾å­¦ä¸€è‡´æ€§ã€‚</li>
<li>è¯¥æ¡†æ¶å¼•å…¥äº†è‡ªé€‚åº”çš„è¿­ä»£æ¨ç†è¿‡ç¨‹ï¼Œé€šè¿‡å¤šæ¬¡åˆ†ææ¸²æŸ“è¾“å‡ºæ¥é€æ­¥æ”¹è¿›åœºæ™¯çš„ä¸€è‡´æ€§ã€‚</li>
<li>MetaSpatialåœ¨å¤šç§åº”ç”¨åœºæ™¯ä¸‹è¡¨ç°å‡ºå“è¶Šçš„æ•ˆæœï¼Œå¦‚å…ƒå®‡å®™ã€AR&#x2F;VRã€æ•°å­—åŒèƒèƒå’Œæ¸¸æˆå¼€å‘ç­‰ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.18470">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-9a3097db8d905794c82d950a1274ae88.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-106860fd65527a76611b25de4bdc9519.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-98f965290fe05553f063fc920b3ff4cd.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="Fast-and-Physically-based-Neural-Explicit-Surface-for-Relightable-Human-Avatars"><a href="#Fast-and-Physically-based-Neural-Explicit-Surface-for-Relightable-Human-Avatars" class="headerlink" title="Fast and Physically-based Neural Explicit Surface for Relightable Human   Avatars"></a>Fast and Physically-based Neural Explicit Surface for Relightable Human   Avatars</h2><p><strong>Authors:Jiacheng Wu, Ruiqi Zhang, Jie Chen, Hui Zhang</strong></p>
<p>Efficiently modeling relightable human avatars from sparse-view videos is crucial for AR&#x2F;VR applications. Current methods use neural implicit representations to capture dynamic geometry and reflectance, which incur high costs due to the need for dense sampling in volume rendering. To overcome these challenges, we introduce Physically-based Neural Explicit Surface (PhyNES), which employs compact neural material maps based on the Neural Explicit Surface (NES) representation. PhyNES organizes human models in a compact 2D space, enhancing material disentanglement efficiency. By connecting Signed Distance Fields to explicit surfaces, PhyNES enables efficient geometry inference around a parameterized human shape model. This approach models dynamic geometry, texture, and material maps as 2D neural representations, enabling efficient rasterization. PhyNES effectively captures physical surface attributes under varying illumination, enabling real-time physically-based rendering. Experiments show that PhyNES achieves relighting quality comparable to SOTA methods while significantly improving rendering speed, memory efficiency, and reconstruction quality. </p>
<blockquote>
<p>å¯¹äºAR&#x2F;VRåº”ç”¨è€Œè¨€ï¼Œä»ç¨€ç–è§†è§’çš„è§†é¢‘ä¸­æœ‰æ•ˆåœ°å»ºæ¨¡å¯é‡æ–°ç…§æ˜çš„çœŸå®äººç±»è§’è‰²è‡³å…³é‡è¦ã€‚å½“å‰çš„æ–¹æ³•ä½¿ç”¨ç¥ç»éšå¼è¡¨ç¤ºæ¥æ•æ‰åŠ¨æ€å‡ ä½•å’Œåå°„ï¼Œè¿™ç”±äºåœ¨ä½“ç§¯æ¸²æŸ“ä¸­éœ€è¦å¯†é›†é‡‡æ ·è€Œäº§ç”Ÿé«˜æ˜‚çš„æˆæœ¬ã€‚ä¸ºäº†å…‹æœè¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬å¼•å…¥äº†åŸºäºç‰©ç†çš„ç¥ç»ç½‘ç»œæ˜¾å¼è¡¨é¢ï¼ˆPhyNESï¼‰ï¼Œå®ƒé‡‡ç”¨åŸºäºç¥ç»ç½‘ç»œæ˜¾å¼è¡¨é¢ï¼ˆNESï¼‰è¡¨ç¤ºçš„ç´§å‡‘ç¥ç»ç½‘ç»œæè´¨å›¾ã€‚PhyNESå°†äººç±»æ¨¡å‹ç»„ç»‡åœ¨ç´§å‡‘çš„äºŒç»´ç©ºé—´ä¸­ï¼Œæé«˜äº†æè´¨åˆ†ç¦»æ•ˆç‡ã€‚é€šè¿‡å°†ç¬¦å·è·ç¦»åœºä¸æ˜¾å¼è¡¨é¢è¿æ¥èµ·æ¥ï¼ŒPhyNESèƒ½å¤Ÿåœ¨å‚æ•°åŒ–çš„äººç±»å½¢çŠ¶æ¨¡å‹å‘¨å›´å®ç°æœ‰æ•ˆçš„å‡ ä½•æ¨æ–­ã€‚è¿™ç§æ–¹æ³•å°†åŠ¨æ€å‡ ä½•ã€çº¹ç†å’Œæè´¨å›¾å»ºæ¨¡ä¸ºäºŒç»´ç¥ç»è¡¨ç¤ºï¼Œå¯å®ç°é«˜æ•ˆçš„ä¸‰è§’åŒ–å¤„ç†ã€‚PhyNESèƒ½å¤Ÿæ•è·ä¸åŒå…‰ç…§ä¸‹çš„ç‰©ç†è¡¨é¢å±æ€§ï¼Œä»è€Œå®ç°åŸºäºç‰©ç†çš„å®æ—¶æ¸²æŸ“ã€‚å®éªŒè¡¨æ˜ï¼ŒPhyNESåœ¨å®ç°é‡æ–°ç…§æ˜è´¨é‡æ–¹é¢ä¸æœ€å…ˆè¿›çš„æ–¹æ³•ç›¸å½“çš„åŒæ—¶ï¼Œæ˜¾è‘—æé«˜äº†æ¸²æŸ“é€Ÿåº¦ã€å†…å­˜æ•ˆç‡å’Œé‡å»ºè´¨é‡ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.18408v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†ä¸€ç§åŸºäºç‰©ç†çš„ç¥ç»ç½‘ç»œæ˜¾å¼è¡¨é¢ï¼ˆPhyNESï¼‰å»ºæ¨¡æ–¹æ³•ï¼Œç”¨äºä»ç¨€ç–è§†è§’çš„è§†é¢‘ä¸­é«˜æ•ˆåœ°æ¨¡æ‹Ÿå¯é‡æ–°ç…§æ˜çš„åŠ¨æ€äººç±»è§’è‰²ã€‚è¯¥æ–¹æ³•é‡‡ç”¨ç´§å‡‘çš„ç¥ç»ç½‘ç»œæè´¨æ˜ å°„ï¼Œç»“åˆç¥ç»ç½‘ç»œæ˜¾å¼è¡¨é¢ï¼ˆNESï¼‰è¡¨ç¤ºï¼Œé€šè¿‡è¿æ¥ç¬¦å·è·ç¦»åœºåˆ°æ˜¾å¼è¡¨é¢ï¼Œå®ç°é«˜æ•ˆå‡ ä½•æ¨æ–­ã€‚æ­¤æ–¹æ³•å°†åŠ¨æ€å‡ ä½•ã€çº¹ç†å’Œæè´¨æ˜ å°„ä¸ºäºŒç»´ç¥ç»ç½‘ç»œè¡¨ç¤ºï¼Œå®ç°é«˜æ•ˆæ¸²æŸ“ã€‚å®éªŒè¡¨æ˜ï¼ŒPhyNESåœ¨é‡æ–°ç…§æ˜è´¨é‡æ–¹é¢è¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ–¹æ³•æ°´å¹³ï¼ŒåŒæ—¶æ˜¾è‘—æé«˜äº†æ¸²æŸ“é€Ÿåº¦ã€å†…å­˜æ•ˆç‡å’Œé‡å»ºè´¨é‡ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>PhyNESæ–¹æ³•èƒ½å¤Ÿé«˜æ•ˆå»ºæ¨¡å¯é‡æ–°ç…§æ˜çš„åŠ¨æ€äººç±»è§’è‰²ï¼Œé€‚ç”¨äºAR&#x2F;VRåº”ç”¨ã€‚</li>
<li>é‡‡ç”¨ç´§å‡‘çš„ç¥ç»ç½‘ç»œæè´¨æ˜ å°„å’Œç¥ç»ç½‘ç»œæ˜¾å¼è¡¨é¢è¡¨ç¤ºã€‚</li>
<li>é€šè¿‡è¿æ¥ç¬¦å·è·ç¦»åœºåˆ°æ˜¾å¼è¡¨é¢ï¼Œå®ç°é«˜æ•ˆå‡ ä½•æ¨æ–­ã€‚</li>
<li>å°†åŠ¨æ€å‡ ä½•ã€çº¹ç†å’Œæè´¨æ˜ å°„ä¸ºäºŒç»´ç¥ç»ç½‘ç»œè¡¨ç¤ºï¼Œå®ç°é«˜æ•ˆæ¸²æŸ“ã€‚</li>
<li>PhyNESèƒ½æœ‰æ•ˆæ•æ‰ç‰©ç†è¡¨é¢å±æ€§åœ¨ä¸åŒç…§æ˜æ¡ä»¶ä¸‹çš„å˜åŒ–ã€‚</li>
<li>å®ç°å®æ—¶ç‰©ç†æ¸²æŸ“ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.18408">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-55e332e94e396ee09b76d4655fe687f8.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-f5275b63ca864b808617e16a0578355f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c3f790f63a878ddaf23055569b122444.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-3faa1a4272f95a5852c224af6be6fa2e.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-d14a0d7f6781e1438a3a78de39f33397.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="PRIMAL-Physically-Reactive-and-Interactive-Motor-Model-for-Avatar-Learning"><a href="#PRIMAL-Physically-Reactive-and-Interactive-Motor-Model-for-Avatar-Learning" class="headerlink" title="PRIMAL: Physically Reactive and Interactive Motor Model for Avatar   Learning"></a>PRIMAL: Physically Reactive and Interactive Motor Model for Avatar   Learning</h2><p><strong>Authors:Yan Zhang, Yao Feng, AlpÃ¡r Cseke, Nitin Saini, Nathan Bajandas, Nicolas Heron, Michael J. Black</strong></p>
<p>To build a motor system of the interactive avatar, it is essential to develop a generative motion model drives the body to move through 3D space in a perpetual, realistic, controllable, and responsive manner. Although motion generation has been extensively studied, most methods do not support <code>embodied intelligence&#39;&#39; due to their offline setting, slow speed, limited motion lengths, or unnatural movements. To overcome these limitations, we propose PRIMAL, an autoregressive diffusion model that is learned with a two-stage paradigm, inspired by recent advances in foundation models. In the pretraining stage, the model learns motion dynamics from a large number of sub-second motion segments, providing </code>motor primitivesâ€™â€™ from which more complex motions are built. In the adaptation phase, we employ a ControlNet-like adaptor to fine-tune the motor control for semantic action generation and spatial target reaching. Experiments show that physics effects emerge from our training. Given a single-frame initial state, our model not only generates unbounded, realistic, and controllable motion, but also enables the avatar to be responsive to induced impulses in real time. In addition, we can effectively and efficiently adapt our base model to few-shot personalized actions and the task of spatial control. Evaluations show that our proposed method outperforms state-of-the-art baselines. We leverage the model to create a real-time character animation system in Unreal Engine that is highly responsive and natural. Code, models, and more results are available at: <a target="_blank" rel="noopener" href="https://yz-cnsdqz.github.io/eigenmotion/PRIMAL">https://yz-cnsdqz.github.io/eigenmotion/PRIMAL</a> </p>
<blockquote>
<p>è¦æ„å»ºäº¤äº’å¼è™šæ‹Ÿè§’è‰²çš„è¿åŠ¨ç³»ç»Ÿï¼Œå…³é”®åœ¨äºå¼€å‘ä¸€ä¸ªç”Ÿæˆè¿åŠ¨æ¨¡å‹ï¼Œä½¿èº«ä½“èƒ½å¤Ÿä»¥æŒç»­ã€çœŸå®ã€å¯æ§å’Œå“åº”è¿…é€Ÿçš„æ–¹å¼åœ¨ä¸‰ç»´ç©ºé—´å†…ç§»åŠ¨ã€‚è™½ç„¶è¿åŠ¨ç”Ÿæˆå·²ç»å¾—åˆ°äº†å¹¿æ³›çš„ç ”ç©¶ï¼Œä½†å¤§å¤šæ•°æ–¹æ³•å¹¶ä¸æ”¯æŒâ€œåµŒå…¥æ™ºèƒ½â€ï¼Œå› ä¸ºå®ƒä»¬æ˜¯åœ¨ç¦»çº¿è®¾ç½®ä¸‹è¿è¡Œçš„ã€é€Ÿåº¦æ…¢ã€è¿åŠ¨é•¿åº¦æœ‰é™æˆ–ä¸è‡ªç„¶ã€‚ä¸ºäº†å…‹æœè¿™äº›å±€é™æ€§ï¼Œæˆ‘ä»¬æå‡ºäº†PRIMAï¼Œè¿™æ˜¯ä¸€ç§åŸºäºè‡ªå›å½’æ‰©æ•£æ¨¡å‹çš„ï¼Œå—åˆ°æœ€æ–°åŸºç¡€æ¨¡å‹å¯å‘çš„ä¸¤é˜¶æ®µå­¦ä¹ èŒƒå¼ã€‚åœ¨é¢„è®­ç»ƒé˜¶æ®µï¼Œæ¨¡å‹ä»å¤§é‡æ¬¡ç§’è¿åŠ¨ç‰‡æ®µä¸­å­¦ä¹ è¿åŠ¨åŠ¨åŠ›å­¦ï¼Œæä¾›â€œè¿åŠ¨åŸå§‹æ•°æ®â€ï¼Œä»ä¸­æ„å»ºæ›´å¤æ‚çš„è¿åŠ¨ã€‚åœ¨é€‚åº”é˜¶æ®µï¼Œæˆ‘ä»¬é‡‡ç”¨ç±»ä¼¼ControlNetçš„é€‚é…å™¨å¯¹è¿åŠ¨æ§åˆ¶è¿›è¡Œå¾®è°ƒï¼Œä»¥ç”Ÿæˆè¯­ä¹‰åŠ¨ä½œå’Œç›®æ ‡ç©ºé—´åˆ°è¾¾ã€‚å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„è®­ç»ƒäº§ç”Ÿäº†ç‰©ç†æ•ˆæœã€‚ç»™å®šå•å¸§åˆå§‹çŠ¶æ€ï¼Œæˆ‘ä»¬çš„æ¨¡å‹ä¸ä»…ç”Ÿæˆæ— ç•Œé™ã€çœŸå®å’Œå¯æ§çš„è¿åŠ¨ï¼Œè¿˜ä½¿è™šæ‹Ÿè§’è‰²èƒ½å¤Ÿå®æ—¶å“åº”äº§ç”Ÿçš„è„‰å†²ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å¯ä»¥æœ‰æ•ˆä¸”é«˜æ•ˆåœ°è°ƒæ•´æˆ‘ä»¬çš„åŸºç¡€æ¨¡å‹è¿›è¡Œä¸ªæ€§åŒ–åŠ¨ä½œå’Œå°‘é‡ç©ºé—´æ§åˆ¶ä»»åŠ¡ã€‚è¯„ä¼°è¡¨æ˜ï¼Œæˆ‘ä»¬æå‡ºçš„æ–¹æ³•ä¼˜äºæœ€æ–°çš„åŸºçº¿æ–¹æ³•ã€‚æˆ‘ä»¬åˆ©ç”¨è¯¥æ¨¡å‹åœ¨Unreal Engineä¸­åˆ›å»ºäº†ä¸€ä¸ªå®æ—¶è§’è‰²åŠ¨ç”»ç³»ç»Ÿï¼Œå…·æœ‰é«˜åº¦å“åº”æ€§å’Œè‡ªç„¶æ€§ã€‚ä»£ç ã€æ¨¡å‹å’Œæ›´å¤šç»“æœå¯åœ¨ï¼š<a target="_blank" rel="noopener" href="https://yz-cnsdqz.github.io/eigenmotion/PRIMA%E4%B8%8A%E6%89%BE%E5%88%B0%E3%80%82">https://yz-cnsdqz.github.io/eigenmotion/PRIMAä¸Šæ‰¾åˆ°ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.17544v1">PDF</a> 18 pages</p>
<p><strong>Summary</strong></p>
<p>è¯¥æ–‡ä»‹ç»äº†æ„å»ºäº¤äº’å¼è™šæ‹Ÿè§’è‰²çš„è¿åŠ¨ç³»ç»Ÿçš„é‡è¦æ€§ï¼Œå¹¶æŒ‡å‡ºä¼ ç»Ÿæ–¹æ³•å­˜åœ¨å±€é™æ€§ã€‚ä¸ºæ­¤ï¼Œæå‡ºäº†åŸºäºç”Ÿæˆæ‰©æ•£æ¨¡å‹çš„æ–°æ–¹æ³•PRIMALï¼ŒåŒ…å«é¢„è®­ç»ƒé˜¶æ®µå’Œè‡ªé€‚åº”é˜¶æ®µã€‚è¯¥æ¨¡å‹èƒ½ä»å¤§é‡æ¬¡ç§’çº§è¿åŠ¨ç‰‡æ®µä¸­å­¦ä¹ è¿åŠ¨åŠ¨åŠ›å­¦ï¼Œç”Ÿæˆå¤æ‚è¿åŠ¨ï¼Œå¹¶èƒ½å®æ—¶å“åº”å¤–éƒ¨åˆºæ¿€ã€‚åŒæ—¶ï¼Œè¯¥æ¨¡å‹è¿˜èƒ½é«˜æ•ˆé€‚åº”ä¸ªæ€§åŒ–åŠ¨ä½œå’Œç©ºé—´æ§åˆ¶ä»»åŠ¡ï¼Œä¼˜äºç°æœ‰æ–¹æ³•ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>äº¤äº’å¼è™šæ‹Ÿè§’è‰²çš„è¿åŠ¨ç³»ç»Ÿéœ€è¦èƒ½ç”ŸæˆæŒç»­ã€çœŸå®ã€å¯æ§å¹¶å“åº”å¤–éƒ¨åˆºæ¿€çš„åŠ¨æ€è¿åŠ¨ã€‚</li>
<li>ç°æœ‰æ–¹æ³•å­˜åœ¨ç¦»çº¿è®¾ç½®ã€é€Ÿåº¦æ…¢ã€è¿åŠ¨é•¿åº¦æœ‰é™æˆ–ä¸è‡ªç„¶ç­‰é—®é¢˜ï¼Œæ— æ³•å®ç°â€œå†…åœ¨æ™ºèƒ½â€ã€‚</li>
<li>æå‡ºæ–°æ–¹æ³•PRIMALï¼Œç»“åˆé¢„è®­ç»ƒé˜¶æ®µå’Œè‡ªé€‚åº”é˜¶æ®µï¼Œä»å¤§é‡è¿åŠ¨ç‰‡æ®µä¸­å­¦ä¹ è¿åŠ¨åŠ¨åŠ›å­¦ã€‚</li>
<li>é¢„è®­ç»ƒé˜¶æ®µæä¾›â€œè¿åŠ¨åŸè¯­â€ï¼Œæ„å»ºå¤æ‚è¿åŠ¨ï¼›è‡ªé€‚åº”é˜¶æ®µé€šè¿‡ControlNet-likeé€‚é…å™¨ç²¾ç»†è°ƒæ•´è¿åŠ¨æ§åˆ¶ï¼Œå®ç°è¯­ä¹‰åŠ¨ä½œç”Ÿæˆå’Œç©ºé—´ç›®æ ‡è¾¾æˆã€‚</li>
<li>æ¨¡å‹èƒ½ç”Ÿæˆæ— ç•Œé™ã€çœŸå®ã€å¯æ§çš„è¿åŠ¨ï¼Œå¹¶å®æ—¶å“åº”å¤–éƒ¨åˆºæ¿€ã€‚</li>
<li>æ¨¡å‹èƒ½é«˜æ•ˆé€‚åº”ä¸ªæ€§åŒ–åŠ¨ä½œå’Œç©ºé—´æ§åˆ¶ä»»åŠ¡ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.17544">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-8c8bdd85a621e48ac3dbb74013a19409.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-eedcaca66fc55810b870d4060e05c87f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-7fcc07537694a1362f3d1e8dba4f583f.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="TaoAvatar-Real-Time-Lifelike-Full-Body-Talking-Avatars-for-Augmented-Reality-via-3D-Gaussian-Splatting"><a href="#TaoAvatar-Real-Time-Lifelike-Full-Body-Talking-Avatars-for-Augmented-Reality-via-3D-Gaussian-Splatting" class="headerlink" title="TaoAvatar: Real-Time Lifelike Full-Body Talking Avatars for Augmented   Reality via 3D Gaussian Splatting"></a>TaoAvatar: Real-Time Lifelike Full-Body Talking Avatars for Augmented   Reality via 3D Gaussian Splatting</h2><p><strong>Authors:Jianchuan Chen, Jingchuan Hu, Gaige Wang, Zhonghua Jiang, Tiansong Zhou, Zhiwen Chen, Chengfei Lv</strong></p>
<p>Realistic 3D full-body talking avatars hold great potential in AR, with applications ranging from e-commerce live streaming to holographic communication. Despite advances in 3D Gaussian Splatting (3DGS) for lifelike avatar creation, existing methods struggle with fine-grained control of facial expressions and body movements in full-body talking tasks. Additionally, they often lack sufficient details and cannot run in real-time on mobile devices. We present TaoAvatar, a high-fidelity, lightweight, 3DGS-based full-body talking avatar driven by various signals. Our approach starts by creating a personalized clothed human parametric template that binds Gaussians to represent appearances. We then pre-train a StyleUnet-based network to handle complex pose-dependent non-rigid deformation, which can capture high-frequency appearance details but is too resource-intensive for mobile devices. To overcome this, we â€œbakeâ€ the non-rigid deformations into a lightweight MLP-based network using a distillation technique and develop blend shapes to compensate for details. Extensive experiments show that TaoAvatar achieves state-of-the-art rendering quality while running in real-time across various devices, maintaining 90 FPS on high-definition stereo devices such as the Apple Vision Pro. </p>
<blockquote>
<p>çœŸå®3Då…¨èº«å¯¹è¯è™šæ‹Ÿäººåœ¨å¢å¼ºç°å®é¢†åŸŸå…·æœ‰å·¨å¤§æ½œåŠ›ï¼Œåº”ç”¨èŒƒå›´ä»ç”µå­å•†åŠ¡ç›´æ’­åˆ°å…¨æ¯é€šä¿¡ã€‚å°½ç®¡åœ¨ç”¨äºåˆ›å»ºé€¼çœŸè™šæ‹Ÿäººçš„3Dé«˜æ–¯æ‹¼è´´ï¼ˆ3DGSï¼‰æŠ€æœ¯æ–¹é¢å–å¾—äº†è¿›å±•ï¼Œä½†ç°æœ‰æ–¹æ³•åœ¨å…¨èº«å¯¹è¯ä»»åŠ¡ä¸­çš„é¢éƒ¨è¡¨æƒ…å’Œèº«ä½“åŠ¨ä½œçš„ç²¾ç»†æ§åˆ¶æ–¹é¢ä»å­˜åœ¨å›°éš¾ã€‚æ­¤å¤–ï¼Œå®ƒä»¬é€šå¸¸ç¼ºä¹è¶³å¤Ÿçš„ç»†èŠ‚ï¼Œæ— æ³•åœ¨ç§»åŠ¨è®¾å¤‡ä¸Šå®æ—¶è¿è¡Œã€‚æˆ‘ä»¬æ¨å‡ºäº†TaoAvatarï¼Œä¸€ç§é«˜ä¿çœŸã€è½»é‡çº§çš„3DGSå…¨èº«å¯¹è¯è™šæ‹Ÿäººï¼Œç”±å„ç§ä¿¡å·é©±åŠ¨ã€‚æˆ‘ä»¬çš„æ–¹æ³•é¦–å…ˆåˆ›å»ºä¸€ä¸ªä¸ªæ€§åŒ–çš„ç©¿è¡£äººç±»å‚æ•°æ¨¡æ¿ï¼Œå°†é«˜æ–¯ç»‘å®šä»¥è¡¨ç¤ºå¤–è§‚ã€‚ç„¶åï¼Œæˆ‘ä»¬é¢„è®­ç»ƒä¸€ä¸ªåŸºäºStyleUnetçš„ç½‘ç»œæ¥å¤„ç†å¤æ‚çš„å§¿åŠ¿ç›¸å…³çš„éåˆšæ€§å˜å½¢ï¼Œè¯¥ç½‘ç»œèƒ½å¤Ÿæ•è·é«˜é¢‘å¤–è§‚ç»†èŠ‚ï¼Œä½†å¯¹äºç§»åŠ¨è®¾å¤‡æ¥è¯´èµ„æºè¿‡äºå¯†é›†ã€‚ä¸ºäº†å…‹æœè¿™ä¸€ç‚¹ï¼Œæˆ‘ä»¬ä½¿ç”¨è’¸é¦æŠ€æœ¯å°†éåˆšæ€§å˜å½¢â€œçƒ˜ç„™â€åˆ°åŸºäºMLPçš„è½»é‡çº§ç½‘ç»œä¸­ï¼Œå¹¶å¼€å‘æ··åˆå½¢çŠ¶æ¥è¡¥å¿ç»†èŠ‚ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼ŒTaoAvataråœ¨ä¿æŒå®æ—¶è¿è¡Œçš„åŒæ—¶å®ç°äº†æœ€å…ˆè¿›çš„æ¸²æŸ“è´¨é‡ï¼Œåœ¨å„ç§è®¾å¤‡ä¸Šéƒ½èƒ½ä¿æŒ90å¸§çš„å¸§ç‡ï¼Œå¦‚åœ¨è‹¹æœè§†ç•Œä¸“ä¸šç­‰é«˜åˆ†è¾¨ç‡ç«‹ä½“å£°è®¾å¤‡ä¸Šã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.17032v1">PDF</a> Accepted by CVPR 2025, project page:   <a target="_blank" rel="noopener" href="https://pixelai-team.github.io/TaoAvatar">https://PixelAI-Team.github.io/TaoAvatar</a></p>
<p><strong>Summary</strong>ï¼š</p>
<p>æœ¬æ–‡ä»‹ç»äº†åŸºäºå®æ—¶åŠ¨æ€ä¿¡å·çš„é€¼çœŸçš„å…¨èº«äº¤äº’å¼åŒ–èº«TaoAvatarçš„ç ”å‘ä¸åº”ç”¨ã€‚å®ƒé‡‡ç”¨äº†åˆ›æ–°çš„åŸºäº3Dé«˜æ–¯å›¾åƒå¹³é“ºæŠ€æœ¯æ¥åˆ›å»ºä¸ªæ€§åŒ–æ¨¡æ¿ï¼Œå¹¶é‡‡ç”¨é¢„è®­ç»ƒçš„StyleUnetç½‘ç»œå¤„ç†å¤æ‚å§¿æ€çš„éåˆšæ€§å˜å½¢ã€‚åŒæ—¶ï¼Œåˆ©ç”¨è’¸é¦æŠ€æœ¯ä¼˜åŒ–æ¨¡å‹ä»¥åœ¨ç§»åŠ¨è®¾å¤‡ä¸Šå®ç°å®æ—¶è¿è¡Œå’Œé«˜å¸§ç‡è¾“å‡ºã€‚</p>
<p><strong>Key Takeaways</strong>ï¼š</p>
<ol>
<li>TaoAvataræ˜¯åŸºäºå¢å¼ºç°å®æŠ€æœ¯çš„å…¨èº«äº¤äº’å¼åŒ–èº«ç³»ç»Ÿï¼Œå¯ç”¨äºç”µå•†ç›´æ’­å’Œå…¨æ¯é€šä¿¡ç­‰å¤šç§åº”ç”¨ã€‚</li>
<li>TaoAvataråˆ©ç”¨ä¸ªæ€§åŒ–çš„äººç±»å‚æ•°åŒ–æ¨¡æ¿åˆ›å»ºåŒ–èº«çš„å¤–è§‚ã€‚è¿™ç§æ¨¡å‹é‡‡ç”¨äº†å…ˆè¿›çš„å®æ—¶ä¿¡å·é©±åŠ¨æŠ€æœ¯ï¼Œæ”¯æŒé«˜åº¦çœŸå®çš„åŠ¨æ€è¡¨è¾¾å’Œè¿åŠ¨æ§åˆ¶ã€‚</li>
<li>é‡‡ç”¨StyleUnetç½‘ç»œå¤„ç†å¤æ‚çš„å§¿æ€ä¾èµ–çš„éåˆšæ€§å˜å½¢ï¼Œèƒ½å¤Ÿæ•æ‰é«˜é¢‘ç‡çš„å¤–è§‚ç»†èŠ‚ã€‚ç„¶è€Œï¼Œè¯¥ç½‘ç»œåœ¨ç§»åŠ¨è®¾å¤‡ä¸Šçš„èµ„æºæ¶ˆè€—è¾ƒå¤§ã€‚</li>
<li>ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œé‡‡ç”¨äº†è’¸é¦æŠ€æœ¯æ¥â€œçƒ˜ç„™â€éåˆšæ€§å˜å½¢æ•°æ®ï¼Œå¹¶åˆ©ç”¨ç¥ç»ç½‘ç»œæ¨ç†è½»é‡åŒ–æ–¹æ³•ä½¿å…¶åœ¨ç§»åŠ¨è®¾å¤‡ä¸Šè¿›è¡Œå®æ—¶è¿è¡Œæˆä¸ºå¯èƒ½ã€‚æ­¤å¤–ï¼Œè¿˜å¼€å‘äº†è¡¥å¿ç»†èŠ‚çš„æ··åˆå½¢çŠ¶æŠ€æœ¯ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.17032">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-d251751954528217baa3a66e8a790fbb.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-2df1e3379d1a25574bbd5482acac7dd0.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c4577a665cc5fa624c1edd48d3f87970.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="Zero-1-to-A-Zero-Shot-One-Image-to-Animatable-Head-Avatars-Using-Video-Diffusion"><a href="#Zero-1-to-A-Zero-Shot-One-Image-to-Animatable-Head-Avatars-Using-Video-Diffusion" class="headerlink" title="Zero-1-to-A: Zero-Shot One Image to Animatable Head Avatars Using Video   Diffusion"></a>Zero-1-to-A: Zero-Shot One Image to Animatable Head Avatars Using Video   Diffusion</h2><p><strong>Authors:Zhenglin Zhou, Fan Ma, Hehe Fan, Tat-Seng Chua</strong></p>
<p>Animatable head avatar generation typically requires extensive data for training. To reduce the data requirements, a natural solution is to leverage existing data-free static avatar generation methods, such as pre-trained diffusion models with score distillation sampling (SDS), which align avatars with pseudo ground-truth outputs from the diffusion model. However, directly distilling 4D avatars from video diffusion often leads to over-smooth results due to spatial and temporal inconsistencies in the generated video. To address this issue, we propose Zero-1-to-A, a robust method that synthesizes a spatial and temporal consistency dataset for 4D avatar reconstruction using the video diffusion model. Specifically, Zero-1-to-A iteratively constructs video datasets and optimizes animatable avatars in a progressive manner, ensuring that avatar quality increases smoothly and consistently throughout the learning process. This progressive learning involves two stages: (1) Spatial Consistency Learning fixes expressions and learns from front-to-side views, and (2) Temporal Consistency Learning fixes views and learns from relaxed to exaggerated expressions, generating 4D avatars in a simple-to-complex manner. Extensive experiments demonstrate that Zero-1-to-A improves fidelity, animation quality, and rendering speed compared to existing diffusion-based methods, providing a solution for lifelike avatar creation. Code is publicly available at: <a target="_blank" rel="noopener" href="https://github.com/ZhenglinZhou/Zero-1-to-A">https://github.com/ZhenglinZhou/Zero-1-to-A</a>. </p>
<blockquote>
<p>åŠ¨ç”»å¤´åƒç”Ÿæˆé€šå¸¸éœ€è¦å¤§é‡çš„æ•°æ®è¿›è¡Œè®­ç»ƒã€‚ä¸ºäº†å‡å°‘æ•°æ®éœ€æ±‚ï¼Œä¸€ç§è‡ªç„¶çš„è§£å†³æ–¹æ¡ˆæ˜¯åˆ©ç”¨æ— æ•°æ®çš„é™æ€å¤´åƒç”Ÿæˆæ–¹æ³•ï¼Œä¾‹å¦‚ä½¿ç”¨å¸¦æœ‰å¾—åˆ†è’¸é¦é‡‡æ ·ï¼ˆSDSï¼‰çš„é¢„è®­ç»ƒæ‰©æ•£æ¨¡å‹ï¼Œå°†å¤´åƒä¸æ‰©æ•£æ¨¡å‹çš„ä¼ªåœ°é¢çœŸå®è¾“å‡ºå¯¹é½ã€‚ç„¶è€Œï¼Œç›´æ¥ä»è§†é¢‘æ‰©æ•£ä¸­æå–4Då¤´åƒå¾€å¾€ä¼šå¯¼è‡´ç»“æœè¿‡äºå¹³æ»‘ï¼Œè¿™æ˜¯ç”±äºç”Ÿæˆè§†é¢‘çš„ç©ºé—´å’Œæ—¶é—´ä¸ä¸€è‡´æ€§æ‰€è‡´ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†Zero-1-to-Aæ–¹æ³•ï¼Œè¿™æ˜¯ä¸€ç§ä½¿ç”¨è§†é¢‘æ‰©æ•£æ¨¡å‹ä¸º4Då¤´åƒé‡å»ºåˆæˆç©ºé—´å’Œæ—¶é—´ä¸€è‡´æ€§æ•°æ®é›†çš„æœ‰æ•ˆæ–¹æ³•ã€‚å…·ä½“æ¥è¯´ï¼ŒZero-1-to-Aé€šè¿‡è¿­ä»£æ„å»ºè§†é¢‘æ•°æ®é›†å’Œä»¥æ¸è¿›çš„æ–¹å¼ä¼˜åŒ–åŠ¨ç”»å¤´åƒï¼Œç¡®ä¿åœ¨å­¦ä¹ è¿‡ç¨‹ä¸­å¤´åƒè´¨é‡å¹³ç¨³ä¸”ä¸€è‡´åœ°æé«˜ã€‚è¿™ç§æ¸è¿›å­¦ä¹ æ¶‰åŠä¸¤ä¸ªé˜¶æ®µï¼šï¼ˆ1ï¼‰ç©ºé—´ä¸€è‡´æ€§å­¦ä¹ ä¿®æ­£è¡¨æƒ…å¹¶ä»æ­£é¢åˆ°ä¾§é¢è¿›è¡Œå­¦ä¹ ï¼›ï¼ˆ2ï¼‰æ—¶é—´ä¸€è‡´æ€§å­¦ä¹ ä¿®æ­£è§†å›¾ï¼Œå¹¶ä»è½»æ¾åˆ°å¤¸å¼ çš„è¡¨æƒ…è¿›è¡Œå­¦ä¹ ï¼Œä»¥ç®€å•åˆ°å¤æ‚çš„æ–¹å¼ç”Ÿæˆ4Då¤´åƒã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼Œä¸ç°æœ‰çš„æ‰©æ•£æ–¹æ³•ç›¸æ¯”ï¼ŒZero-1-to-Aæé«˜äº†ä¿çœŸåº¦ã€åŠ¨ç”»è´¨é‡å’Œæ¸²æŸ“é€Ÿåº¦ï¼Œä¸ºé€¼çœŸå¤´åƒçš„åˆ›ä½œæä¾›äº†è§£å†³æ–¹æ¡ˆã€‚ä»£ç å…¬å¼€å¯ç”¨ï¼š<a target="_blank" rel="noopener" href="https://github.com/ZhenglinZhou/Zero-1-to-A%E3%80%82">https://github.com/ZhenglinZhou/Zero-1-to-Aã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.15851v2">PDF</a> Accepted by CVPR 2025, project page:   <a target="_blank" rel="noopener" href="https://zhenglinzhou.github.io/Zero-1-to-A/">https://zhenglinzhou.github.io/Zero-1-to-A/</a></p>
<p><strong>Summary</strong><br>åŠ¨ç”»å¤´åƒç”Ÿæˆé€šå¸¸éœ€è¦å¤§é‡æ•°æ®è¿›è¡Œè®­ç»ƒã€‚ä¸ºå‡å°‘æ•°æ®éœ€æ±‚ï¼Œå¯åˆ©ç”¨æ— éœ€æ•°æ®çš„é™æ€å¤´åƒç”Ÿæˆæ–¹æ³•ï¼Œå¦‚é¢„è®­ç»ƒçš„æ‰©æ•£æ¨¡å‹ä¸è¯„åˆ†è’¸é¦é‡‡æ ·ï¼ˆSDSï¼‰ã€‚ç„¶è€Œï¼Œç›´æ¥ä»è§†é¢‘æ‰©æ•£ä¸­è’¸é¦å››ç»´å¤´åƒå¾€å¾€ä¼šå¯¼è‡´ç»“æœè¿‡äºå¹³æ»‘ï¼Œå› ä¸ºç”Ÿæˆè§†é¢‘çš„ç©ºé—´å’Œæ—¶é—´ä¸ä¸€è‡´æ€§ã€‚ä¸ºè§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºZero-1-to-Aæ–¹æ³•ï¼Œåˆ©ç”¨è§†é¢‘æ‰©æ•£æ¨¡å‹åˆæˆä¸€ä¸ªå…·æœ‰ç©ºé—´å’Œæ—¶é—´ä¸€è‡´æ€§çš„æ•°æ®é›†ï¼Œç”¨äºå››ç»´å¤´åƒé‡å»ºã€‚è¯¥æ–¹æ³•é€šè¿‡ä¸¤ä¸ªé˜¶æ®µçš„æ¸è¿›å­¦ä¹ ï¼Œç¡®ä¿å¤´åƒè´¨é‡åœ¨å­¦ä¹ è¿‡ç¨‹ä¸­å¹³ç¨³æé«˜ã€‚é¦–å…ˆæ˜¯ç©ºé—´ä¸€è‡´æ€§å­¦ä¹ ï¼Œä¿®å¤è¡¨æƒ…å¹¶ä»æ­£é¢åˆ°ä¾§é¢è¿›è¡Œå­¦ä¹ ï¼›ç„¶åæ˜¯æ—¶é—´ä¸€è‡´æ€§å­¦ä¹ ï¼Œä¿®å¤è§†è§’å¹¶ä»è½»æ¾åˆ°å¤¸å¼ çš„è¡¨æƒ…è¿›è¡Œå­¦ä¹ ï¼Œä»¥ç®€å•åˆ°å¤æ‚çš„æ–¹å¼ç”Ÿæˆå››ç»´å¤´åƒã€‚å®éªŒè¡¨æ˜ï¼ŒZero-1-to-Aæé«˜äº†ä¿çœŸåº¦ã€åŠ¨ç”»è´¨é‡å’Œæ¸²æŸ“é€Ÿåº¦ï¼Œä¸ºåˆ›å»ºé€¼çœŸçš„å¤´åƒæä¾›äº†è§£å†³æ–¹æ¡ˆã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>åŠ¨ç”»å¤´åƒç”Ÿæˆéœ€è¦å¤§æ•°æ®è®­ç»ƒï¼Œä¸ºé™ä½æ•°æ®éœ€æ±‚ï¼Œå¯åˆ©ç”¨é¢„è®­ç»ƒçš„æ‰©æ•£æ¨¡å‹ä¸è¯„åˆ†è’¸é¦é‡‡æ ·æ–¹æ³•ã€‚</li>
<li>ç›´æ¥ä»è§†é¢‘æ‰©æ•£ä¸­è’¸é¦å››ç»´å¤´åƒä¼šå¯¼è‡´ç»“æœè¿‡äºå¹³æ»‘ï¼Œå› ä¸ºç”Ÿæˆè§†é¢‘çš„ç©ºé—´å’Œæ—¶é—´ä¸ä¸€è‡´æ€§ã€‚</li>
<li>æå‡ºZero-1-to-Aæ–¹æ³•ï¼Œé€šè¿‡åˆæˆå…·æœ‰ç©ºé—´å’Œæ—¶é—´ä¸€è‡´æ€§çš„æ•°æ®é›†æ¥è§£å†³è¿™ä¸€é—®é¢˜ã€‚</li>
<li>Zero-1-to-Aæ–¹æ³•åŒ…å«ä¸¤ä¸ªé˜¶æ®µçš„æ¸è¿›å­¦ä¹ ï¼šç©ºé—´ä¸€è‡´æ€§å­¦ä¹ å’Œæ—¶é—´ä¸€è‡´æ€§å­¦ä¹ ã€‚</li>
<li>ç©ºé—´ä¸€è‡´æ€§å­¦ä¹ ä¿®å¤è¡¨æƒ…å¹¶ä»å¤šä¸ªè§†è§’è¿›è¡Œå­¦ä¹ ã€‚</li>
<li>æ—¶é—´ä¸€è‡´æ€§å­¦ä¹ ä¿®å¤è§†è§’å¹¶ä»è½»æ¾åˆ°å¤¸å¼ çš„è¡¨æƒ…è¿›è¡Œå­¦ä¹ ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.15851">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-889ba6b8561d8798337888041dfec83f.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-6c8fa53fbb67d29bd26cbfeb828bbe38.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e4ed3c6d3226799ea29effeea1e08026.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-eaf227b3f992180d2c1323c604b51faf.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-5e2d345abf801aa153315e356a0621cf.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-09c158b16e0da087d0d59d8845641733.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="FATE-Full-head-Gaussian-Avatar-with-Textural-Editing-from-Monocular-Video"><a href="#FATE-Full-head-Gaussian-Avatar-with-Textural-Editing-from-Monocular-Video" class="headerlink" title="FATE: Full-head Gaussian Avatar with Textural Editing from Monocular   Video"></a>FATE: Full-head Gaussian Avatar with Textural Editing from Monocular   Video</h2><p><strong>Authors:Jiawei Zhang, Zijian Wu, Zhiyang Liang, Yicheng Gong, Dongfang Hu, Yao Yao, Xun Cao, Hao Zhu</strong></p>
<p>Reconstructing high-fidelity, animatable 3D head avatars from effortlessly captured monocular videos is a pivotal yet formidable challenge. Although significant progress has been made in rendering performance and manipulation capabilities, notable challenges remain, including incomplete reconstruction and inefficient Gaussian representation. To address these challenges, we introduce FATE, a novel method for reconstructing an editable full-head avatar from a single monocular video. FATE integrates a sampling-based densification strategy to ensure optimal positional distribution of points, improving rendering efficiency. A neural baking technique is introduced to convert discrete Gaussian representations into continuous attribute maps, facilitating intuitive appearance editing. Furthermore, we propose a universal completion framework to recover non-frontal appearance, culminating in a 360$^\circ$-renderable 3D head avatar. FATE outperforms previous approaches in both qualitative and quantitative evaluations, achieving state-of-the-art performance. To the best of our knowledge, FATE is the first animatable and 360$^\circ$ full-head monocular reconstruction method for a 3D head avatar. </p>
<blockquote>
<p>ä»è½»æ¾æ•è·çš„å•ç›®è§†é¢‘ä¸­é‡å»ºé«˜ä¿çœŸã€å¯åŠ¨ç”»çš„3Då¤´åƒæ˜¯ä¸€é¡¹è‡³å…³é‡è¦ä½†è‰°å·¨çš„æŒ‘æˆ˜ã€‚è™½ç„¶åœ¨æ¸²æŸ“æ€§èƒ½å’Œæ“ä½œåŠŸèƒ½ä¸Šå–å¾—äº†æ˜¾è‘—è¿›å±•ï¼Œä½†ä»å­˜åœ¨æ˜¾è‘—æŒ‘æˆ˜ï¼ŒåŒ…æ‹¬é‡å»ºä¸å®Œæ•´å’Œé«˜æ–¯è¡¨ç¤ºæ•ˆç‡ä½ä¸‹ã€‚ä¸ºäº†è§£å†³è¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬å¼•å…¥äº†FATEï¼Œè¿™æ˜¯ä¸€ç§ä»å•ç›®è§†é¢‘é‡å»ºå¯ç¼–è¾‘çš„å…¨å¤´åƒçš„æ–°æ–¹æ³•ã€‚FATEé‡‡ç”¨åŸºäºé‡‡æ ·çš„å¯†é›†åŒ–ç­–ç•¥ï¼Œç¡®ä¿ç‚¹çš„æœ€ä¼˜ä½ç½®åˆ†å¸ƒï¼Œæé«˜æ¸²æŸ“æ•ˆç‡ã€‚å¼•å…¥äº†ä¸€ç§ç¥ç»çƒ˜ç„™æŠ€æœ¯ï¼Œå°†ç¦»æ•£é«˜æ–¯è¡¨ç¤ºè½¬æ¢ä¸ºè¿ç»­å±æ€§å›¾ï¼Œä¾¿äºç›´è§‚çš„å¤–è²Œç¼–è¾‘ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªé€šç”¨çš„å®Œæˆæ¡†æ¶ï¼Œä»¥æ¢å¤éæ­£é¢çš„å¤–è§‚ï¼Œæœ€ç»ˆç”Ÿæˆä¸€ä¸ªå¯æ—‹è½¬360åº¦çš„3Då¤´åƒã€‚FATEåœ¨å®šæ€§å’Œå®šé‡è¯„ä¼°ä¸­éƒ½ä¼˜äºä»¥å‰çš„æ–¹æ³•ï¼Œè¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚æ®æˆ‘ä»¬æ‰€çŸ¥ï¼ŒFATEæ˜¯ç¬¬ä¸€ä¸ªå¯ç”¨äº3Då¤´åƒçš„å¯åŠ¨ç”»å’Œ360åº¦å…¨å¤´å•ç›®é‡å»ºæ–¹æ³•ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2411.15604v2">PDF</a> Accepted by CVPR2025</p>
<p><strong>Summary</strong><br>æ–°ä¸€ä»£ä¸‰ç»´å¤´åƒé‡å»ºæŠ€æœ¯çªç ´ï¼šå•ç›®è§†é¢‘æ•æ‰ï¼Œå…¨å¤´å¯ç¼–è¾‘ã€‚é‡‡ç”¨é‡‡æ ·åŠ å¯†ç­–ç•¥ä¼˜åŒ–ç‚¹åˆ†å¸ƒï¼Œæå‡æ¸²æŸ“æ•ˆç‡ï¼›å¼•å…¥ç¥ç»ç½‘ç»œçƒ˜ç„™æŠ€æœ¯ï¼Œå°†ç¦»æ•£é«˜æ–¯è¡¨ç¤ºè½¬ä¸ºè¿ç»­å±æ€§å›¾ï¼Œä¾¿äºç›´è§‚ç¼–è¾‘å¤–è§‚ï¼›æå‡ºé€šç”¨è¡¥å…¨æ¡†æ¶ï¼Œå®ç°éæ­£é¢è§†è§’çš„æ¸²æŸ“ï¼Œç”Ÿæˆ360Â°å¯æ¸²æŸ“çš„ä¸‰ç»´å¤´åƒã€‚FATEæŠ€æœ¯è¶…è¶Šç°æœ‰æ–¹æ³•ï¼Œè¾¾åˆ°é¢†å…ˆæ°´å¹³ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>FATEæŠ€æœ¯èƒ½å¤Ÿä»å•ç›®è§†é¢‘ä¸­é‡å»ºå‡ºå¯ç¼–è¾‘çš„å…¨å¤´ä¸‰ç»´å¤´åƒã€‚</li>
<li>é‡‡ç”¨é‡‡æ ·åŠ å¯†ç­–ç•¥ä¼˜åŒ–ç‚¹çš„ä½ç½®åˆ†å¸ƒï¼Œæå‡æ¸²æŸ“æ•ˆç‡ã€‚</li>
<li>å¼•å…¥ç¥ç»ç½‘ç»œçƒ˜ç„™æŠ€æœ¯ï¼Œå°†ç¦»æ•£çš„é«˜æ–¯è¡¨ç¤ºè½¬æ¢ä¸ºè¿ç»­å±æ€§å›¾ã€‚</li>
<li>æå‡ºé€šç”¨è¡¥å…¨æ¡†æ¶ï¼Œç”¨äºæ¢å¤éæ­£é¢å¤–è§‚ã€‚</li>
<li>ç”Ÿæˆçš„ä¸‰ç»´å¤´åƒå¯ä»¥å®ç°360Â°æ¸²æŸ“ã€‚</li>
<li>FATEæŠ€æœ¯åœ¨å®šæ€§å’Œå®šé‡è¯„ä¼°ä¸­éƒ½è¡¨ç°å‡ºå“è¶Šæ€§èƒ½ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2411.15604">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-762ffc6d3524f07643c5163ad7e8e450.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-879e62672c6d79d7958155c83d8035cd.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-638e4da3a27fb816a2fe5756d53c7640.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-1d44a0d4c901f3f7637fe47d08cd19ff.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-42889ad0ecb43422d5d1a508e2e21d98.jpg" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-03-27/%E5%85%83%E5%AE%87%E5%AE%99_%E8%99%9A%E6%8B%9F%E4%BA%BA/">https://kedreamix.github.io/Talk2Paper/Paper/2025-03-27/%E5%85%83%E5%AE%87%E5%AE%99_%E8%99%9A%E6%8B%9F%E4%BA%BA/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/%E5%85%83%E5%AE%87%E5%AE%99-%E8%99%9A%E6%8B%9F%E4%BA%BA/">
                                    <span class="chip bg-color">å…ƒå®‡å®™/è™šæ‹Ÿäºº</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-03-27/3DGS/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-952d00c55fe995e0feab67eb01a3ecc7.jpg" class="responsive-img" alt="3DGS">
                        
                        <span class="card-title">3DGS</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            3DGS æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-03-27  PartRM Modeling Part-Level Dynamics with Large Cross-State   Reconstruction Model
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-03-27
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/3DGS/" class="post-category">
                                    3DGS
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/3DGS/">
                        <span class="chip bg-color">3DGS</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-03-27/GAN/">
                    <div class="card-image">
                        
                        <img src="https://pica.zhimg.com/v2-c44b9fac00940094057255e461b9d913.jpg" class="responsive-img" alt="GAN">
                        
                        <span class="card-title">GAN</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            GAN æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-03-27  AvatarArtist Open-Domain 4D Avatarization
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-03-27
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/GAN/" class="post-category">
                                    GAN
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/GAN/">
                        <span class="chip bg-color">GAN</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">30166.1k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
