<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="TTS">
    <meta name="description" content="TTS 方向最新论文已更新，请持续关注 Update in 2025-03-27  Video-T1 Test-Time Scaling for Video Generation">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>TTS | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loader页面消失采用渐隐的方式*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logo出现动画 */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//使用渐隐的方法淡出loading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//强制显示loading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">嘘~  正在从服务器偷取页面 . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>首页</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>标签</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>分类</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>归档</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="搜索" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="深色/浅色模式" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			首页
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			标签
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			分类
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			归档
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://pica.zhimg.com/v2-2b752877c656c637f4afd3a3af12614f.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">TTS</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/TTS/">
                                <span class="chip bg-color">TTS</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/TTS/" class="post-category">
                                TTS
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2025-03-27
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>更新日期:&nbsp;&nbsp;
                    2025-05-14
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp;
                    5.8k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp;
                    23 分
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>阅读次数:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>⚠️ 以下所有内容总结都来自于 大语言模型的能力，如有错误，仅供参考，谨慎使用<br>🔴 请注意：千万不要用于严肃的学术场景，只能用于论文阅读前的初筛！<br>💗 如果您觉得我们的项目对您有帮助 <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ，还请您给我们一些鼓励！⭐️ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFace免费体验</a></p>
</blockquote>
<h1 id="2025-03-27-更新"><a href="#2025-03-27-更新" class="headerlink" title="2025-03-27 更新"></a>2025-03-27 更新</h1><h2 id="Video-T1-Test-Time-Scaling-for-Video-Generation"><a href="#Video-T1-Test-Time-Scaling-for-Video-Generation" class="headerlink" title="Video-T1: Test-Time Scaling for Video Generation"></a>Video-T1: Test-Time Scaling for Video Generation</h2><p><strong>Authors:Fangfu Liu, Hanyang Wang, Yimo Cai, Kaiyan Zhang, Xiaohang Zhan, Yueqi Duan</strong></p>
<p>With the scale capability of increasing training data, model size, and computational cost, video generation has achieved impressive results in digital creation, enabling users to express creativity across various domains. Recently, researchers in Large Language Models (LLMs) have expanded the scaling to test-time, which can significantly improve LLM performance by using more inference-time computation. Instead of scaling up video foundation models through expensive training costs, we explore the power of Test-Time Scaling (TTS) in video generation, aiming to answer the question: if a video generation model is allowed to use non-trivial amount of inference-time compute, how much can it improve generation quality given a challenging text prompt. In this work, we reinterpret the test-time scaling of video generation as a searching problem to sample better trajectories from Gaussian noise space to the target video distribution. Specifically, we build the search space with test-time verifiers to provide feedback and heuristic algorithms to guide searching process. Given a text prompt, we first explore an intuitive linear search strategy by increasing noise candidates at inference time. As full-step denoising all frames simultaneously requires heavy test-time computation costs, we further design a more efficient TTS method for video generation called Tree-of-Frames (ToF) that adaptively expands and prunes video branches in an autoregressive manner. Extensive experiments on text-conditioned video generation benchmarks demonstrate that increasing test-time compute consistently leads to significant improvements in the quality of videos. Project page: <a target="_blank" rel="noopener" href="https://liuff19.github.io/Video-T1">https://liuff19.github.io/Video-T1</a> </p>
<blockquote>
<p>随着训练数据、模型规模和计算成本的规模能力不断提升，视频生成在数字创作中取得了令人印象深刻的结果，使用户能够在各种领域表达创造力。最近，大型语言模型（LLM）的研究人员将规模扩展到了测试阶段，通过增加推理时间计算来显著提高LLM的性能。我们并不通过昂贵的训练成本来扩大视频基础模型的规模，而是探索视频生成中测试时间缩放（TTS）的力量，旨在回答一个问题：如果视频生成模型允许使用非微不足道的推理时间计算量，那么在具有挑战性的文本提示下，它能提高多少生成质量。在这项工作中，我们将视频生成的测试时间缩放重新解释为搜索问题，从高斯噪声空间更好地采样轨迹以到达目标视频分布。具体来说，我们构建了具有测试时间验证器的搜索空间来提供反馈和启发式算法来指导搜索过程。给定一个文本提示，我们首先探索一种直观的线性搜索策略，通过增加推理时间时的噪声候选者来进行。由于同时完全去噪所有帧需要大量的测试时间计算成本，我们进一步为视频生成设计了一种更有效的TTS方法，称为“帧树”（ToF），该方法以自回归的方式自适应地扩展和修剪视频分支。在文本条件视频生成基准测试上的大量实验表明，增加测试时间计算始终导致视频质量显著提高。项目页面：<a target="_blank" rel="noopener" href="https://liuff19.github.io/Video-T1">链接</a>。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.18942v1">PDF</a> Project page: <a target="_blank" rel="noopener" href="https://liuff19.github.io/Video-T1">https://liuff19.github.io/Video-T1</a></p>
<p><strong>Summary</strong><br>     近期研究在视频生成领域应用测试时扩展（TTS）方法，允许模型在推理阶段使用更多计算资源以提高生成质量。本研究将视频生成的测试时扩展重新解释为搜索问题，通过构建搜索空间并利用启发式算法指导搜索过程。通过直观线性搜索策略和高效Tree-of-Frames（ToF）方法，实验证明增加推理阶段计算资源可有效提升视频生成质量。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>视频生成领域通过增加训练数据、模型规模和计算成本，实现了令人印象深刻的数字创作能力。</li>
<li>测试时扩展（TTS）在大型语言模型（LLMs）中的应用可以显著提高LLM性能。</li>
<li>本研究将视频生成的测试时扩展解释为搜索问题，旨在通过增加推理时间计算来提高生成质量。</li>
<li>构建搜索空间，利用测试时验证器提供反馈和启发式算法指导搜索过程。</li>
<li>提出一种直观的线性搜索策略，通过增加噪声候选在推理阶段改进视频生成。</li>
<li>提出Tree-of-Frames（ToF）方法，以自适应地扩展和修剪视频分支，实现高效视频生成。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.18942">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-d085a882f8cb1838f8995bb917bfc436.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-28be37f548465dcd999e72bc35a1c779.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-0c4a0c05cfe09784628b432f623b46e0.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-a2b953663ed9e3786e93e03e40258889.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="From-Faces-to-Voices-Learning-Hierarchical-Representations-for-High-quality-Video-to-Speech"><a href="#From-Faces-to-Voices-Learning-Hierarchical-Representations-for-High-quality-Video-to-Speech" class="headerlink" title="From Faces to Voices: Learning Hierarchical Representations for   High-quality Video-to-Speech"></a>From Faces to Voices: Learning Hierarchical Representations for   High-quality Video-to-Speech</h2><p><strong>Authors:Ji-Hoon Kim, Jeongsoo Choi, Jaehun Kim, Chaeyoung Jung, Joon Son Chung</strong></p>
<p>The objective of this study is to generate high-quality speech from silent talking face videos, a task also known as video-to-speech synthesis. A significant challenge in video-to-speech synthesis lies in the substantial modality gap between silent video and multi-faceted speech. In this paper, we propose a novel video-to-speech system that effectively bridges this modality gap, significantly enhancing the quality of synthesized speech. This is achieved by learning of hierarchical representations from video to speech. Specifically, we gradually transform silent video into acoustic feature spaces through three sequential stages – content, timbre, and prosody modeling. In each stage, we align visual factors – lip movements, face identity, and facial expressions – with corresponding acoustic counterparts to ensure the seamless transformation. Additionally, to generate realistic and coherent speech from the visual representations, we employ a flow matching model that estimates direct trajectories from a simple prior distribution to the target speech distribution. Extensive experiments demonstrate that our method achieves exceptional generation quality comparable to real utterances, outperforming existing methods by a significant margin. </p>
<blockquote>
<p>本文的研究目标是从无声的对话视频生成高质量语音，这一任务也被称为视频到语音的合成。视频到语音合成面临的一个重大挑战是无声视频和多面语音之间存在的巨大模态差距。在本文中，我们提出了一种新型的视频到语音系统，该系统有效地弥合了这种模态差距，大大提高了合成语音的质量。这是通过学习从视频到语音的分层表示来实现的。具体来说，我们通过三个阶段——内容、音色和语调建模，逐步将无声视频转换为声音特征空间。在每个阶段，我们将视觉因素（如嘴唇动作、面部身份和面部表情）与相应的声音因素进行对齐，以确保无缝转换。此外，为了从视觉表示生成真实且连贯的语音，我们采用了一种流动匹配模型，该模型从简单的先验分布估计到目标语音分布的直接轨迹。大量实验表明，我们的方法达到了与真实话语相当的生成质量，显著优于现有方法。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.16956v1">PDF</a> CVPR 2025, demo page: <a target="_blank" rel="noopener" href="https://mm.kaist.ac.kr/projects/faces2voices/">https://mm.kaist.ac.kr/projects/faces2voices/</a></p>
<p><strong>Summary</strong><br>高质量视频转语音合成研究，旨在从无声面部视频生成高质量语音。该研究面临的主要挑战在于视频和语音之间的模态差距。该研究提出了一种新的视频转语音系统，通过从视频到语音学习层次表示来有效弥合这一模态差距，显著提高合成语音的质量。具体通过内容、音质和韵律建模三个阶段逐步将无声视频转换为声音特征空间，并在每个阶段将视觉因素（如嘴唇动作、面部身份和面部表情）与相应的声音特征进行对齐，以确保无缝转换。此外，为了从视觉表示生成真实且连贯的语音，该研究采用了一种流量匹配模型，该模型可从简单先验分布估计到目标语音分布的直接轨迹。实验表明，该方法达到了与真实语音相比的出色生成质量，并大幅度超越了现有方法。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>研究旨在实现高质量的视频转语音合成，即从不说话的面部视频生成逼真的语音。</li>
<li>研究的挑战在于处理视频和语音之间存在的模态差距。</li>
<li>提出了一种新的视频转语音系统，通过层次表示学习来弥合模态差距，进而提高合成语音质量。</li>
<li>系统设计包括三个主要阶段：内容建模、音质建模和韵律建模，将无声视频逐步转化为声音特征空间。</li>
<li>在每个阶段，研究通过视觉因素（如嘴唇动作、面部身份和面部表情）与声音特征的精确对齐来实现无缝转换。</li>
<li>采用流量匹配模型生成真实且连贯的语音，该模型可从简单先验分布估计到目标语音分布的直接轨迹。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.16956">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-cde97e2ffe93194b9c3831c7794a6585.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-3b4e74c7247e36b83834c10b69bfc1c1.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-243c863070db1aed085e4ec0c3daf6ab.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-dab6905813082bb76130317c6986d512.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="VocalEyes-Enhancing-Environmental-Perception-for-the-Visually-Impaired-through-Vision-Language-Models-and-Distance-Aware-Object-Detection"><a href="#VocalEyes-Enhancing-Environmental-Perception-for-the-Visually-Impaired-through-Vision-Language-Models-and-Distance-Aware-Object-Detection" class="headerlink" title="VocalEyes: Enhancing Environmental Perception for the Visually Impaired   through Vision-Language Models and Distance-Aware Object Detection"></a>VocalEyes: Enhancing Environmental Perception for the Visually Impaired   through Vision-Language Models and Distance-Aware Object Detection</h2><p><strong>Authors:Kunal Chavan, Keertan Balaji, Spoorti Barigidad, Samba Raju Chiluveru</strong></p>
<p>With an increasing demand for assistive technologies that promote the independence and mobility of visually impaired people, this study suggests an innovative real-time system that gives audio descriptions of a user’s surroundings to improve situational awareness. The system acquires live video input and processes it with a quantized and fine-tuned Florence-2 big model, adjusted to 4-bit accuracy for efficient operation on low-power edge devices such as the NVIDIA Jetson Orin Nano. By transforming the video signal into frames with a 5-frame latency, the model provides rapid and contextually pertinent descriptions of objects, pedestrians, and barriers, together with their estimated distances. The system employs Parler TTS Mini, a lightweight and adaptable Text-to-Speech (TTS) solution, for efficient audio feedback. It accommodates 34 distinct speaker types and enables customization of speech tone, pace, and style to suit user requirements. This study examines the quantization and fine-tuning techniques utilized to modify the Florence-2 model for this application, illustrating how the integration of a compact model architecture with a versatile TTS component improves real-time performance and user experience. The proposed system is assessed based on its accuracy, efficiency, and usefulness, providing a viable option to aid vision-impaired users in navigating their surroundings securely and successfully. </p>
<blockquote>
<p>随着促进视力障碍者独立性和移动性的辅助技术需求不断增加，本研究提出了一种创新性的实时系统，该系统为用户提供周围环境的音频描述，以提高情境意识。该系统获取实时视频输入，并使用经过量化和精细调整的Florence-2大型模型进行处理，以4位精度调整，可在低功耗边缘设备上高效运行，例如NVIDIA Jetson Orin Nano。通过将视频信号转换为具有5帧延迟的帧，该模型迅速提供与上下文相关的物体、行人和障碍物的描述，以及它们的估计距离。系统采用轻量级、适应性强的Parler TTS Mini文本到语音（TTS）解决方案，提供高效音频反馈。它容纳了34种不同的扬声器类型，并可根据用户需求定制语音语调、语速和风格。本研究探讨了用于此应用程序的量化和微调技术，说明了紧凑模型架构与通用TTS组件的集成如何提高实时性能和用户体验。所提议的系统基于其准确性、效率和实用性进行评估，为视力受损用户提供了一种可行的选择，以安全且成功地导航周围环境。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.16488v1">PDF</a> </p>
<p><strong>摘要</strong><br>     本研究提出一种创新型实时系统，通过音频描述用户周围环境来提高视觉障碍人士的情境意识。系统获取实时视频输入，使用针对低功率边缘设备优化的Florence-2大模型的量化与微调版本进行处理。通过转换视频信号为帧，提供对物体、行人和障碍物的快速且语境相关的描述，以及它们的大致距离。系统采用轻量级、可定制的文本到语音（TTS）解决方案Parler TTS Mini，可提供高效的音频反馈，并适应34种不同的演讲者类型，用户可根据需求调整语音的语调、速度和风格。本研究探讨了用于此应用程序的Florence-2模型的量化和微调技术，说明了紧凑模型架构与通用TTS组件的融合如何改善实时性能和用户体验。所提出的系统已根据其准确性、效率和实用性进行评估，为视觉障碍用户提供了一种安全且成功的导航周围环境的可行选择。</p>
<p><strong>要点</strong></p>
<ol>
<li>实时系统通过音频描述周围环境提高视觉障碍人士的情境意识。</li>
<li>系统使用量化与微调后的Florence-2模型处理视频输入，适用于低功率边缘设备。</li>
<li>模型提供快速、与上下文相关的障碍物和物体描述，及其大致距离。</li>
<li>采用Parler TTS Mini进行音频反馈，可适应多种语音类型和用户定制需求。</li>
<li>研究了模型的量化和微调技术，展示了紧凑模型架构与TTS组件的融合优势。</li>
<li>系统评估包括准确性、效率和实用性，为视觉障碍者提供安全导航的选择。</li>
<li>该系统有助于视觉障碍人士更好地独立行动和移动。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.16488">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pica.zhimg.com/v2-e0447a11143e2ed07642f2de0d3046ac.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d6b072990367bef2101bc191f0b1439b.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-162bc2bd5cb9c2a6677fc21def769c31.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-2b752877c656c637f4afd3a3af12614f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ebe1ea6a13134cecc0b7fe07a239d807.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="Sparse-Alignment-Enhanced-Latent-Diffusion-Transformer-for-Zero-Shot-Speech-Synthesis"><a href="#Sparse-Alignment-Enhanced-Latent-Diffusion-Transformer-for-Zero-Shot-Speech-Synthesis" class="headerlink" title="Sparse Alignment Enhanced Latent Diffusion Transformer for Zero-Shot   Speech Synthesis"></a>Sparse Alignment Enhanced Latent Diffusion Transformer for Zero-Shot   Speech Synthesis</h2><p><strong>Authors:Ziyue Jiang, Yi Ren, Ruiqi Li, Shengpeng Ji, Boyang Zhang, Zhenhui Ye, Chen Zhang, Bai Jionghao, Xiaoda Yang, Jialong Zuo, Yu Zhang, Rui Liu, Xiang Yin, Zhou Zhao</strong></p>
<p>While recent zero-shot text-to-speech (TTS) models have significantly improved speech quality and expressiveness, mainstream systems still suffer from issues related to speech-text alignment modeling: 1) models without explicit speech-text alignment modeling exhibit less robustness, especially for hard sentences in practical applications; 2) predefined alignment-based models suffer from naturalness constraints of forced alignments. This paper introduces \textit{S-DiT}, a TTS system featuring an innovative sparse alignment algorithm that guides the latent diffusion transformer (DiT). Specifically, we provide sparse alignment boundaries to S-DiT to reduce the difficulty of alignment learning without limiting the search space, thereby achieving high naturalness. Moreover, we employ a multi-condition classifier-free guidance strategy for accent intensity adjustment and adopt the piecewise rectified flow technique to accelerate the generation process. Experiments demonstrate that S-DiT achieves state-of-the-art zero-shot TTS speech quality and supports highly flexible control over accent intensity. Notably, our system can generate high-quality one-minute speech with only 8 sampling steps. Audio samples are available at <a target="_blank" rel="noopener" href="https://sditdemo.github.io/sditdemo/">https://sditdemo.github.io/sditdemo/</a>. </p>
<blockquote>
<p>尽管最近的零样本文本到语音（TTS）模型在语音质量和表达力方面有了显著的提升，主流系统仍然面临与语音文本对齐建模相关的问题：1）没有明确的语音文本对齐建模的模型表现出较低的稳健性，特别是在实际应用中的复杂句子；2）基于预定义对齐的模型受到强制对齐的自然性约束的影响。本文介绍了S-DiT，一个具有创新稀疏对齐算法的TTS系统，该算法引导潜在扩散变压器（DiT）。具体来说，我们为S-DiT提供稀疏对齐边界，以减少对齐学习的难度，同时不限制搜索空间，从而实现高自然度。此外，我们采用多条件无分类指导策略进行口音强度调整，并采用分段校正流技术来加速生成过程。实验表明，S-DiT达到了最先进的零样本TTS语音质量，并支持对口音强度进行高度灵活的控制。值得注意的是，我们的系统只需8个采样步骤就能生成高质量的一分钟语音。音频样本可在<a target="_blank" rel="noopener" href="https://sditdemo.github.io/sditdemo%E6%89%BE%E5%88%B0%E3%80%82">https://sditdemo.github.io/sditdemo/找到。</a></p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.18924v2">PDF</a> </p>
<p><strong>Summary</strong><br>本文提出了一种新型的文本转语音（TTS）系统S-DiT，它采用稀疏对齐算法指导潜在扩散转换器（DiT）。通过提供稀疏对齐边界，减少了对齐学习的难度且不会限制搜索空间，从而提高语音的自然性。同时采用多条件分类自由指导策略进行口音强度调整，并使用分段整流流技术加速生成过程。实验证明，S-DiT在零样本TTS语音质量方面达到最佳水平，并支持高度灵活的口音强度控制。同时生成高质量一分钟语音仅需要八次采样步骤。相关音频样本已在网站公开。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>S-DiT是一种新型的文本转语音（TTS）系统，基于稀疏对齐算法改进语音和文本的对齐问题。</li>
<li>S-DiT通过提供稀疏对齐边界减少了对齐学习难度，提高了语音的自然性。</li>
<li>系统采用多条件分类自由指导策略，实现口音强度的灵活调整。</li>
<li>分段整流流技术被用于加速语音生成过程。</li>
<li>实验证明S-DiT在零样本TTS语音质量方面表现优异。</li>
<li>S-DiT系统能够生成高质量一分钟的语音，仅需要八次采样步骤。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.18924">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-617827defbfc37fe71a8094f7a096acc.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c61848e90138a47623544e6508ddede3.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-7235bde963e172c8da3b664a261253c4.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d61b51cb69a1990f12eb9062880aadfb.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="Where-are-we-in-audio-deepfake-detection-A-systematic-analysis-over-generative-and-detection-models"><a href="#Where-are-we-in-audio-deepfake-detection-A-systematic-analysis-over-generative-and-detection-models" class="headerlink" title="Where are we in audio deepfake detection? A systematic analysis over   generative and detection models"></a>Where are we in audio deepfake detection? A systematic analysis over   generative and detection models</h2><p><strong>Authors:Xiang Li, Pin-Yu Chen, Wenqi Wei</strong></p>
<p>Recent advances in Text-to-Speech (TTS) and Voice-Conversion (VC) using generative Artificial Intelligence (AI) technology have made it possible to generate high-quality and realistic human-like audio. This poses growing challenges in distinguishing AI-synthesized speech from the genuine human voice and could raise concerns about misuse for impersonation, fraud, spreading misinformation, and scams. However, existing detection methods for AI-synthesized audio have not kept pace and often fail to generalize across diverse datasets. In this paper, we introduce SONAR, a synthetic AI-Audio Detection Framework and Benchmark, aiming to provide a comprehensive evaluation for distinguishing cutting-edge AI-synthesized auditory content. SONAR includes a novel evaluation dataset sourced from 9 diverse audio synthesis platforms, including leading TTS providers and state-of-the-art TTS models. It is the first framework to uniformly benchmark AI-audio detection across both traditional and foundation model-based detection systems. Through extensive experiments, (1) we reveal the limitations of existing detection methods and demonstrate that foundation models exhibit stronger generalization capabilities, likely due to their model size and the scale and quality of pretraining data. (2) Speech foundation models demonstrate robust cross-lingual generalization capabilities, maintaining strong performance across diverse languages despite being fine-tuned solely on English speech data. This finding also suggests that the primary challenges in audio deepfake detection are more closely tied to the realism and quality of synthetic audio rather than language-specific characteristics. (3) We explore the effectiveness and efficiency of few-shot fine-tuning in improving generalization, highlighting its potential for tailored applications, such as personalized detection systems for specific entities or individuals. </p>
<blockquote>
<p>近期在文本转语音（TTS）和语音转换（VC）方面利用生成式人工智能（AI）技术的进展，使得生成高质量、逼真的类似人类音频成为可能。这带来了日益增长的挑战，即区分AI合成的语音和真正的人类声音，并可能引起关于滥用身份冒充、欺诈、传播误导信息和诈骗的担忧。然而，现有的AI合成音频检测手段并未跟上这一发展速度，往往无法在不同数据集之间进行泛化。在本文中，我们介绍了SONAR，一个合成AI音频检测框架和基准测试，旨在为区分前沿AI合成听觉内容提供全面评估。SONAR包括一个新颖的评价数据集，来源于9个多样化的音频合成平台，包括领先的TTS提供商和先进的TTS模型。它是第一个能够在传统和基于基础模型的检测系统之间统一基准测试AI音频的检测框架。通过广泛的实验，（1）我们揭示了现有检测方法的局限性，并证明基础模型表现出更强的泛化能力，这可能是由于其模型大小以及预训练数据的规模和品质。 （2）语音基础模型展现出强大的跨语言泛化能力，在各种语言中都表现出强劲的性能，尽管它们只针对英语语音数据进行微调。这一发现还表明，音频深度伪造检测的主要挑战更紧密地与合成音频的真实性和质量有关，而与语言特性无关。（3）我们探讨了少量样本微调在提升泛化能力方面的有效性和效率，并突出了其在定制应用方面的潜力，例如针对特定实体或个人的个性化检测系统。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2410.04324v4">PDF</a> </p>
<p><strong>摘要</strong></p>
<p>近期文本转语音（TTS）和语音转换（VC）领域利用生成式人工智能（AI）技术的进展，已能够生成高质量、逼真的类似人类音频。这给区分AI合成语音和真实人类声音带来了日益增长的挑战，并可能引起关于滥用、欺诈、传播虚假信息和诈骗的担忧。然而，现有的AI合成音频检测方法的进步速度却未能与之匹配，往往无法在跨不同数据集时保持普遍适应性。本文介绍SONAR，一个合成AI音频检测框架与基准测试，旨在提供区分最前沿AI合成听觉内容的全面评估。SONAR包括一个来自9个不同音频合成平台的新型评估数据集，涵盖领先的TTS提供商和最新TTS模型。它是第一个能够在传统和基于基础模型的检测系统之间统一基准测试的AI音频检测框架。通过广泛的实验，（1）我们揭示了现有检测方法的局限性，并证明基础模型展现出更强的泛化能力，这可能是由于其模型大小以及预训练数据的规模和质量的缘故。（2）语音基础模型表现出强大的跨语言泛化能力，即使在仅对英语语音数据进行微调的情况下也能保持对不同语言的强大性能。这一发现还表明，音频深度伪造检测的主要挑战更紧密地联系着合成音频的真实性和质量，而非语言特性。（3）我们探讨了少量样本微调在改进泛化方面的有效性和效率，突显其在定制应用中的潜力，如针对特定实体或个人的个性化检测系统。</p>
<p><strong>要点提炼</strong></p>
<ol>
<li>近期AI技术在TTS和VC领域的进展使得生成高质量、逼真的类似人类音频成为可能，引发关于区分AI合成语音和真实人类声音的挑战。</li>
<li>现有AI合成音频检测方法进步缓慢，难以适应跨不同数据集的需求。</li>
<li>SONAR框架旨在提供全面的AI合成音频检测评估，包括来自多个合成平台的评估数据集。</li>
<li>基础模型展现出更强的泛化能力，这与其模型大小及预训练数据的规模和质量有关。</li>
<li>语音基础模型具备跨语言泛化能力，能在不同语言间保持性能。</li>
<li>音频深度伪造检测的挑战更在于合成音频的真实性和质量，而非语言特性。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2410.04324">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-00a7071fbe3977128ac72c0b5bfe57c5.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a3bad7546f3719d6ead1d96f34876a8e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-87f44832df280b543181facbada34854.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-5e86f37f1ffa7ca7c44a1d1ba608a029.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        文章作者:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        文章链接:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-03-27/TTS/">https://kedreamix.github.io/Talk2Paper/Paper/2025-03-27/TTS/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        版权声明:
                    </i>
                </span>
                <span class="reprint-info">
                    本博客所有文章除特別声明外，均采用
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    许可协议。转载请注明来源
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/TTS/">
                                    <span class="chip bg-color">TTS</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;上一篇</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-03-27/Interactive/">
                    <div class="card-image">
                        
                        <img src="https://pic1.zhimg.com/v2-0d1d23a0ee3093c5e5ba8bdc856c1f9e.jpg" class="responsive-img" alt="Interactive">
                        
                        <span class="card-title">Interactive</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Interactive 方向最新论文已更新，请持续关注 Update in 2025-03-27  Information geometry of chemical reaction networks Cramer-Rao bound and   absolute sensitivity revisited
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-03-27
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Interactive/" class="post-category">
                                    Interactive
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Interactive/">
                        <span class="chip bg-color">Interactive</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-03-27/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-0e4d62530a026b201a3a8adfeccfe9b0.jpg" class="responsive-img" alt="医学图像">
                        
                        <span class="card-title">医学图像</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            医学图像 方向最新论文已更新，请持续关注 Update in 2025-03-27  The cross-correlation between soft X-rays and galaxies A new benchmark   for galaxy evolution models
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-03-27
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/" class="post-category">
                                    医学图像
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/">
                        <span class="chip bg-color">医学图像</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- 代码语言 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span
                        class="white-color">23394.3k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- 运行天数提醒. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // 区分是否有年份.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = '本站已运行 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                daysTip = '本站已運行 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = '本站已运行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = '本站已運行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="关注我的知乎: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">知</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- 白天和黑夜主题 -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // 只在桌面版网页启用特效
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- 雪花特效 -->
    

    <!-- 鼠标星星特效 -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--腾讯兔小巢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- 动态标签 -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Σ(っ °Д °;)っ诶，页面崩溃了嘛？", clearTimeout(st)) : (document.title = "φ(゜▽゜*)♪咦，又好了！", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
