<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Agent">
    <meta name="description" content="Agent æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-06-13  &#34;What are my options?&#34; Explaining RL Agents with Diverse Near-Optimal   Alternatives (Extended)">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>Agent | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://pic1.zhimg.com/v2-df04937e3f74637c3683c7c30cd2b471.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Agent</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/Agent/">
                                <span class="chip bg-color">Agent</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/Agent/" class="post-category">
                                Agent
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-06-13
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-07-06
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    14.8k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    60 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-06-13-æ›´æ–°"><a href="#2025-06-13-æ›´æ–°" class="headerlink" title="2025-06-13 æ›´æ–°"></a>2025-06-13 æ›´æ–°</h1><h2 id="â€œWhat-are-my-options-â€-Explaining-RL-Agents-with-Diverse-Near-Optimal-Alternatives-Extended"><a href="#â€œWhat-are-my-options-â€-Explaining-RL-Agents-with-Diverse-Near-Optimal-Alternatives-Extended" class="headerlink" title="â€œWhat are my options?â€: Explaining RL Agents with Diverse Near-Optimal   Alternatives (Extended)"></a>â€œWhat are my options?â€: Explaining RL Agents with Diverse Near-Optimal   Alternatives (Extended)</h2><p><strong>Authors:Noel Brindise, Vijeth Hebbar, Riya Shah, Cedric Langbort</strong></p>
<p>In this work, we provide an extended discussion of a new approach to explainable Reinforcement Learning called Diverse Near-Optimal Alternatives (DNA), first proposed at L4DC 2025. DNA seeks a set of reasonable â€œoptionsâ€ for trajectory-planning agents, optimizing policies to produce qualitatively diverse trajectories in Euclidean space. In the spirit of explainability, these distinct policies are used to â€œexplainâ€ an agentâ€™s options in terms of available trajectory shapes from which a human user may choose. In particular, DNA applies to value function-based policies on Markov decision processes where agents are limited to continuous trajectories. Here, we describe DNA, which uses reward shaping in local, modified Q-learning problems to solve for distinct policies with guaranteed epsilon-optimality. We show that it successfully returns qualitatively different policies that constitute meaningfully different â€œoptionsâ€ in simulation, including a brief comparison to related approaches in the stochastic optimization field of Quality Diversity. Beyond the explanatory motivation, this work opens new possibilities for exploration and adaptive planning in RL. </p>
<blockquote>
<p>åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬å¯¹ä¸€ç§åä¸ºå¤šæ ·è¿‘ä¼˜æ›¿ä»£æ–¹æ¡ˆï¼ˆDNAï¼‰çš„å¯è§£é‡Šå¼ºåŒ–å­¦ä¹ æ–°æ–¹æ³•è¿›è¡Œäº†æ·±å…¥æ¢è®¨ï¼Œè¯¥æ–¹æ³•é¦–å…ˆåœ¨L4DC 2025ä¸Šæå‡ºã€‚DNAä¸ºè½¨è¿¹è§„åˆ’ä»£ç†å¯»æ‰¾ä¸€ç»„åˆç†çš„â€œé€‰é¡¹â€ï¼Œä¼˜åŒ–ç­–ç•¥ä»¥åœ¨æ¬§å‡ é‡Œå¾—ç©ºé—´ä¸­äº§ç”Ÿå®šæ€§å¤šæ ·çš„è½¨è¿¹ã€‚æœ¬ç€å¯è§£é‡Šæ€§çš„ç²¾ç¥ï¼Œè¿™äº›ä¸åŒçš„ç­–ç•¥è¢«ç”¨æ¥â€œè§£é‡Šâ€ä»£ç†çš„å¯é€‰è½¨è¿¹å½¢çŠ¶ï¼Œä¾›äººç±»ç”¨æˆ·é€‰æ‹©ã€‚ç‰¹åˆ«æ˜¯ï¼ŒDNAé€‚ç”¨äºåŸºäºå€¼å‡½æ•°çš„é©¬å°”å¯å¤«å†³ç­–è¿‡ç¨‹ç­–ç•¥ï¼Œå…¶ä¸­ä»£ç†é™äºè¿ç»­è½¨è¿¹ã€‚åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬æè¿°äº†DNAï¼Œå®ƒåœ¨å±€éƒ¨ä¿®æ”¹Qå­¦ä¹ é—®é¢˜ä¸­ä½¿ç”¨å¥–åŠ±å¡‘å½¢æ¥è§£å†³å…·æœ‰ä¿è¯epsilonæœ€ä¼˜æ€§çš„ä¸åŒç­–ç•¥ã€‚æˆ‘ä»¬æ˜¾ç¤ºï¼Œå®ƒåœ¨æ¨¡æ‹Ÿä¸­æˆåŠŸè¿”å›äº†å®šæ€§çš„ä¸åŒç­–ç•¥ï¼Œè¿™äº›ç­–ç•¥æ„æˆäº†æœ‰æ„ä¹‰çš„â€œé€‰é¡¹â€ï¼ŒåŒ…æ‹¬ä¸å¤šæ ·æ€§ä¼˜åŒ–é¢†åŸŸç›¸å…³æ–¹æ³•çš„ç®€çŸ­æ¯”è¾ƒã€‚é™¤äº†è§£é‡ŠåŠ¨æœºå¤–ï¼Œè¿™é¡¹å·¥ä½œè¿˜ä¸ºå¼ºåŒ–å­¦ä¹ ä¸­çš„æ¢ç´¢å’Œè‡ªé€‚åº”è§„åˆ’å¼€è¾Ÿäº†æ–°çš„å¯èƒ½æ€§ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.09901v1">PDF</a> </p>
<p><strong>Summary</strong><br>     è¯¥è®ºæ–‡ä»‹ç»äº†ä¸€ç§æ–°çš„å¯è§£é‡Šçš„å¼ºåŒ–å­¦ä¹ ï¼ˆReinforcement Learningï¼‰æ–¹æ³•â€”â€”å¤šæ ·è¿‘ä¼˜é€‰æ‹©ï¼ˆDNAï¼‰ã€‚DNAé€šè¿‡ä¼˜åŒ–ç­–ç•¥ï¼Œä¸ºè½¨è¿¹è§„åˆ’ä»£ç†æä¾›ä¸€ç³»åˆ—åˆç†çš„â€œé€‰é¡¹â€ï¼Œå¹¶åœ¨æ¬§å‡ é‡Œå¾—ç©ºé—´ä¸­ç”Ÿæˆå®šæ€§å¤šæ ·çš„è½¨è¿¹ã€‚è¿™äº›ä¸åŒçš„ç­–ç•¥ç”¨äºâ€œè§£é‡Šâ€ä»£ç†çš„é€‰é¡¹ï¼Œä»¥äººç±»ç”¨æˆ·å¯ä»¥é€‰æ‹©çš„è½¨è¿¹å½¢çŠ¶çš„å½¢å¼å‘ˆç°ã€‚DNAç‰¹åˆ«é€‚ç”¨äºåŸºäºå€¼å‡½æ•°çš„ç­–ç•¥åœ¨é©¬å°”å¯å¤«å†³ç­–è¿‡ç¨‹ä¸­çš„åº”ç”¨ï¼Œå…¶ä¸­ä»£ç†ä»…é™äºè¿ç»­è½¨è¿¹ã€‚è®ºæ–‡æè¿°DNAé€šè¿‡åœ¨å±€éƒ¨ä¿®æ”¹Q-learningé—®é¢˜ä¸­çš„å¥–åŠ±å½¢çŠ¶æ¥è§£å†³å…·æœ‰ä¿è¯çš„Îµ-æœ€ä¼˜æ€§çš„ä¸åŒç­–ç•¥é—®é¢˜ã€‚ç ”ç©¶ç»“æœè¡¨æ˜ï¼Œå®ƒåœ¨æ¨¡æ‹Ÿä¸­æˆåŠŸè¿”å›äº†å®šæ€§ä¸åŒçš„ç­–ç•¥ï¼Œè¿™äº›ç­–ç•¥æ„æˆäº†æœ‰æ„ä¹‰çš„â€œé€‰é¡¹â€ï¼Œå¹¶ç®€è¦æ¯”è¾ƒäº†ä¸è´¨é‡å¤šæ ·æ€§ç›¸å…³çš„éšæœºä¼˜åŒ–é¢†åŸŸä¸­çš„å…¶ä»–æ–¹æ³•ã€‚é™¤äº†è§£é‡ŠåŠ¨æœºå¤–ï¼Œè¿™é¡¹å·¥ä½œè¿˜ä¸ºå¼ºåŒ–å­¦ä¹ ä¸­çš„æ¢ç´¢å’Œè‡ªé€‚åº”è§„åˆ’æ‰“å¼€äº†æ–°çš„å¯èƒ½æ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>DNAæ˜¯ä¸€ç§æ–°çš„å¼ºåŒ–å­¦ä¹ æ–¹æ³•ï¼Œæ—¨åœ¨æä¾›ä»£ç†çš„å¤šæ ·ä¸”åˆç†çš„å†³ç­–é€‰é¡¹ã€‚</li>
<li>DNAé€‚ç”¨äºè½¨è¿¹è§„åˆ’é—®é¢˜ï¼Œä¼˜åŒ–ç­–ç•¥ä»¥ç”Ÿæˆå¤šæ ·è½¨è¿¹ã€‚</li>
<li>è¿™äº›ç­–ç•¥æ—¨åœ¨â€œè§£é‡Šâ€ä»£ç†çš„é€‰é¡¹ï¼Œä¸ºäººç±»ç”¨æˆ·æä¾›è½¨è¿¹å½¢çŠ¶çš„é€‰æ‹©ã€‚</li>
<li>DNAé€‚ç”¨äºåŸºäºå€¼å‡½æ•°çš„é©¬å°”å¯å¤«å†³ç­–è¿‡ç¨‹ï¼Œå…¶ä¸­ä»£ç†åœ¨è¿ç»­è½¨è¿¹ä¸­æ“ä½œã€‚</li>
<li>DNAé€šè¿‡å±€éƒ¨ä¿®æ”¹Q-learningé—®é¢˜ä¸­çš„å¥–åŠ±å½¢çŠ¶æ¥è§£å†³Îµ-æœ€ä¼˜æ€§çš„ä¸åŒç­–ç•¥é—®é¢˜ã€‚</li>
<li>åœ¨æ¨¡æ‹Ÿç¯å¢ƒä¸­æˆåŠŸæµ‹è¯•äº†DNAï¼Œè¿”å›äº†å¤šç§å®šæ€§ä¸åŒçš„ç­–ç•¥ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.09901">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-247d7314fd55748b654d320260438b92.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="ReasonMed-A-370K-Multi-Agent-Generated-Dataset-for-Advancing-Medical-Reasoning"><a href="#ReasonMed-A-370K-Multi-Agent-Generated-Dataset-for-Advancing-Medical-Reasoning" class="headerlink" title="ReasonMed: A 370K Multi-Agent Generated Dataset for Advancing Medical   Reasoning"></a>ReasonMed: A 370K Multi-Agent Generated Dataset for Advancing Medical   Reasoning</h2><p><strong>Authors:Yu Sun, Xingyu Qian, Weiwen Xu, Hao Zhang, Chenghao Xiao, Long Li, Yu Rong, Wenbing Huang, Qifeng Bai, Tingyang Xu</strong></p>
<p>Though reasoning-based large language models (LLMs) have excelled in mathematics and programming, their capabilities in knowledge-intensive medical question answering remain underexplored. To address this, we introduce ReasonMed, the largest medical reasoning dataset, comprising 370k high-quality examples distilled from 1.7 million initial reasoning paths generated by various LLMs. ReasonMed is constructed through a \textit{multi-agent verification and refinement process}, where we design an \textit{Error Refiner} to enhance the reasoning paths by identifying and correcting error-prone steps flagged by a verifier. Leveraging ReasonMed, we systematically investigate best practices for training medical reasoning models and find that combining detailed Chain-of-Thought (CoT) reasoning with concise answer summaries yields the most effective fine-tuning strategy. Based on this strategy, we train ReasonMed-7B, which sets a new benchmark for sub-10B models, outperforming the prior best by 4.17% and even exceeding LLaMA3.1-70B on PubMedQA by 4.60%. </p>
<blockquote>
<p>è™½ç„¶åŸºäºæ¨ç†çš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨æ•°å­¦å’Œç¼–ç¨‹æ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œä½†å®ƒä»¬åœ¨çŸ¥è¯†å¯†é›†å‹çš„åŒ»ç–—é—®é¢˜å›ç­”æ–¹é¢çš„èƒ½åŠ›ä»è¢«ä½ä¼°ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬æ¨å‡ºäº†ReasonMedï¼Œè¿™æ˜¯æœ€å¤§çš„åŒ»ç–—æ¨ç†æ•°æ®é›†ï¼ŒåŒ…å«ä»ç”±å„ç§LLMç”Ÿæˆçš„170ä¸‡æ¡åˆå§‹æ¨ç†è·¯å¾„ä¸­æç‚¼å‡ºçš„37ä¸‡ä¸ªé«˜è´¨é‡æ ·æœ¬ã€‚ReasonMedçš„æ„å»ºè¿‡ç¨‹ç»è¿‡å¤šæ™ºèƒ½ä½“éªŒè¯å’Œå®Œå–„ï¼Œæˆ‘ä»¬è®¾è®¡äº†ä¸€ä¸ªâ€œé”™è¯¯ä¿®æ­£å™¨â€ï¼Œé€šè¿‡è¯†åˆ«éªŒè¯å™¨æ ‡è®°çš„é”™è¯¯å€¾å‘æ­¥éª¤å¹¶å¯¹å…¶è¿›è¡Œä¿®æ­£ï¼Œä»è€Œå¢å¼ºæ¨ç†è·¯å¾„ã€‚å€ŸåŠ©ReasonMedï¼Œæˆ‘ä»¬ç³»ç»Ÿåœ°ç ”ç©¶äº†è®­ç»ƒåŒ»ç–—æ¨ç†æ¨¡å‹çš„æœ€ä½³å®è·µï¼Œå¹¶å‘ç°å°†è¯¦ç»†çš„æ€ç»´é“¾ï¼ˆCoTï¼‰æ¨ç†ä¸ç®€æ´çš„ç­”æ¡ˆæ‘˜è¦ç›¸ç»“åˆï¼Œæ˜¯æœ€æœ‰æ•ˆçš„å¾®è°ƒç­–ç•¥ã€‚åŸºäºè¿™ä¸€ç­–ç•¥ï¼Œæˆ‘ä»¬è®­ç»ƒäº†ReasonMed-7Bï¼Œè¯¥æ¨¡å‹ä¸ºæ¬¡10Bæ¨¡å‹è®¾ç«‹äº†æ–°åŸºå‡†ï¼Œè¾ƒä¹‹å‰æœ€ä½³æ¨¡å‹æé«˜äº†4.17%ï¼Œç”šè‡³åœ¨PubMedQAä¸Šè¶…è¿‡äº†LLaMA3.1-70Bæ¨¡å‹ï¼Œæé«˜äº†4.60%ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.09513v1">PDF</a> 24 pages, 6 figures, 7 tables</p>
<p><strong>Summary</strong></p>
<p>åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„æ¨ç†èƒ½åŠ›åœ¨åŒ»å­¦é—®ç­”ç­‰çŸ¥è¯†å¯†é›†å‹ä»»åŠ¡ä¸Šå°šæœªå¾—åˆ°å……åˆ†æ¢ç´¢ã€‚ä¸ºè§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬å¼•å…¥äº†ReasonMedæ•°æ®é›†ï¼Œå…¶ä¸­åŒ…å«ç”±ä¸åŒLLMç”Ÿæˆçš„æ•°ç™¾ä¸‡åˆå§‹æ¨ç†è·¯å¾„ä¸­æç‚¼å‡ºçš„37ä¸‡ä¸ªé«˜è´¨é‡æ ·æœ¬ã€‚ReasonMedçš„æ„å»ºé‡‡ç”¨äº†å¤šæ™ºèƒ½éªŒè¯ä¸ä¿®æ­£è¿‡ç¨‹ï¼Œå¹¶è®¾è®¡äº†Error Refineræ¥è¯†åˆ«å¹¶ä¿®æ­£éªŒè¯å™¨æ ‡è®°çš„é”™è¯¯æ­¥éª¤ï¼Œä»¥æé«˜æ¨ç†è·¯å¾„çš„å‡†ç¡®æ€§ã€‚åˆ©ç”¨ReasonMedæ•°æ®é›†ï¼Œæˆ‘ä»¬ç³»ç»Ÿåœ°ç ”ç©¶äº†è®­ç»ƒåŒ»å­¦æ¨ç†æ¨¡å‹çš„æœ€ä½³å®è·µï¼Œå‘ç°å°†è¯¦ç»†çš„Chain-of-Thoughtï¼ˆCoTï¼‰æ¨ç†ä¸ç®€æ´çš„ç­”æ¡ˆæ‘˜è¦ç›¸ç»“åˆæ˜¯æœ€æœ‰æ•ˆçš„å¾®è°ƒç­–ç•¥ã€‚åŸºäºè¿™ä¸€ç­–ç•¥ï¼Œæˆ‘ä»¬è®­ç»ƒäº†ReasonMed-7Bæ¨¡å‹ï¼Œä¸ºå°å‹æ¨¡å‹æ ‘ç«‹äº†æ–°çš„åŸºå‡†çº¿ï¼Œç›¸æ¯”å…ˆå‰æœ€ä½³è¡¨ç°æé«˜äº†4.17%ï¼Œç”šè‡³åœ¨PubMedQAä¸Šè¶…è¿‡äº†LLaMA3.1-70Bæ¨¡å‹ï¼Œæé«˜äº†4.6%ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨çŸ¥è¯†å¯†é›†å‹ä»»åŠ¡å¦‚åŒ»å­¦é—®ç­”ä¸Šçš„èƒ½åŠ›å°šæœªå……åˆ†æ¢ç´¢ã€‚</li>
<li>å¼•å…¥ReasonMedæ•°æ®é›†ï¼Œé€šè¿‡å¤šæ™ºèƒ½éªŒè¯ä¸ä¿®æ­£è¿‡ç¨‹æé«˜æ¨ç†è·¯å¾„çš„å‡†ç¡®æ€§ã€‚</li>
<li>åˆ©ç”¨ReasonMedæ•°æ®é›†ç ”ç©¶è®­ç»ƒåŒ»å­¦æ¨ç†æ¨¡å‹çš„æœ€ä½³å®è·µã€‚</li>
<li>å‘ç°ç»“åˆè¯¦ç»†çš„Chain-of-Thoughtï¼ˆCoTï¼‰æ¨ç†ä¸ç®€æ´ç­”æ¡ˆæ‘˜è¦çš„å¾®è°ƒç­–ç•¥æœ€æœ‰æ•ˆã€‚</li>
<li>åŸºäºè¯¥ç­–ç•¥è®­ç»ƒçš„ReasonMed-7Bæ¨¡å‹æ ‘ç«‹äº†æ–°çš„åŸºå‡†çº¿ã€‚</li>
<li>ReasonMed-7Bæ¨¡å‹ç›¸æ¯”å…ˆå‰æœ€ä½³è¡¨ç°æé«˜äº†4.17%ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.09513">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-8b0aec02e882cf820ce23e33852620c2.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b20991e3bbf0911822ae4daef4d4c1c4.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-1fc4e085a65eb353acb0d0091f9349d6.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-39b8ba42df02e579db98f763c94dd1f3.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b5c3a51a46d2cc8e9b8ec42df834c960.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-243b8247193ffcd5ba409b46bbad94e8.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-6cb4f3536fafebd0812061000bf671bd.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="When-Is-Diversity-Rewarded-in-Cooperative-Multi-Agent-Learning"><a href="#When-Is-Diversity-Rewarded-in-Cooperative-Multi-Agent-Learning" class="headerlink" title="When Is Diversity Rewarded in Cooperative Multi-Agent Learning?"></a>When Is Diversity Rewarded in Cooperative Multi-Agent Learning?</h2><p><strong>Authors:Michael Amir, Matteo Bettini, Amanda Prorok</strong></p>
<p>The success of teams in robotics, nature, and society often depends on the division of labor among diverse specialists; however, a principled explanation for when such diversity surpasses a homogeneous team is still missing. Focusing on multi-agent task allocation problems, our goal is to study this question from the perspective of reward design: what kinds of objectives are best suited for heterogeneous teams? We first consider an instantaneous, non-spatial setting where the global reward is built by two generalized aggregation operators: an inner operator that maps the $N$ agentsâ€™ effort allocations on individual tasks to a task score, and an outer operator that merges the $M$ task scores into the global team reward. We prove that the curvature of these operators determines whether heterogeneity can increase reward, and that for broad reward families this collapses to a simple convexity test. Next, we ask what incentivizes heterogeneity to emerge when embodied, time-extended agents must learn an effort allocation policy. To study heterogeneity in such settings, we use multi-agent reinforcement learning (MARL) as our computational paradigm, and introduce Heterogeneous Environment Design (HED), a gradient-based algorithm that optimizes the parameter space of underspecified MARL environments to find scenarios where heterogeneity is advantageous. Experiments in matrix games and an embodied Multi-Goal-Capture environment show that, despite the difference in settings, HED rediscovers the reward regimes predicted by our theory to maximize the advantage of heterogeneity, both validating HED and connecting our theoretical insights to reward design in MARL. Together, these results help us understand when behavioral diversity delivers a measurable benefit. </p>
<blockquote>
<p>å›¢é˜Ÿåœ¨æœºå™¨äººã€è‡ªç„¶å’Œç¤¾ä¼šä¸­çš„æˆåŠŸå¾€å¾€å–å†³äºä¸åŒä¸“å®¶ä¹‹é—´çš„åŠ³åŠ¨åˆ†å·¥ï¼›ç„¶è€Œï¼Œå…³äºä½•æ—¶å¤šæ ·åŒ–çš„å›¢é˜Ÿä¼šè¶…è¶ŠåŒè´¨å›¢é˜Ÿçš„ç†è®ºè§£é‡Šä»ç„¶ç¼ºå¤±ã€‚æˆ‘ä»¬çš„ç›®æ ‡æ˜¯ä»å¥–åŠ±è®¾è®¡çš„è§’åº¦ç ”ç©¶è¿™ä¸ªé—®é¢˜ï¼šä»€ä¹ˆæ ·çš„ç›®æ ‡æœ€é€‚åˆå¼‚è´¨çš„å›¢é˜Ÿï¼Ÿæˆ‘ä»¬é¦–å…ˆè€ƒè™‘ä¸€ä¸ªå³æ—¶ã€éç©ºé—´çš„ç¯å¢ƒï¼Œå…¨å±€å¥–åŠ±ç”±ä¸¤ä¸ªå¹¿ä¹‰èšåˆç®—å­æ„å»ºï¼šä¸€ä¸ªå†…éƒ¨ç®—å­å°†Nä¸ªä»£ç†åœ¨å•ä¸ªä»»åŠ¡ä¸Šçš„åŠªåŠ›åˆ†é…æ˜ å°„åˆ°ä»»åŠ¡è¯„åˆ†ï¼Œä¸€ä¸ªå¤–éƒ¨ç®—å­å°†Mä¸ªä»»åŠ¡è¯„åˆ†åˆå¹¶åˆ°å…¨å±€å›¢é˜Ÿå¥–åŠ±ã€‚æˆ‘ä»¬è¯æ˜è¿™äº›ç®—å­çš„æ›²ç‡å†³å®šäº†å¼‚è´¨æ€§æ˜¯å¦èƒ½å¢åŠ å¥–åŠ±ï¼Œå¯¹äºå¹¿æ³›çš„å¥–åŠ±å®¶æ—ï¼Œè¿™å½’ç»“ä¸ºä¸€ä¸ªç®€å•çš„å‡¸æ€§æµ‹è¯•ã€‚æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬è¯¢é—®å½“å…·æœ‰å®ä½“çš„ã€æ—¶é—´å»¶é•¿çš„ä»£ç†å¿…é¡»å­¦ä¹ åŠªåŠ›åˆ†é…ç­–ç•¥æ—¶ï¼Œæ˜¯ä»€ä¹ˆæ¿€åŠ±å¼‚è´¨æ€§çš„å‡ºç°ã€‚ä¸ºäº†åœ¨è¿™æ ·çš„ç¯å¢ƒä¸­ç ”ç©¶å¼‚è´¨æ€§ï¼Œæˆ‘ä»¬ä½¿ç”¨å¤šä»£ç†å¼ºåŒ–å­¦ä¹ ä½œä¸ºæˆ‘ä»¬çš„è®¡ç®—èŒƒå¼ï¼Œå¹¶å¼•å…¥å¼‚è´¨ç¯å¢ƒè®¾è®¡ï¼ˆHEDï¼‰è¿™æ˜¯ä¸€ç§åŸºäºæ¢¯åº¦çš„ç®—æ³•ï¼Œå¯ä»¥ä¼˜åŒ–æœªæŒ‡å®šçš„å¤šä»£ç†å¼ºåŒ–å­¦ä¹ ç¯å¢ƒçš„å‚æ•°ç©ºé—´ï¼Œä»¥æ‰¾åˆ°å¼‚è´¨æ€§æœ‰åˆ©çš„åœºæ™¯ã€‚åœ¨çŸ©é˜µæ¸¸æˆå’Œå®ä½“å¤šç›®æ ‡æ•è·ç¯å¢ƒä¸­çš„å®éªŒè¡¨æ˜ï¼Œå°½ç®¡è®¾ç½®ä¸åŒï¼Œä½†HEDé‡æ–°å‘ç°äº†ç†è®ºé¢„æµ‹çš„å¥–åŠ±åˆ¶åº¦ï¼Œä»¥æœ€å¤§åŒ–å¼‚è´¨æ€§çš„ä¼˜åŠ¿ï¼Œæ—¢éªŒè¯äº†HEDï¼Œä¹Ÿå°†æˆ‘ä»¬çš„ç†è®ºè§è§£ä¸å¤šä»£ç†å¼ºåŒ–å­¦ä¹ ä¸­çš„å¥–åŠ±è®¾è®¡è”ç³»èµ·æ¥ã€‚æ€»çš„æ¥è¯´ï¼Œè¿™äº›ç»“æœå¸®åŠ©æˆ‘ä»¬ç†è§£äº†è¡Œä¸ºå¤šæ ·æ€§ä½•æ—¶å¸¦æ¥å¯è¡¡é‡çš„å¥½å¤„ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.09434v1">PDF</a> </p>
<p><strong>æ‘˜è¦</strong></p>
<p>å›¢é˜Ÿåœ¨æœºå™¨äººã€è‡ªç„¶å’Œç¤¾ä¼šä¸­çš„æˆåŠŸå¾€å¾€ä¾èµ–äºä¸åŒä¸“å®¶ä¹‹é—´çš„åŠ³åŠ¨åˆ†å·¥ï¼Œç„¶è€Œï¼Œå…³äºä½•æ—¶å¤šæ ·åŒ–çš„å›¢é˜Ÿè¡¨ç°è¶…è¶Šå•ä¸€åŒ–å›¢é˜Ÿçš„ç†è®ºè§£é‡Šä»ç„¶ç¼ºå¤±ã€‚æœ¬æ–‡å…³æ³¨å¤šæ™ºèƒ½ä½“ä»»åŠ¡åˆ†é…é—®é¢˜ï¼Œä»å¥–åŠ±è®¾è®¡çš„è§’åº¦ç ”ç©¶å¼‚è´¨å›¢é˜Ÿæœ€é€‚åˆå“ªäº›ç›®æ ‡ã€‚é¦–å…ˆï¼Œè€ƒè™‘ä¸€ä¸ªå³æ—¶ã€éç©ºé—´çš„ç¯å¢ƒä¸­ï¼Œå…¨å±€å¥–åŠ±ç”±ä¸¤ä¸ªå¹¿ä¹‰èšåˆç®—å­æ„å»ºï¼šä¸€ä¸ªå†…éƒ¨ç®—å­å°†Nä¸ªæ™ºèƒ½ä½“çš„ä¸ªäººä»»åŠ¡åŠªåŠ›åˆ†é…æ˜ å°„åˆ°ä»»åŠ¡å¾—åˆ†ï¼Œä¸€ä¸ªå¤–éƒ¨ç®—å­å°†Mä¸ªä»»åŠ¡å¾—åˆ†åˆå¹¶ä¸ºå›¢é˜Ÿå…¨å±€å¥–åŠ±ã€‚è¯æ˜äº†è¿™äº›ç®—å­çš„æ›²ç‡å†³å®šäº†å¤šæ ·æ€§æ˜¯å¦èƒ½å¢åŠ å¥–åŠ±ï¼Œå¯¹äºå¹¿æ³›çš„å¥–åŠ±å®¶æ—ï¼Œè¿™å½’ç»“ä¸ºç®€å•çš„å‡¸æ€§æµ‹è¯•ã€‚æ¥ç€ï¼Œæˆ‘ä»¬æ¢è®¨å½“å…·æœ‰å½¢æ€çš„ã€é•¿æœŸæ™ºèƒ½ä½“éœ€è¦å­¦ä¹ åŠªåŠ›åˆ†é…ç­–ç•¥æ—¶ï¼Œå¦‚ä½•æ¿€åŠ±å¼‚è´¨æ€§çš„å‡ºç°ã€‚ä¸ºäº†ç ”ç©¶è¿™ç±»ç¯å¢ƒä¸­çš„å¼‚è´¨æ€§ï¼Œæˆ‘ä»¬ä½¿ç”¨å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ ä½œä¸ºè®¡ç®—èŒƒå¼ï¼Œå¹¶å¼•å…¥å¼‚è´¨ç¯å¢ƒè®¾è®¡ï¼ˆHEDï¼‰ç®—æ³•ï¼Œè¯¥ç®—æ³•åŸºäºæ¢¯åº¦ä¼˜åŒ–æœªæŒ‡å®šçš„å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ ç¯å¢ƒçš„å‚æ•°ç©ºé—´ï¼Œä»¥æ‰¾åˆ°å¼‚è´¨æ€§æœ‰åˆ©çš„åœºæ™¯ã€‚åœ¨çŸ©é˜µæ¸¸æˆå’Œå…·æœ‰å½¢æ€çš„å¤šç›®æ ‡æ•è·ç¯å¢ƒä¸­çš„å®éªŒè¡¨æ˜ï¼Œå°½ç®¡è®¾ç½®ä¸åŒï¼ŒHEDé‡æ–°å‘ç°äº†ç”±ç†è®ºé¢„æµ‹çš„å¥–åŠ±åˆ¶åº¦ï¼Œä»¥æœ€å¤§åŒ–å¼‚è´¨æ€§çš„ä¼˜åŠ¿ï¼Œæ—¢éªŒè¯äº†HEDçš„æœ‰æ•ˆæ€§ï¼Œä¹Ÿå°†æˆ‘ä»¬çš„ç†è®ºè§è§£ä¸å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ ä¸­çš„å¥–åŠ±è®¾è®¡è”ç³»èµ·æ¥ã€‚æ€»çš„æ¥è¯´ï¼Œè¿™äº›ç»“æœæœ‰åŠ©äºç†è§£è¡Œä¸ºå¤šæ ·æ€§ä½•æ—¶å¸¦æ¥å¯è¡¡é‡çš„å¥½å¤„ã€‚</p>
<p><strong>å…³é”®è§è§£</strong></p>
<ol>
<li>å¤šæ ·åŒ–å›¢é˜Ÿçš„åŠ³åŠ¨åˆ†å·¥åœ¨æœºå™¨äººã€è‡ªç„¶å’Œç¤¾ä¼šä¸­çš„å›¢é˜ŸæˆåŠŸä¸­èµ·å…³é”®ä½œç”¨ï¼Œä½†ç¼ºä¹ç†è®ºè§£é‡Šä½•æ—¶å¤šæ ·åŒ–çš„å›¢é˜Ÿè¡¨ç°ä¼šè¶…è¶Šå•ä¸€åŒ–å›¢é˜Ÿã€‚</li>
<li>ä»å¥–åŠ±è®¾è®¡çš„è§’åº¦ç ”ç©¶å¼‚è´¨å›¢é˜Ÿçš„æœ€é€‚åˆç›®æ ‡ï¼Œç‰¹åˆ«æ˜¯åœ¨å¤šæ™ºèƒ½ä½“ä»»åŠ¡åˆ†é…é—®é¢˜çš„èƒŒæ™¯ä¸‹ã€‚</li>
<li>åœ¨å³æ—¶ã€éç©ºé—´çš„ç¯å¢ƒä¸­ï¼Œè¯æ˜äº†å…¨å±€å¥–åŠ±çš„æ„é€ ä¸å†…éƒ¨å’Œå¤–éƒ¨ç®—å­çš„æ›²ç‡æœ‰å…³ï¼Œè¿™å†³å®šäº†å¤šæ ·æ€§å¯¹å¥–åŠ±çš„å½±å“ï¼Œå¹¶å¯ç®€åŒ–ä¸ºå‡¸æ€§æµ‹è¯•ã€‚</li>
<li>é€šè¿‡å¼•å…¥å¼‚è´¨ç¯å¢ƒè®¾è®¡ï¼ˆHEDï¼‰ç®—æ³•ï¼Œç ”ç©¶äº†åœ¨éœ€è¦å­¦ä¹ åŠªåŠ›åˆ†é…ç­–ç•¥çš„ç¯å¢ƒä¸­å¦‚ä½•æ¿€åŠ±å¼‚è´¨æ€§çš„å‡ºç°ã€‚</li>
<li>HEDç®—æ³•åœ¨å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ ç¯å¢ƒä¸­æœ‰æ•ˆï¼Œèƒ½å¤Ÿå‘ç°å¼‚è´¨æ€§æœ‰åˆ©çš„åœºæ™¯ï¼ŒéªŒè¯äº†ç†è®ºé¢„æµ‹ã€‚</li>
<li>å®éªŒç»“æœå±•ç¤ºäº†è¡Œä¸ºå¤šæ ·æ€§å¸¦æ¥çš„å¯è¡¡é‡çš„å¥½å¤„ï¼Œä¸ºç†è§£ä½•æ—¶å¤šæ ·æ€§æœ‰ç›Šæä¾›äº†æ´è§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.09434">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-972ad374252f87fe4eb73711c51042d7.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-7fa930e4207f94acc60e8fe3d8458cb5.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e1743295b81256eacc83034ebf6ab9e9.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="LPO-Towards-Accurate-GUI-Agent-Interaction-via-Location-Preference-Optimization"><a href="#LPO-Towards-Accurate-GUI-Agent-Interaction-via-Location-Preference-Optimization" class="headerlink" title="LPO: Towards Accurate GUI Agent Interaction via Location Preference   Optimization"></a>LPO: Towards Accurate GUI Agent Interaction via Location Preference   Optimization</h2><p><strong>Authors:Jiaqi Tang, Yu Xia, Yi-Feng Wu, Yuwei Hu, Yuhui Chen, Qing-Guo Chen, Xiaogang Xu, Xiangyu Wu, Hao Lu, Yanqing Ma, Shiyin Lu, Qifeng Chen</strong></p>
<p>The advent of autonomous agents is transforming interactions with Graphical User Interfaces (GUIs) by employing natural language as a powerful intermediary. Despite the predominance of Supervised Fine-Tuning (SFT) methods in current GUI agents for achieving spatial localization, these methods face substantial challenges due to their limited capacity to accurately perceive positional data. Existing strategies, such as reinforcement learning, often fail to assess positional accuracy effectively, thereby restricting their utility. In response, we introduce Location Preference Optimization (LPO), a novel approach that leverages locational data to optimize interaction preferences. LPO uses information entropy to predict interaction positions by focusing on zones rich in information. Besides, it further introduces a dynamic location reward function based on physical distance, reflecting the varying importance of interaction positions. Supported by Group Relative Preference Optimization (GRPO), LPO facilitates an extensive exploration of GUI environments and significantly enhances interaction precision. Comprehensive experiments demonstrate LPOâ€™s superior performance, achieving SOTA results across both offline benchmarks and real-world online evaluations. Our code will be made publicly available soon, at <a target="_blank" rel="noopener" href="https://github.com/AIDC-AI/LPO">https://github.com/AIDC-AI/LPO</a>. </p>
<blockquote>
<p>è‡ªä¸»ä»£ç†çš„å‡ºç°ï¼Œé€šè¿‡è¿ç”¨è‡ªç„¶è¯­è¨€ä½œä¸ºå¼ºå¤§çš„ä¸­ä»‹ï¼Œæ­£åœ¨æ”¹å˜ä¸å›¾å½¢ç”¨æˆ·ç•Œé¢ï¼ˆGUIï¼‰çš„äº¤äº’æ–¹å¼ã€‚å°½ç®¡å½“å‰GUIä»£ç†åœ¨å®ç°ç©ºé—´å®šä½æ—¶ä»¥ç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰æ–¹æ³•ä¸ºä¸»ï¼Œä½†è¿™äº›æ–¹æ³•é¢ä¸´ç€å·¨å¤§çš„æŒ‘æˆ˜ï¼Œå› ä¸ºå®ƒä»¬å‡†ç¡®æ„ŸçŸ¥ä½ç½®æ•°æ®çš„èƒ½åŠ›æœ‰é™ã€‚ç°æœ‰çš„ç­–ç•¥ï¼Œå¦‚å¼ºåŒ–å­¦ä¹ ï¼Œå¾€å¾€ä¸èƒ½æœ‰æ•ˆåœ°è¯„ä¼°ä½ç½®å‡†ç¡®æ€§ï¼Œä»è€Œé™åˆ¶äº†å®ƒä»¬çš„å®ç”¨æ€§ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä½ç½®åå¥½ä¼˜åŒ–ï¼ˆLPOï¼‰è¿™ä¸€æ–°æ–¹æ³•ï¼Œå®ƒåˆ©ç”¨ä½ç½®æ•°æ®æ¥ä¼˜åŒ–äº¤äº’åå¥½ã€‚LPOåˆ©ç”¨ä¿¡æ¯ç†µæ¥é¢„æµ‹äº¤äº’ä½ç½®ï¼Œä¾§é‡äºä¿¡æ¯ä¸°å¯Œçš„åŒºåŸŸã€‚æ­¤å¤–ï¼Œå®ƒè¿˜å¼•å…¥äº†ä¸€ä¸ªåŸºäºç‰©ç†è·ç¦»çš„åŠ¨æ€ä½ç½®å¥–åŠ±å‡½æ•°ï¼Œåæ˜ äº†äº¤äº’ä½ç½®çš„ä¸åŒé‡è¦æ€§ã€‚åœ¨Group Relative Preference Optimizationï¼ˆGRPOï¼‰çš„æ”¯æŒä¸‹ï¼ŒLPOä¿ƒè¿›äº†GUIç¯å¢ƒçš„å¹¿æ³›æ¢ç´¢ï¼Œå¹¶æ˜¾è‘—æé«˜äº†äº¤äº’ç²¾åº¦ã€‚ç»¼åˆå®éªŒè¡¨æ˜ï¼ŒLPOæ€§èƒ½å“è¶Šï¼Œåœ¨ç¦»çº¿åŸºå‡†æµ‹è¯•å’ŒçœŸå®ä¸–ç•Œåœ¨çº¿è¯„ä¼°ä¸­éƒ½å–å¾—äº†SOTAç»“æœã€‚æˆ‘ä»¬çš„ä»£ç å¾ˆå¿«å°†åœ¨<a target="_blank" rel="noopener" href="https://github.com/AIDC-AI/LPO">https://github.com/AIDC-AI/LPO</a>ä¸Šå…¬å¼€ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.09373v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>è‡ªä¸»ä»£ç†çš„å‡ºç°æ­£åœ¨é€šè¿‡é‡‡ç”¨è‡ªç„¶è¯­è¨€ä½œä¸ºå¼ºå¤§çš„ä¸­ä»‹æ¥å˜é©ä¸å›¾å½¢ç”¨æˆ·ç•Œé¢ï¼ˆGUIï¼‰çš„äº’åŠ¨æ–¹å¼ã€‚å½“å‰GUIä»£ç†ä¸»è¦ä½¿ç”¨ç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰æ–¹æ³•å®ç°ç©ºé—´å®šä½ï¼Œä½†é¢ä¸´å‡†ç¡®æ„ŸçŸ¥å®šä½æ•°æ®çš„æŒ‘æˆ˜ã€‚ä¸ºåº”å¯¹è¿™ä¸€æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä½ç½®åå¥½ä¼˜åŒ–ï¼ˆLPOï¼‰è¿™ä¸€æ–°æ–¹æ³•ï¼Œå®ƒåˆ©ç”¨ä½ç½®æ•°æ®ä¼˜åŒ–äº’åŠ¨åå¥½ã€‚LPOä½¿ç”¨ä¿¡æ¯ç†µé¢„æµ‹äº¤äº’ä½ç½®ï¼Œä¸“æ³¨äºä¿¡æ¯ä¸°å¯Œçš„åŒºåŸŸï¼Œå¹¶å¼•å…¥åŸºäºç‰©ç†è·ç¦»çš„åŠ¨æ€ä½ç½®å¥–åŠ±å‡½æ•°ï¼Œåæ˜ äº¤äº’ä½ç½®çš„ä¸åŒé‡è¦æ€§ã€‚LPOé…åˆç¾¤ä½“ç›¸å¯¹åå¥½ä¼˜åŒ–ï¼ˆGRPOï¼‰ï¼Œä¿ƒè¿›äº†GUIç¯å¢ƒçš„å¹¿æ³›æ¢ç´¢ï¼Œå¹¶æ˜¾è‘—æé«˜äº¤äº’ç²¾åº¦ã€‚å®éªŒè¡¨æ˜ï¼ŒLPOçš„æ€§èƒ½å“è¶Šï¼Œåœ¨ç¦»çº¿åŸºå‡†æµ‹è¯•å’ŒçœŸå®åœ¨çº¿è¯„ä¼°ä¸­éƒ½è¾¾åˆ°äº†æœ€æ–°æ°´å¹³ã€‚æˆ‘ä»¬çš„ä»£ç å°†å¾ˆå¿«åœ¨<a target="_blank" rel="noopener" href="https://github.com/AIDC-AI/LPO%E5%85%AC%E5%BC%80%E3%80%82">https://github.com/AIDC-AI/LPOå…¬å¼€ã€‚</a></p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>è‡ªä¸»ä»£ç†é€šè¿‡è‡ªç„¶è¯­è¨€ä¸­ä»‹æ”¹å˜ä¸GUIçš„äº’åŠ¨æ–¹å¼ã€‚</li>
<li>ç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰æ–¹æ³•åœ¨GUIä»£ç†çš„ç©ºé—´å®šä½ä¸Šè™½æœ‰å¹¿æ³›åº”ç”¨ï¼Œä½†å­˜åœ¨å‡†ç¡®æ„ŸçŸ¥å®šä½æ•°æ®çš„æŒ‘æˆ˜ã€‚</li>
<li>ä½ç½®åå¥½ä¼˜åŒ–ï¼ˆLPOï¼‰æ–°æ–¹æ³•åˆ©ç”¨ä½ç½®æ•°æ®ä¼˜åŒ–äº’åŠ¨åå¥½ã€‚</li>
<li>LPOä½¿ç”¨ä¿¡æ¯ç†µé¢„æµ‹äº¤äº’ä½ç½®ï¼Œä¸“æ³¨äºä¿¡æ¯ä¸°å¯Œçš„åŒºåŸŸã€‚</li>
<li>LPOå¼•å…¥åŠ¨æ€ä½ç½®å¥–åŠ±å‡½æ•°ï¼Œåæ˜ äº¤äº’ä½ç½®çš„ä¸åŒé‡è¦æ€§ã€‚</li>
<li>LPOé…åˆç¾¤ä½“ç›¸å¯¹åå¥½ä¼˜åŒ–ï¼ˆGRPOï¼‰ï¼Œä¿ƒè¿›GUIç¯å¢ƒçš„å¹¿æ³›æ¢ç´¢ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.09373">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-16c66ecf37df6ff1c4a0c1ed7044158e.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-81f6d466210a8f2a3f15eba28dbd2d1f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f2339f60031315509f905003087eeda9.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="TACTIC-Translation-Agents-with-Cognitive-Theoretic-Interactive-Collaboration"><a href="#TACTIC-Translation-Agents-with-Cognitive-Theoretic-Interactive-Collaboration" class="headerlink" title="TACTIC: Translation Agents with Cognitive-Theoretic Interactive   Collaboration"></a>TACTIC: Translation Agents with Cognitive-Theoretic Interactive   Collaboration</h2><p><strong>Authors:Weiya Li, Junjie Chen, Bei Li, Boyang Liu, Zichen Wen, Nuanqiao Shan, Xiaoqian Liu, Anping Liu, Huajie Liu, Hu Song, Linfeng Zhang</strong></p>
<p>Machine translation has long been a central task in natural language processing. With the rapid advancement of large language models (LLMs), there has been remarkable progress in translation quality. However, fully realizing the translation potential of LLMs remains an open challenge. Recent studies have explored multi-agent systems to decompose complex translation tasks into collaborative subtasks, showing initial promise in enhancing translation quality through agent cooperation and specialization. Nevertheless, existing multi-agent translation frameworks largely neglect foundational insights from cognitive translation studies. These insights emphasize how human translators employ different cognitive strategies, such as balancing literal and free translation, refining expressions based on context, and iteratively evaluating outputs. To address this limitation, we propose a cognitively informed multi-agent framework called TACTIC, which stands for T ranslation A gents with Cognitive- T heoretic Interactive Collaboration. The framework comprises six functionally distinct agents that mirror key cognitive processes observed in human translation behavior. These include agents for drafting, refinement, evaluation, scoring, context reasoning, and external knowledge gathering. By simulating an interactive and theory-grounded translation workflow, TACTIC effectively leverages the full capacity of LLMs for high-quality translation. Experimental results on diverse language pairs from the FLORES-200 and WMT24 benchmarks show that our method consistently achieves state-of-the-art performance. Using DeepSeek-V3 as the base model, TACTIC surpasses GPT-4.1 by an average of +0.6 XCOMET and +1.18 COMETKIWI-23. Compared to DeepSeek-R1, it further improves by +0.84 XCOMET and +2.99 COMETKIWI-23. Code is available at <a target="_blank" rel="noopener" href="https://github.com/weiyali126/TACTIC">https://github.com/weiyali126/TACTIC</a>. </p>
<blockquote>
<p>æœºå™¨ç¿»è¯‘ä¸€ç›´æ˜¯è‡ªç„¶è¯­è¨€å¤„ç†ä¸­çš„æ ¸å¿ƒä»»åŠ¡ã€‚éšç€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„å¿«é€Ÿå‘å±•ï¼Œç¿»è¯‘è´¨é‡å–å¾—äº†æ˜¾è‘—çš„è¿›æ­¥ã€‚ç„¶è€Œï¼Œå®Œå…¨å®ç°LLMsçš„ç¿»è¯‘æ½œåŠ›ä»ç„¶æ˜¯ä¸€ä¸ªå¼€æ”¾æ€§çš„æŒ‘æˆ˜ã€‚æœ€è¿‘çš„ç ”ç©¶æ¢ç´¢äº†å¤šæ™ºèƒ½ä½“ç³»ç»Ÿå°†å¤æ‚çš„ç¿»è¯‘ä»»åŠ¡åˆ†è§£æˆåä½œçš„å­ä»»åŠ¡ï¼Œé€šè¿‡æ™ºèƒ½ä½“çš„åˆä½œå’Œä¸“ä¸šåŒ–ï¼Œåˆæ­¥æ˜¾ç¤ºå‡ºæé«˜ç¿»è¯‘è´¨é‡çš„å¸Œæœ›ã€‚ç„¶è€Œï¼Œç°æœ‰çš„å¤šæ™ºèƒ½ä½“ç¿»è¯‘æ¡†æ¶å¤§å¤šå¿½è§†äº†æ¥è‡ªè®¤çŸ¥ç¿»è¯‘ç ”ç©¶çš„è§è§£ã€‚è¿™äº›è§è§£å¼ºè°ƒäººç±»è¯‘è€…å¦‚ä½•é‡‡ç”¨ä¸åŒçš„è®¤çŸ¥ç­–ç•¥ï¼Œå¦‚å¹³è¡¡ç›´è¯‘å’Œæ„è¯‘ã€æ ¹æ®ä¸Šä¸‹æ–‡ä¼˜åŒ–è¡¨è¾¾ã€ä»¥åŠè¿­ä»£è¯„ä¼°è¾“å‡ºã€‚ä¸ºäº†è§£å†³è¿™ä¸€å±€é™æ€§ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªå—è®¤çŸ¥å¯å‘çš„å¤šæ™ºèƒ½ä½“æ¡†æ¶ï¼Œåä¸ºTACTICï¼Œä»£è¡¨ç¿»è¯‘è®¤çŸ¥ç†è®ºäº¤äº’åä½œçš„æ™ºèƒ½ä½“ã€‚è¯¥æ¡†æ¶åŒ…æ‹¬å…­ä¸ªåŠŸèƒ½å„å¼‚çš„æ™ºèƒ½ä½“ï¼Œè¿™äº›æ™ºèƒ½ä½“åæ˜ äº†äººç±»ç¿»è¯‘è¡Œä¸ºä¸­è§‚å¯Ÿåˆ°çš„å…³é”®è®¤çŸ¥è¿‡ç¨‹ã€‚åŒ…æ‹¬èµ·è‰æ™ºèƒ½ä½“ã€ä¼˜åŒ–æ™ºèƒ½ä½“ã€è¯„ä¼°æ™ºèƒ½ä½“ã€æ‰“åˆ†æ™ºèƒ½ä½“ã€ä¸Šä¸‹æ–‡æ¨ç†æ™ºèƒ½ä½“ä»¥åŠå¤–éƒ¨çŸ¥è¯†æ”¶é›†æ™ºèƒ½ä½“ã€‚é€šè¿‡æ¨¡æ‹Ÿäº¤äº’å’ŒåŸºäºç†è®ºçš„ç¿»è¯‘å·¥ä½œæµç¨‹ï¼ŒTACTICæœ‰æ•ˆåœ°åˆ©ç”¨LLMsçš„å…¨éƒ¨èƒ½åŠ›å®ç°é«˜è´¨é‡ç¿»è¯‘ã€‚åœ¨FLORES-200å’ŒWMT24åŸºå‡†æµ‹è¯•ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•å§‹ç»ˆè¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚ä»¥DeepSeek-V3ä¸ºåŸºç¡€æ¨¡å‹ï¼ŒTACTICå¹³å‡è¶…è¿‡GPT-4.1ï¼ŒXCOMETæé«˜+0.6ï¼ŒCOMETKIWI-23æé«˜+1.18ã€‚ä¸DeepSeek-R1ç›¸æ¯”ï¼Œè¿›ä¸€æ­¥æé«˜XCOMET+0.84å’ŒCOMETKIWI-23+2.99ã€‚ä»£ç å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/weiyali126/TACTIC%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/weiyali126/TACTICæ‰¾åˆ°ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.08403v2">PDF</a> 20 pages, 4 figures, Under review. Code:   <a target="_blank" rel="noopener" href="https://github.com/weiyali126/TACTIC">https://github.com/weiyali126/TACTIC</a></p>
<p><strong>Summary</strong><br>     éšç€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„å¿«é€Ÿå‘å±•ï¼Œæœºå™¨ç¿»è¯‘çš„è´¨é‡å–å¾—äº†æ˜¾è‘—è¿›æ­¥ã€‚ä¸ºè¿›ä¸€æ­¥æé«˜ç¿»è¯‘è´¨é‡ï¼Œç ”ç©¶é‡‡ç”¨å¤šæ™ºèƒ½ä½“ç³»ç»Ÿåˆ†è§£å¤æ‚ç¿»è¯‘ä»»åŠ¡ã€‚é’ˆå¯¹ç°æœ‰æ¡†æ¶å¿½ç•¥è®¤çŸ¥ç¿»è¯‘ç ”ç©¶çš„é—®é¢˜ï¼Œæå‡ºäº†TACTICæ¡†æ¶ï¼Œé€šè¿‡æ¨¡æ‹Ÿäººç±»ç¿»è¯‘è¡Œä¸ºçš„å…³é”®è®¤çŸ¥è¿‡ç¨‹ï¼Œå®ç°äº†åŸºäºç†è®ºåŸºç¡€çš„äº¤äº’å¼åä½œç¿»è¯‘ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ¡†æ¶åœ¨å„ç§è¯­è¨€å¯¹ä¸Šå‡è¾¾åˆ°äº†æœ€æ–°çš„æ€§èƒ½æ°´å¹³ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„å¿«é€Ÿå‘å±•æ˜¾è‘—æé«˜äº†æœºå™¨ç¿»è¯‘çš„è´¨é‡ã€‚</li>
<li>å¤šæ™ºèƒ½ä½“ç³»ç»Ÿè¢«ç”¨äºåˆ†è§£å¤æ‚çš„ç¿»è¯‘ä»»åŠ¡ï¼Œåˆæ­¥æ˜¾ç¤ºå‡ºé€šè¿‡æ™ºèƒ½ä½“åä½œå’Œä¸“ä¸šåŒ–æé«˜ç¿»è¯‘è´¨é‡çš„æ½œåŠ›ã€‚</li>
<li>ç°æœ‰æœºå™¨ç¿»è¯‘æ¡†æ¶å¿½ç•¥äº†è®¤çŸ¥ç¿»è¯‘ç ”ç©¶çš„å…³é”®è§è§£ã€‚</li>
<li>TACTICæ¡†æ¶æ˜¯ä¸€ä¸ªè®¤çŸ¥å¯å‘çš„å¤šæ™ºèƒ½ä½“æ¡†æ¶ï¼Œæ¨¡æ‹Ÿäººç±»ç¿»è¯‘è¡Œä¸ºä¸­çš„å…³é”®è®¤çŸ¥è¿‡ç¨‹ã€‚</li>
<li>TACTICæ¡†æ¶åŒ…æ‹¬è´Ÿè´£èµ·è‰ã€æ”¹è¿›ã€è¯„ä¼°ã€æ‰“åˆ†ã€ä¸Šä¸‹æ–‡æ¨ç†å’Œå¤–éƒ¨çŸ¥è¯†æ”¶é›†çš„å…­ä¸ªåŠŸèƒ½ç‹¬ç‰¹çš„æ™ºèƒ½ä½“ã€‚</li>
<li>TACTICæ¡†æ¶é€šè¿‡æ¨¡æ‹Ÿç†è®ºåŸºç¡€çš„äº¤äº’å¼ç¿»è¯‘å·¥ä½œæµç¨‹ï¼Œæœ‰æ•ˆåœ°åˆ©ç”¨LLMsçš„å…¨éƒ¨èƒ½åŠ›å®ç°é«˜è´¨é‡ç¿»è¯‘ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.08403">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-053169056f2ff854833e43bd493903eb.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-3bd90291c04e414fe8d4bb72f74b83de.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-7956cbdcea204e2eb142880833239a03.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-07c8fd77165b3d84f5497850e2d39a86.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-3ccb951654ecac392c907719c819465a.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="HiBerNAC-Hierarchical-Brain-emulated-Robotic-Neural-Agent-Collective-for-Disentangling-Complex-Manipulation"><a href="#HiBerNAC-Hierarchical-Brain-emulated-Robotic-Neural-Agent-Collective-for-Disentangling-Complex-Manipulation" class="headerlink" title="HiBerNAC: Hierarchical Brain-emulated Robotic Neural Agent Collective   for Disentangling Complex Manipulation"></a>HiBerNAC: Hierarchical Brain-emulated Robotic Neural Agent Collective   for Disentangling Complex Manipulation</h2><p><strong>Authors:Hongjun Wu, Heng Zhang, Pengsong Zhang, Jin Wang, Cong Wang</strong></p>
<p>Recent advances in multimodal vision-language-action (VLA) models have revolutionized traditional robot learning, enabling systems to interpret vision, language, and action in unified frameworks for complex task planning. However, mastering complex manipulation tasks remains an open challenge, constrained by limitations in persistent contextual memory, multi-agent coordination under uncertainty, and dynamic long-horizon planning across variable sequences. To address this challenge, we propose \textbf{HiBerNAC}, a \textbf{Hi}erarchical \textbf{B}rain-\textbf{e}mulated \textbf{r}obotic \textbf{N}eural \textbf{A}gent \textbf{C}ollective, inspired by breakthroughs in neuroscience, particularly in neural circuit mechanisms and hierarchical decision-making. Our framework combines: (1) multimodal VLA planning and reasoning with (2) neuro-inspired reflection and multi-agent mechanisms, specifically designed for complex robotic manipulation tasks. By leveraging neuro-inspired functional modules with decentralized multi-agent collaboration, our approach enables robust and enhanced real-time execution of complex manipulation tasks. In addition, the agentic system exhibits scalable collective intelligence via dynamic agent specialization, adapting its coordination strategy to variable task horizons and complexity. Through extensive experiments on complex manipulation tasks compared with state-of-the-art VLA models, we demonstrate that \textbf{HiBerNAC} reduces average long-horizon task completion time by 23%, and achieves non-zero success rates (12\textendash 31%) on multi-path tasks where prior state-of-the-art VLA models consistently fail. These results provide indicative evidence for bridging biological cognition and robotic learning mechanisms. </p>
<blockquote>
<p>è¿‘æœŸå¤šæ¨¡æ€è§†è§‰è¯­è¨€åŠ¨ä½œï¼ˆVLAï¼‰æ¨¡å‹çš„è¿›æ­¥å·²ç»å½»åº•æ”¹å˜äº†ä¼ ç»Ÿæœºå™¨äººå­¦ä¹ çš„æ–¹å¼ï¼Œä½¿ç³»ç»Ÿåœ¨ç»Ÿä¸€çš„æ¡†æ¶ä¸‹è§£é‡Šè§†è§‰ã€è¯­è¨€å’Œè¡Œä¸ºï¼Œä»è€Œè¿›è¡Œå¤æ‚çš„ä»»åŠ¡è§„åˆ’ã€‚ç„¶è€Œï¼ŒæŒæ¡å¤æ‚çš„æ“ä½œä»»åŠ¡ä»ç„¶æ˜¯ä¸€ä¸ªå…¬å¼€çš„æŒ‘æˆ˜ï¼Œå—åˆ°æŒç»­ä¸Šä¸‹æ–‡è®°å¿†çš„é™åˆ¶ã€ä¸ç¡®å®šæ€§ä¸‹çš„å¤šæ™ºèƒ½ä½“åè°ƒå’Œå¯å˜åºåˆ—ä¸­çš„åŠ¨æ€é•¿æœŸè§„åˆ’ã€‚ä¸ºäº†åº”å¯¹è¿™ä¸€æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†HiBerNACï¼Œè¿™æ˜¯ä¸€ä¸ªå—ç¥ç»ç§‘å­¦çªç ´å¯å‘çš„åˆ†å±‚è„‘æ¨¡æ‹Ÿæœºå™¨äººç¥ç»ç½‘ç»œé›†ä½“ï¼ˆHierarchical Brain-emulated Robotic Neural Agent Collectiveï¼‰ã€‚ç‰¹åˆ«æ˜¯å—åˆ°ç¥ç»ç½‘ç»œæœºåˆ¶å’Œåˆ†å±‚å†³ç­–åˆ¶å®šçš„å¯å‘ã€‚æˆ‘ä»¬çš„æ¡†æ¶ç»“åˆäº†ï¼ˆ1ï¼‰å¤šæ¨¡æ€VLAè§„åˆ’å’Œæ¨ç†ä¸ï¼ˆ2ï¼‰ç¥ç»å¯å‘åæ€å’Œå¤šæ™ºèƒ½ä½“æœºåˆ¶ï¼Œä¸“ä¸ºå¤æ‚çš„æœºå™¨äººæ“ä½œä»»åŠ¡è®¾è®¡ã€‚é€šè¿‡åˆ©ç”¨ç¥ç»å¯å‘çš„åŠŸèƒ½æ¨¡å—å’Œåˆ†æ•£çš„å¤šæ™ºèƒ½ä½“åä½œï¼Œæˆ‘ä»¬çš„æ–¹æ³•èƒ½å¤Ÿå®ç°å¤æ‚æ“ä½œä»»åŠ¡çš„ç¨³å¥å’Œå¢å¼ºå®æ—¶æ‰§è¡Œã€‚æ­¤å¤–ï¼Œè¯¥æ™ºèƒ½ç³»ç»Ÿé€šè¿‡åŠ¨æ€æ™ºèƒ½ä½“ä¸“ä¸šåŒ–å±•ç°å‡ºå¯æ‰©å±•çš„é›†ä½“æ™ºèƒ½ï¼Œä½¿å…¶åè°ƒç­–ç•¥é€‚åº”å¯å˜çš„ä»»åŠ¡èŒƒå›´å’Œå¤æ‚æ€§ã€‚ä¸æœ€æ–°çš„VLAæ¨¡å‹ç›¸æ¯”çš„å¤§è§„æ¨¡å®éªŒè¡¨æ˜ï¼ŒHiBerNACå‡å°‘äº†å¹³å‡é•¿æœŸä»»åŠ¡å®Œæˆæ—¶é—´çš„ç™¾åˆ†ä¹‹äºŒåä¸‰ï¼Œå¹¶åœ¨å¤šè·¯å¾„ä»»åŠ¡ä¸Šå®ç°äº†éé›¶æˆåŠŸç‡ï¼ˆç™¾åˆ†ä¹‹åäºŒè‡³ä¸‰åä¸€ï¼‰ï¼Œè€Œä¹‹å‰çš„æœ€æ–°VLAæ¨¡å‹åˆ™ä¸€ç›´æœªèƒ½æˆåŠŸå®Œæˆè¿™äº›ä»»åŠ¡ã€‚è¿™äº›ç»“æœæä¾›äº†å°†ç”Ÿç‰©è®¤çŸ¥å’Œæœºå™¨äººå­¦ä¹ æœºåˆ¶è”ç³»èµ·æ¥çš„æŒ‡ç¤ºæ€§è¯æ®ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.08296v2">PDF</a> 31 pages,5 figures</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†æœ€æ–°è¿›å±•çš„å¤šæ¨¡æ€è§†è§‰è¯­è¨€åŠ¨ä½œï¼ˆVLAï¼‰æ¨¡å‹å¯¹æœºå™¨äººå­¦ä¹ çš„å½±å“ï¼Œå®ƒå®ç°äº†å¤æ‚çš„ä»»åŠ¡è§„åˆ’ä¸­çš„è§†è§‰ã€è¯­è¨€å’ŒåŠ¨ä½œçš„ç»Ÿä¸€è§£é‡Šã€‚é’ˆå¯¹æŒæ¡å¤æ‚æ“ä½œä»»åŠ¡çš„æŒ‘æˆ˜ï¼Œå¦‚æŒç»­ä¸Šä¸‹æ–‡è®°å¿†çš„é™åˆ¶ã€ä¸ç¡®å®šä¸‹çš„å¤šæ™ºèƒ½ä½“åè°ƒä»¥åŠè·¨è¶Šå¯å˜åºåˆ—çš„åŠ¨æ€é•¿æœŸè§„åˆ’ç­‰ï¼Œæœ¬æ–‡æå‡ºäº†åŸºäºç¥ç»ç§‘å­¦å¯å‘çš„åˆ†å±‚ç¥ç»æœºå™¨äººé›†ä½“ï¼ˆHiBerNACï¼‰ã€‚å®ƒç»“åˆäº†å¤šæ¨¡æ€VLAè§„åˆ’å’Œæ¨ç†ï¼Œä»¥åŠç¥ç»å¯å‘çš„åæ€å’Œå¤šæ™ºèƒ½ä½“æœºåˆ¶ï¼Œç‰¹åˆ«æ˜¯é’ˆå¯¹å¤æ‚çš„æœºå™¨äººæ“ä½œä»»åŠ¡è€Œè®¾è®¡ã€‚é€šè¿‡åˆ©ç”¨ç¥ç»å¯å‘çš„åŠŸèƒ½æ¨¡å—ä¸åˆ†æ•£å¼å¤šæ™ºèƒ½ä½“åä½œï¼ŒHiBerNACèƒ½å¤Ÿç¨³å¥åœ°æ‰§è¡Œå¤æ‚çš„æ“ä½œä»»åŠ¡å¹¶å¢å¼ºå®æ—¶æ€§èƒ½ã€‚æ­¤å¤–ï¼Œè¯¥ç³»ç»Ÿé€šè¿‡åŠ¨æ€æ™ºèƒ½ä½“ä¸“ä¸šåŒ–å±•ç°å‡ºå¯ä¼¸ç¼©çš„é›†ä½“æ™ºèƒ½ï¼Œèƒ½å¤Ÿé€‚åº”å¯å˜çš„ä»»åŠ¡èŒƒå›´å’Œå¤æ‚æ€§ã€‚å®éªŒè¡¨æ˜ï¼ŒHiBerNACåœ¨å¤æ‚çš„æ“ä½œä»»åŠ¡ä¸Šç›¸è¾ƒäºæœ€æ–°çš„VLAæ¨¡å‹å‡å°‘äº†å¹³å‡é•¿æœŸä»»åŠ¡å®Œæˆæ—¶é—´ï¼Œå¹¶åœ¨å¤šè·¯å¾„ä»»åŠ¡ä¸Šå–å¾—äº†éé›¶çš„æˆåŠŸç‡ã€‚è¿™ä¸ºç”Ÿç‰©è®¤çŸ¥ä¸æœºå™¨äººå­¦ä¹ æœºåˆ¶çš„èåˆæä¾›äº†æœ‰åŠ›çš„è¯æ®ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤šæ¨¡æ€è§†è§‰è¯­è¨€åŠ¨ä½œï¼ˆVLAï¼‰æ¨¡å‹çš„æœ€æ–°è¿›å±•ä¸ºæœºå™¨äººå­¦ä¹ å¸¦æ¥äº†é©å‘½æ€§çš„å˜åŒ–ï¼Œä½¿å¾—ç³»ç»Ÿèƒ½å¤Ÿåœ¨ç»Ÿä¸€çš„æ¡†æ¶å†…è§£é‡Šè§†è§‰ã€è¯­è¨€å’ŒåŠ¨ä½œï¼Œä»è€Œå®ç°å¤æ‚çš„ä»»åŠ¡è§„åˆ’ã€‚</li>
<li>é¢å¯¹æŒæ¡å¤æ‚æ“ä½œä»»åŠ¡çš„æŒ‘æˆ˜ï¼Œå¦‚æŒç»­ä¸Šä¸‹æ–‡è®°å¿†çš„é™åˆ¶ã€ä¸ç¡®å®šä¸‹çš„å¤šæ™ºèƒ½ä½“åè°ƒä»¥åŠåŠ¨æ€é•¿æœŸè§„åˆ’ç­‰ï¼Œå­˜åœ¨åˆ¶çº¦å› ç´ ã€‚</li>
<li>æå‡ºäº†åŸºäºç¥ç»ç§‘å­¦å¯å‘çš„åˆ†å±‚ç¥ç»æœºå™¨äººé›†ä½“ï¼ˆHiBerNACï¼‰æ¡†æ¶ï¼Œç»“åˆäº†å¤šæ¨¡æ€VLAè§„åˆ’å’Œæ¨ç†ï¼Œä»¥åŠç¥ç»å¯å‘çš„åæ€å’Œå¤šæ™ºèƒ½ä½“æœºåˆ¶ã€‚</li>
<li>HiBerNACé€šè¿‡åˆ©ç”¨ç¥ç»å¯å‘çš„åŠŸèƒ½æ¨¡å—ä¸åˆ†æ•£å¼å¤šæ™ºèƒ½ä½“åä½œï¼Œèƒ½å¤Ÿç¨³å¥åœ°æ‰§è¡Œå¤æ‚çš„æ“ä½œä»»åŠ¡å¹¶å¢å¼ºå®æ—¶æ€§èƒ½ã€‚</li>
<li>HiBerNACå±•ç°å‡ºå¯ä¼¸ç¼©çš„é›†ä½“æ™ºèƒ½ï¼Œèƒ½å¤Ÿé€‚åº”å¯å˜çš„ä»»åŠ¡èŒƒå›´å’Œå¤æ‚æ€§ï¼Œé€šè¿‡åŠ¨æ€æ™ºèƒ½ä½“ä¸“ä¸šåŒ–å®ç°ã€‚</li>
<li>å®éªŒè¡¨æ˜ï¼ŒHiBerNACç›¸è¾ƒäºæœ€æ–°çš„VLAæ¨¡å‹åœ¨å¤æ‚çš„æ“ä½œä»»åŠ¡ä¸Šè¡¨ç°æ›´ä¼˜ï¼Œå‡å°‘äº†ä»»åŠ¡å®Œæˆæ—¶é—´ï¼Œå¹¶åœ¨å¤šè·¯å¾„ä»»åŠ¡ä¸Šå–å¾—äº†éé›¶çš„æˆåŠŸç‡ã€‚</li>
<li>è¿™äº›ç»“æœä¸ºç”Ÿç‰©è®¤çŸ¥ä¸æœºå™¨äººå­¦ä¹ æœºåˆ¶çš„èåˆæä¾›äº†æœ‰åŠ›çš„è¯æ®ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.08296">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-13996307e925da10bdf03a22284552af.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-b50acf4dc0bca60d09e587feddb34082.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-406e97c14d05c1cfc6259414ad91483e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-3991cfbd9fa2aef9ad238d6a3b5fff2e.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="SAFEFLOW-A-Principled-Protocol-for-Trustworthy-and-Transactional-Autonomous-Agent-Systems"><a href="#SAFEFLOW-A-Principled-Protocol-for-Trustworthy-and-Transactional-Autonomous-Agent-Systems" class="headerlink" title="SAFEFLOW: A Principled Protocol for Trustworthy and Transactional   Autonomous Agent Systems"></a>SAFEFLOW: A Principled Protocol for Trustworthy and Transactional   Autonomous Agent Systems</h2><p><strong>Authors:Peiran Li, Xinkai Zou, Zhuohang Wu, Ruifeng Li, Shuo Xing, Hanwen Zheng, Zhikai Hu, Yuping Wang, Haoxi Li, Qin Yuan, Yingmo Zhang, Zhengzhong Tu</strong></p>
<p>Recent advances in large language models (LLMs) and vision-language models (VLMs) have enabled powerful autonomous agents capable of complex reasoning and multi-modal tool use. Despite their growing capabilities, todayâ€™s agent frameworks remain fragile, lacking principled mechanisms for secure information flow, reliability, and multi-agent coordination. In this work, we introduce SAFEFLOW, a new protocol-level framework for building trustworthy LLM&#x2F;VLM-based agents. SAFEFLOW enforces fine-grained information flow control (IFC), precisely tracking provenance, integrity, and confidentiality of all the data exchanged between agents, tools, users, and environments. By constraining LLM reasoning to respect these security labels, SAFEFLOW prevents untrusted or adversarial inputs from contaminating high-integrity decisions. To ensure robustness in concurrent multi-agent settings, SAFEFLOW introduces transactional execution, conflict resolution, and secure scheduling over shared state, preserving global consistency across agents. We further introduce mechanisms, including write-ahead logging, rollback, and secure caches, that further enhance resilience against runtime errors and policy violations. To validate the performances, we built SAFEFLOWBENCH, a comprehensive benchmark suite designed to evaluate agent reliability under adversarial, noisy, and concurrent operational conditions. Extensive experiments demonstrate that agents built with SAFEFLOW maintain impressive task performance and security guarantees even in hostile environments, substantially outperforming state-of-the-art. Together, SAFEFLOW and SAFEFLOWBENCH lay the groundwork for principled, robust, and secure agent ecosystems, advancing the frontier of reliable autonomy. </p>
<blockquote>
<p>æœ€è¿‘çš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å’Œè§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMï¼‰çš„è¿›æ­¥ï¼Œå·²ç»ä½¿å¾—å¼ºå¤§çš„è‡ªä¸»ä»£ç†èƒ½å¤Ÿå®Œæˆå¤æ‚çš„æ¨ç†å’Œå¤šæ¨¡å¼å·¥å…·ä½¿ç”¨ã€‚å°½ç®¡å®ƒä»¬çš„èƒ½åŠ›ä¸æ–­å¢é•¿ï¼Œä½†ç›®å‰çš„ä»£ç†æ¡†æ¶ä»ç„¶è„†å¼±ï¼Œç¼ºä¹å®‰å…¨ä¿¡æ¯æµåŠ¨ã€å¯é æ€§å’Œå¤šä»£ç†åè°ƒçš„åŸåˆ™æ€§æœºåˆ¶ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬ä»‹ç»äº†SAFEFLOWï¼Œè¿™æ˜¯ä¸€ä¸ªç”¨äºæ„å»ºå¯ä¿¡çš„LLM&#x2F;VLMä»£ç†åè®®çº§æ¡†æ¶ã€‚SAFEFLOWå¼ºåˆ¶å®æ–½ç²¾ç»†çš„ä¿¡æ¯æµæ§åˆ¶ï¼ˆIFCï¼‰ï¼Œç²¾ç¡®è·Ÿè¸ªä»£ç†ã€å·¥å…·ã€ç”¨æˆ·å’Œç¯å¢ƒä¹‹é—´äº¤æ¢çš„æ‰€æœ‰æ•°æ®çš„æ¥æºã€å®Œæ•´æ€§å’Œæœºå¯†æ€§ã€‚é€šè¿‡é™åˆ¶LLMæ¨ç†ä»¥å°Šé‡è¿™äº›å®‰å…¨æ ‡ç­¾ï¼ŒSAFEFLOWé˜²æ­¢ä¸å—ä¿¡ä»»æˆ–å¯¹æŠ—æ€§è¾“å…¥æ±¡æŸ“é«˜å®Œæ•´æ€§çš„å†³ç­–ã€‚ä¸ºäº†ç¡®ä¿åœ¨å¹¶å‘å¤šä»£ç†ç¯å¢ƒä¸­çš„ç¨³å¥æ€§ï¼ŒSAFEFLOWå¼•å…¥äº†äº‹åŠ¡æ‰§è¡Œã€å†²çªè§£å†³å’Œå…±äº«çŠ¶æ€çš„å®‰å…¨è°ƒåº¦ï¼Œä»¥ä¿ç•™å…¨å±€ä»£ç†ä¹‹é—´çš„ä¸€è‡´æ€§ã€‚æˆ‘ä»¬è¿˜å¼•å…¥äº†åŒ…æ‹¬é¢„å†™æ—¥å¿—ã€å›æ»šå’Œå®‰å…¨ç¼“å­˜ç­‰æœºåˆ¶ï¼Œè¿™äº›æœºåˆ¶è¿›ä¸€æ­¥å¢å¼ºäº†ç³»ç»Ÿå¯¹æŠ—è¿è¡Œæ—¶é”™è¯¯å’Œæ”¿ç­–è¿è§„çš„å¤åŸèƒ½åŠ›ã€‚ä¸ºäº†éªŒè¯æ€§èƒ½ï¼Œæˆ‘ä»¬æ„å»ºäº†SAFEFLOWBENCHï¼Œè¿™æ˜¯ä¸€å¥—ç»¼åˆåŸºå‡†æµ‹è¯•ï¼Œæ—¨åœ¨è¯„ä¼°ä»£ç†åœ¨æ•Œå¯¹ã€å˜ˆæ‚å’Œå¹¶å‘æ“ä½œæ¡ä»¶ä¸‹çš„å¯é æ€§ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼Œä½¿ç”¨SAFEFLOWæ„å»ºçš„ä»£ç†å³ä½¿åœ¨æ¶åŠ£ç¯å¢ƒä¸­ä¹Ÿèƒ½ä¿æŒä»¤äººå°è±¡æ·±åˆ»çš„ä»»åŠ¡æ€§èƒ½å’Œå®‰å…¨ä¿è¯ï¼Œæ˜¾è‘—ä¼˜äºå½“å‰æœ€æ–°æŠ€æœ¯ã€‚æ€»ä¹‹ï¼ŒSAFEFLOWå’ŒSAFEFLOWBENCHä¸ºç¨³å¥ä¸”å®‰å…¨çš„ä»£ç†ç”Ÿæ€ç³»ç»Ÿå¥ å®šäº†åŸºç¡€ï¼Œæ¨åŠ¨äº†å¯é è‡ªä¸»æ€§ç ”ç©¶çš„æœ€æ–°å‰æ²¿ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.07564v3">PDF</a> Former versions either contain unrelated content or cannot be   properly converted to PDF</p>
<p><strong>Summary</strong></p>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å’Œè§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMï¼‰çš„æœ€æ–°è¿›å±•å·²ç»å‚¬ç”Ÿäº†èƒ½å¤Ÿè¿›è¡Œå¤æ‚æ¨ç†å’Œå¤šæ¨¡æ€å·¥å…·ä½¿ç”¨çš„å¼ºå¤§è‡ªä¸»ä»£ç†ã€‚ç„¶è€Œï¼Œå½“å‰çš„ä»£ç†æ¡†æ¶ä»ç„¶è„†å¼±ï¼Œç¼ºä¹å®‰å…¨ä¿¡æ¯æµã€å¯é æ€§å’Œå¤šä»£ç†åè°ƒçš„æœºåˆ¶ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬å¼•å…¥äº†SAFEFLOWï¼Œä¸€ä¸ªä¸ºæ„å»ºå¯ä¿¡LLM&#x2F;VLMä»£ç†çš„æ–°åè®®çº§æ¡†æ¶ã€‚SAFEFLOWé€šè¿‡ç²¾ç»†çš„ä¿¡æ¯æµæ§åˆ¶ï¼ˆIFCï¼‰ç¡®ä¿æ•°æ®åœ¨ä»£ç†ã€å·¥å…·ã€ç”¨æˆ·å’Œç¯å¢ƒä¸­äº¤æ¢çš„å‡ºå¤„ã€å®Œæ•´æ€§å’Œæœºå¯†æ€§å¾—åˆ°ç²¾ç¡®è·Ÿè¸ªã€‚é€šè¿‡çº¦æŸLLMæ¨ç†ä»¥å°Šé‡è¿™äº›å®‰å…¨æ ‡ç­¾ï¼ŒSAFEFLOWé˜²æ­¢ä¸å—ä¿¡ä»»æˆ–å¯¹æŠ—æ€§è¾“å…¥æ±¡æŸ“é«˜å®Œæ•´æ€§å†³ç­–ã€‚ä¸ºç¡®ä¿åœ¨å¤šä»£ç†ç¯å¢ƒä¸­çš„å¹¶å‘ç¨³å¥æ€§ï¼ŒSAFEFLOWå¼•å…¥äº†äº‹åŠ¡æ‰§è¡Œã€å†²çªè§£å†³å’Œå®‰å…¨è°ƒåº¦æ¥ä¿æŒå…±äº«çŠ¶æ€çš„å…¨å±€ä¸€è‡´æ€§ã€‚é€šè¿‡ä¸€ç³»åˆ—æœºåˆ¶ï¼ŒåŒ…æ‹¬é¢„å†™æ—¥å¿—ã€å›æ»šå’Œå®‰å…¨ç¼“å­˜ï¼Œè¿›ä¸€æ­¥å¢å¼ºäº†å¯¹è¿è¡Œæ—¶é”™è¯¯å’Œæ”¿ç­–è¿è§„çš„æŠµå¾¡èƒ½åŠ›ã€‚ä¸ºäº†éªŒè¯æ€§èƒ½ï¼Œæˆ‘ä»¬æ„å»ºäº†SAFEFLOWBENCHï¼Œä¸€ä¸ªç»¼åˆåŸºå‡†æµ‹è¯•å¥—ä»¶ï¼Œæ—¨åœ¨è¯„ä¼°ä»£ç†åœ¨æ•Œå¯¹ã€å˜ˆæ‚å’Œå¹¶å‘æ“ä½œæ¡ä»¶ä¸‹çš„å¯é æ€§ã€‚å®éªŒè¡¨æ˜ï¼Œä½¿ç”¨SAFEFLOWæ„å»ºçš„ä»£ç†åœ¨ä¿æŒä»»åŠ¡æ€§èƒ½å’Œå®‰å…¨ä¿éšœçš„åŒæ—¶ï¼Œåœ¨æ•Œå¯¹ç¯å¢ƒä¸­æ˜¾è‘—ä¼˜äºç°æœ‰æŠ€æœ¯ã€‚SAFEFLOWå’ŒSAFEFLOWBENCHå…±åŒä¸ºæ„å»ºæœ‰åŸåˆ™ã€ç¨³å¥å’Œå®‰å…¨çš„ä»£ç†ç”Ÿæ€ç³»ç»Ÿå¥ å®šäº†åŸºç¡€ï¼Œæ¨åŠ¨äº†å¯é è‡ªä¸»æ€§å‰æ²¿çš„å‘å±•ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>LLMså’ŒVLMsçš„æœ€æ–°è¿›å±•å‚¬ç”Ÿäº†å…·æœ‰å¤æ‚æ¨ç†å’Œå¤šæ¨¡æ€å·¥å…·ä½¿ç”¨èƒ½åŠ›çš„å¼ºå¤§è‡ªä¸»ä»£ç†ã€‚</li>
<li>å½“å‰ä»£ç†æ¡†æ¶ç¼ºä¹å®‰å…¨ä¿¡æ¯æµã€å¯é æ€§å’Œå¤šä»£ç†åè°ƒæœºåˆ¶ï¼Œä»æ˜¾è„†å¼±ã€‚</li>
<li>SAFEFLOWæ¡†æ¶é€šè¿‡å¼ºåˆ¶ä¿¡æ¯æµæ§åˆ¶ç¡®ä¿æ•°æ®çš„å®‰å…¨æ€§å’Œå®Œæ•´æ€§ã€‚</li>
<li>SAFEFLOWé˜²æ­¢ä¸å—ä¿¡ä»»æˆ–å¯¹æŠ—æ€§è¾“å…¥å½±å“é«˜å®Œæ•´æ€§å†³ç­–ã€‚</li>
<li>SAFEFLOWé€šè¿‡äº‹åŠ¡æ‰§è¡Œã€å†²çªè§£å†³å’Œå®‰å…¨è°ƒåº¦ç¡®ä¿å¤šä»£ç†ç¯å¢ƒä¸­çš„ç¨³å¥æ€§ã€‚</li>
<li>SAFEFLOWå¼•å…¥äº†ä¸€ç³»åˆ—æœºåˆ¶ä»¥å¢å¼ºå¯¹è¿è¡Œæ—¶é”™è¯¯å’Œæ”¿ç­–è¿è§„çš„æŠµå¾¡èƒ½åŠ›ã€‚</li>
<li>SAFEFLOWBENCHåŸºå‡†æµ‹è¯•å¥—ä»¶ç”¨äºè¯„ä¼°ä»£ç†åœ¨æ•Œå¯¹å’Œå¹¶å‘æ“ä½œæ¡ä»¶ä¸‹çš„å¯é æ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.07564">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-e2f2bd31e684a135e7f158bb0cc473aa.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e8f1e40c16a973bee6c3946ea54b22b4.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d876d22601e61106212ce0886f8a1d6e.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="MedChat-A-Multi-Agent-Framework-for-Multimodal-Diagnosis-with-Large-Language-Models"><a href="#MedChat-A-Multi-Agent-Framework-for-Multimodal-Diagnosis-with-Large-Language-Models" class="headerlink" title="MedChat: A Multi-Agent Framework for Multimodal Diagnosis with Large   Language Models"></a>MedChat: A Multi-Agent Framework for Multimodal Diagnosis with Large   Language Models</h2><p><strong>Authors:Philip R. Liu, Sparsh Bansal, Jimmy Dinh, Aditya Pawar, Ramani Satishkumar, Shail Desai, Neeraj Gupta, Xin Wang, Shu Hu</strong></p>
<p>The integration of deep learning-based glaucoma detection with large language models (LLMs) presents an automated strategy to mitigate ophthalmologist shortages and improve clinical reporting efficiency. However, applying general LLMs to medical imaging remains challenging due to hallucinations, limited interpretability, and insufficient domain-specific medical knowledge, which can potentially reduce clinical accuracy. Although recent approaches combining imaging models with LLM reasoning have improved reporting, they typically rely on a single generalist agent, restricting their capacity to emulate the diverse and complex reasoning found in multidisciplinary medical teams. To address these limitations, we propose MedChat, a multi-agent diagnostic framework and platform that combines specialized vision models with multiple role-specific LLM agents, all coordinated by a director agent. This design enhances reliability, reduces hallucination risk, and enables interactive diagnostic reporting through an interface tailored for clinical review and educational use. Code available at <a target="_blank" rel="noopener" href="https://github.com/Purdue-M2/MedChat">https://github.com/Purdue-M2/MedChat</a>. </p>
<blockquote>
<p>æ·±åº¦å­¦ä¹ é©±åŠ¨çš„é’å…‰çœ¼æ£€æµ‹ä¸å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„é›†æˆï¼Œä¸ºè§£å†³çœ¼ç§‘åŒ»ç”ŸçŸ­ç¼ºé—®é¢˜å’Œæé«˜ä¸´åºŠæŠ¥å‘Šæ•ˆç‡æä¾›äº†è‡ªåŠ¨åŒ–ç­–ç•¥ã€‚ç„¶è€Œï¼Œç”±äºå‡ºç°å¹»è§‰ã€è§£é‡Šæ€§æœ‰é™ä»¥åŠé¢†åŸŸç‰¹å®šçš„åŒ»å­¦çŸ¥è¯†ä¸è¶³ç­‰é—®é¢˜ï¼Œå°†é€šç”¨LLMåº”ç”¨äºåŒ»å­¦å½±åƒä»å­˜åœ¨æŒ‘æˆ˜ï¼Œè¿™å¯èƒ½ä¼šé™ä½ä¸´åºŠå‡†ç¡®æ€§ã€‚è™½ç„¶è¿‘æœŸå°†æˆåƒæ¨¡å‹ä¸LLMæ¨ç†ç›¸ç»“åˆçš„æ–¹æ³•æ”¹å–„äº†æŠ¥å‘Šæ•ˆæœï¼Œä½†å®ƒä»¬é€šå¸¸ä¾èµ–äºå•ä¸€çš„å…¨èƒ½ä»£ç†ï¼Œé™åˆ¶äº†å…¶åœ¨æ¨¡æ‹Ÿå¤šå­¦ç§‘åŒ»ç–—å›¢é˜Ÿä¸­çš„å¤šæ ·åŒ–å’Œå¤æ‚æ¨ç†çš„èƒ½åŠ›ã€‚ä¸ºäº†è§£å†³è¿™äº›å±€é™æ€§ï¼Œæˆ‘ä»¬æå‡ºäº†MedChatï¼Œè¿™æ˜¯ä¸€ä¸ªå¤šä»£ç†è¯Šæ–­æ¡†æ¶å’Œå¹³å°ï¼Œå®ƒå°†ä¸“ä¸šçš„è§†è§‰æ¨¡å‹ä¸å¤šä¸ªç‰¹å®šè§’è‰²çš„LLMä»£ç†ç›¸ç»“åˆï¼Œæ‰€æœ‰ä»£ç†å‡ç”±å¯¼æ¼”ä»£ç†åè°ƒã€‚è¿™ç§è®¾è®¡æé«˜äº†å¯é æ€§ï¼Œé™ä½äº†å‡ºç°å¹»è§‰çš„é£é™©ï¼Œå¹¶é€šè¿‡ä¸€ä¸ªé’ˆå¯¹ä¸´åºŠå®¡æŸ¥å’Œæ•™è‚²ä½¿ç”¨çš„ç•Œé¢ï¼Œå®ç°äº†äº¤äº’å¼è¯Šæ–­æŠ¥å‘Šã€‚ç›¸å…³ä»£ç å¯é€šè¿‡<a target="_blank" rel="noopener" href="https://github.com/Purdue-M2/MedChat%E8%8E%B7%E5%8F%96%E3%80%82">https://github.com/Purdue-M2/MedChatè·å–ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.07400v2">PDF</a> 7 pages, 6 figures. Accepted to the 2025 IEEE 8th International   Conference on Multimedia Information Processing and Retrieval (MIPR)</p>
<p><strong>Summary</strong></p>
<p>æ·±åº¦å­¦ä¹ ç»“åˆå¤§å‹è¯­è¨€æ¨¡å‹åœ¨é’å…‰çœ¼æ£€æµ‹æ–¹é¢çš„åº”ç”¨ä¸ºç¼“è§£çœ¼ç§‘åŒ»ç”ŸçŸ­ç¼ºå’Œæé«˜ä¸´åºŠæŠ¥å‘Šæ•ˆç‡æä¾›äº†è‡ªåŠ¨åŒ–ç­–ç•¥ã€‚ç„¶è€Œï¼Œå°†é€šç”¨è¯­è¨€æ¨¡å‹åº”ç”¨äºåŒ»å­¦å½±åƒå­˜åœ¨æŒ‘æˆ˜ï¼Œå¦‚å¹»è±¡ã€è§£é‡Šæ€§æœ‰é™å’ŒåŒ»å­¦é¢†åŸŸçŸ¥è¯†ä¸è¶³ï¼Œå¯èƒ½å½±å“ä¸´åºŠå‡†ç¡®æ€§ã€‚ä¸ºå…‹æœè¿™äº›å±€é™æ€§ï¼Œæå‡ºäº†ä¸€ç§å¤šä»£ç†è¯Šæ–­æ¡†æ¶å’Œå¹³å°MedChatï¼Œå®ƒç»“åˆäº†ä¸“ä¸šè§†è§‰æ¨¡å‹å’Œå¤šä¸ªè§’è‰²ç‰¹å®šçš„è¯­è¨€æ¨¡å‹ä»£ç†ï¼Œç”±å¯¼æ¼”ä»£ç†åè°ƒã€‚è¯¥è®¾è®¡æé«˜äº†å¯é æ€§ï¼Œå‡å°‘äº†å¹»è±¡é£é™©ï¼Œå¹¶å…è®¸é€šè¿‡é’ˆå¯¹ä¸´åºŠå®¡æ ¸å’Œæ•™è‚²ä½¿ç”¨çš„ç•Œé¢è¿›è¡Œäº¤äº’å¼è¯Šæ–­æŠ¥å‘Šã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>æ·±åº¦å­¦ä¹ ç»“åˆå¤§å‹è¯­è¨€æ¨¡å‹åœ¨é’å…‰çœ¼æ£€æµ‹ä¸­æœ‰åŠ©äºç¼“è§£çœ¼ç§‘åŒ»ç”ŸçŸ­ç¼ºå’Œæé«˜ä¸´åºŠæŠ¥å‘Šæ•ˆç‡ã€‚</li>
<li>åº”ç”¨äºåŒ»å­¦å½±åƒçš„é€šç”¨è¯­è¨€æ¨¡å‹å­˜åœ¨å¹»è±¡ã€è§£é‡Šæ€§æœ‰é™å’ŒåŒ»å­¦é¢†åŸŸçŸ¥è¯†ä¸è¶³ç­‰æŒ‘æˆ˜ã€‚</li>
<li>MedChatæ˜¯ä¸€ä¸ªå¤šä»£ç†è¯Šæ–­æ¡†æ¶å’Œå¹³å°ï¼Œç»“åˆäº†ä¸“ä¸šè§†è§‰æ¨¡å‹å’Œå¤šä¸ªè§’è‰²ç‰¹å®šçš„è¯­è¨€æ¨¡å‹ä»£ç†ã€‚</li>
<li>MedChatè®¾è®¡æé«˜äº†å¯é æ€§ï¼Œå‡å°‘äº†å¹»è±¡é£é™©ã€‚</li>
<li>MedChatå…è®¸äº¤äº’å¼è¯Šæ–­æŠ¥å‘Šï¼Œå…·æœ‰ä¸´åºŠå®¡æ ¸å’Œæ•™è‚²åŠŸèƒ½ã€‚</li>
<li>MedChatå¹³å°é€šè¿‡ç‰¹å®šç•Œé¢ä¿ƒè¿›äº†å›¢é˜Ÿä¹‹é—´çš„åè°ƒå’Œåˆä½œã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.07400">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-89d8b793f64d65d0e5f0424755ab5583.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-cb482543e06b19940258cf55965e0b32.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-62480a5010575119c9f1ad401b551b6d.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-e90c50dd573d0e2c3ebc59a1471417a8.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-5159788121fa791de354730ffe308ff4.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-031fc8416da34c33a949b3d74c3dee8f.jpg" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="Surfer-H-Meets-Holo1-Cost-Efficient-Web-Agent-Powered-by-Open-Weights"><a href="#Surfer-H-Meets-Holo1-Cost-Efficient-Web-Agent-Powered-by-Open-Weights" class="headerlink" title="Surfer-H Meets Holo1: Cost-Efficient Web Agent Powered by Open Weights"></a>Surfer-H Meets Holo1: Cost-Efficient Web Agent Powered by Open Weights</h2><p><strong>Authors:Mathieu Andreux, Breno Baldas Skuk, Hamza Benchekroun, Emilien BirÃ©, Antoine Bonnet, Riaz Bordie, Nathan Bout, Matthias Brunel, Pierre-Louis Cedoz, Antoine Chassang, MickaÃ«l Chen, Alexandra D. Constantinou, Antoine dâ€™AndignÃ©, Hubert de La JonquiÃ¨re, AurÃ©lien Delfosse, Ludovic Denoyer, Alexis Deprez, Augustin Derupti, Michael Eickenberg, MathÃ¯s Federico, Charles Kantor, Xavier Koegler, Yann LabbÃ©, Matthew C. H. Lee, Erwan Le Jumeau de Kergaradec, Amir Mahla, Avshalom Manevich, Adrien Maret, Charles Masson, RafaÃ«l Maurin, Arturo Mena, Philippe Modard, Axel Moyal, Axel Nguyen Kerbel, Julien Revelle, Mats L. Richter, MarÃ­a Santos, Laurent Sifre, Maxime Theillard, Marc Thibault, Louis Thiry, LÃ©o Tronchon, Nicolas Usunier, Tony Wu</strong></p>
<p>We present Surfer-H, a cost-efficient web agent that integrates Vision-Language Models (VLM) to perform user-defined tasks on the web. We pair it with Holo1, a new open-weight collection of VLMs specialized in web navigation and information extraction. Holo1 was trained on carefully curated data sources, including open-access web content, synthetic examples, and self-produced agentic data. Holo1 tops generalist User Interface (UI) benchmarks as well as our new web UI localization benchmark, WebClick. When powered by Holo1, Surfer-H achieves a 92.2% state-of-the-art performance on WebVoyager, striking a Pareto-optimal balance between accuracy and cost-efficiency. To accelerate research advancement in agentic systems, we are open-sourcing both our WebClick evaluation dataset and the Holo1 model weights. </p>
<blockquote>
<p>æˆ‘ä»¬ä»‹ç»äº†Surfer-Hï¼Œè¿™æ˜¯ä¸€æ¬¾å…·æœ‰æˆæœ¬æ•ˆç›Šçš„Webä»£ç†ï¼Œå®ƒé›†æˆäº†è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMï¼‰ä»¥æ‰§è¡ŒWebä¸Šçš„ç”¨æˆ·è‡ªå®šä¹‰ä»»åŠ¡ã€‚æˆ‘ä»¬å°†å…¶ä¸Holo1é…å¯¹ï¼ŒHolo1æ˜¯ä¸€ç§æ–°å‹å¼€æ”¾çš„VLMé›†åˆï¼Œä¸“é—¨ç”¨äºç½‘ç»œå¯¼èˆªå’Œä¿¡æ¯æå–ã€‚Holo1ç»è¿‡ç²¾å¿ƒæŒ‘é€‰çš„æ•°æ®æºè¿›è¡Œè®­ç»ƒï¼ŒåŒ…æ‹¬å¼€æ”¾è®¿é—®çš„ç½‘é¡µå†…å®¹ã€åˆæˆç¤ºä¾‹å’Œè‡ªæˆ‘ç”Ÿæˆçš„ä»£ç†æ•°æ®ã€‚Holo1åœ¨é€šç”¨ç”¨æˆ·ç•Œé¢ï¼ˆUIï¼‰åŸºå‡†æµ‹è¯•ä»¥åŠæˆ‘ä»¬æ–°çš„Web UIå®šä½åŸºå‡†æµ‹è¯•WebClickä¸­éƒ½è¡¨ç°å‡ºè‰²ã€‚åœ¨ç”±Holo1æä¾›æ”¯æŒçš„æƒ…å†µä¸‹ï¼ŒSurfer-Håœ¨WebVoyagerä¸Šè¾¾åˆ°äº†92.2%çš„æœ€æ–°æ€§èƒ½æ°´å¹³ï¼Œåœ¨å‡†ç¡®æ€§å’Œæˆæœ¬æ•ˆç›Šä¹‹é—´è¾¾åˆ°äº†å¸•ç´¯æ‰˜æœ€ä¼˜å¹³è¡¡ã€‚ä¸ºäº†åŠ å¿«ä»£ç†ç³»ç»Ÿçš„ç ”ç©¶å‘å±•ï¼Œæˆ‘ä»¬å°†åŒæ—¶å¼€æºæˆ‘ä»¬çš„WebClickè¯„ä¼°æ•°æ®é›†å’ŒHolo1æ¨¡å‹æƒé‡ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.02865v2">PDF</a> Alphabetical order</p>
<p><strong>Summary</strong>ï¼š</p>
<p>æˆ‘ä»¬æ¨å‡ºäº†Surfer-Hï¼Œè¿™æ˜¯ä¸€æ¬¾ç»æµå®æƒ çš„ç½‘ç»œä»£ç†ï¼Œé›†æˆäº†è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMï¼‰æ¥æ‰§è¡Œç”¨æˆ·åœ¨ç½‘é¡µä¸Šå®šä¹‰çš„å„é¡¹ä»»åŠ¡ã€‚æˆ‘ä»¬å°†å…¶ä¸Holo1é…å¯¹ï¼ŒHolo1æ˜¯ä¸€ä¸ªé’ˆå¯¹ç½‘é¡µå¯¼èˆªå’Œä¿¡æ¯æå–çš„ä¸“é—¨åŒ–æ–°å‹å¼€æ”¾æƒé‡VLMé›†åˆã€‚Holo1ç»è¿‡ç²¾å¿ƒæŒ‘é€‰çš„æ•°æ®æºè¿›è¡Œè®­ç»ƒï¼ŒåŒ…æ‹¬å…¬å¼€è®¿é—®çš„ç½‘é¡µå†…å®¹ã€åˆæˆç¤ºä¾‹å’Œè‡ªæˆ‘äº§ç”Ÿçš„æ™ºèƒ½æ•°æ®ã€‚åœ¨é€šç”¨çš„ç”¨æˆ·ç•Œé¢ï¼ˆUIï¼‰åŸºå‡†æµ‹è¯•ä»¥åŠæˆ‘ä»¬æ–°çš„ç½‘é¡µç”¨æˆ·ç•Œé¢å®šä½åŸºå‡†æµ‹è¯•WebClickä¸­ï¼ŒHolo1éƒ½å–å¾—äº†é¢†å…ˆçš„åœ°ä½ã€‚Surfer-Hå€ŸåŠ©Holo1çš„åŠ›é‡ï¼Œåœ¨WebVoyagerä¸Šè¾¾åˆ°äº†ä¸šç•Œé¢†å…ˆçš„92.2%çš„æ€§èƒ½è¡¨ç°ï¼Œåœ¨ç²¾åº¦å’Œæˆæœ¬æ•ˆç›Šä¹‹é—´å®ç°äº†å¸•ç´¯æ‰˜æœ€ä¼˜å¹³è¡¡ã€‚ä¸ºäº†æ¨åŠ¨æ™ºèƒ½ç³»ç»Ÿçš„ç ”ç©¶å‘å±•ï¼Œæˆ‘ä»¬å…¬å¼€äº†WebClickè¯„ä¼°æ•°æ®é›†å’ŒHolo1æ¨¡å‹æƒé‡ã€‚</p>
<p><strong>Key Takeaways</strong>:</p>
<ol>
<li>Surfer-Hæ˜¯ä¸€æ¬¾ç»“åˆäº†è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMï¼‰çš„é«˜æ•ˆç½‘ç»œä»£ç†ï¼Œç”¨äºæ‰§è¡Œç”¨æˆ·å®šä¹‰çš„ç½‘é¡µä»»åŠ¡ã€‚</li>
<li>Holo1æ˜¯ä¸€ä¸ªé’ˆå¯¹ç½‘é¡µå¯¼èˆªå’Œä¿¡æ¯æå–çš„ä¸“é—¨åŒ–VLMé›†åˆï¼Œè¡¨ç°ä¼˜äºé€šç”¨çš„ç”¨æˆ·ç•Œé¢åŸºå‡†æµ‹è¯•ã€‚</li>
<li>Holo1ç»è¿‡å¤šç§æ•°æ®æºè®­ç»ƒï¼ŒåŒ…æ‹¬å…¬å¼€è®¿é—®çš„ç½‘é¡µå†…å®¹ã€åˆæˆç¤ºä¾‹å’Œè‡ªæˆ‘äº§ç”Ÿçš„æ™ºèƒ½æ•°æ®ã€‚</li>
<li>Surfer-Hä¸Holo1ç»“åˆåï¼Œåœ¨WebVoyagerä¸Šå®ç°äº†ä¸šç•Œé¢†å…ˆçš„æ€§èƒ½è¡¨ç°ï¼Œè¾¾åˆ°92.2%ã€‚</li>
<li>è¯¥ç³»ç»Ÿå®ç°äº†å¸•ç´¯æ‰˜æœ€ä¼˜å¹³è¡¡ï¼Œå³åœ¨ç²¾åº¦å’Œæˆæœ¬æ•ˆç›Šä¹‹é—´çš„å¹³è¡¡ã€‚</li>
<li>ä¸ºäº†æ¨åŠ¨æ™ºèƒ½ç³»ç»Ÿçš„ç ”ç©¶å‘å±•ï¼Œå…¬å¼€äº†WebClickè¯„ä¼°æ•°æ®é›†å’ŒHolo1æ¨¡å‹æƒé‡ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.02865">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-43da51b547e1ef46a7a8d035ae69733e.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-1805d55874abb2a39ab1c50f2074e822.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-ac974b9643482e17537b6515d0fc0832.jpg" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1><h2 id="OWL-Optimized-Workforce-Learning-for-General-Multi-Agent-Assistance-in-Real-World-Task-Automation"><a href="#OWL-Optimized-Workforce-Learning-for-General-Multi-Agent-Assistance-in-Real-World-Task-Automation" class="headerlink" title="OWL: Optimized Workforce Learning for General Multi-Agent Assistance in   Real-World Task Automation"></a>OWL: Optimized Workforce Learning for General Multi-Agent Assistance in   Real-World Task Automation</h2><p><strong>Authors:Mengkang Hu, Yuhang Zhou, Wendong Fan, Yuzhou Nie, Bowei Xia, Tao Sun, Ziyu Ye, Zhaoxuan Jin, Yingru Li, Qiguang Chen, Zeyu Zhang, Yifeng Wang, Qianshuo Ye, Bernard Ghanem, Ping Luo, Guohao Li</strong></p>
<p>Large Language Model (LLM)-based multi-agent systems show promise for automating real-world tasks but struggle to transfer across domains due to their domain-specific nature. Current approaches face two critical shortcomings: they require complete architectural redesign and full retraining of all components when applied to new domains. We introduce Workforce, a hierarchical multi-agent framework that decouples strategic planning from specialized execution through a modular architecture comprising: (i) a domain-agnostic Planner for task decomposition, (ii) a Coordinator for subtask management, and (iii) specialized Workers with domain-specific tool-calling capabilities. This decoupling enables cross-domain transferability during both inference and training phases: During inference, Workforce seamlessly adapts to new domains by adding or modifying worker agents; For training, we introduce Optimized Workforce Learning (OWL), which improves generalization across domains by optimizing a domain-agnostic planner with reinforcement learning from real-world feedback. To validate our approach, we evaluate Workforce on the GAIA benchmark, covering various realistic, multi-domain agentic tasks. Experimental results demonstrate Workforce achieves open-source state-of-the-art performance (69.70%), outperforming commercial systems like OpenAIâ€™s Deep Research by 2.34%. More notably, our OWL-trained 32B model achieves 52.73% accuracy (+16.37%) and demonstrates performance comparable to GPT-4o on challenging tasks. To summarize, by enabling scalable generalization and modular domain transfer, our work establishes a foundation for the next generation of general-purpose AI assistants. </p>
<blockquote>
<p>åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„å¤šæ™ºèƒ½ä½“ç³»ç»Ÿåœ¨è‡ªåŠ¨åŒ–ç°å®ä»»åŠ¡æ–¹é¢æ˜¾ç¤ºå‡ºå·¨å¤§çš„æ½œåŠ›ï¼Œä½†ç”±äºå…¶é¢†åŸŸç‰¹å®šçš„æ€§è´¨ï¼Œå®ƒä»¬åœ¨è·¨é¢†åŸŸè¿ç§»æ–¹é¢é‡åˆ°äº†å›°éš¾ã€‚å½“å‰çš„æ–¹æ³•é¢ä¸´ä¸¤ä¸ªå…³é”®çš„å±€é™æ€§ï¼šå½“åº”ç”¨äºæ–°é¢†åŸŸæ—¶ï¼Œå®ƒä»¬éœ€è¦å®Œå…¨é‡æ–°è®¾è®¡æ¶æ„å¹¶é‡æ–°è®­ç»ƒæ‰€æœ‰ç»„ä»¶ã€‚æˆ‘ä»¬å¼•å…¥äº†Workforceï¼Œè¿™æ˜¯ä¸€ä¸ªåˆ†å±‚çš„å¤šæ™ºèƒ½ä½“æ¡†æ¶ï¼Œå®ƒé€šè¿‡æ¨¡å—åŒ–æ¶æ„å°†æˆ˜ç•¥è§„åˆ’ä¸ä¸“é¡¹æ‰§è¡Œè§£è€¦ï¼Œè¯¥æ¶æ„åŒ…æ‹¬ï¼šï¼ˆiï¼‰ç”¨äºä»»åŠ¡åˆ†è§£çš„é¢†åŸŸé€šç”¨çš„è§„åˆ’å™¨ï¼Œï¼ˆiiï¼‰ç”¨äºå­ä»»åŠ¡ç®¡ç†çš„åè°ƒå™¨ï¼Œä»¥åŠï¼ˆiiiï¼‰å…·æœ‰é¢†åŸŸç‰¹å®šå·¥å…·è°ƒç”¨èƒ½åŠ›çš„ä¸“ä¸šå·¥ä½œè€…ã€‚è¿™ç§è§£è€¦ä½¿å¾—åœ¨æ¨ç†å’Œè®­ç»ƒé˜¶æ®µéƒ½èƒ½å®ç°è·¨é¢†åŸŸçš„å¯è¿ç§»æ€§ï¼šåœ¨æ¨ç†è¿‡ç¨‹ä¸­ï¼ŒWorkforceå¯ä»¥é€šè¿‡æ·»åŠ æˆ–ä¿®æ”¹å·¥ä½œæ™ºèƒ½ä½“æ¥æ— ç¼é€‚åº”æ–°é¢†åŸŸï¼›åœ¨è®­ç»ƒæ–¹é¢ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¼˜åŒ–å·¥ä½œåŠ›å­¦ä¹ ï¼ˆOWLï¼‰ï¼Œé€šè¿‡å¼ºåŒ–å­¦ä¹ ä»ç°å®ä¸–ç•Œçš„åé¦ˆä¸­ä¼˜åŒ–é¢†åŸŸé€šç”¨çš„è§„åˆ’å™¨ï¼Œæé«˜è·¨é¢†åŸŸçš„æ³›åŒ–èƒ½åŠ›ã€‚ä¸ºäº†éªŒè¯æˆ‘ä»¬çš„æ–¹æ³•ï¼Œæˆ‘ä»¬åœ¨GAIAåŸºå‡†æµ‹è¯•ä¸Šè¯„ä¼°äº†Workforceï¼Œè¯¥æµ‹è¯•æ¶µç›–äº†å„ç§ç°å®çš„å¤šé¢†åŸŸæ™ºèƒ½ä»»åŠ¡ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒWorkforceè¾¾åˆ°äº†å¼€æºçš„æœ€æ–°æŠ€æœ¯æ°´å¹³ï¼ˆ69.70%ï¼‰ï¼Œè¶…è¶Šäº†OpenAIçš„æ·±åº¦ç ”ç©¶ç­‰å•†ä¸šç³»ç»Ÿï¼Œé¢†å…ˆäº†2.34%ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œæˆ‘ä»¬è®­ç»ƒçš„OWL 32Bæ¨¡å‹è¾¾åˆ°äº†52.73%çš„å‡†ç¡®ç‡ï¼ˆ+16.37%ï¼‰ï¼Œå¹¶åœ¨å…·æœ‰æŒ‘æˆ˜æ€§çš„ä»»åŠ¡ä¸Šè¡¨ç°å‡ºä¸GPT-4ç›¸å½“çš„æ€§èƒ½ã€‚æ€»çš„æ¥è¯´ï¼Œé€šè¿‡å®ç°å¯æ‰©å±•çš„æ³›åŒ–å’Œæ¨¡å—åŒ–çš„é¢†åŸŸè¿ç§»ï¼Œæˆ‘ä»¬çš„å·¥ä½œä¸ºä¸‹ä¸€ä»£é€šç”¨äººå·¥æ™ºèƒ½åŠ©æ‰‹å¥ å®šäº†åŸºç¡€ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.23885v2">PDF</a> Project Page: <a target="_blank" rel="noopener" href="https://github.com/camel-ai/owl">https://github.com/camel-ai/owl</a></p>
<p><strong>Summary</strong></p>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä¸ºåŸºç¡€çš„å¤šæ™ºèƒ½ä½“ç³»ç»Ÿåœ¨è‡ªåŠ¨åŒ–å®é™…ä»»åŠ¡æ–¹é¢å±•ç°å‡ºæ½œåŠ›ï¼Œä½†å—é™äºè·¨åŸŸè½¬ç§»èƒ½åŠ›ã€‚æœ¬æ–‡æå‡ºWorkforceï¼Œä¸€ç§å±‚æ¬¡åŒ–çš„å¤šæ™ºèƒ½ä½“æ¡†æ¶ï¼Œé€šè¿‡æ¨¡å—åŒ–æ¶æ„å®ç°æˆ˜ç•¥è§„åˆ’ä¸ä¸“ä¸šæ‰§è¡Œçš„è§£è€¦ï¼ŒåŒ…æ‹¬ä»»åŠ¡åˆ†è§£çš„åŸŸæ— å…³è§„åˆ’å™¨ã€å­ä»»åŠ¡ç®¡ç†çš„åè°ƒå™¨å’Œå…·æœ‰åŸŸç‰¹å®šå·¥å…·è°ƒç”¨èƒ½åŠ›çš„ä¸“ä¸šå·¥ä½œè€…ã€‚è¿™ç§è§£è€¦ä½¿Workforceåœ¨æ¨ç†å’Œè®­ç»ƒé˜¶æ®µéƒ½å…·å¤‡è·¨åŸŸå¯è¿ç§»æ€§ã€‚åœ¨æ¨ç†è¿‡ç¨‹ä¸­ï¼ŒWorkforceå¯é€šè¿‡æ·»åŠ æˆ–ä¿®æ”¹å·¥ä½œæ™ºèƒ½ä½“æ— ç¼é€‚åº”æ–°é¢†åŸŸï¼›åœ¨è®­ç»ƒæ–¹é¢ï¼Œæˆ‘ä»¬å¼•å…¥ä¼˜åŒ–å·¥ä½œåŠ›å­¦ä¹ ï¼ˆOWLï¼‰ï¼Œé€šè¿‡å¼ºåŒ–å­¦ä¹ ä»å®é™…åé¦ˆä¸­ä¼˜åŒ–åŸŸæ— å…³è§„åˆ’å™¨ï¼Œæé«˜è·¨åŸŸæ³›åŒ–èƒ½åŠ›ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒWorkforceåœ¨GAIAåŸºå‡†æµ‹è¯•ä¸Šè¾¾åˆ°å¼€æºæœ€æ–°æŠ€æœ¯æ°´å¹³ï¼Œå¹¶ä¼˜äºå•†ä¸šç³»ç»Ÿå¦‚OpenAIçš„æ·±åº¦ç ”ç©¶ã€‚ç‰¹åˆ«æ˜¯ï¼Œæˆ‘ä»¬çš„OWLè®­ç»ƒçš„32Bæ¨¡å‹åœ¨å…·æœ‰æŒ‘æˆ˜æ€§çš„ä»»åŠ¡ä¸Šè¡¨ç°å‡ºä¸GPT-4oç›¸å½“çš„å‡†ç¡®æ€§ã€‚æ€»ä½“è€Œè¨€ï¼ŒWorkforceé€šè¿‡å»ºç«‹é€šç”¨äººå·¥æ™ºèƒ½åŠ©æ‰‹çš„åŸºçŸ³ï¼Œå®ç°äº†å¯æ‰©å±•çš„æ³›åŒ–å’Œæ¨¡å—åŒ–çš„åŸŸè¿ç§»ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>LLM-based multi-agent systems face challenges in automating real-world tasks due to limited cross-domain transfer capabilities.</li>
<li>Workforceæ˜¯ä¸€ä¸ªå±‚æ¬¡åŒ–çš„å¤šæ™ºèƒ½ä½“æ¡†æ¶ï¼Œé€šè¿‡æ¨¡å—åŒ–æ¶æ„å®ç°æˆ˜ç•¥è§„åˆ’å’Œä¸“ä¸šæ‰§è¡Œçš„è§£è€¦ï¼Œä»¥æé«˜ç³»ç»Ÿçš„è·¨åŸŸé€‚åº”æ€§ã€‚</li>
<li>WorkforceåŒ…æ‹¬ä¸€ä¸ªåŸŸæ— å…³çš„è§„åˆ’å™¨ç”¨äºä»»åŠ¡åˆ†è§£ã€ä¸€ä¸ªåè°ƒå™¨ç”¨äºå­ä»»åŠ¡ç®¡ç†ï¼Œä»¥åŠå…·æœ‰åŸŸç‰¹å®šå·¥å…·è°ƒç”¨èƒ½åŠ›çš„ä¸“ä¸šå·¥ä½œè€…ã€‚</li>
<li>åœ¨æ¨ç†è¿‡ç¨‹ä¸­ï¼ŒWorkforceå¯ä»¥é€šè¿‡æ·»åŠ æˆ–ä¿®æ”¹å·¥ä½œæ™ºèƒ½ä½“æ¥æ— ç¼é€‚åº”æ–°é¢†åŸŸã€‚</li>
<li>å¼•å…¥ä¼˜åŒ–å·¥ä½œåŠ›å­¦ä¹ ï¼ˆOWLï¼‰ä»¥æé«˜è·¨åŸŸæ³›åŒ–èƒ½åŠ›ï¼Œé€šè¿‡å¼ºåŒ–å­¦ä¹ ä»å®é™…åé¦ˆä¸­ä¼˜åŒ–åŸŸæ— å…³è§„åˆ’å™¨ã€‚</li>
<li>Workforceåœ¨GAIAåŸºå‡†æµ‹è¯•ä¸Šè¡¨ç°å‡ºä¼˜ç§€çš„æ€§èƒ½ï¼Œè¾¾åˆ°å¼€æºæœ€æ–°æŠ€æœ¯æ°´å¹³ï¼Œå¹¶ä¼˜äºæŸäº›å•†ä¸šç³»ç»Ÿã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.23885">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-553328a824a162e0eb0f200a05cd12a3.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-6dd3438cd07faec54890f3e13e61222f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f5a8447717f2a8721433108e2899db34.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-cfd898382b74686b21b48c1d6ee73456.jpg" align="middle">
</details>


<h1 id="-9"><a href="#-9" class="headerlink" title=""></a></h1><h2 id="Agentic-Robot-A-Brain-Inspired-Framework-for-Vision-Language-Action-Models-in-Embodied-Agents"><a href="#Agentic-Robot-A-Brain-Inspired-Framework-for-Vision-Language-Action-Models-in-Embodied-Agents" class="headerlink" title="Agentic Robot: A Brain-Inspired Framework for Vision-Language-Action   Models in Embodied Agents"></a>Agentic Robot: A Brain-Inspired Framework for Vision-Language-Action   Models in Embodied Agents</h2><p><strong>Authors:Zhejian Yang, Yongchao Chen, Xueyang Zhou, Jiangyue Yan, Dingjie Song, Yinuo Liu, Yuting Li, Yu Zhang, Pan Zhou, Hechang Chen, Lichao Sun</strong></p>
<p>Long-horizon robotic manipulation poses significant challenges for autonomous systems, requiring extended reasoning, precise execution, and robust error recovery across complex sequential tasks. Current approaches, whether based on static planning or end-to-end visuomotor policies, suffer from error accumulation and lack effective verification mechanisms during execution, limiting their reliability in real-world scenarios. We present Agentic Robot, a brain-inspired framework that addresses these limitations through Standardized Action Procedure (SAP)â€“a novel coordination protocol governing component interactions throughout manipulation tasks. Drawing inspiration from Standardized Operating Procedures (SOPs) in human organizations, SAP establishes structured workflows for planning, execution, and verification phases. Our architecture comprises three specialized components: (1) a large reasoning model that decomposes high-level instructions into semantically coherent subgoals, (2) a vision-language-action executor that generates continuous control commands from real-time visual inputs, and (3) a temporal verifier that enables autonomous progression and error recovery through introspective assessment. This SAP-driven closed-loop design supports dynamic self-verification without external supervision. On the LIBERO benchmark, Agentic Robot achieves state-of-the-art performance with an average success rate of 79.6%, outperforming SpatialVLA by 6.1% and OpenVLA by 7.4% on long-horizon tasks. These results demonstrate that SAP-driven coordination between specialized components enhances both performance and interpretability in sequential manipulation, suggesting significant potential for reliable autonomous systems. Project Github: <a target="_blank" rel="noopener" href="https://agentic-robot.github.io/">https://agentic-robot.github.io</a>. </p>
<blockquote>
<p>é•¿æœŸæœºå™¨äººæ“ä½œå¯¹è‡ªä¸»ç³»ç»Ÿæ„æˆäº†é‡å¤§æŒ‘æˆ˜ï¼Œéœ€è¦åœ¨å¤æ‚çš„åºåˆ—ä»»åŠ¡ä¸­è¿›è¡Œæ‰©å±•æ¨ç†ã€ç²¾ç¡®æ‰§è¡Œå’Œç¨³å¥çš„é”™è¯¯æ¢å¤ã€‚å½“å‰çš„æ–¹æ³•ï¼Œæ— è®ºæ˜¯åŸºäºé™æ€è§„åˆ’è¿˜æ˜¯ç«¯åˆ°ç«¯çš„è§†è§‰è¿åŠ¨ç­–ç•¥ï¼Œéƒ½å­˜åœ¨è¯¯å·®ç´¯ç§¯çš„é—®é¢˜ï¼Œå¹¶ä¸”åœ¨æ‰§è¡Œè¿‡ç¨‹ä¸­ç¼ºä¹æœ‰æ•ˆçš„éªŒè¯æœºåˆ¶ï¼Œè¿™åœ¨çœŸå®ä¸–ç•Œåœºæ™¯ä¸­é™åˆ¶äº†å®ƒä»¬çš„å¯é æ€§ã€‚æˆ‘ä»¬æå‡ºäº†Agentic Robotï¼Œè¿™æ˜¯ä¸€ä¸ªå—å¤§è„‘å¯å‘çš„æ¡†æ¶ï¼Œé€šè¿‡æ ‡å‡†åŒ–çš„è¡ŒåŠ¨ç¨‹åºï¼ˆSAPï¼‰è§£å†³è¿™äº›é™åˆ¶â€”â€”ä¸€ç§æ–°å‹åè°ƒåè®®ï¼Œç®¡ç†æ“ä½œä»»åŠ¡ä¸­ç»„ä»¶ä¹‹é—´çš„äº¤äº’ã€‚SAPä»¥äººç±»ç»„ç»‡ä¸­çš„æ ‡å‡†åŒ–æ“ä½œè§„ç¨‹ï¼ˆSOPsï¼‰ä¸ºçµæ„Ÿï¼Œä¸ºè§„åˆ’ã€æ‰§è¡Œå’ŒéªŒè¯é˜¶æ®µå»ºç«‹äº†ç»“æ„åŒ–å·¥ä½œæµç¨‹ã€‚æˆ‘ä»¬çš„æ¶æ„åŒ…å«ä¸‰ä¸ªä¸“ä¸šç»„ä»¶ï¼šï¼ˆ1ï¼‰ä¸€ä¸ªå¤§å‹æ¨ç†æ¨¡å‹ï¼Œå°†é«˜çº§æŒ‡ä»¤åˆ†è§£ä¸ºè¯­ä¹‰è¿è´¯çš„å­ç›®æ ‡ï¼›ï¼ˆ2ï¼‰ä¸€ä¸ªè§†è§‰è¯­è¨€è¡ŒåŠ¨æ‰§è¡Œå™¨ï¼Œæ ¹æ®å®æ—¶è§†è§‰è¾“å…¥ç”Ÿæˆè¿ç»­æ§åˆ¶å‘½ä»¤ï¼›ï¼ˆ3ï¼‰ä¸€ä¸ªæ—¶é—´éªŒè¯å™¨ï¼Œé€šè¿‡å†…çœè¯„ä¼°å®ç°è‡ªä¸»è¿›å±•å’Œé”™è¯¯æ¢å¤ã€‚è¿™ç§SAPé©±åŠ¨çš„é—­ç¯è®¾è®¡æ”¯æŒåŠ¨æ€è‡ªæˆ‘éªŒè¯ï¼Œæ— éœ€å¤–éƒ¨ç›‘ç£ã€‚åœ¨LIBEROåŸºå‡†æµ‹è¯•ä¸­ï¼ŒAgentic Robotè¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œå¹³å‡æˆåŠŸç‡ä¸º79.6%ï¼Œåœ¨é•¿æœŸä»»åŠ¡ä¸Šæ¯”SpatialVLAé«˜å‡º6.1%ï¼Œæ¯”OpenVLAé«˜å‡º7.4%ã€‚è¿™äº›ç»“æœè¡¨æ˜ï¼ŒSAPé©±åŠ¨çš„ä¸“ä¸šç»„ä»¶ä¹‹é—´çš„åè°ƒå¢å¼ºäº†åºåˆ—æ“ä½œä¸­çš„æ€§èƒ½å’Œå¯è§£é‡Šæ€§ï¼Œæ˜¾ç¤ºå‡ºå¯é è‡ªä¸»ç³»ç»Ÿçš„å·¨å¤§æ½œåŠ›ã€‚é¡¹ç›®Githubï¼š<a target="_blank" rel="noopener" href="https://agentic-robot.github.io./">https://agentic-robot.github.ioã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.23450v2">PDF</a> 20 pages, 8 figures</p>
<p><strong>Summary</strong><br>     é’ˆå¯¹é•¿æœŸè§†é‡ä¸‹çš„æœºå™¨äººæ“æ§é—®é¢˜ï¼ŒAgentic Robotæ¡†æ¶é€šè¿‡å€Ÿé‰´äººç±»ç»„ç»‡ä¸­çš„æ ‡å‡†åŒ–æ“ä½œæµç¨‹ï¼ˆSOPsï¼‰ï¼Œæå‡ºäº†æ ‡å‡†åŒ–çš„è¡ŒåŠ¨ç¨‹åºï¼ˆSAPï¼‰æ¥åè°ƒç»„ä»¶é—´çš„äº¤äº’ã€‚è¯¥æ¡†æ¶åŒ…æ‹¬ä¸‰ä¸ªä¸»è¦ç»„ä»¶ï¼šç”¨äºåˆ†è§£é«˜çº§æŒ‡ä»¤ä¸ºè¯­ä¹‰è¿è´¯çš„å­ç›®æ ‡çš„æ¨ç†æ¨¡å‹ã€ä»å®æ—¶è§†è§‰è¾“å…¥ç”Ÿæˆè¿ç»­æ§åˆ¶å‘½ä»¤çš„è§†è¯­è¨€è¡ŒåŠ¨æ‰§è¡Œå™¨ï¼Œä»¥åŠé€šè¿‡å†…çœè¯„ä¼°å®ç°è‡ªä¸»è¿›å±•å’Œé”™è¯¯æ¢å¤çš„ä¸´æ—¶éªŒè¯å™¨ã€‚åœ¨LIBEROåŸºå‡†æµ‹è¯•ä¸­ï¼ŒAgentic Robotè¾¾åˆ°äº†å“è¶Šçš„æ€§èƒ½è¡¨ç°ï¼Œå¹³å‡æˆåŠŸç‡ä¸º79.6%ï¼Œåœ¨ç©ºé—´é•¿æœŸä»»åŠ¡ä¸Šçš„æ€§èƒ½æ¯”SpatialVLAé«˜å‡º6.1%ï¼Œæ¯”OpenVLAé«˜å‡º7.4%ã€‚è¿™è¡¨æ˜SAPé©±åŠ¨çš„åè°ƒæœºåˆ¶åœ¨æå‡åºåˆ—æ“æ§çš„æ€§èƒ½å’Œå¯è§£é‡Šæ€§æ–¹é¢å…·æœ‰æ˜¾è‘—æ½œåŠ›ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>é•¿æœŸè§†é‡çš„æœºå™¨äººæ“æ§å¯¹è‡ªä¸»ç³»ç»Ÿæå‡ºäº†é‡å¤§æŒ‘æˆ˜ï¼Œéœ€è¦æ‰©å±•æ¨ç†ã€ç²¾ç¡®æ‰§è¡Œå’Œå¤æ‚ä»»åŠ¡çš„ç¨³å¥é”™è¯¯æ¢å¤ã€‚</li>
<li>å½“å‰æ–¹æ³•ï¼ˆåŸºäºé™æ€è§„åˆ’æˆ–ç«¯åˆ°ç«¯è§†å¬è§‰ç­–ç•¥ï¼‰å­˜åœ¨è¯¯å·®ç´¯ç§¯å’Œæ‰§è¡Œè¿‡ç¨‹ä¸­ç¼ºä¹æœ‰æ•ˆéªŒè¯æœºåˆ¶çš„é—®é¢˜ï¼Œé™åˆ¶äº†å®ƒä»¬åœ¨ç°å®åœºæ™¯ä¸­çš„å¯é æ€§ã€‚</li>
<li>Agentic Robotæ¡†æ¶é€šè¿‡å€Ÿé‰´äººç±»ç»„ç»‡çš„æ ‡å‡†åŒ–æ“ä½œæµç¨‹ï¼ˆSOPsï¼‰ï¼Œæå‡ºäº†æ ‡å‡†åŒ–çš„è¡ŒåŠ¨ç¨‹åºï¼ˆSAPï¼‰ï¼Œå®ç°äº†å¯¹æœºå™¨äººæ“æ§ä»»åŠ¡ä¸­ç»„ä»¶äº¤äº’çš„æœ‰æ•ˆåè°ƒã€‚</li>
<li>Agentic Robotæ¡†æ¶åŒ…æ‹¬æ¨ç†æ¨¡å‹ã€è§†è¯­è¨€è¡ŒåŠ¨æ‰§è¡Œå™¨å’Œä¸´æ—¶éªŒè¯å™¨ç­‰ä¸‰ä¸ªä¸»è¦ç»„ä»¶ï¼Œåˆ†åˆ«è´Ÿè´£åˆ†è§£é«˜çº§æŒ‡ä»¤ã€ç”Ÿæˆè¿ç»­æ§åˆ¶å‘½ä»¤å’Œè‡ªä¸»è¿›å±•åŠé”™è¯¯æ¢å¤ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.23450">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-2ae1eb45acabf0ccb27c81d2a101a800.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d2bfd722fa898f8ab98aa126b08c8daf.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-5493bf37f70e609759260c680647195b.jpg" align="middle">
</details>


<h1 id="-10"><a href="#-10" class="headerlink" title=""></a></h1><h2 id="Crafting-Customisable-Characters-with-LLMs-Introducing-SimsChat-a-Persona-Driven-Role-Playing-Agent-Framework"><a href="#Crafting-Customisable-Characters-with-LLMs-Introducing-SimsChat-a-Persona-Driven-Role-Playing-Agent-Framework" class="headerlink" title="Crafting Customisable Characters with LLMs: Introducing SimsChat, a   Persona-Driven Role-Playing Agent Framework"></a>Crafting Customisable Characters with LLMs: Introducing SimsChat, a   Persona-Driven Role-Playing Agent Framework</h2><p><strong>Authors:Bohao Yang, Dong Liu, Chenghao Xiao, Kun Zhao, Chao Li, Lin Yuan, Guang Yang, Chenghua Lin</strong></p>
<p>Large Language Models (LLMs) demonstrate remarkable ability to comprehend instructions and generate human-like text, enabling sophisticated agent simulation beyond basic behavior replication. However, the potential for creating freely customisable characters remains underexplored. We introduce the Customisable Conversation Agent Framework, which employs LLMs to simulate real-world characters through personalised characteristic feature injection, enabling diverse character creation according to user preferences. We propose the SimsConv dataset, comprising 68 customised characters and 13,971 multi-turn role-playing dialogues across 1,360 real-world scenes. Characters are initially customised using pre-defined elements (career, aspiration, traits, skills), then expanded through personal and social profiles. Building on this, we present SimsChat, a freely customisable role-playing agent incorporating various realistic settings and topic-specified character interactions. Experimental results on both SimsConv and WikiRoleEval datasets demonstrate SimsChatâ€™s superior performance in maintaining character consistency, knowledge accuracy, and appropriate question rejection compared to existing models. Our framework provides valuable insights for developing more accurate and customisable human simulacra. Our data and code are publicly available at <a target="_blank" rel="noopener" href="https://github.com/Bernard-Yang/SimsChat">https://github.com/Bernard-Yang/SimsChat</a>. </p>
<blockquote>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å±•ç°å‡ºä»¤äººç©ç›®çš„ç†è§£å’Œæ‰§è¡ŒæŒ‡ä»¤çš„èƒ½åŠ›ï¼Œä»¥åŠç”Ÿæˆç±»ä¼¼äººç±»çš„æ–‡æœ¬çš„èƒ½åŠ›ï¼Œèƒ½å¤Ÿå®ç°è¶…è¶ŠåŸºæœ¬è¡Œä¸ºå¤åˆ¶çš„å¤æ‚ä»£ç†æ¨¡æ‹Ÿã€‚ç„¶è€Œï¼Œåˆ›å»ºå¯è‡ªç”±å®šåˆ¶è§’è‰²çš„æ½œåŠ›ä»æœªè¢«å……åˆ†æ¢ç´¢ã€‚æˆ‘ä»¬å¼•å…¥äº†å¯å®šåˆ¶å¯¹è¯ä»£ç†æ¡†æ¶ï¼Œè¯¥æ¡†æ¶åˆ©ç”¨LLMé€šè¿‡ä¸ªæ€§åŒ–ç‰¹å¾æ³¨å…¥æ¨¡æ‹Ÿç°å®ä¸–ç•Œè§’è‰²ï¼Œå¹¶æ ¹æ®ç”¨æˆ·åå¥½å®ç°å¤šæ ·åŒ–è§’è‰²åˆ›å»ºã€‚æˆ‘ä»¬æå‡ºäº†SimsConvæ•°æ®é›†ï¼ŒåŒ…å«68ä¸ªè‡ªå®šä¹‰è§’è‰²å’Œ13971ä¸ªè·¨1360ä¸ªç°å®åœºæ™¯çš„å¤šè½®è§’è‰²æ‰®æ¼”å¯¹è¯ã€‚è§’è‰²æœ€åˆä½¿ç”¨é¢„å®šä¹‰å…ƒç´ ï¼ˆèŒä¸šã€æŠ±è´Ÿã€ç‰¹è´¨ã€æŠ€èƒ½ï¼‰è¿›è¡Œå®šåˆ¶ï¼Œç„¶åé€šè¿‡ä¸ªäººå’Œç¤¾ä¼šæ¦‚å†µè¿›ä¸€æ­¥æ‰©å±•ã€‚åœ¨æ­¤åŸºç¡€ä¸Šï¼Œæˆ‘ä»¬æ¨å‡ºäº†SimsChatï¼Œè¿™æ˜¯ä¸€ä¸ªå¯è‡ªç”±å®šåˆ¶çš„è§’è‰²æ‰®æ¼”ä»£ç†ï¼ŒåŒ…å«å„ç§ç°å®åœºæ™¯å’Œä¸»é¢˜ç‰¹å®šçš„è§’è‰²äº¤äº’ã€‚åœ¨SimsConvå’ŒWikiRoleEvalæ•°æ®é›†ä¸Šçš„å®éªŒç»“æœè¯æ˜äº†SimsChatåœ¨ä¿æŒè§’è‰²ä¸€è‡´æ€§ã€çŸ¥è¯†å‡†ç¡®æ€§å’Œé€‚å½“é—®é¢˜æ‹’ç»æ–¹é¢çš„æ€§èƒ½ä¼˜äºç°æœ‰æ¨¡å‹ã€‚æˆ‘ä»¬çš„æ¡†æ¶ä¸ºå¼€å‘æ›´å‡†ç¡®ã€å¯å®šåˆ¶çš„äººç±»æ¨¡æ‹Ÿä½“æä¾›äº†æœ‰ä»·å€¼çš„è§è§£ã€‚æˆ‘ä»¬çš„æ•°æ®å’Œä»£ç å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/Bernard-Yang/SimsChat%E5%B9%B3%E5%BC%BA%E8%AE%BF%E9%97%AE%E3%80%82">https://github.com/Bernard-Yang/SimsChatå…¬å¼€è®¿é—®ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2406.17962v6">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨ç†è§£å’Œæ‰§è¡ŒæŒ‡ä»¤ä»¥åŠç”Ÿæˆäººç±»æ–‡æœ¬æ–¹é¢è¡¨ç°å‡ºå“è¶Šçš„èƒ½åŠ›ï¼Œèƒ½å¤Ÿæ¨¡æ‹Ÿè¶…è¶ŠåŸºæœ¬è¡Œä¸ºå¤åˆ¶çš„å¤æ‚ä»£ç†ã€‚ç„¶è€Œï¼Œåˆ›å»ºå¯è‡ªç”±å®šåˆ¶è§’è‰²çš„æ½œåŠ›ä»æœªè¢«å……åˆ†æ¢ç´¢ã€‚æˆ‘ä»¬å¼•å…¥äº†å¯å®šåˆ¶å¯¹è¯ä»£ç†æ¡†æ¶ï¼Œè¯¥æ¡†æ¶åˆ©ç”¨LLMsé€šè¿‡ä¸ªæ€§åŒ–ç‰¹å¾æ³¨å…¥æ¥æ¨¡æ‹Ÿç°å®è§’è‰²ï¼Œå¹¶æ ¹æ®ç”¨æˆ·åå¥½å®ç°å¤šæ ·åŒ–çš„è§’è‰²åˆ›å»ºã€‚æˆ‘ä»¬æå‡ºäº†SimsConvæ•°æ®é›†ï¼ŒåŒ…å«68ä¸ªè‡ªå®šä¹‰è§’è‰²å’Œ13971ä¸ªè·¨1360ä¸ªç°å®åœºæ™¯çš„å¤šè½®è§’è‰²æ‰®æ¼”å¯¹è¯ã€‚è§’è‰²æœ€åˆä½¿ç”¨é¢„å®šä¹‰å…ƒç´ ï¼ˆèŒä¸šã€æŠ±è´Ÿã€ç‰¹è´¨ã€æŠ€èƒ½ï¼‰è¿›è¡Œå®šåˆ¶ï¼Œç„¶åé€šè¿‡ä¸ªäººå’Œç¤¾ä¼šèµ„æ–™è¿›ä¸€æ­¥æ‰©å±•ã€‚åœ¨æ­¤åŸºç¡€ä¸Šï¼Œæˆ‘ä»¬æ¨å‡ºäº†å¯è‡ªç”±å®šåˆ¶çš„è§’è‰²æ‰®æ¼”ä»£ç†SimsChatï¼Œå®ƒåŒ…å«å„ç§é€¼çœŸçš„åœºæ™¯å’Œç‰¹å®šä¸»é¢˜çš„äº¤äº’è§’è‰²ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒSimsChatåœ¨ä¿æŒè§’è‰²ä¸€è‡´æ€§ã€çŸ¥è¯†å‡†ç¡®æ€§å’Œé€‚å½“çš„æé—®æ‹’ç»æ–¹é¢ä¼˜äºç°æœ‰æ¨¡å‹ã€‚æˆ‘ä»¬çš„æ¡†æ¶ä¸ºå¼€å‘æ›´å‡†ç¡®å’Œå¯å®šåˆ¶çš„äººç±»æ¨¡æ‹Ÿæä¾›äº†å®è´µçš„è§è§£ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨æ¨¡æ‹Ÿå¤æ‚ä»£ç†æ–¹é¢è¡¨ç°å‡ºå“è¶Šçš„èƒ½åŠ›ï¼Œèƒ½å¤Ÿç†è§£å’Œæ‰§è¡ŒæŒ‡ä»¤ï¼Œç”Ÿæˆäººç±»æ–‡æœ¬ã€‚</li>
<li>è‡ªå®šä¹‰å¯¹è¯ä»£ç†æ¡†æ¶åˆ©ç”¨LLMsæ¨¡æ‹Ÿç°å®è§’è‰²ï¼Œå…è®¸ç”¨æˆ·æ ¹æ®åå¥½åˆ›å»ºå¤šæ ·åŒ–çš„è§’è‰²ã€‚</li>
<li>SimsConvæ•°æ®é›†åŒ…å«å¤šä¸ªè‡ªå®šä¹‰è§’è‰²å’Œè·¨ç°å®åœºæ™¯çš„å¤šè½®è§’è‰²æ‰®æ¼”å¯¹è¯ï¼Œç”¨äºè®­ç»ƒå’Œè¯„ä¼°è§’è‰²æ¨¡æ‹Ÿæ¨¡å‹ã€‚</li>
<li>è§’è‰²å®šåˆ¶åŸºäºé¢„å®šä¹‰å…ƒç´ ï¼Œå¦‚èŒä¸šã€æŠ±è´Ÿã€ç‰¹è´¨å’ŒæŠ€èƒ½ï¼Œå¹¶é€šè¿‡ä¸ªäººå’Œç¤¾ä¼šèµ„æ–™è¿›ä¸€æ­¥æ‰©å±•ã€‚</li>
<li>SimsChatæ˜¯ä¸€ä¸ªå¯è‡ªç”±å®šåˆ¶çš„è§’è‰²æ‰®æ¼”ä»£ç†ï¼Œèƒ½å¤Ÿåœ¨å„ç§é€¼çœŸçš„åœºæ™¯ä¸­æ¨¡æ‹Ÿè§’è‰²äº¤äº’ã€‚</li>
<li>å®éªŒç»“æœè¡¨æ˜ï¼ŒSimsChatåœ¨è§’è‰²ä¸€è‡´æ€§ã€çŸ¥è¯†å‡†ç¡®æ€§å’Œæé—®æ‹’ç»æ–¹é¢ä¼˜äºç°æœ‰æ¨¡å‹ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2406.17962">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-c61bdd5d78a9f1238166afdb94f98d17.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-df04937e3f74637c3683c7c30cd2b471.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-6a0871a08f679c9b34664abb5826eb2e.jpg" align="middle">
</details>


<h1 id="-11"><a href="#-11" class="headerlink" title=""></a></h1><h2 id="LLM2TEA-Agentic-AI-Designer-Finds-Innovative-Objects-with-Generative-Evolutionary-Multitasking"><a href="#LLM2TEA-Agentic-AI-Designer-Finds-Innovative-Objects-with-Generative-Evolutionary-Multitasking" class="headerlink" title="LLM2TEA: Agentic AI Designer Finds Innovative Objects with Generative   Evolutionary Multitasking"></a>LLM2TEA: Agentic AI Designer Finds Innovative Objects with Generative   Evolutionary Multitasking</h2><p><strong>Authors:Melvin Wong, Jiao Liu, Thiago Rios, Stefan Menzel, Yew Soon Ong</strong></p>
<p>In this paper, we introduce LLM-driven MultiTask Evolutionary Algorithm (LLM2TEA), the first agentic AI designer within a generative evolutionary multitasking (GEM) framework that promotes the crossover and synergy of designs from multiple domains, leading to innovative solutions that transcend individual disciplines. Of particular interest is the discovery of objects that are not only innovative but also conform to the physical specifications of the real world in science and engineering. LLM2TEA comprises a large language model to initialize a population of genotypes (defined by text prompts) describing the objects of interest, a text-to-3D generative model to produce phenotypes from these prompts, a classifier to interpret the semantic representations of the objects, and a physics simulation model to assess their physical properties. We propose several novel LLM-based multitask evolutionary operators to guide the search toward the discovery of high-performing practical objects. Experimental results in conceptual design optimization validate the effectiveness of LLM2TEA, revealing from 97% to 174% improvement in the diversity of innovative objects compared to the present text-to-3D generative model baseline. In addition, more than 73% of the generated designs have better physical performance than the top 1% percentile of the designs generated in the baseline. Moreover, LLM2TEA generates designs that are not only aesthetically creative but also functional in real-world applications. Several of these designs have been successfully 3D-printed, emphasizing the proposed approachâ€™s capacity to transform AI-generated outputs into tangible physical objects. The designs produced by LLM2TEA meets practical requirements while showcasing creative and innovative features, underscoring its potential applications in complex design optimization and discovery. </p>
<blockquote>
<p>æœ¬æ–‡ä»‹ç»äº†LLMé©±åŠ¨çš„å¤šä»»åŠ¡è¿›åŒ–ç®—æ³•ï¼ˆLLM2TEAï¼‰ï¼Œè¿™æ˜¯é¦–ä¸ªåœ¨ç”Ÿæˆå¼è¿›åŒ–å¤šä»»åŠ¡ï¼ˆGEMï¼‰æ¡†æ¶å†…çš„è‡ªä¸»äººå·¥æ™ºèƒ½è®¾è®¡å·¥å…·ï¼Œæ—¨åœ¨ä¿ƒè¿›è®¾è®¡è·¨ç•ŒååŒä¸å¤šå­¦ç§‘äº¤å‰èåˆï¼Œæ¨åŠ¨åˆ›æ–°è§£å†³æ–¹æ¡ˆè¶…è¶Šä¸ªä½“å­¦ç§‘ç•Œé™ã€‚ç‰¹åˆ«æ„Ÿå…´è¶£çš„æ˜¯å‘ç°ä¸ä»…å…·æœ‰åˆ›æ–°æ€§è€Œä¸”ç¬¦åˆç§‘å­¦ä¸å·¥ç¨‹ä¸­ç°å®ä¸–ç•Œç‰©ç†è§„èŒƒçš„å¯¹è±¡ã€‚LLM2TEAåŒ…æ‹¬ä¸€ä¸ªå¤§å‹è¯­è¨€æ¨¡å‹ï¼Œç”¨äºåˆå§‹åŒ–æè¿°æ„Ÿå…´è¶£å¯¹è±¡çš„åŸºå› å‹ç§ç¾¤ï¼ˆé€šè¿‡æ–‡æœ¬æç¤ºå®šä¹‰ï¼‰ï¼Œä¸€ä¸ªä»æ–‡æœ¬åˆ°ä¸‰ç»´çš„ç”Ÿæˆæ¨¡å‹ï¼Œç”¨äºä»è¿™äº›æç¤ºä¸­äº§ç”Ÿè¡¨ç°å‹ï¼Œä¸€ä¸ªè§£é‡Šå¯¹è±¡è¯­ä¹‰è¡¨ç¤ºçš„åˆ†ç±»å™¨ï¼Œä»¥åŠä¸€ä¸ªç‰©ç†ä»¿çœŸæ¨¡å‹ï¼Œç”¨äºè¯„ä¼°å…¶ç‰©ç†å±æ€§ã€‚æˆ‘ä»¬æå‡ºäº†å‡ ç§åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹çš„å¤šä»»åŠ¡è¿›åŒ–ç®—å­æ¥æŒ‡å¯¼æœç´¢å‘ç°é«˜æ€§èƒ½å®ç”¨å¯¹è±¡ã€‚åœ¨æ¦‚å¿µè®¾è®¡ä¼˜åŒ–æ–¹é¢çš„å®éªŒç»“æœè¡¨æ˜LLM2TEAçš„æœ‰æ•ˆæ€§ï¼Œä¸å½“å‰æ–‡æœ¬åˆ°ä¸‰ç»´ç”Ÿæˆæ¨¡å‹çš„åŸºçº¿ç›¸æ¯”ï¼Œåˆ›æ–°å¯¹è±¡çš„å¤šæ ·æ€§æé«˜äº†97%~174%ã€‚æ­¤å¤–ï¼Œè¶…è¿‡73%çš„ç”Ÿæˆè®¾è®¡åœ¨ç‰©ç†æ€§èƒ½ä¸Šä¼˜äºåŸºçº¿ä¸­ç”Ÿæˆçš„é¡¶çº§è®¾è®¡çš„ç™¾åˆ†ä¹‹ä¸€ã€‚è€Œä¸”ï¼ŒLLM2TEAç”Ÿæˆçš„è®¾è®¡ä¸ä»…å¯Œæœ‰ç¾å­¦åˆ›æ„ï¼Œè€Œä¸”å…·æœ‰ç°å®åº”ç”¨çš„åŠŸèƒ½æ€§ã€‚è¿™äº›è®¾è®¡ä¸­çš„å¤šä¸ªè®¾è®¡å·²æˆåŠŸå®ç°3Dæ‰“å°ï¼Œè¿™çªæ˜¾äº†æ‰€æå‡ºæ–¹æ³•å°†äººå·¥æ™ºèƒ½ç”Ÿæˆè¾“å‡ºè½¬åŒ–ä¸ºæœ‰å½¢å®ä½“çš„èƒ½åŠ›ã€‚LLM2TEAäº§ç”Ÿçš„è®¾è®¡æ»¡è¶³å®é™…éœ€æ±‚ï¼Œå±•ç¤ºå…¶åˆ›æ–°ç‰¹å¾å’Œåº”ç”¨æ½œåŠ›ï¼Œç‰¹åˆ«é€‚ç”¨äºå¤æ‚è®¾è®¡çš„ä¼˜åŒ–ä¸å‘ç°ç­‰é¢†åŸŸã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2406.14917v2">PDF</a> This work has been submitted to the IEEE for review</p>
<p><strong>Summary</strong><br>     æœ¬æ–‡ä»‹ç»äº†LLMé©±åŠ¨çš„å¤šä»»åŠ¡è¿›åŒ–ç®—æ³•ï¼ˆLLM2TEAï¼‰ï¼Œè¿™æ˜¯é¦–ä¸ªåœ¨ç”Ÿæˆå¼è¿›åŒ–å¤šä»»åŠ¡ï¼ˆGEMï¼‰æ¡†æ¶ä¸‹è¿è¡Œçš„æ™ºèƒ½è®¾è®¡ä»£ç†ã€‚å®ƒç»“åˆäº†ä¸åŒé¢†åŸŸè®¾è®¡çš„äº¤å‰å’ŒååŒä½œç”¨ï¼Œä¿ƒæˆçªç ´å­¦ç§‘é™åˆ¶çš„åˆ›æ–°è§£å†³æ–¹æ¡ˆã€‚LLM2TEAé‡‡ç”¨å¤§å‹è¯­è¨€æ¨¡å‹åˆå§‹åŒ–æè¿°ç›®æ ‡å¯¹è±¡çš„åŸºå› å‹ç¾¤ä½“ï¼Œé€šè¿‡æ–‡æœ¬åˆ°3Dç”Ÿæˆæ¨¡å‹äº§ç”Ÿè¡¨ç°å‹ï¼Œåˆ†ç±»å™¨è§£é‡Šå¯¹è±¡è¯­ä¹‰è¡¨ç¤ºï¼Œç‰©ç†ä»¿çœŸæ¨¡å‹è¯„ä¼°ç‰©ç†ç‰¹æ€§ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒLLM2TEAåœ¨æ¦‚å¿µè®¾è®¡ä¼˜åŒ–ä¸­æ•ˆæœæ˜¾è‘—ï¼Œä¸åˆ›æ–°å¯¹è±¡å¤šæ ·æ€§ç›¸æ¯”ï¼Œç°æœ‰æ–‡æœ¬åˆ°3Dç”Ÿæˆæ¨¡å‹åŸºçº¿æé«˜äº†97%~174%ã€‚æ­¤å¤–ï¼Œè¶…è¿‡73%çš„ç”Ÿæˆè®¾è®¡åœ¨ç‰©ç†æ€§èƒ½ä¸Šä¼˜äºåŸºçº¿ä¸­çš„å‰1%è®¾è®¡ã€‚LLM2TEAä¸ä»…ç”Ÿæˆå…·æœ‰åˆ›æ„çš„è®¾è®¡ï¼Œè€Œä¸”èƒ½å¤Ÿåº”ç”¨äºå®é™…åœºæ™¯ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>LLM2TEAæ˜¯é¦–ä¸ªåœ¨ç”Ÿæˆå¼è¿›åŒ–å¤šä»»åŠ¡ï¼ˆGEMï¼‰æ¡†æ¶ä¸‹çš„æ™ºèƒ½è®¾è®¡ä»£ç†ï¼Œä¿ƒè¿›å¤šé¢†åŸŸè®¾è®¡çš„äº¤å‰å’ŒååŒã€‚</li>
<li>LLM2TEAé‡‡ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ã€æ–‡æœ¬åˆ°3Dç”Ÿæˆæ¨¡å‹ã€åˆ†ç±»å™¨å’Œç‰©ç†ä»¿çœŸæ¨¡å‹ç­‰å¤šä¸ªç»„ä»¶ååŒå·¥ä½œã€‚</li>
<li>å®éªŒç»“æœéªŒè¯äº†LLM2TEAåœ¨æ¦‚å¿µè®¾è®¡ä¼˜åŒ–ä¸­çš„æœ‰æ•ˆæ€§ï¼Œä¸åˆ›æ–°å¯¹è±¡å¤šæ ·æ€§ç›¸æ¯”ï¼Œç°æœ‰æ¨¡å‹åŸºçº¿æœ‰æ˜¾è‘—æé«˜ã€‚</li>
<li>è¶…è¿‡73%çš„LLM2TEAç”Ÿæˆçš„è®¾è®¡åœ¨ç‰©ç†æ€§èƒ½ä¸Šä¼˜äºåŸºçº¿ä¸­çš„é¡¶å°–è®¾è®¡ã€‚</li>
<li>LLM2TEAèƒ½å¤Ÿç”Ÿæˆä¸ä»…å…·æœ‰åˆ›æ„è€Œä¸”é€‚ç”¨äºå®é™…åœºæ™¯çš„è®¾è®¡ã€‚</li>
<li>LLM2TEAæˆåŠŸå°†AIç”Ÿæˆçš„è®¾è®¡è½¬åŒ–ä¸ºå®ç‰©ï¼Œå±•ç¤ºäº†å…¶åœ¨å¤æ‚è®¾è®¡ä¼˜åŒ–å’Œå‘ç°ä¸­çš„æ½œåŠ›ã€‚</li>
<li>LLM2TEAçš„åº”ç”¨é¢†åŸŸå¹¿æ³›ï¼ŒåŒ…æ‹¬ä½†ä¸é™äºç§‘å­¦ã€å·¥ç¨‹ç­‰å¤æ‚è®¾è®¡ä¼˜åŒ–é¢†åŸŸã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2406.14917">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-529ae69f9da9a266b759085e16f39487.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a90674d4a9926b2deb4fc79485ec9a49.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-56bd2e29a731b1d28a8965af7dfc3acb.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-8b96f447d7007ce47f5fd8b8bb400c61.jpg" align="middle">
</details>


<h1 id="-12"><a href="#-12" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-06-13/Agent/">https://kedreamix.github.io/Talk2Paper/Paper/2025-06-13/Agent/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/Agent/">
                                    <span class="chip bg-color">Agent</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-06-13/MMT/">
                    <div class="card-image">
                        
                        <img src="https://pic1.zhimg.com/v2-ab1bc245e0ca943e7cf083d750d46a2b.jpg" class="responsive-img" alt="MMT">
                        
                        <span class="card-title">MMT</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            MMT æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-06-13  MTVQA Benchmarking Multilingual Text-Centric Visual Question Answering
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-06-13
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/MMT/" class="post-category">
                                    MMT
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/MMT/">
                        <span class="chip bg-color">MMT</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-06-13/LLM/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-89f8b96b14d87014d76a7f04f96333ae.jpg" class="responsive-img" alt="LLM">
                        
                        <span class="card-title">LLM</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            LLM æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-06-13  Large Language Models for Toxic Language Detection in Low-Resource   Balkan Languages
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-06-13
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/LLM/" class="post-category">
                                    LLM
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/LLM/">
                        <span class="chip bg-color">LLM</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">23667.4k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
