<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="I2I Translation">
    <meta name="description" content="I2I Translation æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-08-19  StyleMM Stylized 3D Morphable Face Model via Text-Driven Aligned Image   Translation">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>I2I Translation | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://picx.zhimg.com/v2-fbf02856ab90883492ec326e1cae83ba.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">I2I Translation</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/I2I-Translation/">
                                <span class="chip bg-color">I2I Translation</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/I2I-Translation/" class="post-category">
                                I2I Translation
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-08-19
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-09-08
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    7.2k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    29 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-08-19-æ›´æ–°"><a href="#2025-08-19-æ›´æ–°" class="headerlink" title="2025-08-19 æ›´æ–°"></a>2025-08-19 æ›´æ–°</h1><h2 id="StyleMM-Stylized-3D-Morphable-Face-Model-via-Text-Driven-Aligned-Image-Translation"><a href="#StyleMM-Stylized-3D-Morphable-Face-Model-via-Text-Driven-Aligned-Image-Translation" class="headerlink" title="StyleMM: Stylized 3D Morphable Face Model via Text-Driven Aligned Image   Translation"></a>StyleMM: Stylized 3D Morphable Face Model via Text-Driven Aligned Image   Translation</h2><p><strong>Authors:Seungmi Lee, Kwan Yun, Junyong Noh</strong></p>
<p>We introduce StyleMM, a novel framework that can construct a stylized 3D Morphable Model (3DMM) based on user-defined text descriptions specifying a target style. Building upon a pre-trained mesh deformation network and a texture generator for original 3DMM-based realistic human faces, our approach fine-tunes these models using stylized facial images generated via text-guided image-to-image (i2i) translation with a diffusion model, which serve as stylization targets for the rendered mesh. To prevent undesired changes in identity, facial alignment, or expressions during i2i translation, we introduce a stylization method that explicitly preserves the facial attributes of the source image. By maintaining these critical attributes during image stylization, the proposed approach ensures consistent 3D style transfer across the 3DMM parameter space through image-based training. Once trained, StyleMM enables feed-forward generation of stylized face meshes with explicit control over shape, expression, and texture parameters, producing meshes with consistent vertex connectivity and animatability. Quantitative and qualitative evaluations demonstrate that our approach outperforms state-of-the-art methods in terms of identity-level facial diversity and stylization capability. The code and videos are available at <a href="kwanyun.github.io/stylemm_page">kwanyun.github.io&#x2F;stylemm_page</a>. </p>
<blockquote>
<p>æˆ‘ä»¬ä»‹ç»äº†StyleMMï¼Œè¿™æ˜¯ä¸€ä¸ªæ–°å‹æ¡†æ¶ï¼Œå¯ä»¥æ ¹æ®ç”¨æˆ·å®šä¹‰çš„æ–‡æœ¬æè¿°æŒ‡å®šç›®æ ‡é£æ ¼æ¥æ„å»ºé£æ ¼åŒ–çš„3Då¯å˜å½¢æ¨¡å‹ï¼ˆ3DMMï¼‰ã€‚æˆ‘ä»¬çš„æ–¹æ³•å»ºç«‹åœ¨é¢„è®­ç»ƒçš„ç½‘æ ¼å˜å½¢ç½‘ç»œå’ŒåŸå§‹3DMMç°å®äººè„¸çš„çº¹ç†ç”Ÿæˆå™¨ä¹‹ä¸Šï¼Œä½¿ç”¨é€šè¿‡æ–‡æœ¬å¼•å¯¼çš„å›¾åƒåˆ°å›¾åƒï¼ˆi2iï¼‰ç¿»è¯‘æ‰©æ•£æ¨¡å‹ç”Ÿæˆçš„é£æ ¼åŒ–é¢éƒ¨å›¾åƒå¯¹è¿™äº›æ¨¡å‹è¿›è¡Œå¾®è°ƒï¼Œè¿™äº›å›¾åƒä½œä¸ºæ¸²æŸ“ç½‘æ ¼çš„é£æ ¼åŒ–ç›®æ ‡ã€‚ä¸ºäº†é˜²æ­¢åœ¨i2iç¿»è¯‘è¿‡ç¨‹ä¸­èº«ä»½ã€é¢éƒ¨å¯¹é½æˆ–è¡¨æƒ…å‘ç”Ÿä¸å¿…è¦çš„å˜åŒ–ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§æ˜¾å¼ä¿ç•™æºå›¾åƒé¢éƒ¨ç‰¹å¾çš„é£æ ¼åŒ–æ–¹æ³•ã€‚é€šè¿‡ä¿æŒè¿™äº›å…³é”®ç‰¹å¾åœ¨å›¾åƒé£æ ¼åŒ–è¿‡ç¨‹ä¸­çš„ä¸€è‡´æ€§ï¼Œæ‰€æå‡ºçš„æ–¹æ³•ç¡®ä¿äº†é€šè¿‡åŸºäºå›¾åƒçš„è®­ç»ƒåœ¨æ•´ä¸ª3DMMå‚æ•°ç©ºé—´è¿›è¡Œä¸€è‡´çš„3Dé£æ ¼è½¬æ¢ã€‚ä¸€æ—¦è®­ç»ƒå®Œæˆï¼ŒStyleMMå°±èƒ½å¤Ÿä»¥å‰é¦ˆæ–¹å¼ç”Ÿæˆå…·æœ‰æ˜ç¡®å½¢çŠ¶ã€è¡¨æƒ…å’Œçº¹ç†å‚æ•°æ§åˆ¶çš„é£æ ¼åŒ–é¢éƒ¨ç½‘æ ¼ï¼Œäº§ç”Ÿå…·æœ‰ä¸€è‡´é¡¶ç‚¹è¿æ¥å’ŒåŠ¨ç”»èƒ½åŠ›çš„ç½‘æ ¼ã€‚å®šé‡å’Œå®šæ€§è¯„ä¼°è¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨èº«ä»½çº§åˆ«çš„é¢éƒ¨å¤šæ ·æ€§å’Œé£æ ¼åŒ–èƒ½åŠ›æ–¹é¢ä¼˜äºæœ€å…ˆè¿›çš„æ–¹æ³•ã€‚ä»£ç å’Œè§†é¢‘å¯åœ¨<a href="kwanyun.github.io/stylemm_page">kwanyun.github.io&#x2F;stylemm_page</a>æŸ¥çœ‹ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.11203v1">PDF</a> Pacific graphics 2025, CGF, 15 pages</p>
<p><strong>Summary</strong></p>
<p>åŸºäºç”¨æˆ·å®šä¹‰æ–‡æœ¬æè¿°çš„ç›®æ ‡é£æ ¼ï¼Œæˆ‘ä»¬å¼•å…¥äº†StyleMMè¿™ä¸€æ–°å‹æ¡†æ¶ï¼Œæ„å»ºäº†ä¸€ä¸ªé£æ ¼åŒ–çš„3Då¯å˜å½¢æ¨¡å‹ï¼ˆ3DMMï¼‰ã€‚è¯¥æ¡†æ¶åœ¨é¢„è®­ç»ƒçš„ç½‘æ ¼å˜å½¢ç½‘ç»œå’ŒåŸå§‹3DMMé€¼çœŸäººè„¸çº¹ç†ç”Ÿæˆå™¨çš„åŸºç¡€ä¸Šï¼Œä½¿ç”¨æ–‡æœ¬å¼•å¯¼çš„å›¾åƒåˆ°å›¾åƒï¼ˆi2iï¼‰ç¿»è¯‘æ‰©æ•£æ¨¡å‹ç”Ÿæˆé£æ ¼åŒ–é¢éƒ¨å›¾åƒï¼Œä½œä¸ºæ¸²æŸ“ç½‘æ ¼çš„é£æ ¼åŒ–ç›®æ ‡è¿›è¡Œå¾®è°ƒã€‚ä¸ºé˜»æ­¢i2iç¿»è¯‘è¿‡ç¨‹ä¸­èº«ä»½ã€é¢éƒ¨å¯¹é½æˆ–è¡¨æƒ…çš„ä¸å¿…è¦å˜åŒ–ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§æ˜¾å¼ä¿ç•™æºå›¾åƒé¢éƒ¨ç‰¹å¾çš„é£æ ¼åŒ–æ–¹æ³•ã€‚é€šè¿‡ä¿æŒè¿™äº›å…³é”®ç‰¹å¾åœ¨å›¾åƒé£æ ¼åŒ–è¿‡ç¨‹ä¸­çš„ä¸€è‡´æ€§ï¼Œæ‰€æå‡ºçš„æ–¹æ³•ç¡®ä¿äº†åœ¨æ•´ä¸ª3DMMå‚æ•°ç©ºé—´ä¸­çš„3Dé£æ ¼è½¬æ¢é€šè¿‡åŸºäºå›¾åƒçš„è®­ç»ƒå®ç°ä¸€è‡´ã€‚è®­ç»ƒåçš„StyleMMå¯ä»¥é€šè¿‡å‰å‘ç”Ÿæˆé£æ ¼åŒ–çš„é¢éƒ¨ç½‘æ ¼ï¼Œå¯¹å½¢çŠ¶ã€è¡¨æƒ…å’Œçº¹ç†å‚æ•°è¿›è¡Œæ˜¾å¼æ§åˆ¶ï¼Œäº§ç”Ÿå…·æœ‰ä¸€è‡´é¡¶ç‚¹è¿æ¥å’ŒåŠ¨ç”»èƒ½åŠ›çš„ç½‘æ ¼ã€‚å®šé‡å’Œå®šæ€§è¯„ä¼°è¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨èº«ä»½çº§åˆ«çš„é¢éƒ¨å¤šæ ·æ€§å’Œé£æ ¼åŒ–èƒ½åŠ›æ–¹é¢ä¼˜äºç°æœ‰æŠ€æœ¯ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>StyleMMæ˜¯ä¸€ä¸ªåŸºäºç”¨æˆ·å®šä¹‰æ–‡æœ¬æè¿°æ„å»ºé£æ ¼åŒ–3Då¯å˜å½¢æ¨¡å‹ï¼ˆ3DMMï¼‰çš„æ¡†æ¶ã€‚</li>
<li>åˆ©ç”¨é¢„è®­ç»ƒæ¨¡å‹å¹¶ç»“åˆæ–‡æœ¬å¼•å¯¼çš„i2iç¿»è¯‘æ‰©æ•£æ¨¡å‹ç”Ÿæˆé£æ ¼åŒ–é¢éƒ¨å›¾åƒã€‚</li>
<li>å¼•å…¥é£æ ¼åŒ–æ–¹æ³•ï¼Œæ˜¾å¼ä¿ç•™æºå›¾åƒçš„é¢éƒ¨ç‰¹å¾ï¼Œä»¥ä¿æŒèº«ä»½ã€é¢éƒ¨å¯¹é½å’Œè¡¨æƒ…çš„ä¸€è‡´æ€§ã€‚</li>
<li>é€šè¿‡å›¾åƒåŸºè®­ç»ƒå®ç°æ•´ä¸ª3DMMå‚æ•°ç©ºé—´ä¸­çš„ä¸€è‡´3Dé£æ ¼è½¬æ¢ã€‚</li>
<li>StyleMMå¯ä»¥ç”Ÿæˆå…·æœ‰ä¸€è‡´é¡¶ç‚¹è¿æ¥å’ŒåŠ¨ç”»èƒ½åŠ›çš„é£æ ¼åŒ–é¢éƒ¨ç½‘æ ¼ï¼Œå…·æœ‰æ˜¾å¼æ§åˆ¶å½¢çŠ¶ã€è¡¨è¾¾å’Œçº¹ç†å‚æ•°çš„èƒ½åŠ›ã€‚</li>
<li>ä¸ç°æœ‰æŠ€æœ¯ç›¸æ¯”ï¼ŒStyleMMåœ¨èº«ä»½çº§åˆ«çš„é¢éƒ¨å¤šæ ·æ€§å’Œé£æ ¼åŒ–èƒ½åŠ›æ–¹é¢è¡¨ç°ä¼˜è¶Šã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.11203">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-24c4153a81a2390528acff0042cef047.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-3df3c699501d1a68ed0de5fc01b76a00.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-0aaff26d9a31e9a524be9e3ff7806462.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-09a9b2ba661fc3a1f6f83a08284c82b5.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-11bd7253b70daf1ebe6589dcfb09b81d.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="Residual-based-Efficient-Bidirectional-Diffusion-Model-for-Image-Dehazing-and-Haze-Generation"><a href="#Residual-based-Efficient-Bidirectional-Diffusion-Model-for-Image-Dehazing-and-Haze-Generation" class="headerlink" title="Residual-based Efficient Bidirectional Diffusion Model for Image   Dehazing and Haze Generation"></a>Residual-based Efficient Bidirectional Diffusion Model for Image   Dehazing and Haze Generation</h2><p><strong>Authors:Bing Liu, Le Wang, Hao Liu, Mingming Liu</strong></p>
<p>Current deep dehazing methods only focus on removing haze from hazy images, lacking the capability to translate between hazy and haze-free images. To address this issue, we propose a residual-based efficient bidirectional diffusion model (RBDM) that can model the conditional distributions for both dehazing and haze generation. Firstly, we devise dual Markov chains that can effectively shift the residuals and facilitate bidirectional smooth transitions between them. Secondly, the RBDM perturbs the hazy and haze-free images at individual timesteps and predicts the noise in the perturbed data to simultaneously learn the conditional distributions. Finally, to enhance performance on relatively small datasets and reduce computational costs, our method introduces a unified score function learned on image patches instead of entire images. Our RBDM successfully implements size-agnostic bidirectional transitions between haze-free and hazy images with only 15 sampling steps. Extensive experiments demonstrate that the proposed method achieves superior or at least comparable performance to state-of-the-art methods on both synthetic and real-world datasets. </p>
<blockquote>
<p>å½“å‰æ·±åº¦å»é›¾æ–¹æ³•ä»…ä¸“æ³¨äºä»é›¾éœ¾å›¾åƒä¸­å»é™¤é›¾éœ¾ï¼Œç¼ºä¹åœ¨é›¾éœ¾å’Œæ— é›¾å›¾åƒä¹‹é—´è¿›è¡Œç¿»è¯‘çš„èƒ½åŠ›ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åŸºäºæ®‹å·®çš„é«˜æ•ˆåŒå‘æ‰©æ•£æ¨¡å‹ï¼ˆRBDMï¼‰ï¼Œè¯¥æ¨¡å‹å¯ä»¥å¯¹å»é›¾å’Œé›¾éœ¾ç”Ÿæˆçš„æ¡ä»¶åˆ†å¸ƒè¿›è¡Œå»ºæ¨¡ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬è®¾è®¡äº†åŒé©¬å°”å¯å¤«é“¾ï¼Œå¯ä»¥æœ‰æ•ˆåœ°è½¬æ¢æ®‹å·®ï¼Œä¿ƒè¿›å®ƒä»¬ä¹‹é—´çš„åŒå‘å¹³æ»‘è¿‡æ¸¡ã€‚å…¶æ¬¡ï¼ŒRBDMåœ¨å•ä¸ªæ—¶é—´æ­¥é•¿å†…æ‰°åŠ¨æ— é›¾å’Œé›¾éœ¾å›¾åƒï¼Œå¹¶é¢„æµ‹å—æ‰°åŠ¨æ•°æ®ä¸­çš„å™ªå£°ï¼Œä»¥åŒæ—¶å­¦ä¹ æ¡ä»¶åˆ†å¸ƒã€‚æœ€åï¼Œä¸ºäº†æé«˜åœ¨ç›¸å¯¹è¾ƒå°æ•°æ®é›†ä¸Šçš„æ€§èƒ½å¹¶é™ä½è®¡ç®—æˆæœ¬ï¼Œæˆ‘ä»¬çš„æ–¹æ³•å¼•å…¥äº†ä¸€ä¸ªåœ¨å›¾åƒå—ä¸Šå­¦ä¹ çš„ç»Ÿä¸€è¯„åˆ†å‡½æ•°ï¼Œè€Œä¸æ˜¯åœ¨æ•´ä¸ªå›¾åƒä¸Šã€‚æˆ‘ä»¬çš„RBDMä»…ä½¿ç”¨15ä¸ªé‡‡æ ·æ­¥éª¤å°±æˆåŠŸå®ç°äº†æ— é›¾å’Œé›¾éœ¾å›¾åƒä¹‹é—´å¤§å°æ— å…³çš„åŒå‘è¿‡æ¸¡ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼Œæ‰€æå‡ºçš„æ–¹æ³•åœ¨åˆæˆå’ŒçœŸå®ä¸–ç•Œæ•°æ®é›†ä¸Šå‡è¾¾åˆ°äº†æˆ–è‡³å°‘ä¸æœ€å…ˆè¿›çš„æ–¹æ³•ç›¸å½“çš„æ€§èƒ½ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.11134v1">PDF</a> 7 pages, 5 figures, 2025 ICME Accepted</p>
<p><strong>Summary</strong>ï¼š</p>
<p>æå‡ºä¸€ç§åŸºäºæ®‹å·®çš„åŒå‘æ‰©æ•£æ¨¡å‹ï¼ˆRBDMï¼‰ï¼Œèƒ½å»ºæ¨¡å»é›¾å’Œç”Ÿæˆé›¾çš„æ¡ä»¶åˆ†å¸ƒã€‚é€šè¿‡åŒé©¬å°”å¯å¤«é“¾å®ç°æ®‹å·®è½¬ç§»ï¼ŒåŒå‘å¹³æ»‘è¿‡æ¸¡ã€‚å¯¹å»é›¾å’Œæ¸…æ™°å›¾åƒè¿›è¡Œæ‰°åŠ¨ï¼Œé¢„æµ‹æ‰°åŠ¨æ•°æ®çš„å™ªå£°ï¼Œå­¦ä¹ æ¡ä»¶åˆ†å¸ƒã€‚å¼•å…¥ç»Ÿä¸€è¯„åˆ†å‡½æ•°ï¼Œæé«˜å°æ•°æ®é›†æ€§èƒ½ï¼Œé™ä½è®¡ç®—æˆæœ¬ã€‚æˆåŠŸå®ç°å»é›¾å’Œæ¸…æ™°å›¾åƒä¹‹é—´çš„å°ºå¯¸æ— å…³åŒå‘è½¬æ¢ï¼Œä»…éœ€15ä¸ªé‡‡æ ·æ­¥éª¤ã€‚åœ¨åˆæˆå’ŒçœŸå®æ•°æ®é›†ä¸Šå®ç°ä¼˜å¼‚æ€§èƒ½ã€‚</p>
<p><strong>Key Takeaways</strong>ï¼š</p>
<ol>
<li>å¼•å…¥åŸºäºæ®‹å·®çš„åŒå‘æ‰©æ•£æ¨¡å‹ï¼ˆRBDMï¼‰ï¼Œèƒ½å¤„ç†å»é›¾å’Œé›¾ç”Ÿæˆä¸¤ç§æƒ…å†µçš„å›¾åƒè½¬æ¢ã€‚</li>
<li>ä½¿ç”¨åŒé©¬å°”å¯å¤«é“¾å®ç°æ®‹å·®è½¬ç§»ï¼Œå®ç°å›¾åƒé—´çš„åŒå‘å¹³æ»‘è¿‡æ¸¡ã€‚</li>
<li>é€šè¿‡æ‰°åŠ¨å›¾åƒå¹¶é¢„æµ‹å™ªå£°ï¼Œå­¦ä¹ å»é›¾å’Œæ¸…æ™°å›¾åƒçš„æ¡ä»¶åˆ†å¸ƒã€‚</li>
<li>å¼•å…¥ç»Ÿä¸€è¯„åˆ†å‡½æ•°ï¼Œæé«˜åœ¨å°æ•°æ®é›†ä¸Šçš„æ€§èƒ½ï¼Œå¹¶é™ä½è®¡ç®—æˆæœ¬ã€‚</li>
<li>æ¨¡å‹èƒ½åœ¨ä»…15ä¸ªé‡‡æ ·æ­¥éª¤å†…å®ç°å»é›¾å’Œæ¸…æ™°å›¾åƒä¹‹é—´çš„è½¬æ¢ã€‚</li>
<li>åœ¨åˆæˆæ•°æ®é›†ä¸Šçš„æ€§èƒ½ä¼˜äºæˆ–è‡³å°‘ä¸ç°æœ‰æŠ€æœ¯ç›¸å½“ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.11134">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-76a176208cd581cba8c79a197648e07b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e13d2260a752525edf320319bef0d89e.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-1f791d27acc5589854121642b4057152.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-9eebcf3a19639936ba70b237d2f8d248.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-a5955921ee0af8be3322721ef52f1947.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-7f4503a1465caffb7a467a9599a8fa26.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="Novel-View-Synthesis-using-DDIM-Inversion"><a href="#Novel-View-Synthesis-using-DDIM-Inversion" class="headerlink" title="Novel View Synthesis using DDIM Inversion"></a>Novel View Synthesis using DDIM Inversion</h2><p><strong>Authors:Sehajdeep SIngh, A V Subramanyam</strong></p>
<p>Synthesizing novel views from a single input image is a challenging task. It requires extrapolating the 3D structure of a scene while inferring details in occluded regions, and maintaining geometric consistency across viewpoints. Many existing methods must fine-tune large diffusion backbones using multiple views or train a diffusion model from scratch, which is extremely expensive. Additionally, they suffer from blurry reconstruction and poor generalization. This gap presents the opportunity to explore an explicit lightweight view translation framework that can directly utilize the high-fidelity generative capabilities of a pretrained diffusion model while reconstructing a scene from a novel view. Given the DDIM-inverted latent of a single input image, we employ a camera pose-conditioned translation U-Net, TUNet, to predict the inverted latent corresponding to the desired target view. However, the image sampled using the predicted latent may result in a blurry reconstruction. To this end, we propose a novel fusion strategy that exploits the inherent noise correlation structure observed in DDIM inversion. The proposed fusion strategy helps preserve the texture and fine-grained details. To synthesize the novel view, we use the fused latent as the initial condition for DDIM sampling, leveraging the generative prior of the pretrained diffusion model. Extensive experiments on MVImgNet demonstrate that our method outperforms existing methods. </p>
<blockquote>
<p>ä»å•ä¸€è¾“å…¥å›¾åƒåˆæˆæ–°é¢–è§†è§’æ˜¯ä¸€é¡¹å…·æœ‰æŒ‘æˆ˜æ€§çš„ä»»åŠ¡ã€‚å®ƒè¦æ±‚åœ¨æ¨æ–­é®æŒ¡åŒºåŸŸçš„ç»†èŠ‚æ—¶æ¨æ–­å‡ºåœºæ™¯çš„3Dç»“æ„ï¼Œå¹¶åœ¨ä¸åŒè§†è§’ä¹‹é—´ä¿æŒå‡ ä½•ä¸€è‡´æ€§ã€‚è®¸å¤šç°æœ‰æ–¹æ³•å¿…é¡»ä½¿ç”¨å¤šç§è§†è§’å¯¹å¤§å‹æ‰©æ•£ä¸»å¹²è¿›è¡Œå¾®è°ƒï¼Œæˆ–è€…ä»å¤´å¼€å§‹è®­ç»ƒæ‰©æ•£æ¨¡å‹ï¼Œè¿™æˆæœ¬æé«˜ã€‚æ­¤å¤–ï¼Œå®ƒä»¬è¿˜å­˜åœ¨æ¨¡ç³Šé‡å»ºå’Œæ³›åŒ–èƒ½åŠ›å·®çš„ç¼ºç‚¹ã€‚è¿™ä¸€å·®è·ä¸ºæˆ‘ä»¬æ¢ç´¢ä¸€ä¸ªæ˜ç¡®çš„è½»é‡çº§è§†å›¾ç¿»è¯‘æ¡†æ¶æä¾›äº†æœºä¼šï¼Œè¯¥æ¡†æ¶èƒ½å¤Ÿåˆ©ç”¨é¢„è®­ç»ƒæ‰©æ•£æ¨¡å‹çš„é«˜ä¿çœŸç”Ÿæˆèƒ½åŠ›ï¼Œä»æ–°é¢–è§†è§’é‡å»ºåœºæ™¯ã€‚ç»™å®šå•ä¸ªè¾“å…¥å›¾åƒçš„DDIMåå‘ä¼ æ’­æ½œåœ¨ç‰¹å¾ï¼Œæˆ‘ä»¬é‡‡ç”¨å—ç›¸æœºå§¿æ€æ§åˆ¶çš„ç¿»è¯‘U-Netï¼ˆTUNetï¼‰æ¥é¢„æµ‹å¯¹åº”ç›®æ ‡è§†è§’çš„åå‘ä¼ æ’­æ½œåœ¨ç‰¹å¾ã€‚ç„¶è€Œï¼Œä½¿ç”¨é¢„æµ‹æ½œåœ¨ç‰¹å¾æ‰€é‡‡æ ·çš„å›¾åƒå¯èƒ½ä¼šå¯¼è‡´é‡å»ºæ¨¡ç³Šã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åˆ©ç”¨DDIMåæ¼”ä¸­è§‚å¯Ÿåˆ°çš„å›ºæœ‰å™ªå£°ç›¸å…³æ€§ç»“æ„çš„æ–°å‹èåˆç­–ç•¥ã€‚è¯¥èåˆç­–ç•¥æœ‰åŠ©äºä¿ç•™çº¹ç†å’Œç»†ç²’åº¦ç»†èŠ‚ã€‚ä¸ºäº†åˆæˆæ–°é¢–è§†è§’ï¼Œæˆ‘ä»¬ä½¿ç”¨èåˆåçš„æ½œåœ¨ç‰¹å¾ä½œä¸ºDDIMé‡‡æ ·çš„åˆå§‹æ¡ä»¶ï¼Œåˆ©ç”¨é¢„è®­ç»ƒæ‰©æ•£æ¨¡å‹çš„ç”Ÿæˆå…ˆéªŒã€‚åœ¨MVImgNetä¸Šçš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•ä¼˜äºç°æœ‰æ–¹æ³•ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.10688v1">PDF</a> </p>
<p><strong>Summary</strong><br>     é’ˆå¯¹å•ä¸€è¾“å…¥å›¾åƒåˆæˆæ–°é¢–è§†è§’çš„ä»»åŠ¡ï¼Œç°æœ‰æ–¹æ³•éœ€è¦å¾®è°ƒå¤§å‹æ‰©æ•£æ¨¡å‹æˆ–ä½¿ç”¨å¤šä¸ªè§†è§’è¿›è¡Œè®­ç»ƒï¼Œæˆæœ¬é«˜æ˜‚ä¸”å­˜åœ¨æ¨¡ç³Šé‡å»ºå’Œæ³›åŒ–èƒ½åŠ›å·®çš„é—®é¢˜ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬æå‡ºä¸€ç§æ˜¾å¼è½»é‡çº§è§†è§’è½¬æ¢æ¡†æ¶ï¼Œåˆ©ç”¨é¢„è®­ç»ƒæ‰©æ•£æ¨¡å‹çš„é«˜ä¿çœŸç”Ÿæˆèƒ½åŠ›ï¼Œé€šè¿‡ç›¸æœºå§¿æ€è°ƒèŠ‚çš„ç¿»è¯‘U-Netæ¥é¢„æµ‹ç›®æ ‡è§†è§’çš„å€’ç½®æ½œåœ¨å¯¹åº”ç‰©ã€‚ä¸ºæé«˜é‡å»ºå›¾åƒçš„æ¸…æ™°åº¦ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åˆ©ç”¨DDIMåè½¬è¿‡ç¨‹ä¸­è§‚å¯Ÿåˆ°çš„å›ºæœ‰å™ªå£°ç›¸å…³ç»“æ„çš„æ–°èåˆç­–ç•¥ã€‚å®éªŒè¯æ˜ï¼Œè¯¥æ–¹æ³•åœ¨MVImgNetä¸Šè¡¨ç°ä¼˜å¼‚ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>åˆæˆæ–°é¢–è§†è§’æ˜¯ä¸€é¡¹æŒ‘æˆ˜ä»»åŠ¡ï¼Œè¦æ±‚ä»å•ä¸€è¾“å…¥å›¾åƒä¸­æ¨æ–­å‡ºåœºæ™¯çš„3Dç»“æ„å¹¶åœ¨éšè—åŒºåŸŸè¿›è¡Œç»†èŠ‚æ¨æ–­ï¼ŒåŒæ—¶ä¿æŒä¸åŒè§†è§’çš„å‡ ä½•ä¸€è‡´æ€§ã€‚</li>
<li>ç°æœ‰æ–¹æ³•éœ€è¦æ˜‚è´µçš„å¾®è°ƒå¤§å‹æ‰©æ•£æ¨¡å‹æˆ–ä½¿ç”¨å¤šä¸ªè§†è§’è¿›è¡Œè®­ç»ƒï¼Œå­˜åœ¨æ¨¡ç³Šé‡å»ºå’Œæ³›åŒ–èƒ½åŠ›å·®çš„é—®é¢˜ã€‚</li>
<li>æå‡ºä¸€ç§è½»é‡çº§è§†è§’è½¬æ¢æ¡†æ¶ï¼Œåˆ©ç”¨é¢„è®­ç»ƒæ‰©æ•£æ¨¡å‹çš„é«˜ä¿çœŸç”Ÿæˆèƒ½åŠ›ã€‚</li>
<li>ä½¿ç”¨ç›¸æœºå§¿æ€è°ƒèŠ‚çš„ç¿»è¯‘U-Netï¼ˆTUNetï¼‰é¢„æµ‹ç›®æ ‡è§†è§’çš„å€’ç½®æ½œåœ¨å¯¹åº”ç‰©ã€‚</li>
<li>æå‡ºä¸€ç§æ–°å‹èåˆç­–ç•¥ï¼Œåˆ©ç”¨DDIMåè½¬è¿‡ç¨‹ä¸­çš„å™ªå£°ç›¸å…³ç»“æ„ï¼Œå¸®åŠ©ä¿ç•™çº¹ç†å’Œç»†èŠ‚ã€‚</li>
<li>ä½¿ç”¨èåˆåçš„æ½œåœ¨æ¡ä»¶ä½œä¸ºDDIMé‡‡æ ·çš„åˆå§‹æ¡ä»¶ï¼Œåˆ©ç”¨é¢„è®­ç»ƒæ‰©æ•£æ¨¡å‹çš„ç”Ÿæˆå…ˆéªŒæ¥åˆæˆæ–°é¢–è§†è§’ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.10688">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-6f90a471e30ab6f1e73d8bbde4fe994c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-4d431081396646a66cd4c1d9560e98ef.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c7f35760138c043d0c09ceb8b8d60933.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-fbf02856ab90883492ec326e1cae83ba.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="MANGO-Multimodal-Attention-based-Normalizing-Flow-Approach-to-Fusion-Learning"><a href="#MANGO-Multimodal-Attention-based-Normalizing-Flow-Approach-to-Fusion-Learning" class="headerlink" title="MANGO: Multimodal Attention-based Normalizing Flow Approach to Fusion   Learning"></a>MANGO: Multimodal Attention-based Normalizing Flow Approach to Fusion   Learning</h2><p><strong>Authors:Thanh-Dat Truong, Christophe Bobda, Nitin Agarwal, Khoa Luu</strong></p>
<p>Multimodal learning has gained much success in recent years. However, current multimodal fusion methods adopt the attention mechanism of Transformers to implicitly learn the underlying correlation of multimodal features. As a result, the multimodal model cannot capture the essential features of each modality, making it difficult to comprehend complex structures and correlations of multimodal inputs. This paper introduces a novel Multimodal Attention-based Normalizing Flow (MANGO) approach\footnote{The source code of this work will be publicly available.} to developing explicit, interpretable, and tractable multimodal fusion learning. In particular, we propose a new Invertible Cross-Attention (ICA) layer to develop the Normalizing Flow-based Model for multimodal data. To efficiently capture the complex, underlying correlations in multimodal data in our proposed invertible cross-attention layer, we propose three new cross-attention mechanisms: Modality-to-Modality Cross-Attention (MMCA), Inter-Modality Cross-Attention (IMCA), and Learnable Inter-Modality Cross-Attention (LICA). Finally, we introduce a new Multimodal Attention-based Normalizing Flow to enable the scalability of our proposed method to high-dimensional multimodal data. Our experimental results on three different multimodal learning tasks, i.e., semantic segmentation, image-to-image translation, and movie genre classification, have illustrated the state-of-the-art (SoTA) performance of the proposed approach. </p>
<blockquote>
<p>è¿‘å¹´æ¥ï¼Œå¤šæ¨¡æ€å­¦ä¹ å–å¾—äº†å·¨å¤§çš„æˆåŠŸã€‚ç„¶è€Œï¼Œå½“å‰çš„å¤šæ¨¡æ€èåˆæ–¹æ³•é‡‡ç”¨Transformerçš„æ³¨æ„åŠ›æœºåˆ¶æ¥éšå¼åœ°å­¦ä¹ å¤šæ¨¡æ€ç‰¹å¾ä¹‹é—´çš„åº•å±‚å…³è”ã€‚å› æ­¤ï¼Œå¤šæ¨¡æ€æ¨¡å‹æ— æ³•æ•æ‰æ¯ç§æ¨¡æ€çš„åŸºæœ¬ç‰¹å¾ï¼Œéš¾ä»¥ç†è§£å¤šæ¨¡æ€è¾“å…¥çš„å¤æ‚ç»“æ„å’Œå…³è”ã€‚æœ¬æ–‡ä»‹ç»äº†ä¸€ç§æ–°é¢–çš„å¤šæ¨¡æ€æ³¨æ„åŠ›åŸºç¡€å½’ä¸€åŒ–æµï¼ˆMANGOï¼‰æ–¹æ³•ï¼ˆè¯¥å·¥ä½œçš„æºä»£ç å°†å…¬å¼€å‘å¸ƒï¼‰æ¥å¼€å‘æ˜ç¡®ã€å¯è§£é‡Šå’Œå¯è¡Œçš„å¤šæ¨¡æ€èåˆå­¦ä¹ ã€‚ç‰¹åˆ«æ˜¯ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°çš„å¯é€†è·¨æ³¨æ„åŠ›ï¼ˆICAï¼‰å±‚æ¥å¼€å‘åŸºäºå½’ä¸€åŒ–æµçš„å¤šæ¨¡æ€æ•°æ®æ¨¡å‹ã€‚ä¸ºäº†åœ¨æˆ‘ä»¬æå‡ºçš„å¯é€†è·¨æ³¨æ„åŠ›å±‚ä¸­æœ‰æ•ˆåœ°æ•æ‰å¤šæ¨¡æ€æ•°æ®ä¸­å¤æ‚çš„åº•å±‚å…³è”ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸‰ç§æ–°çš„è·¨æ³¨æ„åŠ›æœºåˆ¶ï¼šæ¨¡æ€é—´è·¨æ³¨æ„åŠ›ï¼ˆMMCAï¼‰ã€è·¨æ¨¡æ€é—´æ³¨æ„åŠ›ï¼ˆIMCAï¼‰å’Œå­¦ä¹ è·¨æ¨¡æ€é—´æ³¨æ„åŠ›ï¼ˆLICAï¼‰ã€‚æœ€åï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§æ–°çš„å¤šæ¨¡æ€æ³¨æ„åŠ›åŸºç¡€å½’ä¸€åŒ–æµï¼Œä½¿æ‰€æå‡ºçš„æ–¹æ³•èƒ½å¤Ÿæ‰©å±•åˆ°é«˜ç»´å¤šæ¨¡æ€æ•°æ®ã€‚æˆ‘ä»¬åœ¨ä¸‰ç§ä¸åŒçš„å¤šæ¨¡æ€å­¦ä¹ ä»»åŠ¡ï¼ˆå³è¯­ä¹‰åˆ†å‰²ã€å›¾åƒåˆ°å›¾åƒçš„ç¿»è¯‘å’Œç”µå½±ç±»å‹åˆ†ç±»ï¼‰ä¸Šçš„å®éªŒç»“æœè¯æ˜äº†æ‰€æå‡ºæ–¹æ³•çš„æœ€æ–°æŠ€æœ¯æ€§èƒ½ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.10133v1">PDF</a> </p>
<p><strong>Summary</strong><br>å¤šæ¨¡æ€å­¦ä¹ è¿‘å¹´å–å¾—äº†å¾ˆå¤§è¿›å±•ï¼Œä½†å½“å‰çš„å¤šæ¨¡æ€èåˆæ–¹æ³•é‡‡ç”¨Transformerçš„æ³¨æ„åŠ›æœºåˆ¶æ¥éšå¼å­¦ä¹ å¤šæ¨¡æ€ç‰¹å¾ä¹‹é—´çš„å…³è”ã€‚è¿™å¯¼è‡´å¤šæ¨¡æ€æ¨¡å‹æ— æ³•æ•æ‰æ¯ä¸ªæ¨¡æ€çš„å…³é”®ç‰¹å¾ï¼Œéš¾ä»¥ç†è§£å’Œåˆ†æå¤šæ¨¡æ€è¾“å…¥çš„å¤æ‚ç»“æ„å’Œå…³è”ã€‚æœ¬æ–‡æå‡ºä¸€ç§æ–°é¢–çš„å¤šæ¨¡æ€æ³¨æ„åŠ›åŸºç¡€å½’ä¸€åŒ–æµï¼ˆMANGOï¼‰æ–¹æ³•ï¼Œå¼€å‘æ˜ç¡®ã€å¯è§£é‡Šå’Œå¯è¿½è¸ªçš„å¤šæ¨¡æ€èåˆå­¦ä¹ ã€‚ç‰¹åˆ«æ˜¯ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°çš„å¯é€†äº¤å‰æ³¨æ„åŠ›ï¼ˆICAï¼‰å±‚ï¼Œç”¨äºå¼€å‘åŸºäºå½’ä¸€åŒ–æµçš„å¤šæ¨¡æ€æ•°æ®æ¨¡å‹ã€‚ä¸ºäº†åœ¨æˆ‘ä»¬çš„å¯é€†äº¤å‰æ³¨æ„åŠ›å±‚ä¸­æœ‰æ•ˆåœ°æ•æ‰å¤šæ¨¡æ€æ•°æ®çš„å¤æ‚åº•å±‚å…³è”ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸‰ç§æ–°çš„äº¤å‰æ³¨æ„åŠ›æœºåˆ¶ã€‚æœ€åï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§æ–°çš„å¤šæ¨¡æ€æ³¨æ„åŠ›åŸºç¡€å½’ä¸€åŒ–æµï¼Œä½¿æ‰€ææ–¹æ³•èƒ½å¤Ÿæ‰©å±•åˆ°é«˜ç»´å¤šæ¨¡æ€æ•°æ®ã€‚åœ¨ä¸‰ä¸ªä¸åŒçš„å¤šæ¨¡æ€å­¦ä¹ ä»»åŠ¡ä¸Šçš„å®éªŒç»“æœè¯æ˜äº†æ‰€ææ–¹æ³•çš„ä¼˜è¶Šæ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å½“å‰å¤šæ¨¡æ€èåˆæ–¹æ³•å­˜åœ¨éš¾ä»¥æ•æ‰æ¯ä¸ªæ¨¡æ€å…³é”®ç‰¹å¾çš„é—®é¢˜ã€‚</li>
<li>è®ºæ–‡æå‡ºä¸€ç§æ–°çš„å¤šæ¨¡æ€æ³¨æ„åŠ›åŸºç¡€å½’ä¸€åŒ–æµï¼ˆMANGOï¼‰æ–¹æ³•ï¼Œæ—¨åœ¨è§£å†³ä¸Šè¿°é—®é¢˜ã€‚</li>
<li>å¼•å…¥å¯é€†äº¤å‰æ³¨æ„åŠ›ï¼ˆICAï¼‰å±‚ï¼Œä¸ºå¼€å‘åŸºäºå½’ä¸€åŒ–æµçš„å¤šæ¨¡æ€æ•°æ®æ¨¡å‹æä¾›åŸºç¡€ã€‚</li>
<li>æå‡ºä¸‰ç§æ–°çš„äº¤å‰æ³¨æ„åŠ›æœºåˆ¶ï¼šæ¨¡æ€é—´äº¤å‰æ³¨æ„åŠ›ï¼ˆMMCAï¼‰ã€è·¨æ¨¡æ€äº¤å‰æ³¨æ„åŠ›ï¼ˆIMCAï¼‰å’Œå¯å­¦ä¹ è·¨æ¨¡æ€äº¤å‰æ³¨æ„åŠ›ï¼ˆLICAï¼‰ã€‚</li>
<li>æ‰€ææ–¹æ³•èƒ½å¤Ÿæœ‰æ•ˆæ•æ‰å¤šæ¨¡æ€æ•°æ®çš„å¤æ‚åº•å±‚å…³è”ã€‚</li>
<li>è®ºæ–‡å®éªŒéªŒè¯äº†æ‰€ææ–¹æ³•åœ¨ä¸‰ç§ä¸åŒå¤šæ¨¡æ€å­¦ä¹ ä»»åŠ¡ä¸Šçš„ä¼˜è¶Šæ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.10133">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-cb9f04a6b7cdf765e2ac01b7a1b339a0.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-22389b45c4a020b1d5f50abb844f5468.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="RampNet-A-Two-Stage-Pipeline-for-Bootstrapping-Curb-Ramp-Detection-in-Streetscape-Images-from-Open-Government-Metadata"><a href="#RampNet-A-Two-Stage-Pipeline-for-Bootstrapping-Curb-Ramp-Detection-in-Streetscape-Images-from-Open-Government-Metadata" class="headerlink" title="RampNet: A Two-Stage Pipeline for Bootstrapping Curb Ramp Detection in   Streetscape Images from Open Government Metadata"></a>RampNet: A Two-Stage Pipeline for Bootstrapping Curb Ramp Detection in   Streetscape Images from Open Government Metadata</h2><p><strong>Authors:John S. Oâ€™Meara, Jared Hwang, Zeyu Wang, Michael Saugstad, Jon E. Froehlich</strong></p>
<p>Curb ramps are critical for urban accessibility, but robustly detecting them in images remains an open problem due to the lack of large-scale, high-quality datasets. While prior work has attempted to improve data availability with crowdsourced or manually labeled data, these efforts often fall short in either quality or scale. In this paper, we introduce and evaluate a two-stage pipeline called RampNet to scale curb ramp detection datasets and improve model performance. In Stage 1, we generate a dataset of more than 210,000 annotated Google Street View (GSV) panoramas by auto-translating government-provided curb ramp location data to pixel coordinates in panoramic images. In Stage 2, we train a curb ramp detection model (modified ConvNeXt V2) from the generated dataset, achieving state-of-the-art performance. To evaluate both stages of our pipeline, we compare to manually labeled panoramas. Our generated dataset achieves 94.0% precision and 92.5% recall, and our detection model reaches 0.9236 AP â€“ far exceeding prior work. Our work contributes the first large-scale, high-quality curb ramp detection dataset, benchmark, and model. </p>
<blockquote>
<p>è·¯ç¼˜çŸ³å¡é“å¯¹äºåŸå¸‚å¯è¾¾æ€§è‡³å…³é‡è¦ï¼Œä½†ç”±äºç¼ºä¹å¤§è§„æ¨¡é«˜è´¨é‡æ•°æ®é›†ï¼Œåœ¨å›¾åƒä¸­ç¨³å¥åœ°æ£€æµ‹å®ƒä»¬ä»ç„¶æ˜¯ä¸€ä¸ªæ‚¬è€Œæœªå†³çš„é—®é¢˜ã€‚å°½ç®¡ä¹‹å‰çš„ç ”ç©¶è¯•å›¾é€šè¿‡ä¼—åŒ…æˆ–æ‰‹åŠ¨æ ‡è®°çš„æ•°æ®æ¥æé«˜æ•°æ®å¯ç”¨æ€§ï¼Œä½†è¿™äº›åŠªåŠ›åœ¨è´¨é‡æˆ–è§„æ¨¡ä¸Šå¾€å¾€æœ‰æ‰€æ¬ ç¼ºã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬ä»‹ç»å¹¶è¯„ä¼°äº†ä¸€ä¸ªåä¸ºRampNetçš„ä¸¤é˜¶æ®µæµç¨‹ï¼Œä»¥æ‰©å¤§è·¯ç¼˜çŸ³å¡é“æ£€æµ‹æ•°æ®é›†å¹¶æé«˜æ¨¡å‹æ€§èƒ½ã€‚åœ¨ç¬¬ä¸€é˜¶æ®µï¼Œæˆ‘ä»¬é€šè¿‡è‡ªåŠ¨ç¿»è¯‘æ”¿åºœæä¾›çš„è·¯ç¼˜çŸ³å¡é“ä½ç½®æ•°æ®ï¼Œç”Ÿæˆäº†è¶…è¿‡21ä¸‡ä¸ªæ ‡æ³¨çš„Googleè¡—æ™¯ï¼ˆGSVï¼‰å…¨æ™¯å›¾åƒæ•°æ®é›†ã€‚åœ¨ç¬¬äºŒé˜¶æ®µï¼Œæˆ‘ä»¬æ ¹æ®ç”Ÿæˆçš„æ•°æ®é›†è®­ç»ƒäº†è·¯ç¼˜çŸ³å¡é“æ£€æµ‹æ¨¡å‹ï¼ˆä¿®æ”¹åçš„ConvNeXt V2ï¼‰ï¼Œå–å¾—äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚ä¸ºäº†è¯„ä¼°æˆ‘ä»¬æµç¨‹çš„ä¸¤ä¸ªé˜¶æ®µï¼Œæˆ‘ä»¬å°†ç»“æœä¸æ‰‹åŠ¨æ ‡è®°çš„å…¨æ™¯å›¾åƒè¿›è¡Œäº†æ¯”è¾ƒã€‚æˆ‘ä»¬ç”Ÿæˆçš„æ•°æ®é›†è¾¾åˆ°äº†94.0%çš„ç²¾ç¡®åº¦å’Œ92.5%çš„å¬å›ç‡ï¼Œæˆ‘ä»¬çš„æ£€æµ‹æ¨¡å‹è¾¾åˆ°äº†0.9236çš„å¹³å‡å‡†ç¡®ç‡â€”â€”è¿œè¿œè¶…è¿‡ä»¥å‰çš„å·¥ä½œã€‚æˆ‘ä»¬çš„å·¥ä½œè´¡çŒ®äº†ä¸€ä¸ªå¤§è§„æ¨¡ã€é«˜è´¨é‡çš„è·¯ç¼˜çŸ³å¡é“æ£€æµ‹æ•°æ®é›†ã€åŸºå‡†æµ‹è¯•å’Œæ¨¡å‹ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.09415v1">PDF</a> Accepted to the ICCVâ€™25 Workshop on Vision Foundation Models and   Generative AI for Accessibility: Challenges and Opportunities</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†åˆ©ç”¨RampNetä¸¤é˜¶æ®µç®¡é“å®ç°åŸå¸‚å¡é“æ£€æµ‹æ•°æ®é›†çš„è§„æ¨¡åŒ–ä»¥åŠæ¨¡å‹æ€§èƒ½çš„æå‡ã€‚ç¬¬ä¸€é˜¶æ®µé€šè¿‡è‡ªåŠ¨ç¿»è¯‘æ”¿åºœæä¾›çš„å¡é“ä½ç½®æ•°æ®ç”Ÿæˆè¶…è¿‡21ä¸‡å¼ æ ‡æ³¨çš„Googleè¡—æ™¯å…¨æ™¯å›¾åƒæ•°æ®é›†ã€‚ç¬¬äºŒé˜¶æ®µä½¿ç”¨ä¿®æ”¹åçš„ConvNeXt V2æ¨¡å‹è¿›è¡Œå¡é“æ£€æµ‹ï¼Œè¾¾åˆ°ä¸šç•Œé¢†å…ˆæ°´å¹³ã€‚è¯„ä¼°ç»“æœæ˜¾ç¤ºï¼Œç”Ÿæˆçš„æ•°æ®é›†ç²¾ç¡®åº¦å’Œå¬å›ç‡åˆ†åˆ«è¾¾åˆ°94.0%å’Œ92.5%ï¼Œæ£€æµ‹æ¨¡å‹çš„å¹³å‡ç²¾åº¦è¾¾åˆ°0.9236ï¼Œè¿œè¶…å…ˆå‰å·¥ä½œã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ç¼ºä¹å¤§è§„æ¨¡é«˜è´¨é‡æ•°æ®é›†æ˜¯åŸå¸‚å¡é“æ£€æµ‹é¢ä¸´çš„ä¸»è¦é—®é¢˜ã€‚</li>
<li>RampNetä¸¤é˜¶æ®µç®¡é“è§£å†³äº†å¡é“æ£€æµ‹æ•°æ®é›†çš„è§„æ¨¡åŒ–é—®é¢˜ã€‚</li>
<li>ç¬¬ä¸€é˜¶æ®µé€šè¿‡è‡ªåŠ¨ç¿»è¯‘æ”¿åºœæ•°æ®ç”Ÿæˆå¤§è§„æ¨¡å¡é“ä½ç½®æ•°æ®é›†ã€‚</li>
<li>ç¬¬äºŒé˜¶æ®µä½¿ç”¨ä¿®æ”¹åçš„ConvNeXt V2æ¨¡å‹è¿›è¡Œå¡é“æ£€æµ‹ï¼Œæ€§èƒ½å“è¶Šã€‚</li>
<li>ç”Ÿæˆçš„æ•°æ®é›†ç²¾ç¡®åº¦å’Œå¬å›ç‡å‡è¶…è¿‡92%ã€‚</li>
<li>æ£€æµ‹æ¨¡å‹çš„å¹³å‡ç²¾åº¦è¾¾åˆ°ä¸šç•Œæœ€é«˜æ°´å¹³ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.09415">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-f17e26b4d1874f7351eb9c4d91aa33ae.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-76021e3e7b2e3ddb6d6087f03286ee4a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-14b493482e8ade7ab530b5e92f949f40.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ec17795b775511a77c87c4948de34492.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-8c28ce468f02d41940ae94cd64ae5759.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-1b4853bf95f9199ec5f5b6ee3ae1c8df.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="Recent-Advances-in-Generative-AI-for-Healthcare-Applications"><a href="#Recent-Advances-in-Generative-AI-for-Healthcare-Applications" class="headerlink" title="Recent Advances in Generative AI for Healthcare Applications"></a>Recent Advances in Generative AI for Healthcare Applications</h2><p><strong>Authors:Yasin Shokrollahi, Jose Colmenarez, Wenxi Liu, Sahar Yarmohammadtoosky, Matthew M. Nikahd, Pengfei Dong, Xianqi Li, Linxia Gu</strong></p>
<p>The rapid advancement of Artificial Intelligence (AI) has catalyzed revolutionary changes across various sectors, notably in healthcare. In particular, generative AI-led by diffusion models and transformer architectures-has enabled significant breakthroughs in medical imaging (including image reconstruction, image-to-image translation, generation, and classification), protein structure prediction, clinical documentation, diagnostic assistance, radiology interpretation, clinical decision support, medical coding, and billing, as well as drug design and molecular representation. These innovations have enhanced clinical diagnosis, data reconstruction, and drug synthesis. This review paper aims to offer a comprehensive synthesis of recent advances in healthcare applications of generative AI, with an emphasis on diffusion and transformer models. Moreover, we discuss current capabilities, highlight existing limitations, and outline promising research directions to address emerging challenges. Serving as both a reference for researchers and a guide for practitioners, this work offers an integrated view of the state of the art, its impact on healthcare, and its future potential. </p>
<blockquote>
<p>äººå·¥æ™ºèƒ½ï¼ˆAIï¼‰çš„å¿«é€Ÿå‘å±•å‚¬ç”Ÿäº†å„ä¸ªé¢†åŸŸçš„é©å‘½æ€§å˜åŒ–ï¼Œç‰¹åˆ«æ˜¯åœ¨åŒ»ç–—é¢†åŸŸã€‚ç‰¹åˆ«æ˜¯ä»¥æ‰©æ•£æ¨¡å‹å’Œè½¬æ¢å™¨æ¶æ„ä¸ºé©±åŠ¨çš„ç”Ÿæˆå¼äººå·¥æ™ºèƒ½ï¼Œåœ¨åŒ»å­¦æˆåƒï¼ˆåŒ…æ‹¬å›¾åƒé‡å»ºã€å›¾åƒåˆ°å›¾åƒçš„ç¿»è¯‘ã€ç”Ÿæˆå’Œåˆ†ç±»ï¼‰ã€è›‹ç™½è´¨ç»“æ„é¢„æµ‹ã€ä¸´åºŠæ–‡æ¡£ã€è¯Šæ–­è¾…åŠ©ã€æ”¾å°„å­¦è§£è¯»ã€ä¸´åºŠå†³ç­–æ”¯æŒã€åŒ»ç–—ç¼–ç å’Œè®¡è´¹ä»¥åŠè¯ç‰©è®¾è®¡å’Œåˆ†å­è¡¨ç¤ºç­‰æ–¹é¢å®ç°äº†é‡å¤§çªç ´ã€‚è¿™äº›åˆ›æ–°æé«˜äº†ä¸´åºŠè¯Šæ–­ã€æ•°æ®é‡å»ºå’Œè¯ç‰©åˆæˆçš„èƒ½åŠ›ã€‚è¿™ç¯‡ç»¼è¿°æ–‡ç« æ—¨åœ¨æä¾›å…³äºç”Ÿæˆå¼äººå·¥æ™ºèƒ½åœ¨åŒ»ç–—é¢†åŸŸåº”ç”¨çš„æœ€æ–°è¿›å±•çš„ç»¼åˆåˆ†æï¼Œé‡ç‚¹ä»‹ç»æ‰©æ•£æ¨¡å‹å’Œè½¬æ¢å™¨æ¨¡å‹ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜è®¨è®ºäº†å½“å‰çš„èƒ½åŠ›ï¼Œå¼ºè°ƒäº†ç°æœ‰çš„å±€é™æ€§ï¼Œå¹¶æ¦‚è¿°äº†è§£å†³æ–°å…´æŒ‘æˆ˜çš„æœ‰å¸Œæœ›çš„ç ”ç©¶æ–¹å‘ã€‚è¿™é¡¹å·¥ä½œæ—¢ä¸ºç ”ç©¶è€…æä¾›äº†å‚è€ƒï¼Œä¹Ÿä¸ºä»ä¸šè€…æä¾›äº†æŒ‡å—ï¼Œå…¨é¢å±•ç¤ºäº†æœ€æ–°æŠ€æœ¯ã€å…¶å¯¹åŒ»ç–—é¢†åŸŸçš„å½±å“åŠå…¶æœªæ¥æ½œåŠ›ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.00795v2">PDF</a> 51 pages, 16 figures, 1table</p>
<p><strong>Summary</strong><br>     äººå·¥æ™ºèƒ½ï¼ˆAIï¼‰çš„å¿«é€Ÿå‘å±•å‚¬ç”Ÿäº†å„é¢†åŸŸé©å‘½æ€§çš„å˜é©ï¼Œå°¤å…¶åœ¨åŒ»ç–—é¢†åŸŸã€‚ç”Ÿæˆå¼AIå¼•é¢†çš„æ‰©æ•£æ¨¡å‹å’Œè½¬æ¢å™¨æ¶æ„åœ¨åŒ»ç–—æˆåƒã€è›‹ç™½è´¨ç»“æ„é¢„æµ‹ã€ä¸´åºŠæ–‡æ¡£ã€è¯Šæ–­è¾…åŠ©ã€æ”¾å°„å­¦è§£è¯»ã€ä¸´åºŠå†³ç­–æ”¯æŒç­‰æ–¹é¢å–å¾—äº†é‡å¤§çªç ´ã€‚æœ¬æ–‡æ—¨åœ¨å…¨é¢ç»¼è¿°ç”Ÿæˆå¼AIåœ¨åŒ»ç–—é¢†åŸŸçš„æœ€æ–°è¿›å±•ï¼Œé‡ç‚¹ä»‹ç»æ‰©æ•£æ¨¡å‹å’Œè½¬æ¢å™¨æ¨¡å‹çš„åº”ç”¨ã€‚åŒæ—¶ï¼Œæœ¬æ–‡è®¨è®ºå½“å‰çš„èƒ½åŠ›ï¼Œå¼ºè°ƒç°æœ‰çš„å±€é™æ€§ï¼Œå¹¶æ¦‚è¿°æœ‰å‰æ™¯çš„ç ”ç©¶æ–¹å‘ä»¥åº”å¯¹æ–°å…´æŒ‘æˆ˜ã€‚å®ƒä¸ºç ”ç©¶äººå‘˜æä¾›äº†å‚è€ƒï¼Œä¸ºä»ä¸šè€…æä¾›äº†æŒ‡å—ï¼Œå±•ç°äº†æœ€æ–°çš„æŠ€æœ¯æ€åŠ¿åŠå…¶å¯¹åŒ»ç–—é¢†åŸŸçš„å½±å“å’Œæœªæ¥æ½œåŠ›ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ç”Ÿæˆå¼AIåœ¨åŒ»ç–—é¢†åŸŸå¼•å‘é‡å¤§çªç ´ï¼Œæ¶µç›–åŒ»ç–—æˆåƒã€è›‹ç™½è´¨ç»“æ„é¢„æµ‹ã€ä¸´åºŠæ–‡æ¡£ç­‰æ–¹é¢ã€‚</li>
<li>æ‰©æ•£æ¨¡å‹å’Œè½¬æ¢å™¨æ¶æ„æ˜¯ç”Ÿæˆå¼AIçš„ä¸»è¦æŠ€æœ¯é©±åŠ¨åŠ›ã€‚</li>
<li>è¿™äº›æŠ€æœ¯å¢å¼ºäº†ä¸´åºŠè¯Šæ–­ã€æ•°æ®é‡å»ºå’Œè¯ç‰©åˆæˆçš„èƒ½åŠ›ã€‚</li>
<li>å½“å‰ç”Ÿæˆå¼AIåœ¨åŒ»ç–—é¢†åŸŸçš„åº”ç”¨å·²äº§ç”Ÿæ˜¾è‘—å½±å“ã€‚</li>
<li>å°½ç®¡æœ‰é‡å¤§è¿›å±•ï¼Œä½†ç”Ÿæˆå¼AIåœ¨åŒ»ç–—é¢†åŸŸä»å­˜åœ¨å±€é™æ€§ã€‚</li>
<li>æœ‰å¿…è¦è¿›è¡Œæ›´å¤šç ”ç©¶ä»¥è§£å†³æ–°å…´æŒ‘æˆ˜ï¼Œå¹¶æ¨åŠ¨ç”Ÿæˆå¼AIåœ¨åŒ»ç–—é¢†åŸŸçš„è¿›ä¸€æ­¥å‘å±•ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2310.00795">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-9d5a960f2db8d45ca023bf3f9a54e9ce.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-16e45f22b94ef7397cdce38d931781dc.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-556d751dc4875792fb2156ab39933dcd.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-8f03d143c0ef44bc6208cb18864fa415.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="Ear-Keeper-A-Cross-Platform-AI-System-for-Rapid-and-Accurate-Ear-Disease-Diagnosis"><a href="#Ear-Keeper-A-Cross-Platform-AI-System-for-Rapid-and-Accurate-Ear-Disease-Diagnosis" class="headerlink" title="Ear-Keeper: A Cross-Platform AI System for Rapid and Accurate Ear   Disease Diagnosis"></a>Ear-Keeper: A Cross-Platform AI System for Rapid and Accurate Ear   Disease Diagnosis</h2><p><strong>Authors:Feiyan Lu, Yubiao Yue, Zhenzhang Li, Meiping Zhang, Wen Luo, Fan Zhang, Tong Liu, Jingyong Shi, Guang Wang, Xinyu Zeng</strong></p>
<p>Early and accurate detection systems for ear diseases, powered by deep learning, are essential for preventing hearing impairment and improving population health. However, the limited diversity of existing otoendoscopy datasets and the poor balance between diagnostic accuracy, computational efficiency, and model size have hindered the translation of artificial intelligence (AI) algorithms into healthcare applications. In this study, we constructed a large-scale, multi-center otoendoscopy dataset covering eight common ear diseases and healthy cases. Building upon this resource, we developed Best-EarNet, an ultrafast and lightweight deep learning architecture integrating a novel Local-Global Spatial Feature Fusion Module with a multi-scale supervision strategy, enabling real-time and accurate classification of ear conditions. Leveraging transfer learning, Best-EarNet, with a model size of only 2.94 MB, achieved diagnostic accuracies of 95.23% on an internal test set (22,581 images) and 92.14% on an external test set (1,652 images), while requiring only 0.0125 seconds (80 frames per second) to process a single image on a standard CPU. Further subgroup analysis by gender and age showed consistently excellent performance of Best-EarNet across all demographic groups. To enhance clinical interpretability and user trust, we incorporated Grad-CAM-based visualization, highlighting the specific abnormal ear regions contributing to AI predictions. Most importantly, we developed Ear-Keeper, a cross-platform intelligent diagnosis system built upon Best-EarNet, deployable on smartphones, tablets, and personal computers. Ear-Keeper enables public users and healthcare providers to perform comprehensive real-time video-based ear canal screening, supporting early detection and timely intervention of ear diseases. </p>
<blockquote>
<p>ç”±æ·±åº¦å­¦ä¹ é©±åŠ¨çš„æ—©æœŸä¸”ç²¾ç¡®çš„ç–¾ç—…æ£€æµ‹ç³»ç»Ÿå¯¹äºé¢„é˜²å¬åŠ›å—æŸå¹¶æ”¹å–„å…¬ä¼—å¥åº·è‡³å…³é‡è¦ã€‚ç„¶è€Œï¼Œç°æœ‰çš„è€³å†…çª¥é•œæ•°æ®é›†å¤šæ ·æ€§æœ‰é™ï¼Œè¯Šæ–­å‡†ç¡®æ€§ã€è®¡ç®—æ•ˆç‡å’Œæ¨¡å‹å¤§å°ä¹‹é—´çš„å¹³è¡¡ä¸ä½³ï¼Œè¿™äº›éƒ½é˜»ç¢äº†äººå·¥æ™ºèƒ½ç®—æ³•åœ¨åŒ»ç–—ä¿å¥åº”ç”¨ä¸­çš„è½¬åŒ–ã€‚åœ¨è¿™é¡¹ç ”ç©¶ä¸­ï¼Œæˆ‘ä»¬æ„å»ºäº†ä¸€ä¸ªå¤§è§„æ¨¡ã€å¤šä¸­å¿ƒçš„è€³å†…çª¥é•œæ•°æ®é›†ï¼Œæ¶µç›–äº†å…«ç§å¸¸è§çš„è€³éƒ¨ç–¾ç—…å’Œå¥åº·çŠ¶å†µã€‚åŸºäºè¿™ä¸€èµ„æºï¼Œæˆ‘ä»¬å¼€å‘äº†Best-EarNetï¼Œè¿™æ˜¯ä¸€ç§è¶…å¿«é€Ÿä¸”è½»é‡çº§çš„æ·±åº¦å­¦ä¹ æ¶æ„ï¼Œå®ƒç»“åˆäº†æ–°é¢–çš„å…¨å±€å±€éƒ¨ç©ºé—´ç‰¹å¾èåˆæ¨¡å—å’Œå¤šå°ºåº¦ç›‘ç£ç­–ç•¥ï¼Œèƒ½å¤Ÿå®ç°è€³éƒ¨çŠ¶å†µçš„å®æ—¶å’Œå‡†ç¡®åˆ†ç±»ã€‚é€šè¿‡è¿ç§»å­¦ä¹ ï¼Œä»…2.94MBçš„Best-EarNetåœ¨å†…éƒ¨æµ‹è¯•é›†ï¼ˆ22,581å¼ å›¾åƒï¼‰ä¸Šå®ç°äº†95.23%çš„è¯Šæ–­å‡†ç¡®ç‡ï¼Œåœ¨å¤–éƒ¨æµ‹è¯•é›†ï¼ˆ1,652å¼ å›¾åƒï¼‰ä¸Šå®ç°äº†92.14%çš„å‡†ç¡®ç‡ï¼ŒåŒæ—¶åœ¨æ ‡å‡†CPUä¸Šå¤„ç†å•å¼ å›¾åƒä»…éœ€0.0125ç§’ï¼ˆæ¯ç§’80å¸§ï¼‰ã€‚æŒ‰æ€§åˆ«å’Œå¹´é¾„çš„è¿›ä¸€æ­¥äºšç»„åˆ†ææ˜¾ç¤ºï¼ŒBest-EarNetåœ¨æ‰€æœ‰å¹´é¾„æ®µçš„è¡¨ç°å‡éå¸¸å‡ºè‰²ã€‚ä¸ºäº†æé«˜ä¸´åºŠè§£é‡Šæ€§å’Œç”¨æˆ·ä¿¡ä»»åº¦ï¼Œæˆ‘ä»¬ç»“åˆäº†åŸºäºGrad-CAMçš„å¯è§†åŒ–ï¼Œçªå‡ºæ˜¾ç¤ºå¯¹äººå·¥æ™ºèƒ½é¢„æµ‹èµ·ç‰¹å®šä½œç”¨çš„å¼‚å¸¸è€³éƒ¨åŒºåŸŸã€‚æœ€é‡è¦çš„æ˜¯ï¼Œæˆ‘ä»¬å¼€å‘äº†Ear-Keeperï¼Œè¿™æ˜¯ä¸€æ¬¾åŸºäºBest-EarNetçš„è·¨å¹³å°æ™ºèƒ½è¯Šæ–­ç³»ç»Ÿï¼Œå¯åœ¨æ™ºèƒ½æ‰‹æœºã€å¹³æ¿ç”µè„‘å’Œä¸ªäººç”µè„‘ä¸Šéƒ¨ç½²ã€‚Ear-Keeperä½¿å…¬ä¼—ç”¨æˆ·å’ŒåŒ»ç–—æœåŠ¡æä¾›è€…èƒ½å¤Ÿè¿›è¡Œå…¨é¢å®æ—¶çš„åŸºäºè§†é¢‘çš„è€³é“ç­›æŸ¥ï¼Œæ”¯æŒè€³éƒ¨ç–¾ç—…çš„æ—©æœŸæ£€æµ‹å’ŒåŠæ—¶å¹²é¢„ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10610v5">PDF</a> 18 pages,8 figures</p>
<p><strong>Summary</strong></p>
<p>åŸºäºæ·±åº¦å­¦ä¹ æŠ€æœ¯çš„æ—©æœŸå‡†ç¡®è€³ç—…æ£€æµ‹ç³»ç»Ÿå¯¹äºé¢„é˜²å¬åŠ›å—æŸã€æå‡å…¨æ°‘å¥åº·æ°´å¹³è‡³å…³é‡è¦ã€‚æœ¬ç ”ç©¶æ„å»ºäº†ä¸€ä¸ªå¤§è§„æ¨¡ã€å¤šä¸­å¿ƒè€³å†…é•œæ•°æ®é›†ï¼Œè¦†ç›–å…«ç§å¸¸è§è€³ç—…åŠå¥åº·æ¡ˆä¾‹ã€‚åœ¨æ­¤åŸºç¡€ä¸Šï¼Œç ”ç©¶å›¢é˜Ÿå¼€å‘å‡ºBest-EarNetæ¨¡å‹ï¼Œèåˆäº†å±€éƒ¨å…¨å±€ç©ºé—´ç‰¹å¾èåˆæ¨¡å—å’Œå¤šå°ºåº¦ç›‘ç£ç­–ç•¥ï¼Œå®ç°äº†è€³éƒ¨çŠ¶å†µçš„å®æ—¶å‡†ç¡®åˆ†ç±»ã€‚è¯¥æ¨¡å‹åˆ©ç”¨è¿ç§»å­¦ä¹ ï¼Œä»…2.94MBçš„æ¨¡å‹å¤§å°ä¾¿åœ¨å†…éƒ¨æµ‹è¯•é›†ä¸Šå®ç°äº†95.23%çš„è¯Šæ–­å‡†ç¡®ç‡ï¼Œåœ¨å¤–éƒ¨æµ‹è¯•é›†ä¸Šè¾¾åˆ°äº†92.14%ï¼Œå¤„ç†å•å¼ å›¾ç‰‡ä»…éœ€0.0125ç§’ï¼ˆæ¯ç§’å¤„ç†80å¸§ï¼‰ã€‚ç ”ç©¶è¿˜é€šè¿‡æ€§åˆ«å’Œå¹´é¾„åˆ†ç»„åˆ†æè¯æ˜äº†Best-EarNetåœ¨æ‰€æœ‰äººç¾¤ä¸­çš„å“è¶Šè¡¨ç°ã€‚ä¸ºæå‡ä¸´åºŠè§£é‡Šæ€§å’Œç”¨æˆ·ä¿¡ä»»åº¦ï¼Œç ”ç©¶å›¢é˜Ÿå¼•å…¥äº†åŸºäºGrad-CAMçš„å¯è§†åŒ–æŠ€æœ¯ï¼Œçªå‡ºæ˜¾ç¤ºå¯¼è‡´AIé¢„æµ‹å¼‚å¸¸çš„ç‰¹å®šè€³éƒ¨åŒºåŸŸã€‚æœ€é‡è¦çš„æ˜¯ï¼Œç ”ç©¶å›¢é˜Ÿå¼€å‘äº†è·¨å¹³å°çš„æ™ºèƒ½è¯Šæ–­ç³»ç»ŸEar-Keeperï¼Œå¯éƒ¨ç½²äºæ™ºèƒ½æ‰‹æœºã€å¹³æ¿ç”µè„‘å’Œä¸ªäººç”µè„‘ï¼Œæ”¯æŒå…¬ä¼—å’ŒåŒ»ç–—å·¥ä½œè€…è¿›è¡Œå®æ—¶è§†é¢‘è€³é“ç­›æŸ¥ï¼Œå®ç°æ—©æœŸæ£€æµ‹å’ŒåŠæ—¶å¹²é¢„ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æ·±åº¦å­¦ä¹ é©±åŠ¨çš„è€³ç—…æ—©æœŸæ£€æµ‹ç³»ç»Ÿå¯¹é¢„é˜²å¬åŠ›å—æŸå’Œæé«˜äººå£å¥åº·æ°´å¹³è‡³å…³é‡è¦ã€‚</li>
<li>ç ”ç©¶æ„å»ºäº†ä¸€ä¸ªå¤§è§„æ¨¡ã€å¤šä¸­å¿ƒçš„è€³å†…é•œæ•°æ®é›†ï¼Œè¦†ç›–å¤šç§å¸¸è§è€³ç—…ã€‚</li>
<li>Best-EarNetæ¨¡å‹å®ç°è€³éƒ¨çŠ¶å†µçš„å®æ—¶å‡†ç¡®åˆ†ç±»ï¼Œå…·å¤‡å‡ºè‰²çš„è¯Šæ–­å‡†ç¡®ç‡ã€‚</li>
<li>Best-EarNetæ¨¡å‹å…·å¤‡è¶…å¿«å¤„ç†é€Ÿåº¦å’Œè½»é‡çº§ç‰¹ç‚¹ï¼Œä¾¿äºå®é™…åº”ç”¨ã€‚</li>
<li>æ¨¡å‹åœ¨å¤šç§äººå£åˆ†ç»„ä¸­è¡¨ç°ä¼˜ç§€ï¼Œå…·å¤‡å¹¿æ³›çš„é€‚ç”¨æ€§ã€‚</li>
<li>å¼•å…¥Grad-CAMå¯è§†åŒ–æŠ€æœ¯ï¼Œæå‡æ¨¡å‹ä¸´åºŠè§£é‡Šæ€§å’Œç”¨æˆ·ä¿¡ä»»åº¦ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2308.10610">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-71200bb25fb143804577db89724d25d2.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-4cfca3cd33052e251e5a82a8381aedf3.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d216a77123fb848e8b4cb938ae3b72a6.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-010bb2ce72183068ad0222773dd72d43.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-08-19/I2I%20Translation/">https://kedreamix.github.io/Talk2Paper/Paper/2025-08-19/I2I%20Translation/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/I2I-Translation/">
                                    <span class="chip bg-color">I2I Translation</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-08-19/Vision%20Transformer/">
                    <div class="card-image">
                        
                        <img src="https://pic1.zhimg.com/v2-b13338eebd805883fd0b237bba96ba97.jpg" class="responsive-img" alt="Vision Transformer">
                        
                        <span class="card-title">Vision Transformer</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Vision Transformer æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-08-19  Fine-Grained VLM Fine-tuning via Latent Hierarchical Adapter Learning
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-08-19
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Vision-Transformer/" class="post-category">
                                    Vision Transformer
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Vision-Transformer/">
                        <span class="chip bg-color">Vision Transformer</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-08-19/Few-Shot/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-0480971fd3e9425b1778d2a6a9c613cb.jpg" class="responsive-img" alt="Few-Shot">
                        
                        <span class="card-title">Few-Shot</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Few-Shot æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-08-19  CoFi A Fast Coarse-to-Fine Few-Shot Pipeline for Glomerular Basement   Membrane Segmentation
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-08-19
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Few-Shot/" class="post-category">
                                    Few-Shot
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Few-Shot/">
                        <span class="chip bg-color">Few-Shot</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">27927k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
