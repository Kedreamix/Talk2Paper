<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Agent">
    <meta name="description" content="Agent æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-08-19  DiCriTest Testing Scenario Generation for Decision-Making Agents   Considering Diversity and Criticality">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>Agent | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://picx.zhimg.com/v2-28bf8a8110a9746a3695944324442f4d.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Agent</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/Agent/">
                                <span class="chip bg-color">Agent</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/Agent/" class="post-category">
                                Agent
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-08-19
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-08-23
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    13.4k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    54 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-08-19-æ›´æ–°"><a href="#2025-08-19-æ›´æ–°" class="headerlink" title="2025-08-19 æ›´æ–°"></a>2025-08-19 æ›´æ–°</h1><h2 id="DiCriTest-Testing-Scenario-Generation-for-Decision-Making-Agents-Considering-Diversity-and-Criticality"><a href="#DiCriTest-Testing-Scenario-Generation-for-Decision-Making-Agents-Considering-Diversity-and-Criticality" class="headerlink" title="DiCriTest: Testing Scenario Generation for Decision-Making Agents   Considering Diversity and Criticality"></a>DiCriTest: Testing Scenario Generation for Decision-Making Agents   Considering Diversity and Criticality</h2><p><strong>Authors:Qitong Chu, Yufeng Yue, Danya Yao, Huaxin Pei</strong></p>
<p>The growing deployment of decision-making agents in dynamic environments increases the demand for safety verification. While critical testing scenario generation has emerged as an appealing verification methodology, effectively balancing diversity and criticality remains a key challenge for existing methods, particularly due to local optima entrapment in high-dimensional scenario spaces. To address this limitation, we propose a dual-space guided testing framework that coordinates scenario parameter space and agent behavior space, aiming to generate testing scenarios considering diversity and criticality. Specifically, in the scenario parameter space, a hierarchical representation framework combines dimensionality reduction and multi-dimensional subspace evaluation to efficiently localize diverse and critical subspaces. This guides dynamic coordination between two generation modes: local perturbation and global exploration, optimizing critical scenario quantity and diversity. Complementarily, in the agent behavior space, agent-environment interaction data are leveraged to quantify behavioral criticality&#x2F;diversity and adaptively support generation mode switching, forming a closed feedback loop that continuously enhances scenario characterization and exploration within the parameter space. Experiments show our framework improves critical scenario generation by an average of 56.23% and demonstrates greater diversity under novel parameter-behavior co-driven metrics when tested on five decision-making agents, outperforming state-of-the-art baselines. </p>
<blockquote>
<p>éšç€å†³ç­–ä»£ç†åœ¨åŠ¨æ€ç¯å¢ƒä¸­çš„éƒ¨ç½²ä¸æ–­å¢åŠ ï¼Œå¯¹å®‰å…¨éªŒè¯çš„éœ€æ±‚ä¹Ÿåœ¨å¢é•¿ã€‚è™½ç„¶å…³é”®æµ‹è¯•åœºæ™¯ç”Ÿæˆå·²ç»æˆä¸ºä¸€ç§æœ‰å¸å¼•åŠ›çš„éªŒè¯æ–¹æ³•ï¼Œä½†å¦‚ä½•åœ¨å¤šæ ·æ€§å’Œå…³é”®æ€§ä¹‹é—´è¿›è¡Œæœ‰æ•ˆå¹³è¡¡ä»ç„¶æ˜¯ç°æœ‰æ–¹æ³•çš„å…³é”®æŒ‘æˆ˜ï¼Œå°¤å…¶æ˜¯åœ¨é«˜ç»´åº¦åœºæ™¯ç©ºé—´ä¸­çš„å±€éƒ¨æœ€ä¼˜å›°å¢ƒã€‚ä¸ºäº†è§£å†³è¿™ä¸€å±€é™æ€§ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åŒç©ºé—´å¼•å¯¼æµ‹è¯•æ¡†æ¶ï¼Œè¯¥æ¡†æ¶åè°ƒåœºæ™¯å‚æ•°ç©ºé—´å’Œä»£ç†è¡Œä¸ºç©ºé—´ï¼Œæ—¨åœ¨ç”Ÿæˆè€ƒè™‘å¤šæ ·æ€§å’Œå…³é”®æ€§çš„æµ‹è¯•åœºæ™¯ã€‚å…·ä½“è€Œè¨€ï¼Œåœ¨åœºæ™¯å‚æ•°ç©ºé—´ä¸­ï¼Œåˆ†å±‚è¡¨ç¤ºæ¡†æ¶ç»“åˆé™ç»´å’Œå¤šç»´å­ç©ºé—´è¯„ä¼°ï¼Œä»¥æœ‰æ•ˆåœ°å®šä½å¤šæ ·åŒ–å’Œå…³é”®çš„å­ç©ºé—´ã€‚è¿™æŒ‡å¯¼äº†ä¸¤ç§ç”Ÿæˆæ¨¡å¼ä¹‹é—´çš„åŠ¨æ€åè°ƒï¼šå±€éƒ¨æ‰°åŠ¨å’Œå…¨å±€æ¢ç´¢ï¼Œä»¥ä¼˜åŒ–å…³é”®åœºæ™¯çš„æ•°é‡å’Œå¤šæ ·æ€§ã€‚æ­¤å¤–ï¼Œåœ¨ä»£ç†è¡Œä¸ºç©ºé—´ä¸­ï¼Œåˆ©ç”¨ä»£ç†ä¸ç¯å¢ƒäº¤äº’æ•°æ®æ¥é‡åŒ–è¡Œä¸ºçš„å…³é”®æ€§å’Œå¤šæ ·æ€§ï¼Œå¹¶è‡ªé€‚åº”åœ°æ”¯æŒç”Ÿæˆæ¨¡å¼åˆ‡æ¢ï¼Œå½¢æˆä¸€ä¸ªé—­ç¯åé¦ˆå›è·¯ï¼ŒæŒç»­å¢å¼ºåœºæ™¯è¡¨å¾å’Œåœ¨å‚æ•°ç©ºé—´å†…çš„æ¢ç´¢ã€‚å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ¡†æ¶åœ¨äº”ä¸ªå†³ç­–ä»£ç†ä¸Šæµ‹è¯•æ—¶ï¼Œå…³é”®åœºæ™¯ç”Ÿæˆå¹³å‡æé«˜äº†56.23%ï¼Œåœ¨æ–°å‹å‚æ•°-è¡Œä¸ºååŒé©±åŠ¨æŒ‡æ ‡ä¸‹è¡¨ç°å‡ºæ›´é«˜çš„å¤šæ ·æ€§ï¼Œè¶…è¶Šäº†æœ€å…ˆè¿›çš„åŸºçº¿ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.11514v1">PDF</a> </p>
<p><strong>Summary</strong><br>å†³ç­–ä»£ç†åœ¨åŠ¨æ€ç¯å¢ƒä¸­çš„éƒ¨ç½²å¢é•¿å¯¹å®‰å…¨éªŒè¯æå‡ºäº†æ›´é«˜è¦æ±‚ã€‚ç°æœ‰æ–¹æ³•åœ¨å¹³è¡¡å¤šæ ·æ€§å’Œé‡è¦æ€§æ–¹é¢å­˜åœ¨æŒ‘æˆ˜ï¼Œå°¤å…¶åœ¨é«˜ç»´åœºæ™¯ç©ºé—´ä¸­å®¹æ˜“é™·å…¥å±€éƒ¨æœ€ä¼˜è§£ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åŒç©ºé—´å¼•å¯¼æµ‹è¯•æ¡†æ¶ï¼Œè¯¥æ¡†æ¶åè°ƒåœºæ™¯å‚æ•°ç©ºé—´å’Œä»£ç†è¡Œä¸ºç©ºé—´ï¼Œæ—¨åœ¨ç”Ÿæˆè€ƒè™‘å¤šæ ·æ€§å’Œé‡è¦æ€§çš„æµ‹è¯•åœºæ™¯ã€‚å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ¡†æ¶åœ¨äº”ä¸ªå†³ç­–ä»£ç†ä¸Šçš„å…³é”®åœºæ™¯ç”Ÿæˆå¹³å‡æé«˜äº†56.23%ï¼Œå¹¶åœ¨æ–°å‹å‚æ•°è¡Œä¸ºååŒé©±åŠ¨ä¸‹å±•ç°å‡ºæ›´é«˜çš„å¤šæ ·æ€§ï¼Œä¼˜äºç°æœ‰æœ€æ–°åŸºçº¿æŠ€æœ¯ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å†³ç­–ä»£ç†åœ¨åŠ¨æ€ç¯å¢ƒä¸­çš„åº”ç”¨å¯¹å®‰å…¨éªŒè¯æå‡ºäº†æ›´é«˜è¦æ±‚ã€‚</li>
<li>ç°æœ‰æ–¹æ³•åœ¨ç”Ÿæˆæµ‹è¯•åœºæ™¯æ—¶å¹³è¡¡å¤šæ ·æ€§å’Œé‡è¦æ€§æ–¹é¢å­˜åœ¨æŒ‘æˆ˜ã€‚</li>
<li>åŒç©ºé—´å¼•å¯¼æµ‹è¯•æ¡†æ¶æ—¨åœ¨åè°ƒåœºæ™¯å‚æ•°ç©ºé—´å’Œä»£ç†è¡Œä¸ºç©ºé—´ä»¥ç”Ÿæˆæµ‹è¯•åœºæ™¯ã€‚</li>
<li>è¯¥æ¡†æ¶ä½¿ç”¨å±‚æ¬¡è¡¨ç¤ºæ¡†æ¶ç»“åˆé™ç»´å’Œå¤šç»´å­ç©ºé—´è¯„ä¼°æ¥å®šä½å¤šæ ·ä¸”å…³é”®çš„å­ç©ºé—´ã€‚</li>
<li>è¯¥æ¡†æ¶ä¼˜åŒ–ä¸¤ç§ç”Ÿæˆæ¨¡å¼ï¼šå±€éƒ¨å¾®è°ƒå’Œå…¨å±€æ¢ç´¢ï¼Œä»¥æé«˜å…³é”®åœºæ™¯çš„å¤šæ ·æ€§å’Œæ•°é‡ã€‚</li>
<li>åˆ©ç”¨ä»£ç†ä¸ç¯å¢ƒäº¤äº’æ•°æ®æ¥é‡åŒ–è¡Œä¸ºçš„é‡è¦æ€§å’Œå¤šæ ·æ€§ï¼Œå¹¶æ”¯æŒç”Ÿæˆæ¨¡å¼åˆ‡æ¢ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.11514">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-2187f86c986e0287f7e234fb881b2322.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ad391c9d177291b8d560c1e719612115.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-7470c6835740f8b82b7138a756de1a47.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-2e3f195d567976bb64c793f08c75dd4f.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="CRAFT-GUI-Curriculum-Reinforced-Agent-For-GUI-Tasks"><a href="#CRAFT-GUI-Curriculum-Reinforced-Agent-For-GUI-Tasks" class="headerlink" title="CRAFT-GUI: Curriculum-Reinforced Agent For GUI Tasks"></a>CRAFT-GUI: Curriculum-Reinforced Agent For GUI Tasks</h2><p><strong>Authors:Songqin Nong, Jingxuan Xu, Sheng Zhou, Jianfeng Chen, Xiaoxuan Tang, Tao Jiang, Wenhao Xu</strong></p>
<p>As autonomous agents become adept at understanding and interacting with graphical user interface (GUI) environments, a new era of automated task execution is emerging. Recent studies have demonstrated that Reinforcement Learning (RL) can effectively enhance agentsâ€™ performance in dynamic interactive GUI environments. However, these methods face two key limitations: (1) they overlook the significant variation in difficulty across different GUI tasks by treating the entire training data as a uniform set, which hampers the agentâ€™s ability to adapt its learning process; and (2) most approaches collapse task-specific nuances into a single, coarse reward, leaving the agent with a uniform signal that yields inefficient policy updates. To address these limitations, we propose CRAFT-GUI, a curriculum learning framework based on Group Relative Policy Optimization (GRPO) that explicitly accounts for the varying difficulty across trajectories. To enable more fine-grained policy optimization, we design a reward function that combines simple rule-based signals with model-judged evaluation, providing richer and more nuanced feedback during training. Experimental results demonstrate that our method achieves significant improvements over previous state-of-the-art approaches, outperforming them by 5.6% on public benchmarks Android Control and 10.3% on our internal online benchmarks, respectively. These findings empirically validate the effectiveness of integrating reinforcement learning with curriculum learning in GUI interaction tasks. </p>
<blockquote>
<p>éšç€è‡ªä¸»ä»£ç†ï¼ˆagentsï¼‰åœ¨ç†è§£å’Œå›¾å½¢ç”¨æˆ·ç•Œé¢ï¼ˆGUIï¼‰ç¯å¢ƒäº¤äº’æ–¹é¢çš„èƒ½åŠ›æ—¥ç›Šå¢å¼ºï¼Œä¸€ä¸ªæ–°çš„è‡ªåŠ¨åŒ–ä»»åŠ¡æ‰§è¡Œæ—¶ä»£æ­£åœ¨å…´èµ·ã€‚æœ€è¿‘çš„ç ”ç©¶è¡¨æ˜ï¼Œå¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰å¯ä»¥æœ‰æ•ˆåœ°æé«˜ä»£ç†åœ¨åŠ¨æ€äº¤äº’å¼GUIç¯å¢ƒä¸­çš„æ€§èƒ½ã€‚ç„¶è€Œï¼Œè¿™äº›æ–¹æ³•é¢ä¸´ä¸¤ä¸ªä¸»è¦å±€é™æ€§ï¼šï¼ˆ1ï¼‰å®ƒä»¬å¿½ç•¥äº†ä¸åŒGUIä»»åŠ¡éš¾åº¦çš„æ˜¾è‘—å·®å¼‚ï¼Œå°†æ•´ä¸ªè®­ç»ƒæ•°æ®è§†ä¸ºç»Ÿä¸€é›†ï¼Œè¿™é˜»ç¢äº†ä»£ç†é€‚åº”å…¶å­¦ä¹ è¿‡ç¨‹çš„èƒ½åŠ›ï¼›ï¼ˆ2ï¼‰å¤§å¤šæ•°æ–¹æ³•å°†ç‰¹å®šä»»åŠ¡çš„ç»†å¾®å·®åˆ«ç®€åŒ–ä¸ºå•ä¸€çš„ç²—ç•¥å¥–åŠ±ï¼Œä½¿ä»£ç†åªèƒ½è·å¾—ç»Ÿä¸€çš„ä¿¡å·ï¼Œå¯¼è‡´ç­–ç•¥æ›´æ–°æ•ˆç‡ä½ä¸‹ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†åŸºäºç¾¤ä½“ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–ï¼ˆGRPOï¼‰çš„è¯¾ç¨‹å­¦ä¹ æ¡†æ¶CRAFT-GUIï¼Œå®ƒæ˜¾å¼åœ°è€ƒè™‘äº†è½¨è¿¹é—´çš„ä¸åŒéš¾åº¦ã€‚ä¸ºäº†å®ç°æ›´ç²¾ç»†çš„ç­–ç•¥ä¼˜åŒ–ï¼Œæˆ‘ä»¬è®¾è®¡äº†ä¸€ç§å¥–åŠ±å‡½æ•°ï¼Œå°†åŸºäºç®€å•è§„åˆ™çš„ä¿¡å·ä¸æ¨¡å‹åˆ¤æ–­çš„è¯„ä»·ç›¸ç»“åˆï¼Œåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­æä¾›æ›´ä¸°å¯Œã€æ›´ç»†å¾®çš„åé¦ˆã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨å…¬å…±åŸºå‡†æµ‹è¯•Android Controlä¸Šæ¯”æœ€æ–°æŠ€æœ¯é«˜å‡º5.6%ï¼Œåœ¨æˆ‘ä»¬çš„å†…éƒ¨åœ¨çº¿åŸºå‡†æµ‹è¯•ä¸Šé«˜å‡º10.3%ã€‚è¿™äº›å‘ç°å®è¯äº†å¼ºåŒ–å­¦ä¹ ä¸è¯¾ç¨‹å­¦ä¹ åœ¨GUIäº¤äº’ä»»åŠ¡ä¸­ç»“åˆçš„æœ‰æ•ˆæ€§ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.11360v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰åœ¨æé«˜è‡ªä¸»ä»£ç†åœ¨åŠ¨æ€äº¤äº’å¼å›¾å½¢ç”¨æˆ·ç•Œé¢ï¼ˆGUIï¼‰ç¯å¢ƒä¸­çš„æ€§èƒ½æ–¹é¢å…·æœ‰æ˜¾è‘—æ•ˆæœï¼Œä½†ä»å­˜åœ¨ä¸¤ä¸ªä¸»è¦å±€é™ã€‚ä¸ºè§£å†³è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†åŸºäºç¾¤ä½“ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–ï¼ˆGRPOï¼‰çš„è¯¾ç¨‹å­¦ä¹ æ¡†æ¶CRAFT-GUIï¼Œå¹¶è®¾è®¡äº†ä¸€ç§ç»“åˆåŸºäºè§„åˆ™çš„ç®€å•ä¿¡å·å’Œæ¨¡å‹è¯„ä¼°çš„å¥–åŠ±å‡½æ•°ï¼Œä¸ºè®­ç»ƒè¿‡ç¨‹æä¾›æ›´ä¸°å¯Œã€æ›´ç»†å¾®çš„åé¦ˆã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨å…¬å…±åŸºå‡†æµ‹è¯•ä¸Šè¾ƒä¹‹å‰çš„æœ€å…ˆè¿›æ–¹æ³•æé«˜äº†5.6%ï¼Œåœ¨å†…éƒ¨åœ¨çº¿åŸºå‡†æµ‹è¯•ä¸Šæé«˜äº†10.3%ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰å·²ç”¨äºæå‡è‡ªä¸»ä»£ç†åœ¨GUIç¯å¢ƒä¸­çš„ä»»åŠ¡æ‰§è¡Œèƒ½åŠ›ã€‚</li>
<li>å½“å‰æ–¹æ³•å­˜åœ¨ä¸¤ä¸ªä¸»è¦å±€é™ï¼šå¿½è§†ä¸åŒGUIä»»åŠ¡çš„éš¾åº¦å·®å¼‚ï¼Œä»¥åŠä»»åŠ¡ç‰¹å®šç»†èŠ‚è¢«ç®€åŒ–ä¸ºå•ä¸€çš„ç²—ç³™å¥–åŠ±ã€‚</li>
<li>CRAFT-GUIæ˜¯ä¸€ä¸ªåŸºäºè¯¾ç¨‹å­¦ä¹ çš„æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³ä»¥ä¸Šé—®é¢˜ï¼Œé€šè¿‡ç¾¤ä½“ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–ï¼ˆGRPOï¼‰æ˜¾å¼è€ƒè™‘è½¨è¿¹çš„ä¸åŒéš¾åº¦ã€‚</li>
<li>CRAFT-GUIè®¾è®¡äº†ä¸€ç§ç»“åˆè§„åˆ™åŸºç¡€ç®€å•ä¿¡å·å’Œæ¨¡å‹è¯„ä¼°çš„å¥–åŠ±å‡½æ•°ï¼Œä»¥æä¾›æ›´ä¸°å¯Œå’Œç»†å¾®çš„åé¦ˆã€‚</li>
<li>å®éªŒç»“æœè¡¨æ˜ï¼ŒCRAFT-GUIåœ¨å…¬å…±å’Œå†…éƒ¨åŸºå‡†æµ‹è¯•ä¸Šè¾ƒç°æœ‰æ–¹æ³•æœ‰æ‰€æ”¹è¿›ã€‚</li>
<li>CRAFT-GUIé›†æˆäº†å¼ºåŒ–å­¦ä¹ ä¸è¯¾ç¨‹å­¦ä¹ ï¼Œåœ¨GUIäº¤äº’ä»»åŠ¡ä¸­å±•ç°å‡ºæœ‰æ•ˆæ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.11360">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-37f8b92eebe108f496c235dea7a9ec1b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-87776881c56b10d0709bc94082100d70.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-9272669b22ed3b5e0072aa2b4d8e74bb.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-254f63654a267c120efa8d70235ef454.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-28bf8a8110a9746a3695944324442f4d.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-63e5a43bbff24d4537a4a7cf2c193321.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="Hell-or-High-Water-Evaluating-Agentic-Recovery-from-External-Failures"><a href="#Hell-or-High-Water-Evaluating-Agentic-Recovery-from-External-Failures" class="headerlink" title="Hell or High Water: Evaluating Agentic Recovery from External Failures"></a>Hell or High Water: Evaluating Agentic Recovery from External Failures</h2><p><strong>Authors:Andrew Wang, Sophia Hager, Adi Asija, Daniel Khashabi, Nicholas Andrews</strong></p>
<p>As language model agents are applied to real world problems of increasing complexity, they will be expected to formulate plans across large search spaces. If those plans fail for reasons beyond their control, how well do language agents search for alternative ways to achieve their goals? We devise a specialized agentic planning benchmark to study this question. Each planning problem is solved via combinations of function calls. The agent searches for relevant functions from a set of over four thousand possibilities, and observes environmental feedback in the form of function outputs or error messages. Our benchmark confronts the agent with external failures in its workflow, such as functions that suddenly become unavailable. At the same time, even with the introduction of these failures, we guarantee that the task remains solvable. Ideally, an agentâ€™s performance on the planning task should not be affected by the presence of external failures. Overall, we find that language agents struggle to formulate and execute backup plans in response to environment feedback. While state-of-the-art models are often able to identify the correct function to use in the right context, they struggle to adapt to feedback from the environment and often fail to pursue alternate courses of action, even when the search space is artificially restricted. We provide a systematic analysis of the failures of both open-source and commercial models, examining the effects of search space size, as well as the benefits of scaling model size in our setting. Our analysis identifies key challenges for current generative models as well as promising directions for future work. </p>
<blockquote>
<p>éšç€è¯­è¨€æ¨¡å‹ä»£ç†è¢«åº”ç”¨äºæ—¥ç›Šå¤æ‚çš„å®é™…é—®é¢˜ï¼Œä»–ä»¬å°†è¢«æœŸæœ›åœ¨å¤§æœç´¢ç©ºé—´å†…åˆ¶å®šè®¡åˆ’ã€‚å¦‚æœè¿™äº›è®¡åˆ’å› è¶…å‡ºå…¶æ§åˆ¶çš„åŸå› è€Œå¤±è´¥ï¼Œè¯­è¨€æ¨¡å‹ä»£ç†åœ¨è¾¾æˆç›®æ ‡çš„è¿‡ç¨‹ä¸­ï¼Œå¦‚ä½•æœ‰æ•ˆåœ°å¯»æ‰¾æ›¿ä»£æ–¹å¼ï¼Ÿæˆ‘ä»¬è®¾è®¡äº†ä¸€ä¸ªä¸“ä¸šçš„ä»£ç†è§„åˆ’åŸºå‡†æµ‹è¯•æ¥ç ”ç©¶è¿™ä¸ªé—®é¢˜ã€‚æ¯ä¸ªè§„åˆ’é—®é¢˜éƒ½æ˜¯é€šè¿‡å‡½æ•°è°ƒç”¨ç»„åˆæ¥è§£å†³çš„ã€‚ä»£ç†ä»å››åƒå¤šç§å¯èƒ½æ€§ä¸­æœç´¢ç›¸å…³å‡½æ•°ï¼Œå¹¶ä»¥å‡½æ•°è¾“å‡ºæˆ–é”™è¯¯æ¶ˆæ¯çš„å½¢å¼è§‚å¯Ÿç¯å¢ƒåé¦ˆã€‚æˆ‘ä»¬çš„åŸºå‡†æµ‹è¯•é¢å¯¹ä»£ç†å·¥ä½œæµç¨‹ä¸­çš„å¤–éƒ¨æ•…éšœï¼Œä¾‹å¦‚çªç„¶æ— æ³•ä½¿ç”¨çš„å‡½æ•°ã€‚åŒæ—¶ï¼Œå³ä½¿å¼•å…¥äº†è¿™äº›æ•…éšœï¼Œæˆ‘ä»¬ä¹Ÿèƒ½ä¿è¯ä»»åŠ¡ä»ç„¶å¯ä»¥è§£å†³ã€‚ç†æƒ³æƒ…å†µä¸‹ï¼Œä»£ç†åœ¨è§„åˆ’ä»»åŠ¡ä¸Šçš„è¡¨ç°ä¸åº”å—åˆ°å¤–éƒ¨æ•…éšœçš„å½±å“ã€‚æ€»çš„æ¥è¯´ï¼Œæˆ‘ä»¬å‘ç°è¯­è¨€æ¨¡å‹ä»£ç†åœ¨æ ¹æ®ç¯å¢ƒåé¦ˆåˆ¶å®šå’Œæ‰§è¡Œå¤‡ä»½è®¡åˆ’æ—¶é‡åˆ°äº†å›°éš¾ã€‚è™½ç„¶æœ€å…ˆè¿›çš„æ¨¡å‹é€šå¸¸èƒ½å¤Ÿåœ¨æ­£ç¡®çš„ä¸Šä¸‹æ–‡ä¸­è¯†åˆ«å‡ºè¦ä½¿ç”¨çš„æ­£ç¡®å‡½æ•°ï¼Œä½†å®ƒä»¬å¾ˆéš¾é€‚åº”æ¥è‡ªç¯å¢ƒçš„åé¦ˆï¼Œå¹¶ä¸”å¸¸å¸¸æ— æ³•é‡‡å–æ›¿ä»£çš„è¡ŒåŠ¨ï¼Œå³ä½¿æœç´¢ç©ºé—´è¢«äººä¸ºé™åˆ¶ã€‚æˆ‘ä»¬å¯¹å¼€æºå’Œå•†ä¸šæ¨¡å‹çš„å¤±è´¥è¿›è¡Œäº†ç³»ç»Ÿåˆ†æï¼Œç ”ç©¶äº†æœç´¢ç©ºé—´å¤§å°çš„å½±å“ï¼Œä»¥åŠåœ¨æˆ‘ä»¬ç¯å¢ƒä¸­æ‰©å¤§æ¨¡å‹è§„æ¨¡çš„å¥½å¤„ã€‚æˆ‘ä»¬çš„åˆ†æç¡®å®šäº†å½“å‰ç”Ÿæˆæ¨¡å‹çš„å…³é”®æŒ‘æˆ˜ä»¥åŠæœªæ¥å·¥ä½œçš„æœ‰å‰é€”çš„æ–¹å‘ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.11027v1">PDF</a> Accepted to COLM 2025</p>
<p><strong>Summary</strong></p>
<p>éšç€è¯­è¨€æ¨¡å‹ä»£ç†åœ¨ç°å®ä¸–ç•Œä¸­å¤„ç†æ—¥ç›Šå¤æ‚çš„é—®é¢˜ï¼Œå®ƒä»¬éœ€è¦åœ¨è¾ƒå¤§çš„æœç´¢ç©ºé—´ä¸­åˆ¶å®šè®¡åˆ’ã€‚å½“è¿™äº›è®¡åˆ’å› è¶…å‡ºæ§åˆ¶çš„åŸå› å¤±è´¥æ—¶ï¼Œè¯­è¨€æ¨¡å‹ä»£ç†åœ¨è¾¾æˆç›®æ ‡çš„è¿‡ç¨‹ä¸­å¦‚ä½•å¯»æ‰¾æ›¿ä»£æ–¹æ¡ˆï¼Ÿä¸ºäº†ç ”ç©¶è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬è®¾è®¡äº†ä¸€ä¸ªä¸“é—¨çš„è¯­è¨€ä»£ç†è§„åˆ’åŸºå‡†æµ‹è¯•ã€‚æµ‹è¯•ä¸­å‘ç°ï¼Œè¯­è¨€æ¨¡å‹ä»£ç†åœ¨åº”å¯¹ç¯å¢ƒåé¦ˆæ—¶ï¼Œéš¾ä»¥åˆ¶å®šå¹¶æ‰§è¡Œæ›¿ä»£è®¡åˆ’ã€‚å³ä½¿æœç´¢ç©ºé—´è¢«äººä¸ºé™åˆ¶ï¼Œå®ƒä»¬ä¹Ÿå¾ˆéš¾é€‚åº”ç¯å¢ƒåé¦ˆå¹¶å¸¸å¸¸æ— æ³•é‡‡å–æ›¿ä»£è¡ŒåŠ¨ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>è¯­è¨€æ¨¡å‹ä»£ç†é¢ä¸´æ—¥ç›Šå¤æ‚çš„ç°å®é—®é¢˜ï¼Œéœ€è¦åœ¨è¾ƒå¤§çš„æœç´¢ç©ºé—´ä¸­åˆ¶å®šè®¡åˆ’ã€‚</li>
<li>å½“è¯­è¨€æ¨¡å‹ä»£ç†çš„è®¡åˆ’å¤±è´¥æ—¶ï¼Œå®ƒä»¬å¦‚ä½•å¯»æ‰¾æ›¿ä»£æ–¹æ¡ˆæ˜¯ä¸€ä¸ªé‡è¦é—®é¢˜ã€‚</li>
<li>æˆ‘ä»¬è®¾è®¡äº†ä¸€ä¸ªä¸“é—¨çš„è¯­è¨€ä»£ç†è§„åˆ’åŸºå‡†æµ‹è¯•æ¥ç ”ç©¶è¿™ä¸ªé—®é¢˜ã€‚</li>
<li>è¯­è¨€æ¨¡å‹ä»£ç†åœ¨åº”å¯¹ç¯å¢ƒåé¦ˆæ—¶éš¾ä»¥åˆ¶å®šæ›¿ä»£è®¡åˆ’ã€‚</li>
<li>å³ä½¿æœç´¢ç©ºé—´è¢«é™åˆ¶ï¼Œè¯­è¨€æ¨¡å‹ä»£ç†ä¹Ÿå¾ˆéš¾é‡‡å–æ›¿ä»£è¡ŒåŠ¨ã€‚</li>
<li>å¯¹å¼€æºå’Œå•†ä¸šæ¨¡å‹çš„å¤±è´¥è¿›è¡Œäº†ç³»ç»Ÿåˆ†æï¼Œå‘ç°æœç´¢ç©ºé—´å¤§å°å’Œæ¨¡å‹è§„æ¨¡çš„å½±å“ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.11027">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-171e2000d76d6a40c1a3181dee496da6.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-bc2aab1c1e3b56dff29ae7a20623db00.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e9b7c25f46c24aae83049aa82fd72bf2.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="UI-Venus-Technical-Report-Building-High-performance-UI-Agents-with-RFT"><a href="#UI-Venus-Technical-Report-Building-High-performance-UI-Agents-with-RFT" class="headerlink" title="UI-Venus Technical Report: Building High-performance UI Agents with RFT"></a>UI-Venus Technical Report: Building High-performance UI Agents with RFT</h2><p><strong>Authors:Zhangxuan Gu, Zhengwen Zeng, Zhenyu Xu, Xingran Zhou, Shuheng Shen, Yunfei Liu, Beitong Zhou, Changhua Meng, Tianyu Xia, Weizhi Chen, Yue Wen, Jingya Dou, Fei Tang, Jinzhen Lin, Yulin Liu, Zhenlin Guo, Yichen Gong, Heng Jia, Changlong Gao, Yuan Guo, Yong Deng, Zhenyu Guo, Liang Chen, Weiqiang Wang</strong></p>
<p>We present UI-Venus, a native UI agent that takes only screenshots as input based on a multimodal large language model. UI-Venus achieves SOTA performance on both UI grounding and navigation tasks using only several hundred thousand high-quality training samples through reinforcement finetune (RFT) based on Qwen2.5-VL. Specifically, the 7B and 72B variants of UI-Venus obtain 94.1% &#x2F; 50.8% and 95.3% &#x2F; 61.9% on the standard grounding benchmarks, i.e., Screenspot-V2 &#x2F; Pro, surpassing the previous SOTA baselines including open-source GTA1 and closed-source UI-TARS-1.5. To show UI-Venusâ€™s summary and planing ability, we also evaluate it on the AndroidWorld, an online UI navigation arena, on which our 7B and 72B variants achieve 49.1% and 65.9% success rate, also beating existing models. To achieve this, we introduce carefully designed reward functions for both UI grounding and navigation tasks and corresponding efficient data cleaning strategies. To further boost navigation performance, we propose Self-Evolving Trajectory History Alignment &amp; Sparse Action Enhancement that refine historical reasoning traces and balances the distribution of sparse but critical actions, leading to more coherent planning and better generalization in complex UI tasks. Our contributions include the publish of SOTA open-source UI agents, comprehensive data cleaning protocols and a novel self-evolving framework for improving navigation performance, which encourage further research and development in the community. Code is available at <a target="_blank" rel="noopener" href="https://github.com/inclusionAI/UI-Venus">https://github.com/inclusionAI/UI-Venus</a>. </p>
<blockquote>
<p>æˆ‘ä»¬ä»‹ç»äº†UI-Venusï¼Œè¿™æ˜¯ä¸€ä¸ªåŸºäºå¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹çš„åŸç”Ÿç”¨æˆ·ç•Œé¢ä»£ç†ï¼Œå®ƒä»…ä½¿ç”¨æˆªå›¾ä½œä¸ºè¾“å…¥ã€‚UI-Venusé€šè¿‡ä½¿ç”¨åŸºäºQwen2.5-VLçš„å¼ºåŒ–å¾®è°ƒï¼ˆRFTï¼‰å’Œä»…æ•°ç™¾ä¸‡é«˜è´¨é‡è®­ç»ƒæ ·æœ¬ï¼Œåœ¨UIå®šä½å’Œå¯¼èˆªä»»åŠ¡ä¸Šå®ç°äº†æœ€æ–°æ€§èƒ½ã€‚å…·ä½“æ¥è¯´ï¼ŒUI-Venusçš„7Bå’Œ72Bå˜ä½“åœ¨æ ‡å‡†çš„å®šä½åŸºå‡†æµ‹è¯•ï¼ˆå³Screenspot-V2&#x2F;Proï¼‰ä¸Šåˆ†åˆ«è¾¾åˆ°äº†94.1%&#x2F;50.8%å’Œ95.3%&#x2F;61.9%çš„æ€§èƒ½ï¼Œè¶…è¿‡äº†åŒ…æ‹¬å¼€æºGTA1å’Œé—­æºUI-TARS-1.5åœ¨å†…çš„ä¹‹å‰æœ€æ–°åŸºçº¿ã€‚ä¸ºäº†å±•ç¤ºUI-Venusçš„æ‘˜è¦å’Œè§„åˆ’èƒ½åŠ›ï¼Œæˆ‘ä»¬è¿˜å¯¹å…¶åœ¨åœ¨çº¿UIå¯¼èˆªç«æŠ€åœºAndroidWorldä¸Šè¿›è¡Œäº†è¯„ä¼°ï¼Œæˆ‘ä»¬çš„7Bå’Œ72Bå˜ä½“åœ¨è¯¥ä»»åŠ¡ä¸Šçš„æˆåŠŸç‡è¾¾åˆ°äº†49.1%å’Œ65.9%ï¼Œä¹Ÿå‡»è´¥äº†ç°æœ‰æ¨¡å‹ã€‚ä¸ºäº†å®ç°è¿™ä¸€ç›®æ ‡ï¼Œæˆ‘ä»¬ä¸ºUIå®šä½å’Œå¯¼èˆªä»»åŠ¡ç²¾å¿ƒè®¾è®¡äº†å¥–åŠ±åŠŸèƒ½ä»¥åŠç›¸åº”çš„æœ‰æ•ˆæ•°æ®æ¸…ç†ç­–ç•¥ã€‚ä¸ºäº†è¿›ä¸€æ­¥æé«˜å¯¼èˆªæ€§èƒ½ï¼Œæˆ‘ä»¬æå‡ºäº†è‡ªæ¼”åŒ–è½¨è¿¹å†å²å¯¹é½ä¸ç¨€ç–åŠ¨ä½œå¢å¼ºæ–¹æ³•ï¼Œè¯¥æ–¹æ³•å¯ä»¥ç»†åŒ–å†å²æ¨ç†è½¨è¿¹å¹¶å¹³è¡¡ç¨€ç–ä½†å…³é”®åŠ¨ä½œçš„åˆ†å¸ƒï¼Œä»è€Œå¯¼è‡´æ›´è¿è´¯çš„è§„åˆ’ä»¥åŠåœ¨å¤æ‚UIä»»åŠ¡ä¸­æ›´å¥½çš„æ³›åŒ–èƒ½åŠ›ã€‚æˆ‘ä»¬çš„è´¡çŒ®åŒ…æ‹¬å‘å¸ƒæœ€æ–°çš„å¼€æºUIä»£ç†ã€å…¨é¢çš„æ•°æ®æ¸…ç†åè®®ä»¥åŠä¸€ç§æé«˜å¯¼èˆªæ€§èƒ½çš„è‡ªæ¼”åŒ–æ¡†æ¶ï¼Œè¿™é¼“åŠ±äº†ç¤¾åŒºå†…çš„è¿›ä¸€æ­¥ç ”ç©¶å’Œå¼€å‘ã€‚ä»£ç å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/inclusionAI/UI-Venus%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/inclusionAI/UI-Venusæ‰¾åˆ°ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.10833v2">PDF</a> </p>
<p><strong>æ‘˜è¦</strong></p>
<p>æˆ‘ä»¬æ¨å‡ºäº†åŸºäºå¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹çš„åŸç”ŸUIä»£ç†UI-Venusï¼Œå®ƒä»…é€šè¿‡æˆªå›¾ä½œä¸ºè¾“å…¥ã€‚UI-Venusé€šè¿‡å¼ºåŒ–å¾®è°ƒï¼ˆRFTï¼‰åœ¨UIå®šä½å’Œå¯¼èˆªä»»åŠ¡ä¸Šå®ç°äº†å“è¶Šæ€§èƒ½ï¼Œå…¶7Bå’Œ72Bå˜ç§åœ¨æ ‡å‡†å®šä½åŸºå‡†æµ‹è¯•Screenspot-V2 &#x2F; Proä¸Šåˆ†åˆ«è¾¾åˆ°äº†94.1% &#x2F; 50.8%å’Œ95.3% &#x2F; 61.9%ï¼Œè¶…è¶Šäº†åŒ…æ‹¬å¼€æºGTA1å’Œé—­æºUI-TARS-1.5åœ¨å†…çš„å…ˆå‰æœ€ä½³åŸºå‡†æµ‹è¯•ã€‚æˆ‘ä»¬è¿˜è¯„ä¼°äº†UI-Venusçš„æ€»ç»“å’Œè§„åˆ’èƒ½åŠ›ï¼Œåœ¨åœ¨çº¿UIå¯¼èˆªå¹³å°AndroidWorldä¸Šï¼Œæˆ‘ä»¬çš„7Bå’Œ72Bå˜ç§æˆåŠŸç‡è¾¾åˆ°49.1%å’Œ65.9%ï¼Œä¹Ÿå‡»è´¥äº†ç°æœ‰æ¨¡å‹ã€‚ä¸ºè¾¾åˆ°è¿™ä¸€ç›®çš„ï¼Œæˆ‘ä»¬ä¸ºUIå®šä½å’Œå¯¼èˆªä»»åŠ¡ç²¾å¿ƒè®¾è®¡äº†å¥–åŠ±å‡½æ•°å’Œç›¸åº”çš„æ•°æ®æ¸…ç†ç­–ç•¥ã€‚ä¸ºè¿›ä¸€æ­¥æå‡å¯¼èˆªæ€§èƒ½ï¼Œæˆ‘ä»¬æå‡ºäº†è‡ªæˆ‘è¿›åŒ–çš„è½¨è¿¹å†å²å¯¹é½ä¸ç¨€ç–åŠ¨ä½œå¢å¼ºæ–¹æ³•ï¼Œè¯¥æ–¹æ³•å¯ä»¥ä¼˜åŒ–å†å²æ¨ç†è½¨è¿¹ï¼Œå¹³è¡¡ç¨€ç–ä½†å…³é”®åŠ¨ä½œçš„åˆ†å¸ƒï¼Œä»è€Œå®ç°æ›´è¿è´¯çš„è§„åˆ’å’Œå¤æ‚UIä»»åŠ¡ä¸­æ›´å¥½çš„æ³›åŒ–èƒ½åŠ›ã€‚æˆ‘ä»¬çš„è´¡çŒ®åŒ…æ‹¬å…¬å¼€æœ€ä½³å¼€æºUIä»£ç†ã€å…¨é¢çš„æ•°æ®æ¸…ç†åè®®ä»¥åŠä¸€ç§æé«˜å¯¼èˆªæ€§èƒ½çš„è‡ªæˆ‘è¿›åŒ–æ¡†æ¶ï¼Œè¿™é¼“åŠ±äº†ç¤¾åŒºå†…çš„è¿›ä¸€æ­¥ç ”ç©¶å’Œå¼€å‘ã€‚ä»£ç å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/inclusionAI/UI-Venus">https://github.com/inclusionAI/UI-Venus</a>æ‰¾åˆ°ã€‚</p>
<p><strong>å…³é”®è§è§£</strong></p>
<ol>
<li>UI-Venusæ˜¯åŸºäºå¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹çš„åŸç”ŸUIä»£ç†ï¼Œä»…é€šè¿‡æˆªå›¾ä½œä¸ºè¾“å…¥ã€‚</li>
<li>UI-Venusåœ¨UIå®šä½å’Œå¯¼èˆªä»»åŠ¡ä¸Šå®ç°äº†å“è¶Šæ€§èƒ½ï¼Œè¶…è¶Šäº†å…ˆå‰æœ€ä½³åŸºå‡†æµ‹è¯•ã€‚</li>
<li>åœ¨æ ‡å‡†å®šä½åŸºå‡†æµ‹è¯•Screenspot-V2 &#x2F; Proä¸Šï¼ŒUI-Venusçš„7Bå’Œ72Bå˜ç§åˆ†åˆ«è¾¾åˆ°äº†é«˜å‡†ç¡®ç‡ã€‚</li>
<li>UI-Venusåœ¨åœ¨çº¿UIå¯¼èˆªå¹³å°AndroidWorldä¸Šçš„è¡¨ç°ä¼˜äºå…¶ä»–æ¨¡å‹ã€‚</li>
<li>ä¸ºæå‡UI-Venusçš„æ€§èƒ½ï¼Œç²¾å¿ƒè®¾è®¡äº†å¥–åŠ±å‡½æ•°å’Œæ•°æ®æ¸…ç†ç­–ç•¥ã€‚</li>
<li>æå‡ºè‡ªæˆ‘è¿›åŒ–çš„è½¨è¿¹å†å²å¯¹é½ä¸ç¨€ç–åŠ¨ä½œå¢å¼ºæ–¹æ³•ï¼Œä¼˜åŒ–å†å²æ¨ç†è½¨è¿¹ï¼Œå®ç°æ›´å¥½çš„æ³›åŒ–èƒ½åŠ›ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.10833">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-f5a7428b4cacf8cd1db688e5311ce0ea.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-aac5a1f1b87560022fd07ecc6a21a1e0.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-983480955cc172d16e7c13cb765a9fe3.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="PASS-Probabilistic-Agentic-Supernet-Sampling-for-Interpretable-and-Adaptive-Chest-X-Ray-Reasoning"><a href="#PASS-Probabilistic-Agentic-Supernet-Sampling-for-Interpretable-and-Adaptive-Chest-X-Ray-Reasoning" class="headerlink" title="PASS: Probabilistic Agentic Supernet Sampling for Interpretable and   Adaptive Chest X-Ray Reasoning"></a>PASS: Probabilistic Agentic Supernet Sampling for Interpretable and   Adaptive Chest X-Ray Reasoning</h2><p><strong>Authors:Yushi Feng, Junye Du, Yingying Hong, Qifan Wang, Lequan Yu</strong></p>
<p>Existing tool-augmented agentic systems are limited in the real world by (i) black-box reasoning steps that undermine trust of decision-making and pose safety risks, (ii) poor multimodal integration, which is inherently critical for healthcare tasks, and (iii) rigid and computationally inefficient agentic pipelines. We introduce PASS (Probabilistic Agentic Supernet Sampling), the first multimodal framework to address these challenges in the context of Chest X-Ray (CXR) reasoning. PASS adaptively samples agentic workflows over a multi-tool graph, yielding decision paths annotated with interpretable probabilities. Given the complex CXR reasoning task with multimodal medical data, PASS leverages its learned task-conditioned distribution over the agentic supernet. Thus, it adaptively selects the most suitable tool at each supernet layer, offering probability-annotated trajectories for post-hoc audits and directly enhancing medical AI safety. PASS also continuously compresses salient findings into an evolving personalized memory, while dynamically deciding whether to deepen its reasoning path or invoke an early exit for efficiency. To optimize a Pareto frontier balancing performance and cost, we design a novel three-stage training procedure, including expert knowledge warm-up, contrastive path-ranking, and cost-aware reinforcement learning. To facilitate rigorous evaluation, we introduce CAB-E, a comprehensive benchmark for multi-step, safety-critical, free-form CXR reasoning. Experiments across various benchmarks validate that PASS significantly outperforms strong baselines in multiple metrics (e.g., accuracy, AUC, LLM-J.) while balancing computational costs, pushing a new paradigm shift towards interpretable, adaptive, and multimodal medical agentic systems. </p>
<blockquote>
<p>ç°æœ‰å·¥å…·å¢å¼ºå‹ä»£ç†ç³»ç»Ÿåœ¨ç°å®ä¸–ç•Œä¸­çš„åº”ç”¨å­˜åœ¨ä»¥ä¸‹å±€é™æ€§ï¼šï¼ˆiï¼‰é»‘ç®±æ¨ç†æ­¥éª¤æŸå®³å†³ç­–ä¿¡ä»»å¹¶å¸¦æ¥å®‰å…¨é£é™©ï¼›ï¼ˆiiï¼‰ç¼ºä¹è‰¯å¥½çš„å¤šæ¨¡å¼é›†æˆï¼Œè¿™å¯¹äºåŒ»ç–—ä»»åŠ¡æ¥è¯´è‡³å…³é‡è¦ï¼›ï¼ˆiiiï¼‰ä»£ç†ç®¡é“åƒµåŒ–ä¸”è®¡ç®—æ•ˆç‡ä½ä¸‹ã€‚æˆ‘ä»¬å¼•å…¥äº†PASSï¼ˆæ¦‚ç‡ä»£ç†è¶…ç½‘é‡‡æ ·ï¼‰ï¼Œè¿™æ˜¯ç¬¬ä¸€ä¸ªé’ˆå¯¹èƒ¸éƒ¨Xå°„çº¿ï¼ˆCXRï¼‰æ¨ç†ä¸Šä¸‹æ–‡ä¸­çš„è¿™äº›æŒ‘æˆ˜çš„å¤šæ¨¡å¼æ¡†æ¶ã€‚PASSè‡ªé€‚åº”åœ°åœ¨å¤šå·¥å…·å›¾ä¸Šé‡‡æ ·ä»£ç†å·¥ä½œæµç¨‹ï¼Œäº§ç”Ÿå¸¦æœ‰å¯è§£é‡Šæ¦‚ç‡çš„å†³ç­–è·¯å¾„ã€‚é’ˆå¯¹å…·æœ‰å¤šæ¨¡å¼åŒ»ç–—æ•°æ®çš„å¤æ‚CXRæ¨ç†ä»»åŠ¡ï¼ŒPASSåˆ©ç”¨å…¶å­¦ä¹ åˆ°çš„ä»»åŠ¡æ¡ä»¶åˆ†å¸ƒæ¥ä»£ç†è¶…ç½‘ã€‚å› æ­¤ï¼Œå®ƒè‡ªé€‚åº”åœ°é€‰æ‹©æ¯ä¸€è¶…ç½‘å±‚ä¸Šæœ€åˆé€‚çš„å·¥å…·ï¼Œä¸ºäº‹åå®¡è®¡æä¾›æ¦‚ç‡æ³¨é‡Šè½¨è¿¹ï¼Œå¹¶ç›´æ¥å¢å¼ºåŒ»ç–—äººå·¥æ™ºèƒ½çš„å®‰å…¨æ€§ã€‚PASSè¿˜ä¸æ–­å°†é‡è¦å‘ç°å‹ç¼©æˆä¸æ–­æ¼”å˜çš„ä¸ªæ€§åŒ–è®°å¿†ï¼ŒåŒæ—¶åŠ¨æ€å†³å®šæ˜¯æ·±åŒ–å…¶æ¨ç†è·¯å¾„è¿˜æ˜¯æå‰é€€å‡ºä»¥æé«˜æ•ˆç‡ã€‚ä¸ºäº†ä¼˜åŒ–æ€§èƒ½ä¸æˆæœ¬ä¹‹é—´çš„å¸•ç´¯æ‰˜å‰æ²¿ï¼Œæˆ‘ä»¬è®¾è®¡äº†ä¸€ç§æ–°å‹çš„ä¸‰é˜¶æ®µè®­ç»ƒç¨‹åºï¼ŒåŒ…æ‹¬ä¸“å®¶çŸ¥è¯†é¢„çƒ­ã€å¯¹æ¯”è·¯å¾„æ’åå’Œæˆæœ¬æ„ŸçŸ¥å¼ºåŒ–å­¦ä¹ ã€‚ä¸ºäº†è¿›è¡Œä¸¥æ ¼è¯„ä¼°ï¼Œæˆ‘ä»¬å¼•å…¥äº†CAB-Eï¼Œè¿™æ˜¯ä¸€ä¸ªç”¨äºå¤šæ­¥éª¤ã€å®‰å…¨å…³é”®çš„è‡ªç”±å½¢å¼CXRæ¨ç†çš„ç»¼åˆåŸºå‡†æµ‹è¯•ã€‚åœ¨å„ç§åŸºå‡†æµ‹è¯•ä¸Šçš„å®éªŒéªŒè¯äº†PASSåœ¨å¤šä¸ªæŒ‡æ ‡ï¼ˆä¾‹å¦‚å‡†ç¡®æ€§ã€AUCã€LLM-Jï¼‰ä¸Šæ˜¾è‘—ä¼˜äºå¼ºå¤§çš„åŸºçº¿ï¼ŒåŒæ—¶å¹³è¡¡äº†è®¡ç®—æˆæœ¬ï¼Œæœç€å¯è§£é‡Šã€è‡ªé€‚åº”å’Œå¤šæ¨¡å¼åŒ»ç–—ä»£ç†ç³»ç»Ÿçš„æ–°èŒƒå¼è½¬å˜ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.10501v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†PASSï¼ˆProbabilistic Agentic Supernet Samplingï¼‰è¿™ä¸€å¤šæ¨¡æ€æ¡†æ¶ï¼Œè§£å†³äº†ç°æœ‰å·¥å…·å¢å¼ºå‹ä»£ç†ç³»ç»Ÿåœ¨ç°å®ä¸–ç•Œé¢ä¸´çš„æŒ‘æˆ˜ï¼Œå¦‚é»‘ç®±æ¨ç†æ­¥éª¤ã€å¤šæ¨¡æ€æ•´åˆä¸è¶³ä»¥åŠä»£ç†ç®¡é“åƒµåŒ–ç­‰ã€‚PASSåœ¨èƒ¸éƒ¨Xå°„çº¿ï¼ˆCXRï¼‰æ¨ç†çš„ä¸Šä¸‹æ–‡ä¸­è‡ªé€‚åº”é‡‡æ ·ä»£ç†å·¥ä½œæµç¨‹ï¼Œå¹¶é€šè¿‡åœ¨ä»£ç†è¶…ç½‘ä¸Šå­¦ä¹ çš„ä»»åŠ¡æ¡ä»¶åˆ†å¸ƒæ¥åº”å¯¹å¤šæ¨¡æ€åŒ»å­¦æ•°æ®çš„å¤æ‚ä»»åŠ¡ã€‚è¿™ä¸ºåéªŒå®¡è®¡æä¾›äº†å¯è§£é‡Šçš„æ¦‚ç‡è½¨è¿¹ï¼Œå¹¶ç›´æ¥å¢å¼ºäº†åŒ»ç–—äººå·¥æ™ºèƒ½çš„å®‰å…¨æ€§ã€‚PASSè¿˜èƒ½å°†é‡è¦å‘ç°ä¸æ–­å‹ç¼©æˆä¸æ–­å‘å±•çš„ä¸ªæ€§åŒ–è®°å¿†ï¼ŒåŒæ—¶åŠ¨æ€å†³å®šæ˜¯æ·±åŒ–å…¶æ¨ç†è·¯å¾„è¿˜æ˜¯æå‰é€€å‡ºä»¥æé«˜æ•ˆç‡ã€‚æœ¬æ–‡è¿˜ä»‹ç»äº†ä¸ºä¼˜åŒ–æ€§èƒ½ä¸æˆæœ¬ä¹‹é—´çš„å¸•ç´¯æ‰˜å‰æ²¿è€Œè®¾è®¡çš„æ–°å‹ä¸‰é˜¶æ®µè®­ç»ƒç¨‹åºï¼Œä»¥åŠä¸ºä¸¥æ ¼è¯„ä¼°è€Œå¼•å…¥çš„CAB-Eç»¼åˆåŸºå‡†æµ‹è¯•ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒPASSåœ¨å¤šä¸ªæŒ‡æ ‡ä¸Šæ˜¾è‘—ä¼˜äºå¼ºå¤§çš„åŸºçº¿ï¼ŒåŒæ—¶å¹³è¡¡äº†è®¡ç®—æˆæœ¬ï¼Œæ¨åŠ¨äº†å‘å¯è§£é‡Šã€è‡ªé€‚åº”å’Œå¤šæ¨¡æ€åŒ»ç–—ä»£ç†ç³»ç»Ÿçš„èŒƒå¼è½¬å˜ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>PASSæ˜¯è§£å†³ç°æœ‰å·¥å…·å¢å¼ºå‹ä»£ç†ç³»ç»Ÿé¢ä¸´æŒ‘æˆ˜çš„å¤šæ¨¡æ€æ¡†æ¶ï¼Œé€‚ç”¨äºèƒ¸éƒ¨Xå°„çº¿ï¼ˆCXRï¼‰æ¨ç†ã€‚</li>
<li>PASSé€šè¿‡è‡ªé€‚åº”é‡‡æ ·ä»£ç†å·¥ä½œæµç¨‹å’Œå­¦ä¹ çš„ä»»åŠ¡æ¡ä»¶åˆ†å¸ƒæ¥æé«˜å†³ç­–çš„å¯è§£é‡Šæ€§å’Œå®‰å…¨æ€§ã€‚</li>
<li>PASSèƒ½å¤Ÿå‹ç¼©å…³é”®å‘ç°åˆ°ä¸ªæ€§åŒ–è®°å¿†ï¼Œå¹¶æ ¹æ®éœ€è¦å†³å®šæ¨ç†è·¯å¾„çš„æ·±åº¦æˆ–æå‰é€€å‡ºï¼Œä»è€Œæé«˜æ•ˆç‡ã€‚</li>
<li>å¼•å…¥äº†ä¸€ç§æ–°å‹ä¸‰é˜¶æ®µè®­ç»ƒç¨‹åºï¼Œæ—¨åœ¨å¹³è¡¡æ€§èƒ½ä¸æˆæœ¬ã€‚</li>
<li>é€šè¿‡ä¸“å®¶çŸ¥è¯†é¢„çƒ­ã€å¯¹æ¯”è·¯å¾„æ’åå’Œæˆæœ¬æ„ŸçŸ¥å¼ºåŒ–å­¦ä¹ æ¥ä¼˜åŒ–è®­ç»ƒç¨‹åºã€‚</li>
<li>ä»‹ç»äº†CAB-Eç»¼åˆåŸºå‡†æµ‹è¯•ï¼Œä»¥è¿›è¡Œä¸¥æ ¼çš„è¯„ä¼°ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.10501">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-e4457419d4262a7e70e362ceab8354d0.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-7df19b92122ecd883f6c19a7903fae2c.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-bfbb865d8ba865ab90838d43b5b5da58.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-a415cd9a418fb96da493a845f3795ef5.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-bc887793f16b3e70b8d00b8c06750a47.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-0dfae07fd00786a3315bec146a6f7018.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-390f20e26797659d0712c552b21b4259.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="Seeing-Listening-Remembering-and-Reasoning-A-Multimodal-Agent-with-Long-Term-Memory"><a href="#Seeing-Listening-Remembering-and-Reasoning-A-Multimodal-Agent-with-Long-Term-Memory" class="headerlink" title="Seeing, Listening, Remembering, and Reasoning: A Multimodal Agent with   Long-Term Memory"></a>Seeing, Listening, Remembering, and Reasoning: A Multimodal Agent with   Long-Term Memory</h2><p><strong>Authors:Lin Long, Yichen He, Wentao Ye, Yiyuan Pan, Yuan Lin, Hang Li, Junbo Zhao, Wei Li</strong></p>
<p>We introduce M3-Agent, a novel multimodal agent framework equipped with long-term memory. Like humans, M3-Agent can process real-time visual and auditory inputs to build and update its long-term memory. Beyond episodic memory, it also develops semantic memory, enabling it to accumulate world knowledge over time. Its memory is organized in an entity-centric, multimodal format, allowing deeper and more consistent understanding of the environment. Given an instruction, M3-Agent autonomously performs multi-turn, iterative reasoning and retrieves relevant information from memory to accomplish the task. To evaluate memory effectiveness and memory-based reasoning in multimodal agents, we develop M3-Bench, a new long-video question answering benchmark. M3-Bench comprises 100 newly recorded real-world videos captured from a robotâ€™s perspective (M3-Bench-robot) and 920 web-sourced videos across diverse scenarios (M3-Bench-web). We annotate question-answer pairs designed to test key capabilities essential for agent applications, such as human understanding, general knowledge extraction, and cross-modal reasoning. Experimental results show that M3-Agent, trained via reinforcement learning, outperforms the strongest baseline, a prompting agent using Gemini-1.5-pro and GPT-4o, achieving 6.7%, 7.7%, and 5.3% higher accuracy on M3-Bench-robot, M3-Bench-web and VideoMME-long, respectively. Our work advances the multimodal agents toward more human-like long-term memory and provides insights into their practical design. Model, code and data are available at <a target="_blank" rel="noopener" href="https://github.com/bytedance-seed/m3-agent">https://github.com/bytedance-seed/m3-agent</a> </p>
<blockquote>
<p>æˆ‘ä»¬ä»‹ç»äº†M3-Agentï¼Œè¿™æ˜¯ä¸€ç§é…å¤‡é•¿æœŸè®°å¿†çš„æ–°å‹å¤šæ¨¡æ€ä»£ç†æ¡†æ¶ã€‚ä¸äººç±»ç±»ä¼¼ï¼ŒM3-Agentå¯ä»¥å¤„ç†å®æ—¶çš„è§†è§‰å’Œå¬è§‰è¾“å…¥æ¥æ„å»ºå’Œæ›´æ–°å…¶é•¿æœŸè®°å¿†ã€‚é™¤äº†æƒ…æ™¯è®°å¿†ä¹‹å¤–ï¼Œå®ƒè¿˜å‘å±•å‡ºè¯­ä¹‰è®°å¿†ï¼Œä½¿å…¶èƒ½å¤Ÿéšç€æ—¶é—´çš„æ¨ç§»ç§¯ç´¯ä¸–ç•ŒçŸ¥è¯†ã€‚å®ƒçš„è®°å¿†ä»¥å®ä½“ä¸ºä¸­å¿ƒçš„å¤šæ¨¡æ€æ ¼å¼ç»„ç»‡ï¼Œå…è®¸å¯¹ç¯å¢ƒæœ‰æ›´æ·±å…¥å’Œä¸€è‡´çš„ç†è§£ã€‚æ¥å—æŒ‡ä»¤åï¼ŒM3-Agentå¯ä»¥è‡ªä¸»è¿›è¡Œå¤šè½®è¿­ä»£æ¨ç†ï¼Œä»è®°å¿†ä¸­æ£€ç´¢ç›¸å…³ä¿¡æ¯ä»¥å®Œæˆä»»åŠ¡ã€‚ä¸ºäº†è¯„ä¼°å¤šæ¨¡æ€ä»£ç†ä¸­çš„è®°å¿†æ•ˆæœå’ŒåŸºäºè®°å¿†æ¨ç†èƒ½åŠ›ï¼Œæˆ‘ä»¬å¼€å‘äº†M3-Benchï¼Œè¿™æ˜¯ä¸€ä¸ªæ–°çš„é•¿è§†é¢‘é—®ç­”åŸºå‡†æµ‹è¯•ã€‚M3-BenchåŒ…æ‹¬100ä¸ªæ–°å½•åˆ¶çš„ä¸–ç•ŒçœŸå®è§†é¢‘ï¼ˆä»æœºå™¨äººè§†è§’æ•è·ï¼‰ï¼ˆM3-Bench-robotï¼‰å’Œ920ä¸ªæ¥è‡ªä¸åŒåœºæ™¯çš„ç½‘é¡µè§†é¢‘ï¼ˆM3-Bench-webï¼‰ã€‚æˆ‘ä»¬æ³¨é‡Šäº†é—®é¢˜ç­”æ¡ˆå¯¹ï¼Œæ—¨åœ¨æµ‹è¯•ä»£ç†åº”ç”¨ç¨‹åºå¿…éœ€çš„å…³é”®èƒ½åŠ›ï¼Œå¦‚äººç±»ç†è§£ã€ä¸€èˆ¬çŸ¥è¯†æå–å’Œè·¨æ¨¡æ€æ¨ç†ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œé€šè¿‡å¼ºåŒ–å­¦ä¹ è®­ç»ƒçš„M3-Agentè¶…è¶Šäº†æœ€å¼ºåŸºçº¿ï¼ˆä½¿ç”¨Gemini-1.5-proå’ŒGPT-4oçš„æç¤ºä»£ç†ï¼‰ï¼Œåœ¨M3-Bench-robotã€M3-Bench-webå’ŒVideoMME-longä¸Šçš„å‡†ç¡®ç‡åˆ†åˆ«æé«˜äº†6.7%ã€7.7%å’Œ5.3%ã€‚æˆ‘ä»¬çš„å·¥ä½œä½¿å¤šæ¨¡æ€ä»£ç†æœç€æ›´åƒäººç±»çš„é•¿æ—¶è®°å¿†æ–¹å‘å‘å±•ï¼Œå¹¶ä¸ºå…¶å®è·µè®¾è®¡æä¾›äº†è§è§£ã€‚æ¨¡å‹ã€ä»£ç å’Œæ•°æ®å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/bytedance-seed/m3-agent%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/bytedance-seed/m3-agentæ‰¾åˆ°ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.09736v2">PDF</a> </p>
<p><strong>æ‘˜è¦</strong></p>
<p>M3-Agentæ˜¯ä¸€ç§é…å¤‡é•¿æœŸè®°å¿†çš„å¤šæ¨¡æ€ä»£ç†æ¡†æ¶ã€‚å®ƒèƒ½å¤„ç†å®æ—¶è§†è§‰å’Œå¬è§‰è¾“å…¥æ¥æ„å»ºå’Œæ›´æ–°å…¶é•¿æœŸè®°å¿†ï¼Œå¹¶å‘å±•è¯­ä¹‰è®°å¿†ï¼Œèƒ½å¤Ÿéšæ—¶é—´ç§¯ç´¯ä¸–ç•ŒçŸ¥è¯†ã€‚å…¶è®°å¿†ä»¥å®ä½“ä¸ºä¸­å¿ƒçš„å¤šæ¨¡æ€æ ¼å¼ç»„ç»‡ï¼Œä½¿å…¶å¯¹ç¯å¢ƒæœ‰æ›´æ·±å…¥å’Œä¸€è‡´çš„ç†è§£ã€‚åœ¨æ¥æ”¶åˆ°æŒ‡ä»¤åï¼ŒM3-Agentå¯è‡ªä¸»è¿›è¡Œå¤šå›åˆè¿­ä»£æ¨ç†ï¼Œä»è®°å¿†ä¸­æ£€ç´¢ç›¸å…³ä¿¡æ¯ä»¥å®Œæˆä»»åŠ¡ã€‚ä¸ºè¯„ä¼°å¤šæ¨¡æ€ä»£ç†çš„è®°å¿†æ•ˆæœå’ŒåŸºäºè®°å¿†æ¨ç†èƒ½åŠ›ï¼Œæˆ‘ä»¬å¼€å‘äº†M3-Benchï¼Œæ–°çš„é•¿è§†é¢‘é—®ç­”åŸºå‡†æµ‹è¯•ã€‚M3-BenchåŒ…æ‹¬100ä¸ªæ–°å½•åˆ¶çš„çœŸå®ä¸–ç•Œæœºå™¨äººè§†è§’è§†é¢‘ï¼ˆM3-Bench-robotï¼‰å’Œ920ä¸ªç½‘ç»œæ¥æºçš„è·¨åœºæ™¯è§†é¢‘ï¼ˆM3-Bench-webï¼‰ã€‚æˆ‘ä»¬æ ‡æ³¨äº†é—®ç­”å¯¹ï¼Œæ—¨åœ¨æµ‹è¯•ä»£ç†åº”ç”¨ç¨‹åºå¿…éœ€çš„å…³é”®èƒ½åŠ›ï¼Œå¦‚äººç±»ç†è§£ã€ä¸€èˆ¬çŸ¥è¯†æå–å’Œè·¨æ¨¡æ€æ¨ç†ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œé€šè¿‡å¼ºåŒ–å­¦ä¹ è®­ç»ƒçš„M3-Agentè¶…è¶Šæœ€å¼ºåŸºçº¿ï¼Œä½¿ç”¨Gemini-1.5-proå’ŒGPT-4oçš„æç¤ºä»£ç†ï¼Œåœ¨M3-Bench-robotã€M3-Bench-webå’ŒVideoMME-longä¸Šåˆ†åˆ«æé«˜äº†6.7%ã€7.7%å’Œ5.3%çš„å‡†ç¡®åº¦ã€‚æˆ‘ä»¬çš„å·¥ä½œæ¨åŠ¨äº†å¤šæ¨¡æ€ä»£ç†æœæ›´äººæ€§åŒ–çš„é•¿æœŸè®°å¿†æ–¹å‘å‘å±•ï¼Œå¹¶ä¸ºå…¶å®ç”¨è®¾è®¡æä¾›äº†è§è§£ã€‚</p>
<p><strong>å…³é”®è§è§£</strong></p>
<ol>
<li>M3-Agentæ˜¯ä¸€ç§å¤šæ¨¡æ€ä»£ç†æ¡†æ¶ï¼Œå…·å¤‡å¤„ç†å®æ—¶è§†è§‰å’Œå¬è§‰è¾“å…¥çš„èƒ½åŠ›ï¼Œä»¥æ„å»ºå’Œæ›´æ–°å…¶é•¿æœŸè®°å¿†ã€‚</li>
<li>M3-Agentä¸ä»…æ‹¥æœ‰æƒ…æ™¯è®°å¿†ï¼Œè¿˜å‘å±•è¯­ä¹‰è®°å¿†ï¼Œèƒ½å¤Ÿéšæ—¶é—´ç§¯ç´¯çŸ¥è¯†ã€‚</li>
<li>M3-Agentçš„è®°å¿†ä»¥å®ä½“ä¸ºä¸­å¿ƒçš„å¤šæ¨¡æ€æ ¼å¼ç»„ç»‡ï¼Œæé«˜å¯¹ç¯å¢ƒç†è§£çš„ä¸€è‡´æ€§å’Œæ·±åº¦ã€‚</li>
<li>M3-Agentå¯è‡ªä¸»è¿›è¡Œå¤šå›åˆè¿­ä»£æ¨ç†ï¼Œå®Œæˆå¤æ‚ä»»åŠ¡ã€‚</li>
<li>ä¸ºè¯„ä¼°å¤šæ¨¡æ€ä»£ç†çš„è®°å¿†å’Œæ¨ç†èƒ½åŠ›ï¼Œæ¨å‡ºäº†æ–°çš„é•¿è§†é¢‘é—®ç­”åŸºå‡†æµ‹è¯•M3-Benchã€‚</li>
<li>M3-BenchåŒ…å«æœºå™¨äººå’Œç½‘ç»œè§†è§’çš„çœŸå®ä¸–ç•Œè§†é¢‘ï¼Œæ—¨åœ¨æµ‹è¯•ä»£ç†çš„äººç±»ç†è§£ã€çŸ¥è¯†æå–å’Œè·¨æ¨¡æ€æ¨ç†ç­‰å…³é”®èƒ½åŠ›ã€‚</li>
<li>M3-Agentåœ¨M3-Benchæµ‹è¯•ä¸­è¡¨ç°å‡ºå“è¶Šæ€§èƒ½ï¼Œç›¸è¾ƒäºåŸºçº¿ä»£ç†æœ‰æ˜¾è‘—æé«˜ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.09736">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-88de3300a63ffa024c4db9a2b02953d2.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-2e3d57b7970b35415912f02b69d3f5b9.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d402162a75b9869bddcc4fc2fa75e1a3.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-61cb5764a43a536769aa76a58f6c351b.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="Preacher-Paper-to-Video-Agentic-System"><a href="#Preacher-Paper-to-Video-Agentic-System" class="headerlink" title="Preacher: Paper-to-Video Agentic System"></a>Preacher: Paper-to-Video Agentic System</h2><p><strong>Authors:Jingwei Liu, Ling Yang, Hao Luo, Fan Wang, Hongyan Li, Mengdi Wang</strong></p>
<p>The paper-to-video task converts a research paper into a structured video abstract, distilling key concepts, methods, and conclusions into an accessible, well-organized format. While state-of-the-art video generation models demonstrate potential, they are constrained by limited context windows, rigid video duration constraints, limited stylistic diversity, and an inability to represent domain-specific knowledge. To address these limitations, we introduce Preacher, the first paper-to-video agentic system. Preacher employs a topdown approach to decompose, summarize, and reformulate the paper, followed by bottom-up video generation, synthesizing diverse video segments into a coherent abstract. To align cross-modal representations, we define key scenes and introduce a Progressive Chain of Thought (P-CoT) for granular, iterative planning. Preacher successfully generates high-quality video abstracts across five research fields, demonstrating expertise beyond current video generation models. Code will be released at: <a target="_blank" rel="noopener" href="https://github.com/GenVerse/Paper2Video">https://github.com/GenVerse/Paper2Video</a> </p>
<blockquote>
<p>è¯¥è®ºæ–‡åˆ°è§†é¢‘çš„ä»»åŠ¡æ˜¯å°†ç ”ç©¶è®ºæ–‡è½¬åŒ–ä¸ºç»“æ„åŒ–çš„è§†é¢‘æ‘˜è¦ï¼Œæç‚¼å…³é”®æ¦‚å¿µã€æ–¹æ³•å’Œç»“è®ºï¼Œä½¿å…¶æ˜“äºè®¿é—®å’Œæ•´ç†ã€‚å°½ç®¡æœ€å…ˆè¿›çš„è§†é¢‘ç”Ÿæˆæ¨¡å‹æ˜¾ç¤ºå‡ºæ½œåŠ›ï¼Œä½†å®ƒä»¬å—é™äºæœ‰é™çš„ä¸Šä¸‹æ–‡çª—å£ã€åƒµåŒ–çš„è§†é¢‘æ—¶é•¿çº¦æŸã€æœ‰é™çš„é£æ ¼å¤šæ ·æ€§ä»¥åŠæ— æ³•è¡¨ç¤ºç‰¹å®šé¢†åŸŸçŸ¥è¯†ã€‚ä¸ºäº†è§£å†³è¿™äº›å±€é™æ€§ï¼Œæˆ‘ä»¬å¼•å…¥äº†Preacherï¼Œé¦–ä¸ªè®ºæ–‡åˆ°è§†é¢‘çš„æ™ºèƒ½ç³»ç»Ÿã€‚Preacheré‡‡ç”¨è‡ªä¸Šè€Œä¸‹çš„æ–¹æ³•åˆ†è§£ã€æ€»ç»“å’Œé‡æ„è®ºæ–‡ï¼Œç„¶åè¿›è¡Œè‡ªä¸‹è€Œä¸Šçš„è§†é¢‘ç”Ÿæˆï¼Œå°†å¤šæ ·åŒ–çš„è§†é¢‘ç‰‡æ®µç»¼åˆä¸ºè¿è´¯çš„æ‘˜è¦ã€‚ä¸ºäº†å¯¹é½è·¨æ¨¡æ€è¡¨ç¤ºï¼Œæˆ‘ä»¬å®šä¹‰äº†å…³é”®åœºæ™¯å¹¶å¼•å…¥äº†æ¸è¿›æ€ç»´é“¾ï¼ˆP-CoTï¼‰è¿›è¡Œç²¾ç»†çš„è¿­ä»£è§„åˆ’ã€‚PreacheræˆåŠŸåœ°åœ¨äº”ä¸ªç ”ç©¶é¢†åŸŸç”Ÿæˆäº†é«˜è´¨é‡çš„è§†é¢‘æ‘˜è¦ï¼Œå±•ç¤ºäº†è¶…è¶Šå½“å‰è§†é¢‘ç”Ÿæˆæ¨¡å‹çš„ä¸“ä¸šèƒ½åŠ›ã€‚ä»£ç å°†åœ¨<a target="_blank" rel="noopener" href="https://github.com/GenVerse/Paper2Video%E4%B8%8A%E5%8F%91%E5%B8%83%E3%80%82">https://github.com/GenVerse/Paper2Videoä¸Šå‘å¸ƒã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.09632v3">PDF</a> Code not ready</p>
<p><strong>Summary</strong><br>ç ”ç©¶è®ºæ–‡è½¬åŒ–ä¸ºè§†é¢‘æ‘˜è¦çš„ä»»åŠ¡æ˜¯å°†å…³é”®æ¦‚å¿µã€æ–¹æ³•å’Œç»“è®ºè½¬åŒ–ä¸ºæ˜“äºç†è§£ã€ç»„ç»‡è‰¯å¥½çš„è§†é¢‘æ ¼å¼ã€‚å°½ç®¡ç°æœ‰è§†é¢‘ç”Ÿæˆæ¨¡å‹å…·æœ‰æ½œåŠ›ï¼Œä½†å®ƒä»¬å—é™äºä¸Šä¸‹æ–‡çª—å£ã€è§†é¢‘æ—¶é•¿ã€é£æ ¼å¤šæ ·æ€§å’Œæ— æ³•è¡¨è¾¾ç‰¹å®šé¢†åŸŸçŸ¥è¯†ç­‰ç¼ºç‚¹ã€‚ä¸ºè§£å†³è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬æ¨å‡ºPreacherâ€”â€”é¦–ä¸ªè®ºæ–‡è½¬è§†é¢‘çš„æ™ºèƒ½ç³»ç»Ÿã€‚Preacheré‡‡ç”¨è‡ªä¸Šè€Œä¸‹æ–¹æ³•åˆ†è§£ã€æ€»ç»“å’Œé‡æ„è®ºæ–‡ï¼Œå†é€šè¿‡è‡ªä¸‹è€Œä¸Šçš„è§†é¢‘ç”Ÿæˆæ–¹å¼ï¼Œå°†ä¸åŒè§†é¢‘ç‰‡æ®µåˆæˆè¿è´¯çš„æ‘˜è¦ã€‚ä¸ºå¯¹é½è·¨æ¨¡æ€è¡¨è¾¾ï¼Œæˆ‘ä»¬å®šä¹‰å…³é”®åœºæ™¯å¹¶å¼•å…¥æ¸è¿›æ€ç»´é“¾è¿›è¡Œç»†è‡´ã€è¿­ä»£çš„è§„åˆ’ã€‚PreacheræˆåŠŸç”Ÿæˆäº†è·¨è¶Šäº”ä¸ªç ”ç©¶é¢†åŸŸçš„ä¼˜è´¨è§†é¢‘æ‘˜è¦ï¼Œå±•ç°äº†è¶…è¶Šç°æœ‰è§†é¢‘ç”Ÿæˆæ¨¡å‹çš„ä¸“ä¸šèƒ½åŠ›ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ç ”ç©¶è®ºæ–‡è½¬åŒ–ä¸ºè§†é¢‘æ‘˜è¦å…·æœ‰é‡è¦æ€§å’ŒæŒ‘æˆ˜æ€§ã€‚</li>
<li>ç°æœ‰è§†é¢‘ç”Ÿæˆæ¨¡å‹å­˜åœ¨å¤šç§é™åˆ¶ï¼Œå¦‚ä¸Šä¸‹æ–‡çª—å£ã€è§†é¢‘æ—¶é•¿çº¦æŸç­‰ã€‚</li>
<li>Preacheræ˜¯é¦–ä¸ªè®ºæ–‡è½¬è§†é¢‘çš„æ™ºèƒ½ç³»ç»Ÿï¼Œæ—¨åœ¨è§£å†³ç°æœ‰æ¨¡å‹çš„å±€é™æ€§ã€‚</li>
<li>Preacheré‡‡ç”¨è‡ªä¸Šè€Œä¸‹å’Œè‡ªä¸‹è€Œä¸Šçš„åŒé‡æ–¹æ³•å¤„ç†è®ºæ–‡å’Œè§†é¢‘ç”Ÿæˆã€‚</li>
<li>é€šè¿‡å®šä¹‰å…³é”®åœºæ™¯å’Œæ¸è¿›æ€ç»´é“¾ï¼ŒPreacherå®ç°è·¨æ¨¡æ€è¡¨è¾¾çš„å¯¹é½ã€‚</li>
<li>PreacheræˆåŠŸç”Ÿæˆäº†é«˜è´¨é‡çš„è§†é¢‘æ‘˜è¦ï¼Œé€‚ç”¨äºå¤šä¸ªç ”ç©¶é¢†åŸŸã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.09632">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-50999c62775d2fc4a1c41938baa61249.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-2c35f78f977b7b562e643467f781ae79.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-aabd58efacb3021bc328b855ffb6879f.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-796ef1f12ffd673831080a00b4094a7f.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="The-Roots-of-International-Perceptions-Simulating-US-Attitude-Changes-Towards-China-with-LLM-Agents"><a href="#The-Roots-of-International-Perceptions-Simulating-US-Attitude-Changes-Towards-China-with-LLM-Agents" class="headerlink" title="The Roots of International Perceptions: Simulating US Attitude Changes   Towards China with LLM Agents"></a>The Roots of International Perceptions: Simulating US Attitude Changes   Towards China with LLM Agents</h2><p><strong>Authors:Nicholas Sukiennik, Yichuan Xu, Yuqing Kan, Jinghua Piao, Yuwei Yan, Chen Gao, Yong Li</strong></p>
<p>The rise of LLMs poses new possibilities in modeling opinion evolution, a long-standing task in simulation, by leveraging advanced reasoning abilities to recreate complex, large-scale human cognitive trends. While most prior works focus on opinion evolution surrounding specific isolated events or the views within a country, ours is the first to model the large-scale attitude evolution of a population representing an entire country towards another â€“ US citizensâ€™ perspectives towards China. To tackle the challenges of this broad scenario, we propose a framework that integrates media data collection, user profile creation, and cognitive architecture for opinion updates to successfully reproduce the real trend of US attitudes towards China over a 20-year period from 2005 to today. We also leverage LLMsâ€™ capabilities to introduce debiased media exposure, extracting neutral events from typically subjective news contents, to uncover the roots of polarized opinion formation, as well as a devils advocate agent to help explain the rare reversal from negative to positive attitudes towards China, corresponding with changes in the way Americans obtain information about the country. The simulation results, beyond validating our framework architecture, also reveal the impact of biased framing and selection bias in shaping attitudes. Overall, our work contributes to a new paradigm for LLM-based modeling of cognitive behaviors in a large-scale, long-term, cross-border social context, providing insights into the formation of international biases and offering valuable implications for media consumers to better understand the factors shaping their perspectives, and ultimately contributing to the larger social need for bias reduction and cross-cultural tolerance. </p>
<blockquote>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„å…´èµ·ä¸ºæ¨¡æ‹Ÿé•¿æœŸå­˜åœ¨çš„æ¨¡æ‹Ÿä»»åŠ¡â€”â€”æ„è§æ¼”å˜å¸¦æ¥äº†æ–°çš„å¯èƒ½æ€§ã€‚é€šè¿‡åˆ©ç”¨å…ˆè¿›çš„æ¨ç†èƒ½åŠ›ï¼Œæˆ‘ä»¬èƒ½å¤Ÿé‡æ–°åˆ›å»ºå¤æ‚çš„å¤§è§„æ¨¡äººç±»è®¤çŸ¥è¶‹åŠ¿ã€‚è™½ç„¶ä»¥å‰çš„å¤§å¤šæ•°å·¥ä½œéƒ½é›†ä¸­åœ¨å›´ç»•ç‰¹å®šå­¤ç«‹äº‹ä»¶æˆ–å›½å®¶å†…çš„è§‚ç‚¹çš„æ„è§æ¼”å˜ä¸Šï¼Œä½†æˆ‘ä»¬çš„å·¥ä½œé¦–æ¬¡å¯¹ä»£è¡¨æ•´ä¸ªå›½å®¶é’ˆå¯¹å¦ä¸€ä¸ªå›½å®¶çš„äººå£å¤§è§„æ¨¡æ€åº¦æ¼”å˜è¿›è¡Œå»ºæ¨¡â€”â€”å³ç¾å›½å…¬æ°‘å¯¹ä¸­å›½çš„å¿ƒæ€ã€‚</p>
</blockquote>
<p>ä¸ºäº†åº”å¯¹è¿™ä¸€å¹¿æ³›åœºæ™¯çš„æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªæ¡†æ¶ï¼Œè¯¥æ¡†æ¶é›†æˆäº†åª’ä½“æ•°æ®é‡‡é›†ã€ç”¨æˆ·è§’è‰²åˆ›å»ºå’Œè®¤çŸ¥æ¶æ„ä»¥æ›´æ–°æ„è§ï¼Œä»è€ŒæˆåŠŸåœ°åœ¨ä»2005å¹´è‡³ä»Šçš„20å¹´æœŸé—´å†…å¤åˆ¶äº†ç¾å›½å¯¹ä¸­å›½æ€åº¦çš„çœŸå®è¶‹åŠ¿ã€‚æˆ‘ä»¬è¿˜åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›æ¥å¼•å…¥æ— åè§çš„åª’ä½“æ›å…‰ï¼Œä»é€šå¸¸ä¸»è§‚çš„æ–°é—»å†…å®¹ä¸­æå–ä¸­æ€§äº‹ä»¶ï¼Œä»¥æ­ç¤ºåæ¿€æ„è§å½¢æˆçš„æ ¹æºï¼Œä»¥åŠä½¿ç”¨é­”é¬¼ä»£è¨€äººçš„è§’è‰²æ¥å¸®åŠ©è§£é‡Šä»è´Ÿé¢åˆ°æ­£é¢çš„æ€åº¦è½¬å˜ï¼Œè¿™ç§è½¬å˜ä¸ç¾å›½äººäº†è§£è¯¥å›½çš„æ–¹å¼çš„å˜åŒ–ç›¸å¯¹åº”ã€‚</p>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.08837v2">PDF</a> Submitted to AAAI Social Impact 2026</p>
<p><strong>Summary</strong></p>
<p>åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„å‡ºç°ï¼Œä¸ºæˆ‘ä»¬æä¾›äº†ä¸€ä¸ªå…¨æ–°çš„è§†è§’æ¥æ¨¡æ‹Ÿé•¿æœŸå­˜åœ¨çš„è§‚ç‚¹æ¼”åŒ–ä»»åŠ¡ã€‚é€šè¿‡åˆ©ç”¨å…ˆè¿›çš„æ¨ç†èƒ½åŠ›ï¼Œæˆ‘ä»¬èƒ½å¤Ÿé‡æ–°åˆ›å»ºå¤æ‚çš„å¤§è§„æ¨¡äººç±»è®¤çŸ¥è¶‹åŠ¿ã€‚æœ¬ç ”ç©¶é¦–æ¬¡å…³æ³¨ä»£è¡¨æ•´ä¸ªå›½å®¶å¯¹å¦ä¸€ä¸ªå›½å®¶æ€åº¦çš„æ¼”åŒ–è¿‡ç¨‹ï¼Œç‰¹åˆ«æ˜¯ç¾å›½å…¬æ°‘å¯¹ä¸­å›½çš„æ€åº¦ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªæ•´åˆåª’ä½“æ•°æ®é‡‡é›†ã€ç”¨æˆ·ç”»åƒåˆ›å»ºå’Œè®¤çŸ¥æ¶æ„æ›´æ–°æ„è§æ¡†æ¶ï¼ŒæˆåŠŸå†ç°äº†ç¾å›½å¯¹ä¸­å›½æ€åº¦åœ¨é•¿è¾¾äºŒåå¹´å†…çš„çœŸå®è¶‹åŠ¿ã€‚åŒæ—¶ï¼Œåˆ©ç”¨LLMçš„èƒ½åŠ›å¼•å…¥æ— ååª’ä½“æ›å…‰ï¼Œæå–é€šå¸¸ä¸»è§‚æ–°é—»å†…å®¹ä¸­çš„ä¸­æ€§äº‹ä»¶ï¼Œæ­ç¤ºæ„è§ä¸¤æåˆ†åŒ–çš„æ ¹æºã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬çš„æ¨¡æ‹Ÿç»“æœè¿˜æ­ç¤ºäº†æ¡†æ¶æ¶æ„éªŒè¯è¿‡ç¨‹ä¸­çš„åè§æ¡†æ¶å’Œé€‰æ‹©åè§å¯¹æ€åº¦å½¢æˆçš„å½±å“ã€‚æœ¬ç ”ç©¶ä¸ºåœ¨å¤§è§„æ¨¡ã€é•¿æœŸã€è·¨å›½ç¤¾ä¼šèƒŒæ™¯ä¸‹åˆ©ç”¨LLMè¿›è¡Œè®¤çŸ¥è¡Œä¸ºå»ºæ¨¡æä¾›äº†æ–°çš„èŒƒä¾‹ï¼Œå¯¹äº†è§£å›½é™…åè§å½¢æˆå› ç´ æœ‰é‡è¦å¯ç¤ºï¼Œå¹¶ä¸ºåª’ä½“æ¶ˆè´¹è€…æä¾›äº†ç†è§£å…¶è§‚ç‚¹å½¢æˆå› ç´ çš„è§’åº¦ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>LLMsä¸ºæ¨¡æ‹Ÿè§‚ç‚¹æ¼”åŒ–æä¾›äº†æ–°çš„å¯èƒ½æ€§ï¼Œèƒ½å¤Ÿåˆ©ç”¨å…ˆè¿›çš„æ¨ç†èƒ½åŠ›é‡ç°å¤§è§„æ¨¡äººç±»è®¤çŸ¥è¶‹åŠ¿ã€‚</li>
<li>æœ¬ç ”ç©¶é¦–æ¬¡å…³æ³¨ä»£è¡¨æ•´ä¸ªå›½å®¶å¯¹å¦ä¸€ä¸ªå›½å®¶æ€åº¦çš„æ¼”åŒ–è¿‡ç¨‹ï¼Œç‰¹åˆ«æ˜¯ç¾å›½å…¬æ°‘å¯¹ä¸­å›½çš„æ€åº¦ã€‚</li>
<li>é€šè¿‡æ•´åˆåª’ä½“æ•°æ®ã€ç”¨æˆ·ç”»åƒå’Œè®¤çŸ¥æ¶æ„ï¼ŒæˆåŠŸå†ç°ç¾å›½å¯¹ä¸­å›½æ€åº¦äºŒåå¹´æ¥çš„çœŸå®è¶‹åŠ¿ã€‚</li>
<li>LLMsè¢«ç”¨æ¥å¼•å…¥æ— ååª’ä½“æ›å…‰ï¼Œæ­ç¤ºæ„è§ä¸¤æåˆ†åŒ–çš„æ ¹æºã€‚</li>
<li>æ¨¡æ‹Ÿç»“æœéªŒè¯äº†æ¡†æ¶æ¶æ„çš„æœ‰æ•ˆæ€§ï¼Œå¹¶æ­ç¤ºäº†åè§æ¡†æ¶å’Œé€‰æ‹©åè§å¯¹æ€åº¦å½¢æˆçš„å½±å“ã€‚</li>
<li>æœ¬ç ”ç©¶æä¾›äº†ä¸€ä¸ªåœ¨å¤§è§„æ¨¡ã€é•¿æœŸã€è·¨å›½ç¤¾ä¼šèƒŒæ™¯ä¸‹åˆ©ç”¨LLMè¿›è¡Œè®¤çŸ¥è¡Œä¸ºå»ºæ¨¡çš„æ–°èŒƒä¾‹ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.08837">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-e0317511709c7a23f3611c7c509556c6.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-03c9c14f1cc4683568ba45bdc5d9e04b.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-fd3247ec5930206e94c46f506a4df74b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-abf906a396108c4f1d850f9a01083d59.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-51bcfe8f22c93f142574b78d5f7e4b15.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-10ba197d8663e7487c90df83bd8c2fab.jpg" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="AgentSight-System-Level-Observability-for-AI-Agents-Using-eBPF"><a href="#AgentSight-System-Level-Observability-for-AI-Agents-Using-eBPF" class="headerlink" title="AgentSight: System-Level Observability for AI Agents Using eBPF"></a>AgentSight: System-Level Observability for AI Agents Using eBPF</h2><p><strong>Authors:Yusheng Zheng, Yanpeng Hu, Tong Yu, Andi Quinn</strong></p>
<p>Modern software infrastructure increasingly relies on LLM agents for development and maintenance, such as Claude Code and Gemini-cli. However, these AI agents differ fundamentally from traditional deterministic software, posing a significant challenge to conventional monitoring and debugging. This creates a critical semantic gap: existing tools observe either an agentâ€™s high-level intent (via LLM prompts) or its low-level actions (e.g., system calls), but cannot correlate these two views. This blindness makes it difficult to distinguish between benign operations, malicious attacks, and costly failures. We introduce AgentSight, an AgentOps observability framework that bridges this semantic gap using a hybrid approach. Our approach, boundary tracing, monitors agents from outside their application code at stable system interfaces using eBPF. AgentSight intercepts TLS-encrypted LLM traffic to extract semantic intent, monitors kernel events to observe system-wide effects, and causally correlates these two streams across process boundaries using a real-time engine and secondary LLM analysis. This instrumentation-free technique is framework-agnostic, resilient to rapid API changes, and incurs less than 3% performance overhead. Our evaluation shows AgentSight detects prompt injection attacks, identifies resource-wasting reasoning loops, and reveals hidden coordination bottlenecks in multi-agent systems. AgentSight is released as an open-source project at <a target="_blank" rel="noopener" href="https://github.com/agent-sight/agentsight">https://github.com/agent-sight/agentsight</a>. </p>
<blockquote>
<p>ç°ä»£è½¯ä»¶åŸºç¡€è®¾æ–½è¶Šæ¥è¶Šä¾èµ–LLMä»£ç†è¿›è¡Œå¼€å‘å’Œç»´æŠ¤ï¼Œå¦‚Claude Codeå’ŒGemini-cliã€‚ç„¶è€Œï¼Œè¿™äº›AIä»£ç†ä»æ ¹æœ¬ä¸Šä¸åŒäºä¼ ç»Ÿçš„ç¡®å®šæ€§è½¯ä»¶ï¼Œç»™ä¼ ç»Ÿç›‘æ§å’Œè°ƒè¯•å¸¦æ¥äº†é‡å¤§æŒ‘æˆ˜ã€‚è¿™äº§ç”Ÿäº†ä¸€ä¸ªå…³é”®è¯­ä¹‰é¸¿æ²Ÿï¼šç°æœ‰å·¥å…·åªèƒ½è§‚å¯Ÿåˆ°ä»£ç†çš„é«˜çº§æ„å›¾ï¼ˆé€šè¿‡LLMæç¤ºï¼‰æˆ–ä½çº§æ“ä½œï¼ˆä¾‹å¦‚ç³»ç»Ÿè°ƒç”¨ï¼‰ï¼Œä½†æ— æ³•å…³è”è¿™ä¸¤ç§è§†å›¾ã€‚è¿™ç§ç›²ç›®æ€§ä½¿å¾—éš¾ä»¥åŒºåˆ†è‰¯æ€§æ“ä½œã€æ¶æ„æ”»å‡»å’Œæˆæœ¬é«˜æ˜‚çš„æ•…éšœã€‚æˆ‘ä»¬å¼•å…¥äº†AgentSightï¼Œè¿™æ˜¯ä¸€ä¸ªAgentOpså¯è§‚æ€§æ¡†æ¶ï¼Œå®ƒä½¿ç”¨æ··åˆæ–¹æ³•æ¥å¼¥åˆè¿™ä¸€è¯­ä¹‰é¸¿æ²Ÿã€‚æˆ‘ä»¬çš„æ–¹æ³•ï¼Œè¾¹ç•Œè·Ÿè¸ªï¼Œä»åº”ç”¨ç¨‹åºä»£ç å¤–éƒ¨åœ¨ç¨³å®šçš„ç³»ç»Ÿæ¥å£ä¸Šä½¿ç”¨eBPFç›‘æ§ä»£ç†ã€‚AgentSightæ‹¦æˆªTLSåŠ å¯†çš„LLMæµé‡ä»¥æå–è¯­ä¹‰æ„å›¾ï¼Œç›‘æ§å†…æ ¸äº‹ä»¶ä»¥è§‚å¯Ÿç³»ç»ŸèŒƒå›´çš„å½±å“ï¼Œå¹¶ä½¿ç”¨å®æ—¶å¼•æ“å’Œæ¬¡è¦LLMåˆ†æè·¨è¿›ç¨‹è¾¹ç•Œå› æœå…³è”è¿™ä¸¤è‚¡æµã€‚è¿™ç§æ— éœ€ä»ªå™¨çš„æ–¹æ³•å…·æœ‰æ¡†æ¶æ— å…³æ€§ï¼Œå¯¹å¿«é€ŸAPIæ›´æ”¹å…·æœ‰å¼¹æ€§ï¼Œå¹¶ä¸”æ€§èƒ½å¼€é”€å°äº3%ã€‚æˆ‘ä»¬çš„è¯„ä¼°è¡¨æ˜ï¼ŒAgentSightå¯ä»¥æ£€æµ‹æç¤ºæ³¨å…¥æ”»å‡»ï¼Œè¯†åˆ«èµ„æºæµªè´¹çš„æ¨ç†å¾ªç¯ï¼Œå¹¶æ­ç¤ºå¤šä»£ç†ç³»ç»Ÿä¸­çš„éšè—åè°ƒç“¶é¢ˆã€‚AgentSightå·²åœ¨<a target="_blank" rel="noopener" href="https://github.com/agent-sight/agentsight%E4%B8%8A%E4%BD%9C%E4%B8%BA%E5%BC%80%E6%BA%90%E9%A1%B9%E7%9B%AE%E5%8F%91%E5%B8%83%E3%80%82">https://github.com/agent-sight/agentsightä¸Šä½œä¸ºå¼€æºé¡¹ç›®å‘å¸ƒã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.02736v2">PDF</a> </p>
<p><strong>Summary</strong>ï¼šéšç€ç°ä»£è½¯ä»¶åŸºç¡€è®¾æ–½è¶Šæ¥è¶Šä¾èµ–LLMä»£ç†è¿›è¡Œå¼€å‘å’Œç»´æŠ¤ï¼Œå¦‚Claude Codeå’ŒGemini-cliç­‰AIä»£ç†ä¸ä¼ ç»Ÿçš„ç¡®å®šæ€§è½¯ä»¶å­˜åœ¨æ ¹æœ¬å·®å¼‚ï¼Œç»™ä¼ ç»Ÿçš„ç›‘æ§å’Œè°ƒè¯•å¸¦æ¥äº†é‡å¤§æŒ‘æˆ˜ã€‚è¿™é€ æˆäº†ä¸€ä¸ªå…³é”®çš„è¯­ä¹‰é¸¿æ²Ÿï¼šç°æœ‰å·¥å…·åªèƒ½è§‚å¯Ÿåˆ°ä»£ç†çš„é«˜çº§æ„å›¾ï¼ˆé€šè¿‡LLMæç¤ºï¼‰æˆ–ä½çº§æ“ä½œï¼ˆä¾‹å¦‚ç³»ç»Ÿè°ƒç”¨ï¼‰ï¼Œæ— æ³•å°†è¿™ä¸¤è€…ç»“åˆèµ·æ¥ã€‚ä¸ºè§£å†³è¿™ä¸€é—®é¢˜ï¼Œæå‡ºäº†AgentSightï¼Œä¸€ä¸ªAgentOpså¯è§‚æ€§æ¡†æ¶ï¼Œé€šè¿‡æ··åˆæ–¹æ³•å¡«è¡¥è¿™ä¸€è¯­ä¹‰é¸¿æ²Ÿã€‚å…¶é‡‡ç”¨è¾¹ç•Œè¿½è¸ªçš„æ–¹æ³•ï¼Œåœ¨ç¨³å®šçš„ç³»ç»Ÿæ¥å£å¤„ä»åº”ç”¨ç¨‹åºä»£ç å¤–éƒ¨ç›‘è§†ä»£ç†ï¼Œä½¿ç”¨eBPFè¿›è¡Œç›‘æµ‹ã€‚AgentSightèƒ½å¤Ÿæ‹¦æˆªTLSåŠ å¯†çš„LLMæµé‡ä»¥æå–è¯­ä¹‰æ„å›¾ï¼Œç›‘è§†å†…æ ¸äº‹ä»¶ä»¥è§‚å¯Ÿç³»ç»ŸèŒƒå›´å†…çš„æ•ˆæœï¼Œå¹¶ä½¿ç”¨å®æ—¶å¼•æ“å’ŒäºŒæ¬¡LLMåˆ†æåœ¨è¿›ç¨‹è¾¹ç•Œå¤„å› æœå…³è”è¿™ä¸¤ä¸ªæµã€‚è¿™ç§æ— éœ€ä»ªå™¨çš„æ–¹æ³•å…·æœ‰æ¡†æ¶æ— å…³ã€å¯¹å¿«é€ŸAPIæ›´æ”¹å…·æœ‰å¼¹æ€§ä»¥åŠæ€§èƒ½å¼€é”€å°äº3%çš„ç‰¹ç‚¹ã€‚è¯„ä¼°è¡¨æ˜ï¼ŒAgentSightå¯ä»¥æ£€æµ‹æç¤ºæ³¨å…¥æ”»å‡»ã€è¯†åˆ«èµ„æºæµªè´¹çš„æ¨ç†å¾ªç¯ä»¥åŠæ­ç¤ºå¤šä»£ç†ç³»ç»Ÿä¸­çš„éšè—åè°ƒç“¶é¢ˆã€‚</p>
<p><strong>Key Takeaways</strong>ï¼š</p>
<ol>
<li>ç°ä»£è½¯ä»¶åŸºç¡€è®¾æ–½ä¾èµ–LLMä»£ç†è¿›è¡Œå¼€å‘å’Œç»´æŠ¤ï¼Œå¯¹ä¼ ç»Ÿç›‘æ§å’Œè°ƒè¯•å·¥å…·å¸¦æ¥æŒ‘æˆ˜ã€‚</li>
<li>ç°æœ‰å·¥å…·éš¾ä»¥åŒæ—¶è§‚å¯Ÿä»£ç†çš„é«˜çº§æ„å›¾å’Œä½çº§æ“ä½œï¼Œå½¢æˆè¯­ä¹‰é¸¿æ²Ÿã€‚</li>
<li>AgentSightæ˜¯ä¸€ä¸ªå¡«è¡¥è¯­ä¹‰é¸¿æ²Ÿçš„AgentOpså¯è§‚æ€§æ¡†æ¶ï¼Œé€šè¿‡è¾¹ç•Œè¿½è¸ªå’ŒeBPFæŠ€æœ¯ç›‘è§†ä»£ç†ã€‚</li>
<li>AgentSightèƒ½æ‹¦æˆªåŠ å¯†LLMæµé‡æå–è¯­ä¹‰æ„å›¾ï¼ŒåŒæ—¶ç›‘è§†å†…æ ¸äº‹ä»¶è§‚å¯Ÿç³»ç»ŸèŒƒå›´æ•ˆæœã€‚</li>
<li>AgentSightèƒ½å°†é«˜çº§æ„å›¾å’Œä½çº§æ“ä½œè¿›è¡Œå› æœå…³è”ï¼Œå…·æœ‰æ— éœ€ä»ªå™¨ã€æ¡†æ¶æ— å…³ã€é€‚åº”å¿«é€ŸAPIå˜åŒ–ä»¥åŠä½æ€§èƒ½å¼€é”€çš„ç‰¹ç‚¹ã€‚</li>
<li>AgentSightèƒ½æ£€æµ‹æç¤ºæ³¨å…¥æ”»å‡»å’Œèµ„æºæµªè´¹æ¨ç†å¾ªç¯ç­‰é—®é¢˜ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.02736">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-88e8aeb9431e5707bdf438ea46a6bc5f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ff9cab1e8659cdcce68322c47919c493.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-4a4f4774a3d2084fce10050c602ed32e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-78e073a1113671ae76aaeb5fc25ca7d3.jpg" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1><h2 id="PilotRL-Training-Language-Model-Agents-via-Global-Planning-Guided-Progressive-Reinforcement-Learning"><a href="#PilotRL-Training-Language-Model-Agents-via-Global-Planning-Guided-Progressive-Reinforcement-Learning" class="headerlink" title="PilotRL: Training Language Model Agents via Global Planning-Guided   Progressive Reinforcement Learning"></a>PilotRL: Training Language Model Agents via Global Planning-Guided   Progressive Reinforcement Learning</h2><p><strong>Authors:Keer Lu, Chong Chen, Bin Cui, Huang Leng, Wentao Zhang</strong></p>
<p>Large Language Models (LLMs) have shown remarkable advancements in tackling agent-oriented tasks. Despite their potential, existing work faces challenges when deploying LLMs in agent-based environments. The widely adopted agent paradigm ReAct centers on integrating single-step reasoning with immediate action execution, which limits its effectiveness in complex tasks requiring long-term strategic planning. Furthermore, the coordination between the planner and executor during problem-solving is also a critical factor to consider in agent design. Additionally, current approaches predominantly rely on supervised fine-tuning, which often leads models to memorize established task completion trajectories, thereby restricting their generalization ability when confronted with novel problem contexts. To address these challenges, we introduce an adaptive global plan-based agent paradigm AdaPlan, aiming to synergize high-level explicit guidance with execution to support effective long-horizon decision-making. Based on the proposed paradigm, we further put forward PilotRL, a global planning-guided training framework for LLM agents driven by progressive reinforcement learning. We first develop the modelâ€™s ability to follow explicit guidance from global plans when addressing agent tasks. Subsequently, based on this foundation, we focus on optimizing the quality of generated plans. Finally, we conduct joint optimization of the modelâ€™s planning and execution coordination. Experiments indicate that PilotRL could achieve state-of-the-art performances, with LLaMA3.1-8B-Instruct + PilotRL surpassing closed-sourced GPT-4o by 3.60%, while showing a more substantial gain of 55.78% comparing to GPT-4o-mini at a comparable parameter scale. </p>
<blockquote>
<p>é¢å‘ä»£ç†ä»»åŠ¡çš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å·²ç»å–å¾—äº†æ˜¾è‘—çš„è¿›æ­¥ã€‚å°½ç®¡å®ƒä»¬å…·æœ‰æ½œåŠ›ï¼Œä½†åœ¨åŸºäºä»£ç†çš„ç¯å¢ƒä¸­éƒ¨ç½²LLMsæ—¶ï¼Œç°æœ‰å·¥ä½œä»é¢ä¸´æŒ‘æˆ˜ã€‚å¹¿æ³›é‡‡ç”¨çš„ReActä»£ç†èŒƒå¼ä¾§é‡äºå°†å•æ­¥æ¨ç†ä¸å³æ—¶è¡ŒåŠ¨æ‰§è¡Œç›¸ç»“åˆï¼Œè¿™é™åˆ¶äº†å…¶åœ¨éœ€è¦é•¿æœŸæˆ˜ç•¥è§„åˆ’çš„å¤æ‚ä»»åŠ¡ä¸­çš„æœ‰æ•ˆæ€§ã€‚æ­¤å¤–ï¼Œåœ¨è§£å†³é—®é¢˜è¿‡ç¨‹ä¸­ï¼Œè§„åˆ’è€…å’Œæ‰§è¡Œè€…ä¹‹é—´çš„åè°ƒä¹Ÿæ˜¯ä»£ç†è®¾è®¡éœ€è¦è€ƒè™‘çš„å…³é”®å› ç´ ã€‚å¦å¤–ï¼Œå½“å‰çš„æ–¹æ³•ä¸»è¦ä¾èµ–äºç›‘ç£å¾®è°ƒï¼Œè¿™å¾€å¾€å¯¼è‡´æ¨¡å‹è®°å¿†å·²å»ºç«‹çš„ä»»åŠ¡å®Œæˆè½¨è¿¹ï¼Œä»è€Œåœ¨é¢å¯¹æ–°é—®é¢˜ä¸Šä¸‹æ–‡æ—¶é™åˆ¶å…¶æ³›åŒ–èƒ½åŠ›ã€‚ä¸ºäº†è§£å†³è¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬å¼•å…¥äº†åŸºäºè‡ªé€‚åº”å…¨å±€è§„åˆ’çš„ä»£ç†èŒƒå¼AdaPlanï¼Œæ—¨åœ¨å°†é«˜çº§æ˜¾å¼æŒ‡å¯¼ä¸æ‰§è¡Œç›¸ç»“åˆï¼Œä»¥æ”¯æŒæœ‰æ•ˆçš„é•¿æœŸå†³ç­–ã€‚åŸºäºè¿™ä¸€èŒƒå¼ï¼Œæˆ‘ä»¬è¿›ä¸€æ­¥æå‡ºäº†PilotRLï¼Œè¿™æ˜¯ä¸€ä¸ªç”±å…¨å±€è§„åˆ’å¼•å¯¼çš„LLMä»£ç†è®­ç»ƒæ¡†æ¶ï¼Œç”±æ¸è¿›å¼ºåŒ–å­¦ä¹ é©±åŠ¨ã€‚æˆ‘ä»¬é¦–å…ˆå¼€å‘æ¨¡å‹åœ¨è§£å†³ä»£ç†ä»»åŠ¡æ—¶éµå¾ªå…¨å±€è®¡åˆ’çš„æ˜¾å¼æŒ‡å¯¼èƒ½åŠ›ã€‚åœ¨æ­¤åŸºç¡€ä¸Šï¼Œæˆ‘ä»¬ä¸“æ³¨äºä¼˜åŒ–ç”Ÿæˆçš„è®¡åˆ’çš„è´¨é‡ã€‚æœ€åï¼Œæˆ‘ä»¬å¯¹æ¨¡å‹çš„è§„åˆ’å’Œæ‰§è¡Œåè°ƒè¿›è¡Œè”åˆä¼˜åŒ–ã€‚å®éªŒè¡¨æ˜ï¼ŒPilotRLå¯ä»¥è¾¾åˆ°æœ€å…ˆè¿›çš„æ€§èƒ½ï¼ŒLLaMA3.1-8B-Instruct + PilotRLåœ¨å°é—­æºç GPT-4oä¸Šè¶…è¶Š3.60%ï¼Œè€Œåœ¨å¯æ¯”å‚æ•°è§„æ¨¡çš„GPT-4o-miniä¸Šè¡¨ç°å‡ºæ›´å¤§çš„ä¼˜åŠ¿ï¼Œæé«˜äº†55.78%ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.00344v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨å¤„ç†é¢å‘ä»»åŠ¡çš„ä»£ç†æ–¹é¢å–å¾—äº†æ˜¾è‘—è¿›å±•ï¼Œä½†ä»é¢ä¸´éƒ¨ç½²åœ¨ä»£ç†ç¯å¢ƒä¸­çš„æŒ‘æˆ˜ã€‚ç°æœ‰å·¥ä½œé¢ä¸´çš„é—®é¢˜æ˜¯å•ä¸€æ­¥éª¤æ¨ç†ä¸å³æ—¶è¡ŒåŠ¨æ‰§è¡Œçš„é›†æˆé™åˆ¶äº†åœ¨å¤æ‚ä»»åŠ¡ä¸­çš„é•¿æœŸæˆ˜ç•¥è§„åˆ’çš„æœ‰æ•ˆæ€§ã€‚æ–‡ç« æå‡ºäº†è‡ªé€‚åº”å…¨å±€è®¡åˆ’ä»£ç†èŒƒå¼AdaPlanï¼Œæ—¨åœ¨ç»“åˆé«˜çº§æ˜ç¡®æŒ‡å¯¼ä¸æ‰§è¡Œï¼Œä»¥æ”¯æŒæœ‰æ•ˆçš„é•¿æœŸå†³ç­–åˆ¶å®šã€‚åŸºäºè¯¥èŒƒå¼ï¼Œæå‡ºäº†PilotRLï¼Œä¸€ä¸ªç”±æ¸è¿›å¼ºåŒ–å­¦ä¹ é©±åŠ¨çš„å…¨çƒè§„åˆ’æŒ‡å¯¼çš„LLMä»£ç†è®­ç»ƒæ¡†æ¶ã€‚å®éªŒè¡¨æ˜ï¼ŒPilotRLå¯ä»¥è¾¾åˆ°æœ€æ–°æ€§èƒ½æ°´å¹³ï¼ŒLLaMA3.1-8B-Instruct + PilotRLè¶…è¶Šäº†å°é—­å¼GPT-4o 3.60%ï¼Œåœ¨ç›¸ä¼¼å‚æ•°è§„æ¨¡ä¸‹ï¼Œç›¸è¾ƒäºGPT-4o-miniæœ‰æ›´å¤§çš„æå‡å¹…åº¦ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å¤„ç†é¢å‘ä»»åŠ¡çš„ä»£ç†æ–¹é¢å±•ç°å‡ºæ˜¾è‘—è¿›å±•ï¼Œä½†ä»é¢ä¸´éƒ¨ç½²æŒ‘æˆ˜ã€‚</li>
<li>å½“å‰ä»£ç†è®¾è®¡ä¸»è¦ä¾èµ–å•ä¸€æ­¥éª¤æ¨ç†ä¸å³æ—¶è¡ŒåŠ¨æ‰§è¡Œï¼Œé™åˆ¶äº†é•¿æœŸæˆ˜ç•¥è§„åˆ’çš„æœ‰æ•ˆæ€§ã€‚</li>
<li>AdaPlanè‡ªé€‚åº”å…¨å±€è®¡åˆ’ä»£ç†èŒƒå¼æ—¨åœ¨ç»“åˆé«˜çº§æ˜ç¡®æŒ‡å¯¼ä¸æ‰§è¡Œï¼Œä»¥æ”¯æŒé•¿æœŸå†³ç­–åˆ¶å®šã€‚</li>
<li>PilotRLæ¡†æ¶æ˜¯ä¸€ä¸ªåŸºäºå…¨çƒè§„åˆ’æŒ‡å¯¼çš„LLMä»£ç†è®­ç»ƒæ¡†æ¶ï¼Œé‡‡ç”¨æ¸è¿›å¼ºåŒ–å­¦ä¹ é©±åŠ¨ã€‚</li>
<li>æ¨¡å‹å…·å¤‡éµå¾ªå…¨å±€è®¡åˆ’å®Œæˆä»£ç†ä»»åŠ¡çš„èƒ½åŠ›ï¼Œå¹¶åœ¨æ­¤åŸºç¡€ä¸Šä¼˜åŒ–è®¡åˆ’è´¨é‡ã€‚</li>
<li>é€šè¿‡è”åˆä¼˜åŒ–æ¨¡å‹çš„è§„åˆ’ä¸æ‰§è¡Œåè°ƒï¼Œå®ç°æ€§èƒ½æå‡ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.00344">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-a60c70a675f49b4794d168945848f034.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-bef0443738edc856b3fb262092f2f60a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-187802320c67a5feb410f5c62b554c49.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-1dd24c7d608bc9e029fab6a90d2dab5b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-cc6e238b32346b5babf9172f8c8265dd.jpg" align="middle">
</details>


<h1 id="-9"><a href="#-9" class="headerlink" title=""></a></h1><h2 id="Generational-Adversarial-MAP-Elites-for-Multi-Agent-Game-Illumination"><a href="#Generational-Adversarial-MAP-Elites-for-Multi-Agent-Game-Illumination" class="headerlink" title="Generational Adversarial MAP-Elites for Multi-Agent Game Illumination"></a>Generational Adversarial MAP-Elites for Multi-Agent Game Illumination</h2><p><strong>Authors:TimothÃ©e Anne, Noah Syrkis, Meriem Elhosni, Florian Turati, Franck Legendre, Alain Jaquier, Sebastian Risi</strong></p>
<p>Unlike traditional optimization algorithms, which focus on finding a single optimal solution, Quality-Diversity (QD) algorithms illuminate a search space by finding high-performing solutions that cover a specified behavior space. However, tackling adversarial problems is more challenging due to the behavioral interdependence between opposing sides. Most applications of QD algorithms to these problems evolve only one side, thus reducing illumination coverage. In this paper, we propose a new QD algorithm, Generational Adversarial MAP-Elites (GAME), which coevolves solutions by alternating sides through a sequence of generations. Combining GAME with vision embedding models enables the algorithm to operate directly on videos of behaviors, rather than relying on handcrafted descriptors. Some key findings are that (1) emerging evolutionary dynamics sometimes resemble an arms race, (2) starting each generation from scratch increases open-endedness, and (3) keeping neutral mutations preserves stepping stones that seem necessary to reach the highest performance. In conclusion, the results demonstrate that GAME can successfully illuminate an adversarial multi-agent game, opening up interesting future directions in understanding the emergence of open-ended coevolution. </p>
<blockquote>
<p>ä¸åŒäºä¼ ç»Ÿçš„ä¼˜åŒ–ç®—æ³•åªä¸“æ³¨äºå¯»æ‰¾å•ä¸€çš„æœ€ä¼˜è§£ï¼Œè´¨é‡å¤šæ ·æ€§ï¼ˆQDï¼‰ç®—æ³•é€šè¿‡å¯»æ‰¾è¦†ç›–æŒ‡å®šè¡Œä¸ºç©ºé—´çš„é«˜æ€§èƒ½è§£æ¥ç…§äº®æœç´¢ç©ºé—´ã€‚ç„¶è€Œï¼Œç”±äºå¯¹ç«‹åŒæ–¹ä¹‹é—´çš„è¡Œä¸ºç›¸äº’ä¾èµ–æ€§ï¼Œè§£å†³å¯¹æŠ—æ€§é—®é¢˜æ›´å…·æŒ‘æˆ˜æ€§ã€‚å¤§å¤šæ•°QDç®—æ³•åœ¨å¤„ç†è¿™äº›é—®é¢˜æ—¶åªè¿›åŒ–ä¸€ä¾§ï¼Œä»è€Œé™ä½äº†ç…§æ˜è¦†ç›–ç‡ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°çš„QDç®—æ³•â€”â€”ä¸–ä»£å¯¹æŠ—MAPç²¾è‹±ï¼ˆGAMEï¼‰ï¼Œå®ƒé€šè¿‡ä¸€ç³»åˆ—ä¸–ä»£äº¤æ›¿è¿›åŒ–è§£å†³æ–¹æ¡ˆã€‚å°†GAMEä¸è§†è§‰åµŒå…¥æ¨¡å‹ç›¸ç»“åˆï¼Œä½¿ç®—æ³•èƒ½å¤Ÿç›´æ¥åœ¨è¡Œä¸ºè§†é¢‘ä¸Šè¿è¡Œï¼Œè€Œä¸æ˜¯ä¾èµ–äºæ‰‹å·¥è®¾è®¡çš„æè¿°ç¬¦ã€‚ä¸€äº›å…³é”®å‘ç°æ˜¯ï¼šï¼ˆ1ï¼‰å‡ºç°çš„è¿›åŒ–åŠ¨æ€æœ‰æ—¶ç±»ä¼¼äºå†›å¤‡ç«èµ›ï¼›ï¼ˆ2ï¼‰ä»å¤´å¼€å§‹æ¯ä¸€ä»£å¢åŠ äº†å¼€æ”¾æ€§ï¼›ï¼ˆ3ï¼‰ä¿æŒä¸­æ€§çªå˜ä¿ç•™äº†ä¼¼ä¹è¾¾åˆ°æœ€é«˜æ€§èƒ½æ‰€å¿…éœ€çš„å«è„šçŸ³ã€‚æ€»ä¹‹ï¼Œç»“æœè¡¨æ˜ï¼ŒGAMEèƒ½å¤ŸæˆåŠŸç…§äº®å¯¹æŠ—æ€§å¤šæ™ºèƒ½ä½“æ¸¸æˆï¼Œä¸ºç ”ç©¶å¼€æ”¾å¼ååŒè¿›åŒ–çš„å‡ºç°æä¾›äº†æœ‰è¶£çš„æ–¹å‘ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.06617v2">PDF</a> Accepted at ALIFE 2025</p>
<p><strong>Summary</strong></p>
<p>QDç®—æ³•ä¸ä¼ ç»Ÿä¼˜åŒ–ç®—æ³•ä¸åŒï¼Œå®ƒä¸ä»…å¯»æ‰¾å•ä¸€æœ€ä¼˜è§£ï¼Œè¿˜è‡´åŠ›äºæ‰¾åˆ°è¦†ç›–æŒ‡å®šè¡Œä¸ºç©ºé—´çš„é«˜æ€§èƒ½è§£ã€‚å¤„ç†å¯¹æŠ—æ€§é—®é¢˜æ—¶é¢ä¸´æŒ‘æˆ˜ï¼Œå› å¯¹æŠ—åŒæ–¹çš„è¡Œä¸ºç›¸äº’ä¾èµ–ã€‚å¤§éƒ¨åˆ†QDç®—æ³•çš„åº”ç”¨ä»…é’ˆå¯¹å•ä¸€ä¾§æ¼”åŒ–ï¼Œé™ä½äº†ç…§æ˜è¦†ç›–ç‡ã€‚æœ¬æ–‡æå‡ºæ–°çš„QDç®—æ³•â€”â€”ä¸–ä»£å¯¹æŠ—MAPç²¾è‹±ï¼ˆGAMEï¼‰ï¼Œé€šè¿‡äº¤æ›¿ä¸–ä»£å…±åŒæ¼”åŒ–è§£å†³æ–¹æ¡ˆã€‚ç»“åˆè§†è§‰åµŒå…¥æ¨¡å‹ï¼Œç®—æ³•å¯ç›´æ¥å¤„ç†è¡Œä¸ºè§†é¢‘ï¼Œè€Œéä¾èµ–æ‰‹å·¥æè¿°ã€‚ç ”ç©¶ç»“æœæ˜¾ç¤ºï¼Œæ¸¸æˆå†…çš„è¿›åŒ–åŠ¨æ€æœ‰æ—¶ç±»ä¼¼äºå†›å¤‡ç«èµ›ï¼Œä»é›¶å¼€å§‹æ¯ä¸€ä»£å¢åŠ äº†å¼€æ”¾æ€§ï¼Œä¿æŒä¸­æ€§çªå˜å¯ä¿ç•™é€šå¾€æœ€é«˜æ€§èƒ½çš„å¿…ç»ä¹‹è·¯ã€‚æ€»çš„æ¥è¯´ï¼Œæ¸¸æˆæˆåŠŸç…§äº®äº†å¯¹æŠ—æ€§å¤šæ™ºèƒ½ä½“æ¸¸æˆï¼Œä¸ºç†è§£å¼€æ”¾ååŒè¿›åŒ–çš„å‡ºç°æ‰“å¼€äº†æœ‰è¶£çš„æ–¹å‘ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>QDç®—æ³•æ—¨åœ¨è¦†ç›–è¡Œä¸ºç©ºé—´çš„é«˜æ€§èƒ½è§£ï¼Œè€Œéä»…å¯»æ‰¾å•ä¸€æœ€ä¼˜è§£ã€‚</li>
<li>å¯¹æŠ—æ€§é—®é¢˜ä¸­ï¼Œç”±äºåŒæ–¹è¡Œä¸ºçš„ç›¸äº’ä¾èµ–ï¼Œè§£å†³èµ·æ¥å…·æœ‰æŒ‘æˆ˜æ€§ã€‚</li>
<li>å¤§éƒ¨åˆ†QDç®—æ³•åœ¨å¤„ç†å¯¹æŠ—æ€§é—®é¢˜æ—¶ä»…é’ˆå¯¹å•ä¸€ä¾§æ¼”åŒ–ï¼Œé™ä½äº†ç…§æ˜è¦†ç›–ç‡ã€‚</li>
<li>æå‡ºçš„ä¸–ä»£å¯¹æŠ—MAPç²¾è‹±ï¼ˆGAMEï¼‰ç®—æ³•é€šè¿‡äº¤æ›¿ä¸–ä»£å…±åŒæ¼”åŒ–è§£å†³æ–¹æ¡ˆã€‚</li>
<li>ç»“åˆè§†è§‰åµŒå…¥æ¨¡å‹ï¼Œå¯ç›´æ¥å¤„ç†è¡Œä¸ºè§†é¢‘ã€‚</li>
<li>ç ”ç©¶å‘ç°ï¼Œåœ¨æŸäº›æƒ…å†µä¸‹ï¼Œæ¸¸æˆå†…çš„è¿›åŒ–åŠ¨æ€ç±»ä¼¼äºå†›å¤‡ç«èµ›ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.06617">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-05d2b2a36e4058356f4841e5539b7a85.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-4070960db52124165a73fbc1036cbc0e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c940741633d4bab82335fdd5b33123a5.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-75eed385b40826e9aa2be41ce2d18570.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-18dfe9188abaa8ffb988408cf19f6b47.jpg" align="middle">
</details>


<h1 id="-10"><a href="#-10" class="headerlink" title=""></a></h1><h2 id="Learning-to-Be-A-Doctor-Searching-for-Effective-Medical-Agent-Architectures"><a href="#Learning-to-Be-A-Doctor-Searching-for-Effective-Medical-Agent-Architectures" class="headerlink" title="Learning to Be A Doctor: Searching for Effective Medical Agent   Architectures"></a>Learning to Be A Doctor: Searching for Effective Medical Agent   Architectures</h2><p><strong>Authors:Yangyang Zhuang, Wenjia Jiang, Jiayu Zhang, Ze Yang, Joey Tianyi Zhou, Chi Zhang</strong></p>
<p>Large Language Model (LLM)-based agents have demonstrated strong capabilities across a wide range of tasks, and their application in the medical domain holds particular promise due to the demand for high generalizability and reliance on interdisciplinary knowledge. However, existing medical agent systems often rely on static, manually crafted workflows that lack the flexibility to accommodate diverse diagnostic requirements and adapt to emerging clinical scenarios. Motivated by the success of automated machine learning (AutoML), this paper introduces a novel framework for the automated design of medical agent architectures. Specifically, we define a hierarchical and expressive agent search space that enables dynamic workflow adaptation through structured modifications at the node, structural, and framework levels. Our framework conceptualizes medical agents as graph-based architectures composed of diverse, functional node types and supports iterative self-improvement guided by diagnostic feedback. Experimental results on skin disease diagnosis tasks demonstrate that the proposed method effectively evolves workflow structures and significantly enhances diagnostic accuracy over time. This work represents the first fully automated framework for medical agent architecture design and offers a scalable, adaptable foundation for deploying intelligent agents in real-world clinical environments. </p>
<blockquote>
<p>åŸºäºå¤§è§„æ¨¡è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„ä»£ç†äººåœ¨å„ç§ä»»åŠ¡ä¸­è¡¨ç°å‡ºå¼ºå¤§çš„èƒ½åŠ›ï¼Œå®ƒä»¬åœ¨åŒ»ç–—é¢†åŸŸçš„åº”ç”¨ç”±äºéœ€è¦é«˜åº¦æ³›åŒ–èƒ½åŠ›å’Œä¾èµ–è·¨å­¦ç§‘çŸ¥è¯†è€Œå…·æœ‰ç‰¹æ®Šå‰æ™¯ã€‚ç„¶è€Œï¼Œç°æœ‰çš„åŒ»ç–—ä»£ç†ç³»ç»Ÿé€šå¸¸ä¾èµ–äºé™æ€ã€æ‰‹åŠ¨è®¾è®¡çš„å·¥ä½œæµç¨‹ï¼Œç¼ºä¹é€‚åº”ä¸åŒè¯Šæ–­è¦æ±‚å’Œé€‚åº”æ–°å…´ä¸´åºŠåœºæ™¯çš„çµæ´»æ€§ã€‚å—è‡ªåŠ¨æœºå™¨å­¦ä¹ ï¼ˆAutoMLï¼‰æˆåŠŸçš„å¯å‘ï¼Œæœ¬æ–‡ä»‹ç»äº†ä¸€ç§ç”¨äºè‡ªåŠ¨è®¾è®¡åŒ»ç–—ä»£ç†æ¶æ„çš„æ–°å‹æ¡†æ¶ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬å®šä¹‰äº†ä¸€ä¸ªåˆ†å±‚ä¸”è¡¨è¾¾æ€§å¼ºçš„ä»£ç†æœç´¢ç©ºé—´ï¼Œé€šè¿‡èŠ‚ç‚¹ã€ç»“æ„å’Œæ¡†æ¶å±‚é¢çš„ç»“æ„åŒ–ä¿®æ”¹ï¼Œå®ç°åŠ¨æ€å·¥ä½œæµç¨‹çš„é€‚åº”ã€‚æˆ‘ä»¬çš„æ¡†æ¶å°†åŒ»ç–—ä»£ç†äººæ¦‚å¿µåŒ–ä¸ºåŸºäºå›¾å½¢çš„æ¶æ„ï¼Œç”±å¤šç§åŠŸèƒ½èŠ‚ç‚¹ç±»å‹ç»„æˆï¼Œå¹¶æ”¯æŒé€šè¿‡è¯Šæ–­åé¦ˆæŒ‡å¯¼çš„è¿­ä»£è‡ªæˆ‘æ”¹è¿›ã€‚åœ¨çš®è‚¤ç—…è¯Šæ–­ä»»åŠ¡ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼Œæ‰€æå‡ºçš„æ–¹æ³•æœ‰æ•ˆåœ°è¿›åŒ–äº†å·¥ä½œæµç¨‹ç»“æ„ï¼Œå¹¶éšç€æ—¶é—´çš„æ¨ç§»æ˜¾è‘—æé«˜äº†è¯Šæ–­å‡†ç¡®æ€§ã€‚è¿™é¡¹å·¥ä½œä»£è¡¨äº†åŒ»ç–—ä»£ç†æ¶æ„è®¾è®¡çš„ç¬¬ä¸€ä¸ªå®Œå…¨è‡ªåŠ¨åŒ–çš„æ¡†æ¶ï¼Œä¸ºåœ¨ç°å®ä¸–ç•Œä¸´åºŠç¯å¢ƒä¸­éƒ¨ç½²æ™ºèƒ½ä»£ç†äººæä¾›äº†å¯æ‰©å±•å’Œå¯é€‚åº”çš„åŸºç¡€ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.11301v2">PDF</a> Accepted at ACM MM 2025</p>
<p><strong>æ€»ç»“</strong></p>
<p>åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„ä»£ç†åœ¨å¤šç§ä»»åŠ¡ä¸Šå±•ç°å‡ºå¼ºå¤§çš„èƒ½åŠ›ï¼Œå…¶åœ¨åŒ»ç–—é¢†åŸŸçš„åº”ç”¨å› éœ€æ±‚é«˜æ³›åŒ–èƒ½åŠ›å’Œè·¨å­¦ç§‘çŸ¥è¯†è€Œå…·æœ‰ç‰¹åˆ«å‰æ™¯ã€‚ç„¶è€Œï¼Œç°æœ‰çš„åŒ»ç–—ä»£ç†ç³»ç»Ÿé€šå¸¸ä¾èµ–äºé™æ€ã€æ‰‹åŠ¨æ„å»ºçš„å·¥ä½œæµç¨‹ï¼Œç¼ºä¹é€‚åº”å¤šæ ·è¯Šæ–­éœ€æ±‚å’Œæ–°å…´ä¸´åºŠæƒ…å¢ƒçš„çµæ´»æ€§ã€‚å—è‡ªåŠ¨åŒ–æœºå™¨å­¦ä¹ ï¼ˆAutoMLï¼‰æˆåŠŸçš„å¯å‘ï¼Œæœ¬æ–‡ä»‹ç»äº†ä¸€ç§ç”¨äºåŒ»ç–—ä»£ç†æ¶æ„è‡ªåŠ¨åŒ–è®¾è®¡çš„æ–°å‹æ¡†æ¶ã€‚è¯¥æ¡†æ¶å®šä¹‰äº†å±‚æ¬¡åŒ–å’Œè¡¨è¾¾æ€§çš„ä»£ç†æœç´¢ç©ºé—´ï¼Œé€šè¿‡èŠ‚ç‚¹ã€ç»“æ„å’Œæ¡†æ¶çº§åˆ«çš„ç»“æ„åŒ–ä¿®æ”¹ï¼Œå®ç°åŠ¨æ€å·¥ä½œæµç¨‹é€‚åº”ã€‚è¯¥æ¡†æ¶å°†åŒ»ç–—ä»£ç†æ¦‚å¿µåŒ–ä¸ºåŸºäºå›¾å½¢çš„æ¶æ„ï¼Œç”±å„ç§åŠŸèƒ½èŠ‚ç‚¹ç±»å‹ç»„æˆï¼Œå¹¶å¯é€šè¿‡è¯Šæ–­åé¦ˆè¿›è¡Œè¿­ä»£è‡ªæˆ‘æ”¹è¿›ã€‚åœ¨çš®è‚¤ç–¾ç—…è¯Šæ–­ä»»åŠ¡ä¸Šçš„å®éªŒç»“æœè¯æ˜ï¼Œè¯¥æ–¹æ³•æœ‰æ•ˆåœ°è¿›åŒ–äº†å·¥ä½œæµç¨‹ç»“æ„ï¼Œå¹¶éšæ—¶é—´æ˜¾è‘—æé«˜äº†è¯Šæ–­å‡†ç¡®æ€§ã€‚è¿™é¡¹å·¥ä½œä»£è¡¨äº†åŒ»ç–—ä»£ç†æ¶æ„è®¾è®¡çš„é¦–ä¸ªå®Œå…¨è‡ªåŠ¨åŒ–æ¡†æ¶ï¼Œä¸ºåœ¨çœŸå®ä¸´åºŠç¯å¢ƒä¸­éƒ¨ç½²æ™ºèƒ½ä»£ç†æä¾›äº†å¯æ‰©å±•å’Œå¯é€‚åº”çš„åŸºç¡€ã€‚</p>
<p><strong>å…³é”®è§è§£</strong></p>
<ol>
<li>å¤§å‹è¯­è¨€æ¨¡å‹åœ¨åŒ»ç–—é¢†åŸŸå…·æœ‰å¹¿æ³›åº”ç”¨å‰æ™¯ï¼Œå› å…¶é«˜æ³›åŒ–èƒ½åŠ›å’Œè·¨å­¦ç§‘çŸ¥è¯†éœ€æ±‚ã€‚</li>
<li>ç°æœ‰åŒ»ç–—ä»£ç†ç³»ç»Ÿç¼ºä¹çµæ´»æ€§ï¼Œä¸èƒ½é€‚åº”å¤šæ ·è¯Šæ–­éœ€æ±‚å’Œæ–°å…´ä¸´åºŠæƒ…å¢ƒã€‚</li>
<li>è‡ªåŠ¨åŒ–æœºå™¨å­¦ä¹ åœ¨åŒ»ç–—ä»£ç†è®¾è®¡ä¸­çš„åº”ç”¨æœ‰åŠ©äºæé«˜ä»£ç†çš„çµæ´»æ€§å’Œæ•ˆç‡ã€‚</li>
<li>æå‡ºçš„æ¡†æ¶å®ç°äº†åŒ»ç–—ä»£ç†æ¶æ„çš„è‡ªåŠ¨åŒ–è®¾è®¡ï¼Œé€šè¿‡å±‚æ¬¡åŒ–å’Œè¡¨è¾¾æ€§çš„æœç´¢ç©ºé—´å®ç°åŠ¨æ€å·¥ä½œæµç¨‹é€‚åº”ã€‚</li>
<li>æ¡†æ¶å°†åŒ»ç–—ä»£ç†æ¦‚å¿µåŒ–ä¸ºåŸºäºå›¾å½¢çš„æ¶æ„ï¼Œç”±åŠŸèƒ½èŠ‚ç‚¹ç»„æˆï¼Œæ”¯æŒè¿­ä»£è‡ªæˆ‘æ”¹è¿›ã€‚</li>
<li>åœ¨çš®è‚¤ç–¾ç—…è¯Šæ–­ä»»åŠ¡ä¸Šï¼Œè¯¥æ¡†æ¶æœ‰æ•ˆæé«˜è¯Šæ–­å‡†ç¡®æ€§ã€‚</li>
<li>è¯¥å·¥ä½œä¸ºåœ¨çœŸå®ä¸´åºŠç¯å¢ƒä¸­éƒ¨ç½²æ™ºèƒ½ä»£ç†æä¾›äº†å¯æ‰©å±•å’Œå¯é€‚åº”çš„åŸºç¡€ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.11301">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-15bec03addea5da4c5269e2fdf8cfedf.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-70fcba189f7d9409849e4c0274c50ed5.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-75c70b4bce7523858319d490ab5c2ffe.jpg" align="middle">
</details>


<h1 id="-11"><a href="#-11" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-08-19/Agent/">https://kedreamix.github.io/Talk2Paper/Paper/2025-08-19/Agent/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/Agent/">
                                    <span class="chip bg-color">Agent</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-08-19/Few-Shot/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-0480971fd3e9425b1778d2a6a9c613cb.jpg" class="responsive-img" alt="Few-Shot">
                        
                        <span class="card-title">Few-Shot</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Few-Shot æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-08-19  CoFi A Fast Coarse-to-Fine Few-Shot Pipeline for Glomerular Basement   Membrane Segmentation
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-08-19
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Few-Shot/" class="post-category">
                                    Few-Shot
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Few-Shot/">
                        <span class="chip bg-color">Few-Shot</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-08-19/LLM/">
                    <div class="card-image">
                        
                        <img src="https://pica.zhimg.com/v2-169f8e5805d16b63539c2e6567304608.jpg" class="responsive-img" alt="LLM">
                        
                        <span class="card-title">LLM</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            LLM æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-08-19  Is ChatGPT-5 Ready for Mammogram VQA?
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-08-19
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/LLM/" class="post-category">
                                    LLM
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/LLM/">
                        <span class="chip bg-color">LLM</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">26522.9k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
