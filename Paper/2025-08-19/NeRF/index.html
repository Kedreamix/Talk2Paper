<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="NeRF">
    <meta name="description" content="NeRF 方向最新论文已更新，请持续关注 Update in 2025-08-19  GANDiff FR Hybrid GAN Diffusion Synthesis for Causal Bias Attribution   in Face Recognition">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>NeRF | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loader页面消失采用渐隐的方式*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logo出现动画 */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//使用渐隐的方法淡出loading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//强制显示loading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">嘘~  正在从服务器偷取页面 . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>首页</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>标签</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>分类</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>归档</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="搜索" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="深色/浅色模式" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			首页
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			标签
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			分类
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			归档
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://pic1.zhimg.com/v2-8e4aa5af078a50a81b2fa7a82fb96f0e.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">NeRF</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/NeRF/">
                                <span class="chip bg-color">NeRF</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/NeRF/" class="post-category">
                                NeRF
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2025-08-19
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>更新日期:&nbsp;&nbsp;
                    2025-09-08
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp;
                    5.8k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp;
                    23 分
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>阅读次数:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>⚠️ 以下所有内容总结都来自于 大语言模型的能力，如有错误，仅供参考，谨慎使用<br>🔴 请注意：千万不要用于严肃的学术场景，只能用于论文阅读前的初筛！<br>💗 如果您觉得我们的项目对您有帮助 <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ，还请您给我们一些鼓励！⭐️ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFace免费体验</a></p>
</blockquote>
<h1 id="2025-08-19-更新"><a href="#2025-08-19-更新" class="headerlink" title="2025-08-19 更新"></a>2025-08-19 更新</h1><h2 id="GANDiff-FR-Hybrid-GAN-Diffusion-Synthesis-for-Causal-Bias-Attribution-in-Face-Recognition"><a href="#GANDiff-FR-Hybrid-GAN-Diffusion-Synthesis-for-Causal-Bias-Attribution-in-Face-Recognition" class="headerlink" title="GANDiff FR: Hybrid GAN Diffusion Synthesis for Causal Bias Attribution   in Face Recognition"></a>GANDiff FR: Hybrid GAN Diffusion Synthesis for Causal Bias Attribution   in Face Recognition</h2><p><strong>Authors:Md Asgor Hossain Reaj, Rajan Das Gupta, Md Yeasin Rahat, Nafiz Fahad, Md Jawadul Hasan, Tze Hui Liew</strong></p>
<p>We introduce GANDiff FR, the first synthetic framework that precisely controls demographic and environmental factors to measure, explain, and reduce bias with reproducible rigor. GANDiff FR unifies StyleGAN3-based identity-preserving generation with diffusion-based attribute control, enabling fine-grained manipulation of pose around 30 degrees, illumination (four directions), and expression (five levels) under ceteris paribus conditions. We synthesize 10,000 demographically balanced faces across five cohorts validated for realism via automated detection (98.2%) and human review (89%) to isolate and quantify bias drivers. Benchmarking ArcFace, CosFace, and AdaFace under matched operating points shows AdaFace reduces inter-group TPR disparity by 60% (2.5% vs. 6.3%), with illumination accounting for 42% of residual bias. Cross-dataset evaluation on RFW, BUPT, and CASIA WebFace confirms strong synthetic-to-real transfer (r 0.85). Despite around 20% computational overhead relative to pure GANs, GANDiff FR yields three times more attribute-conditioned variants, establishing a reproducible, regulation-aligned (EU AI Act) standard for fairness auditing. Code and data are released to support transparent, scalable bias evaluation. </p>
<blockquote>
<p>我们介绍了GANDiff FR，这是第一个精确控制人口统计和环境因素的合成框架，以衡量、解释和减少偏见，具有可重复的严谨性。GANDiff FR统一了基于StyleGAN3的身份保留生成与基于扩散的属性控制，能够在保持身份不变的情况下，在ceteris paribus条件下实现30度左右的姿态、四个方向的照明和五个级别的表情的精细操控。我们合成了10000张人口统计上平衡的面孔，跨越五个群体，通过自动化检测（98.2%）和人工审查（89%）验证其真实性，以隔离和量化偏见的驱动因素。在匹配的操作点下，对ArcFace、CosFace和AdaFace进行基准测试显示，AdaFace将组间TPR差异减少了60%（2.5%对比6.3%），照明占剩余偏见的42%。在RFW、BUPT和CASIA WebFace数据集上的跨数据集评估证实了从合成到真实的强大迁移能力（r 0.85）。尽管相对于纯GANs约有20%的计算开销，但GANDiff FR生成了三倍多的属性条件变体，建立了一个可重复、符合法规（欧盟人工智能法案）的公平审计标准。我们公开了代码和数据，以支持透明、可扩展的偏见评估。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.11334v1">PDF</a> Accepted in ICCVDM ‘25</p>
<p><strong>Summary</strong></p>
<p>该研究介绍了一个名为GANDiff FR的合成框架，它能精确控制人口统计和环境因素来测量、解释和减少偏见。该框架结合了StyleGAN3的基于身份保留生成和扩散模型，实现了在固定条件下对姿态、照明和表情的精细控制。通过合成具有现实感的面部图像，验证了框架的有效性，并发现AdaFace能显著降低群体间的TPR差异。该框架为公平审计提供了可复制的、符合法规的标准。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>GANDiff FR是第一个能够精确控制人口统计和环境因素的合成框架，用于测量、解释和减少偏见。</li>
<li>框架结合了StyleGAN3和扩散模型，实现对姿态、照明和表情的精细控制。</li>
<li>合成面部图像通过了自动化检测和人类评审验证，能隔离并量化偏见驱动因素。</li>
<li>AdaFace能有效减少群体间的TPR差异，降低偏见达60%。</li>
<li>照明是剩余偏见的主要来源之一，占42%。</li>
<li>跨数据集评估表明，GANDiff FR具有良好的从合成到现实的迁移能力。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.11334">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-2cab8031aec3d4dacd2c1d8cced48d81.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-784dcd7fd9bce20b5309ea9c2cf98831.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-5af4fb7bd976d74490041bce40e1ddea.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a81ffea240c2856060e3b8408d729662.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-751438e7a4445dafbd253228fc3427e6.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-bba6541386b20815b564bee31bbf442a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a48b94935c089c3c848e6b4fe713e14d.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="A-Survey-on-3D-Gaussian-Splatting-Applications-Segmentation-Editing-and-Generation"><a href="#A-Survey-on-3D-Gaussian-Splatting-Applications-Segmentation-Editing-and-Generation" class="headerlink" title="A Survey on 3D Gaussian Splatting Applications: Segmentation, Editing,   and Generation"></a>A Survey on 3D Gaussian Splatting Applications: Segmentation, Editing,   and Generation</h2><p><strong>Authors:Shuting He, Peilin Ji, Yitong Yang, Changshuo Wang, Jiayi Ji, Yinglin Wang, Henghui Ding</strong></p>
<p>3D Gaussian Splatting (3DGS) has recently emerged as a powerful alternative to Neural Radiance Fields (NeRF) for 3D scene representation, offering high-fidelity photorealistic rendering with real-time performance. Beyond novel view synthesis, the explicit and compact nature of 3DGS enables a wide range of downstream applications that require geometric and semantic understanding. This survey provides a comprehensive overview of recent progress in 3DGS applications. It first introduces 2D foundation models that support semantic understanding and control in 3DGS applications, followed by a review of NeRF-based methods that inform their 3DGS counterparts. We then categorize 3DGS applications into segmentation, editing, generation, and other functional tasks. For each, we summarize representative methods, supervision strategies, and learning paradigms, highlighting shared design principles and emerging trends. Commonly used datasets and evaluation protocols are also summarized, along with comparative analyses of recent methods across public benchmarks. To support ongoing research and development, a continually updated repository of papers, code, and resources is maintained at <a target="_blank" rel="noopener" href="https://github.com/heshuting555/Awesome-3DGS-Applications">https://github.com/heshuting555/Awesome-3DGS-Applications</a>. </p>
<blockquote>
<p>3D高斯贴片（3DGS）作为一种强大的技术，最近作为神经辐射场（NeRF）的替代方案在三维场景表示中崭露头角，它以实时性能提供高保真度照片级渲染。除了新颖视图合成，3DGS的明确和紧凑性质使得它在需要几何和语义理解的一系列下游应用中表现出巨大的潜力。这篇综述全面回顾了近期在3DGS应用方面的进展。首先介绍了支持在3DGS应用中语义理解和控制的二维基础模型，然后回顾了基于NeRF的方法，以启发其对应的3DGS方法。我们将3DGS应用分类为分割、编辑、生成和其他功能任务。对于每一项任务，我们总结了代表性方法、监督策略和学习范式，突出共同的设计原则和新兴趋势。此外还总结了常用的数据集和评估协议，以及在公共基准测试中最近方法的比较分析。为了支持持续的研究和开发，相关论文、代码和资源会不断更新维护在 <a target="_blank" rel="noopener" href="https://github.com/heshuting555/Awesome-3DGS-Applications">https://github.com/heshuting555/Awesome-3DGS-Applications</a> 上。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.09977v1">PDF</a> GitHub Repo:   <a target="_blank" rel="noopener" href="https://github.com/heshuting555/Awesome-3DGS-Applications">https://github.com/heshuting555/Awesome-3DGS-Applications</a></p>
<p><strong>Summary</strong><br>在本文中，对名为3D高斯混编(3DGS)的先进技术在最新进展中的多维度应用进行了全面概述。文章首先介绍了支持三维空间语义理解的二维基础模型，随后回顾了NeRF的方法以供参考其对应的三维模型应用。然后，将重点放在各种基于三维高斯混编的应用上，包括分割、编辑、生成以及其他功能性任务。对每一项应用进行简化方法论介绍的同时，本文也详细描述了相应的监督策略和学习模式。为了支撑持续的研究与开发工作，本文还提供了论文、代码和资源的持续更新仓库链接。</p>
<p><strong>Key Takeaways</strong></p>
<p>以下是本文的关键要点：</p>
<ul>
<li>介绍了新的三维场景表示技术——三维高斯混编（3DGS），它以其强大的表现力和实时性能引起了人们的关注。这种技术可以实现高保真度的逼真渲染效果。</li>
<li>介绍了二维基础模型在三维空间语义理解中的应用，这些模型为三维高斯混编的应用提供了支持。</li>
<li>通过回顾NeRF方法，为理解三维高斯混编提供了参考。这些技术间的比较有助于更好地理解它们的优缺点和适用场景。</li>
<li>详细描述了三维高斯混编在多种应用领域的进展，包括分割、编辑、生成以及其他功能性任务等。这些应用展示了三维高斯混编的多样性和灵活性。文中详细列举了代表性方法和监督策略等。文中也详细介绍了每个应用的监督策略和学习模式。</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.09977">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-2d204af30ec8702ea07e350f310da7b5.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-e6f0a2164690cbd73b271bc90f366993.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="Surg-InvNeRF-Invertible-NeRF-for-3D-tracking-and-reconstruction-in-surgical-vision"><a href="#Surg-InvNeRF-Invertible-NeRF-for-3D-tracking-and-reconstruction-in-surgical-vision" class="headerlink" title="Surg-InvNeRF: Invertible NeRF for 3D tracking and reconstruction in   surgical vision"></a>Surg-InvNeRF: Invertible NeRF for 3D tracking and reconstruction in   surgical vision</h2><p><strong>Authors:Gerardo Loza, Junlei Hu, Dominic Jones, Sharib Ali, Pietro Valdastri</strong></p>
<p>We proposed a novel test-time optimisation (TTO) approach framed by a NeRF-based architecture for long-term 3D point tracking. Most current methods in point tracking struggle to obtain consistent motion or are limited to 2D motion. TTO approaches frame the solution for long-term tracking as optimising a function that aggregates correspondences from other specialised state-of-the-art methods. Unlike the state-of-the-art on TTO, we propose parametrising such a function with our new invertible Neural Radiance Field (InvNeRF) architecture to perform both 2D and 3D tracking in surgical scenarios. Our approach allows us to exploit the advantages of a rendering-based approach by supervising the reprojection of pixel correspondences. It adapts strategies from recent rendering-based methods to obtain a bidirectional deformable-canonical mapping, to efficiently handle a defined workspace, and to guide the rays’ density. It also presents our multi-scale HexPlanes for fast inference and a new algorithm for efficient pixel sampling and convergence criteria. We present results in the STIR and SCARE datasets, for evaluating point tracking and testing the integration of kinematic data in our pipeline, respectively. In 2D point tracking, our approach surpasses the precision and accuracy of the TTO state-of-the-art methods by nearly 50% on average precision, while competing with other approaches. In 3D point tracking, this is the first TTO approach, surpassing feed-forward methods while incorporating the benefits of a deformable NeRF-based reconstruction. </p>
<blockquote>
<p>我们提出了一种新型的基于NeRF架构的测试时优化（TTO）方法，用于长期3D点跟踪。目前大多数点跟踪方法很难获得一致的运动，或者仅限于2D运动。TTO方法将长期跟踪的解决方案定位为优化一个函数，该函数汇聚了来自其他最新专业方法的对应关系。与现有的TTO技术不同，我们提出使用新的可逆神经辐射场（InvNeRF）架构来参数化这样的函数，以在手术场景中进行2D和3D跟踪。我们的方法允许我们利用基于渲染的方法的优势，通过监督像素对应关系的重新投影来实现。它采用最近的基于渲染的方法的策略，获得双向可变形规范映射，以有效处理定义的工作空间并引导射线的密度。它还介绍了我们的用于快速推断的多尺度HexPlanes以及用于高效像素采样和收敛标准的新算法。我们分别在STIR和SCARE数据集上展示了结果，用于评估点跟踪并测试我们管道中运动学数据的集成。在2D点跟踪方面，我们的方法平均精度提高了近50%，超越了TTO最新方法的精度和准确性，同时与其他方法相竞争。在3D点跟踪方面，这是第一个TTO方法，它超越了前馈方法，同时结合了基于可变形NeRF重建的优势。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.09681v1">PDF</a> 10 pages</p>
<p><strong>Summary</strong></p>
<p>本文提出了一种基于NeRF架构的新型测试时间优化（TTO）方法，用于长期3D点跟踪。相较于其他跟踪方法，本文方法能在手术场景中实现2D和3D跟踪，通过参数化函数优化对应点的长期跟踪问题，并借助可逆神经辐射场（InvNeRF）架构实现。该方法利用渲染技术实现像素对应点的监督重投影，并借鉴了最近提出的渲染技术中的策略来获得双向可变形规范映射、高效处理定义的工作空间以及指导射线密度。此外，还引入了多尺度HexPlanes用于快速推理和新的像素采样及收敛标准算法。实验结果表明，本文方法在STIR和SCARE数据集上的2D和3D点跟踪性能均表现优异。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>提出了一种基于NeRF架构的新型测试时间优化（TTO）方法，用于长期3D点跟踪。</li>
<li>利用可逆神经辐射场（InvNeRF）架构实现参数化函数优化，支持2D和3D跟踪在手术场景中的应用。</li>
<li>采用渲染技术实现像素对应点的监督重投影，借鉴渲染技术中的策略获得双向可变形规范映射。</li>
<li>能高效处理定义的工作空间并指导射线密度，引入多尺度HexPlanes用于快速推理。</li>
<li>提出了新的像素采样及收敛标准算法。</li>
<li>在STIR数据集上，本文方法在2D点跟踪方面的精度和准确性超越现有TTO方法近50%。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.09681">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-9ce368eb006962dac39cd1cd110c19de.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b15a19670bdf7774564ecbb23164bac1.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-5265a2e15d6eea33b91274736cce0948.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-2d6896f5d9dd54748d9c0121cc0b915c.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="Casual3DHDR-High-Dynamic-Range-3D-Gaussian-Splatting-from-Casually-Captured-Videos"><a href="#Casual3DHDR-High-Dynamic-Range-3D-Gaussian-Splatting-from-Casually-Captured-Videos" class="headerlink" title="Casual3DHDR: High Dynamic Range 3D Gaussian Splatting from Casually   Captured Videos"></a>Casual3DHDR: High Dynamic Range 3D Gaussian Splatting from Casually   Captured Videos</h2><p><strong>Authors:Shucheng Gong, Lingzhe Zhao, Wenpu Li, Hong Xie, Yin Zhang, Shiyu Zhao, Peidong Liu</strong></p>
<p>Photo-realistic novel view synthesis from multi-view images, such as neural radiance field (NeRF) and 3D Gaussian Splatting (3DGS), has gained significant attention for its superior performance. However, most existing methods rely on low dynamic range (LDR) images, limiting their ability to capture detailed scenes in high-contrast environments. While some prior works address high dynamic range (HDR) scene reconstruction, they typically require multi-view sharp images with varying exposure times captured at fixed camera positions, which is time-consuming and impractical. To make data acquisition more flexible, we propose \textbf{Casual3DHDR}, a robust one-stage method that reconstructs 3D HDR scenes from casually-captured auto-exposure (AE) videos, even under severe motion blur and unknown, varying exposure times. Our approach integrates a continuous camera trajectory into a unified physical imaging model, jointly optimizing exposure times, camera trajectory, and the camera response function (CRF). Extensive experiments on synthetic and real-world datasets demonstrate that \textbf{Casual3DHDR} outperforms existing methods in robustness and rendering quality. Our source code and dataset will be available at <a target="_blank" rel="noopener" href="https://lingzhezhao.github.io/CasualHDRSplat/">https://lingzhezhao.github.io/CasualHDRSplat/</a> </p>
<blockquote>
<p>基于多视角图像的写实性新视角合成，如神经网络辐射场（NeRF）和三维高斯拼贴（3DGS），因其卓越性能而受到广泛关注。然而，大多数现有方法依赖于低动态范围（LDR）图像，限制了它们在高对比度环境中捕捉精细场景的能力。尽管一些早期作品解决了高动态范围（HDR）场景重建问题，但它们通常需要固定相机位置拍摄的多视角清晰图像，且需要不同的曝光时间，这既耗时又不切实际。为了更灵活地获取数据，我们提出了名为“Casual3DHDR”的稳健一步法，可以从随意捕获的自动曝光（AE）视频中重建出HDR场景，即使在严重运动模糊和未知、多变的曝光时间下也能实现。我们的方法将连续的相机轨迹集成到一个统一的物理成像模型中，联合优化曝光时间、相机轨迹和相机响应函数（CRF）。在合成和真实世界数据集上的大量实验表明，“Casual3DHDR”在稳健性和渲染质量方面优于现有方法。我们的源代码和数据集将在<a target="_blank" rel="noopener" href="https://lingzhezhao.github.io/CasualHDRSplat/%E5%BC%80%E6%94%BE%E5%85%B1%E4%BA%AB%E3%80%82">https://lingzhezhao.github.io/CasualHDRSplat/开放共享。</a></p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.17728v2">PDF</a> Published in ACM Multimedia 2025. Project page:   <a target="_blank" rel="noopener" href="https://lingzhezhao.github.io/CasualHDRSplat/">https://lingzhezhao.github.io/CasualHDRSplat/</a> (Previously titled   “CasualHDRSplat: Robust High Dynamic Range 3D Gaussian Splatting from   Casually Captured Videos”)</p>
<p><strong>Summary</strong></p>
<p>该文本介绍了基于神经辐射场（NeRF）和3D高斯贴图（3DGS）技术的多视角图像合成真实感视图的方法。然而，现有方法主要依赖于低动态范围（LDR）图像，难以在高对比度环境中捕捉详细场景。针对这一问题，提出了一种名为Casual3DHDR的稳健一次性方法，可从随意捕获的自动曝光（AE）视频中重建3D HDR场景，甚至在严重运动模糊和未知、变化曝光时间的情况下也可实现。该方法将连续的相机轨迹集成到一个统一的物理成像模型中，联合优化曝光时间、相机轨迹和相机响应函数（CRF）。在合成和真实世界数据集上的广泛实验表明，Casual3DHDR在鲁棒性和渲染质量方面优于现有方法。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>现有基于NeRF和3DGS的多视角图像合成方法主要依赖LDR图像，难以处理高对比度环境。</li>
<li>Casual3DHDR方法能够从随意捕获的AE视频中重建3D HDR场景。</li>
<li>Casual3DHDR方法在严重运动模糊和未知、变化的曝光时间下仍具有稳健性。</li>
<li>该方法将连续的相机轨迹集成到物理成像模型中，并联合优化曝光时间、相机轨迹和CRF。</li>
<li>广泛实验证明Casual3DHDR在鲁棒性和渲染质量方面优于现有方法。</li>
<li>该方法的源代码和数据集将公开可访问。</li>
<li>Casual3DHDR为数据获取提供了更大的灵活性，尤其是在复杂的拍摄环境下。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.17728">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-1f43a2d21e715d72be3f72b487d1e22f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-fa46f4327a0325b05f2a15d45a8d111a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-af240a8d155299044775b22ac9f30a93.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-8051e98ea27320a0fa26c634f7bbad87.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-8bf5ab129892cbee6b7b051e90d197c9.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-54ea4593628d745597d43f098551c054.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="Speedy-Splat-Fast-3D-Gaussian-Splatting-with-Sparse-Pixels-and-Sparse-Primitives"><a href="#Speedy-Splat-Fast-3D-Gaussian-Splatting-with-Sparse-Pixels-and-Sparse-Primitives" class="headerlink" title="Speedy-Splat: Fast 3D Gaussian Splatting with Sparse Pixels and Sparse   Primitives"></a>Speedy-Splat: Fast 3D Gaussian Splatting with Sparse Pixels and Sparse   Primitives</h2><p><strong>Authors:Alex Hanson, Allen Tu, Geng Lin, Vasu Singla, Matthias Zwicker, Tom Goldstein</strong></p>
<p>3D Gaussian Splatting (3D-GS) is a recent 3D scene reconstruction technique that enables real-time rendering of novel views by modeling scenes as parametric point clouds of differentiable 3D Gaussians. However, its rendering speed and model size still present bottlenecks, especially in resource-constrained settings. In this paper, we identify and address two key inefficiencies in 3D-GS to substantially improve rendering speed. These improvements also yield the ancillary benefits of reduced model size and training time. First, we optimize the rendering pipeline to precisely localize Gaussians in the scene, boosting rendering speed without altering visual fidelity. Second, we introduce a novel pruning technique and integrate it into the training pipeline, significantly reducing model size and training time while further raising rendering speed. Our Speedy-Splat approach combines these techniques to accelerate average rendering speed by a drastic $\mathit{6.71\times}$ across scenes from the Mip-NeRF 360, Tanks &amp; Temples, and Deep Blending datasets. </p>
<blockquote>
<p>3D高斯涂抹（3D-GS）是一种最新的3D场景重建技术，它通过将以可微分的高斯形式进行参数化点云建模的场景进行实时渲染，生成新颖的视图。然而，其渲染速度和模型大小仍然存在瓶颈，特别是在资源受限的环境中。在本文中，我们确定了3D-GS中的两个关键低效问题并解决了它们，从而大大提高了渲染速度。这些改进还带来了模型大小和训练时间减少的额外好处。首先，我们优化了渲染流程，精确地将高斯定位在场景中，提高了渲染速度而不影响视觉保真度。其次，我们引入了一种新的修剪技术并将其集成到训练流程中，这大大减少了模型大小和训练时间，并进一步提高了渲染速度。我们的Speedy-Splat方法结合了这些技术，使Mip-NeRF 360、Tanks＆Temples和Deep Blending数据集场景的平均渲染速度提高了惊人的6.71倍。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.00578v3">PDF</a> CVPR 2025, Project Page: <a target="_blank" rel="noopener" href="https://speedysplat.github.io/">https://speedysplat.github.io/</a></p>
<p><strong>Summary</strong></p>
<p>这篇论文针对三维高斯模型（3D-GS）的两个关键瓶颈进行了改进，提升了渲染速度并优化了模型大小和训练时间。通过优化渲染管道并引入新的剪枝技术，论文提出了一种名为Speedy-Splat的方法，显著提高了渲染速度，平均提高了$\mathit{6.71\times}$。这一改进对于资源受限的环境尤为重要。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>论文针对现有技术中的两个关键瓶颈进行了改进，旨在提升渲染速度并优化模型大小和训练时间。</li>
<li>通过优化渲染管道，提高了渲染速度同时保持视觉质量不变。</li>
<li>引入了新的剪枝技术并集成到训练流程中，进一步提高了渲染速度并减少了模型大小和训练时间。</li>
<li>Speedy-Splat方法结合了上述技术，显著提高了渲染速度。</li>
<li>实验结果显示Speedy-Splat方法在Mip-NeRF 360、Tanks &amp; Temples和Deep Blending数据集上的平均渲染速度提高了$\mathit{6.71\times}$。</li>
<li>这些改进对于资源受限的环境特别重要。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.00578">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-b016c6d0d038f79d8168b04288af656d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-8e4aa5af078a50a81b2fa7a82fb96f0e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e0779e7661672a9a13f06c4514c1211c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-48bca12f73986c1407d0764da3620e60.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="Reconstructing-Satellites-in-3D-from-Amateur-Telescope-Images"><a href="#Reconstructing-Satellites-in-3D-from-Amateur-Telescope-Images" class="headerlink" title="Reconstructing Satellites in 3D from Amateur Telescope Images"></a>Reconstructing Satellites in 3D from Amateur Telescope Images</h2><p><strong>Authors:Zhiming Chang, Boyang Liu, Yifei Xia, Youming Guo, Boxin Shi, He Sun</strong></p>
<p>Monitoring space objects is crucial for space situational awareness, yet reconstructing 3D satellite models from ground-based telescope images is challenging due to atmospheric turbulence, long observation distances, limited viewpoints, and low signal-to-noise ratios. In this paper, we propose a novel computational imaging framework that overcomes these obstacles by integrating a hybrid image pre-processing pipeline with a joint pose estimation and 3D reconstruction module based on controlled Gaussian Splatting (GS) and Branch-and-Bound (BnB) search. We validate our approach on both synthetic satellite datasets and on-sky observations of China’s Tiangong Space Station and the International Space Station, achieving robust 3D reconstructions of low-Earth orbit satellites from ground-based data. Quantitative evaluations using SSIM, PSNR, LPIPS, and Chamfer Distance demonstrate that our method outperforms state-of-the-art NeRF-based approaches, and ablation studies confirm the critical role of each component. Our framework enables high-fidelity 3D satellite monitoring from Earth, offering a cost-effective alternative for space situational awareness. Project page: <a target="_blank" rel="noopener" href="https://ai4scientificimaging.org/ReconstructingSatellites">https://ai4scientificimaging.org/ReconstructingSatellites</a> </p>
<blockquote>
<p>对空间目标进行监测对于了解空间态势至关重要，然而从地面望远镜图像重建卫星的三维模型面临许多挑战，如大气湍流、观察距离长、视点有限以及信噪比低等问题。在本文中，我们提出了一种新颖的计算机成像框架，通过结合混合图像预处理管道与基于受控高斯点扩展（GS）和分治（BnB）搜索的联合姿态估计和三维重建模块，克服了这些障碍。我们在合成卫星数据集和中国天宫空间站及国际空间站的实时观测数据上验证了我们的方法，实现了从地面数据对低地球轨道卫星的稳健三维重建。使用结构相似性度量（SSIM）、峰值信噪比（PSNR）、局部感知图像相似性（LPIPS）和Chamfer距离进行的定量评估表明，我们的方法优于最新的基于NeRF的方法，消融研究证实了每个组件的关键作用。我们的框架能够实现从地球的高保真三维卫星监测，为态势感知提供了经济实惠的替代方案。项目页面：<a target="_blank" rel="noopener" href="https://ai4scientificimaging.org/ReconstructingSatellites">https://ai4scientificimaging.org/ReconstructingSatellites</a></p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2404.18394v5">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>该文提出了一种新型的计算成像框架，该框架通过混合图像预处理管道与基于受控高斯溅射（GS）和分支定界（BnB）搜索的联合姿态估计和3D重建模块，克服了从地面望远镜图像重建卫星模型的困难。该框架在合成卫星数据集和中国天宫空间站及国际空间站的实时观测上进行了验证，实现了从地面数据对低地球轨道卫星的稳健3D重建。定量评估表明，该方法优于最新的NeRF技术，并证实了每个组件的关键作用。此框架为从地球进行的高保真3D卫星监测提供了成本效益高的替代方案。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>文中提出了一种新的计算成像框架，旨在从地面望远镜图像重建卫星模型。</li>
<li>该框架集成了混合图像预处理管道和基于受控高斯溅射（GS）与分支定界（BnB）搜索的3D重建模块。</li>
<li>框架在合成卫星数据集和真实卫星观测上进行了验证，展示了对低地球轨道卫星的稳健3D重建能力。</li>
<li>定量评估表明，该框架在性能上超越了现有的NeRF技术。</li>
<li>框架的每个组成部分都经过了严格的测试，证明了其关键作用。</li>
<li>此框架为空间态势感知提供了一种成本效益高的方法，实现了高保真3D卫星监测。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2404.18394">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-9b62f14cc9829fb42b3c0f0f63b2d49f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ff14a3def413dd089c2f5950aba389a6.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-8930004fa7f91273b3dc909aee3c624d.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-6a3cc9e69bc827aa2620018535b4fdb0.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-018982e6735d7f300c3030b152fd3bd3.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        文章作者:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        文章链接:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-08-19/NeRF/">https://kedreamix.github.io/Talk2Paper/Paper/2025-08-19/NeRF/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        版权声明:
                    </i>
                </span>
                <span class="reprint-info">
                    本博客所有文章除特別声明外，均采用
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    许可协议。转载请注明来源
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/NeRF/">
                                    <span class="chip bg-color">NeRF</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;上一篇</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-08-19/Diffusion%20Models/">
                    <div class="card-image">
                        
                        <img src="https://pic1.zhimg.com/v2-4d431081396646a66cd4c1d9560e98ef.jpg" class="responsive-img" alt="Diffusion Models">
                        
                        <span class="card-title">Diffusion Models</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Diffusion Models 方向最新论文已更新，请持续关注 Update in 2025-08-19  LoRAtorio An intrinsic approach to LoRA Skill Composition
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-08-19
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Diffusion-Models/" class="post-category">
                                    Diffusion Models
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Diffusion-Models/">
                        <span class="chip bg-color">Diffusion Models</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-08-19/3DGS/">
                    <div class="card-image">
                        
                        <img src="https://pic1.zhimg.com/v2-3de6c8c965bd3d17eabb4ec183fc9373.jpg" class="responsive-img" alt="3DGS">
                        
                        <span class="card-title">3DGS</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            3DGS 方向最新论文已更新，请持续关注 Update in 2025-08-19  Remove360 Benchmarking Residuals After Object Removal in 3D Gaussian   Splatting
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-08-19
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/3DGS/" class="post-category">
                                    3DGS
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/3DGS/">
                        <span class="chip bg-color">3DGS</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- 代码语言 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span
                        class="white-color">30191.9k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- 运行天数提醒. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // 区分是否有年份.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = '本站已运行 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                daysTip = '本站已運行 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = '本站已运行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = '本站已運行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="关注我的知乎: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">知</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- 白天和黑夜主题 -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // 只在桌面版网页启用特效
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- 雪花特效 -->
    

    <!-- 鼠标星星特效 -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--腾讯兔小巢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- 动态标签 -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Σ(っ °Д °;)っ诶，页面崩溃了嘛？", clearTimeout(st)) : (document.title = "φ(゜▽゜*)♪咦，又好了！", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
