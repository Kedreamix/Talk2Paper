<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="3DGS">
    <meta name="description" content="3DGS æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-08-08  Pseudo Depth Meets Gaussian A Feed-forward RGB SLAM Baseline">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>3DGS | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://picx.zhimg.com/v2-9f6783b7143ec4f25063d879b7cabcc9.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">3DGS</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/3DGS/">
                                <span class="chip bg-color">3DGS</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/3DGS/" class="post-category">
                                3DGS
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-08-08
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-08-20
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    18.8k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    76 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-08-08-æ›´æ–°"><a href="#2025-08-08-æ›´æ–°" class="headerlink" title="2025-08-08 æ›´æ–°"></a>2025-08-08 æ›´æ–°</h1><h2 id="Pseudo-Depth-Meets-Gaussian-A-Feed-forward-RGB-SLAM-Baseline"><a href="#Pseudo-Depth-Meets-Gaussian-A-Feed-forward-RGB-SLAM-Baseline" class="headerlink" title="Pseudo Depth Meets Gaussian: A Feed-forward RGB SLAM Baseline"></a>Pseudo Depth Meets Gaussian: A Feed-forward RGB SLAM Baseline</h2><p><strong>Authors:Linqing Zhao, Xiuwei Xu, Yirui Wang, Hao Wang, Wenzhao Zheng, Yansong Tang, Haibin Yan, Jiwen Lu</strong></p>
<p>Incrementally recovering real-sized 3D geometry from a pose-free RGB stream is a challenging task in 3D reconstruction, requiring minimal assumptions on input data. Existing methods can be broadly categorized into end-to-end and visual SLAM-based approaches, both of which either struggle with long sequences or depend on slow test-time optimization and depth sensors. To address this, we first integrate a depth estimator into an RGB-D SLAM system, but this approach is hindered by inaccurate geometric details in predicted depth. Through further investigation, we find that 3D Gaussian mapping can effectively solve this problem. Building on this, we propose an online 3D reconstruction method using 3D Gaussian-based SLAM, combined with a feed-forward recurrent prediction module to directly infer camera pose from optical flow. This approach replaces slow test-time optimization with fast network inference, significantly improving tracking speed. Additionally, we introduce a local graph rendering technique to enhance robustness in feed-forward pose prediction. Experimental results on the Replica and TUM-RGBD datasets, along with a real-world deployment demonstration, show that our method achieves performance on par with the state-of-the-art SplaTAM, while reducing tracking time by more than 90%. </p>
<blockquote>
<p>ä»æ— éœ€å§¿æ€è®¾å®šçš„RGBæµä¸­é€æ­¥é‡å»ºçœŸå®å°ºå¯¸çš„3Då‡ ä½•ç»“æ„æ˜¯3Dé‡å»ºä¸­çš„ä¸€é¡¹å…·æœ‰æŒ‘æˆ˜æ€§çš„ä»»åŠ¡ï¼Œå®ƒå¯¹è¾“å…¥æ•°æ®çš„è¦æ±‚å°½å¯èƒ½å°‘ã€‚ç°æœ‰æ–¹æ³•å¤§è‡´å¯åˆ†ä¸ºç«¯åˆ°ç«¯æ–¹æ³•å’ŒåŸºäºè§†è§‰çš„SLAMæ–¹æ³•ï¼Œä½†å®ƒä»¬åœ¨å¤„ç†é•¿åºåˆ—æ—¶é‡åˆ°æŒ‘æˆ˜æˆ–ä¾èµ–äºç¼“æ…¢çš„æµ‹è¯•æ—¶é—´ä¼˜åŒ–å’Œæ·±åº¦ä¼ æ„Ÿå™¨ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬é¦–å…ˆå°†æ·±åº¦ä¼°è®¡å™¨é›†æˆåˆ°RGB-D SLAMç³»ç»Ÿä¸­ï¼Œä½†è¿™ç§æ–¹æ³•å—åˆ°é¢„æµ‹æ·±åº¦ä¸­å‡ ä½•ç»†èŠ‚ä¸å‡†ç¡®çš„å½±å“ã€‚é€šè¿‡è¿›ä¸€æ­¥çš„è°ƒæŸ¥ï¼Œæˆ‘ä»¬å‘ç°3Dé«˜æ–¯æ˜ å°„å¯ä»¥æœ‰æ•ˆåœ°è§£å†³è¿™ä¸ªé—®é¢˜ã€‚åœ¨æ­¤åŸºç¡€ä¸Šï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åŸºäºåœ¨çº¿çš„3Dé‡å»ºæ–¹æ³•ï¼Œä½¿ç”¨åŸºäº3Dé«˜æ–¯SLAMæŠ€æœ¯ï¼Œå¹¶ç»“åˆå‰é¦ˆé€’å½’é¢„æµ‹æ¨¡å—ç›´æ¥ä»å…‰æµæ¨æ–­ç›¸æœºå§¿æ€ã€‚è¿™ç§æ–¹æ³•ç”¨å¿«é€Ÿç½‘ç»œæ¨ç†å–ä»£äº†ç¼“æ…¢çš„æµ‹è¯•æ—¶é—´ä¼˜åŒ–ï¼Œå¤§å¤§æé«˜äº†è·Ÿè¸ªé€Ÿåº¦ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜å¼•å…¥äº†ä¸€ç§å±€éƒ¨å›¾å½¢æ¸²æŸ“æŠ€æœ¯ï¼Œä»¥æé«˜å‰é¦ˆå§¿æ€é¢„æµ‹çš„é²æ£’æ€§ã€‚åœ¨Replicaå’ŒTUM-RGBDæ•°æ®é›†ä¸Šçš„å®éªŒç»“æœä»¥åŠçœŸå®ä¸–ç•Œçš„éƒ¨ç½²æ¼”ç¤ºè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•ä¸æœ€å…ˆè¿›çš„SplaTAMæ€§èƒ½ç›¸å½“ï¼ŒåŒæ—¶è·Ÿè¸ªæ—¶é—´å‡å°‘äº†è¶…è¿‡90%ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.04597v1">PDF</a> IROS 2025</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºä¸€ç§åŸºäºåœ¨çº¿çš„3Dé‡å»ºæ–¹æ³•ï¼Œé€šè¿‡æ•´åˆæ·±åº¦ä¼°è®¡å™¨ä¸RGB-D SLAMç³»ç»Ÿï¼Œå¹¶é‡‡ç”¨3Dé«˜æ–¯æ˜ å°„è§£å†³é¢„æµ‹æ·±åº¦ä¸­çš„å‡ ä½•ç»†èŠ‚ä¸å‡†ç¡®é—®é¢˜ã€‚è¯¥æ–¹æ³•å¼•å…¥å‰é¦ˆå¾ªç¯é¢„æµ‹æ¨¡å—ï¼Œç›´æ¥ä»å…‰æµæ¨æ–­ç›¸æœºå§¿æ€ï¼Œæé«˜äº†è·Ÿè¸ªé€Ÿåº¦ã€‚åŒæ—¶ï¼Œé‡‡ç”¨å±€éƒ¨å›¾æ¸²æŸ“æŠ€æœ¯å¢å¼ºå§¿æ€é¢„æµ‹çš„é²æ£’æ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨Replicaå’ŒTUM-RGBDæ•°æ®é›†ä¸Šçš„æ€§èƒ½ä¸æœ€æ–°æŠ€æœ¯SplaTAMç›¸å½“ï¼Œä½†è·Ÿè¸ªæ—¶é—´ç¼©çŸ­äº†è¶…è¿‡90%ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æå‡ºä¸€ç§åœ¨çº¿çš„3Dé‡å»ºæ–¹æ³•ï¼Œæ—¨åœ¨ä»RGBæµä¸­æ¢å¤çœŸå®å°ºå¯¸çš„3Då‡ ä½•ç»“æ„ã€‚</li>
<li>é‡‡ç”¨æ·±åº¦ä¼°è®¡å™¨ä¸RGB-D SLAMç³»ç»Ÿæ•´åˆï¼Œè§£å†³è¾“å…¥æ•°æ®çš„æœ€å°å‡è®¾é—®é¢˜ã€‚</li>
<li>å‘ç°é¢„æµ‹æ·±åº¦ä¸­çš„å‡ ä½•ç»†èŠ‚ä¸å‡†ç¡®çš„é—®é¢˜ï¼Œå¹¶æå‡ºé€šè¿‡3Dé«˜æ–¯æ˜ å°„è§£å†³è¯¥é—®é¢˜ã€‚</li>
<li>å¼•å…¥å‰é¦ˆå¾ªç¯é¢„æµ‹æ¨¡å—ï¼Œç›´æ¥ä»å…‰æµæ¨æ–­ç›¸æœºå§¿æ€ï¼Œæé«˜è·Ÿè¸ªé€Ÿåº¦ã€‚</li>
<li>é‡‡ç”¨å±€éƒ¨å›¾æ¸²æŸ“æŠ€æœ¯ï¼Œå¢å¼ºå§¿æ€é¢„æµ‹çš„é²æ£’æ€§ã€‚</li>
<li>åœ¨Replicaå’ŒTUM-RGBDæ•°æ®é›†ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•æ€§èƒ½ä¸æœ€æ–°æŠ€æœ¯ç›¸å½“ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.04597">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-e56f83d0b3140deeb3fc16ad9cdef361.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-9270c52c8ef96d19d72209c6b509ae06.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-1e2707edb3172e90b39cd84723d73e9a.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-af0839d01d6eef8d2c3cbbdb227bbd18.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e7db8d50d88975778bb899b547e11dc0.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="Surf3R-Rapid-Surface-Reconstruction-from-Sparse-RGB-Views-in-Seconds"><a href="#Surf3R-Rapid-Surface-Reconstruction-from-Sparse-RGB-Views-in-Seconds" class="headerlink" title="Surf3R: Rapid Surface Reconstruction from Sparse RGB Views in Seconds"></a>Surf3R: Rapid Surface Reconstruction from Sparse RGB Views in Seconds</h2><p><strong>Authors:Haodong Zhu, Changbai Li, Yangyang Ren, Zichao Feng, Xuhui Liu, Hanlin Chen, Xiantong Zhen, Baochang Zhang</strong></p>
<p>Current multi-view 3D reconstruction methods rely on accurate camera calibration and pose estimation, requiring complex and time-intensive pre-processing that hinders their practical deployment. To address this challenge, we introduce Surf3R, an end-to-end feedforward approach that reconstructs 3D surfaces from sparse views without estimating camera poses and completes an entire scene in under 10 seconds. Our method employs a multi-branch and multi-view decoding architecture in which multiple reference views jointly guide the reconstruction process. Through the proposed branch-wise processing, cross-view attention, and inter-branch fusion, the model effectively captures complementary geometric cues without requiring camera calibration. Moreover, we introduce a D-Normal regularizer based on an explicit 3D Gaussian representation for surface reconstruction. It couples surface normals with other geometric parameters to jointly optimize the 3D geometry, significantly improving 3D consistency and surface detail accuracy. Experimental results demonstrate that Surf3R achieves state-of-the-art performance on multiple surface reconstruction metrics on ScanNet++ and Replica datasets, exhibiting excellent generalization and efficiency. </p>
<blockquote>
<p>å½“å‰çš„å¤šè§†è§’3Dé‡å»ºæ–¹æ³•ä¾èµ–äºå‡†ç¡®çš„ç›¸æœºæ ¡å‡†å’Œå§¿æ€ä¼°è®¡ï¼Œéœ€è¦å¤æ‚ä¸”è€—æ—¶çš„é¢„å¤„ç†ï¼Œé˜»ç¢äº†å…¶å®é™…éƒ¨ç½²ã€‚ä¸ºäº†åº”å¯¹è¿™ä¸€æŒ‘æˆ˜ï¼Œæˆ‘ä»¬å¼•å…¥äº†Surf3Rï¼Œè¿™æ˜¯ä¸€ç§ç«¯åˆ°ç«¯çš„å‰é¦ˆæ–¹æ³•ï¼Œå¯ä»¥ä»ç¨€ç–è§†è§’é‡å»º3Dè¡¨é¢ï¼Œæ— éœ€ä¼°è®¡ç›¸æœºå§¿æ€ï¼Œå¹¶åœ¨ä¸åˆ°10ç§’å†…å®Œæˆæ•´ä¸ªåœºæ™¯çš„é‡å»ºã€‚æˆ‘ä»¬çš„æ–¹æ³•é‡‡ç”¨å¤šåˆ†æ”¯å¤šè§†è§’è§£ç æ¶æ„ï¼Œå¤šä¸ªå‚è€ƒè§†è§’å…±åŒå¼•å¯¼é‡å»ºè¿‡ç¨‹ã€‚é€šè¿‡æå‡ºçš„åˆ†æ”¯å¤„ç†ã€è·¨è§†è§’æ³¨æ„åŠ›å’Œè·¨åˆ†æ”¯èåˆï¼Œæ¨¡å‹æœ‰æ•ˆåœ°æ•æ‰äº†äº’è¡¥çš„å‡ ä½•çº¿ç´¢ï¼Œæ— éœ€ç›¸æœºæ ¡å‡†ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬åŸºäºæ˜ç¡®çš„3Dé«˜æ–¯è¡¨ç¤ºå¼•å…¥äº†ä¸€ç§D-Normalæ­£åˆ™åŒ–æ–¹æ³•ï¼Œç”¨äºè¡¨é¢é‡å»ºã€‚å®ƒå°†è¡¨é¢æ³•çº¿ä¸å…¶å®ƒå‡ ä½•å‚æ•°ç›¸ç»“åˆï¼Œä»¥å…±åŒä¼˜åŒ–3Då‡ ä½•å½¢çŠ¶ï¼Œå¤§å¤§æé«˜äº†3Dä¸€è‡´æ€§å’Œè¡¨é¢ç»†èŠ‚ç²¾åº¦ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒSurf3Råœ¨ScanNet++å’ŒReplicaæ•°æ®é›†ä¸Šçš„å¤šä¸ªè¡¨é¢é‡å»ºæŒ‡æ ‡ä¸Šè¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œè¡¨ç°å‡ºä¼˜å¼‚çš„é€šç”¨æ€§å’Œæ•ˆç‡ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.04508v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºä¸€ç§åä¸ºSurf3Rçš„ç«¯åˆ°ç«¯å‰é¦ˆæ–¹æ³•ï¼Œç”¨äºä»ç¨€ç–è§†è§’é‡å»º3Dè¡¨é¢ã€‚è¯¥æ–¹æ³•æ— éœ€ä¼°è®¡ç›¸æœºå§¿æ€ï¼Œå³å¯åœ¨å¤šåœºæ™¯ä¸‹å¿«é€Ÿå®Œæˆé‡å»ºè¿‡ç¨‹ï¼Œä¸”æ•´ä¸ªè¿‡ç¨‹ä»…éœ€ä¸åˆ°åç§’ã€‚é€šè¿‡é‡‡ç”¨å¤šåˆ†æ”¯å¤šè§†è§’è§£ç æ¶æ„ï¼Œç»“åˆåˆ†æ”¯å¤„ç†ã€è·¨è§†è§’æ³¨æ„åŠ›æœºåˆ¶å’Œåˆ†æ”¯é—´èåˆç­‰æŠ€æœ¯ï¼Œæ¨¡å‹èƒ½æœ‰æ•ˆæ•æ‰å‡ ä½•ä¿¡æ¯ã€‚åŒæ—¶å¼•å…¥åŸºäºæ˜¾å¼ä¸‰ç»´é«˜æ–¯è¡¨ç¤ºçš„D-Normalæ­£åˆ™åŒ–æ–¹æ³•ç”¨äºè¡¨é¢é‡å»ºï¼Œæé«˜é‡å»ºæ•ˆæœçš„å‡†ç¡®æ€§ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒSurf3Råœ¨å¤šä¸ªæ•°æ®é›†ä¸Šçš„è¡¨é¢é‡å»ºæ•ˆæœè¾¾åˆ°ä¸šç•Œé¢†å…ˆæ°´å¹³ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>Surf3Ræ˜¯ä¸€ç§ç«¯åˆ°ç«¯çš„3Dé‡å»ºæ–¹æ³•ï¼Œæ— éœ€å¤æ‚çš„é¢„å¤„ç†å’Œç›¸æœºæ ¡å‡†ã€‚</li>
<li>è¯¥æ–¹æ³•èƒ½å¤Ÿä»ç¨€ç–è§†è§’å¿«é€Ÿé‡å»º3Dè¡¨é¢ï¼Œæ•´ä¸ªæµç¨‹åœ¨10ç§’å†…å®Œæˆã€‚</li>
<li>å¤šåˆ†æ”¯å¤šè§†è§’è§£ç æ¶æ„ç”¨äºæ•æ‰å‡ ä½•ä¿¡æ¯ï¼Œæé«˜é‡å»ºå‡†ç¡®æ€§ã€‚</li>
<li>å¼•å…¥D-Normalæ­£åˆ™åŒ–æ–¹æ³•ï¼ŒåŸºäºæ˜¾å¼ä¸‰ç»´é«˜æ–¯è¡¨ç¤ºï¼Œæé«˜è¡¨é¢é‡å»ºçš„3Dä¸€è‡´æ€§å’Œè¡¨é¢ç»†èŠ‚ç²¾åº¦ã€‚</li>
<li>å®éªŒç»“æœæ˜¾ç¤ºï¼ŒSurf3Råœ¨å¤šä¸ªæ•°æ®é›†ä¸Šçš„è¡¨é¢é‡å»ºæ•ˆæœè¾¾åˆ°ä¸šç•Œé¢†å…ˆæ°´å¹³ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.04508">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-f68d5be4e4e3ec70a77db3a029853960.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-1dbe4ad3f25574bac1b9883d07ea4e85.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-2225382d7f9c0a1ebdee487d187e7692.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-8b4777c3cd315c99c72056c98af9edc2.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="MuGS-Multi-Baseline-Generalizable-Gaussian-Splatting-Reconstruction"><a href="#MuGS-Multi-Baseline-Generalizable-Gaussian-Splatting-Reconstruction" class="headerlink" title="MuGS: Multi-Baseline Generalizable Gaussian Splatting Reconstruction"></a>MuGS: Multi-Baseline Generalizable Gaussian Splatting Reconstruction</h2><p><strong>Authors:Yaopeng Lou, Liao Shen, Tianqi Liu, Jiaqi Li, Zihao Huang, Huiqiang Sun, Zhiguo Cao</strong></p>
<p>We present Multi-Baseline Gaussian Splatting (MuRF), a generalized feed-forward approach for novel view synthesis that effectively handles diverse baseline settings, including sparse input views with both small and large baselines. Specifically, we integrate features from Multi-View Stereo (MVS) and Monocular Depth Estimation (MDE) to enhance feature representations for generalizable reconstruction. Next, We propose a projection-and-sampling mechanism for deep depth fusion, which constructs a fine probability volume to guide the regression of the feature map. Furthermore, We introduce a reference-view loss to improve geometry and optimization efficiency. We leverage 3D Gaussian representations to accelerate training and inference time while enhancing rendering quality. MuRF achieves state-of-the-art performance across multiple baseline settings and diverse scenarios ranging from simple objects (DTU) to complex indoor and outdoor scenes (RealEstate10K). We also demonstrate promising zero-shot performance on the LLFF and Mip-NeRF 360 datasets. </p>
<blockquote>
<p>æˆ‘ä»¬æå‡ºäº†å¤šåŸºçº¿é«˜æ–¯å±•ç‰‡ï¼ˆMuRFï¼‰ï¼Œè¿™æ˜¯ä¸€ç§ç”¨äºæ–°å‹è§†è§’åˆæˆçš„é€šç”¨å‰é¦ˆæ–¹æ³•ï¼Œèƒ½å¤Ÿæœ‰æ•ˆåœ°å¤„ç†åŒ…æ‹¬ç¨€ç–è¾“å…¥è§†è§’ã€å°åŸºçº¿å’Œå¤§åŸºçº¿åœ¨å†…çš„å¤šç§åŸºçº¿è®¾ç½®ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬æ•´åˆäº†å¤šè§†è§’ç«‹ä½“ï¼ˆMVSï¼‰å’Œå•çœ¼æ·±åº¦ä¼°è®¡ï¼ˆMDEï¼‰çš„ç‰¹å¾ï¼Œä»¥å¢å¼ºå¯æ¦‚æ‹¬é‡å»ºçš„ç‰¹å¾è¡¨ç¤ºã€‚æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§ç”¨äºæ·±åº¦æ·±åº¦èåˆçš„æŠ•å½±å’Œé‡‡æ ·æœºåˆ¶ï¼Œå®ƒæ„å»ºäº†ä¸€ä¸ªç²¾ç»†çš„æ¦‚ç‡ä½“ç§¯æ¥æŒ‡å¯¼ç‰¹å¾å›¾çš„å›å½’ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ä¸ªå‚è€ƒè§†å›¾æŸå¤±æ¥æé«˜å‡ ä½•å’Œä¼˜åŒ–æ•ˆç‡ã€‚æˆ‘ä»¬åˆ©ç”¨3Dé«˜æ–¯è¡¨ç¤ºæ¥åŠ é€Ÿè®­ç»ƒå’Œæ¨ç†æ—¶é—´ï¼ŒåŒæ—¶æé«˜æ¸²æŸ“è´¨é‡ã€‚MuRFåœ¨å¤šç§åŸºçº¿è®¾ç½®å’Œä»ç®€å•å¯¹è±¡ï¼ˆDTUï¼‰åˆ°å¤æ‚å®¤å†…å’Œå®¤å¤–åœºæ™¯ï¼ˆRealEstate10Kï¼‰çš„å¤šç§åœºæ™¯ä¸­å®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚æˆ‘ä»¬åœ¨LLFFå’ŒMip-NeRF 360æ•°æ®é›†ä¸Šå±•ç¤ºäº†æœ‰å‰æ™¯çš„é›¶æ ·æœ¬æ€§èƒ½ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.04297v1">PDF</a> This work is accepted by ICCV 2025</p>
<p><strong>Summary</strong></p>
<p>Multi-Baseline Gaussian Splattingï¼ˆMuRFï¼‰æ˜¯ä¸€ç§ç”¨äºæ–°å‹è§†è§’åˆæˆçš„é€šç”¨å‰é¦ˆæ–¹æ³•ï¼Œèƒ½æœ‰æ•ˆå¤„ç†åŒ…æ‹¬ç¨€ç–è¾“å…¥è§†è§’ã€å°åŸºçº¿å’Œå¤§åŸºçº¿ç­‰ä¸åŒçš„åŸºçº¿è®¾ç½®ã€‚é€šè¿‡æ•´åˆå¤šè§†è§’ç«‹ä½“ï¼ˆMVSï¼‰å’Œå•çœ¼æ·±åº¦ä¼°è®¡ï¼ˆMDEï¼‰çš„ç‰¹æ€§ï¼Œæå‡ç‰¹å¾è¡¨è¾¾ï¼Œå®ç°å¯æ¦‚æ‹¬çš„é‡æ„ã€‚æå‡ºæ·±åº¦èåˆæŠ•å½±é‡‡æ ·æœºåˆ¶ï¼Œæ„å»ºç²¾ç»†æ¦‚ç‡ä½“ç§¯å¼•å¯¼ç‰¹å¾å›¾çš„å›å½’ã€‚å¼•å…¥å‚è€ƒè§†è§’æŸå¤±ï¼Œæå‡å‡ ä½•å’Œä¼˜åŒ–æ•ˆç‡ã€‚åˆ©ç”¨ä¸‰ç»´é«˜æ–¯è¡¨ç¤ºåŠ é€Ÿè®­ç»ƒå’Œæ¨ç†æ—¶é—´ï¼ŒåŒæ—¶æé«˜æ¸²æŸ“è´¨é‡ã€‚MuRFåœ¨å¤šç§åŸºçº¿è®¾ç½®å’Œä»ç®€å•ç‰©ä½“ï¼ˆDTUï¼‰åˆ°å¤æ‚å®¤å†…å®¤å¤–åœºæ™¯ï¼ˆRealEstate10Kï¼‰ä¸­è¡¨ç°æœ€ä½³ï¼Œå¹¶åœ¨LLFFå’ŒMip-NeRF 360æ•°æ®é›†ä¸Šå±•ç°å‡ºé›¶æ ·æœ¬æ€§èƒ½æ½œåŠ›ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>MuRFæ˜¯ä¸€ç§æ–°å‹è§†è§’åˆæˆçš„é€šç”¨å‰é¦ˆæ–¹æ³•ï¼Œé€‚ç”¨äºå¤šç§åŸºçº¿è®¾ç½®ã€‚</li>
<li>ç»“åˆå¤šè§†è§’ç«‹ä½“ï¼ˆMVSï¼‰å’Œå•çœ¼æ·±åº¦ä¼°è®¡ï¼ˆMDEï¼‰æå‡ç‰¹å¾è¡¨è¾¾ã€‚</li>
<li>æå‡ºæ·±åº¦èåˆæŠ•å½±é‡‡æ ·æœºåˆ¶ï¼Œæ„å»ºç²¾ç»†æ¦‚ç‡ä½“ç§¯å¼•å¯¼ç‰¹å¾å›å½’ã€‚</li>
<li>å¼•å…¥å‚è€ƒè§†è§’æŸå¤±ä»¥æå‡å‡ ä½•å’Œä¼˜åŒ–çš„æ•ˆç‡ã€‚</li>
<li>é‡‡ç”¨ä¸‰ç»´é«˜æ–¯è¡¨ç¤ºåŠ é€Ÿè®­ç»ƒä¸æ¨ç†è¿‡ç¨‹ï¼ŒåŒæ—¶æé«˜æ¸²æŸ“è´¨é‡ã€‚</li>
<li>MuRFåœ¨å¤šç§åœºæ™¯å’Œä¸åŒçš„åŸºçº¿è®¾ç½®ä¸‹è¡¨ç°æœ€ä½³ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.04297">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-6fb780814dde9d24d6a64d507567427f.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-b9735e16b71d856246759368983a4741.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b7de7e296fc51da47c17621dc4901829.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="SplitGaussian-Reconstructing-Dynamic-Scenes-via-Visual-Geometry-Decomposition"><a href="#SplitGaussian-Reconstructing-Dynamic-Scenes-via-Visual-Geometry-Decomposition" class="headerlink" title="SplitGaussian: Reconstructing Dynamic Scenes via Visual Geometry   Decomposition"></a>SplitGaussian: Reconstructing Dynamic Scenes via Visual Geometry   Decomposition</h2><p><strong>Authors:Jiahui Li, Shengeng Tang, Jingxuan He, Gang Huang, Zhangye Wang, Yantao Pan, Lechao Cheng</strong></p>
<p>Reconstructing dynamic 3D scenes from monocular video remains fundamentally challenging due to the need to jointly infer motion, structure, and appearance from limited observations. Existing dynamic scene reconstruction methods based on Gaussian Splatting often entangle static and dynamic elements in a shared representation, leading to motion leakage, geometric distortions, and temporal flickering. We identify that the root cause lies in the coupled modeling of geometry and appearance across time, which hampers both stability and interpretability. To address this, we propose \textbf{SplitGaussian}, a novel framework that explicitly decomposes scene representations into static and dynamic components. By decoupling motion modeling from background geometry and allowing only the dynamic branch to deform over time, our method prevents motion artifacts in static regions while supporting view- and time-dependent appearance refinement. This disentangled design not only enhances temporal consistency and reconstruction fidelity but also accelerates convergence. Extensive experiments demonstrate that SplitGaussian outperforms prior state-of-the-art methods in rendering quality, geometric stability, and motion separation. </p>
<blockquote>
<p>ä»å•ç›®è§†é¢‘ä¸­é‡å»ºåŠ¨æ€3Dåœºæ™¯ä»ç„¶å…·æœ‰æ ¹æœ¬çš„æŒ‘æˆ˜æ€§ï¼Œå› ä¸ºéœ€è¦ä»æœ‰é™çš„è§‚å¯Ÿç»“æœä¸­è”åˆæ¨æ–­è¿åŠ¨ã€ç»“æ„å’Œå¤–è§‚ã€‚åŸºäºé«˜æ–¯æ¶‚æŠ¹çš„ç°æœ‰åŠ¨æ€åœºæ™¯é‡å»ºæ–¹æ³•é€šå¸¸ä¼šå°†é™æ€å’ŒåŠ¨æ€å…ƒç´ çº ç¼ åœ¨å…±äº«è¡¨ç¤ºä¸­ï¼Œå¯¼è‡´è¿åŠ¨æ³„éœ²ã€å‡ ä½•å¤±çœŸå’Œæš‚æ—¶é—ªçƒã€‚æˆ‘ä»¬å‘ç°æ ¹æœ¬åŸå› å°±åœ¨äºå‡ ä½•å’Œå¤–è§‚åœ¨æ—¶é—´ä¸Šçš„è€¦åˆå»ºæ¨¡ï¼Œè¿™é˜»ç¢äº†ç¨³å®šæ€§å’Œå¯è§£é‡Šæ€§ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†SplitGaussianè¿™ä¸€æ–°å‹æ¡†æ¶ï¼Œå®ƒå°†åœºæ™¯è¡¨ç¤ºæ˜¾å¼åœ°åˆ†è§£ä¸ºé™æ€å’ŒåŠ¨æ€æˆåˆ†ã€‚é€šè¿‡å°†è¿åŠ¨å»ºæ¨¡ä¸èƒŒæ™¯å‡ ä½•åˆ†ç¦»ï¼Œå¹¶ä»…å…è®¸åŠ¨æ€åˆ†æ”¯éšæ—¶é—´å˜å½¢ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨é™æ€åŒºåŸŸé˜²æ­¢äº†è¿åŠ¨ä¼ªå½±ï¼ŒåŒæ—¶æ”¯æŒè§†å›¾å’Œéšæ—¶é—´å˜åŒ–çš„å¤–è§‚ç»†åŒ–ã€‚è¿™ç§è§£è€¦è®¾è®¡ä¸ä»…æé«˜äº†æ—¶é—´ä¸€è‡´æ€§å’Œé‡å»ºä¿çœŸåº¦ï¼Œè¿˜åŠ é€Ÿäº†æ”¶æ•›ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼ŒSplitGaussianåœ¨æ¸²æŸ“è´¨é‡ã€å‡ ä½•ç¨³å®šæ€§å’Œè¿åŠ¨åˆ†ç¦»æ–¹é¢å‡ä¼˜äºç°æœ‰æœ€å…ˆè¿›çš„æ–¹æ³•ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.04224v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æŒ‡å‡ºä»å•ç›®è§†é¢‘ä¸­é‡å»ºåŠ¨æ€3Dåœºæ™¯å…·æœ‰æŒ‘æˆ˜æ€§ï¼Œå› ä¸ºéœ€è¦ä»æœ‰é™çš„è§‚å¯Ÿä¸­è”åˆæ¨æ–­è¿åŠ¨ã€ç»“æ„å’Œå¤–è§‚ã€‚ç°æœ‰åŸºäºé«˜æ–¯æ‹¼è´´çš„æ–¹æ³•ä¼šå°†é™æ€å’ŒåŠ¨æ€å…ƒç´ çº ç¼ åœ¨ä¸€èµ·ï¼Œå¯¼è‡´è¿åŠ¨æ³„éœ²ã€å‡ ä½•å¤±çœŸå’Œä¸´æ—¶é—ªçƒã€‚ä½œè€…è®¤ä¸ºé—®é¢˜çš„æ ¹æºåœ¨äºæ—¶é—´å’Œå‡ ä½•ä¹‹é—´çš„è€¦åˆå»ºæ¨¡ï¼Œè¿™é˜»ç¢äº†ç¨³å®šæ€§å’Œå¯è§£é‡Šæ€§ã€‚ä¸ºè§£å†³è¿™ä¸€é—®é¢˜ï¼Œä½œè€…æå‡ºäº†SplitGaussianæ¡†æ¶ï¼Œè¯¥æ¡†æ¶å°†åœºæ™¯è¡¨ç¤ºæ˜¾å¼åœ°åˆ†è§£ä¸ºé™æ€å’ŒåŠ¨æ€ç»„ä»¶ã€‚é€šè¿‡å°†è¿åŠ¨å»ºæ¨¡ä¸èƒŒæ™¯å‡ ä½•åˆ†ç¦»ï¼Œåªå…è®¸åŠ¨æ€åˆ†æ”¯éšæ—¶é—´å˜å½¢ï¼Œè¯¥æ–¹æ³•é˜²æ­¢äº†é™æ€åŒºåŸŸçš„è¿åŠ¨ä¼ªå½±ï¼Œå¹¶æ”¯æŒè§†å’Œæ—¶é—´ç›¸å…³çš„å¤–è§‚ä¼˜åŒ–ã€‚è¿™ç§åˆ†ç¦»çš„è®¾è®¡ä¸ä»…æé«˜äº†æ—¶é—´ä¸€è‡´æ€§å’Œé‡å»ºä¿çœŸåº¦ï¼Œè¿˜åŠ é€Ÿäº†æ”¶æ•›ã€‚å®éªŒè¡¨æ˜ï¼ŒSplitGaussianåœ¨æ¸²æŸ“è´¨é‡ã€å‡ ä½•ç¨³å®šæ€§å’Œè¿åŠ¨åˆ†ç¦»æ–¹é¢ä¼˜äºç°æœ‰æ–¹æ³•ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>åŠ¨æ€3Dåœºæ™¯é‡å»ºä»å•ç›®è§†é¢‘å­˜åœ¨æŒ‘æˆ˜ï¼Œéœ€ä»æœ‰é™è§‚å¯Ÿä¸­è”åˆæ¨æ–­è¿åŠ¨ã€ç»“æ„å’Œå¤–è§‚ã€‚</li>
<li>ç°æœ‰æ–¹æ³•å­˜åœ¨è¿åŠ¨æ³„éœ²ã€å‡ ä½•å¤±çœŸå’Œä¸´æ—¶é—ªçƒé—®é¢˜ã€‚</li>
<li>é—®é¢˜æ ¹æºåœ¨äºæ—¶é—´å’Œå‡ ä½•çš„è€¦åˆå»ºæ¨¡ï¼Œå½±å“ç¨³å®šæ€§å’Œå¯è§£é‡Šæ€§ã€‚</li>
<li>SplitGaussianæ¡†æ¶èƒ½æ˜¾å¼åœ°åˆ†è§£åœºæ™¯ä¸ºé™æ€å’ŒåŠ¨æ€ç»„ä»¶ã€‚</li>
<li>è¯¥æ–¹æ³•é€šè¿‡åˆ†ç¦»è¿åŠ¨å»ºæ¨¡å’ŒèƒŒæ™¯å‡ ä½•ï¼Œæé«˜äº†æ—¶é—´ä¸€è‡´æ€§å’Œé‡å»ºè´¨é‡ã€‚</li>
<li>SplitGaussianåœ¨æ¸²æŸ“è´¨é‡ã€å‡ ä½•ç¨³å®šæ€§å’Œè¿åŠ¨åˆ†ç¦»æ–¹é¢ä¼˜äºç°æœ‰æ–¹æ³•ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.04224">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-0a0757e996b2ba11f2eb9b6e5e759f88.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-0f945cd32d0d08e3c6100019e6355b38.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-c6402b54bdfc769cf461afe3a5dffbaa.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-04328468d4da2cc731e9d4c59b068921.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-0c372d5b478988d50c8d708030c9984a.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="DET-GS-Depth-and-Edge-Aware-Regularization-for-High-Fidelity-3D-Gaussian-Splatting"><a href="#DET-GS-Depth-and-Edge-Aware-Regularization-for-High-Fidelity-3D-Gaussian-Splatting" class="headerlink" title="DET-GS: Depth- and Edge-Aware Regularization for High-Fidelity 3D   Gaussian Splatting"></a>DET-GS: Depth- and Edge-Aware Regularization for High-Fidelity 3D   Gaussian Splatting</h2><p><strong>Authors:Zexu Huang, Min Xu, Stuart Perry</strong></p>
<p>3D Gaussian Splatting (3DGS) represents a significant advancement in the field of efficient and high-fidelity novel view synthesis. Despite recent progress, achieving accurate geometric reconstruction under sparse-view conditions remains a fundamental challenge. Existing methods often rely on non-local depth regularization, which fails to capture fine-grained structures and is highly sensitive to depth estimation noise. Furthermore, traditional smoothing methods neglect semantic boundaries and indiscriminately degrade essential edges and textures, consequently limiting the overall quality of reconstruction. In this work, we propose DET-GS, a unified depth and edge-aware regularization framework for 3D Gaussian Splatting. DET-GS introduces a hierarchical geometric depth supervision framework that adaptively enforces multi-level geometric consistency, significantly enhancing structural fidelity and robustness against depth estimation noise. To preserve scene boundaries, we design an edge-aware depth regularization guided by semantic masks derived from Canny edge detection. Furthermore, we introduce an RGB-guided edge-preserving Total Variation loss that selectively smooths homogeneous regions while rigorously retaining high-frequency details and textures. Extensive experiments demonstrate that DET-GS achieves substantial improvements in both geometric accuracy and visual fidelity, outperforming state-of-the-art (SOTA) methods on sparse-view novel view synthesis benchmarks. </p>
<blockquote>
<p>3Dé«˜æ–¯å±•å¼€ï¼ˆ3DGSï¼‰ä»£è¡¨äº†é«˜æ•ˆå’Œé«˜ä¿çœŸæ–°é¢–è§†å›¾åˆæˆé¢†åŸŸçš„é‡è¦è¿›å±•ã€‚å°½ç®¡æœ€è¿‘æœ‰è¿›å±•ï¼Œä½†åœ¨ç¨€ç–è§†å›¾æ¡ä»¶ä¸‹å®ç°å‡†ç¡®çš„å‡ ä½•é‡å»ºä»ç„¶æ˜¯ä¸€ä¸ªåŸºæœ¬æŒ‘æˆ˜ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸ä¾èµ–äºéå±€éƒ¨æ·±åº¦æ­£åˆ™åŒ–ï¼Œè¿™æ— æ³•æ•æ‰ç²¾ç»†ç»“æ„ï¼Œå¹¶ä¸”å¯¹æ·±åº¦ä¼°è®¡å™ªå£°é«˜åº¦æ•æ„Ÿã€‚æ­¤å¤–ï¼Œä¼ ç»Ÿå¹³æ»‘æ–¹æ³•å¿½ç•¥äº†è¯­ä¹‰è¾¹ç•Œï¼Œä¸åŠ åŒºåˆ†åœ°é™ä½äº†é‡è¦è¾¹ç¼˜å’Œçº¹ç†ï¼Œä»è€Œé™åˆ¶äº†é‡å»ºçš„æ•´ä½“è´¨é‡ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†DET-GSï¼Œè¿™æ˜¯ä¸€ä¸ªç”¨äº3Dé«˜æ–¯å±•å¼€çš„æ·±åº¦æ„ŸçŸ¥å’Œè¾¹ç¼˜æ„ŸçŸ¥æ­£åˆ™åŒ–æ¡†æ¶ã€‚DET-GSå¼•å…¥äº†ä¸€ç§åˆ†å±‚å‡ ä½•æ·±åº¦ç›‘ç£æ¡†æ¶ï¼Œè¯¥æ¡†æ¶è‡ªé€‚åº”åœ°æ‰§è¡Œå¤šçº§å‡ ä½•ä¸€è‡´æ€§ï¼Œä»è€Œæ˜¾è‘—æé«˜ç»“æ„ä¿çœŸåº¦å’Œå¯¹æ·±åº¦ä¼°è®¡å™ªå£°çš„é²æ£’æ€§ã€‚ä¸ºäº†ä¿ç•™åœºæ™¯è¾¹ç•Œï¼Œæˆ‘ä»¬è®¾è®¡äº†ä¸€ç§ç”±Cannyè¾¹ç¼˜æ£€æµ‹å¾—åˆ°çš„è¯­ä¹‰æ©è†œå¼•å¯¼çš„è¾¹ç¼˜æ„ŸçŸ¥æ·±åº¦æ­£åˆ™åŒ–æ–¹æ³•ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§ç”±RGBå¼•å¯¼çš„ä¿è¾¹å…¨å˜æŸå¤±ï¼ˆTotal Variation lossï¼‰ï¼Œè¯¥æŸå¤±é€‰æ‹©æ€§åœ°å¹³æ»‘å‡åŒ€åŒºåŸŸï¼ŒåŒæ—¶ä¸¥æ ¼ä¿ç•™é«˜é¢‘ç»†èŠ‚å’Œçº¹ç†ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼ŒDET-GSåœ¨å‡ ä½•ç²¾åº¦å’Œè§†è§‰ä¿çœŸåº¦æ–¹é¢å–å¾—äº†å®è´¨æ€§æ”¹è¿›ï¼Œåœ¨ç¨€ç–è§†å›¾æ–°é¢–è§†å›¾åˆæˆåŸºå‡†æµ‹è¯•ä¸­ä¼˜äºæœ€æ–°æ–¹æ³•ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.04099v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†ä¸‰ç»´é«˜æ–¯èåˆï¼ˆ3DGSï¼‰é¢†åŸŸçš„æ–°è¿›å±•ã€‚ç°æœ‰æ–¹æ³•åœ¨å®ç°ç¨€ç–è§†å›¾ä¸‹çš„ç²¾ç¡®å‡ ä½•é‡å»ºæ—¶é¢ä¸´æŒ‘æˆ˜ï¼Œå®ƒä»¬é€šå¸¸é‡‡ç”¨éå±€éƒ¨æ·±åº¦æ­£åˆ™åŒ–æ–¹æ³•ï¼Œæ— æ³•æ•æ‰ç²¾ç»†ç»“æ„å¹¶å¯¹æ·±åº¦ä¼°è®¡å™ªå£°æ•æ„Ÿã€‚ä¸ºè§£å†³è¿™äº›é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ä¸ªç»Ÿä¸€ã€å…·æœ‰æ·±åº¦æ„ŸçŸ¥å’Œè¾¹ç¼˜æ„ŸçŸ¥çš„æ­£åˆ™åŒ–æ¡†æ¶DET-GSã€‚è¯¥æ¡†æ¶å¼•å…¥åˆ†å±‚å‡ ä½•æ·±åº¦ç›‘ç£æœºåˆ¶ï¼Œè‡ªé€‚åº”åœ°å®ç°å¤šçº§å‡ ä½•ä¸€è‡´æ€§ï¼Œä»è€Œæé«˜ç»“æ„ä¿çœŸåº¦å’Œå¯¹æ·±åº¦ä¼°è®¡å™ªå£°çš„é²æ£’æ€§ã€‚æ­¤å¤–ï¼Œä¸ºäº†ä¿ç•™åœºæ™¯è¾¹ç•Œï¼Œè¯¥æ¡†æ¶è¿˜è®¾è®¡äº†ä¸€ç§å—è¯­ä¹‰æ©ç å¼•å¯¼çš„è¾¹ç•Œæ„ŸçŸ¥æ·±åº¦æ­£åˆ™åŒ–æ–¹æ³•ï¼Œå¹¶é‡‡ç”¨RGBå¼•å¯¼çš„è¾¹ç¼˜ä¿ç•™æ€»å˜å¼‚æŸå¤±æ¥é€‰æ‹©æ€§å¹³æ»‘å‡åŒ€åŒºåŸŸï¼ŒåŒæ—¶ä¸¥æ ¼ä¿ç•™é«˜é¢‘ç»†èŠ‚å’Œçº¹ç†ã€‚å®éªŒè¯æ˜ï¼ŒDET-GSåœ¨å‡ ä½•ç²¾åº¦å’Œè§†è§‰ä¿çœŸåº¦æ–¹é¢å–å¾—äº†æ˜¾è‘—æ”¹è¿›ï¼Œåœ¨ç¨€ç–è§†å›¾æ–°è§†è§’åˆæˆåŸºå‡†æµ‹è¯•ä¸­ä¼˜äºå…¶ä»–æœ€å…ˆè¿›çš„æ–¹æ³•ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>ç°æœ‰æ–¹æ³•åœ¨ç¨€ç–è§†å›¾ä¸‹çš„å‡ ä½•é‡å»ºä¸­é¢ä¸´æŒ‘æˆ˜ï¼Œå­˜åœ¨æ— æ³•æ•æ‰ç²¾ç»†ç»“æ„å’Œå¯¹æ·±åº¦ä¼°è®¡å™ªå£°æ•æ„Ÿçš„é—®é¢˜ã€‚</li>
<li>DET-GSæ˜¯ä¸€ä¸ªç»Ÿä¸€ã€å…·æœ‰æ·±åº¦æ„ŸçŸ¥å’Œè¾¹ç¼˜æ„ŸçŸ¥çš„æ­£åˆ™åŒ–æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³ä¸Šè¿°é—®é¢˜ã€‚</li>
<li>DET-GSå¼•å…¥åˆ†å±‚å‡ ä½•æ·±åº¦ç›‘ç£æœºåˆ¶ï¼Œæé«˜ç»“æ„ä¿çœŸåº¦å’Œå¯¹æ·±åº¦ä¼°è®¡å™ªå£°çš„é²æ£’æ€§ã€‚</li>
<li>æ¡†æ¶é‡‡ç”¨è¯­ä¹‰æ©ç å¼•å¯¼çš„è¾¹ç•Œæ„ŸçŸ¥æ·±åº¦æ­£åˆ™åŒ–æ–¹æ³•ï¼Œä»¥ä¿ç•™åœºæ™¯è¾¹ç•Œã€‚</li>
<li>é‡‡ç”¨RGBå¼•å¯¼çš„è¾¹ç¼˜ä¿ç•™æ€»å˜å¼‚æŸå¤±ï¼Œé€‰æ‹©æ€§å¹³æ»‘å‡åŒ€åŒºåŸŸï¼ŒåŒæ—¶ä¿ç•™é«˜é¢‘ç»†èŠ‚å’Œçº¹ç†ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.04099">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-945644c9110b7c0fd8b8f7e4fa38c4dd.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-4d8c2619183eff1451c3360ca24e9d01.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-9cb36990caf7114e4bbfaf61fce1d6a0.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c58065a90a95fdc9ce6a9d2ce3f94b72.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-5dc592d6a4a09d2c4fe865439b52a4bf.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-70ab76528bf37baf1e55309a41393fc8.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="Bridging-Diffusion-Models-and-3D-Representations-A-3D-Consistent-Super-Resolution-Framework"><a href="#Bridging-Diffusion-Models-and-3D-Representations-A-3D-Consistent-Super-Resolution-Framework" class="headerlink" title="Bridging Diffusion Models and 3D Representations: A 3D Consistent   Super-Resolution Framework"></a>Bridging Diffusion Models and 3D Representations: A 3D Consistent   Super-Resolution Framework</h2><p><strong>Authors:Yi-Ting Chen, Ting-Hsuan Liao, Pengsheng Guo, Alexander Schwing, Jia-Bin Huang</strong></p>
<p>We propose 3D Super Resolution (3DSR), a novel 3D Gaussian-splatting-based super-resolution framework that leverages off-the-shelf diffusion-based 2D super-resolution models. 3DSR encourages 3D consistency across views via the use of an explicit 3D Gaussian-splatting-based scene representation. This makes the proposed 3DSR different from prior work, such as image upsampling or the use of video super-resolution, which either donâ€™t consider 3D consistency or aim to incorporate 3D consistency implicitly. Notably, our method enhances visual quality without additional fine-tuning, ensuring spatial coherence within the reconstructed scene. We evaluate 3DSR on MipNeRF360 and LLFF data, demonstrating that it produces high-resolution results that are visually compelling, while maintaining structural consistency in 3D reconstructions. Code will be released. </p>
<blockquote>
<p>æˆ‘ä»¬æå‡ºäº†åŸºäºä¸‰ç»´é«˜æ–¯æ•£æ–‘çš„è¶…åˆ†è¾¨ç‡æŠ€æœ¯ï¼ˆ3DSRï¼‰ï¼Œè¿™æ˜¯ä¸€ç§æ–°å‹ä¸‰ç»´è¶…åˆ†è¾¨ç‡æ¡†æ¶ï¼Œå®ƒåˆ©ç”¨ç°æˆçš„åŸºäºæ‰©æ•£çš„äºŒç»´è¶…åˆ†è¾¨ç‡æ¨¡å‹ã€‚é€šè¿‡é‡‡ç”¨åŸºäºæ˜ç¡®çš„ä¸‰ç»´é«˜æ–¯æ•£æ–‘çš„åœºæ™¯è¡¨ç¤ºï¼Œ3DSRé¼“åŠ±ä¸åŒè§†è§’çš„ä¸‰ç»´ä¸€è‡´æ€§ã€‚è¿™ä½¿å¾—æ‰€æå‡ºçš„3DSRä¸å…ˆå‰çš„å·¥ä½œæœ‰æ‰€ä¸åŒï¼Œä¾‹å¦‚å›¾åƒä¸Šé‡‡æ ·æˆ–ä½¿ç”¨è§†é¢‘è¶…åˆ†è¾¨ç‡ï¼Œè¿™äº›è¦ä¹ˆä¸è€ƒè™‘ä¸‰ç»´ä¸€è‡´æ€§ï¼Œè¦ä¹ˆæ—¨åœ¨éšå¼åœ°èå…¥ä¸‰ç»´ä¸€è‡´æ€§ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨æ— éœ€é¢å¤–å¾®è°ƒçš„æƒ…å†µä¸‹æé«˜äº†è§†è§‰è´¨é‡ï¼Œç¡®ä¿äº†é‡å»ºåœºæ™¯å†…çš„ç©ºé—´è¿è´¯æ€§ã€‚æˆ‘ä»¬åœ¨MipNeRF360å’ŒLLFFæ•°æ®ä¸Šå¯¹3DSRè¿›è¡Œäº†è¯„ä¼°ï¼Œç»“æœè¡¨æ˜å®ƒäº§ç”Ÿäº†é«˜åˆ†è¾¨ç‡çš„ç»“æœï¼Œè§†è§‰ä¸Šéå¸¸å¸å¼•äººï¼ŒåŒæ—¶åœ¨ä¸‰ç»´é‡å»ºä¸­ä¿æŒäº†ç»“æ„ä¸€è‡´æ€§ã€‚ä»£ç å°†ä¼šå…¬å¼€ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.04090v1">PDF</a> Accepted to ICCV 2025</p>
<p><strong>æ‘˜è¦</strong></p>
<p>æœ¬æ–‡æå‡ºäº†åŸºäºä¸‰ç»´é«˜æ–¯æ¶‚æŠ¹æŠ€æœ¯çš„è¶…çº§åˆ†è¾¨ç‡é‡å»ºæ¡†æ¶ï¼ˆ3DSRï¼‰ã€‚å®ƒåˆ©ç”¨ç°æˆçš„äºŒç»´æ‰©æ•£è¶…çº§åˆ†è¾¨ç‡æ¨¡å‹ï¼Œå¹¶é€šè¿‡æ˜ç¡®çš„3Dé«˜æ–¯æ¶‚æŠ¹åœºæ™¯è¡¨ç¤ºæ¥é¼“åŠ±ä¸åŒè§†è§’ä¸‹çš„ä¸‰ç»´ä¸€è‡´æ€§ã€‚ä¸ä¼ ç»Ÿçš„å›¾åƒä¸Šé‡‡æ ·æˆ–è§†é¢‘è¶…çº§åˆ†è¾¨ç‡æ–¹æ³•ä¸åŒï¼Œæ–°æ–¹æ³•æ— éœ€è€ƒè™‘ä¸‰ç»´ä¸€è‡´æ€§æˆ–è¯•å›¾éšå¼åœ°å®ç°å®ƒã€‚å€¼å¾—æ³¨æ„çš„ç‰¹ç‚¹æ˜¯ï¼Œæˆ‘ä»¬çš„æ–¹æ³•èƒ½å¤Ÿåœ¨ä¸ç»è¿‡å¾®è°ƒçš„æƒ…å†µä¸‹æé«˜è§†è§‰æ•ˆæœï¼Œç¡®ä¿é‡å»ºåœºæ™¯å†…çš„ç©ºé—´è¿è´¯æ€§ã€‚åœ¨MipNeRF360å’ŒLLFFæ•°æ®ä¸Šçš„è¯„ä¼°è¡¨æ˜ï¼Œå®ƒäº§ç”Ÿé«˜åˆ†è¾¨ç‡ç»“æœï¼Œè§†è§‰ä¸Šä»¤äººä¿¡æœï¼ŒåŒæ—¶åœ¨ä¸‰ç»´é‡å»ºä¸­ä¿æŒç»“æ„ä¸€è‡´æ€§ã€‚ä»£ç å³å°†å‘å¸ƒã€‚</p>
<p><strong>å…³é”®è§è§£</strong></p>
<ol>
<li>æå‡ºäº†åŸºäºä¸‰ç»´é«˜æ–¯æ¶‚æŠ¹æŠ€æœ¯çš„è¶…çº§åˆ†è¾¨ç‡é‡å»ºæ¡†æ¶ï¼ˆ3DSRï¼‰ã€‚</li>
<li>åˆ©ç”¨ç°æˆçš„äºŒç»´æ‰©æ•£è¶…çº§åˆ†è¾¨ç‡æ¨¡å‹ã€‚</li>
<li>é€šè¿‡æ˜ç¡®çš„3Dé«˜æ–¯æ¶‚æŠ¹åœºæ™¯è¡¨ç¤ºå®ç°ä¸‰ç»´ä¸€è‡´æ€§ã€‚</li>
<li>ä¸ä¼ ç»Ÿæ–¹æ³•ä¸åŒï¼Œæ— éœ€è€ƒè™‘ä¸‰ç»´ä¸€è‡´æ€§æˆ–éšå¼å®ç°ã€‚</li>
<li>åœ¨ä¸ç»è¿‡å¾®è°ƒçš„æƒ…å†µä¸‹æé«˜è§†è§‰æ•ˆæœã€‚</li>
<li>ç¡®ä¿é‡å»ºåœºæ™¯å†…çš„ç©ºé—´è¿è´¯æ€§ã€‚</li>
<li>åœ¨MipNeRF360å’ŒLLFFæ•°æ®ä¸Šçš„è¯„ä¼°è¡¨ç°å‡ºè‰¯å¥½çš„æ€§èƒ½ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.04090">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-a522873216ea28271b6b90aa6a1598f2.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-16db270af7eea998ad19751660811606.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-6898d6f3a8ef580284b55f71bceca49e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-452831ddf7fb66c921b0c83cd32f7f44.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="RLGS-Reinforcement-Learning-Based-Adaptive-Hyperparameter-Tuning-for-Gaussian-Splatting"><a href="#RLGS-Reinforcement-Learning-Based-Adaptive-Hyperparameter-Tuning-for-Gaussian-Splatting" class="headerlink" title="RLGS: Reinforcement Learning-Based Adaptive Hyperparameter Tuning for   Gaussian Splatting"></a>RLGS: Reinforcement Learning-Based Adaptive Hyperparameter Tuning for   Gaussian Splatting</h2><p><strong>Authors:Zhan Li, Huangying Zhan, Changyang Li, Qingan Yan, Yi Xu</strong></p>
<p>Hyperparameter tuning in 3D Gaussian Splatting (3DGS) is a labor-intensive and expert-driven process, often resulting in inconsistent reconstructions and suboptimal results. We propose RLGS, a plug-and-play reinforcement learning framework for adaptive hyperparameter tuning in 3DGS through lightweight policy modules, dynamically adjusting critical hyperparameters such as learning rates and densification thresholds. The framework is model-agnostic and seamlessly integrates into existing 3DGS pipelines without architectural modifications. We demonstrate its generalization ability across multiple state-of-the-art 3DGS variants, including Taming-3DGS and 3DGS-MCMC, and validate its robustness across diverse datasets. RLGS consistently enhances rendering quality. For example, it improves Taming-3DGS by 0.7dB PSNR on the Tanks and Temple (TNT) dataset, under a fixed Gaussian budget, and continues to yield gains even when baseline performance saturates. Our results suggest that RLGS provides an effective and general solution for automating hyperparameter tuning in 3DGS training, bridging a gap in applying reinforcement learning to 3DGS. </p>
<blockquote>
<p>åœ¨3Dé«˜æ–¯æ··åˆï¼ˆ3DGSï¼‰ä¸­ï¼Œè¶…å‚æ•°è°ƒæ•´æ˜¯ä¸€ä¸ªåŠ³åŠ¨å¯†é›†å‹ä¸”ä¸“å®¶é©±åŠ¨çš„è¿‡ç¨‹ï¼Œå¾€å¾€å¯¼è‡´é‡å»ºç»“æœä¸ä¸€è‡´å’Œæ¬¡ä¼˜ç»“æœã€‚æˆ‘ä»¬æå‡ºäº†RLGSï¼Œè¿™æ˜¯ä¸€ç§ç”¨äºè‡ªé€‚åº”è¶…å‚æ•°è°ƒæ•´çš„å¼ºåŒ–å­¦ä¹ æ¡†æ¶ï¼Œé€šè¿‡è½»é‡çº§ç­–ç•¥æ¨¡å—å®ç°å³æ’å³ç”¨åŠŸèƒ½ï¼ŒåŠ¨æ€è°ƒæ•´å…³é”®è¶…å‚æ•°ï¼Œå¦‚å­¦ä¹ ç‡å’Œå¯†åº¦é˜ˆå€¼ã€‚è¯¥æ¡†æ¶å…·æœ‰æ¨¡å‹é€šç”¨æ€§ï¼Œå¯æ— ç¼é›†æˆåˆ°ç°æœ‰çš„3DGSç®¡é“ä¸­ï¼Œæ— éœ€è¿›è¡Œæ¶æ„ä¿®æ”¹ã€‚æˆ‘ä»¬åœ¨å¤šä¸ªæœ€å…ˆè¿›çš„3DGSå˜ä½“ä¸Šå±•ç¤ºäº†å…¶æ³›åŒ–èƒ½åŠ›ï¼ŒåŒ…æ‹¬é©¯æœ3DGSå’Œ3DGS-MCMCç­‰ï¼Œå¹¶åœ¨å„ç§æ•°æ®é›†ä¸ŠéªŒè¯äº†å…¶ç¨³å¥æ€§ã€‚RLGSæŒç»­æé«˜äº†æ¸²æŸ“è´¨é‡ã€‚ä¾‹å¦‚ï¼Œåœ¨å›ºå®šé«˜æ–¯é¢„ç®—çš„æƒ…å†µä¸‹ï¼Œå®ƒåœ¨å¦å…‹å’Œå¯ºåº™ï¼ˆTNTï¼‰æ•°æ®é›†ä¸Šæ”¹è¿›äº†é©¯æœ3DGSçš„PSNR 0.7dBï¼›å³ä½¿åœ¨åŸºçº¿æ€§èƒ½é¥±å’Œæ—¶ï¼Œä¹Ÿèƒ½ç»§ç»­äº§ç”Ÿæ”¶ç›Šã€‚æˆ‘ä»¬çš„ç»“æœè¡¨æ˜ï¼ŒRLGSæä¾›äº†ä¸€ç§æœ‰æ•ˆä¸”é€šç”¨çš„è§£å†³æ–¹æ¡ˆï¼Œå¯è‡ªåŠ¨åŒ–ç”¨äºè§£å†³3DGSè®­ç»ƒä¸­çš„è¶…å‚æ•°è°ƒæ•´é—®é¢˜ï¼Œå¡«è¡¥äº†å°†å¼ºåŒ–å­¦ä¹ åº”ç”¨äº3DGSçš„ç©ºç™½ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.04078v1">PDF</a> 14 pages, 9 figures</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºä¸€ç§åä¸ºRLGSçš„å¼ºåŒ–å­¦ä¹ æ¡†æ¶ï¼Œç”¨äºè‡ªé€‚åº”è°ƒæ•´3Dé«˜æ–¯èåˆï¼ˆ3DGSï¼‰ä¸­çš„å…³é”®è¶…å‚æ•°ï¼Œå¦‚å­¦ä¹ ç‡å’Œå¯†åº¦é˜ˆå€¼ã€‚è¯¥æ¡†æ¶å…·æœ‰æ¨¡å‹æ— å…³æ€§ï¼Œå¯æ— ç¼é›†æˆåˆ°ç°æœ‰3DGSç®¡é“ä¸­ï¼Œæ— éœ€è¿›è¡Œæ¶æ„ä¿®æ”¹ã€‚å®éªŒè¡¨æ˜ï¼ŒRLGSåœ¨å¤šä¸ªå…ˆè¿›çš„3DGSå˜ä½“ä¸Šå…·æœ‰è‰¯å¥½çš„é€šç”¨æ€§ï¼Œå¹¶åœ¨å„ç§æ•°æ®é›†ä¸ŠéªŒè¯äº†å…¶ç¨³å¥æ€§ã€‚RLGSèƒ½æŒç»­æé«˜æ¸²æŸ“è´¨é‡ï¼Œä¾‹å¦‚ï¼Œåœ¨å›ºå®šçš„é«˜æ–¯é¢„ç®—ä¸‹ï¼Œå®ƒåœ¨Tanks and Templeæ•°æ®é›†ä¸Šå°†Taming-3DGSçš„PSNRæé«˜äº†0.7dBã€‚æ€»ä½“è€Œè¨€ï¼ŒRLGSä¸ºè‡ªåŠ¨è°ƒæ•´3DGSè¶…å‚æ•°æä¾›äº†ä¸€ç§æœ‰æ•ˆä¸”é€šç”¨çš„è§£å†³æ–¹æ¡ˆã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>RLGSæ˜¯ä¸€ç§å¼ºåŒ–å­¦ä¹ æ¡†æ¶ï¼Œç”¨äºè‡ªé€‚åº”è°ƒæ•´3DGSä¸­çš„è¶…å‚æ•°ã€‚</li>
<li>è¯¥æ¡†æ¶å…·æœ‰æ¨¡å‹æ— å…³æ€§ï¼Œå¯è½»æ¾é›†æˆåˆ°ç°æœ‰çš„3DGSç®¡é“ä¸­ã€‚</li>
<li>RLGSåœ¨å¤šä¸ªå…ˆè¿›çš„3DGSå˜ä½“ä¸Šå…·æœ‰è‰¯å¥½çš„é€šç”¨æ€§ã€‚</li>
<li>RLGSåœ¨å¤šç§æ•°æ®é›†ä¸ŠéªŒè¯äº†å…¶ç¨³å¥æ€§ã€‚</li>
<li>RLGSèƒ½æŒç»­æé«˜æ¸²æŸ“è´¨é‡ï¼Œå¦‚Taming-3DGSåœ¨Tanks and Templeæ•°æ®é›†ä¸Šçš„PSNRæé«˜0.7dBã€‚</li>
<li>RLGSå°¤å…¶åœ¨åŸºçº¿æ€§èƒ½é¥±å’Œæ—¶ä»èƒ½ä¿æŒæå‡æ•ˆæœã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.04078">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-604547beb7e53ab975540eb43573dc71.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-9878ac5eb268b6d0411b75a726e4b834.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d8373bed84e121d455d7b8628ed687d1.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ed44129a0fff17c3feb72c1bc34fdf02.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-42d0c248a720803a4b9842817623acbc.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="Uni3R-Unified-3D-Reconstruction-and-Semantic-Understanding-via-Generalizable-Gaussian-Splatting-from-Unposed-Multi-View-Images"><a href="#Uni3R-Unified-3D-Reconstruction-and-Semantic-Understanding-via-Generalizable-Gaussian-Splatting-from-Unposed-Multi-View-Images" class="headerlink" title="Uni3R: Unified 3D Reconstruction and Semantic Understanding via   Generalizable Gaussian Splatting from Unposed Multi-View Images"></a>Uni3R: Unified 3D Reconstruction and Semantic Understanding via   Generalizable Gaussian Splatting from Unposed Multi-View Images</h2><p><strong>Authors:Xiangyu Sun, Haoyi jiang, Liu Liu, Seungtae Nam, Gyeongjin Kang, Xinjie wang, Wei Sui, Zhizhong Su, Wenyu Liu, Xinggang Wang, Eunbyung Park</strong></p>
<p>Reconstructing and semantically interpreting 3D scenes from sparse 2D views remains a fundamental challenge in computer vision. Conventional methods often decouple semantic understanding from reconstruction or necessitate costly per-scene optimization, thereby restricting their scalability and generalizability. In this paper, we introduce Uni3R, a novel feed-forward framework that jointly reconstructs a unified 3D scene representation enriched with open-vocabulary semantics, directly from unposed multi-view images. Our approach leverages a Cross-View Transformer to robustly integrate information across arbitrary multi-view inputs, which then regresses a set of 3D Gaussian primitives endowed with semantic feature fields. This unified representation facilitates high-fidelity novel view synthesis, open-vocabulary 3D semantic segmentation, and depth prediction, all within a single, feed-forward pass. Extensive experiments demonstrate that Uni3R establishes a new state-of-the-art across multiple benchmarks, including 25.07 PSNR on RE10K and 55.84 mIoU on ScanNet. Our work signifies a novel paradigm towards generalizable, unified 3D scene reconstruction and understanding. The code is available at <a target="_blank" rel="noopener" href="https://github.com/HorizonRobotics/Uni3R">https://github.com/HorizonRobotics/Uni3R</a>. </p>
<blockquote>
<p>ä»ç¨€ç–çš„äºŒç»´è§†è§’é‡å»ºå’Œè¯­ä¹‰è§£é‡Šä¸‰ç»´åœºæ™¯ä»ç„¶æ˜¯è®¡ç®—æœºè§†è§‰é¢†åŸŸçš„ä¸€ä¸ªåŸºæœ¬æŒ‘æˆ˜ã€‚ä¼ ç»Ÿçš„æ–¹æ³•é€šå¸¸ä¼šå°†è¯­ä¹‰ç†è§£ä¸é‡å»ºè§£è€¦ï¼Œæˆ–è€…éœ€è¦è¿›è¡Œæ˜‚è´µçš„åœºæ™¯ä¼˜åŒ–ï¼Œä»è€Œé™åˆ¶äº†å…¶å¯æ‰©å±•æ€§å’Œæ³›åŒ–èƒ½åŠ›ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬ä»‹ç»äº†Uni3Rï¼Œè¿™æ˜¯ä¸€ç§æ–°å‹å‰é¦ˆæ¡†æ¶ï¼Œå®ƒèƒ½ç›´æ¥ä»æ— å§¿æ€çš„å¤šè§†è§’å›¾åƒä¸­è”åˆé‡å»ºä¸€ä¸ªç»Ÿä¸€çš„ä¸‰ç»´åœºæ™¯è¡¨ç¤ºï¼Œå¹¶ä¸°å¯Œå¼€æ”¾è¯æ±‡è¯­ä¹‰ã€‚æˆ‘ä»¬çš„æ–¹æ³•åˆ©ç”¨è·¨è§†å›¾å˜å‹å™¨ç¨³å¥åœ°æ•´åˆä»»æ„å¤šè§†è§’è¾“å…¥çš„ä¿¡æ¯ï¼Œç„¶åå›å½’ä¸€ç»„å¸¦æœ‰è¯­ä¹‰ç‰¹å¾åœºçš„ä¸‰ç»´é«˜æ–¯åŸºå…ƒã€‚è¿™ç§ç»Ÿä¸€è¡¨ç¤ºæœ‰åŠ©äºé«˜ä¿çœŸåº¦çš„æ–°è§†è§’åˆæˆã€å¼€æ”¾è¯æ±‡ä¸‰ç»´è¯­ä¹‰åˆ†å‰²å’Œæ·±åº¦é¢„æµ‹ï¼Œæ‰€æœ‰è¿™äº›éƒ½åœ¨å•æ¬¡å‰é¦ˆä¼ é€’ä¸­å®Œæˆã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼ŒUni3Råœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­å»ºç«‹äº†æ–°çš„æœ€å…ˆè¿›çš„æ€§èƒ½ï¼ŒåŒ…æ‹¬RE10Kä¸Šçš„25.07 PSNRå’ŒScanNetä¸Šçš„55.84 mIoUã€‚æˆ‘ä»¬çš„å·¥ä½œæ ‡å¿—ç€æœç€é€šç”¨ã€ç»Ÿä¸€çš„ä¸‰ç»´åœºæ™¯é‡å»ºå’Œç†è§£çš„æ–°èŒƒå¼ã€‚ä»£ç å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/HorizonRobotics/Uni3R%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/HorizonRobotics/Uni3Ræ‰¾åˆ°ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.03643v2">PDF</a> The code is available at <a target="_blank" rel="noopener" href="https://github.com/HorizonRobotics/Uni3R">https://github.com/HorizonRobotics/Uni3R</a></p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸ºUni3Rçš„æ–°å‹å‰é¦ˆæ¡†æ¶ï¼Œå¯ä»æ— å§¿æ€çš„å¤šè§†è§’å›¾åƒç›´æ¥é‡å»ºç»Ÿä¸€çš„ä¸‰ç»´åœºæ™¯è¡¨ç¤ºï¼Œå¹¶èå…¥å¼€æ”¾è¯æ±‡è¯­ä¹‰ã€‚è¯¥æ¡†æ¶åˆ©ç”¨è·¨è§†å›¾å˜å‹å™¨ç¨³å¥åœ°æ•´åˆä»»æ„å¤šè§†å›¾è¾“å…¥çš„ä¿¡æ¯ï¼Œç„¶åå›å½’ä¸€ç»„å¸¦æœ‰è¯­ä¹‰ç‰¹å¾åœºçš„ä¸‰ç»´é«˜æ–¯åŸºæœ¬ä½“ã€‚è¿™ä¸€ç»Ÿä¸€è¡¨ç¤ºæœ‰åŠ©äºé«˜ä¿çœŸåº¦çš„æ–°è§†è§’åˆæˆã€å¼€æ”¾è¯æ±‡çš„3Dè¯­ä¹‰åˆ†å‰²å’Œæ·±åº¦é¢„æµ‹ã€‚åœ¨RE10Kå’ŒScanNetç­‰å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­ï¼ŒUni3Rå–å¾—äº†æœ€æ–°æŠ€æœ¯æˆæœã€‚æ­¤å·¥ä½œæ ‡å¿—ç€é¢å‘å¯æ¦‚æ‹¬çš„ã€ç»Ÿä¸€çš„ä¸‰ç»´åœºæ™¯é‡å»ºå’Œç†è§£çš„å…¨æ–°èŒƒå¼ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>Uni3Ræ˜¯ä¸€ä¸ªæ–°å‹å‰é¦ˆæ¡†æ¶ï¼Œå¯ä»¥ä»ç¨€ç–çš„2Dè§†è§’é‡å»ºå¹¶è¯­ä¹‰è§£é‡Š3Dåœºæ™¯ã€‚</li>
<li>è¯¥æ¡†æ¶é€šè¿‡è·¨è§†å›¾å˜å‹å™¨æ•´åˆä»»æ„å¤šè§†å›¾è¾“å…¥ä¿¡æ¯ï¼Œæé«˜äº†ç¨³å¥æ€§ã€‚</li>
<li>Uni3Rå¯ä»¥ç”Ÿæˆç»Ÿä¸€çš„ä¸‰ç»´åœºæ™¯è¡¨ç¤ºï¼ŒåŒ…æ‹¬ä¸‰ç»´é«˜æ–¯åŸºæœ¬ä½“å’Œè¯­ä¹‰ç‰¹å¾åœºã€‚</li>
<li>è¯¥æ–¹æ³•æ”¯æŒé«˜ä¿çœŸåº¦çš„æ–°è§†è§’åˆæˆã€å¼€æ”¾è¯æ±‡çš„3Dè¯­ä¹‰åˆ†å‰²å’Œæ·±åº¦é¢„æµ‹ã€‚</li>
<li>Uni3Råœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œå¦‚RE10Kçš„PSNRè¾¾åˆ°25.07ï¼ŒScanNetçš„mIoUè¾¾åˆ°55.84ã€‚</li>
<li>Uni3Rçš„å·¥ä½œæ ‡å¿—ç€ç»Ÿä¸€ä¸‰ç»´åœºæ™¯é‡å»ºå’Œç†è§£çš„æ–°èŒƒå¼ï¼Œå¼ºè°ƒå¯æ¦‚æ‹¬æ€§å’Œé€šç”¨æ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.03643">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-1c733dce7577c329eb3310bddedd3b01.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-872d963a6c288f84b81c606193208246.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-0a73727611f9f533d373a7a345f03b9f.jpg" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="H3R-Hybrid-Multi-view-Correspondence-for-Generalizable-3D-Reconstruction"><a href="#H3R-Hybrid-Multi-view-Correspondence-for-Generalizable-3D-Reconstruction" class="headerlink" title="H3R: Hybrid Multi-view Correspondence for Generalizable 3D   Reconstruction"></a>H3R: Hybrid Multi-view Correspondence for Generalizable 3D   Reconstruction</h2><p><strong>Authors:Heng Jia, Linchao Zhu, Na Zhao</strong></p>
<p>Despite recent advances in feed-forward 3D Gaussian Splatting, generalizable 3D reconstruction remains challenging, particularly in multi-view correspondence modeling. Existing approaches face a fundamental trade-off: explicit methods achieve geometric precision but struggle with ambiguous regions, while implicit methods provide robustness but suffer from slow convergence. We present H3R, a hybrid framework that addresses this limitation by integrating volumetric latent fusion with attention-based feature aggregation. Our framework consists of two complementary components: an efficient latent volume that enforces geometric consistency through epipolar constraints, and a camera-aware Transformer that leverages Pl&quot;ucker coordinates for adaptive correspondence refinement. By integrating both paradigms, our approach enhances generalization while converging 2$\times$ faster than existing methods. Furthermore, we show that spatial-aligned foundation models (e.g., SD-VAE) substantially outperform semantic-aligned models (e.g., DINOv2), resolving the mismatch between semantic representations and spatial reconstruction requirements. Our method supports variable-number and high-resolution input views while demonstrating robust cross-dataset generalization. Extensive experiments show that our method achieves state-of-the-art performance across multiple benchmarks, with significant PSNR improvements of 0.59 dB, 1.06 dB, and 0.22 dB on the RealEstate10K, ACID, and DTU datasets, respectively. Code is available at <a target="_blank" rel="noopener" href="https://github.com/JiaHeng-DLUT/H3R">https://github.com/JiaHeng-DLUT/H3R</a>. </p>
<blockquote>
<p>å°½ç®¡æœ€è¿‘åœ¨å‰é¦ˆä¸‰ç»´é«˜æ–¯Splattingæ–¹é¢å–å¾—äº†è¿›å±•ï¼Œä½†é€šç”¨ä¸‰ç»´é‡å»ºä»ç„¶å­˜åœ¨æŒ‘æˆ˜ï¼Œç‰¹åˆ«æ˜¯åœ¨å¤šè§†å›¾å¯¹åº”å»ºæ¨¡æ–¹é¢ã€‚ç°æœ‰æ–¹æ³•é¢ä¸´ä¸€ä¸ªåŸºæœ¬æƒè¡¡ï¼šæ˜¾å¼æ–¹æ³•å®ç°äº†å‡ ä½•ç²¾åº¦ï¼Œä½†åœ¨æ¨¡ç³ŠåŒºåŸŸä¸­è¡¨ç°ä¸ä½³ï¼Œè€Œéšå¼æ–¹æ³•æä¾›äº†ç¨³å¥æ€§ä½†æ”¶æ•›è¾ƒæ…¢ã€‚æˆ‘ä»¬æå‡ºäº†H3Rï¼Œä¸€ä¸ªæ··åˆæ¡†æ¶ï¼Œé€šè¿‡ç»“åˆä½“ç§¯æ½œåœ¨èåˆå’ŒåŸºäºæ³¨æ„åŠ›çš„ç‰¹å¾èšåˆæ¥è§£å†³è¿™ä¸€å±€é™æ€§ã€‚æˆ‘ä»¬çš„æ¡†æ¶ç”±ä¸¤ä¸ªäº’è¡¥çš„ç»„ä»¶æ„æˆï¼šä¸€ä¸ªé«˜æ•ˆçš„æ½œåœ¨ä½“ç§¯ï¼Œå®ƒé€šè¿‡æçº¿çº¦æŸå¼ºåˆ¶æ‰§è¡Œå‡ ä½•ä¸€è‡´æ€§ï¼›ä¸€ä¸ªçŸ¥é“ç›¸æœºçš„Transformerï¼Œå®ƒåˆ©ç”¨PlÃ¼ckeråæ ‡è¿›è¡Œè‡ªé€‚åº”å¯¹åº”ç»†åŒ–ã€‚é€šè¿‡æ•´åˆè¿™ä¸¤ç§èŒƒå¼ï¼Œæˆ‘ä»¬çš„æ–¹æ³•æé«˜äº†é€šç”¨æ€§ï¼Œå¹¶ä¸”æ”¶æ•›é€Ÿåº¦æ¯”ç°æœ‰æ–¹æ³•å¿«ä¸¤å€ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¡¨æ˜ç©ºé—´å¯¹é½çš„åŸºç¡€æ¨¡å‹ï¼ˆä¾‹å¦‚SD-VAEï¼‰åœ¨è¯­ä¹‰å¯¹é½çš„æ¨¡å‹ï¼ˆä¾‹å¦‚DINOv2ï¼‰ä¸Šè¡¨ç°å‡ºæ˜¾è‘—ä¼˜åŠ¿ï¼Œè§£å†³äº†è¯­ä¹‰è¡¨ç¤ºå’Œç©ºé—´é‡å»ºè¦æ±‚ä¹‹é—´çš„ä¸åŒ¹é…é—®é¢˜ã€‚æˆ‘ä»¬çš„æ–¹æ³•æ”¯æŒå¯å˜æ•°é‡å’Œé«˜æ¸…è¾“å…¥è§†å›¾ï¼Œå¹¶è¡¨ç°å‡ºè·¨æ•°æ®é›†çš„ç¨³å¥æ³›åŒ–èƒ½åŠ›ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸Šè¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œåœ¨RealEstate10Kã€ACIDå’ŒDTUæ•°æ®é›†ä¸Šçš„PSNRåˆ†åˆ«æé«˜äº†0.59åˆ†è´ã€1.06åˆ†è´å’Œ0.22åˆ†è´ã€‚ä»£ç å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/JiaHeng-DLUT/H3R%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/JiaHeng-DLUT/H3Ræ‰¾åˆ°ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.03118v1">PDF</a> ICCV 2025</p>
<p><strong>æ‘˜è¦</strong></p>
<p>è¿‘æœŸåœ¨é¢å‘å¤šè§†å›¾é‡å»ºçš„æŒ‘æˆ˜æ€§é—®é¢˜ä¸­ï¼Œå¦‚ç©ºé—´ä¸€è‡´çš„è¯­ä¹‰æ˜ å°„ä¸ç²¾ç»†å‡ ä½•é‡å»ºä¸Šå–å¾—äº†é‡å¤§è¿›å±•ã€‚ä½†ç°æœ‰æ–¹æ³•é¢ä¸´å‡ ä½•ç²¾åº¦ä¸æ¨¡ç³ŠåŒºåŸŸå¤„ç†çš„æƒè¡¡é—®é¢˜ï¼ŒåŒæ—¶éšå¼æ–¹æ³•è™½ç¨³å¥ä½†æ”¶æ•›è¾ƒæ…¢ã€‚æœ¬ç ”ç©¶æå‡ºä¸€ç§æ··åˆæ¡†æ¶H3Rï¼Œé€šè¿‡ä½“ç§¯æ½œåœ¨èåˆä¸åŸºäºæ³¨æ„åŠ›çš„ç‰¹å¾èšåˆæ¥è§£å†³æ­¤é—®é¢˜ã€‚æ¡†æ¶åŒ…å«ä¸¤ä¸ªäº’è¡¥ç»„ä»¶ï¼šé«˜æ•ˆæ½œåœ¨ä½“ç§¯é€šè¿‡æçº¿çº¦æŸå¼ºåˆ¶å‡ ä½•ä¸€è‡´æ€§ï¼Œç›¸æœºæ„ŸçŸ¥Transformeråˆ©ç”¨æ™®å…‹å°”åæ ‡è¿›è¡Œè‡ªé€‚åº”å¯¹åº”ç»†åŒ–ã€‚æœ¬ç ”ç©¶æ–¹æ³•å¢å¼ºäº†æ³›åŒ–èƒ½åŠ›ï¼Œå¹¶ä¸”æ¯”ç°æœ‰æ–¹æ³•å¿«ä¸¤å€æ”¶æ•›ã€‚ç©ºé—´å¯¹é½åŸºç¡€æ¨¡å‹ä¼˜äºè¯­ä¹‰å¯¹é½æ¨¡å‹ï¼Œè§£å†³äº†è¯­ä¹‰è¡¨ç¤ºä¸ç©ºé—´é‡å»ºéœ€æ±‚çš„ä¸åŒ¹é…é—®é¢˜ã€‚æœ¬æ–¹æ³•æ”¯æŒå¤šç§é«˜åˆ†è¾¨ç‡è§†å›¾è¾“å…¥å¹¶æ˜¾ç¤ºå‡ºè‰²çš„è·¨æ•°æ®é›†æ³›åŒ–èƒ½åŠ›ã€‚å®éªŒæ˜¾ç¤ºåœ¨å¤šåŸºå‡†æµ‹è¯•ä¸­å‡å–å¾—æœ€æ–°æ°´å¹³çš„æ€§èƒ½æå‡ï¼Œå¦‚åœ¨RealEstate10Kã€ACIDå’ŒDTUæ•°æ®é›†ä¸Šçš„PSNRæå‡åˆ†åˆ«ä¸º0.59 dBã€1.06 dBå’Œ0.22 dBã€‚ä»£ç å·²å…¬å¼€äºGitHubä¸Šã€‚</p>
<p><strong>å…³é”®è§è§£</strong></p>
<ol>
<li>æå‡ºäº†ä¸€ç§æ··åˆæ¡†æ¶H3Ræ¥è§£å†³å¤šè§†å›¾é‡å»ºä¸­çš„æŒ‘æˆ˜æ€§é—®é¢˜ï¼Œç»“åˆäº†ä½“ç§¯æ½œåœ¨èåˆå’ŒåŸºäºæ³¨æ„åŠ›çš„ç‰¹å¾èšåˆã€‚</li>
<li>é€šè¿‡é«˜æ•ˆæ½œåœ¨ä½“ç§¯å’Œç›¸æœºæ„ŸçŸ¥Transformerå®ç°å‡ ä½•ä¸€è‡´æ€§å’Œè‡ªé€‚åº”å¯¹åº”ç»†åŒ–ã€‚</li>
<li>æ–¹æ³•å¢å¼ºäº†æ³›åŒ–èƒ½åŠ›å¹¶æé«˜äº†æ”¶æ•›é€Ÿåº¦ï¼Œæ¯”ç°æœ‰æ–¹æ³•å¿«ä¸¤å€ã€‚</li>
<li>ç©ºé—´å¯¹é½åŸºç¡€æ¨¡å‹ç›¸è¾ƒäºè¯­ä¹‰å¯¹é½æ¨¡å‹å±•ç°å‡ºæ›´å¥½çš„æ€§èƒ½ï¼Œè§£å†³äº†è¯­ä¹‰è¡¨ç¤ºä¸ç©ºé—´é‡å»ºéœ€æ±‚çš„ä¸åŒ¹é…é—®é¢˜ã€‚</li>
<li>æ–¹æ³•æ”¯æŒå¤šç§é«˜åˆ†è¾¨ç‡è§†å›¾è¾“å…¥å¹¶å…·æœ‰è‰¯å¥½çš„è·¨æ•°æ®é›†æ³›åŒ–èƒ½åŠ›ã€‚</li>
<li>åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­å–å¾—äº†æœ€æ–°æ°´å¹³çš„æ€§èƒ½æå‡ï¼ŒåŒ…æ‹¬RealEstate10Kã€ACIDå’ŒDTUæ•°æ®é›†ä¸Šçš„PSNRæŒ‡æ ‡æå‡ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.03118">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-ffdc1eaf3960ee251107be10e0323022.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-bd840f1ec4da6dca9ba9a2f0c1077ef6.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e929c67630baa9175add1adf4a3cab33.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-14fdc67b9580e8d293879a7af3077a00.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-86ef993c370d32a350af22cda38b0177.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-5b6695b2414de6294c31d74cab4731df.jpg" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1><h2 id="RobustGS-Unified-Boosting-of-Feedforward-3D-Gaussian-Splatting-under-Low-Quality-Conditions"><a href="#RobustGS-Unified-Boosting-of-Feedforward-3D-Gaussian-Splatting-under-Low-Quality-Conditions" class="headerlink" title="RobustGS: Unified Boosting of Feedforward 3D Gaussian Splatting under   Low-Quality Conditions"></a>RobustGS: Unified Boosting of Feedforward 3D Gaussian Splatting under   Low-Quality Conditions</h2><p><strong>Authors:Anran Wu, Long Peng, Xin Di, Xueyuan Dai, Chen Wu, Yang Wang, Xueyang Fu, Yang Cao, Zheng-Jun Zha</strong></p>
<p>Feedforward 3D Gaussian Splatting (3DGS) overcomes the limitations of optimization-based 3DGS by enabling fast and high-quality reconstruction without the need for per-scene optimization. However, existing feedforward approaches typically assume that input multi-view images are clean and high-quality. In real-world scenarios, images are often captured under challenging conditions such as noise, low light, or rain, resulting in inaccurate geometry and degraded 3D reconstruction. To address these challenges, we propose a general and efficient multi-view feature enhancement module, RobustGS, which substantially improves the robustness of feedforward 3DGS methods under various adverse imaging conditions, enabling high-quality 3D reconstruction. The RobustGS module can be seamlessly integrated into existing pretrained pipelines in a plug-and-play manner to enhance reconstruction robustness. Specifically, we introduce a novel component, Generalized Degradation Learner, designed to extract generic representations and distributions of multiple degradations from multi-view inputs, thereby enhancing degradation-awareness and improving the overall quality of 3D reconstruction. In addition, we propose a novel semantic-aware state-space model. It first leverages the extracted degradation representations to enhance corrupted inputs in the feature space. Then, it employs a semantic-aware strategy to aggregate semantically similar information across different views, enabling the extraction of fine-grained cross-view correspondences and further improving the quality of 3D representations. Extensive experiments demonstrate that our approach, when integrated into existing methods in a plug-and-play manner, consistently achieves state-of-the-art reconstruction quality across various types of degradations. </p>
<blockquote>
<p>Feedforward 3D Gaussian Splattingï¼ˆ3DGSï¼‰é€šè¿‡å®ç°å¿«é€Ÿä¸”é«˜è´¨é‡çš„é‡å»ºï¼Œå…‹æœäº†åŸºäºä¼˜åŒ–çš„3DGSçš„å±€é™æ€§ï¼Œæ— éœ€é’ˆå¯¹æ¯ä¸ªåœºæ™¯è¿›è¡Œä¼˜åŒ–ã€‚ç„¶è€Œï¼Œç°æœ‰çš„å‰é¦ˆæ–¹æ³•é€šå¸¸å‡è®¾è¾“å…¥çš„å¤šè§†è§’å›¾åƒæ˜¯å¹²å‡€ä¸”é«˜è´¨é‡çš„ã€‚åœ¨çœŸå®åœºæ™¯ä¸­ï¼Œå›¾åƒé€šå¸¸æ˜¯åœ¨å™ªå£°ã€ä½å…‰æˆ–é›¨å¤©ç­‰å…·æœ‰æŒ‘æˆ˜æ€§çš„æ¡ä»¶ä¸‹æ•è·çš„ï¼Œå¯¼è‡´å‡ ä½•ä¸å‡†ç¡®å’Œ3Dé‡å»ºè´¨é‡ä¸‹é™ã€‚ä¸ºäº†è§£å†³è¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§é€šç”¨ä¸”é«˜æ•ˆçš„å¤šè§†è§’ç‰¹å¾å¢å¼ºæ¨¡å—â€”â€”RobustGSã€‚è¯¥æ¨¡å—åœ¨å„ç§ä¸åˆ©çš„æˆåƒæ¡ä»¶ä¸‹å¤§å¤§æé«˜äº†å‰é¦ˆ3DGSæ–¹æ³•çš„ç¨³å¥æ€§ï¼Œå®ç°äº†é«˜è´¨é‡çš„3Dé‡å»ºã€‚RobustGSæ¨¡å—å¯ä»¥æ— ç¼åœ°ä»¥å³æ’å³ç”¨æ–¹å¼é›†æˆåˆ°ç°æœ‰çš„é¢„è®­ç»ƒç®¡é“ä¸­ï¼Œä»¥å¢å¼ºé‡å»ºçš„ç¨³å¥æ€§ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ä¸ªåä¸ºGeneralized Degradation Learnerçš„æ–°ç»„ä»¶ï¼Œæ—¨åœ¨ä»å¤šè§†è§’è¾“å…¥ä¸­æå–å¤šç§é™è´¨çš„é€šç”¨è¡¨ç¤ºå’Œåˆ†å¸ƒï¼Œä»è€Œæé«˜å¯¹é™è´¨çš„æ„ŸçŸ¥èƒ½åŠ›ï¼Œå¹¶æ”¹å–„3Dé‡å»ºçš„æ•´ä½“è´¨é‡ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°çš„è¯­ä¹‰æ„ŸçŸ¥çŠ¶æ€ç©ºé—´æ¨¡å‹ã€‚å®ƒé¦–å…ˆåˆ©ç”¨æå–çš„é™è´¨è¡¨ç¤ºæ¥å¢å¼ºç‰¹å¾ç©ºé—´ä¸­çš„å—æŸè¾“å…¥ã€‚ç„¶åï¼Œå®ƒé‡‡ç”¨è¯­ä¹‰æ„ŸçŸ¥ç­–ç•¥æ¥èšåˆä¸åŒè§†è§’ä¸‹çš„è¯­ä¹‰ç›¸ä¼¼ä¿¡æ¯ï¼Œä»è€Œå®ç°ç²¾ç»†çš„è·¨è§†è§’å¯¹åº”å…³ç³»çš„æå–ï¼Œå¹¶è¿›ä¸€æ­¥æé«˜äº†3Dè¡¨ç¤ºçš„è´¨é‡ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•ä»¥å³æ’å³ç”¨æ–¹å¼é›†æˆåˆ°ç°æœ‰æ–¹æ³•ä¸­æ—¶ï¼Œåœ¨å„ç§ç±»å‹çš„é™è´¨æƒ…å†µä¸‹å§‹ç»ˆå®ç°äº†æœ€å…ˆè¿›çš„é‡å»ºè´¨é‡ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.03077v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†Feedforward 3D Gaussian Splattingï¼ˆ3DGSï¼‰çš„ä¼˜åŠ¿ï¼Œå…¶å…‹æœäº†åŸºäºä¼˜åŒ–çš„3DGSæ–¹æ³•çš„å±€é™æ€§ï¼Œå®ç°äº†å¿«é€Ÿä¸”é«˜è´¨é‡çš„é‡å»ºã€‚ä½†ç°æœ‰å‰é¦ˆæ–¹æ³•é€šå¸¸å‡è®¾è¾“å…¥çš„å¤šè§†è§’å›¾åƒæ˜¯å¹²å‡€ä¸”é«˜è´¨é‡çš„ã€‚é’ˆå¯¹ç°å®ä¸–ç•Œä¸­å›¾åƒç»å¸¸å­˜åœ¨çš„å™ªå£°ã€ä½å…‰ã€é›¨å¤©ç­‰æŒ‘æˆ˜æ¡ä»¶ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ä¸ªé€šç”¨ä¸”é«˜æ•ˆçš„å¤šè§†è§’ç‰¹å¾å¢å¼ºæ¨¡å—â€”â€”RobustGSï¼Œè¯¥æ¨¡å—æ˜¾è‘—æé«˜äº†å‰é¦ˆ3DGSæ–¹æ³•åœ¨å¤šç§ä¸è‰¯æˆåƒæ¡ä»¶ä¸‹çš„ç¨³å¥æ€§ï¼Œå®ç°äº†é«˜è´¨é‡çš„ä¸‰ç»´é‡å»ºã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>Feedforward 3D Gaussian Splatting (3DGS)å®ç°äº†å¿«é€Ÿä¸”é«˜è´¨é‡çš„é‡å»ºï¼Œå…‹æœäº†ä¼˜åŒ–æ–¹æ³•çš„å±€é™æ€§ã€‚</li>
<li>ç°æœ‰å‰é¦ˆæ–¹æ³•å‡è®¾è¾“å…¥çš„å¤šè§†è§’å›¾åƒæ˜¯å¹²å‡€ä¸”é«˜è´¨é‡çš„ï¼Œä½†ç°å®åœºæ™¯ä¸­çš„å›¾åƒå¸¸é¢ä¸´å™ªå£°ã€ä½å…‰ã€é›¨å¤©ç­‰æŒ‘æˆ˜ã€‚</li>
<li>ä¸ºè§£å†³è¿™äº›æŒ‘æˆ˜ï¼Œæå‡ºäº†ä¸€ä¸ªé€šç”¨ä¸”é«˜æ•ˆçš„å¤šè§†è§’ç‰¹å¾å¢å¼ºæ¨¡å—â€”â€”RobustGSã€‚</li>
<li>RobustGSé€šè¿‡å¼•å…¥Generalized Degradation Learnerï¼Œèƒ½å¤Ÿä»å¤šè§†è§’è¾“å…¥ä¸­æå–é€šç”¨çš„é€€åŒ–è¡¨ç¤ºå’Œåˆ†å¸ƒï¼Œå¢å¼ºå¯¹é€€åŒ–çš„æ„ŸçŸ¥ï¼Œæé«˜ä¸‰ç»´é‡å»ºçš„æ•´ä½“è´¨é‡ã€‚</li>
<li>æå‡ºäº†ä¸€ç§æ–°çš„è¯­ä¹‰æ„ŸçŸ¥çŠ¶æ€ç©ºé—´æ¨¡å‹ï¼Œåˆ©ç”¨æå–çš„é€€åŒ–è¡¨ç¤ºåœ¨ç‰¹å¾ç©ºé—´ä¸­å¢å¼ºå—æŸè¾“å…¥ï¼Œå¹¶é€šè¿‡è¯­ä¹‰æ„ŸçŸ¥ç­–ç•¥èšåˆä¸åŒè§†è§’çš„è¯­ä¹‰ç›¸ä¼¼ä¿¡æ¯ï¼Œè¿›ä¸€æ­¥æé«˜äº†ä¸‰ç»´è¡¨ç¤ºçš„è´¨é‡ã€‚</li>
<li>å®éªŒè¡¨æ˜ï¼ŒRobustGSæ¨¡å—èƒ½æ— ç¼é›†æˆåˆ°ç°æœ‰çš„é¢„è®­ç»ƒç®¡é“ä¸­ï¼Œä»¥å³æ’å³ç”¨æ–¹å¼æé«˜äº†å„ç§é€€åŒ–ç±»å‹ä¸‹çš„é‡å»ºè´¨é‡ï¼Œè¾¾åˆ°ä¸šç•Œé¢†å…ˆæ°´å¹³ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.03077">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-e95a5653d98606f56f8b59891feb57ee.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-d895ddc6c120bbbcd5df0ee35e6b495c.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-3630fc2652660fa9a07ce3088efc3a1a.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-8ae3e8d67b73d7daf8cde4f48c3a1b28.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-acb4a7b3fe3bf398f25583cdd73c8284.jpg" align="middle">
</details>


<h1 id="-9"><a href="#-9" class="headerlink" title=""></a></h1><h2 id="SA-3DGS-A-Self-Adaptive-Compression-Method-for-3D-Gaussian-Splatting"><a href="#SA-3DGS-A-Self-Adaptive-Compression-Method-for-3D-Gaussian-Splatting" class="headerlink" title="SA-3DGS: A Self-Adaptive Compression Method for 3D Gaussian Splatting"></a>SA-3DGS: A Self-Adaptive Compression Method for 3D Gaussian Splatting</h2><p><strong>Authors:Liheng Zhang, Weihao Yu, Zubo Lu, Haozhi Gu, Jin Huang</strong></p>
<p>Recent advancements in 3D Gaussian Splatting have enhanced efficient and high-quality novel view synthesis. However, representing scenes requires a large number of Gaussian points, leading to high storage demands and limiting practical deployment. The latest methods facilitate the compression of Gaussian models but struggle to identify truly insignificant Gaussian points in the scene, leading to a decline in subsequent Gaussian pruning, compression quality, and rendering performance. To address this issue, we propose SA-3DGS, a method that significantly reduces storage costs while maintaining rendering quality. SA-3DGS learns an importance score to automatically identify the least significant Gaussians in scene reconstruction, thereby enabling effective pruning and redundancy reduction. Next, the importance-aware clustering module compresses Gaussians attributes more accurately into the codebook, improving the codebookâ€™s expressive capability while reducing model size. Finally, the codebook repair module leverages contextual scene information to repair the codebook, thereby recovering the original Gaussian point attributes and mitigating the degradation in rendering quality caused by information loss. Experimental results on several benchmark datasets show that our method achieves up to 66x compression while maintaining or even improving rendering quality. The proposed Gaussian pruning approach is not only adaptable to but also improves other pruning-based methods (e.g., LightGaussian), showcasing excellent performance and strong generalization ability. </p>
<blockquote>
<p>è¿‘æœŸï¼Œ3Dé«˜æ–¯è´´å›¾æŠ€æœ¯çš„æ–°è¿›å±•å¤§å¤§æé«˜äº†é«˜æ•ˆé«˜è´¨é‡çš„æ–°å‹è§†å›¾åˆæˆèƒ½åŠ›ã€‚ç„¶è€Œï¼Œè¡¨ç¤ºåœºæ™¯éœ€è¦å¤§é‡çš„é«˜æ–¯ç‚¹ï¼Œè¿™å¯¼è‡´äº†å­˜å‚¨éœ€æ±‚çš„å¢åŠ å¹¶é™åˆ¶äº†å®é™…åº”ç”¨éƒ¨ç½²ã€‚æœ€æ–°çš„æ–¹æ³•è™½ç„¶æ¨åŠ¨äº†é«˜æ–¯æ¨¡å‹çš„å‹ç¼©ï¼Œä½†åœ¨è¯†åˆ«åœºæ™¯ä¸­çœŸæ­£ä¸æ˜¾è‘—çš„é«˜æ–¯ç‚¹æ—¶é‡åˆ°å›°éš¾ï¼Œå¯¼è‡´åç»­çš„é«˜æ–¯ä¿®å‰ªã€å‹ç¼©è´¨é‡å’Œæ¸²æŸ“æ€§èƒ½ä¸‹é™ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†SA-3DGSæ–¹æ³•ï¼Œå®ƒèƒ½åœ¨ä¿æŒæ¸²æŸ“è´¨é‡çš„åŒæ—¶æ˜¾è‘—é™ä½å­˜å‚¨æˆæœ¬ã€‚SA-3DGSå­¦ä¹ é‡è¦æ€§è¯„åˆ†æ¥è‡ªåŠ¨è¯†åˆ«åœºæ™¯é‡å»ºä¸­æœ€ä¸é‡è¦çš„é«˜æ–¯ï¼Œä»è€Œå®ç°æœ‰æ•ˆçš„ä¿®å‰ªå’Œå†—ä½™å‡å°‘ã€‚æ¥ä¸‹æ¥ï¼Œé‡è¦æ€§æ„ŸçŸ¥èšç±»æ¨¡å—å°†é«˜æ–¯å±æ€§æ›´å‡†ç¡®åœ°å‹ç¼©åˆ°ä»£ç ç°¿ä¸­ï¼Œæé«˜äº†ä»£ç ç°¿çš„è¡¨è¾¾èƒ½åŠ›å¹¶å‡å°äº†æ¨¡å‹å¤§å°ã€‚æœ€åï¼Œä»£ç ç°¿ä¿®å¤æ¨¡å—åˆ©ç”¨ä¸Šä¸‹æ–‡åœºæ™¯ä¿¡æ¯æ¥ä¿®å¤ä»£ç ç°¿ï¼Œä»è€Œæ¢å¤åŸå§‹çš„é«˜æ–¯ç‚¹å±æ€§å¹¶ç¼“è§£å› ä¿¡æ¯ä¸¢å¤±è€Œå¯¼è‡´çš„æ¸²æŸ“è´¨é‡ä¸‹é™ã€‚åœ¨å¤šä¸ªåŸºå‡†æ•°æ®é›†ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•èƒ½åœ¨ä¿æŒæˆ–ç”šè‡³æé«˜æ¸²æŸ“è´¨é‡çš„åŒæ—¶å®ç°é«˜è¾¾66å€çš„å‹ç¼©ã€‚æ‰€æå‡ºçš„é«˜æ–¯ä¿®å‰ªæ–¹æ³•ä¸ä»…é€‚ç”¨äºå…¶ä»–ä¿®å‰ªæ–¹æ³•ï¼ˆå¦‚LightGaussianï¼‰ï¼Œè¿˜èƒ½å¯¹å…¶è¿›è¡Œæ”¹è¿›ï¼Œå±•ç°äº†å“è¶Šçš„æ€§èƒ½å’Œå¼ºå¤§çš„æ³›åŒ–èƒ½åŠ›ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.03017v1">PDF</a> 9 pages, 7 figures. Under review at AAAI 2026</p>
<p><strong>Summary</strong><br>     3DGSçš„æœ€æ–°è¿›å±•è™½å¯å®ç°é«˜æ•ˆé«˜è´¨é‡çš„æ–°å‹è§†å›¾åˆæˆï¼Œä½†ç”±äºéœ€è¦å¤§é‡é«˜æ–¯ç‚¹æ¥è¡¨ç¤ºåœºæ™¯ï¼Œå¯¼è‡´å­˜å‚¨éœ€æ±‚å·¨å¤§ä¸”é™åˆ¶äº†å®é™…åº”ç”¨éƒ¨ç½²ã€‚é’ˆå¯¹è¿™ä¸€é—®é¢˜ï¼Œæå‡ºäº†SA-3DGSæ–¹æ³•ï¼Œè¯¥æ–¹æ³•å¯æ˜¾è‘—é™ä½å­˜å‚¨æˆæœ¬åŒæ—¶ä¿æŒæ¸²æŸ“è´¨é‡ã€‚é€šè¿‡é‡è¦æ€§è¯„åˆ†è‡ªåŠ¨è¯†åˆ«åœºæ™¯ä¸­ä¸é‡è¦çš„é«˜æ–¯ç‚¹ä»¥å®ç°æœ‰æ•ˆå‰ªæå’Œå†—ä½™åº¦é™ä½ã€‚åŒæ—¶æ”¹è¿›å‹ç¼©æ¨¡å—ï¼Œåˆ©ç”¨ä¸Šä¸‹æ–‡åœºæ™¯ä¿¡æ¯ä¿®å¤ä»£ç æœ¬ä»¥æ¢å¤åŸå§‹é«˜æ–¯ç‚¹å±æ€§å¹¶ç¼“è§£ä¿¡æ¯æŸå¤±å¯¼è‡´çš„æ¸²æŸ“è´¨é‡ä¸‹é™ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•å¯å®ç°é«˜è¾¾66å€çš„å‹ç¼©æ¯”ï¼ŒåŒæ—¶ä¿æŒæˆ–æé«˜æ¸²æŸ“è´¨é‡ï¼Œå¹¶é€‚ç”¨äºå…¶ä»–å‰ªææ–¹æ³•ï¼Œè¡¨ç°å‡ºå“è¶Šçš„æ€§èƒ½å’Œå¼ºå¤§çš„æ³›åŒ–èƒ½åŠ›ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>3D Gaussian Splattingåœ¨æ–°å‹è§†å›¾åˆæˆä¸­å–å¾—äº†è¿›å±•ï¼Œä½†éœ€è¦å¤§é‡é«˜æ–¯ç‚¹è¡¨ç¤ºåœºæ™¯ï¼Œå¯¼è‡´é«˜å­˜å‚¨éœ€æ±‚å’Œé™åˆ¶å®é™…åº”ç”¨ã€‚</li>
<li>SA-3DGSæ–¹æ³•è¢«æå‡ºä»¥è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œé€šè¿‡é‡è¦æ€§è¯„åˆ†è‡ªåŠ¨è¯†åˆ«ä¸é‡è¦çš„é«˜æ–¯ç‚¹ï¼Œæœ‰æ•ˆå‡å°‘å­˜å‚¨æˆæœ¬å¹¶ä¿æŒæ¸²æŸ“è´¨é‡ã€‚</li>
<li>SA-3DGSåŒ…å«ä¸€ä¸ªé‡è¦æ€§æ„ŸçŸ¥èšç±»æ¨¡å—ï¼Œå¯ä»¥æ›´å‡†ç¡®åœ°å‹ç¼©é«˜æ–¯å±æ€§åˆ°ä»£ç æœ¬ä¸­ï¼Œæé«˜ä»£ç æœ¬çš„è¡¨è¾¾èƒ½åŠ›å¹¶å‡å°æ¨¡å‹å¤§å°ã€‚</li>
<li>ä»£ç æœ¬ä¿®å¤æ¨¡å—åˆ©ç”¨ä¸Šä¸‹æ–‡åœºæ™¯ä¿¡æ¯ä¿®å¤ä»£ç æœ¬ï¼Œæ¢å¤åŸå§‹é«˜æ–¯ç‚¹å±æ€§ï¼Œå¹¶ç¼“è§£å› ä¿¡æ¯æŸå¤±å¯¼è‡´çš„æ¸²æŸ“è´¨é‡ä¸‹é™ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.03017">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-b39127c48ac2214542285783cb9f334c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-9fe1c85a3fb12735d3850924343e4462.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-a37b15291ca6b1869b3b80687c8c3efb.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-2ad5495c670a311f75657b62c598984a.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-cb0b1668b10f7eaced980821e32051a7.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-8bc32c7ccebde062042c96369cedf845.jpg" align="middle">
</details>


<h1 id="-10"><a href="#-10" class="headerlink" title=""></a></h1><h2 id="GENIE-Gaussian-Encoding-for-Neural-Radiance-Fields-Interactive-Editing"><a href="#GENIE-Gaussian-Encoding-for-Neural-Radiance-Fields-Interactive-Editing" class="headerlink" title="GENIE: Gaussian Encoding for Neural Radiance Fields Interactive Editing"></a>GENIE: Gaussian Encoding for Neural Radiance Fields Interactive Editing</h2><p><strong>Authors:MikoÅ‚aj ZieliÅ„ski, Krzysztof Byrski, Tomasz Szczepanik, PrzemysÅ‚aw Spurek</strong></p>
<p>Neural Radiance Fields (NeRF) and Gaussian Splatting (GS) have recently transformed 3D scene representation and rendering. NeRF achieves high-fidelity novel view synthesis by learning volumetric representations through neural networks, but its implicit encoding makes editing and physical interaction challenging. In contrast, GS represents scenes as explicit collections of Gaussian primitives, enabling real-time rendering, faster training, and more intuitive manipulation. This explicit structure has made GS particularly well-suited for interactive editing and integration with physics-based simulation. In this paper, we introduce GENIE (Gaussian Encoding for Neural Radiance Fields Interactive Editing), a hybrid model that combines the photorealistic rendering quality of NeRF with the editable and structured representation of GS. Instead of using spherical harmonics for appearance modeling, we assign each Gaussian a trainable feature embedding. These embeddings are used to condition a NeRF network based on the k nearest Gaussians to each query point. To make this conditioning efficient, we introduce Ray-Traced Gaussian Proximity Search (RT-GPS), a fast nearest Gaussian search based on a modified ray-tracing pipeline. We also integrate a multi-resolution hash grid to initialize and update Gaussian features. Together, these components enable real-time, locality-aware editing: as Gaussian primitives are repositioned or modified, their interpolated influence is immediately reflected in the rendered output. By combining the strengths of implicit and explicit representations, GENIE supports intuitive scene manipulation, dynamic interaction, and compatibility with physical simulation, bridging the gap between geometry-based editing and neural rendering. The code can be found under (<a target="_blank" rel="noopener" href="https://github.com/MikolajZielinski/genie">https://github.com/MikolajZielinski/genie</a>) </p>
<blockquote>
<p>ç¥ç»è¾å°„åœºï¼ˆNeRFï¼‰å’Œé«˜æ–¯æ‹¼è´´ï¼ˆGSï¼‰æœ€è¿‘å·²ç»è½¬å˜äº†3Dåœºæ™¯è¡¨ç¤ºå’Œæ¸²æŸ“çš„æ–¹å¼ã€‚NeRFé€šè¿‡å­¦ä¹ ä½“ç§¯è¡¨ç¤ºé€šè¿‡ç¥ç»ç½‘ç»œå®ç°é«˜ä¿çœŸæ–°é¢–è§†å›¾åˆæˆï¼Œä½†å…¶éšå¼ç¼–ç ä½¿å¾—ç¼–è¾‘å’Œç‰©ç†äº¤äº’å…·æœ‰æŒ‘æˆ˜æ€§ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼ŒGSå°†åœºæ™¯è¡¨ç¤ºä¸ºé«˜æ–¯åŸå§‹æ•°æ®çš„æ˜¾å¼é›†åˆï¼Œä»è€Œå®ç°å®æ—¶æ¸²æŸ“ã€æ›´å¿«çš„è®­ç»ƒå’Œæ›´ç›´è§‚çš„æ“çºµã€‚è¿™ç§æ˜¾å¼ç»“æ„ä½¿GSç‰¹åˆ«é€‚åˆäº¤äº’å¼ç¼–è¾‘å’Œä¸åŸºäºç‰©ç†çš„æ¨¡æ‹Ÿé›†æˆã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬ä»‹ç»äº†GENIEï¼ˆç”¨äºç¥ç»è¾å°„åœºäº¤äº’å¼ç¼–è¾‘çš„é«˜æ–¯ç¼–ç ï¼‰ï¼Œè¿™æ˜¯ä¸€ç§ç»“åˆäº†NeRFçš„å…‰ç…§ç°å®æ¸²æŸ“è´¨é‡å’ŒGSçš„å¯ç¼–è¾‘ç»“æ„åŒ–è¡¨ç¤ºæ–¹æ³•çš„æ··åˆæ¨¡å‹ã€‚æˆ‘ä»¬ä¸ä¸ºå¤–è§‚å»ºæ¨¡ä½¿ç”¨çƒé¢è°æ³¢ï¼Œè€Œæ˜¯ä¸ºæ¯ä¸ªé«˜æ–¯åˆ†é…å¯è®­ç»ƒçš„ç‰¹å¾åµŒå…¥ã€‚è¿™äº›åµŒå…¥è¢«ç”¨äºåŸºäºæ¯ä¸ªæŸ¥è¯¢ç‚¹çš„kä¸ªæœ€è¿‘é«˜æ–¯å€¼æ¥æ¡ä»¶åŒ–NeRFç½‘ç»œã€‚ä¸ºäº†ä½¿è¿™ç§æ¡ä»¶åŒ–æœ‰æ•ˆç‡ï¼Œæˆ‘ä»¬å¼•å…¥äº†åŸºäºä¿®æ”¹åçš„å…‰çº¿è¿½è¸ªç®¡é“çš„å¿«é€Ÿæœ€è¿‘é«˜æ–¯æœç´¢â€”â€”å°„çº¿è¿½è¸ªé«˜æ–¯é‚»è¿‘æœç´¢ï¼ˆRT-GPSï¼‰ã€‚æˆ‘ä»¬è¿˜é›†æˆäº†ä¸€ç§å¤šåˆ†è¾¨ç‡å“ˆå¸Œç½‘æ ¼æ¥åˆå§‹åŒ–å’Œæ›´æ–°é«˜æ–¯ç‰¹å¾ã€‚è¿™äº›ç»„ä»¶å…±åŒä½œç”¨ï¼Œå¯å®ç°å®æ—¶ã€å±€éƒ¨æ„ŸçŸ¥çš„ç¼–è¾‘ï¼šå½“é«˜æ–¯åŸå§‹æ•°æ®è¢«é‡æ–°å®šä½æˆ–ä¿®æ”¹æ—¶ï¼Œå…¶æ’å€¼å½±å“ä¼šç«‹å³åæ˜ åœ¨æ¸²æŸ“è¾“å‡ºä¸­ã€‚é€šè¿‡ç»“åˆéšå¼å’Œæ˜¾å¼è¡¨ç¤ºçš„ä¼˜ç‚¹ï¼ŒGENIEæ”¯æŒç›´è§‚çš„åœºæ™¯æ“ä½œã€åŠ¨æ€äº¤äº’ä»¥åŠä¸ç‰©ç†æ¨¡æ‹Ÿçš„å…¼å®¹æ€§ï¼Œç¼©å°äº†åŸºäºå‡ ä½•çš„ç¼–è¾‘å’Œç¥ç»æ¸²æŸ“ä¹‹é—´çš„å·®è·ã€‚ä»£ç å¯åœ¨ï¼ˆ<a target="_blank" rel="noopener" href="https://github.com/MikolajZielinski/genie%EF%BC%89%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/MikolajZielinski/genieï¼‰æ‰¾åˆ°ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.02831v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>ç¥ç»è¾å°„åœºï¼ˆNeRFï¼‰å’Œé«˜æ–¯å–·ç»˜ï¼ˆGSï¼‰åœ¨ä¸‰ç»´åœºæ™¯è¡¨è¾¾å’Œæ¸²æŸ“æ–¹é¢å–å¾—äº†çªç ´æ€§è¿›å±•ã€‚NeRFé€šè¿‡ç¥ç»ç½‘ç»œå­¦ä¹ ä½“ç§¯è¡¨è¾¾ä»¥å®ç°é«˜ä¿çœŸæ–°è§†è§’åˆæˆï¼Œä½†å…¶éšå¼ç¼–ç ä½¿å¾—ç¼–è¾‘å’Œç‰©ç†äº¤äº’å…·æœ‰æŒ‘æˆ˜æ€§ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼ŒGSå°†åœºæ™¯è¡¨ç¤ºä¸ºæ˜¾å¼çš„é«˜æ–¯åŸºæœ¬å…ƒç´ é›†åˆï¼Œå®ç°äº†å®æ—¶æ¸²æŸ“ã€å¿«é€Ÿè®­ç»ƒå’Œæ›´ç›´è§‚çš„æ“æ§ã€‚æœ¬æ–‡æå‡ºGENIEï¼ˆç¥ç»è¾å°„åœºçš„é«˜æ–¯ç¼–ç äº¤äº’å¼ç¼–è¾‘ï¼‰ï¼Œç»“åˆäº†NeRFçš„å…‰ç…§ç°å®æ¸²æŸ“è´¨é‡ä¸GSçš„å¯ç¼–è¾‘å’Œç»“æ„åŒ–è¡¨è¾¾ã€‚GENIEé€šè¿‡ä¸ºæ¯ä¸ªé«˜æ–¯åˆ†é…å¯è®­ç»ƒç‰¹å¾åµŒå…¥è¿›è¡Œå¤–è§‚å»ºæ¨¡ï¼Œè€Œä¸æ˜¯ä½¿ç”¨çƒé¢è°æ³¢ã€‚è¿™äº›åµŒå…¥è¢«ç”¨äºåŸºäºæ¯ä¸ªæŸ¥è¯¢ç‚¹çš„kä¸ªæœ€è¿‘é«˜æ–¯å€¼æ¥æ¡ä»¶åŒ–NeRFç½‘ç»œã€‚ä¸ºæå‡æ•ˆç‡ï¼Œæœ¬æ–‡å¼•å…¥äº†åŸºäºä¿®æ”¹åçš„å…‰çº¿è¿½è¸ªç®¡é“çš„å¿«é€Ÿæœ€è¿‘é«˜æ–¯æœç´¢æŠ€æœ¯â€”â€”å°„çº¿è¿½è¸ªé«˜æ–¯é‚»è¿‘æœç´¢ï¼ˆRT-GPSï¼‰ã€‚åŒæ—¶ï¼Œé›†æˆäº†å¤šåˆ†è¾¨ç‡å“ˆå¸Œç½‘æ ¼ä»¥åˆå§‹åŒ–å’Œæ›´æ–°é«˜æ–¯ç‰¹å¾ã€‚è¿™äº›ç»„ä»¶å…±åŒå®ç°äº†å®æ—¶ã€å±€éƒ¨æ„ŸçŸ¥çš„ç¼–è¾‘åŠŸèƒ½ï¼šå½“é«˜æ–¯åŸºæœ¬å…ƒç´ è¢«é‡æ–°å®šä½æˆ–ä¿®æ”¹æ—¶ï¼Œå…¶æ’å€¼å½±å“ä¼šç«‹å³åæ˜ åœ¨æ¸²æŸ“è¾“å‡ºä¸­ã€‚GENIEç»“åˆäº†éšå¼å’Œæ˜¾å¼è¡¨è¾¾çš„ä¼˜ç‚¹ï¼Œæ”¯æŒç›´è§‚çš„åœºæ™¯æ“æ§ã€åŠ¨æ€äº¤äº’ä»¥åŠä¸ç‰©ç†æ¨¡æ‹Ÿçš„å…¼å®¹æ€§ï¼Œç¼©å°äº†åŸºäºå‡ ä½•çš„ç¼–è¾‘å’Œç¥ç»æ¸²æŸ“ä¹‹é—´çš„å·®è·ã€‚ä»£ç å¯é€šè¿‡ï¼ˆ<a target="_blank" rel="noopener" href="https://github.com/MikolajZielinski/genie%EF%BC%89%E8%AE%BF%E9%97%AE%E3%80%82">https://github.com/MikolajZielinski/genieï¼‰è®¿é—®ã€‚</a></p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>NeRFå’ŒGSåœ¨3Dåœºæ™¯è¡¨è¾¾å’Œæ¸²æŸ“æ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œä½†å„æœ‰å±€é™æ€§ã€‚</li>
<li>GENIEç»“åˆäº†NeRFå’ŒGSçš„ä¼˜ç‚¹ï¼Œå®ç°é«˜ä¿çœŸæ¸²æŸ“ä¸å®æ—¶ã€å±€éƒ¨æ„ŸçŸ¥çš„ç¼–è¾‘åŠŸèƒ½ã€‚</li>
<li>GENIEé‡‡ç”¨é«˜æ–¯ç‰¹å¾åµŒå…¥è¿›è¡Œå¤–è§‚å»ºæ¨¡ï¼Œæ›¿ä»£äº†çƒé¢è°æ³¢æ–¹æ³•ã€‚</li>
<li>RT-GPSæŠ€æœ¯æé«˜äº†åŸºäºé«˜æ–¯é‚»è¿‘æœç´¢çš„æ•ˆç‡ã€‚</li>
<li>å¤šåˆ†è¾¨ç‡å“ˆå¸Œç½‘æ ¼ç”¨äºåˆå§‹åŒ–å’Œæ›´æ–°é«˜æ–¯ç‰¹å¾ã€‚</li>
<li>GENIEæ”¯æŒç›´è§‚çš„åœºæ™¯æ“æ§å’ŒåŠ¨æ€äº¤äº’ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.02831">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-e2c4c006deb2aa65e0c9dec5a5886ac6.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-423ea2c8f8b707224bc611837cfea5a4.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-6bbec3f0559a96a124c722f82ec766bc.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-a8bb56f50690c907c2ae50fd9e18e3e6.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-993037dbe9087953a523c496c7debfd0.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d224525486436d37cb3eb931a5d39138.jpg" align="middle">
</details>


<h1 id="-11"><a href="#-11" class="headerlink" title=""></a></h1><h2 id="Low-Frequency-First-Eliminating-Floating-Artifacts-in-3D-Gaussian-Splatting"><a href="#Low-Frequency-First-Eliminating-Floating-Artifacts-in-3D-Gaussian-Splatting" class="headerlink" title="Low-Frequency First: Eliminating Floating Artifacts in 3D Gaussian   Splatting"></a>Low-Frequency First: Eliminating Floating Artifacts in 3D Gaussian   Splatting</h2><p><strong>Authors:Jianchao Wang, Peng Zhou, Cen Li, Rong Quan, Jie Qin</strong></p>
<p>3D Gaussian Splatting (3DGS) is a powerful and computationally efficient representation for 3D reconstruction. Despite its strengths, 3DGS often produces floating artifacts, which are erroneous structures detached from the actual geometry and significantly degrade visual fidelity. The underlying mechanisms causing these artifacts, particularly in low-quality initialization scenarios, have not been fully explored. In this paper, we investigate the origins of floating artifacts from a frequency-domain perspective and identify under-optimized Gaussians as the primary source. Based on our analysis, we propose \textit{Eliminating-Floating-Artifacts} Gaussian Splatting (EFA-GS), which selectively expands under-optimized Gaussians to prioritize accurate low-frequency learning. Additionally, we introduce complementary depth-based and scale-based strategies to dynamically refine Gaussian expansion, effectively mitigating detail erosion. Extensive experiments on both synthetic and real-world datasets demonstrate that EFA-GS substantially reduces floating artifacts while preserving high-frequency details, achieving an improvement of 1.68 dB in PSNR over baseline method on our RWLQ dataset. Furthermore, we validate the effectiveness of our approach in downstream 3D editing tasks. We provide our implementation in <a target="_blank" rel="noopener" href="https://jcwang-gh.github.io/EFA-GS">https://jcwang-gh.github.io/EFA-GS</a>. </p>
<blockquote>
<p>3Dé«˜æ–¯å±•å¹³ï¼ˆ3DGSï¼‰æ˜¯ä¸€ç§å¼ºå¤§çš„è®¡ç®—æ•ˆç‡é«˜çš„ä¸‰ç»´é‡å»ºè¡¨ç¤ºæ–¹æ³•ã€‚å°½ç®¡å®ƒå…·æœ‰å¼ºå¤§çš„èƒ½åŠ›ï¼Œä½†3DGSç»å¸¸ä¼šäº§ç”Ÿæ¼‚æµ®çš„ä¼ªå½±ï¼Œè¿™äº›ä¼ªå½±æ˜¯è„±ç¦»å®é™…å‡ ä½•ç»“æ„çš„é”™è¯¯ç»“æ„ï¼Œå¹¶ä¸¥é‡é™ä½äº†è§†è§‰ä¿çœŸåº¦ã€‚ç‰¹åˆ«æ˜¯åœ¨ä½è´¨é‡åˆå§‹åŒ–åœºæ™¯ä¸­å¯¼è‡´è¿™äº›ä¼ªå½±çš„æ½œåœ¨æœºåˆ¶å°šæœªè¢«å®Œå…¨æ¢ç´¢ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬ä»é¢‘ç‡åŸŸçš„è§’åº¦ç ”ç©¶äº†æ¼‚æµ®ä¼ªå½±çš„èµ·æºï¼Œå¹¶ç¡®å®šäº†æœªä¼˜åŒ–çš„é«˜æ–¯ä¸ºä¸»è¦æ¥æºã€‚åŸºäºæˆ‘ä»¬çš„åˆ†æï¼Œæˆ‘ä»¬æå‡ºäº†æ¶ˆé™¤æ¼‚æµ®ä¼ªå½±çš„é«˜æ–¯å±•å¹³ï¼ˆEFA-GSï¼‰ï¼Œå®ƒé€‰æ‹©æ€§åœ°æ‰©å±•æœªä¼˜åŒ–çš„é«˜æ–¯ï¼Œä»¥ä¼˜å…ˆè¿›è¡Œå‡†ç¡®çš„ä½é¢‘å­¦ä¹ ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜å¼•å…¥äº†åŸºäºæ·±åº¦å’ŒåŸºäºå°ºåº¦çš„ç­–ç•¥æ¥åŠ¨æ€ä¼˜åŒ–é«˜æ–¯æ‰©å±•ï¼Œæœ‰æ•ˆåœ°å‡è½»äº†ç»†èŠ‚æµå¤±ã€‚åœ¨åˆæˆå’ŒçœŸå®ä¸–ç•Œæ•°æ®é›†ä¸Šçš„å¤§é‡å®éªŒè¡¨æ˜ï¼ŒEFA-GSåœ¨å‡å°‘æ¼‚æµ®ä¼ªå½±çš„åŒæ—¶ä¿ç•™äº†é«˜é¢‘ç»†èŠ‚ï¼Œåœ¨æˆ‘ä»¬çš„RWLQæ•°æ®é›†ä¸Šæ¯”åŸºçº¿æ–¹æ³•æé«˜äº†1.68dBçš„PSNRã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬åœ¨ä¸‹æ¸¸çš„ä¸‰ç»´ç¼–è¾‘ä»»åŠ¡ä¸­éªŒè¯äº†æˆ‘ä»¬çš„æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚æˆ‘ä»¬åœ¨<a target="_blank" rel="noopener" href="https://jcwang-gh.github.io/EFA-GS%E6%8F%90%E4%BE%9B%E4%BA%86%E6%88%91%E4%BB%AC%E7%9A%84%E5%AE%9E%E7%8E%B0%E3%80%82">https://jcwang-gh.github.io/EFA-GSæä¾›äº†æˆ‘ä»¬çš„å®ç°ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.02493v2">PDF</a> Project Website: <a target="_blank" rel="noopener" href="https://jcwang-gh.github.io/EFA-GS">https://jcwang-gh.github.io/EFA-GS</a></p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ç ”ç©¶äº†åŸºäºä¸‰ç»´é«˜æ–¯èåˆï¼ˆ3DGSï¼‰ä¸­çš„æ¼‚æµ®ç‰©å¹²æ‰°é—®é¢˜ï¼Œæ­ç¤ºäº†å¹²æ‰°å‡ºç°çš„åº•å±‚æœºåˆ¶ä¸»è¦æ¥æºäºæ¬ ä¼˜åŒ–çš„é«˜æ–¯æˆåˆ†ã€‚ä¸ºæ”¹å–„è¿™ä¸€ç°è±¡ï¼Œæœ¬æ–‡æå‡ºäº†æ¶ˆé™¤æ¼‚æµ®ç‰©å¹²æ‰°çš„é«˜æ–¯èåˆï¼ˆEFA-GSï¼‰æ–¹æ³•ã€‚æ­¤æ–¹æ³•é‡‡ç”¨é€‰æ‹©æ€§æ‹“å±•æ¬ ä¼˜åŒ–é«˜æ–¯æˆåˆ†çš„æ–¹å¼ä¼˜å…ˆè¿›è¡Œä½é¢‘å­¦ä¹ ã€‚æ­¤å¤–ï¼Œç»“åˆæ·±åº¦ä¿¡æ¯ä¸å°ºåº¦ä¿¡æ¯çš„é«˜æ–¯å±•å¼€ç»†åŒ–ç­–ç•¥èƒ½æ˜¾è‘—å‡è½»ç»†èŠ‚ä¾µèš€ç°è±¡ã€‚å®éªŒç»“æœè¯æ˜äº†è¯¥ç®—æ³•åœ¨å¤„ç†åˆæˆä¸çœŸå®æ•°æ®é›†æ—¶èƒ½æœ‰æ•ˆå‡å°‘æ¼‚æµ®ç‰©å¹²æ‰°å¹¶ä¿ç•™é«˜é¢‘ç»†èŠ‚ï¼Œç›¸è¾ƒäºåŸºå‡†æ–¹æ³•ï¼Œåœ¨PSNRä¸Šæå‡äº†1.68dBã€‚ç›¸å…³ä»£ç å·²å…¬å¼€äºGitHubä¸Šã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>3DGSåœ¨å¤„ç†è¿‡ç¨‹ä¸­å­˜åœ¨æ¼‚æµ®ç‰©å¹²æ‰°é—®é¢˜ï¼Œè¿™äº›å¹²æ‰°å¯èƒ½å½±å“é‡å»ºçš„å‡ ä½•ç»“æ„å¹¶é™ä½è§†è§‰è´¨é‡ã€‚</li>
<li>æ¼‚æµ®ç‰©å¹²æ‰°çš„ä¸»è¦æ¥æºæ˜¯æ¬ ä¼˜åŒ–çš„é«˜æ–¯æˆåˆ†ï¼Œæœ¬æ–‡é¦–æ¬¡ä»é¢‘ç‡åŸŸè§’åº¦æ¢è®¨äº†å…¶æˆå› ã€‚</li>
<li>æå‡ºEFA-GSç®—æ³•ï¼Œé€šè¿‡é€‰æ‹©æ€§æ‹“å±•æ¬ ä¼˜åŒ–é«˜æ–¯æˆåˆ†ä¼˜å…ˆè¿›è¡Œä½é¢‘å­¦ä¹ ï¼Œä»¥æ”¹å–„æ¼‚æµ®ç‰©å¹²æ‰°é—®é¢˜ã€‚</li>
<li>ç»“åˆæ·±åº¦ä¿¡æ¯ä¸å°ºåº¦ä¿¡æ¯çš„é«˜æ–¯å±•å¼€ç»†åŒ–ç­–ç•¥èƒ½æ›´æœ‰æ•ˆåœ°å‡è½»ç»†èŠ‚ä¾µèš€ç°è±¡ã€‚</li>
<li>å®éªŒç»“æœæ˜¾ç¤ºï¼ŒEFA-GSåœ¨å‡å°‘æ¼‚æµ®ç‰©å¹²æ‰°çš„åŒæ—¶ä¿ç•™äº†é«˜é¢‘ç»†èŠ‚ï¼Œç›¸è¾ƒäºåŸºå‡†æ–¹æ³•æ€§èƒ½æœ‰æ‰€æå‡ã€‚</li>
<li>è¯¥ç ”ç©¶åœ¨ä¸‹æ¸¸çš„ä¸‰ç»´ç¼–è¾‘ä»»åŠ¡ä¸­ä¹ŸéªŒè¯äº†å…¶æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.02493">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-93e2c1e9796df44cf12190bc43281858.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-117c7e3e3b6c744becae67d57fae9b05.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-a112c67235b5a5382f10e68961fd309c.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-89f328c97d98d632f2f99fe98b02a89d.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-5196a78d1579933ee7c75c7a6eeb1aea.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-089702deaf1b6f96008ea4616aaab870.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-15da56edf6e5c5327ba86658aadf901a.jpg" align="middle">
</details>


<h1 id="-12"><a href="#-12" class="headerlink" title=""></a></h1><h2 id="Taking-Language-Embedded-3D-Gaussian-Splatting-into-the-Wild"><a href="#Taking-Language-Embedded-3D-Gaussian-Splatting-into-the-Wild" class="headerlink" title="Taking Language Embedded 3D Gaussian Splatting into the Wild"></a>Taking Language Embedded 3D Gaussian Splatting into the Wild</h2><p><strong>Authors:Yuze Wang, Yue Qi</strong></p>
<p>Recent advances in leveraging large-scale Internet photo collections for 3D reconstruction have enabled immersive virtual exploration of landmarks and historic sites worldwide. However, little attention has been given to the immersive understanding of architectural styles and structural knowledge, which remains largely confined to browsing static text-image pairs. Therefore, can we draw inspiration from 3D in-the-wild reconstruction techniques and use unconstrained photo collections to create an immersive approach for understanding the 3D structure of architectural components? To this end, we extend language embedded 3D Gaussian splatting (3DGS) and propose a novel framework for open-vocabulary scene understanding from unconstrained photo collections. Specifically, we first render multiple appearance images from the same viewpoint as the unconstrained image with the reconstructed radiance field, then extract multi-appearance CLIP features and two types of language feature uncertainty maps-transient and appearance uncertainty-derived from the multi-appearance features to guide the subsequent optimization process. Next, we propose a transient uncertainty-aware autoencoder, a multi-appearance language field 3DGS representation, and a post-ensemble strategy to effectively compress, learn, and fuse language features from multiple appearances. Finally, to quantitatively evaluate our method, we introduce PT-OVS, a new benchmark dataset for assessing open-vocabulary segmentation performance on unconstrained photo collections. Experimental results show that our method outperforms existing methods, delivering accurate open-vocabulary segmentation and enabling applications such as interactive roaming with open-vocabulary queries, architectural style pattern recognition, and 3D scene editing. </p>
<blockquote>
<p>è¿‘æœŸï¼Œå€ŸåŠ©å¤§è§„æ¨¡äº’è”ç½‘å›¾ç‰‡é›†è¿›è¡Œ3Dé‡å»ºçš„æœ€æ–°è¿›å±•ï¼Œå·²ç»èƒ½å¤Ÿå®ç°å…¨çƒå„åœ°åœ°æ ‡å’Œå†å²é—å€çš„æ²‰æµ¸å¼è™šæ‹Ÿæ¢ç´¢ã€‚ç„¶è€Œï¼Œå¯¹äºå»ºç­‘é£æ ¼å’Œç»“æ„çŸ¥è¯†çš„æ²‰æµ¸å¼ç†è§£å´æœªå—åˆ°è¶³å¤Ÿé‡è§†ï¼Œä»ä¸»è¦å±€é™äºæµè§ˆé™æ€æ–‡æœ¬-å›¾åƒå¯¹ã€‚é‚£ä¹ˆï¼Œæˆ‘ä»¬èƒ½ä»é‡ç”Ÿ3Dé‡å»ºæŠ€æœ¯ä¸­æ±²å–çµæ„Ÿï¼Œä½¿ç”¨æ— çº¦æŸçš„å›¾ç‰‡é›†æ¥åˆ›å»ºä¸€ä¸ªæ²‰æµ¸å¼æ–¹æ³•æ¥ç†è§£å»ºç­‘ç»„ä»¶çš„3Dç»“æ„å—ï¼Ÿä¸ºæ­¤ï¼Œæˆ‘ä»¬æ‰©å±•äº†è¯­è¨€åµŒå…¥çš„3Dé«˜æ–¯æ‹¼è´´ï¼ˆ3DGSï¼‰ï¼Œå¹¶æå‡ºä¸€ä¸ªä»æ— çº¦æŸå›¾ç‰‡é›†ä¸­è¿›è¡Œå¼€æ”¾è¯æ±‡åœºæ™¯ç†è§£çš„æ–°æ¡†æ¶ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬é¦–å…ˆä½¿ç”¨é‡å»ºçš„è¾å°„åœºä»åŒä¸€è§†è§’æ¸²æŸ“å¤šä¸ªå¤–è§‚å›¾åƒï¼Œè¿™äº›å›¾åƒä¸æ— çº¦æŸå›¾åƒç›¸å¯¹åº”ã€‚ç„¶åï¼Œæˆ‘ä»¬ä»å¤šå¤–è§‚ç‰¹å¾ä¸­æå–å¤šå¤–è§‚CLIPç‰¹å¾ä»¥åŠä¸¤ç§è¯­è¨€ç‰¹å¾ä¸ç¡®å®šæ€§æ˜ å°„â€”â€”ç¬æ€å’Œå¤–è§‚ä¸ç¡®å®šæ€§ï¼Œä»¥æŒ‡å¯¼éšåçš„ä¼˜åŒ–è¿‡ç¨‹ã€‚æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªç¬æ€ä¸ç¡®å®šæ€§æ„ŸçŸ¥è‡ªåŠ¨ç¼–ç å™¨ã€ä¸€ä¸ªå¤šå¤–è§‚è¯­è¨€åœº3DGSè¡¨ç¤ºä»¥åŠä¸€ä¸ªåé›†æˆç­–ç•¥ï¼Œä»¥æœ‰æ•ˆåœ°å‹ç¼©ã€å­¦ä¹ å’Œèåˆæ¥è‡ªå¤šä¸ªå¤–è§‚çš„è¯­è¨€ç‰¹å¾ã€‚æœ€åï¼Œä¸ºäº†å®šé‡è¯„ä¼°æˆ‘ä»¬çš„æ–¹æ³•ï¼Œæˆ‘ä»¬å¼•å…¥äº†PT-OVSï¼Œè¿™æ˜¯ä¸€ä¸ªæ–°çš„åŸºå‡†æ•°æ®é›†ï¼Œç”¨äºè¯„ä¼°æ— çº¦æŸå›¾ç‰‡é›†ä¸­å¼€æ”¾è¯æ±‡åˆ†å‰²çš„æ€§èƒ½ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œå®ç°äº†å‡†ç¡®çš„å¼€æ”¾è¯æ±‡åˆ†å‰²ï¼Œå¹¶å¯ç”¨äº†åº”ç”¨ç¨‹åºï¼Œå¦‚å¸¦æœ‰å¼€æ”¾è¯æ±‡æŸ¥è¯¢çš„äº¤äº’å¼æ¼«æ¸¸ã€å»ºç­‘é£æ ¼æ¨¡å¼è¯†åˆ«å’Œ3Dåœºæ™¯ç¼–è¾‘ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2507.19830v2">PDF</a> Visit our project page at   <a target="_blank" rel="noopener" href="https://yuzewang1998.github.io/takinglangsplatw/">https://yuzewang1998.github.io/takinglangsplatw/</a></p>
<p><strong>Summary</strong></p>
<p>è¯¥ç ”ç©¶ç»“åˆ3Dé‡å»ºæŠ€æœ¯å’Œå¤§è§„æ¨¡äº’è”ç½‘å›¾ç‰‡é›†ï¼Œæå‡ºä¸€ç§æ–°é¢–æ¡†æ¶ï¼Œç”¨äºä»ä¸å—çº¦æŸçš„å›¾ç‰‡é›†ä¸­ç†è§£å»ºç­‘æ„ä»¶çš„3Dç»“æ„ã€‚è¯¥æ¡†æ¶èåˆäº†è¯­è¨€åµŒå…¥çš„3Dé«˜æ–¯æ˜ å°„æŠ€æœ¯ï¼Œé€šè¿‡æ¸²æŸ“å¤šè§’åº¦è§†å›¾ã€æå–å¤šè§†è§’CLIPç‰¹å¾ã€æ„å»ºè¯­è¨€ç‰¹å¾ä¸ç¡®å®šæ€§åœ°å›¾ï¼Œå¹¶å¼•å…¥ç¬æ—¶ä¸ç¡®å®šæ€§æ„ŸçŸ¥è‡ªç¼–ç å™¨ç­‰æŠ€æœ¯æ‰‹æ®µï¼Œå®ç°å¯¹å»ºç­‘é£æ ¼å’Œç»“æ„çš„æ²‰æµ¸å¼ç†è§£ã€‚åŒæ—¶ï¼Œè¯¥ç ”ç©¶è¿˜æ¨å‡ºæ–°çš„æ•°æ®é›†PT-OVSï¼Œç”¨äºè¯„ä¼°åœ¨ä¸å—çº¦æŸçš„å›¾ç‰‡é›†ä¸Šçš„å¼€æ”¾è¯æ±‡åˆ†å‰²æ€§èƒ½ã€‚å®éªŒè¯æ˜ï¼Œè¯¥æ–¹æ³•ä¼˜äºç°æœ‰æŠ€æœ¯ï¼Œå¯å®ç°å‡†ç¡®çš„å¼€æ”¾è¯æ±‡åˆ†å‰²ï¼Œå¹¶åº”ç”¨äºå¼€æ”¾å¼æŸ¥è¯¢çš„äº¤äº’æ¼«æ¸¸ã€å»ºç­‘é£æ ¼æ¨¡å¼è¯†åˆ«å’Œ3Dåœºæ™¯ç¼–è¾‘ç­‰åº”ç”¨ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>åˆ©ç”¨å¤§è§„æ¨¡äº’è”ç½‘å›¾ç‰‡é›†è¿›è¡Œ3Dé‡å»ºï¼Œå®ç°å…¨çƒåœ°æ ‡å’Œå†å²é—å€çš„æ²‰æµ¸å¼è™šæ‹Ÿæ¢ç´¢ã€‚</li>
<li>ç°æœ‰æŠ€æœ¯å¯¹äºå»ºç­‘é£æ ¼å’Œç»“æ„çŸ¥è¯†çš„ç†è§£ä»ç„¶å±€é™äºæµè§ˆé™æ€æ–‡æœ¬-å›¾åƒå¯¹ï¼Œç¼ºä¹æ²‰æµ¸å¼ç†è§£ã€‚</li>
<li>å¼•å…¥3Dé‡å¤–é‡å»ºæŠ€æœ¯ï¼Œæå‡ºä¸€ç§æ–°é¢–æ¡†æ¶ï¼Œæ—¨åœ¨ä»ä¸å—çº¦æŸçš„å›¾ç‰‡é›†ä¸­ç†è§£å»ºç­‘æ„ä»¶çš„3Dç»“æ„ã€‚</li>
<li>æ¡†æ¶åŒ…æ‹¬ï¼šæ¸²æŸ“å¤šè§’åº¦è§†å›¾ã€æå–å¤šè§†è§’CLIPç‰¹å¾ã€æ„å»ºè¯­è¨€ç‰¹å¾ä¸ç¡®å®šæ€§åœ°å›¾ã€‚</li>
<li>å¼•å…¥ç¬æ—¶ä¸ç¡®å®šæ€§æ„ŸçŸ¥è‡ªç¼–ç å™¨å’Œå¤šè§†è§’è¯­è¨€åœº3DGSè¡¨ç¤ºï¼Œæœ‰æ•ˆå‹ç¼©ã€å­¦ä¹ å’Œèåˆè¯­è¨€ç‰¹å¾ã€‚</li>
<li>æ¨å‡ºæ–°çš„æ•°æ®é›†PT-OVSï¼Œç”¨äºè¯„ä¼°å¼€æ”¾è¯æ±‡åˆ†å‰²æ€§èƒ½ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2507.19830">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-2e8ae25fba8edf271e98553a9bc7b3f5.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-4e8c3cb375052aa8b30a88e2ce333650.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-bfcd97576c92df4df763bdf3e87c85bd.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-540b59271ab4cddc401229df5a5bc629.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-eeb3ed6f9aa82aa155d2778a08d9e385.jpg" align="middle">
</details>


<h1 id="-13"><a href="#-13" class="headerlink" title=""></a></h1><h2 id="AD-GS-Object-Aware-B-Spline-Gaussian-Splatting-for-Self-Supervised-Autonomous-Driving"><a href="#AD-GS-Object-Aware-B-Spline-Gaussian-Splatting-for-Self-Supervised-Autonomous-Driving" class="headerlink" title="AD-GS: Object-Aware B-Spline Gaussian Splatting for Self-Supervised   Autonomous Driving"></a>AD-GS: Object-Aware B-Spline Gaussian Splatting for Self-Supervised   Autonomous Driving</h2><p><strong>Authors:Jiawei Xu, Kai Deng, Zexin Fan, Shenlong Wang, Jin Xie, Jian Yang</strong></p>
<p>Modeling and rendering dynamic urban driving scenes is crucial for self-driving simulation. Current high-quality methods typically rely on costly manual object tracklet annotations, while self-supervised approaches fail to capture dynamic object motions accurately and decompose scenes properly, resulting in rendering artifacts. We introduce AD-GS, a novel self-supervised framework for high-quality free-viewpoint rendering of driving scenes from a single log. At its core is a novel learnable motion model that integrates locality-aware B-spline curves with global-aware trigonometric functions, enabling flexible yet precise dynamic object modeling. Rather than requiring comprehensive semantic labeling, AD-GS automatically segments scenes into objects and background with the simplified pseudo 2D segmentation, representing objects using dynamic Gaussians and bidirectional temporal visibility masks. Further, our model incorporates visibility reasoning and physically rigid regularization to enhance robustness. Extensive evaluations demonstrate that our annotation-free model significantly outperforms current state-of-the-art annotation-free methods and is competitive with annotation-dependent approaches. </p>
<blockquote>
<p>å¯¹åŠ¨æ€åŸå¸‚é©¾é©¶åœºæ™¯çš„å»ºæ¨¡å’Œæ¸²æŸ“å¯¹äºè‡ªåŠ¨é©¾é©¶ä»¿çœŸè‡³å…³é‡è¦ã€‚å½“å‰çš„é«˜è´¨é‡æ–¹æ³•é€šå¸¸ä¾èµ–äºæ˜‚è´µçš„æ‰‹åŠ¨ç›®æ ‡è½¨è¿¹æ ‡æ³¨ï¼Œè€Œè‡ªç›‘ç£çš„æ–¹æ³•åˆ™æ— æ³•å‡†ç¡®æ•æ‰åŠ¨æ€ç›®æ ‡çš„è¿åŠ¨å¹¶é€‚å½“åˆ†è§£åœºæ™¯ï¼Œä»è€Œå¯¼è‡´æ¸²æŸ“å‡ºç°ä¼ªå½±ã€‚æˆ‘ä»¬å¼•å…¥äº†AD-GSï¼Œè¿™æ˜¯ä¸€ç§æ–°å‹è‡ªç›‘ç£æ¡†æ¶ï¼Œç”¨äºä»å•ä¸ªæ—¥å¿—ä¸­è¿›è¡Œé«˜è´¨é‡è‡ªç”±è§†è§’çš„é©¾é©¶åœºæ™¯æ¸²æŸ“ã€‚å…¶æ ¸å¿ƒæ˜¯ä¸€ä¸ªæ–°å‹çš„å¯å­¦ä¹ è¿åŠ¨æ¨¡å‹ï¼Œå®ƒå°†å±€éƒ¨æ„ŸçŸ¥çš„Bæ ·æ¡æ›²çº¿ä¸å…¨å±€æ„ŸçŸ¥çš„ä¸‰è§’å‡½æ•°ç›¸ç»“åˆï¼Œå®ç°äº†çµæ´»è€Œç²¾ç¡®çš„åŠ¨æ€ç›®æ ‡å»ºæ¨¡ã€‚AD-GSä¸éœ€è¦å…¨é¢çš„è¯­ä¹‰æ ‡ç­¾ï¼Œè€Œæ˜¯è‡ªåŠ¨å°†åœºæ™¯åˆ†å‰²ä¸ºç›®æ ‡å’ŒèƒŒæ™¯ï¼Œé‡‡ç”¨ç®€åŒ–çš„ä¼ªäºŒç»´åˆ†å‰²æ¥è¡¨ç¤ºç›®æ ‡ï¼Œå¹¶ä½¿ç”¨åŠ¨æ€é«˜æ–¯å’ŒåŒå‘æ—¶é—´å¯è§æ€§æ©è†œæ¥è¡¨ç¤ºç›®æ ‡ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬çš„æ¨¡å‹è¿˜èå…¥äº†å¯è§æ€§æ¨ç†å’Œç‰©ç†åˆšæ€§æ­£åˆ™åŒ–ï¼Œä»¥æé«˜ç¨³å¥æ€§ã€‚å¤§é‡è¯„ä¼°è¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ— æ ‡æ³¨æ¨¡å‹æ˜¾è‘—ä¼˜äºå½“å‰å…ˆè¿›çš„æ— æ ‡æ³¨æ–¹æ³•ï¼Œå¹¶ä¸ä¾èµ–äºæ ‡æ³¨çš„æ–¹æ³•å…·æœ‰ç«äº‰åŠ›ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2507.12137v3">PDF</a> Accepted by ICCV 2025</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°å‹çš„è‡ªç›‘ç£æ¡†æ¶AD-GSï¼Œç”¨äºä»å•ä¸€æ—¥å¿—ä¸­è¿›è¡Œé«˜è´¨é‡çš„è‡ªç”±è§†è§’é©¾é©¶åœºæ™¯æ¸²æŸ“ã€‚è¯¥æ¡†æ¶é‡‡ç”¨å­¦ä¹ å‹çš„è¿åŠ¨æ¨¡å‹ï¼Œç»“åˆå±€éƒ¨æ„ŸçŸ¥çš„Bæ ·æ¡æ›²çº¿å’Œå…¨å±€æ„ŸçŸ¥çš„ä¸‰è§’å‡½æ•°ï¼Œå®ç°çµæ´»è€Œç²¾ç¡®çš„åŠ¨æ€ç‰©ä½“å»ºæ¨¡ã€‚é€šè¿‡ç®€åŒ–ä¼ªäºŒç»´åˆ†å‰²ï¼ŒAD-GSå¯è‡ªåŠ¨å°†åœºæ™¯åˆ†å‰²ä¸ºç‰©ä½“å’ŒèƒŒæ™¯ï¼Œå¹¶ä½¿ç”¨åŠ¨æ€é«˜æ–¯å’ŒåŒå‘æ—¶é—´å¯è§æ€§æ©è†œè¡¨ç¤ºç‰©ä½“ã€‚æ­¤å¤–ï¼Œè¯¥æ¨¡å‹è¿˜èå…¥äº†å¯è§æ€§æ¨ç†å’Œç‰©ç†åˆšä½“è§„åˆ™åŒ–ä»¥å¢å¼ºç¨³å¥æ€§ï¼Œæ— éœ€å…¨é¢è¯­ä¹‰æ ‡ç­¾å³å¯æ˜¾è‘—è¶…è¶Šå½“å‰æœ€å…ˆè¿›çš„æ— æ ‡æ³¨æ–¹æ³•ï¼Œå¹¶ä¸ä¾èµ–äºæ ‡æ³¨çš„æ–¹æ³•ç›¸ç«äº‰ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>AD-GSæ˜¯ä¸€ç§æ–°å‹è‡ªç›‘ç£æ¡†æ¶ï¼Œç”¨äºé«˜è´¨é‡è‡ªç”±è§†è§’çš„é©¾é©¶åœºæ™¯æ¸²æŸ“ã€‚</li>
<li>æ¡†æ¶æ ¸å¿ƒä¸ºå­¦ä¹ å‹çš„è¿åŠ¨æ¨¡å‹ï¼Œç»“åˆäº†å±€éƒ¨å’Œå…¨å±€æ„ŸçŸ¥å‡½æ•°ï¼Œå®ç°ç²¾ç¡®åŠ¨æ€ç‰©ä½“å»ºæ¨¡ã€‚</li>
<li>æ— éœ€å…¨é¢çš„è¯­ä¹‰æ ‡æ³¨ï¼Œé€šè¿‡ç®€åŒ–ä¼ªäºŒç»´åˆ†å‰²è‡ªåŠ¨åˆ†å‰²åœºæ™¯ã€‚</li>
<li>ä½¿ç”¨åŠ¨æ€é«˜æ–¯å’ŒåŒå‘æ—¶é—´å¯è§æ€§æ©è†œè¡¨ç¤ºç‰©ä½“ã€‚</li>
<li>èå…¥äº†å¯è§æ€§æ¨ç†å’Œç‰©ç†åˆšä½“è§„åˆ™åŒ–å¢å¼ºæ¨¡å‹çš„ç¨³å¥æ€§ã€‚</li>
<li>æ˜¾è‘—è¶…è¶Šäº†ç°æœ‰çš„æ— æ ‡æ³¨æ–¹æ³•ï¼Œå¹¶åœ¨æ€§èƒ½ä¸Šä¸ä¾èµ–äºæ ‡æ³¨çš„æ–¹æ³•ç›¸ç«äº‰ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2507.12137">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-2a912903a12917744dada3f54ed336d7.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-03dd37d5ef57484a792dedbc41afec2d.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-61decd939d6dd22508e8b707c1e35042.jpg" align="middle">
</details>


<h1 id="-14"><a href="#-14" class="headerlink" title=""></a></h1><h2 id="Personalize-Your-Gaussian-Consistent-3D-Scene-Personalization-from-a-Single-Image"><a href="#Personalize-Your-Gaussian-Consistent-3D-Scene-Personalization-from-a-Single-Image" class="headerlink" title="Personalize Your Gaussian: Consistent 3D Scene Personalization from a   Single Image"></a>Personalize Your Gaussian: Consistent 3D Scene Personalization from a   Single Image</h2><p><strong>Authors:Yuxuan Wang, Xuanyu Yi, Qingshan Xu, Yuan Zhou, Long Chen, Hanwang Zhang</strong></p>
<p>Personalizing 3D scenes from a single reference image enables intuitive user-guided editing, which requires achieving both multi-view consistency across perspectives and referential consistency with the input image. However, these goals are particularly challenging due to the viewpoint bias caused by the limited perspective provided in a single image. Lacking the mechanisms to effectively expand reference information beyond the original view, existing methods of image-conditioned 3DGS personalization often suffer from this viewpoint bias and struggle to produce consistent results. Therefore, in this paper, we present Consistent Personalization for 3D Gaussian Splatting (CP-GS), a framework that progressively propagates the single-view reference appearance to novel perspectives. In particular, CP-GS integrates pre-trained image-to-3D generation and iterative LoRA fine-tuning to extract and extend the reference appearance, and finally produces faithful multi-view guidance images and the personalized 3DGS outputs through a view-consistent generation process guided by geometric cues. Extensive experiments on real-world scenes show that our CP-GS effectively mitigates the viewpoint bias, achieving high-quality personalization that significantly outperforms existing methods. The code will be released at <a target="_blank" rel="noopener" href="https://github.com/Yuxuan-W/CP-GS">https://github.com/Yuxuan-W/CP-GS</a>. </p>
<blockquote>
<p>é€šè¿‡å•ä¸€å‚è€ƒå›¾åƒä¸ªæ€§åŒ–3Dåœºæ™¯ï¼Œå¯å®ç°ç›´è§‚çš„ç”¨æˆ·å¼•å¯¼ç¼–è¾‘ï¼Œè¿™è¦æ±‚åœ¨ä¸åŒè§†è§’ä¹‹é—´å®ç°å¤šè§†å›¾ä¸€è‡´æ€§ä»¥åŠä¸è¾“å…¥å›¾åƒçš„å‚ç…§ä¸€è‡´æ€§ã€‚ç„¶è€Œï¼Œç”±äºå•ä¸€å›¾åƒæä¾›çš„æœ‰é™è§†è§’å¯¼è‡´çš„è§†ç‚¹åè§ï¼Œè¿™äº›ç›®æ ‡ç‰¹åˆ«å…·æœ‰æŒ‘æˆ˜æ€§ã€‚ç¼ºä¹åœ¨åŸå§‹è§†å›¾ä¹‹å¤–æœ‰æ•ˆæ‰©å±•å‚è€ƒä¿¡æ¯çš„æœºåˆ¶ï¼Œç°æœ‰çš„å›¾åƒæ¡ä»¶3DGSä¸ªæ€§åŒ–æ–¹æ³•é€šå¸¸å—åˆ°è¿™ç§è§†ç‚¹åè§çš„å½±å“ï¼Œéš¾ä»¥äº§ç”Ÿä¸€è‡´çš„ç»“æœã€‚å› æ­¤ï¼Œæœ¬æ–‡æå‡ºäº†é¢å‘3Dé«˜æ–¯æ‹¼è´´çš„ä¸€è‡´ä¸ªæ€§åŒ–ï¼ˆCP-GSï¼‰æ¡†æ¶ï¼Œè¯¥æ¡†æ¶é€æ­¥å°†å•è§†å›¾å‚è€ƒå¤–è§‚ä¼ æ’­åˆ°æ–°çš„è§†è§’ã€‚ç‰¹åˆ«æ˜¯ï¼ŒCP-GSé›†æˆäº†é¢„è®­ç»ƒçš„å›¾åƒåˆ°3Dç”Ÿæˆå’Œè¿­ä»£LoRAå¾®è°ƒï¼Œä»¥æå–å’Œæ‰©å±•å‚è€ƒå¤–è§‚ï¼Œå¹¶æœ€ç»ˆé€šè¿‡å¿ å®çš„å¤šè§†å›¾æŒ‡å¯¼å›¾åƒå’Œç”±å‡ ä½•çº¿ç´¢å¼•å¯¼çš„ä¸€è‡´ç”Ÿæˆè¿‡ç¨‹ï¼Œäº§ç”Ÿä¸ªæ€§åŒ–çš„3DGSè¾“å‡ºã€‚åœ¨çœŸå®åœºæ™¯ä¸Šçš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„CP-GSæœ‰æ•ˆåœ°å‡è½»äº†è§†ç‚¹åè§ï¼Œå®ç°äº†é«˜è´¨é‡çš„ä¸ªæ€§åŒ–ï¼Œæ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ã€‚ä»£ç å°†åœ¨<a target="_blank" rel="noopener" href="https://github.com/Yuxuan-W/CP-GS">https://github.com/Yuxuan-W/CP-GS</a>å‘å¸ƒã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.14537v2">PDF</a> 18 pages</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸ºCP-GSçš„3Dé«˜æ–¯å–·ç»˜ä¸€è‡´ä¸ªæ€§åŒ–æ¡†æ¶ï¼Œè¯¥æ¡†æ¶èƒ½å¤Ÿä»å•ä¸€è§†è§’çš„å›¾åƒå‚è€ƒä¸­ï¼Œé€æ­¥ä¼ æ’­å¤–è§‚ä¿¡æ¯åˆ°æ–°çš„è§†è§’ã€‚é€šè¿‡æ•´åˆé¢„è®­ç»ƒçš„å›¾åƒåˆ°3Dç”Ÿæˆæ¨¡å‹å’Œè¿­ä»£LoRAå¾®è°ƒæŠ€æœ¯ï¼ŒCP-GSèƒ½å¤Ÿæœ‰æ•ˆåœ°æå–å’Œæ‰©å±•å‚è€ƒå›¾åƒä¸­çš„å¤–è§‚ä¿¡æ¯ï¼Œç”Ÿæˆå¿ å®äºåŸå›¾åƒçš„å¤šè§†è§’æŒ‡å¯¼å›¾åƒï¼Œå¹¶äº§ç”Ÿä¸ªæ€§åŒ–çš„3DGSè¾“å‡ºã€‚å®éªŒè¯æ˜ï¼ŒCP-GSæœ‰æ•ˆå‡è½»äº†è§†è§’åå·®é—®é¢˜ï¼Œæ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>CP-GSæ¡†æ¶å®ç°äº†ä»å•ä¸€å‚è€ƒå›¾åƒåˆ°å¤šè§†è§’çš„ä¸ªæ€§åŒ–3Dåœºæ™¯ç”Ÿæˆã€‚</li>
<li>é€šè¿‡é€æ­¥ä¼ æ’­å•ä¸€è§†è§’çš„å›¾åƒå‚è€ƒå¤–è§‚ä¿¡æ¯åˆ°æ–°çš„è§†è§’ã€‚</li>
<li>æ•´åˆäº†é¢„è®­ç»ƒçš„å›¾åƒåˆ°3Dç”Ÿæˆæ¨¡å‹å’Œè¿­ä»£LoRAå¾®è°ƒæŠ€æœ¯æ¥æå–å’Œæ‰©å±•å‚è€ƒä¿¡æ¯ã€‚</li>
<li>CP-GSæ¡†æ¶èƒ½å¤Ÿç”Ÿæˆå¿ å®äºåŸå›¾åƒçš„å¤šè§†è§’æŒ‡å¯¼å›¾åƒã€‚</li>
<li>å®ç°äº†ä¸ªæ€§åŒ–çš„3DGSè¾“å‡ºï¼Œæ˜¾è‘—å‡è½»äº†è§†è§’åå·®é—®é¢˜ã€‚</li>
<li>CP-GSæ¡†æ¶åœ¨çœŸå®åœºæ™¯çš„å®éªŒä¸­è¡¨ç°å‡ºä¼˜å¼‚æ€§èƒ½ã€‚</li>
<li>ä»£ç å°†å‘å¸ƒåœ¨<a target="_blank" rel="noopener" href="https://github.com/Yuxuan-W/CP-GS%E3%80%82">https://github.com/Yuxuan-W/CP-GSã€‚</a></li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.14537">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-894338b465df107d361f4f251909aea9.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-77c83ce0b46b0cc782efe91cff84ac03.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-b54c10547e7c2872997e29d5bd70acbc.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-9f6783b7143ec4f25063d879b7cabcc9.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-4bd057bab15babaeaf1237097f79551b.jpg" align="middle">
</details>


<h1 id="-15"><a href="#-15" class="headerlink" title=""></a></h1><h2 id="FlowR-Flowing-from-Sparse-to-Dense-3D-Reconstructions"><a href="#FlowR-Flowing-from-Sparse-to-Dense-3D-Reconstructions" class="headerlink" title="FlowR: Flowing from Sparse to Dense 3D Reconstructions"></a>FlowR: Flowing from Sparse to Dense 3D Reconstructions</h2><p><strong>Authors:Tobias Fischer, Samuel Rota BulÃ², Yung-Hsu Yang, Nikhil Keetha, Lorenzo Porzi, Norman MÃ¼ller, Katja Schwarz, Jonathon Luiten, Marc Pollefeys, Peter Kontschieder</strong></p>
<p>3D Gaussian splatting enables high-quality novel view synthesis (NVS) at real-time frame rates. However, its quality drops sharply as we depart from the training views. Thus, dense captures are needed to match the high-quality expectations of applications like Virtual Reality (VR). However, such dense captures are very laborious and expensive to obtain. Existing works have explored using 2D generative models to alleviate this requirement by distillation or generating additional training views. These models typically rely on a noise-to-data generative process conditioned only on a handful of reference input views, leading to hallucinations, inconsistent generation results, and subsequent reconstruction artifacts. Instead, we propose a multi-view, flow matching model that learns a flow to directly connect novel view renderings from possibly sparse reconstructions to renderings that we expect from dense reconstructions. This enables augmenting scene captures with consistent, generated views to improve reconstruction quality. Our model is trained on a novel dataset of 3.6M image pairs and can process up to 45 views at 540x960 resolution (91K tokens) on one H100 GPU in a single forward pass. Our pipeline consistently improves NVS in sparse- and dense-view scenarios, leading to higher-quality reconstructions than prior works across multiple, widely-used NVS benchmarks. </p>
<blockquote>
<p>3Dé«˜æ–¯å±•å¹³æŠ€æœ¯èƒ½å¤Ÿä»¥å®æ—¶å¸§ç‡å®ç°é«˜è´¨é‡çš„æ–°è§†è§’åˆæˆï¼ˆNVSï¼‰ã€‚ç„¶è€Œï¼Œå½“æˆ‘ä»¬åç¦»è®­ç»ƒè§†å›¾æ—¶ï¼Œå…¶è´¨é‡ä¼šæ€¥å‰§ä¸‹é™ã€‚å› æ­¤ï¼Œä¸ºäº†åŒ¹é…è™šæ‹Ÿç°å®ï¼ˆVRï¼‰ç­‰åº”ç”¨çš„é«˜è´¨é‡æœŸæœ›ï¼Œéœ€è¦è¿›è¡Œå¯†é›†çš„æ•è·ã€‚ç„¶è€Œï¼Œè·å–è¿™æ ·çš„å¯†é›†æ•è·éå¸¸è€—æ—¶ä¸”æˆæœ¬é«˜æ˜‚ã€‚ç°æœ‰ç ”ç©¶å·²ç»å°è¯•ä½¿ç”¨2Dç”Ÿæˆæ¨¡å‹é€šè¿‡è’¸é¦æˆ–ç”Ÿæˆé¢å¤–çš„è®­ç»ƒè§†å›¾æ¥ç¼“è§£è¿™ä¸€éœ€æ±‚ã€‚è¿™äº›æ¨¡å‹é€šå¸¸ä¾èµ–äºä»…ä¾èµ–äºå°‘é‡å‚è€ƒè¾“å…¥è§†å›¾çš„å™ªå£°åˆ°æ•°æ®çš„ç”Ÿæˆè¿‡ç¨‹ï¼Œä»è€Œå¯¼è‡´å‡ºç°å¹»è§‰ã€ç”Ÿæˆç»“æœä¸ä¸€è‡´å’Œéšåçš„é‡å»ºä¼ªå½±ã€‚ç›¸åï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§å¤šè§†è§’ã€æµåŒ¹é…æ¨¡å‹ï¼Œè¯¥æ¨¡å‹å­¦ä¹ ä¸€ç§æµï¼Œç›´æ¥è¿æ¥å¯èƒ½ç¨€ç–é‡å»ºçš„æ–°è§†è§’æ¸²æŸ“ï¼Œåˆ°æˆ‘ä»¬æœŸæœ›ä»å¯†é›†é‡å»ºä¸­å¾—åˆ°çš„æ¸²æŸ“ã€‚è¿™èƒ½å¤Ÿé€šè¿‡å¢åŠ åœºæ™¯æ•è·çš„ä¸€è‡´æ€§å’Œç”Ÿæˆçš„è§†è§’æ¥æé«˜é‡å»ºè´¨é‡ã€‚æˆ‘ä»¬çš„æ¨¡å‹æ˜¯åœ¨ä¸€ä¸ªåŒ…å«360ä¸‡å›¾åƒå¯¹çš„æ–°æ•°æ®é›†ä¸Šè¿›è¡Œè®­ç»ƒçš„ï¼Œå¯ä»¥åœ¨ä¸€æ¬¡å‰å‘ä¼ é€’ä¸­ï¼Œåœ¨å•ä¸ªH100 GPUä¸Šä»¥540x960åˆ†è¾¨ç‡å¤„ç†å¤šè¾¾45ä¸ªè§†å›¾ï¼ˆ91Kä»¤ç‰Œï¼‰ã€‚æˆ‘ä»¬çš„ç®¡é“åœ¨ç¨€ç–å’Œå¯†é›†è§†å›¾çš„åœºæ™¯ä¸­æŒç»­æé«˜äº†NVSçš„æ€§èƒ½ï¼Œå¹¶åœ¨å¤šä¸ªå¹¿æ³›ä½¿ç”¨çš„NVSåŸºå‡†æµ‹è¯•ä¸­å®ç°äº†æ¯”å…ˆå‰å·¥ä½œæ›´é«˜è´¨é‡çš„é‡å»ºã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.01647v2">PDF</a> ICCV 2025 Highlight. Project page is available at   <a target="_blank" rel="noopener" href="https://tobiasfshr.github.io/pub/flowr">https://tobiasfshr.github.io/pub/flowr</a></p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºä¸€ç§åŸºäºå¤šè§†è§’æµåŒ¹é…æ¨¡å‹çš„å®æ—¶é«˜è´¨é‡ä¸‰ç»´åœºæ™¯é‡å»ºæ–¹æ³•ã€‚é€šè¿‡ç›´æ¥è¿æ¥ç¨€ç–é‡å»ºçš„æ–°è§†è§’æ¸²æŸ“ä¸å¯†é›†é‡å»ºçš„æ¸²æŸ“ç»“æœï¼Œè¯¥æ–¹æ³•æé«˜äº†åœºæ™¯é‡å»ºçš„è´¨é‡å’Œä¸€è‡´æ€§ã€‚åœ¨å¤§é‡å›¾åƒæ•°æ®å¯¹è®­ç»ƒçš„åŸºç¡€ä¸Šï¼Œè¯¥æ¨¡å‹åœ¨ç¨€ç–å’Œå¯†é›†è§†è§’ä¸‹å‡èƒ½æ”¹å–„æ–°å‹è§†è§’åˆæˆæ•ˆæœï¼Œä¸”åœ¨å¤šä¸ªå¹¿æ³›åº”ç”¨çš„æ–°å‹è§†è§’åˆæˆåŸºå‡†æµ‹è¯•ä¸­å®ç°é«˜è´¨é‡é‡å»ºã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>3Dé«˜æ–¯splatæŠ€æœ¯èƒ½å®æ—¶åˆæˆé«˜è´¨é‡æ–°è§†è§’ï¼Œä½†ç¦»è®­ç»ƒè§†è§’å¤ªè¿œåˆ™è´¨é‡æ€¥å‰§ä¸‹é™ï¼Œéœ€è¦å¯†é›†æ•è·åŒ¹é…VRç­‰é«˜è´¨åº”ç”¨éœ€æ±‚ã€‚</li>
<li>å¯†é›†æ•è·æ—¢åŠ³åŠ›åˆæ˜‚è´µï¼Œç°æœ‰å·¥ä½œå°è¯•ç”¨2Dç”Ÿæˆæ¨¡å‹ç¼“è§£æ­¤é—®é¢˜ï¼Œä½†ä¾èµ–å™ªå£°åˆ°æ•°æ®çš„ç”Ÿæˆè¿‡ç¨‹ï¼Œä»…ä¾èµ–å°‘é‡å‚è€ƒè¾“å…¥è§†è§’ï¼Œå¯¼è‡´å¹»è§‰ã€ç”Ÿæˆç»“æœä¸ä¸€è‡´å’Œé‡å»ºä¼ªå½±ã€‚</li>
<li>æå‡ºä¸€ç§å¤šè§†è§’æµåŒ¹é…æ¨¡å‹ï¼Œå­¦ä¹ ä»ç¨€ç–é‡å»ºåˆ°æ–°è§†è§’æ¸²æŸ“çš„æµè¿æ¥ï¼Œä»¥æé«˜é‡å»ºè´¨é‡å¹¶å¢å¼ºåœºæ™¯æ•è·çš„ä¸€è‡´æ€§ã€‚</li>
<li>æ¨¡å‹åœ¨æ–°æ•°æ®é›†ä¸Šè®­ç»ƒï¼ŒåŒ…å«360ä¸‡å›¾åƒå¯¹ï¼Œèƒ½åœ¨å•ä¸ªH100 GPUä¸Šä¸€æ¬¡å‰å‘ä¼ é€’å¤„ç†é«˜è¾¾45ä¸ªè§†è§’çš„540x960åˆ†è¾¨ç‡ï¼ˆ91Kä»¤ç‰Œï¼‰ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.01647">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-c0ea53e0dbb1ac74661d194b25bc699a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-96ffab44c24f9b24350f6c89fa4dc50f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-47704784d2ce71c162ab9c6c0ce3b11f.jpg" align="middle">
</details>


<h1 id="-16"><a href="#-16" class="headerlink" title=""></a></h1><h2 id="4D-Gaussian-Splatting-Modeling-Dynamic-Scenes-with-Native-4D-Primitives"><a href="#4D-Gaussian-Splatting-Modeling-Dynamic-Scenes-with-Native-4D-Primitives" class="headerlink" title="4D Gaussian Splatting: Modeling Dynamic Scenes with Native 4D Primitives"></a>4D Gaussian Splatting: Modeling Dynamic Scenes with Native 4D Primitives</h2><p><strong>Authors:Zeyu Yang, Zijie Pan, Xiatian Zhu, Li Zhang, Jianfeng Feng, Yu-Gang Jiang, Philip H. S. Torr</strong></p>
<p>Dynamic 3D scene representation and novel view synthesis are crucial for enabling immersive experiences required by AR&#x2F;VR and metaverse applications. It is a challenging task due to the complexity of unconstrained real-world scenes and their temporal dynamics. In this paper, we reformulate the reconstruction of a time-varying 3D scene as approximating its underlying spatiotemporal 4D volume by optimizing a collection of native 4D primitives, i.e., 4D Gaussians, with explicit geometry and appearance modeling. Equipped with a tailored rendering pipeline, our representation can be end-to-end optimized using only photometric supervision while free viewpoint viewing at interactive frame rate, making it suitable for representing real world scene with complex dynamic. This approach has been the first solution to achieve real-time rendering of high-resolution, photorealistic novel views for complex dynamic scenes. To facilitate real-world applications, we derive several compact variants that effectively reduce the memory footprint to address its storage bottleneck. Extensive experiments validate the superiority of 4DGS in terms of visual quality and efficiency across a range of dynamic scene-related tasks (e.g., novel view synthesis, 4D generation, scene understanding) and scenarios (e.g., single object, indoor scenes, driving environments, synthetic and real data). </p>
<blockquote>
<p>åŠ¨æ€ä¸‰ç»´åœºæ™¯è¡¨ç¤ºå’Œæ–°å‹è§†å›¾åˆæˆå¯¹äºå¢å¼ºç°å®&#x2F;è™šæ‹Ÿç°å®å’Œå…ƒå®‡å®™åº”ç”¨ç¨‹åºæ‰€éœ€çš„æ²‰æµ¸å¼ä½“éªŒè‡³å…³é‡è¦ã€‚ç”±äºæ— çº¦æŸçš„ç°å®ä¸–ç•Œåœºæ™¯çš„å¤æ‚æ€§å’Œå…¶æ—¶é—´åŠ¨æ€æ€§ï¼Œè¿™æ˜¯ä¸€é¡¹å…·æœ‰æŒ‘æˆ˜æ€§çš„ä»»åŠ¡ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬å°†æ—¶å˜ä¸‰ç»´åœºæ™¯çš„é‡å»ºé‡æ–°å®šä¹‰ä¸ºé€šè¿‡ä¼˜åŒ–ä¸€ç³»åˆ—æœ¬åœ°å››ç»´åŸå§‹æ•°æ®ï¼ˆå³å…·æœ‰æ˜ç¡®å‡ ä½•å’Œå¤–è§‚å»ºæ¨¡çš„å››ç»´é«˜æ–¯ï¼‰æ¥é€¼è¿‘å…¶åŸºç¡€æ—¶ç©ºå››ç»´ä½“ç§¯ã€‚å‡­å€Ÿé‡èº«å®šåˆ¶çš„æ¸²æŸ“ç®¡é“ï¼Œæˆ‘ä»¬çš„è¡¨ç¤ºå¯ä»¥ä½¿ç”¨ä»…å…‰åº¦ç›‘ç£è¿›è¡Œç«¯åˆ°ç«¯ä¼˜åŒ–ï¼ŒåŒæ—¶ä»¥äº¤äº’å¼å¸§ç‡è¿›è¡Œè‡ªç”±è§†ç‚¹æŸ¥çœ‹ï¼Œä½¿å…¶é€‚åˆè¡¨ç¤ºå…·æœ‰å¤æ‚åŠ¨æ€çš„ç°å®ä¸–ç•Œåœºæ™¯ã€‚è¿™ç§æ–¹æ³•é¦–æ¬¡å®ç°äº†å¯¹å¤æ‚åŠ¨æ€åœºæ™¯çš„é«˜åˆ†è¾¨ç‡ã€é«˜é€¼çœŸåº¦æ–°è§†è§’çš„å®æ—¶æ¸²æŸ“ã€‚ä¸ºäº†ä¿ƒè¿›å®é™…åº”ç”¨ï¼Œæˆ‘ä»¬æ¨å¯¼å‡ºäº†å‡ ç§ç´§å‡‘çš„å˜ä½“ï¼Œæœ‰æ•ˆåœ°å‡å°‘äº†å†…å­˜å ç”¨ï¼Œè§£å†³äº†å…¶å­˜å‚¨ç“¶é¢ˆã€‚å¤§é‡å®éªŒéªŒè¯äº†å››ç»´é«˜æ–¯åˆæˆåœ¨è§†è§‰è´¨é‡å’Œæ•ˆç‡æ–¹é¢çš„ä¼˜è¶Šæ€§ï¼Œæ¶µç›–äº†ä¸€ç³»åˆ—åŠ¨æ€åœºæ™¯ç›¸å…³ä»»åŠ¡ï¼ˆä¾‹å¦‚æ–°è§†è§’åˆæˆã€å››ç»´ç”Ÿæˆã€åœºæ™¯ç†è§£ï¼‰å’Œåœºæ™¯ï¼ˆä¾‹å¦‚å•ä¸ªå¯¹è±¡ã€å®¤å†…åœºæ™¯ã€é©¾é©¶ç¯å¢ƒã€åˆæˆæ•°æ®å’ŒçœŸå®æ•°æ®ï¼‰ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.20720v2">PDF</a> Journal extension of ICLR 2024. arXiv admin note: text overlap with   arXiv:2310.10642</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºä¸€ç§åŸºäºä¼˜åŒ–æœ¬åœ°4DåŸå§‹æ•°æ®ï¼ˆå¦‚4Dé«˜æ–¯ï¼‰çš„æ—¶é—´å˜åŒ–3Dåœºæ™¯é‡å»ºæ–¹æ³•ï¼Œå°†å…¶æ¨¡æ‹Ÿä¸ºå¯¹åº•å±‚æ—¶ç©º4Dä½“ç§¯çš„é€¼è¿‘ã€‚é€šè¿‡ä¸“é—¨çš„æ¸²æŸ“ç®¡é“ï¼Œè¯¥è¡¨ç¤ºæ–¹æ³•å¯åœ¨ä»…ä½¿ç”¨å…‰åº¦ç›‘ç£çš„æƒ…å†µä¸‹è¿›è¡Œç«¯åˆ°ç«¯ä¼˜åŒ–ï¼Œå®ç°å¤æ‚åŠ¨æ€åœºæ™¯çš„å®æ—¶æ¸²æŸ“å’ŒçœŸå®æ„Ÿæ–°è§†è§’è§‚çœ‹ã€‚ä¸ºè§£å†³å­˜å‚¨ç“¶é¢ˆé—®é¢˜ï¼Œæœ¬æ–‡è¿˜æ¨å‡ºäº†å‡ ç§ç´§å‡‘å˜ä½“ä»¥æœ‰æ•ˆå‡å°‘å†…å­˜å ç”¨ã€‚å®éªŒè¯æ˜ï¼Œè¯¥æ–¹æ³•åœ¨è§†è§‰è´¨é‡å’Œæ•ˆç‡æ–¹é¢å‡ä¼˜äºå…¶ä»–æ–¹æ³•ï¼Œé€‚ç”¨äºå¤šç§åŠ¨æ€åœºæ™¯ç›¸å…³ä»»åŠ¡å’Œåœºæ™¯ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>åŠ¨æ€3Dåœºæ™¯è¡¨ç¤ºå’Œæ–°é¢–è§†å›¾åˆæˆå¯¹äºAR&#x2F;VRå’Œå…ƒå®‡å®™åº”ç”¨æ‰€éœ€çš„æ²‰æµ¸å¼ä½“éªŒè‡³å…³é‡è¦ã€‚</li>
<li>æœ¬æ–‡é€šè¿‡å°†æ—¶é—´å˜åŒ–çš„3Dåœºæ™¯é‡å»ºé‡æ–°å®šä¹‰ä¸ºå¯¹åº•å±‚æ—¶ç©º4Dä½“ç§¯çš„é€¼è¿‘æ¥è§£å†³è¿™ä¸€æŒ‘æˆ˜ã€‚</li>
<li>ä½¿ç”¨ä¼˜åŒ–æœ¬åœ°4DåŸå§‹æ•°æ®ï¼ˆå¦‚4Dé«˜æ–¯ï¼‰è¿›è¡Œè¡¨ç¤ºï¼Œå¹¶å…·å¤‡æ˜ç¡®çš„å‡ ä½•å’Œå¤–è§‚å»ºæ¨¡ã€‚</li>
<li>é…å¤‡äº†ä¸“é—¨çš„æ¸²æŸ“ç®¡é“ï¼Œå¯åœ¨ä»…ä½¿ç”¨å…‰åº¦ç›‘ç£çš„æƒ…å†µä¸‹è¿›è¡Œç«¯åˆ°ç«¯ä¼˜åŒ–ï¼Œå®ç°å¤æ‚åŠ¨æ€åœºæ™¯çš„å®æ—¶æ¸²æŸ“å’ŒçœŸå®æ„Ÿæ–°è§†è§’è§‚çœ‹ã€‚</li>
<li>æ¨å‡ºå‡ ç§ç´§å‡‘å˜ä½“ä»¥è§£å†³å­˜å‚¨ç“¶é¢ˆé—®é¢˜ï¼Œæœ‰æ•ˆå‡å°‘å†…å­˜å ç”¨ã€‚</li>
<li>å®éªŒè¯æ˜ï¼Œè¯¥æ–¹æ³•åœ¨è§†è§‰è´¨é‡å’Œæ•ˆç‡æ–¹é¢ä¼˜äºå…¶ä»–æ–¹æ³•ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.20720">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-20890d87c4c3d95e59d8fc6b2a97de40.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-6caa0c8be5f2203d30797e06dd3a8db0.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-6ca75aa2faf9af2c0099374226a905cb.jpg" align="middle">
</details>


<h1 id="-17"><a href="#-17" class="headerlink" title=""></a></h1><h2 id="4D-Scaffold-Gaussian-Splatting-with-Dynamic-Aware-Anchor-Growing-for-Efficient-and-High-Fidelity-Dynamic-Scene-Reconstruction"><a href="#4D-Scaffold-Gaussian-Splatting-with-Dynamic-Aware-Anchor-Growing-for-Efficient-and-High-Fidelity-Dynamic-Scene-Reconstruction" class="headerlink" title="4D Scaffold Gaussian Splatting with Dynamic-Aware Anchor Growing for   Efficient and High-Fidelity Dynamic Scene Reconstruction"></a>4D Scaffold Gaussian Splatting with Dynamic-Aware Anchor Growing for   Efficient and High-Fidelity Dynamic Scene Reconstruction</h2><p><strong>Authors:Woong Oh Cho, In Cho, Seoha Kim, Jeongmin Bae, Youngjung Uh, Seon Joo Kim</strong></p>
<p>Modeling dynamic scenes through 4D Gaussians offers high visual fidelity and fast rendering speeds, but comes with significant storage overhead. Recent approaches mitigate this cost by aggressively reducing the number of Gaussians. However, this inevitably removes Gaussians essential for high-quality rendering, leading to severe degradation in dynamic regions. In this paper, we introduce a novel 4D anchor-based framework that tackles the storage cost in different perspective. Rather than reducing the number of Gaussians, our method retains a sufficient quantity to accurately model dynamic contents, while compressing them into compact, grid-aligned 4D anchor features. Each anchor is processed by an MLP to spawn a set of neural 4D Gaussians, which represent a local spatiotemporal region. We design these neural 4D Gaussians to capture temporal changes with minimal parameters, making them well-suited for the MLP-based spawning. Moreover, we introduce a dynamic-aware anchor growing strategy to effectively assign additional anchors to under-reconstructed dynamic regions. Our method adjusts the accumulated gradients with Gaussiansâ€™ temporal coverage, significantly improving reconstruction quality in dynamic regions. Experimental results highlight that our method achieves state-of-the-art visual quality in dynamic regions, outperforming all baselines by a large margin with practical storage costs. </p>
<blockquote>
<p>é€šè¿‡4Dé«˜æ–¯å»ºæ¨¡åŠ¨æ€åœºæ™¯å¯ä»¥æä¾›é«˜è§†è§‰ä¿çœŸåº¦å’Œå¿«é€Ÿæ¸²æŸ“é€Ÿåº¦ï¼Œä½†åŒæ—¶ä¹Ÿä¼´éšç€æ˜¾è‘—çš„å­˜å‚¨å¼€é”€ã€‚æœ€è¿‘çš„æ–¹æ³•é€šè¿‡å¤§é‡å‡å°‘é«˜æ–¯æ•°é‡æ¥ç¼“è§£è¿™ä¸€æˆæœ¬ã€‚ç„¶è€Œï¼Œè¿™ä¸å¯é¿å…åœ°ç§»é™¤äº†å¯¹é«˜è´¨é‡æ¸²æŸ“è‡³å…³é‡è¦çš„é«˜æ–¯ï¼Œå¯¼è‡´åŠ¨æ€åŒºåŸŸå‡ºç°ä¸¥é‡é€€åŒ–ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§æ–°å‹4Dé”šç‚¹åŸºç¡€æ¡†æ¶ï¼Œä»¥ä»ä¸åŒè§’åº¦è§£å†³å­˜å‚¨æˆæœ¬é—®é¢˜ã€‚æˆ‘ä»¬çš„æ–¹æ³•ä¸æ˜¯å‡å°‘é«˜æ–¯æ•°é‡ï¼Œè€Œæ˜¯ä¿ç•™è¶³å¤Ÿçš„æ•°é‡æ¥å‡†ç¡®å»ºæ¨¡åŠ¨æ€å†…å®¹ï¼ŒåŒæ—¶å°†å®ƒä»¬å‹ç¼©æˆç´§å‡‘ã€ç½‘æ ¼å¯¹é½çš„4Dé”šç‚¹ç‰¹å¾ã€‚æ¯ä¸ªé”šç‚¹é€šè¿‡å¤šå±‚æ„ŸçŸ¥å™¨å¤„ç†ï¼Œç”Ÿæˆä¸€ç»„ç¥ç»4Dé«˜æ–¯ï¼Œä»£è¡¨å±€éƒ¨æ—¶ç©ºåŒºåŸŸã€‚æˆ‘ä»¬è®¾è®¡è¿™äº›ç¥ç»4Dé«˜æ–¯ä»¥æœ€å°çš„å‚æ•°æ•æ‰æ—¶é—´å˜åŒ–ï¼Œéå¸¸é€‚åˆåŸºäºå¤šå±‚æ„ŸçŸ¥å™¨çš„ç”Ÿæˆã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§åŠ¨æ€æ„ŸçŸ¥é”šç‚¹å¢é•¿ç­–ç•¥ï¼Œæœ‰æ•ˆåœ°å°†é¢å¤–é”šç‚¹åˆ†é…ç»™é‡å»ºä¸è¶³çš„åŠ¨æ€åŒºåŸŸã€‚æˆ‘ä»¬çš„æ–¹æ³•é€šè¿‡è°ƒæ•´é«˜æ–¯æ—¶é—´è¦†ç›–çš„ç´¯ç§¯æ¢¯åº¦ï¼Œæ˜¾è‘—æé«˜äº†åŠ¨æ€åŒºåŸŸçš„é‡å»ºè´¨é‡ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨åŠ¨æ€åŒºåŸŸå®ç°äº†æœ€å…ˆè¿›çš„è§†è§‰è´¨é‡ï¼Œä»¥å®é™…å­˜å‚¨æˆæœ¬å¤§å¹…è¶…è¶Šæ‰€æœ‰åŸºçº¿ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2411.17044v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäº4Dé”šç‚¹çš„æ–°å‹æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³å­˜å‚¨æˆæœ¬é—®é¢˜ã€‚ä¸åŒäºå‡å°‘é«˜æ–¯æ•°é‡çš„æ–¹æ³•ï¼Œè¯¥æ–¹æ³•ä¿ç•™äº†è¶³å¤Ÿæ•°é‡çš„é«˜æ–¯ä»¥å‡†ç¡®æ¨¡æ‹ŸåŠ¨æ€å†…å®¹ï¼Œå¹¶å°†å…¶å‹ç¼©æˆç´§å‡‘çš„ã€ä¸ç½‘æ ¼å¯¹é½çš„4Dé”šç‚¹ç‰¹å¾ã€‚æ¯ä¸ªé”šç‚¹é€šè¿‡å¤šå±‚æ„ŸçŸ¥å™¨ç”Ÿæˆä¸€ç»„ç¥ç»4Dé«˜æ–¯ï¼Œä»£è¡¨å±€éƒ¨æ—¶ç©ºåŒºåŸŸã€‚è¿™ç§æ–¹æ³•è®¾è®¡ç”¨äºæ•æ‰æ—¶é—´å˜åŒ–çš„æœ€å°å‚æ•°ï¼Œé€‚åˆåŸºäºMLPçš„ç”Ÿæˆã€‚æ­¤å¤–ï¼Œå¼•å…¥äº†ä¸€ç§åŠ¨æ€æ„ŸçŸ¥é”šç‚¹å¢é•¿ç­–ç•¥ï¼Œæœ‰æ•ˆåœ°ä¸ºé‡å»ºä¸è¶³çš„åŠ¨æ€åŒºåŸŸåˆ†é…é¢å¤–çš„é”šç‚¹ã€‚è¯¥æ–¹æ³•åœ¨åŠ¨æ€åŒºåŸŸå®ç°äº†æœ€ä½³è§†è§‰è´¨é‡ï¼Œä»¥å®ç”¨å­˜å‚¨æˆæœ¬å¤§å¹…åº¦è¶…è¶Šæ‰€æœ‰åŸºçº¿ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>è¯¥è®ºæ–‡æå‡ºäº†ä¸€ç§åŸºäº4Dé”šç‚¹çš„æ–°å‹æ¡†æ¶ï¼Œä¸“æ³¨äºè§£å†³å­˜å‚¨æˆæœ¬é—®é¢˜ã€‚</li>
<li>é€šè¿‡ä¿ç•™è¶³å¤Ÿæ•°é‡çš„é«˜æ–¯æ•°æ¥å‡†ç¡®æ¨¡æ‹ŸåŠ¨æ€å†…å®¹ã€‚</li>
<li>å°†è¿™äº›é«˜æ–¯æ•°å‹ç¼©æˆç´§å‡‘çš„ã€ä¸ç½‘æ ¼å¯¹é½çš„4Dé”šç‚¹ç‰¹å¾ã€‚</li>
<li>ä½¿ç”¨å¤šå±‚æ„ŸçŸ¥å™¨ï¼ˆMLPï¼‰å¤„ç†æ¯ä¸ªé”šç‚¹ï¼Œç”Ÿæˆç¥ç»4Dé«˜æ–¯ã€‚</li>
<li>è®¾è®¡è¿™äº›ç¥ç»4Dé«˜æ–¯ä»¥æœ€å°å‚æ•°æ•æ‰æ—¶é—´å˜åŒ–ã€‚</li>
<li>å¼•å…¥åŠ¨æ€æ„ŸçŸ¥é”šç‚¹å¢é•¿ç­–ç•¥ï¼Œä»¥æé«˜åŠ¨æ€åŒºåŸŸçš„é‡å»ºè´¨é‡ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2411.17044">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-9ed9ff894d29eea85ef1c6184d034220.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-f4d5926e9b5e9fed9f1040da06cc8b1f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-6c30e66900c5128a857202079be6bae3.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-526f155396ee960bee2d333de3bb6bde.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-497f03c779c3cb27cca348f8801f5c66.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-66b03d9790cef30ded1d69007e477477.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-44d157ae3e2283ff4c76eee181ebae13.jpg" align="middle">
</details>


<h1 id="-18"><a href="#-18" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-08-08/3DGS/">https://kedreamix.github.io/Talk2Paper/Paper/2025-08-08/3DGS/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/3DGS/">
                                    <span class="chip bg-color">3DGS</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-08-08/NeRF/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-ce4d29d5056acc8ebd1f2d4bbcbb6ca1.jpg" class="responsive-img" alt="NeRF">
                        
                        <span class="card-title">NeRF</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            NeRF æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-08-08  MuGS Multi-Baseline Generalizable Gaussian Splatting Reconstruction
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-08-08
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/NeRF/" class="post-category">
                                    NeRF
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/NeRF/">
                        <span class="chip bg-color">NeRF</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-08-08/GAN/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-0206045ee3e12efecdf5df2fbb5716dc.jpg" class="responsive-img" alt="GAN">
                        
                        <span class="card-title">GAN</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            GAN æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-08-08  Knowledge Distillation for Underwater Feature Extraction and Matching   via GAN-synthesized Images
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-08-08
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/GAN/" class="post-category">
                                    GAN
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/GAN/">
                        <span class="chip bg-color">GAN</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">28315.1k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
