<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Agent">
    <meta name="description" content="Agent æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-08-08  From MAS to MARS Coordination Failures and Reasoning Trade-offs in   Hierarchical Multi-Agent Robotic Systems within a Healthcare Scenario">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>Agent | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://picx.zhimg.com/v2-66775d0a15f700bc915885216720c027.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Agent</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/Agent/">
                                <span class="chip bg-color">Agent</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/Agent/" class="post-category">
                                Agent
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-08-08
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-08-20
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    18.5k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    75 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-08-08-æ›´æ–°"><a href="#2025-08-08-æ›´æ–°" class="headerlink" title="2025-08-08 æ›´æ–°"></a>2025-08-08 æ›´æ–°</h1><h2 id="From-MAS-to-MARS-Coordination-Failures-and-Reasoning-Trade-offs-in-Hierarchical-Multi-Agent-Robotic-Systems-within-a-Healthcare-Scenario"><a href="#From-MAS-to-MARS-Coordination-Failures-and-Reasoning-Trade-offs-in-Hierarchical-Multi-Agent-Robotic-Systems-within-a-Healthcare-Scenario" class="headerlink" title="From MAS to MARS: Coordination Failures and Reasoning Trade-offs in   Hierarchical Multi-Agent Robotic Systems within a Healthcare Scenario"></a>From MAS to MARS: Coordination Failures and Reasoning Trade-offs in   Hierarchical Multi-Agent Robotic Systems within a Healthcare Scenario</h2><p><strong>Authors:Yuanchen Bai, Zijian Ding, Shaoyue Wen, Xiang Chang, Angelique Taylor</strong></p>
<p>Multi-agent robotic systems (MARS) build upon multi-agent systems by integrating physical and task-related constraints, increasing the complexity of action execution and agent coordination. However, despite the availability of advanced multi-agent frameworks, their real-world deployment on robots remains limited, hindering the advancement of MARS research in practice. To bridge this gap, we conducted two studies to investigate performance trade-offs of hierarchical multi-agent frameworks in a simulated real-world multi-robot healthcare scenario. In Study 1, using CrewAI, we iteratively refine the systemâ€™s knowledge base, to systematically identify and categorize coordination failures (e.g., tool access violations, lack of timely handling of failure reports) not resolvable by providing contextual knowledge alone. In Study 2, using AutoGen, we evaluate a redesigned bidirectional communication structure and further measure the trade-offs between reasoning and non-reasoning models operating within the same robotic team setting. Drawing from our empirical findings, we emphasize the tension between autonomy and stability and the importance of edge-case testing to improve system reliability and safety for future real-world deployment. Supplementary materials, including codes, task agent setup, trace outputs, and annotated examples of coordination failures and reasoning behaviors, are available at: <a target="_blank" rel="noopener" href="https://byc-sophie.github.io/mas-to-mars/">https://byc-sophie.github.io/mas-to-mars/</a>. </p>
<blockquote>
<p>å¤šæ™ºèƒ½ä½“æœºå™¨äººç³»ç»Ÿï¼ˆMARSï¼‰é€šè¿‡æ•´åˆç‰©ç†å’Œä»»åŠ¡ç›¸å…³çº¦æŸï¼Œå»ºç«‹åœ¨å¤šæ™ºèƒ½ä½“ç³»ç»Ÿçš„åŸºç¡€ä¸Šï¼Œå¢åŠ äº†è¡ŒåŠ¨æ‰§è¡Œå’Œæ™ºèƒ½ä½“åè°ƒçš„å¤æ‚æ€§ã€‚ç„¶è€Œï¼Œå°½ç®¡æœ‰å…ˆè¿›çš„æ™ºèƒ½ä½“æ¡†æ¶å¯ç”¨ï¼Œå®ƒä»¬åœ¨æœºå™¨äººä¸Šçš„å®é™…åº”ç”¨éƒ¨ç½²ä»ç„¶æœ‰é™ï¼Œé˜»ç¢äº†MARSç ”ç©¶çš„å®é™…åº”ç”¨å‘å±•ã€‚ä¸ºäº†å¼¥è¡¥è¿™ä¸€å·®è·ï¼Œæˆ‘ä»¬è¿›è¡Œäº†ä¸¤é¡¹ç ”ç©¶ï¼Œä»¥æ¢è®¨æ¨¡æ‹Ÿç°å®ä¸–ç•Œçš„å¤šæœºå™¨äººåŒ»ç–—ä¿å¥åœºæ™¯ä¸­åˆ†å±‚å¤šæ™ºèƒ½ä½“æ¡†æ¶çš„æ€§èƒ½æƒè¡¡ã€‚åœ¨ç¬¬ä¸€é¡¹ç ”ç©¶ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨CrewAIé€æ­¥å®Œå–„ç³»ç»Ÿçš„çŸ¥è¯†åº“ï¼Œç³»ç»Ÿåœ°è¯†åˆ«å’Œåˆ†ç±»ä»…é€šè¿‡æä¾›ä¸Šä¸‹æ–‡çŸ¥è¯†æ— æ³•è§£å†³çš„åè°ƒæ•…éšœï¼ˆä¾‹å¦‚å·¥å…·è®¿é—®è¿è§„ã€æœªèƒ½åŠæ—¶å¤„ç†æ•…éšœæŠ¥å‘Šï¼‰ã€‚åœ¨ç¬¬äºŒé¡¹ç ”ç©¶ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨AutoGenè¯„ä¼°äº†é‡æ–°è®¾è®¡çš„åŒå‘é€šä¿¡ç»“æ„ï¼Œå¹¶è¿›ä¸€æ­¥æµ‹é‡äº†åŒä¸€æœºå™¨äººå›¢é˜Ÿç¯å¢ƒä¸­æ¨ç†å’Œéæ¨ç†æ¨¡å‹ä¹‹é—´çš„æƒè¡¡ã€‚æ ¹æ®æˆ‘ä»¬çš„å®è¯å‘ç°ï¼Œæˆ‘ä»¬å¼ºè°ƒäº†è‡ªä¸»æ€§ä¸ç¨³å®šæ€§ä¹‹é—´çš„ç´§å¼ å…³ç³»ä»¥åŠè¾¹ç¼˜æ¡ˆä¾‹æµ‹è¯•å¯¹æ”¹å–„ç³»ç»Ÿå¯é æ€§å’Œæœªæ¥å®é™…åº”ç”¨éƒ¨ç½²å®‰å…¨çš„é‡è¦æ€§ã€‚è¡¥å……ææ–™åŒ…æ‹¬ä»£ç ã€ä»»åŠ¡æ™ºèƒ½ä½“è®¾ç½®ã€è·Ÿè¸ªè¾“å‡ºä»¥åŠåè°ƒå¤±è´¥å’Œæ¨ç†è¡Œä¸ºçš„æ³¨é‡Šç¤ºä¾‹ï¼Œå¯åœ¨ä»¥ä¸‹ç½‘å€æ‰¾åˆ°ï¼š<a target="_blank" rel="noopener" href="https://byc-sophie.github.io/mas-to-mars/%E3%80%82">https://byc-sophie.github.io/mas-to-mars/ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.04691v1">PDF</a> </p>
<p><strong>Summary</strong><br>å¤šæ™ºèƒ½ä½“æœºå™¨äººç³»ç»Ÿï¼ˆMARSï¼‰åœ¨æ„å»ºè¿‡ç¨‹ä¸­ç»“åˆäº†ç‰©ç†å’Œä»»åŠ¡ç›¸å…³çš„çº¦æŸæ¡ä»¶ï¼Œå¢åŠ äº†åŠ¨ä½œæ‰§è¡Œå’Œæ™ºèƒ½ä½“åè°ƒçš„å¤æ‚æ€§ã€‚ä¸ºå¼¥ç°å®ä¸–ç•Œåº”ç”¨ä¸Šçš„å·®è·ï¼Œç ”ç©¶äººå‘˜è¿›è¡Œä¸¤é¡¹ç ”ç©¶è°ƒæŸ¥åˆ†å±‚å¤šæ™ºèƒ½ä½“æ¡†æ¶åœ¨æ¨¡æ‹Ÿå¤šæœºå™¨äººæŠ¤ç†åœºæ™¯çš„æƒè¡¡æ•ˆç›Šã€‚ç¬¬ä¸€é€šè¿‡CrewAIç ”ç©¶å·¥å…·ç ”ç©¶ä¸å¯ç”±å•ä¸€çŸ¥è¯†è§£å†³çš„ä¸è§£ä¹‹å¤„ï¼ˆåè°ƒæ•…éšœï¼‰ã€‚ç¬¬äºŒé‡‡ç”¨AutoGenè¡¡é‡äº†åŒä¸€ä¸ªæœºå™¨äººå›¢é˜Ÿä¸­çš„æ¨ç†ä¸éæ¨ç†æ¨¡å‹çš„æƒè¡¡å…³ç³»ã€‚ç ”ç©¶è€…ä»ç ”ç©¶ä¸­å¼ºè°ƒäº†è‡ªä¸»æ€§ä¸ç¨³å®šæ€§ä¹‹é—´çš„å¼ åŠ›ï¼Œå¹¶å¼ºè°ƒè¾¹ç¼˜æ¡ˆä¾‹æµ‹è¯•å¯¹æ”¹å–„ç³»ç»Ÿå¯é æ€§å’Œå®‰å…¨æ€§çš„é‡è¦æ€§ï¼Œä¸ºå°†æ¥çš„ç°å®åº”ç”¨æä¾›é‡è¦çš„å‚è€ƒã€‚æ›´å¤šèµ„æ–™å¯é€šè¿‡é“¾æ¥è·å–ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>MARSç»“åˆäº†ç‰©ç†å’Œä»»åŠ¡ç›¸å…³çº¦æŸï¼Œå¢åŠ äº†åŠ¨ä½œæ‰§è¡Œå’Œæ™ºèƒ½ä½“åè°ƒçš„å¤æ‚æ€§ã€‚</li>
<li>ç ”ç©¶æ—¨åœ¨é€šè¿‡å®è¯ç ”ç©¶åˆ†æåˆ†å±‚å¤šæ™ºèƒ½ä½“æ¡†æ¶åœ¨å¤šæœºå™¨äººæŠ¤ç†åœºæ™¯ä¸­çš„æƒè¡¡æ•ˆç›Šã€‚</li>
<li>é€šè¿‡CrewAIç ”ç©¶å·¥å…·ç ”ç©¶ä¸å¯é€šè¿‡å•ä¸€çŸ¥è¯†è§£å†³çš„åè°ƒé—®é¢˜ã€‚</li>
<li>é€šè¿‡AutoGenè¯„ä¼°äº†æœºå™¨äººå›¢é˜Ÿä¸­çš„æ¨ç†ä¸éæ¨ç†æ¨¡å‹çš„æƒè¡¡å…³ç³»ã€‚</li>
<li>ç ”ç©¶ç»“æœå¼ºè°ƒäº†è‡ªä¸»æ€§ä¸ç¨³å®šæ€§ä¹‹é—´çš„å¼ åŠ›ï¼Œä»¥åŠè¾¹ç¼˜æ¡ˆä¾‹æµ‹è¯•å¯¹ç³»ç»Ÿå¯é æ€§å’Œå®‰å…¨æ€§çš„é‡è¦æ€§ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.04691">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-ed0121626dd66eb096699c08d71d3e57.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b3e1ee4874e76db7650fefb3efc55477.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-b2bd92791d994a42f3fd634e3d080906.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-5627ea44a1ba3e0a36d847cd79ce7df9.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="TurboTrain-Towards-Efficient-and-Balanced-Multi-Task-Learning-for-Multi-Agent-Perception-and-Prediction"><a href="#TurboTrain-Towards-Efficient-and-Balanced-Multi-Task-Learning-for-Multi-Agent-Perception-and-Prediction" class="headerlink" title="TurboTrain: Towards Efficient and Balanced Multi-Task Learning for   Multi-Agent Perception and Prediction"></a>TurboTrain: Towards Efficient and Balanced Multi-Task Learning for   Multi-Agent Perception and Prediction</h2><p><strong>Authors:Zewei Zhou, Seth Z. Zhao, Tianhui Cai, Zhiyu Huang, Bolei Zhou, Jiaqi Ma</strong></p>
<p>End-to-end training of multi-agent systems offers significant advantages in improving multi-task performance. However, training such models remains challenging and requires extensive manual design and monitoring. In this work, we introduce TurboTrain, a novel and efficient training framework for multi-agent perception and prediction. TurboTrain comprises two key components: a multi-agent spatiotemporal pretraining scheme based on masked reconstruction learning and a balanced multi-task learning strategy based on gradient conflict suppression. By streamlining the training process, our framework eliminates the need for manually designing and tuning complex multi-stage training pipelines, substantially reducing training time and improving performance. We evaluate TurboTrain on a real-world cooperative driving dataset, V2XPnP-Seq, and demonstrate that it further improves the performance of state-of-the-art multi-agent perception and prediction models. Our results highlight that pretraining effectively captures spatiotemporal multi-agent features and significantly benefits downstream tasks. Moreover, the proposed balanced multi-task learning strategy enhances detection and prediction. </p>
<blockquote>
<p>ç«¯åˆ°ç«¯è®­ç»ƒå¤šæ™ºèƒ½ä½“ç³»ç»Ÿåœ¨æé«˜å¤šä»»åŠ¡æ€§èƒ½æ–¹é¢å…·æœ‰æ˜¾è‘—ä¼˜åŠ¿ã€‚ç„¶è€Œï¼Œè®­ç»ƒæ­¤ç±»æ¨¡å‹ä»ç„¶å…·æœ‰æŒ‘æˆ˜æ€§ï¼Œéœ€è¦å¤§é‡çš„æ‰‹åŠ¨è®¾è®¡å’Œç›‘æ§ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬ä»‹ç»äº†TurboTrainï¼Œè¿™æ˜¯ä¸€ç§ç”¨äºå¤šæ™ºèƒ½ä½“æ„ŸçŸ¥å’Œé¢„æµ‹çš„æ–°å‹é«˜æ•ˆè®­ç»ƒæ¡†æ¶ã€‚TurboTrainåŒ…å«ä¸¤ä¸ªå…³é”®ç»„ä»¶ï¼šåŸºäºæ©è†œé‡å»ºå­¦ä¹ çš„å¤šæ™ºèƒ½ä½“æ—¶ç©ºé¢„è®­ç»ƒæ–¹æ¡ˆå’ŒåŸºäºæ¢¯åº¦å†²çªæŠ‘åˆ¶çš„å¹³è¡¡å¤šä»»åŠ¡å­¦ä¹ ç­–ç•¥ã€‚é€šè¿‡ä¼˜åŒ–è®­ç»ƒè¿‡ç¨‹ï¼Œæˆ‘ä»¬çš„æ¡†æ¶æ— éœ€æ‰‹åŠ¨è®¾è®¡å’Œè°ƒæ•´å¤æ‚çš„åˆ†é˜¶æ®µè®­ç»ƒç®¡é“ï¼Œä»è€Œå¤§å¤§å‡å°‘äº†è®­ç»ƒæ—¶é—´å¹¶æé«˜äº†æ€§èƒ½ã€‚æˆ‘ä»¬åœ¨ç°å®ä¸–ç•Œçš„åˆä½œé©¾é©¶æ•°æ®é›†V2XPnP-Seqä¸Šå¯¹TurboTrainè¿›è¡Œäº†è¯„ä¼°ï¼Œå¹¶è¯æ˜å®ƒè¿›ä¸€æ­¥æé«˜äº†æœ€å…ˆè¿›çš„å¤šæ™ºèƒ½ä½“æ„ŸçŸ¥å’Œé¢„æµ‹æ¨¡å‹çš„æ€§èƒ½ã€‚æˆ‘ä»¬çš„ç»“æœå¼ºè°ƒï¼Œé¢„è®­ç»ƒæœ‰æ•ˆåœ°æ•è·äº†æ—¶ç©ºå¤šæ™ºèƒ½ä½“ç‰¹å¾ï¼Œå¹¶ä¸ºä¸‹æ¸¸ä»»åŠ¡å¸¦æ¥äº†æ˜¾è‘—çš„å¥½å¤„ã€‚æ­¤å¤–ï¼Œæå‡ºçš„å¹³è¡¡å¤šä»»åŠ¡å­¦ä¹ ç­–ç•¥æé«˜äº†æ£€æµ‹å’Œé¢„æµ‹èƒ½åŠ›ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.04682v1">PDF</a> ICCV 2025</p>
<p><strong>Summary</strong></p>
<p>æœ¬å·¥ä½œå¼•å…¥äº†ä¸€ç§åä¸ºTurboTrainçš„æ–°å‹é«˜æ•ˆå¤šæ™ºèƒ½ä½“æ„ŸçŸ¥å’Œé¢„æµ‹è®­ç»ƒæ¡†æ¶ï¼ŒåŒ…å«ä¸¤ä¸ªå…³é”®ç»„ä»¶ï¼šåŸºäºæ©ç é‡å»ºå­¦ä¹ çš„å¤šæ™ºèƒ½ä½“æ—¶ç©ºé¢„è®­ç»ƒæ–¹æ¡ˆå’ŒåŸºäºæ¢¯åº¦å†²çªæŠ‘åˆ¶çš„å¹³è¡¡å¤šä»»åŠ¡å­¦ä¹ ç­–ç•¥ã€‚é€šè¿‡ä¼˜åŒ–è®­ç»ƒè¿‡ç¨‹ï¼Œè¯¥æ¡†æ¶æ¶ˆé™¤äº†æ‰‹åŠ¨è®¾è®¡å’Œè°ƒæ•´å¤æ‚å¤šé˜¶æ®µè®­ç»ƒç®¡é“çš„éœ€æ±‚ï¼Œå¤§å¹…ç¼©çŸ­äº†è®­ç»ƒæ—¶é—´å¹¶æé«˜äº†æ€§èƒ½ã€‚åœ¨çœŸå®ä¸–ç•Œåˆä½œé©¾é©¶æ•°æ®é›†V2XPnP-Seqä¸Šçš„è¯„ä¼°ç»“æœè¡¨æ˜ï¼ŒTurboTrainèƒ½å¤Ÿè¿›ä¸€æ­¥æå‡æœ€å…ˆè¿›çš„æ™ºèƒ½ä½“æ„ŸçŸ¥å’Œé¢„æµ‹æ¨¡å‹æ€§èƒ½ã€‚å…¶ä¸­é¢„è®­ç»ƒèƒ½å¤Ÿæœ‰æ•ˆæ•è·æ—¶ç©ºå¤šæ™ºèƒ½ä½“ç‰¹å¾ï¼Œæ˜¾è‘—ä¿ƒè¿›ä¸‹æ¸¸ä»»åŠ¡æ€§èƒ½çš„æå‡ï¼›è€Œæå‡ºçš„å¹³è¡¡å¤šä»»åŠ¡å­¦ä¹ ç­–ç•¥åˆ™å¢å¼ºäº†æ£€æµ‹å’Œé¢„æµ‹èƒ½åŠ›ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>TurboTrainæ¡†æ¶åŒ…å«ä¸¤ä¸ªå…³é”®ç»„ä»¶ï¼šå¤šæ™ºèƒ½ä½“æ—¶ç©ºé¢„è®­ç»ƒæ–¹æ¡ˆå’Œå¹³è¡¡å¤šä»»åŠ¡å­¦ä¹ ç­–ç•¥ã€‚</li>
<li>å¤šæ™ºèƒ½ä½“æ—¶ç©ºé¢„è®­ç»ƒåŸºäºæ©ç é‡å»ºå­¦ä¹ ï¼Œæœ‰åŠ©äºæ•è·æ™ºèƒ½ä½“é—´çš„å¤æ‚äº¤äº’å’Œæ—¶ç©ºå…³ç³»ã€‚</li>
<li>å¹³è¡¡å¤šä»»åŠ¡å­¦ä¹ ç­–ç•¥é€šè¿‡æ¢¯åº¦å†²çªæŠ‘åˆ¶æœºåˆ¶æå‡æ¨¡å‹åœ¨å¤šä»»åŠ¡åœºæ™¯ä¸‹çš„æ€§èƒ½ã€‚</li>
<li>TurboTrainç®€åŒ–äº†å¤šæ™ºèƒ½ä½“ç³»ç»Ÿçš„è®­ç»ƒè¿‡ç¨‹ï¼Œé™ä½äº†å¤æ‚æ€§å’Œè®­ç»ƒæ—¶é—´ã€‚</li>
<li>åœ¨çœŸå®ä¸–ç•Œåˆä½œé©¾é©¶æ•°æ®é›†ä¸Šçš„è¯„ä¼°è¯æ˜äº†TurboTrainå¯¹æå‡æ™ºèƒ½ä½“æ„ŸçŸ¥å’Œé¢„æµ‹æ¨¡å‹æ€§èƒ½çš„æœ‰æ•ˆæ€§ã€‚</li>
<li>é¢„è®­ç»ƒèƒ½å¤Ÿæœ‰æ•ˆæ•è·æ—¶ç©ºå¤šæ™ºèƒ½ä½“ç‰¹å¾ï¼Œå¯¹ä¸‹æ¸¸ä»»åŠ¡æ€§èƒ½æœ‰æ˜¾è‘—æå‡ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.04682">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-d8998e6c7d84f61eb69afbe2bbad9a3d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-fdeb49ee989a9a1b439241f74fc9b1ba.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-2820e128c477095417dea4f06d1e6141.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-e1fd49382c92b7b8d60b6e84001df755.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="CONVERGE-A-Multi-Agent-Vision-Radio-Architecture-for-xApps"><a href="#CONVERGE-A-Multi-Agent-Vision-Radio-Architecture-for-xApps" class="headerlink" title="CONVERGE: A Multi-Agent Vision-Radio Architecture for xApps"></a>CONVERGE: A Multi-Agent Vision-Radio Architecture for xApps</h2><p><strong>Authors:Filipe B. Teixeira, Carolina SimÃµes, Paulo Fidalgo, Wagner Pedrosa, AndrÃ© Coelho, Manuel Ricardo, Luis M. Pessoa</strong></p>
<p>Telecommunications and computer vision have evolved independently. With the emergence of high-frequency wireless links operating mostly in line-of-sight, visual data can help predict the channel dynamics by detecting obstacles and help overcoming them through beamforming or handover techniques.   This paper proposes a novel architecture for delivering real-time radio and video sensing information to O-RAN xApps through a multi-agent approach, and introduces a new video function capable of generating blockage information for xApps, enabling Integrated Sensing and Communications. Experimental results show that the delay of sensing information remains under 1,ms and that an xApp can successfully use radio and video sensing information to control the 5G&#x2F;6G RAN in real-time. </p>
<blockquote>
<p>ç”µä¿¡å’Œè®¡ç®—æœºè§†è§‰å·²ç‹¬ç«‹å‘å±•ã€‚éšç€é«˜é¢‘æ— çº¿é“¾è·¯çš„å‡ºç°ï¼Œä¸»è¦ç”¨äºè§†çº¿ä¼ è¾“ï¼Œè§†è§‰æ•°æ®å¯ä»¥é€šè¿‡æ£€æµ‹éšœç¢ç‰©é¢„æµ‹ä¿¡é“åŠ¨æ€å˜åŒ–å¹¶æœ‰åŠ©äºå…‹æœé€šè¿‡æ³¢æŸæˆå½¢æˆ–åˆ‡æ¢æŠ€æœ¯ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§é€šè¿‡å¤šæ™ºèƒ½ä½“æ–¹æ³•å°†å®æ—¶æ— çº¿ç”µå’Œè§†é¢‘ä¼ æ„Ÿä¿¡æ¯ä¼ è¾“åˆ°O-RAN xAppsçš„æ–°å‹æ¶æ„ï¼Œå¹¶å¼•å…¥äº†ä¸€ç§å¯ä¸ºxAppsç”Ÿæˆé˜»æŒ¡ä¿¡æ¯çš„æ–°è§†é¢‘åŠŸèƒ½ï¼Œä»¥å®ç°ç»¼åˆæ„ŸçŸ¥å’Œé€šä¿¡ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œä¼ æ„Ÿä¿¡æ¯å»¶è¿Ÿä½äº1æ¯«ç§’ï¼Œå¹¶ä¸”xAppå¯ä»¥æˆåŠŸåˆ©ç”¨æ— çº¿ç”µå’Œè§†é¢‘ä¼ æ„Ÿä¿¡æ¯å®æ—¶æ§åˆ¶5G&#x2F;6G RANã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.04556v1">PDF</a> 7 pages, 5 figures</p>
<p><strong>Summary</strong><br>åœ¨ç”µä¿¡ä¸è®¡ç®—æœºè§†è§‰ç‹¬ç«‹å‘å±•çš„èƒŒæ™¯ä¸‹ï¼Œæœ¬ç ”ç©¶æå‡ºäº†ä¸€ç§æ–°å‹æ¶æ„ï¼Œé€šè¿‡å¤šä»£ç†æ–¹æ³•å°†å®æ—¶æ— çº¿ç”µå’Œè§†é¢‘æ„ŸçŸ¥ä¿¡æ¯ä¼ é€’ç»™O-RAN xAppsã€‚è¯¥ç ”ç©¶åˆ©ç”¨è§†è§‰æ•°æ®é¢„æµ‹ä¿¡é“åŠ¨æ€ï¼Œé€šè¿‡ç”Ÿæˆé˜»æŒ¡ä¿¡æ¯ä¸ºxAppsæä¾›æ”¯æŒï¼Œå®ç°é›†æˆæ„ŸçŸ¥å’Œé€šä¿¡åŠŸèƒ½ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œæ„ŸçŸ¥ä¿¡æ¯çš„å»¶è¿Ÿä½äº1æ¯«ç§’ï¼ŒxAppèƒ½å¤ŸæˆåŠŸåˆ©ç”¨æ— çº¿ç”µå’Œè§†é¢‘æ„ŸçŸ¥ä¿¡æ¯å®æ—¶æ§åˆ¶5G&#x2F;6G RANã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ç”µä¿¡ä¸è®¡ç®—æœºè§†è§‰çš„å„è‡ªå‘å±•ï¼šä»‹ç»äº†ç”µä¿¡ä¸è®¡ç®—æœºè§†è§‰é¢†åŸŸçš„ç‹¬ç«‹å‘å±•ï¼Œä¸ºæ•´åˆä¸¤è€…æ‰“ä¸‹åŸºç¡€ã€‚</li>
<li>é«˜é¢‘æ— çº¿é“¾è·¯ä¸è§†è§‰æ•°æ®çš„ç»“åˆï¼šè§†è§‰æ•°æ®å¯å¸®åŠ©é¢„æµ‹ä¿¡é“åŠ¨æ€ï¼Œé€šè¿‡æ£€æµ‹éšœç¢ç‰©æ¥å¸®åŠ©å…‹æœé€šä¿¡éšœç¢ã€‚</li>
<li>æ–°å‹æ¶æ„çš„æå‡ºï¼šç ”ç©¶æå‡ºäº†ä¸€ç§æ–°çš„æ¶æ„ï¼Œé€šè¿‡å¤šä»£ç†æ–¹æ³•ä¼ é€’å®æ—¶æ— çº¿ç”µå’Œè§†é¢‘æ„ŸçŸ¥ä¿¡æ¯ç»™O-RAN xAppsã€‚</li>
<li>è§†é¢‘åŠŸèƒ½çš„å¼•å…¥ï¼šå¼•å…¥äº†ä¸€ç§èƒ½å¤Ÿç”Ÿæˆé˜»æŒ¡ä¿¡æ¯çš„è§†é¢‘åŠŸèƒ½ï¼Œä¸ºxAppsæä¾›æ”¯æŒã€‚</li>
<li>é›†æˆæ„ŸçŸ¥å’Œé€šä¿¡çš„å®ç°ï¼šé€šè¿‡ç»“åˆæ— çº¿ç”µå’Œè§†é¢‘æ„ŸçŸ¥ä¿¡æ¯ï¼Œå®ç°äº†é›†æˆæ„ŸçŸ¥å’Œé€šä¿¡åŠŸèƒ½ã€‚</li>
<li>å®éªŒç»“æœï¼šå®éªŒç»“æœæ˜¾ç¤ºæ„ŸçŸ¥ä¿¡æ¯çš„å»¶è¿Ÿæä½ï¼Œå¹¶ä¸”xAppèƒ½å¤ŸæˆåŠŸåˆ©ç”¨è¿™äº›ä¿¡æ¯å®æ—¶æ§åˆ¶RANã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.04556">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-61854b4ebae8212351aacad785a555f8.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-39d84b1e8463028edbbb43854e06cf65.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-9874e7082539c13a3e2675a324024d71.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-782a738358436e72205c90635ef6ff3c.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-1ba05c780635eb44804022d84583c03e.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-73b612a7ca6a61281c4dfea00f212164.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="Think-Before-You-Segment-An-Object-aware-Reasoning-Agent-for-Referring-Audio-Visual-Segmentation"><a href="#Think-Before-You-Segment-An-Object-aware-Reasoning-Agent-for-Referring-Audio-Visual-Segmentation" class="headerlink" title="Think Before You Segment: An Object-aware Reasoning Agent for Referring   Audio-Visual Segmentation"></a>Think Before You Segment: An Object-aware Reasoning Agent for Referring   Audio-Visual Segmentation</h2><p><strong>Authors:Jinxing Zhou, Yanghao Zhou, Mingfei Han, Tong Wang, Xiaojun Chang, Hisham Cholakkal, Rao Muhammad Anwer</strong></p>
<p>Referring Audio-Visual Segmentation (Ref-AVS) aims to segment target objects in audible videos based on given reference expressions. Prior works typically rely on learning latent embeddings via multimodal fusion to prompt a tunable SAM&#x2F;SAM2 decoder for segmentation, which requires strong pixel-level supervision and lacks interpretability. From a novel perspective of explicit reference understanding, we propose TGS-Agent, which decomposes the task into a Think-Ground-Segment process, mimicking the human reasoning procedure by first identifying the referred object through multimodal analysis, followed by coarse-grained grounding and precise segmentation. To this end, we first propose Ref-Thinker, a multimodal language model capable of reasoning over textual, visual, and auditory cues. We construct an instruction-tuning dataset with explicit object-aware think-answer chains for Ref-Thinker fine-tuning. The object description inferred by Ref-Thinker is used as an explicit prompt for Grounding-DINO and SAM2, which perform grounding and segmentation without relying on pixel-level supervision. Additionally, we introduce R\textsuperscript{2}-AVSBench, a new benchmark with linguistically diverse and reasoning-intensive references for better evaluating model generalization. Our approach achieves state-of-the-art results on both standard Ref-AVSBench and proposed R\textsuperscript{2}-AVSBench. Code will be available at <a target="_blank" rel="noopener" href="https://github.com/jasongief/TGS-Agent">https://github.com/jasongief/TGS-Agent</a>. </p>
<blockquote>
<p>å‚ç…§è§†å¬åˆ†å‰²ï¼ˆRef-AVSï¼‰æ—¨åœ¨æ ¹æ®ç»™å®šçš„å‚è€ƒè¡¨è¾¾å¼å¯¹å¯å¬è§†é¢‘ä¸­çš„ç›®æ ‡å¯¹è±¡è¿›è¡Œåˆ†å‰²ã€‚æ—©æœŸçš„å·¥ä½œé€šå¸¸ä¾èµ–äºé€šè¿‡å¤šæ¨¡æ€èåˆå­¦ä¹ æ½œåœ¨åµŒå…¥ï¼Œä»¥æç¤ºå¯è°ƒSAM&#x2F;SAM2è§£ç å™¨è¿›è¡Œåˆ†å‰²ï¼Œè¿™éœ€è¦å¼ºçƒˆçš„åƒç´ çº§ç›‘ç£å¹¶ä¸”ç¼ºä¹å¯è§£é‡Šæ€§ã€‚ä»æ˜ç¡®çš„å‚è€ƒç†è§£è¿™ä¸€æ–°é¢–è§’åº¦å‡ºå‘ï¼Œæˆ‘ä»¬æå‡ºäº†TGS-Agentï¼Œå®ƒå°†ä»»åŠ¡åˆ†è§£ä¸ºThink-Ground-Segmentè¿‡ç¨‹ï¼Œé€šè¿‡é¦–å…ˆé€šè¿‡å¤šæ¨¡æ€åˆ†æè¯†åˆ«æ‰€æŒ‡å¯¹è±¡ï¼Œç„¶åè¿›è¡Œç²—ç²’åº¦å®šä½ï¼Œæœ€åç²¾ç¡®åˆ†å‰²ï¼Œæ¨¡ä»¿äººç±»çš„æ¨ç†è¿‡ç¨‹ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬é¦–å…ˆæå‡ºäº†Ref-Thinkerï¼Œè¿™æ˜¯ä¸€ä¸ªèƒ½å¤Ÿæ¨ç†æ–‡æœ¬ã€è§†è§‰å’Œå¬è§‰çº¿ç´¢çš„å¤šæ¨¡æ€è¯­è¨€æ¨¡å‹ã€‚æˆ‘ä»¬æ„å»ºäº†ä¸€ä¸ªæŒ‡ä»¤å¾®è°ƒæ•°æ®é›†ï¼Œå…¶ä¸­åŒ…å«ç”¨äºRef-Thinkerç²¾ç»†è°ƒæ•´çš„å…·æœ‰æ˜ç¡®å¯¹è±¡æ„ŸçŸ¥çš„think-answeré“¾ã€‚é€šè¿‡Ref-Thinkeræ¨æ–­çš„å¯¹è±¡æè¿°è¢«ç”¨ä½œGrounding-DINOå’ŒSAMå©´å„¿åºŠçš„æ˜ç¡®æç¤ºï¼Œå®ƒä»¬æ‰§è¡Œå®šä½ä¸åˆ†å‰²æ— éœ€ä¾èµ–åƒç´ çº§ç›‘ç£ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬ä»‹ç»äº†RÂ² - AVSBenchåŸºå‡†æµ‹è¯•æ•°æ®é›†ç”¨äºæ›´å¥½çš„è¯„ä¼°æ¨¡å‹æ³›åŒ–èƒ½åŠ›å…·æœ‰è¯­è¨€å¤šæ ·æ€§å’Œæ¨ç†å¯†é›†å‹å‚è€ƒé›†çš„æ–°åŸºå‡†æµ‹è¯•æ•°æ®é›†RÂ² AVSBenchä¸Šè¿›è¡Œè¯„ä¼°æˆ‘ä»¬çš„æ–¹æ³•åœ¨æ ‡å‡†Ref AVSBenchä»¥åŠæå‡ºçš„RÂ² AVSBenchä¸Šå‡è¾¾åˆ°äº†æœ€å…ˆè¿›çš„æˆæœç›¸å…³ä»£ç å°†åœ¨<a target="_blank" rel="noopener" href="https://github.com/jasongief/TGS-Agent%E4%B8%8A%E6%8F%90%E4%BE%9B%E3%80%82">https://github.com/jasongief/TGS-Agentä¸Šæä¾›ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.04418v1">PDF</a> Project page: <a target="_blank" rel="noopener" href="https://github.com/jasongief/TGS-Agent">https://github.com/jasongief/TGS-Agent</a></p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†é’ˆå¯¹éŸ³é¢‘è§†é¢‘åˆ†å‰²ä»»åŠ¡çš„æ–°å‹æ–¹æ³•TGS-Agentã€‚è¯¥æ–¹æ³•é‡‡ç”¨æ˜ç¡®å‚è€ƒç†è§£çš„è§’åº¦ï¼Œå°†ä»»åŠ¡åˆ†è§£ä¸ºThink-Ground-Segmentè¿‡ç¨‹ï¼Œé€šè¿‡å¤šæ¨¡æ€åˆ†æè¯†åˆ«ç›®æ ‡å¯¹è±¡ï¼Œç„¶åè¿›è¡Œç²—ç•¥å®šä½ä¸ç²¾ç¡®åˆ†å‰²ã€‚ä¸ºæ­¤ï¼Œæå‡ºäº†Ref-Thinkerå¤šæ¨¡æ€è¯­è¨€æ¨¡å‹ï¼Œèƒ½å¤Ÿæ¨ç†æ–‡æœ¬ã€è§†è§‰å’Œå¬è§‰çº¿ç´¢ã€‚æ„å»ºäº†ç”¨äºRef-Thinkerç²¾ç»†è°ƒæ•´çš„æŒ‡ä»¤è°ƒæ•´æ•°æ®é›†ï¼Œå…¶ä¸­åŒ…å«æ˜ç¡®çš„ç›®æ ‡æ„ŸçŸ¥æ€è€ƒç­”æ¡ˆé“¾ã€‚é€šè¿‡Ref-Thinkeræ¨æ–­çš„å¯¹è±¡æè¿°ä½œä¸ºå¯¹Grounding-DINOå’ŒSAM2çš„æ˜ç¡®æç¤ºï¼Œè¿›è¡Œå®šä½å’Œåˆ†å‰²ï¼Œæ— éœ€åƒç´ çº§ç›‘ç£ã€‚æ­¤å¤–ï¼Œå¼•å…¥äº†æ–°çš„åŸºå‡†æµ‹è¯•R\textsuperscript{2}-AVSBenchï¼Œç”¨äºè¯„ä¼°æ¨¡å‹å¯¹è¯­è¨€å¤šæ ·æ€§å’Œæ¨ç†å¯†é›†å‚è€ƒçš„æ³›åŒ–èƒ½åŠ›ã€‚TGS-Agentåœ¨æ ‡å‡†Ref-AVSBenchå’Œæå‡ºçš„R\textsuperscript{2}-AVSBenchä¸Šå‡å–å¾—æœ€ä½³ç»“æœã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>TGS-Agenté‡‡ç”¨æ˜ç¡®å‚è€ƒç†è§£æ–¹æ³•ï¼Œå°†éŸ³é¢‘è§†é¢‘åˆ†å‰²ä»»åŠ¡åˆ†è§£ä¸ºThink-Ground-Segmentè¿‡ç¨‹ã€‚</li>
<li>æå‡ºRef-Thinkerå¤šæ¨¡æ€è¯­è¨€æ¨¡å‹ï¼Œèƒ½æ¨ç†æ–‡æœ¬ã€è§†è§‰å’Œå¬è§‰çº¿ç´¢ï¼Œç”¨äºè¯†åˆ«ç›®æ ‡å¯¹è±¡ã€‚</li>
<li>æ„å»ºäº†æŒ‡ä»¤è°ƒæ•´æ•°æ®é›†ç”¨äºRef-Thinkerçš„ç²¾ç»†è°ƒæ•´ï¼ŒåŒ…å«ç›®æ ‡æ„ŸçŸ¥æ€è€ƒç­”æ¡ˆé“¾ã€‚</li>
<li>Ref-Thinkeræ¨æ–­çš„å¯¹è±¡æè¿°ä½œä¸ºå¯¹Grounding-DINOå’ŒSAM2çš„æ˜ç¡®æç¤ºï¼Œå®ç°å®šä½å’Œåˆ†å‰²ã€‚</li>
<li>æ— éœ€åƒç´ çº§ç›‘ç£ï¼Œæé«˜äº†æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚</li>
<li>å¼•å…¥æ–°çš„åŸºå‡†æµ‹è¯•R\textsuperscript{2}-AVSBenchï¼Œä»¥è¯„ä¼°æ¨¡å‹åœ¨è¯­è¨€å¤šæ ·æ€§å’Œæ¨ç†å¯†é›†å‚è€ƒæ–¹é¢çš„æ€§èƒ½ã€‚</li>
<li>TGS-Agentåœ¨æ ‡å‡†æµ‹è¯•ä¸Šå–å¾—æœ€ä½³ç»“æœã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.04418">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-5c52c96e0c2875228103089bee9237c0.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-98991b6c2c4c6e21564bc657de0cb844.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-77b4efdfd8c77575c393a2a6cc9f759f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-15dc138b6bc925bf9acfb1a0227d974f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-4e93abc6269c861370f852bd98f60aeb.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="Beyond-Pixels-Exploring-DOM-Downsampling-for-LLM-Based-Web-Agents"><a href="#Beyond-Pixels-Exploring-DOM-Downsampling-for-LLM-Based-Web-Agents" class="headerlink" title="Beyond Pixels: Exploring DOM Downsampling for LLM-Based Web Agents"></a>Beyond Pixels: Exploring DOM Downsampling for LLM-Based Web Agents</h2><p><strong>Authors:Thassilo M. Schiepanski, Nicholas PiÃ«l</strong></p>
<p>Frontier LLMs only recently enabled serviceable, autonomous web agents. At that, a model poses as an instantaneous domain model backend. Ought to suggest interaction, it is consulted with a web-based task and respective application state. The key problem lies in application state serialisation $\unicode{x2013}$ referred to as snapshot. State-of-the-art web agents are premised on grounded GUI snapshots, i.e., screenshots enhanced with visual cues. Not least to resemble human perception, but for images representing relatively cheap means of model input. LLM vision still lag behind code interpretation capabilities. DOM snapshots, which structurally resemble HTML, impose a desired alternative. Vast model input token size, however, disables reliable implementation with web agents to date.   We propose D2Snap, a first-of-its-kind DOM downsampling algorithm. Based on a GPT-4o backend, we evaluate D2Snap on tasks sampled from the Online-Mind2Web dataset. The success rate of D2Snap-downsampled DOM snapshots (67%) matches a grounded GUI snapshot baseline (65%) $\unicode{x2013}$ within the same input token order of magnitude (1e3). Our best evaluated configurations $\unicode{x2013}$ one token order above, but within the modelâ€™s context window $\unicode{x2013}$ outperform this baseline by 8%. Our evaluation, moreover, yields that DOM-inherent hierarchy embodies a strong UI feature for LLMs. </p>
<blockquote>
<p>å‰æ²¿çš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰æœ€è¿‘æ‰å¼€å§‹å®ç°å¯æœåŠ¡çš„ã€è‡ªä¸»çš„Webä»£ç†ã€‚åœ¨æ­¤æƒ…å†µä¸‹ï¼Œä¸€ä¸ªæ¨¡å‹å……å½“å³æ—¶é¢†åŸŸæ¨¡å‹åç«¯ã€‚å½“éœ€è¦å»ºè®®äº¤äº’æ—¶ï¼Œå®ƒä¼šä¸åŸºäºWebçš„ä»»åŠ¡å’Œç›¸åº”çš„åº”ç”¨ç¨‹åºçŠ¶æ€è¿›è¡Œåå•†ã€‚å…³é”®é—®é¢˜åœ¨äºåº”ç”¨ç¨‹åºçŠ¶æ€çš„åºåˆ—åŒ–â€”â€”è¢«ç§°ä¸ºå¿«ç…§ã€‚æœ€å…ˆè¿›çš„Webä»£ç†åŸºäºå®é™…çš„GUIå¿«ç…§ï¼Œå³å¢å¼ºè§†è§‰çº¿ç´¢çš„æˆªå›¾ã€‚è¿™ä¸ä»…æ˜¯ä¸ºäº†æ¨¡ä»¿äººç±»æ„ŸçŸ¥ï¼Œè€Œä¸”å›¾åƒä»£è¡¨äº†ä¸€ç§ç›¸å¯¹å»‰ä»·çš„æ¨¡å‹è¾“å…¥æ‰‹æ®µã€‚ç„¶è€Œï¼ŒLLMçš„è§†é‡ä»ç„¶è½åäºä»£ç è§£é‡Šèƒ½åŠ›ã€‚DOMå¿«ç…§ä»ç»“æ„ä¸Šç±»ä¼¼äºHTMLï¼Œæˆä¸ºäº†ä¸€ç§ç†æƒ³çš„é€‰æ‹©ã€‚ç„¶è€Œï¼Œå·¨å¤§çš„æ¨¡å‹è¾“å…¥ä»¤ç‰Œè§„æ¨¡ä»ç„¶ä½¿å¯é çš„Webä»£ç†å®ç°éš¾ä»¥å®ç°ã€‚æˆ‘ä»¬æå‡ºäº†D2Snapï¼Œè¿™æ˜¯ä¸€ç§é¦–åˆ›çš„DOMé™é‡‡æ ·ç®—æ³•ã€‚åŸºäºGPT-4oåç«¯ï¼Œæˆ‘ä»¬å¯¹Online-Mind2Webæ•°æ®é›†çš„ä»»åŠ¡æ ·æœ¬å¯¹D2Snapè¿›è¡Œäº†è¯„ä¼°ã€‚D2Snapé™é‡‡æ ·DOMå¿«ç…§çš„æˆåŠŸç‡ï¼ˆ67%ï¼‰ä¸åŸºäºå®é™…GUIçš„å¿«ç…§åŸºçº¿ï¼ˆ65%ï¼‰ç›¸åŒ¹é…â€”â€”å¤„äºç›¸åŒçš„è¾“å…¥ä»¤ç‰Œæ•°é‡çº§ï¼ˆ1e3ï¼‰å†…ã€‚æˆ‘ä»¬è¯„ä¼°çš„æœ€ä½³é…ç½®â€”â€”æ¯”æ¨¡å‹ä¸Šä¸‹æ–‡çª—å£é«˜ä¸€ä¸ªä»¤ç‰Œæ•°é‡çº§â€”â€”ä½†è¶…å‡ºäº†è¿™ä¸ªåŸºçº¿8%ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬çš„è¯„ä¼°è¿˜è¡¨æ˜ï¼ŒDOMå›ºæœ‰çš„å±‚æ¬¡ç»“æ„å¯¹äºå¤§å‹è¯­è¨€æ¨¡å‹æ¥è¯´æ˜¯ä¸€ä¸ªå¼ºå¤§çš„ç”¨æˆ·ç•Œé¢ç‰¹å¾ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.04412v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>åŸºäºå‰æ²¿çš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ï¼Œå‡ºç°äº†èƒ½å¤Ÿæä¾›æœåŠ¡ã€è‡ªä¸»è¿è¡Œçš„ç½‘é¡µä»£ç†ã€‚æ¨¡å‹ä½œä¸ºå³æ—¶é¢†åŸŸæ¨¡å‹åç«¯ï¼Œé€šè¿‡å’¨è¯¢webä»»åŠ¡åŠç›¸å…³åº”ç”¨ç¨‹åºçŠ¶æ€è¿›è¡Œäº¤äº’ã€‚ä¸»è¦é—®é¢˜åœ¨äºåº”ç”¨ç¨‹åºçŠ¶æ€åºåˆ—åŒ–ï¼Œå³æ‰€è°“çš„å¿«ç…§æŠ€æœ¯ã€‚å½“å‰å…ˆè¿›çš„ç½‘é¡µä»£ç†ä¾èµ–äºåŸºäºå›¾åƒçš„å¿«ç…§æŠ€æœ¯ï¼Œå³å¢å¼ºè§†è§‰çº¿ç´¢çš„æˆªå›¾ã€‚ä¸ºäº†æ¨¡ä»¿äººç±»æ„ŸçŸ¥ï¼Œå›¾åƒæˆä¸ºæ¨¡å‹è¾“å…¥çš„ç›¸å¯¹å»‰ä»·æ‰‹æ®µã€‚ç„¶è€Œï¼ŒLLMåœ¨è§†è§‰æ–¹é¢ä»ç„¶è½åäºä»£ç è§£é‡Šèƒ½åŠ›ã€‚DOMå¿«ç…§çš„ç»“æ„ç±»ä¼¼äºHTMLï¼Œæˆä¸ºäº†ä¸€ç§ç†æƒ³çš„æ›¿ä»£æ–¹æ¡ˆã€‚ç„¶è€Œï¼Œå·¨å¤§çš„æ¨¡å‹è¾“å…¥ä»¤ç‰Œè§„æ¨¡é˜»ç¢äº†ç½‘é¡µä»£ç†çš„å¯é å®ç°ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬æå‡ºäº†D2Snapï¼Œè¿™æ˜¯ä¸€ç§é¦–åˆ›çš„DOMé™é‡‡æ ·ç®—æ³•ã€‚åŸºäºGPT-4oåç«¯ï¼Œæˆ‘ä»¬å¯¹Online-Mind2Webæ•°æ®é›†çš„ä»»åŠ¡æ ·æœ¬è¿›è¡Œäº†è¯„ä¼°ã€‚D2Snapé™é‡‡æ ·DOMå¿«ç…§çš„æˆåŠŸç‡ï¼ˆ67%ï¼‰ä¸åŸºäºå›¾åƒçš„å¿«ç…§åŸºçº¿ï¼ˆ65%ï¼‰ç›¸å½“ï¼Œä¸”è¾“å…¥ä»¤ç‰Œæ•°é‡çº§ç›¸åŒï¼ˆ1e3ï¼‰ã€‚åœ¨æ¨¡å‹ä¸Šä¸‹æ–‡çª—å£å†…ï¼Œæœ€ä½³é…ç½®è¶…è¶Šäº†è¿™ä¸€åŸºçº¿8%ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬çš„è¯„ä¼°æ˜¾ç¤ºDOMå›ºæœ‰çš„å±‚æ¬¡ç»“æ„å¯¹LLMsæ¥è¯´æ˜¯ä¸€ä¸ªå¼ºå¤§çš„ç”¨æˆ·ç•Œé¢ç‰¹å¾ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å‰æ²¿LLMä½¿å¾—è‡ªä¸»webä»£ç†æˆä¸ºå¯èƒ½ã€‚</li>
<li>å½“å‰webä»£ç†é¢ä¸´çš„ä¸»è¦æŒ‘æˆ˜åœ¨äºåº”ç”¨ç¨‹åºçŠ¶æ€åºåˆ—åŒ–ï¼Œå³å¿«ç…§æŠ€æœ¯ã€‚</li>
<li>åŸºäºå›¾åƒçš„å¿«ç…§æŠ€æœ¯æ¨¡ä»¿äº†äººç±»æ„ŸçŸ¥ï¼Œä½†LLMåœ¨è§†è§‰æ–¹é¢çš„èƒ½åŠ›ä»ç„¶æœ‰é™ã€‚</li>
<li>DOMå¿«ç…§æˆä¸ºäº†ä¸€ç§ç†æƒ³çš„æ›¿ä»£æ–¹æ¡ˆï¼Œä½†å®ç°ä¸Šå­˜åœ¨å¯é æ€§é—®é¢˜ã€‚</li>
<li>æå‡ºçš„D2Snapç®—æ³•æ˜¯é¦–åˆ›çš„DOMé™é‡‡æ ·æ–¹æ³•ï¼Œæ€§èƒ½ä¼˜è¶Šã€‚</li>
<li>D2Snapçš„æˆåŠŸç‡ä¸åŸºäºå›¾åƒçš„å¿«ç…§åŸºçº¿ç›¸å½“ï¼Œå¹¶ä¸”åœ¨æŸäº›é…ç½®ä¸‹è¶…è¶Šäº†è¿™ä¸€åŸºçº¿ã€‚</li>
<li>DOMå›ºæœ‰çš„å±‚æ¬¡ç»“æ„å¯¹LLMsæ¥è¯´æ˜¯ä¸€ä¸ªå¼ºå¤§çš„ç”¨æˆ·ç•Œé¢ç‰¹å¾ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.04412">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-57805b51a3b50aa7d708f0a145156d4e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-9777df4e6fc39f2cca77eab53122dc5b.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-ce812b3b23935dce3e223c3b0208cf7f.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-ab55f931194cb0099472cf9000dd01a0.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-1d1b755a43e8d06f7acf3214080d93df.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="Multi-Agent-Taskforce-Collaboration-Self-Correction-of-Compounding-Errors-in-Long-Form-Literature-Review-Generation"><a href="#Multi-Agent-Taskforce-Collaboration-Self-Correction-of-Compounding-Errors-in-Long-Form-Literature-Review-Generation" class="headerlink" title="Multi-Agent Taskforce Collaboration: Self-Correction of Compounding   Errors in Long-Form Literature Review Generation"></a>Multi-Agent Taskforce Collaboration: Self-Correction of Compounding   Errors in Long-Form Literature Review Generation</h2><p><strong>Authors:Zhi Zhang, Yan Liu, Zhejing Hu, Gong Chen, Sheng-hua Zhong, Jiannong Cao</strong></p>
<p>Literature reviews play an important role in scientific research. Recent advances in large language models (LLMs) have boosted the development of automated systems for the entire literature review workflow, from retrieval to manuscript drafting. However, a key challenge is that mistakes made in early stages can propagate and amplify in subsequent steps, leading to compounding errors that undermine the faithfulness of the final review. To tackle this issue, we propose the Multi-Agent Taskforce Collaboration (MATC) framework, which consists of a manager agent and four executor agents for literature searching, outline generation, fact localization, and manuscript drafting. We propose three novel collaboration paradigms, forming exploration, exploitation, and experience taskforces, to effectively organize agents and mitigate compounding errors both between and within executor agents. Experimental results show that MATC achieves state-of-the-art performance on existing benchmarks. We further propose a new benchmark dataset featuring more diverse topics for faithful literature review generation. </p>
<blockquote>
<p>æ–‡çŒ®ç»¼è¿°åœ¨ç§‘å­¦ç ”ç©¶é¢†åŸŸæ‰®æ¼”ç€é‡è¦è§’è‰²ã€‚è¿‘æœŸï¼Œå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„è¿›æ­¥æ¨åŠ¨äº†æ•´ä¸ªæ–‡çŒ®ç»¼è¿°å·¥ä½œæµçš„è‡ªåŠ¨åŒ–ç³»ç»Ÿçš„å‘å±•ï¼Œä»æ£€ç´¢åˆ°æ‰‹ç¨¿èµ·è‰ã€‚ç„¶è€Œï¼Œä¸€ä¸ªå…³é”®æŒ‘æˆ˜åœ¨äºï¼Œæ—©æœŸé˜¶æ®µçš„é”™è¯¯å¯èƒ½ä¼šåœ¨åç»­æ­¥éª¤ä¸­ä¼ æ’­å’Œæ”¾å¤§ï¼Œä»è€Œå¯¼è‡´ç´¯ç§¯é”™è¯¯ï¼Œç ´åæœ€ç»ˆè¯„å®¡çš„å¿ å®æ€§ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†å¤šä»£ç†ä»»åŠ¡åŠ›åä½œï¼ˆMATCï¼‰æ¡†æ¶ï¼Œè¯¥æ¡†æ¶ç”±ä¸€ä¸ªç®¡ç†ä»£ç†å’Œå››ä¸ªæ‰§è¡Œä»£ç†ç»„æˆï¼Œåˆ†åˆ«è´Ÿè´£æ–‡çŒ®æœç´¢ã€å¤§çº²ç”Ÿæˆã€äº‹å®å®šä½å’Œæ‰‹ç¨¿èµ·è‰ã€‚æˆ‘ä»¬æå‡ºäº†ä¸‰ç§æ–°çš„åä½œèŒƒå¼ï¼Œå³æ¢ç´¢ã€åˆ©ç”¨å’Œç»éªŒä»»åŠ¡åŠ›ï¼Œä»¥æœ‰æ•ˆåœ°ç»„ç»‡ä»£ç†å¹¶å‡è½»æ‰§è¡Œä»£ç†ä¹‹é—´ä»¥åŠå†…éƒ¨çš„ç´¯ç§¯é”™è¯¯ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒMATCåœ¨ç°æœ‰åŸºå‡†æµ‹è¯•ä¸Šè¾¾åˆ°äº†æœ€æ–°æŠ€æœ¯æ°´å¹³ã€‚æˆ‘ä»¬è¿›ä¸€æ­¥æå‡ºäº†ä¸€ä¸ªåŒ…å«æ›´å¤šä¸»é¢˜çš„æ–°åŸºå‡†æ•°æ®é›†ï¼Œç”¨äºç”Ÿæˆå¿ å®çš„æ–‡çŒ®ç»¼è¿°ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.04306v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†æ–‡çŒ®ç»¼è¿°åœ¨ç§‘å­¦ç ”ç©¶ä¸­æ‰®æ¼”çš„é‡è¦è§’è‰²ï¼Œä»¥åŠè¿‘æœŸå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„è¿›æ­¥æ¨åŠ¨äº†è‡ªåŠ¨åŒ–æ–‡çŒ®ç»¼è¿°å·¥ä½œæµçš„å¼€å‘ã€‚ç„¶è€Œï¼Œæ—©æœŸé˜¶æ®µçš„é”™è¯¯ä¼šç´¯ç§¯å¹¶æ”¾å¤§åç»­æ­¥éª¤ä¸­çš„é—®é¢˜ï¼Œå¯¼è‡´æœ€ç»ˆå®¡æŸ¥çš„å¿ å®æ€§å—åˆ°æŸå®³ã€‚ä¸ºè§£å†³è¿™ä¸€é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†å¤šä»£ç†ä»»åŠ¡åä½œï¼ˆMATCï¼‰æ¡†æ¶ï¼ŒåŒ…æ‹¬ä¸€ä¸ªç®¡ç†ä»£ç†å’Œå››ä¸ªæ‰§è¡Œä»£ç†ï¼Œç”¨äºæ–‡çŒ®æ£€ç´¢ã€å¤§çº²ç”Ÿæˆã€äº‹å®å®šä½å’Œæ‰‹ç¨¿èµ·è‰ã€‚é€šè¿‡å½¢æˆæ¢ç´¢ã€å¼€å‘å’Œç»éªŒä»»åŠ¡å°ç»„ï¼Œæœ‰æ•ˆç»„ç»‡ä»£ç†å¹¶å‡è½»æ‰§è¡Œä»£ç†å†…éƒ¨å’Œå¤–éƒ¨çš„ç´¯ç§¯é”™è¯¯ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒMATCåœ¨ç°æœ‰åŸºå‡†æµ‹è¯•ä¸Šå–å¾—äº†æœ€æ–°æŠ€æœ¯æ°´å¹³çš„æ€§èƒ½è¡¨ç°ã€‚æ­¤å¤–ï¼Œæœ¬æ–‡è¿˜æå‡ºäº†ä¸€ä¸ªæ–°çš„åŒ…å«æ›´å¤šä¸»é¢˜å¤šæ ·æ€§çš„åŸºå‡†æ•°æ®é›†ï¼Œç”¨äºå¿ å®æ–‡çŒ®ç»¼è¿°ç”Ÿæˆã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æ–‡çŒ®ç»¼è¿°åœ¨ç§‘å­¦ç ”ç©¶ä¸­å…·æœ‰é‡è¦åœ°ä½ã€‚</li>
<li>å¤§å‹è¯­è¨€æ¨¡å‹çš„è¿›æ­¥æ¨åŠ¨äº†è‡ªåŠ¨åŒ–æ–‡çŒ®ç»¼è¿°å·¥ä½œæµçš„å¼€å‘ã€‚</li>
<li>æ—©æœŸé˜¶æ®µçš„é”™è¯¯ä¼šç´¯ç§¯å¹¶å½±å“åç»­æ­¥éª¤ï¼Œå¯¼è‡´å¿ å®æ€§é—®é¢˜ã€‚</li>
<li>æå‡ºå¤šä»£ç†ä»»åŠ¡åä½œï¼ˆMATCï¼‰æ¡†æ¶ï¼ŒåŒ…æ‹¬ç®¡ç†ä»£ç†å’Œå››ä¸ªæ‰§è¡Œä»£ç†ã€‚</li>
<li>å½¢æˆæ¢ç´¢ã€å¼€å‘å’Œç»éªŒä»»åŠ¡å°ç»„ä»¥æœ‰æ•ˆç»„ç»‡ä»£ç†å¹¶å‡å°‘é”™è¯¯ã€‚</li>
<li>MATCåœ¨ç°æœ‰åŸºå‡†æµ‹è¯•ä¸­è¡¨ç°ä¼˜å¼‚ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.04306">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-03073db20769e5b4c556ff006298eedb.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-7eddd5edb9ff32615d489f88c70d3aea.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-6fa8316ef0d85416570538381a666a04.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-019431fe98dcecc853dbb3516f9516cc.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-5dd1dd6be477343a22da4484cefd3788.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="ShoppingBench-A-Real-World-Intent-Grounded-Shopping-Benchmark-for-LLM-based-Agents"><a href="#ShoppingBench-A-Real-World-Intent-Grounded-Shopping-Benchmark-for-LLM-based-Agents" class="headerlink" title="ShoppingBench: A Real-World Intent-Grounded Shopping Benchmark for   LLM-based Agents"></a>ShoppingBench: A Real-World Intent-Grounded Shopping Benchmark for   LLM-based Agents</h2><p><strong>Authors:Jiangyuan Wang, Kejun Xiao, Qi Sun, Huaipeng Zhao, Tao Luo, Jiandong Zhang, Xiaoyi Zeng</strong></p>
<p>Existing benchmarks in e-commerce primarily focus on basic user intents, such as finding or purchasing products. However, real-world users often pursue more complex goals, such as applying vouchers, managing budgets, and finding multi-products seller. To bridge this gap, we propose ShoppingBench, a novel end-to-end shopping benchmark designed to encompass increasingly challenging levels of grounded intent. Specifically, we propose a scalable framework to simulate user instructions based on various intents derived from sampled real-world products. To facilitate consistent and reliable evaluations, we provide a large-scale shopping sandbox that serves as an interactive simulated environment, incorporating over 2.5 million real-world products. Experimental results demonstrate that even state-of-the-art language agents (such as GPT-4.1) achieve absolute success rates under 50% on our benchmark tasks, highlighting the significant challenges posed by our ShoppingBench. In addition, we propose a trajectory distillation strategy and leverage supervised fine-tuning, along with reinforcement learning on synthetic trajectories, to distill the capabilities of a large language agent into a smaller one. As a result, our trained agent achieves competitive performance compared to GPT-4.1. </p>
<blockquote>
<p>ç°æœ‰çš„ç”µå­å•†åŠ¡åŸºå‡†æµ‹è¯•ä¸»è¦å…³æ³¨ç”¨æˆ·çš„åŸºæœ¬æ„å›¾ï¼Œå¦‚æŸ¥æ‰¾æˆ–è´­ä¹°äº§å“ã€‚ç„¶è€Œï¼Œç°å®ä¸–ç•Œçš„ç”¨æˆ·é€šå¸¸è¿½æ±‚æ›´å¤æ‚çš„ç›®æ ‡ï¼Œå¦‚ä½¿ç”¨ä¼˜æƒ åˆ¸ã€ç®¡ç†é¢„ç®—å’Œå¯»æ‰¾å¤šäº§å“å–å®¶ã€‚ä¸ºäº†å¼¥è¡¥è¿™ä¸€å·®è·ï¼Œæˆ‘ä»¬æå‡ºäº†ShoppingBenchè¿™ä¸€å…¨æ–°çš„ç«¯åˆ°ç«¯è´­ç‰©åŸºå‡†æµ‹è¯•ï¼Œæ—¨åœ¨æ¶µç›–æ—¥ç›Šå¤æ‚çš„åŸºäºæ„å›¾çš„çº§åˆ«ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªå¯æ‰©å±•çš„æ¡†æ¶ï¼ŒåŸºäºä»ç°å®ä¸–ç•Œé‡‡æ ·äº§å“ä¸­å¾—å‡ºçš„å„ç§æ„å›¾æ¥æ¨¡æ‹Ÿç”¨æˆ·æŒ‡ä»¤ã€‚ä¸ºäº†ä¿ƒè¿›ä¸€è‡´å’Œå¯é çš„è¯„ä¼°ï¼Œæˆ‘ä»¬æä¾›äº†ä¸€ä¸ªå¤§è§„æ¨¡çš„è´­ç‰©æ²™ç›˜ï¼Œä½œä¸ºä¸€ä¸ªäº¤äº’å¼æ¨¡æ‹Ÿç¯å¢ƒï¼Œå…¶ä¸­åŒ…å«äº†è¶…è¿‡250ä¸‡ç§çœŸå®ä¸–ç•Œçš„äº§å“ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œå³ä½¿åœ¨æˆ‘ä»¬çš„åŸºå‡†æµ‹è¯•ä»»åŠ¡ä¸Šï¼Œæœ€å…ˆè¿›çš„è¯­è¨€æ™ºèƒ½ä½“ï¼ˆå¦‚GPT-4.1ï¼‰çš„ç»å¯¹æˆåŠŸç‡ä¹Ÿä½äº50%ï¼Œè¿™å‡¸æ˜¾äº†æˆ‘ä»¬çš„ShoppingBenchæ‰€å¸¦æ¥çš„é‡å¤§æŒ‘æˆ˜ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§è½¨è¿¹è’¸é¦ç­–ç•¥ï¼Œå¹¶åˆ©ç”¨ç›‘ç£å¾®è°ƒä»¥åŠå¯¹åˆæˆè½¨è¿¹çš„å¼ºåŒ–å­¦ä¹ ï¼Œå°†å¤§å‹è¯­è¨€æ™ºèƒ½ä½“çš„èƒ½åŠ›æç‚¼åˆ°å°å‹æ™ºèƒ½ä½“ä¸Šã€‚ç»“æœï¼Œæˆ‘ä»¬è®­ç»ƒçš„æ™ºèƒ½ä½“è¡¨ç°å‡ºä¸GPT-4.1ç›¸ç«äº‰çš„æ€§èƒ½ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.04266v1">PDF</a> submit to AAAI2026</p>
<p><strong>Summary</strong></p>
<p>åœ¨ç”µå­å•†åŠ¡é¢†åŸŸï¼Œç°æœ‰åŸºå‡†æµ‹è¯•ä¸»è¦å…³æ³¨ç”¨æˆ·çš„åŸºæœ¬æ„å›¾ï¼Œå¦‚æŸ¥æ‰¾æˆ–è´­ä¹°äº§å“ã€‚ç„¶è€Œï¼ŒçœŸå®ç”¨æˆ·é€šå¸¸è¿½æ±‚æ›´å¤æ‚çš„ç›®æ ‡ï¼Œå¦‚ä½¿ç”¨ä¼˜æƒ åˆ¸ã€ç®¡ç†é¢„ç®—å’Œå¯»æ‰¾å¤šäº§å“å–å®¶ã€‚ä¸ºäº†å¼¥è¡¥è¿™ä¸€å·®è·ï¼Œæˆ‘ä»¬æå‡ºäº†ShoppingBenchï¼Œè¿™æ˜¯ä¸€ä¸ªæ–°çš„ç«¯åˆ°ç«¯è´­ç‰©åŸºå‡†æµ‹è¯•ï¼Œæ—¨åœ¨æ¶µç›–æ—¥ç›Šå¤æ‚çš„åŸºäºæ„å›¾çš„åŸºå‡†æµ‹è¯•ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªå¯æ‰©å±•çš„æ¡†æ¶ï¼ŒåŸºäºé‡‡æ ·è‡ªçœŸå®ä¸–ç•Œçš„äº§å“æ¥æ¨¡æ‹Ÿç”¨æˆ·æŒ‡ä»¤ã€‚æˆ‘ä»¬è¿˜æä¾›äº†ä¸€ä¸ªå¤§å‹è´­ç‰©æ²™ç›˜ï¼Œä½œä¸ºæ¨¡æ‹Ÿç¯å¢ƒï¼ŒåŒ…å«è¶…è¿‡250ä¸‡çœŸå®äº§å“ï¼Œä»¥ç¡®ä¿ä¸€è‡´å’Œå¯é çš„è¯„ä¼°ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œå³ä½¿åœ¨æˆ‘ä»¬çš„åŸºå‡†æµ‹è¯•ä»»åŠ¡ä¸Šï¼Œæœ€å…ˆè¿›çš„è¯­è¨€ä»£ç†ï¼ˆå¦‚GPT-4.1ï¼‰çš„ç»å¯¹æˆåŠŸç‡ä¹Ÿä½äº50%ï¼Œçªæ˜¾å‡ºShoppingBenchçš„é‡å¤§æŒ‘æˆ˜ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§è½¨è¿¹è’¸é¦ç­–ç•¥ï¼Œåˆ©ç”¨ç›‘ç£å¾®è°ƒä¸åˆæˆè½¨è¿¹çš„å¼ºåŒ–å­¦ä¹ æ¥æç‚¼å¤§å‹è¯­è¨€ä»£ç†çš„èƒ½åŠ›ã€‚ç»è¿‡è®­ç»ƒçš„ä»£ç†è¡¨ç°ä¸GPT-4.1ç›¸æ¯”å…·æœ‰ç«äº‰åŠ›ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ç°æœ‰ç”µå­å•†åŠ¡åŸºå‡†æµ‹è¯•ä¸»è¦å…³æ³¨åŸºæœ¬ç”¨æˆ·æ„å›¾ï¼Œä½†çœŸå®ç”¨æˆ·è¿½æ±‚æ›´å¤æ‚çš„ç›®æ ‡ã€‚</li>
<li>ShoppingBenchæ˜¯ä¸€ä¸ªæ–°çš„ç«¯åˆ°ç«¯è´­ç‰©åŸºå‡†æµ‹è¯•ï¼Œæ—¨åœ¨æ¶µç›–æ›´å¤æ‚çš„åŸºäºæ„å›¾çš„åŸºå‡†æµ‹è¯•ã€‚</li>
<li>ShoppingBenchä½¿ç”¨æ¨¡æ‹Ÿç”¨æˆ·æŒ‡ä»¤å’ŒçœŸå®ä¸–ç•Œäº§å“çš„é‡‡æ ·æ¥æ¨¡æ‹Ÿç°å®è´­ç‰©åœºæ™¯ã€‚</li>
<li>å®éªŒç»“æœè¡¨æ˜ï¼Œå³ä½¿æ˜¯æœ€å…ˆè¿›çš„è¯­è¨€ä»£ç†åœ¨é¢å¯¹ShoppingBenchçš„åŸºå‡†æµ‹è¯•ä»»åŠ¡æ—¶ä¹Ÿä¼šé¢ä¸´é‡å¤§æŒ‘æˆ˜ã€‚</li>
<li>æå‡ºäº†ä¸€ç§è½¨è¿¹è’¸é¦ç­–ç•¥ï¼Œé€šè¿‡ç›‘ç£å¾®è°ƒä¸å¼ºåŒ–å­¦ä¹ æé«˜ä»£ç†æ€§èƒ½ã€‚</li>
<li>ç»è¿‡è®­ç»ƒçš„ä»£ç†è¡¨ç°ä¸GPT-4.1ç›¸æ¯”å…·æœ‰ç«äº‰åŠ›ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.04266">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-66775d0a15f700bc915885216720c027.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-93df4a4808585b553fb92e68b44c52ae.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ce90475bb5448a54c53f3f2e5446b42b.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-f6db7d59ca51e93cc2e5c4a3bd1d27f2.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-736b930afb822f53fa58e21511852b5b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b31c4ec5f759f21f0a3811ac94fa3132.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="Empowering-Time-Series-Forecasting-with-LLM-Agents"><a href="#Empowering-Time-Series-Forecasting-with-LLM-Agents" class="headerlink" title="Empowering Time Series Forecasting with LLM-Agents"></a>Empowering Time Series Forecasting with LLM-Agents</h2><p><strong>Authors:Chin-Chia Michael Yeh, Vivian Lai, Uday Singh Saini, Xiran Fan, Yujie Fan, Junpeng Wang, Xin Dai, Yan Zheng</strong></p>
<p>Large Language Model (LLM) powered agents have emerged as effective planners for Automated Machine Learning (AutoML) systems. While most existing AutoML approaches focus on automating feature engineering and model architecture search, recent studies in time series forecasting suggest that lightweight models can often achieve state-of-the-art performance. This observation led us to explore improving data quality, rather than model architecture, as a potentially fruitful direction for AutoML on time series data. We propose DCATS, a Data-Centric Agent for Time Series. DCATS leverages metadata accompanying time series to clean data while optimizing forecasting performance. We evaluated DCATS using four time series forecasting models on a large-scale traffic volume forecasting dataset. Results demonstrate that DCATS achieves an average 6% error reduction across all tested models and time horizons, highlighting the potential of data-centric approaches in AutoML for time series forecasting. </p>
<blockquote>
<p>åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„ä»£ç†å·²ä½œä¸ºè‡ªåŠ¨åŒ–æœºå™¨å­¦ä¹ ï¼ˆAutoMLï¼‰ç³»ç»Ÿçš„æœ‰æ•ˆè§„åˆ’å™¨è€Œå‡ºç°ã€‚è™½ç„¶å¤§å¤šæ•°ç°æœ‰çš„AutoMLæ–¹æ³•ä¾§é‡äºè‡ªåŠ¨åŒ–ç‰¹å¾å·¥ç¨‹å’Œæ¨¡å‹æ¶æ„æœç´¢ï¼Œä½†æœ€è¿‘çš„æ—¶é—´åºåˆ—é¢„æµ‹ç ”ç©¶è¡¨æ˜ï¼Œè½»é‡çº§æ¨¡å‹é€šå¸¸å¯ä»¥è¾¾åˆ°æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚è¿™ä¸€è§‚å¯Ÿç»“æœä¿ƒä½¿æˆ‘ä»¬æ¢ç´¢æ”¹è¿›æ•°æ®è´¨é‡ï¼Œè€Œä¸æ˜¯æ¨¡å‹æ¶æ„ï¼Œä½œä¸ºAutoMLåœ¨æ—¶é—´åºåˆ—æ•°æ®ä¸Šå¯èƒ½ç¡•æœç´¯ç´¯çš„æ–¹å‘ã€‚æˆ‘ä»¬æå‡ºäº†DCATSï¼Œä¸€ä¸ªé¢å‘æ—¶é—´åºåˆ—çš„æ•°æ®ä¸­å¿ƒä»£ç†ã€‚DCATSåˆ©ç”¨ä¼´éšæ—¶é—´åºåˆ—çš„å…ƒæ•°æ®æ¥æ¸…ç†æ•°æ®ï¼ŒåŒæ—¶ä¼˜åŒ–é¢„æµ‹æ€§èƒ½ã€‚æˆ‘ä»¬åœ¨å¤§è§„æ¨¡äº¤é€šæµé‡é¢„æµ‹æ•°æ®é›†ä¸Šä½¿ç”¨å››ä¸ªæ—¶é—´åºåˆ—é¢„æµ‹æ¨¡å‹è¯„ä¼°äº†DCATSã€‚ç»“æœè¡¨æ˜ï¼ŒDCATSåœ¨æ‰€æœ‰æµ‹è¯•æ¨¡å‹å’Œæ‰€æœ‰æ—¶é—´èŒƒå›´å†…å®ç°äº†å¹³å‡6%çš„è¯¯å·®é™ä½ï¼Œçªå‡ºäº†æ•°æ®ä¸­å¿ƒæ–¹æ³•åœ¨AutoMLæ—¶é—´åºåˆ—é¢„æµ‹ä¸­çš„æ½œåŠ›ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.04231v1">PDF</a> </p>
<p><strong>Summary</strong><br>å¤§å‹è¯­è¨€æ¨¡å‹é©±åŠ¨çš„ä»£ç†åœ¨è‡ªåŠ¨åŒ–æœºå™¨å­¦ä¹ ï¼ˆAutoMLï¼‰ç³»ç»Ÿä¸­å‘æŒ¥äº†æœ‰æ•ˆçš„è§„åˆ’ä½œç”¨ã€‚é’ˆå¯¹æ—¶é—´åºåˆ—é¢„æµ‹ï¼Œç ”ç©¶å‘ç°åœ¨æ—¶é—´åºåˆ—æ•°æ®ä¸Šé‡‡ç”¨ä»¥æ•°æ®ä¸ºä¸­å¿ƒçš„æ–¹æ³•å¯èƒ½æ›´æœ‰æˆæ•ˆï¼Œäºæ˜¯æˆ‘ä»¬æå‡ºäº†DCATSæ•°æ®ä¸ºä¸­å¿ƒçš„æ—¶é—´åºåˆ—ä»£ç†ã€‚DCATSåˆ©ç”¨æ—¶é—´åºåˆ—çš„å…ƒæ•°æ®å¯¹æ•°æ®è¿›è¡Œæ¸…ç†å¹¶ä¼˜åŒ–é¢„æµ‹æ€§èƒ½ã€‚åœ¨å¤§å‹äº¤é€šæµé‡é¢„æµ‹æ•°æ®é›†ä¸Šï¼Œå¯¹å››ç§æ—¶é—´åºåˆ—é¢„æµ‹æ¨¡å‹è¿›è¡Œçš„è¯„ä¼°è¡¨æ˜ï¼ŒDCATSåœ¨æ‰€æœ‰æµ‹è¯•æ¨¡å‹å’Œæ—¶é—´èŒƒå›´å†…å¹³å‡å‡å°‘äº†6%çš„è¯¯å·®ï¼Œçªæ˜¾äº†æ•°æ®ä¸ºä¸­å¿ƒçš„æ–¹æ³•åœ¨AutoMLæ—¶é—´åºåˆ—é¢„æµ‹ä¸­çš„æ½œåŠ›ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨è‡ªåŠ¨åŒ–æœºå™¨å­¦ä¹ ï¼ˆAutoMLï¼‰ç³»ç»Ÿä¸­æ‰®æ¼”æœ‰æ•ˆè§„åˆ’è§’è‰²ã€‚</li>
<li>ç°æœ‰AutoMLæ–¹æ³•ä¸»è¦å…³æ³¨ç‰¹å¾å·¥ç¨‹å’Œæ¨¡å‹æ¶æ„æœç´¢çš„è‡ªåŠ¨åŒ–ã€‚</li>
<li>é’ˆå¯¹æ—¶é—´åºåˆ—é¢„æµ‹ï¼Œç ”ç©¶å‘ç°è½»é‡åŒ–æ¨¡å‹å¸¸èƒ½è¾¾åˆ°æœ€ä½³æ€§èƒ½ã€‚</li>
<li>æ•°æ®è´¨é‡æ”¹è¿›æ˜¯ä¸€ä¸ªæœ‰å‰æ™¯çš„æ–¹å‘ï¼Œæå‡ºDCATSæ•°æ®ä¸ºä¸­å¿ƒçš„æ—¶é—´åºåˆ—ä»£ç†ã€‚</li>
<li>DCATSåˆ©ç”¨å…ƒæ•°æ®æ¸…ç†æ•°æ®å¹¶ä¼˜åŒ–é¢„æµ‹æ€§èƒ½ã€‚</li>
<li>åœ¨å¤§å‹äº¤é€šæµé‡é¢„æµ‹æ•°æ®é›†ä¸Šçš„è¯„ä¼°æ˜¾ç¤ºï¼ŒDCATSé™ä½äº†å¹³å‡6%çš„è¯¯å·®ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.04231">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-64f83bfb428dc1acb6db077b71797e7d.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-7b5be49f89ded9e479b9bf77523cdd3d.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-4f49877bcf1fc738fe5478472db92246.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d51708fb006c8e4cf904aaae338e071d.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-3ae6caf004c242a824f4c8c4999b6480.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-49ec6222544380630b89413389c3e180.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-06608c41956449e5ea2dae7437c7bfc7.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-49c86b7e1417a127f312e2ee3110c674.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-7914b87d3bf55c1de6d45cb5b111afb0.jpg" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="AgREE-Agentic-Reasoning-for-Knowledge-Graph-Completion-on-Emerging-Entities"><a href="#AgREE-Agentic-Reasoning-for-Knowledge-Graph-Completion-on-Emerging-Entities" class="headerlink" title="AgREE: Agentic Reasoning for Knowledge Graph Completion on Emerging   Entities"></a>AgREE: Agentic Reasoning for Knowledge Graph Completion on Emerging   Entities</h2><p><strong>Authors:Ruochen Zhao, Simone Conia, Eric Peng, Min Li, Saloni Potdar</strong></p>
<p>Open-domain Knowledge Graph Completion (KGC) faces significant challenges in an ever-changing world, especially when considering the continual emergence of new entities in daily news. Existing approaches for KGC mainly rely on pretrained language modelsâ€™ parametric knowledge, pre-constructed queries, or single-step retrieval, typically requiring substantial supervision and training data. Even so, they often fail to capture comprehensive and up-to-date information about unpopular and&#x2F;or emerging entities. To this end, we introduce Agentic Reasoning for Emerging Entities (AgREE), a novel agent-based framework that combines iterative retrieval actions and multi-step reasoning to dynamically construct rich knowledge graph triplets. Experiments show that, despite requiring zero training efforts, AgREE significantly outperforms existing methods in constructing knowledge graph triplets, especially for emerging entities that were not seen during language modelsâ€™ training processes, outperforming previous methods by up to 13.7%. Moreover, we propose a new evaluation methodology that addresses a fundamental weakness of existing setups and a new benchmark for KGC on emerging entities. Our work demonstrates the effectiveness of combining agent-based reasoning with strategic information retrieval for maintaining up-to-date knowledge graphs in dynamic information environments. </p>
<blockquote>
<p>å¼€æ”¾é¢†åŸŸçŸ¥è¯†å›¾è°±è¡¥å…¨ï¼ˆKGCï¼‰åœ¨æ—¥æ–°æœˆå¼‚çš„ä¸–ç•Œä¸­é¢ä¸´ç€é‡å¤§æŒ‘æˆ˜ï¼Œç‰¹åˆ«æ˜¯è€ƒè™‘åˆ°æ—¥å¸¸æ–°é—»ä¸­ä¸æ–­å‡ºç°çš„æ–°å®ä½“ã€‚ç°æœ‰çš„KGCæ–¹æ³•ä¸»è¦ä¾èµ–äºé¢„è®­ç»ƒè¯­è¨€æ¨¡å‹çš„å‚æ•°çŸ¥è¯†ã€é¢„å…ˆæ„å»ºçš„æŸ¥è¯¢æˆ–å•æ­¥æ£€ç´¢ï¼Œé€šå¸¸éœ€è¦å¤§é‡çš„ç›‘ç£å’Œè®­ç»ƒæ•°æ®ã€‚å°½ç®¡å¦‚æ­¤ï¼Œå®ƒä»¬å¾€å¾€æ— æ³•æ•è·å…³äºä¸å—æ¬¢è¿å’Œ&#x2F;æˆ–æ–°å…´å®ä½“çš„å…¨é¢å’Œæœ€æ–°çš„ä¿¡æ¯ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬å¼•å…¥äº†ç”¨äºæ–°å…´å®ä½“çš„Agenticæ¨ç†ï¼ˆAgREEï¼‰ï¼Œè¿™æ˜¯ä¸€ç§æ–°å‹åŸºäºä»£ç†çš„æ¡†æ¶ï¼Œç»“åˆäº†è¿­ä»£æ£€ç´¢åŠ¨ä½œå’Œå¤šæ­¥æ¨ç†ï¼Œä»¥åŠ¨æ€æ„å»ºä¸°å¯Œçš„çŸ¥è¯†å›¾è°±ä¸‰å…ƒç»„ã€‚å®éªŒè¡¨æ˜ï¼Œå°½ç®¡ä¸éœ€è¦ä»»ä½•è®­ç»ƒåŠªåŠ›ï¼ŒAgREEåœ¨æ„å»ºçŸ¥è¯†å›¾è°±ä¸‰å…ƒç»„æ–¹é¢æ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œå°¤å…¶æ˜¯å¯¹äºåœ¨è¯­è¨€æ¨¡å‹è®­ç»ƒè¿‡ç¨‹ä¸­æœªè§çš„æ–°å…´å®ä½“ï¼Œå…¶æ€§èƒ½ä¼˜äºä»¥å‰çš„æ–¹æ³•é«˜è¾¾13.7%ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°çš„è¯„ä¼°æ–¹æ³•ï¼Œè§£å†³äº†ç°æœ‰è®¾ç½®çš„åŸºæœ¬å¼±ç‚¹ï¼Œä»¥åŠé’ˆå¯¹æ–°å…´å®ä½“çš„KGCçš„æ–°åŸºå‡†æµ‹è¯•ã€‚æˆ‘ä»¬çš„å·¥ä½œè¯æ˜äº†åœ¨åŠ¨æ€ä¿¡æ¯ç¯å¢ƒä¸­ç»“åˆåŸºäºä»£ç†çš„æ¨ç†å’Œæˆ˜ç•¥ä¿¡æ¯æ£€ç´¢ä»¥ç»´æŒæœ€æ–°çŸ¥è¯†å›¾è°±çš„æœ‰æ•ˆæ€§ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.04118v1">PDF</a> </p>
<p><strong>Summary</strong><br>çŸ¥è¯†å›¾è°±è¡¥å…¨ï¼ˆKGCï¼‰åœ¨æ—¥ç›Šå˜åŒ–çš„ä¸–ç•Œä¸­é¢ä¸´å·¨å¤§æŒ‘æˆ˜ï¼Œå°¤å…¶å¯¹äºæŒç»­æ¶Œç°çš„æ–°å…´å®ä½“ã€‚ç°æœ‰æ–¹æ³•ä¸»è¦ä¾èµ–é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹çš„å‚æ•°çŸ¥è¯†ã€é¢„æ„å»ºæŸ¥è¯¢æˆ–å•æ­¥æ£€ç´¢ï¼Œéœ€è¦åºå¤§çš„ç›‘ç£æ•°æ®ï¼Œä½†ä»éš¾ä»¥è·å–å…¨é¢ã€æœ€æ–°çš„å…³äºéçƒ­é—¨æˆ–æ–°å…´å®ä½“çš„ä¿¡æ¯ã€‚ä¸ºè§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†åŸºäºAgentçš„æ–°å…´å®ä½“æ¨ç†ï¼ˆAgREEï¼‰æ¡†æ¶ï¼Œç»“åˆè¿­ä»£æ£€ç´¢åŠ¨ä½œå’Œå¤šæ­¥æ¨ç†æ¥åŠ¨æ€æ„å»ºä¸°å¯Œçš„çŸ¥è¯†å›¾è°±ä¸‰å…ƒç»„ã€‚å®éªŒè¡¨æ˜ï¼ŒAgREEåœ¨æ„å»ºçŸ¥è¯†å›¾è°±ä¸‰å…ƒç»„æ–¹é¢æ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œå°¤å…¶æ˜¯å¯¹æœªåœ¨è¯­è¨€æ¨¡å‹è®­ç»ƒè¿‡ç¨‹ä¸­å‡ºç°çš„æ–°å…´å®ä½“ï¼Œæå‡å¹…åº¦é«˜è¾¾13.7%ã€‚æˆ‘ä»¬è¿˜æå‡ºäº†ä¸€ç§æ–°çš„è¯„ä¼°æ–¹æ³•å’Œä¸ºKGCæ–°å…´å®ä½“è®¾ç«‹çš„æ–°çš„åŸºå‡†æµ‹è¯•ã€‚æˆ‘ä»¬çš„å·¥ä½œè¯æ˜äº†åœ¨åŠ¨æ€ä¿¡æ¯ç¯å¢ƒä¸­ç»“åˆåŸºäºAgentçš„æ¨ç†ä¸ç­–ç•¥æ€§ä¿¡æ¯æ£€ç´¢æ¥ç»´æŠ¤æœ€æ–°çŸ¥è¯†å›¾è°±çš„æœ‰æ•ˆæ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>çŸ¥è¯†å›¾è°±è¡¥å…¨ï¼ˆKGCï¼‰åœ¨å¤„ç†æ–°å…´å®ä½“æ—¶é¢ä¸´æŒ‘æˆ˜ã€‚</li>
<li>ç°æœ‰KGCæ–¹æ³•ä¸»è¦ä¾èµ–é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹ï¼Œä½†éš¾ä»¥è·å–å…³äºæ–°å…´å®ä½“çš„å…¨é¢ã€æœ€æ–°ä¿¡æ¯ã€‚</li>
<li>æå‡ºçš„AgREEæ¡†æ¶ç»“åˆè¿­ä»£æ£€ç´¢åŠ¨ä½œå’Œå¤šæ­¥æ¨ç†ï¼Œèƒ½åŠ¨æ€æ„å»ºçŸ¥è¯†å›¾è°±ä¸‰å…ƒç»„ã€‚</li>
<li>AgREEåœ¨æ„å»ºçŸ¥è¯†å›¾è°±ä¸‰å…ƒç»„æ–¹é¢æ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œå°¤å…¶é’ˆå¯¹æ–°å…´å®ä½“ã€‚</li>
<li>AgREEæå‡å¹…åº¦é«˜è¾¾13.7%ï¼Œæ˜¾ç¤ºå‡ºå…¶æœ‰æ•ˆæ€§ã€‚</li>
<li>ç ”ç©¶è€…è¿˜æå‡ºäº†ä¸€ç§æ–°çš„KGCè¯„ä¼°æ–¹æ³•å’ŒåŸºå‡†æµ‹è¯•ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.04118">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-29563b7d2cf01e277e396be384a96b42.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-e60dadbef861783d2966753b14a74f14.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-97c32996ef972b688a2a8137d2f4372d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b72da8683e40350fed7d005d24cf2852.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-6ff265ac674d9b7918f07e35e428b719.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-b246486caa86441b87dc06d2a749ee2e.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-801b89b544b3c19561fcdef8ba20e678.jpg" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1><h2 id="XARP-Tools-An-Extended-Reality-Platform-for-Humans-and-AI-Agents"><a href="#XARP-Tools-An-Extended-Reality-Platform-for-Humans-and-AI-Agents" class="headerlink" title="XARP Tools: An Extended Reality Platform for Humans and AI Agents"></a>XARP Tools: An Extended Reality Platform for Humans and AI Agents</h2><p><strong>Authors:Arthur Caetano, Misha Sra</strong></p>
<p>This technical report presents XARP Tools, an extended reality (XR) framework designed for human and AI developers alike. XARP comprises a server-side Python library and platform-specific XR clients. The library offers high-level APIs and communicates with clients via a JSON-based protocol over WebSockets. XR clients encapsulate device and runtime specifics, providing responsive, low-latency user interaction. XARP can be utilized in three ways: (i) as a library that abstracts XR development for humans; (ii) as a set of callable tools that allow AI agents to drive on-the-fly interactions with users; and (iii) as a Model Context Protocol server that plugs XR devices into AI ecosystems. XARP code and working examples are released openly at <a target="_blank" rel="noopener" href="https://github.com/HAL-UCSB/xarp">https://github.com/HAL-UCSB/xarp</a>. </p>
<blockquote>
<p>æœ¬æŠ€æœ¯æŠ¥å‘Šä»‹ç»äº†XARPå·¥å…·ï¼Œè¿™æ˜¯ä¸€ä¸ªä¸ºäººå·¥æ™ºèƒ½å¼€å‘äººå‘˜å’Œäººç±»å¼€å‘äººå‘˜è®¾è®¡çš„æ‰©å±•ç°å®ï¼ˆXRï¼‰æ¡†æ¶ã€‚XARPåŒ…æ‹¬æœåŠ¡å™¨ç«¯Pythonåº“å’Œé’ˆå¯¹å¹³å°çš„XRå®¢æˆ·ç«¯ã€‚è¯¥åº“æä¾›é«˜çº§APIï¼Œå¹¶é€šè¿‡WebSocketä¸Šçš„åŸºäºJSONçš„åè®®ä¸å®¢æˆ·ç«¯è¿›è¡Œé€šä¿¡ã€‚XRå®¢æˆ·ç«¯å°è£…äº†è®¾å¤‡å’Œè¿è¡Œæ—¶ç¯å¢ƒçš„è¯¦ç»†ä¿¡æ¯ï¼Œæä¾›å“åº”è¿…é€Ÿã€ä½å»¶è¿Ÿçš„ç”¨æˆ·äº¤äº’ã€‚XARPå¯ä»¥ä»¥ä¸‰ç§æ–¹å¼ä½¿ç”¨ï¼šï¼ˆiï¼‰ä½œä¸ºä¸€ä¸ªäººç±»XRå¼€å‘çš„æŠ½è±¡åº“ï¼›ï¼ˆiiï¼‰ä½œä¸ºä¸€ç»„å¯è°ƒç”¨å·¥å…·ï¼Œå…è®¸AIä»£ç†å®æ—¶ä¸ç”¨æˆ·è¿›è¡Œäº¤äº’ï¼›ï¼ˆiiiï¼‰ä½œä¸ºå°†XRè®¾å¤‡æ¥å…¥AIç”Ÿæ€ç³»ç»Ÿçš„æ¨¡å‹ä¸Šä¸‹æ–‡åè®®æœåŠ¡å™¨ã€‚XARPä»£ç å’Œå·¥ä½œç¤ºä¾‹å·²åœ¨<a target="_blank" rel="noopener" href="https://github.com/HAL-UCSB/xarp%E4%B8%8A%E5%85%AC%E5%BC%80%E5%8F%91%E5%B8%83%E3%80%82">https://github.com/HAL-UCSB/xarpä¸Šå…¬å¼€å‘å¸ƒã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.04108v1">PDF</a> </p>
<p><strong>Summary</strong><br>     æœ¬æŠ€æœ¯æŠ¥å‘Šä»‹ç»äº†XARPå·¥å…·ï¼Œè¿™æ˜¯ä¸€ä¸ªä¸ºäººå·¥æ™ºèƒ½å¼€å‘äººå‘˜å’Œäººç±»å¼€å‘äººå‘˜è®¾è®¡çš„æ‰©å±•ç°å®ï¼ˆXRï¼‰æ¡†æ¶ã€‚XARPåŒ…å«ä¸€ä¸ªæœåŠ¡å™¨ç«¯Pythonåº“å’Œå¹³å°ç‰¹å®šçš„XRå®¢æˆ·ç«¯ã€‚è¯¥åº“æä¾›é«˜çº§APIï¼Œå¹¶é€šè¿‡WebSocketä½¿ç”¨åŸºäºJSONçš„åè®®ä¸å®¢æˆ·ç«¯é€šä¿¡ã€‚XRå®¢æˆ·ç«¯å°è£…äº†è®¾å¤‡å’Œè¿è¡Œæ—¶è¯¦ç»†ä¿¡æ¯ï¼Œæä¾›å“åº”è¿…é€Ÿã€ä½å»¶è¿Ÿçš„ç”¨æˆ·äº¤äº’ã€‚XARPå¯ä»¥ä»¥ä¸‰ç§æ–¹å¼åˆ©ç”¨ï¼šï¼ˆiï¼‰ä½œä¸ºä¸ºäººç±»æŠ½è±¡XRå¼€å‘çš„åº“ï¼›ï¼ˆiiï¼‰ä½œä¸ºå…è®¸AIä»£ç†é©±åŠ¨å³æ—¶ç”¨æˆ·äº¤äº’çš„å¯è°ƒç”¨å·¥å…·é›†ï¼›ï¼ˆiiiï¼‰ä½œä¸ºå°†XRè®¾å¤‡æ’å…¥AIç”Ÿæ€ç³»ç»Ÿçš„æ¨¡å‹ä¸Šä¸‹æ–‡åè®®æœåŠ¡å™¨ã€‚XARPçš„ä»£ç å’Œå·¥ä½œç¤ºä¾‹å·²åœ¨<a target="_blank" rel="noopener" href="https://github.com/HAL-UCSB/xarp%E4%B8%8A%E5%85%AC%E5%BC%80%E5%8F%91%E5%B8%83%E3%80%82">https://github.com/HAL-UCSB/xarpä¸Šå…¬å¼€å‘å¸ƒã€‚</a></p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>XARPå·¥å…·æ˜¯ä¸€ä¸ªæ‰©å±•ç°å®ï¼ˆXRï¼‰æ¡†æ¶ï¼Œé€‚ç”¨äºäººå·¥æ™ºèƒ½å¼€å‘äººå‘˜å’Œäººç±»å¼€å‘äººå‘˜ã€‚</li>
<li>XARPåŒ…å«ä¸€ä¸ªæœåŠ¡å™¨ç«¯Pythonåº“å’Œå¹³å°ç‰¹å®šçš„XRå®¢æˆ·ç«¯ï¼Œæä¾›é«˜çº§APIå’ŒåŸºäºJSONçš„åè®®é€šä¿¡ã€‚</li>
<li>XRå®¢æˆ·ç«¯å°è£…è®¾å¤‡å’Œè¿è¡Œæ—¶è¯¦ç»†ä¿¡æ¯ï¼Œå®ç°å“åº”è¿…é€Ÿã€ä½å»¶è¿Ÿçš„ç”¨æˆ·äº¤äº’ã€‚</li>
<li>XARPå¯ä»¥ä½œä¸ºäººç±»æŠ½è±¡XRå¼€å‘çš„åº“ä½¿ç”¨ã€‚</li>
<li>XARPå…è®¸AIä»£ç†é©±åŠ¨å³æ—¶ç”¨æˆ·äº¤äº’ï¼Œä½œä¸ºå¯è°ƒç”¨å·¥å…·é›†ä½¿ç”¨ã€‚</li>
<li>XARPå¯ä»¥ä½œä¸ºæ¨¡å‹ä¸Šä¸‹æ–‡åè®®æœåŠ¡å™¨ï¼Œå°†XRè®¾å¤‡æ’å…¥AIç”Ÿæ€ç³»ç»Ÿã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.04108">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-893284268450cb320d8842a6131b72c3.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-fd074e0b9309f0cf7637f116bd8c5414.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-ad4eb820e4f8913455c38516a0c656ff.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-0b238a0d9814028c1e679671dd41f1ca.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a247ce7d74733e51c2c7c82e3dfeaef1.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-26ffcc71158df528ef5d21a4940455d5.jpg" align="middle">
</details>


<h1 id="-9"><a href="#-9" class="headerlink" title=""></a></h1><h2 id="HyCodePolicy-Hybrid-Language-Controllers-for-Multimodal-Monitoring-and-Decision-in-Embodied-Agents"><a href="#HyCodePolicy-Hybrid-Language-Controllers-for-Multimodal-Monitoring-and-Decision-in-Embodied-Agents" class="headerlink" title="HyCodePolicy: Hybrid Language Controllers for Multimodal Monitoring and   Decision in Embodied Agents"></a>HyCodePolicy: Hybrid Language Controllers for Multimodal Monitoring and   Decision in Embodied Agents</h2><p><strong>Authors:Yibin Liu, Zhixuan Liang, Zanxin Chen, Tianxing Chen, Mengkang Hu, Wanxi Dong, Congsheng Xu, Zhaoming Han, Yusen Qin, Yao Mu</strong></p>
<p>Recent advances in multimodal large language models (MLLMs) have enabled richer perceptual grounding for code policy generation in embodied agents. However, most existing systems lack effective mechanisms to adaptively monitor policy execution and repair codes during task completion. In this work, we introduce HyCodePolicy, a hybrid language-based control framework that systematically integrates code synthesis, geometric grounding, perceptual monitoring, and iterative repair into a closed-loop programming cycle for embodied agents. Technically, given a natural language instruction, our system first decomposes it into subgoals and generates an initial executable program grounded in object-centric geometric primitives. The program is then executed in simulation, while a vision-language model (VLM) observes selected checkpoints to detect and localize execution failures and infer failure reasons. By fusing structured execution traces capturing program-level events with VLM-based perceptual feedback, HyCodePolicy infers failure causes and repairs programs. This hybrid dual feedback mechanism enables self-correcting program synthesis with minimal human supervision. Our results demonstrate that HyCodePolicy significantly improves the robustness and sample efficiency of robot manipulation policies, offering a scalable strategy for integrating multimodal reasoning into autonomous decision-making pipelines. </p>
<blockquote>
<p>æœ€è¿‘çš„å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆMLLMï¼‰çš„è¿›æ­¥ä¸ºå®ä½“ä»£ç†ä¸­çš„ä»£ç ç­–ç•¥ç”Ÿæˆæä¾›äº†æ›´ä¸°å¯Œçš„æ„ŸçŸ¥åŸºç¡€ã€‚ç„¶è€Œï¼Œå¤§å¤šæ•°ç°æœ‰ç³»ç»Ÿç¼ºä¹æœ‰æ•ˆçš„æœºåˆ¶æ¥åœ¨ä»»åŠ¡å®Œæˆè¿‡ç¨‹ä¸­è‡ªé€‚åº”åœ°ç›‘è§†ç­–ç•¥æ‰§è¡Œå’Œä¿®å¤ä»£ç ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬å¼•å…¥äº†HyCodePolicyï¼Œè¿™æ˜¯ä¸€ä¸ªåŸºäºæ··åˆè¯­è¨€çš„æ§åˆ¶æ¡†æ¶ï¼Œå®ƒç³»ç»Ÿåœ°é›†æˆäº†ä»£ç åˆæˆã€å‡ ä½•åŸºç¡€ã€æ„ŸçŸ¥ç›‘æ§å’Œè¿­ä»£ä¿®å¤ï¼Œå½¢æˆä¸€ä¸ªé—­ç¯ç¼–ç¨‹å‘¨æœŸï¼Œç”¨äºå®ä½“ä»£ç†ã€‚ä»æŠ€æœ¯ä¸Šè®²ï¼Œç»™å®šè‡ªç„¶è¯­è¨€æŒ‡ä»¤åï¼Œæˆ‘ä»¬çš„ç³»ç»Ÿé¦–å…ˆå°†å…¶åˆ†è§£ä¸ºå­ç›®æ ‡å¹¶ç”ŸæˆåŸºäºå¯¹è±¡ä¸­å¿ƒå‡ ä½•åŸå§‹æ•°æ®çš„åˆå§‹å¯æ‰§è¡Œç¨‹åºã€‚ç„¶åè¯¥ç¨‹åºåœ¨ä»¿çœŸä¸­æ‰§è¡Œï¼ŒåŒæ—¶è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMï¼‰ä¼šè§‚å¯Ÿé€‰å®šæ£€æŸ¥ç‚¹ä»¥æ£€æµ‹å’Œå®šä½æ‰§è¡Œå¤±è´¥å¹¶æ¨æ–­å¤±è´¥åŸå› ã€‚é€šè¿‡å°†æ•è·ç¨‹åºçº§äº‹ä»¶çš„ç»“æ„åŒ–æ‰§è¡Œè½¨è¿¹ä¸åŸºäºVLMçš„æ„ŸçŸ¥åé¦ˆç›¸ç»“åˆï¼ŒHyCodePolicyèƒ½å¤Ÿæ¨æ–­å‡ºå¤±è´¥åŸå› å¹¶ä¿®å¤ç¨‹åºã€‚è¿™ç§æ··åˆçš„åŒé‡åé¦ˆæœºåˆ¶èƒ½å¤Ÿå®ç°è‡ªæˆ‘ä¿®æ­£çš„ç¨‹åºåˆæˆï¼Œå‡ ä¹æ— éœ€äººå·¥ç›‘ç£ã€‚æˆ‘ä»¬çš„ç»“æœè¡¨æ˜ï¼ŒHyCodePolicyæ˜¾è‘—æé«˜äº†æœºå™¨äººæ“ä½œç­–ç•¥çš„ç¨³å¥æ€§å’Œæ ·æœ¬æ•ˆç‡ï¼Œä¸ºå°†å¤šæ¨¡æ€æ¨ç†é›†æˆåˆ°è‡ªä¸»å†³ç­–ç®¡é“ä¸­æä¾›äº†å¯æ‰©å±•çš„ç­–ç•¥ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.02629v2">PDF</a> Accepted to ICCV 2025 Workshop on Multi-Modal Reasoning for Agentic   Intelligence</p>
<p><strong>Summary</strong></p>
<p>HyCodePolicyï¼Œä¸€ç§åŸºäºè¯­è¨€çš„æ··åˆæ§åˆ¶æ¡†æ¶ï¼Œå®ç°äº†å¯¹ä½“ç´ æ™ºèƒ½ä½“ç¼–ç ç­–ç•¥ç”Ÿæˆè¿‡ç¨‹ä¸­çš„æ¨¡æ‹Ÿæ‰§è¡Œè¿›è¡Œè‡ªé€‚åº”ç›‘æµ‹ä¸ç¨‹åºä¿®å¤çš„åŠŸèƒ½é›†æˆã€‚æ¡†æ¶åŒ…æ‹¬ä»£ç åˆæˆã€å‡ ä½•å®šä½ã€æ„ŸçŸ¥ç›‘æµ‹åŠè¿­ä»£ä¿®å¤ç¯èŠ‚ï¼Œæœ‰æ•ˆå®ç°é—­ç¯ç¼–ç¨‹å‘¨æœŸã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰çš„è¿›æ­¥ä¸ºä½“ç´ æ™ºèƒ½ä½“ç¼–ç ç­–ç•¥ç”Ÿæˆæä¾›äº†æ›´ä¸°å¯Œæ„ŸçŸ¥åŸºç¡€ã€‚</li>
<li>å½“å‰ç³»ç»Ÿç¼ºä¹åœ¨ä»»åŠ¡å®Œæˆè¿‡ç¨‹ä¸­è‡ªé€‚åº”ç›‘æµ‹æ”¿ç­–æ‰§è¡Œå’Œä¿®å¤ä»£ç çš„æœ‰æ•ˆæœºåˆ¶ã€‚</li>
<li>HyCodePolicyç³»ç»Ÿé€šè¿‡åˆ†è§£è‡ªç„¶è¯­è¨€æŒ‡ä»¤ç”Ÿæˆåˆå§‹å¯æ‰§è¡Œç¨‹åºï¼Œå¹¶æ¨¡æ‹Ÿæ‰§è¡Œã€‚</li>
<li>å€ŸåŠ©è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMï¼‰è§‚æµ‹ç‰¹å®šæ£€æŸ¥ç‚¹ä»¥æ£€æµ‹å¹¶å®šä½æ‰§è¡Œå¤±è´¥ï¼Œæ¨æ–­å¤±è´¥åŸå› ã€‚</li>
<li>ç»“æ„åŒ–æ‰§è¡Œè½¨è¿¹ä¸åŸºäºVLMçš„æ„ŸçŸ¥åé¦ˆçš„èåˆï¼Œä½¿HyCodePolicyèƒ½å¤Ÿæ¨æ–­å¤±è´¥åŸå› å¹¶ä¿®å¤ç¨‹åºã€‚</li>
<li>æ··åˆåŒé‡åé¦ˆæœºåˆ¶å®ç°äº†è‡ªæˆ‘ä¿®æ­£çš„ç¨‹åºåˆæˆï¼Œå¹¶å‡å°‘äº†å¯¹äººå·¥ç›‘ç£çš„éœ€æ±‚ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.02629">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-5db12b4b96b26de657fd02412663a2c3.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-e00bea4a7fb9f8f4ccfb2822d131f8ab.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-071ec1194a132ef9a07dfbf35bf0f5f6.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b03b45c362657aa8047b34093867ff8a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-45c0ca75878461436ff4182c63ab2bee.jpg" align="middle">
</details>


<h1 id="-10"><a href="#-10" class="headerlink" title=""></a></h1><h2 id="The-Dark-Side-of-LLMs-Agent-based-Attacks-for-Complete-Computer-Takeover"><a href="#The-Dark-Side-of-LLMs-Agent-based-Attacks-for-Complete-Computer-Takeover" class="headerlink" title="The Dark Side of LLMs: Agent-based Attacks for Complete Computer   Takeover"></a>The Dark Side of LLMs: Agent-based Attacks for Complete Computer   Takeover</h2><p><strong>Authors:Matteo Lupinacci, Francesco Aurelio Pironti, Francesco Blefari, Francesco Romeo, Luigi Arena, Angelo Furfaro</strong></p>
<p>The rapid adoption of Large Language Model (LLM) agents and multi-agent systems enables remarkable capabilities in natural language processing and generation. However, these systems introduce unprecedented security vulnerabilities that extend beyond traditional content generation attacks to system-level compromise. This paper presents a comprehensive evaluation of the security of LLMs used as reasoning engines within autonomous agents, highlighting how they can be exploited as attack vectors capable of achieving complete computer takeover. We focus on how different attack surfaces and trust boundaries - Direct Prompt Injection, RAG Backdoor, and Inter Agent Trust - can be leveraged to orchestrate such takeovers. We demonstrate that adversaries can effectively coerce popular LLMs (including GPT-4, Claude-4 and Gemini-2.5) into autonomously installing and executing malware on victim machines. Our evaluation of 18 state-of-the-art LLMs reveals an alarming scenario: 94.4% of models succumb to Direct Prompt Injection and 83.3% are vulnerable to the more stealth and evasive RAG Backdoor Attack. Notably, we tested trust boundaries within multi-agent systems, where LLM agents interact and influence each other, and we revealed a critical security flaw: LLMs which successfully resist direct injection or RAG backdoor will execute identical payloads when requested by peer agents. Our findings show that 100.0% of tested LLMs can be compromised through Inter-Agent Trust Exploitation attacks and that every model exhibits context-dependent security behaviors that create exploitable blind spots. Our results also highlight the need to increase awareness and research on the security risks of LLMs, showing a paradigm shift in cybersecurity threats, where AI tools themselves become sophisticated attack vectors. </p>
<blockquote>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä»£ç†çš„å¿«é€Ÿé‡‡ç”¨å’Œå¤šä»£ç†ç³»ç»Ÿçš„å‡ºç°ï¼Œä¸ºè‡ªç„¶è¯­è¨€å¤„ç†å’Œç”Ÿæˆå¸¦æ¥äº†æ˜¾è‘—çš„èƒ½åŠ›ã€‚ç„¶è€Œï¼Œè¿™äº›ç³»ç»Ÿä¹Ÿå¼•å…¥äº†å‰æ‰€æœªæœ‰çš„å®‰å…¨æ¼æ´ï¼Œè¿™äº›æ¼æ´è¶…å‡ºäº†ä¼ ç»Ÿçš„å†…å®¹ç”Ÿæˆæ”»å‡»ï¼Œæ¶‰åŠåˆ°ç³»ç»Ÿçº§åˆ«çš„å¦¥åã€‚æœ¬æ–‡å¯¹ä½œä¸ºè‡ªä¸»ä»£ç†ä¸­çš„æ¨ç†å¼•æ“ä½¿ç”¨çš„å¤§å‹è¯­è¨€æ¨¡å‹çš„å®‰å…¨æ€§èƒ½è¿›è¡Œäº†å…¨é¢è¯„ä¼°ï¼Œå¹¶å¼ºè°ƒäº†å®ƒä»¬å¦‚ä½•åˆ©ç”¨è¿™äº›æ¼æ´å®ç°å®Œå…¨çš„è®¡ç®—æœºæ¥ç®¡ï¼Œä½œä¸ºæ”»å‡»å‘é‡ã€‚æˆ‘ä»¬é‡ç‚¹å…³æ³¨å¦‚ä½•åˆ©ç”¨ä¸åŒçš„æ”»å‡»é¢å’Œä¿¡ä»»è¾¹ç•Œï¼Œå¦‚ç›´æ¥æç¤ºæ³¨å…¥ã€RAGåé—¨å’Œä»£ç†é—´ä¿¡ä»»ï¼Œæ¥åè°ƒæ­¤ç±»æ¥ç®¡è¡ŒåŠ¨ã€‚æˆ‘ä»¬è¯æ˜ï¼Œå¯¹æ‰‹å¯ä»¥æœ‰æ•ˆåœ°è¿«ä½¿æµè¡Œçš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆåŒ…æ‹¬GPT-4ã€Claude-4å’ŒGemini-2. é€šè¿‡å¯¹å½“å‰æœ€å…ˆè¿›çš„18ä¸ªå¤§å‹è¯­è¨€æ¨¡å‹çš„è¯„ä¼°ï¼Œæˆ‘ä»¬å‘ç°äº†ä¸€ä¸ªä»¤äººæ‹…å¿§çš„åœºæ™¯ï¼šæœ‰94.4%çš„æ¨¡å‹ç›´æ¥å—åˆ°æç¤ºæ³¨å…¥çš„å½±å“ï¼Œæœ‰83.3%çš„æ¨¡å‹å®¹æ˜“å—åˆ°æ›´éšè”½å’Œæ›´å…·é€ƒé¿æ€§çš„RAGåé—¨æ”»å‡»çš„å½±å“ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œæˆ‘ä»¬åœ¨å¤šä»£ç†ç³»ç»Ÿä¸­æµ‹è¯•äº†ä¿¡ä»»è¾¹ç•Œï¼Œå…¶ä¸­å¤§å‹è¯­è¨€æ¨¡å‹ä»£ç†ç›¸äº’äº¤äº’å’Œå½±å“ï¼Œæˆ‘ä»¬å‘ç°äº†ä¸€ä¸ªå…³é”®çš„å®‰å…¨æ¼æ´ï¼šå³ä½¿æŸäº›å¤§å‹è¯­è¨€æ¨¡å‹æˆåŠŸæŠµæŠ—äº†ç›´æ¥æ³¨å…¥æˆ–RAGåé—¨æ”»å‡»ï¼Œä½†å½“æ”¶åˆ°å¯¹ç­‰ä»£ç†çš„è¯·æ±‚æ—¶ï¼Œå®ƒä»¬ä»ä¼šæ‰§è¡Œç›¸åŒçš„è´Ÿè½½ã€‚æˆ‘ä»¬çš„ç ”ç©¶ç»“æœè¡¨æ˜ï¼Œé€šè¿‡ä»£ç†é—´ä¿¡ä»»å‰¥å‰Šæ”»å‡»ï¼Œæ‰€æœ‰æµ‹è¯•çš„å¤§å‹è¯­è¨€æ¨¡å‹éƒ½æœ‰å¯èƒ½å—åˆ°å¨èƒï¼Œæ¯ä¸ªæ¨¡å‹éƒ½è¡¨ç°å‡ºä¸ä¸Šä¸‹æ–‡ç›¸å…³çš„å®‰å…¨è¡Œä¸ºï¼Œè¿™äº›è¡Œä¸ºäº§ç”Ÿäº†å¯åˆ©ç”¨çš„ç›²ç‚¹ã€‚æˆ‘ä»¬çš„ç ”ç©¶ç»“æœè¿˜å¼ºè°ƒäº†å¯¹å¤§å‹è¯­è¨€æ¨¡å‹å®‰å…¨é£é™©çš„è®¤è¯†å’Œç ”ç©¶éœ€æ±‚å¢åŠ çš„é‡è¦æ€§ï¼Œå¹¶æ˜¾ç¤ºäº†ç½‘ç»œå®‰å…¨å¨èƒçš„ä¸€ä¸ªèŒƒå¼è½¬å˜ï¼Œäººå·¥æ™ºèƒ½å·¥å…·æœ¬èº«å·²æˆä¸ºå¤æ‚çš„æ”»å‡»å‘é‡ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2507.06850v4">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡å…¨é¢è¯„ä¼°äº†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä½œä¸ºè‡ªä¸»æ¨ç†å¼•æ“çš„å®‰å…¨æ€§ï¼Œæ­ç¤ºäº†å…¶å­˜åœ¨çš„é‡å¤§å®‰å…¨æ¼æ´ã€‚æ–‡ç« æŒ‡å‡ºï¼ŒLLMä»£ç†å’Œå¤šä»£ç†ç³»ç»Ÿè™½ç„¶èƒ½å¸¦æ¥å“è¶Šçš„è‡ªç„¶è¯­è¨€å¤„ç†ä¸ç”Ÿæˆèƒ½åŠ›ï¼Œä½†ä¹Ÿå¸¦æ¥äº†å‰æ‰€æœªæœ‰çš„å®‰å…¨é£é™©ã€‚è¿™äº›é£é™©ä¸ä»…é™äºä¼ ç»Ÿçš„å†…å®¹ç”Ÿæˆæ”»å‡»ï¼Œæ›´å¯èƒ½å¼•å‘ç³»ç»Ÿçº§åˆ«çš„ç ´åã€‚æ–‡ç« å±•ç¤ºäº†å¦‚ä½•é€šè¿‡ä¸åŒçš„æ”»å‡»é¢å’Œä¿¡ä»»è¾¹ç•Œæ¥åˆ©ç”¨LLMä½œä¸ºæ”»å‡»åª’ä»‹ï¼Œå®ç°å¯¹è®¡ç®—æœºçš„å…¨é¢æ¥ç®¡ã€‚æµ‹è¯•ç»“æœæ˜¾ç¤ºï¼Œå¤§å¤šæ•°LLMæ¨¡å‹å­˜åœ¨å®‰å…¨æ¼æ´ï¼Œå®¹æ˜“å—åˆ°æ”»å‡»ã€‚å› æ­¤ï¼Œå¿…é¡»æé«˜å¯¹LLMå®‰å…¨é£é™©çš„æ„è¯†ï¼Œå¹¶åŠ å¼ºç›¸å…³ç ”ç©¶ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å’Œå¤šä»£ç†ç³»ç»Ÿå¼•å…¥å‰æ‰€æœªæœ‰çš„å®‰å…¨é£é™©ã€‚</li>
<li>LLMå¯ä½œä¸ºæ”»å‡»åª’ä»‹ï¼Œå®ç°å¯¹è®¡ç®—æœºçš„å…¨é¢æ¥ç®¡ã€‚</li>
<li>æ–‡ç« å…¨é¢è¯„ä¼°äº†LLMçš„å®‰å…¨æ€§ï¼Œæ­ç¤ºäº†å…¶å­˜åœ¨çš„é‡å¤§å®‰å…¨æ¼æ´ã€‚</li>
<li>é€šè¿‡ä¸åŒçš„æ”»å‡»é¢å’Œä¿¡ä»»è¾¹ç•Œæ¥åˆ©ç”¨LLMè¿›è¡Œæ”»å‡»ã€‚</li>
<li>æµ‹è¯•ç»“æœæ˜¾ç¤ºï¼Œå¤§å¤šæ•°LLMæ¨¡å‹å­˜åœ¨å®‰å…¨æ¼æ´ï¼Œå®¹æ˜“å—åˆ°Direct Prompt Injectionã€RAG Backdoorå’ŒInter-Agent Trust Exploitationç­‰æ”»å‡»ã€‚</li>
<li>LLMæ¨¡å‹é—´çš„äº¤äº’å’Œç›¸äº’å½±å“ä¼šå¼•å‘æ–°çš„å®‰å…¨é£é™©ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2507.06850">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-f8a5040aec42871892615ee4c96ab480.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-09a12eafb8df949a5583efe19d4b39f8.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-6b037c69f61bd6c6af14cb91d2728920.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-64607bd455e58911c25cf7a44f41fb83.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-0a61a344ec294211312fe0f7f129a513.jpg" align="middle">
</details>


<h1 id="-11"><a href="#-11" class="headerlink" title=""></a></h1><h2 id="IS-Bench-Evaluating-Interactive-Safety-of-VLM-Driven-Embodied-Agents-in-Daily-Household-Tasks"><a href="#IS-Bench-Evaluating-Interactive-Safety-of-VLM-Driven-Embodied-Agents-in-Daily-Household-Tasks" class="headerlink" title="IS-Bench: Evaluating Interactive Safety of VLM-Driven Embodied Agents in   Daily Household Tasks"></a>IS-Bench: Evaluating Interactive Safety of VLM-Driven Embodied Agents in   Daily Household Tasks</h2><p><strong>Authors:Xiaoya Lu, Zeren Chen, Xuhao Hu, Yijin Zhou, Weichen Zhang, Dongrui Liu, Lu Sheng, Jing Shao</strong></p>
<p>Flawed planning from VLM-driven embodied agents poses significant safety hazards, hindering their deployment in real-world household tasks. However, existing static, non-interactive evaluation paradigms fail to adequately assess risks within these interactive environments, since they cannot simulate dynamic risks that emerge from an agentâ€™s actions and rely on unreliable post-hoc evaluations that ignore unsafe intermediate steps. To bridge this critical gap, we propose evaluating an agentâ€™s interactive safety: its ability to perceive emergent risks and execute mitigation steps in the correct procedural order. We thus present IS-Bench, the first multi-modal benchmark designed for interactive safety, featuring 161 challenging scenarios with 388 unique safety risks instantiated in a high-fidelity simulator. Crucially, it facilitates a novel process-oriented evaluation that verifies whether risk mitigation actions are performed before&#x2F;after specific risk-prone steps. Extensive experiments on leading VLMs, including the GPT-4o and Gemini-2.5 series, reveal that current agents lack interactive safety awareness, and that while safety-aware Chain-of-Thought can improve performance, it often compromises task completion. By highlighting these critical limitations, IS-Bench provides a foundation for developing safer and more reliable embodied AI systems. Code and data are released under <a target="_blank" rel="noopener" href="https://github.com/AI45Lab/IS-Bench">this https URL</a>. </p>
<blockquote>
<p>ç”±VLMé©±åŠ¨çš„å®ä½“ä»£ç†çš„è§„åˆ’ç¼ºé™·ä¼šæ„æˆé‡å¤§çš„å®‰å…¨éšæ‚£ï¼Œé˜»ç¢äº†å®ƒä»¬åœ¨ç°å®å®¶åº­ä»»åŠ¡ä¸­çš„éƒ¨ç½²ã€‚ç„¶è€Œï¼Œç°æœ‰çš„é™æ€ã€éäº¤äº’å¼çš„è¯„ä¼°æ¨¡å¼æ— æ³•å……åˆ†è¯„ä¼°è¿™äº›äº¤äº’å¼ç¯å¢ƒä¸­çš„é£é™©ï¼Œå› ä¸ºå®ƒä»¬æ— æ³•æ¨¡æ‹Ÿä»£ç†è¡ŒåŠ¨ä¸­å‡ºç°çš„åŠ¨æ€é£é™©ï¼Œå¹¶ä¾èµ–äºå¿½ç•¥ä¸å®‰å…¨ä¸­é—´æ­¥éª¤çš„ä¸å¯é çš„äº‹åè¯„ä¼°ã€‚ä¸ºäº†å¼¥è¡¥è¿™ä¸€å…³é”®å·®è·ï¼Œæˆ‘ä»¬æå‡ºäº†å¯¹ä»£ç†çš„äº¤äº’å®‰å…¨æ€§è¿›è¡Œè¯„ä¼°ï¼šå…¶åœ¨å‡ºç°é£é™©æ—¶çš„æ„ŸçŸ¥èƒ½åŠ›å’ŒæŒ‰æ­£ç¡®ç¨‹åºé¡ºåºæ‰§è¡Œç¼“è§£æ­¥éª¤çš„èƒ½åŠ›ã€‚å› æ­¤ï¼Œæˆ‘ä»¬æ¨å‡ºäº†IS-Benchï¼Œè¿™æ˜¯ä¸“é—¨ä¸ºäº¤äº’å®‰å…¨æ€§è®¾è®¡çš„å¤šæ¨¡å¼åŸºå‡†æµ‹è¯•ï¼Œå…¶ä¸­åŒ…å«161ä¸ªå…·æœ‰æŒ‘æˆ˜æ€§çš„åœºæ™¯ï¼Œåœ¨é«˜åº¦é€¼çœŸçš„æ¨¡æ‹Ÿå™¨ä¸­å®ä¾‹åŒ–388ä¸ªç‹¬ç‰¹çš„å®‰å…¨é£é™©ã€‚å…³é”®çš„æ˜¯ï¼Œå®ƒä¿ƒè¿›äº†é¢å‘è¿‡ç¨‹çš„æ–°å‹è¯„ä¼°ï¼ŒéªŒè¯é£é™©ç¼“è§£è¡ŒåŠ¨æ˜¯å¦åœ¨ç‰¹å®šçš„é£é™©å€¾å‘æ­¥éª¤ä¹‹å‰æˆ–ä¹‹åæ‰§è¡Œã€‚é’ˆå¯¹é¢†å…ˆçš„VLMçš„å¹¿æ³›å®éªŒï¼ŒåŒ…æ‹¬GPT-4oå’ŒGemini-2.5ç³»åˆ—ï¼Œæ­ç¤ºå‡ºå½“å‰ä»£ç†ç¼ºä¹äº¤äº’å®‰å…¨æ„è¯†ï¼Œè™½ç„¶å®‰å…¨æ„è¯†çš„â€œæ€ç»´é“¾â€å¯ä»¥æé«˜æ€§èƒ½ï¼Œä½†å¾€å¾€ä¼šæŸå®³ä»»åŠ¡å®Œæˆã€‚é€šè¿‡çªå‡ºè¿™äº›å…³é”®é™åˆ¶ï¼ŒIS-Benchä¸ºå¼€å‘æ›´å®‰å…¨ã€æ›´å¯é çš„å®ä½“AIç³»ç»Ÿæä¾›äº†åŸºç¡€ã€‚ä»£ç å’Œæ•°æ®åœ¨<a target="_blank" rel="noopener" href="https://github.com/AI45Lab/IS-Bench">è¿™ä¸ªURL</a>å‘å¸ƒã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.16402v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æ–‡æœ¬æŒ‡å‡ºç”±VLMé©±åŠ¨çš„å®ä½“ä»£ç†å­˜åœ¨è§„åˆ’ç¼ºé™·ï¼Œè¿™åœ¨å®é™…å®¶åº­ä»»åŠ¡éƒ¨ç½²ä¸­å¸¦æ¥é‡å¤§å®‰å…¨éšæ‚£ã€‚ç°æœ‰çš„é™æ€ã€éäº’åŠ¨è¯„ä¼°æ¨¡å¼æ— æ³•åœ¨è¿™ç§äº’åŠ¨ç¯å¢ƒä¸­å……åˆ†è¯„ä¼°é£é™©ï¼Œå› ä¸ºå®ƒä»¬æ— æ³•æ¨¡æ‹Ÿç”±ä»£ç†è¡Œä¸ºäº§ç”Ÿçš„åŠ¨æ€é£é™©ï¼Œå¹¶ä¾èµ–äºå¿½è§†ä¸å®‰å…¨ä¸­é—´æ­¥éª¤çš„ä¸å¯é çš„åæœŸè¯„ä¼°ã€‚ä¸ºè§£å†³è¿™ä¸€å…³é”®å·®è·ï¼Œæœ¬æ–‡æå‡ºäº†å¯¹ä»£ç†çš„äº’åŠ¨å®‰å…¨æ€§è¿›è¡Œè¯„ä¼°çš„æ–¹æ³•ï¼Œå³è¯„ä¼°å…¶åœ¨å‡ºç°é£é™©æ—¶æ„ŸçŸ¥å’ŒæŒ‰æ­£ç¡®ç¨‹åºé¡ºåºæ‰§è¡Œç¼“è§£æ­¥éª¤çš„èƒ½åŠ›ã€‚ä¸ºæ­¤ï¼Œå¼•å…¥äº†IS-Benchï¼Œå®ƒæ˜¯é¦–ä¸ªä¸ºå¤šæ¨¡æ€äº’åŠ¨å®‰å…¨æ€§è®¾è®¡çš„åŸºå‡†æµ‹è¯•å¹³å°ï¼ŒåŒ…å«161ä¸ªå……æ»¡æŒ‘æˆ˜çš„åœºæ™¯å’Œ388ä¸ªç‹¬ç‰¹çš„å®‰å…¨é£é™©ï¼Œå¹¶å€ŸåŠ©é«˜ä¿çœŸæ¨¡æ‹Ÿå™¨è¿›è¡Œå®ä¾‹åŒ–ã€‚IS-Benchæä¾›äº†ä¸€ä¸ªè¿‡ç¨‹å¯¼å‘çš„è¯„ä¼°æ–¹æ³•ï¼Œå¯ä»¥éªŒè¯æ˜¯å¦åœ¨ç‰¹å®šé£é™©è¾ƒé«˜çš„æ­¥éª¤ä¹‹å‰æˆ–ä¹‹åæ‰§è¡Œäº†é£é™©ç¼“è§£æªæ–½ã€‚é€šè¿‡å¯¹é¢†å…ˆçš„VLMè¿›è¡Œå®éªŒï¼ŒåŒ…æ‹¬GPT-4oå’ŒGemini-2.5ç³»åˆ—ï¼Œå‘ç°å½“å‰ä»£ç†ç¼ºä¹äº’åŠ¨å®‰å…¨æ„è¯†ï¼Œå°½ç®¡å®‰å…¨æ„è¯†çš„æ€ç»´é“¾å¯ä»¥æå‡æ€§èƒ½ï¼Œä½†å¾€å¾€ä¼šç‰ºç‰²ä»»åŠ¡å®Œæˆåº¦ã€‚IS-Benchä¸ºå¼€å‘æ›´å®‰å…¨ã€æ›´å¯é çš„å®ä½“AIç³»ç»Ÿæä¾›äº†åŸºç¡€ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>VLMé©±åŠ¨çš„å®ä½“ä»£ç†å­˜åœ¨è§„åˆ’ç¼ºé™·ï¼Œå¯¼è‡´å®é™…éƒ¨ç½²ä¸­çš„å®‰å…¨éšæ‚£ã€‚</li>
<li>ç°æœ‰è¯„ä¼°æ¨¡å¼æ— æ³•å……åˆ†è¯„ä¼°äº’åŠ¨ç¯å¢ƒä¸­çš„é£é™©ã€‚</li>
<li>äº’åŠ¨å®‰å…¨æ€§çš„è¯„ä¼°æ˜¯å…³é”®ï¼Œæ¶‰åŠæ„ŸçŸ¥æ–°å…´é£é™©å’ŒæŒ‰æ­£ç¡®é¡ºåºæ‰§è¡Œç¼“è§£æ­¥éª¤çš„èƒ½åŠ›ã€‚</li>
<li>IS-Benchæ˜¯é¦–ä¸ªä¸ºå¤šæ¨¡æ€äº’åŠ¨å®‰å…¨æ€§è®¾è®¡çš„åŸºå‡†æµ‹è¯•å¹³å°ã€‚</li>
<li>IS-Benchæä¾›äº†è¿‡ç¨‹å¯¼å‘çš„è¯„ä¼°æ–¹æ³•ï¼ŒéªŒè¯äº†é£é™©ç¼“è§£æªæ–½æ˜¯å¦é’ˆå¯¹ç‰¹å®šé£é™©æ­¥éª¤æ‰§è¡Œã€‚</li>
<li>å½“å‰VLMå­˜åœ¨ç¼ºä¹äº’åŠ¨å®‰å…¨æ„è¯†çš„å±€é™æ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.16402">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-3dd384469c8db6de91a45fedabe4479e.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-ee138c2f364b8b149f1a8a92ab4e61b8.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a1fd567c1978ceec400494ca3acd96d6.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-4e6d23b51e0c7581b1a2051502554f59.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-5b7879ac8d667181b193ca48fce40cf5.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-84c24c635864c75bc6b5aab5f26bcf05.jpg" align="middle">
</details>


<h1 id="-12"><a href="#-12" class="headerlink" title=""></a></h1><h2 id="UITron-Speech-Towards-Automated-GUI-Agents-Based-on-Speech-Instructions"><a href="#UITron-Speech-Towards-Automated-GUI-Agents-Based-on-Speech-Instructions" class="headerlink" title="UITron-Speech: Towards Automated GUI Agents Based on Speech Instructions"></a>UITron-Speech: Towards Automated GUI Agents Based on Speech Instructions</h2><p><strong>Authors:Wenkang Han, Zhixiong Zeng, Jing Huang, Shu Jiang, Liming Zheng, Haibo Qiu, Chang Yao, Jingyuan Chen, Lin Ma</strong></p>
<p>Autonomous agents for Graphical User Interfaces (GUIs) are revolutionizing human-computer interaction, yet their reliance on text-based instructions imposes limitations on accessibility and convenience, particularly in hands-free scenarios. To address this issue, we propose replacing text with speech as the instruction input modality for GUI agents, and introduce UITron-Speech, which is the first end-to-end GUI agent capable of directly processing speech instructions and on-device screenshots to predict user actions. To tackle the problem of data scarcity, we synthesize high-quality speech instruction datasets using a random-speaker text-to-speech model. Additionally, we design a mixed-modality training strategy to mitigate the inherent modality imbalance in pre-trained foundation models. Furthermore, we conduct a statistical analysis of the distribution of GUI grounding prediction errors and propose a training-free two-step grounding refinement method to alleviate minor localization deviations. Extensive experiments on multiple benchmarks demonstrate that UITron-Speech achieves robust performance and superior adaptability, underscoring the feasibility and potential of speech-driven GUI agents for more accessible and intelligent human-computer interaction. Our code and datasets are available at <a target="_blank" rel="noopener" href="https://github.com/UITron-hub/UITron-Speech">https://github.com/UITron-hub/UITron-Speech</a>. </p>
<blockquote>
<p>å›¾å½¢ç”¨æˆ·ç•Œé¢ï¼ˆGUIï¼‰çš„è‡ªä¸»ä»£ç†æ­£åœ¨å½»åº•æ”¹å˜äººæœºäº¤äº’çš„æ–¹å¼ï¼Œç„¶è€Œå®ƒä»¬å¯¹æ–‡æœ¬æŒ‡ä»¤çš„ä¾èµ–é™åˆ¶äº†å¯è®¿é—®æ€§å’Œä¾¿åˆ©æ€§ï¼Œç‰¹åˆ«æ˜¯åœ¨å…æåœºæ™¯ä¸­ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºç”¨è¯­éŸ³ä»£æ›¿æ–‡æœ¬ä½œä¸ºGUIä»£ç†çš„æŒ‡ä»¤è¾“å…¥æ¨¡å¼ï¼Œå¹¶å¼•å…¥äº†UITron-Speechã€‚å®ƒæ˜¯ä¸€ä¸ªç«¯åˆ°ç«¯çš„é¦–ä¸ªGUIä»£ç†ï¼Œèƒ½å¤Ÿç›´æ¥å¤„ç†è¯­éŸ³æŒ‡ä»¤å’Œè®¾å¤‡æˆªå›¾æ¥é¢„æµ‹ç”¨æˆ·æ“ä½œã€‚ä¸ºäº†è§£å†³æ•°æ®ç¨€ç¼ºçš„é—®é¢˜ï¼Œæˆ‘ä»¬ä½¿ç”¨éšæœºè¯´è¯äººæ–‡æœ¬åˆ°è¯­éŸ³æ¨¡å‹åˆæˆé«˜è´¨é‡è¯­éŸ³æŒ‡ä»¤æ•°æ®é›†ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è®¾è®¡äº†ä¸€ç§æ··åˆæ¨¡å¼è®­ç»ƒç­–ç•¥ï¼Œä»¥ç¼“è§£é¢„è®­ç»ƒåŸºç¡€æ¨¡å‹ä¸­çš„å›ºæœ‰æ¨¡å¼ä¸å¹³è¡¡é—®é¢˜ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å¯¹GUIæ¥åœ°é¢„æµ‹è¯¯å·®çš„åˆ†å¸ƒè¿›è¡Œäº†ç»Ÿè®¡åˆ†æï¼Œå¹¶æå‡ºäº†æ— éœ€è®­ç»ƒçš„ä¸¤æ­¥æ¥åœ°ç»†åŒ–æ–¹æ³•ï¼Œä»¥å‡è½»è½»å¾®çš„å®šä½åå·®ã€‚åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸Šçš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼ŒUITron-Speechå®ç°äº†ç¨³å¥çš„æ€§èƒ½å’Œå“è¶Šçš„é€‚åº”æ€§ï¼Œå‡¸æ˜¾äº†è¯­éŸ³é©±åŠ¨çš„GUIä»£ç†åœ¨æ›´å¯è®¿é—®å’Œæ™ºèƒ½çš„äººæœºäº¤äº’ä¸­çš„å¯è¡Œæ€§å’Œæ½œåŠ›ã€‚æˆ‘ä»¬çš„ä»£ç å’Œæ•°æ®é›†å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/UITron-hub/UITron-Speech%E4%B8%8A%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/UITron-hub/UITron-Speechä¸Šæ‰¾åˆ°ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.11127v2">PDF</a> </p>
<p><strong>Summary</strong><br>è¯­éŸ³é©±åŠ¨çš„GUIä»£ç†æ­£åœ¨æ”¹å˜äººæœºäº¤äº’çš„æ–¹å¼ã€‚è¯¥ç ”ç©¶æå‡ºä½¿ç”¨è¯­éŸ³æŒ‡ä»¤æ›¿ä»£æ–‡æœ¬æŒ‡ä»¤ä½œä¸ºGUIä»£ç†çš„è¾“å…¥æ–¹å¼ï¼Œå¹¶å¼•å…¥UITron-Speechï¼Œå®ƒèƒ½ç›´æ¥å¤„ç†è¯­éŸ³æŒ‡ä»¤å’Œè®¾å¤‡æˆªå›¾ä»¥é¢„æµ‹ç”¨æˆ·æ“ä½œã€‚è¯¥ç ”ç©¶è§£å†³äº†æ•°æ®ç¨€ç¼ºçš„é—®é¢˜ï¼Œå¹¶è®¾è®¡äº†ä¸€ç§æ··åˆæ¨¡æ€è®­ç»ƒç­–ç•¥æ¥ç¼“è§£é¢„è®­ç»ƒåŸºç¡€æ¨¡å‹ä¸­çš„æ¨¡æ€ä¸å¹³è¡¡é—®é¢˜ã€‚æ­¤å¤–ï¼Œè¯¥ç ”ç©¶è¿˜æå‡ºäº†ä¸€ç§è®­ç»ƒå…è´¹çš„ä¸¤æ­¥å®šä½ä¿®æ­£æ–¹æ³•ï¼Œä»¥å‡è½»è½»å¾®å®šä½åå·®çš„é—®é¢˜ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>è‡ªä¸»ä»£ç†åœ¨GUIä¸­æ­£åœ¨é©å‘½åŒ–äººæœºäº¤äº’ã€‚</li>
<li>è¯­éŸ³æŒ‡ä»¤å¯ä»¥ä½œä¸ºGUIä»£ç†çš„è¾“å…¥æ–¹å¼ï¼Œæé«˜æ— éšœç¢æ€§å’Œä¾¿åˆ©æ€§ã€‚</li>
<li>UITron-Speechæ˜¯é¦–ä¸ªèƒ½å¤Ÿç›´æ¥å¤„ç†è¯­éŸ³æŒ‡ä»¤å’Œè®¾å¤‡æˆªå›¾çš„ç«¯åˆ°ç«¯GUIä»£ç†ã€‚</li>
<li>ç ”ç©¶è§£å†³äº†æ•°æ®ç¨€ç¼ºé—®é¢˜ï¼Œé€šè¿‡åˆæˆé«˜è´¨é‡è¯­éŸ³æŒ‡ä»¤æ•°æ®é›†æ¥è§£å†³ã€‚</li>
<li>è®¾è®¡äº†æ··åˆæ¨¡æ€è®­ç»ƒç­–ç•¥ï¼Œä»¥ç¼“è§£é¢„è®­ç»ƒæ¨¡å‹ä¸­çš„æ¨¡æ€ä¸å¹³è¡¡é—®é¢˜ã€‚</li>
<li>æå‡ºäº†è®­ç»ƒå…è´¹çš„å®šä½ä¿®æ­£æ–¹æ³•ï¼Œä»¥å‡è½»è½»å¾®å®šä½åå·®çš„é—®é¢˜ã€‚</li>
<li>UITron-Speechåœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­è¡¨ç°å‡ºç¨³å¥çš„æ€§èƒ½å’Œä¼˜è¶Šçš„é€‚åº”æ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.11127">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-9d925f7e627b1850827fb794a2e767bb.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e7ae03e93249d62cfd6e46704e8c5fb9.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-429bae2058c3eecbf568076778d782f4.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-cc2b64e1065e18c85952e6246c912b08.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-e80976aff71e49a4f1f3191236e77c6d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d99ea0b0e91ec0093aa13abe7e7f6791.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-bb9188fbea236ebf9918eb8aabff5c62.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-0a80e0d36462396c20cbb75d4fc5c25d.jpg" align="middle">
</details>


<h1 id="-13"><a href="#-13" class="headerlink" title=""></a></h1><h2 id="Accelerating-Focal-Search-in-Multi-Agent-Path-Finding-with-Tighter-Lower-Bounds"><a href="#Accelerating-Focal-Search-in-Multi-Agent-Path-Finding-with-Tighter-Lower-Bounds" class="headerlink" title="Accelerating Focal Search in Multi-Agent Path Finding with Tighter Lower   Bounds"></a>Accelerating Focal Search in Multi-Agent Path Finding with Tighter Lower   Bounds</h2><p><strong>Authors:Yimin Tang, Zhenghong Yu, Jiaoyang Li, Sven Koenig</strong></p>
<p>Multi-Agent Path Finding (MAPF) involves finding collision-free paths for multiple agents while minimizing a cost functionâ€“an NP-hard problem. Bounded suboptimal methods like Enhanced Conflict-Based Search (ECBS) and Explicit Estimation CBS (EECBS) balance solution quality with computational efficiency using focal search mechanisms. While effective, traditional focal search faces a limitation: the lower bound (LB) value determining which nodes enter the FOCAL list often increases slowly in early search stages, resulting in a constrained search space that delays finding valid solutions. In this paper, we propose a novel bounded suboptimal algorithm, double-ECBS (DECBS), to address this issue by first determining the maximum LB value and then employing a best-first search guided by this LB to find a collision-free path. Experimental results demonstrate that DECBS outperforms ECBS in most test cases and is compatible with existing optimization techniques. DECBS can reduce nearly 30% high-level CT nodes and 50% low-level focal search nodes. When agent density is moderate to high, DECBS achieves a 23.5% average runtime improvement over ECBS with identical suboptimality bounds and optimizations. </p>
<blockquote>
<p>å¤šæ™ºèƒ½ä½“è·¯å¾„å¯»æ‰¾ï¼ˆMAPFï¼‰æ¶‰åŠä¸ºå¤šä¸ªæ™ºèƒ½ä½“å¯»æ‰¾æ— ç¢°æ’è·¯å¾„ï¼ŒåŒæ—¶æœ€å°åŒ–æˆæœ¬å‡½æ•°â€”â€”è¿™æ˜¯ä¸€ä¸ªNPéš¾é¢˜ã€‚åƒåŸºäºå†²çªå¢å¼ºæœç´¢ï¼ˆECBSï¼‰å’Œæ˜¾å¼ä¼°è®¡CBSï¼ˆEECBSï¼‰è¿™æ ·çš„æœ‰ç•Œæ¬¡ä¼˜æ–¹æ³•é€šè¿‡ä½¿ç”¨ç„¦ç‚¹æœç´¢æœºåˆ¶æ¥å¹³è¡¡è§£å†³æ–¹æ¡ˆè´¨é‡ä¸è®¡ç®—æ•ˆç‡ã€‚å°½ç®¡æœ‰æ•ˆï¼Œä½†ä¼ ç»Ÿç„¦ç‚¹æœç´¢é¢ä¸´ä¸€ä¸ªå±€é™æ€§ï¼šåœ¨æ—©æœŸæœç´¢é˜¶æ®µï¼Œç¡®å®šå“ªäº›èŠ‚ç‚¹è¿›å…¥ç„¦ç‚¹åˆ—è¡¨çš„ä¸‹ç•Œï¼ˆLBï¼‰å€¼é€šå¸¸å¢é•¿ç¼“æ…¢ï¼Œå¯¼è‡´æœç´¢ç©ºé—´å—é™ï¼Œä»è€Œå»¶è¿Ÿæ‰¾åˆ°æœ‰æ•ˆè§£å†³æ–¹æ¡ˆã€‚é’ˆå¯¹è¿™ä¸€é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„æœ‰ç•Œæ¬¡ä¼˜ç®—æ³•â€”â€”åŒECBSï¼ˆDECBSï¼‰ï¼Œé¦–å…ˆç¡®å®šæœ€å¤§LBå€¼ï¼Œç„¶åé‡‡ç”¨æœ€ä½³ä¼˜å…ˆæœç´¢ï¼Œä»¥è¯¥LBä¸ºæŒ‡å¯¼æ‰¾åˆ°æ— ç¢°æ’è·¯å¾„ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒDECBSåœ¨å¤§å¤šæ•°æƒ…å†µä¸‹ä¼˜äºECBSï¼Œå¹¶ä¸”ä¸ç°æœ‰ä¼˜åŒ–æŠ€æœ¯å…¼å®¹ã€‚DECBSå¯ä»¥å‡å°‘è¿‘30%çš„é«˜çº§CTèŠ‚ç‚¹å’Œ50%çš„ä½ä½ç„¦ç‚¹æœç´¢èŠ‚ç‚¹ã€‚å½“æ™ºèƒ½ä½“å¯†åº¦é€‚ä¸­åˆ°è¾ƒé«˜æ—¶ï¼Œä¸ECBSç›¸æ¯”ï¼ŒDECBSåœ¨å…·æœ‰ç›¸åŒæ¬¡ä¼˜æ€§è¾¹ç•Œå’Œä¼˜åŒ–çš„æƒ…å†µä¸‹ï¼Œå¹³å‡è¿è¡Œæ—¶é—´ç¼©çŸ­äº†23.5%ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.03779v2">PDF</a> 7 pages</p>
<p><strong>Summary</strong></p>
<p>è¯¥è®ºæ–‡é’ˆå¯¹å¤šæ™ºèƒ½ä½“è·¯å¾„è§„åˆ’ï¼ˆMAPFï¼‰é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åä¸ºdouble-ECBSï¼ˆDECBSï¼‰çš„æ–°å‹æœ‰ç•Œæ¬¡ä¼˜ç®—æ³•ã€‚è¯¥ç®—æ³•æ—¨åœ¨è§£å†³ä¼ ç»Ÿç„¦ç‚¹æœç´¢é¢ä¸´çš„é™åˆ¶ï¼Œé€šè¿‡å…ˆç¡®å®šæœ€å¤§LBå€¼ï¼Œç„¶åä½¿ç”¨æœ€ä½³ä¼˜å…ˆæœç´¢æ¥æ‰¾åˆ°æ— ç¢°æ’è·¯å¾„ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒDECBSåœ¨å¤§å¤šæ•°æƒ…å†µä¸‹ä¼˜äºECBSï¼Œå¹¶èƒ½ä¸ç°æœ‰ä¼˜åŒ–æŠ€æœ¯å…¼å®¹ã€‚DECBSèƒ½æ˜¾è‘—å‡å°‘é«˜çº§CTèŠ‚ç‚¹å’Œä½çº§åˆ«ç„¦ç‚¹æœç´¢èŠ‚ç‚¹çš„æ•°é‡ï¼Œæé«˜ç®—æ³•æ•ˆç‡ã€‚å¯¹äºä¸­ç­‰è‡³é«˜å¯†åº¦æ™ºèƒ½ä½“ï¼ŒDECBSåœ¨å…·æœ‰ç›¸åŒæ¬¡ä¼˜æ€§è¾¹ç•Œå’Œä¼˜åŒ–çš„æƒ…å†µä¸‹ï¼Œå¹³å‡è¿è¡Œæ—¶é—´æ¯”ECBSæé«˜äº†çº¦23.5%ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤šæ™ºèƒ½ä½“è·¯å¾„è§„åˆ’ï¼ˆMAPFï¼‰æ˜¯ä¸€ä¸ªNPéš¾é¢˜ï¼Œæ—¨åœ¨æ‰¾åˆ°å¤šä¸ªæ™ºèƒ½ä½“çš„æ— ç¢°æ’è·¯å¾„å¹¶æœ€å°åŒ–æˆæœ¬å‡½æ•°ã€‚</li>
<li>Bounded Suboptimalæ–¹æ³•å¦‚ECBSå’ŒEECBSé€šè¿‡ç„¦ç‚¹æœç´¢æœºåˆ¶åœ¨è§£å†³æ–¹æ¡ˆè´¨é‡å’Œè®¡ç®—æ•ˆç‡ä¹‹é—´å–å¾—å¹³è¡¡ã€‚</li>
<li>ä¼ ç»Ÿç„¦ç‚¹æœç´¢é¢ä¸´çš„é—®é¢˜æ˜¯æ—©æœŸæœç´¢é˜¶æ®µLBå€¼å¢é•¿ç¼“æ…¢ï¼Œå¯¼è‡´æœç´¢ç©ºé—´å—é™ï¼Œå»¶è¿Ÿæ‰¾åˆ°æœ‰æ•ˆè§£å†³æ–¹æ¡ˆã€‚</li>
<li>DECBSç®—æ³•æ—¨åœ¨è§£å†³æ­¤é—®é¢˜ï¼Œé€šè¿‡å…ˆç¡®å®šæœ€å¤§LBå€¼ï¼Œç„¶åä½¿ç”¨æœ€ä½³ä¼˜å…ˆæœç´¢æ¥æ‰¾åˆ°æ— ç¢°æ’è·¯å¾„ã€‚</li>
<li>å®éªŒè¡¨æ˜ï¼ŒDECBSåœ¨å¤§å¤šæ•°æµ‹è¯•æ¡ˆä¾‹ä¸­ä¼˜äºECBSï¼Œå¹¶èƒ½æ˜¾è‘—å‡å°‘é«˜çº§CTèŠ‚ç‚¹å’Œä½çº§åˆ«ç„¦ç‚¹æœç´¢èŠ‚ç‚¹çš„æ•°é‡ã€‚</li>
<li>åœ¨ä¸­ç­‰è‡³é«˜å¯†åº¦æ™ºèƒ½ä½“çš„æƒ…å†µä¸‹ï¼ŒDECBSåœ¨å…·æœ‰ç›¸åŒæ¬¡ä¼˜æ€§è¾¹ç•Œå’Œä¼˜åŒ–çš„åœºæ™¯ä¸­æä¾›äº†æ˜¾è‘—çš„æ€§èƒ½æ”¹è¿›ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.03779">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-af94eba65a676db84eb65e73631ad07d.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-453cee9146bebd82f3d4c993ec4c4e8e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-0e0c66724901727ef3808f24e2560dd1.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ea3e0e1f631f7b958469e8ec41b2f6e8.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-41a27e95a8ed25e6ec98c70b60fbeb35.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-4e1f8e6e46dae675d2c824c3ad941501.jpg" align="middle">
</details>


<h1 id="-14"><a href="#-14" class="headerlink" title=""></a></h1><h2 id="RAILGUN-A-Unified-Convolutional-Policy-for-Multi-Agent-Path-Finding-Across-Different-Environments-and-Tasks"><a href="#RAILGUN-A-Unified-Convolutional-Policy-for-Multi-Agent-Path-Finding-Across-Different-Environments-and-Tasks" class="headerlink" title="RAILGUN: A Unified Convolutional Policy for Multi-Agent Path Finding   Across Different Environments and Tasks"></a>RAILGUN: A Unified Convolutional Policy for Multi-Agent Path Finding   Across Different Environments and Tasks</h2><p><strong>Authors:Yimin Tang, Xiao Xiong, Jingyi Xi, Jiaoyang Li, Erdem BÄ±yÄ±k, Sven Koenig</strong></p>
<p>Multi-Agent Path Finding (MAPF), which focuses on finding collision-free paths for multiple robots, is crucial for applications ranging from aerial swarms to warehouse automation. Solving MAPF is NP-hard so learning-based approaches for MAPF have gained attention, particularly those leveraging deep neural networks. Nonetheless, despite the communityâ€™s continued efforts, all learning-based MAPF planners still rely on decentralized planning due to variability in the number of agents and map sizes. We have developed the first centralized learning-based policy for MAPF problem called RAILGUN. RAILGUN is not an agent-based policy but a map-based policy. By leveraging a CNN-based architecture, RAILGUN can generalize across different maps and handle any number of agents. We collect trajectories from rule-based methods to train our model in a supervised way. In experiments, RAILGUN outperforms most baseline methods and demonstrates great zero-shot generalization capabilities on various tasks, maps and agent numbers that were not seen in the training dataset. </p>
<blockquote>
<p>å¤šæ™ºèƒ½ä½“è·¯å¾„å¯»æ‰¾ï¼ˆMAPFï¼‰ä¸“æ³¨äºä¸ºå¤šä¸ªæœºå™¨äººå¯»æ‰¾æ— ç¢°æ’è·¯å¾„ï¼Œå¯¹äºä»æ— äººæœºç¾¤åˆ°ä»“åº“è‡ªåŠ¨åŒ–çš„åº”ç”¨è‡³å…³é‡è¦ã€‚è§£å†³MAPFé—®é¢˜æ˜¯NPéš¾çš„ï¼Œå› æ­¤åŸºäºå­¦ä¹ çš„MAPFæ–¹æ³•å¼•èµ·äº†å…³æ³¨ï¼Œç‰¹åˆ«æ˜¯é‚£äº›åˆ©ç”¨æ·±åº¦ç¥ç»ç½‘ç»œçš„æ–¹æ³•ã€‚å°½ç®¡å¦‚æ­¤ï¼Œå°½ç®¡ç¤¾åŒºä¸€ç›´åœ¨åŠªåŠ›ï¼Œæ‰€æœ‰åŸºäºå­¦ä¹ çš„MAPFè§„åˆ’è€…ä»ç„¶ä¾èµ–äºåˆ†æ•£å¼è§„åˆ’ï¼Œè¿™æ˜¯ç”±äºæ™ºèƒ½ä½“å’Œåœ°å›¾è§„æ¨¡çš„å˜åŒ–ã€‚æˆ‘ä»¬ä¸ºMAPFé—®é¢˜å¼€å‘äº†ç¬¬ä¸€ä¸ªé›†ä¸­å¼å­¦ä¹ ç­–ç•¥ï¼Œåä¸ºRAILGUNã€‚RAILGUNä¸æ˜¯åŸºäºæ™ºèƒ½ä½“çš„ç­–ç•¥ï¼Œè€Œæ˜¯åŸºäºåœ°å›¾çš„ç­–ç•¥ã€‚é€šè¿‡åˆ©ç”¨åŸºäºCNNçš„æ¶æ„ï¼ŒRAILGUNå¯ä»¥åœ¨ä¸åŒçš„åœ°å›¾ä¸Šæ¨å¹¿ï¼Œå¹¶å¤„ç†ä»»ä½•æ•°é‡çš„æ™ºèƒ½ä½“ã€‚æˆ‘ä»¬ä»åŸºäºè§„åˆ™çš„æ–¹æ³•æ”¶é›†è½¨è¿¹ï¼Œä»¥ç›‘ç£çš„æ–¹å¼è®­ç»ƒæˆ‘ä»¬çš„æ¨¡å‹ã€‚åœ¨å®éªŒä¸­ï¼ŒRAILGUNä¼˜äºå¤§å¤šæ•°åŸºçº¿æ–¹æ³•ï¼Œå¹¶åœ¨å„ç§ä»»åŠ¡ã€åœ°å›¾å’Œæ™ºèƒ½ä½“æ•°é‡ä¸Šå±•ç¤ºäº†å‡ºè‰²çš„é›¶æ ·æœ¬æ¨å¹¿èƒ½åŠ›ï¼Œè¿™äº›åœ¨è®­ç»ƒæ•°æ®é›†ä¸­å¹¶æœªè§è¿‡ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.02992v2">PDF</a> 7 pages</p>
<p><strong>Summary</strong></p>
<p>å¤šæ™ºèƒ½ä½“è·¯å¾„æŸ¥æ‰¾ï¼ˆMAPFï¼‰å¯¹äºä»æ— äººæœºç¾¤åˆ°ä»“åº“è‡ªåŠ¨åŒ–ç­‰åº”ç”¨è‡³å…³é‡è¦ï¼Œå®ƒä¸ºå¤šä¸ªæœºå™¨äººæ‰¾åˆ°æ— ç¢°æ’è·¯å¾„ã€‚MAPFé—®é¢˜çš„è§£å†³æ˜¯NPéš¾çš„ï¼Œå› æ­¤åŸºäºå­¦ä¹ çš„MAPFæ–¹æ³•å—åˆ°å…³æ³¨ï¼Œå°¤å…¶æ˜¯åˆ©ç”¨æ·±åº¦ç¥ç»ç½‘ç»œçš„æ–¹æ³•ã€‚ç„¶è€Œï¼Œå°½ç®¡ç¤¾åŒºæŒç»­åŠªåŠ›ï¼Œæ‰€æœ‰åŸºäºå­¦ä¹ çš„MAPFè§„åˆ’å™¨ä»ä¾èµ–äºåˆ†æ•£å¼è§„åˆ’ï¼Œè¿™æ˜¯ç”±äºæ™ºèƒ½ä½“å’Œåœ°å›¾å¤§å°çš„å·®å¼‚é€ æˆçš„ã€‚æˆ‘ä»¬å¼€å‘äº†é¦–ä¸ªé’ˆå¯¹MAPFé—®é¢˜çš„é›†ä¸­å­¦ä¹ æ”¿ç­–ï¼Œç§°ä¸ºRAILGUNã€‚RAILGUNä¸æ˜¯åŸºäºæ™ºèƒ½ä½“çš„ç­–ç•¥ï¼Œè€Œæ˜¯åŸºäºåœ°å›¾çš„ç­–ç•¥ã€‚å®ƒé€šè¿‡åˆ©ç”¨CNNæ¶æ„ï¼Œå¯ä»¥è·¨ä¸åŒåœ°å›¾è¿›è¡Œæ¨å¹¿ï¼Œå¹¶å¤„ç†ä»»ä½•æ•°é‡çš„æ™ºèƒ½ä½“ã€‚æˆ‘ä»¬é€šè¿‡ä»åŸºäºè§„åˆ™çš„æ–¹æ³•æ”¶é›†è½¨è¿¹æ¥ä»¥ç›‘ç£æ–¹å¼è®­ç»ƒæˆ‘ä»¬çš„æ¨¡å‹ã€‚åœ¨å®éªŒä¸­ï¼ŒRAILGUNåœ¨å¤§å¤šæ•°åŸºå‡†æµ‹è¯•æ–¹æ³•ä¸­éƒ½è¡¨ç°å‡ºè‰²ï¼Œå¹¶åœ¨å„ç§ä»»åŠ¡ã€åœ°å›¾å’Œæ™ºèƒ½ä½“æ•°é‡ä¸Šå±•ç¤ºäº†å‡ºè‰²çš„é›¶æ ·æœ¬æ³›åŒ–èƒ½åŠ›ï¼Œè¿™äº›åœ¨è®­ç»ƒæ•°æ®é›†ä¸­å¹¶æœªå‡ºç°ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤šæ™ºèƒ½ä½“è·¯å¾„æŸ¥æ‰¾ï¼ˆMAPFï¼‰åœ¨å¤šä¸ªæœºå™¨äººå¯¼èˆªä¸­èµ·åˆ°å…³é”®ä½œç”¨ï¼Œå¹¿æ³›åº”ç”¨äºä¸åŒé¢†åŸŸã€‚</li>
<li>MAPFé—®é¢˜è§£å†³çš„å¤æ‚æ€§ä½¿å…¶æˆä¸ºNPéš¾é¢˜ï¼Œå› æ­¤åŸºäºå­¦ä¹ çš„æ–¹æ³•å—åˆ°å…³æ³¨ã€‚</li>
<li>åŸºäºå­¦ä¹ çš„MAPFè§„åˆ’å™¨é€šå¸¸é‡‡ç”¨åˆ†æ•£å¼è§„åˆ’ï¼Œå› ä¸ºæ™ºèƒ½ä½“å’Œåœ°å›¾å¤§å°çš„å˜åŒ–å¯¼è‡´é›†ä¸­è§„åˆ’å›°éš¾ã€‚</li>
<li>æå‡ºäº†ä¸€ç§æ–°çš„é›†ä¸­å­¦ä¹ ç­–ç•¥RAILGUNï¼Œå®ƒæ˜¯åŸºäºåœ°å›¾è€Œéæ™ºèƒ½ä½“çš„ç­–ç•¥ã€‚</li>
<li>RAILGUNåˆ©ç”¨CNNæ¶æ„å®ç°ä¸åŒåœ°å›¾ä¹‹é—´çš„æ³›åŒ–ï¼Œå¹¶èƒ½å¤„ç†ä»»æ„æ•°é‡çš„æ™ºèƒ½ä½“ã€‚</li>
<li>RAILGUNé€šè¿‡æ”¶é›†è§„åˆ™æ–¹æ³•çš„è½¨è¿¹è¿›è¡Œè®­ç»ƒï¼Œé‡‡ç”¨ç›‘ç£å­¦ä¹ æ–¹å¼è¿›è¡Œæ¨¡å‹è®­ç»ƒã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.02992">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-11ecbc244756e651e24d7b6106ba9307.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-46f345cc8129231c55ace15c027734b0.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-ada4d9efffb0544abb4fa70cc1a31d3f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-dbac5c9dfd47d6f740671a87d6589e35.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-d97dfe10a8f2ee98e10bf6ec7adf1e07.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-331e762a8f615e64d2b4a4d5e05083bf.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-2274a59ef6df99ba6a32201574aafba8.jpg" align="middle">
</details>


<h1 id="-15"><a href="#-15" class="headerlink" title=""></a></h1><h2 id="Assessing-Agentic-Large-Language-Models-in-Multilingual-National-Bias"><a href="#Assessing-Agentic-Large-Language-Models-in-Multilingual-National-Bias" class="headerlink" title="Assessing Agentic Large Language Models in Multilingual National Bias"></a>Assessing Agentic Large Language Models in Multilingual National Bias</h2><p><strong>Authors:Qianying Liu, Katrina Qiyao Wang, Fei Cheng, Sadao Kurohashi</strong></p>
<p>Large Language Models have garnered significant attention for their capabilities in multilingual natural language processing, while studies on risks associated with cross biases are limited to immediate context preferences. Cross-language disparities in reasoning-based recommendations remain largely unexplored, with a lack of even descriptive analysis. This study is the first to address this gap. We test LLMâ€™s applicability and capability in providing personalized advice across three key scenarios: university applications, travel, and relocation. We investigate multilingual bias in state-of-the-art LLMs by analyzing their responses to decision-making tasks across multiple languages. We quantify bias in model-generated scores and assess the impact of demographic factors and reasoning strategies (e.g., Chain-of-Thought prompting) on bias patterns. Our findings reveal that local language bias is prevalent across different tasks, with GPT-4 and Sonnet reducing bias for English-speaking countries compared to GPT-3.5 but failing to achieve robust multilingual alignment, highlighting broader implications for multilingual AI agents and applications such as education. \footnote{Code available at: <a target="_blank" rel="noopener" href="https://github.com/yiyunya/assess_agentic_national_bias">https://github.com/yiyunya/assess_agentic_national_bias</a> </p>
<blockquote>
<p>å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å¤šè¯­ç§è‡ªç„¶è¯­è¨€å¤„ç†æ–¹é¢å¼•èµ·äº†å¹¿æ³›å…³æ³¨ï¼Œè€Œä¸è·¨è¯­è¨€åè§ç›¸å…³çš„é£é™©ç ”ç©¶ä»…é™äºå³æ—¶è¯­å¢ƒåå¥½ã€‚åŸºäºæ¨ç†çš„æ¨èä¸­çš„è·¨è¯­è¨€å·®å¼‚åœ¨å¾ˆå¤§ç¨‹åº¦ä¸Šå°šæœªè¢«æ¢ç´¢ï¼Œç”šè‡³ç¼ºä¹æè¿°æ€§åˆ†æã€‚æœ¬ç ”ç©¶é¦–æ¬¡å¡«è¡¥äº†è¿™ä¸€ç©ºç™½ã€‚æˆ‘ä»¬æµ‹è¯•äº†å¤§å‹è¯­è¨€æ¨¡å‹åœ¨ä¸‰ä¸ªå…³é”®åœºæ™¯ï¼ˆå¤§å­¦ç”³è¯·ã€æ—…è¡Œå’Œæ¬è¿ï¼‰ä¸­æä¾›ä¸ªæ€§åŒ–å»ºè®®çš„é€‚ç”¨æ€§å’Œèƒ½åŠ›ã€‚é€šè¿‡åˆ†æå¤§å‹è¯­è¨€æ¨¡å‹åœ¨å¤šè¯­è¨€å†³ç­–ä»»åŠ¡ä¸­çš„å›ç­”ï¼Œæˆ‘ä»¬ç ”ç©¶äº†å…¶ä¸­çš„å¤šè¯­è¨€åè§ã€‚æˆ‘ä»¬é‡åŒ–äº†æ¨¡å‹ç”Ÿæˆåˆ†æ•°ä¸­çš„åè§ï¼Œå¹¶è¯„ä¼°äº†äººå£ç»Ÿè®¡å› ç´ å’Œæ¨ç†ç­–ç•¥ï¼ˆå¦‚â€œæ€ç»´é“¾â€æç¤ºï¼‰å¯¹åè§æ¨¡å¼çš„å½±å“ã€‚æˆ‘ä»¬çš„ç ”ç©¶å‘ç°ï¼Œæœ¬åœ°è¯­è¨€åè§åœ¨ä¸åŒä»»åŠ¡ä¸­æ™®éå­˜åœ¨ï¼ŒGPT-4å’ŒSonnetå¯¹è‹±æ–‡å›½å®¶çš„åè§å‡å°‘ï¼Œç›¸è¾ƒäºGPT-3.5ä½†æœªèƒ½å®ç°ç¨³å¥çš„å¤šè¯­è¨€å¯¹é½ï¼Œè¿™å¯¹å¤šè¯­è¨€äººå·¥æ™ºèƒ½ä»£ç†å’Œåº”ç”¨ï¼ˆå¦‚æ•™è‚²ï¼‰å…·æœ‰æ›´å¹¿æ³›çš„å½±å“ã€‚\footnote{ä»£ç å¯åœ¨ï¼š\url{<a target="_blank" rel="noopener" href="https://github.com/yiyunya/assess_agentic_national_bias%7D">https://github.com/yiyunya/assess_agentic_national_bias}</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.17945v2">PDF</a> Accepted to ACL 2025 Findings. 14 pages</p>
<p><strong>Summary</strong></p>
<p>å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å¤šè¯­ç§è‡ªç„¶è¯­è¨€å¤„ç†ä¸­å—åˆ°å¹¿æ³›å…³æ³¨ï¼Œä½†å…³äºè·¨è¯­è¨€åè§é£é™©çš„ç ”ç©¶ä»…é™äºç›´æ¥è¯­å¢ƒåå¥½ã€‚æœ¬ç ”ç©¶é¦–æ¬¡å…³æ³¨è·¨è¯­è¨€å·®å¼‚åœ¨åŸºäºæ¨ç†çš„å»ºè®®ä¸­çš„å½±å“ï¼Œæ¢ç´¢äº†è¯­è¨€æ¨¡å‹åœ¨æä¾›ä¸ªæ€§åŒ–å»ºè®®æ–¹é¢çš„é€‚ç”¨æ€§ã€‚é€šè¿‡å¯¹æœ€æ–°å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å†³ç­–ä»»åŠ¡ä¸­çš„ååº”è¿›è¡Œåˆ†æï¼Œæœ¬ç ”ç©¶é‡åŒ–äº†æ¨¡å‹ç”Ÿæˆçš„åˆ†æ•°ä¸­çš„åè§ï¼Œå¹¶è¯„ä¼°äº†äººå£ç»Ÿè®¡å› ç´ å’Œæ¨ç†ç­–ç•¥å¯¹åè§æ¨¡å¼çš„å½±å“ã€‚ç ”ç©¶å‘ç°ï¼Œæœ¬åœ°è¯­è¨€åè§åœ¨ä¸åŒä»»åŠ¡ä¸­æ™®éå­˜åœ¨ï¼ŒGPT-4å’ŒSonnetç›¸è¾ƒäºGPT-3.5åœ¨è‹±è¯­å›½å®¶çš„åè§æœ‰æ‰€å‡å°‘ï¼Œä½†ä»æœªå®ç°ç¨³å¥çš„å¤šè¯­è¨€å¯¹é½ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å¤šè¯­ç§è‡ªç„¶è¯­è¨€å¤„ç†ä¸­å—åˆ°å¹¿æ³›å…³æ³¨ã€‚</li>
<li>è·¨è¯­è¨€åè§åœ¨åŸºäºæ¨ç†çš„å»ºè®®ä¸­å½±å“æ˜¾è‘—ï¼Œè¿™ä¸€é¢†åŸŸçš„ç ”ç©¶ä»å¾…æ·±å…¥ã€‚</li>
<li>è¯­è¨€æ¨¡å‹åœ¨æä¾›ä¸ªæ€§åŒ–å»ºè®®æ–¹é¢çš„é€‚ç”¨æ€§å¾—åˆ°äº†æ¢ç´¢ã€‚</li>
<li>æœ¬ç ”ç©¶åˆ†æäº†æœ€æ–°å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å†³ç­–ä»»åŠ¡ä¸­çš„ååº”ã€‚</li>
<li>ç ”ç©¶å‘ç°æ¨¡å‹ç”Ÿæˆçš„åˆ†æ•°ä¸­å­˜åœ¨é‡åŒ–åè§ã€‚</li>
<li>äººå£ç»Ÿè®¡å› ç´ å’Œæ¨ç†ç­–ç•¥å¯¹è¯­è¨€æ¨¡å‹çš„åè§æ¨¡å¼æœ‰å½±å“ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.17945">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-511bd72d45c1275e598ee05151f2f58d.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-0b0a34d02ea600b20e3dc1889fea3023.jpg" align="middle">
</details>


<h1 id="-16"><a href="#-16" class="headerlink" title=""></a></h1><h2 id="Evaluating-the-Robustness-of-Multimodal-Agents-Against-Active-Environmental-Injection-Attacks"><a href="#Evaluating-the-Robustness-of-Multimodal-Agents-Against-Active-Environmental-Injection-Attacks" class="headerlink" title="Evaluating the Robustness of Multimodal Agents Against Active   Environmental Injection Attacks"></a>Evaluating the Robustness of Multimodal Agents Against Active   Environmental Injection Attacks</h2><p><strong>Authors:Yurun Chen, Xavier Hu, Keting Yin, Juncheng Li, Shengyu Zhang</strong></p>
<p>As researchers continue to optimize AI agents for more effective task execution within operating systems, they often overlook a critical security concern: the ability of these agents to detect â€œimpostorsâ€ within their environment. Through an analysis of the agentsâ€™ operational context, we identify a significant threat-attackers can disguise malicious attacks as environmental elements, injecting active disturbances into the agentsâ€™ execution processes to manipulate their decision-making. We define this novel threat as the Active Environment Injection Attack (AEIA). Focusing on the interaction mechanisms of the Android OS, we conduct a risk assessment of AEIA and identify two critical security vulnerabilities: (1) Adversarial content injection in multimodal interaction interfaces, where attackers embed adversarial instructions within environmental elements to mislead agent decision-making; and (2) Reasoning gap vulnerabilities in the agentâ€™s task execution process, which increase susceptibility to AEIA attacks during reasoning. To evaluate the impact of these vulnerabilities, we propose AEIA-MN, an attack scheme that exploits interaction vulnerabilities in mobile operating systems to assess the robustness of MLLM-based agents. Experimental results show that even advanced MLLMs are highly vulnerable to this attack, achieving a maximum attack success rate of 93% on the AndroidWorld benchmark by combining two vulnerabilities. </p>
<blockquote>
<p>éšç€ç ”ç©¶äººå‘˜ä¸æ–­ä¼˜åŒ–æ“ä½œç³»ç»Ÿå†…çš„äººå·¥æ™ºèƒ½ä»£ç†ï¼ˆAI agentsï¼‰ï¼Œä»¥æ›´æœ‰æ•ˆåœ°æ‰§è¡Œä»»åŠ¡ï¼Œä»–ä»¬å¾€å¾€å¿½ç•¥äº†ä¸€ä¸ªå…³é”®çš„å®‰å…¨é—®é¢˜ï¼šè¿™äº›ä»£ç†æ£€æµ‹å…¶ç¯å¢ƒä¸­â€œä¼ªè£…è€…â€ï¼ˆimpostorsï¼‰çš„èƒ½åŠ›ã€‚é€šè¿‡åˆ†æä»£ç†çš„æ“ä½œä¸Šä¸‹æ–‡ï¼Œæˆ‘ä»¬å‘ç°äº†ä¸€ç§é‡å¤§å¨èƒï¼šæ”»å‡»è€…å¯ä»¥å°†æ¶æ„æ”»å‡»ä¼ªè£…æˆç¯å¢ƒå› ç´ ï¼Œå‘ä»£ç†çš„æ‰§è¡Œè¿‡ç¨‹ä¸­æ³¨å…¥ä¸»åŠ¨å¹²æ‰°ï¼Œä»¥æ“çºµå…¶å†³ç­–ã€‚æˆ‘ä»¬å°†è¿™ç§æ–°å‹å¨èƒå®šä¹‰ä¸ºâ€œä¸»åŠ¨ç¯å¢ƒæ³¨å…¥æ”»å‡»â€ï¼ˆAEIAï¼‰ã€‚æˆ‘ä»¬å…³æ³¨Androidæ“ä½œç³»ç»Ÿçš„äº¤äº’æœºåˆ¶ï¼Œå¯¹AEIAè¿›è¡Œäº†é£é™©è¯„ä¼°ï¼Œå¹¶å‘ç°äº†ä¸¤ä¸ªå…³é”®çš„å®‰å…¨æ¼æ´ï¼šï¼ˆ1ï¼‰å¤šæ¨¡å¼äº¤äº’ç•Œé¢ä¸­çš„å¯¹æŠ—å†…å®¹æ³¨å…¥ï¼Œæ”»å‡»è€…å°†å¯¹æŠ—æ€§æŒ‡ä»¤åµŒå…¥ç¯å¢ƒå…ƒç´ ä¸­ï¼Œä»¥è¯¯å¯¼ä»£ç†çš„å†³ç­–åˆ¶å®šï¼›ï¼ˆ2ï¼‰ä»£ç†ä»»åŠ¡æ‰§è¡Œè¿‡ç¨‹ä¸­çš„æ¨ç†é—´éš”æ¼æ´ï¼Œå¢åŠ äº†åœ¨æ¨ç†è¿‡ç¨‹ä¸­é­å—AEIAæ”»å‡»çš„é£é™©ã€‚ä¸ºäº†è¯„ä¼°è¿™äº›æ¼æ´çš„å½±å“ï¼Œæˆ‘ä»¬æå‡ºäº†AEIA-MNæ”»å‡»æ–¹æ¡ˆï¼Œè¯¥æ–¹æ¡ˆåˆ©ç”¨ç§»åŠ¨æ“ä½œç³»ç»Ÿä¸­çš„äº¤äº’æ¼æ´æ¥è¯„ä¼°åŸºäºMLLMçš„ä»£ç†çš„ç¨³å¥æ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œå³ä½¿æ˜¯å…ˆè¿›çš„MLLMä¹Ÿææ˜“å—åˆ°è¿™ç§æ”»å‡»çš„å½±å“ï¼Œé€šè¿‡åœ¨AndroidWorldåŸºå‡†æµ‹è¯•ä¸­ç»“åˆä¸¤ä¸ªæ¼æ´ï¼Œæœ€é«˜æ”»å‡»æˆåŠŸç‡è¾¾åˆ°äº†93%ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.13053v3">PDF</a> Accepted at ACM MM 2025 Main Conference</p>
<p><strong>Summary</strong>ï¼š<br>ç ”ç©¶è€…åœ¨ä¼˜åŒ–äººå·¥æ™ºèƒ½ä»£ç†ä»¥åœ¨æ“ä½œç³»ç»Ÿå†…æ›´æœ‰æ•ˆåœ°æ‰§è¡Œä»»åŠ¡æ—¶ï¼Œå¾€å¾€å¿½ç•¥äº†å…³é”®çš„å®‰å…¨é—®é¢˜ï¼Œå³è¿™äº›ä»£ç†æ£€æµ‹ç¯å¢ƒä¸­â€œä¼ªè£…è€…â€çš„èƒ½åŠ›ã€‚é€šè¿‡åˆ†æä»£ç†çš„æ“ä½œä¸Šä¸‹æ–‡ï¼Œæˆ‘ä»¬å‘ç°äº†ä¸€ç§é‡å¤§å¨èƒâ€”â€”æ”»å‡»è€…å¯ä»¥å°†æ¶æ„æ”»å‡»ä¼ªè£…æˆç¯å¢ƒå…ƒç´ ï¼Œå°†ä¸»åŠ¨å¹²æ‰°æ³¨å…¥ä»£ç†çš„æ‰§è¡Œè¿‡ç¨‹ä¸­ï¼Œä»è€Œæ“çºµå…¶å†³ç­–ã€‚æˆ‘ä»¬ç§°è¿™ç§æ–°å‹å¨èƒä¸ºActive Environment Injection Attackï¼ˆAEIAï¼‰ã€‚é€šè¿‡å¯¹Androidæ“ä½œç³»ç»Ÿçš„äº¤äº’æœºåˆ¶è¿›è¡Œé£é™©è¯„ä¼°ï¼Œæˆ‘ä»¬å‘ç°äº†ä¸¤ä¸ªå…³é”®çš„å®‰å…¨æ¼æ´ï¼šä¸€æ˜¯å¤šæ¨¡å¼äº¤äº’ç•Œé¢ä¸­çš„å¯¹æŠ—å†…å®¹æ³¨å…¥ï¼Œæ”»å‡»è€…å¯ä»¥åœ¨ç¯å¢ƒå…ƒç´ ä¸­åµŒå…¥å¯¹æŠ—æŒ‡ä»¤æ¥è¯¯å¯¼ä»£ç†çš„å†³ç­–ï¼›äºŒæ˜¯ä»£ç†ä»»åŠ¡æ‰§è¡Œè¿‡ç¨‹ä¸­çš„æ¨ç†é—´éš”æ¼æ´ï¼Œä¼šå¢åŠ åœ¨æ¨ç†è¿‡ç¨‹ä¸­å—åˆ°AEIAæ”»å‡»çš„é£é™©ã€‚ä¸ºäº†è¯„ä¼°è¿™äº›æ¼æ´çš„å½±å“ï¼Œæˆ‘ä»¬æå‡ºäº†AEIA-MNæ”»å‡»æ–¹æ¡ˆï¼Œè¯¥æ–¹æ¡ˆåˆ©ç”¨ç§»åŠ¨æ“ä½œç³»ç»Ÿä¸­çš„äº¤äº’æ¼æ´æ¥è¯„ä¼°åŸºäºMLLMçš„ä»£ç†çš„ç¨³å¥æ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œå³ä½¿æ˜¯é«˜çº§MLLMä¹Ÿå¾ˆå®¹æ˜“å—åˆ°è¿™ç§æ”»å‡»ï¼Œåœ¨AndroidWorldåŸºå‡†æµ‹è¯•ä¸­ç»“åˆä¸¤ä¸ªæ¼æ´çš„æœ€å¤§æ”»å‡»æˆåŠŸç‡è¾¾åˆ°93%ã€‚</p>
<p><strong>Key Takeaways</strong>ï¼š</p>
<ol>
<li>ç ”ç©¶è€…ä¼˜åŒ–AIä»£ç†æ—¶æ˜“å¿½ç•¥æ£€æµ‹ç¯å¢ƒä¸­â€œä¼ªè£…è€…â€çš„å…³é”®å®‰å…¨é—®é¢˜ã€‚</li>
<li>å‡ºç°äº†ä¸€ç§æ–°å‹å¨èƒActive Environment Injection Attackï¼ˆAEIAï¼‰ï¼Œæ”»å‡»è€…èƒ½å°†æ¶æ„æ”»å‡»ä¼ªè£…æˆç¯å¢ƒå…ƒç´ ã€‚</li>
<li>åœ¨å¤šæ¨¡å¼äº¤äº’ç•Œé¢ä¸­å­˜åœ¨ç€å¯¹æŠ—å†…å®¹æ³¨å…¥çš„å®‰å…¨æ¼æ´ã€‚</li>
<li>ä»£ç†ä»»åŠ¡æ‰§è¡Œè¿‡ç¨‹ä¸­çš„æ¨ç†é—´éš”æ¼æ´ä¼šå¢åŠ å—åˆ°AEIAæ”»å‡»çš„é£é™©ã€‚</li>
<li>AEIAæ”»å‡»èƒ½é€šè¿‡åˆ©ç”¨ç§»åŠ¨æ“ä½œç³»ç»Ÿä¸­çš„äº¤äº’æ¼æ´è¿›è¡Œã€‚</li>
<li>åŸºäºMLLMçš„ä»£ç†å­˜åœ¨è¾ƒå¤§çš„AEIAæ”»å‡»é£é™©ï¼Œæ”»å‡»æˆåŠŸç‡æœ€é«˜å¯è¾¾93%ã€‚</li>
<li>ç°æœ‰AIä»£ç†éœ€è¦è¿›ä¸€æ­¥åŠ å¼ºåœ¨æ“ä½œç³»ç»Ÿå†…çš„å®‰å…¨é˜²æŠ¤èƒ½åŠ›ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.13053">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-131fc6c00975fce0d00661a0f9569ac9.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-cd98be6650e55f97f707ea73f7c966f0.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ed9f8d3d46943fad9e9278d692642a47.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-af74eb4f2f274443cb5879733158cabe.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-85ba09a86aff289f87465c7fa6c0ceb3.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-eadd2d6e8d180256c95a7698c8d0f76d.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-a891d4cf49da8d1d95b3ac849be75ec6.jpg" align="middle">
</details>


<h1 id="-17"><a href="#-17" class="headerlink" title=""></a></h1><h2 id="A-Value-Based-Parallel-Update-MCTS-Method-for-Multi-Agent-Cooperative-Decision-Making-of-Connected-and-Automated-Vehicles"><a href="#A-Value-Based-Parallel-Update-MCTS-Method-for-Multi-Agent-Cooperative-Decision-Making-of-Connected-and-Automated-Vehicles" class="headerlink" title="A Value Based Parallel Update MCTS Method for Multi-Agent Cooperative   Decision Making of Connected and Automated Vehicles"></a>A Value Based Parallel Update MCTS Method for Multi-Agent Cooperative   Decision Making of Connected and Automated Vehicles</h2><p><strong>Authors:Ye Han, Lijun Zhang, Dejian Meng, Zhuang Zhang, Xingyu Hu, Songyu Weng</strong></p>
<p>To solve the problem of lateral and logitudinal joint decision-making of multi-vehicle cooperative driving for connected and automated vehicles (CAVs), this paper proposes a Monte Carlo tree search (MCTS) method with parallel update for multi-agent Markov game with limited horizon and time discounted setting. By analyzing the parallel actions in the multi-vehicle joint action space in the partial-steady-state traffic flow, the parallel update method can quickly exclude potential dangerous actions, thereby increasing the search depth without sacrificing the search breadth. The proposed method is tested in a large number of randomly generated traffic flow. The experiment results show that the algorithm has good robustness and better performance than the SOTA reinforcement learning algorithms and heuristic methods. The vehicle driving strategy using the proposed algorithm shows rationality beyond human drivers, and has advantages in traffic efficiency and safety in the coordinating zone. </p>
<blockquote>
<p>é’ˆå¯¹è¿æ¥è‡ªåŠ¨åŒ–è½¦è¾†ï¼ˆCAVsï¼‰çš„å¤šè½¦ååŒé©¾é©¶çš„æ¨ªå‘å’Œçºµå‘è”åˆå†³ç­–é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºé©¬å°”å¯å¤«åšå¼ˆçš„å¤šæ™ºèƒ½ä½“è’™ç‰¹å¡æ´›æ ‘æœç´¢ï¼ˆMCTSï¼‰æ–¹æ³•ï¼Œè¯¥æ–¹æ³•é‡‡ç”¨å¹¶è¡Œæ›´æ–°ç­–ç•¥ï¼Œé€‚ç”¨äºæœ‰é™è§†é‡å’Œæ—¶é—´æŠ˜æ‰£è®¾ç½®ã€‚é€šè¿‡åˆ†æéƒ¨åˆ†ç¨³æ€äº¤é€šæµä¸­å¤šè½¦è”åˆåŠ¨ä½œç©ºé—´çš„å¹¶è¡ŒåŠ¨ä½œï¼Œå¹¶è¡Œæ›´æ–°æ–¹æ³•å¯ä»¥è¿…é€Ÿæ’é™¤æ½œåœ¨çš„å±é™©åŠ¨ä½œï¼Œä»è€Œåœ¨ä¸å½±å“æœç´¢å¹¿åº¦çš„æƒ…å†µä¸‹å¢åŠ æœç´¢æ·±åº¦ã€‚è¯¥æ–¹æ³•åœ¨å¤§é‡éšæœºç”Ÿæˆçš„äº¤é€šæµä¸­è¿›è¡Œäº†æµ‹è¯•ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥ç®—æ³•å…·æœ‰è‰¯å¥½çš„é²æ£’æ€§ï¼Œå¹¶ä¼˜äºå½“å‰æœ€ä½³çš„å¼ºåŒ–å­¦ä¹ ç®—æ³•å’Œå¯å‘å¼æ–¹æ³•ã€‚ä½¿ç”¨æ‰€æå‡ºç®—æ³•çš„è½¦è¾†é©¾é©¶ç­–ç•¥è¡¨ç°å‡ºäº†è¶…è¶Šäººç±»é©¾é©¶å‘˜çš„åˆç†æ€§ï¼Œå¹¶åœ¨åè°ƒåŒºåŸŸå†…å…·æœ‰æé«˜äº¤é€šæ•ˆç‡å’Œå®‰å…¨æ€§çš„ä¼˜åŠ¿ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2409.13783v2">PDF</a> arXiv admin note: text overlap with arXiv:2408.04295 by other authors</p>
<p><strong>Summary</strong></p>
<p>è¯¥è®ºæ–‡é’ˆå¯¹è¿æ¥å’Œè‡ªåŠ¨åŒ–è½¦è¾†ï¼ˆCAVsï¼‰çš„å¤šè½¦ååŒé©¾é©¶çš„æ¨ªå‘å’Œçºµå‘è”åˆå†³ç­–é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åŸºäºè’™ç‰¹å¡æ´›æ ‘æœç´¢ï¼ˆMCTSï¼‰çš„å¹¶è¡Œæ›´æ–°æ–¹æ³•ï¼Œç”¨äºå¤„ç†å¤šæ™ºèƒ½ä½“é©¬å°”å¯å¤«åšå¼ˆä¸­æœ‰é™è§†ç•Œå’Œæ—¶é—´æŠ˜æ‰£è®¾ç½®ã€‚é€šè¿‡åˆ†æéƒ¨åˆ†ç¨³æ€äº¤é€šæµä¸­çš„å¤šè½¦è”åˆè¡ŒåŠ¨ç©ºé—´ä¸­çš„å¹¶è¡Œè¡ŒåŠ¨ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿè¿…é€Ÿæ’é™¤æ½œåœ¨çš„å±é™©è¡ŒåŠ¨ï¼Œä»è€Œåœ¨å¢åŠ æœç´¢æ·±åº¦çš„åŒæ—¶ä¸ç‰ºç‰²æœç´¢å¹¿åº¦ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥ç®—æ³•å…·æœ‰è‰¯å¥½çš„é²æ£’æ€§ï¼Œä¼˜äºå½“å‰æœ€ä½³å¼ºåŒ–å­¦ä¹ ç®—æ³•å’Œå¯å‘å¼æ–¹æ³•ã€‚ä½¿ç”¨æ­¤ç®—æ³•çš„è½¦è¾†é©¾é©¶ç­–ç•¥åœ¨åè°ƒåŒºåŸŸå†…çš„äº¤é€šæ•ˆç‡å’Œå®‰å…¨æ€§æ–¹é¢è¡¨ç°å‡ºè¶…è¶Šäººç±»é©¾é©¶å‘˜çš„åˆç†æ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>è¯¥è®ºæ–‡æå‡ºäº†ä¸€ç§åŸºäºè’™ç‰¹å¡æ´›æ ‘æœç´¢ï¼ˆMCTSï¼‰çš„å¹¶è¡Œæ›´æ–°æ–¹æ³•ï¼Œç”¨äºè§£å†³å¤šè½¦ååŒé©¾é©¶çš„æ¨ªå‘å’Œçºµå‘è”åˆå†³ç­–é—®é¢˜ã€‚</li>
<li>æ–¹æ³•èƒ½å¤Ÿåœ¨éƒ¨åˆ†ç¨³æ€äº¤é€šæµä¸­åˆ†æå¤šè½¦è”åˆè¡ŒåŠ¨ç©ºé—´çš„å¹¶è¡Œè¡ŒåŠ¨ã€‚</li>
<li>å¹³è¡Œæ›´æ–°æ–¹æ³•å¯ä»¥è¿…é€Ÿæ’é™¤æ½œåœ¨çš„å±é™©è¡ŒåŠ¨ï¼Œå¢åŠ æœç´¢æ·±åº¦è€Œä¸ç‰ºç‰²æœç´¢å¹¿åº¦ã€‚</li>
<li>è¯¥ç®—æ³•åœ¨å¤§é‡éšæœºç”Ÿæˆçš„äº¤é€šæµé‡æµ‹è¯•ä¸­å¾—åˆ°äº†éªŒè¯ï¼Œå…·æœ‰è‰¯å¥½çš„é²æ£’æ€§ã€‚</li>
<li>è¯¥ç®—æ³•åœ¨æ€§èƒ½ä¸Šä¼˜äºå½“å‰çš„å¼ºåŒ–å­¦ä¹ ç®—æ³•å’Œå¯å‘å¼æ–¹æ³•ã€‚</li>
<li>ä½¿ç”¨è¯¥ç®—æ³•çš„è½¦è¾†é©¾é©¶ç­–ç•¥åœ¨äº¤é€šæ•ˆç‡å’Œå®‰å…¨æ€§æ–¹é¢è¡¨ç°å‡ºè¶…è¶Šäººç±»é©¾é©¶å‘˜çš„åˆç†æ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2409.13783">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-7bbd41f332f869ea359cbacb57fd2ad2.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-be243c59337272540aa194b5012e758f.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-1cca88156ceb2dd0b54759d1bd64e660.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-2c256798ec83bdb3921bd2566234d946.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c278434d55c1e991606aa4dcefd4ab31.jpg" align="middle">
</details>


<h1 id="-18"><a href="#-18" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-08-08/Agent/">https://kedreamix.github.io/Talk2Paper/Paper/2025-08-08/Agent/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/Agent/">
                                    <span class="chip bg-color">Agent</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-08-08/Few-Shot/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-2c5a6b0010dcec3d6ae49bd08f7e4a51.jpg" class="responsive-img" alt="Few-Shot">
                        
                        <span class="card-title">Few-Shot</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Few-Shot æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-08-08  GraphProp Training the Graph Foundation Models using Graph Properties
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-08-08
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Few-Shot/" class="post-category">
                                    Few-Shot
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Few-Shot/">
                        <span class="chip bg-color">Few-Shot</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-08-08/LLM/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-71fc6b270c5b319f2b5cb5d4c1013b21.jpg" class="responsive-img" alt="LLM">
                        
                        <span class="card-title">LLM</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            LLM æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-08-08  GeRe Towards Efficient Anti-Forgetting in Continual Learning of LLM via   General Samples Replay
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-08-08
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/LLM/" class="post-category">
                                    LLM
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/LLM/">
                        <span class="chip bg-color">LLM</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">32251.6k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
