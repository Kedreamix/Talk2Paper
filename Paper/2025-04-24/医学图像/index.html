<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="医学图像">
    <meta name="description" content="医学图像 方向最新论文已更新，请持续关注 Update in 2025-04-24  Rotational ultrasound and photoacoustic tomography of the human body">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>医学图像 | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loader页面消失采用渐隐的方式*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logo出现动画 */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//使用渐隐的方法淡出loading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//强制显示loading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">嘘~  正在从服务器偷取页面 . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>首页</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>标签</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>分类</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>归档</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="搜索" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="深色/浅色模式" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			首页
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			标签
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			分类
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			归档
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://pica.zhimg.com/v2-df60ede95705bc7bb12f8536a0c30ccb.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">医学图像</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/">
                                <span class="chip bg-color">医学图像</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/" class="post-category">
                                医学图像
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2025-04-24
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>更新日期:&nbsp;&nbsp;
                    2025-05-14
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp;
                    9.1k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp;
                    37 分
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>阅读次数:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>⚠️ 以下所有内容总结都来自于 大语言模型的能力，如有错误，仅供参考，谨慎使用<br>🔴 请注意：千万不要用于严肃的学术场景，只能用于论文阅读前的初筛！<br>💗 如果您觉得我们的项目对您有帮助 <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ，还请您给我们一些鼓励！⭐️ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFace免费体验</a></p>
</blockquote>
<h1 id="2025-04-24-更新"><a href="#2025-04-24-更新" class="headerlink" title="2025-04-24 更新"></a>2025-04-24 更新</h1><h2 id="Rotational-ultrasound-and-photoacoustic-tomography-of-the-human-body"><a href="#Rotational-ultrasound-and-photoacoustic-tomography-of-the-human-body" class="headerlink" title="Rotational ultrasound and photoacoustic tomography of the human body"></a>Rotational ultrasound and photoacoustic tomography of the human body</h2><p><strong>Authors:Yang Zhang, Shuai Na, Jonathan J. Russin, Karteekeya Sastry, Li Lin, Junfu Zheng, Yilin Luo, Xin Tong, Yujin An, Peng Hu, Konstantin Maslov, Tze-Woei Tan, Charles Y. Liu, Lihong V. Wang</strong></p>
<p>Imaging the human body’s morphological and angiographic information is essential for diagnosing, monitoring, and treating medical conditions. Ultrasonography performs the morphological assessment of the soft tissue based on acoustic impedance variations, whereas photoacoustic tomography (PAT) can visualize blood vessels based on intrinsic hemoglobin absorption. Three-dimensional (3D) panoramic imaging of the vasculature is generally not practical in conventional ultrasonography with limited field-of-view (FOV) probes, and PAT does not provide sufficient scattering-based soft tissue morphological contrast. Complementing each other, fast panoramic rotational ultrasound tomography (RUST) and PAT are integrated for hybrid rotational ultrasound and photoacoustic tomography (RUS-PAT), which obtains 3D ultrasound structural and PAT angiographic images of the human body quasi-simultaneously. The RUST functionality is achieved in a cost-effective manner using a single-element ultrasonic transducer for ultrasound transmission and rotating arc-shaped arrays for 3D panoramic detection. RUST is superior to conventional ultrasonography, which either has a limited FOV with a linear array or is high-cost with a hemispherical array that requires both transmission and receiving. By switching the acoustic source to a light source, the system is conveniently converted to PAT mode to acquire angiographic images in the same region. Using RUS-PAT, we have successfully imaged the human head, breast, hand, and foot with a 10 cm diameter FOV, submillimeter isotropic resolution, and 10 s imaging time for each modality. The 3D RUS-PAT is a powerful tool for high-speed, 3D, dual-contrast imaging of the human body with potential for rapid clinical translation. </p>
<blockquote>
<p>在诊断、监控和治疗医疗状况时，对人体形态和血管造影信息的成像至关重要。超声波检查基于声阻抗变化对软组织进行形态评估，而光声断层扫描（PAT）则能基于血红蛋白的自然吸收来可视化血管。在具有有限视野（FOV）探针的传统超声波检查中，通常无法实现血管的的三维（3D）全景成像，而PAT则不能提供足够的基于散射的软组织形态对比。互为补充的是，快速全景旋转超声断层扫描（RUST）和PAT被整合到混合旋转超声和光声断层扫描（RUS-PAT）中，其几乎同时获得人体的3D超声结构和PAT血管造影图像。通过采用单元素超声换能器进行超声传输和旋转弧形阵列进行3D全景检测的方式，以成本效益的方式实现了RUST功能。RUST优于传统超声波检查，后者要么具有线性阵列的有限视野，要么具有球形阵列的高成本，需要同时传输和接收。通过将声源切换为光源，系统可轻松转换为PAT模式，以在同一区域获取血管造影图像。使用RUS-PAT，我们已成功地对人体的头部、乳房、手和脚进行了成像，具有直径为10厘米的视野、亚毫米级等距分辨率和每种模式的10秒成像时间。三维RUS-PAT是一种强大的工具，用于高速、三维、双对比度的人体成像，具有快速转化为临床应用的潜力。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.16036v1">PDF</a> </p>
<p><strong>Summary</strong><br>    融合超声旋转成像与光声断层扫描技术，实现人体三维超声结构和光声血管造影图像准同步获取，提高诊断、监测和治疗效果。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>医学成像在诊断、监测和治疗过程中具有重要作用，包括形态学评估和血管可视化。</li>
<li>超声和光声成像技术各具优势，但也存在局限性。</li>
<li>融合旋转超声断层扫描（RUST）和光声断层扫描（PAT）技术，形成混合旋转超声和光声断层扫描（RUS-PAT）。</li>
<li>RUST技术采用单元素超声换能器实现低成本、高效的三维全景检测。</li>
<li>RUS-PAT能同时获取人体三维超声结构和光声血管造影图像，提高诊断准确性。</li>
<li>该技术在人体头部、乳房、手和足部成像中得到成功应用。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.16036">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-d57cd7f8f68865a65dc26f9976a56c62.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f5c9edf5ea8efbf4dcd4fa2bb26d13bb.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="Benchmarking-the-Reproducibility-of-Brain-MRI-Segmentation-Across-Scanners-and-Time"><a href="#Benchmarking-the-Reproducibility-of-Brain-MRI-Segmentation-Across-Scanners-and-Time" class="headerlink" title="Benchmarking the Reproducibility of Brain MRI Segmentation Across   Scanners and Time"></a>Benchmarking the Reproducibility of Brain MRI Segmentation Across   Scanners and Time</h2><p><strong>Authors:Ekaterina Kondrateva, Sandzhi Barg, Mikhail Vasiliev</strong></p>
<p>Accurate and reproducible brain morphometry from structural MRI is critical for monitoring neuroanatomical changes across time and across imaging domains. Although deep learning has accelerated segmentation workflows, scanner-induced variability and reproducibility limitations remain-especially in longitudinal and multi-site settings. In this study, we benchmark two modern segmentation pipelines, FastSurfer and SynthSeg, both integrated into FreeSurfer, one of the most widely adopted tools in neuroimaging.   Using two complementary datasets - a 17-year longitudinal cohort (SIMON) and a 9-site test-retest cohort (SRPBS)-we quantify inter-scan segmentation variability using Dice coefficient, Surface Dice, Hausdorff Distance (HD95), and Mean Absolute Percentage Error (MAPE). Our results reveal up to 7-8% volume variation in small subcortical structures such as the amygdala and ventral diencephalon, even under controlled test-retest conditions. This raises a key question: is it feasible to detect subtle longitudinal changes on the order of 5-10% in pea-sized brain regions, given the magnitude of domain-induced morphometric noise?   We further analyze the effects of registration templates and interpolation modes, and propose surface-based quality filtering to improve segmentation reliability. This study provides a reproducible benchmark for morphometric reproducibility and emphasizes the need for harmonization strategies in real-world neuroimaging studies.   Code and figures: <a target="_blank" rel="noopener" href="https://github.com/kondratevakate/brain-mri-segmentation">https://github.com/kondratevakate/brain-mri-segmentation</a> </p>
<blockquote>
<p>从结构磁共振成像（MRI）获取准确且可重复的脑形态测量数据，对于监测随时间以及不同成像领域的神经解剖学变化至关重要。尽管深度学习加速了分割工作流程，但扫描仪引起的可变性和可重复性限制仍然存在，尤其是在纵向和多站点设置中。在这项研究中，我们基准测试了两种集成到神经影像领域最广泛采用工具之一FreeSurfer中的现代分割管道，即FastSurfer和SynthSeg。我们使用两个互补数据集——一个17年的纵向队列（SIMON）和一个9个站点的测试-再测试队列（SRPBS）——通过Dice系数、表面Dice、Hausdorff距离（HD95）和平均绝对百分比误差（MAPE）来量化扫描间分割可变性的大小。我们的结果揭示，即使在受控的测试-再测试条件下，杏仁核和腹侧丘脑等小皮下结构的体积变化率仍高达7-8%。这引发了一个关键问题：考虑到领域引起的形态学噪声的幅度，检测豌豆大小脑区域中5-10%的细微纵向变化是否可行？我们进一步分析了注册模板和插值模式的影响，并提出基于表面的质量过滤方法来提高分割可靠性。这项研究提供了一个可重复的基准测试，用于衡量形态测量的可重复性，并强调在真实世界神经成像研究中需要协调策略。相关代码和图表请访问：<a target="_blank" rel="noopener" href="https://github.com/kondratevakate/brain-mri-segmentation">https://github.com/kondratevakate/brain-mri-segmentation</a></p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.15931v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>本文对比评估了FastSurfer和SynthSeg两个基于深度学习的分割管道在结构MRI中的表现，使用了两个数据集进行量化分析。研究发现即使在控制条件下，小亚皮层结构的体积变化率仍高达7-8%。研究强调了提高分割可靠性的必要性，并提出了基于表面的质量过滤方法。此研究为形态测量学的可重复性提供了可复制的基准线，并强调了现实世界中神经影像研究需要统一策略的重要性。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>深度学习方法在脑MRI分割中的应用加速了神经影像分析，但仍存在扫描仪引起的变异性和可重复性问题。</li>
<li>使用SIMON和SRPBS两个数据集评估了FastSurfer和SynthSeg两个分割管道的表现。</li>
<li>小亚皮层结构的体积变化率高达7-8%，这引发了对检测细微变化的可行性的疑问。</li>
<li>形态测量噪声对检测脑区细微变化的影响显著，需要更精细的影像分析技术。</li>
<li>研究提出了基于表面的质量过滤方法来提高分割可靠性。</li>
<li>此研究为形态测量学的可重复性提供了基准线，强调了统一策略在神经影像研究中的重要性。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.15931">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-ab577dc08c6e8b7e4d585ba6160e63b5.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-5336b35c2d1c5da52c06df09a72eeebe.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-98a8db63920df04e1bc27dc4fcd8c62f.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-00f82efee06d0e3c59af1b4d174025f3.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-df60ede95705bc7bb12f8536a0c30ccb.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-5a87b173110c3bd1d36717d171210ea2.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="Meta-Entity-Driven-Triplet-Mining-for-Aligning-Medical-Vision-Language-Models"><a href="#Meta-Entity-Driven-Triplet-Mining-for-Aligning-Medical-Vision-Language-Models" class="headerlink" title="Meta-Entity Driven Triplet Mining for Aligning Medical Vision-Language   Models"></a>Meta-Entity Driven Triplet Mining for Aligning Medical Vision-Language   Models</h2><p><strong>Authors:Saban Ozturk, Melih B. Yilmaz, Muti Kara, M. Talat Yavuz, Aykut Koç, Tolga Çukur</strong></p>
<p>Diagnostic imaging relies on interpreting both images and radiology reports, but the growing data volumes place significant pressure on medical experts, yielding increased errors and workflow backlogs. Medical vision-language models (med-VLMs) have emerged as a powerful framework to efficiently process multimodal imaging data, particularly in chest X-ray (CXR) evaluations, albeit their performance hinges on how well image and text representations are aligned. Existing alignment methods, predominantly based on contrastive learning, prioritize separation between disease classes over segregation of fine-grained pathology attributes like location, size or severity, leading to suboptimal representations. Here, we propose MedTrim (Meta-entity-driven Triplet mining), a novel method that enhances image-text alignment through multimodal triplet learning synergistically guided by disease class as well as adjectival and directional pathology descriptors. Unlike common alignment methods that separate broad disease classes, MedTrim leverages structured meta-entity information to preserve subtle but clinically significant intra-class variations. For this purpose, we first introduce an ontology-based entity recognition module that extracts pathology-specific meta-entities from CXR reports, as annotations on pathology attributes are rare in public datasets. For refined sample selection in triplet mining, we then introduce a novel score function that captures an aggregate measure of inter-sample similarity based on disease classes and adjectival&#x2F;directional descriptors. Lastly, we introduce a multimodal triplet alignment objective for explicit within- and cross-modal alignment between samples sharing detailed pathology characteristics. Our demonstrations indicate that MedTrim improves performance in downstream retrieval and classification tasks compared to state-of-the-art alignment methods. </p>
<blockquote>
<p>诊断成像依赖于对图像和放射学报告的解释，但日益增长的数据量给医学专家带来了巨大的压力，导致了误差增加和工作流程积压。医疗视觉语言模型（med-VLM）作为一个强大的框架，能够有效地处理多模态成像数据，特别是在胸部X射线（CXR）评估中表现出色。然而，其性能的好坏取决于图像和文本表示的对齐程度。现有的对齐方法主要基于对比学习，更侧重于疾病类别之间的区分，而非细微的病理属性（如位置、大小或严重程度）的分离，导致表示不佳。在这里，我们提出了MedTrim（基于元实体驱动的三元组挖掘），这是一种通过多模态三元组学习增强图像文本对齐的新方法，该方法由疾病类别以及形容词和方向性病理描述符协同引导。与常见的仅区分宽泛疾病类别的对齐方法不同，MedTrim利用结构化的元实体信息来保留细微但临床上重要的类内变化。为此，我们首先引入了一个基于本体论的实体识别模块，该模块从CXR报告中提取病理特定的元实体，因为公共数据集中关于病理属性的注释很少见。为了进行精细的样本选择进行三元组挖掘，然后我们引入了一个新的评分函数，该函数基于疾病类别和形容词&#x2F;方向性描述符来捕获样本间相似性的综合度量。最后，我们引入了多模态三元组对齐目标，用于在具有详细病理特征的样本之间进行明确的内部和跨模态对齐。我们的演示表明，与最新的对齐方法相比，MedTrim在下游检索和分类任务中的性能有所提高。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.15929v1">PDF</a> 18 pages, 7 figures, 6 tables</p>
<p><strong>摘要</strong></p>
<p>本文关注医疗影像诊断中图像与报告解读的压力问题，提出一种名为MedTrim的新型医疗视觉语言模型（med-VLMs），用于增强图像与文本的对应。该模型通过多模态三元组学习，不仅根据疾病类别，还根据形容词和方向性病理描述进行协同引导，从而提高了图像与文本的匹配度。MedTrim采用基于本体的实体识别模块，从胸X光报告中提取病理特异性元实体，为精细化样本选择引入新型评分函数，以捕捉基于疾病类别和形容词&#x2F;方向性描述符的样本间相似性。最后，通过下游检索和分类任务演示了MedTrim相较于当前主流对齐方法的性能提升。</p>
<p><strong>关键见解</strong></p>
<ol>
<li>医疗视觉语言模型（med-VLMs）能有效处理多模态成像数据，特别是在胸X光评价中。</li>
<li>现有对齐方法主要基于对比学习，更注重疾病类别的分离，忽视了如位置、大小、严重程度等精细病理属性的分离，导致表示不佳。</li>
<li>MedTrim通过多模态三元组学习，以疾病类别和形容词及方向性病理描述为引导，增强了图像与文本的匹配。</li>
<li>MedTrim采用基于本体的实体识别模块，从胸X光报告中提取病理特异性元实体，以保留公共数据集中罕见的病理属性注释。</li>
<li>为实现精细化样本选择，MedTrim引入了一种新型评分函数，该函数基于疾病类别和形容词&#x2F;方向性描述符来捕捉样本间的相似性。</li>
<li>MedTrim通过明确的内部和跨模态对齐目标，优化了共享详细病理特征样本的对齐。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.15929">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-875d0f400c8bfba5f742d395129bc4f5.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a2f84989aa64125a6a8ae84fab8dab60.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-1c73b9a2a5b436118f628ec719c098d7.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="Diffuse-X-ray-emission-in-M51-a-hierarchical-Bayesian-spatially-resolved-spectral-analysis"><a href="#Diffuse-X-ray-emission-in-M51-a-hierarchical-Bayesian-spatially-resolved-spectral-analysis" class="headerlink" title="Diffuse X-ray emission in M51: a hierarchical Bayesian   spatially-resolved spectral analysis"></a>Diffuse X-ray emission in M51: a hierarchical Bayesian   spatially-resolved spectral analysis</h2><p><strong>Authors:Luan Luan, Q. Daniel Wang</strong></p>
<p>X-ray observations can be used to effectively probe the galactic ecosystem, particularly its hot and energetic components. However, existing X-ray studies of nearby star-forming galaxies are limited by insufficient data statistics and a lack of suitable spectral modeling to account for X-ray emission and absorption geometry. We present results from an X-ray spectral study of M51 using 1.3-Ms Chandra data, the most extensive for such a galaxy. This allows the extraction of diffuse X-ray emission spectra from spiral arm phase-dependent regions using a logarithmic spiral coordinate system. A hierarchical Bayesian approach analyzes these spectra, testing models from simple 1-T hot plasma to those including distributed hot plasma and X-ray-absorbing cool gas. We recommend a model fitting the spectra well, featuring a galactic corona with a lognormal temperature distribution and a disk with mixed X-ray emissions and absorption. In this model, only half of the coronal emission is subject to internal absorption. The best-fit absorbing gas column density is roughly twice that inferred from optical extinction of stellar light. The temperature distribution shows a mean temperature of $\sim 0.1$ keV and an average one-dex dispersion that is enhanced on the spiral arms. The corona’s radiative cooling might balance the mechanical energy input from stellar feedback. These results highlight the effectiveness of X-ray mapping of the corona and cool gas in spiral galaxies. </p>
<blockquote>
<p>X射线观测可以有效地探测星系生态系统，特别是其高温和高能成分。然而，邻近星系的X射线研究受限于数据统计不足和缺乏合适的光谱模型来解释X射线的发射和吸收几何结构。我们展示了使用最详尽的1.3Ms钱德拉数据对M51进行的X射线光谱研究的结果。这允许使用对数螺旋坐标系从螺旋臂相位依赖的区域中提取出漫射X射线发射光谱。通过分层贝叶斯方法分析这些光谱，测试了从简单的1T热等离子体模型到包含分布式热等离子体和X射线吸收冷气体的模型。我们推荐一个很好地拟合光谱的模型，该模型具有对数正态分布温度的星系冕和混合X射线发射和吸收的磁盘。在此模型中，只有一半的冕发射受到内部吸收的影响。最佳拟合的吸收气体柱密度大约是星光光学消光推断值的两倍。温度分布显示出平均温度为约0.1千电子伏特，平均一标准差的分散度在螺旋臂上有所增强。星系的冕的辐射冷却可能平衡来自恒星反馈的机械能量输入。这些结果强调了X射线映射在星系螺旋臂上的冕和冷气体的有效性。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.15641v1">PDF</a> 18 pages, 8 figures</p>
<p><strong>Summary</strong></p>
<p>X射线观测可有效探测星系生态系统，特别是其热能和活跃成分。然而，邻近星系形成区的X射线研究受限于数据不足和缺乏合适的光谱模型。本研究使用Chandra数据对M51进行大规模的X射线光谱研究，采用对数螺旋坐标系提取不同螺旋臂区域的弥散X射线发射光谱。通过分层贝叶斯方法分析这些光谱，测试从简单的单温等离子体模型到包含分布式热等离子体和X射线吸收冷气体的模型。推荐一个拟合光谱良好的模型，包含具有对数正态分布温度的星系冕和混合X射线发射和吸收的磁盘。在这个模型中，只有一半的冕发射受到内部吸收影响。最佳拟合吸收气体柱密度大约是星光光学消光所推断的两倍。温度分布显示平均温度为~0.1keV，平均一标准偏差分散度在螺旋臂上增强。星系的冕辐射冷却可能平衡来自恒星反馈的机械能量输入。这些结果强调了X射线映射在螺旋星系中探测冕和冷气体的有效性。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>X射线观测是探测星系生态系统，特别是其热能和活跃成分的有效手段。</li>
<li>邻近星系的X射线研究受限于数据不足和光谱模型缺乏。</li>
<li>对M51的X射线光谱研究表明，其光谱可以通过包含星系冕和混合X射线发射与吸收的模型来很好地拟合。</li>
<li>在推荐的模型中，只有一半的星系冕发射受到内部吸收影响。</li>
<li>最佳拟合的吸收气体柱密度大约是星光光学消光的两倍。</li>
<li>温度分布显示平均温度为~0.1keV，并且温度分散在星系螺旋臂上有所增加。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.15641">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-d19c202052421300c4fe1c1c0abbc5e0.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-5ead588d7a8c3dad1509c654a90a0ae8.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-d7f6e0f620bedc7c3f2d740283e46f3b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-8ca350869dd8e1f2e31382b0de936c6f.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-dd95b1c5909e85ccba68a2a87348d912.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-2c9ca034c7f792c6286efde770fe63a3.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="Designing-Optimal-Distorted-Octahedra-Superlattices-for-Strong-Topological-Hall-Effect"><a href="#Designing-Optimal-Distorted-Octahedra-Superlattices-for-Strong-Topological-Hall-Effect" class="headerlink" title="Designing Optimal Distorted-Octahedra Superlattices for Strong   Topological Hall Effect"></a>Designing Optimal Distorted-Octahedra Superlattices for Strong   Topological Hall Effect</h2><p><strong>Authors:Yiyan Fan, Qinghua Zhang, Jingdi Lu, Chuanrui Huo, Tianyang Wang, Qiao Jin, Ting Cui, Qianying Wang, Dongke Rong, Shiqing Deng, Lingfei Wang, Kuijuan Jin, Jun Chen, Er-Jia Guo</strong></p>
<p>Topologically protected spin states hold great promise for applications in next generation of memory circuits and spintronic devices. These intriguing textures typically emerge in bulk materials or heterostructures with broken inversion symmetry, accompanied by an enhanced Dzyaloshinskii-Moriya interaction (DMI). In this study, we successfully induced the topological Hall effect (THE) in atomically designed (DyScO3)n&#x2F;(SrRuO3)n (DnSn) superlattices over a significant range of temperatures (10<del>120K) and thicknesses (16</del>40nm). Using magnetic force microscopy (MFM), we observed the formation and stability of magnetic domains, such as topological skyrmions. By precisely controlling the interlayer thickness (n) and biaxial strain, we elucidated the mechanisms underlying the modulation and induction of magnetic topological states. Supporting evidence was provided by scanning transmission electron microscopy (STEM) and X-ray absorption spectroscopy (XAS), thereby lending further credence to our conclusions. These heterostructures offer a universal method for exploring topological phenomena driven by distorted octahedra, while enhancing the integrability and addressability of topologically protected functional devices. </p>
<blockquote>
<p>拓扑保护的自旋态在下一代内存电路和自旋电子器件的应用中显示出巨大的潜力。这些有趣的纹理通常出现在具有破坏反演对称性的体材料或异质结构中，伴随着增强的Dzyaloshinskii-Moriya相互作用（DMI）。在这项研究中，我们在原子设计的（DyScO3）n&#x2F;（SrRuO3）n（DnSn）超晶格中，成功诱导了温度范围宽（10~120K）和厚度范围宽（16~40nm）拓扑霍尔效应（THE）。利用磁力显微镜（MFM），我们观察到磁畴的形成和稳定性，如拓扑斯基米翁等。通过精确控制夹层厚度（n）和双轴应变，我们阐明了磁拓扑态调制和诱导的机理。扫描透射电子显微镜（STEM）和X射线吸收光谱（XAS）提供了支持证据，进一步证实了我们的结论。这些异质结构提供了一种探索由扭曲八面体驱动拓扑现象的通用方法，同时提高了拓扑保护功能器件的集成度和可寻址性。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.15563v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>本文研究了拓扑保护的自旋态在下一代内存电路和自旋电子器件中的应用前景。通过设计（DyScO3）n&#x2F;（SrRuO3）n（DnSn）超晶格，成功在较宽的温度范围（10<del>120K）和厚度范围（16</del>40nm）内诱导出拓扑霍尔效应。通过磁力显微镜观察到磁畴的形成和稳定性，如拓扑斯基米翁。通过精确控制层间厚度和双向应变，阐明了磁拓扑态的调制和诱导机制。扫描透射电子显微镜和X射线吸收光谱提供了支持证据，进一步证实了结论。这些异质结构为探索由扭曲八面体驱动拓扑现象提供了一种通用方法，同时提高了拓扑保护功能器件的集成度和可寻址性。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>拓扑保护的自旋态在下一代内存电路和自旋电子器件中有广阔应用前景。</li>
<li>设计了（DyScO3）n&#x2F;（SrRuO3）n超晶格，成功在宽温度范围和厚度范围内诱导出拓扑霍尔效应。</li>
<li>通过磁力显微镜观察到磁畴的形成和稳定性，如拓扑斯基米翁。</li>
<li>通过控制层间厚度和双向应变，阐明了磁拓扑态的调制和诱导机制。</li>
<li>扫描透射电子显微镜和X射线吸收光谱为研究结果提供了支持证据。</li>
<li>异质结构提供了一种探索由扭曲八面体驱动的拓扑现象的通用方法。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.15563">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-82feca6db37de3dcbcc044df4e9535c1.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="Automatically-Detecting-Numerical-Instability-in-Machine-Learning-Applications-via-Soft-Assertions"><a href="#Automatically-Detecting-Numerical-Instability-in-Machine-Learning-Applications-via-Soft-Assertions" class="headerlink" title="Automatically Detecting Numerical Instability in Machine Learning   Applications via Soft Assertions"></a>Automatically Detecting Numerical Instability in Machine Learning   Applications via Soft Assertions</h2><p><strong>Authors:Shaila Sharmin, Anwar Hossain Zahid, Subhankar Bhattacharjee, Chiamaka Igwilo, Miryung Kim, Wei Le</strong></p>
<p>Machine learning (ML) applications have become an integral part of our lives. ML applications extensively use floating-point computation and involve very large&#x2F;small numbers; thus, maintaining the numerical stability of such complex computations remains an important challenge. Numerical bugs can lead to system crashes, incorrect output, and wasted computing resources. In this paper, we introduce a novel idea, namely soft assertions (SA), to encode safety&#x2F;error conditions for the places where numerical instability can occur. A soft assertion is an ML model automatically trained using the dataset obtained during unit testing of unstable functions. Given the values at the unstable function in an ML application, a soft assertion reports how to change these values in order to trigger the instability. We then use the output of soft assertions as signals to effectively mutate inputs to trigger numerical instability in ML applications. In the evaluation, we used the GRIST benchmark, a total of 79 programs, as well as 15 real-world ML applications from GitHub. We compared our tool with 5 state-of-the-art (SOTA) fuzzers. We found all the GRIST bugs and outperformed the baselines. We found 13 numerical bugs in real-world code, one of which had already been confirmed by the GitHub developers. While the baselines mostly found the bugs that report NaN and INF, our tool \tool found numerical bugs with incorrect output. We showed one case where the Tumor Detection Model, trained on Brain MRI images, should have predicted “tumor”, but instead, it incorrectly predicted “no tumor” due to the numerical bugs. Our replication package is located at <a target="_blank" rel="noopener" href="https://figshare.com/s/6528d21ccd28bea94c32">https://figshare.com/s/6528d21ccd28bea94c32</a>. </p>
<blockquote>
<p>机器学习（ML）应用已成为我们生活中不可或缺的一部分。机器学习应用广泛地使用浮点计算并涉及非常大的数字或非常小的数字；因此，保持此类复杂计算的数值稳定性仍然是一个重要的挑战。数值错误可能导致系统崩溃、输出错误和计算资源浪费。在本文中，我们介绍了一种新的概念，即软断言（SA），以编码可能在数值不稳定发生的地方的安全&#x2F;错误条件。软断言是一种使用在不稳定函数单元测试期间获得的数据集自动训练的机器学习模型。给定机器学习应用中不稳定函数的值，软断言会报告如何改变这些值以触发不稳定。然后我们将软断言的输出用作信号，以有效地修改输入，从而触发机器学习应用中的数值不稳定。在评估中，我们使用了包含总共79个程序的GRIST基准测试以及来自GitHub的15个真实世界的机器学习应用。我们将我们的工具与5种最新（SOTA）模糊测试工具进行了比较。我们发现所有GRIST错误并超越了基线。我们在真实世界的代码中发现了13个数值错误，其中一个是GitHub开发人员已经确认的错误。虽然基线测试大多找到了报告NaN和INF的错误，但我们的工具发现了具有错误输出的数值错误。我们展示了一个案例，即基于脑MRI图像训练的肿瘤检测模型应该预测为“肿瘤”，但由于数值错误，它错误地预测为“无肿瘤”。我们的复制包位于<a target="_blank" rel="noopener" href="https://figshare.com/s/6528d21ccd28bea94c32%E3%80%82">https://figshare.com/s/6528d21ccd28bea94c32。</a></p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.15507v1">PDF</a> 22 pages, 5 figures. Accepted at FSE 2025</p>
<p><strong>摘要</strong></p>
<p>本文提出了一种基于机器学习模型的新型安全机制——软断言（SA），用于解决机器学习应用中数值不稳定的问题。软断言通过自动训练数据集来编码安全&#x2F;错误条件，预测可能导致数值不稳定性的输入值变化。通过利用软断言的输出作为信号，可以有效突变输入以触发机器学习应用的数值不稳定。实验评估显示，该工具在GRIST基准测试和GitHub上的真实世界机器学习应用中均表现出优异性能，发现了多个数值错误。其中一例为肿瘤检测模型因数值错误导致预测错误。具体表现为，基于脑MRI图像的肿瘤检测模型本应预测为“肿瘤”，但结果却是“无肿瘤”。此方法的复现包可通过<a target="_blank" rel="noopener" href="https://figshare.com/s/6528d21ccd28bea94c32%E8%8E%B7%E5%8F%96%E3%80%82">https://figshare.com/s/6528d21ccd28bea94c32获取。</a></p>
<p><strong>关键见解</strong></p>
<ol>
<li>引入软断言（SA）新概念，基于机器学习模型自动编码安全&#x2F;错误条件，应对机器学习应用中的数值不稳定挑战。</li>
<li>软断言可预测并报告可能导致数值不稳定性的输入值变化。</li>
<li>利用软断言的输出作为信号，能有效突变输入，触发机器学习应用的数值不稳定。</li>
<li>在GRIST基准测试和GitHub真实世界应用中的实验评估显示，该方法在发现数值错误方面表现优异。</li>
<li>所提出方法在一例肿瘤检测模型预测错误中体现实用价值。该模型因数值错误导致将“肿瘤”误判为“无肿瘤”。</li>
<li>此方法的复现包可通过特定链接获取，便于研究使用和进一步验证。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.15507">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-9ee2ae9f3a74d0ad8f3a9ef34cf035e0.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-3f0e402c97f01dfe4b4dd7bf5c5e6045.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="Learned-Primal-Dual-Splitting-for-Self-Supervised-Noise-Adaptive-MRI-Reconstruction"><a href="#Learned-Primal-Dual-Splitting-for-Self-Supervised-Noise-Adaptive-MRI-Reconstruction" class="headerlink" title="Learned Primal Dual Splitting for Self-Supervised Noise-Adaptive MRI   Reconstruction"></a>Learned Primal Dual Splitting for Self-Supervised Noise-Adaptive MRI   Reconstruction</h2><p><strong>Authors:Nikola Janjusevic, Amirhoussein Khalilian-Gourtani, Yao Wang, Li Feng</strong></p>
<p>Magnetic resonance imaging (MRI) reconstruction has largely been dominated by deep neural networks (DNN); however, many state-of-the-art architectures use black-box structures, which hinder interpretability and improvement. Here, we propose an interpretable DNN architecture for self-supervised MRI reconstruction and denoising by directly parameterizing and learning the classical primal-dual splitting, dubbed LPDSNet. This splitting algorithm allows us to decouple the observation model from the signal prior. Experimentally, we show other interpretable architectures without this decoupling property exhibit failure in the self-supervised learning regime. We report state-of-the-art self-supervised joint MRI reconstruction and denoising performance and novel noise-level generalization capabilities, where in contrast black-box networks fail to generalize. </p>
<blockquote>
<p>磁共振成像（MRI）重建主要由深度神经网络（DNN）主导；然而，许多最先进的架构使用黑箱结构，这阻碍了可解释性和改进。在这里，我们提出了一种可解释的深度神经网络架构，用于自监督MRI重建和去噪，通过直接参数化和学习经典的原始-对偶分裂算法，被称为LPDSNet。这种分裂算法使我们能够将观测模型与信号先验解耦。实验表明，其他没有这种解耦属性的可解释架构在自监督学习状态下会表现出失败。我们报告了最先进的自监督联合MRI重建和去噪性能以及新型噪声水平泛化能力，相比之下，黑箱网络无法泛化。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.15390v1">PDF</a> 4 pages, 3 figures, 1 table</p>
<p><strong>Summary</strong><br>     该文本提出了一种利用经典的原位双重分割技术（primal-dual splitting）进行自监督MRI重建和去噪的可解释深度神经网络架构LPDSNet。该架构实现了观察模型和信号先验的解耦，并在自监督学习环境下展示了优越的性能。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>深度神经网络在MRI重建中占主导地位，但许多先进的架构使用黑盒结构，阻碍了可解释性和改进。</li>
<li>提出了一种可解释的DNN架构LPDSNet，用于自监督MRI重建和去噪。</li>
<li>LPDSNet通过直接参数化和学习经典的原位双重分割算法，实现了观察模型和信号先验的解耦。</li>
<li>实验表明，其他没有这种解耦属性的可解释架构在自监督学习环境下会表现出失败。</li>
<li>LPDSNet达到了先进的自监督联合MRI重建和去噪性能。</li>
<li>LPDSNet具有噪声水平泛化能力，而黑盒网络则无法泛化。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.15390">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-b7a0904fe7bc9e32ecc853c4ed04a8ae.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-4bbb6edd0d1b124c8260e1ae156fda15.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-dc9044e0b4a1cccbcb272ec7d47f7770.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-1f5dd6f84a8b03e3814c1a6f498c64ac.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="Cross-domain-Fiber-Cluster-Shape-Analysis-for-Language-Performance-Cognitive-Score-Prediction"><a href="#Cross-domain-Fiber-Cluster-Shape-Analysis-for-Language-Performance-Cognitive-Score-Prediction" class="headerlink" title="Cross-domain Fiber Cluster Shape Analysis for Language Performance   Cognitive Score Prediction"></a>Cross-domain Fiber Cluster Shape Analysis for Language Performance   Cognitive Score Prediction</h2><p><strong>Authors:Yui Lo, Yuqian Chen, Dongnan Liu, Wan Liu, Leo Zekelman, Fan Zhang, Yogesh Rathi, Nikos Makris, Alexandra J. Golby, Weidong Cai, Lauren J. O’Donnell</strong></p>
<p>Shape plays an important role in computer graphics, offering informative features to convey an object’s morphology and functionality. Shape analysis in brain imaging can help interpret structural and functionality correlations of the human brain. In this work, we investigate the shape of the brain’s 3D white matter connections and its potential predictive relationship to human cognitive function. We reconstruct brain connections as sequences of 3D points using diffusion magnetic resonance imaging (dMRI) tractography. To describe each connection, we extract 12 shape descriptors in addition to traditional dMRI connectivity and tissue microstructure features. We introduce a novel framework, Shape–fused Fiber Cluster Transformer (SFFormer), that leverages a multi-head cross-attention feature fusion module to predict subject-specific language performance based on dMRI tractography. We assess the performance of the method on a large dataset including 1065 healthy young adults. The results demonstrate that both the transformer-based SFFormer model and its inter&#x2F;intra feature fusion with shape, microstructure, and connectivity are informative, and together, they improve the prediction of subject-specific language performance scores. Overall, our results indicate that the shape of the brain’s connections is predictive of human language function. </p>
<blockquote>
<p>形状在计算机图形学中扮演着重要角色，它能够提供信息特征，以传达物体的形态和功能。脑成像中的形状分析有助于解释人脑的结构和功能关联。在这项工作中，我们研究了大脑3D白质连接的形状及其与人类认知功能之间的潜在预测关系。我们利用扩散磁共振成像（dMRI）追踪技术重建了大脑连接的3D点序列。为了描述每个连接，我们提取了12个形状描述符，并保留了传统的dMRI连通性和组织微观结构特征。我们引入了一种新型框架——Shape-fused Fiber Cluster Transformer（SFFormer），它利用多头交叉注意力特征融合模块，基于dMRI追踪技术预测特定个体的语言表现。我们在包含1065名健康年轻人的大型数据集上评估了该方法的效果。结果表明，基于transformer的SFFormer模型及其与形状、微观结构和连通性的内部和外部特征融合均具有一定的信息性，它们共同提高了特定个体语言表现分数的预测能力。总体而言，我们的结果表明，大脑连接的形状可以预测人类的语言功能。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2403.19001v4">PDF</a> This paper has been accepted for presentation at The 27th Intl. Conf.   on Medical Image Computing and Computer Assisted Intervention (MICCAI 2024)   Workshop on Computational Diffusion MRI (CDMRI). 11 pages, 2 figures</p>
<p><strong>Summary</strong></p>
<p>本文研究大脑3D白质连接的形状，并探索其与人类认知功能之间的潜在预测关系。通过扩散磁共振成像（dMRI）追踪技术重建大脑连接，提取形状描述符并结合传统dMRI连接和脑组织微观结构特征。引入新型框架Shape–fused Fiber Cluster Transformer（SFFormer），利用多头交叉注意力特征融合模块，基于dMRI追踪技术预测个体语言性能。在包含1065名健康年轻人的大型数据集上评估方法性能，结果表明SFFormer模型及其与形状、微观结构和连接性的内外特征融合对预测个体语言性能具有信息价值。总之，大脑连接形状对人类语言功能具有预测作用。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>研究大脑3D白质连接形状在解读人类认知功能中的作用。</li>
<li>利用扩散磁共振成像（dMRI）技术重建大脑连接。</li>
<li>提取12个形状描述符描述每个大脑连接。</li>
<li>引入新型框架SFFormer，结合形状、微观结构和连接性特征，预测个体语言性能。</li>
<li>在大型数据集上评估方法性能，包括1065名健康年轻人。</li>
<li>SFFormer模型及其特征融合对预测个体语言性能具有信息价值。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2403.19001">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-54ff6c8b4861196747a5ce63b5059ee8.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-deb80c263447c3ba7ad3cf5f7dde9f82.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-6b243edb1d7aa04b35249bf75d178f14.jpg" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="3DGR-CT-Sparse-View-CT-Reconstruction-with-a-3D-Gaussian-Representation"><a href="#3DGR-CT-Sparse-View-CT-Reconstruction-with-a-3D-Gaussian-Representation" class="headerlink" title="3DGR-CT: Sparse-View CT Reconstruction with a 3D Gaussian Representation"></a>3DGR-CT: Sparse-View CT Reconstruction with a 3D Gaussian Representation</h2><p><strong>Authors:Yingtai Li, Xueming Fu, Han Li, Shang Zhao, Ruiyang Jin, S. Kevin Zhou</strong></p>
<p>Sparse-view computed tomography (CT) reduces radiation exposure by acquiring fewer projections, making it a valuable tool in clinical scenarios where low-dose radiation is essential. However, this often results in increased noise and artifacts due to limited data. In this paper we propose a novel 3D Gaussian representation (3DGR) based method for sparse-view CT reconstruction. Inspired by recent success in novel view synthesis driven by 3D Gaussian splatting, we leverage the efficiency and expressiveness of 3D Gaussian representation as an alternative to implicit neural representation. To unleash the potential of 3DGR for CT imaging scenario, we propose two key innovations: (i) FBP-image-guided Guassian initialization and (ii) efficient integration with a differentiable CT projector. Extensive experiments and ablations on diverse datasets demonstrate the proposed 3DGR-CT consistently outperforms state-of-the-art counterpart methods, achieving higher reconstruction accuracy with faster convergence. Furthermore, we showcase the potential of 3DGR-CT for real-time physical simulation, which holds important clinical applications while challenging for implicit neural representations. </p>
<blockquote>
<p>稀疏视图计算机断层扫描（CT）通过获取较少的投影来减少辐射暴露，使其成为在临床场景中低剂量辐射至关重要的有价值的工具。然而，这通常由于数据有限而导致噪声和伪影增加。在本文中，我们提出了一种基于三维高斯表示（3DGR）的稀疏视图CT重建方法。我们受到最近由三维高斯喷射驱动的新型视图合成的成功的启发，利用三维高斯表示的效率和表现力作为隐神经表示的替代方案。为了释放3DGR在CT成像场景中的潜力，我们提出了两个关键创新点：（i）FBP图像引导的高斯初始化，以及（ii）与可微分CT投影仪的有效集成。在多种数据集上的广泛实验和废除实验表明，所提出的3DGR-CT持续超越最新同行方法，以更高的重建精度和更快的收敛速度实现了优势。此外，我们展示了3DGR-CT在实时物理模拟中的潜力，这在临床应用中具有重要意义，同时对隐神经表示形式提出了挑战。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2312.15676v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>本文介绍了基于稀疏视角计算机断层扫描（CT）的重建方法。文章提出了一种新颖的3D高斯表示（3DGR）方法，用于稀疏视角CT重建，以减少辐射暴露并增加数据表达的效率和表现力。文章通过引入两个创新点——FBP图像引导的Guassian初始化和与可微分CT投影仪的高效集成——使得重建的准确性与收敛速度大大提高，同时也展示了对真实时间物理模拟的潜力。这一技术在临床应用方面具有重要价值。</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>稀疏视角计算机断层扫描（CT）通过获取较少的投影来减少辐射暴露。</li>
<li>提出了新颖的3D高斯表示（3DGR）方法用于稀疏视角CT重建。</li>
<li>引入了两个创新点：FBP图像引导的Guassian初始化和与可微分CT投影仪的高效集成。</li>
<li>通过实验验证，所提出的3DGR-CT优于其他先进方法，具有更高的重建准确性和更快的收敛速度。</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2312.15676">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-93a958b2bebf300c785a1a0dacbe7a1f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-dac84cac97f5af2c82fffd052b8f44c6.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-ef8529ddd5583d213a9c5553c43c49e0.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-cad8c93c8c6a54789e0ae42b71315b51.jpg" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        文章作者:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        文章链接:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-04-24/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/">https://kedreamix.github.io/Talk2Paper/Paper/2025-04-24/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        版权声明:
                    </i>
                </span>
                <span class="reprint-info">
                    本博客所有文章除特別声明外，均采用
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    许可协议。转载请注明来源
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/">
                                    <span class="chip bg-color">医学图像</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;上一篇</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-04-24/TTS/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-3194bf3ea8451f88cf38361ae0a6e3ef.jpg" class="responsive-img" alt="TTS">
                        
                        <span class="card-title">TTS</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            TTS 方向最新论文已更新，请持续关注 Update in 2025-04-24  TTRL Test-Time Reinforcement Learning
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-04-24
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/TTS/" class="post-category">
                                    TTS
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/TTS/">
                        <span class="chip bg-color">TTS</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-04-24/Diffusion%20Models/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-5bab06f9fc547a0b2c40652a0533ac66.jpg" class="responsive-img" alt="Diffusion Models">
                        
                        <span class="card-title">Diffusion Models</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Diffusion Models 方向最新论文已更新，请持续关注 Update in 2025-04-24  From Reflection to Perfection Scaling Inference-Time Optimization for   Text-to-Image Diffusion Models via Reflection Tuning
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-04-24
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Diffusion-Models/" class="post-category">
                                    Diffusion Models
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Diffusion-Models/">
                        <span class="chip bg-color">Diffusion Models</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- 代码语言 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span
                        class="white-color">25370.7k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- 运行天数提醒. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // 区分是否有年份.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = '本站已运行 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                daysTip = '本站已運行 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = '本站已运行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = '本站已運行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="关注我的知乎: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">知</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- 白天和黑夜主题 -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // 只在桌面版网页启用特效
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- 雪花特效 -->
    

    <!-- 鼠标星星特效 -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--腾讯兔小巢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- 动态标签 -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Σ(っ °Д °;)っ诶，页面崩溃了嘛？", clearTimeout(st)) : (document.title = "φ(゜▽゜*)♪咦，又好了！", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
