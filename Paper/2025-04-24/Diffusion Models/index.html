<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Diffusion Models">
    <meta name="description" content="Diffusion Models æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-04-24  From Reflection to Perfection Scaling Inference-Time Optimization for   Text-to-Image Diffusion Models via Reflection Tuning">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>Diffusion Models | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://picx.zhimg.com/v2-5bab06f9fc547a0b2c40652a0533ac66.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Diffusion Models</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/Diffusion-Models/">
                                <span class="chip bg-color">Diffusion Models</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/Diffusion-Models/" class="post-category">
                                Diffusion Models
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-04-24
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-05-14
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    8.5k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    34 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-04-24-æ›´æ–°"><a href="#2025-04-24-æ›´æ–°" class="headerlink" title="2025-04-24 æ›´æ–°"></a>2025-04-24 æ›´æ–°</h1><h2 id="From-Reflection-to-Perfection-Scaling-Inference-Time-Optimization-for-Text-to-Image-Diffusion-Models-via-Reflection-Tuning"><a href="#From-Reflection-to-Perfection-Scaling-Inference-Time-Optimization-for-Text-to-Image-Diffusion-Models-via-Reflection-Tuning" class="headerlink" title="From Reflection to Perfection: Scaling Inference-Time Optimization for   Text-to-Image Diffusion Models via Reflection Tuning"></a>From Reflection to Perfection: Scaling Inference-Time Optimization for   Text-to-Image Diffusion Models via Reflection Tuning</h2><p><strong>Authors:Le Zhuo, Liangbing Zhao, Sayak Paul, Yue Liao, Renrui Zhang, Yi Xin, Peng Gao, Mohamed Elhoseiny, Hongsheng Li</strong></p>
<p>Recent text-to-image diffusion models achieve impressive visual quality through extensive scaling of training data and model parameters, yet they often struggle with complex scenes and fine-grained details. Inspired by the self-reflection capabilities emergent in large language models, we propose ReflectionFlow, an inference-time framework enabling diffusion models to iteratively reflect upon and refine their outputs. ReflectionFlow introduces three complementary inference-time scaling axes: (1) noise-level scaling to optimize latent initialization; (2) prompt-level scaling for precise semantic guidance; and most notably, (3) reflection-level scaling, which explicitly provides actionable reflections to iteratively assess and correct previous generations. To facilitate reflection-level scaling, we construct GenRef, a large-scale dataset comprising 1 million triplets, each containing a reflection, a flawed image, and an enhanced image. Leveraging this dataset, we efficiently perform reflection tuning on state-of-the-art diffusion transformer, FLUX.1-dev, by jointly modeling multimodal inputs within a unified framework. Experimental results show that ReflectionFlow significantly outperforms naive noise-level scaling methods, offering a scalable and compute-efficient solution toward higher-quality image synthesis on challenging tasks. </p>
<blockquote>
<p>æœ€è¿‘å‡ºç°çš„æ–‡æœ¬åˆ°å›¾åƒçš„æ‰©æ•£æ¨¡å‹é€šè¿‡å¤§è§„æ¨¡æ‰©å±•è®­ç»ƒæ•°æ®å’Œæ¨¡å‹å‚æ•°ï¼Œå®ç°äº†ä»¤äººå°è±¡æ·±åˆ»çš„è§†è§‰è´¨é‡ï¼Œä½†å®ƒä»¬å¾€å¾€åœ¨å¤„ç†å¤æ‚åœºæ™¯å’Œç²¾ç»†ç»†èŠ‚æ–¹é¢é‡åˆ°å›°éš¾ã€‚å—å¤§å‹è¯­è¨€æ¨¡å‹ä¸­å‡ºç°çš„è‡ªæˆ‘åæ€èƒ½åŠ›çš„å¯å‘ï¼Œæˆ‘ä»¬æå‡ºäº†ReflectionFlowï¼Œè¿™æ˜¯ä¸€ä¸ªæ¨ç†æ—¶é—´æ¡†æ¶ï¼Œèƒ½å¤Ÿä½¿æ‰©æ•£æ¨¡å‹è¿­ä»£åœ°åæ€å’Œå®Œå–„å…¶è¾“å‡ºã€‚ReflectionFlowå¼•å…¥äº†ä¸‰ç§äº’è¡¥çš„æ¨ç†æ—¶é—´å°ºåº¦è½´ï¼šï¼ˆ1ï¼‰å™ªå£°æ°´å¹³å°ºåº¦ä¼˜åŒ–æ½œåœ¨åˆå§‹åŒ–ï¼›ï¼ˆ2ï¼‰æç¤ºæ°´å¹³å°ºåº¦æä¾›ç²¾ç¡®è¯­ä¹‰æŒ‡å¯¼ï¼›ä»¥åŠæœ€å€¼å¾—æ³¨æ„çš„æ˜¯ï¼ˆ3ï¼‰åæ€æ°´å¹³å°ºåº¦ï¼Œå®ƒæ˜ç¡®æä¾›äº†å¯æ“ä½œçš„åæ€æ¥è¿­ä»£è¯„ä¼°å’Œçº æ­£ä¹‹å‰çš„ç”Ÿæˆã€‚ä¸ºäº†ä¿ƒè¿›åæ€æ°´å¹³å°ºåº¦çš„å‘å±•ï¼Œæˆ‘ä»¬æ„å»ºäº†GenRefæ•°æ®é›†ï¼Œè¯¥æ•°æ®é›†åŒ…å«100ä¸‡ç»„ä¸‰å…ƒç»„ï¼Œæ¯ç»„åŒ…å«ä¸€æ¬¡åæ€ã€ä¸€ä¸ªç¼ºé™·å›¾åƒå’Œä¸€ä¸ªå¢å¼ºçš„å›¾åƒã€‚åˆ©ç”¨æ­¤æ•°æ®é›†ï¼Œæˆ‘ä»¬åœ¨ç»Ÿä¸€æ¡†æ¶ä¸‹è”åˆå»ºæ¨¡å¤šæ¨¡å¼è¾“å…¥ï¼Œå¯¹æœ€å…ˆè¿›çš„æ‰©æ•£å˜å‹å™¨FLUX.1-devè¿›è¡Œé«˜æ•ˆåå°„è°ƒä¼˜ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒReflectionFlowæ˜¾è‘—ä¼˜äºç®€å•çš„å™ªå£°æ°´å¹³å°ºåº¦æ–¹æ³•ï¼Œä¸ºå…·æœ‰æŒ‘æˆ˜æ€§çš„ä»»åŠ¡æä¾›äº†å¯ä¼¸ç¼©å’Œè®¡ç®—é«˜æ•ˆçš„è§£å†³æ–¹æ¡ˆï¼Œä»¥å®ç°æ›´é«˜è´¨é‡çš„å›¾åƒåˆæˆã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.16080v1">PDF</a> All code, checkpoints, and datasets are available at   \url{<a target="_blank" rel="noopener" href="https://diffusion-cot.github.io/reflection2perfection%7D">https://diffusion-cot.github.io/reflection2perfection}</a></p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†åŸºäºæ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹çš„æ”¹è¿›æ–¹æ¡ˆReflectionFlowï¼Œå®ƒé€šè¿‡å¼•å…¥å™ªå£°çº§åˆ«ç¼©æ”¾ã€æç¤ºçº§åˆ«ç¼©æ”¾å’Œåå°„çº§åˆ«ç¼©æ”¾ä¸‰ç§äº’è¡¥çš„æ¨ç†æ—¶é—´ç¼©æ”¾è½´ï¼Œæå‡äº†æ‰©æ•£æ¨¡å‹çš„æ€§èƒ½ã€‚å…¶ä¸­ï¼Œåå°„çº§åˆ«ç¼©æ”¾èƒ½å¤Ÿæ˜¾å¼åœ°æä¾›åé¦ˆæ¥è¿­ä»£è¯„ä¼°å’Œä¿®æ­£ä¹‹å‰çš„ç”Ÿæˆå›¾åƒã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒReflectionFlowåœ¨å…·æœ‰æŒ‘æˆ˜æ€§çš„ä»»åŠ¡ä¸Šæ˜¾è‘—ä¼˜äºç®€å•çš„å™ªå£°çº§åˆ«ç¼©æ”¾æ–¹æ³•ï¼Œä¸ºé«˜è´¨é‡å›¾åƒåˆæˆæä¾›äº†å¯æ‰©å±•å’Œè®¡ç®—é«˜æ•ˆçš„è§£å†³æ–¹æ¡ˆã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æ‰©æ•£æ¨¡å‹è™½èƒ½é€šè¿‡å¤§è§„æ¨¡çš„è®­ç»ƒæ•°æ®å’Œæ¨¡å‹å‚æ•°å®ç°é«˜è´¨é‡çš„å›¾åƒç”Ÿæˆï¼Œä½†åœ¨å¤æ‚åœºæ™¯å’Œç²¾ç»†ç»†èŠ‚æ–¹é¢å­˜åœ¨æŒ‘æˆ˜ã€‚</li>
<li>ReflectionFlowæ˜¯ä¸€ä¸ªæ¨ç†æ—¶é—´æ¡†æ¶ï¼Œå¯ç”¨äº†æ‰©æ•£æ¨¡å‹çš„è¿­ä»£åæ€å’Œç»†åŒ–è¾“å‡ºèƒ½åŠ›ã€‚</li>
<li>ReflectionFlowå¼•å…¥äº†ä¸‰ç§äº’è¡¥çš„æ¨ç†æ—¶é—´ç¼©æ”¾è½´ï¼šå™ªå£°çº§åˆ«ç¼©æ”¾ã€æç¤ºçº§åˆ«ç¼©æ”¾å’Œåå°„çº§åˆ«ç¼©æ”¾ã€‚</li>
<li>åå°„çº§åˆ«ç¼©æ”¾èƒ½å¤Ÿæ˜ç¡®æä¾›åé¦ˆï¼Œä»¥è¿­ä»£è¯„ä¼°å’Œä¿®æ­£ä¹‹å‰çš„ç”Ÿæˆå›¾åƒã€‚</li>
<li>ä¸ºäº†ä¿ƒè¿›åå°„çº§åˆ«ç¼©æ”¾ï¼Œæ„å»ºäº†GenRefæ•°æ®é›†ï¼ŒåŒ…å«ç™¾ä¸‡ä¸ªä¸‰å…ƒç»„ï¼Œæ¯ä¸ªåŒ…å«åæ€ã€æœ‰ç¼ºé™·çš„å›¾åƒå’Œå¢å¼ºçš„å›¾åƒã€‚</li>
<li>åˆ©ç”¨GenRefæ•°æ®é›†ï¼Œåœ¨æœ€æ–°æ‰©æ•£å˜å‹å™¨FLUXä¸Šè¿›è¡Œäº†é«˜æ•ˆåå°„è°ƒæ•´ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.16080">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-dfd6c6395e34273a2ed17fc72955362c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-531502b431a822dc1b7da3db6eb89543.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-552efa358ba9c027393f3b69a6329e6a.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-cdd67822a9fd95116aa5102a85ca682d.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="Satellite-to-GroundScape-â€“-Large-scale-Consistent-Ground-View-Generation-from-Satellite-Views"><a href="#Satellite-to-GroundScape-â€“-Large-scale-Consistent-Ground-View-Generation-from-Satellite-Views" class="headerlink" title="Satellite to GroundScape â€“ Large-scale Consistent Ground View   Generation from Satellite Views"></a>Satellite to GroundScape â€“ Large-scale Consistent Ground View   Generation from Satellite Views</h2><p><strong>Authors:Ningli Xu, Rongjun Qin</strong></p>
<p>Generating consistent ground-view images from satellite imagery is challenging, primarily due to the large discrepancies in viewing angles and resolution between satellite and ground-level domains. Previous efforts mainly concentrated on single-view generation, often resulting in inconsistencies across neighboring ground views. In this work, we propose a novel cross-view synthesis approach designed to overcome these challenges by ensuring consistency across ground-view images generated from satellite views. Our method, based on a fixed latent diffusion model, introduces two conditioning modules: satellite-guided denoising, which extracts high-level scene layout to guide the denoising process, and satellite-temporal denoising, which captures camera motion to maintain consistency across multiple generated views. We further contribute a large-scale satellite-ground dataset containing over 100,000 perspective pairs to facilitate extensive ground scene or video generation. Experimental results demonstrate that our approach outperforms existing methods on perceptual and temporal metrics, achieving high photorealism and consistency in multi-view outputs. </p>
<blockquote>
<p>ä»å«æ˜Ÿå›¾åƒç”Ÿæˆè¿è´¯çš„åœ°é¢è§†å›¾å›¾åƒæ˜¯ä¸€é¡¹æŒ‘æˆ˜ï¼Œä¸»è¦æ˜¯ç”±äºå«æ˜Ÿå’Œåœ°é¢é¢†åŸŸä¹‹é—´è§‚çœ‹è§’åº¦å’Œåˆ†è¾¨ç‡å­˜åœ¨å¾ˆå¤§å·®å¼‚ã€‚ä¹‹å‰çš„ç ”ç©¶ä¸»è¦é›†ä¸­åœ¨å•è§†å›¾ç”Ÿæˆä¸Šï¼Œå¾€å¾€å¯¼è‡´ç›¸é‚»åœ°é¢è§†å›¾ä¹‹é—´å‡ºç°ä¸ä¸€è‡´ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°çš„è·¨è§†å›¾åˆæˆæ–¹æ³•ï¼Œæ—¨åœ¨é€šè¿‡ç¡®ä¿ä»å«æ˜Ÿè§†å›¾ç”Ÿæˆçš„åœ°é¢è§†å›¾å›¾åƒä¹‹é—´çš„ä¸€è‡´æ€§æ¥å…‹æœè¿™äº›æŒ‘æˆ˜ã€‚æˆ‘ä»¬çš„æ–¹æ³•åŸºäºå›ºå®šçš„æ½œåœ¨æ‰©æ•£æ¨¡å‹ï¼Œå¼•å…¥äº†ä¸¤ä¸ªæ¡ä»¶æ¨¡å—ï¼šå«æ˜Ÿå¼•å¯¼å»å™ªï¼Œç”¨äºæå–é«˜çº§åœºæ™¯å¸ƒå±€ä»¥å¼•å¯¼å»å™ªè¿‡ç¨‹ï¼›å«æ˜Ÿæ—¶é—´å»å™ªï¼Œç”¨äºæ•è·æ‘„åƒæœºè¿åŠ¨ä»¥ç»´æŒå¤šä¸ªç”Ÿæˆè§†å›¾ä¹‹é—´çš„ä¸€è‡´æ€§ã€‚æˆ‘ä»¬è¿˜è´¡çŒ®äº†ä¸€ä¸ªå¤§è§„æ¨¡å«æ˜Ÿåœ°é¢æ•°æ®é›†ï¼ŒåŒ…å«è¶…è¿‡10ä¸‡ä¸ªé€è§†å¯¹ï¼Œä»¥ä¿ƒè¿›å¹¿æ³›çš„åœ°é¢åœºæ™¯æˆ–è§†é¢‘ç”Ÿæˆã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨æ„ŸçŸ¥å’Œæ—¶é—´åº¦é‡ä¸Šä¼˜äºç°æœ‰æ–¹æ³•ï¼Œå®ç°äº†å¤šè§†å›¾è¾“å‡ºçš„é«˜é€¼çœŸåº¦å’Œä¸€è‡´æ€§ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.15786v1">PDF</a> 8 figures</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºä¸€ç§åŸºäºå›ºå®šæ½œåœ¨æ‰©æ•£æ¨¡å‹çš„æ–°å‹è·¨è§†å›¾åˆæˆæ–¹æ³•ï¼Œæ—¨åœ¨å…‹æœä»å«æ˜Ÿå›¾åƒç”Ÿæˆåœ°é¢è§†å›¾å›¾åƒçš„æŒ‘æˆ˜ã€‚è¯¥æ–¹æ³•é€šè¿‡å¼•å…¥å«æ˜Ÿå¼•å¯¼å»å™ªå’Œå«æ˜Ÿæ—¶é—´å»å™ªä¸¤ä¸ªæ¡ä»¶æ¨¡å—ï¼Œç¡®ä¿ä»ä¸åŒå«æ˜Ÿè§†å›¾ç”Ÿæˆçš„åœ°é¢è§†å›¾å›¾åƒä¹‹é—´çš„ä¸€è‡´æ€§ã€‚åŒæ—¶ï¼Œè´¡çŒ®äº†ä¸€ä¸ªå¤§è§„æ¨¡å«æ˜Ÿ-åœ°é¢æ•°æ®é›†ï¼ŒåŒ…å«è¶…è¿‡10ä¸‡å¯¹è§†è§’æ•°æ®ï¼Œä»¥ä¿ƒè¿›åœ°é¢åœºæ™¯æˆ–è§†é¢‘ç”Ÿæˆçš„ç ”ç©¶ã€‚å®éªŒç»“æœè¯æ˜ï¼Œè¯¥æ–¹æ³•åœ¨æ„ŸçŸ¥å’Œæ—¶é—´åº¦é‡ä¸Šä¼˜äºç°æœ‰æ–¹æ³•ï¼Œå®ç°äº†å¤šè§†å›¾è¾“å‡ºçš„é«˜é€¼çœŸåº¦å’Œä¸€è‡´æ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>è·¨è§†å›¾åˆæˆæ–¹æ³•è¢«æå‡ºï¼Œæ—¨åœ¨ä»å«æ˜Ÿå›¾åƒç”Ÿæˆä¸€è‡´çš„åœ°é¢è§†å›¾å›¾åƒã€‚</li>
<li>æ–¹æ³•åŸºäºå›ºå®šæ½œåœ¨æ‰©æ•£æ¨¡å‹ï¼Œç¡®ä¿å¤šè§†å›¾ä¹‹é—´çš„ä¸€è‡´æ€§ã€‚</li>
<li>å¼•å…¥ä¸¤ä¸ªæ¡ä»¶æ¨¡å—ï¼šå«æ˜Ÿå¼•å¯¼å»å™ªå’Œå«æ˜Ÿæ—¶é—´å»å™ªï¼Œä»¥ä¼˜åŒ–ç”Ÿæˆè¿‡ç¨‹ã€‚</li>
<li>è´¡çŒ®äº†ä¸€ä¸ªå¤§è§„æ¨¡å«æ˜Ÿ-åœ°é¢æ•°æ®é›†ï¼ŒåŒ…å«è¶…è¿‡10ä¸‡å¯¹è§†è§’æ•°æ®ã€‚</li>
<li>æ–¹æ³•åœ¨æ„ŸçŸ¥å’Œæ—¶é—´åº¦é‡ä¸Šè¡¨ç°å‡ºä¼˜è¶Šæ€§ã€‚</li>
<li>ç”Ÿæˆçš„ç»“æœå…·æœ‰é«˜é€¼çœŸåº¦å’Œå¤šè§†å›¾çš„ä¸€è‡´æ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.15786">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-535c4b2eeb07862a15f848901ed4c294.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-074fd0a0d06375ba4b8043d26773776a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b2e38c312338988d53e003c53a06bc15.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-43a28653b0125f17a5eec1a230958fbd.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-8cbdb57f497a29a3bf459bed42df706c.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="InstaRevive-One-Step-Image-Enhancement-via-Dynamic-Score-Matching"><a href="#InstaRevive-One-Step-Image-Enhancement-via-Dynamic-Score-Matching" class="headerlink" title="InstaRevive: One-Step Image Enhancement via Dynamic Score Matching"></a>InstaRevive: One-Step Image Enhancement via Dynamic Score Matching</h2><p><strong>Authors:Yixuan Zhu, Haolin Wang, Ao Li, Wenliang Zhao, Yansong Tang, Jingxuan Niu, Lei Chen, Jie Zhou, Jiwen Lu</strong></p>
<p>Image enhancement finds wide-ranging applications in real-world scenarios due to complex environments and the inherent limitations of imaging devices. Recent diffusion-based methods yield promising outcomes but necessitate prolonged and computationally intensive iterative sampling. In response, we propose InstaRevive, a straightforward yet powerful image enhancement framework that employs score-based diffusion distillation to harness potent generative capability and minimize the sampling steps. To fully exploit the potential of the pre-trained diffusion model, we devise a practical and effective diffusion distillation pipeline using dynamic control to address inaccuracies in updating direction during score matching. Our control strategy enables a dynamic diffusing scope, facilitating precise learning of denoising trajectories within the diffusion model and ensuring accurate distribution matching gradients during training. Additionally, to enrich guidance for the generative power, we incorporate textual prompts via image captioning as auxiliary conditions, fostering further exploration of the diffusion model. Extensive experiments substantiate the efficacy of our framework across a diverse array of challenging tasks and datasets, unveiling the compelling efficacy and efficiency of InstaRevive in delivering high-quality and visually appealing results. Code is available at <a target="_blank" rel="noopener" href="https://github.com/EternalEvan/InstaRevive">https://github.com/EternalEvan/InstaRevive</a>. </p>
<blockquote>
<p>å›¾åƒå¢å¼ºåœ¨ç°å®åœºæ™¯ä¸­å…·æœ‰å¹¿æ³›çš„åº”ç”¨ï¼Œè¿™å½’åŠŸäºå¤æ‚çš„ç¯å¢ƒå’Œæˆåƒè®¾å¤‡å›ºæœ‰çš„å±€é™æ€§ã€‚è™½ç„¶æœ€è¿‘çš„æ‰©æ•£æ–¹æ³•äº§ç”Ÿäº†æœ‰å‰é€”çš„ç»“æœï¼Œä½†å®ƒä»¬éœ€è¦è¿›è¡Œé•¿æœŸå’Œè®¡ç®—å¯†é›†å‹çš„è¿­ä»£é‡‡æ ·ã€‚é’ˆå¯¹è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†InstaReviveï¼Œè¿™æ˜¯ä¸€ä¸ªç®€å•è€Œå¼ºå¤§çš„å›¾åƒå¢å¼ºæ¡†æ¶ï¼Œå®ƒé‡‡ç”¨åŸºäºåˆ†æ•°çš„æ‰©æ•£è’¸é¦æ¥åˆ©ç”¨å¼ºå¤§çš„ç”Ÿæˆèƒ½åŠ›å¹¶å‡å°‘é‡‡æ ·æ­¥éª¤ã€‚ä¸ºäº†å……åˆ†åˆ©ç”¨é¢„è®­ç»ƒæ‰©æ•£æ¨¡å‹çš„æ½œåŠ›ï¼Œæˆ‘ä»¬è®¾è®¡äº†ä¸€ä¸ªå®ç”¨æœ‰æ•ˆçš„æ‰©æ•£è’¸é¦ç®¡é“ï¼Œä½¿ç”¨åŠ¨æ€æ§åˆ¶æ¥è§£å†³åˆ†æ•°åŒ¹é…è¿‡ç¨‹ä¸­æ›´æ–°æ–¹å‘çš„ä¸å‡†ç¡®é—®é¢˜ã€‚æˆ‘ä»¬çš„æ§åˆ¶ç­–ç•¥èƒ½å¤Ÿå®ç°åŠ¨æ€æ‰©æ•£èŒƒå›´ï¼Œä¾¿äºåœ¨æ‰©æ•£æ¨¡å‹ä¸­ç²¾ç¡®å­¦ä¹ å»å™ªè½¨è¿¹ï¼Œå¹¶åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ç¡®ä¿å‡†ç¡®çš„åˆ†å¸ƒåŒ¹é…æ¢¯åº¦ã€‚æ­¤å¤–ï¼Œä¸ºäº†ä¸°å¯Œç”Ÿæˆèƒ½åŠ›çš„æŒ‡å¯¼ï¼Œæˆ‘ä»¬é€šè¿‡å›¾åƒæè¿°ä½œä¸ºè¾…åŠ©æ¡ä»¶èå…¥æ–‡æœ¬æç¤ºï¼Œä¿ƒè¿›æ‰©æ•£æ¨¡å‹çš„è¿›ä¸€æ­¥æ¢ç´¢ã€‚å¤§é‡å®éªŒè¯æ˜ï¼Œæˆ‘ä»¬çš„æ¡†æ¶åœ¨å¤šç§å…·æœ‰æŒ‘æˆ˜æ€§çš„ä»»åŠ¡å’Œæ•°æ®é›†ä¸Šæ•ˆæœæ˜¾è‘—ï¼Œæ­ç¤ºäº†InstaReviveåœ¨æä¾›é«˜è´¨é‡å’Œè§†è§‰ä¸Šå¸å¼•äººçš„ç»“æœæ–¹é¢çš„ä»¤äººä¿¡æœçš„æœ‰æ•ˆæ€§å’Œæ•ˆç‡ã€‚ä»£ç å¯é€šè¿‡ä»¥ä¸‹ç½‘å€è·å–ï¼š<a target="_blank" rel="noopener" href="https://github.com/EternalEvan/InstaRevive">https://github.com/EternalEvan/InstaRevive</a>ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.15513v1">PDF</a> Accepted by ICLR 2025</p>
<p><strong>Summary</strong><br>     é’ˆå¯¹å›¾åƒå¢å¼ºåœ¨çœŸå®åœºæ™¯ä¸­çš„å¹¿æ³›åº”ç”¨åŠæˆåƒè®¾å¤‡çš„å›ºæœ‰å±€é™æ€§ï¼Œæå‡ºäº†ä¸€ç§åŸºäºæ‰©æ•£è’¸é¦çš„å³æ—¶å¢å¼ºæ¡†æ¶InstaReviveã€‚é€šè¿‡å¾—åˆ†ä¸ºåŸºç¡€çš„æ‰©æ•£è’¸é¦æŠ€æœ¯å®ç°å¼ºå¤§çš„ç”Ÿæˆèƒ½åŠ›å’Œå‡å°‘é‡‡æ ·æ­¥éª¤ã€‚ä½¿ç”¨åŠ¨æ€æ§åˆ¶ç­–ç•¥å®ç°é¢„è®­ç»ƒæ‰©æ•£æ¨¡å‹çš„æ½œåŠ›æœ€å¤§åŒ–ï¼Œç¡®ä¿ç²¾ç¡®å­¦ä¹ å»å™ªè½¨è¿¹å’Œåˆ†å¸ƒåŒ¹é…æ¢¯åº¦ã€‚ç»“åˆå›¾åƒæè¿°æ–‡æœ¬æç¤ºä½œä¸ºè¾…åŠ©æ¡ä»¶ï¼Œè¿›ä¸€æ­¥æ¢ç´¢æ‰©æ•£æ¨¡å‹çš„æ½œåŠ›ã€‚å®éªŒè¯æ˜ï¼Œè¯¥æ¡†æ¶åœ¨å¤šç§æŒ‘æˆ˜ä»»åŠ¡å’Œæ•°æ®é›†ä¸Šæ•ˆæœæ˜¾è‘—ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>InstaReviveæ˜¯ä¸€ä¸ªåŸºäºæ‰©æ•£è’¸é¦çš„å›¾åƒå¢å¼ºæ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³å¤æ‚ç¯å¢ƒå’Œæˆåƒè®¾å¤‡é™åˆ¶ä¸‹çš„å›¾åƒé—®é¢˜ã€‚</li>
<li>è¯¥æ¡†æ¶é‡‡ç”¨å¾—åˆ†åŸºç¡€çš„æ‰©æ•£è’¸é¦æŠ€æœ¯ï¼Œä»¥å¼ºå¤§çš„ç”Ÿæˆèƒ½åŠ›å’Œå‡å°‘é‡‡æ ·æ­¥éª¤ä¸ºç‰¹ç‚¹ã€‚</li>
<li>é€šè¿‡åŠ¨æ€æ§åˆ¶ç­–ç•¥å®ç°é¢„è®­ç»ƒæ‰©æ•£æ¨¡å‹çš„æ½œåŠ›æœ€å¤§åŒ–ï¼Œç¡®ä¿ç²¾ç¡®çš„å»å™ªè½¨è¿¹å­¦ä¹ å’Œåˆ†å¸ƒåŒ¹é…æ¢¯åº¦çš„å‡†ç¡®æ€§ã€‚</li>
<li>InstaReviveç»“åˆå›¾åƒæè¿°æ–‡æœ¬æç¤ºï¼Œä½œä¸ºè¾…åŠ©æ¡ä»¶æ¥ä¸°å¯Œç”ŸæˆåŠ›é‡çš„æŒ‡å¯¼ã€‚</li>
<li>æ¡†æ¶åœ¨å¤šç§æŒ‘æˆ˜ä»»åŠ¡å’Œæ•°æ®é›†ä¸Šè¿›è¡Œäº†å¹¿æ³›å®éªŒï¼Œè¯æ˜äº†å…¶æœ‰æ•ˆæ€§å’Œé«˜æ•ˆç‡ã€‚</li>
<li>è¯¥æ¡†æ¶å¯æä¾›é«˜è´¨é‡å’Œè§†è§‰å¸å¼•åŠ›çš„ç»“æœã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.15513">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-14eb16871de689e89029d4d0e9d85aaa.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-28c3df2c41a96e059fb51f1d2323e4f9.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-212568bb9023b67ce4acdcc616050708.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-16fc418fabcc249ffd6f44c3fd7a1cdc.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="Manifold-Induced-Biases-for-Zero-shot-and-Few-shot-Detection-of-Generated-Images"><a href="#Manifold-Induced-Biases-for-Zero-shot-and-Few-shot-Detection-of-Generated-Images" class="headerlink" title="Manifold Induced Biases for Zero-shot and Few-shot Detection of   Generated Images"></a>Manifold Induced Biases for Zero-shot and Few-shot Detection of   Generated Images</h2><p><strong>Authors:Jonathan Brokman, Amit Giloni, Omer Hofman, Roman Vainshtein, Hisashi Kojima, Guy Gilboa</strong></p>
<p>Distinguishing between real and AI-generated images, commonly referred to as â€˜image detectionâ€™, presents a timely and significant challenge. Despite extensive research in the (semi-)supervised regime, zero-shot and few-shot solutions have only recently emerged as promising alternatives. Their main advantage is in alleviating the ongoing data maintenance, which quickly becomes outdated due to advances in generative technologies. We identify two main gaps: (1) a lack of theoretical grounding for the methods, and (2) significant room for performance improvements in zero-shot and few-shot regimes. Our approach is founded on understanding and quantifying the biases inherent in generated content, where we use these quantities as criteria for characterizing generated images. Specifically, we explore the biases of the implicit probability manifold, captured by a pre-trained diffusion model. Through score-function analysis, we approximate the curvature, gradient, and bias towards points on the probability manifold, establishing criteria for detection in the zero-shot regime. We further extend our contribution to the few-shot setting by employing a mixture-of-experts methodology. Empirical results across 20 generative models demonstrate that our method outperforms current approaches in both zero-shot and few-shot settings. This work advances the theoretical understanding and practical usage of generated content biases through the lens of manifold analysis. </p>
<blockquote>
<p>åŒºåˆ†çœŸå®å›¾åƒå’Œäººå·¥æ™ºèƒ½ç”Ÿæˆçš„å›¾åƒï¼Œé€šå¸¸è¢«ç§°ä¸ºâ€œå›¾åƒæ£€æµ‹â€ï¼Œè¿™æ˜¯ä¸€ä¸ªåŠæ—¶ä¸”é‡å¤§çš„æŒ‘æˆ˜ã€‚å°½ç®¡åœ¨ï¼ˆåŠï¼‰ç›‘ç£åˆ¶åº¦æ–¹é¢è¿›è¡Œäº†å¤§é‡ç ”ç©¶ï¼Œä½†é›¶æ ·æœ¬å’Œå°‘æ ·æœ¬è§£å†³æ–¹æ¡ˆæœ€è¿‘æ‰ä½œä¸ºæœ‰å‰é€”çš„æ›¿ä»£æ–¹æ¡ˆå‡ºç°ã€‚å®ƒä»¬çš„ä¸»è¦ä¼˜åŠ¿åœ¨äºç¼“è§£äº†æ­£åœ¨è¿›è¡Œçš„æ•°æ®ç»´æŠ¤é—®é¢˜ï¼Œç”±äºç”ŸæˆæŠ€æœ¯çš„ä¸æ–­è¿›æ­¥ï¼Œè¿™äº›æ•°æ®å¾ˆå¿«ä¼šè¿‡æ—¶ã€‚æˆ‘ä»¬å‘ç°äº†ä¸¤ä¸ªä¸»è¦ç©ºç™½ï¼šï¼ˆ1ï¼‰è¿™äº›æ–¹æ³•ç¼ºä¹ç†è®ºæ”¯æ’‘ï¼Œï¼ˆ2ï¼‰åœ¨é›¶æ ·æœ¬å’Œå°‘æ ·æœ¬åˆ¶åº¦ä¸‹ï¼Œæ€§èƒ½ä»æœ‰å¾ˆå¤§æå‡ç©ºé—´ã€‚æˆ‘ä»¬çš„æ–¹æ³•å»ºç«‹åœ¨ç†è§£å’Œé‡åŒ–ç”Ÿæˆå†…å®¹æ‰€å›ºæœ‰çš„åè§ä¸Šï¼Œæˆ‘ä»¬ä½¿ç”¨è¿™äº›é‡ä½œä¸ºè¡¨å¾ç”Ÿæˆå›¾åƒçš„æ ‡å‡†ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬æ¢ç´¢äº†ç”±é¢„è®­ç»ƒæ‰©æ•£æ¨¡å‹æ•è·çš„éšæ¦‚ç‡æµå½¢åè§ã€‚é€šè¿‡å¾—åˆ†å‡½æ•°åˆ†æï¼Œæˆ‘ä»¬è¿‘ä¼¼æ¦‚ç‡æµå½¢ä¸Šçš„ç‚¹å¤„çš„æ›²ç‡ã€æ¢¯åº¦å’Œåè§ï¼Œä¸ºæ— æ ·æœ¬åˆ¶åº¦ä¸‹å»ºç«‹æ£€æµ‹æ ‡å‡†ã€‚æˆ‘ä»¬è¿›ä¸€æ­¥é€šè¿‡å°†æ··åˆä¸“å®¶æ–¹æ³•åº”ç”¨äºå°‘æ ·æœ¬è®¾ç½®æ¥æ‰©å±•æˆ‘ä»¬çš„è´¡çŒ®ã€‚åœ¨è·¨è¶Š20ä¸ªç”Ÿæˆæ¨¡å‹çš„å®è¯ç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨é›¶æ ·æœ¬å’Œå°‘æ ·æœ¬è®¾ç½®ä¸­éƒ½ä¼˜äºå½“å‰æ–¹æ³•ã€‚è¿™é¡¹å·¥ä½œé€šè¿‡æµå½¢åˆ†æçš„è§’åº¦ï¼Œæ¨åŠ¨äº†ç”Ÿæˆå†…å®¹åè§çš„ç†è®ºç†è§£çš„å®é™…åº”ç”¨ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.15470v1">PDF</a> Accepted to ICLR 2025 (The International Conference on Learning   Representations)</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æ¢è®¨äº†åŒºåˆ†çœŸå®å›¾åƒå’ŒAIç”Ÿæˆå›¾åƒçš„æŒ‘æˆ˜ï¼Œé‡ç‚¹ä»‹ç»äº†åŸºäºç”Ÿæˆå†…å®¹åè§çš„æ£€æµ‹æ–¹æ³•å’Œç†è®ºã€‚é€šè¿‡ç†è§£å¹¶é‡åŒ–ç”Ÿæˆå†…å®¹ä¸­çš„åè§ï¼Œä½¿ç”¨é¢„è®­ç»ƒçš„æ‰©æ•£æ¨¡å‹æ•è·éšå¼æ¦‚ç‡æµå½¢ï¼Œé€šè¿‡è¯„åˆ†å‡½æ•°åˆ†æè¿‘ä¼¼æ›²ç‡ã€æ¢¯åº¦å’Œæ¦‚ç‡æµå½¢ä¸Šçš„ç‚¹åå‘ï¼Œå»ºç«‹é›¶æ ·æœ¬ä¸‹çš„æ£€æµ‹æ ‡å‡†ã€‚åŒæ—¶ï¼Œé‡‡ç”¨æ··åˆä¸“å®¶æ–¹æ³•è§£å†³å°æ ·æœ¬é—®é¢˜ï¼Œå¹¶åœ¨20ä¸ªç”Ÿæˆæ¨¡å‹ä¸Šè¿›è¡Œå®è¯æµ‹è¯•ï¼Œè¯æ˜è¯¥æ–¹æ³•åœ¨é›¶æ ·æœ¬å’Œå°æ ·æœ¬ç¯å¢ƒä¸‹å‡ä¼˜äºç°æœ‰æ–¹æ³•ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>åŒºåˆ†çœŸå®å’ŒAIç”Ÿæˆçš„å›¾åƒæ˜¯ä¸€ä¸ªåŠæ—¶ä¸”é‡è¦çš„æŒ‘æˆ˜ã€‚</li>
<li>é›¶æ ·æœ¬å’Œå°‘æ ·æœ¬è§£å†³æ–¹æ¡ˆæ˜¯æ–°å…´çš„æœ‰å‰é€”çš„æ›¿ä»£æ–¹æ³•ï¼Œå¯ä»¥ç¼“è§£æ•°æ®ç»´æŠ¤çš„é—®é¢˜ã€‚</li>
<li>å½“å‰æ–¹æ³•ç¼ºä¹ç†è®ºæ”¯æ’‘å’Œæ€§èƒ½æ”¹è¿›çš„ç©ºé—´ã€‚</li>
<li>æœ¬æ–‡é€šè¿‡ç†è§£å¹¶é‡åŒ–ç”Ÿæˆå†…å®¹ä¸­çš„åè§æ¥å»ºç«‹æ£€æµ‹æ ‡å‡†ã€‚</li>
<li>ä½¿ç”¨é¢„è®­ç»ƒçš„æ‰©æ•£æ¨¡å‹æ•è·éšå¼æ¦‚ç‡æµå½¢ï¼Œé€šè¿‡è¯„åˆ†å‡½æ•°åˆ†æè¿›è¡Œå›¾åƒæ£€æµ‹ã€‚</li>
<li>åœ¨é›¶æ ·æœ¬å’Œå°æ ·æœ¬ç¯å¢ƒä¸‹ï¼Œè¯¥æ–¹æ³•å‡è¡¨ç°å‡ºä¼˜å¼‚çš„æ€§èƒ½ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.15470">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-d9ff5a9175d553f77043c4f719180c52.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-a8e18012d3e7c1ca7ee3736223aa0c26.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ea90bd09638f3dc67cc37da40227441b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-27a019bc4cefc9d08a846418b46078e4.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="MirrorVerse-Pushing-Diffusion-Models-to-Realistically-Reflect-the-World"><a href="#MirrorVerse-Pushing-Diffusion-Models-to-Realistically-Reflect-the-World" class="headerlink" title="MirrorVerse: Pushing Diffusion Models to Realistically Reflect the World"></a>MirrorVerse: Pushing Diffusion Models to Realistically Reflect the World</h2><p><strong>Authors:Ankit Dhiman, Manan Shah, R Venkatesh Babu</strong></p>
<p>Diffusion models have become central to various image editing tasks, yet they often fail to fully adhere to physical laws, particularly with effects like shadows, reflections, and occlusions. In this work, we address the challenge of generating photorealistic mirror reflections using diffusion-based generative models. Despite extensive training data, existing diffusion models frequently overlook the nuanced details crucial to authentic mirror reflections. Recent approaches have attempted to resolve this by creating synhetic datasets and framing reflection generation as an inpainting task; however, they struggle to generalize across different object orientations and positions relative to the mirror. Our method overcomes these limitations by introducing key augmentations into the synthetic data pipeline: (1) random object positioning, (2) randomized rotations, and (3) grounding of objects, significantly enhancing generalization across poses and placements. To further address spatial relationships and occlusions in scenes with multiple objects, we implement a strategy to pair objects during dataset generation, resulting in a dataset robust enough to handle these complex scenarios. Achieving generalization to real-world scenes remains a challenge, so we introduce a three-stage training curriculum to develop the MirrorFusion 2.0 model to improve real-world performance. We provide extensive qualitative and quantitative evaluations to support our approach. The project page is available at: <a target="_blank" rel="noopener" href="https://mirror-verse.github.io/">https://mirror-verse.github.io/</a>. </p>
<blockquote>
<p>æ‰©æ•£æ¨¡å‹åœ¨å„ç§å›¾åƒç¼–è¾‘ä»»åŠ¡ä¸­å‘æŒ¥ç€æ ¸å¿ƒä½œç”¨ï¼Œä½†å®ƒä»¬å¾€å¾€ä¸èƒ½å®Œå…¨éµå®ˆç‰©ç†å®šå¾‹ï¼Œç‰¹åˆ«æ˜¯åœ¨é˜´å½±ã€åå°„å’Œé®æŒ¡ç­‰æ•ˆæœæ–¹é¢ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬è‡´åŠ›äºåˆ©ç”¨åŸºäºæ‰©æ•£çš„ç”Ÿæˆæ¨¡å‹ç”Ÿæˆé€¼çœŸçš„é•œé¢åå°„å›¾åƒã€‚å°½ç®¡æœ‰å¤§é‡çš„è®­ç»ƒæ•°æ®ï¼Œä½†ç°æœ‰çš„æ‰©æ•£æ¨¡å‹å¾€å¾€ä¼šå¿½ç•¥å¯¹çœŸå®é•œé¢åå°„è‡³å…³é‡è¦çš„ç»†å¾®ç»†èŠ‚ã€‚æœ€è¿‘çš„æ–¹æ³•è¯•å›¾é€šè¿‡åˆ›å»ºåˆæˆæ•°æ®é›†å¹¶å°†åå°„ç”Ÿæˆè§†ä¸ºå¡«å……ä»»åŠ¡æ¥è§£å†³è¿™ä¸ªé—®é¢˜ï¼›ç„¶è€Œï¼Œå®ƒä»¬åœ¨é•œå­ä¸åŒæ–¹å‘å’Œä½ç½®çš„æ³›åŒ–æ–¹é¢å­˜åœ¨å›°éš¾ã€‚æˆ‘ä»¬çš„æ–¹æ³•é€šè¿‡å‘åˆæˆæ•°æ®ç®¡é“ä¸­æ·»åŠ å…³é”®å¢å¼ºæ¥å…‹æœè¿™äº›é™åˆ¶ï¼šï¼ˆ1ï¼‰éšæœºå¯¹è±¡å®šä½ï¼Œï¼ˆ2ï¼‰éšæœºæ—‹è½¬ï¼Œï¼ˆ3ï¼‰å¯¹è±¡æ¥åœ°ï¼Œæ˜¾è‘—æé«˜äº†å§¿åŠ¿å’Œæ”¾ç½®çš„æ³›åŒ–èƒ½åŠ›ã€‚ä¸ºäº†è¿›ä¸€æ­¥è§£å†³å…·æœ‰å¤šä¸ªå¯¹è±¡çš„åœºæ™¯ä¸­çš„ç©ºé—´å…³ç³»å’Œé®æŒ¡é—®é¢˜ï¼Œæˆ‘ä»¬åœ¨æ•°æ®é›†ç”Ÿæˆè¿‡ç¨‹ä¸­å®ç°äº†å¯¹è±¡é…å¯¹ç­–ç•¥ï¼Œä»è€Œå¾—åˆ°ä¸€ä¸ªè¶³ä»¥åº”å¯¹è¿™äº›å¤æ‚åœºæ™¯çš„ç¨³å¥æ•°æ®é›†ã€‚å®ç°å‘çœŸå®ä¸–ç•Œåœºæ™¯çš„æ³›åŒ–ä»ç„¶æ˜¯ä¸€ä¸ªæŒ‘æˆ˜ï¼Œå› æ­¤æˆ‘ä»¬å¼•å…¥äº†ä¸€ä¸ªä¸‰é˜¶æ®µè®­ç»ƒè¯¾ç¨‹æ¥å¼€å‘MirrorFusion 2.0æ¨¡å‹ï¼Œä»¥æé«˜å…¶åœ¨ç°å®ä¸–ç•Œä¸­çš„æ€§èƒ½ã€‚æˆ‘ä»¬æä¾›äº†å¹¿æ³›çš„è´¨é‡å’Œæ•°é‡è¯„ä¼°æ¥æ”¯æŒæˆ‘ä»¬çš„æ–¹æ³•ã€‚é¡¹ç›®é¡µé¢å¯é€šè¿‡ä»¥ä¸‹ç½‘å€è®¿é—®ï¼š<a target="_blank" rel="noopener" href="https://mirror-verse.github.io/%E3%80%82">https://mirror-verse.github.io/ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.15397v1">PDF</a> Accepted to CVPR 2025. Project Page: <a target="_blank" rel="noopener" href="https://mirror-verse.github.io/">https://mirror-verse.github.io/</a></p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡è§£å†³äº†æ‰©æ•£æ¨¡å‹åœ¨ç”ŸæˆçœŸå®é•œé¢åå°„å›¾åƒæ—¶é¢ä¸´çš„æŒ‘æˆ˜ï¼Œé€šè¿‡å¼•å…¥å…³é”®å¢å¼ºæ‰‹æ®µï¼Œå¦‚éšæœºç‰©ä½“å®šä½ã€éšæœºæ—‹è½¬å’Œç‰©ä½“å®šä½ï¼Œæé«˜äº†æ¨¡å‹åœ¨ä¸åŒå§¿æ€å’Œæ”¾ç½®åœºæ™¯ä¸‹çš„æ³›åŒ–èƒ½åŠ›ã€‚ä¸ºè§£å†³å¤šç‰©ä½“åœºæ™¯ä¸­ç©ºé—´å…³ç³»å’Œé®æŒ¡é—®é¢˜ï¼Œé¡¹ç›®å®æ–½äº†é…å¯¹ç‰©ä½“ç”Ÿæˆæ•°æ®é›†ç­–ç•¥ã€‚ä¸ºæå‡ç°å®åœºæ™¯çš„æ³›åŒ–æ€§èƒ½ï¼Œè¿˜æ¨å‡ºäº†ä¸‰é˜¶æ®µè®­ç»ƒè¯¾ç¨‹æ¥å®Œå–„MirrorFusion 2.0æ¨¡å‹ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æ‰©æ•£æ¨¡å‹åœ¨å›¾åƒç¼–è¾‘ä»»åŠ¡ä¸­æ‰®æ¼”æ ¸å¿ƒè§’è‰²ï¼Œä½†åœ¨å¤„ç†é•œé¢åå°„ç­‰ç‰©ç†æ•ˆåº”æ—¶é¢ä¸´æŒ‘æˆ˜ã€‚</li>
<li>ç°æœ‰æ‰©æ•£æ¨¡å‹éš¾ä»¥æ•æ‰é•œé¢åå°„çš„ç»†å¾®ç»†èŠ‚ã€‚</li>
<li>ç°æœ‰æ–¹æ³•é€šè¿‡åˆ›å»ºåˆæˆæ•°æ®é›†å’Œå°†åå°„ç”Ÿæˆè§†ä¸ºè¡¥å…¨ä»»åŠ¡æ¥è§£å†³æ­¤é—®é¢˜ï¼Œä½†éš¾ä»¥æ³›åŒ–ä¸åŒç‰©ä½“ç›¸å¯¹äºé•œå­çš„æ–¹å‘å’Œä½ç½®ã€‚</li>
<li>æœ¬æ–‡é€šè¿‡å¼•å…¥éšæœºç‰©ä½“å®šä½ã€éšæœºæ—‹è½¬å’Œç‰©ä½“å®šä½å…³é”®å¢å¼ºæ‰‹æ®µï¼Œæé«˜äº†æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚</li>
<li>ä¸ºå¤„ç†å¤šç‰©ä½“åœºæ™¯ä¸­çš„ç©ºé—´å…³ç³»å’Œé®æŒ¡ï¼Œé¡¹ç›®å®æ–½äº†é…å¯¹ç‰©ä½“ç”Ÿæˆæ•°æ®é›†ç­–ç•¥ã€‚</li>
<li>ä¸ºæå‡åœ¨ç°å®åœºæ™¯çš„æ³›åŒ–æ€§èƒ½ï¼Œé‡‡ç”¨äº†ä¸‰é˜¶æ®µè®­ç»ƒè¯¾ç¨‹å®Œå–„æ¨¡å‹ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.15397">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-242dc16bb7312369d203405363d8069c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-aaddafa2e08e2c8b8034ae85038a2916.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a82cb68350be8d310ac2b3e1d7516602.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-5b1457aa11fdeb4afc3516d197806a9b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-da8b7429411347cf928870d8ace7012f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-723b7fe671ac0bcea665bdf63276adf6.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="VistaDepth-Frequency-Modulation-With-Bias-Reweighting-For-Enhanced-Long-Range-Depth-Estimation"><a href="#VistaDepth-Frequency-Modulation-With-Bias-Reweighting-For-Enhanced-Long-Range-Depth-Estimation" class="headerlink" title="VistaDepth: Frequency Modulation With Bias Reweighting For Enhanced   Long-Range Depth Estimation"></a>VistaDepth: Frequency Modulation With Bias Reweighting For Enhanced   Long-Range Depth Estimation</h2><p><strong>Authors:Mingxia Zhan, Li Zhang, Xiaomeng Chu, Beibei Wang</strong></p>
<p>Monocular depth estimation (MDE) aims to predict per-pixel depth values from a single RGB image. Recent advancements have positioned diffusion models as effective MDE tools by framing the challenge as a conditional image generation task. Despite their progress, these methods often struggle with accurately reconstructing distant depths, due largely to the imbalanced distribution of depth values and an over-reliance on spatial-domain features. To overcome these limitations, we introduce VistaDepth, a novel framework that integrates adaptive frequency-domain feature enhancements with an adaptive weight-balancing mechanism into the diffusion process. Central to our approach is the Latent Frequency Modulation (LFM) module, which dynamically refines spectral responses in the latent feature space, thereby improving the preservation of structural details and reducing noisy artifacts. Furthermore, we implement an adaptive weighting strategy that modulates the diffusion loss in real-time, enhancing the modelâ€™s sensitivity towards distant depth reconstruction. These innovations collectively result in superior depth perception performance across both distance and detail. Experimental evaluations confirm that VistaDepth achieves state-of-the-art performance among diffusion-based MDE techniques, particularly excelling in the accurate reconstruction of distant regions. </p>
<blockquote>
<p>å•çœ¼æ·±åº¦ä¼°è®¡ï¼ˆMDEï¼‰æ—¨åœ¨ä»å•ä¸ªRGBå›¾åƒé¢„æµ‹æ¯ä¸ªåƒç´ çš„æ·±åº¦å€¼ã€‚æœ€è¿‘çš„å‘å±•ä½¿æ‰©æ•£æ¨¡å‹æˆä¸ºæœ‰æ•ˆçš„MDEå·¥å…·ï¼Œå°†æŒ‘æˆ˜å®šä½ä¸ºæ¡ä»¶å›¾åƒç”Ÿæˆä»»åŠ¡ã€‚å°½ç®¡å–å¾—äº†è¿›å±•ï¼Œè¿™äº›æ–¹æ³•åœ¨å‡†ç¡®é‡å»ºè¿œè·ç¦»æ·±åº¦æ–¹é¢ä»é¢ä¸´å›°éš¾ï¼Œè¿™ä¸»è¦æ˜¯ç”±äºæ·±åº¦å€¼åˆ†å¸ƒä¸å¹³è¡¡ä»¥åŠè¿‡äºä¾èµ–ç©ºé—´åŸŸç‰¹å¾ã€‚ä¸ºäº†å…‹æœè¿™äº›é™åˆ¶ï¼Œæˆ‘ä»¬å¼•å…¥äº†VistaDepthï¼Œè¿™æ˜¯ä¸€ä¸ªæ–°å‹æ¡†æ¶ï¼Œå°†è‡ªé€‚åº”é¢‘åŸŸç‰¹å¾å¢å¼ºå’Œè‡ªé€‚åº”æƒé‡å¹³è¡¡æœºåˆ¶é›†æˆåˆ°æ‰©æ•£è¿‡ç¨‹ä¸­ã€‚æˆ‘ä»¬çš„æ–¹æ³•çš„æ ¸å¿ƒæ˜¯æ½œåœ¨é¢‘ç‡è°ƒåˆ¶ï¼ˆLFMï¼‰æ¨¡å—ï¼Œå®ƒåŠ¨æ€åœ°ä¼˜åŒ–æ½œåœ¨ç‰¹å¾ç©ºé—´ä¸­çš„å…‰è°±å“åº”ï¼Œä»è€Œæé«˜ç»“æ„ç»†èŠ‚çš„ä¿ç•™ï¼Œå‡å°‘å™ªå£°ä¼ªå½±ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å®ç°äº†å®æ—¶è°ƒæ•´æ‰©æ•£æŸå¤±çš„è‡ªé€‚åº”åŠ æƒç­–ç•¥ï¼Œæé«˜æ¨¡å‹å¯¹è¿œè·ç¦»æ·±åº¦é‡å»ºçš„æ•æ„Ÿæ€§ã€‚è¿™äº›åˆ›æ–°å…±åŒå¸¦æ¥äº†åœ¨è·ç¦»å’Œç»†èŠ‚æ–¹é¢çš„å“è¶Šæ·±åº¦æ„ŸçŸ¥æ€§èƒ½ã€‚å®éªŒè¯„ä¼°è¯å®ï¼ŒVistaDepthåœ¨åŸºäºæ‰©æ•£çš„MDEæŠ€æœ¯ä¸­å®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œç‰¹åˆ«æ˜¯åœ¨å‡†ç¡®é‡å»ºè¿œè·ç¦»åŒºåŸŸæ–¹é¢è¡¨ç°å‡ºè‰²ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.15095v2">PDF</a> 8 pages, 6 figures, 4 tables</p>
<p><strong>Summary</strong></p>
<p>æ‰©æ•£æ¨¡å‹åœ¨å•ç›®æ·±åº¦ä¼°è®¡ï¼ˆMDEï¼‰ä¸­å±•ç°å‡ºè‰¯å¥½çš„æ€§èƒ½ï¼Œä½†å­˜åœ¨å¯¹è¿œè·ç¦»æ·±åº¦é‡å»ºçš„ä¸å‡†ç¡®é—®é¢˜ã€‚ä¸ºæ­¤ï¼ŒVistaDepthæ¡†æ¶å¼•å…¥è‡ªé€‚åº”é¢‘åŸŸç‰¹å¾å¢å¼ºå’Œè‡ªé€‚åº”æƒé‡å¹³è¡¡æœºåˆ¶ã€‚å…¶æ ¸å¿ƒæ¨¡å—â€”â€”æ½œåœ¨é¢‘ç‡è°ƒåˆ¶ï¼ˆLFMï¼‰èƒ½åŠ¨æ€ä¼˜åŒ–æ½œåœ¨ç‰¹å¾ç©ºé—´çš„é¢‘è°±å“åº”ï¼Œæé«˜ç»“æ„ç»†èŠ‚ä¿ç•™å¹¶å‡å°‘å™ªå£°ã€‚æ­¤å¤–ï¼Œå®æ–½è‡ªé€‚åº”æƒé‡ç­–ç•¥å®æ—¶è°ƒæ•´æ‰©æ•£æŸå¤±ï¼Œæå‡æ¨¡å‹å¯¹è¿œè·ç¦»æ·±åº¦çš„æ•æ„Ÿåº¦ã€‚è¿™äº›åˆ›æ–°ä½¿VistaDepthåœ¨è·ç¦»å’Œç»†èŠ‚ä¸Šçš„æ·±åº¦æ„ŸçŸ¥æ€§èƒ½å‡è¾¾åˆ°é¢†å…ˆæ°´å¹³ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æ‰©æ•£æ¨¡å‹åœ¨å•ç›®æ·±åº¦ä¼°è®¡ä¸­è¡¨ç°å‡ºè‰¯å¥½çš„æ€§èƒ½ã€‚</li>
<li>ç°æœ‰æ–¹æ³•å­˜åœ¨å¯¹è¿œè·ç¦»æ·±åº¦é‡å»ºçš„ä¸å‡†ç¡®é—®é¢˜ã€‚</li>
<li>VistaDepthæ¡†æ¶å¼•å…¥æ½œåœ¨é¢‘ç‡è°ƒåˆ¶ï¼ˆLFMï¼‰æ¨¡å—ï¼Œæé«˜ç»“æ„ç»†èŠ‚ä¿ç•™å¹¶å‡å°‘å™ªå£°ã€‚</li>
<li>VistaDepthä½¿ç”¨è‡ªé€‚åº”é¢‘åŸŸç‰¹å¾å¢å¼ºå’Œè‡ªé€‚åº”æƒé‡å¹³è¡¡æœºåˆ¶æ¥æ”¹å–„æ‰©æ•£æ¨¡å‹çš„æ€§èƒ½ã€‚</li>
<li>æ½œåœ¨é¢‘ç‡è°ƒåˆ¶èƒ½å¤ŸåŠ¨æ€ä¼˜åŒ–æ½œåœ¨ç‰¹å¾ç©ºé—´çš„é¢‘è°±å“åº”ã€‚</li>
<li>è‡ªé€‚åº”æƒé‡ç­–ç•¥å¯å®æ—¶è°ƒæ•´æ‰©æ•£æŸå¤±ï¼Œæé«˜å¯¹è¿œè·ç¦»æ·±åº¦çš„æ•æ„Ÿåº¦ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.15095">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-6e9541719030f61d80cf36ea1e700f67.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-72cda878b092ffe90a7ac0e1850b497a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-2e61bd7439e03175edb293be32c720b7.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-aada7c6e3a3d4d7c7ab217b83811009b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d38f9f6803a7a066c6cf2b5a5a508534.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="Gungnir-Exploiting-Stylistic-Features-in-Images-for-Backdoor-Attacks-on-Diffusion-Models"><a href="#Gungnir-Exploiting-Stylistic-Features-in-Images-for-Backdoor-Attacks-on-Diffusion-Models" class="headerlink" title="Gungnir: Exploiting Stylistic Features in Images for Backdoor Attacks on   Diffusion Models"></a>Gungnir: Exploiting Stylistic Features in Images for Backdoor Attacks on   Diffusion Models</h2><p><strong>Authors:Yu Pan, Bingrong Dai, Jiahao Chen, Lin Wang, Yi Du, Jiao Liu</strong></p>
<p>In recent years, Diffusion Models (DMs) have demonstrated significant advances in the field of image generation. However, according to current research, DMs are vulnerable to backdoor attacks, which allow attackers to control the modelâ€™s output by inputting data containing covert triggers, such as a specific visual patch or phrase. Existing defense strategies are well equipped to thwart such attacks through backdoor detection and trigger inversion because previous attack methods are constrained by limited input spaces and low-dimensional triggers. For example, visual triggers are easily observed by defenders, text-based or attention-based triggers are more susceptible to neural network detection. To explore more possibilities of backdoor attack in DMs, we propose Gungnir, a novel method that enables attackers to activate the backdoor in DMs through style triggers within input images. Our approach proposes using stylistic features as triggers for the first time and implements backdoor attacks successfully in image-to-image tasks by introducing Reconstructing-Adversarial Noise (RAN) and Short-Term Timesteps-Retention (STTR). Our technique generates trigger-embedded images that are perceptually indistinguishable from clean images, thus bypassing both manual inspection and automated detection neural networks. Experiments demonstrate that Gungnir can easily bypass existing defense methods. Among existing DM defense frameworks, our approach achieves a 0 backdoor detection rate (BDR). Our codes are available at <a target="_blank" rel="noopener" href="https://github.com/paoche11/Gungnir">https://github.com/paoche11/Gungnir</a>. </p>
<blockquote>
<p>è¿‘å¹´æ¥ï¼Œæ‰©æ•£æ¨¡å‹ï¼ˆDMsï¼‰åœ¨å›¾ç”Ÿæˆé¢†åŸŸå–å¾—äº†æ˜¾è‘—è¿›å±•ã€‚ç„¶è€Œï¼Œæ ¹æ®ç›®å‰çš„ç ”ç©¶ï¼ŒDMså®¹æ˜“å—åˆ°åé—¨æ”»å‡»çš„å½±å“ï¼Œæ”»å‡»è€…å¯ä»¥é€šè¿‡è¾“å…¥åŒ…å«éšè”½è§¦å‘å™¨çš„æ•°æ®æ¥æ§åˆ¶æ¨¡å‹çš„è¾“å‡ºï¼Œä¾‹å¦‚ç‰¹å®šçš„è§†è§‰æ–‘å—æˆ–çŸ­è¯­ã€‚ç°æœ‰çš„é˜²å¾¡ç­–ç•¥èƒ½å¤Ÿé€šè¿‡åé—¨æ£€æµ‹å’Œè§¦å‘åè½¬æ¥æœ‰æ•ˆåœ°é˜»æ­¢æ­¤ç±»æ”»å‡»ï¼Œå› ä¸ºä»¥å‰çš„æ”»å‡»æ–¹æ³•å—åˆ°è¾“å…¥ç©ºé—´æœ‰é™å’Œä½ç»´è§¦å‘çš„é™åˆ¶ã€‚ä¾‹å¦‚ï¼Œè§†è§‰è§¦å‘å™¨å¾ˆå®¹æ˜“è¢«é˜²å¾¡è€…è§‚å¯Ÿåˆ°ï¼Œè€ŒåŸºäºæ–‡æœ¬æˆ–åŸºäºæ³¨æ„åŠ›çš„è§¦å‘å™¨æ›´å®¹æ˜“å—åˆ°ç¥ç»ç½‘ç»œæ£€æµ‹ã€‚ä¸ºäº†æ¢ç´¢DMä¸­åé—¨æ”»å‡»çš„å¯èƒ½æ€§ï¼Œæˆ‘ä»¬æå‡ºäº†Gungnirè¿™ä¸€æ–°æ–¹æ³•ï¼Œå®ƒèƒ½å¤Ÿè®©æ”»å‡»è€…é€šè¿‡è¾“å…¥å›¾åƒå†…çš„é£æ ¼è§¦å‘å™¨åœ¨DMsä¸­æ¿€æ´»åé—¨ã€‚æˆ‘ä»¬çš„æ–¹æ³•é¦–æ¬¡æå‡ºä½¿ç”¨é£æ ¼ç‰¹å¾ä½œä¸ºè§¦å‘å™¨ï¼Œå¹¶é€šè¿‡å¼•å…¥é‡å»ºå¯¹æŠ—å™ªå£°ï¼ˆRANï¼‰å’ŒçŸ­æœŸæ—¶é—´æ­¥ä¿ç•™ï¼ˆSTTRï¼‰æˆåŠŸåœ°åœ¨å›¾åƒåˆ°å›¾åƒä»»åŠ¡ä¸­å®ç°åé—¨æ”»å‡»ã€‚æˆ‘ä»¬çš„æŠ€æœ¯ç”Ÿæˆäº†åµŒå…¥è§¦å‘å™¨çš„å›¾åƒï¼Œè¿™äº›å›¾åƒåœ¨æ„ŸçŸ¥ä¸Šä¸å¹²å‡€å›¾åƒæ— æ³•åŒºåˆ†ï¼Œä»è€Œç»•è¿‡äº†æ‰‹åŠ¨æ£€æŸ¥å’Œè‡ªåŠ¨æ£€æµ‹ç¥ç»ç½‘ç»œã€‚å®éªŒè¡¨æ˜ï¼ŒGungnirå¯ä»¥è½»æ¾ç»•è¿‡ç°æœ‰é˜²å¾¡æ–¹æ³•ã€‚åœ¨ç°æœ‰çš„DMé˜²å¾¡æ¡†æ¶ä¸­ï¼Œæˆ‘ä»¬çš„æ–¹æ³•å®ç°äº†0åé—¨æ£€æµ‹ç‡ï¼ˆBDRï¼‰ã€‚æˆ‘ä»¬çš„ä»£ç å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/paoche11/Gungnir%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/paoche11/Gungniræ‰¾åˆ°ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.20650v2">PDF</a> </p>
<p><strong>Summary</strong><br>     æ‰©æ•£æ¨¡å‹ï¼ˆDMsï¼‰åœ¨å›¾åƒç”Ÿæˆé¢†åŸŸå–å¾—äº†æ˜¾è‘—è¿›å±•ï¼Œä½†è¿‘æœŸç ”ç©¶å‘ç°å…¶å­˜åœ¨åé—¨æ”»å‡»æ¼æ´ã€‚æ”»å‡»è€…å¯é€šè¿‡è¾“å…¥å«æœ‰éšè”½è§¦å‘å™¨çš„æ•°æ®æ¥æ§åˆ¶æ¨¡å‹è¾“å‡ºã€‚ç°æœ‰é˜²å¾¡ç­–ç•¥å¯é€šè¿‡åé—¨æ£€æµ‹å’Œè§¦å‘é€†è½¬æ¥é˜»æ­¢æ­¤ç±»æ”»å‡»ã€‚ä¸ºæ¢ç´¢æ‰©æ•£æ¨¡å‹ä¸­åé—¨æ”»å‡»çš„æ–°å¯èƒ½æ€§ï¼Œæå‡ºä¸€ç§æ–°æ–¹æ³•Gungnirï¼Œè¯¥æ–¹æ³•åˆ©ç”¨é£æ ¼è§¦å‘å™¨åœ¨è¾“å…¥å›¾åƒä¸­å®ç°åé—¨æ¿€æ´»ã€‚GungniræˆåŠŸåœ¨å›¾åƒåˆ°å›¾åƒçš„ä»»åŠ¡ä¸­å®æ–½åé—¨æ”»å‡»ï¼Œé€šè¿‡å¼•å…¥é‡å»ºå¯¹æŠ—å™ªå£°ï¼ˆRANï¼‰å’ŒçŸ­æœŸæ—¶é—´æ­¥ä¿ç•™ï¼ˆSTTRï¼‰ï¼Œç”Ÿæˆå«æœ‰è§¦å‘å™¨çš„å›¾åƒï¼Œè¿™äº›å›¾åƒä¸å¹²å‡€å›¾åƒåœ¨æ„ŸçŸ¥ä¸Šæ— æ³•åŒºåˆ†ï¼Œä»è€Œç»•è¿‡æ‰‹åŠ¨æ£€æŸ¥å’Œè‡ªåŠ¨æ£€æµ‹ç¥ç»ç½‘ç»œã€‚å®éªŒè¡¨æ˜ï¼ŒGungnirå¯ä»¥è½»æ¾ç»•è¿‡ç°æœ‰é˜²å¾¡æ–¹æ³•ï¼Œå®ç°é›¶åé—¨æ£€æµ‹ç‡ï¼ˆBDRï¼‰ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æ‰©æ•£æ¨¡å‹ï¼ˆDMsï¼‰åœ¨å›¾åƒç”Ÿæˆé¢†åŸŸè¡¨ç°ä¼˜å¼‚ï¼Œä½†å­˜åœ¨åé—¨æ”»å‡»æ¼æ´ã€‚</li>
<li>ç°æœ‰é˜²å¾¡ç­–ç•¥èƒ½é€šè¿‡åé—¨æ£€æµ‹å’Œè§¦å‘é€†è½¬æ¥é˜»æ­¢æ”»å‡»ã€‚</li>
<li>Gungniræ˜¯ä¸€ç§æ–°çš„æ”»å‡»æ–¹æ³•ï¼Œé€šè¿‡é£æ ¼è§¦å‘å™¨åœ¨è¾“å…¥å›¾åƒä¸­å®ç°åé—¨æ¿€æ´»ã€‚</li>
<li>GungniræˆåŠŸåœ¨å›¾åƒåˆ°å›¾åƒçš„ä»»åŠ¡ä¸­å®æ–½åé—¨æ”»å‡»ï¼Œç”Ÿæˆè§¦å‘åµŒå…¥å›¾åƒï¼Œè¿™äº›å›¾åƒä¸å¹²å‡€å›¾åƒéš¾ä»¥åŒºåˆ†ã€‚</li>
<li>Gungniræ–¹æ³•ç»•è¿‡ç°æœ‰é˜²å¾¡æ–¹æ³•ï¼Œå®ç°é›¶åé—¨æ£€æµ‹ç‡ï¼ˆBDRï¼‰ã€‚</li>
<li>Gungnirä»£ç å·²å…¬å¼€å¯ç”¨ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.20650">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-fff9ed6673e4b713df3f3206b7d2b529.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-cc1a2d8ccf2256a2a2857c9ba590e20d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-5bab06f9fc547a0b2c40652a0533ac66.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a81fca22a2eff8388dc126313d3c966d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-aff4cb75641dfb8a32e6796489f219df.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="On-the-Guidance-of-Flow-Matching"><a href="#On-the-Guidance-of-Flow-Matching" class="headerlink" title="On the Guidance of Flow Matching"></a>On the Guidance of Flow Matching</h2><p><strong>Authors:Ruiqi Feng, Tailin Wu, Chenglei Yu, Wenhao Deng, Peiyan Hu</strong></p>
<p>Flow matching has shown state-of-the-art performance in various generative tasks, ranging from image generation to decision-making, where guided generation is pivotal. However, the guidance of flow matching is more general than and thus substantially different from that of its predecessor, diffusion models. Therefore, the challenge in guidance for general flow matching remains largely underexplored. In this paper, we propose the first framework of general guidance for flow matching. From this framework, we derive a family of guidance techniques that can be applied to general flow matching. These include a new training-free asymptotically exact guidance, novel training losses for training-based guidance, and two classes of approximate guidance that cover classical gradient guidance methods as special cases. We theoretically investigate these different methods to give a practical guideline for choosing suitable methods in different scenarios. Experiments on synthetic datasets, image inverse problems, and offline reinforcement learning demonstrate the effectiveness of our proposed guidance methods and verify the correctness of our flow matching guidance framework. Code to reproduce the experiments can be found at <a target="_blank" rel="noopener" href="https://github.com/AI4Science-WestlakeU/flow_guidance">https://github.com/AI4Science-WestlakeU/flow_guidance</a>. </p>
<blockquote>
<p>æµåŒ¹é…åœ¨å„ç§ç”Ÿæˆä»»åŠ¡ä¸­è¡¨ç°å‡ºäº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œä»å›¾åƒç”Ÿæˆåˆ°å†³ç­–åˆ¶å®šï¼Œå…¶ä¸­å¼•å¯¼ç”Ÿæˆæ˜¯å…³é”®ã€‚ç„¶è€Œï¼ŒæµåŒ¹é…çš„æŒ‡å¯¼æ›´åŠ é€šç”¨ï¼Œå› æ­¤ä¸å…¶å‰èº«æ‰©æ•£æ¨¡å‹æœ‰ç€æ˜¾è‘—å·®å¼‚ã€‚å› æ­¤ï¼Œé€šç”¨æµåŒ¹é…çš„æŒ‡å¯¼æŒ‘æˆ˜ä»ç„¶è¢«å¤§å¤§å¿½è§†ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†æµåŒ¹é…é€šç”¨æŒ‡å¯¼æ¡†æ¶ã€‚åœ¨æ­¤æ¡†æ¶çš„åŸºç¡€ä¸Šï¼Œæˆ‘ä»¬æ¨å¯¼å‡ºäº†ä¸€ç³»åˆ—å¯åº”ç”¨äºé€šç”¨æµåŒ¹é…çš„æŒ‡å¯¼æŠ€æœ¯ã€‚è¿™åŒ…æ‹¬ä¸€ç§æ–°çš„æ— éœ€è®­ç»ƒå³å¯æ¸è¿‘ç²¾ç¡®æŒ‡å¯¼ã€ç”¨äºåŸºäºè®­ç»ƒæŒ‡å¯¼çš„æ–°è®­ç»ƒæŸå¤±ï¼Œä»¥åŠä¸¤ç±»æ¶µç›–ç»å…¸æ¢¯åº¦æŒ‡å¯¼æ–¹æ³•ä¸ºç‰¹æ®Šæƒ…å†µçš„è¿‘ä¼¼æŒ‡å¯¼ã€‚æˆ‘ä»¬ä»ç†è®ºä¸Šæ¢è®¨äº†è¿™äº›æ–¹æ³•ï¼Œä¸ºä¸åŒåœºæ™¯é€‰æ‹©é€‚å½“çš„æ–¹æ³•æä¾›äº†å®ç”¨æŒ‡å—ã€‚åœ¨åˆæˆæ•°æ®é›†ã€å›¾åƒåé—®é¢˜å’Œç¦»çº¿å¼ºåŒ–å­¦ä¹ ä¸Šçš„å®éªŒè¯æ˜äº†æˆ‘ä»¬æå‡ºçš„æŒ‡å¯¼æ–¹æ³•çš„æœ‰æ•ˆæ€§ï¼Œå¹¶éªŒè¯äº†æˆ‘ä»¬çš„æµåŒ¹é…æŒ‡å¯¼æ¡†æ¶çš„æ­£ç¡®æ€§ã€‚å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/AI4Science-WestlakeU/flow_guidance%E6%89%BE%E5%88%B0%E9%87%8D%E7%8E%B0%E5%AE%9E%E9%AA%8C%E7%9A%84%E6%BA%90%E4%BB%A3%E7%A0%81%E3%80%82">https://github.com/AI4Science-WestlakeU/flow_guidanceæ‰¾åˆ°é‡ç°å®éªŒçš„æºä»£ç ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.02150v2">PDF</a> 35 pages, 7 figures</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºäº†é’ˆå¯¹æµåŒ¹é…æŠ€æœ¯çš„é€šç”¨æŒ‡å¯¼æ¡†æ¶ï¼Œæ¶µç›–æ— è®­ç»ƒæŒ‡å¯¼æ–¹æ³•ã€åŸºäºè®­ç»ƒçš„æ–°æŸå¤±å‡½æ•°æŒ‡å¯¼æ–¹æ³•ä»¥åŠåŒ…å«ä¼ ç»Ÿæ¢¯åº¦æŒ‡å¯¼æ–¹æ³•çš„è¿‘ä¼¼æŒ‡å¯¼æ–¹æ³•ä¸¤ç±»ã€‚é€šè¿‡å¯¹ä¸åŒæ–¹æ³•çš„ç†è®ºåˆ†æï¼Œç»™å‡ºäº†åœ¨å®é™…åœºæ™¯ä¸­é€‰å–åˆé€‚æ–¹æ³•çš„å®ç”¨æŒ‡å—ã€‚å®éªŒè¯æ˜ï¼Œè¯¥æŒ‡å¯¼æ¡†æ¶èƒ½æœ‰æ•ˆåº”ç”¨äºåˆæˆæ•°æ®é›†ã€å›¾åƒé€†é—®é¢˜å’Œç¦»çº¿å¼ºåŒ–å­¦ä¹ ç­‰é¢†åŸŸã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æµåŒ¹é…æŠ€æœ¯åœ¨ç”Ÿæˆä»»åŠ¡ä¸­å±•ç°å‡ºå“è¶Šæ€§èƒ½ï¼Œå…¶åº”ç”¨èŒƒå›´ä»å›¾åƒç”Ÿæˆåˆ°å†³ç­–åˆ¶å®šä¸ç­‰ã€‚</li>
<li>æµåŒ¹é…çš„æŒ‡å¯¼ç†å¿µä¸å…¶å‰èº«æ‰©æ•£æ¨¡å‹æœ‰æ˜¾è‘—åŒºåˆ«ï¼Œä½†åè€…ç¼ºä¹é€šç”¨æŒ‡å¯¼æ¡†æ¶ã€‚</li>
<li>æå‡ºé¦–ä¸ªé’ˆå¯¹æµåŒ¹é…çš„é€šç”¨æŒ‡å¯¼æ¡†æ¶ï¼Œæ¶µç›–å¤šç§æŒ‡å¯¼æŠ€æœ¯ã€‚</li>
<li>å¼•å…¥æ— è®­ç»ƒæŒ‡å¯¼æ–¹æ³•ï¼ŒåŒ…æ‹¬æ–°çš„æ¸è¿›ç²¾ç¡®æŒ‡å¯¼æŠ€æœ¯ã€‚</li>
<li>æå‡ºæ–°çš„åŸºäºè®­ç»ƒæŸå¤±å‡½æ•°çš„æ–¹æ³•ä½œä¸ºå¦ä¸€ç§æŒ‡å¯¼æŠ€æœ¯ã€‚</li>
<li>æŒ‡å¯¼æ¡†æ¶åŒ…æ‹¬è¿‘ä¼¼æ–¹æ³•ï¼ŒåŒ…å«ä¼ ç»Ÿçš„æ¢¯åº¦æŒ‡å¯¼æ–¹æ³•ä½œä¸ºç‰¹ä¾‹ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.02150">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-eeec81ef3c2019669004f143eaeb4b1e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-01c5e75ae464f67c34055a16db596472.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a8a3e41427cae22bb2efb6e00eeeb8eb.jpg" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="An-Undetectable-Watermark-for-Generative-Image-Models"><a href="#An-Undetectable-Watermark-for-Generative-Image-Models" class="headerlink" title="An Undetectable Watermark for Generative Image Models"></a>An Undetectable Watermark for Generative Image Models</h2><p><strong>Authors:Sam Gunn, Xuandong Zhao, Dawn Song</strong></p>
<p>We present the first undetectable watermarking scheme for generative image models. Undetectability ensures that no efficient adversary can distinguish between watermarked and un-watermarked images, even after making many adaptive queries. In particular, an undetectable watermark does not degrade image quality under any efficiently computable metric. Our scheme works by selecting the initial latents of a diffusion model using a pseudorandom error-correcting code (Christ and Gunn, 2024), a strategy which guarantees undetectability and robustness. We experimentally demonstrate that our watermarks are quality-preserving and robust using Stable Diffusion 2.1. Our experiments verify that, in contrast to every prior scheme we tested, our watermark does not degrade image quality. Our experiments also demonstrate robustness: existing watermark removal attacks fail to remove our watermark from images without significantly degrading the quality of the images. Finally, we find that we can robustly encode 512 bits in our watermark, and up to 2500 bits when the images are not subjected to watermark removal attacks. Our code is available at <a target="_blank" rel="noopener" href="https://github.com/XuandongZhao/PRC-Watermark">https://github.com/XuandongZhao/PRC-Watermark</a>. </p>
<blockquote>
<p>æˆ‘ä»¬ä¸ºç”Ÿæˆå›¾åƒæ¨¡å‹æå‡ºäº†ç¬¬ä¸€ä¸ªä¸å¯æ£€æµ‹çš„æ°´å°æ–¹æ¡ˆã€‚ä¸å¯æ£€æµ‹æ€§ç¡®ä¿é«˜æ•ˆçš„å¯¹æ‰‹å³ä½¿åœ¨æ‰§è¡Œå¤šæ¬¡è‡ªé€‚åº”æŸ¥è¯¢åï¼Œä¹Ÿæ— æ³•åŒºåˆ†å¸¦æ°´å°å’Œä¸å¸¦æ°´å°çš„å›¾åƒã€‚ç‰¹åˆ«æ˜¯ï¼Œä¸å¯æ£€æµ‹çš„æ°´å°åœ¨ä»»ä½•å¯é«˜æ•ˆè®¡ç®—çš„æŒ‡æ ‡ä¸‹éƒ½ä¸ä¼šé™ä½å›¾åƒè´¨é‡ã€‚æˆ‘ä»¬çš„æ–¹æ¡ˆé€šè¿‡é€‰æ‹©æ‰©æ•£æ¨¡å‹çš„åˆå§‹æ½œåœ¨å˜é‡æ¥å®ç°ï¼Œæ–¹æ³•æ˜¯ä½¿ç”¨ä¼ªéšæœºçº é”™ä»£ç ï¼ˆChristå’ŒGunnï¼Œ2024ï¼‰ï¼Œè¿™ä¸€ç­–ç•¥å¯ä»¥ä¿è¯ä¸å¯æ£€æµ‹æ€§å’Œç¨³å¥æ€§ã€‚æˆ‘ä»¬é€šè¿‡Stable Diffusion 2.1è¿›è¡Œå®éªŒï¼Œè¯æ˜æˆ‘ä»¬çš„æ°´å°è´¨é‡ä¿æŒä¸å˜ä¸”ç¨³å¥ã€‚æˆ‘ä»¬çš„å®éªŒéªŒè¯äº†æˆ‘ä»¬æ‰€æµ‹è¯•çš„æ¯ä¸ªå…ˆå‰æ–¹æ¡ˆç›¸åï¼Œæˆ‘ä»¬çš„æ°´å°ä¸ä¼šé™ä½å›¾åƒè´¨é‡ã€‚æˆ‘ä»¬çš„å®éªŒè¿˜è¯æ˜äº†å…¶ç¨³å¥æ€§ï¼šç°æœ‰çš„æ°´å°ç§»é™¤æ”»å‡»æ— æ³•åœ¨æˆ‘ä»¬çš„æ°´å°ä»å›¾åƒä¸­ç§»é™¤è€Œä¸æ˜¾è‘—é™ä½å›¾åƒè´¨é‡ã€‚æœ€åï¼Œæˆ‘ä»¬å‘ç°æˆ‘ä»¬å¯ä»¥ç¨³å¥åœ°åœ¨æ°´å°ä¸­ç¼–ç 512ä½ä¿¡æ¯ï¼Œå¹¶ä¸”åœ¨å›¾åƒæœªå—åˆ°æ°´å°ç§»é™¤æ”»å‡»æ—¶ï¼Œç”šè‡³å¯ä»¥ç¼–ç é«˜è¾¾2500ä½ä¿¡æ¯ã€‚æˆ‘ä»¬çš„ä»£ç å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/XuandongZhao/PRC-Watermark">https://github.com/XuandongZhao/PRC-Watermark</a>å¤„è·å–ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2410.07369v4">PDF</a> ICLR 2025</p>
<p><strong>Summary</strong><br>     æœ¬æ–‡æå‡ºé¦–ä¸ªé’ˆå¯¹ç”Ÿæˆå›¾åƒæ¨¡å‹çš„ä¸å¯æ£€æµ‹æ°´å°æ–¹æ¡ˆã€‚è¯¥æ–¹æ¡ˆä¿è¯äº†ä¸å¯æ£€æµ‹æ€§ï¼Œå³ä½¿è¿›è¡Œå¤šæ¬¡è‡ªé€‚åº”æŸ¥è¯¢ï¼Œé«˜æ•ˆå¯¹æ‰‹ä¹Ÿæ— æ³•åŒºåˆ†å¸¦æ°´å°å’Œä¸å¸¦æ°´å°çš„å›¾åƒã€‚æ°´å°é€šè¿‡åœ¨æ‰©æ•£æ¨¡å‹çš„åˆå§‹æ½œåœ¨è¡¨ç¤ºä¸­ä½¿ç”¨ä¼ªéšæœºçº é”™ç å®ç°ï¼Œç¡®ä¿äº†ä¸å¯æ£€æµ‹æ€§å’Œç¨³å¥æ€§ã€‚å®éªŒè¯æ˜è¯¥æ°´å°è´¨é‡æ— æŸä¸”ç¨³å¥ï¼Œä½¿ç”¨Stable Diffusion 2.1éªŒè¯ã€‚å¯¹æ¯”å…¶ä»–æµ‹è¯•æ–¹æ¡ˆï¼Œè¯¥æ°´å°ä¸ä¼šé™ä½å›¾åƒè´¨é‡ï¼Œå¹¶ä¸”å…·æœ‰å¼ºå¤§çš„ç¨³å¥æ€§ã€‚åŒæ—¶ï¼Œå¯åœ¨æ°´å°ä¸­ç¨³å¥ç¼–ç 512ä½ä¿¡æ¯ï¼Œè‹¥å›¾åƒæœªé­å—æ°´å°ç§»é™¤æ”»å‡»ï¼Œåˆ™å¯ç¼–ç é«˜è¾¾2500ä½ä¿¡æ¯ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æå‡ºé¦–ä¸ªé’ˆå¯¹ç”Ÿæˆå›¾åƒæ¨¡å‹çš„ä¸å¯æ£€æµ‹æ°´å°æ–¹æ¡ˆã€‚</li>
<li>ä¸å¯æ£€æµ‹æ°´å°ä¿è¯äº†é«˜æ•ˆå¯¹æ‰‹æ— æ³•åŒºåˆ†å¸¦æ°´å°å’Œä¸å¸¦æ°´å°çš„å›¾åƒã€‚</li>
<li>ä½¿ç”¨ä¼ªéšæœºçº é”™ç å®ç°æ°´å°ï¼Œç¡®ä¿ä¸å¯æ£€æµ‹æ€§å’Œç¨³å¥æ€§ã€‚</li>
<li>å®éªŒè¯æ˜æ°´å°è´¨é‡æ— æŸï¼Œä¸ä¼šé™ä½å›¾åƒè´¨é‡ã€‚</li>
<li>æ°´å°å…·æœ‰å¼ºå¤§çš„ç¨³å¥æ€§ï¼Œç°æœ‰æ°´å°ç§»é™¤æ”»å‡»æ— æ³•å»é™¤è¯¥æ°´å°è€Œä¸æ˜¾è‘—ç ´åå›¾åƒè´¨é‡ã€‚</li>
<li>å¯ç¨³å¥åœ°åœ¨æ°´å°ä¸­ç¼–ç 512ä½ä¿¡æ¯ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2410.07369">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-30720469f3974817785ba522061ffe72.jpg" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-04-24/Diffusion%20Models/">https://kedreamix.github.io/Talk2Paper/Paper/2025-04-24/Diffusion%20Models/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/Diffusion-Models/">
                                    <span class="chip bg-color">Diffusion Models</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-04-24/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/">
                    <div class="card-image">
                        
                        <img src="https://pica.zhimg.com/v2-df60ede95705bc7bb12f8536a0c30ccb.jpg" class="responsive-img" alt="åŒ»å­¦å›¾åƒ">
                        
                        <span class="card-title">åŒ»å­¦å›¾åƒ</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            åŒ»å­¦å›¾åƒ æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-04-24  Rotational ultrasound and photoacoustic tomography of the human body
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-04-24
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/" class="post-category">
                                    åŒ»å­¦å›¾åƒ
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/">
                        <span class="chip bg-color">åŒ»å­¦å›¾åƒ</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-04-24/NeRF/">
                    <div class="card-image">
                        
                        <img src="https://pic1.zhimg.com/v2-0e7789b6d465b30f994c1840f140c433.jpg" class="responsive-img" alt="NeRF">
                        
                        <span class="card-title">NeRF</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            NeRF æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-04-24  Pose Optimization for Autonomous Driving Datasets using Neural Rendering   Models
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-04-24
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/NeRF/" class="post-category">
                                    NeRF
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/NeRF/">
                        <span class="chip bg-color">NeRF</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">24595.3k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
