<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Agent">
    <meta name="description" content="Agent 方向最新论文已更新，请持续关注 Update in 2025-09-17  Agentic Temporal Graph of Reasoning with Multimodal Language Models A   Potential AI Aid to Healthcare">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>Agent | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loader页面消失采用渐隐的方式*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logo出现动画 */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//使用渐隐的方法淡出loading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//强制显示loading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">嘘~  正在从服务器偷取页面 . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>首页</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>标签</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>分类</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>归档</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="搜索" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="深色/浅色模式" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			首页
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			标签
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			分类
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			归档
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('D:\MyBlog\AutoFX\arxiv\2025-09-17\./crop_Agent/2509.11944v1/page_2_0.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Agent</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/Agent/">
                                <span class="chip bg-color">Agent</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/Agent/" class="post-category">
                                Agent
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2025-09-17
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>更新日期:&nbsp;&nbsp;
                    2025-09-22
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp;
                    11.9k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp;
                    48 分
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>阅读次数:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>⚠️ 以下所有内容总结都来自于 大语言模型的能力，如有错误，仅供参考，谨慎使用<br>🔴 请注意：千万不要用于严肃的学术场景，只能用于论文阅读前的初筛！<br>💗 如果您觉得我们的项目对您有帮助 <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ，还请您给我们一些鼓励！⭐️ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFace免费体验</a></p>
</blockquote>
<h1 id="2025-09-17-更新"><a href="#2025-09-17-更新" class="headerlink" title="2025-09-17 更新"></a>2025-09-17 更新</h1><h2 id="Agentic-Temporal-Graph-of-Reasoning-with-Multimodal-Language-Models-A-Potential-AI-Aid-to-Healthcare"><a href="#Agentic-Temporal-Graph-of-Reasoning-with-Multimodal-Language-Models-A-Potential-AI-Aid-to-Healthcare" class="headerlink" title="Agentic Temporal Graph of Reasoning with Multimodal Language Models: A   Potential AI Aid to Healthcare"></a>Agentic Temporal Graph of Reasoning with Multimodal Language Models: A   Potential AI Aid to Healthcare</h2><p><strong>Authors:Susanta Mitra</strong></p>
<p>Healthcare and medicine are multimodal disciplines that deal with multimodal data for reasoning and diagnosing multiple diseases. Although some multimodal reasoning models have emerged for reasoning complex tasks in scientific domains, their applications in the healthcare domain remain limited and fall short in correct reasoning for diagnosis. To address the challenges of multimodal medical reasoning for correct diagnosis and assist the healthcare professionals, a novel temporal graph-based reasoning process modelled through a directed graph has been proposed in the current work. It helps in accommodating dynamic changes in reasons through backtracking, refining the reasoning content, and creating new or deleting existing reasons to reach the best recommendation or answer. Again, consideration of multimodal data at different time points can enable tracking and analysis of patient health and disease progression. Moreover, the proposed multi-agent temporal reasoning framework provides task distributions and a cross-validation mechanism to further enhance the accuracy of reasoning outputs. A few basic experiments and analysis results justify the novelty and practical utility of the proposed preliminary approach. </p>
<blockquote>
<p>医疗护理和医学是多模式学科，涉及多模式数据来推理和诊断多种疾病。虽然一些多模式推理模型已经出现在科学领域的复杂任务推理中，它们在医疗领域的应用仍然有限，并且在诊断的正确推理方面存在不足。为了解决多模式医疗推理在正确诊断方面的挑战，并帮助医疗卫生专业人员，当前工作提出了一种基于动态图的新型推理过程，该过程通过有向图进行建模。它有助于通过回溯来容纳原因的动态变化，精炼推理内容，并创建新的或删除现有的原因，以得到最佳建议或答案。同样，在不同时间点考虑多模式数据能够实现对患者健康和疾病进展的跟踪和分析。此外，所提出的基于多智能体的时序推理框架提供了任务分配和交叉验证机制，以进一步提高推理输出的准确性。一些基本实验和分析结果证明了所提出初步方法的新颖性和实用性。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.11944v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>本文介绍了医疗健康领域中的多模态推理模型。虽然科学领域中已经出现了多模态推理模型，但其在医疗诊断领域的应用仍存在局限性，难以满足准确的诊断推理需求。针对这一挑战，本文提出了一种基于时序图的推理过程，通过建立有向图来模拟动态变化的推理过程，可回溯、优化推理内容，并根据需要创建或删除理由以得出最佳答案或建议。同时，考虑不同时间点的多模态数据有助于追踪和分析患者健康和疾病进展情况。此外，文中提出的基于多智能体的时序推理框架具备任务分配和交叉验证机制，可进一步提高推理结果的准确性。初步实验和分析结果证明了该方法的创新性和实用性。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>多模态数据在医疗诊断中的重要作用。</li>
<li>当前多模态推理模型在医疗诊断领域的应用局限和挑战。</li>
<li>基于时序图的推理过程能有效模拟动态变化的医疗诊断推理。</li>
<li>时序图推理过程支持回溯、优化推理内容，并灵活调整理由。</li>
<li>多模态数据在不同时间点的结合有助于追踪和分析患者健康及疾病进展。</li>
<li>多智能体时序推理框架通过任务分配和交叉验证提高推理准确性。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.11944">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-17\./crop_Agent/2509.11944v1/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-17\./crop_Agent/2509.11944v1/page_2_0.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="Neuro-Symbolic-Agents-with-Modal-Logic-for-Autonomous-Diagnostics"><a href="#Neuro-Symbolic-Agents-with-Modal-Logic-for-Autonomous-Diagnostics" class="headerlink" title="Neuro-Symbolic Agents with Modal Logic for Autonomous Diagnostics"></a>Neuro-Symbolic Agents with Modal Logic for Autonomous Diagnostics</h2><p><strong>Authors:Antonin Sulc, Thorsten Hellert</strong></p>
<p>The development of intelligent agents, particularly those powered by language models (LMs), has shown the critical role in various environments that require intelligent and autonomous decision. Environments are not passive testing grounds and they represent the data required for agents to learn and exhibit very challenging conditions that require adaptive, complex and autonomous capacity to make decisions. While the paradigm of scaling models and datasets has led to remarkable emergent capabilities, we argue that scaling the structure, fidelity, and logical consistency of agent reasoning within these environments is a crucial, yet underexplored, dimension of AI research. This paper introduces a neuro-symbolic multi-agent architecture where the belief states of individual agents are formally represented as Kripke models. This foundational choice enables them to reason about known concepts of \emph{possibility} and \emph{necessity} using the formal language of modal logic. In this work, we use of immutable, domain-specific knowledge to make infere information, which is encoded as logical constraints essential for proper diagnosis. In the proposed model, we show constraints that actively guide the hypothesis generation of LMs, effectively preventing them from reaching physically or logically untenable conclusions. In a high-fidelity simulated particle accelerator environment, our system successfully diagnoses complex, cascading failures by combining the powerful semantic intuition of LMs with the rigorous, verifiable validation of modal logic and a factual world model and showcasing a viable path toward more robust, reliable, and verifiable autonomous agents. </p>
<blockquote>
<p>智能体（尤其是那些由语言模型驱动的）的发展，在各种需要智能和自主决策的环境中显示出关键作用。环境并非被动的测试场所，而是代表智能体所需的数据进行学习并展现出极具挑战性的条件，需要适应性强、复杂和自主决策能力。虽然模型和数据集的扩展范式已经带来了显著的新兴能力，但我们主张在这些环境中扩展智能体的结构、逼真度和逻辑一致性推理是人工智能研究中至关重要但尚未被充分探索的维度。本文介绍了一种神经符号多智能体架构，其中单个智能体的信念状态被正式表示为Kripke模型。这一基本选择使他们能够使用模态逻辑的自然语言来推断已知概念的可能性和必要性。在这项工作中，我们使用不可变的领域特定知识来进行信息推断，这些知识被编码为逻辑约束，对于适当的诊断至关重要。在提出的模型中，我们展示了约束条件，这些约束条件积极指导语言模型的假设生成，有效地防止它们得出物理上或逻辑上不可行的结论。在一个高保真模拟的粒子加速器环境中，我们的系统将语言模型的强大语义直觉与模态逻辑的严格可验证验证和事实世界模型相结合，成功诊断出复杂级联故障，并展示了朝着更稳健、可靠和可验证的自主智能体的可行路径。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.11943v1">PDF</a> 10 pages, 1 figure, Scaling Environments for Agents (SEA) Workshop at   NeuralIPS</p>
<p><strong>摘要</strong></p>
<p>智能代理的发展，尤其是那些由语言模型驱动的代理，在各种需要智能和自主决策的环境中发挥了关键作用。环境并非被动的测试场所，而是代表数据，要求代理具备适应复杂环境并自主决策的能力。虽然模型和数据集的扩展已导致出现引人注目的新兴能力，但我们主张在这些环境中扩展代理推理的结构、保真度和逻辑一致性是人工智能研究的关键且尚未充分探索的维度。本文引入了一种神经符号多代理架构，其中单个代理的信念状态被形式化表示为Kripke模型。这一基本选择使他们能够利用模态逻辑的形式语言来推理已知的概念“可能性”和“必要性”。在这项工作中，我们使用不变、特定领域的知识来进行信息推断，这些知识被编码为逻辑约束，对于正确诊断至关重要。在提出的模型中，我们展示了约束条件，这些约束条件积极指导语言模型的假设生成，有效地防止其得出物理上或逻辑上站不住脚的结论。在高保真模拟粒子加速器环境中，我们的系统成功地将语言模型的强大语义直觉与模态逻辑的严格可验证性和事实世界模型相结合，诊断出复杂级联故障，展示了一条实现更稳健、可靠和可验证的自主代理的可行途径。</p>
<p><strong>关键见解</strong></p>
<ol>
<li>智能代理在需要智能和自主决策的环境中发挥关键作用。</li>
<li>扩展代理推理的结构、保真度和逻辑一致性是AI研究的关键维度。</li>
<li>提出的神经符号多代理架构采用Kripke模型表示代理的信念状态。</li>
<li>该架构利用模态逻辑来推理“可能性”和“必要性”的概念。</li>
<li>使用特定领域的、不变的知识进行信息推断，对正确诊断至关重要。</li>
<li>提出的模型通过约束条件积极指导语言模型的假设生成。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.11943">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-17\./crop_Agent/2509.11943v1/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-17\./crop_Agent/2509.11943v1/page_5_0.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="FineQuest-Adaptive-Knowledge-Assisted-Sports-Video-Understanding-via-Agent-of-Thoughts-Reasoning"><a href="#FineQuest-Adaptive-Knowledge-Assisted-Sports-Video-Understanding-via-Agent-of-Thoughts-Reasoning" class="headerlink" title="FineQuest: Adaptive Knowledge-Assisted Sports Video Understanding via   Agent-of-Thoughts Reasoning"></a>FineQuest: Adaptive Knowledge-Assisted Sports Video Understanding via   Agent-of-Thoughts Reasoning</h2><p><strong>Authors:Haodong Chen, Haojian Huang, XinXiang Yin, Dian Shao</strong></p>
<p>Video Question Answering (VideoQA) based on Large Language Models (LLMs) has shown potential in general video understanding but faces significant challenges when applied to the inherently complex domain of sports videos. In this work, we propose FineQuest, the first training-free framework that leverages dual-mode reasoning inspired by cognitive science: i) Reactive Reasoning for straightforward sports queries and ii) Deliberative Reasoning for more complex ones. To bridge the knowledge gap between general-purpose models and domain-specific sports understanding, FineQuest incorporates SSGraph, a multimodal sports knowledge scene graph spanning nine sports, which encodes both visual instances and domain-specific terminology to enhance reasoning accuracy. Furthermore, we introduce two new sports VideoQA benchmarks, Gym-QA and Diving-QA, derived from the FineGym and FineDiving datasets, enabling diverse and comprehensive evaluation. FineQuest achieves state-of-the-art performance on these benchmarks as well as the existing SPORTU dataset, while maintains strong general VideoQA capabilities. </p>
<blockquote>
<p>基于大型语言模型（LLM）的视频问答（VideoQA）在通用视频理解方面显示出潜力，但当应用于固有的复杂体育视频领域时，面临着巨大的挑战。在这项工作中，我们提出了FineQuest，这是第一个无需训练的框架，它受到认知科学的启发，采用双模式推理：i）针对直接的体育查询采用反应推理，ii）针对更复杂的内容采用审慎推理。为了弥补通用模型与特定领域体育理解之间的知识差距，FineQuest引入了SSGraph，这是一个跨越九种体育运动的多媒体体育知识场景图，它编码视觉实例和特定领域的术语，以提高推理的准确性。此外，我们引入了两个新的体育VideoQA基准测试，即Gym-QA和Diving-QA，它们分别基于FineGym和FineDiving数据集，能够实现多样化和全面的评估。FineQuest在这些基准测试以及现有的SPORTU数据集上达到了最先进的性能，同时保持了强大的通用VideoQA能力。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.11796v1">PDF</a> ACM MM 2025</p>
<p><strong>Summary</strong><br>文本主要介绍了针对体育视频理解的基于大型语言模型的视频问答技术面临的挑战，并提出了FineQuest训练免费的框架，它采用双模式推理和跨九种运动的多模态体育知识场景图SSGraph，以提高推理准确性。同时，介绍了两个新的体育视频问答基准测试，Gym-QA和Diving-QA，以及FineQuest在这些基准测试上的表现。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>视频问答技术应用于体育视频理解时面临的挑战。</li>
<li>FineQuest是首个无需训练的框架，采用双模式推理，包括反应性推理和慎思性推理。</li>
<li>SSGraph是一个多模态体育知识场景图，跨越九种运动，旨在缩小通用模型与特定领域体育理解之间的知识差距。</li>
<li>SSGraph结合了视觉实例和特定领域的术语，以提高推理准确性。</li>
<li>引入了两个新的体育视频问答基准测试：Gym-QA和Diving-QA。</li>
<li>FineQuest在基准测试上表现出卓越的性能，同时保持了强大的通用视频问答能力。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.11796">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-17\./crop_Agent/2509.11796v1/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-17\./crop_Agent/2509.11796v1/page_2_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-17\./crop_Agent/2509.11796v1/page_4_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-17\./crop_Agent/2509.11796v1/page_5_0.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="AMLNet-A-Knowledge-Based-Multi-Agent-Framework-to-Generate-and-Detect-Realistic-Money-Laundering-Transactions"><a href="#AMLNet-A-Knowledge-Based-Multi-Agent-Framework-to-Generate-and-Detect-Realistic-Money-Laundering-Transactions" class="headerlink" title="AMLNet: A Knowledge-Based Multi-Agent Framework to Generate and Detect   Realistic Money Laundering Transactions"></a>AMLNet: A Knowledge-Based Multi-Agent Framework to Generate and Detect   Realistic Money Laundering Transactions</h2><p><strong>Authors:Sabin Huda, Ernest Foo, Zahra Jadidi, MA Hakim Newton, Abdul Sattar</strong></p>
<p>Anti-money laundering (AML) research is constrained by the lack of publicly shareable, regulation-aligned transaction datasets. We present AMLNet, a knowledge-based multi-agent framework with two coordinated units: a regulation-aware transaction generator and an ensemble detection pipeline. The generator produces 1,090,173 synthetic transactions (approximately 0.16% laundering-positive) spanning core laundering phases (placement, layering, integration) and advanced typologies (e.g., structuring, adaptive threshold behavior). Regulatory alignment reaches 75% based on AUSTRAC rule coverage (Section 4.2), while a composite technical fidelity score of 0.75 summarizes temporal, structural, and behavioral realism components (Section 4.4). The detection ensemble achieves F1 0.90 (precision 0.84, recall 0.97) on the internal test partitions of AMLNet and adapts to the external SynthAML dataset, indicating architectural generalizability across different synthetic generation paradigms. We provide multi-dimensional evaluation (regulatory, temporal, network, behavioral) and release the dataset (Version 1.0, <a target="_blank" rel="noopener" href="https://doi.org/10.5281/zenodo.16736515">https://doi.org/10.5281/zenodo.16736515</a>), to advance reproducible and regulation-conscious AML experimentation. </p>
<blockquote>
<p>反洗钱（AML）研究受限于缺乏可公开共享的、符合监管要求的交易数据集。我们提出了AMLNet，这是一个基于知识的多智能体框架，包含两个协调单元：一个意识到法规的交易生成器和一个集成检测管道。生成器产生了跨越核心洗钱阶段（放置、分层、集成）和高级类型（例如，结构化、自适应阈值行为）的1,090,173条合成交易（大约0.16%为洗钱阳性）。基于AUSTRAC规则覆盖，监管一致性达到75%（第4.2节），而0.75的综合技术保真度分数概括了时间、结构和行为现实主义的组成部分（第4.4节）。检测组合在AMLNet的内部测试分区上实现了F1分数0.90（精确度0.84，召回率0.97），并适应外部的SynthAML数据集，表明架构在不同合成生成范式之间的通用性。我们提供了多维评估（监管、时间、网络、行为），并公开了数据集（Version 1.0，[<a target="_blank" rel="noopener" href="https://doi.org/10.5281/zenodo.16736515]%EF%BC%8C%E4%BB%A5%E4%BF%83%E8%BF%9B%E5%8F%AF%E9%87%8D%E5%A4%8D%E5%92%8C%E9%81%B5%E5%AE%88%E6%B3%95%E8%A7%84%E7%9A%84%E5%8F%8D%E6%B4%97%E9%92%B1%E5%AE%9E%E9%AA%8C%E3%80%82">https://doi.org/10.5281/zenodo.16736515]，以促进可重复和遵守法规的反洗钱实验。</a></p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.11595v1">PDF</a> </p>
<p><strong>Summary</strong>：</p>
<p>AMLNet是一个基于知识的多代理框架，包括两个协调单元：一个法规意识交易生成器和一个集成检测管道。生成器产生约含洗钱行为的合成交易数据，涵盖核心洗钱阶段和高级类型。该框架符合AUSTRAC规则的合规性达到75%，检测性能良好，可适应不同合成生成范式。发布数据集以推动可重复和遵守法规的AML实验。</p>
<p><strong>Key Takeaways</strong>：</p>
<ol>
<li>AMLNet是一个多代理框架，旨在解决反洗钱（AML）研究中缺乏可公开分享、符合法规的交易数据集的问题。</li>
<li>该框架包括两个协调单元：一个法规意识的交易生成器和一个集成检测管道。</li>
<li>交易生成器能够产生涵盖核心洗钱阶段和高级类型的合成交易数据。</li>
<li>该框架符合AUSTRAC规则的合规性达到75%，并且通过了多方面的评估，包括时间、结构、行为真实性。</li>
<li>检测管道在内部测试分区上实现了F1分数为0.90的良好检测结果，并适应外部SynthAML数据集，表明其架构在不同合成生成范式中的泛化能力。</li>
<li>该研究发布了数据集（Version 1.0），以推动可重复和遵守法规的AML实验。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.11595">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-17\./crop_Agent/2509.11595v1/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-17\./crop_Agent/2509.11595v1/page_3_0.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="A-Survey-of-Reasoning-and-Agentic-Systems-in-Time-Series-with-Large-Language-Models"><a href="#A-Survey-of-Reasoning-and-Agentic-Systems-in-Time-Series-with-Large-Language-Models" class="headerlink" title="A Survey of Reasoning and Agentic Systems in Time Series with Large   Language Models"></a>A Survey of Reasoning and Agentic Systems in Time Series with Large   Language Models</h2><p><strong>Authors:Ching Chang, Yidan Shi, Defu Cao, Wei Yang, Jeehyun Hwang, Haixin Wang, Jiacheng Pang, Wei Wang, Yan Liu, Wen-Chih Peng, Tien-Fu Chen</strong></p>
<p>Time series reasoning treats time as a first-class axis and incorporates intermediate evidence directly into the answer. This survey defines the problem and organizes the literature by reasoning topology with three families: direct reasoning in one step, linear chain reasoning with explicit intermediates, and branch-structured reasoning that explores, revises, and aggregates. The topology is crossed with the main objectives of the field, including traditional time series analysis, explanation and understanding, causal inference and decision making, and time series generation, while a compact tag set spans these axes and captures decomposition and verification, ensembling, tool use, knowledge access, multimodality, agent loops, and LLM alignment regimes. Methods and systems are reviewed across domains, showing what each topology enables and where it breaks down in faithfulness or robustness, along with curated datasets, benchmarks, and resources that support study and deployment (<a target="_blank" rel="noopener" href="https://github.com/blacksnail789521/Time-Series-Reasoning-Survey">https://github.com/blacksnail789521/Time-Series-Reasoning-Survey</a>). Evaluation practices that keep evidence visible and temporally aligned are highlighted, and guidance is distilled on matching topology to uncertainty, grounding with observable artifacts, planning for shift and streaming, and treating cost and latency as design budgets. We emphasize that reasoning structures must balance capacity for grounding and self-correction against computational cost and reproducibility, while future progress will likely depend on benchmarks that tie reasoning quality to utility and on closed-loop testbeds that trade off cost and risk under shift-aware, streaming, and long-horizon settings. Taken together, these directions mark a shift from narrow accuracy toward reliability at scale, enabling systems that not only analyze but also understand, explain, and act on dynamic worlds with traceable evidence and credible outcomes. </p>
<blockquote>
<p>时间序列推理将时间视为第一级轴，并将中间证据直接纳入答案中。本文通过推理拓扑对问题进行了定义和文献整理，主要包括三个家族：一步直接推理、具有明确中间体的线性链推理和探究、修订和聚合的分支结构推理。拓扑与领域的主要目标相结合，包括传统的时间序列分析、解释和理解、因果推断和决策制定以及时间序列生成，而紧凑的标签集则跨越这些轴，涵盖分解和验证、集成、工具使用、知识访问、多模态性、代理循环和LLM对齐机制等。本文回顾了不同领域的方法和系统，展示了每种拓扑的优势和局限性，以及可靠性或稳健性方面的不足，同时提供了支持研究和部署的数据集、基准测试和资源（<a target="_blank" rel="noopener" href="https://github.com/blacksnail789521/Time-Series-Reasoning-Survey%EF%BC%89%E3%80%82%E6%9C%AC%E6%96%87%E5%BC%BA%E8%B0%83%E4%BA%86%E4%BF%9D%E6%8C%81%E8%AF%81%E6%8D%AE%E5%8F%AF%E8%A7%81%E4%B8%94%E6%97%B6%E9%97%B4%E5%AF%B9%E9%BD%90%E7%9A%84%E8%AF%84%E4%BC%B0%E5%AE%9E%E8%B7%B5%EF%BC%8C%E5%B9%B6%E5%B0%B1%E5%8C%B9%E9%85%8D%E6%8B%93%E6%89%91%E4%B8%8E%E4%B8%8D%E7%A1%AE%E5%AE%9A%E6%80%A7%E3%80%81%E4%B8%8E%E5%8F%AF%E8%A7%82%E5%AF%9F%E5%88%B0%E7%9A%84%E4%BC%AA%E8%BF%B9%E5%AF%B9%E6%8E%A5%E3%80%81%E8%A7%84%E5%88%92%E8%BF%81%E7%A7%BB%E5%92%8C%E6%B5%81%E5%BC%8F%E5%A4%84%E7%90%86%E4%BB%A5%E5%8F%8A%E5%B0%86%E6%88%90%E6%9C%AC%E5%92%8C%E5%BB%B6%E8%BF%9F%E8%A7%86%E4%B8%BA%E8%AE%BE%E8%AE%A1%E9%A2%84%E7%AE%97%E7%9A%84%E6%8C%87%E5%AF%BC%E6%96%B9%E9%92%88%E8%BF%9B%E8%A1%8C%E4%BA%86%E6%8F%90%E7%82%BC%E3%80%82%E6%88%91%E4%BB%AC%E5%BC%BA%E8%B0%83%EF%BC%8C%E6%8E%A8%E7%90%86%E7%BB%93%E6%9E%84%E5%BF%85%E9%A1%BB%E5%9C%A8%E5%AE%B9%E7%BA%B3%E8%83%BD%E5%8A%9B%E5%92%8C%E8%87%AA%E6%88%91%E6%A0%A1%E6%AD%A3%E6%96%B9%E9%9D%A2%E8%BE%BE%E5%88%B0%E5%B9%B3%E8%A1%A1%E8%AE%A1%E7%AE%97%E6%88%90%E6%9C%AC%E5%92%8C%E5%8F%AF%E9%87%8D%E5%A4%8D%E6%80%A7%EF%BC%8C%E8%80%8C%E6%9C%AA%E6%9D%A5%E7%9A%84%E8%BF%9B%E5%B1%95%E5%8F%AF%E8%83%BD%E5%8F%96%E5%86%B3%E4%BA%8E%E5%B0%86%E6%8E%A8%E7%90%86%E8%B4%A8%E9%87%8F%E4%B8%8E%E5%AE%9E%E7%94%A8%E6%80%A7%E8%81%94%E7%B3%BB%E5%9C%A8%E4%B8%80%E8%B5%B7%E7%9A%84%E5%9F%BA%E5%87%86%E6%B5%8B%E8%AF%95%EF%BC%8C%E4%BB%A5%E5%8F%8A%E6%9D%83%E8%A1%A1%E6%88%90%E6%9C%AC%E5%92%8C%E9%A3%8E%E9%99%A9%E7%9A%84%E6%83%85%E5%86%B5%E4%B8%8B%EF%BC%8C%E5%9C%A8%E5%85%B7%E5%A4%87%E8%BF%81%E7%A7%BB%E6%84%8F%E8%AF%86%E3%80%81%E6%B5%81%E5%BC%8F%E5%A4%84%E7%90%86%E5%92%8C%E9%95%BF%E6%9C%9F%E8%A7%86%E9%87%8E%E7%9A%84%E7%8E%AF%E5%A2%83%E4%B8%AD%E5%BB%BA%E7%AB%8B%E9%97%AD%E7%8E%AF%E6%B5%8B%E8%AF%95%E5%B9%B3%E5%8F%B0%E3%80%82%E6%80%BB%E7%9A%84%E6%9D%A5%E8%AF%B4%EF%BC%8C%E8%BF%99%E4%BA%9B%E6%96%B9%E5%90%91%E6%A0%87%E5%BF%97%E7%9D%80%E4%BB%8E%E7%8B%AD%E7%AA%84%E7%9A%84%E5%87%86%E7%A1%AE%E6%80%A7%E5%90%91%E5%A4%A7%E8%A7%84%E6%A8%A1%E5%8F%AF%E9%9D%A0%E6%80%A7%E8%BD%AC%E5%8F%98%EF%BC%8C%E4%BD%BF%E7%B3%BB%E7%BB%9F%E4%B8%8D%E4%BB%85%E8%83%BD%E5%A4%9F%E5%88%86%E6%9E%90%EF%BC%8C%E8%80%8C%E4%B8%94%E8%83%BD%E5%A4%9F%E7%90%86%E8%A7%A3%E3%80%81%E8%A7%A3%E9%87%8A%E5%92%8C%E9%87%87%E5%8F%96%E5%AE%9E%E9%99%85%E8%A1%8C%E5%8A%A8%EF%BC%8C%E5%9C%A8%E5%8A%A8%E6%80%81%E4%B8%96%E7%95%8C%E4%B8%AD%E5%AE%9E%E7%8E%B0%E5%8F%AF%E8%BF%BD%E6%BA%AF%E7%9A%84%E8%AF%81%E6%8D%AE%E5%92%8C%E5%8F%AF%E4%BF%A1%E7%9A%84%E7%BB%93%E6%9E%9C%E3%80%82">https://github.com/blacksnail789521/Time-Series-Reasoning-Survey）。本文强调了保持证据可见且时间对齐的评估实践，并就匹配拓扑与不确定性、与可观察到的伪迹对接、规划迁移和流式处理以及将成本和延迟视为设计预算的指导方针进行了提炼。我们强调，推理结构必须在容纳能力和自我校正方面达到平衡计算成本和可重复性，而未来的进展可能取决于将推理质量与实用性联系在一起的基准测试，以及权衡成本和风险的情况下，在具备迁移意识、流式处理和长期视野的环境中建立闭环测试平台。总的来说，这些方向标志着从狭窄的准确性向大规模可靠性转变，使系统不仅能够分析，而且能够理解、解释和采取实际行动，在动态世界中实现可追溯的证据和可信的结果。</a></p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.11575v1">PDF</a> This paper is currently under review</p>
<p><strong>摘要</strong></p>
<p>时间序列推理将时间视为首要轴，并将中间证据直接纳入答案中。本文定义了问题，并通过推理拓扑来组织文献，包括一步直接推理、具有明确中间体的线性链推理和探究、修订和聚合的分支结构推理等三个家族。拓扑与领域的主要目标相结合，如传统的时间序列分析、解释和理解、因果推理和决策制定以及时间序列生成等。同时，一个紧凑的标签集跨越了这些轴，并涵盖了分解和验证、集成、工具使用、知识访问、多模态性、代理循环和LLM对齐机制等。本文回顾了不同领域的方法和系统，展示了每种拓扑的优缺点，以及支持的数据集、基准测试和资源（<a target="_blank" rel="noopener" href="https://github.com/blacksnail789521/Time-Series-Reasoning-Survey%EF%BC%89%E3%80%82%E5%BC%BA%E8%B0%83%E4%BA%86%E4%BF%9D%E6%8C%81%E8%AF%81%E6%8D%AE%E5%8F%AF%E8%A7%81%E6%80%A7%E5%92%8C%E6%97%B6%E9%97%B4%E5%AF%B9%E9%BD%90%E6%80%A7%E7%9A%84%E8%AF%84%E4%BC%B0%E5%AE%9E%E8%B7%B5%EF%BC%8C%E5%B9%B6%E6%8F%90%E4%BE%9B%E4%BA%86%E5%8C%B9%E9%85%8D%E6%8B%93%E6%89%91%E4%B8%8E%E4%B8%8D%E7%A1%AE%E5%AE%9A%E6%80%A7%E3%80%81%E7%94%A8%E5%8F%AF%E8%A7%82%E5%AF%9F%E5%88%B0%E7%9A%84%E4%BC%AA%E8%BF%B9%E8%BF%9B%E8%A1%8C%E6%8E%A5%E5%9C%B0%E3%80%81%E8%A7%84%E5%88%92%E8%BF%81%E7%A7%BB%E5%92%8C%E6%B5%81%E5%BC%8F%E5%A4%84%E7%90%86%E4%BB%A5%E5%8F%8A%E5%B0%86%E6%88%90%E6%9C%AC%E5%92%8C%E5%BB%B6%E8%BF%9F%E8%A7%86%E4%B8%BA%E8%AE%BE%E8%AE%A1%E9%A2%84%E7%AE%97%E7%9A%84%E6%8C%87%E5%AF%BC%E3%80%82%E6%9C%AA%E6%9D%A5%E8%BF%9B%E5%B1%95%E5%8F%AF%E8%83%BD%E5%8F%96%E5%86%B3%E4%BA%8E%E5%B0%86%E6%8E%A8%E7%90%86%E8%B4%A8%E9%87%8F%E4%B8%8E%E5%AE%9E%E7%94%A8%E6%80%A7%E8%81%94%E7%B3%BB%E8%B5%B7%E6%9D%A5%E7%9A%84%E5%9F%BA%E5%87%86%E6%B5%8B%E8%AF%95%EF%BC%8C%E4%BB%A5%E5%8F%8A%E8%83%BD%E5%A4%9F%E5%9C%A8%E6%88%90%E6%9C%AC%E5%92%8C%E9%A3%8E%E9%99%A9%E4%B9%8B%E9%97%B4%E8%BF%9B%E8%A1%8C%E6%9D%83%E8%A1%A1%E7%9A%84%E9%97%AD%E7%8E%AF%E6%B5%8B%E8%AF%95%E5%B9%B3%E5%8F%B0%E3%80%82%E8%BF%99%E4%BA%9B%E6%96%B9%E5%90%91%E6%A0%87%E5%BF%97%E7%9D%80%E4%BB%8E%E7%8B%AD%E9%9A%98%E7%9A%84%E5%87%86%E7%A1%AE%E6%80%A7%E5%90%91%E5%A4%A7%E8%A7%84%E6%A8%A1%E5%8F%AF%E9%9D%A0%E6%80%A7%E8%BD%AC%E5%8F%98%EF%BC%8C%E4%BD%BF%E7%B3%BB%E7%BB%9F%E4%B8%8D%E4%BB%85%E8%83%BD%E5%A4%9F%E5%88%86%E6%9E%90%EF%BC%8C%E8%80%8C%E4%B8%94%E8%83%BD%E5%A4%9F%E7%90%86%E8%A7%A3%E3%80%81%E8%A7%A3%E9%87%8A%E5%92%8C%E5%BA%94%E5%AF%B9%E5%8A%A8%E6%80%81%E4%B8%96%E7%95%8C%EF%BC%8C%E5%85%B7%E6%9C%89%E5%8F%AF%E8%BF%BD%E6%BA%AF%E7%9A%84%E8%AF%81%E6%8D%AE%E5%92%8C%E5%8F%AF%E9%9D%A0%E7%9A%84%E7%BB%93%E6%9E%9C%E3%80%82">https://github.com/blacksnail789521/Time-Series-Reasoning-Survey）。强调了保持证据可见性和时间对齐性的评估实践，并提供了匹配拓扑与不确定性、用可观察到的伪迹进行接地、规划迁移和流式处理以及将成本和延迟视为设计预算的指导。未来进展可能取决于将推理质量与实用性联系起来的基准测试，以及能够在成本和风险之间进行权衡的闭环测试平台。这些方向标志着从狭隘的准确性向大规模可靠性转变，使系统不仅能够分析，而且能够理解、解释和应对动态世界，具有可追溯的证据和可靠的结果。</a></p>
<p><strong>关键见解</strong></p>
<ol>
<li>时间序列推理将时间视为核心要素，纳入中间证据。</li>
<li>推理拓扑包含三种家族：一步直接推理、线性链推理和分支结构推理。</li>
<li>主要领域目标包括时间序列分析、解释和理解等。</li>
<li>紧凑的标签集覆盖了时间序列推理的各个方面。</li>
<li>方法和系统的回顾展示了不同拓扑的优缺点。</li>
<li>评估实践强调保持证据可见性和时间对齐性。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.11575">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-17\./crop_Agent/2509.11575v1/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-17\./crop_Agent/2509.11575v1/page_4_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-17\./crop_Agent/2509.11575v1/page_5_0.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="VulAgent-Hypothesis-Validation-based-Multi-Agent-Vulnerability-Detection"><a href="#VulAgent-Hypothesis-Validation-based-Multi-Agent-Vulnerability-Detection" class="headerlink" title="VulAgent: Hypothesis-Validation based Multi-Agent Vulnerability   Detection"></a>VulAgent: Hypothesis-Validation based Multi-Agent Vulnerability   Detection</h2><p><strong>Authors:Ziliang Wang, Ge Li, Jia Li, Hao Zhu, Zhi Jin</strong></p>
<p>The application of language models to project-level vulnerability detection remains challenging, owing to the dual requirement of accurately localizing security-sensitive code and correctly correlating and reasoning over complex program context. We present VulAgent, a multi-agent vulnerability detection framework based on hypothesis validation. Our design is inspired by how human auditors review code: when noticing a sensitive operation, they form a hypothesis about a possible vulnerability, consider potential trigger paths, and then verify the hypothesis against the surrounding context. VulAgent implements a semantics-sensitive, multi-view detection pipeline: specialized agents, each aligned to a specific analysis perspective (e.g., memory, authorization), collaboratively surface and precisely localize sensitive code sites with higher coverage. Building on this, VulAgent adopts a hypothesis-validation paradigm: for each vulnerability report, it builds hypothesis conditions and a trigger path, steering the LLM to target the relevant program context and defensive checks during verification, which reduces false positives. On average across the two datasets, VulAgent improves overall accuracy by 6.6%, increases the correct identification rate of vulnerable–fixed code pairs by up to 450% (246% on average), and reduces the false positive rate by about 36% compared with state-of-the-art LLM-based baselines. </p>
<blockquote>
<p>将语言模型应用于项目级别的漏洞检测仍然具有挑战性，这归因于准确定位安全敏感代码以及正确关联和推理复杂程序上下文的双重要求。我们提出了VulAgent，一个基于假设验证的多代理漏洞检测框架。我们的设计灵感来自于人类审计员如何审查代码：当注意到敏感操作时，他们会对可能的漏洞形成假设，考虑潜在的触发路径，然后根据周围上下文验证假设。VulAgent实现了一个语义敏感的、多视角的检测流程：专业化的代理，每个代理都对应一个特定的分析角度（例如内存、授权），协同工作，精确定位敏感代码站点，覆盖更广。在此基础上，VulAgent采用假设验证范式：对于每个漏洞报告，它构建假设条件和触发路径，引导大型语言模型在验证过程中定位相关的程序上下文和防御检查，这减少了误报。在两个数据集上平均比较，VulAgent提高了整体准确率6.6%，正确识别脆弱-固定代码对的比率提高了高达450%（平均提高246%），与最新的大型语言模型基准相比，误报率降低了约36%。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.11523v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>基于语言模型的项目级别漏洞检测仍然具有挑战性，需要准确定位安全敏感代码，并正确关联和推理复杂的程序上下文。我们提出了基于假设验证的多智能体漏洞检测框架VulAgent。它的设计灵感来源于人工审核代码的方式，当发现敏感操作时，会形成关于可能漏洞的假设，考虑潜在的触发路径，然后根据周围的上下文验证假设。VulAgent实现了一个语义敏感的多视角检测管道，专业化的智能体，每个智能体对应一个特定的分析角度（例如内存、授权等），协同工作并精确定位敏感代码站点，提高覆盖率。此外，VulAgent采用假设验证模式：针对每个漏洞报告，构建假设条件和触发路径，引导大型语言模型在验证时定位相关程序上下文和防御检查，降低了误报率。与最新的大型语言模型基线相比，VulAgent平均提高了6.6%的整体准确率，对脆弱固定代码对的正确识别率平均提高了246%，并降低了约36%的误报率。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>语言模型在项目级别漏洞检测中的应用具有挑战性，需要同时满足定位安全敏感代码和关联复杂程序上下文的要求。</li>
<li>VulAgent是一个基于假设验证的多智能体漏洞检测框架，模仿人工审核代码的方式。</li>
<li>VulAgent实现语义敏感的多视角检测，通过协同工作的智能体精确识别敏感代码，提高覆盖率。</li>
<li>VulAgent采用假设验证模式，构建假设条件和触发路径，引导大型语言模型进行有针对性的验证，降低误报率。</li>
<li>与现有大型语言模型基线相比，VulAgent在整体准确率、对脆弱固定代码对的识别率和误报率方面均有显著改善。</li>
<li>VulAgent的设计有助于提高漏洞检测的准确性和效率。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.11523">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-17\./crop_Agent/2509.11523v1/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-17\./crop_Agent/2509.11523v1/page_1_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-17\./crop_Agent/2509.11523v1/page_3_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-17\./crop_Agent/2509.11523v1/page_5_0.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="MAPGD-Multi-Agent-Prompt-Gradient-Descent-for-Collaborative-Prompt-Optimization"><a href="#MAPGD-Multi-Agent-Prompt-Gradient-Descent-for-Collaborative-Prompt-Optimization" class="headerlink" title="MAPGD: Multi-Agent Prompt Gradient Descent for Collaborative Prompt   Optimization"></a>MAPGD: Multi-Agent Prompt Gradient Descent for Collaborative Prompt   Optimization</h2><p><strong>Authors:Yichen Han, Bojun Liu, Zhengpeng zhou, Guanyu Liu, Zeng Zhang, Yang Yang, Wenli Wang, Isaac N Shi,  Yunyan, Lewei He, Tianyu Shi</strong></p>
<p>Prompt engineering is crucial for leveraging large language models (LLMs), but existing methods often rely on a single optimization trajectory, limiting adaptability and efficiency while suffering from narrow perspectives, gradient conflicts, and high computational cost. We propose MAPGD (Multi-Agent Prompt Gradient Descent), a framework integrating multi-agent collaboration with gradient-based optimization. MAPGD features specialized agents for task clarity, example selection, format design, and stylistic refinement; semantic gradient coordination to resolve conflicts; bandit-based candidate selection for efficient exploration-exploitation; and theoretical convergence guarantees. Experiments on classification, generation, and reasoning tasks show MAPGD outperforms single-agent and random baselines in accuracy and efficiency. Ablations confirm the benefits of gradient fusion, agent specialization, and conflict resolution, providing a unified, gradient-inspired multi-agent approach to robust and interpretable prompt optimization. </p>
<blockquote>
<p>提示工程在利用大型语言模型（LLM）方面起着至关重要的作用，但现有方法往往依赖于单一优化轨迹，这限制了适应性并降低了效率，同时受到视角狭窄、梯度冲突和高计算成本的困扰。我们提出了MAPGD（多智能体提示梯度下降）框架，它结合了多智能体协作与基于梯度的优化。MAPGD具有任务明确、示例选择、格式设计和风格精炼的专用智能体；语义梯度协调以解决冲突；基于强盗的候选选择以实现有效的探索与开发；以及理论收敛保证。在分类、生成和推理任务上的实验表明，MAPGD在准确性和效率方面优于单智能体和随机基线。剖析实验证实了梯度融合、智能体专业化和冲突解决的好处，提供了一个统一、受梯度启发的多智能体方法，用于稳健和可解释的提示优化。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.11361v1">PDF</a> </p>
<p><strong>Summary</strong><br>多模态提示工程对于利用大型语言模型至关重要，但现有方法受限于单一优化轨迹，存在适应性差、效率低、视角狭窄、梯度冲突和计算成本高的问题。我们提出MAPGD（多智能体提示梯度下降）框架，集成了多智能体协作与梯度优化。MAPGD具有任务清晰、示例选择、格式设计和风格修饰的专职智能体；语义梯度协调以解决冲突；基于强盗的候选选择以实现高效探索与利用；理论收敛性保证。在分类、生成和推理任务上的实验表明，MAPGD在准确性和效率上优于单智能体和随机基线。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>多模态提示工程对大型语言模型的重要性及其现有挑战概述。</li>
<li>MAPGD框架集成了多智能体协作与梯度优化。</li>
<li>MAPGD框架包括任务清晰、示例选择等专职智能体。</li>
<li>MAPGD通过语义梯度协调解决梯度冲突。</li>
<li>基于强盗的候选选择方法实现了高效的探索与利用。</li>
<li>MAPGD具有理论收敛性保证。</li>
<li>实验结果显示MAPGD在分类、生成和推理任务上的优越性能。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.11361">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-17\./crop_Agent/2509.11361v1/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-17\./crop_Agent/2509.11361v1/page_1_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-17\./crop_Agent/2509.11361v1/page_3_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-17\./crop_Agent/2509.11361v1/page_4_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-17\./crop_Agent/2509.11361v1/page_4_1.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="Shell-or-Nothing-Real-World-Benchmarks-and-Memory-Activated-Agents-for-Automated-Penetration-Testing"><a href="#Shell-or-Nothing-Real-World-Benchmarks-and-Memory-Activated-Agents-for-Automated-Penetration-Testing" class="headerlink" title="Shell or Nothing: Real-World Benchmarks and Memory-Activated Agents for   Automated Penetration Testing"></a>Shell or Nothing: Real-World Benchmarks and Memory-Activated Agents for   Automated Penetration Testing</h2><p><strong>Authors:Wuyuao Mai, Geng Hong, Qi Liu, Jinsong Chen, Jiarun Dai, Xudong Pan, Yuan Zhang, Min Yang</strong></p>
<p>Penetration testing is critical for identifying and mitigating security vulnerabilities, yet traditional approaches remain expensive, time-consuming, and dependent on expert human labor. Recent work has explored AI-driven pentesting agents, but their evaluation relies on oversimplified capture-the-flag (CTF) settings that embed prior knowledge and reduce complexity, leading to performance estimates far from real-world practice. We close this gap by introducing the first real-world, agent-oriented pentesting benchmark, TermiBench, which shifts the goal from ‘flag finding’ to achieving full system control. The benchmark spans 510 hosts across 25 services and 30 CVEs, with realistic environments that require autonomous reconnaissance, discrimination between benign and exploitable services, and robust exploit execution. Using this benchmark, we find that existing systems can hardly obtain system shells under realistic conditions.   To address these challenges, we propose TermiAgent, a multi-agent penetration testing framework. TermiAgent mitigates long-context forgetting with a Located Memory Activation mechanism and builds a reliable exploit arsenal via structured code understanding rather than naive retrieval. In evaluations, our work outperforms state-of-the-art agents, exhibiting stronger penetration testing capability, reducing execution time and financial cost, and demonstrating practicality even on laptop-scale deployments. Our work delivers both the first open-source benchmark for real-world autonomous pentesting and a novel agent framework that establishes a milestone for AI-driven penetration testing. </p>
<blockquote>
<p>渗透测试对于识别和缓解安全漏洞至关重要，但传统的方法仍然昂贵、耗时，并且依赖于专业的人工劳动力。最近的工作已经探索了AI驱动的渗透测试代理，但它们的评估依赖于简化的捕获标志（CTF）设置，这些设置会嵌入先验知识并降低复杂性，从而导致性能估计与实际应用相去甚远。我们通过引入面向实际应用的渗透测试基准测试TermiBench来弥补这一差距，该基准测试将目标从“寻找标志”转变为实现全面系统控制。该基准测试涵盖了25项服务和30个CVE的510个主机，具有现实环境，需要自主侦察、区分良性服务和可利用服务，以及强大的漏洞利用执行。使用此基准测试，我们发现现有系统几乎无法在真实条件下获得系统外壳。为了应对这些挑战，我们提出了TermiAgent，这是一个多代理渗透测试框架。TermiAgent通过定位内存激活机制缓解长期上下文遗忘问题，并通过结构化代码理解而不是简单检索来建立可靠的漏洞利用库。在评估中，我们的工作优于最新代理，表现出更强的渗透测试能力，缩短了执行时间并降低了财务成本，甚至在笔记本电脑规模的部署中也证明了实用性。我们的工作不仅提供了首个面向实际应用的开源渗透测试基准测试，还提供了一个新颖的代理框架，为AI驱动的渗透测试树立了里程碑。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.09207v2">PDF</a> </p>
<p><strong>Summary</strong><br>渗透测试对于识别与缓解安全漏洞至关重要，但传统方法仍显昂贵、耗时，并依赖专家人力。为缩小现实与简化设置的差距，我们推出首个面向真实世界的渗透测试基准测试平台TermiBench，旨在实现系统全面控制而非简单的“寻旗”目标。该平台跨越510台主机、涵盖25项服务和30项CVE，提供真实环境以要求自主侦查、辨别良性与可攻击服务及稳定的攻击执行。使用此基准测试平台，我们发现现有系统在实际条件下难以获得系统shell。为解决这些挑战，我们提出多智能体渗透测试框架TermiAgent，借助定位内存激活机制缓解长期上下文遗忘问题，并通过结构化代码理解构建可靠攻击库而非盲目检索。评估显示，我们的工作表现优于最新智能体，展现出更强渗透测试能力、缩短执行时间及降低财务成本，并在笔记本电脑规模部署中展现出实用性。我们的工作不仅推出首个面向真实世界自主渗透测试的开源基准测试平台，还开创性提出里程碑式的AI驱动渗透测试框架。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>渗透测试对于安全至关重要，但传统方法存在成本高、耗时长等缺点。</li>
<li>推出首个面向真实世界的渗透测试基准测试平台TermiBench，目标为全面系统控制。</li>
<li>TermiBench包含多环境，要求自主侦查、辨别服务和执行攻击。</li>
<li>现有系统在现实条件下难以获得系统shell。</li>
<li>提出多智能体渗透测试框架TermiAgent，借助定位内存激活机制缓解长期上下文遗忘。</li>
<li>TermiAgent通过结构化代码理解构建可靠攻击库。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.09207">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-17\./crop_Agent/2509.09207v2/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-17\./crop_Agent/2509.09207v2/page_2_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-17\./crop_Agent/2509.09207v2/page_3_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-17\./crop_Agent/2509.09207v2/page_4_0.jpg" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="GitTaskBench-A-Benchmark-for-Code-Agents-Solving-Real-World-Tasks-Through-Code-Repository-Leveraging"><a href="#GitTaskBench-A-Benchmark-for-Code-Agents-Solving-Real-World-Tasks-Through-Code-Repository-Leveraging" class="headerlink" title="GitTaskBench: A Benchmark for Code Agents Solving Real-World Tasks   Through Code Repository Leveraging"></a>GitTaskBench: A Benchmark for Code Agents Solving Real-World Tasks   Through Code Repository Leveraging</h2><p><strong>Authors:Ziyi Ni, Huacan Wang, Shuo Zhang, Shuo Lu, Ziyang He, Wang You, Zhenheng Tang, Yuntao Du, Bill Sun, Hongzhang Liu, Sen Hu, Ronghao Chen, Bo Li, Xin Li, Chen Hu, Binxing Jiao, Daxin Jiang, Pin Lyu</strong></p>
<p>Beyond scratch coding, exploiting large-scale code repositories (e.g., GitHub) for practical tasks is vital in real-world software development, yet current benchmarks rarely evaluate code agents in such authentic, workflow-driven scenarios. To bridge this gap, we introduce GitTaskBench, a benchmark designed to systematically assess this capability via 54 realistic tasks across 7 modalities and 7 domains. Each task pairs a relevant repository with an automated, human-curated evaluation harness specifying practical success criteria. Beyond measuring execution and task success, we also propose the alpha-value metric to quantify the economic benefit of agent performance, which integrates task success rates, token cost, and average developer salaries. Experiments across three state-of-the-art agent frameworks with multiple advanced LLMs show that leveraging code repositories for complex task solving remains challenging: even the best-performing system, OpenHands+Claude 3.7, solves only 48.15% of tasks (recent progress has pushed the frontier further, with RepoMaster+Claude 3.5 achieving a new record of 62.96%). Error analysis attributes over half of failures to seemingly mundane yet critical steps like environment setup and dependency resolution, highlighting the need for more robust workflow management and increased timeout preparedness. By releasing GitTaskBench, we aim to drive progress and attention toward repository-aware code reasoning, execution, and deployment – moving agents closer to solving complex, end-to-end real-world tasks. The benchmark and code are open-sourced at <a target="_blank" rel="noopener" href="https://github.com/QuantaAlpha/GitTaskBench">https://github.com/QuantaAlpha/GitTaskBench</a>. </p>
<blockquote>
<p>除了Scratch编码之外，利用大规模的代码仓库（例如GitHub）来完成实际任务在现实世界软件开发中至关重要。然而，当前的评价基准很少在这种真实、以工作流程驱动的情境中对代码代理进行评估。为了弥补这一差距，我们引入了GitTaskBench，这是一个旨在通过7种模式和7个领域的54个实际任务来系统地评估这种能力的基准。每个任务都会配对一个相关的仓库，以及一个自动化、人工策划的评价装置，该装置规定了实用的成功标准。除了衡量执行和任务成功之外，我们还提出了alpha值指标来量化代理性能的经济效益，该指标综合了任务成功率、令牌成本和平均开发人员工资。在三个最先进的代理框架和多个先进的LLM上的实验表明，利用代码仓库来解决复杂任务仍然具有挑战性：即使表现最佳的系统OpenHands+Claude 3.7也只能解决48.15%的任务（最近的进展已经将前沿进一步推进，RepoMaster+Claude 3.5创造了62.96%的新纪录）。错误分析将一半以上的失败归因于看似普通但关键步骤，如环境设置和依赖项解析，这突显出对更稳健的工作流管理和增加超时准备的必要性。我们发布GitTaskBench，旨在推动对感知仓库的代码推理、执行和部署的进展和关注，使代理更接近解决复杂、端到端的现实任务。基准测试和代码已开源，地址为：<a target="_blank" rel="noopener" href="https://github.com/QuantaAlpha/GitTaskBench%E3%80%82">https://github.com/QuantaAlpha/GitTaskBench。</a></p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.18993v2">PDF</a> Highly practical, Well-motivated, Actionable</p>
<p><strong>Summary</strong></p>
<p>本文介绍了一个名为GitTaskBench的基准测试，该测试旨在通过54个现实任务来系统地评估代码代理在真实工作流程驱动场景中的能力。测试涵盖了7个模态和领域，通过相关仓库与自动化的人类评估标准配对，评估代理的执行和实用性成功标准。除了衡量执行和任务成功外，还提出了alpha值指标来量化代理性能的经济效益，该指标综合了任务成功率、令牌成本和平均开发人员薪资。实验表明，利用代码仓库解决复杂任务仍然具有挑战性，最佳系统仅解决了48.15%的任务。通过开源GitTaskBench，旨在推动对仓库感知代码推理、执行和部署的关注和发展。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>GitTaskBench是一个旨在评估代码代理在真实软件开发场景中能力的基准测试。</li>
<li>测试包含54个现实任务，涵盖7个模态和领域。</li>
<li>测试通过相关仓库与自动化的人类评估标准配对来评估任务。</li>
<li>提出了alpha值指标来量化代理性能的经济效益。</li>
<li>实验表明，利用代码仓库解决复杂任务具有挑战性，最佳系统仅解决约一半任务。</li>
<li>错误分析显示，环境设置和依赖项解析等看似平凡但关键的步骤是导致失败的主要原因之一。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.18993">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-17\./crop_Agent/2508.18993v2/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-17\./crop_Agent/2508.18993v2/page_2_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-17\./crop_Agent/2508.18993v2/page_3_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-17\./crop_Agent/2508.18993v2/page_3_1.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-17\./crop_Agent/2508.18993v2/page_3_2.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-17\./crop_Agent/2508.18993v2/page_4_0.jpg" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1><h2 id="HiMATE-A-Hierarchical-Multi-Agent-Framework-for-Machine-Translation-Evaluation"><a href="#HiMATE-A-Hierarchical-Multi-Agent-Framework-for-Machine-Translation-Evaluation" class="headerlink" title="HiMATE: A Hierarchical Multi-Agent Framework for Machine Translation   Evaluation"></a>HiMATE: A Hierarchical Multi-Agent Framework for Machine Translation   Evaluation</h2><p><strong>Authors:Shijie Zhang, Renhao Li, Songsheng Wang, Philipp Koehn, Min Yang, Derek F. Wong</strong></p>
<p>The advancement of Large Language Models (LLMs) enables flexible and interpretable automatic evaluations. In the field of machine translation evaluation, utilizing LLMs with translation error annotations based on Multidimensional Quality Metrics (MQM) yields more human-aligned judgments. However, current LLM-based evaluation methods still face challenges in accurately identifying error spans and assessing their severity. In this paper, we propose HiMATE, a Hierarchical Multi-Agent Framework for Machine Translation Evaluation. We argue that existing approaches inadequately exploit the fine-grained structural and semantic information within the MQM hierarchy. To address this, we develop a hierarchical multi-agent system grounded in the MQM error typology, enabling granular evaluation of subtype errors. Two key strategies are incorporated to further mitigate systemic hallucinations within the framework: the utilization of the model’s self-reflection capability and the facilitation of agent discussion involving asymmetric information. Empirically, HiMATE outperforms competitive baselines across different datasets in conducting human-aligned evaluations. Further analyses underscore its significant advantage in error span detection and severity assessment, achieving an average F1-score improvement of 89% over the best-performing baseline. We make our code and data publicly available at <a target="_blank" rel="noopener" href="https://github.com/nlp2ct-shijie/HiMATE">https://github.com/nlp2ct-shijie/HiMATE</a>. </p>
<blockquote>
<p>随着大型语言模型（LLM）的进步，自动评估变得更加灵活和可解释。在机器翻译评估领域，利用基于多维度质量指标（MQM）的翻译错误注释的大型语言模型，可以产生更符合人类判断的结果。然而，当前的基于大型语言模型的评估方法仍然面临准确识别错误范围和评估其严重性的挑战。</p>
</blockquote>
<p>在本文中，我们提出了用于机器翻译评价的分层多智能体框架HiMATE。我们认为现有方法未能充分利用MQM层次结构中的精细粒度结构和语义信息。为了解决这个问题，我们开发了一个基于MQM错误分类的分层多智能体系统，实现对子类型错误的精细评估。为了进一步减轻系统内的幻觉现象，我们采用了两种关键策略：利用模型的自我反思能力和促进涉及不对称信息的智能体讨论。</p>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.16281v2">PDF</a> </p>
<p><strong>Summary</strong>：大型语言模型（LLM）的进步推动了机器翻译评估的灵活性和可解释性自动评估的发展。基于多维质量指标（MQM）的LLM翻译错误注释，使得评估结果更加符合人类判断。然而，当前基于LLM的评估方法仍面临准确识别错误跨度及其严重程度的问题。本研究提出了基于MQM错误分类的分层多智能体机器翻译评估框架HiMATE，通过融入模型自我反思能力和智能体讨论机制解决系统性幻觉问题。实验表明，HiMATE在不同数据集上优于其他基线方法，特别是在错误跨度检测和严重程度评估方面表现显著，平均F1分数提高了89%。</p>
<p><strong>Key Takeaways</strong>：</p>
<ol>
<li>大型语言模型（LLM）在机器翻译评估中表现出灵活性及可解释性自动评估的潜力。</li>
<li>基于多维质量指标（MQM）的LLM翻译错误注释，使得评估结果更加符合人类判断。</li>
<li>当前LLM在机器翻译评估中仍面临准确识别错误跨度及其严重程度的挑战。</li>
<li>提出的HiMATE框架是一种基于MQM错误分类的分层多智能体机器翻译评估方法。</li>
<li>HiMATE通过融入模型自我反思能力和智能体讨论机制解决系统性幻觉问题。</li>
<li>实验结果显示，HiMATE在不同数据集上的表现优于其他基线方法。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.16281">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-17\./crop_Agent/2505.16281v2/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-17\./crop_Agent/2505.16281v2/page_3_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-17\./crop_Agent/2505.16281v2/page_4_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-17\./crop_Agent/2505.16281v2/page_5_0.jpg" align="middle">
</details>


<h1 id="-9"><a href="#-9" class="headerlink" title=""></a></h1><h2 id="Kolb-Based-Experiential-Learning-for-Generalist-Agents-with-Human-Level-Kaggle-Data-Science-Performance"><a href="#Kolb-Based-Experiential-Learning-for-Generalist-Agents-with-Human-Level-Kaggle-Data-Science-Performance" class="headerlink" title="Kolb-Based Experiential Learning for Generalist Agents with Human-Level   Kaggle Data Science Performance"></a>Kolb-Based Experiential Learning for Generalist Agents with Human-Level   Kaggle Data Science Performance</h2><p><strong>Authors:Antoine Grosnit, Alexandre Maraval, Refinath S N, Zichao Zhao, James Doran, Giuseppe Paolo, Albert Thomas, Jonas Gonzalez, Abhineet Kumar, Khyati Khandelwal, Abdelhakim Benechehab, Hamza Cherkaoui, Youssef Attia El-Hili, Kun Shao, Jianye Hao, Jun Yao, Balázs Kégl, Haitham Bou-Ammar, Jun Wang</strong></p>
<p>Human expertise emerges through iterative cycles of interaction, reflection, and internal model updating, which are central to cognitive theories such as Kolb’s experiential learning and Vygotsky’s zone of proximal development. In contrast, current AI systems, particularly LLM agents, rely on static pre-training or rigid workflows, lacking mechanisms for continual adaptation. Recent studies identified early cognitive traits in LLM agents (reflection, revision, and self-correction) suggesting foundational elements of human-like experiential learning. Thus the key question: Can we design LLM agents capable of structured, cognitively grounded learning similar to human processes? In response, we propose a computational framework of Kolb’s learning cycle with Vygotsky’s ZPD for autonomous agents. Our architecture separates extrinsic (environment interaction) and intrinsic (internal reflection&#x2F;abstraction) functions, enabling cognitively grounded scaffolded learning, where the agent initially learns within structured environments, followed by open-ended generalisation. This approach empowers agents to master complex tasks ; domains that traditional fine-tuning or simple reflective methods could not tackle effectively. Its potential is powerfully demonstrated via direct comparison with humans in real-world Kaggle data science competitions. Learning fully automated data science code generation across 81 tasks, our system, Agent K, demonstrated the ability to perform the entire workflow autonomously, achieving an Elo-MMR score of 1694, beyond median score of the Kaggle Masters (the top 2% among 200,000 users) of our study. With 9 gold, 8 silver, and 12 bronze medals level performance - including 4 gold and 4 silver on prize-awarding competitions - Agent K is the 1st AI system to successfully integrate Kolb- and Vygotsky-inspired human cognitive learning, marking a major step toward generalist AI. </p>
<blockquote>
<p>人类专业知识是通过一系列迭代互动、反思和内部模型更新的循环过程逐渐形成的，这在柯尔布的体验式学习和维果斯基的最近发展区等认知理论中占据核心地位。相比之下，当前的人工智能系统，尤其是大型语言模型（LLM）代理，依赖于静态的预训练或刻板的工作流程，缺乏持续适应的机制。最近的研究在大型语言模型代理中发现了早期的认知特征（如反思、修订和自我校正），这表明了与人类体验式学习相似的基础要素。因此，关键问题是：我们能够设计出具有与人类过程相似的结构化、认知基础的大型语言模型（LLM）代理吗？作为回应，我们提出了一个基于柯尔布学习周期和维果斯基最近发展区的自主计算框架。我们的架构将外在（环境互动）和内在（内在反思&#x2F;抽象）功能分开，从而实现认知基础的支持学习，代理最初在结构化环境中学习，随后进行开放式泛化。这种方法使代理能够掌握复杂任务，这些任务在传统的微调或简单的反思方法无法有效处理。其在现实世界中的Kaggle数据科学竞赛中与人类的直接比较中展示了其潜力。学习全自动化数据科学代码生成跨81项任务时，我们的系统Agent K展现出完全自主执行整个工作流程的能力，达到了Elo-MMR分数为1694的水平，超过了我们的研究中Kaggle大师的中位数分数（即在20万名用户中排名前2%）。其表现获得了9枚金牌、8枚银牌和12枚铜牌的成绩——包括获奖竞赛中的4枚金牌和4枚银牌——Agent K是首个成功整合柯尔布和维果斯基启发的人类认知学习的人工智能系统，标志着通用人工智能迈出了重要的一步。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2411.03562v3">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>基于Kolb的体验学习和Vygotsky的最近发展区理论，提出了面向自主代理的计算框架，实现了结构化、以认知为基础的学习过程。通过分离外在（环境交互）和内在（内在反思&#x2F;抽象）功能，使代理最初在结构化的环境中学习，随后进行开放式泛化。这一方法赋予了代理掌握复杂任务的能力，在现实世界的数据科学竞赛中与人类直接比较展现了其潜力。首个整合了Kolb和Vygotsky认知学习理论的人工智能系统Agent K，取得了重大进展。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>人类专家通过互动、反思和内部模型更新的迭代循环出现，这是Kolb的体验学习和Vygotsky的最近发展区认知理论的核心。</li>
<li>当前AI系统，尤其是LLM代理，依赖于静态的预训练或僵硬的工作流程，缺乏持续适应的机制。</li>
<li>最近的研究发现LLM代理的早期认知特征（如反思、修订和自我校正），暗示了人类体验学习的基本要素。</li>
<li>提出了一种面向自主代理的计算框架，该框架基于Kolb的学习周期和Vygotsky的最近发展区理论，实现了结构化、以认知为基础的学习。</li>
<li>通过分离外在和内在功能，代理能够在结构化的环境中学习，然后进行开放式泛化，掌握了复杂任务的能力。</li>
<li>Agent K系统成功整合了Kolb和Vygotsky的认知学习理论，展现了强大的性能。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2411.03562">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-17\./crop_Agent/2411.03562v3/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-17\./crop_Agent/2411.03562v3/page_3_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-17\./crop_Agent/2411.03562v3/page_4_0.jpg" align="middle">
</details>


<h1 id="-10"><a href="#-10" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        文章作者:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        文章链接:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-09-17/Agent/">https://kedreamix.github.io/Talk2Paper/Paper/2025-09-17/Agent/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        版权声明:
                    </i>
                </span>
                <span class="reprint-info">
                    本博客所有文章除特別声明外，均采用
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    许可协议。转载请注明来源
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/Agent/">
                                    <span class="chip bg-color">Agent</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;上一篇</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-09-17/Few-Shot/">
                    <div class="card-image">
                        
                        <img src="D:\MyBlog\AutoFX\arxiv\2025-09-17\./crop_Few-Shot/2507.12932v2/page_5_1.jpg" class="responsive-img" alt="Few-Shot">
                        
                        <span class="card-title">Few-Shot</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Few-Shot 方向最新论文已更新，请持续关注 Update in 2025-09-17  UniPar A Unified LLM-Based Framework for Parallel and Accelerated Code   Translation in HPC
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-09-17
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Few-Shot/" class="post-category">
                                    Few-Shot
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Few-Shot/">
                        <span class="chip bg-color">Few-Shot</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-09-17/LLM/">
                    <div class="card-image">
                        
                        <img src="D:\MyBlog\AutoFX\arxiv\2025-09-17\./crop_LLM/2509.12152v1/page_5_1.jpg" class="responsive-img" alt="LLM">
                        
                        <span class="card-title">LLM</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            LLM 方向最新论文已更新，请持续关注 Update in 2025-09-17  Survival at Any Cost? LLMs and the Choice Between Self-Preservation and   Human Harm
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-09-17
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/LLM/" class="post-category">
                                    LLM
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/LLM/">
                        <span class="chip bg-color">LLM</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- 代码语言 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span
                        class="white-color">28315.1k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- 运行天数提醒. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // 区分是否有年份.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = '本站已运行 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                daysTip = '本站已運行 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = '本站已运行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = '本站已運行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="关注我的知乎: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">知</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- 白天和黑夜主题 -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // 只在桌面版网页启用特效
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- 雪花特效 -->
    

    <!-- 鼠标星星特效 -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--腾讯兔小巢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- 动态标签 -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Σ(っ °Д °;)っ诶，页面崩溃了嘛？", clearTimeout(st)) : (document.title = "φ(゜▽゜*)♪咦，又好了！", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
