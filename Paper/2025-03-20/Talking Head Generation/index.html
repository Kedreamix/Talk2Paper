<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Talking Head Generation">
    <meta name="description" content="Talking Head Generation æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-03-20  PC-Talk Precise Facial Animation Control for Audio-Driven Talking Face   Generation">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>Talking Head Generation | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://pic1.zhimg.com/v2-f9262304a8a2a125837231f0f70d031f.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Talking Head Generation</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/Talking-Head-Generation/">
                                <span class="chip bg-color">Talking Head Generation</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/Talking-Head-Generation/" class="post-category">
                                Talking Head Generation
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-03-20
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-05-14
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    6.9k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    28 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-03-20-æ›´æ–°"><a href="#2025-03-20-æ›´æ–°" class="headerlink" title="2025-03-20 æ›´æ–°"></a>2025-03-20 æ›´æ–°</h1><h2 id="PC-Talk-Precise-Facial-Animation-Control-for-Audio-Driven-Talking-Face-Generation"><a href="#PC-Talk-Precise-Facial-Animation-Control-for-Audio-Driven-Talking-Face-Generation" class="headerlink" title="PC-Talk: Precise Facial Animation Control for Audio-Driven Talking Face   Generation"></a>PC-Talk: Precise Facial Animation Control for Audio-Driven Talking Face   Generation</h2><p><strong>Authors:Baiqin Wang, Xiangyu Zhu, Fan Shen, Hao Xu, Zhen Lei</strong></p>
<p>Recent advancements in audio-driven talking face generation have made great progress in lip synchronization. However, current methods often lack sufficient control over facial animation such as speaking style and emotional expression, resulting in uniform outputs. In this paper, we focus on improving two key factors: lip-audio alignment and emotion control, to enhance the diversity and user-friendliness of talking videos. Lip-audio alignment control focuses on elements like speaking style and the scale of lip movements, whereas emotion control is centered on generating realistic emotional expressions, allowing for modifications in multiple attributes such as intensity. To achieve precise control of facial animation, we propose a novel framework, PC-Talk, which enables lip-audio alignment and emotion control through implicit keypoint deformations. First, our lip-audio alignment control module facilitates precise editing of speaking styles at the word level and adjusts lip movement scales to simulate varying vocal loudness levels, maintaining lip synchronization with the audio. Second, our emotion control module generates vivid emotional facial features with pure emotional deformation. This module also enables the fine modification of intensity and the combination of multiple emotions across different facial regions. Our method demonstrates outstanding control capabilities and achieves state-of-the-art performance on both HDTF and MEAD datasets in extensive experiments. </p>
<blockquote>
<p>è¿‘æœŸéŸ³é¢‘é©±åŠ¨è¯´è¯äººè„¸ç”ŸæˆæŠ€æœ¯çš„è¿›å±•åœ¨å˜´å”‡åŒæ­¥æ–¹é¢å–å¾—äº†å¾ˆå¤§çš„è¿›æ­¥ã€‚ç„¶è€Œï¼Œå½“å‰çš„æ–¹æ³•å¾€å¾€å¯¹é¢éƒ¨åŠ¨ç”»çš„æ§åˆ¶ä¸è¶³ï¼Œå¦‚æ¼”è®²é£æ ¼å’Œæƒ…æ„Ÿè¡¨è¾¾ï¼Œå¯¼è‡´è¾“å‡ºå•ä¸€ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬ä¸“æ³¨äºæ”¹è¿›ä¸¤ä¸ªå…³é”®å› ç´ ï¼šå”‡éŸ³é¢‘å¯¹é½å’Œæƒ…æ„Ÿæ§åˆ¶ï¼Œä»¥æé«˜å¯¹è¯è§†é¢‘çš„å¤šæ ·æ€§å’Œç”¨æˆ·å‹å¥½æ€§ã€‚å”‡éŸ³é¢‘å¯¹é½æ§åˆ¶ä¸“æ³¨äºæ¼”è®²é£æ ¼å’Œå˜´å”‡è¿åŠ¨è§„æ¨¡ç­‰å…ƒç´ ï¼Œè€Œæƒ…æ„Ÿæ§åˆ¶åˆ™ä¾§é‡äºç”Ÿæˆé€¼çœŸçš„æƒ…æ„Ÿè¡¨è¾¾ï¼Œå…è®¸å¼ºåº¦ç­‰å¤šä¸ªå±æ€§çš„ä¿®æ”¹ã€‚ä¸ºäº†å®ç°é¢éƒ¨åŠ¨ç”»çš„ç²¾ç¡®æ§åˆ¶ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°å‹æ¡†æ¶PC-Talkï¼Œå®ƒé€šè¿‡éšå¼å…³é”®ç‚¹å˜å½¢å®ç°å”‡éŸ³é¢‘å¯¹é½å’Œæƒ…æ„Ÿæ§åˆ¶ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬çš„å”‡éŸ³é¢‘å¯¹é½æ§åˆ¶æ¨¡å—ä¾¿äºç²¾ç¡®ç¼–è¾‘å•è¯çº§åˆ«çš„æ¼”è®²é£æ ¼ï¼Œå¹¶è°ƒæ•´å˜´å”‡è¿åŠ¨è§„æ¨¡ä»¥æ¨¡æ‹Ÿä¸åŒçš„éŸ³é‡æ°´å¹³ï¼ŒåŒæ—¶ä¿æŒä¸éŸ³é¢‘çš„å˜´å”‡åŒæ­¥ã€‚å…¶æ¬¡ï¼Œæˆ‘ä»¬çš„æƒ…æ„Ÿæ§åˆ¶æ¨¡å—é€šè¿‡çº¯æƒ…æ„Ÿå˜å½¢ç”Ÿæˆç”ŸåŠ¨çš„æƒ…æ„Ÿé¢éƒ¨ç‰¹å¾ã€‚è¯¥æ¨¡å—è¿˜å®ç°äº†å¼ºåº¦çš„ç²¾ç»†ä¿®æ”¹å’Œä¸åŒé¢éƒ¨åŒºåŸŸå¤šç§æƒ…æ„Ÿçš„ç»„åˆã€‚æˆ‘ä»¬çš„æ–¹æ³•å±•ç¤ºäº†å‡ºè‰²çš„æ§åˆ¶èƒ½åŠ›ï¼Œå¹¶åœ¨HDTFå’ŒMEADæ•°æ®é›†ä¸Šçš„å¹¿æ³›å®éªŒä¸­è¾¾åˆ°äº†æœ€æ–°æ€§èƒ½ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.14295v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†éŸ³é¢‘é©±åŠ¨çš„è¯´è¯é¢éƒ¨ç”ŸæˆæŠ€æœ¯çš„æœ€æ–°è¿›å±•ï¼Œé‡ç‚¹è§£å†³äº†å”‡éŸ³å¯¹é½å’Œæƒ…ç»ªæ§åˆ¶ä¸¤ä¸ªå…³é”®é—®é¢˜ï¼Œä»¥æé«˜è¯´è¯è§†é¢‘çš„å¤šæ ·æ€§å’Œç”¨æˆ·å‹å¥½æ€§ã€‚æ–‡ç« æå‡ºäº†ä¸€ç§æ–°çš„æ¡†æ¶PC-Talkï¼Œé€šè¿‡éšæ€§å…³é”®ç‚¹å˜å½¢å®ç°é¢éƒ¨åŠ¨ç”»çš„ç²¾ç¡®æ§åˆ¶ã€‚è¯¥æ¡†æ¶åŒ…æ‹¬å”‡éŸ³å¯¹é½æ§åˆ¶æ¨¡å—å’Œæƒ…ç»ªæ§åˆ¶æ¨¡å—ï¼Œå‰è€…å¯ä»¥åœ¨è¯çº§ç²¾ç¡®ç¼–è¾‘è¯´è¯é£æ ¼å¹¶è°ƒæ•´å”‡éƒ¨è¿åŠ¨å¹…åº¦ä»¥æ¨¡æ‹Ÿä¸åŒçš„éŸ³é‡æ°´å¹³ï¼Œåè€…å¯ä»¥ç”Ÿæˆé€¼çœŸçš„æƒ…æ„Ÿé¢éƒ¨è¡¨æƒ…å¹¶ç²¾ç»†è°ƒæ•´æƒ…æ„Ÿå¼ºåº¦ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>è¿‘æœŸéŸ³é¢‘é©±åŠ¨çš„è¯´è¯é¢éƒ¨ç”ŸæˆæŠ€æœ¯åœ¨å”‡åŒæ­¥æ–¹é¢å–å¾—æ˜¾è‘—è¿›å±•ï¼Œä½†å¯¹é¢éƒ¨åŠ¨ç”»çš„æ§åˆ¶å¦‚è¯´è¯é£æ ¼å’Œæƒ…æ„Ÿè¡¨è¾¾æ–¹é¢ä»æœ‰ä¸è¶³ã€‚</li>
<li>è®ºæ–‡ä¸»è¦è§£å†³å”‡éŸ³å¯¹é½å’Œæƒ…ç»ªæ§åˆ¶ä¸¤ä¸ªå…³é”®é—®é¢˜ï¼Œæ—¨åœ¨æé«˜è¯´è¯è§†é¢‘çš„å¤šæ ·æ€§å’Œç”¨æˆ·å‹å¥½æ€§ã€‚</li>
<li>æå‡ºçš„PC-Talkæ¡†æ¶é€šè¿‡éšæ€§å…³é”®ç‚¹å˜å½¢å®ç°é¢éƒ¨åŠ¨ç”»çš„ç²¾ç¡®æ§åˆ¶ã€‚</li>
<li>å”‡éŸ³å¯¹é½æ§åˆ¶æ¨¡å—å¯ä»¥ç²¾ç¡®ç¼–è¾‘è¯´è¯é£æ ¼ï¼Œè°ƒæ•´å”‡éƒ¨è¿åŠ¨å¹…åº¦ä»¥æ¨¡æ‹Ÿä¸åŒçš„éŸ³é‡æ°´å¹³ã€‚</li>
<li>æƒ…ç»ªæ§åˆ¶æ¨¡å—å¯ä»¥ç”Ÿæˆé€¼çœŸçš„æƒ…æ„Ÿé¢éƒ¨è¡¨æƒ…ï¼Œå¹¶å…è®¸å¯¹æƒ…æ„Ÿå¼ºåº¦è¿›è¡Œå¾®è°ƒã€‚</li>
<li>PC-Talkæ¡†æ¶åœ¨HDTFå’ŒMEADæ•°æ®é›†ä¸Šçš„å®éªŒè¡¨ç°ä¼˜å¼‚ï¼Œå±•ç°äº†å‡ºè‰²çš„æ§åˆ¶èƒ½åŠ›ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.14295">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-0dea4682391aea1e14e875c46d2f39a2.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-3154734d3aa3d378f235a6e8001265a1.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-8b6fd1e3fad00bf64b745ae760052ccd.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-db2d75adbbe2a300522365c7a04e510e.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-ead007beafb3e49e90d0d544358ec5a7.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-5183ebdaf5036076cade30390574de47.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="SyncDiff-Diffusion-based-Talking-Head-Synthesis-with-Bottlenecked-Temporal-Visual-Prior-for-Improved-Synchronization"><a href="#SyncDiff-Diffusion-based-Talking-Head-Synthesis-with-Bottlenecked-Temporal-Visual-Prior-for-Improved-Synchronization" class="headerlink" title="SyncDiff: Diffusion-based Talking Head Synthesis with Bottlenecked   Temporal Visual Prior for Improved Synchronization"></a>SyncDiff: Diffusion-based Talking Head Synthesis with Bottlenecked   Temporal Visual Prior for Improved Synchronization</h2><p><strong>Authors:Xulin Fan, Heting Gao, Ziyi Chen, Peng Chang, Mei Han, Mark Hasegawa-Johnson</strong></p>
<p>Talking head synthesis, also known as speech-to-lip synthesis, reconstructs the facial motions that align with the given audio tracks. The synthesized videos are evaluated on mainly two aspects, lip-speech synchronization and image fidelity. Recent studies demonstrate that GAN-based and diffusion-based models achieve state-of-the-art (SOTA) performance on this task, with diffusion-based models achieving superior image fidelity but experiencing lower synchronization compared to their GAN-based counterparts. To this end, we propose SyncDiff, a simple yet effective approach to improve diffusion-based models using a temporal pose frame with information bottleneck and facial-informative audio features extracted from AVHuBERT, as conditioning input into the diffusion process. We evaluate SyncDiff on two canonical talking head datasets, LRS2 and LRS3 for direct comparison with other SOTA models. Experiments on LRS2&#x2F;LRS3 datasets show that SyncDiff achieves a synchronization score 27.7%&#x2F;62.3% relatively higher than previous diffusion-based methods, while preserving their high-fidelity characteristics. </p>
<blockquote>
<p>è¯´è¯äººå¤´éƒ¨åˆæˆï¼Œä¹Ÿè¢«ç§°ä¸ºè¯­éŸ³å¯¹å£å‹åˆæˆï¼Œä¼šé‡å»ºä¸ç»™å®šéŸ³é¢‘è½¨è¿¹ç›¸å¯¹åº”çš„é¢éƒ¨åŠ¨ä½œã€‚å¯¹åˆæˆè§†é¢‘çš„è¯„ä¼°ä¸»è¦é›†ä¸­åœ¨ä¸¤ä¸ªæ–¹é¢ï¼šå£å‹è¯­éŸ³åŒæ­¥å’Œå›¾åƒä¿çœŸåº¦ã€‚æœ€è¿‘çš„ç ”ç©¶è¡¨æ˜ï¼ŒåŸºäºç”Ÿæˆå¯¹æŠ—ç½‘ç»œï¼ˆGANï¼‰å’Œæ‰©æ•£æ¨¡å‹çš„æ–¹æ³•åœ¨è¿™é¡¹ä»»åŠ¡ä¸Šè¾¾åˆ°äº†æœ€æ–°æŠ€æœ¯æ°´å¹³ï¼ˆSOTAï¼‰ï¼Œå…¶ä¸­æ‰©æ•£æ¨¡å‹åœ¨å›¾åƒä¿çœŸåº¦æ–¹é¢è¡¨ç°æ›´ä½³ï¼Œä½†ä¸åŸºäºGANçš„æ–¹æ³•ç›¸æ¯”åŒæ­¥æ€§è¾ƒä½ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬æå‡ºäº†SyncDiffï¼Œè¿™æ˜¯ä¸€ç§ç®€å•æœ‰æ•ˆçš„æ–¹æ³•ï¼Œé€šè¿‡é‡‡ç”¨åŒ…å«ä¿¡æ¯ç“¶é¢ˆçš„ä¸´æ—¶å§¿æ€å¸§å’Œä»AVHuBERTä¸­æå–çš„é¢éƒ¨ä¿¡æ¯éŸ³é¢‘ç‰¹å¾ä½œä¸ºæ‰©æ•£è¿‡ç¨‹çš„æ¡ä»¶è¾“å…¥ï¼Œæ”¹è¿›äº†åŸºäºæ‰©æ•£çš„æ¨¡å‹ã€‚æˆ‘ä»¬åœ¨ä¸¤ä¸ªæ ‡å‡†çš„è¯´è¯äººå¤´éƒ¨æ•°æ®é›†LRS2å’ŒLRS3ä¸Šå¯¹SyncDiffè¿›è¡Œäº†è¯„ä¼°ï¼Œä»¥ä¾¿ä¸å…¶ä»–æœ€æ–°æŠ€æœ¯æ¨¡å‹è¿›è¡Œç›´æ¥æ¯”è¾ƒã€‚åœ¨LRS2&#x2F;LRS3æ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒSyncDiffç›¸å¯¹äºä¹‹å‰çš„æ‰©æ•£æ–¹æ³•å®ç°äº†æ›´é«˜çš„åŒæ­¥å¾—åˆ†ï¼Œæé«˜äº†27.7%&#x2F;62.3%ï¼ŒåŒæ—¶ä¿æŒäº†å…¶é«˜ä¿çœŸç‰¹æ€§ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.13371v1">PDF</a> Accepted to WACV 2025</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†è¯´è¯äººå¤´éƒ¨åˆæˆæŠ€æœ¯ï¼Œé‡ç‚¹è®¨è®ºäº†åŸºäºæ‰©æ•£æ¨¡å‹çš„æ”¹è¿›æ–¹æ³•SyncDiffã€‚SyncDiffåˆ©ç”¨æ—¶é—´å§¿åŠ¿å¸§å’Œé¢éƒ¨ä¿¡æ¯éŸ³é¢‘ç‰¹å¾ï¼Œæé«˜äº†æ‰©æ•£æ¨¡å‹çš„æ€§èƒ½ï¼Œå®ç°äº†æ›´å‡†ç¡®çš„å”‡éŸ³åŒæ­¥å’Œé«˜ä¿çœŸå›¾åƒã€‚åœ¨LRS2å’ŒLRS3æ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒSyncDiffç›¸è¾ƒäºå…¶ä»–å…ˆè¿›æ¨¡å‹æœ‰æ›´å¥½çš„åŒæ­¥æ€§èƒ½ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>è¯´è¯äººå¤´éƒ¨åˆæˆæŠ€æœ¯åŒ…æ‹¬è¯­éŸ³åˆ°å”‡éƒ¨çš„åˆæˆï¼Œä¸»è¦è¯„ä¼°ä¸¤ä¸ªæ–¹é¢ï¼šå”‡è¯­éŸ³åŒæ­¥å’Œå›¾åƒä¿çœŸåº¦ã€‚</li>
<li>GANæ¨¡å‹å’Œæ‰©æ•£æ¨¡å‹æ˜¯ç›®å‰è¯¥ä»»åŠ¡çš„æœ€å…ˆè¿›æ¨¡å‹ã€‚</li>
<li>æ‰©æ•£æ¨¡å‹åœ¨å›¾åƒä¿çœŸåº¦ä¸Šè¡¨ç°ä¼˜è¶Šï¼Œä½†åœ¨åŒæ­¥æ–¹é¢ç›¸å¯¹è¾ƒå·®ã€‚</li>
<li>SyncDiffæ–¹æ³•æ˜¯ä¸€ç§ç®€å•æœ‰æ•ˆçš„æ”¹è¿›æ‰©æ•£æ¨¡å‹çš„æ–¹æ³•ï¼Œé€šè¿‡ä½¿ç”¨æ—¶é—´å§¿åŠ¿å¸§å’Œé¢éƒ¨ä¿¡æ¯éŸ³é¢‘ç‰¹å¾ä½œä¸ºæ¡ä»¶è¾“å…¥åˆ°æ‰©æ•£è¿‡ç¨‹ä¸­ã€‚</li>
<li>SyncDiffåœ¨LRS2å’ŒLRS3æ•°æ®é›†ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼Œå…¶åŒæ­¥å¾—åˆ†ç›¸è¾ƒäºå…¶ä»–å…ˆè¿›æ¨¡å‹æœ‰æ˜¾è‘—æé«˜ã€‚</li>
<li>SyncDiffæ–¹æ³•èƒ½å¤Ÿåœ¨ä¿æŒé«˜ä¿çœŸç‰¹æ€§çš„åŒæ—¶ï¼Œæé«˜å”‡è¯­éŸ³åŒæ­¥çš„å‡†ç¡®æ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.13371">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-04cd02607912ce44d044088f63bf2ed2.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-598cdbf1892330f99a556135b5920cae.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c7f6ef84b4251bd688f1f479c3887a61.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-70406ef38b0eeaafa7b28d980054ce5a.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="Unlock-Pose-Diversity-Accurate-and-Efficient-Implicit-Keypoint-based-Spatiotemporal-Diffusion-for-Audio-driven-Talking-Portrait"><a href="#Unlock-Pose-Diversity-Accurate-and-Efficient-Implicit-Keypoint-based-Spatiotemporal-Diffusion-for-Audio-driven-Talking-Portrait" class="headerlink" title="Unlock Pose Diversity: Accurate and Efficient Implicit Keypoint-based   Spatiotemporal Diffusion for Audio-driven Talking Portrait"></a>Unlock Pose Diversity: Accurate and Efficient Implicit Keypoint-based   Spatiotemporal Diffusion for Audio-driven Talking Portrait</h2><p><strong>Authors:Chaolong Yang, Kai Yao, Yuyao Yan, Chenru Jiang, Weiguang Zhao, Jie Sun, Guangliang Cheng, Yifei Zhang, Bin Dong, Kaizhu Huang</strong></p>
<p>Audio-driven single-image talking portrait generation plays a crucial role in virtual reality, digital human creation, and filmmaking. Existing approaches are generally categorized into keypoint-based and image-based methods. Keypoint-based methods effectively preserve character identity but struggle to capture fine facial details due to the fixed points limitation of the 3D Morphable Model. Moreover, traditional generative networks face challenges in establishing causality between audio and keypoints on limited datasets, resulting in low pose diversity. In contrast, image-based approaches produce high-quality portraits with diverse details using the diffusion network but incur identity distortion and expensive computational costs. In this work, we propose KDTalker, the first framework to combine unsupervised implicit 3D keypoint with a spatiotemporal diffusion model. Leveraging unsupervised implicit 3D keypoints, KDTalker adapts facial information densities, allowing the diffusion process to model diverse head poses and capture fine facial details flexibly. The custom-designed spatiotemporal attention mechanism ensures accurate lip synchronization, producing temporally consistent, high-quality animations while enhancing computational efficiency. Experimental results demonstrate that KDTalker achieves state-of-the-art performance regarding lip synchronization accuracy, head pose diversity, and execution efficiency.Our codes are available at <a target="_blank" rel="noopener" href="https://github.com/chaolongy/KDTalker">https://github.com/chaolongy/KDTalker</a>. </p>
<blockquote>
<p>éŸ³é¢‘é©±åŠ¨çš„å•å›¾åƒè¯´è¯è‚–åƒç”Ÿæˆåœ¨è™šæ‹Ÿç°å®ã€æ•°å­—äººç±»åˆ›å»ºå’Œç”µå½±åˆ¶ä½œä¸­æ‰®æ¼”ç€è‡³å…³é‡è¦çš„è§’è‰²ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸åˆ†ä¸ºåŸºäºå…³é”®ç‚¹çš„æ–¹æ³•å’ŒåŸºäºå›¾åƒçš„æ–¹æ³•ã€‚åŸºäºå…³é”®ç‚¹çš„æ–¹æ³•èƒ½å¤Ÿæœ‰æ•ˆåœ°ä¿ç•™äººç‰©èº«ä»½ï¼Œä½†ç”±äº3Då¯å˜å½¢æ¨¡å‹çš„å›ºå®šç‚¹é™åˆ¶ï¼Œå¾ˆéš¾æ•æ‰é¢éƒ¨ç»†èŠ‚ã€‚æ­¤å¤–ï¼Œä¼ ç»Ÿçš„ç”Ÿæˆç½‘ç»œåœ¨æœ‰é™æ•°æ®é›†ä¸Šå»ºç«‹éŸ³é¢‘å’Œå…³é”®ç‚¹ä¹‹é—´çš„å› æœå…³ç³»æ—¶é¢ä¸´æŒ‘æˆ˜ï¼Œå¯¼è‡´å§¿åŠ¿å¤šæ ·æ€§è¾ƒä½ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼ŒåŸºäºå›¾åƒçš„æ–¹æ³•ä½¿ç”¨æ‰©æ•£ç½‘ç»œç”Ÿæˆå…·æœ‰å„ç§ç»†èŠ‚çš„é«˜è´¨é‡è‚–åƒï¼Œä½†ä¼šäº§ç”Ÿèº«ä»½å¤±çœŸå’Œæ˜‚è´µçš„è®¡ç®—æˆæœ¬ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†KDTalkerï¼Œè¿™æ˜¯ç¬¬ä¸€ä¸ªç»“åˆæ— ç›‘ç£éšå¼3Då…³é”®ç‚¹å’Œæ—¶ç©ºæ‰©æ•£æ¨¡å‹çš„æ¡†æ¶ã€‚åˆ©ç”¨æ— ç›‘ç£éšå¼3Då…³é”®ç‚¹ï¼ŒKDTalkeré€‚åº”é¢éƒ¨ä¿¡æ¯å¯†åº¦ï¼Œä½¿æ‰©æ•£è¿‡ç¨‹èƒ½å¤Ÿçµæ´»åœ°æ¨¡æ‹Ÿå„ç§å¤´éƒ¨å§¿åŠ¿å¹¶æ•æ‰é¢éƒ¨ç»†èŠ‚ã€‚å®šåˆ¶è®¾è®¡çš„æ—¶ç©ºæ³¨æ„åŠ›æœºåˆ¶ç¡®ä¿å‡†ç¡®çš„å”‡éƒ¨åŒæ­¥ï¼Œäº§ç”Ÿæ—¶é—´ä¸€è‡´çš„é«˜è´¨é‡åŠ¨ç”»ï¼ŒåŒæ—¶æé«˜è®¡ç®—æ•ˆç‡ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒKDTalkeråœ¨å”‡éƒ¨åŒæ­¥å‡†ç¡®æ€§ã€å¤´éƒ¨å§¿åŠ¿å¤šæ ·æ€§å’Œæ‰§è¡Œæ•ˆç‡æ–¹é¢è¾¾åˆ°æœ€æ–°æŠ€æœ¯æ°´å¹³ã€‚æˆ‘ä»¬çš„ä»£ç å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/chaolongy/KDTalker%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/chaolongy/KDTalkeræ‰¾åˆ°ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.12963v1">PDF</a> </p>
<p><strong>Summary</strong><br>åŸºäºéŸ³é¢‘é©±åŠ¨çš„å•å›¾åƒè¯´è¯è‚–åƒç”Ÿæˆåœ¨è™šæ‹Ÿç°å®ã€æ•°å­—äººç±»åˆ›å»ºå’Œç”µå½±åˆ¶ä½œä¸­èµ·ç€è‡³å…³é‡è¦çš„ä½œç”¨ã€‚ç°æœ‰æ–¹æ³•ä¸»è¦åˆ†ä¸ºåŸºäºå…³é”®ç‚¹çš„æ–¹æ³•å’ŒåŸºäºå›¾åƒçš„æ–¹æ³•ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§ç»“åˆæ— ç›‘ç£éšå¼ä¸‰ç»´å…³é”®ç‚¹ä¸æ—¶ç©ºæ‰©æ•£æ¨¡å‹çš„æ¡†æ¶KDTalkerã€‚å®ƒé‡‡ç”¨æ— ç›‘ç£éšå¼ä¸‰ç»´å…³é”®ç‚¹ï¼Œè‡ªé€‚åº”é¢éƒ¨ä¿¡æ¯å¯†åº¦ï¼Œä½¿æ‰©æ•£è¿‡ç¨‹èƒ½å¤Ÿçµæ´»å»ºæ¨¡å¤šç§å¤´éƒ¨å§¿æ€å¹¶æ•æ‰é¢éƒ¨ç»†èŠ‚ã€‚å®šåˆ¶è®¾è®¡çš„æ—¶ç©ºæ³¨æ„åŠ›æœºåˆ¶ç¡®ä¿äº†å‡†ç¡®çš„å”‡åŒæ­¥ï¼Œäº§ç”Ÿæ—¶é—´è¿è´¯çš„é«˜è´¨é‡åŠ¨ç”»ï¼ŒåŒæ—¶æé«˜è®¡ç®—æ•ˆç‡ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>éŸ³é¢‘é©±åŠ¨çš„å•å›¾åƒè¯´è¯è‚–åƒç”Ÿæˆåœ¨å¤šä¸ªé¢†åŸŸæœ‰é‡è¦åº”ç”¨ã€‚</li>
<li>ç°æœ‰æ–¹æ³•åˆ†ä¸ºåŸºäºå…³é”®ç‚¹å’ŒåŸºäºå›¾åƒä¸¤å¤§ç±»ï¼Œå„æœ‰ä¼˜ç¼ºç‚¹ã€‚</li>
<li>åŸºäºå…³é”®ç‚¹çš„æ–¹æ³•è™½èƒ½ä¿ç•™è§’è‰²èº«ä»½ï¼Œä½†éš¾ä»¥æ•æ‰é¢éƒ¨ç»†èŠ‚ã€‚</li>
<li>ä¼ ç»Ÿç”Ÿæˆç½‘ç»œåœ¨å»ºç«‹éŸ³é¢‘ä¸å…³é”®ç‚¹ä¹‹é—´çš„å› æœå…³ç³»æ—¶é¢ä¸´æŒ‘æˆ˜ã€‚</li>
<li>åŸºäºå›¾åƒçš„æ–¹æ³•èƒ½äº§ç”Ÿé«˜è´¨é‡è‚–åƒï¼Œä½†å¯èƒ½äº§ç”Ÿèº«ä»½æ‰­æ›²å’Œè®¡ç®—æˆæœ¬é«˜çš„é—®é¢˜ã€‚</li>
<li>KDTalkeræ¡†æ¶ç»“åˆäº†æ— ç›‘ç£éšå¼ä¸‰ç»´å…³é”®ç‚¹å’Œæ—¶ç©ºæ‰©æ•£æ¨¡å‹ï¼Œæé«˜äº†é¢éƒ¨ä¿¡æ¯æ•æ‰çš„çµæ´»æ€§å’Œå‡†ç¡®æ€§ã€‚</li>
<li>KDTalkerå®ç°äº†å…ˆè¿›çš„å”‡åŒæ­¥ç²¾åº¦ã€å¤´éƒ¨å§¿æ€å¤šæ ·æ€§å’Œæ‰§è¡Œæ•ˆç‡ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.12963">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-a889d7e910f61352d3fa643e52b58e4a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-5203dc0be2d3da64f568e4872272ea2f.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-49aaa97d719087b1bfb1a2ae82312e86.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-f9262304a8a2a125837231f0f70d031f.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="Prosody-Enhanced-Acoustic-Pre-training-and-Acoustic-Disentangled-Prosody-Adapting-for-Movie-Dubbing"><a href="#Prosody-Enhanced-Acoustic-Pre-training-and-Acoustic-Disentangled-Prosody-Adapting-for-Movie-Dubbing" class="headerlink" title="Prosody-Enhanced Acoustic Pre-training and Acoustic-Disentangled Prosody   Adapting for Movie Dubbing"></a>Prosody-Enhanced Acoustic Pre-training and Acoustic-Disentangled Prosody   Adapting for Movie Dubbing</h2><p><strong>Authors:Zhedong Zhang, Liang Li, Chenggang Yan, Chunshan Liu, Anton van den Hengel, Yuankai Qi</strong></p>
<p>Movie dubbing describes the process of transforming a script into speech that aligns temporally and emotionally with a given movie clip while exemplifying the speakerâ€™s voice demonstrated in a short reference audio clip. This task demands the model bridge character performances and complicated prosody structures to build a high-quality video-synchronized dubbing track. The limited scale of movie dubbing datasets, along with the background noise inherent in audio data, hinder the acoustic modeling performance of trained models. To address these issues, we propose an acoustic-prosody disentangled two-stage method to achieve high-quality dubbing generation with precise prosody alignment. First, we propose a prosody-enhanced acoustic pre-training to develop robust acoustic modeling capabilities. Then, we freeze the pre-trained acoustic system and design a disentangled framework to model prosodic text features and dubbing style while maintaining acoustic quality. Additionally, we incorporate an in-domain emotion analysis module to reduce the impact of visual domain shifts across different movies, thereby enhancing emotion-prosody alignment. Extensive experiments show that our method performs favorably against the state-of-the-art models on two primary benchmarks. The demos are available at <a target="_blank" rel="noopener" href="https://zzdoog.github.io/ProDubber/">https://zzdoog.github.io/ProDubber/</a>. </p>
<blockquote>
<p>ç”µå½±é…éŸ³æ˜¯å°†å‰§æœ¬è½¬åŒ–ä¸ºä¸ç»™å®šç”µå½±ç‰‡æ®µåœ¨æ—¶é—´å’Œæƒ…æ„Ÿä¸Šå¯¹é½çš„å°è¯çš„è¿‡ç¨‹ï¼ŒåŒæ—¶ä»¥ç®€çŸ­å‚è€ƒéŸ³é¢‘ç‰‡æ®µä¸­çš„æ¼”ç¤ºè€…çš„å£°éŸ³ä¸ºæ¦œæ ·ã€‚è¿™é¡¹ä»»åŠ¡è¦æ±‚æ¨¡å‹å°†è§’è‰²è¡¨æ¼”å’Œå¤æ‚çš„éŸµå¾‹ç»“æ„ç»“åˆèµ·æ¥ï¼Œä»¥æ„å»ºé«˜è´¨é‡çš„ä¸è§†é¢‘åŒæ­¥çš„é…éŸ³è½¨è¿¹ã€‚ç”µå½±é…éŸ³æ•°æ®é›†è§„æ¨¡çš„æœ‰é™æ€§ï¼Œä»¥åŠéŸ³é¢‘æ•°æ®ä¸­çš„èƒŒæ™¯å™ªéŸ³ï¼Œé˜»ç¢äº†è®­ç»ƒæ¨¡å‹çš„å£°å­¦å»ºæ¨¡æ€§èƒ½ã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§å£°å­¦éŸµå¾‹è§£è€¦çš„ä¸¤é˜¶æ®µæ–¹æ³•æ¥å®ç°é«˜è´¨é‡çš„é…éŸ³ç”Ÿæˆï¼Œå…·æœ‰ç²¾ç¡®éŸµå¾‹å¯¹é½ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§éŸµå¾‹å¢å¼ºçš„å£°å­¦é¢„è®­ç»ƒï¼Œä»¥å‘å±•ç¨³å¥çš„å£°å­¦å»ºæ¨¡èƒ½åŠ›ã€‚ç„¶åï¼Œæˆ‘ä»¬å†»ç»“é¢„è®­ç»ƒçš„å£°å­¦ç³»ç»Ÿï¼Œè®¾è®¡ä¸€ä¸ªè§£è€¦æ¡†æ¶æ¥å»ºæ¨¡æ–‡æœ¬ç‰¹å¾å’Œé…éŸ³é£æ ¼ï¼ŒåŒæ—¶ä¿æŒå£°å­¦è´¨é‡ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬åŠ å…¥äº†ä¸€ä¸ªé¢†åŸŸå†…çš„æƒ…æ„Ÿåˆ†ææ¨¡å—ï¼Œä»¥å‡å°‘ä¸åŒç”µå½±ä¹‹é—´è§†è§‰é¢†åŸŸå˜åŒ–çš„å½±å“ï¼Œä»è€Œå¢å¼ºæƒ…æ„ŸéŸµå¾‹å¯¹é½ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨ä¸¤ä¸ªä¸»è¦åŸºå‡†æµ‹è¯•ä¸Šçš„è¡¨ç°ä¼˜äºæœ€å…ˆè¿›çš„æ¨¡å‹ã€‚æ¼”ç¤ºåœ°å€æ˜¯ï¼š<a target="_blank" rel="noopener" href="https://zzdoog.github.io/ProDubber/%E3%80%82">https://zzdoog.github.io/ProDubber/ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.12042v2">PDF</a> Accepted by CVPR2025</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†ç”µå½±é…éŸ³çš„è¿‡ç¨‹ï¼Œå¹¶æŒ‡å‡ºäº†ç°æœ‰æ•°æ®é›†å’ŒéŸ³é¢‘æ•°æ®ä¸­çš„èƒŒæ™¯å™ªå£°æ‰€å¸¦æ¥çš„æŒ‘æˆ˜ã€‚ä¸ºè§£å†³è¿™äº›é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åŸºäºå£°å­¦-è¯­è°ƒåˆ†ç¦»çš„ä¸¤é˜¶æ®µæ–¹æ³•æ¥å®ç°é«˜è´¨é‡çš„é…éŸ³ç”Ÿæˆå’Œç²¾ç¡®çš„è¯­è°ƒå¯¹é½ã€‚é¦–å…ˆé€šè¿‡æå‡ºä¸€ç§å¢å¼ºè¯­è°ƒçš„å£°å­¦é¢„è®­ç»ƒæ–¹æ³•ï¼Œå¢å¼ºå£°å­¦å»ºæ¨¡èƒ½åŠ›ã€‚ç„¶åå†»ç»“é¢„è®­ç»ƒçš„å£°å­¦ç³»ç»Ÿï¼Œè®¾è®¡ä¸€ä¸ªåˆ†ç¦»çš„æ¡†æ¶æ¥æ¨¡æ‹Ÿè¯­éŸ³æ–‡æœ¬ç‰¹å¾å’Œé…éŸ³é£æ ¼ï¼ŒåŒæ—¶ä¿æŒå£°å­¦è´¨é‡ã€‚æ­¤å¤–ï¼Œè¿˜å¼•å…¥äº†ä¸€ä¸ªé¢†åŸŸçš„æƒ…æ„Ÿåˆ†ææ¨¡å—ï¼Œä»¥å‡å°‘ä¸åŒç”µå½±ä¹‹é—´è§†è§‰åŸŸå˜åŒ–çš„å†²å‡»ï¼Œä»è€Œæé«˜æƒ…æ„Ÿè¯­è°ƒçš„å¯¹é½æ•ˆæœã€‚å®éªŒè¯æ˜ï¼Œè¯¥æ–¹æ³•åœ¨ä¸¤ä¸ªä¸»è¦åŸºå‡†æµ‹è¯•ä¸Šçš„è¡¨ç°ä¼˜äºç°æœ‰æ¨¡å‹ã€‚ç›¸å…³æ¼”ç¤ºå¯é€šè¿‡<a target="_blank" rel="noopener" href="https://zzdoog.github.io/ProDubber/">é“¾æ¥</a>æŸ¥çœ‹ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ç”µå½±é…éŸ³æ˜¯æš‚æ—¶å’Œæƒ…æ„Ÿä¸Šä¸ç»™å®šç”µå½±ç‰‡æ®µç›¸ç¬¦çš„è¯­éŸ³è½¬æ¢è¿‡ç¨‹ï¼Œéœ€è¦æ¨¡å‹æ¡¥æ¥è§’è‰²è¡¨æ¼”å’Œå¤æ‚çš„è¯­è°ƒç»“æ„æ¥æ„å»ºé«˜è´¨é‡çš„è§†é¢‘åŒæ­¥é…éŸ³è½¨é“ã€‚</li>
<li>å½“å‰é¢ä¸´çš„ä¸»è¦æŒ‘æˆ˜æ˜¯ç”µå½±é…éŸ³æ•°æ®é›†è§„æ¨¡çš„é™åˆ¶ä»¥åŠéŸ³é¢‘æ•°æ®ä¸­çš„èƒŒæ™¯å™ªå£°é—®é¢˜ã€‚</li>
<li>æå‡ºäº†ä¸€ç§åŸºäºå£°å­¦-è¯­è°ƒåˆ†ç¦»çš„ä¸¤é˜¶æ®µæ–¹æ³•æ¥å®ç°é«˜è´¨é‡çš„é…éŸ³ç”Ÿæˆå’Œç²¾ç¡®çš„è¯­è°ƒå¯¹é½ã€‚</li>
<li>é€šè¿‡å£°å­¦é¢„è®­ç»ƒæå‡å£°å­¦å»ºæ¨¡èƒ½åŠ›ï¼Œé€šè¿‡å†»ç»“é¢„è®­ç»ƒå£°å­¦ç³»ç»Ÿå¹¶å»ºç«‹åˆ†ç¦»æ¡†æ¶å¤„ç†æ–‡æœ¬ç‰¹å¾å’Œé…éŸ³é£æ ¼ã€‚</li>
<li>å¼•å…¥äº†é¢†åŸŸçš„æƒ…æ„Ÿåˆ†ææ¨¡å—ï¼Œå‡å°‘ä¸åŒç”µå½±é—´è§†è§‰åŸŸå˜åŒ–å¯¹æƒ…æ„Ÿè¯­è°ƒå¯¹é½çš„å½±å“ã€‚</li>
<li>å®éªŒè¯æ˜è¯¥æ–¹æ³•åœ¨ä¸»è¦åŸºå‡†æµ‹è¯•ä¸Šçš„è¡¨ç°ä¼˜äºç°æœ‰æ¨¡å‹ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.12042">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-f668efb3ad1254019a82b00bfcbdd188.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-53311922658be8ead1ffbba037090584.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-f3614debffb60ad043d0ef7e07834a70.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="RASA-Replace-Anyone-Say-Anything-â€“-A-Training-Free-Framework-for-Audio-Driven-and-Universal-Portrait-Video-Editing"><a href="#RASA-Replace-Anyone-Say-Anything-â€“-A-Training-Free-Framework-for-Audio-Driven-and-Universal-Portrait-Video-Editing" class="headerlink" title="RASA: Replace Anyone, Say Anything â€“ A Training-Free Framework for   Audio-Driven and Universal Portrait Video Editing"></a>RASA: Replace Anyone, Say Anything â€“ A Training-Free Framework for   Audio-Driven and Universal Portrait Video Editing</h2><p><strong>Authors:Tianrui Pan, Lin Liu, Jie Liu, Xiaopeng Zhang, Jie Tang, Gangshan Wu, Qi Tian</strong></p>
<p>Portrait video editing focuses on modifying specific attributes of portrait videos, guided by audio or video streams. Previous methods typically either concentrate on lip-region reenactment or require training specialized models to extract keypoints for motion transfer to a new identity. In this paper, we introduce a training-free universal portrait video editing framework that provides a versatile and adaptable editing strategy. This framework supports portrait appearance editing conditioned on the changed first reference frame, as well as lip editing conditioned on varied speech, or a combination of both. It is based on a Unified Animation Control (UAC) mechanism with source inversion latents to edit the entire portrait, including visual-driven shape control, audio-driven speaking control, and inter-frame temporal control. Furthermore, our method can be adapted to different scenarios by adjusting the initial reference frame, enabling detailed editing of portrait videos with specific head rotations and facial expressions. This comprehensive approach ensures a holistic and flexible solution for portrait video editing. The experimental results show that our model can achieve more accurate and synchronized lip movements for the lip editing task, as well as more flexible motion transfer for the appearance editing task. Demo is available at <a target="_blank" rel="noopener" href="https://alice01010101.github.io/RASA/">https://alice01010101.github.io/RASA/</a>. </p>
<blockquote>
<p>è‚–åƒè§†é¢‘ç¼–è¾‘ä¸»è¦å…³æ³¨æ ¹æ®éŸ³é¢‘æˆ–è§†é¢‘æµä¿®æ”¹è‚–åƒè§†é¢‘çš„å…·ä½“å±æ€§ã€‚ä¹‹å‰çš„æ–¹æ³•é€šå¸¸é›†ä¸­åœ¨å”‡éƒ¨åŒºåŸŸçš„å†ç°ï¼Œæˆ–è€…éœ€è¦è®­ç»ƒä¸“é—¨æ¨¡å‹ä»¥æå–å…³é”®ç‚¹ï¼Œç”¨äºå°†åŠ¨ä½œè½¬ç§»åˆ°æ–°èº«ä»½ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬ä»‹ç»äº†ä¸€ä¸ªæ— è®­ç»ƒé€šç”¨çš„è‚–åƒè§†é¢‘ç¼–è¾‘æ¡†æ¶ï¼Œè¯¥æ¡†æ¶æä¾›äº†ä¸€ç§é€šç”¨å’Œå¯é€‚åº”çš„ç¼–è¾‘ç­–ç•¥ã€‚æ­¤æ¡†æ¶æ”¯æŒæ ¹æ®æ›´æ”¹çš„ç¬¬ä¸€å¸§è¿›è¡Œè‚–åƒå¤–è§‚ç¼–è¾‘ï¼Œä»¥åŠæ ¹æ®å„ç§è¯­éŸ³è¿›è¡Œå”‡éƒ¨ç¼–è¾‘ï¼Œæˆ–ä¸¤è€…çš„ç»„åˆã€‚å®ƒåŸºäºç»Ÿä¸€åŠ¨ç”»æ§åˆ¶ï¼ˆUACï¼‰æœºåˆ¶ï¼Œä½¿ç”¨æºåè½¬æ½œåœ¨å˜é‡æ¥ç¼–è¾‘æ•´ä¸ªè‚–åƒï¼ŒåŒ…æ‹¬è§†è§‰é©±åŠ¨çš„å½¢çŠ¶æ§åˆ¶ã€éŸ³é¢‘é©±åŠ¨çš„è¯´è¯æ§åˆ¶ä»¥åŠå¸§é—´æ—¶é—´æ§åˆ¶ã€‚æ­¤å¤–ï¼Œé€šè¿‡è°ƒæ•´åˆå§‹å‚è€ƒå¸§ï¼Œæˆ‘ä»¬çš„æ–¹æ³•èƒ½å¤Ÿé€‚åº”ä¸åŒåœºæ™¯ï¼Œå®ç°å¯¹å…·æœ‰ç‰¹å®šå¤´éƒ¨æ—‹è½¬å’Œé¢éƒ¨è¡¨æƒ…çš„è‚–åƒè§†é¢‘çš„è¯¦ç»†ç¼–è¾‘ã€‚è¿™ç§ç»¼åˆæ–¹æ³•ç¡®ä¿äº†è‚–åƒè§†é¢‘ç¼–è¾‘çš„å…¨é¢å’Œçµæ´»è§£å†³æ–¹æ¡ˆã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ¨¡å‹åœ¨å”‡éƒ¨ç¼–è¾‘ä»»åŠ¡ä¸Šå¯ä»¥å®ç°æ›´å‡†ç¡®ã€æ›´åŒæ­¥çš„å”‡éƒ¨è¿åŠ¨ï¼Œä»¥åŠåœ¨å¤–è§‚ç¼–è¾‘ä»»åŠ¡ä¸Šå®ç°æ›´çµæ´»çš„åŠ¨æ€è½¬ç§»ã€‚æ¼”ç¤ºè¯·è®¿é—®ï¼š<a target="_blank" rel="noopener" href="https://alice01010101.github.io/RASA/%E3%80%82">https://alice01010101.github.io/RASA/ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.11571v1">PDF</a> Demo is available at <a target="_blank" rel="noopener" href="https://alice01010101.github.io/RASA/">https://alice01010101.github.io/RASA/</a></p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†ä¸€ç§æ— éœ€è®­ç»ƒå³å¯åº”ç”¨çš„é€šç”¨è‚–åƒè§†é¢‘ç¼–è¾‘æ¡†æ¶ï¼Œè¯¥æ¡†æ¶æ”¯æŒåŸºäºæ›´æ”¹çš„ç¬¬ä¸€å¸§çš„è‚–åƒå¤–è§‚ç¼–è¾‘å’ŒåŸºäºä¸åŒè¯­éŸ³çš„å”‡éƒ¨ç¼–è¾‘ï¼Œæˆ–ä¸¤è€…çš„ç»„åˆã€‚å®ƒåŸºäºç»Ÿä¸€åŠ¨ç”»æ§åˆ¶ï¼ˆUACï¼‰æœºåˆ¶ï¼Œé€šè¿‡æºåè½¬æ½œç æ¥ç¼–è¾‘æ•´ä¸ªè‚–åƒï¼ŒåŒ…æ‹¬è§†è§‰é©±åŠ¨çš„å½¢çŠ¶æ§åˆ¶ã€éŸ³é¢‘é©±åŠ¨çš„è¯´è¯æ§åˆ¶å’Œå¸§é—´æ—¶é—´æ§åˆ¶ã€‚æ­¤å¤–ï¼Œé€šè¿‡è°ƒæ•´åˆå§‹å¸§ï¼Œè¯¥æ–¹æ³•å¯é€‚åº”ä¸åŒçš„åœºæ™¯ï¼Œå®ç°å¯¹è‚–åƒè§†é¢‘ç‰¹å®šå¤´éƒ¨æ—‹è½¬å’Œé¢éƒ¨è¡¨æƒ…çš„è¯¦ç»†ç¼–è¾‘ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ä»‹ç»äº†ä¸€ç§æ–°å‹çš„è‚–åƒè§†é¢‘ç¼–è¾‘æ¡†æ¶ï¼Œè¯¥æ¡†æ¶æ— éœ€è®­ç»ƒå³å¯åº”ç”¨ï¼Œå…·æœ‰å¹¿æ³›é€‚åº”æ€§å’Œçµæ´»æ€§ã€‚</li>
<li>æ¡†æ¶æ”¯æŒåŸºäºæ›´æ”¹çš„ç¬¬ä¸€å¸§çš„è‚–åƒå¤–è§‚ç¼–è¾‘å’ŒåŸºäºä¸åŒè¯­éŸ³çš„å”‡éƒ¨ç¼–è¾‘ï¼Œæˆ–ä¸¤è€…çš„ç»„åˆã€‚</li>
<li>è¯¥æ¡†æ¶åŸºäºç»Ÿä¸€åŠ¨ç”»æ§åˆ¶ï¼ˆUACï¼‰æœºåˆ¶ï¼Œè¯¥æœºåˆ¶é€šè¿‡æºåè½¬æ½œç ç¼–è¾‘æ•´ä¸ªè‚–åƒã€‚</li>
<li>å®ç°äº†è§†è§‰é©±åŠ¨çš„å½¢çŠ¶æ§åˆ¶ã€éŸ³é¢‘é©±åŠ¨çš„è¯´è¯æ§åˆ¶å’Œå¸§é—´æ—¶é—´æ§åˆ¶ã€‚</li>
<li>é€šè¿‡è°ƒæ•´åˆå§‹å¸§ï¼Œè¯¥æ¡†æ¶å¯é€‚åº”ä¸åŒçš„ç¼–è¾‘åœºæ™¯ï¼Œå®ç°è¯¦ç»†ç¼–è¾‘ã€‚</li>
<li>å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ¡†æ¶åœ¨å”‡ç¼–è¾‘ä»»åŠ¡ä¸Šèƒ½å®ç°æ›´å‡†ç¡®ã€æ›´åŒæ­¥çš„å”‡éƒ¨è¿åŠ¨ï¼Œåœ¨å¤–è§‚ç¼–è¾‘ä»»åŠ¡ä¸Šèƒ½å®ç°æ›´çµæ´»çš„åŠ¨æ€è½¬ç§»ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.11571">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-494b5351c6dca9bcb5633a94bb18f63d.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-19ed25f2fa2b012b588b574e4b650201.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-689210928e643e3f8fe57b994cfeaf22.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-33ea69f8f4131a693b15aedf596686ba.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="EmoDiffusion-Enhancing-Emotional-3D-Facial-Animation-with-Latent-Diffusion-Models"><a href="#EmoDiffusion-Enhancing-Emotional-3D-Facial-Animation-with-Latent-Diffusion-Models" class="headerlink" title="EmoDiffusion: Enhancing Emotional 3D Facial Animation with Latent   Diffusion Models"></a>EmoDiffusion: Enhancing Emotional 3D Facial Animation with Latent   Diffusion Models</h2><p><strong>Authors:Yixuan Zhang, Qing Chang, Yuxi Wang, Guang Chen, Zhaoxiang Zhang, Junran Peng</strong></p>
<p>Speech-driven 3D facial animation seeks to produce lifelike facial expressions that are synchronized with the speech content and its emotional nuances, finding applications in various multimedia fields. However, previous methods often overlook emotional facial expressions or fail to disentangle them effectively from the speech content. To address these challenges, we present EmoDiffusion, a novel approach that disentangles different emotions in speech to generate rich 3D emotional facial expressions. Specifically, our method employs two Variational Autoencoders (VAEs) to separately generate the upper face region and mouth region, thereby learning a more refined representation of the facial sequence. Unlike traditional methods that use diffusion models to connect facial expression sequences with audio inputs, we perform the diffusion process in the latent space. Furthermore, we introduce an Emotion Adapter to evaluate upper face movements accurately. Given the paucity of 3D emotional talking face data in the animation industry, we capture facial expressions under the guidance of animation experts using LiveLinkFace on an iPhone. This effort results in the creation of an innovative 3D blendshape emotional talking face dataset (3D-BEF) used to train our network. Extensive experiments and perceptual evaluations validate the effectiveness of our approach, confirming its superiority in generating realistic and emotionally rich facial animations. </p>
<blockquote>
<p>è¯­éŸ³é©±åŠ¨çš„ä¸‰ç»´é¢éƒ¨åŠ¨ç”»æ—¨åœ¨äº§ç”Ÿä¸è¯­éŸ³å†…å®¹åŠå…¶æƒ…æ„Ÿç»†å¾®å·®åˆ«åŒæ­¥çš„é€¼çœŸé¢éƒ¨è¡¨æƒ…ï¼Œå¹¶å¹¿æ³›åº”ç”¨äºå„ç§å¤šåª’ä½“é¢†åŸŸã€‚ç„¶è€Œï¼Œä¹‹å‰çš„æ–¹æ³•å¸¸å¸¸å¿½è§†æƒ…æ„Ÿé¢éƒ¨è¡¨æƒ…ï¼Œæˆ–è€…æ— æ³•æœ‰æ•ˆåœ°ä»è¯­éŸ³å†…å®¹ä¸­å°†å…¶åˆ†è¾¨å‡ºæ¥ã€‚ä¸ºäº†åº”å¯¹è¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†EmoDiffusionè¿™ä¸€æ–°æ–¹æ³•ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿåˆ†è¾¨è¯­éŸ³ä¸­çš„ä¸åŒæƒ…æ„Ÿï¼Œç”Ÿæˆä¸°å¯Œçš„ä¸‰ç»´æƒ…æ„Ÿé¢éƒ¨è¡¨æƒ…ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬çš„æ–¹æ³•é‡‡ç”¨ä¸¤ä¸ªå˜åˆ†è‡ªç¼–ç å™¨ï¼ˆVAEsï¼‰åˆ†åˆ«ç”Ÿæˆä¸ŠåŠè„¸åŒºåŸŸå’Œå˜´å·´åŒºåŸŸï¼Œä»è€Œå­¦ä¹ æ›´ç²¾ç»†çš„é¢éƒ¨åºåˆ—è¡¨ç¤ºã€‚ä¸åŒäºä¼ ç»Ÿæ–¹æ³•ä½¿ç”¨æ‰©æ•£æ¨¡å‹å°†é¢éƒ¨è¡¨æƒ…åºåˆ—ä¸éŸ³é¢‘è¾“å…¥ç›¸è¿ï¼Œæˆ‘ä»¬åœ¨æ½œåœ¨ç©ºé—´æ‰§è¡Œæ‰©æ•£è¿‡ç¨‹ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å¼•å…¥æƒ…æ„Ÿé€‚é…å™¨æ¥å‡†ç¡®è¯„ä¼°ä¸ŠåŠè„¸çš„è¿åŠ¨ã€‚é‰´äºåŠ¨ç”»è¡Œä¸šç¼ºä¹ä¸‰ç»´æƒ…æ„Ÿå¯¹è¯é¢éƒ¨æ•°æ®ï¼Œæˆ‘ä»¬åœ¨åŠ¨ç”»ä¸“å®¶çš„æŒ‡å¯¼ä¸‹ä½¿ç”¨iPhoneä¸Šçš„LiveLinkFaceå·¥å…·æ•æ‰é¢éƒ¨è¡¨æƒ…ï¼Œä»è€Œåˆ›å»ºäº†åˆ›æ–°çš„ä¸‰ç»´æƒ…æ„Ÿæ··åˆå¯¹è¯é¢éƒ¨æ•°æ®é›†ï¼ˆ3D-BEFï¼‰ï¼Œç”¨äºè®­ç»ƒæˆ‘ä»¬çš„ç½‘ç»œã€‚å¤§é‡å®éªŒå’Œæ„ŸçŸ¥è¯„ä¼°éªŒè¯äº†æˆ‘ä»¬çš„æ–¹æ³•çš„æœ‰æ•ˆæ€§ï¼Œè¯å®å…¶åœ¨ç”ŸæˆçœŸå®ä¸”æƒ…æ„Ÿä¸°å¯Œçš„é¢éƒ¨åŠ¨ç”»æ–¹é¢çš„ä¼˜è¶Šæ€§ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.11028v1">PDF</a> </p>
<p><strong>Summary</strong>ï¼š</p>
<p>æœ¬æ–‡ä»‹ç»äº†ä¸€ç§åä¸ºEmoDiffusionçš„æ–°æ–¹æ³•ï¼Œè¯¥æ–¹æ³•æ—¨åœ¨è§£å†³è¯­éŸ³é©±åŠ¨çš„3Dé¢éƒ¨åŠ¨ç”»ä¸­çš„æƒ…æ„Ÿè¡¨è¾¾é—®é¢˜ã€‚é€šè¿‡é‡‡ç”¨ä¸¤ä¸ªå˜åˆ†è‡ªç¼–ç å™¨ï¼ˆVAEsï¼‰åˆ†åˆ«ç”Ÿæˆé¢éƒ¨ä¸ŠåŠéƒ¨åˆ†å’Œå˜´å·´åŒºåŸŸï¼Œå¹¶åœ¨æ½œåœ¨ç©ºé—´ä¸­è¿›è¡Œæ‰©æ•£è¿‡ç¨‹ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿç²¾ç»†åœ°è¡¨ç¤ºé¢éƒ¨åºåˆ—ã€‚æ­¤å¤–ï¼Œè¿˜å¼•å…¥äº†ä¸€ä¸ªæƒ…æ„Ÿé€‚é…å™¨æ¥å‡†ç¡®è¯„ä¼°é¢éƒ¨ä¸ŠåŠéƒ¨åˆ†è¿åŠ¨ã€‚ä¸ºè§£å†³åŠ¨ç”»è¡Œä¸šä¸­ç¼ºä¹3Dæƒ…æ„Ÿå¯¹è¯é¢éƒ¨æ•°æ®çš„é—®é¢˜ï¼Œè¯¥ç ”ç©¶è¿˜ä½¿ç”¨iPhoneä¸Šçš„LiveLinkFaceå·¥å…·åœ¨åŠ¨ç”»ä¸“å®¶æŒ‡å¯¼ä¸‹æ•è·é¢éƒ¨è¡¨æƒ…ï¼Œåˆ›å»ºäº†ä¸€ä¸ªåˆ›æ–°çš„3Dæƒ…æ„Ÿè°ˆè¯é¢éƒ¨æ•°æ®é›†ï¼ˆ3D-BEFï¼‰ï¼Œç”¨äºè®­ç»ƒç½‘ç»œã€‚å®éªŒå’Œæ„ŸçŸ¥è¯„ä¼°éªŒè¯äº†è¯¥æ–¹æ³•çš„çœŸå®æ€§å’Œæƒ…æ„Ÿä¸°å¯Œæ€§ã€‚</p>
<p><strong>Key Takeaways</strong>ï¼š</p>
<ol>
<li>EmoDiffusionæ–¹æ³•èƒ½å¤Ÿè§£å†³è¯­éŸ³é©±åŠ¨çš„3Dé¢éƒ¨åŠ¨ç”»ä¸­æƒ…æ„Ÿè¡¨è¾¾çš„é—®é¢˜ã€‚</li>
<li>é€šè¿‡å˜åˆ†è‡ªç¼–ç å™¨ï¼ˆVAEsï¼‰åˆ†åˆ«ç”Ÿæˆé¢éƒ¨ä¸ŠåŠéƒ¨åˆ†å’Œå˜´å·´åŒºåŸŸï¼Œæé«˜é¢éƒ¨åŠ¨ç”»çš„ç²¾ç»†åº¦ã€‚</li>
<li>åœ¨æ½œåœ¨ç©ºé—´ä¸­è¿›è¡Œæ‰©æ•£è¿‡ç¨‹ï¼Œå®ç°é¢éƒ¨è¡¨æƒ…ä¸è¯­éŸ³å†…å®¹çš„æ›´ç´§å¯†å…³è”ã€‚</li>
<li>å¼•å…¥æƒ…æ„Ÿé€‚é…å™¨å‡†ç¡®è¯„ä¼°é¢éƒ¨ä¸ŠåŠéƒ¨åˆ†è¿åŠ¨ã€‚</li>
<li>åˆ›å»ºäº†ä¸€ä¸ªåˆ›æ–°çš„3Dæƒ…æ„Ÿè°ˆè¯é¢éƒ¨æ•°æ®é›†ï¼ˆ3D-BEFï¼‰ï¼Œç”¨äºè®­ç»ƒç½‘ç»œã€‚</li>
<li>è¯¥æ–¹æ³•é€šè¿‡å¹¿æ³›å®éªŒéªŒè¯å…¶æœ‰æ•ˆæ€§ï¼Œå¹¶è¡¨ç°å‡ºç”ŸæˆçœŸå®å’Œæƒ…æ„Ÿä¸°å¯Œé¢éƒ¨åŠ¨ç”»çš„èƒ½åŠ›ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.11028">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-58e853a905eceb5428ab9a863737421b.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-3f254f40f8a1ce87ba5cea036d281732.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="Versatile-Multimodal-Controls-for-Whole-Body-Talking-Human-Animation"><a href="#Versatile-Multimodal-Controls-for-Whole-Body-Talking-Human-Animation" class="headerlink" title="Versatile Multimodal Controls for Whole-Body Talking Human Animation"></a>Versatile Multimodal Controls for Whole-Body Talking Human Animation</h2><p><strong>Authors:Zheng Qin, Ruobing Zheng, Yabing Wang, Tianqi Li, Zixin Zhu, Minghui Yang, Ming Yang, Le Wang</strong></p>
<p>Human animation from a single reference image shall be flexible to synthesize whole-body motion for either a headshot or whole-body portrait, where the motions are readily controlled by audio signal and text prompts. This is hard for most existing methods as they only support producing pre-specified head or half-body motion aligned with audio inputs. In this paper, we propose a versatile human animation method, i.e., VersaAnimator, which generates whole-body talking human from arbitrary portrait images, not only driven by audio signal but also flexibly controlled by text prompts. Specifically, we design a text-controlled, audio-driven motion generator that produces whole-body motion representations in 3D synchronized with audio inputs while following textual motion descriptions. To promote natural smooth motion, we propose a code-pose translation module to link VAE codebooks with 2D DWposes extracted from template videos. Moreover, we introduce a multi-modal video diffusion that generates photorealistic human animation from a reference image according to both audio inputs and whole-body motion representations. Extensive experiments show that VersaAnimator outperforms existing methods in visual quality, identity preservation, and audio-lip synchronization. </p>
<blockquote>
<p>ä»å•ä¸€å‚è€ƒå›¾åƒç”Ÿæˆçš„äººè„¸åŠ¨ç”»åº”è¯¥èƒ½å¤Ÿçµæ´»åœ°åˆæˆå¤´éƒ¨ç‰¹å†™æˆ–å…¨èº«è‚–åƒçš„å…¨èº«è¿åŠ¨ï¼Œè¿™äº›è¿åŠ¨å¯ä»¥é€šè¿‡éŸ³é¢‘ä¿¡å·å’Œæ–‡å­—æç¤ºè½»æ¾æ§åˆ¶ã€‚å¯¹äºå¤§å¤šæ•°ç°æœ‰æ–¹æ³•è€Œè¨€ï¼Œè¿™å¾ˆéš¾å®ç°ï¼Œå› ä¸ºå®ƒä»¬ä»…æ”¯æŒç”Ÿæˆä¸éŸ³é¢‘è¾“å…¥å¯¹é½çš„é¢„è®¾å¤´éƒ¨æˆ–åŠèº«è¿åŠ¨ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§é€šç”¨çš„äººè„¸åŠ¨ç”»æ–¹æ³•ï¼Œå³VersaAnimatorï¼Œå®ƒå¯ä»¥ä»ä»»æ„çš„è‚–åƒå›¾åƒç”Ÿæˆå…¨èº«è¯´è¯çš„äººè„¸åŠ¨ç”»ï¼Œä¸ä»…ç”±éŸ³é¢‘ä¿¡å·é©±åŠ¨ï¼Œè¿˜é€šè¿‡æ–‡å­—æç¤ºè¿›è¡Œçµæ´»æ§åˆ¶ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬è®¾è®¡äº†ä¸€ä¸ªæ–‡æœ¬æ§åˆ¶ã€éŸ³é¢‘é©±åŠ¨çš„è¿åŠ¨ç”Ÿæˆå™¨ï¼Œå®ƒäº§ç”Ÿä¸éŸ³é¢‘è¾“å…¥åŒæ­¥çš„å…¨èº«è¿åŠ¨è¡¨ç¤ºï¼ˆåœ¨3Dä¸­ï¼‰ï¼ŒåŒæ—¶éµå¾ªæ–‡æœ¬è¿åŠ¨æè¿°ã€‚ä¸ºäº†ä¿ƒè¿›è‡ªç„¶æµç•…çš„è¿åŠ¨ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªç¼–ç å§¿åŠ¿è½¬æ¢æ¨¡å—ï¼Œå°†VAEä»£ç æœ¬ä¸ä»æ¨¡æ¿è§†é¢‘ä¸­æå–çš„2DDWå§¿åŠ¿ç›¸å…³è”ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§å¤šæ¨¡å¼è§†é¢‘æ‰©æ•£æ–¹æ³•ï¼Œæ ¹æ®å‚è€ƒå›¾åƒã€éŸ³é¢‘è¾“å…¥å’Œå…¨èº«è¿åŠ¨è¡¨ç¤ºç”Ÿæˆå†™å®é£æ ¼çš„äººè„¸åŠ¨ç”»ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼ŒVersaAnimatoråœ¨è§†è§‰è´¨é‡ã€èº«ä»½ä¿ç•™å’ŒéŸ³é¢‘å”‡å½¢åŒæ­¥æ–¹é¢ä¼˜äºç°æœ‰æ–¹æ³•ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.08714v2">PDF</a> </p>
<p><strong>Summary</strong><br>åŠ¨ç”»æŠ€æœ¯å¯ä»¥ä»å•ä¸€å‚è€ƒå›¾åƒç”Ÿæˆå…¨èº«åŠ¨æ€äººåƒï¼Œè¯¥æŠ€æœ¯çµæ´»æ€§å¼ºï¼Œå¯ä»¥æ ¹æ®éŸ³é¢‘ä¿¡å·å’Œæ–‡æœ¬æç¤ºè¿›è¡Œæ“æ§ã€‚ä»¥å¾€æ–¹æ³•å¤§å¤šåªæ”¯æŒé¢„è®¾å®šçš„å¤´éƒ¨æˆ–åŠèº«è¿åŠ¨ä¸éŸ³é¢‘å¯¹é½ï¼Œè€Œæ­¤æ–¹æ³•ä¸ä»…èƒ½ä»ä»»æ„è‚–åƒå›¾åƒç”Ÿæˆå…¨èº«åŠ¨æ€äººåƒï¼Œæ›´èƒ½é€šè¿‡æ–‡æœ¬æè¿°çµæ´»æ§åˆ¶ï¼ŒéŸ³é¢‘é©±åŠ¨äº§ç”Ÿä¸éŸ³é¢‘è¾“å…¥åŒæ­¥çš„å…¨èº«è¿åŠ¨è¡¨ç°ã€‚æ­¤æ–¹æ³•è®¾è®¡äº†ä¸€ä¸ªæ–‡æœ¬æ§åˆ¶çš„è¿åŠ¨ç”Ÿæˆå™¨ï¼Œé€šè¿‡ä»£ç å§¿åŠ¿ç¿»è¯‘æ¨¡å—è¿æ¥VAEç¼–ç æœ¬ä¸ä»æ¨¡æ¿è§†é¢‘æå–çš„2DDWå§¿åŠ¿ï¼Œä¿ƒè¿›è‡ªç„¶æµç•…çš„è¿åŠ¨ã€‚åŒæ—¶å¼•å…¥å¤šæ¨¡æ€è§†é¢‘æ‰©æ•£æŠ€æœ¯ï¼Œæ ¹æ®å‚è€ƒå›¾åƒã€éŸ³é¢‘è¾“å…¥å’Œå…¨èº«è¿åŠ¨è¡¨ç°ç”Ÿæˆé€¼çœŸçš„åŠ¨ç”»æ•ˆæœã€‚å®éªŒç»“æœè¯æ˜æ­¤æ–¹æ³•åœ¨è§†è§‰è´¨é‡ã€èº«ä»½ä¿ç•™å’ŒéŸ³é¢‘åŒæ­¥æ–¹é¢è¡¨ç°ä¼˜äºç°æœ‰æ–¹æ³•ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>äººåƒåŠ¨ç”»æŠ€æœ¯èƒ½ä»å•ä¸€å‚è€ƒå›¾åƒç”Ÿæˆå…¨èº«åŠ¨æ€äººåƒã€‚</li>
<li>æŠ€æœ¯ç»“åˆéŸ³é¢‘ä¿¡å·å’Œæ–‡æœ¬æç¤ºè¿›è¡Œæ“æ§ï¼Œå…·æœ‰çµæ´»æ€§ã€‚</li>
<li>æå‡ºä¸€ç§æ–‡æœ¬æ§åˆ¶çš„è¿åŠ¨ç”Ÿæˆå™¨ï¼Œèƒ½åŒæ­¥ç”Ÿæˆå…¨èº«è¿åŠ¨è¡¨ç°ã€‚</li>
<li>é€šè¿‡ä»£ç å§¿åŠ¿ç¿»è¯‘æ¨¡å—å’Œå¤šæ¨¡æ€è§†é¢‘æ‰©æ•£æŠ€æœ¯ä¿ƒè¿›è‡ªç„¶æµç•…çš„è¿åŠ¨å¹¶æå‡åŠ¨ç”»æ•ˆæœã€‚</li>
<li>è¯¥æ–¹æ³•åœ¨è§†è§‰è´¨é‡ã€èº«ä»½ä¿ç•™å’ŒéŸ³é¢‘åŒæ­¥æ–¹é¢è¡¨ç°ä¼˜è¶Šã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.08714">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-a4be268b951eb464599915f093168534.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-2b16248ac9cc86d5b6803d40037667cc.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b111d2208a9e49f013d5550bffdaa200.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-28fcbcf16b6a3381317a45ec3ee5082f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-6dfa8bd672ff361a77bf3c1459b8296e.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-03-20/Talking%20Head%20Generation/">https://kedreamix.github.io/Talk2Paper/Paper/2025-03-20/Talking%20Head%20Generation/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/Talking-Head-Generation/">
                                    <span class="chip bg-color">Talking Head Generation</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-03-20/Text-to-Motion/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-82b742bc479adb9e7b33d83aad6fef07.jpg" class="responsive-img" alt="Text-to-Motion">
                        
                        <span class="card-title">Text-to-Motion</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Text-to-Motion æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-03-20  Less is More Improving Motion Diffusion Models with Sparse Keyframes
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-03-20
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Text-to-Motion/" class="post-category">
                                    Text-to-Motion
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Text-to-Motion/">
                        <span class="chip bg-color">Text-to-Motion</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-03-20/Interactive/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-10a3540cf65985bc59d402abe493a471.jpg" class="responsive-img" alt="Interactive">
                        
                        <span class="card-title">Interactive</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Interactive æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-03-20  MusicInfuser Making Video Diffusion Listen and Dance
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-03-20
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Interactive/" class="post-category">
                                    Interactive
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Interactive/">
                        <span class="chip bg-color">Interactive</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">18863.8k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
