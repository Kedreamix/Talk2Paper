<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Agent">
    <meta name="description" content="Agent 方向最新论文已更新，请持续关注 Update in 2025-03-20  DARS Dynamic Action Re-Sampling to Enhance Coding Agent Performance by   Adaptive Tree Traversal">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>Agent | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loader页面消失采用渐隐的方式*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logo出现动画 */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//使用渐隐的方法淡出loading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//强制显示loading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">嘘~  正在从服务器偷取页面 . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>首页</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>标签</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>分类</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>归档</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="搜索" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="深色/浅色模式" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			首页
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			标签
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			分类
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			归档
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://pic1.zhimg.com/v2-1bfcf16d2f1dcb31142c9a8c39dd0b14.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Agent</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/Agent/">
                                <span class="chip bg-color">Agent</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/Agent/" class="post-category">
                                Agent
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2025-03-20
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>更新日期:&nbsp;&nbsp;
                    2025-05-14
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp;
                    8.4k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp;
                    34 分
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>阅读次数:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>⚠️ 以下所有内容总结都来自于 大语言模型的能力，如有错误，仅供参考，谨慎使用<br>🔴 请注意：千万不要用于严肃的学术场景，只能用于论文阅读前的初筛！<br>💗 如果您觉得我们的项目对您有帮助 <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ，还请您给我们一些鼓励！⭐️ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFace免费体验</a></p>
</blockquote>
<h1 id="2025-03-20-更新"><a href="#2025-03-20-更新" class="headerlink" title="2025-03-20 更新"></a>2025-03-20 更新</h1><h2 id="DARS-Dynamic-Action-Re-Sampling-to-Enhance-Coding-Agent-Performance-by-Adaptive-Tree-Traversal"><a href="#DARS-Dynamic-Action-Re-Sampling-to-Enhance-Coding-Agent-Performance-by-Adaptive-Tree-Traversal" class="headerlink" title="DARS: Dynamic Action Re-Sampling to Enhance Coding Agent Performance by   Adaptive Tree Traversal"></a>DARS: Dynamic Action Re-Sampling to Enhance Coding Agent Performance by   Adaptive Tree Traversal</h2><p><strong>Authors:Vaibhav Aggarwal, Ojasv Kamal, Abhinav Japesh, Zhijing Jin, Bernhard Schölkopf</strong></p>
<p>Large Language Models (LLMs) have revolutionized various domains, including natural language processing, data analysis, and software development, by enabling automation. In software engineering, LLM-powered coding agents have garnered significant attention due to their potential to automate complex development tasks, assist in debugging, and enhance productivity. However, existing approaches often struggle with sub-optimal decision-making, requiring either extensive manual intervention or inefficient compute scaling strategies. To improve coding agent performance, we present Dynamic Action Re-Sampling (DARS), a novel inference time compute scaling approach for coding agents, that is faster and more effective at recovering from sub-optimal decisions compared to baselines. While traditional agents either follow linear trajectories or rely on random sampling for scaling compute, our approach DARS works by branching out a trajectory at certain key decision points by taking an alternative action given the history of the trajectory and execution feedback of the previous attempt from that point. We evaluate our approach on SWE-Bench Lite benchmark, demonstrating that this scaling strategy achieves a pass@k score of 55% with Claude 3.5 Sonnet V2. Our framework achieves a pass@1 rate of 47%, outperforming state-of-the-art (SOTA) open-source frameworks. </p>
<blockquote>
<p>大型语言模型（LLM）已经通过实现自动化，在多个领域（包括自然语言处理、数据分析和软件开发等）引发了革命。在软件工程领域，由LLM驱动的编码代理因具备自动化复杂开发任务、辅助调试和提高生产效率的潜力而备受关注。然而，现有方法常常面临决策不理想的困境，需要大量的人工干预或低效的计算扩展策略。为了提升编码代理的性能，我们提出了动态行为重采样（DARS），这是一种针对编码代理的新型推理时间计算扩展方法。与传统的代理相比，DARS在面临次优决策时，能够更快、更有效地恢复。传统的方法通常采用线性轨迹或随机采样进行计算扩展，而我们的DARS方法通过在关键决策点分支轨迹，根据轨迹历史和之前的执行反馈，采取替代行动。我们在SWE-Bench Lite基准测试上评估了我们的方法，结果显示，使用Claude 3.5 Sonnet V2时，该扩展策略达到了55%的pass@k得分。我们的框架实现了47%的pass@1率，超越了现有的开源先进框架。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.14269v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>大型语言模型（LLM）在多个领域引发革命性变革，软件工程领域尤为突出。LLM驱动的编码代理具备自动化复杂开发任务、辅助调试和提高生产效率的潜力。然而，现有方法常在决策制定上表现不佳，需要大量人工干预或低效的计算扩展策略。为改善编码代理性能，本文提出动态行为重采样（DARS）技术，这是一种新颖的推理时间计算扩展方法。相较于传统方法，DARS在关键决策点展开轨迹，结合历史轨迹和执行反馈，选择替代行动。实验表明，DARS在SWE-Bench Lite基准测试上表现优异，超越现有开源框架。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>大型语言模型（LLM）在多个领域有广泛应用，包括自然语言处理、数据分析和软件开发。</li>
<li>LLM在软件工程领域助力自动化复杂开发任务、辅助调试，提高生产效率。</li>
<li>现有编码代理方法在决策制定上表现欠佳，需改进。</li>
<li>提出动态行为重采样（DARS）技术，能在推理时间进行更有效的计算扩展。</li>
<li>DARS在关键决策点展开轨迹，结合历史轨迹和执行反馈选择替代行动。</li>
<li>DARS技术在SWE-Bench Lite基准测试上表现优异，pass@k得分达到55%。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.14269">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pica.zhimg.com/v2-fdc2ef430ffc1ac5bf3bb2d59536623f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-77b529478020b42814fa91a5aa19f99a.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-0d934ed42bedcfdbb71dd7e7f06fd5b2.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f208e0bf0b3c6b8b407a89f08815dac5.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="MDocAgent-A-Multi-Modal-Multi-Agent-Framework-for-Document-Understanding"><a href="#MDocAgent-A-Multi-Modal-Multi-Agent-Framework-for-Document-Understanding" class="headerlink" title="MDocAgent: A Multi-Modal Multi-Agent Framework for Document   Understanding"></a>MDocAgent: A Multi-Modal Multi-Agent Framework for Document   Understanding</h2><p><strong>Authors:Siwei Han, Peng Xia, Ruiyi Zhang, Tong Sun, Yun Li, Hongtu Zhu, Huaxiu Yao</strong></p>
<p>Document Question Answering (DocQA) is a very common task. Existing methods using Large Language Models (LLMs) or Large Vision Language Models (LVLMs) and Retrieval Augmented Generation (RAG) often prioritize information from a single modal, failing to effectively integrate textual and visual cues. These approaches struggle with complex multi-modal reasoning, limiting their performance on real-world documents. We present MDocAgent (A Multi-Modal Multi-Agent Framework for Document Understanding), a novel RAG and multi-agent framework that leverages both text and image. Our system employs five specialized agents: a general agent, a critical agent, a text agent, an image agent and a summarizing agent. These agents engage in multi-modal context retrieval, combining their individual insights to achieve a more comprehensive understanding of the document’s content. This collaborative approach enables the system to synthesize information from both textual and visual components, leading to improved accuracy in question answering. Preliminary experiments on five benchmarks like MMLongBench, LongDocURL demonstrate the effectiveness of our MDocAgent, achieve an average improvement of 12.1% compared to current state-of-the-art method. This work contributes to the development of more robust and comprehensive DocQA systems capable of handling the complexities of real-world documents containing rich textual and visual information. Our data and code are available at <a target="_blank" rel="noopener" href="https://github.com/aiming-lab/MDocAgent">https://github.com/aiming-lab/MDocAgent</a>. </p>
<blockquote>
<p>文档问答（DocQA）是一项非常常见的任务。现有方法主要使用大型语言模型（LLM）或大型视觉语言模型（LVLM）和检索增强生成（RAG），通常优先处理单一模态的信息，无法有效地整合文本和视觉线索。这些方法在处理复杂的跨模态推理时遇到困难，限制了它们在真实文档上的表现。我们提出了MDocAgent（面向文档理解的跨模态多代理框架），这是一个新的RAG和多代理框架，利用文本和图像信息。我们的系统采用五种专业代理：通用代理、关键代理、文本代理、图像代理和总结代理。这些代理参与多模态上下文检索，结合各自的见解，实现对文档内容更全面理解。这种协作方法允许系统综合文本和视觉组件的信息，从而提高问答的准确性。在MMLongBench、LongDocURL等五个基准测试上的初步实验表明，我们的MDocAgent的有效性，与当前最先进的相比，平均提高了12.1%。这项工作促进了更健壮、更全面的DocQA系统的发展，能够处理包含丰富文本和视觉信息的真实文档的复杂性。我们的数据和代码可在<a target="_blank" rel="noopener" href="https://github.com/aiming-lab/MDocAgent%E4%B8%8A%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/aiming-lab/MDocAgent上找到。</a></p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.13964v1">PDF</a> </p>
<p><strong>Summary</strong><br>多模态文档理解的新方法MDocAgent通过结合文本和图像信息，使用五个专门代理（包括通用代理、关键代理、文本代理、图像代理和总结代理）进行多模态上下文检索，实现对文档内容的全面理解。初步实验表明，MDocAgent在五个基准测试上的表现优于当前最先进的模型，平均提高了12.1%。此工作为开发更稳健、全面的文档问答系统铺平了道路。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>MDocAgent是一个新的多模态多代理框架，用于文档理解。它利用文本和图像信息来增强文档理解。</li>
<li>该框架包含五个专门代理：通用代理、关键代理、文本代理、图像代理和总结代理。</li>
<li>这些代理进行多模态上下文检索，结合各自的见解，实现对文档内容的全面理解。</li>
<li>初步实验表明，MDocAgent在多个基准测试上的表现优于现有方法，平均提高了12.1%。</li>
<li>MDocAgent的贡献在于为开发更稳健、全面的文档问答系统铺平了道路，特别是那些需要处理富含文本和图像信息的现实世界文档的系统。</li>
<li>MDocAgent的数据和代码已公开，便于其他研究者使用和改进。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.13964">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-86d444a5664e64d3a9f47bf61f539c98.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-9216f7278b725b767b77d9acc52cf3da.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-7866ff707a20ecf58850d4615ef51cde.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-4d96102a41b65a060e18381f007ed480.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="WebNav-An-Intelligent-Agent-for-Voice-Controlled-Web-Navigation"><a href="#WebNav-An-Intelligent-Agent-for-Voice-Controlled-Web-Navigation" class="headerlink" title="WebNav: An Intelligent Agent for Voice-Controlled Web Navigation"></a>WebNav: An Intelligent Agent for Voice-Controlled Web Navigation</h2><p><strong>Authors:Trisanth Srinivasan, Santosh Patapati</strong></p>
<p>The increasing reliance on web interfaces presents many challenges for visually impaired users, showcasing the need for more advanced assistive technologies. This paper introduces WebNav, a voice-controlled web navigation agent that leverages a ReAct-inspired architecture and generative AI to provide this framework. WebNav comprises of a hierarchical structure: a Digital Navigation Module (DIGNAV) for high-level strategic planning, an Assistant Module for translating abstract commands into executable actions, and an Inference Module for low-level interaction. A key component is a dynamic labeling engine, implemented as a browser extension, that generates real-time labels for interactive elements, creating mapping between voice commands and Document Object Model (DOM) components. Preliminary evaluations show that WebNav outperforms traditional screen readers in response time and task completion accuracy for the visually impaired. Future work will focus on extensive user evaluations, benchmark development, and refining the agent’s adaptive capabilities for real-world deployment. </p>
<blockquote>
<p>随着对网页界面的依赖日益增加，为视觉障碍用户带来了许多挑战，这凸显了需要更先进的辅助技术。本文介绍了WebNav，这是一个语音控制的网页导航代理，它利用受ReAct启发的架构和生成式人工智能来提供此框架。WebNav由分层结构组成：用于高级战略规划的数字导航模块（DIGNAV）、将抽象命令翻译为可执行操作的助理模块，以及用于低级交互的推理模块。一个关键组件是动态标签引擎，它作为浏览器扩展实现，为交互元素生成实时标签，创建语音命令与文档对象模型（DOM）组件之间的映射。初步评估表明，WebNav在响应时间和任务完成准确性方面优于传统的屏幕阅读器，对视觉受损者有很大帮助。未来的工作将侧重于广泛的用户评估、基准测试开发和细化代理的适应能力，以进行实际部署。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.13843v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>WebNav是一款基于语音控制的网页导航代理，它利用ReAct架构和生成式AI提供框架，旨在解决视觉障碍用户在使用网页界面时面临的挑战。WebNav包括数字导航模块、助理模块和推理模块三个层次结构，并通过动态标签引擎生成实时标签，为视觉障碍用户提供交互元素与语音命令之间的映射。初步评估显示，WebNav在响应时间、任务完成准确性等方面优于传统屏幕阅读器。未来的工作将重点放在广泛的用户评估、基准测试发展和进一步完善代理的自适应能力以适应实际部署环境。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>WebNav是一个为视觉障碍用户设计的语音控制的网页导航代理。</li>
<li>它采用ReAct架构和生成式AI技术实现。</li>
<li>WebNav包括数字导航模块、助理模块和推理模块三个核心组成部分。</li>
<li>动态标签引擎是WebNav的关键组件，可以生成实时标签，为视觉障碍用户提供交互元素与语音命令之间的映射。</li>
<li>初步评估显示WebNav在响应时间、任务完成准确性等方面优于传统屏幕阅读器。</li>
<li>未来将进一步完善WebNav的用户适应性以及部署环境适应性。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.13843">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pica.zhimg.com/v2-d1dae6ce322505875208408802822122.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-6eb1e78cbef2cad4fb3087a7e8424a10.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b7f4aa43c022a0e8770177968b81046f.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="SagaLLM-Context-Management-Validation-and-Transaction-Guarantees-for-Multi-Agent-LLM-Planning"><a href="#SagaLLM-Context-Management-Validation-and-Transaction-Guarantees-for-Multi-Agent-LLM-Planning" class="headerlink" title="SagaLLM: Context Management, Validation, and Transaction Guarantees for   Multi-Agent LLM Planning"></a>SagaLLM: Context Management, Validation, and Transaction Guarantees for   Multi-Agent LLM Planning</h2><p><strong>Authors:Edward Y. Chang, Longling Geng</strong></p>
<p>Recent LLM-based agent frameworks have demonstrated impressive capabilities in task delegation and workflow orchestration, but face significant challenges in maintaining context awareness and ensuring planning consistency. This paper presents SagaLLM, a structured multi-agent framework that addresses four fundamental limitations in current LLM approaches: inadequate self-validation, context narrowing, lacking transaction properties, and insufficient inter-agent coordination. By implementing specialized context management agents and validation protocols, SagaLLM preserves critical constraints and state information throughout complex planning processes, enabling robust and consistent decision-making even during disruptions. We evaluate our approach using selected problems from the REALM benchmark, focusing on sequential and reactive planning scenarios that challenge both context retention and adaptive reasoning. Our experiments with state-of-the-art LLMs, Claude 3.7, DeepSeek R1, GPT-4o, and GPT-o1, demonstrate that while these models exhibit impressive reasoning capabilities, they struggle with maintaining global constraint awareness during complex planning tasks, particularly when adapting to unexpected changes. In contrast, the distributed cognitive architecture of SagaLLM shows significant improvements in planning consistency, constraint enforcement, and adaptation to disruptions in various scenarios. </p>
<blockquote>
<p>近期基于大型语言模型的代理框架在任务委派和工作流编排方面展示了令人印象深刻的能力，但在保持上下文意识和确保规划一致性方面面临重大挑战。本文提出了SagaLLM，这是一个结构化多代理框架，解决了当前大型语言模型方法中的四个基本局限性：自检不足、上下文狭窄、缺乏事务属性和代理间协调不足。通过实现专门的上文管理代理和验证协议，SagaLLM在复杂的规划过程中保持了关键的约束和状态信息，即使在中断情况下也能实现稳健和一致性的决策。我们使用REALM基准测试中的选定问题来评估我们的方法，侧重于序列和反应规划场景，这些场景对上下文保留和自适应推理都具有挑战性。我们与最新的大型语言模型进行的实验，包括Claude 3.7、DeepSeek R1、GPT-4o和GPT-o1，表明这些模型虽然具有令人印象深刻的推理能力，但在复杂的规划任务中保持全局约束意识方面存在困难，尤其是在适应意外变化时。相比之下，SagaLLM的分布式认知架构在规划一致性、约束执行和适应各种场景中的中断方面显示出显着改进。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.11951v2">PDF</a> 13 pages, 8 tables, 5 figures</p>
<p><strong>Summary</strong><br>緩冡SagaLLM框架解决了大型语言模型（LLM）在任务委派、工作流编排方面的四个根本局限：缺乏自我验证、上下文狭窄、缺乏事务属性和跨代理协调不足。通过实施专门上下文管理代理和验证协议，SagaLLM能够在复杂的规划过程中保留关键约束和状态信息，从而实现稳健且一致的决策制定，即使面临干扰也是如此。相较于先进的大型语言模型（如GPT系列等），其在适应变化的情境中的规划和一致性方面具有显著改善。本文还提供了通过实际问题来验证上述方法的实用性研究证据。研究评估是基于现实环境中的复杂规划场景的REALM基准进行的。结果验证了新方法的潜力与实用性。使用特定的REALM问题集进行的研究表明，大型语言模型在处理复杂规划任务时，特别是在适应意外变化时，维持全局约束意识方面存在困难。相比之下，SagaLLM在规划一致性、约束执行和适应各种场景中的干扰方面表现出显著优势。该方法也展示出潜在的进步价值和应用潜力。经过实践检验与当下主流的模型和技术的对比和分析得出有效的研究成果。通过SagaLLM的结构化多代理框架解决了现有大型语言模型在处理复杂任务时的问题与缺陷，有望改进当前的模型和增强实践效能与理论效益。<strong>Key Takeaways</strong>:<br>关于所给文本的关键见解，总结如下：</p>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.11951">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-45b888e3adf08f4c88f80fdfe54377a7.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c9d45fe86299488e19c1053716efc699.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-74f72ebf4750534438dc0f293353edd3.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="Program-Synthesis-Dialog-Agents-for-Interactive-Decision-Making"><a href="#Program-Synthesis-Dialog-Agents-for-Interactive-Decision-Making" class="headerlink" title="Program Synthesis Dialog Agents for Interactive Decision-Making"></a>Program Synthesis Dialog Agents for Interactive Decision-Making</h2><p><strong>Authors:Matthew Toles, Nikhil Balwani, Rattandeep Singh, Valentina Giulia Sartori Rodriguez, Zhou Yu</strong></p>
<p>Many real-world eligibility problems, ranging from medical diagnosis to tax planning, can be mapped to decision problems expressed in natural language, wherein a model must make a binary choice based on user features. Large-scale domains such as legal codes or frequently updated funding opportunities render human annotation (e.g., web forms or decision trees) impractical, highlighting the need for agents that can automatically assist in decision-making. Since relevant information is often only known to the user, it is crucial that these agents ask the right questions. As agents determine when to terminate a conversation, they face a trade-off between accuracy and the number of questions asked, a key metric for both user experience and cost. To evaluate this task, we propose BeNYfits, a new benchmark for determining user eligibility for multiple overlapping social benefits opportunities through interactive decision-making. Our experiments show that current language models struggle with frequent hallucinations, with GPT-4o scoring only 35.7 F1 using a ReAct-style chain-of-thought. To address this, we introduce ProADA, a novel approach that leverages program synthesis to assist in decision-making by mapping dialog planning to a code generation problem and using gaps in structured data to determine the best next action. Our agent, ProADA, improves the F1 score to 55.6 while maintaining nearly the same number of dialog turns. </p>
<blockquote>
<p>现实世界中的许多资格问题，从医疗诊断到税务规划，都可以映射到以自然语言表达出的决策问题，其中模型必须基于用户特征进行二元选择。大规模领域（如法律编码或经常更新的资金机会）使得人工标注（例如网页表单或决策树）变得不切实际，这突显了需要能够自动协助决策的智能代理。由于相关信息通常只为用户所知，因此这些代理需要提出正确的问题至关重要。由于代理决定了何时终止对话，因此在准确性与所提问题的数量之间需要进行权衡，这是用户体验和成本的关键指标。为了评估此任务，我们提出了BeNYfits，这是一个新的基准测试，用于通过交互式决策来确定用户对于多个重叠的社会福利机会的资格。我们的实验表明，当前的语言模型经常出现错觉，GPT-4o在ReAct风格的思考链中使用时只有35.7的F1得分。为了解决这一问题，我们引入了ProADA，这是一种利用程序合成协助决策的新方法，通过将对话规划映射到代码生成问题并使用结构化数据中的空白来确定最佳下一步行动。我们的代理ProADA将F1得分提高到55.6，同时几乎保持了相同的对话轮次。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.19610v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>本文探讨了现实世界中从医疗诊断到税务规划等资格问题的决策难题。这些问题可以通过自然语言表达为决策问题，模型根据用户特征做出二元选择。大规模领域如法律编码或频繁更新的资助机会使得人工标注不切实际，需要能够自动协助决策的智能体。智能体需要提问关键信息，并面临何时结束对话的权衡，这对准确性和提问数量提出了挑战。为评估此任务，提出BeNYfits基准测试，通过交互决策确定用户对于多重社会福利机会的资格。实验表明当前语言模型存在频繁幻觉问题，GPT-4o的F1分数仅为35.7。为解决此问题，引入ProADA方法，通过程序合成协助决策，将对话规划映射为代码生成问题并利用结构化数据中的空白确定最佳下一步行动。ProADA提高了F1分数至55.6，同时保持对话轮次数量相近。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>现实世界的许多资格问题可以通过自然语言转化为决策问题，需要智能体自动协助决策。</li>
<li>智能体需能够获取关键信息并作出二元选择。</li>
<li>大规模领域和频繁更新的信息使得人工标注不切实际，要求智能体具备自动决策能力。</li>
<li>智能体在对话过程中需权衡准确性和提问数量，关注用户体验和成本。</li>
<li>BeNYfits基准测试用于评估智能体在用户资格决策方面的表现。</li>
<li>当前语言模型存在幻觉问题，需要新方法提高准确性。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.19610">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-6093650e7a387eed4ba85cdbcafcee5d.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-283ea3d0ad3831b0d6ed83bed37d21f2.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-80d1ab32a1391a1fb6c7b5afbab3be42.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e82167fe74866a1c69b9a2d8e9f750d8.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-d5990b4e4a1f86522c906ab80c529196.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="Collaborative-Instance-Object-Navigation-Leveraging-Uncertainty-Awareness-to-Minimize-Human-Agent-Dialogues"><a href="#Collaborative-Instance-Object-Navigation-Leveraging-Uncertainty-Awareness-to-Minimize-Human-Agent-Dialogues" class="headerlink" title="Collaborative Instance Object Navigation: Leveraging   Uncertainty-Awareness to Minimize Human-Agent Dialogues"></a>Collaborative Instance Object Navigation: Leveraging   Uncertainty-Awareness to Minimize Human-Agent Dialogues</h2><p><strong>Authors:Francesco Taioli, Edoardo Zorzi, Gianni Franchi, Alberto Castellini, Alessandro Farinelli, Marco Cristani, Yiming Wang</strong></p>
<p>Language-driven instance object navigation assumes that human users initiate the task by providing a detailed description of the target instance to the embodied agent. While this description is crucial for distinguishing the target from visually similar instances in a scene, providing it prior to navigation can be demanding for human. To bridge this gap, we introduce Collaborative Instance object Navigation (CoIN), a new task setting where the agent actively resolve uncertainties about the target instance during navigation in natural, template-free, open-ended dialogues with human. We propose a novel training-free method, Agent-user Interaction with UncerTainty Awareness (AIUTA), which operates independently from the navigation policy, and focuses on the human-agent interaction reasoning with Vision-Language Models (VLMs) and Large Language Models (LLMs). First, upon object detection, a Self-Questioner model initiates a self-dialogue within the agent to obtain a complete and accurate observation description with a novel uncertainty estimation technique. Then, an Interaction Trigger module determines whether to ask a question to the human, continue or halt navigation, minimizing user input. For evaluation, we introduce CoIN-Bench, with a curated dataset designed for challenging multi-instance scenarios. CoIN-Bench supports both online evaluation with humans and reproducible experiments with simulated user-agent interactions. On CoIN-Bench, we show that AIUTA serves as a competitive baseline, while existing language-driven instance navigation methods struggle in complex multi-instance scenes. Code and benchmark will be available upon acceptance at <a target="_blank" rel="noopener" href="https://intelligolabs.github.io/CoIN/">https://intelligolabs.github.io/CoIN/</a> </p>
<blockquote>
<p>语言驱动的实例对象导航假设人类用户通过向实体代理提供目标实例的详细描述来启动任务。虽然这个描述对于从场景中的视觉上相似的实例中区分目标至关重要，但在导航之前提供它可能会对人类造成压力。为了弥补这一差距，我们引入了协作实例对象导航（COIN），这是一种新的任务设置，其中代理在与人类进行的无模板、开放式的自然对话过程中积极解决关于目标实例的不确定性。我们提出了一种新的无需训练的方法——具有不确定性感知的代理用户交互（AIUTA），它与导航策略独立，专注于利用视觉语言模型（VLMs）和大型语言模型（LLMs）进行的人机交互推理。首先，在对象检测后，自我提问模型会在代理内部发起一次自我对话，利用一种新的不确定性估计技术来获得完整准确的观察描述。然后，交互触发模块确定是否向人类提出问题、继续或停止导航，以最小化用户输入。为了评估性能，我们推出了COIN-Bench，其中包含专为具有挑战性的多实例场景设计的精选数据集。COIN-Bench支持与人类在线评估以及可重复的模拟用户与代理之间的交互实验。在COIN-Bench上，我们展示了AIUTA作为有竞争力的基准线，而现有的语言驱动实例导航方法在多实例复杂场景中表现挣扎。接受后，代码和基准测试将在<a target="_blank" rel="noopener" href="https://intelligolabs.github.io/CoIN/%E4%B8%8A%E6%8F%90%E4%BE%9B%E3%80%82">https://intelligolabs.github.io/CoIN/上提供。</a></p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.01250v3">PDF</a> <a target="_blank" rel="noopener" href="https://intelligolabs.github.io/CoIN/">https://intelligolabs.github.io/CoIN/</a></p>
<p><strong>Summary</strong></p>
<p>本文介绍了一种新的任务设置——协作式实例对象导航（CoIN），其中代理在与人进行自然、模板自由、开放式的对话过程中，主动解决关于目标实例的不确定性。提出了一种无需训练的方法——具有不确定性感知的代理用户交互（AIUTA），该方法独立于导航策略，专注于人类与代理交互推理，利用视觉语言模型（VLMs）和大型语言模型（LLMs）。通过对象检测和自我提问模型，AIUTA获得完整准确的观察描述，并引入互动触发模块来决定是否向人类提问、继续或停止导航。为评估此任务，推出了CoIN-Bench数据集，支持在线人类评估和可重复的模拟用户-代理互动实验。实验表明，AIUTA作为基准线表现有竞争力，而现有的语言驱动实例导航方法在复杂多实例场景中表现挣扎。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>引入协作式实例对象导航（CoIN）任务设置，代理在导航过程中通过与人类对话解决目标实例的不确定性。</li>
<li>提出一种无需训练的方法——AIUTA，结合视觉语言模型和大型语言模型，处理人类与代理的交互推理。</li>
<li>AIUTA通过自我提问模型获得准确观察描述，并引入互动触发模块以最小化用户输入。</li>
<li>推出CoIN-Bench数据集，支持在线人类评估和模拟用户-代理互动实验。</li>
<li>AIUTA作为基准线表现有竞争力。</li>
<li>现行的语言驱动实例导航方法在复杂多实例场景中面临挑战。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.01250">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-17ed04fcd8938cfbc674d14347d929a0.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c7f9b9f5e2f6f944860dbd31097cb3ca.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-4add5e176edf665f26820eaacf06cd5f.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="OffLight-An-Offline-Multi-Agent-Reinforcement-Learning-Framework-for-Traffic-Signal-Control"><a href="#OffLight-An-Offline-Multi-Agent-Reinforcement-Learning-Framework-for-Traffic-Signal-Control" class="headerlink" title="OffLight: An Offline Multi-Agent Reinforcement Learning Framework for   Traffic Signal Control"></a>OffLight: An Offline Multi-Agent Reinforcement Learning Framework for   Traffic Signal Control</h2><p><strong>Authors:Rohit Bokade, Xiaoning Jin</strong></p>
<p>Efficient traffic control (TSC) is essential for urban mobility, but traditional systems struggle to handle the complexity of real-world traffic. Multi-agent Reinforcement Learning (MARL) offers adaptive solutions, but online MARL requires extensive interactions with the environment, making it costly and impractical. Offline MARL mitigates these challenges by using historical traffic data for training but faces significant difficulties with heterogeneous behavior policies in real-world datasets, where mixed-quality data complicates learning. We introduce OffLight, a novel offline MARL framework designed to handle heterogeneous behavior policies in TSC datasets. To improve learning efficiency, OffLight incorporates Importance Sampling (IS) to correct for distributional shifts and Return-Based Prioritized Sampling (RBPS) to focus on high-quality experiences. OffLight utilizes a Gaussian Mixture Variational Graph Autoencoder (GMM-VGAE) to capture the diverse distribution of behavior policies from local observations. Extensive experiments across real-world urban traffic scenarios show that OffLight outperforms existing offline RL methods, achieving up to a 7.8% reduction in average travel time and 11.2% decrease in queue length. Ablation studies confirm the effectiveness of OffLight’s components in handling heterogeneous data and improving policy performance. These results highlight OffLight’s scalability and potential to improve urban traffic management without the risks of online learning. </p>
<blockquote>
<p>高效的交通控制（TSC）对城市流动性至关重要，但传统系统在处理现实交通的复杂性方面面临困难。多智能体强化学习（MARL）提供自适应解决方案，但在线MARL需要与环境的大量交互，使其成本高昂且不切实际。离线MARL通过使用历史交通数据进行训练来缓解这些挑战，但面临现实数据集中异质行为策略的重大困难，混合质量的数据使学习复杂化。我们引入了OffLight，这是一个新型的离线MARL框架，旨在处理TSC数据集中的异质行为策略。为了提高学习效率，OffLight结合了重要性采样（IS）来纠正分布偏移和基于回报的优先采样（RBPS）来专注于高质量的经验。OffLight利用高斯混合变分图自动编码器（GMM-VGAE）来捕捉从局部观察中行为策略的多样分布。在真实世界城市交通场景的大量实验表明，OffLight的性能优于现有的离线RL方法，平均旅行时间减少了7.8%，队列长度减少了11.2%。消融研究证实了OffLight组件在处理异质数据和提高策略性能方面的有效性。这些结果突出了OffLight的可扩展性和在改善城市交通管理方面的潜力，并且没有在线学习的风险。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2411.06601v3">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>高效交通控制（TSC）对城市交通流动性至关重要，传统的交通控制系统难以应对现实世界的复杂性。多智能体强化学习（MARL）提供了适应性解决方案，但在线MARL需要大量与环境互动，成本高昂且实际操作中难以实现。离线MARL通过使用历史交通数据进行训练来缓解这些问题，但在面临现实世界中异质行为策略时面临挑战，混合质量的数据会复杂化学习过程。我们提出了OffLight这一新型离线MARL框架，专为处理TSC数据集中的异质行为策略而设计。OffLight通过重要性采样（IS）纠正分布转移，并借助基于回报的优先采样（RBPS）专注于高质量经验，以提高学习效率。OffLight利用高斯混合变分图自编码器（GMM-VGAE）从局部观测中捕获行为策略的多样分布。在真实世界城市交通场景的广泛实验表明，OffLight的表现优于现有离线RL方法，平均旅行时间减少了7.8%，排队长度减少了11.2%。消融研究证实了OffLight在处理异质数据和提升策略性能方面的有效性。这些结果突显了OffLight在处理城市智能交通管理方面的可扩展性和潜力，并降低了在线学习的风险。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>高效交通控制对城市交通流动性至关重要，但传统系统难以应对现实世界的复杂性。</li>
<li>多智能体强化学习（MARL）为解决此问题提供适应性解决方案，但在线和离线MARL均面临挑战。</li>
<li>离线MARL通过使用历史交通数据进行训练，但面临处理现实世界中异质行为策略的挑战。</li>
<li>OffLight框架采用重要性采样和基于回报的优先采样提高学习效率。</li>
<li>OffLight利用高斯混合变分图自编码器处理异质数据，从局部观测中捕获行为策略的多样分布。</li>
<li>在真实世界城市交通场景的广泛实验表明，OffLight在平均旅行时间和排队长度方面表现优异。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2411.06601">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-4875cbfad1c8a51a778ee4e1b170e59b.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-eccbcd12c9ac57e54289fd47b5961267.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-355fb71c058937eeb257955228d6cb7a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-6200923ea323818a09777721e998bf84.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-642d0485f25279835c338fd661b8e88e.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-d8321eb500c95227182c129109aa876b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-684f95a4e706f0bbfa78f2372778fad1.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-abab271d89b36fd4df3fb8deba4e4256.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-cb7b1a0d7b83c856068f7f95612edaca.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-1bfcf16d2f1dcb31142c9a8c39dd0b14.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="MAC-SQL-A-Multi-Agent-Collaborative-Framework-for-Text-to-SQL"><a href="#MAC-SQL-A-Multi-Agent-Collaborative-Framework-for-Text-to-SQL" class="headerlink" title="MAC-SQL: A Multi-Agent Collaborative Framework for Text-to-SQL"></a>MAC-SQL: A Multi-Agent Collaborative Framework for Text-to-SQL</h2><p><strong>Authors:Bing Wang, Changyu Ren, Jian Yang, Xinnian Liang, Jiaqi Bai, LinZheng Chai, Zhao Yan, Qian-Wen Zhang, Di Yin, Xing Sun, Zhoujun Li</strong></p>
<p>Recent LLM-based Text-to-SQL methods usually suffer from significant performance degradation on “huge” databases and complex user questions that require multi-step reasoning. Moreover, most existing methods neglect the crucial significance of LLMs utilizing external tools and model collaboration. To address these challenges, we introduce MAC-SQL, a novel LLM-based multi-agent collaborative framework. Our framework comprises a core decomposer agent for Text-to-SQL generation with few-shot chain-of-thought reasoning, accompanied by two auxiliary agents that utilize external tools or models to acquire smaller sub-databases and refine erroneous SQL queries. The decomposer agent collaborates with auxiliary agents, which are activated as needed and can be expanded to accommodate new features or tools for effective Text-to-SQL parsing. In our framework, We initially leverage GPT-4 as the strong backbone LLM for all agent tasks to determine the upper bound of our framework. We then fine-tune an open-sourced instruction-followed model, SQL-Llama, by leveraging Code Llama 7B, to accomplish all tasks as GPT-4 does. Experiments show that SQL-Llama achieves a comparable execution accuracy of 43.94, compared to the baseline accuracy of 46.35 for vanilla GPT-4. At the time of writing, MAC-SQL+GPT-4 achieves an execution accuracy of 59.59 when evaluated on the BIRD benchmark, establishing a new state-of-the-art (SOTA) on its holdout test set (<a target="_blank" rel="noopener" href="https://github.com/wbbeyourself/MAC-SQL">https://github.com/wbbeyourself/MAC-SQL</a>). </p>
<blockquote>
<p>最近基于大型语言模型（LLM）的文本到SQL的方法在处理“大型”数据库和需要多步骤推理的复杂用户问题时通常会面临显著的性能下降。此外，大多数现有方法忽视了利用外部工具和模型协作的大型语言模型（LLM）的关键重要性。为了应对这些挑战，我们引入了MAC-SQL，这是一种基于LLM的新型多智能体协作框架。我们的框架包括一个用于文本到SQL生成的核心分解智能体，具有few-shot链式思维推理能力，以及两个利用外部工具或模型获取较小子数据库并优化错误SQL查询的辅助智能体。分解智能体与辅助智能体进行协作，辅助智能体根据需要被激活，并且可以扩展以容纳新特性或工具，从而实现有效的文本到SQL解析。在我们的框架中，我们首先利用GPT-4作为所有智能体任务的主干LLM，以确定我们框架的上限。然后，我们通过利用Code Llama 7B对开源的指令遵循模型SQL-Llama进行微调，以完成GPT-4所完成的任务。实验表明，SQL-Llama达到了与基线相当的执行准确率43.94%，而原始的GPT-4的准确率为46.35。在撰写本文时，MAC-SQL与GPT-4的组合在BIRD基准测试上的执行准确率为59.59%，在保留的测试集上创下了新的最新技术（<a target="_blank" rel="noopener" href="https://github.com/wbbeyourself/MAC-SQL%EF%BC%89%E3%80%82">https://github.com/wbbeyourself/MAC-SQL）。</a></p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2312.11242v6">PDF</a> Accepted by COLING 2025 (Oral)</p>
<p><strong>Summary</strong><br>在大型数据库和复杂用户问题中，现有LLM文本到SQL的转换方法常常存在性能下降的问题。为了解决这些问题，引入了MAC-SQL多代理协作框架。框架包括一个核心分解器代理进行文本到SQL生成，辅以两个辅助代理利用外部工具或模型获取子数据库并修正错误SQL查询。框架首次使用GPT-4作为所有任务的基础模型，然后通过微调开源的指令遵循模型SQL-Llama实现所有任务。实验表明，SQL-Llama的执行精度与GPT-4相当，MAC-SQL在BIRD基准测试上的执行精度达到59.59%，达到新的最佳水平。</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>LLM-based Text-to-SQL方法在大型数据库和复杂用户问题上存在性能下降的问题。</li>
<li>MAC-SQL是一个新型的多代理协作框架，包括核心分解器代理和辅助代理。</li>
<li>核心分解器代理用于文本到SQL生成，辅助代理利用外部工具或模型优化过程。</li>
<li>GPT-4作为框架的基础模型，SQL-Llama通过微调实现相同任务。</li>
<li>SQL-Llama的执行精度与GPT-4相当。</li>
<li>MAC-SQL在BIRD基准测试上的执行精度达到59.59%，为当前最佳水平。</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2312.11242">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-af4231f613b84be422eb764c165139f9.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-f211aaf9b8682fcdf10782dd7e355ec4.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-30019c8ff4071c5413a82923fa3b0e21.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-15ad9d94115d6285a44de5cae107ba08.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-620a6239123a8c73bdd87fa9c3a38a6d.jpg" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        文章作者:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        文章链接:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-03-20/Agent/">https://kedreamix.github.io/Talk2Paper/Paper/2025-03-20/Agent/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        版权声明:
                    </i>
                </span>
                <span class="reprint-info">
                    本博客所有文章除特別声明外，均采用
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    许可协议。转载请注明来源
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/Agent/">
                                    <span class="chip bg-color">Agent</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;上一篇</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-03-20/Few-Shot/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-fdac063fef1430d06261f18209088ae7.jpg" class="responsive-img" alt="Few-Shot">
                        
                        <span class="card-title">Few-Shot</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Few-Shot 方向最新论文已更新，请持续关注 Update in 2025-03-20  JuDGE Benchmarking Judgment Document Generation for Chinese Legal   System
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-03-20
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Few-Shot/" class="post-category">
                                    Few-Shot
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Few-Shot/">
                        <span class="chip bg-color">Few-Shot</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-03-20/LLM/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-96f22e362929099cfc1528b65e5c71a8.jpg" class="responsive-img" alt="LLM">
                        
                        <span class="card-title">LLM</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            LLM 方向最新论文已更新，请持续关注 Update in 2025-03-20  Aligning Multimodal LLM with Human Preference A Survey
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-03-20
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/LLM/" class="post-category">
                                    LLM
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/LLM/">
                        <span class="chip bg-color">LLM</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- 代码语言 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span
                        class="white-color">27663.8k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- 运行天数提醒. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // 区分是否有年份.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = '本站已运行 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                daysTip = '本站已運行 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = '本站已运行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = '本站已運行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="关注我的知乎: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">知</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- 白天和黑夜主题 -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // 只在桌面版网页启用特效
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- 雪花特效 -->
    

    <!-- 鼠标星星特效 -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--腾讯兔小巢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- 动态标签 -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Σ(っ °Д °;)っ诶，页面崩溃了嘛？", clearTimeout(st)) : (document.title = "φ(゜▽゜*)♪咦，又好了！", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
