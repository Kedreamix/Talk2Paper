<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="3DGS">
    <meta name="description" content="3DGS 方向最新论文已更新，请持续关注 Update in 2025-03-20  RoGSplat Learning Robust Generalizable Human Gaussian Splatting from   Sparse Multi-View Images">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>3DGS | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loader页面消失采用渐隐的方式*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logo出现动画 */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//使用渐隐的方法淡出loading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//强制显示loading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">嘘~  正在从服务器偷取页面 . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>首页</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>标签</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>分类</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>归档</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="搜索" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="深色/浅色模式" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			首页
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			标签
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			分类
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			归档
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://picx.zhimg.com/v2-e34cb982342175ec2888b6d7cc2d4845.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">3DGS</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/3DGS/">
                                <span class="chip bg-color">3DGS</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/3DGS/" class="post-category">
                                3DGS
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2025-03-20
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>更新日期:&nbsp;&nbsp;
                    2025-05-14
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp;
                    5.3k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp;
                    21 分
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>阅读次数:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>⚠️ 以下所有内容总结都来自于 大语言模型的能力，如有错误，仅供参考，谨慎使用<br>🔴 请注意：千万不要用于严肃的学术场景，只能用于论文阅读前的初筛！<br>💗 如果您觉得我们的项目对您有帮助 <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ，还请您给我们一些鼓励！⭐️ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFace免费体验</a></p>
</blockquote>
<h1 id="2025-03-20-更新"><a href="#2025-03-20-更新" class="headerlink" title="2025-03-20 更新"></a>2025-03-20 更新</h1><h2 id="RoGSplat-Learning-Robust-Generalizable-Human-Gaussian-Splatting-from-Sparse-Multi-View-Images"><a href="#RoGSplat-Learning-Robust-Generalizable-Human-Gaussian-Splatting-from-Sparse-Multi-View-Images" class="headerlink" title="RoGSplat: Learning Robust Generalizable Human Gaussian Splatting from   Sparse Multi-View Images"></a>RoGSplat: Learning Robust Generalizable Human Gaussian Splatting from   Sparse Multi-View Images</h2><p><strong>Authors:Junjin Xiao, Qing Zhang, Yonewei Nie, Lei Zhu, Wei-Shi Zheng</strong></p>
<p>This paper presents RoGSplat, a novel approach for synthesizing high-fidelity novel views of unseen human from sparse multi-view images, while requiring no cumbersome per-subject optimization. Unlike previous methods that typically struggle with sparse views with few overlappings and are less effective in reconstructing complex human geometry, the proposed method enables robust reconstruction in such challenging conditions. Our key idea is to lift SMPL vertices to dense and reliable 3D prior points representing accurate human body geometry, and then regress human Gaussian parameters based on the points. To account for possible misalignment between SMPL model and images, we propose to predict image-aligned 3D prior points by leveraging both pixel-level features and voxel-level features, from which we regress the coarse Gaussians. To enhance the ability to capture high-frequency details, we further render depth maps from the coarse 3D Gaussians to help regress fine-grained pixel-wise Gaussians. Experiments on several benchmark datasets demonstrate that our method outperforms state-of-the-art methods in novel view synthesis and cross-dataset generalization. Our code is available at <a target="_blank" rel="noopener" href="https://github.com/iSEE-Laboratory/RoGSplat">https://github.com/iSEE-Laboratory/RoGSplat</a>. </p>
<blockquote>
<p>本文介绍了RoGSplat，这是一种从稀疏的多视角图像合成未见人物的高保真新视角的新方法，而无需进行繁琐的主体优化。与以往通常在视角稀疏、重叠较少的情况下表现挣扎并且在重建复杂人体几何方面效果较差的方法不同，所提出的方法在这种具有挑战性的条件下实现了稳健的重建。我们的核心思想是将SMPL顶点提升到密集且可靠的3D先验点，这些点表示准确的人体几何形状，然后根据这些点回归人体高斯参数。为了考虑SMPL模型与图像之间可能出现的错位对齐问题，我们提出了通过利用像素级特征和体素级特征来预测图像对齐的3D先验点的方法，并从这些点回归粗略的高斯参数。为了提高捕捉高频细节的能力，我们还从粗略的3D高斯渲染深度图，以帮助回归精细的像素级高斯参数。在几个基准数据集上的实验表明，我们的方法在新型视图合成和跨数据集泛化方面优于最先进的方法。我们的代码可以在<a target="_blank" rel="noopener" href="https://github.com/iSEE-Laboratory/RoGSplat%E4%B8%8A%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/iSEE-Laboratory/RoGSplat上找到。</a></p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.14198v1">PDF</a> Accepted to CVPR2025</p>
<p><strong>Summary</strong></p>
<p>本文介绍了RoGSplat方法，该方法能从稀疏的多视角图像中合成高保真度的新视角人体图像，且无需对每个主题进行优化。该方法能够在仅有少量重叠的稀疏视角条件下实现稳健重建，通过提升SMPL顶点至密集可靠的3D先验点表示准确的人体几何结构，并基于此回归人体高斯参数。为解决SMPL模型与图像间可能的对齐问题，该方法预测图像对齐的3D先验点，同时利用像素级特征和体素级特征。为捕捉高频细节，该方法还从粗糙的3D高斯图中渲染深度图，以帮助回归精细的像素级高斯图。实验证明，该方法在新型视图合成和跨数据集泛化方面均优于现有技术。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>RoGSplat是一种从稀疏多视角图像合成高保真度新视角人体图像的新方法。</li>
<li>该方法无需对每个主题进行复杂的优化。</li>
<li>RoGSplat能够在仅有少量重叠的稀疏视角条件下实现稳健重建。</li>
<li>方法通过提升SMPL顶点至密集可靠的3D先验点来表示准确的人体几何结构。</li>
<li>为解决SMPL模型与图像间的对齐问题，该方法利用像素级和体素级特征预测图像对齐的3D先验点。</li>
<li>通过从粗糙的3D高斯图中渲染深度图，增强捕捉高频细节的能力。</li>
<li>实验证明，该方法在新型视图合成和跨数据集泛化方面均优于现有技术。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.14198">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pica.zhimg.com/v2-83aa55397887502c120521ab08f38d9a.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-a2129ae5d0ccbdc4617f93f680083d10.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e34cb982342175ec2888b6d7cc2d4845.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-75a399685fbfa40a3707934772bb6d2a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-4613bb27b23c058af7d71a72dac5841e.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-c8bf58ed412d4653c2e7d8c6a64340f3.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="Rethinking-End-to-End-2D-to-3D-Scene-Segmentation-in-Gaussian-Splatting"><a href="#Rethinking-End-to-End-2D-to-3D-Scene-Segmentation-in-Gaussian-Splatting" class="headerlink" title="Rethinking End-to-End 2D to 3D Scene Segmentation in Gaussian Splatting"></a>Rethinking End-to-End 2D to 3D Scene Segmentation in Gaussian Splatting</h2><p><strong>Authors:Runsong Zhu, Shi Qiu, Zhengzhe Liu, Ka-Hei Hui, Qianyi Wu, Pheng-Ann Heng, Chi-Wing Fu</strong></p>
<p>Lifting multi-view 2D instance segmentation to a radiance field has proven to be effective to enhance 3D understanding. Existing methods rely on direct matching for end-to-end lifting, yielding inferior results; or employ a two-stage solution constrained by complex pre- or post-processing. In this work, we design a new end-to-end object-aware lifting approach, named Unified-Lift that provides accurate 3D segmentation based on the 3D Gaussian representation. To start, we augment each Gaussian point with an additional Gaussian-level feature learned using a contrastive loss to encode instance information. Importantly, we introduce a learnable object-level codebook to account for individual objects in the scene for an explicit object-level understanding and associate the encoded object-level features with the Gaussian-level point features for segmentation predictions. While promising, achieving effective codebook learning is non-trivial and a naive solution leads to degraded performance. Therefore, we formulate the association learning module and the noisy label filtering module for effective and robust codebook learning. We conduct experiments on three benchmarks: LERF-Masked, Replica, and Messy Rooms datasets. Both qualitative and quantitative results manifest that our Unified-Lift clearly outperforms existing methods in terms of segmentation quality and time efficiency. The code is publicly available at \href{<a target="_blank" rel="noopener" href="https://github.com/Runsong123/Unified-Lift%7D%7Bhttps://github.com/Runsong123/Unified-Lift%7D">https://github.com/Runsong123/Unified-Lift}{https://github.com/Runsong123/Unified-Lift}</a>. </p>
<blockquote>
<p>将多视角2D实例分割提升到辐射场已被证明是增强3D理解的有效方法。现有方法依赖于端到端的直接匹配提升，效果较差；或者采用两阶段解决方案，受限于复杂的预处理或后处理。在这项工作中，我们设计了一种新的端到端对象感知提升方法，名为Unified-Lift，它基于3D高斯表示提供准确的3D分割。首先，我们通过使用对比损失学习到的附加高斯级别特征来增强每个高斯点，以编码实例信息。重要的是，我们引入了一个可学习的对象级别代码本，以考虑场景中的单个对象，以进行明确的对象级别理解，并将编码的对象级别特征与高斯级别的点特征关联起来以进行分割预测。尽管前景充满希望，但实现有效的代码本学习并非易事，而简单的解决方案会导致性能下降。因此，我们制定了关联学习模块和噪声标签过滤模块，以实现有效的鲁棒性代码本学习。我们在三个基准测试：LERF-Masked、Replica和Messy Rooms数据集上进行了实验。定性和定量结果都表明，我们的Unified-Lift在分割质量和时间效率方面明显优于现有方法。代码公开在<a target="_blank" rel="noopener" href="https://github.com/Runsong123/Unified-Lift">https://github.com/Runsong123/Unified-Lift</a>。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.14029v1">PDF</a> CVPR 2025. The code is publicly available at this https URL   (<a target="_blank" rel="noopener" href="https://github.com/Runsong123/Unified-Lift">https://github.com/Runsong123/Unified-Lift</a>)</p>
<p><strong>Summary</strong></p>
<p>本文提出了一种新的端到端物体感知提升方法，名为Unified-Lift，用于基于3D高斯表示进行准确的多视角2D实例分割到辐射场的提升。通过引入可学习的物体级别代码本，实现场景中的个体物体明确理解，并将编码的物体级别特征与高斯级别的点特征相结合进行分割预测。该方法在多个数据集上的实验结果均优于现有方法，提高了分割质量和时间效率。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>提出了一种新的端到端物体感知提升方法Unified-Lift，用于多视角2D实例分割到辐射场的提升。</li>
<li>利用高斯点附加高斯级别特征，通过对比损失进行实例信息编码。</li>
<li>引入可学习的物体级别代码本，实现场景中的个体物体明确理解。</li>
<li>结合物体级别特征和高斯级别点特征进行分割预测。</li>
<li>提出了关联学习模块和噪声标签过滤模块，以实现有效的代码本学习。</li>
<li>在多个数据集上的实验结果证明了Unified-Lift在分割质量和时间效率上的优越性。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.14029">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pica.zhimg.com/v2-efc26fe8ecdd8b155b89e53128c97eec.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-02d28195b914be5e9bdbfb11228fd225.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-d7722c1b3626b9ab5c2cfb8df11e7ccc.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d197a58ba404e483b38aca037e8d60d2.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ef159ee208688463cb5fb3f586effa11.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-aa6df7c72bd7cde7470d5f2adeb8d81b.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="Light4GS-Lightweight-Compact-4D-Gaussian-Splatting-Generation-via-Context-Model"><a href="#Light4GS-Lightweight-Compact-4D-Gaussian-Splatting-Generation-via-Context-Model" class="headerlink" title="Light4GS: Lightweight Compact 4D Gaussian Splatting Generation via   Context Model"></a>Light4GS: Lightweight Compact 4D Gaussian Splatting Generation via   Context Model</h2><p><strong>Authors:Mufan Liu, Qi Yang, He Huang, Wenjie Huang, Zhenlong Yuan, Zhu Li, Yiling Xu</strong></p>
<p>3D Gaussian Splatting (3DGS) has emerged as an efficient and high-fidelity paradigm for novel view synthesis. To adapt 3DGS for dynamic content, deformable 3DGS incorporates temporally deformable primitives with learnable latent embeddings to capture complex motions. Despite its impressive performance, the high-dimensional embeddings and vast number of primitives lead to substantial storage requirements. In this paper, we introduce a \textbf{Light}weight \textbf{4}D\textbf{GS} framework, called Light4GS, that employs significance pruning with a deep context model to provide a lightweight storage-efficient dynamic 3DGS representation. The proposed Light4GS is based on 4DGS that is a typical representation of deformable 3DGS. Specifically, our framework is built upon two core components: (1) a spatio-temporal significance pruning strategy that eliminates over 64% of the deformable primitives, followed by an entropy-constrained spherical harmonics compression applied to the remainder; and (2) a deep context model that integrates intra- and inter-prediction with hyperprior into a coarse-to-fine context structure to enable efficient multiscale latent embedding compression. Our approach achieves over 120x compression and increases rendering FPS up to 20% compared to the baseline 4DGS, and also superior to frame-wise state-of-the-art 3DGS compression methods, revealing the effectiveness of our Light4GS in terms of both intra- and inter-prediction methods without sacrificing rendering quality. </p>
<blockquote>
<p>3D高斯点云（3DGS）已经成为一种高效且高保真率的新型视图合成范式。为了适应动态内容，可变形3DGS结合了可学习的潜在嵌入和可变形原始数据，以捕捉复杂的运动。尽管其性能令人印象深刻，但高维嵌入和大量的原始数据需要大量的存储空间。在本文中，我们介绍了一种名为Light4GS的轻量级四维GS框架，该框架采用重要性裁剪和深度上下文模型来提供高效的动态存储压缩方法。所提出的Light4GS基于四维GS（是可变形体的典型代表）。具体来说，我们的框架建立在两个核心组件之上：（1）时空重要性裁剪策略，可以消除超过64％的可变形原始数据，然后对剩余部分应用熵约束球面谐波压缩；（2）深度上下文模型将帧内预测与帧间预测和超先验信息集成到粗到细的上下文结构中，以实现高效的多尺度潜在嵌入压缩。与基线四维GS相比，我们的方法实现了超过120倍的压缩率，并且渲染FPS提高了高达20％，同时也优于当前最先进的帧级三维GS压缩方法，证明了Light4GS在不影响渲染质量的情况下对于帧内和帧间预测的有效性。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.13948v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>本文介绍了Light4GS框架，该框架基于4DGS并采用时空重要性剪枝策略和深度上下文模型，旨在提供轻量级的存储高效动态3DGS表示。通过时空重要性剪枝策略，Light4GS能够消除超过64%的可变形原始数据，并对剩余数据进行熵约束球面谐波压缩。此外，其深度上下文模型结合了帧内和帧间预测与超先验，形成了一种从粗到细的上下文结构，实现了多尺度潜在嵌入的有效压缩。Light4GS框架相较于基线4DGS和其他先进的3DGS压缩方法，实现了超过120倍的压缩率提升和最高20%的渲染帧率提升，同时在渲染质量上不妥协。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>Light4GS框架采用时空重要性剪枝策略，消除多余的可变形原始数据，实现高效的存储和计算。</li>
<li>熵约束球面谐波压缩用于处理剩余数据，确保数据质量。</li>
<li>深度上下文模型结合了帧内和帧间预测与超先验，形成了一种从粗到细的上下文结构。</li>
<li>Light4GS实现了多尺度潜在嵌入的有效压缩，提高了渲染效率。</li>
<li>与基线4DGS相比，Light4GS实现了超过120倍的压缩率提升和最高20%的渲染帧率提升。</li>
<li>Light4GS在渲染质量上不妥协，表现出优异的性能。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.13948">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-d2d9e294032ddb46ea1048748b4fcd7e.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-54e865db192abad87f7e6e60ec35ccd7.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-a8d2c7bbfc84e7374b10ea39fa984c55.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-1aebf40d65ffe1dbbf7a47602a78b603.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="GS-I-3-Gaussian-Splatting-for-Surface-Reconstruction-from-Illumination-Inconsistent-Images"><a href="#GS-I-3-Gaussian-Splatting-for-Surface-Reconstruction-from-Illumination-Inconsistent-Images" class="headerlink" title="GS-I$^{3}$: Gaussian Splatting for Surface Reconstruction from   Illumination-Inconsistent Images"></a>GS-I$^{3}$: Gaussian Splatting for Surface Reconstruction from   Illumination-Inconsistent Images</h2><p><strong>Authors:Tengfei Wang, Yongmao Hou, Zhaoning Zhang, Yiwei Xu, Zongqian Zhan, Xin Wang</strong></p>
<p>Accurate geometric surface reconstruction, providing essential environmental information for navigation and manipulation tasks, is critical for enabling robotic self-exploration and interaction. Recently, 3D Gaussian Splatting (3DGS) has gained significant attention in the field of surface reconstruction due to its impressive geometric quality and computational efficiency. While recent relevant advancements in novel view synthesis under inconsistent illumination using 3DGS have shown promise, the challenge of robust surface reconstruction under such conditions is still being explored. To address this challenge, we propose a method called GS-3I. Specifically, to mitigate 3D Gaussian optimization bias caused by underexposed regions in single-view images, based on Convolutional Neural Network (CNN), a tone mapping correction framework is introduced. Furthermore, inconsistent lighting across multi-view images, resulting from variations in camera settings and complex scene illumination, often leads to geometric constraint mismatches and deviations in the reconstructed surface. To overcome this, we propose a normal compensation mechanism that integrates reference normals extracted from single-view image with normals computed from multi-view observations to effectively constrain geometric inconsistencies. Extensive experimental evaluations demonstrate that GS-3I can achieve robust and accurate surface reconstruction across complex illumination scenarios, highlighting its effectiveness and versatility in this critical challenge. <a target="_blank" rel="noopener" href="https://github.com/TFwang-9527/GS-3I">https://github.com/TFwang-9527/GS-3I</a> </p>
<blockquote>
<p>精确几何表面重建对于实现机器人的自我探索和交互至关重要，它为导航和操作任务提供了必要的环境信息。近期，由于其在几何质量和计算效率方面的出色表现，3D高斯贴图（3DGS）在表面重建领域引起了广泛关注。尽管使用3DGS在不一致照明下进行新颖视图合成的最新进展显示出希望，但在这种条件下的稳健表面重建挑战仍在探索中。为了应对这一挑战，我们提出了一种名为GS-3I的方法。具体来说，为了减轻由于单视图图像中曝光不足区域引起的3D高斯优化偏差，我们基于卷积神经网络（CNN）引入了一种色调映射校正框架。此外，由于相机设置和复杂场景照明的变化，多视图图像之间的照明不一致常常导致几何约束不匹配和重建表面的偏差。为了克服这一问题，我们提出了一种法线补偿机制，该机制将单视图图像中提取的参考法线与多视图观察计算得到的法线相结合，有效地约束了几何不一致性。广泛的实验评估表明，GS-3I可以在复杂的照明场景下实现稳健而准确的表面重建，突显了其在应对这一关键挑战中的有效性和通用性。相关代码链接：<a target="_blank" rel="noopener" href="https://github.com/TFwang-9527/GS-3I">https://github.com/TFwang-9527/GS-3I</a></p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.12335v2">PDF</a> Comments: This work has been submitted to the 2025 IEEE&#x2F;RSJ   International Conference on Intelligent Robots and Systems (IROS 2025) for   possible publication</p>
<p><strong>Summary</strong></p>
<p>基于深度学习和神经网络模型的图像光照补偿技术和基于视角校正和融合的深度补偿技术，对于实现机器人自我探索和交互中的精准几何表面重建至关重要。GS-3I方法通过引入基于卷积神经网络（CNN）的色调映射校正框架和融合单视角图像与多视角观察的正常补偿机制，解决了在复杂光照场景下表面重建的几何不一致性问题，实现了在复杂光照环境下的稳健和准确的表面重建。</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>几何表面重建对于机器人自我探索和交互至关重要，提供了导航和操作任务所需的环境信息。</li>
<li>3D高斯绘制（3DGS）由于其出色的几何质量和计算效率而受到广泛关注。</li>
<li>GS-3I方法解决了光照不一致问题导致的稳健表面重建挑战。</li>
<li>通过引入基于卷积神经网络（CNN）的色调映射校正框架，GS-3I解决了由于单视角图像曝光不足导致的优化偏差问题。</li>
<li>为了解决多视角图像中的光照不一致问题，GS-3I引入了正常补偿机制，该机制融合了单视角图像和多视角观察的法线数据，有效地约束了几何不一致性。</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.12335">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-d6e0c9ab8172fb75800dbd102152181b.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-1c85debbce6363e4e075fafb2ec48624.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-78ed21f454a15ac3f5375e140bcca46f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ca8c7d82b7a2db6d90929d01ff6283f3.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-15c6cad802b775e863ad2757de2c6fbe.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-c5e6193cf6fe5f86e60bf4d89e7384d3.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-35bd20c4d6058d7ef181b8ca7799f544.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="SAFER-Splat-A-Control-Barrier-Function-for-Safe-Navigation-with-Online-Gaussian-Splatting-Maps"><a href="#SAFER-Splat-A-Control-Barrier-Function-for-Safe-Navigation-with-Online-Gaussian-Splatting-Maps" class="headerlink" title="SAFER-Splat: A Control Barrier Function for Safe Navigation with Online   Gaussian Splatting Maps"></a>SAFER-Splat: A Control Barrier Function for Safe Navigation with Online   Gaussian Splatting Maps</h2><p><strong>Authors:Timothy Chen, Aiden Swann, Javier Yu, Ola Shorinwa, Riku Murai, Monroe Kennedy III, Mac Schwager</strong></p>
<p>SAFER-Splat (Simultaneous Action Filtering and Environment Reconstruction) is a real-time, scalable, and minimally invasive action filter, based on control barrier functions, for safe robotic navigation in a detailed map constructed at runtime using Gaussian Splatting (GSplat). We propose a novel Control Barrier Function (CBF) that not only induces safety with respect to all Gaussian primitives in the scene, but when synthesized into a controller, is capable of processing hundreds of thousands of Gaussians while maintaining a minimal memory footprint and operating at 15 Hz during online Splat training. Of the total compute time, a small fraction of it consumes GPU resources, enabling uninterrupted training. The safety layer is minimally invasive, correcting robot actions only when they are unsafe. To showcase the safety filter, we also introduce SplatBridge, an open-source software package built with ROS for real-time GSplat mapping for robots. We demonstrate the safety and robustness of our pipeline first in simulation, where our method is 20-50x faster, safer, and less conservative than competing methods based on neural radiance fields. Further, we demonstrate simultaneous GSplat mapping and safety filtering on a drone hardware platform using only on-board perception. We verify that under teleoperation a human pilot cannot invoke a collision. Our videos and codebase can be found at <a target="_blank" rel="noopener" href="https://chengine.github.io/safer-splat">https://chengine.github.io/safer-splat</a>. </p>
<blockquote>
<p>SAFER-Splat（同时动作过滤和环境重建）是一种基于控制屏障功能的实时、可扩展、微创性动作过滤器，用于在运行时使用高斯拼贴（GSplat）构建的细节地图中进行安全机器人导航。我们提出了一种新型的控制屏障功能（CBF），它不仅会对场景中的所有高斯原始数据产生安全影响，而且当被合成到控制器中时，能够处理数十万的高斯数据，同时保持较小的内存占用，并在在线拼贴训练时以1 结速运行。在总计算时间中，只有一小部分消耗GPU资源，从而实现不间断的训练。安全层是微创性的，仅在机器人动作不安全时进行纠正。为了展示安全过滤器，我们还推出了SplatBridge，这是一款用ROS构建的开源软件包，用于机器人的实时GSplat映射。我们首先在模拟中展示了我们的管道的安全性和稳健性，在这里，我们的方法比基于神经辐射场的方法快20-50倍，更安全，并且不那么保守。此外，我们在无人机硬件平台上展示了同时进行的GSplat映射和安全过滤，仅使用机载感知。我们验证了在遥操作下，人类飞行员无法造成碰撞。我们的视频和代码库可在<a target="_blank" rel="noopener" href="https://chengine.github.io/safer-splat%E6%89%BE%E5%88%B0%E3%80%82">https://chengine.github.io/safer-splat找到。</a></p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2409.09868v2">PDF</a> Accepted to International Conference on Robotics and Automation</p>
<p><strong>摘要</strong></p>
<p>SAFER-Splat是一种基于控制屏障函数的实时、可扩展、侵入性较小的行动过滤器，用于在通过高斯拼贴法构建的详细地图上进行安全机器人导航。它提出了一种新型控制屏障函数，不仅可对场景中的所有高斯原始数据进行安全诱导，而且当合成控制器时，能够处理数十万高斯数据，同时保持较小的内存占用并以15Hz的频率进行在线Splat训练。其计算时间中只有一小部分消耗GPU资源，可实现不间断的训练。安全层具有较小的侵入性，仅在机器人行动不安全时进行校正。为了展示安全过滤器，我们还推出了SplatBridge，这是一款用ROS构建的开源软件包，用于机器人的实时GSplat映射。我们在模拟环境中展示了管道的安全性和稳健性，我们的方法比基于神经辐射场的方法快20-50倍，更加安全和保守。此外，我们在仅使用机载感知的无人机硬件平台上展示了同时进行的GSplat映射和安全过滤。我们验证了在遥操作情况下，人类飞行员无法造成碰撞。更多视频和代码可在<a target="_blank" rel="noopener" href="https://chengine.github.io/safer-splat%E6%89%BE%E5%88%B0%E3%80%82">https://chengine.github.io/safer-splat找到。</a></p>
<p><strong>要点</strong></p>
<ol>
<li>SAFER-Splat是一种基于控制屏障函数的实时行动过滤器，用于机器人导航。</li>
<li>它能够处理大量高斯数据，保持低内存占用，并具备实时训练能力。</li>
<li>安全层仅在必要时进行侵入性校正。</li>
<li>SplatBridge是一个开源软件，用于机器人的实时GSplat映射。</li>
<li>在模拟环境中验证了管道的安全性和稳健性，表现优于其他方法。</li>
<li>实现了在无人机硬件平台上的同时GSplat映射和安全过滤。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2409.09868">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-fc10bbd45c0a8b00b3f829b65037f6ea.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b03ae51085b6bc8e4d6aa5d4057dd809.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-bd97a1f6630d956dca8f24087eec9afe.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-82fe09125ad6ce59c6fb652bd79c05d6.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        文章作者:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        文章链接:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-03-20/3DGS/">https://kedreamix.github.io/Talk2Paper/Paper/2025-03-20/3DGS/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        版权声明:
                    </i>
                </span>
                <span class="reprint-info">
                    本博客所有文章除特別声明外，均采用
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    许可协议。转载请注明来源
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/3DGS/">
                                    <span class="chip bg-color">3DGS</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;上一篇</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-03-20/NeRF/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-f87187633247999b654758645b746bb5.jpg" class="responsive-img" alt="NeRF">
                        
                        <span class="card-title">NeRF</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            NeRF 方向最新论文已更新，请持续关注 Update in 2025-03-20  Segmentation-Guided Neural Radiance Fields for Novel Street View   Synthesis
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-03-20
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/NeRF/" class="post-category">
                                    NeRF
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/NeRF/">
                        <span class="chip bg-color">NeRF</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-03-20/%E5%85%83%E5%AE%87%E5%AE%99_%E8%99%9A%E6%8B%9F%E4%BA%BA/">
                    <div class="card-image">
                        
                        <img src="https://pic1.zhimg.com/v2-ac3ac6966f6c14efd14d4e281fb0f0fd.jpg" class="responsive-img" alt="元宇宙/虚拟人">
                        
                        <span class="card-title">元宇宙/虚拟人</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            元宇宙/虚拟人 方向最新论文已更新，请持续关注 Update in 2025-03-20  LUCAS Layered Universal Codec Avatars
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-03-20
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/%E5%85%83%E5%AE%87%E5%AE%99-%E8%99%9A%E6%8B%9F%E4%BA%BA/" class="post-category">
                                    元宇宙/虚拟人
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/%E5%85%83%E5%AE%87%E5%AE%99-%E8%99%9A%E6%8B%9F%E4%BA%BA/">
                        <span class="chip bg-color">元宇宙/虚拟人</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- 代码语言 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span
                        class="white-color">18293.4k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- 运行天数提醒. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // 区分是否有年份.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = '本站已运行 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                daysTip = '本站已運行 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = '本站已运行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = '本站已運行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="关注我的知乎: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">知</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- 白天和黑夜主题 -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // 只在桌面版网页启用特效
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- 雪花特效 -->
    

    <!-- 鼠标星星特效 -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--腾讯兔小巢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- 动态标签 -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Σ(っ °Д °;)っ诶，页面崩溃了嘛？", clearTimeout(st)) : (document.title = "φ(゜▽゜*)♪咦，又好了！", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
