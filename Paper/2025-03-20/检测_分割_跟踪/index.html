<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="æ£€æµ‹/åˆ†å‰²/è·Ÿè¸ª">
    <meta name="description" content="æ£€æµ‹/åˆ†å‰²/è·Ÿè¸ª æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-03-20  LEGNet Lightweight Edge-Gaussian Driven Network for Low-Quality Remote   Sensing Image Object Detection">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>æ£€æµ‹/åˆ†å‰²/è·Ÿè¸ª | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://picx.zhimg.com/v2-9a2d3ac6f0083779454a51cd45ab1b8a.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">æ£€æµ‹/åˆ†å‰²/è·Ÿè¸ª</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/%E6%A3%80%E6%B5%8B-%E5%88%86%E5%89%B2-%E8%B7%9F%E8%B8%AA/">
                                <span class="chip bg-color">æ£€æµ‹/åˆ†å‰²/è·Ÿè¸ª</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/%E6%A3%80%E6%B5%8B-%E5%88%86%E5%89%B2-%E8%B7%9F%E8%B8%AA/" class="post-category">
                                æ£€æµ‹/åˆ†å‰²/è·Ÿè¸ª
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-03-20
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-04-21
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    6.6k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    26 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-03-20-æ›´æ–°"><a href="#2025-03-20-æ›´æ–°" class="headerlink" title="2025-03-20 æ›´æ–°"></a>2025-03-20 æ›´æ–°</h1><h2 id="LEGNet-Lightweight-Edge-Gaussian-Driven-Network-for-Low-Quality-Remote-Sensing-Image-Object-Detection"><a href="#LEGNet-Lightweight-Edge-Gaussian-Driven-Network-for-Low-Quality-Remote-Sensing-Image-Object-Detection" class="headerlink" title="LEGNet: Lightweight Edge-Gaussian Driven Network for Low-Quality Remote   Sensing Image Object Detection"></a>LEGNet: Lightweight Edge-Gaussian Driven Network for Low-Quality Remote   Sensing Image Object Detection</h2><p><strong>Authors:Wei Lu, Si-Bao Chen, Hui-Dong Li, Qing-Ling Shu, Chris H. Q. Ding, Jin Tang, Bin Luo</strong></p>
<p>Remote sensing object detection (RSOD) faces formidable challenges in complex visual environments. Aerial and satellite images inherently suffer from limitations such as low spatial resolution, sensor noise, blurred objects, low-light degradation, and partial occlusions. These degradation factors collectively compromise the feature discriminability in detection models, resulting in three key issues: (1) reduced contrast that hampers foreground-background separation, (2) structural discontinuities in edge representations, and (3) ambiguous feature responses caused by variations in illumination. These collectively weaken model robustness and deployment feasibility. To address these challenges, we propose LEGNet, a lightweight network that incorporates a novel edge-Gaussian aggregation (EGA) module specifically designed for low-quality remote sensing images. Our key innovation lies in the synergistic integration of Scharr operator-based edge priors with uncertainty-aware Gaussian modeling: (a) The orientation-aware Scharr filters preserve high-frequency edge details with rotational invariance; (b) The uncertainty-aware Gaussian layers probabilistically refine low-confidence features through variance estimation. This design enables precision enhancement while maintaining architectural simplicity. Comprehensive evaluations across four RSOD benchmarks (DOTA-v1.0, v1.5, DIOR-R, FAIR1M-v1.0) and a UAV-view dataset (VisDrone2019) demonstrate significant improvements. LEGNet achieves state-of-the-art performance across five benchmark datasets while ensuring computational efficiency, making it well-suited for deployment on resource-constrained edge devices in real-world remote sensing applications. The code is available at <a target="_blank" rel="noopener" href="https://github.com/lwCVer/LEGNet">https://github.com/lwCVer/LEGNet</a>. </p>
<blockquote>
<p>é¥æ„Ÿç›®æ ‡æ£€æµ‹ï¼ˆRSODï¼‰åœ¨å¤æ‚çš„è§†è§‰ç¯å¢ƒä¸­é¢ä¸´ç€å·¨å¤§çš„æŒ‘æˆ˜ã€‚èˆªç©ºå’Œå«æ˜Ÿå›¾åƒæœ¬è´¨ä¸Šå­˜åœ¨è¯¸å¦‚ç©ºé—´åˆ†è¾¨ç‡ä½ã€ä¼ æ„Ÿå™¨å™ªå£°ã€ç›®æ ‡æ¨¡ç³Šã€ä½å…‰é€€åŒ–å’Œéƒ¨åˆ†é®æŒ¡ç­‰å±€é™æ€§ã€‚è¿™äº›é€€åŒ–å› ç´ é›†ä½“å½±å“äº†æ£€æµ‹æ¨¡å‹ä¸­çš„ç‰¹å¾è¾¨åˆ«åŠ›ï¼Œå¯¼è‡´ä¸‰ä¸ªå…³é”®é—®é¢˜ï¼šï¼ˆ1ï¼‰å¯¹æ¯”åº¦é™ä½ï¼Œå¦¨ç¢å‰æ™¯èƒŒæ™¯åˆ†ç¦»ï¼›ï¼ˆ2ï¼‰è¾¹ç¼˜è¡¨ç¤ºä¸­çš„ç»“æ„ä¸è¿ç»­ï¼›ï¼ˆ3ï¼‰ç”±å…‰ç…§å˜åŒ–å¼•èµ·çš„ç‰¹å¾å“åº”æ¨¡ç³Šã€‚è¿™äº›å…±åŒå‰Šå¼±äº†æ¨¡å‹çš„ç¨³å¥æ€§å’Œéƒ¨ç½²çš„å¯è¡Œæ€§ã€‚ä¸ºäº†è§£å†³è¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†LEGNetï¼Œè¿™æ˜¯ä¸€ä¸ªè½»é‡çº§ç½‘ç»œï¼Œå®ƒèå…¥äº†ä¸€ä¸ªæ–°å‹çš„è¾¹ç¼˜é«˜æ–¯èšåˆï¼ˆEGAï¼‰æ¨¡å—ï¼Œä¸“é—¨é’ˆå¯¹ä½è´¨é‡çš„é¥æ„Ÿå›¾åƒè®¾è®¡ã€‚æˆ‘ä»¬çš„å…³é”®åˆ›æ–°åœ¨äºå°†åŸºäºScharrç®—å­çš„è¾¹ç¼˜å…ˆéªŒä¸ä¸ç¡®å®šæ€§æ„ŸçŸ¥é«˜æ–¯å»ºæ¨¡ååŒé›†æˆï¼šï¼ˆaï¼‰æ–¹å‘æ„ŸçŸ¥çš„Scharræ»¤æ³¢å™¨ä»¥æ—‹è½¬ä¸å˜æ€§ä¿ç•™é«˜é¢‘è¾¹ç¼˜ç»†èŠ‚ï¼›ï¼ˆbï¼‰ä¸ç¡®å®šæ€§æ„ŸçŸ¥çš„é«˜æ–¯å±‚é€šè¿‡æ–¹å·®ä¼°è®¡æ¦‚ç‡åœ°ä¼˜åŒ–ä½ç½®ä¿¡ç‰¹å¾ã€‚è¿™ä¸€è®¾è®¡æ—¢æé«˜äº†ç²¾åº¦ï¼Œåˆä¿æŒäº†æ¶æ„çš„ç®€å•æ€§ã€‚åœ¨å››ä¸ªRSODåŸºå‡†ï¼ˆDOTA-v1.0ã€v1.5ã€DIOR-Rã€FAIR1M-v1.0ï¼‰å’Œä¸€ä¸ªæ— äººæœºè§†è§’æ•°æ®é›†ï¼ˆVisDrone2019ï¼‰ä¸Šçš„å…¨é¢è¯„ä¼°è¡¨æ˜ï¼ŒLEGNetå–å¾—äº†æ˜¾è‘—æ”¹è¿›ï¼Œåœ¨äº”ä¸ªåŸºå‡†æ•°æ®é›†ä¸Šå®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼ŒåŒæ—¶ç¡®ä¿äº†è®¡ç®—æ•ˆç‡ï¼Œéå¸¸é€‚åˆåœ¨èµ„æºå—é™çš„è¾¹ç¼˜è®¾å¤‡ä¸Šç”¨äºç°å®ä¸–ç•Œé¥æ„Ÿåº”ç”¨éƒ¨ç½²ã€‚ä»£ç å¯é€šè¿‡<a target="_blank" rel="noopener" href="https://github.com/lwCVer/LEGNet%E8%8E%B7%E5%8F%96%E3%80%82">https://github.com/lwCVer/LEGNetè·å–ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.14012v1">PDF</a> 12 pages, 5 figures. Remote Sensing Image Object Detection</p>
<p><strong>Summary</strong></p>
<p>åœ¨å¤æ‚çš„è§†è§‰ç¯å¢ƒä¸­ï¼Œé¥æ„Ÿç›®æ ‡æ£€æµ‹é¢ä¸´ä¸¥å³»æŒ‘æˆ˜ã€‚è¿œç¨‹å›¾åƒå› ä½ç©ºé—´åˆ†è¾¨ç‡ã€ä¼ æ„Ÿå™¨å™ªå£°ã€ç›®æ ‡æ¨¡ç³Šã€ä½å…‰ç…§é€€åŒ–å’Œéƒ¨åˆ†é®æŒ¡ç­‰å›ºæœ‰ç¼ºé™·ï¼Œå¯¼è‡´æ£€æµ‹æ¨¡å‹çš„ç‰¹å¾è¾¨åˆ«èƒ½åŠ›ä¸‹é™ã€‚è¿™äº›é—®é¢˜é›†ä½“é€ æˆå¯¹æ¯”å‡å°‘ã€è¾¹ç¼˜æ–­è£‚ä»¥åŠå› å…‰ç…§å˜åŒ–äº§ç”Ÿçš„ç‰¹å¾æ¨¡ç³Šï¼Œé™ä½æ¨¡å‹ç¨³å¥æ€§å’Œéƒ¨ç½²å¯è¡Œæ€§ã€‚ä¸ºè§£å†³æ­¤é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºLEGNetç½‘ç»œï¼Œå®ƒç»“åˆäº†æ–°é¢–çš„è¾¹ç¼˜é«˜æ–¯èšåˆæ¨¡å—ï¼Œä¸“ä¸ºä½è´¨é‡é¥æ„Ÿå›¾åƒè®¾è®¡ã€‚ä¸»è¦åˆ›æ–°åœ¨äºç»“åˆåŸºäºScharrç®—å­çš„è¾¹ç¼˜å…ˆéªŒä¸æ¦‚ç‡åŒ–é«˜æ–¯å»ºæ¨¡ï¼Œæ—¢èƒ½ä¿ç•™è¾¹ç¼˜ç»†èŠ‚åˆèƒ½é€šè¿‡æ–¹å·®ä¼°è®¡ä¼˜åŒ–ä½ç½®ä¿¡åº¦ç‰¹å¾ã€‚åœ¨å››ä¸ªé¥æ„Ÿç›®æ ‡æ£€æµ‹åŸºå‡†æµ‹è¯•ä¸­è¡¨ç°å‡ºå“è¶Šæ€§èƒ½ï¼ŒåŒæ—¶ä¿è¯è®¡ç®—æ•ˆç‡ï¼Œé€‚ç”¨äºèµ„æºå—é™çš„è¾¹ç¼˜è®¾å¤‡è¿›è¡Œé¥æ„Ÿåº”ç”¨éƒ¨ç½²ã€‚ä»£ç å·²ä¸Šä¼ è‡³GitHubä¾›å…¬ä¼—æŸ¥é˜…ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>é¥æ„Ÿç›®æ ‡æ£€æµ‹é¢ä¸´è¯¸å¤šæŒ‘æˆ˜ï¼ŒåŒ…æ‹¬å›¾åƒä½ç©ºé—´åˆ†è¾¨ç‡å’Œæ¨¡ç³Šå¯¹è±¡ç­‰é—®é¢˜ã€‚</li>
<li>ä¸Šè¿°ç¼ºé™·é™ä½æ£€æµ‹æ¨¡å‹çš„æ€§èƒ½åŠè¯†åˆ«ç‰¹å¾çš„å¯é æ€§ã€‚</li>
<li>LEGNetç½‘ç»œè®¾è®¡é’ˆå¯¹ä½è´¨é‡é¥æ„Ÿå›¾åƒæå‡ºï¼ŒåŒ…å«æ–°é¢–çš„è¾¹ç¼˜é«˜æ–¯èšåˆæ¨¡å—ã€‚</li>
<li>ä¸»è¦åˆ›æ–°åœ¨äºç»“åˆåŸºäºScharrç®—å­çš„è¾¹ç¼˜å…ˆéªŒä¸æ¦‚ç‡åŒ–é«˜æ–¯å»ºæ¨¡ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.14012">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-1768f338648abe5981cd8665c707c068.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-791ec0128e7d69293864fb2eab55cd5f.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-d3c64494da2f182f23c2a7aec3a06387.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-901839f9dd68f104edf4325f23b40d31.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="FrustumFusionNets-A-Three-Dimensional-Object-Detection-Network-Based-on-Tractor-Road-Scene"><a href="#FrustumFusionNets-A-Three-Dimensional-Object-Detection-Network-Based-on-Tractor-Road-Scene" class="headerlink" title="FrustumFusionNets: A Three-Dimensional Object Detection Network Based on   Tractor Road Scene"></a>FrustumFusionNets: A Three-Dimensional Object Detection Network Based on   Tractor Road Scene</h2><p><strong>Authors:Lili Yang, Mengshuai Chang, Xiao Guo, Yuxin Feng, Yiwen Mei, Caicong Wu</strong></p>
<p>To address the issues of the existing frustum-based methodsâ€™ underutilization of image information in road three-dimensional object detection as well as the lack of research on agricultural scenes, we constructed an object detection dataset using an 80-line Light Detection And Ranging (LiDAR) and a camera in a complex tractor road scene and proposed a new network called FrustumFusionNets (FFNets). Initially, we utilize the results of image-based two-dimensional object detection to narrow down the search region in the three-dimensional space of the point cloud. Next, we introduce a Gaussian mask to enhance the point cloud information. Then, we extract the features from the frustum point cloud and the crop image using the point cloud feature extraction pipeline and the image feature extraction pipeline, respectively. Finally, we concatenate and fuse the data features from both modalities to achieve three-dimensional object detection. Experiments demonstrate that on the constructed test set of tractor road data, the FrustumFusionNetv2 achieves 82.28% and 95.68% accuracy in the three-dimensional object detection of the two main road objects, cars and people, respectively. This performance is 1.83% and 2.33% better than the original model. It offers a hybrid fusion-based multi-object, high-precision, real-time three-dimensional object detection technique for unmanned agricultural machines in tractor road scenarios. On the Karlsruhe Institute of Technology and Toyota Technological Institute (KITTI) Benchmark Suite validation set, the FrustumFusionNetv2 also demonstrates significant superiority in detecting road pedestrian objects compared with other frustum-based three-dimensional object detection methods. </p>
<blockquote>
<p>ä¸ºäº†è§£å†³ç°æœ‰åŸºäºæˆªé”¥ä½“æ–¹æ³•åœ¨é“è·¯ä¸‰ç»´ç›®æ ‡æ£€æµ‹ä¸­å¯¹å›¾åƒä¿¡æ¯åˆ©ç”¨ä¸è¶³çš„é—®é¢˜ä»¥åŠåœ¨å†œä¸šåœºæ™¯ç ”ç©¶æ–¹é¢çš„ç¼ºä¹ï¼Œæˆ‘ä»¬æ„å»ºäº†ä¸€ä¸ªç›®æ ‡æ£€æµ‹æ•°æ®é›†ï¼Œè¯¥æ•°æ®é›†ä½¿ç”¨æ‹–æ‹‰æœºé“è·¯åœºæ™¯ä¸­ä¸€å°å¤æ‚çš„80çº¿æ¿€å…‰é›·è¾¾å’Œæ‘„åƒæœºã€‚åœ¨æ­¤åŸºç¡€ä¸Šï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°çš„ç½‘ç»œç»“æ„ï¼Œç§°ä¸ºFrustumFusionNetsï¼ˆFFNetsï¼‰ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬åˆ©ç”¨åŸºäºå›¾åƒçš„ä¸¤ç»´ç›®æ ‡æ£€æµ‹ç»“æœæ¥ç¼©å°ç‚¹äº‘çš„ä¸‰ç»´æœç´¢åŒºåŸŸã€‚æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å¼•å…¥é«˜æ–¯æ©è†œä»¥å¢å¼ºç‚¹äº‘ä¿¡æ¯ã€‚ç„¶åï¼Œæˆ‘ä»¬ä»æˆªé”¥ç‚¹äº‘å’Œä½œç‰©å›¾åƒä¸­æå–ç‰¹å¾ï¼Œåˆ†åˆ«ä½¿ç”¨ç‚¹äº‘ç‰¹å¾æå–ç®¡é“å’Œå›¾åƒç‰¹å¾æå–ç®¡é“ã€‚æœ€åï¼Œæˆ‘ä»¬å°†ä¸¤ç§æ¨¡æ€çš„æ•°æ®ç‰¹å¾è¿›è¡Œæ‹¼æ¥å’Œèåˆï¼Œä»¥å®ç°ä¸‰ç»´ç›®æ ‡æ£€æµ‹ã€‚å®éªŒè¡¨æ˜ï¼Œåœ¨æ„å»ºçš„æ‹–æ‹‰æœºé“è·¯æµ‹è¯•é›†ä¸Šï¼ŒFrustumFusionNetv2é’ˆå¯¹ä¸»è¦é“è·¯ç›®æ ‡è½¦è¾†å’Œè¡Œäººï¼Œåœ¨ä¸‰ç»´ç›®æ ‡æ£€æµ‹æ–¹é¢çš„å‡†ç¡®ç‡åˆ†åˆ«è¾¾åˆ°82.28%å’Œ95.68%ã€‚è¿™ä¸€æ€§èƒ½æ¯”åŸå§‹æ¨¡å‹æé«˜äº†1.83%å’Œ2.33%ã€‚å®ƒä¸ºæ— äººé©¾é©¶å†œä¸šæœºå™¨åœ¨æ‹–æ‹‰æœºé“è·¯ä¸Šçš„åœºæ™¯ä¸­æä¾›äº†ä¸€ç§åŸºäºæ··åˆèåˆçš„å¤šç›®æ ‡ã€é«˜ç²¾åº¦ã€å®æ—¶çš„ä¸‰ç»´ç›®æ ‡æ£€æµ‹æŠ€æœ¯ã€‚åœ¨KITTIåŸºå‡†å¥—ä»¶éªŒè¯é›†ä¸Šï¼Œä¸å…¶ä»–çš„åŸºäºæˆªé”¥ä½“çš„ä¸‰ç»´ç›®æ ‡æ£€æµ‹æ–¹æ³•ç›¸æ¯”ï¼ŒFrustumFusionNetv2åœ¨æ£€æµ‹é“è·¯è¡Œäººç›®æ ‡æ–¹é¢è¡¨ç°å‡ºæ˜¾è‘—çš„ä¼˜è¶Šæ€§ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.13951v1">PDF</a> </p>
<p><strong>Summary</strong><br>     é’ˆå¯¹ç°æœ‰åŸºäºFrustumçš„æ–¹æ³•å¯¹å›¾åƒä¿¡æ¯åˆ©ç”¨ä¸è¶³çš„é—®é¢˜ï¼Œä»¥åŠå†œä¸šåœºæ™¯ç ”ç©¶ç¼ºä¹çš„é—®é¢˜ï¼Œæˆ‘ä»¬æ„å»ºäº†ä¸€ä¸ªä½¿ç”¨æ¿€å…‰é›·è¾¾å’Œæ‹–æ‹‰æœºé“è·¯åœºæ™¯ç›¸æœºçš„å¯¹è±¡æ£€æµ‹æ•°æ®é›†ï¼Œå¹¶æå‡ºäº†ä¸€ä¸ªæ–°çš„ç½‘ç»œâ€”â€”FrustumFusionNetsï¼ˆFFNetsï¼‰ã€‚é¦–å…ˆï¼Œåˆ©ç”¨åŸºäºå›¾åƒçš„äºŒç»´å¯¹è±¡æ£€æµ‹ç»“æœç¼©å°ç‚¹äº‘çš„ä¸‰ç»´æœç´¢åŒºåŸŸã€‚æ¥ç€ï¼Œå¼•å…¥é«˜æ–¯æ©è†œå¢å¼ºç‚¹äº‘ä¿¡æ¯ã€‚ç„¶åï¼Œåˆ†åˆ«ä»ç‚¹äº‘å’Œå†œä½œç‰©å›¾åƒä¸­æå–ç‰¹å¾ï¼Œå¹¶é€šè¿‡æ‹¼æ¥èåˆä¸¤ç§æ¨¡æ€çš„æ•°æ®ç‰¹å¾æ¥å®ç°ä¸‰ç»´å¯¹è±¡æ£€æµ‹ã€‚å®éªŒè¡¨æ˜ï¼Œåœ¨æ„å»ºçš„æ‹–æ‹‰æœºé“è·¯æµ‹è¯•é›†ä¸Šï¼ŒFrustumFusionNetv2å¯¹ä¸»è¦é“è·¯å¯¹è±¡æ±½è½¦å’Œè¡Œäººçš„ä¸‰ç»´å¯¹è±¡æ£€æµ‹å‡†ç¡®ç‡åˆ†åˆ«è¾¾åˆ°82.28%å’Œ95.68%ï¼Œè¾ƒåŸæ¨¡å‹æå‡1.83%å’Œ2.33%ã€‚è¯¥æ¨¡å‹ä¸ºæ— äººé©¾é©¶å†œä¸šæœºæ¢°åœ¨æ‹–æ‹‰æœºé“è·¯ä¸Šçš„å¤šå¯¹è±¡ã€é«˜ç²¾åº¦ã€å®æ—¶ä¸‰ç»´å¯¹è±¡æ£€æµ‹æä¾›äº†æ··åˆèåˆæŠ€æœ¯ã€‚åœ¨KITTIåŸºå‡†å¥—ä»¶éªŒè¯é›†ä¸Šï¼Œä¸å…¶ä»–çš„åŸºäºFrustumçš„ä¸‰ç»´å¯¹è±¡æ£€æµ‹æ–¹æ³•ç›¸æ¯”ï¼Œè¯¥æ¨¡å‹åœ¨æ£€æµ‹é“è·¯è¡Œäººå¯¹è±¡æ–¹é¢å…·æœ‰æ˜¾è‘—ä¼˜åŠ¿ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>é’ˆå¯¹ç°æœ‰æ–¹æ³•å›¾åƒä¿¡æ¯åˆ©ç”¨ä¸è¶³çš„é—®é¢˜ï¼Œæ„å»ºäº†åŸºäºæ¿€å…‰é›·è¾¾å’Œç›¸æœºçš„æ‹–æ‹‰æœºé“è·¯åœºæ™¯å¯¹è±¡æ£€æµ‹æ•°æ®é›†ã€‚</li>
<li>æå‡ºäº†ä¸€ç§æ–°çš„ç½‘ç»œç»“æ„â€”â€”FrustumFusionNetsï¼ˆFFNetsï¼‰ã€‚</li>
<li>åˆ©ç”¨äºŒç»´å›¾åƒæ£€æµ‹ç»“æœç¼©å°ä¸‰ç»´ç‚¹äº‘çš„æœç´¢åŒºåŸŸã€‚</li>
<li>é€šè¿‡å¼•å…¥é«˜æ–¯æ©è†œå¢å¼ºç‚¹äº‘ä¿¡æ¯ã€‚</li>
<li>å®ç°äº†ä»ç‚¹äº‘å’Œå†œä½œç‰©å›¾åƒä¸­æå–ç‰¹å¾å¹¶è¿›è¡Œä¸‰ç»´å¯¹è±¡æ£€æµ‹ã€‚</li>
<li>åœ¨æ‹–æ‹‰æœºé“è·¯æµ‹è¯•é›†ä¸Šï¼Œæ–°æ¨¡å‹è¾ƒåŸæ¨¡å‹æœ‰æ˜¾è‘—æå‡ã€‚</li>
<li>æ¨¡å‹ä¸ºæ— äººé©¾é©¶å†œä¸šæœºæ¢°æä¾›äº†æ··åˆèåˆæŠ€æœ¯çš„å¤šå¯¹è±¡ã€é«˜ç²¾åº¦ã€å®æ—¶ä¸‰ç»´å¯¹è±¡æ£€æµ‹æ–¹æ¡ˆã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.13951">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-204845204a87dc53f24c90eeb70f0d2f.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="HSOD-BIT-V2-A-New-Challenging-Benchmarkfor-Hyperspectral-Salient-Object-Detection"><a href="#HSOD-BIT-V2-A-New-Challenging-Benchmarkfor-Hyperspectral-Salient-Object-Detection" class="headerlink" title="HSOD-BIT-V2: A New Challenging Benchmarkfor Hyperspectral Salient Object   Detection"></a>HSOD-BIT-V2: A New Challenging Benchmarkfor Hyperspectral Salient Object   Detection</h2><p><strong>Authors:Yuhao Qiu, Shuyan Bai, Tingfa Xu, Peifu Liu, Haolin Qin, Jianan Li</strong></p>
<p>Salient Object Detection (SOD) is crucial in computer vision, yet RGB-based methods face limitations in challenging scenes, such as small objects and similar color features. Hyperspectral images provide a promising solution for more accurate Hyperspectral Salient Object Detection (HSOD) by abundant spectral information, while HSOD methods are hindered by the lack of extensive and available datasets. In this context, we introduce HSOD-BIT-V2, the largest and most challenging HSOD benchmark dataset to date. Five distinct challenges focusing on small objects and foreground-background similarity are designed to emphasize spectral advantages and real-world complexity. To tackle these challenges, we propose Hyper-HRNet, a high-resolution HSOD network. Hyper-HRNet effectively extracts, integrates, and preserves effective spectral information while reducing dimensionality by capturing the self-similar spectral features. Additionally, it conveys fine details and precisely locates object contours by incorporating comprehensive global information and detailed object saliency representations. Experimental analysis demonstrates that Hyper-HRNet outperforms existing models, especially in challenging scenarios. </p>
<blockquote>
<p>æ˜¾è‘—æ€§ç›®æ ‡æ£€æµ‹ï¼ˆSODï¼‰åœ¨è®¡ç®—æœºè§†è§‰ä¸­è‡³å…³é‡è¦ï¼Œç„¶è€ŒåŸºäºRGBçš„æ–¹æ³•åœ¨å…·æœ‰æŒ‘æˆ˜æ€§çš„åœºæ™¯ä¸­ï¼Œå¦‚å°ç‰©ä½“å’Œç›¸ä¼¼é¢œè‰²ç‰¹å¾æ–¹é¢å­˜åœ¨å±€é™æ€§ã€‚é«˜å…‰è°±å›¾åƒé€šè¿‡ä¸°å¯Œçš„å…‰è°±ä¿¡æ¯ä¸ºè§£å†³æ›´å‡†ç¡®çš„é«˜å…‰è°±æ˜¾è‘—æ€§ç›®æ ‡æ£€æµ‹ï¼ˆHSODï¼‰é—®é¢˜æä¾›äº†æœ‰å‰æ™¯çš„è§£å†³æ–¹æ¡ˆã€‚ç„¶è€Œï¼Œç”±äºç¼ºä¹å¹¿æ³›å¯ç”¨çš„æ•°æ®é›†ï¼ŒHSODæ–¹æ³•å—åˆ°é˜»ç¢ã€‚åœ¨æ­¤èƒŒæ™¯ä¸‹ï¼Œæˆ‘ä»¬ä»‹ç»äº†è¿„ä»Šä¸ºæ­¢æœ€å¤§ä¸”æœ€å…·æŒ‘æˆ˜æ€§çš„é«˜å…‰è°±æ˜¾è‘—æ€§ç›®æ ‡æ£€æµ‹æ•°æ®é›†HSOD-BIT-V2ã€‚æˆ‘ä»¬è®¾è®¡äº†äº”ä¸ªç‹¬ç‰¹æŒ‘æˆ˜ï¼Œé‡ç‚¹å…³æ³¨å°ç‰©ä½“å’Œå‰æ™¯èƒŒæ™¯ç›¸ä¼¼æ€§ï¼Œä»¥çªå‡ºå…‰è°±ä¼˜åŠ¿å’Œç°å®ä¸–ç•Œå¤æ‚æ€§ã€‚ä¸ºäº†è§£å†³è¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†é«˜åˆ†è¾¨ç‡é«˜å…‰è°±æ˜¾è‘—æ€§ç›®æ ‡æ£€æµ‹ç½‘ç»œHyper-HRNetã€‚Hyper-HRNetèƒ½å¤Ÿæœ‰æ•ˆåœ°æå–ã€é›†æˆå’Œä¿ç•™æœ‰æ•ˆçš„å…‰è°±ä¿¡æ¯ï¼Œé€šè¿‡æ•è·è‡ªç›¸ä¼¼å…‰è°±ç‰¹å¾æ¥é™ä½ç»´åº¦ã€‚æ­¤å¤–ï¼Œå®ƒç»“åˆå…¨é¢çš„å…¨å±€ä¿¡æ¯å’Œè¯¦ç»†çš„å¯¹è±¡æ˜¾è‘—æ€§è¡¨ç¤ºï¼Œä¼ é€’äº†ç²¾ç»†çš„ç»†èŠ‚å¹¶å‡†ç¡®åœ°å¯¹å¯¹è±¡è½®å»“è¿›è¡Œäº†å®šä½ã€‚å®éªŒåˆ†æè¡¨æ˜ï¼ŒHyper-HRNetåœ¨å…·æœ‰æŒ‘æˆ˜æ€§çš„åœºæ™¯ä¸­è¡¨ç°ä¼˜äºç°æœ‰æ¨¡å‹ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.13906v1">PDF</a> AAAI 2025</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†åŸºäºè®¡ç®—æœºè§†è§‰çš„æ˜¾è‘—æ€§ç›®æ ‡æ£€æµ‹ï¼ˆSODï¼‰çš„é‡è¦æ€§ï¼ŒæŒ‡å‡ºRGBæ–¹æ³•åœ¨æŸäº›å¤æ‚åœºæ™¯ä¸­å­˜åœ¨å±€é™æ€§ã€‚ä¸ºè§£å†³è¿™ä¸€é—®é¢˜ï¼Œç ”ç©¶è€…å¼•å…¥è¶…å…‰è°±å›¾åƒä½œä¸ºè§£å†³æ–¹æ¡ˆï¼Œå¹¶æ¨å‡ºè¿„ä»Šä¸ºæ­¢æœ€å¤§çš„è¶…å…‰è°±æ˜¾è‘—æ€§ç›®æ ‡æ£€æµ‹ï¼ˆHSODï¼‰æ•°æ®é›†HSOD-BIT-V2ã€‚é’ˆå¯¹è¶…å…‰è°±å›¾åƒçš„ç‰¹ç‚¹å’Œå®é™…åº”ç”¨åœºæ™¯ä¸­çš„å¤æ‚æ€§ï¼Œè®¾è®¡äº”ä¸ªå…·æœ‰æŒ‘æˆ˜æ€§çš„å°ç›®æ ‡è¯†åˆ«åœºæ™¯åŠäº”ä¸ªèƒŒæ™¯è¯†åˆ«æŒ‘æˆ˜åœºæ™¯ã€‚æ­¤å¤–ï¼Œæå‡ºäº†åŸºäºHyper-HRNetçš„è¶…å…‰è°±é«˜åˆ†è¾¨ç‡ç›®æ ‡æ£€æµ‹ç½‘ç»œã€‚è¯¥ç½‘ç»œèƒ½æœ‰æ•ˆæå–ã€æ•´åˆå’Œä¿ç•™æœ‰æ•ˆçš„å…‰è°±ä¿¡æ¯ï¼Œé€šè¿‡æ•æ‰è‡ªç›¸ä¼¼å…‰è°±ç‰¹å¾é™ä½ç»´åº¦ï¼ŒåŒæ—¶ç»“åˆå…¨å±€ä¿¡æ¯å’Œè¯¦ç»†çš„å¯¹è±¡æ˜¾è‘—æ€§è¡¨ç¤ºï¼Œç²¾ç»†åœ°æç»˜å‡ºç‰©ä½“çš„è½®å»“ã€‚å®éªŒè¡¨æ˜ï¼ŒHyper-HRNetç›¸è¾ƒäºç°æœ‰æ¨¡å‹æ€§èƒ½æ›´ä¼˜ï¼Œç‰¹åˆ«æ˜¯åœ¨å¤æ‚åœºæ™¯ä¸‹ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>RGBæ–¹æ³•åœ¨å¤„ç†æŸäº›å¤æ‚åœºæ™¯çš„æ˜¾è‘—æ€§ç›®æ ‡æ£€æµ‹ï¼ˆSODï¼‰æ—¶å­˜åœ¨å±€é™æ€§ã€‚</li>
<li>è¶…å…‰è°±å›¾åƒæä¾›äº†è§£å†³æ­¤é—®é¢˜çš„æœ‰å‰æ™¯çš„è§£å†³æ–¹æ¡ˆï¼Œæ‹¥æœ‰ä¸°å¯Œçš„å…‰è°±ä¿¡æ¯ä»¥æé«˜å‡†ç¡®æ€§ã€‚</li>
<li>HSODæ•°æ®é›†HSOD-BIT-V2æ˜¯ç›®å‰æœ€å¤§çš„è¶…å…‰è°±æ˜¾è‘—æ€§ç›®æ ‡æ£€æµ‹æ•°æ®é›†ï¼ŒåŒ…å«äº”ä¸ªå…·æœ‰æŒ‘æˆ˜æ€§çš„å°ç›®æ ‡è¯†åˆ«åœºæ™¯å’Œäº”ä¸ªèƒŒæ™¯è¯†åˆ«æŒ‘æˆ˜åœºæ™¯ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.13906">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-d698f8db3bb5fd7d9ce28cbf562c2882.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-98a25afaa0aed6520389ca10e34df815.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-7bbd2f5d68a19e30032d0009a3d98964.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-45596f5fcdfe9bf187d00da7e4ff879b.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-c4a51350df28c87fca51337d1ea88627.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-034ca91c43af03854e4fdfca10364d09.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="Biologically-inspired-Semi-supervised-Semantic-Segmentation-for-Biomedical-Imaging"><a href="#Biologically-inspired-Semi-supervised-Semantic-Segmentation-for-Biomedical-Imaging" class="headerlink" title="Biologically-inspired Semi-supervised Semantic Segmentation for   Biomedical Imaging"></a>Biologically-inspired Semi-supervised Semantic Segmentation for   Biomedical Imaging</h2><p><strong>Authors:Luca Ciampi, Gabriele Lagani, Giuseppe Amato, Fabrizio Falchi</strong></p>
<p>We propose a novel bio-inspired semi-supervised learning approach for training downsampling-upsampling semantic segmentation architectures. The first stage does not use backpropagation. Rather, it exploits the Hebbian principle &#96;&#96;fire together, wire togetherâ€™â€™ as a local learning rule for updating the weights of both convolutional and transpose-convolutional layers, allowing unsupervised discovery of data features. In the second stage, the model is fine-tuned with standard backpropagation on a small subset of labeled data. We evaluate our methodology through experiments conducted on several widely used biomedical datasets, deeming that this domain is paramount in computer vision and is notably impacted by data scarcity. Results show that our proposed method outperforms SOTA approaches across different levels of label availability. Furthermore, we show that using our unsupervised stage to initialize the SOTA approaches leads to performance improvements. The code to replicate our experiments can be found at <a target="_blank" rel="noopener" href="https://github.com/ciampluca/hebbian-bootstraping-semi-supervised-medical-imaging">https://github.com/ciampluca/hebbian-bootstraping-semi-supervised-medical-imaging</a> </p>
<blockquote>
<p>æˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°å‹çš„ç”Ÿç‰©å¯å‘åŠç›‘ç£å­¦ä¹ æ–¹æ³•ï¼Œç”¨äºè®­ç»ƒä¸‹é‡‡æ ·-ä¸Šé‡‡æ ·è¯­ä¹‰åˆ†å‰²æ¶æ„ã€‚ç¬¬ä¸€é˜¶æ®µä¸ä½¿ç”¨åå‘ä¼ æ’­ã€‚ç›¸åï¼Œå®ƒåˆ©ç”¨èµ«å¸ƒåŸåˆ™â€œä¸€èµ·å‘å°„ï¼Œä¸€èµ·è¿æ¥â€ä½œä¸ºå±€éƒ¨å­¦ä¹ è§„åˆ™ï¼Œä»¥æ›´æ–°å·ç§¯å±‚å’Œè½¬ç½®å·ç§¯å±‚çš„æƒé‡ï¼Œä»è€Œå®ç°æ•°æ®ç‰¹å¾çš„æ— ç›‘ç£å‘ç°ã€‚åœ¨ç¬¬äºŒé˜¶æ®µï¼Œæ¨¡å‹ä½¿ç”¨æ ‡å‡†åå‘ä¼ æ’­å¯¹å°éƒ¨åˆ†æ ‡è®°æ•°æ®è¿›è¡Œå¾®è°ƒã€‚æˆ‘ä»¬é€šè¿‡å®éªŒè¯„ä¼°äº†æˆ‘ä»¬çš„æ–¹æ³•ï¼Œå®éªŒæ˜¯åœ¨å‡ ä¸ªå¹¿æ³›ä½¿ç”¨çš„ç”Ÿç‰©åŒ»å­¦æ•°æ®é›†ä¸Šè¿›è¡Œçš„ï¼Œæˆ‘ä»¬è®¤ä¸ºè¿™ä¸ªé¢†åŸŸåœ¨è®¡ç®—æœºè§†è§‰é¢†åŸŸä¸­è‡³å…³é‡è¦ï¼Œå¹¶ä¸”å—åˆ°æ•°æ®ç¨€ç¼ºçš„æ˜¾è‘—å½±å“ã€‚ç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨æ ‡ç­¾å¯ç”¨æ€§çš„ä¸åŒå±‚æ¬¡ä¸Šéƒ½ä¼˜äºæœ€æ–°æŠ€æœ¯æ–¹æ³•ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜è¡¨æ˜ä½¿ç”¨æˆ‘ä»¬çš„æ— ç›‘ç£é˜¶æ®µæ¥åˆå§‹åŒ–æœ€æ–°æŠ€æœ¯æ–¹æ³•å¯ä»¥æé«˜æ€§èƒ½ã€‚å¤åˆ¶æˆ‘ä»¬å®éªŒçš„ä»£ç å¯ä»¥åœ¨ <a target="_blank" rel="noopener" href="https://github.com/ciampluca/hebbian-bootstraping-semi-supervised-medical-imaging">https://github.com/ciampluca/hebbian-bootstraping-semi-supervised-medical-imaging</a> æ‰¾åˆ°ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.03192v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°å‹çš„ç”Ÿç‰©å¯å‘åŠç›‘ç£å­¦ä¹ æ–¹æ³•ï¼Œç”¨äºè®­ç»ƒä¸‹é‡‡æ ·-ä¸Šé‡‡æ ·è¯­ä¹‰åˆ†å‰²æ¶æ„ã€‚è¯¥æ–¹æ³•åˆ†ä¸ºä¸¤ä¸ªé˜¶æ®µï¼Œç¬¬ä¸€é˜¶æ®µä¸é‡‡ç”¨åå‘ä¼ æ’­ï¼Œè€Œæ˜¯åˆ©ç”¨èµ«å¸ƒåŸç†ï¼ˆä¸€èµ·æ”¾ç”µï¼Œä¸€èµ·è¿æ¥ï¼‰ä½œä¸ºå±€éƒ¨å­¦ä¹ è§„åˆ™æ¥æ›´æ–°å·ç§¯å’Œè½¬ç½®å·ç§¯å±‚çš„æƒé‡ï¼Œå®ç°æ•°æ®ç‰¹å¾çš„æ— ç›‘ç£å‘ç°ã€‚ç¬¬äºŒé˜¶æ®µä½¿ç”¨æ ‡å‡†åå‘ä¼ æ’­å¯¹æ¨¡å‹è¿›è¡Œå¾®è°ƒï¼Œä»…ä½¿ç”¨å°‘é‡æ ‡è®°æ•°æ®è¿›è¡Œè®­ç»ƒã€‚åœ¨å¤šä¸ªå¹¿æ³›ä½¿ç”¨çš„ç”Ÿç‰©åŒ»å­¦æ•°æ®é›†ä¸Šè¿›è¡Œçš„å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨ä¸åŒæ ‡ç­¾å¯ç”¨æ€§çº§åˆ«ä¸Šå‡ä¼˜äºç°æœ‰æŠ€æœ¯ã€‚æ­¤å¤–ï¼Œä½¿ç”¨æˆ‘ä»¬çš„æ— ç›‘ç£é˜¶æ®µåˆå§‹åŒ–ç°æœ‰æŠ€æœ¯è¿˜å¯ä»¥æé«˜æ€§èƒ½ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æå‡ºäº†ä¸€ç§æ–°çš„åŠç›‘ç£å­¦ä¹ æ–¹æ³•ï¼Œç”¨äºè®­ç»ƒè¯­ä¹‰åˆ†å‰²æ¶æ„ã€‚</li>
<li>æ–¹æ³•åˆ†ä¸ºä¸¤ä¸ªé˜¶æ®µï¼šç¬¬ä¸€é˜¶æ®µåˆ©ç”¨èµ«å¸ƒåŸç†è¿›è¡Œæ— ç›‘ç£å­¦ä¹ ï¼Œæ›´æ–°æƒé‡ã€‚</li>
<li>ç¬¬äºŒé˜¶æ®µä½¿ç”¨æ ‡å‡†åå‘ä¼ æ’­è¿›è¡Œå¾®è°ƒï¼Œä½¿ç”¨å°‘é‡æ ‡è®°æ•°æ®ã€‚</li>
<li>å®éªŒåœ¨å¤šä¸ªç”Ÿç‰©åŒ»å­¦æ•°æ®é›†ä¸Šè¿›è¡Œï¼Œæ˜¾ç¤ºæ–¹æ³•åœ¨ä¸åŒæ ‡ç­¾å¯ç”¨æ€§çº§åˆ«ä¸Šä¼˜äºç°æœ‰æŠ€æœ¯ã€‚</li>
<li>è¯¥æ–¹æ³•æœ‰åŠ©äºæé«˜ç°æœ‰æŠ€æœ¯çš„æ€§èƒ½ï¼Œé€šè¿‡æ— ç›‘ç£é˜¶æ®µè¿›è¡Œåˆå§‹åŒ–ã€‚</li>
<li>è¯¥æ–¹æ³•å¯¹äºæ•°æ®ç¨€ç¼ºé¢†åŸŸï¼ˆå¦‚ç”Ÿç‰©åŒ»å­¦å›¾åƒï¼‰ç‰¹åˆ«æœ‰å½±å“ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.03192">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-33892d7ae6a885c9c8a3d5b83905fb3f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-4f10b4932e9fd6d658fd7949a9958b97.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-0961590f89164df6b22d0ab8cf5b68c8.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-6220ccdad717656c44be42e7167a1eb5.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-f15608aad095c3f68039a3af86063684.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="A-Review-of-Human-Object-Interaction-Detection"><a href="#A-Review-of-Human-Object-Interaction-Detection" class="headerlink" title="A Review of Human-Object Interaction Detection"></a>A Review of Human-Object Interaction Detection</h2><p><strong>Authors:Yuxiao Wang, Yu Lei, Li Cui, Weiying Xue, Qi Liu, Zhenao Wei</strong></p>
<p>Human-object interaction (HOI) detection plays a key role in high-level visual understanding, facilitating a deep comprehension of human activities. Specifically, HOI detection aims to locate the humans and objects involved in interactions within images or videos and classify the specific interactions between them. The success of this task is influenced by several key factors, including the accurate localization of human and object instances, as well as the correct classification of object categories and interaction relationships. This paper systematically summarizes and discusses the recent work in image-based HOI detection. First, the mainstream datasets involved in HOI relationship detection are introduced. Furthermore, starting with two-stage methods and end-to-end one-stage detection approaches, this paper comprehensively discusses the current developments in image-based HOI detection, analyzing the strengths and weaknesses of these two methods. Additionally, the advancements of zero-shot learning, weakly supervised learning, and the application of large-scale language models in HOI detection are discussed. Finally, the current challenges in HOI detection are outlined, and potential research directions and future trends are explored. </p>
<blockquote>
<p>äººæœºäº¤äº’ï¼ˆHOIï¼‰æ£€æµ‹åœ¨é«˜å±‚æ¬¡è§†è§‰ç†è§£ä¸­æ‰®æ¼”ç€å…³é”®è§’è‰²ï¼Œæœ‰åŠ©äºæ·±å…¥ç†è§£äººç±»æ´»åŠ¨ã€‚å…·ä½“è€Œè¨€ï¼ŒHOIæ£€æµ‹æ—¨åœ¨å®šä½å›¾åƒæˆ–è§†é¢‘ä¸­æ¶‰åŠäº¤äº’çš„äººç±»å’Œç‰©ä½“ï¼Œå¹¶åˆ†ç±»å®ƒä»¬ä¹‹é—´çš„ç‰¹å®šäº¤äº’ã€‚è¯¥ä»»åŠ¡çš„æˆåŠŸå—åˆ°å‡ ä¸ªå…³é”®å› ç´ çš„å½±å“ï¼ŒåŒ…æ‹¬äººç±»å’Œç‰©ä½“å®ä¾‹çš„å‡†ç¡®å®šä½ï¼Œä»¥åŠç‰©ä½“ç±»åˆ«å’Œäº¤äº’å…³ç³»çš„æ­£ç¡®åˆ†ç±»ã€‚æœ¬æ–‡ç³»ç»Ÿåœ°æ€»ç»“å’Œè®¨è®ºäº†åŸºäºå›¾åƒçš„HOIæ£€æµ‹çš„æœ€æ–°å·¥ä½œã€‚é¦–å…ˆï¼Œä»‹ç»äº†HOIå…³ç³»æ£€æµ‹æ¶‰åŠçš„ä¸»æµæ•°æ®é›†ã€‚æ­¤å¤–ï¼Œæœ¬æ–‡ç»¼åˆè®¨è®ºäº†åŸºäºå›¾åƒçš„HOIæ£€æµ‹çš„å½“å‰å‘å±•ï¼ŒåŒ…æ‹¬ä¸¤é˜¶æ®µæ–¹æ³•å’Œç«¯åˆ°ç«¯çš„ä¸€é˜¶æ®µæ£€æµ‹æ–¹æ¡ˆï¼Œåˆ†æäº†è¿™ä¸¤ç§æ–¹æ³•çš„ä¼˜ç¼ºç‚¹ã€‚å¦å¤–ï¼Œè¿˜è®¨è®ºäº†é›¶æ ·æœ¬å­¦ä¹ ã€å¼±ç›‘ç£å­¦ä¹ ä»¥åŠå¤§è§„æ¨¡è¯­è¨€æ¨¡å‹åœ¨HOIæ£€æµ‹ä¸­çš„åº”ç”¨ã€‚æœ€åï¼Œæ¦‚è¿°äº†HOIæ£€æµ‹å½“å‰çš„æŒ‘æˆ˜ï¼Œå¹¶æ¢è®¨äº†æ½œåœ¨çš„ç ”ç©¶æ–¹å‘å’Œæœªæ¥è¶‹åŠ¿ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2408.10641v3">PDF</a> Accepted by 2024 2nd International Conference on Computer, Vision and   Intelligent Technology (ICCVIT)</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ç»¼è¿°äº†åŸºäºå›¾åƒçš„HOIæ£€æµ‹ï¼ˆäººæœºäº¤äº’æ£€æµ‹ï¼‰çš„æœ€æ–°å·¥ä½œã€‚ä»‹ç»äº†ä¸»æµæ•°æ®é›†ï¼Œå¹¶è¯¦ç»†è®¨è®ºäº†å½“å‰çš„ä¸¤é˜¶æ®µæ–¹æ³•å’Œç«¯åˆ°ç«¯çš„ä¸€é˜¶æ®µæ£€æµ‹æ–¹æ³•çš„è¿›å±•ï¼Œåˆ†æäº†å®ƒä»¬çš„ä¼˜ç¼ºç‚¹ã€‚æ­¤å¤–ï¼Œè¿˜è®¨è®ºäº†é›¶æ ·æœ¬å­¦ä¹ ã€å¼±ç›‘ç£å­¦ä¹ ä»¥åŠå¤§è§„æ¨¡è¯­è¨€æ¨¡å‹åœ¨HOIæ£€æµ‹ä¸­çš„åº”ç”¨ï¼ŒæŒ‡å‡ºäº†å½“å‰æŒ‘æˆ˜å¹¶æ¢è®¨äº†æœªæ¥ç ”ç©¶æ–¹å‘ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>HOIæ£€æµ‹æ˜¯é«˜çº§è§†è§‰ç†è§£ä¸­çš„å…³é”®ä»»åŠ¡ï¼Œæ—¨åœ¨è¯†åˆ«å›¾åƒæˆ–è§†é¢‘ä¸­çš„äººç±»ä¸ç‰©ä½“çš„äº¤äº’ï¼Œå¹¶åˆ†ç±»å®ƒä»¬ä¹‹é—´çš„äº¤äº’ã€‚</li>
<li>ä¸»è¦æ•°æ®é›†ä»‹ç»ã€‚</li>
<li>å½“å‰çš„ä¸¤é˜¶æ®µæ–¹æ³•å’Œä¸€é˜¶æ®µæ£€æµ‹æ–¹æ³•çš„è¿›å±•ï¼Œä»¥åŠå®ƒä»¬çš„ä¼˜ç¼ºç‚¹ã€‚</li>
<li>é›¶æ ·æœ¬å­¦ä¹ ã€å¼±ç›‘ç£å­¦ä¹ åœ¨HOIæ£€æµ‹ä¸­çš„åº”ç”¨ã€‚</li>
<li>å¤§è§„æ¨¡è¯­è¨€æ¨¡å‹åœ¨HOIæ£€æµ‹ä¸­çš„ä½¿ç”¨æ­£åœ¨å¢é•¿ã€‚</li>
<li>HOIæ£€æµ‹å½“å‰é¢ä¸´çš„æŒ‘æˆ˜ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2408.10641">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-9a2d3ac6f0083779454a51cd45ab1b8a.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-521833083ce03915fa9881a48e46f716.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-61bd2816199f5d3c2f217225352df434.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-e56ed6c302e330bb24da1b64f5575e84.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="Semi-Supervised-Semantic-Segmentation-Based-on-Pseudo-Labels-A-Survey"><a href="#Semi-Supervised-Semantic-Segmentation-Based-on-Pseudo-Labels-A-Survey" class="headerlink" title="Semi-Supervised Semantic Segmentation Based on Pseudo-Labels: A Survey"></a>Semi-Supervised Semantic Segmentation Based on Pseudo-Labels: A Survey</h2><p><strong>Authors:Lingyan Ran, Yali Li, Guoqiang Liang, Yanning Zhang</strong></p>
<p>Semantic segmentation is an important and popular research area in computer vision that focuses on classifying pixels in an image based on their semantics. However, supervised deep learning requires large amounts of data to train models and the process of labeling images pixel by pixel is time-consuming and laborious. This review aims to provide a first comprehensive and organized overview of the state-of-the-art research results on pseudo-label methods in the field of semi-supervised semantic segmentation, which we categorize from different perspectives and present specific methods for specific application areas. In addition, we explore the application of pseudo-label technology in medical and remote-sensing image segmentation. Finally, we also propose some feasible future research directions to address the existing challenges. </p>
<blockquote>
<p>è¯­ä¹‰åˆ†å‰²æ˜¯è®¡ç®—æœºè§†è§‰ä¸­ä¸€ä¸ªé‡è¦ä¸”çƒ­é—¨çš„ç ”ç©¶é¢†åŸŸï¼Œä¸»è¦å…³æ³¨åŸºäºå›¾åƒè¯­ä¹‰å¯¹åƒç´ è¿›è¡Œåˆ†ç±»ã€‚ç„¶è€Œï¼Œæ·±åº¦å­¦ä¹ çš„ç›‘ç£å­¦ä¹ éœ€è¦å¤§é‡çš„æ•°æ®æ¥è®­ç»ƒæ¨¡å‹ï¼Œé€ä¸ªåƒç´ åœ°æ ‡æ³¨å›¾åƒæ—¢è€—æ—¶åˆè´¹åŠ›ã€‚è¿™ç¯‡ç»¼è¿°æ—¨åœ¨å…¨é¢ã€ç³»ç»Ÿåœ°ä»‹ç»åŠç›‘ç£è¯­ä¹‰åˆ†å‰²é¢†åŸŸä¼ªæ ‡ç­¾æ–¹æ³•çš„æœ€æ–°ç ”ç©¶æˆæœï¼Œä»ä¸åŒçš„è§’åº¦å¯¹å®ƒä»¬è¿›è¡Œåˆ†ç±»ï¼Œå¹¶é’ˆå¯¹ç‰¹å®šåº”ç”¨é¢†åŸŸä»‹ç»å…·ä½“æ–¹æ³•ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜æ¢è®¨äº†ä¼ªæ ‡ç­¾æŠ€æœ¯åœ¨åŒ»ç–—å’Œé¥æ„Ÿå›¾åƒåˆ†å‰²ä¸­çš„åº”ç”¨ã€‚æœ€åï¼Œæˆ‘ä»¬è¿˜æå‡ºäº†ä¸€äº›å¯è¡Œçš„æœªæ¥ç ”ç©¶æ–¹å‘ï¼Œä»¥åº”å¯¹ç°æœ‰æŒ‘æˆ˜ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2403.01909v3">PDF</a> Accepted by IEEE Transactions on Circuits and Systems for Video   Technology(TCSVT)</p>
<p><strong>Summary</strong><br>è¯­ä¹‰åˆ†å‰²æ˜¯è®¡ç®—æœºè§†è§‰ä¸­ä¸€ä¸ªé‡è¦ä¸”çƒ­é—¨çš„ç ”ç©¶é¢†åŸŸï¼Œä¸»è¦å¯¹å›¾åƒä¸­çš„åƒç´ è¿›è¡Œåˆ†ç±»ã€‚ç„¶è€Œï¼Œç›‘ç£æ·±åº¦å­¦ä¹ éœ€è¦å¤§é‡æ•°æ®è¿›è¡Œæ¨¡å‹è®­ç»ƒï¼Œé€åƒç´ æ ‡æ³¨å›¾åƒçš„è¿‡ç¨‹è€—æ—¶è´¹åŠ›ã€‚æœ¬æ–‡æ—¨åœ¨æä¾›ä¼ªæ ‡ç­¾æ–¹æ³•åœ¨åŠç›‘ç£è¯­ä¹‰åˆ†å‰²é¢†åŸŸçš„æœ€æ–°ç ”ç©¶æˆæœçš„é¦–æ¬¡å…¨é¢æ¦‚è¿°ï¼Œä»ä¸åŒè§’åº¦åˆ†ç±»å¹¶å‘ˆç°ç‰¹å®šåº”ç”¨é¢†åŸŸçš„å…·ä½“æ–¹æ³•ã€‚æ­¤å¤–ï¼Œæœ¬æ–‡è¿˜æ¢è®¨äº†ä¼ªæ ‡ç­¾æŠ€æœ¯åœ¨åŒ»ç–—å’Œé¥æ„Ÿå›¾åƒåˆ†å‰²ä¸­çš„åº”ç”¨ï¼Œå¹¶æå‡ºè§£å†³ç°æœ‰æŒ‘æˆ˜çš„å¯è¡Œçš„æœªæ¥ç ”ç©¶æ–¹å‘ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>è¯­ä¹‰åˆ†å‰²æ˜¯è®¡ç®—æœºè§†è§‰ä¸­çš„é‡è¦ç ”ç©¶é¢†åŸŸï¼Œä¸“æ³¨äºåŸºäºåƒç´ è¯­ä¹‰å¯¹å›¾åƒè¿›è¡Œåˆ†ç±»ã€‚</li>
<li>ç›‘ç£æ·±åº¦å­¦ä¹ éœ€è¦å¤§é‡æ•°æ®è¿›è¡Œæ¨¡å‹è®­ç»ƒï¼Œæ ‡æ³¨è¿‡ç¨‹è€—æ—¶è´¹åŠ›ã€‚</li>
<li>ä¼ªæ ‡ç­¾æ–¹æ³•åœ¨åŠç›‘ç£è¯­ä¹‰åˆ†å‰²é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ã€‚</li>
<li>æœ¬æ–‡æä¾›äº†ä¼ªæ ‡ç­¾æ–¹æ³•çš„å…¨é¢æ¦‚è¿°ï¼ŒåŒ…æ‹¬ä»ä¸åŒè§’åº¦çš„åˆ†ç±»ä»¥åŠç‰¹å®šé¢†åŸŸçš„åº”ç”¨æ–¹æ³•ã€‚</li>
<li>ä¼ªæ ‡ç­¾æŠ€æœ¯åœ¨åŒ»ç–—å’Œé¥æ„Ÿå›¾åƒåˆ†å‰²é¢†åŸŸçš„åº”ç”¨å¾—åˆ°äº†æ¢è®¨ã€‚</li>
<li>å½“å‰å­˜åœ¨æŒ‘æˆ˜å’Œé—®é¢˜éœ€è¦è§£å†³ï¼Œéœ€è¦è¿›ä¸€æ­¥çš„ç ”ç©¶å’Œæ¢ç´¢ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2403.01909">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-e61ae1cc5d887d26086ba20ed50b1d36.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-aad6bbbd8d18cc7d69a2aff258df9a2a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-50c235727093679ffd70b362dce66667.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c80a069b21c7cb3e3e897e7994498a1d.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="Co-Learning-Semantic-aware-Unsupervised-Segmentation-for-Pathological-Image-Registration"><a href="#Co-Learning-Semantic-aware-Unsupervised-Segmentation-for-Pathological-Image-Registration" class="headerlink" title="Co-Learning Semantic-aware Unsupervised Segmentation for Pathological   Image Registration"></a>Co-Learning Semantic-aware Unsupervised Segmentation for Pathological   Image Registration</h2><p><strong>Authors:Yang Liu, Shi Gu</strong></p>
<p>The registration of pathological images plays an important role in medical applications. Despite its significance, most researchers in this field primarily focus on the registration of normal tissue into normal tissue. The negative impact of focal tissue, such as the loss of spatial correspondence information and the abnormal distortion of tissue, are rarely considered. In this paper, we propose GIRNet, a novel unsupervised approach for pathological image registration by incorporating segmentation and inpainting through the principles of Generation, Inpainting, and Registration (GIR). The registration, segmentation, and inpainting modules are trained simultaneously in a co-learning manner so that the segmentation of the focal area and the registration of inpainted pairs can improve collaboratively. Overall, the registration of pathological images is achieved in a completely unsupervised learning framework. Experimental results on multiple datasets, including Magnetic Resonance Imaging (MRI) of T1 sequences, demonstrate the efficacy of our proposed method. Our results show that our method can accurately achieve the registration of pathological images and identify lesions even in challenging imaging modalities. Our unsupervised approach offers a promising solution for the efficient and cost-effective registration of pathological images. Our code is available at <a target="_blank" rel="noopener" href="https://github.com/brain-intelligence-lab/GIRNet">https://github.com/brain-intelligence-lab/GIRNet</a>. </p>
<blockquote>
<p>ç—…ç†å›¾åƒçš„é…å‡†åœ¨åŒ»ç–—åº”ç”¨ä¸­æ‰®æ¼”ç€é‡è¦è§’è‰²ã€‚å°½ç®¡å…¶æ„ä¹‰é‡å¤§ï¼Œä½†è¯¥é¢†åŸŸçš„å¤§å¤šæ•°ç ”ç©¶è€…ä¸»è¦å…³æ³¨æ­£å¸¸ç»„ç»‡çš„é…å‡†åˆ°æ­£å¸¸ç»„ç»‡ã€‚å¾ˆå°‘è€ƒè™‘ç„¦ç‚¹ç»„ç»‡çš„è´Ÿé¢å½±å“ï¼Œå¦‚ç©ºé—´å¯¹åº”å…³ç³»ä¿¡æ¯çš„ä¸¢å¤±å’Œç»„ç»‡å¼‚å¸¸æ‰­æ›²ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†GIRNetï¼Œè¿™æ˜¯ä¸€ç§é€šè¿‡ç»“åˆåˆ†å‰²å’Œä¿®å¤çš„åŸåˆ™ï¼ˆç”Ÿæˆã€ä¿®å¤å’Œé…å‡†ï¼ˆGIRï¼‰ï¼‰ç”¨äºç—…ç†å›¾åƒé…å‡†çš„æ–°å‹æ— ç›‘ç£æ–¹æ³•ã€‚é…å‡†ã€åˆ†å‰²å’Œä¿®å¤æ¨¡å—ä»¥ååŒå­¦ä¹ çš„æ–¹å¼è¿›è¡Œè®­ç»ƒï¼Œä½¿å¾—ç„¦ç‚¹åŒºåŸŸçš„åˆ†å‰²å’Œä¿®å¤å¯¹çš„é…å‡†å¯ä»¥ååŒæ”¹è¿›ã€‚æ€»ä½“è€Œè¨€ï¼Œç—…ç†å›¾åƒçš„é…å‡†æ˜¯åœ¨ä¸€ä¸ªå®Œå…¨æ— ç›‘ç£çš„å­¦ä¹ æ¡†æ¶ä¸­å®ç°çš„ã€‚åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šçš„å®éªŒç»“æœï¼ŒåŒ…æ‹¬T1åºåˆ—çš„ç£å…±æŒ¯æˆåƒï¼ˆMRIï¼‰ï¼Œè¯æ˜äº†æˆ‘ä»¬æå‡ºçš„æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚æˆ‘ä»¬çš„ç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•å¯ä»¥å‡†ç¡®åœ°å®ç°ç—…ç†å›¾åƒçš„é…å‡†ï¼Œå³ä½¿åœ¨å…·æœ‰æŒ‘æˆ˜æ€§çš„æˆåƒæ¨¡å¼ä¸‹ä¹Ÿèƒ½è¯†åˆ«ç—…å˜ã€‚æˆ‘ä»¬çš„æ— ç›‘ç£æ–¹æ³•ä¸ºç—…ç†å›¾åƒçš„æœ‰æ•ˆå’Œç»æµçš„é…å‡†æä¾›äº†æœ‰å‰æ™¯çš„è§£å†³æ–¹æ¡ˆã€‚æˆ‘ä»¬çš„ä»£ç å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/brain-intelligence-lab/GIRNet%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/brain-intelligence-lab/GIRNetæ‰¾åˆ°ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.11040v3">PDF</a> 13 pages, 7 figures, published in Medical Image Computing and   Computer Assisted Intervention (MICCAI) 2023</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºä¸€ç§åŸºäºç”Ÿæˆã€ä¿®å¤å’Œæ³¨å†Œï¼ˆGIRï¼‰åŸåˆ™çš„æ–°å‹æ— ç›‘ç£ç—…ç†å›¾åƒæ³¨å†Œæ–¹æ³•GIRNetã€‚è¯¥æ–¹æ³•é€šè¿‡åŒæ—¶è®­ç»ƒæ³¨å†Œã€åˆ†å‰²å’Œä¿®å¤æ¨¡å—ï¼Œå®ç°äº†å¯¹ç—…å˜åŒºåŸŸçš„åˆ†å‰²å’Œå¯¹ä¿®å¤åå›¾åƒçš„æ³¨å†Œï¼Œæé«˜äº†ä¸¤è€…çš„ååŒæ€§èƒ½ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šå¯æœ‰æ•ˆå®ç°ç—…ç†å›¾åƒçš„æ³¨å†Œå’Œç—…å˜è¯†åˆ«ï¼Œä¸ºé«˜æ•ˆã€ç»æµçš„ç—…ç†å›¾åƒæ³¨å†Œæä¾›äº†æœ‰å‰é€”çš„è§£å†³æ–¹æ¡ˆã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ç—…ç†å›¾åƒæ³¨å†Œåœ¨åŒ»ç–—åº”ç”¨ä¸­å…·æœ‰é‡è¦æ„ä¹‰ï¼Œä½†ç°æœ‰ç ”ç©¶å¤§å¤šå±€é™äºæ­£å¸¸ç»„ç»‡çš„æ³¨å†Œã€‚</li>
<li>æ–‡ç« æå‡ºäº†ä¸€ä¸ªåä¸ºGIRNetçš„æ–°å‹æ— ç›‘ç£æ–¹æ³•ç”¨äºç—…ç†å›¾åƒæ³¨å†Œã€‚</li>
<li>GIRNetç»“åˆäº†åˆ†å‰²å’Œä¿®å¤æŠ€æœ¯ï¼Œé€šè¿‡ç”Ÿæˆã€ä¿®å¤å’Œæ³¨å†Œçš„åŸåˆ™å®ç°ç—…ç†å›¾åƒçš„ç²¾å‡†æ³¨å†Œã€‚</li>
<li>è¯¥æ–¹æ³•èƒ½å¤Ÿåœ¨æ— ç›‘ç£å­¦ä¹ æ¡†æ¶å†…å®ç°å¯¹ç—…å˜åŒºåŸŸçš„åˆ†å‰²ä»¥åŠå¯¹ä¿®å¤åå›¾åƒçš„æ³¨å†ŒååŒè¿›æ­¥ã€‚</li>
<li>å®éªŒç»“æœæ˜¾ç¤ºGIRNetåœ¨å¤šä¸ªæ•°æ®é›†ä¸Šçš„è¡¨ç°è‰¯å¥½ï¼Œèƒ½æœ‰æ•ˆå®ç°ç—…ç†å›¾åƒçš„æ³¨å†Œå¹¶è¯†åˆ«ç—…å˜ã€‚</li>
<li>æ‰€æå‡ºçš„ä»£ç åœ¨GitHubä¸Šå¼€æ”¾ä¾›ç ”ç©¶ä½¿ç”¨ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2310.11040">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-d0b752b2690a964f4ff37d51c64f21fb.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-19c4512bf5070012829b402135127eb8.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-7a2becdd260ae923525ea4e9ed4ba656.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-03-20/%E6%A3%80%E6%B5%8B_%E5%88%86%E5%89%B2_%E8%B7%9F%E8%B8%AA/">https://kedreamix.github.io/Talk2Paper/Paper/2025-03-20/%E6%A3%80%E6%B5%8B_%E5%88%86%E5%89%B2_%E8%B7%9F%E8%B8%AA/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/%E6%A3%80%E6%B5%8B-%E5%88%86%E5%89%B2-%E8%B7%9F%E8%B8%AA/">
                                    <span class="chip bg-color">æ£€æµ‹/åˆ†å‰²/è·Ÿè¸ª</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-03-20/%E4%BA%BA%E8%84%B8%E7%9B%B8%E5%85%B3/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-11e7e797ea8fd5c561d87275120b3d33.jpg" class="responsive-img" alt="äººè„¸ç›¸å…³">
                        
                        <span class="card-title">äººè„¸ç›¸å…³</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            äººè„¸ç›¸å…³ æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-03-20  Exploring Disparity-Accuracy Trade-offs in Face Recognition Systems The   Role of Datasets, Architectures, and Loss Functions
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-03-20
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/%E4%BA%BA%E8%84%B8%E7%9B%B8%E5%85%B3/" class="post-category">
                                    äººè„¸ç›¸å…³
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/%E4%BA%BA%E8%84%B8%E7%9B%B8%E5%85%B3/">
                        <span class="chip bg-color">äººè„¸ç›¸å…³</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-03-20/Vision%20Transformer/">
                    <div class="card-image">
                        
                        <img src="https://pic1.zhimg.com/v2-e2e4ba0692f50c329b5560452c3ae0f8.jpg" class="responsive-img" alt="Vision Transformer">
                        
                        <span class="card-title">Vision Transformer</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Vision Transformer æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-03-20  Towards Scalable Foundation Model for Multi-modal and Hyperspectral   Geospatial Data
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-03-20
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Vision-Transformer/" class="post-category">
                                    Vision Transformer
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Vision-Transformer/">
                        <span class="chip bg-color">Vision Transformer</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">17259.4k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
