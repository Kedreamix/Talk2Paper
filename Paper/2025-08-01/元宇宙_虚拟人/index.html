<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="å…ƒå®‡å®™/è™šæ‹Ÿäºº">
    <meta name="description" content="å…ƒå®‡å®™/è™šæ‹Ÿäºº æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-08-02  MoGA 3D Generative Avatar Prior for Monocular Gaussian Avatar   Reconstruction">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>å…ƒå®‡å®™/è™šæ‹Ÿäºº | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://pic1.zhimg.com/v2-ffab9676fc57bdedb660e09e9f610722.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">å…ƒå®‡å®™/è™šæ‹Ÿäºº</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/%E5%85%83%E5%AE%87%E5%AE%99-%E8%99%9A%E6%8B%9F%E4%BA%BA/">
                                <span class="chip bg-color">å…ƒå®‡å®™/è™šæ‹Ÿäºº</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/%E5%85%83%E5%AE%87%E5%AE%99-%E8%99%9A%E6%8B%9F%E4%BA%BA/" class="post-category">
                                å…ƒå®‡å®™/è™šæ‹Ÿäºº
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-08-02
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-08-20
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    11.6k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    47 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-08-02-æ›´æ–°"><a href="#2025-08-02-æ›´æ–°" class="headerlink" title="2025-08-02 æ›´æ–°"></a>2025-08-02 æ›´æ–°</h1><h2 id="MoGA-3D-Generative-Avatar-Prior-for-Monocular-Gaussian-Avatar-Reconstruction"><a href="#MoGA-3D-Generative-Avatar-Prior-for-Monocular-Gaussian-Avatar-Reconstruction" class="headerlink" title="MoGA: 3D Generative Avatar Prior for Monocular Gaussian Avatar   Reconstruction"></a>MoGA: 3D Generative Avatar Prior for Monocular Gaussian Avatar   Reconstruction</h2><p><strong>Authors:Zijian Dong, Longteng Duan, Jie Song, Michael J. Black, Andreas Geiger</strong></p>
<p>We present MoGA, a novel method to reconstruct high-fidelity 3D Gaussian avatars from a single-view image. The main challenge lies in inferring unseen appearance and geometric details while ensuring 3D consistency and realism. Most previous methods rely on 2D diffusion models to synthesize unseen views; however, these generated views are sparse and inconsistent, resulting in unrealistic 3D artifacts and blurred appearance. To address these limitations, we leverage a generative avatar model, that can generate diverse 3D avatars by sampling deformed Gaussians from a learned prior distribution. Due to the limited amount of 3D training data such a 3D model alone cannot capture all image details of unseen identities. Consequently, we integrate it as a prior, ensuring 3D consistency by projecting input images into its latent space and enforcing additional 3D appearance and geometric constraints. Our novel approach formulates Gaussian avatar creation as a model inversion process by fitting the generative avatar to synthetic views from 2D diffusion models. The generative avatar provides a meaningful initialization for model fitting, enforces 3D regularization, and helps in refining pose estimation. Experiments show that our method surpasses state-of-the-art techniques and generalizes well to real-world scenarios. Our Gaussian avatars are also inherently animatable </p>
<blockquote>
<p>æˆ‘ä»¬æå‡ºäº†ä¸€ç§åä¸ºMoGAçš„æ–°å‹æ–¹æ³•ï¼Œå¯ä»¥ä»å•è§†å›¾å›¾åƒé‡å»ºé«˜ä¿çœŸ3Dé«˜æ–¯åŒ–èº«ã€‚ä¸»è¦æŒ‘æˆ˜åœ¨äºæ¨æ–­å‡ºçœ‹ä¸è§çš„å¤–è§‚å’Œå‡ ä½•ç»†èŠ‚ï¼ŒåŒæ—¶ç¡®ä¿3Dçš„ä¸€è‡´æ€§å’ŒçœŸå®æ€§ã€‚å¤§å¤šæ•°ä¹‹å‰çš„æ–¹æ³•ä¾èµ–äº2Dæ‰©æ•£æ¨¡å‹æ¥åˆæˆæœªè§çš„è§†å›¾ï¼›ç„¶è€Œï¼Œè¿™äº›ç”Ÿæˆçš„è§†å›¾æ˜¯ç¨€ç–ä¸”ä¸ä¸€è‡´çš„ï¼Œå¯¼è‡´3Då‡ºç°ä¸çœŸå®çš„ä¼ªå½±å’Œæ¨¡ç³Šçš„å¤–è§‚ã€‚ä¸ºäº†è§£å†³è¿™äº›å±€é™æ€§ï¼Œæˆ‘ä»¬åˆ©ç”¨ç”ŸæˆåŒ–èº«æ¨¡å‹ï¼Œé€šè¿‡ä»å­¦ä¹ çš„å…ˆéªŒåˆ†å¸ƒä¸­é‡‡æ ·å˜å½¢çš„é«˜æ–¯å‡½æ•°ï¼Œå¯ä»¥ç”Ÿæˆå¤šæ ·åŒ–çš„3DåŒ–èº«ã€‚ç”±äº3Dè®­ç»ƒæ•°æ®é‡æœ‰é™ï¼Œå•ä¸€çš„3Dæ¨¡å‹æ— æ³•æ•è·æœªè§èº«ä»½çš„æ‰€æœ‰å›¾åƒç»†èŠ‚ã€‚å› æ­¤ï¼Œæˆ‘ä»¬å°†å…¶æ•´åˆä¸ºä¼˜å…ˆçº§ï¼Œé€šè¿‡å°†è¾“å…¥å›¾åƒæŠ•å½±åˆ°å…¶æ½œåœ¨ç©ºé—´å¹¶æ–½åŠ é¢å¤–çš„3Då¤–è§‚å’Œå‡ ä½•çº¦æŸï¼Œç¡®ä¿3Dçš„ä¸€è‡´æ€§ã€‚æˆ‘ä»¬çš„æ–°æ–¹æ³•å°†é«˜æ–¯åŒ–èº«çš„åˆ›å»ºåˆ¶å®šä¸ºä¸€ä¸ªæ¨¡å‹åè½¬è¿‡ç¨‹ï¼Œé€šè¿‡å°†ç”Ÿæˆçš„åŒ–èº«é€‚åº”äºæ¥è‡ª2Dæ‰©æ•£æ¨¡å‹çš„åˆæˆè§†å›¾ã€‚ç”Ÿæˆçš„åŒ–èº«ä¸ºæ¨¡å‹æ‹Ÿåˆæä¾›äº†æœ‰æ„ä¹‰çš„åˆå§‹åŒ–ï¼Œå®æ–½äº†3Dæ­£åˆ™åŒ–ï¼Œå¹¶æœ‰åŠ©äºæ”¹è¿›å§¿æ€ä¼°è®¡ã€‚å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•è¶…è¶Šäº†æœ€å…ˆè¿›çš„æŠ€æœ¯å¹¶åœ¨çœŸå®åœºæ™¯ä¸­å…·æœ‰å¾ˆå¥½çš„é€šç”¨æ€§ã€‚æˆ‘ä»¬çš„é«˜æ–¯åŒ–èº«æœ¬è´¨ä¸Šæ˜¯å¯åŠ¨ç”»çš„ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2507.23597v1">PDF</a> ICCV 2025 (Highlight), Project Page: <a target="_blank" rel="noopener" href="https://zj-dong.github.io/MoGA/">https://zj-dong.github.io/MoGA/</a></p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†MoGAæ–¹æ³•ï¼Œè¿™æ˜¯ä¸€ç§ä»å•è§†è§’å›¾åƒé‡å»ºé«˜ä¿çœŸ3Dé«˜æ–¯è™šæ‹Ÿå½¢è±¡çš„æ–°æŠ€æœ¯ã€‚è¯¥æ–¹æ³•ä¸»è¦æŒ‘æˆ˜åœ¨äºæ¨æ–­æœªè§çš„å¤–è§‚å’Œå‡ ä½•ç»†èŠ‚ï¼ŒåŒæ—¶ç¡®ä¿3Dä¸€è‡´æ€§å’ŒçœŸå®æ€§ã€‚é’ˆå¯¹ç°æœ‰æ–¹æ³•çš„ä¸è¶³ï¼Œè¯¥ç ”ç©¶é‡‡ç”¨ç”Ÿæˆå¼è™šæ‹Ÿå½¢è±¡æ¨¡å‹ï¼Œé€šè¿‡ä»å­¦ä¹ åˆ°çš„å…ˆéªŒåˆ†å¸ƒä¸­é‡‡æ ·å˜å½¢é«˜æ–¯æ¥ç”Ÿæˆå¤šæ ·åŒ–çš„3Dè™šæ‹Ÿå½¢è±¡ã€‚åŒæ—¶ï¼Œç»“åˆè¾“å…¥å›¾åƒçš„æŠ•å½±å’Œé¢å¤–çš„3Då¤–è§‚åŠå‡ ä½•çº¦æŸï¼Œç¡®ä¿3Dä¸€è‡´æ€§ã€‚è¯¥ç ”ç©¶å°†é«˜æ–¯è™šæ‹Ÿå½¢è±¡åˆ›å»ºåˆ¶å®šä¸ºæ¨¡å‹åæ¼”è¿‡ç¨‹ï¼Œé€šè¿‡å°†ç”Ÿæˆå¼è™šæ‹Ÿå½¢è±¡ä¸æ¥è‡ªäºŒç»´æ‰©æ•£æ¨¡å‹çš„åˆæˆè§†å›¾ç›¸åŒ¹é…æ¥å®ç°ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>MoGAæ˜¯ä¸€ç§ä»å•è§†è§’å›¾åƒé‡å»ºé«˜ä¿çœŸ3Dé«˜æ–¯è™šæ‹Ÿå½¢è±¡çš„æ–¹æ³•ã€‚</li>
<li>è¯¥æ–¹æ³•ä¸»è¦æŒ‘æˆ˜åœ¨äºæ¨æ–­æœªè§çš„å¤–è§‚å’Œå‡ ä½•ç»†èŠ‚ï¼Œå¹¶ç¡®ä¿3Dä¸€è‡´æ€§å’ŒçœŸå®æ€§ã€‚</li>
<li>ç°æœ‰æ–¹æ³•ä¸»è¦ä¾èµ–2Dæ‰©æ•£æ¨¡å‹åˆæˆæœªè§è§†å›¾ï¼Œä½†ç”Ÿæˆçš„è§†å›¾ç¨€ç–ä¸”ä¸ä¸€è‡´ï¼Œå¯¼è‡´3Dä¼ªå½±å’Œæ¨¡ç³Šå¤–è§‚ã€‚</li>
<li>ç ”ç©¶é‡‡ç”¨ç”Ÿæˆå¼è™šæ‹Ÿå½¢è±¡æ¨¡å‹ï¼Œé€šè¿‡é‡‡æ ·å˜å½¢é«˜æ–¯æ¥ç”Ÿæˆå¤šæ ·åŒ–çš„3Dè™šæ‹Ÿå½¢è±¡ã€‚</li>
<li>ç»“åˆè¾“å…¥å›¾åƒçš„æŠ•å½±å’Œé¢å¤–çš„3DåŠå‡ ä½•çº¦æŸï¼Œç¡®ä¿3Dä¸€è‡´æ€§ã€‚</li>
<li>é«˜æ–¯è™šæ‹Ÿå½¢è±¡åˆ›å»ºè¢«åˆ¶å®šä¸ºä¸€ä¸ªæ¨¡å‹åæ¼”è¿‡ç¨‹ï¼Œé€šè¿‡åŒ¹é…ç”Ÿæˆå¼è™šæ‹Ÿå½¢è±¡å’Œæ¥è‡ªäºŒç»´æ‰©æ•£æ¨¡å‹çš„åˆæˆè§†å›¾æ¥å®ç°ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2507.23597">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-36299fa1d2de31244961425d9c2f9e03.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-92c4cfb63cc8def479f57a52e048adf5.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-4030795a97d1504b3de20f5c85aeca83.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="Real-time-Generation-of-Various-Types-of-Nodding-for-Avatar-Attentive-Listening-System"><a href="#Real-time-Generation-of-Various-Types-of-Nodding-for-Avatar-Attentive-Listening-System" class="headerlink" title="Real-time Generation of Various Types of Nodding for Avatar Attentive   Listening System"></a>Real-time Generation of Various Types of Nodding for Avatar Attentive   Listening System</h2><p><strong>Authors:Kazushi Kato, Koji Inoue, Divesh Lala, Keiko Ochi, Tatsuya Kawahara</strong></p>
<p>In human dialogue, nonverbal information such as nodding and facial expressions is as crucial as verbal information, and spoken dialogue systems are also expected to express such nonverbal behaviors. We focus on nodding, which is critical in an attentive listening system, and propose a model that predicts both its timing and type in real time. The proposed model builds on the voice activity projection (VAP) model, which predicts voice activity from both listener and speaker audio. We extend it to prediction of various types of nodding in a continuous and real-time manner unlike conventional models. In addition, the proposed model incorporates multi-task learning with verbal backchannel prediction and pretraining on general dialogue data. In the timing and type prediction task, the effectiveness of multi-task learning was significantly demonstrated. We confirmed that reducing the processing rate enables real-time operation without a substantial drop in accuracy, and integrated the model into an avatar attentive listening system. Subjective evaluations showed that it outperformed the conventional method, which always does nodding in sync with verbal backchannel. The code and trained models are available at <a target="_blank" rel="noopener" href="https://github.com/MaAI-Kyoto/MaAI">https://github.com/MaAI-Kyoto/MaAI</a>. </p>
<blockquote>
<p>åœ¨äººç±»çš„å¯¹è¯ä¸­ï¼Œéè¨€è¯­ä¿¡æ¯å¦‚ç‚¹å¤´å’Œé¢éƒ¨è¡¨æƒ…ä¸è¨€è¯­ä¿¡æ¯ä¸€æ ·é‡è¦ï¼Œäººä»¬ä¹ŸæœŸæœ›å¯¹è¯ç³»ç»Ÿèƒ½å¤Ÿè¡¨è¾¾è¿™æ ·çš„éè¨€è¯­è¡Œä¸ºã€‚æˆ‘ä»¬ä¸“æ³¨äºç‚¹å¤´ï¼Œè¿™åœ¨å€¾å¬ç³»ç»Ÿä¸­è‡³å…³é‡è¦ï¼Œå¹¶æå‡ºä¸€ä¸ªæ¨¡å‹ï¼Œè¯¥æ¨¡å‹å¯ä»¥å®æ—¶é¢„æµ‹ç‚¹å¤´çš„æ—¶æœºå’Œç±»å‹ã€‚æ‰€æå‡ºçš„æ¨¡å‹åŸºäºè¯­éŸ³æ´»åŠ¨æŠ•å½±ï¼ˆVAPï¼‰æ¨¡å‹ï¼Œè¯¥æ¨¡å‹å¯ä»¥ä»å¬ä¼—å’Œè¯´è¯è€…çš„éŸ³é¢‘ä¸­é¢„æµ‹è¯­éŸ³æ´»åŠ¨ã€‚æˆ‘ä»¬å°†å…¶æ‰©å±•åˆ°è¿ç»­å®æ—¶é¢„æµ‹å„ç§ç‚¹å¤´æ–¹å¼ï¼Œä¸åŒäºä¼ ç»Ÿæ¨¡å‹ã€‚æ­¤å¤–ï¼Œæ‰€æå‡ºçš„æ¨¡å‹ç»“åˆäº†å¤šä»»åŠ¡å­¦ä¹ ä¸è¨€è¯­åé¦ˆé¢„æµ‹ï¼Œå¹¶åœ¨ä¸€èˆ¬å¯¹è¯æ•°æ®ä¸Šè¿›è¡Œé¢„è®­ç»ƒã€‚åœ¨é¢„æµ‹æ—¶é—´å’Œç±»å‹ä»»åŠ¡ä¸­ï¼Œå¤šä»»åŠ¡å­¦ä¹ çš„æœ‰æ•ˆæ€§å¾—åˆ°äº†æ˜¾è‘—è¯æ˜ã€‚æˆ‘ä»¬ç¡®è®¤é™ä½å¤„ç†é€Ÿç‡å¯ä»¥åœ¨ä¸æ˜¾è‘—é™ä½å‡†ç¡®ç‡çš„æƒ…å†µä¸‹å®ç°å®æ—¶æ“ä½œï¼Œå¹¶å°†è¯¥æ¨¡å‹é›†æˆåˆ°è™šæ‹Ÿè§’è‰²å€¾å¬ç³»ç»Ÿä¸­ã€‚ä¸»è§‚è¯„ä¼°è¡¨æ˜ï¼Œå®ƒä¼˜äºä¼ ç»Ÿæ–¹æ³•ï¼Œåè€…æ€»æ˜¯ä¸è¨€è¯­åé¦ˆåŒæ­¥ç‚¹å¤´ã€‚ç›¸å…³ä»£ç å’Œè®­ç»ƒå¥½çš„æ¨¡å‹å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/MaAI-Kyoto/MaAI%E4%B8%8A%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/MaAI-Kyoto/MaAIä¸Šæ‰¾åˆ°ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2507.23298v1">PDF</a> Accepted by 27th ACM International Conference on Multimodal   Interaction (ICMI â€˜25), Long paper</p>
<p><strong>Summary</strong><br>     è¯¥ç ”ç©¶å…³æ³¨äººç±»å¯¹è¯ä¸­çš„ç‚¹å¤´è¡Œä¸ºï¼Œè¿™æ˜¯ä¸€ç§é‡è¦çš„éè¨€è¯­ä¿¡æ¯ã€‚ç ”ç©¶å›¢é˜Ÿæå‡ºäº†ä¸€ç§æ¨¡å‹ï¼Œèƒ½å¤Ÿå®æ—¶é¢„æµ‹ç‚¹å¤´çš„æ—¶æœºå’Œç±»å‹ã€‚è¯¥æ¨¡å‹åŸºäºè¯­éŸ³æ´»åŠ¨é¢„æµ‹æ¨¡å‹ï¼Œå¹¶è¿›è¡Œäº†æ‰©å±•ï¼Œä»¥è¿ç»­å®æ—¶çš„æ–¹å¼é¢„æµ‹å„ç§ç‚¹å¤´è¡Œä¸ºã€‚æ­¤å¤–ï¼Œè¯¥æ¨¡å‹è¿˜ç»“åˆäº†è¯­è¨€å›é¦ˆé¢„æµ‹å¤šä»»åŠ¡å­¦ä¹ å’Œä¸€èˆ¬å¯¹è¯æ•°æ®çš„é¢„è®­ç»ƒã€‚å®éªŒè¯æ˜ï¼Œå¤šä»»åŠ¡å­¦ä¹ åœ¨é¢„æµ‹ç‚¹å¤´æ—¶æœºå’Œç±»å‹æ–¹é¢æ•ˆæœæ˜¾è‘—ã€‚è¯¥æ¨¡å‹è¢«é›†æˆåˆ°ä¸€ä¸ªè™šæ‹Ÿäººèº«çš„å€¾å¬ç³»ç»Ÿä¸­ï¼Œä¸»è§‚è¯„ä¼°è¡¨æ˜ï¼Œä¸ä¼ ç»Ÿçš„æ€»æ˜¯ä¸è¯­è¨€å›é¦ˆåŒæ­¥ç‚¹å¤´çš„æ–¹æ³•ç›¸æ¯”ï¼Œè¯¥æ¨¡å‹è¡¨ç°æ›´ä½³ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ç ”ç©¶é‡è§†éè¨€è¯­ä¿¡æ¯ï¼Œç‰¹åˆ«æ˜¯ç‚¹å¤´è¡Œä¸ºåœ¨å¯¹è¯ä¸­çš„é‡è¦æ€§ã€‚</li>
<li>æå‡ºä¸€ç§æ¨¡å‹ï¼Œèƒ½å®æ—¶é¢„æµ‹ç‚¹å¤´çš„æ—¶æœºå’Œç±»å‹ã€‚</li>
<li>æ¨¡å‹åŸºäºè¯­éŸ³æ´»åŠ¨é¢„æµ‹æ¨¡å‹è¿›è¡Œæ‰©å±•ï¼Œä»¥è¿ç»­å®æ—¶çš„æ–¹å¼é¢„æµ‹å„ç§ç‚¹å¤´è¡Œä¸ºã€‚</li>
<li>æ¨¡å‹é‡‡ç”¨å¤šä»»åŠ¡å­¦ä¹ ï¼Œç»“åˆè¯­è¨€å›é¦ˆé¢„æµ‹ï¼Œå¹¶åœ¨ä¸€èˆ¬å¯¹è¯æ•°æ®ä¸Šè¿›è¡Œé¢„è®­ç»ƒã€‚</li>
<li>å¤šä»»åŠ¡å­¦ä¹ åœ¨é¢„æµ‹ç‚¹å¤´æ—¶æœºå’Œç±»å‹ä¸Šæ•ˆæœæ˜¾è‘—ã€‚</li>
<li>æ¨¡å‹è¢«æˆåŠŸé›†æˆåˆ°è™šæ‹Ÿäººèº«çš„å€¾å¬ç³»ç»Ÿä¸­ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2507.23298">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-458752ced0bc4d07c912c3a9e5e9dfa6.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-342afd05c6526d5d2eb6ff7d8500949a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-07a33c83dd5f46758771e1bebf3e417d.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-823ccf16ce1a587fe983b141c93f6b52.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-6e584b2bb129f0073f4510f1d54b42df.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-ba079bca0e9185f43e89b465bc1af867.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-f162a317e8191aa34ce82ec687608c01.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-b44c4576c0a10df7e3ebe7da894ceebd.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="Towards-Privacy-preserving-Photorealistic-Self-avatars-in-Mixed-Reality"><a href="#Towards-Privacy-preserving-Photorealistic-Self-avatars-in-Mixed-Reality" class="headerlink" title="Towards Privacy-preserving Photorealistic Self-avatars in Mixed Reality"></a>Towards Privacy-preserving Photorealistic Self-avatars in Mixed Reality</h2><p><strong>Authors:Ethan Wilson, Vincent Bindschaedler, Sophie JÃ¶rg, Sean Sheikholeslam, Kevin Butler, Eakta Jain</strong></p>
<p>Photorealistic 3D avatar generation has rapidly improved in recent years, and realistic avatars that match a userâ€™s true appearance are more feasible in Mixed Reality (MR) than ever before. Yet, there are known risks to sharing oneâ€™s likeness online, and photorealistic MR avatars could exacerbate these risks. If user likenesses were to be shared broadly, there are risks for cyber abuse or targeted fraud based on user appearances. We propose an alternate avatar rendering scheme for broader social MR â€“ synthesizing realistic avatars that preserve a userâ€™s demographic identity while being distinct enough from the individual user to protect facial biometric information. We introduce a methodology for privatizing appearance by isolating identity within the feature space of identity-encoding generative models. We develop two algorithms that then obfuscate identity: \epsmethod{} provides differential privacy guarantees and \thetamethod{} provides fine-grained control for the level of identity offset. These methods are shown to successfully generate de-identified virtual avatars across multiple generative architectures in 2D and 3D. With these techniques, it is possible to protect user privacy while largely preserving attributes related to sense of self. Employing these techniques in public settings could enable the use of photorealistic avatars broadly in MR, maintaining high realism and immersion without privacy risk. </p>
<blockquote>
<p>è¿‘å¹´æ¥ï¼Œé€¼çœŸçš„ä¸‰ç»´åŒ–èº«ç”ŸæˆæŠ€æœ¯å·²å¾—åˆ°è¿…é€Ÿæ”¹è¿›ï¼Œåœ¨æ··åˆç°å®ï¼ˆMRï¼‰ä¸­åŒ¹é…ç”¨æˆ·çœŸå®å¤–è²Œçš„é€¼çœŸåŒ–èº«æ¯”ä»¥å¾€ä»»ä½•æ—¶å€™éƒ½æ›´åŠ å¯è¡Œã€‚ç„¶è€Œï¼Œåœ¨çº¿ä¸Šåˆ†äº«è‡ªå·±çš„è‚–åƒå­˜åœ¨å·²çŸ¥é£é™©ï¼Œè€Œé€¼çœŸçš„MRåŒ–èº«å¯èƒ½ä¼šåŠ å‰§è¿™äº›é£é™©ã€‚å¦‚æœç”¨æˆ·çš„è‚–åƒè¢«å¹¿æ³›åˆ†äº«ï¼Œé‚£ä¹ˆæ ¹æ®ç”¨æˆ·çš„å¤–è²Œç‰¹å¾è¿›è¡Œç½‘ç»œæ¬ºå‡Œæˆ–é’ˆå¯¹æ€§æ¬ºè¯ˆçš„é£é™©å°±ä¼šå¢åŠ ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§ç”¨äºæ›´å¹¿æ³›çš„ç¤¾ä¼šMRçš„æ›¿ä»£åŒ–èº«æ¸²æŸ“æ–¹æ¡ˆâ€”â€”åˆæˆé€¼çœŸçš„åŒ–èº«ï¼Œä¿ç•™ç”¨æˆ·çš„èº«ä»½ç‰¹å¾ä¿¡æ¯ï¼ŒåŒæ—¶è¶³å¤Ÿä¸ªæ€§åŒ–åœ°ä¿æŠ¤é¢éƒ¨ç”Ÿç‰©è¯†åˆ«ä¿¡æ¯ã€‚æˆ‘ä»¬ä»‹ç»äº†ä¸€ç§é€šè¿‡èº«ä»½ç¼–ç ç”Ÿæˆæ¨¡å‹çš„ç‰¹æ€§ç©ºé—´æ¥éš”ç¦»èº«ä»½ä»è€Œä¿æŠ¤å¤–è²Œéšç§çš„æ–¹æ³•è®ºã€‚æˆ‘ä»¬å¼€å‘äº†ä¸¤ä¸ªæ¨¡ç³Šèº«ä»½ç‰¹å¾çš„ç®—æ³•ï¼š\epsmethod{}æä¾›å·®åˆ†éšç§ä¿è¯ï¼Œè€Œ\thetamethod{}æä¾›ç²¾ç»†çš„èº«ä»½åç§»æ§åˆ¶çº§åˆ«ã€‚è¿™äº›æ–¹æ³•æˆåŠŸåœ°åœ¨äºŒç»´å’Œä¸‰ç»´çš„å¤šä¸ªç”Ÿæˆæ¶æ„ä¸­ç”Ÿæˆäº†åŒ¿åè™šæ‹ŸåŒ–èº«ã€‚é€šè¿‡è¿™äº›æŠ€æœ¯ï¼Œå¯ä»¥åœ¨ä¿æŠ¤ç”¨æˆ·éšç§çš„åŒæ—¶ï¼Œä¿ç•™ä¸è‡ªæˆ‘æ„è¯†ç›¸å…³çš„å±æ€§ã€‚åœ¨å…¬å…±åœºæ‰€é‡‡ç”¨è¿™äº›æŠ€æœ¯ï¼Œå¯ä»¥åœ¨ä¿æŒé«˜åº¦ç°å®æ„Ÿå’Œæ²‰æµ¸æ„Ÿçš„åŒæ—¶ï¼Œå®ç°MRä¸­é€¼çœŸåŒ–èº«çš„å¹¿æ³›åº”ç”¨ï¼Œè€Œä¸å­˜åœ¨éšç§é£é™©ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2507.22153v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>è¿‘æœŸ3Då¤´åƒç”ŸæˆæŠ€æœ¯è¿…é€Ÿå‘å±•ï¼Œä½¿å¾—åœ¨æ··åˆç°å®ï¼ˆMRï¼‰ä¸­åˆ›å»ºä¸ç”¨æˆ·çœŸå®å¤–è²Œç›¸åŒ¹é…çš„é€¼çœŸå¤´åƒå˜å¾—æ›´ä¸ºå¯è¡Œã€‚ç„¶è€Œï¼Œåˆ†äº«ä¸ªäººè‚–åƒå­˜åœ¨é£é™©ï¼Œè€Œé€¼çœŸçš„MRå¤´åƒå¯èƒ½åŠ å‰§è¿™äº›é£é™©ã€‚è‹¥ç”¨æˆ·è‚–åƒè¢«å¹¿æ³›åˆ†äº«ï¼Œå¯èƒ½ä¼šé­å—ç½‘ç»œæ¬ºå‡Œæˆ–é’ˆå¯¹ä¸ªäººå¤–è²Œçš„æ¬ºè¯ˆã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ›¿ä»£çš„å¤´åƒæ¸²æŸ“æ–¹æ¡ˆâ€”â€”åˆæˆé€¼çœŸå¤´åƒï¼Œä¿ç•™ç”¨æˆ·çš„èº«ä»½ç‰¹å¾ä¿¡æ¯çš„åŒæ—¶ï¼Œåˆèƒ½ä¿æŠ¤é¢éƒ¨ç”Ÿç‰©è¯†åˆ«ä¿¡æ¯ã€‚é€šè¿‡èº«ä»½ç¼–ç ç”Ÿæˆæ¨¡å‹çš„ç‰¹æ€§ç©ºé—´è¿›è¡Œèº«ä»½ä¿¡æ¯çš„éš”ç¦»ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸¤ç§æ¨¡ç³Šèº«ä»½çš„æ–¹æ³•ï¼šæä¾›å·®åˆ†éšç§ä¿è¯çš„Îµæ–¹æ³•ï¼ˆ\epsmethodï¼‰å’Œæä¾›ç²¾ç»†èº«ä»½åç§»æ§åˆ¶çš„Î¸æ–¹æ³•ï¼ˆ\thetamethodï¼‰ã€‚è¿™äº›æ–¹æ³•æˆåŠŸåœ°åœ¨å¤šç§äºŒç»´å’Œä¸‰ç»´ç”Ÿæˆæ¶æ„ä¸­ç”Ÿæˆäº†åŒ¿åè™šæ‹Ÿå¤´åƒã€‚è¿™äº›æŠ€æœ¯èƒ½å¤Ÿåœ¨ä¿æŠ¤ç”¨æˆ·éšç§çš„åŒæ—¶ï¼Œä¿ç•™ä¸è‡ªæˆ‘è®¤çŸ¥ç›¸å…³çš„å±æ€§ã€‚åœ¨å…¬å…±åœºåˆåº”ç”¨è¿™äº›æŠ€æœ¯ï¼Œå¯ä»¥åœ¨ä¿æŒé«˜çœŸå®æ„Ÿå’Œæ²‰æµ¸æ„Ÿçš„åŒæ—¶ï¼Œé™ä½ä½¿ç”¨MRä¸­çš„é€¼çœŸå¤´åƒçš„éšç§é£é™©ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>3Då¤´åƒç”ŸæˆæŠ€æœ¯è¿…é€Ÿå‘å±•ï¼Œä½¿å¾—åœ¨æ··åˆç°å®ä¸­åˆ›å»ºä¸ç”¨æˆ·çœŸå®å¤–è²ŒåŒ¹é…çš„å¤´åƒæ›´ä¸ºå¯è¡Œã€‚</li>
<li>åˆ†äº«ä¸ªäººè‚–åƒå­˜åœ¨é£é™©ï¼Œé€¼çœŸçš„MRå¤´åƒå¯èƒ½åŠ å‰§è¿™äº›é£é™©ï¼Œå¦‚é­å—ç½‘ç»œæ¬ºå‡Œæˆ–æ¬ºè¯ˆã€‚</li>
<li>æå‡ºäº†ä¸€ç§åˆæˆé€¼çœŸå¤´åƒçš„æ–¹æ³•ï¼Œæ—¢ä¿ç•™ç”¨æˆ·èº«ä»½ç‰¹å¾ä¿¡æ¯ï¼Œåˆä¿æŠ¤é¢éƒ¨ç”Ÿç‰©è¯†åˆ«ä¿¡æ¯ã€‚</li>
<li>é€šè¿‡èº«ä»½ç¼–ç ç”Ÿæˆæ¨¡å‹çš„ç‰¹æ€§ç©ºé—´è¿›è¡Œèº«ä»½ä¿¡æ¯çš„éš”ç¦»ã€‚</li>
<li>ä»‹ç»äº†ä¸¤ç§æ¨¡ç³Šèº«ä»½çš„æ–¹æ³•ï¼Œæä¾›äº†å·®åˆ†éšç§ä¿è¯å’Œç²¾ç»†çš„èº«ä»½åç§»æ§åˆ¶ã€‚</li>
<li>è¿™äº›æ–¹æ³•åœ¨å¤šç§ç”Ÿæˆæ¶æ„ä¸­æˆåŠŸç”Ÿæˆäº†åŒ¿åè™šæ‹Ÿå¤´åƒã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2507.22153">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-6269479aae69abfdfa9bee215f3619fd.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-a05cdb712c4e211781686b6a9f272156.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ba3951aeb000e8a3deee37d5a2bafcb0.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="JWB-DH-V1-Benchmark-for-Joint-Whole-Body-Talking-Avatar-and-Speech-Generation-Version-1"><a href="#JWB-DH-V1-Benchmark-for-Joint-Whole-Body-Talking-Avatar-and-Speech-Generation-Version-1" class="headerlink" title="JWB-DH-V1: Benchmark for Joint Whole-Body Talking Avatar and Speech   Generation Version 1"></a>JWB-DH-V1: Benchmark for Joint Whole-Body Talking Avatar and Speech   Generation Version 1</h2><p><strong>Authors:Xinhan Di, Kristin Qi, Pengqian Yu</strong></p>
<p>Recent advances in diffusion-based video generation have enabled photo-realistic short clips, but current methods still struggle to achieve multi-modal consistency when jointly generating whole-body motion and natural speech. Current approaches lack comprehensive evaluation frameworks that assess both visual and audio quality, and there are insufficient benchmarks for region-specific performance analysis. To address these gaps, we introduce the Joint Whole-Body Talking Avatar and Speech Generation Version I(JWB-DH-V1), comprising a large-scale multi-modal dataset with 10,000 unique identities across 2 million video samples, and an evaluation protocol for assessing joint audio-video generation of whole-body animatable avatars. Our evaluation of SOTA models reveals consistent performance disparities between face&#x2F;hand-centric and whole-body performance, which incidates essential areas for future research. The dataset and evaluation tools are publicly available at <a target="_blank" rel="noopener" href="https://github.com/deepreasonings/WholeBodyBenchmark">https://github.com/deepreasonings/WholeBodyBenchmark</a>. </p>
<blockquote>
<p>è¿‘æœŸæ‰©æ•£å¼è§†é¢‘ç”ŸæˆæŠ€æœ¯çš„è¿›å±•å·²ç»èƒ½å¤Ÿå®ç°é€¼çœŸçš„çŸ­ç‰‡ç”Ÿæˆï¼Œä½†å½“å‰çš„æ–¹æ³•åœ¨è”åˆç”Ÿæˆå…¨èº«è¿åŠ¨å’Œè‡ªç„¶è¯­éŸ³æ—¶ï¼Œä»éš¾ä»¥å®ç°å¤šæ¨¡å¼çš„ä¸€è‡´æ€§ã€‚ç°æœ‰æ–¹æ³•ç¼ºä¹ç»¼åˆè¯„ä¼°æ¡†æ¶ï¼Œæ— æ³•å¯¹è§†è§‰å’ŒéŸ³é¢‘è´¨é‡è¿›è¡Œè¯„ä¼°ï¼Œä¸”é’ˆå¯¹ç‰¹å®šåŒºåŸŸçš„æ€§èƒ½åˆ†æåŸºå‡†ä¸è¶³ã€‚ä¸ºäº†å¼¥è¡¥è¿™äº›ç©ºç™½ï¼Œæˆ‘ä»¬æ¨å‡ºäº†è”åˆå…¨èº«è¯´è¯è™šæ‹Ÿå½¢è±¡ä¸è¯­éŸ³ç”Ÿæˆç‰ˆæœ¬Iï¼ˆJWB-DH-V1ï¼‰ï¼Œå…¶åŒ…æ‹¬ä¸€ä¸ªå¤§è§„æ¨¡å¤šæ¨¡å¼æ•°æ®é›†ï¼Œæ¶µç›–1ä¸‡ä¸ªå”¯ä¸€èº«ä»½å’Œè¶…è¿‡2ç™¾ä¸‡è§†é¢‘æ ·æœ¬ï¼Œä»¥åŠä¸€ä¸ªç”¨äºè¯„ä¼°å…¨èº«å¯åŠ¨ç”»è™šæ‹Ÿå½¢è±¡çš„è”åˆéŸ³è§†é¢‘ç”Ÿæˆçš„è¯„ä¼°åè®®ã€‚æˆ‘ä»¬å¯¹æœ€æ–°æ¨¡å‹çš„è¯„ä¼°æ˜¾ç¤ºï¼Œé¢å‘é¢éƒ¨&#x2F;æ‰‹éƒ¨ä¸å…¨èº«æ€§èƒ½ä¹‹é—´å­˜åœ¨æŒç»­çš„æ€§èƒ½å·®å¼‚ï¼Œè¿™æŒ‡æ˜äº†æœªæ¥ç ”ç©¶çš„å…³é”®é¢†åŸŸã€‚æ•°æ®é›†å’Œè¯„ä¼°å·¥å…·å¯åœ¨ <a target="_blank" rel="noopener" href="https://github.com/deepreasonings/WholeBodyBenchmark">https://github.com/deepreasonings/WholeBodyBenchmark</a> å…¬å¼€è·å–ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2507.20987v2">PDF</a> WiCV @ ICCV 2025</p>
<p><strong>Summary</strong></p>
<p>è¿‘æœŸæ‰©æ•£æŠ€æœ¯è¿›å±•ä¸ºç”Ÿæˆé€¼çœŸçš„çŸ­ç‰‡è§†é¢‘æä¾›äº†å¯èƒ½ï¼Œä½†åœ¨è”åˆç”Ÿæˆå…¨èº«è¿åŠ¨å’Œè‡ªç„¶è¯­éŸ³æ—¶ä»é¢ä¸´å¤šæ¨¡æ€ä¸€è‡´æ€§æŒ‘æˆ˜ã€‚ç¼ºä¹ç»¼åˆè¯„ä¼°æ¡†æ¶å¯¹è§†è§‰å’ŒéŸ³é¢‘è´¨é‡è¿›è¡Œè¯„ä¼°ï¼Œä¸”åŒºåŸŸç‰¹å®šæ€§èƒ½åˆ†æçš„åŸºå‡†æµ‹è¯•ä¸è¶³ã€‚ä¸ºè§£å†³è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬æ¨å‡ºè”åˆå…¨èº«è¯´è¯åŠèº«åƒå’Œè¯­éŸ³ç”Ÿæˆç‰ˆæœ¬ä¸€ï¼ˆJWB-DH-V1ï¼‰ï¼ŒåŒ…æ‹¬å¤§è§„æ¨¡å¤šæ¨¡æ€æ•°æ®é›†ï¼Œæ¶µç›–10,000ä¸ªå”¯ä¸€èº«ä»½å’Œè¶…è¿‡2ç™¾ä¸‡è§†é¢‘æ ·æœ¬ï¼Œä»¥åŠè¯„ä¼°å…¨èº«å¯åŠ¨ç”»åŠèº«åƒè”åˆéŸ³è§†é¢‘ç”Ÿæˆçš„è¯„ä¼°åè®®ã€‚å¯¹æœ€æ–°æ¨¡å‹çš„è¯„ä¼°æ˜¾ç¤ºï¼Œé¢éƒ¨&#x2F;æ‰‹éƒ¨ä¸ºä¸­å¿ƒä¸å…¨èº«æ€§èƒ½ä¹‹é—´å­˜åœ¨æŒç»­çš„æ€§èƒ½å·®å¼‚ï¼Œè¿™ä¸ºæœªæ¥ç ”ç©¶æŒ‡æ˜äº†å…³é”®æ–¹å‘ã€‚æ•°æ®é›†å’Œè¯„ä¼°å·¥å…·å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/deepreasonings/WholeBodyBenchmark%E5%85%AC%E5%BC%80%E8%8E%B7%E5%8F%96%E3%80%82">https://github.com/deepreasonings/WholeBodyBenchmarkå…¬å¼€è·å–ã€‚</a></p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æ‰©æ•£æŠ€æœ¯å·²ç»å®ç°äº†é€¼çœŸè§†é¢‘çš„ç”Ÿæˆã€‚</li>
<li>å½“å‰æŠ€æœ¯åœ¨è”åˆç”Ÿæˆå…¨èº«è¿åŠ¨å’Œè‡ªç„¶è¯­éŸ³æ—¶é¢ä¸´å¤šæ¨¡æ€ä¸€è‡´æ€§æŒ‘æˆ˜ã€‚</li>
<li>ç¼ºä¹è¯„ä¼°è§†è§‰å’ŒéŸ³é¢‘è´¨é‡çš„ç»¼åˆè¯„ä¼°æ¡†æ¶ã€‚</li>
<li>éœ€è¦æ›´å¤šçš„åŒºåŸŸç‰¹å®šæ€§èƒ½åˆ†æçš„åŸºå‡†æµ‹è¯•ã€‚</li>
<li>æ¨å‡ºJWB-DH-V1æ•°æ®é›†ï¼ŒåŒ…å«å¤§è§„æ¨¡å¤šæ¨¡æ€æ•°æ®ï¼Œæ—¨åœ¨è§£å†³ä¸Šè¿°é—®é¢˜ã€‚</li>
<li>å¯¹ç°æœ‰æ¨¡å‹çš„è¯„ä¼°æ˜¾ç¤ºï¼Œå…¨èº«æ€§èƒ½ä¸é¢éƒ¨&#x2F;æ‰‹éƒ¨ä¸ºä¸­å¿ƒçš„æ¨¡å‹ä¹‹é—´å­˜åœ¨æ€§èƒ½å·®å¼‚ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2507.20987">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-a1738fdcf4dfcf467db3947c0e47550a.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-696ad95e0d2fcb14f0881d251efb20f4.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-11c7871f7403d58731e479868f6c99fc.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-53368c3d87762a87a882d497cff99cdd.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="HairCUP-Hair-Compositional-Universal-Prior-for-3D-Gaussian-Avatars"><a href="#HairCUP-Hair-Compositional-Universal-Prior-for-3D-Gaussian-Avatars" class="headerlink" title="HairCUP: Hair Compositional Universal Prior for 3D Gaussian Avatars"></a>HairCUP: Hair Compositional Universal Prior for 3D Gaussian Avatars</h2><p><strong>Authors:Byungjun Kim, Shunsuke Saito, Giljoo Nam, Tomas Simon, Jason Saragih, Hanbyul Joo, Junxuan Li</strong></p>
<p>We present a universal prior model for 3D head avatars with explicit hair compositionality. Existing approaches to build generalizable priors for 3D head avatars often adopt a holistic modeling approach, treating the face and hair as an inseparable entity. This overlooks the inherent compositionality of the human head, making it difficult for the model to naturally disentangle face and hair representations, especially when the dataset is limited. Furthermore, such holistic models struggle to support applications like 3D face and hairstyle swapping in a flexible and controllable manner. To address these challenges, we introduce a prior model that explicitly accounts for the compositionality of face and hair, learning their latent spaces separately. A key enabler of this approach is our synthetic hairless data creation pipeline, which removes hair from studio-captured datasets using estimated hairless geometry and texture derived from a diffusion prior. By leveraging a paired dataset of hair and hairless captures, we train disentangled prior models for face and hair, incorporating compositionality as an inductive bias to facilitate effective separation. Our modelâ€™s inherent compositionality enables seamless transfer of face and hair components between avatars while preserving identity. Additionally, we demonstrate that our model can be fine-tuned in a few-shot manner using monocular captures to create high-fidelity, hair-compositional 3D head avatars for unseen subjects. These capabilities highlight the practical applicability of our approach in real-world scenarios, paving the way for flexible and expressive 3D avatar generation. </p>
<blockquote>
<p>æˆ‘ä»¬æå‡ºäº†ä¸€ç§å…·æœ‰æ˜ç¡®å¤´å‘ç»„åˆæ€§çš„3Då¤´åƒé€šç”¨å…ˆéªŒæ¨¡å‹ã€‚ç°æœ‰çš„ä¸º3Då¤´åƒæ„å»ºé€šç”¨å…ˆéªŒæ¨¡å‹çš„æ–¹æ³•é€šå¸¸é‡‡ç”¨æ•´ä½“å»ºæ¨¡æ–¹æ³•ï¼Œå°†è„¸å’Œå¤´å‘è§†ä¸ºä¸€ä¸ªä¸å¯åˆ†å‰²çš„å®ä½“ã€‚è¿™å¿½ç•¥äº†äººå¤´çš„å†…åœ¨ç»„åˆæ€§ï¼Œä½¿å¾—æ¨¡å‹å¾ˆéš¾è‡ªç„¶åœ°åˆ†ç¦»é¢éƒ¨å’Œå¤´å‘çš„è¡¨ç¤ºï¼Œå°¤å…¶æ˜¯åœ¨æ•°æ®é›†æœ‰é™çš„æƒ…å†µä¸‹ã€‚æ­¤å¤–ï¼Œè¿™ç§æ•´ä½“æ¨¡å‹å¾ˆéš¾ä»¥çµæ´»å’Œå¯æ§çš„æ–¹å¼æ”¯æŒ3Dé¢éƒ¨å’Œå‘å‹äº¤æ¢ç­‰åº”ç”¨ç¨‹åºã€‚ä¸ºäº†åº”å¯¹è¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§å…ˆéªŒæ¨¡å‹ï¼Œè¯¥æ¨¡å‹æ˜ç¡®è€ƒè™‘äº†é¢éƒ¨å’Œå¤´å‘çš„ç»„åˆæ€§ï¼Œåˆ†åˆ«å­¦ä¹ å®ƒä»¬çš„æ½œåœ¨ç©ºé—´ã€‚æ­¤æ–¹æ³•çš„å…³é”®æ˜¯æˆ‘ä»¬åˆæˆæ— å‘æ•°æ®åˆ›å»ºç®¡é“ï¼Œè¯¥ç®¡é“ä½¿ç”¨ä¼°è®¡çš„æ— å‘å‡ ä½•å’Œçº¹ç†ä»æ‰©æ•£å…ˆéªŒä¸­å»é™¤ä»å·¥ä½œå®¤æ•è·çš„æ•°æ®é›†ä¸­çš„å¤´å‘ã€‚é€šè¿‡åˆ©ç”¨å¸¦æœ‰å¤´å‘å’Œæ— å‘æ•è·çš„é…å¯¹æ•°æ®é›†ï¼Œæˆ‘ä»¬å¯¹é¢éƒ¨å’Œå¤´å‘è¿›è¡Œäº†åˆ†ç¦»è®­ç»ƒå…ˆéªŒæ¨¡å‹ï¼Œå°†ç»„åˆæ€§ä½œä¸ºå½’çº³åç½®ï¼Œä»¥ä¿ƒè¿›æœ‰æ•ˆçš„åˆ†ç¦»ã€‚æˆ‘ä»¬æ¨¡å‹çš„å†…åœ¨ç»„åˆæ€§ä½¿å¾—å¤´åƒä¹‹é—´çš„é¢éƒ¨å’Œå¤´å‘ç»„ä»¶æ— ç¼è½¬ç§»ï¼ŒåŒæ—¶ä¿æŒèº«ä»½ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¯æ˜æˆ‘ä»¬çš„æ¨¡å‹å¯ä»¥é€šè¿‡å•ç›®æ•è·è¿›è¡Œå¾®è°ƒï¼Œä¸ºæœªè§è¿‡çš„ä¸»é¢˜åˆ›å»ºé«˜ä¿çœŸã€å…·æœ‰å¤´å‘ç»„åˆçš„3Då¤´åƒã€‚è¿™äº›åŠŸèƒ½çªæ˜¾äº†æˆ‘ä»¬çš„æ–¹æ³•åœ¨ç°å®ä¸–ç•Œåœºæ™¯ä¸­çš„å®é™…åº”ç”¨æ€§ï¼Œä¸ºçµæ´»å’Œå¯Œæœ‰è¡¨ç°åŠ›çš„3Då¤´åƒç”Ÿæˆé“ºå¹³äº†é“è·¯ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2507.19481v1">PDF</a> ICCV 2025. Project Page: <a target="_blank" rel="noopener" href="https://bjkim95.github.io/haircup/">https://bjkim95.github.io/haircup/</a></p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†ä¸€ç§é’ˆå¯¹å…·æœ‰æ˜ç¡®å¤´å‘ç»„åˆæ€§çš„3Då¤´éƒ¨åŒ–èº«é€šç”¨å…ˆéªŒæ¨¡å‹ã€‚ç°æœ‰æ–¹æ³•åœ¨å¤„ç†å¯æ¨å¹¿çš„å…ˆéªŒæ¨¡å‹æ—¶å¸¸å¸¸é‡‡ç”¨æ•´ä½“å»ºæ¨¡æ–¹å¼ï¼Œå°†é¢éƒ¨å’Œå¤´å‘è§†ä¸ºä¸å¯åˆ†å‰²çš„å®ä½“ï¼Œå¿½ç•¥äº†å¤´éƒ¨å›ºæœ‰çš„ç»„åˆæ€§ã€‚æœ¬æ–‡æ–¹æ³•é€šè¿‡æ˜ç¡®è€ƒè™‘é¢éƒ¨å’Œå¤´å‘çš„ç»„åˆæ€§ï¼Œåˆ†åˆ«å­¦ä¹ å®ƒä»¬çš„æ½œåœ¨ç©ºé—´æ¥è§£å†³è¿™ä¸€é—®é¢˜ã€‚é€šè¿‡åˆæˆæ— å‘æ•°æ®åˆ›å»ºç®¡é“å»é™¤åŸºäºæ‰©æ•£å…ˆéªŒä¼°è®¡çš„æ— å‘å‡ ä½•ç»“æ„å’Œçº¹ç†çš„æ•è·æ•°æ®ä¸­çš„å¤´å‘ï¼Œå¹¶ä½¿ç”¨é…å¯¹çš„æ•°æ®é›†å¯¹è„¸å’Œå¤´å‘è¿›è¡Œè®­ç»ƒï¼Œèå…¥ç»„åˆæ€§ä½œä¸ºå½’çº³åç½®ä»¥ä¿ƒè¿›æœ‰æ•ˆåˆ†ç¦»ã€‚è¯¥æ¨¡å‹çš„å›ºæœ‰ç»„åˆæ€§èƒ½å¤Ÿå®ç°åŒ–èº«ä¹‹é—´çš„è„¸å’Œå¤´å‘ç»„ä»¶æ— ç¼è½¬ç§»ï¼ŒåŒæ—¶ä¿ç•™èº«ä»½ã€‚æ­¤å¤–ï¼Œè¯¥ç ”ç©¶è¿˜å±•ç¤ºäº†è¯¥æ¨¡å‹å¯ä»¥é€šè¿‡å°‘é‡å•ç›®æ•è·è¿›è¡Œå¾®è°ƒï¼Œä¸ºæœªè§è¿‡çš„ä¸»ä½“åˆ›å»ºé«˜ä¿çœŸã€å…·æœ‰å¤´å‘ç»„åˆçš„3Då¤´éƒ¨åŒ–èº«ï¼Œçªæ˜¾äº†å…¶åœ¨ç°å®åœºæ™¯ä¸­çš„å®ç”¨åº”ç”¨ä»·å€¼ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ç°æœ‰3Då¤´éƒ¨åŒ–èº«é€šç”¨å…ˆéªŒæ¨¡å‹å¸¸å¸¸é‡‡ç”¨æ•´ä½“å»ºæ¨¡æ–¹å¼ï¼Œéš¾ä»¥è‡ªç„¶åˆ†ç¦»é¢éƒ¨å’Œå¤´å‘è¡¨ç¤ºã€‚</li>
<li>æœ¬æ–‡æå‡ºäº†ä¸€ç§è€ƒè™‘é¢éƒ¨å’Œå¤´å‘ç»„åˆæ€§çš„å…ˆéªŒæ¨¡å‹ï¼Œåˆ†åˆ«å­¦ä¹ å®ƒä»¬çš„æ½œåœ¨ç©ºé—´ã€‚</li>
<li>é€šè¿‡åˆæˆæ— å‘æ•°æ®åˆ›å»ºç®¡é“å»é™¤å¤´å‘ï¼Œä½¿ç”¨é…å¯¹æ•°æ®é›†è¿›è¡Œè®­ç»ƒã€‚</li>
<li>æ¨¡å‹çš„å›ºæœ‰ç»„åˆæ€§å¯å®ç°æ— ç¼è½¬ç§»è„¸å’Œå¤´å‘ç»„ä»¶ã€‚</li>
<li>æ¨¡å‹å¯å°‘é‡å•ç›®æ•è·è¿›è¡Œå¾®è°ƒï¼Œåˆ›å»ºé«˜ä¿çœŸ3Då¤´éƒ¨åŒ–èº«ã€‚</li>
<li>è¯¥æ–¹æ³•ä¸ºæœªè§è¿‡çš„ä¸»ä½“æä¾›çµæ´»çš„3Då¤´åƒç”Ÿæˆèƒ½åŠ›ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2507.19481">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-8aa8de00e7d38452acb243d554363483.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-9599f6e34f5fc13f0e1bbc7adb0b3b0c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-60413872fed10c130b8a41474945f840.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="AI-Enabled-6G-for-Semantic-Metaverse-Prospects-Challenges-and-Solutions-for-Future-Wireless-VR"><a href="#AI-Enabled-6G-for-Semantic-Metaverse-Prospects-Challenges-and-Solutions-for-Future-Wireless-VR" class="headerlink" title="AI Enabled 6G for Semantic Metaverse: Prospects, Challenges and   Solutions for Future Wireless VR"></a>AI Enabled 6G for Semantic Metaverse: Prospects, Challenges and   Solutions for Future Wireless VR</h2><p><strong>Authors:Muhammad Ahmed Mohsin, Sagnik Bhattacharya, Abhiram Gorle, Muhammad Ali Jamshed, John M. Cioffi</strong></p>
<p>Wireless support of virtual reality (VR) has challenges when a network has multiple users, particularly for 3D VR gaming, digital AI avatars, and remote team collaboration. This work addresses these challenges through investigation of the low-rank channels that inevitably occur when there are more active users than there are degrees of spatial freedom, effectively often the number of antennas. The presented approach uses optimal nonlinear transceivers, equivalently generalized decision-feedback or successive cancellation for uplink and superposition or dirty-paper precoders for downlink. Additionally, a powerful optimization approach for the usersâ€™ energy allocation and decoding order appears to provide large improvements over existing methods, effectively nearing theoretical optima. As the latter optimization methods pose real-time challenges, approximations using deep reinforcement learning (DRL) are used to approximate best performance with much lower (5x at least) complexity. Experimental results show significantly larger sum rates and very large power savings to attain the data rates found necessary to support VR. Experimental results show the proposed algorithm outperforms current industry standards like orthogonal multiple access (OMA), non-orthogonal multiple access (NOMA), as well as the highly researched methods in multi-carrier NOMA (MC-NOMA), enhancing sum data rate by 39%, 28%, and 16%, respectively, at a given power level. For the same data rate, it achieves power savings of 75%, 45%, and 40%, making it ideal for VR applications. Additionally, a near-optimal deep reinforcement learning (DRL)-based resource allocation framework for real-time use by being 5x faster and reaching 83% of the global optimum is introduced. </p>
<blockquote>
<p>æ— çº¿æŠ€æœ¯åœ¨å¯¹è™šæ‹Ÿç¯å¢ƒï¼ˆVRï¼‰æä¾›æ”¯æŒæ—¶é¢ä¸´å¤šä¸ªç”¨æˆ·çš„æŒ‘æˆ˜ï¼Œå°¤å…¶æ˜¯åœ¨è¯¸å¦‚å¤šäººå‚ä¸çš„åœ¨çº¿è™šæ‹Ÿä¸–ç•Œä½“éªŒç­‰3Dè™šæ‹Ÿç°å®æ¸¸æˆä»¥åŠæ•°å­—äººå·¥æ™ºèƒ½åˆ†èº«æˆ–è¿œç¨‹å›¢é˜Ÿåˆä½œçš„åœºåˆã€‚è¯¥ç ”ç©¶è§£å†³äº†ä¸Šè¿°é—®é¢˜ï¼Œé’ˆå¯¹å‡ºç°æ›´å¤šæ´»è·ƒç”¨æˆ·ç›¸è¾ƒäºå¯ç”¨çš„ç©ºé—´è‡ªç”±åº¦æ—¶æ‰€ä¸å¯é¿å…åœ°äº§ç”Ÿçš„ä½ç§©é€šé“è¿›è¡Œäº†æ·±å…¥ç ”ç©¶ã€‚è¿™åœ¨è®¸å¤šåœºæ™¯ä¸‹æ„å‘³ç€é¢ä¸´ç”¨æˆ·å¤©çº¿æ•°é‡ä¸è¶³çš„éš¾é¢˜ã€‚æ–‡ä¸­ä½¿ç”¨äº†ä¸€ç§æœ€ä¼˜çš„éçº¿æ€§æ”¶å‘å™¨ï¼ŒåŒ…æ‹¬ä¸Šè¡Œé“¾è·¯ä¸­çš„å¹¿ä¹‰å†³ç­–åé¦ˆæˆ–è¿ç»­å–æ¶ˆæŠ€æœ¯ï¼Œä»¥åŠä¸‹è¡Œé“¾è·¯ä¸­çš„å åŠ æˆ–è„çº¸ç¼–ç æŠ€æœ¯ã€‚æ­¤å¤–ï¼Œå¯¹äºç”¨æˆ·èƒ½é‡åˆ†é…å’Œè§£ç é¡ºåºçš„å¼ºå¤§ä¼˜åŒ–æ–¹æ³•ä¹Ÿå¸¦æ¥äº†å¯¹å·²æœ‰æŠ€æœ¯çš„å·¨å¤§æ”¹è¿›ï¼Œè¿™ç§æ”¹è¿›æ¥è¿‘ç†è®ºæœ€ä¼˜è§£ã€‚å°½ç®¡åè€…æå‡ºçš„ä¼˜åŒ–æ–¹æ³•é¢ä¸´å®æ—¶å¤„ç†æ–¹é¢çš„æŒ‘æˆ˜ï¼Œä½†é€šè¿‡æ·±åº¦å¼ºåŒ–å­¦ä¹ è¿›è¡Œçš„è¿‘ä¼¼ç®—æ³•èƒ½åœ¨å¤§å¤§é™ä½è®¡ç®—å¤æ‚åº¦ï¼ˆè‡³å°‘å‡å°‘ä¸€åŠï¼‰çš„æƒ…å†µä¸‹å®ç°è¿‘ä¼¼æœ€ä¼˜æ€§èƒ½ã€‚å®éªŒç»“æœæ˜¾ç¤ºå‡ºæ–°å‹ç®—æ³•æ”¯æŒæ˜¾è‘—æ›´é«˜çš„æ•°æ®ä¼ è¾“ç‡åŠæ›´ä½çš„èƒ½è€—æ°´å¹³ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œç›¸è¾ƒäºæ­£äº¤å¤šå€æ¥å…¥ï¼ˆOMAï¼‰ã€éæ­£äº¤å¤šå€æ¥å…¥ï¼ˆNOMAï¼‰ä»¥åŠå¤šè½½æ³¢éæ­£äº¤å¤šå€æ¥å…¥ï¼ˆMC-NOMAï¼‰ç­‰ç°æœ‰è¡Œä¸šæ ‡å‡†çš„åè®®è¡¨ç°ä¼˜è¶Šã€‚å½“å¤„äºç›¸åŒçš„åŠŸç‡æ°´å¹³æ—¶ï¼Œæ‰€æç®—æ³•æé«˜äº†å„è‡ªè¡Œä¸šæ ‡å‡†çš„ä¼ è¾“ç‡åˆ†åˆ«è¾¾åˆ°æƒŠäººçš„è¿‘ä¸‰åˆ†ä¹‹ä¸€ï¼Œä¸”æ¶ˆè€—çš„åŠŸç‡é™ä½å››åˆ†ä¹‹ä¸€å·¦å³ã€‚è¿™ä½¿å…¶æˆä¸ºç†æƒ³æ”¯æŒè™šæ‹Ÿç°å®åº”ç”¨çš„é€šä¿¡æŠ€æœ¯ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜å¼•å…¥äº†ä¸€ç§åŸºäºæ·±åº¦å¼ºåŒ–å­¦ä¹ çš„èµ„æºåˆ†é…æ¡†æ¶ï¼Œèƒ½å¤Ÿåœ¨æ¥è¿‘å®æ—¶çš„ç¯å¢ƒä¸­å¿«é€Ÿè¿è¡Œå¹¶è¾¾åˆ°å…¨å±€æœ€ä¼˜è§£çš„å…«æˆå·¦å³ã€‚è¿™æ˜¯ä¸€ç§å…·æœ‰é‡å¤§åº”ç”¨ä»·å€¼çš„è¿‘ä¹ç†æƒ³çš„ä¼˜åŒ–ç­–ç•¥ï¼Œç‰¹åˆ«é€‚åˆåœ¨æœªæ¥åŸºäºå¤šç”¨æˆ·çš„æ— çº¿é€šä¿¡ç½‘ç»œä¸­å‘æŒ¥ä½œç”¨ä»¥æ¨åŠ¨å…ƒå®‡å®™æŠ€æœ¯çš„å¹¿æ³›è¿ç”¨åŠé•¿è¶³å‘å±•ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2507.19124v1">PDF</a> IEEE Wireless Communications Magazine</p>
<p><strong>Summary</strong><br>     é’ˆå¯¹è™šæ‹Ÿç°å®ï¼ˆVRï¼‰çš„æ— çº¿æ”¯æŒåœ¨å¤šç”¨æˆ·ç½‘ç»œä¸­é¢ä¸´æŒ‘æˆ˜ï¼Œç‰¹åˆ«æ˜¯åœ¨3D VRæ¸¸æˆã€æ•°å­—AIåŒ–èº«å’Œè¿œç¨‹å›¢é˜Ÿåä½œä¸­ã€‚æœ¬ç ”ç©¶é€šè¿‡æ¢ç´¢ä½ç­‰çº§é€šé“æ¥è§£å†³è¿™äº›é—®é¢˜ï¼Œå½“æ´»è·ƒç”¨æˆ·æ•°é‡è¶…è¿‡ç©ºé—´è‡ªç”±åº¦æ—¶ï¼Œè¿™äº›é€šé“ä¸å¯é¿å…åœ°ä¼šå‡ºç°ã€‚ç ”ç©¶é‡‡ç”¨æœ€ä¼˜éçº¿æ€§æ”¶å‘å™¨ï¼Œå¹¶åˆ©ç”¨æ·±åº¦å­¦ä¹ å¼ºåŒ–ç®—æ³•ä¼˜åŒ–ç”¨æˆ·èƒ½é‡åˆ†é…å’Œè§£ç é¡ºåºã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•ä¼˜äºå½“å‰è¡Œä¸šæ ‡å‡†ï¼Œæé«˜äº†æ•°æ®é€Ÿç‡å¹¶å¤§å¹…èŠ‚çœèƒ½æºã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>è™šæ‹Ÿç°å®ï¼ˆVRï¼‰çš„æ— çº¿æ”¯æŒåœ¨å¤šç”¨æˆ·ç½‘ç»œä¸­å…·æœ‰æŒ‘æˆ˜ï¼Œç‰¹åˆ«æ˜¯åœ¨3D VRæ¸¸æˆã€æ•°å­—AIåŒ–èº«å’Œè¿œç¨‹å›¢é˜Ÿåä½œä¸­ã€‚</li>
<li>ç ”ç©¶é€šè¿‡æ¢ç´¢ä½ç­‰çº§é€šé“è§£å†³æŒ‘æˆ˜ï¼Œé‡‡ç”¨æœ€ä¼˜éçº¿æ€§æ”¶å‘å™¨ã€‚</li>
<li>é€šè¿‡æ·±åº¦å­¦ä¹ å¼ºåŒ–ç®—æ³•ä¼˜åŒ–ç”¨æˆ·èƒ½é‡åˆ†é…å’Œè§£ç é¡ºåºï¼Œä»¥é€¼è¿‘ç†è®ºæœ€ä¼˜æ€§èƒ½ã€‚</li>
<li>å®éªŒç»“æœæ˜¾ç¤ºè¯¥æ–¹æ³•ä¼˜äºå½“å‰è¡Œä¸šæ ‡å‡†ï¼Œå¦‚æ­£äº¤å¤šå€æ¥å…¥ï¼ˆOMAï¼‰ã€éæ­£äº¤å¤šå€æ¥å…¥ï¼ˆNOMAï¼‰å’Œå¤šè½½æ³¢NOMAï¼ˆMC-NOMAï¼‰ã€‚</li>
<li>è¯¥æ–¹æ³•åœ¨ç»™å®šåŠŸç‡æ°´å¹³ä¸‹æé«˜äº†æ•°æ®é€Ÿç‡ï¼Œå¹¶åœ¨ç›¸åŒæ•°æ®é€Ÿç‡ä¸‹å®ç°äº†æ˜¾è‘—çš„èŠ‚èƒ½ã€‚</li>
<li>å¼•å…¥äº†ä¸€ç§åŸºäºæ·±åº¦å­¦ä¹ å¼ºåŒ–ç®—æ³•çš„å®æ—¶èµ„æºåˆ†é…æ¡†æ¶ï¼Œè¿è¡Œé€Ÿåº¦å¿«ï¼Œæ¥è¿‘å…¨å±€æœ€ä¼˜è§£çš„83%ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2507.19124">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-d45237997c34be63a15d3de9ab31dafe.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-ffab9676fc57bdedb660e09e9f610722.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-5d50ddb0be88879dfbde917b35066cd6.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-04a589a431d5370ee5d864f52468c219.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-2000d42b8d8203ed355de97c8f498c22.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="GeoAvatar-Adaptive-Geometrical-Gaussian-Splatting-for-3D-Head-Avatar"><a href="#GeoAvatar-Adaptive-Geometrical-Gaussian-Splatting-for-3D-Head-Avatar" class="headerlink" title="GeoAvatar: Adaptive Geometrical Gaussian Splatting for 3D Head Avatar"></a>GeoAvatar: Adaptive Geometrical Gaussian Splatting for 3D Head Avatar</h2><p><strong>Authors:SeungJun Moon, Hah Min Lew, Seungeun Lee, Ji-Su Kang, Gyeong-Moon Park</strong></p>
<p>Despite recent progress in 3D head avatar generation, balancing identity preservation, i.e., reconstruction, with novel poses and expressions, i.e., animation, remains a challenge. Existing methods struggle to adapt Gaussians to varying geometrical deviations across facial regions, resulting in suboptimal quality. To address this, we propose GeoAvatar, a framework for adaptive geometrical Gaussian Splatting. GeoAvatar leverages Adaptive Pre-allocation Stage (APS), an unsupervised method that segments Gaussians into rigid and flexible sets for adaptive offset regularization. Then, based on mouth anatomy and dynamics, we introduce a novel mouth structure and the part-wise deformation strategy to enhance the animation fidelity of the mouth. Finally, we propose a regularization loss for precise rigging between Gaussians and 3DMM faces. Moreover, we release DynamicFace, a video dataset with highly expressive facial motions. Extensive experiments show the superiority of GeoAvatar compared to state-of-the-art methods in reconstruction and novel animation scenarios. </p>
<blockquote>
<p>å°½ç®¡æœ€è¿‘åœ¨3Då¤´åƒç”Ÿæˆæ–¹é¢å–å¾—äº†è¿›å±•ï¼Œä½†åœ¨å¹³è¡¡èº«ä»½ä¿ç•™ï¼ˆå³é‡å»ºï¼‰ä¸æ–°é¢–å§¿åŠ¿å’Œè¡¨æƒ…ï¼ˆå³åŠ¨ç”»ï¼‰ä¹‹é—´ä»ç„¶å­˜åœ¨æŒ‘æˆ˜ã€‚ç°æœ‰æ–¹æ³•éš¾ä»¥å°†é«˜æ–¯é€‚åº”é¢éƒ¨å„åŒºåŸŸçš„å‡ ä½•åå·®å˜åŒ–ï¼Œå¯¼è‡´è´¨é‡ä¸ä½³ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†GeoAvatarï¼Œä¸€ä¸ªè‡ªé€‚åº”å‡ ä½•é«˜æ–¯æ‹¼è´´æ¡†æ¶ã€‚GeoAvataråˆ©ç”¨è‡ªé€‚åº”é¢„åˆ†é…é˜¶æ®µï¼ˆAPSï¼‰ï¼Œè¿™æ˜¯ä¸€ç§æ— ç›‘ç£æ–¹æ³•ï¼Œå°†é«˜æ–¯åˆ†ä¸ºåˆšæ€§å’ŒæŸ”æ€§é›†ï¼Œç”¨äºè‡ªé€‚åº”åç§»æ­£åˆ™åŒ–ã€‚ç„¶åï¼ŒåŸºäºå£è…”ç»“æ„å’ŒåŠ¨æ€ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§æ–°çš„å£è…”ç»“æ„å’Œéƒ¨åˆ†å˜å½¢ç­–ç•¥ï¼Œä»¥æé«˜å£è…”åŠ¨ç”»çš„ä¿çœŸåº¦ã€‚æœ€åï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§é’ˆå¯¹é«˜æ–¯å’Œ3DMMé¢éƒ¨ä¹‹é—´ç²¾ç¡®éª¨æ¶çš„æ­£åˆ™åŒ–æŸå¤±ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å‘å¸ƒäº†DynamicFaceï¼Œè¿™æ˜¯ä¸€ä¸ªé«˜åº¦è¡¨æƒ…ä¸°å¯Œçš„é¢éƒ¨åŠ¨ä½œè§†é¢‘æ•°æ®é›†ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼ŒGeoAvataråœ¨é‡å»ºå’Œæ–°é¢–åŠ¨ç”»åœºæ™¯æ–¹é¢ä¼˜äºæœ€æ–°æ–¹æ³•ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2507.18155v1">PDF</a> ICCV 2025, Project page: <a target="_blank" rel="noopener" href="https://hahminlew.github.io/geoavatar/">https://hahminlew.github.io/geoavatar/</a></p>
<p><strong>Summary</strong></p>
<p>è¯¥æ–‡æ¢è®¨äº†ä¸‰ç»´å¤´åƒç”ŸæˆæŠ€æœ¯é¢ä¸´çš„æŒ‘æˆ˜ï¼Œå°¤å…¶æ˜¯åœ¨ä¿æŒèº«ä»½ï¼ˆé‡å»ºï¼‰ä¸æ–°é¢–å§¿æ€å’Œè¡¨æƒ…ï¼ˆåŠ¨ç”»ï¼‰ä¹‹é—´çš„å¹³è¡¡é—®é¢˜ã€‚ä¸ºè§£å†³ç°æœ‰æ–¹æ³•åœ¨å¤„ç†é¢éƒ¨å‡ ä½•åå·®æ—¶é¢ä¸´çš„æŒ‘æˆ˜ï¼Œæå‡ºGeoAvataræ¡†æ¶ï¼Œé€šè¿‡è‡ªé€‚åº”å‡ ä½•é«˜æ–¯æ‹¼è´´æŠ€æœ¯ï¼Œæé«˜äº†å¤´åƒç”Ÿæˆçš„å“è´¨ã€‚åŒæ—¶ï¼Œå¼•å…¥äº†ä¸€ç§æ–°çš„å˜´å·´ç»“æ„å’Œéƒ¨åˆ†å˜å½¢ç­–ç•¥ï¼Œå¢å¼ºäº†å˜´å·´åŠ¨ç”»çš„é€¼çœŸåº¦ã€‚æ­¤å¤–ï¼Œè¿˜æå‡ºäº†ä¸€ç§æ­£åˆ™åŒ–æŸå¤±æ–¹æ³•ï¼Œç”¨äºç²¾ç¡®è°ƒæ•´é«˜æ–¯ä¸ä¸‰ç»´äººè„¸æ¨¡å‹ä¹‹é—´çš„å¯¹åº”å…³ç³»ã€‚å®éªŒè¡¨æ˜ï¼ŒGeoAvatarç›¸è¾ƒäºç°æœ‰æŠ€æœ¯æœ‰æ˜æ˜¾ä¼˜åŠ¿ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>GeoAvataræ¡†æ¶æ—¨åœ¨è§£å†³ä¸‰ç»´å¤´åƒç”Ÿæˆä¸­çš„èº«ä»½ä¸åŠ¨ç”»å¹³è¡¡é—®é¢˜ã€‚</li>
<li>ç°æœ‰æ–¹æ³•åœ¨é¢éƒ¨å‡ ä½•åå·®å¤„ç†ä¸Šå­˜åœ¨æŒ‘æˆ˜ï¼Œå¯¼è‡´ç”Ÿæˆè´¨é‡ä¸ä½³ã€‚</li>
<li>GeoAvataré‡‡ç”¨è‡ªé€‚åº”å‡ ä½•é«˜æ–¯æ‹¼è´´æŠ€æœ¯æé«˜å¤´åƒç”Ÿæˆè´¨é‡ã€‚</li>
<li>å¼•å…¥æ–°çš„å˜´å·´ç»“æ„å’Œéƒ¨åˆ†å˜å½¢ç­–ç•¥ï¼Œå¢å¼ºå˜´å·´åŠ¨ç”»çš„é€¼çœŸåº¦ã€‚</li>
<li>æå‡ºä¸€ç§æ­£åˆ™åŒ–æŸå¤±æ–¹æ³•ï¼Œç²¾ç¡®è°ƒæ•´é«˜æ–¯ä¸ä¸‰ç»´äººè„¸æ¨¡å‹ä¹‹é—´çš„å¯¹åº”å…³ç³»ã€‚</li>
<li>DynamicFaceæ•°æ®é›†ç”¨äºå®éªŒéªŒè¯ï¼Œå±•ç¤ºäº†GeoAvataråœ¨é‡å»ºå’Œæ–°é¢–åŠ¨ç”»åœºæ™¯ä¸­çš„ä¼˜è¶Šæ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2507.18155">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-f17f65e62b20cd25d392adba8e0daebc.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-3ba7e89bc4b3b9648de01db46af3d015.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-4532f8b7796c6218f83f1ee0ae03a99d.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-de3c27123c0082f233ed6945ac6023d8.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-a4780f90f36cb275c32235c1c57d6585.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-e7f942e51a4d8e6bf812dce3334525b1.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="StreamME-Simplify-3D-Gaussian-Avatar-within-Live-Stream"><a href="#StreamME-Simplify-3D-Gaussian-Avatar-within-Live-Stream" class="headerlink" title="StreamME: Simplify 3D Gaussian Avatar within Live Stream"></a>StreamME: Simplify 3D Gaussian Avatar within Live Stream</h2><p><strong>Authors:Luchuan Song, Yang Zhou, Zhan Xu, Yi Zhou, Deepali Aneja, Chenliang Xu</strong></p>
<p>We propose StreamME, a method focuses on fast 3D avatar reconstruction. The StreamME synchronously records and reconstructs a head avatar from live video streams without any pre-cached data, enabling seamless integration of the reconstructed appearance into downstream applications. This exceptionally fast training strategy, which we refer to as on-the-fly training, is central to our approach. Our method is built upon 3D Gaussian Splatting (3DGS), eliminating the reliance on MLPs in deformable 3DGS and relying solely on geometry, which significantly improves the adaptation speed to facial expression. To further ensure high efficiency in on-the-fly training, we introduced a simplification strategy based on primary points, which distributes the point clouds more sparsely across the facial surface, optimizing points number while maintaining rendering quality. Leveraging the on-the-fly training capabilities, our method protects the facial privacy and reduces communication bandwidth in VR system or online conference. Additionally, it can be directly applied to downstream application such as animation, toonify, and relighting. Please refer to our project page for more details: <a target="_blank" rel="noopener" href="https://songluchuan.github.io/StreamME/">https://songluchuan.github.io/StreamME/</a>. </p>
<blockquote>
<p>æˆ‘ä»¬æå‡ºäº†StreamMEæ–¹æ³•ï¼Œå®ƒä¸“æ³¨äºå¿«é€Ÿ3DåŒ–èº«é‡å»ºã€‚StreamMEåŒæ­¥è®°å½•å¹¶ä»å®æ—¶è§†é¢‘æµä¸­é‡å»ºå¤´éƒ¨åŒ–èº«ï¼Œæ— éœ€ä»»ä½•é¢„å…ˆç¼“å­˜çš„æ•°æ®ï¼Œä½¿å¾—é‡å»ºçš„å¤–è§‚èƒ½å¤Ÿæ— ç¼åœ°é›†æˆåˆ°ä¸‹æ¸¸åº”ç”¨ä¸­ã€‚æˆ‘ä»¬ç§°ä¹‹ä¸ºâ€œå³æ—¶è®­ç»ƒâ€çš„è¿™ç§æå…¶å¿«é€Ÿçš„è®­ç»ƒç­–ç•¥æ˜¯æˆ‘ä»¬çš„æ–¹æ³•çš„æ ¸å¿ƒã€‚æˆ‘ä»¬çš„æ–¹æ³•å»ºç«‹åœ¨3Dé«˜æ–¯å¹³é“ºï¼ˆ3DGSï¼‰çš„åŸºç¡€ä¸Šï¼Œæ¶ˆé™¤äº†å¯¹å¯å˜å½¢3DGSä¸­å¤šå±‚æ„ŸçŸ¥å™¨ï¼ˆMLPsï¼‰çš„ä¾èµ–ï¼Œåªä¾èµ–äºå‡ ä½•ç»“æ„ï¼Œè¿™æ˜¾è‘—æé«˜äº†å¯¹é¢éƒ¨è¡¨æƒ…çš„é€‚åº”é€Ÿåº¦ã€‚ä¸ºäº†ç¡®ä¿å³æ—¶è®­ç»ƒçš„é«˜æ•ˆç‡ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§åŸºäºä¸»è¦ç‚¹çš„ç®€åŒ–ç­–ç•¥ï¼Œè¯¥ç­–ç•¥åœ¨é¢éƒ¨è¡¨é¢æ›´ç¨€ç–åœ°åˆ†å¸ƒç‚¹äº‘ï¼Œåœ¨ä¿æŒæ¸²æŸ“è´¨é‡çš„åŒæ—¶ä¼˜åŒ–äº†ç‚¹çš„æ•°é‡ã€‚åˆ©ç”¨å³æ—¶è®­ç»ƒåŠŸèƒ½ï¼Œæˆ‘ä»¬çš„æ–¹æ³•ä¿æŠ¤äº†é¢éƒ¨çš„éšç§å¹¶é™ä½äº†VRç³»ç»Ÿæˆ–åœ¨çº¿ä¼šè®®ä¸­çš„é€šä¿¡å¸¦å®½ã€‚æ­¤å¤–ï¼Œå®ƒå¯ä»¥ç›´æ¥åº”ç”¨äºåŠ¨ç”»ã€å¡é€šåŒ–å’Œé‡æ–°ç…§æ˜ç­‰ä¸‹æ¸¸åº”ç”¨ã€‚æ›´å¤šç»†èŠ‚è¯·å‚è§æˆ‘ä»¬çš„é¡¹ç›®é¡µé¢ï¼š<a target="_blank" rel="noopener" href="https://songluchuan.github.io/StreamME/%E3%80%82">https://songluchuan.github.io/StreamME/ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2507.17029v1">PDF</a> 12 pages, 15 Figures</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºäº†StreamMEæ–¹æ³•ï¼Œä¸“æ³¨äºå¿«é€Ÿ3Då¤´åƒé‡å»ºã€‚è¯¥æ–¹æ³•å¯ä»å®æ—¶è§†é¢‘æµä¸­åŒæ­¥å½•åˆ¶å¹¶é‡å»ºå¤´åƒï¼Œæ— éœ€é¢„å…ˆç¼“å­˜æ•°æ®ï¼Œä½¿å¾—é‡å»ºçš„å¤–è§‚èƒ½å¤Ÿæ— ç¼èå…¥ä¸‹æ¸¸åº”ç”¨ã€‚å…¶æ ¸å¿ƒæ˜¯é‡‡ç”¨å³æ—¶è®­ç»ƒç­–ç•¥ï¼Œå»ºç«‹åœ¨3Dé«˜æ–¯é£æº…æŠ€æœ¯ä¹‹ä¸Šï¼Œç®€åŒ–ç‚¹äº‘åˆ†å¸ƒï¼Œæé«˜æ¸²æŸ“è´¨é‡ï¼ŒåŒæ—¶ä¿æŠ¤é¢éƒ¨éšç§å¹¶é™ä½VRç³»ç»Ÿæˆ–åœ¨çº¿ä¼šè®®çš„é€šä¿¡å¸¦å®½ã€‚å¯åº”ç”¨äºåŠ¨ç”»ã€å¡é€šåŒ–å’Œé‡ç…§æ˜ç­‰ä¸‹æ¸¸åº”ç”¨ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>StreamMEæ–¹æ³•ä¸“æ³¨äºå¿«é€Ÿ3Då¤´åƒé‡å»ºï¼Œä»å®æ—¶è§†é¢‘æµä¸­åŒæ­¥å½•åˆ¶å¹¶é‡å»ºå¤´åƒã€‚</li>
<li>é‡‡ç”¨å³æ—¶è®­ç»ƒç­–ç•¥ï¼Œæ— éœ€é¢„å…ˆç¼“å­˜æ•°æ®ï¼Œå¯æ— ç¼èå…¥ä¸‹æ¸¸åº”ç”¨ã€‚</li>
<li>æ–¹æ³•å»ºç«‹åœ¨3Dé«˜æ–¯é£æº…æŠ€æœ¯ä¹‹ä¸Šï¼Œæé«˜é¢éƒ¨è¡¨è¾¾é€‚åº”æ€§ã€‚</li>
<li>é€šè¿‡ç®€åŒ–ç‚¹äº‘åˆ†å¸ƒä¼˜åŒ–æ¸²æŸ“è´¨é‡ï¼ŒåŒæ—¶ä¿æŠ¤é¢éƒ¨éšç§ã€‚</li>
<li>é™ä½VRç³»ç»Ÿæˆ–åœ¨çº¿ä¼šè®®çš„é€šä¿¡å¸¦å®½ã€‚</li>
<li>å¯ç›´æ¥åº”ç”¨äºåŠ¨ç”»ã€å¡é€šåŒ–å’Œé‡ç…§æ˜ç­‰ä¸‹æ¸¸åº”ç”¨ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2507.17029">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-02629449751a7b8e7335e258911c30d1.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-facb3a2875aa1ff49609f4ed51701e2a.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-39db404d7510185eb41364a776ca8189.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a17537a8404bc1a4a156373cfa1392d0.jpg" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="MMS-Player-an-open-source-software-for-parametric-data-driven-animation-of-Sign-Language-avatars"><a href="#MMS-Player-an-open-source-software-for-parametric-data-driven-animation-of-Sign-Language-avatars" class="headerlink" title="MMS Player: an open source software for parametric data-driven animation   of Sign Language avatars"></a>MMS Player: an open source software for parametric data-driven animation   of Sign Language avatars</h2><p><strong>Authors:Fabrizio Nunnari, Shailesh Mishra, Patrick Gebhard</strong></p>
<p>This paper describes the MMS-Player, an open source software able to synthesise sign language animations from a novel sign language representation format called MMS (MultiModal Signstream). The MMS enhances gloss-based representations by adding information on parallel execution of signs, timing, and inflections. The implementation consists of Python scripts for the popular Blender 3D authoring tool and can be invoked via command line or HTTP API. Animations can be rendered as videos or exported in other popular 3D animation exchange formats. The software is freely available under GPL-3.0 license at <a target="_blank" rel="noopener" href="https://github.com/DFKI-SignLanguage/MMS-Player">https://github.com/DFKI-SignLanguage/MMS-Player</a>. </p>
<blockquote>
<p>æœ¬æ–‡ä»‹ç»äº†MMS-Playerè¿™ä¸€å¼€æºè½¯ä»¶ï¼Œå®ƒèƒ½å¤Ÿä»æœªç»å¤„ç†çš„æ‰‹è¯­è¡¨ç¤ºæ ¼å¼ï¼ˆç§°ä¸ºMMSï¼Œå³å¤šæ¨¡æ€æ‰‹è¯­æµï¼‰åˆæˆæ‰‹è¯­åŠ¨ç”»ã€‚MMSé€šè¿‡å¢åŠ å…³äºæ‰‹è¯­å¹¶è¡Œæ‰§è¡Œã€æ—¶é—´å’Œè¯­è°ƒçš„ä¿¡æ¯ï¼Œå¢å¼ºäº†åŸºäºæ‰‹è¯­è¯æ±‡çš„æè¿°ã€‚è¯¥å®ç°åŒ…å«é’ˆå¯¹æµè¡Œçš„Blender 3Dåˆ›ä½œå·¥å…·çš„Pythonè„šæœ¬ï¼Œå¯ä»¥é€šè¿‡å‘½ä»¤è¡Œæˆ–HTTP APIè¿›è¡Œè°ƒç”¨ã€‚åŠ¨ç”»å¯ä»¥å‘ˆç°ä¸ºè§†é¢‘æˆ–ä»¥å…¶ä»–æµè¡Œçš„3DåŠ¨ç”»äº¤æ¢æ ¼å¼å¯¼å‡ºã€‚è¯¥è½¯ä»¶å¯åœ¨GPL-3.0è®¸å¯ä¸‹å…è´¹è®¿é—®ï¼š<a target="_blank" rel="noopener" href="https://github.com/DFKI-SignLanguage/MMS-Player">https://github.com/DFKI-SignLanguage/MMS-Player</a>ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2507.16463v1">PDF</a> </p>
<p><strong>Summary</strong>ï¼š<br>æœ¬æ–‡ä»‹ç»äº†ä¸€ä¸ªåä¸ºMMS-Playerçš„å¼€æºè½¯ä»¶ï¼Œè¯¥è½¯ä»¶èƒ½å¤Ÿä»ä¸€ç§æ–°å‹çš„æ‰‹åŠ¿è¯­è¨€è¡¨ç¤ºæ ¼å¼MMSï¼ˆå¤šæ¨¡å¼æ‰‹åŠ¿æµï¼‰ä¸­åˆæˆæ‰‹åŠ¿è¯­è¨€åŠ¨ç”»ã€‚MMSé€šè¿‡å¢åŠ å…³äºæ‰‹åŠ¿å¹¶è¡Œæ‰§è¡Œã€æ—¶åºå’Œè¯­è°ƒçš„ä¿¡æ¯ï¼Œå¢å¼ºäº†åŸºäºå…‰æ³½çš„è¡¨ç¤ºã€‚è¯¥è½¯ä»¶ä½¿ç”¨Pythonè„šæœ¬ä¸ºæµè¡Œçš„Blender 3Dåˆ›ä½œå·¥å…·å®ç°ï¼Œå¯é€šè¿‡å‘½ä»¤è¡Œæˆ–HTTP APIè¿›è¡Œè°ƒç”¨ã€‚åŠ¨ç”»å¯ä»¥å‘ˆç°ä¸ºè§†é¢‘æˆ–ä»¥å…¶ä»–æµè¡Œçš„3DåŠ¨ç”»äº¤æ¢æ ¼å¼å¯¼å‡ºã€‚è¯¥è½¯ä»¶åœ¨GPL-3.0è®¸å¯ä¸‹å…è´¹æä¾›ï¼Œå¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/DFKI-SignLanguage/MMS-Player%E8%8E%B7%E5%8F%96%E3%80%82">https://github.com/DFKI-SignLanguage/MMS-Playerè·å–ã€‚</a></p>
<p><strong>Key Takeaways</strong>:</p>
<ol>
<li>MMS-Playeræ˜¯ä¸€æ¬¾å¼€æºè½¯ä»¶ï¼Œå¯ä»¥ä»MMSï¼ˆå¤šæ¨¡å¼æ‰‹åŠ¿æµï¼‰æ ¼å¼ä¸­åˆæˆæ‰‹åŠ¿è¯­è¨€åŠ¨ç”»ã€‚</li>
<li>MMSåœ¨åŸæœ‰æ‰‹åŠ¿è¯­è¨€è¡¨ç¤ºåŸºç¡€ä¸Šå¢åŠ äº†å¹¶è¡Œæ‰§è¡Œã€æ—¶åºå’Œè¯­è°ƒçš„ä¿¡æ¯ã€‚</li>
<li>è½¯ä»¶é‡‡ç”¨Pythonè„šæœ¬å®ç°ï¼Œé€‚ç”¨äºBlender 3Dåˆ›ä½œå·¥å…·ã€‚</li>
<li>å¯é€šè¿‡å‘½ä»¤è¡Œæˆ–HTTP APIè°ƒç”¨è½¯ä»¶ã€‚</li>
<li>åŠ¨ç”»å¯å‘ˆç°ä¸ºè§†é¢‘ï¼Œä¹Ÿå¯å¯¼å‡ºä¸ºå…¶ä»–æµè¡Œçš„3DåŠ¨ç”»äº¤æ¢æ ¼å¼ã€‚</li>
<li>è½¯ä»¶åœ¨GPL-3.0è®¸å¯ä¸‹å…è´¹æä¾›ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2507.16463">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-d4e901ef07082204aae1cc253a6c9428.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a288fba734fad3aa68e524aab77853e5.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-bf85e62566f439c0f80e37cd26dcce17.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-73bae2c71257d7b559a3732df7ab38f4.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-362c36836e849de2225dee487eb85c3c.jpg" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1><h2 id="Dream-Lift-Animate-From-Single-Images-to-Animatable-Gaussian-Avatars"><a href="#Dream-Lift-Animate-From-Single-Images-to-Animatable-Gaussian-Avatars" class="headerlink" title="Dream, Lift, Animate: From Single Images to Animatable Gaussian Avatars"></a>Dream, Lift, Animate: From Single Images to Animatable Gaussian Avatars</h2><p><strong>Authors:Marcel C. BÃ¼hler, Ye Yuan, Xueting Li, Yangyi Huang, Koki Nagano, Umar Iqbal</strong></p>
<p>We introduce Dream, Lift, Animate (DLA), a novel framework that reconstructs animatable 3D human avatars from a single image. This is achieved by leveraging multi-view generation, 3D Gaussian lifting, and pose-aware UV-space mapping of 3D Gaussians. Given an image, we first dream plausible multi-views using a video diffusion model, capturing rich geometric and appearance details. These views are then lifted into unstructured 3D Gaussians. To enable animation, we propose a transformer-based encoder that models global spatial relationships and projects these Gaussians into a structured latent representation aligned with the UV space of a parametric body model. This latent code is decoded into UV-space Gaussians that can be animated via body-driven deformation and rendered conditioned on pose and viewpoint. By anchoring Gaussians to the UV manifold, our method ensures consistency during animation while preserving fine visual details. DLA enables real-time rendering and intuitive editing without requiring post-processing. Our method outperforms state-of-the-art approaches on ActorsHQ and 4D-Dress datasets in both perceptual quality and photometric accuracy. By combining the generative strengths of video diffusion models with a pose-aware UV-space Gaussian mapping, DLA bridges the gap between unstructured 3D representations and high-fidelity, animation-ready avatars. </p>
<blockquote>
<p>æˆ‘ä»¬ä»‹ç»äº†Dreamã€Liftã€Animateï¼ˆDLAï¼‰ï¼Œè¿™æ˜¯ä¸€ç§ä»å•å¼ å›¾åƒé‡å»ºå¯åŠ¨ç”»çš„3Däººç±»è™šæ‹Ÿå¶åƒçš„æ–°å‹æ¡†æ¶ã€‚è¿™é€šè¿‡åˆ©ç”¨å¤šè§†è§’ç”Ÿæˆã€3Dé«˜æ–¯æå‡å’Œå§¿æ€æ„ŸçŸ¥çš„UVç©ºé—´é«˜æ–¯æ˜ å°„æ¥å®ç°ã€‚ç»™å®šä¸€å¼ å›¾åƒï¼Œæˆ‘ä»¬é¦–å…ˆä½¿ç”¨è§†é¢‘æ‰©æ•£æ¨¡å‹æ¢¦æƒ³å‡ºåˆç†çš„å¤šè§†è§’ï¼Œæ•æ‰ä¸°å¯Œçš„å‡ ä½•å’Œå¤–è§‚ç»†èŠ‚ã€‚ç„¶åï¼Œè¿™äº›è§†è§’è¢«æå‡ä¸ºæ— ç»“æ„çš„3Dé«˜æ–¯ã€‚ä¸ºäº†å®ç°åŠ¨ç”»æ•ˆæœï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åŸºäºå˜å‹å™¨çš„ç¼–ç å™¨ï¼Œè¯¥ç¼–ç å™¨å¯¹å…¨å±€ç©ºé—´å…³ç³»è¿›è¡Œå»ºæ¨¡ï¼Œå¹¶å°†è¿™äº›é«˜æ–¯æŠ•å½±åˆ°ä¸å‚æ•°åŒ–èº«ä½“æ¨¡å‹çš„UVç©ºé—´å¯¹é½çš„ç»“æ„åŒ–æ½œåœ¨è¡¨ç¤ºä¸­ã€‚è¿™ä¸ªæ½œåœ¨ä»£ç è¢«è§£ç æˆUVç©ºé—´çš„é«˜æ–¯ï¼Œå¯ä»¥é€šè¿‡èº«ä½“é©±åŠ¨çš„å˜å½¢è¿›è¡ŒåŠ¨ç”»å¤„ç†ï¼Œå¹¶æ ¹æ®å§¿æ€å’Œè§†ç‚¹è¿›è¡Œæ¸²æŸ“ã€‚é€šè¿‡å°†é«˜æ–¯é”šå®šåˆ°UVæµå½¢ä¸Šï¼Œæˆ‘ä»¬çš„æ–¹æ³•ç¡®ä¿äº†åŠ¨ç”»çš„ä¸€è‡´æ€§ï¼ŒåŒæ—¶ä¿ç•™äº†ç²¾ç»†çš„è§†è§‰ç»†èŠ‚ã€‚DLAå®ç°äº†å®æ—¶æ¸²æŸ“å’Œç›´è§‚ç¼–è¾‘ï¼Œæ— éœ€åæœŸå¤„ç†ã€‚æˆ‘ä»¬çš„æ–¹æ³•åœ¨ActorsHQå’Œ4D-Dressæ•°æ®é›†ä¸Šçš„æ„ŸçŸ¥è´¨é‡å’Œå…‰åº¦å‡†ç¡®æ€§æ–¹é¢éƒ½ä¼˜äºæœ€å…ˆè¿›çš„æ–¹æ³•ã€‚é€šè¿‡å°†è§†é¢‘æ‰©æ•£æ¨¡å‹çš„ç”Ÿæˆèƒ½åŠ›ä¸å§¿æ€æ„ŸçŸ¥çš„UVç©ºé—´é«˜æ–¯æ˜ å°„ç›¸ç»“åˆï¼ŒDLAåœ¨éç»“æ„åŒ–ä¸‰ç»´è¡¨ç¤ºå’Œé«˜ä¿çœŸã€åŠ¨ç”»å‡†å¤‡çš„è™šæ‹Ÿå¶åƒä¹‹é—´æ¶èµ·äº†ä¸€åº§æ¡¥æ¢ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2507.15979v1">PDF</a> </p>
<p><strong>Summary</strong>ï¼š<br>DLAæ¡†æ¶èƒ½å¤Ÿä»å•ä¸€å›¾åƒé‡å»ºå¯åŠ¨ç”»çš„3Däººç±»è§’è‰²ã€‚å®ƒåˆ©ç”¨å¤šè§’åº¦ç”Ÿæˆã€3Dé«˜æ–¯æå‡å’Œå§¿æ€æ„ŸçŸ¥UVç©ºé—´é«˜æ–¯æ˜ å°„ç­‰æŠ€æœ¯å®ç°ã€‚ç»™å®šå›¾åƒï¼Œé¦–å…ˆé€šè¿‡è§†é¢‘æ‰©æ•£æ¨¡å‹ç”Ÿæˆå¤šè§’åº¦è§†å›¾ï¼Œç„¶åæå‡åˆ°3Dé«˜æ–¯ç©ºé—´ï¼Œå†é€šè¿‡åŸºäºå˜å‹å™¨çš„ç¼–ç å™¨è¿›è¡ŒåŠ¨ç”»å¤„ç†ï¼Œå°†é«˜æ–¯æ˜ å°„åˆ°å‚æ•°åŒ–èº«ä½“æ¨¡å‹çš„UVç©ºé—´ã€‚è¿™ç§æ–¹æ³•å¯å®ç°å®æ—¶æ¸²æŸ“å’Œç›´è§‚ç¼–è¾‘ï¼Œæ— éœ€åæœŸå¤„ç†ï¼Œä¸”åœ¨ActorsHQå’Œ4D-Dressæ•°æ®é›†ä¸Šçš„è¡¨ç°ä¼˜äºç°æœ‰æ–¹æ³•ã€‚</p>
<p><strong>Key Takeaways</strong>ï¼š</p>
<ol>
<li>DLAæ¡†æ¶èƒ½ä»å•ä¸€å›¾åƒé‡å»ºå¯åŠ¨ç”»çš„3Däººç±»è§’è‰²ã€‚</li>
<li>åˆ©ç”¨è§†é¢‘æ‰©æ•£æ¨¡å‹ç”Ÿæˆå¤šè§’åº¦è§†å›¾ï¼Œä¸°å¯Œå‡ ä½•å’Œå¤–è§‚ç»†èŠ‚ã€‚</li>
<li>é€šè¿‡3Dé«˜æ–¯æå‡æŠ€æœ¯å°†è§†å›¾æå‡åˆ°3Dç©ºé—´ã€‚</li>
<li>é‡‡ç”¨åŸºäºå˜å‹å™¨çš„ç¼–ç å™¨è¿›è¡ŒåŠ¨ç”»å¤„ç†ï¼Œå°†é«˜æ–¯æ˜ å°„åˆ°å‚æ•°åŒ–èº«ä½“æ¨¡å‹çš„UVç©ºé—´ã€‚</li>
<li>æ–¹æ³•å¯å®ç°å®æ—¶æ¸²æŸ“å’Œç›´è§‚ç¼–è¾‘ï¼Œæ— éœ€åæœŸå¤„ç†ã€‚</li>
<li>åœ¨ActorsHQå’Œ4D-Dressæ•°æ®é›†ä¸Šçš„è¡¨ç°ä¼˜äºç°æœ‰æ–¹æ³•ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2507.15979">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-6161ba9eca45fca54927b8e44a8a7c0b.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-7a75902651c46718c09a3d58ad4695ad.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-1993fad8fee038706e3fcd007ea9e86e.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-42e78dccc4101aec54cd4d5c4b8796e7.jpg" align="middle">
</details>


<h1 id="-9"><a href="#-9" class="headerlink" title=""></a></h1><h2 id="TaoAvatar-Real-Time-Lifelike-Full-Body-Talking-Avatars-for-Augmented-Reality-via-3D-Gaussian-Splatting"><a href="#TaoAvatar-Real-Time-Lifelike-Full-Body-Talking-Avatars-for-Augmented-Reality-via-3D-Gaussian-Splatting" class="headerlink" title="TaoAvatar: Real-Time Lifelike Full-Body Talking Avatars for Augmented   Reality via 3D Gaussian Splatting"></a>TaoAvatar: Real-Time Lifelike Full-Body Talking Avatars for Augmented   Reality via 3D Gaussian Splatting</h2><p><strong>Authors:Jianchuan Chen, Jingchuan Hu, Gaige Wang, Zhonghua Jiang, Tiansong Zhou, Zhiwen Chen, Chengfei Lv</strong></p>
<p>Realistic 3D full-body talking avatars hold great potential in AR, with applications ranging from e-commerce live streaming to holographic communication. Despite advances in 3D Gaussian Splatting (3DGS) for lifelike avatar creation, existing methods struggle with fine-grained control of facial expressions and body movements in full-body talking tasks. Additionally, they often lack sufficient details and cannot run in real-time on mobile devices. We present TaoAvatar, a high-fidelity, lightweight, 3DGS-based full-body talking avatar driven by various signals. Our approach starts by creating a personalized clothed human parametric template that binds Gaussians to represent appearances. We then pre-train a StyleUnet-based network to handle complex pose-dependent non-rigid deformation, which can capture high-frequency appearance details but is too resource-intensive for mobile devices. To overcome this, we â€œbakeâ€ the non-rigid deformations into a lightweight MLP-based network using a distillation technique and develop blend shapes to compensate for details. Extensive experiments show that TaoAvatar achieves state-of-the-art rendering quality while running in real-time across various devices, maintaining 90 FPS on high-definition stereo devices such as the Apple Vision Pro. </p>
<blockquote>
<p>é€¼çœŸçš„3Då…¨èº«å¯¹è¯è™šæ‹Ÿäººåœ¨å¢å¼ºç°å®é¢†åŸŸå…·æœ‰å·¨å¤§çš„æ½œåŠ›ï¼Œå…¶åº”ç”¨èŒƒå›´ä»ç”µå­å•†åŠ¡ç›´æ’­åˆ°å…¨æ¯é€šä¿¡ã€‚å°½ç®¡åœ¨ç”¨äºåˆ›å»ºé€¼çœŸè™šæ‹Ÿäººçš„3Dé«˜æ–¯æ‹¼è´´ï¼ˆ3DGSï¼‰æ–¹é¢å–å¾—äº†è¿›å±•ï¼Œä½†ç°æœ‰æ–¹æ³•åœ¨å…¨èº«å¯¹è¯ä»»åŠ¡ä¸­çš„é¢éƒ¨è¡¨æƒ…å’Œèº¯ä½“åŠ¨ä½œçš„ç²¾ç»†æ§åˆ¶æ–¹é¢ä»é¢ä¸´æŒ‘æˆ˜ã€‚æ­¤å¤–ï¼Œå®ƒä»¬é€šå¸¸ç¼ºä¹è¶³å¤Ÿçš„ç»†èŠ‚ï¼Œæ— æ³•åœ¨ç§»åŠ¨è®¾å¤‡ä¸Šå®æ—¶è¿è¡Œã€‚æˆ‘ä»¬æ¨å‡ºäº†TaoAvatarï¼Œä¸€ä¸ªç”±å„ç§ä¿¡å·é©±åŠ¨çš„é«˜ä¿çœŸã€è½»é‡çº§çš„3DGSå…¨èº«å¯¹è¯è™šæ‹Ÿäººã€‚æˆ‘ä»¬çš„æ–¹æ³•é¦–å…ˆæ˜¯é€šè¿‡åˆ›å»ºä¸ªæ€§åŒ–çš„ç©¿è¡£äººç±»å‚æ•°æ¨¡æ¿æ¥ç»‘å®šé«˜æ–¯å€¼ä»¥è¡¨ç¤ºå¤–è§‚ã€‚ç„¶åï¼Œæˆ‘ä»¬åŸºäºStyleUnetç½‘ç»œè¿›è¡Œé¢„å…ˆè®­ç»ƒï¼Œä»¥å¤„ç†å¤æ‚çš„å§¿åŠ¿ç›¸å…³çš„éåˆšæ€§å˜å½¢ï¼Œè¯¥ç½‘ç»œèƒ½å¤Ÿæ•æ‰é«˜é¢‘å¤–è§‚ç»†èŠ‚ï¼Œä½†å¯¹äºç§»åŠ¨è®¾å¤‡æ¥è¯´èµ„æºè¿‡äºå¯†é›†ã€‚ä¸ºäº†å…‹æœè¿™ä¸€ç‚¹ï¼Œæˆ‘ä»¬ä½¿ç”¨è’¸é¦æŠ€æœ¯å°†éåˆšæ€§å˜å½¢â€œçƒ˜ç„™â€åˆ°ä¸€ä¸ªåŸºäºMLPçš„è½»é‡çº§ç½‘ç»œä¸­ï¼Œå¹¶å¼€å‘æ··åˆå½¢çŠ¶æ¥è¡¥å¿ç»†èŠ‚ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼ŒTaoAvataråœ¨è¿½æ±‚å®æ—¶æ¸²æŸ“çš„åŒæ—¶è¾¾åˆ°äº†ä¸šç•Œé¢†å…ˆçš„æ¸²æŸ“è´¨é‡ï¼Œåœ¨å„ç§è®¾å¤‡ä¸Šå‡èƒ½å®æ—¶è¿è¡Œï¼Œåœ¨é«˜åˆ†è¾¨ç‡ç«‹ä½“å£°è®¾å¤‡å¦‚Apple Vision Proä¸Šä¿æŒ90 FPSã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.17032v2">PDF</a> Accepted by CVPR 2025 (Highlight), project page:   <a target="_blank" rel="noopener" href="https://pixelai-team.github.io/TaoAvatar">https://PixelAI-Team.github.io/TaoAvatar</a></p>
<p><strong>Summary</strong>ï¼š</p>
<p>é¢å‘å¢å¼ºç°å®åº”ç”¨çš„çœŸå®3Då…¨èº«å¯¹è¯è™šæ‹Ÿäººå…·æœ‰å·¨å¤§æ½œåŠ›ï¼Œæ¶µç›–ç”µå•†ç›´æ’­ã€å…¨æ¯é€šä¿¡ç­‰é¢†åŸŸã€‚é’ˆå¯¹ç°æœ‰æ–¹æ³•åœ¨ç²¾ç»†é¢éƒ¨è¡¨æƒ…å’Œå…¨èº«åŠ¨ä½œæ§åˆ¶ä¸Šçš„ä¸è¶³ï¼Œæå‡ºä¸€ç§åŸºäº3Dé«˜æ–¯æ‹¼è´´æŠ€æœ¯çš„é«˜ä¿çœŸã€è½»é‡çº§å…¨èº«å¯¹è¯è™šæ‹ŸäººTaoAvatarã€‚é€šè¿‡åˆ›å»ºä¸ªæ€§åŒ–æ¨¡æ¿å’Œé¢„è®­ç»ƒç½‘ç»œå¤„ç†å¤æ‚å§¿åŠ¿ç›¸å…³çš„éåˆšæ€§å˜å½¢ï¼Œå¹¶é‡‡ç”¨è’¸é¦æŠ€æœ¯å’Œæ··åˆå½¢çŠ¶æŠ€æœ¯å®ç°é«˜è´¨é‡æ¸²æŸ“å’Œå®æ—¶è¿è¡Œã€‚TaoAvataråœ¨Apple Vision Proç­‰é«˜æ¸…ç«‹ä½“è®¾å¤‡ä¸Šå®ç°äº†æ¯ç§’90å¸§çš„å®æ—¶æ¸²æŸ“æ€§èƒ½ã€‚</p>
<p><strong>Key Takeaways</strong>:</p>
<ol>
<li>çœŸå®3Då…¨èº«å¯¹è¯è™šæ‹Ÿäººåœ¨ARé¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ï¼ŒåŒ…æ‹¬ç”µå•†ç›´æ’­å’Œå…¨æ¯é€šä¿¡ç­‰ã€‚</li>
<li>ç°æœ‰æ–¹æ³•åœ¨ç²¾ç»†é¢éƒ¨è¡¨æƒ…å’Œå…¨èº«åŠ¨ä½œæ§åˆ¶ä¸Šå­˜åœ¨æŒ‘æˆ˜ã€‚</li>
<li>TaoAvataråŸºäº3Dé«˜æ–¯æ‹¼è´´æŠ€æœ¯ï¼Œæ—¨åœ¨è§£å†³è¿™äº›é—®é¢˜å¹¶å®ç°é«˜ä¿çœŸæ¸²æŸ“ã€‚</li>
<li>åˆ›å»ºä¸ªæ€§åŒ–æ¨¡æ¿ä»¥è¡¨ç¤ºå¤–è§‚ï¼Œå¹¶é¢„è®­ç»ƒç½‘ç»œå¤„ç†å¤æ‚å§¿åŠ¿çš„éåˆšæ€§å˜å½¢ã€‚</li>
<li>é‡‡ç”¨è’¸é¦æŠ€æœ¯å°†éåˆšæ€§å˜å½¢â€œçƒ˜ç„™â€åˆ°è½»é‡çº§MLPç½‘ç»œä¸­ã€‚</li>
<li>å‘å±•æ··åˆå½¢çŠ¶æŠ€æœ¯ä»¥è¡¥å¿ç»†èŠ‚æŸå¤±ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.17032">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-d7c6fc7f90c9ecf5776ccb3ce30576ed.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-862ccee15de60e9a0bb0b546ea2e0803.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-708c54c5743edb92f1155d68fe2c3af3.jpg" align="middle">
</details>


<h1 id="-10"><a href="#-10" class="headerlink" title=""></a></h1><h2 id="StrandHead-Text-to-Hair-Disentangled-3D-Head-Avatars-Using-Human-Centric-Priors"><a href="#StrandHead-Text-to-Hair-Disentangled-3D-Head-Avatars-Using-Human-Centric-Priors" class="headerlink" title="StrandHead: Text to Hair-Disentangled 3D Head Avatars Using   Human-Centric Priors"></a>StrandHead: Text to Hair-Disentangled 3D Head Avatars Using   Human-Centric Priors</h2><p><strong>Authors:Xiaokun Sun, Zeyu Cai, Ying Tai, Jian Yang, Zhenyu Zhang</strong></p>
<p>While haircut indicates distinct personality, existing avatar generation methods fail to model practical hair due to the data limitation or entangled representation. We propose StrandHead, a novel text-driven method capable of generating 3D hair strands and disentangled head avatars with strand-level attributes. Instead of using large-scale hair-text paired data for supervision, we demonstrate that realistic hair strands can be generated from prompts by distilling 2D generative models pre-trained on human mesh data. To this end, we propose a meshing approach guided by strand geometry to guarantee the gradient flow from the distillation objective to the neural strand representation. The optimization is then regularized by statistically significant haircut features, leading to stable updating of strands against unreasonable drifting. These employed 2D&#x2F;3D human-centric priors contribute to text-aligned and realistic 3D strand generation. Extensive experiments show that StrandHead achieves the state-of-the-art performance on text to strand generation and disentangled 3D head avatar modeling. The generated 3D hair can be applied on avatars for strand-level editing, as well as implemented in the graphics engine for physical simulation or other applications. Project page: <a target="_blank" rel="noopener" href="https://xiaokunsun.github.io/StrandHead.github.io/">https://xiaokunsun.github.io/StrandHead.github.io/</a>. </p>
<blockquote>
<p>è™½ç„¶å‘å‹å¯ä»¥æ˜¾ç¤ºä¸ªæ€§ï¼Œä½†ç°æœ‰çš„åŒ–èº«ç”Ÿæˆæ–¹æ³•ç”±äºå—æ•°æ®é™åˆ¶æˆ–è¡¨ç¤ºçº ç¼ è€Œæ— æ³•æ¨¡æ‹Ÿå®é™…å‘å‹ã€‚æˆ‘ä»¬æå‡ºä¸€ç§åä¸ºStrandHeadçš„æ–°å‹æ–‡æœ¬é©±åŠ¨æ–¹æ³•ï¼Œèƒ½å¤Ÿç”Ÿæˆ3Då‘ä¸å’Œæ²¡æœ‰çº ç¼ çš„å¤´åŒ–èº«ï¼Œå¹¶å…·æœ‰å‘ä¸çº§åˆ«çš„å±æ€§ã€‚æˆ‘ä»¬è¯æ˜äº†ä¸éœ€è¦å¤§è§„æ¨¡çš„å‘å‹æ–‡æœ¬é…å¯¹æ•°æ®è¿›è¡Œç›‘ç£ï¼Œé€šè¿‡è’¸é¦é¢„å…ˆè®­ç»ƒåœ¨äººç±»ç½‘æ ¼æ•°æ®ä¸Šçš„2Dç”Ÿæˆæ¨¡å‹ï¼Œå°±å¯ä»¥ä»æç¤ºä¸­ç”Ÿæˆé€¼çœŸçš„å‘ä¸ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§ç”±å‘ä¸å‡ ä½•å½¢çŠ¶å¼•å¯¼çš„ç½‘æ ¼åŒ–æ–¹æ³•ï¼Œä»¥ä¿è¯ä»è’¸é¦ç›®æ ‡åˆ°ç¥ç»å‘ä¸è¡¨ç¤ºçš„æ¢¯åº¦æµã€‚ç„¶åï¼Œé€šè¿‡ç»Ÿè®¡ä¸Šæ˜¾è‘—çš„å‘å‹ç‰¹å¾å¯¹ä¼˜åŒ–è¿›è¡Œæ­£åˆ™åŒ–ï¼Œé˜²æ­¢å‘ä¸åœ¨ä¸åˆç†çš„æ–¹å‘ä¸Šæ¼‚ç§»ï¼Œä»è€Œå®ç°ç¨³å®šçš„æ›´æ–°ã€‚è¿™äº›æ‰€é‡‡ç”¨çš„2D&#x2F;3Dä»¥äººç±»ä¸ºä¸­å¿ƒçš„å…ˆéªŒçŸ¥è¯†æœ‰åŠ©äºå®ç°ä¸æ–‡æœ¬å¯¹é½ä¸”é€¼çœŸçš„3Då‘ä¸ç”Ÿæˆã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼ŒStrandHeadåœ¨æ–‡æœ¬åˆ°å‘ä¸ç”Ÿæˆå’Œå»çº ç¼ çš„3Då¤´åŒ–èº«å»ºæ¨¡æ–¹é¢è¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚ç”Ÿæˆçš„3Då‘å‹å¯åº”ç”¨äºåŒ–èº«å‘ä¸çº§åˆ«çš„ç¼–è¾‘ï¼Œå¹¶å¯åœ¨å›¾å½¢å¼•æ“ä¸­å®ç°ç‰©ç†æ¨¡æ‹Ÿæˆ–å…¶ä»–åº”ç”¨ã€‚é¡¹ç›®é¡µé¢ï¼š<a target="_blank" rel="noopener" href="https://xiaokunsun.github.io/StrandHead.github.io/%E3%80%82">https://xiaokunsun.github.io/StrandHead.github.io/ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.11586v3">PDF</a> Accepted by ICCV 2025</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸ºStrandHeadçš„æ–°å‹æ–‡æœ¬é©±åŠ¨æ–¹æ³•ï¼Œèƒ½å¤Ÿç”Ÿæˆ3Då‘ä¸å¹¶èƒ½å¤Ÿè§£è€¦å¤´éƒ¨è™šæ‹Ÿå½¢è±¡ã€‚è¯¥æ–¹æ³•é€šè¿‡è’¸é¦é¢„è®­ç»ƒåœ¨äººä½“ç½‘æ ¼æ•°æ®ä¸Šçš„2Dç”Ÿæˆæ¨¡å‹ï¼Œä»æç¤ºä¸­ç”ŸæˆçœŸå®å‘ä¸ã€‚é‡‡ç”¨ç”±å‘ä¸å‡ ä½•å¼•å¯¼çš„ç½‘æ ¼æ–¹æ³•ï¼Œç¡®ä¿ä»è’¸é¦ç›®æ ‡åˆ°ç¥ç»å‘ä¸è¡¨ç¤ºçš„æ¢¯åº¦æµã€‚é€šè¿‡ç»Ÿè®¡æ˜¾è‘—çš„å‘å‹ç‰¹å¾è¿›è¡Œæ­£åˆ™åŒ–ä¼˜åŒ–ï¼Œä½¿å‘ä¸æ›´æ–°ç¨³å®šï¼Œé¿å…ä¸åˆç†æ¼‚ç§»ã€‚æ‰€é‡‡çº³çš„2D&#x2F;3Däººä½“ä¼˜å…ˆç­–ç•¥æœ‰åŠ©äºå®ç°æ–‡æœ¬å¯¹é½å’ŒçœŸå®çš„3Då‘ä¸ç”Ÿæˆã€‚å®éªŒè¡¨æ˜ï¼ŒStrandHeadåœ¨æ–‡æœ¬åˆ°å‘ä¸ç”Ÿæˆå’Œè§£è€¦3Då¤´éƒ¨è™šæ‹Ÿå½¢è±¡å»ºæ¨¡æ–¹é¢è¾¾åˆ°æœ€æ–°æŠ€æœ¯æ°´å¹³ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>StrandHeadæ˜¯ä¸€ç§æ–°å‹çš„æ–‡æœ¬é©±åŠ¨æ–¹æ³•ï¼Œèƒ½å¤Ÿç”Ÿæˆ3Då‘ä¸å¹¶è§£è€¦å¤´éƒ¨è™šæ‹Ÿå½¢è±¡ã€‚</li>
<li>é€šè¿‡è’¸é¦é¢„è®­ç»ƒçš„2Dç”Ÿæˆæ¨¡å‹ï¼Œä»æç¤ºä¸­ç”ŸæˆçœŸå®å‘ä¸ã€‚</li>
<li>é‡‡ç”¨ç”±å‘ä¸å‡ ä½•å¼•å¯¼çš„ç½‘æ ¼æ–¹æ³•ï¼Œç¡®ä¿ä»è’¸é¦ç›®æ ‡çš„æ¢¯åº¦æµåˆ°ç¥ç»å‘ä¸è¡¨ç¤ºã€‚</li>
<li>é€šè¿‡ç»Ÿè®¡æ˜¾è‘—çš„å‘å‹ç‰¹å¾è¿›è¡Œæ­£åˆ™åŒ–ä¼˜åŒ–ï¼Œç¨³å®šå‘ä¸æ›´æ–°ã€‚</li>
<li>é‡‡çº³çš„2D&#x2F;3Däººä½“ä¼˜å…ˆç­–ç•¥æœ‰åŠ©äºå®ç°æ–‡æœ¬å¯¹é½å’ŒçœŸå®çš„3Då‘ä¸ç”Ÿæˆã€‚</li>
<li>StrandHeadåœ¨æ–‡æœ¬åˆ°å‘ä¸ç”Ÿæˆå’Œè§£è€¦3Då¤´éƒ¨è™šæ‹Ÿå½¢è±¡å»ºæ¨¡æ–¹é¢è¾¾åˆ°æœ€æ–°æŠ€æœ¯æ°´å¹³ã€‚</li>
<li>ç”Ÿæˆçš„3Då‘ä¸å¯ç”¨äºè™šæ‹Ÿå½¢è±¡çš„å‘ä¸çº§åˆ«ç¼–è¾‘ï¼Œå¹¶å¯åº”ç”¨äºå›¾å½¢å¼•æ“è¿›è¡Œç‰©ç†æ¨¡æ‹Ÿæˆ–å…¶ä»–åº”ç”¨ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.11586">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-6a0fc3964f3d77301fe468f43e3dcc17.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-51a665740d01f0f966c33f3534122596.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-76347c133a66f3c90c13940c92f6bb52.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-1b9c00e67eba53cedb919645d11b2f37.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-7e2e3de758d25f5572cf3bff0f9ab667.jpg" align="middle">
</details>


<h1 id="-11"><a href="#-11" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-08-01/%E5%85%83%E5%AE%87%E5%AE%99_%E8%99%9A%E6%8B%9F%E4%BA%BA/">https://kedreamix.github.io/Talk2Paper/Paper/2025-08-01/%E5%85%83%E5%AE%87%E5%AE%99_%E8%99%9A%E6%8B%9F%E4%BA%BA/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/%E5%85%83%E5%AE%87%E5%AE%99-%E8%99%9A%E6%8B%9F%E4%BA%BA/">
                                    <span class="chip bg-color">å…ƒå®‡å®™/è™šæ‹Ÿäºº</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-08-01/3DGS/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-c20ea647f542e878705d061131ccfb2a.jpg" class="responsive-img" alt="3DGS">
                        
                        <span class="card-title">3DGS</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            3DGS æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-08-02  Gaussian Variation Field Diffusion for High-fidelity Video-to-4D   Synthesis
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-08-02
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/3DGS/" class="post-category">
                                    3DGS
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/3DGS/">
                        <span class="chip bg-color">3DGS</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-08-01/GAN/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-f55b25dd93b83437b5e43038bd3e0a8f.jpg" class="responsive-img" alt="GAN">
                        
                        <span class="card-title">GAN</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            GAN æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-08-02  IN45023 Neural Network Design Patterns in Computer Vision Seminar   Report, Summer 2025
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-08-02
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/GAN/" class="post-category">
                                    GAN
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/GAN/">
                        <span class="chip bg-color">GAN</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">26551.5k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
