<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Speech">
    <meta name="description" content="Speech æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-01-29  Mixture-of-Mamba Enhancing Multi-Modal State-Space Models with   Modality-Aware Sparsity">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>Speech | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://pic1.zhimg.com/v2-856797e45217b0a2fa09970219a9b08c.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Speech</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/Speech/">
                                <span class="chip bg-color">Speech</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/Speech/" class="post-category">
                                Speech
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-01-29
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-02-12
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    6.5k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    26 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-01-29-æ›´æ–°"><a href="#2025-01-29-æ›´æ–°" class="headerlink" title="2025-01-29 æ›´æ–°"></a>2025-01-29 æ›´æ–°</h1><h2 id="Mixture-of-Mamba-Enhancing-Multi-Modal-State-Space-Models-with-Modality-Aware-Sparsity"><a href="#Mixture-of-Mamba-Enhancing-Multi-Modal-State-Space-Models-with-Modality-Aware-Sparsity" class="headerlink" title="Mixture-of-Mamba: Enhancing Multi-Modal State-Space Models with   Modality-Aware Sparsity"></a>Mixture-of-Mamba: Enhancing Multi-Modal State-Space Models with   Modality-Aware Sparsity</h2><p><strong>Authors:Weixin Liang, Junhong Shen, Genghan Zhang, Ning Dong, Luke Zettlemoyer, Lili Yu</strong></p>
<p>State Space Models (SSMs) have emerged as efficient alternatives to Transformers for sequential modeling, but their inability to leverage modality-specific features limits their performance in multi-modal pretraining. Here, we propose Mixture-of-Mamba, a novel SSM architecture that introduces modality-aware sparsity through modality-specific parameterization of the Mamba block. Building on Mixture-of-Transformers (W. Liang et al. arXiv:2411.04996; 2024), we extend the benefits of modality-aware sparsity to SSMs while preserving their computational efficiency. We evaluate Mixture-of-Mamba across three multi-modal pretraining settings: Transfusion (interleaved text and continuous image tokens with diffusion loss), Chameleon (interleaved text and discrete image tokens), and an extended three-modality framework incorporating speech. Mixture-of-Mamba consistently reaches the same loss values at earlier training steps with significantly reduced computational costs. In the Transfusion setting, Mixture-of-Mamba achieves equivalent image loss using only 34.76% of the training FLOPs at the 1.4B scale. In the Chameleon setting, Mixture-of-Mamba reaches similar image loss with just 42.50% of the FLOPs at the 1.4B scale, and similar text loss with just 65.40% of the FLOPs. In the three-modality setting, MoM matches speech loss at 24.80% of the FLOPs at the 1.4B scale. Our ablation study highlights the synergistic effects of decoupling projection components, where joint decoupling yields greater gains than individual modifications. These results establish modality-aware sparsity as a versatile and effective design principle, extending its impact from Transformers to SSMs and setting new benchmarks in multi-modal pretraining. Our code can be accessed at <a target="_blank" rel="noopener" href="https://github.com/Weixin-Liang/Mixture-of-Mamba">https://github.com/Weixin-Liang/Mixture-of-Mamba</a> </p>
<blockquote>
<p>çŠ¶æ€ç©ºé—´æ¨¡å‹ï¼ˆSSMsï¼‰ä½œä¸ºåºåˆ—å»ºæ¨¡çš„æœ‰æ•ˆæ›¿ä»£æ–¹æ¡ˆï¼Œå·²ç»å´­éœ²å¤´è§’ã€‚ç„¶è€Œï¼Œå®ƒä»¬æ— æ³•åˆ©ç”¨ç‰¹å®šæ¨¡æ€çš„ç‰¹å¾ï¼Œè¿™åœ¨å¤šæ¨¡æ€é¢„è®­ç»ƒä¸­é™åˆ¶äº†æ€§èƒ½ã€‚åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬æå‡ºäº†åä¸ºMixture-of-Mambaçš„æ–°å‹SSMæ¶æ„ï¼Œå®ƒé€šè¿‡Mambaå—çš„ç‰¹å®šæ¨¡æ€å‚æ•°åŒ–å¼•å…¥äº†æ¨¡æ€æ„ŸçŸ¥ç¨€ç–æ€§ã€‚åŸºäºMixture-of-Transformersï¼ˆW. Liangç­‰äººï¼ŒarXiv:2411.04996ï¼›2024ï¼‰ï¼Œæˆ‘ä»¬å°†æ¨¡æ€æ„ŸçŸ¥ç¨€ç–æ€§çš„å¥½å¤„æ‰©å±•åˆ°SSMï¼ŒåŒæ—¶ä¿æŒå…¶è®¡ç®—æ•ˆç‡ã€‚æˆ‘ä»¬åœ¨ä¸‰ç§å¤šæ¨¡æ€é¢„è®­ç»ƒç¯å¢ƒä¸­è¯„ä¼°äº†Mixture-of-Mambaçš„æ•ˆæœï¼šTransfusionï¼ˆäº¤æ›¿æ–‡æœ¬å’Œè¿ç»­å›¾åƒä»¤ç‰Œä¸æ‰©æ•£æŸå¤±ï¼‰ã€Chameleonï¼ˆäº¤æ›¿æ–‡æœ¬å’Œç¦»æ•£å›¾åƒä»¤ç‰Œï¼‰ï¼Œä»¥åŠä¸€ä¸ªåŒ…å«è¯­éŸ³çš„æ‰©å±•ä¸‰æ¨¡æ€æ¡†æ¶ã€‚Mixture-of-Mambaåœ¨è¾ƒæ—©çš„è®­ç»ƒæ­¥éª¤ä¸­å§‹ç»ˆè¾¾åˆ°ç›¸åŒçš„æŸå¤±å€¼ï¼Œå¹¶å¤§å¤§é™ä½äº†è®¡ç®—æˆæœ¬ã€‚åœ¨Transfusionè®¾ç½®ä¸­ï¼ŒMixture-of-Mambaä»…ä½¿ç”¨34.76%çš„è®­ç»ƒæµ®ç‚¹è¿ç®—é‡å°±è¾¾åˆ°äº†ç›¸å½“çš„å›¾åƒæŸå¤±å€¼åœ¨è§„æ¨¡ä¸º1.4Bæ—¶ã€‚åœ¨Chameleonè®¾ç½®ä¸­ï¼ŒMixture-of-Mambaåœ¨è§„æ¨¡ä¸º1.4Bæ—¶ä»…ä»¥42.5%çš„æµ®ç‚¹è¿ç®—é‡è¾¾åˆ°ç›¸ä¼¼çš„å›¾åƒæŸå¤±å€¼ï¼Œå¹¶ä»¥ä»…65.4%çš„æµ®ç‚¹è¿ç®—é‡è¾¾åˆ°ç›¸ä¼¼çš„æ–‡æœ¬æŸå¤±å€¼ã€‚åœ¨ä¸‰æ¨¡æ€è®¾ç½®ä¸­ï¼ŒMoMåœ¨è§„æ¨¡ä¸º1.4Bæ—¶ä»…ä»¥24.8%çš„æµ®ç‚¹è¿ç®—é‡è¾¾åˆ°è¯­éŸ³æŸå¤±åŒ¹é…æ°´å¹³ã€‚æˆ‘ä»¬çš„æ¶ˆèç ”ç©¶çªå‡ºäº†åˆ†ç¦»æŠ•å½±ç»„ä»¶çš„ååŒä½œç”¨ï¼Œè”åˆåˆ†ç¦»æ¯”å•ç‹¬ä¿®æ”¹èƒ½è·å¾—æ›´å¤§çš„æ”¶ç›Šã€‚è¿™äº›ç»“æœç¡®ç«‹äº†æ¨¡æ€æ„ŸçŸ¥ç¨€ç–æ€§ä½œä¸ºä¸€ç§é€šç”¨ä¸”æœ‰æ•ˆçš„è®¾è®¡åŸåˆ™çš„åœ°ä½ï¼Œå°†å…¶å½±å“ä»Transformeræ‰©å±•åˆ°SSMï¼Œå¹¶ä¸ºå¤šæ¨¡æ€é¢„è®­ç»ƒè®¾å®šäº†æ–°çš„åŸºå‡†ã€‚æˆ‘ä»¬çš„ä»£ç å¯è®¿é—®äº <a target="_blank" rel="noopener" href="https://github.com/Weixin-Liang/Mixture-of-Mamba">https://github.com/Weixin-Liang/Mixture-of-Mamba</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.16295v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>çŠ¶æ€ç©ºé—´æ¨¡å‹ï¼ˆSSMsï¼‰ä½œä¸ºåºåˆ—å»ºæ¨¡çš„æœ‰æ•ˆæ›¿ä»£æ–¹æ¡ˆï¼Œå±•ç°å‡ºå…¶é«˜æ•ˆæ€§ï¼Œä½†åœ¨å¤šæ¨¡æ€é¢„è®­ç»ƒä¸­çš„æ€§èƒ½å—é™äºæ— æ³•åˆ©ç”¨æ¨¡æ€ç‰¹å®šç‰¹å¾ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬æå‡ºäº†Mixture-of-Mambaè¿™ä¸€æ–°å‹SSMæ¶æ„ï¼Œå®ƒé€šè¿‡æ¨¡æ€ç‰¹å®šå‚æ•°åŒ–Mambaå—å¼•å…¥æ¨¡æ€æ„ŸçŸ¥ç¨€ç–æ€§ã€‚åœ¨Mixture-of-Transformersçš„åŸºç¡€ä¸Šï¼Œæˆ‘ä»¬æ‹“å±•äº†æ¨¡æ€æ„ŸçŸ¥ç¨€ç–æ€§çš„ä¼˜åŠ¿è‡³SSMï¼ŒåŒæ—¶ä¿æŒäº†å…¶è®¡ç®—æ•ˆç‡ã€‚Mixture-of-Mambaåœ¨å¤šæ¨¡æ€é¢„è®­ç»ƒçš„ä¸‰ç§è®¾ç½®ä¸­è¿›è¡Œäº†è¯„ä¼°ï¼šèåˆï¼ˆæ–‡æœ¬å’Œè¿ç»­å›¾åƒæ ‡è®°äº¤æ›¿å‡ºç°å¹¶ä½¿ç”¨æ‰©æ•£æŸå¤±ï¼‰ã€å˜è‰²é¾™ï¼ˆäº¤æ›¿ä½¿ç”¨æ–‡æœ¬å’Œç¦»æ•£å›¾åƒæ ‡è®°ï¼‰ï¼Œä»¥åŠä¸€ä¸ªåŒ…å«è¯­éŸ³çš„ä¸‰æ¨¡æ€æ‰©å±•æ¡†æ¶ã€‚Mixture-of-Mambaåœ¨å‡å°‘è®¡ç®—æˆæœ¬çš„åŒæ—¶ï¼Œèƒ½å¤Ÿåœ¨æ—©æœŸè®­ç»ƒæ­¥éª¤è¾¾åˆ°ç›¸åŒçš„æŸå¤±å€¼ã€‚åœ¨èåˆè®¾ç½®ä¸­ï¼ŒMixture-of-Mambaä»…ä½¿ç”¨34.76%çš„è®­ç»ƒæµ®ç‚¹è¿ç®—ï¼ˆFLOPsï¼‰ä¾¿è¾¾åˆ°ç›¸åŒçš„å›¾åƒæŸå¤±å€¼ã€‚åœ¨å˜è‰²é¾™è®¾ç½®ä¸­ï¼Œå®ƒåœ¨1.4Bè§„æ¨¡ä¸‹ä»¥42.5%çš„FLOPsè¾¾åˆ°ç›¸ä¼¼çš„å›¾åƒæŸå¤±ï¼Œå¹¶ä»¥65.4%çš„FLOPsè¾¾åˆ°ç›¸ä¼¼çš„æ–‡æœ¬æŸå¤±ã€‚åœ¨ä¸‰æ¨¡æ€è®¾ç½®ä¸­ï¼ŒMoMåœ¨1.4Bè§„æ¨¡ä¸‹ä»¥24.8%çš„FLOPsåŒ¹é…è¯­éŸ³æŸå¤±ã€‚æˆ‘ä»¬çš„æ¶ˆèç ”ç©¶çªå‡ºäº†åˆ†ç¦»æŠ•å½±ç»„ä»¶çš„ååŒä½œç”¨ï¼Œè”åˆåˆ†ç¦»æ¯”å•ç‹¬ä¿®æ”¹äº§ç”Ÿæ›´å¤§çš„æ”¶ç›Šã€‚è¿™äº›ç»“æœè¯æ˜äº†æ¨¡æ€æ„ŸçŸ¥ç¨€ç–æ€§æ˜¯ä¸€ç§é€šç”¨ä¸”æœ‰æ•ˆçš„è®¾è®¡åŸåˆ™ï¼Œå®ƒä»Transformeræ‰©å±•è‡³SSMï¼Œå¹¶ä¸ºå¤šæ¨¡æ€é¢„è®­ç»ƒè®¾å®šäº†æ–°çš„åŸºå‡†ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>çŠ¶æ€ç©ºé—´æ¨¡å‹ï¼ˆSSMsï¼‰åœ¨è®¡ç®—æ•ˆç‡ä¸Šå±•ç°å‡ºä¼˜åŠ¿ï¼Œä½†å¤šæ¨¡æ€é¢„è®­ç»ƒæ€§èƒ½å—é™ã€‚</li>
<li>Mixture-of-Mambaæ¶æ„é€šè¿‡å¼•å…¥æ¨¡æ€æ„ŸçŸ¥ç¨€ç–æ€§ï¼Œæå‡äº†SSMåœ¨å¤šæ¨¡æ€é¢„è®­ç»ƒä¸­çš„æ€§èƒ½ã€‚</li>
<li>Mixture-of-Mambaåœ¨å¤šç§å¤šæ¨¡æ€é¢„è®­ç»ƒè®¾ç½®ä¸­è¿›è¡Œè¯„ä¼°ï¼ŒåŒ…æ‹¬Transfusionã€Chameleonå’Œä¸‰æ¨¡æ€æ‰©å±•æ¡†æ¶ã€‚</li>
<li>Mixture-of-Mambaèƒ½åœ¨æ—©æœŸè®­ç»ƒæ­¥éª¤è¾¾åˆ°ç›¸åŒæŸå¤±å€¼ï¼ŒåŒæ—¶æ˜¾è‘—é™ä½è®¡ç®—æˆæœ¬ã€‚</li>
<li>åœ¨ç‰¹å®šçš„å¤šæ¨¡æ€é¢„è®­ç»ƒè®¾ç½®ä¸­ï¼ŒMixture-of-Mambaä½¿ç”¨è¾ƒå°‘çš„è®¡ç®—èµ„æºå³å¯è¾¾åˆ°ç›¸ä¼¼çš„æ€§èƒ½ã€‚</li>
<li>æ¶ˆèç ”ç©¶å¼ºè°ƒäº†åˆ†ç¦»æŠ•å½±ç»„ä»¶çš„ååŒä½œç”¨ï¼Œè”åˆåˆ†ç¦»æ•ˆæœæ›´ä½³ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.16295">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-14747c41ace67ff7773e867250de6aac.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c593bd28eb817c10d325b6d340b0adff.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-bfd5921954709e2b60233a89cba5b74c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-56724732d79d512d18d92353a3000a0e.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="Enhancing-and-Exploring-Mild-Cognitive-Impairment-Detection-with-W2V-BERT-2-0"><a href="#Enhancing-and-Exploring-Mild-Cognitive-Impairment-Detection-with-W2V-BERT-2-0" class="headerlink" title="Enhancing and Exploring Mild Cognitive Impairment Detection with   W2V-BERT-2.0"></a>Enhancing and Exploring Mild Cognitive Impairment Detection with   W2V-BERT-2.0</h2><p><strong>Authors:Yueguan Wang, Tatsunari Matsushima, Soichiro Matsushima, Toshimitsu Sakai</strong></p>
<p>This study explores a multi-lingual audio self-supervised learning model for detecting mild cognitive impairment (MCI) using the TAUKADIAL cross-lingual dataset. While speech transcription-based detection with BERT models is effective, limitations exist due to a lack of transcriptions and temporal information. To address these issues, the study utilizes features directly from speech utterances with W2V-BERT-2.0. We propose a visualization method to detect essential layers of the model for MCI classification and design a specific inference logic considering the characteristics of MCI. The experiment shows competitive results, and the proposed inference logic significantly contributes to the improvements from the baseline. We also conduct detailed analysis which reveals the challenges related to speaker bias in the features and the sensitivity of MCI classification accuracy to the data split, providing valuable insights for future research. </p>
<blockquote>
<p>æœ¬ç ”ç©¶æ¢ç´¢äº†ä¸€ç§å¤šè¯­è¨€éŸ³é¢‘è‡ªç›‘ç£å­¦ä¹ æ¨¡å‹ï¼Œè¯¥æ¨¡å‹ä½¿ç”¨TAUKADIALè·¨è¯­è¨€æ•°æ®é›†æ£€æµ‹è½»åº¦è®¤çŸ¥éšœç¢ï¼ˆMCIï¼‰ã€‚è™½ç„¶åŸºäºBERTæ¨¡å‹çš„è¯­éŸ³è½¬å½•æ£€æµ‹æ˜¯æœ‰æ•ˆçš„ï¼Œä½†ç”±äºç¼ºä¹è½¬å½•å’Œæ—¶åºä¿¡æ¯ï¼Œä»å­˜åœ¨å±€é™æ€§ã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œç ”ç©¶ç›´æ¥ä»è¯­éŸ³ç‰‡æ®µä¸­æå–ç‰¹å¾ï¼Œä½¿ç”¨W2V-BERT-2.0ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§å¯è§†åŒ–æ–¹æ³•æ¥æ£€æµ‹ç”¨äºMCIåˆ†ç±»çš„å…³é”®æ¨¡å‹å±‚ï¼Œå¹¶è®¾è®¡äº†ä¸€ç§è€ƒè™‘MCIç‰¹å¾çš„ç‰¹å®šæ¨ç†é€»è¾‘ã€‚å®éªŒæ˜¾ç¤ºç»“æœå…·æœ‰ç«äº‰åŠ›ï¼Œæ‰€æå‡ºçš„æ¨ç†é€»è¾‘å¯¹åŸºçº¿æ”¹è¿›åšå‡ºäº†é‡å¤§è´¡çŒ®ã€‚æˆ‘ä»¬è¿˜è¿›è¡Œäº†è¯¦ç»†åˆ†æï¼Œæ­ç¤ºäº†ä¸è¯´è¯è€…åè§ç›¸å…³çš„æŒ‘æˆ˜ä»¥åŠMCIåˆ†ç±»ç²¾åº¦å¯¹æ•°æ®åˆ†å‰²çš„æ•æ„Ÿæ€§ï¼Œä¸ºæœªæ¥ç ”ç©¶æä¾›äº†å®è´µè§è§£ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.16201v1">PDF</a> Submitted to ICASSP-SPADE workshop 2025</p>
<p><strong>Summary</strong></p>
<p>æœ¬ç ”ç©¶åˆ©ç”¨å¤šè¯­è¨€éŸ³é¢‘è‡ªç›‘ç£å­¦ä¹ æ¨¡å‹ï¼Œç»“åˆTAUKADIALè·¨è¯­è¨€æ•°æ®é›†ï¼Œå¯¹è½»åº¦è®¤çŸ¥éšœç¢ï¼ˆMCIï¼‰è¿›è¡Œæ£€æµ‹ã€‚ç ”ç©¶é‡‡ç”¨åŸºäºè¯­éŸ³ç‰¹å¾çš„W2V-BERT-2.0æ¨¡å‹ï¼Œå…‹æœäº†ä¾èµ–è½¬å½•çš„BERTæ¨¡å‹å› ç¼ºä¹è½¬å½•å’Œæ—¶åºä¿¡æ¯è€Œå­˜åœ¨çš„å±€é™æ€§ã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜æå‡ºäº†ä¸€ç§å¯è§†åŒ–æ–¹æ³•ï¼Œç”¨äºæ£€æµ‹ç”¨äºMCIåˆ†ç±»çš„å…³é”®æ¨¡å‹å±‚ï¼Œå¹¶è®¾è®¡äº†é’ˆå¯¹MCIç‰¹æ€§çš„æ¨ç†é€»è¾‘ã€‚å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•å…·æœ‰ç«äº‰åŠ›ï¼Œæå‡ºçš„æ¨ç†é€»è¾‘å¯¹æ”¹è¿›åŸºçº¿æœ‰æ˜¾è‘—è´¡çŒ®ã€‚åŒæ—¶ï¼Œç ”ç©¶è¿˜è¯¦ç»†åˆ†æäº†ä¸è¯´è¯è€…ç›¸å…³çš„ç‰¹å¾æŒ‘æˆ˜å’Œæ•°æ®åˆ†å‰²å¯¹MCIåˆ†ç±»ç²¾åº¦çš„å½±å“ï¼Œä¸ºæœªæ¥çš„ç ”ç©¶æä¾›äº†å®è´µè§è§£ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ç ”ç©¶é‡‡ç”¨å¤šè¯­è¨€éŸ³é¢‘è‡ªç›‘ç£å­¦ä¹ æ¨¡å‹ï¼Œåˆ©ç”¨TAUKADIALè·¨è¯­è¨€æ•°æ®é›†è¿›è¡Œè½»åº¦è®¤çŸ¥éšœç¢ï¼ˆMCIï¼‰æ£€æµ‹ã€‚</li>
<li>é’ˆå¯¹ç°æœ‰åŸºäºè¯­éŸ³è½¬å½•çš„BERTæ¨¡å‹çš„å±€é™æ€§ï¼Œå¼•å…¥åŸºäºè¯­éŸ³ç‰¹å¾çš„W2V-BERT-2.0æ¨¡å‹ã€‚</li>
<li>é¦–æ¬¡æå‡ºå¯è§†åŒ–æ–¹æ³•ä»¥æ£€æµ‹ç”¨äºMCIåˆ†ç±»çš„å…³é”®æ¨¡å‹å±‚ã€‚</li>
<li>è®¾è®¡é’ˆå¯¹MCIç‰¹æ€§çš„æ¨ç†é€»è¾‘ï¼Œæ˜¾è‘—æé«˜äº†æ£€æµ‹å‡†ç¡®ç‡ã€‚</li>
<li>å®éªŒç»“æœæ˜¾ç¤ºæ‰€æå‡ºçš„æ–¹æ³•å…·æœ‰ç«äº‰åŠ›ã€‚</li>
<li>ç ”ç©¶å‘ç°è¯´è¯è€…ç›¸å…³çš„ç‰¹å¾æŒ‘æˆ˜å¯¹MCIåˆ†ç±»çš„å½±å“ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.16201">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-9ba56485901ec948017c82e099fbf417.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-fd3e724db987cb92b9df5ee2c4c7fe24.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-8617c8707a3dba1458050f175736f363.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-d8414d8a5772f0fec74d6d9861688e20.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="Optimized-Self-supervised-Training-with-BEST-RQ-for-Speech-Recognition"><a href="#Optimized-Self-supervised-Training-with-BEST-RQ-for-Speech-Recognition" class="headerlink" title="Optimized Self-supervised Training with BEST-RQ for Speech Recognition"></a>Optimized Self-supervised Training with BEST-RQ for Speech Recognition</h2><p><strong>Authors:Ilja Baumann, Dominik Wagner, Korbinian Riedhammer, Tobias Bocklet</strong></p>
<p>Self-supervised learning has been successfully used for various speech related tasks, including automatic speech recognition. BERT-based Speech pre-Training with Random-projection Quantizer (BEST-RQ) has achieved state-of-the-art results in speech recognition. In this work, we further optimize the BEST-RQ approach using Kullback-Leibler divergence as an additional regularizing loss and multi-codebook extension per cluster derived from low-level feature clustering. Preliminary experiments on train-100 split of LibriSpeech result in a relative improvement of 11.2% on test-clean by using multiple codebooks, utilizing a combination of cross-entropy and Kullback-Leibler divergence further reduces the word error rate by 4.5%. The proposed optimizations on full LibriSpeech pre-training and fine-tuning result in relative word error rate improvements of up to 23.8% on test-clean and 30.6% on test-other using 6 codebooks. Furthermore, the proposed setup leads to faster convergence in pre-training and fine-tuning and additionally stabilizes the pre-training. </p>
<blockquote>
<p>è‡ªç›‘ç£å­¦ä¹ å·²æˆåŠŸåº”ç”¨äºå„ç§è¯­éŸ³ç›¸å…³ä»»åŠ¡ï¼ŒåŒ…æ‹¬è‡ªåŠ¨è¯­éŸ³è¯†åˆ«ã€‚åŸºäºBERTçš„éšæœºæŠ•å½±é‡åŒ–å™¨ï¼ˆBEST-RQï¼‰çš„è¯­éŸ³é¢„è®­ç»ƒåœ¨è¯­éŸ³è¯†åˆ«æ–¹é¢å–å¾—äº†æœ€å…ˆè¿›çš„æˆæœã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬è¿›ä¸€æ­¥ä½¿ç”¨Kullback-Leibleræ•£åº¦ä½œä¸ºé¢å¤–çš„æ­£åˆ™åŒ–æŸå¤±ï¼Œå¹¶åˆ©ç”¨åŸºäºä½çº§åˆ«ç‰¹å¾èšç±»çš„æ¯ä¸ªé›†ç¾¤çš„å¤šä»£ç æœ¬æ‰©å±•æ¥ä¼˜åŒ–BEST-RQæ–¹æ³•ã€‚åœ¨LibriSpeechçš„train-100åˆ†å‰²ä¸Šè¿›è¡Œåˆæ­¥å®éªŒï¼Œé€šè¿‡ä½¿ç”¨å¤šä¸ªä»£ç æœ¬ï¼Œæµ‹è¯•cleanä¸Šçš„ç›¸å¯¹æ”¹è¿›äº†11.2%ã€‚ç»“åˆäº¤å‰ç†µå’ŒKullback-Leibleræ•£åº¦ï¼Œè¿›ä¸€æ­¥é™ä½äº†å•è¯é”™è¯¯ç‡4.5%ã€‚å¯¹LibriSpeechçš„å®Œå…¨é¢„è®­ç»ƒå’Œå¾®è°ƒæå‡ºçš„ä¼˜åŒ–ï¼Œåœ¨æµ‹è¯•cleanä¸Šç›¸å¯¹å•è¯é”™è¯¯ç‡æé«˜äº†23.8%ï¼Œåœ¨æµ‹è¯•å…¶ä»–ä¸Šæé«˜äº†30.6%ï¼Œä½¿ç”¨6ä¸ªä»£ç æœ¬ã€‚æ­¤å¤–ï¼Œè¯¥è®¾ç½®è¿˜å¯¼è‡´äº†é¢„è®­ç»ƒå’Œå¾®è°ƒä¸­çš„æ›´å¿«æ”¶æ•›ï¼Œå¹¶é¢å¤–ç¨³å®šäº†é¢„è®­ç»ƒã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.16131v1">PDF</a> ICASSP 2025</p>
<p><strong>Summary</strong><br>æœ¬æ–‡ä»‹ç»äº†åŸºäºBERTçš„è¯­éŸ³é¢„è®­ç»ƒæ–¹æ³•BEST-RQçš„ä¼˜åŒ–ç ”ç©¶ã€‚é€šè¿‡ä½¿ç”¨Kullback-Leibleræ•£åº¦ä½œä¸ºé¢å¤–çš„æ­£åˆ™åŒ–æŸå¤±å’Œå¤šä»£ç æœ¬æ‰©å±•ï¼Œå¯¹LibriSpeechæ•°æ®é›†è¿›è¡Œåˆæ­¥å®éªŒï¼Œå–å¾—äº†æ˜¾è‘—çš„è¯é”™è¯¯ç‡æ”¹è¿›ã€‚ä¼˜åŒ–åçš„æ–¹æ³•åœ¨æµ‹è¯•é›†cleanä¸Šç›¸å¯¹æ”¹è¿›äº†é«˜è¾¾23.8%ï¼Œåœ¨å…¶ä»–æµ‹è¯•é›†ä¸Šç›¸å¯¹æ”¹è¿›äº†30.6%ï¼ŒåŒæ—¶ä½¿ç”¨å¤šç§ä»£ç æœ¬è¿˜èƒ½åŠ é€Ÿé¢„è®­ç»ƒå’Œå¾®è°ƒè¿‡ç¨‹çš„æ”¶æ•›ï¼Œå¹¶å¢å¼ºå…¶ç¨³å®šæ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>BERT-based Speech pre-Training with Random-projection Quantizer (BEST-RQ)å·²ç”¨äºè¯­éŸ³è¯†åˆ«ä»»åŠ¡ï¼Œå¹¶è·å¾—äº†ä¸šç•Œæœ€ä½³ç»“æœã€‚</li>
<li>ç ”ç©¶è€…å¯¹BEST-RQæ–¹æ³•è¿›è¡Œäº†ä¼˜åŒ–ï¼Œé‡‡ç”¨Kullback-Leibleræ•£åº¦ä½œä¸ºæ­£åˆ™åŒ–æŸå¤±å’Œå¤šä»£ç æœ¬æ‰©å±•æ–¹æ³•ã€‚</li>
<li>åœ¨LibriSpeechæ•°æ®é›†ä¸Šè¿›è¡Œçš„åˆæ­¥å®éªŒæ˜¾ç¤ºï¼Œä½¿ç”¨å¤šä¸ªä»£ç æœ¬ç›¸è¾ƒäºæœªä¼˜åŒ–æ¨¡å‹é™ä½äº†è¯é”™è¯¯ç‡ï¼ˆWERï¼‰ã€‚åœ¨æµ‹è¯•é›†cleanä¸Šçš„ç›¸å¯¹æ”¹è¿›è¾¾åˆ°äº†é«˜è¾¾23.8%ï¼Œåœ¨å…¶ä»–æµ‹è¯•é›†ä¸Šçš„ç›¸å¯¹æ”¹è¿›è¾¾åˆ°äº†é«˜è¾¾30.6%ã€‚</li>
<li>ç»“åˆäº¤å‰ç†µå’ŒKullback-Leibleræ•£åº¦çš„ä¼˜åŒ–æ–¹æ³•è¿›ä¸€æ­¥é™ä½äº†è¯é”™è¯¯ç‡ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.16131">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-126122bfcc926849ac66a5899fe2ff4c.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-f7b4949477a259e0d62cba0d80ab1181.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-b01835cbc5c8b0b8ad613ad3d63e3453.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-59d955566b1d17e136570dacd7b7f899.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-87289884f3e654ed26f54f21002e7088.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-4d845c74f918cb28e3802d2cd1458f6b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-80829edbd42aa38d3aa9cad9b45fec92.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="Classification-Error-Bound-for-Low-Bayes-Error-Conditions-in-Machine-Learning"><a href="#Classification-Error-Bound-for-Low-Bayes-Error-Conditions-in-Machine-Learning" class="headerlink" title="Classification Error Bound for Low Bayes Error Conditions in Machine   Learning"></a>Classification Error Bound for Low Bayes Error Conditions in Machine   Learning</h2><p><strong>Authors:Zijian Yang, Vahe Eminyan, Ralf SchlÃ¼ter, Hermann Ney</strong></p>
<p>In statistical classification and machine learning, classification error is an important performance measure, which is minimized by the Bayes decision rule. In practice, the unknown true distribution is usually replaced with a model distribution estimated from the training data in the Bayes decision rule. This substitution introduces a mismatch between the Bayes error and the model-based classification error. In this work, we apply classification error bounds to study the relationship between the error mismatch and the Kullback-Leibler divergence in machine learning. Motivated by recent observations of low model-based classification errors in many machine learning tasks, bounding the Bayes error to be lower, we propose a linear approximation of the classification error bound for low Bayes error conditions. Then, the bound for class priors are discussed. Moreover, we extend the classification error bound for sequences. Using automatic speech recognition as a representative example of machine learning applications, this work analytically discusses the correlations among different performance measures with extended bounds, including cross-entropy loss, language model perplexity, and word error rate. </p>
<blockquote>
<p>åœ¨ç»Ÿè®¡åˆ†ç±»å’Œæœºå™¨å­¦ä¹ é¢†åŸŸï¼Œåˆ†ç±»è¯¯å·®æ˜¯ä¸€é¡¹é‡è¦çš„æ€§èƒ½åº¦é‡ï¼Œé€šè¿‡è´å¶æ–¯å†³ç­–è§„åˆ™æ¥æœ€å°åŒ–ã€‚åœ¨å®è·µä¸­ï¼Œè´å¶æ–¯å†³ç­–è§„åˆ™ä¸­çš„æœªçŸ¥çœŸå®åˆ†å¸ƒé€šå¸¸ä¼šç”¨åŸºäºè®­ç»ƒæ•°æ®ä¼°è®¡çš„æ¨¡å‹åˆ†å¸ƒæ¥æ›¿ä»£ã€‚è¿™ç§æ›¿ä»£å¼•å…¥äº†è´å¶æ–¯è¯¯å·®å’ŒåŸºäºæ¨¡å‹çš„åˆ†ç±»è¯¯å·®ä¹‹é—´çš„ä¸åŒ¹é…ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬åº”ç”¨åˆ†ç±»è¯¯å·®ç•Œé™æ¥ç ”ç©¶æœºå™¨å­¦ä¹ ä¸­çš„è¯¯å·®ä¸åŒ¹é…ä¸Kullback-Leibleræ•£åº¦ä¹‹é—´çš„å…³ç³»ã€‚å—è¿‘æœŸè®¸å¤šæœºå™¨å­¦ä¹ ä»»åŠ¡ä¸­è§‚å¯Ÿåˆ°çš„ä½æ¨¡å‹åˆ†ç±»è¯¯å·®çš„å¯å‘ï¼Œä¸ºäº†å°†è´å¶æ–¯è¯¯å·®é™å®šåœ¨è¾ƒä½èŒƒå›´ï¼Œæˆ‘ä»¬æå‡ºäº†ä½è´å¶æ–¯è¯¯å·®æ¡ä»¶ä¸‹çš„åˆ†ç±»è¯¯å·®ç•Œé™çš„çº¿æ€§è¿‘ä¼¼ã€‚ç„¶åï¼Œè®¨è®ºäº†ç±»åˆ«å…ˆéªŒçš„ç•Œé™ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æ‰©å±•äº†åºåˆ—çš„åˆ†ç±»è¯¯å·®ç•Œé™ã€‚ä»¥è‡ªåŠ¨è¯­éŸ³è¯†åˆ«ä½œä¸ºæœºå™¨å­¦ä¹ çš„ä»£è¡¨æ€§åº”ç”¨ï¼Œè¿™é¡¹å·¥ä½œé€šè¿‡æ‰©å±•çš„ç•Œé™åˆ†æè®¨è®ºäº†ä¸åŒçš„æ€§èƒ½åº¦é‡ä¹‹é—´çš„ç›¸å…³æ€§ï¼ŒåŒ…æ‹¬äº¤å‰ç†µæŸå¤±ã€è¯­è¨€æ¨¡å‹å›°æƒ‘åº¦å’Œè¯é”™è¯¯ç‡ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.15977v1">PDF</a> accepted at ICASSP 2025</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æ¢è®¨äº†ç»Ÿè®¡åˆ†ç±»å’Œæœºå™¨å­¦ä¹ ä¸­çš„åˆ†ç±»é”™è¯¯è¡¡é‡æ ‡å‡†ï¼Œä»‹ç»äº†è´å¶æ–¯å†³ç­–è§„åˆ™ä¸­çš„è¯¯å·®ä¸æ¨¡å‹åˆ†å¸ƒä¹‹é—´çš„ä¸åŒ¹é…é—®é¢˜ã€‚æ–‡ç« é€šè¿‡åˆ†ç±»è¯¯å·®ç•Œé™ç ”ç©¶äº†è¯¯å·®ä¸åŒ¹é…ä¸Kullback-Leibleræ•£åº¦çš„å…³ç³»ï¼Œæå‡ºäº†ä½è´å¶æ–¯è¯¯å·®æ¡ä»¶ä¸‹çš„åˆ†ç±»è¯¯å·®ç•Œé™çš„çº¿æ€§è¿‘ä¼¼æ–¹æ³•ï¼Œå¹¶è®¨è®ºäº†ç±»åˆ«å…ˆéªŒçš„ç•Œé™ã€‚æ­¤å¤–ï¼Œæ–‡ç« è¿˜å°†åˆ†ç±»è¯¯å·®ç•Œé™æ‰©å±•åˆ°åºåˆ—ï¼Œä»¥è‡ªåŠ¨è¯­éŸ³è¯†åˆ«ä¸ºä¾‹ï¼Œè®¨è®ºäº†ä¸åŒæ€§èƒ½è¡¡é‡æ ‡å‡†ï¼ˆåŒ…æ‹¬äº¤å‰ç†µæŸå¤±ã€è¯­è¨€æ¨¡å‹å›°æƒ‘åº¦å’Œè¯é”™è¯¯ç‡ï¼‰çš„å…³è”ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>åˆ†ç±»é”™è¯¯æ˜¯è¡¡é‡æœºå™¨å­¦ä¹ æ¨¡å‹æ€§èƒ½çš„é‡è¦æ ‡å‡†ï¼Œè´å¶æ–¯å†³ç­–è§„åˆ™æ—¨åœ¨æœ€å°åŒ–æ­¤è¯¯å·®ã€‚</li>
<li>åœ¨å®è·µä¸­ï¼Œæ¨¡å‹çš„æœªçŸ¥çœŸå®åˆ†å¸ƒé€šå¸¸ä½¿ç”¨ä»è®­ç»ƒæ•°æ®ä¸­ä¼°è®¡å‡ºçš„æ¨¡å‹åˆ†å¸ƒæ¥æ›¿ä»£ï¼Œè¿™å¼•å…¥äº†è´å¶æ–¯è¯¯å·®å’Œæ¨¡å‹åŸºäºçš„åˆ†ç±»è¯¯å·®ä¹‹é—´çš„ä¸åŒ¹é…ã€‚</li>
<li>æ–‡ç« é€šè¿‡åˆ†ç±»è¯¯å·®ç•Œé™ç ”ç©¶äº†è¯¯å·®ä¸åŒ¹é…ä¸Kullback-Leibleræ•£åº¦çš„å…³ç³»ã€‚</li>
<li>å¯¹äºä½è´å¶æ–¯è¯¯å·®æ¡ä»¶ï¼Œæ–‡ç« æå‡ºäº†åˆ†ç±»è¯¯å·®ç•Œé™çš„çº¿æ€§è¿‘ä¼¼æ–¹æ³•ã€‚</li>
<li>æ–‡ç« è®¨è®ºäº†ç±»åˆ«å…ˆéªŒçš„ç•Œé™ã€‚</li>
<li>æ–‡ç« å°†åˆ†ç±»è¯¯å·®ç•Œé™æ‰©å±•åˆ°åºåˆ—ï¼Œå¹¶æ¢è®¨äº†è‡ªåŠ¨è¯­éŸ³è¯†åˆ«ç­‰æœºå™¨å­¦ä¹ åº”ç”¨ä¸­ä¸åŒæ€§èƒ½è¡¡é‡æ ‡å‡†ä¹‹é—´çš„å…³è”ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.15977">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-b47ba7063698dae18fd3c177488f22b9.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-88a2dac0fc0a959e0df501f23a725a8b.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-20f8f278d19704a66fad6f352e965534.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="AnyEnhance-A-Unified-Generative-Model-with-Prompt-Guidance-and-Self-Critic-for-Voice-Enhancement"><a href="#AnyEnhance-A-Unified-Generative-Model-with-Prompt-Guidance-and-Self-Critic-for-Voice-Enhancement" class="headerlink" title="AnyEnhance: A Unified Generative Model with Prompt-Guidance and   Self-Critic for Voice Enhancement"></a>AnyEnhance: A Unified Generative Model with Prompt-Guidance and   Self-Critic for Voice Enhancement</h2><p><strong>Authors:Junan Zhang, Jing Yang, Zihao Fang, Yuancheng Wang, Zehua Zhang, Zhuo Wang, Fan Fan, Zhizheng Wu</strong></p>
<p>We introduce AnyEnhance, a unified generative model for voice enhancement that processes both speech and singing voices. Based on a masked generative model, AnyEnhance is capable of handling both speech and singing voices, supporting a wide range of enhancement tasks including denoising, dereverberation, declipping, super-resolution, and target speaker extraction, all simultaneously and without fine-tuning. AnyEnhance introduces a prompt-guidance mechanism for in-context learning, which allows the model to natively accept a reference speakerâ€™s timbre. In this way, it could boost enhancement performance when a reference audio is available and enable the target speaker extraction task without altering the underlying architecture. Moreover, we also introduce a self-critic mechanism into the generative process for masked generative models, yielding higher-quality outputs through iterative self-assessment and refinement. Extensive experiments on various enhancement tasks demonstrate AnyEnhance outperforms existing methods in terms of both objective metrics and subjective listening tests. Demo audios are publicly available at <a target="_blank" rel="noopener" href="https://amphionspace.github.io/anyenhance/">https://amphionspace.github.io/anyenhance/</a>. </p>
<blockquote>
<p>æˆ‘ä»¬ä»‹ç»äº†AnyEnhanceï¼Œè¿™æ˜¯ä¸€ä¸ªç»Ÿä¸€çš„ç”Ÿæˆæ¨¡å‹ï¼Œç”¨äºå¤„ç†è¯­éŸ³å’Œæ­Œå£°çš„å¢å¼ºã€‚åŸºäºæ©æ¨¡ç”Ÿæˆæ¨¡å‹ï¼ŒAnyEnhanceèƒ½å¤ŸåŒæ—¶å¤„ç†è¯­éŸ³å’Œæ­Œå£°ï¼Œæ”¯æŒå¹¿æ³›çš„å¢å¼ºä»»åŠ¡ï¼ŒåŒ…æ‹¬å»å™ªã€å»æ··å“ã€å»å‰ªè¾‘ã€è¶…åˆ†è¾¨ç‡å’Œç›®æ ‡è¯´è¯äººæå–ï¼Œè€Œä¸”æ— éœ€å¾®è°ƒã€‚AnyEnhanceå¼•å…¥äº†ä¸€ç§ä¸Šä¸‹æ–‡å­¦ä¹ ä¸­çš„æç¤ºå¼•å¯¼æœºåˆ¶ï¼Œå…è®¸æ¨¡å‹åŸç”Ÿæ¥å—å‚è€ƒè¯´è¯äººçš„éŸ³è‰²ã€‚è¿™æ ·ï¼Œå½“å‚è€ƒéŸ³é¢‘å¯ç”¨æ—¶ï¼Œå®ƒå¯ä»¥æé«˜å¢å¼ºæ€§èƒ½ï¼Œå¹¶åœ¨ä¸æ”¹å˜åº•å±‚æ¶æ„çš„æƒ…å†µä¸‹å®ç°ç›®æ ‡è¯´è¯äººæå–ä»»åŠ¡ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜å°†åœ¨ç”Ÿæˆè¿‡ç¨‹ä¸­ä¸ºæ©æ¨¡ç”Ÿæˆæ¨¡å‹å¼•å…¥è‡ªæˆ‘æ‰¹åˆ¤æœºåˆ¶ï¼Œé€šè¿‡è¿­ä»£è‡ªæˆ‘è¯„ä¼°å’Œç»†åŒ–äº§ç”Ÿæ›´é«˜è´¨é‡çš„è¾“å‡ºã€‚å¯¹å„ç§å¢å¼ºä»»åŠ¡çš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼ŒAnyEnhanceåœ¨å®¢è§‚æŒ‡æ ‡å’Œä¸»è§‚å¬è§‰æµ‹è¯•æ–¹é¢å‡ä¼˜äºç°æœ‰æ–¹æ³•ã€‚æ¼”ç¤ºéŸ³é¢‘å¯åœ¨<a target="_blank" rel="noopener" href="https://amphionspace.github.io/anyenhance/%E5%85%AC%E5%BC%BA%E3%80%82">https://amphionspace.github.io/anyenhance/å…¬å¼€è®¿é—®ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.15417v1">PDF</a> 12 pages, 4 figures</p>
<p><strong>Summary</strong></p>
<p>AnyEnhanceæ˜¯ä¸€ä¸ªç»Ÿä¸€çš„ç”Ÿæˆæ¨¡å‹ï¼Œç”¨äºå¤„ç†è¯­éŸ³å’Œæ­Œå”±å£°éŸ³çš„å¢å¼ºã€‚å®ƒåŸºäºæ©æ¨¡ç”Ÿæˆæ¨¡å‹ï¼Œæ”¯æŒå¤šç§å¢å¼ºä»»åŠ¡ï¼Œå¦‚å»å™ªã€å»æ··å“ã€å»å‰ªè¾‘ã€è¶…åˆ†è¾¨ç‡å’Œç›®æ ‡è¯´è¯äººæå–ã€‚AnyEnhanceå¼•å…¥æç¤ºæŒ‡å¯¼æœºåˆ¶ï¼Œå¯åœ¨æœ‰å‚è€ƒéŸ³é¢‘çš„æƒ…å†µä¸‹æé«˜å¢å¼ºæ€§èƒ½ï¼Œå¹¶å¯ç”¨ç›®æ ‡è¯´è¯äººæå–ä»»åŠ¡ã€‚æ­¤å¤–ï¼Œå®ƒè¿˜å¼•å…¥äº†è‡ªæˆ‘æ‰¹åˆ¤æœºåˆ¶ï¼Œé€šè¿‡è¿­ä»£è‡ªæˆ‘è¯„ä¼°å’Œç»†åŒ–äº§ç”Ÿæ›´é«˜è´¨é‡çš„è¾“å‡ºã€‚å®éªŒè¡¨æ˜ï¼ŒAnyEnhanceåœ¨å®¢è§‚æŒ‡æ ‡å’Œä¸»è§‚å¬è§‰æµ‹è¯•æ–¹é¢ä¼˜äºç°æœ‰æ–¹æ³•ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>AnyEnhanceæ˜¯ä¸€ä¸ªç»Ÿä¸€çš„ç”Ÿæˆæ¨¡å‹ï¼Œç”¨äºè¯­éŸ³å’Œæ­Œå”±å£°éŸ³å¢å¼ºã€‚</li>
<li>æ”¯æŒå¤šç§å¢å¼ºä»»åŠ¡ï¼ŒåŒ…æ‹¬å»å™ªã€å»æ··å“ã€å»å‰ªè¾‘ã€è¶…åˆ†è¾¨ç‡å’Œç›®æ ‡è¯´è¯äººæå–ã€‚</li>
<li>AnyEnhanceé€šè¿‡å¼•å…¥æç¤ºæŒ‡å¯¼æœºåˆ¶ï¼Œåœ¨æœ‰å‚è€ƒéŸ³é¢‘çš„æƒ…å†µä¸‹æé«˜å¢å¼ºæ€§èƒ½ã€‚</li>
<li>å¼•å…¥è‡ªæˆ‘æ‰¹åˆ¤æœºåˆ¶ï¼Œé€šè¿‡è¿­ä»£è‡ªæˆ‘è¯„ä¼°å’Œç»†åŒ–æé«˜è¾“å‡ºè´¨é‡ã€‚</li>
<li>è¯¥æ¨¡å‹å¯ä»¥åŒæ—¶å¤„ç†å¤šç§ä»»åŠ¡ï¼Œæ— éœ€å¾®è°ƒã€‚</li>
<li>AnyEnhanceåœ¨å®¢è§‚æŒ‡æ ‡å’Œä¸»è§‚å¬è§‰æµ‹è¯•æ–¹é¢çš„æ€§èƒ½ä¼˜äºç°æœ‰æ–¹æ³•ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.15417">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-d77a7db8d6a59a7eb4cb95c821a7884a.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-b397074400c2907518f223b2e1be6a4c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-6dc93f2ba7f3f4dcbb459304d0351e88.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-772bd3a411096a0ad3324ffd7af9bfb8.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-8453d9b3f560a716e3b29a7d6d9fbc8c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-856797e45217b0a2fa09970219a9b08c.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="Robust-Cross-Etiology-and-Speaker-Independent-Dysarthric-Speech-Recognition"><a href="#Robust-Cross-Etiology-and-Speaker-Independent-Dysarthric-Speech-Recognition" class="headerlink" title="Robust Cross-Etiology and Speaker-Independent Dysarthric Speech   Recognition"></a>Robust Cross-Etiology and Speaker-Independent Dysarthric Speech   Recognition</h2><p><strong>Authors:Satwinder Singh, Qianli Wang, Zihan Zhong, Clarion Mendes, Mark Hasegawa-Johnson, Waleed Abdulla, Seyed Reza Shahamiri</strong></p>
<p>In this paper, we present a speaker-independent dysarthric speech recognition system, with a focus on evaluating the recently released Speech Accessibility Project (SAP-1005) dataset, which includes speech data from individuals with Parkinsonâ€™s disease (PD). Despite the growing body of research in dysarthric speech recognition, many existing systems are speaker-dependent and adaptive, limiting their generalizability across different speakers and etiologies. Our primary objective is to develop a robust speaker-independent model capable of accurately recognizing dysarthric speech, irrespective of the speaker. Additionally, as a secondary objective, we aim to test the cross-etiology performance of our model by evaluating it on the TORGO dataset, which contains speech samples from individuals with cerebral palsy (CP) and amyotrophic lateral sclerosis (ALS). By leveraging the Whisper model, our speaker-independent system achieved a CER of 6.99% and a WER of 10.71% on the SAP-1005 dataset. Further, in cross-etiology settings, we achieved a CER of 25.08% and a WER of 39.56% on the TORGO dataset. These results highlight the potential of our approach to generalize across unseen speakers and different etiologies of dysarthria. </p>
<blockquote>
<p>æœ¬æ–‡ä»‹ç»äº†ä¸€ä¸ªç‹¬ç«‹äºè¯´è¯è€…çš„è¨€è¯­éšœç¢è¯­éŸ³è¯†åˆ«ç³»ç»Ÿã€‚æˆ‘ä»¬é‡ç‚¹å…³æ³¨äºè¯„ä¼°æœ€è¿‘å‘å¸ƒçš„è¯­éŸ³æ— éšœç¢é¡¹ç›®ï¼ˆSAP-1005ï¼‰æ•°æ®é›†ï¼Œè¯¥æ•°æ®é›†åŒ…å«å¸•é‡‘æ£®ç—…æ‚£è€…ï¼ˆPDï¼‰çš„è¯­éŸ³æ•°æ®ã€‚å°½ç®¡è¨€è¯­éšœç¢è¯­éŸ³è¯†åˆ«çš„ç ”ç©¶æ—¥ç›Šå¢å¤šï¼Œä½†è®¸å¤šç°æœ‰ç³»ç»Ÿéƒ½æ˜¯ä¾èµ–äºè¯´è¯è€…å’Œè‡ªé€‚åº”çš„ï¼Œé™åˆ¶äº†å®ƒä»¬åœ¨ä¸åŒè¯´è¯è€…å’Œç—…å› ä¸­çš„é€šç”¨æ€§ã€‚æˆ‘ä»¬çš„ä¸»è¦ç›®æ ‡æ˜¯å¼€å‘ä¸€ä¸ªç¨³å¥çš„ç‹¬ç«‹äºè¯´è¯è€…çš„æ¨¡å‹ï¼Œèƒ½å¤Ÿå‡†ç¡®è¯†åˆ«è¨€è¯­éšœç¢è¯­éŸ³ï¼Œè€Œæ— è®ºè¯´è¯è€…å¦‚ä½•ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬çš„æ¬¡è¦ç›®æ ‡æ˜¯é€šè¿‡åœ¨TORGOæ•°æ®é›†ä¸Šè¯„ä¼°æ¨¡å‹æ¥æµ‹è¯•æ¨¡å‹çš„è·¨ç—…å› æ€§èƒ½ã€‚TORGOæ•°æ®é›†åŒ…å«æ¥è‡ªè„‘ç˜«ï¼ˆCPï¼‰å’Œè‚Œèç¼©æ€§ä¾§ç´¢ç¡¬åŒ–ç—‡ï¼ˆALSï¼‰æ‚£è€…çš„è¯­éŸ³æ ·æœ¬ã€‚é€šè¿‡åˆ©ç”¨Whisperæ¨¡å‹ï¼Œæˆ‘ä»¬çš„ç‹¬ç«‹äºè¯´è¯è€…çš„ç³»ç»Ÿå®ç°äº†SAP-1005æ•°æ®é›†ä¸Šçš„å­—ç¬¦é”™è¯¯ç‡ï¼ˆCERï¼‰ä¸º6.99%ï¼Œå•è¯é”™è¯¯ç‡ï¼ˆWERï¼‰ä¸º10.71%ã€‚æ­¤å¤–ï¼Œåœ¨è·¨ç—…å› è®¾ç½®ä¸‹ï¼Œæˆ‘ä»¬åœ¨TORGOæ•°æ®é›†ä¸Šå®ç°äº†CERä¸º25.08%ï¼ŒWERä¸º39.56%ã€‚è¿™äº›ç»“æœçªæ˜¾äº†æˆ‘ä»¬çš„æ–¹æ³•åœ¨ä¸åŒæœªè§è¿‡çš„è¯´è¯è€…å’Œä¸åŒçš„è¨€è¯­éšœç¢ç—…å› ä¸­çš„é€šç”¨æ½œåŠ›ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.14994v1">PDF</a> Accepted to ICASSP 2025</p>
<p><strong>Summary</strong>ï¼š<br>æœ¬ç ”ç©¶æå‡ºä¸€ä¸ªä¸ä¾èµ–äºç‰¹å®šè¯´è¯è€…çš„è¯­è¨€éšœç¢è¯­éŸ³è¯†åˆ«ç³»ç»Ÿï¼Œé‡ç‚¹åœ¨äºè¯„ä¼°æœ€æ–°å‘å¸ƒçš„è¯­éŸ³å¯è®¿é—®æ€§é¡¹ç›®ï¼ˆSAP-1005ï¼‰æ•°æ®é›†ï¼Œå…¶ä¸­åŒ…å«å¸•é‡‘æ£®ç—…æ‚£è€…ï¼ˆPDï¼‰çš„è¯­éŸ³æ•°æ®ã€‚ç³»ç»Ÿæ—¨åœ¨å¼€å‘ä¸€ä¸ªç¨³å¥çš„è·¨è¯´è¯è€…æ¨¡å‹ï¼Œèƒ½å¤Ÿå‡†ç¡®è¯†åˆ«è¯­è¨€éšœç¢è¯­éŸ³ï¼Œæ— è®ºè¯´è¯è€…å¦‚ä½•ã€‚ä½¿ç”¨whisperæ¨¡å‹ï¼Œè¯¥æ¨¡å‹åœ¨SAP-1005æ•°æ®é›†ä¸Šå–å¾—äº†å­—ç¬¦é”™è¯¯ç‡ï¼ˆCERï¼‰ä¸º6.99%ï¼Œè¯é”™è¯¯ç‡ï¼ˆWERï¼‰ä¸º10.71%çš„æˆç»©ã€‚æ­¤å¤–ï¼Œåœ¨è·¨ç–¾ç—…è®¾ç½®ä¸‹ï¼Œæ¨¡å‹åœ¨TORGOæ•°æ®é›†ä¸Šå–å¾—äº†CERä¸º25.08%ï¼ŒWERä¸º39.56%çš„æˆç»©ã€‚è¿™äº›ç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•å…·æœ‰è·¨æœªè§è¯´è¯è€…å’Œä¸åŒè¯­è¨€éšœç¢ç±»å‹çš„æ¨å¹¿æ½œåŠ›ã€‚</p>
<p><strong>Key Takeaways</strong>ï¼š</p>
<ol>
<li>ç ”ç©¶æå‡ºäº†ä¸€ä¸ªä¸ä¾èµ–äºç‰¹å®šè¯´è¯è€…çš„è¯­è¨€éšœç¢è¯­éŸ³è¯†åˆ«ç³»ç»Ÿã€‚</li>
<li>ç³»ç»Ÿè¯„ä¼°äº†SAP-1005æ•°æ®é›†ï¼ŒåŒ…å«å¸•é‡‘æ£®ç—…æ‚£è€…ï¼ˆPDï¼‰çš„è¯­éŸ³æ•°æ®ã€‚</li>
<li>åˆ©ç”¨whisperæ¨¡å‹ï¼Œç³»ç»Ÿåœ¨SAP-1005æ•°æ®é›†ä¸Šå®ç°äº†è¾ƒå¥½çš„è¯†åˆ«æ•ˆæœã€‚</li>
<li>ç³»ç»Ÿå°è¯•åœ¨TORGOæ•°æ®é›†ä¸Šè¿›è¡Œè·¨ç–¾ç—…æµ‹è¯•ï¼Œå–å¾—äº†ä¸€å®šæˆç»©ã€‚</li>
<li>è¯¥ç³»ç»Ÿå…·æœ‰è·¨æœªè§è¯´è¯è€…å’Œä¸åŒè¯­è¨€éšœç¢ç±»å‹çš„æ¨å¹¿æ½œåŠ›ã€‚</li>
<li>è¯¥ç ”ç©¶å¡«è¡¥äº†å…³äºè¯­è¨€éšœç¢è¯­éŸ³è¯†åˆ«çš„ç°æœ‰ç³»ç»Ÿçš„ä¸è¶³ï¼Œå¦‚ä¾èµ–ç‰¹å®šè¯´è¯è€…æˆ–ç¼ºä¹è·¨ä¸åŒè¯´è¯è€…å’Œç—…å› çš„æ³›åŒ–èƒ½åŠ›ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.14994">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-81c3bd3c93a12b84de617404ee1febf8.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c091d923febf2fd1328c49543f1c7752.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-5247a86fdd00756951f49cac853e4ea0.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-6999031f2367bf57302d11d6042f29c6.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c27f3b12cd882f0a61b0620c7363e852.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="DeSTA2-Developing-Instruction-Following-Speech-Language-Model-Without-Speech-Instruction-Tuning-Data"><a href="#DeSTA2-Developing-Instruction-Following-Speech-Language-Model-Without-Speech-Instruction-Tuning-Data" class="headerlink" title="DeSTA2: Developing Instruction-Following Speech Language Model Without   Speech Instruction-Tuning Data"></a>DeSTA2: Developing Instruction-Following Speech Language Model Without   Speech Instruction-Tuning Data</h2><p><strong>Authors:Ke-Han Lu, Zhehuai Chen, Szu-Wei Fu, Chao-Han Huck Yang, Jagadeesh Balam, Boris Ginsburg, Yu-Chiang Frank Wang, Hung-yi Lee</strong></p>
<p>Recent end-to-end speech language models (SLMs) have expanded upon the capabilities of large language models (LLMs) by incorporating pre-trained speech models. However, these SLMs often undergo extensive speech instruction-tuning to bridge the gap between speech and text modalities. This requires significant annotation efforts and risks catastrophic forgetting of the original language capabilities. In this work, we present a simple yet effective automatic process for creating speech-text pair data that carefully injects speech paralinguistic understanding abilities into SLMs while preserving the inherent language capabilities of the text-based LLM. Our model demonstrates general capabilities for speech-related tasks without the need for speech instruction-tuning data, achieving impressive performance on Dynamic-SUPERB and AIR-Bench-Chat benchmarks. Furthermore, our model exhibits the ability to follow complex instructions derived from LLMs, such as specific output formatting and chain-of-thought reasoning. Our approach not only enhances the versatility and effectiveness of SLMs but also reduces reliance on extensive annotated datasets, paving the way for more efficient and capable speech understanding systems. </p>
<blockquote>
<p>æœ€è¿‘çš„ç«¯åˆ°ç«¯è¯­éŸ³è¯­è¨€æ¨¡å‹ï¼ˆSLMï¼‰é€šè¿‡èå…¥é¢„è®­ç»ƒçš„è¯­éŸ³æ¨¡å‹ï¼Œæ‰©å¤§äº†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„èƒ½åŠ›ã€‚ç„¶è€Œï¼Œè¿™äº›SLMé€šå¸¸éœ€è¦è¿›è¡Œå¤§é‡çš„è¯­éŸ³æŒ‡ä»¤è°ƒæ•´ï¼Œä»¥å¼¥åˆè¯­éŸ³å’Œæ–‡æœ¬æ¨¡æ€ä¹‹é—´çš„å·®è·ã€‚è¿™éœ€è¦å¤§é‡çš„æ ‡æ³¨å·¥ä½œï¼Œå¹¶å­˜åœ¨åŸæœ‰è¯­è¨€èƒ½åŠ›ç¾éš¾æ€§é—å¿˜çš„é£é™©ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2409.20007v2">PDF</a> Accepted by ICASSP 2025</p>
<p><strong>Summary</strong></p>
<p>è¿‘æœŸç«¯å¯¹ç«¯è¯­éŸ³è¯­è¨€æ¨¡å‹ï¼ˆSLMï¼‰ç»“åˆé¢„è®­ç»ƒè¯­éŸ³æ¨¡å‹ï¼Œæå‡äº†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„åŠŸèƒ½ã€‚ç„¶è€Œï¼Œè¿™äº›SLMéœ€è¦ç»è¿‡å¤§é‡çš„è¯­éŸ³æŒ‡ä»¤è°ƒæ•´æ¥å¼¥åˆè¯­éŸ³ä¸æ–‡æœ¬æ¨¡æ€ä¹‹é—´çš„å·®è·ï¼Œè¿™éœ€è¦å¤§é‡çš„æ ‡æ³¨å·¥ä½œå¹¶å­˜åœ¨é—å¿˜åŸå§‹è¯­è¨€èƒ½åŠ›çš„é£é™©ã€‚æœ¬ç ”ç©¶æå‡ºäº†ä¸€ç§ç®€å•æœ‰æ•ˆçš„è‡ªåŠ¨åˆ›å»ºè¯­éŸ³æ–‡æœ¬å¯¹æ•°æ®çš„è¿‡ç¨‹ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿè°¨æ…åœ°å°†è¯­éŸ³å‰¯è¯­è¨€ç†è§£åŠ›æ³¨å…¥SLMä¸­ï¼ŒåŒæ—¶ä¿ç•™æ–‡æœ¬åŸºç¡€LLMçš„å›ºæœ‰è¯­è¨€èƒ½åŠ›ã€‚æˆ‘ä»¬çš„æ¨¡å‹åœ¨åŠ¨æ€SUPERBå’ŒAIR-Bench-ChatåŸºå‡†æµ‹è¯•ä¸­è¡¨ç°å‡ºè‰²ï¼Œæ— éœ€è¯­éŸ³æŒ‡ä»¤è°ƒæ•´æ•°æ®å³å¯è¿›è¡Œè¯­éŸ³ç›¸å…³ä»»åŠ¡ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬çš„æ¨¡å‹å±•ç°å‡ºéµå¾ªLLMæ´¾ç”Ÿçš„å¤æ‚æŒ‡ä»¤çš„èƒ½åŠ›ï¼Œå¦‚ç‰¹å®šçš„è¾“å‡ºæ ¼å¼å’Œé“¾å¼æ€ç»´æ¨ç†ã€‚æˆ‘ä»¬çš„æ–¹æ³•ä¸ä»…æé«˜äº†SLMçš„é€šç”¨æ€§å’Œæ•ˆç‡ï¼Œè¿˜å‡å°‘äº†å¯¹é¢å¤§é‡æ ‡æ³¨æ•°æ®é›†çš„ä¾èµ–ï¼Œä¸ºæ„å»ºæ›´é«˜æ•ˆã€æ›´å¼ºå¤§çš„è¯­éŸ³ç†è§£ç³»ç»Ÿé“ºå¹³äº†é“è·¯ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ç«¯å¯¹ç«¯è¯­éŸ³è¯­è¨€æ¨¡å‹ï¼ˆSLMï¼‰ç»“åˆäº†é¢„è®­ç»ƒè¯­éŸ³æ¨¡å‹ä»¥æå‡å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„åŠŸèƒ½ã€‚</li>
<li>SLMséœ€è¦é€šè¿‡è¯­éŸ³æŒ‡ä»¤è°ƒæ•´æ¥æ¡¥æ¥è¯­éŸ³å’Œæ–‡æœ¬æ¨¡æ€ä¹‹é—´çš„å·®è·ï¼Œè¿™éœ€è¦å¤§é‡æ ‡æ³¨æ•°æ®å¹¶å­˜åœ¨é—å¿˜åŸå§‹è¯­è¨€èƒ½åŠ›çš„é£é™©ã€‚</li>
<li>æå‡ºäº†ä¸€ç§è‡ªåŠ¨åˆ›å»ºè¯­éŸ³æ–‡æœ¬å¯¹æ•°æ®çš„æ–¹æ³•ï¼Œä»¥æ³¨å…¥è¯­éŸ³å‰¯è¯­è¨€ç†è§£åŠ›å¹¶ä¿ç•™LLMçš„å›ºæœ‰è¯­è¨€èƒ½åŠ›ã€‚</li>
<li>æ¨¡å‹åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­è¡¨ç°å‡ºè‰²ï¼Œæ— éœ€é¢å¤–çš„è¯­éŸ³æŒ‡ä»¤è°ƒæ•´å³å¯æ‰§è¡Œè¯­éŸ³ç›¸å…³ä»»åŠ¡ã€‚</li>
<li>æ¨¡å‹èƒ½å¤Ÿéµå¾ªå¤æ‚çš„æŒ‡ä»¤ï¼ŒåŒ…æ‹¬ç‰¹å®šçš„è¾“å‡ºæ ¼å¼å’Œé“¾å¼æ€ç»´æ¨ç†ã€‚</li>
<li>æ–¹æ³•æé«˜äº†SLMçš„é€šç”¨æ€§å’Œæ•ˆç‡ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2409.20007">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-bb12237f5028b2ef8c4688ba3bd7db85.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-58f6ab46ca8afa96573693f49a1013dd.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-1e1917e83ea95b32bc22dbb5f4a38fc4.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-6ef2fd4ebdb88d017ed0400cb0f713b7.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-01-29/Speech/">https://kedreamix.github.io/Talk2Paper/Paper/2025-01-29/Speech/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/Speech/">
                                    <span class="chip bg-color">Speech</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-01-29/GAN/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-b14916c16d3d32298e69c2323e02fc21.jpg" class="responsive-img" alt="GAN">
                        
                        <span class="card-title">GAN</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            GAN æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-01-29  Can Location Embeddings Enhance Super-Resolution of Satellite Imagery?
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-01-29
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/GAN/" class="post-category">
                                    GAN
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/GAN/">
                        <span class="chip bg-color">GAN</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-01-29/%E5%8C%BB%E5%AD%A6%E5%BD%B1%E5%83%8F_Breast%20Ultrasound/">
                    <div class="card-image">
                        
                        <img src="https://pica.zhimg.com/v2-2811f111cf82d1b45ea48dbd665cbe52.jpg" class="responsive-img" alt="åŒ»å­¦å½±åƒ/Breast Ultrasound">
                        
                        <span class="card-title">åŒ»å­¦å½±åƒ/Breast Ultrasound</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            åŒ»å­¦å½±åƒ/Breast Ultrasound æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-01-29  Tumor Detection, Segmentation and Classification Challenge on Automated   3D Breast Ultrasound The TDSC-ABUS Challenge
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-01-29
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/%E5%8C%BB%E5%AD%A6%E5%BD%B1%E5%83%8F-Breast-Ultrasound/" class="post-category">
                                    åŒ»å­¦å½±åƒ/Breast Ultrasound
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/%E5%8C%BB%E5%AD%A6%E5%BD%B1%E5%83%8F-Breast-Ultrasound/">
                        <span class="chip bg-color">åŒ»å­¦å½±åƒ/Breast Ultrasound</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">18863.8k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
