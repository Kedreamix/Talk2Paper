<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Agent">
    <meta name="description" content="Agent æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-01-29  Multi-Agent Geospatial Copilots for Remote Sensing Workflows">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>Agent | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://pic1.zhimg.com/v2-caf86bb6b82999c627b07f01da571c08.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Agent</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/Agent/">
                                <span class="chip bg-color">Agent</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/Agent/" class="post-category">
                                Agent
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-01-29
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-02-12
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    15.1k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    61 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-01-29-æ›´æ–°"><a href="#2025-01-29-æ›´æ–°" class="headerlink" title="2025-01-29 æ›´æ–°"></a>2025-01-29 æ›´æ–°</h1><h2 id="Multi-Agent-Geospatial-Copilots-for-Remote-Sensing-Workflows"><a href="#Multi-Agent-Geospatial-Copilots-for-Remote-Sensing-Workflows" class="headerlink" title="Multi-Agent Geospatial Copilots for Remote Sensing Workflows"></a>Multi-Agent Geospatial Copilots for Remote Sensing Workflows</h2><p><strong>Authors:Chaehong Lee, Varatheepan Paramanayakam, Andreas Karatzas, Yanan Jian, Michael Fore, Heming Liao, Fuxun Yu, Ruopu Li, Iraklis Anagnostopoulos, Dimitrios Stamoulis</strong></p>
<p>We present GeoLLM-Squad, a geospatial Copilot that introduces the novel multi-agent paradigm to remote sensing (RS) workflows. Unlike existing single-agent approaches that rely on monolithic large language models (LLM), GeoLLM-Squad separates agentic orchestration from geospatial task-solving, by delegating RS tasks to specialized sub-agents. Built on the open-source AutoGen and GeoLLM-Engine frameworks, our work enables the modular integration of diverse applications, spanning urban monitoring, forestry protection, climate analysis, and agriculture studies. Our results demonstrate that while single-agent systems struggle to scale with increasing RS task complexity, GeoLLM-Squad maintains robust performance, achieving a 17% improvement in agentic correctness over state-of-the-art baselines. Our findings highlight the potential of multi-agent AI in advancing RS workflows. </p>
<blockquote>
<p>æˆ‘ä»¬æå‡ºäº†GeoLLM-Squadï¼Œè¿™æ˜¯ä¸€ä¸ªåœ°ç†ç©ºé—´Copilotï¼Œå®ƒå¼•å…¥äº†é¥æ„Ÿï¼ˆRSï¼‰å·¥ä½œæµä¸­çš„æ–°å‹å¤šæ™ºèƒ½ä½“èŒƒå¼ã€‚ä¸ä¾èµ–å•ä¸€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„ç°æœ‰å•æ™ºèƒ½ä½“æ–¹æ³•ä¸åŒï¼ŒGeoLLM-Squadé€šè¿‡å°†é¥æ„Ÿä»»åŠ¡å§”æ´¾ç»™ä¸“ä¸šå­æ™ºèƒ½ä½“ï¼Œå°†æ™ºèƒ½ä½“çš„ç¼–æ’ä¸åœ°ç†ç©ºé—´ä»»åŠ¡è§£å†³åˆ†å¼€ã€‚æˆ‘ä»¬çš„å·¥ä½œå»ºç«‹åœ¨å¼€æºçš„AutoGenå’ŒGeoLLM-Engineæ¡†æ¶ä¹‹ä¸Šï¼Œèƒ½å¤Ÿå®ç°æ¨¡å—åŒ–é›†æˆå„ç§åº”ç”¨ï¼Œæ¶µç›–åŸå¸‚ç›‘æµ‹ã€æ—ä¸šä¿æŠ¤ã€æ°”å€™åˆ†æå’Œå†œä¸šç ”ç©¶ç­‰é¢†åŸŸã€‚æˆ‘ä»¬çš„ç»“æœè¡¨æ˜ï¼Œè™½ç„¶å•æ™ºèƒ½ä½“ç³»ç»Ÿåœ¨å¤„ç†æ—¥ç›Šå¤æ‚çš„é¥æ„Ÿä»»åŠ¡æ—¶éš¾ä»¥æ‰©å±•ï¼Œä½†GeoLLM-Squadèƒ½å¤Ÿä¿æŒç¨³å¥çš„æ€§èƒ½ï¼Œåœ¨æœ€æ–°åŸºçº¿çš„åŸºç¡€ä¸Šæé«˜äº†17%çš„æ™ºèƒ½æ­£ç¡®æ€§ã€‚æˆ‘ä»¬çš„ç ”ç©¶çªå‡ºäº†å¤šæ™ºèƒ½ä½“äººå·¥æ™ºèƒ½åœ¨æ¨è¿›é¥æ„Ÿå·¥ä½œæµä¸­çš„æ½œåŠ›ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.16254v1">PDF</a> </p>
<p><strong>Summary</strong><br>åŸºäºå¤šä»£ç†çš„GeoLLM-Squadç³»ç»Ÿè¢«æå‡ºï¼Œç”¨äºé¥æ„Ÿå·¥ä½œæµç¨‹ä¸­çš„æ–°å‹è¿œç¨‹æ£€æµ‹ã€‚ä¸ä¼ ç»Ÿä¾èµ–å•ä¸€å¤§å‹è¯­è¨€æ¨¡å‹çš„æ–¹æ¡ˆä¸åŒï¼Œè¯¥ç³»ç»Ÿå°†ä»»åŠ¡åˆ†å‘è‡³ä¸“é—¨çš„å­ä»£ç†æ¥å®Œæˆã€‚é€šè¿‡å¼€æºçš„AutoGenå’ŒGeoLLM-Engineæ¡†æ¶ï¼Œè¯¥æ–¹æ¡ˆå¯æ¨¡å—åŒ–é›†æˆå„ç§åº”ç”¨ï¼Œå¦‚åŸå¸‚ç›‘æµ‹ã€æ—ä¸šä¿æŠ¤ã€æ°”å€™åˆ†æå’Œå†œä¸šç ”ç©¶ç­‰ã€‚å®éªŒç»“æœè¯æ˜ï¼Œåœ¨é¥æ„Ÿä»»åŠ¡å¤æ‚æ€§å¢åŠ æ—¶ï¼ŒGeoLLM-Squadç›¸å¯¹äºç°æœ‰æŠ€æœ¯æé«˜äº†é«˜è¾¾17%çš„æ­£ç¡®ç‡ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>GeoLLM-Squadå¼•å…¥äº†ä¸€ç§æ–°å‹çš„å¤šä»£ç†èŒƒå¼ç”¨äºé¥æ„Ÿå·¥ä½œã€‚</li>
<li>è¯¥ç³»ç»Ÿè§£å†³äº†ç°æœ‰å•ä¸€å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å¤„ç†å¤æ‚é¥æ„Ÿä»»åŠ¡æ—¶çš„å±€é™æ€§ã€‚</li>
<li>GeoLLM-Squadå®ç°äº†æ¨¡å—åŒ–çš„åº”ç”¨é›†æˆï¼Œæ¶µç›–åŸå¸‚ç›‘æµ‹ã€æ—ä¸šä¿æŠ¤ç­‰å¤šä¸ªé¢†åŸŸã€‚</li>
<li>ç³»ç»Ÿæ€§èƒ½ç¨³å¥ï¼Œç›¸è¾ƒäºå½“å‰ä¸»æµæŠ€æœ¯æé«˜äº†çº¦17%çš„ä»£ç†æ­£ç¡®æ€§ã€‚</li>
<li>GeoLLM-Squadçš„åŸºç¡€æ˜¯å¼€æºçš„AutoGenå’ŒGeoLLM-Engineæ¡†æ¶ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.16254">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-70f2a39df2b44462be9818db93127572.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-fd7b06e0688daeaf387436ca9db10e9a.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-6ea6d2e284e3c320ffd00fc4df32c7dd.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a77d32e96d7e54f66dd1270080346ba7.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-51725de2da9640223f00aa98770926d7.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="Will-Systems-of-LLM-Agents-Cooperate-An-Investigation-into-a-Social-Dilemma"><a href="#Will-Systems-of-LLM-Agents-Cooperate-An-Investigation-into-a-Social-Dilemma" class="headerlink" title="Will Systems of LLM Agents Cooperate: An Investigation into a Social   Dilemma"></a>Will Systems of LLM Agents Cooperate: An Investigation into a Social   Dilemma</h2><p><strong>Authors:Richard Willis, Yali Du, Joel Z Leibo, Michael Luck</strong></p>
<p>As autonomous agents become more prevalent, understanding their collective behaviour in strategic interactions is crucial. This study investigates the emergent cooperative tendencies of systems of Large Language Model (LLM) agents in a social dilemma. Unlike previous research where LLMs output individual actions, we prompt state-of-the-art LLMs to generate complete strategies for iterated Prisonerâ€™s Dilemma. Using evolutionary game theory, we simulate populations of agents with different strategic dispositions (aggressive, cooperative, or neutral) and observe their evolutionary dynamics. Our findings reveal that different LLMs exhibit distinct biases affecting the relative success of aggressive versus cooperative strategies. This research provides insights into the potential long-term behaviour of systems of deployed LLM-based autonomous agents and highlights the importance of carefully considering the strategic environments in which they operate. </p>
<blockquote>
<p>éšç€è‡ªä¸»ä»£ç†ï¼ˆautonomous agentsï¼‰è¶Šæ¥è¶Šæ™®åŠï¼Œç†è§£å…¶åœ¨æˆ˜ç•¥äº’åŠ¨ä¸­çš„é›†ä½“è¡Œä¸ºè‡³å…³é‡è¦ã€‚æœ¬ç ”ç©¶è°ƒæŸ¥äº†ç¤¾ä¼šå›°å¢ƒä¸­å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä»£ç†ç³»ç»Ÿçš„æ–°å…´åˆä½œå€¾å‘ã€‚ä¸åŒäºä¹‹å‰çš„ç ”ç©¶ä¸­LLMè¾“å‡ºçš„ä¸ªä½“è¡Œä¸ºï¼Œæˆ‘ä»¬æç¤ºé‡‡ç”¨æœ€æ–°æŠ€æœ¯çš„LLMä¸ºåå¤åšå¼ˆçš„å›šå¾’å›°å¢ƒç”Ÿæˆå®Œæ•´ç­–ç•¥ã€‚æˆ‘ä»¬è¿ç”¨è¿›åŒ–åšå¼ˆè®ºï¼Œæ¨¡æ‹Ÿå…·æœ‰ä¸åŒæˆ˜ç•¥å€¾å‘ï¼ˆæ”»å‡»æ€§ã€åˆä½œæ€§æˆ–ä¸­ç«‹æ€§ï¼‰çš„ä»£ç†ç¾¤ä½“ï¼Œå¹¶è§‚å¯Ÿå®ƒä»¬çš„è¿›åŒ–åŠ¨æ€ã€‚æˆ‘ä»¬çš„ç ”ç©¶å‘ç°ï¼Œä¸åŒçš„LLMè¡¨ç°å‡ºä¸åŒçš„åè§ï¼Œå½±å“æ”»å‡»ä¸åˆä½œçš„ç›¸å¯¹æˆåŠŸç­–ç•¥ã€‚æœ¬ç ”ç©¶æ­ç¤ºäº†å·²éƒ¨ç½²çš„LLMåŸºç¡€è‡ªä¸»ä»£ç†ç³»ç»Ÿçš„æ½œåœ¨é•¿æœŸè¡Œä¸ºï¼Œå¹¶å¼ºè°ƒäº†ä»”ç»†è€ƒè™‘å…¶è¿è¥çš„æˆ˜ç•¥ç¯å¢ƒçš„é‡è¦æ€§ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.16173v1">PDF</a> 7 pages (10 including references), 4 figures</p>
<p><strong>Summary</strong></p>
<p>éšç€è‡ªä¸»ä»£ç†äººçš„æ™®åŠï¼Œç†è§£å…¶åœ¨æˆ˜ç•¥äº¤äº’ä¸­çš„é›†ä½“è¡Œä¸ºè‡³å…³é‡è¦ã€‚æœ¬ç ”ç©¶è°ƒæŸ¥äº†å¤§å‹è¯­è¨€æ¨¡å‹ä»£ç†ç³»ç»Ÿåœ¨ç¤¾äº¤å›°å¢ƒä¸­çš„æ–°å…´åˆä½œå€¾å‘ã€‚ä¸åŒäºä»¥å¾€åªå…³æ³¨LLMä¸ªä½“è¡Œä¸ºçš„è¾“å‡ºï¼Œæˆ‘ä»¬æç¤ºæœ€å…ˆè¿›çš„LLMç”Ÿæˆé‡å¤å›šå¾’å›°å¢ƒçš„å®Œæ•´ç­–ç•¥ã€‚é€šè¿‡æ¼”åŒ–åšå¼ˆç†è®ºï¼Œæˆ‘ä»¬æ¨¡æ‹Ÿä¸åŒç­–ç•¥å€¾å‘çš„ä»£ç†äººç¾¤ä½“ï¼ˆä¾µç•¥æ€§ã€åˆä½œæ€§æˆ–ä¸­ç«‹æ€§ï¼‰ï¼Œå¹¶è§‚å¯Ÿå…¶æ¼”åŒ–åŠ¨æ€ã€‚ç ”ç©¶å‘ç°ä¸åŒLLMè¡¨ç°å‡ºä¸åŒçš„åè§ï¼Œå½±å“ä¾µç•¥ä¸åˆä½œç­–ç•¥çš„ç›¸å¯¹æˆåŠŸã€‚è¯¥ç ”ç©¶ä¸ºéƒ¨ç½²çš„LLMè‡ªä¸»ä»£ç†ç³»ç»Ÿçš„æ½œåœ¨é•¿æœŸè¡Œä¸ºæä¾›äº†è§è§£ï¼Œå¹¶å¼ºè°ƒäº†è€ƒè™‘å…¶è¿è¥æˆ˜ç•¥ç¯å¢ƒçš„é‡è¦æ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤§å‹è¯­è¨€æ¨¡å‹ä»£ç†åœ¨ç¤¾äº¤å›°å¢ƒä¸­å±•ç°å‡ºæ–°å…´åˆä½œå€¾å‘ã€‚</li>
<li>ä¸ä»¥å¾€ç ”ç©¶ä¸åŒï¼Œæœ¬ç ”ç©¶å…³æ³¨LLMåœ¨é‡å¤å›šå¾’å›°å¢ƒä¸­çš„å®Œæ•´ç­–ç•¥ç”Ÿæˆã€‚</li>
<li>é‡‡ç”¨æ¼”åŒ–åšå¼ˆç†è®ºæ¨¡æ‹Ÿä¸åŒç­–ç•¥å€¾å‘çš„ä»£ç†äººç¾¤ä½“ã€‚</li>
<li>ä¸åŒLLMåœ¨æˆ˜ç•¥äº¤äº’ä¸­è¡¨ç°å‡ºä¸åŒçš„åè§ã€‚</li>
<li>ä¾µç•¥æ€§å’Œåˆä½œæ€§ç­–ç•¥çš„ç›¸å¯¹æˆåŠŸå—LLMåè§å½±å“ã€‚</li>
<li>è¯¥ç ”ç©¶æ­ç¤ºäº†éƒ¨ç½²çš„LLMè‡ªä¸»ä»£ç†ç³»ç»Ÿçš„æ½œåœ¨é•¿æœŸè¡Œä¸ºã€‚</li>
<li>è€ƒè™‘åˆ°æˆ˜ç•¥ç¯å¢ƒå¯¹LLMè‡ªä¸»ä»£ç†çš„å½±å“è‡³å…³é‡è¦ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.16173">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-3244b4f986daa13299041ed2a9bdeb0e.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-5702f55657a9d27828b27688c77f8ed8.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c23265d64dde7aaa4352789a4ece2ebb.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-937aaf7e0f05c0e83647ae282bd60ab2.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-8816d5d31732a351c6c9f9913c60caa5.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="Multi-Agent-Meta-Offline-Reinforcement-Learning-for-Timely-UAV-Path-Planning-and-Data-Collection"><a href="#Multi-Agent-Meta-Offline-Reinforcement-Learning-for-Timely-UAV-Path-Planning-and-Data-Collection" class="headerlink" title="Multi-Agent Meta-Offline Reinforcement Learning for Timely UAV Path   Planning and Data Collection"></a>Multi-Agent Meta-Offline Reinforcement Learning for Timely UAV Path   Planning and Data Collection</h2><p><strong>Authors:Eslam Eldeeb, Hirley Alves</strong></p>
<p>Multi-agent reinforcement learning (MARL) has been widely adopted in high-performance computing and complex data-driven decision-making in the wireless domain. However, conventional MARL schemes face many obstacles in real-world scenarios. First, most MARL algorithms are online, which might be unsafe and impractical. Second, MARL algorithms are environment-specific, meaning network configuration changes require model retraining. This letter proposes a novel meta-offline MARL algorithm that combines conservative Q-learning (CQL) and model agnostic meta-learning (MAML). CQL enables offline training by leveraging pre-collected datasets, while MAML ensures scalability and adaptability to dynamic network configurations and objectives. We propose two algorithm variants: independent training (M-I-MARL) and centralized training decentralized execution (M-CTDE-MARL). Simulation results show that the proposed algorithm outperforms conventional schemes, especially the CTDE approach that achieves 50 % faster convergence in dynamic scenarios than the benchmarks. The proposed framework enhances scalability, robustness, and adaptability in wireless communication systems by optimizing UAV trajectories and scheduling policies. </p>
<blockquote>
<p>å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ ï¼ˆMARLï¼‰å·²è¢«å¹¿æ³›åº”ç”¨äºæ— çº¿é€šä¿¡é¢†åŸŸçš„é«˜æ€§èƒ½è®¡ç®—å’Œå¤æ‚æ•°æ®é©±åŠ¨å†³ç­–ã€‚ç„¶è€Œï¼Œä¼ ç»Ÿçš„MARLæ–¹æ¡ˆåœ¨å®é™…åœºæ™¯ä¸­é¢ä¸´è®¸å¤šéšœç¢ã€‚é¦–å…ˆï¼Œå¤§å¤šæ•°MARLç®—æ³•æ˜¯åœ¨çº¿çš„ï¼Œè¿™å¯èƒ½ä¼šå¸¦æ¥å®‰å…¨éšæ‚£ä¸”ä¸å¤ªå®ç”¨ã€‚å…¶æ¬¡ï¼ŒMARLç®—æ³•å…·æœ‰ç¯å¢ƒç‰¹å®šæ€§ï¼Œæ„å‘³ç€ç½‘ç»œé…ç½®æ›´æ”¹éœ€è¦æ¨¡å‹é‡æ–°è®­ç»ƒã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°å‹çš„å…ƒç¦»çº¿MARLç®—æ³•ï¼Œè¯¥ç®—æ³•ç»“åˆäº†ä¿å®ˆQå­¦ä¹ ï¼ˆCQLï¼‰å’Œæ¨¡å‹ä¸å¯çŸ¥å…ƒå­¦ä¹ ï¼ˆMAMLï¼‰ã€‚CQLé€šè¿‡åˆ©ç”¨é¢„å…ˆæ”¶é›†çš„æ•°æ®é›†è¿›è¡Œç¦»çº¿è®­ç»ƒï¼Œè€ŒMAMLç¡®ä¿äº†å¯¹åŠ¨æ€ç½‘ç»œé…ç½®å’Œç›®æ ‡çš„å¯æ‰©å±•æ€§å’Œé€‚åº”æ€§ã€‚æˆ‘ä»¬æå‡ºäº†ä¸¤ç§ç®—æ³•å˜ä½“ï¼šç‹¬ç«‹è®­ç»ƒï¼ˆM-I-MARLï¼‰å’Œé›†ä¸­å¼è®­ç»ƒåˆ†å¸ƒå¼æ‰§è¡Œï¼ˆM-CTDE-MARLï¼‰ã€‚ä»¿çœŸç»“æœè¡¨æ˜ï¼Œæ‰€æå‡ºçš„ç®—æ³•ä¼˜äºä¼ ç»Ÿæ–¹æ¡ˆï¼Œå°¤å…¶æ˜¯CTDEæ–¹æ³•ï¼Œåœ¨åŠ¨æ€åœºæ™¯ä¸­å®ç°äº†æ¯”åŸºå‡†æµ‹è¯•å¿«50%çš„æ”¶æ•›é€Ÿåº¦ã€‚é€šè¿‡ä¼˜åŒ–æ— äººæœºè½¨è¿¹å’Œè°ƒåº¦ç­–ç•¥ï¼Œæ‰€æå‡ºçš„æ¡†æ¶æé«˜äº†æ— çº¿é€šä¿¡ç³»ç»Ÿçš„å¯æ‰©å±•æ€§ã€é²æ£’æ€§å’Œé€‚åº”æ€§ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.16098v1">PDF</a> </p>
<p><strong>Summary</strong><br>å¼ºåŒ–å­¦ä¹ åœ¨å¤šæ™ºèƒ½ä½“ç³»ç»Ÿï¼ˆMulti-Agent Reinforcement Learningï¼Œç®€ç§°MARLï¼‰ä¸­å¹¿æ³›ç”¨äºé«˜æ€§èƒ½è®¡ç®—å’Œæ— çº¿é¢†åŸŸçš„æ•°æ®é©±åŠ¨å†³ç­–ã€‚ç„¶è€Œï¼Œä¼ ç»Ÿçš„MARLæ–¹æ¡ˆåœ¨ç°å®åœºæ™¯ä¸­é¢ä¸´è¯¸å¤šæŒ‘æˆ˜ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§ç»“åˆä¿å®ˆQå­¦ä¹ ï¼ˆCQLï¼‰å’Œæ¨¡å‹ä¸å¯çŸ¥å…ƒå­¦ä¹ ï¼ˆMAMLï¼‰çš„å…ƒç¦»çº¿MARLç®—æ³•ã€‚CQLåˆ©ç”¨é¢„å…ˆæ”¶é›†çš„æ•°æ®é›†è¿›è¡Œç¦»çº¿è®­ç»ƒï¼Œè€ŒMAMLç¡®ä¿äº†å¯¹åŠ¨æ€ç½‘ç»œé…ç½®å’Œç›®æ ‡çš„é€‚åº”æ€§å’Œå¯æ‰©å±•æ€§ã€‚ä»¿çœŸç»“æœè¡¨æ˜ï¼Œè¯¥ç®—æ³•ä¼˜äºä¼ ç»Ÿæ–¹æ¡ˆï¼Œç‰¹åˆ«æ˜¯CTDEæ–¹æ³•åœ¨åŠ¨æ€åœºæ™¯ä¸­çš„æ”¶æ•›é€Ÿåº¦æé«˜äº†50%ã€‚è¯¥æ¡†æ¶é€šè¿‡ä¼˜åŒ–æ— äººæœºè½¨è¿¹å’Œè°ƒåº¦ç­–ç•¥ï¼Œæé«˜äº†æ— çº¿é€šä¿¡ç³»ç»Ÿçš„å¯æ‰©å±•æ€§ã€é²æ£’æ€§å’Œé€‚åº”æ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ ï¼ˆMARLï¼‰åœ¨æ— çº¿é¢†åŸŸçš„é«˜æ€§èƒ½è®¡ç®—å’Œå¤æ‚æ•°æ®é©±åŠ¨å†³ç­–ä¸­æœ‰å¹¿æ³›åº”ç”¨ã€‚</li>
<li>ä¼ ç»ŸMARLæ–¹æ¡ˆåœ¨ç°å®åœºæ™¯ä¸­å­˜åœ¨åœ¨çº¿è®­ç»ƒä¸å®‰å…¨ã€ä¸å®é™…çš„é—®é¢˜ã€‚</li>
<li>æœ¬æ–‡æå‡ºäº†ä¸€ç§å…ƒç¦»çº¿MARLç®—æ³•ï¼Œç»“åˆä¿å®ˆQå­¦ä¹ ï¼ˆCQLï¼‰å’Œæ¨¡å‹ä¸å¯çŸ¥å…ƒå­¦ä¹ ï¼ˆMAMLï¼‰ã€‚</li>
<li>CQLå…è®¸ç¦»çº¿è®­ç»ƒï¼Œåˆ©ç”¨é¢„å…ˆæ”¶é›†çš„æ•°æ®é›†ï¼›MAMLç¡®ä¿å¯¹åŠ¨æ€ç½‘ç»œé…ç½®å’Œç›®æ ‡çš„é€‚åº”æ€§å’Œå¯æ‰©å±•æ€§ã€‚</li>
<li>æå‡ºäº†ä¸¤ç§ç®—æ³•å˜ä½“ï¼šç‹¬ç«‹è®­ç»ƒï¼ˆM-I-MARLï¼‰å’Œé›†ä¸­è®­ç»ƒåˆ†æ•£æ‰§è¡Œï¼ˆM-CTDE-MARLï¼‰ã€‚</li>
<li>ä»¿çœŸç»“æœæ˜¾ç¤ºï¼Œæ‰€æç®—æ³•ä¼˜äºä¼ ç»Ÿæ–¹æ¡ˆï¼Œç‰¹åˆ«æ˜¯åœ¨åŠ¨æ€åœºæ™¯ä¸­çš„æ”¶æ•›é€Ÿåº¦ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.16098">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-6d5a9f9f1f83b78d61b1a4d497ab4c88.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-58c5a7592a0e952e9086a8fc706b9994.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-8e7cdf299c70ed28ffd4a9cc8ef6ec55.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-82298fd62c6ab54e78365922b559493b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-8285c6a8c2acf98c4d4abc0b697b4694.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="Harnessing-Diverse-Perspectives-A-Multi-Agent-Framework-for-Enhanced-Error-Detection-in-Knowledge-Graphs"><a href="#Harnessing-Diverse-Perspectives-A-Multi-Agent-Framework-for-Enhanced-Error-Detection-in-Knowledge-Graphs" class="headerlink" title="Harnessing Diverse Perspectives: A Multi-Agent Framework for Enhanced   Error Detection in Knowledge Graphs"></a>Harnessing Diverse Perspectives: A Multi-Agent Framework for Enhanced   Error Detection in Knowledge Graphs</h2><p><strong>Authors:Yu Li, Yi Huang, Guilin Qi, Junlan Feng, Nan Hu, Songlin Zhai, Haohan Xue, Yongrui Chen, Ruoyan Shen, Tongtong Wu</strong></p>
<p>Knowledge graphs are widely used in industrial applications, making error detection crucial for ensuring the reliability of downstream applications. Existing error detection methods often fail to effectively leverage fine-grained subgraph information and rely solely on fixed graph structures, while also lacking transparency in their decision-making processes, which results in suboptimal detection performance. In this paper, we propose a novel Multi-Agent framework for Knowledge Graph Error Detection (MAKGED) that utilizes multiple large language models (LLMs) in a collaborative setting. By concatenating fine-grained, bidirectional subgraph embeddings with LLM-based query embeddings during training, our framework integrates these representations to produce four specialized agents. These agents utilize subgraph information from different dimensions to engage in multi-round discussions, thereby improving error detection accuracy and ensuring a transparent decision-making process. Extensive experiments on FB15K and WN18RR demonstrate that MAKGED outperforms state-of-the-art methods, enhancing the accuracy and robustness of KG evaluation. For specific industrial scenarios, our framework can facilitate the training of specialized agents using domain-specific knowledge graphs for error detection, which highlights the potential industrial application value of our framework. Our code and datasets are available at <a target="_blank" rel="noopener" href="https://github.com/kse-ElEvEn/MAKGED">https://github.com/kse-ElEvEn/MAKGED</a>. </p>
<blockquote>
<p>çŸ¥è¯†å›¾è°±åœ¨å·¥ä¸šåº”ç”¨ä¸­å¾—åˆ°äº†å¹¿æ³›åº”ç”¨ï¼Œå› æ­¤é”™è¯¯æ£€æµ‹å¯¹äºç¡®ä¿ä¸‹æ¸¸åº”ç”¨çš„å¯é æ€§è‡³å…³é‡è¦ã€‚ç°æœ‰çš„é”™è¯¯æ£€æµ‹æ–¹æ³•å¾€å¾€ä¸èƒ½æœ‰æ•ˆåœ°åˆ©ç”¨ç»†ç²’åº¦å­å›¾ä¿¡æ¯ï¼Œä»…ä¾èµ–äºå›ºå®šå›¾ç»“æ„ï¼Œä¸”å†³ç­–è¿‡ç¨‹ç¼ºä¹é€æ˜åº¦ï¼Œå¯¼è‡´æ£€æµ‹æ€§èƒ½ä¸ä½³ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§ç”¨äºçŸ¥è¯†å›¾è°±é”™è¯¯æ£€æµ‹çš„å¤šæ™ºèƒ½ä½“æ¡†æ¶ï¼ˆMAKGEDï¼‰ï¼Œè¯¥æ¡†æ¶åœ¨åä½œç¯å¢ƒä¸­åˆ©ç”¨å¤šä¸ªå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ã€‚é€šè¿‡è®­ç»ƒè¿‡ç¨‹ä¸­ç»†ç²’åº¦åŒå‘å­å›¾åµŒå…¥ä¸åŸºäºLLMçš„æŸ¥è¯¢åµŒå…¥çš„è¿æ¥ï¼Œæˆ‘ä»¬çš„æ¡†æ¶å°†è¿™äº›è¡¨ç¤ºé›†æˆåœ¨ä¸€èµ·ï¼Œäº§ç”Ÿå››ä¸ªä¸“ä¸šæ™ºèƒ½ä½“ã€‚è¿™äº›æ™ºèƒ½ä½“åˆ©ç”¨æ¥è‡ªä¸åŒç»´åº¦çš„å­å›¾ä¿¡æ¯è¿›è¡Œå¤šè½®è®¨è®ºï¼Œä»è€Œæé«˜é”™è¯¯æ£€æµ‹ç²¾åº¦ï¼Œå¹¶ç¡®ä¿é€æ˜çš„å†³ç­–è¿‡ç¨‹ã€‚åœ¨FB15Kå’ŒWN18RRä¸Šçš„å¤§é‡å®éªŒè¡¨æ˜ï¼ŒMAKGEDä¼˜äºæœ€æ–°æ–¹æ³•ï¼Œæé«˜äº†çŸ¥è¯†å›¾è°±è¯„ä¼°çš„å‡†ç¡®æ€§å’Œç¨³å¥æ€§ã€‚å¯¹äºç‰¹å®šçš„å·¥ä¸šåœºæ™¯ï¼Œæˆ‘ä»¬çš„æ¡†æ¶å¯ä»¥åˆ©ç”¨é¢†åŸŸç‰¹å®šçš„çŸ¥è¯†å›¾è°±è®­ç»ƒä¸“ä¸šæ™ºèƒ½ä½“è¿›è¡Œé”™è¯¯æ£€æµ‹ï¼Œè¿™å‡¸æ˜¾äº†æˆ‘ä»¬æ¡†æ¶æ½œåœ¨çš„å·¥ä¸šåº”ç”¨ä»·å€¼ã€‚æˆ‘ä»¬çš„ä»£ç å’Œæ•°æ®é›†å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/kse-ElEvEn/MAKGED">https://github.com/kse-ElEvEn/MAKGED</a>è·å¾—ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.15791v1">PDF</a> </p>
<p><strong>Summary</strong><br>çŸ¥è¯†å›¾è°±åœ¨å·¥ä¸šåº”ç”¨ä¸­çš„é”™è¯¯æ£€æµ‹è‡³å…³é‡è¦ã€‚ç°æœ‰æ–¹æ³•æœªèƒ½æœ‰æ•ˆåˆ©ç”¨ç»†ç²’åº¦å­å›¾ä¿¡æ¯ï¼Œä¸”å†³ç­–è¿‡ç¨‹ç¼ºä¹é€æ˜åº¦ã€‚æœ¬æ–‡æå‡ºä¸€ç§åŸºäºå¤šæ™ºèƒ½ä½“çš„çŸ¥è¯†å›¾è°±é”™è¯¯æ£€æµ‹æ¡†æ¶ï¼ˆMAKGEDï¼‰ï¼Œç»“åˆç»†ç²’åº¦å­å›¾åµŒå…¥ä¸å¤§å‹è¯­è¨€æ¨¡å‹æŸ¥è¯¢åµŒå…¥ã€‚é€šè¿‡è®­ç»ƒç”Ÿæˆå››ä¸ªä¸“ä¸šæ™ºèƒ½ä½“ï¼Œåˆ©ç”¨ä¸åŒç»´åº¦çš„å­å›¾ä¿¡æ¯å‚ä¸å¤šè½®è®¨è®ºï¼Œæé«˜é”™è¯¯æ£€æµ‹å‡†ç¡®æ€§å’Œå†³ç­–é€æ˜åº¦ã€‚å®éªŒè¡¨æ˜ï¼ŒMAKGEDä¼˜äºç°æœ‰æ–¹æ³•ï¼Œå¯æé«˜çŸ¥è¯†å›¾è°±è¯„ä¼°çš„å‡†ç¡®æ€§å’Œç¨³å¥æ€§ï¼Œå…·æœ‰å·¥ä¸šåº”ç”¨æ½œåŠ›ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>çŸ¥è¯†å›¾è°±åœ¨å·¥ä¸šåº”ç”¨ä¸­çš„é”™è¯¯æ£€æµ‹å¾ˆé‡è¦ï¼Œå½±å“ä¸‹æ¸¸åº”ç”¨çš„å¯é æ€§ã€‚</li>
<li>ç°æœ‰é”™è¯¯æ£€æµ‹æ–¹æ³•æœªèƒ½æœ‰æ•ˆåˆ©ç”¨ç»†ç²’åº¦å­å›¾ä¿¡æ¯ï¼Œå†³ç­–è¿‡ç¨‹ç¼ºä¹é€æ˜åº¦ã€‚</li>
<li>æœ¬æ–‡æå‡ºåŸºäºå¤šæ™ºèƒ½ä½“çš„çŸ¥è¯†å›¾è°±é”™è¯¯æ£€æµ‹æ¡†æ¶ï¼ˆMAKGEDï¼‰ã€‚</li>
<li>MAKGEDç»“åˆç»†ç²’åº¦å­å›¾åµŒå…¥å’Œå¤§å‹è¯­è¨€æ¨¡å‹æŸ¥è¯¢åµŒå…¥ï¼Œç”Ÿæˆå››ä¸ªä¸“ä¸šæ™ºèƒ½ä½“ã€‚</li>
<li>è¿™äº›æ™ºèƒ½ä½“åˆ©ç”¨ä¸åŒç»´åº¦çš„å­å›¾ä¿¡æ¯è¿›è¡Œå¤šè½®è®¨è®ºï¼Œæé«˜é”™è¯¯æ£€æµ‹å‡†ç¡®æ€§å’Œå†³ç­–é€æ˜åº¦ã€‚</li>
<li>å®éªŒè¯æ˜ï¼ŒMAKGEDä¼˜äºç°æœ‰æ–¹æ³•ï¼Œæé«˜çŸ¥è¯†å›¾è°±è¯„ä¼°çš„å‡†ç¡®æ€§å’Œç¨³å¥æ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.15791">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-3f7c09bd60e210d26dda8526d7ab7e2e.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-126ca263648d9cd60b51d2af93171882.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-17ffd2a5700a070175f49091f796c4f3.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="LLM-powered-Multi-agent-Framework-for-Goal-oriented-Learning-in-Intelligent-Tutoring-System"><a href="#LLM-powered-Multi-agent-Framework-for-Goal-oriented-Learning-in-Intelligent-Tutoring-System" class="headerlink" title="LLM-powered Multi-agent Framework for Goal-oriented Learning in   Intelligent Tutoring System"></a>LLM-powered Multi-agent Framework for Goal-oriented Learning in   Intelligent Tutoring System</h2><p><strong>Authors:Tianfu Wang, Yi Zhan, Jianxun Lian, Zhengyu Hu, Nicholas Jing Yuan, Qi Zhang, Xing Xie, Hui Xiong</strong></p>
<p>Intelligent Tutoring Systems (ITSs) have revolutionized education by offering personalized learning experiences. However, as goal-oriented learning, which emphasizes efficiently achieving specific objectives, becomes increasingly important in professional contexts, existing ITSs often struggle to deliver this type of targeted learning experience. In this paper, we propose GenMentor, an LLM-powered multi-agent framework designed to deliver goal-oriented, personalized learning within ITS. GenMentor begins by accurately mapping learnersâ€™ goals to required skills using a fine-tuned LLM trained on a custom goal-to-skill dataset. After identifying the skill gap, it schedules an efficient learning path using an evolving optimization approach, driven by a comprehensive and dynamic profile of learnersâ€™ multifaceted status. Additionally, GenMentor tailors learning content with an exploration-drafting-integration mechanism to align with individual learner needs. Extensive automated and human evaluations demonstrate GenMentorâ€™s effectiveness in learning guidance and content quality. Furthermore, we have deployed it in practice and also implemented it as an application. Practical human study with professional learners further highlights its effectiveness in goal alignment and resource targeting, leading to enhanced personalization. Supplementary resources are available at <a target="_blank" rel="noopener" href="https://github.com/GeminiLight/gen-mentor">https://github.com/GeminiLight/gen-mentor</a>. </p>
<blockquote>
<p>æ™ºèƒ½è¾…å¯¼ç³»ç»Ÿï¼ˆITSï¼‰é€šè¿‡æä¾›ä¸ªæ€§åŒ–çš„å­¦ä¹ ä½“éªŒï¼Œå·²ç»å½»åº•æ”¹å˜äº†æ•™è‚²æ–¹å¼ã€‚ç„¶è€Œï¼Œéšç€ä»¥è¾¾æˆç‰¹å®šç›®æ ‡ä¸ºç›®çš„çš„å­¦ä¹ åœ¨ä¸“ä¸šç¯å¢ƒä¸­å˜å¾—è¶Šæ¥è¶Šé‡è¦ï¼Œç°æœ‰ITSç³»ç»Ÿå¾€å¾€éš¾ä»¥æä¾›è¿™ç§æœ‰é’ˆå¯¹æ€§çš„å­¦ä¹ ä½“éªŒã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†GenMentorï¼Œè¿™æ˜¯ä¸€ä¸ªç”±å¤§å‹è¯­è¨€æ¨¡å‹é©±åŠ¨çš„å¤šæ™ºèƒ½ä½“æ¡†æ¶ï¼Œæ—¨åœ¨åœ¨ITSå†…éƒ¨æä¾›ä»¥ç›®æ ‡ä¸ºå¯¼å‘çš„ä¸ªæ€§åŒ–å­¦ä¹ ã€‚GenMentoré¦–å…ˆé€šè¿‡ç²¾ç¡®åœ°å°†å­¦ä¹ è€…çš„ç›®æ ‡æ˜ å°„åˆ°æ‰€éœ€æŠ€èƒ½æ¥ä½¿ç”¨ç»è¿‡å¾®è°ƒçš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼Œè¯¥æ¨¡å‹åœ¨ç‰¹å®šçš„ç›®æ ‡åˆ°æŠ€èƒ½æ•°æ®é›†ä¸Šè¿›è¡Œè®­ç»ƒã€‚åœ¨ç¡®å®šäº†æŠ€èƒ½å·®è·åï¼Œå®ƒä½¿ç”¨ä¸æ–­å‘å±•çš„ä¼˜åŒ–æ–¹æ³•ï¼Œç»“åˆå­¦ä¹ è€…çš„å¤šç»´åº¦çŠ¶æ€çš„å…¨é¢åŠ¨æ€æ¡£æ¡ˆï¼Œè§„åˆ’å‡ºé«˜æ•ˆçš„å­¦ä¹ è·¯å¾„ã€‚æ­¤å¤–ï¼ŒGenMentoré€šè¿‡æ¢ç´¢-èµ·è‰-æ•´åˆæœºåˆ¶æ¥å®šåˆ¶å­¦ä¹ å†…å®¹ï¼Œä»¥æ»¡è¶³ä¸ªåˆ«å­¦ä¹ è€…çš„éœ€æ±‚ã€‚å¹¿æ³›è‡ªåŠ¨å’Œäººç±»è¯„ä¼°è¯æ˜äº†GenMentoråœ¨å­¦ä¹ æŒ‡å¯¼å’Œå†…å®¹è´¨é‡æ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å·²ç»å°†å…¶éƒ¨ç½²åœ¨å®è·µä¸­ï¼Œå¹¶å¼€å‘ä¸ºåº”ç”¨ç¨‹åºã€‚ä¸ä¸“ä¸šå­¦ä¹ è€…è¿›è¡Œçš„å®é™…äººç±»ç ”ç©¶è¿›ä¸€æ­¥çªæ˜¾äº†å…¶åœ¨ç›®æ ‡å¯¹é½å’Œèµ„æºå®šä½æ–¹é¢çš„æœ‰æ•ˆæ€§ï¼Œä»è€Œå¢å¼ºäº†ä¸ªæ€§åŒ–ã€‚è¾…åŠ©èµ„æºå¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/GeminiLight/gen-mentor%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/GeminiLight/gen-mentoræ‰¾åˆ°ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.15749v1">PDF</a> Accepted by WWW 2025 (Industry Track)</p>
<p><strong>Summary</strong></p>
<p>æ™ºèƒ½è¾…å¯¼ç³»ç»Ÿï¼ˆITSï¼‰å·²ç»é€šè¿‡æä¾›ä¸ªæ€§åŒ–å­¦ä¹ ä½“éªŒå®ç°äº†æ•™è‚²çš„é©æ–°ã€‚ç„¶è€Œï¼Œéšç€èŒä¸šç¯å¢ƒä¸­ä»¥è¾¾æˆç‰¹å®šç›®æ ‡ä¸ºç›®çš„çš„å­¦ä¹ æ—¥ç›Šé‡è¦ï¼Œç°æœ‰ITSåœ¨æä¾›æ­¤ç±»æœ‰é’ˆå¯¹æ€§çš„å­¦ä¹ ä½“éªŒæ–¹é¢å¾€å¾€åŠ›ä¸ä»å¿ƒã€‚æœ¬æ–‡æå‡ºäº†GenMentorç³»ç»Ÿï¼Œè¿™æ˜¯ä¸€ä¸ªç”±å¤§å‹è¯­è¨€æ¨¡å‹é©±åŠ¨çš„å¤šæ™ºèƒ½ä½“æ¡†æ¶ï¼Œæ—¨åœ¨åœ¨ITSä¸­å®ç°ä»¥ç›®æ ‡ä¸ºå¯¼å‘çš„ä¸ªæ€§åŒ–å­¦ä¹ ã€‚GenMentoré¦–å…ˆé€šè¿‡ç²¾ç¡®æ˜ å°„å­¦ä¹ è€…ç›®æ ‡ä¸æ‰€éœ€æŠ€èƒ½ï¼Œåˆ©ç”¨ç»è¿‡å¾®è°ƒçš„å¤§å‹è¯­è¨€æ¨¡å‹æ¥ç¡®å®šæŠ€èƒ½å·®è·ã€‚ç„¶åï¼Œå®ƒä½¿ç”¨ä¸€ç§ä¸æ–­å‘å±•çš„ä¼˜åŒ–æ–¹æ³•ï¼Œæ ¹æ®å­¦ä¹ è€…çš„å¤šç»´åŠ¨æ€çŠ¶æ€æ¥è§„åˆ’é«˜æ•ˆçš„å­¦ä¹ è·¯å¾„ã€‚æ­¤å¤–ï¼ŒGenMentorè¿˜é€šè¿‡æ¢ç´¢-èµ·è‰-æ•´åˆæœºåˆ¶æ¥å®šåˆ¶å­¦ä¹ å†…å®¹ï¼Œä»¥æ»¡è¶³ä¸ªäººéœ€æ±‚ã€‚å¤§é‡è‡ªåŠ¨åŒ–å’Œäººç±»è¯„ä¼°ç»“æœè¡¨æ˜ï¼ŒGenMentoråœ¨å­¦ä¹ æŒ‡å¯¼å’Œå†…å®¹è´¨é‡æ–¹é¢éå¸¸æœ‰æ•ˆã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å·²ç»åœ¨å®è·µä¸­éƒ¨ç½²äº†å®ƒå¹¶å°†å…¶å¼€å‘ä¸ºåº”ç”¨ç¨‹åºã€‚ä¸ä¸“ä¸šå­¦ä¹ è€…çš„å®é™…äººç±»ç ”ç©¶è¿›ä¸€æ­¥çªå‡ºäº†å…¶åœ¨ç›®æ ‡å¯¹é½å’Œèµ„æºå®šä½æ–¹é¢çš„æœ‰æ•ˆæ€§ï¼Œä»è€Œå®ç°äº†å¢å¼ºçš„ä¸ªæ€§åŒ–ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æ™ºèƒ½è¾…å¯¼ç³»ç»Ÿï¼ˆITSï¼‰å·²ç»å®ç°äº†æ•™è‚²çš„ä¸ªæ€§åŒ–é©æ–°ï¼Œä½†åœ¨æä¾›ç›®æ ‡å¯¼å‘çš„å­¦ä¹ ä½“éªŒæ–¹é¢å­˜åœ¨æŒ‘æˆ˜ã€‚</li>
<li>GenMentoræ˜¯ä¸€ä¸ªå¤šæ™ºèƒ½ä½“æ¡†æ¶ï¼Œæ—¨åœ¨é€šè¿‡å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æŠ€æœ¯è§£å†³è¿™ä¸€é—®é¢˜ã€‚</li>
<li>GenMentorèƒ½å‡†ç¡®æ˜ å°„å­¦ä¹ è€…ç›®æ ‡ä¸æ‰€éœ€æŠ€èƒ½ï¼Œå¹¶ç¡®å®šæŠ€èƒ½å·®è·ã€‚</li>
<li>è¯¥ç³»ç»Ÿä½¿ç”¨ä¼˜åŒ–æ–¹æ³•ä¸ºå­¦ä¹ è€…è§„åˆ’é«˜æ•ˆå­¦ä¹ è·¯å¾„ï¼Œå¹¶è€ƒè™‘å­¦ä¹ è€…çš„å¤šç»´åŠ¨æ€çŠ¶æ€ã€‚</li>
<li>GenMentoré€šè¿‡æ¢ç´¢-èµ·è‰-æ•´åˆæœºåˆ¶å®šåˆ¶å­¦ä¹ å†…å®¹ï¼Œä»¥æ»¡è¶³ä¸ªäººéœ€æ±‚ã€‚</li>
<li>è‡ªåŠ¨åŒ–å’Œäººç±»è¯„ä¼°è¯æ˜äº†GenMentoråœ¨å­¦ä¹ æŒ‡å¯¼å’Œå†…å®¹è´¨é‡æ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚</li>
<li>GenMentorå·²åœ¨å®è·µä¸­éƒ¨ç½²ï¼Œå¹¶ä½œä¸ºåº”ç”¨ç¨‹åºå®ç°ï¼Œä¸ä¸“ä¸šå­¦ä¹ è€…çš„ç ”ç©¶çªå‡ºäº†å…¶åœ¨ç›®æ ‡å¯¹é½å’Œèµ„æºå®šä½æ–¹é¢çš„ä¼˜åŠ¿ï¼Œå¢å¼ºäº†ä¸ªæ€§åŒ–å­¦ä¹ ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.15749">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-e05bc2fc215cc95978ced0ac078387ec.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-fb2ae0965f5f59a6ee0d79e0befb5963.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-dce57ce8fae2d533505a427fb8a1f065.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-ea008ff289be01fbceadad64106ab68f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-57421d44d38630d06214bccb8b5d5727.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-4e7ad9a359ae39aabab623296e5a00b7.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="Expert-Free-Online-Transfer-Learning-in-Multi-Agent-Reinforcement-Learning"><a href="#Expert-Free-Online-Transfer-Learning-in-Multi-Agent-Reinforcement-Learning" class="headerlink" title="Expert-Free Online Transfer Learning in Multi-Agent Reinforcement   Learning"></a>Expert-Free Online Transfer Learning in Multi-Agent Reinforcement   Learning</h2><p><strong>Authors:Alberto Castagna</strong></p>
<p>Reinforcement Learning (RL) enables an intelligent agent to optimise its performance in a task by continuously taking action from an observed state and receiving a feedback from the environment in form of rewards. RL typically uses tables or linear approximators to map state-action tuples that maximises the reward. Combining RL with deep neural networks (DRL) significantly increases its scalability and enables it to address more complex problems than before. However, DRL also inherits downsides from both RL and deep learning. Despite DRL improves generalisation across similar state-action pairs when compared to simpler RL policy representations like tabular methods, it still requires the agent to adequately explore the state-action space. Additionally, deep methods require more training data, with the volume of data escalating with the complexity and size of the neural network. As a result, deep RL requires a long time to collect enough agent-environment samples and to successfully learn the underlying policy. Furthermore, often even a slight alteration to the task invalidates any previous acquired knowledge. To address these shortcomings, Transfer Learning (TL) has been introduced, which enables the use of external knowledge from other tasks or agents to enhance a learning process. The goal of TL is to reduce the learning complexity for an agent dealing with an unfamiliar task by simplifying the exploration process. This is achieved by lowering the amount of new information required by its learning model, resulting in a reduced overall convergence timeâ€¦ </p>
<blockquote>
<p>å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰å…è®¸æ™ºèƒ½ä»£ç†é€šè¿‡ä¸æ–­ä»è§‚å¯Ÿåˆ°çš„çŠ¶æ€é‡‡å–è¡ŒåŠ¨å¹¶ä»ç¯å¢ƒä¸­è·å¾—å¥–åŠ±çš„åé¦ˆæ¥ä¼˜åŒ–å…¶åœ¨ä»»åŠ¡ä¸­çš„è¡¨ç°ã€‚RLé€šå¸¸ä½¿ç”¨è¡¨æ ¼æˆ–çº¿æ€§é€¼è¿‘å™¨æ¥æ˜ å°„æœ€å¤§åŒ–å¥–åŠ±çš„çŠ¶æ€-è¡ŒåŠ¨ç»„åˆã€‚å°†RLä¸æ·±åº¦ç¥ç»ç½‘ç»œï¼ˆDRLï¼‰ç›¸ç»“åˆï¼Œæ˜¾è‘—æé«˜äº†å…¶å¯æ‰©å±•æ€§ï¼Œå¹¶ä½¿å…¶èƒ½å¤Ÿè§£å†³æ¯”ä»¥å‰æ›´å¤æ‚çš„é—®é¢˜ã€‚ç„¶è€Œï¼ŒDRLä¹Ÿç»§æ‰¿äº†RLå’Œæ·±åº¦å­¦ä¹ ä¸¤è€…çš„ç¼ºç‚¹ã€‚ä¸åƒè¡¨æ ¼æ–¹æ³•è¿™æ ·æ›´ç®€å•çš„RLæ”¿ç­–è¡¨ç¤ºç›¸æ¯”ï¼ŒDRLåœ¨ç±»ä¼¼çš„å·è¡ŒåŠ¨å¯¹ä¸Šæé«˜äº†æ³›åŒ–èƒ½åŠ›ï¼Œä½†å®ƒä»ç„¶è¦æ±‚ä»£ç†å……åˆ†æ¢ç´¢å·è¡ŒåŠ¨ç©ºé—´ã€‚æ­¤å¤–ï¼Œæ·±åº¦æ–¹æ³•éœ€è¦æ›´å¤šçš„è®­ç»ƒæ•°æ®ï¼Œéšç€ç¥ç»ç½‘ç»œå¤æ‚æ€§å’Œè§„æ¨¡çš„å¢åŠ ï¼Œæ‰€éœ€æ•°æ®é‡ä¹Ÿåœ¨ä¸Šå‡ã€‚å› æ­¤ï¼Œæ·±åº¦RLéœ€è¦å¾ˆé•¿æ—¶é—´æ¥æ”¶é›†è¶³å¤Ÿçš„ä»£ç†ç¯å¢ƒæ ·æœ¬å¹¶æˆåŠŸå­¦ä¹ åŸºç¡€ç­–ç•¥ã€‚æ­¤å¤–ï¼Œä»»åŠ¡çš„å¾®å°å˜åŒ–å¾€å¾€ä¼šä½¿å¾—ä¹‹å‰è·å¾—çš„çŸ¥è¯†æ— æ•ˆã€‚ä¸ºäº†è§£å†³è¿™äº›ä¸è¶³ï¼Œå¼•å…¥äº†è¿ç§»å­¦ä¹ ï¼ˆTLï¼‰ï¼Œå®ƒå…è®¸ä½¿ç”¨æ¥è‡ªå…¶ä»–ä»»åŠ¡æˆ–ä»£ç†çš„å¤–éƒ¨çŸ¥è¯†æ¥å¢å¼ºå­¦ä¹ è¿‡ç¨‹ã€‚TLçš„ç›®æ ‡æ˜¯é€šè¿‡ç®€åŒ–æ¢ç´¢è¿‡ç¨‹ï¼Œé™ä½ä»£ç†å¤„ç†ä¸ç†Ÿæ‚‰ä»»åŠ¡çš„å­¦ä¹ å¤æ‚æ€§ã€‚è¿™æ˜¯é€šè¿‡å‡å°‘å…¶å­¦ä¹ æ¨¡å‹æ‰€éœ€çš„æ–°ä¿¡æ¯é‡æ¥å®ç°çš„ï¼Œä»è€Œç¼©çŸ­äº†æ•´ä½“çš„æ”¶æ•›æ—¶é—´â€¦</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.15495v1">PDF</a> PhD Thesis</p>
<p><strong>Summary</strong><br>å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰é€šè¿‡è®©æ™ºèƒ½ä»£ç†ä»è§‚å¯Ÿåˆ°çš„çŠ¶æ€é‡‡å–è¡ŒåŠ¨å¹¶ä»ç¯å¢ƒä¸­è·å¾—å¥–åŠ±åé¦ˆæ¥ä¼˜åŒ–ä»»åŠ¡æ€§èƒ½ã€‚RLé€šå¸¸ä½¿ç”¨è¡¨æ ¼æˆ–çº¿æ€§é€¼è¿‘å™¨æ¥æ˜ å°„çŠ¶æ€-åŠ¨ä½œç»„åˆï¼Œä»¥æœ€å¤§åŒ–å¥–åŠ±ã€‚ç»“åˆæ·±åº¦ç¥ç»ç½‘ç»œï¼ˆDRLï¼‰æ˜¾è‘—æé«˜äº†å…¶å¯æ‰©å±•æ€§ï¼Œå¹¶èƒ½å¤Ÿè§£å†³æ¯”ä¼ ç»ŸRLæ›´å¤æ‚çš„é—®é¢˜ã€‚ç„¶è€Œï¼ŒDRLä¹Ÿç»§æ‰¿äº†RLå’Œæ·±åº¦å­¦ä¹ çš„ä¸€äº›ç¼ºç‚¹ã€‚å°½ç®¡DRLåœ¨ä¸å…¶ä»–ç®€å•çš„RLç­–ç•¥è¡¨ç¤ºï¼ˆå¦‚è¡¨æ ¼æ–¹æ³•ï¼‰ç›¸æ¯”æ—¶ï¼Œåœ¨ç±»ä¼¼çŠ¶æ€-åŠ¨ä½œå¯¹ä¸Šå…·æœ‰æ›´å¥½çš„æ¦‚æ‹¬æ€§ï¼Œä½†å®ƒä»ç„¶è¦æ±‚ä»£ç†å……åˆ†æ¢ç´¢çŠ¶æ€-åŠ¨ä½œç©ºé—´ã€‚æ­¤å¤–ï¼Œæ·±åº¦æ–¹æ³•éœ€è¦æ›´å¤šçš„è®­ç»ƒæ•°æ®ï¼Œæ•°æ®é‡éšç€ç¥ç»ç½‘ç»œå¤æ‚æ€§å’Œè§„æ¨¡çš„å¢åŠ è€Œå¢åŠ ã€‚å› æ­¤ï¼Œæ·±åº¦å¼ºåŒ–å­¦ä¹ éœ€è¦å¤§é‡çš„æ—¶é—´æ”¶é›†è¶³å¤Ÿçš„ä»£ç†ç¯å¢ƒæ ·æœ¬å¹¶æˆåŠŸå­¦ä¹ åŸºç¡€ç­–ç•¥ã€‚ä¸ºè§£å†³è¿™äº›é—®é¢˜ï¼Œå¼•å…¥äº†è¿ç§»å­¦ä¹ ï¼ˆTLï¼‰ï¼Œå¯ä»¥åˆ©ç”¨å…¶ä»–ä»»åŠ¡æˆ–ä»£ç†çš„å¤–éƒ¨çŸ¥è¯†æ¥æé«˜å­¦ä¹ è¿‡ç¨‹ã€‚è¿ç§»å­¦ä¹ çš„ç›®æ ‡æ˜¯é™ä½ä»£ç†å¤„ç†ä¸ç†Ÿæ‚‰ä»»åŠ¡çš„å¤æ‚æ€§ï¼Œç®€åŒ–æ¢ç´¢è¿‡ç¨‹ã€‚é€šè¿‡å‡å°‘å­¦ä¹ æ¨¡å‹æ‰€éœ€çš„æ–°ä¿¡æ¯é‡æ¥å®ç°è¿™ä¸€ç›®æ ‡ï¼Œä»è€Œå‡å°‘æ•´ä½“æ”¶æ•›æ—¶é—´ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰å…è®¸æ™ºèƒ½ä»£ç†é€šè¿‡ä¸æ–­å°è¯•åŠ¨ä½œå’Œæ¥æ”¶ç¯å¢ƒåé¦ˆå¥–åŠ±æ¥ä¼˜åŒ–ä»»åŠ¡æ€§èƒ½ã€‚</li>
<li>ç»“åˆæ·±åº¦ç¥ç»ç½‘ç»œï¼ˆDRLï¼‰å¢å¼ºäº†å¼ºåŒ–å­¦ä¹ çš„å¯æ‰©å±•æ€§ï¼Œå¹¶è§£å†³äº†æ›´å¤æ‚çš„ä»»åŠ¡ã€‚</li>
<li>DRLé¢ä¸´æ¢ç´¢çŠ¶æ€-åŠ¨ä½œç©ºé—´çš„æŒ‘æˆ˜ï¼Œéœ€è¦ä»£ç†å……åˆ†æ¢ç´¢ã€‚</li>
<li>æ·±åº¦æ–¹æ³•éœ€è¦å¤§é‡çš„è®­ç»ƒæ•°æ®ï¼Œéšç€ç¥ç»ç½‘ç»œå¤æ‚æ€§å’Œè§„æ¨¡çš„å¢åŠ ï¼Œæ•°æ®é‡ä¹Ÿåœ¨å¢åŠ ã€‚</li>
<li>æ·±åº¦å¼ºåŒ–å­¦ä¹ éœ€è¦é•¿æ—¶é—´æ”¶é›†è¶³å¤Ÿçš„ä»£ç†ç¯å¢ƒæ ·æœ¬å¹¶æˆåŠŸå­¦ä¹ åŸºç¡€ç­–ç•¥ã€‚</li>
<li>è¿ç§»å­¦ä¹ ï¼ˆTLï¼‰åˆ©ç”¨å…¶ä»–ä»»åŠ¡æˆ–ä»£ç†çš„å¤–éƒ¨çŸ¥è¯†æ¥æé«˜å­¦ä¹ è¿‡ç¨‹ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.15495">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-1a761bcd25183653b018130119171123.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="Improving-Retrieval-Augmented-Generation-through-Multi-Agent-Reinforcement-Learning"><a href="#Improving-Retrieval-Augmented-Generation-through-Multi-Agent-Reinforcement-Learning" class="headerlink" title="Improving Retrieval-Augmented Generation through Multi-Agent   Reinforcement Learning"></a>Improving Retrieval-Augmented Generation through Multi-Agent   Reinforcement Learning</h2><p><strong>Authors:Yiqun Chen, Lingyong Yan, Weiwei Sun, Xinyu Ma, Yi Zhang, Shuaiqiang Wang, Dawei Yin, Yiming Yang, Jiaxin Mao</strong></p>
<p>Retrieval-augmented generation (RAG) is extensively utilized to incorporate external, current knowledge into large language models, thereby minimizing hallucinations. A standard RAG pipeline may comprise several components, such as query rewriting, document retrieval, document filtering, and answer generation. However, these components are typically optimized separately through supervised fine-tuning, which can lead to misalignments between the objectives of individual modules and the overarching aim of generating accurate answers in question-answering (QA) tasks. Although recent efforts have explored reinforcement learning (RL) to optimize specific RAG components, these approaches often focus on overly simplistic pipelines with only two components or do not adequately address the complex interdependencies and collaborative interactions among the modules. To overcome these challenges, we propose treating the RAG pipeline as a multi-agent cooperative task, with each component regarded as an RL agent. Specifically, we present MMOA-RAG, a Multi-Module joint Optimization Algorithm for RAG, which employs multi-agent reinforcement learning to harmonize all agentsâ€™ goals towards a unified reward, such as the F1 score of the final answer. Experiments conducted on various QA datasets demonstrate that MMOA-RAG improves the overall pipeline performance and outperforms existing baselines. Furthermore, comprehensive ablation studies validate the contributions of individual components and the adaptability of MMOA-RAG across different RAG components and datasets. The code of MMOA-RAG is on <a target="_blank" rel="noopener" href="https://github.com/chenyiqun/MMOA-RAG">https://github.com/chenyiqun/MMOA-RAG</a>. </p>
<blockquote>
<p>æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰è¢«å¹¿æ³›åº”ç”¨äºå°†å¤–éƒ¨ã€å½“å‰çš„çŸ¥è¯†èå…¥å¤§å‹è¯­è¨€æ¨¡å‹ï¼Œä»è€Œæœ€å°åŒ–å¹»è§‰ã€‚æ ‡å‡†çš„RAGæµç¨‹å¯èƒ½åŒ…å«å¤šä¸ªç»„ä»¶ï¼Œå¦‚æŸ¥è¯¢é‡å†™ã€æ–‡æ¡£æ£€ç´¢ã€æ–‡æ¡£è¿‡æ»¤å’Œç­”æ¡ˆç”Ÿæˆã€‚ç„¶è€Œï¼Œè¿™äº›ç»„ä»¶é€šå¸¸é€šè¿‡æœ‰ç›‘ç£çš„å¾®è°ƒè¿›è¡Œå•ç‹¬ä¼˜åŒ–ï¼Œè¿™å¯èƒ½å¯¼è‡´å„ä¸ªæ¨¡å—çš„ç›®æ ‡ä¸é—®ç­”ï¼ˆQAï¼‰ä»»åŠ¡ä¸­ç”Ÿæˆå‡†ç¡®ç­”æ¡ˆçš„æ€»ä½“ç›®æ ‡ä¹‹é—´å­˜åœ¨ä¸åŒ¹é…ã€‚å°½ç®¡æœ€è¿‘çš„åŠªåŠ›å·²ç»æ¢ç´¢äº†ä½¿ç”¨å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰æ¥ä¼˜åŒ–ç‰¹å®šçš„RAGç»„ä»¶ï¼Œä½†è¿™äº›æ–¹æ³•é€šå¸¸ä¸“æ³¨äºè¿‡äºç®€å•çš„ç®¡é“ï¼Œåªæœ‰ä¸¤ä¸ªç»„ä»¶ï¼Œæˆ–è€…æ²¡æœ‰å……åˆ†è§£å†³æ¨¡å—ä¹‹é—´çš„å¤æ‚ä¾èµ–å…³ç³»å’Œåä½œäº¤äº’ã€‚ä¸ºäº†å…‹æœè¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºå°†RAGæµç¨‹è§†ä¸ºå¤šä»£ç†åˆä½œä»»åŠ¡ï¼Œå¹¶å°†æ¯ä¸ªç»„ä»¶è§†ä¸ºRLä»£ç†ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬æå‡ºäº†MMOA-RAGï¼ˆç”¨äºRAGçš„å¤šæ¨¡å—è”åˆä¼˜åŒ–ç®—æ³•ï¼‰ï¼Œå®ƒé‡‡ç”¨å¤šä»£ç†å¼ºåŒ–å­¦ä¹ æ¥åè°ƒæ‰€æœ‰ä»£ç†çš„ç›®æ ‡ï¼Œä»¥è¾¾æˆç»Ÿä¸€çš„å¥–åŠ±ï¼Œå¦‚æœ€ç»ˆç­”æ¡ˆçš„F1åˆ†æ•°ã€‚åœ¨ä¸åŒé—®ç­”æ•°æ®é›†ä¸Šè¿›è¡Œçš„å®éªŒè¡¨æ˜ï¼ŒMMOA-RAGæé«˜äº†æ•´ä½“æµç¨‹çš„æ€§èƒ½ï¼Œå¹¶ä¼˜äºç°æœ‰åŸºçº¿ã€‚æ­¤å¤–ï¼Œå…¨é¢çš„æ¶ˆèç ”ç©¶éªŒè¯äº†å„ä¸ªç»„ä»¶çš„è´¡çŒ®ä»¥åŠMMOA-RAGåœ¨ä¸åŒRAGç»„ä»¶å’Œæ•°æ®é›†ä¸Šçš„é€‚åº”æ€§ã€‚MMOA-RAGçš„ä»£ç ä½äº<a target="_blank" rel="noopener" href="https://github.com/chenyiqun/MMOA-RAG%E3%80%82">https://github.com/chenyiqun/MMOA-RAGã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.15228v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>è¯¥æ–‡æœ¬ä»‹ç»äº†ä½¿ç”¨å¤šæ¨¡å—ååŒä¼˜åŒ–çš„æ–¹æ³•æ¥ä¼˜åŒ–åŸºäºæ£€ç´¢çš„è¾…åŠ©ç”Ÿæˆæ¨¡å‹ï¼ˆRAGï¼‰æ€§èƒ½çš„ç›¸å…³ç ”ç©¶ã€‚é’ˆå¯¹å½“å‰ç‹¬ç«‹ä¼˜åŒ–å„æ¨¡å—å¯èƒ½å¯¼è‡´çš„ç›®æ ‡ä¸ä¸€è‡´é—®é¢˜ï¼Œè¯¥ç ”ç©¶æå‡ºå°†RAGçš„å„ä¸ªç»„ä»¶è§†ä¸ºå¤šæ™ºèƒ½ä½“è¿›è¡ŒååŒä»»åŠ¡ã€‚å…·ä½“æ¥è¯´ï¼Œä½¿ç”¨å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ åè°ƒå„ä¸ªç»„ä»¶çš„ç›®æ ‡ä»¥ç»Ÿä¸€å¥–åŠ±ä¸ºä¼˜åŒ–æ–¹å‘ï¼Œå¹¶åœ¨å¤šç§é—®ç­”æ•°æ®é›†ä¸ŠéªŒè¯æ‰€æå‡ºçš„æ–¹æ³•èƒ½å¤Ÿæå‡æ•´ä½“æ€§èƒ½ã€‚æœ‰å…³è¯¥ç ”ç©¶çš„ä»£ç å·²ç»ä¸Šä¼ è‡³GitHubä»“åº“ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>RAGæ¨¡å‹å¹¿æ³›åº”ç”¨äºå¤§å‹è¯­è¨€æ¨¡å‹ä¸­ä»¥èå…¥å¤–éƒ¨å®æ—¶çŸ¥è¯†ï¼Œå‡å°‘å¹»è§‰ç°è±¡ã€‚</li>
<li>RAGæ¨¡å‹åŒ…å«å¤šä¸ªç»„ä»¶å¦‚æŸ¥è¯¢é‡å†™ã€æ–‡æ¡£æ£€ç´¢ç­‰ï¼Œä½†é€šå¸¸è¿™äº›ç»„ä»¶æ˜¯é€šè¿‡ç›‘ç£å¾®è°ƒå•ç‹¬ä¼˜åŒ–çš„ã€‚</li>
<li>è¿™ç§å•ç‹¬ä¼˜åŒ–å¯èƒ½å¯¼è‡´å„ç»„ä»¶ç›®æ ‡ä¸æ•´ä½“ç›®æ ‡ç”Ÿæˆå‡†ç¡®ç­”æ¡ˆä¹‹é—´çš„ä¸ä¸€è‡´æ€§ã€‚é’ˆå¯¹è¯¥é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§å¤šæ¨¡å—ååŒä¼˜åŒ–çš„æ–°æ–¹æ³•MMOA-RAGã€‚</li>
<li>MMOA-RAGå°†RAGçš„å„ä¸ªç»„ä»¶è§†ä¸ºå¤šæ™ºèƒ½ä½“è¿›è¡ŒååŒä»»åŠ¡ï¼Œå¹¶é‡‡ç”¨å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ æ¥åè°ƒå„ç»„ä»¶çš„ç›®æ ‡ã€‚</li>
<li>å®éªŒè¡¨æ˜ï¼ŒMMOA-RAGèƒ½æé«˜æ•´ä½“æ€§èƒ½å¹¶ä¼˜äºç°æœ‰åŸºå‡†æµ‹è¯•ã€‚æ­¤å¤–ï¼Œå…¨é¢çš„æ¶ˆèç ”ç©¶éªŒè¯äº†å„ç»„ä»¶çš„è´¡çŒ®ä»¥åŠMMOA-RAGåœ¨ä¸åŒæ•°æ®é›†ä¸Šçš„é€‚åº”æ€§ã€‚</li>
<li>è¯¥ç ”ç©¶çš„ä»£ç å·²ä¸Šä¼ è‡³GitHubä»“åº“ä»¥ä¾›å…¬ä¼—è®¿é—®å’Œä½¿ç”¨ã€‚è¿™å¯¹äºç ”ç©¶è€…å’Œå¼€å‘è€…æ¥è¯´æ˜¯ä¸€ä¸ªå¾ˆå¥½çš„èµ„æºã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.15228">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-542fb79a2ef57ed7a133492dddff1156.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-5e576fc835cf027818e96d68921304f3.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-65e0d388eba265fb6ad5428e888b703a.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="MoColl-Agent-Based-Specific-and-General-Model-Collaboration-for-Image-Captioning"><a href="#MoColl-Agent-Based-Specific-and-General-Model-Collaboration-for-Image-Captioning" class="headerlink" title="MoColl: Agent-Based Specific and General Model Collaboration for Image   Captioning"></a>MoColl: Agent-Based Specific and General Model Collaboration for Image   Captioning</h2><p><strong>Authors:Pu Yang, Bin Dong</strong></p>
<p>Image captioning is a critical task at the intersection of computer vision and natural language processing, with wide-ranging applications across various domains. For complex tasks such as diagnostic report generation, deep learning models require not only domain-specific image-caption datasets but also the incorporation of relevant general knowledge to provide contextual accuracy. Existing approaches exhibit inherent limitations: specialized models excel in capturing domain-specific details but lack generalization, while vision-language models (VLMs) built on large language models (LLMs) leverage general knowledge but struggle with domain-specific adaptation. To address these limitations, this paper proposes a novel agent-enhanced model collaboration framework, which we call MoColl, designed to effectively integrate domain-specific and general knowledge. Specifically, our approach is to decompose complex image captioning tasks into a series of interconnected question-answer subtasks. A trainable visual question answering (VQA) model is employed as a specialized tool to focus on domain-specific visual analysis, answering task-specific questions based on image content. Concurrently, an LLM-based agent with general knowledge formulates these questions and synthesizes the resulting question-answer pairs into coherent captions. Beyond its role in leveraging the VQA model, the agent further guides its training to enhance its domain-specific capabilities. Experimental results on radiology report generation validate the effectiveness of the proposed framework, demonstrating significant improvements in the quality of generated reports. </p>
<blockquote>
<p>å›¾åƒæè¿°æ˜¯è®¡ç®—æœºè§†è§‰å’Œè‡ªç„¶è¯­è¨€å¤„ç†é¢†åŸŸçš„äº¤å‰ä»»åŠ¡ï¼Œå…·æœ‰å¹¿æ³›çš„åº”ç”¨èŒƒå›´ã€‚å¯¹äºç”Ÿæˆè¯Šæ–­æŠ¥å‘Šç­‰å¤æ‚ä»»åŠ¡ï¼Œæ·±åº¦å­¦ä¹ æ¨¡å‹ä¸ä»…éœ€è¦ç‰¹å®šé¢†åŸŸçš„å›¾åƒæè¿°æ•°æ®é›†ï¼Œè¿˜éœ€è¦èå…¥ç›¸å…³çš„é€šç”¨çŸ¥è¯†ä»¥æä¾›ä¸Šä¸‹æ–‡å‡†ç¡®æ€§ã€‚ç°æœ‰æ–¹æ³•å­˜åœ¨å›ºæœ‰å±€é™æ€§ï¼šä¸“ä¸šæ¨¡å‹æ“…é•¿æ•æ‰ç‰¹å®šé¢†åŸŸçš„ç»†èŠ‚ï¼Œä½†ç¼ºä¹æ³›åŒ–èƒ½åŠ›ï¼›è€ŒåŸºäºå¤§å‹è¯­è¨€æ¨¡å‹çš„è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMsï¼‰åˆ©ç”¨é€šç”¨çŸ¥è¯†ï¼Œä½†åœ¨ç‰¹å®šé¢†åŸŸçš„é€‚åº”æ€§æ–¹é¢å´é‡åˆ°å›°éš¾ã€‚ä¸ºäº†å…‹æœè¿™äº›å±€é™æ€§ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°å‹ä»£ç†å¢å¼ºæ¨¡å‹åä½œæ¡†æ¶ï¼Œæˆ‘ä»¬ç§°ä¹‹ä¸ºMoCollï¼Œæ—¨åœ¨æœ‰æ•ˆåœ°æ•´åˆç‰¹å®šé¢†åŸŸçŸ¥è¯†å’Œé€šç”¨çŸ¥è¯†ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬çš„æ–¹æ³•æ˜¯å°†å¤æ‚çš„å›¾åƒæè¿°ä»»åŠ¡åˆ†è§£ä¸ºä¸€ç³»åˆ—ç›¸äº’å…³è”çš„é—®ç­”å­ä»»åŠ¡ã€‚æˆ‘ä»¬é‡‡ç”¨å¯è®­ç»ƒçš„è§†è§‰é—®ç­”ï¼ˆVQAï¼‰æ¨¡å‹ä½œä¸ºä¸“ä¸šå·¥å…·ï¼Œä¸“æ³¨äºç‰¹å®šé¢†åŸŸçš„è§†è§‰åˆ†æï¼Œæ ¹æ®å›¾åƒå†…å®¹å›ç­”ç‰¹å®šä»»åŠ¡çš„é—®é¢˜ã€‚åŒæ—¶ï¼Œå…·æœ‰é€šç”¨çŸ¥è¯†çš„åŸºäºLLMçš„ä»£ç†è´Ÿè´£åˆ¶å®šè¿™äº›é—®é¢˜ï¼Œå¹¶å°†å¾—åˆ°çš„é—®é¢˜ç­”æ¡ˆå¯¹ç»¼åˆæˆè¿è´¯çš„æè¿°ã€‚é™¤äº†å‘æŒ¥å¯¹VQAæ¨¡å‹çš„åˆ©ç”¨ä½œç”¨å¤–ï¼Œä»£ç†è¿˜è¿›ä¸€æ­¥æŒ‡å¯¼å…¶è®­ç»ƒï¼Œä»¥å¢å¼ºå…¶åœ¨ç‰¹å®šé¢†åŸŸçš„ä¸“ä¸šèƒ½åŠ›ã€‚åœ¨æ”¾å°„å­¦æŠ¥å‘Šç”Ÿæˆæ–¹é¢çš„å®éªŒéªŒè¯äº†æ‰€æå‡ºæ¡†æ¶çš„æœ‰æ•ˆæ€§ï¼Œæ˜¾ç¤ºå‡ºç”Ÿæˆçš„æŠ¥å‘Šè´¨é‡æ˜¾è‘—æé«˜ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.01834v3">PDF</a> </p>
<p><strong>Summary</strong><br>å›¾åƒæè¿°æ˜¯è®¡ç®—æœºè§†è§‰å’Œè‡ªç„¶è¯­è¨€å¤„ç†é¢†åŸŸçš„æ ¸å¿ƒä»»åŠ¡ä¹‹ä¸€ï¼Œå¹¿æ³›åº”ç”¨äºå„ç§é¢†åŸŸã€‚é’ˆå¯¹è¯Šæ–­æŠ¥å‘Šç”Ÿæˆç­‰å¤æ‚ä»»åŠ¡ï¼Œæ·±åº¦å­¦ä¹ æ¨¡å‹ä¸ä»…éœ€è¦ç‰¹å®šçš„å›¾åƒæè¿°æ•°æ®é›†ï¼Œè¿˜éœ€è¦èå…¥ç›¸å…³çš„é€šç”¨çŸ¥è¯†ä»¥æä¾›ä¸Šä¸‹æ–‡å‡†ç¡®æ€§ã€‚ç°æœ‰æ–¹æ³•å­˜åœ¨å±€é™æ€§ï¼šä¸“ä¸šæ¨¡å‹æ“…é•¿æ•æ‰ç‰¹å®šé¢†åŸŸçš„ç»†èŠ‚ï¼Œä½†ç¼ºä¹æ³›åŒ–èƒ½åŠ›ï¼›è€ŒåŸºäºå¤§å‹è¯­è¨€æ¨¡å‹çš„è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMsï¼‰è™½ç„¶å¯ä»¥åˆ©ç”¨é€šç”¨çŸ¥è¯†ï¼Œä½†åœ¨ç‰¹å®šé¢†åŸŸçš„é€‚åº”æ€§ä¸Šå´é‡åˆ°å›°éš¾ã€‚ä¸ºè§£å†³è¿™äº›é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°å‹ä»£ç†å¢å¼ºæ¨¡å‹åä½œæ¡†æ¶MoCollï¼Œæ—¨åœ¨æœ‰æ•ˆæ•´åˆç‰¹å®šé¢†åŸŸçŸ¥è¯†å’Œé€šç”¨çŸ¥è¯†ã€‚è¯¥æ–¹æ³•é€šè¿‡å°†å¤æ‚çš„å›¾åƒæè¿°ä»»åŠ¡åˆ†è§£ä¸ºä¸€ç³»åˆ—ç›¸äº’å…³è”çš„é—®é¢˜å›ç­”å­ä»»åŠ¡æ¥è¾¾æˆç›®æ ‡ã€‚ä½¿ç”¨å¯è®­ç»ƒçš„è§†è§‰é—®ç­”ï¼ˆVQAï¼‰æ¨¡å‹ä½œä¸ºä¸“ä¸šå·¥å…·ï¼Œä¸“æ³¨äºç‰¹å®šé¢†åŸŸçš„è§†è§‰åˆ†æï¼Œæ ¹æ®å›¾åƒå†…å®¹å›ç­”ä»»åŠ¡ç‰¹å®šé—®é¢˜ã€‚åŒæ—¶ï¼Œå…·æœ‰é€šç”¨çŸ¥è¯†çš„LLMä»£ç†åˆ¶å®šè¿™äº›é—®é¢˜å¹¶å°†é—®é¢˜ç­”æ¡ˆå¯¹åˆæˆä¸ºè¿è´¯çš„æè¿°ã€‚é™¤äº†åˆ©ç”¨VQAæ¨¡å‹å¤–ï¼Œä»£ç†è¿˜è¿›ä¸€æ­¥æŒ‡å¯¼å…¶è®­ç»ƒä»¥å¢å¼ºå…¶ç‰¹å®šé¢†åŸŸçš„èƒ½åŠ›ã€‚åœ¨æ”¾å°„å­¦æŠ¥å‘Šç”Ÿæˆæ–¹é¢çš„å®éªŒéªŒè¯äº†è¯¥æ¡†æ¶çš„æœ‰æ•ˆæ€§ï¼Œæ˜¾ç¤ºå‡ºç”Ÿæˆçš„æŠ¥å‘Šè´¨é‡æ˜¾è‘—æé«˜ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å›¾åƒæè¿°æ˜¯è®¡ç®—æœºè§†è§‰å’Œè‡ªç„¶è¯­è¨€å¤„ç†é¢†åŸŸçš„æ ¸å¿ƒä»»åŠ¡ï¼Œæ¶‰åŠå¤šç§åº”ç”¨é¢†åŸŸã€‚</li>
<li>ç°æœ‰æ–¹æ³•åœ¨å¤„ç†å¤æ‚ä»»åŠ¡æ—¶å­˜åœ¨å±€é™æ€§ï¼Œä¸“ä¸šæ¨¡å‹ç¼ºä¹æ³›åŒ–èƒ½åŠ›ï¼Œè€Œè§†è§‰è¯­è¨€æ¨¡å‹åœ¨ç‰¹å®šé¢†åŸŸé€‚åº”æ€§ä¸Šå›°éš¾ã€‚</li>
<li>MoCollæ¡†æ¶ç»“åˆäº†ç‰¹å®šé¢†åŸŸçŸ¥è¯†å’Œé€šç”¨çŸ¥è¯†æ¥è§£å†³è¿™ä¸ªé—®é¢˜ã€‚</li>
<li>é€šè¿‡å°†å›¾åƒæè¿°ä»»åŠ¡åˆ†è§£ä¸ºé—®é¢˜å›ç­”å­ä»»åŠ¡æ¥æé«˜æ¨¡å‹æ€§èƒ½ã€‚</li>
<li>VQAæ¨¡å‹ç”¨äºæ•æ‰ç‰¹å®šé¢†åŸŸçš„è§†è§‰ç»†èŠ‚ï¼Œè€ŒLLMä»£ç†è´Ÿè´£åˆ©ç”¨é€šç”¨çŸ¥è¯†åˆæˆè¿è´¯çš„æè¿°ã€‚</li>
<li>ä»£ç†ä¸ä»…åˆ©ç”¨VQAæ¨¡å‹ï¼Œè¿˜æŒ‡å¯¼å…¶è®­ç»ƒä»¥å¢å¼ºç‰¹å®šé¢†åŸŸçš„èƒ½åŠ›ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.01834">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-cb69644e91a7b349961cf1c04f25d063.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-811ad4a5b368c246b4952b26c019fc17.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f0283a42a9aa48959a6aa7894357d615.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-04a640bc94b9f14871940594caf37f26.jpg" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="WebRL-Training-LLM-Web-Agents-via-Self-Evolving-Online-Curriculum-Reinforcement-Learning"><a href="#WebRL-Training-LLM-Web-Agents-via-Self-Evolving-Online-Curriculum-Reinforcement-Learning" class="headerlink" title="WebRL: Training LLM Web Agents via Self-Evolving Online Curriculum   Reinforcement Learning"></a>WebRL: Training LLM Web Agents via Self-Evolving Online Curriculum   Reinforcement Learning</h2><p><strong>Authors:Zehan Qi, Xiao Liu, Iat Long Iong, Hanyu Lai, Xueqiao Sun, Wenyi Zhao, Yu Yang, Xinyue Yang, Jiadai Sun, Shuntian Yao, Tianjie Zhang, Wei Xu, Jie Tang, Yuxiao Dong</strong></p>
<p>Large language models (LLMs) have shown remarkable potential as autonomous agents, particularly in web-based tasks. However, existing LLM web agents heavily rely on expensive proprietary LLM APIs, while open LLMs lack the necessary decision-making capabilities. This paper introduces WebRL, a self-evolving online curriculum reinforcement learning framework designed to train high-performance web agents using open LLMs. WebRL addresses three key challenges in building LLM web agents, including the scarcity of training tasks, sparse feedback signals, and policy distribution drift in online learning. Specifically, WebRL incorporates 1) a self-evolving curriculum that generates new tasks from unsuccessful attempts, 2) a robust outcome-supervised reward model (ORM), and 3) adaptive reinforcement learning strategies to ensure consistent improvements. We apply WebRL to transform open Llama-3.1 and GLM-4 models into proficient web agents. On WebArena-Lite, WebRL improves the success rate of Llama-3.1-8B from 4.8% to 42.4%, and from 6.1% to 43% for GLM-4-9B. These open models significantly surpass the performance of GPT-4-Turbo (17.6%) and GPT-4o (13.9%) and outperform previous state-of-the-art web agents trained on open LLMs (AutoWebGLM, 18.2%). Our findings demonstrate WebRLâ€™s effectiveness in bridging the gap between open and proprietary LLM-based web agents, paving the way for more accessible and powerful autonomous web interaction systems. </p>
<blockquote>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä½œä¸ºè‡ªä¸»ä»£ç†äººåœ¨ç½‘é¡µä»»åŠ¡ä¸­è¡¨ç°å‡ºäº†æ˜¾è‘—æ½œåŠ›ã€‚ç„¶è€Œï¼Œç°æœ‰çš„LLMç½‘ç»œä»£ç†äººä¸¥é‡ä¾èµ–äºæ˜‚è´µçš„ä¸“æœ‰LLM APIï¼Œè€Œå¼€æºLLMç¼ºä¹å¿…è¦çš„å†³ç­–èƒ½åŠ›ã€‚æœ¬æ–‡ä»‹ç»äº†WebRLï¼Œè¿™æ˜¯ä¸€ç§è‡ªæˆ‘è¿›åŒ–çš„åœ¨çº¿è¯¾ç¨‹å¼ºåŒ–å­¦ä¹ æ¡†æ¶ï¼Œæ—¨åœ¨åˆ©ç”¨å¼€æºLLMè®­ç»ƒé«˜æ€§èƒ½çš„ç½‘ç»œä»£ç†äººã€‚WebRLè§£å†³äº†æ„å»ºLLMç½‘ç»œä»£ç†äººçš„ä¸‰ä¸ªå…³é”®æŒ‘æˆ˜ï¼ŒåŒ…æ‹¬è®­ç»ƒä»»åŠ¡çš„ç¨€ç¼ºæ€§ã€åé¦ˆä¿¡å·çš„ç¨€ç–æ€§ä»¥åŠåœ¨çº¿å­¦ä¹ ä¸­çš„ç­–ç•¥åˆ†å¸ƒæ¼‚ç§»ã€‚å…·ä½“æ¥è¯´ï¼ŒWebRLç»“åˆäº†1ï¼‰ä¸€ç§è‡ªæˆ‘è¿›åŒ–çš„è¯¾ç¨‹ï¼Œå¯ä»¥ä»å¤±è´¥çš„å°è¯•ä¸­ç”Ÿæˆæ–°ä»»åŠ¡ï¼Œ2ï¼‰ä¸€ç§ç¨³å¥çš„ç»“æœç›‘ç£å¥–åŠ±æ¨¡å‹ï¼ˆORMï¼‰ï¼Œä»¥åŠ3ï¼‰è‡ªé€‚åº”å¼ºåŒ–å­¦ä¹ ç­–ç•¥ï¼Œä»¥ç¡®ä¿æŒç»­æ”¹è¿›ã€‚æˆ‘ä»¬å°†WebRLåº”ç”¨äºå°†å¼€æºçš„Llama-3.1å’ŒGLM-4æ¨¡å‹è½¬åŒ–ä¸ºç†Ÿç»ƒçš„ç½‘ç»œä»£ç†äººã€‚åœ¨WebArena-Liteä¸Šï¼ŒWebRLå°†Llama-3.1-8Bçš„æˆåŠŸç‡ä»4.8%æé«˜åˆ°42.4%ï¼Œå¹¶å°†GLM-4-9Bçš„æˆåŠŸç‡ä»6.1%æé«˜åˆ°43%ã€‚è¿™äº›å¼€æºæ¨¡å‹çš„æ€§èƒ½æ˜¾è‘—è¶…è¿‡äº†GPT-4 Turboï¼ˆ17.6%ï¼‰å’ŒGPT-4oï¼ˆ13.9%ï¼‰çš„è¡¨ç°ï¼Œå¹¶ä¸”ä¼˜äºä¹‹å‰åœ¨å¼€æºLLMä¸Šè®­ç»ƒçš„æœ€ä½³ç½‘ç»œä»£ç†äººï¼ˆAutoWebGLMï¼Œ18.2%ï¼‰ã€‚æˆ‘ä»¬çš„ç ”ç©¶ç»“æœè¡¨æ˜ï¼ŒWebRLåœ¨å¼¥åˆå¼€æºå’Œä¸“æœ‰LLMåŸºäºçš„ç½‘é¡µä»£ç†äººä¹‹é—´çš„å·®è·æ–¹é¢éå¸¸æœ‰æ•ˆï¼Œä¸ºæ›´æ˜“äºè®¿é—®å’Œæ›´å¼ºå¤§çš„è‡ªä¸»ç½‘é¡µäº¤äº’ç³»ç»Ÿé“ºå¹³äº†é“è·¯ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2411.02337v3">PDF</a> Published as a conference paper at ICLR 2025</p>
<p><strong>Summary</strong></p>
<p>LLMsä½œä¸ºè‡ªä¸»ä»£ç†äººåœ¨ç½‘é¡µä»»åŠ¡ä¸­å±•ç°å‡ºå·¨å¤§æ½œåŠ›ï¼Œä½†ä¾èµ–æ˜‚è´µçš„ä¸“æœ‰LLM APIä¸”å¼€æ”¾å¼LLMsç¼ºä¹å†³ç­–èƒ½åŠ›ã€‚æœ¬æ–‡æå‡ºWebRLæ¡†æ¶ï¼Œä¸€ä¸ªè‡ªæˆ‘è¿›åŒ–çš„åœ¨çº¿è¯¾ç¨‹å¼ºåŒ–å­¦ä¹ æ¡†æ¶ï¼Œæ—¨åœ¨åˆ©ç”¨å¼€æ”¾å¼LLMsè®­ç»ƒé«˜æ€§èƒ½ç½‘é¡µä»£ç†äººã€‚WebRLè§£å†³äº†æ„å»ºLLMç½‘é¡µä»£ç†äººçš„ä¸‰ä¸ªå…³é”®æŒ‘æˆ˜ï¼ŒåŒ…æ‹¬è®­ç»ƒä»»åŠ¡çš„ç¨€ç¼ºæ€§ã€åé¦ˆä¿¡å·çš„ç¨€ç–æ€§ä»¥åŠåœ¨çº¿å­¦ä¹ ä¸­çš„ç­–ç•¥åˆ†å¸ƒæ¼‚ç§»ã€‚å®éªŒè¯æ˜ï¼ŒWebRLèƒ½æˆåŠŸå°†å¼€æºçš„Llama-3.1å’ŒGLM-4æ¨¡å‹è½¬åŒ–ä¸ºç†Ÿç»ƒçš„ç½‘é¡µä»£ç†äººï¼Œæ˜¾è‘—æé«˜æˆåŠŸç‡ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>LLMsåœ¨webä»»åŠ¡ä¸­è¡¨ç°å‡ºå¼ºå¤§çš„è‡ªä¸»æ€§ã€‚</li>
<li>ç°æœ‰LLM webä»£ç†äººä¸¥é‡ä¾èµ–æ˜‚è´µçš„ä¸“æœ‰APIã€‚</li>
<li>å¼€æ”¾å¼LLMsç¼ºä¹å¿…è¦çš„å†³ç­–èƒ½åŠ›ã€‚</li>
<li>WebRLæ˜¯ä¸€ä¸ªè‡ªæˆ‘è¿›åŒ–çš„åœ¨çº¿è¯¾ç¨‹å¼ºåŒ–å­¦ä¹ æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³LLMç½‘é¡µä»£ç†äººçš„æŒ‘æˆ˜ã€‚</li>
<li>WebRLè§£å†³äº†è®­ç»ƒä»»åŠ¡ç¨€ç¼ºã€åé¦ˆä¿¡å·ç¨€ç–å’Œåœ¨çº¿å­¦ä¹ ä¸­çš„ç­–ç•¥åˆ†å¸ƒæ¼‚ç§»é—®é¢˜ã€‚</li>
<li>WebRLèƒ½æˆåŠŸå°†å¼€æºLLMsè½¬åŒ–ä¸ºé«˜æ•ˆçš„ç½‘é¡µä»£ç†äººã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2411.02337">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-c17541626fda691e410c1a5f14cee68c.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-abb3b8055c8be717bb4bf4370b219fd6.jpg" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1><h2 id="Knowledge-Graph-Enhanced-Language-Agents-for-Recommendation"><a href="#Knowledge-Graph-Enhanced-Language-Agents-for-Recommendation" class="headerlink" title="Knowledge Graph Enhanced Language Agents for Recommendation"></a>Knowledge Graph Enhanced Language Agents for Recommendation</h2><p><strong>Authors:Taicheng Guo, Chaochun Liu, Hai Wang, Varun Mannam, Fang Wang, Xin Chen, Xiangliang Zhang, Chandan K. Reddy</strong></p>
<p>Language agents have recently been used to simulate human behavior and user-item interactions for recommendation systems. However, current language agent simulations do not understand the relationships between users and items, leading to inaccurate user profiles and ineffective recommendations. In this work, we explore the utility of Knowledge Graphs (KGs), which contain extensive and reliable relationships between users and items, for recommendation. Our key insight is that the paths in a KG can capture complex relationships between users and items, eliciting the underlying reasons for user preferences and enriching user profiles. Leveraging this insight, we propose Knowledge Graph Enhanced Language Agents(KGLA), a framework that unifies language agents and KG for recommendation systems. In the simulated recommendation scenario, we position the user and item within the KG and integrate KG paths as natural language descriptions into the simulation. This allows language agents to interact with each other and discover sufficient rationale behind their interactions, making the simulation more accurate and aligned with real-world cases, thus improving recommendation performance. Our experimental results show that KGLA significantly improves recommendation performance (with a 33%-95% boost in NDCG@1 among three widely used benchmarks) compared to the previous best baseline method. </p>
<blockquote>
<p>è¯­è¨€ä»£ç†æœ€è¿‘è¢«ç”¨æ¥æ¨¡æ‹Ÿäººç±»è¡Œä¸ºå’Œç”¨æˆ·é¡¹ç›®äº¤äº’ï¼Œä¸ºæ¨èç³»ç»Ÿæä¾›æ¨èã€‚ç„¶è€Œï¼Œå½“å‰çš„è¯­è¨€ä»£ç†æ¨¡æ‹Ÿæ— æ³•ç†è§£ç”¨æˆ·å’Œé¡¹ç›®ä¹‹é—´çš„å…³ç³»ï¼Œå¯¼è‡´ç”¨æˆ·é…ç½®æ–‡ä»¶ä¸å‡†ç¡®å’Œæ¨èæ•ˆæœä¸ä½³ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬æ¢è®¨äº†çŸ¥è¯†å›¾è°±ï¼ˆKGï¼‰åœ¨æ¨èä¸­çš„å®ç”¨æ€§ã€‚çŸ¥è¯†å›¾è°±åŒ…å«äº†ç”¨æˆ·å’Œé¡¹ç›®ä¹‹é—´å¹¿æ³›è€Œå¯é çš„å…³ç³»ã€‚æˆ‘ä»¬çš„å…³é”®è§è§£æ˜¯ï¼ŒçŸ¥è¯†å›¾è°±ä¸­çš„è·¯å¾„å¯ä»¥æ•æ‰ç”¨æˆ·å’Œé¡¹ç›®ä¹‹é—´çš„å¤æ‚å…³ç³»ï¼Œæ¿€å‘ç”¨æˆ·åå¥½çš„æ ¹æœ¬åŸå› å¹¶ä¸°å¯Œç”¨æˆ·é…ç½®æ–‡ä»¶ã€‚åˆ©ç”¨è¿™ä¸€è§è§£ï¼Œæˆ‘ä»¬æå‡ºäº†çŸ¥è¯†å›¾è°±å¢å¼ºè¯­è¨€ä»£ç†ï¼ˆKGLAï¼‰ï¼Œè¿™æ˜¯ä¸€ä¸ªç»Ÿä¸€è¯­è¨€ä»£ç†å’ŒçŸ¥è¯†å›¾è°±çš„æ¨èç³»ç»Ÿæ¡†æ¶ã€‚åœ¨æ¨¡æ‹Ÿæ¨èåœºæ™¯ä¸­ï¼Œæˆ‘ä»¬å°†ç”¨æˆ·å’Œé¡¹ç›®å®šä½åœ¨çŸ¥è¯†å›¾è°±å†…ï¼Œå¹¶å°†çŸ¥è¯†å›¾è°±è·¯å¾„æ•´åˆä¸ºè‡ªç„¶è¯­è¨€æè¿°èå…¥æ¨¡æ‹Ÿä¸­ã€‚è¿™å…è®¸è¯­è¨€ä»£ç†ç›¸äº’äº¤äº’å¹¶å‘ç°å…¶äº¤äº’èƒŒåçš„å……è¶³ç†ç”±ï¼Œä½¿æ¨¡æ‹Ÿæ›´åŠ å‡†ç¡®å¹¶ä¸çœŸå®æƒ…å†µç›¸ç¬¦ï¼Œä»è€Œæé«˜æ¨èæ€§èƒ½ã€‚æˆ‘ä»¬çš„å®éªŒç»“æœè¡¨æ˜ï¼Œä¸ä¹‹å‰çš„æœ€ä½³åŸºçº¿æ–¹æ³•ç›¸æ¯”ï¼ŒKGLAæ˜¾è‘—æé«˜äº†æ¨èæ€§èƒ½ï¼ˆåœ¨ä¸‰ä¸ªå¹¿æ³›ä½¿ç”¨çš„åŸºå‡†æµ‹è¯•ä¸­ï¼ŒNDCG@1æå‡äº†33%-95%ï¼‰ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2410.19627v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>çŸ¥è¯†å›¾è°±å¢å¼ºè¯­è¨€ä»£ç†ï¼ˆKGLAï¼‰åˆ©ç”¨çŸ¥è¯†å›¾è°±ï¼ˆKGï¼‰ä¸­çš„ç”¨æˆ·ä¸ç‰©å“ä¹‹é—´çš„å…³ç³»ï¼Œæé«˜äº†æ¨èç³»ç»Ÿçš„å‡†ç¡®æ€§ã€‚é€šè¿‡æ¨¡æ‹Ÿç”¨æˆ·ä¸ç‰©å“åœ¨çŸ¥è¯†å›¾è°±ä¸­çš„ä½ç½®ï¼Œå°†çŸ¥è¯†å›¾è°±è·¯å¾„ä½œä¸ºè‡ªç„¶è¯­è¨€æè¿°èå…¥æ¨¡æ‹Ÿä¸­ï¼Œä½¿è¯­è¨€ä»£ç†äº¤äº’æ›´å…·ç†æ€§ï¼Œæé«˜äº†æ¨èæ€§èƒ½ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>è¯­è¨€ä»£ç†è¢«ç”¨äºæ¨¡æ‹Ÿæ¨èç³»ç»Ÿä¸­çš„ç”¨æˆ·è¡Œä¸ºå’Œç”¨æˆ·-ç‰©å“äº’åŠ¨ï¼Œä½†ç°æœ‰æ¨¡æ‹Ÿæ— æ³•ç†è§£ç”¨æˆ·ä¸ç‰©å“ä¹‹é—´çš„å…³ç³»ã€‚</li>
<li>çŸ¥è¯†å›¾è°±ï¼ˆKGï¼‰åŒ…å«ç”¨æˆ·ä¸ç‰©å“ä¹‹é—´å¹¿æ³›å¯é çš„å…³ç³»ï¼Œå¯¹äºæ¨èç³»ç»Ÿå…·æœ‰å®ç”¨æ€§ã€‚</li>
<li>çŸ¥è¯†å›¾è°±ä¸­çš„è·¯å¾„å¯ä»¥æ•æ‰ç”¨æˆ·ä¸ç‰©å“ä¹‹é—´çš„å¤æ‚å…³ç³»ï¼Œæ­ç¤ºç”¨æˆ·åå¥½çš„æ ¹æœ¬åŸå› å¹¶ä¸°å¯Œç”¨æˆ·èµ„æ–™ã€‚</li>
<li>æå‡ºçš„KGLAæ¡†æ¶ç»“åˆäº†è¯­è¨€ä»£ç†å’ŒçŸ¥è¯†å›¾è°±ï¼Œæé«˜äº†æ¨èç³»ç»Ÿçš„æ¨¡æ‹Ÿå‡†ç¡®æ€§ï¼Œä½¿å…¶æ›´è´´è¿‘çœŸå®ä¸–ç•Œæ¡ˆä¾‹ã€‚</li>
<li>KGLAé€šè¿‡èå…¥çŸ¥è¯†å›¾è°±è·¯å¾„çš„è‡ªç„¶è¯­è¨€æè¿°ï¼Œä½¿è¯­è¨€ä»£ç†äº¤äº’æ›´å…·ç†æ€§ã€‚</li>
<li>å®éªŒç»“æœè¡¨æ˜ï¼ŒKGLAåœ¨ä¸‰ä¸ªå¹¿æ³›ä½¿ç”¨çš„åŸºå‡†æµ‹è¯•ä¸Šï¼Œç›¸è¾ƒäºä¹‹å‰æœ€ä½³åŸºçº¿æ–¹æ³•ï¼Œæ¨èæ€§èƒ½æå‡äº†33%-95%çš„NDCG@1ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2410.19627">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-0aca4443d3eb64b55529c665b6b0ca45.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-dfa32a5d359d3000f278d0e68b803a63.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-dbbb19548b6563fecaaa8d24f2012234.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-abd2b1bb752e3677d452c239dbb30305.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-7f9a043c894735c2f3151cd5daa67ad6.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-fcfe3d2e6b8c3fedfd732c2422c47476.jpg" align="middle">
</details>


<h1 id="-9"><a href="#-9" class="headerlink" title=""></a></h1><h2 id="Agent-Skill-Acquisition-for-Large-Language-Models-via-CycleQD"><a href="#Agent-Skill-Acquisition-for-Large-Language-Models-via-CycleQD" class="headerlink" title="Agent Skill Acquisition for Large Language Models via CycleQD"></a>Agent Skill Acquisition for Large Language Models via CycleQD</h2><p><strong>Authors:So Kuroki, Taishi Nakamura, Takuya Akiba, Yujin Tang</strong></p>
<p>Training large language models to acquire specific skills remains a challenging endeavor. Conventional training approaches often struggle with data distribution imbalances and inadequacies in objective functions that do not align well with task-specific performance. To address these challenges, we introduce CycleQD, a novel approach that leverages the Quality Diversity framework through a cyclic adaptation of the algorithm, along with a model merging based crossover and an SVD-based mutation. In CycleQD, each taskâ€™s performance metric is alternated as the quality measure while the others serve as the behavioral characteristics. This cyclic focus on individual tasks allows for concentrated effort on one task at a time, eliminating the need for data ratio tuning and simplifying the design of the objective function. Empirical results from AgentBench indicate that applying CycleQD to LLAMA3-8B-INSTRUCT based models not only enables them to surpass traditional fine-tuning methods in coding, operating systems, and database tasks, but also achieves performance on par with GPT-3.5-TURBO, which potentially contains much more parameters, across these domains. Crucially, this enhanced performance is achieved while retaining robust language capabilities, as evidenced by its performance on widely adopted language benchmark tasks. We highlight the key design choices in CycleQD, detailing how these contribute to its effectiveness. Furthermore, our method is general and can be applied to image segmentation models, highlighting its applicability across different domains. </p>
<blockquote>
<p>è®­ç»ƒå¤§å‹è¯­è¨€æ¨¡å‹ä»¥è·å–ç‰¹å®šæŠ€èƒ½ä»ç„¶æ˜¯ä¸€é¡¹å…·æœ‰æŒ‘æˆ˜æ€§çš„å·¥ä½œã€‚ä¼ ç»Ÿçš„è®­ç»ƒæ–¹æ³•å¸¸å¸¸é¢ä¸´æ•°æ®åˆ†å¸ƒä¸å¹³è¡¡å’Œå®¢è§‚åŠŸèƒ½ä¸è¶³çš„é—®é¢˜ï¼Œè¿™äº›é—®é¢˜ä¸ç‰¹å®šä»»åŠ¡çš„æ€§èƒ½ä¸å¤ªå»åˆã€‚ä¸ºäº†è§£å†³è¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬å¼•å…¥äº†CycleQDè¿™ä¸€æ–°æ–¹æ³•ï¼Œå®ƒåˆ©ç”¨è´¨é‡å¤šæ ·æ€§æ¡†æ¶ï¼Œé€šè¿‡ç®—æ³•çš„å¾ªç¯é€‚åº”ã€åŸºäºæ¨¡å‹åˆå¹¶çš„äº¤å‰å’ŒåŸºäºSVDçš„çªå˜æ¥å®ç°ã€‚åœ¨CycleQDä¸­ï¼Œæ¯ä¸ªä»»åŠ¡çš„æ€§èƒ½æŒ‡æ ‡è½®æµä½œä¸ºè´¨é‡åº¦é‡ï¼Œè€Œå…¶ä»–æŒ‡æ ‡åˆ™ä½œä¸ºè¡Œä¸ºç‰¹å¾ã€‚è¿™ç§å¯¹å•ä¸ªä»»åŠ¡çš„å¾ªç¯å…³æ³¨å…è®¸æ¯æ¬¡é›†ä¸­ç²¾åŠ›äºä¸€ä¸ªä»»åŠ¡ï¼Œä»è€Œæ¶ˆé™¤äº†å¯¹æ•°æ®æ¯”ç‡è°ƒæ•´çš„éœ€æ±‚ï¼Œå¹¶ç®€åŒ–äº†ç›®æ ‡å‡½æ•°çš„è®¾è®¡ã€‚æ¥è‡ªAgentBenchçš„ç»éªŒç»“æœè¡¨æ˜ï¼Œå°†CycleQDåº”ç”¨äºLLAMA3-8B-INSTRUCTåŸºç¡€æ¨¡å‹ï¼Œä¸ä»…èƒ½ä½¿å®ƒä»¬åœ¨ç¼–ç ã€æ“ä½œç³»ç»Ÿå’Œæ•°æ®åº“ä»»åŠ¡ä¸Šè¶…è¶Šä¼ ç»Ÿçš„å¾®è°ƒæ–¹æ³•ï¼Œè€Œä¸”åœ¨è¿™äº›é¢†åŸŸå®ç°äº†ä¸GPT-3.5-TURBOç›¸å½“çš„æ€§èƒ½ï¼Œå°½ç®¡GPT-3.5-TURBOå¯èƒ½åŒ…å«æ›´å¤šçš„å‚æ•°ã€‚å…³é”®çš„æ˜¯ï¼Œè¿™ç§å¢å¼ºçš„æ€§èƒ½æ˜¯åœ¨ä¿ç•™ç¨³å¥çš„è¯­è¨€èƒ½åŠ›çš„æƒ…å†µä¸‹å®ç°çš„ï¼Œè¿™ä»å…¶æµè¡Œçš„è¯­è¨€åŸºå‡†ä»»åŠ¡ä¸­çš„è¡¨ç°å°±å¯ä»¥å¾—åˆ°è¯æ˜ã€‚æˆ‘ä»¬å¼ºè°ƒäº†CycleQDä¸­çš„å…³é”®è®¾è®¡é€‰æ‹©ï¼Œè¯¦ç»†è¯´æ˜äº†è¿™äº›æ˜¯å¦‚ä½•ä¿ƒè¿›å…¶æœ‰æ•ˆæ€§çš„ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬çš„æ–¹æ³•æ˜¯é€šç”¨çš„ï¼Œå¯åº”ç”¨äºå›¾åƒåˆ†å‰²æ¨¡å‹ï¼Œçªæ˜¾å…¶åœ¨ä¸åŒé¢†åŸŸçš„åº”ç”¨æ€§ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2410.14735v3">PDF</a> To appear at the 13th International Conference on Learning   Representations (ICLR 2025)</p>
<p><strong>Summary</strong></p>
<p>å¤§å‹è¯­è¨€æ¨¡å‹çš„ç‰¹å®šæŠ€èƒ½è·å–è®­ç»ƒä»ç„¶æ˜¯ä¸€é¡¹æŒ‘æˆ˜ã€‚ä¼ ç»Ÿè®­ç»ƒæ–¹æ³•å¸¸å¸¸é¢ä¸´æ•°æ®åˆ†å¸ƒä¸å¹³è¡¡å’Œå®¢è§‚å‡½æ•°ä¸ä»»åŠ¡ç‰¹å®šæ€§èƒ½ä¸åŒ¹é…çš„é—®é¢˜ã€‚ä¸ºè§£å†³è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†CycleQDæ–¹æ³•ï¼Œè¯¥æ–¹æ³•åˆ©ç”¨è´¨é‡å¤šæ ·æ€§æ¡†æ¶ï¼Œé€šè¿‡ç®—æ³•çš„å¾ªç¯é€‚åº”ã€åŸºäºæ¨¡å‹åˆå¹¶çš„äº¤å‰å’ŒåŸºäºSVDçš„çªå˜æ¥å®ç°ã€‚CycleQDä¸­ï¼Œæ¯ä¸ªä»»åŠ¡çš„æ€§èƒ½æŒ‡æ ‡è½®æµä½œä¸ºè´¨é‡åº¦é‡ï¼Œè€Œå…¶ä»–æŒ‡æ ‡åˆ™ä½œä¸ºè¡Œä¸ºç‰¹å¾ã€‚è¿™ç§å¯¹å•ä¸ªä»»åŠ¡çš„å¾ªç¯å…³æ³¨å…è®¸æ¯æ¬¡é›†ä¸­ç²¾åŠ›äºä¸€ä¸ªä»»åŠ¡ï¼Œä»è€Œæ¶ˆé™¤äº†å¯¹æ•°æ®æ¯”ç‡è°ƒæ•´çš„éœ€æ±‚ï¼Œå¹¶ç®€åŒ–äº†ç›®æ ‡å‡½æ•°çš„è®¾è®¡ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œå°†CycleQDåº”ç”¨äºLLAMA3-8B-INSTRUCTåŸºç¡€æ¨¡å‹ï¼Œä¸ä»…åœ¨ç¼–ç ã€æ“ä½œç³»ç»Ÿå’Œæ•°æ®åº“ä»»åŠ¡ä¸Šè¶…è¶Šäº†ä¼ ç»Ÿå¾®è°ƒæ–¹æ³•ï¼Œè€Œä¸”åœ¨è¿™äº›é¢†åŸŸå®ç°äº†ä¸GPT-3.5-TURBOç›¸å½“çš„æ€§èƒ½ï¼Œå°½ç®¡GPT-3.5-TURBOå¯èƒ½åŒ…å«æ›´å¤šçš„å‚æ•°ã€‚å…³é”®çš„æ˜¯ï¼Œè¿™ç§å¢å¼ºæ€§èƒ½çš„åŒæ—¶ä¿æŒäº†å¼ºå¤§çš„è¯­è¨€åŠŸèƒ½ï¼Œè¿™ç”±å…¶åœ¨å¹¿æ³›é‡‡ç”¨çš„è¯­è¨€åŸºå‡†ä»»åŠ¡ä¸Šçš„è¡¨ç°æ‰€è¯æ˜ã€‚æˆ‘ä»¬è¿˜å¼ºè°ƒäº†CycleQDä¸­çš„å…³é”®è®¾è®¡é€‰æ‹©ï¼Œè¯¦ç»†è¯´æ˜äº†è¿™äº›é€‰æ‹©å¦‚ä½•ä¿ƒè¿›å…¶æœ‰æ•ˆæ€§ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬çš„æ–¹æ³•æ˜¯é€šç”¨çš„ï¼Œå¯åº”ç”¨äºå›¾åƒåˆ†å‰²æ¨¡å‹ï¼Œå‡¸æ˜¾å…¶åœ¨ä¸åŒé¢†åŸŸçš„åº”ç”¨æ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤§å‹è¯­è¨€æ¨¡å‹çš„ç‰¹å®šæŠ€èƒ½è·å–è®­ç»ƒå­˜åœ¨æŒ‘æˆ˜ï¼Œä¼ ç»Ÿæ–¹æ³•é¢ä¸´æ•°æ®åˆ†å¸ƒå’Œå®¢è§‚å‡½æ•°çš„é—®é¢˜ã€‚</li>
<li>CycleQDæ–¹æ³•åˆ©ç”¨è´¨é‡å¤šæ ·æ€§æ¡†æ¶ï¼Œé€šè¿‡å¾ªç¯é€‚åº”ç®—æ³•ã€æ¨¡å‹åˆå¹¶äº¤å‰å’ŒSVDçªå˜æ¥è§£å†³è¿™äº›é—®é¢˜ã€‚</li>
<li>CycleQDå…³æ³¨å•ä¸ªä»»åŠ¡çš„å¾ªç¯ï¼Œç®€åŒ–ç›®æ ‡å‡½æ•°è®¾è®¡ï¼Œå¹¶æ¶ˆé™¤æ•°æ®æ¯”ç‡è°ƒæ•´çš„éœ€æ±‚ã€‚</li>
<li>åœ¨ç¼–ç ã€æ“ä½œç³»ç»Ÿå’Œæ•°æ®åº“ä»»åŠ¡ä¸Šï¼ŒCycleQDè¶…è¶Šäº†ä¼ ç»Ÿæ–¹æ³•ï¼Œæ€§èƒ½ä¸GPT-3.5-TURBOç›¸å½“ã€‚</li>
<li>CycleQDåœ¨å¹¿æ³›çš„è¯­è¨€åŸºå‡†ä»»åŠ¡ä¸Šè¡¨ç°ä¼˜ç§€ï¼Œè¯æ˜äº†å…¶ä¿æŒå¼ºå¤§è¯­è¨€åŠŸèƒ½çš„èƒ½åŠ›ã€‚</li>
<li>CycleQDçš„å…³é”®è®¾è®¡é€‰æ‹©å¯¹äºå…¶æœ‰æ•ˆæ€§è‡³å…³é‡è¦ï¼ŒåŒ…æ‹¬è´¨é‡åº¦é‡å’Œè¡Œä¸ºç‰¹å¾çš„è®¾å®šã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2410.14735">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-e94e886e9de7695e0936f8151d9c22c1.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-b4da8ead3391d46521dd5d4f4dd251ba.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-db210a04bf3de59b821d362ea3c78899.jpg" align="middle">
</details>


<h1 id="-10"><a href="#-10" class="headerlink" title=""></a></h1><h2 id="Explaining-Decisions-of-Agents-in-Mixed-Motive-Games"><a href="#Explaining-Decisions-of-Agents-in-Mixed-Motive-Games" class="headerlink" title="Explaining Decisions of Agents in Mixed-Motive Games"></a>Explaining Decisions of Agents in Mixed-Motive Games</h2><p><strong>Authors:Maayan Orner, Oleg Maksimov, Akiva Kleinerman, Charles Ortiz, Sarit Kraus</strong></p>
<p>In recent years, agents have become capable of communicating seamlessly via natural language and navigating in environments that involve cooperation and competition, a fact that can introduce social dilemmas. Due to the interleaving of cooperation and competition, understanding agentsâ€™ decision-making in such environments is challenging, and humans can benefit from obtaining explanations. However, such environments and scenarios have rarely been explored in the context of explainable AI. While some explanation methods for cooperative environments can be applied in mixed-motive setups, they do not address inter-agent competition, cheap-talk, or implicit communication by actions. In this work, we design explanation methods to address these issues. Then, we proceed to establish generality and demonstrate the applicability of the methods to three games with vastly different properties. Lastly, we demonstrate the effectiveness and usefulness of the methods for humans in two mixed-motive games. The first is a challenging 7-player game called no-press Diplomacy. The second is a 3-player game inspired by the prisonerâ€™s dilemma, featuring communication in natural language. </p>
<blockquote>
<p>è¿‘å¹´æ¥ï¼Œä»£ç†ï¼ˆagentsï¼‰å·²ç»èƒ½å¤Ÿæ— ç¼åœ°é€šè¿‡è‡ªç„¶è¯­è¨€è¿›è¡Œäº¤æµï¼Œå¹¶åœ¨æ¶‰åŠåˆä½œä¸ç«äº‰çš„ç¯å¢ƒä¸­å¯¼èˆªï¼Œè¿™ä¸€äº‹å®å¯èƒ½å¼•å‘ç¤¾ä¼šå›°å¢ƒã€‚ç”±äºåˆä½œä¸ç«äº‰çš„äº¤ç»‡ï¼Œç†è§£ä»£ç†åœ¨è¿™ç§ç¯å¢ƒä¸­çš„å†³ç­–åˆ¶å®šå…·æœ‰æŒ‘æˆ˜æ€§ï¼Œäººç±»ä»è·å¾—è§£é‡Šä¸­å—ç›Šã€‚ç„¶è€Œï¼Œè¿™ç§ç¯å¢ƒå’Œåœºæ™¯åœ¨å¯è§£é‡Šäººå·¥æ™ºèƒ½çš„ä¸Šä¸‹æ–‡ä¸­å¾ˆå°‘è¢«æ¢ç´¢ã€‚è™½ç„¶ä¸€äº›åˆä½œç¯å¢ƒçš„è§£é‡Šæ–¹æ³•å¯ä»¥åº”ç”¨äºæ··åˆåŠ¨æœºè®¾ç½®ï¼Œä½†å®ƒä»¬å¹¶ä¸è§£å†³ä»£ç†é—´çš„ç«äº‰ã€å»‰ä»·å¯¹è¯æˆ–é€šè¿‡è¡ŒåŠ¨è¿›è¡Œçš„éšæ€§æ²Ÿé€šã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬è®¾è®¡äº†è§£é‡Šæ–¹æ³•æ¥è§£å†³è¿™äº›é—®é¢˜ã€‚ç„¶åï¼Œæˆ‘ä»¬ç»§ç»­å»ºç«‹æ™®éæ€§ï¼Œå¹¶è¯æ˜è¿™äº›æ–¹æ³•åœ¨ä¸‰ç§å…·æœ‰æˆªç„¶ä¸åŒå±æ€§çš„æ¸¸æˆä¸­çš„åº”ç”¨ã€‚æœ€åï¼Œæˆ‘ä»¬åœ¨ä¸¤ä¸ªæ··åˆåŠ¨æœºçš„æ¸¸æˆä¸­è¯æ˜äº†è¿™äº›æ–¹æ³•å¯¹äººç±»çš„æœ‰æ•ˆæ€§å’Œå®ç”¨æ€§ã€‚ç¬¬ä¸€ä¸ªæ˜¯ä¸€æ¬¾åä¸ºâ€œä¸æ–½åŠ å‹åŠ›çš„å¤–äº¤â€çš„7äººæ¸¸æˆï¼Œå……æ»¡æŒ‘æˆ˜ã€‚ç¬¬äºŒä¸ªæ˜¯å—å›šå¾’å›°å¢ƒå¯å‘çš„3äººæ¸¸æˆï¼Œä»¥è‡ªç„¶è¯­è¨€æ²Ÿé€šä¸ºç‰¹å¾ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2407.15255v3">PDF</a> To be published in AAAI 2025</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æ¢è®¨äº†æ™ºèƒ½ä»£ç†åœ¨åŒ…å«åˆä½œä¸ç«äº‰å…ƒç´ çš„ç¯å¢ƒä¸­é¢ä¸´çš„ç¤¾äº¤éš¾é¢˜ï¼Œå¦‚å†³ç­–åˆ¶å®šã€è§£é‡Šæ–¹æ³•å’Œåº”ç”¨åœºæ™¯ç­‰ã€‚é’ˆå¯¹æ··åˆåŠ¨æœºä¸‹çš„è§£é‡Šéš¾é¢˜ï¼Œè®¾è®¡äº†ä¸“é—¨çš„è§£é‡Šæ–¹æ³•å¹¶è¿›è¡Œäº†éªŒè¯ã€‚åŒæ—¶ä»‹ç»äº†è¯¥å·¥ä½œåœ¨å¤šç§ä¸åŒæ€§è´¨æ¸¸æˆä¸­çš„å®é™…åº”ç”¨æ•ˆæœï¼Œè¯æ˜äº†æ–¹æ³•çš„é€šç”¨æ€§å’Œæœ‰æ•ˆæ€§ã€‚äººç±»åœ¨è¯¥ç ”ç©¶ä¸­è¢«ç”¨ä½œå‚ä¸ä¸»ä½“è¯„ä¼°æ€§èƒ½çš„å…³é”®æˆå‘˜ï¼Œåœ¨ä¸åŒçš„åˆä½œç«äº‰åœºæ™¯ä¸‹å¯¹è¯¥æ–¹æ³•è¿›è¡Œå®é™…åº”ç”¨è¯„ä¼°ï¼Œæ¯”å¦‚ä¸€ç§æ— å‹åŠ›å¤–äº¤çš„æ¸¸æˆå’Œä¸€ä¸ªç”±è‡ªç„¶è¯­è¨€é©±åŠ¨çš„å›šçŠ¯å›°å¢ƒå¯å‘çš„æ¸¸æˆç­‰åœºæ™¯ã€‚åŒæ—¶æå‡ºäº†ä¸€ç§ç­–ç•¥äº¤äº’æ¨¡å¼ã€‚è¿™ä¸€æ€»ç»“ä½“ç°äº†ç ”ç©¶å·¥ä½œçš„æ·±åº¦ä¸å¹¿åº¦ï¼Œå¹¶ä¸”ä»¥ç®€æ´æ˜äº†çš„æ–¹å¼æ¦‚æ‹¬äº†æ ¸å¿ƒè¦ç‚¹ã€‚å¸Œæœ›è¿™ä¸ªæ€»ç»“èƒ½å¤Ÿå¸®åŠ©è¯»è€…å¿«é€Ÿç†è§£æœ¬æ–‡çš„ä¸»è¦å†…å®¹å’Œåˆ›æ–°ç‚¹ã€‚æ€»çš„æ¥è¯´ï¼Œæœ¬æ–‡ç ”ç©¶å…·æœ‰é‡è¦çš„ç†è®ºæ„ä¹‰å’Œå®è·µä»·å€¼ã€‚ç›¸ä¿¡è¿™é¡¹ç ”ç©¶å°†åœ¨äººå·¥æ™ºèƒ½é¢†åŸŸä¸­å¼•å‘å¹¿æ³›çš„å…³æ³¨å’Œåº”ç”¨æ¢ç´¢ã€‚ä¾‹å¦‚å¯ä»¥é€šè¿‡æ‰©å¤§å¯¹åšå¼ˆä¸­çš„è‡ªç„¶è¯­è¨€çš„å»ºæ¨¡è§„æ¨¡å’Œå¯¹å¤§è§„æ¨¡ç¤¾äº¤ç½‘ç»œç¯å¢ƒçš„æ”¯æŒèƒ½åŠ›ï¼Œä»¥æ”¹å–„æœªæ¥çš„åº”ç”¨ä½“éªŒå’Œæé«˜ç¤¾äº¤æœºå™¨äººçš„èƒ½åŠ›æ°´å¹³ç­‰è§’åº¦å…¥æ‰‹æ¥è¿›ä¸€æ­¥æ·±åŒ–æœ¬é¡¹ç ”ç©¶ã€‚<br><strong>Key Takeaways</strong></p>
<ul>
<li>æ™ºèƒ½ä»£ç†éœ€è¦åº”å¯¹åˆä½œä¸ç«äº‰å¹¶å­˜çš„ç¯å¢ƒï¼Œå¼•å…¥ç¤¾äº¤éš¾é¢˜ï¼Œå¯¹äººç±»å’Œä»£ç†å†³ç­–é€ æˆæŒ‘æˆ˜ã€‚è¿™ä¸€èƒŒæ™¯å¼•å‘äº†è§£é‡Šæ–¹æ³•çš„éœ€æ±‚ä»¥ååŠ©äººç±»ç†è§£æ™ºèƒ½ä»£ç†çš„è¡Œä¸ºæ¨¡å¼ä»¥åŠè¿›è¡Œæœ€ä¼˜å†³ç­–ã€‚</li>
<li>å½“å‰ç ”ç©¶ä¸­è§£é‡Šæ–¹æ³•çš„åº”ç”¨èŒƒå›´æœ‰é™ï¼Œç‰¹åˆ«æ˜¯åœ¨æ··åˆåŠ¨æœºç¯å¢ƒä¸‹çš„è§£é‡Šæ–¹æ³•å°šå¾…å®Œå–„ï¼Œå­˜åœ¨å¯¹å»‰ä»·å¯¹è¯å’Œéšæ€§æ²Ÿé€šçš„æŒ‘æˆ˜ã€‚æœ¬ç ”ç©¶è®¾è®¡äº†è§£é‡Šæ–¹æ³•æ¥åº”å¯¹è¿™äº›é—®é¢˜ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2407.15255">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-85bfc21ce59b5547c82c4527c427886c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-53aef7d097ab01a42f0f1756bc1b2fc0.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-88216a2e49dfe8556b924a00471aeb04.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-be533729d49f2a1177ac18fedb9898d2.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f9a4c47acd953ac6c0bd3d103b926619.jpg" align="middle">
</details>


<h1 id="-11"><a href="#-11" class="headerlink" title=""></a></h1><h2 id="Grounded-Language-Agent-for-Product-Search-via-Intelligent-Web-Interactions"><a href="#Grounded-Language-Agent-for-Product-Search-via-Intelligent-Web-Interactions" class="headerlink" title="Grounded Language Agent for Product Search via Intelligent Web   Interactions"></a>Grounded Language Agent for Product Search via Intelligent Web   Interactions</h2><p><strong>Authors:Moghis Fereidouni, Adib Mosharrof, A. B. Siddique</strong></p>
<p>The development of agents powered by large language models (LLMs) to accomplish complex high-level user intents, has attracted significant attention recently. However, employing LLMs with billions of parameters (e.g., GPT-4) may incur substantial costs on top of handcrafting extensive prompts. To address this, we introduce a Grounded Language Agent for Intelligent Web Interactions, named GLAINTEL. GLAINTEL employs Flan-T5 as its backbone and is flexible in training in various settings: unsupervised learning, supervised learning, and unsupervised domain adaptation. Specifically, we tackle both the challenge of learning without human demonstrations and the opportunity to leverage human demonstrations effectively when those are available. Additionally, we explore unsupervised domain adaptation for cases where demonstrations are limited to a specific domain. Experimental evaluations across diverse setups demonstrate the effectiveness of GLAINTEL in unsupervised settings, outperforming in-context learning-based approaches that employ larger models with up to 540 billion parameters. Surprisingly, behavioral cloning-based methods that straightforwardly use human demonstrations do not outperform unsupervised variants of GLAINTEL. Additionally, we show that combining human demonstrations with reinforcement learning-based training yields results comparable to methods utilizing GPT-4. The code is available at: <a target="_blank" rel="noopener" href="https://github.com/MultifacetedNLP/WebAgents-Unsupervised">https://github.com/MultifacetedNLP/WebAgents-Unsupervised</a>. </p>
<blockquote>
<p>åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„ä»£ç†å‘å±•ï¼Œä»¥å®Œæˆå¤æ‚çš„é«˜çº§ç”¨æˆ·æ„å›¾ï¼Œæœ€è¿‘å¼•èµ·äº†å¹¿æ³›å…³æ³¨ã€‚ç„¶è€Œï¼Œä½¿ç”¨å…·æœ‰æ•°åäº¿å‚æ•°çš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆä¾‹å¦‚GPT-4ï¼‰é™¤äº†éœ€è¦å¤§é‡æ‰‹å·¥åˆ¶ä½œçš„æç¤ºå¤–ï¼Œè¿˜å¯èƒ½äº§ç”Ÿå·¨å¤§æˆæœ¬ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬æ¨å‡ºäº†ä¸€ä¸ªåä¸ºGLAINTELçš„æ™ºèƒ½åŒ–ç½‘ç»œäº¤äº’æ¥åœ°è¯­è¨€ä»£ç†ã€‚GLAINTELé‡‡ç”¨Flan-T5ä½œä¸ºå…¶ä¸»å¹²ï¼Œåœ¨å„ç§è®¾ç½®ï¼ˆæ— ç›‘ç£å­¦ä¹ ã€ç›‘ç£å­¦ä¹ å’Œæ— ç›‘ç£åŸŸé€‚åº”ï¼‰ä¸­è¿›è¡Œè®­ç»ƒæ—¶è¡¨ç°å‡ºçµæ´»æ€§ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬è§£å†³äº†æ²¡æœ‰äººç±»æ¼”ç¤ºæ—¶çš„å­¦ä¹ æŒ‘æˆ˜ï¼Œå¹¶æŠ“ä½äº†åœ¨æœ‰å¯ç”¨çš„äººç±»æ¼”ç¤ºæ—¶æœ‰æ•ˆåˆ©ç”¨è¿™äº›æ¼”ç¤ºçš„æœºä¼šã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜æ¢ç´¢äº†æ¼”ç¤ºä»…é™äºç‰¹å®šé¢†åŸŸçš„æƒ…å†µä¸‹çš„æ— ç›‘ç£åŸŸé€‚åº”ã€‚åœ¨å¤šç§è®¾ç½®ä¸‹çš„å®éªŒè¯„ä¼°è¡¨æ˜ï¼ŒGLAINTELåœ¨æ— ç›‘ç£ç¯å¢ƒä¸­çš„æœ‰æ•ˆæ€§ï¼Œè¶…è¶Šäº†ä½¿ç”¨æ›´å¤§æ¨¡å‹çš„åŸºäºä¸Šä¸‹æ–‡å­¦ä¹ çš„æ–¹æ³•ï¼Œè¿™äº›æ¨¡å‹çš„å‚æ•°é«˜è¾¾540äº¿ã€‚ä»¤äººæƒŠè®¶çš„æ˜¯ï¼Œç›´æ¥ä½¿ç”¨äººç±»æ¼”ç¤ºçš„è¡Œä¸ºå…‹éš†æ–¹æ³•å¹¶æ²¡æœ‰è¶…è¶ŠGLAINTELçš„æ— ç›‘ç£ç‰ˆæœ¬ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜è¡¨æ˜ï¼Œå°†äººç±»æ¼”ç¤ºä¸åŸºäºå¼ºåŒ–å­¦ä¹ çš„è®­ç»ƒç›¸ç»“åˆï¼Œæ‰€äº§ç”Ÿçš„ç»“æœä¸åˆ©ç”¨GPT-4çš„æ–¹æ³•ç›¸å½“ã€‚ç›¸å…³ä»£ç å¯è®¿é—®ï¼š<a target="_blank" rel="noopener" href="https://github.com/MultifacetedNLP/WebAgents-Unsupervised">https://github.com/MultifacetedNLP/WebAgents-Unsupervised</a>ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2404.10887v2">PDF</a> 9 pages</p>
<p><strong>Summary</strong></p>
<p>åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„ä»£ç†å¼€å‘ï¼Œç”¨äºå®ç°å¤æ‚çš„é«˜çº§ç”¨æˆ·æ„å›¾ï¼Œå·²å¼•èµ·å¹¿æ³›å…³æ³¨ã€‚ä¸ºè§£å†³ä½¿ç”¨å¤§å‹è¯­è¨€æ¨¡å‹çš„é«˜æˆæœ¬é—®é¢˜ï¼Œæ¨å‡ºäº†åä¸ºGLAINTELçš„æ™ºèƒ½äº’åŠ¨è¯­è¨€ä»£ç†ã€‚GLAINTELä»¥Flan-T-Basedä¸ºå…¶éª¨å¹²æ¶æ„ï¼Œå¹¶çµæ´»é€‚åº”å¤šç§è®­ç»ƒåœºæ™¯ï¼ŒåŒ…æ‹¬æ— ç›‘ç£å­¦ä¹ ã€ç›‘ç£å­¦ä¹ å’Œæ— ç›‘ç£åŸŸé€‚åº”ã€‚å…¶åº”å¯¹æŒ‘æˆ˜ä¹‹ä¸€æ˜¯æ— éœ€äººç±»æ¼”ç¤ºè¿›è¡Œå­¦ä¹ ï¼ŒåŒæ—¶åœ¨æœ‰äººç±»æ¼”ç¤ºçš„æƒ…å†µä¸‹æœ‰æ•ˆåŠ ä»¥åˆ©ç”¨ã€‚é’ˆå¯¹æ¼”ç¤ºé™äºç‰¹å®šé¢†åŸŸçš„åœºæ™¯ï¼ŒGLAINTELè¿˜æ¢ç´¢äº†æ— ç›‘ç£åŸŸé€‚åº”ã€‚åœ¨å¤šæ ·åŒ–çš„å®éªŒç¯å¢ƒä¸‹ï¼ŒGLAINTELåœ¨æ— ç›‘ç£ç¯å¢ƒä¸‹çš„è¡¨ç°æ•ˆæœæ˜¾è‘—ï¼Œè¶…è¿‡äº†åŸºäºä¸Šä¸‹æ–‡çš„è¾ƒå¤§æ¨¡å‹å­¦ä¹ æ¨¡å‹ï¼Œè¡¨ç°å‡ºè‰¯å¥½çš„è¡¨ç°æ€§èƒ½ã€‚ç‰¹åˆ«çš„æ˜¯ï¼Œç»“åˆäº†äººç±»æ¼”ç¤ºä¸å¼ºåŒ–å­¦ä¹ è®­ç»ƒçš„æ–¹æ³•äº§ç”Ÿçš„ç»“æœä¸GPT-4ç›¸å½“ã€‚ä»£ç å·²å…¬å¼€åœ¨GitHubä¸Šã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ä»£ç†çš„å‘å±•å¸å¼•äº†å¹¿æ³›å…³æ³¨ï¼Œç”¨äºå®ç°å¤æ‚çš„é«˜çº§ç”¨æˆ·æ„å›¾ã€‚</li>
<li>GLAINTELæ˜¯ä¸€ä¸ªæ™ºèƒ½äº’åŠ¨è¯­è¨€ä»£ç†ï¼Œä»¥Flan-T-Basedä½œä¸ºå…¶éª¨å¹²æ¶æ„ï¼Œèƒ½çµæ´»é€‚åº”ä¸åŒçš„è®­ç»ƒåœºæ™¯ã€‚</li>
<li>GLAINTELå¯ä»¥è§£å†³åœ¨æ²¡æœ‰äººç±»æ¼”ç¤ºçš„æƒ…å†µä¸‹è¿›è¡Œå­¦ä¹ çš„é—®é¢˜ï¼Œå¹¶èƒ½æœ‰æ•ˆåˆ©ç”¨äººç±»æ¼”ç¤ºã€‚</li>
<li>GLAINTELåœ¨æ— ç›‘ç£åŸŸé€‚åº”æ–¹é¢è¿›è¡Œäº†æ¢ç´¢ï¼Œé€‚ç”¨äºæ¼”ç¤ºé™äºç‰¹å®šé¢†åŸŸçš„åœºæ™¯ã€‚</li>
<li>åœ¨å¤šæ ·åŒ–çš„å®éªŒç¯å¢ƒä¸‹ï¼ŒGLAINTELåœ¨æ— ç›‘ç£ç¯å¢ƒä¸‹çš„è¡¨ç°æ•ˆæœæ˜¾è‘—ï¼Œè¶…è¿‡äº†åŸºäºä¸Šä¸‹æ–‡çš„è¾ƒå¤§æ¨¡å‹å­¦ä¹ æ¨¡å‹ã€‚</li>
<li>ç»“åˆäººç±»æ¼”ç¤ºä¸å¼ºåŒ–å­¦ä¹ è®­ç»ƒçš„æ–¹æ³•äº§ç”Ÿçš„ç»“æœä¸GPT-4ç›¸å½“ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2404.10887">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-4bccadfdfbaedda3f7895b64e1554304.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-e8fffa7edd50b99d5e37c5217d4daa2e.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-caf86bb6b82999c627b07f01da571c08.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-0fdbcd8bb171f49a4debedeedc92f429.jpg" align="middle">
</details>


<h1 id="-12"><a href="#-12" class="headerlink" title=""></a></h1><h2 id="KnowAgent-Knowledge-Augmented-Planning-for-LLM-Based-Agents"><a href="#KnowAgent-Knowledge-Augmented-Planning-for-LLM-Based-Agents" class="headerlink" title="KnowAgent: Knowledge-Augmented Planning for LLM-Based Agents"></a>KnowAgent: Knowledge-Augmented Planning for LLM-Based Agents</h2><p><strong>Authors:Yuqi Zhu, Shuofei Qiao, Yixin Ou, Shumin Deng, Ningyu Zhang, Shiwei Lyu, Yue Shen, Lei Liang, Jinjie Gu, Huajun Chen</strong></p>
<p>Large Language Models (LLMs) have demonstrated great potential in complex reasoning tasks, yet they fall short when tackling more sophisticated challenges, especially when interacting with environments through generating executable actions. This inadequacy primarily stems from the lack of built-in action knowledge in language agents, which fails to effectively guide the planning trajectories during task solving and results in planning hallucination. To address this issue, we introduce KnowAgent, a novel approach designed to enhance the planning capabilities of LLMs by incorporating explicit action knowledge. Specifically, KnowAgent employs an action knowledge base and a knowledgeable self-learning strategy to constrain the action path during planning, enabling more reasonable trajectory synthesis, and thereby enhancing the planning performance of language agents. Experimental results on HotpotQA and ALFWorld based on various backbone models demonstrate that KnowAgent can achieve comparable or superior performance to existing baselines. Further analysis indicates the effectiveness of KnowAgent in terms of planning hallucinations mitigation. Code is available in <a target="_blank" rel="noopener" href="https://github.com/zjunlp/KnowAgent">https://github.com/zjunlp/KnowAgent</a>. </p>
<blockquote>
<p>å¤§è§„æ¨¡è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å¤æ‚çš„æ¨ç†ä»»åŠ¡ä¸­å±•ç°å‡ºäº†å·¨å¤§çš„æ½œåŠ›ï¼Œä½†åœ¨åº”å¯¹æ›´é«˜çº§çš„æŒ‘æˆ˜æ—¶ï¼Œå°¤å…¶æ˜¯åœ¨é€šè¿‡ç”Ÿæˆå¯æ‰§è¡ŒåŠ¨ä½œä¸ç¯å¢ƒè¿›è¡Œäº¤äº’æ—¶ï¼Œå®ƒä»¬çš„è¡¨ç°å´ä¸å°½å¦‚äººæ„ã€‚è¿™ç§ä¸è¶³ä¸»è¦æºäºè¯­è¨€æ¨¡å‹ä¸­ç¼ºä¹å†…ç½®çš„åŠ¨ä½œçŸ¥è¯†ï¼Œå¯¼è‡´åœ¨ä»»åŠ¡è§£å†³è¿‡ç¨‹ä¸­æ— æ³•æœ‰æ•ˆåœ°æŒ‡å¯¼è§„åˆ’è½¨è¿¹ï¼Œè¿›è€Œäº§ç”Ÿè§„åˆ’å¹»è§‰ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬å¼•å…¥äº†KnowAgentï¼Œè¿™æ˜¯ä¸€ç§é€šè¿‡èå…¥æ˜ç¡®åŠ¨ä½œçŸ¥è¯†æ¥å¢å¼ºLLMè§„åˆ’èƒ½åŠ›çš„æ–°å‹æ–¹æ³•ã€‚å…·ä½“æ¥è¯´ï¼ŒKnowAgenté‡‡ç”¨åŠ¨ä½œçŸ¥è¯†åº“å’ŒçŸ¥è¯†è‡ªæˆ‘å­¦ä¹ ç­–ç•¥æ¥çº¦æŸè§„åˆ’è¿‡ç¨‹ä¸­çš„åŠ¨ä½œè·¯å¾„ï¼Œä»è€Œå®ç°æ›´åˆç†çš„è½¨è¿¹åˆæˆï¼Œæå‡è¯­è¨€ä»£ç†çš„è§„åˆ’æ€§èƒ½ã€‚åœ¨HotpotQAå’ŒåŸºäºä¸åŒéª¨å¹²æ¨¡å‹çš„ALFWorldä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼ŒKnowAgentå¯ä»¥è¾¾åˆ°æˆ–è¶…è¶Šç°æœ‰åŸºå‡†çº¿çš„æ€§èƒ½ã€‚è¿›ä¸€æ­¥çš„åˆ†æè¡¨æ˜ï¼ŒKnowAgentåœ¨ç¼“è§£è§„åˆ’å¹»è§‰æ–¹é¢éå¸¸æœ‰æ•ˆã€‚ä»£ç å¯è®¿é—® <a target="_blank" rel="noopener" href="https://github.com/zjunlp/KnowAgent%E3%80%82">https://github.com/zjunlp/KnowAgentã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2403.03101v2">PDF</a> NAACL 2025 Findings. Project page:   <a target="_blank" rel="noopener" href="https://zjunlp.github.io/project/KnowAgent/">https://zjunlp.github.io/project/KnowAgent/</a> Code:   <a target="_blank" rel="noopener" href="https://github.com/zjunlp/KnowAgent">https://github.com/zjunlp/KnowAgent</a></p>
<p><strong>Summary</strong></p>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å¤æ‚æ¨ç†ä»»åŠ¡ä¸­å±•ç°å‡ºå·¨å¤§æ½œåŠ›ï¼Œä½†åœ¨åº”å¯¹æ›´é«˜çº§æŒ‘æˆ˜æ—¶ï¼Œå°¤å…¶æ˜¯åœ¨é€šè¿‡ç”Ÿæˆå¯æ‰§è¡ŒåŠ¨ä½œä¸ç¯å¢ƒäº’åŠ¨æ–¹é¢å­˜åœ¨ä¸è¶³ã€‚æ­¤ä¸è¶³ä¸»è¦æºäºè¯­è¨€æ¨¡å‹ä¸­ç¼ºä¹å†…ç½®çš„åŠ¨ä½œçŸ¥è¯†ï¼Œæ— æ³•æœ‰æ•ˆæŒ‡å¯¼ä»»åŠ¡è§£å†³è¿‡ç¨‹ä¸­çš„è§„åˆ’è½¨è¿¹ï¼Œå¯¼è‡´è§„åˆ’å¹»è§‰ã€‚ä¸ºè§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºKnowAgentï¼Œè¿™æ˜¯ä¸€ç§é€šè¿‡èå…¥æ˜ç¡®åŠ¨ä½œçŸ¥è¯†æ¥æå‡LLMè§„åˆ’èƒ½åŠ›çš„æ–°æ–¹æ³•ã€‚KnowAgenté‡‡ç”¨åŠ¨ä½œçŸ¥è¯†åº“å’ŒçŸ¥è¯†è‡ªæˆ‘å­¦ä¹ ç­–ç•¥æ¥çº¦æŸè§„åˆ’è¿‡ç¨‹ä¸­çš„åŠ¨ä½œè·¯å¾„ï¼Œå®ç°æ›´åˆç†çš„è½¨è¿¹åˆæˆï¼Œä»è€Œæå‡è¯­è¨€ä»£ç†çš„è§„åˆ’æ€§èƒ½ã€‚åœ¨HotpotQAå’ŒALFWorldä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼ŒKnowAgentçš„æ€§èƒ½ä¸ç°æœ‰åŸºçº¿ç›¸æ¯”å…·æœ‰ç«äº‰åŠ›æˆ–æ›´ä¼˜ç§€ã€‚KnowAgentåœ¨ç¼“è§£è§„åˆ’å¹»è§‰æ–¹é¢è¡¨ç°å‡ºæœ‰æ•ˆæ€§ã€‚ç›¸å…³ä»£ç å¯è®¿é—®ï¼š<a target="_blank" rel="noopener" href="https://github.com/zjunlp/KnowAgent%E3%80%82">https://github.com/zjunlp/KnowAgentã€‚</a></p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å¤æ‚æ¨ç†ä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ï¼Œä½†åœ¨å¤„ç†æ›´é«˜çº§æŒ‘æˆ˜æ—¶å­˜åœ¨ç¼ºé™·ï¼Œç‰¹åˆ«æ˜¯åœ¨ä¸ç¯å¢ƒäº¤äº’æ–¹é¢ã€‚</li>
<li>ç¼ºé™·çš„æ ¹æºåœ¨äºLLMç¼ºä¹å†…ç½®çš„åŠ¨ä½œçŸ¥è¯†ï¼Œæ— æ³•æœ‰æ•ˆæŒ‡å¯¼ä»»åŠ¡è§£å†³è¿‡ç¨‹ä¸­çš„è§„åˆ’è½¨è¿¹ã€‚</li>
<li>KnowAgentæ˜¯ä¸€ç§é€šè¿‡èå…¥æ˜ç¡®åŠ¨ä½œçŸ¥è¯†æå‡LLMè§„åˆ’èƒ½åŠ›çš„æ–¹æ³•ã€‚</li>
<li>KnowAgenté‡‡ç”¨åŠ¨ä½œçŸ¥è¯†åº“å’ŒçŸ¥è¯†è‡ªæˆ‘å­¦ä¹ ç­–ç•¥æ¥çº¦æŸè§„åˆ’è¿‡ç¨‹ä¸­çš„åŠ¨ä½œè·¯å¾„ã€‚</li>
<li>KnowAgentå®ç°äº†æ›´åˆç†çš„è½¨è¿¹åˆæˆï¼Œæå‡äº†è¯­è¨€ä»£ç†çš„è§„åˆ’æ€§èƒ½ã€‚</li>
<li>åœ¨HotpotQAå’ŒALFWorldä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒKnowAgentæ€§èƒ½ä¼˜è¶Šï¼Œä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”å…·æœ‰ç«äº‰åŠ›ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2403.03101">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-4a31cf76514ca2f6549064ddafce540d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-1af90a76392f397af561b17378e1fad9.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-6744251ca499fc6a5c064618ed027103.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-27c564a63466f631520a742f943d7c8a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d22361c4a1e3e4e040f976bb2f17f5d2.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-fe686f06ccf16f87e7d18e8fb639ff90.jpg" align="middle">
</details>


<h1 id="-13"><a href="#-13" class="headerlink" title=""></a></h1><h2 id="Agent-OM-Leveraging-LLM-Agents-for-Ontology-Matching"><a href="#Agent-OM-Leveraging-LLM-Agents-for-Ontology-Matching" class="headerlink" title="Agent-OM: Leveraging LLM Agents for Ontology Matching"></a>Agent-OM: Leveraging LLM Agents for Ontology Matching</h2><p><strong>Authors:Zhangcheng Qiang, Weiqing Wang, Kerry Taylor</strong></p>
<p>Ontology matching (OM) enables semantic interoperability between different ontologies and resolves their conceptual heterogeneity by aligning related entities. OM systems currently have two prevailing design paradigms: conventional knowledge-based expert systems and newer machine learning-based predictive systems. While large language models (LLMs) and LLM agents have revolutionised data engineering and have been applied creatively in many domains, their potential for OM remains underexplored. This study introduces a novel agent-powered LLM-based design paradigm for OM systems. With consideration of several specific challenges in leveraging LLM agents for OM, we propose a generic framework, namely Agent-OM (Agent for Ontology Matching), consisting of two Siamese agents for retrieval and matching, with a set of OM tools. Our framework is implemented in a proof-of-concept system. Evaluations of three Ontology Alignment Evaluation Initiative (OAEI) tracks over state-of-the-art OM systems show that our system can achieve results very close to the long-standing best performance on simple OM tasks and can significantly improve the performance on complex and few-shot OM tasks. </p>
<blockquote>
<p>æœ¬ä½“åŒ¹é…ï¼ˆOMï¼‰èƒ½å¤Ÿåœ¨ä¸åŒçš„æœ¬ä½“ä¹‹é—´å®ç°è¯­ä¹‰äº’æ“ä½œæ€§ï¼Œå¹¶é€šè¿‡å¯¹é½ç›¸å…³å®ä½“è§£å†³å…¶æ¦‚å¿µä¸Šçš„å¼‚è´¨æ€§ã€‚ç›®å‰ï¼ŒOMç³»ç»Ÿä¸»è¦æœ‰ä¸¤ç§æµè¡Œçš„è®¾è®¡èŒƒå¼ï¼šä¼ ç»Ÿçš„åŸºäºçŸ¥è¯†çš„ä¸“å®¶ç³»ç»Ÿå’Œè¾ƒæ–°çš„åŸºäºæœºå™¨å­¦ä¹ çš„é¢„æµ‹ç³»ç»Ÿã€‚è™½ç„¶å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å’ŒLLMä»£ç†å·²ç»å½»åº•æ”¹å˜äº†æ•°æ®å·¥ç¨‹ï¼Œå¹¶ä¸”å·²ç»åœ¨è®¸å¤šé¢†åŸŸå¾—åˆ°äº†åˆ›é€ æ€§çš„åº”ç”¨ï¼Œä½†å®ƒä»¬åœ¨OMä¸­çš„æ½œåŠ›ä»ç„¶è¢«ä½ä¼°ã€‚æœ¬ç ”ç©¶å¼•å…¥äº†ä¸€ç§åŸºäºä»£ç†çš„LLMè®¾è®¡èŒƒå¼çš„æ–°å‹OMç³»ç»Ÿã€‚è€ƒè™‘åˆ°åˆ©ç”¨LLMä»£ç†è¿›è¡ŒOMé¢ä¸´çš„è‹¥å¹²ç‰¹å®šæŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªé€šç”¨æ¡†æ¶ï¼Œå³Agent-OMï¼ˆç”¨äºæœ¬ä½“åŒ¹é…çš„ä»£ç†ï¼‰ï¼Œå®ƒç”±ä¸¤ä¸ªç”¨äºæ£€ç´¢å’ŒåŒ¹é…çš„Siameseä»£ç†å’Œä¸€ç»„OMå·¥å…·ç»„æˆã€‚æˆ‘ä»¬çš„æ¡†æ¶åœ¨ä¸€ä¸ªæ¦‚å¿µéªŒè¯ç³»ç»Ÿä¸­å®ç°ã€‚å¯¹ä¸‰ä¸ªæœ¬ä½“å¯¹é½è¯„ä¼°å€¡è®®ï¼ˆOAEIï¼‰èµ›é“çš„æœ€å…ˆè¿›OMç³»ç»Ÿçš„è¯„ä¼°è¡¨æ˜ï¼Œæˆ‘ä»¬çš„ç³»ç»Ÿåœ¨ç®€å•OMä»»åŠ¡ä¸Šçš„ç»“æœéå¸¸æ¥è¿‘é•¿æœŸä»¥æ¥çš„æœ€ä½³æ€§èƒ½ï¼Œå¹¶ä¸”åœ¨å¤æ‚å’Œå°‘é‡OMä»»åŠ¡ä¸Šå¯ä»¥æ˜¾è‘—æé«˜æ€§èƒ½ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2312.00326v7">PDF</a> 19 pages, 12 figures, 3 tables</p>
<p><strong>Summary</strong></p>
<p>åŸºäºæœ¬ä½“åŒ¹é…çš„OMç³»ç»Ÿèƒ½é€šè¿‡ä¸¤ç§æµè¡Œè®¾è®¡èŒƒä¾‹å®ç°è¯­ä¹‰äº’é€šæ€§ï¼Œä½†è¿˜å­˜åœ¨æ½œåœ¨çš„æŒ–æ˜ä¸è¶³çš„é—®é¢˜ã€‚è¿™é¡¹ç ”ç©¶åˆ©ç”¨è¯­è¨€å¤§æ¨¡å‹å’Œç›¸åº”çš„å®ä½“æ™ºèƒ½ä½“è®¾è®¡äº†ä¸€ç§æ–°å‹çš„OMç³»ç»Ÿï¼Œå¹¶é€šè¿‡ä½¿ç”¨ä¸€å¥—å·¥å…·é›†æ¥è§£å†³å„ç§æŒ‘æˆ˜ã€‚è¯„ä»·æ˜¾ç¤ºï¼Œè¯¥ç³»ç»Ÿçš„æ€§èƒ½æ¥è¿‘äºé•¿æœŸä»¥æ¥çš„æœ€ä½³è¡¨ç°ï¼Œå¹¶åœ¨å¤æ‚å’Œå°‘æ ·æœ¬çš„OMä»»åŠ¡ä¸Šæ˜¾è‘—æé«˜æ€§èƒ½ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2312.00326">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-52161e898ad82f80ae924e0739023488.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-3be1f670b4b3e5e54e8dc998918fda9d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-1cde61049b12372f9a36b0b53054ed8c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-1489e8850d1b5cc66334d1a52d1e015b.jpg" align="middle">
</details>


<h1 id="-14"><a href="#-14" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-01-29/Agent/">https://kedreamix.github.io/Talk2Paper/Paper/2025-01-29/Agent/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/Agent/">
                                    <span class="chip bg-color">Agent</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-01-29/MMT/">
                    <div class="card-image">
                        
                        <img src="https://pic1.zhimg.com/v2-5b387b561138112390a193753a2d886d.jpg" class="responsive-img" alt="MMT">
                        
                        <span class="card-title">MMT</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            MMT æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-01-29  Pangea A Fully Open Multilingual Multimodal LLM for 39 Languages
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-01-29
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/MMT/" class="post-category">
                                    MMT
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/MMT/">
                        <span class="chip bg-color">MMT</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-01-29/LLM/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-2c75a7bea1840643d0720bc3bfbfb1ce.jpg" class="responsive-img" alt="LLM">
                        
                        <span class="card-title">LLM</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            LLM æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-01-29  RAPID Retrieval-Augmented Parallel Inference Drafting for Text-Based   Video Event Retrieval
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-01-29
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/LLM/" class="post-category">
                                    LLM
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/LLM/">
                        <span class="chip bg-color">LLM</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">15534.8k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
