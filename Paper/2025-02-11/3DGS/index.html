<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="3DGS">
    <meta name="description" content="3DGS 方向最新论文已更新，请持续关注 Update in 2025-02-11  AuraFusion360 Augmented Unseen Region Alignment for Reference-based   360° Unbounded Scene Inpainting">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>3DGS | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loader页面消失采用渐隐的方式*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logo出现动画 */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//使用渐隐的方法淡出loading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//强制显示loading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">嘘~  正在从服务器偷取页面 . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>首页</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>标签</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>分类</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>归档</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="搜索" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="深色/浅色模式" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			首页
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			标签
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			分类
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			归档
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://picx.zhimg.com/v2-1a1261f37839c32f4bcc44800933edd0.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">3DGS</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/3DGS/">
                                <span class="chip bg-color">3DGS</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/3DGS/" class="post-category">
                                3DGS
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2025-02-11
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>更新日期:&nbsp;&nbsp;
                    2025-02-13
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp;
                    7.5k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp;
                    30 分
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>阅读次数:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>⚠️ 以下所有内容总结都来自于 大语言模型的能力，如有错误，仅供参考，谨慎使用<br>🔴 请注意：千万不要用于严肃的学术场景，只能用于论文阅读前的初筛！<br>💗 如果您觉得我们的项目对您有帮助 <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ，还请您给我们一些鼓励！⭐️ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFace免费体验</a></p>
</blockquote>
<h1 id="2025-02-11-更新"><a href="#2025-02-11-更新" class="headerlink" title="2025-02-11 更新"></a>2025-02-11 更新</h1><h2 id="AuraFusion360-Augmented-Unseen-Region-Alignment-for-Reference-based-360°-Unbounded-Scene-Inpainting"><a href="#AuraFusion360-Augmented-Unseen-Region-Alignment-for-Reference-based-360°-Unbounded-Scene-Inpainting" class="headerlink" title="AuraFusion360: Augmented Unseen Region Alignment for Reference-based   360° Unbounded Scene Inpainting"></a>AuraFusion360: Augmented Unseen Region Alignment for Reference-based   360° Unbounded Scene Inpainting</h2><p><strong>Authors:Chung-Ho Wu, Yang-Jung Chen, Ying-Huan Chen, Jie-Ying Lee, Bo-Hsu Ke, Chun-Wei Tuan Mu, Yi-Chuan Huang, Chin-Yang Lin, Min-Hung Chen, Yen-Yu Lin, Yu-Lun Liu</strong></p>
<p>Three-dimensional scene inpainting is crucial for applications from virtual reality to architectural visualization, yet existing methods struggle with view consistency and geometric accuracy in 360{\deg} unbounded scenes. We present AuraFusion360, a novel reference-based method that enables high-quality object removal and hole filling in 3D scenes represented by Gaussian Splatting. Our approach introduces (1) depth-aware unseen mask generation for accurate occlusion identification, (2) Adaptive Guided Depth Diffusion, a zero-shot method for accurate initial point placement without requiring additional training, and (3) SDEdit-based detail enhancement for multi-view coherence. We also introduce 360-USID, the first comprehensive dataset for 360{\deg} unbounded scene inpainting with ground truth. Extensive experiments demonstrate that AuraFusion360 significantly outperforms existing methods, achieving superior perceptual quality while maintaining geometric accuracy across dramatic viewpoint changes. See our project page for video results and the dataset at <a target="_blank" rel="noopener" href="https://kkennethwu.github.io/aurafusion360/">https://kkennethwu.github.io/aurafusion360/</a>. </p>
<blockquote>
<p>三维场景补全对于从虚拟现实到建筑可视化等应用至关重要，但现有方法在360°无界场景的视图一致性及几何精度方面存在困难。我们提出了AuraFusion360，这是一种基于参考的新方法，能够在高斯散斑表示的三维场景中进行高质量的对象移除和空洞填充。我们的方法引入了（1）深度感知未见掩模生成，用于准确识别遮挡，（2）自适应引导深度扩散，这是一种无需额外训练的零样本方法，可用于准确放置初始点，（3）基于SDEdit的细节增强，以实现多视图一致性。我们还引入了360-USID，这是首个针对360°无界场景补全的综合数据集，带有真实标签。大量实验表明，AuraFusion360在感知质量上显著优于现有方法，在剧烈视点变化时也能保持几何精度。视频结果和数据集请参见我们的项目页面：<a target="_blank" rel="noopener" href="https://kkennethwu.github.io/aurafusion360/%EF%BC%88%E9%93%BE%E6%8E%A5%E5%9C%B0%E5%9D%80%E8%AF%B7%E6%A0%B9%E6%8D%AE%E5%AE%9E%E9%99%85%E4%BF%AE%E6%94%B9%EF%BC%89%E3%80%82">https://kkennethwu.github.io/aurafusion360/（链接地址请根据实际情况修改）。</a></p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.05176v1">PDF</a> Project page: <a target="_blank" rel="noopener" href="https://kkennethwu.github.io/aurafusion360/">https://kkennethwu.github.io/aurafusion360/</a></p>
<p><strong>Summary</strong></p>
<p>本文介绍了一种名为AuraFusion360的新型基于参考的三维场景补全方法，适用于虚拟现实和建筑可视化等应用。该方法在Gaussian Splatting表示的3D场景中进行高质量的对象移除和空洞填充，具有深度感知的未见掩膜生成、自适应引导深度扩散和SDEdit细节增强等技术特点。同时，引入了首个全面的360°无界场景补全数据集360-USID，实验表明AuraFusion360在视觉质量和几何准确性方面显著优于现有方法。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>AuraFusion360是一种新型基于参考的三维场景补全方法，适用于多种应用如虚拟现实和建筑可视化。</li>
<li>该方法采用Gaussian Splatting表示3D场景，进行高质量的对象移除和空洞填充。</li>
<li>深度感知的未见掩膜生成技术，能准确识别遮挡区域。</li>
<li>引入自适应引导深度扩散技术，无需额外训练即可实现准确初始点放置。</li>
<li>SDEdit细节增强技术，实现多视角一致性。</li>
<li>引入首个全面的360°无界场景补全数据集360-USID，提供真实场景数据。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.05176">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-d0985c2d524d2cb6b7c157d592029a65.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c4af89a16be88b8e1887549b3708586d.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-1f6637599b95cf645f4f52ef4704e887.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b8e8b589c3d537119a0d4f3486615c24.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="GaussRender-Learning-3D-Occupancy-with-Gaussian-Rendering"><a href="#GaussRender-Learning-3D-Occupancy-with-Gaussian-Rendering" class="headerlink" title="GaussRender: Learning 3D Occupancy with Gaussian Rendering"></a>GaussRender: Learning 3D Occupancy with Gaussian Rendering</h2><p><strong>Authors:Loick Chambon, Eloi Zablocki, Alexandre Boulch, Mickael Chen, Matthieu Cord</strong></p>
<p>Understanding the 3D geometry and semantics of driving scenes is critical for developing of safe autonomous vehicles. While 3D occupancy models are typically trained using voxel-based supervision with standard losses (e.g., cross-entropy, Lovasz, dice), these approaches treat voxel predictions independently, neglecting their spatial relationships. In this paper, we propose GaussRender, a plug-and-play 3D-to-2D reprojection loss that enhances voxel-based supervision. Our method projects 3D voxel representations into arbitrary 2D perspectives and leverages Gaussian splatting as an efficient, differentiable rendering proxy of voxels, introducing spatial dependencies across projected elements. This approach improves semantic and geometric consistency, handles occlusions more efficiently, and requires no architectural modifications. Extensive experiments on multiple benchmarks (SurroundOcc-nuScenes, Occ3D-nuScenes, SSCBench-KITTI360) demonstrate consistent performance gains across various 3D occupancy models (TPVFormer, SurroundOcc, Symphonies), highlighting the robustness and versatility of our framework. The code is available at <a target="_blank" rel="noopener" href="https://github.com/valeoai/GaussRender">https://github.com/valeoai/GaussRender</a>. </p>
<blockquote>
<p>了解驾驶场景的3D几何和语义对于开发安全自动驾驶汽车至关重要。虽然3D占用模型通常使用基于体素的标准损失（例如交叉熵、Lovasz和dice）进行训练，但这些方法独立处理体素预测，忽略了它们的空间关系。在本文中，我们提出了一种即插即用的3D到2D重投影损失GaussRender，它增强了基于体素的监督方法。我们的方法将3D体素表示投影到任意二维视角，并利用高斯模板作为体素高效、可微分的渲染代理，在投影元素之间引入空间依赖性。这种方法提高了语义和几何一致性，能更有效地处理遮挡问题，且无需修改架构。在多个基准测试集（SurroundOcc-nuScenes、Occ3D-nuScenes、SSCBench-KITTI360）上的大量实验表明，在各种3D占用模型（TPVFormer、SurroundOcc、Symphonies）中都能获得稳定的性能提升，突显了我们框架的稳健性和通用性。代码可访问<a target="_blank" rel="noopener" href="https://github.com/valeoai/GaussRender%E3%80%82">https://github.com/valeoai/GaussRender。</a></p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.05040v1">PDF</a> </p>
<p><strong>摘要</strong></p>
<p>本文提出一种名为GaussRender的3D到2D重投影损失方法，用于增强基于体素的监督训练，提高自主车辆对驾驶场景的理解能力。该方法将3D体素表示投影到任意2D视角，并利用高斯平铺作为体素的可微高效渲染代理，引入投影元素之间的空间依赖性。该方法提高了语义和几何一致性，更有效地处理遮挡问题，且无需修改架构。在多个基准测试集上的实验表明，该方法在各种3D占用模型上的性能均有所提升，凸显了其稳健性和通用性。代码已公开。</p>
<p><strong>要点</strong></p>
<ol>
<li>自主车辆对驾驶场景的理解需依赖于3D几何和语义分析。</li>
<li>传统3D占用模型训练多采用基于体素的监督方法和标准损失函数，但忽略了空间关系。</li>
<li>GaussRender是一种新型的3D到2D重投影损失方法，旨在增强基于体素的监督训练。</li>
<li>GaussRender通过将3D体素表示投影到任意2D视角，并借助高斯平铺技术处理体素渲染，从而引入空间依赖性。</li>
<li>该方法提高了语义和几何一致性，更有效地处理遮挡问题。</li>
<li>GaussRender具有广泛的适用性和稳健性，适用于多种3D占用模型，且在多个基准测试集上表现优异。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.05040">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-0246f513938274ec5b263020c3ee0ee5.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-30eb81535d172bd5cdf2f11ec0e3ba54.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-46384b196f72ced0f057afaae07bb39c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-bf41e85fc092d7b3b3d45236d4d7db91.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-5e7292d30ba53c1790271e8069ffb2de.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-dd69fb6f0b946676d5b7a414f6048036.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-716be8913f8d7362174812386a1a183f.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="OccGS-Zero-shot-3D-Occupancy-Reconstruction-with-Semantic-and-Geometric-Aware-Gaussian-Splatting"><a href="#OccGS-Zero-shot-3D-Occupancy-Reconstruction-with-Semantic-and-Geometric-Aware-Gaussian-Splatting" class="headerlink" title="OccGS: Zero-shot 3D Occupancy Reconstruction with Semantic and   Geometric-Aware Gaussian Splatting"></a>OccGS: Zero-shot 3D Occupancy Reconstruction with Semantic and   Geometric-Aware Gaussian Splatting</h2><p><strong>Authors:Xiaoyu Zhou, Jingqi Wang, Yongtao Wang, Yufei Wei, Nan Dong, Ming-Hsuan Yang</strong></p>
<p>Obtaining semantic 3D occupancy from raw sensor data without manual annotations remains an essential yet challenging task. While prior works have approached this as a perception prediction problem, we formulate it as scene-aware 3D occupancy reconstruction with geometry and semantics. In this work, we propose OccGS, a novel 3D Occupancy reconstruction framework utilizing Semantic and Geometric-Aware Gaussian Splatting in a zero-shot manner. Leveraging semantics extracted from vision-language models and geometry guided by LiDAR points, OccGS constructs Semantic and Geometric-Aware Gaussians from raw multisensor data. We also develop a cumulative Gaussian-to-3D voxel splatting method for reconstructing occupancy from the Gaussians. OccGS performs favorably against self-supervised methods in occupancy prediction, achieving comparable performance to fully supervised approaches and achieving state-of-the-art performance on zero-shot semantic 3D occupancy estimation. </p>
<blockquote>
<p>从原始传感器数据获取语义3D占用信息，无需手动注释，仍然是一项重要而具有挑战性的任务。尽管以前的工作将其视为感知预测问题，但我们将其制定为场景感知的3D占用重建问题，涉及几何和语义。在这项工作中，我们提出OccGS，这是一种利用语义和几何感知的高斯点散作为零样本方式的三维占用重建框架。借助从视觉语言模型中提取的语义信息和激光雷达点引导的几何信息，OccGS从原始多传感器数据中构建语义和几何感知的高斯分布。我们还开发了一种累积高斯到三维体素点散方法，用于从高斯分布重建占用情况。在占用预测方面，OccGS的表现优于自监督方法，其性能与全监督方法相当，并在零样本语义3D占用估计方面达到了最先进的性能。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.04981v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>本文提出了一项将语义和几何感知结合的新型三维占用重建框架OccGS，采用零样本方式从原始传感器数据中获取语义三维占用信息。利用视觉语言模型提取的语义信息和激光雷达点引导的几何信息，构建语义和几何感知高斯映射，再通过累积高斯到三维体素点迹法重建占用情况。相较于自监督方法，OccGS在占用预测上表现优越，甚至在零样本语义三维占用估计上达到了最先进的性能。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>将语义三维占用重建任务从单纯的感知预测问题转化为场景感知问题，强调几何和语义的结合。</li>
<li>提出了新型框架OccGS，能够利用原始多传感器数据中的语义和几何信息。</li>
<li>采用零样本方式处理数据，无需手动标注。</li>
<li>利用视觉语言模型提取语义信息，并引入激光雷达点以指导几何信息的利用。</li>
<li>通过构建语义和几何感知高斯映射，提高了占用预测的精度。</li>
<li>采用累积高斯到三维体素点迹法重建占用情况，这一方法具有创新性。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.04981">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-0555e119e5e68089acc842f310b655a2.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-462fc0ea2bca106f7ec397dbcb9afdb0.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-2723215b70891e752419f735d02fda55.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e5d60175efa997bd1444659692b24258.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="PoI-Pixel-of-Interest-for-Novel-View-Synthesis-Assisted-Scene-Coordinate-Regression"><a href="#PoI-Pixel-of-Interest-for-Novel-View-Synthesis-Assisted-Scene-Coordinate-Regression" class="headerlink" title="PoI: Pixel of Interest for Novel View Synthesis Assisted Scene   Coordinate Regression"></a>PoI: Pixel of Interest for Novel View Synthesis Assisted Scene   Coordinate Regression</h2><p><strong>Authors:Feifei Li, Qi Song, Chi Zhang, Hui Shuai, Rui Huang</strong></p>
<p>The task of estimating camera poses can be enhanced through novel view synthesis techniques such as NeRF and Gaussian Splatting to increase the diversity and extension of training data. However, these techniques often produce rendered images with issues like blurring and ghosting, which compromise their reliability. These issues become particularly pronounced for Scene Coordinate Regression (SCR) methods, which estimate 3D coordinates at the pixel level. To mitigate the problems associated with unreliable rendered images, we introduce a novel filtering approach, which selectively extracts well-rendered pixels while discarding the inferior ones. This filter simultaneously measures the SCR model’s real-time reprojection loss and gradient during training. Building on this filtering technique, we also develop a new strategy to improve scene coordinate regression using sparse inputs, drawing on successful applications of sparse input techniques in novel view synthesis. Our experimental results validate the effectiveness of our method, demonstrating state-of-the-art performance on indoor and outdoor datasets. </p>
<blockquote>
<p>通过NeRF和Gaussian Splatting等新型视图合成技术，可以增强对相机姿态的估计任务，从而提高训练数据的多样性和扩展性。然而，这些技术往往产生的渲染图像存在模糊和重影等问题，从而影响了它们的可靠性。这些问题在场景坐标回归（SCR）方法中尤为突出，这些方法估计像素级别的3D坐标。为了缓解与不可靠的渲染图像相关的问题，我们引入了一种新型过滤方法，该方法能够有选择地提取渲染良好的像素，同时丢弃质量较差的像素。该过滤器在训练过程中实时测量SCR模型的再投影损失和梯度。基于这种过滤技术，我们还开发了一种利用稀疏输入改进场景坐标回归的新策略，这借鉴了稀疏输入技术在新型视图合成中的成功应用。我们的实验结果验证了该方法的有效性，在室内和室外数据集上均表现出卓越的性能。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.04843v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>该文本探讨了如何通过新技术改进相机姿态估计任务，例如NeRF和高斯贴片技术可增加训练数据的多样性和扩展性。然而，这些技术生成的渲染图像常常存在模糊和重影等问题，影响可靠性。对于像素级估计的场景坐标回归（SCR）方法，这些问题尤为突出。为缓解不可靠渲染图像带来的问题，研究引入了新型过滤方法，能够选择性提取渲染良好的像素并舍弃质量较差的像素。该过滤器同时测量SCR模型的实时重投影损失和训练过程中的梯度。基于过滤技术，研究还开发出一种利用稀疏输入改进场景坐标回归的新策略，该方法借鉴了稀疏输入在新型视图合成中的成功应用。实验证明该方法的先进性，在室内和室外数据集上表现出最佳性能。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>新视图合成技术如NeRF和高斯贴片能提高相机姿态估计任务的多样性和扩展性。</li>
<li>渲染图像常常存在模糊和重影问题，影响可靠性。</li>
<li>为解决上述问题，研究引入了新型过滤方法，选择性提取良好渲染的像素并舍弃质量差的像素。</li>
<li>该过滤技术同时测量场景坐标回归模型的实时重投影损失和训练过程中的梯度。</li>
<li>利用上述过滤技术，发展出使用稀疏输入改进场景坐标回归的新策略。</li>
<li>实验证明该方法的先进性，室内和室外数据集上表现最佳性能。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.04843">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pica.zhimg.com/v2-80d0d5daf6af8982d8f4502a500cf2f2.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-160b55184ecaabeb25376e2f6992bc41.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-0932b33274244d439b130360e28b13b3.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-5f27615cf0f687e2df11510c5931d6d2.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-5f95e3c3be491facd663a5ffcbb97e08.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="SC-OmniGS-Self-Calibrating-Omnidirectional-Gaussian-Splatting"><a href="#SC-OmniGS-Self-Calibrating-Omnidirectional-Gaussian-Splatting" class="headerlink" title="SC-OmniGS: Self-Calibrating Omnidirectional Gaussian Splatting"></a>SC-OmniGS: Self-Calibrating Omnidirectional Gaussian Splatting</h2><p><strong>Authors:Huajian Huang, Yingshu Chen, Longwei Li, Hui Cheng, Tristan Braud, Yajie Zhao, Sai-Kit Yeung</strong></p>
<p>360-degree cameras streamline data collection for radiance field 3D reconstruction by capturing comprehensive scene data. However, traditional radiance field methods do not address the specific challenges inherent to 360-degree images. We present SC-OmniGS, a novel self-calibrating omnidirectional Gaussian splatting system for fast and accurate omnidirectional radiance field reconstruction using 360-degree images. Rather than converting 360-degree images to cube maps and performing perspective image calibration, we treat 360-degree images as a whole sphere and derive a mathematical framework that enables direct omnidirectional camera pose calibration accompanied by 3D Gaussians optimization. Furthermore, we introduce a differentiable omnidirectional camera model in order to rectify the distortion of real-world data for performance enhancement. Overall, the omnidirectional camera intrinsic model, extrinsic poses, and 3D Gaussians are jointly optimized by minimizing weighted spherical photometric loss. Extensive experiments have demonstrated that our proposed SC-OmniGS is able to recover a high-quality radiance field from noisy camera poses or even no pose prior in challenging scenarios characterized by wide baselines and non-object-centric configurations. The noticeable performance gain in the real-world dataset captured by consumer-grade omnidirectional cameras verifies the effectiveness of our general omnidirectional camera model in reducing the distortion of 360-degree images. </p>
<blockquote>
<p>360度相机通过捕捉全面的场景数据，简化了辐射场3D重建的数据收集过程。然而，传统的辐射场方法并没有解决360度图像所特有的挑战。我们提出了SC-OmniGS，这是一种新型的自标定全向高斯喷溅系统，利用360度图像快速准确地重建全向辐射场。我们并不将360度图像转换为立方体地图并进行透视图像校准，而是将360度图像视为整个球体，并推导出一个数学框架，该框架能够实现直接的全向相机姿态校准，以及通过3D高斯进行优化。此外，我们引入了一个可区分的全向相机模型，以矫正真实世界数据的失真，从而提高性能。总体而言，通过最小化加权球面光度损失，对全向相机的内在模型、外在姿态和3D高斯进行联合优化。大量实验表明，我们提出的SC-OmniGS能够从具有挑战性的场景中恢复高质量辐射场，这些场景的特征是基线宽、非以对象为中心的配置、带有噪声的相机姿态，甚至在没有任何姿态先验的情况下也能如此。由消费级全向相机捕获的真实世界数据集的性能提升显著，这验证了我们的通用全向相机模型在减少360度图像失真方面的有效性。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.04734v1">PDF</a> Accepted to ICLR 2025, Project Page:   <a target="_blank" rel="noopener" href="http://www.chenyingshu.com/sc-omnigs/">http://www.chenyingshu.com/sc-omnigs/</a></p>
<p><strong>Summary</strong></p>
<p>本文介绍了SC-OmniGS系统，该系统采用全景相机技术，通过优化全景相机模型实现对辐射场的重建。该方法无需将全景图像转换为立方体地图并进行透视图像校准，而是直接将全景图像视为整体球体，并采用数学模型直接进行全景相机姿态校准及优化三维高斯球体形态。另外还引入了可区分的全景相机模型以减少实际数据中的畸变并提升性能表现。系统通过对全景相机内在模型、外在姿态和三维高斯球体的联合优化，达到降低辐射场重建的难度和提高图像质量的目的。</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>全景相机技术用于简化辐射场重建的数据收集过程。</li>
<li>SC-OmniGS系统是一种新型的自校准全景高斯球状系统，适用于快速准确的辐射场重建。</li>
<li>该方法无需将全景图像转换为立方体地图进行透视图像校准，而是直接将全景图像视为整体球体进行数学处理。</li>
<li>系统采用数学模型直接进行全景相机姿态校准和三维高斯球体优化。</li>
<li>系统引入可区分的全景相机模型，以提高性能表现并减少实际数据中的畸变。</li>
<li>通过联合优化全景相机的内在模型、外在姿态和三维高斯球体，系统可有效提高辐射场重建的质量。</li>
<li>实验证明SC-OmniGS在具有挑战性的场景中，如噪声相机姿态或没有姿态先验的情况下，仍能恢复高质量辐射场。</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.04734">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-9e6a219f18ca768b68c22a24b5855b55.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-a8f35296224377603a248f85269979e8.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-34697135c04e95141e7a6b66b0a2df59.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-79f527c30d2fc14e625a5c17907c5489.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="High-Speed-Dynamic-3D-Imaging-with-Sensor-Fusion-Splatting"><a href="#High-Speed-Dynamic-3D-Imaging-with-Sensor-Fusion-Splatting" class="headerlink" title="High-Speed Dynamic 3D Imaging with Sensor Fusion Splatting"></a>High-Speed Dynamic 3D Imaging with Sensor Fusion Splatting</h2><p><strong>Authors:Zihao Zou, Ziyuan Qu, Xi Peng, Vivek Boominathan, Adithya Pediredla, Praneeth Chakravarthula</strong></p>
<p>Capturing and reconstructing high-speed dynamic 3D scenes has numerous applications in computer graphics, vision, and interdisciplinary fields such as robotics, aerodynamics, and evolutionary biology. However, achieving this using a single imaging modality remains challenging. For instance, traditional RGB cameras suffer from low frame rates, limited exposure times, and narrow baselines. To address this, we propose a novel sensor fusion approach using Gaussian splatting, which combines RGB, depth, and event cameras to capture and reconstruct deforming scenes at high speeds. The key insight of our method lies in leveraging the complementary strengths of these imaging modalities: RGB cameras capture detailed color information, event cameras record rapid scene changes with microsecond resolution, and depth cameras provide 3D scene geometry. To unify the underlying scene representation across these modalities, we represent the scene using deformable 3D Gaussians. To handle rapid scene movements, we jointly optimize the 3D Gaussian parameters and their temporal deformation fields by integrating data from all three sensor modalities. This fusion enables efficient, high-quality imaging of fast and complex scenes, even under challenging conditions such as low light, narrow baselines, or rapid motion. Experiments on synthetic and real datasets captured with our prototype sensor fusion setup demonstrate that our method significantly outperforms state-of-the-art techniques, achieving noticeable improvements in both rendering fidelity and structural accuracy. </p>
<blockquote>
<p>捕捉和重建高速动态三维场景在计算机图形学、计算机视觉以及跨学科领域（如机器人技术、空气动力学和进化生物学）具有众多应用。然而，使用单一成像模式实现这一目标仍然具有挑战性。例如，传统RGB相机存在帧率较低、曝光时间有限和基线较窄等问题。为了解决这一问题，我们提出了一种新颖的传感器融合方法，采用高斯喷溅技术，结合RGB、深度和事件相机，以高速捕捉和重建变形场景。我们的方法的关键在于利用这些成像模式的互补优势：RGB相机捕捉详细的颜色信息，事件相机以微秒分辨率记录场景快速变化，深度相机提供三维场景几何结构。为了统一这些模式下的场景表示，我们使用可变形三维高斯来表示场景。为了处理场景的快速运动，我们通过整合所有三种传感器模式的数据，联合优化三维高斯参数及其时间变形场。这种融合即使在具有挑战性的条件下（例如低光、窄基线或快速运动）也能实现高效、高质量的快照和复杂场景的成像。在我们原型传感器融合设置上进行的合成和真实数据集的实验表明，我们的方法显著优于最先进的技术，在渲染保真度和结构准确性方面都取得了明显的改进。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.04630v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>本文提出一种融合RGB、深度及事件相机的新型传感器融合方法，采用高斯平铺技术捕捉和重建高速动态3D场景。该方法利用各成像模式的长处，通过优化3D高斯参数及其时间变形场，实现高效、高质量的快照和复杂场景的成像，即使在低光、窄基线或快速运动等挑战条件下也表现优异。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>传感器融合方法结合了RGB、深度及事件相机，以捕捉和重建高速动态3D场景。</li>
<li>方法的关键洞察在于利用各成像模式（RGB、事件和深度相机）的互补优势。</li>
<li>通过使用变形3D高斯来统一不同模式的场景表示。</li>
<li>联合优化3D高斯参数及其时间变形场，以处理快速场景移动。</li>
<li>该融合方法在合成和真实数据集上的实验表现显著优于现有技术。</li>
<li>即使在挑战条件下（如低光、窄基线或快速运动），该方法也能实现高质量成像。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.04630">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pica.zhimg.com/v2-88e25ab1b8778862fefae5cdada43fea.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-290cd9398f2741561dcdab165d749a29.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-6be7e678bb31c4e2484fc83ed19b04c3.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-67eb9e4203c88529a546559661924d51.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="Drag-Your-Gaussian-Effective-Drag-Based-Editing-with-Score-Distillation-for-3D-Gaussian-Splatting"><a href="#Drag-Your-Gaussian-Effective-Drag-Based-Editing-with-Score-Distillation-for-3D-Gaussian-Splatting" class="headerlink" title="Drag Your Gaussian: Effective Drag-Based Editing with Score Distillation   for 3D Gaussian Splatting"></a>Drag Your Gaussian: Effective Drag-Based Editing with Score Distillation   for 3D Gaussian Splatting</h2><p><strong>Authors:Yansong Qu, Dian Chen, Xinyang Li, Xiaofan Li, Shengchuan Zhang, Liujuan Cao, Rongrong Ji</strong></p>
<p>Recent advancements in 3D scene editing have been propelled by the rapid development of generative models. Existing methods typically utilize generative models to perform text-guided editing on 3D representations, such as 3D Gaussian Splatting (3DGS). However, these methods are often limited to texture modifications and fail when addressing geometric changes, such as editing a character’s head to turn around. Moreover, such methods lack accurate control over the spatial position of editing results, as language struggles to precisely describe the extent of edits. To overcome these limitations, we introduce DYG, an effective 3D drag-based editing method for 3D Gaussian Splatting. It enables users to conveniently specify the desired editing region and the desired dragging direction through the input of 3D masks and pairs of control points, thereby enabling precise control over the extent of editing. DYG integrates the strengths of the implicit triplane representation to establish the geometric scaffold of the editing results, effectively overcoming suboptimal editing outcomes caused by the sparsity of 3DGS in the desired editing regions. Additionally, we incorporate a drag-based Latent Diffusion Model into our method through the proposed Drag-SDS loss function, enabling flexible, multi-view consistent, and fine-grained editing. Extensive experiments demonstrate that DYG conducts effective drag-based editing guided by control point prompts, surpassing other baselines in terms of editing effect and quality, both qualitatively and quantitatively. Visit our project page at <a target="_blank" rel="noopener" href="https://quyans.github.io/Drag-Your-Gaussian">https://quyans.github.io/Drag-Your-Gaussian</a>. </p>
<blockquote>
<p>近期三维场景编辑的进展得益于生成模型的快速发展。现有方法通常利用生成模型对三维表示进行文本引导编辑，例如三维高斯平铺（3DGS）。然而，这些方法通常仅限于纹理修改，在几何变化方面表现不佳，例如编辑角色头部以进行旋转。此外，这些方法对编辑结果的空间位置控制不准确，因为语言难以精确描述编辑的程度。为了克服这些限制，我们引入了DYG，这是一种针对三维高斯平铺的有效基于拖拽的三维编辑方法。它使用户可以通过输入三维掩码和控制点对来方便地指定所需的编辑区域和拖拽方向，从而实现对编辑程度的精确控制。DYG结合了隐式三平面表示的优势，建立编辑结果的三维骨架，有效克服了所需编辑区域内3DGS稀疏所导致的次优编辑结果。此外，我们通过提出的Drag-SDS损失函数，将基于拖拽的潜在扩散模型融入我们的方法，实现了灵活、多视角一致、精细的编辑。大量实验表明，DYG通过控制点提示进行有效的基于拖拽的编辑，在编辑效果和品质方面都超越了其他基线方法。请访问我们的项目页面：<a target="_blank" rel="noopener" href="https://quyans.github.io/Drag-Your-Gaussian%E6%BB%A4%E6%9B%B4%E5%A4%9A%E4%BF%A1%E6%81%AF%E3%80%82">https://quyans.github.io/Drag-Your-Gaussian了解更多信息。</a></p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.18672v2">PDF</a> Visit our project page at <a target="_blank" rel="noopener" href="https://quyans.github.io/Drag-Your-Gaussian">https://quyans.github.io/Drag-Your-Gaussian</a></p>
<p><strong>Summary</strong></p>
<p>本文介绍了基于3D高斯绘制（3DGS）的3D拖拽编辑方法DYG。DYG克服了现有生成模型在3D场景编辑中的局限性，实现了对3D对象几何结构的精准编辑。通过引入3D掩膜和控制点对，DYG为用户提供了便捷的编辑区域和拖拽方向指定方式，同时结合隐式triplane表示和Drag-SDS损失函数，实现了灵活、多视角一致、精细的编辑效果。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>3D场景编辑技术受到生成模型快速发展的推动。</li>
<li>现有方法主要利用生成模型进行文本引导的3D表示编辑，但局限于纹理修改，难以进行几何变化。</li>
<li>DYG方法引入3D掩膜和控制点对，方便用户指定编辑区域和拖拽方向。</li>
<li>DYG结合隐式triplane表示，建立编辑结果几何骨架，有效克服3DGS在编辑区域的稀疏性问题。</li>
<li>引入基于拖拽的潜在扩散模型，通过Drag-SDS损失函数，实现灵活、多视角一致、精细的编辑。</li>
<li>DYG在编辑效果和品质上超越其他基线方法。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.18672">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-e9edf1fcce47705f26ddebeb7fa20d22.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-32ff45e272d6e24c63eeb2e76f5ba032.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-8417e6fbf6e3b5bf38b6c11633406bd2.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-4c3cf313e5a992e9cedcf7def299ceaa.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-8ab2954a178f94aad6981a71eb7d85a6.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="HAC-Towards-100X-Compression-of-3D-Gaussian-Splatting"><a href="#HAC-Towards-100X-Compression-of-3D-Gaussian-Splatting" class="headerlink" title="HAC++: Towards 100X Compression of 3D Gaussian Splatting"></a>HAC++: Towards 100X Compression of 3D Gaussian Splatting</h2><p><strong>Authors:Yihang Chen, Qianyi Wu, Weiyao Lin, Mehrtash Harandi, Jianfei Cai</strong></p>
<p>3D Gaussian Splatting (3DGS) has emerged as a promising framework for novel view synthesis, boasting rapid rendering speed with high fidelity. However, the substantial Gaussians and their associated attributes necessitate effective compression techniques. Nevertheless, the sparse and unorganized nature of the point cloud of Gaussians (or anchors in our paper) presents challenges for compression. To achieve a compact size, we propose HAC++, which leverages the relationships between unorganized anchors and a structured hash grid, utilizing their mutual information for context modeling. Additionally, HAC++ captures intra-anchor contextual relationships to further enhance compression performance. To facilitate entropy coding, we utilize Gaussian distributions to precisely estimate the probability of each quantized attribute, where an adaptive quantization module is proposed to enable high-precision quantization of these attributes for improved fidelity restoration. Moreover, we incorporate an adaptive masking strategy to eliminate invalid Gaussians and anchors. Overall, HAC++ achieves a remarkable size reduction of over 100X compared to vanilla 3DGS when averaged on all datasets, while simultaneously improving fidelity. It also delivers more than 20X size reduction compared to Scaffold-GS. Our code is available at <a target="_blank" rel="noopener" href="https://github.com/YihangChen-ee/HAC-plus">https://github.com/YihangChen-ee/HAC-plus</a>. </p>
<blockquote>
<p>3D高斯映射（3DGS）已成为新型视角合成的一种有前途的框架，具有快速渲染和高保真度的特点。然而，大量的高斯及其相关属性需要进行有效的压缩技术处理。尽管如此，高斯点的稀疏性和非组织性（或我们论文中的锚点）给压缩带来了挑战。为了实现紧凑的大小，我们提出了HAC++，它利用非组织锚点之间的关系和一个结构化的哈希网格，利用它们的互信息来进行上下文建模。此外，HAC++捕捉了锚点内的上下文关系，以进一步增强压缩性能。为了促进熵编码，我们利用高斯分布来精确估计每个量化属性的概率，并提出了一种自适应量化模块，实现对这些属性的高精度量化，以提高保真度的恢复。此外，我们采用自适应掩码策略来消除无效的高斯和锚点。总的来说，HAC++在所有数据集上平均相比基础3DGS实现了超过100倍的大小缩减，同时提高了保真度。与Scaffold-GS相比，它实现了超过20倍的大小缩减。我们的代码可在<a target="_blank" rel="noopener" href="https://github.com/YihangChen-ee/HAC-plus%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/YihangChen-ee/HAC-plus找到。</a></p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.12255v3">PDF</a> Project Page: <a target="_blank" rel="noopener" href="https://yihangchen-ee.github.io/project_hac++/">https://yihangchen-ee.github.io/project_hac++/</a> Code:   <a target="_blank" rel="noopener" href="https://github.com/YihangChen-ee/HAC-plus">https://github.com/YihangChen-ee/HAC-plus</a>. This paper is a journal extension   of HAC at arXiv:2403.14530 (ECCV 2024)</p>
<p><strong>Summary</strong></p>
<p>本文介绍了基于三维高斯分裂（3DGS）技术的视图合成方法，该方法具有快速渲染和高保真度的特点。针对高斯及其属性的压缩问题，提出了利用点云间关系的HAC++压缩技术，该技术结合了结构化哈希网格与锚点间的互信息关系进行上下文建模，同时优化了量化属性概率估计的熵编码过程。此外，还引入了自适应掩码策略以消除无效的高斯和锚点。相较于传统方法，HAC++实现了超过百倍的数据压缩率提升，同时保证了良好的保真度恢复效果。</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>3DGS技术在视图合成领域展现出快速渲染和高保真度的优势。</li>
<li>高斯及其属性的压缩是3DGS技术中的关键挑战。</li>
<li>HAC++技术利用点云间关系进行上下文建模，结合了结构化哈希网格与锚点间的互信息关系。</li>
<li>HAC++技术优化了量化属性概率估计的熵编码过程。</li>
<li>自适应掩码策略用于消除无效的高斯和锚点。</li>
<li>HAC++相较于传统方法实现了超过百倍的数据压缩率提升。</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.12255">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pica.zhimg.com/v2-3659d37f25fdbd0856958a6df31bf3a8.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-9eba4d767f2e2d1502a447d6240e2c43.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-e69e293f6cc07acf566d6e20d321a6b9.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-0db7d13986e4d7cfd9c70f70be0136ce.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-1a1261f37839c32f4bcc44800933edd0.jpg" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        文章作者:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        文章链接:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-02-11/3DGS/">https://kedreamix.github.io/Talk2Paper/Paper/2025-02-11/3DGS/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        版权声明:
                    </i>
                </span>
                <span class="reprint-info">
                    本博客所有文章除特別声明外，均采用
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    许可协议。转载请注明来源
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/3DGS/">
                                    <span class="chip bg-color">3DGS</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;上一篇</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-02-11/NeRF/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-160b55184ecaabeb25376e2f6992bc41.jpg" class="responsive-img" alt="NeRF">
                        
                        <span class="card-title">NeRF</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            NeRF 方向最新论文已更新，请持续关注 Update in 2025-02-11  PoI Pixel of Interest for Novel View Synthesis Assisted Scene   Coordinate Regression
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-02-11
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/NeRF/" class="post-category">
                                    NeRF
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/NeRF/">
                        <span class="chip bg-color">NeRF</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-02-11/Speech/">
                    <div class="card-image">
                        
                        <img src="https://pica.zhimg.com/v2-f26ab90b15d4bb9037e21d3026fb3d91.jpg" class="responsive-img" alt="Speech">
                        
                        <span class="card-title">Speech</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Speech 方向最新论文已更新，请持续关注 Update in 2025-02-11  Evaluating Standard and Dialectal Frisian ASR Multilingual Fine-tuning   and Language Identification for Improved Low-resource Performance
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-02-11
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Speech/" class="post-category">
                                    Speech
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Speech/">
                        <span class="chip bg-color">Speech</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- 代码语言 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span
                        class="white-color">12041.4k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- 运行天数提醒. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // 区分是否有年份.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = '本站已运行 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                daysTip = '本站已運行 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = '本站已运行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = '本站已運行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="关注我的知乎: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">知</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- 白天和黑夜主题 -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // 只在桌面版网页启用特效
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- 雪花特效 -->
    

    <!-- 鼠标星星特效 -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--腾讯兔小巢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- 动态标签 -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Σ(っ °Д °;)っ诶，页面崩溃了嘛？", clearTimeout(st)) : (document.title = "φ(゜▽゜*)♪咦，又好了！", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
