<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Diffusion Models">
    <meta name="description" content="Diffusion Models æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-05-02  HoloTime Taming Video Diffusion Models for Panoramic 4D Scene   Generation">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>Diffusion Models | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://picx.zhimg.com/v2-e403b5782e7295d29c441e83aa07c4aa.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Diffusion Models</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/Diffusion-Models/">
                                <span class="chip bg-color">Diffusion Models</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/Diffusion-Models/" class="post-category">
                                Diffusion Models
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-05-02
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-05-25
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    12.4k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    50 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-05-02-æ›´æ–°"><a href="#2025-05-02-æ›´æ–°" class="headerlink" title="2025-05-02 æ›´æ–°"></a>2025-05-02 æ›´æ–°</h1><h2 id="HoloTime-Taming-Video-Diffusion-Models-for-Panoramic-4D-Scene-Generation"><a href="#HoloTime-Taming-Video-Diffusion-Models-for-Panoramic-4D-Scene-Generation" class="headerlink" title="HoloTime: Taming Video Diffusion Models for Panoramic 4D Scene   Generation"></a>HoloTime: Taming Video Diffusion Models for Panoramic 4D Scene   Generation</h2><p><strong>Authors:Haiyang Zhou, Wangbo Yu, Jiawen Guan, Xinhua Cheng, Yonghong Tian, Li Yuan</strong></p>
<p>The rapid advancement of diffusion models holds the promise of revolutionizing the application of VR and AR technologies, which typically require scene-level 4D assets for user experience. Nonetheless, existing diffusion models predominantly concentrate on modeling static 3D scenes or object-level dynamics, constraining their capacity to provide truly immersive experiences. To address this issue, we propose HoloTime, a framework that integrates video diffusion models to generate panoramic videos from a single prompt or reference image, along with a 360-degree 4D scene reconstruction method that seamlessly transforms the generated panoramic video into 4D assets, enabling a fully immersive 4D experience for users. Specifically, to tame video diffusion models for generating high-fidelity panoramic videos, we introduce the 360World dataset, the first comprehensive collection of panoramic videos suitable for downstream 4D scene reconstruction tasks. With this curated dataset, we propose Panoramic Animator, a two-stage image-to-video diffusion model that can convert panoramic images into high-quality panoramic videos. Following this, we present Panoramic Space-Time Reconstruction, which leverages a space-time depth estimation method to transform the generated panoramic videos into 4D point clouds, enabling the optimization of a holistic 4D Gaussian Splatting representation to reconstruct spatially and temporally consistent 4D scenes. To validate the efficacy of our method, we conducted a comparative analysis with existing approaches, revealing its superiority in both panoramic video generation and 4D scene reconstruction. This demonstrates our methodâ€™s capability to create more engaging and realistic immersive environments, thereby enhancing user experiences in VR and AR applications. </p>
<blockquote>
<p>æ‰©æ•£æ¨¡å‹çš„å¿«é€Ÿå‘å±•æœ‰æœ›å½»åº•æ”¹å˜VRå’ŒARæŠ€æœ¯çš„åº”ç”¨å‰æ™¯ï¼Œè¿™äº›æŠ€æœ¯é€šå¸¸éœ€è¦åœºæ™¯çº§çš„å››ç»´èµ„äº§æ¥æå‡ç”¨æˆ·ä½“éªŒã€‚ç„¶è€Œï¼Œç°æœ‰çš„æ‰©æ•£æ¨¡å‹ä¸»è¦é›†ä¸­åœ¨é™æ€ä¸‰ç»´åœºæ™¯çš„å»ºæ¨¡æˆ–å¯¹è±¡çº§åˆ«çš„åŠ¨æ€å»ºæ¨¡ä¸Šï¼Œè¿™é™åˆ¶äº†å®ƒä»¬æä¾›çœŸæ­£æ²‰æµ¸å¼ä½“éªŒçš„èƒ½åŠ›ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†HoloTimeæ¡†æ¶ï¼Œå®ƒç»“åˆäº†è§†é¢‘æ‰©æ•£æ¨¡å‹æ¥ç”Ÿæˆå…¨æ™¯è§†é¢‘ï¼Œä»ä¸€ä¸ªå•ä¸€çš„æç¤ºæˆ–å‚è€ƒå›¾åƒå¼€å§‹ï¼Œå¹¶ä½¿ç”¨ä¸€ç§å…¨æ™¯çš„4Dåœºæ™¯é‡å»ºæ–¹æ³•ï¼Œå°†ç”Ÿæˆçš„å…¨æ™¯è§†é¢‘æ— ç¼åœ°è½¬åŒ–ä¸ºå››ç»´èµ„äº§ï¼Œä¸ºç”¨æˆ·å¸¦æ¥å…¨é¢çš„æ²‰æµ¸å¼ä½“éªŒã€‚å…·ä½“æ¥è¯´ï¼Œä¸ºäº†é©¾é©­è§†é¢‘æ‰©æ•£æ¨¡å‹ä»¥ç”Ÿæˆé«˜è´¨é‡å…¨æ™¯è§†é¢‘ï¼Œæˆ‘ä»¬å¼•å…¥äº†é¦–ä¸ªå…¨æ™¯è§†é¢‘æ•°æ®é›†360Worldæ•°æ®é›†ï¼Œé€‚åˆç”¨äºä¸‹æ¸¸å››ç»´åœºæ™¯é‡å»ºä»»åŠ¡ã€‚æœ‰äº†è¿™ä¸ªå®šåˆ¶çš„æ•°æ®é›†ï¼Œæˆ‘ä»¬æå‡ºäº†å…¨æ™¯åŠ¨ç”»ç”Ÿæˆå™¨ï¼ˆPanoramic Animatorï¼‰ï¼Œä¸€ä¸ªä¸¤é˜¶æ®µçš„å›¾åƒåˆ°è§†é¢‘çš„æ‰©æ•£æ¨¡å‹ï¼Œèƒ½å¤Ÿå°†å…¨æ™¯å›¾åƒè½¬æ¢ä¸ºé«˜è´¨é‡å…¨æ™¯è§†é¢‘ã€‚éšåï¼Œæˆ‘ä»¬æå‡ºäº†å…¨æ™¯æ—¶ç©ºé‡å»ºï¼ˆPanoramic Space-Time Reconstructionï¼‰ï¼Œåˆ©ç”¨æ—¶ç©ºæ·±åº¦ä¼°è®¡æ–¹æ³•å°†ç”Ÿæˆçš„å…¨æ™¯è§†é¢‘è½¬åŒ–ä¸ºå››ç»´ç‚¹äº‘ï¼Œå¹¶ä¼˜åŒ–æ•´ä½“çš„å››ç»´é«˜æ–¯æº…å°„è¡¨ç¤ºæ³•æ¥é‡å»ºç©ºé—´å’Œæ—¶é—´ä¸Šè¿è´¯çš„å››ç»´åœºæ™¯ã€‚ä¸ºäº†éªŒè¯æˆ‘ä»¬æ–¹æ³•çš„æœ‰æ•ˆæ€§ï¼Œæˆ‘ä»¬ä¸ç°æœ‰æ–¹æ³•è¿›è¡Œäº†æ¯”è¾ƒåˆ†æï¼Œç»“æœæ˜¾ç¤ºæˆ‘ä»¬çš„æ–¹æ³•åœ¨å…¨æ™¯è§†é¢‘ç”Ÿæˆå’Œå››ç»´åœºæ™¯é‡å»ºæ–¹é¢éƒ½è¡¨ç°å‡ºå“è¶Šçš„æ€§èƒ½ã€‚è¿™è¡¨æ˜æˆ‘ä»¬çš„æ–¹æ³•èƒ½å¤Ÿåˆ›å»ºæ›´å…·å¸å¼•åŠ›å’Œæ›´é€¼çœŸçš„æ²‰æµ¸å¼ç¯å¢ƒï¼Œä»è€Œå¢å¼ºVRå’ŒARåº”ç”¨ç¨‹åºä¸­çš„ç”¨æˆ·ä½“éªŒã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.21650v1">PDF</a> Project homepage: <a target="_blank" rel="noopener" href="https://zhouhyocean.github.io/holotime/">https://zhouhyocean.github.io/holotime/</a></p>
<p><strong>Summary</strong></p>
<p>æ‰©æ•£æ¨¡å‹çš„å¿«é€Ÿå‘å±•ä¸ºVRå’ŒARæŠ€æœ¯çš„å¹¿æ³›åº”ç”¨å¸¦æ¥äº†é©å‘½æ€§çš„å¸Œæœ›ã€‚ç°æœ‰çš„æ‰©æ•£æ¨¡å‹ä¸»è¦å…³æ³¨é™æ€ä¸‰ç»´åœºæ™¯æˆ–å¯¹è±¡çº§åˆ«çš„åŠ¨æ€å»ºæ¨¡ï¼Œéš¾ä»¥æä¾›çœŸæ­£çš„æ²‰æµ¸å¼ä½“éªŒã€‚æœ¬æ–‡æå‡ºHoloTimeæ¡†æ¶ï¼Œé€šè¿‡æ•´åˆè§†é¢‘æ‰©æ•£æ¨¡å‹ç”Ÿæˆå…¨æ™¯è§†é¢‘ï¼Œå¹¶é‡‡ç”¨360åº¦å››ç»´åœºæ™¯é‡å»ºæ–¹æ³•ï¼Œå°†ç”Ÿæˆçš„å…¨æ™¯è§†é¢‘æ— ç¼è½¬æ¢ä¸ºå››ç»´èµ„äº§ï¼Œä¸ºç”¨æˆ·å¸¦æ¥å…¨æ–°çš„æ²‰æµ¸å¼å››ç»´ä½“éªŒã€‚ä¸ºäº†ç”Ÿæˆé«˜è´¨é‡çš„å…¨æ™¯è§†é¢‘ï¼Œå¼•å…¥äº†360Worldæ•°æ®é›†ï¼Œå¹¶æå‡ºå…¨æ™¯åŠ¨ç”»å¸ˆï¼ˆPanoramic Animatorï¼‰æ¨¡å‹ã€‚æ¥ç€ä½¿ç”¨æ—¶ç©ºé‡å»ºæŠ€æœ¯å°†å…¨æ™¯è§†é¢‘è½¬åŒ–ä¸ºå››ç»´ç‚¹äº‘ï¼Œæœ€ç»ˆä¼˜åŒ–æ•´ä½“å››ç»´é«˜æ–¯æç»˜ï¼ˆGaussian Splattingï¼‰æ¥å®ç°ç©ºé—´å’Œæ—¶é—´ä¸Šä¸€è‡´çš„åœºæ™¯é‡å»ºã€‚æœ¬ç ”ç©¶éªŒè¯äº†æ‰€æå‡ºæ–¹æ³•åœ¨å…¨æ™¯è§†é¢‘ç”Ÿæˆå’Œå››ç»´åœºæ™¯é‡å»ºæ–¹é¢çš„ä¼˜åŠ¿ï¼Œå¢å¼ºäº†VRå’ŒARåº”ç”¨çš„ç”¨æˆ·ä½“éªŒã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æ‰©æ•£æ¨¡å‹çš„è¿›æ­¥ä¸ºVRå’ŒARæŠ€æœ¯çš„æ²‰æµ¸å¼ä½“éªŒæä¾›äº†å·¨å¤§çš„æ½œåŠ›å’Œæœºé‡ã€‚</li>
<li>å½“å‰æ‰©æ•£æ¨¡å‹ä¸»è¦é›†ä¸­åœ¨é™æ€ä¸‰ç»´åœºæ™¯å’Œå¯¹è±¡çº§åˆ«çš„åŠ¨æ€å»ºæ¨¡ä¸Šï¼Œéš¾ä»¥æ»¡è¶³çœŸæ­£çš„æ²‰æµ¸å¼éœ€æ±‚ã€‚</li>
<li>HoloTimeæ¡†æ¶æ•´åˆè§†é¢‘æ‰©æ•£æ¨¡å‹ç”Ÿæˆå…¨æ™¯è§†é¢‘ï¼Œå®ç°å•ä¸€æç¤ºæˆ–å‚è€ƒå›¾åƒçš„åœºæ™¯é‡å»ºã€‚</li>
<li>å¼•å…¥çš„360Worldæ•°æ®é›†ä¸ºå…¨æ™¯è§†é¢‘ç”Ÿæˆæä¾›äº†é«˜è´¨é‡èµ„æºã€‚</li>
<li>æå‡ºå…¨æ™¯åŠ¨ç”»å¸ˆï¼ˆPanoramic Animatorï¼‰æ¨¡å‹ï¼Œç”¨äºå°†å…¨æ™¯å›¾åƒè½¬æ¢ä¸ºé«˜è´¨é‡å…¨æ™¯è§†é¢‘ã€‚</li>
<li>åˆ©ç”¨æ—¶ç©ºé‡å»ºæŠ€æœ¯å°†å…¨æ™¯è§†é¢‘è½¬åŒ–ä¸ºå››ç»´ç‚¹äº‘ï¼Œè¿›ä¸€æ­¥ä¼˜åŒ–äº†å››ç»´åœºæ™¯é‡å»ºçš„æ•ˆæœã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.21650">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-108d8be07258f28f73c4a9781b72eae5.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-404094d08fe4de07420ee6d582f758d4.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-43c94392690dc8358107d9f8dd554658.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-3cc9ac35ee0db72fbe3d4e35aa6b32bf.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="Diffusion-based-Adversarial-Identity-Manipulation-for-Facial-Privacy-Protection"><a href="#Diffusion-based-Adversarial-Identity-Manipulation-for-Facial-Privacy-Protection" class="headerlink" title="Diffusion-based Adversarial Identity Manipulation for Facial Privacy   Protection"></a>Diffusion-based Adversarial Identity Manipulation for Facial Privacy   Protection</h2><p><strong>Authors:Liqin Wang, Qianyue Hu, Wei Lu, Xiangyang Luo</strong></p>
<p>The success of face recognition (FR) systems has led to serious privacy concerns due to potential unauthorized surveillance and user tracking on social networks. Existing methods for enhancing privacy fail to generate natural face images that can protect facial privacy. In this paper, we propose diffusion-based adversarial identity manipulation (DiffAIM) to generate natural and highly transferable adversarial faces against malicious FR systems. To be specific, we manipulate facial identity within the low-dimensional latent space of a diffusion model. This involves iteratively injecting gradient-based adversarial identity guidance during the reverse diffusion process, progressively steering the generation toward the desired adversarial faces. The guidance is optimized for identity convergence towards a target while promoting semantic divergence from the source, facilitating effective impersonation while maintaining visual naturalness. We further incorporate structure-preserving regularization to preserve facial structure consistency during manipulation. Extensive experiments on both face verification and identification tasks demonstrate that compared with the state-of-the-art, DiffAIM achieves stronger black-box attack transferability while maintaining superior visual quality. We also demonstrate the effectiveness of the proposed approach for commercial FR APIs, including Face++ and Aliyun. </p>
<blockquote>
<p>äººè„¸è¯†åˆ«ï¼ˆFRï¼‰ç³»ç»Ÿçš„æˆåŠŸå¼•å‘äº†ä¸¥é‡çš„éšç§æ‹…å¿§ï¼Œå› ä¸ºå¯èƒ½å­˜åœ¨æœªç»æˆæƒçš„ç›‘ç£å’Œç¤¾ä¼šç½‘ç»œä¸Šçš„ç”¨æˆ·è·Ÿè¸ªã€‚ç°æœ‰çš„å¢å¼ºéšç§çš„æ–¹æ³•æ— æ³•ç”Ÿæˆèƒ½å¤Ÿä¿æŠ¤é¢éƒ¨éšç§çš„è‡ªç„¶é¢éƒ¨å›¾åƒã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†åŸºäºæ‰©æ•£çš„å¯¹æŠ—æ€§èº«ä»½æ“çºµï¼ˆDiffAIMï¼‰æ–¹æ³•ï¼Œç”Ÿæˆè‡ªç„¶ä¸”é«˜åº¦å¯è½¬ç§»çš„å¯¹æŠ—æ€§é¢éƒ¨å›¾åƒï¼Œä»¥å¯¹æŠ—æ¶æ„FRç³»ç»Ÿã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬åœ¨æ‰©æ•£æ¨¡å‹çš„ä½ç»´æ½œåœ¨ç©ºé—´å†…å¯¹èº«ä»½è¿›è¡Œæ“çºµã€‚è¿™æ¶‰åŠåœ¨åå‘æ‰©æ•£è¿‡ç¨‹ä¸­è¿­ä»£æ³¨å…¥åŸºäºæ¢¯åº¦çš„å¯¹æŠ—æ€§èº«ä»½æŒ‡å¯¼ï¼Œé€æ­¥å¼•å¯¼ç”Ÿæˆèµ°å‘ç›®æ ‡å¯¹æŠ—æ€§é¢éƒ¨å›¾åƒã€‚æŒ‡å¯¼ä¼˜åŒ–æ—¨åœ¨ä½¿èº«ä»½æ”¶æ•›äºç›®æ ‡ï¼ŒåŒæ—¶ä¿ƒè¿›ä¸æºä¹‹é—´çš„è¯­ä¹‰å‘æ•£ï¼Œä»è€Œåœ¨ä¿æŒè§†è§‰è‡ªç„¶æ€§çš„åŒæ—¶å®ç°æœ‰æ•ˆçš„ä¼ªè£…ã€‚æˆ‘ä»¬è¿›ä¸€æ­¥å¼•å…¥äº†ç»“æ„ä¿æŒæ­£åˆ™åŒ–ï¼Œä»¥ä¿æŒé¢éƒ¨ç»“æ„ä¸€è‡´æ€§åœ¨æ“çºµè¿‡ç¨‹ä¸­ã€‚å¯¹é¢éƒ¨éªŒè¯å’Œè¯†åˆ«ä»»åŠ¡çš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼Œä¸æœ€æ–°æŠ€æœ¯ç›¸æ¯”ï¼ŒDiffAIMå®ç°äº†æ›´å¼ºçš„é»‘ç›’æ”»å‡»è½¬ç§»æ€§ï¼ŒåŒæ—¶ä¿æŒäº†å“è¶Šçš„å¯è§†è´¨é‡ã€‚æˆ‘ä»¬è¿˜è¯æ˜äº†æ‰€æå‡ºæ–¹æ³•åœ¨åŒ…æ‹¬Face++å’Œé˜¿é‡Œäº‘åœ¨å†…çš„å•†ä¸šFR APIä¸Šçš„æœ‰æ•ˆæ€§ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.21646v1">PDF</a> </p>
<p><strong>Summary</strong><br>äººè„¸è¯†åˆ«ç³»ç»Ÿçš„æˆåŠŸå¼•å‘äº†å…³äºä¸ªäººéšç§çš„ä¸¥é‡å…³æ³¨ï¼Œå› ä¸ºå­˜åœ¨æ½œåœ¨çš„æœªç»æˆæƒç›‘æ§å’Œç”¨æˆ·ç¤¾äº¤ç½‘ç»œè¿½è¸ªã€‚ç°æœ‰çš„éšç§ä¿æŠ¤æ–¹æ³•æ— æ³•ç”Ÿæˆèƒ½ä¿æŠ¤é¢éƒ¨éšç§çš„è‡ªç„¶é¢éƒ¨å›¾åƒã€‚æœ¬ç ”ç©¶æå‡ºäº†ä¸€ç§åŸºäºæ‰©æ•£å¯¹æŠ—èº«ä»½æ“æ§ï¼ˆDiffAIMï¼‰çš„æ–¹æ³•ï¼Œç”¨äºç”Ÿæˆå¯¹æŠ—æ€§é¢éƒ¨å›¾åƒï¼Œä»¥æŠµå¾¡æ¶æ„äººè„¸è¯†åˆ«ç³»ç»Ÿã€‚DiffAIMåœ¨ä½ç»´æ½œåœ¨ç©ºé—´å†…æ“çºµé¢éƒ¨èº«ä»½ï¼Œå¹¶åœ¨åå‘æ‰©æ•£è¿‡ç¨‹ä¸­æ³¨å…¥åŸºäºæ¢¯åº¦çš„å¯¹æŠ—æ€§èº«ä»½æŒ‡å¯¼ï¼Œé€æ­¥å¼•å¯¼ç”Ÿæˆå›¾åƒæœå‘ç›®æ ‡å¯¹æŠ—æ€§é¢éƒ¨ã€‚æ­¤æ–¹æ³•ä¼˜åŒ–äº†èº«ä»½æ”¶æ•›è‡³ç›®æ ‡çš„åŒæ—¶ï¼Œä¿ƒè¿›ä¸æºå›¾åƒçš„è¯­ä¹‰å·®å¼‚ï¼Œä»¥å®ç°æœ‰æ•ˆä¼ªè£…å¹¶ç»´æŒè§†è§‰è‡ªç„¶æ€§ã€‚æ­¤å¤–ï¼Œè¿˜èå…¥äº†ç»“æ„ä¿æŒæ­£åˆ™åŒ–ï¼Œä»¥ä¿æŒé¢éƒ¨ç»“æ„ä¸€è‡´æ€§ã€‚å®éªŒè¡¨æ˜ï¼Œç›¸è¾ƒäºå…¶ä»–é¡¶å°–æ–¹æ³•ï¼ŒDiffAIMåœ¨é¢éƒ¨éªŒè¯å’Œè¯†åˆ«ä»»åŠ¡ä¸Šå®ç°äº†æ›´å¼ºçš„é»‘ç›’æ”»å‡»è½¬ç§»èƒ½åŠ›ï¼ŒåŒæ—¶ä¿æŒäº†å“è¶Šè§†è§‰è´¨é‡ã€‚è¯¥ç­–ç•¥å¯¹åŒ…æ‹¬Face++å’Œé˜¿é‡Œäº‘åœ¨å†…çš„äººè„¸è¯†åˆ«APIåŒæ ·æœ‰æ•ˆã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>äººè„¸è¯†åˆ«ç³»ç»Ÿçš„æˆåŠŸå¼•å‘äº†å…³äºéšç§çš„é‡å¤§æ‹…å¿§ï¼Œç‰¹åˆ«æ˜¯æœªç»æˆæƒçš„ç›‘æ§å’Œç¤¾äº¤ç½‘ç»œè¿½è¸ªã€‚</li>
<li>ç°æœ‰éšç§ä¿æŠ¤æ–¹æ³•æ— æ³•è‡ªç„¶ç”Ÿæˆèƒ½ä¿æŠ¤é¢éƒ¨éšç§çš„å›¾åƒã€‚</li>
<li>DiffAIMæ–¹æ³•åŸºäºæ‰©æ•£æ¨¡å‹ï¼Œåœ¨ä½ç»´æ½œåœ¨ç©ºé—´å†…æ“æ§é¢éƒ¨èº«ä»½ã€‚</li>
<li>DiffAIMé€šè¿‡æ³¨å…¥æ¢¯åº¦åŸºäºçš„å¯¹æŠ—æ€§èº«ä»½æŒ‡å¯¼ï¼Œé€æ­¥ç”Ÿæˆå¯¹æŠ—æ€§é¢éƒ¨å›¾åƒã€‚</li>
<li>DiffAIMåœ¨ä¼˜åŒ–èº«ä»½æ”¶æ•›è‡³ç›®æ ‡çš„åŒæ—¶ï¼Œä¿ƒè¿›ä¸æºå›¾åƒçš„è¯­ä¹‰å·®å¼‚ï¼Œç»´æŒè§†è§‰è‡ªç„¶æ€§ã€‚</li>
<li>ç»“æ„ä¿æŒæ­£åˆ™åŒ–è¢«ç”¨äºä¿æŒé¢éƒ¨ç»“æ„ä¸€è‡´æ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.21646">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-94eb472108f8f00e94d5c6e05491eb21.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-3d82d52452e5f49bfc0f3a224c873176.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-58cc7ead29eb1b6f99da38c2be1ad145.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-7c3ffd0ffde01cea604bc3781c6b8a48.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="Latent-Feature-Guided-Conditional-Diffusion-for-High-Fidelity-Generative-Image-Semantic-Communication"><a href="#Latent-Feature-Guided-Conditional-Diffusion-for-High-Fidelity-Generative-Image-Semantic-Communication" class="headerlink" title="Latent Feature-Guided Conditional Diffusion for High-Fidelity Generative   Image Semantic Communication"></a>Latent Feature-Guided Conditional Diffusion for High-Fidelity Generative   Image Semantic Communication</h2><p><strong>Authors:Zehao Chen, Xinfeng Wei, Haonan Tong, Zhaohui Yang, Changchuan Yin</strong></p>
<p>Semantic communication is proposed and expected to improve the efficiency and effectiveness of massive data transmission over sixth generation (6G) networks. However, existing deep learning-based joint source and channel coding (DeepJSCC) image semantic communication scheme predominantly focuses on optimizing pixel-level metrics, and neglects human perceptual requirements, which results in degraded perceptual quality. To address this issue, we propose a latent representation-oriented image semantic communication (LRISC) system, which transmits latent semantic features for image generation with semantic consistency, thereby ensuring the perceptual quality at the receiver. In particular, we first map the source image to latent features in a high-dimensional semantic space via a neural network (NN)- based non-linear transformation. Subsequently, these features are encoded using a joint source and channel coding (JSCC) scheme with adaptive coding length for efficient transmission over a wireless channel. At the receiver, a conditional diffusion model is developed by using the received latent features as conditional guidance to steer the reverse diffusion process, progressively reconstructing high-fidelity images while preserving semantic consistency. Moreover, we introduce a channel signal-to-noise ratio (SNR) adaptation mechanism, allowing one model to work across various channel states. Experiments show that the proposed method significantly outperforms existing methods, in terms of learned perceptual image patch similarity (LPIPS) and robustness against channel noise, with an average LPIPS reduction of 43.3% compared to DeepJSCC, while guaranteeing the semantic consistency. </p>
<blockquote>
<p>è¯­ä¹‰é€šä¿¡æ—¨åœ¨æé«˜ç¬¬å…­ä»£ï¼ˆ6Gï¼‰ç½‘ç»œä¸Šå¤§è§„æ¨¡æ•°æ®ä¼ è¾“çš„æ•ˆç‡å’Œæ•ˆæœã€‚ç„¶è€Œï¼Œç°æœ‰çš„åŸºäºæ·±åº¦å­¦ä¹ çš„è”åˆæºä¿¡é“ç¼–ç ï¼ˆDeepJSCCï¼‰å›¾åƒè¯­ä¹‰é€šä¿¡æ–¹æ¡ˆä¸»è¦å…³æ³¨åƒç´ çº§çš„æŒ‡æ ‡ä¼˜åŒ–ï¼Œå¿½è§†äº†äººç±»æ„ŸçŸ¥çš„éœ€æ±‚ï¼Œå¯¼è‡´æ„ŸçŸ¥è´¨é‡ä¸‹é™ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§é¢å‘æ½œåœ¨è¡¨ç¤ºçš„å›¾åƒè¯­ä¹‰é€šä¿¡ï¼ˆLRISCï¼‰ç³»ç»Ÿï¼Œè¯¥ç³»ç»Ÿä¼ è¾“ç”¨äºå›¾åƒç”Ÿæˆçš„æ½œåœ¨è¯­ä¹‰ç‰¹å¾ï¼Œä»¥ç¡®ä¿æ¥æ”¶ç«¯çš„æ„ŸçŸ¥è´¨é‡å…·æœ‰è¯­ä¹‰ä¸€è‡´æ€§ã€‚å…·ä½“è€Œè¨€ï¼Œæˆ‘ä»¬é¦–å…ˆå°†æºå›¾åƒæ˜ å°„åˆ°é«˜ç»´è¯­ä¹‰ç©ºé—´ä¸­çš„æ½œåœ¨ç‰¹å¾ï¼Œé€šè¿‡ç¥ç»ç½‘ç»œï¼ˆNNï¼‰è¿›è¡Œéçº¿æ€§å˜æ¢ã€‚éšåï¼Œè¿™äº›ç‰¹å¾ä½¿ç”¨å…·æœ‰è‡ªé€‚åº”ç¼–ç é•¿åº¦çš„è”åˆæºä¿¡é“ç¼–ç ï¼ˆJSCCï¼‰æ–¹æ¡ˆè¿›è¡Œç¼–ç ï¼Œä»¥ä¾¿åœ¨æ— çº¿ä¿¡é“ä¸Šè¿›è¡Œæœ‰æ•ˆä¼ è¾“ã€‚åœ¨æ¥æ”¶ç«¯ï¼Œæˆ‘ä»¬åˆ©ç”¨æ¥æ”¶åˆ°çš„æ½œåœ¨ç‰¹å¾ä½œä¸ºæ¡ä»¶æŒ‡å¯¼ï¼Œå¼€å‘äº†ä¸€ç§æ¡ä»¶æ‰©æ•£æ¨¡å‹ï¼Œå¼•å¯¼åå‘æ‰©æ•£è¿‡ç¨‹ï¼Œé€æ­¥é‡å»ºé«˜è´¨é‡å›¾åƒï¼ŒåŒæ—¶ä¿æŒè¯­ä¹‰ä¸€è‡´æ€§ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜å¼•å…¥äº†ä¸€ç§ä¿¡é“ä¿¡å™ªæ¯”ï¼ˆSNRï¼‰è‡ªé€‚åº”æœºåˆ¶ï¼Œä½¿æ¨¡å‹èƒ½å¤Ÿåœ¨å„ç§ä¿¡é“çŠ¶æ€ä¸‹å·¥ä½œã€‚å®éªŒè¡¨æ˜ï¼Œæ‰€ææ–¹æ³•åœ¨å­¦ä¹ çš„æ„ŸçŸ¥å›¾åƒè¡¥ä¸ç›¸ä¼¼æ€§ï¼ˆLPIPSï¼‰å’Œå¯¹æŠ—ä¿¡é“å™ªå£°çš„ç¨³å¥æ€§æ–¹é¢éƒ½æ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œä¸DeepJSCCç›¸æ¯”ï¼Œå¹³å‡LPIPSé™ä½äº†43.3%ï¼ŒåŒæ—¶ä¿è¯äº†è¯­ä¹‰ä¸€è‡´æ€§ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.21577v1">PDF</a> 6 pages, 6 figures</p>
<p><strong>æ‘˜è¦</strong><br>    é’ˆå¯¹ç¬¬å…­ä»£ï¼ˆ6Gï¼‰ç½‘ç»œä¸­çš„å¤§è§„æ¨¡æ•°æ®ä¼ è¾“ï¼Œæå‡ºè¯­ä¹‰é€šä¿¡èƒ½æé«˜ä¼ è¾“æ•ˆç‡å’Œæ•ˆæœã€‚ç„¶è€Œï¼Œç°æœ‰çš„åŸºäºæ·±åº¦å­¦ä¹ çš„è”åˆæºä¿¡é“ç¼–ç ï¼ˆDeepJSCCï¼‰å›¾åƒè¯­ä¹‰é€šä¿¡æ–¹æ¡ˆä¸»è¦å…³æ³¨åƒç´ çº§æŒ‡æ ‡ä¼˜åŒ–ï¼Œå¿½è§†äº†äººç±»æ„ŸçŸ¥éœ€æ±‚ï¼Œå¯¼è‡´æ„ŸçŸ¥è´¨é‡ä¸‹é™ã€‚ä¸ºè§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªåŸºäºæ½œåœ¨è¡¨ç¤ºçš„å›¾åƒè¯­ä¹‰é€šä¿¡ç³»ç»Ÿï¼ˆLRISCï¼‰ï¼Œé€šè¿‡ä¼ è¾“æ½œåœ¨è¯­ä¹‰ç‰¹å¾æ¥ç”Ÿæˆå›¾åƒï¼Œç¡®ä¿æ¥æ”¶ç«¯çš„æ„ŸçŸ¥è´¨é‡ã€‚å…·ä½“è€Œè¨€ï¼Œæˆ‘ä»¬é¦–å…ˆå°†æºå›¾åƒæ˜ å°„åˆ°é«˜ç»´è¯­ä¹‰ç©ºé—´çš„æ½œåœ¨ç‰¹å¾ä¸Šï¼Œç„¶åé€šè¿‡è”åˆæºä¿¡é“ç¼–ç è¿›è¡Œç¼–ç ä»¥é€‚åº”æ— çº¿ä¿¡é“çš„ä¼ è¾“ã€‚åœ¨æ¥æ”¶ç«¯ï¼Œåˆ©ç”¨æ¥æ”¶åˆ°çš„æ½œåœ¨ç‰¹å¾ä½œä¸ºæ¡ä»¶æŒ‡å¯¼ï¼Œå‘å±•äº†ä¸€ç§æ¡ä»¶æ‰©æ•£æ¨¡å‹ï¼Œä»¥é€†å‘æ‰©æ•£è¿‡ç¨‹é€æ­¥é‡å»ºé«˜è´¨é‡å›¾åƒå¹¶ä¿æŒè¯­ä¹‰ä¸€è‡´æ€§ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¿¡é“ä¿¡å™ªæ¯”ï¼ˆSNRï¼‰è‡ªé€‚åº”æœºåˆ¶ï¼Œä½¿æ¨¡å‹èƒ½é€‚åº”å„ç§ä¿¡é“çŠ¶æ€ã€‚å®éªŒè¡¨æ˜ï¼Œç›¸è¾ƒäºDeepJSCCï¼Œæ‰€ææ–¹æ³•åœ¨æ„ŸçŸ¥å›¾åƒè¡¥ä¸ç›¸ä¼¼æ€§ï¼ˆLPIPSï¼‰ä¸Šå¹³å‡é™ä½äº†43.3%ï¼Œåœ¨æŠµæŠ—ä¿¡é“å™ªå£°æ–¹é¢æ›´åŠ ç¨³å¥ï¼ŒåŒæ—¶ä¿è¯äº†è¯­ä¹‰ä¸€è‡´æ€§ã€‚</p>
<p><strong>å…³é”®è§è§£</strong></p>
<ol>
<li>è¯­ä¹‰é€šä¿¡åœ¨6Gç½‘ç»œä¸­å¯¹äºå¤§è§„æ¨¡æ•°æ®ä¼ è¾“çš„æ•ˆç‡ä¸æ•ˆæœæå‡è‡³å…³é‡è¦ã€‚</li>
<li>ç°æœ‰DeepJSCCæ–¹æ¡ˆä¸»è¦å…³æ³¨åƒç´ çº§ä¼˜åŒ–ï¼Œå¿½è§†äº†äººç±»æ„ŸçŸ¥éœ€æ±‚ï¼Œé€ æˆæ„ŸçŸ¥è´¨é‡ä¸‹é™ã€‚</li>
<li>LRISCç³»ç»Ÿé€šè¿‡ä¼ è¾“æ½œåœ¨è¯­ä¹‰ç‰¹å¾æ¥ç¡®ä¿å›¾åƒçš„è¯­ä¹‰ä¸€è‡´æ€§å’Œæ¥æ”¶ç«¯çš„æ„ŸçŸ¥è´¨é‡ã€‚</li>
<li>æºå›¾åƒé¦–å…ˆè¢«æ˜ å°„åˆ°é«˜ç»´è¯­ä¹‰ç©ºé—´çš„æ½œåœ¨ç‰¹å¾ä¸Šï¼Œç„¶åé€šè¿‡è”åˆæºä¿¡é“ç¼–ç è¿›è¡Œç¼–ç ä»¥é€‚åº”æ— çº¿ä¼ è¾“ã€‚</li>
<li>æ¥æ”¶ç«¯é‡‡ç”¨æ¡ä»¶æ‰©æ•£æ¨¡å‹ï¼Œåˆ©ç”¨æ½œåœ¨ç‰¹å¾é€æ­¥é‡å»ºé«˜è´¨é‡å›¾åƒã€‚</li>
<li>å¼•å…¥ä¿¡é“SNRè‡ªé€‚åº”æœºåˆ¶ï¼Œå¢å¼ºæ¨¡å‹å¯¹å„ç§ä¿¡é“çŠ¶æ€çš„é€‚åº”æ€§ã€‚</li>
<li>å®éªŒæ˜¾ç¤ºLRISCåœ¨LPIPSæŒ‡æ ‡ä¸Šæ˜¾è‘—ä¼˜äºDeepJSCCï¼Œä¸”æ›´æŠ—ä¿¡é“å™ªå£°å¹²æ‰°ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.21577">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-f5dc5e5fdd60a21cd2a12c32814006b4.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-dd9390a281ba11735752e5850746e20c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-23a8abc6e19c7394ba9a3f1443f4f237.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-1f9eeca927664cf00d1efd7050ea90ad.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e403b5782e7295d29c441e83aa07c4aa.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-5f27ffbd80653c75f77a8cdc3e61ac46.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="MagicPortrait-Temporally-Consistent-Face-Reenactment-with-3D-Geometric-Guidance"><a href="#MagicPortrait-Temporally-Consistent-Face-Reenactment-with-3D-Geometric-Guidance" class="headerlink" title="MagicPortrait: Temporally Consistent Face Reenactment with 3D Geometric   Guidance"></a>MagicPortrait: Temporally Consistent Face Reenactment with 3D Geometric   Guidance</h2><p><strong>Authors:Mengting Wei, Yante Li, Tuomas Varanka, Yan Jiang, Licai Sun, Guoying Zhao</strong></p>
<p>In this paper, we propose a method for video face reenactment that integrates a 3D face parametric model into a latent diffusion framework, aiming to improve shape consistency and motion control in existing video-based face generation approaches. Our approach employs the FLAME (Faces Learned with an Articulated Model and Expressions) model as the 3D face parametric representation, providing a unified framework for modeling face expressions and head pose. This enables precise extraction of detailed face geometry and motion features from driving videos. Specifically, we enhance the latent diffusion model with rich 3D expression and detailed pose information by incorporating depth maps, normal maps, and rendering maps derived from FLAME sequences. A multi-layer face movements fusion module with integrated self-attention mechanisms is used to combine identity and motion latent features within the spatial domain. By utilizing the 3D face parametric model as motion guidance, our method enables parametric alignment of face identity between the reference image and the motion captured from the driving video. Experimental results on benchmark datasets show that our method excels at generating high-quality face animations with precise expression and head pose variation modeling. In addition, it demonstrates strong generalization performance on out-of-domain images. Code is publicly available at <a target="_blank" rel="noopener" href="https://github.com/weimengting/MagicPortrait">https://github.com/weimengting/MagicPortrait</a>. </p>
<blockquote>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ç§å°†3Däººè„¸å‚æ•°æ¨¡å‹é›†æˆåˆ°æ½œåœ¨æ‰©æ•£æ¡†æ¶ä¸­çš„è§†é¢‘äººè„¸å†ç°æ–¹æ³•ã€‚è¯¥æ–¹æ³•æ—¨åœ¨æé«˜ç°æœ‰è§†é¢‘äººè„¸ç”Ÿæˆæ–¹æ³•ä¸­çš„å½¢çŠ¶ä¸€è‡´æ€§å’Œè¿åŠ¨æ§åˆ¶ã€‚æˆ‘ä»¬çš„æ–¹æ³•é‡‡ç”¨FLAMEï¼ˆå¸¦æœ‰å…³èŠ‚æ¨¡å‹å’Œè¡¨æƒ…çš„äººè„¸å­¦ä¹ ï¼‰æ¨¡å‹ä½œä¸º3Däººè„¸å‚æ•°è¡¨ç¤ºï¼Œä¸ºé¢éƒ¨è¡¨æƒ…å’Œå¤´éƒ¨å§¿æ€å»ºæ¨¡æä¾›äº†ä¸€ä¸ªç»Ÿä¸€æ¡†æ¶ã€‚è¿™å¯ä»¥ä»é©±åŠ¨è§†é¢‘ä¸­æå–è¯¦ç»†çš„é¢éƒ¨å‡ ä½•å’Œè¿åŠ¨ç‰¹å¾ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬é€šè¿‡èå…¥ä»FLAMEåºåˆ—æ´¾ç”Ÿçš„æ·±åº¦å›¾ã€æ³•çº¿å›¾ä»¥åŠæ¸²æŸ“å›¾ï¼Œä¸°å¯Œäº†æ½œåœ¨æ‰©æ•£æ¨¡å‹çš„3Dè¡¨æƒ…å’Œè¯¦ç»†å§¿æ€ä¿¡æ¯ã€‚é‡‡ç”¨å…·æœ‰é›†æˆè‡ªæ³¨æ„åŠ›æœºåˆ¶çš„å¤šå±‚é¢éƒ¨è¿åŠ¨èåˆæ¨¡å—ï¼Œåœ¨ç©ºåŸŸå†…ç»“åˆèº«ä»½å’Œè¿åŠ¨æ½œåœ¨ç‰¹å¾ã€‚é€šè¿‡åˆ©ç”¨3Däººè„¸å‚æ•°æ¨¡å‹ä½œä¸ºè¿åŠ¨æŒ‡å¯¼ï¼Œæˆ‘ä»¬çš„æ–¹æ³•èƒ½å¤Ÿåœ¨å‚è€ƒå›¾åƒå’Œä»é©±åŠ¨è§†é¢‘ä¸­æ•è·çš„è¿åŠ¨ä¹‹é—´å®ç°äººè„¸èº«ä»½çš„å‚æ•°å¯¹é½ã€‚åœ¨åŸºå‡†æ•°æ®é›†ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨ç”Ÿæˆé«˜è´¨é‡çš„äººè„¸åŠ¨ç”»ã€ç²¾ç¡®çš„è¡¨æƒ…å’Œå¤´éƒ¨å§¿æ€å˜åŒ–å»ºæ¨¡æ–¹é¢è¡¨ç°å‡ºè‰²ã€‚æ­¤å¤–ï¼Œå®ƒåœ¨åŸŸå¤–å›¾åƒä¸Šè¡¨ç°å‡ºå¼ºå¤§çš„æ³›åŒ–æ€§èƒ½ã€‚ç›¸å…³ä»£ç å·²å…¬å¼€åœ¨<a target="_blank" rel="noopener" href="https://github.com/weimengting/MagicPortrait%E4%B8%8A%E3%80%82">https://github.com/weimengting/MagicPortraitä¸Šã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.21497v1">PDF</a> </p>
<p><strong>Summary</strong><br>æ–°ä¸€ä»£è§†é¢‘äººè„¸æ›¿æ¢æŠ€æœ¯ç»“åˆäº†ä¸‰ç»´äººè„¸å‚æ•°æ¨¡å‹ä¸æ½œåœ¨æ‰©æ•£æ¡†æ¶ï¼Œæ—¨åœ¨æ”¹è¿›ç°æœ‰è§†é¢‘äººè„¸ç”Ÿæˆæ–¹æ³•ä¸­çš„å½¢çŠ¶ä¸€è‡´æ€§å’Œè¿åŠ¨æ§åˆ¶ã€‚é€šè¿‡é‡‡ç”¨FLAMEæ¨¡å‹ä½œä¸ºä¸‰ç»´äººè„¸å‚æ•°è¡¨ç¤ºï¼Œè¯¥æ–¹æ³•ä¸ºé¢éƒ¨è¡¨æƒ…å’Œå¤´éƒ¨å§¿æ€å»ºæ¨¡æä¾›äº†ç»Ÿä¸€æ¡†æ¶ï¼Œä»è€Œç²¾ç¡®åœ°æå–äº†é©±åŠ¨è§†é¢‘ä¸­çš„é¢éƒ¨å‡ ä½•å’Œè¿åŠ¨ç‰¹å¾ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•è¿˜é€šè¿‡èå…¥æ·±åº¦å›¾ã€æ³•çº¿å›¾ä»¥åŠä»FLAMEåºåˆ—ä¸­å¾—åˆ°çš„æ¸²æŸ“å›¾å¢å¼ºäº†æ½œåœ¨æ‰©æ•£æ¨¡å‹çš„ä¸°å¯Œä¸‰ç»´è¡¨æƒ…å’Œç²¾ç»†å§¿æ€ä¿¡æ¯ã€‚åˆ©ç”¨ä¸‰ç»´äººè„¸å‚æ•°æ¨¡å‹ä½œä¸ºè¿åŠ¨æŒ‡å¯¼ï¼Œè¯¥æ–¹æ³•å®ç°äº†å‚è€ƒå›¾åƒä¸ä»é©±åŠ¨è§†é¢‘ä¸­æ•è·çš„è¿åŠ¨ä¹‹é—´çš„é¢éƒ¨èº«ä»½å‚æ•°å¯¹é½ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨ç”Ÿæˆé«˜è´¨é‡é¢éƒ¨åŠ¨ç”»ã€ç²¾ç¡®è¡¨è¾¾åŠå¤´éƒ¨å§¿æ€å˜åŒ–å»ºæ¨¡æ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œä¸”åœ¨è·¨åŸŸå›¾åƒä¸Šå…·æœ‰è¾ƒå¼ºçš„æ³›åŒ–æ€§èƒ½ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>è¯¥è®ºæ–‡æå‡ºäº†ä¸€ç§å°†3Däººè„¸å‚æ•°æ¨¡å‹èå…¥æ½œåœ¨æ‰©æ•£æ¡†æ¶çš„è§†é¢‘äººè„¸æ›¿æ¢æ–°æ–¹æ³•ã€‚</li>
<li>é‡‡ç”¨FLAMEæ¨¡å‹ä½œä¸º3Däººè„¸å‚æ•°è¡¨ç¤ºï¼Œä¸ºé¢éƒ¨è¡¨æƒ…å’Œå¤´éƒ¨å§¿æ€å»ºæ¨¡æä¾›ç»Ÿä¸€æ¡†æ¶ã€‚</li>
<li>é€šè¿‡èå…¥æ·±åº¦å›¾ã€æ³•çº¿å›¾å’Œæ¸²æŸ“å›¾å¢å¼ºæ½œåœ¨æ‰©æ•£æ¨¡å‹çš„ä¸°å¯Œä¸‰ç»´è¡¨æƒ…å’Œç²¾ç»†å§¿æ€ä¿¡æ¯ã€‚</li>
<li>åˆ©ç”¨ä¸‰ç»´äººè„¸å‚æ•°æ¨¡å‹ä½œä¸ºè¿åŠ¨æŒ‡å¯¼ï¼Œå®ç°é¢éƒ¨èº«ä»½ä¸è¿åŠ¨çš„å‚æ•°å¯¹é½ã€‚</li>
<li>è¯¥æ–¹æ³•åœ¨ç”Ÿæˆé«˜è´¨é‡é¢éƒ¨åŠ¨ç”»ã€ç²¾ç¡®è¡¨è¾¾åŠå¤´éƒ¨å§¿æ€å˜åŒ–å»ºæ¨¡æ–¹é¢è¡¨ç°ä¼˜å¼‚ã€‚</li>
<li>è¯¥æ–¹æ³•å…·æœ‰å¼ºå¤§çš„æ³›åŒ–èƒ½åŠ›ï¼Œé€‚ç”¨äºè·¨åŸŸå›¾åƒã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.21497">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-50daa0821b58ae4c4360e8d879fb4d5e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a98f99abe6f13361d5376728b9b6229c.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-475855bb8d6048f8dc11b0fa9c396653.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-814454a25c5df812963c2d907fbd77d8.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="DGSolver-Diffusion-Generalist-Solver-with-Universal-Posterior-Sampling-for-Image-Restoration"><a href="#DGSolver-Diffusion-Generalist-Solver-with-Universal-Posterior-Sampling-for-Image-Restoration" class="headerlink" title="DGSolver: Diffusion Generalist Solver with Universal Posterior Sampling   for Image Restoration"></a>DGSolver: Diffusion Generalist Solver with Universal Posterior Sampling   for Image Restoration</h2><p><strong>Authors:Hebaixu Wang, Jing Zhang, Haonan Guo, Di Wang, Jiayi Ma, Bo Du</strong></p>
<p>Diffusion models have achieved remarkable progress in universal image restoration. While existing methods speed up inference by reducing sampling steps, substantial step intervals often introduce cumulative errors. Moreover, they struggle to balance the commonality of degradation representations and restoration quality. To address these challenges, we introduce \textbf{DGSolver}, a diffusion generalist solver with universal posterior sampling. We first derive the exact ordinary differential equations for generalist diffusion models and tailor high-order solvers with a queue-based accelerated sampling strategy to improve both accuracy and efficiency. We then integrate universal posterior sampling to better approximate manifold-constrained gradients, yielding a more accurate noise estimation and correcting errors in inverse inference. Extensive experiments show that DGSolver outperforms state-of-the-art methods in restoration accuracy, stability, and scalability, both qualitatively and quantitatively. Code and models will be available at <a target="_blank" rel="noopener" href="https://github.com/MiliLab/DGSolver">https://github.com/MiliLab/DGSolver</a>. </p>
<blockquote>
<p>æ‰©æ•£æ¨¡å‹åœ¨é€šç”¨å›¾åƒä¿®å¤æ–¹é¢å–å¾—äº†æ˜¾è‘—çš„è¿›æ­¥ã€‚è™½ç„¶ç°æœ‰æ–¹æ³•é€šè¿‡å‡å°‘é‡‡æ ·æ­¥éª¤æ¥åŠ é€Ÿæ¨ç†ï¼Œä½†è¾ƒå¤§çš„æ­¥éª¤é—´éš”é€šå¸¸ä¼šå¼•å…¥ç´¯ç§¯è¯¯å·®ã€‚æ­¤å¤–ï¼Œå®ƒä»¬å¾ˆéš¾åœ¨é€€åŒ–è¡¨ç¤ºçš„å…±åŒæ€§å’Œä¿®å¤è´¨é‡ä¹‹é—´å–å¾—å¹³è¡¡ã€‚ä¸ºäº†è§£å†³è¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬å¼•å…¥äº†<strong>DGSolver</strong>ï¼Œè¿™æ˜¯ä¸€ç§å¸¦æœ‰é€šç”¨åéªŒé‡‡æ ·çš„æ‰©æ•£é€šç”¨æ±‚è§£å™¨ã€‚æˆ‘ä»¬é¦–å…ˆä¸ºé€šç”¨æ‰©æ•£æ¨¡å‹æ¨å¯¼å‡ºç²¾ç¡®çš„å¸¸å¾®åˆ†æ–¹ç¨‹ï¼Œå¹¶ä½¿ç”¨åŸºäºé˜Ÿåˆ—çš„åŠ é€Ÿé‡‡æ ·ç­–ç•¥å®šåˆ¶é«˜é˜¶æ±‚è§£å™¨ï¼Œä»¥æé«˜å‡†ç¡®æ€§å’Œæ•ˆç‡ã€‚ç„¶åï¼Œæˆ‘ä»¬èå…¥é€šç”¨åéªŒé‡‡æ ·ï¼Œä»¥æ›´å¥½åœ°è¿‘ä¼¼æµå½¢çº¦æŸæ¢¯åº¦ï¼Œä»è€Œå¾—åˆ°æ›´å‡†ç¡®çš„å™ªå£°ä¼°è®¡å’Œé€†å‘æ¨ç†ä¸­çš„è¯¯å·®æ ¡æ­£ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼Œæ— è®ºæ˜¯åœ¨å®šæ€§è¿˜æ˜¯å®šé‡æ–¹é¢ï¼ŒDGSolveråœ¨ä¿®å¤å‡†ç¡®æ€§ã€ç¨³å®šæ€§å’Œå¯æ‰©å±•æ€§æ–¹é¢éƒ½ä¼˜äºæœ€å…ˆè¿›çš„æ–¹æ³•ã€‚ç›¸å…³ä»£ç å’Œæ¨¡å‹å°†åœ¨<a target="_blank" rel="noopener" href="https://github.com/MiliLab/DGSolver%E4%B8%8A%E6%8F%90%E4%BE%9B%E3%80%82">https://github.com/MiliLab/DGSolverä¸Šæä¾›ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.21487v1">PDF</a> </p>
<p><strong>Summary</strong>ï¼šé’ˆå¯¹é€šç”¨æ‰©æ•£æ¨¡å‹åœ¨å›¾åƒä¿®å¤æ–¹é¢çš„ä¸è¶³ï¼Œæå‡ºä¸€ç§åä¸ºDGSolverçš„é€šç”¨æ‰©æ•£æ±‚è§£å™¨ï¼Œé‡‡ç”¨ç²¾ç¡®å¸¸å¾®åˆ†æ–¹ç¨‹å’Œé«˜é˜¶æ±‚è§£å™¨æ¥æé«˜ä¿®å¤å‡†ç¡®æ€§å’Œæ•ˆç‡ã€‚ç»“åˆé€šç”¨åé‡‡æ ·ç­–ç•¥è¿›è¡Œå™ªå£°ä¼°è®¡å’Œé€†å‘æ¨ç†è¯¯å·®æ ¡æ­£ï¼Œæé«˜ä¿®å¤è´¨é‡ã€‚åœ¨å¤šé¡¹å®éªŒä¸­ï¼ŒDGSolveråœ¨ä¿®å¤å‡†ç¡®æ€§ã€ç¨³å®šæ€§å’Œå¯æ‰©å±•æ€§æ–¹é¢å‡ä¼˜äºç°æœ‰æ–¹æ³•ã€‚</p>
<p><strong>Key Takeaways</strong>ï¼š</p>
<ol>
<li>ç°æœ‰æ‰©æ•£æ¨¡å‹åœ¨å›¾åƒä¿®å¤ä¸­é¢ä¸´æŒ‘æˆ˜ï¼Œå¦‚ç´¯ç§¯è¯¯å·®å’Œå¹³è¡¡é€€åŒ–è¡¨ç¤ºä¸ä¿®å¤è´¨é‡çš„é—®é¢˜ã€‚</li>
<li>æå‡ºDGSolverï¼Œé‡‡ç”¨ç²¾ç¡®å¸¸å¾®åˆ†æ–¹ç¨‹å’Œé«˜é˜¶æ±‚è§£å™¨æ”¹å–„ä¿®å¤æ•ˆç‡å’Œå‡†ç¡®æ€§ã€‚</li>
<li>é‡‡ç”¨åŸºäºé˜Ÿåˆ—çš„åŠ é€Ÿé‡‡æ ·ç­–ç•¥æé«˜æ€§èƒ½ã€‚</li>
<li>ç»“åˆé€šç”¨åé‡‡æ ·ä»¥æ›´å¥½åœ°è¿‘ä¼¼æµå½¢çº¦æŸæ¢¯åº¦ï¼Œå‡†ç¡®ä¼°è®¡å™ªå£°å¹¶çº æ­£é€†å‘æ¨ç†è¯¯å·®ã€‚</li>
<li>DGSolveråœ¨å¤šé¡¹å®éªŒä¸­çš„ä¿®å¤å‡†ç¡®æ€§ã€ç¨³å®šæ€§å’Œå¯æ‰©å±•æ€§ä¼˜äºç°æœ‰æ–¹æ³•ã€‚</li>
<li>DGSolverä»£ç å’Œæ¨¡å‹å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/MiliLab/DGSolver%E4%B8%8A%E8%8E%B7%E3%80%82">https://github.com/MiliLab/DGSolverä¸Šè·å–ã€‚</a></li>
<li>DGSolverè®¾è®¡å…·æœ‰æ™®é€‚æ€§ï¼Œå¯åº”ç”¨äºå¤šç§å›¾åƒä¿®å¤ä»»åŠ¡ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.21487">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-f045a63e71be310818c0262a3fe65eef.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-2ea14c0d296a3d3293494d893af5dcb1.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c7defe55add8baabc0eafec95e88b12d.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-8577738c701f00cdf6e825c271f94fdc.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="IDDM-Bridging-Synthetic-to-Real-Domain-Gap-from-Physics-Guided-Diffusion-for-Real-world-Image-Dehazing"><a href="#IDDM-Bridging-Synthetic-to-Real-Domain-Gap-from-Physics-Guided-Diffusion-for-Real-world-Image-Dehazing" class="headerlink" title="IDDM: Bridging Synthetic-to-Real Domain Gap from Physics-Guided   Diffusion for Real-world Image Dehazing"></a>IDDM: Bridging Synthetic-to-Real Domain Gap from Physics-Guided   Diffusion for Real-world Image Dehazing</h2><p><strong>Authors:Shijun Zhou, Yajing Liu, Chunhui Hao, Zhiyuan Liu, Jiandong Tian</strong></p>
<p>Due to the domain gap between real-world and synthetic hazy images, current data-driven dehazing algorithms trained on synthetic datasets perform well on synthetic data but struggle to generalize to real-world scenarios. To address this challenge, we propose \textbf{I}mage \textbf{D}ehazing \textbf{D}iffusion \textbf{M}odels (IDDM), a novel diffusion process that incorporates the atmospheric scattering model into noise diffusion. IDDM aims to use the gradual haze formation process to help the denoising Unet robustly learn the distribution of clear images from the conditional input hazy images. We design a specialized training strategy centered around IDDM. Diffusion models are leveraged to bridge the domain gap from synthetic to real-world, while the atmospheric scattering model provides physical guidance for haze formation. During the forward process, IDDM simultaneously introduces haze and noise into clear images, and then robustly separates them during the sampling process. By training with physics-guided information, IDDM shows the ability of domain generalization, and effectively restores the real-world hazy images despite being trained on synthetic datasets. Extensive experiments demonstrate the effectiveness of our method through both quantitative and qualitative comparisons with state-of-the-art approaches. </p>
<blockquote>
<p>ç”±äºçœŸå®ä¸–ç•Œå’Œåˆæˆé›¾å›¾åƒä¹‹é—´çš„é¢†åŸŸå·®è·ï¼Œå½“å‰åŸºäºåˆæˆæ•°æ®é›†è®­ç»ƒçš„æ•°æ®é©±åŠ¨å»é›¾ç®—æ³•åœ¨åˆæˆæ•°æ®ä¸Šè¡¨ç°è‰¯å¥½ï¼Œä½†åœ¨çœŸå®åœºæ™¯ä¸­çš„æ³›åŒ–èƒ½åŠ›è¾ƒå·®ã€‚ä¸ºäº†åº”å¯¹è¿™ä¸€æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†å›¾åƒå»é›¾æ‰©æ•£æ¨¡å‹ï¼ˆIDDMï¼‰ï¼Œè¿™æ˜¯ä¸€ç§æ–°çš„æ‰©æ•£è¿‡ç¨‹ï¼Œå°†å¤§æ°”æ•£å°„æ¨¡å‹èå…¥å™ªå£°æ‰©æ•£ä¸­ã€‚IDDMæ—¨åœ¨åˆ©ç”¨é€æ­¥çš„é›¾å½¢æˆè¿‡ç¨‹ï¼Œå¸®åŠ©å»å™ªU-Netä»æ¡ä»¶è¾“å…¥çš„æœ‰é›¾å›¾åƒä¸­ç¨³å¥åœ°å­¦ä¹ æ¸…æ™°å›¾åƒåˆ†å¸ƒã€‚æˆ‘ä»¬å›´ç»•IDDMè®¾è®¡äº†ä¸€ç§ä¸“é—¨çš„è®­ç»ƒç­–ç•¥ã€‚æ‰©æ•£æ¨¡å‹è¢«ç”¨æ¥å¼¥åˆåˆæˆå’ŒçœŸå®ä¸–ç•Œä¹‹é—´çš„é¢†åŸŸå·®è·ï¼Œè€Œå¤§æ°”æ•£å°„æ¨¡å‹åˆ™ä¸ºé›¾çš„å½¢æˆæä¾›äº†ç‰©ç†æŒ‡å¯¼ã€‚åœ¨æ­£å‘è¿‡ç¨‹ä¸­ï¼ŒIDDMåŒæ—¶å°†é›¾å’Œå™ªå£°å¼•å…¥æ¸…æ™°å›¾åƒï¼Œç„¶ååœ¨é‡‡æ ·è¿‡ç¨‹ä¸­ç¨³å¥åœ°åˆ†ç¦»å®ƒä»¬ã€‚é€šè¿‡ç‰©ç†æŒ‡å¯¼ä¿¡æ¯è¿›è¡Œè®­ç»ƒï¼ŒIDDMå±•ç°å‡ºé¢†åŸŸæ³›åŒ–çš„èƒ½åŠ›ï¼Œå³ä½¿åœ¨åˆæˆæ•°æ®é›†ä¸Šè®­ç»ƒï¼Œä¹Ÿèƒ½æœ‰æ•ˆåœ°æ¢å¤çœŸå®ä¸–ç•Œçš„é›¾å›¾åƒã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•ä¸æœ€å…ˆè¿›çš„æ–¹æ³•ç›¸æ¯”ï¼Œåœ¨å®šé‡å’Œå®šæ€§æ¯”è¾ƒä¸­éƒ½è¡¨ç°å‡ºæœ‰æ•ˆæ€§ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.21385v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºä¸€ç§åä¸ºå›¾åƒå»é›¾æ‰©æ•£æ¨¡å‹ï¼ˆIDDMï¼‰çš„æ–°æ–¹æ³•ï¼Œæ—¨åœ¨è§£å†³åˆæˆæ•°æ®é›†è®­ç»ƒçš„ç°æœ‰æ•°æ®é©±åŠ¨å»é›¾ç®—æ³•åœ¨çœŸå®ä¸–ç•Œåœºæ™¯ä¸­çš„æ³›åŒ–æ€§èƒ½æŒ‘æˆ˜ã€‚é€šè¿‡å°†å¤§æ°”æ•£å°„æ¨¡å‹èå…¥å™ªå£°æ‰©æ•£ï¼ŒIDDMåˆ©ç”¨æ¸è¿›çš„é›¾å½¢æˆè¿‡ç¨‹å¸®åŠ©å»å™ªUnetä»æ¡ä»¶è¾“å…¥é›¾å›¾åƒä¸­å­¦ä¹ æ¸…æ™°å›¾åƒåˆ†å¸ƒã€‚é€šè¿‡è®¾è®¡ä»¥IDDMä¸ºä¸­å¿ƒçš„è®­ç»ƒç­–ç•¥ï¼Œåˆ©ç”¨æ‰©æ•£æ¨¡å‹ç¼©å°åˆæˆæ•°æ®ä¸çœŸå®ä¸–ç•Œä¹‹é—´çš„é¢†åŸŸå·®è·ï¼ŒåŒæ—¶å¤§æ°”æ•£å°„æ¨¡å‹ä¸ºé›¾çš„å½¢æˆæä¾›ç‰©ç†æŒ‡å¯¼ã€‚å®éªŒè¯æ˜ï¼Œè¯¥æ–¹æ³•åœ¨åˆæˆæ•°æ®é›†ä¸Šè®­ç»ƒåï¼Œèƒ½æœ‰æ•ˆæ¢å¤çœŸå®ä¸–ç•Œä¸­çš„é›¾å›¾åƒã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å½“å‰æ•°æ®é©±åŠ¨çš„å»é›¾ç®—æ³•åœ¨çœŸå®ä¸–ç•Œåœºæ™¯ä¸­æ³›åŒ–æ€§èƒ½è¾ƒå·®ï¼Œä¸»è¦åŸå› æ˜¯åˆæˆå›¾åƒå’ŒçœŸå®ä¸–ç•Œå›¾åƒä¹‹é—´çš„åŸŸå·®è·ã€‚</li>
<li>æå‡ºäº†ä¸€ç§æ–°çš„å›¾åƒå»é›¾æ‰©æ•£æ¨¡å‹ï¼ˆIDDMï¼‰ï¼Œå°†å¤§æ°”æ•£å°„æ¨¡å‹èå…¥å™ªå£°æ‰©æ•£ä¸­ã€‚</li>
<li>IDDMåˆ©ç”¨æ¸è¿›çš„é›¾å½¢æˆè¿‡ç¨‹å¸®åŠ©å»å™ªUnetä»æ¡ä»¶è¾“å…¥é›¾å›¾åƒä¸­å­¦ä¹ æ¸…æ™°å›¾åƒåˆ†å¸ƒã€‚</li>
<li>è®¾è®¡äº†ä»¥IDDMä¸ºä¸­å¿ƒçš„è®­ç»ƒç­–ç•¥ï¼Œåˆ©ç”¨æ‰©æ•£æ¨¡å‹ç¼©å°åˆæˆæ•°æ®å’ŒçœŸå®ä¸–ç•Œä¹‹é—´çš„é¢†åŸŸå·®è·ã€‚</li>
<li>å¤§æ°”æ•£å°„æ¨¡å‹ä¸ºé›¾çš„å½¢æˆæä¾›ç‰©ç†æŒ‡å¯¼ï¼Œä½¿å¾—IDDMèƒ½å¤Ÿæ›´æœ‰æ•ˆåœ°æ¢å¤çœŸå®ä¸–ç•Œçš„é›¾å›¾åƒã€‚</li>
<li>IDDMåœ¨å®šé‡å’Œå®šæ€§æ¯”è¾ƒæ–¹é¢å‡æ˜¾ç¤ºå‡ºå…¶æœ‰æ•ˆæ€§ï¼Œä¸ç°æœ‰å…ˆè¿›æ–¹æ³•ç›¸æ¯”å…·æœ‰ä¼˜åŠ¿ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.21385">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-26d0939fc277001a4bbd70efb0d190c8.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-db1630cdd4dd3e88421d9f411362d3d5.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-052162f8e25e52986f17d40ae111114e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d192fbf780041bfa2e76088cfb5b5cf0.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-67b2022990e1105873930134229afa08.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="Sparse-to-Sparse-Training-of-Diffusion-Models"><a href="#Sparse-to-Sparse-Training-of-Diffusion-Models" class="headerlink" title="Sparse-to-Sparse Training of Diffusion Models"></a>Sparse-to-Sparse Training of Diffusion Models</h2><p><strong>Authors:InÃªs Cardoso Oliveira, Decebal Constantin Mocanu, Luis A. Leiva</strong></p>
<p>Diffusion models (DMs) are a powerful type of generative models that have achieved state-of-the-art results in various image synthesis tasks and have shown potential in other domains, such as natural language processing and temporal data modeling. Despite their stable training dynamics and ability to produce diverse high-quality samples, DMs are notorious for requiring significant computational resources, both in the training and inference stages. Previous work has focused mostly on increasing the efficiency of model inference. This paper introduces, for the first time, the paradigm of sparse-to-sparse training to DMs, with the aim of improving both training and inference efficiency. We focus on unconditional generation and train sparse DMs from scratch (Latent Diffusion and ChiroDiff) on six datasets using three different methods (Static-DM, RigL-DM, and MagRan-DM) to study the effect of sparsity in model performance. Our experiments show that sparse DMs are able to match and often outperform their Dense counterparts, while substantially reducing the number of trainable parameters and FLOPs. We also identify safe and effective values to perform sparse-to-sparse training of DMs. </p>
<blockquote>
<p>æ‰©æ•£æ¨¡å‹ï¼ˆDMsï¼‰æ˜¯ä¸€ç§å¼ºå¤§çš„ç”Ÿæˆæ¨¡å‹ï¼Œåœ¨å„ç§å›¾åƒåˆæˆä»»åŠ¡ä¸­è¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ°´å¹³ï¼Œå¹¶åœ¨å…¶ä»–é¢†åŸŸå¦‚è‡ªç„¶è¯­è¨€å¤„ç†å’Œæ—¶åºæ•°æ®å»ºæ¨¡ä¸­æ˜¾ç¤ºå‡ºæ½œåŠ›ã€‚å°½ç®¡DMså…·æœ‰ç¨³å®šçš„è®­ç»ƒåŠ¨åŠ›å¹¶èƒ½å¤Ÿäº§ç”Ÿå¤šæ ·åŒ–çš„é«˜è´¨é‡æ ·æœ¬ï¼Œä½†å®ƒä»¬å´ä»¥åœ¨è®­ç»ƒå’Œæ¨ç†é˜¶æ®µéƒ½éœ€è¦å¤§é‡è®¡ç®—èµ„æºè€Œé—»åã€‚ä»¥å‰çš„å·¥ä½œä¸»è¦é›†ä¸­åœ¨æé«˜æ¨¡å‹æ¨ç†çš„æ•ˆç‡ã€‚æœ¬æ–‡é¦–æ¬¡å°†ç¨€ç–åˆ°ç¨€ç–çš„è®­ç»ƒèŒƒå¼å¼•å…¥æ‰©æ•£æ¨¡å‹ï¼Œæ—¨åœ¨æé«˜è®­ç»ƒå’Œæ¨ç†çš„æ•ˆç‡ã€‚æˆ‘ä»¬å…³æ³¨æ— æ¡ä»¶ç”Ÿæˆï¼Œä»é›¶å¼€å§‹è®­ç»ƒç¨€ç–æ‰©æ•£æ¨¡å‹ï¼ˆæ½œåœ¨æ‰©æ•£å’ŒChiroDiffï¼‰ï¼Œåœ¨å…­ä¸ªæ•°æ®é›†ä¸Šä½¿ç”¨ä¸‰ç§ä¸åŒçš„æ–¹æ³•ï¼ˆStatic-DMã€RigL-DMå’ŒMagRan-DMï¼‰æ¥ç ”ç©¶ç¨€ç–æ€§å¯¹æ¨¡å‹æ€§èƒ½çš„å½±å“ã€‚æˆ‘ä»¬çš„å®éªŒè¡¨æ˜ï¼Œç¨€ç–DMsèƒ½å¤ŸåŒ¹é…ç”šè‡³è¶…è¶Šå…¶å¯†é›†å¯¹åº”æ¨¡å‹çš„è¡¨ç°ï¼ŒåŒæ—¶å¤§å¤§å‡å°‘å¯è®­ç»ƒå‚æ•°å’Œæµ®ç‚¹è¿ç®—æ¬¡æ•°ã€‚æˆ‘ä»¬è¿˜ç¡®å®šäº†è¿›è¡ŒDMsçš„ç¨€ç–åˆ°ç¨€ç–è®­ç»ƒçš„å®‰å…¨å’Œæœ‰æ•ˆå€¼ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.21380v1">PDF</a> </p>
<p><strong>æ‘˜è¦</strong></p>
<p>æ‰©æ•£æ¨¡å‹ï¼ˆDMsï¼‰æ˜¯ä¸€ç§å¼ºå¤§çš„ç”Ÿæˆæ¨¡å‹ï¼Œåœ¨å„ç§å›¾åƒåˆæˆä»»åŠ¡ä¸­å–å¾—äº†æœ€æ–°æˆæœï¼Œå¹¶åœ¨è‡ªç„¶è¯­è¨€å¤„ç†å’Œæ—¶åºæ•°æ®å»ºæ¨¡ç­‰é¢†åŸŸæ˜¾ç¤ºå‡ºæ½œåŠ›ã€‚å°½ç®¡DMså…·æœ‰ç¨³å®šçš„è®­ç»ƒåŠ¨åŠ›å­¦å’Œäº§ç”Ÿå¤šæ ·åŒ–é«˜è´¨é‡æ ·æœ¬çš„èƒ½åŠ›ï¼Œä½†å®ƒä»¬å´åœ¨è®­ç»ƒå’Œæ¨ç†é˜¶æ®µéƒ½éœ€è¦å¤§é‡çš„è®¡ç®—èµ„æºã€‚ä»¥å‰çš„å·¥ä½œä¸»è¦é›†ä¸­åœ¨æé«˜æ¨¡å‹æ¨ç†çš„æ•ˆç‡ã€‚æœ¬æ–‡é¦–æ¬¡å°†ç¨€ç–åˆ°ç¨€ç–çš„è®­ç»ƒèŒƒå¼å¼•å…¥åˆ°DMsä¸­ï¼Œæ—¨åœ¨æé«˜è®­ç»ƒå’Œæ¨ç†çš„æ•ˆç‡ã€‚æˆ‘ä»¬ä¸“æ³¨äºæ— æ¡ä»¶ç”Ÿæˆï¼Œä½¿ç”¨ä¸‰ç§ä¸åŒçš„æ–¹æ³•ï¼ˆStatic-DMã€RigL-DMå’ŒMagRan-DMï¼‰åœ¨å…­ä¸ªæ•°æ®é›†ä¸Šä»å¤´å¼€å§‹è®­ç»ƒç¨€ç–DMsï¼ˆæ½œåœ¨æ‰©æ•£å’ŒChiroDiffï¼‰ã€‚å®éªŒè¡¨æ˜ï¼Œç¨€ç–DMsèƒ½å¤ŸåŒ¹é…ç”šè‡³è¶…è¶Šå…¶å¯†é›†å¯¹åº”æ¨¡å‹çš„è¡¨ç°ï¼ŒåŒæ—¶å¤§å¹…å‡å°‘å¯è®­ç»ƒå‚æ•°å’Œæµ®ç‚¹è¿ç®—æ¬¡æ•°ã€‚æˆ‘ä»¬è¿˜ç¡®å®šäº†è¿›è¡ŒDMsçš„ç¨€ç–åˆ°ç¨€ç–è®­ç»ƒçš„å®‰å…¨å’Œæœ‰æ•ˆå€¼ã€‚</p>
<p><strong>è¦ç‚¹</strong></p>
<ol>
<li>æ‰©æ•£æ¨¡å‹ï¼ˆDMsï¼‰åœ¨å›¾åƒåˆæˆç­‰é¢†åŸŸè¡¨ç°å‡ºå¼ºå¤§çš„ç”Ÿæˆèƒ½åŠ›ã€‚</li>
<li>DMsåœ¨è®­ç»ƒå’Œæ¨ç†é˜¶æ®µéƒ½éœ€è¦å¤§é‡è®¡ç®—èµ„æºã€‚</li>
<li>æœ¬æ–‡é¦–æ¬¡å¼•å…¥ç¨€ç–åˆ°ç¨€ç–çš„è®­ç»ƒèŒƒå¼åˆ°DMsä¸­ï¼Œæ—¨åœ¨æé«˜è®­ç»ƒå’Œæ¨ç†çš„æ•ˆç‡ã€‚</li>
<li>åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šå®éªŒè¡¨æ˜ï¼Œç¨€ç–DMsèƒ½åŒ¹é…ç”šè‡³è¶…è¶Šå¯†é›†DMsçš„è¡¨ç°ã€‚</li>
<li>ç¨€ç–DMsèƒ½å¤§å¹…å‡å°‘å¯è®­ç»ƒå‚æ•°å’Œæµ®ç‚¹è¿ç®—æ¬¡æ•°ã€‚</li>
<li>æœ¬æ–‡æä¾›äº†è¿›è¡ŒDMsçš„ç¨€ç–åˆ°ç¨€ç–è®­ç»ƒçš„æœ‰æ•ˆæ–¹æ³•ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.21380">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-61f78d34c780d486569ba18ed648bc9d.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-5549363362063e5e22423667c4cf7aec.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-74bece3d5e501392582b911afeed596c.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="Nexus-Gen-A-Unified-Model-for-Image-Understanding-Generation-and-Editing"><a href="#Nexus-Gen-A-Unified-Model-for-Image-Understanding-Generation-and-Editing" class="headerlink" title="Nexus-Gen: A Unified Model for Image Understanding, Generation, and   Editing"></a>Nexus-Gen: A Unified Model for Image Understanding, Generation, and   Editing</h2><p><strong>Authors:Hong Zhang, Zhongjie Duan, Xingjun Wang, Yingda Chen, Yuze Zhao, Yu Zhang</strong></p>
<p>Unified multimodal large language models (MLLMs) aim to integrate multimodal understanding and generation abilities through a single framework. Despite their versatility, existing open-source unified models exhibit performance gaps against domain-specific architectures. To bridge this gap, we present Nexus-Gen, a unified model that synergizes the language reasoning capabilities of LLMs with the image synthesis power of diffusion models. To align the embedding space of the LLM and diffusion model, we conduct a dual-phase alignment training process. (1) The autoregressive LLM learns to predict image embeddings conditioned on multimodal inputs, while (2) the vision decoder is trained to reconstruct high-fidelity images from these embeddings. During training the LLM, we identified a critical discrepancy between the autoregressive paradigmâ€™s training and inference phases, where error accumulation in continuous embedding space severely degrades generation quality. To avoid this issue, we introduce a prefilled autoregression strategy that prefills input sequence with position-embedded special tokens instead of continuous embeddings. Through dual-phase training, Nexus-Gen has developed the integrated capability to comprehensively address the image understanding, generation and editing tasks. All models, datasets, and codes are published at <a target="_blank" rel="noopener" href="https://github.com/modelscope/Nexus-Gen.git">https://github.com/modelscope/Nexus-Gen.git</a> to facilitate further advancements across the field. </p>
<blockquote>
<p>ç»Ÿä¸€å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆMLLMï¼‰æ—¨åœ¨é€šè¿‡å•ä¸€æ¡†æ¶æ•´åˆå¤šæ¨¡æ€ç†è§£å’Œç”Ÿæˆèƒ½åŠ›ã€‚å°½ç®¡å®ƒä»¬å…·æœ‰å¤šåŠŸèƒ½æ€§ï¼Œä½†ç°æœ‰çš„å¼€æºç»Ÿä¸€æ¨¡å‹ä¸ç‰¹å®šé¢†åŸŸçš„æ¶æ„ä¹‹é—´ä»å­˜åœ¨ä¸€å®šçš„æ€§èƒ½å·®è·ã€‚ä¸ºäº†å¼¥è¡¥è¿™ä¸€å·®è·ï¼Œæˆ‘ä»¬æå‡ºäº†Nexus-Genï¼Œè¿™æ˜¯ä¸€æ¬¾ç»Ÿä¸€æ¨¡å‹ï¼Œå®ƒååŒäº†LLMçš„è¯­è¨€æ¨ç†èƒ½åŠ›ä¸æ‰©æ•£æ¨¡å‹çš„å›¾åƒåˆæˆèƒ½åŠ›ã€‚ä¸ºäº†å¯¹é½LLMå’Œæ‰©æ•£æ¨¡å‹çš„åµŒå…¥ç©ºé—´ï¼Œæˆ‘ä»¬è¿›è¡Œäº†åŒé˜¶æ®µå¯¹é½è®­ç»ƒè¿‡ç¨‹ã€‚ï¼ˆ1ï¼‰è‡ªå›å½’LLMå­¦ä¹ æ ¹æ®å¤šæ¨¡æ€è¾“å…¥é¢„æµ‹å›¾åƒåµŒå…¥ï¼Œï¼ˆ2ï¼‰è§†è§‰è§£ç å™¨åˆ™è®­ç»ƒä»è¿™äº›åµŒå…¥ä¸­é‡å»ºé«˜ä¿çœŸå›¾åƒã€‚åœ¨è®­ç»ƒLLMçš„è¿‡ç¨‹ä¸­ï¼Œæˆ‘ä»¬å‘ç°è‡ªå›å½’èŒƒå¼è®­ç»ƒä¸æ¨ç†é˜¶æ®µä¹‹é—´å­˜åœ¨å…³é”®å·®å¼‚ï¼Œè¿ç»­åµŒå…¥ç©ºé—´ä¸­çš„è¯¯å·®ç´¯ç§¯ä¼šä¸¥é‡é™ä½ç”Ÿæˆè´¨é‡ã€‚ä¸ºäº†é¿å…è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§é¢„å¡«å……è‡ªå›å½’ç­–ç•¥ï¼Œè¯¥ç­–ç•¥ç”¨ä½ç½®åµŒå…¥ç‰¹æ®Šä»¤ç‰Œé¢„å¡«å……è¾“å…¥åºåˆ—ï¼Œè€Œä¸æ˜¯è¿ç»­åµŒå…¥ã€‚é€šè¿‡åŒé˜¶æ®µè®­ç»ƒï¼ŒNexus-Genå·²ç»å…·å¤‡äº†å…¨é¢è§£å†³å›¾åƒç†è§£ã€ç”Ÿæˆå’Œç¼–è¾‘ä»»åŠ¡çš„èƒ½åŠ›ã€‚æ‰€æœ‰æ¨¡å‹ã€æ•°æ®é›†å’Œä»£ç éƒ½å·²å‘å¸ƒåœ¨<a target="_blank" rel="noopener" href="https://github.com/modelscope/Nexus-Gen.git%EF%BC%8C%E4%BB%A5%E4%BF%83%E8%BF%9B%E8%AF%A5%E9%A2%86%E5%9F%9F%E7%9A%84%E8%BF%9B%E4%B8%80%E6%AD%A5%E5%8F%91%E5%B1%95%E3%80%82">https://github.com/modelscope/Nexus-Gen.gitï¼Œä»¥ä¿ƒè¿›è¯¥é¢†åŸŸçš„è¿›ä¸€æ­¥å‘å±•ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.21356v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>åŸºäºç»Ÿä¸€å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰çš„ç›®æ ‡æ˜¯é€šè¿‡å•ä¸€æ¡†æ¶æ•´åˆå¤šæ¨¡æ€ç†è§£å’Œç”Ÿæˆèƒ½åŠ›ã€‚ç°æœ‰å¼€æºç»Ÿä¸€æ¨¡å‹åœ¨é¢†åŸŸç‰¹å®šæ¶æ„æ–¹é¢å­˜åœ¨æ€§èƒ½å·®è·ã€‚ä¸ºäº†ç¼©å°è¿™ä¸€å·®è·ï¼Œæˆ‘ä»¬æå‡ºäº†Nexus-Genï¼Œä¸€ä¸ªèåˆäº†è¯­è¨€æ¨ç†èƒ½åŠ›å’Œæ‰©æ•£æ¨¡å‹å›¾åƒåˆæˆèƒ½åŠ›çš„ç»Ÿä¸€æ¨¡å‹ã€‚é€šè¿‡åŒé˜¶æ®µå¯¹é½è®­ç»ƒè¿‡ç¨‹ï¼Œå®ç°äº†LLMå’Œæ‰©æ•£æ¨¡å‹çš„åµŒå…¥ç©ºé—´å¯¹é½ã€‚ç¬¬ä¸€é˜¶æ®µæ˜¯è‡ªé€‚åº”å›å½’LLMå­¦ä¹ åŸºäºå¤šæ¨¡æ€è¾“å…¥çš„å›¾åƒåµŒå…¥é¢„æµ‹ï¼Œç¬¬äºŒé˜¶æ®µæ˜¯è§†è§‰è§£ç å™¨ä»è¿™äº›åµŒå…¥ä¸­é‡å»ºé«˜ä¿çœŸå›¾åƒã€‚åœ¨è®­ç»ƒLLMè¿‡ç¨‹ä¸­ï¼Œæˆ‘ä»¬å‘ç°è‡ªé€‚åº”å›å½’èŒƒå¼åœ¨è®­ç»ƒå’Œæ¨ç†é˜¶æ®µä¹‹é—´å­˜åœ¨å…³é”®å·®å¼‚ï¼Œè¿ç»­åµŒå…¥ç©ºé—´ä¸­çš„è¯¯å·®ç´¯ç§¯ä¸¥é‡é™ä½äº†ç”Ÿæˆè´¨é‡ã€‚ä¸ºäº†é¿å…è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§é¢„å¡«å……è‡ªé€‚åº”å›å½’ç­–ç•¥ï¼Œè¯¥ç­–ç•¥ç”¨ä½ç½®åµŒå…¥ç‰¹æ®Šä»¤ç‰Œé¢„å¡«å……è¾“å…¥åºåˆ—ï¼Œè€Œä¸æ˜¯è¿ç»­åµŒå…¥ã€‚é€šè¿‡åŒé˜¶æ®µè®­ç»ƒï¼ŒNexus-Genå…·å¤‡äº†å…¨é¢è§£å†³å›¾åƒç†è§£ã€ç”Ÿæˆå’Œç¼–è¾‘ä»»åŠ¡çš„ç»¼åˆèƒ½åŠ›ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ç»Ÿä¸€å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰çš„ç›®æ ‡æ˜¯æ•´åˆå¤šæ¨¡æ€ç†è§£å’Œç”Ÿæˆèƒ½åŠ›ã€‚</li>
<li>ç°æœ‰å¼€æºç»Ÿä¸€æ¨¡å‹åœ¨ç‰¹å®šé¢†åŸŸæ€§èƒ½æ–¹é¢å­˜åœ¨å·®è·ã€‚</li>
<li>Nexus-Genèåˆäº†è¯­è¨€æ¨ç†èƒ½åŠ›å’Œæ‰©æ•£æ¨¡å‹çš„å›¾åƒåˆæˆèƒ½åŠ›ã€‚</li>
<li>é€šè¿‡åŒé˜¶æ®µå¯¹é½è®­ç»ƒè¿‡ç¨‹ï¼Œå®ç°äº†LLMå’Œæ‰©æ•£æ¨¡å‹çš„åµŒå…¥ç©ºé—´å¯¹é½ã€‚</li>
<li>åœ¨è®­ç»ƒLLMè¿‡ç¨‹ä¸­ï¼Œå‘ç°å¹¶è§£å†³äº†è‡ªé€‚åº”å›å½’èŒƒå¼çš„å…³é”®å·®å¼‚é—®é¢˜ã€‚</li>
<li>å¼•å…¥äº†é¢„å¡«å……è‡ªé€‚åº”å›å½’ç­–ç•¥ï¼Œä»¥æé«˜ç”Ÿæˆè´¨é‡ã€‚</li>
<li>Nexus-Genå…·å¤‡å›¾åƒç†è§£ã€ç”Ÿæˆå’Œç¼–è¾‘çš„ç»¼åˆèƒ½åŠ›ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.21356">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-8b08bca29f0be492d8a0eaa935de8e3b.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-e38ca9a369d5342fcb3eaac097539f92.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-f870bede37548c9a3885c4ff0fbd97ed.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-5ce13c70f0d32254591fab13dabe9ae4.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-09a436404eaa50247abe30ab1918b1b8.jpg" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="Efficient-Diffusion-Models-A-Survey"><a href="#Efficient-Diffusion-Models-A-Survey" class="headerlink" title="Efficient Diffusion Models: A Survey"></a>Efficient Diffusion Models: A Survey</h2><p><strong>Authors:Hui Shen, Jingxuan Zhang, Boning Xiong, Rui Hu, Shoufa Chen, Zhongwei Wan, Xin Wang, Yu Zhang, Zixuan Gong, Guangyin Bao, Chaofan Tao, Yongfeng Huang, Ye Yuan, Mi Zhang</strong></p>
<p>Diffusion models have emerged as powerful generative models capable of producing high-quality contents such as images, videos, and audio, demonstrating their potential to revolutionize digital content creation. However, these capabilities come at the cost of their significant computational resources and lengthy generation time, underscoring the critical need to develop efficient techniques for practical deployment. In this survey, we provide a systematic and comprehensive review of research on efficient diffusion models. We organize the literature in a taxonomy consisting of three main categories, covering distinct yet interconnected efficient diffusion model topics from algorithm-level, system-level, and framework perspective, respectively. We have also created a GitHub repository where we organize the papers featured in this survey at <a target="_blank" rel="noopener" href="https://github.com/AIoT-MLSys-Lab/Efficient-Diffusion-Model-Survey">https://github.com/AIoT-MLSys-Lab/Efficient-Diffusion-Model-Survey</a>. We hope our survey can serve as a valuable resource to help researchers and practitioners gain a systematic understanding of efficient diffusion model research and inspire them to contribute to this important and exciting field. </p>
<blockquote>
<p>æ‰©æ•£æ¨¡å‹ä½œä¸ºå¼ºå¤§çš„ç”Ÿæˆæ¨¡å‹å·²ç»å´­éœ²å¤´è§’ï¼Œèƒ½å¤Ÿç”Ÿæˆé«˜è´¨é‡çš„å†…å®¹ï¼Œå¦‚å›¾åƒã€è§†é¢‘å’ŒéŸ³é¢‘ï¼Œæ˜¾ç¤ºå‡ºå®ƒä»¬æœ‰æ½œåŠ›å½»åº•æ”¹å˜æ•°å­—å†…å®¹çš„åˆ›ä½œæ–¹å¼ã€‚ç„¶è€Œï¼Œè¿™äº›èƒ½åŠ›éœ€è¦è€—è´¹å¤§é‡çš„è®¡ç®—èµ„æºå’Œæ¼«é•¿çš„ç”Ÿæˆæ—¶é—´ï¼Œè¿™å‡¸æ˜¾äº†å¼€å‘é«˜æ•ˆæŠ€æœ¯ä»¥ç”¨äºå®é™…éƒ¨ç½²çš„è¿«åˆ‡éœ€æ±‚ã€‚åœ¨è¿™ç¯‡ç»¼è¿°ä¸­ï¼Œæˆ‘ä»¬å¯¹é«˜æ•ˆçš„æ‰©æ•£æ¨¡å‹ç ”ç©¶è¿›è¡Œäº†ç³»ç»Ÿè€Œå…¨é¢çš„å›é¡¾ã€‚æˆ‘ä»¬ä»ç®—æ³•å±‚é¢ã€ç³»ç»Ÿå±‚é¢å’Œæ¡†æ¶è§†è§’ä¸‰ä¸ªä¸»è¦ç±»åˆ«å¯¹æ–‡çŒ®è¿›è¡Œäº†åˆ†ç±»ï¼Œæ¶µç›–äº†ä¸åŒä½†ç›¸äº’å…³è”çš„é«˜æ•ˆæ‰©æ•£æ¨¡å‹ä¸»é¢˜ã€‚æˆ‘ä»¬è¿˜åˆ›å»ºäº†ä¸€ä¸ªGitHubä»“åº“ï¼Œå…¶ä¸­æ•´ç†äº†æœ¬ç»¼è¿°ä¸­æåˆ°çš„è®ºæ–‡ï¼Œåœ°å€ä¸ºï¼š<a target="_blank" rel="noopener" href="https://github.com/AIoT-MLSys-Lab/Efficient-Diffusion-Model-Survey%E3%80%82%E6%88%91%E4%BB%AC%E5%B8%AE%E5%B8%AE%E5%AF%BC%E5%B9%BF%E5%BA%AB%E6%9D%BF%E7%BB%BC%E8%BF%BD%E7%BB%AD%E5%9C%B0%E4%BA%86%E8%A7%A3%E5%AE%BD%E6%B5%94%E6%95%A3%E6%A8%A1%E5%9E%8B%E7%9A%84%E7%A0%94%E7%A9%B6%EF%BC%8C%E5%B9%B6%E6%BF%80%E5%8F%91%E4%BB%96%E4%BB%AC%E5%9C%A8%E8%BF%99%E4%B8%AA%E9%87%8D%E8%A6%81%E4%B8%94%E5%85%B7%E6%9C%89%E6%8C%91%E6%88%98%E6%80%A7%E7%9A%84%E9%A2%86%E5%9F%9F%E8%BF%9B%E8%A1%8C%E5%88%9B%E6%96%B0%E3%80%82">https://github.com/AIoT-MLSys-Lab/Efficient-Diffusion-Model-Surveyã€‚æˆ‘ä»¬å¸Œæœ›è¿™ç¯‡ç»¼è¿°èƒ½å¤Ÿä½œä¸ºæœ‰ä»·å€¼çš„èµ„æºï¼Œå¸®åŠ©ç ”ç©¶äººå‘˜å’Œä»ä¸šè€…ç³»ç»Ÿåœ°äº†è§£é«˜æ•ˆçš„æ‰©æ•£æ¨¡å‹ç ”ç©¶ï¼Œå¹¶æ¿€å‘ä»–ä»¬ä¸ºè¿™ä¸ªé‡è¦è€Œæ¿€åŠ¨äººå¿ƒçš„é¢†åŸŸåšå‡ºè´¡çŒ®ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.06805v2">PDF</a> Published in Transactions on Machine Learning Research (TMLR-2025)</p>
<p><strong>Summary</strong></p>
<p>æ‰©æ•£æ¨¡å‹ä½œä¸ºå¼ºå¤§çš„ç”Ÿæˆæ¨¡å‹ï¼Œåœ¨å›¾åƒã€è§†é¢‘å’ŒéŸ³é¢‘ç­‰å†…å®¹åˆ›ä½œæ–¹é¢è¡¨ç°å‡ºå“è¶Šçš„èƒ½åŠ›ï¼Œå…·æœ‰é©æ–°æ•°å­—å†…å®¹åˆ›ä½œçš„æ½œåŠ›ã€‚ç„¶è€Œï¼Œå…¶å¼ºå¤§çš„èƒ½åŠ›éœ€è¦æ¶ˆè€—å¤§é‡çš„è®¡ç®—èµ„æºå’Œæ—¶é—´ï¼Œå› æ­¤å¼€å‘é«˜æ•ˆçš„æŠ€æœ¯ä»¥å®é™…åº”ç”¨æ˜¾å¾—å°¤ä¸ºé‡è¦ã€‚æœ¬æ¬¡è°ƒç ”ç³»ç»Ÿåœ°ç»¼è¿°äº†å…³äºé«˜æ•ˆæ‰©æ•£æ¨¡å‹çš„ç ”ç©¶ï¼Œå°†æ–‡çŒ®åˆ†ä¸ºç®—æ³•å±‚é¢ã€ç³»ç»Ÿå±‚é¢å’Œæ¡†æ¶å±‚é¢çš„ä¸‰ä¸ªä¸»è¦ç±»åˆ«ï¼Œä»¥å…¨é¢è¦†ç›–ä¸åŒä½†ç›¸äº’å…³è”çš„é«˜æ•ˆæ‰©æ•£æ¨¡å‹ä¸»é¢˜ã€‚æˆ‘ä»¬åˆ›å»ºäº†GitHubä»“åº“ï¼Œæ•´ç†å¹¶åˆ†äº«äº†æœ¬æ¬¡è°ƒç ”ä¸­çš„è®ºæ–‡ï¼Œç½‘å€ä¸ºï¼š[<a target="_blank" rel="noopener" href="https://github.com/AIoT-MLSys-Lab/Efficient-Diffusion-Model-Survey%E3%80%82%E6%88%91%E4%BB%AC%E5%B8%8C%E6%9C%9B%E6%9C%AC%E6%AC%A1%E8%B0%83%E7%A0%94%E8%83%BD%E4%B8%BA%E7%A0%94%E7%A9%B6%E8%80%85%E5%92%8C%E4%BB%8E%E4%B8%9A%E8%80%85%E6%8F%90%E4%BE%9B%E5%AF%B9%E9%AB%98%E6%95%88%E6%89%A9%E6%95%A3%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%85%A8%E9%9D%A2%E7%90%86%E8%A7%A3%EF%BC%8C%E5%B9%B6%E6%BF%80%E5%8F%91%E4%BB%96%E4%BB%AC%E5%9C%A8%E8%BF%99%E4%B8%80%E9%87%8D%E8%A6%81%E4%B8%94%E6%BF%80%E5%8A%A8%E4%BA%BA%E5%BF%83%E7%9A%84%E9%A2%86%E5%9F%9F%E5%81%9A%E5%87%BA%E8%B4%A1%E7%8C%AE%E3%80%82]">https://github.com/AIoT-MLSys-Lab/Efficient-Diffusion-Model-Surveyã€‚æˆ‘ä»¬å¸Œæœ›æœ¬æ¬¡è°ƒç ”èƒ½ä¸ºç ”ç©¶è€…å’Œä»ä¸šè€…æä¾›å¯¹é«˜æ•ˆæ‰©æ•£æ¨¡å‹çš„å…¨é¢ç†è§£ï¼Œå¹¶æ¿€å‘ä»–ä»¬åœ¨è¿™ä¸€é‡è¦ä¸”æ¿€åŠ¨äººå¿ƒçš„é¢†åŸŸåšå‡ºè´¡çŒ®ã€‚]</a>(<a target="_blank" rel="noopener" href="https://github.com/AIoT-MLSys-Lab/Efficient-Diffusion-Model-Survey%E3%80%82%E6%88%91%E4%BB%AC%E5%B8%AE%E5%A4%9A%E5%AF%BB%E7%A0%94%E6%B5%B7%E5%AF%BC%E5%AF%BC%E5%AD%A6%E8%BF%BD%E5%AF%BB%E6%B3%A8%E5%AE%9E%E7%94%A8%E7%9A%84%E6%9C%AC%%EF%BC%88%E4%B8%AD%E6%96%87%E4%B8%BA%E2%80%9C%E6%88%91%E4%BB%AC%E5%B8%8C%E6%9C%9B%E9%80%9A%E8%BF%87%E6%9C%AC%E6%AC%A1%E8%B0%83%E7%A0%94%E5%BC%95%E9%A2%86%E5%AD%A6%E8%80%85%E5%92%8C%E4%BB%8E%E4%B8%9A%E8%80%85%E4%BA%86%E8%A7%A3%E9%AB%98%E6%95%88%E6%89%A9%E6%95%A3%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%9C%80%E6%96%B0%E8%BF%9B%E5%B1%95%E5%B9%B6%E6%BF%80%E5%8F%91%E4%BB%96%E4%BB%AC%E5%AF%B9%E8%BF%99%E4%B8%80%E9%87%8D%E8%A6%81%E9%A2%86%E5%9F%9F%E7%9A%84%E8%B4%A1%E7%8C%AE%E3%80%82%E2%80%9D%EF%BC%89%E6%AD%A4%E5%8F%A5%E8%AF%9D%E7%BB%93%E5%B0%BE%E6%9C%89%E7%9C%81%E7%95%A5%E5%8F%B7%E6%BC%8F%E8%AF%91%E6%83%85%E5%86%B5%EF%BC%89%E6%AD%A4%E5%A4%84%E4%B8%BA%E6%82%A8%E8%BF%9B%E8%A1%8C%E4%BA%86%E5%AE%8C%E6%95%B4%E8%A1%A5%E5%85%85%E3%80%82%E5%BD%93%E5%89%8D%E8%8B%B1%E6%96%87%E9%83%A8%E5%88%86%E5%85%A8%E9%83%A8%E4%B8%BA%E5%AE%8C%E6%95%B4%E7%BF%BB%E8%AF%91%E7%BB%93%E6%9E%9C%E3%80%82%E6%88%91%E4%BB%AC%E6%95%B4%E7%90%86%E7%9A%84%E8%B5%84%E6%BA%90%E8%83%BD%E5%A4%9F%E5%B8%AE%E5%8A%A9%E5%A4%A7%E5%AE%B6%E6%9B%B4%E5%A5%BD%E5%9C%B0%E7%90%86%E8%A7%A3%E5%92%8C%E7%A0%94%E7%A9%B6%E9%AB%98%E6%95%88%E6%89%A9%E6%95%A3%E6%A8%A1%E5%9E%8B%EF%BC%8C%E5%B9%B6%E6%8E%A8%E5%8A%A8%E8%BF%99%E4%B8%80%E9%A2%86%E5%9F%9F%E7%9A%84%E8%BF%9B%E4%B8%80%E6%AD%A5%E5%8F%91%E5%B1%95%E3%80%82%E5%B8%8C%E6%9C%9B%E6%88%91%E4%BB%AC%E7%9A%84%E8%B0%83%E7%A0%94%E8%83%BD%E4%B8%BA%E5%A4%A7%E5%AE%B6%E6%8F%90%E4%BE%9B%E6%9C%89%E4%BB%B7%E5%80%BC%E7%9A%84%E5%8F%82%E8%80%83%E5%92%8C%E5%B8%AE%E5%8A%A9%E3%80%82">https://github.com/AIoT-MLSys-Lab/Efficient-Diffusion-Model-Survey%E3%80%82%E6%88%91%E4%BB%AC%E5%B8%AE%E5%A4%9A%E5%AF%BB%E7%A0%94%E6%B5%B7%E5%AF%BC%E5%AF%BC%E5%AD%A6%E8%BF%BD%E5%AF%BB%E6%B3%A8%E5%AE%9E%E7%94%A8%E7%9A%84%E6%9C%AC%ï¼ˆä¸­æ–‡ä¸ºâ€œæˆ‘ä»¬å¸Œæœ›é€šè¿‡æœ¬æ¬¡è°ƒç ”å¼•é¢†å­¦è€…å’Œä»ä¸šè€…äº†è§£é«˜æ•ˆæ‰©æ•£æ¨¡å‹çš„æœ€æ–°è¿›å±•å¹¶æ¿€å‘ä»–ä»¬å¯¹è¿™ä¸€é‡è¦é¢†åŸŸçš„è´¡çŒ®ã€‚â€ï¼‰æ­¤å¥è¯ç»“å°¾æœ‰çœç•¥å·æ¼è¯‘æƒ…å†µï¼‰æ­¤å¤„ä¸ºæ‚¨è¿›è¡Œäº†å®Œæ•´è¡¥å……ã€‚å½“å‰è‹±æ–‡éƒ¨åˆ†å…¨éƒ¨ä¸ºå®Œæ•´ç¿»è¯‘ç»“æœã€‚æˆ‘ä»¬æ•´ç†çš„èµ„æºèƒ½å¤Ÿå¸®åŠ©å¤§å®¶æ›´å¥½åœ°ç†è§£å’Œç ”ç©¶é«˜æ•ˆæ‰©æ•£æ¨¡å‹ï¼Œå¹¶æ¨åŠ¨è¿™ä¸€é¢†åŸŸçš„è¿›ä¸€æ­¥å‘å±•ã€‚å¸Œæœ›æˆ‘ä»¬çš„è°ƒç ”èƒ½ä¸ºå¤§å®¶æä¾›æœ‰ä»·å€¼çš„å‚è€ƒå’Œå¸®åŠ©ã€‚</a></p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æ‰©æ•£æ¨¡å‹å…·æœ‰å¼ºå¤§çš„ç”Ÿæˆèƒ½åŠ›ï¼Œå°¤å…¶åœ¨å›¾åƒã€è§†é¢‘å’ŒéŸ³é¢‘åˆ›ä½œé¢†åŸŸã€‚</li>
<li>æ‰©æ•£æ¨¡å‹çš„è®¡ç®—èµ„æºæ¶ˆè€—é‡å¤§ï¼Œç”Ÿæˆæ—¶é—´é•¿ï¼Œéœ€å¼€å‘é«˜æ•ˆæŠ€æœ¯æ»¡è¶³å®é™…åº”ç”¨éœ€æ±‚ã€‚</li>
<li>æœ¬æ¬¡è°ƒç ”ç³»ç»Ÿåœ°æ€»ç»“äº†å…³äºé«˜æ•ˆæ‰©æ•£æ¨¡å‹çš„ç ”ç©¶æ–‡çŒ®ï¼Œåˆ†ä¸ºä¸‰ä¸ªä¸»è¦ç±»åˆ«ï¼šç®—æ³•å±‚é¢ã€ç³»ç»Ÿå±‚é¢å’Œæ¡†æ¶å±‚é¢ã€‚</li>
<li>åˆ›å»ºäº†GitHubä»“åº“åˆ†äº«è°ƒç ”è®ºæ–‡ï¼Œä¾¿äºç ”ç©¶è€…å’Œä»ä¸šè€…è·å–èµ„æºã€‚</li>
<li>è°ƒç ”æ—¨åœ¨å¸®åŠ©ç†è§£é«˜æ•ˆæ‰©æ•£æ¨¡å‹çš„æœ€æ–°ç ”ç©¶è¿›å±•ã€‚</li>
<li>æ¿€å‘å¯¹é«˜æ•ˆæ‰©æ•£æ¨¡å‹é¢†åŸŸçš„è´¡çŒ®å’Œåˆ›æ–°ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.06805">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-b52459d56e423d5a44382a950ed3fdf8.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-4d5f08f168cc71a3bf5f02a365c7d57e.jpg" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1><h2 id="Diffusion-Bridge-Implicit-Models"><a href="#Diffusion-Bridge-Implicit-Models" class="headerlink" title="Diffusion Bridge Implicit Models"></a>Diffusion Bridge Implicit Models</h2><p><strong>Authors:Kaiwen Zheng, Guande He, Jianfei Chen, Fan Bao, Jun Zhu</strong></p>
<p>Denoising diffusion bridge models (DDBMs) are a powerful variant of diffusion models for interpolating between two arbitrary paired distributions given as endpoints. Despite their promising performance in tasks like image translation, DDBMs require a computationally intensive sampling process that involves the simulation of a (stochastic) differential equation through hundreds of network evaluations. In this work, we take the first step in fast sampling of DDBMs without extra training, motivated by the well-established recipes in diffusion models. We generalize DDBMs via a class of non-Markovian diffusion bridges defined on the discretized timesteps concerning sampling, which share the same marginal distributions and training objectives, give rise to generative processes ranging from stochastic to deterministic, and result in diffusion bridge implicit models (DBIMs). DBIMs are not only up to 25$\times$ faster than the vanilla sampler of DDBMs but also induce a novel, simple, and insightful form of ordinary differential equation (ODE) which inspires high-order numerical solvers. Moreover, DBIMs maintain the generation diversity in a distinguished way, by using a booting noise in the initial sampling step, which enables faithful encoding, reconstruction, and semantic interpolation in image translation tasks. Code is available at <a target="_blank" rel="noopener" href="https://github.com/thu-ml/DiffusionBridge">https://github.com/thu-ml/DiffusionBridge</a>. </p>
<blockquote>
<p>å»å™ªæ‰©æ•£æ¡¥æ¨¡å‹ï¼ˆDDBMsï¼‰æ˜¯åœ¨ç»™å®šä¸¤ä¸ªä»»æ„é…å¯¹åˆ†å¸ƒä½œä¸ºç«¯ç‚¹æ—¶ï¼Œç”¨äºè¿›è¡Œæ’å€¼çš„æ‰©æ•£æ¨¡å‹çš„å¼ºå¤§å˜ä½“ã€‚å°½ç®¡å®ƒä»¬åœ¨å›¾åƒç¿»è¯‘ç­‰ä»»åŠ¡ä¸­è¡¨ç°å‡ºæœ‰å¸Œæœ›çš„æ€§èƒ½ï¼Œä½†DDBMséœ€è¦è¿›è¡Œè®¡ç®—å¯†é›†å‹çš„é‡‡æ ·è¿‡ç¨‹ï¼Œè¿™æ¶‰åŠé€šè¿‡æ•°ç™¾æ¬¡ç½‘ç»œè¯„ä¼°æ¥æ¨¡æ‹Ÿï¼ˆéšæœºï¼‰å¾®åˆ†æ–¹ç¨‹ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬é‡‡å–äº†åŠ å¿«DDBMsé‡‡æ ·çš„ç¬¬ä¸€æ­¥ï¼Œæ— éœ€é¢å¤–çš„è®­ç»ƒï¼Œè¿™æ˜¯ç”±æ‰©æ•£æ¨¡å‹çš„æ—¢å®šé…æ–¹æ‰€æ¿€å‘çš„ã€‚æˆ‘ä»¬é€šè¿‡å®šä¹‰ä¸€ç±»å…³äºé‡‡æ ·ç¦»æ•£æ—¶é—´æ­¥é•¿çš„éé©¬å°”å¯å¤«æ‰©æ•£æ¡¥æ¥æ¨å¹¿DDBMsï¼Œè¿™äº›æ¡¥å…·æœ‰ç›¸åŒçš„è¾¹ç¼˜åˆ†å¸ƒå’Œè®­ç»ƒç›®æ ‡ï¼Œäº§ç”Ÿä»éšæœºåˆ°ç¡®å®šçš„ç”Ÿæˆè¿‡ç¨‹ï¼Œå¹¶å¯¼è‡´æ‰©æ•£æ¡¥éšå¼æ¨¡å‹ï¼ˆDBIMsï¼‰çš„å‡ºç°ã€‚DBIMsä¸ä»…æ¯”DDBMsçš„åŸç”Ÿé‡‡æ ·å™¨å¿«è¾¾25å€ï¼Œè€Œä¸”è¿˜å¼•å‡ºäº†ä¸€ç§æ–°çš„ã€ç®€å•ä¸”å¯Œæœ‰æ´å¯ŸåŠ›çš„å¸¸å¾®åˆ†æ–¹ç¨‹ï¼ˆODEï¼‰ï¼Œè¿™æ¿€å‘äº†é«˜é˜¶æ•°å€¼æ±‚è§£å™¨çš„çµæ„Ÿã€‚æ­¤å¤–ï¼ŒDBIMsä»¥ç‹¬ç‰¹çš„æ–¹å¼ä¿æŒç”Ÿæˆå¤šæ ·æ€§ï¼Œé€šè¿‡åœ¨åˆå§‹é‡‡æ ·æ­¥éª¤ä¸­ä½¿ç”¨å¼•å¯¼å™ªå£°ï¼Œè¿™ä½¿å¾—åœ¨å›¾åƒç¿»è¯‘ä»»åŠ¡ä¸­èƒ½å¤Ÿå®ç°å¿ å®ç¼–ç ã€é‡å»ºå’Œè¯­ä¹‰æ’å€¼ã€‚ä»£ç å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/thu-ml/DiffusionBridge%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/thu-ml/DiffusionBridgeæ‰¾åˆ°ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2405.15885v6">PDF</a> Accepted at ICLR 2025</p>
<p><strong>Summary</strong></p>
<p>DDBMsï¼ˆå»å™ªæ‰©æ•£æ¡¥æ¢æ¨¡å‹ï¼‰æ˜¯ä¸€ç§å¼ºå¤§çš„æ‰©æ•£æ¨¡å‹ï¼Œèƒ½å¤Ÿåœ¨ä¸¤ä¸ªä»»æ„é…å¯¹åˆ†å¸ƒä¹‹é—´è¿›è¡Œæ’å€¼ã€‚ä½†å…¶é‡‡æ ·è¿‡ç¨‹è®¡ç®—å¯†é›†ï¼Œæ¶‰åŠæ¨¡æ‹Ÿå¾®åˆ†æ–¹ç¨‹å’Œå¤§é‡ç½‘ç»œè¯„ä¼°ã€‚æœ¬ç ”ç©¶é¦–æ¬¡å°è¯•å¯¹DDBMsè¿›è¡Œå¿«é€Ÿé‡‡æ ·ï¼Œæ— éœ€é¢å¤–è®­ç»ƒã€‚é€šè¿‡å®šä¹‰éé©¬å°”å¯å¤«æ‰©æ•£æ¡¥æ¢çš„ç±»åˆ«ï¼Œæˆ‘ä»¬æå‡ºäº†æ‰©æ•£æ¡¥æ¢éšæ¨¡å‹ï¼ˆDBIMsï¼‰ï¼Œå®ƒä»¬å…·æœ‰ç›¸åŒçš„è¾¹é™…åˆ†å¸ƒå’ŒåŸ¹è®­ç›®æ ‡ï¼Œç”Ÿæˆè¿‡ç¨‹ä»éšæœºåˆ°ç¡®å®šæ€§ä¸ç­‰ã€‚DBIMsä¸ä»…ä½¿é‡‡æ ·é€Ÿåº¦æé«˜äº†25å€ï¼Œè¿˜å¯å‘äº†ä¸€ç§æ–°å‹ç®€å•çš„å¸¸å¾®åˆ†æ–¹ç¨‹ï¼ˆODEï¼‰ã€‚æ­¤å¤–ï¼Œé€šè¿‡åˆå§‹é‡‡æ ·æ­¥éª¤ä¸­çš„å¼•å¯¼å™ªå£°ï¼ŒDBIMsä»¥ç‹¬ç‰¹çš„æ–¹å¼ä¿æŒäº†ç”Ÿæˆçš„å¤šæ ·æ€§ï¼Œä½¿å›¾åƒç¿»è¯‘ä»»åŠ¡ä¸­çš„ç¼–ç ã€é‡å»ºå’Œè¯­ä¹‰æ’å€¼æ›´åŠ çœŸå®ã€‚ç›¸å…³ä»£ç å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/thu-ml/DiffusionBridge">é“¾æ¥</a>æ‰¾åˆ°ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>DDBMs æ˜¯ä¸€ç§èƒ½å¤Ÿåœ¨ä¸¤ä¸ªä»»æ„é…å¯¹åˆ†å¸ƒä¹‹é—´æ’å€¼çš„å¼ºå¤§æ‰©æ•£æ¨¡å‹ã€‚</li>
<li>DDBMs çš„é‡‡æ ·è¿‡ç¨‹è®¡ç®—å¯†é›†ï¼Œæ¶‰åŠæ¨¡æ‹Ÿå¾®åˆ†æ–¹ç¨‹å’Œå¤§é‡ç½‘ç»œè¯„ä¼°ã€‚</li>
<li>æœ¬ç ”ç©¶é¦–æ¬¡å°è¯•å¯¹ DDBMs è¿›è¡Œå¿«é€Ÿé‡‡æ ·ï¼Œæå‡ºäº†æ‰©æ•£æ¡¥æ¢éšæ¨¡å‹ï¼ˆDBIMsï¼‰ã€‚</li>
<li>DBIMs é€šè¿‡å®šä¹‰éé©¬å°”å¯å¤«æ‰©æ•£æ¡¥æ¢å®ç°å¿«é€Ÿé‡‡æ ·ï¼Œå…·æœ‰ç›¸åŒçš„è¾¹é™…åˆ†å¸ƒå’ŒåŸ¹è®­ç›®æ ‡ã€‚</li>
<li>DBIMs çš„ç”Ÿæˆè¿‡ç¨‹åŒ…æ‹¬ä»éšæœºåˆ°ç¡®å®šæ€§çš„å¤šç§å½¢æ€ã€‚</li>
<li>DBIMs æé«˜äº†é‡‡æ ·é€Ÿåº¦ï¼ŒåŒæ—¶ä¿æŒäº†ç”Ÿæˆçš„å¤šæ ·æ€§ï¼Œé€šè¿‡åˆå§‹é‡‡æ ·æ­¥éª¤ä¸­çš„å¼•å¯¼å™ªå£°å®ç°ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2405.15885">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-02081eaef27d75b9cc468b098557d710.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-2168847ad73418759c0cf49bea42be57.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-9c68df5f067cc793625a158171eb849a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-5742d0aa04c7dfd7f20275519faf3475.jpg" align="middle">
</details>


<h1 id="-9"><a href="#-9" class="headerlink" title=""></a></h1><h2 id="SignDiff-Diffusion-Model-for-American-Sign-Language-Production"><a href="#SignDiff-Diffusion-Model-for-American-Sign-Language-Production" class="headerlink" title="SignDiff: Diffusion Model for American Sign Language Production"></a>SignDiff: Diffusion Model for American Sign Language Production</h2><p><strong>Authors:Sen Fang, Chunyu Sui, Yanghao Zhou, Xuedong Zhang, Hongbin Zhong, Yapeng Tian, Chen Chen</strong></p>
<p>In this paper, we propose a dual-condition diffusion pre-training model named SignDiff that can generate human sign language speakers from a skeleton pose. SignDiff has a novel Frame Reinforcement Network called FR-Net, similar to dense human pose estimation work, which enhances the correspondence between text lexical symbols and sign language dense pose frames, reduces the occurrence of multiple fingers in the diffusion model. In addition, we propose a new method for American Sign Language Production (ASLP), which can generate ASL skeletal pose videos from text input, integrating two new improved modules and a new loss function to improve the accuracy and quality of sign language skeletal posture and enhance the ability of the model to train on large-scale data. We propose the first baseline for ASL production and report the scores of 17.19 and 12.85 on BLEU-4 on the How2Sign dev&#x2F;test sets. We evaluated our model on the previous mainstream dataset PHOENIX14T, and the experiments achieved the SOTA results. In addition, our image quality far exceeds all previous results by 10 percentage points in terms of SSIM. </p>
<blockquote>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸ºSignDiffçš„åŒæ¡ä»¶æ‰©æ•£é¢„è®­ç»ƒæ¨¡å‹ï¼Œè¯¥æ¨¡å‹å¯ä»¥ä»éª¨æ¶å§¿æ€ç”Ÿæˆäººç±»æ‰‹è¯­ã€‚SignDiffå…·æœ‰ä¸€ä¸ªåä¸ºFR-Netçš„æ–°å‹æ¡†æ¶å¼ºåŒ–ç½‘ç»œï¼Œç±»ä¼¼äºå¯†é›†äººä½“å§¿æ€ä¼°è®¡å·¥ä½œï¼Œå®ƒå¢å¼ºäº†æ–‡æœ¬è¯æ±‡ç¬¦å·ä¸æ‰‹è¯­å¯†é›†å§¿æ€æ¡†æ¶ä¹‹é—´çš„å¯¹åº”å…³ç³»ï¼Œå‡å°‘äº†æ‰©æ•£æ¨¡å‹ä¸­å¤šä¸ªæ‰‹æŒ‡çš„å‡ºç°ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°çš„ç¾å›½æ‰‹è¯­ç”Ÿäº§ï¼ˆASLPï¼‰æ–¹æ³•ï¼Œå¯ä»¥ä»æ–‡æœ¬è¾“å…¥ç”ŸæˆASLéª¨æ¶å§¿æ€è§†é¢‘ï¼Œé›†æˆä¸¤ä¸ªæ–°æ”¹è¿›æ¨¡å—å’Œæ–°çš„æŸå¤±å‡½æ•°ï¼Œä»¥æé«˜æ‰‹è¯­éª¨æ¶å§¿æ€çš„å‡†ç¡®æ€§å’Œè´¨é‡ï¼Œå¹¶å¢å¼ºæ¨¡å‹åœ¨å¤§è§„æ¨¡æ•°æ®ä¸Šçš„è®­ç»ƒèƒ½åŠ›ã€‚æˆ‘ä»¬ä¸ºASLç”Ÿäº§æå‡ºäº†ç¬¬ä¸€ä¸ªåŸºå‡†çº¿ï¼Œå¹¶åœ¨How2Signçš„dev&#x2F;testé›†ä¸ŠæŠ¥å‘Šäº†BLEU-4å¾—åˆ†ä¸º17.19å’Œ12.85ã€‚æˆ‘ä»¬åœ¨ä¹‹å‰çš„ä¸»æµæ•°æ®é›†PHOENIX14Tä¸Šè¯„ä¼°äº†æˆ‘ä»¬çš„æ¨¡å‹ï¼Œå®éªŒè¾¾åˆ°äº†SOTAç»“æœã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬çš„å›¾åƒè´¨é‡åœ¨SSIMæ–¹é¢è¶…è¿‡äº†ä¹‹å‰æ‰€æœ‰ç»“æœï¼Œæé«˜äº†10ä¸ªç™¾åˆ†ç‚¹ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.16082v4">PDF</a> Camera-Ready Version; Project Page at <a target="_blank" rel="noopener" href="https://signdiff.github.io/">https://signdiff.github.io</a></p>
<p><strong>Summary</strong><br>     è¯¥è®ºæ–‡æå‡ºäº†ä¸€ç§åä¸ºSignDiffçš„åŒæ¡ä»¶æ‰©æ•£é¢„è®­ç»ƒæ¨¡å‹ï¼Œèƒ½å¤Ÿä»éª¨æ¶å§¿æ€ç”Ÿæˆäººç±»æ‰‹åŠ¿è¯­è¨€ã€‚SignDiffå…·æœ‰æ–°å‹å¸§å¼ºåŒ–ç½‘ç»œFR-Netï¼Œä¸å¯†é›†äººç±»å§¿æ€ä¼°è®¡å·¥ä½œç±»ä¼¼ï¼Œå¢å¼ºäº†æ–‡æœ¬è¯æ±‡ç¬¦å·ä¸æ‰‹åŠ¿è¯­è¨€å¯†é›†å§¿æ€å¸§ä¹‹é—´çš„å¯¹åº”å…³ç³»ï¼Œå‡å°‘äº†æ‰©æ•£æ¨¡å‹ä¸­å¤šä¸ªæ‰‹æŒ‡çš„å‡ºç°ã€‚æ­¤å¤–ï¼Œè®ºæ–‡è¿˜æå‡ºäº†ç¾å¼æ‰‹åŠ¿è¯­è¨€ç”Ÿäº§ï¼ˆASLPï¼‰çš„æ–°æ–¹æ³•ï¼Œå¯ä»æ–‡æœ¬è¾“å…¥ç”ŸæˆASLéª¨æ¶å§¿æ€è§†é¢‘ï¼Œé›†æˆä¸¤ä¸ªæ–°æ”¹è¿›æ¨¡å—å’Œæ–°çš„æŸå¤±å‡½æ•°ï¼Œæé«˜æ‰‹åŠ¿è¯­è¨€éª¨æ¶å§¿æ€çš„å‡†ç¡®æ€§å’Œè´¨é‡ï¼Œå¹¶å¢å¼ºæ¨¡å‹åœ¨å¤§è§„æ¨¡æ•°æ®ä¸Šçš„è®­ç»ƒèƒ½åŠ›ã€‚è®ºæ–‡é¦–æ¬¡æå‡ºASLç”Ÿäº§çš„åŸºçº¿ï¼Œå¹¶åœ¨How2Signçš„dev&#x2F;testé›†ä¸Šå–å¾—BLEU-4è¯„åˆ†ä¸º17.19å’Œ12.85ã€‚åœ¨PHOENIX14Tä¸»æµæ•°æ®é›†ä¸Šçš„å®éªŒè¾¾åˆ°äº†æœ€ä½³ç»“æœï¼Œä¸”å›¾åƒè´¨é‡åœ¨SSIMæ–¹é¢è¶…è¿‡äº†ä¹‹å‰æ‰€æœ‰ç»“æœï¼Œæé«˜äº†10ä¸ªç™¾åˆ†ç‚¹ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>SignDiffæ¨¡å‹èƒ½å¤ŸåŸºäºéª¨æ¶å§¿æ€ç”Ÿæˆäººç±»æ‰‹åŠ¿è¯­è¨€ã€‚</li>
<li>SignDiffæ‹¥æœ‰åä¸ºFR-Netçš„æ–°å‹Frame Reinforcementç½‘ç»œï¼Œå¢å¼ºäº†æ–‡æœ¬ä¸æ‰‹åŠ¿è¯­è¨€å§¿æ€ä¹‹é—´çš„å¯¹åº”å…³ç³»ã€‚</li>
<li>FR-Netå‡å°‘äº†æ‰©æ•£æ¨¡å‹ä¸­å¤šä¸ªæ‰‹æŒ‡çš„å‡ºç°ã€‚</li>
<li>æå‡ºäº†ç¾å¼æ‰‹åŠ¿è¯­è¨€ç”Ÿäº§ï¼ˆASLPï¼‰çš„æ–°æ–¹æ³•ï¼Œé›†æˆäº†ä¸¤ä¸ªæ”¹è¿›æ¨¡å—å’Œæ–°çš„æŸå¤±å‡½æ•°ã€‚</li>
<li>ASLPæ–¹æ³•èƒ½æé«˜æ‰‹åŠ¿è¯­è¨€éª¨æ¶å§¿æ€çš„å‡†ç¡®æ€§å’Œè´¨é‡ã€‚</li>
<li>è®ºæ–‡åœ¨How2Signæ•°æ®é›†ä¸Šå–å¾—äº†è¾ƒé«˜çš„BLEU-4è¯„åˆ†ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2308.16082">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-8383cad4a8dcb42bcf6225d684f23e23.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ab850608039f4e08a01a18f850fbceee.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-84b78c46d413ca62b84dc0bef2467a05.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-748dcf45ecaef95aaca763e16ac8899b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-6ec776f38ce95833bc406ba7f922d20b.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-1fbbcc95c3f3436c2c2eb6fdb3adc84d.jpg" align="middle">
</details>


<h1 id="-10"><a href="#-10" class="headerlink" title=""></a></h1><h2 id="Generalizable-Synthetic-Image-Detection-via-Language-guided-Contrastive-Learning"><a href="#Generalizable-Synthetic-Image-Detection-via-Language-guided-Contrastive-Learning" class="headerlink" title="Generalizable Synthetic Image Detection via Language-guided Contrastive   Learning"></a>Generalizable Synthetic Image Detection via Language-guided Contrastive   Learning</h2><p><strong>Authors:Haiwei Wu, Jiantao Zhou, Shile Zhang</strong></p>
<p>The heightened realism of AI-generated images can be attributed to the rapid development of synthetic models, including generative adversarial networks (GANs) and diffusion models (DMs). The malevolent use of synthetic images, such as the dissemination of fake news or the creation of fake profiles, however, raises significant concerns regarding the authenticity of images. Though many forensic algorithms have been developed for detecting synthetic images, their performance, especially the generalization capability, is still far from being adequate to cope with the increasing number of synthetic models. In this work, we propose a simple yet very effective synthetic image detection method via a language-guided contrastive learning. Specifically, we augment the training images with carefully-designed textual labels, enabling us to use a joint visual-language contrastive supervision for learning a forensic feature space with better generalization. It is shown that our proposed LanguAge-guided SynThEsis Detection (LASTED) model achieves much improved generalizability to unseen image generation models and delivers promising performance that far exceeds state-of-the-art competitors over four datasets. The code is available at <a target="_blank" rel="noopener" href="https://github.com/HighwayWu/LASTED">https://github.com/HighwayWu/LASTED</a>. </p>
<blockquote>
<p>äººå·¥æ™ºèƒ½ç”Ÿæˆå›¾åƒçš„é«˜åº¦é€¼çœŸæ€§å¯å½’åŠŸäºåˆæˆæ¨¡å‹çš„å¿«é€Ÿå‘å±•ï¼ŒåŒ…æ‹¬ç”Ÿæˆå¯¹æŠ—ç½‘ç»œï¼ˆGANï¼‰å’Œæ‰©æ•£æ¨¡å‹ï¼ˆDMï¼‰ã€‚ç„¶è€Œï¼Œåˆæˆå›¾åƒè¢«æ¶æ„ä½¿ç”¨çš„ç°è±¡ï¼Œå¦‚ä¼ æ’­å‡æ–°é—»æˆ–åˆ›å»ºè™šå‡ä¸ªäººå½¢è±¡ï¼Œå¼•å‘äº†äººä»¬å¯¹å›¾åƒçœŸå®æ€§çš„ä¸¥é‡å…³æ³¨ã€‚å°½ç®¡å·²ç»å¼€å‘äº†è®¸å¤šç”¨äºæ£€æµ‹åˆæˆå›¾åƒçš„æ³•åŒ»ç®—æ³•ï¼Œä½†å®ƒä»¬çš„æ€§èƒ½ï¼Œç‰¹åˆ«æ˜¯å…¶æ³›åŒ–èƒ½åŠ›ï¼Œä»ç„¶è¿œè¿œä¸è¶³ä»¥åº”å¯¹æ—¥ç›Šå¢å¤šçš„åˆæˆæ¨¡å‹æ•°é‡ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§ç®€å•è€Œæœ‰æ•ˆçš„åˆæˆå›¾åƒæ£€æµ‹æ–¹æ³•ï¼Œè¯¥æ–¹æ³•é‡‡ç”¨è¯­è¨€å¼•å¯¼å¯¹æ¯”å­¦ä¹ ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬é€šè¿‡ç²¾å¿ƒè®¾è®¡çš„æ–‡æœ¬æ ‡ç­¾æ‰©å……è®­ç»ƒå›¾åƒï¼Œä½¿æˆ‘ä»¬èƒ½å¤Ÿä½¿ç”¨è”åˆè§†è§‰è¯­è¨€å¯¹æ¯”ç›‘ç£æ¥å­¦ä¹ å…·æœ‰æ›´å¥½æ³›åŒ–çš„æ³•åŒ»ç‰¹å¾ç©ºé—´ã€‚ç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬æå‡ºçš„LanguAgeå¼•å¯¼çš„åˆæˆå›¾åƒæ£€æµ‹ï¼ˆLASTEDï¼‰æ¨¡å‹åœ¨æœªè§è¿‡çš„å›¾åƒç”Ÿæˆæ¨¡å‹ä¸Šå®ç°äº†æ˜¾è‘—çš„å¯æ³›åŒ–æ€§æå‡ï¼Œå¹¶ä¸”åœ¨å››ä¸ªæ•°æ®é›†ä¸Šçš„æ€§èƒ½è¿œè¶…æœ€æ–°ç«äº‰å¯¹æ‰‹ã€‚ä»£ç å¯é€šè¿‡<a target="_blank" rel="noopener" href="https://github.com/HighwayWu/LASTED%E8%8E%B7%E5%8F%96%E3%80%82">https://github.com/HighwayWu/LASTEDè·å–ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2305.13800v2">PDF</a> </p>
<p><strong>Summary</strong><br>     äººå·¥æ™ºèƒ½å›¾åƒç”ŸæˆæŠ€æœ¯çš„å¿«é€Ÿå‘å±•ï¼Œå¦‚ç”Ÿæˆå¯¹æŠ—ç½‘ç»œï¼ˆGANsï¼‰å’Œæ‰©æ•£æ¨¡å‹ï¼ˆDMsï¼‰ï¼Œæé«˜äº†å›¾åƒçš„çœŸå®æ€§ã€‚ç„¶è€Œï¼Œæ¶æ„ä½¿ç”¨åˆæˆå›¾åƒï¼Œå¦‚ä¼ æ’­å‡æ–°é—»æˆ–åˆ›å»ºè™šå‡ä¸ªäººèµ„æ–™ï¼Œå¼•å‘äº†äººä»¬å¯¹å›¾åƒçœŸå®æ€§çš„å…³æ³¨ã€‚è™½ç„¶å·²å¼€å‘å‡ºè®¸å¤šç”¨äºæ£€æµ‹åˆæˆå›¾åƒçš„å‰ç«¯ç®—æ³•ï¼Œä½†å…¶æ€§èƒ½å°¤å…¶æ˜¯æ³›åŒ–èƒ½åŠ›ä»ä¸è¶³ä»¥åº”å¯¹ä¸æ–­å¢å¤šçš„åˆæˆæ¨¡å‹ã€‚æœ¬ç ”ç©¶æå‡ºäº†ä¸€ç§ç®€å•æœ‰æ•ˆçš„åˆæˆå›¾åƒæ£€æµ‹æ–¹æ³•â€”â€”é€šè¿‡è¯­è¨€å¼•å¯¼å¯¹æ¯”å­¦ä¹ ã€‚é€šè¿‡å¢å¼ºè®­ç»ƒå›¾åƒå¹¶è®¾è®¡å·§å¦™çš„æ–‡æœ¬æ ‡ç­¾ï¼Œæˆ‘ä»¬èƒ½å¤Ÿä½¿ç”¨è”åˆè§†è§‰è¯­è¨€å¯¹æ¯”ç›‘ç£æ¥å­¦ä¹ å…·æœ‰æ›´å¥½æ³›åŒ–èƒ½åŠ›çš„æ³•åŒ»ç‰¹å¾ç©ºé—´ã€‚æ‰€æå‡ºçš„LanguAgeå¼•å¯¼çš„åˆæˆå›¾åƒæ£€æµ‹ï¼ˆLASTEDï¼‰æ¨¡å‹åœ¨æœªè§è¿‡çš„å›¾åƒç”Ÿæˆæ¨¡å‹ä¸Šè¡¨ç°å‡ºæ›´é«˜çš„æ³›åŒ–èƒ½åŠ›ï¼Œå¹¶åœ¨å››ä¸ªæ•°æ®é›†ä¸Šçš„æ€§èƒ½è¿œè¶…æœ€æ–°ç«äº‰å¯¹æ‰‹ã€‚ç›¸å…³ä»£ç å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/HighwayWu/LASTED%E8%8E%B7%E5%8F%96%E3%80%82">https://github.com/HighwayWu/LASTEDè·å–ã€‚</a></p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>AIå›¾åƒç”ŸæˆæŠ€æœ¯å¦‚GANså’ŒDMsæé«˜äº†å›¾åƒçš„çœŸå®æ€§ã€‚</li>
<li>åˆæˆå›¾åƒçš„æ¶æ„ä½¿ç”¨å¼•å‘äº†å…³äºå›¾åƒçœŸå®æ€§çš„æ‹…å¿§ã€‚</li>
<li>å°½ç®¡å·²æœ‰è®¸å¤šå‰ç«¯ç®—æ³•ç”¨äºæ£€æµ‹åˆæˆå›¾åƒï¼Œä½†å…¶æ³›åŒ–èƒ½åŠ›ä»ç„¶ä¸è¶³ã€‚</li>
<li>æœ¬ç ”ç©¶æå‡ºäº†ä¸€ç§æ–°çš„åˆæˆå›¾åƒæ£€æµ‹æ–¹æ³•â€”â€”é€šè¿‡è¯­è¨€å¼•å¯¼å¯¹æ¯”å­¦ä¹ ã€‚</li>
<li>é€šè¿‡è®¾è®¡æ–‡æœ¬æ ‡ç­¾å¢å¼ºè®­ç»ƒå›¾åƒï¼Œä»¥æé«˜æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚</li>
<li>LASTEDæ¨¡å‹åœ¨æœªè§è¿‡çš„å›¾åƒç”Ÿæˆæ¨¡å‹ä¸Šè¡¨ç°å‡ºè¾ƒé«˜çš„æ³›åŒ–èƒ½åŠ›ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2305.13800">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-6c924b1d6d8939ccc18f7c5e62d4de88.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-7285e9f9a560ad6d403326c10007f64f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d1723ea7ed3e29b53b6f94e182918937.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-231c7fe1970d47a90270147be514c569.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c7b53c51a7b1945209f6dcbc357dffc8.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-74a6a4da279abaf3fbc7b7b78d951875.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-2b38c7b72c550016c4cf3d15e1331248.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-169ff44f83247c27acd78179f15c3910.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-51561b2ec6bac160d8d20d9dba641346.jpg" align="middle">
</details>


<h1 id="-11"><a href="#-11" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-05-02/Diffusion%20Models/">https://kedreamix.github.io/Talk2Paper/Paper/2025-05-02/Diffusion%20Models/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/Diffusion-Models/">
                                    <span class="chip bg-color">Diffusion Models</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-05-02/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/">
                    <div class="card-image">
                        
                        <img src="https://pica.zhimg.com/v2-d92fc23fea6223950917f3abf2912343.jpg" class="responsive-img" alt="åŒ»å­¦å›¾åƒ">
                        
                        <span class="card-title">åŒ»å­¦å›¾åƒ</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            åŒ»å­¦å›¾åƒ æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-05-02  A simple and effective approach for body part recognition on CT scans   based on projection estimation
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-05-02
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/" class="post-category">
                                    åŒ»å­¦å›¾åƒ
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/">
                        <span class="chip bg-color">åŒ»å­¦å›¾åƒ</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-05-02/NeRF/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-bd6e08e666d2413b081672afa5619a13.jpg" class="responsive-img" alt="NeRF">
                        
                        <span class="card-title">NeRF</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            NeRF æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-05-02  SMOGAN Synthetic Minority Oversampling with GAN Refinement for   Imbalanced Regression
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-05-02
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/NeRF/" class="post-category">
                                    NeRF
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/NeRF/">
                        <span class="chip bg-color">NeRF</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">25219.3k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
