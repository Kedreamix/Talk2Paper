<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="R1_Reasoning">
    <meta name="description" content="R1_Reasoning æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-05-02  DeepSeek-Prover-V2 Advancing Formal Mathematical Reasoning via   Reinforcement Learning for Subgoal Decomposition">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>R1_Reasoning | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://picx.zhimg.com/v2-7f3ea181c49e2c7bbe1af35cd0fee256.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">R1_Reasoning</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/R1-Reasoning/">
                                <span class="chip bg-color">R1_Reasoning</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/R1-Reasoning/" class="post-category">
                                R1_Reasoning
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-05-02
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-05-25
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    11.5k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    46 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-05-02-æ›´æ–°"><a href="#2025-05-02-æ›´æ–°" class="headerlink" title="2025-05-02 æ›´æ–°"></a>2025-05-02 æ›´æ–°</h1><h2 id="DeepSeek-Prover-V2-Advancing-Formal-Mathematical-Reasoning-via-Reinforcement-Learning-for-Subgoal-Decomposition"><a href="#DeepSeek-Prover-V2-Advancing-Formal-Mathematical-Reasoning-via-Reinforcement-Learning-for-Subgoal-Decomposition" class="headerlink" title="DeepSeek-Prover-V2: Advancing Formal Mathematical Reasoning via   Reinforcement Learning for Subgoal Decomposition"></a>DeepSeek-Prover-V2: Advancing Formal Mathematical Reasoning via   Reinforcement Learning for Subgoal Decomposition</h2><p><strong>Authors:Z. Z. Ren, Zhihong Shao, Junxiao Song, Huajian Xin, Haocheng Wang, Wanjia Zhao, Liyue Zhang, Zhe Fu, Qihao Zhu, Dejian Yang, Z. F. Wu, Zhibin Gou, Shirong Ma, Hongxuan Tang, Yuxuan Liu, Wenjun Gao, Daya Guo, Chong Ruan</strong></p>
<p>We introduce DeepSeek-Prover-V2, an open-source large language model designed for formal theorem proving in Lean 4, with initialization data collected through a recursive theorem proving pipeline powered by DeepSeek-V3. The cold-start training procedure begins by prompting DeepSeek-V3 to decompose complex problems into a series of subgoals. The proofs of resolved subgoals are synthesized into a chain-of-thought process, combined with DeepSeek-V3â€™s step-by-step reasoning, to create an initial cold start for reinforcement learning. This process enables us to integrate both informal and formal mathematical reasoning into a unified model. The resulting model, DeepSeek-Prover-V2-671B, achieves state-of-the-art performance in neural theorem proving, reaching 88.9% pass ratio on the MiniF2F-test and solving 49 out of 658 problems from PutnamBench. In addition to standard benchmarks, we introduce ProverBench, a collection of 325 formalized problems, to enrich our evaluation, including 15 selected problems from the recent AIME competitions (years 24-25). Further evaluation on these 15 AIME problems shows that the model successfully solves 6 of them. In comparison, DeepSeek-V3 solves 8 of these problems using majority voting, highlighting that the gap between formal and informal mathematical reasoning in large language models is substantially narrowing. </p>
<blockquote>
<p>æˆ‘ä»¬æ¨å‡ºäº†DeepSeek-Prover-V2ï¼Œè¿™æ˜¯ä¸€æ¬¾é’ˆå¯¹Lean 4è¿›è¡Œå½¢å¼åŒ–å®šç†è¯æ˜è®¾è®¡çš„å¼€æºå¤§å‹è¯­è¨€æ¨¡å‹ã€‚å…¶åˆå§‹åŒ–æ•°æ®æ˜¯é€šè¿‡DeepSeek-V3é©±åŠ¨çš„é€’å½’å®šç†è¯æ˜ç®¡é“æ”¶é›†çš„ã€‚å†·å¯åŠ¨è®­ç»ƒç¨‹åºä»æç¤ºDeepSeek-V3å¼€å§‹ï¼Œå°†å¤æ‚é—®é¢˜åˆ†è§£ä¸ºä¸€ç³»åˆ—å­ç›®æ ‡ã€‚å·²è§£å†³çš„å­ç›®æ ‡çš„è¯æ˜è¢«åˆæˆä¸ºä¸€ç§æ€ç»´é“¾è¿‡ç¨‹ï¼Œä¸DeepSeek-V3çš„é€æ­¥æ¨ç†ç›¸ç»“åˆï¼Œä¸ºå¼ºåŒ–å­¦ä¹ åˆ›å»ºä¸€ä¸ªåˆæ­¥çš„å†·å¯åŠ¨ã€‚è¿™ä¸€è¿‡ç¨‹ä½¿æˆ‘ä»¬èƒ½å¤Ÿå°†éæ­£å¼å’Œæ­£å¼çš„æ•°å­¦æ¨ç†æ•´åˆåˆ°ä¸€ä¸ªç»Ÿä¸€çš„æ¨¡å‹ä¸­ã€‚æœ€ç»ˆçš„äº§å“æ¨¡å‹DeepSeek-Prover-V2-671Båœ¨ç¥ç»å®šç†è¯æ˜æ–¹é¢è¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œåœ¨MiniF2Fæµ‹è¯•ä¸­çš„é€šè¿‡ç‡è¾¾åˆ°äº†88.9%ï¼Œå¹¶è§£å†³äº†PutnamBenchä¸­çš„49ä¸ªä¸­çš„658ä¸ªé—®é¢˜ã€‚é™¤äº†æ ‡å‡†åŸºå‡†æµ‹è¯•å¤–ï¼Œæˆ‘ä»¬è¿˜æ¨å‡ºäº†ProverBenchï¼Œè¿™æ˜¯ä¸€ç»„åŒ…å«325ä¸ªå½¢å¼åŒ–é—®é¢˜çš„é›†åˆï¼Œä»¥ä¸°å¯Œæˆ‘ä»¬çš„è¯„ä¼°å†…å®¹ï¼Œå…¶ä¸­åŒ…æ‹¬æœ€è¿‘AIMEç«èµ›ï¼ˆç¬¬24è‡³25å¹´ï¼‰é€‰æ‹©çš„15ä¸ªé—®é¢˜ã€‚å¯¹è¿™15ä¸ªAIMEé—®é¢˜çš„è¿›ä¸€æ­¥è¯„ä¼°è¡¨æ˜ï¼Œè¯¥æ¨¡å‹æˆåŠŸè§£å†³äº†å…¶ä¸­6ä¸ªé—®é¢˜ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼ŒDeepSeek-V3é€šè¿‡å¤šæ•°æŠ•ç¥¨è§£å†³äº†å…¶ä¸­8ä¸ªé—®é¢˜ï¼Œè¿™è¡¨æ˜å¤§å‹è¯­è¨€æ¨¡å‹ä¸­æ­£å¼ä¸éæ­£å¼æ•°å­¦æ¨ç†ä¹‹é—´çš„å·®è·æ­£åœ¨æ˜¾è‘—ç¼©å°ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.21801v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<pre><code>æˆ‘ä»¬æ¨å‡ºäº†DeepSeek-Prover-V2ï¼Œè¿™æ˜¯ä¸€æ¬¾ä¸ºLean 4ä¸­çš„å½¢å¼åŒ–å®šç†è¯æ˜è€Œè®¾è®¡çš„å¼€æºå¤§å‹è¯­è¨€æ¨¡å‹ã€‚é€šè¿‡DeepSeek-V3é©±åŠ¨çš„é€’å½’å®šç†è¯æ˜æµæ°´çº¿æ”¶é›†åˆå§‹åŒ–æ•°æ®ï¼Œé‡‡ç”¨å†·å¯åŠ¨è®­ç»ƒç¨‹åºï¼Œå°†å¤æ‚é—®é¢˜åˆ†è§£ä¸ºä¸€ç³»åˆ—å­ç›®æ ‡ã€‚é€šè¿‡DeepSeek-V3çš„é€æ­¥æ¨ç†ï¼Œå°†å·²è§£å†³å­ç›®æ ‡çš„è¯æ˜åˆæˆæ€ç»´é“¾ï¼Œä¸ºå¼ºåŒ–å­¦ä¹ åˆ›å»ºåˆå§‹å†·å¯åŠ¨ã€‚æ­¤è¿‡ç¨‹ä½¿æˆ‘ä»¬èƒ½å¤Ÿå°†éæ­£å¼å’Œæ­£å¼çš„æ•°å­¦æ¨ç†æ•´åˆåˆ°ç»Ÿä¸€æ¨¡å‹ä¸­ã€‚ç»“æœæ¨¡å‹DeepSeek-Prover-V2-671Båœ¨ç¥ç»å®šç†è¯æ˜æ–¹é¢è¾¾åˆ°äº†æœ€æ–°æ€§èƒ½ï¼Œåœ¨MiniF2Fæµ‹è¯•ä¸­çš„é€šè¿‡ç‡è¾¾åˆ°äº†88.9%ï¼Œå¹¶è§£å†³PutnamBenchä¸­çš„49ä¸ªéš¾é¢˜ä¸­çš„658ä¸ªé—®é¢˜ã€‚é™¤äº†æ ‡å‡†åŸºå‡†æµ‹è¯•å¤–ï¼Œæˆ‘ä»¬è¿˜æ¨å‡ºäº†ProverBenchï¼Œè¿™æ˜¯ä¸€ç»„åŒ…å«æ¥è‡ªæœ€æ–°AIMEç«èµ›ï¼ˆç¬¬24-25å¹´ï¼‰çš„ç²¾é€‰é—®é¢˜çš„325ä¸ªå½¢å¼åŒ–é—®é¢˜é›†åˆã€‚åœ¨è¿™15ä¸ªAIMEé—®é¢˜ä¸Šçš„è¿›ä¸€æ­¥è¯„ä¼°è¡¨æ˜ï¼Œè¯¥æ¨¡å‹æˆåŠŸè§£å†³äº†å…¶ä¸­å…­ä¸ªé—®é¢˜ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼ŒDeepSeek-V3ä½¿ç”¨å¤šæ•°æŠ•ç¥¨è§£å†³äº†å…¶ä¸­å…«ä¸ªé—®é¢˜ï¼Œçªæ˜¾å‡ºåœ¨å¤§å‹è¯­è¨€æ¨¡å‹ä¸­å½¢å¼å’Œéå½¢å¼æ•°å­¦æ¨ç†ä¹‹é—´çš„å·®è·æ­£åœ¨æ˜¾è‘—ç¼©å°ã€‚
</code></pre>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>DeepSeek-Prover-V2æ˜¯ä¸€ä¸ªç”¨äºå½¢å¼å®šç†è¯æ˜çš„å¤§å‹è¯­è¨€æ¨¡å‹ã€‚</li>
<li>è¯¥æ¨¡å‹é€šè¿‡é€’å½’å®šç†è¯æ˜æµæ°´çº¿è¿›è¡Œè®­ç»ƒï¼Œç»“åˆDeepSeek-V3çš„é€æ­¥æ¨ç†èƒ½åŠ›ã€‚</li>
<li>DeepSeek-Prover-V2-671Bæ¨¡å‹åœ¨ç¥ç»å®šç†è¯æ˜æ–¹é¢è¡¨ç°å‡ºå“è¶Šæ€§èƒ½ã€‚</li>
<li>åœ¨MiniF2Fæµ‹è¯•ä¸­ï¼Œè¯¥æ¨¡å‹çš„é€šè¿‡ç‡è¾¾åˆ°äº†88.9%ã€‚</li>
<li>è¯¥æ¨¡å‹æˆåŠŸè§£å†³äº†PutnamBenchä¸­çš„49ä¸ªéš¾é¢˜å’ŒProverBenchä¸­çš„å¤šä¸ªé—®é¢˜ã€‚</li>
<li>ProverBenchæ˜¯ä¸€ä¸ªæ–°çš„è¯„ä¼°å·¥å…·ï¼ŒåŒ…å«æ¥è‡ªAIMEç«èµ›çš„å½¢å¼åŒ–é—®é¢˜ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.21801">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-7ef543751ec0ec9f23a2e4d8397c5474.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-76b2c2489950bcd2680edcd10a3661c0.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-2f45986e3210815b3e23c1b2005da863.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="WebThinker-Empowering-Large-Reasoning-Models-with-Deep-Research-Capability"><a href="#WebThinker-Empowering-Large-Reasoning-Models-with-Deep-Research-Capability" class="headerlink" title="WebThinker: Empowering Large Reasoning Models with Deep Research   Capability"></a>WebThinker: Empowering Large Reasoning Models with Deep Research   Capability</h2><p><strong>Authors:Xiaoxi Li, Jiajie Jin, Guanting Dong, Hongjin Qian, Yutao Zhu, Yongkang Wu, Ji-Rong Wen, Zhicheng Dou</strong></p>
<p>Large reasoning models (LRMs), such as OpenAI-o1 and DeepSeek-R1, demonstrate impressive long-horizon reasoning capabilities. However, their reliance on static internal knowledge limits their performance on complex, knowledge-intensive tasks and hinders their ability to produce comprehensive research reports requiring synthesis of diverse web information. To address this, we propose \textbf{WebThinker}, a deep research agent that empowers LRMs to autonomously search the web, navigate web pages, and draft research reports during the reasoning process. WebThinker integrates a \textbf{Deep Web Explorer} module, enabling LRMs to dynamically search, navigate, and extract information from the web when encountering knowledge gaps. It also employs an \textbf{Autonomous Think-Search-and-Draft strategy}, allowing the model to seamlessly interleave reasoning, information gathering, and report writing in real time. To further enhance research tool utilization, we introduce an \textbf{RL-based training strategy} via iterative online Direct Preference Optimization (DPO). Extensive experiments on complex reasoning benchmarks (GPQA, GAIA, WebWalkerQA, HLE) and scientific report generation tasks (Glaive) demonstrate that WebThinker significantly outperforms existing methods and strong proprietary systems. Our approach enhances LRM reliability and applicability in complex scenarios, paving the way for more capable and versatile deep research systems. The code is available at <a target="_blank" rel="noopener" href="https://github.com/RUC-NLPIR/WebThinker">https://github.com/RUC-NLPIR/WebThinker</a>. </p>
<blockquote>
<p>å¤§å‹æ¨ç†æ¨¡å‹ï¼ˆLRMsï¼‰ï¼Œå¦‚OpenAI-o1å’ŒDeepSeek-R1ï¼Œå±•ç°äº†ä»¤äººå°è±¡æ·±åˆ»çš„é•¿è¿œæ¨ç†èƒ½åŠ›ã€‚ç„¶è€Œï¼Œå®ƒä»¬å¯¹é™æ€å†…éƒ¨çŸ¥è¯†çš„ä¾èµ–é™åˆ¶äº†å®ƒä»¬åœ¨å¤æ‚ã€çŸ¥è¯†å¯†é›†å‹ä»»åŠ¡ä¸Šçš„æ€§èƒ½ï¼Œå¹¶é˜»ç¢äº†å®ƒä»¬ç”Ÿæˆéœ€è¦åˆæˆå„ç§ç½‘ç»œä¿¡æ¯çš„ç»¼åˆç ”ç©¶æŠ¥å‘Šçš„èƒ½åŠ›ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†<strong>WebThinker</strong>ï¼Œè¿™æ˜¯ä¸€ç§æ·±åº¦ç ”ç©¶ä»£ç†ï¼Œèƒ½å¤Ÿèµ‹äºˆLRMsè‡ªä¸»ä¸Šç½‘ã€æµè§ˆç½‘é¡µå¹¶åœ¨æ¨ç†è¿‡ç¨‹ä¸­èµ·è‰ç ”ç©¶æŠ¥å‘Šçš„èƒ½åŠ›ã€‚WebThinkeré›†æˆäº†<strong>æ·±ç½‘æ¢ç´¢å™¨</strong>æ¨¡å—ï¼Œä½¿LRMsèƒ½å¤Ÿåœ¨é‡åˆ°çŸ¥è¯†ç©ºç™½æ—¶åŠ¨æ€åœ°ä»ç½‘ä¸Šæœç´¢ã€æµè§ˆå’Œæå–ä¿¡æ¯ã€‚å®ƒè¿˜é‡‡ç”¨äº†ä¸€ç§<strong>è‡ªä¸»æ€è€ƒ-æœç´¢-èµ·è‰ç­–ç•¥</strong>ï¼Œä½¿æ¨¡å‹èƒ½å¤Ÿå®æ—¶æ— ç¼åœ°äº¤æ›¿è¿›è¡Œæ¨ç†ã€ä¿¡æ¯æ”¶é›†å’Œç ”ç©¶æŠ¥å‘Šå†™ä½œã€‚ä¸ºäº†è¿›ä¸€æ­¥æé«˜ç ”ç©¶å·¥å…·çš„ä½¿ç”¨æ•ˆç‡ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§åŸºäºå¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰çš„è®­ç»ƒç­–ç•¥ï¼Œé€šè¿‡åœ¨çº¿ç›´æ¥åå¥½ä¼˜åŒ–ï¼ˆDPOï¼‰è¿›è¡Œè¿­ä»£ã€‚åœ¨å¤æ‚æ¨ç†åŸºå‡†æµ‹è¯•ï¼ˆGPQAã€GAIAã€WebWalkerQAã€HLEï¼‰å’Œç§‘å­¦æŠ¥å‘Šç”Ÿæˆä»»åŠ¡ï¼ˆGlaiveï¼‰ä¸Šçš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼ŒWebThinkeræ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•å’Œå¼ºå¤§çš„ä¸“æœ‰ç³»ç»Ÿã€‚æˆ‘ä»¬çš„æ–¹æ³•æé«˜äº†LRMåœ¨å¤æ‚åœºæ™¯ä¸­çš„å¯é æ€§å’Œé€‚ç”¨æ€§ï¼Œä¸ºæ›´å¼ºå¤§ã€æ›´é€šç”¨çš„æ·±åº¦ç ”ç©¶ç³»ç»Ÿé“ºå¹³äº†é“è·¯ã€‚ä»£ç å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/RUC-NLPIR/WebThinker%E4%B8%8A%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/RUC-NLPIR/WebThinkerä¸Šæ‰¾åˆ°ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.21776v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>å¤§å‹æ¨ç†æ¨¡å‹ï¼ˆLRMsï¼‰å¦‚OpenAI-o1å’ŒDeepSeek-R1å…·å¤‡å‡ºè‰²çš„é•¿è¿œæ¨ç†èƒ½åŠ›ï¼Œä½†åœ¨å¤„ç†å¤æ‚ã€çŸ¥è¯†å¯†é›†å‹ä»»åŠ¡å’Œç”Ÿæˆç»¼åˆç ”ç©¶æŠ¥å‘Šæ—¶å­˜åœ¨å±€é™æ€§ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬æå‡ºäº†WebThinkerï¼Œä¸€ä¸ªæ·±åº¦ç ”ç©¶ä»£ç†ï¼Œèƒ½å¤Ÿè‡ªä¸»ä¸Šç½‘ã€å¯¼èˆªç½‘é¡µå¹¶èƒ½åœ¨æ¨ç†è¿‡ç¨‹ä¸­æ’°å†™ç ”ç©¶æŠ¥å‘Šã€‚WebThinkeré€šè¿‡é›†æˆDeep Web Exploreræ¨¡å—å’Œè‡ªä¸»æ€è€ƒ-æœç´¢-èµ·è‰ç­–ç•¥ï¼Œå®ç°äº†å®æ—¶æ¨ç†ã€ä¿¡æ¯æ”¶é›†ä¸æŠ¥å‘Šæ’°å†™çš„æ— ç¼è¡”æ¥ã€‚é€šè¿‡åŸºäºå¼ºåŒ–å­¦ä¹ çš„è®­ç»ƒç­–ç•¥å’Œåœ¨çº¿ç›´æ¥åå¥½ä¼˜åŒ–ï¼ˆDPOï¼‰ï¼ŒWebThinkeråœ¨å¤æ‚æ¨ç†å’Œç§‘ç ”æŠ¥å‘Šç”Ÿæˆä»»åŠ¡ä¸Šæ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•å’Œå¼ºå¤§ä¸“æœ‰ç³»ç»Ÿã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>å¤§å‹æ¨ç†æ¨¡å‹ï¼ˆLRMsï¼‰å…·æœ‰ä¼˜ç§€çš„é•¿è¿œæ¨ç†èƒ½åŠ›ã€‚</li>
<li>LRMsåœ¨å¤„ç†å¤æ‚ã€çŸ¥è¯†å¯†é›†å‹ä»»åŠ¡å’Œç”Ÿæˆç»¼åˆç ”ç©¶æŠ¥å‘Šæ—¶å­˜åœ¨å±€é™æ€§ã€‚</li>
<li>WebThinkeræ˜¯ä¸€ä¸ªæ·±åº¦ç ”ç©¶ä»£ç†ï¼Œèƒ½å¤Ÿè‡ªä¸»ä¸Šç½‘ã€å¯¼èˆªç½‘é¡µï¼ŒåŠ©åŠ›LRMså…‹æœçŸ¥è¯†ç¼ºå£ã€‚</li>
<li>WebThinkeré›†æˆäº†Deep Web Exploreræ¨¡å—ï¼Œå®ç°åŠ¨æ€ç½‘é¡µä¿¡æ¯æœç´¢ã€å¯¼èˆªå’Œæå–ã€‚</li>
<li>WebThinkeré‡‡ç”¨è‡ªä¸»æ€è€ƒ-æœç´¢-èµ·è‰ç­–ç•¥ï¼Œå®ç°æ¨ç†ã€ä¿¡æ¯æ”¶é›†ä¸æŠ¥å‘Šæ’°å†™çš„æ— ç¼è¡”æ¥ã€‚</li>
<li>åŸºäºå¼ºåŒ–å­¦ä¹ çš„è®­ç»ƒç­–ç•¥å’Œåœ¨çº¿ç›´æ¥åå¥½ä¼˜åŒ–ï¼ˆDPOï¼‰æå‡äº†WebThinkerçš„æ€§èƒ½ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.21776">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-a1cf4df980dfb110bbafc5df012faeff.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f3467e8fcc5f657c2d1c86ee0e54372d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-2a54d5db09094083127770b451d082b0.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="MAC-Tuning-LLM-Multi-Compositional-Problem-Reasoning-with-Enhanced-Knowledge-Boundary-Awareness"><a href="#MAC-Tuning-LLM-Multi-Compositional-Problem-Reasoning-with-Enhanced-Knowledge-Boundary-Awareness" class="headerlink" title="MAC-Tuning: LLM Multi-Compositional Problem Reasoning with Enhanced   Knowledge Boundary Awareness"></a>MAC-Tuning: LLM Multi-Compositional Problem Reasoning with Enhanced   Knowledge Boundary Awareness</h2><p><strong>Authors:Junsheng Huang, Zhitao He, Sandeep Polisetty, Qingyun Wang, May Fung</strong></p>
<p>With the widespread application of large language models (LLMs), the issue of generating non-existing facts, known as hallucination, has garnered increasing attention. Previous research in enhancing LLM confidence estimation mainly focuses on the single problem setting. However, LLM awareness of its internal parameterized knowledge boundary under the more challenging multi-problem setting, which requires answering multiple problems accurately simultaneously, remains underexplored. To bridge this gap, we introduce a novel method, Multiple Answers and Confidence Stepwise Tuning (MAC-Tuning), that separates the learning of answer prediction and confidence estimation during fine-tuning on instruction data. Extensive experiments demonstrate that our method outperforms baselines by up to 25% in average precision. </p>
<blockquote>
<p>éšç€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„å¹¿æ³›åº”ç”¨ï¼Œç”Ÿæˆä¸å­˜åœ¨çš„äº‹å®çš„é—®é¢˜ï¼Œå³è¢«ç§°ä¸ºå¹»è§‰çš„é—®é¢˜ï¼Œå·²ç»å¼•èµ·äº†è¶Šæ¥è¶Šå¤šçš„å…³æ³¨ã€‚ä¹‹å‰å…³äºæé«˜LLMä¿¡å¿ƒä¼°è®¡çš„ç ”ç©¶ä¸»è¦é›†ä¸­åœ¨å•ä¸€é—®é¢˜è®¾ç½®ä¸Šã€‚ç„¶è€Œï¼Œåœ¨æ›´å…·æŒ‘æˆ˜æ€§çš„å¤šé—®é¢˜è®¾ç½®ä¸‹ï¼ŒLLMå¯¹å…¶å†…éƒ¨å‚æ•°åŒ–çŸ¥è¯†è¾¹ç•Œçš„è®¤è¯†ï¼Œå³åœ¨åŒä¸€æ—¶é—´å†…å‡†ç¡®å›ç­”å¤šä¸ªé—®é¢˜çš„èƒ½åŠ›ï¼Œä»ç„¶è¢«å¾ˆå°‘æ¢ç´¢ã€‚ä¸ºäº†å¼¥è¡¥è¿™ä¸€å·®è·ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§æ–°æ–¹æ³•ï¼Œå³å¤šç­”æ¡ˆä¸ä¿¡å¿ƒé€æ­¥è°ƒæ•´ï¼ˆMAC-Tuningï¼‰ï¼Œåœ¨æŒ‡ä»¤æ•°æ®çš„å¾®è°ƒè¿‡ç¨‹ä¸­ï¼Œå®ƒå°†ç­”æ¡ˆé¢„æµ‹å’Œä¿¡å¿ƒä¼°è®¡çš„å­¦ä¹ åˆ†å¼€ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨å¹³å‡ç²¾åº¦ä¸Šæ¯”åŸºçº¿é«˜å‡º25%ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.21773v1">PDF</a> </p>
<p><strong>Summary</strong>ï¼šéšç€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„å¹¿æ³›åº”ç”¨ï¼Œç”Ÿæˆä¸å­˜åœ¨çš„äº‹å®å³å¹»è§‰é—®é¢˜å·²å¼•èµ·è¶Šæ¥è¶Šå¤šçš„å…³æ³¨ã€‚è™½ç„¶å¢å¼ºLLMä¿¡å¿ƒè¯„ä¼°çš„ç ”ç©¶ä¸»è¦é›†ä¸­åœ¨å•ä¸€é—®é¢˜è®¾ç½®ä¸Šï¼Œä½†åœ¨æ›´å…·æŒ‘æˆ˜æ€§çš„å¤šé—®é¢˜è®¾ç½®ä¸‹ï¼ŒLLMå¯¹å…¶å†…éƒ¨å‚æ•°åŒ–çŸ¥è¯†è¾¹ç•Œçš„è®¤è¯†ï¼Œå³è¦æ±‚åŒæ—¶å‡†ç¡®å›ç­”å¤šä¸ªé—®é¢˜çš„èƒ½åŠ›ï¼Œä»ç„¶è¢«å¿½è§†ã€‚ä¸ºäº†å¼¥è¡¥è¿™ä¸€ç©ºç™½ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°çš„æ–¹æ³•â€”â€”å¤šç­”æ¡ˆä¸ä¿¡å¿ƒé€æ­¥è°ƒæ•´ï¼ˆMAC-Tuningï¼‰ï¼Œåœ¨æŒ‡ä»¤æ•°æ®å¾®è°ƒæœŸé—´å°†ç­”æ¡ˆé¢„æµ‹å’Œä¿¡å¿ƒè¯„ä¼°çš„å­¦ä¹ åˆ†å¼€ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•å¹³å‡ç²¾åº¦æ¯”åŸºçº¿é«˜å‡ºé«˜è¾¾25%ã€‚</p>
<p><strong>Key Takeaways</strong>ï¼š</p>
<ol>
<li>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨ç”Ÿæˆç­”æ¡ˆæ—¶å¯èƒ½å‡ºç°ç”Ÿæˆéå­˜åœ¨äº‹å®ï¼ˆå¹»è§‰ï¼‰çš„é—®é¢˜ã€‚</li>
<li>ç°æœ‰ç ”ç©¶ä¸»è¦å…³æ³¨å•ä¸€é—®é¢˜è®¾ç½®ä¸‹çš„LLMä¿¡å¿ƒè¯„ä¼°ã€‚</li>
<li>åœ¨æ›´å…·æŒ‘æˆ˜æ€§çš„å¤šé—®é¢˜è®¾ç½®ä¸‹ï¼ŒLLMå¯¹å…¶å†…éƒ¨å‚æ•°åŒ–çŸ¥è¯†è¾¹ç•Œçš„è®¤è¯†éœ€è¦è¿›ä¸€æ­¥æé«˜ã€‚</li>
<li>æå‡ºäº†ä¸€ç§æ–°çš„æ–¹æ³•MAC-Tuningï¼Œè¯¥æ–¹æ³•åœ¨æŒ‡ä»¤æ•°æ®å¾®è°ƒæœŸé—´åˆ†ç¦»ç­”æ¡ˆé¢„æµ‹å’Œä¿¡å¿ƒè¯„ä¼°çš„å­¦ä¹ ã€‚</li>
<li>MAC-Tuningæ–¹æ³•é€šè¿‡åˆ†ç¦»å­¦ä¹ æµç¨‹æé«˜äº†LLMçš„æ€§èƒ½ã€‚</li>
<li>å¹¿æ³›å®éªŒè¡¨æ˜ï¼ŒMAC-Tuningæ–¹æ³•çš„å¹³å‡ç²¾åº¦æ¯”åŸºçº¿æ–¹æ³•é«˜å‡ºæ˜¾è‘—ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.21773">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-2329c1ecf80e1e1f93935c6493d2a0e8.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-9b8c1553b87fbb2d95d5529ab5a8e0e9.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-0136a57e7dc4dc48cc00aec9c6ae26e1.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-caf00fbb4b33f2eb25005cf61838456f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-8c0e5eb7a2592ce8c2e52014f520035e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-5aeecc3012b4f46240ed5f21ff74ffe9.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="AdaR1-From-Long-CoT-to-Hybrid-CoT-via-Bi-Level-Adaptive-Reasoning-Optimization"><a href="#AdaR1-From-Long-CoT-to-Hybrid-CoT-via-Bi-Level-Adaptive-Reasoning-Optimization" class="headerlink" title="AdaR1: From Long-CoT to Hybrid-CoT via Bi-Level Adaptive Reasoning   Optimization"></a>AdaR1: From Long-CoT to Hybrid-CoT via Bi-Level Adaptive Reasoning   Optimization</h2><p><strong>Authors:Haotian Luo, Haiying He, Yibo Wang, Jinluan Yang, Rui Liu, Naiqiang Tan, Xiaochun Cao, Dacheng Tao, Li Shen</strong></p>
<p>Recently, long-thought reasoning models achieve strong performance on complex reasoning tasks, but often incur substantial inference overhead, making efficiency a critical concern. Our empirical analysis reveals that the benefit of using Long-CoT varies across problems: while some problems require elaborate reasoning, others show no improvement, or even degraded accuracy. This motivates adaptive reasoning strategies that tailor reasoning depth to the input. However, prior work primarily reduces redundancy within long reasoning paths, limiting exploration of more efficient strategies beyond the Long-CoT paradigm. To address this, we propose a novel two-stage framework for adaptive and efficient reasoning. First, we construct a hybrid reasoning model by merging long and short CoT models to enable diverse reasoning styles. Second, we apply bi-level preference training to guide the model to select suitable reasoning styles (group-level), and prefer concise and correct reasoning within each style group (instance-level). Experiments demonstrate that our method significantly reduces inference costs compared to other baseline approaches, while maintaining performance. Notably, on five mathematical datasets, the average length of reasoning is reduced by more than 50%, highlighting the potential of adaptive strategies to optimize reasoning efficiency in large language models. Our code is coming soon at <a target="_blank" rel="noopener" href="https://github.com/StarDewXXX/AdaR1">https://github.com/StarDewXXX/AdaR1</a> </p>
<blockquote>
<p>æœ€è¿‘ï¼Œé•¿æœŸè¢«è®¤ä¸ºåœ¨å¤æ‚æ¨ç†ä»»åŠ¡ä¸Šè¡¨ç°è‰¯å¥½çš„æ¨ç†æ¨¡å‹ï¼Œå¾€å¾€ä¼šäº§ç”Ÿå¤§é‡çš„æ¨ç†å¼€é”€ï¼Œä½¿å¾—æ•ˆç‡æˆä¸ºä¸€ä¸ªå…³é”®é—®é¢˜ã€‚æˆ‘ä»¬çš„å®è¯åˆ†ææ˜¾ç¤ºï¼Œä½¿ç”¨Long-CoTçš„æ”¶ç›Šåœ¨ä¸åŒé—®é¢˜é—´å­˜åœ¨å·®å¼‚ï¼šä¸€äº›é—®é¢˜éœ€è¦ç²¾ç»†æ¨ç†ï¼Œè€Œå¦ä¸€äº›é—®é¢˜åˆ™æ˜¾ç¤ºæ— æ”¹è¿›ï¼Œç”šè‡³ç²¾åº¦ä¸‹é™ã€‚è¿™æ¿€å‘äº†é€‚åº”æ€§çš„æ¨ç†ç­–ç•¥ï¼Œå³æ ¹æ®è¾“å…¥å®šåˆ¶æ¨ç†æ·±åº¦ã€‚ç„¶è€Œï¼Œä¹‹å‰çš„å·¥ä½œä¸»è¦ä¾§é‡äºå‡å°‘é•¿æ¨ç†è·¯å¾„ä¸­çš„å†—ä½™ï¼Œè€Œå¿½ç•¥äº†Long-CoTèŒƒå¼ä¹‹å¤–æ›´é«˜æ•ˆçš„ç­–ç•¥æ¢ç´¢ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°å‹çš„ä¸¤é˜¶æ®µè‡ªé€‚åº”é«˜æ•ˆæ¨ç†æ¡†æ¶ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬é€šè¿‡åˆå¹¶é•¿çŸ­CoTæ¨¡å‹æ„å»ºæ··åˆæ¨ç†æ¨¡å‹ï¼Œä»¥å®ç°å¤šæ ·åŒ–çš„æ¨ç†é£æ ¼ã€‚å…¶æ¬¡ï¼Œæˆ‘ä»¬åº”ç”¨ä¸¤çº§åå¥½è®­ç»ƒï¼Œå¼•å¯¼æ¨¡å‹é€‰æ‹©é€‚åˆçš„æ¨ç†é£æ ¼ï¼ˆç¾¤ç»„çº§åˆ«ï¼‰ï¼Œå¹¶åœ¨æ¯ç§é£æ ¼å†…åå¥½ç®€æ´æ­£ç¡®çš„æ¨ç†ï¼ˆå®ä¾‹çº§åˆ«ï¼‰ã€‚å®éªŒè¡¨æ˜ï¼Œä¸å…¶ä»–åŸºçº¿æ–¹æ³•ç›¸æ¯”ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨ä¿æŒæ€§èƒ½çš„åŒæ—¶ï¼Œæ˜¾è‘—é™ä½äº†æ¨ç†æˆæœ¬ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œåœ¨äº”ä¸ªæ•°å­¦æ•°æ®é›†ä¸Šï¼Œå¹³å‡æ¨ç†é•¿åº¦å‡å°‘äº†è¶…è¿‡50%ï¼Œçªæ˜¾äº†è‡ªé€‚åº”ç­–ç•¥åœ¨ä¼˜åŒ–å¤§å‹è¯­è¨€æ¨¡å‹æ¨ç†æ•ˆç‡æ–¹é¢çš„æ½œåŠ›ã€‚æˆ‘ä»¬çš„ä»£ç å¾ˆå¿«å°†åœ¨<a target="_blank" rel="noopener" href="https://github.com/StarDewXXX/AdaR1%E4%B8%8A%E5%8F%91%E5%B8%83%E3%80%82">https://github.com/StarDewXXX/AdaR1ä¸Šå‘å¸ƒã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.21659v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æ¢è®¨äº†é•¿æœŸè®¤çŸ¥æ¨ç†æ¨¡å‹åœ¨å¤„ç†å¤æ‚æ¨ç†ä»»åŠ¡æ—¶çš„é«˜æ€§èƒ½è¡¨ç°åŠå…¶å¸¦æ¥çš„æ•ˆç‡é—®é¢˜ã€‚ç ”ç©¶å‘ç°ï¼Œåœ¨ä¸åŒé—®é¢˜ä¸­ï¼Œä½¿ç”¨Long-CoTçš„æ”¶ç›Šæœ‰æ‰€ä¸åŒã€‚ä¸ºæ­¤ï¼Œæ–‡ç« æå‡ºäº†ä¸€ç§æ–°å‹çš„ä¸¤é˜¶æ®µè‡ªé€‚åº”é«˜æ•ˆæ¨ç†æ¡†æ¶ï¼Œé€šè¿‡ç»“åˆé•¿çŸ­æ¨ç†æ¨¡å‹å®ç°å¤šæ ·åŒ–æ¨ç†é£æ ¼ï¼Œå¹¶é€šè¿‡åŒçº§åå¥½è®­ç»ƒå¼•å¯¼æ¨¡å‹é€‰æ‹©é€‚å½“çš„æ¨ç†é£æ ¼ï¼ŒåŒæ—¶ä¼˜åŒ–æ¯ç§é£æ ¼å†…çš„ç®€æ´æ­£ç¡®æ€§ã€‚å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨ä¿æŒæ€§èƒ½çš„åŒæ—¶ï¼Œæ˜¾è‘—é™ä½æ¨ç†æˆæœ¬ï¼Œç‰¹åˆ«æ˜¯åœ¨äº”ä¸ªæ•°å­¦æ•°æ®é›†ä¸Šï¼Œå¹³å‡æ¨ç†é•¿åº¦å‡å°‘äº†50%ä»¥ä¸Šã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>é•¿æœŸè®¤çŸ¥æ¨ç†æ¨¡å‹åœ¨å¤æ‚ä»»åŠ¡ä¸­è¡¨ç°è‰¯å¥½ï¼Œä½†æ¨ç†æ•ˆç‡æˆä¸ºå…³é”®é—®é¢˜ã€‚</li>
<li>ä½¿ç”¨Long-CoTçš„æ”¶ç›Šåœ¨ä¸åŒé—®é¢˜ä¸­æœ‰æ‰€ä¸åŒã€‚</li>
<li>æå‡ºäº†ä¸€ä¸ªä¸¤é˜¶æ®µè‡ªé€‚åº”é«˜æ•ˆæ¨ç†æ¡†æ¶ï¼Œå®ç°å¤šæ ·åŒ–æ¨ç†é£æ ¼ã€‚</li>
<li>é€šè¿‡ç»“åˆé•¿çŸ­æ¨ç†æ¨¡å‹æ„å»ºæ··åˆæ¨ç†æ¨¡å‹ã€‚</li>
<li>é‡‡ç”¨åŒçº§åå¥½è®­ç»ƒï¼Œå¼•å¯¼æ¨¡å‹é€‰æ‹©é€‚å½“çš„æ¨ç†é£æ ¼ã€‚</li>
<li>å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨ä¿æŒæ€§èƒ½çš„åŒæ—¶ï¼Œæ˜¾è‘—é™ä½æ¨ç†æˆæœ¬ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.21659">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-88bb340d629bf87739297f4acd62cb56.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-86364842f179fc9066b99241de68d0b0.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-bf44a1eb4df9462dda3b7c0f51197437.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="BiasGuard-A-Reasoning-enhanced-Bias-Detection-Tool-For-Large-Language-Models"><a href="#BiasGuard-A-Reasoning-enhanced-Bias-Detection-Tool-For-Large-Language-Models" class="headerlink" title="BiasGuard: A Reasoning-enhanced Bias Detection Tool For Large Language   Models"></a>BiasGuard: A Reasoning-enhanced Bias Detection Tool For Large Language   Models</h2><p><strong>Authors:Zhiting Fan, Ruizhe Chen, Zuozhu Liu</strong></p>
<p>Identifying bias in LLM-generated content is a crucial prerequisite for ensuring fairness in LLMs. Existing methods, such as fairness classifiers and LLM-based judges, face limitations related to difficulties in understanding underlying intentions and the lack of criteria for fairness judgment. In this paper, we introduce BiasGuard, a novel bias detection tool that explicitly analyzes inputs and reasons through fairness specifications to provide accurate judgments. BiasGuard is implemented through a two-stage approach: the first stage initializes the model to explicitly reason based on fairness specifications, while the second stage leverages reinforcement learning to enhance its reasoning and judgment capabilities. Our experiments, conducted across five datasets, demonstrate that BiasGuard outperforms existing tools, improving accuracy and reducing over-fairness misjudgments. We also highlight the importance of reasoning-enhanced decision-making and provide evidence for the effectiveness of our two-stage optimization pipeline. </p>
<blockquote>
<p>è¯†åˆ«LLMç”Ÿæˆå†…å®¹ä¸­çš„åè§æ˜¯ä¿è¯LLMå…¬å¹³æ€§çš„é‡è¦å‰æã€‚ç°æœ‰æ–¹æ³•ï¼Œå¦‚å…¬å¹³æ€§åˆ†ç±»å™¨å’ŒåŸºäºLLMçš„åˆ¤å®šå™¨ï¼Œé¢ä¸´ç†è§£æ½œåœ¨æ„å›¾çš„å›°éš¾å’Œç¼ºä¹å…¬å¹³æ€§åˆ¤æ–­æ ‡å‡†çš„å±€é™æ€§ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬ä»‹ç»äº†BiasGuardï¼Œè¿™æ˜¯ä¸€ç§æ–°å‹åè§æ£€æµ‹å·¥å…·ï¼Œå®ƒå¯ä»¥é€šè¿‡æ˜ç¡®åˆ†æè¾“å…¥å†…å®¹å¹¶é€šè¿‡å…¬å¹³æ€§è§„èŒƒè¿›è¡Œæ¨ç†ï¼Œä»¥æä¾›å‡†ç¡®çš„åˆ¤æ–­ã€‚BiasGuardé€šè¿‡ä¸¤é˜¶æ®µæ–¹æ³•å®ç°ï¼šç¬¬ä¸€é˜¶æ®µåˆå§‹åŒ–æ¨¡å‹ï¼Œä½¿å…¶èƒ½å¤Ÿæ ¹æ®å…¬å¹³æ€§è§„èŒƒè¿›è¡Œæ˜ç¡®æ¨ç†ï¼Œè€Œç¬¬äºŒé˜¶æ®µåˆ©ç”¨å¼ºåŒ–å­¦ä¹ æé«˜å…¶æ¨ç†å’Œåˆ¤æ–­èƒ½åŠ›ã€‚æˆ‘ä»¬åœ¨äº”ä¸ªæ•°æ®é›†ä¸Šè¿›è¡Œçš„å®éªŒè¡¨æ˜ï¼ŒBiasGuardä¼˜äºç°æœ‰å·¥å…·ï¼Œæé«˜äº†å‡†ç¡®æ€§å¹¶å‡å°‘äº†è¿‡åº¦å…¬å¹³çš„è¯¯åˆ¤ã€‚æˆ‘ä»¬è¿˜å¼ºè°ƒäº†å¢å¼ºæ¨ç†å†³ç­–çš„é‡è¦æ€§ï¼Œå¹¶ä¸ºæˆ‘ä»¬çš„ä¸¤é˜¶æ®µä¼˜åŒ–ç®¡é“çš„æœ‰æ•ˆæ€§æä¾›äº†è¯æ®ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.21299v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æ–‡æœ¬ä»‹ç»äº†è¯†åˆ«LLMç”Ÿæˆå†…å®¹ä¸­çš„åè§å¯¹äºç¡®ä¿LLMå…¬å¹³æ€§çš„é‡è¦å‰æã€‚ç°æœ‰çš„æ–¹æ³•å­˜åœ¨ç†è§£å’Œè¯„ä¼°å…¬å¹³æ ‡å‡†çš„å›°éš¾ï¼Œå› æ­¤é¢ä¸´å±€é™æ€§ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°å‹åè§æ£€æµ‹å·¥å…·BiasGuardï¼Œå®ƒé€šè¿‡æ˜ç¡®åˆ†æè¾“å…¥å¹¶é€šè¿‡å…¬å¹³è§„èŒƒè¿›è¡Œæ¨ç†ï¼Œä»¥æä¾›å‡†ç¡®çš„åˆ¤æ–­ã€‚BiasGuardé€šè¿‡ä¸¤é˜¶æ®µæ–¹æ³•å®ç°ï¼šç¬¬ä¸€é˜¶æ®µæ ¹æ®å…¬å¹³è§„èŒƒè¿›è¡Œæ˜¾å¼æ¨ç†åˆå§‹åŒ–æ¨¡å‹ï¼Œç¬¬äºŒé˜¶æ®µåˆ©ç”¨å¼ºåŒ–å­¦ä¹ æé«˜æ¨ç†å’Œåˆ¤æ–­èƒ½åŠ›ã€‚å®éªŒè¯æ˜ï¼ŒBiasGuardåœ¨äº”ç»„æ•°æ®é›†ä¸Šçš„è¡¨ç°ä¼˜äºç°æœ‰å·¥å…·ï¼Œæé«˜äº†å‡†ç¡®æ€§å¹¶é™ä½äº†è¿‡åº¦å…¬å¹³è¯¯åˆ¤çš„æƒ…å†µã€‚æœ¬æ–‡è¿˜å¼ºè°ƒäº†åŸºäºæ¨ç†çš„å†³ç­–åˆ¶å®šçš„é‡è¦æ€§ï¼Œå¹¶æä¾›äº†ä¸¤é˜¶æ®µä¼˜åŒ–æµç¨‹æœ‰æ•ˆæ€§çš„è¯æ®ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>è¯†åˆ«LLMç”Ÿæˆå†…å®¹ä¸­çš„åè§æ˜¯ç¡®ä¿LLMå…¬å¹³æ€§çš„å…³é”®å‰æã€‚</li>
<li>ç°æœ‰åè§æ£€æµ‹æ–¹æ³•å­˜åœ¨ç†è§£å’Œè¯„ä¼°å…¬å¹³æ ‡å‡†çš„å›°éš¾ã€‚</li>
<li>æå‡ºäº†ä¸€ç§æ–°å‹åè§æ£€æµ‹å·¥å…·BiasGuardï¼Œå®ƒé€šè¿‡æ˜ç¡®åˆ†æè¾“å…¥å’Œé€šè¿‡å…¬å¹³è§„èŒƒè¿›è¡Œæ¨ç†æ¥æä¾›å‡†ç¡®åˆ¤æ–­ã€‚</li>
<li>BiasGuardé‡‡ç”¨ä¸¤é˜¶æ®µæ–¹æ³•ï¼Œé¦–å…ˆæ ¹æ®å…¬å¹³è§„èŒƒè¿›è¡Œæ˜¾å¼æ¨ç†åˆå§‹åŒ–æ¨¡å‹ï¼Œç„¶ååˆ©ç”¨å¼ºåŒ–å­¦ä¹ æé«˜æ¨ç†å’Œåˆ¤æ–­èƒ½åŠ›ã€‚</li>
<li>å®éªŒè¯æ˜BiasGuardåœ¨äº”ç»„æ•°æ®é›†ä¸Šçš„è¡¨ç°ä¼˜äºç°æœ‰å·¥å…·ã€‚</li>
<li>BiasGuardæé«˜äº†å‡†ç¡®æ€§å¹¶é™ä½äº†è¿‡åº¦å…¬å¹³è¯¯åˆ¤çš„æƒ…å†µã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.21299">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-6e4bf4ab3d825b3b457037ade68f38d1.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-afccdeb181de95951be6fc329237e953.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-bef2a652b38bc2d5769f4940556cc85a.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="LLMs-for-Engineering-Teaching-Models-to-Design-High-Powered-Rockets"><a href="#LLMs-for-Engineering-Teaching-Models-to-Design-High-Powered-Rockets" class="headerlink" title="LLMs for Engineering: Teaching Models to Design High Powered Rockets"></a>LLMs for Engineering: Teaching Models to Design High Powered Rockets</h2><p><strong>Authors:Toby Simonds</strong></p>
<p>Large Language Models (LLMs) have transformed software engineering, but their application to physical engineering domains remains underexplored. This paper evaluates LLMsâ€™ capabilities in high-powered rocketry design through RocketBench, a benchmark connecting LLMs to high-fidelity rocket simulations. We test models on two increasingly complex design tasks: target altitude optimization and precision landing challenges. Our findings reveal that while state-of-the-art LLMs demonstrate strong baseline engineering knowledge, they struggle to iterate on their designs when given simulation results and ultimately plateau below human performance levels. However, when enhanced with reinforcement learning (RL), we show that a 7B parameter model outperforms both SoTA foundation models and human experts. This research demonstrates that RL-trained LLMs can serve as effective tools for complex engineering optimization, potentially transforming engineering domains beyond software development. </p>
<blockquote>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å·²ç»æ”¹å˜äº†è½¯ä»¶å·¥ç¨‹çš„é¢è²Œï¼Œä½†å®ƒä»¬åœ¨ç‰©ç†å·¥ç¨‹é¢†åŸŸçš„åº”ç”¨ä»ç„¶è¢«å¿½è§†ã€‚æœ¬æ–‡é€šè¿‡RocketBenchè¿™ä¸€å°†LLMä¸é«˜ç²¾åº¦ç«ç®­æ¨¡æ‹Ÿç›¸ç»“åˆçš„åŸºå‡†æµ‹è¯•ï¼Œè¯„ä¼°äº†LLMåœ¨ç«ç®­è®¾è®¡é¢†åŸŸçš„èƒ½åŠ›ã€‚æˆ‘ä»¬åœ¨ä¸¤ä¸ªæ—¥ç›Šå¤æ‚çš„ä»»åŠ¡ä¸Šæµ‹è¯•äº†æ¨¡å‹ï¼šç›®æ ‡é«˜åº¦ä¼˜åŒ–å’Œç²¾ç¡®ç€é™†æŒ‘æˆ˜ã€‚æˆ‘ä»¬çš„ç ”ç©¶å‘ç°ï¼Œè™½ç„¶æœ€æ–°çš„LLMå±•ç¤ºäº†å¼ºå¤§çš„åŸºçº¿å·¥ç¨‹çŸ¥è¯†ï¼Œä½†å®ƒä»¬åœ¨ç»™å®šæ¨¡æ‹Ÿç»“æœæ—¶å¯¹è®¾è®¡è¿›è¡Œè¿­ä»£æ—¶é¢ä¸´å›°éš¾ï¼Œæœ€ç»ˆæ€§èƒ½æ°´å¹³ä½äºäººç±»ã€‚ç„¶è€Œï¼Œå½“ä½¿ç”¨å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰è¿›è¡Œå¢å¼ºæ—¶ï¼Œæˆ‘ä»¬è¯æ˜äº†ä¸€ä¸ªæ‹¥æœ‰7äº¿å‚æ•°çš„æ¨¡å‹è¶…è¿‡äº†æœ€æ–°æŠ€æœ¯çš„åŸºå‡†æ¨¡å‹å’Œäººç±»ä¸“å®¶ã€‚è¿™é¡¹ç ”ç©¶è¡¨æ˜ï¼Œç»è¿‡RLè®­ç»ƒçš„LLMå¯ä»¥ä½œä¸ºå¤æ‚å·¥ç¨‹ä¼˜åŒ–çš„æœ‰æ•ˆå·¥å…·ï¼Œæœ‰æ½œåŠ›æ”¹å˜è½¯ä»¶å¼€å‘ä»¥å¤–çš„å·¥ç¨‹é¢†åŸŸã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.19394v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨è½¯ä»¶å·¥ç¨‹ä¸­çš„åº”ç”¨å·²ç›¸å½“æˆç†Ÿï¼Œä½†åœ¨ç‰©ç†å·¥ç¨‹é¢†åŸŸçš„åº”ç”¨ä»ç„¶ç¼ºä¹ç ”ç©¶ã€‚æœ¬æ–‡åˆ©ç”¨RocketBenchåŸºå‡†æµ‹è¯•è¯„ä¼°äº†LLMsåœ¨é«˜åŠŸç‡ç«ç®­è®¾è®¡ä¸­çš„èƒ½åŠ›ï¼Œæµ‹è¯•åŒ…æ‹¬ç›®æ ‡é«˜åº¦ä¼˜åŒ–å’Œç²¾å‡†ç€é™†æŒ‘æˆ˜ç­‰ä¸¤ä¸ªé€’è¿›å¼è®¾è®¡ä»»åŠ¡ã€‚ç ”ç©¶ç»“æœæ˜¾ç¤ºï¼Œå°½ç®¡ç°æœ‰LLMså±•ç°å‡ºè‰¯å¥½çš„å·¥ç¨‹åŸºç¡€çŸ¥è¯†ï¼Œä½†åœ¨æ¨¡æ‹Ÿç»“æœåé¦ˆçš„è¿­ä»£è®¾è®¡ä¸Šå­˜åœ¨å›°éš¾ï¼Œæœ€ç»ˆæ€§èƒ½æœªèƒ½è¶…è¶Šäººç±»æ°´å¹³ã€‚ç„¶è€Œï¼Œé€šè¿‡å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰è¿›è¡Œè®­ç»ƒåï¼Œä¸€ä¸ªæ‹¥æœ‰7äº¿å‚æ•°çš„æ¨¡å‹è¡¨ç°å‡ºè¶…è¶Šå½“å‰å‰æ²¿åŸºç¡€æ¨¡å‹çš„æ€§èƒ½ï¼Œç”šè‡³åœ¨æŸäº›æ–¹é¢è¶…è¶Šäº†äººç±»ä¸“å®¶ã€‚æ­¤ç ”ç©¶å±•ç¤ºäº†RL-è®­ç»ƒçš„LLMsåœ¨å¤æ‚å·¥ç¨‹ä¼˜åŒ–ä¸­çš„æ½œåŠ›ï¼Œæœ‰æœ›ä¸ºå·¥ç¨‹é¢†åŸŸçš„å‘å±•å¸¦æ¥å˜é©ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨ç‰©ç†å·¥ç¨‹é¢†åŸŸçš„åº”ç”¨å°šå¾…æ¢ç´¢ã€‚</li>
<li>RocketBenchåŸºå‡†æµ‹è¯•è¢«ç”¨æ¥è¯„ä¼°LLMsåœ¨é«˜åŠŸç‡ç«ç®­è®¾è®¡ä¸­çš„åº”ç”¨èƒ½åŠ›ã€‚</li>
<li>LLMså±•ç°å‡ºè‰¯å¥½çš„å·¥ç¨‹åŸºç¡€çŸ¥è¯†ï¼Œä½†åœ¨æ¨¡æ‹Ÿç»“æœåé¦ˆçš„è¿­ä»£è®¾è®¡ä¸Šå­˜åœ¨å›°éš¾ã€‚</li>
<li>LLMsçš„æ€§èƒ½åœ¨å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰å¢å¼ºåæœ‰æ‰€æå‡ï¼Œç”šè‡³è¶…è¶Šäº†äººç±»ä¸“å®¶çš„è¡¨ç°ã€‚</li>
<li>RL-è®­ç»ƒçš„LLMsåœ¨å¤æ‚å·¥ç¨‹ä¼˜åŒ–ä¸­å…·æœ‰æ½œåŠ›ã€‚</li>
<li>LLMsçš„å˜é©æ€§å½±å“å¯èƒ½ä¼šè¶…è¶Šè½¯ä»¶å·¥ç¨‹é¢†åŸŸï¼Œæ‹“å±•è‡³æ›´å¹¿æ³›çš„å·¥ç¨‹é¢†åŸŸã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.19394">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-02adee3bbae0abefc6043e4174b6d9d9.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-7f3ea181c49e2c7bbe1af35cd0fee256.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-88a7af346ad180344aa60e089e07d99d.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="PolyMath-Evaluating-Mathematical-Reasoning-in-Multilingual-Contexts"><a href="#PolyMath-Evaluating-Mathematical-Reasoning-in-Multilingual-Contexts" class="headerlink" title="PolyMath: Evaluating Mathematical Reasoning in Multilingual Contexts"></a>PolyMath: Evaluating Mathematical Reasoning in Multilingual Contexts</h2><p><strong>Authors:Yiming Wang, Pei Zhang, Jialong Tang, Haoran Wei, Baosong Yang, Rui Wang, Chenshu Sun, Feitong Sun, Jiran Zhang, Junxuan Wu, Qiqian Cang, Yichang Zhang, Fei Huang, Junyang Lin, Fei Huang, Jingren Zhou</strong></p>
<p>In this paper, we introduce PolyMath, a multilingual mathematical reasoning benchmark covering 18 languages and 4 easy-to-hard difficulty levels. Our benchmark ensures difficulty comprehensiveness, language diversity, and high-quality translation, making it a highly discriminative multilingual mathematical benchmark in the era of reasoning LLMs. We conduct a comprehensive evaluation for advanced LLMs and find that even Qwen-3-235B-A22B-Thinking and Gemini-2.5-pro, achieve only 54.6 and 52.2 benchmark scores, with about 40% accuracy under the highest level From a language perspective, our benchmark reveals several key challenges of LLMs in multilingual reasoning: (1) Reasoning performance varies widely across languages for current LLMs; (2) Input-output language consistency is low in reasoning LLMs and may be correlated with performance; (3) The thinking length differs significantly by language for current LLMs. Additionally, we demonstrate that controlling the output language in the instructions has the potential to affect reasoning performance, especially for some low-resource languages, suggesting a promising direction for improving multilingual capabilities in LLMs. </p>
<blockquote>
<p>æœ¬æ–‡ä»‹ç»äº†PolyMathï¼Œè¿™æ˜¯ä¸€ä¸ªæ¶µç›–18ç§è¯­è¨€å’Œ4ä¸ªéš¾åº¦ç­‰çº§ï¼ˆä»ç®€å•åˆ°å›°éš¾ï¼‰çš„å¤šè¯­è¨€æ•°å­¦æ¨ç†åŸºå‡†æµ‹è¯•ã€‚æˆ‘ä»¬çš„åŸºå‡†æµ‹è¯•ç¡®ä¿äº†éš¾åº¦å…¨é¢æ€§ã€è¯­è¨€å¤šæ ·æ€§å’Œé«˜è´¨é‡ç¿»è¯‘ï¼Œä½¿å…¶æˆä¸ºæ¨ç†å¤§å‹è¯­è¨€æ¨¡å‹æ—¶ä»£çš„é«˜åº¦åŒºåˆ†æ€§çš„å¤šè¯­è¨€æ•°å­¦åŸºå‡†æµ‹è¯•ã€‚æˆ‘ä»¬å¯¹å…ˆè¿›çš„å¤§å‹è¯­è¨€æ¨¡å‹è¿›è¡Œäº†å…¨é¢è¯„ä¼°ï¼Œå‘ç°å³ä½¿æ˜¯Qwen-3-235B-A22B-Thinkingå’ŒGemini-2.5-proï¼Œä¹Ÿä»…è·å¾—54.6å’Œ52.2çš„åŸºå‡†æµ‹è¯•åˆ†æ•°ï¼Œæœ€é«˜éš¾åº¦ä¸‹çš„å‡†ç¡®ç‡çº¦ä¸º40%ã€‚ä»è¯­è¨€è§’åº¦çœ‹ï¼Œæˆ‘ä»¬çš„åŸºå‡†æµ‹è¯•æ­ç¤ºäº†å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å¤šè¯­è¨€æ¨ç†çš„å‡ ä¸ªå…³é”®æŒ‘æˆ˜ï¼šï¼ˆ1ï¼‰å½“å‰å¤§å‹è¯­è¨€æ¨¡å‹çš„æ¨ç†æ€§èƒ½åœ¨ä¸åŒè¯­è¨€ä¸­å·®å¼‚å¾ˆå¤§ï¼›ï¼ˆ2ï¼‰æ¨ç†å¤§å‹è¯­è¨€æ¨¡å‹ä¸­è¾“å…¥è¾“å‡ºè¯­è¨€çš„ä¸€è‡´æ€§è¾ƒä½ï¼Œå¯èƒ½ä¸æ€§èƒ½ç›¸å…³ï¼›ï¼ˆ3ï¼‰å½“å‰å¤§å‹è¯­è¨€æ¨¡å‹çš„æ€è€ƒé•¿åº¦åœ¨ä¸åŒè¯­è¨€ä¸­å­˜åœ¨æ˜¾è‘—å·®å¼‚ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜è¯æ˜ï¼ŒæŒ‡ä»¤ä¸­æ§åˆ¶è¾“å‡ºè¯­è¨€æœ‰å¯èƒ½å½±å“æ¨ç†æ€§èƒ½ï¼Œå°¤å…¶æ˜¯å¯¹äºä¸€äº›èµ„æºè¾ƒå°‘çš„è¯­è¨€ï¼Œè¿™ä¸ºæé«˜å¤§å‹è¯­è¨€æ¨¡å‹çš„å¤šè¯­è¨€èƒ½åŠ›æä¾›äº†æœ‰å¸Œæœ›çš„æ–¹å‘ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.18428v2">PDF</a> Work in Progress</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†PolyMathå¤šè¯­è¨€æ•°å­¦æ¨ç†åŸºå‡†æµ‹è¯•ï¼Œè¦†ç›–18ç§è¯­è¨€å’Œ4ä¸ªéš¾åº¦çº§åˆ«ã€‚è¯¥åŸºå‡†æµ‹è¯•ç¡®ä¿äº†éš¾åº¦å…¨é¢æ€§ã€è¯­è¨€å¤šæ ·æ€§å’Œé«˜è´¨é‡ç¿»è¯‘ï¼Œæ˜¯å½“ä»£æ¨ç†å¤§å‹è¯­è¨€æ¨¡å‹ä¸­çš„é«˜åº¦åŒºåˆ†æ€§å¤šè¯­è¨€æ•°å­¦åŸºå‡†æµ‹è¯•ã€‚å¯¹å…ˆè¿›çš„å¤§å‹è¯­è¨€æ¨¡å‹è¿›è¡Œäº†å…¨é¢è¯„ä¼°ï¼Œå‘ç°å³ä½¿æ˜¯é¡¶å°–æ¨¡å‹ï¼Œåœ¨é«˜éš¾åº¦çº§åˆ«ä¸‹çš„å‡†ç¡®ç‡ä¹Ÿåªæœ‰çº¦40%ã€‚æ­¤å¤–ï¼Œè¯¥åŸºå‡†æµ‹è¯•æ­ç¤ºäº†å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å¤šè¯­è¨€æ¨ç†ä¸­çš„å…³é”®æŒ‘æˆ˜ï¼ŒåŒ…æ‹¬ä¸åŒè¯­è¨€çš„æ¨ç†æ€§èƒ½å·®å¼‚å¤§ã€è¾“å…¥è¾“å‡ºè¯­è¨€ä¸€è‡´æ€§ä½ã€ä¸åŒè¯­è¨€çš„æ€è€ƒé•¿åº¦å·®å¼‚æ˜¾è‘—ç­‰ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>PolyMathæ˜¯ä¸€ä¸ªå¤šè¯­è¨€æ•°å­¦æ¨ç†åŸºå‡†æµ‹è¯•ï¼ŒåŒ…å«18ç§è¯­è¨€å’Œ4ä¸ªéš¾åº¦çº§åˆ«ï¼Œå¼ºè°ƒéš¾åº¦å…¨é¢æ€§ã€è¯­è¨€å¤šæ ·æ€§å’Œé«˜è´¨é‡ç¿»è¯‘ã€‚</li>
<li>ç°æœ‰é¡¶çº§å¤§å‹è¯­è¨€æ¨¡å‹åœ¨é«˜éš¾åº¦çº§åˆ«ä¸‹çš„å‡†ç¡®ç‡ä»…çº¦40%ï¼Œè¯´æ˜å­˜åœ¨æ˜¾è‘—æŒ‘æˆ˜ã€‚</li>
<li>å¤§å‹è¯­è¨€æ¨¡å‹åœ¨ä¸åŒè¯­è¨€çš„æ¨ç†æ€§èƒ½å­˜åœ¨æ˜¾è‘—å·®å¼‚ã€‚</li>
<li>æ¨ç†å¤§å‹è¯­è¨€æ¨¡å‹çš„è¾“å…¥è¾“å‡ºè¯­è¨€ä¸€è‡´æ€§è¾ƒä½ï¼Œå¯èƒ½å½±å“æ€§èƒ½ã€‚</li>
<li>ä¸åŒè¯­è¨€åœ¨å¤§å‹è¯­è¨€æ¨¡å‹ä¸­çš„æ€è€ƒé•¿åº¦æœ‰æ˜¾è‘—å·®å¼‚ã€‚</li>
<li>æŒ‡ä»¤è¾“å‡ºè¯­è¨€çš„æ§åˆ¶å¯¹æ¨ç†æ€§èƒ½æœ‰å½±å“ï¼Œç‰¹åˆ«æ˜¯é’ˆå¯¹ä¸€äº›ä½èµ„æºè¯­è¨€ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.18428">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-24b983806c5b2de5c25a691ede49213a.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-42054d723cdd7946b52032c6cbe48b99.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-57b272e2c62248ec6d14e19aed222f44.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-1073b7a28568edfaa8c772e7eec09fae.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-a8ec32a75c93dc8e3aced2b9da137ead.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-7843ab0c760e41c1b8ee0a389f22667c.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="Weight-Ensembling-Improves-Reasoning-in-Language-Models"><a href="#Weight-Ensembling-Improves-Reasoning-in-Language-Models" class="headerlink" title="Weight Ensembling Improves Reasoning in Language Models"></a>Weight Ensembling Improves Reasoning in Language Models</h2><p><strong>Authors:Xingyu Dang, Christina Baek, Kaiyue Wen, Zico Kolter, Aditi Raghunathan</strong></p>
<p>We investigate a failure mode that arises during the training of reasoning models, where the diversity of generations begins to collapse, leading to suboptimal test-time scaling. Notably, the Pass@1 rate reliably improves during supervised finetuning (SFT), but Pass@k rapidly deteriorates. Surprisingly, a simple intervention of interpolating the weights of the latest SFT checkpoint with an early checkpoint, otherwise known as WiSE-FT, almost completely recovers Pass@k while also improving Pass@1. The WiSE-FT variant achieves better test-time scaling (Best@k, majority vote) and achieves superior results with less data when tuned further by reinforcement learning. Finally, we find that WiSE-FT provides complementary performance gains that cannot be achieved only through diversity-inducing decoding strategies, like temperature scaling. We formalize a bias-variance tradeoff of Pass@k with respect to the expectation and variance of Pass@1 over the test distribution. We find that WiSE-FT can reduce bias and variance simultaneously, while temperature scaling inherently trades off between bias and variance. </p>
<blockquote>
<p>æˆ‘ä»¬ç ”ç©¶äº†ä¸€ç§åœ¨è®­ç»ƒæ¨ç†æ¨¡å‹è¿‡ç¨‹ä¸­å‡ºç°çš„æ•…éšœæ¨¡å¼ï¼Œå…¶ä¸­ç”Ÿæˆçš„å¤šæ ·æ€§å¼€å§‹å´©æºƒï¼Œå¯¼è‡´æµ‹è¯•æ—¶çš„æ‰©å±•æ€§ä¸ä½³ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œè™½ç„¶åœ¨æœ‰ç›‘ç£çš„å¾®è°ƒï¼ˆSFTï¼‰è¿‡ç¨‹ä¸­Pass@1ç‡å¯é åœ°æé«˜äº†ï¼Œä½†Pass@kå´è¿…é€Ÿæ¶åŒ–ã€‚ä»¤äººæƒŠè®¶çš„æ˜¯ï¼Œé€šè¿‡æ’å€¼æœ€æ–°SFTæ£€æŸ¥ç‚¹ä¸æ—©æœŸæ£€æŸ¥ç‚¹çš„æƒé‡ï¼ˆä¹Ÿç§°ä¸ºWiSE-FTï¼‰çš„ç®€å•å¹²é¢„æªæ–½ï¼Œå‡ ä¹å¯ä»¥å®Œå…¨æ¢å¤Pass@kï¼ŒåŒæ—¶æé«˜Pass@1ã€‚WiSE-FTå˜ä½“å®ç°äº†æ›´å¥½çš„æµ‹è¯•æ—¶æ‰©å±•æ€§ï¼ˆBest@kï¼Œå¤šæ•°æŠ•ç¥¨ï¼‰ï¼Œå¹¶ä¸”åœ¨é€šè¿‡å¼ºåŒ–å­¦ä¹ è¿›ä¸€æ­¥è°ƒæ•´æ—¶ï¼Œç”¨æ›´å°‘çš„æ•°æ®å®ç°äº†ä¼˜è¶Šçš„ç»“æœã€‚æœ€åï¼Œæˆ‘ä»¬å‘ç°WiSE-FTæä¾›äº†æ— æ³•é€šè¿‡è¯¸å¦‚æ¸©åº¦ç¼©æ”¾ä¹‹ç±»çš„ä»…ç”¨äºè¯±å¯¼å¤šæ ·æ€§çš„è§£ç ç­–ç•¥æ¥å®ç°çš„äº’è¡¥æ€§èƒ½æå‡ã€‚æˆ‘ä»¬æ­£å¼æå‡ºäº†å…³äºPass@kçš„æœŸæœ›å’Œæ–¹å·®ä¹‹é—´çš„åå·®-æ–¹å·®æƒè¡¡ï¼Œåœ¨æµ‹è¯•åˆ†å¸ƒä¸Šå…³äºPass@1çš„æœŸæœ›å’Œæ–¹å·®ã€‚æˆ‘ä»¬å‘ç°WiSE-FTå¯ä»¥åŒæ—¶å‡å°‘åå·®å’Œæ–¹å·®ï¼Œè€Œæ¸©åº¦ç¼©æ”¾æœ¬è´¨ä¸Šæ˜¯åœ¨åå·®å’Œæ–¹å·®ä¹‹é—´è¿›è¡Œæƒè¡¡ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.10478v3">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æ¢è®¨äº†è®­ç»ƒæ¨ç†æ¨¡å‹æ—¶å‡ºç°çš„å¤šæ ·æ€§å´©æºƒé—®é¢˜ï¼Œè¡¨ç°ä¸ºåœ¨ç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰æœŸé—´Pass@1ç‡è™½æœ‰æ‰€æ”¹å–„ï¼Œä½†Pass@kå´è¿…é€Ÿæ¶åŒ–ã€‚é‡‡ç”¨ä¸€ç§ç®€å•å¹²é¢„æªæ–½â€”â€”æ’å€¼æœ€æ–°SFTæ£€æŸ¥ç‚¹ä¸æ—©æœŸæ£€æŸ¥ç‚¹çš„æƒé‡ï¼ˆå³WiSE-FTï¼‰ï¼Œå‡ ä¹å¯ä»¥å®Œå…¨æ¢å¤Pass@kå¹¶æ”¹å–„Pass@1ã€‚WiSE-FTåœ¨æµ‹è¯•æ—¶å®ç°äº†æ›´å¥½çš„æ‰©å±•æ€§ï¼Œå¹¶åœ¨è¿›ä¸€æ­¥é€šè¿‡å¼ºåŒ–å­¦ä¹ æ—¶è·å¾—æ›´å¥½çš„ç»“æœã€‚WiSE-FTæä¾›äº†æ— æ³•é€šè¿‡å•ä¸€è§£ç ç­–ç•¥å®ç°çš„æ€§èƒ½å¢ç›Šï¼Œå¦‚æ¸©åº¦ç¼©æ”¾ã€‚æœ¬æ–‡è¿˜æå‡ºäº†å…³äºPass@kçš„æœŸæœ›ä¸æ–¹å·®ä¹‹é—´çš„åå·®æ–¹å·®æƒè¡¡ï¼Œå‘ç°WiSE-FTå¯ä»¥åŒæ—¶å‡å°‘åå·®å’Œæ–¹å·®ï¼Œè€Œæ¸©åº¦ç¼©æ”¾åˆ™å­˜åœ¨å›ºæœ‰çš„åå·®ä¸æ–¹å·®æƒè¡¡é—®é¢˜ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>è®­ç»ƒæ¨ç†æ¨¡å‹æ—¶ä¼šå‡ºç°å¤šæ ·æ€§å´©æºƒé—®é¢˜ï¼Œè¡¨ç°ä¸ºPass@kæŒ‡æ ‡çš„å¿«é€Ÿæ¶åŒ–ã€‚</li>
<li>ç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰æœŸé—´ï¼Œè™½ç„¶Pass@1ç‡æœ‰æ‰€æå‡ï¼Œä½†Pass@kæŒ‡æ ‡å´ä¸‹é™ã€‚</li>
<li>WiSE-FTæ–¹æ³•é€šè¿‡æ’å€¼æœ€æ–°å’Œæ—©æœŸæ£€æŸ¥ç‚¹çš„æƒé‡ï¼Œèƒ½æœ‰æ•ˆæ¢å¤Pass@kå¹¶æ”¹å–„Pass@1ã€‚</li>
<li>WiSE-FTæ–¹æ³•åœ¨æµ‹è¯•æ—¶å®ç°äº†æ›´å¥½çš„æ‰©å±•æ€§ï¼Œå¹¶é€šè¿‡å¼ºåŒ–å­¦ä¹ è¿›ä¸€æ­¥æå‡äº†æ€§èƒ½ã€‚</li>
<li>WiSE-FTæä¾›çš„æ€§èƒ½å¢ç›Šæ— æ³•é€šè¿‡å•ä¸€è§£ç ç­–ç•¥ï¼ˆå¦‚æ¸©åº¦ç¼©æ”¾ï¼‰å®ç°ã€‚</li>
<li>å­˜åœ¨Pass@kæŒ‡æ ‡çš„æœŸæœ›ä¸æ–¹å·®ä¹‹é—´çš„åå·®æ–¹å·®æƒè¡¡é—®é¢˜ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.10478">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-7c3a33fb7ac55d54a70a524104a0fb86.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-35ab658160b62d3f0d616864b4337d50.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-5947e4a2da656061a1b5b79012acce62.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-644c79548a4c3a9ed2164f571ce6a777.jpg" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="VisualPuzzles-Decoupling-Multimodal-Reasoning-Evaluation-from-Domain-Knowledge"><a href="#VisualPuzzles-Decoupling-Multimodal-Reasoning-Evaluation-from-Domain-Knowledge" class="headerlink" title="VisualPuzzles: Decoupling Multimodal Reasoning Evaluation from Domain   Knowledge"></a>VisualPuzzles: Decoupling Multimodal Reasoning Evaluation from Domain   Knowledge</h2><p><strong>Authors:Yueqi Song, Tianyue Ou, Yibo Kong, Zecheng Li, Graham Neubig, Xiang Yue</strong></p>
<p>Current multimodal benchmarks often conflate reasoning with domain-specific knowledge, making it difficult to isolate and evaluate general reasoning abilities in non-expert settings. To address this, we introduce VisualPuzzles, a benchmark that targets visual reasoning while deliberately minimizing reliance on specialized knowledge. VisualPuzzles consists of diverse questions spanning five categories: algorithmic, analogical, deductive, inductive, and spatial reasoning. One major source of our questions is manually translated logical reasoning questions from the Chinese Civil Service Examination. Experiments show that VisualPuzzles requires significantly less intensive domain-specific knowledge and more complex reasoning compared to benchmarks like MMMU, enabling us to better evaluate genuine multimodal reasoning. Evaluations show that state-of-the-art multimodal large language models consistently lag behind human performance on VisualPuzzles, and that strong performance on knowledge-intensive benchmarks does not necessarily translate to success on reasoning-focused, knowledge-light tasks. Additionally, reasoning enhancements such as scaling up inference compute (with â€œthinkingâ€ modes) yield inconsistent gains across models and task types, and we observe no clear correlation between model size and performance. We also found that models exhibit different reasoning and answering patterns on VisualPuzzles compared to benchmarks with heavier emphasis on knowledge. VisualPuzzles offers a clearer lens through which to evaluate reasoning capabilities beyond factual recall and domain knowledge. </p>
<blockquote>
<p>å½“å‰çš„å¤šæ¨¡æ€åŸºå‡†æµ‹è¯•å¾€å¾€å°†æ¨ç†ä¸ç‰¹å®šé¢†åŸŸçš„çŸ¥è¯†æ··æ·†åœ¨ä¸€èµ·ï¼Œåœ¨éä¸“ä¸šç¯å¢ƒä¸­å¾ˆéš¾å­¤ç«‹åœ°è¯„ä¼°ä¸€èˆ¬çš„æ¨ç†èƒ½åŠ›ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬æ¨å‡ºäº†VisualPuzzlesï¼Œè¿™æ˜¯ä¸€ä¸ªæ—¨åœ¨é’ˆå¯¹è§†è§‰æ¨ç†çš„åŸºå‡†æµ‹è¯•ï¼ŒåŒæ—¶åˆ»æ„å‡å°‘å¯¹ä¸“ä¸šçŸ¥è¯†çš„ä¾èµ–ã€‚VisualPuzzlesåŒ…å«äº”ä¸ªç±»åˆ«çš„é—®é¢˜ï¼šç®—æ³•ã€ç±»æ¯”ã€æ¼”ç»ã€å½’çº³å’Œç©ºé—´æ¨ç†ã€‚æˆ‘ä»¬çš„é—®é¢˜çš„ä¸»è¦æ¥æºæ˜¯æ‰‹åŠ¨ç¿»è¯‘è‡ªä¸­å›½å…¬åŠ¡å‘˜è€ƒè¯•ä¸­çš„é€»è¾‘æ¨ç†é—®é¢˜ã€‚å®éªŒè¡¨æ˜ï¼Œç›¸è¾ƒäºMMMUç­‰åŸºå‡†æµ‹è¯•ï¼ŒVisualPuzzlesè¦æ±‚çš„ä¸“ä¸šé¢†åŸŸçŸ¥è¯†æ›´å°‘ã€æ¨ç†æ›´ä¸ºå¤æ‚ï¼Œä»è€Œèƒ½å¤Ÿæ›´å¥½åœ°è¯„ä¼°çœŸæ­£çš„å¤šæ¨¡æ€æ¨ç†èƒ½åŠ›ã€‚è¯„ä¼°æ˜¾ç¤ºï¼Œæœ€å…ˆè¿›çš„å¤šå…ƒæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹åœ¨VisualPuzzlesä¸Šçš„è¡¨ç°å§‹ç»ˆè½åäºäººç±»ï¼Œè€Œä¸”åœ¨çŸ¥è¯†å¯†é›†å‹çš„åŸºå‡†æµ‹è¯•ä¸Šè¡¨ç°å‡ºè‰²å¹¶ä¸ä¸€å®šèƒ½åœ¨æ³¨é‡æ¨ç†ã€è½»çŸ¥è¯†çš„ä»»åŠ¡ä¸Šå–å¾—æˆåŠŸã€‚æ­¤å¤–ï¼Œè¯¸å¦‚é€šè¿‡æ‰©å¤§æ¨ç†è®¡ç®—è§„æ¨¡ï¼ˆä½¿ç”¨â€œæ€è€ƒâ€æ¨¡å¼ï¼‰ç­‰å¢å¼ºæ¨ç†çš„æ–¹æ³•åœ¨å„ç±»æ¨¡å‹ä¸ä»»åŠ¡ä¸­å¸¦æ¥çš„æ”¶ç›Šå¹¶ä¸ä¸€è‡´ï¼Œå¹¶ä¸”æˆ‘ä»¬è§‚å¯Ÿåˆ°æ¨¡å‹å¤§å°ä¸æ€§èƒ½ä¹‹é—´å¹¶æ²¡æœ‰æ˜ç¡®çš„å…³è”ã€‚æˆ‘ä»¬è¿˜å‘ç°ï¼Œä¸é‚£äº›æ›´ä¾§é‡äºçŸ¥è¯†çš„åŸºå‡†æµ‹è¯•ç›¸æ¯”ï¼Œæ¨¡å‹åœ¨VisualPuzzlesä¸Šå±•ç°å‡ºä¸åŒçš„æ¨ç†å’Œç­”é¢˜æ¨¡å¼ã€‚VisualPuzzlesæä¾›äº†ä¸€ä¸ªæ›´æ¸…æ™°çš„é€é•œï¼Œè®©æˆ‘ä»¬èƒ½å¤Ÿè¯„ä¼°è¶…è¶Šäº‹å®å›å¿†å’Œé¢†åŸŸçŸ¥è¯†çš„æ¨ç†èƒ½åŠ›ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.10342v3">PDF</a> 56 pages, 43 figures</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†VisualPuzzlesè¿™ä¸€åŸºå‡†æµ‹è¯•ï¼Œæ—¨åœ¨é’ˆå¯¹è§†è§‰æ¨ç†èƒ½åŠ›è¿›è¡Œè¯„ä¼°ï¼Œå¹¶å°½é‡å‡å°‘å¯¹ä¸“ä¸šçŸ¥è¯†é¢†åŸŸçš„ä¾èµ–ã€‚é€šè¿‡äº”å¤§ç±»é—®é¢˜ï¼ˆç®—æ³•ã€ç±»æ¯”ã€æ¼”ç»ã€å½’çº³å’Œç©ºé—´æ¨ç†ï¼‰æ¥æµ‹è¯•å—è¯•è€…çš„æ¨ç†èƒ½åŠ›ã€‚å®éªŒè¡¨æ˜ï¼Œç›¸è¾ƒäºå…¶ä»–åŸºå‡†æµ‹è¯•ï¼ŒVisualPuzzlesæ›´ä¾§é‡äºè¯„ä¼°çœŸå®çš„è·¨æ¨¡æ€æ¨ç†èƒ½åŠ›ï¼Œå¯¹ä¸“ä¸šçŸ¥è¯†çš„è¦æ±‚è¾ƒä½ã€‚åŒæ—¶ï¼Œç°æœ‰çš„è·¨æ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹åœ¨VisualPuzzlesä¸Šçš„è¡¨ç°ä»ç„¶è½åäºäººç±»ï¼Œä¸”æ¨ç†èƒ½åŠ›çš„å¢å¼ºæªæ–½ï¼ˆå¦‚å¢åŠ æ¨ç†è®¡ç®—æˆ–æ¨¡å‹è§„æ¨¡ï¼‰æ•ˆæœå¹¶ä¸æ˜¾è‘—ã€‚æ€»ä½“è€Œè¨€ï¼ŒVisualPuzzlesæä¾›äº†ä¸€ä¸ªæ›´æ¸…æ™°çš„è§†è§’æ¥è¯„ä¼°è¶…è¶Šäº‹å®å›å¿†å’Œä¸“ä¸šçŸ¥è¯†é¢†åŸŸçš„æ¨ç†èƒ½åŠ›ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>VisualPuzzlesæ˜¯ä¸€ä¸ªæ—¨åœ¨è¯„ä¼°è§†è§‰æ¨ç†èƒ½åŠ›çš„åŸºå‡†æµ‹è¯•ï¼Œå‡å°‘å¯¹ä¸“ä¸šçŸ¥è¯†é¢†åŸŸçš„ä¾èµ–ã€‚</li>
<li>å®ƒåŒ…å«äº”å¤§ç±»é—®é¢˜ï¼Œæ¶µç›–å¤šç§æ¨ç†ç±»å‹ã€‚</li>
<li>å®éªŒæ˜¾ç¤ºï¼ŒVisualPuzzlesæ›´ä¾§é‡äºè¯„ä¼°çœŸå®çš„è·¨æ¨¡æ€æ¨ç†èƒ½åŠ›ï¼Œå¯¹ä¸“ä¸šçŸ¥è¯†çš„è¦æ±‚è¾ƒä½ã€‚</li>
<li>ç°æœ‰è·¨æ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹åœ¨VisualPuzzlesä¸Šçš„è¡¨ç°è½åäºäººç±»ã€‚</li>
<li>æ¨ç†èƒ½åŠ›å¢å¼ºæªæ–½æ•ˆæœå¹¶ä¸æ˜¾è‘—ï¼Œä¸”æ¨¡å‹è¡¨ç°ä¸æ¨¡å‹è§„æ¨¡ä¹‹é—´æ— æ˜æ˜¾å…³è”ã€‚</li>
<li>VisualPuzzlesæä¾›çš„è¯„ä¼°æ–¹å¼èƒ½æ›´æ¸…æ™°åœ°è§‚å¯Ÿæ¨¡å‹çš„æ¨ç†èƒ½åŠ›ï¼Œè¶…è¶Šäº‹å®å›å¿†å’Œä¸“ä¸šçŸ¥è¯†é¢†åŸŸã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.10342">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-11b7a8773c14e16edf7107e5acbb111d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-7d978ad9899040c77f89efe8c0764d40.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-ea435c18c082e0889e2175cf11074b9e.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-2b70d49771c8059a717a01fa4cce49f1.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c6bb5ec5fc171fdeea62265fbf6ca1c4.jpg" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1><h2 id="JuDGE-Benchmarking-Judgment-Document-Generation-for-Chinese-Legal-System"><a href="#JuDGE-Benchmarking-Judgment-Document-Generation-for-Chinese-Legal-System" class="headerlink" title="JuDGE: Benchmarking Judgment Document Generation for Chinese Legal   System"></a>JuDGE: Benchmarking Judgment Document Generation for Chinese Legal   System</h2><p><strong>Authors:Weihang Su, Baoqing Yue, Qingyao Ai, Yiran Hu, Jiaqi Li, Changyue Wang, Kaiyuan Zhang, Yueyue Wu, Yiqun Liu</strong></p>
<p>This paper introduces JuDGE (Judgment Document Generation Evaluation), a novel benchmark for evaluating the performance of judgment document generation in the Chinese legal system. We define the task as generating a complete legal judgment document from the given factual description of the case. To facilitate this benchmark, we construct a comprehensive dataset consisting of factual descriptions from real legal cases, paired with their corresponding full judgment documents, which serve as the ground truth for evaluating the quality of generated documents. This dataset is further augmented by two external legal corpora that provide additional legal knowledge for the task: one comprising statutes and regulations, and the other consisting of a large collection of past judgment documents. In collaboration with legal professionals, we establish a comprehensive automated evaluation framework to assess the quality of generated judgment documents across various dimensions. We evaluate various baseline approaches, including few-shot in-context learning, fine-tuning, and a multi-source retrieval-augmented generation (RAG) approach, using both general and legal-domain LLMs. The experimental results demonstrate that, while RAG approaches can effectively improve performance in this task, there is still substantial room for further improvement. All the codes and datasets are available at: <a target="_blank" rel="noopener" href="https://github.com/oneal2000/JuDGE">https://github.com/oneal2000/JuDGE</a>. </p>
<blockquote>
<p>æœ¬æ–‡ä»‹ç»äº†JuDGEï¼ˆåˆ¤å†³ä¹¦ç”Ÿæˆè¯„ä¼°ï¼‰è¿™ä¸€æ–°å‹åŸºå‡†æµ‹è¯•ï¼Œç”¨äºè¯„ä¼°ä¸­æ–‡æ³•å¾‹ä½“ç³»ä¸­åˆ¤å†³ä¹¦ç”Ÿæˆç³»ç»Ÿçš„æ€§èƒ½ã€‚æˆ‘ä»¬å°†ä»»åŠ¡å®šä¹‰ä¸ºæ ¹æ®ç»™å®šçš„æ¡ˆä»¶äº‹å®æè¿°ç”Ÿæˆå®Œæ•´çš„æ³•å¾‹åˆ¤å†³ä¹¦ã€‚ä¸ºäº†æ¨åŠ¨è¿™ä¸€åŸºå‡†æµ‹è¯•çš„å‘å±•ï¼Œæˆ‘ä»¬æ„å»ºäº†ä¸€ä¸ªç»¼åˆæ•°æ®é›†ï¼Œå…¶ä¸­åŒ…æ‹¬çœŸå®æ³•å¾‹æ¡ˆä»¶çš„æ¡ˆä»¶äº‹å®æè¿°ä¸å…¶å¯¹åº”çš„å®Œæ•´åˆ¤å†³ä¹¦ï¼Œè¿™äº›åˆ¤å†³ä¹¦ä½œä¸ºè¯„ä¼°ç”Ÿæˆæ–‡æ¡£è´¨é‡çš„çœŸå®æ ‡å‡†ã€‚è¯¥æ•°æ®é›†é€šè¿‡ä¸¤ä¸ªå¤–éƒ¨æ³•å¾‹è¯­æ–™åº“è¿›è¡Œäº†æ‰©å……ï¼Œè¿™äº›è¯­æ–™åº“ä¸ºä»»åŠ¡æä¾›äº†é¢å¤–çš„æ³•å¾‹çŸ¥è¯†ï¼šä¸€ä¸ªåŒ…å«æ³•è§„å’Œæ¡ä¾‹ï¼Œå¦ä¸€ä¸ªåˆ™åŒ…å«å¤§é‡çš„è¿‡å»åˆ¤å†³ä¹¦ã€‚æˆ‘ä»¬ä¸æ³•å¾‹ä¸“ä¸šäººå£«åˆä½œï¼Œå»ºç«‹äº†ä¸€ä¸ªå…¨é¢çš„è‡ªåŠ¨åŒ–è¯„ä¼°æ¡†æ¶ï¼Œä»å¤šä¸ªç»´åº¦è¯„ä¼°ç”Ÿæˆçš„åˆ¤å†³ä¹¦çš„å“è´¨ã€‚æˆ‘ä»¬è¯„ä¼°äº†å¤šç§åŸºçº¿æ–¹æ³•ï¼ŒåŒ…æ‹¬ä¸Šä¸‹æ–‡å­¦ä¹ ã€å¾®è°ƒä»¥åŠä½¿ç”¨é€šç”¨å’Œå¤§èŒƒå›´æ³•å¾‹é¢†åŸŸå¤§å‹è¯­è¨€æ¨¡å‹çš„ä»¥å¤šæºæ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰çš„æ–¹æ³•ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè™½ç„¶RAGæ–¹æ³•å¯ä»¥æœ‰æ•ˆæé«˜æ­¤ä»»åŠ¡çš„æ€§èƒ½ï¼Œä½†ä»å­˜åœ¨å¾ˆå¤§çš„æ”¹è¿›ç©ºé—´ã€‚æ‰€æœ‰ä»£ç å’Œæ•°æ®é›†å‡å¯åœ¨ï¼š<a target="_blank" rel="noopener" href="https://github.com/oneal2000/JuDGE%E4%B8%8A%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/oneal2000/JuDGEä¸Šæ‰¾åˆ°ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.14258v3">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†JuDGEï¼ˆåˆ¤å†³æ–‡ä¹¦ç”Ÿæˆè¯„ä¼°ï¼‰åŸºå‡†æµ‹è¯•ï¼Œè¯¥æµ‹è¯•æ—¨åœ¨è¯„ä¼°ä¸­æ–‡æ³•å¾‹ç³»ç»Ÿä¸­åˆ¤å†³æ–‡ä¹¦ç”Ÿæˆæ€§èƒ½ã€‚æ–‡ç« å®šä¹‰äº†ä»»åŠ¡ç›®æ ‡ä¸ºä»ç»™å®šçš„æ¡ˆä»¶äº‹å®æè¿°ç”Ÿæˆå®Œæ•´çš„æ³•å¾‹åˆ¤å†³ä¹¦ï¼Œå¹¶æ„å»ºäº†ä¸€ä¸ªåŒ…å«çœŸå®æ³•å¾‹æ¡ˆä¾‹äº‹å®æè¿°åŠå…¶å¯¹åº”åˆ¤å†³ä¹¦çš„ç»¼åˆæ•°æ®é›†ä½œä¸ºè¯„ä¼°æ ‡å‡†ã€‚åŒæ—¶å¼•å…¥ä¸¤ä¸ªé¢å¤–çš„æ³•å¾‹è¯­æ–™åº“ä¸ºä»»åŠ¡æä¾›é¢å¤–çš„æ³•å¾‹çŸ¥è¯†ã€‚é€šè¿‡ä¸æ³•å¾‹ä¸“ä¸šäººå£«åˆä½œï¼Œå»ºç«‹äº†å…¨é¢çš„è‡ªåŠ¨åŒ–è¯„ä¼°æ¡†æ¶ï¼Œä»ä¸åŒç»´åº¦è¯„ä¼°ç”Ÿæˆçš„åˆ¤å†³æ–‡ä¹¦è´¨é‡ã€‚æ–‡ç« è¿˜è¯„ä¼°äº†å‡ ç§åŸºçº¿æ–¹æ³•ï¼ŒåŒ…æ‹¬å°æ ·æœ¬ä¸Šä¸‹æ–‡å­¦ä¹ ã€å¾®è°ƒä»¥åŠå¤šæºæ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰æ–¹æ³•ï¼Œä½¿ç”¨é€šç”¨å’Œæ³•å¾‹é¢†åŸŸçš„LLMï¼ˆå¤§å‹é¢„è®­ç»ƒæ¨¡å‹ï¼‰ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè™½ç„¶RAGæ–¹æ³•å¯ä»¥æœ‰æ•ˆæé«˜ä»»åŠ¡æ€§èƒ½ï¼Œä½†ä»æœ‰å¾ˆå¤§çš„æ”¹è¿›ç©ºé—´ã€‚æ‰€æœ‰ä»£ç å’Œæ•°æ®é›†å‡å¯åœ¨ä»¥ä¸‹é“¾æ¥æ‰¾åˆ°ï¼š<a target="_blank" rel="noopener" href="https://github.com/oneal2000/JuDGE">é“¾æ¥åœ°å€</a>ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¼•å…¥JuDGEåŸºå‡†æµ‹è¯•ï¼Œæ—¨åœ¨è¯„ä¼°ä¸­æ–‡æ³•å¾‹ç³»ç»Ÿä¸­åˆ¤å†³æ–‡ä¹¦ç”Ÿæˆæ€§èƒ½ã€‚</li>
<li>ä»»åŠ¡å®šä¹‰ä¸ºä»ç»™å®šçš„æ¡ˆä»¶äº‹å®æè¿°ç”Ÿæˆå®Œæ•´çš„æ³•å¾‹åˆ¤å†³ä¹¦ã€‚</li>
<li>æ„å»ºäº†ä¸€ä¸ªç»¼åˆæ•°æ®é›†ï¼ŒåŒ…å«çœŸå®æ³•å¾‹æ¡ˆä¾‹çš„äº‹å®æè¿°å’Œå¯¹åº”åˆ¤å†³ä¹¦ï¼Œä½œä¸ºè¯„ä¼°æ ‡å‡†ã€‚</li>
<li>å¼•å…¥ä¸¤ä¸ªæ³•å¾‹è¯­æ–™åº“æä¾›é¢å¤–çš„æ³•å¾‹çŸ¥è¯†ã€‚</li>
<li>å»ºç«‹å…¨é¢çš„è‡ªåŠ¨åŒ–è¯„ä¼°æ¡†æ¶ï¼Œä»ä¸åŒç»´åº¦è¯„ä¼°ç”Ÿæˆçš„åˆ¤å†³æ–‡ä¹¦è´¨é‡ã€‚</li>
<li>è¯„ä¼°äº†å‡ ç§åŸºçº¿æ–¹æ³•ï¼ŒåŒ…æ‹¬å°æ ·æœ¬ä¸Šä¸‹æ–‡å­¦ä¹ ã€å¾®è°ƒä»¥åŠRAGæ–¹æ³•ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.14258">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-c6d6bcdd83d9b07e4d843e17aa1238df.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c14b175f466ff4ca8c464bfb43ec4adf.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-e3e76fe575a8b299d2cbc5630dba7c8e.jpg" align="middle">
</details>


<h1 id="-9"><a href="#-9" class="headerlink" title=""></a></h1><h2 id="Are-Transformers-Able-to-Reason-by-Connecting-Separated-Knowledge-in-Training-Data"><a href="#Are-Transformers-Able-to-Reason-by-Connecting-Separated-Knowledge-in-Training-Data" class="headerlink" title="Are Transformers Able to Reason by Connecting Separated Knowledge in   Training Data?"></a>Are Transformers Able to Reason by Connecting Separated Knowledge in   Training Data?</h2><p><strong>Authors:Yutong Yin, Zhaoran Wang</strong></p>
<p>Humans exhibit remarkable compositional reasoning by integrating knowledge from various sources. For example, if someone learns ( B &#x3D; f(A) ) from one source and ( C &#x3D; g(B) ) from another, they can deduce ( C&#x3D;g(B)&#x3D;g(f(A)) ) even without encountering ( ABC ) together, showcasing the generalization ability of human intelligence. In this paper, we introduce a synthetic learning task, â€œFTCTâ€ (Fragmented at Training, Chained at Testing), to validate the potential of Transformers in replicating this skill and interpret its inner mechanism. In the training phase, data consist of separated knowledge fragments from an overall causal graph. During testing, Transformers must infer complete causal graph traces by integrating these fragments. Our findings demonstrate that few-shot Chain-of-Thought prompting enables Transformers to perform compositional reasoning on FTCT by revealing correct combinations of fragments, even if such combinations were absent in the training data. Furthermore, the emergence of compositional reasoning ability is strongly correlated with the model complexity and training-testing data similarity. We propose, both theoretically and empirically, that Transformers learn an underlying generalizable program from training, enabling effective compositional reasoning during testing. </p>
<blockquote>
<p>äººç±»åœ¨æ•´åˆæ¥è‡ªä¸åŒæ¥æºçš„çŸ¥è¯†æ—¶ï¼Œå±•ç°å‡ºæƒŠäººçš„ç»„åˆæ¨ç†èƒ½åŠ›ã€‚ä¾‹å¦‚ï¼Œå¦‚æœæœ‰äººä»æŸä¸€æ¥æºå­¦ä¹ åˆ°ï¼ˆB&#x3D;fï¼ˆAï¼‰ï¼‰ï¼Œä»å¦ä¸€æ¥æºå­¦ä¹ åˆ°ï¼ˆC&#x3D;gï¼ˆBï¼‰ï¼‰ï¼Œé‚£ä¹ˆå³ä½¿ä»–ä»¬æ²¡æœ‰ä¸€èµ·é‡åˆ°è¿‡ï¼ˆABCï¼‰ï¼Œä¹Ÿèƒ½æ¨å¯¼å‡ºï¼ˆC&#x3D;gï¼ˆBï¼‰&#x3D;gï¼ˆfï¼ˆAï¼‰ï¼‰ï¼‰ï¼Œè¿™å±•ç¤ºäº†äººç±»æ™ºæ…§çš„æ¨å¹¿èƒ½åŠ›ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬ä»‹ç»äº†ä¸€ç§åˆæˆå­¦ä¹ ä»»åŠ¡â€œFTCTâ€ï¼ˆè®­ç»ƒæ—¶åˆ†æ•£ï¼Œæµ‹è¯•æ—¶ä¸²è”ï¼‰ï¼Œä»¥éªŒè¯Transformeråœ¨å¤åˆ¶è¿™ç§æŠ€èƒ½æ–¹é¢çš„æ½œåŠ›å¹¶è§£é‡Šå…¶å†…åœ¨æœºåˆ¶ã€‚åœ¨è®­ç»ƒé˜¶æ®µï¼Œæ•°æ®ç”±æ¥è‡ªæ•´ä½“å› æœå›¾çš„åˆ†ç¦»çŸ¥è¯†ç‰‡æ®µç»„æˆã€‚åœ¨æµ‹è¯•æœŸé—´ï¼ŒTransformerå¿…é¡»é€šè¿‡æ•´åˆè¿™äº›ç‰‡æ®µæ¥æ¨æ–­å®Œæ•´çš„å› æœå›¾è½¨è¿¹ã€‚æˆ‘ä»¬çš„ç ”ç©¶å‘ç°ï¼Œå³ä½¿åœ¨è®­ç»ƒæ•°æ®ä¸­ç¼ºå°‘æ­£ç¡®çš„ç‰‡æ®µç»„åˆï¼Œé€šè¿‡å°‘é‡æç¤ºçš„â€œæ€ç»´é“¾â€ä¹Ÿèƒ½ä¿ƒä½¿Transformeråœ¨FTCTä¸Šè¡¨ç°å‡ºç»„åˆæ¨ç†èƒ½åŠ›ã€‚æ­¤å¤–ï¼Œç»„åˆæ¨ç†èƒ½åŠ›çš„å‡ºç°ä¸æ¨¡å‹å¤æ‚åº¦å’Œè®­ç»ƒ-æµ‹è¯•æ•°æ®ç›¸ä¼¼æ€§å¯†åˆ‡ç›¸å…³ã€‚æˆ‘ä»¬ä»ç†è®ºå’Œå®è·µä¸¤æ–¹é¢æå‡ºï¼ŒTransformerä»è®­ç»ƒä¸­å­¦ä¹ äº†ä¸€ä¸ªå¯æ¨å¹¿çš„åŸºæœ¬ç¨‹åºï¼Œä»è€Œåœ¨æµ‹è¯•æœŸé—´å®ç°æœ‰æ•ˆçš„ç»„åˆæ¨ç†ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.15857v4">PDF</a> Accepted by ICLR 2025</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†äººç±»å±•ç°å‡ºçš„å“è¶Šç»„åˆæ¨ç†èƒ½åŠ›ï¼Œé€šè¿‡æ•´åˆæ¥è‡ªä¸åŒæ¥æºçš„çŸ¥è¯†è¿›è¡Œæ¨ç†ã€‚ä¸ºéªŒè¯äººå·¥æ™ºèƒ½æ¨¡å‹ï¼Œå¦‚Transformerï¼Œæ˜¯å¦å…·å¤‡æ­¤èƒ½åŠ›ï¼Œå¹¶è§£è¯»å…¶å†…åœ¨æœºåˆ¶ï¼Œæ–‡ä¸­å¼•å…¥äº†ä¸€é¡¹åä¸ºâ€œFTCTâ€ï¼ˆè®­ç»ƒæ—¶åˆ†æ•£ï¼Œæµ‹è¯•æ—¶ä¸²è”ï¼‰çš„åˆæˆå­¦ä¹ ä»»åŠ¡ã€‚ç ”ç©¶å‘ç°ï¼Œé€šè¿‡å°‘æ•°å›åˆçš„æ€è€ƒæç¤ºï¼ˆChain-of-Thoughtï¼‰ï¼ŒTransformerèƒ½åœ¨FTCTä»»åŠ¡ä¸Šæ‰§è¡Œç»„åˆæ¨ç†ï¼Œå¹¶æ­£ç¡®ç»„åˆè®­ç»ƒæ•°æ®ä¸­ä¸å­˜åœ¨çš„ç‰‡æ®µã€‚æ­¤å¤–ï¼Œæ¨¡å‹çš„å¤æ‚æ€§å’Œè®­ç»ƒæµ‹è¯•æ•°æ®çš„ç›¸ä¼¼æ€§å¯¹ç»„åˆæ¨ç†èƒ½åŠ›çš„å‡ºç°æœ‰é‡è¦å½±å“ã€‚æœ¬æ–‡æå‡ºï¼ŒTransformerä»è®­ç»ƒä¸­å­¦ä¹ åˆ°çš„é€šç”¨ç¨‹åºåœ¨æµ‹è¯•æ—¶èƒ½æœ‰æ•ˆè¿›è¡Œç»„åˆæ¨ç†ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>äººç±»èƒ½æ•´åˆæ¥è‡ªä¸åŒæ¥æºçš„çŸ¥è¯†è¿›è¡Œç»„åˆæ¨ç†ã€‚</li>
<li>â€œFTCTâ€ä»»åŠ¡è¢«ç”¨æ¥éªŒè¯Transformeræ˜¯å¦å…·æœ‰ç»„åˆæ¨ç†èƒ½åŠ›ã€‚</li>
<li>é€šè¿‡Chain-of-Thoughtæç¤ºï¼ŒTransformerèƒ½åœ¨æµ‹è¯•æ—¶æ‰§è¡Œç»„åˆæ¨ç†ã€‚</li>
<li>ç»„åˆæ¨ç†èƒ½åŠ›å—åˆ°æ¨¡å‹å¤æ‚æ€§å’Œè®­ç»ƒæµ‹è¯•æ•°æ®ç›¸ä¼¼æ€§çš„å½±å“ã€‚</li>
<li>Transformeré€šè¿‡è®­ç»ƒå­¦ä¹ åˆ°é€šç”¨ç¨‹åºï¼Œåœ¨æµ‹è¯•æ—¶èƒ½å¤Ÿè¿›è¡Œæœ‰æ•ˆç»„åˆæ¨ç†ã€‚</li>
<li>æ­£ç¡®ç»„åˆçŸ¥è¯†ç¢ç‰‡æ˜¯æ‰§è¡Œç»„åˆæ¨ç†çš„å…³é”®ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.15857">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-e97528241200e7fcf62a2d4211b821a9.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-df1a1e1d6c7939762f9f833466e43c67.jpg" align="middle">
</details>


<h1 id="-10"><a href="#-10" class="headerlink" title=""></a></h1><h2 id="LongProc-Benchmarking-Long-Context-Language-Models-on-Long-Procedural-Generation"><a href="#LongProc-Benchmarking-Long-Context-Language-Models-on-Long-Procedural-Generation" class="headerlink" title="LongProc: Benchmarking Long-Context Language Models on Long Procedural   Generation"></a>LongProc: Benchmarking Long-Context Language Models on Long Procedural   Generation</h2><p><strong>Authors:Xi Ye, Fangcong Yin, Yinghui He, Joie Zhang, Howard Yen, Tianyu Gao, Greg Durrett, Danqi Chen</strong></p>
<p>Existing benchmarks for evaluating long-context language models (LCLMs) primarily focus on long-context recall, requiring models to produce short responses based on a few critical snippets while processing thousands of irrelevant tokens. We introduce LongProc (Long Procedural Generation), a new benchmark that requires both the integration of highly dispersed information and long-form generation. LongProc consists of six diverse procedural generation tasks, such as extracting structured information from HTML pages into a TSV format and executing complex search procedures to create travel plans. These tasks challenge LCLMs by testing their ability to follow detailed procedural instructions, synthesize and reason over dispersed information, and generate structured, long-form outputs (up to 8K tokens). Furthermore, as these tasks adhere to deterministic procedures and yield structured outputs, they enable reliable rule-based evaluation. We evaluated 23 LCLMs, including instruction-tuned models and recent reasoning models, on LongProc at three difficulty levels, with the maximum number of output tokens set at 500, 2K, and 8K. Notably, while all tested models claim a context window size above 32K tokens, open-weight models typically falter on 2K-token tasks, and closed-source models like GPT-4o show significant degradation on 8K-token tasks. Reasoning models achieve stronger overall performance in long-form generation, benefiting from long CoT training. Further analysis reveals that LCLMs struggle to maintain long-range coherence in long-form generations. These findings highlight critical limitations in current LCLMs and suggest substantial room for improvement. Data and code available at: <a target="_blank" rel="noopener" href="https://princeton-pli.github.io/LongProc">https://princeton-pli.github.io/LongProc</a>. </p>
<blockquote>
<p>ç°æœ‰çš„è¯„ä¼°é•¿è¯­å¢ƒè¯­è¨€æ¨¡å‹ï¼ˆLCLMï¼‰çš„åŸºå‡†æµ‹è¯•ä¸»è¦ä¾§é‡äºé•¿è¯­å¢ƒå›å¿†ï¼Œè¦æ±‚æ¨¡å‹åœ¨å¤„ç†æˆåƒä¸Šä¸‡çš„æ— å…³æ ‡è®°æ—¶ï¼ŒåŸºäºå‡ ä¸ªå…³é”®ç‰‡æ®µäº§ç”ŸçŸ­å›ç­”ã€‚æˆ‘ä»¬å¼•å…¥äº†LongProcï¼ˆé•¿ç¨‹åºç”Ÿæˆï¼‰è¿™ä¸€æ–°åŸºå‡†æµ‹è¯•ï¼Œå®ƒè¦æ±‚æ—¢æœ‰é«˜åº¦åˆ†æ•£çš„ä¿¡æ¯æ•´åˆèƒ½åŠ›ï¼Œåˆæœ‰é•¿å½¢å¼ç”Ÿæˆèƒ½åŠ›ã€‚LongProcç”±å…­ä¸ªä¸åŒçš„ç¨‹åºç”Ÿæˆä»»åŠ¡ç»„æˆï¼Œä¾‹å¦‚ä»HTMLé¡µé¢æå–ç»“æ„åŒ–ä¿¡æ¯å¹¶è½¬æ¢ä¸ºTSVæ ¼å¼ï¼Œä»¥åŠæ‰§è¡Œå¤æ‚çš„æœç´¢ç¨‹åºä»¥åˆ›å»ºæ—…è¡Œè®¡åˆ’ã€‚è¿™äº›ä»»åŠ¡é€šè¿‡æµ‹è¯•LCLMéµå¾ªè¯¦ç»†ç¨‹åºæŒ‡ä»¤ã€åˆæˆå’Œæ¨ç†åˆ†æ•£ä¿¡æ¯ã€ç”Ÿæˆç»“æ„åŒ–é•¿å½¢å¼è¾“å‡ºï¼ˆæœ€å¤šè¾¾8Kä»¤ç‰Œï¼‰çš„èƒ½åŠ›æ¥æŒ‘æˆ˜LCLMã€‚æ­¤å¤–ï¼Œç”±äºè¿™äº›ä»»åŠ¡éµå¾ªç¡®å®šæ€§ç¨‹åºå¹¶äº§ç”Ÿç»“æ„åŒ–è¾“å‡ºï¼Œå› æ­¤å®ƒä»¬èƒ½å¤Ÿè¿›è¡Œå¯é çš„åŸºäºè§„åˆ™çš„è¯„ä»·ã€‚æˆ‘ä»¬åœ¨LongProcä¸Šè¯„ä¼°äº†23ä¸ªLCLMï¼ŒåŒ…æ‹¬æŒ‡ä»¤è°ƒæ•´æ¨¡å‹å’Œæœ€æ–°çš„æ¨ç†æ¨¡å‹ï¼Œéš¾åº¦åˆ†ä¸ºä¸‰ä¸ªçº§åˆ«ï¼Œè¾“å‡ºä»¤ç‰Œçš„æœ€å¤§æ•°é‡è®¾å®šä¸º500ã€2Kå’Œ8Kã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œå°½ç®¡æ‰€æœ‰æµ‹è¯•è¿‡çš„æ¨¡å‹éƒ½å£°ç§°å…¶è¯­å¢ƒçª—å£å¤§å°è¶…è¿‡32Kä»¤ç‰Œï¼Œä½†å¼€æ”¾æƒé‡æ¨¡å‹é€šå¸¸åœ¨2Kä»¤ç‰Œä»»åŠ¡ä¸Šè¡¨ç°ä¸ä½³ï¼Œè€ŒåƒGPT-4oè¿™æ ·çš„é—­æºæ¨¡å‹åœ¨8Kä»¤ç‰Œä»»åŠ¡ä¸Šè¡¨ç°å‡ºæ˜¾è‘—é€€åŒ–ã€‚æ¨ç†æ¨¡å‹åœ¨é•¿å½¢å¼ç”Ÿæˆæ–¹é¢å®ç°æ›´å¼ºçš„æ€»ä½“æ€§èƒ½ï¼Œå¾—ç›Šäºé•¿æœŸä¸Šä¸‹æ–‡è®­ç»ƒã€‚è¿›ä¸€æ­¥çš„åˆ†æè¡¨æ˜ï¼ŒLCLMåœ¨é•¿ç¯‡ç”Ÿæˆä¸­éš¾ä»¥ä¿æŒé•¿è¿œçš„ä¸€è‡´æ€§ã€‚è¿™äº›å‘ç°çªå‡ºäº†å½“å‰LCLMçš„å…³é”®å±€é™æ€§ï¼Œå¹¶è¡¨æ˜æœ‰å¾ˆå¤§çš„æ”¹è¿›ç©ºé—´ã€‚[é¡¹ç›®ç½‘ç«™ï¼š<a target="_blank" rel="noopener" href="https://princeton-pli.github.io/LongProc]">https://princeton-pli.github.io/LongProc]</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.05414v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>é•¿æ–‡æœ¬è¯­å¢ƒè¯­è¨€æ¨¡å‹ï¼ˆLCLMï¼‰çš„ç°æœ‰è¯„ä¼°åŸºå‡†ä¸»è¦å…³æ³¨é•¿æ–‡æœ¬å›å¿†èƒ½åŠ›ï¼Œè¦æ±‚æ¨¡å‹åœ¨å¤„ç†å¤§é‡æ— å…³æ ‡è®°çš„åŒæ—¶ï¼ŒåŸºäºå‡ ä¸ªå…³é”®ç‰‡æ®µäº§ç”Ÿç®€çŸ­å›åº”ã€‚æœ¬æ–‡ä»‹ç»äº†ä¸€ä¸ªæ–°çš„è¯„ä¼°åŸºå‡†â€”â€”LongProcï¼ˆé•¿ç¨‹åºç”Ÿæˆï¼‰ï¼Œå®ƒè¦æ±‚æ—¢æ•´åˆé«˜åº¦åˆ†æ•£çš„ä¿¡æ¯ï¼Œåˆè¿›è¡Œé•¿æ–‡æœ¬ç”Ÿæˆã€‚LongProcåŒ…å«å…­ä¸ªä¸åŒçš„ç¨‹åºç”Ÿæˆä»»åŠ¡ï¼Œå¦‚ä»HTMLé¡µé¢æå–ç»“æ„åŒ–ä¿¡æ¯å¹¶è½¬æ¢ä¸ºTSVæ ¼å¼å’Œæ‰§è¡Œå¤æ‚çš„æœç´¢ç¨‹åºä»¥åˆ¶å®šæ—…è¡Œè®¡åˆ’ç­‰ã€‚è¿™äº›ä»»åŠ¡æŒ‘æˆ˜äº†LCLMï¼Œæµ‹è¯•äº†å…¶éµå¾ªè¯¦ç»†ç¨‹åºæŒ‡ä»¤ã€åˆæˆå’Œæ¨ç†åˆ†æ•£ä¿¡æ¯ä»¥åŠç”Ÿæˆç»“æ„åŒ–é•¿æ–‡æœ¬è¾“å‡ºçš„èƒ½åŠ›ã€‚æˆ‘ä»¬åœ¨ä¸‰ä¸ªéš¾åº¦çº§åˆ«ä¸Šå¯¹23ä¸ªLCLMè¿›è¡Œäº†LongProcè¯„ä¼°ï¼ŒåŒ…æ‹¬æŒ‡ä»¤è°ƒæ•´æ¨¡å‹å’Œæœ€æ–°æ¨ç†æ¨¡å‹ã€‚ç»“æœæç¤ºå½“å‰LCLMå­˜åœ¨å…³é”®å±€é™ï¼Œåœ¨é•¿æ–‡æœ¬ç”Ÿæˆä¸­ä»å­˜åœ¨å¤§é‡æ”¹è¿›ç©ºé—´ã€‚è¯¦ç»†æ•°æ®å’Œä»£ç å¯è®¿é—®ï¼š<a target="_blank" rel="noopener" href="https://princeton-pli.github.io/LongProc%E3%80%82">https://princeton-pli.github.io/LongProcã€‚</a></p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>ç°æœ‰è¯„ä¼°åŸºå‡†ä¸»è¦å…³æ³¨é•¿æ–‡æœ¬è¯­å¢ƒè¯­è¨€æ¨¡å‹ï¼ˆLCLMï¼‰çš„é•¿æ–‡æœ¬å›å¿†èƒ½åŠ›ã€‚</li>
<li>æœ¬æ–‡æå‡ºäº†ä¸€ä¸ªæ–°çš„è¯„ä¼°åŸºå‡†LongProcï¼ŒåŒ…å«å…­ä¸ªç¨‹åºç”Ÿæˆä»»åŠ¡ï¼Œæ—¨åœ¨æµ‹è¯•LCLMåœ¨é•¿æ–‡æœ¬å¤„ç†ä¸­çš„ç»¼åˆèƒ½åŠ›ã€‚</li>
<li>LongProcä»»åŠ¡è¦æ±‚æ¨¡å‹æ•´åˆé«˜åº¦åˆ†æ•£çš„ä¿¡æ¯å¹¶è¿›è¡Œé•¿æ–‡æœ¬ç”Ÿæˆï¼ŒæŒ‘æˆ˜äº†LCLMçš„å¤šç§èƒ½åŠ›ã€‚</li>
<li>åœ¨LongProcåŸºå‡†ä¸Šè¯„ä¼°äº†23ä¸ªLCLMï¼Œå‘ç°ç°æœ‰æ¨¡å‹åœ¨é•¿æ–‡æœ¬ç”Ÿæˆæ–¹é¢å­˜åœ¨å…³é”®å±€é™ã€‚</li>
<li>æ¨ç†æ¨¡å‹åœ¨é•¿æ–‡æœ¬ç”Ÿæˆæ–¹é¢è¡¨ç°è¾ƒå¼ºï¼Œå¾—ç›Šäºå…¶é•¿æœŸæ¨ç†è®­ç»ƒã€‚</li>
<li>LCLMåœ¨é•¿æ–‡æœ¬ç”Ÿæˆä¸­ç»´æŒé•¿æœŸè¿è´¯æ€§æ–¹é¢å­˜åœ¨å›°éš¾ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.05414">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-4ce28306b47a1dbffbb2bbf4146a3eb1.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-e4a38315911c4a91d92aa1ad4a03a35d.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-2d898e6f0c0ac5cc49aa0982bd4b3ac7.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-6440a9afa5c04fdaf8703baefdc84a0d.jpg" align="middle">
</details>


<h1 id="-11"><a href="#-11" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-05-02/R1_Reasoning/">https://kedreamix.github.io/Talk2Paper/Paper/2025-05-02/R1_Reasoning/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/R1-Reasoning/">
                                    <span class="chip bg-color">R1_Reasoning</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-05-02/LLM/">
                    <div class="card-image">
                        
                        <img src="https://pic1.zhimg.com/v2-3e0b279adcebf07254a23f8c5be9f8c9.jpg" class="responsive-img" alt="LLM">
                        
                        <span class="card-title">LLM</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            LLM æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-05-02  COMPACT COMPositional Atomic-to-Complex Visual Capability Tuning
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-05-02
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/LLM/" class="post-category">
                                    LLM
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/LLM/">
                        <span class="chip bg-color">LLM</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-05-01/Talking%20Head%20Generation/">
                    <div class="card-image">
                        
                        <img src="https://pic1.zhimg.com/v2-37b87189576c03cf50993939fe028f40.jpg" class="responsive-img" alt="Talking Head Generation">
                        
                        <span class="card-title">Talking Head Generation</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Talking Head Generation æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-05-01  IM-Portrait Learning 3D-aware Video Diffusion for Photorealistic   Talking Heads from Monocular Videos
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-05-01
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Talking-Head-Generation/" class="post-category">
                                    Talking Head Generation
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Talking-Head-Generation/">
                        <span class="chip bg-color">Talking Head Generation</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">31373.8k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
