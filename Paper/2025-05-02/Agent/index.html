<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Agent">
    <meta name="description" content="Agent æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-05-02  SWE-smith Scaling Data for Software Engineering Agents">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>Agent | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://picx.zhimg.com/v2-502399b049ae062d1b078916628e2c19.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Agent</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/Agent/">
                                <span class="chip bg-color">Agent</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/Agent/" class="post-category">
                                Agent
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-05-02
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-05-25
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    12.8k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    52 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-05-02-æ›´æ–°"><a href="#2025-05-02-æ›´æ–°" class="headerlink" title="2025-05-02 æ›´æ–°"></a>2025-05-02 æ›´æ–°</h1><h2 id="SWE-smith-Scaling-Data-for-Software-Engineering-Agents"><a href="#SWE-smith-Scaling-Data-for-Software-Engineering-Agents" class="headerlink" title="SWE-smith: Scaling Data for Software Engineering Agents"></a>SWE-smith: Scaling Data for Software Engineering Agents</h2><p><strong>Authors:John Yang, Kilian Leret, Carlos E. Jimenez, Alexander Wettig, Kabir Khandpur, Yanzhe Zhang, Binyuan Hui, Ofir Press, Ludwig Schmidt, Diyi Yang</strong></p>
<p>Despite recent progress in Language Models (LMs) for software engineering, collecting training data remains a significant pain point. Existing datasets are small, with at most 1,000s of training instances from 11 or fewer GitHub repositories. The procedures to curate such datasets are often complex, necessitating hundreds of hours of human labor; companion execution environments also take up several terabytes of storage, severely limiting their scalability and usability. To address this pain point, we introduce SWE-smith, a novel pipeline for generating software engineering training data at scale. Given any Python codebase, SWE-smith constructs a corresponding execution environment, then automatically synthesizes 100s to 1,000s of task instances that break existing test(s) in the codebase. Using SWE-smith, we create a dataset of 50k instances sourced from 128 GitHub repositories, an order of magnitude larger than all previous works. We train SWE-agent-LM-32B, achieving 40.2% Pass@1 resolve rate on the SWE-bench Verified benchmark, state of the art among open source models. We open source SWE-smith (collection procedure, task instances, trajectories, models) to lower the barrier of entry for research in LM systems for automated software engineering. All assets available at <a target="_blank" rel="noopener" href="https://swesmith.com/">https://swesmith.com</a>. </p>
<blockquote>
<p>å°½ç®¡æœ€è¿‘åœ¨è½¯ä»¶å·¥ç¨‹è¯­è¨€æ¨¡å‹ï¼ˆLMsï¼‰æ–¹é¢å–å¾—äº†è¿›å±•ï¼Œä½†æ”¶é›†è®­ç»ƒæ•°æ®ä»ç„¶æ˜¯ä¸€ä¸ªç—›ç‚¹ã€‚ç°æœ‰æ•°æ®é›†å¾ˆå°ï¼Œæœ€å¤šåªæœ‰æ¥è‡ª11ä¸ªæˆ–æ›´å°‘GitHubä»“åº“çš„æ•°åƒä¸ªè®­ç»ƒå®ä¾‹ã€‚æ•´ç†æ­¤ç±»æ•°æ®é›†çš„æµç¨‹é€šå¸¸å¾ˆå¤æ‚ï¼Œéœ€è¦æ•°ç™¾å°æ—¶çš„äººå·¥åŠ³åŠ¨ï¼›ä¼´éšçš„æ‰§è¡Œç¯å¢ƒä¹Ÿéœ€è¦å ç”¨æ•°å…†å­—èŠ‚çš„å­˜å‚¨ç©ºé—´ï¼Œä¸¥é‡é™åˆ¶äº†å…¶å¯æ‰©å±•æ€§å’Œå¯ç”¨æ€§ã€‚ä¸ºäº†è§£å†³è¿™ä¸€ç—›ç‚¹ï¼Œæˆ‘ä»¬å¼•å…¥äº†SWE-smithï¼Œè¿™æ˜¯ä¸€ä¸ªå¤§è§„æ¨¡ç”Ÿæˆè½¯ä»¶å·¥ç¨‹è®­ç»ƒæ•°æ®çš„æ–°å‹ç®¡é“ã€‚ç»™å®šä»»ä½•Pythonä»£ç åº“ï¼ŒSWE-smithæ„å»ºç›¸åº”çš„æ‰§è¡Œç¯å¢ƒï¼Œç„¶åè‡ªåŠ¨åˆæˆæ•°ç™¾åˆ°æ•°åƒä¸ªä»»åŠ¡å®ä¾‹ï¼Œè¿™äº›å®ä¾‹ä¼šç ´åä»£ç åº“ä¸­çš„ç°æœ‰æµ‹è¯•ã€‚ä½¿ç”¨SWE-smithï¼Œæˆ‘ä»¬åˆ›å»ºäº†ä¸€ä¸ªåŒ…å«5ä¸‡ä¸ªå®ä¾‹çš„æ•°æ®é›†ï¼Œè¿™äº›å®ä¾‹æ¥æºäº128ä¸ªGitHubä»“åº“ï¼Œè§„æ¨¡æ¯”ä»¥å‰çš„æ‰€æœ‰å·¥ä½œéƒ½å¤§ä¸€ä¸ªæ•°é‡çº§ã€‚æˆ‘ä»¬è®­ç»ƒäº†SWE-agent-LM-32Bæ¨¡å‹ï¼Œåœ¨SWE-benchç»è¿‡éªŒè¯çš„åŸºå‡†æµ‹è¯•ä¸­è¾¾åˆ°äº†40.2%çš„Pass@1è§£å†³ç‡ï¼Œåœ¨å¼€æºæ¨¡å‹ä¸­å¤„äºæœ€å…ˆè¿›æ°´å¹³ã€‚ä¸ºäº†é™ä½è¯­è¨€æ¨¡å‹ç³»ç»Ÿåœ¨è‡ªåŠ¨è½¯ä»¶å·¥ç¨‹æ–¹é¢çš„å…¥é—¨é—¨æ§›ï¼Œæˆ‘ä»¬å°†SWE-smithï¼ˆæ”¶é›†æµç¨‹ã€ä»»åŠ¡å®ä¾‹ã€è½¨è¿¹ã€æ¨¡å‹ï¼‰å¼€æºã€‚æ‰€æœ‰èµ„æºå‡å¯åœ¨<a target="_blank" rel="noopener" href="https://swesmith.comæ‰¾åˆ°./">https://swesmith.comæ‰¾åˆ°ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.21798v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†é’ˆå¯¹è½¯ä»¶å·¥ç¨‹æŠ€æœ¯è®­ç»ƒæ•°æ®æ”¶é›†éš¾é¢˜çš„æ–°å‹è§£å†³æ–¹æ¡ˆSWE-smithã€‚SWE-smithèƒ½å¤Ÿè‡ªåŠ¨ç”Ÿæˆå¤§é‡çš„ä»»åŠ¡å®ä¾‹ï¼Œæ‰“ç ´äº†ä»¥å¾€æµ‹è¯•é›†çš„é™åˆ¶ï¼Œä»GitHubä»“åº“ä¸­æ„å»ºäº†ç›¸åº”çš„æ‰§è¡Œç¯å¢ƒã€‚é€šè¿‡SWE-smithç”Ÿæˆçš„åŒ…å«5ä¸‡ä¸ªå®ä¾‹çš„æ•°æ®é›†æ˜¾è‘—æé«˜äº†è½¯ä»¶å·¥ç¨‹æŠ€æœ¯è®­ç»ƒæ•°æ®è§„æ¨¡ã€‚å¹¶ä¸”å¼€æºæ¨¡å‹SWE-agent-LM-32Båœ¨SWE-bench VerifiedåŸºå‡†æµ‹è¯•ä¸­å®ç°äº†è¾ƒé«˜çš„æ€§èƒ½è¡¨ç°ã€‚æ–‡ç« çš„æ‰€æœ‰èµ„æºå‡å·²åœ¨<a target="_blank" rel="noopener" href="https://swesmith.comä¸Šå…¬å¼€./">https://swesmith.comä¸Šå…¬å¼€ã€‚</a></p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>SWE-smithæ˜¯ä¸€ç§æ–°å‹è½¯ä»¶å·¥ç¨‹æŠ€æœ¯è®­ç»ƒæ•°æ®ç”Ÿæˆç®¡é“ï¼Œèƒ½å¤Ÿè‡ªåŠ¨ç”Ÿæˆå¤§é‡ä»»åŠ¡å®ä¾‹ã€‚</li>
<li>è¯¥æ–¹æ³•é€šè¿‡æ„å»ºæ‰§è¡Œç¯å¢ƒï¼Œæ‰“ç ´äº†ä»¥å¾€æµ‹è¯•é›†çš„é™åˆ¶ã€‚</li>
<li>ä½¿ç”¨SWE-smithç”Ÿæˆçš„æ•°æ®é›†åŒ…å«5ä¸‡ä¸ªå®ä¾‹ï¼Œæ¥è‡ª128ä¸ªGitHubä»“åº“ï¼Œè§„æ¨¡æ˜¾è‘—ã€‚</li>
<li>å¼€æºæ¨¡å‹SWE-agent-LM-32Båœ¨åŸºå‡†æµ‹è¯•ä¸­æ€§èƒ½é¢†å…ˆã€‚</li>
<li>SWE-smithçš„å¼€æºåŒ–é™ä½äº†è¿›å…¥é—¨æ§›ï¼Œä¾¿äºç ”ç©¶LMç³»ç»Ÿåœ¨è‡ªåŠ¨åŒ–è½¯ä»¶å·¥ç¨‹ä¸­çš„åº”ç”¨ã€‚</li>
<li>æ‰€æœ‰ç›¸å…³èµ„æºå‡å¯åœ¨<a target="_blank" rel="noopener" href="https://swesmith.comä¸Šæ‰¾åˆ°./">https://swesmith.comä¸Šæ‰¾åˆ°ã€‚</a></li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.21798">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-d199e7b46a64d1c50b45928415cfd4e6.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-8207f403a642629b35b2aa369b289803.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-675d21f975d7aabeae134c524d886f36.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-39657d3fac58f7c96868c173bc2ccb0b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d4be2b64492da148d6329a62a8cce6f2.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-c8d4888217bb4d60e95f2c46a06ba0e5.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="LLM-Empowered-Embodied-Agent-for-Memory-Augmented-Task-Planning-in-Household-Robotics"><a href="#LLM-Empowered-Embodied-Agent-for-Memory-Augmented-Task-Planning-in-Household-Robotics" class="headerlink" title="LLM-Empowered Embodied Agent for Memory-Augmented Task Planning in   Household Robotics"></a>LLM-Empowered Embodied Agent for Memory-Augmented Task Planning in   Household Robotics</h2><p><strong>Authors:Marc Glocker, Peter HÃ¶nig, Matthias Hirschmanner, Markus Vincze</strong></p>
<p>We present an embodied robotic system with an LLM-driven agent-orchestration architecture for autonomous household object management. The system integrates memory-augmented task planning, enabling robots to execute high-level user commands while tracking past actions. It employs three specialized agents: a routing agent, a task planning agent, and a knowledge base agent, each powered by task-specific LLMs. By leveraging in-context learning, our system avoids the need for explicit model training. RAG enables the system to retrieve context from past interactions, enhancing long-term object tracking. A combination of Grounded SAM and LLaMa3.2-Vision provides robust object detection, facilitating semantic scene understanding for task planning. Evaluation across three household scenarios demonstrates high task planning accuracy and an improvement in memory recall due to RAG. Specifically, Qwen2.5 yields best performance for specialized agents, while LLaMA3.1 excels in routing tasks. The source code is available at: <a target="_blank" rel="noopener" href="https://github.com/marc1198/chat-hsr">https://github.com/marc1198/chat-hsr</a>. </p>
<blockquote>
<p>æˆ‘ä»¬å‘ˆç°äº†ä¸€ä¸ªå…·æœ‰LLMé©±åŠ¨çš„ä¸»ä½“ç¼–æ’æ¶æ„çš„å®ä½“æœºå™¨äººç³»ç»Ÿï¼Œç”¨äºè‡ªä¸»ç®¡ç†å®¶å±…ç‰©å“ã€‚è¯¥ç³»ç»Ÿç»“åˆäº†å¢å¼ºè®°å¿†çš„ä»»åŠ¡è§„åˆ’ï¼Œä½¿æœºå™¨äººèƒ½å¤Ÿæ‰§è¡Œé«˜çº§ç”¨æˆ·å‘½ä»¤ï¼ŒåŒæ—¶è·Ÿè¸ªè¿‡å»çš„åŠ¨ä½œã€‚å®ƒé‡‡ç”¨äº†ä¸‰ä¸ªä¸“ä¸šä»£ç†ï¼šè·¯ç”±ä»£ç†ã€ä»»åŠ¡è§„åˆ’ä»£ç†å’ŒçŸ¥è¯†åº“ä»£ç†ï¼Œæ¯ä¸ªä»£ç†éƒ½ç”±ç‰¹å®šä»»åŠ¡çš„LLMæä¾›æ”¯æŒã€‚é€šè¿‡åˆ©ç”¨ä¸Šä¸‹æ–‡å­¦ä¹ ï¼Œæˆ‘ä»¬çš„ç³»ç»Ÿé¿å…äº†å¯¹æ˜ç¡®æ¨¡å‹è®­ç»ƒçš„éœ€æ±‚ã€‚RAGä½¿ç³»ç»Ÿèƒ½å¤Ÿä»è¿‡å»çš„äº¤äº’ä¸­æ£€ç´¢ä¸Šä¸‹æ–‡ï¼Œä»è€Œæé«˜é•¿æœŸç‰©ä½“è·Ÿè¸ªèƒ½åŠ›ã€‚Grounded SAMå’ŒLLaMa3.2-Visionçš„ç»“åˆæä¾›äº†å¼ºå¤§çš„ç‰©ä½“æ£€æµ‹åŠŸèƒ½ï¼Œä¿ƒè¿›ä»»åŠ¡è§„åˆ’çš„è¯­ä¹‰åœºæ™¯ç†è§£ã€‚åœ¨ä¸‰ä¸ªå®¶åº­åœºæ™¯ä¸­çš„è¯„ä¼°è¡¨æ˜ï¼Œä»»åŠ¡è§„åˆ’ç²¾åº¦é«˜ï¼Œä¸”ç”±äºRAGçš„å‚ä¸ï¼Œè®°å¿†å›å¿†èƒ½åŠ›æœ‰æ‰€æé«˜ã€‚å…·ä½“æ¥è¯´ï¼ŒQwen2.5åœ¨ä¸“ä¸šä»£ç†æ–¹é¢è¡¨ç°æœ€ä½³ï¼Œè€ŒLLaMA3.1åœ¨è·¯ç”±ä»»åŠ¡æ–¹é¢è¡¨ç°å‡ºè‰²ã€‚æºä»£ç å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/marc1198/chat-hsr%E4%B8%8A%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/marc1198/chat-hsrä¸Šæ‰¾åˆ°ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.21716v1">PDF</a> Accepted at Austrian Robotics Workshop 2025</p>
<p><strong>Summary</strong></p>
<p>ä¸€ä¸ªå…·æœ‰LLMé©±åŠ¨ä»£ç†ç¼–æ’æ¶æ„çš„å®ä½“æœºå™¨äººç³»ç»Ÿï¼Œç”¨äºè‡ªä¸»ç®¡ç†å®¶å±…ç‰©å“ã€‚è¯¥ç³»ç»Ÿç»“åˆäº†è®°å¿†å¢å¼ºçš„ä»»åŠ¡è§„åˆ’ï¼Œä½¿æœºå™¨äººèƒ½å¤Ÿæ‰§è¡Œé«˜çº§ç”¨æˆ·å‘½ä»¤å¹¶è·Ÿè¸ªè¿‡å»çš„è¡ŒåŠ¨ã€‚é€šè¿‡åˆ©ç”¨ä¸Šä¸‹æ–‡å­¦ä¹ ï¼Œè¯¥ç³»ç»Ÿé¿å…äº†æ˜¾å¼æ¨¡å‹è®­ç»ƒçš„éœ€è¦ã€‚RAGä½¿ç³»ç»Ÿèƒ½å¤Ÿä»è¿‡å»çš„äº’åŠ¨ä¸­æ£€ç´¢ä¸Šä¸‹æ–‡ï¼Œæé«˜é•¿æœŸç‰©å“è·Ÿè¸ªèƒ½åŠ›ã€‚ç»“åˆGrounded SAMå’ŒLLaMa3.2-Visionï¼Œæä¾›ç¨³å¥çš„å¯¹è±¡æ£€æµ‹ï¼Œä¿ƒè¿›åœºæ™¯è¯­ä¹‰ç†è§£ä»¥è¿›è¡Œä»»åŠ¡è§„åˆ’ã€‚åœ¨ä¸‰ä¸ªå®¶åº­åœºæ™¯ä¸­çš„è¯„ä¼°æ˜¾ç¤ºï¼Œä»»åŠ¡è§„åˆ’ç²¾åº¦é«˜ï¼Œä¸”ç”±äºRAGçš„å­˜åœ¨ï¼Œè®°å¿†å›å¿†æœ‰æ‰€æ”¹å–„ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>è¯¥ç³»ç»Ÿæ˜¯ä¸€ä¸ªå®ä½“æœºå™¨äººå¹³å°ï¼Œæ—¨åœ¨é€šè¿‡LLMé©±åŠ¨ä»£ç†ç¼–æ’æ¶æ„è¿›è¡Œè‡ªä¸»å®¶å±…ç‰©å“ç®¡ç†ã€‚</li>
<li>é›†æˆè®°å¿†å¢å¼ºçš„ä»»åŠ¡è§„åˆ’åŠŸèƒ½ï¼Œä½¿æœºå™¨äººèƒ½æ‰§è¡Œé«˜çº§ç”¨æˆ·å‘½ä»¤å¹¶è·Ÿè¸ªè¿‡å»çš„è¡Œä¸ºã€‚</li>
<li>ç³»ç»Ÿé‡‡ç”¨ä¸Šä¸‹æ–‡å­¦ä¹ ï¼Œæ— éœ€æ˜ç¡®çš„æ¨¡å‹è®­ç»ƒã€‚</li>
<li>RAGèƒ½å¤Ÿä»è¿‡å»çš„äº’åŠ¨ä¸­æ£€ç´¢ä¸Šä¸‹æ–‡ï¼Œæé«˜é•¿æœŸç‰©å“è·Ÿè¸ªèƒ½åŠ›ã€‚</li>
<li>Grounded SAMå’ŒLLaMa3.2-Visionçš„ç»“åˆä¸ºç³»ç»Ÿæä¾›äº†ç¨³å¥çš„å¯¹è±¡æ£€æµ‹åŠŸèƒ½ã€‚</li>
<li>ç³»ç»Ÿåœ¨ä¸‰ä¸ªå®¶åº­åœºæ™¯ä¸­çš„è¯„ä¼°ç»“æœè¡¨æ˜ï¼Œä»»åŠ¡è§„åˆ’ç²¾åº¦é«˜ï¼Œè®°å¿†å¬å›ä¹Ÿæœ‰æ‰€æ”¹å–„ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.21716">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-dca7c9be1a75c46296d95c57f4f3bc5e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a66ab9c531e90f69ca0c9b8d40792a16.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-3582528f93ede71a06f39e4df31f9f7e.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-e590cec1d0b46dd417a5515916e21a17.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b0d6bc3c58292319b55dcecc9e4608ae.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-c76ab1d3e3d6f7daaa52d6abce1c6e8e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-bd25b12de6c70dc0852d1416f14fc390.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="Iterative-Trajectory-Exploration-for-Multimodal-Agents"><a href="#Iterative-Trajectory-Exploration-for-Multimodal-Agents" class="headerlink" title="Iterative Trajectory Exploration for Multimodal Agents"></a>Iterative Trajectory Exploration for Multimodal Agents</h2><p><strong>Authors:Pengxiang Li, Zhi Gao, Bofei Zhang, Yapeng Mi, Xiaojian Ma, Chenrui Shi, Tao Yuan, Yuwei Wu, Yunde Jia, Song-Chun Zhu, Qing Li</strong></p>
<p>Multimodal agents, which integrate a controller (e.g., a large language model) with external tools, have demonstrated remarkable capabilities in tackling complex tasks. However, existing agents need to collect a large number of expert data for fine-tuning to adapt to new environments. In this paper, we propose an online self-exploration method for multimodal agents, namely SPORT, via step-wise preference optimization to refine the trajectories of agents, which automatically generates tasks and learns from solving the generated tasks, without any expert annotation. SPORT operates through four iterative components: task synthesis, step sampling, step verification, and preference tuning. First, we synthesize multi-modal tasks using language models. Then, we introduce a novel search scheme, where step sampling and step verification are executed alternately to solve each generated task. We employ a verifier to provide AI feedback to construct step-wise preference data. The data is subsequently used to update the controllerâ€™s policy through preference tuning, producing a SPORT Agent. By interacting with real environments, the SPORT Agent evolves into a more refined and capable system. Evaluation in the GTA and GAIA benchmarks show that the SPORT Agent achieves 6.41% and 3.64% improvements, underscoring the generalization and effectiveness introduced by our method. The project page is <a target="_blank" rel="noopener" href="https://sport-agents.github.io/">https://SPORT-Agents.github.io</a>. </p>
<blockquote>
<p>å¤šæ¨¡æ€æ™ºèƒ½ä½“é€šè¿‡æ•´åˆæ§åˆ¶å™¨ï¼ˆå¦‚å¤§å‹è¯­è¨€æ¨¡å‹ï¼‰ä¸å¤–éƒ¨å·¥å…·ï¼Œåœ¨åº”å¯¹å¤æ‚ä»»åŠ¡æ–¹é¢å±•ç°å‡ºå“è¶Šçš„èƒ½åŠ›ã€‚ç„¶è€Œï¼Œç°æœ‰æ™ºèƒ½ä½“éœ€è¦æ”¶é›†å¤§é‡ä¸“å®¶æ•°æ®æ¥è¿›è¡Œå¾®è°ƒä»¥é€‚åº”æ–°ç¯å¢ƒã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åœ¨çº¿è‡ªæˆ‘æ¢ç´¢çš„å¤šæ¨¡æ€æ™ºèƒ½ä½“æ–¹æ³•ï¼Œåä¸ºSPORTï¼Œé€šè¿‡é€æ­¥åå¥½ä¼˜åŒ–æ¥ä¼˜åŒ–æ™ºèƒ½ä½“çš„è½¨è¿¹ï¼Œè¯¥æ–¹æ³•å¯ä»¥è‡ªåŠ¨ç”Ÿæˆä»»åŠ¡å¹¶ä»è§£å†³ç”Ÿæˆçš„ä»»åŠ¡ä¸­å­¦ä¹ ï¼Œæ— éœ€ä»»ä½•ä¸“å®¶æ ‡æ³¨ã€‚SPORTé€šè¿‡å››ä¸ªè¿­ä»£ç»„ä»¶è¿›è¡Œæ“ä½œï¼šä»»åŠ¡åˆæˆã€æ­¥éª¤é‡‡æ ·ã€æ­¥éª¤éªŒè¯å’Œåå¥½è°ƒæ•´ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬ä½¿ç”¨è¯­è¨€æ¨¡å‹åˆæˆå¤šæ¨¡æ€ä»»åŠ¡ã€‚ç„¶åï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§æ–°é¢–çš„æœç´¢æ–¹æ¡ˆï¼Œè¯¥æ–¹æ¡ˆäº¤æ›¿æ‰§è¡Œæ­¥éª¤é‡‡æ ·å’Œæ­¥éª¤éªŒè¯æ¥è§£å†³æ¯ä¸ªç”Ÿæˆçš„ä»»åŠ¡ã€‚æˆ‘ä»¬é‡‡ç”¨éªŒè¯å™¨ä¸ºäººå·¥æ™ºèƒ½æä¾›åé¦ˆæ¥æ„å»ºé€æ­¥åå¥½æ•°æ®ã€‚éšåï¼Œè¿™äº›æ•°æ®è¢«ç”¨æ¥é€šè¿‡åå¥½è°ƒæ•´æ›´æ–°æ§åˆ¶å™¨çš„ç­–ç•¥ï¼Œä»è€Œäº§ç”Ÿä¸€ä¸ªSPORTæ™ºèƒ½ä½“ã€‚é€šè¿‡ä¸çœŸå®ç¯å¢ƒè¿›è¡Œäº¤äº’ï¼ŒSPORTæ™ºèƒ½ä½“è¿›åŒ–æˆä¸€ä¸ªæ›´åŠ ç²¾ç»†å’Œå¼ºå¤§çš„ç³»ç»Ÿã€‚åœ¨GTAå’ŒGAIAåŸºå‡†æµ‹è¯•ä¸­çš„è¯„ä¼°æ˜¾ç¤ºï¼ŒSPORTæ™ºèƒ½ä½“çš„æ”¹è¿›ç‡è¾¾åˆ°6.41%å’Œ3.64%ï¼Œå‡¸æ˜¾äº†æˆ‘ä»¬æ–¹æ³•çš„é€šç”¨æ€§å’Œæœ‰æ•ˆæ€§ã€‚é¡¹ç›®é¡µé¢ä¸º<a target="_blank" rel="noopener" href="https://sport-agents.github.io./">https://SPORT-Agents.github.ioã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.21561v1">PDF</a> 16 pages, 8 figures</p>
<p><strong>Summary</strong><br>å¤šæ¨¡æ€æ™ºèƒ½ä½“é€šè¿‡ä¸å¤–éƒ¨å·¥å…·é›†æˆå¤§å‹è¯­è¨€æ¨¡å‹æ§åˆ¶å™¨ï¼Œå±•ç°å‡ºå¤„ç†å¤æ‚ä»»åŠ¡çš„èƒ½åŠ›ã€‚ç„¶è€Œï¼Œç°æœ‰æ™ºèƒ½ä½“éœ€è¦æ”¶é›†å¤§é‡ä¸“å®¶æ•°æ®è¿›è¡Œå¾®è°ƒä»¥é€‚åº”æ–°ç¯å¢ƒã€‚æœ¬ç ”ç©¶æå‡ºä¸€ç§åœ¨çº¿è‡ªæˆ‘æ¢ç´¢æ–¹æ³•SPORTï¼Œé€šè¿‡æ­¥éª¤åå¥½ä¼˜åŒ–ä¸ºæ™ºèƒ½ä½“è°ƒæ•´è½¨è¿¹ï¼Œä½¿å…¶è‡ªåŠ¨ç”Ÿæˆä»»åŠ¡å¹¶ä»è§£å†³çš„ä»»åŠ¡ä¸­å­¦ä¹ ï¼Œæ— éœ€ä¸“å®¶æ ‡æ³¨ã€‚SPORTé€šè¿‡ä»»åŠ¡åˆæˆã€æ­¥éª¤é‡‡æ ·ã€æ­¥éª¤éªŒè¯å’Œåå¥½è°ƒæ•´å››ä¸ªè¿­ä»£ç¯èŠ‚æ“ä½œã€‚åˆ©ç”¨è¯­è¨€æ¨¡å‹åˆæˆå¤šæ¨¡æ€ä»»åŠ¡ï¼Œå¼•å…¥æ–°å‹æœç´¢æ–¹æ¡ˆï¼Œäº¤æ›¿æ‰§è¡Œæ­¥éª¤é‡‡æ ·å’ŒéªŒè¯æ¥è§£å†³æ¯ä¸ªç”Ÿæˆçš„ä»»åŠ¡ã€‚é‡‡ç”¨éªŒè¯å™¨æä¾›AIåé¦ˆæ¥æ„å»ºæ­¥éª¤åå¥½æ•°æ®ï¼Œéšåç”¨äºé€šè¿‡åå¥½è°ƒæ•´æ›´æ–°æ§åˆ¶å™¨çš„ç­–ç•¥ï¼Œäº§ç”ŸSPORTæ™ºèƒ½ä½“ã€‚åœ¨ä¸å®é™…ç¯å¢ƒäº’åŠ¨ä¸­ï¼ŒSPORTæ™ºèƒ½ä½“é€æ¸è¿›åŒ–ä¸ºæ›´ç²¾ç»†ã€æ›´å¼ºå¤§çš„ç³»ç»Ÿã€‚åœ¨GTAå’ŒGAIAåŸºå‡†æµ‹è¯•ä¸­ï¼ŒSPORTæ™ºèƒ½ä½“çš„è¡¨ç°è¯æ˜äº†è¯¥æ–¹æ³•å¸¦æ¥çš„æ¨å¹¿å’Œæœ‰æ•ˆæ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤šæ¨¡æ€æ™ºèƒ½ä½“é€šè¿‡é›†æˆå¤§å‹è¯­è¨€æ¨¡å‹æ§åˆ¶å™¨å’Œå¤–éƒ¨å·¥å…·ï¼Œå…·å¤‡å¤„ç†å¤æ‚ä»»åŠ¡çš„èƒ½åŠ›ã€‚</li>
<li>ç°æœ‰æ™ºèƒ½ä½“éœ€è¦å¤§é‡ä¸“å®¶æ•°æ®è¿›è¡Œå¾®è°ƒä»¥é€‚åº”æ–°ç¯å¢ƒã€‚</li>
<li>SPORTæ˜¯ä¸€ç§åœ¨çº¿è‡ªæˆ‘æ¢ç´¢æ–¹æ³•ï¼Œä¸ºæ™ºèƒ½ä½“è°ƒæ•´è½¨è¿¹ï¼Œæ— éœ€ä¸“å®¶æ ‡æ³¨å³å¯è‡ªåŠ¨ç”Ÿæˆä»»åŠ¡å¹¶å­¦ä¹ ã€‚</li>
<li>SPORTé€šè¿‡ä»»åŠ¡åˆæˆã€æ­¥éª¤é‡‡æ ·ã€æ­¥éª¤éªŒè¯å’Œåå¥½è°ƒæ•´å››ä¸ªè¿­ä»£ç¯èŠ‚æ“ä½œã€‚</li>
<li>é‡‡ç”¨è¯­è¨€æ¨¡å‹åˆæˆå¤šæ¨¡æ€ä»»åŠ¡ï¼Œå¹¶å¼•å…¥æ–°å‹æœç´¢æ–¹æ¡ˆè§£å†³ç”Ÿæˆçš„ä»»åŠ¡ã€‚</li>
<li>é€šè¿‡AIåé¦ˆæ„å»ºæ­¥éª¤åå¥½æ•°æ®ï¼Œç”¨äºæ›´æ–°æ§åˆ¶å™¨çš„ç­–ç•¥ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.21561">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-6dba05ca9c947ea9ad6bd4dc9efe0cb8.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-dea9dfff1165c627098ac16bf0c0510d.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-5039b2f01305fb73e4b911ba2ca2526e.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-ee56d2bda0dbb7beaafbf4bc65b58781.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-3811ed6d42d50432abac83478bd9ea82.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="Unsupervised-Feature-Transformation-via-In-context-Generation-Generator-critic-LLM-Agents-and-Duet-play-Teaming"><a href="#Unsupervised-Feature-Transformation-via-In-context-Generation-Generator-critic-LLM-Agents-and-Duet-play-Teaming" class="headerlink" title="Unsupervised Feature Transformation via In-context Generation,   Generator-critic LLM Agents, and Duet-play Teaming"></a>Unsupervised Feature Transformation via In-context Generation,   Generator-critic LLM Agents, and Duet-play Teaming</h2><p><strong>Authors:Nanxu Gong, Xinyuan Wang, Wangyang Ying, Haoyue Bai, Sixun Dong, Haifeng Chen, Yanjie Fu</strong></p>
<p>Feature transformation involves generating a new set of features from the original dataset to enhance the dataâ€™s utility. In certain domains like material performance screening, dimensionality is large and collecting labels is expensive and lengthy. It highly necessitates transforming feature spaces efficiently and without supervision to enhance data readiness and AI utility. However, existing methods fall short in efficient navigation of a vast space of feature combinations, and are mostly designed for supervised settings. To fill this gap, our unique perspective is to leverage a generator-critic duet-play teaming framework using LLM agents and in-context learning to derive pseudo-supervision from unsupervised data. The framework consists of three interconnected steps: (1) Critic agent diagnoses data to generate actionable advice, (2) Generator agent produces tokenized feature transformations guided by the criticâ€™s advice, and (3) Iterative refinement ensures continuous improvement through feedback between agents. The generator-critic framework can be generalized to human-agent collaborative generation, by replacing the critic agent with human experts. Extensive experiments demonstrate that the proposed framework outperforms even supervised baselines in feature transformation efficiency, robustness, and practical applicability across diverse datasets. </p>
<blockquote>
<p>ç‰¹å¾è½¬æ¢æ¶‰åŠä»åŸå§‹æ•°æ®é›†ä¸­ç”Ÿæˆæ–°çš„ç‰¹å¾é›†ï¼Œä»¥æé«˜æ•°æ®çš„æ•ˆç”¨ã€‚åœ¨æŸäº›é¢†åŸŸï¼Œå¦‚ææ–™æ€§èƒ½ç­›é€‰ä¸­ï¼Œç»´åº¦å¾ˆå¤§ï¼Œæ”¶é›†æ ‡ç­¾æ—¢æ˜‚è´µåˆè€—æ—¶ã€‚è¿™å¼ºçƒˆéœ€è¦æœ‰æ•ˆåœ°è¿›è¡Œç‰¹å¾ç©ºé—´è½¬æ¢ï¼Œå¹¶ä¸”æ— éœ€ç›‘ç£æ¥æé«˜æ•°æ®å‡†å¤‡å’Œäººå·¥æ™ºèƒ½çš„æ•ˆç”¨ã€‚ç„¶è€Œï¼Œç°æœ‰æ–¹æ³•åœ¨æœ‰æ•ˆåœ°éå†å¤§é‡çš„ç‰¹å¾ç»„åˆç©ºé—´æ–¹é¢å­˜åœ¨ä¸è¶³ï¼Œå¹¶ä¸”å¤§å¤šæ˜¯ä¸ºæœ‰ç›‘ç£ç¯å¢ƒè®¾è®¡çš„ã€‚ä¸ºäº†å¡«è¡¥è¿™ä¸€ç©ºç™½ï¼Œæˆ‘ä»¬çš„ç‹¬ç‰¹è§†è§’æ˜¯åˆ©ç”¨ç”Ÿæˆå™¨-è¯„è®ºå®¶äºŒé‡å¥åä½œæ¡†æ¶ï¼Œä½¿ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä»£ç†å’Œä¸Šä¸‹æ–‡å­¦ä¹ ï¼Œä»æ— ç›‘ç£æ•°æ®ä¸­è·å–ä¼ªç›‘ç£ã€‚è¯¥æ¡†æ¶åŒ…å«ä¸‰ä¸ªç›¸äº’å…³è”çš„æ­¥éª¤ï¼šï¼ˆ1ï¼‰è¯„è®ºå®¶ä»£ç†è¯Šæ–­æ•°æ®ä»¥ç”Ÿæˆå¯æ“ä½œçš„å»ºè®®ï¼Œï¼ˆ2ï¼‰ç”Ÿæˆå™¨ä»£ç†æ ¹æ®è¯„è®ºå®¶çš„å»ºè®®ç”Ÿæˆæ ‡è®°åŒ–çš„ç‰¹å¾è½¬æ¢ï¼Œï¼ˆ3ï¼‰è¿­ä»£ä¼˜åŒ–ç¡®ä¿é€šè¿‡ä»£ç†ä¹‹é—´çš„åé¦ˆè¿›è¡ŒæŒç»­æ”¹è¿›ã€‚ç”Ÿæˆå™¨-è¯„è®ºå®¶æ¡†æ¶å¯ä»¥é€šè¿‡ç”¨äººç±»ä¸“å®¶æ›¿æ¢è¯„è®ºå®¶ä»£ç†æ¥æ¨å¹¿åˆ°äººç±»-ä»£ç†åä½œç”Ÿæˆã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼Œæ‰€æå‡ºçš„æ¡†æ¶åœ¨ç‰¹å¾è½¬æ¢æ•ˆç‡ã€ç¨³å¥æ€§å’Œå®é™…åº”ç”¨çš„é€‚ç”¨æ€§æ–¹é¢ç”šè‡³è¶…è¿‡äº†æœ‰ç›‘ç£çš„åŸºçº¿æ¨¡å‹ï¼Œé€‚ç”¨äºå¤šç§æ•°æ®é›†ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.21304v1">PDF</a> Accepted to IJCAI 2025</p>
<p><strong>Summary</strong></p>
<p>ç‰¹å¾è½¬æ¢é€šè¿‡ä»åŸå§‹æ•°æ®é›†ä¸­ç”Ÿæˆæ–°çš„ç‰¹å¾é›†æ¥æé«˜æ•°æ®æ•ˆç”¨ã€‚åœ¨ææ–™æ€§èƒ½ç­›é€‰ç­‰é¢†åŸŸï¼Œç”±äºç»´åº¦å¤§ä¸”æ”¶é›†æ ‡ç­¾çš„æˆæœ¬é«˜ä¸”è€—æ—¶ï¼Œé«˜æ•ˆä¸”æ— ç›‘ç£çš„ç‰¹å¾ç©ºé—´è½¬æ¢å˜å¾—è‡³å…³é‡è¦ã€‚ç°æœ‰æ–¹æ³•éš¾ä»¥åœ¨å¤§é‡çš„ç‰¹å¾ç»„åˆç©ºé—´ä¸­è¿›è¡Œæœ‰æ•ˆå¯¼èˆªï¼Œå¹¶ä¸”å¤§å¤šè®¾è®¡ç”¨äºç›‘ç£ç¯å¢ƒã€‚ä¸ºè§£å†³æ­¤ç©ºç™½ï¼Œæˆ‘ä»¬åˆ©ç”¨ç”Ÿæˆå™¨-è¯„è®ºå®¶äºŒé‡å¥çš„æ¡†æ¶ï¼Œç»“åˆå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä»£ç†å’Œä¸Šä¸‹æ–‡å­¦ä¹ ï¼Œä»æ— ç›‘ç£æ•°æ®ä¸­è¡ç”Ÿä¼ªç›‘ç£ã€‚è¯¥æ¡†æ¶åŒ…å«ä¸‰ä¸ªç›¸äº’å…³è”çš„æ­¥éª¤ï¼šè¯„è®ºå®¶ä»£ç†è¯Šæ–­æ•°æ®ä»¥ç”Ÿæˆå¯æ“ä½œçš„å»ºè®®ï¼Œç”Ÿæˆå™¨ä»£ç†æ ¹æ®è¯„è®ºå®¶çš„å»ºè®®äº§ç”Ÿæ ‡è®°åŒ–çš„ç‰¹å¾è½¬æ¢ï¼Œä»¥åŠè¿­ä»£ä¼˜åŒ–ç¡®ä¿é€šè¿‡ä»£ç†ä¹‹é—´çš„åé¦ˆæŒç»­æ”¹è¿›ã€‚ç”Ÿæˆå™¨-è¯„è®ºå®¶æ¡†æ¶å¯æ¨å¹¿è‡³äººæœºåä½œç”Ÿæˆï¼Œä»¥äººç±»ä¸“å®¶æ›¿ä»£è¯„è®ºå®¶ä»£ç†ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼Œè¯¥æ¡†æ¶åœ¨ç‰¹å¾è½¬æ¢æ•ˆç‡ã€ç¨³å¥æ€§å’Œå®é™…åº”ç”¨çš„å¤šæ ·æ€§æ–¹é¢ï¼Œç”šè‡³è¶…è¶Šäº†ç›‘ç£åŸºçº¿ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ç‰¹å¾è½¬æ¢èƒ½æé«˜æ•°æ®çš„æ•ˆç”¨ï¼Œç‰¹åˆ«æ˜¯åœ¨ç»´åº¦å¤§ã€æ ‡ç­¾æ”¶é›†æˆæœ¬é«˜çš„é¢†åŸŸã€‚</li>
<li>ç°æœ‰ç‰¹å¾è½¬æ¢æ–¹æ³•å­˜åœ¨å¯¹å¤§é‡ç‰¹å¾ç»„åˆç©ºé—´å¯¼èˆªå›°éš¾çš„é—®é¢˜ï¼Œä¸”ä¸»è¦é€‚ç”¨äºç›‘ç£ç¯å¢ƒã€‚</li>
<li>åˆ©ç”¨ç”Ÿæˆå™¨-è¯„è®ºå®¶äºŒé‡å¥æ¡†æ¶ï¼Œç»“åˆå¤§å‹è¯­è¨€æ¨¡å‹ä»£ç†å’Œä¸Šä¸‹æ–‡å­¦ä¹ ï¼Œå¯ä»æ— ç›‘ç£æ•°æ®ä¸­è¡ç”Ÿä¼ªç›‘ç£ã€‚</li>
<li>æ¡†æ¶åŒ…å«ä¸‰ä¸ªä¸»è¦æ­¥éª¤ï¼šæ•°æ®è¯Šæ–­ã€ç‰¹å¾ç”Ÿæˆå’Œè¿­ä»£ä¼˜åŒ–ã€‚</li>
<li>ç”Ÿæˆå™¨-è¯„è®ºå®¶æ¡†æ¶å¯æ¨å¹¿è‡³äººæœºåä½œç”Ÿæˆï¼Œä»¥äººç±»ä¸“å®¶æ›¿ä»£è¯„è®ºå®¶ä»£ç†ã€‚</li>
<li>è¯¥æ¡†æ¶åœ¨ç‰¹å¾è½¬æ¢æ•ˆç‡ã€ç¨³å¥æ€§å’Œå®é™…åº”ç”¨çš„å¤šæ ·æ€§æ–¹é¢è¡¨ç°ä¼˜å¼‚ï¼Œè¶…è¶Šç›‘ç£åŸºçº¿ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.21304">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-6f4147f076c3a035a438ade3f815503e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-3c7227c2d89d0f0bff15a3621429f7d8.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-3f7353bdbd45197c006f6808a616498b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-498edde4723a82591a80f8345822949e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-abdb33736677fa09d4399cd1b428c921.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-88d5fc0a3972f02f864fdfe46796dfdb.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-43e0c00251478e97492ffe03e014c64f.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="Robust-Multi-agent-Communication-Based-on-Decentralization-Oriented-Adversarial-Training"><a href="#Robust-Multi-agent-Communication-Based-on-Decentralization-Oriented-Adversarial-Training" class="headerlink" title="Robust Multi-agent Communication Based on Decentralization-Oriented   Adversarial Training"></a>Robust Multi-agent Communication Based on Decentralization-Oriented   Adversarial Training</h2><p><strong>Authors:Xuyan Ma, Yawen Wang, Junjie Wang, Xiaofei Xie, Boyu Wu, Shoubin Li, Fanjiang Xu, Qing Wang</strong></p>
<p>In typical multi-agent reinforcement learning (MARL) problems, communication is important for agents to share information and make the right decisions. However, due to the complexity of training multi-agent communication, existing methods often fall into the dilemma of local optimization, which leads to the concentration of communication in a limited number of channels and presents an unbalanced structure. Such unbalanced communication policy are vulnerable to abnormal conditions, where the damage of critical communication channels can trigger the crash of the entire system. Inspired by decentralization theory in sociology, we propose DMAC, which enhances the robustness of multi-agent communication policies by retraining them into decentralized patterns. Specifically, we train an adversary DMAC_Adv which can dynamically identify and mask the critical communication channels, and then apply the adversarial samples generated by DMAC_Adv to the adversarial learning of the communication policy to force the policy in exploring other potential communication schemes and transition to a decentralized structure. As a training method to improve robustness, DMAC can be fused with any learnable communication policy algorithm. The experimental results in two communication policies and four multi-agent tasks demonstrate that DMAC achieves higher improvement on robustness and performance of communication policy compared with two state-of-the-art and commonly-used baselines. Also, the results demonstrate that DMAC can achieve decentralized communication structure with acceptable communication cost. </p>
<blockquote>
<p>åœ¨å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ ï¼ˆMARLï¼‰çš„å…¸å‹é—®é¢˜ä¸­ï¼Œé€šä¿¡å¯¹äºæ™ºèƒ½ä½“å…±äº«ä¿¡æ¯å’Œåšå‡ºæ­£ç¡®å†³ç­–è‡³å…³é‡è¦ã€‚ç„¶è€Œï¼Œç”±äºè®­ç»ƒå¤šæ™ºèƒ½ä½“é€šä¿¡çš„å¤æ‚æ€§ï¼Œç°æœ‰æ–¹æ³•å¾€å¾€é™·å…¥å±€éƒ¨ä¼˜åŒ–çš„å›°å¢ƒï¼Œå¯¼è‡´é€šä¿¡é›†ä¸­åœ¨æœ‰é™çš„é€šé“ä¸Šï¼Œå‘ˆç°å‡ºä¸å¹³è¡¡çš„ç»“æ„ã€‚è¿™ç§ä¸å¹³è¡¡çš„é€šä¿¡ç­–ç•¥åœ¨å¼‚å¸¸æ¡ä»¶ä¸‹å¾ˆè„†å¼±ï¼Œå…³é”®é€šä¿¡é€šé“çš„æŸåå¯èƒ½ä¼šå¼•å‘æ•´ä¸ªç³»ç»Ÿçš„å´©æºƒã€‚å—ç¤¾ä¼šå­¦ä¸­åˆ†æ•£åŒ–ç†è®ºçš„å¯å‘ï¼Œæˆ‘ä»¬æå‡ºäº†DMACï¼ˆåˆ†æ•£å¤šæ™ºèƒ½ä½“é€šä¿¡ï¼‰ç®—æ³•ï¼Œå®ƒé€šè¿‡é‡æ–°è®­ç»ƒæ™ºèƒ½ä½“é€šä¿¡ç­–ç•¥æ¥æé«˜å…¶é²æ£’æ€§ï¼Œä½¿å®ƒä»¬å‘ˆç°åˆ†æ•£çš„æ¨¡å¼ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬è®­ç»ƒäº†ä¸€ä¸ªå¯¹æ‰‹DMAC_Advï¼Œå®ƒèƒ½å¤ŸåŠ¨æ€åœ°è¯†åˆ«å’Œå±è”½å…³é”®çš„é€šä¿¡é€šé“ï¼Œç„¶åå°†ç”±DMAC_Advç”Ÿæˆçš„å¯¹æŠ—æ ·æœ¬åº”ç”¨äºé€šä¿¡ç­–ç•¥çš„å¯¹æŠ—æ€§å­¦ä¹ ï¼Œè¿«ä½¿ç­–ç•¥æ¢ç´¢å…¶ä»–æ½œåœ¨çš„é€šä¿¡æ–¹æ¡ˆï¼Œå¹¶è½¬å‘åˆ†æ•£çš„ç»“æ„ã€‚ä½œä¸ºä¸€ç§æé«˜é²æ£’æ€§çš„è®­ç»ƒæ–¹æ³•ï¼ŒDMACå¯ä»¥ä¸ä»»ä½•å¯å­¦ä¹ çš„é€šä¿¡ç­–ç•¥ç®—æ³•ç›¸ç»“åˆã€‚åœ¨ä¸¤ä¸ªé€šä¿¡ç­–ç•¥å’Œå››ä¸ªå¤šæ™ºèƒ½ä½“ä»»åŠ¡çš„å®éªŒç»“æœè¯æ˜äº†DMACåœ¨æé«˜é€šä¿¡ç­–ç•¥çš„é²æ£’æ€§å’Œæ€§èƒ½æ–¹é¢çš„ä¼˜åŠ¿ï¼Œç›¸è¾ƒäºä¸¤ä¸ªå…ˆè¿›ä¸”å¸¸ç”¨çš„åŸºçº¿æ–¹æ³•ï¼ŒDMACå–å¾—äº†æ›´é«˜çš„æ”¹è¿›ã€‚æ­¤å¤–ï¼Œç»“æœè¿˜è¡¨æ˜DMACèƒ½å¤Ÿå®ç°å…·æœ‰å¯æ¥å—çš„é€šä¿¡æˆæœ¬çš„åˆ†æ•£å¼é€šä¿¡ç»“æ„ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.21278v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ ä¸­çš„é€šä¿¡è‡³å…³é‡è¦ï¼Œä½†ç°æœ‰æ–¹æ³•æ˜“é™·å…¥å±€éƒ¨ä¼˜åŒ–å›°å¢ƒï¼Œå¯¼è‡´é€šä¿¡ä¸å¹³è¡¡ã€‚æœ¬æ–‡å—ç¤¾ä¼šå­¦ä¸­åˆ†æƒç†è®ºå¯å‘ï¼Œæå‡ºDMACæ–¹æ³•ï¼Œé€šè¿‡é‡æ–°è®­ç»ƒæ™ºèƒ½ä½“é€šä¿¡ç­–ç•¥ä»¥å¢å¼ºå…¶é²æ£’æ€§ï¼Œå¹¶é‡‡ç”¨å¯¹æŠ—æ€§è®­ç»ƒæ–¹å¼ä¿ƒä½¿æ™ºèƒ½ä½“æ¢ç´¢å…¶ä»–æ½œåœ¨é€šä¿¡æ–¹æ¡ˆå¹¶å®ç°å»ä¸­å¿ƒåŒ–ç»“æ„ã€‚å®éªŒè¡¨æ˜ï¼ŒDMACèƒ½æé«˜é€šä¿¡ç­–ç•¥çš„é²æ£’æ€§å’Œæ€§èƒ½ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ ä¸­ï¼Œé€šä¿¡å¯¹æ™ºèƒ½ä½“å†³ç­–è‡³å…³é‡è¦ã€‚</li>
<li>ç°æœ‰æ–¹æ³•é¢ä¸´å±€éƒ¨ä¼˜åŒ–é—®é¢˜ï¼Œå¯¼è‡´é€šä¿¡ä¸å¹³è¡¡å’Œç»“æ„è„†å¼±ã€‚</li>
<li>DMACæ–¹æ³•å—ç¤¾ä¼šå­¦ä¸­åˆ†æƒç†è®ºå¯å‘ï¼Œæ—¨åœ¨å¢å¼ºæ™ºèƒ½ä½“é€šä¿¡ç­–ç•¥çš„é²æ£’æ€§ã€‚</li>
<li>DMACé€šè¿‡é‡æ–°è®­ç»ƒé€šä¿¡ç­–ç•¥ï¼Œä¿ƒä½¿æ™ºèƒ½ä½“å®ç°å»ä¸­å¿ƒåŒ–ç»“æ„ã€‚</li>
<li>DMACé‡‡ç”¨å¯¹æŠ—æ€§è®­ç»ƒæ–¹å¼ï¼Œä½¿æ™ºèƒ½ä½“èƒ½åŠ¨æ€è¯†åˆ«å¹¶å±è”½å…³é”®é€šä¿¡é€šé“ã€‚</li>
<li>å®éªŒè¡¨æ˜ï¼ŒDMACç›¸è¾ƒäºä¸¤ç§å…ˆè¿›åŸºçº¿æ–¹æ³•ï¼Œåœ¨æé«˜é€šä¿¡ç­–ç•¥çš„é²æ£’æ€§å’Œæ€§èƒ½æ–¹é¢æœ‰æ›´é«˜æˆæ•ˆã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.21278">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-e49cf3a91dfba59b6fc9f0d69daaf261.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-81c590ba3880e72522fd22b5326f58bf.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-98b83501f415ee3baee1770ed6d5cb40.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e2f9aec2d36b98a1aad6f4927d9699f2.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-ef574ff608a77dec178ce566dfdc0cc1.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="Talk-Before-You-Retrieve-Agent-Led-Discussions-for-Better-RAG-in-Medical-QA"><a href="#Talk-Before-You-Retrieve-Agent-Led-Discussions-for-Better-RAG-in-Medical-QA" class="headerlink" title="Talk Before You Retrieve: Agent-Led Discussions for Better RAG in   Medical QA"></a>Talk Before You Retrieve: Agent-Led Discussions for Better RAG in   Medical QA</h2><p><strong>Authors:Xuanzhao Dong, Wenhui Zhu, Hao Wang, Xiwen Chen, Peijie Qiu, Rui Yin, Yi Su, Yalin Wang</strong></p>
<p>Medical question answering (QA) is a reasoning-intensive task that remains challenging for large language models (LLMs) due to hallucinations and outdated domain knowledge. Retrieval-Augmented Generation (RAG) provides a promising post-training solution by leveraging external knowledge. However, existing medical RAG systems suffer from two key limitations: (1) a lack of modeling for human-like reasoning behaviors during information retrieval, and (2) reliance on suboptimal medical corpora, which often results in the retrieval of irrelevant or noisy snippets. To overcome these challenges, we propose Discuss-RAG, a plug-and-play module designed to enhance the medical QA RAG system through collaborative agent-based reasoning. Our method introduces a summarizer agent that orchestrates a team of medical experts to emulate multi-turn brainstorming, thereby improving the relevance of retrieved content. Additionally, a decision-making agent evaluates the retrieved snippets before their final integration. Experimental results on four benchmark medical QA datasets show that Discuss-RAG consistently outperforms MedRAG, especially significantly improving answer accuracy by up to 16.67% on BioASQ and 12.20% on PubMedQA. The code is available at: <a target="_blank" rel="noopener" href="https://github.com/LLM-VLM-GSL/Discuss-RAG">https://github.com/LLM-VLM-GSL/Discuss-RAG</a>. </p>
<blockquote>
<p>åŒ»ç–—é—®ç­”ï¼ˆQAï¼‰æ˜¯ä¸€é¡¹éœ€è¦å¤§é‡æ¨ç†çš„ä»»åŠ¡ï¼Œå¯¹äºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ¥è¯´ä»ç„¶å…·æœ‰æŒ‘æˆ˜æ€§ï¼Œå› ä¸ºå­˜åœ¨è™šæ„å’Œè¿‡æ—¶çš„é¢†åŸŸçŸ¥è¯†ã€‚æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰é€šè¿‡åˆ©ç”¨å¤–éƒ¨çŸ¥è¯†æä¾›äº†ä¸€ç§æœ‰å‰é€”çš„åæœŸè®­ç»ƒè§£å†³æ–¹æ¡ˆã€‚ç„¶è€Œï¼Œç°æœ‰çš„åŒ»ç–—RAGç³»ç»Ÿå­˜åœ¨ä¸¤ä¸ªä¸»è¦å±€é™æ€§ï¼šï¼ˆ1ï¼‰åœ¨ä¿¡æ¯æ£€ç´¢è¿‡ç¨‹ä¸­ç¼ºä¹å¯¹äººç±»å¼æ¨ç†è¡Œä¸ºçš„å»ºæ¨¡ï¼›ï¼ˆ2ï¼‰ä¾èµ–äºæ¬¡ä¼˜çš„åŒ»ç–—è¯­æ–™åº“ï¼Œè¿™å¾€å¾€å¯¼è‡´æ£€ç´¢åˆ°ä¸ç›¸å…³æˆ–å˜ˆæ‚çš„ç‰‡æ®µã€‚ä¸ºäº†å…‹æœè¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†Discuss-RAGï¼Œè¿™æ˜¯ä¸€ä¸ªå³æ’å³ç”¨çš„æ¨¡å—ï¼Œæ—¨åœ¨é€šè¿‡åŸºäºåä½œä»£ç†çš„æ¨ç†æ¥å¢å¼ºåŒ»ç–—é—®ç­”RAGç³»ç»Ÿã€‚æˆ‘ä»¬çš„æ–¹æ³•å¼•å…¥äº†ä¸€ä¸ªæ€»ç»“ä»£ç†ï¼Œè¯¥ä»£ç†åè°ƒåŒ»ç–—ä¸“å®¶å›¢é˜Ÿè¿›è¡Œå¤šæ¬¡å¤´è„‘é£æš´ï¼Œä»è€Œæé«˜æ£€ç´¢å†…å®¹çš„å…³è”æ€§ã€‚æ­¤å¤–ï¼Œä¸€ä¸ªå†³ç­–ä»£ç†åœ¨æœ€ç»ˆæ•´åˆä¹‹å‰è¯„ä¼°æ£€ç´¢åˆ°çš„ç‰‡æ®µã€‚åœ¨å››ä¸ªåŸºå‡†åŒ»ç–—é—®ç­”æ•°æ®é›†ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼ŒDiscuss-RAGæŒç»­ä¼˜äºMedRAGï¼Œç‰¹åˆ«æ˜¯åœ¨BioASQä¸Šç­”æ¡ˆå‡†ç¡®ç‡æé«˜äº†é«˜è¾¾16.67%ï¼Œåœ¨PubMedQAä¸Šæé«˜äº†12.20%ã€‚ä»£ç å¯åœ¨ï¼š<a target="_blank" rel="noopener" href="https://github.com/LLM-VLM-GSL/Discuss-RAG%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/LLM-VLM-GSL/Discuss-RAGæ‰¾åˆ°ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.21252v1">PDF</a> </p>
<p><strong>æ‘˜è¦</strong></p>
<p>åŒ»å­¦é—®ç­”æ˜¯ä¸€ä¸ªéœ€è¦å¤§é‡æ¨ç†çš„ä»»åŠ¡ï¼Œå¯¹äºå¤§å‹è¯­è¨€æ¨¡å‹æ¥è¯´ä»ç„¶å…·æœ‰æŒ‘æˆ˜æ€§ï¼Œå› ä¸ºå­˜åœ¨è™šæ„å’Œè¿‡æ—¶çš„é¢†åŸŸçŸ¥è¯†é—®é¢˜ã€‚æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰é€šè¿‡åˆ©ç”¨å¤–éƒ¨çŸ¥è¯†æä¾›äº†ä¸€ç§æœ‰å‰æ™¯çš„åæœŸè®­ç»ƒè§£å†³æ–¹æ¡ˆã€‚ç„¶è€Œï¼Œç°æœ‰çš„åŒ»å­¦RAGç³»ç»Ÿå­˜åœ¨ä¸¤ä¸ªä¸»è¦å±€é™æ€§ï¼šï¼ˆ1ï¼‰åœ¨ä¿¡æ¯æ£€ç´¢è¿‡ç¨‹ä¸­ç¼ºä¹äººç±»å¼æ¨ç†è¡Œä¸ºçš„å»ºæ¨¡ï¼›ï¼ˆ2ï¼‰ä¾èµ–äºæ¬¡ä¼˜åŒ»å­¦è¯­æ–™åº“ï¼Œè¿™é€šå¸¸ä¼šå¯¼è‡´æ£€ç´¢åˆ°ä¸ç›¸å…³æˆ–å˜ˆæ‚çš„ç‰‡æ®µã€‚ä¸ºäº†å…‹æœè¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†Discuss-RAGï¼Œè¿™æ˜¯ä¸€ä¸ªå³æ’å³ç”¨çš„æ¨¡å—ï¼Œæ—¨åœ¨é€šè¿‡åŸºäºåä½œä»£ç†çš„æ¨ç†å¢å¼ºåŒ»å­¦é—®ç­”RAGç³»ç»Ÿã€‚æˆ‘ä»¬çš„æ–¹æ³•å¼•å…¥äº†ä¸€ä¸ªæ€»ç»“ä»£ç†ï¼Œè¯¥ä»£ç†åè°ƒåŒ»å­¦ä¸“å®¶å›¢é˜Ÿè¿›è¡Œå¤šè½®è®¨è®ºï¼Œä»è€Œæé«˜æ£€ç´¢å†…å®¹çš„å…³è”æ€§ã€‚æ­¤å¤–ï¼Œä¸€ä¸ªå†³ç­–ä»£ç†å¯¹æ£€ç´¢åˆ°çš„ç‰‡æ®µè¿›è¡Œè¯„ä¼°ï¼Œç„¶åå†è¿›è¡Œæœ€ç»ˆé›†æˆã€‚åœ¨å››ä¸ªåŸºå‡†åŒ»å­¦é—®ç­”æ•°æ®é›†ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼ŒDiscuss-RAGçš„æ€§èƒ½æŒç»­ä¼˜äºMedRAGï¼Œå°¤å…¶æ˜¯åœ¨BioASQä¸Šç­”æ¡ˆå‡†ç¡®ç‡æé«˜é«˜è¾¾16.67%ï¼Œåœ¨PubMedQAä¸Šæé«˜12.20%ã€‚ç›¸å…³ä»£ç å¯åœ¨ï¼š<a target="_blank" rel="noopener" href="https://github.com/LLM-VLM-GSL/Discuss-RAG%E8%8E%B7%E5%8F%96%E3%80%82">https://github.com/LLM-VLM-GSL/Discuss-RAGè·å–ã€‚</a></p>
<p><strong>è¦ç‚¹</strong></p>
<ol>
<li>åŒ»å­¦é—®ç­”æ˜¯ä¸€ä¸ªå¯¹å¤§å‹è¯­è¨€æ¨¡å‹å…·æœ‰æŒ‘æˆ˜æ€§çš„ä»»åŠ¡ï¼Œå› ä¸ºå­˜åœ¨è™šæ„å’Œé¢†åŸŸçŸ¥è¯†è¿‡æ—¶çš„é—®é¢˜ã€‚</li>
<li>æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰æ˜¯ä¸€ç§åˆ©ç”¨å¤–éƒ¨çŸ¥è¯†çš„åæœŸè®­ç»ƒè§£å†³æ–¹æ¡ˆã€‚</li>
<li>ç°æœ‰åŒ»å­¦RAGç³»ç»Ÿå­˜åœ¨ä¸¤ä¸ªä¸»è¦å±€é™æ€§ï¼šç¼ºä¹äººç±»å¼æ¨ç†è¡Œä¸ºçš„å»ºæ¨¡å’Œä¾èµ–äºæ¬¡ä¼˜åŒ»å­¦è¯­æ–™åº“ã€‚</li>
<li>Discuss-RAGé€šè¿‡å¼•å…¥æ€»ç»“ä»£ç†å’Œå†³ç­–ä»£ç†ï¼Œæ—¨åœ¨è§£å†³è¿™äº›æŒ‘æˆ˜ã€‚</li>
<li>æ€»ç»“ä»£ç†åè°ƒåŒ»å­¦ä¸“å®¶å›¢é˜Ÿè¿›è¡Œå¤šè½®è®¨è®ºï¼Œæé«˜æ£€ç´¢å†…å®¹çš„å…³è”æ€§ã€‚</li>
<li>å†³ç­–ä»£ç†å¯¹æ£€ç´¢åˆ°çš„ç‰‡æ®µè¿›è¡Œè¯„ä¼°ï¼Œå†è¿›è¡Œæœ€ç»ˆé›†æˆã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.21252">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-a9615066a83ce517a9bd2181d1572205.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-3c4f626f9094f6d3b55b48e201d7500f.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-d094249ff31a94fc16939de87bc4f6e2.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-22cee3d38ea983dc8524663713d51b0c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-6b63636f493f1b01c25fd0e31cd7d4f3.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="VideoMultiAgents-A-Multi-Agent-Framework-for-Video-Question-Answering"><a href="#VideoMultiAgents-A-Multi-Agent-Framework-for-Video-Question-Answering" class="headerlink" title="VideoMultiAgents: A Multi-Agent Framework for Video Question Answering"></a>VideoMultiAgents: A Multi-Agent Framework for Video Question Answering</h2><p><strong>Authors:Noriyuki Kugo, Xiang Li, Zixin Li, Ashish Gupta, Arpandeep Khatua, Nidhish Jain, Chaitanya Patel, Yuta Kyuragi, Yasunori Ishii, Masamoto Tanabiki, Kazuki Kozuka, Ehsan Adeli</strong></p>
<p>Video Question Answering (VQA) inherently relies on multimodal reasoning, integrating visual, temporal, and linguistic cues to achieve a deeper understanding of video content. However, many existing methods rely on feeding frame-level captions into a single model, making it difficult to adequately capture temporal and interactive contexts. To address this limitation, we introduce VideoMultiAgents, a framework that integrates specialized agents for vision, scene graph analysis, and text processing. It enhances video understanding leveraging complementary multimodal reasoning from independently operating agents. Our approach is also supplemented with a question-guided caption generation, which produces captions that highlight objects, actions, and temporal transitions directly relevant to a given query, thus improving the answer accuracy. Experimental results demonstrate that our method achieves state-of-the-art performance on Intent-QA (79.0%, +6.2% over previous SOTA), EgoSchema subset (75.4%, +3.4%), and NExT-QA (79.6%, +0.4%). The source code is available at <a target="_blank" rel="noopener" href="https://github.com/PanasonicConnect/VideoMultiAgents">https://github.com/PanasonicConnect/VideoMultiAgents</a>. </p>
<blockquote>
<p>è§†é¢‘é—®ç­”ï¼ˆVQAï¼‰æœ¬è´¨ä¸Šä¾èµ–äºå¤šæ¨¡æ€æ¨ç†ï¼Œå®ƒç»“åˆäº†è§†è§‰ã€æ—¶é—´å’Œè¯­è¨€çº¿ç´¢ï¼Œä»¥å®ç°æ›´æ·±å±‚æ¬¡çš„è§†é¢‘å†…å®¹ç†è§£ã€‚ç„¶è€Œï¼Œè®¸å¤šç°æœ‰æ–¹æ³•ä¾èµ–äºå°†å¸§çº§å­—å¹•è¾“å…¥å•ä¸€æ¨¡å‹ï¼Œè¿™ä½¿å¾—éš¾ä»¥å……åˆ†æ•è·æ—¶é—´å’Œäº¤äº’ä¸Šä¸‹æ–‡ã€‚ä¸ºäº†è§£å†³è¿™ä¸€å±€é™æ€§ï¼Œæˆ‘ä»¬å¼•å…¥äº†VideoMultiAgentsæ¡†æ¶ï¼Œè¯¥æ¡†æ¶é›†æˆäº†ç”¨äºè§†è§‰ã€åœºæ™¯å›¾åˆ†æå’Œæ–‡æœ¬å¤„ç†çš„ä¸“é—¨ä»£ç†ã€‚å®ƒé€šè¿‡ç‹¬ç«‹è¿è¡Œçš„ä»£ç†çš„äº’è¡¥å¤šæ¨¡æ€æ¨ç†æ¥å¢å¼ºè§†é¢‘ç†è§£ã€‚æˆ‘ä»¬çš„æ–¹æ³•è¿˜è¾…ä»¥é—®é¢˜å¼•å¯¼çš„å­—å¹•ç”Ÿæˆï¼Œç”Ÿæˆçš„å­—å¹•çªå‡ºäº†ä¸ç»™å®šæŸ¥è¯¢ç›´æ¥ç›¸å…³çš„å¯¹è±¡ã€åŠ¨ä½œå’Œæ—¶é—´è¿‡æ¸¡ï¼Œä»è€Œæé«˜äº†ç­”æ¡ˆçš„å‡†ç¡®æ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨Intent-QAï¼ˆæ„å›¾é—®ç­”ï¼Œ79.0%ï¼Œè¾ƒä¹‹å‰çš„æœ€ä¼˜æ–¹æ³•é«˜å‡º6.2%ï¼‰ã€EgoSchemaå­é›†ï¼ˆ75.4%ï¼Œé«˜å‡º3.4%ï¼‰å’ŒNExT-QAï¼ˆä¸‹ä¸€ä¸ªé—®ç­”ï¼Œ79.6%ï¼Œé«˜å‡º0.4%ï¼‰ä¸Šè¾¾åˆ°äº†æœ€æ–°æŠ€æœ¯æ°´å¹³ã€‚æºä»£ç å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/PanasonicConnect/VideoMultiAgents%E8%8E%B7%E5%8F%96%E3%80%82">https://github.com/PanasonicConnect/VideoMultiAgentsè·å–ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.20091v2">PDF</a> </p>
<p><strong>Summary</strong><br>è§†é¢‘é—®ç­”ï¼ˆVQAï¼‰éœ€è¦ä¾é å¯¹è§†é¢‘å†…å®¹çš„å¤šæ¨¡æ€æ¨ç†è¿›è¡Œå›ç­”ï¼ŒåŒ…æ‹¬å¯¹è§†è§‰ã€æ—¶é—´å’Œè¯­è¨€çº¿ç´¢çš„æ•´åˆã€‚ç„¶è€Œï¼Œç°æœ‰æ–¹æ³•å¤§å¤šä¾èµ–äºå°†å¸§çº§å­—å¹•è¾“å…¥å•ä¸€æ¨¡å‹ï¼Œéš¾ä»¥å……åˆ†æ•æ‰æ—¶é—´å’Œäº¤äº’ä¸Šä¸‹æ–‡ã€‚ä¸ºè§£å†³æ­¤é—®é¢˜ï¼Œæˆ‘ä»¬æ¨å‡ºVideoMultiAgentsæ¡†æ¶ï¼Œé›†æˆä¸“é—¨ç”¨äºè§†è§‰ã€åœºæ™¯å›¾åˆ†æå’Œæ–‡æœ¬å¤„ç†çš„ä»£ç†ã€‚å®ƒé€šè¿‡ç‹¬ç«‹æ“ä½œçš„ä»£ç†çš„äº’è¡¥å¤šæ¨¡æ€æ¨ç†å¢å¼ºè§†é¢‘ç†è§£ã€‚æ­¤å¤–ï¼Œè¾…ä»¥é—®é¢˜å¯¼å‘çš„æ ‡é¢˜ç”Ÿæˆï¼Œç”Ÿæˆä¸æŸ¥è¯¢ç›´æ¥ç›¸å…³çš„ç‰©ä½“ã€åŠ¨ä½œå’Œæ—¶é—´è¿‡æ¸¡çš„æ ‡é¢˜ï¼Œä»è€Œæé«˜ç­”æ¡ˆçš„å‡†ç¡®æ€§ã€‚å®éªŒç»“æœè¯æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨Intent-QAï¼ˆæå‡6.2%ï¼Œè¾¾åˆ°79.0%ï¼‰ã€EgoSchemaå­é›†ï¼ˆæå‡3.4%ï¼Œè¾¾åˆ°75.4%ï¼‰å’ŒNExT-QAï¼ˆæå‡0.4%ï¼Œè¾¾åˆ°79.6%ï¼‰ä¸Šè¾¾åˆ°äº†æœ€æ–°çš„æ°´å¹³ã€‚ä»£ç å¯åœ¨PanasonicConnectå…¬å¸çš„VideoMultiAgentsé¡¹ç›®ä¸­æ‰¾åˆ°ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>VQAä¾èµ–äºå¤šæ¨¡æ€æ¨ç†ï¼Œéœ€è¦æ•´åˆè§†è§‰ã€æ—¶é—´å’Œè¯­è¨€çº¿ç´¢ã€‚</li>
<li>ç°æœ‰æ–¹æ³•ä¸»è¦ä¾èµ–å•ä¸€æ¨¡å‹å¤„ç†å¸§çº§å­—å¹•ï¼Œéš¾ä»¥æ•æ‰æ—¶é—´å’Œäº¤äº’ä¸Šä¸‹æ–‡ã€‚</li>
<li>VideoMultiAgentsæ¡†æ¶é›†æˆäº†ä¸“é—¨ç”¨äºè§†è§‰ã€åœºæ™¯å›¾åˆ†æå’Œæ–‡æœ¬å¤„ç†çš„ä»£ç†ï¼Œé€šè¿‡ç‹¬ç«‹æ“ä½œçš„ä»£ç†çš„äº’è¡¥è¿›è¡Œè§†é¢‘ç†è§£ã€‚</li>
<li>é—®é¢˜å¯¼å‘çš„æ ‡é¢˜ç”ŸæˆæŠ€æœ¯å¯ä»¥æé«˜ç­”æ¡ˆçš„å‡†ç¡®æ€§ã€‚</li>
<li>VideoMultiAgentsåœ¨å¤šä¸ªæ•°æ®é›†ä¸Šå–å¾—äº†æœ€æ–°æˆæœï¼ŒåŒ…æ‹¬Intent-QAã€EgoSchemaå­é›†å’ŒNExT-QAã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.20091">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-502399b049ae062d1b078916628e2c19.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-76608eb954f541943dcb8b3274cf1e3d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-015b959e445ff6acd218f29ef8902276.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="OS-Genesis-Automating-GUI-Agent-Trajectory-Construction-via-Reverse-Task-Synthesis"><a href="#OS-Genesis-Automating-GUI-Agent-Trajectory-Construction-via-Reverse-Task-Synthesis" class="headerlink" title="OS-Genesis: Automating GUI Agent Trajectory Construction via Reverse   Task Synthesis"></a>OS-Genesis: Automating GUI Agent Trajectory Construction via Reverse   Task Synthesis</h2><p><strong>Authors:Qiushi Sun, Kanzhi Cheng, Zichen Ding, Chuanyang Jin, Yian Wang, Fangzhi Xu, Zhenyu Wu, Chengyou Jia, Liheng Chen, Zhoumianze Liu, Ben Kao, Guohao Li, Junxian He, Yu Qiao, Zhiyong Wu</strong></p>
<p>Graphical User Interface (GUI) agents powered by Vision-Language Models (VLMs) have demonstrated human-like computer control capability. Despite their utility in advancing digital automation, a critical bottleneck persists: collecting high-quality trajectory data for training. Common practices for collecting such data rely on human supervision or synthetic data generation through executing pre-defined tasks, which are either resource-intensive or unable to guarantee data quality. Moreover, these methods suffer from limited data diversity and significant gaps between synthetic data and real-world environments. To address these challenges, we propose OS-Genesis, a novel GUI data synthesis pipeline that reverses the conventional trajectory collection process. Instead of relying on pre-defined tasks, OS-Genesis enables agents first to perceive environments and perform step-wise interactions, then retrospectively derive high-quality tasks to enable trajectory-level exploration. A trajectory reward model is then employed to ensure the quality of the generated trajectories. We demonstrate that training GUI agents with OS-Genesis significantly improves their performance on highly challenging online benchmarks. In-depth analysis further validates OS-Genesisâ€™s efficiency and its superior data quality and diversity compared to existing synthesis methods. Our codes, data, and checkpoints are available at <a target="_blank" rel="noopener" href="https://qiushisun.github.io/OS-Genesis-Home/">https://qiushisun.github.io/OS-Genesis-Home/</a>. </p>
<blockquote>
<p>ç”±è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMsï¼‰é©±åŠ¨çš„å›¾å½¢ç”¨æˆ·ç•Œé¢ï¼ˆGUIï¼‰ä»£ç†å·²ç»å±•ç°å‡ºäººç±»èˆ¬çš„è®¡ç®—æœºæ§åˆ¶èƒ½åŠ›ã€‚å°½ç®¡å®ƒä»¬åœ¨æ¨è¿›æ•°å­—è‡ªåŠ¨åŒ–æ–¹é¢å¾ˆæœ‰ç”¨ï¼Œä½†ä»ç„¶å­˜åœ¨ä¸€ä¸ªå…³é”®ç“¶é¢ˆï¼šæ”¶é›†é«˜è´¨é‡è½¨è¿¹æ•°æ®è¿›è¡Œè®­ç»ƒã€‚ç›®å‰å¸¸è§çš„æ”¶é›†æ­¤ç±»æ•°æ®çš„æ–¹æ³•ä¾èµ–äºäººå·¥ç›‘ç£æˆ–é€šè¿‡æ‰§è¡Œé¢„å®šä¹‰ä»»åŠ¡æ¥ç”Ÿæˆåˆæˆæ•°æ®ï¼Œè¿™äº›æ–¹æ³•è¦ä¹ˆèµ„æºå¯†é›†ï¼Œè¦ä¹ˆæ— æ³•ä¿è¯æ•°æ®è´¨é‡ã€‚æ­¤å¤–ï¼Œè¿™äº›æ–¹æ³•è¿˜é­å—æ•°æ®å¤šæ ·æ€§æœ‰é™ä»¥åŠåˆæˆæ•°æ®ä¸çœŸå®ä¸–ç•Œç¯å¢ƒä¹‹é—´æ˜¾è‘—å·®å¼‚çš„å›°æ‰°ã€‚ä¸ºäº†åº”å¯¹è¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†OS-Genesisï¼Œä¸€ç§æ–°å‹GUIæ•°æ®åˆæˆç®¡é“ï¼Œå®ƒé¢ è¦†äº†ä¼ ç»Ÿçš„è½¨è¿¹æ”¶é›†è¿‡ç¨‹ã€‚ä¸åŒäºä¾èµ–é¢„å®šä¹‰ä»»åŠ¡çš„æ–¹æ³•ï¼ŒOS-Genesisä½¿ä»£ç†é¦–å…ˆæ„ŸçŸ¥ç¯å¢ƒå¹¶æ‰§è¡Œåˆ†æ­¥äº¤äº’ï¼Œç„¶åå›é¡¾æ€§åœ°æ¨å¯¼é«˜è´¨é‡ä»»åŠ¡ä»¥å®ç°è½¨è¿¹å±‚é¢çš„æ¢ç´¢ã€‚æ¥ç€ï¼Œé‡‡ç”¨è½¨è¿¹å¥–åŠ±æ¨¡å‹æ¥ä¿è¯ç”Ÿæˆè½¨è¿¹çš„è´¨é‡ã€‚æˆ‘ä»¬è¯æ˜ï¼Œä½¿ç”¨OS-Genesisè®­ç»ƒçš„GUIä»£ç†åœ¨é«˜åº¦æŒ‘æˆ˜æ€§çš„åœ¨çº¿åŸºå‡†æµ‹è¯•ä¸­æ˜¾è‘—æé«˜äº†æ€§èƒ½ã€‚æ·±å…¥åˆ†æè¿›ä¸€æ­¥éªŒè¯äº†OS-Genesisçš„æ•ˆç‡åŠå…¶ç›¸è¾ƒäºç°æœ‰åˆæˆæ–¹æ³•åœ¨æ•°æ®è´¨é‡å’Œå¤šæ ·æ€§æ–¹é¢çš„ä¼˜è¶Šæ€§ã€‚æˆ‘ä»¬çš„ä»£ç ã€æ•°æ®å’Œæ£€æŸ¥ç‚¹ä½äºï¼š<a target="_blank" rel="noopener" href="https://qiushisun.github.io/OS-Genesis-Home%E3%80%82">https://qiushisun.github.io/OS-Genesis-Home/ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.19723v2">PDF</a> Work in progress</p>
<p><strong>Summary</strong></p>
<p>åŸºäºVision-Language Modelsï¼ˆVLMsï¼‰çš„å›¾å½¢ç”¨æˆ·ç•Œé¢ï¼ˆGUIï¼‰ä»£ç†å±•ç°äº†äººç±»èˆ¬çš„è®¡ç®—æœºæ§åˆ¶åŠŸèƒ½ã€‚ç„¶è€Œï¼Œæ”¶é›†é«˜è´¨é‡è½¨è¿¹æ•°æ®ä»¥è¿›è¡Œè®­ç»ƒä»æ˜¯ç“¶é¢ˆã€‚å¸¸è§„çš„æ•°æ®æ”¶é›†æ–¹æ³•ä¾èµ–äºäººå·¥ç›‘ç£æˆ–æ‰§è¡Œé¢„å®šä¹‰ä»»åŠ¡ç”Ÿæˆåˆæˆæ•°æ®ï¼Œè¿™äº›æ–¹æ³•è¦ä¹ˆèµ„æºæ¶ˆè€—å¤§ï¼Œè¦ä¹ˆæ— æ³•ä¿è¯æ•°æ®è´¨é‡ã€‚ä¸ºè§£å†³è¿™äº›é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†OS-Genesisï¼Œä¸€ç§æ–°å‹çš„GUIæ•°æ®åˆæˆæµç¨‹ã€‚OS-Genesisæ”¹å˜äº†ä¼ ç»Ÿè½¨è¿¹æ”¶é›†è¿‡ç¨‹ï¼Œè®©ä»£ç†é¦–å…ˆæ„ŸçŸ¥ç¯å¢ƒå¹¶æ‰§è¡Œé€æ­¥äº¤äº’ï¼Œç„¶åå›é¡¾æ€§åœ°ç”Ÿæˆé«˜è´¨é‡ä»»åŠ¡ä»¥å®ç°è½¨è¿¹å±‚é¢çš„æ¢ç´¢ã€‚ä½¿ç”¨è½¨è¿¹å¥–åŠ±æ¨¡å‹ç¡®ä¿ç”Ÿæˆè½¨è¿¹çš„è´¨é‡ã€‚å®éªŒè¯æ˜ï¼Œä½¿ç”¨OS-Genesisè®­ç»ƒçš„GUIä»£ç†åœ¨å…·æœ‰æŒ‘æˆ˜æ€§çš„åœ¨çº¿åŸºå‡†æµ‹è¯•ä¸­è¡¨ç°ä¼˜å¼‚ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>GUIä»£ç†åˆ©ç”¨Vision-Language Modelsï¼ˆVLMsï¼‰å®ç°äº†äººç±»èˆ¬çš„è®¡ç®—æœºæ§åˆ¶åŠŸèƒ½ã€‚</li>
<li>æ”¶é›†é«˜è´¨é‡è½¨è¿¹æ•°æ®æ˜¯è®­ç»ƒGUIä»£ç†çš„ç“¶é¢ˆã€‚</li>
<li>ä¼ ç»Ÿæ•°æ®æ”¶é›†æ–¹æ³•ä¾èµ–äººå·¥ç›‘ç£æˆ–é¢„å®šä¹‰ä»»åŠ¡ç”Ÿæˆåˆæˆæ•°æ®ï¼Œå­˜åœ¨èµ„æºæ¶ˆè€—å¤§ã€æ•°æ®è´¨é‡éš¾ä»¥ä¿è¯çš„é—®é¢˜ã€‚</li>
<li>OS-Genesisæ˜¯ä¸€ç§æ–°å‹çš„GUIæ•°æ®åˆæˆæµç¨‹ï¼Œæ”¹å˜äº†è½¨è¿¹æ”¶é›†æ–¹å¼ï¼Œè®©ä»£ç†é€šè¿‡æ„ŸçŸ¥ç¯å¢ƒå’Œé€æ­¥äº¤äº’æ¥ç”Ÿæˆé«˜è´¨é‡ä»»åŠ¡ã€‚</li>
<li>OS-Genesisä½¿ç”¨è½¨è¿¹å¥–åŠ±æ¨¡å‹ç¡®ä¿ç”Ÿæˆè½¨è¿¹çš„è´¨é‡ã€‚</li>
<li>ä½¿ç”¨OS-Genesisè®­ç»ƒçš„GUIä»£ç†åœ¨åœ¨çº¿åŸºå‡†æµ‹è¯•ä¸­è¡¨ç°ä¼˜å¼‚ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.19723">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-9b95e3404a2256293bb6c7fe11e915b6.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ba1700a31e10b46cddf93e69f2e267ac.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-30a5e1826f4a8033f3903760f890bd0c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e6f45987406f2bc882472004fb4ed52b.jpg" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="You-Name-It-I-Run-It-An-LLM-Agent-to-Execute-Tests-of-Arbitrary-Projects"><a href="#You-Name-It-I-Run-It-An-LLM-Agent-to-Execute-Tests-of-Arbitrary-Projects" class="headerlink" title="You Name It, I Run It: An LLM Agent to Execute Tests of Arbitrary   Projects"></a>You Name It, I Run It: An LLM Agent to Execute Tests of Arbitrary   Projects</h2><p><strong>Authors:Islem Bouzenia, Michael Pradel</strong></p>
<p>The ability to execute the test suite of a project is essential in many scenarios, e.g., to assess code quality and code coverage, to validate code changes made by developers or automated tools, and to ensure compatibility with dependencies. Despite its importance, executing the test suite of a project can be challenging in practice because different projects use different programming languages, software ecosystems, build systems, testing frameworks, and other tools. These challenges make it difficult to create a reliable, universal test execution method that works across different projects. This paper presents ExecutionAgent, an automated technique that prepares scripts for building an arbitrary project from source code and running its test cases. Inspired by the way a human developer would address this task, our approach is a large language model (LLM)-based agent that autonomously executes commands and interacts with the host system. The agent uses meta-prompting to gather guidelines on the latest technologies related to the given project, and it iteratively refines its process based on feedback from the previous steps. Our evaluation applies ExecutionAgent to 50 open-source projects that use 14 different programming languages and many different build and testing tools. The approach successfully executes the test suites of 33&#x2F;50 projects, while matching the test results of ground truth test suite executions with a deviation of only 7.5%. These results improve over the best previously available technique by 6.6x. The costs imposed by the approach are reasonable, with an execution time of 74 minutes and LLM costs of USD 0.16, on average per project. We envision ExecutionAgent to serve as a valuable tool for developers, automated programming tools, and researchers that need to execute tests across a wide variety of projects. </p>
<blockquote>
<p>æ‰§è¡Œé¡¹ç›®æµ‹è¯•é›†çš„èƒ½åŠ›åœ¨è®¸å¤šåœºæ™¯ä¸­éƒ½æ˜¯è‡³å…³é‡è¦çš„ï¼Œä¾‹å¦‚è¯„ä¼°ä»£ç è´¨é‡å’Œä»£ç è¦†ç›–ç‡ã€éªŒè¯å¼€å‘äººå‘˜æˆ–è‡ªåŠ¨åŒ–å·¥å…·æ‰€åšçš„ä»£ç æ›´æ”¹ï¼Œä»¥åŠç¡®ä¿ä¸ä¾èµ–é¡¹çš„å…¼å®¹æ€§ã€‚å°½ç®¡å…¶é‡è¦æ€§ä¸è¨€è€Œå–»ï¼Œä½†åœ¨å®è·µä¸­æ‰§è¡Œé¡¹ç›®çš„æµ‹è¯•é›†å¯èƒ½ä¼šé¢ä¸´æŒ‘æˆ˜ï¼Œå› ä¸ºä¸åŒçš„é¡¹ç›®ä¼šä½¿ç”¨ä¸åŒçš„ç¼–ç¨‹è¯­è¨€ã€è½¯ä»¶ç”Ÿæ€ç³»ç»Ÿã€æ„å»ºç³»ç»Ÿã€æµ‹è¯•æ¡†æ¶å’Œå…¶ä»–å·¥å…·ã€‚è¿™äº›æŒ‘æˆ˜ä½¿å¾—åˆ›å»ºä¸€ä¸ªå¯é ã€é€šç”¨çš„è·¨é¡¹ç›®æµ‹è¯•æ‰§è¡Œæ–¹æ³•å˜å¾—å›°éš¾ã€‚</p>
</blockquote>
<p>æœ¬æ–‡ä»‹ç»äº†ExecutionAgentï¼Œè¿™æ˜¯ä¸€ç§è‡ªåŠ¨åŒ–æŠ€æœ¯ï¼Œç”¨äºä¸ºä»æºä»£ç æ„å»ºä»»æ„é¡¹ç›®å¹¶è¿è¡Œå…¶æµ‹è¯•ç”¨ä¾‹ç”Ÿæˆè„šæœ¬ã€‚æˆ‘ä»¬çš„æ–¹æ³•çµæ„Ÿæ¥è‡ªäºäººç±»å¼€å‘è€…å¦‚ä½•å®Œæˆæ­¤ä»»åŠ¡ï¼Œå®ƒæ˜¯ä¸€ä¸ªåŸºäºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„ä»£ç†ï¼Œå¯ä»¥è‡ªä¸»æ‰§è¡Œå‘½ä»¤å¹¶ä¸ä¸»æœºç³»ç»Ÿäº¤äº’ã€‚è¯¥ä»£ç†ä½¿ç”¨å…ƒæç¤ºæ¥æ”¶é›†æœ‰å…³ç»™å®šé¡¹ç›®çš„æœ€æ–°æŠ€æœ¯æŒ‡å—ï¼Œå¹¶åŸºäºä¸Šä¸€æ­¥çš„åé¦ˆæ¥è¿­ä»£ä¼˜åŒ–å…¶æµç¨‹ã€‚</p>
<p>æˆ‘ä»¬çš„è¯„ä¼°å°†ExecutionAgentåº”ç”¨äº50ä¸ªä½¿ç”¨14ç§ä¸åŒç¼–ç¨‹è¯­è¨€ä»¥åŠè®¸å¤šä¸åŒæ„å»ºå’Œæµ‹è¯•å·¥å…·çš„å¼€æºé¡¹ç›®ã€‚è¯¥æ–¹æ³•æˆåŠŸæ‰§è¡Œäº†33&#x2F;50ä¸ªé¡¹ç›®çš„æµ‹è¯•é›†ï¼Œä¸åŸºå‡†æµ‹è¯•é›†æ‰§è¡Œç»“æœçš„åŒ¹é…åº¦è¾¾åˆ°äº†ä»…7.5%çš„åå·®ã€‚è¿™äº›ç»“æœæ¯”ä¹‹å‰å¯ç”¨çš„æœ€ä½³æŠ€æœ¯æœ‰äº†6.6å€çš„æå‡ã€‚è¯¥æ–¹æ³•çš„æˆæœ¬æ˜¯åˆç†çš„ï¼Œæ¯ä¸ªé¡¹ç›®çš„å¹³å‡æ‰§è¡Œæ—¶é—´ä¸º74åˆ†é’Ÿï¼ŒLLMçš„æˆæœ¬ä¸º0.16ç¾å…ƒã€‚</p>
<p>æˆ‘ä»¬æœŸæœ›ExecutionAgentèƒ½æˆä¸ºå¼€å‘è€…ã€è‡ªåŠ¨åŒ–ç¼–ç¨‹å·¥å…·å’Œç ”ç©¶äººå‘˜æ‰§è¡Œå¹¿æ³›é¡¹ç›®æµ‹è¯•çš„æœ‰ä»·å€¼å·¥å…·ã€‚</p>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.10133v2">PDF</a> PUBLISHED AT ISSTA 2025</p>
<p><strong>Summary</strong><br>é¡¹ç›®æµ‹è¯•å¥—ä»¶æ‰§è¡Œèƒ½åŠ›åœ¨è®¸å¤šåœºæ™¯ä¸­è‡³å…³é‡è¦ï¼Œå¦‚è¯„ä¼°ä»£ç è´¨é‡å’Œè¦†ç›–ç‡ã€éªŒè¯å¼€å‘è€…å’Œè‡ªåŠ¨åŒ–å·¥å…·æ‰€åšçš„ä»£ç æ›´æ”¹ä»¥åŠç¡®ä¿ä¸ä¾èµ–é¡¹çš„å…¼å®¹æ€§ã€‚ç„¶è€Œï¼Œæ‰§è¡Œé¡¹ç›®æµ‹è¯•å¥—ä»¶åœ¨å®è·µä¸­å¯èƒ½å…·æœ‰æŒ‘æˆ˜æ€§ï¼Œå› ä¸ºä¸åŒé¡¹ç›®ä½¿ç”¨çš„ç¼–ç¨‹è¯­è¨€ã€è½¯ä»¶ç”Ÿæ€ç³»ç»Ÿã€æ„å»ºç³»ç»Ÿã€æµ‹è¯•æ¡†æ¶å’Œå…¶ä»–å·¥å…·éƒ½æœ‰æ‰€ä¸åŒã€‚æœ¬æ–‡æå‡ºExecutionAgentï¼Œä¸€ç§è‡ªåŠ¨åŒ–æŠ€æœ¯ï¼Œç”¨äºä¸ºä»»æ„é¡¹ç›®ä»æºä»£ç æ„å»ºè„šæœ¬å¹¶è¿è¡Œå…¶æµ‹è¯•ç”¨ä¾‹ã€‚è¯¥æ–¹æ³•æ˜¯åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„ä»£ç†ï¼Œå¯è‡ªä¸»æ‰§è¡Œå‘½ä»¤å¹¶ä¸ä¸»æœºç³»ç»Ÿäº¤äº’ã€‚é€šè¿‡å¯¹50ä¸ªä½¿ç”¨ä¸åŒç¼–ç¨‹è¯­è¨€å’Œæ„å»ºåŠæµ‹è¯•å·¥å…·çš„å¼€æºé¡¹ç›®è¿›è¡Œè¯„ä¼°ï¼Œè¯¥æ–¹æ³•æˆåŠŸæ‰§è¡Œäº†å…¶ä¸­33ä¸ªé¡¹ç›®çš„æµ‹è¯•å¥—ä»¶ï¼Œä¸çœŸå®æµ‹è¯•å¥—ä»¶æ‰§è¡Œç»“æœçš„åå·®ä»…ä¸º7.5%ã€‚ç›¸è¾ƒäºä¹‹å‰æœ€ä½³çš„æŠ€æœ¯æ–¹æ³•ï¼Œè¿™ä¸€ç»“æœæé«˜äº†6.6å€ã€‚è¯¥æ–¹æ³•çš„æ‰§è¡Œæ—¶é—´å’ŒLLMæˆæœ¬åˆç†ã€‚é¢„æœŸExecutionAgentèƒ½ä¸ºéœ€è¦è·¨å¤šç§é¡¹ç›®æ‰§è¡Œæµ‹è¯•çš„å¼€å‘è€…ã€è‡ªåŠ¨åŒ–ç¼–ç¨‹å·¥å…·å’Œç ”ç©¶è€…æä¾›æœ‰ä»·å€¼çš„å·¥å…·ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æ‰§è¡Œæµ‹è¯•å¥—ä»¶å¯¹äºè¯„ä¼°ä»£ç è´¨é‡ã€éªŒè¯ä»£ç æ›´æ”¹å’Œç¡®ä¿ä¾èµ–å…¼å®¹æ€§è‡³å…³é‡è¦ã€‚</li>
<li>ä¸åŒé¡¹ç›®åœ¨æ‰§è¡Œæµ‹è¯•å¥—ä»¶æ—¶é¢ä¸´å¤šç§æŒ‘æˆ˜ï¼Œå¦‚ä½¿ç”¨çš„ç¼–ç¨‹è¯­è¨€ã€è½¯ä»¶ç”Ÿæ€ç³»ç»Ÿç­‰å·®å¼‚ã€‚</li>
<li>ExecutionAgentæ˜¯ä¸€ç§è‡ªåŠ¨åŒ–æŠ€æœ¯ï¼Œå¯ä»¥ä»æºä»£ç ä¸ºä»»æ„é¡¹ç›®æ„å»ºè„šæœ¬å¹¶è¿è¡Œå…¶æµ‹è¯•ç”¨ä¾‹ã€‚</li>
<li>ExecutionAgentåŸºäºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ï¼Œè‡ªä¸»æ‰§è¡Œå‘½ä»¤å¹¶ä¸ä¸»æœºç³»ç»Ÿäº¤äº’ã€‚</li>
<li>è¯¥æ–¹æ³•æˆåŠŸæ‰§è¡Œäº†33ä¸ªé¡¹ç›®çš„æµ‹è¯•å¥—ä»¶ï¼Œä¸çœŸå®ç»“æœçš„åå·®ä»…ä¸º7.5%ã€‚</li>
<li>ExecutionAgentç›¸è¾ƒäºä¹‹å‰çš„æŠ€æœ¯æ–¹æ³•æœ‰æ˜¾è‘—æé«˜ï¼Œæ‰§è¡Œæ—¶é—´åˆç†ï¼Œä¸”LLMæˆæœ¬ä¸é«˜ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.10133">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-dd9b0910e499c3df86e5b013dd2042ce.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-081fe0fb00f5659d83f9859b97f5bc27.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-7e2016364c4ce18c327939cab4898b71.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f7458436ca34177ab0a697086fdbb3dc.jpg" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1><h2 id="Adsorb-Agent-Autonomous-Identification-of-Stable-Adsorption-Configurations-via-Large-Language-Model-Agent"><a href="#Adsorb-Agent-Autonomous-Identification-of-Stable-Adsorption-Configurations-via-Large-Language-Model-Agent" class="headerlink" title="Adsorb-Agent: Autonomous Identification of Stable Adsorption   Configurations via Large Language Model Agent"></a>Adsorb-Agent: Autonomous Identification of Stable Adsorption   Configurations via Large Language Model Agent</h2><p><strong>Authors:Janghoon Ock, Tirtha Vinchurkar, Yayati Jadhav, Amir Barati Farimani</strong></p>
<p>Adsorption energy is a key reactivity descriptor in catalysis, enabling efficient screening for optimal catalysts. However, determining adsorption energy typically requires evaluating numerous adsorbate-catalyst configurations. Current algorithmic approaches rely on exhaustive enumeration of adsorption sites and configurations, which makes the process computationally intensive and does not inherently guarantee the identification of the global minimum energy. In this work, we introduce Adsorb-Agent, a Large Language Model (LLM) agent designed to efficiently identify system-specific stable adsorption configurations corresponding to the global minimum adsorption energy. Adsorb-Agent leverages its built-in knowledge and emergent reasoning capabilities to strategically explore adsorption configurations likely to hold adsorption energy. By reducing the reliance on exhaustive sampling, it significantly decreases the number of initial configurations required while improving the accuracy of adsorption energy predictions. We evaluate Adsorb-Agentâ€™s performance across twenty representative systems encompassing a range of complexities. The Adsorb-Agent successfully identifies comparable adsorption energies for 83.7% of the systems and achieves lower energies, closer to the actual global minimum, for 35% of the systems, while requiring significantly fewer initial configurations than conventional methods. Its capability is particularly evident in complex systems, where it identifies lower adsorption energies for 46.7% of systems involving intermetallic surfaces and 66.7% of systems with large adsorbate molecules. These results demonstrate the potential of Adsorb-Agent to accelerate catalyst discovery by reducing computational costs and improving the reliability of adsorption energy predictions. </p>
<blockquote>
<p>å¸é™„èƒ½æ˜¯å‚¬åŒ–ä¸­çš„å…³é”®ååº”æ€§æè¿°ç¬¦ï¼Œèƒ½å¤Ÿå®ç°é«˜æ•ˆç­›é€‰æœ€ä½³å‚¬åŒ–å‰‚ã€‚ç„¶è€Œï¼Œç¡®å®šå¸é™„èƒ½é€šå¸¸éœ€è¦è¯„ä¼°å¤§é‡çš„å¸é™„ç‰©-å‚¬åŒ–å‰‚æ„å‹ã€‚å½“å‰çš„ç®—æ³•æ–¹æ³•ä¾èµ–äºå¸é™„ä½ç‚¹å’Œæ„å‹çš„è¯¦å°½åˆ—ä¸¾ï¼Œè¿™ä½¿å¾—è¿‡ç¨‹è®¡ç®—å¯†é›†ï¼Œå¹¶ä¸”ä¸ä¿è¯èƒ½å›ºæœ‰åœ°è¯†åˆ«å…¨å±€æœ€ä½èƒ½é‡ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬å¼•å…¥äº†Adsorb-Agentï¼Œè¿™æ˜¯ä¸€ä¸ªå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä»£ç†ï¼Œæ—¨åœ¨æœ‰æ•ˆåœ°è¯†åˆ«ä¸å…¨å±€æœ€ä½å¸é™„èƒ½ç›¸å¯¹åº”çš„ç‰¹å®šç³»ç»Ÿç¨³å®šå¸é™„æ„å‹ã€‚Adsorb-Agentåˆ©ç”¨å…¶å†…ç½®çŸ¥è¯†å’Œæ–°å…´æ¨ç†èƒ½åŠ›æ¥æœ‰ç­–ç•¥åœ°æ¢ç´¢å¯èƒ½å«æœ‰å¸é™„èƒ½çš„å¸é™„æ„å‹ã€‚é€šè¿‡å‡å°‘å¯¹è¯¦å°½é‡‡æ ·çš„ä¾èµ–ï¼Œå®ƒåœ¨å‡å°‘æ‰€éœ€åˆå§‹æ„å‹æ•°é‡çš„åŒæ—¶æé«˜äº†å¸é™„èƒ½é¢„æµ‹çš„å‡†ç¡®æ€§ã€‚æˆ‘ä»¬è¯„ä¼°äº†Adsorb-Agentåœ¨æ¶µç›–å„ç§å¤æ‚æ€§çš„äºŒåä¸ªä»£è¡¨æ€§ç³»ç»Ÿä¸Šçš„æ€§èƒ½ã€‚Adsorb-AgentæˆåŠŸåœ°ä¸º83.7%çš„ç³»ç»Ÿç¡®å®šäº†ç›¸å½“çš„å¸é™„èƒ½ï¼Œå¹¶ä¸º35%çš„ç³»ç»Ÿå®ç°äº†æ›´æ¥è¿‘å®é™…å…¨å±€æœ€ä½å€¼çš„èƒ½é‡ï¼ŒåŒæ—¶æ‰€éœ€çš„åˆå§‹æ„å‹è¿œå°‘äºä¼ ç»Ÿæ–¹æ³•ã€‚å…¶èƒ½åŠ›åœ¨å¤æ‚ç³»ç»Ÿä¸­å°¤å…¶æ˜æ˜¾ï¼Œä¸ºæ¶‰åŠé‡‘å±é—´è¡¨é¢çš„ç³»ç»Ÿä¸­æœ‰46.7%å’Œå…·æœ‰å¤§å¸é™„åˆ†å­çš„ç³»ç»Ÿä¸­66.7%ç¡®å®šäº†è¾ƒä½çš„å¸é™„èƒ½ã€‚è¿™äº›ç»“æœè¯æ˜äº†Adsorb-Agentåœ¨åŠ é€Ÿå‚¬åŒ–å‰‚å‘ç°æ–¹é¢çš„æ½œåŠ›ï¼Œå¯ä»¥é™ä½è®¡ç®—æˆæœ¬å¹¶æé«˜å¸é™„èƒ½é¢„æµ‹çš„å¯ä¿¡åº¦ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2410.16658v3">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>å¸é™„èƒ½æ˜¯å‚¬åŒ–ä¸­çš„é‡è¦ååº”æè¿°ç¬¦ï¼Œç”¨äºæœ‰æ•ˆç­›é€‰æœ€ä½³å‚¬åŒ–å‰‚ã€‚ç„¶è€Œï¼Œç¡®å®šå¸é™„èƒ½é€šå¸¸éœ€è¦è¯„ä¼°è®¸å¤šå¸é™„è´¨-å‚¬åŒ–å‰‚é…ç½®ã€‚å½“å‰ç®—æ³•æ–¹æ³•ä¾èµ–äºå¸é™„ä½ç‚¹å’Œé…ç½®çš„è¯¦å°½åˆ—ä¸¾ï¼Œè¿™ä½¿å¾—è¿‡ç¨‹è®¡ç®—å¯†é›†ï¼Œå¹¶ä¸ä¿è¯æ‰¾åˆ°å…¨å±€æœ€ä½èƒ½é‡ã€‚åœ¨æœ¬ç ”ç©¶ä¸­ï¼Œæˆ‘ä»¬å¼•å…¥äº†å¸é™„å‰‚ä»£ç†ï¼ˆAdsorb-Agentï¼‰ï¼Œè¿™æ˜¯ä¸€ä¸ªå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä»£ç†ï¼Œæ—¨åœ¨æœ‰æ•ˆè¯†åˆ«ä¸å…¨å±€æœ€ä½å¸é™„èƒ½å¯¹åº”çš„ç³»ç»Ÿç‰¹å®šç¨³å®šå¸é™„é…ç½®ã€‚å®ƒé€šè¿‡åˆ©ç”¨å†…ç½®çŸ¥è¯†å’Œæ–°å…´æ¨ç†èƒ½åŠ›æ¥ç­–ç•¥æ€§åœ°æ¢ç´¢å¯èƒ½åŒ…å«å¸é™„èƒ½çš„å¸é™„é…ç½®ï¼Œå‡å°‘äº†å¯¹è¯¦å°½é‡‡æ ·çš„ä¾èµ–ï¼Œåœ¨å‡å°‘æ‰€éœ€åˆå§‹é…ç½®æ•°é‡çš„åŒæ—¶æé«˜äº†å¸é™„èƒ½é¢„æµ‹çš„å‡†ç¡®æ€§ã€‚æˆ‘ä»¬å¯¹Adsorb-Agentçš„æ€§èƒ½åœ¨äºŒåä¸ªä»£è¡¨æ€§ç³»ç»Ÿä¸Šè¿›è¡Œè¯„ä¼°ï¼Œæ¶µç›–äº†ä¸€ç³»åˆ—å¤æ‚æ€§ã€‚Adsorb-AgentæˆåŠŸä¸º83.7%çš„ç³»ç»Ÿç¡®å®šäº†å¯æ¯”çš„å¸é™„èƒ½ï¼Œä¸º35%çš„ç³»ç»Ÿè¾¾åˆ°æ›´æ¥è¿‘å®é™…å…¨å±€æœ€å°å€¼çš„èƒ½é‡ï¼ŒåŒæ—¶æ¯”ä¼ ç»Ÿæ–¹æ³•éœ€è¦çš„åˆå§‹é…ç½®è¦å°‘å¾—å¤šã€‚å…¶åœ¨å¤æ‚ç³»ç»Ÿä¸­çš„èƒ½åŠ›ç‰¹åˆ«æ˜æ˜¾ï¼Œåœ¨æ¶‰åŠé‡‘å±é—´è¡¨é¢çš„ç³»ç»Ÿä¸­ä¸º46.7%çš„ç³»ç»Ÿä»¥åŠå…·æœ‰å¤§å¸é™„è´¨åˆ†å­çš„ç³»ç»Ÿä¸­ä¸º66.7%çš„ç³»ç»Ÿç¡®å®šäº†è¾ƒä½çš„å¸é™„èƒ½ã€‚è¿™äº›ç»“æœè¯æ˜äº†Adsorb-Agentåœ¨åŠ é€Ÿå‚¬åŒ–å‰‚å‘ç°æ–¹é¢çš„æ½œåŠ›ï¼Œå¯é™ä½è®¡ç®—æˆæœ¬å¹¶æé«˜å¸é™„èƒ½é¢„æµ‹çš„å¯é æ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¸é™„èƒ½æ˜¯å‚¬åŒ–ä¸­é‡è¦çš„ååº”æè¿°ç¬¦ï¼Œå¯¹äºç­›é€‰æœ€ä½³å‚¬åŒ–å‰‚è‡³å…³é‡è¦ã€‚</li>
<li>å½“å‰ç®—æ³•åœ¨ç¡®å®šå¸é™„èƒ½æ—¶ä¾èµ–è¯¦å°½çš„å¸é™„ä½ç‚¹å’Œé…ç½®åˆ—ä¸¾ï¼Œè®¡ç®—å¯†é›†ä¸”ä¸ä¸€å®šæ‰¾åˆ°å…¨å±€æœ€ä½èƒ½é‡ã€‚</li>
<li>Adsorb-Agentæ˜¯ä¸€ä¸ªå¤§å‹è¯­è¨€æ¨¡å‹ä»£ç†ï¼Œå¯é«˜æ•ˆè¯†åˆ«ç³»ç»Ÿç‰¹å®šçš„ç¨³å®šå¸é™„é…ç½®å’Œå…¨å±€æœ€ä½å¸é™„èƒ½ã€‚</li>
<li>Adsorb-Agentåˆ©ç”¨å†…ç½®çŸ¥è¯†å’Œæ–°å…´æ¨ç†èƒ½åŠ›æ¥ç­–ç•¥æ€§æ¢ç´¢å¸é™„é…ç½®ã€‚</li>
<li>è¯¥ä»£ç†å‡å°‘äº†å¯¹è¯¦å°½é‡‡æ ·çš„ä¾èµ–ï¼Œæé«˜äº†é¢„æµ‹å¸é™„èƒ½çš„å‡†ç¡®æ€§å’Œæ•ˆç‡ã€‚</li>
<li>åœ¨å¤šä¸ªä»£è¡¨æ€§ç³»ç»Ÿä¸Šè¯„ä¼°ï¼ŒAdsorb-Agentåœ¨å¤æ‚ç³»ç»Ÿä¸­è¡¨ç°ç‰¹åˆ«å‡ºè‰²ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2410.16658">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-3e0b279adcebf07254a23f8c5be9f8c9.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-9284e878eb4d416f5a7a9dd166185b3e.jpg" align="middle">
</details>


<h1 id="-9"><a href="#-9" class="headerlink" title=""></a></h1><h2 id="Can-We-Trust-Embodied-Agents-Exploring-Backdoor-Attacks-against-Embodied-LLM-based-Decision-Making-Systems"><a href="#Can-We-Trust-Embodied-Agents-Exploring-Backdoor-Attacks-against-Embodied-LLM-based-Decision-Making-Systems" class="headerlink" title="Can We Trust Embodied Agents? Exploring Backdoor Attacks against   Embodied LLM-based Decision-Making Systems"></a>Can We Trust Embodied Agents? Exploring Backdoor Attacks against   Embodied LLM-based Decision-Making Systems</h2><p><strong>Authors:Ruochen Jiao, Shaoyuan Xie, Justin Yue, Takami Sato, Lixu Wang, Yixuan Wang, Qi Alfred Chen, Qi Zhu</strong></p>
<p>Large Language Models (LLMs) have shown significant promise in real-world decision-making tasks for embodied artificial intelligence, especially when fine-tuned to leverage their inherent common sense and reasoning abilities while being tailored to specific applications. However, this fine-tuning process introduces considerable safety and security vulnerabilities, especially in safety-critical cyber-physical systems. In this work, we propose the first comprehensive framework for Backdoor Attacks against LLM-based Decision-making systems (BALD) in embodied AI, systematically exploring the attack surfaces and trigger mechanisms. Specifically, we propose three distinct attack mechanisms: word injection, scenario manipulation, and knowledge injection, targeting various components in the LLM-based decision-making pipeline. We perform extensive experiments on representative LLMs (GPT-3.5, LLaMA2, PaLM2) in autonomous driving and home robot tasks, demonstrating the effectiveness and stealthiness of our backdoor triggers across various attack channels, with cases like vehicles accelerating toward obstacles and robots placing knives on beds. Our word and knowledge injection attacks achieve nearly 100% success rate across multiple models and datasets while requiring only limited access to the system. Our scenario manipulation attack yields success rates exceeding 65%, reaching up to 90%, and does not require any runtime system intrusion. We also assess the robustness of these attacks against defenses, revealing their resilience. Our findings highlight critical security vulnerabilities in embodied LLM systems and emphasize the urgent need for safeguarding these systems to mitigate potential risks. </p>
<blockquote>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨å®ä½“äººå·¥æ™ºèƒ½çš„ç°å®å†³ç­–ä»»åŠ¡ä¸­æ˜¾ç¤ºå‡ºå·¨å¤§çš„æ½œåŠ›ï¼Œå°¤å…¶æ˜¯åœ¨å¾®è°ƒä»¥åˆ©ç”¨å…¶å›ºæœ‰çš„å¸¸è¯†å’Œæ¨ç†èƒ½åŠ›çš„åŒæ—¶ï¼Œé’ˆå¯¹ç‰¹å®šåº”ç”¨è¿›è¡Œå®šåˆ¶æ—¶ã€‚ç„¶è€Œï¼Œè¿™ç§å¾®è°ƒè¿‡ç¨‹å¼•å…¥äº†ç›¸å½“å¤§çš„å®‰å…¨å’Œæ¼æ´éšæ‚£ï¼Œç‰¹åˆ«æ˜¯åœ¨å®‰å…¨å…³é”®çš„ç½‘ç‰©ç³»ç»Ÿã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†é’ˆå¯¹åŸºäºLLMçš„å†³ç­–ç³»ç»Ÿï¼ˆBALDï¼‰çš„ç¬¬ä¸€ä¸ªå…¨é¢çš„æ¡†æ¶ï¼Œç³»ç»Ÿåœ°æ¢ç´¢æ”»å‡»é¢å’Œè§¦å‘æœºåˆ¶ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸‰ç§ç‹¬ç‰¹çš„æ”»å‡»æœºåˆ¶ï¼šå•è¯æ³¨å…¥ã€åœºæ™¯æ“æ§å’ŒçŸ¥è¯†æ³¨å…¥ï¼Œé’ˆå¯¹åŸºäºLLMçš„å†³ç­–ç®¡é“çš„ä¸åŒç»„ä»¶ã€‚æˆ‘ä»¬å¯¹å…·æœ‰ä»£è¡¨æ€§çš„LLMï¼ˆGPT-3.5ã€LLaMA2ã€PaLM2ï¼‰åœ¨è‡ªåŠ¨é©¾é©¶å’Œå®¶åº­æœºå™¨äººä»»åŠ¡ä¸Šè¿›è¡Œäº†å¹¿æ³›çš„å®éªŒï¼Œè¯æ˜äº†æˆ‘ä»¬çš„åé—¨è§¦å‘åœ¨é€šè¿‡å„ç§æ”»å‡»æ¸ é“æ—¶çš„æœ‰æ•ˆæ€§å’Œéšè”½æ€§ï¼ŒåŒ…æ‹¬è½¦è¾†åŠ é€Ÿå†²å‘éšœç¢å’Œæœºå™¨äººåœ¨åºŠä¸Šæ”¾ç½®åˆ€å…·ç­‰æ¡ˆä¾‹ã€‚æˆ‘ä»¬çš„å•è¯å’ŒçŸ¥è¯†æ³¨å…¥æ”»å‡»åœ¨å¤šä¸ªæ¨¡å‹å’Œæ•°æ®é›†ä¸ŠæˆåŠŸç‡æ¥è¿‘100%ï¼Œè€Œä¸”åªéœ€è¦å¯¹ç³»ç»Ÿæœ‰é™çš„è®¿é—®æƒé™ã€‚æˆ‘ä»¬çš„åœºæ™¯æ“æ§æ”»å‡»æˆåŠŸç‡è¶…è¿‡65%ï¼Œæœ€é«˜å¯è¾¾90%ï¼Œè€Œä¸”ä¸éœ€è¦ä»»ä½•è¿è¡Œæ—¶ç³»ç»Ÿå…¥ä¾µã€‚æˆ‘ä»¬è¿˜å¯¹æ”»å‡»è¿›è¡Œäº†é˜²å¾¡è¯„ä¼°ï¼Œæ­ç¤ºäº†å®ƒä»¬çš„éŸ§æ€§ã€‚æˆ‘ä»¬çš„ç ”ç©¶å‘ç°äº†å®ä½“LLMç³»ç»Ÿä¸­å…³é”®çš„å®‰å…¨æ¼æ´ï¼Œå¹¶å¼ºè°ƒäº†ä¿æŠ¤è¿™äº›ç³»ç»Ÿä»¥å‡è½»æ½œåœ¨é£é™©çš„ç´§è¿«éœ€æ±‚ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2405.20774v3">PDF</a> Accepted paper at ICLR 2025, 31 pages, including main paper,   references, and appendix</p>
<p><strong>Summary</strong></p>
<p>å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å®ä½“äººå·¥æ™ºèƒ½çš„å†³ç­–ä»»åŠ¡ä¸­å±•ç°å‡ºå·¨å¤§æ½œåŠ›ï¼Œä½†ç²¾ç»†è°ƒæ•´è¿‡ç¨‹ä¼šå¼•å‘å®‰å…¨å’Œä¿éšœæ¼æ´ï¼Œç‰¹åˆ«æ˜¯åœ¨å®‰å…¨å…³é”®çš„ç½‘è·¯ç‰©ç†ç³»ç»Ÿä¸­ã€‚æœ¬ç ”ç©¶é¦–æ¬¡æå‡ºé’ˆå¯¹åŸºäºLLMçš„å†³ç­–ç³»ç»Ÿçš„åé—¨æ”»å‡»ï¼ˆBALDï¼‰çš„å…¨é¢æ¡†æ¶ï¼Œé’ˆå¯¹LLMå†³ç­–ç®¡é“çš„ä¸åŒç»„ä»¶ï¼Œæå‡ºä¸‰ç§ç‹¬ç‰¹çš„æ”»å‡»æœºåˆ¶ï¼šå•è¯æ³¨å…¥ã€åœºæ™¯æ“æ§å’ŒçŸ¥è¯†æ³¨å…¥ã€‚æˆ‘ä»¬åœ¨è‡ªåŠ¨é©¾é©¶å’Œå®¶åº­æœºå™¨äººä»»åŠ¡ä¸­å¯¹ä»£è¡¨æ€§LLMï¼ˆGPT-3.5ã€LLaMA2ã€PaLM2ï¼‰è¿›è¡Œäº†å¹¿æ³›å®éªŒï¼Œè¯æ˜äº†æˆ‘ä»¬çš„åé—¨è§¦å‘æœºåˆ¶åœ¨å„ç§æ”»å‡»é€šé“ä¸­çš„æœ‰æ•ˆæ€§å’Œéšè”½æ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨å®ä½“äººå·¥æ™ºèƒ½çš„å†³ç­–ä»»åŠ¡ä¸­å…·æœ‰æ˜¾è‘—æ½œåŠ›ï¼Œä½†ç²¾ç»†è°ƒæ•´è¿‡ç¨‹å¼•å‘å®‰å…¨å’Œä¿éšœæ¼æ´ã€‚</li>
<li>é¦–æ¬¡æå‡ºé’ˆå¯¹LLMå†³ç­–ç³»ç»Ÿçš„åé—¨æ”»å‡»ï¼ˆBALMï¼‰çš„å…¨é¢æ¡†æ¶ã€‚</li>
<li>æå‡ºä¸‰ç§æ”»å‡»æœºåˆ¶ï¼šå•è¯æ³¨å…¥ã€åœºæ™¯æ“æ§å’ŒçŸ¥è¯†æ³¨å…¥ï¼Œå¯é’ˆå¯¹LLMå†³ç­–ç®¡é“çš„ä¸åŒéƒ¨åˆ†ã€‚</li>
<li>å®éªŒè¯æ˜ï¼Œåœ¨è‡ªåŠ¨é©¾é©¶å’Œå®¶åº­æœºå™¨äººä»»åŠ¡ä¸­ï¼Œæ‰€ææ”»å‡»æ–¹æ³•å…·æœ‰é«˜æ•ˆæ€§å’Œéšè”½æ€§ã€‚</li>
<li>å•è¯æ³¨å…¥å’ŒçŸ¥è¯†æ³¨å…¥æ”»å‡»çš„æˆåŠŸç‡é«˜è¾¾è¿‘100%ï¼Œåœºæ™¯æ“æ§æ”»å‡»çš„æˆåŠŸç‡è¶…è¿‡65%ï¼Œç”šè‡³è¾¾åˆ°90%ã€‚</li>
<li>è¿™äº›æ”»å‡»å¯¹ç³»ç»Ÿçš„é˜²å¾¡å…·æœ‰æŠ—æ€§ï¼Œæ˜¾ç¤ºå‡ºå…¶ç¨³å¥æ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2405.20774">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-842f7f6aa0552215c096a1f303f44a48.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-90fa48e7117e3fdefa8db34cae8b585d.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-6941e439ba12306cd7de2a0c04ed4485.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-99347939275fb9711341c0808ccb9940.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-5d49293eb3303e13511d4fa6d50668b6.jpg" align="middle">
</details>


<h1 id="-10"><a href="#-10" class="headerlink" title=""></a></h1><h2 id="Variational-Offline-Multi-agent-Skill-Discovery"><a href="#Variational-Offline-Multi-agent-Skill-Discovery" class="headerlink" title="Variational Offline Multi-agent Skill Discovery"></a>Variational Offline Multi-agent Skill Discovery</h2><p><strong>Authors:Jiayu Chen, Tian Lan, Vaneet Aggarwal</strong></p>
<p>Skills are effective temporal abstractions established for sequential decision making, which enable efficient hierarchical learning for long-horizon tasks and facilitate multi-task learning through their transferability. Despite extensive research, research gaps remain in multi-agent scenarios, particularly for automatically extracting subgroup coordination patterns in a multi-agent task. In this case, we propose two novel auto-encoder schemes: VO-MASD-3D and VO-MASD-Hier, to simultaneously capture subgroup- and temporal-level abstractions and form multi-agent skills, which firstly solves the aforementioned challenge. An essential algorithm component of these schemes is a dynamic grouping function that can automatically detect latent subgroups based on agent interactions in a task. Further, our method can be applied to offline multi-task data, and the discovered subgroup skills can be transferred across relevant tasks without retraining. Empirical evaluations on StarCraft tasks indicate that our approach significantly outperforms existing hierarchical multi-agent reinforcement learning (MARL) methods. Moreover, skills discovered using our method can effectively reduce the learning difficulty in MARL scenarios with delayed and sparse reward signals. The codebase is available at <a target="_blank" rel="noopener" href="https://github.com/LucasCJYSDL/VOMASD">https://github.com/LucasCJYSDL/VOMASD</a>. </p>
<blockquote>
<p>æŠ€èƒ½æ˜¯ä¸ºé¡ºåºå†³ç­–è€Œå»ºç«‹çš„æœ‰æ•ˆæ—¶é—´æŠ½è±¡ï¼Œå®ƒä»¬ä¸ºé•¿æœŸä»»åŠ¡æä¾›äº†é«˜æ•ˆçš„å±‚æ¬¡åŒ–å­¦ä¹ ï¼Œå¹¶é€šè¿‡å…¶å¯è½¬ç§»æ€§ä¿ƒè¿›äº†å¤šä»»åŠ¡å­¦ä¹ ã€‚å°½ç®¡å·²æœ‰å¤§é‡ç ”ç©¶ï¼Œä½†åœ¨å¤šæ™ºèƒ½ä½“åœºæ™¯ä¸­ä»å­˜åœ¨ç ”ç©¶ç©ºç™½ï¼Œç‰¹åˆ«æ˜¯åœ¨å¤šæ™ºèƒ½ä½“ä»»åŠ¡ä¸­è‡ªåŠ¨æå–å­ç»„åè°ƒæ¨¡å¼æ–¹é¢ã€‚é’ˆå¯¹è¿™ç§æƒ…å†µï¼Œæˆ‘ä»¬æå‡ºäº†ä¸¤ç§æ–°å‹è‡ªåŠ¨ç¼–ç å™¨æ–¹æ¡ˆï¼šVO-MASD-3Då’ŒVO-MASD-Hierï¼Œå®ƒä»¬å¯ä»¥åŒæ—¶æ•è·å­ç»„å’Œæ—¶é—´å±‚é¢çš„æŠ½è±¡ï¼Œå½¢æˆå¤šæ™ºèƒ½ä½“æŠ€èƒ½ï¼Œé¦–å…ˆè§£å†³äº†ä¸Šè¿°æŒ‘æˆ˜ã€‚è¿™äº›æ–¹æ¡ˆçš„ä¸€ä¸ªåŸºæœ¬ç®—æ³•ç»„ä»¶æ˜¯ä¸€ä¸ªåŠ¨æ€åˆ†ç»„å‡½æ•°ï¼Œè¯¥å‡½æ•°å¯ä»¥åŸºäºä»»åŠ¡ä¸­çš„æ™ºèƒ½ä½“äº¤äº’è‡ªåŠ¨æ£€æµ‹æ½œåœ¨å­ç»„ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬çš„æ–¹æ³•å¯ä»¥åº”ç”¨äºç¦»çº¿å¤šä»»åŠ¡æ•°æ®ï¼Œå¹¶ä¸”å‘ç°çš„å­ç»„æŠ€èƒ½å¯ä»¥åœ¨ç›¸å…³ä»»åŠ¡ä¹‹é—´è½¬ç§»è€Œæ— éœ€é‡æ–°è®­ç»ƒã€‚åœ¨æ˜Ÿé™…äº‰éœ¸ä»»åŠ¡ä¸Šçš„ç»éªŒè¯„ä¼°è¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•æ˜¾è‘—ä¼˜äºç°æœ‰çš„åˆ†å±‚å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ ï¼ˆMARLï¼‰æ–¹æ³•ã€‚æ­¤å¤–ï¼Œä½¿ç”¨æˆ‘ä»¬çš„æ–¹æ³•å‘ç°çš„æŠ€èƒ½å¯ä»¥æœ‰æ•ˆåœ°é™ä½å…·æœ‰å»¶è¿Ÿå’Œç¨€ç–å¥–åŠ±ä¿¡å·çš„å¤šæ™ºèƒ½ä½“åœºæ™¯ä¸­çš„å­¦ä¹ éš¾åº¦ã€‚ä»£ç åº“ä½äº<a target="_blank" rel="noopener" href="https://github.com/LucasCJYSDL/VOMASD%E3%80%82">https://github.com/LucasCJYSDL/VOMASDã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2405.16386v3">PDF</a> This work will appear in the proceedings of IJCAI 2025</p>
<p><strong>Summary</strong><br>æŠ€èƒ½æ˜¯æœ‰æ•ˆçš„æ—¶åºæŠ½è±¡ï¼Œç”¨äºåºåˆ—å†³ç­–åˆ¶å®šï¼Œèƒ½å¤Ÿå®ç°é•¿å‘¨æœŸä»»åŠ¡çš„é«˜æ•ˆå±‚æ¬¡å­¦ä¹ ï¼Œå¹¶é€šè¿‡å…¶å¯è½¬ç§»æ€§ä¿ƒè¿›å¤šä»»åŠ¡å­¦ä¹ ã€‚ç„¶è€Œï¼Œåœ¨å¤šæ™ºèƒ½ä½“åœºæ™¯ä¸­ï¼Œè‡ªåŠ¨æå–æ™ºèƒ½ä½“åè°ƒæ¨¡å¼çš„ç ”ç©¶è¿˜å­˜åœ¨ç¼ºå£ã€‚é’ˆå¯¹æ­¤é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸¤ç§æ–°å‹è‡ªåŠ¨ç¼–ç å™¨æ–¹æ¡ˆï¼šVO-MASD-3Då’ŒVO-MASD-Hierï¼Œå®ƒä»¬å¯ä»¥åŒæ—¶æ•è·å­ç¾¤ä½“å’Œæ—¶åºå±‚é¢çš„æŠ½è±¡ä¿¡æ¯ï¼Œå½¢æˆå¤šæ™ºèƒ½ä½“æŠ€èƒ½ã€‚å…³é”®ç®—æ³•ç»„ä»¶æ˜¯åŠ¨æ€åˆ†ç»„åŠŸèƒ½ï¼Œå¯ä»¥åŸºäºä»»åŠ¡ä¸­æ™ºèƒ½ä½“çš„äº¤äº’è‡ªåŠ¨æ£€æµ‹æ½œåœ¨å­ç¾¤ä½“ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬çš„æ–¹æ³•å¯åº”ç”¨äºç¦»çº¿å¤šä»»åŠ¡æ•°æ®ï¼Œå‘ç°çš„å­ç¾¤ä½“æŠ€èƒ½å¯ä»¥åœ¨ç›¸å…³ä»»åŠ¡ä¹‹é—´è½¬ç§»è€Œæ— éœ€é‡æ–°è®­ç»ƒã€‚åœ¨æ˜Ÿé™…äº‰éœ¸ä»»åŠ¡ä¸Šçš„å®è¯è¯„ä¼°è¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•æ˜¾è‘—ä¼˜äºç°æœ‰çš„åˆ†å±‚å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ ï¼ˆMARLï¼‰æ–¹æ³•ã€‚æ­¤å¤–ï¼Œä½¿ç”¨æˆ‘ä»¬çš„æ–¹æ³•å‘ç°çš„æŠ€èƒ½å¯ä»¥æœ‰æ•ˆåœ°é™ä½MARLåœºæ™¯ä¸­å»¶è¿Ÿå’Œç¨€ç–å¥–åŠ±ä¿¡å·çš„å­¦ä¹ éš¾åº¦ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æŠ€èƒ½æ˜¯æ—¶åºæŠ½è±¡ï¼Œç”¨äºåºåˆ—å†³ç­–åˆ¶å®šï¼Œä¿ƒè¿›é•¿å‘¨æœŸä»»åŠ¡çš„é«˜æ•ˆå±‚æ¬¡å­¦ä¹ ã€‚</li>
<li>åœ¨å¤šæ™ºèƒ½ä½“åœºæ™¯ä¸­ï¼Œè‡ªåŠ¨æå–æ™ºèƒ½ä½“åè°ƒæ¨¡å¼çš„ç ”ç©¶å­˜åœ¨ç¼ºå£ã€‚</li>
<li>æå‡ºäº†VO-MASD-3Då’ŒVO-MASD-Hierä¸¤ç§æ–°å‹è‡ªåŠ¨ç¼–ç å™¨æ–¹æ¡ˆï¼Œè§£å†³è‡ªåŠ¨æå–æ™ºèƒ½ä½“åè°ƒæ¨¡å¼çš„é—®é¢˜ã€‚</li>
<li>åŠ¨æ€åˆ†ç»„åŠŸèƒ½å¯è‡ªåŠ¨æ£€æµ‹æ½œåœ¨å­ç¾¤ä½“ï¼ŒåŸºäºä»»åŠ¡ä¸­æ™ºèƒ½ä½“çš„äº¤äº’ã€‚</li>
<li>æ–¹æ³•å¯åº”ç”¨äºç¦»çº¿å¤šä»»åŠ¡æ•°æ®ï¼Œå¹¶å¯å®ç°å­ç¾¤ä½“æŠ€èƒ½åœ¨ä¸åŒä»»åŠ¡é—´çš„è½¬ç§»ã€‚</li>
<li>åœ¨æ˜Ÿé™…äº‰éœ¸ä»»åŠ¡ä¸Šçš„å®è¯è¯„ä¼°æ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•ä¼˜äºç°æœ‰åˆ†å±‚å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ æ–¹æ³•ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2405.16386">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-b0a8be7e31993a4239e674834d5250d1.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-2ba1d4949c66ed769530ca4cffbfe470.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-99706e16fc96cf352c4a0d40b7a101d7.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-f374dd307f94b1dafe02e846899e0c5a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-845db53a71fc9b124551218313b4d8d8.jpg" align="middle">
</details>


<h1 id="-11"><a href="#-11" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-05-02/Agent/">https://kedreamix.github.io/Talk2Paper/Paper/2025-05-02/Agent/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/Agent/">
                                    <span class="chip bg-color">Agent</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-05-02/Few-Shot/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-5ace09a772af15c1e1590e4016d55c8c.jpg" class="responsive-img" alt="Few-Shot">
                        
                        <span class="card-title">Few-Shot</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Few-Shot æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-05-02  DNB-AI-Project at SemEval-2025 Task 5 An LLM-Ensemble Approach for   Automated Subject Indexing
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-05-02
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Few-Shot/" class="post-category">
                                    Few-Shot
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Few-Shot/">
                        <span class="chip bg-color">Few-Shot</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-05-02/LLM/">
                    <div class="card-image">
                        
                        <img src="https://pic1.zhimg.com/v2-3e0b279adcebf07254a23f8c5be9f8c9.jpg" class="responsive-img" alt="LLM">
                        
                        <span class="card-title">LLM</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            LLM æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-05-02  COMPACT COMPositional Atomic-to-Complex Visual Capability Tuning
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-05-02
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/LLM/" class="post-category">
                                    LLM
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/LLM/">
                        <span class="chip bg-color">LLM</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">32714.1k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
