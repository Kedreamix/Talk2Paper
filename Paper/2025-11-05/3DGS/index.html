<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="3DGS">
    <meta name="description" content="3DGS æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-11-05  SAGS Self-Adaptive Alias-Free Gaussian Splatting for Dynamic Surgical   Endoscopic Reconstruction">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>3DGS | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://pic-private.zhihu.com/v2-58c899a334cf40efffae65498ea1a5d8~resize:0:q75.jpg?source=1f5c5e47&expiration=1762311074&auth_key=1762311074-0-0-c72cd7854fb18504e27e04d25c489246&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">3DGS</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/3DGS/">
                                <span class="chip bg-color">3DGS</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/3DGS/" class="post-category">
                                3DGS
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-11-05
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-11-06
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    18.9k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    77 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-11-05-æ›´æ–°"><a href="#2025-11-05-æ›´æ–°" class="headerlink" title="2025-11-05 æ›´æ–°"></a>2025-11-05 æ›´æ–°</h1><h2 id="SAGS-Self-Adaptive-Alias-Free-Gaussian-Splatting-for-Dynamic-Surgical-Endoscopic-Reconstruction"><a href="#SAGS-Self-Adaptive-Alias-Free-Gaussian-Splatting-for-Dynamic-Surgical-Endoscopic-Reconstruction" class="headerlink" title="SAGS: Self-Adaptive Alias-Free Gaussian Splatting for Dynamic Surgical   Endoscopic Reconstruction"></a>SAGS: Self-Adaptive Alias-Free Gaussian Splatting for Dynamic Surgical   Endoscopic Reconstruction</h2><p><strong>Authors:Wenfeng Huang, Xiangyun Liao, Yinling Qian, Hao Liu, Yongming Yang, Wenjing Jia, Qiong Wang</strong></p>
<p>Surgical reconstruction of dynamic tissues from endoscopic videos is a crucial technology in robot-assisted surgery. The development of Neural Radiance Fields (NeRFs) has greatly advanced deformable tissue reconstruction, achieving high-quality results from video and image sequences. However, reconstructing deformable endoscopic scenes remains challenging due to aliasing and artifacts caused by tissue movement, which can significantly degrade visualization quality. The introduction of 3D Gaussian Splatting (3DGS) has improved reconstruction efficiency by enabling a faster rendering pipeline. Nevertheless, existing 3DGS methods often prioritize rendering speed while neglecting these critical issues. To address these challenges, we propose SAGS, a self-adaptive alias-free Gaussian splatting framework. We introduce an attention-driven, dynamically weighted 4D deformation decoder, leveraging 3D smoothing filters and 2D Mip filters to mitigate artifacts in deformable tissue reconstruction and better capture the fine details of tissue movement. Experimental results on two public benchmarks, EndoNeRF and SCARED, demonstrate that our method achieves superior performance in all metrics of PSNR, SSIM, and LPIPS compared to the state of the art while also delivering better visualization quality. </p>
<blockquote>
<p>æ‰‹æœ¯å†…çª¥é•œè§†é¢‘ä¸­çš„åŠ¨æ€ç»„ç»‡é‡å»ºæ˜¯æœºå™¨äººè¾…åŠ©æ‰‹æœ¯ä¸­çš„ä¸€é¡¹å…³é”®æŠ€æœ¯ã€‚ç¥ç»è¾å°„åœºï¼ˆNeRFsï¼‰çš„å‘å±•æå¤§åœ°æ¨åŠ¨äº†å˜å½¢ç»„ç»‡é‡å»ºçš„è¿›æ­¥ï¼Œèƒ½å¤Ÿä»è§†é¢‘å’Œå›¾åƒåºåˆ—ä¸­è·å¾—é«˜è´¨é‡çš„ç»“æœã€‚ç„¶è€Œï¼Œç”±äºç»„ç»‡è¿åŠ¨å¯¼è‡´çš„æ··å å’Œä¼ªå½±ï¼Œé‡å»ºå¯å˜å½¢å†…çª¥é•œåœºæ™¯ä»ç„¶å…·æœ‰æŒ‘æˆ˜æ€§ï¼Œè¿™å¯èƒ½ä¼šæ˜¾è‘—é™ä½å¯è§†åŒ–è´¨é‡ã€‚ä¸‰ç»´é«˜æ–¯å¹³é“ºï¼ˆ3DGSï¼‰çš„å¼•å…¥æé«˜äº†é‡å»ºæ•ˆç‡ï¼Œé€šè¿‡å®ç°æ›´å¿«çš„æ¸²æŸ“æµç¨‹ã€‚ç„¶è€Œï¼Œç°æœ‰çš„ä¸‰ç»´é«˜æ–¯å¹³é“ºæ–¹æ³•å¾€å¾€ä¼˜å…ˆè¿½æ±‚æ¸²æŸ“é€Ÿåº¦è€Œå¿½è§†è¿™äº›å…³é”®é—®é¢˜ã€‚ä¸ºäº†è§£å†³è¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†SAGSï¼Œä¸€ç§è‡ªé€‚åº”æ— æ··å é«˜æ–¯å¹³é“ºæ¡†æ¶ã€‚æˆ‘ä»¬å¼•å…¥äº†ä¸€ç§æ³¨æ„åŠ›é©±åŠ¨ã€åŠ¨æ€åŠ æƒçš„å››ç»´å˜å½¢è§£ç å™¨ï¼Œåˆ©ç”¨ä¸‰ç»´å¹³æ»‘æ»¤æ³¢å™¨å’ŒäºŒç»´Mipæ»¤æ³¢å™¨æ¥å‡å°‘å¯å˜å½¢ç»„ç»‡é‡å»ºä¸­çš„ä¼ªå½±ï¼Œå¹¶æ›´å¥½åœ°æ•æ‰ç»„ç»‡è¿åŠ¨çš„ç»†èŠ‚ã€‚åœ¨EndoNeRFå’ŒSCAREDä¸¤ä¸ªå…¬å¼€åŸºå‡†æµ‹è¯•ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨å³°å€¼ä¿¡å™ªæ¯”ï¼ˆPSNRï¼‰ã€ç»“æ„ç›¸ä¼¼æ€§ï¼ˆSSIMï¼‰å’Œå±€éƒ¨æ„ŸçŸ¥å›¾åƒç›¸ä¼¼æ€§ï¼ˆLPIPSï¼‰ç­‰æ‰€æœ‰æŒ‡æ ‡ä¸Šå‡è¾¾åˆ°äº†é¢†å…ˆæ°´å¹³ï¼ŒåŒæ—¶æä¾›äº†æ›´å¥½çš„å¯è§†åŒ–è´¨é‡ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.27318v1">PDF</a> </p>
<p><strong>Summary</strong><br>     åŸºäºå†…é•œè§†é¢‘çš„åŠ¨æ€ç»„ç»‡é‡å»ºæ˜¯æœºå™¨äººè¾…åŠ©æ‰‹æœ¯ä¸­çš„é‡è¦æŠ€æœ¯ã€‚ç¥ç»è¾å°„åœºï¼ˆNeRFsï¼‰çš„å‘å±•æå¤§åœ°æ¨åŠ¨äº†å˜å½¢ç»„ç»‡é‡å»ºçš„è¿›æ­¥ï¼Œä»è§†é¢‘å’Œå›¾åƒåºåˆ—ä¸­è·å¾—äº†é«˜è´¨é‡çš„ç»“æœã€‚ç„¶è€Œï¼Œç”±äºç»„ç»‡è¿åŠ¨å¯¼è‡´çš„æ··å å’Œä¼ªå½±ï¼Œå¯å˜å½¢å†…çª¥é•œåœºæ™¯çš„é‡å»ºä»ç„¶å…·æœ‰æŒ‘æˆ˜æ€§ï¼Œè¿™å¯èƒ½ä¼šæ˜¾è‘—é™ä½å¯è§†åŒ–è´¨é‡ã€‚3Dé«˜æ–¯å–·æ´’ï¼ˆ3DGSï¼‰çš„å¼•å…¥æé«˜äº†é‡å»ºæ•ˆç‡ï¼Œå®ç°äº†æ›´å¿«çš„æ¸²æŸ“æµç¨‹ã€‚ç„¶è€Œï¼Œç°æœ‰çš„3DGSæ–¹æ³•å¾€å¾€ä¾§é‡äºæ¸²æŸ“é€Ÿåº¦ï¼Œè€Œå¿½è§†äº†è¿™äº›å…³é”®é—®é¢˜ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬æå‡ºäº†SAGSï¼Œä¸€ç§è‡ªé€‚åº”çš„æ— æ··å é«˜æ–¯å–·æ´’æ¡†æ¶ã€‚æˆ‘ä»¬å¼•å…¥äº†ä¸€ç§åŸºäºæ³¨æ„åŠ›çš„ã€åŠ¨æ€åŠ æƒçš„4Då˜å½¢è§£ç å™¨ï¼Œåˆ©ç”¨3Då¹³æ»‘æ»¤æ³¢å™¨å’Œ2DMipæ»¤æ³¢å™¨æ¥ç¼“è§£å˜å½¢ç»„ç»‡é‡å»ºä¸­çš„ä¼ªå½±ï¼Œæ›´å¥½åœ°æ•æ‰ç»„ç»‡è¿åŠ¨çš„ç»†èŠ‚ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨å…¬å…±åŸºå‡†æµ‹è¯•EndoNeRFå’ŒSCAREDä¸Šçš„æ€§èƒ½ä¼˜äºå…¶ä»–æœ€æ–°æŠ€æœ¯ï¼Œå¹¶åœ¨PSNRã€SSIMå’ŒLPIPSç­‰æŒ‡æ ‡ä¸Šå‡è¡¨ç°ä¼˜è¶Šï¼ŒåŒæ—¶æä¾›äº†æ›´å¥½çš„å¯è§†åŒ–è´¨é‡ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ç¥ç»è¾å°„åœºï¼ˆNeRFï¼‰æŠ€æœ¯å·²ç”¨äºä»è§†é¢‘å’Œå›¾åƒåºåˆ—é‡å»ºå˜å½¢ç»„ç»‡ï¼Œå¹¶å–å¾—é«˜è´¨é‡ç»“æœã€‚</li>
<li>å¯å˜å½¢å†…çª¥é•œåœºæ™¯çš„é‡å»ºé¢ä¸´ç»„ç»‡è¿åŠ¨å¯¼è‡´çš„æ··å å’Œä¼ªå½±çš„æŒ‘æˆ˜ã€‚</li>
<li>3Dé«˜æ–¯å–·æ´’ï¼ˆ3DGSï¼‰æé«˜äº†é‡å»ºæ•ˆç‡ï¼Œä½†ç°æœ‰æ–¹æ³•å¿½è§†äº†æ··å å’Œä¼ªå½±é—®é¢˜ã€‚</li>
<li>æå‡ºçš„SAGSæ¡†æ¶åˆ©ç”¨åŠ¨æ€åŠ æƒçš„4Då˜å½¢è§£ç å™¨å’Œ3D&#x2F;2Dæ»¤æ³¢å™¨æ¥å‡å°‘ä¼ªå½±å¹¶æ•æ‰ç»„ç»‡è¿åŠ¨çš„ç»†èŠ‚ã€‚</li>
<li>SAGSåœ¨EndoNeRFå’ŒSCAREDåŸºå‡†æµ‹è¯•ä¸Šçš„æ€§èƒ½ä¼˜äºå…¶ä»–æœ€æ–°æŠ€æœ¯ã€‚</li>
<li>SAGSåœ¨PSNRã€SSIMå’ŒLPIPSç­‰æŒ‡æ ‡ä¸Šè¡¨ç°ä¼˜è¶Šã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.27318">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-7e32fc98ca9358266ec21e43526abbf8~resize:0:q75.jpg?source=1f5c5e47&expiration=1762311081&auth_key=1762311081-0-0-0500d441d3c8a607313edbe132f8ee53&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-33665b4c4d0d2048e168a6bdf6ad21bf~resize:0:q75.jpg?source=1f5c5e47&expiration=1762311089&auth_key=1762311089-0-0-8b797c2acf86ade3353c1320144668a3&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="WildfireX-SLAM-A-Large-scale-Low-altitude-RGB-D-Dataset-for-Wildfire-SLAM-and-Beyond"><a href="#WildfireX-SLAM-A-Large-scale-Low-altitude-RGB-D-Dataset-for-Wildfire-SLAM-and-Beyond" class="headerlink" title="WildfireX-SLAM: A Large-scale Low-altitude RGB-D Dataset for Wildfire   SLAM and Beyond"></a>WildfireX-SLAM: A Large-scale Low-altitude RGB-D Dataset for Wildfire   SLAM and Beyond</h2><p><strong>Authors:Zhicong Sun, Jacqueline Lo, Jinxing Hu</strong></p>
<p>3D Gaussian splatting (3DGS) and its subsequent variants have led to remarkable progress in simultaneous localization and mapping (SLAM). While most recent 3DGS-based SLAM works focus on small-scale indoor scenes, developing 3DGS-based SLAM methods for large-scale forest scenes holds great potential for many real-world applications, especially for wildfire emergency response and forest management. However, this line of research is impeded by the absence of a comprehensive and high-quality dataset, and collecting such a dataset over real-world scenes is costly and technically infeasible. To this end, we have built a large-scale, comprehensive, and high-quality synthetic dataset for SLAM in wildfire and forest environments. Leveraging the Unreal Engine 5 Electric Dreams Environment Sample Project, we developed a pipeline to easily collect aerial and ground views, including ground-truth camera poses and a range of additional data modalities from unmanned aerial vehicle. Our pipeline also provides flexible controls on environmental factors such as light, weather, and types and conditions of wildfire, supporting the need for various tasks covering forest mapping, wildfire emergency response, and beyond. The resulting pilot dataset, WildfireX-SLAM, contains 5.5k low-altitude RGB-D aerial images from a large-scale forest map with a total size of 16 km2. On top of WildfireX-SLAM, a thorough benchmark is also conducted, which not only reveals the unique challenges of 3DGS-based SLAM in the forest but also highlights potential improvements for future works. The dataset and code will be publicly available. Project page: <a target="_blank" rel="noopener" href="https://zhicongsun.github.io/wildfirexslam">https://zhicongsun.github.io/wildfirexslam</a>. </p>
<blockquote>
<p>åŸºäºä¸‰ç»´é«˜æ–¯å±•å¸ƒï¼ˆ3DGSï¼‰åŠå…¶åç»­å˜ç§çš„ç ”ç©¶åœ¨åŒæ—¶å®šä½ä¸åœ°å›¾æ„å»ºï¼ˆSLAMï¼‰é¢†åŸŸå–å¾—äº†æ˜¾è‘—è¿›å±•ã€‚è™½ç„¶æœ€è¿‘åŸºäº3DGSçš„SLAMå·¥ä½œä¸»è¦é›†ä¸­åœ¨å°è§„æ¨¡å®¤å†…åœºæ™¯ï¼Œä½†ä¸ºå¤§è§„æ¨¡æ£®æ—åœºæ™¯å¼€å‘åŸºäº3DGSçš„SLAMæ–¹æ³•åœ¨è®¸å¤šçœŸå®ä¸–ç•Œåº”ç”¨ä¸­å…·æœ‰å·¨å¤§æ½œåŠ›ï¼Œå°¤å…¶æ˜¯åœ¨é‡ç«åº”æ€¥å“åº”å’Œæ£®æ—ç®¡ç†é¢†åŸŸã€‚ç„¶è€Œï¼Œç”±äºç¼ºä¹å…¨é¢ä¸”é«˜è´¨é‡çš„æ•°æ®é›†ï¼Œè¿™ä¸€é¢†åŸŸçš„ç ”ç©¶å—åˆ°é˜»ç¢ï¼Œè€Œåœ¨çœŸå®åœºæ™¯æ”¶é›†æ­¤ç±»æ•°æ®é›†æˆæœ¬é«˜æ˜‚ä¸”æŠ€æœ¯ä¸Šä¸å¯è¡Œã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬å»ºç«‹äº†ä¸€ä¸ªç”¨äºé‡ç«å’Œæ£®æ—ç¯å¢ƒä¸­SLAMçš„å¤§å‹ã€å…¨é¢ã€é«˜è´¨é‡åˆæˆæ•°æ®é›†ã€‚æˆ‘ä»¬åˆ©ç”¨Unreal Engine 5 Electric Dreams Environment Sample Projectï¼Œå¼€å‘äº†ä¸€æ¡ç®¡é“ï¼Œå¯è½»æ¾æ”¶é›†ç©ºä¸­å’Œåœ°é¢è§†å›¾ï¼ŒåŒ…æ‹¬çœŸå®çš„ç›¸æœºå§¿æ€å’Œå„ç§é¢å¤–çš„æ•°æ®æ¨¡å¼ï¼Œæ¥æºäºæ— äººæœºã€‚æˆ‘ä»¬çš„ç®¡é“è¿˜æä¾›ç¯å¢ƒå› ç´ çš„çµæ´»æ§åˆ¶ï¼Œä¾‹å¦‚å…‰çº¿ã€å¤©æ°”ã€ä»¥åŠé‡ç«çš„ç±»å‹å’ŒçŠ¶å†µï¼Œæ”¯æŒæ¶µç›–æ£®æ—åœ°å›¾ã€é‡ç«åº”æ€¥å“åº”ç­‰å„ç§ä»»åŠ¡çš„éœ€æ±‚ä»¥åŠå…¶ä»–æ›´å¤šé¢†åŸŸã€‚ç”±æ­¤äº§ç”Ÿçš„è¯•ç‚¹æ•°æ®é›†WildfireX-SLAMåŒ…å«æ¥è‡ªå¤§è§„æ¨¡æ£®æ—åœ°å›¾çš„5500å¼ ä½ç©ºRGB-Dèˆªç©ºå›¾åƒï¼Œæ€»é¢ç§¯ä¸º16å¹³æ–¹å…¬é‡Œã€‚åœ¨WildfireX-SLAMçš„åŸºç¡€ä¸Šï¼Œæˆ‘ä»¬è¿˜è¿›è¡Œäº†å…¨é¢çš„åŸºå‡†æµ‹è¯•ï¼Œè¿™ä¸ä»…æ­ç¤ºäº†æ£®æ—ç¯å¢ƒä¸­åŸºäº3DGSçš„SLAMæ‰€é¢ä¸´çš„ç‹¬ç‰¹æŒ‘æˆ˜ï¼Œè¿˜çªå‡ºäº†æœªæ¥å·¥ä½œçš„æ½œåœ¨æ”¹è¿›æ–¹å‘ã€‚æ•°æ®é›†å’Œä»£ç å°†å…¬å¼€å¯ç”¨ã€‚é¡¹ç›®é¡µé¢ï¼š<a target="_blank" rel="noopener" href="https://zhicongsun.github.io/wildfirexslam%E3%80%82">https://zhicongsun.github.io/wildfirexslamã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.27133v1">PDF</a> This paper has been accepted by MMM 2026</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†åŸºäº3Dé«˜æ–¯å–·æº…ï¼ˆ3DGSï¼‰çš„åŒæ­¥å®šä½ä¸åœ°å›¾æ„å»ºï¼ˆSLAMï¼‰æŠ€æœ¯åœ¨æ£®æ—åœºæ™¯ä¸­çš„ç ”ç©¶ä¸åº”ç”¨ã€‚æ–‡ç« æŒ‡å‡ºå½“å‰SLAMåœ¨å¤§è§„æ¨¡æ£®æ—åœºæ™¯ä¸­çš„æ½œåŠ›ä¸ç¼ºä¹é«˜è´¨é‡æ•°æ®é›†çš„é—®é¢˜ã€‚ä¸ºæ­¤ï¼Œåˆ©ç”¨Unreal Engine 5ç¯å¢ƒï¼Œæ„å»ºäº†ä¸€ä¸ªå¤§è§„æ¨¡ã€ç»¼åˆã€é«˜è´¨é‡é’ˆå¯¹æ£®æ—ç«ç¾åº”æ€¥å“åº”ç­‰åº”ç”¨çš„åˆæˆæ•°æ®é›†WildfireX-SLAMã€‚è¯¥æ•°æ®é›†åŒ…å«ä½ç©ºRGB-Dèˆªç©ºå›¾åƒå’Œçµæ´»çš„ç¯å¢ƒæ§åˆ¶ï¼Œå¦‚å…‰çº¿ã€å¤©æ°”å’Œç«ç¾ç±»å‹åŠçŠ¶å†µç­‰ã€‚æ­¤å¤–ï¼Œæ–‡ç« è¿˜è¿›è¡Œäº†å…¨é¢çš„åŸºå‡†æµ‹è¯•ï¼Œæ­ç¤ºäº†æ£®æ—ç¯å¢ƒä¸­åŸºäº3DGSçš„SLAMçš„ç‹¬ç‰¹æŒ‘æˆ˜å’Œæœªæ¥æ”¹è¿›æ–¹å‘ã€‚æ•°æ®é›†å’Œä»£ç å°†å…¬å¼€å‘å¸ƒã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>3DGSåœ¨SLAMä¸­å¯¹äºå¤§è§„æ¨¡æ£®æ—åœºæ™¯çš„åº”ç”¨å…·æœ‰æ½œåŠ›ã€‚</li>
<li>ç¼ºä¹é’ˆå¯¹æ£®æ—åœºæ™¯çš„é«˜è´¨é‡SLAMæ•°æ®é›†ã€‚</li>
<li>åˆ©ç”¨Unreal Engine 5ç¯å¢ƒæ„å»ºäº†ä¸€ä¸ªåä¸ºWildfireX-SLAMçš„å¤§è§„æ¨¡ã€ç»¼åˆã€é«˜è´¨é‡åˆæˆæ•°æ®é›†ã€‚</li>
<li>WildfireX-SLAMåŒ…å«ä½ç©ºRGB-Dèˆªç©ºå›¾åƒï¼Œå¹¶æä¾›äº†çµæ´»çš„ç¯å¢ƒæ§åˆ¶ã€‚</li>
<li>åŸºäºWildfireX-SLAMçš„åŸºå‡†æµ‹è¯•æ­ç¤ºäº†æ£®æ—ç¯å¢ƒä¸­åŸºäº3DGSçš„SLAMçš„æŒ‘æˆ˜å’Œæ”¹è¿›æ–¹å‘ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.27133">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-cd294ff3aae9dda10fe0702a23f49884~resize:0:q75.jpg?source=1f5c5e47&expiration=1762311096&auth_key=1762311096-0-0-f7e96c6cbe2327f2a0795ec8e7627b75&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-dfad99a8278eed1a42721fa96da890dc~resize:0:q75.jpg?source=1f5c5e47&expiration=1762311103&auth_key=1762311103-0-0-cb07cef77715fcaa8b0b45a5e259cfa3&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-734e27bab952c1e02961db801321b466~resize:0:q75.jpg?source=1f5c5e47&expiration=1762311110&auth_key=1762311110-0-0-dae7f76b3ec8db7ed6853bf87950edce&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-b82716e6fa8ff7e6602251cae8cde96e~resize:0:q75.jpg?source=1f5c5e47&expiration=1762311117&auth_key=1762311117-0-0-c92a58ff28d18b08270ebdb3af11ce59&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="DC4GS-Directional-Consistency-Driven-Adaptive-Density-Control-for-3D-Gaussian-Splatting"><a href="#DC4GS-Directional-Consistency-Driven-Adaptive-Density-Control-for-3D-Gaussian-Splatting" class="headerlink" title="DC4GS: Directional Consistency-Driven Adaptive Density Control for 3D   Gaussian Splatting"></a>DC4GS: Directional Consistency-Driven Adaptive Density Control for 3D   Gaussian Splatting</h2><p><strong>Authors:Moonsoo Jeong, Dongbeen Kim, Minseong Kim, Sungkil Lee</strong></p>
<p>We present a Directional Consistency (DC)-driven Adaptive Density Control (ADC) for 3D Gaussian Splatting (DC4GS). Whereas the conventional ADC bases its primitive splitting on the magnitudes of positional gradients, we further incorporate the DC of the gradients into ADC, and realize it through the angular coherence of the gradients. Our DC better captures local structural complexities in ADC, avoiding redundant splitting. When splitting is required, we again utilize the DC to define optimal split positions so that sub-primitives best align with the local structures than the conventional random placement. As a consequence, our DC4GS greatly reduces the number of primitives (up to 30% in our experiments) than the existing ADC, and also enhances reconstruction fidelity greatly. </p>
<blockquote>
<p>æˆ‘ä»¬æå‡ºäº†ä¸€ç§åŸºäºæ–¹å‘ä¸€è‡´æ€§ï¼ˆDCï¼‰çš„é€‚åº”å¯†åº¦æ§åˆ¶ï¼ˆADCï¼‰æ–¹æ³•ï¼Œç”¨äºä¸‰ç»´é«˜æ–¯æ¨¡ç³Šï¼ˆDC4GSï¼‰ã€‚ä¼ ç»Ÿçš„ADCåŸºäºä½ç½®æ¢¯åº¦çš„å¹…åº¦è¿›è¡ŒåŸºæœ¬åˆ†è£‚ï¼Œæˆ‘ä»¬è¿›ä¸€æ­¥å°†æ¢¯åº¦çš„DCçº³å…¥ADCï¼Œå¹¶é€šè¿‡æ¢¯åº¦çš„è§’ç›¸å¹²æ€§æ¥å®ç°ã€‚æˆ‘ä»¬çš„DCèƒ½æ›´å¥½åœ°æ•æ‰ADCä¸­çš„å±€éƒ¨ç»“æ„å¤æ‚æ€§ï¼Œé¿å…å†—ä½™åˆ†è£‚ã€‚å½“éœ€è¦åˆ†è£‚æ—¶ï¼Œæˆ‘ä»¬å†æ¬¡ä½¿ç”¨DCæ¥å®šä¹‰æœ€ä½³åˆ†è£‚ä½ç½®ï¼Œä»¥ä½¿å­åŸºæœ¬ä½“æ¯”ä¼ ç»Ÿéšæœºæ”¾ç½®æ›´å¥½åœ°ä¸å±€éƒ¨ç»“æ„å¯¹é½ã€‚å› æ­¤ï¼Œæˆ‘ä»¬çš„DC4GSå¤§å¤§å‡å°‘äº†åŸºæœ¬ä½“çš„æ•°é‡ï¼ˆåœ¨æˆ‘ä»¬çš„å®éªŒä¸­æœ€å¤šå‡å°‘30%ï¼‰ï¼Œå¹¶ä¸”ä¹Ÿæ¯”ç°æœ‰çš„ADCå¤§å¤§æé«˜äº†é‡å»ºçš„ä¿çœŸåº¦ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.26921v1">PDF</a> Accepted to NeurIPS 2025 &#x2F; Project page:   <a target="_blank" rel="noopener" href="https://github.com/cgskku/dc4gs">https://github.com/cgskku/dc4gs</a></p>
<p><strong>Summary</strong><br>     æœ¬æ–‡æå‡ºäº†åŸºäºæ–¹å‘ä¸€è‡´æ€§ï¼ˆDCï¼‰é©±åŠ¨çš„é€‚åº”æ€§å¯†åº¦æ§åˆ¶ï¼ˆADCï¼‰çš„3Dé«˜æ–¯å–·ç»˜ï¼ˆDC4GSï¼‰ã€‚è¯¥æ–¹æ³•å°†æ¢¯åº¦æ–¹å‘çš„ä¸€è‡´æ€§çº³å…¥é€‚åº”æ€§å¯†åº¦æ§åˆ¶ä¸­ï¼Œé€šè¿‡æ¢¯åº¦çš„è§’åº¦ä¸€è‡´æ€§å®ç°ã€‚DCèƒ½å¤Ÿæ›´å¥½åœ°æ•æ‰é€‚åº”æ€§å¯†åº¦æ§åˆ¶ä¸­çš„å±€éƒ¨ç»“æ„å¤æ‚æ€§ï¼Œé¿å…å†—ä½™åˆ†è£‚ã€‚åœ¨éœ€è¦åˆ†è£‚æ—¶ï¼Œåˆ©ç”¨DCå®šä¹‰æœ€ä½³åˆ†è£‚ä½ç½®ï¼Œä½¿å­åŸå§‹æ•°æ®æ›´å¥½åœ°ä¸å±€éƒ¨ç»“æ„å¯¹é½ã€‚å› æ­¤ï¼ŒDC4GSå¤§å¤§å‡å°‘äº†åŸå§‹æ•°æ®é‡ï¼ˆå®éªŒä¸­å‡å°‘30%ï¼‰ï¼Œå¹¶å¤§å¤§æé«˜äº†é‡å»ºçš„ä¿çœŸåº¦ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æå‡ºäº†åŸºäºæ–¹å‘ä¸€è‡´æ€§ï¼ˆDCï¼‰çš„é€‚åº”æ€§å¯†åº¦æ§åˆ¶ï¼ˆADCï¼‰æ–¹æ³•ï¼Œç”¨äºæ”¹è¿›3Dé«˜æ–¯å–·ç»˜ï¼ˆDC4GSï¼‰ã€‚</li>
<li>DCæ–¹æ³•å°†æ¢¯åº¦æ–¹å‘çš„ä¸€è‡´æ€§çº³å…¥ADCä¸­ï¼Œæé«˜äº†å¯¹å±€éƒ¨ç»“æ„å¤æ‚æ€§çš„æ•æ‰èƒ½åŠ›ã€‚</li>
<li>DCèƒ½å¤Ÿæ›´å¥½åœ°é¿å…å†—ä½™åˆ†è£‚ï¼Œæé«˜åˆ†è£‚æ•ˆç‡ã€‚</li>
<li>åœ¨éœ€è¦åˆ†è£‚æ—¶ï¼Œåˆ©ç”¨DCå®šä¹‰æœ€ä½³åˆ†è£‚ä½ç½®ï¼Œä½¿å­åŸå§‹æ•°æ®ä¸å±€éƒ¨ç»“æ„æ›´å¯¹é½ã€‚</li>
<li>DC4GSæ–¹æ³•ç›¸è¾ƒäºä¼ ç»ŸADCæ–¹æ³•å‡å°‘äº†åŸå§‹æ•°æ®é‡ã€‚</li>
<li>DC4GSèƒ½å¤Ÿæ˜¾è‘—æé«˜é‡å»ºçš„ä¿çœŸåº¦ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.26921">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-8caa28b4fcac6303d311ebb3c816e6f8~resize:0:q75.jpg?source=1f5c5e47&expiration=1762311124&auth_key=1762311124-0-0-f56cc530e238d7d494e856d86bce6c0f&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-fa80feb3eba4a2b2b6e4bf89806ca21c~resize:0:q75.jpg?source=1f5c5e47&expiration=1762311132&auth_key=1762311132-0-0-445c31cf87ab7f71babe24c339a52c51&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-e7ee3bfb6de12c5d44b8006d2c4f741b~resize:0:q75.jpg?source=1f5c5e47&expiration=1762311139&auth_key=1762311139-0-0-f8f1dcc10c029856c4c9a75d611dbcda&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-2129d0cf7b037c05da51b3d0b3e40afa~resize:0:q75.jpg?source=1f5c5e47&expiration=1762311145&auth_key=1762311145-0-0-29b98f66e61c11eba038de08ed3c2ab8&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-23c1aa2316f8ea58b73b5f014d8d48fd~resize:0:q75.jpg?source=1f5c5e47&expiration=1762311152&auth_key=1762311152-0-0-a2e00ae17ac6ff6f96ebfa6714fabc91&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="HEIR-Learning-Graph-Based-Motion-Hierarchies"><a href="#HEIR-Learning-Graph-Based-Motion-Hierarchies" class="headerlink" title="HEIR: Learning Graph-Based Motion Hierarchies"></a>HEIR: Learning Graph-Based Motion Hierarchies</h2><p><strong>Authors:Cheng Zheng, William Koch, Baiang Li, Felix Heide</strong></p>
<p>Hierarchical structures of motion exist across research fields, including computer vision, graphics, and robotics, where complex dynamics typically arise from coordinated interactions among simpler motion components. Existing methods to model such dynamics typically rely on manually-defined or heuristic hierarchies with fixed motion primitives, limiting their generalizability across different tasks. In this work, we propose a general hierarchical motion modeling method that learns structured, interpretable motion relationships directly from data. Our method represents observed motions using graph-based hierarchies, explicitly decomposing global absolute motions into parent-inherited patterns and local motion residuals. We formulate hierarchy inference as a differentiable graph learning problem, where vertices represent elemental motions and directed edges capture learned parent-child dependencies through graph neural networks. We evaluate our hierarchical reconstruction approach on three examples: 1D translational motion, 2D rotational motion, and dynamic 3D scene deformation via Gaussian splatting. Experimental results show that our method reconstructs the intrinsic motion hierarchy in 1D and 2D cases, and produces more realistic and interpretable deformations compared to the baseline on dynamic 3D Gaussian splatting scenes. By providing an adaptable, data-driven hierarchical modeling paradigm, our method offers a formulation applicable to a broad range of motion-centric tasks. Project Page: <a target="_blank" rel="noopener" href="https://light.princeton.edu/HEIR/">https://light.princeton.edu/HEIR/</a> </p>
<blockquote>
<p>åœ¨è¿åŠ¨ç ”ç©¶é¢†åŸŸï¼ŒåŒ…æ‹¬è®¡ç®—æœºè§†è§‰ã€å›¾å½¢å­¦å’Œæœºå™¨äººæŠ€æœ¯ï¼Œéƒ½å­˜åœ¨å±‚æ¬¡åŒ–çš„è¿åŠ¨ç»“æ„ã€‚å¤æ‚çš„åŠ¨æ€é€šå¸¸æºäºç®€å•è¿åŠ¨ç»„ä»¶ä¹‹é—´çš„åè°ƒäº¤äº’ã€‚ç°æœ‰çš„å»ºæ¨¡æ­¤ç±»åŠ¨æ€çš„æ–¹æ³•é€šå¸¸ä¾èµ–äºæ‰‹åŠ¨å®šä¹‰æˆ–å¯å‘å¼å±‚æ¬¡ç»“æ„ä»¥åŠå›ºå®šçš„è¿åŠ¨åŸå§‹å½¢æ€ï¼Œè¿™é™åˆ¶äº†å®ƒä»¬åœ¨ä¸åŒä»»åŠ¡ä¸­çš„é€šç”¨æ€§ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§é€šç”¨çš„å±‚æ¬¡åŒ–è¿åŠ¨å»ºæ¨¡æ–¹æ³•ï¼Œè¯¥æ–¹æ³•ç›´æ¥ä»æ•°æ®ä¸­å­¦ä¹ ç»“æ„åŒ–ã€å¯è§£é‡Šçš„è¿åŠ¨å…³ç³»ã€‚æˆ‘ä»¬çš„æ–¹æ³•ä½¿ç”¨åŸºäºå›¾çš„å±‚æ¬¡ç»“æ„æ¥è¡¨ç¤ºè§‚å¯Ÿåˆ°çš„è¿åŠ¨ï¼Œæ˜¾å¼åœ°å°†å…¨å±€ç»å¯¹è¿åŠ¨åˆ†è§£ä¸ºçˆ¶çº§ç»§æ‰¿æ¨¡å¼å’Œå±€éƒ¨è¿åŠ¨æ®‹å·®ã€‚æˆ‘ä»¬å°†å±‚æ¬¡ç»“æ„æ¨æ–­åˆ¶å®šä¸ºå¯å¾®å›¾å­¦ä¹ é—®é¢˜ï¼Œå…¶ä¸­é¡¶ç‚¹ä»£è¡¨åŸºæœ¬è¿åŠ¨ï¼Œæœ‰å‘è¾¹é€šè¿‡å›¾ç¥ç»ç½‘ç»œæ•è·ä¹ å¾—çš„çˆ¶å­ä¾èµ–å…³ç³»ã€‚æˆ‘ä»¬åœ¨ä¸‰ä¸ªç¤ºä¾‹ä¸Šè¯„ä¼°äº†æˆ‘ä»¬çš„å±‚æ¬¡é‡å»ºæ–¹æ³•ï¼š1Då¹³ç§»è¿åŠ¨ã€2Dæ—‹è½¬è¿åŠ¨å’Œé€šè¿‡é«˜æ–¯æ˜ å°„çš„åŠ¨æ€3Dåœºæ™¯å˜å½¢ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨1Då’Œ2Dæƒ…å†µä¸‹é‡å»ºäº†å†…åœ¨è¿åŠ¨å±‚æ¬¡ï¼Œå¹¶åœ¨åŠ¨æ€3Dé«˜æ–¯æ˜ å°„åœºæ™¯ä¸Šä¸åŸºçº¿ç›¸æ¯”äº§ç”Ÿäº†æ›´çœŸå®ã€æ›´å¯è§£é‡Šçš„å˜å½¢ã€‚é€šè¿‡æä¾›è‡ªé€‚åº”ã€æ•°æ®é©±åŠ¨çš„å±‚æ¬¡åŒ–å»ºæ¨¡èŒƒå¼ï¼Œæˆ‘ä»¬çš„æ–¹æ³•é€‚ç”¨äºå¹¿æ³›çš„ä»¥è¿åŠ¨ä¸ºä¸­å¿ƒçš„ä»»åŠ¡ã€‚é¡¹ç›®é¡µé¢ï¼š<a target="_blank" rel="noopener" href="https://light.princeton.edu/HEIR/">https://light.princeton.edu/HEIR/</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.26786v1">PDF</a> Code link: <a target="_blank" rel="noopener" href="https://github.com/princeton-computational-imaging/HEIR">https://github.com/princeton-computational-imaging/HEIR</a></p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºä¸€ç§é€šç”¨çš„å±‚æ¬¡åŒ–è¿åŠ¨å»ºæ¨¡æ–¹æ³•ï¼Œè¯¥æ–¹æ³•ç›´æ¥ä»æ•°æ®ä¸­å­¦ä¹ ç»“æ„åŒ–çš„ã€å¯è§£é‡Šçš„è¿åŠ¨å…³ç³»ã€‚é€šè¿‡åŸºäºå›¾çš„å±‚æ¬¡ç»“æ„è¡¨ç¤ºè§‚å¯Ÿåˆ°çš„è¿åŠ¨ï¼Œå°†å…¨å±€ç»å¯¹è¿åŠ¨æ˜¾å¼åœ°åˆ†è§£ä¸ºçˆ¶ç³»ç»§æ‰¿çš„æ¨¡å¼å’Œå±€éƒ¨è¿åŠ¨æ®‹ç•™ã€‚å±‚æ¬¡æ¨æ–­è¢«åˆ¶å®šä¸ºä¸€ä¸ªå¯å¾®åˆ†çš„å›¾å­¦ä¹ é—®é¢˜ï¼Œå…¶ä¸­é¡¶ç‚¹ä»£è¡¨åŸºæœ¬è¿åŠ¨ï¼Œæœ‰å‘è¾¹é€šè¿‡å›¾ç¥ç»ç½‘ç»œå­¦ä¹ çˆ¶-å­ä¾èµ–å…³ç³»ã€‚åœ¨1Då¹³ç§»è¿åŠ¨ã€2Dæ—‹è½¬è¿åŠ¨å’ŒåŠ¨æ€3Dåœºæ™¯å˜å½¢ç­‰ä¸‰ä¸ªå®éªŒæ¡ˆä¾‹ä¸­ï¼Œè¯¥æ–¹æ³•é‡å»ºäº†å†…åœ¨è¿åŠ¨å±‚æ¬¡ï¼Œå¹¶åœ¨åŠ¨æ€3Dé«˜æ–¯å–·æº…åœºæ™¯ä¸­ç›¸æ¯”åŸºçº¿æ–¹æ³•äº§ç”Ÿæ›´çœŸå®ã€æ›´å¯è§£é‡Šçš„ç»“æœã€‚è¯¥æ–¹æ³•æä¾›äº†ä¸€ç§é€‚åº”æ€§å¼ºã€æ•°æ®é©±åŠ¨çš„è¿åŠ¨å±‚æ¬¡å»ºæ¨¡èŒƒå¼ï¼Œé€‚ç”¨äºå¹¿æ³›çš„è¿åŠ¨ä»»åŠ¡ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å±‚æ¬¡åŒ–è¿åŠ¨å»ºæ¨¡æ–¹æ³•ç›´æ¥ä»æ•°æ®ä¸­å­¦ä¹ ç»“æ„åŒ–çš„è¿åŠ¨å…³ç³»ã€‚</li>
<li>æ–¹æ³•é‡‡ç”¨åŸºäºå›¾çš„å±‚æ¬¡ç»“æ„æ¥è¡¨ç¤ºè§‚å¯Ÿåˆ°çš„è¿åŠ¨ï¼Œåˆ†è§£å…¨å±€è¿åŠ¨å’Œå±€éƒ¨è¿åŠ¨æ®‹ç•™ã€‚</li>
<li>å±‚æ¬¡æ¨æ–­è¢«è½¬åŒ–ä¸ºå¯å¾®åˆ†çš„å›¾å­¦ä¹ é—®é¢˜ï¼Œå…¶ä¸­é¡¶ç‚¹ä»£è¡¨åŸºæœ¬è¿åŠ¨ï¼Œè¾¹ä»£è¡¨çˆ¶-å­ä¾èµ–å…³ç³»ã€‚</li>
<li>æ–¹æ³•åœ¨1Då’Œ2Dè¿åŠ¨æ¡ˆä¾‹ä¸­æˆåŠŸé‡å»ºäº†å†…åœ¨è¿åŠ¨å±‚æ¬¡ã€‚</li>
<li>åœ¨åŠ¨æ€3Dåœºæ™¯å˜å½¢å®éªŒä¸­ï¼Œç›¸æ¯”åŸºçº¿æ–¹æ³•ï¼Œè¯¥æ–¹æ³•äº§ç”Ÿæ›´çœŸå®ã€æ›´å¯è§£é‡Šçš„ç»“æœã€‚</li>
<li>è¯¥æ–¹æ³•æä¾›äº†ä¸€ç§æ•°æ®é©±åŠ¨çš„è¿åŠ¨å±‚æ¬¡å»ºæ¨¡èŒƒå¼ï¼Œå…·æœ‰å¹¿æ³›çš„é€‚ç”¨æ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.26786">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-78da6df7a9b1cb9a63dee690ee0e3e60~resize:0:q75.jpg?source=1f5c5e47&expiration=1762311160&auth_key=1762311160-0-0-679cf67bbc58736a62acce5f6910dd00&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-506f0755f1659fca5e9b1ed4472ab491~resize:0:q75.jpg?source=1f5c5e47&expiration=1762311167&auth_key=1762311167-0-0-1dfa523620405dd966c46e092e405e2e&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="AgriGS-SLAM-Orchard-Mapping-Across-Seasons-via-Multi-View-Gaussian-Splatting-SLAM"><a href="#AgriGS-SLAM-Orchard-Mapping-Across-Seasons-via-Multi-View-Gaussian-Splatting-SLAM" class="headerlink" title="AgriGS-SLAM: Orchard Mapping Across Seasons via Multi-View Gaussian   Splatting SLAM"></a>AgriGS-SLAM: Orchard Mapping Across Seasons via Multi-View Gaussian   Splatting SLAM</h2><p><strong>Authors:Mirko Usuelli, David Rapado-Rincon, Gert Kootstra, Matteo Matteucci</strong></p>
<p>Autonomous robots in orchards require real-time 3D scene understanding despite repetitive row geometry, seasonal appearance changes, and wind-driven foliage motion. We present AgriGS-SLAM, a Visualâ€“LiDAR SLAM framework that couples direct LiDAR odometry and loop closures with multi-camera 3D Gaussian Splatting (3DGS) rendering. Batch rasterization across complementary viewpoints recovers orchard structure under occlusions, while a unified gradient-driven map lifecycle executed between keyframes preserves fine details and bounds memory. Pose refinement is guided by a probabilistic LiDAR-based depth consistency term, back-propagated through the camera projection to tighten geometry-appearance coupling. We deploy the system on a field platform in apple and pear orchards across dormancy, flowering, and harvesting, using a standardized trajectory protocol that evaluates both training-view and novel-view synthesis to reduce 3DGS overfitting in evaluation. Across seasons and sites, AgriGS-SLAM delivers sharper, more stable reconstructions and steadier trajectories than recent state-of-the-art 3DGS-SLAM baselines while maintaining real-time performance on-tractor. While demonstrated in orchard monitoring, the approach can be applied to other outdoor domains requiring robust multimodal perception. </p>
<blockquote>
<p>åœ¨æœå›­ä¸­ï¼Œè‡ªä¸»æœºå™¨äººéœ€è¦å®æ—¶ç†è§£ä¸‰ç»´åœºæ™¯ï¼Œå³ä¾¿é¢å¯¹é‡å¤çš„è¡Œåˆ—å‡ ä½•ç»“æ„ã€å­£èŠ‚æ€§çš„å¤–è§‚å˜åŒ–ï¼Œä»¥åŠé£åŠ›é©±åŠ¨çš„å¶å­è¿åŠ¨ã€‚æˆ‘ä»¬æ¨å‡ºäº†AgriGS-SLAMç³»ç»Ÿï¼Œè¿™æ˜¯ä¸€ä¸ªè§†è§‰ä¸æ¿€å…‰é›·è¾¾SLAMæ¡†æ¶ï¼Œç»“åˆäº†ç›´æ¥çš„æ¿€å…‰é›·è¾¾é‡Œç¨‹è®¡ä¸å¾ªç¯é—­åˆï¼Œä»¥åŠå¤šæ‘„åƒå¤´ä¸‰ç»´é«˜æ–¯è´´ç‰‡ï¼ˆ3DGSï¼‰æ¸²æŸ“æŠ€æœ¯ã€‚åœ¨ä¸åŒè§†è§’çš„æ‰¹é‡å…‰æ …åŒ–å¤„ç†ä¸‹ï¼Œå³ä½¿åœ¨é®æŒ¡æƒ…å†µä¸‹ä¹Ÿèƒ½æ¢å¤æœå›­ç»“æ„ï¼›è€Œåœ¨å…³é”®å¸§ä¹‹é—´æ‰§è¡Œç»Ÿä¸€æ¢¯åº¦é©±åŠ¨åœ°å›¾ç”Ÿå‘½å‘¨æœŸï¼Œå¯ä»¥ä¿ç•™ç»†èŠ‚å¹¶é™åˆ¶å†…å­˜ä½¿ç”¨ã€‚ä½å§¿ä¼˜åŒ–ç”±åŸºäºæ¦‚ç‡çš„æ¿€å…‰é›·è¾¾æ·±åº¦ä¸€è‡´æ€§é¡¹å¼•å¯¼ï¼Œé€šè¿‡ç›¸æœºæŠ•å½±è¿›è¡Œåå‘ä¼ æ’­ï¼Œä»¥åŠ å¼ºå‡ ä½•å¤–è§‚è€¦åˆã€‚æˆ‘ä»¬åœ¨è‹¹æœå’Œæ¢¨å›­çš„å¹³å°ç°åœºï¼Œè·¨è¶Šä¼‘çœ æœŸã€èŠ±æœŸå’Œé‡‡æ”¶æœŸéƒ¨ç½²äº†è¯¥ç³»ç»Ÿï¼Œé‡‡ç”¨æ ‡å‡†åŒ–è½¨è¿¹åè®®æ¥è¯„ä¼°è®­ç»ƒè§†å›¾å’Œæ–°é¢–è§†å›¾åˆæˆï¼Œä»¥å‡å°‘è¯„ä¼°ä¸­çš„3DGSè¿‡åº¦æ‹Ÿåˆã€‚åœ¨ä¸åŒå­£èŠ‚å’Œåœ°ç‚¹ï¼ŒAgriGS-SLAMæä¾›äº†æ›´æ¸…æ™°ã€æ›´ç¨³å®šçš„é‡å»ºç»“æœå’Œæ›´ç¨³å®šçš„è½¨è¿¹è·Ÿè¸ªï¼Œç›¸è¾ƒäºæœ€æ–°çš„é«˜çº§3DGS-SLAMåŸºå‡†æµ‹è¯•ï¼ŒåŒæ—¶åœ¨æ‹–æ‹‰æœºä¸Šå®ç°äº†å®æ—¶æ€§èƒ½ã€‚è™½ç„¶è¯¥æ–¹æ³•åœ¨æœå›­ç›‘æµ‹ä¸­å¾—åˆ°äº†å±•ç¤ºï¼Œä½†å®ƒä¹Ÿå¯ä»¥åº”ç”¨äºå…¶ä»–éœ€è¦ç¨³å¥å¤šæ¨¡å¼æ„ŸçŸ¥çš„æˆ·å¤–é¢†åŸŸã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.26358v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>å†œä¸šç¯å¢ƒä¸­çš„è‡ªä¸»æœºå™¨äººéœ€è¦å®æ—¶ä¸‰ç»´åœºæ™¯ç†è§£ï¼Œé¢ä¸´æœå›­æ’åˆ—é‡å¤ã€å­£èŠ‚å¤–è§‚å˜åŒ–å’Œé£é©±æå¶è¿åŠ¨ç­‰æŒ‘æˆ˜ã€‚æœ¬æ–‡æå‡ºAgriGS-SLAMï¼Œç»“åˆæ¿€å…‰é›·è¾¾ç›´æ¥é‡Œç¨‹è®¡ä¸å¾ªç¯é—­åˆï¼Œä»¥åŠå¤šç›¸æœºä¸‰ç»´é«˜æ–¯å–·ç»˜ï¼ˆ3DGSï¼‰æ¸²æŸ“æŠ€æœ¯ã€‚é€šè¿‡ä¸åŒè§†è§’çš„æ‰¹é‡å…‰æ …åŒ–æ¢å¤æœå›­ç»“æ„é®æŒ¡é—®é¢˜ï¼Œå¹¶åœ¨å…³é”®å¸§ä¹‹é—´æ‰§è¡Œç»Ÿä¸€æ¢¯åº¦é©±åŠ¨åœ°å›¾ç”Ÿå‘½å‘¨æœŸä»¥ä¿ç•™ç»†èŠ‚å¹¶é™åˆ¶å†…å­˜ã€‚ä½å§¿ä¼˜åŒ–ç”±åŸºäºæ¦‚ç‡çš„æ¿€å…‰é›·è¾¾æ·±åº¦ä¸€è‡´æ€§é¡¹å¼•å¯¼ï¼Œåå‘ä¼ æ’­åˆ°ç›¸æœºæŠ•å½±ä»¥åŠ å¼ºå‡ ä½•å¤–è§‚è€¦åˆã€‚ç³»ç»Ÿéƒ¨ç½²åœ¨è‹¹æœå’Œæ¢¨æ ‘æœå›­çš„ç”°é‡å¹³å°ä¸Šï¼Œé‡‡ç”¨æ ‡å‡†åŒ–è½¨è¿¹åè®®è¯„ä¼°è®­ç»ƒè§†å›¾å’Œæ–°é¢–è§†å›¾åˆæˆï¼Œä»¥å‡å°‘3DGSè¿‡åº¦æ‹Ÿåˆäºè¯„ä¼°ç»“æœã€‚è·¨å­£èŠ‚å’Œåœ°ç‚¹ï¼ŒAgriGS-SLAMæä¾›æ›´æ¸…æ™°ã€æ›´ç¨³å®šçš„é‡å»ºå’Œæ›´ç¨³å®šçš„è½¨è¿¹ï¼Œç›¸æ¯”æœ€æ–°çš„å…ˆè¿›3DGS-SLAMåŸºçº¿ä¿æŒå®æ—¶æ€§èƒ½ã€‚è™½ç„¶æ¼”ç¤ºäºæœå›­ç›‘æµ‹ï¼Œä½†è¯¥æ–¹æ³•å¯åº”ç”¨äºå…¶ä»–éœ€è¦ç¨³å¥å¤šæ¨¡å¼æ„ŸçŸ¥çš„æˆ·å¤–é¢†åŸŸã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>è‡ªä¸»æœºå™¨äººåœ¨æœå›­ç¯å¢ƒä¸­çš„å®æ—¶ä¸‰ç»´åœºæ™¯ç†è§£è‡³å…³é‡è¦ã€‚</li>
<li>AgriGS-SLAMç»“åˆäº†LiDARç›´æ¥é‡Œç¨‹è®¡ä¸å¾ªç¯é—­åˆæŠ€æœ¯ã€‚</li>
<li>å¤šç›¸æœºä¸‰ç»´é«˜æ–¯å–·ç»˜ï¼ˆ3DGSï¼‰æ¸²æŸ“ç”¨äºæ¢å¤æœå›­ç»“æ„ã€‚</li>
<li>é€šè¿‡ä¸åŒè§†è§’çš„æ‰¹é‡å…‰æ …åŒ–å¤„ç†é®æŒ¡é—®é¢˜ã€‚</li>
<li>ç»Ÿä¸€æ¢¯åº¦é©±åŠ¨åœ°å›¾ç”Ÿå‘½å‘¨æœŸä¿ç•™ç»†èŠ‚å¹¶ç®¡ç†å†…å­˜ã€‚</li>
<li>ä½å§¿ä¼˜åŒ–åŸºäºæ¦‚ç‡çš„æ¿€å…‰é›·è¾¾æ·±åº¦ä¸€è‡´æ€§é¡¹å¼•å¯¼ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.26358">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-842f43df9ba65efab368952812af9bfc~resize:0:q75.jpg?source=1f5c5e47&expiration=1762311174&auth_key=1762311174-0-0-25f9581d8bfd177372949fb174f0864e&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-7140b6afd6a72deb73e657d9f13b167f~resize:0:q75.jpg?source=1f5c5e47&expiration=1762311181&auth_key=1762311181-0-0-b1ace5d065853fda96d9a7b55f7554b1&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-e9241bad460e9fd17f9c98b185477748~resize:0:q75.jpg?source=1f5c5e47&expiration=1762311188&auth_key=1762311188-0-0-b6e00b67c8bfce6c44375cc0bbaa9870&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-b14891d93b7d6e644db0c64922568abc~resize:0:q75.jpg?source=1f5c5e47&expiration=1762311195&auth_key=1762311195-0-0-a1b244f79a828147e28d3d0177860593&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-a9693b783f3cd78e49573596b7637cf8~resize:0:q75.jpg?source=1f5c5e47&expiration=1762311203&auth_key=1762311203-0-0-196d84a389faf82378ccbcb1d1a0e1ab&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-537b15e5ac54279bb75d8560a2cec236~resize:0:q75.jpg?source=1f5c5e47&expiration=1762311210&auth_key=1762311210-0-0-4abefbd1cd8d514d4360c3a1e8706278&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="6D-Channel-Knowledge-Map-Construction-via-Bidirectional-Wireless-Gaussian-Splatting"><a href="#6D-Channel-Knowledge-Map-Construction-via-Bidirectional-Wireless-Gaussian-Splatting" class="headerlink" title="6D Channel Knowledge Map Construction via Bidirectional Wireless   Gaussian Splatting"></a>6D Channel Knowledge Map Construction via Bidirectional Wireless   Gaussian Splatting</h2><p><strong>Authors:Juncong Zhou, Chao Hu, Guanlin Wu, Zixiang Ren, Han Hu, Juyong Zhang, Rui Zhang, Jie Xu</strong></p>
<p>This paper investigates the construction of channel knowledge map (CKM) from sparse channel measurements. Dif ferent from conventional two-&#x2F;three-dimensional (2D&#x2F;3D) CKM approaches assuming fixed base station configurations, we present a six-dimensional (6D) CKM framework named bidirectional wireless Gaussian splatting (BiWGS), which is capable of mod eling wireless channels across dynamic transmitter (Tx) and receiver (Rx) positions in 3D space. BiWGS uses Gaussian el lipsoids to represent virtual scatterer clusters and environmental obstacles in the wireless environment. By properly learning the bidirectional scattering patterns and complex attenuation profiles based on channel measurements, these ellipsoids inherently cap ture the electromagnetic transmission characteristics of wireless environments, thereby accurately modeling signal transmission under varying transceiver configurations. Experiment results show that BiWGS significantly outperforms classic multi-layer perception (MLP) for the construction of 6D channel power gain map with varying Tx-Rx positions, and achieves spatial spectrum prediction accuracy comparable to the state-of-the art wireless radiation field Gaussian splatting (WRF-GS) for 3D CKM construction. This validates the capability of the proposed BiWGS in accomplishing dimensional expansion of 6D CKM construction, without compromising fidelity. </p>
<blockquote>
<p>æœ¬æ–‡ç ”ç©¶äº†åŸºäºç¨€ç–ä¿¡é“æµ‹é‡çš„ä¿¡é“çŸ¥è¯†å›¾è°±ï¼ˆCKMï¼‰çš„æ„å»ºé—®é¢˜ã€‚ä¸åŒäºä¼ ç»Ÿçš„äºŒç»´&#x2F;ä¸‰ç»´ï¼ˆ2D&#x2F;3Dï¼‰CKMæ–¹æ³•å‡å®šå›ºå®šåŸºç«™é…ç½®ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åä¸ºåŒå‘æ— çº¿é«˜æ–¯å±•å¸ƒï¼ˆBiWGSï¼‰çš„å…­ç»´ï¼ˆ6Dï¼‰CKMæ¡†æ¶ã€‚è¯¥æ¡†æ¶èƒ½å¤Ÿå»ºæ¨¡åŠ¨æ€å‘å°„å™¨ï¼ˆTxï¼‰å’Œæ¥æ”¶å™¨ï¼ˆRxï¼‰åœ¨ä¸‰ç»´ç©ºé—´ä¸­çš„æ— çº¿ä¿¡é“ã€‚BiWGSä½¿ç”¨é«˜æ–¯æ¤­åœ†ä½“æ¥è¡¨ç¤ºæ— çº¿ç¯å¢ƒä¸­çš„è™šæ‹Ÿæ•£å°„ç°‡å’Œç¯å¢ƒéšœç¢ç‰©ã€‚é€šè¿‡åŸºäºä¿¡é“æµ‹é‡é€‚å½“åœ°å­¦ä¹ åŒå‘æ•£å°„æ¨¡å¼å’Œå¤æ‚çš„è¡°å‡æ›²çº¿ï¼Œè¿™äº›æ¤­åœ†ä½“èƒ½å¤Ÿå›ºæœ‰åœ°æ•è·æ— çº¿ç”µç£ç¯å¢ƒçš„ä¼ è¾“ç‰¹æ€§ï¼Œä»è€Œå‡†ç¡®åœ°åœ¨ä¸åŒçš„æ”¶å‘å™¨é…ç½®ä¸‹å»ºæ¨¡ä¿¡å·ä¼ è¾“ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œä¸ç»å…¸çš„å¤šå±‚æ„ŸçŸ¥å™¨ï¼ˆMLPï¼‰ç›¸æ¯”ï¼ŒBiWGSåœ¨æ„å»ºå…·æœ‰ä¸åŒTx-Rxä½ç½®çš„6Dä¿¡é“åŠŸç‡å¢ç›Šå›¾æ–¹é¢è¡¨ç°æ˜¾è‘—ä¼˜åŠ¿ï¼Œå¹¶åœ¨ç©ºé—´é¢‘è°±é¢„æµ‹å‡†ç¡®æ€§æ–¹é¢å®ç°äº†ä¸æœ€æ–°æ— çº¿è¾å°„åœºé«˜æ–¯å±•å¸ƒï¼ˆWRF-GSï¼‰ç›¸æ¯”çš„3D CKMæ„å»ºã€‚è¿™éªŒè¯äº†æ‰€æå‡ºçš„BiWGSåœ¨å®Œæˆ6D CKMæ„å»ºçš„ç»´åº¦æ‰©å±•æ–¹é¢çš„èƒ½åŠ›ï¼Œå¹¶ä¸”ä¸ä¼šæŸå®³ä¿çœŸåº¦ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.26166v1">PDF</a> </p>
<p><strong>Summary</strong><br>æ— çº¿é€šé“çŸ¥è¯†å›¾è°±æ„å»ºæŠ€æœ¯å¾—åˆ°ç ”ç©¶ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ä¸ªåŸºäºå…­ç»´çš„æ— çº¿é€šé“çŸ¥è¯†å›¾è°±ï¼ˆCKMï¼‰æ¡†æ¶â€”â€”åŒå‘æ— çº¿é«˜æ–¯å±•å¼€æŠ€æœ¯ï¼ˆBiWGSï¼‰ã€‚åŒºåˆ«äºä¼ ç»Ÿçš„äºŒç»´æˆ–ä¸‰ç»´CKMæ–¹æ³•å‡è®¾å›ºå®šåŸºç«™é…ç½®çš„å±€é™ï¼ŒBiWGSå¯æ¨¡æ‹Ÿè·¨è¶ŠåŠ¨æ€å‘å°„å™¨å’Œæ¥æ”¶å™¨ä½ç½®çš„æ— çº¿é€šé“ï¼Œå¹¶å…·æœ‰åœ¨ä¸åŒå‘å°„å’Œæ¥æ”¶é…ç½®ä¸‹ç²¾ç¡®å»ºæ¨¡ä¿¡å·ä¼ è¾“çš„èƒ½åŠ›ã€‚å®éªŒè¯æ˜ï¼ŒBiWGSåœ¨æ„å»ºå…·æœ‰ä¸åŒå‘å°„å™¨å’Œæ¥æ”¶å™¨ä½ç½®çš„å…­ç»´é€šé“åŠŸç‡å¢ç›Šå›¾æ–¹é¢æ˜¾è‘—ä¼˜äºç»å…¸çš„å¤šå±‚æ„ŸçŸ¥æŠ€æœ¯ï¼Œå…¶é¢„æµ‹å‡†ç¡®æ€§å¯ä»¥ä¸æœ€æ–°æ— çº¿è¾å°„åœºé«˜æ–¯å±•å¼€æŠ€æœ¯ç›¸å½“ã€‚éªŒè¯äº†BiWGSåœ¨å®Œæˆå…­ç»´CKMæ„å»ºçš„ç»´åº¦æ‰©å±•æ–¹é¢çš„èƒ½åŠ›ï¼Œä¸”ä¿çœŸåº¦ä¸ä¼šé™ä½ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>æœ¬ç ”ç©¶æ¢è®¨äº†åŸºäºç¨€ç–é€šé“æµ‹é‡çš„æ— çº¿é€šé“çŸ¥è¯†å›¾è°±ï¼ˆCKMï¼‰æ„å»ºæŠ€æœ¯ã€‚</li>
<li>æå‡ºäº†ä¸€ç§æ–°çš„å…­ç»´CKMæ¡†æ¶â€”â€”åŒå‘æ— çº¿é«˜æ–¯å±•å¼€æŠ€æœ¯ï¼ˆBiWGSï¼‰ã€‚</li>
<li>BiWGSèƒ½å¤Ÿåœ¨åŠ¨æ€å‘å°„å™¨å’Œæ¥æ”¶å™¨ä½ç½®å»ºæ¨¡æ— çº¿é€šé“ã€‚</li>
<li>BiWGSé€šè¿‡æ¨¡æ‹Ÿè™šæ‹Ÿæ•£å°„ç°‡å’Œç¯å¢ƒéšœç¢æ¥æ•æ‰æ— çº¿ç¯å¢ƒçš„ç”µç£ä¼ è¾“ç‰¹æ€§ã€‚</li>
<li>å®éªŒè¯æ˜ï¼ŒBiWGSåœ¨æ„å»ºå…­ç»´é€šé“åŠŸç‡å¢ç›Šå›¾æ–¹é¢ä¼˜äºå¤šå±‚æ„ŸçŸ¥æŠ€æœ¯ã€‚</li>
<li>BiWGSçš„é¢„æµ‹å‡†ç¡®æ€§å¯ä¸æœ€æ–°çš„æ— çº¿è¾å°„åœºé«˜æ–¯å±•å¼€æŠ€æœ¯ç›¸å½“ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.26166">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-23e174fc9dd17e01a11cb08b82f4c1de~resize:0:q75.jpg?source=1f5c5e47&expiration=1762311239&auth_key=1762311239-0-0-a44cbf87270ee79339a03aeb78f38173&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-629b1fa2b3eccfd4b6ca6c173b5cbe69~resize:0:q75.jpg?source=1f5c5e47&expiration=1762311246&auth_key=1762311246-0-0-580c85559814042902a45b8aea7d0edb&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-33e89c6037ea8c6ed779a67f3c012c2f~resize:0:q75.jpg?source=1f5c5e47&expiration=1762311253&auth_key=1762311253-0-0-c72449c829e5c365488b6ad80282c704&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="JOGS-Joint-Optimization-of-Pose-Estimation-and-3D-Gaussian-Splatting"><a href="#JOGS-Joint-Optimization-of-Pose-Estimation-and-3D-Gaussian-Splatting" class="headerlink" title="JOGS: Joint Optimization of Pose Estimation and 3D Gaussian Splatting"></a>JOGS: Joint Optimization of Pose Estimation and 3D Gaussian Splatting</h2><p><strong>Authors:Yuxuan Li, Tao Wang, Xianben Yang</strong></p>
<p>Traditional novel view synthesis methods heavily rely on external camera pose estimation tools such as COLMAP, which often introduce computational bottlenecks and propagate errors. To address these challenges, we propose a unified framework that jointly optimizes 3D Gaussian points and camera poses without requiring pre-calibrated inputs. Our approach iteratively refines 3D Gaussian parameters and updates camera poses through a novel co-optimization strategy, ensuring simultaneous improvements in scene reconstruction fidelity and pose accuracy. The key innovation lies in decoupling the joint optimization into two interleaved phases: first, updating 3D Gaussian parameters via differentiable rendering with fixed poses, and second, refining camera poses using a customized 3D optical flow algorithm that incorporates geometric and photometric constraints. This formulation progressively reduces projection errors, particularly in challenging scenarios with large viewpoint variations and sparse feature distributions, where traditional methods struggle. Extensive evaluations on multiple datasets demonstrate that our approach significantly outperforms existing COLMAP-free techniques in reconstruction quality, and also surpasses the standard COLMAP-based baseline in general. </p>
<blockquote>
<p>ä¼ ç»Ÿçš„å°è¯´è§†å›¾åˆæˆæ–¹æ³•ä¸¥é‡ä¾èµ–äºå¦‚COLMAPç­‰å¤–éƒ¨ç›¸æœºå§¿æ€ä¼°è®¡å·¥å…·ï¼Œè¿™å¾€å¾€å¼•å…¥è®¡ç®—ç“¶é¢ˆå¹¶ä¼ æ’­é”™è¯¯ã€‚ä¸ºäº†è§£å†³è¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§è”åˆä¼˜åŒ–3Dé«˜æ–¯ç‚¹å’Œç›¸æœºå§¿æ€çš„ç»Ÿä¸€æ¡†æ¶ï¼Œè€Œæ— éœ€é¢„å…ˆæ ¡å‡†çš„è¾“å…¥ã€‚æˆ‘ä»¬çš„æ–¹æ³•é€šè¿‡ä¸€ç§æ–°é¢–çš„ååŒä¼˜åŒ–ç­–ç•¥ï¼Œè¿­ä»£åœ°ä¼˜åŒ–3Dé«˜æ–¯å‚æ•°å¹¶æ›´æ–°ç›¸æœºå§¿æ€ï¼Œç¡®ä¿åœºæ™¯é‡å»ºä¿çœŸåº¦å’Œå§¿æ€å‡†ç¡®æ€§å¾—åˆ°åŒæ—¶æé«˜ã€‚å…³é”®åˆ›æ–°åœ¨äºå°†è”åˆä¼˜åŒ–è§£è€¦ä¸ºä¸¤ä¸ªäº¤æ›¿è¿›è¡Œçš„é˜¶æ®µï¼šé¦–å…ˆï¼Œé€šè¿‡å¯å¾®æ¸²æŸ“å’Œå›ºå®šå§¿æ€æ›´æ–°3Dé«˜æ–¯å‚æ•°ï¼›å…¶æ¬¡ï¼Œä½¿ç”¨å®šåˆ¶çš„3Då…‰æµç®—æ³•ç»†åŒ–ç›¸æœºå§¿æ€ï¼Œè¯¥ç®—æ³•ç»“åˆäº†å‡ ä½•å’Œå…‰åº¦çº¦æŸã€‚è¿™ç§å…¬å¼é€æ­¥å‡å°‘äº†æŠ•å½±è¯¯å·®ï¼Œç‰¹åˆ«æ˜¯åœ¨è§†ç‚¹å˜åŒ–å¤§ã€ç‰¹å¾åˆ†å¸ƒç¨€ç–ç­‰å…·æœ‰æŒ‘æˆ˜æ€§çš„åœºæ™¯ä¸­ï¼Œä¼ ç»Ÿæ–¹æ³•å¾€å¾€éš¾ä»¥åº”å¯¹ã€‚åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šçš„å¹¿æ³›è¯„ä¼°è¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨é‡å»ºè´¨é‡ä¸Šå¤§å¤§ä¼˜äºç°æœ‰çš„æ— COLMAPæŠ€æœ¯ï¼Œå¹¶ä¸”åœ¨æ€»ä½“ä¸Šç”šè‡³è¶…è¶Šäº†åŸºäºCOLMAPçš„åŸºçº¿æ°´å¹³ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.26117v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºä¸€ç§è”åˆä¼˜åŒ–3Dé«˜æ–¯ç‚¹å’Œç›¸æœºå§¿æ€çš„ç»Ÿä¸€æ¡†æ¶ï¼Œæ— éœ€é¢„å…ˆæ ¡å‡†çš„è¾“å…¥ã€‚é€šè¿‡è¿­ä»£ä¼˜åŒ–3Dé«˜æ–¯å‚æ•°å¹¶æ›´æ–°ç›¸æœºå§¿æ€ï¼ŒåŒæ—¶æé«˜åœºæ™¯é‡å»ºçš„ä¿çœŸåº¦å’Œå§¿æ€å‡†ç¡®æ€§ã€‚å…³é”®åˆ›æ–°åœ¨äºå°†è”åˆä¼˜åŒ–è§£è€¦ä¸ºä¸¤ä¸ªäº¤æ›¿é˜¶æ®µï¼šé¦–å…ˆï¼Œé€šè¿‡å¯å¾®æ¸²æŸ“å›ºå®šå§¿æ€æ›´æ–°3Dé«˜æ–¯å‚æ•°ï¼›å…¶æ¬¡ï¼Œä½¿ç”¨å®šåˆ¶åŒ–çš„3Då…‰æµç®—æ³•ä¼˜åŒ–ç›¸æœºå§¿æ€ï¼Œèå…¥å‡ ä½•å’Œå…‰åº¦çº¦æŸã€‚æ­¤æ–¹æ³•åœ¨è§†ç‚¹å˜åŒ–å¤§ã€ç‰¹å¾åˆ†å¸ƒç¨€ç–ç­‰æŒ‘æˆ˜åœºæ™¯ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œæ˜¾è‘—ä¼˜äºæ— COLMAPæŠ€æœ¯å’Œæ ‡å‡†çš„COLMAPåŸºçº¿æ–¹æ³•ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æå‡ºä¸€ç§æ— éœ€ä¾èµ–å¤–éƒ¨ç›¸æœºå§¿æ€ä¼°è®¡å·¥å…·ï¼ˆå¦‚COLMAPï¼‰çš„ç»Ÿä¸€æ¡†æ¶ï¼Œè§£å†³äº†ä¼ ç»Ÿå°è¯´è§†å›¾åˆæˆæ–¹æ³•é¢ä¸´çš„æŒ‘æˆ˜ã€‚</li>
<li>é€šè¿‡è”åˆä¼˜åŒ–3Dé«˜æ–¯ç‚¹å’Œç›¸æœºå§¿æ€ï¼Œæé«˜äº†åœºæ™¯é‡å»ºçš„ä¿çœŸåº¦å’Œå§¿æ€å‡†ç¡®æ€§ã€‚</li>
<li>å°†ä¼˜åŒ–è¿‡ç¨‹è§£è€¦ä¸ºä¸¤ä¸ªäº¤æ›¿é˜¶æ®µï¼šæ›´æ–°3Dé«˜æ–¯å‚æ•°å’Œæ›´æ–°ç›¸æœºå§¿æ€ã€‚</li>
<li>åˆ©ç”¨å¯å¾®æ¸²æŸ“æŠ€æœ¯å›ºå®šç›¸æœºå§¿æ€ï¼Œæ›´æ–°3Dé«˜æ–¯å‚æ•°ã€‚</li>
<li>é‡‡ç”¨å®šåˆ¶çš„3Då…‰æµç®—æ³•ä¼˜åŒ–ç›¸æœºå§¿æ€ï¼ŒåŒæ—¶è€ƒè™‘å‡ ä½•å’Œå…‰åº¦çº¦æŸã€‚</li>
<li>è¯¥æ–¹æ³•åœ¨è§†ç‚¹å˜åŒ–å¤§ã€ç‰¹å¾åˆ†å¸ƒç¨€ç–ç­‰æŒ‘æˆ˜åœºæ™¯ä¸­è¡¨ç°ä¼˜å¼‚ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.26117">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-ee25e87c0ad7f1c0fecb3f7d30ee72be~resize:0:q75.jpg?source=1f5c5e47&expiration=1762311260&auth_key=1762311260-0-0-616d8112d7df7bede697927ed555d13a&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-15ae35155acdb178e4f84bdef7ca8551~resize:0:q75.jpg?source=1f5c5e47&expiration=1762311267&auth_key=1762311267-0-0-9052cdb82219cf591714fae257bc03ff&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-b089a7ec427c8ae9c999197336a38995~resize:0:q75.jpg?source=1f5c5e47&expiration=1762311274&auth_key=1762311274-0-0-43af1bc3b53b2ec2376c316c12157e7d&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="D-2-GS-Dense-Depth-Regularization-for-LiDAR-free-Urban-Scene-Reconstruction"><a href="#D-2-GS-Dense-Depth-Regularization-for-LiDAR-free-Urban-Scene-Reconstruction" class="headerlink" title="D$^2$GS: Dense Depth Regularization for LiDAR-free Urban Scene   Reconstruction"></a>D$^2$GS: Dense Depth Regularization for LiDAR-free Urban Scene   Reconstruction</h2><p><strong>Authors:Kejing Xia, Jidong Jia, Ke Jin, Yucai Bai, Li Sun, Dacheng Tao, Youjian Zhang</strong></p>
<p>Recently, Gaussian Splatting (GS) has shown great potential for urban scene reconstruction in the field of autonomous driving. However, current urban scene reconstruction methods often depend on multimodal sensors as inputs, \textit{i.e.} LiDAR and images. Though the geometry prior provided by LiDAR point clouds can largely mitigate ill-posedness in reconstruction, acquiring such accurate LiDAR data is still challenging in practice: i) precise spatiotemporal calibration between LiDAR and other sensors is required, as they may not capture data simultaneously; ii) reprojection errors arise from spatial misalignment when LiDAR and cameras are mounted at different locations. To avoid the difficulty of acquiring accurate LiDAR depth, we propose D$^2$GS, a LiDAR-free urban scene reconstruction framework. In this work, we obtain geometry priors that are as effective as LiDAR while being denser and more accurate. $\textbf{First}$, we initialize a dense point cloud by back-projecting multi-view metric depth predictions. This point cloud is then optimized by a Progressive Pruning strategy to improve the global consistency. $\textbf{Second}$, we jointly refine Gaussian geometry and predicted dense metric depth via a Depth Enhancer. Specifically, we leverage diffusion priors from a depth foundation model to enhance the depth maps rendered by Gaussians. In turn, the enhanced depths provide stronger geometric constraints during Gaussian training. $\textbf{Finally}$, we improve the accuracy of ground geometry by constraining the shape and normal attributes of Gaussians within road regions. Extensive experiments on the Waymo dataset demonstrate that our method consistently outperforms state-of-the-art methods, producing more accurate geometry even when compared with those using ground-truth LiDAR data. </p>
<blockquote>
<p>è¿‘æœŸï¼Œé«˜æ–¯æ‘Šé“ºï¼ˆGSï¼‰åœ¨è‡ªåŠ¨é©¾é©¶é¢†åŸŸçš„åŸå¸‚åœºæ™¯é‡å»ºä¸­æ˜¾ç¤ºå‡ºå·¨å¤§æ½œåŠ›ã€‚ç„¶è€Œï¼Œå½“å‰çš„åŸå¸‚åœºæ™¯é‡å»ºæ–¹æ³•å¾€å¾€ä¾èµ–äºå¤šæ¨¡æ€ä¼ æ„Ÿå™¨ä½œä¸ºè¾“å…¥ï¼Œä¾‹å¦‚æ¿€å…‰é›·è¾¾å’Œå›¾åƒã€‚å°½ç®¡æ¿€å…‰é›·è¾¾ç‚¹äº‘æä¾›çš„å‡ ä½•å…ˆéªŒä¿¡æ¯å¯ä»¥åœ¨å¾ˆå¤§ç¨‹åº¦ä¸Šç¼“è§£é‡å»ºä¸­çš„ä¸é€‚å®šæ€§é—®é¢˜ï¼Œä½†åœ¨å®è·µä¸­è·å–å¦‚æ­¤ç²¾ç¡®çš„æ¿€å…‰é›·è¾¾æ•°æ®ä»ç„¶å…·æœ‰æŒ‘æˆ˜æ€§ï¼šä¸€æ˜¯å¯¹æ¿€å…‰é›·è¾¾ä¸å…¶ä»–ä¼ æ„Ÿå™¨ä¹‹é—´çš„ç²¾ç¡®æ—¶ç©ºæ ‡å®šæœ‰è¦æ±‚ï¼Œå› ä¸ºå®ƒä»¬å¯èƒ½æ— æ³•åŒæ—¶æ•è·æ•°æ®ï¼›äºŒæ˜¯å½“æ¿€å…‰é›·è¾¾å’Œç›¸æœºå®‰è£…åœ¨ä¸åŒçš„ä½ç½®æ—¶ï¼Œä¼šå‡ºç°ç”±ç©ºé—´é”™ä½å¼•èµ·çš„å†æŠ•å½±è¯¯å·®ã€‚ä¸ºäº†é¿å…è·å–å‡†ç¡®æ¿€å…‰é›·è¾¾æ·±åº¦çš„å›°éš¾ï¼Œæˆ‘ä»¬æå‡ºäº†D$^2$GSï¼Œè¿™æ˜¯ä¸€ç§æ— éœ€æ¿€å…‰é›·è¾¾çš„åŸå¸‚åœºæ™¯é‡å»ºæ¡†æ¶ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬è·å¾—äº†ä¸æ¿€å…‰é›·è¾¾åŒæ ·æœ‰æ•ˆçš„å‡ ä½•å…ˆéªŒä¿¡æ¯ï¼ŒåŒæ—¶æ›´åŠ å¯†é›†å’Œå‡†ç¡®ã€‚</p>
</blockquote>
<p><strong>é¦–å…ˆ</strong>ï¼Œæˆ‘ä»¬é€šè¿‡åå‘æŠ•å½±å¤šè§†å›¾åº¦é‡æ·±åº¦é¢„æµ‹æ¥åˆå§‹åŒ–å¯†é›†ç‚¹äº‘ã€‚ç„¶åé‡‡ç”¨æ¸è¿›ä¿®å‰ªç­–ç•¥å¯¹ç‚¹äº‘è¿›è¡Œä¼˜åŒ–ï¼Œä»¥æé«˜å…¨å±€ä¸€è‡´æ€§ã€‚</p>
<p><strong>å…¶æ¬¡</strong>ï¼Œæˆ‘ä»¬é€šè¿‡æ·±åº¦å¢å¼ºå™¨è”åˆä¼˜åŒ–é«˜æ–¯å‡ ä½•å’Œé¢„æµ‹å¯†é›†åº¦é‡æ·±åº¦ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬åˆ©ç”¨æ·±åº¦åŸºç¡€æ¨¡å‹çš„æ‰©æ•£å…ˆéªŒçŸ¥è¯†æ¥å¢å¼ºé«˜æ–¯æ¸²æŸ“çš„æ·±åº¦å›¾ã€‚åè¿‡æ¥ï¼Œå¢å¼ºçš„æ·±åº¦åœ¨é«˜æ–¯è®­ç»ƒè¿‡ç¨‹ä¸­æä¾›äº†æ›´å¼ºçš„å‡ ä½•çº¦æŸã€‚</p>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.25173v2">PDF</a> </p>
<p><strong>æ‘˜è¦</strong></p>
<p>è¿‘æœŸï¼Œé«˜æ–¯èåˆæŠ€æœ¯ï¼ˆGSï¼‰åœ¨è‡ªåŠ¨é©¾é©¶é¢†åŸŸçš„åŸå¸‚åœºæ™¯é‡å»ºä¸­å±•ç°å‡ºå·¨å¤§æ½œåŠ›ã€‚ç„¶è€Œï¼Œå½“å‰çš„åŸå¸‚åœºæ™¯é‡å»ºæ–¹æ³•å¾€å¾€ä¾èµ–äºå¤šæ¨¡æ€ä¼ æ„Ÿå™¨è¾“å…¥ï¼Œå¦‚æ¿€å…‰é›·è¾¾å’Œå›¾åƒã€‚è™½ç„¶æ¿€å…‰é›·è¾¾ç‚¹äº‘æä¾›çš„å‡ ä½•å…ˆéªŒä¿¡æ¯èƒ½å¤Ÿå¤§å¤§å‡å°‘é‡å»ºä¸­çš„ä¸é€‚å®šæ€§ï¼Œä½†åœ¨å®è·µä¸­è·å–å‡†ç¡®çš„æ¿€å…‰é›·è¾¾æ•°æ®ä»ç„¶å…·æœ‰æŒ‘æˆ˜æ€§ï¼šé¦–å…ˆï¼Œæ¿€å…‰é›·è¾¾ä¸å…¶ä»–ä¼ æ„Ÿå™¨ä¹‹é—´çš„ç²¾ç¡®æ—¶ç©ºæ ‡å®šæ˜¯å¿…è¦çš„ï¼Œå› ä¸ºå®ƒä»¬å¯èƒ½æ— æ³•åŒæ—¶æ•è·æ•°æ®ï¼›å…¶æ¬¡ï¼Œå½“æ¿€å…‰é›·è¾¾å’Œç›¸æœºå®‰è£…ä½ç½®ä¸åŒæ—¶ï¼Œä¼šå‡ºç°ç©ºé—´ä¸åŒ¹é…å¯¼è‡´é‡æŠ•å½±è¯¯å·®ã€‚ä¸ºäº†é¿å…è·å–å‡†ç¡®æ¿€å…‰é›·è¾¾æ·±åº¦çš„å›°éš¾ï¼Œæˆ‘ä»¬æå‡ºäº†D$^2$GSï¼Œä¸€ç§æ— éœ€æ¿€å…‰é›·è¾¾çš„åŸå¸‚åœºæ™¯é‡å»ºæ¡†æ¶ã€‚æˆ‘ä»¬çš„æ–¹æ³•èƒ½è·å–ä¸æ¿€å…‰é›·è¾¾åŒæ ·æœ‰æ•ˆçš„å‡ ä½•å…ˆéªŒä¿¡æ¯ï¼ŒåŒæ—¶æ›´å¯†é›†ã€æ›´å‡†ç¡®ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬é€šè¿‡åå‘æŠ•å½±å¤šè§†è§’åº¦é‡æ·±åº¦é¢„æµ‹æ¥åˆå§‹åŒ–å¯†é›†ç‚¹äº‘ï¼Œç„¶åé€šè¿‡æ¸è¿›å‰ªæç­–ç•¥å¯¹å…¶è¿›è¡Œä¼˜åŒ–ï¼Œä»¥æé«˜å…¨å±€ä¸€è‡´æ€§ã€‚å…¶æ¬¡ï¼Œæˆ‘ä»¬é€šè¿‡æ·±åº¦å¢å¼ºå™¨è”åˆä¼˜åŒ–é«˜æ–¯å‡ ä½•å’Œé¢„æµ‹å¯†é›†åº¦é‡æ·±åº¦ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬åˆ©ç”¨æ·±åº¦åŸºç¡€æ¨¡å‹çš„æ‰©æ•£å…ˆéªŒä¿¡æ¯æ¥å¢å¼ºç”±é«˜æ–¯æ¸²æŸ“çš„æ·±åº¦å›¾ã€‚åè¿‡æ¥ï¼Œå¢å¼ºåçš„æ·±åº¦åœ¨è®­ç»ƒé«˜æ–¯æ—¶æä¾›äº†æ›´å¼ºçš„å‡ ä½•çº¦æŸã€‚æœ€åï¼Œæˆ‘ä»¬é€šè¿‡çº¦æŸé“è·¯åŒºåŸŸå†…çš„é«˜æ–¯å½¢çŠ¶å’Œæ³•çº¿å±æ€§æ¥æé«˜åœ°é¢å‡ ä½•çš„å‡†ç¡®æ€§ã€‚åœ¨Waymoæ•°æ®é›†ä¸Šçš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•å§‹ç»ˆä¼˜äºæœ€å…ˆè¿›çš„æ–¹æ³•ï¼Œå³ä½¿åœ¨ä¸ä½¿ç”¨çœŸå®æ¿€å…‰é›·è¾¾æ•°æ®çš„æ–¹æ³•ç›¸æ¯”æ—¶ï¼Œä¹Ÿèƒ½äº§ç”Ÿæ›´å‡†ç¡®çš„å‡ ä½•ç»“æ„ã€‚</p>
<p><strong>è¦ç‚¹æ‘˜è¦</strong></p>
<ol>
<li>é«˜æ–¯èåˆæŠ€æœ¯ï¼ˆGSï¼‰åœ¨åŸå¸‚åœºæ™¯é‡å»ºä¸­å…·æœ‰æ½œåŠ›ã€‚</li>
<li>å½“å‰æ–¹æ³•ä¾èµ–å¤šæ¨¡æ€ä¼ æ„Ÿå™¨ï¼Œå¦‚æ¿€å…‰é›·è¾¾å’Œå›¾åƒï¼Œä½†è·å–å‡†ç¡®æ¿€å…‰é›·è¾¾æ•°æ®å…·æœ‰æŒ‘æˆ˜æ€§ã€‚</li>
<li>æå‡ºD$^2$GSæ¡†æ¶ï¼Œæ— éœ€æ¿€å…‰é›·è¾¾è¿›è¡ŒåŸå¸‚åœºæ™¯é‡å»ºã€‚</li>
<li>é€šè¿‡åå‘æŠ•å½±å¤šè§†è§’åº¦é‡æ·±åº¦é¢„æµ‹åˆå§‹åŒ–å¯†é›†ç‚¹äº‘ï¼Œå¹¶é€šè¿‡æ¸è¿›å‰ªæç­–ç•¥ä¼˜åŒ–ã€‚</li>
<li>è”åˆä¼˜åŒ–é«˜æ–¯å‡ ä½•å’Œé¢„æµ‹æ·±åº¦ï¼Œåˆ©ç”¨æ·±åº¦åŸºç¡€æ¨¡å‹çš„æ‰©æ•£å…ˆéªŒä¿¡æ¯å¢å¼ºæ·±åº¦å›¾ã€‚</li>
<li>å¢å¼ºåçš„æ·±åº¦åœ¨è®­ç»ƒé«˜æ–¯æ—¶æä¾›æ›´å¼ºå‡ ä½•çº¦æŸã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.25173">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-729c08c8feb4449057ba02b5343bf657~resize:0:q75.jpg?source=1f5c5e47&expiration=1762311281&auth_key=1762311281-0-0-442bd0f0f4e2d186b81792dd47cb9203&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-b23900dc53500bd9e91eb177cccfc74b~resize:0:q75.jpg?source=1f5c5e47&expiration=1762311289&auth_key=1762311289-0-0-1fd002b1710632209e11979eba1d3800&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-58c899a334cf40efffae65498ea1a5d8~resize:0:q75.jpg?source=1f5c5e47&expiration=1762311295&auth_key=1762311295-0-0-c8551891ac58c20761edc4ae656ffd0b&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="AtlasGS-Atlanta-world-Guided-Surface-Reconstruction-with-Implicit-Structured-Gaussians"><a href="#AtlasGS-Atlanta-world-Guided-Surface-Reconstruction-with-Implicit-Structured-Gaussians" class="headerlink" title="AtlasGS: Atlanta-world Guided Surface Reconstruction with Implicit   Structured Gaussians"></a>AtlasGS: Atlanta-world Guided Surface Reconstruction with Implicit   Structured Gaussians</h2><p><strong>Authors:Xiyu Zhang, Chong Bao, Yipeng Chen, Hongjia Zhai, Yitong Dong, Hujun Bao, Zhaopeng Cui, Guofeng Zhang</strong></p>
<p>3D reconstruction of indoor and urban environments is a prominent research topic with various downstream applications. However, existing geometric priors for addressing low-texture regions in indoor and urban settings often lack global consistency. Moreover, Gaussian Splatting and implicit SDF fields often suffer from discontinuities or exhibit computational inefficiencies, resulting in a loss of detail. To address these issues, we propose an Atlanta-world guided implicit-structured Gaussian Splatting that achieves smooth indoor and urban scene reconstruction while preserving high-frequency details and rendering efficiency. By leveraging the Atlanta-world model, we ensure the accurate surface reconstruction for low-texture regions, while the proposed novel implicit-structured GS representations provide smoothness without sacrificing efficiency and high-frequency details. Specifically, we propose a semantic GS representation to predict the probability of all semantic regions and deploy a structure plane regularization with learnable plane indicators for global accurate surface reconstruction. Extensive experiments demonstrate that our method outperforms state-of-the-art approaches in both indoor and urban scenes, delivering superior surface reconstruction quality. </p>
<blockquote>
<p>å®¤å†…å’Œå®¤å¤–ç¯å¢ƒçš„3Dé‡å»ºæ˜¯ä¸€ä¸ªé‡è¦çš„ç ”ç©¶ä¸»é¢˜ï¼Œå…·æœ‰å¤šç§ä¸‹æ¸¸åº”ç”¨ã€‚ç„¶è€Œï¼Œé’ˆå¯¹å®¤å†…å’ŒåŸå¸‚ç¯å¢ƒä¸­ä½çº¹ç†åŒºåŸŸçš„ç°æœ‰å‡ ä½•å…ˆéªŒé€šå¸¸ç¼ºä¹å…¨å±€ä¸€è‡´æ€§ã€‚æ­¤å¤–ï¼Œé«˜æ–¯å¹³é“ºå’Œéšå¼SDFåœºç»å¸¸å‡ºç°ä¸è¿ç»­æˆ–è®¡ç®—æ•ˆç‡ä½ä¸‹çš„é—®é¢˜ï¼Œå¯¼è‡´ç»†èŠ‚ä¸¢å¤±ã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§å—äºšç‰¹å…°å¤§ä¸–ç•Œå¼•å¯¼çš„éšå¼ç»“æ„åŒ–é«˜æ–¯å¹³é“ºæ–¹æ³•ï¼Œè¯¥æ–¹æ³•å¯ä»¥å®ç°å®¤å†…å’ŒåŸå¸‚åœºæ™¯çš„å¹³æ»‘é‡å»ºï¼ŒåŒæ—¶ä¿ç•™é«˜é¢‘ç»†èŠ‚å¹¶æé«˜æ¸²æŸ“æ•ˆç‡ã€‚é€šè¿‡åˆ©ç”¨äºšç‰¹å…°å¤§ä¸–ç•Œæ¨¡å‹ï¼Œæˆ‘ä»¬ç¡®ä¿äº†ä½çº¹ç†åŒºåŸŸçš„å‡†ç¡®è¡¨é¢é‡å»ºï¼Œè€Œæˆ‘ä»¬æ‰€æå‡ºçš„æ–°å‹éšå¼ç»“æ„åŒ–GSè¡¨ç¤ºåˆ™æä¾›äº†å¹³æ»‘æ€§ï¼ŒåŒæ—¶ä¸ç‰ºç‰²æ•ˆç‡å’Œé«˜é¢‘ç»†èŠ‚ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§è¯­ä¹‰GSè¡¨ç¤ºï¼Œç”¨äºé¢„æµ‹æ‰€æœ‰è¯­ä¹‰åŒºåŸŸçš„æ¦‚ç‡ï¼Œå¹¶éƒ¨ç½²äº†ä¸€ç§ç»“æ„å¹³é¢æ­£åˆ™åŒ–ä»¥åŠå¯å­¦ä¹ çš„å¹³é¢æŒ‡æ ‡è¿›è¡Œå…¨å±€å‡†ç¡®è¡¨é¢é‡å»ºã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨å®¤å†…å’Œå®¤å¤–åœºæ™¯ä¸­éƒ½ä¼˜äºæœ€æ–°æŠ€æœ¯ï¼Œå¯æä¾›å“è¶Šçš„è¡¨é¢é‡å»ºè´¨é‡ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.25129v1">PDF</a> 18 pages, 11 figures. NeurIPS 2025; Project page:   <a target="_blank" rel="noopener" href="https://zju3dv.github.io/AtlasGS/">https://zju3dv.github.io/AtlasGS/</a></p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºä¸€ç§åŸºäºAtlanta-worldæ¨¡å‹å¼•å¯¼çš„æ–°å‹éšç»“æ„é«˜æ–¯å–·å°„æ³•ï¼ˆGaussian Splattingï¼‰ï¼Œæ—¨åœ¨è§£å†³å®¤å†…å’ŒåŸå¸‚ç¯å¢ƒä¸­ä½çº¹ç†åŒºåŸŸçš„å‡ ä½•å…ˆéªŒç¼ºä¹å…¨å±€ä¸€è‡´æ€§çš„é—®é¢˜ã€‚è¯¥æ–¹æ³•ä¸ä»…èƒ½å¹³æ»‘é‡å»ºåœºæ™¯ï¼Œè¿˜èƒ½ä¿ç•™é«˜é¢‘ç»†èŠ‚å’Œæé«˜æ¸²æŸ“æ•ˆç‡ã€‚é€šè¿‡å¼•å…¥è¯­ä¹‰GSè¡¨ç¤ºå’Œç»“æ„å¹³é¢æ­£åˆ™åŒ–ï¼Œå®ç°äº†å¯¹ä½çº¹ç†åŒºåŸŸçš„å‡†ç¡®è¡¨é¢é‡å»ºå’Œå…¨å±€ç²¾ç¡®è¡¨é¢é‡å»ºã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>3Dé‡å»ºå®¤å†…å’ŒåŸå¸‚ç¯å¢ƒæ˜¯çƒ­é—¨ç ”ç©¶è¯é¢˜ï¼Œå…·æœ‰å¤šç§ä¸‹æ¸¸åº”ç”¨ã€‚</li>
<li>ç°æœ‰å‡ ä½•å…ˆéªŒåœ¨å¤„ç†ä½çº¹ç†åŒºåŸŸæ—¶ç¼ºä¹å…¨å±€ä¸€è‡´æ€§ã€‚</li>
<li>æå‡ºçš„åŸºäºAtlanta-worldæ¨¡å‹å¼•å¯¼çš„æ–°å‹éšç»“æ„é«˜æ–¯å–·å°„æ³•å¯å®ç°å¹³æ»‘çš„å®¤å†…å’ŒåŸå¸‚åœºæ™¯é‡å»ºã€‚</li>
<li>è¯¥æ–¹æ³•èƒ½ä¿ç•™é«˜é¢‘ç»†èŠ‚å¹¶æé«˜æ¸²æŸ“æ•ˆç‡ã€‚</li>
<li>è¯­ä¹‰GSè¡¨ç¤ºç”¨äºé¢„æµ‹æ‰€æœ‰è¯­ä¹‰åŒºåŸŸçš„æ¦‚ç‡ã€‚</li>
<li>å¼•å…¥ç»“æ„å¹³é¢æ­£åˆ™åŒ–ï¼Œé€šè¿‡å¯å­¦ä¹ çš„å¹³é¢æŒ‡æ ‡å®ç°å…¨å±€ç²¾ç¡®è¡¨é¢é‡å»ºã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.25129">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-3a5a8e64e5000bed296d58c86587a6a7~resize:0:q75.jpg?source=1f5c5e47&expiration=1762311303&auth_key=1762311303-0-0-6e1837bdc4ce95d0680cee854b9e818d&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-a86828102cb9b73c2ecb9e5ea13a5a8e~resize:0:q75.jpg?source=1f5c5e47&expiration=1762311310&auth_key=1762311310-0-0-18d39552ebdf6d2edf30eb7948556f51&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-902f33254bab6dd1307057fea0f9b545~resize:0:q75.jpg?source=1f5c5e47&expiration=1762311317&auth_key=1762311317-0-0-6a3e59f24e218b0eecf39d444c9183d4&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1><h2 id="NVSim-Novel-View-Synthesis-Simulator-for-Large-Scale-Indoor-Navigation"><a href="#NVSim-Novel-View-Synthesis-Simulator-for-Large-Scale-Indoor-Navigation" class="headerlink" title="NVSim: Novel View Synthesis Simulator for Large Scale Indoor Navigation"></a>NVSim: Novel View Synthesis Simulator for Large Scale Indoor Navigation</h2><p><strong>Authors:Mingyu Jeong, Eunsung Kim, Sehun Park, Andrew Jaeyong Choi</strong></p>
<p>We present NVSim, a framework that automatically constructs large-scale, navigable indoor simulators from only common image sequences, overcoming the cost and scalability limitations of traditional 3D scanning. Our approach adapts 3D Gaussian Splatting to address visual artifacts on sparsely observed floors a common issue in robotic traversal data. We introduce Floor-Aware Gaussian Splatting to ensure a clean, navigable ground plane, and a novel mesh-free traversability checking algorithm that constructs a topological graph by directly analyzing rendered views. We demonstrate our systemâ€™s ability to generate valid, large-scale navigation graphs from real-world data. A video demonstration is avilable at <a target="_blank" rel="noopener" href="https://youtu.be/tTiIQt6nXC8">https://youtu.be/tTiIQt6nXC8</a> </p>
<blockquote>
<p>æˆ‘ä»¬æ¨å‡ºäº†NVSimï¼Œè¿™æ˜¯ä¸€ä¸ªèƒ½å¤Ÿä»å¸¸è§çš„å›¾åƒåºåˆ—è‡ªåŠ¨æ„å»ºå¤§è§„æ¨¡ã€å¯å¯¼èˆªå®¤å†…æ¨¡æ‹Ÿå™¨çš„æ¡†æ¶ï¼Œå…‹æœäº†ä¼ ç»Ÿ3Dæ‰«æçš„æˆæœ¬å’Œå¯æ‰©å±•æ€§é™åˆ¶ã€‚æˆ‘ä»¬çš„æ–¹æ³•é€‚åº”äº†3Dé«˜æ–¯æ‹¼è´´æŠ€æœ¯ï¼Œä»¥è§£å†³åœ¨æœºå™¨äººéå†æ•°æ®ä¸­å¸¸è§çš„ç¨€ç–è§‚æµ‹åœ°é¢ä¸Šçš„è§†è§‰ä¼ªå½±é—®é¢˜ã€‚æˆ‘ä»¬å¼•å…¥äº†åœ°é¢æ„ŸçŸ¥é«˜æ–¯æ‹¼è´´æŠ€æœ¯ï¼Œä»¥ç¡®ä¿å¹²å‡€ã€å¯å¯¼èˆªçš„åœ°é¢å¹³é¢ï¼Œä»¥åŠä¸€ç§æ–°å‹çš„æ— éœ€ç½‘æ ¼çš„éå†æ€§æ£€æŸ¥ç®—æ³•ï¼Œè¯¥ç®—æ³•é€šè¿‡ç›´æ¥åˆ†ææ¸²æŸ“è§†å›¾æ¥æ„å»ºæ‹“æ‰‘å›¾ã€‚æˆ‘ä»¬å±•ç¤ºäº†æˆ‘ä»¬çš„ç³»ç»Ÿä»çœŸå®ä¸–ç•Œæ•°æ®ç”Ÿæˆæœ‰æ•ˆçš„å¤§è§„æ¨¡å¯¼èˆªå›¾çš„èƒ½åŠ›ã€‚è§†é¢‘æ¼”ç¤ºå¯åœ¨<a target="_blank" rel="noopener" href="https://youtu.be/tTiIQt6nXC8%E8%A7%82%E7%9C%8B%E3%80%82">https://youtu.be/tTiIQt6nXC8è§‚çœ‹ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.24335v1">PDF</a> 9 pages, 10 figures</p>
<p><strong>Summary</strong><br>åŸºäºå¸¸è§çš„å›¾åƒåºåˆ—ï¼ŒNVSimæ¡†æ¶å¯è‡ªåŠ¨æ„å»ºå¤§è§„æ¨¡å¯å¯¼èˆªå®¤å†…æ¨¡æ‹Ÿå™¨ï¼Œè§£å†³äº†ä¼ ç»Ÿ3Dæ‰«æçš„æˆæœ¬å’Œå¯æ‰©å±•æ€§é™åˆ¶é—®é¢˜ã€‚è¯¥æ–¹æ³•é‡‡ç”¨æ”¹è¿›çš„3Dé«˜æ–¯æ‹¼è´´æŠ€æœ¯ï¼Œè§£å†³äº†æœºå™¨äººéå†æ•°æ®åœ¨ç¨€ç–è§‚æµ‹åœ°æ¿ä¸Šå¸¸è§çš„è§†è§‰ä¼ªå½±é—®é¢˜ã€‚é€šè¿‡å¼•å…¥åœ°æ¿æ„ŸçŸ¥é«˜æ–¯æ‹¼è´´æŠ€æœ¯ï¼Œç¡®ä¿æ¸…æ´ã€å¯å¯¼èˆªçš„åœ°é¢å¹³é¢ï¼Œå¹¶é‡‡ç”¨æ–°å‹çš„æ— éœ€ç½‘æ ¼çš„éå†æ€§æ£€æŸ¥ç®—æ³•ï¼Œé€šè¿‡ç›´æ¥åˆ†ææ¸²æŸ“è§†å›¾æ„å»ºæ‹“æ‰‘å›¾ã€‚ç³»ç»Ÿèƒ½å¤Ÿä»çœŸå®ä¸–ç•Œæ•°æ®ç”Ÿæˆæœ‰æ•ˆçš„å¤§è§„æ¨¡å¯¼èˆªå›¾ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>NVSimæ¡†æ¶èƒ½å¤Ÿä»å¸¸è§çš„å›¾åƒåºåˆ—è‡ªåŠ¨æ„å»ºå¤§è§„æ¨¡å¯å¯¼èˆªå®¤å†…æ¨¡æ‹Ÿå™¨ã€‚</li>
<li>NVSimè§£å†³äº†ä¼ ç»Ÿ3Dæ‰«æçš„æˆæœ¬å’Œå¯æ‰©å±•æ€§é™åˆ¶ã€‚</li>
<li>é‡‡ç”¨æ”¹è¿›çš„3Dé«˜æ–¯æ‹¼è´´æŠ€æœ¯å¤„ç†è§†è§‰ä¼ªå½±é—®é¢˜ã€‚</li>
<li>å¼•å…¥åœ°æ¿æ„ŸçŸ¥é«˜æ–¯æ‹¼è´´æŠ€æœ¯ï¼Œç¡®ä¿æ¸…æ´ã€å¯å¯¼èˆªçš„åœ°é¢å¹³é¢ã€‚</li>
<li>é‡‡ç”¨æ— éœ€ç½‘æ ¼çš„éå†æ€§æ£€æŸ¥ç®—æ³•ï¼Œç›´æ¥åˆ†ææ¸²æŸ“è§†å›¾æ„å»ºæ‹“æ‰‘å›¾ã€‚</li>
<li>ç³»ç»Ÿèƒ½å¤Ÿç”Ÿæˆæœ‰æ•ˆçš„å¤§è§„æ¨¡å¯¼èˆªå›¾ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.24335">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-f2af3bf7d60debdb0f904439983b2178~resize:0:q75.jpg?source=1f5c5e47&expiration=1762311325&auth_key=1762311325-0-0-b154e18ec9d63a966820cfef1780d857&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-70a7fba1365932418cc85dd25fae11df~resize:0:q75.jpg?source=1f5c5e47&expiration=1762311332&auth_key=1762311332-0-0-bfc2d83b5408dae643fe387195fa1198&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-459319728a4113a887b758adb0566d76~resize:0:q75.jpg?source=1f5c5e47&expiration=1762311339&auth_key=1762311339-0-0-e2cb6e066fab0f35888b2f41645564ee&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-be5269783f8c543726e0f18ae0c237a9~resize:0:q75.jpg?source=1f5c5e47&expiration=1762311345&auth_key=1762311345-0-0-5e9b8d835630d913baad437dc3903f99&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-e86f6a3a37d958d9867b73ece229e3b3~resize:0:q75.jpg?source=1f5c5e47&expiration=1762311352&auth_key=1762311352-0-0-c211cd2de76be5d0ed1cd5e1f3d6161c&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-87b8c8b6127cabb8904a60316ee24ac3~resize:0:q75.jpg?source=1f5c5e47&expiration=1762311358&auth_key=1762311358-0-0-c6e4b2e22b114766fc85b69828836441&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-9"><a href="#-9" class="headerlink" title=""></a></h1><h2 id="LagMemo-Language-3D-Gaussian-Splatting-Memory-for-Multi-modal-Open-vocabulary-Multi-goal-Visual-Navigation"><a href="#LagMemo-Language-3D-Gaussian-Splatting-Memory-for-Multi-modal-Open-vocabulary-Multi-goal-Visual-Navigation" class="headerlink" title="LagMemo: Language 3D Gaussian Splatting Memory for Multi-modal   Open-vocabulary Multi-goal Visual Navigation"></a>LagMemo: Language 3D Gaussian Splatting Memory for Multi-modal   Open-vocabulary Multi-goal Visual Navigation</h2><p><strong>Authors:Haotian Zhou, Xiaole Wang, He Li, Fusheng Sun, Shengyu Guo, Guolei Qi, Jianghuan Xu, Huijing Zhao</strong></p>
<p>Navigating to a designated goal using visual information is a fundamental capability for intelligent robots. Most classical visual navigation methods are restricted to single-goal, single-modality, and closed set goal settings. To address the practical demands of multi-modal, open-vocabulary goal queries and multi-goal visual navigation, we propose LagMemo, a navigation system that leverages a language 3D Gaussian Splatting memory. During exploration, LagMemo constructs a unified 3D language memory. With incoming task goals, the system queries the memory, predicts candidate goal locations, and integrates a local perception-based verification mechanism to dynamically match and validate goals during navigation. For fair and rigorous evaluation, we curate GOAT-Core, a high-quality core split distilled from GOAT-Bench tailored to multi-modal open-vocabulary multi-goal visual navigation. Experimental results show that LagMemoâ€™s memory module enables effective multi-modal open-vocabulary goal localization, and that LagMemo outperforms state-of-the-art methods in multi-goal visual navigation. Project page: <a target="_blank" rel="noopener" href="https://weekgoodday.github.io/lagmemo">https://weekgoodday.github.io/lagmemo</a> </p>
<blockquote>
<p>ä½¿ç”¨è§†è§‰ä¿¡æ¯å¯¼èˆªåˆ°æŒ‡å®šç›®æ ‡æ˜¯æ™ºèƒ½æœºå™¨äººçš„åŸºæœ¬èƒ½åŠ›ã€‚å¤§å¤šæ•°ä¼ ç»Ÿçš„è§†è§‰å¯¼èˆªæ–¹æ³•ä»…é™äºå•ç›®æ ‡ã€å•æ¨¡æ€å’Œå°é—­é›†åˆç›®æ ‡è®¾ç½®ã€‚ä¸ºäº†è§£å†³å¤šæ¨¡æ€ã€å¼€æ”¾è¯æ±‡ç›®æ ‡æŸ¥è¯¢å’Œå¤šç›®æ ‡è§†è§‰å¯¼èˆªçš„å®é™…éœ€æ±‚ï¼Œæˆ‘ä»¬æå‡ºäº†LagMemoå¯¼èˆªç³»ç»Ÿï¼Œè¯¥ç³»ç»Ÿåˆ©ç”¨è¯­è¨€3Dé«˜æ–¯æ•£æ–‘è®°å¿†ã€‚åœ¨æ¢ç´¢è¿‡ç¨‹ä¸­ï¼ŒLagMemoæ„å»ºäº†ä¸€ä¸ªç»Ÿä¸€çš„3Dè¯­è¨€è®°å¿†ã€‚å¯¹äºè¾“å…¥çš„ä»»åŠ¡ç›®æ ‡ï¼Œç³»ç»Ÿä¼šæŸ¥è¯¢è®°å¿†ï¼Œé¢„æµ‹å€™é€‰ç›®æ ‡ä½ç½®ï¼Œå¹¶ç»“åˆåŸºäºå±€éƒ¨æ„ŸçŸ¥çš„éªŒè¯æœºåˆ¶ï¼Œåœ¨å¯¼èˆªè¿‡ç¨‹ä¸­åŠ¨æ€åŒ¹é…å’ŒéªŒè¯ç›®æ ‡ã€‚ä¸ºäº†è¿›è¡Œå…¬å¹³å’Œä¸¥æ ¼çš„è¯„ä»·ï¼Œæˆ‘ä»¬ä»GOAT-Benchä¸­ç²¾å¿ƒæŒ‘é€‰äº†GOAT-Coreé«˜è´¨é‡æ ¸å¿ƒå­é›†ï¼Œä¸“é—¨ç”¨äºå¤šæ¨¡æ€å¼€æ”¾è¯æ±‡å¤šç›®æ ‡è§†è§‰å¯¼èˆªã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒLagMemoçš„è®°å¿†æ¨¡å—èƒ½å¤Ÿå®ç°æœ‰æ•ˆçš„å¤šæ¨¡æ€å¼€æ”¾è¯æ±‡ç›®æ ‡å®šä½ï¼Œå¹¶ä¸”åœ¨å¤šç›®æ ‡è§†è§‰å¯¼èˆªæ–¹é¢ä¼˜äºæœ€å…ˆè¿›çš„æ–¹æ³•ã€‚é¡¹ç›®é¡µé¢ï¼š<a target="_blank" rel="noopener" href="https://weekgoodday.github.io/lagmemo">https://weekgoodday.github.io/lagmemo</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.24118v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>LagMemoæ˜¯ä¸€ç§é’ˆå¯¹æ™ºèƒ½æœºå™¨äººçš„å¯¼èˆªç³»ç»Ÿçš„æå‡ºï¼Œè§£å†³äº†ç°å®ç¯å¢ƒä¸­çš„å¤šç§æ¨¡æ€ã€å¼€æ”¾å¼è¯æ±‡è¡¨çš„ç›®æ ‡æŸ¥è¯¢å’Œå¤šç›®æ ‡è§†è§‰å¯¼èˆªé—®é¢˜ã€‚è¯¥ç³»ç»Ÿåˆ©ç”¨è¯­è¨€3Dé«˜æ–¯æ··åˆè®°å¿†æŠ€æœ¯ï¼Œæ„å»ºç»Ÿä¸€çš„è¯­è¨€è®°å¿†æ¨¡å‹ï¼Œé€šè¿‡æŸ¥è¯¢è®°å¿†é¢„æµ‹ç›®æ ‡ä½ç½®ï¼Œå¹¶ç»“åˆåŸºäºå±€éƒ¨æ„ŸçŸ¥çš„éªŒè¯æœºåˆ¶è¿›è¡ŒåŠ¨æ€åŒ¹é…å’ŒéªŒè¯ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒLagMemoçš„è®°å¿†æ¨¡å—èƒ½å¤Ÿå®ç°æœ‰æ•ˆçš„å¤šæ¨¡æ€å¼€æ”¾å¼è¯æ±‡è¡¨ç›®æ ‡å®šä½ï¼Œå¹¶åœ¨å¤šç›®æ ‡è§†è§‰å¯¼èˆªæ–¹é¢ä¼˜äºç°æœ‰æŠ€æœ¯ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>LagMemoæ˜¯ä¸€ä¸ªè§£å†³å¤šæ¨¡æ€ã€å¼€æ”¾å¼è¯æ±‡è¡¨å’Œå¤šç›®æ ‡è§†è§‰å¯¼èˆªé—®é¢˜çš„ç³»ç»Ÿã€‚</li>
<li>åˆ©ç”¨è¯­è¨€3Dé«˜æ–¯æ··åˆè®°å¿†æŠ€æœ¯æ„å»ºç»Ÿä¸€çš„è¯­è¨€è®°å¿†æ¨¡å‹ã€‚</li>
<li>é€šè¿‡æŸ¥è¯¢è®°å¿†é¢„æµ‹ç›®æ ‡ä½ç½®ï¼Œå¹¶ç»“åˆå±€éƒ¨æ„ŸçŸ¥è¿›è¡ŒåŠ¨æ€åŒ¹é…å’ŒéªŒè¯ã€‚</li>
<li>GOAT-Coreæ˜¯ä¸€ä¸ªä¸“ä¸ºå¤šæ¨¡æ€å¼€æ”¾å¼è¯æ±‡è¡¨å¤šç›®æ ‡è§†è§‰å¯¼èˆªä»»åŠ¡å®šåˆ¶çš„ä¼˜è´¨æ ¸å¿ƒæ•°æ®é›†ã€‚</li>
<li>å®éªŒç»“æœæ˜¾ç¤ºLagMemoçš„è®°å¿†æ¨¡å—å…·æœ‰æœ‰æ•ˆå®šä½å¤šæ¨¡æ€å¼€æ”¾å¼è¯æ±‡è¡¨ç›®æ ‡çš„èƒ½åŠ›ã€‚</li>
<li>LagMemoåœ¨å¤šç›®æ ‡è§†è§‰å¯¼èˆªæ–¹é¢çš„æ€§èƒ½ä¼˜äºç°æœ‰æŠ€æœ¯ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.24118">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-4f1e0ff41e683f0020705a827a8474c4~resize:0:q75.jpg?source=1f5c5e47&expiration=1762311366&auth_key=1762311366-0-0-480196135a606ee672b01c5f3476cc26&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-df43d09e29ea5d195703e167c2317df6~resize:0:q75.jpg?source=1f5c5e47&expiration=1762311374&auth_key=1762311374-0-0-83e0e5cda978dd1c3922d74514c8cf62&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-900021b8394123a66bb9557fb58b6c1d~resize:0:q75.jpg?source=1f5c5e47&expiration=1762311381&auth_key=1762311381-0-0-f6bfccf7b9fb57196e4a36dc27b927c6&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-721444a5789cad30895eee60be630cb9~resize:0:q75.jpg?source=1f5c5e47&expiration=1762311388&auth_key=1762311388-0-0-769cf2543adce38e11f7fb22cfcdc693&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-a32e40741efbb5fb4eb510be8b8bb8c1~resize:0:q75.jpg?source=1f5c5e47&expiration=1762311395&auth_key=1762311395-0-0-c2a46d3066211a2a5cde394f30b114c2&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-2a826fbbb54066f36aebdb3e2dd65edd~resize:0:q75.jpg?source=1f5c5e47&expiration=1762311401&auth_key=1762311401-0-0-0ecdc675bc519d560d4438c91e6ce74f&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-9b3b93c44822f1033fb2c9bb504348d4~resize:0:q75.jpg?source=1f5c5e47&expiration=1762311408&auth_key=1762311408-0-0-0a2f8878c8215f354bba753b01ce2af9&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-44712e4a707fe303fb04067b9e44ceb0~resize:0:q75.jpg?source=1f5c5e47&expiration=1762311415&auth_key=1762311415-0-0-232456efdea3ecb61f4f7cef79b95489&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-10"><a href="#-10" class="headerlink" title=""></a></h1><h2 id="GauSSmart-Enhanced-3D-Reconstruction-through-2D-Foundation-Models-and-Geometric-Filtering"><a href="#GauSSmart-Enhanced-3D-Reconstruction-through-2D-Foundation-Models-and-Geometric-Filtering" class="headerlink" title="GauSSmart: Enhanced 3D Reconstruction through 2D Foundation Models and   Geometric Filtering"></a>GauSSmart: Enhanced 3D Reconstruction through 2D Foundation Models and   Geometric Filtering</h2><p><strong>Authors:Alexander Valverde, Brian Xu, Yuyin Zhou, Meng Xu, Hongyun Wang</strong></p>
<p>Scene reconstruction has emerged as a central challenge in computer vision, with approaches such as Neural Radiance Fields (NeRF) and Gaussian Splatting achieving remarkable progress. While Gaussian Splatting demonstrates strong performance on large-scale datasets, it often struggles to capture fine details or maintain realism in regions with sparse coverage, largely due to the inherent limitations of sparse 3D training data.   In this work, we propose GauSSmart, a hybrid method that effectively bridges 2D foundational models and 3D Gaussian Splatting reconstruction. Our approach integrates established 2D computer vision techniques, including convex filtering and semantic feature supervision from foundational models such as DINO, to enhance Gaussian-based scene reconstruction. By leveraging 2D segmentation priors and high-dimensional feature embeddings, our method guides the densification and refinement of Gaussian splats, improving coverage in underrepresented areas and preserving intricate structural details.   We validate our approach across three datasets, where GauSSmart consistently outperforms existing Gaussian Splatting in the majority of evaluated scenes. Our results demonstrate the significant potential of hybrid 2D-3D approaches, highlighting how the thoughtful combination of 2D foundational models with 3D reconstruction pipelines can overcome the limitations inherent in either approach alone. </p>
<blockquote>
<p>åœºæ™¯é‡å»ºå·²æˆä¸ºè®¡ç®—æœºè§†è§‰çš„æ ¸å¿ƒæŒ‘æˆ˜ï¼Œç¥ç»è¾å°„åœºï¼ˆNeRFï¼‰å’Œé«˜æ–¯è´´å›¾ï¼ˆGaussian Splattingï¼‰ç­‰æ–¹æ³•å–å¾—äº†æ˜¾è‘—è¿›å±•ã€‚è™½ç„¶é«˜æ–¯è´´å›¾åœ¨å¤§è§„æ¨¡æ•°æ®é›†ä¸Šè¡¨ç°å‡ºå¼ºå¤§çš„æ€§èƒ½ï¼Œä½†åœ¨ç¨€ç–è¦†ç›–çš„åŒºåŸŸæ•æ‰ç²¾ç»†ç»†èŠ‚æˆ–ä¿æŒçœŸå®æ„Ÿæ–¹é¢å¸¸å¸¸é‡åˆ°å›°éš¾ï¼Œè¿™ä¸»è¦æ˜¯ç”±äºç¨€ç–3Dè®­ç»ƒæ•°æ®çš„å›ºæœ‰å±€é™æ€§æ‰€è‡´ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.14270v2">PDF</a> </p>
<p><strong>æ‘˜è¦</strong><br>    æå‡ºäº†ä¸€ç§ç»“åˆäºŒç»´åŸºç¡€æ¨¡å‹å’Œä¸‰ç»´é«˜æ–¯å¹³é“ºé‡å»ºçš„æ··åˆæ–¹æ³•GauSSmartï¼Œè§£å†³äº†åœºæ™¯é‡å»ºä¸­çš„å…³é”®é—®é¢˜ã€‚è¯¥æ–¹æ³•æ•´åˆäº†æˆç†Ÿçš„äºŒç»´è®¡ç®—æœºè§†è§‰æŠ€æœ¯ï¼Œå¦‚å‡¸è¿‡æ»¤å™¨å’Œæ¥è‡ªDINOç­‰åŸºç¡€æ¨¡å‹çš„è¯­ä¹‰ç‰¹å¾ç›‘ç£ï¼Œå¢å¼ºäº†åŸºäºé«˜æ–¯çš„åœºæ™¯é‡å»ºã€‚é€šè¿‡åˆ©ç”¨äºŒç»´åˆ†å‰²å…ˆéªŒå’Œé«˜ç»´ç‰¹å¾åµŒå…¥ï¼Œè¯¥æ–¹æ³•æŒ‡å¯¼é«˜æ–¯å¹³é“ºçš„ç¨ å¯†åŒ–å’Œç²¾ç»†åŒ–ï¼Œæ”¹è¿›äº†ä»£è¡¨æ€§ä¸è¶³åŒºåŸŸçš„è¦†ç›–æƒ…å†µï¼ŒåŒæ—¶ä¿ç•™äº†å¤æ‚ç»“æ„ç»†èŠ‚ã€‚åœ¨ä¸‰ä¸ªæ•°æ®é›†ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼ŒGauSSmartåœ¨å¤§å¤šæ•°è¯„ä¼°åœºæ™¯ä¸­ä¸€è‡´åœ°ä¼˜äºç°æœ‰çš„é«˜æ–¯å¹³é“ºæŠ€æœ¯ï¼Œå±•ç¤ºäº†æ··åˆäºŒç»´-ä¸‰ç»´æ–¹æ³•çš„å·¨å¤§æ½œåŠ›ã€‚</p>
<p><strong>è¦ç‚¹</strong></p>
<ol>
<li>Gaussian Splattingåœ¨å¤§å‹æ•°æ®é›†ä¸Šè¡¨ç°å‡ºå¼ºå¤§çš„æ€§èƒ½ï¼Œä½†åœ¨ç»†èŠ‚æ•æ‰å’Œç¨€ç–åŒºåŸŸçš„ç°å®æ€§ç»´æŒæ–¹é¢å­˜åœ¨æŒ‘æˆ˜ã€‚</li>
<li>æå‡ºäº†ä¸€ç§æ–°çš„æ··åˆæ–¹æ³•GauSSmartï¼Œç»“åˆäº†äºŒç»´åŸºç¡€æ¨¡å‹å’Œä¸‰ç»´Gaussian Splattingé‡å»ºã€‚</li>
<li>é€šè¿‡æ•´åˆæˆç†Ÿçš„äºŒç»´è®¡ç®—æœºè§†è§‰æŠ€æœ¯ï¼ˆå¦‚å‡¸è¿‡æ»¤å™¨å’Œæ¥è‡ªDINOç­‰åŸºç¡€æ¨¡å‹çš„è¯­ä¹‰ç‰¹å¾ç›‘ç£ï¼‰å¢å¼ºäº†Gaussian-basedåœºæ™¯é‡å»ºã€‚</li>
<li>åˆ©ç”¨äºŒç»´åˆ†å‰²å…ˆéªŒå’Œé«˜ç»´ç‰¹å¾åµŒå…¥ï¼Œæ”¹è¿›äº†ç¨€ç–åŒºåŸŸçš„è¦†ç›–å¹¶ä¿ç•™äº†å¤æ‚ç»“æ„ç»†èŠ‚ã€‚</li>
<li>åœ¨å¤šä¸ªæ•°æ®é›†ä¸ŠéªŒè¯äº†GauSSmartçš„æœ‰æ•ˆæ€§ï¼Œè¡¨ç°ä¼˜äºä¼ ç»Ÿçš„é«˜æ–¯Splattingæ–¹æ³•ã€‚</li>
<li>æ˜¾ç¤ºäº†æ··åˆäºŒç»´-ä¸‰ç»´æ–¹æ³•å…‹æœå•ä¸€æ–¹æ³•å±€é™æ€§çš„å·¨å¤§æ½œåŠ›ã€‚</li>
<li>é«˜ç»´åº¦çš„ç‰¹å¾åµŒå…¥å’ŒäºŒç»´åˆ†å‰²å…ˆéªŒå¯¹äºç¨ å¯†åŒ–å’Œç²¾ç»†åŒ–é«˜æ–¯å¹³é“ºèµ·åˆ°äº†å…³é”®ä½œç”¨ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.14270">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-439c6dafcfefaecd87af483474985b50~resize:0:q75.jpg?source=1f5c5e47&expiration=1762311423&auth_key=1762311423-0-0-0949a063058e262ea920ad79d3739ca4&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-ce10a941529e531a97f079066de5d6d9~resize:0:q75.jpg?source=1f5c5e47&expiration=1762311430&auth_key=1762311430-0-0-9d3a60834995be93a7f9eeaa8964a233&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-5410135cd5e523629df20d961f072fa8~resize:0:q75.jpg?source=1f5c5e47&expiration=1762311437&auth_key=1762311437-0-0-394f70134f76380da90e107052397c6d&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-cf51a1426d76308cf72aa9b8477ee678~resize:0:q75.jpg?source=1f5c5e47&expiration=1762311443&auth_key=1762311443-0-0-ab8d4db17e4d59c8ec6e73be5d0867a3&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-a091cc0ae86436254de50778d513e4f1~resize:0:q75.jpg?source=1f5c5e47&expiration=1762311450&auth_key=1762311450-0-0-029ab60b3979cb9ad156bf96f2d42ae6&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-cfaf455274dbb883378f7edb6c713edf~resize:0:q75.jpg?source=1f5c5e47&expiration=1762311457&auth_key=1762311457-0-0-8b2ae1e531345d8eb585417123b84975&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-11"><a href="#-11" class="headerlink" title=""></a></h1><h2 id="Capture-Canonicalize-Splat-Zero-Shot-3D-Gaussian-Avatars-from-Unstructured-Phone-Images"><a href="#Capture-Canonicalize-Splat-Zero-Shot-3D-Gaussian-Avatars-from-Unstructured-Phone-Images" class="headerlink" title="Capture, Canonicalize, Splat: Zero-Shot 3D Gaussian Avatars from   Unstructured Phone Images"></a>Capture, Canonicalize, Splat: Zero-Shot 3D Gaussian Avatars from   Unstructured Phone Images</h2><p><strong>Authors:Emanuel Garbin, Guy Adam, Oded Krams, Zohar Barzelay, Eran Guendelman, Michael Schwarz, Matteo Presutto, Moran Vatelmacher, Yigal Shenkman, Eli Peker, Itai Druker, Uri Patish, Yoav Blum, Max Bluvstein, Junxuan Li, Rawal Khirodkar, Shunsuke Saito</strong></p>
<p>We present a novel, zero-shot pipeline for creating hyperrealistic, identity-preserving 3D avatars from a few unstructured phone images. Existing methods face several challenges: single-view approaches suffer from geometric inconsistencies and hallucinations, degrading identity preservation, while models trained on synthetic data fail to capture high-frequency details like skin wrinkles and fine hair, limiting realism. Our method introduces two key contributions: (1) a generative canonicalization module that processes multiple unstructured views into a standardized, consistent representation, and (2) a transformer-based model trained on a new, large-scale dataset of high-fidelity Gaussian splatting avatars derived from dome captures of real people. This â€œCapture, Canonicalize, Splatâ€ pipeline produces static quarter-body avatars with compelling realism and robust identity preservation from unstructured photos. </p>
<blockquote>
<p>æˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°é¢–çš„é›¶æ ·æœ¬ç®¡é“ï¼Œç”¨äºä»å°‘é‡éç»“æ„åŒ–çš„æ‰‹æœºå›¾åƒä¸­åˆ›å»ºè¶…é€¼çœŸçš„èº«ä»½ä¿ç•™3Då¤´åƒã€‚ç°æœ‰æ–¹æ³•é¢ä¸´è¯¸å¤šæŒ‘æˆ˜ï¼šå•è§†å›¾æ–¹æ³•å—åˆ°å‡ ä½•ä¸ä¸€è‡´å’Œå¹»è§‰çš„å½±å“ï¼ŒæŸå®³èº«ä»½ä¿ç•™ï¼Œè€ŒåŸºäºåˆæˆæ•°æ®è®­ç»ƒçš„æ¨¡å‹æ— æ³•æ•æ‰çš®è‚¤çš±çº¹å’Œç²¾ç»†å¤´å‘ç­‰é«˜é¢‘ç»†èŠ‚ï¼Œé™åˆ¶äº†çœŸå®æ€§ã€‚æˆ‘ä»¬çš„æ–¹æ³•å¼•å…¥äº†ä¸¤ä¸ªå…³é”®è´¡çŒ®ï¼š(1)ä¸€ä¸ªç”Ÿæˆè§„èŒƒåŒ–æ¨¡å—ï¼Œè¯¥æ¨¡å—å°†å¤šä¸ªéç»“æ„åŒ–è§†å›¾å¤„ç†ä¸ºæ ‡å‡†åŒ–ã€ä¸€è‡´æ€§çš„è¡¨ç¤ºï¼›(2)ä¸€ä¸ªåŸºäºå˜å‹å™¨çš„æ–°æ¨¡å‹ï¼Œè¯¥æ¨¡å‹æ˜¯åœ¨ä»çœŸå®äººç‰©çš„ç©¹é¡¶æ•è·çš„é«˜ä¿çœŸé«˜æ–¯å¹³é“ºå¤´åƒçš„å¤§è§„æ¨¡æ•°æ®é›†ä¸Šè®­ç»ƒçš„ã€‚â€œæ•è·ã€è§„èŒƒåŒ–ã€å¹³é“ºâ€ç®¡é“èƒ½å¤Ÿä»éç»“æ„åŒ–ç…§ç‰‡ä¸­äº§ç”Ÿé™æ€çš„å››åˆ†ä¹‹ä¸€èº«ä½“å¤´åƒï¼Œå…·æœ‰å¼•äººæ³¨ç›®çš„çœŸå®æ€§å’Œç¨³å¥çš„èº«ä»½ä¿ç•™ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.14081v3">PDF</a> This work received the Best Paper Honorable Mention at the AMFG   Workshop, ICCV 2025</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†ä¸€ç§å…¨æ–°çš„é›¶æ ·æœ¬ç®¡é“ï¼Œè¯¥ç®¡é“å¯ä»å°‘é‡éç»“æ„åŒ–æ‰‹æœºå›¾åƒä¸­åˆ›å»ºè¶…é€¼çœŸçš„èº«ä»½ä¿ç•™3Då¤´åƒã€‚ç°æœ‰æ–¹æ³•é¢ä¸´å‡ ä½•ä¸ä¸€è‡´æ€§ã€å›¾åƒå˜å½¢ç­‰é—®é¢˜ï¼Œéš¾ä»¥ä¿æŒèº«ä»½çš„ä¸€è‡´æ€§ã€‚æœ¬æ–‡æå‡ºçš„æ–¹æ³•æœ‰ä¸¤ä¸ªå…³é”®è´¡çŒ®ï¼šä¸€æ˜¯ç”Ÿæˆè§„èŒƒæ¨¡å—ï¼Œèƒ½å°†å¤šä¸ªéç»“æ„åŒ–è§†å›¾å¤„ç†æˆæ ‡å‡†åŒ–çš„ä¸€è‡´è¡¨ç¤ºï¼›äºŒæ˜¯åŸºäºè½¬æ¢å™¨çš„æ–°å¤§å‹æ•°æ®é›†æ¨¡å‹è®­ç»ƒæ¨¡å‹è®­ç»ƒäºåŸºäºçœŸå®äººç‰©ç©¹é¡¶æ•æ‰çš„é«˜ä¿çœŸé«˜æ–¯æ¶‚æŠ¹å¤´åƒæ•°æ®é›†ã€‚è¿™ç§â€œæ•æ‰ã€è§„èŒƒã€æ¶‚æŠ¹â€ç®¡é“èƒ½ä»éç»“æ„åŒ–ç…§ç‰‡ä¸­ç”Ÿæˆä»¤äººä¿¡æœçš„å››åˆ†ä¹‹ä¸€èº«ä½“å¤´åƒï¼Œå…·æœ‰é«˜åº¦ç°å®æ„Ÿå’Œå¼ºå¤§çš„èº«ä»½ä¿ç•™èƒ½åŠ›ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æå‡ºäº†ä¸€ç§æ–°çš„é›¶æ ·æœ¬ç®¡é“ç”¨äºåˆ›å»ºè¶…é€¼çœŸçš„èº«ä»½ä¿ç•™çš„3Då¤´åƒã€‚</li>
<li>è§£å†³äº†ç°æœ‰æ–¹æ³•é¢ä¸´çš„å‡ ä½•ä¸ä¸€è‡´æ€§å’Œå›¾åƒå˜å½¢é—®é¢˜ã€‚</li>
<li>ç”Ÿæˆè§„èŒƒæ¨¡å—èƒ½å°†å¤šä¸ªéç»“æ„åŒ–è§†å›¾å¤„ç†æˆæ ‡å‡†åŒ–çš„ä¸€è‡´è¡¨ç¤ºã€‚</li>
<li>åˆ©ç”¨åŸºäºè½¬æ¢å™¨çš„å¤§å‹æ•°æ®é›†æ¨¡å‹è®­ç»ƒäºåŸºäºçœŸå®äººç‰©ç©¹é¡¶æ•æ‰çš„é«˜ä¿çœŸé«˜æ–¯æ¶‚æŠ¹å¤´åƒæ•°æ®é›†ã€‚</li>
<li>è¯¥æ–¹æ³•å®ç°äº†ä»éç»“æ„åŒ–ç…§ç‰‡ç”Ÿæˆé«˜åº¦é€¼çœŸçš„å››åˆ†ä¹‹ä¸€èº«ä½“å¤´åƒçš„èƒ½åŠ›ã€‚</li>
<li>å…·æœ‰é«˜åº¦çš„ç°å®æ„Ÿå’Œå¼ºå¤§çš„èº«ä»½ä¿ç•™èƒ½åŠ›æ˜¯è¯¥æ–¹æ³•çš„æ˜¾è‘—ç‰¹ç‚¹ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.14081">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-7d97fe9413428307c54a449ff6fd1e67~resize:0:q75.jpg?source=1f5c5e47&expiration=1762311464&auth_key=1762311464-0-0-9ca10223bbea8be1ef02b90fd405d7f5&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-f6ec8bf5d9b586a7caa6bbc2d137b0d9~resize:0:q75.jpg?source=1f5c5e47&expiration=1762311471&auth_key=1762311471-0-0-69b00924d2a2bd76f8234d1c985a9f96&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-1c1703e42d1d97e3de556adc726d67f8~resize:0:q75.jpg?source=1f5c5e47&expiration=1762311478&auth_key=1762311478-0-0-2e9782e98176e3e2420b6cbc406bc6e1&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-dbc7217e9083a3baae400e8b07b86206~resize:0:q75.jpg?source=1f5c5e47&expiration=1762311484&auth_key=1762311484-0-0-b4845c3840b6c91918f3fc136c14f466&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-82e29cc3e27099379c6c3c76d77a9f29~resize:0:q75.jpg?source=1f5c5e47&expiration=1762311491&auth_key=1762311491-0-0-d65676a73354f8c59c9995f20aa9e060&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-12"><a href="#-12" class="headerlink" title=""></a></h1><h2 id="Dynamic-Gaussian-Splatting-from-Defocused-and-Motion-blurred-Monocular-Videos"><a href="#Dynamic-Gaussian-Splatting-from-Defocused-and-Motion-blurred-Monocular-Videos" class="headerlink" title="Dynamic Gaussian Splatting from Defocused and Motion-blurred Monocular   Videos"></a>Dynamic Gaussian Splatting from Defocused and Motion-blurred Monocular   Videos</h2><p><strong>Authors:Xuankai Zhang, Junjin Xiao, Qing Zhang</strong></p>
<p>This paper presents a unified framework that allows high-quality dynamic Gaussian Splatting from both defocused and motion-blurred monocular videos. Due to the significant difference between the formation processes of defocus blur and motion blur, existing methods are tailored for either one of them, lacking the ability to simultaneously deal with both of them. Although the two can be jointly modeled as blur kernel-based convolution, the inherent difficulty in estimating accurate blur kernels greatly limits the progress in this direction. In this work, we go a step further towards this direction. Particularly, we propose to estimate per-pixel reliable blur kernels using a blur prediction network that exploits blur-related scene and camera information and is subject to a blur-aware sparsity constraint. Besides, we introduce a dynamic Gaussian densification strategy to mitigate the lack of Gaussians for incomplete regions, and boost the performance of novel view synthesis by incorporating unseen view information to constrain scene optimization. Extensive experiments show that our method outperforms the state-of-the-art methods in generating photorealistic novel view synthesis from defocused and motion-blurred monocular videos. Our code is available at <a target="_blank" rel="noopener" href="https://github.com/hhhddddddd/dydeblur">https://github.com/hhhddddddd/dydeblur</a>. </p>
<blockquote>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ä¸ªç»Ÿä¸€çš„æ¡†æ¶ï¼Œå¯ä»¥ä»å¤±ç„¦å’ŒåŠ¨æ€æ¨¡ç³Šçš„å•ç›®è§†é¢‘ä¸­å®ç°é«˜è´¨é‡åŠ¨æ€é«˜æ–¯æ··åˆã€‚ç”±äºå¤±ç„¦æ¨¡ç³Šå’ŒåŠ¨æ€æ¨¡ç³Šçš„å½¢æˆè¿‡ç¨‹ä¹‹é—´å­˜åœ¨å¾ˆå¤§å·®å¼‚ï¼Œç°æœ‰æ–¹æ³•å¤§å¤šé’ˆå¯¹å…¶ä¸­ä¸€ç§æƒ…å†µï¼Œç¼ºä¹åŒæ—¶å¤„ç†ä¸¤è€…çš„èƒ½åŠ›ã€‚è™½ç„¶å¯ä»¥å°†è¿™ä¸¤è€…å…±åŒå»ºæ¨¡ä¸ºåŸºäºæ¨¡ç³Šæ ¸çš„å·ç§¯ï¼Œä½†ä¼°è®¡å‡†ç¡®æ¨¡ç³Šæ ¸çš„å›ºæœ‰éš¾åº¦æå¤§åœ°é™åˆ¶äº†è¿™ä¸€æ–¹å‘çš„å‘å±•ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬æœè¿™ä¸ªæ–¹å‘è¿ˆå‡ºäº†æ–°çš„ä¸€æ­¥ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬æå‡ºåˆ©ç”¨æ¨¡ç³Šé¢„æµ‹ç½‘ç»œæ¥ä¼°è®¡æ¯ä¸ªåƒç´ å¯é çš„æ¨¡ç³Šæ ¸ï¼Œè¯¥ç½‘ç»œåˆ©ç”¨ä¸æ¨¡ç³Šç›¸å…³çš„åœºæ™¯å’Œç›¸æœºä¿¡æ¯ï¼Œå¹¶å—åˆ°æ¨¡ç³Šæ„ŸçŸ¥ç¨€ç–æ€§çº¦æŸã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§åŠ¨æ€é«˜æ–¯ç¨ å¯†åŒ–ç­–ç•¥ï¼Œä»¥ç¼“è§£ä¸å®Œæ•´åŒºåŸŸçš„é«˜æ–¯ç¼ºä¹é—®é¢˜ï¼Œå¹¶é€šè¿‡èå…¥æœªè§è§†å›¾ä¿¡æ¯æ¥ä¼˜åŒ–åœºæ™¯åˆæˆæ€§èƒ½ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨ä»å¤±ç„¦å’ŒåŠ¨æ€æ¨¡ç³Šçš„å•ç›®è§†é¢‘ä¸­ç”Ÿæˆé€¼çœŸæ–°è§†å›¾æ–¹é¢ä¼˜äºæœ€å…ˆè¿›çš„æ–¹æ³•ã€‚æˆ‘ä»¬çš„ä»£ç å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/hhhddddddd/dydeblur%E4%B8%8A%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/hhhddddddd/dydeblurä¸Šæ‰¾åˆ°ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.10691v3">PDF</a> Accepted to NeurIPS 2025</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ç§ç»Ÿä¸€çš„æ¡†æ¶ï¼Œèƒ½å¤Ÿä»å¤±ç„¦å’ŒåŠ¨æ€æ¨¡ç³Šçš„å•ç›®è§†é¢‘ä¸­å®ç°é«˜è´¨é‡åŠ¨æ€é«˜æ–¯èåˆã€‚ç”±äºå¤±ç„¦æ¨¡ç³Šå’ŒåŠ¨æ€æ¨¡ç³Šå½¢æˆè¿‡ç¨‹çš„æ˜¾è‘—å·®å¼‚ï¼Œç°æœ‰æ–¹æ³•å¤§å¤šé’ˆå¯¹å…¶ä¸­ä¹‹ä¸€ï¼Œç¼ºä¹åŒæ—¶å¤„ç†ä¸¤è€…çš„èƒ½åŠ›ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºæ¨¡ç³Šé¢„æµ‹ç½‘ç»œçš„å¯é æ¨¡ç³Šæ ¸ä¼°è®¡æ–¹æ³•ï¼Œå¹¶ç»“åˆæ¨¡ç³Šæ„ŸçŸ¥ç¨€ç–çº¦æŸï¼Œåˆ©ç”¨åœºæ™¯å’Œç›¸æœºä¿¡æ¯è¿›è¡Œæ¨¡ç³Šç›¸å…³é¢„æµ‹ã€‚æ­¤å¤–ï¼Œè¿˜å¼•å…¥äº†ä¸€ç§åŠ¨æ€é«˜æ–¯ç¨ å¯†åŒ–ç­–ç•¥ï¼Œä»¥ç¼“è§£ä¸å®Œæ•´åŒºåŸŸçš„é«˜æ–¯ç¼ºå¤±é—®é¢˜ï¼Œå¹¶é€šè¿‡èå…¥æœªè§è§†å›¾ä¿¡æ¯æå‡åœºæ™¯ä¼˜åŒ–çš„æ€§èƒ½ã€‚å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨ç”Ÿæˆå¤±ç„¦å’ŒåŠ¨æ€æ¨¡ç³Šå•ç›®è§†é¢‘çš„å…‰ç…§çœŸå®æ„Ÿæ–°è§†å›¾æ–¹é¢ä¼˜äºç°æœ‰æŠ€æœ¯ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æ–‡ç« æå‡ºäº†ä¸€ç§æ–°çš„ç»Ÿä¸€æ¡†æ¶ï¼Œç”¨äºä»å¤±ç„¦å’ŒåŠ¨æ€æ¨¡ç³Šçš„å•ç›®è§†é¢‘ä¸­å®ç°é«˜è´¨é‡åŠ¨æ€é«˜æ–¯èåˆã€‚</li>
<li>ç°æœ‰æ–¹æ³•ä¸»è¦å¤„ç†å¤±ç„¦æ¨¡ç³Šæˆ–åŠ¨æ€æ¨¡ç³Šä¸­çš„ä¸€ç§ï¼Œè€Œè¯¥æ–‡ç« çš„æ–¹æ³•å¯ä»¥åŒæ—¶å¤„ç†ä¸¤è€…ã€‚</li>
<li>è¯¥æ–‡ç« é€šè¿‡æ¨¡ç³Šé¢„æµ‹ç½‘ç»œä¼°è®¡å¯é çš„æ¨¡ç³Šæ ¸ï¼Œå¹¶ç»“åˆæ¨¡ç³Šæ„ŸçŸ¥ç¨€ç–çº¦æŸæ¥å¤„ç†æ¨¡ç³Šç›¸å…³é¢„æµ‹ã€‚</li>
<li>å¼•å…¥äº†ä¸€ç§åŠ¨æ€é«˜æ–¯ç¨ å¯†åŒ–ç­–ç•¥ï¼Œä»¥æ”¹å–„ä¸å®Œæ•´åŒºåŸŸçš„é«˜æ–¯ç¼ºå¤±é—®é¢˜ã€‚</li>
<li>é€šè¿‡èå…¥æœªè§è§†å›¾ä¿¡æ¯æå‡åœºæ™¯ä¼˜åŒ–çš„æ€§èƒ½ã€‚</li>
<li>å®éªŒè¯æ˜è¯¥æ–¹æ³•åœ¨ç”Ÿæˆå¤±ç„¦å’ŒåŠ¨æ€æ¨¡ç³Šå•ç›®è§†é¢‘çš„å…‰ç…§çœŸå®æ„Ÿæ–°è§†å›¾æ–¹é¢ä¼˜äºç°æœ‰æŠ€æœ¯ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.10691">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-3b7da1ea88237aa574ce30999d035df3~resize:0:q75.jpg?source=1f5c5e47&expiration=1762311498&auth_key=1762311498-0-0-59d81700b682b5ddf0168e1b820f77d6&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-86742ee8b328189854c04fe55e727d98~resize:0:q75.jpg?source=1f5c5e47&expiration=1762311506&auth_key=1762311506-0-0-d7a5092f12a871e31d7020c9e66b84d0&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-d8a47db1787487c21cf5fa106d4348ed~resize:0:q75.jpg?source=1f5c5e47&expiration=1762311513&auth_key=1762311513-0-0-8e0b783f23b985af5a831ded645c07d6&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-1e00a16fda493eb4986aa98163d7e4fd~resize:0:q75.jpg?source=1f5c5e47&expiration=1762311519&auth_key=1762311519-0-0-89c385f03f6b308db5f2c088dc1d2dc8&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-13"><a href="#-13" class="headerlink" title=""></a></h1><h2 id="InstDrive-Instance-Aware-3D-Gaussian-Splatting-for-Driving-Scenes"><a href="#InstDrive-Instance-Aware-3D-Gaussian-Splatting-for-Driving-Scenes" class="headerlink" title="InstDrive: Instance-Aware 3D Gaussian Splatting for Driving Scenes"></a>InstDrive: Instance-Aware 3D Gaussian Splatting for Driving Scenes</h2><p><strong>Authors:Hongyuan Liu, Haochen Yu, Bochao Zou, Jianfei Jiang, Qiankun Liu, Jiansheng Chen, Huimin Ma</strong></p>
<p>Reconstructing dynamic driving scenes from dashcam videos has attracted increasing attention due to its significance in autonomous driving and scene understanding. While recent advances have made impressive progress, most methods still unify all background elements into a single representation, hindering both instance-level understanding and flexible scene editing. Some approaches attempt to lift 2D segmentation into 3D space, but often rely on pre-processed instance IDs or complex pipelines to map continuous features to discrete identities. Moreover, these methods are typically designed for indoor scenes with rich viewpoints, making them less applicable to outdoor driving scenarios. In this paper, we present InstDrive, an instance-aware 3D Gaussian Splatting framework tailored for the interactive reconstruction of dynamic driving scene. We use masks generated by SAM as pseudo ground-truth to guide 2D feature learning via contrastive loss and pseudo-supervised objectives. At the 3D level, we introduce regularization to implicitly encode instance identities and enforce consistency through a voxel-based loss. A lightweight static codebook further bridges continuous features and discrete identities without requiring data pre-processing or complex optimization. Quantitative and qualitative experiments demonstrate the effectiveness of InstDrive, and to the best of our knowledge, it is the first framework to achieve 3D instance segmentation in dynamic, open-world driving scenes.More visualizations are available at our project page. </p>
<blockquote>
<p>é‡å»ºè¡Œè½¦åŠ¨æ€åœºæ™¯ä»è¡Œè½¦è®°å½•ä»ªè§†é¢‘å·²ç»å¼•èµ·äº†è¶Šæ¥è¶Šå¤šçš„å…³æ³¨ï¼Œè¿™åœ¨è‡ªåŠ¨é©¾é©¶å’Œåœºæ™¯ç†è§£æ–¹é¢å…·æœ‰é‡è¦æ„ä¹‰ã€‚è™½ç„¶æœ€è¿‘çš„è¿›å±•å·²ç»å–å¾—äº†ä»¤äººå°è±¡æ·±åˆ»çš„è¿›æ­¥ï¼Œä½†å¤§å¤šæ•°æ–¹æ³•ä»ç„¶å°†æ‰€æœ‰èƒŒæ™¯å…ƒç´ ç»Ÿä¸€åˆ°ä¸€ä¸ªå•ä¸€è¡¨ç¤ºä¸­ï¼Œè¿™é˜»ç¢äº†å®ä¾‹çº§åˆ«çš„ç†è§£å’Œçµæ´»çš„åœºæ™¯ç¼–è¾‘ã€‚ä¸€äº›æ–¹æ³•è¯•å›¾å°†2Dåˆ†å‰²æå‡åˆ°3Dç©ºé—´ï¼Œä½†é€šå¸¸ä¾èµ–äºé¢„å…ˆå¤„ç†çš„å®ä¾‹IDæˆ–å¤æ‚çš„ç®¡é“æ¥å°†è¿ç»­ç‰¹å¾æ˜ å°„åˆ°ç¦»æ•£èº«ä»½ã€‚è€Œä¸”ï¼Œè¿™äº›æ–¹æ³•é€šå¸¸é’ˆå¯¹å®¤å†…åœºæ™¯è®¾è®¡ï¼Œè§†ç‚¹ä¸°å¯Œï¼Œä½¿å…¶ä¸å¤ªé€‚åˆå®¤å¤–é©¾é©¶åœºæ™¯ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸“ä¸ºåŠ¨æ€é©¾é©¶åœºæ™¯çš„äº¤äº’å¼é‡å»ºé‡èº«å®šåˆ¶çš„å®ä¾‹æ„ŸçŸ¥3Dé«˜æ–¯Splattingæ¡†æ¶â€”â€”InstDriveã€‚æˆ‘ä»¬ä½¿ç”¨SAMç”Ÿæˆçš„è’™ç‰ˆä½œä¸ºä¼ªçœŸå®æ ‡ç­¾ï¼Œé€šè¿‡å¯¹æ¯”æŸå¤±å’Œä¼ªç›‘ç£ç›®æ ‡æ¥æŒ‡å¯¼2Dç‰¹å¾å­¦ä¹ ã€‚åœ¨3Då±‚é¢ï¼Œæˆ‘ä»¬å¼•å…¥æ­£åˆ™åŒ–æ¥éšå¼ç¼–ç å®ä¾‹èº«ä»½å¹¶é€šè¿‡åŸºäºä½“ç´ çš„æŸå¤±å¼ºåˆ¶æ‰§è¡Œä¸€è‡´æ€§ã€‚ä¸€ä¸ªè½»é‡çº§çš„é™æ€ç æœ¬è¿›ä¸€æ­¥è¿æ¥è¿ç»­ç‰¹å¾å’Œç¦»æ•£èº«ä»½ï¼Œæ— éœ€æ•°æ®é¢„å¤„ç†æˆ–å¤æ‚çš„ä¼˜åŒ–ã€‚å®šé‡å’Œå®šæ€§å®éªŒè¯æ˜äº†InstDriveçš„æœ‰æ•ˆæ€§ï¼Œæ®æˆ‘ä»¬æ‰€çŸ¥ï¼Œå®ƒæ˜¯ç¬¬ä¸€ä¸ªå®ç°åœ¨åŠ¨æ€ã€å¼€æ”¾ä¸–ç•Œé©¾é©¶åœºæ™¯ä¸­3Då®ä¾‹åˆ†å‰²çš„æ¡†æ¶ã€‚æ›´å¤šçš„å¯è§†åŒ–å†…å®¹å¯åœ¨æˆ‘ä»¬çš„é¡¹ç›®é¡µé¢æŸ¥çœ‹ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.12015v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>è¯¥æ–‡æœ¬æå‡ºäº†ä¸€ç§åä¸ºInstDriveçš„äº¤äº’å¼é‡å»ºåŠ¨æ€é©¾é©¶åœºæ™¯çš„å®ä¾‹æ„ŸçŸ¥3Dé«˜æ–¯æ¶‚æŠ¹æ¡†æ¶ã€‚å®ƒé€šè¿‡ç”Ÿæˆå¯¹æŠ—æ©æ¨¡æ¥å¼•å¯¼ç‰¹å¾å­¦ä¹ ï¼ŒåŒæ—¶åœ¨3Dçº§åˆ«å¼•å…¥æ­£åˆ™åŒ–éšå¼ç¼–ç å®ä¾‹èº«ä»½å’Œå¼ºåˆ¶ä¸€è‡´æ€§ã€‚æ¡†æ¶å¯åœ¨æ— é¢„å¤„ç†å¤æ‚ä¼˜åŒ–å’Œæ•°æ®é¢„å¤„ç†çš„æƒ…å¢ƒä¸‹è¿æ¥è¿ç»­ç‰¹å¾å’Œç¦»æ•£èº«ä»½ã€‚æ­¤ä¸ºåŠ¨æ€ã€å¼€æ”¾ä¸–ç•Œé©¾é©¶åœºæ™¯ä¸­çš„é¦–ä¸ªå®ç°3Då®ä¾‹åˆ†å‰²çš„æ¡†æ¶ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>åŠ¨æ€é©¾é©¶åœºæ™¯çš„é‡å»ºå·²æˆä¸ºè‡ªä¸»é©¾é©¶å’Œåœºæ™¯ç†è§£çš„é‡è¦ç ”ç©¶æ–¹å‘ã€‚</li>
<li>ç›®å‰å¤§å¤šæ•°æ–¹æ³•æ— æ³•åŒºåˆ†èƒŒæ™¯å…ƒç´ çš„å®ä¾‹çº§åˆ«ï¼Œå½±å“äº†å¯¹åœºæ™¯çš„ç†è§£å’Œç¼–è¾‘çµæ´»æ€§ã€‚</li>
<li>è¯¥æ–‡æœ¬æå‡ºäº†ä¸€ç§åä¸ºInstDriveçš„æ–°æ¡†æ¶ï¼Œæ—¨åœ¨å®ç°åŠ¨æ€é©¾é©¶åœºæ™¯çš„äº¤äº’å¼é‡å»ºï¼Œå¹¶ç‰¹åˆ«å…³æ³¨å®ä¾‹æ„ŸçŸ¥çš„3Dåˆ†å‰²ã€‚</li>
<li>ä½¿ç”¨SAMç”Ÿæˆçš„æ©æ¨¡ä½œä¸ºä¼ªçœŸå®æ ‡ç­¾æ¥å¼•å¯¼ç‰¹å¾å­¦ä¹ ã€‚</li>
<li>åœ¨3Då±‚é¢å¼•å…¥æ­£åˆ™åŒ–ï¼Œéšå¼ç¼–ç å®ä¾‹èº«ä»½å¹¶å¼ºåˆ¶ä¸€è‡´æ€§ã€‚</li>
<li>é€šè¿‡è½»é‡çº§é™æ€ä»£ç æœ¬æ¡¥æ¥è¿ç»­ç‰¹å¾å’Œç¦»æ•£èº«ä»½ï¼Œæ— éœ€æ•°æ®é¢„å¤„ç†æˆ–å¤æ‚ä¼˜åŒ–ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.12015">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-19bbe68d4bb7ba49bf0d43bfb40fdbd1~resize:0:q75.jpg?source=1f5c5e47&expiration=1762311527&auth_key=1762311527-0-0-8a8711899e0b3e3eb324da9c339f2205&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-71b30a80b2e0730822ec28e391cc0f7c~resize:0:q75.jpg?source=1f5c5e47&expiration=1762311535&auth_key=1762311535-0-0-4f832d02a9db4b7b9d1cafa884b7e74a&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-f66b2dfb1f5e6db1642b7f8aafbf33bd~resize:0:q75.jpg?source=1f5c5e47&expiration=1762311542&auth_key=1762311542-0-0-b4a7aaf15f7bdc760aa4e9a529e57469&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-e579047780fbbc1d92929dc5740c7bdd~resize:0:q75.jpg?source=1f5c5e47&expiration=1762311549&auth_key=1762311549-0-0-b4fb3992f25d0930f1aa13729b83ce89&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-14"><a href="#-14" class="headerlink" title=""></a></h1><h2 id="MILo-Mesh-In-the-Loop-Gaussian-Splatting-for-Detailed-and-Efficient-Surface-Reconstruction"><a href="#MILo-Mesh-In-the-Loop-Gaussian-Splatting-for-Detailed-and-Efficient-Surface-Reconstruction" class="headerlink" title="MILo: Mesh-In-the-Loop Gaussian Splatting for Detailed and Efficient   Surface Reconstruction"></a>MILo: Mesh-In-the-Loop Gaussian Splatting for Detailed and Efficient   Surface Reconstruction</h2><p><strong>Authors:Antoine GuÃ©don, Diego Gomez, Nissim Maruani, Bingchen Gong, George Drettakis, Maks Ovsjanikov</strong></p>
<p>While recent advances in Gaussian Splatting have enabled fast reconstruction of high-quality 3D scenes from images, extracting accurate surface meshes remains a challenge. Current approaches extract the surface through costly post-processing steps, resulting in the loss of fine geometric details or requiring significant time and leading to very dense meshes with millions of vertices. More fundamentally, the a posteriori conversion from a volumetric to a surface representation limits the ability of the final mesh to preserve all geometric structures captured during training. We present MILo, a novel Gaussian Splatting framework that bridges the gap between volumetric and surface representations by differentiably extracting a mesh from the 3D Gaussians. We design a fully differentiable procedure that constructs the mesh-including both vertex locations and connectivity-at every iteration directly from the parameters of the Gaussians, which are the only quantities optimized during training. Our method introduces three key technical contributions: a bidirectional consistency framework ensuring both representations-Gaussians and the extracted mesh-capture the same underlying geometry during training; an adaptive mesh extraction process performed at each training iteration, which uses Gaussians as differentiable pivots for Delaunay triangulation; a novel method for computing signed distance values from the 3D Gaussians that enables precise surface extraction while avoiding geometric erosion. Our approach can reconstruct complete scenes, including backgrounds, with state-of-the-art quality while requiring an order of magnitude fewer mesh vertices than previous methods. Due to their light weight and empty interior, our meshes are well suited for downstream applications such as physics simulations or animation. </p>
<blockquote>
<p>è™½ç„¶é«˜æ–¯æ¶‚æŠ¹ï¼ˆGaussian Splattingï¼‰çš„è¿‘æœŸè¿›å±•å·²ç»å®ç°äº†ä»å›¾åƒå¿«é€Ÿé‡å»ºé«˜è´¨é‡çš„ä¸‰ç»´åœºæ™¯ï¼Œä½†æå–ç²¾ç¡®çš„è¡¨é¢ç½‘æ ¼ä»ç„¶æ˜¯ä¸€ä¸ªæŒ‘æˆ˜ã€‚å½“å‰çš„æ–¹æ³•é€šè¿‡æ˜‚è´µçš„åå¤„ç†æ­¥éª¤æå–è¡¨é¢ï¼Œå¯¼è‡´ä¸¢å¤±äº†ç²¾ç»†çš„å‡ ä½•ç»†èŠ‚ï¼Œæˆ–è€…éœ€è¦èŠ±è´¹å¤§é‡æ—¶é—´ï¼Œå¹¶äº§ç”Ÿéå¸¸å¯†é›†çš„ç½‘æ ¼ï¼ŒåŒ…å«æ•°ç™¾ä¸‡ä¸ªé¡¶ç‚¹ã€‚æ›´æ ¹æœ¬çš„æ˜¯ï¼Œä»ä½“ç§¯è¡¨ç¤ºåˆ°è¡¨é¢è¡¨ç¤ºçš„åæœŸè½¬æ¢é™åˆ¶äº†æœ€ç»ˆç½‘æ ¼ä¿ç•™åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­æ•è·çš„æ‰€æœ‰å‡ ä½•ç»“æ„çš„èƒ½åŠ›ã€‚æˆ‘ä»¬æå‡ºäº†MILoï¼Œè¿™æ˜¯ä¸€ç§æ–°å‹çš„é«˜æ–¯æ¶‚æŠ¹æ¡†æ¶ï¼Œå®ƒé€šè¿‡ä»ä¸‰ç»´é«˜æ–¯ä¸­å¯å¾®æå–ç½‘æ ¼æ¥å¼¥åˆä½“ç§¯è¡¨ç¤ºå’Œè¡¨é¢è¡¨ç¤ºä¹‹é—´çš„å·®è·ã€‚æˆ‘ä»¬è®¾è®¡äº†ä¸€ç§å®Œå…¨å¯å¾®åˆ†çš„ç¨‹åºï¼Œå®ƒå¯ä»¥ç›´æ¥ä»é«˜æ–¯çš„å‚æ•°ï¼ˆåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å”¯ä¸€è¢«ä¼˜åŒ–çš„é‡ï¼‰ä¸­ï¼Œåœ¨æ¯æ¬¡è¿­ä»£æ—¶æ„å»ºç½‘æ ¼ï¼ŒåŒ…æ‹¬é¡¶ç‚¹çš„ä½ç½®å’Œè¿æ¥ã€‚æˆ‘ä»¬çš„æ–¹æ³•å¼•å…¥äº†ä¸‰é¡¹å…³é”®çš„æŠ€æœ¯è´¡çŒ®ï¼šä¸€ç§åŒå‘ä¸€è‡´æ€§æ¡†æ¶ï¼Œç¡®ä¿é«˜æ–¯å’Œæå–çš„ç½‘æ ¼åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­æ•è·ç›¸åŒçš„åº•å±‚å‡ ä½•ï¼›ä¸€ç§åœ¨æ¯ä¸ªè®­ç»ƒè¿­ä»£ä¸­è¿›è¡Œçš„è‡ªé€‚åº”ç½‘æ ¼æå–è¿‡ç¨‹ï¼Œå®ƒä½¿ç”¨é«˜æ–¯ä½œä¸ºDelaunayä¸‰è§’å‰–åˆ†çš„å¯å¾®åˆ†æ”¯ç‚¹ï¼›ä¸€ç§ä»ä¸‰ç»´é«˜æ–¯è®¡ç®—å¸¦ç¬¦å·è·ç¦»å€¼çš„æ–°æ–¹æ³•ï¼Œå®ƒèƒ½å¤Ÿå®ç°ç²¾ç¡®çš„è¡¨é¢æå–ï¼ŒåŒæ—¶é¿å…å‡ ä½•ä¾µèš€ã€‚æˆ‘ä»¬çš„æ–¹æ³•å¯ä»¥é‡å»ºåŒ…æ‹¬èƒŒæ™¯åœ¨å†…çš„å®Œæ•´åœºæ™¯ï¼Œè¾¾åˆ°æœ€å…ˆè¿›çš„å“è´¨ï¼ŒåŒæ—¶æ‰€éœ€çš„ç½‘æ ¼é¡¶ç‚¹æ¯”ä»¥å‰çš„æ–¹æ³•å°‘ä¸€ä¸ªæ•°é‡çº§ã€‚ç”±äºæˆ‘ä»¬çš„ç½‘æ ¼è½»å·§ä¸”å†…éƒ¨ä¸ºç©ºï¼Œå› æ­¤éå¸¸é€‚åˆç”¨äºç‰©ç†æ¨¡æ‹Ÿæˆ–åŠ¨ç”»ç­‰ä¸‹æ¸¸åº”ç”¨ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.24096v2">PDF</a> 10 pages. A presentation video of our approach is available at   <a target="_blank" rel="noopener" href="https://youtu.be/_SGNhhNz0fE">https://youtu.be/_SGNhhNz0fE</a></p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†åŸºäºé«˜æ–¯æ‹¼è´´çš„æ–°æ–¹æ³•MILOï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ç›´æ¥ä»é«˜æ–¯å‚æ•°æ„å»ºç½‘æ ¼ï¼Œå®ç°é«˜è´¨é‡çš„ä¸‰ç»´åœºæ™¯é‡å»ºã€‚MILOé€šè¿‡å¯å¾®åˆ†çš„ç¨‹åºæå–ç½‘æ ¼ï¼ŒåŒ…å«é¡¶ç‚¹ä½ç½®å’Œè¿æ¥ä¿¡æ¯ï¼Œå¹¶å¼•å…¥ä¸‰é¡¹å…³é”®æŠ€æœ¯è´¡çŒ®ï¼šç¡®ä¿é«˜æ–¯å’Œæå–ç½‘æ ¼æ•æ‰ç›¸åŒåº•å±‚å‡ ä½•çš„åŒå‘ä¸€è‡´æ€§æ¡†æ¶ï¼›ä»¥é«˜æ–¯ä½œä¸ºå¯å¾®åˆ†ä¸­å¿ƒçš„è‡ªé€‚åº”ç½‘æ ¼æå–è¿‡ç¨‹ï¼›è®¡ç®—ä»ä¸‰ç»´é«˜æ–¯ä¸­ç²¾ç¡®æå–è¡¨é¢çš„å¸¦ç¬¦å·è·ç¦»å€¼çš„æ–°æ–¹æ³•ã€‚è¯¥æ–¹æ³•èƒ½å¤Ÿé‡å»ºåŒ…æ‹¬èƒŒæ™¯åœ¨å†…çš„å®Œæ•´åœºæ™¯ï¼Œä½¿ç”¨æ¯”ä¼ ç»Ÿæ–¹æ³•æ›´å°‘ä¸€ä¸ªæ•°é‡çº§çš„ç½‘æ ¼é¡¶ç‚¹ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>MILOæ˜¯ä¸€ç§åŸºäºé«˜æ–¯æ‹¼è´´çš„æ–°æ–¹æ³•ï¼Œå®ç°äº†é«˜è´¨é‡çš„ä¸‰ç»´åœºæ™¯é‡å»ºã€‚</li>
<li>ä¼ ç»Ÿçš„ç½‘æ ¼æå–æ–¹æ³•æˆæœ¬é«˜ä¸”å¯èƒ½æŸå¤±ç»†èŠ‚ï¼Œè€ŒMILOèƒ½å¤Ÿåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ç›´æ¥æ„å»ºç½‘æ ¼ï¼Œå‡å°‘äº†å¤æ‚çš„åæœŸå¤„ç†æ­¥éª¤ã€‚</li>
<li>MILOçš„ä¸»è¦æŠ€æœ¯è´¡çŒ®åŒ…æ‹¬åŒå‘ä¸€è‡´æ€§æ¡†æ¶ã€è‡ªé€‚åº”ç½‘æ ¼æå–è¿‡ç¨‹å’Œè®¡ç®—å¸¦ç¬¦å·è·ç¦»å€¼çš„æ–°æ–¹æ³•ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.24096">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-f3b6d60c2c7ecfb8cf99b9e57b7f3ebb~resize:0:q75.jpg?source=1f5c5e47&expiration=1762311556&auth_key=1762311556-0-0-bae3f1329c6d1a43b0ba37c3da5c3fd1&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-3896d8b186582f10de4c748f2f554212~resize:0:q75.jpg?source=1f5c5e47&expiration=1762311564&auth_key=1762311564-0-0-cfd9dc17c924ed1bc6e2ebb59ce4079b&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-aa17c7cb26ea820c32400714a65494ed~resize:0:q75.jpg?source=1f5c5e47&expiration=1762311571&auth_key=1762311571-0-0-b24d5dd232be6bc2b09bc8909535e7d7&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-d409a52f864cea816c0c84072bc3b829~resize:0:q75.jpg?source=1f5c5e47&expiration=1762311577&auth_key=1762311577-0-0-4ab734d2c6a37d2a4de07047b1d48c1c&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-15"><a href="#-15" class="headerlink" title=""></a></h1><h2 id="Anti-Aliased-2D-Gaussian-Splatting"><a href="#Anti-Aliased-2D-Gaussian-Splatting" class="headerlink" title="Anti-Aliased 2D Gaussian Splatting"></a>Anti-Aliased 2D Gaussian Splatting</h2><p><strong>Authors:Mae Younes, Adnane Boukhayma</strong></p>
<p>2D Gaussian Splatting (2DGS) has recently emerged as a promising method for novel view synthesis and surface reconstruction, offering better view-consistency and geometric accuracy than volumetric 3DGS. However, 2DGS suffers from severe aliasing artifacts when rendering at different sampling rates than those used during training, limiting its practical applications in scenarios requiring camera zoom or varying fields of view. We identify that these artifacts stem from two key limitations: the lack of frequency constraints in the representation and an ineffective screen-space clamping approach. To address these issues, we present AA-2DGS, an anti-aliased formulation of 2D Gaussian Splatting that maintains its geometric benefits while significantly enhancing rendering quality across different scales. Our method introduces a world-space flat smoothing kernel that constrains the frequency content of 2D Gaussian primitives based on the maximal sampling frequency from training views, effectively eliminating high-frequency artifacts when zooming in. Additionally, we derive a novel object-space Mip filter by leveraging an affine approximation of the ray-splat intersection mapping, which allows us to efficiently apply proper anti-aliasing directly in the local space of each splat. </p>
<blockquote>
<p>äºŒç»´é«˜æ–¯è´´ç‰‡ï¼ˆ2DGSï¼‰ä½œä¸ºä¸€ç§æ–°å…´æŠ€æœ¯ï¼Œåœ¨æ–°å‹è§†å›¾åˆæˆå’Œè¡¨é¢é‡å»ºé¢†åŸŸå±•ç°å‡ºå·¨å¤§çš„æ½œåŠ›ï¼Œç›¸è¾ƒäºä½“ç§¯ä¸‰ç»´é«˜æ–¯è´´ç‰‡ï¼ˆ3DGSï¼‰ï¼Œå®ƒåœ¨è§†å›¾ä¸€è‡´æ€§å’Œå‡ ä½•ç²¾åº¦æ–¹é¢è¡¨ç°æ›´ä½³ã€‚ç„¶è€Œï¼Œå½“åœ¨ä¸åŒäºè®­ç»ƒæ—¶ä½¿ç”¨çš„é‡‡æ ·ç‡è¿›è¡Œæ¸²æŸ“æ—¶ï¼ŒäºŒç»´é«˜æ–¯è´´ç‰‡ä¼šå‡ºç°ä¸¥é‡çš„æ··å ä¼ªå½±ï¼Œé™åˆ¶äº†å…¶åœ¨ç›¸æœºç¼©æ”¾æˆ–å˜åŒ–è§†é‡åœºæ™¯ä¸­çš„å®é™…åº”ç”¨ã€‚æˆ‘ä»¬ç¡®å®šäº†è¿™äº›ä¼ªå½±æºäºä¸¤ä¸ªä¸»è¦å±€é™ï¼šè¡¨ç¤ºä¸­ç¼ºä¹é¢‘ç‡çº¦æŸä»¥åŠå±å¹•ç©ºé—´å¤¹æŒæ–¹æ³•æ— æ•ˆã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†æŠ—æ··å äºŒç»´é«˜æ–¯è´´ç‰‡ï¼ˆAA-2DGSï¼‰ï¼Œè¿™æ˜¯ä¸€ç§ä¿æŒå‡ ä½•ä¼˜åŠ¿çš„åŒæ—¶æ˜¾è‘—æé«˜ä¸åŒå°ºåº¦æ¸²æŸ“è´¨é‡çš„æŠ—æ··å äºŒç»´é«˜æ–¯è´´ç‰‡æ–¹æ³•ã€‚æˆ‘ä»¬çš„æ–¹æ³•å¼•å…¥äº†ä¸€ä¸ªä¸–ç•Œç©ºé—´å¹³é¢å¹³æ»‘æ ¸ï¼Œæ ¹æ®è®­ç»ƒè§†å›¾çš„æœ€é«˜é‡‡æ ·é¢‘ç‡çº¦æŸäºŒç»´é«˜æ–¯åŸºå…ƒçš„é¢‘ç‡å†…å®¹ï¼Œä»è€Œåœ¨æ”¾å¤§æ—¶æœ‰æ•ˆæ¶ˆé™¤é«˜é¢‘ä¼ªå½±ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬é€šè¿‡åˆ©ç”¨å°„çº¿è´´ç‰‡äº¤ç‚¹æ˜ å°„çš„ä»¿å°„è¿‘ä¼¼ï¼Œæ¨å¯¼äº†ä¸€ç§æ–°å‹çš„å¯¹è±¡ç©ºé—´Mipæ»¤æ³¢å™¨ï¼Œè¿™ä½¿æˆ‘ä»¬èƒ½å¤Ÿåœ¨æ¯ä¸ªè´´ç‰‡çš„å±€éƒ¨ç©ºé—´ä¸­ç›´æ¥æœ‰æ•ˆåœ°åº”ç”¨é€‚å½“çš„æŠ—æ··å å¤„ç†ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.11252v2">PDF</a> NeurIPS 2025. Code will be available at   <a target="_blank" rel="noopener" href="https://github.com/maeyounes/AA-2DGS">https://github.com/maeyounes/AA-2DGS</a></p>
<p><strong>Summary</strong></p>
<p>è¿™ç¯‡æ‘˜è¦ä»‹ç»äº†äºŒç»´é«˜æ–¯é‡‡æ ·æŠ€æœ¯ï¼ˆ2DGSï¼‰çš„å±€é™æ€§å’ŒæŠ—é”¯é½¿å¤„ç†è§£å†³æ–¹æ¡ˆã€‚æ–‡ç« æŒ‡å‡ºï¼Œå°½ç®¡å…¶åœ¨æ–°å‹è§†è§’åˆæˆå’Œè¡¨é¢é‡å»ºé¢†åŸŸè¡¨ç°ä¼˜å¼‚ï¼Œä½†åœ¨ä¸åŒé‡‡æ ·ç‡ä¸‹è¿›è¡Œæ¸²æŸ“æ—¶ä¼šå‡ºç°ä¸¥é‡çš„é”¯é½¿çŠ¶ä¼ªå½±ï¼Œé™åˆ¶äº†å…¶åœ¨ç›¸æœºç¼©æ”¾æˆ–ä¸åŒè§†è§’åœºæ™¯ä¸­çš„åº”ç”¨ã€‚æ–‡ç« æå‡ºäº†AA-2DGSæ–¹æ¡ˆï¼Œé€šè¿‡å¼•å…¥ä¸–ç•Œç©ºé—´å¹³é¢å¹³æ»‘æ ¸å’Œå¯¹è±¡ç©ºé—´Mipæ»¤é•œæŠ€æœ¯ï¼Œæ¶ˆé™¤äº†é”¯é½¿çŠ¶ä¼ªå½±å¹¶æå‡äº†æ¸²æŸ“è´¨é‡ã€‚è¿™ä¸€æŠ€æœ¯å¢å¼ºäº†é«˜é¢‘ä¿¡æ¯çš„å¤„ç†ï¼Œä¼˜åŒ–äº†è§†è§‰æ•ˆæœã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>äºŒç»´é«˜æ–¯é‡‡æ ·æŠ€æœ¯ï¼ˆ2DGSï¼‰åœ¨è§†è§’åˆæˆå’Œè¡¨é¢é‡å»ºé¢†åŸŸè¡¨ç°ä¼˜å¼‚ï¼Œä½†åœ¨ä¸åŒé‡‡æ ·ç‡ä¸‹æ¸²æŸ“æ—¶å‡ºç°ä¸¥é‡çš„é”¯é½¿çŠ¶ä¼ªå½±ã€‚è¿™é™åˆ¶äº†å®ƒåœ¨éœ€è¦ç›¸æœºç¼©æ”¾æˆ–ä¸åŒè§†é‡åœºæ™¯ä¸­çš„å®é™…åº”ç”¨ã€‚è¿™äº›ä¼ªå½±æ˜¯ç”±äºè¡¨ç¤ºä¸­çš„é¢‘ç‡çº¦æŸä¸è¶³å’Œå±å¹•ç©ºé—´å¤¹æŒæ–¹æ³•æ— æ•ˆå¯¼è‡´çš„ã€‚</li>
<li>AA-2DGSæ˜¯ä¸€ç§æŠ—é”¯é½¿å¤„ç†çš„äºŒç»´é«˜æ–¯é‡‡æ ·æŠ€æœ¯ï¼Œå®ƒä¿æŒäº†äºŒç»´é«˜æ–¯é‡‡æ ·çš„å‡ ä½•ä¼˜åŠ¿ï¼ŒåŒæ—¶æ˜¾è‘—æé«˜äº†ä¸åŒå°ºåº¦ä¸‹çš„æ¸²æŸ“è´¨é‡ã€‚é€šè¿‡å¼•å…¥ä¸–ç•Œç©ºé—´å¹³é¢å¹³æ»‘æ ¸æŠ€æœ¯ï¼ŒåŸºäºè®­ç»ƒè§†å›¾çš„æœ€å¤§é‡‡æ ·é¢‘ç‡çº¦æŸäºŒç»´é«˜æ–¯åŸå§‹æ•°æ®çš„é¢‘ç‡å†…å®¹ï¼Œæœ‰æ•ˆåœ°æ¶ˆé™¤äº†ç¼©æ”¾æ—¶çš„é«˜é¢‘ä¼ªå½±ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.11252">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-80d64af522f3986372719f7abb34746e~resize:0:q75.jpg?source=1f5c5e47&expiration=1762311585&auth_key=1762311585-0-0-732d0f042ca994b4b0a8592d0109c58d&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-baf76e99d6d694bca5665ccdc45d1acb~resize:0:q75.jpg?source=1f5c5e47&expiration=1762311592&auth_key=1762311592-0-0-0f22fc34253a4371e78c52309e72d8c6&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-16"><a href="#-16" class="headerlink" title=""></a></h1><h2 id="HAIF-GS-Hierarchical-and-Induced-Flow-Guided-Gaussian-Splatting-for-Dynamic-Scene"><a href="#HAIF-GS-Hierarchical-and-Induced-Flow-Guided-Gaussian-Splatting-for-Dynamic-Scene" class="headerlink" title="HAIF-GS: Hierarchical and Induced Flow-Guided Gaussian Splatting for   Dynamic Scene"></a>HAIF-GS: Hierarchical and Induced Flow-Guided Gaussian Splatting for   Dynamic Scene</h2><p><strong>Authors:Jianing Chen, Zehao Li, Yujun Cai, Hao Jiang, Chengxuan Qian, Juyuan Kang, Shuqin Gao, Honglong Zhao, Tianlu Mao, Yucheng Zhang</strong></p>
<p>Reconstructing dynamic 3D scenes from monocular videos remains a fundamental challenge in 3D vision. While 3D Gaussian Splatting (3DGS) achieves real-time rendering in static settings, extending it to dynamic scenes is challenging due to the difficulty of learning structured and temporally consistent motion representations. This challenge often manifests as three limitations in existing methods: redundant Gaussian updates, insufficient motion supervision, and weak modeling of complex non-rigid deformations. These issues collectively hinder coherent and efficient dynamic reconstruction. To address these limitations, we propose HAIF-GS, a unified framework that enables structured and consistent dynamic modeling through sparse anchor-driven deformation. It first identifies motion-relevant regions via an Anchor Filter to suppress redundant updates in static areas. A self-supervised Induced Flow-Guided Deformation module induces anchor motion using multi-frame feature aggregation, eliminating the need for explicit flow labels. To further handle fine-grained deformations, a Hierarchical Anchor Propagation mechanism increases anchor resolution based on motion complexity and propagates multi-level transformations. Extensive experiments on synthetic and real-world benchmarks validate that HAIF-GS significantly outperforms prior dynamic 3DGS methods in rendering quality, temporal coherence, and reconstruction efficiency. </p>
<blockquote>
<p>ä»å•ç›®è§†é¢‘ä¸­é‡å»ºåŠ¨æ€ä¸‰ç»´åœºæ™¯ä»ç„¶æ˜¯ä¸‰ç»´è§†è§‰é¢†åŸŸçš„ä¸€ä¸ªåŸºæœ¬æŒ‘æˆ˜ã€‚è™½ç„¶ä¸‰ç»´é«˜æ–¯æ‹¼è´´ï¼ˆ3DGSï¼‰åœ¨é™æ€åœºæ™¯ä¸­å®ç°äº†å®æ—¶æ¸²æŸ“ï¼Œä½†å°†å…¶æ‰©å±•åˆ°åŠ¨æ€åœºæ™¯å´å…·æœ‰æŒ‘æˆ˜æ€§ï¼Œè¿™ä¸»è¦æ˜¯ç”±äºå­¦ä¹ ç»“æ„å’Œæ—¶é—´ä¸Šä¸€è‡´çš„è¿åŠ¨è¡¨ç¤ºå¾ˆå›°éš¾ã€‚è¿™ä¸€æŒ‘æˆ˜åœ¨ç°æœ‰æ–¹æ³•ä¸­é€šå¸¸è¡¨ç°ä¸ºä¸‰ä¸ªå±€é™æ€§ï¼šé«˜æ–¯æ›´æ–°å†—ä½™ã€è¿åŠ¨ç›‘ç£ä¸è¶³ä»¥åŠå¤æ‚éåˆšæ€§å˜å½¢çš„å¼±å»ºæ¨¡ã€‚è¿™äº›é—®é¢˜å…±åŒé˜»ç¢äº†è¿è´¯å’Œé«˜æ•ˆçš„åŠ¨æ€é‡å»ºã€‚ä¸ºäº†è§£å†³è¿™äº›å±€é™æ€§ï¼Œæˆ‘ä»¬æå‡ºäº†HAIF-GSï¼Œè¿™æ˜¯ä¸€ä¸ªé€šè¿‡ç¨€ç–é”šç‚¹é©±åŠ¨å˜å½¢å®ç°ç»“æ„å’Œä¸€è‡´åŠ¨æ€å»ºæ¨¡çš„ç»Ÿä¸€æ¡†æ¶ã€‚å®ƒé¦–å…ˆé€šè¿‡é”šç‚¹è¿‡æ»¤å™¨è¯†åˆ«è¿åŠ¨ç›¸å…³åŒºåŸŸï¼Œä»¥æŠ‘åˆ¶é™æ€åŒºåŸŸä¸­çš„å†—ä½™æ›´æ–°ã€‚è‡ªç›‘ç£çš„è¯±å¯¼æµå¼•å¯¼å˜å½¢æ¨¡å—åˆ©ç”¨å¤šå¸§ç‰¹å¾èšåˆè¯±å¯¼é”šç‚¹è¿åŠ¨ï¼Œä»è€Œæ¶ˆé™¤äº†å¯¹æ˜¾å¼æµæ ‡ç­¾çš„éœ€æ±‚ã€‚ä¸ºäº†è¿›ä¸€æ­¥å¤„ç†ç»†å¾®çš„å˜å½¢ï¼Œåˆ†å±‚é”šç‚¹ä¼ æ’­æœºåˆ¶åŸºäºè¿åŠ¨å¤æ‚æ€§æé«˜é”šç‚¹åˆ†è¾¨ç‡ï¼Œå¹¶ä¼ æ’­å¤šçº§å˜æ¢ã€‚åœ¨åˆæˆå’ŒçœŸå®ä¸–ç•Œçš„åŸºå‡†æµ‹è¯•ä¸Šçš„å¤§é‡å®éªŒéªŒè¯äº†HAIF-GSåœ¨æ¸²æŸ“è´¨é‡ã€æ—¶é—´è¿è´¯æ€§å’Œé‡å»ºæ•ˆç‡æ–¹é¢æ˜¾è‘—ä¼˜äºå…ˆå‰çš„åŠ¨æ€3DGSæ–¹æ³•ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.09518v2">PDF</a> Accepted to NeurIPS 2025. Project page:   <a target="_blank" rel="noopener" href="https://echopickle.github.io/HAIF-GS.github.io/">https://echopickle.github.io/HAIF-GS.github.io/</a></p>
<p><strong>Summary</strong><br>åŠ¨æ€ä¸‰ç»´åœºæ™¯çš„å•ç›®è§†é¢‘é‡å»ºä»æ˜¯ä¸‰ç»´è§†è§‰é¢†åŸŸçš„åŸºæœ¬æŒ‘æˆ˜ã€‚é’ˆå¯¹ç°æœ‰æ–¹æ³•åœ¨åŠ¨æ€åœºæ™¯é‡å»ºä¸­å‡ºç°çš„å†—ä½™é«˜æ–¯æ›´æ–°ã€è¿åŠ¨ç›‘ç£ä¸è¶³ä»¥åŠå¤æ‚éåˆšæ€§å˜å½¢å»ºæ¨¡è¾ƒå¼±ç­‰é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†HAIF-GSç»Ÿä¸€æ¡†æ¶ã€‚å®ƒé€šè¿‡ç¨€ç–é”šç‚¹é©±åŠ¨å˜å½¢è¿›è¡Œç»“æ„åŒ–ã€ä¸€è‡´æ€§çš„åŠ¨æ€å»ºæ¨¡ï¼Œæœ‰æ•ˆè§£å†³äº†ä¸Šè¿°é—®é¢˜ã€‚é€šè¿‡å¤šå±‚æ¬¡å®éªŒéªŒè¯ï¼ŒHAIF-GSåœ¨æ¸²æŸ“è´¨é‡ã€æ—¶é—´è¿è´¯æ€§å’Œé‡å»ºæ•ˆç‡æ–¹é¢å‡æ˜¾è‘—ä¼˜äºå…¶ä»–åŠ¨æ€3DGSæ–¹æ³•ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>åŠ¨æ€ä¸‰ç»´åœºæ™¯é‡å»ºä»æ˜¯3Dè§†è§‰é¢†åŸŸçš„æ ¸å¿ƒæŒ‘æˆ˜ã€‚</li>
<li>ç°æœ‰æ–¹æ³•åœ¨åŠ¨æ€åœºæ™¯é‡å»ºä¸­å­˜åœ¨å†—ä½™é«˜æ–¯æ›´æ–°ã€è¿åŠ¨ç›‘ç£ä¸è¶³å’Œå¤æ‚éåˆšæ€§å˜å½¢å»ºæ¨¡è¾ƒå¼±ç­‰é—®é¢˜ã€‚</li>
<li>HAIF-GSæ¡†æ¶é€šè¿‡ç¨€ç–é”šç‚¹é©±åŠ¨å˜å½¢è¿›è¡Œç»“æ„åŒ–ã€ä¸€è‡´æ€§çš„åŠ¨æ€å»ºæ¨¡ï¼Œä»¥è§£å†³ä¸Šè¿°é—®é¢˜ã€‚</li>
<li>Anchor Filterèƒ½è¯†åˆ«è¿åŠ¨ç›¸å…³åŒºåŸŸï¼ŒæŠ‘åˆ¶é™æ€åŒºåŸŸçš„å†—ä½™æ›´æ–°ã€‚</li>
<li>å¼•å…¥äº†è‡ªç›‘ç£çš„Induced Flow-Guided Deformationæ¨¡å—ï¼Œåˆ©ç”¨å¤šå¸§ç‰¹å¾èšåˆè¯±å¯¼é”šç‚¹è¿åŠ¨ï¼Œæ— éœ€æ˜ç¡®çš„æµæ ‡ç­¾ã€‚</li>
<li>Hierarchical Anchor Propagationæœºåˆ¶èƒ½æé«˜é”šç‚¹åˆ†è¾¨ç‡ï¼Œæ ¹æ®è¿åŠ¨å¤æ‚æ€§ä¼ æ’­å¤šå±‚æ¬¡å˜æ¢ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.09518">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-5f34513cb92db2e9c116b1d972e87af0~resize:0:q75.jpg?source=1f5c5e47&expiration=1762311599&auth_key=1762311599-0-0-21904852e11c3dbb1e292f3773e9f534&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-373d7a63ea6741d353ca66e82b7d6082~resize:0:q75.jpg?source=1f5c5e47&expiration=1762311607&auth_key=1762311607-0-0-0c023f4fd13a595b688a1b10536f8b4b&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-615470f23be0c2fa1fedfe79585bda9d~resize:0:q75.jpg?source=1f5c5e47&expiration=1762311613&auth_key=1762311613-0-0-6ff5cff090a86a56153b1fa99c0db712&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-17"><a href="#-17" class="headerlink" title=""></a></h1><h2 id="GS4-Generalizable-Sparse-Splatting-Semantic-SLAM"><a href="#GS4-Generalizable-Sparse-Splatting-Semantic-SLAM" class="headerlink" title="GS4: Generalizable Sparse Splatting Semantic SLAM"></a>GS4: Generalizable Sparse Splatting Semantic SLAM</h2><p><strong>Authors:Mingqi Jiang, Chanho Kim, Chen Ziwen, Li Fuxin</strong></p>
<p>Traditional SLAM algorithms excel at camera tracking, but typically produce incomplete and low-resolution maps that are not tightly integrated with semantics prediction. Recent work integrates Gaussian Splatting (GS) into SLAM to enable dense, photorealistic 3D mapping, yet existing GS-based SLAM methods require per-scene optimization that is slow and consumes an excessive number of Gaussians. We present GS4, the first generalizable GS-based semantic SLAM system. Compared with prior approaches, GS4 runs 10x faster, uses 10x fewer Gaussians, and achieves state-of-the-art performance across color, depth, semantic mapping and camera tracking. From an RGB-D video stream, GS4 incrementally builds and updates a set of 3D Gaussians using a feed-forward network. First, the Gaussian Prediction Model estimates a sparse set of Gaussian parameters from input frame, which integrates both color and semantic prediction with the same backbone. Then, the Gaussian Refinement Network merges new Gaussians with the existing set while avoiding redundancy. Finally, we propose to optimize GS for only 1-5 iterations that corrects drift and floaters when significant pose changes are detected. Experiments on the real-world ScanNet and ScanNet++ benchmarks demonstrate state-of-the-art semantic SLAM performance, with strong generalization capability shown through zero-shot transfer to the NYUv2 and TUM RGB-D datasets. </p>
<blockquote>
<p>ä¼ ç»ŸSLAMç®—æ³•åœ¨æ‘„åƒå¤´è·Ÿè¸ªæ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œä½†é€šå¸¸ç”Ÿæˆä¸å®Œæ•´ä¸”åˆ†è¾¨ç‡ä½çš„åœ°å›¾ï¼Œæ— æ³•ç´§å¯†åœ°èå…¥è¯­ä¹‰é¢„æµ‹ã€‚æœ€è¿‘çš„ç ”ç©¶å°†é«˜æ–¯æº…å¢¨æ³•ï¼ˆGSï¼‰é›†æˆåˆ°SLAMä¸­ï¼Œä»¥å®ç°å¯†é›†ã€é€¼çœŸçš„ä¸‰ç»´æ˜ å°„ï¼Œä½†ç°æœ‰çš„åŸºäºGSçš„SLAMæ–¹æ³•éœ€è¦å¯¹æ¯ä¸ªåœºæ™¯è¿›è¡Œä¼˜åŒ–ï¼Œè¿™æ—¢ç¼“æ…¢åˆæ¶ˆè€—äº†å¤§é‡é«˜æ–¯æ•°ã€‚æˆ‘ä»¬æå‡ºäº†GS4ï¼Œè¿™æ˜¯ç¬¬ä¸€ä¸ªåŸºäºGSçš„å¯é€šç”¨çš„è¯­ä¹‰SLAMç³»ç»Ÿã€‚ä¸ä»¥å‰çš„æ–¹æ³•ç›¸æ¯”ï¼ŒGS4è¿è¡Œé€Ÿåº¦æé«˜äº†10å€ï¼Œä½¿ç”¨çš„é«˜æ–¯æ•°å‡å°‘äº†10å€ï¼Œå¹¶åœ¨é¢œè‰²ã€æ·±åº¦ã€è¯­ä¹‰æ˜ å°„å’Œæ‘„åƒå¤´è·Ÿè¸ªæ–¹é¢è¾¾åˆ°äº†æœ€æ–°æ€§èƒ½æ°´å¹³ã€‚GS4é€šè¿‡RGB-Dè§†é¢‘æµé€æ­¥æ„å»ºå¹¶æ›´æ–°ä¸€ç»„ä¸‰ç»´é«˜æ–¯æ•°ï¼Œä½¿ç”¨å‰é¦ˆç½‘ç»œè¿›è¡Œå¤„ç†ã€‚é¦–å…ˆï¼Œé«˜æ–¯é¢„æµ‹æ¨¡å‹ä»è¾“å…¥å¸§ä¼°è®¡ä¸€ç»„ç¨€ç–çš„é«˜æ–¯å‚æ•°ï¼ŒåŒæ—¶æ•´åˆé¢œè‰²å’Œè¯­ä¹‰é¢„æµ‹ã€‚ç„¶åï¼Œé«˜æ–¯ç»†åŒ–ç½‘ç»œå°†æ–°é«˜æ–¯æ•°ä¸ç°æœ‰é›†åˆåˆå¹¶ï¼ŒåŒæ—¶é¿å…å†—ä½™ã€‚æœ€åï¼Œæˆ‘ä»¬æå‡ºä»…å¯¹GSè¿›è¡Œä¸€åˆ°äº”æ¬¡è¿­ä»£ä¼˜åŒ–ï¼Œå½“æ£€æµ‹åˆ°æ˜¾è‘—å§¿æ€å˜åŒ–æ—¶ï¼Œå¯çº æ­£æ¼‚ç§»å’Œæµ®åŠ¨é—®é¢˜ã€‚åœ¨ç°å®ä¸–ç•ŒScanNetå’ŒScanNet++åŸºå‡†æµ‹è¯•ä¸Šçš„å®éªŒè¯æ˜äº†å…¶é¢†å…ˆçš„è¯­ä¹‰SLAMæ€§èƒ½ï¼Œå¼ºå¤§çš„æ³›åŒ–èƒ½åŠ›é€šè¿‡é›¶æ ·æœ¬è¿ç§»åˆ°NYUv2å’ŒTUM RGB-Dæ•°æ®é›†ä¸Šå¾—ä»¥å±•ç¤ºã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.06517v2">PDF</a> 17 pages, 6 figures</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†GS4ï¼Œä¸€ä¸ªåŸºäºé«˜æ–¯æ¶‚ç»˜ï¼ˆGSï¼‰çš„è¯­ä¹‰SLAMç³»ç»Ÿã€‚ç›¸è¾ƒäºä¼ ç»ŸSLAMç®—æ³•å’Œç°æœ‰GS-based SLAMæ–¹æ³•ï¼ŒGS4å®ç°äº†å¿«é€Ÿã€é«˜æ•ˆçš„å¯†é›†ä¸‰ç»´æ˜ å°„ï¼Œå…·æœ‰æ›´å¼ºçš„æ³›åŒ–èƒ½åŠ›ã€‚å®ƒä½¿ç”¨RGB-Dè§†é¢‘æµè¿›è¡Œå¢é‡æ›´æ–°å’Œä¼˜åŒ–ï¼Œé›†æˆäº†é¢œè‰²å’Œè¯­ä¹‰é¢„æµ‹ï¼Œæé«˜äº†åœ°å›¾çš„å®Œæ•´æ€§å’Œåˆ†è¾¨ç‡ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>GS4æ˜¯é¦–ä¸ªåŸºäºé«˜æ–¯æ¶‚ç»˜ï¼ˆGSï¼‰çš„è¯­ä¹‰SLAMç³»ç»Ÿï¼Œå®ç°äº†å¿«é€Ÿã€é«˜æ•ˆçš„ä¸‰ç»´æ˜ å°„ã€‚</li>
<li>GS4ä½¿ç”¨RGB-Dè§†é¢‘æµè¿›è¡Œå¢é‡æ›´æ–°å’Œä¼˜åŒ–ï¼Œæé«˜äº†åœ°å›¾çš„å®Œæ•´æ€§å’Œåˆ†è¾¨ç‡ã€‚</li>
<li>GS4é€šè¿‡é›†æˆé¢œè‰²å’Œè¯­ä¹‰é¢„æµ‹ï¼Œæé«˜äº†åœ°å›¾çš„å…‰ç…§çœŸå®æ„Ÿå’Œè¯­ä¹‰ä¸°å¯Œæ€§ã€‚</li>
<li>GS4é‡‡ç”¨ç¨€ç–é«˜æ–¯å‚æ•°ä¼°è®¡å’Œå†—ä½™é¿å…ç­–ç•¥ï¼Œå®ç°äº†æ›´é«˜æ•ˆçš„é«˜æ–¯æ¶‚ç»˜å¤„ç†ã€‚</li>
<li>GS4ä»…è¿›è¡Œå°‘é‡è¿­ä»£ä¼˜åŒ–ï¼Œå¯åœ¨æ£€æµ‹åˆ°æ˜¾è‘—å§¿æ€å˜åŒ–æ—¶çº æ­£æ¼‚ç§»å’Œæµ®åŠ¨é—®é¢˜ã€‚</li>
<li>å®éªŒç»“æœè¡¨æ˜ï¼ŒGS4åœ¨ScanNetå’ŒScanNet++ç­‰çœŸå®ä¸–ç•Œæ•°æ®é›†ä¸Šå®ç°äº†æœ€å…ˆè¿›çš„è¯­ä¹‰SLAMæ€§èƒ½ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.06517">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-efa5d627f7d2cd1339de4a7eba936de8~resize:0:q75.jpg?source=1f5c5e47&expiration=1762311621&auth_key=1762311621-0-0-a57fe1db773834c59e56526c18ab17ab&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-7845d573c6df1a3a50a6165dc5cfecf8~resize:0:q75.jpg?source=1f5c5e47&expiration=1762311628&auth_key=1762311628-0-0-042997cde1d5f81b027eebb9612dab21&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-4dc3b44485de71878df4c54b8ee09ae6~resize:0:q75.jpg?source=1f5c5e47&expiration=1762311636&auth_key=1762311636-0-0-7d05e883786c88af3c6a5c45af52b0c1&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-18"><a href="#-18" class="headerlink" title=""></a></h1><h2 id="LODGE-Level-of-Detail-Large-Scale-Gaussian-Splatting-with-Efficient-Rendering"><a href="#LODGE-Level-of-Detail-Large-Scale-Gaussian-Splatting-with-Efficient-Rendering" class="headerlink" title="LODGE: Level-of-Detail Large-Scale Gaussian Splatting with Efficient   Rendering"></a>LODGE: Level-of-Detail Large-Scale Gaussian Splatting with Efficient   Rendering</h2><p><strong>Authors:Jonas Kulhanek, Marie-Julie Rakotosaona, Fabian Manhardt, Christina Tsalicoglou, Michael Niemeyer, Torsten Sattler, Songyou Peng, Federico Tombari</strong></p>
<p>In this work, we present a novel level-of-detail (LOD) method for 3D Gaussian Splatting that enables real-time rendering of large-scale scenes on memory-constrained devices. Our approach introduces a hierarchical LOD representation that iteratively selects optimal subsets of Gaussians based on camera distance, thus largely reducing both rendering time and GPU memory usage. We construct each LOD level by applying a depth-aware 3D smoothing filter, followed by importance-based pruning and fine-tuning to maintain visual fidelity. To further reduce memory overhead, we partition the scene into spatial chunks and dynamically load only relevant Gaussians during rendering, employing an opacity-blending mechanism to avoid visual artifacts at chunk boundaries. Our method achieves state-of-the-art performance on both outdoor (Hierarchical 3DGS) and indoor (Zip-NeRF) datasets, delivering high-quality renderings with reduced latency and memory requirements. </p>
<blockquote>
<p>åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§ç”¨äº3Dé«˜æ–¯å¹³é“ºï¼ˆ3DGSï¼‰çš„æ–°å‹ç»†èŠ‚å±‚æ¬¡ï¼ˆLODï¼‰æ–¹æ³•ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿåœ¨å†…å­˜å—é™çš„è®¾å¤‡ä¸Šå®ç°å¤§è§„æ¨¡åœºæ™¯çš„å®æ—¶æ¸²æŸ“ã€‚æˆ‘ä»¬çš„æ–¹æ³•å¼•å…¥äº†ä¸€ç§å±‚æ¬¡å‹LODè¡¨ç¤ºï¼Œæ ¹æ®æ‘„åƒæœºè·ç¦»è¿­ä»£é€‰æ‹©æœ€ä¼˜çš„é«˜æ–¯å­é›†ï¼Œä»è€Œå¤§å¤§é™ä½äº†æ¸²æŸ“æ—¶é—´å’ŒGPUå†…å­˜çš„ä½¿ç”¨ã€‚æˆ‘ä»¬é€šè¿‡åº”ç”¨æ·±åº¦æ„ŸçŸ¥çš„3Då¹³æ»‘æ»¤æ³¢å™¨æ¥æ„å»ºæ¯ä¸ªLODçº§åˆ«ï¼Œç„¶ååŸºäºé‡è¦æ€§è¿›è¡Œä¿®å‰ªå’Œå¾®è°ƒä»¥ç»´æŒè§†è§‰ä¿çœŸåº¦ã€‚ä¸ºäº†è¿›ä¸€æ­¥ä¼˜åŒ–å†…å­˜å¼€é”€ï¼Œæˆ‘ä»¬å°†åœºæ™¯åˆ’åˆ†ä¸ºç©ºé—´å—ï¼Œå¹¶åœ¨æ¸²æŸ“æ—¶åŠ¨æ€åŠ è½½ç›¸å…³çš„é«˜æ–¯å€¼ï¼Œé‡‡ç”¨ä¸é€æ˜åº¦æ··åˆæœºåˆ¶ä»¥é¿å…å—è¾¹ç•Œå¤„çš„è§†è§‰ä¼ªå½±ã€‚æˆ‘ä»¬çš„æ–¹æ³•åœ¨æˆ·å¤–ï¼ˆåˆ†å±‚3DGSï¼‰å’Œå®¤å†…ï¼ˆZip-NeRFï¼‰æ•°æ®é›†ä¸Šéƒ½è¾¾åˆ°äº†æœ€å…ˆè¿›çš„æŠ€æœ¯æ°´å¹³ï¼Œèƒ½å¤Ÿä»¥è¾ƒä½å»¶è¿Ÿå’Œå†…å­˜éœ€æ±‚å®ç°é«˜è´¨é‡æ¸²æŸ“æ•ˆæœã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.23158v2">PDF</a> NeurIPS 2025; Web: <a target="_blank" rel="noopener" href="https://lodge-gs.github.io/">https://lodge-gs.github.io/</a></p>
<p><strong>Summary</strong><br>     è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§ç”¨äºå®æ—¶æ¸²æŸ“å¤§è§„æ¨¡åœºæ™¯çš„æ–°å‹ç»†èŠ‚å±‚æ¬¡ï¼ˆLODï¼‰æ–¹æ³•ï¼Œé€‚ç”¨äºå†…å­˜å—é™çš„è®¾å¤‡ã€‚è¯¥æ–¹æ³•å¼•å…¥äº†ä¸€ç§å±‚æ¬¡å‹LODè¡¨ç¤ºï¼Œæ ¹æ®æ‘„åƒæœºè·ç¦»è¿­ä»£é€‰æ‹©æœ€ä¼˜çš„é«˜æ–¯å­é›†ï¼Œä»è€Œå¤§å¤§å‡å°‘æ¸²æŸ“æ—¶é—´å’ŒGPUå†…å­˜ä½¿ç”¨ã€‚é€šè¿‡æ·±åº¦æ„ŸçŸ¥çš„3Då¹³æ»‘æ»¤æ³¢å™¨æ„å»ºæ¯ä¸ªLODçº§åˆ«ï¼Œé€šè¿‡é‡è¦æ€§ä¿®å‰ªå’Œå¾®è°ƒä¿æŒè§†è§‰ä¿çœŸåº¦ã€‚é€šè¿‡å°†åœºæ™¯åˆ’åˆ†ä¸ºç©ºé—´å—å¹¶åŠ¨æ€åŠ è½½æ¸²æŸ“æœŸé—´çš„æœ‰å…³é«˜æ–¯å€¼ï¼Œè¿›ä¸€æ­¥å‡å°‘å†…å­˜å¼€é”€ï¼Œé‡‡ç”¨ä¸é€æ˜åº¦æ··åˆæœºåˆ¶é¿å…å—è¾¹ç•Œå¤„çš„è§†è§‰ä¼ªå½±ã€‚è¯¥æ–¹æ³•åœ¨æˆ·å¤–å’Œå®¤å†…æ•°æ®é›†ä¸Šå‡å®ç°äº†å“è¶Šæ€§èƒ½ï¼Œä»¥ä½å»¶è¿Ÿå’Œå†…å­˜è¦æ±‚æä¾›é«˜è´¨é‡æ¸²æŸ“ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¼•å…¥äº†ä¸€ç§æ–°å‹çš„ç»†èŠ‚å±‚æ¬¡ï¼ˆLODï¼‰æ–¹æ³•ï¼Œé€‚ç”¨äºå®æ—¶æ¸²æŸ“å¤§è§„æ¨¡åœºæ™¯åœ¨å†…å­˜å—é™çš„è®¾å¤‡ä¸Šã€‚</li>
<li>åŸºäºæ‘„åƒæœºè·ç¦»é€‰æ‹©æœ€ä¼˜çš„é«˜æ–¯å­é›†ï¼Œæ˜¾è‘—å‡å°‘æ¸²æŸ“æ—¶é—´å’ŒGPUå†…å­˜ä½¿ç”¨ã€‚</li>
<li>é€šè¿‡æ·±åº¦æ„ŸçŸ¥çš„3Då¹³æ»‘æ»¤æ³¢å™¨æ„å»ºæ¯ä¸ªLODå±‚æ¬¡ï¼Œå¢å¼ºè§†è§‰æ•ˆæœã€‚</li>
<li>å®æ–½é‡è¦æ€§ä¿®å‰ªå’Œå¾®è°ƒæ¥ä¿æŒè§†è§‰ä¿çœŸåº¦ã€‚</li>
<li>é€šè¿‡åˆ’åˆ†åœºæ™¯ä¸ºç©ºé—´å—å¹¶åŠ¨æ€åŠ è½½ç›¸å…³é«˜æ–¯å€¼ï¼Œé™ä½å†…å­˜å¼€é”€ã€‚</li>
<li>é‡‡ç”¨ä¸é€æ˜åº¦æ··åˆæœºåˆ¶é¿å…å—è¾¹ç•Œçš„è§†è§‰ä¼ªå½±ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.23158">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-486b9dc1c75aa076019c2515e5fd01f5~resize:0:q75.jpg?source=1f5c5e47&expiration=1762311643&auth_key=1762311643-0-0-ef57af3a902e521eb954e8a9612321fa&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-d1be0481afccd1378c703bd48f31726c~resize:0:q75.jpg?source=1f5c5e47&expiration=1762311650&auth_key=1762311650-0-0-046def3dc9878ea921aa73724a342113&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-45ce03e1287066d6975403723b5f0728~resize:0:q75.jpg?source=1f5c5e47&expiration=1762311657&auth_key=1762311657-0-0-362b2a3fb269a28610e6193bb39cd162&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-568135090e32db17615de91c3aba66ab~resize:0:q75.jpg?source=1f5c5e47&expiration=1762311664&auth_key=1762311664-0-0-1aaaabe880111c5c715e81bcf5026642&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-19"><a href="#-19" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-11-05/3DGS/">https://kedreamix.github.io/Talk2Paper/Paper/2025-11-05/3DGS/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/3DGS/">
                                    <span class="chip bg-color">3DGS</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-11-05/NeRF/">
                    <div class="card-image">
                        
                        <img src="https://pic-private.zhihu.com/v2-73ffebfdd9b9c86bdd553fc0d74142cb~resize:0:q75.jpg?source=1f5c5e47&expiration=1762311671&auth_key=1762311671-0-0-f3bf57155910a43b8b6341b70b683e57&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" class="responsive-img" alt="NeRF">
                        
                        <span class="card-title">NeRF</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            NeRF æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-11-05  SAGS Self-Adaptive Alias-Free Gaussian Splatting for Dynamic Surgical   Endoscopic Reconstruction
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-11-05
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/NeRF/" class="post-category">
                                    NeRF
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/NeRF/">
                        <span class="chip bg-color">NeRF</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-11-05/%E5%85%83%E5%AE%87%E5%AE%99_%E8%99%9A%E6%8B%9F%E4%BA%BA/">
                    <div class="card-image">
                        
                        <img src="https://pic-private.zhihu.com/v2-458a143d2cb57029074f19c1e7a98771~resize:0:q75.jpg?source=1f5c5e47&expiration=1762310909&auth_key=1762310909-0-0-2dd2d8fb5d211f09302c99ec20e1bc67&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" class="responsive-img" alt="å…ƒå®‡å®™/è™šæ‹Ÿäºº">
                        
                        <span class="card-title">å…ƒå®‡å®™/è™šæ‹Ÿäºº</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            å…ƒå®‡å®™/è™šæ‹Ÿäºº æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-11-05  ESCA Enabling Seamless Codec Avatar Execution through Algorithm and   Hardware Co-Optimization for Virtual Reality
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-11-05
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/%E5%85%83%E5%AE%87%E5%AE%99-%E8%99%9A%E6%8B%9F%E4%BA%BA/" class="post-category">
                                    å…ƒå®‡å®™/è™šæ‹Ÿäºº
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/%E5%85%83%E5%AE%87%E5%AE%99-%E8%99%9A%E6%8B%9F%E4%BA%BA/">
                        <span class="chip bg-color">å…ƒå®‡å®™/è™šæ‹Ÿäºº</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">31879.7k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
