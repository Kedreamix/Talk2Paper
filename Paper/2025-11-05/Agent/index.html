<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Agent">
    <meta name="description" content="Agent æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-11-05  InnovatorBench Evaluating Agents&#39; Ability to Conduct Innovative LLM   Research">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>Agent | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://picx.zhimg.com/v2-2f43dd3462e62bdce8e3ed2f3f7e8aa7')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Agent</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/Agent/">
                                <span class="chip bg-color">Agent</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/Agent/" class="post-category">
                                Agent
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-11-05
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-11-15
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    17.5k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    71 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-11-05-æ›´æ–°"><a href="#2025-11-05-æ›´æ–°" class="headerlink" title="2025-11-05 æ›´æ–°"></a>2025-11-05 æ›´æ–°</h1><h2 id="InnovatorBench-Evaluating-Agentsâ€™-Ability-to-Conduct-Innovative-LLM-Research"><a href="#InnovatorBench-Evaluating-Agentsâ€™-Ability-to-Conduct-Innovative-LLM-Research" class="headerlink" title="InnovatorBench: Evaluating Agentsâ€™ Ability to Conduct Innovative LLM   Research"></a>InnovatorBench: Evaluating Agentsâ€™ Ability to Conduct Innovative LLM   Research</h2><p><strong>Authors:Yunze Wu, Dayuan Fu, Weiye Si, Zhen Huang, Mohan Jiang, Keyu Li, Shijie Xia, Jie Sun, Tianze Xu, Xiangkun Hu, Pengrui Lu, Xiaojie Cai, Lyumanshan Ye, Wenhong Zhu, Yang Xiao, Pengfei Liu</strong></p>
<p>AI agents could accelerate scientific discovery by automating hypothesis formation, experiment design, coding, execution, and analysis, yet existing benchmarks probe narrow skills in simplified settings. To address this gap, we introduce InnovatorBench, a benchmark-platform pair for realistic, end-to-end assessment of agents performing Large Language Model (LLM) research. It comprises 20 tasks spanning Data Construction, Filtering, Augmentation, Loss Design, Reward Design, and Scaffold Construction, which require runnable artifacts and assessment of correctness, performance, output quality, and uncertainty. To support agent operation, we develop ResearchGym, a research environment offering rich action spaces, distributed and long-horizon execution, asynchronous monitoring, and snapshot saving. We also implement a lightweight ReAct agent that couples explicit reasoning with executable planning using frontier models such as Claude-4, GPT-5, GLM-4.5, and Kimi-K2. Our experiments demonstrate that while frontier models show promise in code-driven research tasks, they struggle with fragile algorithm-related tasks and long-horizon decision making, such as impatience, poor resource management, and overreliance on template-based reasoning. Furthermore, agents require over 11 hours to achieve their best performance on InnovatorBench, underscoring the benchmarkâ€™s difficulty and showing the potential of InnovatorBench to be the next generation of code-based research benchmark. </p>
<blockquote>
<p>äººå·¥æ™ºèƒ½ä»£ç†å¯ä»¥é€šè¿‡è‡ªåŠ¨åŒ–å‡è®¾å½¢æˆã€å®éªŒè®¾è®¡ã€ç¼–ç ã€æ‰§è¡Œå’Œåˆ†ææ¥åŠ é€Ÿç§‘å­¦å‘ç°ã€‚ç„¶è€Œï¼Œç°æœ‰çš„åŸºå‡†æµ‹è¯•é€šå¸¸åœ¨ç®€åŒ–çš„ç¯å¢ƒä¸­å¯¹ç‹­çª„çš„æŠ€èƒ½è¿›è¡Œæ¢æŸ¥ã€‚ä¸ºäº†å¼¥è¡¥è¿™ä¸€å·®è·ï¼Œæˆ‘ä»¬å¼•å…¥äº†InnovatorBenchï¼Œè¿™æ˜¯ä¸€ä¸ªç”¨äºè¯„ä¼°æ‰§è¡Œå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ç ”ç©¶çš„ä»£ç†çš„åŸºå‡†æµ‹è¯•å¹³å°ã€‚å®ƒåŒ…å«è·¨è¶Šæ•°æ®æ„å»ºã€è¿‡æ»¤ã€å¢å¼ºã€æŸå¤±è®¾è®¡ã€å¥–åŠ±è®¾è®¡å’Œè„šæ‰‹æ¶æ„å»ºçš„20é¡¹ä»»åŠ¡ï¼Œéœ€è¦å¯è¿è¡Œå·¥ä»¶ä»¥åŠæ­£ç¡®æ€§ã€æ€§èƒ½ã€è¾“å‡ºè´¨é‡å’Œä¸ç¡®å®šæ€§çš„è¯„ä¼°ã€‚ä¸ºäº†æ”¯æŒä»£ç†æ“ä½œï¼Œæˆ‘ä»¬å¼€å‘äº†ResearchGymï¼Œè¿™æ˜¯ä¸€ä¸ªç ”ç©¶ç¯å¢ƒï¼Œæä¾›äº†ä¸°å¯Œçš„è¡ŒåŠ¨ç©ºé—´ã€åˆ†å¸ƒå¼å’Œé•¿æœŸè§†è§’çš„æ‰§è¡Œã€å¼‚æ­¥ç›‘æ§å’Œå¿«ç…§ä¿å­˜åŠŸèƒ½ã€‚æˆ‘ä»¬è¿˜å®ç°äº†ä¸€ä¸ªè½»é‡çº§çš„ReActä»£ç†ï¼Œè¯¥ä»£ç†åˆ©ç”¨å‰æ²¿æ¨¡å‹ï¼ˆå¦‚Claude-4ã€GPT-5ã€GLM-4.5å’ŒKimi-K2ï¼‰è¿›è¡Œæ˜ç¡®çš„æ¨ç†å’Œå¯æ‰§è¡Œçš„è§„åˆ’ã€‚æˆ‘ä»¬çš„å®éªŒè¡¨æ˜ï¼Œå°½ç®¡å‰æ²¿æ¨¡å‹åœ¨ä»£ç é©±åŠ¨çš„ç ”ç©¶ä»»åŠ¡ä¸­æ˜¾ç¤ºå‡ºæ½œåŠ›ï¼Œä½†åœ¨è„†å¼±çš„ç®—æ³•ç›¸å…³ä»»åŠ¡å’Œé•¿æœŸå†³ç­–åˆ¶å®šæ–¹é¢ä»é¢ä¸´æŒ‘æˆ˜ï¼Œå¦‚ç¼ºä¹è€å¿ƒã€èµ„æºç®¡ç†ä¸å–„ä»¥åŠå¯¹æ¨¡æ¿æ¨ç†çš„è¿‡åº¦ä¾èµ–ã€‚æ­¤å¤–ï¼Œä»£ç†åœ¨InnovatorBenchä¸Šè¾¾åˆ°æœ€ä½³æ€§èƒ½éœ€è¦è¶…è¿‡11ä¸ªå°æ—¶ï¼Œè¿™çªæ˜¾äº†åŸºå‡†æµ‹è¯•çš„å›°éš¾æ€§ï¼Œå¹¶å±•ç¤ºäº†InnovatorBenchä½œä¸ºä¸‹ä¸€ä»£ä»£ç åŸºå‡†æµ‹è¯•çš„æ½œåŠ›ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.27598v2">PDF</a> </p>
<p><strong>Summary</strong><br>     äººå·¥æ™ºèƒ½ä»£ç†å¯åŠ é€Ÿç§‘å­¦å‘ç°ï¼Œé€šè¿‡è‡ªåŠ¨åŒ–å‡è®¾å½¢æˆã€å®éªŒè®¾è®¡ã€ç¼–ç ã€æ‰§è¡Œå’Œåˆ†æã€‚ä¸ºè¯„ä¼°ä»£ç†åœ¨å¤§è§„æ¨¡è¯­è¨€æ¨¡å‹ç ”ç©¶ä¸­çš„è¡¨ç°ï¼Œæ¨å‡ºäº†InnovatorBenchå¹³å°å’Œä¸€ç³»åˆ—ä»»åŠ¡ï¼Œæ¶µç›–æ•°æ®æ„å»ºã€è¿‡æ»¤ã€å¢å¼ºã€æŸå¤±è®¾è®¡ã€å¥–åŠ±è®¾è®¡å’Œè„šæ‰‹æ¶æ„å»ºç­‰æ–¹é¢ã€‚åŒæ—¶ï¼Œå¼€å‘äº†ResearchGymç¯å¢ƒæ”¯æŒä»£ç†æ“ä½œã€‚å®éªŒè¡¨æ˜ï¼Œå‰æ²¿æ¨¡å‹åœ¨ä»£ç é©±åŠ¨çš„ç ”ç©¶ä»»åŠ¡ä¸­è¡¨ç°å‡ºæ½œåŠ›ï¼Œä½†åœ¨è„†å¼±çš„ç®—æ³•ç›¸å…³ä»»åŠ¡å’Œé•¿æœŸå†³ç­–åˆ¶å®šæ–¹é¢å­˜åœ¨æŒ‘æˆ˜ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>AIä»£ç†å¯åŠ é€Ÿç§‘å­¦å‘ç°çš„å¤šä¸ªç¯èŠ‚ï¼ŒåŒ…æ‹¬å‡è®¾å½¢æˆã€å®éªŒè®¾è®¡ç­‰ã€‚</li>
<li>InnovatorBenchæ˜¯ä¸€ä¸ªç”¨äºè¯„ä¼°AIä»£ç†åœ¨å¤§è§„æ¨¡è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ç ”ç©¶ä¸­è¡¨ç°çš„åŸºå‡†æµ‹è¯•å¹³å°ã€‚</li>
<li>InnovatorBenchåŒ…å«æ¶µç›–å¤šä¸ªæ–¹é¢çš„20é¡¹ä»»åŠ¡ï¼Œéœ€è¦è¯„ä¼°æ­£ç¡®æ€§ã€æ€§èƒ½ã€è¾“å‡ºè´¨é‡å’Œä¸ç¡®å®šæ€§ã€‚</li>
<li>ResearchGymæ˜¯ä¸€ä¸ªç ”ç©¶ç¯å¢ƒï¼Œä¸ºAIä»£ç†æ“ä½œæä¾›æ”¯æŒï¼Œå…·æœ‰ä¸°å¯Œè¡ŒåŠ¨ç©ºé—´ã€åˆ†å¸ƒå¼æ‰§è¡Œç­‰ç‰¹æ€§ã€‚</li>
<li>å‰æ²¿æ¨¡å‹åœ¨ä»£ç é©±åŠ¨çš„ç ”ç©¶ä»»åŠ¡ä¸­è¡¨ç°å‡ºæ½œåŠ›ï¼Œä½†åœ¨æŸäº›ç‰¹å®šä»»åŠ¡ä¸Šå­˜åœ¨æŒ‘æˆ˜ï¼Œå¦‚è„†å¼±çš„ç®—æ³•ç›¸å…³ä»»åŠ¡å’Œé•¿æœŸå†³ç­–åˆ¶å®šã€‚</li>
<li>ä»£ç†å®Œæˆä»»åŠ¡éœ€è¦è¶…è¿‡11å°æ—¶ï¼Œè¡¨æ˜InnovatorBenchçš„éš¾åº¦å’Œæ½œåŠ›ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.27598">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-4900e81a56665a293b66b4112b24926d" align="middle">
<img src="https://picx.zhimg.com/v2-4787a1e0a2109ca4ceb7354cf74fa97f" align="middle">
<img src="https://picx.zhimg.com/v2-7881931c959c0b28f5680837953f09bb" align="middle">
<img src="https://picx.zhimg.com/v2-34d12f2248aeb5e4455bcf8bab42abdc" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="MCP-Flow-Facilitating-LLM-Agents-to-Master-Real-World-Diverse-and-Scaling-MCP-Tools"><a href="#MCP-Flow-Facilitating-LLM-Agents-to-Master-Real-World-Diverse-and-Scaling-MCP-Tools" class="headerlink" title="MCP-Flow: Facilitating LLM Agents to Master Real-World, Diverse and   Scaling MCP Tools"></a>MCP-Flow: Facilitating LLM Agents to Master Real-World, Diverse and   Scaling MCP Tools</h2><p><strong>Authors:Wenhao Wang, Peizhi Niu, Zhao Xu, Zhaoyu Chen, Jian Du, Yaxin Du, Xianghe Pang, Keduan Huang, Yanfeng Wang, Qiang Yan, Siheng Chen</strong></p>
<p>Large Language Models (LLMs) increasingly rely on external tools to perform complex, realistic tasks, yet their ability to utilize the rapidly expanding Model Contextual Protocol (MCP) ecosystem remains limited. Existing MCP research covers few servers, depends on costly manual curation, and lacks training support, hindering progress toward real-world deployment. To overcome these limitations, we introduce MCP-Flow, an automated web-agent-driven pipeline for large-scale server discovery, data synthesis, and model training. MCP-Flow collects and filters data from 1166 servers and 11536 tools, producing 68733 high-quality instruction-function call pairs and 6439 trajectories, far exceeding prior work in scale and diversity. Extensive experiments demonstrate MCP-Flowâ€™s effectiveness in driving superior MCP tool selection, function-call generation, and enhanced agentic task performance. MCP-Flow thus provides a scalable foundation for advancing LLM agentsâ€™ proficiency in real-world MCP environments. MCP-Flow is publicly available at \href{<a target="_blank" rel="noopener" href="https://github.com/wwh0411/MCP-Flow%7D%7Bhttps://github.com/wwh0411/MCP-Flow%7D">https://github.com/wwh0411/MCP-Flow}{https://github.com/wwh0411/MCP-Flow}</a>. </p>
<blockquote>
<p>éšç€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰è¶Šæ¥è¶Šä¾èµ–å¤–éƒ¨å·¥å…·æ¥æ‰§è¡Œå¤æ‚ã€ç°å®çš„ä»»åŠ¡ï¼Œå®ƒä»¬åˆ©ç”¨è¿…é€Ÿæ‰©å±•çš„æ¨¡å‹ä¸Šä¸‹æ–‡åè®®ï¼ˆMCPï¼‰ç”Ÿæ€ç³»ç»Ÿçš„èƒ½åŠ›ä»ç„¶æœ‰é™ã€‚ç°æœ‰çš„MCPç ”ç©¶æ¶‰åŠæœåŠ¡å™¨æ•°é‡æœ‰é™ï¼Œä¾èµ–äºæ˜‚è´µçš„äººå·¥æ•´ç†ï¼Œä¸”ç¼ºä¹åŸ¹è®­æ”¯æŒï¼Œé˜»ç¢äº†å…¶åœ¨ç°å®ä¸–ç•Œéƒ¨ç½²æ–¹é¢çš„è¿›å±•ã€‚ä¸ºäº†å…‹æœè¿™äº›é™åˆ¶ï¼Œæˆ‘ä»¬å¼•å…¥äº†MCP-Flowï¼Œè¿™æ˜¯ä¸€ä¸ªè‡ªåŠ¨åŒ–ç½‘ç»œé©±åŠ¨çš„ç®¡é“ï¼Œç”¨äºå¤§è§„æ¨¡æœåŠ¡å™¨å‘ç°ã€æ•°æ®åˆæˆå’Œæ¨¡å‹è®­ç»ƒã€‚MCP-Flowä»åŒ…æ‹¬è§„æ¨¡ä¸ºç¬¬ä¸‰æ–¹åº”ç”¨çš„æœç´¢å¼•æ“ç­‰èµ„æºä¸­æå–ç»“æ„åŒ–å’Œéç»“æ„åŒ–æ–‡æœ¬å½¢å¼çš„å„ç§èµ„æºå’Œåº”ç”¨ç¨‹åºè¯­å¢ƒä¿¡æ¯ï¼Œå¹¶ä»è¿™äº›èµ„æºä¸­æ”¶é›†å¹¶è¿‡æ»¤æ•°æ®ã€‚å®ƒä»æ¥è‡ªåŒ…æ‹¬æœåŠ¡å™¨ã€å·¥å…·ç­‰çš„æ•°æ®ä¸­ç”Ÿæˆå¤§é‡é«˜è´¨é‡çš„æŒ‡ä»¤å‡½æ•°è°ƒç”¨å¯¹å’Œè½¨è¿¹ã€‚å®éªŒè¡¨æ˜ï¼ŒMCP-Flowåœ¨é©±åŠ¨ä¼˜è´¨MCPå·¥å…·é€‰æ‹©ã€å‡½æ•°è°ƒç”¨ç”Ÿæˆä»¥åŠå¢å¼ºä»£ç†ä»»åŠ¡æ€§èƒ½æ–¹é¢å…·æœ‰å‡ºè‰²æ•ˆæœã€‚æˆ‘ä»¬çš„ä¸»è¦ç»“æœè¡¨æ˜é€šè¿‡çµæ´»çš„æ¿€åŠ±ç®—æ³•æ‰©å±•åœºæ™¯æœ‰æ•ˆæ€§ä¼˜åŠ¿æ–¹å‘åˆ†è§£æ•ˆæœç›®å‰æ•ˆæœå¾ˆå¥½å¹¶åˆ†æäº†è¯¸å¤šåº”ç”¨ç¨‹åºä¸Šç”Ÿå‘½å‘¨æœŸå¦‚å®æ—¶æ›´æ–°ç­‰ã€‚å› æ­¤ï¼ŒMCP-Flowä¸ºæå‡LLMä»£ç†åœ¨ç°å®ä¸–ç•Œçš„MCPç¯å¢ƒä¸­çš„èƒ½åŠ›æä¾›äº†å¯æ‰©å±•çš„åŸºç¡€ã€‚MCP-Flowçš„å…¬å¼€åœ°å€ä¸ºï¼š<a target="_blank" rel="noopener" href="https://github.com/wwh0411/mcp-flow">https://github.com/wwh0411/MCP-Flow</a>ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.24284v2">PDF</a> Preprint, Under Review</p>
<p><strong>Summary</strong></p>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰è¶Šæ¥è¶Šå¤šåœ°ä¾èµ–å¤–éƒ¨å·¥å…·æ¥å®Œæˆå¤æ‚ã€ç°å®çš„ä»»åŠ¡ï¼Œç„¶è€Œå®ƒä»¬åˆ©ç”¨è¿…é€Ÿæ‰©å±•çš„æ¨¡å‹ä¸Šä¸‹æ–‡åè®®ï¼ˆMCPï¼‰ç”Ÿæ€ç³»ç»Ÿçš„èƒ½åŠ›ä»ç„¶æœ‰é™ã€‚ä¸ºäº†å…‹æœè¿™äº›é™åˆ¶ï¼Œæˆ‘ä»¬æ¨å‡ºäº†MCP-Flowï¼Œè¿™æ˜¯ä¸€ä¸ªè‡ªåŠ¨åŒ–çš„ç½‘ç»œä»£ç†é©±åŠ¨ç®¡é“ï¼Œç”¨äºå¤§è§„æ¨¡æœåŠ¡å™¨å‘ç°ã€æ•°æ®åˆæˆå’Œæ¨¡å‹è®­ç»ƒã€‚å®ƒæ”¶é›†å¹¶è¿‡æ»¤äº†æ¥è‡ª1166ä¸ªæœåŠ¡å™¨å’Œ11536ä¸ªå·¥å…·çš„æ•°æ®ï¼Œäº§ç”Ÿäº†é«˜è´¨é‡æŒ‡ä»¤å‡½æ•°è°ƒç”¨å¯¹å’Œä»»åŠ¡è½¨è¿¹ï¼Œè§„æ¨¡å’Œå¤šæ ·æ€§å‡è¶…è¿‡ä»¥å‰çš„å·¥ä½œã€‚å®éªŒè¯æ˜ï¼ŒMCP-Flowåœ¨é©±åŠ¨MCPå·¥å…·é€‰æ‹©ã€å‡½æ•°è°ƒç”¨ç”Ÿæˆå’Œå¢å¼ºä»£ç†ä»»åŠ¡æ€§èƒ½æ–¹é¢éå¸¸æœ‰æ•ˆï¼Œä¸ºLLMä»£ç†åœ¨ç°å®ä¸–ç•Œçš„MCPç¯å¢ƒä¸­æä¾›äº†å¯æ‰©å±•çš„åŸºç¡€ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨åˆ©ç”¨æ¨¡å‹ä¸Šä¸‹æ–‡åè®®ï¼ˆMCPï¼‰ç”Ÿæ€ç³»ç»Ÿæ–¹é¢å­˜åœ¨å±€é™æ€§ã€‚</li>
<li>MCP-Flowæ˜¯ä¸€ä¸ªè‡ªåŠ¨åŒ–çš„ç½‘ç»œä»£ç†é©±åŠ¨ç®¡é“ï¼Œç”¨äºå¤§è§„æ¨¡æœåŠ¡å™¨å‘ç°ã€æ•°æ®åˆæˆå’Œæ¨¡å‹è®­ç»ƒã€‚</li>
<li>MCP-Flowèƒ½å¤Ÿæ”¶é›†å¹¶è¿‡æ»¤å¤§é‡æ•°æ®ï¼Œäº§ç”Ÿé«˜è´¨é‡æŒ‡ä»¤å‡½æ•°è°ƒç”¨å¯¹å’Œä»»åŠ¡è½¨è¿¹ã€‚</li>
<li>MCP-Flowçš„è§„æ¨¡å’Œå¤šæ ·æ€§è¶…è¿‡ä»¥å‰çš„å·¥ä½œã€‚</li>
<li>MCP-Flowèƒ½æœ‰æ•ˆé©±åŠ¨MCPå·¥å…·é€‰æ‹©ã€å‡½æ•°è°ƒç”¨ç”Ÿæˆã€‚</li>
<li>MCP-Flowèƒ½å¢å¼ºä»£ç†ä»»åŠ¡æ€§èƒ½ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.24284">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-38c532215855141bfd3d6f76c1393b93" align="middle">
<img src="https://picx.zhimg.com/v2-2191b9912d5c38dffb1710237af35c59" align="middle">
<img src="https://picx.zhimg.com/v2-66e2d1fa4ffce5936c01fec292fe8940" align="middle">
<img src="https://picx.zhimg.com/v2-8ffe531d5d67d2dc3acb0e78338ef226" align="middle">
<img src="https://picx.zhimg.com/v2-07f40cf772070d068ecd5fc04e0dc77a" align="middle">
<img src="https://picx.zhimg.com/v2-b4ea0e17edf85598b89785546c0991c2" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="Experience-Driven-Exploration-for-Efficient-API-Free-AI-Agents"><a href="#Experience-Driven-Exploration-for-Efficient-API-Free-AI-Agents" class="headerlink" title="Experience-Driven Exploration for Efficient API-Free AI Agents"></a>Experience-Driven Exploration for Efficient API-Free AI Agents</h2><p><strong>Authors:Chenwei Tang, Jingyu Xing, Xinyu Liu, Zizhou Wang, Jiawei Du, Liangli Zhen, Jiancheng Lv</strong></p>
<p>Most existing software lacks accessible Application Programming Interfaces (APIs), requiring agents to operate solely through pixel-based Graphical User Interfaces (GUIs). In this API-free setting, large language model (LLM)-based agents face severe efficiency bottlenecks: limited to local visual experiences, they make myopic decisions and rely on inefficient trial-and-error, hindering both skill acquisition and long-term planning. To address these challenges, we propose KG-Agent, an experience-driven learning framework that structures an agentâ€™s raw pixel-level interactions into a persistent State-Action Knowledge Graph (SA-KG). KG-Agent overcomes inefficient exploration by linking functionally similar but visually distinct GUI states, forming a rich neighborhood of experience that enables the agent to generalize from a diverse set of historical strategies. To support long-horizon reasoning, we design a hybrid intrinsic reward mechanism based on the graph topology, combining a state value reward for exploiting known high-value pathways with a novelty reward that encourages targeted exploration. This approach decouples strategic planning from pure discovery, allowing the agent to effectively value setup actions with delayed gratification. We evaluate KG-Agent in two complex, open-ended GUI-based decision-making environments (Civilization V and Slay the Spire), demonstrating significant improvements in exploration efficiency and strategic depth over the state-of-the-art methods. </p>
<blockquote>
<p>ç°æœ‰å¤§å¤šæ•°è½¯ä»¶ç¼ºä¹å¯è®¿é—®çš„åº”ç”¨ç¨‹åºç¼–ç¨‹æ¥å£ï¼ˆAPIï¼‰ï¼Œå¯¼è‡´æ™ºèƒ½ä½“åªèƒ½é€šè¿‡åŸºäºåƒç´ çš„å›¾å½¢ç”¨æˆ·ç•Œé¢ï¼ˆGUIï¼‰è¿›è¡Œæ“ä½œã€‚åœ¨è¿™ç§æ— APIçš„è®¾ç½®ä¸‹ï¼ŒåŸºäºå¤§å‹è¯­è¨€æ¨¡å‹çš„æ™ºèƒ½ä½“é¢ä¸´ä¸¥é‡çš„æ•ˆç‡ç“¶é¢ˆï¼šå®ƒä»¬ä»…é™äºæœ¬åœ°è§†è§‰ä½“éªŒï¼Œåšå‡ºçŸ­è§†çš„å†³ç­–ï¼Œå¹¶ä¾èµ–ä½æ•ˆçš„è¯•é”™æ–¹æ³•ï¼Œè¿™é˜»ç¢äº†æŠ€èƒ½è·å–å’Œé•¿æœŸè§„åˆ’ã€‚ä¸ºäº†è§£å†³è¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†KG-Agentï¼Œè¿™æ˜¯ä¸€ç§ä»¥ç»éªŒé©±åŠ¨çš„å­¦ä¹ æ¡†æ¶ï¼Œå®ƒå°†æ™ºèƒ½ä½“çš„åŸå§‹åƒç´ çº§äº’åŠ¨ç»“æ„åŒ–ä¸ºä¸€ä¸ªæŒä¹…çš„çŠ¶æ€-åŠ¨ä½œçŸ¥è¯†å›¾ï¼ˆSA-KGï¼‰ã€‚KG-Agenté€šè¿‡è¿æ¥åŠŸèƒ½ç›¸ä¼¼ä½†è§†è§‰ä¸Šæœ‰åŒºåˆ«çš„GUIçŠ¶æ€æ¥å…‹æœä½æ•ˆçš„æ¢ç´¢ï¼Œå½¢æˆäº†ä¸€ä¸ªä¸°å¯Œçš„ç»éªŒé‚»åŸŸï¼Œä½¿æ™ºèƒ½ä½“èƒ½å¤Ÿä»ä¸€ç³»åˆ—å†å²ç­–ç•¥ä¸­æ¦‚æ‹¬çŸ¥è¯†ã€‚ä¸ºäº†æ”¯æŒé•¿æœŸæ¨ç†ï¼Œæˆ‘ä»¬è®¾è®¡äº†ä¸€ç§åŸºäºå›¾å½¢æ‹“æ‰‘çš„æ··åˆå†…åœ¨å¥–åŠ±æœºåˆ¶ï¼Œè¯¥æœºåˆ¶ç»“åˆäº†çŠ¶æ€ä»·å€¼å¥–åŠ±ï¼Œç”¨äºåˆ©ç”¨å·²çŸ¥çš„é«˜ä»·å€¼è·¯å¾„ï¼Œä»¥åŠé¼“åŠ±æœ‰é’ˆå¯¹æ€§çš„æ¢ç´¢çš„æ–°é¢–æ€§å¥–åŠ±ã€‚è¿™ç§æ–¹æ³•å°†æˆ˜ç•¥è§„åˆ’ä¸çº¯ç²¹çš„å‘ç°è§£è€¦ï¼Œå…è®¸æ™ºèƒ½ä½“æœ‰æ•ˆåœ°è¯„ä¼°å»¶è¿Ÿæ»¡è¶³çš„è®¾ç½®åŠ¨ä½œã€‚æˆ‘ä»¬åœ¨ä¸¤ä¸ªå¤æ‚ä¸”å¼€æ”¾å¼çš„GUIå†³ç­–ç¯å¢ƒï¼ˆæ–‡æ˜Vå’Œå± æ€å¡”åˆºï¼‰ä¸­å¯¹KG-Agentè¿›è¡Œäº†è¯„ä¼°ï¼Œä¸æœ€å…ˆè¿›çš„æ–¹æ³•ç›¸æ¯”ï¼Œå®ƒåœ¨æ¢ç´¢æ•ˆç‡å’Œæˆ˜ç•¥æ·±åº¦æ–¹é¢è¡¨ç°å‡ºäº†æ˜¾è‘—çš„æ”¹è¿›ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.15259v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºä¸€ç§åŸºäºçŸ¥è¯†å›¾è°±çš„ä»£ç†å­¦ä¹ æ¡†æ¶KG-Agentï¼Œè§£å†³äº†ç°æœ‰è½¯ä»¶ç¼ºä¹åº”ç”¨ç¨‹åºç¼–ç¨‹æ¥å£ï¼ˆAPIï¼‰å¯¼è‡´çš„æ•ˆç‡ç“¶é¢ˆé—®é¢˜ã€‚KG-Agentèƒ½å¤Ÿå°†ä»£ç†çš„åŸå§‹åƒç´ çº§äº¤äº’ç»“æ„åŒ–å¹¶æŒä¹…åŒ–ä¸ºçŠ¶æ€åŠ¨ä½œçŸ¥è¯†å›¾è°±ï¼ˆSA-KGï¼‰ã€‚å®ƒå…‹æœäº†ä½æ•ˆçš„æ¢ç´¢ï¼Œé€šè¿‡é“¾æ¥åŠŸèƒ½ç›¸ä¼¼ä½†è§†è§‰ä¸åŒçš„GUIçŠ¶æ€ï¼Œå½¢æˆä¸€ä¸ªä¸°å¯Œçš„ç»éªŒé‚»åŸŸï¼Œä½¿ä»£ç†èƒ½å¤Ÿä»ä¸€ç³»åˆ—å†å²ç­–ç•¥ä¸­æ¦‚æ‹¬çŸ¥è¯†ã€‚æ­¤å¤–ï¼Œè¿˜è®¾è®¡äº†ä¸€ç§åŸºäºå›¾å½¢æ‹“æ‰‘çš„æ··åˆå†…åœ¨å¥–åŠ±æœºåˆ¶ï¼Œä»¥æ”¯æŒé•¿æœŸè§„åˆ’ã€‚åœ¨å¤æ‚çš„å¼€æ”¾GUIå†³ç­–ç¯å¢ƒï¼ˆå¦‚æ–‡æ˜äº”å’Œå‡»è´¥é­”ç‹ï¼‰ä¸­ï¼ŒKG-Agentæ˜¾ç¤ºå‡ºæ˜¾è‘—çš„æ¢ç´¢æ•ˆç‡å’Œæˆ˜ç•¥æ·±åº¦æ”¹è¿›ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>è½¯ä»¶ä¸­æ™®éå­˜åœ¨ç¼ºä¹åº”ç”¨ç¨‹åºç¼–ç¨‹æ¥å£ï¼ˆAPIï¼‰ï¼Œå¯¼è‡´å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä»£ç†åœ¨æ“ä½œè¿‡ç¨‹ä¸­å­˜åœ¨æ•ˆç‡ç“¶é¢ˆã€‚</li>
<li>KG-Agentæ˜¯ä¸€ç§åŸºäºçŸ¥è¯†å›¾è°±çš„å­¦ä¹ æ¡†æ¶ï¼Œå¯ä»¥å°†ä»£ç†çš„åƒç´ çº§äº¤äº’ç»“æ„åŒ–å¹¶æŒä¹…åŒ–ã€‚</li>
<li>KG-Agenté€šè¿‡é“¾æ¥åŠŸèƒ½ç›¸ä¼¼ä½†è§†è§‰ä¸åŒçš„GUIçŠ¶æ€ï¼Œå½¢æˆä¸°å¯Œçš„ç»éªŒé‚»åŸŸï¼Œæé«˜ä»£ç†çš„æ¦‚æ‹¬èƒ½åŠ›ã€‚</li>
<li>KG-Agentè®¾è®¡äº†ä¸€ç§åŸºäºå›¾å½¢æ‹“æ‰‘çš„æ··åˆå†…åœ¨å¥–åŠ±æœºåˆ¶ï¼Œä»¥æ”¯æŒé•¿æœŸè§„åˆ’ã€‚</li>
<li>è¯¥æœºåˆ¶ç»“åˆäº†çŠ¶æ€ä»·å€¼å¥–åŠ±å’Œæ–°é¢–æ€§å¥–åŠ±ï¼Œä»¥é¼“åŠ±æœ‰é’ˆå¯¹æ€§çš„æ¢ç´¢å’Œè§£è„±çš„æˆ˜ç•¥è§„åˆ’ã€‚</li>
<li>KG-Agentåœ¨å¤æ‚çš„å¼€æ”¾GUIå†³ç­–ç¯å¢ƒä¸­è¡¨ç°å‡ºæ˜¾è‘—çš„æ¢ç´¢æ•ˆç‡å’Œæˆ˜ç•¥æ·±åº¦æ”¹è¿›ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.15259">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-c0e4515c7ee7db3eafc40f16cbca9c7b" align="middle">
<img src="https://picx.zhimg.com/v2-caa2fe8a841d7ec0a1c95ce2910b57cf" align="middle">
<img src="https://picx.zhimg.com/v2-d3f708bd9060c1e30120648770b2929d" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="KVCOMM-Online-Cross-context-KV-cache-Communication-for-Efficient-LLM-based-Multi-agent-Systems"><a href="#KVCOMM-Online-Cross-context-KV-cache-Communication-for-Efficient-LLM-based-Multi-agent-Systems" class="headerlink" title="KVCOMM: Online Cross-context KV-cache Communication for Efficient   LLM-based Multi-agent Systems"></a>KVCOMM: Online Cross-context KV-cache Communication for Efficient   LLM-based Multi-agent Systems</h2><p><strong>Authors:Hancheng Ye, Zhengqi Gao, Mingyuan Ma, Qinsi Wang, Yuzhe Fu, Ming-Yu Chung, Yueqian Lin, Zhijian Liu, Jianyi Zhang, Danyang Zhuo, Yiran Chen</strong></p>
<p>Multi-agent large language model (LLM) systems are increasingly adopted for complex language processing tasks that require communication and coordination among agents. However, these systems often suffer substantial overhead from repeated reprocessing of overlapping contexts across agents. In typical pipelines, once an agent receives a message from its predecessor, the full context-including prior turns-must be reprocessed from scratch, leading to inefficient processing. While key-value (KV) caching is an effective solution for avoiding redundant computation in single-agent settings where prefixes remain unchanged, it cannot be directly reused in multi-agent scenarios due to diverging prefixes introduced by agent-specific context extensions. We identify that the core challenge lies in the offset variance of KV-caches across agents. To address this, we propose KVCOMM, a training-free framework that enables efficient prefilling in multi-agent inference by reusing KV-caches and aligning cache offsets of overlapping contexts under diverse prefix contexts. KVCOMM estimates and adjusts KV-caches for shared content by referencing a pool of cached examples-termed anchors-that store observed cache deviations under varying prefixes. The anchor pool is maintained and updated online, allowing dynamic adaptation to distinct user requests and context structures. KVCOMM achieves over 70% reuse rate across diverse multi-agent workloads, including retrieval-augmented generation, math reasoning, and collaborative coding tasks, all without quality degradation. Particularly, when each fully-connected agent receives 1K input tokens with 512 prefix tokens and 512 output tokens under a five-agent setting, KVCOMM achieves up to 7.8x speedup compared to the standard prefill pipeline, reducing TTFT from ~430 ms to ~55 ms. </p>
<blockquote>
<p>å¤šä¸»ä½“å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ç³»ç»Ÿè¶Šæ¥è¶Šå¤šåœ°è¢«ç”¨äºéœ€è¦ä¸»ä½“é—´é€šä¿¡å’Œåè°ƒçš„å¤æ‚è¯­è¨€å¤„ç†ä»»åŠ¡ã€‚ç„¶è€Œï¼Œè¿™äº›ç³»ç»Ÿç»å¸¸é­å—æ¥è‡ªä¸»ä½“é—´é‡å ä¸Šä¸‹æ–‡é‡å¤å¤„ç†çš„å·¨å¤§å¼€é”€ã€‚åœ¨å…¸å‹æµç¨‹ä¸­ï¼Œä¸€æ—¦ä¸»ä½“æ”¶åˆ°æ¥è‡ªå…¶å‰åºä¸»ä½“çš„æ¶ˆæ¯ï¼Œæ•´ä¸ªä¸Šä¸‹æ–‡ï¼ˆåŒ…æ‹¬å…ˆå‰çš„å›åˆï¼‰å¿…é¡»ä»å¤´å¼€å§‹é‡æ–°å¤„ç†ï¼Œå¯¼è‡´å¤„ç†æ•ˆç‡ä½ä¸‹ã€‚è™½ç„¶åœ¨å•ä¸»ä½“ç¯å¢ƒä¸­ï¼Œé”®å€¼ï¼ˆKVï¼‰ç¼“å­˜å¯¹äºé¿å…å†—ä½™è®¡ç®—æ˜¯ä¸€ä¸ªæœ‰æ•ˆçš„è§£å†³æ–¹æ¡ˆï¼Œå…¶ä¸­å‰ç¼€ä¿æŒä¸å˜ï¼Œä½†ç”±äºä¸»ä½“ç‰¹å®šçš„ä¸Šä¸‹æ–‡æ‰©å±•å¯¼è‡´çš„å‰ç¼€åˆ†æ­§ï¼Œå®ƒä¸èƒ½ç›´æ¥ç”¨äºå¤šä¸»ä½“åœºæ™¯ã€‚æˆ‘ä»¬ç¡®å®šäº†æ ¸å¿ƒæŒ‘æˆ˜åœ¨äºä¸»ä½“é—´KVç¼“å­˜çš„åç§»é‡å·®å¼‚ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†KVCOMMï¼Œè¿™æ˜¯ä¸€ä¸ªæ— éœ€è®­ç»ƒçš„æ¡†æ¶ï¼Œé€šè¿‡é‡ç”¨KVç¼“å­˜å’Œå¯¹ä¸åŒå‰ç¼€ä¸Šä¸‹æ–‡ä¸‹é‡å ä¸Šä¸‹æ–‡çš„ç¼“å­˜åç§»è¿›è¡Œå¯¹é½ï¼Œå®ç°äº†å¤šä¸»ä½“æ¨æ–­ä¸­çš„é«˜æ•ˆé¢„å¡«å……ã€‚KVCOMMé€šè¿‡å¼•ç”¨å­˜å‚¨äº†è§‚å¯Ÿåˆ°çš„ç¼“å­˜åå·®çš„é”šç‚¹ç¤ºä¾‹æ± æ¥ä¼°è®¡å’Œè°ƒæ•´å…±äº«å†…å®¹çš„KVç¼“å­˜ã€‚è¿™ä¸ªé”šç‚¹æ± åœ¨çº¿ç»´æŠ¤å’Œæ›´æ–°ï¼Œå…è®¸æ ¹æ®ç‹¬ç‰¹çš„ç”¨æˆ·è¯·æ±‚å’Œä¸Šä¸‹æ–‡ç»“æ„è¿›è¡ŒåŠ¨æ€é€‚åº”ã€‚KVCOMMåœ¨å¤šæ ·åŒ–çš„å¤šä¸»ä½“å·¥ä½œè´Ÿè½½ä¸Šå®ç°äº†è¶…è¿‡70%çš„é‡ç”¨ç‡ï¼ŒåŒ…æ‹¬å¢å¼ºæ£€ç´¢ç”Ÿæˆã€æ•°å­¦æ¨ç†å’Œåä½œç¼–ç ä»»åŠ¡ç­‰ï¼Œä¸”ä¸ä¼šé™ä½è´¨é‡ã€‚å°¤å…¶å½“æ¯ä¸ªå…¨è¿æ¥çš„ä¸»ä½“åœ¨äº”ä¸ªä¸»ä½“çš„è®¾ç½®ä¸‹æ¥æ”¶1Kè¾“å…¥ä»¤ç‰Œï¼ˆåŒ…æ‹¬512ä¸ªå‰ç¼€ä»¤ç‰Œå’Œ512ä¸ªè¾“å‡ºä»¤ç‰Œï¼‰æ—¶ï¼ŒKVCOMMä¸æ ‡å‡†é¢„å¡«å……æµæ°´çº¿ç›¸æ¯”ï¼Œå®ç°äº†é«˜è¾¾7.8å€çš„åŠ é€Ÿï¼Œå°†TTFTä»çº¦430æ¯«ç§’å‡å°‘åˆ°çº¦55æ¯«ç§’ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.12872v2">PDF</a> Accepted for publication in NeurIPS2025. Code is available at   \url{<a target="_blank" rel="noopener" href="https://github.com/FastMAS/KVCOMM%7D">https://github.com/FastMAS/KVCOMM}</a></p>
<p><strong>Summary</strong></p>
<p>è¯¥æ–‡æœ¬ä»‹ç»äº†å¤šä»£ç†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ç³»ç»Ÿåœ¨å¤„ç†å¤æ‚çš„è¯­è¨€ä»»åŠ¡æ—¶é¢ä¸´çš„æŒ‘æˆ˜ï¼Œå¦‚é‡å¤å¤„ç†é‡å çš„ä¸Šä¸‹æ–‡å¯¼è‡´æ•ˆç‡ä½ä¸‹çš„é—®é¢˜ã€‚æ–‡ç« æå‡ºKVCOMMæ¡†æ¶ï¼Œèƒ½å¤Ÿåœ¨æ— éœ€è®­ç»ƒçš„æƒ…å†µä¸‹ï¼Œé€šè¿‡é‡ç”¨KVç¼“å­˜å¹¶è°ƒæ•´ç¼“å­˜åç§»æ¥å…‹æœå¤šä»£ç†ç¯å¢ƒä¸­çš„å†—ä½™è®¡ç®—é—®é¢˜ï¼Œä»è€Œæé«˜å¤šä»£ç†æ¨ç†çš„æ•ˆç‡ã€‚è¯¥æ¡†æ¶åˆ©ç”¨é”šæ± æ¥å­˜å‚¨è§‚å¯Ÿåˆ°çš„ç¼“å­˜åå·®ï¼Œå¹¶å¯¹å…¶è¿›è¡ŒåŠ¨æ€è°ƒæ•´ä»¥é€‚åº”ä¸åŒçš„ç”¨æˆ·è¯·æ±‚å’Œä¸Šä¸‹æ–‡ç»“æ„ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒKVCOMMåœ¨å¤šç§å¤šä»£ç†å·¥ä½œè´Ÿè½½ä¸Šå®ç°äº†è¶…è¿‡70%çš„é‡ç”¨ç‡ï¼Œä¸”æ²¡æœ‰è´¨é‡ä¸‹é™ã€‚åœ¨ç‰¹å®šçš„å®éªŒæ¡ä»¶ä¸‹ï¼Œä¸æ ‡å‡†çš„é¢„å¡«å……ç®¡é“ç›¸æ¯”ï¼ŒKVCOMMå®ç°äº†é«˜è¾¾7.8å€çš„åŠ é€Ÿã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤šä»£ç†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨å¤„ç†å¤æ‚çš„è¯­è¨€ä»»åŠ¡æ—¶é¢ä¸´é‡å¤å¤„ç†é‡å ä¸Šä¸‹æ–‡çš„é—®é¢˜ï¼Œå¯¼è‡´æ•ˆç‡ä½ä¸‹ã€‚</li>
<li>KVCOMMæ¡†æ¶æ—¨åœ¨è§£å†³å¤šä»£ç†ç¯å¢ƒä¸­å†—ä½™è®¡ç®—çš„é—®é¢˜ï¼Œé€šè¿‡é‡ç”¨KVç¼“å­˜å¹¶è°ƒæ•´ç¼“å­˜åç§»æ¥æé«˜å¤šä»£ç†æ¨ç†çš„æ•ˆç‡ã€‚</li>
<li>KVCOMMåˆ©ç”¨é”šæ± æ¥å­˜å‚¨å¹¶æ›´æ–°ç¼“å­˜åå·®ï¼Œä»¥é€‚åº”ä¸åŒçš„ç”¨æˆ·è¯·æ±‚å’Œä¸Šä¸‹æ–‡ç»“æ„ã€‚</li>
<li>KVCOMMåœ¨å¤šç§å¤šä»£ç†å·¥ä½œè´Ÿè½½ä¸Šå®ç°äº†è¶…è¿‡70%çš„ç¼“å­˜é‡ç”¨ç‡ï¼Œä¸”ä¸ä¼šé™ä½è´¨é‡ã€‚</li>
<li>åœ¨ç‰¹å®šæ¡ä»¶ä¸‹ï¼Œä¸æ ‡å‡†é¢„å¡«å……ç®¡é“ç›¸æ¯”ï¼ŒKVCOMMå®ç°äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ï¼Œè¾¾åˆ°7.8å€çš„åŠ é€Ÿã€‚</li>
<li>KVCOMMæ¡†æ¶æ— éœ€è®­ç»ƒï¼Œå¯å¿«é€Ÿé€‚åº”ä¸åŒçš„ç¯å¢ƒå’Œä»»åŠ¡éœ€æ±‚ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.12872">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-fc3a756b6a5931deff93f50d1cec5650" align="middle">
<img src="https://picx.zhimg.com/v2-dc56c44c5ea255771f17ae0c40fdcaed" align="middle">
<img src="https://picx.zhimg.com/v2-313cfc2d62ffd167e1389f41b01104b2" align="middle">
<img src="https://picx.zhimg.com/v2-8d796a6c0e90e3a8b48761e2e972393a" align="middle">
<img src="https://picx.zhimg.com/v2-7808092f47df9122ecec394e2031bb6e" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="A-Survey-of-Reasoning-and-Agentic-Systems-in-Time-Series-with-Large-Language-Models"><a href="#A-Survey-of-Reasoning-and-Agentic-Systems-in-Time-Series-with-Large-Language-Models" class="headerlink" title="A Survey of Reasoning and Agentic Systems in Time Series with Large   Language Models"></a>A Survey of Reasoning and Agentic Systems in Time Series with Large   Language Models</h2><p><strong>Authors:Ching Chang, Yidan Shi, Defu Cao, Wei Yang, Jeehyun Hwang, Haixin Wang, Jiacheng Pang, Wei Wang, Yan Liu, Wen-Chih Peng, Tien-Fu Chen</strong></p>
<p>Time series reasoning treats time as a first-class axis and incorporates intermediate evidence directly into the answer. This survey defines the problem and organizes the literature by reasoning topology with three families: direct reasoning in one step, linear chain reasoning with explicit intermediates, and branch-structured reasoning that explores, revises, and aggregates. The topology is crossed with the main objectives of the field, including traditional time series analysis, explanation and understanding, causal inference and decision making, and time series generation, while a compact tag set spans these axes and captures decomposition and verification, ensembling, tool use, knowledge access, multimodality, agent loops, and LLM alignment regimes. Methods and systems are reviewed across domains, showing what each topology enables and where it breaks down in faithfulness or robustness, along with curated datasets, benchmarks, and resources that support study and deployment (<a target="_blank" rel="noopener" href="https://github.com/blacksnail789521/Time-Series-Reasoning-Survey">https://github.com/blacksnail789521/Time-Series-Reasoning-Survey</a>). Evaluation practices that keep evidence visible and temporally aligned are highlighted, and guidance is distilled on matching topology to uncertainty, grounding with observable artifacts, planning for shift and streaming, and treating cost and latency as design budgets. We emphasize that reasoning structures must balance capacity for grounding and self-correction against computational cost and reproducibility, while future progress will likely depend on benchmarks that tie reasoning quality to utility and on closed-loop testbeds that trade off cost and risk under shift-aware, streaming, and long-horizon settings. Taken together, these directions mark a shift from narrow accuracy toward reliability at scale, enabling systems that not only analyze but also understand, explain, and act on dynamic worlds with traceable evidence and credible outcomes. </p>
<blockquote>
<p>æ—¶é—´åºåˆ—æ¨ç†å°†æ—¶é—´è§†ä¸ºç¬¬ä¸€ç±»çš„è½´ï¼Œå¹¶å°†ä¸­é—´è¯æ®ç›´æ¥çº³å…¥ç­”æ¡ˆä¸­ã€‚æœ¬æ–‡é€šè¿‡æ¨ç†æ‹“æ‰‘æ¥å®šä¹‰é—®é¢˜å¹¶æ•´ç†æ–‡çŒ®ï¼Œä¸»è¦åˆ†ä¸ºä¸‰ä¸ªå®¶æ—ï¼šä¸€æ­¥ç›´æ¥æ¨ç†ã€å…·æœ‰æ˜ç¡®ä¸­é—´ä½“çš„çº¿æ€§é“¾æ¨ç†ï¼Œä»¥åŠæ¢ç´¢ã€ä¿®è®¢å’Œèšåˆçš„åˆ†æ”¯ç»“æ„æ¨ç†ã€‚æ‹“æ‰‘ä¸é¢†åŸŸçš„ä¸»è¦ç›®æ ‡ç›¸ç»“åˆï¼ŒåŒ…æ‹¬ä¼ ç»Ÿçš„æ—¶é—´åºåˆ—åˆ†æã€è§£é‡Šå’Œç†è§£ã€å› æœæ¨ç†å’Œå†³ç­–åˆ¶å®šï¼Œä»¥åŠæ—¶é—´åºåˆ—ç”Ÿæˆï¼›åŒæ—¶ï¼Œä¸€ä¸ªç´§å‡‘çš„æ ‡ç­¾é›†è·¨è¶Šè¿™äº›è½´ï¼Œæ¶µç›–åˆ†è§£å’ŒéªŒè¯ã€é›†æˆã€å·¥å…·ä½¿ç”¨ã€çŸ¥è¯†è®¿é—®ã€å¤šæ¨¡æ€æ€§ã€ä»£ç†å¾ªç¯å’ŒLLMå¯¹é½æœºåˆ¶ç­‰ã€‚æœ¬æ–‡å›é¡¾äº†ä¸åŒé¢†åŸŸçš„æ–¹æ³•å’Œç³»ç»Ÿï¼Œå±•ç¤ºäº†æ¯ç§æ‹“æ‰‘çš„ä¼˜ç¼ºç‚¹ï¼Œä»¥åŠæ”¯æŒç ”ç©¶å’Œéƒ¨ç½²çš„ç²¾é€‰æ•°æ®é›†ã€åŸºå‡†æµ‹è¯•å’Œèµ„æºï¼ˆ<a target="_blank" rel="noopener" href="https://github.com/blacksnail789521/Time-Series-Reasoning-Survey%EF%BC%89%E3%80%82%E6%9C%AC%E6%96%87%E5%BC%BA%E8%B0%83%E4%BA%86%E4%BF%9D%E6%8C%81%E8%AF%81%E6%8D%AE%E5%8F%AF%E8%A7%81%E4%B8%94%E6%97%B6%E9%97%B4%E5%AF%B9%E9%BD%90%E7%9A%84%E8%AF%84%E4%BC%B0%E5%AE%9E%E8%B7%B5%EF%BC%8C%E5%B9%B6%E5%B0%B1%E5%8C%B9%E9%85%8D%E6%8B%93%E6%89%91%E4%B8%8E%E4%B8%8D%E7%A1%AE%E5%AE%9A%E6%80%A7%E3%80%81%E4%B8%8E%E5%8F%AF%E8%A7%82%E5%AF%9F%E5%88%B0%E7%9A%84%E4%BC%AA%E8%BF%B9%E6%8E%A5%E5%9C%B0%E3%80%81%E8%A7%84%E5%88%92%E8%BD%AC%E5%8F%98%E5%92%8C%E6%B5%81%E5%BC%8F%E4%BC%A0%E8%BE%93%E4%BB%A5%E5%8F%8A%E5%B0%86%E6%88%90%E6%9C%AC%E5%92%8C%E5%BB%B6%E8%BF%9F%E8%A7%86%E4%B8%BA%E8%AE%BE%E8%AE%A1%E9%A2%84%E7%AE%97%E7%AD%89%E6%96%B9%E9%9D%A2%E6%8F%90%E4%BE%9B%E4%BA%86%E6%8C%87%E5%AF%BC%E3%80%82%E6%88%91%E4%BB%AC%E5%BC%BA%E8%B0%83%EF%BC%8C%E6%8E%A8%E7%90%86%E7%BB%93%E6%9E%84%E5%BF%85%E9%A1%BB%E5%9C%A8%E5%9C%B0%E9%9D%A2%E5%92%8C%E8%87%AA%E6%A0%A1%E6%AD%A3%E8%83%BD%E5%8A%9B%E3%80%81%E8%AE%A1%E7%AE%97%E6%88%90%E6%9C%AC%E5%92%8C%E5%8F%AF%E9%87%8D%E5%A4%8D%E6%80%A7%E4%B9%8B%E9%97%B4%E5%8F%96%E5%BE%97%E5%B9%B3%E8%A1%A1%EF%BC%8C%E8%80%8C%E6%9C%AA%E6%9D%A5%E7%9A%84%E8%BF%9B%E5%B1%95%E5%8F%AF%E8%83%BD%E5%8F%96%E5%86%B3%E4%BA%8E%E5%B0%86%E6%8E%A8%E7%90%86%E8%B4%A8%E9%87%8F%E4%B8%8E%E5%AE%9E%E7%94%A8%E6%80%A7%E8%81%94%E7%B3%BB%E5%9C%A8%E4%B8%80%E8%B5%B7%E7%9A%84%E5%9F%BA%E5%87%86%E6%B5%8B%E8%AF%95%EF%BC%8C%E4%BB%A5%E5%8F%8A%E5%9C%A8%E5%85%B7%E6%9C%89%E8%BD%AC%E5%8F%98%E6%84%9F%E7%9F%A5%E3%80%81%E6%B5%81%E5%BC%8F%E4%BC%A0%E8%BE%93%E5%92%8C%E9%95%BF%E6%9C%9F%E8%A7%86%E9%87%8E%E7%9A%84%E5%B0%81%E9%97%AD%E5%BE%AA%E7%8E%AF%E6%B5%8B%E8%AF%95%E5%BA%8A%E4%B8%8A%E6%9D%83%E8%A1%A1%E6%88%90%E6%9C%AC%E5%92%8C%E9%A3%8E%E9%99%A9%E7%9A%84%E5%AE%9E%E8%B7%B5%E3%80%82%E6%80%BB%E4%B9%8B%EF%BC%8C%E8%BF%99%E4%BA%9B%E6%96%B9%E5%90%91%E6%A0%87%E5%BF%97%E7%9D%80%E4%BB%8E%E7%8B%AD%E9%9A%98%E7%9A%84%E5%87%86%E7%A1%AE%E6%80%A7%E5%90%91%E5%A4%A7%E8%A7%84%E6%A8%A1%E5%8F%AF%E9%9D%A0%E6%80%A7%E8%BD%AC%E5%8F%98%EF%BC%8C%E4%BD%BF%E7%B3%BB%E7%BB%9F%E4%B8%8D%E4%BB%85%E8%83%BD%E5%A4%9F%E5%88%86%E6%9E%90%EF%BC%8C%E8%80%8C%E4%B8%94%E8%83%BD%E5%A4%9F%E7%90%86%E8%A7%A3%E3%80%81%E8%A7%A3%E9%87%8A%E5%92%8C%E9%87%87%E5%8F%96%E5%AE%9E%E9%99%85%E8%A1%8C%E5%8A%A8%EF%BC%8C%E5%AF%B9%E5%8A%A8%E6%80%81%E4%B8%96%E7%95%8C%E4%BA%A7%E7%94%9F%E5%8F%AF%E8%BF%BD%E8%B8%AA%E7%9A%84%E8%AF%81%E6%8D%AE%E5%92%8C%E5%8F%AF%E4%BF%A1%E7%9A%84%E7%BB%93%E6%9E%9C%E3%80%82">https://github.com/blacksnail789521/Time-Series-Reasoning-Surveyï¼‰ã€‚æœ¬æ–‡å¼ºè°ƒäº†ä¿æŒè¯æ®å¯è§ä¸”æ—¶é—´å¯¹é½çš„è¯„ä¼°å®è·µï¼Œå¹¶å°±åŒ¹é…æ‹“æ‰‘ä¸ä¸ç¡®å®šæ€§ã€ä¸å¯è§‚å¯Ÿåˆ°çš„ä¼ªè¿¹æ¥åœ°ã€è§„åˆ’è½¬å˜å’Œæµå¼ä¼ è¾“ä»¥åŠå°†æˆæœ¬å’Œå»¶è¿Ÿè§†ä¸ºè®¾è®¡é¢„ç®—ç­‰æ–¹é¢æä¾›äº†æŒ‡å¯¼ã€‚æˆ‘ä»¬å¼ºè°ƒï¼Œæ¨ç†ç»“æ„å¿…é¡»åœ¨åœ°é¢å’Œè‡ªæ ¡æ­£èƒ½åŠ›ã€è®¡ç®—æˆæœ¬å’Œå¯é‡å¤æ€§ä¹‹é—´å–å¾—å¹³è¡¡ï¼Œè€Œæœªæ¥çš„è¿›å±•å¯èƒ½å–å†³äºå°†æ¨ç†è´¨é‡ä¸å®ç”¨æ€§è”ç³»åœ¨ä¸€èµ·çš„åŸºå‡†æµ‹è¯•ï¼Œä»¥åŠåœ¨å…·æœ‰è½¬å˜æ„ŸçŸ¥ã€æµå¼ä¼ è¾“å’Œé•¿æœŸè§†é‡çš„å°é—­å¾ªç¯æµ‹è¯•åºŠä¸Šæƒè¡¡æˆæœ¬å’Œé£é™©çš„å®è·µã€‚æ€»ä¹‹ï¼Œè¿™äº›æ–¹å‘æ ‡å¿—ç€ä»ç‹­éš˜çš„å‡†ç¡®æ€§å‘å¤§è§„æ¨¡å¯é æ€§è½¬å˜ï¼Œä½¿ç³»ç»Ÿä¸ä»…èƒ½å¤Ÿåˆ†æï¼Œè€Œä¸”èƒ½å¤Ÿç†è§£ã€è§£é‡Šå’Œé‡‡å–å®é™…è¡ŒåŠ¨ï¼Œå¯¹åŠ¨æ€ä¸–ç•Œäº§ç”Ÿå¯è¿½è¸ªçš„è¯æ®å’Œå¯ä¿¡çš„ç»“æœã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.11575v2">PDF</a> This paper is currently under review</p>
<p><strong>Summary</strong><br>     æ—¶é—´åºåˆ—æ¨ç†å°†æ—¶é—´ä½œä¸ºé¦–è¦è€ƒé‡è½´ï¼Œèå…¥ä¸­é—´è¯æ®ç›´æ¥å¾—å‡ºç­”æ¡ˆã€‚è¿™ç¯‡ç»¼è¿°å®šä¹‰äº†é—®é¢˜å¹¶é€šè¿‡æ¨ç†æ‹“æ‰‘ç»„ç»‡æ–‡çŒ®ï¼Œåˆ†ä¸ºä¸‰ä¸ªç±»åˆ«ï¼šä¸€æ­¥ç›´æ¥æ¨ç†ã€å¸¦æœ‰æ˜ç¡®ä¸­é—´ä½“çš„çº¿æ€§é“¾æ¨ç†å’Œæ¢ç©¶ã€ä¿®è®¢å¹¶èšåˆçš„åˆ†æ”¯ç»“æ„æ¨ç†ã€‚æ‹“æ‰‘ä¸é¢†åŸŸçš„ä¸»è¦ç›®æ ‡ç›¸ç»“åˆï¼ŒåŒ…æ‹¬ä¼ ç»Ÿæ—¶é—´åºåˆ—åˆ†æã€è§£é‡Šä¸ç†è§£ã€å› æœæ¨æ–­ä¸å†³ç­–åˆ¶å®šä»¥åŠæ—¶é—´åºåˆ—ç”Ÿæˆã€‚åŒæ—¶ï¼Œä¸€ä¸ªç´§å‡‘çš„æ ‡ç­¾é›†è·¨è¶Šè¿™äº›è½´ï¼Œæ¶µç›–åˆ†è§£ä¸éªŒè¯ã€é›†æˆã€å·¥å…·ä½¿ç”¨ã€çŸ¥è¯†è®¿é—®ã€å¤šæ¨¡æ€æ€§ã€ä»£ç†å¾ªç¯å’ŒLLMå¯¹é½æœºåˆ¶ç­‰ã€‚æœ¬æ–‡è¯„è¿°äº†ä¸åŒé¢†åŸŸçš„æ–¹æ³•å’Œç³»ç»Ÿï¼Œå±•ç¤ºäº†æ¯ç§æ‹“æ‰‘çš„ä¼˜åŠ¿å’Œå±€é™æ€§ï¼Œå¹¶æä¾›äº†æ”¯æŒç ”ç©¶å’Œéƒ¨ç½²çš„æ•°æ®é›†ã€åŸºå‡†æµ‹è¯•å’Œèµ„æºã€‚å¼ºè°ƒäº†åœ¨ä¿æŒè¯æ®å¯è§æ€§å’Œæ—¶é—´å¯¹é½çš„è¯„ä¼°å®è·µä¸‹ï¼Œå¯¹åŒ¹é…æ‹“æ‰‘åˆ°ä¸ç¡®å®šæ€§ã€ä¸å¯è§‚å¯Ÿåˆ°çš„å·¥ä»¶æ¥åœ°ã€è§„åˆ’è½¬å˜å’Œæµå¼ä¼ è¾“ä»¥åŠå°†æˆæœ¬å’Œå»¶è¿Ÿä½œä¸ºè®¾è®¡é¢„ç®—çš„æŒ‡å¯¼æ„è§è¿›è¡Œäº†æç‚¼ã€‚æœªæ¥è¿›å±•å¯èƒ½å–å†³äºå°†æ¨ç†è´¨é‡ä¸å®ç”¨æ€§ç›¸è”ç³»çš„åŸºå‡†æµ‹è¯•ï¼Œä»¥åŠèƒ½å¤Ÿåœ¨æˆæœ¬å’Œé£é™©ä¹‹é—´è¿›è¡Œæƒè¡¡çš„é—­ç¯æµ‹è¯•å¹³å°ã€‚è¿™ç¯‡ç»¼è¿°æ ‡å¿—ç€ä»ç‹­éš˜çš„å‡†ç¡®æ€§å‘å¤§è§„æ¨¡å¯é æ€§çš„è½¬å˜ï¼Œä½¿ç³»ç»Ÿä¸ä»…èƒ½å¤Ÿåˆ†æè€Œä¸”èƒ½å¤Ÿç†è§£ã€è§£é‡Šå’Œè¡ŒåŠ¨äºåŠ¨æ€ä¸–ç•Œï¼Œå…·æœ‰å¯è¿½æº¯çš„è¯æ®å’Œå¯ä¿¡çš„ç»“æœã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æ—¶é—´åºåˆ—æ¨ç†å°†æ—¶é—´è§†ä¸ºé¦–è¦è€ƒé‡è½´ï¼Œèå…¥ä¸­é—´è¯æ®è¿›è¡Œæ¨ç†ã€‚</li>
<li>ç»¼è¿°å®šä¹‰äº†æ—¶é—´åºåˆ—æ¨ç†çš„é—®é¢˜å¹¶é€šè¿‡æ¨ç†æ‹“æ‰‘ç»„ç»‡æ–‡çŒ®ï¼ŒåŒ…æ‹¬ç›´æ¥æ¨ç†ã€çº¿æ€§é“¾æ¨ç†å’Œåˆ†æ”¯ç»“æ„æ¨ç†ã€‚</li>
<li>æ¨ç†æ‹“æ‰‘ä¸é¢†åŸŸç›®æ ‡ï¼ˆå¦‚ä¼ ç»Ÿæ—¶é—´åºåˆ—åˆ†æã€è§£é‡Šä¸ç†è§£ç­‰ï¼‰ç›¸ç»“åˆã€‚</li>
<li>ç´§å‡‘çš„æ ‡ç­¾é›†åŒ…å«åˆ†è§£ä¸éªŒè¯ã€é›†æˆã€å·¥å…·ä½¿ç”¨ç­‰å¤šæ¨¡æ€æ€§å…³é”®è¦ç´ ã€‚</li>
<li>æ–¹æ³•å’Œç³»ç»Ÿçš„è¯„è¿°å±•ç¤ºäº†å„ç§æ‹“æ‰‘çš„ä¼˜åŠ¿å’Œå±€é™æ€§ï¼Œå¹¶æä¾›æ•°æ®é›†ã€åŸºå‡†æµ‹è¯•å’Œèµ„æºæ”¯æŒã€‚</li>
<li>å¼ºè°ƒä¿æŒè¯æ®å¯è§æ€§å’Œæ—¶é—´å¯¹é½çš„è¯„ä¼°å®è·µï¼Œæä¾›åŒ¹é…æ‹“æ‰‘ä¸ä¸ç¡®å®šæ€§çš„æŒ‡å¯¼ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.11575">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-fad1b689814d0202e7d837dc5dcf5ff5" align="middle">
<img src="https://picx.zhimg.com/v2-56cd859ad1a23e228b842b55c3fe3a48" align="middle">
<img src="https://picx.zhimg.com/v2-be326dfe4ce09d5bcef2b5d7a4416fa7" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="SE-Agent-Self-Evolution-Trajectory-Optimization-in-Multi-Step-Reasoning-with-LLM-Based-Agents"><a href="#SE-Agent-Self-Evolution-Trajectory-Optimization-in-Multi-Step-Reasoning-with-LLM-Based-Agents" class="headerlink" title="SE-Agent: Self-Evolution Trajectory Optimization in Multi-Step Reasoning   with LLM-Based Agents"></a>SE-Agent: Self-Evolution Trajectory Optimization in Multi-Step Reasoning   with LLM-Based Agents</h2><p><strong>Authors:Jiaye Lin, Yifu Guo, Yuzhen Han, Sen Hu, Ziyi Ni, Licheng Wang, Mingguang Chen, Hongzhang Liu, Ronghao Chen, Yangfan He, Daxin Jiang, Binxing Jiao, Chen Hu, Huacan Wang</strong></p>
<p>Large Language Model (LLM)-based agents have recently shown impressive capabilities in complex reasoning and tool use via multi-step interactions with their environments. While these agents have the potential to tackle complicated tasks, their problem-solving process, i.e., agentsâ€™ interaction trajectory leading to task completion, remains underexploited. These trajectories contain rich feedback that can navigate agents toward the right directions for solving problems correctly. Although prevailing approaches, such as Monte Carlo Tree Search (MCTS), can effectively balance exploration and exploitation, they ignore the interdependence among various trajectories and lack the diversity of search spaces, which leads to redundant reasoning and suboptimal outcomes. To address these challenges, we propose SE-Agent, a Self-Evolution framework that enables Agents to optimize their reasoning processes iteratively. Our approach revisits and enhances former pilot trajectories through three key operations: revision, recombination, and refinement. This evolutionary mechanism enables two critical advantages: (1) it expands the search space beyond local optima by intelligently exploring diverse solution paths guided by previous trajectories, and (2) it leverages cross-trajectory inspiration to efficiently enhance performance while mitigating the impact of suboptimal reasoning paths. Through these mechanisms, SE-Agent achieves continuous self-evolution that incrementally improves reasoning quality. We evaluate SE-Agent on SWE-bench Verified to resolve real-world GitHub issues. Experimental results across five strong LLMs show that integrating SE-Agent delivers up to 55% relative improvement, achieving state-of-the-art performance among all open-source agents on SWE-bench Verified. Our code and demonstration materials are publicly available at <a target="_blank" rel="noopener" href="https://github.com/JARVIS-Xs/SE-Agent">https://github.com/JARVIS-Xs/SE-Agent</a>. </p>
<blockquote>
<p>åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„ä»£ç†æœ€è¿‘è¡¨ç°å‡ºé€šè¿‡ä¸å…¶ç¯å¢ƒçš„å¤šæ­¥éª¤äº¤äº’è¿›è¡Œå¤æ‚æ¨ç†å’Œå·¥å…·ä½¿ç”¨çš„ä»¤äººå°è±¡æ·±åˆ»çš„èƒ½åŠ›ã€‚è™½ç„¶è¿™äº›ä»£ç†æœ‰æ½œåŠ›å¤„ç†å¤æ‚ä»»åŠ¡ï¼Œä½†ä»–ä»¬çš„è§£å†³é—®é¢˜è¿‡ç¨‹ï¼Œå³ä»£ç†å®Œæˆä»»åŠ¡çš„äº¤äº’è½¨è¿¹ï¼Œä»æœªå¾—åˆ°å……åˆ†æ¢ç´¢ã€‚è¿™äº›è½¨è¿¹åŒ…å«ä¸°å¯Œçš„åé¦ˆï¼Œå¯ä»¥å¼•å¯¼ä»£ç†æœç€æ­£ç¡®çš„æ–¹å‘è§£å†³é—®é¢˜ã€‚è™½ç„¶ç°æœ‰çš„æ–¹æ³•ï¼Œå¦‚è’™ç‰¹å¡æ´›æ ‘æœç´¢ï¼ˆMCTSï¼‰ï¼Œå¯ä»¥æœ‰æ•ˆåœ°å¹³è¡¡æ¢ç´¢å’Œåˆ©ç”¨ï¼Œä½†å®ƒä»¬å¿½ç•¥äº†å„ç§è½¨è¿¹ä¹‹é—´çš„ç›¸äº’ä¾èµ–æ€§ï¼Œç¼ºä¹æœç´¢ç©ºé—´çš„å¤šæ ·æ€§ï¼Œè¿™å¯¼è‡´å†—ä½™æ¨ç†å’Œæ¬¡ä¼˜ç»“æœã€‚ä¸ºäº†è§£å†³è¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†SE-Agentï¼Œè¿™æ˜¯ä¸€ç§è‡ªæˆ‘è¿›åŒ–æ¡†æ¶ï¼Œä½¿ä»£ç†èƒ½å¤Ÿè¿­ä»£åœ°ä¼˜åŒ–ä»–ä»¬çš„æ¨ç†è¿‡ç¨‹ã€‚æˆ‘ä»¬çš„æ–¹æ³•é€šè¿‡ä¸‰ä¸ªå…³é”®æ“ä½œï¼šä¿®è®¢ã€é‡ç»„å’Œç»†åŒ–ï¼Œæ¥é‡æ–°å®¡è§†å’Œæ”¹è¿›å…ˆå‰çš„è½¨è¿¹ã€‚è¿™ç§è¿›åŒ–æœºåˆ¶å¸¦æ¥äº†ä¸¤ä¸ªå…³é”®ä¼˜åŠ¿ï¼šï¼ˆ1ï¼‰å®ƒé€šè¿‡æ™ºèƒ½åœ°æ¢ç´¢ä»¥å‰è½¨è¿¹å¼•å¯¼çš„å¤šæ ·åŒ–è§£å†³æ–¹æ¡ˆè·¯å¾„ï¼Œæ‰©å¤§äº†æœç´¢ç©ºé—´ï¼Œè¶…è¶Šäº†å±€éƒ¨æœ€ä¼˜ï¼›ï¼ˆ2ï¼‰å®ƒåˆ©ç”¨è·¨è½¨è¿¹çš„çµæ„Ÿæ¥æœ‰æ•ˆåœ°æé«˜æ€§èƒ½ï¼ŒåŒæ—¶å‡è½»æ¬¡ä¼˜æ¨ç†è·¯å¾„çš„å½±å“ã€‚é€šè¿‡è¿™äº›æœºåˆ¶ï¼ŒSE-Agentå®ç°äº†æŒç»­çš„è‡ªæˆ‘è¿›åŒ–ï¼Œé€æ­¥æé«˜äº†æ¨ç†è´¨é‡ã€‚æˆ‘ä»¬åœ¨SWE-bench Verifiedä¸Šè¯„ä¼°äº†SE-Agentï¼Œä»¥è§£å†³ç°å®ä¸–ç•Œä¸­çš„GitHubé—®é¢˜ã€‚åœ¨äº”ä¸ªå¼ºå¤§çš„LLMä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼Œé›†æˆSE-Agentå¸¦æ¥äº†é«˜è¾¾55%çš„ç›¸å¯¹æ”¹è¿›ï¼Œåœ¨SWE-bench Verifiedä¸Šçš„å¼€æºä»£ç†ä¸­å®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚æˆ‘ä»¬çš„ä»£ç å’Œæ¼”ç¤ºææ–™å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/JARVIS-Xs/SE-Agent%E4%B8%8A%E5%85%AC%E5%BC%80%E8%8E%B7%E5%BE%97%E3%80%82">https://github.com/JARVIS-Xs/SE-Agentä¸Šå…¬å¼€è·å¾—ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.02085v6">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„ä»£ç†åœ¨å¤æ‚æ¨ç†å’Œå·¥å…·ä½¿ç”¨æ–¹é¢å±•ç°å‡ºå¼ºå¤§çš„èƒ½åŠ›ï¼Œé€šè¿‡ä¸ç¯å¢ƒçš„å¤šæ­¥äº¤äº’å®Œæˆä»»åŠ¡ã€‚ç„¶è€Œï¼Œå…¶è§£é¢˜è¿‡ç¨‹ï¼Œå³ä»£ç†çš„äº¤äº’è½¨è¿¹ï¼Œå°šæœªå¾—åˆ°å……åˆ†ç ”ç©¶ã€‚è¿™äº›è½¨è¿¹åŒ…å«ä¸°å¯Œçš„åé¦ˆï¼Œå¯ä»¥å¼•å¯¼ä»£ç†æ­£ç¡®è§£å†³é—®é¢˜ã€‚è™½ç„¶ç°æœ‰çš„æ–¹æ³•å¦‚è’™ç‰¹å¡æ´›æ ‘æœç´¢ï¼ˆMCTSï¼‰å¯ä»¥å¹³è¡¡æ¢ç´¢å’Œå¼€å‘ï¼Œä½†å®ƒä»¬å¿½ç•¥äº†è½¨è¿¹ä¹‹é—´çš„ä¾èµ–æ€§ï¼Œå¹¶ä¸”ç¼ºä¹æœç´¢ç©ºé—´çš„å¤šæ ·æ€§ï¼Œå¯¼è‡´å†—ä½™æ¨ç†å’Œæ¬¡ä¼˜ç»“æœã€‚ä¸ºè§£å†³è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†SE-Agentï¼Œä¸€ä¸ªè‡ªæˆ‘è¿›åŒ–æ¡†æ¶ï¼Œä½¿ä»£ç†èƒ½å¤Ÿè¿­ä»£ä¼˜åŒ–å…¶æ¨ç†è¿‡ç¨‹ã€‚é€šè¿‡ä¿®è®¢ã€é‡ç»„å’Œç»†åŒ–ä¹‹å‰çš„è½¨è¿¹ï¼ŒSE-Agentå®ç°äº†ä¸¤ä¸ªå…³é”®ä¼˜åŠ¿ï¼šä¸€æ˜¯é€šè¿‡æ™ºèƒ½æ¢ç´¢ç”±å…ˆå‰è½¨è¿¹å¼•å¯¼çš„å¤šæ ·åŒ–è§£å†³æ–¹æ¡ˆè·¯å¾„æ¥æ‰©å±•æœç´¢ç©ºé—´è¶…è¶Šå±€éƒ¨æœ€ä¼˜ï¼›äºŒæ˜¯åˆ©ç”¨è·¨è½¨è¿¹çµæ„Ÿæ¥æœ‰æ•ˆå¢å¼ºæ€§èƒ½å¹¶å‡å°‘æ¬¡ä¼˜æ¨ç†è·¯å¾„çš„å½±å“ã€‚åœ¨GitHubé—®é¢˜ä¸Šå¯¹SE-Agentè¿›è¡ŒSWE-bench Verifiedè¯„ä¼°æ˜¾ç¤ºï¼Œç›¸è¾ƒäºäº”ç§é¡¶å°–LLMé›†æˆç®—æ³•æé«˜åˆ°äº†æœ€é«˜å¯è¾¾çš„ç™¾åˆ†ä¹‹äº”åäº”çš„æ€§èƒ½æ”¹è¿›æ•ˆæœã€‚å…¬å¼€çš„ä»£ç å’Œæ¼”ç¤ºææ–™å·²åœ¨Githubå…¬å¼€æ‰˜ç®¡æœåŠ¡ä¸­å¼€æ”¾å…±äº«ã€‚æˆ‘ä»¬åœ¨é™„ä»¶æä¾›äº†æˆ‘ä»¬æå‡ºçš„ç ”ç©¶å®ç°çš„è¿›ä¸€æ­¥è§£è¯»å’Œæ€»ç»“ä»£ç å±•ç¤ºä¸‹è½½åœ°å€å’Œè¯¦ç»†å†…å®¹å‚è€ƒæè¿°æ–‡ä»¶åœ°å€ä»¥ä¾›å‚è€ƒã€‚[æ€»ç»“ç”±å…¶ä»–äººåœ¨è‡ªç„¶è¯­è¨€è¯­å¢ƒä¸‹ç®€åŒ–ç‰ˆå¤è¿°ç‰ˆæœ¬ï¼Œå¦‚æœ‰åå·®è¯·ä»¥åŸæ–‡ä¸ºå‡†] </p>
<p><strong>Key Takeaways</strong></p>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.02085">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-1887ba010ee3aabb095b636d1a3398b3" align="middle">
<img src="https://picx.zhimg.com/v2-243e0e97f0eea7fa8142b2276bcef793" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="A-Self-Evolving-AI-Agent-System-for-Climate-Science"><a href="#A-Self-Evolving-AI-Agent-System-for-Climate-Science" class="headerlink" title="A Self-Evolving AI Agent System for Climate Science"></a>A Self-Evolving AI Agent System for Climate Science</h2><p><strong>Authors:Zijie Guo, Jiong Wang, Fenghua Ling, Wangxu Wei, Xiaoyu Yue, Zhe Jiang, Wanghan Xu, Jing-Jia Luo, Lijing Cheng, Yoo-Geun Ham, Fengfei Song, Pierre Gentine, Toshio Yamagata, Ben Fei, Wenlong Zhang, Xinyu Gu, Chao Li, Yaqiang Wang, Tao Chen, Wanli Ouyang, Bowen Zhou, Lei Bai</strong></p>
<p>Scientific progress in Earth science depends on integrating data across the planetâ€™s interconnected spheres. However, the accelerating volume and fragmentation of multi-sphere knowledge and data have surpassed human analytical capacity. This creates a major bottleneck for discovery, especially in climate science. To address this challenge, we introduce EarthLink, the first self-evolving AI agent system designed as an interactive â€œcopilotâ€ for Earth scientists. Through natural language interaction, EarthLink automates the entire research workflow by integrating planning, code execution, data analysis, and physical reasoning into a unified process that directly addresses this limitation. Beyond efficiency, it exhibits human-like cross-disciplinary analytical ability and achieves proficiency comparable to a junior researcher in expert evaluations on core large-scale climate tasks, including model-observation comparison and climate change understanding. When tasked with an open scientific problem, specifically the discovery of precursors of the Atlantic Ni~no, EarthLink autonomously developed a research strategy, identified sources of predictability, verified its hypotheses with available data, and proposed a physically consistent mechanism. These emerging capabilities enable a new human-AI research paradigm. Scientists can focus on value and result judgments, while AI systems handle complex data analysis and knowledge integration. This accelerates the pace and breadth of discovery in Earth sciences. The system is accessible at our website <a target="_blank" rel="noopener" href="https://earthlink.intern-ai.org.cn/">https://earthlink.intern-ai.org.cn</a>. </p>
<blockquote>
<p>åœ°çƒç§‘å­¦çš„ç§‘å­¦è¿›æ­¥å–å†³äºæ•´åˆå…¨çƒäº’è”é¢†åŸŸçš„æ•°æ®ã€‚ç„¶è€Œï¼Œå¤šé¢†åŸŸçŸ¥è¯†å’Œæ•°æ®çš„ä¸æ–­å¢åŠ å’Œç¢ç‰‡åŒ–å·²ç»è¶…å‡ºäº†äººç±»çš„åˆ†æèƒ½åŠ›ï¼Œè¿™æˆä¸ºäº†å‘ç°çš„ä¸»è¦ç“¶é¢ˆï¼Œç‰¹åˆ«æ˜¯åœ¨æ°”å€™ç§‘å­¦é¢†åŸŸã€‚ä¸ºäº†åº”å¯¹è¿™ä¸€æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æ¨å‡ºäº†EarthLinkï¼Œè¿™æ˜¯é¦–ä¸ªè‡ªæˆ‘è¿›åŒ–çš„AIä»£ç†ç³»ç»Ÿï¼Œæ—¨åœ¨æˆä¸ºåœ°çƒç§‘å­¦å®¶çš„äº¤äº’å¼â€œå‰¯é©¾é©¶â€ã€‚é€šè¿‡è‡ªç„¶è¯­è¨€äº¤äº’ï¼ŒEarthLinké€šè¿‡æ•´åˆè§„åˆ’ã€ä»£ç æ‰§è¡Œã€æ•°æ®åˆ†æå’Œç‰©ç†æ¨ç†ï¼Œå°†æ•´ä¸ªè¿‡ç¨‹è‡ªåŠ¨åŒ–ï¼Œç›´æ¥è§£å†³è¿™ä¸€é™åˆ¶ã€‚é™¤äº†æé«˜æ•ˆç‡å¤–ï¼Œå®ƒè¿˜è¡¨ç°å‡ºç±»ä¼¼äººç±»çš„è·¨å­¦ç§‘åˆ†æèƒ½åŠ›ï¼Œå¹¶åœ¨æ ¸å¿ƒå¤§è§„æ¨¡æ°”å€™ä»»åŠ¡çš„ä¸“å®¶è¯„ä¼°ä¸­è¾¾åˆ°äº†åˆçº§ç ”ç©¶å‘˜çš„ä¸“ä¸šæ°´å¹³ï¼ŒåŒ…æ‹¬æ¨¡å‹è§‚æµ‹å¯¹æ¯”å’Œæ°”å€™å˜åŒ–ç†è§£ã€‚åœ¨é¢å¯¹ä¸€ä¸ªå…¬å¼€çš„ç§‘å­¦é—®é¢˜ï¼Œç‰¹åˆ«æ˜¯å¤§è¥¿æ´‹å°¼è¯ºå…ˆå…†çš„å‘ç°é—®é¢˜æ—¶ï¼ŒEarthLinkè‡ªä¸»åœ°åˆ¶å®šäº†ç ”ç©¶ç­–ç•¥ï¼Œç¡®å®šäº†å¯é¢„æµ‹æ€§çš„æ¥æºï¼Œç”¨ç°æœ‰æ•°æ®éªŒè¯äº†å…¶å‡è®¾ï¼Œå¹¶æå‡ºäº†ä¸€ä¸ªç‰©ç†ä¸€è‡´çš„æœºåˆ¶ã€‚è¿™äº›æ–°å…´çš„èƒ½åŠ›ä½¿äººç±»-AIç ”ç©¶èŒƒå¼å¾—ä»¥æ›´æ–°ã€‚ç§‘å­¦å®¶ä»¬å¯ä»¥ä¸“æ³¨äºä»·å€¼å’Œç»“æœåˆ¤æ–­ï¼Œè€ŒAIç³»ç»Ÿåˆ™å¤„ç†å¤æ‚çš„æ•°æ®åˆ†æå’ŒçŸ¥è¯†æ•´åˆã€‚è¿™åŠ å¿«äº†åœ°çƒç§‘å­¦å‘ç°çš„æ­¥ä¼å’Œå¹¿åº¦ã€‚è¯¥ç³»ç»Ÿå¯åœ¨æˆ‘ä»¬çš„ç½‘ç«™<a target="_blank" rel="noopener" href="https://earthlink.intern-ai.org.cnè®¿é—®./">https://earthlink.intern-ai.org.cnè®¿é—®ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2507.17311v3">PDF</a> </p>
<p><strong>æ‘˜è¦</strong></p>
<p>åœ°çƒç§‘å­¦é¢†åŸŸçš„ç§‘å­¦è¿›æ­¥ä¾èµ–äºå¯¹å…¨çƒäº’è”é¢†åŸŸçš„æ•°æ®è¿›è¡Œé›†æˆã€‚ç„¶è€Œï¼Œéšç€çŸ¥è¯†å’Œæ•°æ®ä½“é‡çš„ä¸æ–­åŠ é€Ÿå¢é•¿å’Œç¢ç‰‡åŒ–ï¼Œå·²ç»è¶…å‡ºäº†äººç±»çš„åˆ†æèƒ½åŠ›ã€‚è¿™æˆä¸ºäº†å‘ç°çš„ä¸€å¤§ç“¶é¢ˆï¼Œç‰¹åˆ«æ˜¯åœ¨æ°”å€™ç§‘å­¦é¢†åŸŸã€‚ä¸ºè§£å†³è¿™ä¸€æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æ¨å‡ºäº†EarthLinkï¼Œé¦–ä¸ªè‡ªæˆ‘è¿›åŒ–çš„AIä»£ç†ç³»ç»Ÿï¼Œæ—¨åœ¨æˆä¸ºåœ°çƒç§‘å­¦å®¶çš„äº¤äº’å¼â€œå‰¯é©¾é©¶â€ã€‚é€šè¿‡è‡ªç„¶è¯­è¨€äº¤äº’ï¼ŒEarthLinkè‡ªåŠ¨åŒ–äº†æ•´ä¸ªç ”ç©¶å·¥ä½œæµç¨‹ï¼Œå°†è§„åˆ’ã€ä»£ç æ‰§è¡Œã€æ•°æ®åˆ†æå’Œç‰©ç†æ¨ç†æ•´åˆä¸ºä¸€ä¸ªç»Ÿä¸€çš„è¿‡ç¨‹ï¼Œç›´æ¥è§£å†³äº†è¿™ä¸€å±€é™æ€§ã€‚é™¤äº†æé«˜æ•ˆç‡å¤–ï¼Œå®ƒè¿˜å…·æœ‰è·¨å­¦ç§‘çš„äººç±»åˆ†æèƒ½åŠ›ï¼Œå¹¶åœ¨æ ¸å¿ƒçš„å¤§è§„æ¨¡æ°”å€™ä»»åŠ¡çš„è¯„ä»·ä¸­è¾¾åˆ°äº†åˆçº§ç ”ç©¶å‘˜çš„æ°´å¹³ï¼ŒåŒ…æ‹¬æ¨¡å‹è§‚æµ‹æ¯”è¾ƒå’Œæ°”å€™å˜åŒ–ç†è§£ã€‚é¢å¯¹å¼€æ”¾çš„ç§‘ç ”é—®é¢˜ï¼Œä¾‹å¦‚å¤§è¥¿æ´‹Ni~noçš„å…ˆå…†å‘ç°ï¼ŒEarthLinkå¯è‡ªä¸»åˆ¶å®šç ”ç©¶ç­–ç•¥ï¼Œç¡®å®šé¢„æµ‹çš„æ¥æºï¼Œç”¨ç°æœ‰æ•°æ®éªŒè¯å‡è®¾ï¼Œå¹¶æå‡ºç‰©ç†ä¸€è‡´çš„æœºåˆ¶ã€‚è¿™äº›æ–°å…´çš„èƒ½åŠ›ä½¿äººç±»-AIç ”ç©¶èŒƒå¼å¾—ä»¥å¼€å¯ã€‚ç§‘å­¦å®¶å¯ä»¥ä¸“æ³¨äºä»·å€¼å’Œç»“æœåˆ¤æ–­ï¼Œè€ŒAIç³»ç»Ÿåˆ™å¤„ç†å¤æ‚çš„æ•°æ®åˆ†æå’ŒçŸ¥è¯†æ•´åˆã€‚è¿™åŠ é€Ÿäº†åœ°çƒç§‘å­¦é¢†åŸŸçš„å‘ç°é€Ÿåº¦å’Œå¹¿åº¦ã€‚è¯¥ç³»ç»Ÿå¯é€šè¿‡è®¿é—®æˆ‘ä»¬çš„ç½‘ç«™<a target="_blank" rel="noopener" href="https://www.earthlink.intern-ai.org.cnè·å–./">https://www.earthlink.intern-ai.org.cnè·å–ã€‚</a></p>
<p><strong>å…³é”®è§è§£</strong></p>
<ol>
<li>åœ°çƒç§‘å­¦è¿›æ­¥éœ€æ•´åˆå…¨çƒäº’è”é¢†åŸŸçš„æ•°æ®ã€‚</li>
<li>çŸ¥è¯†å’Œæ•°æ®çš„å¿«é€Ÿå¢åŠ å’Œç¢ç‰‡åŒ–å·²è¶…è¶Šäººç±»åˆ†æèƒ½åŠ›çš„æé™ã€‚</li>
<li>EarthLinkæ˜¯é¦–ä¸ªè‡ªæˆ‘è¿›åŒ–çš„AIä»£ç†ç³»ç»Ÿï¼Œæ—¨åœ¨è§£å†³æ­¤æŒ‘æˆ˜ã€‚</li>
<li>EarthLinké€šè¿‡è‡ªç„¶è¯­è¨€äº¤äº’è‡ªåŠ¨åŒ–ç ”ç©¶æµç¨‹ï¼Œå¹¶é›†æˆäº†è§„åˆ’ã€ä»£ç æ‰§è¡Œã€æ•°æ®åˆ†æå’Œç‰©ç†æ¨ç†ã€‚</li>
<li>EarthLinkå…·æœ‰è·¨å­¦ç§‘çš„äººç±»åˆ†æèƒ½åŠ›ï¼Œå¹¶åœ¨æ°”å€™ç§‘å­¦ä»»åŠ¡ä¸­è¡¨ç°å‡ºåˆçº§ç ”ç©¶å‘˜æ°´å¹³çš„æŠ€èƒ½ã€‚</li>
<li>åœ¨å¤„ç†å¼€æ”¾ç§‘å­¦é—®é¢˜æ—¶ï¼ŒEarthLinkèƒ½è‡ªä¸»åˆ¶å®šç­–ç•¥ã€éªŒè¯å‡è®¾å¹¶æå‡ºç‰©ç†æœºåˆ¶ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2507.17311">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-39cc11336a177d389db1b65ba9fae352" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="How-to-Train-Your-LLM-Web-Agent-A-Statistical-Diagnosis"><a href="#How-to-Train-Your-LLM-Web-Agent-A-Statistical-Diagnosis" class="headerlink" title="How to Train Your LLM Web Agent: A Statistical Diagnosis"></a>How to Train Your LLM Web Agent: A Statistical Diagnosis</h2><p><strong>Authors:Dheeraj Vattikonda, Santhoshi Ravichandran, Emiliano Penaloza, Hadi Nekoei, Megh Thakkar, Thibault Le Sellier de Chezelles, Nicolas Gontier, Miguel MuÃ±oz-MÃ¡rmol, Sahar Omidi Shayegan, Stefania Raimondo, Xue Liu, Alexandre Drouin, Laurent Charlin, Alexandre PichÃ©, Alexandre Lacoste, Massimo Caccia</strong></p>
<p>LLM-based web agents have recently made significant progress, but much of it has occurred in closed-source systems, widening the gap with open-source alternatives. Progress has been held back by two key challenges: first, a narrow focus on single-step tasks that overlooks the complexity of multi-step web interactions; and second, the high compute costs required to post-train LLM-based web agents. To address this, we present the first statistically grounded study on compute allocation for LLM web-agent post-training. Our approach uses a two-stage pipeline, training a Llama 3.1 8B student to imitate a Llama 3.3 70B teacher via supervised fine-tuning (SFT), followed by on-policy reinforcement learning. We find this process highly sensitive to hyperparameter choices, making exhaustive sweeps impractical. To spare others from expensive trial-and-error, we sample 1,370 configurations and use bootstrapping to estimate effective hyperparameters. Our results show that combining SFT with on-policy RL consistently outperforms either approach alone on both WorkArena and MiniWob++. Further, this strategy requires only 55% of the compute to match the peak performance of pure SFT on MiniWob++, effectively pushing the compute-performance Pareto frontier, and is the only strategy that can close the gap with closed-source models. </p>
<blockquote>
<p>åŸºäºLLMçš„Webä»£ç†æœ€è¿‘å–å¾—äº†æ˜¾è‘—è¿›å±•ï¼Œä½†å¤§éƒ¨åˆ†è¿›å±•å‡ºç°åœ¨å°é—­æºä»£ç ç³»ç»Ÿä¸­ï¼Œä¸å¼€æºæ›¿ä»£æ–¹æ¡ˆçš„å·®è·åŠ å¤§ã€‚è¿›å±•å—åˆ°ä¸¤ä¸ªä¸»è¦æŒ‘æˆ˜çš„é™åˆ¶ï¼šé¦–å…ˆï¼Œå¯¹å•æ­¥ä»»åŠ¡çš„ç‹­çª„å…³æ³¨ï¼Œå¿½è§†äº†å¤šæ­¥Webäº¤äº’çš„å¤æ‚æ€§ï¼›å…¶æ¬¡ï¼ŒåŸºäºLLMçš„Webä»£ç†åè®­ç»ƒæ‰€éœ€çš„é«˜è®¡ç®—æˆæœ¬ã€‚ä¸ºè§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬å¯¹LLM Webä»£ç†åè®­ç»ƒçš„è®¡ç®—åˆ†é…è¿›è¡Œäº†é¦–æ¬¡ç»Ÿè®¡ç ”ç©¶ã€‚æˆ‘ä»¬çš„æ–¹æ³•é‡‡ç”¨ä¸¤é˜¶æ®µç®¡é“ï¼Œè®­ç»ƒä¸€ä¸ªLlama 3.1 8Bå­¦ç”Ÿï¼Œé€šè¿‡æœ‰ç›‘ç£çš„å¾®è°ƒï¼ˆSFTï¼‰æ¨¡ä»¿Llama 3.3 70Bæ•™å¸ˆï¼Œéšåè¿›è¡ŒåŸºäºç­–ç•¥çš„ç­–ç•¥å¼ºåŒ–å­¦ä¹ ã€‚æˆ‘ä»¬å‘ç°è¿™ä¸ªè¿‡ç¨‹å¯¹è¶…å‚æ•°é€‰æ‹©éå¸¸æ•æ„Ÿï¼Œä½¿å…¨é¢æ‰«æå˜å¾—ä¸åˆ‡å®é™…ã€‚ä¸ºäº†èŠ‚çœä»–äººæ˜‚è´µçš„è¯•é”™è¿‡ç¨‹ï¼Œæˆ‘ä»¬å¯¹1370ä¸ªé…ç½®è¿›è¡ŒæŠ½æ ·ï¼Œå¹¶ä½¿ç”¨bootstrappingä¼°è®¡æœ‰æ•ˆçš„è¶…å‚æ•°ã€‚æˆ‘ä»¬çš„ç»“æœè¡¨æ˜ï¼Œç»“åˆSFTå’ŒåŸºäºç­–ç•¥RLçš„æ–¹æ³•åœ¨å·¥ä½œç«æŠ€åœºå’ŒMiniWob++ä¸Šå§‹ç»ˆä¼˜äºå•ç‹¬ä½¿ç”¨ä»»ä½•ä¸€ç§æ–¹æ³•ã€‚æ­¤å¤–ï¼Œè¯¥ç­–ç•¥ä»…éœ€55%çš„è®¡ç®—é‡å³å¯è¾¾åˆ°çº¯SFTåœ¨MiniWob++ä¸Šçš„å³°å€¼æ€§èƒ½ï¼Œæœ‰æ•ˆåœ°æ¨åŠ¨äº†è®¡ç®—æ€§èƒ½å¸•ç´¯æ‰˜å‰æ²¿ï¼Œå¹¶ä¸”æ˜¯å”¯ä¸€èƒ½å¤Ÿç¼©å°ä¸å°é—­æºä»£ç æ¨¡å‹å·®è·çš„ç­–ç•¥ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2507.04103v3">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>LLMç½‘ç»œä»£ç†åœ¨é—­æºç³»ç»Ÿä¸­å–å¾—æ˜¾è‘—è¿›å±•ï¼Œä½†ä¸å¼€æºæ›¿ä»£æ–¹æ¡ˆä¹‹é—´å­˜åœ¨å·®è·ã€‚ç ”ç©¶é€šè¿‡ç»Ÿè®¡ç ”ç©¶è®¡ç®—åˆ†é…æ¥è§£å†³LLMç½‘ç»œä»£ç†åè®­ç»ƒé¢ä¸´çš„æŒ‘æˆ˜ï¼Œé‡‡ç”¨ä¸¤é˜¶æ®µç®¡é“ï¼Œé€šè¿‡ç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰è®­ç»ƒLlama 3.1 8Bå­¦ç”Ÿæ¥æ¨¡ä»¿Llama 3.3 70Bæ•™å¸ˆï¼Œç„¶åè¿›è¡Œç­–ç•¥å¼ºåŒ–å­¦ä¹ ã€‚ç ”ç©¶å‘ç°è¯¥è¿‡ç¨‹å¯¹è¶…å‚æ•°é€‰æ‹©é«˜åº¦æ•æ„Ÿï¼Œé€šè¿‡é‡‡æ ·1370ç§é…ç½®å¹¶åˆ©ç”¨bootstrapä¼°è®¡æœ‰æ•ˆè¶…å‚æ•°æ¥é¿å…æ˜‚è´µçš„è¯•é”™è¿‡ç¨‹ã€‚ç»“åˆSFTå’Œç­–ç•¥RLçš„æ–¹æ³•åœ¨WorkArenaå’ŒMiniWob++ä¸Šçš„è¡¨ç°å‡ä¼˜äºå•ç‹¬ä½¿ç”¨å…¶ä¸­ä»»ä½•ä¸€ç§æ–¹æ³•ã€‚æ­¤æ–¹æ³•åªéœ€ä½¿ç”¨çº¦55%çš„è®¡ç®—èµ„æºå³å¯è¾¾åˆ°åœ¨MiniWob++ä¸Šçš„å³°å€¼æ€§èƒ½ï¼Œæœ‰æ•ˆåœ°æ¨åŠ¨äº†è®¡ç®—æ€§èƒ½å¸•ç´¯æ‰˜å‰æ²¿ï¼Œå¹¶ä¸”æ˜¯å”¯ä¸€èƒ½å¤Ÿç¼©å°ä¸é—­æºæ¨¡å‹å·®è·çš„ç­–ç•¥ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>LLMç½‘ç»œä»£ç†åœ¨é—­æºç³»ç»Ÿä¸­å–å¾—æ˜¾è‘—è¿›å±•ï¼Œä½†å¼€æºä¸é—­æºä¹‹é—´å­˜åœ¨å·®è·ã€‚</li>
<li>ç ”ç©¶çš„æŒ‘æˆ˜åŒ…æ‹¬å•æ­¥ä»»åŠ¡è§†é‡ç‹­çª„ï¼Œå¿½è§†å¤šæ­¥äº¤äº’å¤æ‚æ€§ä»¥åŠé«˜æ˜‚çš„è®¡ç®—æˆæœ¬ã€‚</li>
<li>ç ”ç©¶é‡‡ç”¨ä¸¤é˜¶æ®µç®¡é“è§£å†³æŒ‘æˆ˜ï¼ŒåŒ…æ‹¬ç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰å’Œç­–ç•¥å¼ºåŒ–å­¦ä¹ ã€‚</li>
<li>æ–¹æ³•å¯¹è¶…å‚æ•°é€‰æ‹©é«˜åº¦æ•æ„Ÿï¼Œå› æ­¤é€šè¿‡å¤§é‡é‡‡æ ·é…ç½®ä¼°è®¡æœ‰æ•ˆè¶…å‚æ•°æ¥é¿å…è¯•é”™ã€‚</li>
<li>ç»“åˆSFTå’Œç­–ç•¥RLçš„æ–¹æ³•åœ¨å¤šä¸ªä»»åŠ¡ä¸Šè¡¨ç°ä¼˜è¶Šã€‚</li>
<li>æ­¤æ–¹æ³•åœ¨è®¡ç®—èµ„æºä½¿ç”¨ä¸Šæ›´ä¸ºé«˜æ•ˆï¼Œæ¨åŠ¨äº†è®¡ç®—æ€§èƒ½å‰æ²¿ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2507.04103">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-4fe2c8243ddc5841a4a32c794d8ea536" align="middle">
<img src="https://picx.zhimg.com/v2-ade1769f22dda1f303b12d5b292fc2be" align="middle">
<img src="https://picx.zhimg.com/v2-d0b71dd9eec0eaff35956afe95d8cd53" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="VideoExplorer-Think-With-Videos-For-Agentic-Long-Video-Understanding"><a href="#VideoExplorer-Think-With-Videos-For-Agentic-Long-Video-Understanding" class="headerlink" title="VideoExplorer: Think With Videos For Agentic Long-Video Understanding"></a>VideoExplorer: Think With Videos For Agentic Long-Video Understanding</h2><p><strong>Authors:Huaying Yuan, Zheng Liu, Junjie Zhou, Hongjin Qian, Yan Shu, Nicu Sebe, Ji-Rong Wen, Zhicheng Dou</strong></p>
<p>Long-video understanding~(LVU) is a challenging problem in computer vision. Existing methods either downsample frames for single-pass reasoning, sacrificing fine-grained details, or depend on textual reasoning over task-agnostic representations, hindering task-specific perception and exploration. In this paper, we propose VideoExplorer, a framework grounded in the principle of &#96;&#96;thinking with videoâ€™â€™, which naturally intertwines planning, temporal grounding, and scalable perception into a coherent reasoning process. Rather than reasoning over a static context, VideoExplorer iteratively formulates sub-questions, locates relevant moments, and performs task-oriented, temporally scalable video understanding until reaching the final answer, enabling faithful, efficient, and interpretable reasoning. To address the lack of LVU training resources, we construct a long-video reasoning dataset using difficulty-adaptive sampling to ensure high-quality trajectories on complex tasks. Building on this dataset, we design a two-stage training pipeline: supervised trajectory initialization followed by trajectory-level preference optimization, encouraging adaptive temporal grounding and iterative information integration guided by downstream rewards. Extensive evaluations on popular long-video understanding and reasoning benchmarks demonstrate VideoExplorerâ€™s significant advantage over existing baselines, highlighting its robustness, adaptability, and efficiency. Our code is made publicly available in this repository(<a target="_blank" rel="noopener" href="https://github.com/yhy-2000/VideoDeepResearch">https://github.com/yhy-2000/VideoDeepResearch</a>). </p>
<blockquote>
<p>é•¿è§†é¢‘ç†è§£ï¼ˆLVUï¼‰æ˜¯è®¡ç®—æœºè§†è§‰é¢†åŸŸçš„ä¸€ä¸ªå…·æœ‰æŒ‘æˆ˜æ€§çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•è¦ä¹ˆä¸ºäº†å•æ¬¡æ¨ç†è€Œé™ä½å¸§åˆ†è¾¨ç‡ï¼Œç‰ºç‰²äº†ç²¾ç»†ç»†èŠ‚ï¼Œè¦ä¹ˆä¾èµ–äºä»»åŠ¡æ— å…³è¡¨ç¤ºä¸Šçš„æ–‡æœ¬æ¨ç†ï¼Œé˜»ç¢äº†ç‰¹å®šä»»åŠ¡çš„æ„ŸçŸ¥å’Œæ¢ç´¢ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†VideoExploreræ¡†æ¶ï¼Œè¯¥æ¡†æ¶åŸºäºâ€œç”¨è§†é¢‘æ€è€ƒâ€çš„åŸåˆ™ï¼Œå°†è§„åˆ’ã€æ—¶é—´å®šä½å’Œå¯æ‰©å±•æ„ŸçŸ¥è‡ªç„¶åœ°äº¤ç»‡æˆä¸€ä¸ªè¿è´¯çš„æ¨ç†è¿‡ç¨‹ã€‚VideoExplorerä¸æ˜¯å¯¹é™æ€ä¸Šä¸‹æ–‡è¿›è¡Œæ¨ç†ï¼Œè€Œæ˜¯è¿­ä»£åœ°åˆ¶å®šå­é—®é¢˜ã€å®šä½ç›¸å…³æ—¶åˆ»ï¼Œå¹¶è¿›è¡Œé¢å‘ä»»åŠ¡çš„ã€æ—¶é—´å¯æ‰©å±•çš„è§†é¢‘ç†è§£ï¼Œç›´åˆ°è¾¾åˆ°æœ€ç»ˆç­”æ¡ˆï¼Œä»è€Œå®ç°å¿ å®ã€é«˜æ•ˆå’Œå¯è§£é‡Šçš„æ¨ç†ã€‚ä¸ºäº†è§£å†³LVUè®­ç»ƒèµ„æºä¸è¶³çš„é—®é¢˜ï¼Œæˆ‘ä»¬ä½¿ç”¨éš¾åº¦è‡ªé€‚åº”é‡‡æ ·æ„å»ºäº†ä¸€ä¸ªé•¿è§†é¢‘æ¨ç†æ•°æ®é›†ï¼Œä»¥ç¡®ä¿åœ¨å¤æ‚ä»»åŠ¡ä¸Šçš„é«˜è´¨é‡è½¨è¿¹ã€‚åŸºäºè¿™ä¸ªæ•°æ®é›†ï¼Œæˆ‘ä»¬è®¾è®¡äº†ä¸€ä¸ªä¸¤é˜¶æ®µçš„è®­ç»ƒç®¡é“ï¼šç›‘ç£è½¨è¿¹åˆå§‹åŒ–ï¼Œç„¶åæ˜¯è½¨è¿¹çº§åˆ«çš„åå¥½ä¼˜åŒ–ï¼Œé¼“åŠ±è‡ªé€‚åº”æ—¶é—´å®šä½ä»¥åŠç”±ä¸‹æ¸¸å¥–åŠ±å¼•å¯¼çš„è¿­ä»£ä¿¡æ¯æ•´åˆã€‚åœ¨æµè¡Œçš„é•¿è§†é¢‘ç†è§£å’Œæ¨ç†åŸºå‡†æµ‹è¯•ä¸Šçš„å¹¿æ³›è¯„ä¼°è¡¨æ˜ï¼ŒVideoExplorerç›¸å¯¹äºç°æœ‰åŸºçº¿å…·æœ‰æ˜¾è‘—ä¼˜åŠ¿ï¼Œçªæ˜¾äº†å…¶ç¨³å¥æ€§ã€é€‚åº”æ€§å’Œæ•ˆç‡ã€‚æˆ‘ä»¬çš„ä»£ç å·²å…¬å¼€å‘å¸ƒåœ¨æ­¤ä»“åº“ä¸­ï¼š<a target="_blank" rel="noopener" href="https://github.com/yhy-2000/VideoDeepResearch">https://github.com/yhy-2000/VideoDeepResearch</a>ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.10821v6">PDF</a> </p>
<p><strong>æ€»ç»“</strong><br>    è§†é¢‘æ·±åº¦ç ”ç©¶æå‡ºä¸€ç§æ–°çš„é•¿è§†é¢‘ç†è§£æ¡†æ¶VideoExplorerï¼Œèåˆäº†è§„åˆ’ã€æ—¶é—´å®šä½å’Œå¯ä¼¸ç¼©æ„ŸçŸ¥è¿›è¡ŒååŒæ¨ç†ã€‚å®ƒé‡‡ç”¨è¿­ä»£å­é—®é¢˜å½¢å¼åŒ–ã€ç›¸å…³æ—¶åˆ»å®šä½å’Œä»»åŠ¡å¯¼å‘çš„ã€å¯ä¼¸ç¼©çš„è§†é¢‘ç†è§£ï¼Œè¾¾åˆ°æœ€ç»ˆç­”æ¡ˆã€‚ä¸ºè§£å†³é•¿è§†é¢‘ç†è§£èµ„æºç¼ºä¹çš„é—®é¢˜ï¼Œæ„å»ºäº†ä¸€ä¸ªé•¿è§†é¢‘æ¨ç†æ•°æ®é›†ï¼Œå¹¶é‡‡ç”¨ä¸¤é˜¶æ®µè®­ç»ƒç®¡é“ï¼ŒåŒ…æ‹¬ç›‘ç£è½¨è¿¹åˆå§‹åŒ–å’Œè½¨è¿¹çº§åˆ«åå¥½ä¼˜åŒ–ã€‚VideoExploreråœ¨æµè¡Œçš„é•¿è§†é¢‘ç†è§£å’Œæ¨ç†åŸºå‡†æµ‹è¯•ä¸­è¡¨ç°å‡ºæ˜¾è‘—ä¼˜åŠ¿ã€‚</p>
<p><strong>è¦ç‚¹</strong></p>
<ol>
<li>é•¿è§†é¢‘ç†è§£ï¼ˆLVUï¼‰æ˜¯è®¡ç®—æœºè§†è§‰ä¸­çš„éš¾é¢˜ã€‚</li>
<li>ç°æœ‰æ–¹æ³•é€šè¿‡é™å¸§è¿›è¡Œå•æ¬¡æ¨ç†æˆ–ä¾èµ–æ–‡æœ¬æ¨ç†ï¼Œç‰ºç‰²äº†ç²¾ç»†ç²’åº¦çš„ç»†èŠ‚æˆ–é˜»ç¢äº†ç‰¹å®šä»»åŠ¡çš„æ„ŸçŸ¥å’Œæ¢ç´¢ã€‚</li>
<li>VideoExploreræ¡†æ¶åŸºäºâ€œç”¨è§†é¢‘æ€è€ƒâ€çš„åŸåˆ™ï¼Œå°†è§„åˆ’ã€æ—¶é—´å®šä½å’Œå¯ä¼¸ç¼©æ„ŸçŸ¥è‡ªç„¶èå…¥ååŒæ¨ç†è¿‡ç¨‹ã€‚</li>
<li>VideoExploreré€šè¿‡è¿­ä»£å­é—®é¢˜å½¢å¼åŒ–ã€ç›¸å…³æ—¶åˆ»å®šä½å’Œä»»åŠ¡å¯¼å‘çš„å¯ä¼¸ç¼©è§†é¢‘ç†è§£ï¼Œå®ç°å¿ å®ã€é«˜æ•ˆå’Œå¯è§£é‡Šæ€§çš„æ¨ç†ã€‚</li>
<li>ä¸ºè§£å†³LVUè®­ç»ƒèµ„æºç¼ºä¹çš„é—®é¢˜ï¼Œæ„å»ºäº†ä¸€ä¸ªé•¿è§†é¢‘æ¨ç†æ•°æ®é›†ï¼Œé‡‡ç”¨éš¾åº¦è‡ªé€‚åº”é‡‡æ ·ç¡®ä¿å¤æ‚ä»»åŠ¡çš„é«˜è´¨é‡è½¨è¿¹ã€‚</li>
<li>é‡‡ç”¨ä¸¤é˜¶æ®µè®­ç»ƒç®¡é“ï¼ŒåŒ…æ‹¬ç›‘ç£è½¨è¿¹åˆå§‹åŒ–å’Œè½¨è¿¹çº§åˆ«åå¥½ä¼˜åŒ–ï¼Œé¼“åŠ±è‡ªé€‚åº”æ—¶é—´å®šä½å’Œè¿­ä»£ä¿¡æ¯æ•´åˆï¼Œç”±ä¸‹æ¸¸å¥–åŠ±å¼•å¯¼ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.10821">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-b31468bd5159a731ce376126022c81d6" align="middle">
<img src="https://picx.zhimg.com/v2-b41e55244a19e89f085020aef2fe1e7d" align="middle">
<img src="https://picx.zhimg.com/v2-a1354efd99dd20d14ec19fa2317db009" align="middle">
<img src="https://picx.zhimg.com/v2-8254d77d416f5d1febadae624aad3065" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1><h2 id="CoP-Agentic-Red-teaming-for-Large-Language-Models-using-Composition-of-Principles"><a href="#CoP-Agentic-Red-teaming-for-Large-Language-Models-using-Composition-of-Principles" class="headerlink" title="CoP: Agentic Red-teaming for Large Language Models using Composition of   Principles"></a>CoP: Agentic Red-teaming for Large Language Models using Composition of   Principles</h2><p><strong>Authors:Chen Xiong, Pin-Yu Chen, Tsung-Yi Ho</strong></p>
<p>Recent advances in Large Language Models (LLMs) have spurred transformative applications in various domains, ranging from open-source to proprietary LLMs. However, jailbreak attacks, which aim to break safety alignment and user compliance by tricking the target LLMs into answering harmful and risky responses, are becoming an urgent concern. The practice of red-teaming for LLMs is to proactively explore potential risks and error-prone instances before the release of frontier AI technology. This paper proposes an agentic workflow to automate and scale the red-teaming process of LLMs through the Composition-of-Principles (CoP) framework, where human users provide a set of red-teaming principles as instructions to an AI agent to automatically orchestrate effective red-teaming strategies and generate jailbreak prompts. Distinct from existing red-teaming methods, our CoP framework provides a unified and extensible framework to encompass and orchestrate human-provided red-teaming principles to enable the automated discovery of new red-teaming strategies. When tested against leading LLMs, CoP reveals unprecedented safety risks by finding novel jailbreak prompts and improving the best-known single-turn attack success rate by up to 19.0 times. </p>
<blockquote>
<p>æœ€è¿‘å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„è¿›æ­¥å·²ç»åœ¨å„ä¸ªé¢†åŸŸä¸­å‚¬ç”Ÿäº†å˜é©æ€§çš„åº”ç”¨ï¼Œä»å¼€æºåˆ°ä¸“æœ‰LLMã€‚ç„¶è€Œï¼Œè¶Šç‹±æ”»å‡»æ—¨åœ¨é€šè¿‡æ¬ºéª—ç›®æ ‡LLMå›ç­”æœ‰å®³å’Œå±é™©å›åº”æ¥ç ´åå®‰å…¨å¯¹é½å’Œç”¨æˆ·åˆè§„æ€§ï¼Œè¿™å·²æˆä¸ºä¸€é¡¹ç´§è¿«çš„å…³åˆ‡ã€‚LLMçš„çº¢é˜Ÿå®è·µæ˜¯åœ¨å‰æ²¿AIæŠ€æœ¯å‘å¸ƒä¹‹å‰ç§¯ææ¢ç´¢æ½œåœ¨é£é™©å’Œæ˜“å‡ºé”™æƒ…å†µã€‚æœ¬æ–‡æå‡ºäº†ä¸€ä¸ªåŸºäºåŸåˆ™ç»„æˆï¼ˆCoPï¼‰æ¡†æ¶çš„ä»£ç†å·¥ä½œæµç¨‹ï¼Œä»¥è‡ªåŠ¨åŒ–å’Œæ‰©å±•LLMçš„çº¢é˜Ÿæµç¨‹ã€‚åœ¨è¯¥æµç¨‹ä¸­ï¼Œäººç±»ç”¨æˆ·æä¾›ä¸€ç»„çº¢é˜ŸåŸåˆ™ä½œä¸ºAIä»£ç†çš„æŒ‡ä»¤ï¼Œä»¥è‡ªåŠ¨åè°ƒæœ‰æ•ˆçš„çº¢é˜Ÿç­–ç•¥å¹¶ç”Ÿæˆè¶Šç‹±æç¤ºã€‚ä¸ç°æœ‰çš„çº¢é˜Ÿæ–¹æ³•ä¸åŒï¼Œæˆ‘ä»¬çš„CoPæ¡†æ¶æä¾›äº†ä¸€ä¸ªç»Ÿä¸€å’Œå¯æ‰©å±•çš„æ¡†æ¶ï¼Œå¯ä»¥åŒ…å«å’Œåè°ƒäººç±»æä¾›çš„çº¢é˜ŸåŸåˆ™ï¼Œä»¥å®ç°è‡ªåŠ¨å‘ç°æ–°çš„çº¢é˜Ÿç­–ç•¥ã€‚åœ¨ä¸é¢†å…ˆçš„LLMè¿›è¡Œæµ‹è¯•æ—¶ï¼ŒCoPé€šè¿‡å‘ç°æ–°çš„è¶Šç‹±æç¤ºå¹¶æé«˜äº†å·²çŸ¥å•è½®æ”»å‡»çš„æˆåŠŸç‡æœ€å¤šè¾¾19.0å€ï¼Œæ­ç¤ºäº†å‰æ‰€æœªæœ‰çš„å®‰å…¨é£é™©ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.00781v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„è¿‘æœŸè¿›å±•ä¸ºå„é¢†åŸŸå¸¦æ¥äº†å˜é©æ€§çš„åº”ç”¨ï¼Œä½†LLMé¢ä¸´çš„å®‰å…¨é—®é¢˜ä¹Ÿéšä¹‹çªæ˜¾ï¼Œå°¤å…¶æ˜¯jailbreakæ”»å‡»ï¼Œå³æ„å›¾é€šè¿‡æ¬ºéª—LLMäº§ç”Ÿæœ‰å®³å’Œå±é™©å›åº”æ¥ç ´åå…¶å®‰å…¨å¯¹é½å’Œç”¨æˆ·åˆè§„æ€§ã€‚é’ˆå¯¹å‰æ²¿AIæŠ€æœ¯çš„é‡Šæ”¾å‰é£é™©æ¢ç´¢ï¼Œçº¢é˜Ÿå®è·µæ˜¯ä¸€ç§æœ‰æ•ˆæ–¹æ³•ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ä¸ªåŸºäºåŸåˆ™ç»„åˆï¼ˆCoPï¼‰æ¡†æ¶çš„ä»£ç†å·¥ä½œæµç¨‹ï¼Œé€šè¿‡äººç±»ç”¨æˆ·æä¾›ä¸€å¥—çº¢é˜ŸåŸåˆ™ä½œä¸ºæŒ‡ä»¤æ¥è‡ªåŠ¨åè°ƒæœ‰æ•ˆçš„çº¢é˜Ÿç­–ç•¥å¹¶ç”Ÿæˆjailbreakæç¤ºã€‚ä¸åŒäºç°æœ‰çš„çº¢é˜Ÿæ–¹æ³•ï¼Œæˆ‘ä»¬çš„CoPæ¡†æ¶æä¾›äº†ä¸€ä¸ªç»Ÿä¸€å’Œå¯æ‰©å±•çš„æ¡†æ¶ï¼Œèƒ½å¤ŸåŒ…å«å’Œåè°ƒäººç±»æä¾›çš„çº¢é˜ŸåŸåˆ™ï¼Œä»¥å®ç°è‡ªåŠ¨åŒ–å‘ç°æ–°çš„çº¢é˜Ÿç­–ç•¥ã€‚åœ¨é’ˆå¯¹é¢†å…ˆçš„LLMè¿›è¡Œæµ‹è¯•æ—¶ï¼ŒCoPæ­ç¤ºäº†å‰æ‰€æœªæœ‰çš„å®‰å…¨é£é™©ï¼Œé€šè¿‡å‘ç°æ–°çš„jailbreakæç¤ºå¹¶æé«˜äº†å·²çŸ¥å•è½®æ”»å‡»çš„æˆåŠŸç‡ï¼Œæœ€é«˜è¾¾19å€ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å¤šä¸ªé¢†åŸŸå¸¦æ¥å˜é©æ€§åº”ç”¨ï¼Œä½†é¢ä¸´jailbreakæ”»å‡»ç­‰å®‰å…¨é—®é¢˜çš„æŒ‘æˆ˜ã€‚</li>
<li>çº¢é˜Ÿå®è·µæ˜¯æ¢ç´¢å‰æ²¿AIæŠ€æœ¯é‡Šæ”¾å‰é£é™©çš„æœ‰æ•ˆæ–¹æ³•ã€‚</li>
<li>æå‡ºäº†åŸºäºåŸåˆ™ç»„åˆï¼ˆCoPï¼‰æ¡†æ¶çš„ä»£ç†å·¥ä½œæµç¨‹ï¼Œä»¥è‡ªåŠ¨åŒ–å’Œè§„æ¨¡åŒ–LLMsçš„çº¢é˜Ÿå®è·µã€‚</li>
<li>CoPæ¡†æ¶é€šè¿‡äººç±»æä¾›çš„çº¢é˜ŸåŸåˆ™æ¥è‡ªåŠ¨åè°ƒçº¢é˜Ÿç­–ç•¥å¹¶ç”Ÿæˆjailbreakæç¤ºã€‚</li>
<li>CoPæ¡†æ¶å®ç°äº†å¯¹ç°æœ‰äººå·¥æ™ºèƒ½æŠ€æœ¯çš„è‡ªåŠ¨åŒ–æ”¹è¿›å’Œç­–ç•¥å‘ç°ã€‚</li>
<li>CoPåœ¨é’ˆå¯¹é¢†å…ˆLLMçš„æµ‹è¯•ä¸­å‘ç°æ–°çš„jailbreakæç¤ºå¹¶æ˜¾è‘—æé«˜æ”»å‡»æˆåŠŸç‡ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.00781">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-2f43dd3462e62bdce8e3ed2f3f7e8aa7" align="middle">
<img src="https://picx.zhimg.com/v2-442ce8ca753ab0b301dac94cabf32557" align="middle">
<img src="https://picx.zhimg.com/v2-7d73fcb923f6e66f637c70d8f2908435" align="middle">
</details>


<h1 id="-9"><a href="#-9" class="headerlink" title=""></a></h1><h2 id="UI-Evol-Automatic-Knowledge-Evolving-for-Computer-Use-Agents"><a href="#UI-Evol-Automatic-Knowledge-Evolving-for-Computer-Use-Agents" class="headerlink" title="UI-Evol: Automatic Knowledge Evolving for Computer Use Agents"></a>UI-Evol: Automatic Knowledge Evolving for Computer Use Agents</h2><p><strong>Authors:Ziyun Zhang, Xinyi Liu, Xiaoyi Zhang, Jun Wang, Gang Chen, Yan Lu</strong></p>
<p>External knowledge has played a crucial role in the recent development of computer use agents. We identify a critical knowledge-execution gap: retrieved knowledge often fails to translate into effective real-world task execution. Our analysis shows even 90% correct knowledge yields only 41% execution success rate. To bridge this gap, we propose UI-Evol, a plug-and-play module for autonomous GUI knowledge evolution. UI-Evol consists of two stages: a Retrace Stage that extracts faithful objective action sequences from actual agent-environment interactions, and a Critique Stage that refines existing knowledge by comparing these sequences against external references. We conduct comprehensive experiments on the OSWorld benchmark with the state-of-the-art Agent S2. Our results demonstrate that UI-Evol not only significantly boosts task performance but also addresses a previously overlooked issue of high behavioral standard deviation in computer use agents, leading to superior performance on computer use tasks and substantially improved agent reliability. </p>
<blockquote>
<p>å¤–éƒ¨çŸ¥è¯†åœ¨è®¡ç®—æœºä½¿ç”¨ä»£ç†çš„è¿‘æœŸå‘å±•ä¸­èµ·åˆ°äº†è‡³å…³é‡è¦çš„ä½œç”¨ã€‚æˆ‘ä»¬è¯†åˆ«å‡ºäº†ä¸€ä¸ªå…³é”®çš„çŸ¥è¯†æ‰§è¡Œå·®è·ï¼šæ£€ç´¢çš„çŸ¥è¯†å¾€å¾€æ— æ³•è½¬åŒ–ä¸ºæœ‰æ•ˆçš„ç°å®ä¸–ç•Œä»»åŠ¡æ‰§è¡Œã€‚æˆ‘ä»¬çš„åˆ†æè¡¨æ˜ï¼Œå³ä½¿90%çš„çŸ¥è¯†æ˜¯æ­£ç¡®çš„ï¼Œä¹Ÿåªèƒ½è¾¾åˆ°41%çš„æ‰§è¡ŒæˆåŠŸç‡ã€‚ä¸ºäº†å¼¥è¡¥è¿™ä¸€å·®è·ï¼Œæˆ‘ä»¬æå‡ºäº†UI-Evolï¼Œè¿™æ˜¯ä¸€ä¸ªç”¨äºè‡ªä¸»GUIçŸ¥è¯†è¿›åŒ–çš„å³æ’å³ç”¨æ¨¡å—ã€‚UI-Evolç”±ä¸¤ä¸ªé˜¶æ®µç»„æˆï¼šä¸€ä¸ªè¿½æº¯é˜¶æ®µï¼Œä»å®é™…çš„ä»£ç†ç¯å¢ƒäº¤äº’ä¸­æå–å¿ å®çš„å®¢è§‚è¡ŒåŠ¨åºåˆ—ï¼›ä¸€ä¸ªæ‰¹åˆ¤é˜¶æ®µï¼Œé€šè¿‡å°†è¿™äº›åºåˆ—ä¸å¤–éƒ¨å‚è€ƒè¿›è¡Œæ¯”è¾ƒæ¥å®Œå–„ç°æœ‰çŸ¥è¯†ã€‚æˆ‘ä»¬åœ¨OSWorldåŸºå‡†æµ‹è¯•ä¸Šè¿›è¡Œäº†å…¨é¢çš„å®éªŒï¼Œä½¿ç”¨æœ€å…ˆè¿›çš„ä»£ç†S2ã€‚ç»“æœè¡¨æ˜ï¼ŒUI-Evolä¸ä»…æ˜¾è‘—æé«˜äº†ä»»åŠ¡æ€§èƒ½ï¼Œè€Œä¸”è§£å†³äº†ä¹‹å‰è¢«å¿½è§†çš„è®¡ç®—æœºä½¿ç”¨ä»£ç†ä¸­è¡Œä¸ºæ ‡å‡†å·®é«˜çš„é—®é¢˜ï¼Œä»è€Œæé«˜äº†è®¡ç®—æœºä½¿ç”¨ä»»åŠ¡çš„æ€§èƒ½å’Œä»£ç†çš„å¯é æ€§ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.21964v2">PDF</a> Accepted to ICML 2025 Workshop on Computer Use Agents</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡å¼ºè°ƒäº†å¤–éƒ¨çŸ¥è¯†åœ¨è®¡ç®—æœºä½¿ç”¨ä»£ç†å‘å±•ä¸­çš„é‡è¦æ€§ï¼Œå¹¶æŒ‡å‡ºäº†çŸ¥è¯†æ‰§è¡Œä¹‹é—´çš„å…³é”®å·®è·ã€‚å³ä½¿å‡†ç¡®çš„çŸ¥è¯†è¾¾åˆ°90%ï¼Œå…¶æ‰§è¡ŒæˆåŠŸç‡ä¹Ÿåªæœ‰41%ã€‚ä¸ºå¼¥è¡¥è¿™ä¸€å·®è·ï¼Œæœ¬æ–‡æå‡ºäº†UI-Evolï¼Œè¿™æ˜¯ä¸€ç§ç”¨äºè‡ªä¸»GUIçŸ¥è¯†è¿›åŒ–çš„å³æ’å³ç”¨æ¨¡å—ã€‚è¯¥æ¨¡å—åŒ…æ‹¬ä¸¤ä¸ªé˜¶æ®µï¼šRetraceé˜¶æ®µä»å®é™…çš„ä»£ç†ç¯å¢ƒäº¤äº’ä¸­æå–å¿ å®çš„å®¢è§‚è¡ŒåŠ¨åºåˆ—ï¼Œè€ŒCritiqueé˜¶æ®µåˆ™é€šè¿‡æ¯”è¾ƒè¿™äº›åºåˆ—ä¸å¤–éƒ¨å‚è€ƒæ¥å®Œå–„ç°æœ‰çŸ¥è¯†ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒUI-Evolä¸ä»…æ˜¾è‘—æé«˜ä»»åŠ¡æ€§èƒ½ï¼Œè€Œä¸”è§£å†³äº†è®¡ç®—æœºä½¿ç”¨ä»£ç†ä¸­å…ˆå‰è¢«å¿½è§†çš„é«˜çš„è¡Œä¸ºæ ‡å‡†åå·®é—®é¢˜ï¼Œä»è€Œåœ¨è®¡ç®—æœºä½¿ç”¨ä»»åŠ¡ä¸Šå®ç°å“è¶Šæ€§èƒ½å¹¶å¤§å¹…æé«˜ä»£ç†å¯é æ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤–éƒ¨çŸ¥è¯†åœ¨è®¡ç®—æœºä½¿ç”¨ä»£ç†çš„å‘å±•ä¸­æ‰®æ¼”äº†é‡è¦è§’è‰²ã€‚</li>
<li>å­˜åœ¨ä¸€ä¸ªçŸ¥è¯†æ‰§è¡Œå·®è·ï¼Œå³è·å–çš„çŸ¥è¯†å¾€å¾€æ— æ³•æœ‰æ•ˆåœ°è½¬åŒ–ä¸ºå®é™…ä»»åŠ¡æ‰§è¡Œã€‚</li>
<li>å³ä½¿çŸ¥è¯†çš„å‡†ç¡®æ€§é«˜è¾¾90%ï¼Œå…¶æ‰§è¡ŒæˆåŠŸç‡ä¹Ÿåªæœ‰41%ã€‚</li>
<li>ä¸ºè§£å†³è¿™ä¸€å·®è·ï¼Œæå‡ºäº†UI-Evolæ¨¡å—ï¼ŒåŒ…æ‹¬Retraceå’ŒCritiqueä¸¤ä¸ªé˜¶æ®µã€‚</li>
<li>Retraceé˜¶æ®µä»ä»£ç†ç¯å¢ƒäº¤äº’ä¸­æå–å¿ å®å®¢è§‚çš„è¡ŒåŠ¨åºåˆ—ã€‚</li>
<li>Critiqueé˜¶æ®µé€šè¿‡æ¯”è¾ƒè¡ŒåŠ¨åºåˆ—ä¸å¤–éƒ¨å‚è€ƒæ¥å®Œå–„ç°æœ‰çŸ¥è¯†ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.21964">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-64307c58215d78d70717298114d1761a" align="middle">
<img src="https://picx.zhimg.com/v2-6753fb00c7d3f5862fa7f69b88ec4616" align="middle">
<img src="https://picx.zhimg.com/v2-a4f7a9f7950de9c817c25aaa3723abad" align="middle">
<img src="https://picx.zhimg.com/v2-81315d35ad5f88cfc93e4cffada260ff" align="middle">
<img src="https://picx.zhimg.com/v2-115bba515460eb7a00bbd9f0864c269b" align="middle">
</details>


<h1 id="-10"><a href="#-10" class="headerlink" title=""></a></h1><h2 id="Deep-Video-Discovery-Agentic-Search-with-Tool-Use-for-Long-form-Video-Understanding"><a href="#Deep-Video-Discovery-Agentic-Search-with-Tool-Use-for-Long-form-Video-Understanding" class="headerlink" title="Deep Video Discovery: Agentic Search with Tool Use for Long-form Video   Understanding"></a>Deep Video Discovery: Agentic Search with Tool Use for Long-form Video   Understanding</h2><p><strong>Authors:Xiaoyi Zhang, Zhaoyang Jia, Zongyu Guo, Jiahao Li, Bin Li, Houqiang Li, Yan Lu</strong></p>
<p>Long-form video understanding presents significant challenges due to extensive temporal-spatial complexity and the difficulty of question answering under such extended contexts. While Large Language Models (LLMs) have demonstrated considerable advancements in video analysis capabilities and long context handling, they continue to exhibit limitations when processing information-dense hour-long videos. To overcome such limitations, we propose the Deep Video Discovery (DVD) agent to leverage an agentic search strategy over segmented video clips. Unlike previous video agents that rely on predefined workflows applied uniformly across different queries, our approach emphasizes the autonomous and adaptive nature of agents. By providing a set of search-centric tools on multi-granular video database, our DVD agent leverages the advanced reasoning capability of LLM to plan on its current observation state, strategically selects tools to orchestrate adaptive workflow for different queries in light of the gathered information. We perform comprehensive evaluation on multiple long video understanding benchmarks that demonstrates our advantage. Our DVD agent achieves state-of-the-art performance on the challenging LVBench dataset, reaching an accuracy of 74.2%, which substantially surpasses all prior works, and further improves to 76.0% with transcripts. The code has been released at <a target="_blank" rel="noopener" href="https://github.com/microsoft/DeepVideoDiscovery">https://github.com/microsoft/DeepVideoDiscovery</a>. </p>
<blockquote>
<p>é•¿è§†é¢‘ç†è§£é¢ä¸´ç€å·¨å¤§çš„æŒ‘æˆ˜ï¼Œç”±äºå·¨å¤§çš„æ—¶ç©ºå¤æ‚æ€§å’Œåœ¨è¿™ç§æ‰©å±•ç¯å¢ƒä¸‹è¿›è¡Œé—®ç­”çš„éš¾åº¦ã€‚è™½ç„¶å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨è§†é¢‘åˆ†æèƒ½åŠ›å’Œé•¿æ–‡æœ¬å¤„ç†èƒ½åŠ›æ–¹é¢å–å¾—äº†æ˜¾è‘—çš„è¿›æ­¥ï¼Œä½†åœ¨å¤„ç†ä¿¡æ¯å¯†é›†çš„å°æ—¶é•¿çš„è§†é¢‘æ—¶ï¼Œå®ƒä»¬ä»ç„¶è¡¨ç°å‡ºå±€é™æ€§ã€‚ä¸ºäº†å…‹æœè¿™äº›å±€é™æ€§ï¼Œæˆ‘ä»¬æå‡ºäº†æ·±åº¦è§†é¢‘å‘ç°ï¼ˆDVDï¼‰ä»£ç†ï¼Œé‡‡ç”¨ä»£ç†æœç´¢ç­–ç•¥å¯¹åˆ†å‰²çš„è§†é¢‘ç‰‡æ®µè¿›è¡Œå¤„ç†ã€‚ä¸åŒäºä»¥å‰ä¾èµ–äºä¸ºä¸åŒæŸ¥è¯¢ç»Ÿä¸€åº”ç”¨é¢„å®šä¹‰å·¥ä½œæµç¨‹çš„è§†é¢‘ä»£ç†ï¼Œæˆ‘ä»¬çš„æ–¹æ³•å¼ºè°ƒä»£ç†çš„è‡ªä¸»æ€§å’Œé€‚åº”æ€§ã€‚é€šè¿‡åœ¨å¤šç²’åº¦è§†é¢‘æ•°æ®åº“ä¸Šæä¾›ä¸€ç³»åˆ—ä»¥æœç´¢ä¸ºä¸­å¿ƒçš„å·¥å…·ï¼Œæˆ‘ä»¬çš„DVDä»£ç†åˆ©ç”¨LLMçš„é«˜çº§æ¨ç†èƒ½åŠ›æ¥è§„åˆ’å…¶å½“å‰è§‚å¯ŸçŠ¶æ€ï¼Œæ ¹æ®æ”¶é›†çš„ä¿¡æ¯æˆ˜ç•¥æ€§åœ°é€‰æ‹©å·¥å…·æ¥åè°ƒé€‚åº”ä¸åŒæŸ¥è¯¢çš„å·¥ä½œæµç¨‹ã€‚æˆ‘ä»¬åœ¨å¤šä¸ªé•¿è§†é¢‘ç†è§£åŸºå‡†æµ‹è¯•ä¸Šè¿›è¡Œäº†å…¨é¢è¯„ä¼°ï¼Œè¯æ˜äº†æˆ‘ä»¬çš„ä¼˜åŠ¿ã€‚æˆ‘ä»¬çš„DVDä»£ç†åœ¨å…·æœ‰æŒ‘æˆ˜æ€§çš„LVBenchæ•°æ®é›†ä¸Šè¾¾åˆ°äº†74.2%çš„å‡†ç¡®ç‡ï¼Œè¿™å¤§å¤§è¶…è¿‡äº†ä»¥å‰çš„æ‰€æœ‰ä½œå“ï¼Œå¹¶ä¸”åœ¨ä½¿ç”¨å­—å¹•çš„æƒ…å†µä¸‹è¿›ä¸€æ­¥æé«˜åˆ°äº†76.0%ã€‚ä»£ç å·²å‘å¸ƒåœ¨<a target="_blank" rel="noopener" href="https://github.com/microsoft/DeepVideoDiscovery%E3%80%82">https://github.com/microsoft/DeepVideoDiscoveryã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.18079v4">PDF</a> Accepted to NeurIPS 2025</p>
<p><strong>Summary</strong></p>
<p>è¯¥æ–‡æœ¬ä¸»è¦ä»‹ç»äº†å¤„ç†é•¿è§†é¢‘ç†è§£æ—¶çš„æŒ‘æˆ˜ä»¥åŠæå‡ºçš„è§£å†³æ–¹æ¡ˆã€‚é€šè¿‡ä½¿ç”¨æ·±åº¦è§†é¢‘å‘ç°ï¼ˆDVDï¼‰ä»£ç†ï¼Œå®ç°äº†åŸºäºå¤šç²’åº¦è§†é¢‘æ•°æ®åº“çš„æœç´¢ä¸­å¿ƒå·¥å…·é›†ï¼Œèƒ½å¤Ÿæ ¹æ®å½“å‰è§‚å¯ŸçŠ¶æ€è¿›è¡Œè§„åˆ’ï¼Œçµæ´»é€‰æ‹©å·¥å…·ä»¥é€‚åº”ä¸åŒçš„æŸ¥è¯¢éœ€æ±‚ã€‚åœ¨å¤šä¸ªé•¿è§†é¢‘ç†è§£åŸºå‡†æµ‹è¯•ä¸Šçš„è¯„ä¼°æ˜¾ç¤ºï¼ŒDVDä»£ç†å…·æœ‰ä¼˜åŠ¿ï¼Œç‰¹åˆ«æ˜¯åœ¨å…·æœ‰æŒ‘æˆ˜æ€§çš„LVBenchæ•°æ®é›†ä¸Šå®ç°äº†74.2%çš„å‡†ç¡®ç‡ï¼Œè¶…è¶Šäº†æ‰€æœ‰å…ˆå‰çš„å·¥ä½œï¼Œå¹¶ä¸”åœ¨ä½¿ç”¨è½¬å½•çš„æƒ…å†µä¸‹è¿›ä¸€æ­¥æé«˜åˆ°äº†76.0%ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>é•¿è§†é¢‘ç†è§£é¢ä¸´å·¨å¤§çš„æ—¶ç©ºå¤æ‚æ€§å’Œé—®ç­”æŒ‘æˆ˜ã€‚</li>
<li>å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å¤„ç†ä¿¡æ¯å¯†é›†å‹é•¿è§†é¢‘æ—¶å­˜åœ¨å±€é™æ€§ã€‚</li>
<li>æå‡ºçš„Deep Video Discoveryï¼ˆDVDï¼‰ä»£ç†é‡‡ç”¨åŸºäºå¤šç²’åº¦è§†é¢‘æ•°æ®åº“çš„æœç´¢ä¸­å¿ƒç­–ç•¥ã€‚</li>
<li>DVDä»£ç†å¼ºè°ƒä»£ç†çš„è‡ªä¸»æ€§å’Œé€‚åº”æ€§ã€‚</li>
<li>DVDä»£ç†èƒ½å¤Ÿæ ¹æ®å½“å‰è§‚å¯ŸçŠ¶æ€è¿›è¡Œè§„åˆ’ï¼Œçµæ´»é€‰æ‹©å·¥å…·ä»¥é€‚åº”ä¸åŒçš„æŸ¥è¯¢éœ€æ±‚ã€‚</li>
<li>åœ¨å¤šä¸ªé•¿è§†é¢‘ç†è§£åŸºå‡†æµ‹è¯•ä¸Šï¼ŒDVDä»£ç†è¡¨ç°å‡ºä¼˜åŠ¿ï¼Œç‰¹åˆ«æ˜¯åœ¨LVBenchæ•°æ®é›†ä¸Šå®ç°äº†è¾ƒé«˜çš„å‡†ç¡®ç‡ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.18079">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-796f68dbba55594e233ef07afa279018" align="middle">
<img src="https://picx.zhimg.com/v2-953a2e0735dc1523c356980ffc004edb" align="middle">
<img src="https://picx.zhimg.com/v2-c0e8498103aa5bc89e894bf7d2bb4679" align="middle">
<img src="https://picx.zhimg.com/v2-3dad245277e45299ac6e5439e602471c" align="middle">
</details>


<h1 id="-11"><a href="#-11" class="headerlink" title=""></a></h1><h2 id="HEXGEN-FLOW-Optimizing-LLM-Inference-Request-Scheduling-for-Agentic-Text-to-SQL"><a href="#HEXGEN-FLOW-Optimizing-LLM-Inference-Request-Scheduling-for-Agentic-Text-to-SQL" class="headerlink" title="HEXGEN-FLOW: Optimizing LLM Inference Request Scheduling for Agentic   Text-to-SQL"></a>HEXGEN-FLOW: Optimizing LLM Inference Request Scheduling for Agentic   Text-to-SQL</h2><p><strong>Authors:You Peng, Youhe Jiang, Wenqi Jiang, Chen Wang, Binhang Yuan</strong></p>
<p>Recent advancements in leveraging the agentic paradigm of large language models (LLMs) have substantially improved Text-to-SQL capabilities, empowering users without specialized database knowledge to intuitively query databases. However, deploying agentic LLM-based Text-to-SQL systems in production presents significant challenges, stemming from their inherently multi-stage computational dependencies, strict latency requirements, and the complexity of deployment across heterogeneous GPUs widely existing in enterprise clusters. Meanwhile, existing LLM serving frameworks are primarily designed for independent inference tasks, resulting in suboptimal performance and frequent service-level objective (SLO) violations in Text-to-SQL workloads. In this paper, we introduce HEXGEN-FLOW, a novel framework designed explicitly to schedule and execute agentic multi-stage LLM-based Text-to-SQL workflows on heterogeneous GPU clusters serving multi-tenant Text-to-SQL requests. HEXGEN-FLOW introduces a hierarchical scheduling approach that combines global workload-balanced task dispatching with an adaptive local priority queue, guided by a systematic analysis of agentic Text-to-SQL workflows. Additionally, we propose a lightweight simulation-based method for tuning critical scheduling hyperparameters, further enhancing robustness and adaptability. Our evaluation on realistic Text-to-SQL benchmarks demonstrates that HEXGEN-FLOW significantly outperforms state-of-the-art LLM serving frameworks. Across all traces, HEXGEN-FLOW reduces P95 tail latency by $1.42{\sim}1.56\times$ and increases throughput by $1.49{\sim}1.81\times$, demonstrating robust improvements under diverse workloads. Our code is available at <a target="_blank" rel="noopener" href="https://github.com/Relaxed-System-Lab/Hexgen-Flow">https://github.com/Relaxed-System-Lab/Hexgen-Flow</a>. </p>
<blockquote>
<p>æœ€è¿‘ï¼Œåˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„ä»£ç†èŒƒå¼åœ¨Text-to-SQLèƒ½åŠ›æ–¹é¢å–å¾—äº†å®è´¨æ€§è¿›æ­¥ï¼Œä½¿å¾—æ²¡æœ‰ä¸“ä¸šæ•°æ®åº“çŸ¥è¯†çš„ç”¨æˆ·èƒ½å¤Ÿç›´è§‚åœ°æŸ¥è¯¢æ•°æ®åº“ã€‚ç„¶è€Œï¼Œåœ¨ç”Ÿäº§ç¯å¢ƒä¸­éƒ¨ç½²åŸºäºä»£ç†LLMçš„Text-to-SQLç³»ç»Ÿé¢ä¸´ç€é‡å¤§æŒ‘æˆ˜ï¼Œè¿™äº›æŒ‘æˆ˜æºäºå…¶å›ºæœ‰çš„å¤šé˜¶æ®µè®¡ç®—ä¾èµ–æ€§ã€ä¸¥æ ¼çš„å»¶è¿Ÿè¦æ±‚å’Œåœ¨ä¼ä¸šé›†ç¾¤ä¸­å¹¿æ³›å­˜åœ¨çš„å¼‚æ„GPUéƒ¨ç½²çš„å¤æ‚æ€§ã€‚åŒæ—¶ï¼Œç°æœ‰çš„LLMæœåŠ¡æ¡†æ¶ä¸»è¦è®¾è®¡ç”¨äºç‹¬ç«‹æ¨ç†ä»»åŠ¡ï¼Œå¯¼è‡´åœ¨Text-to-SQLå·¥ä½œè´Ÿè½½ä¸­çš„æ€§èƒ½ä¸ä½³å’Œé¢‘ç¹çš„æœåŠ¡çº§åˆ«ç›®æ ‡ï¼ˆSLOï¼‰è¿è§„ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬ä»‹ç»äº†HEXGEN-FLOWï¼Œè¿™æ˜¯ä¸€ä¸ªä¸“é—¨è®¾è®¡ç”¨äºåœ¨å¼‚æ„GPUé›†ç¾¤ä¸Šè°ƒåº¦å’Œæ‰§è¡ŒåŸºäºä»£ç†çš„å¤šé˜¶æ®µLLM Text-to-SQLå·¥ä½œæµç¨‹çš„æ–°æ¡†æ¶ï¼ŒæœåŠ¡äºå¤šç§Ÿæˆ·Text-to-SQLè¯·æ±‚ã€‚HEXGEN-FLOWå¼•å…¥äº†ä¸€ç§åˆ†å±‚è°ƒåº¦æ–¹æ³•ï¼Œç»“åˆå…¨å±€è´Ÿè½½å‡è¡¡çš„ä»»åŠ¡åˆ†é…å’Œè‡ªé€‚åº”æœ¬åœ°ä¼˜å…ˆçº§é˜Ÿåˆ—ï¼Œä»¥ç³»ç»Ÿåˆ†æä»£ç†Text-to-SQLå·¥ä½œæµç¨‹ä¸ºæŒ‡å¯¼ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜æå‡ºäº†ä¸€ç§åŸºäºè½»é‡çº§æ¨¡æ‹Ÿçš„æ–¹æ³•æ¥è°ƒæ•´å…³é”®è°ƒåº¦è¶…å‚æ•°ï¼Œè¿›ä¸€æ­¥å¢å¼ºäº†ç¨³å¥æ€§å’Œé€‚åº”æ€§ã€‚æˆ‘ä»¬åœ¨å®é™…çš„Text-to-SQLåŸºå‡†æµ‹è¯•ä¸Šçš„è¯„ä¼°è¡¨æ˜ï¼ŒHEXGEN-FLOWæ˜¾è‘—ä¼˜äºæœ€æ–°çš„LLMæœåŠ¡æ¡†æ¶ã€‚åœ¨æ‰€æœ‰ç—•è¿¹ä¸­ï¼ŒHEXGEN-FLOWå°†P95å°¾éƒ¨å»¶è¿Ÿé™ä½äº†$ 1.42{\sim} 1.56 \times $ï¼Œååé‡æé«˜äº†$ 1.49{\sim} 1.81 \times $ï¼Œåœ¨å¤šç§å·¥ä½œè´Ÿè½½ä¸‹æ˜¾ç¤ºå‡ºç¨³å¥çš„æ”¹è¿›ã€‚æˆ‘ä»¬çš„ä»£ç å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/Relaxed-System-Lab/Hexgen-Flow%E4%B8%8A%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/Relaxed-System-Lab/Hexgen-Flowä¸Šæ‰¾åˆ°ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.05286v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>è¯¥æ–‡ä»‹ç»äº†åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„agenticèŒƒå¼æå‡Text-to-SQLèƒ½åŠ›çš„æœ€æ–°è¿›å±•ï¼Œä½¿ç”¨æˆ·èƒ½å¤Ÿç›´è§‚æŸ¥è¯¢æ•°æ®åº“è€Œæ— éœ€ç‰¹å®šçŸ¥è¯†ã€‚ç„¶è€Œï¼Œåœ¨ç”Ÿäº§ç¯å¢ƒä¸­éƒ¨ç½²åŸºäºLLMçš„Text-to-SQLç³»ç»Ÿé¢ä¸´è¯¸å¤šæŒ‘æˆ˜ï¼Œå¦‚å¤šé˜¶æ®µè®¡ç®—ä¾èµ–ã€ä¸¥æ ¼å»¶è¿Ÿè¦æ±‚å’Œåœ¨ä¼ä¸šé›†ç¾¤ä¸­éƒ¨ç½²çš„å¼‚æ„GPUçš„å¤æ‚æ€§ç­‰ã€‚é’ˆå¯¹è¿™äº›é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°å‹æ¡†æ¶HEXGEN-FLOWï¼Œç”¨äºåœ¨å¼‚æ„GPUé›†ç¾¤ä¸Šè°ƒåº¦å’Œæ‰§è¡Œå¤šé˜¶æ®µLLMåŸºäºText-to-SQLçš„å·¥ä½œæµã€‚HEXGEN-FLOWç»“åˆäº†å…¨å±€è´Ÿè½½å¹³è¡¡çš„ä»»åŠ¡åˆ†é…å’Œè‡ªé€‚åº”æœ¬åœ°ä¼˜å…ˆé˜Ÿåˆ—çš„åˆ†å±‚è°ƒåº¦æ–¹æ³•ï¼Œå¹¶é€šè¿‡ç³»ç»Ÿåˆ†ææŒ‡å¯¼agentic Text-to-SQLå·¥ä½œæµã€‚æ­¤å¤–ï¼Œè¿˜æå‡ºäº†ä¸€ç§åŸºäºè½»é‡çº§æ¨¡æ‹Ÿçš„æ–¹æ³•ï¼Œç”¨äºè°ƒæ•´å…³é”®è°ƒåº¦è¶…å‚æ•°ï¼Œæé«˜äº†ç¨³å¥æ€§å’Œé€‚åº”æ€§ã€‚åœ¨ç°å®çš„Text-to-SQLåŸºå‡†æµ‹è¯•ä¸­ï¼ŒHEXGEN-FLOWæ˜¾è‘—ä¼˜äºç°æœ‰çš„LLMæœåŠ¡æ¡†æ¶ï¼Œé™ä½äº†P95å°¾éƒ¨å»¶è¿Ÿï¼Œå¹¶æé«˜äº†ååé‡ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>LLMçš„agenticèŒƒå¼åœ¨Text-to-SQLèƒ½åŠ›ä¸Šå–å¾—äº†è¿›å±•ï¼Œæ”¯æŒç”¨æˆ·ç›´è§‚æŸ¥è¯¢æ•°æ®åº“ã€‚</li>
<li>ç”Ÿäº§ç¯å¢ƒä¸­éƒ¨ç½²åŸºäºLLMçš„Text-to-SQLç³»ç»Ÿé¢ä¸´æŒ‘æˆ˜ï¼ŒåŒ…æ‹¬å¤šé˜¶æ®µè®¡ç®—ã€å»¶è¿Ÿå’Œå¼‚æ„GPUéƒ¨ç½²çš„å¤æ‚æ€§ã€‚</li>
<li>HEXGEN-FLOWæ¡†æ¶è¢«è®¾è®¡ç”¨äºåœ¨å¼‚æ„GPUé›†ç¾¤ä¸Šè°ƒåº¦å’Œæ‰§è¡Œå¤šé˜¶æ®µLLMçš„Text-to-SQLå·¥ä½œæµã€‚</li>
<li>HEXGEN-FLOWé‡‡ç”¨åˆ†å±‚è°ƒåº¦æ–¹æ³•ï¼Œç»“åˆå…¨å±€è´Ÿè½½å¹³è¡¡å’Œè‡ªé€‚åº”æœ¬åœ°ä¼˜å…ˆé˜Ÿåˆ—ã€‚</li>
<li>HEXGEN-FLOWé€šè¿‡ç³»ç»Ÿåˆ†ææŒ‡å¯¼agentic Text-to-SQLå·¥ä½œæµï¼Œå¹¶æå‡ºä¸€ç§è½»é‡çº§æ¨¡æ‹Ÿæ–¹æ³•è°ƒæ•´è°ƒåº¦è¶…å‚æ•°ã€‚</li>
<li>åœ¨Text-to-SQLåŸºå‡†æµ‹è¯•ä¸­ï¼ŒHEXGEN-FLOWæ˜¾è‘—ä¼˜äºç°æœ‰LLMæœåŠ¡æ¡†æ¶ã€‚</li>
<li>HEXGEN-FLOWé™ä½äº†P95å°¾éƒ¨å»¶è¿Ÿå¹¶æé«˜äº†ååé‡ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.05286">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-706d2bf550e99f3459e3b004a395de3d" align="middle">
<img src="https://picx.zhimg.com/v2-c7e5ed5f18bf82204ac3d133dd2f8b8a" align="middle">
<img src="https://picx.zhimg.com/v2-3359159e604162e7ca3526b9ad1a4451" align="middle">
</details>


<h1 id="-12"><a href="#-12" class="headerlink" title=""></a></h1><h2 id="MARFT-Multi-Agent-Reinforcement-Fine-Tuning"><a href="#MARFT-Multi-Agent-Reinforcement-Fine-Tuning" class="headerlink" title="MARFT: Multi-Agent Reinforcement Fine-Tuning"></a>MARFT: Multi-Agent Reinforcement Fine-Tuning</h2><p><strong>Authors:Junwei Liao, Muning Wen, Jun Wang, Weinan Zhang</strong></p>
<p>LLM-based Multi-Agent Systems have demonstrated remarkable capabilities in addressing complex, agentic tasks, from generating high-quality presentation slides to even conducting sophisticated scientific research. Meanwhile, RL has been widely recognized for its effectiveness in enhancing agent intelligence, but limited research has investigated the fine-tuning of LaMAS using foundational RL techniques. Moreover, the direct application of MARL methods to LaMAS introduces significant challenges, stemming from the unique characteristics and mechanisms inherent to LaMAS. To address these challenges, this article presents a comprehensive study of LLM-based MARL and proposes a novel paradigm termed Multi-Agent Reinforcement Fine-Tuning (MARFT). We introduce a brand-new MG called Flex-MG, which aligns with the LaMAS optimization in real-world applications and a universal algorithmic framework tailored specifically for LaMAS, outlining the conceptual foundations, key distinctions, and practical implementation strategies. We review the evolution from RL to RFT, setting the stage for a parallel analysis in the multi-agent domain. In the context of LaMAS, we elucidate critical differences between MARL and MARFT. These differences motivate a transition toward a LaMAS-oriented formulation of RFT. Central to this work is a robust and scalable MARFT framework. We detail the core algorithm and provide a complete, open-source implementation to facilitate adoption and further research. The latter sections of the paper explore real-world application perspectives and opening challenges in MARFT. By bridging theoretical underpinnings with practical methodologies, this work serves as a roadmap for researchers seeking to advance MARFT toward resilient and adaptive solutions in agentic systems. Our implementation of the proposed framework is publicly available at: <a target="_blank" rel="noopener" href="https://github.com/jwliao-ai/MARFT">https://github.com/jwliao-ai/MARFT</a>. </p>
<blockquote>
<p>åŸºäºLLMçš„å¤šæ™ºèƒ½ä½“ç³»ç»Ÿå·²åœ¨è§£å†³å¤æ‚çš„ã€å¤šæ™ºèƒ½ä½“çš„ä»»åŠ¡æ–¹é¢è¡¨ç°å‡ºäº†å“è¶Šçš„èƒ½åŠ›ï¼Œæ— è®ºæ˜¯ç”Ÿæˆé«˜è´¨é‡æ¼”ç¤ºå¹»ç¯ç‰‡è¿˜æ˜¯è¿›è¡Œé«˜çº§ç§‘å­¦ç ”ç©¶ã€‚ä¸æ­¤åŒæ—¶ï¼Œå¼ºåŒ–å­¦ä¹ åœ¨æé«˜æ™ºèƒ½ä½“æ™ºèƒ½æ–¹é¢å¾—åˆ°äº†å¹¿æ³›è®¤å¯ï¼Œä½†å…³äºä½¿ç”¨åŸºç¡€å¼ºåŒ–å­¦ä¹ æŠ€æœ¯å¯¹å¤§å‹å¤šæ™ºèƒ½ä½“ç³»ç»Ÿï¼ˆLaMASï¼‰è¿›è¡Œå¾®è°ƒçš„ç ”ç©¶ä»ç„¶æœ‰é™ã€‚æ­¤å¤–ï¼Œå°†å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ ï¼ˆMARLï¼‰æ–¹æ³•ç›´æ¥åº”ç”¨äºLaMASå¼•å…¥äº†é‡å¤§æŒ‘æˆ˜ï¼Œè¿™äº›æŒ‘æˆ˜æºäºLaMASå›ºæœ‰çš„ç‹¬ç‰¹ç‰¹å¾å’Œæœºåˆ¶ã€‚ä¸ºäº†è§£å†³è¿™äº›æŒ‘æˆ˜ï¼Œæœ¬æ–‡è¿›è¡Œäº†åŸºäºLLMçš„MARLçš„ç»¼åˆç ”ç©¶ï¼Œå¹¶æå‡ºäº†ä¸€ç§æ–°å‹èŒƒå¼â€”â€”å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ å¾®è°ƒï¼ˆMARFTï¼‰ã€‚æˆ‘ä»¬å¼•å…¥äº†ä¸€ç§å…¨æ–°çš„å›¾çµæ¸¸æˆï¼ˆFlex-MGï¼‰ï¼Œå®ƒç¬¦åˆLaMASåœ¨ç°å®ä¸–ç•Œåº”ç”¨ä¸­çš„ä¼˜åŒ–ï¼Œä»¥åŠä¸“ä¸ºLaMASå®šåˆ¶çš„é€šç”¨ç®—æ³•æ¡†æ¶ï¼Œæ¦‚è¿°äº†æ¦‚å¿µåŸºç¡€ã€å…³é”®åŒºåˆ«å’Œå®è·µå®æ–½ç­–ç•¥ã€‚æˆ‘ä»¬å›é¡¾äº†ä»å¼ºåŒ–å­¦ä¹ åˆ°å¼ºåŒ–å¾®è°ƒï¼ˆRFTï¼‰çš„æ¼”å˜ï¼Œä¸ºåœ¨å¤šæ™ºèƒ½ä½“é¢†åŸŸè¿›è¡Œå¹³è¡Œåˆ†æå¥ å®šäº†åŸºç¡€ã€‚åœ¨LaMASçš„èƒŒæ™¯ä¸‹ï¼Œæˆ‘ä»¬é˜æ˜äº†MARLå’ŒMARFTä¹‹é—´çš„å…³é”®åŒºåˆ«ã€‚è¿™äº›åŒºåˆ«ä¿ƒä½¿æˆ‘ä»¬æœç€ä»¥LaMASä¸ºå¯¼å‘çš„RFTå…¬å¼è½¬å˜ã€‚æœ¬å·¥ä½œçš„æ ¸å¿ƒæ˜¯ç¨³å¥ä¸”å¯æ‰©å±•çš„MARFTæ¡†æ¶ã€‚æˆ‘ä»¬è¯¦ç»†ä»‹ç»äº†æ ¸å¿ƒç®—æ³•ï¼Œå¹¶æä¾›äº†ä¸€ä¸ªå®Œæ•´ã€å¼€æºçš„å®ç°ï¼Œä»¥ä¿ƒè¿›é‡‡ç”¨å’Œè¿›ä¸€æ­¥ç ”ç©¶ã€‚è®ºæ–‡çš„åå‡ éƒ¨åˆ†æ¢è®¨äº†ç°å®ä¸–ç•Œçš„åº”ç”¨è§†è§’å’ŒMARFTä¸­çš„å¼€æ”¾æŒ‘æˆ˜ã€‚é€šè¿‡æ¡¥æ¥ç†è®ºåŸºçŸ³ä¸å®è·µæ–¹æ³•ï¼Œæœ¬ç ”ç©¶ä¸ºç ”ç©¶äººå‘˜æ¨è¿›MARFTæœç€æ™ºèƒ½ç³»ç»Ÿä¸­çš„å¼¹æ€§å’Œé€‚åº”æ€§è§£å†³æ–¹æ¡ˆæä¾›äº†è·¯çº¿å›¾ã€‚æˆ‘ä»¬æå‡ºçš„æ¡†æ¶å®ç°å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/jwliao-ai/MARFT">https://github.com/jwliao-ai/MARFT</a>å…¬å¼€è®¿é—®ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.16129v4">PDF</a> 42 pages</p>
<p><strong>Summary</strong></p>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä¸ºåŸºç¡€çš„å¤šæ™ºèƒ½ä½“ç³»ç»Ÿï¼ˆLaMASï¼‰åœ¨è§£å†³å¤æ‚çš„æ™ºèƒ½ä»»åŠ¡æ–¹é¢å±•ç°å‡ºå“è¶Šçš„èƒ½åŠ›ï¼Œå¦‚ç”Ÿæˆé«˜è´¨é‡æ¼”ç¤ºå¹»ç¯ç‰‡åŠå¼€å±•é«˜çº§ç§‘å­¦ç ”ç©¶ç­‰ã€‚å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰è¢«å…¬è®¤ä¸ºå¢å¼ºæ™ºèƒ½ä½“æ™ºèƒ½çš„æœ‰æ•ˆæ–¹æ³•ï¼Œä½†å…³äºä½¿ç”¨åŸºç¡€å¼ºåŒ–å­¦ä¹ æŠ€æœ¯å¯¹LaMASè¿›è¡Œç²¾ç»†è°ƒæ•´çš„ç ”ç©¶ä»ç„¶æœ‰é™ã€‚é’ˆå¯¹ç›´æ¥åº”ç”¨å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ ï¼ˆMARLï¼‰æ–¹æ³•äºLaMASæ‰€é¢ä¸´çš„æŒ‘æˆ˜ï¼Œæœ¬æ–‡è¿›è¡Œäº†å…¨é¢çš„ç ”ç©¶å¹¶æå‡ºäº†åä¸ºâ€œå¤šæ™ºèƒ½ä½“å¼ºåŒ–ç²¾ç»†è°ƒæ•´â€ï¼ˆMARFTï¼‰çš„æ–°å‹èŒƒå¼ã€‚ä»‹ç»äº†ä¸LaMASä¼˜åŒ–åœ¨ç°å®åº”ç”¨ä¸­å¯¹é½çš„Flex-MGæ–°å‹æ¨¡å‹ï¼Œä»¥åŠä¸“ä¸ºLaMaså®šåˆ¶çš„é€šç”¨ç®—æ³•æ¡†æ¶ã€‚æ–‡ç« é˜è¿°äº†ä»RLåˆ°RFTçš„æ¼”å˜è¿‡ç¨‹ï¼Œå¹¶å¯¹å¤šæ™ºèƒ½ä½“é¢†åŸŸè¿›è¡Œäº†å¹³è¡Œåˆ†æã€‚åœ¨LaMASçš„è¯­å¢ƒä¸‹ï¼Œæœ¬æ–‡é˜è¿°äº†MARLå’ŒMARFTä¹‹é—´çš„å…³é”®åŒºåˆ«ï¼Œæ¨åŠ¨äº†é¢å‘LaMasçš„RFTå¯¼å‘æ€§è¡¨è¿°çš„å‘å±•ã€‚æ–‡ç« çš„æ ¸å¿ƒåœ¨äºç¨³å¥ä¸”å¯æ‰©å±•çš„MARFTæ¡†æ¶ï¼Œè¯¦ç»†è¯´æ˜äº†æ ¸å¿ƒç®—æ³•ï¼Œå¹¶æä¾›å¼€æºå®ç°ä»¥ä¿ƒè¿›é‡‡çº³å’Œè¿›ä¸€æ­¥ç ”ç©¶ã€‚æœ¬æ–‡æ¢è®¨äº†ç°å®åº”ç”¨è§†è§’å’ŒMARFTçš„å¼€æ”¾æŒ‘æˆ˜ï¼Œä¸ºç ”ç©¶äººå‘˜æä¾›äº†é€šå¾€å…·æœ‰å¼¹æ€§å’Œé€‚åº”æ€§çš„è§£å†³æ–¹æ¡ˆçš„é“è·¯å›¾ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>LLM-based Multi-Agent Systems (LaMAS)å…·å¤‡å¤„ç†å¤æ‚ä»»åŠ¡çš„èƒ½åŠ›ï¼Œå¦‚ç”Ÿæˆæ¼”ç¤ºå¹»ç¯ç‰‡åŠç§‘å­¦ç ”ç©¶ã€‚</li>
<li>å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰å¯æœ‰æ•ˆæå‡æ™ºèƒ½ä½“æ™ºèƒ½ï¼Œä½†å…¶åœ¨LaMASä¸­çš„åº”ç”¨ç ”ç©¶å’Œç²¾ç»†è°ƒæ•´å—é™ã€‚</li>
<li>é¢ä¸´ç›´æ¥åº”ç”¨å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ ï¼ˆMARLï¼‰æ–¹æ³•äºLaMASçš„æŒ‘æˆ˜ï¼Œéœ€è€ƒè™‘LaMASçš„ç‹¬ç‰¹ç‰¹æ€§å’Œæœºåˆ¶ã€‚</li>
<li>æå‡ºäº†ä¸€ç§æ–°å‹èŒƒå¼â€”â€”Multi-Agent Reinforcement Fine-Tuning (MARFT)ä»¥åº”å¯¹è¿™äº›æŒ‘æˆ˜ã€‚</li>
<li>ä»‹ç»äº†ä¸LaMASä¼˜åŒ–å¯¹é½çš„Flex-MGæ¨¡å‹å’Œå®šåˆ¶é€šç”¨ç®—æ³•æ¡†æ¶ã€‚</li>
<li>æ–‡ç« é˜è¿°äº†ä»RLåˆ°RFTçš„æ¼”å˜ï¼Œå¼ºè°ƒäº†å¤šæ™ºèƒ½ä½“é¢†åŸŸçš„å¹³è¡Œåˆ†æã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.16129">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-82c689b68f4bb086972236b0f78f27de" align="middle">
<img src="https://picx.zhimg.com/v2-7dadbf55d3bdd89d0b200da801274800" align="middle">
</details>


<h1 id="-13"><a href="#-13" class="headerlink" title=""></a></h1><h2 id="3MDBench-Medical-Multimodal-Multi-agent-Dialogue-Benchmark"><a href="#3MDBench-Medical-Multimodal-Multi-agent-Dialogue-Benchmark" class="headerlink" title="3MDBench: Medical Multimodal Multi-agent Dialogue Benchmark"></a>3MDBench: Medical Multimodal Multi-agent Dialogue Benchmark</h2><p><strong>Authors:Ivan Sviridov, Amina Miftakhova, Artemiy Tereshchenko, Galina Zubkova, Pavel Blinov, Andrey Savchenko</strong></p>
<p>Though Large Vision-Language Models (LVLMs) are being actively explored in medicine, their ability to conduct complex real-world telemedicine consultations combining accurate diagnosis with professional dialogue remains underexplored. This paper presents 3MDBench (Medical Multimodal Multi-agent Dialogue Benchmark), an open-source framework for simulating and evaluating LVLM-driven telemedical consultations. 3MDBench simulates patient variability through temperament-based Patient Agent and evaluates diagnostic accuracy and dialogue quality via Assessor Agent. It includes 2996 cases across 34 diagnoses from real-world telemedicine interactions, combining textual and image-based data. The experimental study compares diagnostic strategies for widely used open and closed-source LVLMs. We demonstrate that multimodal dialogue with internal reasoning improves F1 score by 6.5% over non-dialogue settings, highlighting the importance of context-aware, information-seeking questioning. Moreover, injecting predictions from a diagnostic convolutional neural network into the LVLMâ€™s context boosts F1 by up to 20%. Source code is available at <a target="_blank" rel="noopener" href="https://github.com/univanxx/3mdbench">https://github.com/univanxx/3mdbench</a>. </p>
<blockquote>
<p>è™½ç„¶å¤§å‹è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆLVLMsï¼‰åœ¨åŒ»å­¦é¢†åŸŸå¾—åˆ°äº†ç§¯æçš„ç ”ç©¶å’Œæ¢ç´¢ï¼Œä½†å®ƒä»¬åœ¨è¿›è¡Œç»“åˆå‡†ç¡®è¯Šæ–­å’Œä¸“ä¸šå¯¹è¯çš„å¤æ‚ç°å®ä¸–ç•Œè¿œç¨‹åŒ»ç–—å’¨è¯¢æ–¹é¢çš„èƒ½åŠ›ä»ç„¶è¢«ä½ä¼°ã€‚æœ¬æ–‡ä»‹ç»äº†3MDBenchï¼ˆåŒ»ç–—å¤šæ¨¡æ€å¤šæ™ºèƒ½ä½“å¯¹è¯åŸºå‡†æµ‹è¯•ï¼‰ï¼Œè¿™æ˜¯ä¸€ä¸ªå¼€æºæ¡†æ¶ï¼Œç”¨äºæ¨¡æ‹Ÿå’Œè¯„ä¼°LVLMé©±åŠ¨çš„è¿œç¨‹åŒ»ç–—å’¨è¯¢ã€‚3MDBenché€šè¿‡åŸºäºæ€§æ ¼çš„æ‚£è€…æ™ºèƒ½ä½“æ¨¡æ‹Ÿæ‚£è€…å˜å¼‚æ€§ï¼Œå¹¶é€šè¿‡è¯„ä¼°æ™ºèƒ½ä½“è¯„ä¼°è¯Šæ–­å‡†ç¡®æ€§å’Œå¯¹è¯è´¨é‡ã€‚å®ƒåŒ…æ‹¬æ¥è‡ªç°å®ä¸–ç•Œè¿œç¨‹åŒ»ç–—äº’åŠ¨çš„34ä¸ªè¯Šæ–­ä¸­çš„2996ä¸ªæ¡ˆä¾‹ï¼Œç»“åˆäº†æ–‡æœ¬å’Œå›¾åƒæ•°æ®ã€‚å®éªŒæ€§ç ”ç©¶æ¯”è¾ƒäº†å¹¿æ³›ä½¿ç”¨çš„å¼€æºå’Œé—­æºLVLMsçš„è¯Šæ–­ç­–ç•¥ã€‚æˆ‘ä»¬è¯æ˜ï¼Œä¸æ— å¯¹è¯ç¯å¢ƒç›¸æ¯”ï¼Œå…·æœ‰å†…éƒ¨æ¨ç†çš„å¤šæ¨¡å¼å¯¹è¯å¯ä»¥æé«˜F1åˆ†æ•°6.5%ï¼Œè¿™çªæ˜¾äº†ä¸Šä¸‹æ–‡æ„ŸçŸ¥ã€å¯»æ±‚ä¿¡æ¯çš„é—®é¢˜çš„é‡è¦æ€§ã€‚æ­¤å¤–ï¼Œå°†è¯Šæ–­å·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNï¼‰çš„é¢„æµ‹ç»“æœæ³¨å…¥LVLMçš„è¯­å¢ƒä¸­ï¼ŒF1å¯ä»¥æé«˜é«˜è¾¾20%ã€‚æºä»£ç å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/univanxx/3mdbench%E8%8E%B7%E5%8F%96%E3%80%82">https://github.com/univanxx/3mdbenchè·å–ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.13861v3">PDF</a> EMNLP 25 (main)</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†ä¸€ä¸ªåä¸º3MDBenchçš„å¼€æ”¾æºä»£ç æ¡†æ¶ï¼Œç”¨äºæ¨¡æ‹Ÿå’Œè¯„ä¼°å¤§å‹è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆLVLMsï¼‰åœ¨è¿œç¨‹åŒ»ç–—å’¨è¯¢ä¸­çš„è¡¨ç°ã€‚è¯¥æ¡†æ¶ç»“åˆäº†æ–‡æœ¬å’Œå›¾åƒæ•°æ®ï¼Œæ¨¡æ‹Ÿæ‚£è€…çš„ä¸ªä½“å·®å¼‚ï¼Œå¹¶é€šè¿‡è¯„ä¼°å™¨è¯„ä¼°è¯Šæ–­å‡†ç¡®æ€§å’Œå¯¹è¯è´¨é‡ã€‚å®éªŒç ”ç©¶è¡¨æ˜ï¼Œä¸éå¯¹è¯è®¾ç½®ç›¸æ¯”ï¼Œæ¨¡æ€å¯¹è¯ä¸å†…éƒ¨æ¨ç†å¯ä»¥æé«˜F1åˆ†æ•°è¾¾6.5%ï¼Œè€Œå°†è¯Šæ–­å·ç§¯ç¥ç»ç½‘ç»œçš„é¢„æµ‹ç»“æœæ³¨å…¥LVLMsçš„èƒŒæ™¯ä¿¡æ¯ä¸­ï¼Œå¯ä»¥æé«˜F1åˆ†æ•°è¾¾20%ã€‚è¯¥æ¡†æ¶ä¸ºåŒ»ç–—é¢†åŸŸçš„å¤æ‚ç°å®å’¨è¯¢æä¾›äº†æ–°çš„æ¨¡æ‹Ÿå’Œè¯„ä¼°å·¥å…·ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>3MDBenchæ˜¯ä¸€ä¸ªæ¨¡æ‹Ÿè¯„ä¼°å¤§å‹è§†è§‰è¯­è¨€æ¨¡å‹åœ¨è¿œç¨‹åŒ»ç–—å’¨è¯¢ä¸­çš„æ€§èƒ½æ¡†æ¶ã€‚</li>
<li>å®ƒç»“åˆäº†æ–‡æœ¬å’Œå›¾åƒæ•°æ®ï¼Œæ¨¡æ‹Ÿæ‚£è€…çš„ä¸ªä½“å·®å¼‚ã€‚</li>
<li>3MDBenché€šè¿‡è¯„ä¼°å™¨è¯„ä¼°è¯Šæ–­å‡†ç¡®æ€§å’Œå¯¹è¯è´¨é‡ã€‚</li>
<li>å¤šæ¨¡æ€å¯¹è¯ä¸å†…éƒ¨æ¨ç†ç›¸æ¯”éå¯¹è¯è®¾ç½®èƒ½æé«˜F1åˆ†æ•°è¾¾6.5%ã€‚</li>
<li>å°†è¯Šæ–­å·ç§¯ç¥ç»ç½‘ç»œçš„é¢„æµ‹ç»“æœæ³¨å…¥LVLMçš„èƒŒæ™¯ä¿¡æ¯å¯ä»¥æé«˜F1åˆ†æ•°è¾¾20%ã€‚</li>
<li>è¯¥æ¡†æ¶ä¸ºè¿œç¨‹åŒ»ç–—å’¨è¯¢æä¾›äº†æ–°çš„æ¨¡æ‹Ÿå’Œè¯„ä¼°å·¥å…·ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.13861">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-8bde5ecef5d9e0b95c5c075f85839c23" align="middle">
<img src="https://picx.zhimg.com/v2-1988fbce9480b6158d44653acfadfc9d" align="middle">
<img src="https://picx.zhimg.com/v2-3bf90eb646ae6c69c97a54aaea0638bb" align="middle">
<img src="https://picx.zhimg.com/v2-fb3991b91788a6436088ed83321b2c1d" align="middle">
<img src="https://picx.zhimg.com/v2-a1de8d1a4c3f8ea9c97ebc302604be55" align="middle">
</details>


<h1 id="-14"><a href="#-14" class="headerlink" title=""></a></h1><h2 id="LLM-Strategic-Reasoning-Agentic-Study-through-Behavioral-Game-Theory"><a href="#LLM-Strategic-Reasoning-Agentic-Study-through-Behavioral-Game-Theory" class="headerlink" title="LLM Strategic Reasoning: Agentic Study through Behavioral Game Theory"></a>LLM Strategic Reasoning: Agentic Study through Behavioral Game Theory</h2><p><strong>Authors:Jingru Jia, Zehua Yuan, Junhao Pan, Paul E. McNamara, Deming Chen</strong></p>
<p>Strategic decision-making involves interactive reasoning where agents adapt their choices in response to others, yet existing evaluations of large language models (LLMs) often emphasize Nash Equilibrium (NE) approximation, overlooking the mechanisms driving their strategic choices. To bridge this gap, we introduce an evaluation framework grounded in behavioral game theory, disentangling reasoning capability from contextual effects. Testing 22 state-of-the-art LLMs, we find that GPT-o3-mini, GPT-o1, and DeepSeek-R1 dominate most games yet also demonstrate that the model scale alone does not determine performance. In terms of prompting enhancement, Chain-of-Thought (CoT) prompting is not universally effective, as it increases strategic reasoning only for models at certain levels while providing limited gains elsewhere. Additionally, we investigate the impact of encoded demographic features on the models, observing that certain assignments impact the decision-making pattern. For instance, GPT-4o shows stronger strategic reasoning with female traits than males, while Gemma assigns higher reasoning levels to heterosexual identities compared to other sexual orientations, indicating inherent biases. These findings underscore the need for ethical standards and contextual alignment to balance improved reasoning with fairness. </p>
<blockquote>
<p>æˆ˜ç•¥å†³ç­–åˆ¶å®šæ¶‰åŠäº¤äº’å¼æ¨ç†ï¼Œå…¶ä¸­ä»£ç†ä¼šæ ¹æ®ä»–äººçš„é€‰æ‹©è°ƒæ•´è‡ªå·±çš„å†³ç­–ã€‚ç„¶è€Œï¼Œå¯¹äºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„ç°æœ‰è¯„ä¼°é€šå¸¸ä¾§é‡äºçº³ä»€å‡è¡¡ï¼ˆNEï¼‰è¿‘ä¼¼ï¼Œå¿½ç•¥äº†é©±åŠ¨å…¶æˆ˜ç•¥é€‰æ‹©èƒŒåçš„æœºåˆ¶ã€‚ä¸ºäº†å¡«è¡¥è¿™ä¸€ç©ºç™½ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ä¸ªåŸºäºè¡Œä¸ºåšå¼ˆè®ºçš„è¯„ä¼°æ¡†æ¶ï¼Œä»æƒ…å¢ƒæ•ˆåº”ä¸­åˆ†ç¦»æ¨ç†èƒ½åŠ›ã€‚é€šè¿‡å¯¹22ä¸ªæœ€æ–°å¤§å‹è¯­è¨€æ¨¡å‹çš„æµ‹è¯•ï¼Œæˆ‘ä»¬å‘ç°GPT-o3-miniã€GPT-o1å’ŒDeepSeek-R1åœ¨å¤§å¤šæ•°æ¸¸æˆä¸­å æ®ä¸»å¯¼åœ°ä½ï¼Œä½†åŒæ—¶ä¹Ÿè¡¨æ˜æ¨¡å‹è§„æ¨¡æœ¬èº«å¹¶ä¸èƒ½å†³å®šæ€§èƒ½ã€‚åœ¨æç¤ºå¢å¼ºæ–¹é¢ï¼Œé“¾å¼æ€ç»´ï¼ˆCoTï¼‰æç¤ºå¹¶éæ™®éæœ‰æ•ˆï¼Œå› ä¸ºå®ƒåªé’ˆå¯¹æŸäº›çº§åˆ«çš„æ¨¡å‹æé«˜æˆ˜ç•¥æ¨ç†èƒ½åŠ›ï¼Œè€Œåœ¨å…¶ä»–åœ°æ–¹æä¾›æœ‰é™çš„æ”¶ç›Šã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜æ¢è®¨äº†ç¼–ç çš„äººå£ç‰¹å¾å¯¹æ¨¡å‹çš„å½±å“ï¼Œå‘ç°æŸäº›ä»»åŠ¡ä¼šå½±å“å†³ç­–æ¨¡å¼ã€‚ä¾‹å¦‚ï¼ŒGPT-4oåœ¨å¥³æ€§ç‰¹è´¨æ–¹é¢è¡¨ç°å‡ºæ›´å¼ºçš„æˆ˜ç•¥æ¨ç†èƒ½åŠ›ç›¸å¯¹äºç”·æ€§ï¼Œè€ŒGemmaä¸ºå¼‚æ€§æ‹èº«ä»½åˆ†é…äº†è¾ƒé«˜çš„æ¨ç†æ°´å¹³ä¸å…¶ä»–æ€§å–å‘ç›¸æ¯”ï¼Œè¿™è¡¨æ˜äº†å›ºæœ‰çš„åè§ã€‚è¿™äº›å‘ç°å¼ºè°ƒäº†éœ€è¦åœ¨æ”¹è¿›æ¨ç†ä¸å…¬å¹³ä¹‹é—´å–å¾—å¹³è¡¡çš„é“å¾·æ ‡å‡†å’Œæƒ…å¢ƒå¯¹é½ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.20432v3">PDF</a> Accepted by NeurIPS 2025</p>
<p><strong>Summary</strong></p>
<p>è¿™ç¯‡æ–‡æœ¬æ¢è®¨äº†æˆ˜ç•¥å†³ç­–åˆ¶å®šè¿‡ç¨‹ä¸­çš„äº¤äº’æ¨ç†å’Œå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„è¯„ä»·é—®é¢˜ã€‚æ–‡ç« å¼ºè°ƒç°æœ‰è¯„ä»·æ¡†æ¶è¿‡äºå…³æ³¨çº³ä»€å‡è¡¡ï¼ˆNEï¼‰è¿‘ä¼¼ï¼Œå¿½ç•¥äº†é©±åŠ¨æˆ˜ç•¥é€‰æ‹©çš„æœºåˆ¶ã€‚ä¸ºæ­¤ï¼Œæ–‡ç« æå‡ºäº†åŸºäºè¡Œä¸ºåšå¼ˆè®ºçš„è¯„ä»·æ¡†æ¶ï¼Œå°†æ¨ç†èƒ½åŠ›ä¸æƒ…å¢ƒæ•ˆåº”åŒºåˆ†å¼€æ¥ã€‚é€šè¿‡å¯¹å¤šæ¬¾å‰æ²¿LLMçš„æµ‹è¯•å‘ç°ï¼ŒGPT-o3-miniã€GPT-o1å’ŒDeepSeek-R1åœ¨æ¸¸æˆä¸­çš„è¡¨ç°æœ€ä¸ºå‡ºè‰²ï¼Œä½†æ¨¡å‹è§„æ¨¡æœ¬èº«å¹¶ä¸å†³å®šæ€§èƒ½ã€‚æ­¤å¤–ï¼Œæ–‡ç« è¿˜æ¢è®¨äº†æç¤ºå¢å¼ºæ–¹å¼çš„å½±å“ï¼Œå‘ç°é“¾å¼æ€ç»´ï¼ˆCoTï¼‰æç¤ºå¹¶éæ™®éæœ‰æ•ˆï¼Œè€Œä¸”å¯¹æ¨¡å‹æˆ˜ç•¥æ¨ç†çš„æå‡æœ‰é™ã€‚åŒæ—¶ï¼Œæ–‡ç« è¿˜å‘ç°ç¼–ç åçš„ç‰¹å¾å¯¹æ¨¡å‹å†³ç­–åˆ¶å®šæ¨¡å¼æœ‰å½±å“ï¼Œä½“ç°äº†ä¸åŒæ¨¡å‹å¯¹äººå£ç‰¹å¾çš„å›ºæœ‰åè§ã€‚æ€»ç»“æ¥è¯´ï¼Œè¦æé«˜æˆ˜ç•¥å†³ç­–åˆ¶å®šçš„å…¬æ­£æ€§å’Œæ•ˆç‡ï¼Œéœ€è¦æ³¨é‡æ¨¡å‹çš„æƒ…å¢ƒå¯¹é½å’Œä¼¦ç†æ ‡å‡†çš„å¹³è¡¡ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>æˆ˜ç•¥å†³ç­–æ¶‰åŠäº’åŠ¨æ¨ç†ï¼Œå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„è¯„ä»·åº”é‡è§†è¡Œä¸ºåšå¼ˆç†è®ºæ¡†æ¶ã€‚</li>
<li>GPT-o3-miniã€GPT-o1å’ŒDeepSeek-R1åœ¨å¤šæ•°æ¸¸æˆä¸­çš„è¡¨ç°çªå‡ºï¼Œä½†æ¨¡å‹è§„æ¨¡å¹¶éå†³å®šæ€§èƒ½çš„å”¯ä¸€å› ç´ ã€‚</li>
<li>é“¾å¼æ€ç»´ï¼ˆCoTï¼‰æç¤ºå¹¶éå¯¹æ‰€æœ‰æ¨¡å‹éƒ½æœ‰æ•ˆï¼Œå¯¹æˆ˜ç•¥æ¨ç†çš„æå‡æœ‰é™ã€‚</li>
<li>æ¨¡å‹åœ¨æˆ˜ç•¥å†³ç­–ä¸­å—åˆ°ç¼–ç åçš„äººå£ç‰¹å¾å½±å“ï¼Œè¡¨ç°å‡ºå›ºæœ‰åè§ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.20432">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-310b9722d2f9b5f4834692a748b113f7" align="middle">
<img src="https://picx.zhimg.com/v2-4f82870e579c5fd47f9aeb5344777896" align="middle">
<img src="https://picx.zhimg.com/v2-d1ed24ea02280de2e3ef31303b539943" align="middle">
</details>


<h1 id="-15"><a href="#-15" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-11-05/Agent/">https://kedreamix.github.io/Talk2Paper/Paper/2025-11-05/Agent/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/Agent/">
                                    <span class="chip bg-color">Agent</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-11-05/Few-Shot/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-0e51a2cddeb30fd7f0f218dc4fac60c8" class="responsive-img" alt="Few-Shot">
                        
                        <span class="card-title">Few-Shot</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Few-Shot æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-11-05  Patient-Centered Summarization Framework for AI Clinical Summarization   A Mixed-Methods Design
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-11-05
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Few-Shot/" class="post-category">
                                    Few-Shot
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Few-Shot/">
                        <span class="chip bg-color">Few-Shot</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-11-05/LLM/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-366da6853bec5e8188a1ade9dca3abed" class="responsive-img" alt="LLM">
                        
                        <span class="card-title">LLM</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            LLM æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-11-05  NAUTILUS A Large Multimodal Model for Underwater Scene Understanding
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-11-05
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/LLM/" class="post-category">
                                    LLM
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/LLM/">
                        <span class="chip bg-color">LLM</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">32306k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
