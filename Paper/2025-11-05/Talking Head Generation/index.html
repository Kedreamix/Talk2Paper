<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Talking Head Generation">
    <meta name="description" content="Talking Head Generation æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-11-05  See the Speaker Crafting High-Resolution Talking Faces from Speech with   Prior Guidance and Region Refinement">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>Talking Head Generation | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://pic-private.zhihu.com/v2-7e50e979b90b47a71545c2fde3f71161~resize:0:q75.jpg?source=1f5c5e47&expiration=1762309334&auth_key=1762309334-0-0-7a2157565ed14088f6173004f0617fa9&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Talking Head Generation</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/Talking-Head-Generation/">
                                <span class="chip bg-color">Talking Head Generation</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/Talking-Head-Generation/" class="post-category">
                                Talking Head Generation
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-11-05
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-11-11
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    9.9k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    40 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-11-05-æ›´æ–°"><a href="#2025-11-05-æ›´æ–°" class="headerlink" title="2025-11-05 æ›´æ–°"></a>2025-11-05 æ›´æ–°</h1><h2 id="See-the-Speaker-Crafting-High-Resolution-Talking-Faces-from-Speech-with-Prior-Guidance-and-Region-Refinement"><a href="#See-the-Speaker-Crafting-High-Resolution-Talking-Faces-from-Speech-with-Prior-Guidance-and-Region-Refinement" class="headerlink" title="See the Speaker: Crafting High-Resolution Talking Faces from Speech with   Prior Guidance and Region Refinement"></a>See the Speaker: Crafting High-Resolution Talking Faces from Speech with   Prior Guidance and Region Refinement</h2><p><strong>Authors:Jinting Wang, Jun Wang, Hei Victor Cheng, Li Liu</strong></p>
<p>Unlike existing methods that rely on source images as appearance references and use source speech to generate motion, this work proposes a novel approach that directly extracts information from the speech, addressing key challenges in speech-to-talking face. Specifically, we first employ a speech-to-face portrait generation stage, utilizing a speech-conditioned diffusion model combined with statistical facial prior and a sample-adaptive weighting module to achieve high-quality portrait generation. In the subsequent speech-driven talking face generation stage, we embed expressive dynamics such as lip movement, facial expressions, and eye movements into the latent space of the diffusion model and further optimize lip synchronization using a region-enhancement module. To generate high-resolution outputs, we integrate a pre-trained Transformer-based discrete codebook with an image rendering network, enhancing video frame details in an end-to-end manner. Experimental results demonstrate that our method outperforms existing approaches on the HDTF, VoxCeleb, and AVSpeech datasets. Notably, this is the first method capable of generating high-resolution, high-quality talking face videos exclusively from a single speech input. </p>
<blockquote>
<p>ä¸ä¼ ç»Ÿæ–¹æ³•ä¸åŒï¼Œä¼ ç»Ÿæ–¹æ³•ä¾èµ–äºæºå›¾åƒä½œä¸ºå¤–è§‚å‚è€ƒå¹¶ä½¿ç”¨æºè¯­éŸ³æ¥ç”Ÿæˆè¿åŠ¨ï¼Œè€Œè¿™é¡¹å·¥ä½œæå‡ºäº†ä¸€ç§ç›´æ¥ä»è¯­éŸ³ä¸­æå–ä¿¡æ¯çš„æ–°æ–¹æ³•ï¼Œè§£å†³äº†è¯­éŸ³åˆ°è¯­éŸ³æŒ‘æˆ˜ä¸­çš„å…³é”®å¯¹è¯é¢éƒ¨ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬é¦–å…ˆé‡‡ç”¨ä»è¯­éŸ³åˆ°äººè„¸è‚–åƒç”Ÿæˆé˜¶æ®µï¼Œåˆ©ç”¨å—è¯­éŸ³æ§åˆ¶çš„æ‰©æ•£æ¨¡å‹ï¼Œç»“åˆç»Ÿè®¡é¢éƒ¨å…ˆéªŒçŸ¥è¯†å’Œæ ·æœ¬è‡ªé€‚åº”åŠ æƒæ¨¡å—ï¼Œå®ç°é«˜è´¨é‡è‚–åƒç”Ÿæˆã€‚åœ¨éšåçš„è¯­éŸ³é©±åŠ¨å¯¹è¯é¢éƒ¨ç”Ÿæˆé˜¶æ®µï¼Œæˆ‘ä»¬å°†è¡¨æƒ…åŠ¨æ€ï¼ˆå¦‚å˜´å”‡åŠ¨ä½œã€é¢éƒ¨è¡¨æƒ…å’Œçœ¼éƒ¨è¿åŠ¨ï¼‰åµŒå…¥åˆ°æ‰©æ•£æ¨¡å‹çš„æ½œåœ¨ç©ºé—´ä¸­ï¼Œå¹¶è¿›ä¸€æ­¥ä½¿ç”¨åŒºåŸŸå¢å¼ºæ¨¡å—ä¼˜åŒ–å˜´å”‡åŒæ­¥ã€‚ä¸ºäº†ç”Ÿæˆé«˜åˆ†è¾¨ç‡è¾“å‡ºï¼Œæˆ‘ä»¬å°†é¢„è®­ç»ƒçš„åŸºäºTransformerçš„ç¦»æ•£ç æœ¬ä¸å›¾åƒæ¸²æŸ“ç½‘ç»œç›¸ç»“åˆï¼Œä»¥ç«¯åˆ°ç«¯çš„æ–¹å¼å¢å¼ºè§†é¢‘å¸§ç»†èŠ‚ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨HDTFã€VoxCelebå’ŒAVSpeechæ•°æ®é›†ä¸Šçš„æ€§èƒ½ä¼˜äºç°æœ‰æ–¹æ³•ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œè¿™æ˜¯ç¬¬ä¸€ç§èƒ½å¤Ÿä»å•ä¸€è¯­éŸ³è¾“å…¥ç”Ÿæˆé«˜åˆ†è¾¨ç‡ã€é«˜è´¨é‡å¯¹è¯é¢éƒ¨è§†é¢‘çš„æ–¹æ³•ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.26819v1">PDF</a> 16 pages,15 figures, accepted by TASLP</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„æ–¹æ³•ï¼Œç›´æ¥ä»è¯­éŸ³ä¸­æå–ä¿¡æ¯æ¥ç”Ÿæˆè¯´è¯è€…çš„é¢éƒ¨åŠ¨ç”»ï¼Œè§£å†³äº†è¯­éŸ³åˆ°è¯´è¯äººè„¸çš„å…³é”®æŒ‘æˆ˜ã€‚é¦–å…ˆï¼Œé€šè¿‡ç»“åˆè¯­éŸ³æ¡ä»¶æ‰©æ•£æ¨¡å‹ã€é¢éƒ¨ç»Ÿè®¡å…ˆéªŒçŸ¥è¯†å’Œæ ·æœ¬è‡ªé€‚åº”åŠ æƒæ¨¡å—ï¼Œè¿›è¡Œè¯­éŸ³é©±åŠ¨çš„äººè„¸è‚–åƒç”Ÿæˆã€‚éšåï¼Œåœ¨è¯­éŸ³é©±åŠ¨çš„äººè„¸åŠ¨ç”»ç”Ÿæˆé˜¶æ®µï¼Œå°†å˜´å”‡åŠ¨ä½œã€é¢éƒ¨è¡¨æƒ…å’Œçœ¼ç›è¿åŠ¨ç­‰è¡¨è¾¾æ€§åŠ¨æ€åµŒå…¥æ‰©æ•£æ¨¡å‹çš„æ½œåœ¨ç©ºé—´ï¼Œå¹¶ä½¿ç”¨åŒºåŸŸå¢å¼ºæ¨¡å—è¿›ä¸€æ­¥ä¼˜åŒ–å˜´å”‡åŒæ­¥ã€‚æœ€åï¼Œé€šè¿‡é›†æˆé¢„è®­ç»ƒçš„åŸºäºTransformerçš„ç¦»æ•£ç æœ¬å’Œå›¾åƒæ¸²æŸ“ç½‘ç»œï¼Œä»¥ç«¯åˆ°ç«¯çš„æ–¹å¼æé«˜è§†é¢‘å¸§çš„ç»†èŠ‚åˆ†è¾¨ç‡ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨HDTFã€VoxCelebå’ŒAVSpeechæ•°æ®é›†ä¸Šçš„è¡¨ç°ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œå¹¶ä¸”æ˜¯é¦–ä¸ªèƒ½å¤Ÿä»…ä»å•ä¸€è¯­éŸ³è¾“å…¥ç”Ÿæˆé«˜åˆ†è¾¨ç‡ã€é«˜è´¨é‡è¯´è¯äººè„¸è§†é¢‘çš„æ–¹æ³•ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æå‡ºäº†æ–°çš„æ–¹æ³•ï¼Œç›´æ¥ä»è¯­éŸ³ä¸­æå–ä¿¡æ¯ç”Ÿæˆè¯´è¯è€…çš„é¢éƒ¨åŠ¨ç”»ã€‚</li>
<li>é€šè¿‡ç»“åˆè¯­éŸ³æ¡ä»¶æ‰©æ•£æ¨¡å‹ã€é¢éƒ¨ç»Ÿè®¡å…ˆéªŒçŸ¥è¯†å’Œæ ·æœ¬è‡ªé€‚åº”åŠ æƒæ¨¡å—ï¼Œå®ç°é«˜è´¨é‡çš„äººè„¸è‚–åƒç”Ÿæˆã€‚</li>
<li>åœ¨è¯­éŸ³é©±åŠ¨çš„äººè„¸åŠ¨ç”»ç”Ÿæˆé˜¶æ®µï¼ŒåµŒå…¥è¡¨è¾¾æ€§åŠ¨æ€å¦‚å˜´å”‡åŠ¨ä½œã€é¢éƒ¨è¡¨æƒ…å’Œçœ¼ç›è¿åŠ¨ã€‚</li>
<li>ä½¿ç”¨åŒºåŸŸå¢å¼ºæ¨¡å—ä¼˜åŒ–å˜´å”‡åŒæ­¥ã€‚</li>
<li>é€šè¿‡é›†æˆé¢„è®­ç»ƒçš„åŸºäºTransformerçš„ç¦»æ•£ç æœ¬å’Œå›¾åƒæ¸²æŸ“ç½‘ç»œï¼Œæé«˜è§†é¢‘å¸§çš„ç»†èŠ‚åˆ†è¾¨ç‡ã€‚</li>
<li>è¯¥æ–¹æ³•åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šçš„è¡¨ç°ä¼˜äºç°æœ‰æ–¹æ³•ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.26819">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-fa24aaab9b941586a58f03e38f6a9525~resize:0:q75.jpg?source=1f5c5e47&expiration=1762309291&auth_key=1762309291-0-0-23dc6a0d5c2ce76d3f0d99d4618cfb09&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-aa9181bd10a9be2f9da70ea828680c21~resize:0:q75.jpg?source=1f5c5e47&expiration=1762309299&auth_key=1762309299-0-0-3b54d70971bdd2bc770585a34bac0c9a&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-d2d8b228e62f52fbd6afc2be16ff1ac8~resize:0:q75.jpg?source=1f5c5e47&expiration=1762309306&auth_key=1762309306-0-0-cf01d31e6f53f92035b3705a5424bda7&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-0fc5501fa0cba588a199bd7cf803ea2e~resize:0:q75.jpg?source=1f5c5e47&expiration=1762309313&auth_key=1762309313-0-0-a05222ea1314e0cb0abde133cce4f6fd&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-839c07f1e8172a1131c6a0d545624d78~resize:0:q75.jpg?source=1f5c5e47&expiration=1762309319&auth_key=1762309319-0-0-066d30ddb811604ebe99481538b6f9a1&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="Talk2Ref-A-Dataset-for-Reference-Prediction-from-Scientific-Talks"><a href="#Talk2Ref-A-Dataset-for-Reference-Prediction-from-Scientific-Talks" class="headerlink" title="Talk2Ref: A Dataset for Reference Prediction from Scientific Talks"></a>Talk2Ref: A Dataset for Reference Prediction from Scientific Talks</h2><p><strong>Authors:Frederik Broy, Maike ZÃ¼fle, Jan Niehues</strong></p>
<p>Scientific talks are a growing medium for disseminating research, and automatically identifying relevant literature that grounds or enriches a talk would be highly valuable for researchers and students alike. We introduce Reference Prediction from Talks (RPT), a new task that maps long, and unstructured scientific presentations to relevant papers. To support research on RPT, we present Talk2Ref, the first large-scale dataset of its kind, containing 6,279 talks and 43,429 cited papers (26 per talk on average), where relevance is approximated by the papers cited in the talkâ€™s corresponding source publication. We establish strong baselines by evaluating state-of-the-art text embedding models in zero-shot retrieval scenarios, and propose a dual-encoder architecture trained on Talk2Ref. We further explore strategies for handling long transcripts, as well as training for domain adaptation. Our results show that fine-tuning on Talk2Ref significantly improves citation prediction performance, demonstrating both the challenges of the task and the effectiveness of our dataset for learning semantic representations from spoken scientific content. The dataset and trained models are released under an open license to foster future research on integrating spoken scientific communication into citation recommendation systems. </p>
<blockquote>
<p>ç§‘å­¦è®²åº§æ˜¯ä¼ æ’­ç ”ç©¶çš„ä¸€ç§æ—¥ç›Šé‡è¦çš„åª’ä»‹ï¼Œè‡ªåŠ¨è¯†åˆ«èƒ½æ”¯æ’‘æˆ–ä¸°å¯Œè®²åº§å†…å®¹çš„ç›¸å…³æ–‡çŒ®å¯¹ç ”ç©¶è€…å’Œå­¦ç”Ÿæ¥è¯´éƒ½æä¸ºå®è´µã€‚æˆ‘ä»¬å¼•å…¥äº†â€œä»è®²åº§å¼•ç”¨é¢„æµ‹ï¼ˆRPTï¼‰â€è¿™ä¸€æ–°ä»»åŠ¡ï¼Œå®ƒå°†é•¿ä¸”éç»“æ„çš„ç§‘å­¦è®²åº§æ˜ å°„åˆ°ç›¸å…³è®ºæ–‡ä¸Šã€‚ä¸ºäº†æ”¯æŒRPTç ”ç©¶ï¼Œæˆ‘ä»¬æ¨å‡ºäº†Talk2Refæ•°æ®é›†ï¼Œè¿™æ˜¯ç›®å‰é¦–ä¸ªå¤§è§„æ¨¡æ•°æ®é›†ï¼ŒåŒ…å«6,279åœºè®²åº§å’Œ43,429ç¯‡è¢«å¼•ç”¨çš„è®ºæ–‡ï¼ˆå¹³å‡æ¯åœºè®²åº§æœ‰26ç¯‡è®ºæ–‡ï¼‰ï¼Œå…¶ä¸­ç›¸å…³æ€§ç”±è®²åº§å¯¹åº”æºå‡ºç‰ˆç‰©ä¸­å¼•ç”¨çš„è®ºæ–‡æ¥è¿‘ä¼¼åˆ¤æ–­ã€‚æˆ‘ä»¬é€šè¿‡è¯„ä¼°æœ€å…ˆè¿›æ–‡æœ¬åµŒå…¥æ¨¡å‹åœ¨é›¶æ ·æœ¬æ£€ç´¢åœºæ™¯ä¸­çš„è¡¨ç°æ¥å»ºç«‹å¼ºåŸºçº¿ï¼Œå¹¶æå‡ºä¸€ç§åœ¨Talk2Refä¸Šè®­ç»ƒçš„åŒç¼–ç å™¨æ¶æ„ã€‚æˆ‘ä»¬è¿›ä¸€æ­¥æ¢ç´¢äº†å¤„ç†é•¿æ–‡æœ¬çš„ç­–ç•¥ä»¥åŠé’ˆå¯¹é¢†åŸŸçš„é€‚åº”æ€§è®­ç»ƒã€‚æˆ‘ä»¬çš„ç»“æœè¡¨æ˜ï¼Œåœ¨Talk2Refä¸Šè¿›è¡Œå¾®è°ƒèƒ½æ˜¾è‘—æé«˜å¼•ç”¨é¢„æµ‹æ€§èƒ½ï¼Œè¿™ä¸ä»…ä½“ç°äº†è¯¥ä»»åŠ¡å…·æœ‰æŒ‘æˆ˜æ€§ä¹Ÿæ˜¾ç¤ºäº†æˆ‘ä»¬çš„æ•°æ®é›†å¯¹äºå­¦ä¹ å£å¤´ç§‘å­¦å†…å®¹çš„è¯­ä¹‰è¡¨ç¤ºçš„æœ‰æ•ˆæ€§ã€‚æ•°æ®é›†å’Œè®­ç»ƒå¥½çš„æ¨¡å‹éƒ½åœ¨å¼€æ”¾è®¸å¯ä¸‹å‘å¸ƒï¼Œä»¥ä¿ƒè¿›æœªæ¥ç ”ç©¶å°†å£å¤´ç§‘å­¦äº¤æµèå…¥å¼•ç”¨æ¨èç³»ç»Ÿã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.24478v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†ä»æ¼”è®²ä¸­é¢„æµ‹å‚è€ƒæ–‡çŒ®ï¼ˆRPTï¼‰çš„æ–°ä»»åŠ¡ï¼Œè¯¥ä»»åŠ¡æ—¨åœ¨å°†é•¿ä¸”éç»“æ„çš„ç§‘å­¦æ¼”è®²ä¸ç›¸å…³çš„è®ºæ–‡ç›¸åŒ¹é…ã€‚ä¸ºæ”¯æŒRPTç ”ç©¶ï¼Œæ–‡ç« æ¨å‡ºäº†Talk2Refæ•°æ®é›†ï¼ŒåŒ…å«6,279ä¸ªæ¼”è®²å’Œ43,429ç¯‡è¢«å¼•ç”¨çš„è®ºæ–‡ï¼ˆå¹³å‡æ¯ç¯‡æ¼”è®²æœ‰26ç¯‡è®ºæ–‡ï¼‰ã€‚æ–‡ç« è¯„ä¼°äº†æœ€å…ˆè¿›çš„æ–‡æœ¬åµŒå…¥æ¨¡å‹åœ¨é›¶æ ·æœ¬æ£€ç´¢åœºæ™¯ä¸­çš„è¡¨ç°ï¼Œå¹¶æå‡ºäº†ä¸€ç§åœ¨Talk2Refä¸Šè®­ç»ƒçš„åŒé‡ç¼–ç å™¨æ¶æ„ã€‚æ­¤å¤–ï¼Œæ–‡ç« è¿˜æ¢è®¨äº†å¤„ç†é•¿æ–‡æœ¬çš„ç­–ç•¥ä»¥åŠé¢†åŸŸé€‚åº”æ€§çš„è®­ç»ƒç­–ç•¥ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œåœ¨Talk2Refä¸Šè¿›è¡Œå¾®è°ƒå¯ä»¥æ˜¾è‘—æé«˜å¼•ç”¨é¢„æµ‹æ€§èƒ½ï¼Œè¿™æ—¢ä½“ç°äº†è¯¥ä»»åŠ¡çš„æŒ‘æˆ˜æ€§ï¼Œä¹Ÿè¯æ˜äº†æ•°æ®é›†ä»å£å¤´ç§‘å­¦å†…å®¹ä¸­å­¦ä¹ è¯­ä¹‰è¡¨ç¤ºçš„æœ‰æ•ˆæ€§ã€‚æ•°æ®é›†å’Œè®­ç»ƒå¥½çš„æ¨¡å‹ä»¥å¼€æ”¾è®¸å¯æ–¹å¼å‘å¸ƒï¼Œä»¥ä¿ƒè¿›å°†æ¥å°†å£å¤´ç§‘å­¦äº¤æµèå…¥å¼•æ–‡æ¨èç³»ç»Ÿçš„ç ”ç©¶ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æå‡ºäº†ä»æ¼”è®²ä¸­é¢„æµ‹å‚è€ƒæ–‡çŒ®ï¼ˆRPTï¼‰çš„æ–°ä»»åŠ¡ï¼Œæ—¨åœ¨å°†ç§‘å­¦æ¼”è®²ä¸ç›¸å…³çš„è®ºæ–‡ç›¸åŒ¹é…ã€‚</li>
<li>ä»‹ç»äº†Talk2Refæ•°æ®é›†ï¼ŒåŒ…å«å¤§é‡ç§‘å­¦æ¼”è®²åŠå…¶å¯¹åº”çš„å‚è€ƒæ–‡çŒ®ã€‚</li>
<li>è¯„ä¼°äº†æ–‡æœ¬åµŒå…¥æ¨¡å‹åœ¨é›¶æ ·æœ¬æ£€ç´¢åœºæ™¯ä¸­çš„è¡¨ç°ã€‚</li>
<li>æå‡ºäº†åŒé‡ç¼–ç å™¨æ¶æ„ï¼Œå¹¶åœ¨Talk2Refæ•°æ®é›†ä¸Šè¿›è¡Œè®­ç»ƒã€‚</li>
<li>æ¢è®¨äº†å¦‚ä½•å¤„ç†é•¿æ–‡æœ¬ä»¥åŠé¢†åŸŸé€‚åº”æ€§è®­ç»ƒçš„ç­–ç•¥ã€‚</li>
<li>å¾®è°ƒTalk2Refæ•°æ®é›†å¯ä»¥æ˜¾è‘—æé«˜å¼•ç”¨é¢„æµ‹æ€§èƒ½ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.24478">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-9d6841dab088647fe61ef632b07be2b0~resize:0:q75.jpg?source=1f5c5e47&expiration=1762309327&auth_key=1762309327-0-0-f0443dc9e1474f9576ea32c019d88d0c&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-7e50e979b90b47a71545c2fde3f71161~resize:0:q75.jpg?source=1f5c5e47&expiration=1762309334&auth_key=1762309334-0-0-7a2157565ed14088f6173004f0617fa9&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-04185f563b530c5b202cfe8ddb63cc86~resize:0:q75.jpg?source=1f5c5e47&expiration=1762309341&auth_key=1762309341-0-0-59128ed8ab9ee91a6bd01a11237f1bf1&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="Lookahead-Anchoring-Preserving-Character-Identity-in-Audio-Driven-Human-Animation"><a href="#Lookahead-Anchoring-Preserving-Character-Identity-in-Audio-Driven-Human-Animation" class="headerlink" title="Lookahead Anchoring: Preserving Character Identity in Audio-Driven Human   Animation"></a>Lookahead Anchoring: Preserving Character Identity in Audio-Driven Human   Animation</h2><p><strong>Authors:Junyoung Seo, Rodrigo Mira, Alexandros Haliassos, Stella Bounareli, Honglie Chen, Linh Tran, Seungryong Kim, Zoe Landgraf, Jie Shen</strong></p>
<p>Audio-driven human animation models often suffer from identity drift during temporal autoregressive generation, where characters gradually lose their identity over time. One solution is to generate keyframes as intermediate temporal anchors that prevent degradation, but this requires an additional keyframe generation stage and can restrict natural motion dynamics. To address this, we propose Lookahead Anchoring, which leverages keyframes from future timesteps ahead of the current generation window, rather than within it. This transforms keyframes from fixed boundaries into directional beacons: the model continuously pursues these future anchors while responding to immediate audio cues, maintaining consistent identity through persistent guidance. This also enables self-keyframing, where the reference image serves as the lookahead target, eliminating the need for keyframe generation entirely. We find that the temporal lookahead distance naturally controls the balance between expressivity and consistency: larger distances allow for greater motion freedom, while smaller ones strengthen identity adherence. When applied to three recent human animation models, Lookahead Anchoring achieves superior lip synchronization, identity preservation, and visual quality, demonstrating improved temporal conditioning across several different architectures. Video results are available at the following link: <a target="_blank" rel="noopener" href="https://lookahead-anchoring.github.io/">https://lookahead-anchoring.github.io</a>. </p>
<blockquote>
<p>éŸ³é¢‘é©±åŠ¨çš„äººç‰©åŠ¨ç”»æ¨¡å‹åœ¨æ—¶åºè‡ªå›å½’ç”Ÿæˆè¿‡ç¨‹ä¸­å¸¸å¸¸ä¼šé‡åˆ°èº«ä»½æ¼‚ç§»çš„é—®é¢˜ï¼Œå³è§’è‰²éšç€æ—¶é—´çš„æ¨ç§»é€æ¸å¤±å»å…¶èº«ä»½ç‰¹å¾ã€‚ä¸€ç§è§£å†³æ–¹æ¡ˆæ˜¯ç”Ÿæˆå…³é”®å¸§ä½œä¸ºä¸­é—´æ—¶åºé”šç‚¹æ¥é˜²æ­¢é€€åŒ–ï¼Œä½†è¿™éœ€è¦é¢å¤–çš„å…³é”®å¸§ç”Ÿæˆé˜¶æ®µï¼Œå¹¶å¯èƒ½é™åˆ¶è‡ªç„¶è¿åŠ¨åŠ¨åŠ›å­¦ã€‚ä¸ºè§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†å‰ç»æ€§é”šå®šï¼ˆLookahead Anchoringï¼‰æ–¹æ³•ï¼Œå®ƒåˆ©ç”¨å½“å‰ç”Ÿæˆçª—å£ä¹‹å¤–æœªæ¥æ—¶é—´æ­¥çš„å…³é”®å¸§ï¼Œè€Œä¸æ˜¯çª—å£å†…çš„å…³é”®å¸§ã€‚è¿™å°†å…³é”®å¸§ä»å›ºå®šè¾¹ç•Œè½¬å˜ä¸ºæ–¹å‘æ€§è·¯æ ‡ï¼šæ¨¡å‹åœ¨å“åº”å³æ—¶éŸ³é¢‘æç¤ºçš„åŒæ—¶ï¼Œä¸æ–­è¿½æ±‚è¿™äº›æœªæ¥çš„é”šç‚¹ï¼Œé€šè¿‡æŒç»­çš„æŒ‡å¯¼æ¥ç»´æŒä¸€è‡´çš„èº«ä»½ã€‚è¿™ä¹Ÿå®ç°äº†è‡ªæˆ‘å…³é”®å¸§ï¼ˆself-keyframingï¼‰ï¼Œå…¶ä¸­å‚è€ƒå›¾åƒä½œä¸ºå‰ç»æ€§ç›®æ ‡ï¼Œå®Œå…¨æ¶ˆé™¤äº†å¯¹å…³é”®å¸§ç”Ÿæˆçš„éœ€æ±‚ã€‚æˆ‘ä»¬å‘ç°ï¼Œå‰ç»æ€§è§†è·è‡ªç„¶åœ°åœ¨è¡¨ç°åŠ›å’Œä¸€è‡´æ€§ä¹‹é—´æ‰¾åˆ°äº†å¹³è¡¡ï¼šè¾ƒå¤§çš„è·ç¦»å…è®¸æ›´å¤§çš„è¿åŠ¨è‡ªç”±åº¦ï¼Œè€Œè¾ƒå°çš„è·ç¦»åˆ™å¢å¼ºäº†å¯¹èº«ä»½ç‰¹å¾çš„åšæŒã€‚å°†å‰ç»æ€§é”šå®šåº”ç”¨äºä¸‰ä¸ªæœ€æ–°çš„äººç‰©åŠ¨ç”»æ¨¡å‹åï¼Œå®ç°äº†ä¼˜è¶Šçš„å”‡åŒæ­¥ã€èº«ä»½ä¿ç•™å’Œè§†è§‰è´¨é‡ï¼Œè¯æ˜äº†å…¶åœ¨ä¸åŒæ¶æ„ä¸­çš„æ”¹è¿›æ—¶åºæ¡ä»¶ã€‚è§†é¢‘ç»“æœå¯é€šè¿‡ä»¥ä¸‹é“¾æ¥æŸ¥çœ‹ï¼š<a target="_blank" rel="noopener" href="https://lookahead-anchoring.github.io./">https://lookahead-anchoring.github.ioã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.23581v1">PDF</a> Project page: <a target="_blank" rel="noopener" href="https://lookahead-anchoring.github.io/">https://lookahead-anchoring.github.io</a></p>
<p><strong>Summary</strong></p>
<p>åŸºäºéŸ³é¢‘é©±åŠ¨çš„äººç‰©åŠ¨ç”»æ¨¡å‹åœ¨æ—¶é—´è‡ªå›å½’ç”Ÿæˆè¿‡ç¨‹ä¸­ä¼šå‡ºç°èº«ä»½æ¼‚ç§»é—®é¢˜ï¼Œå³è§’è‰²éšæ—¶é—´é€æ¸å¤±å»å…¶èº«ä»½ç‰¹å¾ã€‚ä¸€ç§è§£å†³æ–¹æ¡ˆæ˜¯ç”Ÿæˆå…³é”®å¸§ä½œä¸ºä¸­é—´æ—¶é—´é”šç‚¹ä»¥é˜²æ­¢é€€åŒ–ï¼Œä½†è¿™éœ€è¦é¢å¤–çš„å…³é”®å¸§ç”Ÿæˆé˜¶æ®µï¼Œå¹¶å¯èƒ½é™åˆ¶è‡ªç„¶è¿åŠ¨åŠ¨æ€ã€‚ä¸ºè§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºå‰ç»é”šå®šï¼ˆLookahead Anchoringï¼‰æ–¹æ³•ï¼Œå®ƒåˆ©ç”¨å½“å‰ç”Ÿæˆçª—å£ä¹‹å¤–æœªæ¥æ—¶åˆ»çš„å…³é”®å¸§ï¼Œå°†å…³é”®å¸§ä»å›ºå®šè¾¹ç•Œè½¬å˜ä¸ºæ–¹å‘æŒ‡ç¤ºæ ‡ã€‚æ¨¡å‹åœ¨æŒç»­è¿½æ±‚è¿™äº›æœªæ¥é”šç‚¹çš„åŒæ—¶ï¼Œå“åº”å³æ—¶éŸ³é¢‘çº¿ç´¢ï¼Œé€šè¿‡æŒç»­æŒ‡å¯¼ä¿æŒèº«ä»½ä¸€è‡´æ€§ã€‚è¿™è¿˜åŒ…æ‹¬è‡ªæˆ‘å…³é”®å¸§ç”ŸæˆåŠŸèƒ½ï¼Œå…¶ä¸­å‚è€ƒå›¾åƒä½œä¸ºå‰ç»ç›®æ ‡ï¼Œå®Œå…¨æ¶ˆé™¤äº†å¯¹å…³é”®å¸§ç”Ÿæˆçš„éœ€æ±‚ã€‚æˆ‘ä»¬å‘ç°å‰ç»è·ç¦»è‡ªç„¶åœ°æ§åˆ¶äº†è¡¨ç°åŠ›å’Œä¸€è‡´æ€§ä¹‹é—´çš„å¹³è¡¡ï¼šè¾ƒå¤§çš„è·ç¦»å…è®¸æ›´å¤§çš„è¿åŠ¨è‡ªç”±åº¦ï¼Œè€Œè¾ƒå°çš„è·ç¦»åˆ™å¢å¼ºäº†èº«ä»½çš„ä¸€è‡´æ€§ã€‚å°†Lookahead Anchoringåº”ç”¨äºä¸‰ä¸ªè¿‘æœŸçš„äººç‰©åŠ¨ç”»æ¨¡å‹åï¼Œåœ¨å”‡åŒæ­¥ã€èº«ä»½ä¿ç•™å’Œè§†è§‰è´¨é‡æ–¹é¢å–å¾—äº†æ˜¾è‘—ä¼˜åŠ¿ï¼Œå¹¶åœ¨å¤šç§æ¶æ„ä¸­å±•ç¤ºäº†æ”¹è¿›çš„æ—¶é—´æ¡ä»¶ã€‚ç›¸å…³è§†é¢‘ç»“æœå¯é€šè¿‡ä»¥ä¸‹é“¾æ¥æŸ¥çœ‹ï¼š<a target="_blank" rel="noopener" href="https://lookahead-anchoring.github.io/">https://lookahead-anchoring.github.io</a>ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>éŸ³é¢‘é©±åŠ¨çš„äººç‰©åŠ¨ç”»æ¨¡å‹é¢ä¸´èº«ä»½æ¼‚ç§»é—®é¢˜ã€‚</li>
<li>å…³é”®å¸§ç”Ÿæˆå¯ä½œä¸ºä¸­é—´æ—¶é—´é”šç‚¹é˜²æ­¢é€€åŒ–ï¼Œä½†éœ€é¢å¤–é˜¶æ®µä¸”å¯èƒ½é™åˆ¶è‡ªç„¶è¿åŠ¨ã€‚</li>
<li>æå‡ºLookahead Anchoringæ–¹æ³•ï¼Œåˆ©ç”¨æœªæ¥æ—¶åˆ»çš„å…³é”®å¸§ï¼Œå®ç°èº«ä»½ä¸€è‡´æ€§ç»´æŒã€‚</li>
<li>Lookahead Anchoringå¯æ¶ˆé™¤å¯¹å…³é”®å¸§ç”Ÿæˆçš„éœ€æ±‚ã€‚</li>
<li>å‰ç»è·ç¦»å½±å“è¡¨ç°åŠ›å’Œä¸€è‡´æ€§å¹³è¡¡ã€‚</li>
<li>åœ¨ä¸‰ä¸ªè¿‘æœŸäººç‰©åŠ¨ç”»æ¨¡å‹ä¸­å–å¾—æ˜¾è‘—ä¼˜åŠ¿ï¼ŒåŒ…æ‹¬å”‡åŒæ­¥ã€èº«ä»½ä¿ç•™å’Œè§†è§‰è´¨é‡æå‡ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.23581">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-06476f0c48c5993da76ef6532a0b9d67~resize:0:q75.jpg?source=1f5c5e47&expiration=1762309348&auth_key=1762309348-0-0-3e2ed4c867306a8711250db260e3bb00&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-2a8542672420b8da9f632a0524dccd6f~resize:0:q75.jpg?source=1f5c5e47&expiration=1762309355&auth_key=1762309355-0-0-8ae5499c142bcb94af0926c1449fc4d6&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-36a7451008ea3848d87a0c0b7d2442bf~resize:0:q75.jpg?source=1f5c5e47&expiration=1762309362&auth_key=1762309362-0-0-becc5d1ad0129ba01e290323a1f6197a&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-601836b5d029944a7764b162898d08a6~resize:0:q75.jpg?source=1f5c5e47&expiration=1762309369&auth_key=1762309369-0-0-792f4c982fd98d7f78bbd3a32720d999&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="MAGIC-Talk-Motion-aware-Audio-Driven-Talking-Face-Generation-with-Customizable-Identity-Control"><a href="#MAGIC-Talk-Motion-aware-Audio-Driven-Talking-Face-Generation-with-Customizable-Identity-Control" class="headerlink" title="MAGIC-Talk: Motion-aware Audio-Driven Talking Face Generation with   Customizable Identity Control"></a>MAGIC-Talk: Motion-aware Audio-Driven Talking Face Generation with   Customizable Identity Control</h2><p><strong>Authors:Fatemeh Nazarieh, Zhenhua Feng, Diptesh Kanojia, Muhammad Awais, Josef Kittler</strong></p>
<p>Audio-driven talking face generation has gained significant attention for applications in digital media and virtual avatars. While recent methods improve audio-lip synchronization, they often struggle with temporal consistency, identity preservation, and customization, especially in long video generation. To address these issues, we propose MAGIC-Talk, a one-shot diffusion-based framework for customizable and temporally stable talking face generation. MAGIC-Talk consists of ReferenceNet, which preserves identity and enables fine-grained facial editing via text prompts, and AnimateNet, which enhances motion coherence using structured motion priors. Unlike previous methods requiring multiple reference images or fine-tuning, MAGIC-Talk maintains identity from a single image while ensuring smooth transitions across frames. Additionally, a progressive latent fusion strategy is introduced to improve long-form video quality by reducing motion inconsistencies and flickering. Extensive experiments demonstrate that MAGIC-Talk outperforms state-of-the-art methods in visual quality, identity preservation, and synchronization accuracy, offering a robust solution for talking face generation. </p>
<blockquote>
<p>éŸ³é¢‘é©±åŠ¨çš„è¯´è¯äººè„¸ç”Ÿæˆåœ¨æ•°å­—åª’ä½“å’Œè™šæ‹ŸåŒ–èº«çš„åº”ç”¨ä¸­å¼•èµ·äº†æå¤§çš„å…³æ³¨ã€‚è™½ç„¶æœ€è¿‘çš„æ–¹æ³•æé«˜äº†éŸ³é¢‘ä¸å˜´å”‡çš„åŒæ­¥æ€§ï¼Œä½†åœ¨é•¿æœŸè§†é¢‘ç”Ÿæˆä¸­ï¼Œå®ƒä»¬é€šå¸¸é¢ä¸´æ—¶é—´ä¸€è‡´æ€§ã€èº«ä»½ä¿ç•™å’Œå®šåˆ¶åŒ–çš„é—®é¢˜ã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†MAGIC-Talkï¼Œè¿™æ˜¯ä¸€ä¸ªåŸºäºå•æ¬¡æ‰©æ•£çš„å¯å®šåˆ¶ä¸”æ—¶é—´ç¨³å®šçš„è¯´è¯äººè„¸ç”Ÿæˆæ¡†æ¶ã€‚MAGIC-TalkåŒ…æ‹¬ReferenceNetå’ŒAnimateNetä¸¤éƒ¨åˆ†ã€‚ReferenceNetä¿ç•™äº†èº«ä»½å¹¶é€šè¿‡æ–‡æœ¬æç¤ºå®ç°äº†ç²¾ç»†çš„é¢éƒ¨ç¼–è¾‘ï¼Œè€ŒAnimateNetåˆ™ä½¿ç”¨ç»“æ„åŒ–çš„è¿åŠ¨å…ˆéªŒå¢å¼ºäº†è¿åŠ¨çš„ä¸€è‡´æ€§ã€‚ä¸éœ€è¦å¤šå¼ å‚è€ƒå›¾åƒæˆ–ç²¾ç»†è°ƒæ•´ä¹‹å‰çš„æ–¹æ³•ä¸åŒï¼ŒMAGIC-Talkèƒ½å¤Ÿä»å•å¼ å›¾åƒä¸­ä¿æŒèº«ä»½ï¼ŒåŒæ—¶ç¡®ä¿è·¨å¸§çš„å¹³æ»‘è¿‡æ¸¡ã€‚æ­¤å¤–ï¼Œè¿˜å¼•å…¥äº†ä¸€ç§æ¸è¿›å¼æ½œåœ¨èåˆç­–ç•¥ï¼Œé€šè¿‡å‡å°‘è¿åŠ¨ä¸ä¸€è‡´å’Œé—ªçƒæ¥æé«˜é•¿æ ¼å¼è§†é¢‘çš„è´¨é‡ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼Œåœ¨è§†è§‰è´¨é‡ã€èº«ä»½ä¿ç•™å’ŒåŒæ­¥å‡†ç¡®æ€§æ–¹é¢ï¼ŒMAGIC-Talkä¼˜äºæœ€æ–°æŠ€æœ¯æ–¹æ³•ï¼Œä¸ºè¯´è¯äººè„¸ç”Ÿæˆæä¾›äº†ç¨³å¥çš„è§£å†³æ–¹æ¡ˆã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.22810v1">PDF</a> </p>
<p><strong>Summary</strong><br>æ–°ä¸€ä»£éŸ³é¢‘é©±åŠ¨è¯´è¯äººè„¸ç”ŸæˆæŠ€æœ¯å·²ç»å¼•èµ·äº†æ•°å­—åª’ä½“å’Œè™šæ‹Ÿè§’è‰²çš„å…³æ³¨ã€‚ä¸ºäº†è§£å†³é•¿æœŸè§†é¢‘ç”Ÿæˆä¸­çš„æ—¶é—´ä¸€è‡´æ€§ã€èº«ä»½ä¿ç•™å’Œä¸ªæ€§åŒ–é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åŸºäºå•æ¬¡æ‰©æ•£çš„æ¡†æ¶MAGIC-Talkã€‚å®ƒåŒ…å«ReferenceNetå’ŒAnimateNetä¸¤éƒ¨åˆ†ï¼Œå‰è€…ä¿ç•™èº«ä»½å¹¶å…è®¸é€šè¿‡æ–‡æœ¬æç¤ºè¿›è¡Œç²¾ç»†é¢éƒ¨ç¼–è¾‘ï¼Œåè€…ä½¿ç”¨ç»“æ„è¿åŠ¨å…ˆéªŒå¢å¼ºè¿åŠ¨ä¸€è‡´æ€§ã€‚ä¸å…¶ä»–éœ€è¦å¤šå¼ å‚è€ƒå›¾åƒæˆ–ç²¾ç»†è°ƒæ•´çš„æ–¹æ³•ä¸åŒï¼ŒMAGIC-Talkèƒ½å¤Ÿä»å•å¼ å›¾åƒä¸­ä¿æŒèº«ä»½ï¼ŒåŒæ—¶ç¡®ä¿è·¨å¸§çš„å¹³æ»‘è¿‡æ¸¡ã€‚æ­¤å¤–ï¼Œå¼•å…¥äº†ä¸€ç§æ¸è¿›å¼æ½œåœ¨èåˆç­–ç•¥ï¼Œä»¥æé«˜é•¿è§†é¢‘çš„è´¨é‡ï¼Œå‡å°‘è¿åŠ¨ä¸ä¸€è‡´å’Œé—ªçƒç°è±¡ã€‚å¹¿æ³›çš„å®éªŒè¡¨æ˜ï¼ŒMAGIC-Talkåœ¨è§†è§‰è´¨é‡ã€èº«ä»½ä¿ç•™å’ŒåŒæ­¥ç²¾åº¦æ–¹é¢å‡ä¼˜äºå…¶ä»–æŠ€æœ¯çš„å‰æ²¿æŠ€æœ¯ï¼Œä¸ºè¯´è¯äººè„¸ç”Ÿæˆæä¾›äº†å¯é çš„è§£å†³æ–¹æ¡ˆã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>éŸ³é¢‘é©±åŠ¨è¯´è¯äººè„¸ç”ŸæˆæŠ€æœ¯åœ¨æ•°å­—åª’ä½“å’Œè™šæ‹Ÿè§’è‰²åº”ç”¨ä¸­è·å¾—å…³æ³¨ã€‚</li>
<li>MAGIC-Talkæ¡†æ¶è§£å†³æ—¶é—´ä¸€è‡´æ€§ã€èº«ä»½ä¿ç•™å’Œä¸ªæ€§åŒ–é—®é¢˜ã€‚</li>
<li>åŒ…å«ReferenceNetå’ŒAnimateNetä¸¤éƒ¨åˆ†ï¼Œåˆ†åˆ«è´Ÿè´£èº«ä»½ä¿ç•™å’Œè¿åŠ¨ä¸€è‡´æ€§å¢å¼ºã€‚</li>
<li>ä¸å…¶ä»–æ–¹æ³•ä¸åŒï¼ŒMAGIC-Talkèƒ½å¤Ÿä»å•å¼ å›¾åƒä¿æŒèº«ä»½å¹¶ä¿éšœè·¨å¸§å¹³æ»‘è¿‡æ¸¡ã€‚</li>
<li>å¼•å…¥æ¸è¿›å¼æ½œåœ¨èåˆç­–ç•¥ï¼Œæé«˜é•¿è§†é¢‘è´¨é‡ï¼Œå‡å°‘è¿åŠ¨ä¸ä¸€è‡´å’Œé—ªçƒã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.22810">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-4f114fac103d63cdb0c7175645188941~resize:0:q75.jpg?source=1f5c5e47&expiration=1762309376&auth_key=1762309376-0-0-ae6582bcb47e362b4fb9480bf3bc98e9&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-3a24b884afefde93c615ecd4d338944c~resize:0:q75.jpg?source=1f5c5e47&expiration=1762309384&auth_key=1762309384-0-0-0934b05255a544dba385690a6d80e07b&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-356157a279e65a49e97b8961f4134515~resize:0:q75.jpg?source=1f5c5e47&expiration=1762309391&auth_key=1762309391-0-0-bacfaa5e733b2355a10e09977b65d7ee&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-f6a6f7e2a8f28f8c316a15d573e38035~resize:0:q75.jpg?source=1f5c5e47&expiration=1762309398&auth_key=1762309398-0-0-16011f2e9afe08f5a3c4bb1fea366174&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="LSF-Animation-Label-Free-Speech-Driven-Facial-Animation-via-Implicit-Feature-Representation"><a href="#LSF-Animation-Label-Free-Speech-Driven-Facial-Animation-via-Implicit-Feature-Representation" class="headerlink" title="LSF-Animation: Label-Free Speech-Driven Facial Animation via Implicit   Feature Representation"></a>LSF-Animation: Label-Free Speech-Driven Facial Animation via Implicit   Feature Representation</h2><p><strong>Authors:Xin Lu, Chuanqing Zhuang, Chenxi Jin, Zhengda Lu, Yiqun Wang, Wu Liu, Jun Xiao</strong></p>
<p>Speech-driven 3D facial animation has attracted increasing interest since its potential to generate expressive and temporally synchronized digital humans. While recent works have begun to explore emotion-aware animation, they still depend on explicit one-hot encodings to represent identity and emotion with given emotion and identity labels, which limits their ability to generalize to unseen speakers. Moreover, the emotional cues inherently present in speech are often neglected, limiting the naturalness and adaptability of generated animations. In this work, we propose LSF-Animation, a novel framework that eliminates the reliance on explicit emotion and identity feature representations. Specifically, LSF-Animation implicitly extracts emotion information from speech and captures the identity features from a neutral facial mesh, enabling improved generalization to unseen speakers and emotional states without requiring manual labels. Furthermore, we introduce a Hierarchical Interaction Fusion Block (HIFB), which employs a fusion token to integrate dual transformer features and more effectively integrate emotional, motion-related and identity-related cues. Extensive experiments conducted on the 3DMEAD dataset demonstrate that our method surpasses recent state-of-the-art approaches in terms of emotional expressiveness, identity generalization, and animation realism. The source code will be released at: <a target="_blank" rel="noopener" href="https://github.com/Dogter521/LSF-Animation">https://github.com/Dogter521/LSF-Animation</a>. </p>
<blockquote>
<p>è¯­éŸ³é©±åŠ¨çš„3Dé¢éƒ¨åŠ¨ç”»å› å…¶ç”Ÿæˆè¡¨æƒ…ä¸°å¯Œã€æ—¶é—´åŒæ­¥çš„æ•°å­—äººç±»çš„å¯èƒ½æ€§è€Œè¶Šæ¥è¶Šå—åˆ°å…³æ³¨ã€‚å°½ç®¡è¿‘æœŸçš„ç ”ç©¶å¼€å§‹æ¢ç´¢æƒ…æ„Ÿæ„ŸçŸ¥åŠ¨ç”»ï¼Œä½†å®ƒä»¬ä»ç„¶ä¾èµ–äºæ˜ç¡®çš„ç‹¬çƒ­ç¼–ç æ¥è¡¨ç¤ºç»™å®šæƒ…æ„Ÿå’Œèº«ä»½æ ‡ç­¾çš„èº«ä»½å’Œæƒ…æ„Ÿï¼Œè¿™é™åˆ¶äº†å®ƒä»¬å¯¹æœªè§è¿‡çš„è¯´è¯è€…çš„æ³›åŒ–èƒ½åŠ›ã€‚æ­¤å¤–ï¼Œå¾€å¾€å¿½è§†äº†è¯­éŸ³ä¸­å›ºæœ‰çš„æƒ…æ„Ÿçº¿ç´¢ï¼Œé™åˆ¶äº†ç”ŸæˆåŠ¨ç”»çš„è‡ªç„¶æ€§å’Œé€‚åº”æ€§ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†LSF-Animationï¼Œä¸€ä¸ªæ¶ˆé™¤å¯¹æ˜ç¡®æƒ…æ„Ÿå’Œèº«ä»½ç‰¹å¾è¡¨ç¤ºä¾èµ–çš„æ–°å‹æ¡†æ¶ã€‚å…·ä½“æ¥è¯´ï¼ŒLSF-Animationä»è¯­éŸ³ä¸­éšå¼æå–æƒ…æ„Ÿä¿¡æ¯ï¼Œä»ä¸­æ€§é¢éƒ¨ç½‘æ ¼ä¸­æ•è·èº«ä»½ç‰¹å¾ï¼Œæ”¹è¿›äº†å¯¹æœªè§è¿‡çš„è¯´è¯è€…å’Œæƒ…æ„ŸçŠ¶æ€çš„æ³›åŒ–èƒ½åŠ›ï¼Œæ— éœ€æ‰‹åŠ¨æ ‡ç­¾ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å¼•å…¥äº†åˆ†å±‚äº¤äº’èåˆå—ï¼ˆHIFBï¼‰ï¼Œå®ƒä½¿ç”¨èåˆä»¤ç‰Œæ¥é›†æˆåŒé‡è½¬æ¢å™¨ç‰¹å¾ï¼Œæ›´æœ‰æ•ˆåœ°æ•´åˆæƒ…æ„Ÿã€è¿åŠ¨ç›¸å…³å’Œèº«ä»½ç›¸å…³çš„çº¿ç´¢ã€‚åœ¨3DMEADæ•°æ®é›†ä¸Šè¿›è¡Œçš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨æƒ…æ„Ÿè¡¨è¾¾ã€èº«ä»½æ³›åŒ–å’ŒåŠ¨ç”»é€¼çœŸåº¦æ–¹é¢è¶…è¿‡äº†æœ€è¿‘çš„æœ€å…ˆè¿›æ–¹æ³•ã€‚æºä»£ç å°†åœ¨<a target="_blank" rel="noopener" href="https://github.com/Dogter521/LSF-Animation%E4%B8%8A%E5%8F%91%E5%B8%83%E3%80%82">https://github.com/Dogter521/LSF-Animationä¸Šå‘å¸ƒã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.21864v1">PDF</a> </p>
<p><strong>Summary</strong>ï¼š</p>
<p>æå‡ºäº†ä¸€ç§åä¸ºLSF-Animationçš„æ–°å‹æ¡†æ¶ï¼Œè¯¥æ¡†æ¶èƒ½å¤Ÿä»è¯­éŸ³ä¸­éšå¼æå–æƒ…æ„Ÿä¿¡æ¯ï¼Œå¹¶ä»ä¸­æ€§é¢éƒ¨ç½‘æ ¼ä¸­æ•è·èº«ä»½ä¿¡æ¯ï¼Œæé«˜äº†å¯¹æœªè§è¯´è¯è€…å’Œæƒ…æ„ŸçŠ¶æ€çš„æ³›åŒ–èƒ½åŠ›ï¼Œæ— éœ€æ‰‹åŠ¨æ ‡ç­¾ã€‚å¼•å…¥åˆ†å±‚äº¤äº’èåˆå—ï¼ˆHIFBï¼‰ï¼Œæœ‰æ•ˆæ•´åˆæƒ…æ„Ÿã€è¿åŠ¨ç›¸å…³å’Œèº«ä»½ç›¸å…³çº¿ç´¢ã€‚åœ¨3DMEADæ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨æƒ…æ„Ÿè¡¨è¾¾ã€èº«ä»½æ³›åŒ–å’ŒåŠ¨ç”»çœŸå®æ€§æ–¹é¢è¶…è¶Šäº†æœ€æ–°çš„å…ˆè¿›æŠ€æœ¯ã€‚</p>
<p><strong>Key Takeaways</strong>ï¼š</p>
<ol>
<li>LSF-Animationæ¡†æ¶å¯ä»¥éšå¼åœ°ä»è¯­éŸ³ä¸­æå–æƒ…æ„Ÿä¿¡æ¯ï¼Œå¹¶æ•è·èº«ä»½ä¿¡æ¯ã€‚</li>
<li>è¯¥æ¡†æ¶æé«˜äº†å¯¹æœªè§è¯´è¯è€…å’Œæƒ…æ„ŸçŠ¶æ€çš„æ³›åŒ–èƒ½åŠ›ã€‚</li>
<li>LSF-Animationä¸éœ€è¦æ‰‹åŠ¨æ ‡ç­¾ã€‚</li>
<li>å¼•å…¥äº†ä¸€ç§æ–°å‹ç»“æ„â€”â€”åˆ†å±‚äº¤äº’èåˆå—ï¼ˆHIFBï¼‰ã€‚</li>
<li>HIFBèƒ½æœ‰æ•ˆæ•´åˆæƒ…æ„Ÿã€è¿åŠ¨ç›¸å…³å’Œèº«ä»½ç›¸å…³çº¿ç´¢ã€‚</li>
<li>åœ¨3DMEADæ•°æ®é›†ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼ŒLSF-Animationåœ¨æƒ…æ„Ÿè¡¨è¾¾ã€èº«ä»½æ³›åŒ–å’ŒåŠ¨ç”»çœŸå®æ€§æ–¹é¢è¡¨ç°ä¼˜å¼‚ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.21864">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-772751a2607c7c42882745f6edc27114~resize:0:q75.jpg?source=1f5c5e47&expiration=1762309406&auth_key=1762309406-0-0-6614bdb473a46bbaaaea2f60dc8163fc&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-002b2ecc7026ea97da9c9aa9c0ec2a92~resize:0:q75.jpg?source=1f5c5e47&expiration=1762309413&auth_key=1762309413-0-0-f88792d2a6072d5728543c4a61bd1a22&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-9b098f80a89eef0d43cf984ae57b8ddc~resize:0:q75.jpg?source=1f5c5e47&expiration=1762309420&auth_key=1762309420-0-0-9f93d49dff2af3c337c5ca768e75273a&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-49b96fe50c4b0fa7861103585d692e99~resize:0:q75.jpg?source=1f5c5e47&expiration=1762309427&auth_key=1762309427-0-0-8345b2ebbe5af2f337dba3cddd723df5&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="Unmasking-Puppeteers-Leveraging-Biometric-Leakage-to-Disarm-Impersonation-in-AI-based-Videoconferencing"><a href="#Unmasking-Puppeteers-Leveraging-Biometric-Leakage-to-Disarm-Impersonation-in-AI-based-Videoconferencing" class="headerlink" title="Unmasking Puppeteers: Leveraging Biometric Leakage to Disarm   Impersonation in AI-based Videoconferencing"></a>Unmasking Puppeteers: Leveraging Biometric Leakage to Disarm   Impersonation in AI-based Videoconferencing</h2><p><strong>Authors:Danial Samadi Vahdati, Tai Duc Nguyen, Ekta Prashnani, Koki Nagano, David Luebke, Orazio Gallo, Matthew Stamm</strong></p>
<p>AI-based talking-head videoconferencing systems reduce bandwidth by sending a compact pose-expression latent and re-synthesizing RGB at the receiver, but this latent can be puppeteered, letting an attacker hijack a victimâ€™s likeness in real time. Because every frame is synthetic, deepfake and synthetic video detectors fail outright. To address this security problem, we exploit a key observation: the pose-expression latent inherently contains biometric information of the driving identity. Therefore, we introduce the first biometric leakage defense without ever looking at the reconstructed RGB video: a pose-conditioned, large-margin contrastive encoder that isolates persistent identity cues inside the transmitted latent while cancelling transient pose and expression. A simple cosine test on this disentangled embedding flags illicit identity swaps as the video is rendered. Our experiments on multiple talking-head generation models show that our method consistently outperforms existing puppeteering defenses, operates in real-time, and shows strong generalization to out-of-distribution scenarios. </p>
<blockquote>
<p>åŸºäºAIçš„è¯­éŸ³å¤´éƒ¨è§†é¢‘ä¼šè®®ç³»ç»Ÿé€šè¿‡å‘é€ç´§å‡‘çš„å§¿æ€è¡¨è¾¾æ½œåƒå¹¶åœ¨æ¥æ”¶å™¨å¤„é‡æ–°åˆæˆRGBæ¥å‡å°‘å¸¦å®½ï¼Œä½†è¿™ä¸€æ½œåƒå¯ä»¥è¢«æ“çºµï¼Œä½¿å¾—æ”»å‡»è€…èƒ½å¤Ÿå®æ—¶åŠ«æŒå—å®³è€…çš„å¤–è²Œã€‚ç”±äºæ¯ä¸€å¸§éƒ½æ˜¯åˆæˆçš„ï¼Œæ·±åº¦ä¼ªé€ å’Œåˆæˆè§†é¢‘æ£€æµ‹å™¨ä¼šå®Œå…¨å¤±æ•ˆã€‚ä¸ºäº†è§£å†³è¿™ä¸€å®‰å…¨é—®é¢˜ï¼Œæˆ‘ä»¬åˆ©ç”¨äº†ä¸€ä¸ªå…³é”®è§‚å¯Ÿç»“æœï¼šå§¿æ€è¡¨è¾¾æ½œåƒæœ¬èº«åŒ…å«é©±åŠ¨èº«ä»½çš„ç”Ÿç‰©è¯†åˆ«ä¿¡æ¯ã€‚å› æ­¤ï¼Œæˆ‘ä»¬å¼•å…¥äº†ç¬¬ä¸€ä¸ªæ— éœ€æŸ¥çœ‹é‡å»ºçš„RGBè§†é¢‘çš„ç”Ÿç‰©æ³„éœ²é˜²å¾¡ï¼šä¸€ä¸ªåŸºäºå§¿æ€æ¡ä»¶çš„ã€å…·æœ‰è¾ƒå¤§è¾¹ç•Œçš„å¯¹æ¯”ç¼–ç å™¨ï¼Œå®ƒèƒ½åœ¨ä¼ è¾“çš„æ½œåƒä¸­éš”ç¦»æŒä¹…çš„èº«ä»½çº¿ç´¢ï¼ŒåŒæ—¶å–æ¶ˆçŸ­æš‚çš„å§¿æ€å’Œè¡¨æƒ…ã€‚åœ¨è¿™ä¸ªåˆ†ç¦»åµŒå…¥ç‰©ä¸Šè¿›è¡Œç®€å•çš„ä½™å¼¦æµ‹è¯•å¯ä»¥åœ¨è§†é¢‘æ¸²æŸ“æ—¶æ ‡è®°å‡ºéæ³•èº«ä»½äº¤æ¢ã€‚æˆ‘ä»¬åœ¨å¤šä¸ªè¯­éŸ³å¤´éƒ¨ç”Ÿæˆæ¨¡å‹ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•å§‹ç»ˆä¼˜äºç°æœ‰çš„æ“çºµé˜²å¾¡æŠ€æœ¯ï¼Œå¯å®æ—¶æ“ä½œï¼Œå¯¹è¶…å‡ºåˆ†å¸ƒèŒƒå›´çš„åœºæ™¯å…·æœ‰å¾ˆå¼ºçš„é€šç”¨æ€§ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.03548v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>åŸºäºAIçš„è¯´è¯äººå¤´è§†é¢‘ä¼šè®®ç³»ç»Ÿé€šè¿‡å‘é€ç´§å‡‘çš„å§¿æ€è¡¨è¾¾æ½œåƒå¹¶åœ¨æ¥æ”¶å™¨ç«¯é‡æ–°åˆæˆRGBæ¥å‡å°‘å¸¦å®½ï¼Œä½†è¿™ä¸€æ½œåƒå¯ä»¥è¢«æ“çºµï¼Œä½¿æ”»å‡»è€…èƒ½å¤Ÿåœ¨å®æ—¶ä¸­åŠ«æŒå—å®³è€…çš„è‚–åƒã€‚ç”±äºæ¯ä¸€å¸§éƒ½æ˜¯åˆæˆçš„ï¼Œå› æ­¤æ·±åº¦ä¼ªé€ å’Œåˆæˆè§†é¢‘æ£€æµ‹å™¨ç›´æ¥å¤±æ•ˆã€‚ä¸ºè§£å†³è¿™ä¸€å®‰å…¨é—®é¢˜ï¼Œæˆ‘ä»¬è§‚å¯Ÿåˆ°å§¿æ€è¡¨è¾¾æ½œåƒæœ¬èº«å°±å«æœ‰é©±åŠ¨èº«ä»½çš„ç”Ÿç‰©è¯†åˆ«ä¿¡æ¯ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°çš„é˜²å¾¡æ–¹æ³•ï¼Œå³åœ¨ä¸æŸ¥çœ‹é‡å»ºçš„RGBè§†é¢‘çš„æƒ…å†µä¸‹ï¼Œåˆ©ç”¨å§¿æ€è°ƒèŠ‚çš„å¤§è¾¹è·å¯¹æ¯”ç¼–ç å™¨æ¥éš”ç¦»ä¼ è¾“æ½œåƒä¸­çš„æŒä¹…èº«ä»½çº¿ç´¢ï¼ŒåŒæ—¶å–æ¶ˆçŸ­æš‚çš„å§¿æ€å’Œè¡¨æƒ…ã€‚åœ¨è¿™ä¸ªåˆ†è§£åµŒå…¥çš„åŸºç¡€ä¸Šè¿›è¡Œçš„ç®€å•ä½™å¼¦æµ‹è¯•èƒ½å¤Ÿåœ¨è§†é¢‘æ¸²æŸ“è¿‡ç¨‹ä¸­æ£€æµ‹å‡ºèº«ä»½çš„ä¸æ­£å½“æ›¿æ¢ã€‚åœ¨å¤šä¸ªè¯´è¯äººå¤´ç”Ÿæˆæ¨¡å‹ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•ä¸€è‡´ä¼˜äºç°æœ‰çš„æ“çºµé˜²å¾¡æ–¹æ³•ï¼Œå¯å®ç°å®æ—¶æ“ä½œï¼Œå¯¹è¶…å‡ºåˆ†å¸ƒèŒƒå›´çš„åœºæ™¯è¡¨ç°å‡ºå¼ºå¤§çš„æ³›åŒ–èƒ½åŠ›ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>AIè°ˆè¯å¤´è§†é¢‘ä¼šè®®ç³»ç»Ÿå¯å‡å°‘å¸¦å®½ä½¿ç”¨ï¼Œä½†æ½œåƒè¢«æ“çºµçš„é£é™©å­˜åœ¨ã€‚</li>
<li>åˆæˆè§†é¢‘çš„å¹¿æ³›é‡‡ç”¨ä½¿å¾—ä¼ ç»Ÿæ·±åº¦ä¼ªé€ å’Œåˆæˆè§†é¢‘æ£€æµ‹å™¨å¤±æ•ˆã€‚</li>
<li>å§¿æ€è¡¨è¾¾æ½œåƒåŒ…å«ç”Ÿç‰©è¯†åˆ«ä¿¡æ¯ï¼Œå¯ç”¨äºé˜²å¾¡æŠ€æœ¯ã€‚</li>
<li>æå‡ºäº†ä¸€ç§æ–°çš„é˜²å¾¡ç­–ç•¥ï¼Œé€šè¿‡å§¿æ€è°ƒèŠ‚çš„å¤§è¾¹è·å¯¹æ¯”ç¼–ç å™¨æ¥è¯†åˆ«èº«ä»½ä¸å½“æ›¿æ¢ã€‚</li>
<li>æ–¹æ³•åœ¨ä¸æŸ¥çœ‹é‡å»ºçš„RGBè§†é¢‘çš„æƒ…å†µä¸‹å·¥ä½œï¼Œå…·æœ‰å®æ—¶æ“ä½œçš„èƒ½åŠ›ã€‚</li>
<li>è¯¥æ–¹æ³•åœ¨ä¸åŒçš„æ¨¡å‹å’Œåœºæ™¯ä¸­è¡¨ç°å‡ºä¼˜è¶Šçš„æ€§èƒ½å’Œæ³›åŒ–èƒ½åŠ›ã€‚</li>
<li>æ­¤æŠ€æœ¯å¯¹äºä¿æŠ¤è™šæ‹Ÿä¼šè®®å’Œåœ¨çº¿äº¤æµä¸­çš„èº«ä»½å®‰å…¨æ€§å…·æœ‰é‡è¦æ„ä¹‰ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.03548">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-48562df7fc030eebc5581a93cf07c404~resize:0:q75.jpg?source=1f5c5e47&expiration=1762309434&auth_key=1762309434-0-0-e5edba52c3664235225117d72351dd7b&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-efb8fac75d807eaf0f619a9101b68e1d~resize:0:q75.jpg?source=1f5c5e47&expiration=1762309441&auth_key=1762309441-0-0-d75d3eaf0e7c577f43a5611466eba0e2&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-c2c13d6e2ac68bd8272a19c2496c8eac~resize:0:q75.jpg?source=1f5c5e47&expiration=1762309448&auth_key=1762309448-0-0-d7d5a0208d9d63dcf9fe3611a17a95e8&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-95c9e61a53d54efcd356e4c879493300~resize:0:q75.jpg?source=1f5c5e47&expiration=1762309456&auth_key=1762309456-0-0-69d8da3a3f3b28bb384c23d1bef18543&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="Audio-Driven-Real-Time-Facial-Animation-for-Social-Telepresence"><a href="#Audio-Driven-Real-Time-Facial-Animation-for-Social-Telepresence" class="headerlink" title="Audio Driven Real-Time Facial Animation for Social Telepresence"></a>Audio Driven Real-Time Facial Animation for Social Telepresence</h2><p><strong>Authors:Jiye Lee, Chenghui Li, Linh Tran, Shih-En Wei, Jason Saragih, Alexander Richard, Hanbyul Joo, Shaojie Bai</strong></p>
<p>We present an audio-driven real-time system for animating photorealistic 3D facial avatars with minimal latency, designed for social interactions in virtual reality for anyone. Central to our approach is an encoder model that transforms audio signals into latent facial expression sequences in real time, which are then decoded as photorealistic 3D facial avatars. Leveraging the generative capabilities of diffusion models, we capture the rich spectrum of facial expressions necessary for natural communication while achieving real-time performance (&lt;15ms GPU time). Our novel architecture minimizes latency through two key innovations: an online transformer that eliminates dependency on future inputs and a distillation pipeline that accelerates iterative denoising into a single step. We further address critical design challenges in live scenarios for processing continuous audio signals frame-by-frame while maintaining consistent animation quality. The versatility of our framework extends to multimodal applications, including semantic modalities such as emotion conditions and multimodal sensors with head-mounted eye cameras on VR headsets. Experimental results demonstrate significant improvements in facial animation accuracy over existing offline state-of-the-art baselines, achieving 100 to 1000 times faster inference speed. We validate our approach through live VR demonstrations and across various scenarios such as multilingual speeches. </p>
<blockquote>
<p>æˆ‘ä»¬æå‡ºäº†ä¸€ç§éŸ³é¢‘é©±åŠ¨çš„å®æ—¶ç³»ç»Ÿï¼Œç”¨äºé©±åŠ¨å…·æœ‰æä½å»¶è¿Ÿçš„å…‰ç…§çœŸå®3Dé¢éƒ¨åŒ–èº«åŠ¨ç”»ï¼Œä¸“ä¸ºè™šæ‹Ÿç°å®ä¸­çš„ç¤¾äº¤äº’åŠ¨è®¾è®¡ï¼Œé€‚ç”¨äºä»»ä½•äººã€‚æˆ‘ä»¬çš„æ–¹æ³•çš„æ ¸å¿ƒæ˜¯ä¸€ä¸ªç¼–ç å™¨æ¨¡å‹ï¼Œå®ƒå°†éŸ³é¢‘ä¿¡å·å®æ—¶è½¬æ¢ä¸ºæ½œåœ¨çš„é¢éƒ¨è¡¨æƒ…åºåˆ—ï¼Œç„¶åè§£ç ä¸ºå…‰ç…§çœŸå®çš„3Dé¢éƒ¨åŒ–èº«ã€‚æˆ‘ä»¬åˆ©ç”¨æ‰©æ•£æ¨¡å‹çš„ç”Ÿæˆèƒ½åŠ›ï¼Œæ•æ‰è‡ªç„¶æ²Ÿé€šæ‰€éœ€çš„ä¸°å¯Œé¢éƒ¨è¡¨æƒ…è°±ï¼ŒåŒæ—¶å®ç°å®æ—¶æ€§èƒ½ï¼ˆ&lt;15æ¯«ç§’GPUæ—¶é—´ï¼‰ã€‚æˆ‘ä»¬çš„æ–°å‹æ¶æ„é€šè¿‡ä¸¤ä¸ªå…³é”®åˆ›æ–°æ¥æœ€å°åŒ–å»¶è¿Ÿï¼šä¸€ç§åœ¨çº¿å˜å‹å™¨ï¼Œæ¶ˆé™¤å¯¹æœªæ¥è¾“å…¥çš„ä¾èµ–ï¼›ä¸€ç§è’¸é¦ç®¡é“ï¼Œå°†è¿­ä»£å»å™ªåŠ é€Ÿä¸ºå•æ­¥å®Œæˆã€‚æˆ‘ä»¬è¿›ä¸€æ­¥è§£å†³äº†ç°åœºåœºæ™¯ä¸­å¤„ç†è¿ç»­éŸ³é¢‘ä¿¡å·çš„å…³é”®è®¾è®¡æŒ‘æˆ˜ï¼Œé€å¸§ä¿æŒä¸€è‡´çš„åŠ¨ç”»è´¨é‡ã€‚æˆ‘ä»¬æ¡†æ¶çš„é€šç”¨æ€§æ‰©å±•åˆ°å¤šæ¨¡å¼åº”ç”¨ï¼ŒåŒ…æ‹¬è¯­ä¹‰æ¨¡å¼ï¼Œå¦‚æƒ…ç»ªæ¡ä»¶å’Œå¸¦æœ‰å¤´æˆ´å¼çœ¼æ‘„åƒå¤´çš„VRå¤´ç›”çš„å¤šæ¨¡å¼ä¼ æ„Ÿå™¨ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œåœ¨é¢éƒ¨åŠ¨ç”»å‡†ç¡®æ€§æ–¹é¢ï¼Œæˆ‘ä»¬çš„æ–¹æ³•æ˜¾è‘—ä¼˜äºç°æœ‰çš„ç¦»çº¿æœ€å…ˆè¿›çš„åŸºçº¿ï¼Œæ¨ç†é€Ÿåº¦æé«˜100åˆ°1000å€ã€‚æˆ‘ä»¬é€šè¿‡ç°åœºVRæ¼”ç¤ºå’Œå¤šç§åœºæ™¯ï¼ˆå¦‚å¤šè¯­è¨€æ¼”è®²ï¼‰éªŒè¯äº†æˆ‘ä»¬çš„æ–¹æ³•ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.01176v2">PDF</a> SIGGRAPH Asia 2025. Project page:   <a target="_blank" rel="noopener" href="https://jiyewise.github.io/projects/AudioRTA">https://jiyewise.github.io/projects/AudioRTA</a></p>
<p><strong>Summary</strong></p>
<p>å®æ—¶éŸ³é¢‘é©±åŠ¨çš„å…‰ç…§ç°å®3Dé¢éƒ¨è§’è‰²åŠ¨ç”»ç³»ç»Ÿï¼Œä¸“ä¸ºè™šæ‹Ÿç°å®ç¤¾äº¤äº’åŠ¨è®¾è®¡ã€‚ç³»ç»Ÿé‡‡ç”¨ç¼–ç æ¨¡å‹å°†éŸ³é¢‘ä¿¡å·å®æ—¶è½¬æ¢ä¸ºæ½œåœ¨é¢éƒ¨è¡¨æƒ…åºåˆ—ï¼Œå†è§£ç ä¸ºå…‰ç…§ç°å®3Dé¢éƒ¨è§’è‰²ã€‚å€ŸåŠ©æ‰©æ•£æ¨¡å‹çš„ç”Ÿæˆèƒ½åŠ›ï¼Œç³»ç»Ÿèƒ½æ•æ‰ä¸°å¯Œçš„é¢éƒ¨è¡¨æƒ…ï¼Œå®ç°å®æ—¶æ€§èƒ½(&lt;15ms GPUæ—¶é—´)ã€‚ç³»ç»Ÿé€šè¿‡ä¸¤é¡¹å…³é”®åˆ›æ–°â€”â€”åœ¨çº¿å˜å‹å™¨å’Œè’¸é¦ç®¡é“ï¼Œæœ€å°åŒ–å»¶è¿Ÿã€‚åŒæ—¶ï¼Œç³»ç»Ÿå¤„ç†è¿ç»­éŸ³é¢‘ä¿¡å·æ—¶ï¼Œèƒ½é€å¸§ä¿æŒä¸€è‡´çš„åŠ¨ç”»è´¨é‡ï¼Œå¹¶æ‰©å±•åˆ°å¤šæ¨¡å¼åº”ç”¨ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å®æ—¶éŸ³é¢‘é©±åŠ¨çš„å…‰ç…§ç°å®3Dé¢éƒ¨è§’è‰²åŠ¨ç”»ç³»ç»Ÿä¸“ä¸ºè™šæ‹Ÿç°å®ç¤¾äº¤äº’åŠ¨è®¾è®¡ã€‚</li>
<li>ç³»ç»Ÿä½¿ç”¨ç¼–ç æ¨¡å‹å®æ—¶è½¬æ¢éŸ³é¢‘ä¿¡å·ä¸ºæ½œåœ¨é¢éƒ¨è¡¨æƒ…åºåˆ—ã€‚</li>
<li>å€ŸåŠ©æ‰©æ•£æ¨¡å‹ç”Ÿæˆèƒ½åŠ›ï¼Œç³»ç»Ÿèƒ½æ•æ‰ä¸°å¯Œçš„é¢éƒ¨è¡¨æƒ…å¹¶å®ç°å®æ—¶æ€§èƒ½ã€‚</li>
<li>ç³»ç»Ÿé€šè¿‡åœ¨çº¿å˜å‹å™¨å’Œè’¸é¦ç®¡é“ä¸¤é¡¹å…³é”®åˆ›æ–°æ¥æœ€å°åŒ–å»¶è¿Ÿã€‚</li>
<li>ç³»ç»Ÿé€å¸§å¤„ç†è¿ç»­éŸ³é¢‘ä¿¡å·ï¼Œä¿æŒä¸€è‡´çš„åŠ¨ç”»è´¨é‡ã€‚</li>
<li>ç³»ç»Ÿå…·æœ‰å¯æ‰©å±•æ€§ï¼Œæ”¯æŒå¤šæ¨¡å¼åº”ç”¨ï¼ŒåŒ…æ‹¬æƒ…æ„Ÿæ¡ä»¶å’Œå¤šæ¨¡æ€ä¼ æ„Ÿå™¨ç­‰ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.01176">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-04d55f6b0866196736698dd39708272c~resize:0:q75.jpg?source=1f5c5e47&expiration=1762309464&auth_key=1762309464-0-0-e253b0a3b0d07406bb2e6260fee2aa95&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-c7ef9389de8cd96fd29c6ffd9f4417cb~resize:0:q75.jpg?source=1f5c5e47&expiration=1762309471&auth_key=1762309471-0-0-aedd5de9d2c9b9d41a49be40ccf074b1&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-328debd438615282756fc04d9c3bea93~resize:0:q75.jpg?source=1f5c5e47&expiration=1762309478&auth_key=1762309478-0-0-f517c350ddc54504da68578cfcb15ecc&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-752f4312f804e9244a43e82ab6a22c15~resize:0:q75.jpg?source=1f5c5e47&expiration=1762309485&auth_key=1762309485-0-0-38026418613df65a2648809e99ad118b&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="HM-Talker-Hybrid-Motion-Modeling-for-High-Fidelity-Talking-Head-Synthesis"><a href="#HM-Talker-Hybrid-Motion-Modeling-for-High-Fidelity-Talking-Head-Synthesis" class="headerlink" title="HM-Talker: Hybrid Motion Modeling for High-Fidelity Talking Head   Synthesis"></a>HM-Talker: Hybrid Motion Modeling for High-Fidelity Talking Head   Synthesis</h2><p><strong>Authors:Shiyu Liu, Kui Jiang, Xianming Liu, Hongxun Yao, Xiaocheng Feng</strong></p>
<p>Audio-driven talking head video generation enhances user engagement in human-computer interaction. However, current methods frequently produce videos with motion blur and lip jitter, primarily due to their reliance on implicit modeling of audio-facial motion correlationsâ€“an approach lacking explicit articulatory priors (i.e., anatomical guidance for speech-related facial movements). To overcome this limitation, we propose HM-Talker, a novel framework for generating high-fidelity, temporally coherent talking heads. HM-Talker leverages a hybrid motion representation combining both implicit and explicit motion cues. Explicit cues use Action Units (AUs), anatomically defined facial muscle movements, alongside implicit features to minimize phoneme-viseme misalignment. Specifically, our Cross-Modal Disentanglement Module (CMDM) extracts complementary implicit&#x2F;explicit motion features while predicting AUs directly from audio input aligned to visual cues. To mitigate identity-dependent biases in explicit features and enhance cross-subject generalization, we introduce the Hybrid Motion Modeling Module (HMMM). This module dynamically merges randomly paired implicit&#x2F;explicit features, enforcing identity-agnostic learning. Together, these components enable robust lip synchronization across diverse identities, advancing personalized talking head synthesis. Extensive experiments demonstrate HM-Talkerâ€™s superiority over state-of-the-art methods in visual quality and lip-sync accuracy. </p>
<blockquote>
<p>éŸ³é¢‘é©±åŠ¨çš„è¯´è¯äººå¤´éƒ¨è§†é¢‘ç”Ÿæˆæé«˜äº†äººæœºäº¤äº’ä¸­çš„ç”¨æˆ·å‚ä¸åº¦ã€‚ç„¶è€Œï¼Œå½“å‰çš„æ–¹æ³•ç»å¸¸äº§ç”Ÿè¿åŠ¨æ¨¡ç³Šå’Œå˜´å”‡æŠ–åŠ¨ç­‰é—®é¢˜çš„è§†é¢‘ï¼Œè¿™ä¸»è¦æ˜¯å› ä¸ºå®ƒä»¬ä¾èµ–äºéŸ³é¢‘é¢éƒ¨è¿åŠ¨ä¹‹é—´çš„éšæ€§å»ºæ¨¡å…³è”â€”â€”ä¸€ç§ç¼ºä¹æ˜ç¡®çš„å‘éŸ³å…ˆéªŒçŸ¥è¯†ï¼ˆå³ä¸è¯­éŸ³ç›¸å…³çš„é¢éƒ¨è¿åŠ¨çš„è§£å‰–æŒ‡å¯¼ï¼‰çš„æ–¹æ³•ã€‚ä¸ºäº†å…‹æœè¿™ä¸€å±€é™æ€§ï¼Œæˆ‘ä»¬æå‡ºäº†HM-Talkerï¼Œè¿™æ˜¯ä¸€ä¸ªç”¨äºç”Ÿæˆé«˜ä¿çœŸã€æ—¶é—´ä¸Šè¿è´¯çš„è¯´è¯äººå¤´éƒ¨çš„å…¨æ–°æ¡†æ¶ã€‚HM-Talkeråˆ©ç”¨äº†ä¸€ç§æ··åˆè¿åŠ¨è¡¨ç¤ºæ³•ï¼Œç»“åˆäº†éšæ€§å’Œæ˜¾æ€§è¿åŠ¨çº¿ç´¢ã€‚æ˜¾æ€§çº¿ç´¢ä½¿ç”¨é¢éƒ¨è‚Œè‚‰è¿åŠ¨çš„åŠ¨ä½œå•ä½ï¼ˆAUsï¼‰ï¼Œä¸éšæ€§ç‰¹å¾ç›¸ç»“åˆï¼Œä»¥æœ€å°åŒ–éŸ³ç´ -å¯è§è¯­ç´ é”™ä½ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬çš„è·¨æ¨¡æ€åˆ†ç¦»æ¨¡å—ï¼ˆCMDMï¼‰åœ¨é¢„æµ‹ä¸è§†è§‰çº¿ç´¢å¯¹é½çš„éŸ³é¢‘è¾“å…¥çš„ç›´æ¥AUæ—¶ï¼Œæå–äº†äº’è¡¥çš„éšå¼&#x2F;æ˜¾å¼è¿åŠ¨ç‰¹å¾ã€‚ä¸ºäº†å‡è½»æ˜¾æ€§ç‰¹å¾ä¸­çš„èº«ä»½ç›¸å…³åè§å¹¶å¢å¼ºè·¨ä¸»ä½“æ³›åŒ–èƒ½åŠ›ï¼Œæˆ‘ä»¬å¼•å…¥äº†æ··åˆè¿åŠ¨å»ºæ¨¡æ¨¡å—ï¼ˆHMMMï¼‰ã€‚è¯¥æ¨¡å—åŠ¨æ€åœ°åˆå¹¶éšæœºé…å¯¹çš„éšå¼&#x2F;æ˜¾å¼ç‰¹å¾ï¼Œå¼ºåˆ¶å®æ–½èº«ä»½æ— å…³çš„å­¦ä¹ ã€‚è¿™äº›ç»„ä»¶å…±åŒä½œç”¨ï¼Œå®ç°äº†è·¨ä¸åŒèº«ä»½çš„ç¨³å¥å˜´å”‡åŒæ­¥ï¼Œæ¨åŠ¨äº†ä¸ªæ€§åŒ–è¯´è¯å¤´éƒ¨åˆæˆçš„è¿›æ­¥ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼ŒHM-Talkeråœ¨è§†è§‰è´¨é‡å’Œå˜´å”‡åŒæ­¥å‡†ç¡®æ€§æ–¹é¢ä¼˜äºæœ€å…ˆè¿›çš„æ–¹æ³•ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.10566v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºä¸€ç§åä¸ºHM-Talkerçš„æ–°å‹æ¡†æ¶ï¼Œç”¨äºç”Ÿæˆé«˜ä¿çœŸã€æ—¶é—´è¿è´¯çš„è°ˆè¯å¤´éƒ¨è§†é¢‘ã€‚HM-Talkerç»“åˆäº†éšå¼å’Œæ˜¾å¼è¿åŠ¨çº¿ç´¢çš„æ··åˆè¿åŠ¨è¡¨ç¤ºï¼Œä½¿ç”¨åŠ¨ä½œå•å…ƒï¼ˆAUsï¼‰ç­‰é¢éƒ¨è‚Œè‚‰è¿åŠ¨çš„è§£å‰–å®šä¹‰ï¼Œä¸éšå¼ç‰¹å¾ç›¸ç»“åˆï¼Œä»¥æœ€å°åŒ–éŸ³ç´ ä¸é¢éƒ¨è¡¨æƒ…çš„ä¸å¯¹é½ã€‚æ­¤å¤–ï¼Œæœ¬æ–‡ä»‹ç»äº†è·¨æ¨¡æ€å»æ¨¡å—åŒ–å’Œæ··åˆè¿åŠ¨å»ºæ¨¡æ¨¡å—ï¼Œåˆ†åˆ«è§£å†³äº†éšå¼ç‰¹å¾ä¸éŸ³é¢‘ä¹‹é—´çš„ä¸åŒ¹é…é—®é¢˜ä»¥åŠè·¨ä¸»ä½“èº«ä»½è¯†åˆ«çš„åè§é—®é¢˜ã€‚å®éªŒè¯æ˜ï¼ŒHM-Talkeråœ¨è§†è§‰è´¨é‡å’Œå”‡åŒæ­¥å‡†ç¡®æ€§æ–¹é¢ä¼˜äºç°æœ‰æŠ€æœ¯ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>HM-Talkeræ¡†æ¶è¢«æå‡ºç”¨äºç”Ÿæˆé«˜ä¿çœŸã€æ—¶é—´è¿è´¯çš„è°ˆè¯å¤´éƒ¨è§†é¢‘ï¼Œå…‹æœäº†ç°æœ‰æ–¹æ³•äº§ç”Ÿçš„è¿åŠ¨æ¨¡ç³Šå’Œå”‡éƒ¨æŠ–åŠ¨çš„é—®é¢˜ã€‚</li>
<li>è¯¥æ¡†æ¶ç»“åˆäº†éšå¼å’Œæ˜¾å¼è¿åŠ¨çº¿ç´¢çš„æ··åˆè¿åŠ¨è¡¨ç¤ºï¼Œä»¥æé«˜è§†é¢‘è´¨é‡ã€‚</li>
<li>ä½¿ç”¨åŠ¨ä½œå•å…ƒï¼ˆAUsï¼‰ç­‰é¢éƒ¨è‚Œè‚‰è¿åŠ¨çš„è§£å‰–å®šä¹‰ï¼Œä¸éšå¼ç‰¹å¾ç›¸ç»“åˆï¼Œå®ç°æ›´å‡†ç¡®çš„è¯­éŸ³ä¸é¢éƒ¨è¡¨æƒ…çš„åŒ¹é…ã€‚</li>
<li>Cross-Modal Disentanglement Moduleï¼ˆCMDMï¼‰èƒ½å¤Ÿæå–éšå¼å’Œæ˜¾å¼è¿åŠ¨ç‰¹å¾çš„äº’è¡¥ä¿¡æ¯ï¼Œå¹¶é¢„æµ‹ä¸è§†è§‰çº¿ç´¢å¯¹é½çš„éŸ³é¢‘è¾“å…¥çš„AUsã€‚</li>
<li>Hybrid Motion Modeling Moduleï¼ˆHMMMï¼‰è§£å†³äº†æ˜¾å¼ç‰¹å¾çš„ä¸»ä½“ä¾èµ–åè§é—®é¢˜ï¼Œå¢å¼ºäº†è·¨ä¸»ä½“æ³›åŒ–èƒ½åŠ›ã€‚</li>
<li>é€šè¿‡åŠ¨æ€èåˆéšæœºé…å¯¹çš„éšå¼å’Œæ˜¾å¼ç‰¹å¾ï¼Œå®ç°èº«ä»½æ— å…³çš„å­¦ä¹ ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.10566">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-ca59ea4c6cec848c51ba9e0202a6f93d~resize:0:q75.jpg?source=1f5c5e47&expiration=1762309492&auth_key=1762309492-0-0-c2bbd45ea5d9bd2c01b5b2b8a584e49e&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-40ba1f350c6a5ffe7bc08e3f4e2e2217~resize:0:q75.jpg?source=1f5c5e47&expiration=1762309499&auth_key=1762309499-0-0-d49193e5af755a89b0fe4691625bcb2a&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-63ac38f4ef71ce02b0f52513267ddb22~resize:0:q75.jpg?source=1f5c5e47&expiration=1762309506&auth_key=1762309506-0-0-1ea42a48ca08b5720086fff02a5c488d&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-89c0fba6949d44d082d9bd511e4d327c~resize:0:q75.jpg?source=1f5c5e47&expiration=1762309514&auth_key=1762309514-0-0-6e5ad4b7fab65bb466695542a5a3dad1&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-c7f0a8842fca7a54c0a776066ddaef55~resize:0:q75.jpg?source=1f5c5e47&expiration=1762309520&auth_key=1762309520-0-0-b13d6c46b26b16401510c69152d19c44&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="MOSPA-Human-Motion-Generation-Driven-by-Spatial-Audio"><a href="#MOSPA-Human-Motion-Generation-Driven-by-Spatial-Audio" class="headerlink" title="MOSPA: Human Motion Generation Driven by Spatial Audio"></a>MOSPA: Human Motion Generation Driven by Spatial Audio</h2><p><strong>Authors:Shuyang Xu, Zhiyang Dou, Mingyi Shi, Liang Pan, Leo Ho, Jingbo Wang, Yuan Liu, Cheng Lin, Yuexin Ma, Wenping Wang, Taku Komura</strong></p>
<p>Enabling virtual humans to dynamically and realistically respond to diverse auditory stimuli remains a key challenge in character animation, demanding the integration of perceptual modeling and motion synthesis. Despite its significance, this task remains largely unexplored. Most previous works have primarily focused on mapping modalities like speech, audio, and music to generate human motion. As of yet, these models typically overlook the impact of spatial features encoded in spatial audio signals on human motion. To bridge this gap and enable high-quality modeling of human movements in response to spatial audio, we introduce the first comprehensive Spatial Audio-Driven Human Motion (SAM) dataset, which contains diverse and high-quality spatial audio and motion data. For benchmarking, we develop a simple yet effective diffusion-based generative framework for human MOtion generation driven by SPatial Audio, termed MOSPA, which faithfully captures the relationship between body motion and spatial audio through an effective fusion mechanism. Once trained, MOSPA can generate diverse, realistic human motions conditioned on varying spatial audio inputs. We perform a thorough investigation of the proposed dataset and conduct extensive experiments for benchmarking, where our method achieves state-of-the-art performance on this task. Our code and model are publicly available at <a target="_blank" rel="noopener" href="https://github.com/xsy27/Mospa-Acoustic-driven-Motion-Generation">https://github.com/xsy27/Mospa-Acoustic-driven-Motion-Generation</a> </p>
<blockquote>
<p>å®ç°è™šæ‹Ÿäººç‰©å¯¹å¤šç§å¬è§‰åˆºæ¿€çš„åŠ¨æ€çœŸå®ååº”åœ¨è§’è‰²åŠ¨ç”»ä¸­ä»ç„¶æ˜¯ä¸€ä¸ªå…³é”®æŒ‘æˆ˜ï¼Œè¿™éœ€è¦æ„ŸçŸ¥å»ºæ¨¡å’Œè¿åŠ¨åˆæˆçš„é›†æˆã€‚å°½ç®¡è¿™ä¸€ä»»åŠ¡å…·æœ‰é‡è¦æ„ä¹‰ï¼Œä½†è¿„ä»Šä¸ºæ­¢ä»é²œæœ‰ç ”ç©¶ã€‚ä»¥å‰çš„å¤§å¤šæ•°å·¥ä½œä¸»è¦é›†ä¸­åœ¨å°†è¯­éŸ³ã€éŸ³é¢‘å’ŒéŸ³ä¹ç­‰æ˜ å°„æ¨¡å¼æ˜ å°„åˆ°äººç±»è¿åŠ¨ç”Ÿæˆä¸Šã€‚ç„¶è€Œï¼Œè¿™äº›æ¨¡å‹é€šå¸¸å¿½è§†äº†ç©ºé—´éŸ³é¢‘ä¿¡å·ç¼–ç çš„ç©ºé—´ç‰¹å¾å¯¹äººç±»è¿åŠ¨çš„å½±å“ã€‚ä¸ºäº†å¡«è¡¥è¿™ä¸€ç©ºç™½ï¼Œå®ç°å¯¹ç©ºé—´éŸ³é¢‘å“åº”ä¸‹çš„äººç±»è¿åŠ¨é«˜è´¨é‡å»ºæ¨¡ï¼Œæˆ‘ä»¬é¦–æ¬¡æ¨å‡ºå…¨é¢çš„ç©ºé—´éŸ³é¢‘é©±åŠ¨äººç±»è¿åŠ¨ï¼ˆSAMï¼‰æ•°æ®é›†ï¼Œå…¶ä¸­åŒ…å«å¤šæ ·ä¸”é«˜è´¨é‡çš„ç©ºé—´éŸ³é¢‘å’Œè¿åŠ¨æ•°æ®ã€‚ä¸ºäº†åŸºå‡†æµ‹è¯•ï¼Œæˆ‘ä»¬å¼€å‘äº†ä¸€ç§åŸºäºæ‰©æ•£çš„ç®€å•æœ‰æ•ˆçš„ç”Ÿæˆæ¡†æ¶ï¼Œç”¨äºç©ºé—´éŸ³é¢‘é©±åŠ¨çš„äººç±»è¿åŠ¨ç”Ÿæˆï¼Œè¢«ç§°ä¸ºMOSPAã€‚MOSPAé€šè¿‡æœ‰æ•ˆçš„èåˆæœºåˆ¶å¿ å®æ•æ‰èº«ä½“è¿åŠ¨å’Œç©ºé—´éŸ³é¢‘ä¹‹é—´çš„å…³ç³»ã€‚ä¸€æ—¦è®­ç»ƒå®Œæˆï¼ŒMOSPAå°±èƒ½å¤Ÿæ ¹æ®å„ç§ç©ºé—´éŸ³é¢‘è¾“å…¥ç”Ÿæˆå¤šæ ·ä¸”é€¼çœŸçš„è¿åŠ¨ã€‚æˆ‘ä»¬å¯¹æå‡ºçš„æ•°æ®é›†è¿›è¡Œäº†å…¨é¢è°ƒæŸ¥ï¼Œå¹¶è¿›è¡Œäº†å¹¿æ³›çš„åŸºå‡†æµ‹è¯•å®éªŒï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨è¿™ä¸€ä»»åŠ¡ä¸Šå–å¾—äº†æœ€å…ˆè¿›çš„æ€§èƒ½è¡¨ç°ã€‚æˆ‘ä»¬çš„ä»£ç å’Œæ¨¡å‹åœ¨<a target="_blank" rel="noopener" href="https://github.com/xsy27/Mospa-Acoustc-driven-Motion-Generation%E5%85%AC%E5%BC%80%E5%8F%AF%E7%94%A8%E3%80%82">https://github.com/xsy27/Mospa-Acoustc-driven-Motion-Generationå…¬å¼€å¯ç”¨ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2507.11949v2">PDF</a> NeurIPS 2025 (Spotlight)</p>
<p><strong>Summary</strong>:</p>
<p>è¯¥æ–‡æœ¬ä»‹ç»äº†ä¸€ç§åº”å¯¹è™šæ‹Ÿäººç‰©åŠ¨æ€çœŸå®ååº”å¤šç§å¬è§‰åˆºæ¿€çš„æŒ‘æˆ˜çš„è§£å†³æ–¹æ¡ˆã€‚åˆ›å»ºäº†é¦–ä¸ªå…¨é¢çš„ç©ºé—´éŸ³é¢‘é©±åŠ¨äººç‰©è¿åŠ¨ï¼ˆSAMï¼‰æ•°æ®é›†ï¼Œæ—¨åœ¨å¡«è¡¥ç°æœ‰æ¨¡å‹å¿½ç•¥çš„ç©ºé—´éŸ³é¢‘ä¿¡å·å¯¹äººç‰©è¿åŠ¨å½±å“çš„ç©ºç™½ã€‚å¹¶æå‡ºäº†ä¸€ç§åŸºäºæ‰©æ•£çš„ç®€å•æœ‰æ•ˆçš„ç©ºé—´éŸ³é¢‘é©±åŠ¨äººç‰©è¿åŠ¨ç”Ÿæˆæ¡†æ¶MOSPAï¼Œå®ƒèƒ½å¤Ÿæœ‰æ•ˆåœ°æ•æ‰äººç‰©è¿åŠ¨å’Œç©ºé—´éŸ³é¢‘ä¹‹é—´çš„å…³ç³»ã€‚</p>
<p><strong>Key Takeaways</strong>:</p>
<ol>
<li>ç©ºé—´éŸ³é¢‘å¯¹äººç‰©è¿åŠ¨çš„å½±å“è¢«å¿½è§†ï¼Œåˆ›å»ºé¦–ä¸ªå…¨é¢çš„ç©ºé—´éŸ³é¢‘é©±åŠ¨äººç‰©è¿åŠ¨ï¼ˆSAMï¼‰æ•°æ®é›†ä»¥å¡«è¡¥è¿™ä¸€ç©ºç™½ã€‚</li>
<li>å¼•å…¥äº†ä¸€ç§åŸºäºæ‰©æ•£çš„ç”Ÿæˆæ¡†æ¶MOSPAï¼Œç”¨äºæ ¹æ®ç©ºé—´éŸ³é¢‘ç”Ÿæˆäººç‰©è¿åŠ¨ã€‚</li>
<li>MOSPAèƒ½å¤ŸçœŸå®åœ°æ•æ‰äººç‰©è¿åŠ¨å’Œç©ºé—´éŸ³é¢‘ä¹‹é—´çš„å…³ç³»ã€‚</li>
<li>MOSPAå¯åœ¨ä¸åŒçš„ç©ºé—´éŸ³é¢‘è¾“å…¥ä¸‹ç”Ÿæˆå¤šæ ·ä¸”ç°å®çš„äººç‰©è¿åŠ¨ã€‚</li>
<li>è¯¥æ–¹æ³•åœ¨æå‡ºçš„SAMæ•°æ®é›†ä¸Šè¿›è¡Œäº†å…¨é¢çš„è°ƒæŸ¥å’Œå¹¿æ³›çš„å®éªŒè¯„ä¼°ï¼Œè¾¾åˆ°äº†åœ¨è¯¥ä»»åŠ¡ä¸Šçš„æœ€ä½³æ€§èƒ½ã€‚</li>
<li>ä»£ç å’Œæ¨¡å‹å·²å…¬å¼€å‘å¸ƒï¼Œä¾¿äºå…¬ä¼—è®¿é—®å’Œä½¿ç”¨ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2507.11949">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-e9e34dc2f030fae5a59784ade6f0f57d~resize:0:q75.jpg?source=1f5c5e47&expiration=1762309528&auth_key=1762309528-0-0-d4dd6e1970fd79aa43f95bac300fc579&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-35a714aee61052b3a38e9ea8f6ade198~resize:0:q75.jpg?source=1f5c5e47&expiration=1762309536&auth_key=1762309536-0-0-38b0d7d5b0ab171f438997cd84f033cd&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-02a69dbc05a3e51b12c6b1fb00637e59~resize:0:q75.jpg?source=1f5c5e47&expiration=1762309543&auth_key=1762309543-0-0-522f1ba212264601f09196a2db3ce9f2&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-cf4a9995c947f2746c494e29be8b27ad~resize:0:q75.jpg?source=1f5c5e47&expiration=1762309550&auth_key=1762309550-0-0-c6dbd5f8755aa26363cec80c7123674f&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1><h2 id="Talk-Listen-Connect-How-Humans-and-AI-Evaluate-Empathy-in-Responses-to-Emotionally-Charged-Narratives"><a href="#Talk-Listen-Connect-How-Humans-and-AI-Evaluate-Empathy-in-Responses-to-Emotionally-Charged-Narratives" class="headerlink" title="Talk, Listen, Connect: How Humans and AI Evaluate Empathy in Responses   to Emotionally Charged Narratives"></a>Talk, Listen, Connect: How Humans and AI Evaluate Empathy in Responses   to Emotionally Charged Narratives</h2><p><strong>Authors:Mahnaz Roshanaei, Rezvaneh Rezapour, Magy Seif El-Nasr</strong></p>
<p>Social interactions promote well-being, yet barriers like geographic distance, time limitations, and mental health conditions can limit face-to-face interactions. Emotionally responsive AI systems, such as chatbots, offer new opportunities for social and emotional support, but raise critical questions about how empathy is perceived and experienced in human-AI interactions. This study examines how empathy is evaluated in AI-generated versus human responses. Using personal narratives, we explored how persona attributes (e.g., gender, empathic traits, shared experiences) and story qualities affect empathy ratings. We compared responses from standard and fine-tuned AI models with human judgments. Results show that while humans are highly sensitive to emotional vividness and shared experience, AI-responses are less influenced by these cues, often lack nuance in empathic expression. These findings highlight challenges in designing emotionally intelligent systems that respond meaningfully across diverse users and contexts, and informs the design of ethically aware tools to support social connection and well-being. </p>
<blockquote>
<p>ç¤¾ä¼šäº’åŠ¨æœ‰åŠ©äºä¿ƒè¿›ç¦ç¥‰ï¼Œç„¶è€Œï¼Œåœ°ç†è·ç¦»ã€æ—¶é—´é™åˆ¶å’Œå¿ƒç†å¥åº·çŠ¶å†µç­‰éšœç¢é™åˆ¶äº†é¢å¯¹é¢çš„äº’åŠ¨ã€‚æƒ…æ„Ÿå“åº”çš„AIç³»ç»Ÿï¼Œå¦‚èŠå¤©æœºå™¨äººï¼Œä¸ºç¤¾ä¼šå’Œæƒ…æ„Ÿæ”¯æŒæä¾›äº†æ–°çš„æœºä¼šï¼Œä½†ä¹Ÿå¼•å‘äº†å…³äºäººç±»ä¸AIäº’åŠ¨ä¸­å¦‚ä½•æ„ŸçŸ¥å’Œä½“éªŒå…±æƒ…çš„å…³é”®é—®é¢˜ã€‚æœ¬ç ”ç©¶æ—¨åœ¨è€ƒå¯ŸAIç”Ÿæˆä¸äººç±»å›åº”ä¸­çš„å…±æƒ…è¯„ä¼°æ–¹å¼ã€‚é€šè¿‡ä¸ªäººå™äº‹ï¼Œæˆ‘ä»¬æ¢è®¨äº†äººæ ¼ç‰¹è´¨ï¼ˆå¦‚æ€§åˆ«ã€å…±æƒ…ç‰¹è´¨ã€å…±äº«ç»éªŒï¼‰å’Œæ•…äº‹è´¨é‡å¦‚ä½•å½±å“å…±æƒ…è¯„åˆ†ã€‚æˆ‘ä»¬å°†æ ‡å‡†AIæ¨¡å‹å’Œç»è¿‡å¾®è°ƒåçš„AIæ¨¡å‹çš„ååº”ä¸äººç±»åˆ¤æ–­è¿›è¡Œäº†æ¯”è¾ƒã€‚ç»“æœè¡¨æ˜ï¼Œè™½ç„¶äººç±»å¯¹æƒ…æ„Ÿç”ŸåŠ¨æ€§å’Œå…±äº«ç»éªŒé«˜åº¦æ•æ„Ÿï¼Œä½†AIååº”å¯¹è¿™äº›çº¿ç´¢çš„å½±å“è¾ƒå°ï¼Œå¾€å¾€ç¼ºä¹å¾®å¦™çš„å…±æƒ…è¡¨è¾¾ã€‚è¿™äº›å‘ç°çªæ˜¾äº†åœ¨è®¾è®¡å’Œå¼€å‘æ™ºèƒ½ç³»ç»Ÿä¸­é¢ä¸´çš„æŒ‘æˆ˜ï¼Œå³åœ¨è·¨ç”¨æˆ·æƒ…å¢ƒä¸­è¿›è¡Œæœ‰æ„ä¹‰çš„å“åº”ã€‚è¿™ä¸ºæ”¯æŒç¤¾äº¤è”ç³»å’Œç¦ç¥‰çš„ä¼¦ç†æ„è¯†å·¥å…·çš„è®¾è®¡æä¾›äº†ä¿¡æ¯ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2409.15550v3">PDF</a> 18 pages, 4 figures, 6 tables. Title updated from â€œTalk, Listen,   Connect: Navigating Empathy in Human-AI Interactionsâ€ to â€œTalk, Listen,   Connect: How Humans and AI Evaluate Empathy in Responses to Emotionally   Charged Narrativesâ€ in this version. This is version 3 (v3) of the paper. All   previous citations of arXiv:2409.15550 with the old title still refer to the   same paper</p>
<p><strong>Summary</strong><br>äººå·¥æ™ºèƒ½åœ¨ç¤¾äº¤äº’åŠ¨ä¸­çš„è§’è‰²åŠå…¶å¯¹äººç±»å…±æƒ…çš„å½±å“ã€‚ç ”ç©¶è¡¨æ˜ï¼Œå°½ç®¡AIç³»ç»Ÿèƒ½æä¾›æƒ…æ„Ÿæ”¯æŒï¼Œä½†å®ƒä»¬å¯¹å…±æƒ…çš„ç†è§£å’Œè¡¨è¾¾ä¸äººç±»ä¸åŒã€‚å¯¹æ¯”AIç”Ÿæˆå’Œäººç±»å›åº”ï¼Œå‘ç°äººç±»åœ¨æƒ…æ„Ÿç”ŸåŠ¨æ€§å’Œå…±åŒç»å†ä¸Šæ›´æ•æ„Ÿï¼Œè€ŒAIå¯¹æ­¤ç±»çº¿ç´¢ååº”è¾ƒå°‘ï¼Œç¼ºä¹ç»†å¾®çš„å…±æƒ…è¡¨è¾¾ã€‚è¿™ä¸ºè®¾è®¡èƒ½åœ¨å¤šæ ·ç”¨æˆ·å’Œè¯­å¢ƒä¸­å›åº”çš„ä¼¦ç†æ„è¯†å·¥å…·å¸¦æ¥äº†æŒ‘æˆ˜ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ç¤¾ä¼šäº’åŠ¨å¯¹ç¦ç¥‰æœ‰ç§¯æå½±å“ï¼Œä½†åœ°ç†è·ç¦»ã€æ—¶é—´é™åˆ¶å’Œç²¾ç¥å¥åº·ç­‰éšœç¢é™åˆ¶äº†é¢å¯¹é¢çš„äº¤æµã€‚</li>
<li>AIç³»ç»Ÿå¦‚èŠå¤©æœºå™¨äººæä¾›äº†æ–°çš„ç¤¾äº¤å’Œæƒ…æ„Ÿæ”¯æŒæœºä¼šï¼Œä½†åœ¨äººæœºäº’åŠ¨ä¸­å¦‚ä½•ç†è§£å’Œä½“éªŒå…±æƒ…å¼•å‘å…³é”®é—®é¢˜ã€‚</li>
<li>å¯¹æ¯”AIç”Ÿæˆå’Œäººç±»å›åº”å‘ç°ï¼Œäººç±»åœ¨æƒ…æ„Ÿç”ŸåŠ¨æ€§å’Œå…±åŒç»å†ä¸Šé«˜åº¦æ•æ„Ÿï¼Œè€ŒAIå¯¹æ­¤ç±»çº¿ç´¢ååº”è¾ƒå°‘ã€‚</li>
<li>AIåœ¨å…±æƒ…è¡¨è¾¾ä¸Šå¸¸ç¼ºä¹ç»†å¾®å·®åˆ«ï¼Œè¿™å½±å“äº†å®ƒä»¬åœ¨ä¸åŒç”¨æˆ·å’Œè¯­å¢ƒä¸­çš„å›åº”èƒ½åŠ›ã€‚</li>
<li>è®¾è®¡æƒ…æ„Ÿæ™ºèƒ½ç³»ç»Ÿæ—¶ï¼Œéœ€è€ƒè™‘å¦‚ä½•å…‹æœè¿™äº›æŒ‘æˆ˜ï¼Œä»¥ç¡®ä¿æœ‰æ•ˆæ”¯æŒç¤¾ä¼šè”ç³»å’Œç¦ç¥‰ã€‚</li>
<li>åº”é‡è§†ä¼¦ç†æ„è¯†åœ¨è®¾è®¡æƒ…æ„Ÿæ™ºèƒ½ç³»ç»Ÿä¸­çš„ä½œç”¨ï¼Œä»¥ç¡®ä¿å®ƒä»¬èƒ½å¤Ÿå…¬å¹³ã€å…¬æ­£åœ°å›åº”ä¸åŒç”¨æˆ·çš„éœ€æ±‚ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2409.15550">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-355dbd47bbf60938818d2b76dd434170~resize:0:q75.jpg?source=1f5c5e47&expiration=1762309558&auth_key=1762309558-0-0-9af44a6186570c58b914192d431f2476&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-956b2fd9c1e9fcd3c5f38c31e14ea825~resize:0:q75.jpg?source=1f5c5e47&expiration=1762309565&auth_key=1762309565-0-0-f5af5e280a13b0528bbbf27afcfec53b&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-a66ba62aede9976e2ce71b84dca65ae6~resize:0:q75.jpg?source=1f5c5e47&expiration=1762309572&auth_key=1762309572-0-0-a8b906572358351a288d8c08c9d47a03&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-79085de3735a3d4428a6c6e8eef68640~resize:0:q75.jpg?source=1f5c5e47&expiration=1762309578&auth_key=1762309578-0-0-0503ffb4312444707aae0cab296b4297&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-9"><a href="#-9" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-11-05/Talking%20Head%20Generation/">https://kedreamix.github.io/Talk2Paper/Paper/2025-11-05/Talking%20Head%20Generation/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/Talking-Head-Generation/">
                                    <span class="chip bg-color">Talking Head Generation</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-11-06/R1_Reasoning/">
                    <div class="card-image">
                        
                        <img src="https://pic-private.zhihu.com/v2-2f776ed60e692f0ffd1e478593546123~resize:0:q75.jpg?source=1f5c5e47&expiration=1762365210&auth_key=1762365210-0-0-0345851d258d0abe284859b257cee634&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" class="responsive-img" alt="R1_Reasoning">
                        
                        <span class="card-title">R1_Reasoning</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            R1_Reasoning æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-11-06  Agent-Omni Test-Time Multimodal Reasoning via Model Coordination for   Understanding Anything
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-11-06
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/R1-Reasoning/" class="post-category">
                                    R1_Reasoning
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/R1-Reasoning/">
                        <span class="chip bg-color">R1_Reasoning</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-11-05/Interactive/">
                    <div class="card-image">
                        
                        <img src="https://pic-private.zhihu.com/v2-1988fbce9480b6158d44653acfadfc9d~resize:0:q75.jpg?source=1f5c5e47&expiration=1762307888&auth_key=1762307888-0-0-7ef442949a63ffdeb62d5e872ae8c432&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" class="responsive-img" alt="Interactive">
                        
                        <span class="card-title">Interactive</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Interactive æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-11-05  LISTEN to Your Preferences An LLM Framework for Multi-Objective   Selection
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-11-05
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Interactive/" class="post-category">
                                    Interactive
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Interactive/">
                        <span class="chip bg-color">Interactive</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">32251.6k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
