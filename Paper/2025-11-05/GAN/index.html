<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="GAN">
    <meta name="description" content="GAN æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-11-05  GLYPH-SR Can We Achieve Both High-Quality Image Super-Resolution and   High-Fidelity Text Recovery via VLM-guided Latent Diffusion Model?">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>GAN | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://pic-private.zhihu.com/v2-801920636b580710278daf4c56c85e40~resize:0:q75.jpg?source=1f5c5e47&expiration=1762310546&auth_key=1762310546-0-0-11f547c17684dc5fa797ecd96aff7bd8&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">GAN</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/GAN/">
                                <span class="chip bg-color">GAN</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/GAN/" class="post-category">
                                GAN
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-11-05
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-11-10
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    10k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    41 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-11-05-æ›´æ–°"><a href="#2025-11-05-æ›´æ–°" class="headerlink" title="2025-11-05 æ›´æ–°"></a>2025-11-05 æ›´æ–°</h1><h2 id="GLYPH-SR-Can-We-Achieve-Both-High-Quality-Image-Super-Resolution-and-High-Fidelity-Text-Recovery-via-VLM-guided-Latent-Diffusion-Model"><a href="#GLYPH-SR-Can-We-Achieve-Both-High-Quality-Image-Super-Resolution-and-High-Fidelity-Text-Recovery-via-VLM-guided-Latent-Diffusion-Model" class="headerlink" title="GLYPH-SR: Can We Achieve Both High-Quality Image Super-Resolution and   High-Fidelity Text Recovery via VLM-guided Latent Diffusion Model?"></a>GLYPH-SR: Can We Achieve Both High-Quality Image Super-Resolution and   High-Fidelity Text Recovery via VLM-guided Latent Diffusion Model?</h2><p><strong>Authors:Mingyu Sung, Seungjae Ham, Kangwoo Kim, Yeokyoung Yoon, Sangseok Yun, Il-Min Kim, Jae-Mo Kang</strong></p>
<p>Image super-resolution(SR) is fundamental to many vision system-from surveillance and autonomy to document analysis and retail analytics-because recovering high-frequency details, especially scene-text, enables reliable downstream perception. Scene-text, i.e., text embedded in natural images such as signs, product labels, and storefronts, often carries the most actionable information; when characters are blurred or hallucinated, optical character recognition(OCR) and subsequent decisions fail even if the rest of the image appears sharp. Yet previous SR research has often been tuned to distortion (PSNR&#x2F;SSIM) or learned perceptual metrics (LIPIS, MANIQA, CLIP-IQA, MUSIQ) that are largely insensitive to character-level errors. Furthermore, studies that do address text SR often focus on simplified benchmarks with isolated characters, overlooking the challenges of text within complex natural scenes. As a result, scene-text is effectively treated as generic texture. For SR to be effective in practical deployments, it is therefore essential to explicitly optimize for both text legibility and perceptual quality. We present GLYPH-SR, a vision-language-guided diffusion framework that aims to achieve both objectives jointly. GLYPH-SR utilizes a Text-SR Fusion ControlNet(TS-ControlNet) guided by OCR data, and a ping-pong scheduler that alternates between text- and scene-centric guidance. To enable targeted text restoration, we train these components on a synthetic corpus while keeping the main SR branch frozen. Across SVT, SCUT-CTW1500, and CUTE80 at x4, and x8, GLYPH-SR improves OCR F1 by up to +15.18 percentage points over diffusion&#x2F;GAN baseline (SVT x8, OpenOCR) while maintaining competitive MANIQA, CLIP-IQA, and MUSIQ. GLYPH-SR is designed to satisfy both objectives simultaneously-high readability and high visual realism-delivering SR that looks right and reds right. </p>
<blockquote>
<p>å›¾åƒè¶…åˆ†è¾¨ç‡ï¼ˆSRï¼‰å¯¹äºè®¸å¤šè§†è§‰ç³»ç»Ÿï¼Œä»ç›‘æ§å’Œè‡ªä¸»åˆ°æ–‡æ¡£åˆ†æå’Œé›¶å”®åˆ†æéƒ½æ˜¯è‡³å…³é‡è¦çš„ï¼Œå› ä¸ºæ¢å¤é«˜é¢‘ç»†èŠ‚ï¼Œç‰¹åˆ«æ˜¯åœºæ™¯æ–‡æœ¬ï¼Œå¯ä»¥å®ç°å¯é çš„ä¸‹æ¸¸æ„ŸçŸ¥ã€‚åœºæ™¯æ–‡æœ¬ï¼Œå³åµŒå…¥åœ¨è‡ªç„¶å›¾åƒä¸­çš„æ–‡æœ¬ï¼Œå¦‚æ ‡å¿—ã€äº§å“æ ‡ç­¾å’Œåº—é¢ï¼Œé€šå¸¸æºå¸¦æœ€å…·æ“ä½œæ€§çš„ä¿¡æ¯ï¼›å½“å­—ç¬¦æ¨¡ç³Šæˆ–äº§ç”Ÿå¹»è§‰æ—¶ï¼Œå³ä½¿å…¶ä½™å›¾åƒçœ‹èµ·æ¥å¾ˆæ¸…æ™°ï¼Œå…‰å­¦å­—ç¬¦è¯†åˆ«ï¼ˆOCRï¼‰å’Œéšåçš„å†³ç­–ä¹Ÿä¼šå¤±è´¥ã€‚ç„¶è€Œï¼Œä¹‹å‰çš„SRç ”ç©¶é€šå¸¸é’ˆå¯¹æ‰­æ›²ï¼ˆPSNR&#x2F;SSIMï¼‰æˆ–å­¦ä¹ æ„ŸçŸ¥æŒ‡æ ‡ï¼ˆLIPISã€MANIQAã€CLIP-IQAã€MUSIQï¼‰ï¼Œè¿™äº›æŒ‡æ ‡å¯¹å­—ç¬¦çº§åˆ«çš„é”™è¯¯å¤§å¤šä¸æ•æ„Ÿã€‚æ­¤å¤–ï¼Œç¡®å®å…³æ³¨æ–‡æœ¬SRçš„ç ”ç©¶é€šå¸¸é›†ä¸­åœ¨å…·æœ‰å­¤ç«‹å­—ç¬¦çš„ç®€å•åŸºå‡†æµ‹è¯•ä¸Šï¼Œå¿½ç•¥äº†å¤æ‚è‡ªç„¶åœºæ™¯ä¸­æ–‡æœ¬çš„æŒ‘æˆ˜ã€‚å› æ­¤ï¼Œåœºæ™¯æ–‡æœ¬å®é™…ä¸Šè¢«è§†ä¸ºé€šç”¨çº¹ç†ã€‚è¦ä½¿SRåœ¨å®é™…éƒ¨ç½²ä¸­æœ‰æ•ˆï¼Œå› æ­¤å¿…é¡»æ˜¾å¼ä¼˜åŒ–æ–‡æœ¬å¯è¯»æ€§å’Œæ„ŸçŸ¥è´¨é‡ã€‚æˆ‘ä»¬æå‡ºäº†GLYPH-SRï¼Œè¿™æ˜¯ä¸€ä¸ªç”±è§†è§‰è¯­è¨€å¼•å¯¼çš„æ‰©æ•£æ¡†æ¶ï¼Œæ—¨åœ¨åŒæ—¶å®ç°è¿™ä¸¤ä¸ªç›®æ ‡ã€‚GLYPH-SRåˆ©ç”¨ç”±OCRæ•°æ®å¼•å¯¼çš„Text-SR Fusion ControlNetï¼ˆTS-ControlNetï¼‰å’Œä¸€ä¸ªäº¤æ›¿è¿›è¡Œæ–‡æœ¬å’Œåœºæ™¯ä¸ºä¸­å¿ƒçš„æŒ‡å¯¼çš„ä¹’ä¹“è°ƒåº¦å™¨ã€‚ä¸ºäº†å®ç°æœ‰é’ˆå¯¹æ€§çš„æ–‡æœ¬æ¢å¤ï¼Œæˆ‘ä»¬åœ¨åˆæˆè¯­æ–™åº“ä¸Šè®­ç»ƒè¿™äº›ç»„ä»¶ï¼ŒåŒæ—¶ä¿æŒä¸»SRåˆ†æ”¯å†»ç»“ã€‚åœ¨SVTã€SCUT-CTW1500å’ŒCUTE80çš„x4å’Œx8åˆ†è¾¨ç‡ä¸‹ï¼ŒGLYPH-SRåœ¨æ‰©æ•£&#x2F;GANåŸºå‡†æµ‹è¯•çš„åŸºç¡€ä¸Šæé«˜äº†OCR F1åˆ†æ•°é«˜è¾¾+15.18ä¸ªç™¾åˆ†ç‚¹ï¼ˆSVT x8ï¼ŒOpenOCRï¼‰ï¼ŒåŒæ—¶ä¿æŒæœ‰ç«äº‰åŠ›çš„MANIQAã€CLIP-IQAå’ŒMUSIQæŒ‡æ ‡ã€‚GLYPH-SRè¢«è®¾è®¡æˆåŒæ—¶æ»¡è¶³ä¸¤ä¸ªç›®æ ‡â€”â€”é«˜å¯è¯»æ€§å’Œé«˜è§†è§‰é€¼çœŸåº¦ï¼Œå®ç°æ—¢çœ‹èµ·æ¥æ­£ç¡®åˆè¯»å¾—æ­£ç¡®çš„SRæ•ˆæœã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.26339v1">PDF</a> 11 pages, 6 figures. Includes supplementary material. Under review as   a conference paper at ICLR 2026</p>
<p><strong>Summary</strong><br>     æ–‡æœ¬è¶…åˆ†è¾¨ç‡ï¼ˆSRï¼‰åœ¨è®¸å¤šè§†è§‰ç³»ç»Ÿä¸­è‡³å…³é‡è¦ï¼Œå¦‚ç›‘æ§ã€è‡ªä¸»é©¾é©¶ã€æ–‡æ¡£åˆ†æå’Œé›¶å”®åˆ†æç­‰ã€‚GLYPSH-SRæ˜¯ä¸€ç§æ—¨åœ¨è”åˆå®ç°æ–‡æœ¬å¯è¯»æ€§å’Œæ„ŸçŸ¥è´¨é‡ä¼˜åŒ–çš„è§†è§‰è¯­è¨€å¼•å¯¼æ‰©æ•£æ¡†æ¶ã€‚å®ƒé€šè¿‡Text-SR Fusion ControlNetï¼ˆTS-ControlNetï¼‰å’Œä¹’ä¹“è°ƒåº¦å™¨å®ç°ç›®æ ‡ï¼Œå¹¶åœ¨åˆæˆè¯­æ–™åº“ä¸Šè®­ç»ƒç»„ä»¶ï¼ŒåŒæ—¶ä¿æŒä¸»è¦çš„SRåˆ†æ”¯å†»ç»“ã€‚åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šï¼ŒGLYPH-SRæ”¹è¿›äº†OCRçš„F1åˆ†æ•°ï¼ŒåŒæ—¶ä¿æŒäº†ç«äº‰æ€§çš„MANIQAã€CLIP-IQAå’ŒMUSIQè¯„åˆ†ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å›¾åƒè¶…åˆ†è¾¨ç‡ï¼ˆSRï¼‰åœ¨è®¸å¤šè§†è§‰ç³»ç»Ÿä¸­éå¸¸é‡è¦ï¼Œå› ä¸ºå®ƒèƒ½æ¢å¤é«˜é¢‘ç»†èŠ‚ï¼Œå°¤å…¶æ˜¯åœºæ™¯æ–‡æœ¬ï¼Œä½¿ä¸‹æ¸¸æ„ŸçŸ¥ä»»åŠ¡æ›´å¯é ã€‚</li>
<li>ä¹‹å‰çš„SRç ”ç©¶é€šå¸¸é’ˆå¯¹å¤±çœŸæˆ–å­¦ä¹ æ„ŸçŸ¥æŒ‡æ ‡ï¼Œè¿™äº›æŒ‡æ ‡å¯¹å­—ç¬¦çº§é”™è¯¯å¤§å¤šä¸æ•æ„Ÿã€‚</li>
<li>é’ˆå¯¹æ–‡æœ¬SRçš„ç ”ç©¶å¾€å¾€é›†ä¸­åœ¨ç®€åŒ–çš„åŸºå‡†æµ‹è¯•ä¸Šï¼Œå¿½ç•¥äº†å¤æ‚è‡ªç„¶åœºæ™¯ä¸­çš„æ–‡æœ¬æŒ‘æˆ˜ã€‚</li>
<li>GLYPH-SRæ˜¯ä¸€ç§è”åˆä¼˜åŒ–æ–‡æœ¬å¯è¯»æ€§å’Œæ„ŸçŸ¥è´¨é‡çš„è§†è§‰è¯­è¨€å¼•å¯¼æ‰©æ•£æ¡†æ¶ã€‚</li>
<li>GLYPH-SRé€šè¿‡TS-ControlNetå’Œä¹’ä¹“è°ƒåº¦å™¨å®ç°ç›®æ ‡æ–‡æœ¬æ¢å¤ã€‚</li>
<li>GLYPH-SRåœ¨åˆæˆè¯­æ–™åº“ä¸Šè®­ç»ƒç»„ä»¶ï¼ŒåŒæ—¶ä¿æŒä¸»è¦çš„SRåˆ†æ”¯å†»ç»“ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.26339">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-7ce105691ec1c7c58f88de114eccb2a1~resize:0:q75.jpg?source=1f5c5e47&expiration=1762310553&auth_key=1762310553-0-0-34f734930baee18c49899e4fcfb380a2&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-cfd761fe87b8bb1d52c3f085cfb9a261~resize:0:q75.jpg?source=1f5c5e47&expiration=1762310582&auth_key=1762310582-0-0-4cfc4e104f309290bda50962054a7654&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-f42a313d0f149703464fb55c25cb3ade~resize:0:q75.jpg?source=1f5c5e47&expiration=1762310589&auth_key=1762310589-0-0-7e6937b3eaf2be6fb6784e780a19da08&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-801920636b580710278daf4c56c85e40~resize:0:q75.jpg?source=1f5c5e47&expiration=1762310596&auth_key=1762310596-0-0-5a0708bc5b6cec3ae173fbeb55859522&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="BOLT-GAN-Bayes-Optimal-Loss-for-Stable-GAN-Training"><a href="#BOLT-GAN-Bayes-Optimal-Loss-for-Stable-GAN-Training" class="headerlink" title="BOLT-GAN: Bayes-Optimal Loss for Stable GAN Training"></a>BOLT-GAN: Bayes-Optimal Loss for Stable GAN Training</h2><p><strong>Authors:Mohammadreza Tavasoli Naeini, Ali Bereyhi, Morteza Noshad, Ben Liang, Alfred O. Hero III</strong></p>
<p>We introduce BOLT-GAN, a simple yet effective modification of the WGAN framework inspired by the Bayes Optimal Learning Threshold (BOLT). We show that with a Lipschitz continuous discriminator, BOLT-GAN implicitly minimizes a different metric distance than the Earth Mover (Wasserstein) distance and achieves better training stability. Empirical evaluations on four standard image generation benchmarks (CIFAR-10, CelebA-64, LSUN Bedroom-64, and LSUN Church-64) show that BOLT-GAN consistently outperforms WGAN, achieving 10-60% lower Frechet Inception Distance (FID). Our results suggest that BOLT is a broadly applicable principle for enhancing GAN training. </p>
<blockquote>
<p>æˆ‘ä»¬ä»‹ç»äº†BOLT-GANï¼Œå®ƒæ˜¯å—Bayesæœ€ä¼˜å­¦ä¹ é˜ˆå€¼ï¼ˆBOLTï¼‰å¯å‘çš„WGANæ¡†æ¶çš„ç®€å•æœ‰æ•ˆçš„æ”¹è¿›ã€‚æˆ‘ä»¬è¡¨æ˜ï¼Œå…·æœ‰Lipschitzè¿ç»­åˆ¤åˆ«å™¨çš„BOLT-GANéšå¼åœ°æœ€å°åŒ–äº†ä¸åŒäºåœ°çƒç§»åŠ¨ï¼ˆWassersteinï¼‰è·ç¦»çš„å¦ä¸€ç§åº¦é‡è·ç¦»ï¼Œå¹¶å®ç°äº†æ›´å¥½çš„è®­ç»ƒç¨³å®šæ€§ã€‚åœ¨å››ä¸ªæ ‡å‡†å›¾åƒç”ŸæˆåŸºå‡†æµ‹è¯•ï¼ˆCIFAR-10ã€CelebA-64ã€LSUN Bedroom-64å’ŒLSUN Church-64ï¼‰ä¸Šçš„ç»éªŒè¯„ä¼°è¡¨æ˜ï¼ŒBOLT-GANæŒç»­ä¼˜äºWGANï¼Œå®ç°äº†10-60%æ›´ä½çš„Frechet Inception Distanceï¼ˆFIDï¼‰ã€‚æˆ‘ä»¬çš„ç»“æœè¡¨æ˜ï¼ŒBOLTæ˜¯æé«˜GANè®­ç»ƒçš„ä¸€ä¸ªæ™®éé€‚ç”¨çš„åŸåˆ™ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.25609v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>BOLT-GANæ˜¯WGANæ¡†æ¶çš„ç®€å•æœ‰æ•ˆæ”¹è¿›ï¼Œå—åˆ°Bayes Optimal Learning Thresholdï¼ˆBOLTï¼‰çš„å¯å‘ã€‚å®ƒåˆ©ç”¨Lipschitzè¿ç»­é‰´åˆ«å™¨ï¼Œéšå¼åœ°æœ€å°åŒ–ä¸åŒäºEarth Moverï¼ˆWassersteinï¼‰è·ç¦»çš„åº¦é‡æ ‡å‡†ï¼Œå®ç°æ›´å¥½çš„è®­ç»ƒç¨³å®šæ€§ã€‚åœ¨å››ä¸ªæ ‡å‡†å›¾åƒç”ŸæˆåŸºå‡†æµ‹è¯•ä¸Šçš„å®è¯è¯„ä¼°è¡¨æ˜ï¼ŒBOLT-GANæŒç»­ä¼˜äºWGANï¼ŒFrechet Inception Distanceï¼ˆFIDï¼‰é™ä½10-60%ã€‚ç ”ç©¶ç»“æœè¡¨æ˜ï¼ŒBOLTæ˜¯å¹¿æ³›é€‚ç”¨äºå¢å¼ºGANè®­ç»ƒçš„åŸåˆ™ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>BOLT-GANæ˜¯WGANæ¡†æ¶çš„æ”¹è¿›ç‰ˆæœ¬ï¼Œå—Bayes Optimal Learning Thresholdï¼ˆBOLTï¼‰å¯å‘ã€‚</li>
<li>BOLT-GANåˆ©ç”¨Lipschitzè¿ç»­é‰´åˆ«å™¨éšå¼åœ°æœ€å°åŒ–ä¸åŒçš„åº¦é‡è·ç¦»ã€‚</li>
<li>ä¸Earth Moverï¼ˆWassersteinï¼‰è·ç¦»ä¸åŒï¼ŒBOLT-GANå®ç°æ›´å¥½çš„è®­ç»ƒç¨³å®šæ€§ã€‚</li>
<li>åœ¨å››ä¸ªæ ‡å‡†å›¾åƒç”ŸæˆåŸºå‡†æµ‹è¯•ä¸Šï¼ŒBOLT-GANè¡¨ç°ä¼˜äºWGANã€‚</li>
<li>BOLT-GANé™ä½äº†Frechet Inception Distanceï¼ˆFIDï¼‰è¾¾10-60%ã€‚</li>
<li>å®è¯è¯„ä¼°è¯æ˜ï¼ŒBOLT-GANåœ¨å›¾åƒç”Ÿæˆä»»åŠ¡ä¸Šå…·æœ‰æ˜¾è‘—ä¼˜åŠ¿ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.25609">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-6593ed754a85e4f2771d40b3e67008e3~resize:0:q75.jpg?source=1f5c5e47&expiration=1762310603&auth_key=1762310603-0-0-1f289ca0fdc1dffd7a795f12915b1da2&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="PSTF-AttControl-Per-Subject-Tuning-Free-Personalized-Image-Generation-with-Controllable-Face-Attributes"><a href="#PSTF-AttControl-Per-Subject-Tuning-Free-Personalized-Image-Generation-with-Controllable-Face-Attributes" class="headerlink" title="PSTF-AttControl: Per-Subject-Tuning-Free Personalized Image Generation   with Controllable Face Attributes"></a>PSTF-AttControl: Per-Subject-Tuning-Free Personalized Image Generation   with Controllable Face Attributes</h2><p><strong>Authors:Xiang liu, Zhaoxiang Liu, Huan Hu, Zipeng Wang, Ping Chen, Zezhou Chen, Kai Wang, Shiguo Lian</strong></p>
<p>Recent advancements in personalized image generation have significantly improved facial identity preservation, particularly in fields such as entertainment and social media. However, existing methods still struggle to achieve precise control over facial attributes in a per-subject-tuning-free (PSTF) way. Tuning-based techniques like PreciseControl have shown promise by providing fine-grained control over facial features, but they often require extensive technical expertise and additional training data, limiting their accessibility. In contrast, PSTF approaches simplify the process by enabling image generation from a single facial input, but they lack precise control over facial attributes. In this paper, we introduce a novel, PSTF method that enables both precise control over facial attributes and high-fidelity preservation of facial identity. Our approach utilizes a face recognition model to extract facial identity features, which are then mapped into the $W^+$ latent space of StyleGAN2 using the e4e encoder. We further enhance the model with a Triplet-Decoupled Cross-Attention module, which integrates facial identity, attribute features, and text embeddings into the UNet architecture, ensuring clean separation of identity and attribute information. Trained on the FFHQ dataset, our method allows for the generation of personalized images with fine-grained control over facial attributes, while without requiring additional fine-tuning or training data for individual identities. We demonstrate that our approach successfully balances personalization with precise facial attribute control, offering a more efficient and user-friendly solution for high-quality, adaptable facial image synthesis. The code is publicly available at <a target="_blank" rel="noopener" href="https://github.com/UnicomAI/PSTF-AttControl">https://github.com/UnicomAI/PSTF-AttControl</a>. </p>
<blockquote>
<p>åœ¨ä¸ªæ€§åŒ–å›¾åƒç”Ÿæˆçš„æœ€æ–°è¿›å±•ä¸­ï¼Œé¢éƒ¨èº«ä»½ä¿ç•™èƒ½åŠ›å·²ç»å¾—åˆ°äº†æ˜¾è‘—çš„æå‡ï¼Œç‰¹åˆ«æ˜¯åœ¨å¨±ä¹å’Œç¤¾äº¤åª’ä½“ç­‰é¢†åŸŸã€‚ç„¶è€Œï¼Œç°æœ‰æ–¹æ³•ä»ç„¶éš¾ä»¥åœ¨æ— éœ€é’ˆå¯¹æ¯ä¸ªä¸»ä½“è¿›è¡Œå¾®è°ƒï¼ˆPSTFï¼‰çš„æƒ…å†µä¸‹å®ç°å¯¹é¢éƒ¨å±æ€§çš„ç²¾ç¡®æ§åˆ¶ã€‚åŸºäºè°ƒæ•´çš„æŠ€æœ¯ï¼ˆå¦‚PreciseControlï¼‰é€šè¿‡å¯¹é¢éƒ¨ç‰¹å¾è¿›è¡Œç²¾ç»†æ§åˆ¶è€Œæ˜¾ç¤ºå‡ºå‰æ™¯ï¼Œä½†å®ƒä»¬é€šå¸¸éœ€è¦å¤§é‡çš„æŠ€æœ¯ä¸“é•¿å’Œé¢å¤–çš„è®­ç»ƒæ•°æ®ï¼Œä»è€Œé™åˆ¶äº†å…¶æ™®åŠæ€§ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼ŒPSTFæ–¹æ³•é€šè¿‡ä»å•ä¸ªé¢éƒ¨è¾“å…¥ç”Ÿæˆå›¾åƒç®€åŒ–äº†æµç¨‹ï¼Œä½†å®ƒä»¬æ— æ³•å¯¹é¢éƒ¨å±æ€§è¿›è¡Œç²¾ç¡®æ§åˆ¶ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬ä»‹ç»äº†ä¸€ç§æ–°é¢–çš„PSTFæ–¹æ³•ï¼Œæ—¢èƒ½å¤Ÿå®ç°å¯¹é¢éƒ¨å±æ€§çš„ç²¾ç¡®æ§åˆ¶ï¼Œåˆèƒ½é«˜åº¦ä¿çœŸåœ°ä¿ç•™é¢éƒ¨èº«ä»½ã€‚æˆ‘ä»¬çš„æ–¹æ³•åˆ©ç”¨é¢éƒ¨è¯†åˆ«æ¨¡å‹æå–é¢éƒ¨èº«ä»½ç‰¹å¾ï¼Œç„¶åå°†å…¶æ˜ å°„åˆ°StyleGAN2çš„$W^+$æ½œåœ¨ç©ºé—´ï¼Œå¹¶ä½¿ç”¨e4eç¼–ç å™¨è¿›è¡Œæ˜ å°„ã€‚æˆ‘ä»¬è¿›ä¸€æ­¥ä½¿ç”¨Triplet-Decoupled Cross-Attentionæ¨¡å—å¢å¼ºæ¨¡å‹ï¼Œè¯¥æ¨¡å—å°†é¢éƒ¨èº«ä»½ã€å±æ€§ç‰¹å¾å’Œæ–‡æœ¬åµŒå…¥é›†æˆåˆ°UNetæ¶æ„ä¸­ï¼Œç¡®ä¿èº«ä»½å’Œå±æ€§ä¿¡æ¯çš„æ¸…æ™°åˆ†ç¦»ã€‚æˆ‘ä»¬çš„æ–¹æ³•åœ¨FFHQæ•°æ®é›†ä¸Šè¿›è¡Œè®­ç»ƒï¼Œå…è®¸ç”Ÿæˆå…·æœ‰å¯¹é¢éƒ¨å±æ€§è¿›è¡Œç²¾ç»†æ§åˆ¶çš„ä¸ªæ€§åŒ–å›¾åƒï¼ŒåŒæ—¶æ— éœ€é’ˆå¯¹ä¸ªåˆ«èº«ä»½è¿›è¡Œå¾®è°ƒæˆ–æä¾›é¢å¤–çš„è®­ç»ƒæ•°æ®ã€‚æˆ‘ä»¬è¯æ˜æˆ‘ä»¬çš„æ–¹æ³•æˆåŠŸåœ°åœ¨ä¸ªæ€§åŒ–å’Œç²¾ç¡®é¢éƒ¨å±æ€§æ§åˆ¶ä¹‹é—´å–å¾—äº†å¹³è¡¡ï¼Œä¸ºé«˜è´¨é‡ã€å¯é€‚åº”çš„é¢éƒ¨å›¾åƒåˆæˆæä¾›äº†æ›´é«˜æ•ˆå’Œç”¨æˆ·å‹å¥½çš„è§£å†³æ–¹æ¡ˆã€‚ä»£ç å…¬å¼€åœ¨[<a target="_blank" rel="noopener" href="https://github.com/UnicomAI/PSTF-AttControl%E3%80%82]">https://github.com/UnicomAI/PSTF-AttControlã€‚]</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.25084v1">PDF</a> Accepted by Image and Vision Computing (18 pages, 8 figures)</p>
<p><strong>Summary</strong><br>     æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„ä¸ªæ€§åŒ–å›¾åƒç”Ÿæˆæ–¹æ³•ï¼Œèƒ½å¤Ÿåœ¨æ— éœ€é’ˆå¯¹ä¸ªäººè¿›è¡Œå¾®è°ƒï¼ˆPSTFï¼‰çš„æƒ…å†µä¸‹ï¼Œå®ç°å¯¹é¢éƒ¨ç‰¹å¾çš„ç²¾ç»†æ§åˆ¶å¹¶é«˜åº¦ä¿æŒé¢éƒ¨èº«ä»½ç‰¹å¾ã€‚è¯¥æ–¹æ³•åˆ©ç”¨é¢éƒ¨è¯†åˆ«æ¨¡å‹æå–é¢éƒ¨èº«ä»½ç‰¹å¾ï¼Œå¹¶å°†å…¶æ˜ å°„åˆ°StyleGAN2çš„$W^+$æ½œåœ¨ç©ºé—´ï¼ŒåŒæ—¶é‡‡ç”¨Triplet-Decoupled Cross-Attentionæ¨¡å—æ¥æ•´åˆé¢éƒ¨èº«ä»½ã€å±æ€§ç‰¹å¾å’Œæ–‡æœ¬åµŒå…¥ï¼Œç¡®ä¿èº«ä»½å’Œå±æ€§ä¿¡æ¯çš„æ¸…æ™°åˆ†ç¦»ã€‚åœ¨FFHQæ•°æ®é›†ä¸Šè®­ç»ƒåï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿç”Ÿæˆå…·æœ‰ç²¾ç»†æ§åˆ¶çš„ä¸ªæ€§åŒ–å›¾åƒï¼Œæ— éœ€é’ˆå¯¹ä¸ªäººèº«ä»½è¿›è¡Œé¢å¤–çš„å¾®è°ƒæˆ–è®­ç»ƒæ•°æ®ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>è¯¥æ–¹æ³•å®ç°äº†ä¸ªæ€§åŒ–å›¾åƒç”Ÿæˆä¸­é¢éƒ¨èº«ä»½çš„é«˜åº¦ä¿æŒã€‚</li>
<li>é€šè¿‡æ–°é¢–çš„PSTFæ–¹æ³•ï¼Œå®ç°äº†å¯¹é¢éƒ¨å±æ€§çš„ç²¾ç»†æ§åˆ¶ï¼Œæ— éœ€é’ˆå¯¹ä¸ªäººè¿›è¡Œå¾®è°ƒã€‚</li>
<li>åˆ©ç”¨é¢éƒ¨è¯†åˆ«æ¨¡å‹æå–é¢éƒ¨èº«ä»½ç‰¹å¾ï¼Œå¹¶æ˜ å°„åˆ°StyleGAN2çš„$W^+$æ½œåœ¨ç©ºé—´ã€‚</li>
<li>é‡‡ç”¨Triplet-Decoupled Cross-Attentionæ¨¡å—æ•´åˆé¢éƒ¨èº«ä»½ã€å±æ€§ä¿¡æ¯å’Œæ–‡æœ¬åµŒå…¥ã€‚</li>
<li>è¯¥æ–¹æ³•åœ¨FFHQæ•°æ®é›†ä¸Šè¿›è¡Œè®­ç»ƒï¼Œè¯æ˜äº†å…¶æœ‰æ•ˆæ€§å’Œé€‚ç”¨æ€§ã€‚</li>
<li>ç”Ÿæˆçš„å›¾åƒå…·æœ‰é«˜è´¨é‡çš„é¢éƒ¨åˆæˆï¼Œå¹³è¡¡äº†ä¸ªæ€§åŒ–å’Œé¢éƒ¨å±æ€§æ§åˆ¶ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.25084">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-888f5c3a455705330289260cb83c2fdf~resize:0:q75.jpg?source=1f5c5e47&expiration=1762310633&auth_key=1762310633-0-0-bd519117967aeec9ebd3adce516dd638&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="Cross-view-Localization-and-Synthesis-â€“-Datasets-Challenges-and-Opportunities"><a href="#Cross-view-Localization-and-Synthesis-â€“-Datasets-Challenges-and-Opportunities" class="headerlink" title="Cross-view Localization and Synthesis â€“ Datasets, Challenges and   Opportunities"></a>Cross-view Localization and Synthesis â€“ Datasets, Challenges and   Opportunities</h2><p><strong>Authors:Ningli Xu, Rongjun Qin</strong></p>
<p>Cross-view localization and synthesis are two fundamental tasks in cross-view visual understanding, which deals with cross-view datasets: overhead (satellite or aerial) and ground-level imagery. These tasks have gained increasing attention due to their broad applications in autonomous navigation, urban planning, and augmented reality. Cross-view localization aims to estimate the geographic position of ground-level images based on information provided by overhead imagery while cross-view synthesis seeks to generate ground-level images based on information from the overhead imagery. Both tasks remain challenging due to significant differences in viewing perspective, resolution, and occlusion, which are widely embedded in cross-view datasets. Recent years have witnessed rapid progress driven by the availability of large-scale datasets and novel approaches. Typically, cross-view localization is formulated as an image retrieval problem where ground-level features are matched with tiled overhead images feature, extracted by convolutional neural networks (CNNs) or vision transformers (ViTs) for cross-view feature embedding. Cross-view synthesis, on the other hand, seeks to generate ground-level views based on information from overhead imagery, generally using generative adversarial networks (GANs) or diffusion models. This paper presents a comprehensive survey of advances in cross-view localization and synthesis, reviewing widely used datasets, highlighting key challenges, and providing an organized overview of state-of-the-art techniques. Furthermore, it discusses current limitations, offers comparative analyses, and outlines promising directions for future research. We also include the project page via <a target="_blank" rel="noopener" href="https://github.com/GDAOSU/Awesome-Cross-View-Methods">https://github.com/GDAOSU/Awesome-Cross-View-Methods</a>. </p>
<blockquote>
<p>è·¨è§†å›¾å®šä½ä¸åˆæˆæ˜¯è·¨è§†å›¾è§†è§‰ç†è§£ä¸­çš„ä¸¤ä¸ªåŸºæœ¬ä»»åŠ¡ï¼Œè¯¥é¢†åŸŸå¤„ç†è·¨è§†å›¾æ•°æ®é›†ï¼šä¿¯è§†å›¾ï¼ˆå«æ˜Ÿæˆ–èˆªç©ºï¼‰å’Œåœ°é¢çº§åˆ«å›¾åƒã€‚è¿™äº›ä»»åŠ¡åœ¨è‡ªä¸»å¯¼èˆªã€åŸå¸‚è§„åˆ’å’Œå¢å¼ºç°å®ç­‰é¢†åŸŸæœ‰ç€å¹¿æ³›çš„åº”ç”¨ï¼Œå› æ­¤å—åˆ°äº†è¶Šæ¥è¶Šå¤šçš„å…³æ³¨ã€‚è·¨è§†å›¾å®šä½æ—¨åœ¨åŸºäºä¿¯è§†å›¾å›¾åƒæä¾›çš„ä¿¡æ¯æ¥ä¼°è®¡åœ°é¢å›¾åƒçš„åœ°ç†ä½ç½®ï¼Œè€Œè·¨è§†å›¾åˆæˆåˆ™æ—¨åœ¨åŸºäºä¿¯è§†å›¾å›¾åƒçš„ä¿¡æ¯ç”Ÿæˆåœ°é¢å›¾åƒã€‚è¿™ä¸¤ä¸ªä»»åŠ¡ä»ç„¶å­˜åœ¨æŒ‘æˆ˜ï¼Œå› ä¸ºè§†å›¾è§’åº¦ã€åˆ†è¾¨ç‡å’Œé®æŒ¡ç­‰æ–¹é¢çš„å·¨å¤§å·®å¼‚æ™®éå­˜åœ¨äºè·¨è§†å›¾æ•°æ®é›†ä¸­ã€‚è¿‘å¹´æ¥ï¼Œç”±äºå¤§è§„æ¨¡æ•°æ®é›†å’Œæ–°é¢–æ–¹æ³•çš„å‡ºç°ï¼Œè¿›å±•è¿…é€Ÿã€‚é€šå¸¸ï¼Œè·¨è§†å›¾å®šä½è¢«åˆ¶å®šä¸ºå›¾åƒæ£€ç´¢é—®é¢˜ï¼Œå…¶ä¸­åœ°é¢ç‰¹å¾ä¼šä¸ç“¦ç‰‡ä¿¯è§†å›¾å›¾åƒç‰¹å¾è¿›è¡ŒåŒ¹é…ï¼Œè¿™äº›ç‰¹å¾é€šè¿‡å·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNï¼‰æˆ–è§†è§‰è½¬æ¢å™¨ï¼ˆViTï¼‰è¿›è¡Œè·¨è§†å›¾ç‰¹å¾åµŒå…¥ã€‚å¦ä¸€æ–¹é¢ï¼Œè·¨è§†å›¾åˆæˆåˆ™æ—¨åœ¨åŸºäºä¿¯è§†å›¾å›¾åƒçš„ä¿¡æ¯ç”Ÿæˆåœ°é¢è§†å›¾ï¼Œé€šå¸¸ä½¿ç”¨ç”Ÿæˆå¯¹æŠ—ç½‘ç»œï¼ˆGANï¼‰æˆ–æ‰©æ•£æ¨¡å‹ã€‚æœ¬æ–‡å¯¹è·¨è§†å›¾å®šä½å’Œåˆæˆçš„è¿›å±•è¿›è¡Œäº†å…¨é¢çš„ç»¼è¿°ï¼Œå›é¡¾äº†å¹¿æ³›ä½¿ç”¨çš„æ•°æ®é›†ï¼Œå¼ºè°ƒäº†å…³é”®æŒ‘æˆ˜ï¼Œå¹¶æä¾›äº†æœ€æ–°æŠ€æœ¯çš„æœ‰æ¡ç†æ¦‚è¿°ã€‚æ­¤å¤–ï¼Œå®ƒè¿˜è®¨è®ºäº†å½“å‰å±€é™æ€§ã€æä¾›äº†æ¯”è¾ƒåˆ†æï¼Œå¹¶æ¦‚è¿°äº†æœªæ¥ç ”ç©¶çš„æœ‰å‰é€”çš„æ–¹å‘ã€‚æˆ‘ä»¬è¿˜é€šè¿‡<a target="_blank" rel="noopener" href="https://github.com/GDAOSU/Awesome-Cross-View-Methods%E5%8C%85%E5%90%AB%E9%A1%B9%E7%9B%AE%E9%A1%B5%E9%9D%A2%E3%80%82">https://github.com/GDAOSU/Awesome-Cross-View-MethodsåŒ…å«é¡¹ç›®é¡µé¢ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.22736v2">PDF</a> 15 Figures</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡å…¨é¢æ¦‚è¿°äº†è·¨è§†è§’å®šä½ä¸åˆæˆçš„ç ”ç©¶è¿›å±•ï¼Œä»‹ç»äº†å¸¸ç”¨æ•°æ®é›†ï¼Œå¼ºè°ƒäº†å…³é”®æŒ‘æˆ˜ï¼Œæä¾›äº†æœ€æ–°æŠ€æœ¯çš„æœ‰åºæ¦‚è§ˆã€‚æ–‡ç« è®¨è®ºäº†å½“å‰é™åˆ¶ï¼Œè¿›è¡Œäº†æ¯”è¾ƒåˆ†æï¼Œå¹¶æŒ‡å‡ºäº†æœªæ¥ç ”ç©¶çš„æœ‰å‰é€”çš„æ–¹å‘ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>è·¨è§†è§’å®šä½ä¸åˆæˆæ˜¯å¤„ç†è·¨è§†è§’æ•°æ®é›†ï¼ˆåŒ…æ‹¬ä¿¯è§†å›¾å’Œåœ°é¢çº§å›¾åƒï¼‰çš„ä¸¤ä¸ªåŸºæœ¬ä»»åŠ¡ï¼Œå¹¿æ³›åº”ç”¨äºè‡ªä¸»å¯¼èˆªã€åŸå¸‚è§„åˆ’å’Œå¢å¼ºç°å®ã€‚</li>
<li>è·¨è§†è§’å®šä½æ—¨åœ¨æ ¹æ®ä¿¯è§†å›¾ä¿¡æ¯ä¼°è®¡åœ°é¢çº§å›¾åƒçš„åœ°ç†ä½ç½®ã€‚</li>
<li>è·¨è§†è§’åˆæˆåˆ™æ—¨åœ¨åŸºäºä¿¯è§†å›¾ä¿¡æ¯ç”Ÿæˆåœ°é¢çº§å›¾åƒã€‚</li>
<li>è¿™ä¸¤ä¸ªä»»åŠ¡é¢ä¸´çš„ä¸»è¦æŒ‘æˆ˜åŒ…æ‹¬è§†è§’ã€åˆ†è¾¨ç‡å’Œé®æŒ¡çš„æ˜¾è‘—å·®å¼‚ã€‚</li>
<li>è·¨è§†è§’å®šä½é€šå¸¸è¢«åˆ¶å®šä¸ºå›¾åƒæ£€ç´¢é—®é¢˜ï¼Œå…¶ä¸­åœ°é¢ç‰¹å¾ä¼šä¸åˆ‡å‰²çš„ä¿¯è§†å›¾ç‰¹å¾è¿›è¡ŒåŒ¹é…ã€‚</li>
<li>è·¨è§†è§’åˆæˆé€šå¸¸ä½¿ç”¨ç”Ÿæˆå¯¹æŠ—ç½‘ç»œï¼ˆGANsï¼‰æˆ–æ‰©æ•£æ¨¡å‹æ¥åŸºäºä¿¯è§†å›¾ä¿¡æ¯ç”Ÿæˆåœ°é¢çº§è§†å›¾ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.22736">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-e2e15f4bd462a76e632ba7f8cad3193d~resize:0:q75.jpg?source=1f5c5e47&expiration=1762310641&auth_key=1762310641-0-0-b0c13aa1953b6fd97307b7daca4a6270&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-9152fe1d65f0f70cc737b09082dae9c5~resize:0:q75.jpg?source=1f5c5e47&expiration=1762310648&auth_key=1762310648-0-0-61f2c8490c4a1e9670626978b117e454&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-6f70a148096c4f608ef16e0df6a81055~resize:0:q75.jpg?source=1f5c5e47&expiration=1762310655&auth_key=1762310655-0-0-d31ecf1fc610b3f1835b4a4318c081e4&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-67f80b8c5567312a647bc324244527b4~resize:0:q75.jpg?source=1f5c5e47&expiration=1762310662&auth_key=1762310662-0-0-288539ed7336417c096374c43cefb2a6&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-fea87ab0ef324ca484facd451c7dcd8d~resize:0:q75.jpg?source=1f5c5e47&expiration=1762310668&auth_key=1762310668-0-0-48a05131a5742fb24e1623aa61ae4d7e&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="Wavelet-based-GAN-Fingerprint-Detection-using-ResNet50"><a href="#Wavelet-based-GAN-Fingerprint-Detection-using-ResNet50" class="headerlink" title="Wavelet-based GAN Fingerprint Detection using ResNet50"></a>Wavelet-based GAN Fingerprint Detection using ResNet50</h2><p><strong>Authors:Sai Teja Erukude, Suhasnadh Reddy Veluru, Viswa Chaitanya Marella</strong></p>
<p>Identifying images generated by Generative Adversarial Networks (GANs) has become a significant challenge in digital image forensics. This research presents a wavelet-based detection method that uses discrete wavelet transform (DWT) preprocessing and a ResNet50 classification layer to differentiate the StyleGAN-generated images from real ones. Haar and Daubechies wavelet filters are applied to convert the input images into multi-resolution representations, which will then be fed to a ResNet50 network for classification, capitalizing on subtle artifacts left by the generative process. Moreover, the wavelet-based models are compared to an identical ResNet50 model trained on spatial data. The Haar and Daubechies preprocessed models achieved a greater accuracy of 93.8 percent and 95.1 percent, much higher than the model developed in the spatial domain (accuracy rate of 81.5 percent). The Daubechies-based model outperforms Haar, showing that adding layers of descriptive frequency patterns can lead to even greater distinguishing power. These results indicate that the GAN-generated images have unique wavelet-domain artifacts or â€œfingerprints.â€ The method proposed illustrates the effectiveness of wavelet-domain analysis to detect GAN images and emphasizes the potential of further developing the capabilities of future deepfake detection systems. </p>
<blockquote>
<p>é‰´åˆ«ç”Ÿæˆå¯¹æŠ—ç½‘ç»œï¼ˆGANsï¼‰ç”Ÿæˆçš„å›¾åƒå·²æˆä¸ºæ•°å­—å›¾åƒå–è¯é¢†åŸŸçš„ä¸€ä¸ªé‡è¦æŒ‘æˆ˜ã€‚æœ¬ç ”ç©¶æå‡ºäº†ä¸€ç§åŸºäºå°æ³¢çš„æ£€æµ‹æ–¹æ³•ï¼Œè¯¥æ–¹æ³•ä½¿ç”¨ç¦»æ•£å°æ³¢å˜æ¢ï¼ˆDWTï¼‰é¢„å¤„ç†å’ŒResNet50åˆ†ç±»å±‚æ¥åŒºåˆ†StyleGANç”Ÿæˆçš„å›¾åƒå’ŒçœŸå®å›¾åƒã€‚é‡‡ç”¨Haarå’ŒDaubechieså°æ³¢æ»¤æ³¢å™¨å°†è¾“å…¥å›¾åƒè½¬æ¢ä¸ºå¤šåˆ†è¾¨ç‡è¡¨ç¤ºå½¢å¼ï¼Œç„¶åå°†å…¶è¾“å…¥ResNet50ç½‘ç»œè¿›è¡Œåˆ†ç±»ï¼Œå……åˆ†åˆ©ç”¨ç”Ÿæˆè¿‡ç¨‹ç•™ä¸‹çš„ç»†å¾®ç—•è¿¹ã€‚æ­¤å¤–ï¼Œå°†åŸºäºå°æ³¢æ¨¡å‹çš„æ€§èƒ½ä¸ç»è¿‡ç©ºé—´æ•°æ®è®­ç»ƒçš„ç›¸åŒResNet50æ¨¡å‹è¿›è¡Œäº†æ¯”è¾ƒã€‚Haarå’ŒDaubechiesé¢„å¤„ç†æ¨¡å‹çš„å‡†ç¡®ç‡åˆ†åˆ«è¾¾åˆ°äº†93.8%å’Œ95.1%ï¼Œè¿œé«˜äºåœ¨ç©ºåŸŸå¼€å‘çš„æ¨¡å‹ï¼ˆå‡†ç¡®ç‡ä¸º81.5%ï¼‰ã€‚åŸºäºDaubechiesçš„æ¨¡å‹è¡¨ç°ä¼˜äºHaaræ¨¡å‹ï¼Œè¡¨æ˜æ·»åŠ æè¿°æ€§é¢‘ç‡æ¨¡å¼å±‚å¯ä»¥å¯¼è‡´æ›´é«˜çš„åŒºåˆ†èƒ½åŠ›ã€‚è¿™äº›ç»“æœè¡¨æ˜ï¼ŒGANç”Ÿæˆçš„å›¾åƒå…·æœ‰ç‹¬ç‰¹çš„å°æ³¢åŸŸç‰¹å¾æˆ–â€œæŒ‡çº¹â€ã€‚æ‰€æå‡ºçš„æ–¹æ³•è¯´æ˜äº†å°æ³¢åŸŸåˆ†æåœ¨æ£€æµ‹GANå›¾åƒæ—¶çš„æœ‰æ•ˆæ€§ï¼Œå¹¶å¼ºè°ƒäº†æœªæ¥è¿›ä¸€æ­¥å‘å±•æ·±åº¦ä¼ªé€ æ£€æµ‹ç³»ç»Ÿæ½œåŠ›çš„å·¨å¤§ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.21822v1">PDF</a> 6 pages; Published in IEEE</p>
<p><strong>Summary</strong><br>     æœ¬æ–‡æå‡ºä¸€ç§åŸºäºå°æ³¢çš„æ£€æµ‹æ–¹æ³•ï¼Œåˆ©ç”¨ç¦»æ•£å°æ³¢å˜æ¢é¢„å¤„ç†å’ŒResNet50åˆ†ç±»å±‚æ¥åŒºåˆ†StyleGANç”Ÿæˆçš„å›¾åƒä¸çœŸå®å›¾åƒã€‚ç ”ç©¶ç»“æœè¡¨æ˜ï¼Œé€šè¿‡Haarå’ŒDaubechieså°æ³¢è¿‡æ»¤å™¨é¢„å¤„ç†å›¾åƒåï¼Œç»“åˆResNet50ç½‘ç»œåˆ†ç±»ï¼Œå¯ä»¥æœ‰æ•ˆè¯†åˆ«å‡ºGANç”Ÿæˆçš„å›¾åƒï¼Œå‡†ç¡®ç‡é«˜è¾¾93.8%å’Œ95.1%ã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜å‘ç°ï¼Œåœ¨é¢‘ç‡åŸŸæ·»åŠ æè¿°æ€§æ¨¡å¼å±‚å¯ä»¥æé«˜æ¨¡å‹çš„åŒºåˆ†èƒ½åŠ›ã€‚è¿™è¡¨æ˜GANç”Ÿæˆçš„å›¾åƒåœ¨å°æ³¢åŸŸå…·æœ‰ç‹¬ç‰¹çš„â€œæŒ‡çº¹â€ç‰¹å¾ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>GANç”Ÿæˆçš„å›¾åƒæ£€æµ‹å·²æˆä¸ºæ•°å­—å›¾åƒå–è¯çš„é‡è¦æŒ‘æˆ˜ã€‚</li>
<li>ç ”ç©¶æå‡ºäº†ä¸€ç§åŸºäºå°æ³¢çš„æ£€æµ‹æ–¹æ³•ï¼Œé€šè¿‡ç¦»æ•£å°æ³¢å˜æ¢é¢„å¤„ç†å›¾åƒæ•°æ®ã€‚</li>
<li>åˆ©ç”¨ResNet50åˆ†ç±»å±‚å¯¹StyleGANç”Ÿæˆçš„å›¾åƒè¿›è¡Œé‰´åˆ«ï¼Œæé«˜äº†æ£€æµ‹çš„å‡†ç¡®æ€§ã€‚</li>
<li>Haarå’ŒDaubechieså°æ³¢æ»¤æ³¢å™¨é¢„å¤„ç†å›¾åƒåï¼Œå‡†ç¡®ç‡åˆ†åˆ«è¾¾åˆ°93.8%å’Œ95.1%ã€‚</li>
<li>å¯¹æ¯”ç ”ç©¶æ˜¾ç¤ºäº†åœ¨å°æ³¢åŸŸåˆ†æçš„ä¼˜è¶Šæ€§ä»¥åŠå…¶å¯¹GANå›¾åƒæ£€æµ‹çš„æœ‰æ•ˆæ€§ã€‚</li>
<li>Daubechiesæ»¤æ³¢å™¨ç›¸æ¯”Haaræ»¤æ³¢å™¨åœ¨æ£€æµ‹ä¸­è¡¨ç°æ›´å¥½ï¼Œæ˜¾ç¤ºæ·»åŠ æè¿°æ€§é¢‘ç‡æ¨¡å¼å±‚èƒ½æé«˜æ¨¡å‹çš„åŒºåˆ†èƒ½åŠ›ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.21822">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-eab16bf3846b427929a529f83eef1d0d~resize:0:q75.jpg?source=1f5c5e47&expiration=1762310677&auth_key=1762310677-0-0-e19dc648be7f08a34b25887a8e6d844c&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-6c271502d445b56f4877db79d66d2f97~resize:0:q75.jpg?source=1f5c5e47&expiration=1762310684&auth_key=1762310684-0-0-2a0d1235435ef2213cfa908c68c9ebb6&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-84068c6e2fb17168454e293d437cbd75~resize:0:q75.jpg?source=1f5c5e47&expiration=1762310691&auth_key=1762310691-0-0-5aa155378505f6371211a62e003ca32e&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-7f39f77394679b4b1064a458dc0dabb7~resize:0:q75.jpg?source=1f5c5e47&expiration=1762310697&auth_key=1762310697-0-0-139ec900c3e2bcf30ab6b90ff635c684&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-03e886caa50ad49789fdbb6ab9ed6d79~resize:0:q75.jpg?source=1f5c5e47&expiration=1762310704&auth_key=1762310704-0-0-254ac2c47d5a4003adf360f8a1af9abc&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-44f099d6e1cf94885692a948a6447026~resize:0:q75.jpg?source=1f5c5e47&expiration=1762310711&auth_key=1762310711-0-0-b07c7a5dc13314e54391c02f3038b90c&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-c8f168153f960103cb5fdbe3d9ac74f6~resize:0:q75.jpg?source=1f5c5e47&expiration=1762310717&auth_key=1762310717-0-0-d336b8109326a2bc6b5f8b3223553d31&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-70e4483a35673b51ff2c2c26ce996834~resize:0:q75.jpg?source=1f5c5e47&expiration=1762310724&auth_key=1762310724-0-0-4626ff8d8c1d1a52bab4bd0371446a75&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="GENRE-CMR-Generalizable-Deep-Learning-for-Diverse-Multi-Domain-Cardiac-MRI-Reconstruction"><a href="#GENRE-CMR-Generalizable-Deep-Learning-for-Diverse-Multi-Domain-Cardiac-MRI-Reconstruction" class="headerlink" title="GENRE-CMR: Generalizable Deep Learning for Diverse Multi-Domain Cardiac   MRI Reconstruction"></a>GENRE-CMR: Generalizable Deep Learning for Diverse Multi-Domain Cardiac   MRI Reconstruction</h2><p><strong>Authors:Kian Anvari Hamedani, Narges Razizadeh, Shahabedin Nabavi, Mohsen Ebrahimi Moghaddam</strong></p>
<p>Accelerated Cardiovascular Magnetic Resonance (CMR) image reconstruction remains a critical challenge due to the trade-off between scan time and image quality, particularly when generalizing across diverse acquisition settings. We propose GENRE-CMR, a generative adversarial network (GAN)-based architecture employing a residual deep unrolled reconstruction framework to enhance reconstruction fidelity and generalization. The architecture unrolls iterative optimization into a cascade of convolutional subnetworks, enriched with residual connections to enable progressive feature propagation from shallow to deeper stages. To further improve performance, we integrate two loss functions: (1) an Edge-Aware Region (EAR) loss, which guides the network to focus on structurally informative regions and helps prevent common reconstruction blurriness; and (2) a Statistical Distribution Alignment (SDA) loss, which regularizes the feature space across diverse data distributions via a symmetric KL divergence formulation. Extensive experiments confirm that GENRE-CMR surpasses state-of-the-art methods on training and unseen data, achieving 0.9552 SSIM and 38.90 dB PSNR on unseen distributions across various acceleration factors and sampling trajectories. Ablation studies confirm the contribution of each proposed component to reconstruction quality and generalization. Our framework presents a unified and robust solution for high-quality CMR reconstruction, paving the way for clinically adaptable deployment across heterogeneous acquisition protocols. </p>
<blockquote>
<p>åœ¨å¿ƒè¡€ç®¡ç£å…±æŒ¯ï¼ˆCMRï¼‰å›¾åƒé‡å»ºä¸­ï¼Œç”±äºæ‰«ææ—¶é—´ä¸å›¾åƒè´¨é‡ä¹‹é—´çš„æƒè¡¡ï¼Œç‰¹åˆ«æ˜¯åœ¨ä¸åŒé‡‡é›†ç¯å¢ƒä¸­çš„åº”ç”¨æ¨å¹¿æ–¹é¢ï¼Œä»é¢ä¸´é‡å¤§æŒ‘æˆ˜ã€‚æˆ‘ä»¬æå‡ºäº†åŸºäºç”Ÿæˆå¯¹æŠ—ç½‘ç»œï¼ˆGANï¼‰çš„GENRE-CMRæ¶æ„ï¼Œé‡‡ç”¨æ®‹å·®æ·±åº¦å±•å¼€é‡å»ºæ¡†æ¶ï¼Œä»¥æé«˜é‡å»ºçš„ä¿çœŸåº¦å’Œæ³›åŒ–èƒ½åŠ›ã€‚è¯¥æ¶æ„å°†è¿­ä»£ä¼˜åŒ–å±•å¼€æˆå·ç§¯å­ç½‘ç»œçš„çº§è”ï¼Œå¹¶åŠ å…¥æ®‹å·®è¿æ¥ï¼Œä»¥å®ç°ä»æµ…å±‚åˆ°æ·±å±‚é˜¶æ®µçš„æ¸è¿›ç‰¹å¾ä¼ æ’­ã€‚ä¸ºäº†è¿›ä¸€æ­¥æé«˜æ€§èƒ½ï¼Œæˆ‘ä»¬æ•´åˆäº†ä¸¤ç§æŸå¤±å‡½æ•°ï¼šï¼ˆ1ï¼‰è¾¹ç¼˜æ„ŸçŸ¥åŒºåŸŸï¼ˆEARï¼‰æŸå¤±ï¼Œå¼•å¯¼ç½‘ç»œå…³æ³¨ç»“æ„ä¿¡æ¯ä¸°å¯Œçš„åŒºåŸŸï¼Œæœ‰åŠ©äºé˜²æ­¢å¸¸è§çš„é‡å»ºæ¨¡ç³Šï¼›ï¼ˆ2ï¼‰ç»Ÿè®¡åˆ†å¸ƒå¯¹é½ï¼ˆSDAï¼‰æŸå¤±ï¼Œé€šè¿‡å¯¹ç§°KLæ•£åº¦å…¬å¼ï¼Œæ­£è§„åŒ–ä¸åŒæ•°æ®åˆ†å¸ƒçš„ç‰¹å¾ç©ºé—´ã€‚å¤§é‡å®éªŒè¯å®ï¼ŒGENRE-CMRåœ¨è®­ç»ƒå’Œæœªè§æ•°æ®ä¸Šè¶…è¶Šäº†æœ€å…ˆè¿›çš„æ–¹æ³•ï¼Œåœ¨æœªè§åˆ†å¸ƒçš„å„ç§åŠ é€Ÿå› å­å’Œé‡‡æ ·è½¨è¿¹ä¸Šè¾¾åˆ°äº†0.9552çš„ç»“æ„ç›¸ä¼¼æ€§æŒ‡æ ‡ï¼ˆSSIMï¼‰å’Œ38.90åˆ†è´çš„å³°å€¼ä¿¡å™ªæ¯”ï¼ˆPSNRï¼‰ã€‚æ¶ˆèç ”ç©¶è¯å®äº†æ¯ä¸ªæ‰€æå‡ºç»„ä»¶å¯¹é‡å»ºè´¨é‡å’Œæ¨å¹¿çš„è´¡çŒ®ã€‚æˆ‘ä»¬çš„æ¡†æ¶ä¸ºé«˜è´¨é‡CMRé‡å»ºæä¾›äº†ç»Ÿä¸€ä¸”ç¨³å¥çš„è§£å†³æ–¹æ¡ˆï¼Œä¸ºåœ¨ä¸åŒå¼‚è´¨é‡‡é›†åè®®ä¸­çš„ä¸´åºŠé€‚åº”æ€§éƒ¨ç½²é“ºå¹³äº†é“è·¯ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.20600v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>åŸºäºç”Ÿæˆå¯¹æŠ—ç½‘ç»œï¼ˆGANï¼‰çš„GENRE-CMRå›¾åƒé‡å»ºæŠ€æœ¯åˆ©ç”¨æ·±åº¦å±•å¼€é‡å»ºæ¡†æ¶æå‡äº†å›¾åƒé‡å»ºçš„çœŸå®æ€§å’Œæ³›åŒ–èƒ½åŠ›ã€‚å®ƒé€šè¿‡ç»“åˆè¾¹ç¼˜æ„ŸçŸ¥åŒºåŸŸï¼ˆEARï¼‰æŸå¤±å’Œç»Ÿè®¡åˆ†å¸ƒå¯¹é½ï¼ˆSDAï¼‰æŸå¤±æ¥ä¼˜åŒ–æ€§èƒ½ã€‚è¯¥æŠ€æœ¯åœ¨å¯¹å¤šç§åŠ é€Ÿå› å­å’Œé‡‡æ ·è½¨è¿¹çš„æœªè§æ•°æ®é›†ä¸Šè¡¨ç°ä¼˜å¼‚ï¼Œä¸ºä¸´åºŠéƒ¨ç½²æä¾›äº†å¯èƒ½ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>GENRE-CMRæ˜¯ä¸€ç§åŸºäºGANçš„CMRIå›¾åƒé‡å»ºæ–¹æ³•ï¼Œé‡‡ç”¨æ·±åº¦å±•å¼€é‡å»ºæ¡†æ¶ä»¥æé«˜é‡å»ºè´¨é‡å’Œæ³›åŒ–èƒ½åŠ›ã€‚</li>
<li>è¯¥æŠ€æœ¯ç»“åˆäº†ä¸¤ç§æŸå¤±å‡½æ•°ï¼šEARæŸå¤±ç”¨äºå…³æ³¨ç»“æ„ä¿¡æ¯ä¸°å¯Œçš„åŒºåŸŸï¼Œé˜²æ­¢é‡å»ºæ¨¡ç³Šï¼›SDAæŸå¤±é€šè¿‡å¯¹ç§°KLæ•£åº¦å…¬å¼å¯¹ç‰¹å¾ç©ºé—´è¿›è¡Œè§„èŒƒåŒ–ï¼Œé€‚åº”ä¸åŒçš„æ•°æ®åˆ†å¸ƒã€‚</li>
<li>å®éªŒè¡¨æ˜ï¼ŒGENRE-CMRåœ¨è®­ç»ƒå’Œæœªè§æ•°æ®ä¸Šçš„è¡¨ç°å‡è¶…è¶Šäº†ç°æœ‰æ–¹æ³•ï¼Œå®ç°äº†é«˜é‡å»ºè´¨é‡å’Œæ³›åŒ–èƒ½åŠ›ã€‚</li>
<li>æ¶ˆèç ”ç©¶è¯å®äº†æ‰€æå‡ºç»„ä»¶å¯¹é‡å»ºè´¨é‡å’Œæ³›åŒ–çš„è´¡çŒ®ã€‚</li>
<li>è¯¥æŠ€æœ¯ä¸ºé«˜è´¨é‡CMRIå›¾åƒé‡å»ºæä¾›äº†ç»Ÿä¸€ä¸”ç¨³å¥çš„è§£å†³æ–¹æ¡ˆï¼Œæœ‰æœ›åœ¨å¤šç§ä¸åŒçš„é‡‡é›†åè®®ä¸­å®ç°ä¸´åºŠéƒ¨ç½²ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.20600">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-30fa05b74c6e5166774e40bc908af851~resize:0:q75.jpg?source=1f5c5e47&expiration=1762310730&auth_key=1762310730-0-0-260d182376311e1597a8d05ddc39f99f&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-1109b4a6fcdc8cfddd405424cff595f9~resize:0:q75.jpg?source=1f5c5e47&expiration=1762310738&auth_key=1762310738-0-0-03228f1439ff6173a111be987af1fb56&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-4cd28d3b468472fe2bb303f833c974e2~resize:0:q75.jpg?source=1f5c5e47&expiration=1762310745&auth_key=1762310745-0-0-1a19dd8216312bfe54dde88d9e7ebe51&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="ScoreAdv-Score-based-Targeted-Generation-of-Natural-Adversarial-Examples-via-Diffusion-Models"><a href="#ScoreAdv-Score-based-Targeted-Generation-of-Natural-Adversarial-Examples-via-Diffusion-Models" class="headerlink" title="ScoreAdv: Score-based Targeted Generation of Natural Adversarial   Examples via Diffusion Models"></a>ScoreAdv: Score-based Targeted Generation of Natural Adversarial   Examples via Diffusion Models</h2><p><strong>Authors:Chihan Huang, Hao Tang</strong></p>
<p>Despite the success of deep learning across various domains, it remains vulnerable to adversarial attacks. Although many existing adversarial attack methods achieve high success rates, they typically rely on $\ell_{p}$-norm perturbation constraints, which do not align with human perceptual capabilities. Consequently, researchers have shifted their focus toward generating natural, unrestricted adversarial examples (UAEs). GAN-based approaches suffer from inherent limitations, such as poor image quality due to instability and mode collapse. Meanwhile, diffusion models have been employed for UAE generation, but they still rely on iterative PGD perturbation injection, without fully leveraging their central denoising capabilities. In this paper, we introduce a novel approach for generating UAEs based on diffusion models, named ScoreAdv. This method incorporates an interpretable adversarial guidance mechanism to gradually shift the sampling distribution towards the adversarial distribution, while using an interpretable saliency map to inject the visual information of a reference image into the generated samples. Notably, our method is capable of generating an unlimited number of natural adversarial examples and can attack not only classification models but also retrieval models. We conduct extensive experiments on ImageNet and CelebA datasets, validating the performance of ScoreAdv across ten target models in both black-box and white-box settings. Our results demonstrate that ScoreAdv achieves state-of-the-art attack success rates and image quality, while maintaining inference efficiency. Furthermore, the dynamic balance between denoising and adversarial perturbation enables ScoreAdv to remain robust even under defensive measures. </p>
<blockquote>
<p>å°½ç®¡æ·±åº¦å­¦ä¹ åœ¨å„ç§é¢†åŸŸå–å¾—äº†æˆåŠŸï¼Œä½†å®ƒä»ç„¶å®¹æ˜“å—åˆ°å¯¹æŠ—æ€§æ”»å‡»çš„å½±å“ã€‚è™½ç„¶ç°æœ‰çš„è®¸å¤šå¯¹æŠ—æ€§æ”»å‡»æ–¹æ³•è¾¾åˆ°äº†è¾ƒé«˜çš„æˆåŠŸç‡ï¼Œä½†å®ƒä»¬é€šå¸¸ä¾èµ–äº$\ell_{p}$èŒƒæ•°æ‰°åŠ¨çº¦æŸï¼Œè¿™äº›çº¦æŸå¹¶ä¸ç¬¦åˆäººç±»çš„æ„ŸçŸ¥èƒ½åŠ›ã€‚å› æ­¤ï¼Œç ”ç©¶äººå‘˜å°†é‡ç‚¹è½¬å‘ç”Ÿæˆè‡ªç„¶ã€æ— é™åˆ¶çš„å¯¹æŠ—æ€§ç¤ºä¾‹ï¼ˆUAEsï¼‰ã€‚åŸºäºGANçš„æ–¹æ³•å­˜åœ¨å†…åœ¨å±€é™æ€§ï¼Œä¾‹å¦‚ç”±äºä¸ç¨³å®šå’Œæ¨¡å¼å´©æºƒå¯¼è‡´çš„å›¾åƒè´¨é‡å·®ã€‚åŒæ—¶ï¼Œè™½ç„¶æ‰©æ•£æ¨¡å‹å·²è¢«ç”¨äºUAEç”Ÿæˆï¼Œä½†å®ƒä»¬ä»ç„¶ä¾èµ–äºè¿­ä»£PGDæ‰°åŠ¨æ³¨å…¥ï¼Œæ²¡æœ‰å……åˆ†åˆ©ç”¨å…¶æ ¸å¿ƒçš„é™å™ªèƒ½åŠ›ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬ä»‹ç»äº†ä¸€ç§åŸºäºæ‰©æ•£æ¨¡å‹ç”ŸæˆUAEsçš„æ–°æ–¹æ³•ï¼Œåä¸ºScoreAdvã€‚è¯¥æ–¹æ³•é‡‡ç”¨å¯è§£é‡Šçš„å¯¹æŠ—æ€§æŒ‡å¯¼æœºåˆ¶ï¼Œé€æ­¥å°†é‡‡æ ·åˆ†å¸ƒè½¬å‘å¯¹æŠ—æ€§åˆ†å¸ƒï¼ŒåŒæ—¶ä½¿ç”¨å¯è§£é‡Šæ˜¾è‘—æ€§å›¾å°†å‚è€ƒå›¾åƒçš„å¯è§†ä¿¡æ¯æ³¨å…¥ç”Ÿæˆçš„æ ·æœ¬ä¸­ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œæˆ‘ä»¬çš„æ–¹æ³•èƒ½å¤Ÿç”Ÿæˆæ— é™æ•°é‡çš„è‡ªç„¶å¯¹æŠ—æ€§ç¤ºä¾‹ï¼Œå¹¶ä¸”å¯ä»¥æ”»å‡»åˆ†ç±»æ¨¡å‹ä»¥åŠæ£€ç´¢æ¨¡å‹ã€‚æˆ‘ä»¬åœ¨ImageNetå’ŒCelebAæ•°æ®é›†ä¸Šè¿›è¡Œäº†å¹¿æ³›çš„å®éªŒï¼Œåœ¨é»‘ç™½ç›’è®¾ç½®ä¸­å¯¹ScoreAdvè¿›è¡Œäº†åç§ç›®æ ‡æ¨¡å‹çš„æ€§èƒ½éªŒè¯ã€‚æˆ‘ä»¬çš„ç»“æœè¡¨æ˜ï¼ŒScoreAdvè¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ”»å‡»æˆåŠŸç‡å’Œå›¾åƒè´¨é‡ï¼ŒåŒæ—¶ä¿æŒäº†æ¨ç†æ•ˆç‡ã€‚æ­¤å¤–ï¼Œé™å™ªå’Œå¯¹æŠ—æ€§æ‰°åŠ¨ä¹‹é—´çš„åŠ¨æ€å¹³è¡¡ä½¿ScoreAdvå³ä½¿åœ¨é˜²å¾¡æªæ–½ä¸‹ä¹Ÿèƒ½ä¿æŒç¨³å¥æ€§ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2507.06078v2">PDF</a> </p>
<p><strong>æ‘˜è¦</strong></p>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºæ‰©æ•£æ¨¡å‹çš„æ–°å‹ç”Ÿæˆè‡ªç„¶æ— é™åˆ¶å¯¹æŠ—æ ·æœ¬çš„æ–¹æ³•ï¼Œåä¸ºScoreAdvã€‚è¯¥æ–¹æ³•é€šè¿‡å¯è§£é‡Šçš„å¯¹æŠ—æ€§æŒ‡å¯¼æœºåˆ¶é€æ­¥å°†é‡‡æ ·åˆ†å¸ƒè½¬å‘å¯¹æŠ—åˆ†å¸ƒï¼ŒåŒæ—¶ä½¿ç”¨å¯è§£é‡Šçš„æ˜¾è‘—æ€§åœ°å›¾å°†å‚è€ƒå›¾åƒçš„å¯è§†ä¿¡æ¯æ³¨å…¥ç”Ÿæˆçš„æ ·æœ¬ä¸­ã€‚ScoreAdvä¸ä»…èƒ½ç”Ÿæˆå¤§é‡è‡ªç„¶å¯¹æŠ—æ ·æœ¬ï¼Œè¿˜èƒ½æ”»å‡»åˆ†ç±»æ¨¡å‹å’Œæ£€ç´¢æ¨¡å‹ã€‚åœ¨ImageNetå’ŒCelebAæ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒScoreAdvåœ¨é»‘ç™½ç›’è®¾ç½®ä¸­é’ˆå¯¹åä¸ªç›®æ ‡æ¨¡å‹çš„æ”»å‡»æˆåŠŸç‡åŠå›¾åƒè´¨é‡å‡è¾¾åˆ°ä¸šç•Œæœ€ä½³ï¼ŒåŒæ—¶ä¿æŒæ¨ç†æ•ˆç‡ã€‚å…¶åŠ¨æ€å¹³è¡¡çš„é™å™ªå’Œå¯¹æŠ—æ‰°åŠ¨èƒ½åŠ›ä½¿ScoreAdvåœ¨é˜²å¾¡æªæ–½ä¸‹ä»èƒ½ä¿æŒç¨³å¥ã€‚</p>
<p><strong>å…³é”®è§è§£</strong></p>
<ol>
<li>ç°æœ‰å¯¹æŠ—æ”»å‡»æ–¹æ³•ä¸»è¦ä¾èµ–$\ell_{p}$-normæ‰°åŠ¨çº¦æŸï¼Œä¸ç¬¦åˆäººç±»æ„ŸçŸ¥èƒ½åŠ›ï¼Œç ”ç©¶å·²è½¬å‘ç”Ÿæˆè‡ªç„¶æ— é™åˆ¶å¯¹æŠ—æ ·æœ¬ï¼ˆUAEsï¼‰ã€‚</li>
<li>GANså­˜åœ¨å›¾åƒè´¨é‡å·®çš„é—®é¢˜ï¼Œå¦‚ä¸ç¨³å®šå’Œæ¨¡å¼å´©æºƒç­‰å†…åœ¨å±€é™æ€§ã€‚</li>
<li>æ‰©æ•£æ¨¡å‹å·²è¢«ç”¨äºUAEç”Ÿæˆï¼Œä½†ä»ä¾èµ–è¿­ä»£PGDæ‰°åŠ¨æ³¨å…¥ï¼Œæœªå……åˆ†åˆ©ç”¨å…¶æ ¸å¿ƒå»å™ªèƒ½åŠ›ã€‚</li>
<li>ScoreAdvæ–¹æ³•ç»“åˆæ‰©æ•£æ¨¡å‹ï¼Œé€šè¿‡å¯è§£é‡Šçš„å¯¹æŠ—æŒ‡å¯¼æœºåˆ¶å’Œæ˜¾è‘—æ€§åœ°å›¾ç”ŸæˆUAEsã€‚</li>
<li>ScoreAdvèƒ½ç”Ÿæˆå¤§é‡è‡ªç„¶å¯¹æŠ—æ ·æœ¬ï¼Œå¹¶æ”»å‡»åˆ†ç±»å’Œæ£€ç´¢æ¨¡å‹ã€‚</li>
<li>åœ¨ImageNetå’ŒCelebAæ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ScoreAdvè¾¾åˆ°ä¸šç•Œæœ€ä½³æ”»å‡»æˆåŠŸç‡å’Œå›¾åƒè´¨é‡ï¼ŒåŒæ—¶ä¿æŒæ¨ç†æ•ˆç‡ã€‚</li>
<li>ScoreAdvçš„åŠ¨æ€å¹³è¡¡èƒ½åŠ›ä½¿å…¶åœ¨é˜²å¾¡æªæ–½ä¸‹ä»èƒ½ä¿æŒç¨³å¥ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2507.06078">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-584d056a1913429053a8c64afeaa57f4~resize:0:q75.jpg?source=1f5c5e47&expiration=1762310753&auth_key=1762310753-0-0-27b4d4f9a9cebf71899c40f962f9d40c&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-ae16f944c719c56b27833a8665e6b534~resize:0:q75.jpg?source=1f5c5e47&expiration=1762310760&auth_key=1762310760-0-0-711a86fd49bc798c6000387ad3ebb971&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-89bd4a6bee3cd2d0c91acc52a70619f6~resize:0:q75.jpg?source=1f5c5e47&expiration=1762310767&auth_key=1762310767-0-0-cb48ca0f21a9ce4073c8ad50e4424bed&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-a6e0220884e0c5c71d9eeeedbd057bcb~resize:0:q75.jpg?source=1f5c5e47&expiration=1762310774&auth_key=1762310774-0-0-9db9be0f1d1a767846292a6f82aa4e49&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-5beefea2acf34b4a2c355a58534e23fe~resize:0:q75.jpg?source=1f5c5e47&expiration=1762310781&auth_key=1762310781-0-0-74b4848060860032bdcac6123e5d2a76&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-d683ca3bf144a2c83a76640085c83c65~resize:0:q75.jpg?source=1f5c5e47&expiration=1762310788&auth_key=1762310788-0-0-a2dc210ad58f9df848b5a5b99bbce3ed&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="A-Racing-Dataset-and-Baseline-Model-for-Track-Detection-in-Autonomous-Racing"><a href="#A-Racing-Dataset-and-Baseline-Model-for-Track-Detection-in-Autonomous-Racing" class="headerlink" title="A Racing Dataset and Baseline Model for Track Detection in Autonomous   Racing"></a>A Racing Dataset and Baseline Model for Track Detection in Autonomous   Racing</h2><p><strong>Authors:Shreya Ghosh, Yi-Huan Chen, Ching-Hsiang Huang, Abu Shafin Mohammad Mahdee Jameel, Chien Chou Ho, Aly El Gamal, Samuel Labi</strong></p>
<p>A significant challenge in racing-related research is the lack of publicly available datasets containing raw images with corresponding annotations for the downstream task. In this paper, we introduce RoRaTrack, a novel dataset that contains annotated multi-camera image data from racing scenarios for track detection. The data is collected on a Dallara AV-21 at a racing circuit in Indiana, in collaboration with the Indy Autonomous Challenge (IAC). RoRaTrack addresses common problems such as blurriness due to high speed, color inversion from the camera, and absence of lane markings on the track. Consequently, we propose RaceGAN, a baseline model based on a Generative Adversarial Network (GAN) that effectively addresses these challenges. The proposed model demonstrates superior performance compared to current state-of-the-art machine learning models in track detection. The dataset and code for this work are available at <a target="_blank" rel="noopener" href="https://github.com/ghosh64/RaceGAN">https://github.com/ghosh64/RaceGAN</a>. </p>
<blockquote>
<p>åœ¨èµ›è½¦ç›¸å…³ç ”ç©¶ä¸­ï¼Œä¸€ä¸ªé‡å¤§æŒ‘æˆ˜æ˜¯ç¼ºä¹å…¬å¼€å¯ç”¨çš„æ•°æ®é›†ï¼Œå…¶ä¸­åŒ…å«ç”¨äºä¸‹æ¸¸ä»»åŠ¡çš„åŸå§‹å›¾åƒåŠå…¶ç›¸åº”çš„æ³¨é‡Šã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬ä»‹ç»äº†RoRaTrackæ•°æ®é›†ï¼Œè¿™æ˜¯ä¸€ä¸ªåŒ…å«èµ›è½¦åœºæ™¯çš„å¤šç›¸æœºå›¾åƒæ•°æ®çš„æ–°æ•°æ®é›†ï¼Œç”¨äºè½¦é“æ£€æµ‹ã€‚è¯¥æ•°æ®æ˜¯åœ¨å°ç¬¬å®‰çº³å·çš„ä¸€ä¸ªèµ›è½¦åœºåœ°ä¸Šï¼Œä¸Indy Autonomous Challenge (IAC)åˆä½œï¼Œä½¿ç”¨Dallara AV-21æ”¶é›†çš„ã€‚RoRaTrackè§£å†³äº†ç”±äºé«˜é€Ÿå¯¼è‡´çš„æ¨¡ç³Šã€ç›¸æœºé¢œè‰²åè½¬ä»¥åŠèµ›é“ä¸Šç¼ºå°‘è½¦é“æ ‡è®°ç­‰å¸¸è§é—®é¢˜ã€‚å› æ­¤ï¼Œæˆ‘ä»¬æå‡ºäº†åŸºäºç”Ÿæˆå¯¹æŠ—ç½‘ç»œï¼ˆGANï¼‰çš„RaceGANåŸºçº¿æ¨¡å‹ï¼Œè¯¥æ¨¡å‹å¯ä»¥æœ‰æ•ˆåœ°è§£å†³è¿™äº›æŒ‘æˆ˜ã€‚ä¸å½“å‰æœ€å…ˆè¿›çš„æœºå™¨å­¦ä¹ æ¨¡å‹ç›¸æ¯”ï¼Œæ‰€æå‡ºçš„æ¨¡å‹åœ¨è½¦é“æ£€æµ‹æ–¹é¢è¡¨ç°å‡ºå“è¶Šçš„æ€§èƒ½ã€‚è¯¥æ•°æ®é›†å’Œè¯¥å·¥ä½œçš„ä»£ç å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/ghosh64/RaceGAN%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/ghosh64/RaceGANæ‰¾åˆ°ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.14068v2">PDF</a> Currently Under Review</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†ä¸€é¡¹å…³äºèµ›è½¦ç›¸å…³ç ”ç©¶çš„æŒ‘æˆ˜ï¼šç¼ºä¹å…¬å¼€å¯ç”¨çš„å¸¦æœ‰ç›¸åº”æ³¨é‡Šçš„åŸå§‹å›¾åƒæ•°æ®é›†ç”¨äºä¸‹æ¸¸ä»»åŠ¡ã€‚é’ˆå¯¹è¿™ä¸€é—®é¢˜ï¼Œè®ºæ–‡å¼•å…¥äº†RoRaTrackæ•°æ®é›†ï¼Œè¯¥æ•°æ®é›†åŒ…å«æ¥è‡ªèµ›è½¦åœºæ™¯çš„å¸¦æ³¨é‡Šçš„å¤šç›¸æœºå›¾åƒæ•°æ®ï¼Œç”¨äºè½¦é“æ£€æµ‹ã€‚æ•°æ®æ˜¯åœ¨å°ç¬¬å®‰çº³å·çš„ä¸€ä¸ªèµ›è½¦åœºä½¿ç”¨Dallara AV-21æ”¶é›†çš„ï¼Œå¹¶ä¸Indy Autonomous Challengeï¼ˆIACï¼‰åˆä½œã€‚RoRaTrackè§£å†³äº†ç”±äºé«˜é€Ÿå¯¼è‡´çš„æ¨¡ç³Šã€ç›¸æœºé¢œè‰²åè½¬ä»¥åŠèµ›é“ä¸Šæ— è½¦é“æ ‡è®°ç­‰é—®é¢˜ã€‚ä¸ºæ­¤ï¼Œè®ºæ–‡æå‡ºäº†åŸºäºç”Ÿæˆå¯¹æŠ—ç½‘ç»œï¼ˆGANï¼‰çš„RaceGANåŸºçº¿æ¨¡å‹ï¼Œè¯¥æ¨¡å‹æœ‰æ•ˆè§£å†³äº†è¿™äº›æŒ‘æˆ˜ã€‚ç›¸è¾ƒäºå½“å‰å…ˆè¿›çš„æœºå™¨å­¦ä¹ æ¨¡å‹ï¼Œè¯¥æ¨¡å‹åœ¨è½¦é“æ£€æµ‹æ–¹é¢è¡¨ç°å‡ºå“è¶Šçš„æ€§èƒ½ã€‚ç›¸å…³æ•°æ®é›†å’Œä»£ç å·²å…¬å¼€åˆ†äº«è‡³<a target="_blank" rel="noopener" href="https://github.com/ghosh64/RaceGAN%E3%80%82">https://github.com/ghosh64/RaceGANã€‚</a></p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ç¼ºä¹å…¬å¼€å¯ç”¨çš„å¸¦æœ‰æ³¨é‡Šçš„åŸå§‹å›¾åƒæ•°æ®é›†æ˜¯èµ›è½¦ç›¸å…³ç ”ç©¶çš„æŒ‘æˆ˜ã€‚</li>
<li>è®ºæ–‡å¼•å…¥äº†RoRaTrackæ•°æ®é›†ï¼ŒåŒ…å«å¸¦æ³¨é‡Šçš„å¤šç›¸æœºå›¾åƒæ•°æ®ç”¨äºè½¦é“æ£€æµ‹ã€‚</li>
<li>æ•°æ®æ˜¯åœ¨çœŸå®èµ›è½¦ç¯å¢ƒä¸‹ä½¿ç”¨Dallara AV-21æ”¶é›†çš„ã€‚</li>
<li>RoRaTrackè§£å†³äº†é«˜é€Ÿå¯¼è‡´çš„å›¾åƒæ¨¡ç³Šã€ç›¸æœºé¢œè‰²åè½¬åŠèµ›é“æ— è½¦é“æ ‡è®°ç­‰é—®é¢˜ã€‚</li>
<li>è®ºæ–‡æå‡ºäº†åŸºäºç”Ÿæˆå¯¹æŠ—ç½‘ç»œï¼ˆGANï¼‰çš„RaceGANæ¨¡å‹ï¼Œç”¨äºè§£å†³ç›¸å…³æŒ‘æˆ˜ã€‚</li>
<li>RaceGANæ¨¡å‹åœ¨è½¦é“æ£€æµ‹æ–¹é¢è¡¨ç°å‡ºå“è¶Šæ€§èƒ½ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.14068">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-3fa48e4d69b69ec3d7f75bb587757030~resize:0:q75.jpg?source=1f5c5e47&expiration=1762310796&auth_key=1762310796-0-0-278056334c29aa093b8274aa8b2148f8&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-1142b23b45bb3c162b2b628f8d364524~resize:0:q75.jpg?source=1f5c5e47&expiration=1762310803&auth_key=1762310803-0-0-4a87499f4158eab54f00de38e2bc4c4e&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-d78a64a609f3d24b643b7cdb66350f2c~resize:0:q75.jpg?source=1f5c5e47&expiration=1762310810&auth_key=1762310810-0-0-85d7612581c84095dd91b0db89f12900&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-ef5ca2e8a25f05c01234bc4d1385b8ee~resize:0:q75.jpg?source=1f5c5e47&expiration=1762310817&auth_key=1762310817-0-0-b261a6a72c96b9bc9ac42b3cf7bc07ba&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-0f7a9903c861e8440635fc7da63f5dcf~resize:0:q75.jpg?source=1f5c5e47&expiration=1762310824&auth_key=1762310824-0-0-95edfb5d169bef06a0755bb38db67c7c&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-98b834b7f5a1519eae9497da5b5195b6~resize:0:q75.jpg?source=1f5c5e47&expiration=1762310830&auth_key=1762310830-0-0-ddbee4abf419a101b67203369fc1e9da&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="SRAGAN-Saliency-Regularized-and-Attended-Generative-Adversarial-Network-for-Chinese-Ink-wash-Painting-Style-Transfer"><a href="#SRAGAN-Saliency-Regularized-and-Attended-Generative-Adversarial-Network-for-Chinese-Ink-wash-Painting-Style-Transfer" class="headerlink" title="SRAGAN: Saliency Regularized and Attended Generative Adversarial Network   for Chinese Ink-wash Painting Style Transfer"></a>SRAGAN: Saliency Regularized and Attended Generative Adversarial Network   for Chinese Ink-wash Painting Style Transfer</h2><p><strong>Authors:Xiang Gao, Yuqi Zhang</strong></p>
<p>Recent style transfer problems are still largely dominated by Generative Adversarial Network (GAN) from the perspective of cross-domain image-to-image (I2I) translation, where the pivotal issue is to learn and transfer target-domain style patterns onto source-domain content images. This paper handles the problem of translating real pictures into traditional Chinese ink-wash paintings, i.e., Chinese ink-wash painting style transfer. Though a wide range of I2I models tackle this problem, a notable challenge is that the content details of the source image could be easily erased or corrupted due to the transfer of ink-wash style elements. To remedy this issue, we propose to incorporate saliency detection into the unpaired I2I framework to regularize image content, where the detected saliency map is utilized from two aspects: (\romannumeral1) we propose saliency IOU (SIOU) loss to explicitly regularize object content structure by enforcing saliency consistency before and after image stylization; (\romannumeral2) we propose saliency adaptive normalization (SANorm) which implicitly enhances object structure integrity of the generated paintings by dynamically injecting image saliency information into the generator to guide stylization process. Besides, we also propose saliency attended discriminator which harnesses image saliency information to focus generative adversarial attention onto the drawn objects, contributing to generating more vivid and delicate brush strokes and ink-wash textures. Extensive qualitative and quantitative experiments demonstrate superiority of our approach over related advanced image stylization methods in both GAN and diffusion model paradigms. </p>
<blockquote>
<p>è¿‘æœŸé£æ ¼è¿ç§»é—®é¢˜ä»ä¸»è¦ä»è·¨åŸŸå›¾åƒåˆ°å›¾åƒï¼ˆI2Iï¼‰è½¬æ¢çš„è§’åº¦å—åˆ°ç”Ÿæˆå¯¹æŠ—ç½‘ç»œï¼ˆGANï¼‰çš„ä¸»å¯¼ã€‚è¿™é‡Œçš„å…³é”®é—®é¢˜æ˜¯å­¦ä¹ å’Œå°†ç›®æ ‡åŸŸçš„æ ·å¼æ¨¡å¼è½¬ç§»åˆ°æºåŸŸçš„å†…å®¹å›¾åƒä¸Šã€‚æœ¬æ–‡é’ˆå¯¹å°†çœŸå®å›¾ç‰‡ç¿»è¯‘æˆä¼ ç»Ÿæ°´å¢¨ç”»çš„é—®é¢˜ï¼Œå³æ°´å¢¨ç”»é£æ ¼è¿ç§»ã€‚å°½ç®¡æœ‰è®¸å¤šI2Iæ¨¡å‹è§£å†³äº†è¿™ä¸ªé—®é¢˜ï¼Œä½†ä¸€ä¸ªæ˜¾è‘—çš„æŒ‘æˆ˜æ˜¯æºå›¾åƒçš„å†…å®¹ç»†èŠ‚åœ¨è½¬æ¢æ°´å¢¨é£æ ¼å…ƒç´ æ—¶å¾ˆå®¹æ˜“è¢«æŠ¹å»æˆ–ç ´åã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºå°†æ˜¾è‘—æ€§æ£€æµ‹èå…¥åˆ°éé…å¯¹çš„I2Iæ¡†æ¶ä¸­ä»¥å¯¹å›¾åƒå†…å®¹è¿›è¡Œè§„èŒƒåŒ–ï¼Œåˆ©ç”¨æ£€æµ‹åˆ°çš„æ˜¾è‘—æ€§å›¾ä»ä¸¤ä¸ªæ–¹é¢ï¼šä¸€ã€æˆ‘ä»¬æå‡ºäº†æ˜¾è‘—æ€§IOUï¼ˆSIOUï¼‰æŸå¤±ï¼Œé€šè¿‡å¼ºåˆ¶æ˜¾è‘—æ€§ä¸€è‡´æ€§åœ¨å›¾åƒé£æ ¼åŒ–å‰åæ˜¾å¼åœ°è§„èŒƒå¯¹è±¡å†…å®¹ç»“æ„ï¼›äºŒã€æˆ‘ä»¬æå‡ºäº†æ˜¾è‘—æ€§è‡ªé€‚åº”å½’ä¸€åŒ–ï¼ˆSANormï¼‰ï¼Œå®ƒé€šè¿‡åŠ¨æ€å°†å›¾åƒæ˜¾è‘—æ€§ä¿¡æ¯æ³¨å…¥ç”Ÿæˆå™¨æ¥éšå«åœ°å¢å¼ºç”Ÿæˆç”»ä½œçš„å¯¹è±¡ç»“æ„å®Œæ•´æ€§ï¼Œä»è€ŒæŒ‡å¯¼é£æ ¼åŒ–è¿‡ç¨‹ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜æå‡ºäº†æ˜¾è‘—æ€§å…³æ³¨é‰´åˆ«å™¨ï¼Œå®ƒåˆ©ç”¨å›¾åƒæ˜¾è‘—æ€§ä¿¡æ¯å°†ç”Ÿæˆå¯¹æŠ—çš„æ³¨æ„åŠ›é›†ä¸­åœ¨ç»˜åˆ¶çš„å¯¹è±¡ä¸Šï¼Œæœ‰åŠ©äºç”Ÿæˆæ›´ç”ŸåŠ¨ã€æ›´ç²¾ç»†çš„ç¬”è§¦å’Œæ°´å¢¨çº¹ç†ã€‚å¤§é‡çš„å®šæ€§å’Œå®šé‡å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨GANå’Œæ‰©æ•£æ¨¡å‹èŒƒå¼ä¸­å‡ä¼˜äºç›¸å…³çš„å…ˆè¿›å›¾åƒé£æ ¼åŒ–æ–¹æ³•ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2404.15743v3">PDF</a> Pattern Recognition, Volume 162, June 2025, 111344</p>
<p><strong>Summary</strong><br>åœ¨è·¨åŸŸå›¾åƒåˆ°å›¾åƒï¼ˆI2Iï¼‰ç¿»è¯‘é¢†åŸŸï¼Œç”Ÿæˆå¯¹æŠ—ç½‘ç»œï¼ˆGANï¼‰ä»ç„¶æ˜¯é£æ ¼è½¬ç§»é—®é¢˜çš„ä¸»å¯¼ã€‚æœ¬æ–‡è§£å†³å°†çœŸå®å›¾ç‰‡ç¿»è¯‘æˆä¼ ç»Ÿæ°´å¢¨ç”»çš„é—®é¢˜ï¼Œå³æ°´å¢¨ç”»é£æ ¼è½¬ç§»ã€‚è™½ç„¶æœ‰è®¸å¤šI2Iæ¨¡å‹å¤„ç†è¿™ä¸ªé—®é¢˜ï¼Œä½†ä¸€ä¸ªæ˜¾è‘—æŒ‘æˆ˜æ˜¯æºå›¾åƒçš„å†…å®¹ç»†èŠ‚åœ¨è½¬ç§»æ°´å¢¨é£æ ¼å…ƒç´ æ—¶å®¹æ˜“è¢«æŠ¹å»æˆ–ç ´åã€‚ä¸ºè§£å†³æ­¤é—®é¢˜ï¼Œæˆ‘ä»¬å°†æ˜¾è‘—æ€§æ£€æµ‹èå…¥éé…å¯¹çš„I2Iæ¡†æ¶ä»¥è§„èŒƒå›¾åƒå†…å®¹ã€‚é€šè¿‡ä¸¤ä¸ªæ–¹é¢åˆ©ç”¨æ£€æµ‹åˆ°çš„æ˜¾è‘—æ€§åœ°å›¾ï¼šä¸€æ˜¯æå‡ºæ˜¾è‘—æ€§IOUï¼ˆSIOUï¼‰æŸå¤±ï¼Œé€šè¿‡å¼ºåˆ¶é£æ ¼åŒ–å‰åçš„æ˜¾è‘—æ€§ä¸€è‡´æ€§æ¥æ˜ç¡®è§„èŒƒå¯¹è±¡å†…å®¹ç»“æ„ï¼›äºŒæ˜¯æå‡ºæ˜¾è‘—æ€§è‡ªé€‚åº”å½’ä¸€åŒ–ï¼ˆSANormï¼‰ï¼Œé€šè¿‡åŠ¨æ€å°†å›¾åƒæ˜¾è‘—æ€§ä¿¡æ¯æ³¨å…¥ç”Ÿæˆå™¨ï¼Œéšå¼å¢å¼ºç”Ÿæˆç”»ä½œçš„å¯¹è±¡ç»“æ„å®Œæ•´æ€§ï¼Œä»¥æŒ‡å¯¼é£æ ¼åŒ–è¿‡ç¨‹ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜æå‡ºäº†æ˜¾è‘—æ€§æ³¨æ„åˆ¤åˆ«å™¨ï¼Œåˆ©ç”¨å›¾åƒæ˜¾è‘—æ€§ä¿¡æ¯å°†ç”Ÿæˆå¯¹æŠ—æ³¨æ„åŠ›äºç»˜åˆ¶å¯¹è±¡ä¸Šï¼Œæœ‰åŠ©äºç”Ÿæˆæ›´ç”ŸåŠ¨å’Œç²¾è‡´çš„æ°´å¢¨ç¬”è§¦å’Œçº¹ç†ã€‚å®éªŒè¯æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•ç›¸è¾ƒäºGANå’Œæ‰©æ•£æ¨¡å‹èŒƒå¼ä¸­çš„ç›¸å…³å…ˆè¿›å›¾åƒé£æ ¼åŒ–æ–¹æ³•å…·æœ‰ä¼˜è¶Šæ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>GANåœ¨è·¨åŸŸå›¾åƒé£æ ¼è½¬ç§»ä¸­ä»å ä¸»å¯¼åœ°ä½ï¼Œç‰¹åˆ«æ˜¯åœ¨ä¼ ç»Ÿæ°´å¢¨ç”»é£æ ¼è½¬ç§»æ–¹é¢ã€‚</li>
<li>æ˜¾è‘—æ€§æ£€æµ‹è¢«èå…¥éé…å¯¹I2Iæ¡†æ¶ï¼Œä»¥è§„èŒƒå›¾åƒå†…å®¹ï¼Œè§£å†³æºå›¾åƒå†…å®¹ç»†èŠ‚åœ¨é£æ ¼è½¬ç§»ä¸­å®¹æ˜“ä¸¢å¤±çš„é—®é¢˜ã€‚</li>
<li>æå‡ºäº†æ˜¾è‘—æ€§IOUï¼ˆSIOUï¼‰æŸå¤±å’Œæ˜¾è‘—æ€§è‡ªé€‚åº”å½’ä¸€åŒ–ï¼ˆSANormï¼‰æ–¹æ³•ï¼Œåˆ†åˆ«é€šè¿‡æ˜ç¡®è§„èŒƒå¯¹è±¡å†…å®¹ç»“æ„å’Œéšå¼å¢å¼ºå¯¹è±¡ç»“æ„å®Œæ•´æ€§æ¥æ”¹å–„é£æ ¼è½¬ç§»ç»“æœã€‚</li>
<li>å¼•å…¥æ˜¾è‘—æ€§æ³¨æ„åˆ¤åˆ«å™¨ï¼Œèƒ½å°†ç”Ÿæˆå¯¹æŠ—æ³¨æ„åŠ›äºç»˜åˆ¶å¯¹è±¡ä¸Šï¼Œç”Ÿæˆæ›´ç”ŸåŠ¨å’Œç²¾è‡´çš„æ°´å¢¨ç¬”è§¦å’Œçº¹ç†ã€‚</li>
<li>å®éªŒè¯æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å®šé‡å’Œå®šæ€§æ–¹é¢å‡ä¼˜äºå…¶ä»–å…ˆè¿›çš„å›¾åƒé£æ ¼åŒ–æ–¹æ³•ã€‚</li>
<li>è¯¥æ–¹æ³•å¯¹äºä¿æŠ¤å’Œå‘å±•ä¼ ç»Ÿæ°´å¢¨ç”»è‰ºæœ¯ï¼Œä»¥åŠå®ç°çœŸå®å›¾ç‰‡ä¸è‰ºæœ¯ä½œå“ä¹‹é—´çš„è½¬æ¢å…·æœ‰æ½œåœ¨ä»·å€¼ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2404.15743">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-5799f2c099b33b9b160635053ff8a3aa~resize:0:q75.jpg?source=1f5c5e47&expiration=1762310838&auth_key=1762310838-0-0-244576793ebdd8e1ea17fcd440683de4&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-dfa3d8c03770e2a1e3d63df40c81942f~resize:0:q75.jpg?source=1f5c5e47&expiration=1762310846&auth_key=1762310846-0-0-6a2f721b6668164420e216f6a3584d45&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-fdb1867304a1d698ec5a97aee4cd1b34~resize:0:q75.jpg?source=1f5c5e47&expiration=1762310853&auth_key=1762310853-0-0-566b642dd11eaa22ba1f369081f6e8d8&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1><h2 id="Time-Weaver-A-Conditional-Time-Series-Generation-Model"><a href="#Time-Weaver-A-Conditional-Time-Series-Generation-Model" class="headerlink" title="Time Weaver: A Conditional Time Series Generation Model"></a>Time Weaver: A Conditional Time Series Generation Model</h2><p><strong>Authors:Sai Shankar Narasimhan, Shubhankar Agarwal, Oguzhan Akcin, Sujay Sanghavi, Sandeep Chinchali</strong></p>
<p>Imagine generating a cityâ€™s electricity demand pattern based on weather, the presence of an electric vehicle, and location, which could be used for capacity planning during a winter freeze. Such real-world time series are often enriched with paired heterogeneous contextual metadata (e.g., weather and location). Current approaches to time series generation often ignore this paired metadata. Additionally, the heterogeneity in metadata poses several practical challenges in adapting existing conditional generation approaches from the image, audio, and video domains to the time series domain. To address this gap, we introduce TIME WEAVER, a novel diffusion-based model that leverages the heterogeneous metadata in the form of categorical, continuous, and even time-variant variables to significantly improve time series generation. Additionally, we show that naive extensions of standard evaluation metrics from the image to the time series domain are insufficient. These metrics do not penalize conditional generation approaches for their poor specificity in reproducing the metadata-specific features in the generated time series. Thus, we innovate a novel evaluation metric that accurately captures the specificity of conditional generation and the realism of the generated time series. We show that TIME WEAVER outperforms state-of-the-art benchmarks, such as Generative Adversarial Networks (GANs), by up to 30% in downstream classification tasks on real-world energy, medical, air quality, and traffic datasets. </p>
<blockquote>
<p>æƒ³è±¡ä¸€ä¸‹ï¼ŒåŸºäºå¤©æ°”ã€ç”µåŠ¨æ±½è½¦çš„å­˜åœ¨å’Œä½ç½®ç­‰å› ç´ æ¥ç”ŸæˆåŸå¸‚çš„ç”µåŠ›éœ€æ±‚æ¨¡å¼ï¼Œè¿™å¯ä»¥ç”¨äºåº”å¯¹å†¬å­£ç”µåŠ›çŸ­ç¼ºçš„å®¹é‡è§„åˆ’ã€‚è¿™ç±»ç°å®ä¸–ç•Œçš„æ—¶é—´åºåˆ—æ•°æ®é€šå¸¸æ‹¥æœ‰ä¸°å¯Œçš„é…å¯¹å¼‚æ„ä¸Šä¸‹æ–‡å…ƒæ•°æ®ï¼ˆä¾‹å¦‚å¤©æ°”å’Œä½ç½®ï¼‰ã€‚ç„¶è€Œï¼Œå½“å‰çš„æ—¶é—´åºåˆ—ç”Ÿæˆæ–¹æ³•å¾€å¾€å¿½ç•¥äº†è¿™äº›é…å¯¹å…ƒæ•°æ®ã€‚æ­¤å¤–ï¼Œå…ƒæ•°æ®çš„å¼‚æ„æ€§ç»™é€‚åº”å›¾åƒã€éŸ³é¢‘å’Œè§†é¢‘åŸŸä¸­çš„ç°æœ‰æ¡ä»¶ç”Ÿæˆæ–¹æ³•å¸¦æ¥äº†è¯¸å¤šå®é™…æŒ‘æˆ˜ã€‚ä¸ºäº†å¼¥è¡¥è¿™ä¸€ç©ºç™½ï¼Œæˆ‘ä»¬å¼•å…¥äº†TIME WEAVERï¼Œè¿™æ˜¯ä¸€ç§æ–°å‹åŸºäºæ‰©æ•£çš„æ¨¡å‹ï¼Œå®ƒä»¥ç±»åˆ«ã€è¿ç»­ç”šè‡³æ˜¯æ—¶é—´å˜é‡å½¢å¼çš„å¼‚æ„å…ƒæ•°æ®æ¥æ˜¾è‘—æ”¹è¿›æ—¶é—´åºåˆ—ç”Ÿæˆã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜è¡¨æ˜ï¼Œä»å›¾åƒé¢†åŸŸåˆ°æ—¶é—´åºåˆ—é¢†åŸŸï¼Œæ ‡å‡†è¯„ä¼°æŒ‡æ ‡çš„ç®€å•æ‰©å±•æ˜¯ä¸å¤Ÿçš„ã€‚è¿™äº›æŒ‡æ ‡å¹¶æ²¡æœ‰å› ä¸ºæ¡ä»¶ç”Ÿæˆæ–¹æ³•åœ¨ç”Ÿæˆçš„æ—¶é—´åºåˆ—ä¸­é‡ç°å…ƒæ•°æ®ç‰¹å®šç‰¹å¾çš„ç‰¹å¼‚æ€§ä¸è¶³è€Œå¯¹å…¶è¿›è¡Œæƒ©ç½šã€‚å› æ­¤ï¼Œæˆ‘ä»¬åˆ›æ–°äº†ä¸€ç§æ–°çš„è¯„ä¼°æŒ‡æ ‡ï¼Œèƒ½å¤Ÿå‡†ç¡®æ•æ‰æ¡ä»¶ç”Ÿæˆçš„ç‰¹å¼‚æ€§å’Œç”Ÿæˆæ—¶é—´åºåˆ—çš„ç°å®æ€§ã€‚æˆ‘ä»¬è¯æ˜äº†TIME WEAVERåœ¨ç°å®ä¸–ç•Œçš„æ•°æ®é›†ä¸Šï¼Œåœ¨ä¸‹æ¸¸åˆ†ç±»ä»»åŠ¡ä¸Šçš„è¡¨ç°ä¼˜äºç”Ÿæˆå¯¹æŠ—ç½‘ç»œï¼ˆGANsï¼‰ç­‰æœ€æ–°æŠ€æœ¯åŸºå‡†æµ‹è¯•ï¼Œæé«˜äº†é«˜è¾¾30%ã€‚è¿™åœ¨èƒ½æºã€åŒ»ç–—ã€ç©ºæ°”è´¨é‡å’Œäº¤é€šæ•°æ®é›†ä¸Šéƒ½æœ‰ä½“ç°ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2403.02682v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸ºTIME WEAVERçš„æ–°å‹æ‰©æ•£æ¨¡å‹ï¼Œè¯¥æ¨¡å‹èƒ½å¤Ÿåˆ©ç”¨å¼‚è´¨å…ƒæ•°æ®ï¼ˆå¦‚åˆ†ç±»ã€è¿ç»­å’Œæ—¶é—´å˜é‡ï¼‰æ¥æ”¹å–„æ—¶é—´åºåˆ—ç”Ÿæˆã€‚æ¨¡å‹å¯æ ¹æ®å¤©æ°”ã€ç”µåŠ¨æ±½è½¦çš„å­˜åœ¨å’Œåœ°ç‚¹ç­‰é…å¯¹å…ƒæ•°æ®ç”ŸæˆåŸå¸‚ç”µåŠ›éœ€æ±‚æ¨¡å¼ã€‚åŒæ—¶ï¼Œæœ¬æ–‡è¿˜æå‡ºäº†ä¸€ç§æ–°çš„è¯„ä¼°æŒ‡æ ‡ï¼Œä»¥æ›´å‡†ç¡®åœ°è¡¡é‡æ¡ä»¶ç”Ÿæˆå’Œç”Ÿæˆæ—¶é—´åºåˆ—çš„é€¼çœŸåº¦ã€‚å®éªŒè¡¨æ˜ï¼ŒTIME WEAVERåœ¨çœŸå®ä¸–ç•Œçš„èƒ½æºã€åŒ»ç–—ã€ç©ºæ°”è´¨é‡å’Œäº¤é€šæ•°æ®é›†ä¸Šçš„ä¸‹æ¸¸åˆ†ç±»ä»»åŠ¡ä¸­ï¼Œè¾ƒç”Ÿæˆå¯¹æŠ—ç½‘ç»œï¼ˆGANsï¼‰é«˜å‡º30%çš„è¡¨ç°ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>TIME WEAVERæ¨¡å‹åˆ©ç”¨å¼‚è´¨å…ƒæ•°æ®æ¥æ”¹å–„æ—¶é—´åºåˆ—ç”Ÿæˆã€‚</li>
<li>æ¨¡å‹å¯åŸºäºå¤©æ°”ã€ç”µåŠ¨æ±½è½¦åŠåœ°ç‚¹ç­‰é…å¯¹å…ƒæ•°æ®ç”ŸæˆåŸå¸‚ç”µåŠ›éœ€æ±‚æ¨¡å¼ã€‚</li>
<li>ç°æœ‰è¯„ä¼°æŒ‡æ ‡åœ¨è¡¡é‡æ—¶é—´åºåˆ—ç”Ÿæˆæ—¶å­˜åœ¨ä¸è¶³ï¼Œæ— æ³•å‡†ç¡®åæ˜ å…ƒæ•°æ®å¯¹ç”Ÿæˆç»“æœçš„å½±å“ã€‚</li>
<li>æå‡ºäº†ä¸€ç§æ–°çš„è¯„ä¼°æŒ‡æ ‡ï¼Œä»¥æ›´å‡†ç¡®åœ°è¡¡é‡æ¡ä»¶ç”Ÿæˆå’Œç”Ÿæˆæ—¶é—´åºåˆ—çš„é€¼çœŸåº¦ã€‚</li>
<li>TIME WEAVERæ¨¡å‹åœ¨å¤šä¸ªçœŸå®ä¸–ç•Œæ•°æ®é›†ä¸Šçš„ä¸‹æ¸¸åˆ†ç±»ä»»åŠ¡è¡¨ç°ä¼˜å¼‚ã€‚</li>
<li>è¯¥æ¨¡å‹åœ¨ç”Ÿæˆå¯¹æŠ—ç½‘ç»œï¼ˆGANsï¼‰çš„åŸºç¡€ä¸Šæœ‰æ‰€åˆ›æ–°ï¼Œæé«˜äº†ç”Ÿæˆè´¨é‡ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2403.02682">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic-private.zhihu.com/v2-a587e01105c4e688cf874b183b3d24ec~resize:0:q75.jpg?source=1f5c5e47&expiration=1762310860&auth_key=1762310860-0-0-d8ec6ac056a52a40703c812465008537&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-714c781c617751c6d5d649e157182f59~resize:0:q75.jpg?source=1f5c5e47&expiration=1762310867&auth_key=1762310867-0-0-046c67f2ef329f7ae3b13a7cd812e87b&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-a889a673d74d5359622342f699d0cf77~resize:0:q75.jpg?source=1f5c5e47&expiration=1762310874&auth_key=1762310874-0-0-bcd5c3110bf00e9b926b66795a645eb1&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-b2763b686befff9dda3a9b5d06d03879~resize:0:q75.jpg?source=1f5c5e47&expiration=1762310903&auth_key=1762310903-0-0-60853a32f89b8e7c3ef6e2658cbbfab3&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-9"><a href="#-9" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-11-05/GAN/">https://kedreamix.github.io/Talk2Paper/Paper/2025-11-05/GAN/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/GAN/">
                                    <span class="chip bg-color">GAN</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-11-05/%E5%85%83%E5%AE%87%E5%AE%99_%E8%99%9A%E6%8B%9F%E4%BA%BA/">
                    <div class="card-image">
                        
                        <img src="https://pic-private.zhihu.com/v2-458a143d2cb57029074f19c1e7a98771~resize:0:q75.jpg?source=1f5c5e47&expiration=1762310909&auth_key=1762310909-0-0-2dd2d8fb5d211f09302c99ec20e1bc67&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" class="responsive-img" alt="å…ƒå®‡å®™/è™šæ‹Ÿäºº">
                        
                        <span class="card-title">å…ƒå®‡å®™/è™šæ‹Ÿäºº</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            å…ƒå®‡å®™/è™šæ‹Ÿäºº æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-11-05  ESCA Enabling Seamless Codec Avatar Execution through Algorithm and   Hardware Co-Optimization for Virtual Reality
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-11-05
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/%E5%85%83%E5%AE%87%E5%AE%99-%E8%99%9A%E6%8B%9F%E4%BA%BA/" class="post-category">
                                    å…ƒå®‡å®™/è™šæ‹Ÿäºº
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/%E5%85%83%E5%AE%87%E5%AE%99-%E8%99%9A%E6%8B%9F%E4%BA%BA/">
                        <span class="chip bg-color">å…ƒå®‡å®™/è™šæ‹Ÿäºº</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-11-05/Face%20Swapping/">
                    <div class="card-image">
                        
                        <img src="https://pic-private.zhihu.com/v2-efb8fac75d807eaf0f619a9101b68e1d~resize:0:q75.jpg?source=1f5c5e47&expiration=1762310422&auth_key=1762310422-0-0-e778936d02ee2108e61bd8123c64da3e&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" class="responsive-img" alt="Face Swapping">
                        
                        <span class="card-title">Face Swapping</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Face Swapping æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-11-05  A Dual-Branch CNN for Robust Detection of AI-Generated Facial Forgeries
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-11-05
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Face-Swapping/" class="post-category">
                                    Face Swapping
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Face-Swapping/">
                        <span class="chip bg-color">Face Swapping</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">32140.8k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
