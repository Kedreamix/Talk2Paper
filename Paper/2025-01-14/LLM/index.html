<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="LLM">
    <meta name="description" content="LLM æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-01-14  AgroGPT Efficient Agricultural Vision-Language Model with Expert Tuning">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>LLM | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://pic1.zhimg.com/v2-cc41d6a4994aa580d50294bdd66e41dc.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">LLM</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/LLM/">
                                <span class="chip bg-color">LLM</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/LLM/" class="post-category">
                                LLM
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-01-14
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-01-14
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    8.6k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    35 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-01-14-æ›´æ–°"><a href="#2025-01-14-æ›´æ–°" class="headerlink" title="2025-01-14 æ›´æ–°"></a>2025-01-14 æ›´æ–°</h1><h2 id="AgroGPT-Efficient-Agricultural-Vision-Language-Model-with-Expert-Tuning"><a href="#AgroGPT-Efficient-Agricultural-Vision-Language-Model-with-Expert-Tuning" class="headerlink" title="AgroGPT: Efficient Agricultural Vision-Language Model with Expert Tuning"></a>AgroGPT: Efficient Agricultural Vision-Language Model with Expert Tuning</h2><p><strong>Authors:Muhammad Awais, Ali Husain Salem Abdulla Alharthi, Amandeep Kumar, Hisham Cholakkal, Rao Muhammad Anwer</strong></p>
<p>Significant progress has been made in advancing large multimodal conversational models (LMMs), capitalizing on vast repositories of image-text data available online. Despite this progress, these models often encounter substantial domain gaps, hindering their ability to engage in complex conversations across new domains. Recent efforts have aimed to mitigate this issue, albeit relying on domain-specific image-text data to curate instruction-tuning data. However, many domains, such as agriculture, lack such vision-language data. In this work, we propose an approach to construct instruction-tuning data that harnesses vision-only data for the agriculture domain. We utilize diverse agricultural datasets spanning multiple domains, curate class-specific information, and employ large language models (LLMs) to construct an expert-tuning set, resulting in a 70k expert-tuning dataset called AgroInstruct. Subsequently, we expert-tuned and created AgroGPT, an efficient LMM that can hold complex agriculture-related conversations and provide useful insights. We also develop AgroEvals for evaluation and compare {AgroGPTâ€™s} performance with large open and closed-source models. {AgroGPT} excels at identifying fine-grained agricultural concepts, can act as an agriculture expert, and provides helpful information for multimodal agriculture questions. The code, datasets, and models are available at <a target="_blank" rel="noopener" href="https://github.com/awaisrauf/agroGPT">https://github.com/awaisrauf/agroGPT</a>. </p>
<blockquote>
<p>åœ¨æ¨è¿›å¤§å‹å¤šæ¨¡æ€å¯¹è¯æ¨¡å‹ï¼ˆLMMsï¼‰æ–¹é¢å–å¾—äº†é‡å¤§è¿›å±•ï¼Œè¿™å¾—ç›Šäºç½‘ç»œä¸Šå¯ç”¨çš„æµ·é‡å›¾åƒæ–‡æœ¬æ•°æ®ä»“åº“ã€‚å°½ç®¡å–å¾—äº†è¿™äº›è¿›å±•ï¼Œä½†è¿™äº›æ¨¡å‹ä»ç„¶ç»å¸¸é‡åˆ°å·¨å¤§çš„é¢†åŸŸå·®è·ï¼Œé˜»ç¢äº†å®ƒä»¬åœ¨æ–°é¢†åŸŸè¿›è¡Œå¤æ‚å¯¹è¯çš„èƒ½åŠ›ã€‚æœ€è¿‘çš„åŠªåŠ›æ—¨åœ¨ç¼“è§£è¿™ä¸ªé—®é¢˜ï¼Œå°½ç®¡è¿™ä¾èµ–äºç‰¹å®šé¢†åŸŸçš„å›¾åƒæ–‡æœ¬æ•°æ®æ¥ç­–åˆ’æŒ‡ä»¤å¾®è°ƒæ•°æ®ã€‚ç„¶è€Œï¼Œè®¸å¤šé¢†åŸŸï¼Œå¦‚å†œä¸šï¼Œç¼ºä¹è¿™æ ·çš„è§†è§‰è¯­è¨€æ•°æ®ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ„å»ºæŒ‡ä»¤å¾®è°ƒæ•°æ®çš„æ–¹æ³•ï¼Œè¯¥æ–¹æ³•åˆ©ç”¨ä»…è§†è§‰æ•°æ®é’ˆå¯¹å†œä¸šé¢†åŸŸã€‚æˆ‘ä»¬åˆ©ç”¨è·¨è¶Šå¤šä¸ªé¢†åŸŸçš„å„ç§å†œä¸šæ•°æ®é›†ï¼Œæ•´ç†ç‰¹å®šç±»åˆ«çš„ä¿¡æ¯ï¼Œå¹¶é‡‡ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰æ¥æ„å»ºä¸“å®¶è°ƒæ•´é›†ï¼Œä»è€Œå½¢æˆäº†åä¸ºAgroInstructçš„70kä¸“å®¶è°ƒæ•´æ•°æ®é›†ã€‚éšåï¼Œæˆ‘ä»¬è¿›è¡Œäº†ä¸“å®¶è°ƒæ•´å¹¶åˆ›å»ºäº†AgrGPTï¼Œè¿™æ˜¯ä¸€ä¸ªæœ‰æ•ˆçš„LMMï¼Œå¯ä»¥è¿›è¡Œå¤æ‚çš„å†œä¸šç›¸å…³å¯¹è¯å¹¶æä¾›æœ‰ç”¨çš„è§è§£ã€‚æˆ‘ä»¬è¿˜å¼€å‘äº†AgroEvalsè¿›è¡Œè¯„ä¼°ï¼Œå¹¶å°†AgrGPTçš„æ€§èƒ½ä¸å¤§å‹å¼€æºå’Œé—­æºæ¨¡å‹è¿›è¡Œæ¯”è¾ƒã€‚AgrGPTæ“…é•¿è¯†åˆ«å†œä¸šä¸­çš„ç»†å¾®æ¦‚å¿µï¼Œå¯ä»¥ä½œä¸ºå†œä¸šä¸“å®¶å‘æŒ¥ä½œç”¨ï¼Œå¹¶ä¸ºå¤šæ¨¡æ€å†œä¸šé—®é¢˜æä¾›æœ‰ç”¨çš„ä¿¡æ¯ã€‚ä»£ç ã€æ•°æ®é›†å’Œæ¨¡å‹å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/awaisrauf/agroGPT%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/awaisrauf/agroGPTæ‰¾åˆ°ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2410.08405v2">PDF</a> Accepted at WACV, 2025</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†é’ˆå¯¹å†œä¸šé¢†åŸŸçš„å¤§å‹å¤šæ¨¡æ€å¯¹è¯æ¨¡å‹ï¼ˆLMMsï¼‰çš„ç ”ç©¶ã€‚ç ”ç©¶å›¢é˜Ÿåˆ©ç”¨ä»…æœ‰è§†è§‰æ•°æ®æ„å»ºäº†å†œä¸šé¢†åŸŸçš„æŒ‡ä»¤è°ƒä¼˜æ•°æ®é›†AgroInstructï¼Œå¹¶ä»¥æ­¤ä¸ºåŸºç¡€è®­ç»ƒå‡ºèƒ½è¿›è¡Œå¤æ‚å†œä¸šç›¸å…³å¯¹è¯å¹¶æä¾›æœ‰ç”¨è§è§£çš„ä¸“å®¶çº§æ¨¡å‹AgroGPTã€‚è¯¥æ¨¡å‹åœ¨å†œä¸šé¢†åŸŸçš„ç²¾ç»†æ¦‚å¿µè¯†åˆ«æ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œå¯ä½œä¸ºå†œä¸šä¸“å®¶æä¾›ä¿¡æ¯ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ç ”ç©¶è¿›å±•ï¼šå¤§å‹å¤šæ¨¡æ€å¯¹è¯æ¨¡å‹ï¼ˆLMMsï¼‰åœ¨åˆ©ç”¨ä¸°å¯Œçš„åœ¨çº¿å›¾åƒæ–‡æœ¬æ•°æ®æ–¹é¢å–å¾—äº†æ˜¾è‘—è¿›å±•ã€‚</li>
<li>é¢†åŸŸå·®è·é—®é¢˜ï¼šå°½ç®¡æœ‰è¿™äº›è¿›å±•ï¼Œä½†æ¨¡å‹åœ¨æ–°é¢†åŸŸè¿›è¡Œå¤æ‚å¯¹è¯æ—¶ä»ä¼šé‡åˆ°æ˜¾è‘—çš„é¢†åŸŸå·®è·é—®é¢˜ã€‚</li>
<li>ç°æœ‰è§£å†³æ–¹æ¡ˆçš„ä¸è¶³ï¼šå°½ç®¡æœ‰åŠªåŠ›é€šè¿‡åŸŸç‰¹å®šçš„å›¾åƒæ–‡æœ¬æ•°æ®æ¥å‡è½»è¿™ä¸ªé—®é¢˜ï¼Œä½†åœ¨è¯¸å¦‚å†œä¸šç­‰é¢†åŸŸï¼Œç”±äºç¼ºä¹æ­¤ç±»è§†è§‰è¯­è¨€æ•°æ®ï¼Œè¿™ä¸€æ–¹æ³•å¹¶ä¸é€‚ç”¨ã€‚</li>
<li>æ–°æ–¹æ³•ä»‹ç»ï¼šæå‡ºäº†ä¸€ç§åˆ©ç”¨ä»…æœ‰è§†è§‰æ•°æ®æ„å»ºå†œä¸šé¢†åŸŸçš„æŒ‡ä»¤è°ƒä¼˜æ•°æ®é›†çš„æ–¹æ³•ï¼Œå¹¶å‘½åä¸ºAgroInstructã€‚</li>
<li>ä¸“å®¶çº§æ¨¡å‹çš„è®­ç»ƒï¼šåŸºäºAgroInstructæ•°æ®é›†è®­ç»ƒå‡ºäº†åä¸ºAgroGPTçš„ä¸“å®¶çº§æ¨¡å‹ï¼Œèƒ½å¤Ÿè¿›è¡Œå¤æ‚çš„å†œä¸šç›¸å…³å¯¹è¯å¹¶æä¾›æœ‰ç”¨ä¿¡æ¯ã€‚</li>
<li>æ¨¡å‹æ€§èƒ½è¯„ä¼°ï¼šå¼€å‘äº†AgroEvalsç”¨äºè¯„ä¼°AgroGPTçš„æ€§èƒ½ï¼Œå¹¶ä¸å¤§å‹å¼€æºå’Œé—­æºæ¨¡å‹è¿›è¡Œäº†æ¯”è¾ƒã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2410.08405">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-4fb6bb063106a83d1b181828e153836b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ae074963b022cb9e9b9e23706022a6c0.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-46d778d88f41e24c0299f92e8fe3b503.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-888f0ac51d6936a853074049556d541e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-9fb55857815a09adfea2ba8e8c367e4a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-37af65f3d1437afd0a1118ae7c35ac8f.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-7e7c17ea3e65075ab0ef5a8d2cda2ccc.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="MacST-Multi-Accent-Speech-Synthesis-via-Text-Transliteration-for-Accent-Conversion"><a href="#MacST-Multi-Accent-Speech-Synthesis-via-Text-Transliteration-for-Accent-Conversion" class="headerlink" title="MacST: Multi-Accent Speech Synthesis via Text Transliteration for Accent   Conversion"></a>MacST: Multi-Accent Speech Synthesis via Text Transliteration for Accent   Conversion</h2><p><strong>Authors:Sho Inoue, Shuai Wang, Wanxing Wang, Pengcheng Zhu, Mengxiao Bi, Haizhou Li</strong></p>
<p>In accented voice conversion or accent conversion, we seek to convert the accent in speech from one another while preserving speaker identity and semantic content. In this study, we formulate a novel method for creating multi-accented speech samples, thus pairs of accented speech samples by the same speaker, through text transliteration for training accent conversion systems. We begin by generating transliterated text with Large Language Models (LLMs), which is then fed into multilingual TTS models to synthesize accented English speech. As a reference system, we built a sequence-to-sequence model on the synthetic parallel corpus for accent conversion. We validated the proposed method for both native and non-native English speakers. Subjective and objective evaluations further validate our datasetâ€™s effectiveness in accent conversion studies. </p>
<blockquote>
<p>åœ¨å£éŸ³è½¬æ¢æˆ–è¯­éŸ³è½¬æ¢ä¸­ï¼Œæˆ‘ä»¬æ—¨åœ¨å°†è¯­éŸ³ä¸­çš„å£éŸ³è¿›è¡Œè½¬æ¢ï¼ŒåŒæ—¶ä¿ç•™è¯´è¯è€…çš„èº«ä»½å’Œè¯­ä¹‰å†…å®¹ã€‚æœ¬ç ”ç©¶ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°çš„æ–¹æ³•ï¼Œé€šè¿‡æ–‡æœ¬è½¬è¯‘æ¥åˆ›å»ºå¤šå£éŸ³è¯­éŸ³æ ·æœ¬ï¼Œä»è€Œä¸ºå£éŸ³è½¬æ¢ç³»ç»Ÿè®­ç»ƒæä¾›åŒä¸€è¯´è¯äººçš„å¸¦å£éŸ³è¯­éŸ³æ ·æœ¬å¯¹ã€‚æˆ‘ä»¬é¦–å…ˆä½¿ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ç”Ÿæˆè½¬è¯‘æ–‡æœ¬ï¼Œç„¶åå°†å…¶è¾“å…¥å¤šè¯­è¨€TTSæ¨¡å‹ï¼Œåˆæˆå¸¦æœ‰å£éŸ³çš„è‹±è¯­è¯­éŸ³ã€‚ä½œä¸ºå‚è€ƒç³»ç»Ÿï¼Œæˆ‘ä»¬åœ¨åˆæˆå¹³è¡Œè¯­æ–™åº“ä¸Šå»ºç«‹äº†åºåˆ—åˆ°åºåˆ—çš„æ¨¡å‹è¿›è¡Œå£éŸ³è½¬æ¢ã€‚æˆ‘ä»¬éªŒè¯äº†æ‰€æå‡ºçš„æ–¹æ³•å¯¹äºè‹±è¯­æ¯è¯­è€…å’Œéæ¯è¯­è€…éƒ½æœ‰æ•ˆã€‚ä¸»è§‚å’Œå®¢è§‚è¯„ä¼°è¿›ä¸€æ­¥éªŒè¯äº†æˆ‘ä»¬çš„æ•°æ®é›†åœ¨å£éŸ³è½¬æ¢ç ”ç©¶ä¸­çš„æœ‰æ•ˆæ€§ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2409.09352v2">PDF</a> This is accepted to IEEE ICASSP 2025; Project page with Speech Demo:   <a target="_blank" rel="noopener" href="https://github.com/shinshoji01/MacST-project-page">https://github.com/shinshoji01/MacST-project-page</a></p>
<p><strong>Summary</strong></p>
<p>åœ¨å£éŸ³è½¬æ¢ç ”ç©¶ä¸­ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°å‹çš„å¤šå£éŸ³è¯­éŸ³æ ·æœ¬åˆ›å»ºæ–¹æ³•ã€‚é€šè¿‡å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰è¿›è¡Œæ–‡æœ¬è½¬è¯‘ï¼Œç”Ÿæˆå£éŸ³æ ·æœ¬å¯¹ï¼Œç”¨äºè®­ç»ƒå£éŸ³è½¬æ¢ç³»ç»Ÿã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•èƒ½æœ‰æ•ˆå®ç°å£éŸ³è½¬æ¢ï¼ŒåŒæ—¶ä¿ç•™è¯´è¯äººèº«ä»½å’Œè¯­ä¹‰å†…å®¹ã€‚å¯¹æœ¬åœ°å’Œéæœ¬åœ°è‹±è¯­è¯´è¯è€…å‡è¿›è¡Œäº†éªŒè¯ã€‚ä¸»è§‚å’Œå®¢è§‚è¯„ä¼°è¿›ä¸€æ­¥éªŒè¯äº†æ•°æ®é›†åœ¨å£éŸ³è½¬æ¢ç ”ç©¶ä¸­çš„æœ‰æ•ˆæ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æœ¬æ–‡æå‡ºäº†ä½¿ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ç”Ÿæˆæ–‡æœ¬è½¬è¯‘æ¥åˆ›å»ºå¤šå£éŸ³è¯­éŸ³æ ·æœ¬çš„æ–¹æ³•ã€‚</li>
<li>åˆ›å»ºçš„å£éŸ³æ ·æœ¬å¯¹ç”¨äºè®­ç»ƒå£éŸ³è½¬æ¢ç³»ç»Ÿã€‚</li>
<li>è¯´è¯äººçš„èº«ä»½å’Œè¯­ä¹‰å†…å®¹åœ¨å£éŸ³è½¬æ¢è¿‡ç¨‹ä¸­å¾—ä»¥ä¿ç•™ã€‚</li>
<li>è¯¥æ–¹æ³•æ—¢é€‚ç”¨äºæœ¬åœ°è‹±è¯­è¯´è¯è€…ä¹Ÿé€‚ç”¨äºéæœ¬åœ°è‹±è¯­è¯´è¯è€…ã€‚</li>
<li>ä¸»è§‚å’Œå®¢è§‚è¯„ä¼°éªŒè¯äº†æ•°æ®é›†çš„æœ‰æ•ˆæ€§ã€‚</li>
<li>æœ¬æ–‡é‡‡ç”¨äº†ä¸€ç§åºåˆ—åˆ°åºåˆ—æ¨¡å‹è¿›è¡Œå£éŸ³è½¬æ¢ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2409.09352">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-bda998ee7c6539ce6d05781d2e0e4d1c.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-081b421c361ba539819a9c6ba2a70296.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-255fe0b982a65b5a7f38cd3d865e82da.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-5fbf0627b83804e6fad6f45ab6436e4d.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-78b865ce5c3ba31b1c0a8168716a2d00.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="The-Mamba-in-the-Llama-Distilling-and-Accelerating-Hybrid-Models"><a href="#The-Mamba-in-the-Llama-Distilling-and-Accelerating-Hybrid-Models" class="headerlink" title="The Mamba in the Llama: Distilling and Accelerating Hybrid Models"></a>The Mamba in the Llama: Distilling and Accelerating Hybrid Models</h2><p><strong>Authors:Junxiong Wang, Daniele Paliotta, Avner May, Alexander M. Rush, Tri Dao</strong></p>
<p>Linear RNN architectures, like Mamba, can be competitive with Transformer models in language modeling while having advantageous deployment characteristics. Given the focus on training large-scale Transformer models, we consider the challenge of converting these pretrained models for deployment. We demonstrate that it is feasible to distill large Transformers into linear RNNs by reusing the linear projection weights from attention layers with academic GPU resources. The resulting hybrid model, which incorporates a quarter of the attention layers, achieves performance comparable to the original Transformer in chat benchmarks and outperforms open-source hybrid Mamba models trained from scratch with trillions of tokens in both chat benchmarks and general benchmarks. Moreover, we introduce a hardware-aware speculative decoding algorithm that accelerates the inference speed of Mamba and hybrid models. Overall we show how, with limited computation resources, we can remove many of the original attention layers and generate from the resulting model more efficiently. Our top-performing model, distilled from Llama3-8B-Instruct, achieves a 29.61 length-controlled win rate on AlpacaEval 2 against GPT-4 and 7.35 on MT-Bench, surpassing the best 8B scale instruction-tuned linear RNN model. We also find that the distilled model has natural length extrapolation, showing almost perfect accuracy in the needle-in-a-haystack test at 20x the distillation length. Code and pre-trained checkpoints are open-sourced at <a target="_blank" rel="noopener" href="https://github.com/jxiw/MambaInLlama">https://github.com/jxiw/MambaInLlama</a> and <a target="_blank" rel="noopener" href="https://github.com/itsdaniele/speculative_mamba">https://github.com/itsdaniele/speculative_mamba</a>. </p>
<blockquote>
<p>çº¿æ€§RNNæ¶æ„ï¼ˆå¦‚Mambaï¼‰åœ¨è¯­è¨€å»ºæ¨¡æ–¹é¢å¯ä»¥ä¸Transformeræ¨¡å‹ç«äº‰ï¼ŒåŒæ—¶æ‹¥æœ‰ä¼˜åŠ¿éƒ¨ç½²ç‰¹æ€§ã€‚é‰´äºç›®å‰ä¸»è¦å…³æ³¨è®­ç»ƒå¤§è§„æ¨¡Transformeræ¨¡å‹ï¼Œæˆ‘ä»¬é¢ä¸´å°†è¿™äº›é¢„è®­ç»ƒæ¨¡å‹è¿›è¡Œéƒ¨ç½²çš„æŒ‘æˆ˜ã€‚æˆ‘ä»¬è¯æ˜äº†é€šè¿‡åˆ©ç”¨GPUèµ„æºé‡å¤ä½¿ç”¨æ³¨æ„åŠ›å±‚çš„çº¿æ€§æŠ•å½±æƒé‡ï¼Œå°†å¤§å‹Transformerè’¸é¦æˆçº¿æ€§RNNæ˜¯å¯è¡Œçš„ã€‚æ‰€å¾—æ··åˆæ¨¡å‹ç»“åˆäº†å››åˆ†ä¹‹ä¸€çš„æ³¨æ„åŠ›å±‚ï¼Œåœ¨èŠå¤©åŸºå‡†æµ‹è¯•ä¸­å®ç°äº†ä¸åŸå§‹Transformerç›¸å½“çš„æ€§èƒ½ï¼Œå¹¶ä¸”åœ¨èŠå¤©åŸºå‡†æµ‹è¯•å’Œä¸€èˆ¬åŸºå‡†æµ‹è¯•ä¸­è¡¨ç°ä¼˜äºä»å¤´å¼€å§‹è®­ç»ƒçš„å¼€æºæ··åˆMambaæ¨¡å‹ï¼ˆè¿™äº›æ¨¡å‹è®­ç»ƒæ—¶ä½¿ç”¨äº†ä¸‡äº¿ä¸ªä»¤ç‰Œï¼‰ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§ç¡¬ä»¶æ„ŸçŸ¥çš„æŠ•æœºè§£ç ç®—æ³•ï¼Œè¯¥ç®—æ³•åŠ é€Ÿäº†Mambaå’Œæ··åˆæ¨¡å‹çš„æ¨ç†é€Ÿåº¦ã€‚æ€»ä½“è€Œè¨€ï¼Œæˆ‘ä»¬å±•ç¤ºäº†å¦‚ä½•åœ¨æœ‰é™çš„è®¡ç®—èµ„æºä¸‹åˆ é™¤è®¸å¤šåŸå§‹æ³¨æ„åŠ›å±‚å¹¶æ›´é«˜æ•ˆåœ°ç”Ÿæˆç»“æœæ¨¡å‹ã€‚æˆ‘ä»¬çš„é«˜æ€§èƒ½æ¨¡å‹ä»Llama3-8B-Instructä¸­æç‚¼å‡ºæ¥ï¼Œåœ¨AlpacaEval 2ä¸Šç›¸å¯¹äºGPT-4è¾¾åˆ°äº†29.61çš„é•¿åº¦æ§åˆ¶èƒœç‡ï¼Œå¹¶åœ¨MT-Benchä¸Šè¾¾åˆ°äº†7.35ï¼Œè¶…è¿‡äº†æœ€ä½³8Bè§„æ¨¡æŒ‡ä»¤è°ƒæ•´çº¿æ€§RNNæ¨¡å‹ã€‚æˆ‘ä»¬è¿˜å‘ç°ï¼Œæç‚¼åçš„æ¨¡å‹å…·æœ‰è‡ªç„¶çš„é•¿åº¦æ‰©å±•èƒ½åŠ›ï¼Œåœ¨è’¸é¦é•¿åº¦æé«˜20å€çš„æƒ…å†µä¸‹ï¼Œå‡ ä¹è¾¾åˆ°äº†å®Œç¾çš„å‡†ç¡®ç‡åœ¨â€œæµ·åº•æé’ˆâ€æµ‹è¯•ä¸­ã€‚ä»£ç å’Œé¢„å…ˆè®­ç»ƒçš„æ¨¡å‹æ£€æŸ¥ç‚¹å·²å¼€æºåˆ†äº«è‡³ï¼š<a target="_blank" rel="noopener" href="https://github.com/jxiw/MambaInLlama%E5%92%8Chttps://github.com/itsdaniele/speculative_mamba%E3%80%82">https://github.com/jxiw/MambaInLlamaå’Œhttps://github.com/itsdaniele/speculative_mambaã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2408.15237v3">PDF</a> NeurIPS 2024. v3 updates: fix format errors</p>
<p><strong>æ‘˜è¦</strong></p>
<p>çº¿æ€§RNNæ¶æ„å¦‚Mambaï¼Œåœ¨è¯­è¨€å»ºæ¨¡æ–¹é¢å¯ä¸Transformeræ¨¡å‹ç«äº‰ï¼Œå¹¶å…·æœ‰ä¼˜åŠ¿éƒ¨ç½²ç‰¹æ€§ã€‚ç ”ç©¶æŒ‘æˆ˜åœ¨äºå°†å¤§å‹é¢„è®­ç»ƒTransformeræ¨¡å‹è¿›è¡Œéƒ¨ç½²è½¬æ¢ã€‚ç ”ç©¶å±•ç¤ºäº†ç”¨å­¦æœ¯GPUèµ„æºé€šè¿‡å¤ç”¨æ³¨æ„åŠ›å±‚çš„çº¿æ€§æŠ•å½±æƒé‡æ¥è’¸é¦å¤§å‹Transformerä¸ºçº¿æ€§RNNçš„å¯è¡Œæ€§ã€‚å¾—åˆ°çš„æ··åˆæ¨¡å‹åªä½¿ç”¨äº†å››åˆ†ä¹‹ä¸€çš„æ³¨æ„åŠ›å±‚ï¼Œåœ¨èŠå¤©åŸºå‡†æµ‹è¯•ä¸­è¡¨ç°ä¸åŸå§‹Transformerç›¸å½“ï¼Œå¹¶ä¸”åœ¨èŠå¤©åŸºå‡†æµ‹è¯•å’Œä¸€èˆ¬åŸºå‡†æµ‹è¯•ä¸­è¡¨ç°ä¼˜äºä»å¤´å¼€å§‹è®­ç»ƒçš„å¼€æºæ··åˆMambaæ¨¡å‹ã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜å¼•å…¥äº†ä¸€ç§ç¡¬ä»¶æ„ŸçŸ¥çš„æŠ•æœºè§£ç ç®—æ³•ï¼Œæé«˜äº†Mambaå’Œæ··åˆæ¨¡å‹çš„æ¨ç†é€Ÿåº¦ã€‚æ€»ä½“ä¸Šï¼Œç ”ç©¶å±•ç¤ºäº†å¦‚ä½•åœ¨æœ‰é™çš„è®¡ç®—èµ„æºä¸‹å‡å°‘è®¸å¤šåŸå§‹æ³¨æ„åŠ›å±‚å¹¶æ›´é«˜æ•ˆåœ°ç”Ÿæˆæ¨¡å‹ã€‚æœ€ä½³æ€§èƒ½çš„æ¨¡å‹æ˜¯ä»Llama3-8B-Instructä¸­æç‚¼å‡ºæ¥çš„ï¼Œåœ¨AlpacaEval 2ä¸Šç›¸å¯¹äºGPT-4å–å¾—äº†29.61çš„é•¿åº¦æ§åˆ¶èƒœç‡ï¼Œåœ¨MT-Benchä¸Šå–å¾—äº†7.35çš„æˆç»©ï¼Œè¶…è¿‡äº†æœ€ä½³8Bè§„æ¨¡æŒ‡ä»¤è°ƒæ•´çº¿æ€§RNNæ¨¡å‹ã€‚è¿˜å‘ç°æç‚¼çš„æ¨¡å‹å…·æœ‰è‡ªç„¶é•¿åº¦å¤–æ¨èƒ½åŠ›ï¼Œåœ¨è’¸é¦é•¿åº¦æé«˜20å€çš„æƒ…å†µä¸‹ï¼Œå‡ ä¹è¾¾åˆ°äº†å®Œç¾çš„å‡†ç¡®ç‡ã€‚ä»£ç å’Œé¢„å…ˆè®­ç»ƒçš„æ¨¡å‹æ£€æŸ¥ç‚¹åœ¨GitHubä¸Šå¼€æºã€‚</p>
<p><strong>å…³é”®è§è§£</strong></p>
<ol>
<li>çº¿æ€§RNNæ¶æ„å¦‚Mambaåœ¨è¯­è¨€å»ºæ¨¡æ–¹é¢å¯ä¸Transformeræ¨¡å‹ç«äº‰ï¼Œä¸”å…·æœ‰ä¼˜åŠ¿éƒ¨ç½²ç‰¹æ€§ã€‚</li>
<li>é€šè¿‡å¤ç”¨æ³¨æ„åŠ›å±‚çš„çº¿æ€§æŠ•å½±æƒé‡ï¼Œå¯ä»¥å°†å¤§å‹Transformeræ¨¡å‹è’¸é¦ä¸ºçº¿æ€§RNNæ¨¡å‹ã€‚</li>
<li>æ··åˆæ¨¡å‹ä½¿ç”¨å››åˆ†ä¹‹ä¸€çš„æ³¨æ„åŠ›å±‚å³å¯å®ç°ä¸åŸå§‹Transformerç›¸å½“çš„æ€§èƒ½ã€‚</li>
<li>å¼•å…¥äº†ä¸€ç§ç¡¬ä»¶æ„ŸçŸ¥çš„æŠ•æœºè§£ç ç®—æ³•ï¼Œä»¥æé«˜æ¨¡å‹æ¨ç†é€Ÿåº¦ã€‚</li>
<li>æœ€ä½³æ€§èƒ½çš„æ¨¡å‹æ˜¯ä»å¤§å‹é¢„è®­ç»ƒæ¨¡å‹Llama3-8B-Instructä¸­æç‚¼å‡ºæ¥çš„ã€‚</li>
<li>æç‚¼çš„æ¨¡å‹åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­è¡¨ç°å‡ºè‰²ï¼Œè¶…è¿‡äº†å…¶ä»–ç±»ä¼¼è§„æ¨¡çš„æ¨¡å‹ã€‚</li>
<li>æç‚¼çš„æ¨¡å‹å…·æœ‰è‡ªç„¶é•¿åº¦å¤–æ¨èƒ½åŠ›ï¼Œè¡¨ç°å‡ºå¼ºå¤§çš„æ€§èƒ½ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2408.15237">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-cf99c5bab0e409ab07d7e12bef0dd9b2.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-bcee4de37c49a214575b87b42e5bef80.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-cc41d6a4994aa580d50294bdd66e41dc.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-330d8a7004a7626191ebda5a54f9ebb9.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="Codebook-LLMs-Evaluating-LLMs-as-Measurement-Tools-for-Political-Science-Concepts"><a href="#Codebook-LLMs-Evaluating-LLMs-as-Measurement-Tools-for-Political-Science-Concepts" class="headerlink" title="Codebook LLMs: Evaluating LLMs as Measurement Tools for Political   Science Concepts"></a>Codebook LLMs: Evaluating LLMs as Measurement Tools for Political   Science Concepts</h2><p><strong>Authors:Andrew Halterman, Katherine A. Keith</strong></p>
<p>Codebooks â€“ documents that operationalize concepts and outline annotation procedures â€“ are used almost universally by social scientists when coding political texts. To code these texts automatically, researchers are increasing turning to generative large language models (LLMs). However, there is limited empirical evidence on whether â€œoff-the-shelfâ€ LLMs faithfully follow real-world codebook operationalizations and measure complex political constructs with sufficient accuracy. To address this, we gather and curate three real-world political science codebooks â€“ covering protest events, political violence and manifestos â€“ along with their unstructured texts and human labels. We also propose a five-stage framework for codebook-LLM measurement: preparing a codebook for both humans and LLMs, testing LLMsâ€™ basic capabilities on a codebook, evaluating zero-shot measurement accuracy (i.e. off-the-shelf performance), analyzing errors, and further (parameter-efficient) supervised training of LLMs. We provide an empirical demonstration of this framework using our three codebook datasets and several pretrained 7-12 billion open-weight LLMs. We find current open-weight LLMs have limitations in following codebooks zero-shot, but that supervised instruction tuning can substantially improve performance. Rather than suggesting the â€œbestâ€ LLM, our contribution lies in our codebook datasets, evaluation framework, and guidance for applied researchers who wish to implement their own codebook-LLM measurement projects. </p>
<blockquote>
<p>æ¦‚å¿µæ“ä½œåŒ–æ–‡æ¡£å’Œæ¦‚è¿°æ³¨é‡Šç¨‹åºçš„æ‰‹å†Œå‡ ä¹è¢«ç¤¾ä¼šç§‘å­¦å®¶åœ¨åˆ†ææ”¿æ²»æ–‡æœ¬ç¼–ç æ—¶æ™®éä½¿ç”¨ã€‚ä¸ºäº†è‡ªåŠ¨å¯¹è¿™äº›æ–‡æœ¬è¿›è¡Œç¼–ç ï¼Œç ”ç©¶äººå‘˜æ­£è¶Šæ¥è¶Šå¤šåœ°è½¬å‘ç”Ÿæˆå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ã€‚ç„¶è€Œï¼Œå…³äºâ€œç°æˆçš„â€LLMæ˜¯å¦èƒ½å¤Ÿå¿ å®éµå¾ªç°å®ä¸–ç•Œçš„æ‰‹å†Œæ“ä½œåŒ–ï¼Œå¹¶ä»¥è¶³å¤Ÿçš„å‡†ç¡®æ€§è¡¡é‡å¤æ‚çš„æ”¿æ²»ç»“æ„ï¼Œç°æœ‰çš„å®è¯è¯æ®æœ‰é™ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬æ”¶é›†å¹¶æ•´ç†äº†ä¸‰ä¸ªç°å®ä¸–ç•Œçš„æ”¿æ²»ç§‘å­¦æ‰‹å†Œæ•°æ®é›†ï¼Œæ¶µç›–æŠ—è®®äº‹ä»¶ã€æ”¿æ²»æš´åŠ›å’Œå®£è¨€ç­‰å†…å®¹åŠå…¶éç»“æ„åŒ–æ–‡æœ¬å’Œäººç±»æ ‡ç­¾ã€‚æˆ‘ä»¬è¿˜æå‡ºäº†ä¸€ä¸ªäº”é˜¶æ®µçš„æ‰‹å†Œ-LLMæµ‹é‡æ¡†æ¶ï¼šä¸ºäººå·¥å’ŒLLMå‡†å¤‡æ‰‹å†Œï¼Œæµ‹è¯•LLMåœ¨æ‰‹å†Œä¸Šçš„åŸºæœ¬èƒ½åŠ›ï¼Œè¯„ä¼°é›¶å¯åŠ¨æµ‹é‡ç²¾åº¦ï¼ˆå³ç°æˆæ€§èƒ½ï¼‰ï¼Œåˆ†æé”™è¯¯ï¼Œä»¥åŠå¯¹LLMè¿›è¡Œè¿›ä¸€æ­¥çš„ï¼ˆå‚æ•°é«˜æ•ˆï¼‰ç›‘ç£è®­ç»ƒã€‚æˆ‘ä»¬ä½¿ç”¨è¿™ä¸‰ä¸ªæ‰‹å†Œæ•°æ®é›†å’Œå‡ ä¸ªé¢„è®­ç»ƒçš„7-12äº¿å¼€æ”¾å¼æƒé‡LLMæ¥å®è¯å±•ç¤ºè¿™ä¸ªæ¡†æ¶ã€‚æˆ‘ä»¬å‘ç°ç°æœ‰çš„å¼€æ”¾å¼æƒé‡LLMåœ¨é›¶å¯åŠ¨éµå¾ªæ‰‹å†Œæ–¹é¢å­˜åœ¨å±€é™æ€§ï¼Œä½†ç›‘ç£æŒ‡ä»¤å¾®è°ƒå¯ä»¥æ˜¾è‘—æé«˜æ€§èƒ½ã€‚æˆ‘ä»¬çš„è´¡çŒ®ä¸åœ¨äºå»ºè®®â€œæœ€ä½³â€LLMï¼Œè€Œåœ¨äºæˆ‘ä»¬çš„æ‰‹å†Œæ•°æ®é›†ã€è¯„ä¼°æ¡†æ¶ä»¥åŠå¸Œæœ›å¯¹è‡ªå®¶è¿›è¡Œæ‰‹å†Œ-LLMæµ‹é‡é¡¹ç›®çš„åº”ç”¨ç ”ç©¶è€…æä¾›çš„æŒ‡å¯¼ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2407.10747v2">PDF</a> Version 2 (v1 Presented at PolMeth 2024)</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æ¢è®¨äº†ç¤¾ä¼šç§‘å­¦å®¶åœ¨è¿›è¡Œæ”¿æ²»æ–‡æœ¬ç¼–ç æ—¶æ™®éä½¿ç”¨çš„ç¼–ç æ‰‹å†Œï¼ˆcodebooksï¼‰ä¸å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„ç»“åˆåº”ç”¨ã€‚é’ˆå¯¹ç°æœ‰ç ”ç©¶ä¸­å…³äºLLMsæ˜¯å¦èƒ½å¿ å®éµå¾ªç°å®ç¼–ç æ‰‹å†Œæ“ä½œå¹¶å‡†ç¡®æµ‹é‡å¤æ‚æ”¿æ²»æ¦‚å¿µçš„é—®é¢˜ï¼Œä½œè€…æ”¶é›†å¹¶æ•´ç†äº†ä¸‰ä¸ªçœŸå®ä¸–ç•Œçš„æ”¿æ²»ç§‘å­¦ç¼–ç æ‰‹å†ŒåŠå…¶ç›¸å…³æ–‡æœ¬å’Œäººç±»æ ‡ç­¾ã€‚åŒæ—¶ï¼Œä½œè€…æå‡ºäº†ä¸€ä¸ªäº”é˜¶æ®µçš„ç¼–ç æ‰‹å†Œ-LLMæµ‹é‡æ¡†æ¶ï¼ŒåŒ…æ‹¬å‡†å¤‡ç¼–ç æ‰‹å†Œã€æµ‹è¯•LLMçš„åŸºæœ¬èƒ½åŠ›ã€è¯„ä¼°é›¶æ ·æœ¬æµ‹é‡ç²¾åº¦ã€åˆ†æè¯¯å·®ä»¥åŠè¿›ä¸€æ­¥å¯¹LLMè¿›è¡Œå‚æ•°æœ‰æ•ˆçš„ç›‘ç£è®­ç»ƒã€‚é€šè¿‡å®è¯æ¼”ç¤ºï¼Œä½œè€…å‘ç°ç°æœ‰çš„å¤§å‹è¯­è¨€æ¨¡å‹åœ¨é›¶æ ·æœ¬éµå¾ªç¼–ç æ‰‹å†Œæ–¹é¢å­˜åœ¨å±€é™æ€§ï¼Œä½†é€šè¿‡ç›‘ç£æŒ‡ä»¤å¾®è°ƒå¯ä»¥æ˜¾è‘—æé«˜æ€§èƒ½ã€‚æœ¬æ–‡çš„è´¡çŒ®åœ¨äºæä¾›ç¼–ç æ‰‹å†Œæ•°æ®é›†ã€è¯„ä¼°æ¡†æ¶ä»¥åŠä¸ºå¸Œæœ›å®æ–½è‡ªå·±çš„ç¼–ç æ‰‹å†Œ-LLMæµ‹é‡é¡¹ç›®çš„åº”ç”¨ç ”ç©¶è€…æä¾›æŒ‡å¯¼ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ç¤¾ä¼šç§‘å­¦å®¶æ™®éä½¿ç”¨ç¼–ç æ‰‹å†Œï¼ˆcodebooksï¼‰å¯¹æ”¿æ²»æ–‡æœ¬è¿›è¡Œç¼–ç ã€‚</li>
<li>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰è¢«è¶Šæ¥è¶Šå¤šåœ°ç”¨äºè‡ªåŠ¨ç¼–ç è¿™äº›æ–‡æœ¬ã€‚</li>
<li>ç›®å‰å¯¹äºLLMsæ˜¯å¦å¿ å®éµå¾ªç°å®ç¼–ç æ‰‹å†Œæ“ä½œå¹¶å‡†ç¡®æµ‹é‡å¤æ‚æ”¿æ²»æ¦‚å¿µçš„ç ”ç©¶è¯æ®æœ‰é™ã€‚</li>
<li>ä½œè€…æå‡ºäº†ä¸€ä¸ªäº”é˜¶æ®µçš„ç¼–ç æ‰‹å†Œ-LLMæµ‹é‡æ¡†æ¶ï¼ŒåŒ…æ‹¬å‡†å¤‡ã€æµ‹è¯•ã€è¯„ä¼°ã€åˆ†æå’Œè¿›ä¸€æ­¥è®­ç»ƒLLMã€‚</li>
<li>å®è¯ç ”ç©¶è¡¨æ˜ï¼Œç°æœ‰LLMsåœ¨é›¶æ ·æœ¬éµå¾ªç¼–ç æ‰‹å†Œæ–¹é¢å­˜åœ¨å±€é™æ€§ã€‚</li>
<li>é€šè¿‡ç›‘ç£æŒ‡ä»¤å¾®è°ƒå¯ä»¥æ˜¾è‘—æé«˜LLMsçš„æ€§èƒ½ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2407.10747">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-9f238a7514c29df2a3bf0dc93700f46f.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-51fd56598189b9beaf44475a61b3e21b.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="Benchmarking-Uncertainty-Quantification-Methods-for-Large-Language-Models-with-LM-Polygraph"><a href="#Benchmarking-Uncertainty-Quantification-Methods-for-Large-Language-Models-with-LM-Polygraph" class="headerlink" title="Benchmarking Uncertainty Quantification Methods for Large Language   Models with LM-Polygraph"></a>Benchmarking Uncertainty Quantification Methods for Large Language   Models with LM-Polygraph</h2><p><strong>Authors:Roman Vashurin, Ekaterina Fadeeva, Artem Vazhentsev, Lyudmila Rvanova, Akim Tsvigun, Daniil Vasilev, Rui Xing, Abdelrahman Boda Sadallah, Kirill Grishchenkov, Sergey Petrakov, Alexander Panchenko, Timothy Baldwin, Preslav Nakov, Maxim Panov, Artem Shelmanov</strong></p>
<p>The rapid proliferation of large language models (LLMs) has stimulated researchers to seek effective and efficient approaches to deal with LLM hallucinations and low-quality outputs. Uncertainty quantification (UQ) is a key element of machine learning applications in dealing with such challenges. However, research to date on UQ for LLMs has been fragmented in terms of techniques and evaluation methodologies. In this work, we address this issue by introducing a novel benchmark that implements a collection of state-of-the-art UQ baselines and offers an environment for controllable and consistent evaluation of novel UQ techniques over various text generation tasks. Our benchmark also supports the assessment of confidence normalization methods in terms of their ability to provide interpretable scores. Using our benchmark, we conduct a large-scale empirical investigation of UQ and normalization techniques across eleven tasks, identifying the most effective approaches. Code: <a target="_blank" rel="noopener" href="https://github.com/IINemo/lm-polygraph">https://github.com/IINemo/lm-polygraph</a> Benchmark: <a target="_blank" rel="noopener" href="https://huggingface.co/LM-Polygraph">https://huggingface.co/LM-Polygraph</a> </p>
<blockquote>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„è¿…é€Ÿå¢æ®–ä¿ƒä½¿ç ”ç©¶äººå‘˜å¯»æ±‚æœ‰æ•ˆä¸”é«˜æ•ˆçš„æ–¹æ³•æ¥åº”å¯¹LLMå¹»è§‰å’Œè¾“å‡ºè´¨é‡ä½çš„é—®é¢˜ã€‚ä¸ç¡®å®šæ€§é‡åŒ–ï¼ˆUQï¼‰æ˜¯æœºå™¨å­¦ä¹ åº”ç”¨ä¸­è§£å†³æ­¤ç±»æŒ‘æˆ˜çš„å…³é”®å› ç´ ã€‚ç„¶è€Œï¼Œè¿„ä»Šä¸ºæ­¢å…³äºLLMçš„ä¸ç¡®å®šæ€§é‡åŒ–çš„ç ”ç©¶åœ¨æŠ€æœ¯å’Œè¯„ä¼°æ–¹æ³•æ–¹é¢éƒ½æ˜¯é›¶ç¢çš„ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬é€šè¿‡å¼•å…¥ä¸€ä¸ªæ–°å‹åŸºå‡†æµ‹è¯•æ¥è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œè¯¥æµ‹è¯•å®ç°äº†æœ€å…ˆè¿›çš„UQåŸºçº¿æŠ€æœ¯çš„é›†åˆï¼Œå¹¶æä¾›äº†å¯¹å„ç§æ–‡æœ¬ç”Ÿæˆä»»åŠ¡ä¸­æ–°å‹UQæŠ€æœ¯è¿›è¡Œå¯æ§ä¸”ä¸€è‡´è¯„ä¼°çš„ç¯å¢ƒã€‚æˆ‘ä»¬çš„åŸºå‡†æµ‹è¯•è¿˜æ”¯æŒå¯¹ä¿¡å¿ƒå½’ä¸€åŒ–æ–¹æ³•çš„è¯„ä¼°ï¼Œä»¥è¯„ä¼°å…¶æä¾›å¯è§£é‡Šåˆ†æ•°çš„èƒ½åŠ›ã€‚ä½¿ç”¨æˆ‘ä»¬çš„åŸºå‡†æµ‹è¯•ï¼Œæˆ‘ä»¬å¯¹UQå’Œå½’ä¸€åŒ–æŠ€æœ¯åœ¨åä¸€ä¸ªä»»åŠ¡ä¸Šè¿›è¡Œäº†å¤§è§„æ¨¡å®è¯ç ”ç©¶ï¼Œç¡®å®šäº†æœ€æœ‰æ•ˆçš„æ–¹å¼ã€‚ä»£ç ï¼š<a target="_blank" rel="noopener" href="https://github.com/IINemo/lm-polygraph">https://github.com/IINemo/lm-polygraph</a> åŸºå‡†æµ‹è¯•ï¼š<a target="_blank" rel="noopener" href="https://huggingface.co/LM-Polygraph">https://huggingface.co/LM-Polygraph</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2406.15627v3">PDF</a> Accepted to TACL 2025, pre-MIT Press publication version. Roman   Vashurin, Ekaterina Fadeeva, Artem Vazhentsev contributed equally</p>
<p><strong>Summary</strong></p>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„å¿«é€Ÿå‘å±•å¼•å‘äº†ç ”ç©¶äººå‘˜å¯¹äºå¤„ç†LLMå¹»è§‰å’Œä½è´¨é‡è¾“å‡ºçš„æœ‰æ•ˆå’Œé«˜æ•ˆæ–¹æ³•çš„æ¢æ±‚ã€‚ä¸ç¡®å®šæ€§é‡åŒ–ï¼ˆUQï¼‰æ˜¯æœºå™¨å­¦ä¹ åº”ç”¨ä¸­åº”å¯¹è¿™äº›æŒ‘æˆ˜çš„å…³é”®å› ç´ ã€‚ç„¶è€Œï¼Œè¿„ä»Šä¸ºæ­¢ï¼Œé’ˆå¯¹LLMçš„ä¸ç¡®å®šæ€§é‡åŒ–ç ”ç©¶åœ¨æŠ€æœ¯å’Œè¯„ä¼°æ–¹æ³•ä¸Šéƒ½æ˜¯åˆ†æ•£çš„ã€‚æœ¬ç ”ç©¶é€šè¿‡å¼•å…¥æ–°å‹åŸºå‡†æµ‹è¯•æ¥è§£å†³è¿™ä¸€é—®é¢˜ï¼Œè¯¥åŸºå‡†æµ‹è¯•å®ç°äº†å…ˆè¿›çš„ä¸ç¡®å®šæ€§é‡åŒ–åŸºå‡†æµ‹è¯•é›†åˆï¼Œå¹¶ä¸ºå„ç§æ–‡æœ¬ç”Ÿæˆä»»åŠ¡ä¸Šæ–°å‹ä¸ç¡®å®šæ€§é‡åŒ–æŠ€æœ¯çš„å¯æ§å’Œä¸€è‡´è¯„ä¼°æä¾›äº†ç¯å¢ƒã€‚æ­¤å¤–ï¼Œè¯¥åŸºå‡†æµ‹è¯•è¿˜æ”¯æŒå¯¹ä¿¡å¿ƒå½’ä¸€åŒ–æ–¹æ³•çš„è¯„ä¼°ï¼Œä»¥è¡¡é‡å…¶æä¾›å¯è§£é‡Šåˆ†æ•°èƒ½åŠ›çš„é«˜ä½ã€‚å€ŸåŠ©æˆ‘ä»¬çš„åŸºå‡†æµ‹è¯•ï¼Œæˆ‘ä»¬å¯¹UQå’Œå½’ä¸€åŒ–æŠ€æœ¯åœ¨åä¸€ä¸ªä»»åŠ¡ä¸Šè¿›è¡Œäº†å¤§è§„æ¨¡å®è¯ç ”ç©¶ï¼Œå¹¶ç¡®å®šäº†æœ€æœ‰æ•ˆçš„é€”å¾„ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„å¿«é€Ÿå‘å±•å¼•å‘äº†å¯¹äºå¤„ç†å…¶å¹»è§‰å’Œä½è´¨é‡è¾“å‡ºçš„å…³æ³¨ã€‚</li>
<li>ä¸ç¡®å®šæ€§é‡åŒ–ï¼ˆUQï¼‰åœ¨åº”å¯¹LLMæŒ‘æˆ˜ä¸­æ‰®æ¼”é‡è¦è§’è‰²ã€‚</li>
<li>ç›®å‰é’ˆå¯¹LLMçš„ä¸ç¡®å®šæ€§é‡åŒ–ç ”ç©¶åœ¨æŠ€æœ¯å’Œè¯„ä¼°æ–¹æ³•ä¸Šè¾ƒä¸ºåˆ†æ•£ã€‚</li>
<li>å¼•å…¥çš„æ–°å‹åŸºå‡†æµ‹è¯•é›†åˆå®ç°äº†å…ˆè¿›çš„ä¸ç¡®å®šæ€§é‡åŒ–åŸºå‡†æµ‹è¯•ã€‚</li>
<li>è¯¥åŸºå‡†æµ‹è¯•ä¸ºå„ç§æ–‡æœ¬ç”Ÿæˆä»»åŠ¡ä¸Šçš„æ–°å‹ä¸ç¡®å®šæ€§é‡åŒ–æŠ€æœ¯æä¾›äº†å¯æ§å’Œä¸€è‡´çš„è¯„ä¼°ç¯å¢ƒã€‚</li>
<li>åŸºå‡†æµ‹è¯•æ”¯æŒå¯¹ä¿¡å¿ƒå½’ä¸€åŒ–æ–¹æ³•çš„è¯„ä¼°ï¼Œè¡¡é‡å…¶æä¾›å¯è§£é‡Šåˆ†æ•°çš„èƒ½åŠ›ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2406.15627">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-8e564a5f891e3d7e0893b95401140a1e.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-bc18d24a40af11f55f58b1cf47d12e93.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="NV-Embed-Improved-Techniques-for-Training-LLMs-as-Generalist-Embedding-Models"><a href="#NV-Embed-Improved-Techniques-for-Training-LLMs-as-Generalist-Embedding-Models" class="headerlink" title="NV-Embed: Improved Techniques for Training LLMs as Generalist Embedding   Models"></a>NV-Embed: Improved Techniques for Training LLMs as Generalist Embedding   Models</h2><p><strong>Authors:Chankyu Lee, Rajarshi Roy, Mengyao Xu, Jonathan Raiman, Mohammad Shoeybi, Bryan Catanzaro, Wei Ping</strong></p>
<p>Decoder-only large language model (LLM)-based embedding models are beginning to outperform BERT or T5-based embedding models in general-purpose text embedding tasks, including dense vector-based retrieval. In this work, we introduce the NV-Embed model, incorporating architectural designs, training procedures, and curated datasets to significantly enhance the performance of LLM as a versatile embedding model, while maintaining its simplicity and reproducibility. For model architecture, we propose a latent attention layer to obtain pooled embeddings, which consistently improves retrieval and downstream task accuracy compared to mean pooling or using the last <EOS> token embedding from LLMs. To enhance representation learning, we remove the causal attention mask of LLMs during contrastive training. For training algorithm, we introduce a two-stage contrastive instruction-tuning method. It first applies contrastive training with instructions on retrieval datasets, utilizing in-batch negatives and curated hard negative examples. At stage-2, it blends various non-retrieval into instruction tuning, which not only enhances non-retrieval task accuracy but also improves retrieval performance. For training data, we utilize the hard-negative mining, synthetic data generation and existing public available datasets to boost the performance of embedding model. By combining these techniques, our NV-Embed-v1 and NV-Embed-v2 models obtained the No.1 position on the Massive Text Embedding Benchmark (MTEB) (as of May 24, 2024 and August 30, 2024, respectively) across 56 embedding tasks, demonstrating the sustained effectiveness of the proposed methods over time. Additionally, it achieved the highest scores in the Long Doc section and the second-highest scores in the QA section of the AIR Benchmark, which covers a range of out-of-domain information retrieval topics beyond those in MTEB. </p>
<blockquote>
<p>åŸºäºè§£ç å™¨çš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åµŒå…¥æ¨¡å‹å¼€å§‹åœ¨é€šç”¨æ–‡æœ¬åµŒå…¥ä»»åŠ¡ä¸­è¡¨ç°ä¼˜äºBERTæˆ–T5åµŒå…¥æ¨¡å‹ï¼ŒåŒ…æ‹¬åŸºäºå¯†é›†å‘é‡çš„æ£€ç´¢ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬å¼•å…¥äº†NV-Embedæ¨¡å‹ï¼Œå®ƒç»“åˆäº†æ¶æ„è®¾è®¡ã€è®­ç»ƒç¨‹åºå’Œç²¾é€‰æ•°æ®é›†ï¼Œæ—¨åœ¨æ˜¾è‘—å¢å¼ºLLMä½œä¸ºé€šç”¨åµŒå…¥æ¨¡å‹çš„è¡¨ç°ï¼ŒåŒæ—¶ä¿æŒå…¶ç®€æ´æ€§å’Œå¯é‡å¤æ€§ã€‚åœ¨æ¨¡å‹æ¶æ„æ–¹é¢ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ½œåœ¨æ³¨æ„åŠ›å±‚æ¥è·å¾—æ± åŒ–åµŒå…¥ï¼Œä¸åŸºäºLLMçš„å¹³å‡æ± åŒ–æˆ–ä½¿ç”¨æœ€åä¸€ä¸ª<EOS>ä»¤ç‰ŒåµŒå…¥ç›¸æ¯”ï¼Œå®ƒå§‹ç»ˆæé«˜äº†æ£€ç´¢å’Œä¸‹æ¸¸ä»»åŠ¡çš„å‡†ç¡®æ€§ã€‚ä¸ºäº†å¢å¼ºè¡¨ç¤ºå­¦ä¹ ï¼Œæˆ‘ä»¬åœ¨å¯¹æ¯”è®­ç»ƒæœŸé—´ç§»é™¤äº†LLMçš„å› æœæ³¨æ„åŠ›æ©ç ã€‚åœ¨è®­ç»ƒç®—æ³•æ–¹é¢ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§ä¸¤é˜¶æ®µçš„å¯¹æ¯”æŒ‡ä»¤å¾®è°ƒæ–¹æ³•ã€‚å®ƒé¦–å…ˆåœ¨æ£€ç´¢æ•°æ®é›†ä¸Šåº”ç”¨å¸¦æœ‰æŒ‡ä»¤çš„å¯¹æ¯”è®­ç»ƒï¼Œåˆ©ç”¨æ‰¹å¤„ç†å†…çš„è´Ÿæ ·æœ¬å’Œç²¾é€‰çš„ç¡¬è´Ÿæ ·æœ¬ã€‚åœ¨ç¬¬äºŒé˜¶æ®µï¼Œå®ƒå°†å„ç§éæ£€ç´¢ä»»åŠ¡èå…¥æŒ‡ä»¤å¾®è°ƒä¸­ï¼Œè¿™ä¸ä»…æé«˜äº†éæ£€ç´¢ä»»åŠ¡å‡†ç¡®æ€§ï¼Œè¿˜æé«˜äº†æ£€ç´¢æ€§èƒ½ã€‚å¯¹äºè®­ç»ƒæ•°æ®ï¼Œæˆ‘ä»¬åˆ©ç”¨ç¡¬è´Ÿæ ·æœ¬æŒ–æ˜ã€åˆæˆæ•°æ®ç”Ÿæˆå’Œç°æœ‰å…¬å…±å¯ç”¨æ•°æ®é›†æ¥æå‡åµŒå…¥æ¨¡å‹çš„æ€§èƒ½ã€‚é€šè¿‡ç»“åˆè¿™äº›æŠ€æœ¯ï¼Œæˆ‘ä»¬çš„NV-Embed-v1å’ŒNV-Embed-v2æ¨¡å‹åœ¨56ä¸ªåµŒå…¥ä»»åŠ¡ä¸Šè·å¾—äº†å¤§è§„æ¨¡æ–‡æœ¬åµŒå…¥åŸºå‡†æµ‹è¯•ï¼ˆMTEBï¼‰çš„ç¬¬ä¸€åï¼ˆæˆªè‡³2024å¹´5æœˆ24æ—¥å’Œ2024å¹´8æœˆ30æ—¥ï¼‰ï¼Œè¯æ˜äº†æ‰€æå‡ºæ–¹æ³•éšæ—¶é—´æ¨ç§»çš„æŒç»­æœ‰æ•ˆæ€§ã€‚æ­¤å¤–ï¼Œå®ƒåœ¨AIRåŸºå‡†æµ‹è¯•çš„Long Docéƒ¨åˆ†è·å¾—æœ€é«˜åˆ†ï¼Œåœ¨QAéƒ¨åˆ†è·å¾—ç¬¬äºŒåï¼Œæ¶µç›–äº†MTEBä»¥å¤–çš„å¹¿æ³›è·¨åŸŸä¿¡æ¯æ£€ç´¢ä¸»é¢˜ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2405.17428v2">PDF</a> We open-source the model at:   <a target="_blank" rel="noopener" href="https://huggingface.co/nvidia/NV-Embed-v2">https://huggingface.co/nvidia/NV-Embed-v2</a></p>
<p><strong>Summary</strong></p>
<p>åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„è§£ç å™¨åµŒå…¥æ¨¡å‹åœ¨é€šç”¨æ–‡æœ¬åµŒå…¥ä»»åŠ¡ä¸­å¼€å§‹è¡¨ç°å‡ºä¼˜äºBERTæˆ–T5çš„åµŒå…¥æ¨¡å‹æ€§èƒ½ï¼ŒåŒ…æ‹¬åŸºäºå¯†é›†å‘é‡çš„æ£€ç´¢ä»»åŠ¡ã€‚æœ¬ç ”ç©¶ä»‹ç»äº†NV-Embedæ¨¡å‹ï¼Œé€šè¿‡è®¾è®¡æ¶æ„ã€è®­ç»ƒç¨‹åºå’Œå®šåˆ¶æ•°æ®é›†æ¥æ˜¾è‘—æé«˜LLMä½œä¸ºé€šç”¨åµŒå…¥æ¨¡å‹çš„æ€§èƒ½ï¼ŒåŒæ—¶ä¿æŒå…¶ç®€å•æ€§å’Œå¯å¤ç°æ€§ã€‚NV-Embedæ¨¡å‹é€šè¿‡ä½¿ç”¨æ½œåœ¨æ„å›¾å±‚è¿›è¡Œæ± åŒ–åµŒå…¥æ¥æ”¹å–„æ£€ç´¢å’Œä¸‹æ¸¸ä»»åŠ¡å‡†ç¡®æ€§ï¼Œå¹¶å»é™¤LLMä¸­çš„å› æœæ³¨æ„åŠ›æ©ç è¿›è¡Œå¯¹æ¯”è®­ç»ƒã€‚æ­¤å¤–ï¼Œè¿˜ä»‹ç»äº†ä¸¤é˜¶æ®µå¯¹æ¯”æŒ‡ä»¤å¾®è°ƒæ–¹æ³•ï¼Œå¹¶åˆ©ç”¨ç¡¬è´Ÿæ ·æœ¬æŒ–æ˜ã€åˆæˆæ•°æ®ç”Ÿæˆç­‰ç°æœ‰å…¬å¼€æ•°æ®é›†æå‡åµŒå…¥æ¨¡å‹çš„æ€§èƒ½ã€‚NV-Embedæ¨¡å‹åœ¨å¤§é‡æ–‡æœ¬åµŒå…¥åŸºå‡†æµ‹è¯•ï¼ˆMTEBï¼‰ä¸­è·å¾—ç¬¬ä¸€åï¼Œåœ¨é•¿æœŸå’ŒçŸ­æœŸè¯„ä»·ä¸­éƒ½å±•ç¤ºäº†æ–¹æ³•çš„æœ‰æ•ˆæ€§ï¼Œå¹¶åœ¨AIRåŸºå‡†æµ‹è¯•ä¸­å–å¾—äº†ä¼˜å¼‚æˆç»©ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>LLMçš„è§£ç å™¨åµŒå…¥æ¨¡å‹åœ¨é€šç”¨æ–‡æœ¬åµŒå…¥ä»»åŠ¡ä¸­è¡¨ç°å‡ºä¼˜è¶Šæ€§èƒ½ã€‚</li>
<li>NV-Embedæ¨¡å‹é€šè¿‡ç‰¹å®šæ¶æ„ã€è®­ç»ƒç¨‹åºå’Œå®šåˆ¶æ•°æ®é›†æ˜¾è‘—æé«˜äº†LLMçš„åµŒå…¥æ€§èƒ½ã€‚</li>
<li>æ½œåœ¨æ„å›¾å±‚ç”¨äºæ± åŒ–åµŒå…¥æ”¹å–„äº†æ£€ç´¢å’Œä¸‹æ¸¸ä»»åŠ¡å‡†ç¡®æ€§ã€‚</li>
<li>å»é™¤LLMçš„å› æœæ³¨æ„åŠ›æ©ç è¿›è¡Œå¯¹æ¯”è®­ç»ƒå¢å¼ºäº†è¡¨ç¤ºå­¦ä¹ ã€‚</li>
<li>ä¸¤é˜¶æ®µå¯¹æ¯”æŒ‡ä»¤å¾®è°ƒæ–¹æ³•æé«˜äº†éæ£€ç´¢ä»»åŠ¡å‡†ç¡®æ€§å’Œæ£€ç´¢æ€§èƒ½ã€‚</li>
<li>åˆ©ç”¨ç¡¬è´Ÿæ ·æœ¬æŒ–æ˜ã€åˆæˆæ•°æ®ç”Ÿæˆç­‰ç­–ç•¥æå‡äº†åµŒå…¥æ¨¡å‹çš„æ€§èƒ½ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2405.17428">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-0e0d00d194d61af581720adde76700fd.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-4f6bed9c73cb84d797cc460c1b9e090a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f5d3e81a4d996b2f5400d0d6a1d7cdbb.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="Attention-Mechanisms-Donâ€™t-Learn-Additive-Models-Rethinking-Feature-Importance-for-Transformers"><a href="#Attention-Mechanisms-Donâ€™t-Learn-Additive-Models-Rethinking-Feature-Importance-for-Transformers" class="headerlink" title="Attention Mechanisms Donâ€™t Learn Additive Models: Rethinking Feature   Importance for Transformers"></a>Attention Mechanisms Donâ€™t Learn Additive Models: Rethinking Feature   Importance for Transformers</h2><p><strong>Authors:Tobias Leemann, Alina Fastowski, Felix Pfeiffer, Gjergji Kasneci</strong></p>
<p>We address the critical challenge of applying feature attribution methods to the transformer architecture, which dominates current applications in natural language processing and beyond. Traditional attribution methods to explainable AI (XAI) explicitly or implicitly rely on linear or additive surrogate models to quantify the impact of input features on a modelâ€™s output. In this work, we formally prove an alarming incompatibility: transformers are structurally incapable of representing linear or additive surrogate models used for feature attribution, undermining the grounding of these conventional explanation methodologies. To address this discrepancy, we introduce the Softmax-Linked Additive Log Odds Model (SLALOM), a novel surrogate model specifically designed to align with the transformer framework. SLALOM demonstrates the capacity to deliver a range of insightful explanations with both synthetic and real-world datasets. We highlight SLALOMâ€™s unique efficiency-quality curve by showing that SLALOM can produce explanations with substantially higher fidelity than competing surrogate models or provide explanations of comparable quality at a fraction of their computational costs. We release code for SLALOM as an open-source project online at <a target="_blank" rel="noopener" href="https://github.com/tleemann/slalom_explanations">https://github.com/tleemann/slalom_explanations</a>. </p>
<blockquote>
<p>æˆ‘ä»¬é¢ä¸´å°†ç‰¹å¾å½’å› æ–¹æ³•åº”ç”¨äºä¸»å¯¼å½“å‰è‡ªç„¶è¯­è¨€å¤„ç†åŠå…¶ä»–é¢†åŸŸåº”ç”¨çš„å˜å‹å™¨æ¶æ„çš„å…³é”®æŒ‘æˆ˜ã€‚ä¼ ç»Ÿçš„å½’å› æ–¹æ³•æ˜ç¡®åœ°æˆ–éšå«åœ°ä¾èµ–äºçº¿æ€§æˆ–é™„åŠ æ›¿ä»£æ¨¡å‹æ¥é‡åŒ–è¾“å…¥ç‰¹å¾å¯¹æ¨¡å‹è¾“å‡ºçš„å½±å“ï¼Œä»¥å®ç°å¯è§£é‡Šäººå·¥æ™ºèƒ½ï¼ˆXAIï¼‰ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬æ­£å¼è¯æ˜äº†ä¸€ä¸ªä»¤äººè­¦è§‰çš„çŸ›ç›¾ï¼šä»ç»“æ„ä¸Šæ¥è¯´ï¼Œå˜å‹å™¨æ— æ³•ä»£è¡¨ç”¨äºç‰¹å¾å½’å› çš„çº¿æ€§æˆ–é™„åŠ æ›¿ä»£æ¨¡å‹ï¼Œè¿™ç ´åäº†è¿™äº›ä¼ ç»Ÿè§£é‡Šæ–¹æ³•çš„åŸºç¡€ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬å¼•å…¥äº†Softmax-Linked Additive Log Odds Modelï¼ˆSLALOMï¼‰ï¼Œè¿™æ˜¯ä¸€ç§ä¸“é—¨è®¾è®¡æ¥ä¸å˜å‹å™¨æ¡†æ¶å¯¹é½çš„æ–°å‹æ›¿ä»£æ¨¡å‹ã€‚SLALOMå±•ç¤ºäº†åœ¨åˆæˆå’ŒçœŸå®ä¸–ç•Œæ•°æ®é›†ä¸Šæä¾›ä¸€ç³»åˆ—æ·±åˆ»è§£é‡Šçš„èƒ½åŠ›ã€‚æˆ‘ä»¬é€šè¿‡å±•ç¤ºSLALOMèƒ½å¤Ÿäº§ç”Ÿæ¯”ç«äº‰æ›¿ä»£æ¨¡å‹æ›´é«˜ä¿çœŸåº¦çš„è§£é‡Šï¼Œæˆ–è€…æä¾›åŒç­‰è´¨é‡çš„è§£é‡Šä½†è®¡ç®—æˆæœ¬è¾ƒä½ï¼Œæ¥çªå‡ºSLALOMç‹¬ç‰¹çš„æ•ˆç‡-è´¨é‡æ›²çº¿ã€‚æˆ‘ä»¬åœ¨<a target="_blank" rel="noopener" href="https://github.com/tleemann/slalom_explanations%E4%B8%8A%E5%8F%91%E5%B8%83%E4%BA%86SLALOM%E7%9A%84%E5%BC%80%E6%BA%90%E9%A1%B9%E7%9B%AE%E4%BB%A3%E7%A0%81%E3%80%82">https://github.com/tleemann/slalom_explanationsä¸Šå‘å¸ƒäº†SLALOMçš„å¼€æºé¡¹ç›®ä»£ç ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2405.13536v2">PDF</a> TMLR Camera-Ready version</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡è§£å†³äº†å°†ç‰¹å¾å½’å› æ–¹æ³•åº”ç”¨äºè‡ªç„¶è¯­è¨€å¤„ç†åŠå…¶ä»–é¢†åŸŸå¹¿æ³›åº”ç”¨çš„transformeræ¶æ„çš„å…³é”®æŒ‘æˆ˜ã€‚ä¼ ç»Ÿçš„äººå·¥æ™ºèƒ½è§£é‡Šï¼ˆXAIï¼‰å½’å› æ–¹æ³•ç›´æ¥æˆ–é—´æ¥ä¾èµ–äºçº¿æ€§æˆ–é™„åŠ ä»£ç†æ¨¡å‹æ¥è¡¡é‡è¾“å…¥ç‰¹å¾å¯¹æ¨¡å‹è¾“å‡ºçš„å½±å“ã€‚ç„¶è€Œï¼Œæœ¬æ–‡æ­£å¼è¯æ˜äº†ä¸€ä¸ªä»¤äººæ‹…å¿§çš„ä¸å…¼å®¹æ€§ï¼štransformerçš„ç»“æ„æ— æ³•ä»£è¡¨ç”¨äºç‰¹å¾å½’å› çš„çº¿æ€§æˆ–é™„åŠ ä»£ç†æ¨¡å‹ï¼Œè¿™ä½¿å¾—è¿™äº›ä¼ ç»Ÿè§£é‡Šæ–¹æ³•çš„æ ¹åŸºåŠ¨æ‘‡ã€‚ä¸ºè§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†åä¸ºSLALOMçš„æ–°å‹ä»£ç†æ¨¡å‹ï¼Œè¯¥æ¨¡å‹ä¸“é—¨è®¾è®¡ä»¥ä¸transformeræ¡†æ¶å¯¹é½ã€‚SLALOMèƒ½å¤Ÿåœ¨åˆæˆå’ŒçœŸå®æ•°æ®é›†ä¸Šæä¾›ä¸€ç³»åˆ—æ·±å…¥çš„è§£é‡Šã€‚æˆ‘ä»¬å¼ºè°ƒSLALOMçš„é«˜æ•ˆæ€§ä¸å…¶è´¨é‡ä¹‹é—´çš„ç‹¬ç‰¹å…³ç³»æ›²çº¿ï¼Œè¡¨æ˜SLALOMå¯ä»¥åœ¨æä¾›æ›´é«˜ä¿çœŸåº¦çš„è§£é‡Šçš„åŒæ—¶ï¼Œç›¸è¾ƒäºå…¶ä»–ä»£ç†æ¨¡å‹å¤§å¹…é™ä½è®¡ç®—æˆæœ¬ã€‚æˆ‘ä»¬å·²å°†SLALOMçš„ä»£ç ä½œä¸ºå¼€æºé¡¹ç›®åœ¨çº¿å‘å¸ƒåœ¨[é“¾æ¥åœ°å€]ï¼ˆè¯·æ ¹æ®å®é™…æƒ…å†µæ›¿æ¢ï¼‰ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ä¼ ç»Ÿç‰¹å¾å½’å› æ–¹æ³•ä¾èµ–äºçº¿æ€§æˆ–é™„åŠ ä»£ç†æ¨¡å‹ï¼Œä½†åœ¨transformeræ¶æ„ä¸­å­˜åœ¨ä¸å…¼å®¹æ€§é—®é¢˜ã€‚</li>
<li>å¼•å…¥æ–°å‹ä»£ç†æ¨¡å‹SLALOMï¼Œä¸“ä¸ºtransformeræ¶æ„è®¾è®¡ï¼Œä»¥è§£å†³ä¼ ç»Ÿè§£é‡Šæ–¹æ³•çš„ä¸å…¼å®¹é—®é¢˜ã€‚</li>
<li>SLALOMåœ¨åˆæˆå’ŒçœŸå®æ•°æ®é›†ä¸Šå±•ç°å‡ºå¼ºå¤§çš„è§£é‡Šèƒ½åŠ›ã€‚</li>
<li>SLALOMä¸ç°æœ‰ä»£ç†æ¨¡å‹ç›¸æ¯”å…·æœ‰è¾ƒé«˜çš„ä¿çœŸåº¦å’Œè®¡ç®—æ•ˆç‡ä¼˜åŠ¿ã€‚ </li>
<li>é€šè¿‡å…¬å¼€ä»£ç å®ç°ï¼Œä¾¿äºç ”ç©¶è€…å’Œå¼€å‘è€…ä½¿ç”¨SLALOMè¿›è¡Œè¿›ä¸€æ­¥ç ”ç©¶å’Œåº”ç”¨ã€‚ </li>
<li>SLALOMå¯¹äºç†è§£å’Œè§£é‡Štransformeræ¶æ„çš„å·¥ä½œåŸç†å…·æœ‰é‡è¦æ„ä¹‰ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2405.13536">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-73c677aae868613292b4aebaf3a79434.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-acd85c6b62daabeff15410f32047f968.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-2bcc361a70633a5f73b8583ed046eef6.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="AlgoFormer-An-Efficient-Transformer-Framework-with-Algorithmic-Structures"><a href="#AlgoFormer-An-Efficient-Transformer-Framework-with-Algorithmic-Structures" class="headerlink" title="AlgoFormer: An Efficient Transformer Framework with Algorithmic   Structures"></a>AlgoFormer: An Efficient Transformer Framework with Algorithmic   Structures</h2><p><strong>Authors:Yihang Gao, Chuanyang Zheng, Enze Xie, Han Shi, Tianyang Hu, Yu Li, Michael K. Ng, Zhenguo Li, Zhaoqiang Liu</strong></p>
<p>Besides natural language processing, transformers exhibit extraordinary performance in solving broader applications, including scientific computing and computer vision. Previous works try to explain this from the expressive power and capability perspectives that standard transformers are capable of performing some algorithms. To empower transformers with algorithmic capabilities and motivated by the recently proposed looped transformer, we design a novel transformer framework, dubbed Algorithm Transformer (abbreviated as AlgoFormer). We provide an insight that efficient transformer architectures can be designed by leveraging prior knowledge of tasks and the underlying structure of potential algorithms. Compared with the standard transformer and vanilla looped transformer, the proposed AlgoFormer can perform efficiently in algorithm representation in some specific tasks. In particular, inspired by the structure of human-designed learning algorithms, our transformer framework consists of a pre-transformer that is responsible for task preprocessing, a looped transformer for iterative optimization algorithms, and a post-transformer for producing the desired results after post-processing. We provide theoretical evidence of the expressive power of the AlgoFormer in solving some challenging problems, mirroring human-designed algorithms. Furthermore, some theoretical and empirical results are presented to show that the designed transformer has the potential to perform algorithm representation and learning. Experimental results demonstrate the empirical superiority of the proposed transformer in that it outperforms the standard transformer and vanilla looped transformer in some specific tasks. An extensive experiment on real language tasks (e.g., neural machine translation of German and English, and text classification) further validates the expressiveness and effectiveness of AlgoFormer. </p>
<blockquote>
<p>é™¤äº†è‡ªç„¶è¯­è¨€å¤„ç†å¤–ï¼Œå˜å‹å™¨ï¼ˆtransformerï¼‰åœ¨è§£å†³æ›´å¹¿æ³›çš„åº”ç”¨æ–¹é¢è¡¨ç°å‡ºå“è¶Šçš„æ€§èƒ½ï¼ŒåŒ…æ‹¬ç§‘å­¦è®¡ç®—å’Œè®¡ç®—æœºè§†è§‰ã€‚ä¹‹å‰çš„ç ”ç©¶å·¥ä½œè¯•å›¾ä»è¡¨ç°åŠ›å’Œèƒ½åŠ›è§’åº¦è§£é‡Šè¿™ä¸€ç‚¹ï¼Œå³æ ‡å‡†å˜å‹å™¨èƒ½å¤Ÿæ‰§è¡ŒæŸäº›ç®—æ³•ã€‚ä¸ºäº†èµ‹äºˆå˜å‹å™¨ç®—æ³•èƒ½åŠ›ï¼Œå¹¶å—åˆ°æœ€è¿‘æå‡ºçš„å¾ªç¯å˜å‹å™¨çš„å¯å‘ï¼Œæˆ‘ä»¬è®¾è®¡äº†ä¸€ç§æ–°å‹å˜å‹å™¨æ¡†æ¶ï¼Œç§°ä¸ºç®—æ³•å˜å‹å™¨ï¼ˆAlgorithm Transformerï¼Œç®€ç§°AlgoFormerï¼‰ã€‚æˆ‘ä»¬æä¾›äº†ä¸€ç§è§è§£ï¼Œå³é€šè¿‡åˆ©ç”¨ä»»åŠ¡çš„å…ˆéªŒçŸ¥è¯†å’Œæ½œåœ¨ç®—æ³•çš„åŸºæœ¬ç»“æ„ï¼Œå¯ä»¥æœ‰æ•ˆåœ°è®¾è®¡å˜å‹å™¨æ¶æ„ã€‚ä¸æ ‡å‡†å˜å‹å™¨å’ŒåŸºæœ¬çš„å¾ªç¯å˜å‹å™¨ç›¸æ¯”ï¼Œæ‰€æå‡ºçš„AlgoFormeråœ¨æŸäº›ç‰¹å®šä»»åŠ¡çš„ç®—æ³•è¡¨ç¤ºæ–¹é¢èƒ½å¤Ÿé«˜æ•ˆæ‰§è¡Œã€‚ç‰¹åˆ«æ˜¯ï¼Œå—åˆ°äººç±»è®¾è®¡çš„å­¦ä¹ ç®—æ³•çš„ç»“æ„çš„å¯å‘ï¼Œæˆ‘ä»¬çš„å˜å‹å™¨æ¡†æ¶åŒ…æ‹¬ä¸€ä¸ªè´Ÿè´£ä»»åŠ¡é¢„å¤„ç†çš„é¢„å˜å‹å™¨ã€ä¸€ä¸ªç”¨äºè¿­ä»£ä¼˜åŒ–ç®—æ³•çš„å¾ªç¯å˜å‹å™¨ã€ä»¥åŠä¸€ä¸ªç”¨äºåå¤„ç†çš„åå˜å‹å™¨ï¼Œä»¥äº§ç”Ÿæ‰€éœ€çš„ç»“æœã€‚æˆ‘ä»¬æä¾›äº†AlgoFormeråœ¨è§£å†³ä¸€äº›å…·æœ‰æŒ‘æˆ˜æ€§çš„é—®é¢˜æ—¶çš„è¡¨ç°åŠ›çš„ç†è®ºè¯æ®ï¼Œåæ˜ äººç±»è®¾è®¡çš„ç®—æ³•ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜æä¾›äº†ä¸€äº›ç†è®ºå’Œå®è¯ç»“æœï¼Œä»¥å±•ç¤ºæ‰€è®¾è®¡çš„å˜å‹å™¨åœ¨ç®—æ³•è¡¨ç¤ºå’Œå­¦ä¹ æ–¹é¢çš„æ½œåŠ›ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œæ‰€æå‡ºçš„å˜å‹å™¨åœ¨æŸäº›ç‰¹å®šä»»åŠ¡ä¸Šä¼˜äºæ ‡å‡†å˜å‹å™¨å’ŒåŸºæœ¬çš„å¾ªç¯å˜å‹å™¨ã€‚åœ¨çœŸå®è¯­è¨€ä»»åŠ¡ï¼ˆä¾‹å¦‚å¾·è¯­å’Œè‹±è¯­çš„ç¥ç»æœºå™¨ç¿»è¯‘å’Œæ–‡æœ¬åˆ†ç±»ï¼‰ä¸Šçš„å¤§é‡å®éªŒè¿›ä¸€æ­¥éªŒè¯äº†AlgoFormerçš„è¡¨è¾¾åŠ›å’Œæœ‰æ•ˆæ€§ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2402.13572v2">PDF</a> Published at Transactions on Machine Learning Research (TMLR). The   paper provides insight that the Transformer architectures can mimic the   algorithm structures in (in-context) algorithm learning and representation.   The incorporated algorithmic structure in Algoformer shows its potential in   (deep learning for) scientific computing, besides the real language tasks</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†é™¤è‡ªç„¶è¯­è¨€å¤„ç†å¤–ï¼Œå˜å‹å™¨åœ¨æ›´å¹¿æ³›çš„åº”ç”¨ä¸­çš„å“è¶Šæ€§èƒ½ï¼ŒåŒ…æ‹¬ç§‘å­¦è®¡ç®—å’Œè®¡ç®—æœºè§†è§‰ã€‚ä¸ºèµ‹èƒ½å˜å‹å™¨å…·æœ‰ç®—æ³•èƒ½åŠ›ï¼Œå¹¶å—å¾ªç¯å˜å‹å™¨çš„å¯å‘ï¼Œè®¾è®¡äº†ä¸€ç§æ–°å‹å˜å‹å™¨æ¡†æ¶â€”â€”Algorithm Transformerï¼ˆç®€ç§°AlgoFormerï¼‰ã€‚é€šè¿‡åˆ©ç”¨ä»»åŠ¡å…ˆéªŒçŸ¥è¯†å’Œæ½œåœ¨ç®—æ³•çš„åº•å±‚ç»“æ„ï¼Œå¯ä»¥è®¾è®¡æœ‰æ•ˆçš„å˜å‹å™¨æ¶æ„ã€‚ä¸æ ‡å‡†å˜å‹å™¨å’Œå¾ªç¯å˜å‹å™¨ç›¸æ¯”ï¼Œæ‰€æå‡ºçš„AlgoFormeråœ¨æŸäº›ç‰¹å®šä»»åŠ¡ä¸­çš„ç®—æ³•è¡¨ç¤ºæ•ˆç‡æ›´é«˜ã€‚è¯¥æ¡†æ¶åŒ…æ‹¬è´Ÿè´£ä»»åŠ¡é¢„å¤„ç†çš„é¢„å˜å‹å™¨ã€è´Ÿè´£è¿­ä»£ä¼˜åŒ–ç®—æ³•çš„å¾ªç¯å˜å‹å™¨ä»¥åŠè´Ÿè´£åå¤„ç†çš„åå˜å‹å™¨ã€‚ç†è®ºè¯æ®è¡¨æ˜AlgoFormeråœ¨è§£å†³æŸäº›æŒ‘æˆ˜æ€§é—®é¢˜æ—¶å…·æœ‰è¡¨ç°åŠ›ï¼Œå¯æ¨¡æ‹Ÿäººç±»è®¾è®¡çš„ç®—æ³•ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥å˜å‹å™¨åœ¨ç‰¹å®šä»»åŠ¡ä¸Šçš„è¡¨ç°ä¼˜äºæ ‡å‡†å’Œå¾ªç¯å˜å‹å™¨ã€‚åœ¨çœŸå®è¯­è¨€ä»»åŠ¡ä¸Šçš„å¹¿æ³›å®éªŒè¿›ä¸€æ­¥éªŒè¯äº†AlgoFormerçš„è¡¨è¾¾åŠ›å’Œæœ‰æ•ˆæ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å˜å‹å™¨åœ¨è‡ªç„¶è¯­è¨€å¤„ç†ä»¥å¤–çš„é¢†åŸŸï¼Œå¦‚ç§‘å­¦è®¡ç®—å’Œè®¡ç®—æœºè§†è§‰ï¼Œä¹Ÿæœ‰å“è¶Šæ€§èƒ½ã€‚</li>
<li>æå‡ºäº†ä¸€ç§æ–°å‹å˜å‹å™¨æ¡†æ¶Algorithm Transformerï¼ˆAlgoFormerï¼‰ï¼Œèåˆäº†é¢„å˜å‹å™¨ã€å¾ªç¯å˜å‹å™¨å’Œåå˜å‹å™¨çš„è®¾è®¡ã€‚</li>
<li>AlgoFormeråˆ©ç”¨ä»»åŠ¡çš„å…ˆéªŒçŸ¥è¯†å’Œæ½œåœ¨ç®—æ³•çš„åº•å±‚ç»“æ„æ¥æé«˜ç®—æ³•è¡¨ç¤ºçš„æ•ˆç‡ã€‚</li>
<li>AlgoFormeråœ¨æŸäº›ç‰¹å®šä»»åŠ¡ä¸Šçš„è¡¨ç°ä¼˜äºæ ‡å‡†å˜å‹å™¨å’Œå¾ªç¯å˜å‹å™¨ã€‚</li>
<li>AlgoFormerå…·æœ‰è§£å†³æŸäº›æŒ‘æˆ˜æ€§é—®é¢˜çš„ç†è®ºä¾æ®ï¼Œå¯æ¨¡æ‹Ÿäººç±»è®¾è®¡çš„ç®—æ³•ã€‚</li>
<li>å®éªŒç»“æœè¯æ˜äº†AlgoFormerçš„æœ‰æ•ˆæ€§å’Œä¼˜è¶Šæ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2402.13572">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-d409c02cbc5d0682413f4b3ea8fb9f16.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-316649059c7148ae44d0220a2695effb.jpg" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-01-14/LLM/">https://kedreamix.github.io/Talk2Paper/Paper/2025-01-14/LLM/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/LLM/">
                                    <span class="chip bg-color">LLM</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-01-13/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/">
                    <div class="card-image">
                        
                        <img src="https://pica.zhimg.com/v2-fbe9ac1ef0f46cbfd28ac30122713098.jpg" class="responsive-img" alt="åŒ»å­¦å›¾åƒ">
                        
                        <span class="card-title">åŒ»å­¦å›¾åƒ</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            åŒ»å­¦å›¾åƒ æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-01-14  The ultraviolet luminosity function of star-forming galaxies between   redshifts of 0.4 and 0.6
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-01-14
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/" class="post-category">
                                    åŒ»å­¦å›¾åƒ
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/">
                        <span class="chip bg-color">åŒ»å­¦å›¾åƒ</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-01-13/Diffusion%20Models/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-bf4c14965d29e3ebccb6c77db3899446.jpg" class="responsive-img" alt="Diffusion Models">
                        
                        <span class="card-title">Diffusion Models</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Diffusion Models æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-01-14  FaceMe Robust Blind Face Restoration with Personal Identification
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-01-14
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Diffusion-Models/" class="post-category">
                                    Diffusion Models
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Diffusion-Models/">
                        <span class="chip bg-color">Diffusion Models</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">29301k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
