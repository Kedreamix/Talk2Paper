<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="R1_Reasoning">
    <meta name="description" content="R1_Reasoning æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-11-12  Revisiting the Data Sampling in Multimodal Post-training from a Difficulty-Distinguish View">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>R1_Reasoning | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://picx.zhimg.com/v2-b8f6490cca3316d74c39ef4c9194fd74')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">R1_Reasoning</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/R1-Reasoning/">
                                <span class="chip bg-color">R1_Reasoning</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/R1-Reasoning/" class="post-category">
                                R1_Reasoning
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-11-12
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-11-15
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    9.1k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    37 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-11-12-æ›´æ–°"><a href="#2025-11-12-æ›´æ–°" class="headerlink" title="2025-11-12 æ›´æ–°"></a>2025-11-12 æ›´æ–°</h1><h2 id="Revisiting-the-Data-Sampling-in-Multimodal-Post-training-from-a-Difficulty-Distinguish-View"><a href="#Revisiting-the-Data-Sampling-in-Multimodal-Post-training-from-a-Difficulty-Distinguish-View" class="headerlink" title="Revisiting the Data Sampling in Multimodal Post-training from a Difficulty-Distinguish View"></a>Revisiting the Data Sampling in Multimodal Post-training from a Difficulty-Distinguish View</h2><p><strong>Authors:Jianyu Qi, Ding Zou, Wenrui Yan, Rui Ma, Jiaxu Li, Zhijie Zheng, Zhiguo Yang, Rongchang Zhao</strong></p>
<p>Recent advances in Multimodal Large Language Models (MLLMs) have spurred significant progress in Chain-of-Thought (CoT) reasoning. Building on the success of Deepseek-R1, researchers extended multimodal reasoning to post-training paradigms based on reinforcement learning (RL), focusing predominantly on mathematical datasets. However, existing post-training paradigms tend to neglect two critical aspects: (1) The lack of quantifiable difficulty metrics capable of strategically screening samples for post-training optimization. (2) Suboptimal post-training paradigms that fail to jointly optimize perception and reasoning capabilities. To address this gap, we propose two novel difficulty-aware sampling strategies: Progressive Image Semantic Masking (PISM) quantifies sample hardness through systematic image degradation, while Cross-Modality Attention Balance (CMAB) assesses cross-modal interaction complexity via attention distribution analysis. Leveraging these metrics, we design a hierarchical training framework that incorporates both GRPO-only and SFT+GRPO hybrid training paradigms, and evaluate them across six benchmark datasets. Experiments demonstrate consistent superiority of GRPO applied to difficulty-stratified samples compared to conventional SFT+GRPO pipelines, indicating that strategic data sampling can obviate the need for supervised fine-tuning while improving model accuracy. Our code will be released at <a target="_blank" rel="noopener" href="https://github.com/qijianyu277/DifficultySampling">https://github.com/qijianyu277/DifficultySampling</a>.</p>
<blockquote>
<p>åœ¨Multimodal Large Language Modelsï¼ˆMLLMsï¼‰çš„æœ€æ–°è¿›å±•æ¨åŠ¨ä¸‹ï¼Œé“¾å¼æ€ç»´ï¼ˆCoTï¼‰æ¨ç†å–å¾—äº†é‡å¤§è¿›å±•ã€‚åŸºäºDeepseek-R1çš„æˆåŠŸï¼Œç ”ç©¶è€…å°†å¤šæ¨¡æ€æ¨ç†æ‰©å±•åˆ°åŸºäºå¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰çš„åæœŸè®­ç»ƒæ¨¡å¼ï¼Œä¸»è¦é›†ä¸­åœ¨æ•°å­¦æ•°æ®é›†ä¸Šã€‚ç„¶è€Œï¼Œç°æœ‰çš„åæœŸè®­ç»ƒæ¨¡å¼å¾€å¾€å¿½ç•¥äº†ä¸¤ä¸ªå…³é”®æ–¹é¢ï¼šï¼ˆ1ï¼‰ç¼ºä¹å¯é‡åŒ–çš„éš¾åº¦æŒ‡æ ‡ï¼Œæ— æ³•ä¸ºåæœŸè®­ç»ƒä¼˜åŒ–ç­–ç•¥æ€§åœ°ç­›é€‰æ ·æœ¬ã€‚ï¼ˆ2ï¼‰æ¬¡ä¼˜çš„åæœŸè®­ç»ƒæ¨¡å¼æ— æ³•åŒæ—¶ä¼˜åŒ–æ„ŸçŸ¥å’Œæ¨ç†èƒ½åŠ›ã€‚ä¸ºäº†å¼¥è¡¥è¿™ä¸€ç©ºç™½ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸¤ç§æ–°çš„éš¾åº¦æ„ŸçŸ¥é‡‡æ ·ç­–ç•¥ï¼šæ¸è¿›å›¾åƒè¯­ä¹‰æ©è”½ï¼ˆPISMï¼‰é€šè¿‡ç³»ç»Ÿå›¾åƒé€€åŒ–é‡åŒ–æ ·æœ¬éš¾åº¦ï¼Œè€Œè·¨æ¨¡æ€æ³¨æ„åŠ›å¹³è¡¡ï¼ˆCMABï¼‰åˆ™é€šè¿‡æ³¨æ„åŠ›åˆ†å¸ƒåˆ†æè¯„ä¼°è·¨æ¨¡æ€äº¤äº’å¤æ‚æ€§ã€‚åˆ©ç”¨è¿™äº›æŒ‡æ ‡ï¼Œæˆ‘ä»¬è®¾è®¡äº†ä¸€ä¸ªåˆ†å±‚è®­ç»ƒæ¡†æ¶ï¼Œè¯¥æ¡†æ¶ç»“åˆäº†ä»…ä½¿ç”¨GRPOå’ŒSFT+GRPOæ··åˆè®­ç»ƒæ¨¡å¼ï¼Œå¹¶åœ¨å…­ä¸ªåŸºå‡†æ•°æ®é›†ä¸Šè¿›è¡Œäº†è¯„ä¼°ã€‚å®éªŒè¡¨æ˜ï¼Œä¸å¸¸è§„SFT+GRPOç®¡é“ç›¸æ¯”ï¼Œåº”ç”¨äºéš¾åº¦åˆ†å±‚æ ·æœ¬çš„GRPOè¡¨ç°æ›´ä¼˜è¶Šä¸”ä¸€è‡´ï¼Œè¿™è¡¨æ˜æˆ˜ç•¥æ•°æ®é‡‡æ ·å¯ä»¥å–ä»£ç›‘ç£å¾®è°ƒçš„éœ€è¦ï¼ŒåŒæ—¶æé«˜æ¨¡å‹å‡†ç¡®æ€§ã€‚æˆ‘ä»¬çš„ä»£ç å°†åœ¨<a target="_blank" rel="noopener" href="https://github.com/qijianyu277/DifficultySampling%E4%B8%8A%E5%8F%91%E5%B8%83%E3%80%82">https://github.com/qijianyu277/DifficultySamplingä¸Šå‘å¸ƒã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2511.06722v1">PDF</a> Accpeted by AAAI 2026</p>
<p><strong>Summary</strong><br>å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰åœ¨é“¾å¼æ€ç»´ï¼ˆCoTï¼‰æ¨ç†æ–¹é¢å–å¾—äº†æ˜¾è‘—è¿›å±•ã€‚ç„¶è€Œï¼Œç°æœ‰ç ”ç©¶å¿½ç•¥äº†é‡åŒ–éš¾åº¦æŒ‡æ ‡å’Œè”åˆä¼˜åŒ–æ„ŸçŸ¥å’Œæ¨ç†èƒ½åŠ›çš„ç­–ç•¥ã€‚ä¸ºè§£å†³è¿™äº›é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†ä¸¤ç§éš¾åº¦æ„ŸçŸ¥é‡‡æ ·ç­–ç•¥ï¼Œå¹¶é€šè¿‡åˆ†å±‚è®­ç»ƒæ¡†æ¶åº”ç”¨äºå¤šä¸ªåŸºå‡†æ•°æ®é›†è¿›è¡Œå®éªŒè¯„ä¼°ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œåœ¨éš¾åº¦åˆ†å±‚æ ·æœ¬ä¸Šåº”ç”¨GRPOç›¸æ¯”ä¼ ç»ŸSFT+GRPOç®¡é“å…·æœ‰ä¸€è‡´æ€§ä¼˜åŠ¿ï¼Œè¡¨æ˜æˆ˜ç•¥æ•°æ®é‡‡æ ·å¯æé«˜æ¨¡å‹ç²¾åº¦ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰åœ¨é“¾å¼æ€ç»´ï¼ˆCoTï¼‰æ¨ç†æ–¹é¢å–å¾—è¿›å±•ã€‚</li>
<li>ç°æœ‰ç ”ç©¶å¿½è§†äº†é‡åŒ–éš¾åº¦æŒ‡æ ‡å’Œè”åˆä¼˜åŒ–æ„ŸçŸ¥å’Œæ¨ç†èƒ½åŠ›çš„ç­–ç•¥ã€‚</li>
<li>æœ¬æ–‡æå‡ºäº†ä¸¤ç§éš¾åº¦æ„ŸçŸ¥é‡‡æ ·ç­–ç•¥ï¼šæ¸è¿›å›¾åƒè¯­ä¹‰æ©è”½ï¼ˆPISMï¼‰å’Œè·¨æ¨¡æ€æ³¨æ„åŠ›å¹³è¡¡ï¼ˆCMABï¼‰ã€‚</li>
<li>é€šè¿‡åˆ†å±‚è®­ç»ƒæ¡†æ¶å°†è¿™ä¸¤ç§ç­–ç•¥åº”ç”¨äºå¤šä¸ªåŸºå‡†æ•°æ®é›†è¿›è¡Œè¯„ä¼°ã€‚</li>
<li>å®éªŒç»“æœæ˜¾ç¤ºGRPOåœ¨éš¾åº¦åˆ†å±‚æ ·æœ¬ä¸Šå…·æœ‰ä¼˜åŠ¿ï¼Œè¶…è¶Šäº†ä¼ ç»Ÿçš„SFT+GRPOç®¡é“ã€‚</li>
<li>æˆ˜ç•¥æ•°æ®é‡‡æ ·å¯ä»¥æé«˜æ¨¡å‹ç²¾åº¦ï¼Œç”šè‡³å¯èƒ½å–ä»£ç›‘ç£å¾®è°ƒçš„éœ€è¦ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2511.06722">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-6280d482774b7ae31151bf73d38778de" align="middle">
<img src="https://picx.zhimg.com/v2-71cdccbf20bacefac66fb326c8572a09" align="middle">
<img src="https://picx.zhimg.com/v2-5c4b4c74a4d77362a8766e99329d6647" align="middle">
<img src="https://picx.zhimg.com/v2-57d13a09d544134ce12a848e0be23305" align="middle">
<img src="https://picx.zhimg.com/v2-54f1846667d95f5001e67e7f8fc0cdd1" align="middle">
<img src="https://picx.zhimg.com/v2-40476707e7d2b8db725f19e2752b6b9e" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="EgoExo-Con-Exploring-View-Invariant-Video-Temporal-Understanding"><a href="#EgoExo-Con-Exploring-View-Invariant-Video-Temporal-Understanding" class="headerlink" title="EgoExo-Con: Exploring View-Invariant Video Temporal Understanding"></a>EgoExo-Con: Exploring View-Invariant Video Temporal Understanding</h2><p><strong>Authors:Minjoon Jung, Junbin Xiao, Junghyun Kim, Byoung-Tak Zhang, Angela Yao</strong></p>
<p>Can Video-LLMs achieve consistent temporal understanding when videos capture the same event from different viewpoints? To study this, we introduce EgoExo-Con (Consistency), a benchmark of comprehensively synchronized egocentric and exocentric video pairs with human-refined queries in natural language. EgoExo-Con emphasizes two temporal understanding tasks: Temporal Verification and Temporal Grounding. It evaluates not only correctness but consistency across viewpoints. Our analysis reveals two critical limitations of existing Video-LLMs: (1) models often fail to maintain consistency, with results far worse than their single-view performances. (2) When naively finetuned with synchronized videos of both viewpoints, the models show improved consistency but often underperform those trained on a single view. For improvements, we propose View-GRPO, a novel reinforcement learning framework that effectively strengthens view-specific temporal reasoning while encouraging consistent comprehension across viewpoints. Our method demonstrates its superiority over naive SFT and GRPO, especially for improving cross-view consistency. All resources will be made publicly available.</p>
<blockquote>
<p>è§†é¢‘LLMsï¼ˆå¤§è¯­è¨€æ¨¡å‹ï¼‰åœ¨ä»å¤šä¸ªè§’åº¦æ•æ‰åŒä¸€äº‹ä»¶æ—¶æ˜¯å¦èƒ½å®ç°ä¸€è‡´çš„æ—¶é—´ç†è§£ï¼Ÿä¸ºäº†ç ”ç©¶è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬å¼•å…¥äº†EgoExo-Conï¼ˆä¸€è‡´æ€§ï¼‰åŸºå‡†æµ‹è¯•ï¼Œè¿™æ˜¯ä¸€ä¸ªåŒ…å«äººç±»è‡ªç„¶è¯­è¨€çš„ç²¾ç‚¼æŸ¥è¯¢çš„å…¨æ–¹ä½åŒæ­¥çš„ç¬¬ä¸€äººç§°å’Œç¬¬ä¸‰äººç§°è§†é¢‘å¯¹ã€‚EgoExo-Conå¼ºè°ƒä¸¤ä¸ªæ—¶é—´ç†è§£ä»»åŠ¡ï¼šæ—¶é—´éªŒè¯å’Œæ—¶é—´å®šä½ã€‚å®ƒä¸ä»…è¯„ä¼°æ­£ç¡®æ€§ï¼Œè¿˜è¯„ä¼°ä¸åŒè§†è§’ä¸‹çš„ä¸€è‡´æ€§ã€‚æˆ‘ä»¬çš„åˆ†ææ­ç¤ºäº†ç°æœ‰è§†é¢‘LLMçš„ä¸¤ä¸ªå…³é”®å±€é™æ€§ï¼šï¼ˆ1ï¼‰æ¨¡å‹é€šå¸¸å¾ˆéš¾ä¿æŒä¸€è‡´æ€§ï¼Œå…¶æ€§èƒ½è¿œä¸åŠå•è§†è§’çš„è¡¨ç°ï¼›ï¼ˆ2ï¼‰å½“ç›´æ¥ç”¨ä¸¤ä¸ªè§†è§’åŒæ­¥çš„è§†é¢‘è¿›è¡Œå¾®è°ƒæ—¶ï¼Œæ¨¡å‹çš„è§†è§’ä¸€è‡´æ€§æœ‰æ‰€æå‡ï¼Œä½†æ€§èƒ½å¸¸å¸¸ä¸åŠåœ¨å•ä¸€è§†è§’è®­ç»ƒçš„è¡¨ç°ã€‚ä¸ºäº†æ”¹è¿›ï¼Œæˆ‘ä»¬æå‡ºäº†View-GRPOè¿™ä¸€æ–°å‹å¼ºåŒ–å­¦ä¹ æ¡†æ¶ï¼Œå®ƒæœ‰æ•ˆåœ°åŠ å¼ºäº†ç‰¹å®šè§†è§’çš„æ—¶é—´æ¨ç†èƒ½åŠ›ï¼ŒåŒæ—¶é¼“åŠ±ä¸åŒè§†è§’ä¹‹é—´çš„ä¸€è‡´ç†è§£ã€‚æˆ‘ä»¬çš„æ–¹æ³•æ˜¾ç¤ºå‡ºå…¶åœ¨ç®€å•SFTå’ŒGRPOä¸Šçš„ä¼˜åŠ¿ï¼Œç‰¹åˆ«æ˜¯åœ¨æé«˜è·¨è§†è§’ä¸€è‡´æ€§æ–¹é¢ã€‚æ‰€æœ‰èµ„æºéƒ½å°†å…¬å¼€æä¾›ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.26113v1">PDF</a> project page: \url{<a target="_blank" rel="noopener" href="https://minjoong507.github.io/projects/EgoExo-Con/%7D">https://minjoong507.github.io/projects/EgoExo-Con/}</a></p>
<p><strong>Summary</strong><br>     ä¸ºæ¢ç©¶è§†é¢‘LLMåœ¨ä¸åŒè§†è§’æ•æ‰åŒä¸€äº‹ä»¶æ—¶çš„æ—¶åºç†è§£èƒ½åŠ›ï¼Œæå‡ºEgoExo-Conï¼ˆä¸€è‡´æ€§ï¼‰åŸºå‡†æµ‹è¯•ï¼ŒåŒ…å«å…¨é¢åŒæ­¥çš„ç¬¬ä¸€äººç§°å’Œç¬¬ä¸‰äººç§°è§†é¢‘å¯¹ï¼Œä»¥åŠè‡ªç„¶è¯­è¨€äººç±»ç²¾ç‚¼æŸ¥è¯¢ã€‚EgoExo-Conå¼ºè°ƒä¸¤ä¸ªæ—¶åºç†è§£ä»»åŠ¡ï¼šæ—¶åºéªŒè¯å’Œæ—¶åºå®šä½ï¼Œè¯„ä¼°ç»“æœä¸ä»…æ­£ç¡®è€Œä¸”è·¨è§†è§’ä¸€è‡´ã€‚åˆ†ææ˜¾ç¤ºç°æœ‰è§†é¢‘LLMä¸¤å¤§å±€é™ï¼šä¸€æ˜¯æ¨¡å‹éš¾ä»¥ç»´æŒä¸€è‡´æ€§ï¼Œç»“æœè¾ƒå•ä¸€è§†è§’æ€§èƒ½å·®ï¼›äºŒæ˜¯ä»…é€šè¿‡åŒæ­¥åŒè§†è§’è§†é¢‘å¾®è°ƒï¼Œæ¨¡å‹ä¸€è‡´æ€§è™½æé«˜ä½†å¾€å¾€ä¸å¦‚å•ä¸€è§†è§’è®­ç»ƒè¡¨ç°ã€‚ä¸ºæ­¤ï¼Œæå‡ºView-GRPOæ–°å‹å¼ºåŒ–å­¦ä¹ æ¡†æ¶ï¼Œæœ‰æ•ˆå¼ºåŒ–ç‰¹å®šè§†è§’æ—¶åºæ¨ç†ï¼ŒåŒæ—¶é¼“åŠ±è·¨è§†è§’ä¸€è‡´ç†è§£ã€‚è¯¥æ–¹æ³•åœ¨æœ´ç´ SFTå’ŒGRPOä¸Šè¡¨ç°ä¼˜è¶Šï¼Œå°¤å…¶æé«˜äº†è·¨è§†è§’ä¸€è‡´æ€§ã€‚æ‰€æœ‰èµ„æºå°†å…¬å¼€å‘å¸ƒã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¼•å…¥EgoExo-ConåŸºå‡†æµ‹è¯•ï¼Œç”¨äºè¯„ä¼°è§†é¢‘LLMåœ¨ä¸åŒè§†è§’æ•æ‰åŒä¸€äº‹ä»¶æ—¶çš„æ—¶åºç†è§£èƒ½åŠ›ã€‚</li>
<li>ç°æœ‰è§†é¢‘LLMåœ¨ç»´æŒè·¨è§†è§’ä¸€è‡´æ€§æ–¹é¢å­˜åœ¨å±€é™ã€‚</li>
<li>å•çº¯é€šè¿‡åŒæ­¥åŒè§†è§’è§†é¢‘å¾®è°ƒï¼Œè™½ç„¶èƒ½æé«˜æ¨¡å‹çš„ä¸€è‡´æ€§ï¼Œä½†å¯èƒ½ç‰ºç‰²å•ä¸€è§†è§’çš„æ€§èƒ½ã€‚</li>
<li>æå‡ºView-GRPOå¼ºåŒ–å­¦ä¹ æ¡†æ¶ï¼Œæ—¨åœ¨å¼ºåŒ–ç‰¹å®šè§†è§’çš„æ—¶åºæ¨ç†å¹¶æå‡è·¨è§†è§’çš„ä¸€è‡´æ€§ç†è§£ã€‚</li>
<li>View-GRPOåœ¨æœ´ç´ SFTå’ŒGRPOæ–¹æ³•åŸºç¡€ä¸Šè¡¨ç°ä¼˜è¶Šï¼Œå°¤å…¶æœ‰åŠ©äºæå‡è·¨è§†è§’ä¸€è‡´æ€§ã€‚</li>
<li>è¯¥ç ”ç©¶å¼ºè°ƒè·¨è§†è§’ä¸€è‡´æ€§åœ¨è§†é¢‘ç†è§£ä¸­çš„é‡è¦æ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.26113">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-87331238a761cb4cc8f3c343821f8434" align="middle">
<img src="https://picx.zhimg.com/v2-f25e6495ff1726fa3c382a6cf4b0440c" align="middle">
<img src="https://picx.zhimg.com/v2-9c783264b71c48ac5e9008a38fe7e533" align="middle">
<img src="https://picx.zhimg.com/v2-12f184a215496584e09314140181d91e" align="middle">
<img src="https://picx.zhimg.com/v2-cc5806587a095f2527e8a82cce4eee9d" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="Geometric-Mean-Policy-Optimization"><a href="#Geometric-Mean-Policy-Optimization" class="headerlink" title="Geometric-Mean Policy Optimization"></a>Geometric-Mean Policy Optimization</h2><p><strong>Authors:Yuzhong Zhao, Yue Liu, Junpeng Liu, Jingye Chen, Xun Wu, Yaru Hao, Tengchao Lv, Shaohan Huang, Lei Cui, Qixiang Ye, Fang Wan, Furu Wei</strong></p>
<p>Group Relative Policy Optimization (GRPO) has significantly enhanced the reasoning capability of large language models by optimizing the arithmetic mean of token-level rewards. Unfortunately, GRPO is observed to suffer from unstable policy updates when facing tokens with outlier importance-weighted rewards, which manifest as extreme importance sampling ratios during training. In this study, we propose Geometric-Mean Policy Optimization (GMPO), with the aim to improve the stability of GRPO through suppressing token reward outliers. Instead of optimizing the arithmetic mean, GMPO maximizes the geometric mean of token-level rewards, which is inherently less sensitive to outliers and maintains a more stable range of importance sampling ratio. GMPO is plug-and-play-simply replacing GRPOâ€™s arithmetic mean with the geometric mean of token-level rewards, as the latter is inherently less sensitive to outliers. GMPO is theoretically plausible-analysis reveals that both GMPO and GRPO are weighted forms of the policy gradient while the former enjoys more stable weights, which consequently benefits policy optimization and performance. Experiments on multiple mathematical reasoning benchmarks show that GMPO-7B improves the average Pass@1 of GRPO by up to 4.1%, outperforming many state-of-the-art approaches. Code is available at <a target="_blank" rel="noopener" href="https://github.com/callsys/GMPO">https://github.com/callsys/GMPO</a>.</p>
<blockquote>
<p>é›†å›¢ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–ï¼ˆGRPOï¼‰é€šè¿‡ä¼˜åŒ–ä»¤ç‰Œçº§åˆ«å¥–åŠ±çš„ç®—æœ¯å¹³å‡å€¼ï¼Œæ˜¾è‘—æé«˜äº†å¤§å‹è¯­è¨€æ¨¡å‹çš„æ¨ç†èƒ½åŠ›ã€‚ç„¶è€Œï¼Œç ”ç©¶äººå‘˜å‘ç°GRPOåœ¨é¢å¯¹å…·æœ‰å¼‚å¸¸é‡è¦æ€§åŠ æƒå¥–åŠ±çš„ä»¤ç‰Œæ—¶ï¼Œä¼šå‡ºç°ç­–ç•¥æ›´æ–°ä¸ç¨³å®šçš„æƒ…å†µï¼Œè¿™è¡¨ç°ä¸ºè®­ç»ƒè¿‡ç¨‹ä¸­çš„é‡è¦æ€§é‡‡æ ·æ¯”ç‡æç«¯åŒ–ã€‚é’ˆå¯¹è¿™ä¸€é—®é¢˜ï¼Œæœ¬ç ”ç©¶æå‡ºå‡ ä½•å‡å€¼ç­–ç•¥ä¼˜åŒ–ï¼ˆGMPOï¼‰ï¼Œæ—¨åœ¨é€šè¿‡æŠ‘åˆ¶ä»¤ç‰Œå¥–åŠ±å¼‚å¸¸å€¼æ¥æé«˜GRPOçš„ç¨³å®šæ€§ã€‚ä¸åŒäºä¼˜åŒ–ç®—æœ¯å¹³å‡å€¼ï¼ŒGMPOæœ€å¤§åŒ–ä»¤ç‰Œçº§åˆ«å¥–åŠ±çš„å‡ ä½•å¹³å‡å€¼ï¼Œåè€…å¯¹å¼‚å¸¸å€¼å…·æœ‰å›ºæœ‰çš„ä¸æ•æ„Ÿæ€§ï¼Œå¹¶ä¿æŒäº†æ›´ç¨³å®šçš„é‡è¦æ€§é‡‡æ ·æ¯”ç‡èŒƒå›´ã€‚GMPOå³æ’å³ç”¨ï¼Œåªéœ€å°†GRPOçš„ç®—æœ¯å¹³å‡å€¼æ›¿æ¢ä¸ºä»¤ç‰Œçº§åˆ«å¥–åŠ±çš„å‡ ä½•å¹³å‡å€¼ï¼Œå› ä¸ºåè€…å¯¹å¼‚å¸¸å€¼å…·æœ‰å›ºæœ‰çš„ä¸æ•æ„Ÿæ€§ã€‚ä»ç†è®ºä¸Šè®²ï¼Œåˆ†æè¡¨æ˜GMPOå’ŒGRPOéƒ½æ˜¯ç­–ç•¥æ¢¯åº¦çš„åŠ æƒå½¢å¼ï¼Œè€Œå‰è€…å…·æœ‰æ›´ç¨³å®šçš„æƒé‡ï¼Œä»è€Œæœ‰åˆ©äºç­–ç•¥ä¼˜åŒ–å’Œæ€§èƒ½æå‡ã€‚åœ¨å¤šä¸ªæ•°å­¦æ¨ç†åŸºå‡†æµ‹è¯•ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒGMPO-7Bå°†GRPOçš„å¹³å‡é€šè¿‡ç‡æé«˜äº†é«˜è¾¾4.1%ï¼Œè¶…è¶Šäº†è®¸å¤šæœ€å…ˆè¿›çš„æ–¹æ³•ã€‚ä»£ç å¯è®¿é—®<a target="_blank" rel="noopener" href="https://github.com/callsys/GMPO%E3%80%82">https://github.com/callsys/GMPOã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2507.20673v3">PDF</a> Code is available at <a target="_blank" rel="noopener" href="https://github.com/callsys/GMPO">https://github.com/callsys/GMPO</a></p>
<p><strong>Summary</strong></p>
<p>å¤§å‹è¯­è¨€æ¨¡å‹çš„æ¨ç†èƒ½åŠ›é€šè¿‡ä¼˜åŒ–ä»¤ç‰Œçº§åˆ«å¥–åŠ±çš„ç®—æœ¯å¹³å‡å€¼å¾—åˆ°äº†æ˜¾è‘—æå‡ï¼Œä½†é¢ä¸´å…·æœ‰å¼‚å¸¸é‡è¦æ€§åŠ æƒå¥–åŠ±çš„ä»¤ç‰Œæ—¶ï¼Œä¼šå‡ºç°æ”¿ç­–æ›´æ–°ä¸ç¨³å®šçš„é—®é¢˜ã€‚æœ¬ç ”ç©¶æå‡ºå‡ ä½•å‡å€¼æ”¿ç­–ä¼˜åŒ–ï¼ˆGMPOï¼‰ï¼Œæ—¨åœ¨é€šè¿‡æŠ‘åˆ¶ä»¤ç‰Œå¥–åŠ±å¼‚å¸¸å€¼æ¥æé«˜GRPOçš„ç¨³å®šæ€§ã€‚GMPOæœ€å¤§åŒ–ä»¤ç‰Œçº§åˆ«å¥–åŠ±çš„å‡ ä½•å¹³å‡å€¼ï¼Œè€Œéç®—æœ¯å¹³å‡å€¼ï¼Œå¯¹å¼‚å¸¸å€¼å…·æœ‰æ›´å°çš„æ•æ„Ÿæ€§ï¼Œå¹¶èƒ½ç»´æŒæ›´ç¨³å®šçš„é‡è¦æ€§é‡‡æ ·æ¯”ç‡èŒƒå›´ã€‚GMPOå³æ’å³ç”¨ï¼Œåªéœ€å°†GRPOçš„ç®—æœ¯å¹³å‡å€¼æ›¿æ¢ä¸ºä»¤ç‰Œçº§åˆ«å¥–åŠ±çš„å‡ ä½•å¹³å‡å€¼ã€‚ç†è®ºåˆ†æè¡¨æ˜ï¼ŒGMPOå’ŒGRPOéƒ½æ˜¯æ”¿ç­–æ¢¯åº¦çš„åŠ æƒå½¢å¼ï¼Œè€Œå‰è€…äº«æœ‰æ›´ç¨³å®šçš„æƒé‡ï¼Œæœ‰åˆ©äºæ”¿ç­–ä¼˜åŒ–å’Œæ€§èƒ½æå‡ã€‚åœ¨å¤šä¸ªæ•°å­¦æ¨ç†åŸºå‡†æµ‹è¯•ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒGMPO-7Bå°†GRPOçš„å¹³å‡é€šè¿‡ç‡æé«˜äº†4.1%ï¼Œä¼˜äºè®¸å¤šæœ€å…ˆè¿›çš„æ–¹æ³•ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>Group Relative Policy Optimization (GRPO) é€šè¿‡ä¼˜åŒ–ä»¤ç‰Œçº§åˆ«å¥–åŠ±çš„ç®—æœ¯å¹³å‡å€¼å¢å¼ºäº†å¤§å‹è¯­è¨€æ¨¡å‹çš„æ¨ç†èƒ½åŠ›ã€‚</li>
<li>GRPO åœ¨é¢å¯¹å…·æœ‰å¼‚å¸¸é‡è¦æ€§åŠ æƒå¥–åŠ±çš„ä»¤ç‰Œæ—¶ï¼Œä¼šå‡ºç°æ”¿ç­–æ›´æ–°ä¸ç¨³å®šçš„é—®é¢˜ã€‚</li>
<li>å‡ ä½•å‡å€¼æ”¿ç­–ä¼˜åŒ–ï¼ˆGMPOï¼‰æ—¨åœ¨é€šè¿‡æœ€å¤§åŒ–ä»¤ç‰Œçº§åˆ«å¥–åŠ±çš„å‡ ä½•å¹³å‡å€¼æ¥æé«˜GRPOçš„ç¨³å®šæ€§ï¼Œå¯¹å¼‚å¸¸å€¼å…·æœ‰æ›´å°çš„æ•æ„Ÿæ€§ã€‚</li>
<li>GMPO èƒ½ç»´æŒæ›´ç¨³å®šçš„é‡è¦æ€§é‡‡æ ·æ¯”ç‡èŒƒå›´ï¼Œå¹¶é€šè¿‡æ›¿æ¢GRPOä¸­çš„ç®—æœ¯å¹³å‡å€¼ä¸ºå‡ ä½•å¹³å‡å€¼æ¥å®æ–½ã€‚</li>
<li>ç†è®ºåˆ†ææ˜¾ç¤ºGMPOäº«æœ‰æ›´ç¨³å®šçš„æƒé‡ï¼Œæœ‰åˆ©äºæ”¿ç­–ä¼˜åŒ–å’Œæ€§èƒ½æå‡ã€‚</li>
<li>åœ¨æ•°å­¦æ¨ç†åŸºå‡†æµ‹è¯•ä¸Šï¼ŒGMPO-7B è¾ƒ GRPO æœ‰æ˜¾è‘—æ€§èƒ½æå‡ï¼Œå¹³å‡é€šè¿‡ç‡æé«˜4.1%ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2507.20673">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-c4794f074b42e62fbcf1ac5701dc402a" align="middle">
<img src="https://picx.zhimg.com/v2-37365044d88dbbe15a5b33c45a88dfe8" align="middle">
<img src="https://picx.zhimg.com/v2-6710ec2a917acffb18f210f7e75a5bb9" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="EFRame-Deeper-Reasoning-via-Exploration-Filter-Replay-Reinforcement-Learning-Framework"><a href="#EFRame-Deeper-Reasoning-via-Exploration-Filter-Replay-Reinforcement-Learning-Framework" class="headerlink" title="EFRame: Deeper Reasoning via Exploration-Filter-Replay Reinforcement Learning Framework"></a>EFRame: Deeper Reasoning via Exploration-Filter-Replay Reinforcement Learning Framework</h2><p><strong>Authors:Chen Wang, Lai Wei, Yanzhi Zhang, Chenyang Shao, Zedong Dan, Weiran Huang, Yuzhi Zhang, Yue Wang</strong></p>
<p>Recent advances in reinforcement learning (RL) have significantly enhanced the reasoning capabilities of large language models (LLMs). Group Relative Policy Optimization (GRPO), a lightweight variant of Proximal Policy Optimization (PPO), improves efficiency but suffers from limited exploration and training instability, limiting its effectiveness on complex reasoning tasks. To address these challenges, we introduce EFRame, an Exploration-Filter-Replay framework that augments GRPO across three dimensions: additional rollouts enable deeper and more targeted exploration, online filtering removes low-quality samples to stabilize gradients and accelerate training, and experience replay amplifies rare yet informative trajectories for stable convergence. This unified framework establishes a principled training cycle that balances exploration, efficiency, and stability. Experiments on diverse reasoning benchmarks demonstrate that EFRame achieves consistent gains, including a 37.9% relative improvement on Geometry3K over GRPO. EFRame further supports fine-grained sample categorization and precise entropy control, highlighting it as a robust solution for advancing deeper reasoning in LLMs. Our code is available at <a target="_blank" rel="noopener" href="https://github.com/597358816/EFRame">https://github.com/597358816/EFRame</a>.</p>
<blockquote>
<p>éšç€å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰çš„æœ€æ–°è¿›å±•ï¼Œå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„æ¨ç†èƒ½åŠ›å¾—åˆ°äº†æ˜¾è‘—æå‡ã€‚Group Relative Policy Optimizationï¼ˆGRPOï¼‰æ˜¯Proximal Policy Optimizationï¼ˆPPOï¼‰çš„ä¸€ç§è½»é‡çº§å˜ä½“ï¼Œæé«˜äº†æ•ˆç‡ï¼Œä½†å­˜åœ¨æ¢ç´¢æœ‰é™å’Œè®­ç»ƒä¸ç¨³å®šçš„é—®é¢˜ï¼Œä½¿å…¶åœ¨å¤æ‚æ¨ç†ä»»åŠ¡ä¸Šçš„æ•ˆæœæœ‰é™ã€‚ä¸ºäº†è§£å†³è¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬å¼•å…¥äº†EFRameï¼Œå³ä¸€ä¸ªæ¢ç´¢-è¿‡æ»¤-å›æ”¾æ¡†æ¶ï¼Œå®ƒä»ä¸‰ä¸ªç»´åº¦å¢å¼ºGRPOï¼šé¢å¤–çš„è¿­ä»£å®ç°æ›´æ·±ã€æ›´ç²¾å‡†çš„æ¢ç´¢ï¼›åœ¨çº¿è¿‡æ»¤åˆ™ç§»é™¤ä½è´¨é‡æ ·æœ¬ï¼Œç¨³å®šæ¢¯åº¦å¹¶åŠ é€Ÿè®­ç»ƒï¼›ç»éªŒå›æ”¾åˆ™æ”¾å¤§ç¨€æœ‰ä½†ä¿¡æ¯é‡å¤§çš„è½¨è¿¹ä»¥å®ç°ç¨³å®šçš„æ”¶æ•›ã€‚è¿™ä¸€ç»Ÿä¸€çš„æ¡†æ¶å»ºç«‹äº†ä¸€ä¸ªæœ‰åŸåˆ™çš„è®­ç»ƒå‘¨æœŸï¼Œå¹³è¡¡äº†æ¢ç´¢ã€æ•ˆç‡å’Œç¨³å®šæ€§ã€‚åœ¨å¤šç§æ¨ç†åŸºå‡†æµ‹è¯•ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒEFRameå–å¾—äº†æŒç»­çš„æ”¶ç›Šï¼ŒåŒ…æ‹¬å¯¹Geometry3Kçš„37.9%çš„ç›¸å¯¹æ”¹è¿›ã€‚æ­¤å¤–ï¼ŒEFRameè¿˜æ”¯æŒç²¾ç»†çš„æ ·æœ¬åˆ†ç±»å’Œç²¾ç¡®çš„ä¸ç¡®å®šæ€§æ§åˆ¶ï¼Œå‡¸æ˜¾å…¶ä½œä¸ºæ¨è¿›LLMæ·±åº¦æ¨ç†çš„ç¨³å¥è§£å†³æ–¹æ¡ˆã€‚æˆ‘ä»¬çš„ä»£ç å¯åœ¨[<a target="_blank" rel="noopener" href="https://github.com/5973588]%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/5973588]æ‰¾åˆ°ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.22200v5">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>å¼ºåŒ–å­¦ä¹ åœ¨æå‡å¤§å‹è¯­è¨€æ¨¡å‹çš„æ¨ç†èƒ½åŠ›æ–¹é¢å–å¾—äº†é‡è¦è¿›å±•ã€‚ç„¶è€Œï¼ŒGroup Relative Policy Optimizationï¼ˆGRPOï¼‰åœ¨å¤„ç†å¤æ‚æ¨ç†ä»»åŠ¡æ—¶é¢ä¸´æœ‰é™æ¢ç´¢å’Œè®­ç»ƒä¸ç¨³å®šçš„é—®é¢˜ã€‚ä¸ºè§£å†³è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†EFRameæ¡†æ¶ï¼Œè¯¥æ¡†æ¶ä»ä¸‰ä¸ªç»´åº¦å¯¹GRPOè¿›è¡Œäº†å¢å¼ºï¼šé¢å¤–çš„rolloutså®ç°æ›´æ·±æ›´ç²¾å‡†çš„æ¢ç´¢ï¼Œåœ¨çº¿è¿‡æ»¤ç§»é™¤ä½è´¨é‡æ ·æœ¬ä»¥ç¨³å®šæ¢¯åº¦å¹¶åŠ é€Ÿè®­ç»ƒï¼Œç»éªŒå›æ”¾æ”¾å¤§ç¨€æœ‰ä½†é‡è¦çš„è½¨è¿¹ä»¥å®ç°ç¨³å®šæ”¶æ•›ã€‚å®éªŒè¯æ˜ï¼ŒEFRameåœ¨å¤šç§æ¨ç†åŸºå‡†æµ‹è¯•ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œç›¸å¯¹äºGRPOæœ‰æ˜¾è‘—æ”¹å–„ï¼Œå¦‚åœ¨Geometry3Kä¸Šç›¸å¯¹æå‡äº†37.9%ã€‚è¯¥æ¡†æ¶æ”¯æŒç²¾ç»†æ ·æœ¬åˆ†ç±»å’Œç²¾ç¡®ç†µæ§åˆ¶ï¼Œå±•ç°äº†å…¶åœ¨æ¨åŠ¨å¤§å‹è¯­è¨€æ¨¡å‹æ·±åº¦æ¨ç†æ–¹é¢çš„ç¨³å¥æ€§ã€‚ç›¸å…³ä»£ç å·²å‘å¸ƒåœ¨GitHubä¸Šã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¼ºåŒ–å­¦ä¹ æå‡äº†å¤§å‹è¯­è¨€æ¨¡å‹çš„æ¨ç†èƒ½åŠ›ã€‚</li>
<li>Group Relative Policy Optimizationï¼ˆGRPOï¼‰åœ¨å¤æ‚æ¨ç†ä»»åŠ¡ä¸­é¢ä¸´æœ‰é™æ¢ç´¢å’Œè®­ç»ƒä¸ç¨³å®šçš„é—®é¢˜ã€‚</li>
<li>EFRameæ¡†æ¶é€šè¿‡ä¸‰ä¸ªç»´åº¦å¢å¼ºGRPOæ€§èƒ½ï¼šæ·±åº¦æ¢ç´¢ã€ç¨³å®šçš„è®­ç»ƒå’Œæ ·æœ¬ä¼˜åŒ–ç®¡ç†ã€‚</li>
<li>EFRameæ¡†æ¶å®ç°äº†æ›´æ·±çš„æ¢ç´¢ï¼Œé€šè¿‡åœ¨çº¿è¿‡æ»¤å’Œä½è´¨é‡æ ·æœ¬ç§»é™¤ç¨³å®šæ¢¯åº¦ï¼ŒåŠ é€Ÿè®­ç»ƒè¿‡ç¨‹ã€‚</li>
<li>ç»éªŒå›æ”¾æœºåˆ¶æœ‰åŠ©äºæ”¾å¤§é‡è¦ä½†ç¨€æœ‰çš„è½¨è¿¹ä¿¡æ¯ï¼Œä»¥å®ç°æ›´ç¨³å®šçš„æ”¶æ•›ã€‚</li>
<li>EFRameåœ¨å¤šç§åŸºå‡†æµ‹è¯•ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œç›¸è¾ƒäºGRPOæœ‰æ˜¾è‘—æ”¹è¿›ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.22200">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-5fe3e8cf57d9aef82e5a465aed86a03a" align="middle">
<img src="https://picx.zhimg.com/v2-8de2dfdc57792bf33c1489a8401c67b4" align="middle">
<img src="https://picx.zhimg.com/v2-1a82580fd03363b8cf4e0d93bf896e27" align="middle">
<img src="https://picx.zhimg.com/v2-15eac75fbf7a0d9a099b12279b7a4bab" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="SEEA-R1-Tree-Structured-Reinforcement-Fine-Tuning-for-Self-Evolving-Embodied-Agents"><a href="#SEEA-R1-Tree-Structured-Reinforcement-Fine-Tuning-for-Self-Evolving-Embodied-Agents" class="headerlink" title="SEEA-R1: Tree-Structured Reinforcement Fine-Tuning for Self-Evolving Embodied Agents"></a>SEEA-R1: Tree-Structured Reinforcement Fine-Tuning for Self-Evolving Embodied Agents</h2><p><strong>Authors:Wanxin Tian, Shijie Zhang, Kevin Zhang, Xiaowei Chi, Chunkai Fan, Junyu Lu, Yulin Luo, Qiang Zhou, Yiming Zhao, Ning Liu, Siyu Lin, Zhiyuan Qin, Xiaozhu Ju, Shanghang Zhang, Jian Tang</strong></p>
<p>Self-evolution, the ability of agents to autonomously improve their reasoning and behavior, is essential for the embodied domain with long-horizon, real-world tasks. Despite current advancements in reinforcement fine-tuning (RFT) showing strong performance in enhancing reasoning in LLMs, its potential to enable self-evolving embodied intelligence with multi-modal interactions remains largely unexplored. Specifically, reinforcement fine-tuning faces two fundamental obstacles in embodied settings: (i) the lack of accessible intermediate rewards in multi-step reasoning tasks limits effective learning signals, and (ii) reliance on hand-crafted reward functions restricts generalization to novel tasks and environments. To address these challenges, we present Self-Evolving Embodied Agents-R1, SEEA-R1, the first RFT framework designed for enabling the self-evolving capabilities of embodied agents. Specifically, to convert sparse delayed rewards into denser intermediate signals that improve multi-step reasoning, we propose Tree-based group relative policy optimization (Tree-GRPO) integrates Monte Carlo Tree Search into GRPO. To generalize reward estimation across tasks and scenes, supporting autonomous adaptation and reward-driven self-evolution, we further introduce Multi-modal Generative Reward Model (MGRM). To holistically evaluate the effectiveness of SEEA-R1, we evaluate on the ALFWorld benchmark, surpassing state-of-the-art methods with scores of 85.07% (textual) and 46.27% (multi-modal), outperforming prior models including GPT-4o. SEEA-R1 also achieves scores of 80.3% (textual) and 44.03% (multi-modal) without ground truth reward, surpassing all open-source baselines and highlighting its scalability as a self-evolving embodied agent. Additional experiments and qualitative analysis further support the potential of SEEA-R1 for future research in scalable embodied intelligence.</p>
<blockquote>
<p>è‡ªæˆ‘è¿›åŒ–ï¼Œå³æ™ºèƒ½ä½“è‡ªä¸»æé«˜å…¶æ¨ç†å’Œè¡Œä¸ºçš„èƒ½åŠ›ï¼Œå¯¹äºå…·æœ‰é•¿è¿œè§†é‡å’Œç°å®ä¸–ç•Œä»»åŠ¡çš„å…·ä½“é¢†åŸŸè‡³å…³é‡è¦ã€‚å°½ç®¡å¼ºåŒ–å¾®è°ƒï¼ˆRFTï¼‰çš„å½“å‰è¿›å±•åœ¨å¢å¼ºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„æ¨ç†èƒ½åŠ›æ–¹é¢è¡¨ç°å‡ºå¼ºå¤§çš„æ€§èƒ½ï¼Œä½†å…¶å®ç°å…·æœ‰å¤šæ¨¡æ€äº¤äº’çš„è‡ªæˆ‘è¿›åŒ–æ™ºèƒ½çš„æ½œåŠ›ä»è¢«å¤§é‡æ¢ç´¢ã€‚å…·ä½“æ¥è¯´ï¼Œå¼ºåŒ–å¾®è°ƒåœ¨é¢å¯¹å…·ä½“é¢†åŸŸæ—¶é¢ä¸´ä¸¤å¤§åŸºæœ¬éšœç¢ï¼šï¼ˆiï¼‰å¤šæ­¥æ¨ç†ä»»åŠ¡ä¸­ç¼ºä¹å¯è®¿é—®çš„ä¸­é—´å¥–åŠ±é™åˆ¶äº†æœ‰æ•ˆçš„å­¦ä¹ ä¿¡å·ï¼›ï¼ˆiiï¼‰å¯¹æ‰‹åŠ¨è®¾è®¡å¥–åŠ±å‡½æ•°çš„ä¾èµ–é™åˆ¶äº†å…¶åœ¨æ–°å‹ä»»åŠ¡å’Œç¯å¢ƒä¸­çš„æ³›åŒ–èƒ½åŠ›ã€‚é’ˆå¯¹è¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†è‡ªæˆ‘è¿›åŒ–å®ä½“ä»£ç†-R1ï¼Œå³SEEA-R1ï¼Œè¿™æ˜¯ç¬¬ä¸€ä¸ªæ—¨åœ¨å®ç°å®ä½“ä»£ç†è‡ªæˆ‘è¿›åŒ–èƒ½åŠ›çš„å¼ºåŒ–å¾®è°ƒæ¡†æ¶ã€‚å…·ä½“æ¥è¯´ï¼Œä¸ºäº†å°†ç¨€ç–çš„å»¶è¿Ÿå¥–åŠ±è½¬åŒ–ä¸ºæ›´å¯†é›†çš„ä¸­é—´ä¿¡å·ï¼Œä»¥æé«˜å¤šæ­¥æ¨ç†èƒ½åŠ›ï¼Œæˆ‘ä»¬æå‡ºäº†åŸºäºæ ‘çš„ç¾¤ä½“ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–ï¼ˆTree-GRPOï¼‰ï¼Œå®ƒå°†è’™ç‰¹å¡æ´›æ ‘æœç´¢æ•´åˆåˆ°GRPOä¸­ã€‚ä¸ºäº†å¯¹ä»»åŠ¡å’Œåœºæ™¯è¿›è¡Œæ³›åŒ–çš„å¥–åŠ±ä¼°è®¡ï¼Œæ”¯æŒè‡ªä¸»é€‚åº”å’Œå¥–åŠ±é©±åŠ¨çš„è‡ªæˆ‘è¿›åŒ–ï¼Œæˆ‘ä»¬è¿›ä¸€æ­¥å¼•å…¥äº†å¤šæ¨¡æ€ç”Ÿæˆå¥–åŠ±æ¨¡å‹ï¼ˆMGRMï¼‰ã€‚ä¸ºäº†å…¨é¢è¯„ä¼°SEEA-R1çš„æœ‰æ•ˆæ€§ï¼Œæˆ‘ä»¬åœ¨ALFWorldåŸºå‡†æµ‹è¯•ä¸Šè¿›è¡Œäº†è¯„ä¼°ï¼Œè¶…è¶Šäº†æœ€å…ˆè¿›çš„æ–¹æ³•ï¼Œè¾¾åˆ°äº†æ–‡æœ¬ç±»85.07%å’Œå¤šæ¨¡æ€ç±»46.27%çš„æˆç»©ï¼Œè¶…è¶Šäº†åŒ…æ‹¬GPT-4oåœ¨å†…çš„å…ˆå‰æ¨¡å‹ã€‚SEEA-R1åœ¨ä¸ä½¿ç”¨çœŸå®å¥–åŠ±çš„æƒ…å†µä¸‹è¿˜å®ç°äº†æ–‡æœ¬ç±»80.3%å’Œå¤šæ¨¡æ€ç±»44.03%çš„æˆç»©ï¼Œè¶…è¶Šäº†æ‰€æœ‰å¼€æºåŸºå‡†æµ‹è¯•ï¼Œçªæ˜¾äº†å…¶ä½œä¸ºè‡ªæˆ‘è¿›åŒ–å®ä½“ä»£ç†çš„å¯æ‰©å±•æ€§ã€‚é¢å¤–çš„å®éªŒå’Œå®šæ€§åˆ†æè¿›ä¸€æ­¥æ”¯æŒSEEA-R1åœ¨æœªæ¥å¯æ‰©å±•æ™ºèƒ½é¢†åŸŸçš„ç ”ç©¶æ½œåŠ›ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.21669v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>è‡ªæˆ‘è¿›åŒ–èƒ½åŠ›å¯¹äºæ‰§è¡Œé•¿æœŸã€çœŸå®ä¸–ç•Œä»»åŠ¡å°¤ä¸ºé‡è¦ã€‚å¼ºåŒ–å¾®è°ƒï¼ˆRFTï¼‰åœ¨æå‡å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„æ¨ç†èƒ½åŠ›æ–¹é¢è¡¨ç°å‡ºå¼ºå¤§çš„æ€§èƒ½ï¼Œä½†åœ¨å®ç°å…·æœ‰å¤šæ¨¡æ€äº¤äº’çš„è‡ªæˆ‘è¿›åŒ–æ™ºèƒ½æ–¹é¢ä»æœ‰å¾…æ¢ç´¢ã€‚é’ˆå¯¹å¼ºåŒ–å¾®è°ƒåœ¨å®ä½“åœºæ™¯ä¸­çš„ä¸¤ä¸ªåŸºæœ¬éšœç¢ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸ºSEEA-R1çš„è‡ªæˆ‘è¿›åŒ–å®ä½“ä»£ç†RFTæ¡†æ¶ã€‚é€šè¿‡Tree-GRPOå’ŒMGRMæ–¹æ³•è§£å†³å»¶è¿Ÿå¥–åŠ±å’Œå¥–åŠ±å‡½æ•°æ‰‹å·¥è®¾è®¡çš„é—®é¢˜ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒSEEA-R1åœ¨ALFWorldåŸºå‡†æµ‹è¯•ä¸Šå–å¾—äº†æ˜¾è‘—çš„æˆæœã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>è‡ªæˆ‘è¿›åŒ–èƒ½åŠ›å¯¹äºæ‰§è¡Œé•¿æœŸã€çœŸå®ä¸–ç•Œä»»åŠ¡éå¸¸é‡è¦ã€‚</li>
<li>å¼ºåŒ–å¾®è°ƒï¼ˆRFTï¼‰åœ¨æå‡å¤§å‹è¯­è¨€æ¨¡å‹æ¨ç†èƒ½åŠ›æ–¹é¢è¡¨ç°ä¼˜å¼‚ï¼Œä½†åœ¨å®ç°è‡ªæˆ‘è¿›åŒ–æ™ºèƒ½æ–¹é¢ä»å¾…æ¢ç´¢ã€‚</li>
<li>SEEA-R1æ˜¯é¦–ä¸ªä¸ºå®ä½“ä»£ç†çš„è‡ªæˆ‘è¿›åŒ–èƒ½åŠ›è®¾è®¡çš„RFTæ¡†æ¶ã€‚</li>
<li>Tree-GRPOæ–¹æ³•å°†ç¨€ç–å»¶è¿Ÿå¥–åŠ±è½¬åŒ–ä¸ºæ›´å¯†é›†çš„ä¸­é—´ä¿¡å·ï¼Œä»¥æé«˜å¤šæ­¥æ¨ç†èƒ½åŠ›ã€‚</li>
<li>MGRMæ–¹æ³•ç”¨äºè·¨ä»»åŠ¡å’Œåœºæ™¯çš„å¥–åŠ±ä¼°è®¡ï¼Œæ”¯æŒè‡ªä¸»é€‚åº”å’Œå¥–åŠ±é©±åŠ¨çš„è‡ªæˆ‘è¿›åŒ–ã€‚</li>
<li>åœ¨ALFWorldåŸºå‡†æµ‹è¯•ä¸­ï¼ŒSEEA-R1å–å¾—äº†æ˜¾è‘—çš„æˆç»©ï¼Œè¶…è¶Šäº†ç°æœ‰æ–¹æ³•ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.21669">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-d9298fe12fdf0f5cb176836375bfc11e" align="middle">
<img src="https://picx.zhimg.com/v2-515d632a1adcf5ee5920b32c6a4529a4" align="middle">
<img src="https://picx.zhimg.com/v2-6b178bac27bca143b72a37f11fc1133d" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="DeepVideo-R1-Video-Reinforcement-Fine-Tuning-via-Difficulty-aware-Regressive-GRPO"><a href="#DeepVideo-R1-Video-Reinforcement-Fine-Tuning-via-Difficulty-aware-Regressive-GRPO" class="headerlink" title="DeepVideo-R1: Video Reinforcement Fine-Tuning via Difficulty-aware Regressive GRPO"></a>DeepVideo-R1: Video Reinforcement Fine-Tuning via Difficulty-aware Regressive GRPO</h2><p><strong>Authors:Jinyoung Park, Jeehye Na, Jinyoung Kim, Hyunwoo J. Kim</strong></p>
<p>Recent works have demonstrated the effectiveness of reinforcement learning (RL)-based post-training for enhancing the reasoning capabilities of large language models (LLMs). In particular, Group Relative Policy Optimization (GRPO) has shown impressive success using a PPO-style reinforcement algorithm with group-normalized rewards. However, the effectiveness of GRPO in Video Large Language Models (VideoLLMs) has still been less studyed. In this paper, we explore GRPO and identify two problems that deteriorate the effective learning: (1) reliance on safeguards, and (2) vanishing advantage. To mitigate these challenges, we propose DeepVideo-R1, a video large language model trained with Reg-GRPO (Regressive GRPO) and difficulty-aware data augmentation. Reg-GRPO reformulates the GRPO loss function into a regression task that directly predicts the advantage in GRPO, eliminating the need for safeguards such as the clipping and min functions. It directly aligns the model with advantages, providing guidance to prefer better ones. The difficulty-aware data augmentation strategy augments input prompts&#x2F;videos to locate the difficulty of samples at solvable difficulty levels, enabling diverse reward signals. Our experimental results show that our approach significantly improves video reasoning performance across multiple benchmarks.</p>
<blockquote>
<p>æœ€è¿‘çš„ç ”ç©¶å·¥ä½œå±•ç¤ºäº†åŸºäºå¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰çš„è®­ç»ƒåå¤„ç†åœ¨æå‡å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„æ¨ç†èƒ½åŠ›æ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚ç‰¹åˆ«æ˜¯ï¼Œç¾¤ç»„ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–ï¼ˆGRPOï¼‰ä½¿ç”¨PPOé£æ ¼çš„å¼ºåŒ–ç®—æ³•å’Œç¾¤ç»„å½’ä¸€åŒ–å¥–åŠ±ï¼Œå–å¾—äº†ä»¤äººå°è±¡æ·±åˆ»çš„æˆåŠŸã€‚ç„¶è€Œï¼ŒGRPOåœ¨è§†é¢‘å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆVideoLLMsï¼‰ä¸­çš„æœ‰æ•ˆæ€§ç ”ç©¶ä»ç„¶è¾ƒå°‘ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æ¢ç´¢äº†GRPOï¼Œå¹¶è¯†åˆ«å‡ºä¸¤ä¸ªå¯¼è‡´å­¦ä¹ æ•ˆèƒ½ä¸‹é™çš„é—®é¢˜ï¼šï¼ˆ1ï¼‰å¯¹ä¿éšœæªæ–½çš„ä¾èµ–ï¼›ï¼ˆ2ï¼‰ä¼˜åŠ¿æ¶ˆå¤±ã€‚ä¸ºäº†ç¼“è§£è¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†DeepVideo-R1ï¼Œè¿™æ˜¯ä¸€ç§ç”¨å›å½’GRPOï¼ˆReg-GRPOï¼‰å’Œéš¾åº¦æ„ŸçŸ¥æ•°æ®å¢å¼ºè®­ç»ƒçš„è§†é¢‘å¤§å‹è¯­è¨€æ¨¡å‹ã€‚Reg-GRPOå°†GRPOæŸå¤±å‡½æ•°é‡æ–°å®šä¹‰ä¸ºå›å½’ä»»åŠ¡ï¼Œç›´æ¥é¢„æµ‹GRPOä¸­çš„ä¼˜åŠ¿ï¼Œæ¶ˆé™¤äº†å¯¹ä¿éšœæªæ–½ï¼ˆå¦‚è£å‰ªå’Œæœ€å°å‡½æ•°ï¼‰çš„éœ€æ±‚ã€‚å®ƒç›´æ¥ä½¿æ¨¡å‹ä¸ä¼˜åŠ¿å¯¹é½ï¼Œä¸ºæ›´å¥½çš„æ¨¡å‹æä¾›æŒ‡å¯¼ã€‚éš¾åº¦æ„ŸçŸ¥æ•°æ®å¢å¼ºç­–ç•¥å¢åŠ äº†è¾“å…¥æç¤º&#x2F;è§†é¢‘ï¼Œä»¥å®šä½åœ¨å¯è§£å†³éš¾åº¦æ°´å¹³æ ·æœ¬çš„éš¾åº¦ï¼Œä»è€Œå®ç°å¤šæ ·åŒ–çš„å¥–åŠ±ä¿¡å·ã€‚æˆ‘ä»¬çš„å®éªŒç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨å¤šåŸºå‡†æµ‹è¯•ä¸­æ˜¾è‘—æé«˜äº†è§†é¢‘æ¨ç†æ€§èƒ½ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.07464v4">PDF</a> NeurIPS 2025</p>
<p><strong>Summary</strong></p>
<p>å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰åœ¨æå‡å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„æ¨ç†èƒ½åŠ›æ–¹é¢è¡¨ç°å‡ºæ˜¾è‘—æ•ˆæœï¼Œç‰¹åˆ«æ˜¯ä½¿ç”¨PPOé£æ ¼çš„å¼ºåŒ–ç®—æ³•çš„Group Relative Policy Optimizationï¼ˆGRPOï¼‰æ–¹æ³•ã€‚ç„¶è€Œï¼ŒGRPOåœ¨è§†é¢‘å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆVideoLLMsï¼‰ä¸­çš„åº”ç”¨ä»ç¼ºä¹ç ”ç©¶ã€‚æœ¬æ–‡æ¢è®¨äº†GRPOï¼Œå¹¶æŒ‡å‡ºå…¶å­˜åœ¨çš„ä¸¤ä¸ªé—®é¢˜ï¼šä¾èµ–ä¿éšœæœºåˆ¶å’Œä¼˜åŠ¿æ¶ˆå¤±é—®é¢˜ã€‚ä¸ºè§£å†³è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†DeepVideo-R1ï¼Œè¿™æ˜¯ä¸€ç§ä½¿ç”¨Reg-GRPOå’Œéš¾åº¦æ„ŸçŸ¥æ•°æ®å¢å¼ºçš„è§†é¢‘å¤§å‹è¯­è¨€æ¨¡å‹ã€‚Reg-GRPOå°†GRPOæŸå¤±å‡½æ•°é‡æ–°å®šä¹‰ä¸ºå›å½’ä»»åŠ¡ï¼Œç›´æ¥é¢„æµ‹GRPOä¸­çš„ä¼˜åŠ¿ï¼Œæ¶ˆé™¤å¯¹ä¿éšœæœºåˆ¶çš„ä¾èµ–ã€‚éš¾åº¦æ„ŸçŸ¥æ•°æ®å¢å¼ºç­–ç•¥å¢åŠ äº†è¾“å…¥æç¤º&#x2F;è§†é¢‘çš„éš¾åº¦ï¼Œä½¿å…¶å¤„äºå¯è§£å†³æ°´å¹³ï¼Œæä¾›å¤šæ ·åŒ–çš„å¥–åŠ±ä¿¡å·ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å¤šåŸºå‡†æµ‹è¯•ä¸­æ˜¾è‘—æé«˜äº†è§†é¢‘æ¨ç†æ€§èƒ½ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¼ºåŒ–å­¦ä¹ åœ¨æå‡å¤§å‹è¯­è¨€æ¨¡å‹çš„æ¨ç†èƒ½åŠ›æ–¹é¢æœ‰æ•ˆï¼Œç‰¹åˆ«æ˜¯GRPOæ–¹æ³•ã€‚</li>
<li>GRPOåœ¨è§†é¢‘å¤§å‹è¯­è¨€æ¨¡å‹ä¸­çš„åº”ç”¨å­˜åœ¨ä¾èµ–ä¿éšœæœºåˆ¶å’Œä¼˜åŠ¿æ¶ˆå¤±çš„é—®é¢˜ã€‚</li>
<li>Reg-GRPOå°†GRPOæŸå¤±å‡½æ•°é‡æ–°å®šä¹‰ä¸ºå›å½’ä»»åŠ¡ï¼Œæ¶ˆé™¤å¯¹ä¿éšœæœºåˆ¶çš„ä¾èµ–ã€‚</li>
<li>éš¾åº¦æ„ŸçŸ¥æ•°æ®å¢å¼ºç­–ç•¥å¯ä»¥æé«˜è¾“å…¥æç¤º&#x2F;è§†é¢‘çš„éš¾åº¦ï¼Œä½¿å…¶å¤„äºå¯è§£å†³æ°´å¹³ã€‚</li>
<li>DeepVideo-R1é€šè¿‡ç»“åˆReg-GRPOå’Œéš¾åº¦æ„ŸçŸ¥æ•°æ®å¢å¼ºï¼Œæ˜¾è‘—æé«˜äº†è§†é¢‘æ¨ç†æ€§èƒ½ã€‚</li>
<li>è¯¥æ–¹æ³•åœ¨å¤šåŸºå‡†æµ‹è¯•ä¸­è¡¨ç°å‡ºè‰¯å¥½çš„æ€§èƒ½ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.07464">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-013123f77802e25833b0adc740752017" align="middle">
<img src="https://picx.zhimg.com/v2-f1ecb9e7d1f8c03f2e581b2611774c85" align="middle">
<img src="https://picx.zhimg.com/v2-b945f3fc7c6c05987b0013c159cdf9a1" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="AgentThink-A-Unified-Framework-for-Tool-Augmented-Chain-of-Thought-Reasoning-in-Vision-Language-Models-for-Autonomous-Driving"><a href="#AgentThink-A-Unified-Framework-for-Tool-Augmented-Chain-of-Thought-Reasoning-in-Vision-Language-Models-for-Autonomous-Driving" class="headerlink" title="AgentThink: A Unified Framework for Tool-Augmented Chain-of-Thought Reasoning in Vision-Language Models for Autonomous Driving"></a>AgentThink: A Unified Framework for Tool-Augmented Chain-of-Thought Reasoning in Vision-Language Models for Autonomous Driving</h2><p><strong>Authors:Kangan Qian, Sicong Jiang, Yang Zhong, Ziang Luo, Zilin Huang, Tianze Zhu, Kun Jiang, Mengmeng Yang, Zheng Fu, Jinyu Miao, Yining Shi, He Zhe Lim, Li Liu, Tianbao Zhou, Huang Yu, Yifei Hu, Guang Li, Guang Chen, Hao Ye, Lijun Sun, Diange Yang</strong></p>
<p>Vision-Language Models (VLMs) show promise for autonomous driving, yet their struggle with hallucinations, inefficient reasoning, and limited real-world validation hinders accurate perception and robust step-by-step reasoning. To overcome this, we introduce \textbf{AgentThink}, a pioneering unified framework that integrates Chain-of-Thought (CoT) reasoning with dynamic, agent-style tool invocation for autonomous driving tasks. AgentThinkâ€™s core innovations include: \textbf{(i) Structured Data Generation}, which establishes an autonomous driving tool library to automatically construct structured, self-verified reasoning data explicitly incorporating tool usage for diverse driving scenarios; \textbf{(ii) A Two-stage Training Pipeline}, employing Supervised Fine-Tuning (SFT) with Group Relative Policy Optimization (GRPO) to equip VLMs with the capability for autonomous tool invocation; and \textbf{(iii) Agent-style Tool-Usage Evaluation}, introducing a novel multi-tool assessment protocol to rigorously evaluate the modelâ€™s tool invocation and utilization. Experiments on the DriveLMM-o1 benchmark demonstrate that AgentThink significantly boosts overall reasoning scores by \textbf{53.91%} and enhances answer accuracy by \textbf{33.54%}, while markedly improving reasoning quality and consistency. Furthermore, ablation studies and robust zero-shot&#x2F;few-shot generalization experiments across various benchmarks underscore its powerful capabilities. These findings highlight a promising trajectory for developing trustworthy and tool-aware autonomous driving models. Code is available at <a target="_blank" rel="noopener" href="https://github.com/curryqka/AgentThink">https://github.com/curryqka/AgentThink</a>.</p>
<blockquote>
<p>è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMsï¼‰åœ¨è‡ªåŠ¨é©¾é©¶é¢†åŸŸæ˜¾ç¤ºå‡ºå·¨å¤§çš„æ½œåŠ›ï¼Œç„¶è€Œå®ƒä»¬æ‰€é¢ä¸´çš„å¹»è§‰ã€æ¨ç†æ•ˆç‡ä½ä¸‹å’Œç°å®ä¸–ç•ŒéªŒè¯æœ‰é™ç­‰é—®é¢˜é˜»ç¢äº†å‡†ç¡®çš„æ„ŸçŸ¥å’Œç¨³å¥çš„é€æ­¥æ¨ç†ã€‚ä¸ºäº†å…‹æœè¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬å¼•å…¥äº†<strong>AgentThink</strong>ï¼Œè¿™æ˜¯ä¸€ä¸ªå¼€åˆ›æ€§çš„ç»Ÿä¸€æ¡†æ¶ï¼Œå®ƒå°†æ€ç»´é“¾ï¼ˆCoTï¼‰æ¨ç†ä¸åŠ¨æ€ã€ä»£ç†å¼å·¥å…·è°ƒç”¨ç›¸ç»“åˆï¼Œç”¨äºè‡ªåŠ¨é©¾é©¶ä»»åŠ¡ã€‚AgentThinkçš„æ ¸å¿ƒåˆ›æ–°åŒ…æ‹¬ï¼š<strong>ï¼ˆiï¼‰ç»“æ„åŒ–æ•°æ®ç”Ÿæˆ</strong>ï¼Œå»ºç«‹è‡ªåŠ¨é©¾é©¶å·¥å…·åº“ï¼Œè‡ªåŠ¨æ„å»ºç»“æ„åŒ–ã€è‡ªæˆ‘éªŒè¯çš„æ¨ç†æ•°æ®ï¼Œæ˜ç¡®èå…¥å„ç§é©¾é©¶åœºæ™¯çš„å·¥å…·ä½¿ç”¨ï¼›<strong>ï¼ˆiiï¼‰ä¸¤é˜¶æ®µè®­ç»ƒç®¡é“</strong>ï¼Œé‡‡ç”¨ç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰å’Œç¾¤ç»„ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–ï¼ˆGRPOï¼‰ï¼Œä½¿VLMså…·å¤‡è‡ªä¸»å·¥å…·è°ƒç”¨çš„èƒ½åŠ›ï¼›<strong>ï¼ˆiiiï¼‰ä»£ç†å¼å·¥å…·ä½¿ç”¨è¯„ä¼°</strong>ï¼Œå¼•å…¥ä¸€ç§æ–°çš„å¤šå·¥å…·è¯„ä¼°åè®®ï¼Œä¸¥æ ¼è¯„ä¼°æ¨¡å‹çš„å·¥å…·è°ƒç”¨å’Œä½¿ç”¨æƒ…å†µã€‚åœ¨DriveLMM-o1åŸºå‡†æµ‹è¯•ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒAgentThinkæ•´ä½“æ¨ç†å¾—åˆ†æé«˜äº†**53.91%<strong>ï¼Œç­”æ¡ˆå‡†ç¡®æ€§æé«˜äº†</strong>33.54%**ï¼ŒåŒæ—¶æ˜¾è‘—æé«˜äº†æ¨ç†è´¨é‡å’Œä¸€è‡´æ€§ã€‚æ­¤å¤–ï¼Œæ¶ˆèç ”ç©¶å’Œåœ¨å„ç§åŸºå‡†æµ‹è¯•ä¸Šçš„ç¨³å¥é›¶æ ·æœ¬&#x2F;å°‘æ ·æœ¬æ³›åŒ–å®éªŒçªæ˜¾äº†å…¶å¼ºå¤§çš„èƒ½åŠ›ã€‚è¿™äº›å‘ç°ä¸ºæˆ‘ä»¬å¼€å‘å¯ä¿¡ä¸”å·¥å…·æ„ŸçŸ¥çš„è‡ªåŠ¨é©¾é©¶æ¨¡å‹æŒ‡æ˜äº†æœ‰å¸Œæœ›çš„è·¯å¾„ã€‚ä»£ç å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/curryqka/AgentThink%E5%A4%84%E8%8E%B7%E5%8F%96%E3%80%82">https://github.com/curryqka/AgentThinkå¤„è·å–ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.15298v4">PDF</a> 19 pages, 8 figures</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†é’ˆå¯¹è‡ªåŠ¨é©¾é©¶é¢†åŸŸè§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMsï¼‰å­˜åœ¨çš„å±€é™è€Œæå‡ºçš„ä¸€ç§åä¸ºAgentThinkçš„ç»Ÿä¸€æ¡†æ¶ã€‚è¯¥æ¡†æ¶ç»“åˆäº†é“¾å¼æ€ç»´ï¼ˆCoTï¼‰æ¨ç†ä¸åŠ¨æ€å·¥å…·è°ƒç”¨æŠ€æœ¯ï¼Œä»¥æé«˜VLMsçš„æ„ŸçŸ¥å‡†ç¡®æ€§å’Œé€æ­¥æ¨ç†çš„ç¨³å¥æ€§ã€‚AgentThinkçš„æ ¸å¿ƒåˆ›æ–°åŒ…æ‹¬ç»“æ„åŒ–æ•°æ®ç”Ÿæˆã€ä¸¤é˜¶æ®µè®­ç»ƒç®¡é“å’Œå·¥å…·ä½¿ç”¨è¯„ä¼°åè®®ã€‚å®éªŒè¡¨æ˜ï¼ŒAgentThinkæ˜¾è‘—æé«˜äº†æ¨ç†å¾—åˆ†å’Œç­”æ¡ˆå‡†ç¡®æ€§ï¼Œå¹¶æ”¹å–„äº†æ¨ç†è´¨é‡å’Œä¸€è‡´æ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>AgentThinkæ˜¯ä¸€ä¸ªç»Ÿä¸€æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³è‡ªåŠ¨é©¾é©¶ä¸­è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMsï¼‰å­˜åœ¨çš„å±€é™ï¼Œå¦‚å¹»è§‰ã€ä½æ•ˆæ¨ç†å’Œç¼ºä¹çœŸå®ä¸–ç•ŒéªŒè¯ç­‰é—®é¢˜ã€‚</li>
<li>è¯¥æ¡†æ¶ç»“åˆäº†é“¾å¼æ€ç»´ï¼ˆCoTï¼‰æ¨ç†ä¸åŠ¨æ€å·¥å…·è°ƒç”¨æŠ€æœ¯ï¼Œä»¥å¼ºåŒ–æ¨¡å‹çš„æ„ŸçŸ¥å’Œæ¨ç†èƒ½åŠ›ã€‚</li>
<li>AgentThinkçš„æ ¸å¿ƒåˆ›æ–°åŒ…æ‹¬ç»“æ„åŒ–æ•°æ®ç”Ÿæˆã€ä¸¤é˜¶æ®µè®­ç»ƒç®¡é“ä»¥åŠæ–°é¢–çš„è¯„ä¼°åè®®ï¼Œç”¨äºè¯„ä¼°æ¨¡å‹åœ¨å¤šç§é©¾é©¶åœºæ™¯ä¸­çš„å·¥å…·è°ƒç”¨å’Œä½¿ç”¨èƒ½åŠ›ã€‚</li>
<li>åœ¨DriveLMM-o1åŸºå‡†æµ‹è¯•ä¸Šè¿›è¡Œçš„å®éªŒè¡¨æ˜ï¼ŒAgentThinkæ˜¾è‘—æé«˜äº†æ¨ç†å¾—åˆ†å’Œç­”æ¡ˆå‡†ç¡®æ€§ï¼Œæ”¹å–„äº†æ¨ç†è´¨é‡å’Œä¸€è‡´æ€§ã€‚</li>
<li>è¯¥æ¡†æ¶å±•ç°å‡ºå¼ºå¤§çš„è·¨åŸºå‡†æµ‹è¯•èƒ½åŠ›ï¼Œé€šè¿‡ç¨³å¥çš„é›¶æ ·æœ¬å’Œå°‘æ ·æœ¬æ³›åŒ–å®éªŒå¾—åˆ°éªŒè¯ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.15298">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-b85619e531f2c155789012fe96eeb561" align="middle">
<img src="https://picx.zhimg.com/v2-d1af87f52b1bc48bc374a6e55f809a60" align="middle">
<img src="https://picx.zhimg.com/v2-7a73d8a17e55c2a08f09551420082944" align="middle">
<img src="https://picx.zhimg.com/v2-5361ef7a8e6860020e18feecfe9e7c22" align="middle">
<img src="https://picx.zhimg.com/v2-a97ce5d3c4803036b61628789abddc5d" align="middle">
<img src="https://picx.zhimg.com/v2-599a29349cceb911f8507014c3af8512" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="Fast-Slow-Thinking-GRPO-for-Large-Vision-Language-Model-Reasoning"><a href="#Fast-Slow-Thinking-GRPO-for-Large-Vision-Language-Model-Reasoning" class="headerlink" title="Fast-Slow Thinking GRPO for Large Vision-Language Model Reasoning"></a>Fast-Slow Thinking GRPO for Large Vision-Language Model Reasoning</h2><p><strong>Authors:Wenyi Xiao, Leilei Gan</strong></p>
<p>When applying reinforcement learningâ€“typically through GRPOâ€“to large vision-language model reasoning struggles to effectively scale reasoning length or generates verbose outputs across all tasks with only marginal gains in accuracy. To address this issue, we present FAST-GRPO, a variant of GRPO that dynamically adapts reasoning depth based on question characteristics. Through empirical analysis, we establish the feasibility of fast-slow thinking in LVLMs by investigating how response length and data distribution affect performance. Inspired by these observations, we introduce two complementary metrics to estimate the difficulty of the questions, guiding the model to determine when fast or slow thinking is more appropriate. Next, we incorporate adaptive length-based rewards and difficulty-aware KL divergence into the GRPO algorithm. Experiments across seven reasoning benchmarks demonstrate that FAST achieves state-of-the-art accuracy with over 10% relative improvement compared to the base model, while reducing token usage by 32.7-67.3% compared to previous slow-thinking approaches, effectively balancing reasoning length and accuracy.</p>
<blockquote>
<p>å½“ä½¿ç”¨å¼ºåŒ–å­¦ä¹ ï¼ˆé€šå¸¸é€šè¿‡GRPOï¼‰å¯¹å¤§å‹è§†è§‰è¯­è¨€æ¨¡å‹è¿›è¡Œæ¨ç†æ—¶ï¼Œé¢ä¸´ç€éš¾ä»¥æœ‰æ•ˆæ‰©å±•æ¨ç†é•¿åº¦çš„é—®é¢˜ï¼Œæˆ–åœ¨æ‰€æœ‰ä»»åŠ¡ä¸­ç”Ÿæˆå†—é•¿çš„è¾“å‡ºï¼Œè€Œå‡†ç¡®ç‡åªæœ‰å¾®å°çš„æé«˜ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†FAST-GRPOï¼Œè¿™æ˜¯GRPOçš„ä¸€ç§å˜ä½“ï¼Œå®ƒæ ¹æ®é—®é¢˜çš„ç‰¹æ€§åŠ¨æ€é€‚åº”æ¨ç†æ·±åº¦ã€‚é€šè¿‡å®è¯åˆ†æï¼Œæˆ‘ä»¬è¯æ˜äº†å¿«æ…¢æ€ç»´åœ¨LVLMsä¸­çš„å¯è¡Œæ€§ï¼Œå¹¶ç ”ç©¶äº†å“åº”é•¿åº¦å’Œæ•°æ®åˆ†å¸ƒå¦‚ä½•å½±å“æ€§èƒ½ã€‚å—è¿™äº›è§‚å¯Ÿçš„å¯å‘ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸¤ç§äº’è¡¥çš„æŒ‡æ ‡æ¥ä¼°è®¡é—®é¢˜çš„éš¾åº¦ï¼ŒæŒ‡å¯¼æ¨¡å‹ç¡®å®šä½•æ—¶ä½¿ç”¨å¿«é€Ÿæˆ–æ…¢é€Ÿæ€ç»´æ›´ä¸ºåˆé€‚ã€‚æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å°†åŸºäºé•¿åº¦çš„è‡ªé€‚åº”å¥–åŠ±å’Œéš¾åº¦æ„ŸçŸ¥KLæ•£åº¦çº³å…¥GRPOç®—æ³•ã€‚åœ¨ä¸ƒä¸ªæ¨ç†åŸºå‡†æµ‹è¯•ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒFASTå®ç°äº†æœ€å…ˆè¿›çš„å‡†ç¡®æ€§ï¼Œä¸åŸºç¡€æ¨¡å‹ç›¸æ¯”ï¼Œç›¸å¯¹æé«˜äº†10%ä»¥ä¸Šï¼ŒåŒæ—¶ä¸ä¹‹å‰çš„æ…¢é€Ÿæ€ç»´æ–¹æ³•ç›¸æ¯”ï¼Œä»¤ç‰Œä½¿ç”¨é‡å‡å°‘äº†32.7-67.3%ï¼Œæœ‰æ•ˆåœ°å¹³è¡¡äº†æ¨ç†é•¿åº¦å’Œå‡†ç¡®æ€§ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.18458v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>åœ¨å¤§å‹è§†è§‰è¯­è¨€æ¨¡å‹ä¸­ï¼Œåº”ç”¨å¼ºåŒ–å­¦ä¹ ï¼ˆé€šå¸¸é€šè¿‡GRPOå®ç°ï¼‰è¿›è¡Œæ¨ç†æ—¶ï¼Œå­˜åœ¨æ¨ç†é•¿åº¦éš¾ä»¥æœ‰æ•ˆæ‰©å±•æˆ–è¾“å‡ºè¿‡äºå†—é•¿çš„é—®é¢˜ï¼Œä¸”å‡†ç¡®åº¦ä»…ç•¥æœ‰æå‡ã€‚ä¸ºè§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†FAST-GRPOæ–¹æ³•ï¼Œè¿™æ˜¯ä¸€ç§èƒ½æ ¹æ®é—®é¢˜ç‰¹æ€§åŠ¨æ€è°ƒæ•´æ¨ç†æ·±åº¦çš„GRPOå˜ä½“ã€‚é€šè¿‡å®è¯ç ”ç©¶ï¼Œæˆ‘ä»¬è¯æ˜äº†å¿«æ…¢æ€è€ƒçš„å¯è¡Œæ€§ï¼Œå¹¶å‘ç°å“åº”é•¿åº¦å’Œæ•°æ®åˆ†å¸ƒå¯¹æ€§èƒ½çš„å½±å“ã€‚åŸºäºæ­¤è§‚å¯Ÿï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸¤ç§äº’è¡¥æŒ‡æ ‡æ¥è¯„ä¼°é—®é¢˜çš„éš¾åº¦ï¼ŒæŒ‡å¯¼æ¨¡å‹åˆ¤æ–­ä½•æ—¶é‡‡ç”¨å¿«é€Ÿæˆ–æ…¢é€Ÿæ€è€ƒæ›´ä¸ºåˆé€‚ã€‚æ¥ç€ï¼Œæˆ‘ä»¬å°†åŸºäºé•¿åº¦çš„è‡ªé€‚åº”å¥–åŠ±å’Œéš¾åº¦æ„ŸçŸ¥KLæ•£åº¦èå…¥GRPOç®—æ³•ã€‚åœ¨ä¸ƒä¸ªæ¨ç†åŸºå‡†æµ‹è¯•ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒFASTæ–¹æ³•å®ç°äº†æœ€å…ˆè¿›çš„å‡†ç¡®æ€§ï¼Œç›¸å¯¹äºåŸºç¡€æ¨¡å‹æœ‰è¶…è¿‡10%çš„ç›¸å¯¹æ”¹è¿›ï¼ŒåŒæ—¶ç›¸æ¯”ä¹‹å‰çš„æ…¢é€Ÿæ€è€ƒæ–¹æ³•å‡å°‘äº†32.7-67.3%çš„ä»¤ç‰Œä½¿ç”¨é‡ï¼Œæœ‰æ•ˆåœ°å¹³è¡¡äº†æ¨ç†é•¿åº¦å’Œå‡†ç¡®æ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>åº”ç”¨å¼ºåŒ–å­¦ä¹ åœ¨å¤§å‹è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆLVLMsï¼‰è¿›è¡Œæ¨ç†æ—¶é¢ä¸´æ¨ç†é•¿åº¦å’Œè¾“å‡ºå†—é•¿çš„é—®é¢˜ã€‚</li>
<li>æå‡ºFAST-GRPOæ–¹æ³•ï¼Œèƒ½æ ¹æ®é—®é¢˜ç‰¹æ€§åŠ¨æ€è°ƒæ•´æ¨ç†æ·±åº¦ã€‚</li>
<li>é€šè¿‡å®è¯ç ”ç©¶è¯æ˜äº†å¿«æ…¢æ€è€ƒçš„å¯è¡Œæ€§ã€‚</li>
<li>å¼•å…¥ä¸¤ç§äº’è¡¥æŒ‡æ ‡è¯„ä¼°é—®é¢˜éš¾åº¦ï¼ŒæŒ‡å¯¼æ¨¡å‹é€‰æ‹©é€‚å½“çš„æ€è€ƒé€Ÿåº¦ã€‚</li>
<li>å°†è‡ªé€‚åº”é•¿åº¦å¥–åŠ±å’Œéš¾åº¦æ„ŸçŸ¥KLæ•£åº¦èå…¥GRPOç®—æ³•ã€‚</li>
<li>åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­ï¼ŒFASTæ–¹æ³•å®ç°äº†è¾ƒé«˜çš„å‡†ç¡®æ€§å’Œæ˜¾è‘—çš„ç›¸å¯¹æ”¹è¿›ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.18458">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-6bc5187d636c144bd877ef554cc80ce6" align="middle">
<img src="https://picx.zhimg.com/v2-317a48aba66dc9f0c3be490547c8c71a" align="middle">
<img src="https://picx.zhimg.com/v2-a47face625e3e6937e292b02d2b5293a" align="middle">
<img src="https://picx.zhimg.com/v2-b8f6490cca3316d74c39ef4c9194fd74" align="middle">
<img src="https://picx.zhimg.com/v2-a372da57c9562b358b42b9a829c6f6cd" align="middle">
<img src="https://picx.zhimg.com/v2-00fc667e02b7382ad6f1366c46c99388" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="Video-R1-Reinforcing-Video-Reasoning-in-MLLMs"><a href="#Video-R1-Reinforcing-Video-Reasoning-in-MLLMs" class="headerlink" title="Video-R1: Reinforcing Video Reasoning in MLLMs"></a>Video-R1: Reinforcing Video Reasoning in MLLMs</h2><p><strong>Authors:Kaituo Feng, Kaixiong Gong, Bohao Li, Zonghao Guo, Yibing Wang, Tianshuo Peng, Junfei Wu, Xiaoying Zhang, Benyou Wang, Xiangyu Yue</strong></p>
<p>Inspired by DeepSeek-R1â€™s success in eliciting reasoning abilities through rule-based reinforcement learning (RL), we introduce Video-R1 as the first attempt to systematically explore the R1 paradigm for incentivizing video reasoning within multimodal large language models (MLLMs). However, directly applying RL training with the GRPO algorithm to video reasoning presents two primary challenges: (i) a lack of temporal modeling for video reasoning, and (ii) the scarcity of high-quality video-reasoning data. To address these issues, we first propose the T-GRPO algorithm, which encourages models to utilize temporal information in videos for reasoning. Additionally, instead of relying solely on video data, we incorporate high-quality image-reasoning data into the training process. We have constructed two datasets: Video-R1-CoT-165k for SFT cold start and Video-R1-260k for RL training, both comprising image and video data. Experimental results demonstrate that Video-R1 achieves significant improvements on video reasoning benchmarks such as VideoMMMU and VSI-Bench, as well as on general video benchmarks including MVBench and TempCompass, etc. Notably, Video-R1-7B attains a 37.1% accuracy on video spatial reasoning benchmark VSI-bench, surpassing the commercial proprietary model GPT-4o. All code, models, and data are released in: <a target="_blank" rel="noopener" href="https://github.com/tulerfeng/Video-R1">https://github.com/tulerfeng/Video-R1</a>.</p>
<blockquote>
<p>å—DeepSeek-R1åœ¨åŸºäºè§„åˆ™çš„å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰ä¸­æ¿€å‘æ¨ç†èƒ½åŠ›çš„æˆåŠŸçš„å¯å‘ï¼Œæˆ‘ä»¬æ¨å‡ºVideo-R1ï¼Œé¦–æ¬¡å°è¯•åœ¨å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰ä¸­ç³»ç»Ÿåœ°æ¢ç´¢R1èŒƒå¼ä»¥æ¿€åŠ±è§†é¢‘æ¨ç†ã€‚ç„¶è€Œï¼Œç›´æ¥å°†RLè®­ç»ƒå’ŒGRPOç®—æ³•åº”ç”¨äºè§†é¢‘æ¨ç†é¢ä¸´ä¸¤ä¸ªä¸»è¦æŒ‘æˆ˜ï¼šï¼ˆiï¼‰è§†é¢‘æ¨ç†ç¼ºä¹æ—¶é—´å»ºæ¨¡ï¼›ï¼ˆiiï¼‰é«˜è´¨é‡è§†é¢‘æ¨ç†æ•°æ®çš„ç¨€ç¼ºã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬é¦–å…ˆæå‡ºT-GRPOç®—æ³•ï¼Œè¯¥ç®—æ³•é¼“åŠ±æ¨¡å‹åœ¨æ¨ç†æ—¶åˆ©ç”¨è§†é¢‘ä¸­çš„æ—¶é—´ä¿¡æ¯ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬ä¸æ˜¯ä»…ä¾èµ–è§†é¢‘æ•°æ®ï¼Œè€Œæ˜¯å°†é«˜è´¨é‡å›¾åƒæ¨ç†æ•°æ®çº³å…¥è®­ç»ƒè¿‡ç¨‹ã€‚æˆ‘ä»¬æ„å»ºäº†ä¸¤ä¸ªæ•°æ®é›†ï¼šç”¨äºSFTå†·å¯åŠ¨çš„Video-R1-CoT-165kå’Œç”¨äºRLè®­ç»ƒçš„è§†é¢‘R1-260kï¼Œä¸¤è€…éƒ½åŒ…å«å›¾åƒå’Œè§†é¢‘æ•°æ®ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒVideo-R1åœ¨è§†é¢‘æ¨ç†åŸºå‡†æµ‹è¯•ï¼ˆå¦‚VideoMMMUå’ŒVSI-Benchï¼‰ä»¥åŠé€šç”¨è§†é¢‘åŸºå‡†æµ‹è¯•ï¼ˆå¦‚MVBenchå’ŒTempCompassç­‰ï¼‰ä¸Šå–å¾—äº†æ˜¾è‘—æ”¹è¿›ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼ŒVideo-R1-7Båœ¨è§†é¢‘ç©ºé—´æ¨ç†åŸºå‡†VSI-benchä¸Šè¾¾åˆ°äº†37.1%çš„å‡†ç¡®ç‡ï¼Œè¶…è¿‡äº†å•†ä¸šä¸“æœ‰æ¨¡å‹GPT-4oã€‚æ‰€æœ‰ä»£ç ã€æ¨¡å‹å’Œæ•°æ®å‡å·²åœ¨<a target="_blank" rel="noopener" href="https://github.com/tulerfeng/Video-Rl%E4%B8%AD%E5%8F%91%E5%B8%83%E3%80%82">https://github.com/tulerfeng/Video-Rlä¸­å‘å¸ƒã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.21776v4">PDF</a> NeurIPS 2025, Project page: <a target="_blank" rel="noopener" href="https://github.com/tulerfeng/Video-R1">https://github.com/tulerfeng/Video-R1</a></p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†åŸºäºDeepSeek-R1æˆåŠŸæ¿€å‘æ¨ç†èƒ½åŠ›çš„å¯å‘ï¼Œæ¨å‡ºVideo-R1ï¼Œæ—¨åœ¨ç³»ç»Ÿæ¢ç´¢R1èŒƒå¼åœ¨å¤šåª’ä½“å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰ä¸­æ¿€åŠ±è§†é¢‘æ¨ç†çš„åº”ç”¨ã€‚é’ˆå¯¹ç›´æ¥åº”ç”¨å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰è®­ç»ƒè§†é¢‘æ¨ç†é¢ä¸´çš„æŒ‘æˆ˜ï¼Œå¦‚ç¼ºä¹è§†é¢‘çš„æ—¶é—´å»ºæ¨¡å’Œé«˜è´¨é‡è§†é¢‘æ¨ç†æ•°æ®çš„ç¨€ç¼ºæ€§ï¼Œæå‡ºäº†T-GRPOç®—æ³•ï¼Œå¹¶èå…¥å›¾åƒæ¨ç†æ•°æ®ã€‚æ„å»ºäº†Video-R1-CoT-165kå’ŒVideo-R1-260kæ•°æ®é›†ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒVideo-R1åœ¨è§†é¢‘æ¨ç†åŸºå‡†æµ‹è¯•ã€é€šç”¨è§†é¢‘åŸºå‡†æµ‹è¯•ç­‰æ–¹é¢å–å¾—æ˜¾è‘—æ”¹è¿›ï¼Œè¶…è¶Šäº†å•†ä¸šä¸“æœ‰æ¨¡å‹GPT-4oã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>Video-R1æ˜¯é¦–ä¸ªå°è¯•ç³»ç»Ÿæ¢ç´¢R1èŒƒå¼ä»¥æ¿€åŠ±å¤šåª’ä½“å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰ä¸­è§†é¢‘æ¨ç†çš„ç ”ç©¶ã€‚</li>
<li>ç›´æ¥åº”ç”¨å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰è®­ç»ƒè§†é¢‘æ¨ç†é¢ä¸´ä¸¤å¤§æŒ‘æˆ˜ï¼šç¼ºä¹è§†é¢‘æ—¶é—´å»ºæ¨¡å’Œé«˜è´¨é‡è§†é¢‘æ¨ç†æ•°æ®ç¨€ç¼ºã€‚</li>
<li>ä¸ºè§£å†³è¿™äº›é—®é¢˜ï¼Œæå‡ºäº†T-GRPOç®—æ³•ï¼Œé¼“åŠ±æ¨¡å‹åˆ©ç”¨è§†é¢‘ä¸­çš„æ—¶é—´ä¿¡æ¯è¿›è¡Œæ¨ç†ã€‚</li>
<li>é™¤äº†è§†é¢‘æ•°æ®ï¼Œè¿˜èå…¥äº†é«˜è´¨é‡å›¾åƒæ¨ç†æ•°æ®ï¼Œæ„å»ºäº†Video-R1-CoT-165kå’ŒVideo-R1-260kæ•°æ®é›†ã€‚</li>
<li>Video-R1åœ¨è§†é¢‘æ¨ç†åŸºå‡†æµ‹è¯•å¦‚VideoMMMUå’ŒVSI-Benchä¸Šå–å¾—äº†æ˜¾è‘—æ”¹è¿›ã€‚</li>
<li>Video-R1åœ¨é€šç”¨è§†é¢‘åŸºå‡†æµ‹è¯•å¦‚MVBenchå’ŒTempCompassä¸Šä¹Ÿè¡¨ç°å‡ºä¼˜è¶Šæ€§èƒ½ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.21776">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-86cc482ec732628c8b77ba22e9574cb1" align="middle">
<img src="https://picx.zhimg.com/v2-03055b08915b92cc8504eb63f628b535" align="middle">
<img src="https://picx.zhimg.com/v2-0b631a2259ac95749d4a78b6f901dd5b" align="middle">
<img src="https://picx.zhimg.com/v2-b5b5b4b8c2a0b62ef37e9b99900c7d55" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-11-12/R1_Reasoning/">https://kedreamix.github.io/Talk2Paper/Paper/2025-11-12/R1_Reasoning/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/R1-Reasoning/">
                                    <span class="chip bg-color">R1_Reasoning</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-11-12/3DGS/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-39a6797277e1b30604038c9e0a5b7c5c" class="responsive-img" alt="3DGS">
                        
                        <span class="card-title">3DGS</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            3DGS æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-11-12  Human-VDM Learning Single-Image 3D Human Gaussian Splatting from Video Diffusion Models
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-11-12
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/3DGS/" class="post-category">
                                    3DGS
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/3DGS/">
                        <span class="chip bg-color">3DGS</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-11-11/Talking%20Head%20Generation/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-0ec34a24e484e5230672a711d01539b0" class="responsive-img" alt="Talking Head Generation">
                        
                        <span class="card-title">Talking Head Generation</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Talking Head Generation æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-11-11  Shared Latent Representation for Joint Text-to-Audio-Visual Synthesis
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-11-11
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Talking-Head-Generation/" class="post-category">
                                    Talking Head Generation
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Talking-Head-Generation/">
                        <span class="chip bg-color">Talking Head Generation</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">32306k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
