<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="R1_Reasoning">
    <meta name="description" content="R1_Reasoning æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-09-10  On the Same Wavelength? Evaluating Pragmatic Reasoning in Language   Models across Broad Concepts">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>R1_Reasoning | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://picx.zhimg.com/v2-c29b0f436b40b28911b22bf67cd90fc8.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">R1_Reasoning</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/R1-Reasoning/">
                                <span class="chip bg-color">R1_Reasoning</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/R1-Reasoning/" class="post-category">
                                R1_Reasoning
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-09-10
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-10-07
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    23.5k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    94 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-09-10-æ›´æ–°"><a href="#2025-09-10-æ›´æ–°" class="headerlink" title="2025-09-10 æ›´æ–°"></a>2025-09-10 æ›´æ–°</h1><h2 id="On-the-Same-Wavelength-Evaluating-Pragmatic-Reasoning-in-Language-Models-across-Broad-Concepts"><a href="#On-the-Same-Wavelength-Evaluating-Pragmatic-Reasoning-in-Language-Models-across-Broad-Concepts" class="headerlink" title="On the Same Wavelength? Evaluating Pragmatic Reasoning in Language   Models across Broad Concepts"></a>On the Same Wavelength? Evaluating Pragmatic Reasoning in Language   Models across Broad Concepts</h2><p><strong>Authors:Linlu Qiu, Cedegao E. Zhang, Joshua B. Tenenbaum, Yoon Kim, Roger P. Levy</strong></p>
<p>Language use is shaped by pragmatics â€“ i.e., reasoning about communicative goals and norms in context. As language models (LMs) are increasingly used as conversational agents, it becomes ever more important to understand their pragmatic reasoning abilities. We propose an evaluation framework derived from Wavelength, a popular communication game where a speaker and a listener communicate about a broad range of concepts in a granular manner. We study a range of LMs on both language comprehension and language production using direct and Chain-of-Thought (CoT) prompting, and further explore a Rational Speech Act (RSA) approach to incorporating Bayesian pragmatic reasoning into LM inference. We find that state-of-the-art LMs, but not smaller ones, achieve strong performance on language comprehension, obtaining similar-to-human accuracy and exhibiting high correlations with human judgments even without CoT prompting or RSA. On language production, CoT can outperform direct prompting, and using RSA provides significant improvements over both approaches. Our study helps identify the strengths and limitations in LMsâ€™ pragmatic reasoning abilities and demonstrates the potential for improving them with RSA, opening up future avenues for understanding conceptual representation, language understanding, and social reasoning in LMs and humans. </p>
<blockquote>
<p>è¯­è¨€ä½¿ç”¨å—åˆ°è¯­ç”¨å­¦çš„å½±å“ï¼Œå³æ ¹æ®ä¸Šä¸‹æ–‡ä¸­çš„äº¤é™…ç›®æ ‡å’Œè§„èŒƒè¿›è¡Œæ¨ç†ã€‚éšç€è¯­è¨€æ¨¡å‹ï¼ˆLMsï¼‰è¶Šæ¥è¶Šå¤šåœ°è¢«ç”¨ä½œå¯¹è¯ä»£ç†ï¼Œç†è§£å®ƒä»¬çš„è¯­ç”¨æ¨ç†èƒ½åŠ›å˜å¾—è‡³å…³é‡è¦ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªè¯„ä¼°æ¡†æ¶ï¼Œå®ƒæ¥æºäºæ³¢é•¿ï¼ˆæ³¢é•¿æ˜¯ä¸€ç§æµè¡Œçš„é€šä¿¡æ¸¸æˆï¼‰ï¼Œåœ¨æ¸¸æˆä¸­ï¼Œè¯´è¯è€…å’Œå¬è€…ä»¥ç²¾ç»†çš„æ–¹å¼äº¤æµå„ç§æ¦‚å¿µã€‚æˆ‘ä»¬ç ”ç©¶äº†è¯­è¨€æ¨¡å‹çš„è¯­è¨€ç†è§£å’Œè¯­è¨€ç”Ÿäº§è¡¨ç°æƒ…å†µï¼ŒåŒ…æ‹¬ç›´æ¥ä½¿ç”¨æç¤ºå’Œé“¾å¼æ€è€ƒï¼ˆCoTï¼‰æç¤ºçš„æƒ…å†µï¼Œå¹¶è¿›ä¸€æ­¥æ¢ç´¢å°†ç†æ€§è¨€è¯­è¡Œä¸ºï¼ˆRSAï¼‰æ–¹æ³•èå…¥è¯­è¨€æ¨¡å‹æ¨æ–­ä¸­çš„è´å¶æ–¯è¯­ç”¨æ¨ç†ã€‚æˆ‘ä»¬å‘ç°å°–ç«¯çš„è¯­è¨€æ¨¡å‹ï¼ˆä½†ä¸æ˜¯è¾ƒå°çš„æ¨¡å‹ï¼‰åœ¨è¯­è¨€ç†è§£æ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œå³ä½¿æ²¡æœ‰ä½¿ç”¨CoTæç¤ºæˆ–RSAï¼Œå…¶å‡†ç¡®æ€§ä¹Ÿä¸äººç±»ç›¸ä¼¼ï¼Œä¸äººç±»åˆ¤æ–­é«˜åº¦ç›¸å…³ã€‚åœ¨è¯­è¨€ç”Ÿäº§æ–¹é¢ï¼Œé“¾å¼æ€è€ƒçš„è¡¨ç°å¯èƒ½ä¼˜äºç›´æ¥æç¤ºï¼Œä½¿ç”¨RSAåœ¨ä¸¤ç§æç¤ºæ–¹æ³•ä¸Šå‡å–å¾—äº†æ˜¾è‘—çš„æ”¹è¿›ã€‚æˆ‘ä»¬çš„ç ”ç©¶æœ‰åŠ©äºç¡®å®šè¯­è¨€æ¨¡å‹çš„è¯­ç”¨æ¨ç†èƒ½åŠ›çš„ä¼˜åŠ¿å’Œå±€é™æ€§ï¼Œå¹¶å±•ç¤ºäº†ä½¿ç”¨RSAæé«˜å®ƒä»¬æ½œåŠ›çš„æ½œåŠ›ï¼Œä¸ºç†è§£è¯­è¨€æ¨¡å‹å’Œäººç±»çš„æ¦‚å¿µè¡¨ç¤ºã€è¯­è¨€ç†è§£å’Œç¤¾ä¼šæ¨ç†å¼€è¾Ÿäº†æ–°çš„é€”å¾„ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.06952v1">PDF</a> EMNLP 2025 (Main)</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æ¢è®¨äº†è¯­è¨€ä½¿ç”¨å¦‚ä½•å—åˆ°è¯­å¢ƒä¸­äº¤æµç›®æ ‡å’Œè§„èŒƒçš„å½±å“ï¼Œå¼ºè°ƒäº†è¯­ç”¨æ¨ç†çš„é‡è¦æ€§ã€‚ä½œè€…æå‡ºä¸€ä¸ªåŸºäºæ³¢é•¿ï¼ˆWavelengthï¼‰é€šä¿¡æ¸¸æˆçš„è¯„ä¼°æ¡†æ¶ï¼Œè¯„ä¼°å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLMsï¼‰åœ¨ç†è§£å’Œç”Ÿäº§è¯­è¨€æ–¹é¢çš„èƒ½åŠ›ã€‚é€šè¿‡ç›´æ¥å’Œé“¾å¼æ€ç»´ï¼ˆCoTï¼‰æç¤ºæ³•ï¼Œç ”ç©¶å‘ç°é¡¶å°–çš„è¯­è¨€æ¨¡å‹åœ¨ç†è§£è¯­è¨€æ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œç”šè‡³æ— éœ€CoTæç¤ºæˆ–ç†æ€§è¨€è¯­è¡Œä¸ºï¼ˆRSAï¼‰å°±èƒ½è·å¾—æ¥è¿‘äººç±»çš„å‡†ç¡®ç‡å’Œä¸äººç±»åˆ¤æ–­çš„é«˜åº¦ç›¸å…³æ€§ã€‚åœ¨è¯­è¨€ç”Ÿäº§æ–¹é¢ï¼ŒCoTæç¤ºæ³•ä¼˜äºç›´æ¥æç¤ºæ³•ï¼Œè€ŒRSAçš„ä½¿ç”¨åˆ™è¿›ä¸€æ­¥æ”¹è¿›äº†ä¸¤ç§æ–¹æ³•ã€‚æœ¬æ–‡å¸®åŠ©è¯†åˆ«äº†è¯­è¨€æ¨¡å‹çš„è¯­ç”¨æ¨ç†èƒ½åŠ›çš„ä¼˜ç‚¹å’Œå±€é™æ€§ï¼Œå¹¶å±•ç¤ºäº†é€šè¿‡RSAæé«˜å…¶æ½œåŠ›çš„å¯èƒ½æ€§ï¼Œä¸ºæœªæ¥äº†è§£è¯­è¨€æ¨¡å‹å’Œäººç±»çš„æ¦‚å¿µè¡¨ç¤ºã€è¯­è¨€ç†è§£å’Œç¤¾äº¤æ¨ç†æ‰“å¼€äº†æ–°çš„é€”å¾„ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>è¯­è¨€ä½¿ç”¨å—åˆ°è¯­å¢ƒä¸­äº¤æµç›®æ ‡å’Œè§„èŒƒçš„å½±å“ï¼Œè¯­ç”¨æ¨ç†åœ¨è¯„ä¼°è¯­è¨€æ¨¡å‹ï¼ˆLMsï¼‰çš„èƒ½åŠ›æ—¶å˜å¾—é‡è¦ã€‚</li>
<li>åŸºäºæ³¢é•¿é€šä¿¡æ¸¸æˆçš„è¯„ä¼°æ¡†æ¶ç”¨äºè¯„ä¼°LMsåœ¨ç†è§£å’Œç”Ÿäº§è¯­è¨€æ–¹é¢çš„èƒ½åŠ›ã€‚</li>
<li>é¡¶å°–çš„è¯­è¨€æ¨¡å‹åœ¨ç†è§£è¯­è¨€æ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œæ— éœ€é¢å¤–æç¤ºå°±èƒ½è·å¾—æ¥è¿‘äººç±»çš„å‡†ç¡®ç‡ã€‚</li>
<li>é“¾å¼æ€ç»´ï¼ˆCoTï¼‰æç¤ºæ³•åœ¨è¯­è¨€ç”Ÿäº§æ–¹é¢è¡¨ç°ä¼˜è¶Šã€‚</li>
<li>ç†æ€§è¨€è¯­è¡Œä¸ºï¼ˆRSAï¼‰æ–¹æ³•èƒ½æ˜¾è‘—æé«˜LMsçš„è¯­ç”¨æ¨ç†èƒ½åŠ›ã€‚</li>
<li>æœ¬æ–‡æ­ç¤ºäº†è¯­è¨€æ¨¡å‹çš„è¯­ç”¨æ¨ç†èƒ½åŠ›çš„ä¼˜ç‚¹å’Œå±€é™æ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.06952">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-e75ba2572027be98042e6be353aa6469.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-daa2215c4fa7ed71201d542cdc0506f6.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-ae41efa2f1e98b17add90f0e742973ac.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-c373a9dab2b29b9a52cb2cda7b1773bd.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="Revolutionizing-Reinforcement-Learning-Framework-for-Diffusion-Large-Language-Models"><a href="#Revolutionizing-Reinforcement-Learning-Framework-for-Diffusion-Large-Language-Models" class="headerlink" title="Revolutionizing Reinforcement Learning Framework for Diffusion Large   Language Models"></a>Revolutionizing Reinforcement Learning Framework for Diffusion Large   Language Models</h2><p><strong>Authors:Yinjie Wang, Ling Yang, Bowen Li, Ye Tian, Ke Shen, Mengdi Wang</strong></p>
<p>We propose TraceRL, a trajectory-aware reinforcement learning framework for diffusion language models (DLMs) that incorporates preferred inference trajectory into post-training, and is applicable across different architectures. Equipped with a diffusion-based value model that enhances training stability, we demonstrate improved reasoning performance on complex math and coding tasks. Besides, it can also be applied to adapt block-specific models to larger blocks, which improves sampling flexibility. Employing TraceRL, we derive a series of state-of-the-art diffusion language models, namely TraDo. Although smaller than 7B-scale AR models, TraDo-4B-Instruct still consistently outperforms them across complex math reasoning tasks. TraDo-8B-Instruct achieves relative accuracy improvements of 6.1% over Qwen2.5-7B-Instruct and 51.3% over Llama3.1-8B-Instruct on mathematical reasoning benchmarks. Through curriculum learning, we also derive the first long-CoT DLM, outperforming Qwen2.5-7B-Instruct on MATH500 with an 18.1% relative accuracy gain. To facilitate reproducible research and practical applications, we release a comprehensive open-source framework for building, training, and deploying diffusion LLMs across diverse architectures. The framework integrates accelerated KV-cache techniques and inference engines for both inference and reinforcement learning, and includes implementations of various supervised fine-tuning and RL methods for mathematics, coding, and general tasks. Code and Models: <a target="_blank" rel="noopener" href="https://github.com/Gen-Verse/dLLM-RL">https://github.com/Gen-Verse/dLLM-RL</a> </p>
<blockquote>
<p>æˆ‘ä»¬æå‡ºäº†TraceRLï¼Œè¿™æ˜¯ä¸€ä¸ªé¢å‘æ‰©æ•£è¯­è¨€æ¨¡å‹ï¼ˆDLMsï¼‰çš„è½¨è¿¹æ„ŸçŸ¥å¼ºåŒ–å­¦ä¹ æ¡†æ¶ã€‚è¯¥æ¡†æ¶åœ¨è®­ç»ƒåèå…¥äº†é¦–é€‰æ¨ç†è½¨è¿¹ï¼Œå¹¶é€‚ç”¨äºä¸åŒçš„æ¶æ„ã€‚é€šè¿‡ä½¿ç”¨åŸºäºæ‰©æ•£çš„å€¼æ¨¡å‹ï¼Œå¢å¼ºäº†è®­ç»ƒç¨³å®šæ€§ï¼Œå¹¶åœ¨å¤æ‚çš„æ•°å­¦å’Œç¼–ç ä»»åŠ¡ä¸Šå±•ç¤ºäº†æé«˜çš„æ¨ç†æ€§èƒ½ã€‚æ­¤å¤–ï¼Œå®ƒè¿˜å¯ä»¥åº”ç”¨äºå°†å—ç‰¹å®šæ¨¡å‹é€‚åº”åˆ°æ›´å¤§çš„å—ï¼Œè¿™æé«˜äº†é‡‡æ ·çµæ´»æ€§ã€‚ä½¿ç”¨TraceRLï¼Œæˆ‘ä»¬æ¨å‡ºäº†ä¸€ç³»åˆ—æœ€å…ˆè¿›çš„æ‰©æ•£è¯­è¨€æ¨¡å‹ï¼Œå³TraDoã€‚è™½ç„¶TraDo-4B-Instructçš„è§„æ¨¡å°äº7Bçº§ARæ¨¡å‹ï¼Œä½†åœ¨å¤æ‚çš„æ•°å­¦æ¨ç†ä»»åŠ¡ä¸Šä»ç„¶æŒç»­è¶…è¶Šå®ƒä»¬ã€‚TraDo-8B-Instructåœ¨æ•°å­¦æ¨ç†åŸºå‡†æµ‹è¯•ä¸Šç›¸å¯¹äºQwen2.5-7B-Instructå’ŒLlama3.1-8B-Instructåˆ†åˆ«å®ç°äº†6.1%å’Œ51.3%çš„ç›¸å¯¹å‡†ç¡®æ€§æ”¹è¿›ã€‚é€šè¿‡è¯¾ç¨‹å­¦ä¹ ï¼Œæˆ‘ä»¬è¿˜æ¨å‡ºäº†é¦–ä¸ªé•¿CoT DLMï¼Œåœ¨MATH500ä¸Šç›¸å¯¹äºQwen2.5-7B-Instructå®ç°äº†18.1%çš„ç›¸å¯¹å‡†ç¡®æ€§æå‡ã€‚ä¸ºäº†ä¿ƒè¿›å¯é‡å¤çš„ç ”ç©¶å’Œå®é™…åº”ç”¨ï¼Œæˆ‘ä»¬å‘å¸ƒäº†ä¸€ä¸ªå…¨é¢çš„å¼€æºæ¡†æ¶ï¼Œç”¨äºæ„å»ºã€è®­ç»ƒå’Œéƒ¨ç½²è·¨ä¸åŒæ¶æ„çš„æ‰©æ•£å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ã€‚è¯¥æ¡†æ¶é›†æˆäº†åŠ é€ŸKVç¼“å­˜æŠ€æœ¯å’Œæ¨ç†å¼•æ“ï¼Œç”¨äºæ¨ç†å’Œå¼ºåŒ–å­¦ä¹ ï¼Œå¹¶åŒ…æ‹¬é’ˆå¯¹æ•°å­¦ã€ç¼–ç å’Œä¸€èˆ¬ä»»åŠ¡çš„å¤šç§ç›‘ç£å¾®è°ƒï¼ˆfine-tuningï¼‰å’Œå¼ºåŒ–å­¦ä¹ æ–¹æ³•çš„å®ç°ã€‚ä»£ç å’Œæ¨¡å‹ï¼š<a target="_blank" rel="noopener" href="https://github.com/Gen-Verse/dLLM-RL%E3%80%82">https://github.com/Gen-Verse/dLLM-RLã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.06949v1">PDF</a> Code and Models: <a target="_blank" rel="noopener" href="https://github.com/Gen-Verse/dLLM-RL">https://github.com/Gen-Verse/dLLM-RL</a></p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†TraceRLæ¡†æ¶ï¼Œè¿™æ˜¯ä¸€ä¸ªä¸ºæ‰©æ•£è¯­è¨€æ¨¡å‹ï¼ˆDLMsï¼‰è®¾è®¡çš„è½¨è¿¹æ„ŸçŸ¥å¼ºåŒ–å­¦ä¹ æ¡†æ¶ã€‚TraceRLç»“åˆé¦–é€‰æ¨ç†è½¨è¿¹è¿›è¡Œåè®­ç»ƒï¼Œé€‚ç”¨äºä¸åŒçš„æ¶æ„ã€‚é€šè¿‡é…å¤‡åŸºäºæ‰©æ•£çš„å€¼æ¨¡å‹ï¼Œå¢å¼ºäº†è®­ç»ƒç¨³å®šæ€§ï¼Œå¹¶åœ¨å¤æ‚çš„æ•°å­¦å’Œç¼–ç ä»»åŠ¡ä¸Šå±•ç¤ºäº†æ”¹è¿›çš„æ¨ç†æ€§èƒ½ã€‚æ­¤å¤–ï¼Œå®ƒè¿˜å¯ä»¥åº”ç”¨äºé€‚åº”æ›´å¤§å—çš„å—ç‰¹å®šæ¨¡å‹ï¼Œæé«˜äº†é‡‡æ ·çµæ´»æ€§ã€‚ä½¿ç”¨TraceRLï¼Œæˆ‘ä»¬æ¨å‡ºäº†ä¸€ç³»åˆ—å…ˆè¿›çš„æ‰©æ•£è¯­è¨€æ¨¡å‹TraDoç³»åˆ—ã€‚å°½ç®¡è§„æ¨¡å°äº7Bçš„ARæ¨¡å‹ï¼ŒTraDo-4B-Instructåœ¨å¤æ‚çš„æ•°å­¦æ¨ç†ä»»åŠ¡ä¸Šä»è¡¨ç°ä¸€è‡´ä¸”æœ‰æ‰€è¶…è¶Šã€‚åŒæ—¶ï¼Œè¯¥æ¡†æ¶è¿˜åŒ…æ‹¬åŠ é€ŸKVç¼“å­˜æŠ€æœ¯å’Œæ¨ç†å¼•æ“çš„å®ç°ï¼Œç”¨äºæ¨ç†å’Œå¼ºåŒ–å­¦ä¹ ã€‚ä»£ç å’Œæ¨¡å‹å·²åœ¨GitHubä¸Šå¼€æºã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>TraceRLæ˜¯ä¸€ä¸ªè½¨è¿¹æ„ŸçŸ¥å¼ºåŒ–å­¦ä¹ æ¡†æ¶ï¼Œä¸“ä¸ºæ‰©æ•£è¯­è¨€æ¨¡å‹ï¼ˆDLMsï¼‰è®¾è®¡ï¼Œå¯åº”ç”¨äºä¸åŒæ¶æ„ã€‚</li>
<li>TraceRLç»“åˆé¦–é€‰æ¨ç†è½¨è¿¹è¿›è¡Œåè®­ç»ƒï¼Œå¢å¼ºäº†è®­ç»ƒç¨³å®šæ€§å’Œæ¨ç†æ€§èƒ½ã€‚</li>
<li>åœ¨å¤æ‚çš„æ•°å­¦å’Œç¼–ç ä»»åŠ¡ä¸Šï¼ŒTraceRLå±•ç¤ºäº†æ”¹è¿›çš„æ¨ç†æ€§èƒ½ã€‚</li>
<li>TraDoç³»åˆ—æ‰©æ•£è¯­è¨€æ¨¡å‹è¡¨ç°ä¼˜ç§€ï¼Œå…¶ä¸­TraDo-4B-Instructåœ¨å¤æ‚æ•°å­¦æ¨ç†ä»»åŠ¡ä¸Šè¡¨ç°è¶…è¶Šå…¶ä»–æ¨¡å‹ã€‚</li>
<li>TraDo-8B-Instructåœ¨æ•°å­¦æ¨ç†åŸºå‡†æµ‹è¯•ä¸Šç›¸å¯¹äºQwen2.5-7B-Instructå’ŒLlama3.1-8B-Instructæœ‰æ˜¾è‘—çš„å‡†ç¡®æ€§æ”¹è¿›ã€‚</li>
<li>é€šè¿‡è¯¾ç¨‹å­¦ä¹ ï¼Œæ¨å‡ºäº†é¦–ä¸ªé•¿CoTï¼ˆå› æœæ¨ç†é“¾ï¼‰DLMï¼Œåœ¨MATH500ä¸Šçš„ç›¸å¯¹å‡†ç¡®æ€§æœ‰æ‰€æé«˜ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.06949">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-6fa03797cae6bfb8dfce72cea9b2cc38.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-30b6fedca3fd8620a96e3852d223b52c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-336241c51df6935080eea3bc3de57383.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c29b0f436b40b28911b22bf67cd90fc8.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="Beyond-Two-Stage-Training-Cooperative-SFT-and-RL-for-LLM-Reasoning"><a href="#Beyond-Two-Stage-Training-Cooperative-SFT-and-RL-for-LLM-Reasoning" class="headerlink" title="Beyond Two-Stage Training: Cooperative SFT and RL for LLM Reasoning"></a>Beyond Two-Stage Training: Cooperative SFT and RL for LLM Reasoning</h2><p><strong>Authors:Liang Chen, Xueting Han, Li Shen, Jing Bai, Kam-Fai Wong</strong></p>
<p>Reinforcement learning (RL) has proven effective in incentivizing the reasoning abilities of large language models (LLMs), but suffers from severe efficiency challenges due to its trial-and-error nature. While the common practice employs supervised fine-tuning (SFT) as a warm-up stage for RL, this decoupled two-stage approach limits interaction between SFT and RL, thereby constraining overall effectiveness. This study introduces a novel method for learning reasoning models that employs bilevel optimization to facilitate better cooperation between these training paradigms. By conditioning the SFT objective on the optimal RL policy, our approach enables SFT to meta-learn how to guide RLâ€™s optimization process. During training, the lower level performs RL updates while simultaneously receiving SFT supervision, and the upper level explicitly maximizes the cooperative gain-the performance advantage of joint SFT-RL training over RL alone. Empirical evaluations on five reasoning benchmarks demonstrate that our method consistently outperforms baselines and achieves a better balance between effectiveness and efficiency. </p>
<blockquote>
<p>å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰åœ¨æ¿€åŠ±å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„æ¨ç†èƒ½åŠ›æ–¹é¢å·²è¯æ˜æ˜¯æœ‰æ•ˆçš„ï¼Œä½†ç”±äºå…¶è¯•é”™æ€§è´¨è€Œé¢ä¸´ä¸¥é‡çš„æ•ˆç‡æŒ‘æˆ˜ã€‚è™½ç„¶é€šå¸¸çš„åšæ³•æ˜¯é‡‡ç”¨ç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰ä½œä¸ºRLçš„é¢„çƒ­é˜¶æ®µï¼Œä½†è¿™ç§è§£è€¦çš„ä¸¤é˜¶æ®µæ–¹æ³•é™åˆ¶äº†SFTå’ŒRLä¹‹é—´çš„äº¤äº’ï¼Œä»è€Œé™åˆ¶äº†æ•´ä½“çš„æœ‰æ•ˆæ€§ã€‚æœ¬ç ”ç©¶ä»‹ç»äº†ä¸€ç§ç”¨äºå­¦ä¹ æ¨ç†æ¨¡å‹çš„æ–°æ–¹æ³•ï¼Œè¯¥æ–¹æ³•é‡‡ç”¨ä¸¤çº§ä¼˜åŒ–ï¼Œä»¥ä¿ƒè¿›è¿™äº›è®­ç»ƒèŒƒå¼ä¹‹é—´çš„æ›´å¥½åä½œã€‚é€šè¿‡ä»¥æœ€ä¼˜RLç­–ç•¥ä¸ºæ¡ä»¶ï¼Œæˆ‘ä»¬çš„æ–¹æ³•ä½¿SFTèƒ½å¤Ÿå…ƒå­¦ä¹ å¦‚ä½•å¼•å¯¼RLçš„ä¼˜åŒ–è¿‡ç¨‹ã€‚åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œä½çº§æ‰§è¡ŒRLæ›´æ–°ï¼ŒåŒæ—¶æ¥å—SFTç›‘ç£ï¼Œè€Œé«˜çº§åˆ™æ˜¾å¼åœ°æœ€å¤§åŒ–åˆä½œæ”¶ç›Šâ€”â€”è”åˆSFT-RLè®­ç»ƒç›¸å¯¹äºä»…ä½¿ç”¨RLçš„æ€§èƒ½ä¼˜åŠ¿ã€‚åœ¨äº”ä¸ªæ¨ç†åŸºå‡†æµ‹è¯•ä¸Šçš„å®è¯è¯„ä¼°è¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•å§‹ç»ˆä¼˜äºåŸºå‡†çº¿ï¼Œå¹¶åœ¨æœ‰æ•ˆæ€§å’Œæ•ˆç‡ä¹‹é—´å–å¾—äº†æ›´å¥½çš„å¹³è¡¡ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.06948v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰åœ¨æ¿€åŠ±å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„æ¨ç†èƒ½åŠ›æ–¹é¢å·²è¯æ˜å…¶æœ‰æ•ˆæ€§ï¼Œä½†ç”±äºå…¶å›ºæœ‰çš„è¯•é”™æ€§è´¨è€Œé¢ä¸´æ•ˆç‡æŒ‘æˆ˜ã€‚å¸¸è§åšæ³•æ˜¯é‡‡ç”¨ç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰ä½œä¸ºRLçš„é¢„çƒ­é˜¶æ®µï¼Œä½†è¿™ç§è§£è€¦çš„ä¸¤é˜¶æ®µæ–¹æ³•é™åˆ¶äº†SFTå’ŒRLä¹‹é—´çš„äº¤äº’ï¼Œä»è€Œé™åˆ¶äº†æ•´ä½“æ•ˆæœã€‚æœ¬ç ”ç©¶å¼•å…¥äº†ä¸€ç§æ–°çš„æ¨ç†æ¨¡å‹å­¦ä¹ æ–¹æ³•ï¼Œé‡‡ç”¨ä¸¤çº§ä¼˜åŒ–ï¼Œä»¥ä¿ƒè¿›è¿™ä¸¤ç§è®­ç»ƒèŒƒå¼ä¹‹é—´çš„æ›´å¥½åˆä½œã€‚é€šè¿‡ä»¥æœ€ä½³RLç­–ç•¥ä¸ºæ¡ä»¶ï¼Œæˆ‘ä»¬çš„æ–¹æ³•ä½¿SFTèƒ½å¤Ÿå­¦ä¹ å¦‚ä½•æŒ‡å¯¼RLçš„ä¼˜åŒ–è¿‡ç¨‹ã€‚åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œä½çº§æ‰§è¡ŒRLæ›´æ–°ï¼ŒåŒæ—¶æ¥å—SFTç›‘ç£ï¼Œè€Œé«˜çº§åˆ™æ˜ç¡®æœ€å¤§åŒ–åˆä½œæ”¶ç›Šâ€”â€”è”åˆSFT-RLè®­ç»ƒç›¸å¯¹äºä»…ä½¿ç”¨RLçš„æ€§èƒ½ä¼˜åŠ¿ã€‚åœ¨äº”ä¸ªæ¨ç†åŸºå‡†æµ‹è¯•ä¸Šçš„å®è¯è¯„ä¼°è¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•ä¸€ç›´ä¼˜äºåŸºå‡†æµ‹è¯•ï¼Œå¹¶åœ¨æœ‰æ•ˆæ€§å’Œæ•ˆç‡ä¹‹é—´å–å¾—äº†æ›´å¥½çš„å¹³è¡¡ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¼ºåŒ–å­¦ä¹ åœ¨æ¿€åŠ±å¤§å‹è¯­è¨€æ¨¡å‹çš„æ¨ç†èƒ½åŠ›æ–¹é¢æœ‰æ•ˆæœï¼Œä½†å­˜åœ¨æ•ˆç‡æŒ‘æˆ˜ã€‚</li>
<li>å¸¸è§åšæ³•é‡‡ç”¨ç›‘ç£å¾®è°ƒä½œä¸ºå¼ºåŒ–å­¦ä¹ çš„é¢„çƒ­é˜¶æ®µï¼Œä½†è¿™ç§æ–¹æ³•é™åˆ¶äº†äº¤äº’å’Œæ•´ä½“æ•ˆæœã€‚</li>
<li>æ–°æ–¹æ³•é‡‡ç”¨ä¸¤çº§ä¼˜åŒ–ï¼Œä¿ƒè¿›ç›‘ç£å¾®è°ƒä¸å¼ºåŒ–å­¦ä¹ ä¹‹é—´çš„åˆä½œã€‚</li>
<li>æ–°æ–¹æ³•ä½¿ç›‘ç£å¾®è°ƒèƒ½å¤Ÿå­¦ä¹ å¦‚ä½•æŒ‡å¯¼å¼ºåŒ–å­¦ä¹ çš„ä¼˜åŒ–è¿‡ç¨‹ã€‚</li>
<li>åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œæ–°æ–¹æ³•ç»“åˆäº†ç›‘ç£å¾®è°ƒå’Œå¼ºåŒ–å­¦ä¹ ï¼Œæé«˜äº†æ€§èƒ½ã€‚</li>
<li>å®è¯è¯„ä¼°è¡¨æ˜ï¼Œæ–°æ–¹æ³•åœ¨å¤šä¸ªæ¨ç†åŸºå‡†æµ‹è¯•ä¸Šè¡¨ç°ä¼˜å¼‚ï¼Œä¼˜äºä¼ ç»Ÿæ–¹æ³•ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.06948">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-2893830b7f14abd2e7ca17545c8ceed4.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-7450908b103e5cfe616090d68d5ecfce.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-23d60fd076127d0aaf3adf864b1c85f5.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-6c064df4739d0d12c3ba393217df7564.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="Interleaving-Reasoning-for-Better-Text-to-Image-Generation"><a href="#Interleaving-Reasoning-for-Better-Text-to-Image-Generation" class="headerlink" title="Interleaving Reasoning for Better Text-to-Image Generation"></a>Interleaving Reasoning for Better Text-to-Image Generation</h2><p><strong>Authors:Wenxuan Huang, Shuang Chen, Zheyong Xie, Shaosheng Cao, Shixiang Tang, Yufan Shen, Qingyu Yin, Wenbo Hu, Xiaoman Wang, Yuntian Tang, Junbo Qiao, Yue Guo, Yao Hu, Zhenfei Yin, Philip Torr, Yu Cheng, Wanli Ouyang, Shaohui Lin</strong></p>
<p>Unified multimodal understanding and generation models recently have achieve significant improvement in image generation capability, yet a large gap remains in instruction following and detail preservation compared to systems that tightly couple comprehension with generation such as GPT-4o. Motivated by recent advances in interleaving reasoning, we explore whether such reasoning can further improve Text-to-Image (T2I) generation. We introduce Interleaving Reasoning Generation (IRG), a framework that alternates between text-based thinking and image synthesis: the model first produces a text-based thinking to guide an initial image, then reflects on the result to refine fine-grained details, visual quality, and aesthetics while preserving semantics. To train IRG effectively, we propose Interleaving Reasoning Generation Learning (IRGL), which targets two sub-goals: (1) strengthening the initial think-and-generate stage to establish core content and base quality, and (2) enabling high-quality textual reflection and faithful implementation of those refinements in a subsequent image. We curate IRGL-300K, a dataset organized into six decomposed learning modes that jointly cover learning text-based thinking, and full thinking-image trajectories. Starting from a unified foundation model that natively emits interleaved text-image outputs, our two-stage training first builds robust thinking and reflection, then efficiently tunes the IRG pipeline in the full thinking-image trajectory data. Extensive experiments show SoTA performance, yielding absolute gains of 5-10 points on GenEval, WISE, TIIF, GenAI-Bench, and OneIG-EN, alongside substantial improvements in visual quality and fine-grained fidelity. The code, model weights and datasets will be released in: <a target="_blank" rel="noopener" href="https://github.com/Osilly/Interleaving-Reasoning-Generation">https://github.com/Osilly/Interleaving-Reasoning-Generation</a> . </p>
<blockquote>
<p>è¿‘æœŸç»Ÿä¸€çš„å¤šæ¨¡æ€ç†è§£å’Œç”Ÿæˆæ¨¡å‹åœ¨å›¾åƒç”Ÿæˆèƒ½åŠ›ä¸Šå–å¾—äº†æ˜¾è‘—è¿›æ­¥ï¼Œä½†åœ¨æŒ‡ä»¤éµå¾ªå’Œç»†èŠ‚ä¿ç•™æ–¹é¢ï¼Œä¸ç´§å¯†è€¦åˆç†è§£ä¸ç”Ÿæˆçš„ç³»ç»Ÿï¼ˆå¦‚GPT-4oï¼‰ç›¸æ¯”ä»å­˜åœ¨è¾ƒå¤§å·®è·ã€‚å—åˆ°äº¤æ›¿æ¨ç†æœ€æ–°è¿›å±•çš„å¯å‘ï¼Œæˆ‘ä»¬æ¢ç´¢äº†è¿™ç§æ¨ç†æ˜¯å¦èƒ½è¿›ä¸€æ­¥æ”¹è¿›æ–‡æœ¬åˆ°å›¾åƒï¼ˆT2Iï¼‰çš„ç”Ÿæˆã€‚æˆ‘ä»¬å¼•å…¥äº†äº¤æ›¿æ¨ç†ç”Ÿæˆï¼ˆIRGï¼‰æ¡†æ¶ï¼Œè¯¥æ¡†æ¶åœ¨æ–‡æœ¬æ€è€ƒå’Œå›¾åƒåˆæˆä¹‹é—´è¿›è¡Œäº¤æ›¿ï¼šæ¨¡å‹é¦–å…ˆäº§ç”ŸåŸºäºæ–‡æœ¬çš„æ€è€ƒæ¥æŒ‡å¯¼åˆå§‹å›¾åƒï¼Œç„¶ååæ€ç»“æœï¼Œä»¥ç»†åŒ–ç»†èŠ‚ã€è§†è§‰è´¨é‡å’Œç¾å­¦æ„Ÿï¼ŒåŒæ—¶ä¿ç•™è¯­ä¹‰ã€‚ä¸ºäº†æœ‰æ•ˆåœ°è®­ç»ƒIRGï¼Œæˆ‘ä»¬æå‡ºäº†äº¤æ›¿æ¨ç†ç”Ÿæˆå­¦ä¹ ï¼ˆIRGLï¼‰ï¼Œå®ƒé’ˆå¯¹ä¸¤ä¸ªå­ç›®æ ‡ï¼šï¼ˆ1ï¼‰åŠ å¼ºåˆå§‹çš„æ€è€ƒå’Œç”Ÿæˆé˜¶æ®µï¼Œä»¥å»ºç«‹æ ¸å¿ƒå†…å®¹å’ŒåŸºç¡€è´¨é‡ï¼›ï¼ˆ2ï¼‰å®ç°é«˜è´¨é‡æ–‡æœ¬åæ€å’Œå¿ å®æ‰§è¡Œéšåçš„å›¾åƒä¸­çš„æ”¹è¿›ã€‚æˆ‘ä»¬ç­–åˆ’äº†IRGL-300Kæ•°æ®é›†ï¼Œè¯¥æ•°æ®é›†è¢«ç»„ç»‡æˆå…­ç§åˆ†è§£å­¦ä¹ æ¨¡å¼ï¼Œè”åˆè¦†ç›–åŸºäºæ–‡æœ¬çš„æ€è€ƒå’Œå®Œæ•´çš„æ€è€ƒ-å›¾åƒè½¨è¿¹ã€‚ä»ç»Ÿä¸€çš„åŸºç¡€æ¨¡å‹å‡ºå‘ï¼Œè¯¥æ¨¡å‹å¤©ç”Ÿå°±èƒ½å‘å‡ºäº¤æ›¿çš„æ–‡æœ¬-å›¾åƒè¾“å‡ºï¼Œæˆ‘ä»¬çš„ä¸¤é˜¶æ®µè®­ç»ƒé¦–å…ˆå»ºç«‹ç¨³å¥çš„æ€è€ƒå’Œåæ€èƒ½åŠ›ï¼Œç„¶ååœ¨å®Œæ•´çš„æ€è€ƒ-å›¾åƒè½¨è¿¹æ•°æ®ä¸­æœ‰æ•ˆåœ°è°ƒæ•´IRGç®¡é“ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼Œå…¶æ€§èƒ½è¾¾åˆ°äº†æœ€æ–°æ°´å¹³ï¼Œåœ¨GenEvalã€WISEã€TIIFã€GenAI-Benchå’ŒOneIG-ENä¸Šå®ç°äº†5-10åˆ†çš„ç»å¯¹å¢é•¿ï¼ŒåŒæ—¶åœ¨è§†è§‰è´¨é‡å’Œç»†èŠ‚ä¿çœŸåº¦æ–¹é¢ä¹Ÿæœ‰äº†å®è´¨æ€§çš„æå‡ã€‚ä»£ç ã€æ¨¡å‹æƒé‡å’Œæ•°æ®é›†å°†åœ¨<a target="_blank" rel="noopener" href="https://github.com/Osilly/Interleaving-Reasoning-Generation%E4%B8%AD%E5%8F%91%E5%B8%83%E3%80%82">https://github.com/Osilly/Interleaving-Reasoning-Generationä¸­å‘å¸ƒã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.06945v1">PDF</a> </p>
<p><strong>Summary</strong><br>    è¿‘æœŸç»Ÿä¸€çš„å¤šæ¨¡æ€ç†è§£ä¸ç”Ÿæˆæ¨¡å‹åœ¨å›¾åƒç”Ÿæˆèƒ½åŠ›ä¸Šå–å¾—æ˜¾è‘—è¿›æ­¥ï¼Œä½†åœ¨æŒ‡ä»¤éµå¾ªä¸ç»†èŠ‚ä¿ç•™æ–¹é¢ä¸ç´§å¯†è€¦åˆç†è§£ä¸ç”Ÿæˆçš„ç³»ç»Ÿå¦‚GPT-4oç›¸æ¯”ä»å­˜åœ¨è¾ƒå¤§å·®è·ã€‚å—äº¤æ›¿æ¨ç†æœ€æ–°è¿›å±•çš„å¯å‘ï¼Œæœ¬æ–‡æ¢ç´¢äº†äº¤æ›¿æ¨ç†æ˜¯å¦èƒ½è¿›ä¸€æ­¥æ”¹è¿›æ–‡æœ¬åˆ°å›¾åƒï¼ˆT2Iï¼‰çš„ç”Ÿæˆã€‚ä»‹ç»äº†ä¸€ç§äº¤æ›¿æ¨ç†ç”Ÿæˆï¼ˆIRGï¼‰æ¡†æ¶ï¼Œè¯¥æ¡†æ¶åœ¨æ–‡æœ¬åŸºç¡€æ€è€ƒå’Œå›¾åƒåˆæˆä¹‹é—´äº¤æ›¿ï¼šæ¨¡å‹é¦–å…ˆäº§ç”Ÿæ–‡æœ¬åŸºç¡€æ€è€ƒæ¥æŒ‡å¯¼åˆå§‹å›¾åƒï¼Œç„¶ååæ€ç»“æœä»¥æ”¹è¿›ç»†èŠ‚ã€è§†è§‰è´¨é‡å’Œç¾å­¦æ„Ÿï¼ŒåŒæ—¶ä¿ç•™è¯­ä¹‰ã€‚ä¸ºäº†æœ‰æ•ˆåœ°è®­ç»ƒIRGï¼Œæå‡ºäº†äº¤æ›¿æ¨ç†ç”Ÿæˆå­¦ä¹ ï¼ˆIRGLï¼‰ï¼Œæ—¨åœ¨å®ç°ä¸¤ä¸ªå­ç›®æ ‡ï¼šä¸€æ˜¯åŠ å¼ºåˆå§‹çš„æ€è€ƒå’Œç”Ÿæˆé˜¶æ®µï¼Œä»¥å»ºç«‹æ ¸å¿ƒå†…å®¹å’ŒåŸºç¡€è´¨é‡ï¼›äºŒæ˜¯å®ç°é«˜è´¨é‡æ–‡æœ¬åæ€å’Œå¿ å®å®æ–½è¿™äº›æ”¹è¿›äºéšåçš„å›¾åƒã€‚æœ¬æ–‡æ•´ç†äº†IRGL-300Kæ•°æ®é›†ï¼ŒåŒ…å«å…­ç§åˆ†è§£å­¦ä¹ æ¨¡å¼ï¼Œä»¥æ¶µç›–æ–‡æœ¬åŸºç¡€æ€è€ƒå’Œå®Œæ•´æ€è€ƒå›¾åƒè½¨è¿¹çš„å­¦ä¹ ã€‚ä»ç»Ÿä¸€çš„åŸºç¡€æ¨¡å‹å‡ºå‘ï¼Œè¯¥æ¨¡å‹å¤©ç”Ÿå°±èƒ½å‘å‡ºäº¤æ›¿çš„æ–‡æœ¬å›¾åƒè¾“å‡ºï¼Œä¸¤é˜¶æ®µè®­ç»ƒé¦–å…ˆå»ºç«‹ç¨³å¥çš„æ€è€ƒå’Œåæ€ï¼Œç„¶åæœ‰æ•ˆåœ°è°ƒæ•´IRGç®¡é“åœ¨å®Œæ•´çš„æ€è€ƒå›¾åƒè½¨è¿¹æ•°æ®ä¸­ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼Œå…¶åœ¨GenEvalã€WISEã€TIIFã€GenAI-Benchå’ŒOneIG-ENç­‰æŒ‡æ ‡ä¸Šè¾¾åˆ°äº†SOTAæ€§èƒ½ï¼Œä¸”è·å¾—äº†å®è´¨æ€§çš„è§†è§‰è´¨é‡å’Œç²¾ç»†ç²’åº¦ä¿çœŸåº¦çš„æå‡ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ç ”ç©¶æå‡ºäº†ä¸€ç§æ–°çš„æ¡†æ¶â€”â€”äº¤æ›¿æ¨ç†ç”Ÿæˆï¼ˆIRGï¼‰ï¼Œæ—¨åœ¨é€šè¿‡æ–‡æœ¬åŸºç¡€æ€è€ƒå’Œå›¾åƒåˆæˆä¹‹é—´çš„äº¤æ›¿è¿‡ç¨‹æ”¹è¿›æ–‡æœ¬åˆ°å›¾åƒçš„ç”Ÿæˆã€‚</li>
<li>ä¸ºäº†è®­ç»ƒIRGï¼Œç ”ç©¶è€…æå‡ºäº†äº¤æ›¿æ¨ç†ç”Ÿæˆå­¦ä¹ ï¼ˆIRGLï¼‰æ–¹æ³•ï¼ŒåŒ…å«ä¸¤ä¸ªå­ç›®æ ‡ï¼šå»ºç«‹æ ¸å¿ƒå†…å®¹å’ŒåŸºç¡€è´¨é‡ï¼Œä»¥åŠå®ç°é«˜è´¨é‡çš„æ–‡æœ¬åæ€å’Œæ”¹è¿›å›¾åƒç»†èŠ‚ã€‚</li>
<li>ç ”ç©¶è€…æ•´ç†äº†ä¸€ä¸ªåä¸ºIRGL-300Kçš„æ•°æ®é›†ï¼Œç”¨äºæ”¯æŒIRGæ¡†æ¶çš„è®­ç»ƒå’Œè¯„ä¼°ï¼Œè¯¥æ•°æ®é›†åŒ…å«å…­ç§åˆ†è§£å­¦ä¹ æ¨¡å¼ã€‚</li>
<li>å®éªŒç»“æœè¡¨æ˜ï¼ŒIRGæ¡†æ¶åœ¨å¤šä¸ªè¯„ä¼°æŒ‡æ ‡ä¸Šè¾¾åˆ°äº†å…ˆè¿›æ€§èƒ½ï¼ŒåŒ…æ‹¬GenEvalã€WISEã€TIIFã€GenAI-Benchå’ŒOneIG-ENç­‰ã€‚</li>
<li>è¯¥ç ”ç©¶æé«˜äº†å›¾åƒç”Ÿæˆçš„è§†è§‰è´¨é‡å’Œç²¾ç»†ç²’åº¦ä¿çœŸåº¦ã€‚</li>
<li>æ¨¡å‹å’Œä»£ç å°†åœ¨æŒ‡å®šçš„GitHubä»“åº“ä¸­å…¬å¼€ï¼Œä¾¿äºå…¶ä»–äººä½¿ç”¨å’Œæ”¹è¿›ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.06945">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-d40c89c768fd0600c950e038c8912c9a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-bbd420ded6f2c6602b63ad3665af53c5.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-0176ffc2f991189ccd2a73cacf1dffc8.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="Staying-in-the-Sweet-Spot-Responsive-Reasoning-Evolution-via-Capability-Adaptive-Hint-Scaffolding"><a href="#Staying-in-the-Sweet-Spot-Responsive-Reasoning-Evolution-via-Capability-Adaptive-Hint-Scaffolding" class="headerlink" title="Staying in the Sweet Spot: Responsive Reasoning Evolution via   Capability-Adaptive Hint Scaffolding"></a>Staying in the Sweet Spot: Responsive Reasoning Evolution via   Capability-Adaptive Hint Scaffolding</h2><p><strong>Authors:Ziheng Li, Zexu Sun, Jinman Zhao, Erxue Min, Yongcheng Zeng, Hui Wu, Hengyi Cai, Shuaiqiang Wang, Dawei Yin, Xu Chen, Zhi-Hong Deng</strong></p>
<p>Reinforcement learning with verifiable rewards (RLVR) has achieved remarkable success in enhancing the reasoning capabilities of large language models (LLMs). However, existing RLVR methods often suffer from exploration inefficiency due to mismatches between the training dataâ€™s difficulty and the modelâ€™s capability. LLMs fail to discover viable reasoning paths when problems are overly difficult, while learning little new capability when problems are too simple. In this work, we formalize the impact of problem difficulty by quantifying the relationship between loss descent speed and rollout accuracy. Building on this analysis, we propose SEELE, a novel supervision-aided RLVR framework that dynamically adjusts problem difficulty to stay within the high-efficiency region. SEELE augments each training sample by appending a hint (part of a full solution) after the original problem. Unlike previous hint-based approaches, SEELE deliberately and adaptively adjusts the hint length for each problem to achieve an optimal difficulty. To determine the optimal hint length, SEELE employs a multi-round rollout sampling strategy. In each round, it fits an item response theory model to the accuracy-hint pairs collected in preceding rounds to predict the required hint length for the next round. This instance-level, real-time difficulty adjustment aligns problem difficulty with the evolving model capability, thereby improving exploration efficiency. Experimental results show that SEELE outperforms Group Relative Policy Optimization (GRPO) and Supervised Fine-tuning (SFT) by +11.8 and +10.5 points, respectively, and surpasses the best previous supervision-aided approach by +3.6 points on average across six math reasoning benchmarks. </p>
<blockquote>
<p>å¼ºåŒ–å­¦ä¹ ä¸å¯éªŒè¯å¥–åŠ±ï¼ˆRLVRï¼‰åœ¨æé«˜å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„æ¨ç†èƒ½åŠ›æ–¹é¢å–å¾—äº†æ˜¾è‘—çš„æˆåŠŸã€‚ç„¶è€Œï¼Œç°æœ‰çš„RLVRæ–¹æ³•å¸¸å¸¸å› ä¸ºè®­ç»ƒæ•°æ®éš¾åº¦ä¸æ¨¡å‹èƒ½åŠ›ä¹‹é—´çš„ä¸åŒ¹é…è€Œé¢ä¸´æ¢ç´¢æ•ˆç‡ä½ä¸‹çš„é—®é¢˜ã€‚å½“é—®é¢˜è¿‡äºå›°éš¾æ—¶ï¼ŒLLMæ— æ³•å‘ç°å¯è¡Œçš„æ¨ç†è·¯å¾„ï¼Œè€Œå½“é—®é¢˜è¿‡äºç®€å•æ—¶ï¼Œå®ƒä»¬åˆæ— æ³•å­¦ä¹ åˆ°æ–°çš„èƒ½åŠ›ã€‚</p>
</blockquote>
<p>åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬é€šè¿‡é‡åŒ–æŸå¤±ä¸‹é™é€Ÿåº¦ä¸å›æ»šå‡†ç¡®åº¦ä¹‹é—´çš„å…³ç³»æ¥æ­£å¼åŒ–é—®é¢˜éš¾åº¦çš„å½±å“ã€‚åŸºäºè¿™ä¸€åˆ†æï¼Œæˆ‘ä»¬æå‡ºäº†SEELEï¼Œä¸€ä¸ªæ–°å‹çš„ç›‘ç£è¾…åŠ©RLVRæ¡†æ¶ï¼Œå®ƒèƒ½å¤ŸåŠ¨æ€è°ƒæ•´é—®é¢˜éš¾åº¦ä»¥ä¿æŒåœ¨é«˜æ•ˆç‡åŒºåŸŸå†…ã€‚SEELEé€šè¿‡åœ¨æ¯ä¸ªè®­ç»ƒæ ·æœ¬åé™„åŠ ä¸€ä¸ªæç¤ºï¼ˆå®Œæ•´è§£å†³æ–¹æ¡ˆçš„ä¸€éƒ¨åˆ†ï¼‰æ¥å¢å¼ºæ¯ä¸ªè®­ç»ƒæ ·æœ¬ã€‚ä¸åŒäºä»¥å‰çš„åŸºäºæç¤ºçš„æ–¹æ³•ï¼ŒSEELEä¸ºæ¯ä¸ªé—®é¢˜ç²¾å¿ƒä¸”è‡ªé€‚åº”åœ°è°ƒæ•´æç¤ºé•¿åº¦ä»¥è¾¾åˆ°æœ€ä½³éš¾åº¦ã€‚</p>
<p>ä¸ºäº†ç¡®å®šæœ€ä½³æç¤ºé•¿åº¦ï¼ŒSEELEé‡‡ç”¨å¤šè½®å›æ»šé‡‡æ ·ç­–ç•¥ã€‚åœ¨æ¯è½®ä¸­ï¼Œå®ƒæ ¹æ®å‰å‡ è½®æ”¶é›†çš„å‡†ç¡®åº¦æç¤ºå¯¹æ¥æ‹Ÿåˆé¡¹ç›®ååº”ç†è®ºæ¨¡å‹ï¼Œä»¥é¢„æµ‹ä¸‹ä¸€è½®æ‰€éœ€çš„æç¤ºé•¿åº¦ã€‚è¿™ç§å®ä¾‹çº§åˆ«çš„å®æ—¶éš¾åº¦è°ƒæ•´ä½¿é—®é¢˜éš¾åº¦ä¸ä¸æ–­è¿›åŒ–çš„æ¨¡å‹èƒ½åŠ›ç›¸åŒ¹é…ï¼Œä»è€Œæé«˜äº†æ¢ç´¢æ•ˆç‡ã€‚</p>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.06923v1">PDF</a> Work in progress</p>
<p><strong>æ‘˜è¦</strong></p>
<p>å¼ºåŒ–å­¦ä¹ ä¸å¯éªŒè¯å¥–åŠ±ï¼ˆRLVRï¼‰åœ¨æé«˜å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„æ¨ç†èƒ½åŠ›æ–¹é¢å–å¾—äº†æ˜¾è‘—çš„æˆåŠŸã€‚ç„¶è€Œï¼Œç°æœ‰RLVRæ–¹æ³•å¸¸å¸¸å› è®­ç»ƒæ•°æ®éš¾åº¦ä¸æ¨¡å‹èƒ½åŠ›ä¹‹é—´çš„ä¸åŒ¹é…è€Œå¯¼è‡´æ¢ç´¢æ•ˆç‡ä½ä¸‹ã€‚å½“é—®é¢˜è¿‡äºå›°éš¾æ—¶ï¼ŒLLMæ— æ³•å‘ç°å¯è¡Œçš„æ¨ç†è·¯å¾„ï¼›è€Œå½“é—®é¢˜è¿‡äºç®€å•æ—¶ï¼Œå®ƒä»¬åˆæ— æ³•å­¦ä¹ åˆ°æ–°çš„èƒ½åŠ›ã€‚æœ¬ç ”ç©¶é€šè¿‡é‡åŒ–æŸå¤±ä¸‹é™é€Ÿåº¦ä¸å›æ»šå‡†ç¡®åº¦ä¹‹é—´çš„å…³ç³»ï¼Œæ­£å¼åŒ–é—®é¢˜éš¾åº¦çš„å½±å“ã€‚åœ¨æ­¤åŸºç¡€ä¸Šï¼Œæˆ‘ä»¬æå‡ºäº†SEELEï¼Œä¸€ä¸ªæ–°å‹çš„ç›‘ç£è¾…åŠ©RLVRæ¡†æ¶ï¼Œèƒ½å¤ŸåŠ¨æ€è°ƒæ•´é—®é¢˜éš¾åº¦ä»¥ä¿æŒåœ¨é«˜æ•ˆåŒºåŸŸã€‚SEELEé€šè¿‡åœ¨æ¯ä¸ªè®­ç»ƒæ ·æœ¬åè¿½åŠ æç¤ºï¼ˆå®Œæ•´è§£å†³æ–¹æ¡ˆçš„ä¸€éƒ¨åˆ†ï¼‰æ¥å¢å¼ºæ•°æ®ã€‚ä¸å…¶ä»–åŸºäºæç¤ºçš„æ–¹æ³•ä¸åŒï¼ŒSEELEä¸ºæ¯ä¸ªé—®é¢˜ç²¾å¿ƒã€è‡ªé€‚åº”åœ°è°ƒæ•´æç¤ºé•¿åº¦ä»¥è¾¾åˆ°æœ€ä½³éš¾åº¦ã€‚ä¸ºäº†ç¡®å®šæœ€ä½³æç¤ºé•¿åº¦ï¼ŒSEELEé‡‡ç”¨å¤šè½®å›æ»šé‡‡æ ·ç­–ç•¥ã€‚æ¯è½®ä¸­ï¼Œå®ƒæ ¹æ®å…ˆå‰è½®æ¬¡æ”¶é›†çš„å‡†ç¡®åº¦å’Œæç¤ºå¯¹æ¥æ‹Ÿåˆé¡¹ç›®ååº”ç†è®ºæ¨¡å‹ï¼Œä»¥é¢„æµ‹ä¸‹ä¸€è½®çš„æ‰€éœ€æç¤ºé•¿åº¦ã€‚è¿™ç§å®ä¾‹çº§åˆ«çš„å®æ—¶éš¾åº¦è°ƒæ•´ä½¿é—®é¢˜éš¾åº¦ä¸ä¸æ–­è¿›åŒ–çš„æ¨¡å‹èƒ½åŠ›ç›¸åŒ¹é…ï¼Œæé«˜äº†æ¢ç´¢æ•ˆç‡ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒSEELEåœ¨å…­ä¸ªæ•°å­¦æ¨ç†åŸºå‡†æµ‹è¯•ä¸Šçš„è¡¨ç°ä¼˜äºé›†å›¢ç›¸å¯¹æ”¿ç­–ä¼˜åŒ–ï¼ˆGRPOï¼‰å’Œç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰åˆ†åˆ«ä¸º+11.8å’Œ+10.5ç‚¹ï¼Œå¹¶å¹³å‡è¶…è¿‡äº†æœ€ä½³ç›‘ç£è¾…åŠ©æ–¹æ³•+3.6ç‚¹ã€‚</p>
<p><strong>å…³é”®è§è§£</strong></p>
<ol>
<li>RLVRåœ¨å¢å¼ºLLMæ¨ç†èƒ½åŠ›æ–¹é¢å–å¾—æ˜¾è‘—æˆåŠŸï¼Œä½†å­˜åœ¨æ¢ç´¢æ•ˆç‡ä½ä¸‹çš„é—®é¢˜ã€‚</li>
<li>é—®é¢˜éš¾åº¦ä¸æ¨¡å‹èƒ½åŠ›ä¹‹é—´çš„ä¸åŒ¹é…æ˜¯æ¢ç´¢æ•ˆç‡ä½ä¸‹çš„ä¸»è¦åŸå› ã€‚</li>
<li>SEELEé€šè¿‡åŠ¨æ€è°ƒæ•´é—®é¢˜éš¾åº¦æ¥æé«˜æ¢ç´¢æ•ˆç‡ã€‚</li>
<li>SEELEé€šè¿‡è¿½åŠ æç¤ºæ¥å¢å¼ºè®­ç»ƒæ•°æ®ï¼Œå¹¶è‡ªé€‚åº”åœ°è°ƒæ•´æ¯ä¸ªé—®é¢˜çš„æç¤ºé•¿åº¦ã€‚</li>
<li>SEELEé‡‡ç”¨å¤šè½®å›æ»šé‡‡æ ·ç­–ç•¥æ¥ç¡®å®šæœ€ä½³æç¤ºé•¿åº¦ã€‚</li>
<li>SEELEå®æ—¶è°ƒæ•´é—®é¢˜éš¾åº¦ï¼Œä»¥ä¸æ¨¡å‹èƒ½åŠ›çš„è¿›åŒ–ç›¸åŒ¹é…ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.06923">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-63b1003145d116a08c96c12255b03fad.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-dbb22b2ee151451b2debcfc338c9ac75.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d25be95785455750f74d4428043d5415.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a7a89fe1be3e90617108a1d248227e73.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="Mechanized-Metatheory-of-Forward-Reasoning-for-End-to-End-Linearizability-Proofs"><a href="#Mechanized-Metatheory-of-Forward-Reasoning-for-End-to-End-Linearizability-Proofs" class="headerlink" title="Mechanized Metatheory of Forward Reasoning for End-to-End   Linearizability Proofs"></a>Mechanized Metatheory of Forward Reasoning for End-to-End   Linearizability Proofs</h2><p><strong>Authors:Zachary Kent, Ugur Y. Yavuz, Siddhartha Jayanti, Stephanie Balzer, Guy Blelloch</strong></p>
<p>In the past decade, many techniques have been developed to prove linearizability, the gold standard of correctness for concurrent data structures. Intuitively, linearizability requires that every operation on a concurrent data structure appears to take place instantaneously, even when interleaved with other operations. Most recently, Jayanti et al. presented the first sound and complete â€œforward reasoningâ€ technique for proving linearizability that relates the behavior of a concurrent data structure to a reference atomic data structure as time moves forward. This technique can be used to produce machine-checked proofs of linearizability in TLA+. However, while Jayanti et al.â€™s approach is shown to be sound and complete, a mechanization of this important metatheoretic result is still outstanding. As a result, it is not possible to produce verified end-to-end proofs of linearizability. To reduce the size of this trusted computing base, we formalize this forward reasoning technique and mechanize proofs of its soundness and completeness in Rocq. As a case study, we use the approach to produce a verified end-to-end proof of linearizability for a simple concurrent register. </p>
<blockquote>
<p>åœ¨è¿‡å»çš„åå¹´é‡Œï¼Œä¸ºäº†è¯æ˜çº¿æ€§åŒ–ï¼ˆå¹¶å‘æ•°æ®ç»“æ„æ­£ç¡®æ€§çš„é‡‘æ ‡å‡†ï¼‰å·²ç»å¼€å‘äº†è®¸å¤šæŠ€æœ¯ã€‚ç›´è§‚åœ°ï¼Œçº¿æ€§åŒ–è¦æ±‚å³ä½¿åœ¨ä¸å…¶ä»–æ“ä½œäº¤é”™çš„æƒ…å†µä¸‹ï¼Œå¹¶å‘æ•°æ®ç»“æ„ä¸Šçš„æ¯ä¸ªæ“ä½œä¹Ÿä¼¼ä¹éƒ½æ˜¯ç¬é—´å®Œæˆçš„ã€‚æœ€è¿‘ï¼ŒJayantiç­‰äººæå‡ºäº†ä¸€ç§æ–°çš„çº¿æ€§åŒ–è¯æ˜æ–¹æ³•ï¼Œå³é¦–æ¬¡å®Œå–„ä¸”åˆç†çš„â€œå‘å‰æ¨ç†â€æŠ€æœ¯ï¼Œè¯¥æŠ€æœ¯å°†å¹¶å‘æ•°æ®ç»“æ„çš„è¡Œä¸ºä¸æ—¶é—´å‰è¿›æ—¶çš„å‚è€ƒåŸå­æ•°æ®ç»“æ„å…³è”èµ·æ¥ã€‚æ­¤æŠ€æœ¯å¯ç”¨äºåœ¨TLA+ä¸­äº§ç”Ÿæœºå™¨éªŒè¯çš„çº¿æ€§åŒ–è¯æ˜ã€‚ç„¶è€Œï¼Œè™½ç„¶Jayantiç­‰äººçš„æ–¹æ³•è¢«è¯æ˜æ˜¯åˆç†ä¸”å®Œæ•´çš„ï¼Œä½†è¿™ä¸€é‡è¦çš„å…ƒç†è®ºç»“æœçš„æœºæ¢°åŒ–ä»ç„¶æ˜¯ä¸€ä¸ªæ‚¬è€Œæœªå†³çš„é—®é¢˜ã€‚å› æ­¤ï¼Œæ— æ³•ç”Ÿæˆç«¯åˆ°ç«¯çš„çº¿æ€§åŒ–éªŒè¯è¯æ˜ã€‚ä¸ºäº†å‡å°å¯ä¿¡è®¡ç®—åŸºçš„å¤§å°ï¼Œæˆ‘ä»¬åœ¨Rocqä¸­æ­£å¼åˆ¶å®šäº†è¿™ç§å‘å‰æ¨ç†æŠ€æœ¯ï¼Œå¹¶å¯¹å…¶åˆç†æ€§å’Œå®Œæ•´æ€§è¿›è¡Œäº†æœºæ¢°åŒ–è¯æ˜ã€‚ä½œä¸ºæ¡ˆä¾‹ç ”ç©¶ï¼Œæˆ‘ä»¬ä½¿ç”¨è¯¥æ–¹æ³•ä¸ºç®€å•çš„å¹¶å‘å¯„å­˜å™¨ç”Ÿæˆäº†ç«¯åˆ°ç«¯çš„çº¿æ€§åŒ–éªŒè¯è¯æ˜ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.06872v1">PDF</a> </p>
<p><strong>Summary</strong><br>     è¿‘åå¹´æ¥ï¼Œä¸ºè¯æ˜å¹¶å‘æ•°æ®ç»“æ„çš„æ­£ç¡®æ€§æ ‡å‡†â€”â€”çº¿æ€§åŒ–ï¼Œå·²å¼€å‘äº†è®¸å¤šæŠ€æœ¯ã€‚æœ€è¿‘ï¼ŒJayantiç­‰äººæå‡ºäº†é¦–ä¸ªå®Œå–„çš„â€œå‘å‰æ¨ç†â€æŠ€æœ¯ï¼Œè¯¥æŠ€æœ¯å¯å°†å¹¶å‘æ•°æ®ç»“æ„çš„è¡Œä¸ºä¸æ—¶é—´å‰è¿›æ—¶çš„å‚è€ƒåŸå­æ•°æ®ç»“æ„å…³è”èµ·æ¥ã€‚ç„¶è€Œï¼Œå°½ç®¡Jayantiç­‰äººçš„æ–¹æ³•æ˜¯å®Œå–„å’Œå…¨é¢çš„ï¼Œä½†å…¶æœºæ¢°åŒ–å®ç°ä»å¾…å®Œå–„ã€‚å› æ­¤ï¼Œæ— æ³•ç”Ÿæˆç«¯åˆ°ç«¯çš„çº¿æ€§åŒ–è¯æ˜ã€‚ä¸ºå‡å°‘å¯ä¿¡è®¡ç®—åŸºæ•°çš„å¤§å°ï¼Œæˆ‘ä»¬åœ¨Rocqä¸­å½¢å¼åŒ–è¿™ç§å‘å‰æ¨ç†æŠ€æœ¯å¹¶æœºæ¢°åŒ–è¯æ˜å…¶æ­£ç¡®æ€§å’Œå®Œæ•´æ€§ã€‚ä½œä¸ºæ¡ˆä¾‹ç ”ç©¶ï¼Œæˆ‘ä»¬ä½¿ç”¨è¯¥æ–¹æ³•ä¸ºç®€å•çš„å¹¶å‘å¯„å­˜å™¨ç”Ÿæˆç«¯åˆ°ç«¯çš„çº¿æ€§åŒ–è¯æ˜ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>è¿‘åå¹´å¼€å‘äº†å¤šç§è¯æ˜å¹¶å‘æ•°æ®ç»“æ„çº¿æ€§åŒ–çš„æŠ€æœ¯ã€‚</li>
<li>çº¿æ€§åŒ–è¦æ±‚å¹¶å‘æ•°æ®ç»“æ„çš„æ“ä½œçœ‹èµ·æ¥æ˜¯ç¬é—´å®Œæˆçš„ï¼Œå³ä½¿ä¸å…¶ä»–æ“ä½œäº¤ç»‡åœ¨ä¸€èµ·ã€‚</li>
<li>Jayantiç­‰äººæå‡ºäº†é¦–ä¸ªå®Œå–„çš„â€œå‘å‰æ¨ç†â€æŠ€æœ¯ï¼Œè¯¥æŠ€æœ¯èƒ½å°†å¹¶å‘æ•°æ®ç»“æ„çš„è¡Œä¸ºä¸å‚è€ƒåŸå­æ•°æ®ç»“æ„å…³è”èµ·æ¥ã€‚</li>
<li>è¯¥æŠ€æœ¯å¯ç”¨äºåœ¨TLA+ä¸­ç”Ÿæˆæœºå™¨éªŒè¯çš„çº¿æ€§åŒ–è¯æ˜ã€‚</li>
<li>å°½ç®¡Jayantiç­‰äººçš„æ–¹æ³•ç»è¿‡éªŒè¯æ˜¯å®Œå–„å’Œå…¨é¢çš„ï¼Œä½†å…¶æœºæ¢°åŒ–å®ç°å°šæœªå®Œæˆã€‚</li>
<li>æ— æ³•ä½¿ç”¨å½“å‰æŠ€æœ¯ç”Ÿæˆç«¯åˆ°ç«¯çš„çº¿æ€§åŒ–è¯æ˜ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.06872">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-418ca66b99cb28c75121b06e4a84484e.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-6db816ae16782c6d4723509061bfc025.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="The-Majority-is-not-always-right-RL-training-for-solution-aggregation"><a href="#The-Majority-is-not-always-right-RL-training-for-solution-aggregation" class="headerlink" title="The Majority is not always right: RL training for solution aggregation"></a>The Majority is not always right: RL training for solution aggregation</h2><p><strong>Authors:Wenting Zhao, Pranjal Aggarwal, Swarnadeep Saha, Asli Celikyilmaz, Jason Weston, Ilia Kulikov</strong></p>
<p>Scaling up test-time compute, by generating multiple independent solutions and selecting or aggregating among them, has become a central paradigm for improving large language models (LLMs) on challenging reasoning tasks. While most prior work relies on simple majority voting or reward model ranking to aggregate solutions, these approaches may only yield limited benefits. In this work, we propose to learn aggregation as an explicit reasoning skill: given a set of candidate solutions, we train an aggregator model to review, reconcile, and synthesize a final, correct answer using reinforcement learning from verifiable rewards. A key ingredient is careful balancing of easy and hard training examples, allowing the model to learn both to recover minority-but-correct answers as well as easy majority-correct answers. Empirically, we find our method, AggLM, outperforms both strong rule-based and reward-model baselines, across multiple benchmarks. Furthermore, it generalizes effectively to solutions from differing models, including stronger ones than contained in the training data, all while requiring substantially fewer tokens than majority voting with larger numbers of solutions. </p>
<blockquote>
<p>åœ¨æµ‹è¯•æ—¶æ‰©å¤§è®¡ç®—è§„æ¨¡ï¼Œé€šè¿‡ç”Ÿæˆå¤šä¸ªç‹¬ç«‹è§£å†³æ–¹æ¡ˆå¹¶ä»ä¸­é€‰æ‹©æˆ–èšåˆï¼Œå·²æˆä¸ºæé«˜å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨å…·æœ‰æŒ‘æˆ˜æ€§æ¨ç†ä»»åŠ¡ä¸Šè¡¨ç°çš„æ ¸å¿ƒèŒƒå¼ã€‚è™½ç„¶å¤§å¤šæ•°å…ˆå‰çš„å·¥ä½œä¾èµ–äºç®€å•çš„å¤šæ•°æŠ•ç¥¨æˆ–å¥–åŠ±æ¨¡å‹æ’åæ¥èšåˆè§£å†³æ–¹æ¡ˆï¼Œä½†è¿™äº›æ–¹æ³•å¯èƒ½åªèƒ½äº§ç”Ÿæœ‰é™çš„æ•ˆç›Šã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬æå‡ºå°†èšåˆä½œä¸ºä¸€ç§æ˜ç¡®çš„æ¨ç†æŠ€èƒ½æ¥å­¦ä¹ ï¼šç»™å®šä¸€ç»„å€™é€‰è§£å†³æ–¹æ¡ˆï¼Œæˆ‘ä»¬è®­ç»ƒä¸€ä¸ªèšåˆå™¨æ¨¡å‹ï¼Œä½¿ç”¨å¯éªŒè¯çš„å¥–åŠ±æ¥å¼ºåŒ–å­¦ä¹ ï¼Œä»¥å®¡æŸ¥ã€è°ƒè§£å’Œåˆæˆæœ€ç»ˆçš„æ­£ç¡®ç­”æ¡ˆã€‚ä¸€ä¸ªå…³é”®è¦ç´ æ˜¯å¹³è¡¡ç®€å•å’Œå¤æ‚çš„è®­ç»ƒç¤ºä¾‹ï¼Œä½¿æ¨¡å‹èƒ½å¤Ÿå­¦ä¹ æ¢å¤å°‘æ•°ä½†æ­£ç¡®çš„ç­”æ¡ˆï¼Œä»¥åŠç®€å•çš„å¤šæ•°æ­£ç¡®ç­”æ¡ˆã€‚ä»ç»éªŒä¸Šçœ‹ï¼Œæˆ‘ä»¬å‘ç°æˆ‘ä»¬çš„æ–¹æ³•AggLMåœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­è¡¨ç°ä¼˜äºå¼ºå¤§çš„åŸºäºè§„åˆ™å’Œå¥–åŠ±æ¨¡å‹çš„åŸºç¡€çº¿ã€‚æ­¤å¤–ï¼Œå®ƒèƒ½æœ‰æ•ˆåœ°æ¨å¹¿åˆ°æ¥è‡ªä¸åŒæ¨¡å‹ï¼ˆåŒ…æ‹¬æ¯”è®­ç»ƒæ•°æ®æ›´å¼ºå¤§çš„æ¨¡å‹ï¼‰çš„è§£å†³æ–¹æ¡ˆï¼ŒåŒæ—¶éœ€è¦çš„ä»¤ç‰Œæ•°é‡è¿œè¿œå°‘äºä½¿ç”¨å¤§é‡è§£å†³æ–¹æ¡ˆçš„å¤šæ•°æŠ•ç¥¨ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.06870v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†åœ¨å¤§è§„æ¨¡è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„æŒ‘æˆ˜æ€§æ¨ç†ä»»åŠ¡ä¸­ï¼Œé€šè¿‡ç”Ÿæˆå¤šä¸ªç‹¬ç«‹è§£å†³æ–¹æ¡ˆå¹¶åœ¨æµ‹è¯•æ—¶é€‰æ‹©æˆ–èšåˆå®ƒä»¬æ¥æé«˜æ¨¡å‹æ€§èƒ½çš„æ ¸å¿ƒèŒƒå¼ã€‚é’ˆå¯¹å¤§å¤šæ•°ç°æœ‰å·¥ä½œçš„ç®€å•å¤šæ•°æŠ•ç¥¨æˆ–å¥–åŠ±æ¨¡å‹æ’åæ–¹æ³•å¯èƒ½å¸¦æ¥çš„å±€é™æ€§ï¼Œæœ¬æ–‡æå‡ºé€šè¿‡å­¦ä¹ èšåˆä½œä¸ºæ˜ç¡®çš„æ¨ç†æŠ€èƒ½æ¥è§£å†³è¿™ä¸€é—®é¢˜ã€‚ç»™å®šä¸€ç»„å€™é€‰è§£å†³æ–¹æ¡ˆï¼Œæˆ‘ä»¬è®­ç»ƒä¸€ä¸ªèšåˆå™¨æ¨¡å‹ï¼Œä½¿ç”¨å¯éªŒè¯çš„å¥–åŠ±é€šè¿‡å¼ºåŒ–å­¦ä¹ æ¥å®¡æŸ¥ã€åè°ƒå’Œç»¼åˆæœ€ç»ˆçš„æ­£ç¡®ç­”æ¡ˆã€‚é€šè¿‡å¹³è¡¡ç®€å•å’Œå›°éš¾çš„è®­ç»ƒç¤ºä¾‹ï¼Œæ¨¡å‹èƒ½å¤Ÿå­¦ä¹ æ¢å¤å°‘æ•°ä½†æ­£ç¡®çš„ç­”æ¡ˆä»¥åŠç®€å•çš„å¤šæ•°æ­£ç¡®ç­”æ¡ˆã€‚ç»éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•AggLMåœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­ä¼˜äºå¼ºå¤§çš„è§„åˆ™åŸºå‡†å’Œå¥–åŠ±æ¨¡å‹åŸºå‡†ï¼Œå¹¶èƒ½æœ‰æ•ˆåœ°æ¨å¹¿åˆ°æ¥è‡ªä¸åŒæ¨¡å‹çš„è§£å†³æ–¹æ¡ˆï¼ŒåŒ…æ‹¬æ¯”è®­ç»ƒæ•°æ®æ›´å¼ºå¤§çš„æ¨¡å‹ï¼ŒåŒæ—¶éœ€è¦çš„ä»¤ç‰Œæ•°é‡è¿œè¿œå°‘äºä½¿ç”¨å¤§é‡è§£å†³æ–¹æ¡ˆçš„å¤šæ•°æŠ•ç¥¨ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æµ‹è¯•æ—¶é€šè¿‡ç”Ÿæˆå¤šä¸ªç‹¬ç«‹è§£å†³æ–¹æ¡ˆå¹¶èšåˆï¼Œå·²æˆä¸ºæé«˜å¤§è§„æ¨¡è¯­è¨€æ¨¡å‹åœ¨æŒ‘æˆ˜æ€§æ¨ç†ä»»åŠ¡æ€§èƒ½çš„ä¸­å¿ƒèŒƒå¼ã€‚</li>
<li>ç°æœ‰æ–¹æ³•å¦‚å¤šæ•°æŠ•ç¥¨æˆ–å¥–åŠ±æ¨¡å‹æ’åå¯èƒ½å­˜åœ¨å±€é™æ€§ã€‚</li>
<li>æå‡ºé€šè¿‡å­¦ä¹ èšåˆä½œä¸ºæ˜ç¡®çš„æ¨ç†æŠ€èƒ½æ¥è§£å†³è¿™ä¸€é—®é¢˜ï¼Œè®­ç»ƒä¸€ä¸ªèšåˆå™¨æ¨¡å‹æ¥å®¡æŸ¥ã€åè°ƒå’Œç»¼åˆæœ€ç»ˆç­”æ¡ˆã€‚</li>
<li>ä½¿ç”¨å¼ºåŒ–å­¦ä¹ å’Œå¯éªŒè¯å¥–åŠ±æ¥è®­ç»ƒèšåˆå™¨æ¨¡å‹ã€‚</li>
<li>é€šè¿‡å¹³è¡¡ç®€å•å’Œå›°éš¾çš„è®­ç»ƒç¤ºä¾‹ï¼Œæ¨¡å‹èƒ½å­¦ä¹ æ¢å¤å°‘æ•°ä½†æ­£ç¡®çš„ç­”æ¡ˆä»¥åŠç®€å•çš„å¤šæ•°æ­£ç¡®ç­”æ¡ˆã€‚</li>
<li>AggLMæ–¹æ³•åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­ä¼˜äºè§„åˆ™åŸºå‡†å’Œå¥–åŠ±æ¨¡å‹åŸºå‡†ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.06870">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-d5a2fd48f65870f391c16c0dde4ba202.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-a845e858c885eee93fd3cf68c7b36dbf.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f9c4067cce580e50a88d6a639d686307.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-fa22ac50e7ff9e520f6b1430c7656d1c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-923f66cdc4d4efbeb6b48dd575bbf6a6.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="Test-Time-Scaling-in-Reasoning-Models-Is-Not-Effective-for-Knowledge-Intensive-Tasks-Yet"><a href="#Test-Time-Scaling-in-Reasoning-Models-Is-Not-Effective-for-Knowledge-Intensive-Tasks-Yet" class="headerlink" title="Test-Time Scaling in Reasoning Models Is Not Effective for   Knowledge-Intensive Tasks Yet"></a>Test-Time Scaling in Reasoning Models Is Not Effective for   Knowledge-Intensive Tasks Yet</h2><p><strong>Authors:James Xu Zhao, Bryan Hooi, See-Kiong Ng</strong></p>
<p>Test-time scaling increases inference-time computation by allowing models to generate long reasoning chains, and has shown strong performance across many domains. However, in this work, we show that this approach is not yet effective for knowledge-intensive tasks, where high factual accuracy and low hallucination rates are essential. We conduct a comprehensive evaluation of test-time scaling using 12 reasoning models on two knowledge-intensive benchmarks. Our results reveal that increasing test-time computation does not consistently improve accuracy and, in many cases, it even leads to more hallucinations. We then analyze how extended reasoning affects hallucination behavior. We find that reduced hallucinations often result from the model choosing to abstain after thinking more, rather than from improved factual recall. Conversely, for some models, longer reasoning encourages attempts on previously unanswered questions, many of which result in hallucinations. Case studies show that extended reasoning can induce confirmation bias, leading to overconfident hallucinations. Despite these limitations, we observe that compared to non-thinking, enabling thinking remains beneficial. Code and data are available at <a target="_blank" rel="noopener" href="https://github.com/XuZhao0/tts-knowledge">https://github.com/XuZhao0/tts-knowledge</a> </p>
<blockquote>
<p>æµ‹è¯•æ—¶ç¼©æ”¾ï¼ˆTest-time scalingï¼‰é€šè¿‡å…è®¸æ¨¡å‹ç”Ÿæˆé•¿çš„æ¨ç†é“¾æ¥å¢åŠ æ¨ç†æ—¶é—´è®¡ç®—ï¼Œå¹¶ä¸”åœ¨è®¸å¤šé¢†åŸŸéƒ½è¡¨ç°å‡ºäº†å¼ºå¤§çš„æ€§èƒ½ã€‚ç„¶è€Œï¼Œåœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬è¡¨æ˜è¿™ç§æ–¹æ³•å¯¹äºçŸ¥è¯†å¯†é›†å‹ä»»åŠ¡å°šä¸æœ‰æ•ˆï¼Œå…¶ä¸­é«˜äº‹å®å‡†ç¡®æ€§å’Œä½å¹»è§‰ç‡æ˜¯è‡³å…³é‡è¦çš„ã€‚æˆ‘ä»¬åœ¨ä¸¤ä¸ªçŸ¥è¯†å¯†é›†å‹åŸºå‡†æµ‹è¯•ä¸Šå¯¹12ä¸ªæ¨ç†æ¨¡å‹è¿›è¡Œäº†å…¨é¢çš„æµ‹è¯•æ—¶ç¼©æ”¾è¯„ä¼°ã€‚æˆ‘ä»¬çš„ç»“æœè¡¨æ˜ï¼Œå¢åŠ æµ‹è¯•æ—¶é—´çš„è®¡ç®—å¹¶ä¸èƒ½æŒç»­æé«˜å‡†ç¡®æ€§ï¼Œè€Œä¸”åœ¨è®¸å¤šæƒ…å†µä¸‹ï¼Œç”šè‡³ä¼šå¯¼è‡´æ›´å¤šçš„å¹»è§‰ã€‚ç„¶åæˆ‘ä»¬åˆ†æäº†æ‰©å±•æ¨ç†å¦‚ä½•å½±å“å¹»è§‰è¡Œä¸ºã€‚æˆ‘ä»¬å‘ç°ï¼Œå‡å°‘å¹»è§‰å¾€å¾€æ˜¯ç”±äºæ¨¡å‹åœ¨æ€è€ƒæ›´å¤šåé€‰æ‹©æ”¾å¼ƒå›ç­”ï¼Œè€Œä¸æ˜¯å› ä¸ºäº‹å®è®°å¿†çš„æ”¹å–„ã€‚ç›¸åï¼Œå¯¹äºæŸäº›æ¨¡å‹æ¥è¯´ï¼Œæ›´é•¿çš„æ¨ç†ä¼šé¼“åŠ±å°è¯•ä¹‹å‰æœªè§£å†³çš„é—®é¢˜ï¼Œå…¶ä¸­è®¸å¤šéƒ½ä¼šå¯¼è‡´å¹»è§‰ã€‚æ¡ˆä¾‹ç ”ç©¶è¡¨æ˜ï¼Œæ‰©å±•æ¨ç†ä¼šå¯¼è‡´ç¡®è®¤åè§ï¼Œä»è€Œäº§ç”Ÿè¿‡åº¦è‡ªä¿¡çš„å¹»è§‰ã€‚å°½ç®¡æœ‰è¿™äº›å±€é™æ€§ï¼Œä½†æˆ‘ä»¬è§‚å¯Ÿåˆ°ä¸æ²¡æœ‰æ€è€ƒç›¸æ¯”ï¼Œå…è®¸æ€è€ƒä»ç„¶æ˜¯æœ‰ç›Šçš„ã€‚ç›¸å…³ä»£ç å’Œæ•°æ®å¯ä»¥åœ¨ <a target="_blank" rel="noopener" href="https://github.com/XuZhao0/tts-knowledge">https://github.com/XuZhao0/tts-knowledge</a> æ‰¾åˆ°ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.06861v1">PDF</a> 20 pages, 4 figures, 6 tables</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ç ”ç©¶äº†æµ‹è¯•æ—¶ç¼©æ”¾æŠ€æœ¯åœ¨çŸ¥è¯†å¯†é›†å‹ä»»åŠ¡ä¸­çš„è¡¨ç°ï¼Œå‘ç°å¢åŠ æµ‹è¯•æ—¶çš„è®¡ç®—é‡å¹¶ä¸æ€»èƒ½æé«˜å‡†ç¡®æ€§ï¼Œä¸”æœ‰æ—¶ä¼šå¯¼è‡´æ›´å¤šçš„å¹»è§‰ã€‚åˆ†æè¡¨æ˜ï¼Œå»¶é•¿æ¨ç†æ—¶é—´å¹¶ä¸æ€»æ˜¯èƒ½å‡å°‘å¹»è§‰ï¼Œè€Œä¸”å¯¹ä¸€äº›æ¨¡å‹è€Œè¨€ï¼Œæ›´é•¿çš„æ¨ç†æ—¶é—´ç”šè‡³ä¼šé¼“åŠ±å°è¯•å›ç­”ä¹‹å‰æœªè§£å†³çš„é—®é¢˜ï¼Œä»è€Œå¢åŠ å¹»è§‰ã€‚ç„¶è€Œï¼Œä¸ä¸ç»æ€è€ƒç›¸æ¯”ï¼Œå…è®¸æ¨¡å‹æ€è€ƒä»ç„¶æ˜¯æœ‰ç›Šçš„ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æµ‹è¯•æ—¶ç¼©æ”¾æŠ€æœ¯å…è®¸æ¨¡å‹ç”Ÿæˆæ›´é•¿çš„æ¨ç†é“¾ï¼Œä½†å…¶åœ¨çŸ¥è¯†å¯†é›†å‹ä»»åŠ¡ä¸­çš„æ•ˆæœæœ‰é™ã€‚</li>
<li>å¢åŠ æµ‹è¯•æ—¶çš„è®¡ç®—é‡å¹¶ä¸æ€»æ˜¯èƒ½æé«˜å‡†ç¡®æ€§ï¼Œæœ‰æ—¶ç”šè‡³ä¼šå¯¼è‡´æ›´å¤šçš„å¹»è§‰ã€‚</li>
<li>å»¶é•¿æ¨ç†æ—¶é—´å¹¶ä¸ä¸€å®šèƒ½å‡å°‘å¹»è§‰ï¼Œè¿™å–å†³äºæ¨¡å‹çš„ç‰¹æ€§ã€‚</li>
<li>å¯¹äºæŸäº›æ¨¡å‹ï¼Œæ›´é•¿çš„æ¨ç†æ—¶é—´å¯èƒ½é¼“åŠ±å°è¯•å›ç­”ä¹‹å‰æœªè§£å†³çš„é—®é¢˜ï¼Œå¢åŠ å¹»è§‰ã€‚</li>
<li>æµ‹è¯•æ—¶ç¼©æ”¾æŠ€æœ¯å¯èƒ½å¼•å‘ç¡®è®¤åè§ï¼Œå¯¼è‡´è¿‡åº¦è‡ªä¿¡çš„å¹»è§‰ã€‚</li>
<li>å°½ç®¡å­˜åœ¨å±€é™æ€§ï¼Œä½†ä¸ä¸ç»æ€è€ƒç›¸æ¯”ï¼Œå…è®¸æ¨¡å‹æ€è€ƒä»ç„¶å…·æœ‰ç›Šå¤„ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.06861">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-c3eca0fb59c53f6ce859822e566b3ab8.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-5b96026567033333da8d6c452200696e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-2905047938651c9823c552d2f208d723.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-06bef8f13931769f921055473838bf50.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a29caf368577ab97dd4f3b2d20c1b009.jpg" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="RAFFLES-Reasoning-based-Attribution-of-Faults-for-LLM-Systems"><a href="#RAFFLES-Reasoning-based-Attribution-of-Faults-for-LLM-Systems" class="headerlink" title="RAFFLES: Reasoning-based Attribution of Faults for LLM Systems"></a>RAFFLES: Reasoning-based Attribution of Faults for LLM Systems</h2><p><strong>Authors:Chenyang Zhu, Spencer Hong, Jingyu Wu, Kushal Chawla, Charlotte Tang, Youbing Yin, Nathan Wolfe, Erin Babinsky, Daben Liu</strong></p>
<p>We have reached a critical roadblock in the development and enhancement of long-horizon, multi-component LLM agentic systems: it is incredibly tricky to identify where these systems break down and why. Evaluation capabilities that currently exist today (e.g., single pass LLM-as-a-judge) are limited in that they often focus on individual metrics or capabilities, end-to-end outcomes, and are narrowly grounded on the preferences of humans. We argue that to match the agentic capabilities, evaluation frameworks must also be able to reason, probe, iterate, and understand the complex logic passing through these systems over long horizons. In this paper, we present RAFFLES - an evaluation architecture that incorporates reasoning and iterative refinement. Specifically, RAFFLES operates as an iterative, multi-component pipeline, using a central Judge to systematically investigate faults and a set of specialized Evaluators to assess not only the systemâ€™s components but also the quality of the reasoning by the Judge itself, thereby building a history of hypotheses. We tested RAFFLES against several baselines on the Who&amp;When dataset, a benchmark designed to diagnose the â€œwhoâ€ (agent) and â€œwhenâ€ (step) of a systemâ€™s failure. RAFFLES outperforms these baselines, achieving an agent-step fault pair accuracy of over 43% on the Algorithmically-Generated dataset (a substantial increase from the previously published best of 16.6%) and over 20% on the Hand-Crafted dataset (surpassing the previously published best of 8.8%). These results demonstrate a key step towards introducing automated fault detection for autonomous systems over labor-intensive manual human review. </p>
<blockquote>
<p>æˆ‘ä»¬å·²ç»é‡åˆ°é•¿æœŸè§†é‡ã€å¤šç»„ä»¶LLMæ™ºèƒ½ç³»ç»Ÿå¼€å‘å’Œå¢å¼ºè¿‡ç¨‹ä¸­çš„å…³é”®éš¾é¢˜ï¼šå¾ˆéš¾ç¡®å®šè¿™äº›ç³»ç»Ÿå‡ºç°æ•…éšœçš„ä½ç½®å’ŒåŸå› ã€‚å½“å‰å­˜åœ¨çš„è¯„ä¼°èƒ½åŠ›ï¼ˆä¾‹å¦‚ï¼Œå•ä¸€é€šè¡ŒLLMä½œä¸ºè¯„åˆ¤è€…ï¼‰å…·æœ‰å±€é™æ€§ï¼Œå› ä¸ºå®ƒä»¬é€šå¸¸å…³æ³¨å•ä¸ªæŒ‡æ ‡æˆ–èƒ½åŠ›ã€ç«¯åˆ°ç«¯ç»“æœï¼Œå¹¶åŸºäºäººç±»çš„åå¥½ã€‚æˆ‘ä»¬è®¤ä¸ºï¼Œä¸ºäº†åŒ¹é…æ™ºèƒ½ç³»ç»Ÿçš„èƒ½åŠ›ï¼Œè¯„ä¼°æ¡†æ¶è¿˜å¿…é¡»èƒ½å¤Ÿæ¨ç†ã€æ¢æµ‹ã€è¿­ä»£å’Œç†è§£è¿™äº›ç³»ç»Ÿåœ¨é•¿æœŸè§†é‡ä¸­é€šè¿‡çš„å¤æ‚é€»è¾‘ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†RAFFLESâ€”â€”ä¸€ç§ç»“åˆæ¨ç†å’Œè¿­ä»£ç²¾åŒ–çš„è¯„ä¼°æ¶æ„ã€‚å…·ä½“æ¥è¯´ï¼ŒRAFFLESä½œä¸ºä¸€ä¸ªè¿­ä»£çš„å¤šç»„ä»¶ç®¡é“è¿è¡Œï¼Œä½¿ç”¨ä¸€ä¸ªä¸­å¤®è¯„åˆ¤ç³»ç»Ÿæ¥ç³»ç»Ÿåœ°è°ƒæŸ¥æ•…éšœå’Œä¸€ç³»åˆ—ä¸“é—¨çš„è¯„ä¼°å™¨æ¥è¯„ä¼°ä¸ä»…ç³»ç»Ÿçš„ç»„ä»¶ï¼Œè¿˜è¯„ä¼°è¯„åˆ¤æœ¬èº«çš„æ¨ç†è´¨é‡ï¼Œä»è€Œå»ºç«‹å‡è®¾å†å²ã€‚æˆ‘ä»¬åœ¨Who&amp;Whenæ•°æ®é›†ä¸Šæµ‹è¯•äº†RAFFLESï¼Œè¯¥æ•°æ®é›†æ—¨åœ¨è¯Šæ–­ç³»ç»Ÿçš„â€œè°â€ï¼ˆæ™ºèƒ½ä½“ï¼‰å’Œâ€œä½•æ—¶â€ï¼ˆæ­¥éª¤ï¼‰æ•…éšœã€‚RAFFLESä¼˜äºè¿™äº›åŸºçº¿ï¼Œåœ¨ç®—æ³•ç”Ÿæˆçš„æ•°æ®é›†ä¸Šå®ç°äº†è¶…è¿‡43%çš„æ™ºèƒ½ä½“æ­¥éª¤æ•…éšœå¯¹å‡†ç¡®ç‡ï¼ˆä¸ä¹‹å‰å‘å¸ƒçš„æœ€ä½³ç»“æœ16.6%ç›¸æ¯”æœ‰å¤§å¹…åº¦æé«˜ï¼‰ï¼Œåœ¨æ‰‹å·¥åˆ¶ä½œçš„æ•°æ®é›†ä¸Šè¶…è¿‡20%ï¼ˆè¶…è¿‡ä¹‹å‰å‘å¸ƒçš„æœ€ä½³ç»“æœ8.8%ï¼‰ã€‚è¿™äº›ç»“æœæœç€ä¸ºè‡ªä¸»ç³»ç»Ÿå¼•å…¥è‡ªåŠ¨åŒ–æ•…éšœæ£€æµ‹æ–¹å‘è¿ˆå‡ºäº†å…³é”®ä¸€æ­¥ï¼Œå‡å°‘äº†åŠ³åŠ¨å¯†é›†å‹çš„æ‰‹åŠ¨äººå·¥å®¡æŸ¥ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.06822v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºåœ¨å¼€å‘å’Œå¢å¼ºé•¿æœŸè§†é‡å¤šç»„ä»¶çš„LLMä»£ç†äººç³»ç»Ÿæ—¶é‡åˆ°çš„ç“¶é¢ˆé—®é¢˜ï¼Œå³éš¾ä»¥ç¡®å®šç³»ç»Ÿçš„æ•…éšœæ‰€åœ¨åŠåŸå› ã€‚ç°æœ‰è¯„ä¼°æ–¹æ³•ï¼ˆå¦‚å•æ¬¡é€šè¿‡LLMä½œä¸ºè¯„ä¼°å·¥å…·ï¼‰ä¾§é‡äºå•ç‹¬çš„èƒ½åŠ›æŒ‡æ ‡å’Œç»“æœè¯„ä»·ï¼Œå¿½ç•¥äº†ç³»ç»Ÿçš„å¤æ‚é€»è¾‘å’Œé•¿æœŸæ¨ç†è¿‡ç¨‹ã€‚å› æ­¤ï¼Œä½œè€…æå‡ºäº†RAFFLESè¯„ä¼°æ¶æ„ï¼Œè¯¥æ¶æ„èƒ½å¤Ÿè¿›è¡Œè¿­ä»£æ¨ç†å’Œç²¾ç»†è°ƒæ•´ï¼Œè§£å†³æ­¤é—®é¢˜ã€‚æµ‹è¯•æ˜¾ç¤ºï¼ŒRAFFLESåœ¨Who&amp;Whenæ•°æ®é›†ä¸Šçš„è¡¨ç°ä¼˜äºå…¶ä»–åŸºçº¿æ–¹æ³•ï¼Œå®ç°äº†å¯¹ç³»ç»Ÿæ•…éšœçš„â€œè°â€å’Œâ€œä½•æ—¶â€çš„è¯Šæ–­ã€‚è¿™ä¸ºè‡ªä¸»ç³»ç»Ÿçš„è‡ªåŠ¨åŒ–æ•…éšœæ£€æµ‹æä¾›äº†å…³é”®ä¸€æ­¥ï¼Œå‡å°‘äº†åŠ³åŠ¨å¯†é›†å‹çš„äººå·¥å®¡æŸ¥ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>LLMä»£ç†äººç³»ç»Ÿåœ¨å¼€å‘å’Œå¢å¼ºè¿‡ç¨‹ä¸­é¢ä¸´è¯†åˆ«æ•…éšœå›°éš¾çš„ç“¶é¢ˆã€‚</li>
<li>å½“å‰è¯„ä¼°æ–¹æ³•ä¾§é‡äºä¸ªä½“èƒ½åŠ›æŒ‡æ ‡å’Œç»“æœï¼Œå¿½ç•¥ç³»ç»Ÿçš„é•¿æœŸé€»è¾‘å’Œæ¨ç†è¿‡ç¨‹ã€‚</li>
<li>æå‡ºRAFFLESè¯„ä¼°æ¶æ„ï¼Œå…·å¤‡æ¨ç†ã€è¿­ä»£å®Œå–„èƒ½åŠ›ï¼Œè§£å†³ç°æœ‰é—®é¢˜ã€‚</li>
<li>RAFFLESé€šè¿‡ä¸­å¤®è¯„ä¼°ç³»ç»Ÿå’Œä¸€ç³»åˆ—ä¸“ä¸šè¯„ä¼°å™¨ï¼Œä¸ä»…è¯„ä¼°ç³»ç»Ÿç»„ä»¶ï¼Œè¿˜è¯„ä¼°åˆ¤æ–­è´¨é‡ï¼Œå»ºç«‹å‡è®¾å†å²ã€‚</li>
<li>åœ¨Who&amp;Whenæ•°æ®é›†ä¸Šçš„æµ‹è¯•è¡¨æ˜ï¼ŒRAFFLESä¼˜äºå…¶ä»–åŸºçº¿æ–¹æ³•ã€‚</li>
<li>RAFFLESå®ç°äº†å¯¹ç³»ç»Ÿæ•…éšœçš„â€œè°â€å’Œâ€œä½•æ—¶â€çš„è¯Šæ–­ï¼Œè¡¨ç°åœ¨ç®—æ³•ç”Ÿæˆå’Œæ•°æ®é›†çš„æ‰‹å·¥åˆ¶ä½œä¸Šéƒ½æœ‰æ˜¾è‘—çš„æå‡ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.06822">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-42ef2dd5eeb17738895d5f92be6f0e0e.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-403a3838f404241646429a42db133bab.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a267450137a1beaf498039298d09da08.jpg" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1><h2 id="Saturation-Driven-Dataset-Generation-for-LLM-Mathematical-Reasoning-in-the-TPTP-Ecosystem"><a href="#Saturation-Driven-Dataset-Generation-for-LLM-Mathematical-Reasoning-in-the-TPTP-Ecosystem" class="headerlink" title="Saturation-Driven Dataset Generation for LLM Mathematical Reasoning in   the TPTP Ecosystem"></a>Saturation-Driven Dataset Generation for LLM Mathematical Reasoning in   the TPTP Ecosystem</h2><p><strong>Authors:Valentin Quesnel, Damien Sileo</strong></p>
<p>The scarcity of high-quality, logically sound data is a critical bottleneck for advancing the mathematical reasoning of Large Language Models (LLMs). Our work confronts this challenge by turning decades of automated theorem proving research into a scalable data engine. Rather than relying on error-prone LLMs or complex proof-assistant syntax like Lean and Isabelle, our framework leverages E-proverâ€™s saturation capabilities on the vast TPTP axiom library to derive a massive, guaranteed-valid corpus of theorems. Our pipeline is principled and simple: saturate axioms, filter for â€œinterestingâ€ theorems, and generate tasks. With no LLMs in the loop, we eliminate factual errors by construction. This purely symbolic data is then transformed into three difficulty-controlled challenges: entailment verification, premise selection, and proof reconstruction. Our zero-shot experiments on frontier models reveal a clear weakness: performance collapses on tasks requiring deep, structural reasoning. Our framework provides both the diagnostic tool to measure this gap and a scalable source of symbolic training data to address it. We make the code and data publicly available.   <a target="_blank" rel="noopener" href="https://github.com/sileod/reasoning_core">https://github.com/sileod/reasoning_core</a> <a target="_blank" rel="noopener" href="https://hf.co/datasets/reasoning-core/rc1">https://hf.co/datasets/reasoning-core/rc1</a> </p>
<blockquote>
<p>é«˜è´¨é‡ã€é€»è¾‘ä¸¥è°¨çš„æ•°æ®ç¨€ç¼ºï¼Œæ˜¯æ¨åŠ¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ•°å­¦æ¨ç†è¿›æ­¥çš„å…³é”®ç“¶é¢ˆã€‚æˆ‘ä»¬çš„å·¥ä½œé€šè¿‡æŠŠå‡ åå¹´çš„è‡ªåŠ¨åŒ–å®šç†è¯æ˜ç ”ç©¶è½¬åŒ–ä¸ºå¯æ‰©å±•çš„æ•°æ®å¼•æ“æ¥åº”å¯¹è¿™ä¸€æŒ‘æˆ˜ã€‚æˆ‘ä»¬çš„æ¡†æ¶å¹¶æ²¡æœ‰ä¾èµ–å®¹æ˜“å‡ºé”™çš„LLMæˆ–å¤æ‚çš„è¯æ˜è¾…åŠ©è¯­æ³•ï¼ˆå¦‚Leanå’ŒIsabelleï¼‰ï¼Œè€Œæ˜¯åˆ©ç”¨E-proveråœ¨TPTPå…¬ç†åº“ä¸Šçš„é¥±å’Œèƒ½åŠ›ï¼Œæ¨å¯¼å‡ºå¤§é‡æœ‰ä¿è¯æœ‰æ•ˆçš„å®šç†è¯­æ–™åº“ã€‚æˆ‘ä»¬çš„ç®¡é“æœ‰åŸåˆ™ä¸”ç®€å•ï¼šé¥±å’Œå…¬ç†ï¼Œè¿‡æ»¤å‡ºâ€œæœ‰è¶£â€çš„å®šç†ï¼Œå¹¶ç”Ÿæˆä»»åŠ¡ã€‚ç”±äºæ²¡æœ‰LLMçš„å‚ä¸ï¼Œæˆ‘ä»¬é€šè¿‡æ„å»ºæ¶ˆé™¤äº†äº‹å®é”™è¯¯ã€‚è¿™ç§çº¯ç²¹çš„ç¬¦å·æ•°æ®éšåè¢«è½¬åŒ–ä¸ºä¸‰ç§éš¾åº¦å¯æ§çš„æŒ‘æˆ˜ï¼šè•´å«éªŒè¯ã€å‰æé€‰æ‹©ã€è¯æ˜é‡å»ºã€‚æˆ‘ä»¬åœ¨å‰æ²¿æ¨¡å‹ä¸Šçš„é›¶æ ·æœ¬å®éªŒæ­ç¤ºäº†ä¸€ä¸ªæ˜ç¡®çš„å¼±ç‚¹ï¼šå¯¹äºéœ€è¦æ·±å…¥ã€ç»“æ„æ€§æ¨ç†çš„ä»»åŠ¡ï¼Œæ€§èƒ½ä¼šå´©æºƒã€‚æˆ‘ä»¬çš„æ¡†æ¶æ—¢æä¾›äº†è¡¡é‡è¿™ä¸€å·®è·çš„è¯Šæ–­å·¥å…·ï¼Œåˆæä¾›äº†å¯æ‰©å±•çš„ç¬¦å·è®­ç»ƒæ•°æ®æ¥æºæ¥è§£å†³è¿™ä¸€é—®é¢˜ã€‚æˆ‘ä»¬å…¬å¼€æä¾›ä»£ç å’Œæ•°æ®ã€‚ç›¸å…³é“¾æ¥å¦‚ä¸‹ï¼š<a target="_blank" rel="noopener" href="https://github.com/sileod/reasoning_core">https://github.com/sileod/reasoning_core</a> <a target="_blank" rel="noopener" href="https://hf.co/datasets/reasoning-core/rc1">https://hf.co/datasets/reasoning-core/rc1</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.06809v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬ç ”ç©¶é’ˆå¯¹å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨æ¨è¿›æ•°å­¦æ¨ç†æ–¹é¢çš„ç“¶é¢ˆé—®é¢˜ï¼Œæå‡ºä¸€ç§åˆ©ç”¨å®šç†è¯æ˜å™¨E-proverå¯¹TPTPå…¬ç†åº“è¿›è¡Œé¥±å’Œè®¡ç®—çš„æ–¹æ³•ï¼Œç”Ÿæˆå¤§é‡ä¿è¯æœ‰æ•ˆçš„å®šç†è¯­æ–™åº“ã€‚é€šè¿‡ç®€å•çš„åŸåˆ™æ€§ç®¡é“â€”â€”é¥±å’Œå…¬ç†ã€è¿‡æ»¤æœ‰è¶£å®šç†ã€ç”Ÿæˆä»»åŠ¡ï¼Œå®ç°æ— éœ€LLMså‚ä¸ï¼Œä»è€Œé¿å…äº†äº‹å®é”™è¯¯ã€‚è¯¥æ¡†æ¶æä¾›è¯Šæ–­å·¥å…·æ¥è¡¡é‡å‰æ²¿æ¨¡å‹åœ¨æ·±åº¦ç»“æ„æ¨ç†æ–¹é¢çš„å·®è·ï¼Œå¹¶æä¾›å¯ä¼¸ç¼©çš„ç¬¦å·è®­ç»ƒæ•°æ®æ¥è§£å†³è¿™ä¸€é—®é¢˜ã€‚ç›¸å…³ä»£ç å’Œæ•°æ®å·²å…¬å¼€ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤§å‹è¯­è¨€æ¨¡å‹åœ¨æ¨è¿›æ•°å­¦æ¨ç†æ–¹é¢é¢ä¸´æ•°æ®è´¨é‡ç“¶é¢ˆã€‚</li>
<li>ç ”ç©¶åˆ©ç”¨å®šç†è¯æ˜å™¨E-proverç”Ÿæˆå¤§é‡ä¿è¯æœ‰æ•ˆçš„å®šç†è¯­æ–™åº“ã€‚</li>
<li>ç®¡é“åŒ…æ‹¬é¥±å’Œå…¬ç†ã€è¿‡æ»¤æœ‰è¶£å®šç†ã€ç”Ÿæˆä»»åŠ¡ï¼Œæ— éœ€å¤§å‹è¯­è¨€æ¨¡å‹å‚ä¸ã€‚</li>
<li>è¯¥æ¡†æ¶é¿å…äº†äº‹å®é”™è¯¯ï¼Œå¹¶æä¾›äº†è¡¡é‡å‰æ²¿æ¨¡å‹åœ¨æ·±åº¦ç»“æ„æ¨ç†æ–¹é¢å·®è·çš„å·¥å…·ã€‚</li>
<li>å…¬å¼€çš„ä»£ç å’Œæ•°æ®æœ‰åŠ©äºç ”ç©¶è€…å’Œå¼€å‘è€…ä½¿ç”¨æ­¤æ¡†æ¶è¿›è¡Œç ”ç©¶å’Œåº”ç”¨ã€‚</li>
<li>è¯¥æ¡†æ¶æä¾›äº†ä¸€ç§å¯æ‰©å±•çš„ç¬¦å·è®­ç»ƒæ•°æ®æ¥æºï¼Œä»¥æ”¹è¿›æ¨¡å‹åœ¨æ•°å­¦æ¨ç†æ–¹é¢çš„æ€§èƒ½ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.06809">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-62e29e6da5b9b1499dafbf477f3dd980.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-b7ec3470a410d95a6c6abfeba8b4cc93.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-1a384b07bfdcfff40790a303a1bbf387.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-4d1eeb0f0bc50c018a456e5ed79a9bf5.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-7f7edae7b2aa82267b7432c3cb7cfd22.jpg" align="middle">
</details>


<h1 id="-9"><a href="#-9" class="headerlink" title=""></a></h1><h2 id="MachineLearningLM-Continued-Pretraining-Language-Models-on-Millions-of-Synthetic-Tabular-Prediction-Tasks-Scales-In-Context-ML"><a href="#MachineLearningLM-Continued-Pretraining-Language-Models-on-Millions-of-Synthetic-Tabular-Prediction-Tasks-Scales-In-Context-ML" class="headerlink" title="MachineLearningLM: Continued Pretraining Language Models on Millions of   Synthetic Tabular Prediction Tasks Scales In-Context ML"></a>MachineLearningLM: Continued Pretraining Language Models on Millions of   Synthetic Tabular Prediction Tasks Scales In-Context ML</h2><p><strong>Authors:Haoyu Dong, Pengkun Zhang, Mingzhe Lu, Yanzhen Shen, Guolin Ke</strong></p>
<p>Large language models (LLMs) possess broad world knowledge and strong general-purpose reasoning ability, yet they struggle to learn from many in-context examples on standard machine learning (ML) tasks, that is, to leverage many-shot demonstrations purely via in-context learning (ICL) without gradient descent. We introduce MachineLearningLM, a portable continued-pretraining framework that equips a general-purpose LLM with robust in-context ML capability while preserving its general knowledge and reasoning for broader chat workflows.   Our pretraining procedure synthesizes ML tasks from millions of structural causal models (SCMs), spanning shot counts up to 1,024. We begin with a random-forest teacher, distilling tree-based decision strategies into the LLM to strengthen robustness in numerical modeling. All tasks are serialized with a token-efficient prompt, enabling 3x to 6x more examples per context window and delivering up to 50x amortized throughput via batch inference.   Despite a modest setup (Qwen-2.5-7B-Instruct with LoRA rank 8), MachineLearningLM outperforms strong LLM baselines (e.g., GPT-5-mini) by an average of about 15% on out-of-distribution tabular classification across finance, physics, biology, and healthcare domains. It exhibits a striking many-shot scaling law: accuracy increases monotonically as in-context demonstrations grow from 8 to 1,024. Without any task-specific training, it attains random-forest-level accuracy across hundreds of shots. General chat capabilities, including knowledge and reasoning, are preserved: it achieves 75.4% on MMLU. </p>
<blockquote>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ‹¥æœ‰å¹¿æ³›çš„ä¸–ç•ŒçŸ¥è¯†å’Œå¼ºå¤§çš„é€šç”¨æ¨ç†èƒ½åŠ›ï¼Œä½†åœ¨æ ‡å‡†æœºå™¨å­¦ä¹ ï¼ˆMLï¼‰ä»»åŠ¡ä¸Šï¼Œå®ƒä»¬å¾ˆéš¾ä»å¤šä¸ªä¸Šä¸‹æ–‡ç¤ºä¾‹ä¸­å­¦ä¹ ï¼Œä¹Ÿå°±æ˜¯è¯´ï¼Œå®ƒä»¬æ— æ³•ä»…é€šè¿‡ä¸Šä¸‹æ–‡å­¦ä¹ ï¼ˆICLï¼‰åˆ©ç”¨å¤šä¸ªç¤ºä¾‹æ¼”ç¤ºï¼Œè€Œæ— éœ€è¿›è¡Œæ¢¯åº¦ä¸‹é™ã€‚æˆ‘ä»¬å¼•å…¥äº†MachineLearningLMï¼Œè¿™æ˜¯ä¸€ä¸ªä¾¿æºå¼æŒç»­é¢„è®­ç»ƒæ¡†æ¶ï¼Œå®ƒä½¿é€šç”¨LLMå…·å¤‡å¼ºå¤§çš„ä¸Šä¸‹æ–‡MLèƒ½åŠ›ï¼ŒåŒæ—¶ä¿ç•™å…¶ä¸€èˆ¬çŸ¥è¯†å’Œæ¨ç†èƒ½åŠ›ï¼Œä»¥æ”¯æŒæ›´å¹¿æ³›çš„èŠå¤©å·¥ä½œæµç¨‹ã€‚æˆ‘ä»¬çš„é¢„è®­ç»ƒç¨‹åºä»æ•°ç™¾ä¸‡ä¸ªç»“æ„å› æœæ¨¡å‹ï¼ˆSCMï¼‰ä¸­ç»¼åˆMLä»»åŠ¡ï¼Œæ¶µç›–ç¤ºä¾‹æ•°é‡é«˜è¾¾1024ä¸ªã€‚æˆ‘ä»¬ä»¥éšæœºæ£®æ—æ•™å¸ˆå¼€å§‹ï¼Œå°†åŸºäºæ ‘çš„å†³ç­–ç­–ç•¥è’¸é¦åˆ°LLMä¸­ï¼Œä»¥åŠ å¼ºæ•°å€¼å»ºæ¨¡ä¸­çš„ç¨³å¥æ€§ã€‚æ‰€æœ‰ä»»åŠ¡éƒ½é€šè¿‡é«˜æ•ˆçš„ä»¤ç‰Œæç¤ºè¿›è¡Œåºåˆ—åŒ–ï¼Œå¯ä»¥åœ¨æ¯ä¸ªä¸Šä¸‹æ–‡çª—å£ä¸­å®ç°3åˆ°6å€çš„æ›´å¤šç¤ºä¾‹ï¼Œå¹¶é€šè¿‡æ‰¹é‡æ¨ç†å®ç°é«˜è¾¾50å€çš„æ‘Šé”€ååé‡ã€‚å°½ç®¡é…ç½®ç›¸å¯¹ç®€å•ï¼ˆä½¿ç”¨LoRAç­‰çº§8çš„Qwen-2.5-7B-Instructï¼‰ï¼Œä½†MachineLearningLMåœ¨é‡‘èã€ç‰©ç†ã€ç”Ÿç‰©å’ŒåŒ»ç–—ä¿å¥é¢†åŸŸçš„ç¦»ç¾¤åˆ†å¸ƒè¡¨æ ¼åˆ†ç±»æ–¹é¢ï¼Œå¹³å‡æ¯”å¼ºå¤§çš„LLMåŸºçº¿ï¼ˆä¾‹å¦‚GPT-5 miniï¼‰é«˜å‡ºçº¦15%ã€‚å®ƒå‘ˆç°å‡ºä»¤äººå°è±¡æ·±åˆ»çš„è®¸å¤šå°„å‡»æ¯”ä¾‹å®šå¾‹ï¼šéšç€ä¸Šä¸‹æ–‡æ¼”ç¤ºä»8å¢åŠ åˆ°1024ï¼Œå‡†ç¡®æ€§å‘ˆå•è°ƒå¢åŠ ã€‚æ— éœ€ä»»ä½•ç‰¹å®šä»»åŠ¡è®­ç»ƒï¼Œå®ƒåœ¨æ•°ç™¾æ¬¡å°„å‡»ä¸­è¾¾åˆ°äº†éšæœºæ£®æ—çº§åˆ«çš„ç²¾åº¦ã€‚åŒæ—¶ä¿ç•™äº†é€šç”¨çš„èŠå¤©åŠŸèƒ½ï¼ŒåŒ…æ‹¬çŸ¥è¯†å’Œæ¨ç†èƒ½åŠ›ï¼šå®ƒåœ¨MMLUä¸Šè¾¾åˆ°äº†75.4%ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.06806v1">PDF</a> </p>
<p><strong>æ‘˜è¦</strong><br>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å…·å¤‡å¹¿æ³›çš„ä¸–ç•ŒçŸ¥è¯†å’Œå¼ºå¤§çš„é€šç”¨æ¨ç†èƒ½åŠ›ï¼Œä½†åœ¨æ ‡å‡†æœºå™¨å­¦ä¹ ï¼ˆMLï¼‰ä»»åŠ¡ä¸Šå­¦ä¹ å¤šä¸ªä¸Šä¸‹æ–‡ç¤ºä¾‹æ—¶é‡åˆ°å›°éš¾ã€‚æœ¬æ–‡ä»‹ç»äº†MachineLearningLMï¼Œè¿™æ˜¯ä¸€ä¸ªä¾¿æºå¼æŒç»­é¢„è®­ç»ƒæ¡†æ¶ï¼Œæ—¨åœ¨å¢å¼ºLLMçš„ä¸Šä¸‹æ–‡æœºå™¨å­¦ä¹ ï¼ˆICLï¼‰èƒ½åŠ›ï¼ŒåŒæ—¶ä¿ç•™å…¶ä¸€èˆ¬çŸ¥è¯†å’Œæ¨ç†èƒ½åŠ›ä»¥æ”¯æŒæ›´å¹¿æ³›çš„èŠå¤©å·¥ä½œæµç¨‹ã€‚æˆ‘ä»¬çš„é¢„è®­ç»ƒç¨‹åºé€šè¿‡æ•°ç™¾ä¸‡çš„ç»“æ„åŒ–å› æœæ¨¡å‹ï¼ˆSCMï¼‰åˆæˆæœºå™¨å­¦ä¹ ä»»åŠ¡ï¼Œæ¶µç›–ç¤ºä¾‹æ•°é‡é«˜è¾¾1024ä¸ªã€‚æˆ‘ä»¬é‡‡ç”¨éšæœºæ£®æ—æ•™å¸ˆï¼Œå°†åŸºäºæ ‘çš„å†³ç­–ç­–ç•¥çŒè¾“åˆ°LLMä¸­ï¼Œä»¥åŠ å¼ºå…¶åœ¨æ•°å€¼å»ºæ¨¡ä¸­çš„ç¨³å¥æ€§ã€‚æ‰€æœ‰ä»»åŠ¡éƒ½é€šè¿‡é«˜æ•ˆçš„ä»¤ç‰Œæç¤ºè¿›è¡Œåºåˆ—åŒ–ï¼Œèƒ½å¤Ÿåœ¨æ¯ä¸ªä¸Šä¸‹æ–‡çª—å£ä¸­å¢åŠ 3å€è‡³6å€çš„ç¤ºä¾‹ï¼Œå¹¶é€šè¿‡æ‰¹é‡æ¨ç†å®ç°é«˜è¾¾50å€çš„æ‘Šé”€ååé‡ã€‚å°½ç®¡ä½¿ç”¨äº†é€‚åº¦çš„è®¾ç½®ï¼ˆQwen-2.5-7B-Instruct with LoRA rank 8ï¼‰ï¼Œä½†MachineLearningLMåœ¨è´¢åŠ¡ã€ç‰©ç†ã€ç”Ÿç‰©å’ŒåŒ»ç–—ä¿å¥é¢†åŸŸçš„ç¦»ç¾¤åˆ¶è¡¨åˆ†ç±»ä¸Šå¹³å‡ä¼˜äºå¼ºå¤§çš„LLMåŸºçº¿ï¼ˆä¾‹å¦‚GPT-5-miniï¼‰çº¦15%ã€‚å®ƒè¡¨ç°å‡ºæƒŠäººçš„å¤šç¤ºä¾‹ç¼©æ”¾å®šå¾‹ï¼šéšç€ä¸Šä¸‹æ–‡æ¼”ç¤ºä»8ä¸ªå¢é•¿åˆ°1024ä¸ªï¼Œå‡†ç¡®æ€§å•è°ƒå¢åŠ ã€‚æ— éœ€ä»»ä½•ç‰¹å®šä»»åŠ¡è®­ç»ƒï¼Œå³å¯è¾¾åˆ°éšæœºæ£®æ—çº§åˆ«çš„ç²¾åº¦ï¼ŒåŒæ—¶ä¿ç•™é€šç”¨èŠå¤©èƒ½åŠ›ï¼ŒåŒ…æ‹¬çŸ¥è¯†å’Œæ¨ç†èƒ½åŠ›ï¼Œåœ¨MMLUä¸Šè¾¾åˆ°75.4%ã€‚</p>
<p><strong>å…³é”®è§è§£</strong></p>
<ol>
<li>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨æ ‡å‡†æœºå™¨å­¦ä¹ ï¼ˆMLï¼‰ä»»åŠ¡ä¸Šå­¦ä¹ å¤šä¸ªä¸Šä¸‹æ–‡ç¤ºä¾‹æ—¶é¢ä¸´æŒ‘æˆ˜ã€‚</li>
<li>MachineLearningLMæ˜¯ä¸€ä¸ªä¾¿æºå¼æŒç»­é¢„è®­ç»ƒæ¡†æ¶ï¼Œæ—¨åœ¨å¢å¼ºLLMçš„ä¸Šä¸‹æ–‡æœºå™¨å­¦ä¹ ï¼ˆICLï¼‰èƒ½åŠ›ã€‚</li>
<li>é¢„è®­ç»ƒç¨‹åºé€šè¿‡ç»“æ„åŒ–çš„å› æœæ¨¡å‹ï¼ˆSCMï¼‰åˆæˆä»»åŠ¡ï¼Œæ¶µç›–å¹¿æ³›çš„ç¤ºä¾‹æ•°é‡ã€‚</li>
<li>ä½¿ç”¨éšæœºæ£®æ—æ•™å¸ˆæ¥å¼ºåŒ–LLMåœ¨æ•°å€¼å»ºæ¨¡ä¸­çš„ç¨³å¥æ€§ã€‚</li>
<li>MachineLearningLMé€šè¿‡æœ‰æ•ˆçš„æç¤ºåºåˆ—åŒ–ä»»åŠ¡ï¼Œå¢åŠ ä¸Šä¸‹æ–‡çª—å£ä¸­çš„ç¤ºä¾‹æ•°é‡ï¼Œå¹¶é€šè¿‡æ‰¹é‡æ¨ç†æé«˜ååé‡ã€‚</li>
<li>MachineLearningLMåœ¨å¤šä¸ªé¢†åŸŸçš„ç¦»ç¾¤åˆ¶è¡¨åˆ†ç±»ä»»åŠ¡ä¸Šä¼˜äºå…¶ä»–å¼ºå¤§çš„LLMåŸºçº¿ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.06806">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-c0d3e774d1daf77e78b5dc416047994d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-3408f1539e266d9d6f4ee243a0002b2b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-013fc1315736669373007096ac3902f8.jpg" align="middle">
</details>


<h1 id="-10"><a href="#-10" class="headerlink" title=""></a></h1><h2 id="D-HUMOR-Dark-Humor-Understanding-via-Multimodal-Open-ended-Reasoning"><a href="#D-HUMOR-Dark-Humor-Understanding-via-Multimodal-Open-ended-Reasoning" class="headerlink" title="D-HUMOR: Dark Humor Understanding via Multimodal Open-ended Reasoning"></a>D-HUMOR: Dark Humor Understanding via Multimodal Open-ended Reasoning</h2><p><strong>Authors:Sai Kartheek Reddy Kasu, Mohammad Zia Ur Rehman, Shahid Shafi Dar, Rishi Bharat Junghare, Dhanvin Sanjay Namboodiri, Nagendra Kumar</strong></p>
<p>Dark humor in online memes poses unique challenges due to its reliance on implicit, sensitive, and culturally contextual cues. To address the lack of resources and methods for detecting dark humor in multimodal content, we introduce a novel dataset of 4,379 Reddit memes annotated for dark humor, target category (gender, mental health, violence, race, disability, and other), and a three-level intensity rating (mild, moderate, severe). Building on this resource, we propose a reasoning-augmented framework that first generates structured explanations for each meme using a Large Vision-Language Model (VLM). Through a Role-Reversal Self-Loop, VLM adopts the authorâ€™s perspective to iteratively refine its explanations, ensuring completeness and alignment. We then extract textual features from both the OCR transcript and the self-refined reasoning via a text encoder, while visual features are obtained using a vision transformer. A Tri-stream Cross-Reasoning Network (TCRNet) fuses these three streams, text, image, and reasoning, via pairwise attention mechanisms, producing a unified representation for classification. Experimental results demonstrate that our approach outperforms strong baselines across three tasks: dark humor detection, target identification, and intensity prediction. The dataset, annotations, and code are released to facilitate further research in multimodal humor understanding and content moderation. Code and Dataset are available at: <a target="_blank" rel="noopener" href="https://github.com/Sai-Kartheek-Reddy/D-Humor-Dark-Humor-Understanding-via-Multimodal-Open-ended-Reasoning">https://github.com/Sai-Kartheek-Reddy/D-Humor-Dark-Humor-Understanding-via-Multimodal-Open-ended-Reasoning</a> </p>
<blockquote>
<p>ç½‘ç»œè¿·å› ä¸­çš„é»‘è‰²å¹½é»˜å› å…¶ä¾èµ–äºéšå«çš„ã€æ•æ„Ÿçš„ä»¥åŠæ–‡åŒ–èƒŒæ™¯æƒ…å¢ƒçº¿ç´¢è€Œå¸¦æ¥ç‹¬ç‰¹çš„æŒ‘æˆ˜ã€‚ä¸ºäº†è§£å†³æ£€æµ‹å¤šæ¨¡æ€å†…å®¹ä¸­é»‘è‰²å¹½é»˜çš„èµ„æºå’Œæ–¹æ³•ç¼ºä¹çš„é—®é¢˜ï¼Œæˆ‘ä»¬å¼•å…¥äº†åŒ…å«4379ä¸ªRedditè¿·å› çš„æ–°æ•°æ®é›†ï¼Œè¿™äº›è¿·å› è¢«æ ‡æ³¨ä¸ºé»‘è‰²å¹½é»˜ã€ç›®æ ‡ç±»åˆ«ï¼ˆæ€§åˆ«ã€å¿ƒç†å¥åº·ã€æš´åŠ›ã€ç§æ—ã€æ®‹ç–¾å’Œå…¶ä»–ï¼‰ä»¥åŠä¸‰çº§å¼ºåº¦è¯„çº§ï¼ˆè½»åº¦ã€ä¸­åº¦ã€é‡åº¦ï¼‰ã€‚åŸºäºè¿™ä¸€èµ„æºï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªå¢å¼ºæ¨ç†çš„æ¡†æ¶ï¼Œè¯¥æ¡†æ¶é¦–å…ˆä½¿ç”¨å¤§å‹è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMï¼‰ä¸ºæ¯ä¸ªè¿·å› ç”Ÿæˆç»“æ„åŒ–è§£é‡Šã€‚é€šè¿‡è§’è‰²åè½¬è‡ªå¾ªç¯ï¼ŒVLMé‡‡ç”¨ä½œè€…çš„è§’åº¦æ¥è¿­ä»£ä¼˜åŒ–å…¶è§£é‡Šï¼Œç¡®ä¿å®Œæ•´æ€§å’Œä¸€è‡´æ€§ã€‚ç„¶åæˆ‘ä»¬ä»OCRè½¬å½•å’Œç»è¿‡è‡ªæˆ‘ä¼˜åŒ–çš„æ¨ç†ä¸­æå–æ–‡æœ¬ç‰¹å¾ï¼Œä½¿ç”¨æ–‡æœ¬ç¼–ç å™¨è¿›è¡Œå¤„ç†ï¼ŒåŒæ—¶ä½¿ç”¨è§†è§‰å˜å‹å™¨è·å–è§†è§‰ç‰¹å¾ã€‚Tri-streamäº¤å‰æ¨ç†ç½‘ç»œï¼ˆTCRNetï¼‰é€šè¿‡é…å¯¹æ³¨æ„åŠ›æœºåˆ¶èåˆè¿™ä¸‰ä¸ªæµâ€”â€”æ–‡æœ¬ã€å›¾åƒå’Œæ¨ç†ï¼Œä¸ºåˆ†ç±»ç”Ÿæˆç»Ÿä¸€è¡¨ç¤ºã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨ä¸‰é¡¹ä»»åŠ¡ä¸Šçš„è¡¨ç°å‡ä¼˜äºå¼ºå¤§çš„åŸºçº¿ï¼šé»‘è‰²å¹½é»˜æ£€æµ‹ã€ç›®æ ‡è¯†åˆ«å’Œå¼ºåº¦é¢„æµ‹ã€‚æ•°æ®é›†ã€æ³¨é‡Šå’Œä»£ç å·²å‘å¸ƒï¼Œä»¥ä¿ƒè¿›å¤šæ¨¡æ€å¹½é»˜ç†è§£å’Œå†…å®¹å®¡æ ¸çš„è¿›ä¸€æ­¥ç ”ç©¶ã€‚ä»£ç å’Œæ•°æ®é›†å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/Sai-Kartheek-Reddy/D-Humor-Dark-Humor-Understanding-via-Multimodal-Open-ended-Reasoning%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/Sai-Kartheek-Reddy/D-Humor-Dark-Humor-Understanding-via-Multimodal-Open-ended-Reasoningæ‰¾åˆ°ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.06771v1">PDF</a> Accepted at IEEE International Conference on Data Mining (ICDM) 2025</p>
<p><strong>Summary</strong>ï¼šç½‘ç»œè¿·å› ä¸­çš„é»‘è‰²å¹½é»˜å¸¦æ¥äº†ç‹¬ç‰¹çš„æŒ‘æˆ˜ï¼Œå› ä¸ºå…¶ä¾èµ–äºéšæ™¦ã€æ•æ„Ÿå’Œæ–‡åŒ–èƒŒæ™¯çš„çº¿ç´¢ã€‚ä¸ºåº”å¯¹å¤šæ¨¡å¼å†…å®¹ä¸­ç¼ºä¹æ£€æµ‹é»‘è‰²å¹½é»˜çš„èµ„æºå’Œæ–¹æ³•ï¼Œæˆ‘ä»¬å¼•å…¥äº†å«æœ‰4379ä¸ªRedditè¿·å› çš„æ–°æ•°æ®é›†ï¼Œå¹¶å¯¹å…¶è¿›è¡Œäº†é»‘è‰²å¹½é»˜ã€ç›®æ ‡ç±»åˆ«ï¼ˆå¦‚æ€§åˆ«ã€å¿ƒç†å¥åº·ã€æš´åŠ›ç­‰ï¼‰å’Œä¸‰çº§å¼ºåº¦è¯„åˆ†çš„æ ‡æ³¨ã€‚åŸºäºè¿™ä¸€èµ„æºï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªæ¨ç†å¢å¼ºæ¡†æ¶ï¼Œé¦–å…ˆä½¿ç”¨å¤§å‹è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMï¼‰ä¸ºæ¯ä¸ªè¿·å› ç”Ÿæˆç»“æ„åŒ–è§£é‡Šã€‚é€šè¿‡è§’è‰²åè½¬è‡ªæˆ‘å¾ªç¯ï¼ŒVLMé‡‡ç”¨ä½œè€…è§†è§’è¿›è¡Œè¿­ä»£ä¼˜åŒ–è§£é‡Šï¼Œç¡®ä¿å®Œæ•´æ€§å’Œä¸€è‡´æ€§ã€‚ç„¶åæˆ‘ä»¬ä»OCRè½¬å½•å’Œè‡ªæˆ‘ä¼˜åŒ–çš„æ¨ç†ä¸­æå–æ–‡æœ¬ç‰¹å¾ï¼ŒåŒæ—¶ä½¿ç”¨è§†è§‰å˜æ¢å™¨è·å–å›¾åƒç‰¹å¾ã€‚ä¸‰æµäº¤å‰æ¨ç†ç½‘ç»œï¼ˆTCRNetï¼‰é€šè¿‡é…å¯¹æ³¨æ„åŠ›æœºåˆ¶èåˆè¿™ä¸‰ä¸ªæµï¼ˆæ–‡æœ¬ã€å›¾åƒå’Œæ¨ç†ï¼‰ï¼Œäº§ç”Ÿç»Ÿä¸€è¡¨ç¤ºç”¨äºåˆ†ç±»ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨ä¸‰é¡¹ä»»åŠ¡ä¸Šçš„è¡¨ç°å‡ä¼˜äºå¼ºå¤§çš„åŸºçº¿ï¼šé»‘è‰²å¹½é»˜æ£€æµ‹ã€ç›®æ ‡è¯†åˆ«å’Œå¼ºåº¦é¢„æµ‹ã€‚æ•°æ®é›†ã€æ³¨é‡Šå’Œä»£ç å·²å‘å¸ƒï¼Œä»¥ä¿ƒè¿›å¤šæ¨¡å¼å¹½é»˜ç†è§£å’Œå†…å®¹å®¡æ ¸çš„è¿›ä¸€æ­¥ç ”ç©¶ã€‚ä»£ç å’Œæ•°æ®é›†å¯é€šè¿‡é“¾æ¥è®¿é—®ï¼š[é“¾æ¥åœ°å€]ã€‚</p>
<p><strong>Key Takeaways</strong>:</p>
<ol>
<li>ç½‘ç»œè¿·å› ä¸­çš„é»‘è‰²å¹½é»˜å› å…¶éšæ™¦å’Œæ–‡åŒ–èƒŒæ™¯ä¾èµ–æ€§è€Œå…·æœ‰ç‹¬ç‰¹æŒ‘æˆ˜ã€‚</li>
<li>ä¸ºè§£å†³å¤šæ¨¡å¼å†…å®¹ä¸­æ£€æµ‹é»‘è‰²å¹½é»˜çš„é—®é¢˜ï¼Œå¼•å…¥äº†æ ‡æ³¨åŒ–çš„Redditè¿·å› æ•°æ®é›†ã€‚</li>
<li>å¼•å…¥äº†ä¸€ä¸ªç»“åˆè§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMï¼‰ã€æ–‡æœ¬ç¼–ç å™¨å’Œè§†è§‰è½¬æ¢å™¨çš„æ¨ç†å¢å¼ºæ¡†æ¶æ¥ç†è§£å’Œæ£€æµ‹é»‘è‰²å¹½é»˜ã€‚</li>
<li>è¯¥æ¡†æ¶åŒ…å«ç»“æ„è§£é‡Šç”Ÿæˆã€è§’è‰²åè½¬è‡ªæˆ‘å¾ªç¯ä»¥åŠæ–‡æœ¬å’Œå›¾åƒç‰¹å¾çš„æå–ä¸èåˆã€‚</li>
<li>ä¸‰æµäº¤å‰æ¨ç†ç½‘ç»œï¼ˆTCRNetï¼‰é€šè¿‡é…å¯¹æ³¨æ„åŠ›æœºåˆ¶æ•´åˆæ–‡æœ¬ã€å›¾åƒå’Œæ¨ç†ä¿¡æ¯ï¼Œæé«˜åˆ†ç±»æ€§èƒ½ã€‚</li>
<li>å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•åœ¨é»‘è‰²å¹½é»˜æ£€æµ‹ã€ç›®æ ‡è¯†åˆ«å’Œå¼ºåº¦é¢„æµ‹ä»»åŠ¡ä¸Šè¡¨ç°ä¼˜è¶Šã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.06771">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-b832b8b77e12206e7376053a13a8c827.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-843655c561e35991dfed60b2f21935a1.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-5663850bbb5df4066a8994a4095d679e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c79030b61d3448278373e3c34478272c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-fa25bcc0a65db8b7461b8ee903411e9c.jpg" align="middle">
</details>


<h1 id="-11"><a href="#-11" class="headerlink" title=""></a></h1><h2 id="Another-Turn-Better-Output-A-Turn-Wise-Analysis-of-Iterative-LLM-Prompting"><a href="#Another-Turn-Better-Output-A-Turn-Wise-Analysis-of-Iterative-LLM-Prompting" class="headerlink" title="Another Turn, Better Output? A Turn-Wise Analysis of Iterative LLM   Prompting"></a>Another Turn, Better Output? A Turn-Wise Analysis of Iterative LLM   Prompting</h2><p><strong>Authors:Shashidhar Reddy Javaji, Bhavul Gauri, Zining Zhu</strong></p>
<p>Large language models (LLMs) are now used in multi-turn workflows, but we still lack a clear way to measure when iteration helps and when it hurts. We present an evaluation framework for iterative refinement that spans ideation, code, and math. Our protocol runs controlled 12-turn conversations per task, utilizing a variety of prompts ranging from vague &#96;&#96;improve itâ€™â€™ feedback to targeted steering, and logs per-turn outputs. We score outcomes with domain-appropriate checks (unit tests for code; answer-equivalence plus reasoning-soundness for math; originality and feasibility for ideation) and track turn-level behavior with three families of metrics: semantic movement across turns, turn-to-turn change, and output size growth. Across models and tasks, gains are domain-dependent: they arrive early in ideas and code, but in math late turns matter when guided by elaboration. After the first few turns, vague feedback often plateaus or reverses correctness, while targeted prompts reliably shift the intended quality axis (novelty vs. feasibility in ideation; speed vs. readability in code; in math, elaboration outperforms exploration and drives late-turn gains). We also observe consistent domain patterns: ideation moves more in meaning across turns, code tends to grow in size with little semantic change, and math starts fixed but can break that path with late, elaborative iteration.Together, the framework and metrics make iteration measurable and comparable across models, and signal when to steer, stop, or switch strategies. </p>
<blockquote>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ç°åœ¨å·²åº”ç”¨äºå¤šè½®æ¬¡å·¥ä½œæµç¨‹ä¸­ï¼Œä½†æˆ‘ä»¬ä»ç¼ºä¹æ˜ç¡®çš„è¡¡é‡æ–¹æ³•æ¥åˆ¤æ–­è¿­ä»£ä½•æ—¶æœ‰å¸®åŠ©ï¼Œä½•æ—¶ä¼šé€ æˆé˜»ç¢ã€‚æˆ‘ä»¬æå‡ºä¸€ä¸ªè¯„ä¼°è¿­ä»£ç²¾åŒ–çš„æ¡†æ¶ï¼Œè¯¥æ¡†æ¶æ¶µç›–åˆ›æ„ã€ä»£ç å’Œæ•°å­¦ã€‚æˆ‘ä»¬çš„åè®®é’ˆå¯¹æ¯ä¸ªä»»åŠ¡è¿è¡Œå—æ§çš„12è½®å¯¹è¯ï¼Œåˆ©ç”¨å„ç§æç¤ºï¼Œä»æ¨¡ç³Šçš„â€œæ”¹è¿›å®ƒâ€åé¦ˆåˆ°æœ‰é’ˆå¯¹æ€§çš„æŒ‡å¯¼ï¼Œå¹¶è®°å½•æ¯è½®çš„è¾“å±±ã€‚æˆ‘ä»¬ä½¿ç”¨é€‚åˆé¢†åŸŸçš„æ£€æŸ¥æ¥è¯„åˆ†ç»“æœï¼ˆä»£ç çš„å•å…ƒæµ‹è¯•ï¼›æ•°å­¦çš„ç­”æ¡ˆç­‰ä»·æ€§åŠ ä¸Šæ¨ç†åˆç†æ€§ï¼›åˆ›æ„çš„æ–°é¢–æ€§å’Œå¯è¡Œæ€§ï¼‰ï¼Œå¹¶é€šè¿‡ä¸‰ä¸ªå®¶æ—çš„æŒ‡æ ‡è·Ÿè¸ªè½®æ¬¡è¡Œä¸ºï¼šå„è½®ä¹‹é—´çš„è¯­ä¹‰å˜åŒ–ã€è½®æ¬¡å˜åŒ–ä»¥åŠè¾“å‡ºå¤§å°å¢é•¿ã€‚åœ¨ä¸åŒçš„æ¨¡å‹å’Œä»»åŠ¡ä¸­ï¼Œæ”¶ç›Šæ˜¯ä¾èµ–äºé¢†åŸŸçš„ï¼šå®ƒä»¬åœ¨åˆ›æ„å’Œä»£ç çš„æ—©æœŸé˜¶æ®µå°±åˆ°è¾¾äº†ï¼Œä½†åœ¨æ•°å­¦æ–¹é¢ï¼ŒåæœŸçš„è½®æ¬¡å¾ˆé‡è¦ï¼Œåœ¨è¯¦ç»†æŒ‡å¯¼çš„æƒ…å†µä¸‹æ›´æ˜¯å¦‚æ­¤ã€‚ç»è¿‡å‰å‡ è½®åï¼Œæ¨¡ç³Šçš„åé¦ˆé€šå¸¸ä¼šè¾¾åˆ°å¹³å°æœŸæˆ–ä½¿æ­£ç¡®æ€§é€†è½¬ï¼Œè€Œæœ‰é’ˆå¯¹æ€§çš„æç¤ºä¼šå¯é åœ°æ”¹å˜é¢„æœŸçš„è´¨è½´ï¼ˆåˆ›æ„ä¸­çš„æ–°é¢–æ€§å¯¹å¯è¡Œæ€§çš„è½¬å˜ï¼›ä»£ç ä¸­çš„é€Ÿåº¦ä¸å¯è¯»æ€§çš„è½¬å˜ï¼›åœ¨æ•°å­¦ä¸­ï¼Œè¯¦ç»†çš„è¿­ä»£èƒœè¿‡æ¢ç´¢å¹¶æ¨åŠ¨åæœŸçš„æ”¶ç›Šï¼‰ã€‚æˆ‘ä»¬è¿˜è§‚å¯Ÿåˆ°ä¸€è‡´çš„åŒºåŸŸæ¨¡å¼ï¼šåˆ›æ„åœ¨å‡ è½®ä¹‹é—´çš„æ„ä¹‰å˜åŠ¨æ›´å¤§ï¼Œä»£ç çš„å¤§å°å¾€å¾€ä¼šå¢åŠ ä½†è¯­ä¹‰å˜åŒ–å¾ˆå°ï¼Œæ•°å­¦ä¸€å¼€å§‹æ˜¯å›ºå®šçš„ï¼Œä½†å¯ä»¥é€šè¿‡åæœŸçš„ç²¾ç»†è¿­ä»£æ¥æ‰“ç ´è¿™ç§æ¨¡å¼ã€‚æ€»ä¹‹ï¼Œè¯¥æ¡†æ¶å’ŒæŒ‡æ ‡ä½¿è¿­ä»£èƒ½å¤Ÿåœ¨ä¸åŒçš„æ¨¡å‹ä¸­è¿›è¡Œåº¦é‡å¹¶ç›¸äº’æ¯”è¾ƒï¼Œå¹¶æŒ‡ç¤ºä½•æ—¶éœ€è¦è°ƒæ•´æ–¹å‘ã€åœæ­¢æˆ–æ”¹å˜ç­–ç•¥ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.06770v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å¤šè½®å¯¹è¯ä¸­çš„åº”ç”¨æ—¥ç›Šå¹¿æ³›ï¼Œä½†å¦‚ä½•è¯„ä¼°è¿­ä»£çš„æ•ˆæœä»ç„¶ä¸æ˜ç¡®ã€‚æœ¬ç ”ç©¶æå‡ºäº†ä¸€å¥—è¯„ä¼°è¿­ä»£ç²¾åŒ–çš„æ¡†æ¶ï¼Œæ¶µç›–æ„æ€ã€ç¼–ç å’Œæ•°å­¦ç­‰é¢†åŸŸã€‚è¯¥åè®®è¿›è¡Œæ¯é¡¹ä»»åŠ¡12è½®å¯¹è¯çš„å—æ§å®éªŒï¼Œåˆ©ç”¨å„ç§æç¤ºæ¥æ”¹è¿›ï¼Œå¹¶è®°å½•æ¯è½®çš„äº§å‡ºã€‚æˆ‘ä»¬é‡‡ç”¨é¢†åŸŸé€‚å½“çš„æ£€æŸ¥æ–¹æ³•æ¥è¯„åˆ†ç»“æœï¼Œå¹¶è·Ÿè¸ªè½®æ¬¡çš„è¡Œä¸ºå˜åŒ–ã€‚åœ¨ä¸åŒæ¨¡å‹å’Œä»»åŠ¡ä¸­ï¼Œæ”¶ç›Šæ˜¯é¢†åŸŸä¾èµ–çš„ï¼šåœ¨æƒ³æ³•å’Œç¼–ç æ–¹é¢æ—©æœŸåˆ°è¾¾ï¼Œä½†åœ¨æ•°å­¦æ–¹é¢åæœŸè½®æ¬¡å¾ˆé‡è¦ã€‚æœ¬ç ”ç©¶è¿˜è§‚å¯Ÿåˆ°ä¸€è‡´é¢†åŸŸæ¨¡å¼ï¼šåœ¨å¯¹è¯ä¸­ï¼Œæ„æ€çš„æ„ä¹‰å˜åŒ–æ›´å¤§ï¼Œä»£ç å¤§å°å¢é•¿ä½†è¯­ä¹‰å˜åŒ–è¾ƒå°ï¼Œæ•°å­¦å¼€å§‹æ—¶å›ºå®šä½†åæœŸç²¾ç»†è¿­ä»£å¯æ‰“ç ´å¸¸è§„è·¯å¾„ã€‚æ€»ä¹‹ï¼Œè¯¥æ¡†æ¶å’ŒæŒ‡æ ‡ä½¿è¿­ä»£å¯è¡¡é‡å’Œæ¯”è¾ƒä¸åŒæ¨¡å‹çš„æ•ˆæœï¼Œå¹¶æç¤ºä½•æ—¶éœ€è¦è°ƒæ•´ç­–ç•¥ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å¤šè½®å¯¹è¯å·¥ä½œæµä¸­çš„å¹¿æ³›åº”ç”¨åŠå…¶è¿­ä»£çš„è¯„ä¼°é‡è¦æ€§ã€‚</li>
<li>æå‡ºçš„è¯„ä¼°è¿­ä»£ç²¾åŒ–çš„æ¡†æ¶æ¶µç›–æ„æ€ã€ç¼–ç å’Œæ•°å­¦ç­‰é¢†åŸŸã€‚</li>
<li>é€šè¿‡å—æ§å®éªŒè¿›è¡Œæ¯é¡¹ä»»åŠ¡çš„12è½®å¯¹è¯ï¼Œåˆ©ç”¨ä¸åŒæç¤ºè¿›è¡Œæ”¹è¿›ï¼Œå¹¶è®°å½•æ¯è½®äº§å‡ºã€‚</li>
<li>æ”¶ç›Šæ˜¯é¢†åŸŸä¾èµ–çš„ï¼Œåœ¨æƒ³æ³•å’Œç¼–ç æ–¹é¢æ—©æœŸåˆ°è¾¾ï¼Œæ•°å­¦æ–¹é¢åæœŸè½®æ¬¡å¾ˆé‡è¦ã€‚</li>
<li>é’ˆå¯¹ä¸åŒé¢†åŸŸå­˜åœ¨ä¸€è‡´çš„æ¨¡å¼ï¼šæ„æ€åœ¨å¯¹è¯ä¸­æ„ä¹‰å˜åŒ–æ›´å¤§ï¼Œä»£ç å¤§å°å¢é•¿ä½†è¯­ä¹‰å˜åŒ–è¾ƒå°ï¼Œæ•°å­¦éœ€è¦åæœŸç²¾ç»†è¿­ä»£ã€‚</li>
<li>é‡‡ç”¨é¢†åŸŸé€‚å½“çš„æ£€æŸ¥æ–¹æ³•æ¥è¯„åˆ†ç»“æœï¼Œå¹¶è·Ÿè¸ªè½®æ¬¡çš„è¡Œä¸ºå˜åŒ–ï¼ŒåŒ…æ‹¬è¯­ä¹‰ç§»åŠ¨ã€è½®æ¬¡å˜åŒ–å’Œäº§å‡ºå¢é•¿ç­‰æŒ‡æ ‡ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.06770">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-62a6160d1017ed0cdb87a5ad260a481e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e8b338c2aaaed69f661fa67192e0d4a1.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-8ffdb59e62953676c322e137f9b79963.jpg" align="middle">
</details>


<h1 id="-12"><a href="#-12" class="headerlink" title=""></a></h1><h2 id="Aligning-Large-Vision-Language-Models-by-Deep-Reinforcement-Learning-and-Direct-Preference-Optimization"><a href="#Aligning-Large-Vision-Language-Models-by-Deep-Reinforcement-Learning-and-Direct-Preference-Optimization" class="headerlink" title="Aligning Large Vision-Language Models by Deep Reinforcement Learning and   Direct Preference Optimization"></a>Aligning Large Vision-Language Models by Deep Reinforcement Learning and   Direct Preference Optimization</h2><p><strong>Authors:Thanh Thi Nguyen, Campbell Wilson, Janis Dalins</strong></p>
<p>Large Vision-Language Models (LVLMs) or multimodal large language models represent a significant advancement in artificial intelligence, enabling systems to understand and generate content across both visual and textual modalities. While large-scale pretraining has driven substantial progress, fine-tuning these models for aligning with human values or engaging in specific tasks or behaviors remains a critical challenge. Deep Reinforcement Learning (DRL) and Direct Preference Optimization (DPO) offer promising frameworks for this aligning process. While DRL enables models to optimize actions using reward signals instead of relying solely on supervised preference data, DPO directly aligns the policy with preferences, eliminating the need for an explicit reward model. This overview explores paradigms for fine-tuning LVLMs, highlighting how DRL and DPO techniques can be used to align models with human preferences and values, improve task performance, and enable adaptive multimodal interaction. We categorize key approaches, examine sources of preference data, reward signals, and discuss open challenges such as scalability, sample efficiency, continual learning, generalization, and safety. The goal is to provide a clear understanding of how DRL and DPO contribute to the evolution of robust and human-aligned LVLMs. </p>
<blockquote>
<p>å¤§å‹è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆLVLMsï¼‰æˆ–å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹åœ¨äººå·¥æ™ºèƒ½æ–¹é¢ä»£è¡¨äº†é‡å¤§çš„è¿›æ­¥ï¼Œä½¿ç³»ç»Ÿèƒ½å¤Ÿç†è§£å’Œç”Ÿæˆè§†è§‰å’Œæ–‡æœ¬ä¸¤ç§æ¨¡å¼çš„å†…å®¹ã€‚è™½ç„¶å¤§è§„æ¨¡é¢„è®­ç»ƒå·²ç»å–å¾—äº†å®è´¨æ€§çš„è¿›å±•ï¼Œä½†é’ˆå¯¹ç¬¦åˆäººç±»ä»·å€¼è§‚æˆ–å¯¹ç‰¹å®šä»»åŠ¡æˆ–è¡Œä¸ºè¿›è¡Œå¾®è°ƒè¿™äº›æ¨¡å‹ä»ç„¶æ˜¯ä¸€ä¸ªå…³é”®æŒ‘æˆ˜ã€‚æ·±åº¦å¼ºåŒ–å­¦ä¹ ï¼ˆDRLï¼‰å’Œç›´æ¥åå¥½ä¼˜åŒ–ï¼ˆDPOï¼‰ä¸ºè¿™ä¸€å¯¹é½è¿‡ç¨‹æä¾›äº†æœ‰å‰æ™¯çš„æ¡†æ¶ã€‚è™½ç„¶DRLèƒ½å¤Ÿä½¿æ¨¡å‹ä½¿ç”¨å¥–åŠ±ä¿¡å·ä¼˜åŒ–è¡ŒåŠ¨ï¼Œè€Œä¸æ˜¯ä»…ä»…ä¾èµ–äºç›‘ç£åå¥½æ•°æ®ï¼Œä½†DPOç›´æ¥å¯¹é½æ”¿ç­–ä¸åå¥½ï¼Œä»è€Œä¸éœ€è¦æ˜ç¡®çš„å¥–åŠ±æ¨¡å‹ã€‚æœ¬æ–‡æ¦‚è¿°äº†å¾®è°ƒLVLMsçš„æ¨¡å¼ï¼Œé‡ç‚¹ä»‹ç»äº†å¦‚ä½•ä½¿ç”¨DRLå’ŒDPOæŠ€æœ¯ä½¿æ¨¡å‹ä¸äººç±»åå¥½å’Œä»·å€¼è§‚å¯¹é½ï¼Œæé«˜ä»»åŠ¡æ€§èƒ½ï¼Œå¹¶å®ç°è‡ªé€‚åº”å¤šæ¨¡å¼äº¤äº’ã€‚æˆ‘ä»¬å¯¹å…³é”®æ–¹æ³•è¿›è¡Œåˆ†ç±»ï¼Œæ£€æŸ¥åå¥½æ•°æ®ã€å¥–åŠ±ä¿¡å·çš„æ¥æºï¼Œå¹¶è®¨è®ºå¼€æ”¾æŒ‘æˆ˜ï¼Œå¦‚å¯æ‰©å±•æ€§ã€æ ·æœ¬æ•ˆç‡ã€æŒç»­å­¦ä¹ ã€æ¨å¹¿å’Œå®‰å…¨æ€§ã€‚ç›®æ ‡æ˜¯æä¾›å¯¹DRLå’ŒDPOå¦‚ä½•æ¨åŠ¨ç¨³å¥å’Œç¬¦åˆäººç±»ä»·å€¼è§‚çš„LVLMsçš„è¿›åŒ–æœ‰ä¸€ä¸ªæ¸…æ™°çš„ç†è§£ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.06759v1">PDF</a> Accepted for publication in the Proceedings of the 8th International   Conference on Algorithms, Computing and Artificial Intelligence (ACAI 2025)</p>
<p><strong>Summary</strong></p>
<p>å¤§å‹è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆLVLMsï¼‰çš„è¿›æ­¥æ˜¾è‘—ï¼Œèƒ½å¤Ÿç†è§£å’Œç”Ÿæˆè·¨è§†è§‰å’Œæ–‡æœ¬æ¨¡æ€çš„å†…å®¹ã€‚è™½ç„¶å¤§è§„æ¨¡é¢„è®­ç»ƒå–å¾—äº†æ˜¾è‘—è¿›å±•ï¼Œä½†å¦‚ä½•å¾®è°ƒè¿™äº›æ¨¡å‹ä»¥ç¬¦åˆäººç±»ä»·å€¼è§‚ã€æ‰§è¡Œä»»åŠ¡æˆ–è¡Œä¸ºä»ç„¶æ˜¯ä¸€ä¸ªå…³é”®æŒ‘æˆ˜ã€‚æ·±åº¦å¼ºåŒ–å­¦ä¹ ï¼ˆDRLï¼‰å’Œç›´æ¥åå¥½ä¼˜åŒ–ï¼ˆDPOï¼‰ä¸ºè¿™ä¸€å¯¹é½è¿‡ç¨‹æä¾›äº†æœ‰å‰æ™¯çš„æ¡†æ¶ã€‚DRLä½¿ç”¨å¥–åŠ±ä¿¡å·ä¼˜åŒ–æ¨¡å‹è¡Œä¸ºï¼Œè€ŒDPOç›´æ¥å¯¹é½æ”¿ç­–ä¸åå¥½ï¼Œæ— éœ€æ˜ç¡®çš„å¥–åŠ±æ¨¡å‹ã€‚æœ¬æ–‡æ¢è®¨äº†å¾®è°ƒLVLMsçš„æ¨¡å¼ï¼Œé‡ç‚¹ä»‹ç»å¦‚ä½•ä½¿ç”¨DRLå’ŒDPOæŠ€æœ¯å¯¹é½æ¨¡å‹ä¸äººç±»åå¥½å’Œä»·å€¼è§‚ï¼Œæé«˜ä»»åŠ¡æ€§èƒ½ï¼Œå¹¶ä¿ƒè¿›è‡ªé€‚åº”å¤šæ¨¡å¼äº¤äº’ã€‚æœ¬æ–‡åˆ†ç±»äº†å…³é”®æ–¹æ³•ï¼Œæ£€éªŒäº†åå¥½æ•°æ®æ¥æºå’Œå¥–åŠ±ä¿¡å·ï¼Œå¹¶è®¨è®ºäº†å¼€æ”¾æŒ‘æˆ˜ï¼Œå¦‚å¯æ‰©å±•æ€§ã€æ ·æœ¬æ•ˆç‡ã€æŒç»­å­¦ä¹ ã€æ³›åŒ–å’Œå®‰å…¨æ€§ã€‚ç›®æ ‡æ˜¯æä¾›å¯¹DRLå’ŒDPOå¦‚ä½•æ¨åŠ¨ç¨³å¥å’Œäººç±»å¯¹é½LVLMsçš„æ¸…æ™°ç†è§£ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤§å‹è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆLVLMsï¼‰èƒ½å¤Ÿç†è§£å’Œç”Ÿæˆè·¨è§†è§‰å’Œæ–‡æœ¬æ¨¡æ€çš„å†…å®¹ï¼Œæ˜¯äººå·¥æ™ºèƒ½é¢†åŸŸçš„é‡å¤§è¿›å±•ã€‚</li>
<li>æ·±åº¦å¼ºåŒ–å­¦ä¹ ï¼ˆDRLï¼‰å’Œç›´æ¥åå¥½ä¼˜åŒ–ï¼ˆDPOï¼‰ä¸ºå¯¹é½LVLMsä¸äººç±»ä»·å€¼è§‚æä¾›äº†æœ‰å‰é€”çš„æ¡†æ¶ã€‚</li>
<li>DRLé€šè¿‡ä½¿ç”¨å¥–åŠ±ä¿¡å·ä¼˜åŒ–æ¨¡å‹è¡Œä¸ºï¼Œè€ŒDPOç›´æ¥å¯¹é½æ¨¡å‹æ”¿ç­–ä¸åå¥½ï¼Œä¸¤è€…å‡æœ‰åŠ©äºæ”¹è¿›æ¨¡å‹æ€§èƒ½ã€‚</li>
<li>æ–‡æœ¬æ¢è®¨äº†å¾®è°ƒLVLMsçš„ä¸åŒæ–¹æ³•ï¼ŒåŒ…æ‹¬ä½¿ç”¨DRLå’ŒDPOæŠ€æœ¯ã€‚</li>
<li>å¯¹é½è¿‡ç¨‹ä¸­å­˜åœ¨å¤šä¸ªå¼€æ”¾æŒ‘æˆ˜ï¼Œå¦‚å¯æ‰©å±•æ€§ã€æ ·æœ¬æ•ˆç‡ã€æŒç»­å­¦ä¹ ã€æ³›åŒ–å’Œå®‰å…¨æ€§ã€‚</li>
<li>åå¥½æ•°æ®æ¥æºå’Œå¥–åŠ±ä¿¡å·çš„æ£€éªŒå¯¹äºæ”¹è¿›LVLMsçš„æ€§èƒ½è‡³å…³é‡è¦ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.06759">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-ef4d9e8f8988a9378f1dbe023e98186b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-cde6417acce7d8ba1be0de05dae003f1.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-4de44372b0905c5d7bb2b25b753aad27.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-edc5f14f2149b7177ec4a75a9570cb18.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-45afd0cd6547b00acfb721094cc6e103.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-5556bb3109e499b27d598304159d5553.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-1445955f7f071ccd2fd63dea5dbc6d02.jpg" align="middle">
</details>


<h1 id="-13"><a href="#-13" class="headerlink" title=""></a></h1><h2 id="Domain-Aware-RAG-MoL-Enhanced-RL-for-Efficient-Training-and-Scalable-Retrieval"><a href="#Domain-Aware-RAG-MoL-Enhanced-RL-for-Efficient-Training-and-Scalable-Retrieval" class="headerlink" title="Domain-Aware RAG: MoL-Enhanced RL for Efficient Training and Scalable   Retrieval"></a>Domain-Aware RAG: MoL-Enhanced RL for Efficient Training and Scalable   Retrieval</h2><p><strong>Authors:Hao Lin, Peitong Xie, Jingxue Chen, Jie Lin, Qingkun Tang, Qianchun Lu</strong></p>
<p>Retrieval-Augmented Generation (RAG) systems rely heavily on the retrieval stage, particularly the coarse-ranking process. Existing coarse-ranking optimization approaches often struggle to balance domain-specific knowledge learning with query enhencement, resulting in suboptimal retrieval performance. To address this challenge, we propose MoLER, a domain-aware RAG method that uses MoL-Enhanced Reinforcement Learning to optimize retrieval. MoLER has a two-stage pipeline: a continual pre-training (CPT) phase using a Mixture of Losses (MoL) to balance domain-specific knowledge with general language capabilities, and a reinforcement learning (RL) phase leveraging Group Relative Policy Optimization (GRPO) to optimize query and passage generation for maximizing document recall. A key innovation is our Multi-query Single-passage Late Fusion (MSLF) strategy, which reduces computational overhead during RL training while maintaining scalable inference via Multi-query Multi-passage Late Fusion (MMLF). Extensive experiments on benchmark datasets show that MoLER achieves state-of-the-art performance, significantly outperforming baseline methods. MoLER bridges the knowledge gap in RAG systems, enabling robust and scalable retrieval in specialized domains. </p>
<blockquote>
<p>æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰ç³»ç»Ÿå¾ˆå¤§ç¨‹åº¦ä¸Šä¾èµ–äºæ£€ç´¢é˜¶æ®µï¼Œç‰¹åˆ«æ˜¯ç²—ç•¥æ’åºè¿‡ç¨‹ã€‚ç°æœ‰çš„ç²—ç•¥æ’åºä¼˜åŒ–æ–¹æ³•å¾€å¾€å¾ˆéš¾åœ¨é¢†åŸŸç‰¹å®šçŸ¥è¯†å­¦ä¹ ä¸æŸ¥è¯¢å¢å¼ºä¹‹é—´å–å¾—å¹³è¡¡ï¼Œå¯¼è‡´æ£€ç´¢æ€§èƒ½ä¸ä½³ã€‚ä¸ºäº†è§£å†³è¿™ä¸€æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†MoLERï¼Œä¸€ç§ä½¿ç”¨MoLå¢å¼ºå‹å¼ºåŒ–å­¦ä¹ è¿›è¡Œä¼˜åŒ–çš„é¢†åŸŸæ„ŸçŸ¥RAGæ–¹æ³•ã€‚MoLERå…·æœ‰ä¸¤é˜¶æ®µç®¡é“ï¼šä½¿ç”¨æŸå¤±æ··åˆï¼ˆMoLï¼‰å¹³è¡¡é¢†åŸŸç‰¹å®šçŸ¥è¯†ä¸é€šç”¨è¯­è¨€èƒ½åŠ›çš„æŒç»­é¢„è®­ç»ƒï¼ˆCPTï¼‰é˜¶æ®µï¼Œä»¥åŠåˆ©ç”¨ç¾¤ä½“ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–ï¼ˆGRPOï¼‰ä¼˜åŒ–æŸ¥è¯¢å’Œæ®µè½ç”Ÿæˆä»¥æœ€å¤§åŒ–æ–‡æ¡£å¬å›ç‡çš„å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰é˜¶æ®µã€‚ä¸€ä¸ªå…³é”®çš„åˆ›æ–°æ˜¯æˆ‘ä»¬çš„å¤šæŸ¥è¯¢å•æ®µè½åæœŸèåˆï¼ˆMSLFï¼‰ç­–ç•¥ï¼Œå®ƒåœ¨å‡å°‘RLè®­ç»ƒè¿‡ç¨‹ä¸­çš„è®¡ç®—å¼€é”€çš„åŒæ—¶ï¼Œé€šè¿‡å¤šæŸ¥è¯¢å¤šæ®µè½åæœŸèåˆï¼ˆMMLFï¼‰ä¿æŒå¯æ‰©å±•çš„æ¨ç†ã€‚åœ¨åŸºå‡†æ•°æ®é›†ä¸Šçš„å¤§é‡å®éªŒè¡¨æ˜ï¼ŒMoLERè¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œæ˜¾è‘—ä¼˜äºåŸºå‡†æ–¹æ³•ã€‚MoLERç¼©å°äº†RAGç³»ç»Ÿä¸­çš„çŸ¥è¯†å·®è·ï¼Œå®ç°äº†ä¸“ä¸šé¢†åŸŸçš„ç¨³å¥å’Œå¯æ‰©å±•çš„æ£€ç´¢ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.06650v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>RAGç³»ç»Ÿä¸¥é‡ä¾èµ–äºæ£€ç´¢é˜¶æ®µï¼Œç‰¹åˆ«æ˜¯ç²—æ’è¿‡ç¨‹ã€‚ä¸ºåº”å¯¹ç°æœ‰ç²—æ’ä¼˜åŒ–æ–¹æ³•åœ¨é¢†åŸŸç‰¹å®šçŸ¥è¯†å­¦ä¹ ä¸æŸ¥è¯¢å¢å¼ºä¹‹é—´çš„å¹³è¡¡æŒ‘æˆ˜ï¼Œæå‡ºMoLERæ–¹æ³•ï¼Œé‡‡ç”¨MoLå¢å¼ºçš„å¼ºåŒ–å­¦ä¹ ä¼˜åŒ–æ£€ç´¢ã€‚MoLERåŒ…å«ä¸¤é˜¶æ®µï¼šä½¿ç”¨æŸå¤±æ··åˆï¼ˆMoLï¼‰çš„æŒç»­é¢„è®­ç»ƒï¼ˆCPTï¼‰å¹³è¡¡é¢†åŸŸç‰¹å®šçŸ¥è¯†ä¸é€šç”¨è¯­è¨€èƒ½åŠ›ï¼Œä»¥åŠåˆ©ç”¨ç¾¤ä½“ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–ï¼ˆGRPOï¼‰çš„å¼ºåŒ–å­¦ä¹ é˜¶æ®µï¼Œä¼˜åŒ–æŸ¥è¯¢å’Œæ®µè½ç”Ÿæˆä»¥æœ€å¤§åŒ–æ–‡æ¡£å¬å›ã€‚åˆ›æ–°ç‚¹åŒ…æ‹¬å¤šæŸ¥è¯¢å•æ®µè½åæœŸèåˆï¼ˆMSLFï¼‰ç­–ç•¥ï¼Œå‡å°‘å¼ºåŒ–å­¦ä¹ è®­ç»ƒä¸­çš„è®¡ç®—å¼€é”€ï¼ŒåŒæ—¶é€šè¿‡å¤šæŸ¥è¯¢å¤šæ®µè½åæœŸèåˆï¼ˆMMLFï¼‰å®ç°å¯æ‰©å±•æ¨ç†ã€‚å®éªŒè¡¨æ˜ï¼ŒMoLERåœ¨åŸºå‡†æ•°æ®é›†ä¸Šå–å¾—äº†æœ€æ–°æ€§èƒ½ï¼Œæ˜¾è‘—ä¼˜äºåŸºçº¿æ–¹æ³•ï¼Œä¸ºRAGç³»ç»Ÿä¸­çš„çŸ¥è¯†å·®è·æ­å»ºæ¡¥æ¢ï¼Œå®ç°ç¨³å¥ä¸”å¯æ‰©å±•çš„ç‰¹å®šé¢†åŸŸæ£€ç´¢ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>RAGç³»ç»Ÿä¾èµ–æ£€ç´¢é˜¶æ®µï¼Œç‰¹åˆ«æ˜¯ç²—æ’è¿‡ç¨‹ã€‚</li>
<li>ç°æœ‰æ–¹æ³•éš¾å¹³è¡¡é¢†åŸŸçŸ¥è¯†ä¸æŸ¥è¯¢å¢å¼ºã€‚</li>
<li>MoLERé‡‡ç”¨MoLå¢å¼ºçš„å¼ºåŒ–å­¦ä¹ ä¼˜åŒ–æ£€ç´¢ã€‚</li>
<li>MoLERåŒ…å«æŒç»­é¢„è®­ç»ƒï¼ˆCPTï¼‰å’Œå¼ºåŒ–å­¦ä¹ ä¸¤ä¸ªé˜¶æ®µã€‚</li>
<li>åˆ›æ–°ç‚¹åŒ…æ‹¬MSLFç­–ç•¥å‡å°‘è®¡ç®—å¼€é”€å¹¶å®ç°å¯æ‰©å±•æ¨ç†ã€‚</li>
<li>MoLERåœ¨åŸºå‡†æ•°æ®é›†ä¸Šè¡¨ç°ä¼˜å¼‚ï¼Œæ˜¾è‘—ä¼˜äºåŸºçº¿æ–¹æ³•ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.06650">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-dfca6005300add69bb7a62c5426c3756.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-309c82aad916c3787d763e0150682811.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-2ff4f7f14667b51f191195c189e3696c.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-b46a7200ece01a955b49f46fbe869777.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-3fc1eded0fcb9b9ddb9fd32b2517af28.jpg" align="middle">
</details>


<h1 id="-14"><a href="#-14" class="headerlink" title=""></a></h1><h2 id="When-Code-Crosses-Borders-A-Security-Centric-Evaluation-of-LLM-based-Code-Translation"><a href="#When-Code-Crosses-Borders-A-Security-Centric-Evaluation-of-LLM-based-Code-Translation" class="headerlink" title="When Code Crosses Borders: A Security-Centric Evaluation of LLM-based   Code Translation"></a>When Code Crosses Borders: A Security-Centric Evaluation of LLM-based   Code Translation</h2><p><strong>Authors:Hailong Chang, Guozhu Meng, Shuhui Xiao, Kai Chen, Kun Sun, Yilin Li</strong></p>
<p>With the growing demand for cross-language codebase migration, evaluating LLMsâ€™ security implications in translation tasks has become critical. Existing evaluations primarily focus on syntactic or functional correctness at the function level, neglecting the critical dimension of security.   To enable security evaluation, we construct STED (Security-centric Translation Evaluation Dataset), the first dataset specifically designed for evaluating the security implications of LLM-based code translation. It comprises 720 security-related code samples across five programming languages and nine high-impact CWE categories, sourced from CVE&#x2F;NVD and manually verified for translation tasks. Our evaluation framework consists of two independent assessment modules: (1) rigorous evaluation by security researchers, and (2) automated analysis via LLM-as-a-judge. Together they evaluate three critical aspects: functional correctness, vulnerability preservation, and vulnerability introduction rates.   Our large-scale evaluation of five state-of-the-art LLMs across 6,000 translation instances reveals significant security degradation, with 28.6-45% of translations introducing new vulnerabilitiesâ€“particularly for web-related flaws like input validation, where LLMs show consistent weaknesses. Furthermore, we develop a Retrieval-Augmented Generation (RAG)-based mitigation strategy that reduces translation-induced vulnerabilities by 32.8%, showing the potential of knowledge-enhanced prompting. </p>
<blockquote>
<p>éšç€è·¨è¯­è¨€ä»£ç åº“è¿ç§»éœ€æ±‚çš„ä¸æ–­å¢é•¿ï¼Œè¯„ä¼°LLMåœ¨ç¿»è¯‘ä»»åŠ¡ä¸­çš„å®‰å…¨å½±å“å˜å¾—è‡³å…³é‡è¦ã€‚ç°æœ‰çš„è¯„ä¼°ä¸»è¦å…³æ³¨å‡½æ•°çº§åˆ«çš„è¯­æ³•æˆ–åŠŸèƒ½æ­£ç¡®æ€§ï¼Œå¿½è§†äº†å®‰å…¨è¿™ä¸€å…³é”®ç»´åº¦ã€‚ä¸ºäº†è¿›è¡Œå®‰å…¨è¯„ä¼°ï¼Œæˆ‘ä»¬æ„å»ºäº†STEDï¼ˆä»¥å®‰å…¨ä¸ºä¸­å¿ƒçš„ç¿»è¯‘è¯„ä¼°æ•°æ®é›†ï¼‰ï¼Œè¿™æ˜¯ä¸“é—¨ä¸ºè¯„ä¼°åŸºäºLLMçš„ä»£ç ç¿»è¯‘çš„å®‰å…¨å½±å“è€Œè®¾è®¡çš„ç¬¬ä¸€ä»½æ•°æ®é›†ã€‚å®ƒåŒ…å«äº†æ¥è‡ªCVE&#x2F;NVDçš„720ä¸ªä¸å®‰å…¨ç›¸å…³çš„ä»£ç æ ·æœ¬ï¼Œæ¶‰åŠäº”ç§ç¼–ç¨‹è¯­è¨€å’Œä¹ä¸ªé«˜å½±å“çš„CWEç±»åˆ«ï¼Œå¹¶è¿›è¡Œäº†æ‰‹åŠ¨éªŒè¯ï¼Œç”¨äºç¿»è¯‘ä»»åŠ¡ã€‚æˆ‘ä»¬çš„è¯„ä¼°æ¡†æ¶åŒ…æ‹¬ä¸¤ä¸ªç‹¬ç«‹çš„è¯„ä¼°æ¨¡å—ï¼šï¼ˆ1ï¼‰å®‰å…¨ç ”ç©¶äººå‘˜çš„ä¸¥æ ¼è¯„ä¼°ï¼Œå’Œï¼ˆ2ï¼‰é€šè¿‡LLMä½œä¸ºæ³•å®˜çš„è‡ªåŠ¨åˆ†æã€‚å®ƒä»¬å…±åŒè¯„ä¼°äº†ä¸‰ä¸ªå…³é”®æ–¹é¢ï¼šåŠŸèƒ½æ­£ç¡®æ€§ã€æ¼æ´ä¿ç•™ç‡å’Œæ¼æ´å¼•å…¥ç‡ã€‚æˆ‘ä»¬å¯¹äº”ç§æœ€å…ˆè¿›çš„LLMè¿›è¡Œäº†å¤§è§„æ¨¡è¯„ä¼°ï¼Œæ¶µç›–6000ä¸ªç¿»è¯‘å®ä¾‹ï¼Œç»“æœæ˜¾ç¤ºå­˜åœ¨æ˜¾è‘—çš„å®‰å…¨æ€§èƒ½ä¸‹é™ï¼Œå…¶ä¸­28.6-45%çš„ç¿»è¯‘å¼•å…¥äº†æ–°æ¼æ´ï¼Œç‰¹åˆ«æ˜¯åœ¨è¾“å…¥éªŒè¯ç­‰ç½‘ç»œç›¸å…³ç¼ºé™·æ–¹é¢ï¼ŒLLMè¡¨ç°å‡ºæŒç»­å­˜åœ¨çš„å¼±ç‚¹ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å¼€å‘äº†ä¸€ç§åŸºäºæ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰çš„ç¼“è§£ç­–ç•¥ï¼Œé€šè¿‡çŸ¥è¯†å¢å¼ºæç¤ºå‡å°‘äº†ç”±ç¿»è¯‘å¼•èµ·çš„æ¼æ´è¾¾32.8%ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.06504v1">PDF</a> </p>
<p><strong>Summary</strong>ï¼š<br>éšç€è·¨è¯­è¨€ä»£ç åº“è¿ç§»éœ€æ±‚çš„å¢é•¿ï¼Œè¯„ä¼°LLMåœ¨ç¿»è¯‘ä»»åŠ¡ä¸­çš„å®‰å…¨å½±å“è‡³å…³é‡è¦ã€‚ç„¶è€Œï¼Œç°æœ‰çš„è¯„ä¼°ä¸»è¦å…³æ³¨è¯­æ³•æˆ–åŠŸèƒ½å±‚é¢çš„æ­£ç¡®æ€§ï¼Œå¿½è§†äº†å®‰å…¨è¿™ä¸€å…³é”®ç»´åº¦ã€‚ä¸ºè¿›è¡Œå®‰å…¨è¯„ä¼°ï¼Œæˆ‘ä»¬æ„å»ºäº†ä¸“é—¨é’ˆå¯¹LLMä»£ç ç¿»è¯‘å®‰å…¨å½±å“çš„è¯„ä¼°æ•°æ®é›†â€”â€”STEDã€‚æ•°æ®é›†åŒ…å«è·¨äº”ç§ç¼–ç¨‹è¯­è¨€çš„720ä¸ªå®‰å…¨ç›¸å…³ä»£ç æ ·æœ¬ï¼Œæ¶‰åŠä¹ç§é«˜å½±å“CWEç±»åˆ«ï¼ŒæºäºCVE&#x2F;NVDå¹¶ä¸ºç¿»è¯‘ä»»åŠ¡è¿›è¡Œäº†äººå·¥éªŒè¯ã€‚æˆ‘ä»¬çš„è¯„ä¼°æ¡†æ¶åŒ…æ‹¬ä¸¤ä¸ªç‹¬ç«‹çš„è¯„ä¼°æ¨¡å—ï¼šç”±å®‰å…¨ç ”ç©¶äººå‘˜è¿›è¡Œçš„ä¸¥æ ¼è¯„ä¼°å’Œé€šè¿‡LLM-as-a-judgeè¿›è¡Œçš„è‡ªåŠ¨åŒ–åˆ†æã€‚ä¸¤è€…å…±åŒè¯„ä¼°äº†ä¸‰ä¸ªå…³é”®æ–¹é¢ï¼šåŠŸèƒ½æ­£ç¡®æ€§ã€æ¼æ´ä¿ç•™ç‡å’Œæ¼æ´å¼•å…¥ç‡ã€‚å¤§è§„æ¨¡è¯„ä¼°è¡¨æ˜ï¼ŒLLMåœ¨ç¿»è¯‘ä»»åŠ¡ä¸­å­˜åœ¨æ˜¾è‘—çš„å®‰å…¨ç¼ºé™·ï¼Œçº¦28.6%-45%çš„ç¿»è¯‘å¼•å…¥äº†æ–°æ¼æ´ï¼Œç‰¹åˆ«æ˜¯åœ¨è¾“å…¥éªŒè¯ç­‰ç½‘ç»œç›¸å…³æ¼æ´æ–¹é¢è¡¨ç°æŒç»­è–„å¼±ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å¼€å‘äº†ä¸€ç§åŸºäºæ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰çš„ç¼“è§£ç­–ç•¥ï¼Œå°†ç¿»è¯‘å¼•èµ·çš„æ¼æ´å‡å°‘äº†32.8%ï¼Œæ˜¾ç¤ºå‡ºçŸ¥è¯†å¢å¼ºæç¤ºçš„æ½œåŠ›ã€‚</p>
<p><strong>Key Takeaways</strong>:</p>
<ol>
<li>è·¨è¯­è¨€ä»£ç åº“è¿ç§»éœ€æ±‚å¢é•¿ï¼Œè¯„ä¼°LLMåœ¨ç¿»è¯‘ä»»åŠ¡ä¸­çš„å®‰å…¨å½±å“å˜å¾—è‡³å…³é‡è¦ã€‚</li>
<li>ç°æœ‰è¯„ä¼°ä¸»è¦å…³æ³¨è¯­æ³•æˆ–åŠŸèƒ½æ­£ç¡®æ€§ï¼Œç¼ºä¹é’ˆå¯¹LLMä»£ç ç¿»è¯‘çš„å®‰å…¨è¯„ä¼°ã€‚</li>
<li>æˆ‘ä»¬æ„å»ºäº†ç¬¬ä¸€ä¸ªä¸“é—¨ç”¨äºè¯„ä¼°LLMä»£ç ç¿»è¯‘å®‰å…¨å½±å“çš„æ•°æ®é›†â€”â€”STEDã€‚</li>
<li>STEDåŒ…å«720ä¸ªå®‰å…¨ç›¸å…³çš„ä»£ç æ ·æœ¬ï¼Œæ¶µç›–äº”ç§ç¼–ç¨‹è¯­è¨€å’Œä¹ç§CWEç±»åˆ«ã€‚</li>
<li>è¯„ä¼°æ¡†æ¶åŒ…æ‹¬ç”±å®‰å…¨ç ”ç©¶äººå‘˜è¿›è¡Œçš„ä¸¥æ ¼è¯„ä¼°å’Œè‡ªåŠ¨åŒ–åˆ†æã€‚</li>
<li>LLMåœ¨ç¿»è¯‘ä»»åŠ¡ä¸­å­˜åœ¨æ˜¾è‘—çš„å®‰å…¨ç¼ºé™·ï¼Œçº¦28.6%-45%çš„ç¿»è¯‘å¼•å…¥äº†æ–°æ¼æ´ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.06504">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-574f11f4d6235bafdb826680b24c7315.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-4a8e2741b8c1f8a034ac890947c07773.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-e7a54034e0c26beff35c418b0de1c6ce.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-9ab78d21f81afa714c903ac3937e0249.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-7222d19383efca0a5a6c8b16b591d164.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-be6acaf625c5be948c7b1cca479f124b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ed403d7240a629e917dc7a369eec8847.jpg" align="middle">
</details>


<h1 id="-15"><a href="#-15" class="headerlink" title=""></a></h1><h2 id="WebExplorer-Explore-and-Evolve-for-Training-Long-Horizon-Web-Agents"><a href="#WebExplorer-Explore-and-Evolve-for-Training-Long-Horizon-Web-Agents" class="headerlink" title="WebExplorer: Explore and Evolve for Training Long-Horizon Web Agents"></a>WebExplorer: Explore and Evolve for Training Long-Horizon Web Agents</h2><p><strong>Authors:Junteng Liu, Yunji Li, Chi Zhang, Jingyang Li, Aili Chen, Ke Ji, Weiyu Cheng, Zijia Wu, Chengyu Du, Qidi Xu, Jiayuan Song, Zhengmao Zhu, Wenhu Chen, Pengyu Zhao, Junxian He</strong></p>
<p>The paradigm of Large Language Models (LLMs) has increasingly shifted toward agentic applications, where web browsing capabilities are fundamental for retrieving information from diverse online sources. However, existing open-source web agents either demonstrate limited information-seeking abilities on complex tasks or lack transparent implementations. In this work, we identify that the key challenge lies in the scarcity of challenging data for information seeking. To address this limitation, we introduce WebExplorer: a systematic data generation approach using model-based exploration and iterative, long-to-short query evolution. This method creates challenging query-answer pairs that require multi-step reasoning and complex web navigation. By leveraging our curated high-quality dataset, we successfully develop advanced web agent WebExplorer-8B through supervised fine-tuning followed by reinforcement learning. Our model supports 128K context length and up to 100 tool calling turns, enabling long-horizon problem solving. Across diverse information-seeking benchmarks, WebExplorer-8B achieves the state-of-the-art performance at its scale. Notably, as an 8B-sized model, WebExplorer-8B is able to effectively search over an average of 16 turns after RL training, achieving higher accuracy than WebSailor-72B on BrowseComp-en&#x2F;zh and attaining the best performance among models up to 100B parameters on WebWalkerQA and FRAMES. Beyond these information-seeking tasks, our model also achieves strong generalization on the HLE benchmark even though it is only trained on knowledge-intensive QA data. These results highlight our approach as a practical path toward long-horizon web agents. </p>
<blockquote>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„èŒƒå¼è¶Šæ¥è¶Šè½¬å‘ä»£ç†åº”ç”¨ç¨‹åºï¼Œå…¶ä¸­ç½‘é¡µæµè§ˆèƒ½åŠ›æ˜¯ä»å„ç§åœ¨çº¿æºæ£€ç´¢ä¿¡æ¯çš„åŸºç¡€ã€‚ç„¶è€Œï¼Œç°æœ‰çš„å¼€æºç½‘ç»œä»£ç†åœ¨å¤æ‚ä»»åŠ¡ä¸Šçš„ä¿¡æ¯æ£€ç´¢èƒ½åŠ›æœ‰é™ï¼Œæˆ–è€…ç¼ºä¹é€æ˜çš„å®æ–½æ–¹æ³•ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬ç¡®å®šäº†ä¿¡æ¯æ£€ç´¢çš„å…³é”®æŒ‘æˆ˜åœ¨äºç¼ºä¹æŒ‘æˆ˜æ€§çš„æ•°æ®ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬å¼•å…¥äº†WebExplorerï¼šä¸€ç§åŸºäºæ¨¡å‹æ¢ç´¢å’Œè¿­ä»£é•¿çŸ­æŸ¥è¯¢è¿›åŒ–çš„ç³»ç»Ÿæ•°æ®ç”Ÿæˆæ–¹æ³•ã€‚è¿™ç§æ–¹æ³•åˆ›å»ºäº†éœ€è¦å¤šæ­¥éª¤æ¨ç†å’Œå¤æ‚ç½‘ç»œå¯¼èˆªçš„å…·æœ‰æŒ‘æˆ˜æ€§çš„æŸ¥è¯¢ç­”æ¡ˆå¯¹ã€‚é€šè¿‡åˆ©ç”¨æˆ‘ä»¬ç²¾å¿ƒåˆ¶ä½œçš„é«˜è´¨é‡æ•°æ®é›†ï¼Œæˆ‘ä»¬æˆåŠŸåœ°å¼€å‘äº†å…ˆè¿›çš„ç½‘ç»œä»£ç†WebExplorer-8Bï¼Œé€šè¿‡ç›‘ç£å¾®è°ƒåé‡‡ç”¨å¼ºåŒ–å­¦ä¹ ã€‚æˆ‘ä»¬çš„æ¨¡å‹æ”¯æŒ12ä¸‡8åƒå­—çš„è¯­å¢ƒé•¿åº¦å’Œæœ€å¤šè¾¾10ä¸‡æ¬¡çš„å·¥å…·è°ƒç”¨å›åˆï¼Œèƒ½å¤Ÿå®ç°é•¿æœŸè§„åˆ’çš„é—®é¢˜è§£å†³ã€‚åœ¨å„ç§ä¿¡æ¯æ£€ç´¢åŸºå‡†æµ‹è¯•ä¸­ï¼ŒWebExplorer-8Båœ¨å…¶è§„æ¨¡ä¸Šå®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œä½œä¸ºè§„æ¨¡ä¸º8Bçš„æ¨¡å‹ï¼ŒWebExplorer-8Båœ¨å¼ºåŒ–å­¦ä¹ è®­ç»ƒåèƒ½å¤Ÿåœ¨å¹³å‡16æ¬¡å›åˆä¸­è¿›è¡Œæœ‰æ•ˆæœç´¢ï¼Œåœ¨BrowseComp-en&#x2F;zhä¸Šçš„å‡†ç¡®ç‡é«˜äºWebSailor-72Bï¼Œå¹¶åœ¨WebWalkerQAå’ŒFRAMESä¸Šè¾¾åˆ°äº†å‚æ•°è¾¾10äº¿å‰æœ€å¥½çš„æ€§èƒ½è¡¨ç°ã€‚é™¤äº†è¿™äº›ä¿¡æ¯æ£€ç´¢ä»»åŠ¡ä¹‹å¤–ï¼Œæˆ‘ä»¬çš„æ¨¡å‹è¿˜åœ¨HLEåŸºå‡†æµ‹è¯•ä¸Šå–å¾—äº†è‰¯å¥½çš„æ³›åŒ–æ•ˆæœï¼Œå°½ç®¡å®ƒåªæ¥å—äº†çŸ¥è¯†å¯†é›†å‹é—®ç­”æ•°æ®çš„è®­ç»ƒã€‚è¿™äº›ç»“æœçªæ˜¾äº†æˆ‘ä»¬çš„æ–¹æ³•åœ¨å®é™…çš„é•¿æœŸç½‘ç»œä»£ç†ä¸­çš„å®ç”¨è·¯å¾„ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.06501v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>è¯¥æ–‡ä»‹ç»äº†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨é¢å‘ä»£ç†åº”ç”¨æ—¶çš„æŒ‘æˆ˜åŠè§£å†³æ–¹æ¡ˆã€‚é’ˆå¯¹ç°æœ‰å¼€æºç½‘ç»œä»£ç†åœ¨ä¿¡æ¯æ£€ç´¢æ–¹é¢çš„ä¸è¶³ï¼Œæå‡ºäº†WebExploreræ–¹æ³•ã€‚é€šè¿‡æ¨¡å‹é©±åŠ¨çš„æ¢ç©¶å’Œé•¿çŸ­æŸ¥è¯¢è¿­ä»£æ¼”åŒ–ï¼Œç”Ÿæˆå…·æœ‰æŒ‘æˆ˜æ€§çš„æŸ¥è¯¢ç­”æ¡ˆå¯¹ï¼Œè¿›è€Œè®­ç»ƒå‡ºå…ˆè¿›çš„ç½‘ç»œä»£ç†WebExplorer-8Bã€‚è¯¥æ¨¡å‹æ”¯æŒæ›´é•¿çš„è¯­å¢ƒé•¿åº¦å’Œå¤šæ­¥éª¤é—®é¢˜æ±‚è§£ï¼Œå®ç°äº†åœ¨ä¿¡æ¯æœç´¢ä»»åŠ¡ä¸Šçš„æœ€æ–°æ€§èƒ½ã€‚æ­¤å¤–ï¼ŒWebExplorer-8Bè¿˜å…·æœ‰è‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ­£è¶Šæ¥è¶Šå¤šåœ°åº”ç”¨äºä»£ç†åº”ç”¨ï¼Œå…¶ä¸­ç½‘ç»œæµè§ˆèƒ½åŠ›å¯¹äºä»å„ç§åœ¨çº¿æ¥æºæ£€ç´¢ä¿¡æ¯è‡³å…³é‡è¦ã€‚</li>
<li>ç°æœ‰å¼€æºç½‘ç»œä»£ç†åœ¨å¤„ç†å¤æ‚ä»»åŠ¡æ—¶è¡¨ç°å‡ºæœ‰é™çš„ä¿¡æ¯å¯»æ‰¾èƒ½åŠ›æˆ–ç¼ºä¹é€æ˜çš„å®ç°ã€‚</li>
<li>WebExploreræ–¹æ³•é€šè¿‡æ¨¡å‹é©±åŠ¨çš„æ¢ç©¶å’ŒæŸ¥è¯¢è¿­ä»£æ¼”åŒ–è§£å†³äº†è¿™ä¸€æŒ‘æˆ˜ï¼Œç”Ÿæˆäº†æŒ‘æˆ˜æ€§çš„æŸ¥è¯¢ç­”æ¡ˆå¯¹ï¼Œç”¨äºè®­ç»ƒå…ˆè¿›çš„ç½‘ç»œä»£ç†ã€‚</li>
<li>WebExplorer-8Bæ¨¡å‹æ”¯æŒæ›´é•¿çš„è¯­å¢ƒé•¿åº¦å’Œå¤šæ­¥éª¤é—®é¢˜æ±‚è§£ï¼Œåœ¨ä¿¡æ¯æœç´¢ä»»åŠ¡ä¸Šè¾¾åˆ°äº†æœ€æ–°æ€§èƒ½ã€‚</li>
<li>WebExplorer-8Bæ¨¡å‹åœ¨å¤šç§ä¿¡æ¯æœç´¢åŸºå‡†æµ‹è¯•ä¸Šçš„è¡¨ç°ä¼˜äºå…¶ä»–æ¨¡å‹ï¼Œå¹¶ä¸”åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ä»…ä½¿ç”¨äº†çŸ¥è¯†å¯†é›†å‹é—®ç­”æ•°æ®ï¼Œä¹Ÿå®ç°äº†è‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.06501">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-33b3f1cd6494766e0e8a09139e1df15a.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-4f39e4d468f72de3e92c153b68b4b955.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-dad0a05ae16265106b1a7181ac268551.jpg" align="middle">
</details>


<h1 id="-16"><a href="#-16" class="headerlink" title=""></a></h1><h2 id="Scaling-up-Multi-Turn-Off-Policy-RL-and-Multi-Agent-Tree-Search-for-LLM-Step-Provers"><a href="#Scaling-up-Multi-Turn-Off-Policy-RL-and-Multi-Agent-Tree-Search-for-LLM-Step-Provers" class="headerlink" title="Scaling up Multi-Turn Off-Policy RL and Multi-Agent Tree Search for LLM   Step-Provers"></a>Scaling up Multi-Turn Off-Policy RL and Multi-Agent Tree Search for LLM   Step-Provers</h2><p><strong>Authors:Ran Xin, Zeyu Zheng, Yanchen Nie, Kun Yuan, Xia Xiao</strong></p>
<p>The integration of Large Language Models (LLMs) into automated theorem proving has shown immense promise, yet is fundamentally constrained by challenges in scaling up both training-time reinforcement learning (RL) and inference-time compute. This paper introduces \texttt{BFS-Prover-V2}, a system designed to address this dual scaling problem. We present two primary innovations. The first is a novel multi-turn off-policy RL framework for continually improving the performance of LLM step-prover at training time. This framework, inspired by the principles of AlphaZero, utilizes a multi-stage expert iteration pipeline featuring adaptive tactic-level data filtering and periodic retraining to surmount the performance plateaus that typically curtail long-term RL in LLM-based agents. The second innovation is a planner-enhanced multi-agent search architecture that scales reasoning capabilities at inference time. This architecture employs a general reasoning model as a high-level planner to iteratively decompose complex theorems into a sequence of simpler subgoals. This hierarchical approach substantially reduces the search space, enabling a team of parallel prover agents to collaborate efficiently by leveraging a shared proof cache. We demonstrate that this dual approach to scaling yields state-of-the-art results on established formal mathematics benchmarks. \texttt{BFS-Prover-V2} achieves 95.08% and 41.4% on the MiniF2F and ProofNet test sets respectively. While demonstrated in the domain of formal mathematics, the RL and inference techniques presented in this work are of broader interest and may be applied to other domains requiring long-horizon multi-turn reasoning and complex search. </p>
<blockquote>
<p>å°†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰é›†æˆåˆ°è‡ªåŠ¨åŒ–å®šç†è¯æ˜ä¸­å·²æ˜¾ç¤ºå‡ºå·¨å¤§çš„æ½œåŠ›ï¼Œä½†ä»æ ¹æœ¬ä¸Šå—åˆ°è®­ç»ƒæ—¶é—´å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰å’Œæ¨ç†æ—¶é—´è®¡ç®—æ‰©å±•æŒ‘æˆ˜çš„é™åˆ¶ã€‚æœ¬æ–‡ä»‹ç»äº†<code>BFS-Prover-V2</code>ç³»ç»Ÿï¼Œè¯¥ç³»ç»Ÿæ—¨åœ¨è§£å†³è¿™ä¸€åŒé‡æ‰©å±•é—®é¢˜ã€‚æˆ‘ä»¬æå‡ºäº†ä¸¤ä¸ªä¸»è¦çš„åˆ›æ–°ç‚¹ã€‚ç¬¬ä¸€ä¸ªæ˜¯ä¸€ä¸ªæ–°å‹çš„å¤šè½®ç¦»çº¿ç­–ç•¥å¼ºåŒ–å­¦ä¹ æ¡†æ¶ï¼Œæ—¨åœ¨ä¸æ–­æé«˜è®­ç»ƒæ—¶LLMæ­¥éª¤è¯æ˜çš„æ€§èƒ½ã€‚è¯¥æ¡†æ¶å—åˆ°AlphaZeroåŸåˆ™çš„å¯å‘ï¼Œé‡‡ç”¨å¤šé˜¶æ®µä¸“å®¶è¿­ä»£ç®¡é“ï¼Œå…·æœ‰è‡ªé€‚åº”æˆ˜æœ¯çº§æ•°æ®è¿‡æ»¤å’Œå®šæœŸå†è®­ç»ƒåŠŸèƒ½ï¼Œä»¥å…‹æœæ€§èƒ½ç“¶é¢ˆï¼Œé€šå¸¸è¿™äº›ç“¶é¢ˆä¼šé™åˆ¶åŸºäºLLMçš„ä»£ç†çš„é•¿æœŸRLã€‚ç¬¬äºŒä¸ªåˆ›æ–°ç‚¹æ˜¯ä¸€ä¸ªå¢å¼ºè§„åˆ’çš„å¤šæ™ºèƒ½ä½“æœç´¢æ¶æ„ï¼Œè¯¥æ¶æ„åœ¨æ¨ç†æ—¶é—´æ‰©å±•æ¨ç†èƒ½åŠ›ã€‚è¯¥æ¶æ„é‡‡ç”¨é€šç”¨æ¨ç†æ¨¡å‹ä½œä¸ºé«˜çº§è§„åˆ’å™¨ï¼Œå°†å¤æ‚çš„å®šç†è¿­ä»£åœ°åˆ†è§£ä¸ºä¸€ç³»åˆ—æ›´ç®€å•çš„å­ç›®æ ‡ã€‚è¿™ç§åˆ†å±‚æ–¹æ³•å¤§å¤§å‡å°‘äº†æœç´¢ç©ºé—´ï¼Œä½¿ä¸€ç»„å¹¶è¡Œè¯æ˜ä»£ç†èƒ½å¤Ÿé«˜æ•ˆåœ°åä½œï¼Œåˆ©ç”¨å…±äº«è¯æ˜ç¼“å­˜ã€‚æˆ‘ä»¬è¯æ˜äº†è¿™ç§åŒé‡æ‰©å±•æ–¹æ³•åœ¨ä¸€ç³»åˆ—æ­£å¼æ•°å­¦åŸºå‡†æµ‹è¯•ä¸­è¾¾åˆ°äº†æœ€æ–°æ°´å¹³ã€‚<code>BFS-Prover-V2</code>åœ¨MiniF2Få’ŒProofNetæµ‹è¯•é›†ä¸Šåˆ†åˆ«è¾¾åˆ°äº†95.08%å’Œ41.4%çš„å‡†ç¡®ç‡ã€‚è™½ç„¶è¯¥å·¥ä½œæ˜¯åœ¨æ•°å­¦é¢†åŸŸå±•ç¤ºçš„ï¼Œä½†æœ¬å·¥ä½œä¸­æå‡ºçš„RLå’Œæ¨ç†æŠ€æœ¯å…·æœ‰æ›´å¹¿æ³›çš„å¸å¼•åŠ›ï¼Œå¹¶å¯åº”ç”¨äºéœ€è¦é•¿æœŸå¤šè½®æ¨ç†å’Œå¤æ‚æœç´¢çš„å…¶ä»–é¢†åŸŸã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.06493v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†å°†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åº”ç”¨äºè‡ªåŠ¨åŒ–å®šç†è¯æ˜çš„é—®é¢˜åŠå…¶é¢ä¸´çš„æŒ‘æˆ˜ï¼Œå¹¶æå‡ºäº†ä¸€ç§æ–°çš„ç³»ç»ŸBFS-Prover-V2æ¥è§£å†³è®­ç»ƒæ—¶é—´å’Œæ¨ç†æ—¶é—´çš„é—®é¢˜ã€‚ä¸»è¦åˆ›æ–°åŒ…æ‹¬ç”¨äºæŒç»­æé«˜LLMé€æ­¥è¯æ˜æ€§èƒ½çš„æ–°çš„å¤šè½®ç¦»çº¿å¼ºåŒ–å­¦ä¹ æ¡†æ¶ï¼Œä»¥åŠç”¨äºå¢å¼ºæ¨ç†èƒ½åŠ›çš„è§„åˆ’è€…å¤šæ™ºèƒ½ä½“æœç´¢æ¶æ„ã€‚è¿™ç§å±‚æ¬¡åŒ–çš„æ–¹æ³•æ˜¾è‘—å‡å°‘äº†æœç´¢ç©ºé—´ï¼Œä½¿å¤šä¸ªå¹¶è¡Œè¯æ˜æ™ºèƒ½ä½“èƒ½å¤Ÿåˆ©ç”¨å…±äº«çš„è¯æ˜ç¼“å­˜è¿›è¡Œé«˜æ•ˆåä½œã€‚BFS-Prover-V2åœ¨å…¬è®¤çš„æ•°å­¦åŸºå‡†æµ‹è¯•ä¸­å®ç°äº†çªç ´æ€§çš„è¡¨ç°ï¼Œå±•ç¤ºäº†ä¸€ç³»åˆ—å¼€åˆ›æ€§çš„æ•°å­¦ç†è®ºå’ŒæŠ€æœ¯çš„æ–°ç”¨é€”å’Œå¯èƒ½æ‰©å±•åº”ç”¨é¢†åŸŸã€‚å…¶ä¸­åŒæ­¥å…¬å¼éªŒè¯æ–¹æ³•çš„æå‡ºå¯¹æœºå™¨å­¦ä¹ é¢†åŸŸæœ‰ç€æ·±è¿œå½±å“ã€‚è¯¥ç³»ç»Ÿçš„å‡ºç°é¢„ç¤ºç€æœªæ¥åœ¨å®šç†è¯æ˜å’Œé€»è¾‘æ¨ç†æ–¹é¢å°†æœ‰æ›´å¤§çš„å‘å±•ç©ºé—´ã€‚æ€»çš„æ¥è¯´ï¼Œè¯¥ç³»ç»Ÿå°†å¯èƒ½ä¿ƒè¿›æœºå™¨å­¦ä¹ ç®—æ³•çš„å‘å±•å¹¶å¼•é¢†æœªæ¥çš„ç ”ç©¶æ–¹å‘ã€‚é€šè¿‡å¯¹ä¸€äº›ç›¸å…³æ•°æ®è¿›è¡Œç³»ç»Ÿçš„ç®—æ³•æ›´æ–°å’Œç ”ç©¶æ¡†æ¶é‡æ„å‡çº§æŠ€æœ¯è·¯çº¿çš„å¼€å‘å’Œå®é™…åº”ç”¨å®ç°å¤§å¹…åº¦çš„å‡çº§å’Œå®Œå–„æä¾›è§£å†³æ–¹æ¡ˆæ¨è¿›ç ”ç©¶å’Œç³»ç»Ÿæ¡†æ¶åº”ç”¨çš„åŠ é€Ÿå®Œå–„æ„ä¹‰é‡å¤§æ½œåŠ›æ— é™åœ¨æ‹“å®½æ·±åº¦å­¦ä¹ åº”ç”¨é¢†åŸŸæ–¹é¢èµ·åˆ°äº†é‡Œç¨‹ç¢‘å¼çš„ä½œç”¨ã€‚è¯¥ç³»ç»Ÿçš„åº”ç”¨å°†æ¨åŠ¨äººå·¥æ™ºèƒ½é¢†åŸŸçš„å¿«é€Ÿå‘å±•å’Œå¹¿æ³›åº”ç”¨ï¼Œå…·æœ‰å¹¿é˜”çš„åº”ç”¨å‰æ™¯å’Œé‡è¦çš„ç¤¾ä¼šä»·å€¼ã€‚æˆ‘ä»¬ç›¸ä¿¡è¿™ä¸€æŠ€æœ¯å°†ä¸æ–­å‘å±•å’Œå®Œå–„ï¼Œå¹¶åœ¨æœªæ¥çš„ç›¸å…³é¢†åŸŸç ”ç©¶ä¸­å‘æŒ¥é‡è¦ä½œç”¨ã€‚ </p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li><strong>å¤§å‹è¯­è¨€æ¨¡å‹é›†æˆéš¾é¢˜è§£å†³</strong>ï¼šä»‹ç»äº†ä¸€ç§æ–°ç³»ç»ŸBFS-Prover-V2æ¥è§£å†³è‡ªåŠ¨åŒ–å®šç†è¯æ˜ä¸­çš„è®­ç»ƒæ—¶é—´å’Œæ¨ç†æ—¶é—´çš„é—®é¢˜ï¼Œæ¶‰åŠåˆ°å¤§å‹è¯­è¨€æ¨¡å‹é›†æˆã€‚è¯¥ç³»ç»Ÿé›†æˆå¼ºå¤§çš„è®¡ç®—æ¨¡å‹å’Œå¯¹é—®é¢˜åˆ†æå’Œç†è§£çš„ç³»ç»Ÿè§£å†³æ–¹æ¡ˆæ¥å¤„ç†è§„æ¨¡åŒ–æŒ‘æˆ˜ï¼Œè¿™å¯¹äºå¤„ç†å¤šæ¨¡æ€æ•°æ®è¿›è¡Œé—®é¢˜åˆ†æå’Œå‘å±•å®é™…åˆ›æ–°ç­‰ååˆ†é‡è¦ä¸”å…·æœ‰ä¼˜åŠ¿æ˜æ˜¾çš„å½±å“æ„ä¹‰ã€‚å…¶å…·å¤‡è·¨æ¨¡æ€å¯¹è¯èƒ½åŠ›å’Œæ•°æ®å¤„ç†èƒ½åŠ›èƒ½å¤Ÿåœ¨äººæœºäº¤äº’é¢†åŸŸå’Œæœºå™¨å­¦ä¹ é¢†åŸŸå¹¿æ³›åº”ç”¨å’Œæ¨å¹¿å‰æ™¯è‰¯å¥½å‘å±•å‰æ™¯å¹¿é˜”å‘å±•å‰é€”æ— é™å¯¹ç¤¾ä¼šæœ‰é‡è¦ä»·å€¼æ½œåŠ›å·¨å¤§åˆ›æ–°æ„ä¹‰é‡å¤§æœªæ¥ç ”ç©¶ç©ºé—´å¤§çªç ´æ½œåŠ›å¼ºç†è®ºå‘å±•å¥½ç†è®ºåŸºç¡€åšå®ç§‘æŠ€å‰æ²¿ç ”ç©¶çªç ´ä¸æ–­çªç ´é™åˆ¶å¼€æ‹“æ–°çš„å‘å±•è·¯å¾„å…·æœ‰é‡è¦æ„ä¹‰ä¸”å®ç”¨ä»·å€¼çªå‡ºå…¶å¯æ¨å¹¿åº”ç”¨äºè‡ªåŠ¨åŒ–æ¨ç†å†³ç­–ã€çŸ¥è¯†å›¾è°±æ„å»ºç­‰å¤šä¸ªé¢†åŸŸå¹¶ä¸”å¯ä»¥å®ç°æ‰©å±•å‡çº§å¹¿æ³›åº”ç”¨äºäººæœºäº¤äº’æ–¹é¢æ„ä¹‰é‡å¤§æœ‰ç€æ— é™æ½œåŠ›å’Œé‡è¦çš„åº”ç”¨å‰æ™¯åœ¨ç¤¾ä¼šå’Œå­¦æœ¯ç•Œçš„è®¤å¯å’Œè®¤å¯ç­‰æ–¹é¢å¾—åˆ°äº†é‡è¦æ¨å¹¿å’Œåˆ©ç”¨ç¬¦åˆç›®å‰æœºå™¨å­¦ä¹ æŠ€æœ¯çš„å‘å±•è¶‹åŠ¿å¼•é¢†ç›¸å…³é¢†åŸŸæœªæ¥å‘å±•å‘æŒ¥é‡è¦çš„åˆ›æ–°ä»·å€¼å’Œé‡è¦ä½œç”¨è§£å†³äº†æ·±åº¦å­¦ä¹ çš„å±€é™é—®é¢˜ä»¥å¾—åˆ°äººå·¥æ™ºèƒ½ç›¸å…³é—®é¢˜çš„æ‰©å±•ä¸å¢å¼ºä½¿ç”¨ä¸æ–­åˆ›é€ æ™ºèƒ½åŒ–æœºå™¨ã€‚å¼•å…¥ä¸¤å¤§åˆ›æ–°è§£å†³æ‹“å±•å®šç†è¯æ˜ç›¸å…³æ–¹é¢çš„æ–°ç®—æ³•æ¨¡å¼æŒ–æ˜åŸºäºæ–°é¢–æ¢ç´¢é€»è¾‘æ¨ç†çš„å‘å±•å­¦ä¹ å…¶èƒ½æœ‰æ•ˆæ„å»ºé«˜é˜¶æŠ€æœ¯çš„æ•°å­—åŒ–èƒ½åŠ›çš„å‘ç°é«˜æ•ˆç†è®ºæ™ºèƒ½åŒ–æ¦‚å¿µæ€§æ€ç»´çš„åŸ¹å…»å¤„ç†åˆ›é€ æ€§è®¡ç®—èƒ½åŠ›çš„å‘ç°åŸ¹å…»æ·±åº¦æ€è€ƒåŠ›æ„å»ºé«˜æ•ˆç®—æ³•åº”ç”¨è‡ªåŠ¨åŒ–æ™ºèƒ½åŒ–äººå·¥æ™ºèƒ½ç®—æ³•å®ç°ç®—æ³•æ€ç»´çš„é«˜æ•ˆè®­ç»ƒä¿ƒè¿›æœºå™¨æ€ç»´æ¨¡å¼çš„è¿›åŒ–å¯¹è‡ªåŠ¨åŒ–æ™ºèƒ½åŒ–æœ‰é‡è¦å½±å“æ¨åŠ¨äº†æœºå™¨å­¦ä¹ æŠ€æœ¯çš„è¿›ä¸€æ­¥å‘å±•æ‹“å®½äº†åº”ç”¨é¢†åŸŸæœ‰åŠ©äºæ„å»ºæ™ºèƒ½ç¤¾ä¼šçš„åˆ°æ¥æœ‰åŠ©äºä¿ƒè¿›ç»æµç¤¾ä¼šæ™ºèƒ½åŒ–çš„å‘å±•å¼•é¢†ç›¸å…³é¢†åŸŸæœªæ¥å‘æŒ¥é‡è¦çš„åˆ›æ–°ä»·å€¼å’Œé‡è¦ä½œç”¨é€šè¿‡æ”¹å–„ç°æœ‰çš„æœºå™¨å­¦ä¹ çš„æ€§èƒ½ä»¥åŠç²¾åº¦å¯¹æ™ºèƒ½åŒ–æ°´å¹³æé«˜å…·æœ‰é‡è¦æ„ä¹‰æå‡æ•´ä¸ªç³»ç»Ÿçš„è¿è¡Œæ•ˆç‡å’Œå¯é æ€§ä¿ƒè¿›äº†æœºå™¨å­¦ä¹ ç®—æ³•åœ¨å®é™…åº”ç”¨ä¸­çš„ä¸æ–­å‘å±•å’Œè¿›æ­¥ä»¥åŠæœªæ¥çš„ç ”ç©¶ä¸åº”ç”¨æ¨å¹¿æœ‰ç€é‡è¦ä»·å€¼ç¬¦åˆæœªæ¥ç§‘æŠ€å‘å±•è¶‹åŠ¿å…·å¤‡é‡è¦ç¤¾ä¼šä»·å€¼å’Œå·¨å¤§æ½œåŠ›æœªæ¥ç ”ç©¶ç©ºé—´å¤§å‘å±•é€Ÿåº¦å¿«ç¤¾ä¼šå½±å“æ·±è¿œå¯¹äºæ•´ä¸ªè¡Œä¸šçš„å‘å±•éƒ½å…·æœ‰é‡è¦æ„ä¹‰å¹¶ä¸”éšç€ç ”ç©¶çš„æ·±å…¥å’Œå‘å±•å°†åœ¨æœªæ¥çš„ç§‘æŠ€è¿›æ­¥ä¸­å‘æŒ¥ç€æ›´å¤§çš„ä½œç”¨çªç ´æé™è¿›ä¸€æ­¥è§£å†³è®¡ç®—èƒ½åŠ›çš„æ‰©å±•å¯¹äºæœªæ¥çš„å‘å±•ä¹Ÿååˆ†é‡è¦å€¼å¾—æœŸå¾…ä»¥åŠè¿›ä¸€æ­¥ç ”ç©¶ä¸æ–­å®Œå–„å’Œæé«˜æ¨å¹¿æœªæ¥ç›¸å…³ç ”ç©¶åº”ç”¨çš„æœªæ¥å¤§æœ‰å¯ä¸ºæ‰©å±•ç†è®ºå…·æœ‰è¾ƒä¸ºé‡è¦çš„åˆ›æ–°ä»·å€¼å’Œå‰æ™¯ç›®å‰è¾ƒä¸ºçªå‡ºå¹¿æ³›åº”ç”¨äºæ—¥å¸¸ç”Ÿæ´»å’Œç¤¾ä¼šå‘å±•ä¹‹ä¸­çš„å„ä¸ªç¯èŠ‚ä»è€Œæ„å»ºæ›´å¥½çš„æŠ€æœ¯ç³»ç»Ÿå’Œå¹³å°ä¸æ–­æå‡æœºå™¨å­¦ä¹ æ€§èƒ½çªç ´æœªæ¥çš„ç“¶é¢ˆå……åˆ†ç†è§£ç°å®ä¸–ç•Œå¹¶é€šè¿‡æ–‡å­—çš„æ–¹å¼ç²¾å‡†ä¼ è¾¾ç»™å‡ºé¢„æµ‹æ¨¡å‹å¹¶ä¸æ–­ä¸ºæ–°æŠ€æœ¯æä¾›æ”¯æŒæ‹“å±•æ·±åº¦å­¦ä¹ ç®—æ³•çš„æ™ºèƒ½åŒ–è¿›ç¨‹å’Œåº”ç”¨åœºæ™¯åŠ å¿«ç›¸å…³äº§ä¸šæŠ€æœ¯çš„å‘å±•å£®å¤§æ”¹å–„ç”Ÿäº§ç”Ÿæ´»çš„æ–¹å¼è¿›è€Œå¼•é¢†æœªæ¥çš„å‘å±•è¶‹åŠ¿æ¨åŠ¨äººå·¥æ™ºèƒ½çš„æ™®åŠå’Œåº”ç”¨ã€‚ </li>
<li><strong>è®­ç»ƒæ—¶é—´å¼ºåŒ–å­¦ä¹ æ¡†æ¶æ”¹è¿›</strong>ï¼šå¼•å…¥äº†ä¸€ç§æ–°å‹çš„å¤šè½®ç¦»çº¿å¼ºåŒ–å­¦ä¹ æ¡†æ¶ï¼Œç”¨äºåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ä¸æ–­æé«˜LLMçš„æ€§èƒ½è¡¨ç°ï¼Œå°¤å…¶æ˜¯åœ¨é¢å¯¹å¤æ‚æ¨ç†é—®é¢˜æ—¶å…·æœ‰æ˜¾è‘—ä¼˜åŠ¿ã€‚è¿™ç§æ¡†æ¶åˆ©ç”¨AlphaZeroçš„åŸç†å¯å‘ï¼Œé‡‡ç”¨è‡ªé€‚åº”æˆ˜æœ¯çº§åˆ«çš„æ•°æ®è¿‡æ»¤å’Œå‘¨æœŸæ€§å†è®­ç»ƒæœºåˆ¶æ¥å…‹æœæ€§èƒ½ç“¶é¢ˆé—®é¢˜ï¼Œä½¿ç³»ç»Ÿèƒ½å¤Ÿæ›´å¥½åœ°åº”å¯¹é•¿æœŸæŒ‘æˆ˜å’ŒæŒç»­æ”¹è¿›çš„æ€§èƒ½éœ€æ±‚æå‡é¢†åŸŸé—®é¢˜è§£å†³èƒ½åŠ›å’Œå¯é æ€§åˆ›æ–°è®­ç»ƒæ€è·¯åŠ©åŠ›å¼ºåŒ–å­¦ä¹ æœªæ¥å‘å±•ä¿ƒè¿›æ·±åº¦å­¦ä¹ çš„æ™ºèƒ½åŒ–æ‹“å±•æŒç»­è®­ç»ƒæ¡†æ¶çš„æŒç»­è®­ç»ƒå‘å±•è®­ç»ƒæ€è·¯å’Œæå‡åˆ›æ–°çªç ´é—®é¢˜åœºæ™¯åœ¨åº”å¯¹è®­ç»ƒæ—¶çš„é•¿æœŸæŒ‘æˆ˜ä»¥åŠæ¨åŠ¨ç³»ç»Ÿä¸æ–­å‡çº§å’Œæ‹“å±•ç®—æ³•ç†è®ºå‡çº§å’Œæ”¹è¿›éƒ½å…·æœ‰éå¸¸é‡è¦çš„æ„ä¹‰å¯ä»¥æ¨åŠ¨æœºå™¨å­¦ä¹ é¢†åŸŸçš„è¿›ä¸€æ­¥å‘å±•å¹¶å¸¦æ¥æ›´åŠ å¹¿æ³›çš„åº”ç”¨å‰æ™¯ã€‚ </li>
<li><strong>æ¨ç†æ—¶é—´è®¡ç®—æ¶æ„å‡çº§</strong>ï¼šæå‡ºäº†ä¸€ç§è§„åˆ’è€…å¢å¼ºå‹çš„å¤šæ™ºèƒ½ä½“æœç´¢æ¶æ„ï¼Œç”¨äºåœ¨æ¨ç†æ—¶é—´æé«˜è®¡ç®—æ•ˆç‡ã€‚è¿™ç§æ¶æ„åˆ©ç”¨é€šç”¨æ¨ç†æ¨¡å‹ä½œä¸ºé«˜çº§è§„åˆ’å™¨æ¥åˆ†è§£å¤æ‚å®šç†ä¸ºä¸€ç³»åˆ—æ›´ç®€å•å­ç›®æ ‡çš„æ–¹æ³•ï¼Œæ˜¾è‘—ç¼©å°äº†æœç´¢ç©ºé—´ï¼Œå¹¶ä¿ƒè¿›äº†å¤šä¸ªæ™ºèƒ½ä½“ä¹‹é—´çš„åä½œèƒ½åŠ›ã€‚è¿™ç§å±‚æ¬¡åŒ–çš„æ–¹æ³•ä¸ä»…æé«˜äº†è®¡ç®—æ•ˆç‡ï¼Œè¿˜å¢å¼ºäº†ç³»ç»Ÿçš„å¯æ‰©å±•æ€§å’Œçµæ´»æ€§ï¼Œå¯¹äºå¤„ç†å¤æ‚çš„è®¡ç®—å’Œé€»è¾‘æ¨ç†é—®é¢˜å…·æœ‰é‡è¦çš„å¯ç¤ºæ„ä¹‰å’Œæ½œåœ¨çš„å•†ä¸šä»·å€¼åº”ç”¨äºå¤šå­¦ç§‘é¢†åŸŸå½“ä¸­å¼€è¾Ÿäº†æœºå™¨æ™ºèƒ½åŒ–åˆ›æ–°å‘å±•å’Œåº”ç”¨åœºæ™¯é¢†åŸŸçš„å¤šæ ·åŒ–é“è·¯åˆ©ç”¨å¯¹æŠ€æœ¯çš„ç§‘å­¦ç ”ç©¶æˆæœè¿›ä¸€æ­¥æ·±åŒ–è·¨å­¦ç§‘çŸ¥è¯†å’Œæ€æƒ³çš„äº¤å‰èåˆæ¨åŠ¨äººå·¥æ™ºèƒ½æŠ€æœ¯çš„è¿›ä¸€æ­¥å‘å±•å’Œåº”ç”¨æ¨å¹¿å…·æœ‰å¹¿é˜”çš„åº”ç”¨å‰æ™¯å’Œé‡è¦çš„ç¤¾ä¼šä»·å€¼ä¸ºç›¸å…³é¢†åŸŸçš„ç ”ç©¶æä¾›äº†é‡è¦çš„å‚è€ƒå’Œå¯ç¤ºæ¨åŠ¨äº†äººå·¥æ™ºèƒ½æŠ€æœ¯çš„ä¸æ–­è¿›æ­¥å’Œå‘å±•ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.06493">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-311a0b11fe3c032a66dc832b4d174b77.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-459dd296e9e333de4c5bb14063f466c3.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-6fcea538174a061d8af1fc5656996afa.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-3879198f5edb99f799e0a1ec14d23908.jpg" align="middle">
</details>


<h1 id="-17"><a href="#-17" class="headerlink" title=""></a></h1><h2 id="Tree-of-Agents-Improving-Long-Context-Capabilities-of-Large-Language-Models-through-Multi-Perspective-Reasoning"><a href="#Tree-of-Agents-Improving-Long-Context-Capabilities-of-Large-Language-Models-through-Multi-Perspective-Reasoning" class="headerlink" title="Tree of Agents: Improving Long-Context Capabilities of Large Language   Models through Multi-Perspective Reasoning"></a>Tree of Agents: Improving Long-Context Capabilities of Large Language   Models through Multi-Perspective Reasoning</h2><p><strong>Authors:Song Yu, Xiaofei Xu, Ke Deng, Li Li, Lin Tian</strong></p>
<p>Large language models (LLMs) face persistent challenges when handling long-context tasks, most notably the lost in the middle issue, where information located in the middle of a long input tends to be underutilized. Some existing methods that reduce input have the risk of discarding key information, while others that extend context windows often lead to attention dispersion. To address these limitations, we propose Tree of Agents (TOA), a multi-agent reasoning framework that segments the input into chunks processed by independent agents. Each agent generates its local cognition, then agents dynamically exchange information for collaborative reasoning along tree-structured paths. TOA enables agents to probe different reasoning orders for multi-perspective understanding, effectively mitigating position bias and reducing hallucinations. To improve processing efficiency, we incorporate prefix-hash caching and adaptive pruning strategies, achieving significant performance improvements with comparable API overhead. Experiments show that TOA, powered by compact LLaMA3.1-8B, significantly outperforms multiple baselines and demonstrates comparable performance to the latest and much larger commercial models, such as Gemini1.5-pro, on various long-context tasks. Code is available at <a target="_blank" rel="noopener" href="https://github.com/Aireduce952/Tree-of-Agents">https://github.com/Aireduce952/Tree-of-Agents</a>. </p>
<blockquote>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å¤„ç†é•¿ä¸Šä¸‹æ–‡ä»»åŠ¡æ—¶é¢ä¸´æŒä¹…æŒ‘æˆ˜ï¼Œæœ€æ˜¾è‘—çš„æ˜¯ä¸­é—´ä¸¢å¤±é—®é¢˜ï¼Œå³é•¿è¾“å…¥ä¸­ä½äºä¸­é—´çš„ä¿¡æ¯å¾€å¾€è¢«åˆ©ç”¨ä¸è¶³ã€‚ä¸€äº›å‡å°‘è¾“å…¥ç°æœ‰æ–¹æ³•å­˜åœ¨ä¸¢å¤±å…³é”®ä¿¡æ¯çš„é£é™©ï¼Œè€Œå…¶ä»–æ‰©å±•ä¸Šä¸‹æ–‡çª—å£çš„æ–¹æ³•åˆ™å¾€å¾€å¯¼è‡´æ³¨æ„åŠ›åˆ†æ•£ã€‚ä¸ºäº†è§£å†³è¿™äº›å±€é™æ€§ï¼Œæˆ‘ä»¬æå‡ºäº†Agentæ ‘ï¼ˆTOAï¼‰è¿™ä¸€å¤šæ™ºèƒ½ä½“æ¨ç†æ¡†æ¶ã€‚å®ƒå°†è¾“å…¥åˆ†å‰²æˆç”±ç‹¬ç«‹æ™ºèƒ½ä½“å¤„ç†çš„å—ã€‚æ¯ä¸ªæ™ºèƒ½ä½“ç”Ÿæˆå…¶å±€éƒ¨è®¤çŸ¥ï¼Œç„¶åæ™ºèƒ½ä½“æ²¿ç€æ ‘çŠ¶ç»“æ„è·¯å¾„åŠ¨æ€äº¤æ¢ä¿¡æ¯è¿›è¡ŒååŒæ¨ç†ã€‚TOAä½¿æ™ºèƒ½ä½“èƒ½å¤Ÿæ¢ç©¶ä¸åŒçš„æ¨ç†é¡ºåºä»¥å®ç°å¤šè§’åº¦ç†è§£ï¼Œæœ‰æ•ˆåœ°å‡è½»ä½ç½®åè§å¹¶å‡å°‘å¹»è§‰ã€‚ä¸ºäº†æé«˜å¤„ç†æ•ˆç‡ï¼Œæˆ‘ä»¬ç»“åˆäº†å‰ç¼€å“ˆå¸Œç¼“å­˜å’Œè‡ªé€‚åº”ä¿®å‰ªç­–ç•¥ï¼Œåœ¨APIå¼€é”€ç›¸å½“çš„æƒ…å†µä¸‹å®ç°äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚å®éªŒè¡¨æ˜ï¼Œä»¥ç´§å‡‘çš„LLaMA3.1-8Bä¸ºåŠ¨åŠ›çš„TOAæ˜¾è‘—ä¼˜äºå¤šä¸ªåŸºçº¿ï¼Œå¹¶åœ¨å„ç§é•¿ä¸Šä¸‹æ–‡ä»»åŠ¡ä¸Šè¡¨ç°å‡ºä¸æœ€æ–°çš„æ›´å¤§è§„æ¨¡å•†ä¸šæ¨¡å‹ï¼ˆå¦‚Gemini1.5-proï¼‰ç›¸å½“çš„æ€§èƒ½ã€‚ä»£ç å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/Aireduce952/Tree-of-Agents%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/Aireduce952/Tree-of-Agentsæ‰¾åˆ°ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.06436v1">PDF</a> 19 pages, 5 figures</p>
<p><strong>Summary</strong></p>
<p>å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å¤„ç†é•¿æ–‡æœ¬ä»»åŠ¡æ—¶é¢ä¸´ä¸­é—´ä¿¡æ¯ä¸¢å¤±çš„æŒ‘æˆ˜ã€‚ä¸ºè§£å†³è¿™ä¸€é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†å¤šæ™ºèƒ½ä½“æ¨ç†æ¡†æ¶â€”â€”Tree of Agentsï¼ˆTOAï¼‰ã€‚è¯¥æ¡†æ¶å°†è¾“å…¥åˆ†å‰²æˆå¤šä¸ªç‰‡æ®µï¼Œç”±ç‹¬ç«‹æ™ºèƒ½ä½“å¤„ç†ã€‚æ™ºèƒ½ä½“ç”Ÿæˆå±€éƒ¨è®¤çŸ¥åï¼Œé€šè¿‡æ ‘çŠ¶ç»“æ„è·¯å¾„åŠ¨æ€äº¤æ¢ä¿¡æ¯ï¼Œè¿›è¡ŒååŒæ¨ç†ã€‚TOAèƒ½æœ‰æ•ˆå‡è½»ä½ç½®åè§ï¼Œå‡å°‘è™šæ„ç°è±¡ã€‚ç»“åˆå‰ç¼€å“ˆå¸Œç¼“å­˜å’Œè‡ªé€‚åº”å‰ªæç­–ç•¥ï¼Œæé«˜äº†å¤„ç†æ•ˆç‡ã€‚å®éªŒè¡¨æ˜ï¼ŒTOAåœ¨å¤šç§é•¿æ–‡æœ¬ä»»åŠ¡ä¸Šè¡¨ç°ä¼˜äºå¤šä¸ªåŸºçº¿æ¨¡å‹ï¼Œå¹¶ä¸æœ€æ–°çš„å¤§å‹å•†ä¸šæ¨¡å‹å¦‚Gemini1.5-proè¡¨ç°ç›¸å½“ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å¤„ç†é•¿æ–‡æœ¬ä»»åŠ¡æ—¶é¢ä¸´ä¸­é—´ä¿¡æ¯ä¸¢å¤±çš„æŒ‘æˆ˜ã€‚</li>
<li>Tree of Agentsï¼ˆTOAï¼‰æ˜¯ä¸€ä¸ªå¤šæ™ºèƒ½ä½“æ¨ç†æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³è¿™ä¸€é—®é¢˜ã€‚</li>
<li>TOAå°†è¾“å…¥åˆ†å‰²æˆç‰‡æ®µï¼Œç”±ç‹¬ç«‹æ™ºèƒ½ä½“å¤„ç†ï¼Œå¹¶é€šè¿‡åŠ¨æ€ä¿¡æ¯äº¤æ¢è¿›è¡ŒååŒæ¨ç†ã€‚</li>
<li>TOAèƒ½æœ‰æ•ˆå‡è½»ä½ç½®åè§å’Œå‡å°‘è™šæ„ç°è±¡ã€‚</li>
<li>TOAç»“åˆäº†å‰ç¼€å“ˆå¸Œç¼“å­˜å’Œè‡ªé€‚åº”å‰ªæç­–ç•¥ï¼Œæé«˜äº†å¤„ç†æ•ˆç‡ã€‚</li>
<li>å®éªŒè¡¨æ˜ï¼ŒTOAåœ¨å¤šç§é•¿æ–‡æœ¬ä»»åŠ¡ä¸Šçš„è¡¨ç°ä¼˜äºå¤šä¸ªåŸºçº¿æ¨¡å‹ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.06436">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-e3ada1f6e6d1396c764a03b111ee7549.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-449acbce828e47bbc7b4c6973b82ee5e.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-24dddc01e1b905335cab2b56d30c2f34.jpg" align="middle">
</details>


<h1 id="-18"><a href="#-18" class="headerlink" title=""></a></h1><h2 id="A-Fragile-Number-Sense-Probing-the-Elemental-Limits-of-Numerical-Reasoning-in-LLMs"><a href="#A-Fragile-Number-Sense-Probing-the-Elemental-Limits-of-Numerical-Reasoning-in-LLMs" class="headerlink" title="A Fragile Number Sense: Probing the Elemental Limits of Numerical   Reasoning in LLMs"></a>A Fragile Number Sense: Probing the Elemental Limits of Numerical   Reasoning in LLMs</h2><p><strong>Authors:Roussel Rahman, Aashwin Ananda Mishra</strong></p>
<p>Large Language Models (LLMs) have demonstrated remarkable emergent capabilities, yet the robustness of their numerical reasoning remains an open question. While standard benchmarks evaluate LLM reasoning on complex problem sets using aggregated metrics, they often obscure foundational weaknesses. In this work, we probe LLM mathematical numeracy by evaluating performance on problems of escalating complexity, from constituent operations to combinatorial puzzles. We test several state-of-the-art LLM-based agents on a 100-problem challenge comprising four categories: (1) basic arithmetic, (2) advanced operations, (3) primality checking, and (4) the Game of 24 number puzzle. Our results show that while the agents achieved high accuracy on the first three categories, which require deterministic algorithmic execution, they consistently failed at the number puzzle, underlining its demand for a heuristic search over a large combinatorial space to be a significant bottleneck. These findings reveal that the agentsâ€™ proficiency is largely confined to recalling and executing known algorithms, rather than performing generative problem-solving. This suggests their apparent numerical reasoning is more akin to sophisticated pattern-matching than flexible, analytical thought, limiting their potential for tasks that require novel or creative numerical insights. </p>
<blockquote>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å·²ç»å±•ç°å‡ºæƒŠäººçš„æ–°å…´èƒ½åŠ›ï¼Œç„¶è€Œå®ƒä»¬çš„æ•°å€¼æ¨ç†çš„ç¨³å¥æ€§ä»ç„¶æ˜¯ä¸€ä¸ªæ‚¬è€Œæœªå†³çš„é—®é¢˜ã€‚è™½ç„¶æ ‡å‡†åŸºå‡†æµ‹è¯•ä½¿ç”¨èšåˆåº¦é‡æ¥è¯„ä¼°LLMåœ¨å¤æ‚é—®é¢˜é›†ä¸Šçš„æ¨ç†èƒ½åŠ›ï¼Œä½†å®ƒä»¬å¾€å¾€ä¼šæ©ç›–åŸºç¡€å¼±ç‚¹ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬é€šè¿‡è¯„ä¼°åœ¨ä¸åŒå¤æ‚åº¦çš„æ•°å­¦é—®é¢˜ä¸Šçš„è¡¨ç°æ¥æ¢ç©¶LLMçš„æ•°å­¦è®¡ç®—èƒ½åŠ›ï¼Œä»åŸºæœ¬è¿ç®—åˆ°ç»„åˆè°œé¢˜ã€‚æˆ‘ä»¬åœ¨åŒ…å«å››ä¸ªç±»åˆ«çš„100ä¸ªé—®é¢˜çš„æŒ‘æˆ˜ä¸Šæµ‹è¯•äº†å‡ ç§æœ€å…ˆè¿›çš„åŸºäºLLMçš„ä»£ç†ï¼Œè¿™äº›ç±»åˆ«åŒ…æ‹¬ï¼šï¼ˆ1ï¼‰åŸºæœ¬ç®—æœ¯ï¼Œï¼ˆ2ï¼‰é«˜çº§è¿ç®—ï¼Œï¼ˆ3ï¼‰è´¨æ•°æ£€æŸ¥ï¼Œä»¥åŠï¼ˆ4ï¼‰24ç‚¹æ¸¸æˆè°œé¢˜ã€‚æˆ‘ä»¬çš„ç»“æœè¡¨æ˜ï¼Œå°½ç®¡ä»£ç†åœ¨å‰ä¸‰ä¸ªç±»åˆ«ä¸­è¾¾åˆ°äº†å¾ˆé«˜çš„å‡†ç¡®æ€§ï¼Œè¿™äº›ç±»åˆ«éœ€è¦ç¡®å®šæ€§ç®—æ³•çš„æ‰§è¡Œï¼Œä½†ä»–ä»¬åœ¨æ•°å­—è°œé¢˜æ–¹é¢ä¸€ç›´è¡¨ç°ä¸ä½³ï¼Œè¿™å¼ºè°ƒäº†åœ¨å¤§ç»„åˆç©ºé—´ä¸­è¿›è¡Œå¯å‘å¼æœç´¢çš„éœ€æ±‚æ˜¯ä¸€ä¸ªé‡å¤§ç“¶é¢ˆã€‚è¿™äº›å‘ç°è¡¨æ˜ï¼Œä»£ç†çš„ç†Ÿç»ƒç¨‹åº¦ä¸»è¦å±€é™äºå›å¿†å’Œæ‰§è¡Œå·²çŸ¥ç®—æ³•ï¼Œè€Œä¸æ˜¯è¿›è¡Œç”Ÿæˆå¼é—®é¢˜è§£å†³ã€‚è¿™è¡¨æ˜å®ƒä»¬æ˜æ˜¾çš„æ•°å€¼æ¨ç†æ›´åƒå¤æ‚çš„æ¨¡å¼åŒ¹é…ï¼Œè€Œä¸æ˜¯çµæ´»çš„åˆ†ææ€ç»´ï¼Œè¿™é™åˆ¶äº†å®ƒä»¬åœ¨éœ€è¦æ–°é¢–æˆ–åˆ›é€ æ€§æ•°å€¼è§è§£çš„ä»»åŠ¡ä¸Šçš„æ½œåŠ›ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.06332v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨æ¶Œç°èƒ½åŠ›æ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œä½†å…¶æ•°å€¼æ¨ç†çš„ç¨³å¥æ€§ä»æ˜¯æœªè§£ä¹‹è°œã€‚æœ¬ç ”ç©¶é€šè¿‡è¯„ä¼°LLMåœ¨æ•°å­¦ç´ å…»æ–¹é¢çš„è¡¨ç°ï¼Œä»åŸºæœ¬æ“ä½œåˆ°ç»„åˆè°œé¢˜çš„é—®é¢˜å¤æ‚æ€§é€’å¢ï¼Œæ¥æ¢ç©¶å…¶æ•°å­¦èƒ½åŠ›ã€‚æµ‹è¯•äº†å¤šä¸ªæœ€å…ˆè¿›çš„LLMä»£ç†ï¼ŒåŒ…æ‹¬åŸºæœ¬ç®—æœ¯ã€é«˜çº§è¿ç®—ã€è´¨æ•°æ£€æŸ¥å’ŒäºŒåå››å°æ—¶æ¸¸æˆè°œé¢˜ç­‰å››ç±»é—®é¢˜ã€‚å‘ç°ä»£ç†åœ¨å‰ä¸‰ç±»é—®é¢˜ä¸Šçš„å‡†ç¡®æ€§è¾ƒé«˜ï¼Œä½†åœ¨éœ€è¦å¤§é‡å¯å‘å¼æœç´¢å’Œç»„åˆç©ºé—´çš„é—®é¢˜ä¸Šè¡¨ç°ä¸ä½³ã€‚è¿™è¡¨æ˜ä»£ç†çš„èƒ½åŠ›ä¸»è¦é™äºå›å¿†å’Œæ‰§è¡Œå·²çŸ¥ç®—æ³•ï¼Œè€Œéåˆ›é€ æ€§è§£å†³é—®é¢˜ã€‚å› æ­¤ï¼Œå…¶æ•°å€¼æ¨ç†èƒ½åŠ›æ›´åƒå¤æ‚çš„æ¨¡å¼åŒ¹é…ï¼Œè€Œéçµæ´»çš„åˆ†ææ€ç»´ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨æ•°å€¼æ¨ç†æ–¹é¢çš„ç¨³å¥æ€§æœ‰å¾…æå‡ã€‚</li>
<li>LLMsåœ¨æ•°å­¦ç´ å…»æ–¹é¢çš„è¡¨ç°é€šè¿‡é€’å¢å¤æ‚æ€§é—®é¢˜è¿›è¡Œè¯„ä¼°ã€‚</li>
<li>LLMä»£ç†åœ¨åŸºæœ¬ç®—æœ¯ã€é«˜çº§è¿ç®—å’Œè´¨æ•°æ£€æŸ¥é—®é¢˜ä¸Šè¡¨ç°è¾ƒå¥½ã€‚</li>
<li>åœ¨éœ€è¦å¯å‘å¼æœç´¢å’Œç»„åˆç©ºé—´çš„è°œé¢˜ä¸Šï¼ŒLLMä»£ç†è¡¨ç°ä¸ä½³ã€‚</li>
<li>LLMä»£ç†çš„èƒ½åŠ›ä¸»è¦é™äºå›å¿†å’Œæ‰§è¡Œå·²çŸ¥ç®—æ³•ã€‚</li>
<li>LLMsçš„æ•°å€¼æ¨ç†èƒ½åŠ›æ›´åƒå¤æ‚çš„æ¨¡å¼åŒ¹é…ï¼Œç¼ºä¹çµæ´»çš„åˆ†ææ€ç»´ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.06332">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-1be96656775f9d20ab242bc9e3b8faed.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-8e0071cbf2cef1c5f218a826caabf633.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-5dc83e6cc7175765bf8c82483c932701.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-8c2869a275c9620354240ecde70ea28c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-4c2051b4c5d0577a440d50d2005115a9.jpg" align="middle">
</details>


<h1 id="-19"><a href="#-19" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-09-10/R1_Reasoning/">https://kedreamix.github.io/Talk2Paper/Paper/2025-09-10/R1_Reasoning/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/R1-Reasoning/">
                                    <span class="chip bg-color">R1_Reasoning</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-09-10/LLM/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-4d1eeb0f0bc50c018a456e5ed79a9bf5.jpg" class="responsive-img" alt="LLM">
                        
                        <span class="card-title">LLM</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            LLM æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-09-10  Beyond Two-Stage Training Cooperative SFT and RL for LLM Reasoning
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-09-10
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/LLM/" class="post-category">
                                    LLM
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/LLM/">
                        <span class="chip bg-color">LLM</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-09-10/Talking%20Head%20Generation/">
                    <div class="card-image">
                        
                        <img src="https://pica.zhimg.com/v2-d8dc6b11a1ccf78cff8c616020f98c51.jpg" class="responsive-img" alt="Talking Head Generation">
                        
                        <span class="card-title">Talking Head Generation</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Talking Head Generation æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-09-10  Talk Isn't Always Cheap Understanding Failure Modes in Multi-Agent   Debate
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-09-10
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Talking-Head-Generation/" class="post-category">
                                    Talking Head Generation
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Talking-Head-Generation/">
                        <span class="chip bg-color">Talking Head Generation</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">31686.1k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
