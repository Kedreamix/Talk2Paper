<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="LLM">
    <meta name="description" content="LLM 方向最新论文已更新，请持续关注 Update in 2025-09-10  Beyond Two-Stage Training Cooperative SFT and RL for LLM Reasoning">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>LLM | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loader页面消失采用渐隐的方式*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logo出现动画 */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//使用渐隐的方法淡出loading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//强制显示loading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">嘘~  正在从服务器偷取页面 . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>首页</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>标签</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>分类</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>归档</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="搜索" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="深色/浅色模式" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			首页
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			标签
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			分类
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			归档
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://picx.zhimg.com/v2-4d1eeb0f0bc50c018a456e5ed79a9bf5.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">LLM</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/LLM/">
                                <span class="chip bg-color">LLM</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/LLM/" class="post-category">
                                LLM
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2025-09-10
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>更新日期:&nbsp;&nbsp;
                    2025-09-10
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp;
                    22.2k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp;
                    90 分
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>阅读次数:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>⚠️ 以下所有内容总结都来自于 大语言模型的能力，如有错误，仅供参考，谨慎使用<br>🔴 请注意：千万不要用于严肃的学术场景，只能用于论文阅读前的初筛！<br>💗 如果您觉得我们的项目对您有帮助 <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ，还请您给我们一些鼓励！⭐️ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFace免费体验</a></p>
</blockquote>
<h1 id="2025-09-10-更新"><a href="#2025-09-10-更新" class="headerlink" title="2025-09-10 更新"></a>2025-09-10 更新</h1><h2 id="Beyond-Two-Stage-Training-Cooperative-SFT-and-RL-for-LLM-Reasoning"><a href="#Beyond-Two-Stage-Training-Cooperative-SFT-and-RL-for-LLM-Reasoning" class="headerlink" title="Beyond Two-Stage Training: Cooperative SFT and RL for LLM Reasoning"></a>Beyond Two-Stage Training: Cooperative SFT and RL for LLM Reasoning</h2><p><strong>Authors:Liang Chen, Xueting Han, Li Shen, Jing Bai, Kam-Fai Wong</strong></p>
<p>Reinforcement learning (RL) has proven effective in incentivizing the reasoning abilities of large language models (LLMs), but suffers from severe efficiency challenges due to its trial-and-error nature. While the common practice employs supervised fine-tuning (SFT) as a warm-up stage for RL, this decoupled two-stage approach limits interaction between SFT and RL, thereby constraining overall effectiveness. This study introduces a novel method for learning reasoning models that employs bilevel optimization to facilitate better cooperation between these training paradigms. By conditioning the SFT objective on the optimal RL policy, our approach enables SFT to meta-learn how to guide RL’s optimization process. During training, the lower level performs RL updates while simultaneously receiving SFT supervision, and the upper level explicitly maximizes the cooperative gain-the performance advantage of joint SFT-RL training over RL alone. Empirical evaluations on five reasoning benchmarks demonstrate that our method consistently outperforms baselines and achieves a better balance between effectiveness and efficiency. </p>
<blockquote>
<p>强化学习（RL）已经证明可以激励大型语言模型（LLM）的推理能力，但由于其试错性质而面临严重的效率挑战。虽然通常的做法是采用监督微调（SFT）作为RL的预热阶段，但这种解耦的两阶段方法限制了SFT和RL之间的交互，从而限制了整体效果。本研究引入了一种学习推理模型的新方法，该方法采用两级优化，以促进这些训练模式之间的更好协作。通过根据最佳RL策略制定SFT目标，我们的方法使SFT能够元学习如何引导RL的优化过程。在训练过程中，较低层次进行RL更新，同时接受SFT监督，而较高层次则明确最大化合作收益——联合SFT-RL训练相对于仅使用RL的性能优势。在五个推理基准测试上的经验评估表明，我们的方法始终优于基线，并在有效性和效率之间取得了更好的平衡。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.06948v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>强化学习（RL）在激励大型语言模型（LLM）的推理能力方面表现出良好的效果，但由于其试错性质而面临效率挑战。虽然常见的做法是采用监督微调（SFT）作为RL的预热阶段，但这种解耦的两阶段方法限制了SFT和RL之间的交互，从而限制了整体效果。本研究引入了一种采用双层优化方法学习推理模型的新方法，以促进这两种训练范式之间的更好合作。通过以最佳RL策略为条件，我们的方法使SFT能够元学习如何引导RL的优化过程。在训练过程中，下层执行RL更新，同时接受SFT监督，上层则明确最大化合作收益——联合SFT-RL训练相对于仅使用RL的性能优势。实证评估表明，我们的方法在五个推理基准测试上均优于基线，并在有效性和效率之间达到了更好的平衡。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>强化学习在激励大型语言模型的推理能力上有效，但存在效率挑战。</li>
<li>常见的强化学习方法采用监督微调作为预热阶段，但这种方法限制了交互和整体效果。</li>
<li>本研究提出了一种采用双层优化的新方法，以促进监督微调与强化学习之间的合作。</li>
<li>该方法使监督微调能够元学习如何引导强化学习的优化过程。</li>
<li>在训练过程中，下层执行强化学习更新并接受监督调教的监督，上层则关注于最大化合作收益。</li>
<li>实证评估表明，该方法在多个推理基准测试上优于基线方法。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.06948">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-2893830b7f14abd2e7ca17545c8ceed4.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-7450908b103e5cfe616090d68d5ecfce.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-23d60fd076127d0aaf3adf864b1c85f5.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-6c064df4739d0d12c3ba393217df7564.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="Staying-in-the-Sweet-Spot-Responsive-Reasoning-Evolution-via-Capability-Adaptive-Hint-Scaffolding"><a href="#Staying-in-the-Sweet-Spot-Responsive-Reasoning-Evolution-via-Capability-Adaptive-Hint-Scaffolding" class="headerlink" title="Staying in the Sweet Spot: Responsive Reasoning Evolution via   Capability-Adaptive Hint Scaffolding"></a>Staying in the Sweet Spot: Responsive Reasoning Evolution via   Capability-Adaptive Hint Scaffolding</h2><p><strong>Authors:Ziheng Li, Zexu Sun, Jinman Zhao, Erxue Min, Yongcheng Zeng, Hui Wu, Hengyi Cai, Shuaiqiang Wang, Dawei Yin, Xu Chen, Zhi-Hong Deng</strong></p>
<p>Reinforcement learning with verifiable rewards (RLVR) has achieved remarkable success in enhancing the reasoning capabilities of large language models (LLMs). However, existing RLVR methods often suffer from exploration inefficiency due to mismatches between the training data’s difficulty and the model’s capability. LLMs fail to discover viable reasoning paths when problems are overly difficult, while learning little new capability when problems are too simple. In this work, we formalize the impact of problem difficulty by quantifying the relationship between loss descent speed and rollout accuracy. Building on this analysis, we propose SEELE, a novel supervision-aided RLVR framework that dynamically adjusts problem difficulty to stay within the high-efficiency region. SEELE augments each training sample by appending a hint (part of a full solution) after the original problem. Unlike previous hint-based approaches, SEELE deliberately and adaptively adjusts the hint length for each problem to achieve an optimal difficulty. To determine the optimal hint length, SEELE employs a multi-round rollout sampling strategy. In each round, it fits an item response theory model to the accuracy-hint pairs collected in preceding rounds to predict the required hint length for the next round. This instance-level, real-time difficulty adjustment aligns problem difficulty with the evolving model capability, thereby improving exploration efficiency. Experimental results show that SEELE outperforms Group Relative Policy Optimization (GRPO) and Supervised Fine-tuning (SFT) by +11.8 and +10.5 points, respectively, and surpasses the best previous supervision-aided approach by +3.6 points on average across six math reasoning benchmarks. </p>
<blockquote>
<p>强化学习可验证奖励（RLVR）在提高大型语言模型（LLM）的推理能力方面取得了显著的成功。然而，现有的RLVR方法常常因为训练数据难度与模型能力之间的不匹配而导致探索效率低下。当问题过于困难时，LLM无法发现可行的推理路径，而当问题过于简单时，它们又无法学习到新的能力。</p>
</blockquote>
<p>在这项工作中，我们通过量化损失下降速度与回滚准确度之间的关系来正式化问题难度的影响。基于这一分析，我们提出了SEELE，一个新型的监督辅助RLVR框架，它能动态调整问题难度以保持在高效区域。SEELE通过在每个训练样本后附加一个提示（完整解决方案的一部分）来增强每个训练样本。不同于以前的基于提示的方法，SEELE为每个问题精心且自适应地调整提示长度以达到最佳难度。</p>
<p>为了确定最佳的提示长度，SEELE采用多轮回滚采样策略。在每轮中，它根据前面几轮收集的准确度和提示对来拟合项目反应理论模型，以预测下一轮所需的提示长度。这种实例级别的实时难度调整使问题难度与不断进化的模型能力相匹配，从而提高了探索效率。</p>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.06923v1">PDF</a> Work in progress</p>
<p><strong>Summary</strong></p>
<p>强化学习可验证奖励（RLVR）在提高大型语言模型（LLM）的推理能力方面取得了显著的成功。然而，现有RLVR方法常因训练数据难度与模型能力的不匹配而导致探索效率低下。当问题过于困难时，LLM无法发现可行的推理路径；当问题过于简单时，模型学习不到新的能力。本研究通过量化损失下降速度与回滚准确性的关系，正式化问题难度的影响。基于此分析，我们提出了SEELE，一个新型的监督辅助RLVR框架，能够动态调整问题难度以保持在高效区域。SEELE通过追加提示（完整解决方案的一部分）来增强每个训练样本。不同于以往的提示方法，SEELE为每个问题精心且自适应地调整提示长度以达到最佳难度。为了确定最佳提示长度，SEELE采用多轮回滚采样策略。每轮中，它根据前几轮收集的准确性与提示对来拟合项目反应理论模型，以预测下一轮所需的提示长度。这种实例级别的实时难度调整使问题难度与不断进化的模型能力相匹配，提高了探索效率。实验结果显示，SEELE在六个数学推理基准测试中分别优于Group Relative Policy Optimization（GRPO）和Supervised Fine-tuning（SFT）11.8和10.5个百分点，并平均优于之前的最佳监督辅助方法3.6个百分点。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>RLVR在提高LLM推理能力上表现卓越，但存在探索效率低下的问题。</li>
<li>问题难度与模型能力的不匹配是探索效率低下的主要原因。</li>
<li>SEELE框架通过动态调整问题难度来提高探索效率。</li>
<li>SEELE通过追加提示来增强训练样本，并自适应地调整每个问题的提示长度。</li>
<li>SEELE采用多轮回滚采样策略来确定最佳提示长度。</li>
<li>SEELE实例级别的实时难度调整匹配问题难度与模型能力。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.06923">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-63b1003145d116a08c96c12255b03fad.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-dbb22b2ee151451b2debcfc338c9ac75.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-d25be95785455750f74d4428043d5415.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a7a89fe1be3e90617108a1d248227e73.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="The-Majority-is-not-always-right-RL-training-for-solution-aggregation"><a href="#The-Majority-is-not-always-right-RL-training-for-solution-aggregation" class="headerlink" title="The Majority is not always right: RL training for solution aggregation"></a>The Majority is not always right: RL training for solution aggregation</h2><p><strong>Authors:Wenting Zhao, Pranjal Aggarwal, Swarnadeep Saha, Asli Celikyilmaz, Jason Weston, Ilia Kulikov</strong></p>
<p>Scaling up test-time compute, by generating multiple independent solutions and selecting or aggregating among them, has become a central paradigm for improving large language models (LLMs) on challenging reasoning tasks. While most prior work relies on simple majority voting or reward model ranking to aggregate solutions, these approaches may only yield limited benefits. In this work, we propose to learn aggregation as an explicit reasoning skill: given a set of candidate solutions, we train an aggregator model to review, reconcile, and synthesize a final, correct answer using reinforcement learning from verifiable rewards. A key ingredient is careful balancing of easy and hard training examples, allowing the model to learn both to recover minority-but-correct answers as well as easy majority-correct answers. Empirically, we find our method, AggLM, outperforms both strong rule-based and reward-model baselines, across multiple benchmarks. Furthermore, it generalizes effectively to solutions from differing models, including stronger ones than contained in the training data, all while requiring substantially fewer tokens than majority voting with larger numbers of solutions. </p>
<blockquote>
<p>通过生成多个独立解决方案并在其中进行选择或聚合，扩大测试时的计算能力，已成为在具有挑战性的推理任务中改进大型语言模型（LLM）的核心范式。虽然大多数先前的工作依赖于简单的多数投票或奖励模型排名来聚合解决方案，但这些方法可能只能产生有限的效益。在本研究中，我们提出将聚合作为一种明确的推理技能来学习：给定一组候选解决方案，我们训练一个聚合器模型，使用可验证的奖励进行强化学习，以审查、协调并合成最终的正确答案。关键要素是仔细平衡简单和困难的训练示例，让模型既能恢复少数但正确的答案，也能获得简单的多数正确答案。从经验上看，我们发现我们的方法AggLM在多基准测试中均表现出优于强大的基于规则和奖励模型基线。此外，它还能够有效地推广到来自不同模型的解决方案，包括训练数据中的更强模型。同时，它需要使用的令牌数量远远少于使用更多解决方案的多数投票方法。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.06870v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>大规模语言模型（LLM）在挑战性推理任务上，通过生成多个独立解决方案并进行选择或聚合来提高性能已成为中心范式。然而，大多数先前的工作依赖于简单的多数投票或奖励模型排名来聚合解决方案，这些方法可能只能带来有限的效益。在这项工作中，我们提出将聚合作为一种明确的推理技能来学习：给定一组候选解决方案，我们训练一个聚合器模型，使用可验证的奖励通过强化学习来审查、协调和综合最终的正确答案。通过平衡简单和困难的训练示例，我们的模型可以学习从少数但正确的答案和大多数正确的答案中恢复答案的能力。实验结果显示，我们的方法AggLM在多组标准测试上的表现优于基于规则和奖励模型的基线方法，并且可以有效地推广到来自不同模型的解决方案，包括比训练数据更强的模型，同时需要的令牌数量大大减少。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>通过生成多个独立解决方案并在测试时进行聚合，已成为改善大型语言模型（LLM）在挑战性推理任务上表现的中心范式。</li>
<li>大多数现有方法依赖于简单的多数投票或奖励模型排名来聚合解决方案，这可能会导致有限的效益。</li>
<li>在这项研究中，提出了一种新的方法——AggLM，通过训练一个聚合器模型，使用强化学习从可验证的奖励中审查、协调和综合答案。</li>
<li>AggLM能够在平衡简单和困难的训练示例时学习恢复答案的能力，包括从少数但正确的答案和大多数正确的答案中恢复。</li>
<li>AggLM在多个标准测试上的表现优于基于规则和奖励模型的基线方法。</li>
<li>AggLM可以有效地推广到来自不同模型的解决方案，包括比训练数据更强的模型。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.06870">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-d5a2fd48f65870f391c16c0dde4ba202.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-a845e858c885eee93fd3cf68c7b36dbf.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-f9c4067cce580e50a88d6a639d686307.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-fa22ac50e7ff9e520f6b1430c7656d1c.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-923f66cdc4d4efbeb6b48dd575bbf6a6.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="EPT-Benchmark-Evaluation-of-Persian-Trustworthiness-in-Large-Language-Models"><a href="#EPT-Benchmark-Evaluation-of-Persian-Trustworthiness-in-Large-Language-Models" class="headerlink" title="EPT Benchmark: Evaluation of Persian Trustworthiness in Large Language   Models"></a>EPT Benchmark: Evaluation of Persian Trustworthiness in Large Language   Models</h2><p><strong>Authors:Mohammad Reza Mirbagheri, Mohammad Mahdi Mirkamali, Zahra Motoshaker Arani, Ali Javeri, Amir Mahdi Sadeghzadeh, Rasool Jalili</strong></p>
<p>Large Language Models (LLMs), trained on extensive datasets using advanced deep learning architectures, have demonstrated remarkable performance across a wide range of language tasks, becoming a cornerstone of modern AI technologies. However, ensuring their trustworthiness remains a critical challenge, as reliability is essential not only for accurate performance but also for upholding ethical, cultural, and social values. Careful alignment of training data and culturally grounded evaluation criteria are vital for developing responsible AI systems. In this study, we introduce the EPT (Evaluation of Persian Trustworthiness) metric, a culturally informed benchmark specifically designed to assess the trustworthiness of LLMs across six key aspects: truthfulness, safety, fairness, robustness, privacy, and ethical alignment. We curated a labeled dataset and evaluated the performance of several leading models - including ChatGPT, Claude, DeepSeek, Gemini, Grok, LLaMA, Mistral, and Qwen - using both automated LLM-based and human assessments. Our results reveal significant deficiencies in the safety dimension, underscoring the urgent need for focused attention on this critical aspect of model behavior. Furthermore, our findings offer valuable insights into the alignment of these models with Persian ethical-cultural values and highlight critical gaps and opportunities for advancing trustworthy and culturally responsible AI. The dataset is publicly available at: <a target="_blank" rel="noopener" href="https://github.com/Rezamirbagheri110/EPT-Benchmark">https://github.com/Rezamirbagheri110/EPT-Benchmark</a>. </p>
<blockquote>
<p>大型语言模型（LLM）通过先进的深度学习架构在大量数据集上进行训练，已在各种语言任务中展现出卓越的性能，成为现代AI技术的核心。然而，确保它们的可信性仍然是一个巨大的挑战，因为可靠性不仅对准确性能至关重要，而且也是维持道德、文化和社会价值的关键。培训数据的仔细对齐和文化上立足的评估标准是发展负责任的AI系统的重要条件。在本研究中，我们介绍了EPT（波斯语可信度评估）指标，这是一个受文化启发的基准测试，专门设计用于评估LLM在真实性、安全性、公平性、稳健性、隐私和道德一致性等六个关键方面的可信度。我们整理了一个标记数据集，并使用基于LLM的自动化评估和人工评估，对包括ChatGPT、Claude、DeepSeek、Gemini、Grok、LLaMA、Mistral和Qwen等多个领先模型进行了评估。我们的结果表明，在安全方面存在显著缺陷，这突显了对模型行为这一关键方面的关注迫在眉睫。此外，我们的研究还发现这些模型与波斯道德文化价值观的契合程度，并揭示了实现可信和符合文化的AI的关键差距和机会。数据集可在以下网址公开获取：<a target="_blank" rel="noopener" href="https://github.com/Rezamirbagheri110/EPT-Benchmark">https://github.com/Rezamirbagheri110/EPT-Benchmark</a> 。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.06838v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>大规模语言模型（LLM）在现代AI技术中扮演着重要角色，已广泛应用于各种语言任务并展现出卓越性能。然而，确保其可信性是至关重要的挑战，不仅关乎性能准确性，也关乎维护伦理、文化和社值。本研究介绍了EPT（波斯可信性评价）指标，这是一个专门设计的文化信息基准测试，用于评估LLM在真实性、安全性、公平性、稳健性、隐私和道德对齐等六个关键方面的可信度。通过对多个主流模型的安全性能进行评估，发现存在明显缺陷，强调迫切需要关注这一关键模型行为的方面。此外，本研究还发现这些模型与波斯伦理文化价值观的契合度存在差距和机遇，为促进可信和文化负责的人工智能提供了宝贵见解。数据集可在公开访问：<a target="_blank" rel="noopener" href="https://github.com/Rezamirbagheri110/EPT-Benchmark%E3%80%82">https://github.com/Rezamirbagheri110/EPT-Benchmark。</a></p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>LLMs已成为现代AI技术的核心，广泛应用于各种语言任务。</li>
<li>确保LLMs的可靠性对于维护伦理、文化和社会价值至关重要。</li>
<li>EPT指标是一个文化信息基准测试，用于评估LLM在六个关键方面的可信度：真实性、安全性、公平性、稳健性、隐私和道德对齐。</li>
<li>LLM在安全性能方面存在明显不足，需要重点关注。</li>
<li>LLM与波斯伦理文化价值观的契合度存在差距和机遇。</li>
<li>公开可用的数据集为推进可信和文化负责的人工智能提供了资源。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.06838">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-624f2cf48af5042d337cdc311e2cd662.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-e39c5aa2542d33c3c5b1106eea6f4c45.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-ce762213c79be8f2ebcdc0699aa51ed6.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="RAFFLES-Reasoning-based-Attribution-of-Faults-for-LLM-Systems"><a href="#RAFFLES-Reasoning-based-Attribution-of-Faults-for-LLM-Systems" class="headerlink" title="RAFFLES: Reasoning-based Attribution of Faults for LLM Systems"></a>RAFFLES: Reasoning-based Attribution of Faults for LLM Systems</h2><p><strong>Authors:Chenyang Zhu, Spencer Hong, Jingyu Wu, Kushal Chawla, Charlotte Tang, Youbing Yin, Nathan Wolfe, Erin Babinsky, Daben Liu</strong></p>
<p>We have reached a critical roadblock in the development and enhancement of long-horizon, multi-component LLM agentic systems: it is incredibly tricky to identify where these systems break down and why. Evaluation capabilities that currently exist today (e.g., single pass LLM-as-a-judge) are limited in that they often focus on individual metrics or capabilities, end-to-end outcomes, and are narrowly grounded on the preferences of humans. We argue that to match the agentic capabilities, evaluation frameworks must also be able to reason, probe, iterate, and understand the complex logic passing through these systems over long horizons. In this paper, we present RAFFLES - an evaluation architecture that incorporates reasoning and iterative refinement. Specifically, RAFFLES operates as an iterative, multi-component pipeline, using a central Judge to systematically investigate faults and a set of specialized Evaluators to assess not only the system’s components but also the quality of the reasoning by the Judge itself, thereby building a history of hypotheses. We tested RAFFLES against several baselines on the Who&amp;When dataset, a benchmark designed to diagnose the “who” (agent) and “when” (step) of a system’s failure. RAFFLES outperforms these baselines, achieving an agent-step fault pair accuracy of over 43% on the Algorithmically-Generated dataset (a substantial increase from the previously published best of 16.6%) and over 20% on the Hand-Crafted dataset (surpassing the previously published best of 8.8%). These results demonstrate a key step towards introducing automated fault detection for autonomous systems over labor-intensive manual human review. </p>
<blockquote>
<p>我们在长期多组件LLM主体系统的开发和增强方面遇到了关键的难题：很难确定这些系统在何处崩溃以及原因是什么。目前存在的评估能力（例如，单通道LLM-作为评判）仅限于关注个体指标或能力、端到端的结果，并狭隘地基于人类的偏好。我们认为，为了匹配主体的能力，评估框架还必须能够推理、探索、迭代并理解长期内通过这些系统的复杂逻辑。在本文中，我们介绍了RAFFLES——一个结合了推理和迭代优化的评估架构。具体来说，RAFFLES作为一个迭代的多组件管道进行操作，使用一个中央评判来系统地调查故障和一系列专门的评估器来评估不仅系统的组件，还评估评判本身的推理质量，从而建立假设历史。我们在Who&amp;When数据集上对RAFFLES进行了几次基准测试，该基准测试旨在诊断系统的“谁”（主体）和“何时”（步骤）故障。RAFFLES优于这些基准测试，在算法生成的数据集上，主体步骤故障对准确率超过43%（较之前发布的最佳成绩16.6%有大幅度提高），在手工制作的数据集上准确率超过2.对于目前的自然语言处理和人工智能模型领域而言这是一个重大进步，它朝着引入自主系统的自动化故障检测方向迈出了关键一步，减少了劳动密集型的传统人工审查。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.06822v1">PDF</a> </p>
<p><strong>摘要</strong></p>
<p>该文针对长周期、多组件LLM智能系统的发展和提升，提出了一个关键难题：如何识别这些系统的故障及其原因。现有的评估方法（如单一通过LLM作为评判）存在局限性，难以全面评估系统性能。为此，作者提出了RAFFLES评估架构，融合了推理和迭代优化。RAFFLES采用迭代、多组件管道形式，通过中央评判系统调查故障，并使用一系列专业评估器不仅评估系统组件，还评估评判本身的推理质量，从而建立假设库。在Who&amp;When数据集上的实验表明，RAFFLES在算法生成数据集上的agent-step故障对准确率超过43%，大幅超越之前的最佳成绩（仅16.6%），并在手工数据集上超过20%（超越之前的最佳成绩仅8.8%）。这证明了自动化故障检测在自主系统发展中的关键作用。总的来说，RAFFLES为智能系统的故障检测提供了新的方向。</p>
<p><strong>关键见解</strong></p>
<ol>
<li>LLM智能系统在识别和诊断故障方面面临挑战。</li>
<li>当前评估方法存在局限性，无法全面评估长周期、多组件LLM智能系统的性能。</li>
<li>提出了RAFFLES评估架构，结合了推理和迭代优化来诊断LLM智能系统的故障。</li>
<li>RAFFLES通过中央评判系统和专业评估器来系统地调查故障并评估系统性能。</li>
<li>在Who&amp;When数据集上的实验结果表明，RAFFLES显著提高了故障检测的准确性。</li>
<li>RAFFLES为自主系统的自动化故障检测提供了新的可能性。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.06822">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-42ef2dd5eeb17738895d5f92be6f0e0e.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-403a3838f404241646429a42db133bab.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-a267450137a1beaf498039298d09da08.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="A-Comparative-Benchmark-of-Large-Language-Models-for-Labelling-Wind-Turbine-Maintenance-Logs"><a href="#A-Comparative-Benchmark-of-Large-Language-Models-for-Labelling-Wind-Turbine-Maintenance-Logs" class="headerlink" title="A Comparative Benchmark of Large Language Models for Labelling Wind   Turbine Maintenance Logs"></a>A Comparative Benchmark of Large Language Models for Labelling Wind   Turbine Maintenance Logs</h2><p><strong>Authors:Max Malyi, Jonathan Shek, Alasdair McDonald, Andre Biscaya</strong></p>
<p>Effective Operation and Maintenance (O&amp;M) is critical to reducing the Levelised Cost of Energy (LCOE) from wind power, yet the unstructured, free-text nature of turbine maintenance logs presents a significant barrier to automated analysis. Our paper addresses this by presenting a novel and reproducible framework for benchmarking Large Language Models (LLMs) on the task of classifying these complex industrial records. To promote transparency and encourage further research, this framework has been made publicly available as an open-source tool. We systematically evaluate a diverse suite of state-of-the-art proprietary and open-source LLMs, providing a foundational assessment of their trade-offs in reliability, operational efficiency, and model calibration. Our results quantify a clear performance hierarchy, identifying top models that exhibit high alignment with a benchmark standard and trustworthy, well-calibrated confidence scores. We also demonstrate that classification performance is highly dependent on the task’s semantic ambiguity, with all models showing higher consensus on objective component identification than on interpretive maintenance actions. Given that no model achieves perfect accuracy and that calibration varies dramatically, we conclude that the most effective and responsible near-term application is a Human-in-the-Loop system, where LLMs act as a powerful assistant to accelerate and standardise data labelling for human experts, thereby enhancing O&amp;M data quality and downstream reliability analysis. </p>
<blockquote>
<p>有效的操作和维护（O＆M）对于降低风力发电的平准化能源成本（LCOE）至关重要。然而，涡轮机维护日志的非结构化、自由文本性质给自动化分析造成了重大障碍。我们的论文通过提出一个新型的可重复使用的框架来解决这个问题，该框架用于在分类这些复杂的工业记录的任务上评估大型语言模型（LLM）。为了促进透明度和鼓励进一步研究，该框架已作为开源工具公开发布。我们系统地评估了一系列最先进的专有和开源LLM，对它们在可靠性、操作效率和模型校准方面的优缺点进行了基础评估。我们的结果量化了一个清晰的性能层次结构，确定了与高基准标准相符程度最高的模型，以及可信赖、校准良好的置信度得分。我们还证明，分类性能高度依赖于任务语义模糊性，所有模型在客观组件识别上的共识高于解释性维护行动。鉴于没有模型能达到完美精度，且校准差异很大，我们得出结论，最有效和负责任的近期应用是“人在循环中”的系统，LLM作为强大的助手，可以加快并标准化人类专家的数据标注，从而提高O＆M数据质量和下游可靠性分析。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.06813v1">PDF</a> Associated GitHub repository:   <a target="_blank" rel="noopener" href="https://github.com/mvmalyi/wind-farm-maintenance-logs-labelling-with-llms">https://github.com/mvmalyi/wind-farm-maintenance-logs-labelling-with-llms</a></p>
<p><strong>Summary</strong></p>
<p>本文介绍了运用大型语言模型（LLM）对风力发电设备维护日志进行分类的新框架。该框架为公开源代码工具，旨在促进透明度并鼓励进一步研究。文章评估了多种最新LLM的可靠性、操作效率和模型校准方面的优劣，明确了各模型之间的性能层次。研究结果表明，分类性能高度依赖于任务的语义模糊性，且所有模型在客观组件识别上的共识高于对解释性维护行动的分类。因此，文章认为目前最有效的应用是“人在循环中”的系统，LLM可作为人类专家的得力助手，加速并标准化数据标注，从而提高操作与维护（O&amp;M）数据质量和后续可靠性分析。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>大型语言模型（LLM）在风力发电设备维护日志分类中的应用至关重要，有助于降低运行维护成本并提高能源生产效率。</li>
<li>提出的分类框架是一个公开源代码工具，有助于推动自动化分析的透明度及进一步研究。</li>
<li>不同LLM在可靠性、操作效率和模型校准方面的评估结果各异，存在明确的性能层次。</li>
<li>LLM的分类性能受任务语义模糊性影响显著。</li>
<li>所有模型在客观组件识别上达成共识，但在解释性维护行动上的分类表现有所不足。</li>
<li>没有模型能达到完美准确率，模型校准也存在显著差异。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.06813">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-702bb558d54c36126a765905c1e4a35d.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-c323e17b3e3180b789d10a03add129f4.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="Saturation-Driven-Dataset-Generation-for-LLM-Mathematical-Reasoning-in-the-TPTP-Ecosystem"><a href="#Saturation-Driven-Dataset-Generation-for-LLM-Mathematical-Reasoning-in-the-TPTP-Ecosystem" class="headerlink" title="Saturation-Driven Dataset Generation for LLM Mathematical Reasoning in   the TPTP Ecosystem"></a>Saturation-Driven Dataset Generation for LLM Mathematical Reasoning in   the TPTP Ecosystem</h2><p><strong>Authors:Valentin Quesnel, Damien Sileo</strong></p>
<p>The scarcity of high-quality, logically sound data is a critical bottleneck for advancing the mathematical reasoning of Large Language Models (LLMs). Our work confronts this challenge by turning decades of automated theorem proving research into a scalable data engine. Rather than relying on error-prone LLMs or complex proof-assistant syntax like Lean and Isabelle, our framework leverages E-prover’s saturation capabilities on the vast TPTP axiom library to derive a massive, guaranteed-valid corpus of theorems. Our pipeline is principled and simple: saturate axioms, filter for “interesting” theorems, and generate tasks. With no LLMs in the loop, we eliminate factual errors by construction. This purely symbolic data is then transformed into three difficulty-controlled challenges: entailment verification, premise selection, and proof reconstruction. Our zero-shot experiments on frontier models reveal a clear weakness: performance collapses on tasks requiring deep, structural reasoning. Our framework provides both the diagnostic tool to measure this gap and a scalable source of symbolic training data to address it. We make the code and data publicly available.   <a target="_blank" rel="noopener" href="https://github.com/sileod/reasoning_core">https://github.com/sileod/reasoning_core</a> <a target="_blank" rel="noopener" href="https://hf.co/datasets/reasoning-core/rc1">https://hf.co/datasets/reasoning-core/rc1</a> </p>
<blockquote>
<p>高质量、逻辑严谨的数据的稀缺性是推进大型语言模型（LLM）数学推理的一个关键瓶颈。我们的工作通过把几十年的自动化定理证明研究转化为可扩展的数据引擎来应对这一挑战。我们的框架并没有依赖容易出错的LLM或复杂的证明助手语法（如Lean和Isabelle），而是利用E-prover在TPTP公理库上的饱和能力，推导出大量保证有效的定理语料库。我们的管道有原则且简单：饱和公理，过滤出“有趣”的定理，并生成任务。我们没有使用LLM循环，因此通过构建消除了事实错误。这种纯粹的符号数据随后被转化为三种难度可控的挑战：蕴含验证、前提选择、证明重建。我们在前沿模型上的零样本实验表明了一个明确的弱点：在面对需要深入、结构性推理的任务时，性能会崩溃。我们的框架既提供了衡量这一差距的诊断工具，又提供了解决这一问题的可扩展的符号训练数据来源。我们公开了代码和数据。 <a target="_blank" rel="noopener" href="https://github.com/sileod/reasoning_core">https://github.com/sileod/reasoning_core</a> <a target="_blank" rel="noopener" href="https://hf.co/datasets/reasoning-core/rc1">https://hf.co/datasets/reasoning-core/rc1</a></p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.06809v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>本文提出一个利用定理证明器E-prover和TPTP公理库构建大规模、保证有效的定理语料库的框架，解决了高质量逻辑数据稀缺的问题，为推进大型语言模型（LLM）的数学推理能力提供了突破。框架采用简单原则的方法，通过对公理进行饱和处理，过滤出有趣的定理并生成任务。这种方法无需依赖可能出错的LLM或复杂的证明辅助语法工具如Lean和Isabelle，避免了由事实错误造成的错误风险。生成的纯符号数据可转化为难度级别不同的三大挑战任务：蕴含验证、前提选择和证明重建。零样本实验显示前沿模型在需要深度结构推理的任务上表现明显不足，本文框架不仅提供了衡量这一差距的诊断工具，还提供了解决这一问题的可扩展符号训练数据来源。相关代码和数据已公开。更多详情参见相关网站链接：<a target="_blank" rel="noopener" href="https://github.com/sileod/reasoning_core">https://github.com/sileod/reasoning_core</a> 和 <a target="_blank" rel="noopener" href="https://hf.co/datasets/reasoning-core/rc1">https://hf.co/datasets/reasoning-core/rc1</a>。</p>
<p><strong>Key Takeaways</strong></p>
<p>以下是基于文本的重要观点摘要：</p>
<ul>
<li>面临高质量逻辑数据稀缺的问题，对推进大型语言模型（LLM）的数学推理能力构成瓶颈。</li>
<li>提出利用定理证明器E-prover和TPTP公理库构建大规模有效定理语料库的框架。</li>
<li>采用简单原则的方法，通过饱和公理处理过滤出有趣的定理并生成任务。该方法不涉及可能出错的LLM或复杂的证明辅助语法工具，降低了风险。</li>
<li>将生成的纯符号数据转化为三大挑战任务：蕴含验证、前提选择和证明重建，以适应不同难度级别。</li>
<li>零样本实验揭示前沿模型在深度结构推理任务上的明显不足。</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.06809">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-62e29e6da5b9b1499dafbf477f3dd980.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-b7ec3470a410d95a6c6abfeba8b4cc93.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-1a384b07bfdcfff40790a303a1bbf387.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-4d1eeb0f0bc50c018a456e5ed79a9bf5.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-7f7edae7b2aa82267b7432c3cb7cfd22.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="MachineLearningLM-Continued-Pretraining-Language-Models-on-Millions-of-Synthetic-Tabular-Prediction-Tasks-Scales-In-Context-ML"><a href="#MachineLearningLM-Continued-Pretraining-Language-Models-on-Millions-of-Synthetic-Tabular-Prediction-Tasks-Scales-In-Context-ML" class="headerlink" title="MachineLearningLM: Continued Pretraining Language Models on Millions of   Synthetic Tabular Prediction Tasks Scales In-Context ML"></a>MachineLearningLM: Continued Pretraining Language Models on Millions of   Synthetic Tabular Prediction Tasks Scales In-Context ML</h2><p><strong>Authors:Haoyu Dong, Pengkun Zhang, Mingzhe Lu, Yanzhen Shen, Guolin Ke</strong></p>
<p>Large language models (LLMs) possess broad world knowledge and strong general-purpose reasoning ability, yet they struggle to learn from many in-context examples on standard machine learning (ML) tasks, that is, to leverage many-shot demonstrations purely via in-context learning (ICL) without gradient descent. We introduce MachineLearningLM, a portable continued-pretraining framework that equips a general-purpose LLM with robust in-context ML capability while preserving its general knowledge and reasoning for broader chat workflows.   Our pretraining procedure synthesizes ML tasks from millions of structural causal models (SCMs), spanning shot counts up to 1,024. We begin with a random-forest teacher, distilling tree-based decision strategies into the LLM to strengthen robustness in numerical modeling. All tasks are serialized with a token-efficient prompt, enabling 3x to 6x more examples per context window and delivering up to 50x amortized throughput via batch inference.   Despite a modest setup (Qwen-2.5-7B-Instruct with LoRA rank 8), MachineLearningLM outperforms strong LLM baselines (e.g., GPT-5-mini) by an average of about 15% on out-of-distribution tabular classification across finance, physics, biology, and healthcare domains. It exhibits a striking many-shot scaling law: accuracy increases monotonically as in-context demonstrations grow from 8 to 1,024. Without any task-specific training, it attains random-forest-level accuracy across hundreds of shots. General chat capabilities, including knowledge and reasoning, are preserved: it achieves 75.4% on MMLU. </p>
<blockquote>
<p>大型语言模型（LLM）拥有广泛的世界知识和强大的通用推理能力，但在标准机器学习（ML）任务上，它们很难从多个上下文示例中学习，也就是说，它们无法仅凭上下文学习（ICL）来利用多个示例，而无需进行梯度下降。我们引入了MachineLearningLM，这是一个便携式持续预训练框架，它使通用LLM具备强大的上下文ML功能，同时保留其一般知识和推理能力，以支持更广泛的聊天工作流程。我们的预训练程序从数百万个结构因果模型（SCM）中综合ML任务，涵盖示例数量高达1024个。我们以随机森林教师开始，将基于树的决策策略蒸馏到LLM中，以加强数值建模中的稳健性。所有任务都通过高效的标记提示符进行序列化，使每个上下文窗口能够增加3倍至6倍的示例数量，并通过批量推理实现高达50倍的摊销吞吐量。尽管使用了适度的设置（使用LoRA等级8的Qwen-2.5-7B-Instruct），但MachineLearningLM在金融、物理、生物和医疗保健领域的离分布表格分类任务上，平均比强大的LLM基线（例如GPT-5-mini）高出约15%的准确率。它表现出引人注目的多示例扩展定律：随着上下文示例从8个增加到1024个，准确性单调增加。无需任何特定任务的训练，它就能在各种场景下达到随机森林级别的准确性。同时保留了一般聊天功能，包括知识和推理能力：它在MMLU上达到了75.4%的准确率。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.06806v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>大型语言模型（LLM）拥有广泛的知识和强大的通用推理能力，但在标准机器学习（ML）任务上难以从多个上下文示例中学习。为此，我们推出了MachineLearningLM，这是一个便携的持续预训练框架，旨在赋予通用LLM强大的上下文ML能力，同时保留其一般知识和推理能力，以应对更广泛的聊天工作流程。我们的预训练程序通过合成来自数百万结构因果模型（SCM）的ML任务来强化LLM的数值建模能力，并增强了其在不同领域中的表现。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>LLMs虽具有广泛知识和推理能力，但在标准ML任务上难以从多个上下文示例中学习。</li>
<li>MachineLearningLM框架旨在增强LLM的上下文ML能力，同时保留其一般知识和推理能力。</li>
<li>预训练程序通过合成来自数百万结构因果模型（SCM）的ML任务来强化LLM的数值建模能力。</li>
<li>使用随机森林教师来提炼树形决策策略，增强LLM在数值建模中的稳健性。</li>
<li>通过序列化任务并使用高效的提示，使LLM能够在每个上下文窗口中处理更多的示例，并通过批量推理实现更高的吞吐量。</li>
<li>MachineLearningLM在多个领域（如金融、物理、生物和医疗保健）的分类任务上，相对于GPT-5-mini等强大LLM基准测试，平均提高了约15%的准确率。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.06806">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-c0d3e774d1daf77e78b5dc416047994d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-3408f1539e266d9d6f4ee243a0002b2b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-013fc1315736669373007096ac3902f8.jpg" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="Another-Turn-Better-Output-A-Turn-Wise-Analysis-of-Iterative-LLM-Prompting"><a href="#Another-Turn-Better-Output-A-Turn-Wise-Analysis-of-Iterative-LLM-Prompting" class="headerlink" title="Another Turn, Better Output? A Turn-Wise Analysis of Iterative LLM   Prompting"></a>Another Turn, Better Output? A Turn-Wise Analysis of Iterative LLM   Prompting</h2><p><strong>Authors:Shashidhar Reddy Javaji, Bhavul Gauri, Zining Zhu</strong></p>
<p>Large language models (LLMs) are now used in multi-turn workflows, but we still lack a clear way to measure when iteration helps and when it hurts. We present an evaluation framework for iterative refinement that spans ideation, code, and math. Our protocol runs controlled 12-turn conversations per task, utilizing a variety of prompts ranging from vague &#96;&#96;improve it’’ feedback to targeted steering, and logs per-turn outputs. We score outcomes with domain-appropriate checks (unit tests for code; answer-equivalence plus reasoning-soundness for math; originality and feasibility for ideation) and track turn-level behavior with three families of metrics: semantic movement across turns, turn-to-turn change, and output size growth. Across models and tasks, gains are domain-dependent: they arrive early in ideas and code, but in math late turns matter when guided by elaboration. After the first few turns, vague feedback often plateaus or reverses correctness, while targeted prompts reliably shift the intended quality axis (novelty vs. feasibility in ideation; speed vs. readability in code; in math, elaboration outperforms exploration and drives late-turn gains). We also observe consistent domain patterns: ideation moves more in meaning across turns, code tends to grow in size with little semantic change, and math starts fixed but can break that path with late, elaborative iteration.Together, the framework and metrics make iteration measurable and comparable across models, and signal when to steer, stop, or switch strategies. </p>
<blockquote>
<p>大型语言模型（LLM）现在已应用于多轮工作流程中，但我们仍缺乏明确的衡量方法来判断迭代在何时有帮助，何时会产生负面影响。我们提出一个评估迭代优化的框架，该框架涵盖构思、编码和数学。我们的协议针对每个任务运行受控的12轮对话，使用各种提示，从模糊的“改进它”反馈到有针对性的指导，并记录每轮的输岀。我们使用适合领域的检查来评分结果（代码中的单元测试；数学中的答案等价性加上推理合理性；构思中的原创性和可行性），并通过三个家族的指标来跟踪轮次级别的行为：各轮之间的语义变化、轮次之间的变化以及输出大小的增长。在不同的模型和任务中，收益是领域依赖的：它们在想法和代码中早早地到达，但在数学中，后期轮次在指导下的细化很重要。经过前几轮后，模糊的反馈通常会达到平台期或使正确性逆转，而有针对性的提示会可靠地改变预期的质量轴（构思中的新颖性对比可行性；编码中的速度对比可读性；在数学中，细化表现优于探索并推动后期的收益）。我们还观察到一致领域模式：在构思中，各轮之间的意义变化更大；代码往往大小增长而语义变化很小；数学开始时是固定的，但可以通过后期的细化迭代来打破这一路径。总之，框架和指标使迭代可以在模型之间进行比较和衡量，并指示何时需要调整方向、停止或改变策略。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.06770v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>大型语言模型（LLM）在多轮对话工作流中得到了广泛应用，但缺乏对迭代是否有效的明确衡量方式。本文提出一个评估迭代优化效果的框架，涵盖创意、代码和数学领域。通过控制每任务12轮对话的实验流程，使用各种提示来引导，并记录每轮的输出来评估效果。结果显示，在不同领域和任务中，迭代的增益具有依赖性：在创意和代码方面，早期迭代效果明显；在数学方面，则需要更多的迭代。此外，还观察到各领域的一致性模式：创意方面的迭代更多体现在意义的变化上，代码倾向于大小增长而语义变化较小，数学则开始稳定但后来通过深入迭代获得提升。总之，该框架和指标使迭代效果可衡量和比较，并能指导何时需要调整策略。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>大型语言模型（LLM）在多轮对话工作流中广泛应用，但迭代优化的衡量方式尚不清楚。</li>
<li>提出的评估框架可用于衡量迭代优化在创意、代码和数学领域的效果。</li>
<li>控制每任务12轮对话的实验流程，使用不同提示来引导对话。</li>
<li>迭代增益具有领域依赖性：在创意和代码方面，早期迭代效果显着；数学方面则需要更多深入迭代。</li>
<li>创意方面的迭代更多体现在意义的变化上，代码大小增长而语义变化较小，数学领域开始稳定但后来通过深入迭代获得提升。</li>
<li>框架和指标使迭代效果可衡量和比较，有助于判断何时需要调整策略。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.06770">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-62a6160d1017ed0cdb87a5ad260a481e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e8b338c2aaaed69f661fa67192e0d4a1.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-8ffdb59e62953676c322e137f9b79963.jpg" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1><h2 id="SFR-DeepResearch-Towards-Effective-Reinforcement-Learning-for-Autonomously-Reasoning-Single-Agents"><a href="#SFR-DeepResearch-Towards-Effective-Reinforcement-Learning-for-Autonomously-Reasoning-Single-Agents" class="headerlink" title="SFR-DeepResearch: Towards Effective Reinforcement Learning for   Autonomously Reasoning Single Agents"></a>SFR-DeepResearch: Towards Effective Reinforcement Learning for   Autonomously Reasoning Single Agents</h2><p><strong>Authors:Xuan-Phi Nguyen, Shrey Pandit, Revanth Gangi Reddy, Austin Xu, Silvio Savarese, Caiming Xiong, Shafiq Joty</strong></p>
<p>Equipping large language models (LLMs) with complex, interleaved reasoning and tool-use capabilities has become a key focus in agentic AI research, especially with recent advances in reasoning-oriented (&#96;&#96;thinking’’) models. Such capabilities are key to unlocking a number of important applications. One such application is Deep Research (DR), which requires extensive search and reasoning over many sources. Our work in this paper focuses on the development of native Autonomous Single-Agent models for DR featuring minimal web crawling and Python tool integration. Unlike multi-agent systems, where agents take up pre-defined roles and are told what to do at each step in a static workflow, an autonomous single-agent determines its next action dynamically based on context, without manual directive. While prior work has proposed training recipes for base or instruction-tuned LLMs, we focus on continual reinforcement learning (RL) of reasoning-optimized models to further enhance agentic skills while preserving reasoning ability. Towards this end, we propose a simple RL recipe with entirely synthetic data, which we apply to various open-source LLMs. Our best variant SFR-DR-20B achieves up to 28.7% on Humanity’s Last Exam benchmark. In addition, we conduct key analysis experiments to provide more insights into our methodologies. </p>
<blockquote>
<p>为大型语言模型（LLM）配备复杂、交织的推理和工具使用能力已成为代理人工智能研究的关键焦点，尤其是最近基于推理导向（“思考”）模型的进步。这些能力是解锁许多重要应用的关键。其中一个应用是深度研究（DR），它需要在多个来源之间进行广泛搜索和推理。本文的工作重点是为DR开发本地自主单代理模型，具有最少的网络爬虫和Python工具集成。不同于多代理系统，其中代理承担预定义角色，并在静态工作流中的每一步被告知要做什么，自主单代理会根据上下文动态地确定其下一步行动，无需手动指令。虽然先前的工作已经提出了针对基础或指令微调LLM的训练配方，但我们专注于对推理优化模型的持续强化学习（RL），以进一步增强代理技能，同时保留推理能力。为此，我们提出了一个使用完全合成数据的简单RL配方，可应用于各种开源LLM。我们最好的变体SFR-DR-20B在人类最后的考试基准测试中达到了28.7%。此外，我们还进行了关键的分析实验，以更深入地了解我们的方法。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.06283v1">PDF</a> Technical Report</p>
<p><strong>Summary</strong></p>
<p>本文关注大型语言模型（LLM）在深度研究（DR）中的应用，强调自主单一代理模型的发展，该模型具备动态决策能力，无需手动指导。研究团队通过持续强化学习（RL）提升模型的推理能力，并推出适用于开源LLM的简易RL配方。其中，SFR-DR-20B模型在Humanity’s Last Exam基准测试中表现优秀。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>大型语言模型（LLM）正在被赋予更复杂的推理和工具使用能力，成为智能体AI研究的关键焦点。</li>
<li>自主单一代理模型在深度研究（DR）中表现突出，具备动态决策能力，无需预设角色和静态工作流程。</li>
<li>持续的强化学习（RL）用于提升LLM的推理能力，同时保持其原有的推理技能。</li>
<li>研究团队推出了一个简易的RL配方，适用于各种开源LLM。</li>
<li>SFR-DR-20B模型在Humanity’s Last Exam基准测试中表现卓越，达到了28.7%的效果。</li>
<li>研究团队还进行了关键的分析实验，以深入了解其方法的有效性。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.06283">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-3286312ad1f0e5fe82d0c2b56d68d124.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-762a81b044fa30a731e76b1e1c36c50e.jpg" align="middle">
</details>


<h1 id="-9"><a href="#-9" class="headerlink" title=""></a></h1><h2 id="Code2MCP-A-Multi-Agent-Framework-for-Automated-Transformation-of-Code-Repositories-into-Model-Context-Protocol-Services"><a href="#Code2MCP-A-Multi-Agent-Framework-for-Automated-Transformation-of-Code-Repositories-into-Model-Context-Protocol-Services" class="headerlink" title="Code2MCP: A Multi-Agent Framework for Automated Transformation of Code   Repositories into Model Context Protocol Services"></a>Code2MCP: A Multi-Agent Framework for Automated Transformation of Code   Repositories into Model Context Protocol Services</h2><p><strong>Authors:Chaoqian Ouyang, Ling Yue, Shimin Di, Libin Zheng, Shaowu Pan, Min-Ling Zhang</strong></p>
<p>The proliferation of Large Language Models (LLMs) has created a significant integration challenge in the AI agent ecosystem, often called the “$N \times M$ problem,” where N models require custom integrations for M tools. This fragmentation stifles innovation and creates substantial development overhead. While the Model Context Protocol (MCP) has emerged as a standard to resolve this, its adoption is hindered by the manual effort required to convert the vast universe of existing software into MCP-compliant services. This is especially true for the millions of open-source repositories on GitHub, the world’s largest collection of functional code. This paper introduces Code2MCP, a highly automated, agentic framework designed to transform any GitHub repository into a functional MCP service with minimal human intervention. Our system employs a multi-stage workflow that automates the entire process, from code analysis and environment configuration to service generation and deployment. A key innovation of our framework is an LLM-driven, closed-loop “Run–Review–Fix” cycle, which enables the system to autonomously debug and repair the code it generates. Code2MCP produces not only deployable services but also comprehensive technical documentation, acting as a catalyst to accelerate the MCP ecosystem by systematically unlocking the world’s largest open-source code repository and automating the critical last mile of tool integration. The code is open-sourced at <a target="_blank" rel="noopener" href="https://github.com/DEFENSE-SEU/MCP-Github-Agent">https://github.com/DEFENSE-SEU/MCP-Github-Agent</a>. </p>
<blockquote>
<p>大型语言模型（LLM）的普及给人工智能代理生态系统带来了重大的集成挑战，通常被称为”$N × M$问题”，其中N个模型需要为M个工具进行自定义集成。这种碎片化阻碍了创新，并产生了大量开发额外负担。虽然模型上下文协议（MCP）已作为解决此问题的标准而出现，但其采用受到了将现有大量软件转换为符合MCP的服务所需的人工努力的阻碍。这在GitHub上的数百万个开源存储库中尤其如此，GitHub是世界上功能代码的最大集合。本文介绍了Code2MCP，这是一个高度自动化的代理框架，旨在将任何GitHub仓库转换为功能性的MCP服务，并尽量减少人工干预。我们的系统采用多阶段工作流程，自动化了整个过程，从代码分析、环境配置到服务生成和部署。我们框架的一个关键创新是由大型语言模型驱动的闭环“运行-审查-修复”循环，使系统能够自主调试和修复其生成的代码。Code2MCP不仅生成可部署的服务，还生成全面的技术文档，通过系统地解锁世界上最大的开源代码库并自动执行工具集成的关键最后一英里，从而加速MCP生态系统的发展。代码已公开在<a target="_blank" rel="noopener" href="https://github.com/DEFENSE-SEU/MCP-Github-Agent%E3%80%82">https://github.com/DEFENSE-SEU/MCP-Github-Agent。</a></p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.05941v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>大规模语言模型（LLM）的普及给人工智能代理生态系统带来了显著的集成挑战，这通常被称为“$N \times M$ 问题”，即N个模型需要为M个工具进行自定义集成。这一问题造成了碎片化的局面，阻碍了创新并增加了开发成本。虽然模型上下文协议（MCP）已出现为解决此问题，但由于需要将大量现有软件转换为符合MCP的服务所需的手动工作，其采用受到了阻碍。特别是对于GitHub上的数百万开源仓库来说，更是如此。本文介绍了Code2MCP，这是一个高度自动化的代理框架，旨在以最小的手动干预将任何GitHub仓库转换为功能性的MCP服务。我们的系统采用多阶段工作流程，自动完成从代码分析、环境配置到服务生成和部署的整个流程。我们的框架的一个关键创新是由大型语言模型驱动的闭环“运行-审查-修复”循环，使系统能够自主调试和修复其生成的代码。Code2MCP不仅生成可部署的服务，还提供全面的技术文档，通过系统地解锁世界上最大的开源代码仓库并自动化工具集成的关键最后一英里，从而加快MCP生态系统的发展。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>LLMs在AI代理生态系统中引发重大集成挑战，表现为“$N \times M$ 问题”。</li>
<li>Model Context Protocol (MCP)旨在解决此问题，但手动转换现有软件成为一大挑战。</li>
<li>Code2MCP框架旨在自动化GitHub仓库到功能性的MCP服务的转化过程。</li>
<li>Code2MCP包含多阶段工作流程，从代码分析到服务部署都实现自动化。</li>
<li>LLM驱动的闭环“运行-审查-修复”循环是Code2MCP的关键创新点。</li>
<li>Code2MCP不仅生成可部署的服务，还提供全面的技术文档。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.05941">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-57803352518a20e2c50e6c300a5503f9.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-2040146710d010fee393882c590a0db8.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-4194a6ce1299f78a3f38d164c04f3dda.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b01a0f472f33e66a5bac0aeb648b445a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f252cbe26f4ff8f15349dcde5e0cc843.jpg" align="middle">
</details>


<h1 id="-10"><a href="#-10" class="headerlink" title=""></a></h1><h2 id="LM-Searcher-Cross-domain-Neural-Architecture-Search-with-LLMs-via-Unified-Numerical-Encoding"><a href="#LM-Searcher-Cross-domain-Neural-Architecture-Search-with-LLMs-via-Unified-Numerical-Encoding" class="headerlink" title="LM-Searcher: Cross-domain Neural Architecture Search with LLMs via   Unified Numerical Encoding"></a>LM-Searcher: Cross-domain Neural Architecture Search with LLMs via   Unified Numerical Encoding</h2><p><strong>Authors:Yuxuan Hu, Jihao Liu, Ke Wang, Jinliang Zhen, Weikang Shi, Manyuan Zhang, Qi Dou, Rui Liu, Aojun Zhou, Hongsheng Li</strong></p>
<p>Recent progress in Large Language Models (LLMs) has opened new avenues for solving complex optimization problems, including Neural Architecture Search (NAS). However, existing LLM-driven NAS approaches rely heavily on prompt engineering and domain-specific tuning, limiting their practicality and scalability across diverse tasks. In this work, we propose LM-Searcher, a novel framework that leverages LLMs for cross-domain neural architecture optimization without the need for extensive domain-specific adaptation. Central to our approach is NCode, a universal numerical string representation for neural architectures, which enables cross-domain architecture encoding and search. We also reformulate the NAS problem as a ranking task, training LLMs to select high-performing architectures from candidate pools using instruction-tuning samples derived from a novel pruning-based subspace sampling strategy. Our curated dataset, encompassing a wide range of architecture-performance pairs, encourages robust and transferable learning. Comprehensive experiments demonstrate that LM-Searcher achieves competitive performance in both in-domain (e.g., CNNs for image classification) and out-of-domain (e.g., LoRA configurations for segmentation and generation) tasks, establishing a new paradigm for flexible and generalizable LLM-based architecture search. The datasets and models will be released at <a target="_blank" rel="noopener" href="https://github.com/Ashone3/LM-Searcher">https://github.com/Ashone3/LM-Searcher</a>. </p>
<blockquote>
<p>大型语言模型（LLM）的最新进展为解决复杂的优化问题开辟了新的途径，包括神经网络架构搜索（NAS）。然而，现有的基于LLM的NAS方法严重依赖于提示工程和特定领域的调整，这限制了它们在跨不同任务时的实用性和可扩展性。在这项工作中，我们提出了LM-Searcher，这是一个新型框架，它利用LLM进行跨域神经网络架构优化，而无需进行广泛的特定领域适应。我们的方法的核心是NCode，这是一种用于神经网络架构的通用数值字符串表示，它实现了跨域架构编码和搜索。我们还重新将NAS问题表述为排序任务，训练LLM从候选池中选择高性能架构，使用基于新型基于剪枝的子空间采样策略生成的指令调整样本。我们整理的数据集涵盖了广泛的架构性能对，鼓励稳健和可迁移的学习。综合实验表明，LM-Searcher在域内（例如，用于图像分类的CNN）和域外（例如，用于分割和生成的LoRA配置）的任务中都取得了具有竞争力的性能，为灵活和通用的基于LLM的架构搜索建立了新范式。数据集和模型将在<a target="_blank" rel="noopener" href="https://github.com/Ashone3/LM-Searcher%E5%8F%91%E5%B8%83%E3%80%82">https://github.com/Ashone3/LM-Searcher发布。</a></p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.05657v1">PDF</a> EMNLP2025</p>
<p><strong>Summary</strong></p>
<p>大型语言模型（LLM）的最新进展为求解复杂优化问题提供了新的途径，包括神经网络架构搜索（NAS）。然而，现有的LLM驱动的NAS方法过于依赖提示工程和特定领域的调整，这在实践中限制了其在不同任务中的实用性和可扩展性。本文提出一种新的框架LM-Searcher，该框架利用LLM进行跨域神经网络架构优化，无需广泛的特定领域适应。其核心是NCode，一种用于神经网络架构的通用数值字符串表示，可实现跨域架构编码和搜索。此外，本文将NAS问题重新表述为排名任务，训练LLM从候选池中为高性能架构打分，采用基于修剪的子空间采样策略生成指令调整样本。实验表明，LM-Searcher在内部领域（如图像分类的CNN）和外部领域（如分割和生成的LoRA配置）的任务中均取得了具有竞争力的表现，为灵活和通用的LLM基础架构搜索建立了新的范例。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>LLM的最新进展为求解复杂优化问题提供了新的途径。</li>
<li>现有LLM驱动的NAS方法存在对提示工程和特定领域调整的依赖，限制了其实用性和可扩展性。</li>
<li>LM-Searcher框架利用LLM进行跨域神经网络架构优化，无需广泛的特定领域适应。</li>
<li>NCode是一种用于神经网络架构的通用数值字符串表示，支持跨域架构编码和搜索。</li>
<li>NAS问题被重新表述为排名任务，LLM从候选池中为高性能架构打分。</li>
<li>采用基于修剪的子空间采样策略生成指令调整样本，用于训练LLM。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.05657">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pica.zhimg.com/v2-0dc511e5e1f20c4d5d70404f811de075.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-eabf1aea7b1da4bec1b86d711e42d064.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-8cc26ce48438df86b43d5c6a4cceea72.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e7713f74c7f52e814602cf90ace66351.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-53ce69ff6656bb0640075e354d458af7.jpg" align="middle">
</details>


<h1 id="-11"><a href="#-11" class="headerlink" title=""></a></h1><h2 id="Comparative-Analysis-of-Transformer-Models-in-Disaster-Tweet-Classification-for-Public-Safety"><a href="#Comparative-Analysis-of-Transformer-Models-in-Disaster-Tweet-Classification-for-Public-Safety" class="headerlink" title="Comparative Analysis of Transformer Models in Disaster Tweet   Classification for Public Safety"></a>Comparative Analysis of Transformer Models in Disaster Tweet   Classification for Public Safety</h2><p><strong>Authors:Sharif Noor Zisad, N. M. Istiak Chowdhury, Ragib Hasan</strong></p>
<p>Twitter and other social media platforms have become vital sources of real time information during disasters and public safety emergencies. Automatically classifying disaster related tweets can help emergency services respond faster and more effectively. Traditional Machine Learning (ML) models such as Logistic Regression, Naive Bayes, and Support Vector Machines have been widely used for this task, but they often fail to understand the context or deeper meaning of words, especially when the language is informal, metaphorical, or ambiguous. We posit that, in this context, transformer based models can perform better than traditional ML models. In this paper, we evaluate the effectiveness of transformer based models, including BERT, DistilBERT, RoBERTa, and DeBERTa, for classifying disaster related tweets. These models are compared with traditional ML approaches to highlight the performance gap. Experimental results show that BERT achieved the highest accuracy (91%), significantly outperforming traditional models like Logistic Regression and Naive Bayes (both at 82%). The use of contextual embeddings and attention mechanisms allows transformer models to better understand subtle language in tweets, where traditional ML models fall short. This research demonstrates that transformer architectures are far more suitable for public safety applications, offering improved accuracy, deeper language understanding, and better generalization across real world social media text. </p>
<blockquote>
<p>推特和其他社交媒体平台在灾难和公共安全紧急事件期间已成为实时信息的重要来源。自动分类与灾难相关的推特可以帮助紧急服务更快、更有效地作出反应。传统机器学习（ML）模型，如逻辑回归、朴素贝叶斯和支持向量机，已广泛应用于此项任务，但它们常常无法理解语境或单词的深层含义，尤其是在语言非正式、隐晦或含糊不清的情况下。我们认为，在这种情况下，基于变压器模型的表现可以优于传统机器学习模型。在本文中，我们评估了基于变压器模型的有效性，包括BERT、DistilBERT、RoBERTa和DeBERTa，用于分类与灾难相关的推特。这些模型与传统机器学习方法进行比较，以突出表现差距。实验结果表明，BERT的准确率最高（91%），显著优于逻辑回归和朴素贝叶斯等传统模型（均为82%）。上下文嵌入和注意力机制的使用使得变压器模型能够更好地理解推特中的微妙语言，这是传统机器学习模型所无法做到的。这项研究表明，变压器架构非常适合公共安全应用，具有更高的准确性、更深的语言理解能力和在现实社交媒本文本中更好的泛化能力。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.04650v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>本文探讨了社交媒体平台在灾难和公共安全紧急事件中的实时信息重要性。针对灾难相关的推特分类，评估了基于变压器的模型（如BERT、DistilBERT、RoBERTa和DeBERTa）的效果，并与传统机器学习模型进行了比较。实验结果显示，BERT达到了最高的准确性（91%），显著优于逻辑回归和朴素贝叶斯等传统模型（均为82%）。基于变压器的模型能更好地理解推文中的细微语言，而传统模型则在这方面表现不足。本研究表明，对于公共安全应用，基于变压器的架构更适合，具有更高的准确性、更深的语言理解能力和更好的泛化能力。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>社交媒体平台已成为灾难和公共安全紧急事件的重要实时信息来源。</li>
<li>传统机器学习模型在分类灾难相关推特时存在语境理解不足的问题。</li>
<li>基于变压器的模型（如BERT）在分类灾难相关推特方面表现出色，其中BERT达到91%的准确性。</li>
<li>与传统模型相比，基于变压器的模型能更好地理解推文中的细微语言和语境。</li>
<li>基于变压器的模型具有更深的语言理解能力和更好的泛化能力。</li>
<li>本研究证明了基于变压器的架构在公共安全应用中的适用性。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.04650">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-711435f1ab19dcd29e3f5ed0c8e5e948.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-11d59b0e34060fd853bb80b7b8ac8693.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-bfb42aeda1262d35a02164ee411cbcd5.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-6e1b273842af41c3d818221ae933c85a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b22a0720498bbe965a202eccc747f05f.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-aa869209f2853937bfbeaea14fe3d07c.jpg" align="middle">
</details>


<h1 id="-12"><a href="#-12" class="headerlink" title=""></a></h1><h2 id="Oyster-I-Beyond-Refusal-–-Constructive-Safety-Alignment-for-Responsible-Language-Models"><a href="#Oyster-I-Beyond-Refusal-–-Constructive-Safety-Alignment-for-Responsible-Language-Models" class="headerlink" title="Oyster-I: Beyond Refusal – Constructive Safety Alignment for   Responsible Language Models"></a>Oyster-I: Beyond Refusal – Constructive Safety Alignment for   Responsible Language Models</h2><p><strong>Authors:Ranjie Duan, Jiexi Liu, Xiaojun Jia, Shiji Zhao, Ruoxi Cheng, Fengxiang Wang, Cheng Wei, Yong Xie, Chang Liu, Defeng Li, Yinpeng Dong, Yichi Zhang, Yuefeng Chen, Chongwen Wang, Xingjun Ma, Xingxing Wei, Yang Liu, Hang Su, Jun Zhu, Xinfeng Li, Yitong Sun, Jie Zhang, Jinzhao Hu, Sha Xu, Yitong Yang, Jialing Tao, Hui Xue</strong></p>
<p>Large language models (LLMs) typically deploy safety mechanisms to prevent harmful content generation. Most current approaches focus narrowly on risks posed by malicious actors, often framing risks as adversarial events and relying on defensive refusals. However, in real-world settings, risks also come from non-malicious users seeking help while under psychological distress (e.g., self-harm intentions). In such cases, the model’s response can strongly influence the user’s next actions. Simple refusals may lead them to repeat, escalate, or move to unsafe platforms, creating worse outcomes. We introduce Constructive Safety Alignment (CSA), a human-centric paradigm that protects against malicious misuse while actively guiding vulnerable users toward safe and helpful results. Implemented in Oyster-I (Oy1), CSA combines game-theoretic anticipation of user reactions, fine-grained risk boundary discovery, and interpretable reasoning control, turning safety into a trust-building process. Oy1 achieves state-of-the-art safety among open models while retaining high general capabilities. On our Constructive Benchmark, it shows strong constructive engagement, close to GPT-5, and unmatched robustness on the Strata-Sword jailbreak dataset, nearing GPT-o1 levels. By shifting from refusal-first to guidance-first safety, CSA redefines the model-user relationship, aiming for systems that are not just safe, but meaningfully helpful. We release Oy1, code, and the benchmark to support responsible, user-centered AI. </p>
<blockquote>
<p>大型语言模型（LLM）通常会部署安全机制以防止生成有害内容。当前大多数方法主要关注恶意行为者带来的风险，通常将这些风险视为对抗性事件并依赖防御性拒绝。然而，在真实世界环境中，风险还来自于非恶意用户在心理压力下寻求帮助（例如，自我伤害意图）。在这种情况下，模型的反应会强烈影响用户的下一步行动。简单的拒绝可能会使他们重复、升级或转向不安全的平台，造成更糟的结果。我们引入了建设性安全对齐（CSA）这一以人类为中心的模式，它既能防止恶意滥用，又能积极指导脆弱用户获得安全和有益的结果。在牡蛎-I（Oy1）中实现的CSA结合了博弈理论对用户反应的预期、精细的风险边界发现和可解释推理控制，将安全转变为建立信任的过程。Oy1在开放模型中实现了最先进的安技术全性，同时保持了高泛化能力。在我们的建设性基准测试中，它显示出强大的建设性参与度，接近GPT-5，在Strata-Sword越狱数据集上表现出无与伦比的稳健性，接近GPT-o1水平。通过将拒绝优先的安全转变为指导优先的安全，CSA重新定义了模型与用户之间的关系，旨在构建不仅是安全而且真正有意义的系统。我们发布了Oy1、代码和基准测试，以支持用户为中心、负责任的人工智能。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.01909v3">PDF</a> Technical Report Code &amp; Model weights available:   <a target="_blank" rel="noopener" href="https://github.com/Alibaba-AAIG/Oyster">https://github.com/Alibaba-AAIG/Oyster</a></p>
<p><strong>Summary</strong>：<br>大型语言模型（LLM）通常采用安全机制防止生成有害内容。现有方法主要关注恶意行为者带来的风险，将风险视为对抗性事件并依赖防御性拒绝。然而，在现实世界中，风险还来自于有心理困扰的用户的求助需求。针对这种情况，模型响应会影响用户下一步行动。本文提出建设性安全对齐（CSA）方法，既防止恶意误用，又积极引导脆弱用户获得安全和有帮助的结果。该方法将安全转变为建立信任的过程，实现了Oyster-I（Oy1）模型的高安全性和高通用性。</p>
<p><strong>Key Takeaways</strong>：</p>
<ol>
<li>大型语言模型（LLM）部署安全机制防止生成有害内容。</li>
<li>现有方法主要关注恶意行为者的风险，但忽略了来自心理困扰用户的真实风险。</li>
<li>建设性安全对齐（CSA）是一种新的保护方法，既防止恶意误用，又积极指导脆弱用户获得安全和有帮助的结果。</li>
<li>CSA将安全转变为建立信任的过程，提高了模型与用户之间的互动性。</li>
<li>Oy1模型实现了高安全性和高通用性，展现了强大的建设性交互能力，同时在Strata-Sword越狱数据集上展现了强大的稳健性。</li>
<li>CSA重新定义模型与用户之间的关系，旨在建立不仅安全而且有意义的帮助系统。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.01909">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-af071cfabbf26ab5029dc03b0eb04d34.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-1e75ab0cc30f21c22e90cb1fc0f56298.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-7e07ff1e230994a339e4659cf7ce1fe1.jpg" align="middle">
</details>


<h1 id="-13"><a href="#-13" class="headerlink" title=""></a></h1><h2 id="Not-All-Features-Deserve-Attention-Graph-Guided-Dependency-Learning-for-Tabular-Data-Generation-with-Language-Models"><a href="#Not-All-Features-Deserve-Attention-Graph-Guided-Dependency-Learning-for-Tabular-Data-Generation-with-Language-Models" class="headerlink" title="Not All Features Deserve Attention: Graph-Guided Dependency Learning for   Tabular Data Generation with Language Models"></a>Not All Features Deserve Attention: Graph-Guided Dependency Learning for   Tabular Data Generation with Language Models</h2><p><strong>Authors:Zheyu Zhang, Shuo Yang, Bardh Prenkaj, Gjergji Kasneci</strong></p>
<p>Large Language Models (LLMs) have shown strong potential for tabular data generation by modeling textualized feature-value pairs. However, tabular data inherently exhibits sparse feature-level dependencies, where many feature interactions are structurally insignificant. This creates a fundamental mismatch as LLMs’ self-attention mechanism inevitably distributes focus across all pairs, diluting attention on critical relationships, particularly in datasets with complex dependencies or semantically ambiguous features. To address this limitation, we propose GraDe (Graph-Guided Dependency Learning), a novel method that explicitly integrates sparse dependency graphs into LLMs’ attention mechanism. GraDe employs a lightweight dynamic graph learning module guided by externally extracted functional dependencies, prioritizing key feature interactions while suppressing irrelevant ones. Our experiments across diverse real-world datasets demonstrate that GraDe outperforms existing LLM-based approaches by up to 12% on complex datasets while achieving competitive results with state-of-the-art approaches in synthetic data quality. Our method is minimally intrusive yet effective, offering a practical solution for structure-aware tabular data modeling with LLMs. </p>
<blockquote>
<p>大型语言模型（LLM）通过建模文本化的特征值对，在表格数据生成方面显示出强大的潜力。然而，表格数据本质上表现出稀疏的特征级依赖关系，其中许多特征交互在结构上并不显著。这造成了一个根本性的不匹配，因为LLM的自注意力机制不可避免地会分散到所有对上，稀释了对关键关系的注意力，特别是在具有复杂依赖关系或语义模糊特征的数据集中。为了解决这一局限性，我们提出了GraDe（Graph引导依赖学习），这是一种将稀疏依赖图显式集成到LLM注意力机制中的新方法。GraDe采用轻量级的动态图学习模块，该模块由外部提取的功能依赖关系引导，优先关注关键特征交互，同时抑制无关交互。我们在多个真实世界数据集上的实验表明，在处理复杂数据集时，GraDe相较于现有的LLM方法表现优异，提高了高达12%，同时在合成数据质量方面达到前沿水平。我们的方法几乎不需要额外工作，但却效果显著，为使用LLM进行结构感知的表格数据建模提供了实用解决方案。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2507.18504v2">PDF</a> Accepted to EMNLP 2025 (Findings)</p>
<p><strong>Summary</strong></p>
<p>LLMs在通过建模文本化的特征值对进行表格数据生成方面表现出强大的潜力。然而，表格数据内在存在稀疏的特征级别依赖关系，导致许多特征交互在结构上并不重要。这造成了一个根本性的不匹配，因为LLMs的自注意力机制不可避免地会分散到所有对上，稀释了对关键关系上的注意力，特别是在具有复杂依赖或语义模糊特征的数据库中。为解决此局限性，提出了一种名为GraDe（图引导依赖学习）的新方法，该方法将稀疏依赖图显式地集成到LLMs的注意力机制中。GraDe使用外部提取的功能依赖引导的轻量级动态图学习模块，优先关注关键特征交互，同时抑制无关交互。在多种真实数据集上的实验表明，GraDe在复杂数据集上的表现优于现有的LLM方法，合成数据质量方面达到了与最新方法相当的水平。我们的方法具有最小的侵入性且有效，为使用LLM进行结构感知的表格数据建模提供了实用的解决方案。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>LLMs在表格数据生成方面展现出强大的潜力，通过建模文本化的特征值对进行表现。</li>
<li>表格数据存在稀疏的特征级别依赖关系，导致LLMs自注意力机制的不匹配问题。</li>
<li>GraDe方法通过集成稀疏依赖图到LLMs的注意力机制中来解决这一问题。</li>
<li>GraDe使用外部提取的功能依赖来优先关注关键特征交互并抑制无关交互。</li>
<li>GraDe在复杂数据集上的表现优于现有LLM方法，合成数据质量方面达到了与最新方法相当的水平。</li>
<li>GraDe方法具有最小的侵入性且有效。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2507.18504">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-05db724bb924eb638a8c9ecbc9317b42.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d1ba43a21e6b9be009837ba0debf9cf5.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-d0468bb0e4b58862792702435ae24998.jpg" align="middle">
</details>


<h1 id="-14"><a href="#-14" class="headerlink" title=""></a></h1><h2 id="ChatCFD-An-LLM-Driven-Agent-for-End-to-End-CFD-Automation-with-Domain-Specific-Structured-Reasoning"><a href="#ChatCFD-An-LLM-Driven-Agent-for-End-to-End-CFD-Automation-with-Domain-Specific-Structured-Reasoning" class="headerlink" title="ChatCFD: An LLM-Driven Agent for End-to-End CFD Automation with   Domain-Specific Structured Reasoning"></a>ChatCFD: An LLM-Driven Agent for End-to-End CFD Automation with   Domain-Specific Structured Reasoning</h2><p><strong>Authors:E Fan, Kang Hu, Zhuowen Wu, Jiangyang Ge, Jiawei Miao, Yuzhi Zhang, He Sun, Weizong Wang, Tianhan Zhang</strong></p>
<p>Computational Fluid Dynamics (CFD) is essential for advancing scientific and engineering fields but is hindered by operational complexity, high expertise requirements, and limited accessibility. This paper introduces ChatCFD, an automated agent system for OpenFOAM simulations that processes multi-modal inputs (e.g., research papers, meshes) via an interactive interface, leveraging DeepSeek-R1 and DeepSeek-V3 large language models, a multi-agent architecture, and OpenFOAM knowledge. Its four-stage pipeline (Knowledge Base Construction, User Input Processing, Case File Generation, and Execution and Error Reflection) enables iterative trial-reflection-refinement for intricate setups, supporting diverse physical models and external meshes. Validation on 205 benchmark tutorial cases, 110 perturbed variants, and 2 literature-derived cases shows ChatCFD’s 82.1 percent operational success rate on basic cases, outperforming MetaOpenFOAM (6.2 percent) and Foam-Agent (42.3 percent), and 60-80 percent on literature-derived complex cases. Turbulence model studies show a 40 percent success rate for common models versus 10 percent for rare ones like RNG k-epsilon. Physics coupling analyses reveal higher resource demands for multi-physics-coupled cases, while LLM bias toward simpler setups introduces persistent errors, such as dimensional inconsistency. Ablation studies highlight the efficacy of RAG-based modules and reflection mechanisms. By automating hypothesis testing and parameter exploration, ChatCFD accelerates scientific discovery in fluid mechanics and engineering, addressing LLM limitations through structured design and showing strong potential as a modular component in MCP-based agent networks for collaborative multi-agent systems, paving the way for scalable AI-driven CFD innovation. The code for ChatCFD is available at <a target="_blank" rel="noopener" href="https://github.com/ConMoo/ChatCFD">https://github.com/ConMoo/ChatCFD</a>. </p>
<blockquote>
<p>计算流体动力学（CFD）对于推动科学和工程领域的发展至关重要，但受到操作复杂、专业要求高和可访问性有限的阻碍。本文介绍了ChatCFD，这是一个用于OpenFOAM模拟的自动化代理系统，它通过交互式接口处理多模式输入（例如研究论文、网格），利用DeepSeek-R1和DeepSeek-V3大型语言模型、多代理架构和OpenFOAM知识。其四阶段管道（知识库构建、用户输入处理、案例文件生成、执行和错误反思）为复杂的设置提供了迭代试验-反思-改进的支持，支持多种物理模型和外部网格。对205个基准教程案例、110个扰动变体和2个文献衍生的案例进行验证，表明ChatCFD在基本案例中的操作成功率为82.1%，超过了MetaOpenFOAM（6.2%）和Foam-Agent（42.3%），在文献衍生的复杂案例中的成功率为60-80%。湍流模型研究表明，对于常见模型的成功率为40%，而对于稀有的如RNG k-epsilon等模型仅为10%。物理耦合分析表明，多物理耦合案例的资源需求更高，而大型语言模型对更简单设置的偏好会导致持久性错误，例如尺寸不一致。消融研究突出了基于RAG的模块和反射机制的有效性。通过自动化假设检验和参数探索，ChatCFD加速了流体力学和工程中的科学发现，通过结构化设计解决了大型语言模型的局限性，并显示出作为模块化组件在基于MCP的代理网络中用于协作多代理系统的强大潜力，为可伸缩的AI驱动CFD创新铺平了道路。ChatCFD的代码可在<a target="_blank" rel="noopener" href="https://github.com/ConMoo/ChatCFD">https://github.com/ConMoo/ChatCFD</a>获取。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.02019v2">PDF</a> 19 pages, 8 figures</p>
<p><strong>摘要</strong><br>    本论文介绍了一种基于OpenFOAM的自动代理系统ChatCFD，该系统通过交互式接口处理多模态输入，利用DeepSeek-R1和DeepSeek-V3大型语言模型以及多代理架构实现CFD模拟的自动化。ChatCFD的四阶段管道包括知识库构建、用户输入处理、案例文件生成和执行及错误反馈，支持多种物理模型和外部网格，并在复杂设置上实现了迭代试验-反思-改进。在多个基准测试案例和文献衍生案例上的验证表明，ChatCFD在基本案例上的操作成功率为82.1%，超过了MetaOpenFOAM（6.2%）和Foam-Agent（42.3%），并在文献衍生的复杂案例上达到60-80%的成功率。研究还涉及了湍流模型和物理耦合分析，揭示了多物理耦合案例的资源需求较高，以及大型语言模型在简单设置上的偏差导致的持久性错误。通过自动化假设检验和参数探索，ChatCFD加速了流体力学和工程领域的科学发现，并通过结构化设计解决了大型语言模型的局限性，显示出作为模块化组件在基于模型的协作多代理系统中的强大潜力，为可扩展的AI驱动的CFD创新铺平了道路。</p>
<p><strong>关键见解</strong></p>
<ol>
<li>ChatCFD是一个基于OpenFOAM的自动化代理系统，用于处理多模态输入，包括研究论文和网格，为流体动力学模拟提供了一种新的方法。</li>
<li>ChatCFD的四阶段管道包括知识库构建、用户输入处理、案例文件生成和执行及错误反馈，支持多种物理模型和外部网格，并能进行迭代试验-反思-改进。</li>
<li>ChatCFD在基准测试案例上的操作成功率较高，达到了82.1%，并且相对于其他系统（如MetaOpenFOAM和Foam-Agent）表现更好。</li>
<li>在文献衍生的复杂案例上，ChatCFD也表现出了较强的潜力，成功率为60-80%。</li>
<li>研究还发现多物理耦合的流体动力学模拟有较高的资源需求。</li>
<li>大型语言模型在某些情况下可能存在偏差，导致一些持久性错误，如尺寸不一致等问题。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.02019">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-3af26f181e7a4ad53856f66ea548e05e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ea76bfd92920ba11392f33c694ba0e65.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-b1b562b04a9a8dc18b7bbf5a2f47c436.jpg" align="middle">
</details>


<h1 id="-15"><a href="#-15" class="headerlink" title=""></a></h1><h2 id="Efficient-Dynamic-Clustering-Based-Document-Compression-for-Retrieval-Augmented-Generation"><a href="#Efficient-Dynamic-Clustering-Based-Document-Compression-for-Retrieval-Augmented-Generation" class="headerlink" title="Efficient Dynamic Clustering-Based Document Compression for   Retrieval-Augmented-Generation"></a>Efficient Dynamic Clustering-Based Document Compression for   Retrieval-Augmented-Generation</h2><p><strong>Authors:Weitao Li, Kaiming Liu, Xiangyu Zhang, Xuanyu Lei, Weizhi Ma, Yang Liu</strong></p>
<p>Retrieval-Augmented Generation (RAG) has emerged as a widely adopted approach for knowledge injection during large language model (LLM) inference in recent years. However, due to their limited ability to exploit fine-grained inter-document relationships, current RAG implementations face challenges in effectively addressing the retrieved noise and redundancy content, which may cause error in the generation results. To address these limitations, we propose an Efficient Dynamic Clustering-based document Compression framework (EDC2-RAG) that utilizes latent inter-document relationships while simultaneously removing irrelevant information and redundant content. We validate our approach, built upon GPT-3.5-Turbo and GPT-4o-mini, on widely used knowledge-QA and Hallucination-Detection datasets. Experimental results show that our method achieves consistent performance improvements across various scenarios and experimental settings, demonstrating strong robustness and applicability. Our code and datasets are available at <a target="_blank" rel="noopener" href="https://github.com/Tsinghua-dhy/EDC-2-RAG">https://github.com/Tsinghua-dhy/EDC-2-RAG</a>. </p>
<blockquote>
<p>近年来，检索增强生成（RAG）作为一种广泛采用的知识注入方法，在大语言模型（LLM）推理中受到关注。然而，由于当前RAG实施对于精细粒度跨文档关系的利用能力有限，它们在有效处理检索到的噪声和冗余内容方面面临挑战，这可能导致生成结果出现错误。为了解决这些局限性，我们提出了一种基于高效动态聚类的文档压缩框架（EDC2-RAG），它利用潜在的跨文档关系，同时去除无关信息和冗余内容。我们在广泛使用的知识问答和幻觉检测数据集上验证了我们方法的有效性。实验结果表明，我们的方法在各种场景和实验设置下实现了性能改进的一致性，表现出强大的稳健性和适用性。我们的代码和数据集可在<a target="_blank" rel="noopener" href="https://github.com/Tsinghua-dhy/EDC-2-RAG%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/Tsinghua-dhy/EDC-2-RAG找到。</a></p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.03165v3">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>当前大型语言模型（LLM）推理中广泛采用检索增强生成（RAG）方法实现知识注入。然而，现有RAG方法在应对检索噪声和冗余内容时面临挑战，限制了它们在处理精细粒度文档关系方面的能力，可能导致生成结果出现错误。为此，我们提出一种高效动态聚类基础的文档压缩框架（EDC²-RAG），利用潜在文档关系的同时移除无关信息和冗余内容。我们在广泛使用的知识问答和幻视检测数据集上验证了我们基于GPT-3.5 Turbo和GPT-4o mini的方法，实验结果表明，该方法在各种场景和实验设置下性能有所提升，展现出强大的稳健性和适用性。我们的代码和数据集可在<a target="_blank" rel="noopener" href="https://github.com/Tsinghua-dhy/EDC-2-RAG%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/Tsinghua-dhy/EDC-2-RAG找到。</a></p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>检索增强生成（RAG）是LLM知识注入的流行方法，但存在处理检索噪声和冗余内容的挑战。</li>
<li>现有RAG方法难以有效利用精细粒度文档关系，可能导致生成错误。</li>
<li>我们提出了高效动态聚类基础的文档压缩框架（EDC²-RAG），旨在解决这些问题。</li>
<li>EDC²-RAG利用潜在文档关系，同时移除无关信息和冗余内容。</li>
<li>方法在知识问答和幻视检测数据集上进行了验证，实验结果表明性能有所提升。</li>
<li>方法基于GPT-3.5 Turbo和GPT-4o mini构建，表现出强大的稳健性和适用性。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.03165">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-b4209b4b047abc66d0ac29431507770d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-4c4995774dbd305c85da0a77243c5c19.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-4549a74d16d6b8742bda2492c21b383b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b9e83f92597a9c1d94a00353a69cd479.jpg" align="middle">
</details>


<h1 id="-16"><a href="#-16" class="headerlink" title=""></a></h1><h2 id="Dita-Scaling-Diffusion-Transformer-for-Generalist-Vision-Language-Action-Policy"><a href="#Dita-Scaling-Diffusion-Transformer-for-Generalist-Vision-Language-Action-Policy" class="headerlink" title="Dita: Scaling Diffusion Transformer for Generalist   Vision-Language-Action Policy"></a>Dita: Scaling Diffusion Transformer for Generalist   Vision-Language-Action Policy</h2><p><strong>Authors:Zhi Hou, Tianyi Zhang, Yuwen Xiong, Haonan Duan, Hengjun Pu, Ronglei Tong, Chengyang Zhao, Xizhou Zhu, Yu Qiao, Jifeng Dai, Yuntao Chen</strong></p>
<p>While recent vision-language-action models trained on diverse robot datasets exhibit promising generalization capabilities with limited in-domain data, their reliance on compact action heads to predict discretized or continuous actions constrains adaptability to heterogeneous action spaces. We present Dita, a scalable framework that leverages Transformer architectures to directly denoise continuous action sequences through a unified multimodal diffusion process. Departing from prior methods that condition denoising on fused embeddings via shallow networks, Dita employs in-context conditioning – enabling fine-grained alignment between denoised actions and raw visual tokens from historical observations. This design explicitly models action deltas and environmental nuances. By scaling the diffusion action denoiser alongside the Transformer’s scalability, Dita effectively integrates cross-embodiment datasets across diverse camera perspectives, observation scenes, tasks, and action spaces. Such synergy enhances robustness against various variances and facilitates the successful execution of long-horizon tasks. Evaluations across extensive benchmarks demonstrate state-of-the-art or comparative performance in simulation. Notably, Dita achieves robust real-world adaptation to environmental variances and complex long-horizon tasks through 10-shot finetuning, using only third-person camera inputs. The architecture establishes a versatile, lightweight and open-source baseline for generalist robot policy learning. Project Page: <a target="_blank" rel="noopener" href="https://robodita.github.io/">https://robodita.github.io</a>. </p>
<blockquote>
<p>最近针对多样化机器人数据集训练的视觉-语言-动作模型，在有限领域内展现出令人鼓舞的泛化能力。然而，这些模型依赖于紧凑的动作头来预测离散或连续动作，这限制了其在异构动作空间中的适应性。我们提出了Dita，一个可扩展的框架，它利用Transformer架构通过统一的多模态扩散过程直接对连续动作序列进行去噪。与以往依赖于浅层网络融合嵌入进行去噪的方法不同，Dita采用上下文条件——实现在去噪动作与来自历史观察的原生视觉标记之间的精细对齐。这种设计显式地建模动作差异和环境细微差别。通过扩散动作去噪器与Transformer的可扩展性相结合，Dita有效地整合了跨不同相机角度、观察场景、任务和动作空间的跨体态数据集。这种协同作用增强了对各种变量的稳健性，并促进了长期任务的成功执行。在广泛基准测试上的评估证明了其在仿真环境中的最新或相当性能。值得注意的是，Dita仅通过第三人称相机输入实现了对环境和复杂长期任务的稳健适应，只需进行10次微调即可。该架构为通用机器人策略学习建立了通用、轻便和开源的基线。项目页面：<a target="_blank" rel="noopener" href="https://robodita.github.io./">https://robodita.github.io。</a></p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.19757v2">PDF</a> Preprint; <a target="_blank" rel="noopener" href="https://robodita.github.io/">https://robodita.github.io</a>; To appear in ICCV2025</p>
<p><strong>Summary</strong></p>
<p>近期基于多样化机器人数据集训练的视觉-语言-动作模型在有限领域内数据上展现出良好的泛化能力，但它们预测离散或连续动作时依赖于紧凑的动作头，这限制了它们在异构动作空间中的适应性。为此，我们提出了Dita框架，它利用Transformer架构通过统一的多模态扩散过程直接对连续动作序列进行去噪。不同于先前依赖于融合嵌入并通过浅层网络进行条件去噪的方法，Dita采用上下文条件，实现了去噪动作与来自历史观察的原生视觉标记之间的精细对齐。这种设计显式地模拟动作差异和环境细微差别。通过扩散动作去噪器与Transformer的可扩展性相结合，Dita能够有效地整合跨不同相机角度、观察场景、任务和动作空间的跨体态数据集。这种协同增强了对各种变化的稳健性，并促进了长期任务的成功执行。在广泛的基准测试上进行的评估表明，Dita在模拟环境中达到了最新或相当的性能水平。值得注意的是，Dita仅通过第三人称相机输入，就能在真实世界环境中实现对环境变化和复杂长期任务的稳健适应，并通过10次微调射击达到稳健性。该架构为通用机器人政策学习建立了灵活、轻便和开源的基线。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>近期视觉-语言-动作模型在多样化机器人数据集上展现出良好的泛化能力。</li>
<li>现有模型在预测连续动作方面存在依赖紧凑动作头的限制，影响在异构动作空间中的适应性。</li>
<li>Dita框架利用Transformer架构直接对连续动作序列进行去噪，提高模型适应性。</li>
<li>Dita采用上下文条件方法，实现去噪动作与原生视觉标记的精细对齐。</li>
<li>扩散动作去噪器与Transformer的结合增强了模型的稳健性，并促进了长期任务的执行。</li>
<li>Dita在模拟环境中达到最新或相当的性能水平，并在真实世界环境中实现对环境变化和复杂长期任务的适应。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.19757">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-2858411e5c8ade32917a8cddf74f956f.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-7084a4872835e2d3bb86b9c07f95c029.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-e0040aaf9dc111b2bdb2dc8ecdf1ceaa.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-c6c4179b02220164b602e40441f0658f.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-c5d1af79bedd9a6bfa81091f95cb7981.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-a93699852682634a909cb4615760d9a8.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ab8c62b49b5686f87cb75573a01c6ac6.jpg" align="middle">
</details>


<h1 id="-17"><a href="#-17" class="headerlink" title=""></a></h1><h2 id="Error-Classification-of-Large-Language-Models-on-Math-Word-Problems-A-Dynamically-Adaptive-Framework"><a href="#Error-Classification-of-Large-Language-Models-on-Math-Word-Problems-A-Dynamically-Adaptive-Framework" class="headerlink" title="Error Classification of Large Language Models on Math Word Problems: A   Dynamically Adaptive Framework"></a>Error Classification of Large Language Models on Math Word Problems: A   Dynamically Adaptive Framework</h2><p><strong>Authors:Yuhong Sun, Zhangyue Yin, Xuanjing Huang, Xipeng Qiu, Hui Zhao</strong></p>
<p>Large Language Models (LLMs) have demonstrated remarkable capabilities across various domains. Math Word Problems (MWPs) serve as a crucial benchmark for evaluating LLMs’ reasoning abilities. While most research primarily focuses on improving accuracy, it often neglects understanding and addressing the underlying patterns of errors. Current error classification methods rely on static and predefined categories, which limit their ability to capture the full spectrum of error patterns in mathematical reasoning. To enable systematic error analysis, we collect error samples from 15 different LLMs of varying sizes across four distinct MWP datasets using multiple sampling strategies. Based on this extensive collection, we introduce MWPES-300K, a comprehensive dataset containing 304,865 error samples that cover diverse error patterns and reasoning paths. To reduce human bias and enable fine-grained analysis of error patterns, we propose a novel framework for automated dynamic error classification in mathematical reasoning. Experimental results demonstrate that dataset characteristics significantly shape error patterns, which evolve from basic to complex manifestations as model capabilities increase. With deeper insights into error patterns, we propose Error-Aware Prompting (EAP) that incorporates common error patterns as explicit guidance, leading to significant improvements in mathematical reasoning performance. </p>
<blockquote>
<p>大型语言模型（LLM）已在各个领域展现出显著的能力。数学应用题（MWP）是评估LLM推理能力的重要基准。虽然大多数研究主要集中在提高准确性上，但它往往忽视了理解和解决错误模式的底层原因。当前的错误分类方法依赖于静态和预定义的类别，这限制了它们捕捉数学推理中错误模式全貌的能力。为了进行系统的错误分析，我们从不同大小的15个LLM中，使用多种采样策略，收集了跨四个不同MWP数据集的错误样本。基于广泛的收集，我们推出了MWPES-300K，这是一个包含304865个错误样本的综合数据集，涵盖了多种错误模式和推理路径。为了减少人为偏见并实现对错误模式的精细分析，我们提出了用于数学推理的自动化动态错误分类的新框架。实验结果表明，数据集特性显著影响错误模式，随着模型能力的提高，错误模式从基本到复杂的表现形式都会发生变化。通过对错误模式有更深入的了解，我们提出了结合常见错误模式作为明确指导的“错误感知提示”（EAP），这极大地提高了数学推理性能。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.15581v2">PDF</a> 28 pages, 10 figures, accepted by Findings of EMNLP2025</p>
<p><strong>Summary</strong></p>
<p>大型语言模型（LLMs）在多领域展现出卓越的能力，数学文字题（MWPs）是评估LLMs推理能力的重要基准。现有研究多关注提高准确率，却忽视了理解和解决底层错误模式。我们收集了来自不同规模和不同数学文字题数据集的错误样本，建立了包含多种错误模式和推理路径的综合数据集MWPES-300K。为了减少人为偏见并精细分析错误模式，我们提出了自动动态数学推理错误分类的新框架。实验结果表明，数据集特性显著影响错误模式，随着模型能力的提高，错误模式从基础到复杂演变。基于对错误模式的深入了解，我们提出了结合常见错误模式作为明确指导的错误感知提示（EAP），显著提高了数学推理性能。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>LLMs在数学文字题（MWPs）上的表现是重要的评估基准。</li>
<li>现有研究主要关注提高LLMs的准确率，但忽视了错误模式的深入分析。</li>
<li>我们建立了一个综合数据集MWPES-300K，包含多种错误模式和推理路径。</li>
<li>为减少人为偏见并精细分析错误模式，我们提出了自动动态数学推理错误分类的新框架。</li>
<li>数据集特性对错误模式有显著影响，错误模式随着模型能力的提高而演变。</li>
<li>基于对错误模式的深入了解，我们提出了错误感知提示（EAP）方法，该方法结合常见错误模式作为明确指导，有效提高数学推理性能。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.15581">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-8a9ecdb0920b1ef290700c8f02e00903.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-7bd66de101a9ddf072c503bf326d3b76.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-69f325176268ed98f1b42f46fddd4901.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-99b3d61832c08ec86ebf111a00561e13.jpg" align="middle">
</details>


<h1 id="-18"><a href="#-18" class="headerlink" title=""></a></h1><h2 id="Bias-in-Decision-Making-for-AI’s-Ethical-Dilemmas-A-Comparative-Study-of-ChatGPT-and-Claude"><a href="#Bias-in-Decision-Making-for-AI’s-Ethical-Dilemmas-A-Comparative-Study-of-ChatGPT-and-Claude" class="headerlink" title="Bias in Decision-Making for AI’s Ethical Dilemmas: A Comparative Study   of ChatGPT and Claude"></a>Bias in Decision-Making for AI’s Ethical Dilemmas: A Comparative Study   of ChatGPT and Claude</h2><p><strong>Authors:Yile Yan, Yuqi Zhu, Wentao Xu</strong></p>
<p>Recent advances in Large Language Models (LLMs) have enabled human-like responses across various tasks, raising questions about their ethical decision-making capabilities and potential biases. This study systematically evaluates how nine popular LLMs (both open-source and closed-source) respond to ethical dilemmas involving protected attributes. Across 50,400 trials spanning single and intersectional attribute combinations in four dilemma scenarios (protective vs. harmful), we assess models’ ethical preferences, sensitivity, stability, and clustering patterns. Results reveal significant biases in protected attributes in all models, with differing preferences depending on model type and dilemma context. Notably, open-source LLMs show stronger preferences for marginalized groups and greater sensitivity in harmful scenarios, while closed-source models are more selective in protective situations and tend to favor mainstream groups. We also find that ethical behavior varies across dilemma types: LLMs maintain consistent patterns in protective scenarios but respond with more diverse and cognitively demanding decisions in harmful ones. Furthermore, models display more pronounced ethical tendencies under intersectional conditions than in single-attribute settings, suggesting that complex inputs reveal deeper biases. These findings highlight the need for multi-dimensional, context-aware evaluation of LLMs’ ethical behavior and offer a systematic evaluation and approach to understanding and addressing fairness in LLM decision-making. </p>
<blockquote>
<p>近期大型语言模型（LLM）的进步使得在各种任务中都能产生类似人类的反应，这引发了关于其伦理决策能力和潜在偏见的问题。本研究系统地评估了九种流行的大型语言模型（包括开源和闭源）如何应对涉及受保护属性的道德困境。在跨越单一属性和交叉属性组合的四种困境场景（保护性对有害性）的50400次试验中，我们评估了模型的道德偏好、敏感性、稳定性和聚类模式。结果表明，所有模型在受保护属性上都存在显著的偏见，且偏好因模型类型和困境背景而异。值得注意的是，开源LLM对边缘群体有更强的偏好，在有害场景中更为敏感，而闭源模型在保护情况下更为挑剔，更倾向于主流群体。我们还发现，道德行为因困境类型而异：LLM在保护场景中保持了一致的模式，但在有害场景中做出了更多样化、更具认知挑战的决定。此外，与单一属性设置相比，模型在交叉条件下的道德倾向更为明显，这表明复杂的输入揭示了更深的偏见。这些发现强调了多维、上下文感知的LLM伦理行为评估的必要性，为我们提供了一个系统的评估和解决大型语言模型决策中公平问题的方法。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.10484v3">PDF</a> This paper has been accepted by International AAAI Conference on Web   and Social Media 2026 (ICWSM 2026), sunny Los Angeles, California</p>
<p><strong>Summary</strong></p>
<p>大型语言模型（LLM）的最新进展使得它们能够在各种任务中做出类似人类的响应，引发关于其伦理决策能力和潜在偏见的问题。本研究系统地评估了九种流行的LLM（包括开源和闭源）在涉及保护属性的道德困境中的反应。研究进行了超过四万五千次试验，发现模型在处理四种不同困境中的单一属性和跨界属性组合时存在明显的偏见。尤其是开源LLM更倾向于保护边缘群体并对有害场景更为敏感，而闭源模型更倾向于保护主流群体并选择性地进行防护。此外，还发现LLM在不同类型的困境中表现出不同的道德行为模式，并在复杂情境下显示出更深刻的偏见。因此，需要多维度、基于情境地评估LLM的伦理行为。研究为人们提供了一个系统性的评价方法来了解和解决LLM决策中的公平性问题。</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>LLMs在处理涉及保护属性的道德困境时表现出明显的偏见。</li>
<li>开源LLM倾向于保护边缘群体，对有害场景更敏感；闭源模型则更倾向于保护主流群体。</li>
<li>LLM的伦理行为在不同类型的困境中存在差异，表现为在复杂情境下的决策更为多样和认知需求更高。</li>
<li>模型在处理跨界属性组合时显示出更深刻的偏见。</li>
<li>需要多维度、基于情境地评估LLM的伦理行为，以确保决策的公平性。</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.10484">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-2e3221368c23aa9dd5f9a4d2a4fd8d97.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e6d695dbd6af0c7258ed9a7f172cc4b0.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-ba479860b35149d4ebd3a2c0be13ccb9.jpg" align="middle">
</details>


<h1 id="-19"><a href="#-19" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        文章作者:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        文章链接:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-09-10/LLM/">https://kedreamix.github.io/Talk2Paper/Paper/2025-09-10/LLM/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        版权声明:
                    </i>
                </span>
                <span class="reprint-info">
                    本博客所有文章除特別声明外，均采用
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    许可协议。转载请注明来源
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/LLM/">
                                    <span class="chip bg-color">LLM</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;上一篇</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-09-10/Agent/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-71bb0a6592c54b405fa40a2e9e64055b.jpg" class="responsive-img" alt="Agent">
                        
                        <span class="card-title">Agent</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Agent 方向最新论文已更新，请持续关注 Update in 2025-09-10  AxelSMOTE An Agent-Based Oversampling Algorithm for Imbalanced   Classification
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-09-10
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Agent/" class="post-category">
                                    Agent
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Agent/">
                        <span class="chip bg-color">Agent</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-09-10/R1_Reasoning/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-c29b0f436b40b28911b22bf67cd90fc8.jpg" class="responsive-img" alt="R1_Reasoning">
                        
                        <span class="card-title">R1_Reasoning</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            R1_Reasoning 方向最新论文已更新，请持续关注 Update in 2025-09-10  On the Same Wavelength? Evaluating Pragmatic Reasoning in Language   Models across Broad Concepts
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-09-10
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/R1-Reasoning/" class="post-category">
                                    R1_Reasoning
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/R1-Reasoning/">
                        <span class="chip bg-color">R1_Reasoning</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- 代码语言 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span
                        class="white-color">27348.8k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- 运行天数提醒. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // 区分是否有年份.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = '本站已运行 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                daysTip = '本站已運行 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = '本站已运行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = '本站已運行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="关注我的知乎: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">知</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- 白天和黑夜主题 -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // 只在桌面版网页启用特效
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- 雪花特效 -->
    

    <!-- 鼠标星星特效 -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--腾讯兔小巢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- 动态标签 -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Σ(っ °Д °;)っ诶，页面崩溃了嘛？", clearTimeout(st)) : (document.title = "φ(゜▽゜*)♪咦，又好了！", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
