<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="LLM">
    <meta name="description" content="LLM æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-09-10  Beyond Two-Stage Training Cooperative SFT and RL for LLM Reasoning">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>LLM | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://picx.zhimg.com/v2-4d1eeb0f0bc50c018a456e5ed79a9bf5.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">LLM</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/LLM/">
                                <span class="chip bg-color">LLM</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/LLM/" class="post-category">
                                LLM
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-09-10
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-10-07
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    22.2k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    90 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-09-10-æ›´æ–°"><a href="#2025-09-10-æ›´æ–°" class="headerlink" title="2025-09-10 æ›´æ–°"></a>2025-09-10 æ›´æ–°</h1><h2 id="Beyond-Two-Stage-Training-Cooperative-SFT-and-RL-for-LLM-Reasoning"><a href="#Beyond-Two-Stage-Training-Cooperative-SFT-and-RL-for-LLM-Reasoning" class="headerlink" title="Beyond Two-Stage Training: Cooperative SFT and RL for LLM Reasoning"></a>Beyond Two-Stage Training: Cooperative SFT and RL for LLM Reasoning</h2><p><strong>Authors:Liang Chen, Xueting Han, Li Shen, Jing Bai, Kam-Fai Wong</strong></p>
<p>Reinforcement learning (RL) has proven effective in incentivizing the reasoning abilities of large language models (LLMs), but suffers from severe efficiency challenges due to its trial-and-error nature. While the common practice employs supervised fine-tuning (SFT) as a warm-up stage for RL, this decoupled two-stage approach limits interaction between SFT and RL, thereby constraining overall effectiveness. This study introduces a novel method for learning reasoning models that employs bilevel optimization to facilitate better cooperation between these training paradigms. By conditioning the SFT objective on the optimal RL policy, our approach enables SFT to meta-learn how to guide RLâ€™s optimization process. During training, the lower level performs RL updates while simultaneously receiving SFT supervision, and the upper level explicitly maximizes the cooperative gain-the performance advantage of joint SFT-RL training over RL alone. Empirical evaluations on five reasoning benchmarks demonstrate that our method consistently outperforms baselines and achieves a better balance between effectiveness and efficiency. </p>
<blockquote>
<p>å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰å·²ç»è¯æ˜å¯ä»¥æ¿€åŠ±å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„æ¨ç†èƒ½åŠ›ï¼Œä½†ç”±äºå…¶è¯•é”™æ€§è´¨è€Œé¢ä¸´ä¸¥é‡çš„æ•ˆç‡æŒ‘æˆ˜ã€‚è™½ç„¶é€šå¸¸çš„åšæ³•æ˜¯é‡‡ç”¨ç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰ä½œä¸ºRLçš„é¢„çƒ­é˜¶æ®µï¼Œä½†è¿™ç§è§£è€¦çš„ä¸¤é˜¶æ®µæ–¹æ³•é™åˆ¶äº†SFTå’ŒRLä¹‹é—´çš„äº¤äº’ï¼Œä»è€Œé™åˆ¶äº†æ•´ä½“æ•ˆæœã€‚æœ¬ç ”ç©¶å¼•å…¥äº†ä¸€ç§å­¦ä¹ æ¨ç†æ¨¡å‹çš„æ–°æ–¹æ³•ï¼Œè¯¥æ–¹æ³•é‡‡ç”¨ä¸¤çº§ä¼˜åŒ–ï¼Œä»¥ä¿ƒè¿›è¿™äº›è®­ç»ƒæ¨¡å¼ä¹‹é—´çš„æ›´å¥½åä½œã€‚é€šè¿‡æ ¹æ®æœ€ä½³RLç­–ç•¥åˆ¶å®šSFTç›®æ ‡ï¼Œæˆ‘ä»¬çš„æ–¹æ³•ä½¿SFTèƒ½å¤Ÿå…ƒå­¦ä¹ å¦‚ä½•å¼•å¯¼RLçš„ä¼˜åŒ–è¿‡ç¨‹ã€‚åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œè¾ƒä½å±‚æ¬¡è¿›è¡ŒRLæ›´æ–°ï¼ŒåŒæ—¶æ¥å—SFTç›‘ç£ï¼Œè€Œè¾ƒé«˜å±‚æ¬¡åˆ™æ˜ç¡®æœ€å¤§åŒ–åˆä½œæ”¶ç›Šâ€”â€”è”åˆSFT-RLè®­ç»ƒç›¸å¯¹äºä»…ä½¿ç”¨RLçš„æ€§èƒ½ä¼˜åŠ¿ã€‚åœ¨äº”ä¸ªæ¨ç†åŸºå‡†æµ‹è¯•ä¸Šçš„ç»éªŒè¯„ä¼°è¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•å§‹ç»ˆä¼˜äºåŸºçº¿ï¼Œå¹¶åœ¨æœ‰æ•ˆæ€§å’Œæ•ˆç‡ä¹‹é—´å–å¾—äº†æ›´å¥½çš„å¹³è¡¡ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.06948v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰åœ¨æ¿€åŠ±å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„æ¨ç†èƒ½åŠ›æ–¹é¢è¡¨ç°å‡ºè‰¯å¥½çš„æ•ˆæœï¼Œä½†ç”±äºå…¶è¯•é”™æ€§è´¨è€Œé¢ä¸´æ•ˆç‡æŒ‘æˆ˜ã€‚è™½ç„¶å¸¸è§çš„åšæ³•æ˜¯é‡‡ç”¨ç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰ä½œä¸ºRLçš„é¢„çƒ­é˜¶æ®µï¼Œä½†è¿™ç§è§£è€¦çš„ä¸¤é˜¶æ®µæ–¹æ³•é™åˆ¶äº†SFTå’ŒRLä¹‹é—´çš„äº¤äº’ï¼Œä»è€Œé™åˆ¶äº†æ•´ä½“æ•ˆæœã€‚æœ¬ç ”ç©¶å¼•å…¥äº†ä¸€ç§é‡‡ç”¨åŒå±‚ä¼˜åŒ–æ–¹æ³•å­¦ä¹ æ¨ç†æ¨¡å‹çš„æ–°æ–¹æ³•ï¼Œä»¥ä¿ƒè¿›è¿™ä¸¤ç§è®­ç»ƒèŒƒå¼ä¹‹é—´çš„æ›´å¥½åˆä½œã€‚é€šè¿‡ä»¥æœ€ä½³RLç­–ç•¥ä¸ºæ¡ä»¶ï¼Œæˆ‘ä»¬çš„æ–¹æ³•ä½¿SFTèƒ½å¤Ÿå…ƒå­¦ä¹ å¦‚ä½•å¼•å¯¼RLçš„ä¼˜åŒ–è¿‡ç¨‹ã€‚åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œä¸‹å±‚æ‰§è¡ŒRLæ›´æ–°ï¼ŒåŒæ—¶æ¥å—SFTç›‘ç£ï¼Œä¸Šå±‚åˆ™æ˜ç¡®æœ€å¤§åŒ–åˆä½œæ”¶ç›Šâ€”â€”è”åˆSFT-RLè®­ç»ƒç›¸å¯¹äºä»…ä½¿ç”¨RLçš„æ€§èƒ½ä¼˜åŠ¿ã€‚å®è¯è¯„ä¼°è¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨äº”ä¸ªæ¨ç†åŸºå‡†æµ‹è¯•ä¸Šå‡ä¼˜äºåŸºçº¿ï¼Œå¹¶åœ¨æœ‰æ•ˆæ€§å’Œæ•ˆç‡ä¹‹é—´è¾¾åˆ°äº†æ›´å¥½çš„å¹³è¡¡ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¼ºåŒ–å­¦ä¹ åœ¨æ¿€åŠ±å¤§å‹è¯­è¨€æ¨¡å‹çš„æ¨ç†èƒ½åŠ›ä¸Šæœ‰æ•ˆï¼Œä½†å­˜åœ¨æ•ˆç‡æŒ‘æˆ˜ã€‚</li>
<li>å¸¸è§çš„å¼ºåŒ–å­¦ä¹ æ–¹æ³•é‡‡ç”¨ç›‘ç£å¾®è°ƒä½œä¸ºé¢„çƒ­é˜¶æ®µï¼Œä½†è¿™ç§æ–¹æ³•é™åˆ¶äº†äº¤äº’å’Œæ•´ä½“æ•ˆæœã€‚</li>
<li>æœ¬ç ”ç©¶æå‡ºäº†ä¸€ç§é‡‡ç”¨åŒå±‚ä¼˜åŒ–çš„æ–°æ–¹æ³•ï¼Œä»¥ä¿ƒè¿›ç›‘ç£å¾®è°ƒä¸å¼ºåŒ–å­¦ä¹ ä¹‹é—´çš„åˆä½œã€‚</li>
<li>è¯¥æ–¹æ³•ä½¿ç›‘ç£å¾®è°ƒèƒ½å¤Ÿå…ƒå­¦ä¹ å¦‚ä½•å¼•å¯¼å¼ºåŒ–å­¦ä¹ çš„ä¼˜åŒ–è¿‡ç¨‹ã€‚</li>
<li>åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œä¸‹å±‚æ‰§è¡Œå¼ºåŒ–å­¦ä¹ æ›´æ–°å¹¶æ¥å—ç›‘ç£è°ƒæ•™çš„ç›‘ç£ï¼Œä¸Šå±‚åˆ™å…³æ³¨äºæœ€å¤§åŒ–åˆä½œæ”¶ç›Šã€‚</li>
<li>å®è¯è¯„ä¼°è¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å¤šä¸ªæ¨ç†åŸºå‡†æµ‹è¯•ä¸Šä¼˜äºåŸºçº¿æ–¹æ³•ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.06948">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-2893830b7f14abd2e7ca17545c8ceed4.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-7450908b103e5cfe616090d68d5ecfce.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-23d60fd076127d0aaf3adf864b1c85f5.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-6c064df4739d0d12c3ba393217df7564.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="Staying-in-the-Sweet-Spot-Responsive-Reasoning-Evolution-via-Capability-Adaptive-Hint-Scaffolding"><a href="#Staying-in-the-Sweet-Spot-Responsive-Reasoning-Evolution-via-Capability-Adaptive-Hint-Scaffolding" class="headerlink" title="Staying in the Sweet Spot: Responsive Reasoning Evolution via   Capability-Adaptive Hint Scaffolding"></a>Staying in the Sweet Spot: Responsive Reasoning Evolution via   Capability-Adaptive Hint Scaffolding</h2><p><strong>Authors:Ziheng Li, Zexu Sun, Jinman Zhao, Erxue Min, Yongcheng Zeng, Hui Wu, Hengyi Cai, Shuaiqiang Wang, Dawei Yin, Xu Chen, Zhi-Hong Deng</strong></p>
<p>Reinforcement learning with verifiable rewards (RLVR) has achieved remarkable success in enhancing the reasoning capabilities of large language models (LLMs). However, existing RLVR methods often suffer from exploration inefficiency due to mismatches between the training dataâ€™s difficulty and the modelâ€™s capability. LLMs fail to discover viable reasoning paths when problems are overly difficult, while learning little new capability when problems are too simple. In this work, we formalize the impact of problem difficulty by quantifying the relationship between loss descent speed and rollout accuracy. Building on this analysis, we propose SEELE, a novel supervision-aided RLVR framework that dynamically adjusts problem difficulty to stay within the high-efficiency region. SEELE augments each training sample by appending a hint (part of a full solution) after the original problem. Unlike previous hint-based approaches, SEELE deliberately and adaptively adjusts the hint length for each problem to achieve an optimal difficulty. To determine the optimal hint length, SEELE employs a multi-round rollout sampling strategy. In each round, it fits an item response theory model to the accuracy-hint pairs collected in preceding rounds to predict the required hint length for the next round. This instance-level, real-time difficulty adjustment aligns problem difficulty with the evolving model capability, thereby improving exploration efficiency. Experimental results show that SEELE outperforms Group Relative Policy Optimization (GRPO) and Supervised Fine-tuning (SFT) by +11.8 and +10.5 points, respectively, and surpasses the best previous supervision-aided approach by +3.6 points on average across six math reasoning benchmarks. </p>
<blockquote>
<p>å¼ºåŒ–å­¦ä¹ å¯éªŒè¯å¥–åŠ±ï¼ˆRLVRï¼‰åœ¨æé«˜å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„æ¨ç†èƒ½åŠ›æ–¹é¢å–å¾—äº†æ˜¾è‘—çš„æˆåŠŸã€‚ç„¶è€Œï¼Œç°æœ‰çš„RLVRæ–¹æ³•å¸¸å¸¸å› ä¸ºè®­ç»ƒæ•°æ®éš¾åº¦ä¸æ¨¡å‹èƒ½åŠ›ä¹‹é—´çš„ä¸åŒ¹é…è€Œå¯¼è‡´æ¢ç´¢æ•ˆç‡ä½ä¸‹ã€‚å½“é—®é¢˜è¿‡äºå›°éš¾æ—¶ï¼ŒLLMæ— æ³•å‘ç°å¯è¡Œçš„æ¨ç†è·¯å¾„ï¼Œè€Œå½“é—®é¢˜è¿‡äºç®€å•æ—¶ï¼Œå®ƒä»¬åˆæ— æ³•å­¦ä¹ åˆ°æ–°çš„èƒ½åŠ›ã€‚</p>
</blockquote>
<p>åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬é€šè¿‡é‡åŒ–æŸå¤±ä¸‹é™é€Ÿåº¦ä¸å›æ»šå‡†ç¡®åº¦ä¹‹é—´çš„å…³ç³»æ¥æ­£å¼åŒ–é—®é¢˜éš¾åº¦çš„å½±å“ã€‚åŸºäºè¿™ä¸€åˆ†æï¼Œæˆ‘ä»¬æå‡ºäº†SEELEï¼Œä¸€ä¸ªæ–°å‹çš„ç›‘ç£è¾…åŠ©RLVRæ¡†æ¶ï¼Œå®ƒèƒ½åŠ¨æ€è°ƒæ•´é—®é¢˜éš¾åº¦ä»¥ä¿æŒåœ¨é«˜æ•ˆåŒºåŸŸã€‚SEELEé€šè¿‡åœ¨æ¯ä¸ªè®­ç»ƒæ ·æœ¬åé™„åŠ ä¸€ä¸ªæç¤ºï¼ˆå®Œæ•´è§£å†³æ–¹æ¡ˆçš„ä¸€éƒ¨åˆ†ï¼‰æ¥å¢å¼ºæ¯ä¸ªè®­ç»ƒæ ·æœ¬ã€‚ä¸åŒäºä»¥å‰çš„åŸºäºæç¤ºçš„æ–¹æ³•ï¼ŒSEELEä¸ºæ¯ä¸ªé—®é¢˜ç²¾å¿ƒä¸”è‡ªé€‚åº”åœ°è°ƒæ•´æç¤ºé•¿åº¦ä»¥è¾¾åˆ°æœ€ä½³éš¾åº¦ã€‚</p>
<p>ä¸ºäº†ç¡®å®šæœ€ä½³çš„æç¤ºé•¿åº¦ï¼ŒSEELEé‡‡ç”¨å¤šè½®å›æ»šé‡‡æ ·ç­–ç•¥ã€‚åœ¨æ¯è½®ä¸­ï¼Œå®ƒæ ¹æ®å‰é¢å‡ è½®æ”¶é›†çš„å‡†ç¡®åº¦å’Œæç¤ºå¯¹æ¥æ‹Ÿåˆé¡¹ç›®ååº”ç†è®ºæ¨¡å‹ï¼Œä»¥é¢„æµ‹ä¸‹ä¸€è½®æ‰€éœ€çš„æç¤ºé•¿åº¦ã€‚è¿™ç§å®ä¾‹çº§åˆ«çš„å®æ—¶éš¾åº¦è°ƒæ•´ä½¿é—®é¢˜éš¾åº¦ä¸ä¸æ–­è¿›åŒ–çš„æ¨¡å‹èƒ½åŠ›ç›¸åŒ¹é…ï¼Œä»è€Œæé«˜äº†æ¢ç´¢æ•ˆç‡ã€‚</p>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.06923v1">PDF</a> Work in progress</p>
<p><strong>Summary</strong></p>
<p>å¼ºåŒ–å­¦ä¹ å¯éªŒè¯å¥–åŠ±ï¼ˆRLVRï¼‰åœ¨æé«˜å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„æ¨ç†èƒ½åŠ›æ–¹é¢å–å¾—äº†æ˜¾è‘—çš„æˆåŠŸã€‚ç„¶è€Œï¼Œç°æœ‰RLVRæ–¹æ³•å¸¸å› è®­ç»ƒæ•°æ®éš¾åº¦ä¸æ¨¡å‹èƒ½åŠ›çš„ä¸åŒ¹é…è€Œå¯¼è‡´æ¢ç´¢æ•ˆç‡ä½ä¸‹ã€‚å½“é—®é¢˜è¿‡äºå›°éš¾æ—¶ï¼ŒLLMæ— æ³•å‘ç°å¯è¡Œçš„æ¨ç†è·¯å¾„ï¼›å½“é—®é¢˜è¿‡äºç®€å•æ—¶ï¼Œæ¨¡å‹å­¦ä¹ ä¸åˆ°æ–°çš„èƒ½åŠ›ã€‚æœ¬ç ”ç©¶é€šè¿‡é‡åŒ–æŸå¤±ä¸‹é™é€Ÿåº¦ä¸å›æ»šå‡†ç¡®æ€§çš„å…³ç³»ï¼Œæ­£å¼åŒ–é—®é¢˜éš¾åº¦çš„å½±å“ã€‚åŸºäºæ­¤åˆ†æï¼Œæˆ‘ä»¬æå‡ºäº†SEELEï¼Œä¸€ä¸ªæ–°å‹çš„ç›‘ç£è¾…åŠ©RLVRæ¡†æ¶ï¼Œèƒ½å¤ŸåŠ¨æ€è°ƒæ•´é—®é¢˜éš¾åº¦ä»¥ä¿æŒåœ¨é«˜æ•ˆåŒºåŸŸã€‚SEELEé€šè¿‡è¿½åŠ æç¤ºï¼ˆå®Œæ•´è§£å†³æ–¹æ¡ˆçš„ä¸€éƒ¨åˆ†ï¼‰æ¥å¢å¼ºæ¯ä¸ªè®­ç»ƒæ ·æœ¬ã€‚ä¸åŒäºä»¥å¾€çš„æç¤ºæ–¹æ³•ï¼ŒSEELEä¸ºæ¯ä¸ªé—®é¢˜ç²¾å¿ƒä¸”è‡ªé€‚åº”åœ°è°ƒæ•´æç¤ºé•¿åº¦ä»¥è¾¾åˆ°æœ€ä½³éš¾åº¦ã€‚ä¸ºäº†ç¡®å®šæœ€ä½³æç¤ºé•¿åº¦ï¼ŒSEELEé‡‡ç”¨å¤šè½®å›æ»šé‡‡æ ·ç­–ç•¥ã€‚æ¯è½®ä¸­ï¼Œå®ƒæ ¹æ®å‰å‡ è½®æ”¶é›†çš„å‡†ç¡®æ€§ä¸æç¤ºå¯¹æ¥æ‹Ÿåˆé¡¹ç›®ååº”ç†è®ºæ¨¡å‹ï¼Œä»¥é¢„æµ‹ä¸‹ä¸€è½®æ‰€éœ€çš„æç¤ºé•¿åº¦ã€‚è¿™ç§å®ä¾‹çº§åˆ«çš„å®æ—¶éš¾åº¦è°ƒæ•´ä½¿é—®é¢˜éš¾åº¦ä¸ä¸æ–­è¿›åŒ–çš„æ¨¡å‹èƒ½åŠ›ç›¸åŒ¹é…ï¼Œæé«˜äº†æ¢ç´¢æ•ˆç‡ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒSEELEåœ¨å…­ä¸ªæ•°å­¦æ¨ç†åŸºå‡†æµ‹è¯•ä¸­åˆ†åˆ«ä¼˜äºGroup Relative Policy Optimizationï¼ˆGRPOï¼‰å’ŒSupervised Fine-tuningï¼ˆSFTï¼‰11.8å’Œ10.5ä¸ªç™¾åˆ†ç‚¹ï¼Œå¹¶å¹³å‡ä¼˜äºä¹‹å‰çš„æœ€ä½³ç›‘ç£è¾…åŠ©æ–¹æ³•3.6ä¸ªç™¾åˆ†ç‚¹ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>RLVRåœ¨æé«˜LLMæ¨ç†èƒ½åŠ›ä¸Šè¡¨ç°å“è¶Šï¼Œä½†å­˜åœ¨æ¢ç´¢æ•ˆç‡ä½ä¸‹çš„é—®é¢˜ã€‚</li>
<li>é—®é¢˜éš¾åº¦ä¸æ¨¡å‹èƒ½åŠ›çš„ä¸åŒ¹é…æ˜¯æ¢ç´¢æ•ˆç‡ä½ä¸‹çš„ä¸»è¦åŸå› ã€‚</li>
<li>SEELEæ¡†æ¶é€šè¿‡åŠ¨æ€è°ƒæ•´é—®é¢˜éš¾åº¦æ¥æé«˜æ¢ç´¢æ•ˆç‡ã€‚</li>
<li>SEELEé€šè¿‡è¿½åŠ æç¤ºæ¥å¢å¼ºè®­ç»ƒæ ·æœ¬ï¼Œå¹¶è‡ªé€‚åº”åœ°è°ƒæ•´æ¯ä¸ªé—®é¢˜çš„æç¤ºé•¿åº¦ã€‚</li>
<li>SEELEé‡‡ç”¨å¤šè½®å›æ»šé‡‡æ ·ç­–ç•¥æ¥ç¡®å®šæœ€ä½³æç¤ºé•¿åº¦ã€‚</li>
<li>SEELEå®ä¾‹çº§åˆ«çš„å®æ—¶éš¾åº¦è°ƒæ•´åŒ¹é…é—®é¢˜éš¾åº¦ä¸æ¨¡å‹èƒ½åŠ›ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.06923">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-63b1003145d116a08c96c12255b03fad.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-dbb22b2ee151451b2debcfc338c9ac75.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-d25be95785455750f74d4428043d5415.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a7a89fe1be3e90617108a1d248227e73.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="The-Majority-is-not-always-right-RL-training-for-solution-aggregation"><a href="#The-Majority-is-not-always-right-RL-training-for-solution-aggregation" class="headerlink" title="The Majority is not always right: RL training for solution aggregation"></a>The Majority is not always right: RL training for solution aggregation</h2><p><strong>Authors:Wenting Zhao, Pranjal Aggarwal, Swarnadeep Saha, Asli Celikyilmaz, Jason Weston, Ilia Kulikov</strong></p>
<p>Scaling up test-time compute, by generating multiple independent solutions and selecting or aggregating among them, has become a central paradigm for improving large language models (LLMs) on challenging reasoning tasks. While most prior work relies on simple majority voting or reward model ranking to aggregate solutions, these approaches may only yield limited benefits. In this work, we propose to learn aggregation as an explicit reasoning skill: given a set of candidate solutions, we train an aggregator model to review, reconcile, and synthesize a final, correct answer using reinforcement learning from verifiable rewards. A key ingredient is careful balancing of easy and hard training examples, allowing the model to learn both to recover minority-but-correct answers as well as easy majority-correct answers. Empirically, we find our method, AggLM, outperforms both strong rule-based and reward-model baselines, across multiple benchmarks. Furthermore, it generalizes effectively to solutions from differing models, including stronger ones than contained in the training data, all while requiring substantially fewer tokens than majority voting with larger numbers of solutions. </p>
<blockquote>
<p>é€šè¿‡ç”Ÿæˆå¤šä¸ªç‹¬ç«‹è§£å†³æ–¹æ¡ˆå¹¶åœ¨å…¶ä¸­è¿›è¡Œé€‰æ‹©æˆ–èšåˆï¼Œæ‰©å¤§æµ‹è¯•æ—¶çš„è®¡ç®—èƒ½åŠ›ï¼Œå·²æˆä¸ºåœ¨å…·æœ‰æŒ‘æˆ˜æ€§çš„æ¨ç†ä»»åŠ¡ä¸­æ”¹è¿›å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„æ ¸å¿ƒèŒƒå¼ã€‚è™½ç„¶å¤§å¤šæ•°å…ˆå‰çš„å·¥ä½œä¾èµ–äºç®€å•çš„å¤šæ•°æŠ•ç¥¨æˆ–å¥–åŠ±æ¨¡å‹æ’åæ¥èšåˆè§£å†³æ–¹æ¡ˆï¼Œä½†è¿™äº›æ–¹æ³•å¯èƒ½åªèƒ½äº§ç”Ÿæœ‰é™çš„æ•ˆç›Šã€‚åœ¨æœ¬ç ”ç©¶ä¸­ï¼Œæˆ‘ä»¬æå‡ºå°†èšåˆä½œä¸ºä¸€ç§æ˜ç¡®çš„æ¨ç†æŠ€èƒ½æ¥å­¦ä¹ ï¼šç»™å®šä¸€ç»„å€™é€‰è§£å†³æ–¹æ¡ˆï¼Œæˆ‘ä»¬è®­ç»ƒä¸€ä¸ªèšåˆå™¨æ¨¡å‹ï¼Œä½¿ç”¨å¯éªŒè¯çš„å¥–åŠ±è¿›è¡Œå¼ºåŒ–å­¦ä¹ ï¼Œä»¥å®¡æŸ¥ã€åè°ƒå¹¶åˆæˆæœ€ç»ˆçš„æ­£ç¡®ç­”æ¡ˆã€‚å…³é”®è¦ç´ æ˜¯ä»”ç»†å¹³è¡¡ç®€å•å’Œå›°éš¾çš„è®­ç»ƒç¤ºä¾‹ï¼Œè®©æ¨¡å‹æ—¢èƒ½æ¢å¤å°‘æ•°ä½†æ­£ç¡®çš„ç­”æ¡ˆï¼Œä¹Ÿèƒ½è·å¾—ç®€å•çš„å¤šæ•°æ­£ç¡®ç­”æ¡ˆã€‚ä»ç»éªŒä¸Šçœ‹ï¼Œæˆ‘ä»¬å‘ç°æˆ‘ä»¬çš„æ–¹æ³•AggLMåœ¨å¤šåŸºå‡†æµ‹è¯•ä¸­å‡è¡¨ç°å‡ºä¼˜äºå¼ºå¤§çš„åŸºäºè§„åˆ™å’Œå¥–åŠ±æ¨¡å‹åŸºçº¿ã€‚æ­¤å¤–ï¼Œå®ƒè¿˜èƒ½å¤Ÿæœ‰æ•ˆåœ°æ¨å¹¿åˆ°æ¥è‡ªä¸åŒæ¨¡å‹çš„è§£å†³æ–¹æ¡ˆï¼ŒåŒ…æ‹¬è®­ç»ƒæ•°æ®ä¸­çš„æ›´å¼ºæ¨¡å‹ã€‚åŒæ—¶ï¼Œå®ƒéœ€è¦ä½¿ç”¨çš„ä»¤ç‰Œæ•°é‡è¿œè¿œå°‘äºä½¿ç”¨æ›´å¤šè§£å†³æ–¹æ¡ˆçš„å¤šæ•°æŠ•ç¥¨æ–¹æ³•ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.06870v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>å¤§è§„æ¨¡è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨æŒ‘æˆ˜æ€§æ¨ç†ä»»åŠ¡ä¸Šï¼Œé€šè¿‡ç”Ÿæˆå¤šä¸ªç‹¬ç«‹è§£å†³æ–¹æ¡ˆå¹¶è¿›è¡Œé€‰æ‹©æˆ–èšåˆæ¥æé«˜æ€§èƒ½å·²æˆä¸ºä¸­å¿ƒèŒƒå¼ã€‚ç„¶è€Œï¼Œå¤§å¤šæ•°å…ˆå‰çš„å·¥ä½œä¾èµ–äºç®€å•çš„å¤šæ•°æŠ•ç¥¨æˆ–å¥–åŠ±æ¨¡å‹æ’åæ¥èšåˆè§£å†³æ–¹æ¡ˆï¼Œè¿™äº›æ–¹æ³•å¯èƒ½åªèƒ½å¸¦æ¥æœ‰é™çš„æ•ˆç›Šã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬æå‡ºå°†èšåˆä½œä¸ºä¸€ç§æ˜ç¡®çš„æ¨ç†æŠ€èƒ½æ¥å­¦ä¹ ï¼šç»™å®šä¸€ç»„å€™é€‰è§£å†³æ–¹æ¡ˆï¼Œæˆ‘ä»¬è®­ç»ƒä¸€ä¸ªèšåˆå™¨æ¨¡å‹ï¼Œä½¿ç”¨å¯éªŒè¯çš„å¥–åŠ±é€šè¿‡å¼ºåŒ–å­¦ä¹ æ¥å®¡æŸ¥ã€åè°ƒå’Œç»¼åˆæœ€ç»ˆçš„æ­£ç¡®ç­”æ¡ˆã€‚é€šè¿‡å¹³è¡¡ç®€å•å’Œå›°éš¾çš„è®­ç»ƒç¤ºä¾‹ï¼Œæˆ‘ä»¬çš„æ¨¡å‹å¯ä»¥å­¦ä¹ ä»å°‘æ•°ä½†æ­£ç¡®çš„ç­”æ¡ˆå’Œå¤§å¤šæ•°æ­£ç¡®çš„ç­”æ¡ˆä¸­æ¢å¤ç­”æ¡ˆçš„èƒ½åŠ›ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œæˆ‘ä»¬çš„æ–¹æ³•AggLMåœ¨å¤šç»„æ ‡å‡†æµ‹è¯•ä¸Šçš„è¡¨ç°ä¼˜äºåŸºäºè§„åˆ™å’Œå¥–åŠ±æ¨¡å‹çš„åŸºçº¿æ–¹æ³•ï¼Œå¹¶ä¸”å¯ä»¥æœ‰æ•ˆåœ°æ¨å¹¿åˆ°æ¥è‡ªä¸åŒæ¨¡å‹çš„è§£å†³æ–¹æ¡ˆï¼ŒåŒ…æ‹¬æ¯”è®­ç»ƒæ•°æ®æ›´å¼ºçš„æ¨¡å‹ï¼ŒåŒæ—¶éœ€è¦çš„ä»¤ç‰Œæ•°é‡å¤§å¤§å‡å°‘ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>é€šè¿‡ç”Ÿæˆå¤šä¸ªç‹¬ç«‹è§£å†³æ–¹æ¡ˆå¹¶åœ¨æµ‹è¯•æ—¶è¿›è¡Œèšåˆï¼Œå·²æˆä¸ºæ”¹å–„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨æŒ‘æˆ˜æ€§æ¨ç†ä»»åŠ¡ä¸Šè¡¨ç°çš„ä¸­å¿ƒèŒƒå¼ã€‚</li>
<li>å¤§å¤šæ•°ç°æœ‰æ–¹æ³•ä¾èµ–äºç®€å•çš„å¤šæ•°æŠ•ç¥¨æˆ–å¥–åŠ±æ¨¡å‹æ’åæ¥èšåˆè§£å†³æ–¹æ¡ˆï¼Œè¿™å¯èƒ½ä¼šå¯¼è‡´æœ‰é™çš„æ•ˆç›Šã€‚</li>
<li>åœ¨è¿™é¡¹ç ”ç©¶ä¸­ï¼Œæå‡ºäº†ä¸€ç§æ–°çš„æ–¹æ³•â€”â€”AggLMï¼Œé€šè¿‡è®­ç»ƒä¸€ä¸ªèšåˆå™¨æ¨¡å‹ï¼Œä½¿ç”¨å¼ºåŒ–å­¦ä¹ ä»å¯éªŒè¯çš„å¥–åŠ±ä¸­å®¡æŸ¥ã€åè°ƒå’Œç»¼åˆç­”æ¡ˆã€‚</li>
<li>AggLMèƒ½å¤Ÿåœ¨å¹³è¡¡ç®€å•å’Œå›°éš¾çš„è®­ç»ƒç¤ºä¾‹æ—¶å­¦ä¹ æ¢å¤ç­”æ¡ˆçš„èƒ½åŠ›ï¼ŒåŒ…æ‹¬ä»å°‘æ•°ä½†æ­£ç¡®çš„ç­”æ¡ˆå’Œå¤§å¤šæ•°æ­£ç¡®çš„ç­”æ¡ˆä¸­æ¢å¤ã€‚</li>
<li>AggLMåœ¨å¤šä¸ªæ ‡å‡†æµ‹è¯•ä¸Šçš„è¡¨ç°ä¼˜äºåŸºäºè§„åˆ™å’Œå¥–åŠ±æ¨¡å‹çš„åŸºçº¿æ–¹æ³•ã€‚</li>
<li>AggLMå¯ä»¥æœ‰æ•ˆåœ°æ¨å¹¿åˆ°æ¥è‡ªä¸åŒæ¨¡å‹çš„è§£å†³æ–¹æ¡ˆï¼ŒåŒ…æ‹¬æ¯”è®­ç»ƒæ•°æ®æ›´å¼ºçš„æ¨¡å‹ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.06870">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-d5a2fd48f65870f391c16c0dde4ba202.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-a845e858c885eee93fd3cf68c7b36dbf.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-f9c4067cce580e50a88d6a639d686307.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-fa22ac50e7ff9e520f6b1430c7656d1c.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-923f66cdc4d4efbeb6b48dd575bbf6a6.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="EPT-Benchmark-Evaluation-of-Persian-Trustworthiness-in-Large-Language-Models"><a href="#EPT-Benchmark-Evaluation-of-Persian-Trustworthiness-in-Large-Language-Models" class="headerlink" title="EPT Benchmark: Evaluation of Persian Trustworthiness in Large Language   Models"></a>EPT Benchmark: Evaluation of Persian Trustworthiness in Large Language   Models</h2><p><strong>Authors:Mohammad Reza Mirbagheri, Mohammad Mahdi Mirkamali, Zahra Motoshaker Arani, Ali Javeri, Amir Mahdi Sadeghzadeh, Rasool Jalili</strong></p>
<p>Large Language Models (LLMs), trained on extensive datasets using advanced deep learning architectures, have demonstrated remarkable performance across a wide range of language tasks, becoming a cornerstone of modern AI technologies. However, ensuring their trustworthiness remains a critical challenge, as reliability is essential not only for accurate performance but also for upholding ethical, cultural, and social values. Careful alignment of training data and culturally grounded evaluation criteria are vital for developing responsible AI systems. In this study, we introduce the EPT (Evaluation of Persian Trustworthiness) metric, a culturally informed benchmark specifically designed to assess the trustworthiness of LLMs across six key aspects: truthfulness, safety, fairness, robustness, privacy, and ethical alignment. We curated a labeled dataset and evaluated the performance of several leading models - including ChatGPT, Claude, DeepSeek, Gemini, Grok, LLaMA, Mistral, and Qwen - using both automated LLM-based and human assessments. Our results reveal significant deficiencies in the safety dimension, underscoring the urgent need for focused attention on this critical aspect of model behavior. Furthermore, our findings offer valuable insights into the alignment of these models with Persian ethical-cultural values and highlight critical gaps and opportunities for advancing trustworthy and culturally responsible AI. The dataset is publicly available at: <a target="_blank" rel="noopener" href="https://github.com/Rezamirbagheri110/EPT-Benchmark">https://github.com/Rezamirbagheri110/EPT-Benchmark</a>. </p>
<blockquote>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰é€šè¿‡å…ˆè¿›çš„æ·±åº¦å­¦ä¹ æ¶æ„åœ¨å¤§é‡æ•°æ®é›†ä¸Šè¿›è¡Œè®­ç»ƒï¼Œå·²åœ¨å„ç§è¯­è¨€ä»»åŠ¡ä¸­å±•ç°å‡ºå“è¶Šçš„æ€§èƒ½ï¼Œæˆä¸ºç°ä»£AIæŠ€æœ¯çš„æ ¸å¿ƒã€‚ç„¶è€Œï¼Œç¡®ä¿å®ƒä»¬çš„å¯ä¿¡æ€§ä»ç„¶æ˜¯ä¸€ä¸ªå·¨å¤§çš„æŒ‘æˆ˜ï¼Œå› ä¸ºå¯é æ€§ä¸ä»…å¯¹å‡†ç¡®æ€§èƒ½è‡³å…³é‡è¦ï¼Œè€Œä¸”ä¹Ÿæ˜¯ç»´æŒé“å¾·ã€æ–‡åŒ–å’Œç¤¾ä¼šä»·å€¼çš„å…³é”®ã€‚åŸ¹è®­æ•°æ®çš„ä»”ç»†å¯¹é½å’Œæ–‡åŒ–ä¸Šç«‹è¶³çš„è¯„ä¼°æ ‡å‡†æ˜¯å‘å±•è´Ÿè´£ä»»çš„AIç³»ç»Ÿçš„é‡è¦æ¡ä»¶ã€‚åœ¨æœ¬ç ”ç©¶ä¸­ï¼Œæˆ‘ä»¬ä»‹ç»äº†EPTï¼ˆæ³¢æ–¯è¯­å¯ä¿¡åº¦è¯„ä¼°ï¼‰æŒ‡æ ‡ï¼Œè¿™æ˜¯ä¸€ä¸ªå—æ–‡åŒ–å¯å‘çš„åŸºå‡†æµ‹è¯•ï¼Œä¸“é—¨è®¾è®¡ç”¨äºè¯„ä¼°LLMåœ¨çœŸå®æ€§ã€å®‰å…¨æ€§ã€å…¬å¹³æ€§ã€ç¨³å¥æ€§ã€éšç§å’Œé“å¾·ä¸€è‡´æ€§ç­‰å…­ä¸ªå…³é”®æ–¹é¢çš„å¯ä¿¡åº¦ã€‚æˆ‘ä»¬æ•´ç†äº†ä¸€ä¸ªæ ‡è®°æ•°æ®é›†ï¼Œå¹¶ä½¿ç”¨åŸºäºLLMçš„è‡ªåŠ¨åŒ–è¯„ä¼°å’Œäººå·¥è¯„ä¼°ï¼Œå¯¹åŒ…æ‹¬ChatGPTã€Claudeã€DeepSeekã€Geminiã€Grokã€LLaMAã€Mistralå’ŒQwenç­‰å¤šä¸ªé¢†å…ˆæ¨¡å‹è¿›è¡Œäº†è¯„ä¼°ã€‚æˆ‘ä»¬çš„ç»“æœè¡¨æ˜ï¼Œåœ¨å®‰å…¨æ–¹é¢å­˜åœ¨æ˜¾è‘—ç¼ºé™·ï¼Œè¿™çªæ˜¾äº†å¯¹æ¨¡å‹è¡Œä¸ºè¿™ä¸€å…³é”®æ–¹é¢çš„å…³æ³¨è¿«åœ¨çœ‰ç«ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬çš„ç ”ç©¶è¿˜å‘ç°è¿™äº›æ¨¡å‹ä¸æ³¢æ–¯é“å¾·æ–‡åŒ–ä»·å€¼è§‚çš„å¥‘åˆç¨‹åº¦ï¼Œå¹¶æ­ç¤ºäº†å®ç°å¯ä¿¡å’Œç¬¦åˆæ–‡åŒ–çš„AIçš„å…³é”®å·®è·å’Œæœºä¼šã€‚æ•°æ®é›†å¯åœ¨ä»¥ä¸‹ç½‘å€å…¬å¼€è·å–ï¼š<a target="_blank" rel="noopener" href="https://github.com/Rezamirbagheri110/EPT-Benchmark">https://github.com/Rezamirbagheri110/EPT-Benchmark</a> ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.06838v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>å¤§è§„æ¨¡è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨ç°ä»£AIæŠ€æœ¯ä¸­æ‰®æ¼”ç€é‡è¦è§’è‰²ï¼Œå·²å¹¿æ³›åº”ç”¨äºå„ç§è¯­è¨€ä»»åŠ¡å¹¶å±•ç°å‡ºå“è¶Šæ€§èƒ½ã€‚ç„¶è€Œï¼Œç¡®ä¿å…¶å¯ä¿¡æ€§æ˜¯è‡³å…³é‡è¦çš„æŒ‘æˆ˜ï¼Œä¸ä»…å…³ä¹æ€§èƒ½å‡†ç¡®æ€§ï¼Œä¹Ÿå…³ä¹ç»´æŠ¤ä¼¦ç†ã€æ–‡åŒ–å’Œç¤¾å€¼ã€‚æœ¬ç ”ç©¶ä»‹ç»äº†EPTï¼ˆæ³¢æ–¯å¯ä¿¡æ€§è¯„ä»·ï¼‰æŒ‡æ ‡ï¼Œè¿™æ˜¯ä¸€ä¸ªä¸“é—¨è®¾è®¡çš„æ–‡åŒ–ä¿¡æ¯åŸºå‡†æµ‹è¯•ï¼Œç”¨äºè¯„ä¼°LLMåœ¨çœŸå®æ€§ã€å®‰å…¨æ€§ã€å…¬å¹³æ€§ã€ç¨³å¥æ€§ã€éšç§å’Œé“å¾·å¯¹é½ç­‰å…­ä¸ªå…³é”®æ–¹é¢çš„å¯ä¿¡åº¦ã€‚é€šè¿‡å¯¹å¤šä¸ªä¸»æµæ¨¡å‹çš„å®‰å…¨æ€§èƒ½è¿›è¡Œè¯„ä¼°ï¼Œå‘ç°å­˜åœ¨æ˜æ˜¾ç¼ºé™·ï¼Œå¼ºè°ƒè¿«åˆ‡éœ€è¦å…³æ³¨è¿™ä¸€å…³é”®æ¨¡å‹è¡Œä¸ºçš„æ–¹é¢ã€‚æ­¤å¤–ï¼Œæœ¬ç ”ç©¶è¿˜å‘ç°è¿™äº›æ¨¡å‹ä¸æ³¢æ–¯ä¼¦ç†æ–‡åŒ–ä»·å€¼è§‚çš„å¥‘åˆåº¦å­˜åœ¨å·®è·å’Œæœºé‡ï¼Œä¸ºä¿ƒè¿›å¯ä¿¡å’Œæ–‡åŒ–è´Ÿè´£çš„äººå·¥æ™ºèƒ½æä¾›äº†å®è´µè§è§£ã€‚æ•°æ®é›†å¯åœ¨å…¬å¼€è®¿é—®ï¼š<a target="_blank" rel="noopener" href="https://github.com/Rezamirbagheri110/EPT-Benchmark%E3%80%82">https://github.com/Rezamirbagheri110/EPT-Benchmarkã€‚</a></p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>LLMså·²æˆä¸ºç°ä»£AIæŠ€æœ¯çš„æ ¸å¿ƒï¼Œå¹¿æ³›åº”ç”¨äºå„ç§è¯­è¨€ä»»åŠ¡ã€‚</li>
<li>ç¡®ä¿LLMsçš„å¯é æ€§å¯¹äºç»´æŠ¤ä¼¦ç†ã€æ–‡åŒ–å’Œç¤¾ä¼šä»·å€¼è‡³å…³é‡è¦ã€‚</li>
<li>EPTæŒ‡æ ‡æ˜¯ä¸€ä¸ªæ–‡åŒ–ä¿¡æ¯åŸºå‡†æµ‹è¯•ï¼Œç”¨äºè¯„ä¼°LLMåœ¨å…­ä¸ªå…³é”®æ–¹é¢çš„å¯ä¿¡åº¦ï¼šçœŸå®æ€§ã€å®‰å…¨æ€§ã€å…¬å¹³æ€§ã€ç¨³å¥æ€§ã€éšç§å’Œé“å¾·å¯¹é½ã€‚</li>
<li>LLMåœ¨å®‰å…¨æ€§èƒ½æ–¹é¢å­˜åœ¨æ˜æ˜¾ä¸è¶³ï¼Œéœ€è¦é‡ç‚¹å…³æ³¨ã€‚</li>
<li>LLMä¸æ³¢æ–¯ä¼¦ç†æ–‡åŒ–ä»·å€¼è§‚çš„å¥‘åˆåº¦å­˜åœ¨å·®è·å’Œæœºé‡ã€‚</li>
<li>å…¬å¼€å¯ç”¨çš„æ•°æ®é›†ä¸ºæ¨è¿›å¯ä¿¡å’Œæ–‡åŒ–è´Ÿè´£çš„äººå·¥æ™ºèƒ½æä¾›äº†èµ„æºã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.06838">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-624f2cf48af5042d337cdc311e2cd662.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-e39c5aa2542d33c3c5b1106eea6f4c45.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-ce762213c79be8f2ebcdc0699aa51ed6.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="RAFFLES-Reasoning-based-Attribution-of-Faults-for-LLM-Systems"><a href="#RAFFLES-Reasoning-based-Attribution-of-Faults-for-LLM-Systems" class="headerlink" title="RAFFLES: Reasoning-based Attribution of Faults for LLM Systems"></a>RAFFLES: Reasoning-based Attribution of Faults for LLM Systems</h2><p><strong>Authors:Chenyang Zhu, Spencer Hong, Jingyu Wu, Kushal Chawla, Charlotte Tang, Youbing Yin, Nathan Wolfe, Erin Babinsky, Daben Liu</strong></p>
<p>We have reached a critical roadblock in the development and enhancement of long-horizon, multi-component LLM agentic systems: it is incredibly tricky to identify where these systems break down and why. Evaluation capabilities that currently exist today (e.g., single pass LLM-as-a-judge) are limited in that they often focus on individual metrics or capabilities, end-to-end outcomes, and are narrowly grounded on the preferences of humans. We argue that to match the agentic capabilities, evaluation frameworks must also be able to reason, probe, iterate, and understand the complex logic passing through these systems over long horizons. In this paper, we present RAFFLES - an evaluation architecture that incorporates reasoning and iterative refinement. Specifically, RAFFLES operates as an iterative, multi-component pipeline, using a central Judge to systematically investigate faults and a set of specialized Evaluators to assess not only the systemâ€™s components but also the quality of the reasoning by the Judge itself, thereby building a history of hypotheses. We tested RAFFLES against several baselines on the Who&amp;When dataset, a benchmark designed to diagnose the â€œwhoâ€ (agent) and â€œwhenâ€ (step) of a systemâ€™s failure. RAFFLES outperforms these baselines, achieving an agent-step fault pair accuracy of over 43% on the Algorithmically-Generated dataset (a substantial increase from the previously published best of 16.6%) and over 20% on the Hand-Crafted dataset (surpassing the previously published best of 8.8%). These results demonstrate a key step towards introducing automated fault detection for autonomous systems over labor-intensive manual human review. </p>
<blockquote>
<p>æˆ‘ä»¬åœ¨é•¿æœŸå¤šç»„ä»¶LLMä¸»ä½“ç³»ç»Ÿçš„å¼€å‘å’Œå¢å¼ºæ–¹é¢é‡åˆ°äº†å…³é”®çš„éš¾é¢˜ï¼šå¾ˆéš¾ç¡®å®šè¿™äº›ç³»ç»Ÿåœ¨ä½•å¤„å´©æºƒä»¥åŠåŸå› æ˜¯ä»€ä¹ˆã€‚ç›®å‰å­˜åœ¨çš„è¯„ä¼°èƒ½åŠ›ï¼ˆä¾‹å¦‚ï¼Œå•é€šé“LLM-ä½œä¸ºè¯„åˆ¤ï¼‰ä»…é™äºå…³æ³¨ä¸ªä½“æŒ‡æ ‡æˆ–èƒ½åŠ›ã€ç«¯åˆ°ç«¯çš„ç»“æœï¼Œå¹¶ç‹­éš˜åœ°åŸºäºäººç±»çš„åå¥½ã€‚æˆ‘ä»¬è®¤ä¸ºï¼Œä¸ºäº†åŒ¹é…ä¸»ä½“çš„èƒ½åŠ›ï¼Œè¯„ä¼°æ¡†æ¶è¿˜å¿…é¡»èƒ½å¤Ÿæ¨ç†ã€æ¢ç´¢ã€è¿­ä»£å¹¶ç†è§£é•¿æœŸå†…é€šè¿‡è¿™äº›ç³»ç»Ÿçš„å¤æ‚é€»è¾‘ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬ä»‹ç»äº†RAFFLESâ€”â€”ä¸€ä¸ªç»“åˆäº†æ¨ç†å’Œè¿­ä»£ä¼˜åŒ–çš„è¯„ä¼°æ¶æ„ã€‚å…·ä½“æ¥è¯´ï¼ŒRAFFLESä½œä¸ºä¸€ä¸ªè¿­ä»£çš„å¤šç»„ä»¶ç®¡é“è¿›è¡Œæ“ä½œï¼Œä½¿ç”¨ä¸€ä¸ªä¸­å¤®è¯„åˆ¤æ¥ç³»ç»Ÿåœ°è°ƒæŸ¥æ•…éšœå’Œä¸€ç³»åˆ—ä¸“é—¨çš„è¯„ä¼°å™¨æ¥è¯„ä¼°ä¸ä»…ç³»ç»Ÿçš„ç»„ä»¶ï¼Œè¿˜è¯„ä¼°è¯„åˆ¤æœ¬èº«çš„æ¨ç†è´¨é‡ï¼Œä»è€Œå»ºç«‹å‡è®¾å†å²ã€‚æˆ‘ä»¬åœ¨Who&amp;Whenæ•°æ®é›†ä¸Šå¯¹RAFFLESè¿›è¡Œäº†å‡ æ¬¡åŸºå‡†æµ‹è¯•ï¼Œè¯¥åŸºå‡†æµ‹è¯•æ—¨åœ¨è¯Šæ–­ç³»ç»Ÿçš„â€œè°â€ï¼ˆä¸»ä½“ï¼‰å’Œâ€œä½•æ—¶â€ï¼ˆæ­¥éª¤ï¼‰æ•…éšœã€‚RAFFLESä¼˜äºè¿™äº›åŸºå‡†æµ‹è¯•ï¼Œåœ¨ç®—æ³•ç”Ÿæˆçš„æ•°æ®é›†ä¸Šï¼Œä¸»ä½“æ­¥éª¤æ•…éšœå¯¹å‡†ç¡®ç‡è¶…è¿‡43%ï¼ˆè¾ƒä¹‹å‰å‘å¸ƒçš„æœ€ä½³æˆç»©16.6%æœ‰å¤§å¹…åº¦æé«˜ï¼‰ï¼Œåœ¨æ‰‹å·¥åˆ¶ä½œçš„æ•°æ®é›†ä¸Šå‡†ç¡®ç‡è¶…è¿‡2.å¯¹äºç›®å‰çš„è‡ªç„¶è¯­è¨€å¤„ç†å’Œäººå·¥æ™ºèƒ½æ¨¡å‹é¢†åŸŸè€Œè¨€è¿™æ˜¯ä¸€ä¸ªé‡å¤§è¿›æ­¥ï¼Œå®ƒæœç€å¼•å…¥è‡ªä¸»ç³»ç»Ÿçš„è‡ªåŠ¨åŒ–æ•…éšœæ£€æµ‹æ–¹å‘è¿ˆå‡ºäº†å…³é”®ä¸€æ­¥ï¼Œå‡å°‘äº†åŠ³åŠ¨å¯†é›†å‹çš„ä¼ ç»Ÿäººå·¥å®¡æŸ¥ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.06822v1">PDF</a> </p>
<p><strong>æ‘˜è¦</strong></p>
<p>è¯¥æ–‡é’ˆå¯¹é•¿å‘¨æœŸã€å¤šç»„ä»¶LLMæ™ºèƒ½ç³»ç»Ÿçš„å‘å±•å’Œæå‡ï¼Œæå‡ºäº†ä¸€ä¸ªå…³é”®éš¾é¢˜ï¼šå¦‚ä½•è¯†åˆ«è¿™äº›ç³»ç»Ÿçš„æ•…éšœåŠå…¶åŸå› ã€‚ç°æœ‰çš„è¯„ä¼°æ–¹æ³•ï¼ˆå¦‚å•ä¸€é€šè¿‡LLMä½œä¸ºè¯„åˆ¤ï¼‰å­˜åœ¨å±€é™æ€§ï¼Œéš¾ä»¥å…¨é¢è¯„ä¼°ç³»ç»Ÿæ€§èƒ½ã€‚ä¸ºæ­¤ï¼Œä½œè€…æå‡ºäº†RAFFLESè¯„ä¼°æ¶æ„ï¼Œèåˆäº†æ¨ç†å’Œè¿­ä»£ä¼˜åŒ–ã€‚RAFFLESé‡‡ç”¨è¿­ä»£ã€å¤šç»„ä»¶ç®¡é“å½¢å¼ï¼Œé€šè¿‡ä¸­å¤®è¯„åˆ¤ç³»ç»Ÿè°ƒæŸ¥æ•…éšœï¼Œå¹¶ä½¿ç”¨ä¸€ç³»åˆ—ä¸“ä¸šè¯„ä¼°å™¨ä¸ä»…è¯„ä¼°ç³»ç»Ÿç»„ä»¶ï¼Œè¿˜è¯„ä¼°è¯„åˆ¤æœ¬èº«çš„æ¨ç†è´¨é‡ï¼Œä»è€Œå»ºç«‹å‡è®¾åº“ã€‚åœ¨Who&amp;Whenæ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒRAFFLESåœ¨ç®—æ³•ç”Ÿæˆæ•°æ®é›†ä¸Šçš„agent-stepæ•…éšœå¯¹å‡†ç¡®ç‡è¶…è¿‡43%ï¼Œå¤§å¹…è¶…è¶Šä¹‹å‰çš„æœ€ä½³æˆç»©ï¼ˆä»…16.6%ï¼‰ï¼Œå¹¶åœ¨æ‰‹å·¥æ•°æ®é›†ä¸Šè¶…è¿‡20%ï¼ˆè¶…è¶Šä¹‹å‰çš„æœ€ä½³æˆç»©ä»…8.8%ï¼‰ã€‚è¿™è¯æ˜äº†è‡ªåŠ¨åŒ–æ•…éšœæ£€æµ‹åœ¨è‡ªä¸»ç³»ç»Ÿå‘å±•ä¸­çš„å…³é”®ä½œç”¨ã€‚æ€»çš„æ¥è¯´ï¼ŒRAFFLESä¸ºæ™ºèƒ½ç³»ç»Ÿçš„æ•…éšœæ£€æµ‹æä¾›äº†æ–°çš„æ–¹å‘ã€‚</p>
<p><strong>å…³é”®è§è§£</strong></p>
<ol>
<li>LLMæ™ºèƒ½ç³»ç»Ÿåœ¨è¯†åˆ«å’Œè¯Šæ–­æ•…éšœæ–¹é¢é¢ä¸´æŒ‘æˆ˜ã€‚</li>
<li>å½“å‰è¯„ä¼°æ–¹æ³•å­˜åœ¨å±€é™æ€§ï¼Œæ— æ³•å…¨é¢è¯„ä¼°é•¿å‘¨æœŸã€å¤šç»„ä»¶LLMæ™ºèƒ½ç³»ç»Ÿçš„æ€§èƒ½ã€‚</li>
<li>æå‡ºäº†RAFFLESè¯„ä¼°æ¶æ„ï¼Œç»“åˆäº†æ¨ç†å’Œè¿­ä»£ä¼˜åŒ–æ¥è¯Šæ–­LLMæ™ºèƒ½ç³»ç»Ÿçš„æ•…éšœã€‚</li>
<li>RAFFLESé€šè¿‡ä¸­å¤®è¯„åˆ¤ç³»ç»Ÿå’Œä¸“ä¸šè¯„ä¼°å™¨æ¥ç³»ç»Ÿåœ°è°ƒæŸ¥æ•…éšœå¹¶è¯„ä¼°ç³»ç»Ÿæ€§èƒ½ã€‚</li>
<li>åœ¨Who&amp;Whenæ•°æ®é›†ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼ŒRAFFLESæ˜¾è‘—æé«˜äº†æ•…éšœæ£€æµ‹çš„å‡†ç¡®æ€§ã€‚</li>
<li>RAFFLESä¸ºè‡ªä¸»ç³»ç»Ÿçš„è‡ªåŠ¨åŒ–æ•…éšœæ£€æµ‹æä¾›äº†æ–°çš„å¯èƒ½æ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.06822">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-42ef2dd5eeb17738895d5f92be6f0e0e.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-403a3838f404241646429a42db133bab.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-a267450137a1beaf498039298d09da08.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="A-Comparative-Benchmark-of-Large-Language-Models-for-Labelling-Wind-Turbine-Maintenance-Logs"><a href="#A-Comparative-Benchmark-of-Large-Language-Models-for-Labelling-Wind-Turbine-Maintenance-Logs" class="headerlink" title="A Comparative Benchmark of Large Language Models for Labelling Wind   Turbine Maintenance Logs"></a>A Comparative Benchmark of Large Language Models for Labelling Wind   Turbine Maintenance Logs</h2><p><strong>Authors:Max Malyi, Jonathan Shek, Alasdair McDonald, Andre Biscaya</strong></p>
<p>Effective Operation and Maintenance (O&amp;M) is critical to reducing the Levelised Cost of Energy (LCOE) from wind power, yet the unstructured, free-text nature of turbine maintenance logs presents a significant barrier to automated analysis. Our paper addresses this by presenting a novel and reproducible framework for benchmarking Large Language Models (LLMs) on the task of classifying these complex industrial records. To promote transparency and encourage further research, this framework has been made publicly available as an open-source tool. We systematically evaluate a diverse suite of state-of-the-art proprietary and open-source LLMs, providing a foundational assessment of their trade-offs in reliability, operational efficiency, and model calibration. Our results quantify a clear performance hierarchy, identifying top models that exhibit high alignment with a benchmark standard and trustworthy, well-calibrated confidence scores. We also demonstrate that classification performance is highly dependent on the taskâ€™s semantic ambiguity, with all models showing higher consensus on objective component identification than on interpretive maintenance actions. Given that no model achieves perfect accuracy and that calibration varies dramatically, we conclude that the most effective and responsible near-term application is a Human-in-the-Loop system, where LLMs act as a powerful assistant to accelerate and standardise data labelling for human experts, thereby enhancing O&amp;M data quality and downstream reliability analysis. </p>
<blockquote>
<p>æœ‰æ•ˆçš„æ“ä½œå’Œç»´æŠ¤ï¼ˆOï¼†Mï¼‰å¯¹äºé™ä½é£åŠ›å‘ç”µçš„å¹³å‡†åŒ–èƒ½æºæˆæœ¬ï¼ˆLCOEï¼‰è‡³å…³é‡è¦ã€‚ç„¶è€Œï¼Œæ¶¡è½®æœºç»´æŠ¤æ—¥å¿—çš„éç»“æ„åŒ–ã€è‡ªç”±æ–‡æœ¬æ€§è´¨ç»™è‡ªåŠ¨åŒ–åˆ†æé€ æˆäº†é‡å¤§éšœç¢ã€‚æˆ‘ä»¬çš„è®ºæ–‡é€šè¿‡æå‡ºä¸€ä¸ªæ–°å‹çš„å¯é‡å¤ä½¿ç”¨çš„æ¡†æ¶æ¥è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œè¯¥æ¡†æ¶ç”¨äºåœ¨åˆ†ç±»è¿™äº›å¤æ‚çš„å·¥ä¸šè®°å½•çš„ä»»åŠ¡ä¸Šè¯„ä¼°å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ã€‚ä¸ºäº†ä¿ƒè¿›é€æ˜åº¦å’Œé¼“åŠ±è¿›ä¸€æ­¥ç ”ç©¶ï¼Œè¯¥æ¡†æ¶å·²ä½œä¸ºå¼€æºå·¥å…·å…¬å¼€å‘å¸ƒã€‚æˆ‘ä»¬ç³»ç»Ÿåœ°è¯„ä¼°äº†ä¸€ç³»åˆ—æœ€å…ˆè¿›çš„ä¸“æœ‰å’Œå¼€æºLLMï¼Œå¯¹å®ƒä»¬åœ¨å¯é æ€§ã€æ“ä½œæ•ˆç‡å’Œæ¨¡å‹æ ¡å‡†æ–¹é¢çš„ä¼˜ç¼ºç‚¹è¿›è¡Œäº†åŸºç¡€è¯„ä¼°ã€‚æˆ‘ä»¬çš„ç»“æœé‡åŒ–äº†ä¸€ä¸ªæ¸…æ™°çš„æ€§èƒ½å±‚æ¬¡ç»“æ„ï¼Œç¡®å®šäº†ä¸é«˜åŸºå‡†æ ‡å‡†ç›¸ç¬¦ç¨‹åº¦æœ€é«˜çš„æ¨¡å‹ï¼Œä»¥åŠå¯ä¿¡èµ–ã€æ ¡å‡†è‰¯å¥½çš„ç½®ä¿¡åº¦å¾—åˆ†ã€‚æˆ‘ä»¬è¿˜è¯æ˜ï¼Œåˆ†ç±»æ€§èƒ½é«˜åº¦ä¾èµ–äºä»»åŠ¡è¯­ä¹‰æ¨¡ç³Šæ€§ï¼Œæ‰€æœ‰æ¨¡å‹åœ¨å®¢è§‚ç»„ä»¶è¯†åˆ«ä¸Šçš„å…±è¯†é«˜äºè§£é‡Šæ€§ç»´æŠ¤è¡ŒåŠ¨ã€‚é‰´äºæ²¡æœ‰æ¨¡å‹èƒ½è¾¾åˆ°å®Œç¾ç²¾åº¦ï¼Œä¸”æ ¡å‡†å·®å¼‚å¾ˆå¤§ï¼Œæˆ‘ä»¬å¾—å‡ºç»“è®ºï¼Œæœ€æœ‰æ•ˆå’Œè´Ÿè´£ä»»çš„è¿‘æœŸåº”ç”¨æ˜¯â€œäººåœ¨å¾ªç¯ä¸­â€çš„ç³»ç»Ÿï¼ŒLLMä½œä¸ºå¼ºå¤§çš„åŠ©æ‰‹ï¼Œå¯ä»¥åŠ å¿«å¹¶æ ‡å‡†åŒ–äººç±»ä¸“å®¶çš„æ•°æ®æ ‡æ³¨ï¼Œä»è€Œæé«˜Oï¼†Mæ•°æ®è´¨é‡å’Œä¸‹æ¸¸å¯é æ€§åˆ†æã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.06813v1">PDF</a> Associated GitHub repository:   <a target="_blank" rel="noopener" href="https://github.com/mvmalyi/wind-farm-maintenance-logs-labelling-with-llms">https://github.com/mvmalyi/wind-farm-maintenance-logs-labelling-with-llms</a></p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†è¿ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å¯¹é£åŠ›å‘ç”µè®¾å¤‡ç»´æŠ¤æ—¥å¿—è¿›è¡Œåˆ†ç±»çš„æ–°æ¡†æ¶ã€‚è¯¥æ¡†æ¶ä¸ºå…¬å¼€æºä»£ç å·¥å…·ï¼Œæ—¨åœ¨ä¿ƒè¿›é€æ˜åº¦å¹¶é¼“åŠ±è¿›ä¸€æ­¥ç ”ç©¶ã€‚æ–‡ç« è¯„ä¼°äº†å¤šç§æœ€æ–°LLMçš„å¯é æ€§ã€æ“ä½œæ•ˆç‡å’Œæ¨¡å‹æ ¡å‡†æ–¹é¢çš„ä¼˜åŠ£ï¼Œæ˜ç¡®äº†å„æ¨¡å‹ä¹‹é—´çš„æ€§èƒ½å±‚æ¬¡ã€‚ç ”ç©¶ç»“æœè¡¨æ˜ï¼Œåˆ†ç±»æ€§èƒ½é«˜åº¦ä¾èµ–äºä»»åŠ¡çš„è¯­ä¹‰æ¨¡ç³Šæ€§ï¼Œä¸”æ‰€æœ‰æ¨¡å‹åœ¨å®¢è§‚ç»„ä»¶è¯†åˆ«ä¸Šçš„å…±è¯†é«˜äºå¯¹è§£é‡Šæ€§ç»´æŠ¤è¡ŒåŠ¨çš„åˆ†ç±»ã€‚å› æ­¤ï¼Œæ–‡ç« è®¤ä¸ºç›®å‰æœ€æœ‰æ•ˆçš„åº”ç”¨æ˜¯â€œäººåœ¨å¾ªç¯ä¸­â€çš„ç³»ç»Ÿï¼ŒLLMå¯ä½œä¸ºäººç±»ä¸“å®¶çš„å¾—åŠ›åŠ©æ‰‹ï¼ŒåŠ é€Ÿå¹¶æ ‡å‡†åŒ–æ•°æ®æ ‡æ³¨ï¼Œä»è€Œæé«˜æ“ä½œä¸ç»´æŠ¤ï¼ˆO&amp;Mï¼‰æ•°æ®è´¨é‡å’Œåç»­å¯é æ€§åˆ†æã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨é£åŠ›å‘ç”µè®¾å¤‡ç»´æŠ¤æ—¥å¿—åˆ†ç±»ä¸­çš„åº”ç”¨è‡³å…³é‡è¦ï¼Œæœ‰åŠ©äºé™ä½è¿è¡Œç»´æŠ¤æˆæœ¬å¹¶æé«˜èƒ½æºç”Ÿäº§æ•ˆç‡ã€‚</li>
<li>æå‡ºçš„åˆ†ç±»æ¡†æ¶æ˜¯ä¸€ä¸ªå…¬å¼€æºä»£ç å·¥å…·ï¼Œæœ‰åŠ©äºæ¨åŠ¨è‡ªåŠ¨åŒ–åˆ†æçš„é€æ˜åº¦åŠè¿›ä¸€æ­¥ç ”ç©¶ã€‚</li>
<li>ä¸åŒLLMåœ¨å¯é æ€§ã€æ“ä½œæ•ˆç‡å’Œæ¨¡å‹æ ¡å‡†æ–¹é¢çš„è¯„ä¼°ç»“æœå„å¼‚ï¼Œå­˜åœ¨æ˜ç¡®çš„æ€§èƒ½å±‚æ¬¡ã€‚</li>
<li>LLMçš„åˆ†ç±»æ€§èƒ½å—ä»»åŠ¡è¯­ä¹‰æ¨¡ç³Šæ€§å½±å“æ˜¾è‘—ã€‚</li>
<li>æ‰€æœ‰æ¨¡å‹åœ¨å®¢è§‚ç»„ä»¶è¯†åˆ«ä¸Šè¾¾æˆå…±è¯†ï¼Œä½†åœ¨è§£é‡Šæ€§ç»´æŠ¤è¡ŒåŠ¨ä¸Šçš„åˆ†ç±»è¡¨ç°æœ‰æ‰€ä¸è¶³ã€‚</li>
<li>æ²¡æœ‰æ¨¡å‹èƒ½è¾¾åˆ°å®Œç¾å‡†ç¡®ç‡ï¼Œæ¨¡å‹æ ¡å‡†ä¹Ÿå­˜åœ¨æ˜¾è‘—å·®å¼‚ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.06813">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-702bb558d54c36126a765905c1e4a35d.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-c323e17b3e3180b789d10a03add129f4.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="Saturation-Driven-Dataset-Generation-for-LLM-Mathematical-Reasoning-in-the-TPTP-Ecosystem"><a href="#Saturation-Driven-Dataset-Generation-for-LLM-Mathematical-Reasoning-in-the-TPTP-Ecosystem" class="headerlink" title="Saturation-Driven Dataset Generation for LLM Mathematical Reasoning in   the TPTP Ecosystem"></a>Saturation-Driven Dataset Generation for LLM Mathematical Reasoning in   the TPTP Ecosystem</h2><p><strong>Authors:Valentin Quesnel, Damien Sileo</strong></p>
<p>The scarcity of high-quality, logically sound data is a critical bottleneck for advancing the mathematical reasoning of Large Language Models (LLMs). Our work confronts this challenge by turning decades of automated theorem proving research into a scalable data engine. Rather than relying on error-prone LLMs or complex proof-assistant syntax like Lean and Isabelle, our framework leverages E-proverâ€™s saturation capabilities on the vast TPTP axiom library to derive a massive, guaranteed-valid corpus of theorems. Our pipeline is principled and simple: saturate axioms, filter for â€œinterestingâ€ theorems, and generate tasks. With no LLMs in the loop, we eliminate factual errors by construction. This purely symbolic data is then transformed into three difficulty-controlled challenges: entailment verification, premise selection, and proof reconstruction. Our zero-shot experiments on frontier models reveal a clear weakness: performance collapses on tasks requiring deep, structural reasoning. Our framework provides both the diagnostic tool to measure this gap and a scalable source of symbolic training data to address it. We make the code and data publicly available.   <a target="_blank" rel="noopener" href="https://github.com/sileod/reasoning_core">https://github.com/sileod/reasoning_core</a> <a target="_blank" rel="noopener" href="https://hf.co/datasets/reasoning-core/rc1">https://hf.co/datasets/reasoning-core/rc1</a> </p>
<blockquote>
<p>é«˜è´¨é‡ã€é€»è¾‘ä¸¥è°¨çš„æ•°æ®çš„ç¨€ç¼ºæ€§æ˜¯æ¨è¿›å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ•°å­¦æ¨ç†çš„ä¸€ä¸ªå…³é”®ç“¶é¢ˆã€‚æˆ‘ä»¬çš„å·¥ä½œé€šè¿‡æŠŠå‡ åå¹´çš„è‡ªåŠ¨åŒ–å®šç†è¯æ˜ç ”ç©¶è½¬åŒ–ä¸ºå¯æ‰©å±•çš„æ•°æ®å¼•æ“æ¥åº”å¯¹è¿™ä¸€æŒ‘æˆ˜ã€‚æˆ‘ä»¬çš„æ¡†æ¶å¹¶æ²¡æœ‰ä¾èµ–å®¹æ˜“å‡ºé”™çš„LLMæˆ–å¤æ‚çš„è¯æ˜åŠ©æ‰‹è¯­æ³•ï¼ˆå¦‚Leanå’ŒIsabelleï¼‰ï¼Œè€Œæ˜¯åˆ©ç”¨E-proveråœ¨TPTPå…¬ç†åº“ä¸Šçš„é¥±å’Œèƒ½åŠ›ï¼Œæ¨å¯¼å‡ºå¤§é‡ä¿è¯æœ‰æ•ˆçš„å®šç†è¯­æ–™åº“ã€‚æˆ‘ä»¬çš„ç®¡é“æœ‰åŸåˆ™ä¸”ç®€å•ï¼šé¥±å’Œå…¬ç†ï¼Œè¿‡æ»¤å‡ºâ€œæœ‰è¶£â€çš„å®šç†ï¼Œå¹¶ç”Ÿæˆä»»åŠ¡ã€‚æˆ‘ä»¬æ²¡æœ‰ä½¿ç”¨LLMå¾ªç¯ï¼Œå› æ­¤é€šè¿‡æ„å»ºæ¶ˆé™¤äº†äº‹å®é”™è¯¯ã€‚è¿™ç§çº¯ç²¹çš„ç¬¦å·æ•°æ®éšåè¢«è½¬åŒ–ä¸ºä¸‰ç§éš¾åº¦å¯æ§çš„æŒ‘æˆ˜ï¼šè•´å«éªŒè¯ã€å‰æé€‰æ‹©ã€è¯æ˜é‡å»ºã€‚æˆ‘ä»¬åœ¨å‰æ²¿æ¨¡å‹ä¸Šçš„é›¶æ ·æœ¬å®éªŒè¡¨æ˜äº†ä¸€ä¸ªæ˜ç¡®çš„å¼±ç‚¹ï¼šåœ¨é¢å¯¹éœ€è¦æ·±å…¥ã€ç»“æ„æ€§æ¨ç†çš„ä»»åŠ¡æ—¶ï¼Œæ€§èƒ½ä¼šå´©æºƒã€‚æˆ‘ä»¬çš„æ¡†æ¶æ—¢æä¾›äº†è¡¡é‡è¿™ä¸€å·®è·çš„è¯Šæ–­å·¥å…·ï¼Œåˆæä¾›äº†è§£å†³è¿™ä¸€é—®é¢˜çš„å¯æ‰©å±•çš„ç¬¦å·è®­ç»ƒæ•°æ®æ¥æºã€‚æˆ‘ä»¬å…¬å¼€äº†ä»£ç å’Œæ•°æ®ã€‚ <a target="_blank" rel="noopener" href="https://github.com/sileod/reasoning_core">https://github.com/sileod/reasoning_core</a> <a target="_blank" rel="noopener" href="https://hf.co/datasets/reasoning-core/rc1">https://hf.co/datasets/reasoning-core/rc1</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.06809v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºä¸€ä¸ªåˆ©ç”¨å®šç†è¯æ˜å™¨E-proverå’ŒTPTPå…¬ç†åº“æ„å»ºå¤§è§„æ¨¡ã€ä¿è¯æœ‰æ•ˆçš„å®šç†è¯­æ–™åº“çš„æ¡†æ¶ï¼Œè§£å†³äº†é«˜è´¨é‡é€»è¾‘æ•°æ®ç¨€ç¼ºçš„é—®é¢˜ï¼Œä¸ºæ¨è¿›å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„æ•°å­¦æ¨ç†èƒ½åŠ›æä¾›äº†çªç ´ã€‚æ¡†æ¶é‡‡ç”¨ç®€å•åŸåˆ™çš„æ–¹æ³•ï¼Œé€šè¿‡å¯¹å…¬ç†è¿›è¡Œé¥±å’Œå¤„ç†ï¼Œè¿‡æ»¤å‡ºæœ‰è¶£çš„å®šç†å¹¶ç”Ÿæˆä»»åŠ¡ã€‚è¿™ç§æ–¹æ³•æ— éœ€ä¾èµ–å¯èƒ½å‡ºé”™çš„LLMæˆ–å¤æ‚çš„è¯æ˜è¾…åŠ©è¯­æ³•å·¥å…·å¦‚Leanå’ŒIsabelleï¼Œé¿å…äº†ç”±äº‹å®é”™è¯¯é€ æˆçš„é”™è¯¯é£é™©ã€‚ç”Ÿæˆçš„çº¯ç¬¦å·æ•°æ®å¯è½¬åŒ–ä¸ºéš¾åº¦çº§åˆ«ä¸åŒçš„ä¸‰å¤§æŒ‘æˆ˜ä»»åŠ¡ï¼šè•´å«éªŒè¯ã€å‰æé€‰æ‹©å’Œè¯æ˜é‡å»ºã€‚é›¶æ ·æœ¬å®éªŒæ˜¾ç¤ºå‰æ²¿æ¨¡å‹åœ¨éœ€è¦æ·±åº¦ç»“æ„æ¨ç†çš„ä»»åŠ¡ä¸Šè¡¨ç°æ˜æ˜¾ä¸è¶³ï¼Œæœ¬æ–‡æ¡†æ¶ä¸ä»…æä¾›äº†è¡¡é‡è¿™ä¸€å·®è·çš„è¯Šæ–­å·¥å…·ï¼Œè¿˜æä¾›äº†è§£å†³è¿™ä¸€é—®é¢˜çš„å¯æ‰©å±•ç¬¦å·è®­ç»ƒæ•°æ®æ¥æºã€‚ç›¸å…³ä»£ç å’Œæ•°æ®å·²å…¬å¼€ã€‚æ›´å¤šè¯¦æƒ…å‚è§ç›¸å…³ç½‘ç«™é“¾æ¥ï¼š<a target="_blank" rel="noopener" href="https://github.com/sileod/reasoning_core">https://github.com/sileod/reasoning_core</a> å’Œ <a target="_blank" rel="noopener" href="https://hf.co/datasets/reasoning-core/rc1">https://hf.co/datasets/reasoning-core/rc1</a>ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<p>ä»¥ä¸‹æ˜¯åŸºäºæ–‡æœ¬çš„é‡è¦è§‚ç‚¹æ‘˜è¦ï¼š</p>
<ul>
<li>é¢ä¸´é«˜è´¨é‡é€»è¾‘æ•°æ®ç¨€ç¼ºçš„é—®é¢˜ï¼Œå¯¹æ¨è¿›å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„æ•°å­¦æ¨ç†èƒ½åŠ›æ„æˆç“¶é¢ˆã€‚</li>
<li>æå‡ºåˆ©ç”¨å®šç†è¯æ˜å™¨E-proverå’ŒTPTPå…¬ç†åº“æ„å»ºå¤§è§„æ¨¡æœ‰æ•ˆå®šç†è¯­æ–™åº“çš„æ¡†æ¶ã€‚</li>
<li>é‡‡ç”¨ç®€å•åŸåˆ™çš„æ–¹æ³•ï¼Œé€šè¿‡é¥±å’Œå…¬ç†å¤„ç†è¿‡æ»¤å‡ºæœ‰è¶£çš„å®šç†å¹¶ç”Ÿæˆä»»åŠ¡ã€‚è¯¥æ–¹æ³•ä¸æ¶‰åŠå¯èƒ½å‡ºé”™çš„LLMæˆ–å¤æ‚çš„è¯æ˜è¾…åŠ©è¯­æ³•å·¥å…·ï¼Œé™ä½äº†é£é™©ã€‚</li>
<li>å°†ç”Ÿæˆçš„çº¯ç¬¦å·æ•°æ®è½¬åŒ–ä¸ºä¸‰å¤§æŒ‘æˆ˜ä»»åŠ¡ï¼šè•´å«éªŒè¯ã€å‰æé€‰æ‹©å’Œè¯æ˜é‡å»ºï¼Œä»¥é€‚åº”ä¸åŒéš¾åº¦çº§åˆ«ã€‚</li>
<li>é›¶æ ·æœ¬å®éªŒæ­ç¤ºå‰æ²¿æ¨¡å‹åœ¨æ·±åº¦ç»“æ„æ¨ç†ä»»åŠ¡ä¸Šçš„æ˜æ˜¾ä¸è¶³ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.06809">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-62e29e6da5b9b1499dafbf477f3dd980.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-b7ec3470a410d95a6c6abfeba8b4cc93.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-1a384b07bfdcfff40790a303a1bbf387.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-4d1eeb0f0bc50c018a456e5ed79a9bf5.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-7f7edae7b2aa82267b7432c3cb7cfd22.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="MachineLearningLM-Continued-Pretraining-Language-Models-on-Millions-of-Synthetic-Tabular-Prediction-Tasks-Scales-In-Context-ML"><a href="#MachineLearningLM-Continued-Pretraining-Language-Models-on-Millions-of-Synthetic-Tabular-Prediction-Tasks-Scales-In-Context-ML" class="headerlink" title="MachineLearningLM: Continued Pretraining Language Models on Millions of   Synthetic Tabular Prediction Tasks Scales In-Context ML"></a>MachineLearningLM: Continued Pretraining Language Models on Millions of   Synthetic Tabular Prediction Tasks Scales In-Context ML</h2><p><strong>Authors:Haoyu Dong, Pengkun Zhang, Mingzhe Lu, Yanzhen Shen, Guolin Ke</strong></p>
<p>Large language models (LLMs) possess broad world knowledge and strong general-purpose reasoning ability, yet they struggle to learn from many in-context examples on standard machine learning (ML) tasks, that is, to leverage many-shot demonstrations purely via in-context learning (ICL) without gradient descent. We introduce MachineLearningLM, a portable continued-pretraining framework that equips a general-purpose LLM with robust in-context ML capability while preserving its general knowledge and reasoning for broader chat workflows.   Our pretraining procedure synthesizes ML tasks from millions of structural causal models (SCMs), spanning shot counts up to 1,024. We begin with a random-forest teacher, distilling tree-based decision strategies into the LLM to strengthen robustness in numerical modeling. All tasks are serialized with a token-efficient prompt, enabling 3x to 6x more examples per context window and delivering up to 50x amortized throughput via batch inference.   Despite a modest setup (Qwen-2.5-7B-Instruct with LoRA rank 8), MachineLearningLM outperforms strong LLM baselines (e.g., GPT-5-mini) by an average of about 15% on out-of-distribution tabular classification across finance, physics, biology, and healthcare domains. It exhibits a striking many-shot scaling law: accuracy increases monotonically as in-context demonstrations grow from 8 to 1,024. Without any task-specific training, it attains random-forest-level accuracy across hundreds of shots. General chat capabilities, including knowledge and reasoning, are preserved: it achieves 75.4% on MMLU. </p>
<blockquote>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ‹¥æœ‰å¹¿æ³›çš„ä¸–ç•ŒçŸ¥è¯†å’Œå¼ºå¤§çš„é€šç”¨æ¨ç†èƒ½åŠ›ï¼Œä½†åœ¨æ ‡å‡†æœºå™¨å­¦ä¹ ï¼ˆMLï¼‰ä»»åŠ¡ä¸Šï¼Œå®ƒä»¬å¾ˆéš¾ä»å¤šä¸ªä¸Šä¸‹æ–‡ç¤ºä¾‹ä¸­å­¦ä¹ ï¼Œä¹Ÿå°±æ˜¯è¯´ï¼Œå®ƒä»¬æ— æ³•ä»…å‡­ä¸Šä¸‹æ–‡å­¦ä¹ ï¼ˆICLï¼‰æ¥åˆ©ç”¨å¤šä¸ªç¤ºä¾‹ï¼Œè€Œæ— éœ€è¿›è¡Œæ¢¯åº¦ä¸‹é™ã€‚æˆ‘ä»¬å¼•å…¥äº†MachineLearningLMï¼Œè¿™æ˜¯ä¸€ä¸ªä¾¿æºå¼æŒç»­é¢„è®­ç»ƒæ¡†æ¶ï¼Œå®ƒä½¿é€šç”¨LLMå…·å¤‡å¼ºå¤§çš„ä¸Šä¸‹æ–‡MLåŠŸèƒ½ï¼ŒåŒæ—¶ä¿ç•™å…¶ä¸€èˆ¬çŸ¥è¯†å’Œæ¨ç†èƒ½åŠ›ï¼Œä»¥æ”¯æŒæ›´å¹¿æ³›çš„èŠå¤©å·¥ä½œæµç¨‹ã€‚æˆ‘ä»¬çš„é¢„è®­ç»ƒç¨‹åºä»æ•°ç™¾ä¸‡ä¸ªç»“æ„å› æœæ¨¡å‹ï¼ˆSCMï¼‰ä¸­ç»¼åˆMLä»»åŠ¡ï¼Œæ¶µç›–ç¤ºä¾‹æ•°é‡é«˜è¾¾1024ä¸ªã€‚æˆ‘ä»¬ä»¥éšæœºæ£®æ—æ•™å¸ˆå¼€å§‹ï¼Œå°†åŸºäºæ ‘çš„å†³ç­–ç­–ç•¥è’¸é¦åˆ°LLMä¸­ï¼Œä»¥åŠ å¼ºæ•°å€¼å»ºæ¨¡ä¸­çš„ç¨³å¥æ€§ã€‚æ‰€æœ‰ä»»åŠ¡éƒ½é€šè¿‡é«˜æ•ˆçš„æ ‡è®°æç¤ºç¬¦è¿›è¡Œåºåˆ—åŒ–ï¼Œä½¿æ¯ä¸ªä¸Šä¸‹æ–‡çª—å£èƒ½å¤Ÿå¢åŠ 3å€è‡³6å€çš„ç¤ºä¾‹æ•°é‡ï¼Œå¹¶é€šè¿‡æ‰¹é‡æ¨ç†å®ç°é«˜è¾¾50å€çš„æ‘Šé”€ååé‡ã€‚å°½ç®¡ä½¿ç”¨äº†é€‚åº¦çš„è®¾ç½®ï¼ˆä½¿ç”¨LoRAç­‰çº§8çš„Qwen-2.5-7B-Instructï¼‰ï¼Œä½†MachineLearningLMåœ¨é‡‘èã€ç‰©ç†ã€ç”Ÿç‰©å’ŒåŒ»ç–—ä¿å¥é¢†åŸŸçš„ç¦»åˆ†å¸ƒè¡¨æ ¼åˆ†ç±»ä»»åŠ¡ä¸Šï¼Œå¹³å‡æ¯”å¼ºå¤§çš„LLMåŸºçº¿ï¼ˆä¾‹å¦‚GPT-5-miniï¼‰é«˜å‡ºçº¦15%çš„å‡†ç¡®ç‡ã€‚å®ƒè¡¨ç°å‡ºå¼•äººæ³¨ç›®çš„å¤šç¤ºä¾‹æ‰©å±•å®šå¾‹ï¼šéšç€ä¸Šä¸‹æ–‡ç¤ºä¾‹ä»8ä¸ªå¢åŠ åˆ°1024ä¸ªï¼Œå‡†ç¡®æ€§å•è°ƒå¢åŠ ã€‚æ— éœ€ä»»ä½•ç‰¹å®šä»»åŠ¡çš„è®­ç»ƒï¼Œå®ƒå°±èƒ½åœ¨å„ç§åœºæ™¯ä¸‹è¾¾åˆ°éšæœºæ£®æ—çº§åˆ«çš„å‡†ç¡®æ€§ã€‚åŒæ—¶ä¿ç•™äº†ä¸€èˆ¬èŠå¤©åŠŸèƒ½ï¼ŒåŒ…æ‹¬çŸ¥è¯†å’Œæ¨ç†èƒ½åŠ›ï¼šå®ƒåœ¨MMLUä¸Šè¾¾åˆ°äº†75.4%çš„å‡†ç¡®ç‡ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.06806v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ‹¥æœ‰å¹¿æ³›çš„çŸ¥è¯†å’Œå¼ºå¤§çš„é€šç”¨æ¨ç†èƒ½åŠ›ï¼Œä½†åœ¨æ ‡å‡†æœºå™¨å­¦ä¹ ï¼ˆMLï¼‰ä»»åŠ¡ä¸Šéš¾ä»¥ä»å¤šä¸ªä¸Šä¸‹æ–‡ç¤ºä¾‹ä¸­å­¦ä¹ ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬æ¨å‡ºäº†MachineLearningLMï¼Œè¿™æ˜¯ä¸€ä¸ªä¾¿æºçš„æŒç»­é¢„è®­ç»ƒæ¡†æ¶ï¼Œæ—¨åœ¨èµ‹äºˆé€šç”¨LLMå¼ºå¤§çš„ä¸Šä¸‹æ–‡MLèƒ½åŠ›ï¼ŒåŒæ—¶ä¿ç•™å…¶ä¸€èˆ¬çŸ¥è¯†å’Œæ¨ç†èƒ½åŠ›ï¼Œä»¥åº”å¯¹æ›´å¹¿æ³›çš„èŠå¤©å·¥ä½œæµç¨‹ã€‚æˆ‘ä»¬çš„é¢„è®­ç»ƒç¨‹åºé€šè¿‡åˆæˆæ¥è‡ªæ•°ç™¾ä¸‡ç»“æ„å› æœæ¨¡å‹ï¼ˆSCMï¼‰çš„MLä»»åŠ¡æ¥å¼ºåŒ–LLMçš„æ•°å€¼å»ºæ¨¡èƒ½åŠ›ï¼Œå¹¶å¢å¼ºäº†å…¶åœ¨ä¸åŒé¢†åŸŸä¸­çš„è¡¨ç°ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>LLMsè™½å…·æœ‰å¹¿æ³›çŸ¥è¯†å’Œæ¨ç†èƒ½åŠ›ï¼Œä½†åœ¨æ ‡å‡†MLä»»åŠ¡ä¸Šéš¾ä»¥ä»å¤šä¸ªä¸Šä¸‹æ–‡ç¤ºä¾‹ä¸­å­¦ä¹ ã€‚</li>
<li>MachineLearningLMæ¡†æ¶æ—¨åœ¨å¢å¼ºLLMçš„ä¸Šä¸‹æ–‡MLèƒ½åŠ›ï¼ŒåŒæ—¶ä¿ç•™å…¶ä¸€èˆ¬çŸ¥è¯†å’Œæ¨ç†èƒ½åŠ›ã€‚</li>
<li>é¢„è®­ç»ƒç¨‹åºé€šè¿‡åˆæˆæ¥è‡ªæ•°ç™¾ä¸‡ç»“æ„å› æœæ¨¡å‹ï¼ˆSCMï¼‰çš„MLä»»åŠ¡æ¥å¼ºåŒ–LLMçš„æ•°å€¼å»ºæ¨¡èƒ½åŠ›ã€‚</li>
<li>ä½¿ç”¨éšæœºæ£®æ—æ•™å¸ˆæ¥æç‚¼æ ‘å½¢å†³ç­–ç­–ç•¥ï¼Œå¢å¼ºLLMåœ¨æ•°å€¼å»ºæ¨¡ä¸­çš„ç¨³å¥æ€§ã€‚</li>
<li>é€šè¿‡åºåˆ—åŒ–ä»»åŠ¡å¹¶ä½¿ç”¨é«˜æ•ˆçš„æç¤ºï¼Œä½¿LLMèƒ½å¤Ÿåœ¨æ¯ä¸ªä¸Šä¸‹æ–‡çª—å£ä¸­å¤„ç†æ›´å¤šçš„ç¤ºä¾‹ï¼Œå¹¶é€šè¿‡æ‰¹é‡æ¨ç†å®ç°æ›´é«˜çš„ååé‡ã€‚</li>
<li>MachineLearningLMåœ¨å¤šä¸ªé¢†åŸŸï¼ˆå¦‚é‡‘èã€ç‰©ç†ã€ç”Ÿç‰©å’ŒåŒ»ç–—ä¿å¥ï¼‰çš„åˆ†ç±»ä»»åŠ¡ä¸Šï¼Œç›¸å¯¹äºGPT-5-miniç­‰å¼ºå¤§LLMåŸºå‡†æµ‹è¯•ï¼Œå¹³å‡æé«˜äº†çº¦15%çš„å‡†ç¡®ç‡ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.06806">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-c0d3e774d1daf77e78b5dc416047994d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-3408f1539e266d9d6f4ee243a0002b2b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-013fc1315736669373007096ac3902f8.jpg" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="Another-Turn-Better-Output-A-Turn-Wise-Analysis-of-Iterative-LLM-Prompting"><a href="#Another-Turn-Better-Output-A-Turn-Wise-Analysis-of-Iterative-LLM-Prompting" class="headerlink" title="Another Turn, Better Output? A Turn-Wise Analysis of Iterative LLM   Prompting"></a>Another Turn, Better Output? A Turn-Wise Analysis of Iterative LLM   Prompting</h2><p><strong>Authors:Shashidhar Reddy Javaji, Bhavul Gauri, Zining Zhu</strong></p>
<p>Large language models (LLMs) are now used in multi-turn workflows, but we still lack a clear way to measure when iteration helps and when it hurts. We present an evaluation framework for iterative refinement that spans ideation, code, and math. Our protocol runs controlled 12-turn conversations per task, utilizing a variety of prompts ranging from vague &#96;&#96;improve itâ€™â€™ feedback to targeted steering, and logs per-turn outputs. We score outcomes with domain-appropriate checks (unit tests for code; answer-equivalence plus reasoning-soundness for math; originality and feasibility for ideation) and track turn-level behavior with three families of metrics: semantic movement across turns, turn-to-turn change, and output size growth. Across models and tasks, gains are domain-dependent: they arrive early in ideas and code, but in math late turns matter when guided by elaboration. After the first few turns, vague feedback often plateaus or reverses correctness, while targeted prompts reliably shift the intended quality axis (novelty vs. feasibility in ideation; speed vs. readability in code; in math, elaboration outperforms exploration and drives late-turn gains). We also observe consistent domain patterns: ideation moves more in meaning across turns, code tends to grow in size with little semantic change, and math starts fixed but can break that path with late, elaborative iteration.Together, the framework and metrics make iteration measurable and comparable across models, and signal when to steer, stop, or switch strategies. </p>
<blockquote>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ç°åœ¨å·²åº”ç”¨äºå¤šè½®å·¥ä½œæµç¨‹ä¸­ï¼Œä½†æˆ‘ä»¬ä»ç¼ºä¹æ˜ç¡®çš„è¡¡é‡æ–¹æ³•æ¥åˆ¤æ–­è¿­ä»£åœ¨ä½•æ—¶æœ‰å¸®åŠ©ï¼Œä½•æ—¶ä¼šäº§ç”Ÿè´Ÿé¢å½±å“ã€‚æˆ‘ä»¬æå‡ºä¸€ä¸ªè¯„ä¼°è¿­ä»£ä¼˜åŒ–çš„æ¡†æ¶ï¼Œè¯¥æ¡†æ¶æ¶µç›–æ„æ€ã€ç¼–ç å’Œæ•°å­¦ã€‚æˆ‘ä»¬çš„åè®®é’ˆå¯¹æ¯ä¸ªä»»åŠ¡è¿è¡Œå—æ§çš„12è½®å¯¹è¯ï¼Œä½¿ç”¨å„ç§æç¤ºï¼Œä»æ¨¡ç³Šçš„â€œæ”¹è¿›å®ƒâ€åé¦ˆåˆ°æœ‰é’ˆå¯¹æ€§çš„æŒ‡å¯¼ï¼Œå¹¶è®°å½•æ¯è½®çš„è¾“å²€ã€‚æˆ‘ä»¬ä½¿ç”¨é€‚åˆé¢†åŸŸçš„æ£€æŸ¥æ¥è¯„åˆ†ç»“æœï¼ˆä»£ç ä¸­çš„å•å…ƒæµ‹è¯•ï¼›æ•°å­¦ä¸­çš„ç­”æ¡ˆç­‰ä»·æ€§åŠ ä¸Šæ¨ç†åˆç†æ€§ï¼›æ„æ€ä¸­çš„åŸåˆ›æ€§å’Œå¯è¡Œæ€§ï¼‰ï¼Œå¹¶é€šè¿‡ä¸‰ä¸ªå®¶æ—çš„æŒ‡æ ‡æ¥è·Ÿè¸ªè½®æ¬¡çº§åˆ«çš„è¡Œä¸ºï¼šå„è½®ä¹‹é—´çš„è¯­ä¹‰å˜åŒ–ã€è½®æ¬¡ä¹‹é—´çš„å˜åŒ–ä»¥åŠè¾“å‡ºå¤§å°çš„å¢é•¿ã€‚åœ¨ä¸åŒçš„æ¨¡å‹å’Œä»»åŠ¡ä¸­ï¼Œæ”¶ç›Šæ˜¯é¢†åŸŸä¾èµ–çš„ï¼šå®ƒä»¬åœ¨æƒ³æ³•å’Œä»£ç ä¸­æ—©æ—©åœ°åˆ°è¾¾ï¼Œä½†åœ¨æ•°å­¦ä¸­ï¼ŒåæœŸè½®æ¬¡åœ¨æŒ‡å¯¼ä¸‹çš„ç»†åŒ–å¾ˆé‡è¦ã€‚ç»è¿‡å‰å‡ è½®åï¼Œæ¨¡ç³Šçš„åé¦ˆé€šå¸¸ä¼šè¾¾åˆ°å¹³å°æœŸæˆ–ä½¿æ­£ç¡®æ€§é€†è½¬ï¼Œè€Œæœ‰é’ˆå¯¹æ€§çš„æç¤ºä¼šå¯é åœ°æ”¹å˜é¢„æœŸçš„è´¨é‡è½´ï¼ˆæ„æ€ä¸­çš„æ–°é¢–æ€§å¯¹æ¯”å¯è¡Œæ€§ï¼›ç¼–ç ä¸­çš„é€Ÿåº¦å¯¹æ¯”å¯è¯»æ€§ï¼›åœ¨æ•°å­¦ä¸­ï¼Œç»†åŒ–è¡¨ç°ä¼˜äºæ¢ç´¢å¹¶æ¨åŠ¨åæœŸçš„æ”¶ç›Šï¼‰ã€‚æˆ‘ä»¬è¿˜è§‚å¯Ÿåˆ°ä¸€è‡´é¢†åŸŸæ¨¡å¼ï¼šåœ¨æ„æ€ä¸­ï¼Œå„è½®ä¹‹é—´çš„æ„ä¹‰å˜åŒ–æ›´å¤§ï¼›ä»£ç å¾€å¾€å¤§å°å¢é•¿è€Œè¯­ä¹‰å˜åŒ–å¾ˆå°ï¼›æ•°å­¦å¼€å§‹æ—¶æ˜¯å›ºå®šçš„ï¼Œä½†å¯ä»¥é€šè¿‡åæœŸçš„ç»†åŒ–è¿­ä»£æ¥æ‰“ç ´è¿™ä¸€è·¯å¾„ã€‚æ€»ä¹‹ï¼Œæ¡†æ¶å’ŒæŒ‡æ ‡ä½¿è¿­ä»£å¯ä»¥åœ¨æ¨¡å‹ä¹‹é—´è¿›è¡Œæ¯”è¾ƒå’Œè¡¡é‡ï¼Œå¹¶æŒ‡ç¤ºä½•æ—¶éœ€è¦è°ƒæ•´æ–¹å‘ã€åœæ­¢æˆ–æ”¹å˜ç­–ç•¥ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.06770v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨å¤šè½®å¯¹è¯å·¥ä½œæµä¸­å¾—åˆ°äº†å¹¿æ³›åº”ç”¨ï¼Œä½†ç¼ºä¹å¯¹è¿­ä»£æ˜¯å¦æœ‰æ•ˆçš„æ˜ç¡®è¡¡é‡æ–¹å¼ã€‚æœ¬æ–‡æå‡ºä¸€ä¸ªè¯„ä¼°è¿­ä»£ä¼˜åŒ–æ•ˆæœçš„æ¡†æ¶ï¼Œæ¶µç›–åˆ›æ„ã€ä»£ç å’Œæ•°å­¦é¢†åŸŸã€‚é€šè¿‡æ§åˆ¶æ¯ä»»åŠ¡12è½®å¯¹è¯çš„å®éªŒæµç¨‹ï¼Œä½¿ç”¨å„ç§æç¤ºæ¥å¼•å¯¼ï¼Œå¹¶è®°å½•æ¯è½®çš„è¾“å‡ºæ¥è¯„ä¼°æ•ˆæœã€‚ç»“æœæ˜¾ç¤ºï¼Œåœ¨ä¸åŒé¢†åŸŸå’Œä»»åŠ¡ä¸­ï¼Œè¿­ä»£çš„å¢ç›Šå…·æœ‰ä¾èµ–æ€§ï¼šåœ¨åˆ›æ„å’Œä»£ç æ–¹é¢ï¼Œæ—©æœŸè¿­ä»£æ•ˆæœæ˜æ˜¾ï¼›åœ¨æ•°å­¦æ–¹é¢ï¼Œåˆ™éœ€è¦æ›´å¤šçš„è¿­ä»£ã€‚æ­¤å¤–ï¼Œè¿˜è§‚å¯Ÿåˆ°å„é¢†åŸŸçš„ä¸€è‡´æ€§æ¨¡å¼ï¼šåˆ›æ„æ–¹é¢çš„è¿­ä»£æ›´å¤šä½“ç°åœ¨æ„ä¹‰çš„å˜åŒ–ä¸Šï¼Œä»£ç å€¾å‘äºå¤§å°å¢é•¿è€Œè¯­ä¹‰å˜åŒ–è¾ƒå°ï¼Œæ•°å­¦åˆ™å¼€å§‹ç¨³å®šä½†åæ¥é€šè¿‡æ·±å…¥è¿­ä»£è·å¾—æå‡ã€‚æ€»ä¹‹ï¼Œè¯¥æ¡†æ¶å’ŒæŒ‡æ ‡ä½¿è¿­ä»£æ•ˆæœå¯è¡¡é‡å’Œæ¯”è¾ƒï¼Œå¹¶èƒ½æŒ‡å¯¼ä½•æ—¶éœ€è¦è°ƒæ•´ç­–ç•¥ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨å¤šè½®å¯¹è¯å·¥ä½œæµä¸­å¹¿æ³›åº”ç”¨ï¼Œä½†è¿­ä»£ä¼˜åŒ–çš„è¡¡é‡æ–¹å¼å°šä¸æ¸…æ¥šã€‚</li>
<li>æå‡ºçš„è¯„ä¼°æ¡†æ¶å¯ç”¨äºè¡¡é‡è¿­ä»£ä¼˜åŒ–åœ¨åˆ›æ„ã€ä»£ç å’Œæ•°å­¦é¢†åŸŸçš„æ•ˆæœã€‚</li>
<li>æ§åˆ¶æ¯ä»»åŠ¡12è½®å¯¹è¯çš„å®éªŒæµç¨‹ï¼Œä½¿ç”¨ä¸åŒæç¤ºæ¥å¼•å¯¼å¯¹è¯ã€‚</li>
<li>è¿­ä»£å¢ç›Šå…·æœ‰é¢†åŸŸä¾èµ–æ€§ï¼šåœ¨åˆ›æ„å’Œä»£ç æ–¹é¢ï¼Œæ—©æœŸè¿­ä»£æ•ˆæœæ˜¾ç€ï¼›æ•°å­¦æ–¹é¢åˆ™éœ€è¦æ›´å¤šæ·±å…¥è¿­ä»£ã€‚</li>
<li>åˆ›æ„æ–¹é¢çš„è¿­ä»£æ›´å¤šä½“ç°åœ¨æ„ä¹‰çš„å˜åŒ–ä¸Šï¼Œä»£ç å¤§å°å¢é•¿è€Œè¯­ä¹‰å˜åŒ–è¾ƒå°ï¼Œæ•°å­¦é¢†åŸŸå¼€å§‹ç¨³å®šä½†åæ¥é€šè¿‡æ·±å…¥è¿­ä»£è·å¾—æå‡ã€‚</li>
<li>æ¡†æ¶å’ŒæŒ‡æ ‡ä½¿è¿­ä»£æ•ˆæœå¯è¡¡é‡å’Œæ¯”è¾ƒï¼Œæœ‰åŠ©äºåˆ¤æ–­ä½•æ—¶éœ€è¦è°ƒæ•´ç­–ç•¥ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.06770">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-62a6160d1017ed0cdb87a5ad260a481e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e8b338c2aaaed69f661fa67192e0d4a1.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-8ffdb59e62953676c322e137f9b79963.jpg" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1><h2 id="SFR-DeepResearch-Towards-Effective-Reinforcement-Learning-for-Autonomously-Reasoning-Single-Agents"><a href="#SFR-DeepResearch-Towards-Effective-Reinforcement-Learning-for-Autonomously-Reasoning-Single-Agents" class="headerlink" title="SFR-DeepResearch: Towards Effective Reinforcement Learning for   Autonomously Reasoning Single Agents"></a>SFR-DeepResearch: Towards Effective Reinforcement Learning for   Autonomously Reasoning Single Agents</h2><p><strong>Authors:Xuan-Phi Nguyen, Shrey Pandit, Revanth Gangi Reddy, Austin Xu, Silvio Savarese, Caiming Xiong, Shafiq Joty</strong></p>
<p>Equipping large language models (LLMs) with complex, interleaved reasoning and tool-use capabilities has become a key focus in agentic AI research, especially with recent advances in reasoning-oriented (&#96;&#96;thinkingâ€™â€™) models. Such capabilities are key to unlocking a number of important applications. One such application is Deep Research (DR), which requires extensive search and reasoning over many sources. Our work in this paper focuses on the development of native Autonomous Single-Agent models for DR featuring minimal web crawling and Python tool integration. Unlike multi-agent systems, where agents take up pre-defined roles and are told what to do at each step in a static workflow, an autonomous single-agent determines its next action dynamically based on context, without manual directive. While prior work has proposed training recipes for base or instruction-tuned LLMs, we focus on continual reinforcement learning (RL) of reasoning-optimized models to further enhance agentic skills while preserving reasoning ability. Towards this end, we propose a simple RL recipe with entirely synthetic data, which we apply to various open-source LLMs. Our best variant SFR-DR-20B achieves up to 28.7% on Humanityâ€™s Last Exam benchmark. In addition, we conduct key analysis experiments to provide more insights into our methodologies. </p>
<blockquote>
<p>ä¸ºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰é…å¤‡å¤æ‚ã€äº¤ç»‡çš„æ¨ç†å’Œå·¥å…·ä½¿ç”¨èƒ½åŠ›å·²æˆä¸ºä»£ç†äººå·¥æ™ºèƒ½ç ”ç©¶çš„å…³é”®ç„¦ç‚¹ï¼Œå°¤å…¶æ˜¯æœ€è¿‘åŸºäºæ¨ç†å¯¼å‘ï¼ˆâ€œæ€è€ƒâ€ï¼‰æ¨¡å‹çš„è¿›æ­¥ã€‚è¿™äº›èƒ½åŠ›æ˜¯è§£é”è®¸å¤šé‡è¦åº”ç”¨çš„å…³é”®ã€‚å…¶ä¸­ä¸€ä¸ªåº”ç”¨æ˜¯æ·±åº¦ç ”ç©¶ï¼ˆDRï¼‰ï¼Œå®ƒéœ€è¦åœ¨å¤šä¸ªæ¥æºä¹‹é—´è¿›è¡Œå¹¿æ³›æœç´¢å’Œæ¨ç†ã€‚æœ¬æ–‡çš„å·¥ä½œé‡ç‚¹æ˜¯ä¸ºDRå¼€å‘æœ¬åœ°è‡ªä¸»å•ä»£ç†æ¨¡å‹ï¼Œå…·æœ‰æœ€å°‘çš„ç½‘ç»œçˆ¬è™«å’ŒPythonå·¥å…·é›†æˆã€‚ä¸åŒäºå¤šä»£ç†ç³»ç»Ÿï¼Œå…¶ä¸­ä»£ç†æ‰¿æ‹…é¢„å®šä¹‰è§’è‰²ï¼Œå¹¶åœ¨é™æ€å·¥ä½œæµä¸­çš„æ¯ä¸€æ­¥è¢«å‘ŠçŸ¥è¦åšä»€ä¹ˆï¼Œè‡ªä¸»å•ä»£ç†ä¼šæ ¹æ®ä¸Šä¸‹æ–‡åŠ¨æ€åœ°ç¡®å®šå…¶ä¸‹ä¸€æ­¥è¡ŒåŠ¨ï¼Œæ— éœ€æ‰‹åŠ¨æŒ‡ä»¤ã€‚è™½ç„¶å…ˆå‰çš„å·¥ä½œå·²ç»æå‡ºäº†é’ˆå¯¹åŸºç¡€æˆ–æŒ‡ä»¤å¾®è°ƒLLMçš„è®­ç»ƒé…æ–¹ï¼Œä½†æˆ‘ä»¬ä¸“æ³¨äºå¯¹æ¨ç†ä¼˜åŒ–æ¨¡å‹çš„æŒç»­å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰ï¼Œä»¥è¿›ä¸€æ­¥å¢å¼ºä»£ç†æŠ€èƒ½ï¼ŒåŒæ—¶ä¿ç•™æ¨ç†èƒ½åŠ›ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªä½¿ç”¨å®Œå…¨åˆæˆæ•°æ®çš„ç®€å•RLé…æ–¹ï¼Œå¯åº”ç”¨äºå„ç§å¼€æºLLMã€‚æˆ‘ä»¬æœ€å¥½çš„å˜ä½“SFR-DR-20Båœ¨äººç±»æœ€åçš„è€ƒè¯•åŸºå‡†æµ‹è¯•ä¸­è¾¾åˆ°äº†28.7%ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜è¿›è¡Œäº†å…³é”®çš„åˆ†æå®éªŒï¼Œä»¥æ›´æ·±å…¥åœ°äº†è§£æˆ‘ä»¬çš„æ–¹æ³•ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.06283v1">PDF</a> Technical Report</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡å…³æ³¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨æ·±åº¦ç ”ç©¶ï¼ˆDRï¼‰ä¸­çš„åº”ç”¨ï¼Œå¼ºè°ƒè‡ªä¸»å•ä¸€ä»£ç†æ¨¡å‹çš„å‘å±•ï¼Œè¯¥æ¨¡å‹å…·å¤‡åŠ¨æ€å†³ç­–èƒ½åŠ›ï¼Œæ— éœ€æ‰‹åŠ¨æŒ‡å¯¼ã€‚ç ”ç©¶å›¢é˜Ÿé€šè¿‡æŒç»­å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰æå‡æ¨¡å‹çš„æ¨ç†èƒ½åŠ›ï¼Œå¹¶æ¨å‡ºé€‚ç”¨äºå¼€æºLLMçš„ç®€æ˜“RLé…æ–¹ã€‚å…¶ä¸­ï¼ŒSFR-DR-20Bæ¨¡å‹åœ¨Humanityâ€™s Last ExamåŸºå‡†æµ‹è¯•ä¸­è¡¨ç°ä¼˜ç§€ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ­£åœ¨è¢«èµ‹äºˆæ›´å¤æ‚çš„æ¨ç†å’Œå·¥å…·ä½¿ç”¨èƒ½åŠ›ï¼Œæˆä¸ºæ™ºèƒ½ä½“AIç ”ç©¶çš„å…³é”®ç„¦ç‚¹ã€‚</li>
<li>è‡ªä¸»å•ä¸€ä»£ç†æ¨¡å‹åœ¨æ·±åº¦ç ”ç©¶ï¼ˆDRï¼‰ä¸­è¡¨ç°çªå‡ºï¼Œå…·å¤‡åŠ¨æ€å†³ç­–èƒ½åŠ›ï¼Œæ— éœ€é¢„è®¾è§’è‰²å’Œé™æ€å·¥ä½œæµç¨‹ã€‚</li>
<li>æŒç»­çš„å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰ç”¨äºæå‡LLMçš„æ¨ç†èƒ½åŠ›ï¼ŒåŒæ—¶ä¿æŒå…¶åŸæœ‰çš„æ¨ç†æŠ€èƒ½ã€‚</li>
<li>ç ”ç©¶å›¢é˜Ÿæ¨å‡ºäº†ä¸€ä¸ªç®€æ˜“çš„RLé…æ–¹ï¼Œé€‚ç”¨äºå„ç§å¼€æºLLMã€‚</li>
<li>SFR-DR-20Bæ¨¡å‹åœ¨Humanityâ€™s Last ExamåŸºå‡†æµ‹è¯•ä¸­è¡¨ç°å“è¶Šï¼Œè¾¾åˆ°äº†28.7%çš„æ•ˆæœã€‚</li>
<li>ç ”ç©¶å›¢é˜Ÿè¿˜è¿›è¡Œäº†å…³é”®çš„åˆ†æå®éªŒï¼Œä»¥æ·±å…¥äº†è§£å…¶æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.06283">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-3286312ad1f0e5fe82d0c2b56d68d124.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-762a81b044fa30a731e76b1e1c36c50e.jpg" align="middle">
</details>


<h1 id="-9"><a href="#-9" class="headerlink" title=""></a></h1><h2 id="Code2MCP-A-Multi-Agent-Framework-for-Automated-Transformation-of-Code-Repositories-into-Model-Context-Protocol-Services"><a href="#Code2MCP-A-Multi-Agent-Framework-for-Automated-Transformation-of-Code-Repositories-into-Model-Context-Protocol-Services" class="headerlink" title="Code2MCP: A Multi-Agent Framework for Automated Transformation of Code   Repositories into Model Context Protocol Services"></a>Code2MCP: A Multi-Agent Framework for Automated Transformation of Code   Repositories into Model Context Protocol Services</h2><p><strong>Authors:Chaoqian Ouyang, Ling Yue, Shimin Di, Libin Zheng, Shaowu Pan, Min-Ling Zhang</strong></p>
<p>The proliferation of Large Language Models (LLMs) has created a significant integration challenge in the AI agent ecosystem, often called the â€œ$N \times M$ problem,â€ where N models require custom integrations for M tools. This fragmentation stifles innovation and creates substantial development overhead. While the Model Context Protocol (MCP) has emerged as a standard to resolve this, its adoption is hindered by the manual effort required to convert the vast universe of existing software into MCP-compliant services. This is especially true for the millions of open-source repositories on GitHub, the worldâ€™s largest collection of functional code. This paper introduces Code2MCP, a highly automated, agentic framework designed to transform any GitHub repository into a functional MCP service with minimal human intervention. Our system employs a multi-stage workflow that automates the entire process, from code analysis and environment configuration to service generation and deployment. A key innovation of our framework is an LLM-driven, closed-loop â€œRunâ€“Reviewâ€“Fixâ€ cycle, which enables the system to autonomously debug and repair the code it generates. Code2MCP produces not only deployable services but also comprehensive technical documentation, acting as a catalyst to accelerate the MCP ecosystem by systematically unlocking the worldâ€™s largest open-source code repository and automating the critical last mile of tool integration. The code is open-sourced at <a target="_blank" rel="noopener" href="https://github.com/DEFENSE-SEU/MCP-Github-Agent">https://github.com/DEFENSE-SEU/MCP-Github-Agent</a>. </p>
<blockquote>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„æ™®åŠç»™äººå·¥æ™ºèƒ½ä»£ç†ç”Ÿæ€ç³»ç»Ÿå¸¦æ¥äº†é‡å¤§çš„é›†æˆæŒ‘æˆ˜ï¼Œé€šå¸¸è¢«ç§°ä¸ºâ€$N Ã— M$é—®é¢˜â€ï¼Œå…¶ä¸­Nä¸ªæ¨¡å‹éœ€è¦ä¸ºMä¸ªå·¥å…·è¿›è¡Œè‡ªå®šä¹‰é›†æˆã€‚è¿™ç§ç¢ç‰‡åŒ–é˜»ç¢äº†åˆ›æ–°ï¼Œå¹¶äº§ç”Ÿäº†å¤§é‡å¼€å‘é¢å¤–è´Ÿæ‹…ã€‚è™½ç„¶æ¨¡å‹ä¸Šä¸‹æ–‡åè®®ï¼ˆMCPï¼‰å·²ä½œä¸ºè§£å†³æ­¤é—®é¢˜çš„æ ‡å‡†è€Œå‡ºç°ï¼Œä½†å…¶é‡‡ç”¨å—åˆ°äº†å°†ç°æœ‰å¤§é‡è½¯ä»¶è½¬æ¢ä¸ºç¬¦åˆMCPçš„æœåŠ¡æ‰€éœ€çš„äººå·¥åŠªåŠ›çš„é˜»ç¢ã€‚è¿™åœ¨GitHubä¸Šçš„æ•°ç™¾ä¸‡ä¸ªå¼€æºå­˜å‚¨åº“ä¸­å°¤å…¶å¦‚æ­¤ï¼ŒGitHubæ˜¯ä¸–ç•Œä¸ŠåŠŸèƒ½ä»£ç çš„æœ€å¤§é›†åˆã€‚æœ¬æ–‡ä»‹ç»äº†Code2MCPï¼Œè¿™æ˜¯ä¸€ä¸ªé«˜åº¦è‡ªåŠ¨åŒ–çš„ä»£ç†æ¡†æ¶ï¼Œæ—¨åœ¨å°†ä»»ä½•GitHubä»“åº“è½¬æ¢ä¸ºåŠŸèƒ½æ€§çš„MCPæœåŠ¡ï¼Œå¹¶å°½é‡å‡å°‘äººå·¥å¹²é¢„ã€‚æˆ‘ä»¬çš„ç³»ç»Ÿé‡‡ç”¨å¤šé˜¶æ®µå·¥ä½œæµç¨‹ï¼Œè‡ªåŠ¨åŒ–äº†æ•´ä¸ªè¿‡ç¨‹ï¼Œä»ä»£ç åˆ†æã€ç¯å¢ƒé…ç½®åˆ°æœåŠ¡ç”Ÿæˆå’Œéƒ¨ç½²ã€‚æˆ‘ä»¬æ¡†æ¶çš„ä¸€ä¸ªå…³é”®åˆ›æ–°æ˜¯ç”±å¤§å‹è¯­è¨€æ¨¡å‹é©±åŠ¨çš„é—­ç¯â€œè¿è¡Œ-å®¡æŸ¥-ä¿®å¤â€å¾ªç¯ï¼Œä½¿ç³»ç»Ÿèƒ½å¤Ÿè‡ªä¸»è°ƒè¯•å’Œä¿®å¤å…¶ç”Ÿæˆçš„ä»£ç ã€‚Code2MCPä¸ä»…ç”Ÿæˆå¯éƒ¨ç½²çš„æœåŠ¡ï¼Œè¿˜ç”Ÿæˆå…¨é¢çš„æŠ€æœ¯æ–‡æ¡£ï¼Œé€šè¿‡ç³»ç»Ÿåœ°è§£é”ä¸–ç•Œä¸Šæœ€å¤§çš„å¼€æºä»£ç åº“å¹¶è‡ªåŠ¨æ‰§è¡Œå·¥å…·é›†æˆçš„å…³é”®æœ€åä¸€è‹±é‡Œï¼Œä»è€ŒåŠ é€ŸMCPç”Ÿæ€ç³»ç»Ÿçš„å‘å±•ã€‚ä»£ç å·²å…¬å¼€åœ¨<a target="_blank" rel="noopener" href="https://github.com/DEFENSE-SEU/MCP-Github-Agent%E3%80%82">https://github.com/DEFENSE-SEU/MCP-Github-Agentã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.05941v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>å¤§è§„æ¨¡è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„æ™®åŠç»™äººå·¥æ™ºèƒ½ä»£ç†ç”Ÿæ€ç³»ç»Ÿå¸¦æ¥äº†æ˜¾è‘—çš„é›†æˆæŒ‘æˆ˜ï¼Œè¿™é€šå¸¸è¢«ç§°ä¸ºâ€œ$N \times M$ é—®é¢˜â€ï¼Œå³Nä¸ªæ¨¡å‹éœ€è¦ä¸ºMä¸ªå·¥å…·è¿›è¡Œè‡ªå®šä¹‰é›†æˆã€‚è¿™ä¸€é—®é¢˜é€ æˆäº†ç¢ç‰‡åŒ–çš„å±€é¢ï¼Œé˜»ç¢äº†åˆ›æ–°å¹¶å¢åŠ äº†å¼€å‘æˆæœ¬ã€‚è™½ç„¶æ¨¡å‹ä¸Šä¸‹æ–‡åè®®ï¼ˆMCPï¼‰å·²å‡ºç°ä¸ºè§£å†³æ­¤é—®é¢˜ï¼Œä½†ç”±äºéœ€è¦å°†å¤§é‡ç°æœ‰è½¯ä»¶è½¬æ¢ä¸ºç¬¦åˆMCPçš„æœåŠ¡æ‰€éœ€çš„æ‰‹åŠ¨å·¥ä½œï¼Œå…¶é‡‡ç”¨å—åˆ°äº†é˜»ç¢ã€‚ç‰¹åˆ«æ˜¯å¯¹äºGitHubä¸Šçš„æ•°ç™¾ä¸‡å¼€æºä»“åº“æ¥è¯´ï¼Œæ›´æ˜¯å¦‚æ­¤ã€‚æœ¬æ–‡ä»‹ç»äº†Code2MCPï¼Œè¿™æ˜¯ä¸€ä¸ªé«˜åº¦è‡ªåŠ¨åŒ–çš„ä»£ç†æ¡†æ¶ï¼Œæ—¨åœ¨ä»¥æœ€å°çš„æ‰‹åŠ¨å¹²é¢„å°†ä»»ä½•GitHubä»“åº“è½¬æ¢ä¸ºåŠŸèƒ½æ€§çš„MCPæœåŠ¡ã€‚æˆ‘ä»¬çš„ç³»ç»Ÿé‡‡ç”¨å¤šé˜¶æ®µå·¥ä½œæµç¨‹ï¼Œè‡ªåŠ¨å®Œæˆä»ä»£ç åˆ†æã€ç¯å¢ƒé…ç½®åˆ°æœåŠ¡ç”Ÿæˆå’Œéƒ¨ç½²çš„æ•´ä¸ªæµç¨‹ã€‚æˆ‘ä»¬çš„æ¡†æ¶çš„ä¸€ä¸ªå…³é”®åˆ›æ–°æ˜¯ç”±å¤§å‹è¯­è¨€æ¨¡å‹é©±åŠ¨çš„é—­ç¯â€œè¿è¡Œ-å®¡æŸ¥-ä¿®å¤â€å¾ªç¯ï¼Œä½¿ç³»ç»Ÿèƒ½å¤Ÿè‡ªä¸»è°ƒè¯•å’Œä¿®å¤å…¶ç”Ÿæˆçš„ä»£ç ã€‚Code2MCPä¸ä»…ç”Ÿæˆå¯éƒ¨ç½²çš„æœåŠ¡ï¼Œè¿˜æä¾›å…¨é¢çš„æŠ€æœ¯æ–‡æ¡£ï¼Œé€šè¿‡ç³»ç»Ÿåœ°è§£é”ä¸–ç•Œä¸Šæœ€å¤§çš„å¼€æºä»£ç ä»“åº“å¹¶è‡ªåŠ¨åŒ–å·¥å…·é›†æˆçš„å…³é”®æœ€åä¸€è‹±é‡Œï¼Œä»è€ŒåŠ å¿«MCPç”Ÿæ€ç³»ç»Ÿçš„å‘å±•ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>LLMsåœ¨AIä»£ç†ç”Ÿæ€ç³»ç»Ÿä¸­å¼•å‘é‡å¤§é›†æˆæŒ‘æˆ˜ï¼Œè¡¨ç°ä¸ºâ€œ$N \times M$ é—®é¢˜â€ã€‚</li>
<li>Model Context Protocol (MCP)æ—¨åœ¨è§£å†³æ­¤é—®é¢˜ï¼Œä½†æ‰‹åŠ¨è½¬æ¢ç°æœ‰è½¯ä»¶æˆä¸ºä¸€å¤§æŒ‘æˆ˜ã€‚</li>
<li>Code2MCPæ¡†æ¶æ—¨åœ¨è‡ªåŠ¨åŒ–GitHubä»“åº“åˆ°åŠŸèƒ½æ€§çš„MCPæœåŠ¡çš„è½¬åŒ–è¿‡ç¨‹ã€‚</li>
<li>Code2MCPåŒ…å«å¤šé˜¶æ®µå·¥ä½œæµç¨‹ï¼Œä»ä»£ç åˆ†æåˆ°æœåŠ¡éƒ¨ç½²éƒ½å®ç°è‡ªåŠ¨åŒ–ã€‚</li>
<li>LLMé©±åŠ¨çš„é—­ç¯â€œè¿è¡Œ-å®¡æŸ¥-ä¿®å¤â€å¾ªç¯æ˜¯Code2MCPçš„å…³é”®åˆ›æ–°ç‚¹ã€‚</li>
<li>Code2MCPä¸ä»…ç”Ÿæˆå¯éƒ¨ç½²çš„æœåŠ¡ï¼Œè¿˜æä¾›å…¨é¢çš„æŠ€æœ¯æ–‡æ¡£ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.05941">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-57803352518a20e2c50e6c300a5503f9.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-2040146710d010fee393882c590a0db8.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-4194a6ce1299f78a3f38d164c04f3dda.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b01a0f472f33e66a5bac0aeb648b445a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f252cbe26f4ff8f15349dcde5e0cc843.jpg" align="middle">
</details>


<h1 id="-10"><a href="#-10" class="headerlink" title=""></a></h1><h2 id="LM-Searcher-Cross-domain-Neural-Architecture-Search-with-LLMs-via-Unified-Numerical-Encoding"><a href="#LM-Searcher-Cross-domain-Neural-Architecture-Search-with-LLMs-via-Unified-Numerical-Encoding" class="headerlink" title="LM-Searcher: Cross-domain Neural Architecture Search with LLMs via   Unified Numerical Encoding"></a>LM-Searcher: Cross-domain Neural Architecture Search with LLMs via   Unified Numerical Encoding</h2><p><strong>Authors:Yuxuan Hu, Jihao Liu, Ke Wang, Jinliang Zhen, Weikang Shi, Manyuan Zhang, Qi Dou, Rui Liu, Aojun Zhou, Hongsheng Li</strong></p>
<p>Recent progress in Large Language Models (LLMs) has opened new avenues for solving complex optimization problems, including Neural Architecture Search (NAS). However, existing LLM-driven NAS approaches rely heavily on prompt engineering and domain-specific tuning, limiting their practicality and scalability across diverse tasks. In this work, we propose LM-Searcher, a novel framework that leverages LLMs for cross-domain neural architecture optimization without the need for extensive domain-specific adaptation. Central to our approach is NCode, a universal numerical string representation for neural architectures, which enables cross-domain architecture encoding and search. We also reformulate the NAS problem as a ranking task, training LLMs to select high-performing architectures from candidate pools using instruction-tuning samples derived from a novel pruning-based subspace sampling strategy. Our curated dataset, encompassing a wide range of architecture-performance pairs, encourages robust and transferable learning. Comprehensive experiments demonstrate that LM-Searcher achieves competitive performance in both in-domain (e.g., CNNs for image classification) and out-of-domain (e.g., LoRA configurations for segmentation and generation) tasks, establishing a new paradigm for flexible and generalizable LLM-based architecture search. The datasets and models will be released at <a target="_blank" rel="noopener" href="https://github.com/Ashone3/LM-Searcher">https://github.com/Ashone3/LM-Searcher</a>. </p>
<blockquote>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„æœ€æ–°è¿›å±•ä¸ºè§£å†³å¤æ‚çš„ä¼˜åŒ–é—®é¢˜å¼€è¾Ÿäº†æ–°çš„é€”å¾„ï¼ŒåŒ…æ‹¬ç¥ç»ç½‘ç»œæ¶æ„æœç´¢ï¼ˆNASï¼‰ã€‚ç„¶è€Œï¼Œç°æœ‰çš„åŸºäºLLMçš„NASæ–¹æ³•ä¸¥é‡ä¾èµ–äºæç¤ºå·¥ç¨‹å’Œç‰¹å®šé¢†åŸŸçš„è°ƒæ•´ï¼Œè¿™é™åˆ¶äº†å®ƒä»¬åœ¨è·¨ä¸åŒä»»åŠ¡æ—¶çš„å®ç”¨æ€§å’Œå¯æ‰©å±•æ€§ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†LM-Searcherï¼Œè¿™æ˜¯ä¸€ä¸ªæ–°å‹æ¡†æ¶ï¼Œå®ƒåˆ©ç”¨LLMè¿›è¡Œè·¨åŸŸç¥ç»ç½‘ç»œæ¶æ„ä¼˜åŒ–ï¼Œè€Œæ— éœ€è¿›è¡Œå¹¿æ³›çš„ç‰¹å®šé¢†åŸŸé€‚åº”ã€‚æˆ‘ä»¬çš„æ–¹æ³•çš„æ ¸å¿ƒæ˜¯NCodeï¼Œè¿™æ˜¯ä¸€ç§ç”¨äºç¥ç»ç½‘ç»œæ¶æ„çš„é€šç”¨æ•°å€¼å­—ç¬¦ä¸²è¡¨ç¤ºï¼Œå®ƒå®ç°äº†è·¨åŸŸæ¶æ„ç¼–ç å’Œæœç´¢ã€‚æˆ‘ä»¬è¿˜é‡æ–°å°†NASé—®é¢˜è¡¨è¿°ä¸ºæ’åºä»»åŠ¡ï¼Œè®­ç»ƒLLMä»å€™é€‰æ± ä¸­é€‰æ‹©é«˜æ€§èƒ½æ¶æ„ï¼Œä½¿ç”¨åŸºäºæ–°å‹åŸºäºå‰ªæçš„å­ç©ºé—´é‡‡æ ·ç­–ç•¥ç”Ÿæˆçš„æŒ‡ä»¤è°ƒæ•´æ ·æœ¬ã€‚æˆ‘ä»¬æ•´ç†çš„æ•°æ®é›†æ¶µç›–äº†å¹¿æ³›çš„æ¶æ„æ€§èƒ½å¯¹ï¼Œé¼“åŠ±ç¨³å¥å’Œå¯è¿ç§»çš„å­¦ä¹ ã€‚ç»¼åˆå®éªŒè¡¨æ˜ï¼ŒLM-Searcheråœ¨åŸŸå†…ï¼ˆä¾‹å¦‚ï¼Œç”¨äºå›¾åƒåˆ†ç±»çš„CNNï¼‰å’ŒåŸŸå¤–ï¼ˆä¾‹å¦‚ï¼Œç”¨äºåˆ†å‰²å’Œç”Ÿæˆçš„LoRAé…ç½®ï¼‰çš„ä»»åŠ¡ä¸­éƒ½å–å¾—äº†å…·æœ‰ç«äº‰åŠ›çš„æ€§èƒ½ï¼Œä¸ºçµæ´»å’Œé€šç”¨çš„åŸºäºLLMçš„æ¶æ„æœç´¢å»ºç«‹äº†æ–°èŒƒå¼ã€‚æ•°æ®é›†å’Œæ¨¡å‹å°†åœ¨<a target="_blank" rel="noopener" href="https://github.com/Ashone3/LM-Searcher%E5%8F%91%E5%B8%83%E3%80%82">https://github.com/Ashone3/LM-Searcherå‘å¸ƒã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.05657v1">PDF</a> EMNLP2025</p>
<p><strong>Summary</strong></p>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„æœ€æ–°è¿›å±•ä¸ºæ±‚è§£å¤æ‚ä¼˜åŒ–é—®é¢˜æä¾›äº†æ–°çš„é€”å¾„ï¼ŒåŒ…æ‹¬ç¥ç»ç½‘ç»œæ¶æ„æœç´¢ï¼ˆNASï¼‰ã€‚ç„¶è€Œï¼Œç°æœ‰çš„LLMé©±åŠ¨çš„NASæ–¹æ³•è¿‡äºä¾èµ–æç¤ºå·¥ç¨‹å’Œç‰¹å®šé¢†åŸŸçš„è°ƒæ•´ï¼Œè¿™åœ¨å®è·µä¸­é™åˆ¶äº†å…¶åœ¨ä¸åŒä»»åŠ¡ä¸­çš„å®ç”¨æ€§å’Œå¯æ‰©å±•æ€§ã€‚æœ¬æ–‡æå‡ºä¸€ç§æ–°çš„æ¡†æ¶LM-Searcherï¼Œè¯¥æ¡†æ¶åˆ©ç”¨LLMè¿›è¡Œè·¨åŸŸç¥ç»ç½‘ç»œæ¶æ„ä¼˜åŒ–ï¼Œæ— éœ€å¹¿æ³›çš„ç‰¹å®šé¢†åŸŸé€‚åº”ã€‚å…¶æ ¸å¿ƒæ˜¯NCodeï¼Œä¸€ç§ç”¨äºç¥ç»ç½‘ç»œæ¶æ„çš„é€šç”¨æ•°å€¼å­—ç¬¦ä¸²è¡¨ç¤ºï¼Œå¯å®ç°è·¨åŸŸæ¶æ„ç¼–ç å’Œæœç´¢ã€‚æ­¤å¤–ï¼Œæœ¬æ–‡å°†NASé—®é¢˜é‡æ–°è¡¨è¿°ä¸ºæ’åä»»åŠ¡ï¼Œè®­ç»ƒLLMä»å€™é€‰æ± ä¸­ä¸ºé«˜æ€§èƒ½æ¶æ„æ‰“åˆ†ï¼Œé‡‡ç”¨åŸºäºä¿®å‰ªçš„å­ç©ºé—´é‡‡æ ·ç­–ç•¥ç”ŸæˆæŒ‡ä»¤è°ƒæ•´æ ·æœ¬ã€‚å®éªŒè¡¨æ˜ï¼ŒLM-Searcheråœ¨å†…éƒ¨é¢†åŸŸï¼ˆå¦‚å›¾åƒåˆ†ç±»çš„CNNï¼‰å’Œå¤–éƒ¨é¢†åŸŸï¼ˆå¦‚åˆ†å‰²å’Œç”Ÿæˆçš„LoRAé…ç½®ï¼‰çš„ä»»åŠ¡ä¸­å‡å–å¾—äº†å…·æœ‰ç«äº‰åŠ›çš„è¡¨ç°ï¼Œä¸ºçµæ´»å’Œé€šç”¨çš„LLMåŸºç¡€æ¶æ„æœç´¢å»ºç«‹äº†æ–°çš„èŒƒä¾‹ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>LLMçš„æœ€æ–°è¿›å±•ä¸ºæ±‚è§£å¤æ‚ä¼˜åŒ–é—®é¢˜æä¾›äº†æ–°çš„é€”å¾„ã€‚</li>
<li>ç°æœ‰LLMé©±åŠ¨çš„NASæ–¹æ³•å­˜åœ¨å¯¹æç¤ºå·¥ç¨‹å’Œç‰¹å®šé¢†åŸŸè°ƒæ•´çš„ä¾èµ–ï¼Œé™åˆ¶äº†å…¶å®ç”¨æ€§å’Œå¯æ‰©å±•æ€§ã€‚</li>
<li>LM-Searcheræ¡†æ¶åˆ©ç”¨LLMè¿›è¡Œè·¨åŸŸç¥ç»ç½‘ç»œæ¶æ„ä¼˜åŒ–ï¼Œæ— éœ€å¹¿æ³›çš„ç‰¹å®šé¢†åŸŸé€‚åº”ã€‚</li>
<li>NCodeæ˜¯ä¸€ç§ç”¨äºç¥ç»ç½‘ç»œæ¶æ„çš„é€šç”¨æ•°å€¼å­—ç¬¦ä¸²è¡¨ç¤ºï¼Œæ”¯æŒè·¨åŸŸæ¶æ„ç¼–ç å’Œæœç´¢ã€‚</li>
<li>NASé—®é¢˜è¢«é‡æ–°è¡¨è¿°ä¸ºæ’åä»»åŠ¡ï¼ŒLLMä»å€™é€‰æ± ä¸­ä¸ºé«˜æ€§èƒ½æ¶æ„æ‰“åˆ†ã€‚</li>
<li>é‡‡ç”¨åŸºäºä¿®å‰ªçš„å­ç©ºé—´é‡‡æ ·ç­–ç•¥ç”ŸæˆæŒ‡ä»¤è°ƒæ•´æ ·æœ¬ï¼Œç”¨äºè®­ç»ƒLLMã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.05657">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-0dc511e5e1f20c4d5d70404f811de075.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-eabf1aea7b1da4bec1b86d711e42d064.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-8cc26ce48438df86b43d5c6a4cceea72.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e7713f74c7f52e814602cf90ace66351.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-53ce69ff6656bb0640075e354d458af7.jpg" align="middle">
</details>


<h1 id="-11"><a href="#-11" class="headerlink" title=""></a></h1><h2 id="Comparative-Analysis-of-Transformer-Models-in-Disaster-Tweet-Classification-for-Public-Safety"><a href="#Comparative-Analysis-of-Transformer-Models-in-Disaster-Tweet-Classification-for-Public-Safety" class="headerlink" title="Comparative Analysis of Transformer Models in Disaster Tweet   Classification for Public Safety"></a>Comparative Analysis of Transformer Models in Disaster Tweet   Classification for Public Safety</h2><p><strong>Authors:Sharif Noor Zisad, N. M. Istiak Chowdhury, Ragib Hasan</strong></p>
<p>Twitter and other social media platforms have become vital sources of real time information during disasters and public safety emergencies. Automatically classifying disaster related tweets can help emergency services respond faster and more effectively. Traditional Machine Learning (ML) models such as Logistic Regression, Naive Bayes, and Support Vector Machines have been widely used for this task, but they often fail to understand the context or deeper meaning of words, especially when the language is informal, metaphorical, or ambiguous. We posit that, in this context, transformer based models can perform better than traditional ML models. In this paper, we evaluate the effectiveness of transformer based models, including BERT, DistilBERT, RoBERTa, and DeBERTa, for classifying disaster related tweets. These models are compared with traditional ML approaches to highlight the performance gap. Experimental results show that BERT achieved the highest accuracy (91%), significantly outperforming traditional models like Logistic Regression and Naive Bayes (both at 82%). The use of contextual embeddings and attention mechanisms allows transformer models to better understand subtle language in tweets, where traditional ML models fall short. This research demonstrates that transformer architectures are far more suitable for public safety applications, offering improved accuracy, deeper language understanding, and better generalization across real world social media text. </p>
<blockquote>
<p>æ¨ç‰¹å’Œå…¶ä»–ç¤¾äº¤åª’ä½“å¹³å°åœ¨ç¾éš¾å’Œå…¬å…±å®‰å…¨ç´§æ€¥äº‹ä»¶æœŸé—´å·²æˆä¸ºå®æ—¶ä¿¡æ¯çš„é‡è¦æ¥æºã€‚è‡ªåŠ¨åˆ†ç±»ä¸ç¾éš¾ç›¸å…³çš„æ¨ç‰¹å¯ä»¥å¸®åŠ©ç´§æ€¥æœåŠ¡æ›´å¿«ã€æ›´æœ‰æ•ˆåœ°ä½œå‡ºååº”ã€‚ä¼ ç»Ÿæœºå™¨å­¦ä¹ ï¼ˆMLï¼‰æ¨¡å‹ï¼Œå¦‚é€»è¾‘å›å½’ã€æœ´ç´ è´å¶æ–¯å’Œæ”¯æŒå‘é‡æœºï¼Œå·²å¹¿æ³›åº”ç”¨äºæ­¤é¡¹ä»»åŠ¡ï¼Œä½†å®ƒä»¬å¸¸å¸¸æ— æ³•ç†è§£è¯­å¢ƒæˆ–å•è¯çš„æ·±å±‚å«ä¹‰ï¼Œå°¤å…¶æ˜¯åœ¨è¯­è¨€éæ­£å¼ã€éšæ™¦æˆ–å«ç³Šä¸æ¸…çš„æƒ…å†µä¸‹ã€‚æˆ‘ä»¬è®¤ä¸ºï¼Œåœ¨è¿™ç§æƒ…å†µä¸‹ï¼ŒåŸºäºå˜å‹å™¨æ¨¡å‹çš„è¡¨ç°å¯ä»¥ä¼˜äºä¼ ç»Ÿæœºå™¨å­¦ä¹ æ¨¡å‹ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬è¯„ä¼°äº†åŸºäºå˜å‹å™¨æ¨¡å‹çš„æœ‰æ•ˆæ€§ï¼ŒåŒ…æ‹¬BERTã€DistilBERTã€RoBERTaå’ŒDeBERTaï¼Œç”¨äºåˆ†ç±»ä¸ç¾éš¾ç›¸å…³çš„æ¨ç‰¹ã€‚è¿™äº›æ¨¡å‹ä¸ä¼ ç»Ÿæœºå™¨å­¦ä¹ æ–¹æ³•è¿›è¡Œæ¯”è¾ƒï¼Œä»¥çªå‡ºè¡¨ç°å·®è·ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒBERTçš„å‡†ç¡®ç‡æœ€é«˜ï¼ˆ91%ï¼‰ï¼Œæ˜¾è‘—ä¼˜äºé€»è¾‘å›å½’å’Œæœ´ç´ è´å¶æ–¯ç­‰ä¼ ç»Ÿæ¨¡å‹ï¼ˆå‡ä¸º82%ï¼‰ã€‚ä¸Šä¸‹æ–‡åµŒå…¥å’Œæ³¨æ„åŠ›æœºåˆ¶çš„ä½¿ç”¨ä½¿å¾—å˜å‹å™¨æ¨¡å‹èƒ½å¤Ÿæ›´å¥½åœ°ç†è§£æ¨ç‰¹ä¸­çš„å¾®å¦™è¯­è¨€ï¼Œè¿™æ˜¯ä¼ ç»Ÿæœºå™¨å­¦ä¹ æ¨¡å‹æ‰€æ— æ³•åšåˆ°çš„ã€‚è¿™é¡¹ç ”ç©¶è¡¨æ˜ï¼Œå˜å‹å™¨æ¶æ„éå¸¸é€‚åˆå…¬å…±å®‰å…¨åº”ç”¨ï¼Œå…·æœ‰æ›´é«˜çš„å‡†ç¡®æ€§ã€æ›´æ·±çš„è¯­è¨€ç†è§£èƒ½åŠ›å’Œåœ¨ç°å®ç¤¾äº¤åª’æœ¬æ–‡æœ¬ä¸­æ›´å¥½çš„æ³›åŒ–èƒ½åŠ›ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.04650v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æ¢è®¨äº†ç¤¾äº¤åª’ä½“å¹³å°åœ¨ç¾éš¾å’Œå…¬å…±å®‰å…¨ç´§æ€¥äº‹ä»¶ä¸­çš„å®æ—¶ä¿¡æ¯é‡è¦æ€§ã€‚é’ˆå¯¹ç¾éš¾ç›¸å…³çš„æ¨ç‰¹åˆ†ç±»ï¼Œè¯„ä¼°äº†åŸºäºå˜å‹å™¨çš„æ¨¡å‹ï¼ˆå¦‚BERTã€DistilBERTã€RoBERTaå’ŒDeBERTaï¼‰çš„æ•ˆæœï¼Œå¹¶ä¸ä¼ ç»Ÿæœºå™¨å­¦ä¹ æ¨¡å‹è¿›è¡Œäº†æ¯”è¾ƒã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒBERTè¾¾åˆ°äº†æœ€é«˜çš„å‡†ç¡®æ€§ï¼ˆ91%ï¼‰ï¼Œæ˜¾è‘—ä¼˜äºé€»è¾‘å›å½’å’Œæœ´ç´ è´å¶æ–¯ç­‰ä¼ ç»Ÿæ¨¡å‹ï¼ˆå‡ä¸º82%ï¼‰ã€‚åŸºäºå˜å‹å™¨çš„æ¨¡å‹èƒ½æ›´å¥½åœ°ç†è§£æ¨æ–‡ä¸­çš„ç»†å¾®è¯­è¨€ï¼Œè€Œä¼ ç»Ÿæ¨¡å‹åˆ™åœ¨è¿™æ–¹é¢è¡¨ç°ä¸è¶³ã€‚æœ¬ç ”ç©¶è¡¨æ˜ï¼Œå¯¹äºå…¬å…±å®‰å…¨åº”ç”¨ï¼ŒåŸºäºå˜å‹å™¨çš„æ¶æ„æ›´é€‚åˆï¼Œå…·æœ‰æ›´é«˜çš„å‡†ç¡®æ€§ã€æ›´æ·±çš„è¯­è¨€ç†è§£èƒ½åŠ›å’Œæ›´å¥½çš„æ³›åŒ–èƒ½åŠ›ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ç¤¾äº¤åª’ä½“å¹³å°å·²æˆä¸ºç¾éš¾å’Œå…¬å…±å®‰å…¨ç´§æ€¥äº‹ä»¶çš„é‡è¦å®æ—¶ä¿¡æ¯æ¥æºã€‚</li>
<li>ä¼ ç»Ÿæœºå™¨å­¦ä¹ æ¨¡å‹åœ¨åˆ†ç±»ç¾éš¾ç›¸å…³æ¨ç‰¹æ—¶å­˜åœ¨è¯­å¢ƒç†è§£ä¸è¶³çš„é—®é¢˜ã€‚</li>
<li>åŸºäºå˜å‹å™¨çš„æ¨¡å‹ï¼ˆå¦‚BERTï¼‰åœ¨åˆ†ç±»ç¾éš¾ç›¸å…³æ¨ç‰¹æ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œå…¶ä¸­BERTè¾¾åˆ°91%çš„å‡†ç¡®æ€§ã€‚</li>
<li>ä¸ä¼ ç»Ÿæ¨¡å‹ç›¸æ¯”ï¼ŒåŸºäºå˜å‹å™¨çš„æ¨¡å‹èƒ½æ›´å¥½åœ°ç†è§£æ¨æ–‡ä¸­çš„ç»†å¾®è¯­è¨€å’Œè¯­å¢ƒã€‚</li>
<li>åŸºäºå˜å‹å™¨çš„æ¨¡å‹å…·æœ‰æ›´æ·±çš„è¯­è¨€ç†è§£èƒ½åŠ›å’Œæ›´å¥½çš„æ³›åŒ–èƒ½åŠ›ã€‚</li>
<li>æœ¬ç ”ç©¶è¯æ˜äº†åŸºäºå˜å‹å™¨çš„æ¶æ„åœ¨å…¬å…±å®‰å…¨åº”ç”¨ä¸­çš„é€‚ç”¨æ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.04650">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-711435f1ab19dcd29e3f5ed0c8e5e948.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-11d59b0e34060fd853bb80b7b8ac8693.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-bfb42aeda1262d35a02164ee411cbcd5.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-6e1b273842af41c3d818221ae933c85a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b22a0720498bbe965a202eccc747f05f.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-aa869209f2853937bfbeaea14fe3d07c.jpg" align="middle">
</details>


<h1 id="-12"><a href="#-12" class="headerlink" title=""></a></h1><h2 id="Oyster-I-Beyond-Refusal-â€“-Constructive-Safety-Alignment-for-Responsible-Language-Models"><a href="#Oyster-I-Beyond-Refusal-â€“-Constructive-Safety-Alignment-for-Responsible-Language-Models" class="headerlink" title="Oyster-I: Beyond Refusal â€“ Constructive Safety Alignment for   Responsible Language Models"></a>Oyster-I: Beyond Refusal â€“ Constructive Safety Alignment for   Responsible Language Models</h2><p><strong>Authors:Ranjie Duan, Jiexi Liu, Xiaojun Jia, Shiji Zhao, Ruoxi Cheng, Fengxiang Wang, Cheng Wei, Yong Xie, Chang Liu, Defeng Li, Yinpeng Dong, Yichi Zhang, Yuefeng Chen, Chongwen Wang, Xingjun Ma, Xingxing Wei, Yang Liu, Hang Su, Jun Zhu, Xinfeng Li, Yitong Sun, Jie Zhang, Jinzhao Hu, Sha Xu, Yitong Yang, Jialing Tao, Hui Xue</strong></p>
<p>Large language models (LLMs) typically deploy safety mechanisms to prevent harmful content generation. Most current approaches focus narrowly on risks posed by malicious actors, often framing risks as adversarial events and relying on defensive refusals. However, in real-world settings, risks also come from non-malicious users seeking help while under psychological distress (e.g., self-harm intentions). In such cases, the modelâ€™s response can strongly influence the userâ€™s next actions. Simple refusals may lead them to repeat, escalate, or move to unsafe platforms, creating worse outcomes. We introduce Constructive Safety Alignment (CSA), a human-centric paradigm that protects against malicious misuse while actively guiding vulnerable users toward safe and helpful results. Implemented in Oyster-I (Oy1), CSA combines game-theoretic anticipation of user reactions, fine-grained risk boundary discovery, and interpretable reasoning control, turning safety into a trust-building process. Oy1 achieves state-of-the-art safety among open models while retaining high general capabilities. On our Constructive Benchmark, it shows strong constructive engagement, close to GPT-5, and unmatched robustness on the Strata-Sword jailbreak dataset, nearing GPT-o1 levels. By shifting from refusal-first to guidance-first safety, CSA redefines the model-user relationship, aiming for systems that are not just safe, but meaningfully helpful. We release Oy1, code, and the benchmark to support responsible, user-centered AI. </p>
<blockquote>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰é€šå¸¸ä¼šéƒ¨ç½²å®‰å…¨æœºåˆ¶ä»¥é˜²æ­¢ç”Ÿæˆæœ‰å®³å†…å®¹ã€‚å½“å‰å¤§å¤šæ•°æ–¹æ³•ä¸»è¦å…³æ³¨æ¶æ„è¡Œä¸ºè€…å¸¦æ¥çš„é£é™©ï¼Œé€šå¸¸å°†è¿™äº›é£é™©è§†ä¸ºå¯¹æŠ—æ€§äº‹ä»¶å¹¶ä¾èµ–é˜²å¾¡æ€§æ‹’ç»ã€‚ç„¶è€Œï¼Œåœ¨çœŸå®ä¸–ç•Œç¯å¢ƒä¸­ï¼Œé£é™©è¿˜æ¥è‡ªäºéæ¶æ„ç”¨æˆ·åœ¨å¿ƒç†å‹åŠ›ä¸‹å¯»æ±‚å¸®åŠ©ï¼ˆä¾‹å¦‚ï¼Œè‡ªæˆ‘ä¼¤å®³æ„å›¾ï¼‰ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæ¨¡å‹çš„ååº”ä¼šå¼ºçƒˆå½±å“ç”¨æˆ·çš„ä¸‹ä¸€æ­¥è¡ŒåŠ¨ã€‚ç®€å•çš„æ‹’ç»å¯èƒ½ä¼šä½¿ä»–ä»¬é‡å¤ã€å‡çº§æˆ–è½¬å‘ä¸å®‰å…¨çš„å¹³å°ï¼Œé€ æˆæ›´ç³Ÿçš„ç»“æœã€‚æˆ‘ä»¬å¼•å…¥äº†å»ºè®¾æ€§å®‰å…¨å¯¹é½ï¼ˆCSAï¼‰è¿™ä¸€ä»¥äººç±»ä¸ºä¸­å¿ƒçš„æ¨¡å¼ï¼Œå®ƒæ—¢èƒ½é˜²æ­¢æ¶æ„æ»¥ç”¨ï¼Œåˆèƒ½ç§¯ææŒ‡å¯¼è„†å¼±ç”¨æˆ·è·å¾—å®‰å…¨å’Œæœ‰ç›Šçš„ç»“æœã€‚åœ¨ç‰¡è›-Iï¼ˆOy1ï¼‰ä¸­å®ç°çš„CSAç»“åˆäº†åšå¼ˆç†è®ºå¯¹ç”¨æˆ·ååº”çš„é¢„æœŸã€ç²¾ç»†çš„é£é™©è¾¹ç•Œå‘ç°å’Œå¯è§£é‡Šæ¨ç†æ§åˆ¶ï¼Œå°†å®‰å…¨è½¬å˜ä¸ºå»ºç«‹ä¿¡ä»»çš„è¿‡ç¨‹ã€‚Oy1åœ¨å¼€æ”¾æ¨¡å‹ä¸­å®ç°äº†æœ€å…ˆè¿›çš„å®‰æŠ€æœ¯å…¨æ€§ï¼ŒåŒæ—¶ä¿æŒäº†é«˜æ³›åŒ–èƒ½åŠ›ã€‚åœ¨æˆ‘ä»¬çš„å»ºè®¾æ€§åŸºå‡†æµ‹è¯•ä¸­ï¼Œå®ƒæ˜¾ç¤ºå‡ºå¼ºå¤§çš„å»ºè®¾æ€§å‚ä¸åº¦ï¼Œæ¥è¿‘GPT-5ï¼Œåœ¨Strata-Swordè¶Šç‹±æ•°æ®é›†ä¸Šè¡¨ç°å‡ºæ— ä¸ä¼¦æ¯”çš„ç¨³å¥æ€§ï¼Œæ¥è¿‘GPT-o1æ°´å¹³ã€‚é€šè¿‡å°†æ‹’ç»ä¼˜å…ˆçš„å®‰å…¨è½¬å˜ä¸ºæŒ‡å¯¼ä¼˜å…ˆçš„å®‰å…¨ï¼ŒCSAé‡æ–°å®šä¹‰äº†æ¨¡å‹ä¸ç”¨æˆ·ä¹‹é—´çš„å…³ç³»ï¼Œæ—¨åœ¨æ„å»ºä¸ä»…æ˜¯å®‰å…¨è€Œä¸”çœŸæ­£æœ‰æ„ä¹‰çš„ç³»ç»Ÿã€‚æˆ‘ä»¬å‘å¸ƒäº†Oy1ã€ä»£ç å’ŒåŸºå‡†æµ‹è¯•ï¼Œä»¥æ”¯æŒç”¨æˆ·ä¸ºä¸­å¿ƒã€è´Ÿè´£ä»»çš„äººå·¥æ™ºèƒ½ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.01909v3">PDF</a> Technical Report Code &amp; Model weights available:   <a target="_blank" rel="noopener" href="https://github.com/Alibaba-AAIG/Oyster">https://github.com/Alibaba-AAIG/Oyster</a></p>
<p><strong>Summary</strong>ï¼š<br>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰é€šå¸¸é‡‡ç”¨å®‰å…¨æœºåˆ¶é˜²æ­¢ç”Ÿæˆæœ‰å®³å†…å®¹ã€‚ç°æœ‰æ–¹æ³•ä¸»è¦å…³æ³¨æ¶æ„è¡Œä¸ºè€…å¸¦æ¥çš„é£é™©ï¼Œå°†é£é™©è§†ä¸ºå¯¹æŠ—æ€§äº‹ä»¶å¹¶ä¾èµ–é˜²å¾¡æ€§æ‹’ç»ã€‚ç„¶è€Œï¼Œåœ¨ç°å®ä¸–ç•Œä¸­ï¼Œé£é™©è¿˜æ¥è‡ªäºæœ‰å¿ƒç†å›°æ‰°çš„ç”¨æˆ·çš„æ±‚åŠ©éœ€æ±‚ã€‚é’ˆå¯¹è¿™ç§æƒ…å†µï¼Œæ¨¡å‹å“åº”ä¼šå½±å“ç”¨æˆ·ä¸‹ä¸€æ­¥è¡ŒåŠ¨ã€‚æœ¬æ–‡æå‡ºå»ºè®¾æ€§å®‰å…¨å¯¹é½ï¼ˆCSAï¼‰æ–¹æ³•ï¼Œæ—¢é˜²æ­¢æ¶æ„è¯¯ç”¨ï¼Œåˆç§¯æå¼•å¯¼è„†å¼±ç”¨æˆ·è·å¾—å®‰å…¨å’Œæœ‰å¸®åŠ©çš„ç»“æœã€‚è¯¥æ–¹æ³•å°†å®‰å…¨è½¬å˜ä¸ºå»ºç«‹ä¿¡ä»»çš„è¿‡ç¨‹ï¼Œå®ç°äº†Oyster-Iï¼ˆOy1ï¼‰æ¨¡å‹çš„é«˜å®‰å…¨æ€§å’Œé«˜é€šç”¨æ€§ã€‚</p>
<p><strong>Key Takeaways</strong>ï¼š</p>
<ol>
<li>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰éƒ¨ç½²å®‰å…¨æœºåˆ¶é˜²æ­¢ç”Ÿæˆæœ‰å®³å†…å®¹ã€‚</li>
<li>ç°æœ‰æ–¹æ³•ä¸»è¦å…³æ³¨æ¶æ„è¡Œä¸ºè€…çš„é£é™©ï¼Œä½†å¿½ç•¥äº†æ¥è‡ªå¿ƒç†å›°æ‰°ç”¨æˆ·çš„çœŸå®é£é™©ã€‚</li>
<li>å»ºè®¾æ€§å®‰å…¨å¯¹é½ï¼ˆCSAï¼‰æ˜¯ä¸€ç§æ–°çš„ä¿æŠ¤æ–¹æ³•ï¼Œæ—¢é˜²æ­¢æ¶æ„è¯¯ç”¨ï¼Œåˆç§¯ææŒ‡å¯¼è„†å¼±ç”¨æˆ·è·å¾—å®‰å…¨å’Œæœ‰å¸®åŠ©çš„ç»“æœã€‚</li>
<li>CSAå°†å®‰å…¨è½¬å˜ä¸ºå»ºç«‹ä¿¡ä»»çš„è¿‡ç¨‹ï¼Œæé«˜äº†æ¨¡å‹ä¸ç”¨æˆ·ä¹‹é—´çš„äº’åŠ¨æ€§ã€‚</li>
<li>Oy1æ¨¡å‹å®ç°äº†é«˜å®‰å…¨æ€§å’Œé«˜é€šç”¨æ€§ï¼Œå±•ç°äº†å¼ºå¤§çš„å»ºè®¾æ€§äº¤äº’èƒ½åŠ›ï¼ŒåŒæ—¶åœ¨Strata-Swordè¶Šç‹±æ•°æ®é›†ä¸Šå±•ç°äº†å¼ºå¤§çš„ç¨³å¥æ€§ã€‚</li>
<li>CSAé‡æ–°å®šä¹‰æ¨¡å‹ä¸ç”¨æˆ·ä¹‹é—´çš„å…³ç³»ï¼Œæ—¨åœ¨å»ºç«‹ä¸ä»…å®‰å…¨è€Œä¸”æœ‰æ„ä¹‰çš„å¸®åŠ©ç³»ç»Ÿã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.01909">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-af071cfabbf26ab5029dc03b0eb04d34.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-1e75ab0cc30f21c22e90cb1fc0f56298.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-7e07ff1e230994a339e4659cf7ce1fe1.jpg" align="middle">
</details>


<h1 id="-13"><a href="#-13" class="headerlink" title=""></a></h1><h2 id="Not-All-Features-Deserve-Attention-Graph-Guided-Dependency-Learning-for-Tabular-Data-Generation-with-Language-Models"><a href="#Not-All-Features-Deserve-Attention-Graph-Guided-Dependency-Learning-for-Tabular-Data-Generation-with-Language-Models" class="headerlink" title="Not All Features Deserve Attention: Graph-Guided Dependency Learning for   Tabular Data Generation with Language Models"></a>Not All Features Deserve Attention: Graph-Guided Dependency Learning for   Tabular Data Generation with Language Models</h2><p><strong>Authors:Zheyu Zhang, Shuo Yang, Bardh Prenkaj, Gjergji Kasneci</strong></p>
<p>Large Language Models (LLMs) have shown strong potential for tabular data generation by modeling textualized feature-value pairs. However, tabular data inherently exhibits sparse feature-level dependencies, where many feature interactions are structurally insignificant. This creates a fundamental mismatch as LLMsâ€™ self-attention mechanism inevitably distributes focus across all pairs, diluting attention on critical relationships, particularly in datasets with complex dependencies or semantically ambiguous features. To address this limitation, we propose GraDe (Graph-Guided Dependency Learning), a novel method that explicitly integrates sparse dependency graphs into LLMsâ€™ attention mechanism. GraDe employs a lightweight dynamic graph learning module guided by externally extracted functional dependencies, prioritizing key feature interactions while suppressing irrelevant ones. Our experiments across diverse real-world datasets demonstrate that GraDe outperforms existing LLM-based approaches by up to 12% on complex datasets while achieving competitive results with state-of-the-art approaches in synthetic data quality. Our method is minimally intrusive yet effective, offering a practical solution for structure-aware tabular data modeling with LLMs. </p>
<blockquote>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰é€šè¿‡å»ºæ¨¡æ–‡æœ¬åŒ–çš„ç‰¹å¾å€¼å¯¹ï¼Œåœ¨è¡¨æ ¼æ•°æ®ç”Ÿæˆæ–¹é¢æ˜¾ç¤ºå‡ºå¼ºå¤§çš„æ½œåŠ›ã€‚ç„¶è€Œï¼Œè¡¨æ ¼æ•°æ®æœ¬è´¨ä¸Šè¡¨ç°å‡ºç¨€ç–çš„ç‰¹å¾çº§ä¾èµ–å…³ç³»ï¼Œå…¶ä¸­è®¸å¤šç‰¹å¾äº¤äº’åœ¨ç»“æ„ä¸Šå¹¶ä¸æ˜¾è‘—ã€‚è¿™é€ æˆäº†ä¸€ä¸ªæ ¹æœ¬æ€§çš„ä¸åŒ¹é…ï¼Œå› ä¸ºLLMçš„è‡ªæ³¨æ„åŠ›æœºåˆ¶ä¸å¯é¿å…åœ°ä¼šåˆ†æ•£åˆ°æ‰€æœ‰å¯¹ä¸Šï¼Œç¨€é‡Šäº†å¯¹å…³é”®å…³ç³»çš„æ³¨æ„åŠ›ï¼Œç‰¹åˆ«æ˜¯åœ¨å…·æœ‰å¤æ‚ä¾èµ–å…³ç³»æˆ–è¯­ä¹‰æ¨¡ç³Šç‰¹å¾çš„æ•°æ®é›†ä¸­ã€‚ä¸ºäº†è§£å†³è¿™ä¸€å±€é™æ€§ï¼Œæˆ‘ä»¬æå‡ºäº†GraDeï¼ˆGraphå¼•å¯¼ä¾èµ–å­¦ä¹ ï¼‰ï¼Œè¿™æ˜¯ä¸€ç§å°†ç¨€ç–ä¾èµ–å›¾æ˜¾å¼é›†æˆåˆ°LLMæ³¨æ„åŠ›æœºåˆ¶ä¸­çš„æ–°æ–¹æ³•ã€‚GraDeé‡‡ç”¨è½»é‡çº§çš„åŠ¨æ€å›¾å­¦ä¹ æ¨¡å—ï¼Œè¯¥æ¨¡å—ç”±å¤–éƒ¨æå–çš„åŠŸèƒ½ä¾èµ–å…³ç³»å¼•å¯¼ï¼Œä¼˜å…ˆå…³æ³¨å…³é”®ç‰¹å¾äº¤äº’ï¼ŒåŒæ—¶æŠ‘åˆ¶æ— å…³äº¤äº’ã€‚æˆ‘ä»¬åœ¨å¤šä¸ªçœŸå®ä¸–ç•Œæ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œåœ¨å¤„ç†å¤æ‚æ•°æ®é›†æ—¶ï¼ŒGraDeç›¸è¾ƒäºç°æœ‰çš„LLMæ–¹æ³•è¡¨ç°ä¼˜å¼‚ï¼Œæé«˜äº†é«˜è¾¾12%ï¼ŒåŒæ—¶åœ¨åˆæˆæ•°æ®è´¨é‡æ–¹é¢è¾¾åˆ°å‰æ²¿æ°´å¹³ã€‚æˆ‘ä»¬çš„æ–¹æ³•å‡ ä¹ä¸éœ€è¦é¢å¤–å·¥ä½œï¼Œä½†å´æ•ˆæœæ˜¾è‘—ï¼Œä¸ºä½¿ç”¨LLMè¿›è¡Œç»“æ„æ„ŸçŸ¥çš„è¡¨æ ¼æ•°æ®å»ºæ¨¡æä¾›äº†å®ç”¨è§£å†³æ–¹æ¡ˆã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2507.18504v2">PDF</a> Accepted to EMNLP 2025 (Findings)</p>
<p><strong>Summary</strong></p>
<p>LLMsåœ¨é€šè¿‡å»ºæ¨¡æ–‡æœ¬åŒ–çš„ç‰¹å¾å€¼å¯¹è¿›è¡Œè¡¨æ ¼æ•°æ®ç”Ÿæˆæ–¹é¢è¡¨ç°å‡ºå¼ºå¤§çš„æ½œåŠ›ã€‚ç„¶è€Œï¼Œè¡¨æ ¼æ•°æ®å†…åœ¨å­˜åœ¨ç¨€ç–çš„ç‰¹å¾çº§åˆ«ä¾èµ–å…³ç³»ï¼Œå¯¼è‡´è®¸å¤šç‰¹å¾äº¤äº’åœ¨ç»“æ„ä¸Šå¹¶ä¸é‡è¦ã€‚è¿™é€ æˆäº†ä¸€ä¸ªæ ¹æœ¬æ€§çš„ä¸åŒ¹é…ï¼Œå› ä¸ºLLMsçš„è‡ªæ³¨æ„åŠ›æœºåˆ¶ä¸å¯é¿å…åœ°ä¼šåˆ†æ•£åˆ°æ‰€æœ‰å¯¹ä¸Šï¼Œç¨€é‡Šäº†å¯¹å…³é”®å…³ç³»ä¸Šçš„æ³¨æ„åŠ›ï¼Œç‰¹åˆ«æ˜¯åœ¨å…·æœ‰å¤æ‚ä¾èµ–æˆ–è¯­ä¹‰æ¨¡ç³Šç‰¹å¾çš„æ•°æ®åº“ä¸­ã€‚ä¸ºè§£å†³æ­¤å±€é™æ€§ï¼Œæå‡ºäº†ä¸€ç§åä¸ºGraDeï¼ˆå›¾å¼•å¯¼ä¾èµ–å­¦ä¹ ï¼‰çš„æ–°æ–¹æ³•ï¼Œè¯¥æ–¹æ³•å°†ç¨€ç–ä¾èµ–å›¾æ˜¾å¼åœ°é›†æˆåˆ°LLMsçš„æ³¨æ„åŠ›æœºåˆ¶ä¸­ã€‚GraDeä½¿ç”¨å¤–éƒ¨æå–çš„åŠŸèƒ½ä¾èµ–å¼•å¯¼çš„è½»é‡çº§åŠ¨æ€å›¾å­¦ä¹ æ¨¡å—ï¼Œä¼˜å…ˆå…³æ³¨å…³é”®ç‰¹å¾äº¤äº’ï¼ŒåŒæ—¶æŠ‘åˆ¶æ— å…³äº¤äº’ã€‚åœ¨å¤šç§çœŸå®æ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒGraDeåœ¨å¤æ‚æ•°æ®é›†ä¸Šçš„è¡¨ç°ä¼˜äºç°æœ‰çš„LLMæ–¹æ³•ï¼Œåˆæˆæ•°æ®è´¨é‡æ–¹é¢è¾¾åˆ°äº†ä¸æœ€æ–°æ–¹æ³•ç›¸å½“çš„æ°´å¹³ã€‚æˆ‘ä»¬çš„æ–¹æ³•å…·æœ‰æœ€å°çš„ä¾µå…¥æ€§ä¸”æœ‰æ•ˆï¼Œä¸ºä½¿ç”¨LLMè¿›è¡Œç»“æ„æ„ŸçŸ¥çš„è¡¨æ ¼æ•°æ®å»ºæ¨¡æä¾›äº†å®ç”¨çš„è§£å†³æ–¹æ¡ˆã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>LLMsåœ¨è¡¨æ ¼æ•°æ®ç”Ÿæˆæ–¹é¢å±•ç°å‡ºå¼ºå¤§çš„æ½œåŠ›ï¼Œé€šè¿‡å»ºæ¨¡æ–‡æœ¬åŒ–çš„ç‰¹å¾å€¼å¯¹è¿›è¡Œè¡¨ç°ã€‚</li>
<li>è¡¨æ ¼æ•°æ®å­˜åœ¨ç¨€ç–çš„ç‰¹å¾çº§åˆ«ä¾èµ–å…³ç³»ï¼Œå¯¼è‡´LLMsè‡ªæ³¨æ„åŠ›æœºåˆ¶çš„ä¸åŒ¹é…é—®é¢˜ã€‚</li>
<li>GraDeæ–¹æ³•é€šè¿‡é›†æˆç¨€ç–ä¾èµ–å›¾åˆ°LLMsçš„æ³¨æ„åŠ›æœºåˆ¶ä¸­æ¥è§£å†³è¿™ä¸€é—®é¢˜ã€‚</li>
<li>GraDeä½¿ç”¨å¤–éƒ¨æå–çš„åŠŸèƒ½ä¾èµ–æ¥ä¼˜å…ˆå…³æ³¨å…³é”®ç‰¹å¾äº¤äº’å¹¶æŠ‘åˆ¶æ— å…³äº¤äº’ã€‚</li>
<li>GraDeåœ¨å¤æ‚æ•°æ®é›†ä¸Šçš„è¡¨ç°ä¼˜äºç°æœ‰LLMæ–¹æ³•ï¼Œåˆæˆæ•°æ®è´¨é‡æ–¹é¢è¾¾åˆ°äº†ä¸æœ€æ–°æ–¹æ³•ç›¸å½“çš„æ°´å¹³ã€‚</li>
<li>GraDeæ–¹æ³•å…·æœ‰æœ€å°çš„ä¾µå…¥æ€§ä¸”æœ‰æ•ˆã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2507.18504">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-05db724bb924eb638a8c9ecbc9317b42.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d1ba43a21e6b9be009837ba0debf9cf5.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-d0468bb0e4b58862792702435ae24998.jpg" align="middle">
</details>


<h1 id="-14"><a href="#-14" class="headerlink" title=""></a></h1><h2 id="ChatCFD-An-LLM-Driven-Agent-for-End-to-End-CFD-Automation-with-Domain-Specific-Structured-Reasoning"><a href="#ChatCFD-An-LLM-Driven-Agent-for-End-to-End-CFD-Automation-with-Domain-Specific-Structured-Reasoning" class="headerlink" title="ChatCFD: An LLM-Driven Agent for End-to-End CFD Automation with   Domain-Specific Structured Reasoning"></a>ChatCFD: An LLM-Driven Agent for End-to-End CFD Automation with   Domain-Specific Structured Reasoning</h2><p><strong>Authors:E Fan, Kang Hu, Zhuowen Wu, Jiangyang Ge, Jiawei Miao, Yuzhi Zhang, He Sun, Weizong Wang, Tianhan Zhang</strong></p>
<p>Computational Fluid Dynamics (CFD) is essential for advancing scientific and engineering fields but is hindered by operational complexity, high expertise requirements, and limited accessibility. This paper introduces ChatCFD, an automated agent system for OpenFOAM simulations that processes multi-modal inputs (e.g., research papers, meshes) via an interactive interface, leveraging DeepSeek-R1 and DeepSeek-V3 large language models, a multi-agent architecture, and OpenFOAM knowledge. Its four-stage pipeline (Knowledge Base Construction, User Input Processing, Case File Generation, and Execution and Error Reflection) enables iterative trial-reflection-refinement for intricate setups, supporting diverse physical models and external meshes. Validation on 205 benchmark tutorial cases, 110 perturbed variants, and 2 literature-derived cases shows ChatCFDâ€™s 82.1 percent operational success rate on basic cases, outperforming MetaOpenFOAM (6.2 percent) and Foam-Agent (42.3 percent), and 60-80 percent on literature-derived complex cases. Turbulence model studies show a 40 percent success rate for common models versus 10 percent for rare ones like RNG k-epsilon. Physics coupling analyses reveal higher resource demands for multi-physics-coupled cases, while LLM bias toward simpler setups introduces persistent errors, such as dimensional inconsistency. Ablation studies highlight the efficacy of RAG-based modules and reflection mechanisms. By automating hypothesis testing and parameter exploration, ChatCFD accelerates scientific discovery in fluid mechanics and engineering, addressing LLM limitations through structured design and showing strong potential as a modular component in MCP-based agent networks for collaborative multi-agent systems, paving the way for scalable AI-driven CFD innovation. The code for ChatCFD is available at <a target="_blank" rel="noopener" href="https://github.com/ConMoo/ChatCFD">https://github.com/ConMoo/ChatCFD</a>. </p>
<blockquote>
<p>è®¡ç®—æµä½“åŠ¨åŠ›å­¦ï¼ˆCFDï¼‰å¯¹äºæ¨åŠ¨ç§‘å­¦å’Œå·¥ç¨‹é¢†åŸŸçš„å‘å±•è‡³å…³é‡è¦ï¼Œä½†å—åˆ°æ“ä½œå¤æ‚ã€ä¸“ä¸šè¦æ±‚é«˜å’Œå¯è®¿é—®æ€§æœ‰é™çš„é˜»ç¢ã€‚æœ¬æ–‡ä»‹ç»äº†ChatCFDï¼Œè¿™æ˜¯ä¸€ä¸ªç”¨äºOpenFOAMæ¨¡æ‹Ÿçš„è‡ªåŠ¨åŒ–ä»£ç†ç³»ç»Ÿï¼Œå®ƒé€šè¿‡äº¤äº’å¼æ¥å£å¤„ç†å¤šæ¨¡å¼è¾“å…¥ï¼ˆä¾‹å¦‚ç ”ç©¶è®ºæ–‡ã€ç½‘æ ¼ï¼‰ï¼Œåˆ©ç”¨DeepSeek-R1å’ŒDeepSeek-V3å¤§å‹è¯­è¨€æ¨¡å‹ã€å¤šä»£ç†æ¶æ„å’ŒOpenFOAMçŸ¥è¯†ã€‚å…¶å››é˜¶æ®µç®¡é“ï¼ˆçŸ¥è¯†åº“æ„å»ºã€ç”¨æˆ·è¾“å…¥å¤„ç†ã€æ¡ˆä¾‹æ–‡ä»¶ç”Ÿæˆã€æ‰§è¡Œå’Œé”™è¯¯åæ€ï¼‰ä¸ºå¤æ‚çš„è®¾ç½®æä¾›äº†è¿­ä»£è¯•éªŒ-åæ€-æ”¹è¿›çš„æ”¯æŒï¼Œæ”¯æŒå¤šç§ç‰©ç†æ¨¡å‹å’Œå¤–éƒ¨ç½‘æ ¼ã€‚å¯¹205ä¸ªåŸºå‡†æ•™ç¨‹æ¡ˆä¾‹ã€110ä¸ªæ‰°åŠ¨å˜ä½“å’Œ2ä¸ªæ–‡çŒ®è¡ç”Ÿçš„æ¡ˆä¾‹è¿›è¡ŒéªŒè¯ï¼Œè¡¨æ˜ChatCFDåœ¨åŸºæœ¬æ¡ˆä¾‹ä¸­çš„æ“ä½œæˆåŠŸç‡ä¸º82.1%ï¼Œè¶…è¿‡äº†MetaOpenFOAMï¼ˆ6.2%ï¼‰å’ŒFoam-Agentï¼ˆ42.3%ï¼‰ï¼Œåœ¨æ–‡çŒ®è¡ç”Ÿçš„å¤æ‚æ¡ˆä¾‹ä¸­çš„æˆåŠŸç‡ä¸º60-80%ã€‚æ¹æµæ¨¡å‹ç ”ç©¶è¡¨æ˜ï¼Œå¯¹äºå¸¸è§æ¨¡å‹çš„æˆåŠŸç‡ä¸º40%ï¼Œè€Œå¯¹äºç¨€æœ‰çš„å¦‚RNG k-epsilonç­‰æ¨¡å‹ä»…ä¸º10%ã€‚ç‰©ç†è€¦åˆåˆ†æè¡¨æ˜ï¼Œå¤šç‰©ç†è€¦åˆæ¡ˆä¾‹çš„èµ„æºéœ€æ±‚æ›´é«˜ï¼Œè€Œå¤§å‹è¯­è¨€æ¨¡å‹å¯¹æ›´ç®€å•è®¾ç½®çš„åå¥½ä¼šå¯¼è‡´æŒä¹…æ€§é”™è¯¯ï¼Œä¾‹å¦‚å°ºå¯¸ä¸ä¸€è‡´ã€‚æ¶ˆèç ”ç©¶çªå‡ºäº†åŸºäºRAGçš„æ¨¡å—å’Œåå°„æœºåˆ¶çš„æœ‰æ•ˆæ€§ã€‚é€šè¿‡è‡ªåŠ¨åŒ–å‡è®¾æ£€éªŒå’Œå‚æ•°æ¢ç´¢ï¼ŒChatCFDåŠ é€Ÿäº†æµä½“åŠ›å­¦å’Œå·¥ç¨‹ä¸­çš„ç§‘å­¦å‘ç°ï¼Œé€šè¿‡ç»“æ„åŒ–è®¾è®¡è§£å†³äº†å¤§å‹è¯­è¨€æ¨¡å‹çš„å±€é™æ€§ï¼Œå¹¶æ˜¾ç¤ºå‡ºä½œä¸ºæ¨¡å—åŒ–ç»„ä»¶åœ¨åŸºäºMCPçš„ä»£ç†ç½‘ç»œä¸­ç”¨äºåä½œå¤šä»£ç†ç³»ç»Ÿçš„å¼ºå¤§æ½œåŠ›ï¼Œä¸ºå¯ä¼¸ç¼©çš„AIé©±åŠ¨CFDåˆ›æ–°é“ºå¹³äº†é“è·¯ã€‚ChatCFDçš„ä»£ç å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/ConMoo/ChatCFD">https://github.com/ConMoo/ChatCFD</a>è·å–ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.02019v2">PDF</a> 19 pages, 8 figures</p>
<p><strong>æ‘˜è¦</strong><br>    æœ¬è®ºæ–‡ä»‹ç»äº†ä¸€ç§åŸºäºOpenFOAMçš„è‡ªåŠ¨ä»£ç†ç³»ç»ŸChatCFDï¼Œè¯¥ç³»ç»Ÿé€šè¿‡äº¤äº’å¼æ¥å£å¤„ç†å¤šæ¨¡æ€è¾“å…¥ï¼Œåˆ©ç”¨DeepSeek-R1å’ŒDeepSeek-V3å¤§å‹è¯­è¨€æ¨¡å‹ä»¥åŠå¤šä»£ç†æ¶æ„å®ç°CFDæ¨¡æ‹Ÿçš„è‡ªåŠ¨åŒ–ã€‚ChatCFDçš„å››é˜¶æ®µç®¡é“åŒ…æ‹¬çŸ¥è¯†åº“æ„å»ºã€ç”¨æˆ·è¾“å…¥å¤„ç†ã€æ¡ˆä¾‹æ–‡ä»¶ç”Ÿæˆå’Œæ‰§è¡ŒåŠé”™è¯¯åé¦ˆï¼Œæ”¯æŒå¤šç§ç‰©ç†æ¨¡å‹å’Œå¤–éƒ¨ç½‘æ ¼ï¼Œå¹¶åœ¨å¤æ‚è®¾ç½®ä¸Šå®ç°äº†è¿­ä»£è¯•éªŒ-åæ€-æ”¹è¿›ã€‚åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•æ¡ˆä¾‹å’Œæ–‡çŒ®è¡ç”Ÿæ¡ˆä¾‹ä¸Šçš„éªŒè¯è¡¨æ˜ï¼ŒChatCFDåœ¨åŸºæœ¬æ¡ˆä¾‹ä¸Šçš„æ“ä½œæˆåŠŸç‡ä¸º82.1%ï¼Œè¶…è¿‡äº†MetaOpenFOAMï¼ˆ6.2%ï¼‰å’ŒFoam-Agentï¼ˆ42.3%ï¼‰ï¼Œå¹¶åœ¨æ–‡çŒ®è¡ç”Ÿçš„å¤æ‚æ¡ˆä¾‹ä¸Šè¾¾åˆ°60-80%çš„æˆåŠŸç‡ã€‚ç ”ç©¶è¿˜æ¶‰åŠäº†æ¹æµæ¨¡å‹å’Œç‰©ç†è€¦åˆåˆ†æï¼Œæ­ç¤ºäº†å¤šç‰©ç†è€¦åˆæ¡ˆä¾‹çš„èµ„æºéœ€æ±‚è¾ƒé«˜ï¼Œä»¥åŠå¤§å‹è¯­è¨€æ¨¡å‹åœ¨ç®€å•è®¾ç½®ä¸Šçš„åå·®å¯¼è‡´çš„æŒä¹…æ€§é”™è¯¯ã€‚é€šè¿‡è‡ªåŠ¨åŒ–å‡è®¾æ£€éªŒå’Œå‚æ•°æ¢ç´¢ï¼ŒChatCFDåŠ é€Ÿäº†æµä½“åŠ›å­¦å’Œå·¥ç¨‹é¢†åŸŸçš„ç§‘å­¦å‘ç°ï¼Œå¹¶é€šè¿‡ç»“æ„åŒ–è®¾è®¡è§£å†³äº†å¤§å‹è¯­è¨€æ¨¡å‹çš„å±€é™æ€§ï¼Œæ˜¾ç¤ºå‡ºä½œä¸ºæ¨¡å—åŒ–ç»„ä»¶åœ¨åŸºäºæ¨¡å‹çš„åä½œå¤šä»£ç†ç³»ç»Ÿä¸­çš„å¼ºå¤§æ½œåŠ›ï¼Œä¸ºå¯æ‰©å±•çš„AIé©±åŠ¨çš„CFDåˆ›æ–°é“ºå¹³äº†é“è·¯ã€‚</p>
<p><strong>å…³é”®è§è§£</strong></p>
<ol>
<li>ChatCFDæ˜¯ä¸€ä¸ªåŸºäºOpenFOAMçš„è‡ªåŠ¨åŒ–ä»£ç†ç³»ç»Ÿï¼Œç”¨äºå¤„ç†å¤šæ¨¡æ€è¾“å…¥ï¼ŒåŒ…æ‹¬ç ”ç©¶è®ºæ–‡å’Œç½‘æ ¼ï¼Œä¸ºæµä½“åŠ¨åŠ›å­¦æ¨¡æ‹Ÿæä¾›äº†ä¸€ç§æ–°çš„æ–¹æ³•ã€‚</li>
<li>ChatCFDçš„å››é˜¶æ®µç®¡é“åŒ…æ‹¬çŸ¥è¯†åº“æ„å»ºã€ç”¨æˆ·è¾“å…¥å¤„ç†ã€æ¡ˆä¾‹æ–‡ä»¶ç”Ÿæˆå’Œæ‰§è¡ŒåŠé”™è¯¯åé¦ˆï¼Œæ”¯æŒå¤šç§ç‰©ç†æ¨¡å‹å’Œå¤–éƒ¨ç½‘æ ¼ï¼Œå¹¶èƒ½è¿›è¡Œè¿­ä»£è¯•éªŒ-åæ€-æ”¹è¿›ã€‚</li>
<li>ChatCFDåœ¨åŸºå‡†æµ‹è¯•æ¡ˆä¾‹ä¸Šçš„æ“ä½œæˆåŠŸç‡è¾ƒé«˜ï¼Œè¾¾åˆ°äº†82.1%ï¼Œå¹¶ä¸”ç›¸å¯¹äºå…¶ä»–ç³»ç»Ÿï¼ˆå¦‚MetaOpenFOAMå’ŒFoam-Agentï¼‰è¡¨ç°æ›´å¥½ã€‚</li>
<li>åœ¨æ–‡çŒ®è¡ç”Ÿçš„å¤æ‚æ¡ˆä¾‹ä¸Šï¼ŒChatCFDä¹Ÿè¡¨ç°å‡ºäº†è¾ƒå¼ºçš„æ½œåŠ›ï¼ŒæˆåŠŸç‡ä¸º60-80%ã€‚</li>
<li>ç ”ç©¶è¿˜å‘ç°å¤šç‰©ç†è€¦åˆçš„æµä½“åŠ¨åŠ›å­¦æ¨¡æ‹Ÿæœ‰è¾ƒé«˜çš„èµ„æºéœ€æ±‚ã€‚</li>
<li>å¤§å‹è¯­è¨€æ¨¡å‹åœ¨æŸäº›æƒ…å†µä¸‹å¯èƒ½å­˜åœ¨åå·®ï¼Œå¯¼è‡´ä¸€äº›æŒä¹…æ€§é”™è¯¯ï¼Œå¦‚å°ºå¯¸ä¸ä¸€è‡´ç­‰é—®é¢˜ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.02019">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-3af26f181e7a4ad53856f66ea548e05e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ea76bfd92920ba11392f33c694ba0e65.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-b1b562b04a9a8dc18b7bbf5a2f47c436.jpg" align="middle">
</details>


<h1 id="-15"><a href="#-15" class="headerlink" title=""></a></h1><h2 id="Efficient-Dynamic-Clustering-Based-Document-Compression-for-Retrieval-Augmented-Generation"><a href="#Efficient-Dynamic-Clustering-Based-Document-Compression-for-Retrieval-Augmented-Generation" class="headerlink" title="Efficient Dynamic Clustering-Based Document Compression for   Retrieval-Augmented-Generation"></a>Efficient Dynamic Clustering-Based Document Compression for   Retrieval-Augmented-Generation</h2><p><strong>Authors:Weitao Li, Kaiming Liu, Xiangyu Zhang, Xuanyu Lei, Weizhi Ma, Yang Liu</strong></p>
<p>Retrieval-Augmented Generation (RAG) has emerged as a widely adopted approach for knowledge injection during large language model (LLM) inference in recent years. However, due to their limited ability to exploit fine-grained inter-document relationships, current RAG implementations face challenges in effectively addressing the retrieved noise and redundancy content, which may cause error in the generation results. To address these limitations, we propose an Efficient Dynamic Clustering-based document Compression framework (EDC2-RAG) that utilizes latent inter-document relationships while simultaneously removing irrelevant information and redundant content. We validate our approach, built upon GPT-3.5-Turbo and GPT-4o-mini, on widely used knowledge-QA and Hallucination-Detection datasets. Experimental results show that our method achieves consistent performance improvements across various scenarios and experimental settings, demonstrating strong robustness and applicability. Our code and datasets are available at <a target="_blank" rel="noopener" href="https://github.com/Tsinghua-dhy/EDC-2-RAG">https://github.com/Tsinghua-dhy/EDC-2-RAG</a>. </p>
<blockquote>
<p>è¿‘å¹´æ¥ï¼Œæ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰ä½œä¸ºä¸€ç§å¹¿æ³›é‡‡ç”¨çš„çŸ¥è¯†æ³¨å…¥æ–¹æ³•ï¼Œåœ¨å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ¨ç†ä¸­å—åˆ°å…³æ³¨ã€‚ç„¶è€Œï¼Œç”±äºå½“å‰RAGå®æ–½å¯¹äºç²¾ç»†ç²’åº¦è·¨æ–‡æ¡£å…³ç³»çš„åˆ©ç”¨èƒ½åŠ›æœ‰é™ï¼Œå®ƒä»¬åœ¨æœ‰æ•ˆå¤„ç†æ£€ç´¢åˆ°çš„å™ªå£°å’Œå†—ä½™å†…å®¹æ–¹é¢é¢ä¸´æŒ‘æˆ˜ï¼Œè¿™å¯èƒ½å¯¼è‡´ç”Ÿæˆç»“æœå‡ºç°é”™è¯¯ã€‚ä¸ºäº†è§£å†³è¿™äº›å±€é™æ€§ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åŸºäºé«˜æ•ˆåŠ¨æ€èšç±»çš„æ–‡æ¡£å‹ç¼©æ¡†æ¶ï¼ˆEDC2-RAGï¼‰ï¼Œå®ƒåˆ©ç”¨æ½œåœ¨çš„è·¨æ–‡æ¡£å…³ç³»ï¼ŒåŒæ—¶å»é™¤æ— å…³ä¿¡æ¯å’Œå†—ä½™å†…å®¹ã€‚æˆ‘ä»¬åœ¨å¹¿æ³›ä½¿ç”¨çš„çŸ¥è¯†é—®ç­”å’Œå¹»è§‰æ£€æµ‹æ•°æ®é›†ä¸ŠéªŒè¯äº†æˆ‘ä»¬æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨å„ç§åœºæ™¯å’Œå®éªŒè®¾ç½®ä¸‹å®ç°äº†æ€§èƒ½æ”¹è¿›çš„ä¸€è‡´æ€§ï¼Œè¡¨ç°å‡ºå¼ºå¤§çš„ç¨³å¥æ€§å’Œé€‚ç”¨æ€§ã€‚æˆ‘ä»¬çš„ä»£ç å’Œæ•°æ®é›†å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/Tsinghua-dhy/EDC-2-RAG%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/Tsinghua-dhy/EDC-2-RAGæ‰¾åˆ°ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.03165v3">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>å½“å‰å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ¨ç†ä¸­å¹¿æ³›é‡‡ç”¨æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰æ–¹æ³•å®ç°çŸ¥è¯†æ³¨å…¥ã€‚ç„¶è€Œï¼Œç°æœ‰RAGæ–¹æ³•åœ¨åº”å¯¹æ£€ç´¢å™ªå£°å’Œå†—ä½™å†…å®¹æ—¶é¢ä¸´æŒ‘æˆ˜ï¼Œé™åˆ¶äº†å®ƒä»¬åœ¨å¤„ç†ç²¾ç»†ç²’åº¦æ–‡æ¡£å…³ç³»æ–¹é¢çš„èƒ½åŠ›ï¼Œå¯èƒ½å¯¼è‡´ç”Ÿæˆç»“æœå‡ºç°é”™è¯¯ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬æå‡ºä¸€ç§é«˜æ•ˆåŠ¨æ€èšç±»åŸºç¡€çš„æ–‡æ¡£å‹ç¼©æ¡†æ¶ï¼ˆEDCÂ²-RAGï¼‰ï¼Œåˆ©ç”¨æ½œåœ¨æ–‡æ¡£å…³ç³»çš„åŒæ—¶ç§»é™¤æ— å…³ä¿¡æ¯å’Œå†—ä½™å†…å®¹ã€‚æˆ‘ä»¬åœ¨å¹¿æ³›ä½¿ç”¨çš„çŸ¥è¯†é—®ç­”å’Œå¹»è§†æ£€æµ‹æ•°æ®é›†ä¸ŠéªŒè¯äº†æˆ‘ä»¬åŸºäºGPT-3.5 Turboå’ŒGPT-4o miniçš„æ–¹æ³•ï¼Œå®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å„ç§åœºæ™¯å’Œå®éªŒè®¾ç½®ä¸‹æ€§èƒ½æœ‰æ‰€æå‡ï¼Œå±•ç°å‡ºå¼ºå¤§çš„ç¨³å¥æ€§å’Œé€‚ç”¨æ€§ã€‚æˆ‘ä»¬çš„ä»£ç å’Œæ•°æ®é›†å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/Tsinghua-dhy/EDC-2-RAG%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/Tsinghua-dhy/EDC-2-RAGæ‰¾åˆ°ã€‚</a></p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰æ˜¯LLMçŸ¥è¯†æ³¨å…¥çš„æµè¡Œæ–¹æ³•ï¼Œä½†å­˜åœ¨å¤„ç†æ£€ç´¢å™ªå£°å’Œå†—ä½™å†…å®¹çš„æŒ‘æˆ˜ã€‚</li>
<li>ç°æœ‰RAGæ–¹æ³•éš¾ä»¥æœ‰æ•ˆåˆ©ç”¨ç²¾ç»†ç²’åº¦æ–‡æ¡£å…³ç³»ï¼Œå¯èƒ½å¯¼è‡´ç”Ÿæˆé”™è¯¯ã€‚</li>
<li>æˆ‘ä»¬æå‡ºäº†é«˜æ•ˆåŠ¨æ€èšç±»åŸºç¡€çš„æ–‡æ¡£å‹ç¼©æ¡†æ¶ï¼ˆEDCÂ²-RAGï¼‰ï¼Œæ—¨åœ¨è§£å†³è¿™äº›é—®é¢˜ã€‚</li>
<li>EDCÂ²-RAGåˆ©ç”¨æ½œåœ¨æ–‡æ¡£å…³ç³»ï¼ŒåŒæ—¶ç§»é™¤æ— å…³ä¿¡æ¯å’Œå†—ä½™å†…å®¹ã€‚</li>
<li>æ–¹æ³•åœ¨çŸ¥è¯†é—®ç­”å’Œå¹»è§†æ£€æµ‹æ•°æ®é›†ä¸Šè¿›è¡Œäº†éªŒè¯ï¼Œå®éªŒç»“æœè¡¨æ˜æ€§èƒ½æœ‰æ‰€æå‡ã€‚</li>
<li>æ–¹æ³•åŸºäºGPT-3.5 Turboå’ŒGPT-4o miniæ„å»ºï¼Œè¡¨ç°å‡ºå¼ºå¤§çš„ç¨³å¥æ€§å’Œé€‚ç”¨æ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.03165">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-b4209b4b047abc66d0ac29431507770d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-4c4995774dbd305c85da0a77243c5c19.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-4549a74d16d6b8742bda2492c21b383b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b9e83f92597a9c1d94a00353a69cd479.jpg" align="middle">
</details>


<h1 id="-16"><a href="#-16" class="headerlink" title=""></a></h1><h2 id="Dita-Scaling-Diffusion-Transformer-for-Generalist-Vision-Language-Action-Policy"><a href="#Dita-Scaling-Diffusion-Transformer-for-Generalist-Vision-Language-Action-Policy" class="headerlink" title="Dita: Scaling Diffusion Transformer for Generalist   Vision-Language-Action Policy"></a>Dita: Scaling Diffusion Transformer for Generalist   Vision-Language-Action Policy</h2><p><strong>Authors:Zhi Hou, Tianyi Zhang, Yuwen Xiong, Haonan Duan, Hengjun Pu, Ronglei Tong, Chengyang Zhao, Xizhou Zhu, Yu Qiao, Jifeng Dai, Yuntao Chen</strong></p>
<p>While recent vision-language-action models trained on diverse robot datasets exhibit promising generalization capabilities with limited in-domain data, their reliance on compact action heads to predict discretized or continuous actions constrains adaptability to heterogeneous action spaces. We present Dita, a scalable framework that leverages Transformer architectures to directly denoise continuous action sequences through a unified multimodal diffusion process. Departing from prior methods that condition denoising on fused embeddings via shallow networks, Dita employs in-context conditioning â€“ enabling fine-grained alignment between denoised actions and raw visual tokens from historical observations. This design explicitly models action deltas and environmental nuances. By scaling the diffusion action denoiser alongside the Transformerâ€™s scalability, Dita effectively integrates cross-embodiment datasets across diverse camera perspectives, observation scenes, tasks, and action spaces. Such synergy enhances robustness against various variances and facilitates the successful execution of long-horizon tasks. Evaluations across extensive benchmarks demonstrate state-of-the-art or comparative performance in simulation. Notably, Dita achieves robust real-world adaptation to environmental variances and complex long-horizon tasks through 10-shot finetuning, using only third-person camera inputs. The architecture establishes a versatile, lightweight and open-source baseline for generalist robot policy learning. Project Page: <a target="_blank" rel="noopener" href="https://robodita.github.io/">https://robodita.github.io</a>. </p>
<blockquote>
<p>æœ€è¿‘é’ˆå¯¹å¤šæ ·åŒ–æœºå™¨äººæ•°æ®é›†è®­ç»ƒçš„è§†è§‰-è¯­è¨€-åŠ¨ä½œæ¨¡å‹ï¼Œåœ¨æœ‰é™é¢†åŸŸå†…å±•ç°å‡ºä»¤äººé¼“èˆçš„æ³›åŒ–èƒ½åŠ›ã€‚ç„¶è€Œï¼Œè¿™äº›æ¨¡å‹ä¾èµ–äºç´§å‡‘çš„åŠ¨ä½œå¤´æ¥é¢„æµ‹ç¦»æ•£æˆ–è¿ç»­åŠ¨ä½œï¼Œè¿™é™åˆ¶äº†å…¶åœ¨å¼‚æ„åŠ¨ä½œç©ºé—´ä¸­çš„é€‚åº”æ€§ã€‚æˆ‘ä»¬æå‡ºäº†Ditaï¼Œä¸€ä¸ªå¯æ‰©å±•çš„æ¡†æ¶ï¼Œå®ƒåˆ©ç”¨Transformeræ¶æ„é€šè¿‡ç»Ÿä¸€çš„å¤šæ¨¡æ€æ‰©æ•£è¿‡ç¨‹ç›´æ¥å¯¹è¿ç»­åŠ¨ä½œåºåˆ—è¿›è¡Œå»å™ªã€‚ä¸ä»¥å¾€ä¾èµ–äºæµ…å±‚ç½‘ç»œèåˆåµŒå…¥è¿›è¡Œå»å™ªçš„æ–¹æ³•ä¸åŒï¼ŒDitaé‡‡ç”¨ä¸Šä¸‹æ–‡æ¡ä»¶â€”â€”å®ç°åœ¨å»å™ªåŠ¨ä½œä¸æ¥è‡ªå†å²è§‚å¯Ÿçš„åŸç”Ÿè§†è§‰æ ‡è®°ä¹‹é—´çš„ç²¾ç»†å¯¹é½ã€‚è¿™ç§è®¾è®¡æ˜¾å¼åœ°å»ºæ¨¡åŠ¨ä½œå·®å¼‚å’Œç¯å¢ƒç»†å¾®å·®åˆ«ã€‚é€šè¿‡æ‰©æ•£åŠ¨ä½œå»å™ªå™¨ä¸Transformerçš„å¯æ‰©å±•æ€§ç›¸ç»“åˆï¼ŒDitaæœ‰æ•ˆåœ°æ•´åˆäº†è·¨ä¸åŒç›¸æœºè§’åº¦ã€è§‚å¯Ÿåœºæ™¯ã€ä»»åŠ¡å’ŒåŠ¨ä½œç©ºé—´çš„è·¨ä½“æ€æ•°æ®é›†ã€‚è¿™ç§ååŒä½œç”¨å¢å¼ºäº†å¯¹å„ç§å˜é‡çš„ç¨³å¥æ€§ï¼Œå¹¶ä¿ƒè¿›äº†é•¿æœŸä»»åŠ¡çš„æˆåŠŸæ‰§è¡Œã€‚åœ¨å¹¿æ³›åŸºå‡†æµ‹è¯•ä¸Šçš„è¯„ä¼°è¯æ˜äº†å…¶åœ¨ä»¿çœŸç¯å¢ƒä¸­çš„æœ€æ–°æˆ–ç›¸å½“æ€§èƒ½ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼ŒDitaä»…é€šè¿‡ç¬¬ä¸‰äººç§°ç›¸æœºè¾“å…¥å®ç°äº†å¯¹ç¯å¢ƒå’Œå¤æ‚é•¿æœŸä»»åŠ¡çš„ç¨³å¥é€‚åº”ï¼Œåªéœ€è¿›è¡Œ10æ¬¡å¾®è°ƒå³å¯ã€‚è¯¥æ¶æ„ä¸ºé€šç”¨æœºå™¨äººç­–ç•¥å­¦ä¹ å»ºç«‹äº†é€šç”¨ã€è½»ä¾¿å’Œå¼€æºçš„åŸºçº¿ã€‚é¡¹ç›®é¡µé¢ï¼š<a target="_blank" rel="noopener" href="https://robodita.github.io./">https://robodita.github.ioã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.19757v2">PDF</a> Preprint; <a target="_blank" rel="noopener" href="https://robodita.github.io/">https://robodita.github.io</a>; To appear in ICCV2025</p>
<p><strong>Summary</strong></p>
<p>è¿‘æœŸåŸºäºå¤šæ ·åŒ–æœºå™¨äººæ•°æ®é›†è®­ç»ƒçš„è§†è§‰-è¯­è¨€-åŠ¨ä½œæ¨¡å‹åœ¨æœ‰é™é¢†åŸŸå†…æ•°æ®ä¸Šå±•ç°å‡ºè‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›ï¼Œä½†å®ƒä»¬é¢„æµ‹ç¦»æ•£æˆ–è¿ç»­åŠ¨ä½œæ—¶ä¾èµ–äºç´§å‡‘çš„åŠ¨ä½œå¤´ï¼Œè¿™é™åˆ¶äº†å®ƒä»¬åœ¨å¼‚æ„åŠ¨ä½œç©ºé—´ä¸­çš„é€‚åº”æ€§ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬æå‡ºäº†Ditaæ¡†æ¶ï¼Œå®ƒåˆ©ç”¨Transformeræ¶æ„é€šè¿‡ç»Ÿä¸€çš„å¤šæ¨¡æ€æ‰©æ•£è¿‡ç¨‹ç›´æ¥å¯¹è¿ç»­åŠ¨ä½œåºåˆ—è¿›è¡Œå»å™ªã€‚ä¸åŒäºå…ˆå‰ä¾èµ–äºèåˆåµŒå…¥å¹¶é€šè¿‡æµ…å±‚ç½‘ç»œè¿›è¡Œæ¡ä»¶å»å™ªçš„æ–¹æ³•ï¼ŒDitaé‡‡ç”¨ä¸Šä¸‹æ–‡æ¡ä»¶ï¼Œå®ç°äº†å»å™ªåŠ¨ä½œä¸æ¥è‡ªå†å²è§‚å¯Ÿçš„åŸç”Ÿè§†è§‰æ ‡è®°ä¹‹é—´çš„ç²¾ç»†å¯¹é½ã€‚è¿™ç§è®¾è®¡æ˜¾å¼åœ°æ¨¡æ‹ŸåŠ¨ä½œå·®å¼‚å’Œç¯å¢ƒç»†å¾®å·®åˆ«ã€‚é€šè¿‡æ‰©æ•£åŠ¨ä½œå»å™ªå™¨ä¸Transformerçš„å¯æ‰©å±•æ€§ç›¸ç»“åˆï¼ŒDitaèƒ½å¤Ÿæœ‰æ•ˆåœ°æ•´åˆè·¨ä¸åŒç›¸æœºè§’åº¦ã€è§‚å¯Ÿåœºæ™¯ã€ä»»åŠ¡å’ŒåŠ¨ä½œç©ºé—´çš„è·¨ä½“æ€æ•°æ®é›†ã€‚è¿™ç§ååŒå¢å¼ºäº†å¯¹å„ç§å˜åŒ–çš„ç¨³å¥æ€§ï¼Œå¹¶ä¿ƒè¿›äº†é•¿æœŸä»»åŠ¡çš„æˆåŠŸæ‰§è¡Œã€‚åœ¨å¹¿æ³›çš„åŸºå‡†æµ‹è¯•ä¸Šè¿›è¡Œçš„è¯„ä¼°è¡¨æ˜ï¼ŒDitaåœ¨æ¨¡æ‹Ÿç¯å¢ƒä¸­è¾¾åˆ°äº†æœ€æ–°æˆ–ç›¸å½“çš„æ€§èƒ½æ°´å¹³ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼ŒDitaä»…é€šè¿‡ç¬¬ä¸‰äººç§°ç›¸æœºè¾“å…¥ï¼Œå°±èƒ½åœ¨çœŸå®ä¸–ç•Œç¯å¢ƒä¸­å®ç°å¯¹ç¯å¢ƒå˜åŒ–å’Œå¤æ‚é•¿æœŸä»»åŠ¡çš„ç¨³å¥é€‚åº”ï¼Œå¹¶é€šè¿‡10æ¬¡å¾®è°ƒå°„å‡»è¾¾åˆ°ç¨³å¥æ€§ã€‚è¯¥æ¶æ„ä¸ºé€šç”¨æœºå™¨äººæ”¿ç­–å­¦ä¹ å»ºç«‹äº†çµæ´»ã€è½»ä¾¿å’Œå¼€æºçš„åŸºçº¿ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>è¿‘æœŸè§†è§‰-è¯­è¨€-åŠ¨ä½œæ¨¡å‹åœ¨å¤šæ ·åŒ–æœºå™¨äººæ•°æ®é›†ä¸Šå±•ç°å‡ºè‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›ã€‚</li>
<li>ç°æœ‰æ¨¡å‹åœ¨é¢„æµ‹è¿ç»­åŠ¨ä½œæ–¹é¢å­˜åœ¨ä¾èµ–ç´§å‡‘åŠ¨ä½œå¤´çš„é™åˆ¶ï¼Œå½±å“åœ¨å¼‚æ„åŠ¨ä½œç©ºé—´ä¸­çš„é€‚åº”æ€§ã€‚</li>
<li>Ditaæ¡†æ¶åˆ©ç”¨Transformeræ¶æ„ç›´æ¥å¯¹è¿ç»­åŠ¨ä½œåºåˆ—è¿›è¡Œå»å™ªï¼Œæé«˜æ¨¡å‹é€‚åº”æ€§ã€‚</li>
<li>Ditaé‡‡ç”¨ä¸Šä¸‹æ–‡æ¡ä»¶æ–¹æ³•ï¼Œå®ç°å»å™ªåŠ¨ä½œä¸åŸç”Ÿè§†è§‰æ ‡è®°çš„ç²¾ç»†å¯¹é½ã€‚</li>
<li>æ‰©æ•£åŠ¨ä½œå»å™ªå™¨ä¸Transformerçš„ç»“åˆå¢å¼ºäº†æ¨¡å‹çš„ç¨³å¥æ€§ï¼Œå¹¶ä¿ƒè¿›äº†é•¿æœŸä»»åŠ¡çš„æ‰§è¡Œã€‚</li>
<li>Ditaåœ¨æ¨¡æ‹Ÿç¯å¢ƒä¸­è¾¾åˆ°æœ€æ–°æˆ–ç›¸å½“çš„æ€§èƒ½æ°´å¹³ï¼Œå¹¶åœ¨çœŸå®ä¸–ç•Œç¯å¢ƒä¸­å®ç°å¯¹ç¯å¢ƒå˜åŒ–å’Œå¤æ‚é•¿æœŸä»»åŠ¡çš„é€‚åº”ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.19757">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-2858411e5c8ade32917a8cddf74f956f.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-7084a4872835e2d3bb86b9c07f95c029.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-e0040aaf9dc111b2bdb2dc8ecdf1ceaa.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-c6c4179b02220164b602e40441f0658f.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-c5d1af79bedd9a6bfa81091f95cb7981.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-a93699852682634a909cb4615760d9a8.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ab8c62b49b5686f87cb75573a01c6ac6.jpg" align="middle">
</details>


<h1 id="-17"><a href="#-17" class="headerlink" title=""></a></h1><h2 id="Error-Classification-of-Large-Language-Models-on-Math-Word-Problems-A-Dynamically-Adaptive-Framework"><a href="#Error-Classification-of-Large-Language-Models-on-Math-Word-Problems-A-Dynamically-Adaptive-Framework" class="headerlink" title="Error Classification of Large Language Models on Math Word Problems: A   Dynamically Adaptive Framework"></a>Error Classification of Large Language Models on Math Word Problems: A   Dynamically Adaptive Framework</h2><p><strong>Authors:Yuhong Sun, Zhangyue Yin, Xuanjing Huang, Xipeng Qiu, Hui Zhao</strong></p>
<p>Large Language Models (LLMs) have demonstrated remarkable capabilities across various domains. Math Word Problems (MWPs) serve as a crucial benchmark for evaluating LLMsâ€™ reasoning abilities. While most research primarily focuses on improving accuracy, it often neglects understanding and addressing the underlying patterns of errors. Current error classification methods rely on static and predefined categories, which limit their ability to capture the full spectrum of error patterns in mathematical reasoning. To enable systematic error analysis, we collect error samples from 15 different LLMs of varying sizes across four distinct MWP datasets using multiple sampling strategies. Based on this extensive collection, we introduce MWPES-300K, a comprehensive dataset containing 304,865 error samples that cover diverse error patterns and reasoning paths. To reduce human bias and enable fine-grained analysis of error patterns, we propose a novel framework for automated dynamic error classification in mathematical reasoning. Experimental results demonstrate that dataset characteristics significantly shape error patterns, which evolve from basic to complex manifestations as model capabilities increase. With deeper insights into error patterns, we propose Error-Aware Prompting (EAP) that incorporates common error patterns as explicit guidance, leading to significant improvements in mathematical reasoning performance. </p>
<blockquote>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å·²åœ¨å„ä¸ªé¢†åŸŸå±•ç°å‡ºæ˜¾è‘—çš„èƒ½åŠ›ã€‚æ•°å­¦åº”ç”¨é¢˜ï¼ˆMWPï¼‰æ˜¯è¯„ä¼°LLMæ¨ç†èƒ½åŠ›çš„é‡è¦åŸºå‡†ã€‚è™½ç„¶å¤§å¤šæ•°ç ”ç©¶ä¸»è¦é›†ä¸­åœ¨æé«˜å‡†ç¡®æ€§ä¸Šï¼Œä½†å®ƒå¾€å¾€å¿½è§†äº†ç†è§£å’Œè§£å†³é”™è¯¯æ¨¡å¼çš„åº•å±‚åŸå› ã€‚å½“å‰çš„é”™è¯¯åˆ†ç±»æ–¹æ³•ä¾èµ–äºé™æ€å’Œé¢„å®šä¹‰çš„ç±»åˆ«ï¼Œè¿™é™åˆ¶äº†å®ƒä»¬æ•æ‰æ•°å­¦æ¨ç†ä¸­é”™è¯¯æ¨¡å¼å…¨è²Œçš„èƒ½åŠ›ã€‚ä¸ºäº†è¿›è¡Œç³»ç»Ÿçš„é”™è¯¯åˆ†æï¼Œæˆ‘ä»¬ä»ä¸åŒå¤§å°çš„15ä¸ªLLMä¸­ï¼Œä½¿ç”¨å¤šç§é‡‡æ ·ç­–ç•¥ï¼Œæ”¶é›†äº†è·¨å››ä¸ªä¸åŒMWPæ•°æ®é›†çš„é”™è¯¯æ ·æœ¬ã€‚åŸºäºå¹¿æ³›çš„æ”¶é›†ï¼Œæˆ‘ä»¬æ¨å‡ºäº†MWPES-300Kï¼Œè¿™æ˜¯ä¸€ä¸ªåŒ…å«304865ä¸ªé”™è¯¯æ ·æœ¬çš„ç»¼åˆæ•°æ®é›†ï¼Œæ¶µç›–äº†å¤šç§é”™è¯¯æ¨¡å¼å’Œæ¨ç†è·¯å¾„ã€‚ä¸ºäº†å‡å°‘äººä¸ºåè§å¹¶å®ç°å¯¹é”™è¯¯æ¨¡å¼çš„ç²¾ç»†åˆ†æï¼Œæˆ‘ä»¬æå‡ºäº†ç”¨äºæ•°å­¦æ¨ç†çš„è‡ªåŠ¨åŒ–åŠ¨æ€é”™è¯¯åˆ†ç±»çš„æ–°æ¡†æ¶ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œæ•°æ®é›†ç‰¹æ€§æ˜¾è‘—å½±å“é”™è¯¯æ¨¡å¼ï¼Œéšç€æ¨¡å‹èƒ½åŠ›çš„æé«˜ï¼Œé”™è¯¯æ¨¡å¼ä»åŸºæœ¬åˆ°å¤æ‚çš„è¡¨ç°å½¢å¼éƒ½ä¼šå‘ç”Ÿå˜åŒ–ã€‚é€šè¿‡å¯¹é”™è¯¯æ¨¡å¼æœ‰æ›´æ·±å…¥çš„äº†è§£ï¼Œæˆ‘ä»¬æå‡ºäº†ç»“åˆå¸¸è§é”™è¯¯æ¨¡å¼ä½œä¸ºæ˜ç¡®æŒ‡å¯¼çš„â€œé”™è¯¯æ„ŸçŸ¥æç¤ºâ€ï¼ˆEAPï¼‰ï¼Œè¿™æå¤§åœ°æé«˜äº†æ•°å­¦æ¨ç†æ€§èƒ½ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.15581v2">PDF</a> 28 pages, 10 figures, accepted by Findings of EMNLP2025</p>
<p><strong>Summary</strong></p>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å¤šé¢†åŸŸå±•ç°å‡ºå“è¶Šçš„èƒ½åŠ›ï¼Œæ•°å­¦æ–‡å­—é¢˜ï¼ˆMWPsï¼‰æ˜¯è¯„ä¼°LLMsæ¨ç†èƒ½åŠ›çš„é‡è¦åŸºå‡†ã€‚ç°æœ‰ç ”ç©¶å¤šå…³æ³¨æé«˜å‡†ç¡®ç‡ï¼Œå´å¿½è§†äº†ç†è§£å’Œè§£å†³åº•å±‚é”™è¯¯æ¨¡å¼ã€‚æˆ‘ä»¬æ”¶é›†äº†æ¥è‡ªä¸åŒè§„æ¨¡å’Œä¸åŒæ•°å­¦æ–‡å­—é¢˜æ•°æ®é›†çš„é”™è¯¯æ ·æœ¬ï¼Œå»ºç«‹äº†åŒ…å«å¤šç§é”™è¯¯æ¨¡å¼å’Œæ¨ç†è·¯å¾„çš„ç»¼åˆæ•°æ®é›†MWPES-300Kã€‚ä¸ºäº†å‡å°‘äººä¸ºåè§å¹¶ç²¾ç»†åˆ†æé”™è¯¯æ¨¡å¼ï¼Œæˆ‘ä»¬æå‡ºäº†è‡ªåŠ¨åŠ¨æ€æ•°å­¦æ¨ç†é”™è¯¯åˆ†ç±»çš„æ–°æ¡†æ¶ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œæ•°æ®é›†ç‰¹æ€§æ˜¾è‘—å½±å“é”™è¯¯æ¨¡å¼ï¼Œéšç€æ¨¡å‹èƒ½åŠ›çš„æé«˜ï¼Œé”™è¯¯æ¨¡å¼ä»åŸºç¡€åˆ°å¤æ‚æ¼”å˜ã€‚åŸºäºå¯¹é”™è¯¯æ¨¡å¼çš„æ·±å…¥äº†è§£ï¼Œæˆ‘ä»¬æå‡ºäº†ç»“åˆå¸¸è§é”™è¯¯æ¨¡å¼ä½œä¸ºæ˜ç¡®æŒ‡å¯¼çš„é”™è¯¯æ„ŸçŸ¥æç¤ºï¼ˆEAPï¼‰ï¼Œæ˜¾è‘—æé«˜äº†æ•°å­¦æ¨ç†æ€§èƒ½ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>LLMsåœ¨æ•°å­¦æ–‡å­—é¢˜ï¼ˆMWPsï¼‰ä¸Šçš„è¡¨ç°æ˜¯é‡è¦çš„è¯„ä¼°åŸºå‡†ã€‚</li>
<li>ç°æœ‰ç ”ç©¶ä¸»è¦å…³æ³¨æé«˜LLMsçš„å‡†ç¡®ç‡ï¼Œä½†å¿½è§†äº†é”™è¯¯æ¨¡å¼çš„æ·±å…¥åˆ†æã€‚</li>
<li>æˆ‘ä»¬å»ºç«‹äº†ä¸€ä¸ªç»¼åˆæ•°æ®é›†MWPES-300Kï¼ŒåŒ…å«å¤šç§é”™è¯¯æ¨¡å¼å’Œæ¨ç†è·¯å¾„ã€‚</li>
<li>ä¸ºå‡å°‘äººä¸ºåè§å¹¶ç²¾ç»†åˆ†æé”™è¯¯æ¨¡å¼ï¼Œæˆ‘ä»¬æå‡ºäº†è‡ªåŠ¨åŠ¨æ€æ•°å­¦æ¨ç†é”™è¯¯åˆ†ç±»çš„æ–°æ¡†æ¶ã€‚</li>
<li>æ•°æ®é›†ç‰¹æ€§å¯¹é”™è¯¯æ¨¡å¼æœ‰æ˜¾è‘—å½±å“ï¼Œé”™è¯¯æ¨¡å¼éšç€æ¨¡å‹èƒ½åŠ›çš„æé«˜è€Œæ¼”å˜ã€‚</li>
<li>åŸºäºå¯¹é”™è¯¯æ¨¡å¼çš„æ·±å…¥äº†è§£ï¼Œæˆ‘ä»¬æå‡ºäº†é”™è¯¯æ„ŸçŸ¥æç¤ºï¼ˆEAPï¼‰æ–¹æ³•ï¼Œè¯¥æ–¹æ³•ç»“åˆå¸¸è§é”™è¯¯æ¨¡å¼ä½œä¸ºæ˜ç¡®æŒ‡å¯¼ï¼Œæœ‰æ•ˆæé«˜æ•°å­¦æ¨ç†æ€§èƒ½ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.15581">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-8a9ecdb0920b1ef290700c8f02e00903.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-7bd66de101a9ddf072c503bf326d3b76.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-69f325176268ed98f1b42f46fddd4901.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-99b3d61832c08ec86ebf111a00561e13.jpg" align="middle">
</details>


<h1 id="-18"><a href="#-18" class="headerlink" title=""></a></h1><h2 id="Bias-in-Decision-Making-for-AIâ€™s-Ethical-Dilemmas-A-Comparative-Study-of-ChatGPT-and-Claude"><a href="#Bias-in-Decision-Making-for-AIâ€™s-Ethical-Dilemmas-A-Comparative-Study-of-ChatGPT-and-Claude" class="headerlink" title="Bias in Decision-Making for AIâ€™s Ethical Dilemmas: A Comparative Study   of ChatGPT and Claude"></a>Bias in Decision-Making for AIâ€™s Ethical Dilemmas: A Comparative Study   of ChatGPT and Claude</h2><p><strong>Authors:Yile Yan, Yuqi Zhu, Wentao Xu</strong></p>
<p>Recent advances in Large Language Models (LLMs) have enabled human-like responses across various tasks, raising questions about their ethical decision-making capabilities and potential biases. This study systematically evaluates how nine popular LLMs (both open-source and closed-source) respond to ethical dilemmas involving protected attributes. Across 50,400 trials spanning single and intersectional attribute combinations in four dilemma scenarios (protective vs. harmful), we assess modelsâ€™ ethical preferences, sensitivity, stability, and clustering patterns. Results reveal significant biases in protected attributes in all models, with differing preferences depending on model type and dilemma context. Notably, open-source LLMs show stronger preferences for marginalized groups and greater sensitivity in harmful scenarios, while closed-source models are more selective in protective situations and tend to favor mainstream groups. We also find that ethical behavior varies across dilemma types: LLMs maintain consistent patterns in protective scenarios but respond with more diverse and cognitively demanding decisions in harmful ones. Furthermore, models display more pronounced ethical tendencies under intersectional conditions than in single-attribute settings, suggesting that complex inputs reveal deeper biases. These findings highlight the need for multi-dimensional, context-aware evaluation of LLMsâ€™ ethical behavior and offer a systematic evaluation and approach to understanding and addressing fairness in LLM decision-making. </p>
<blockquote>
<p>è¿‘æœŸå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„è¿›æ­¥ä½¿å¾—åœ¨å„ç§ä»»åŠ¡ä¸­éƒ½èƒ½äº§ç”Ÿç±»ä¼¼äººç±»çš„ååº”ï¼Œè¿™å¼•å‘äº†å…³äºå…¶ä¼¦ç†å†³ç­–èƒ½åŠ›å’Œæ½œåœ¨åè§çš„é—®é¢˜ã€‚æœ¬ç ”ç©¶ç³»ç»Ÿåœ°è¯„ä¼°äº†ä¹ç§æµè¡Œçš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆåŒ…æ‹¬å¼€æºå’Œé—­æºï¼‰å¦‚ä½•åº”å¯¹æ¶‰åŠå—ä¿æŠ¤å±æ€§çš„é“å¾·å›°å¢ƒã€‚åœ¨è·¨è¶Šå•ä¸€å±æ€§å’Œäº¤å‰å±æ€§ç»„åˆçš„å››ç§å›°å¢ƒåœºæ™¯ï¼ˆä¿æŠ¤æ€§å¯¹æœ‰å®³æ€§ï¼‰çš„50400æ¬¡è¯•éªŒä¸­ï¼Œæˆ‘ä»¬è¯„ä¼°äº†æ¨¡å‹çš„é“å¾·åå¥½ã€æ•æ„Ÿæ€§ã€ç¨³å®šæ€§å’Œèšç±»æ¨¡å¼ã€‚ç»“æœè¡¨æ˜ï¼Œæ‰€æœ‰æ¨¡å‹åœ¨å—ä¿æŠ¤å±æ€§ä¸Šéƒ½å­˜åœ¨æ˜¾è‘—çš„åè§ï¼Œä¸”åå¥½å› æ¨¡å‹ç±»å‹å’Œå›°å¢ƒèƒŒæ™¯è€Œå¼‚ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œå¼€æºLLMå¯¹è¾¹ç¼˜ç¾¤ä½“æœ‰æ›´å¼ºçš„åå¥½ï¼Œåœ¨æœ‰å®³åœºæ™¯ä¸­æ›´ä¸ºæ•æ„Ÿï¼Œè€Œé—­æºæ¨¡å‹åœ¨ä¿æŠ¤æƒ…å†µä¸‹æ›´ä¸ºæŒ‘å‰”ï¼Œæ›´å€¾å‘äºä¸»æµç¾¤ä½“ã€‚æˆ‘ä»¬è¿˜å‘ç°ï¼Œé“å¾·è¡Œä¸ºå› å›°å¢ƒç±»å‹è€Œå¼‚ï¼šLLMåœ¨ä¿æŠ¤åœºæ™¯ä¸­ä¿æŒäº†ä¸€è‡´çš„æ¨¡å¼ï¼Œä½†åœ¨æœ‰å®³åœºæ™¯ä¸­åšå‡ºäº†æ›´å¤šæ ·åŒ–ã€æ›´å…·è®¤çŸ¥æŒ‘æˆ˜çš„å†³å®šã€‚æ­¤å¤–ï¼Œä¸å•ä¸€å±æ€§è®¾ç½®ç›¸æ¯”ï¼Œæ¨¡å‹åœ¨äº¤å‰æ¡ä»¶ä¸‹çš„é“å¾·å€¾å‘æ›´ä¸ºæ˜æ˜¾ï¼Œè¿™è¡¨æ˜å¤æ‚çš„è¾“å…¥æ­ç¤ºäº†æ›´æ·±çš„åè§ã€‚è¿™äº›å‘ç°å¼ºè°ƒäº†å¤šç»´ã€ä¸Šä¸‹æ–‡æ„ŸçŸ¥çš„LLMä¼¦ç†è¡Œä¸ºè¯„ä¼°çš„å¿…è¦æ€§ï¼Œä¸ºæˆ‘ä»¬æä¾›äº†ä¸€ä¸ªç³»ç»Ÿçš„è¯„ä¼°å’Œè§£å†³å¤§å‹è¯­è¨€æ¨¡å‹å†³ç­–ä¸­å…¬å¹³é—®é¢˜çš„æ–¹æ³•ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.10484v3">PDF</a> This paper has been accepted by International AAAI Conference on Web   and Social Media 2026 (ICWSM 2026), sunny Los Angeles, California</p>
<p><strong>Summary</strong></p>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„æœ€æ–°è¿›å±•ä½¿å¾—å®ƒä»¬èƒ½å¤Ÿåœ¨å„ç§ä»»åŠ¡ä¸­åšå‡ºç±»ä¼¼äººç±»çš„å“åº”ï¼Œå¼•å‘å…³äºå…¶ä¼¦ç†å†³ç­–èƒ½åŠ›å’Œæ½œåœ¨åè§çš„é—®é¢˜ã€‚æœ¬ç ”ç©¶ç³»ç»Ÿåœ°è¯„ä¼°äº†ä¹ç§æµè¡Œçš„LLMï¼ˆåŒ…æ‹¬å¼€æºå’Œé—­æºï¼‰åœ¨æ¶‰åŠä¿æŠ¤å±æ€§çš„é“å¾·å›°å¢ƒä¸­çš„ååº”ã€‚ç ”ç©¶è¿›è¡Œäº†è¶…è¿‡å››ä¸‡äº”åƒæ¬¡è¯•éªŒï¼Œå‘ç°æ¨¡å‹åœ¨å¤„ç†å››ç§ä¸åŒå›°å¢ƒä¸­çš„å•ä¸€å±æ€§å’Œè·¨ç•Œå±æ€§ç»„åˆæ—¶å­˜åœ¨æ˜æ˜¾çš„åè§ã€‚å°¤å…¶æ˜¯å¼€æºLLMæ›´å€¾å‘äºä¿æŠ¤è¾¹ç¼˜ç¾¤ä½“å¹¶å¯¹æœ‰å®³åœºæ™¯æ›´ä¸ºæ•æ„Ÿï¼Œè€Œé—­æºæ¨¡å‹æ›´å€¾å‘äºä¿æŠ¤ä¸»æµç¾¤ä½“å¹¶é€‰æ‹©æ€§åœ°è¿›è¡Œé˜²æŠ¤ã€‚æ­¤å¤–ï¼Œè¿˜å‘ç°LLMåœ¨ä¸åŒç±»å‹çš„å›°å¢ƒä¸­è¡¨ç°å‡ºä¸åŒçš„é“å¾·è¡Œä¸ºæ¨¡å¼ï¼Œå¹¶åœ¨å¤æ‚æƒ…å¢ƒä¸‹æ˜¾ç¤ºå‡ºæ›´æ·±åˆ»çš„åè§ã€‚å› æ­¤ï¼Œéœ€è¦å¤šç»´åº¦ã€åŸºäºæƒ…å¢ƒåœ°è¯„ä¼°LLMçš„ä¼¦ç†è¡Œä¸ºã€‚ç ”ç©¶ä¸ºäººä»¬æä¾›äº†ä¸€ä¸ªç³»ç»Ÿæ€§çš„è¯„ä»·æ–¹æ³•æ¥äº†è§£å’Œè§£å†³LLMå†³ç­–ä¸­çš„å…¬å¹³æ€§é—®é¢˜ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>LLMsåœ¨å¤„ç†æ¶‰åŠä¿æŠ¤å±æ€§çš„é“å¾·å›°å¢ƒæ—¶è¡¨ç°å‡ºæ˜æ˜¾çš„åè§ã€‚</li>
<li>å¼€æºLLMå€¾å‘äºä¿æŠ¤è¾¹ç¼˜ç¾¤ä½“ï¼Œå¯¹æœ‰å®³åœºæ™¯æ›´æ•æ„Ÿï¼›é—­æºæ¨¡å‹åˆ™æ›´å€¾å‘äºä¿æŠ¤ä¸»æµç¾¤ä½“ã€‚</li>
<li>LLMçš„ä¼¦ç†è¡Œä¸ºåœ¨ä¸åŒç±»å‹çš„å›°å¢ƒä¸­å­˜åœ¨å·®å¼‚ï¼Œè¡¨ç°ä¸ºåœ¨å¤æ‚æƒ…å¢ƒä¸‹çš„å†³ç­–æ›´ä¸ºå¤šæ ·å’Œè®¤çŸ¥éœ€æ±‚æ›´é«˜ã€‚</li>
<li>æ¨¡å‹åœ¨å¤„ç†è·¨ç•Œå±æ€§ç»„åˆæ—¶æ˜¾ç¤ºå‡ºæ›´æ·±åˆ»çš„åè§ã€‚</li>
<li>éœ€è¦å¤šç»´åº¦ã€åŸºäºæƒ…å¢ƒåœ°è¯„ä¼°LLMçš„ä¼¦ç†è¡Œä¸ºï¼Œä»¥ç¡®ä¿å†³ç­–çš„å…¬å¹³æ€§ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.10484">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-2e3221368c23aa9dd5f9a4d2a4fd8d97.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e6d695dbd6af0c7258ed9a7f172cc4b0.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-ba479860b35149d4ebd3a2c0be13ccb9.jpg" align="middle">
</details>


<h1 id="-19"><a href="#-19" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-09-10/LLM/">https://kedreamix.github.io/Talk2Paper/Paper/2025-09-10/LLM/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/LLM/">
                                    <span class="chip bg-color">LLM</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-09-10/Agent/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-71bb0a6592c54b405fa40a2e9e64055b.jpg" class="responsive-img" alt="Agent">
                        
                        <span class="card-title">Agent</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Agent æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-09-10  AxelSMOTE An Agent-Based Oversampling Algorithm for Imbalanced   Classification
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-09-10
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Agent/" class="post-category">
                                    Agent
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Agent/">
                        <span class="chip bg-color">Agent</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-09-10/R1_Reasoning/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-c29b0f436b40b28911b22bf67cd90fc8.jpg" class="responsive-img" alt="R1_Reasoning">
                        
                        <span class="card-title">R1_Reasoning</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            R1_Reasoning æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-09-10  On the Same Wavelength? Evaluating Pragmatic Reasoning in Language   Models across Broad Concepts
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-09-10
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/R1-Reasoning/" class="post-category">
                                    R1_Reasoning
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/R1-Reasoning/">
                        <span class="chip bg-color">R1_Reasoning</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">30930.2k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
