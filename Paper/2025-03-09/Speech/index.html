<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Speech">
    <meta name="description" content="Speech æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-03-09  Self-Supervised Models for Phoneme Recognition Applications in   Children&#39;s Speech for Reading Learning">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>Speech | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://pica.zhimg.com/v2-1e06eab19b066abfa2e65ec81756cd6d.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Speech</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/Speech/">
                                <span class="chip bg-color">Speech</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/Speech/" class="post-category">
                                Speech
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-03-09
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-03-14
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    7.6k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    31 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-03-09-æ›´æ–°"><a href="#2025-03-09-æ›´æ–°" class="headerlink" title="2025-03-09 æ›´æ–°"></a>2025-03-09 æ›´æ–°</h1><h2 id="Self-Supervised-Models-for-Phoneme-Recognition-Applications-in-Childrenâ€™s-Speech-for-Reading-Learning"><a href="#Self-Supervised-Models-for-Phoneme-Recognition-Applications-in-Childrenâ€™s-Speech-for-Reading-Learning" class="headerlink" title="Self-Supervised Models for Phoneme Recognition: Applications in   Childrenâ€™s Speech for Reading Learning"></a>Self-Supervised Models for Phoneme Recognition: Applications in   Childrenâ€™s Speech for Reading Learning</h2><p><strong>Authors:Lucas Block Medin, Thomas Pellegrini, Lucile Gelin</strong></p>
<p>Child speech recognition is still an underdeveloped area of research due to the lack of data (especially on non-English languages) and the specific difficulties of this task. Having explored various architectures for child speech recognition in previous work, in this article we tackle recent self-supervised models. We first compare wav2vec 2.0, HuBERT and WavLM models adapted to phoneme recognition in French child speech, and continue our experiments with the best of them, WavLM base+. We then further adapt it by unfreezing its transformer blocks during fine-tuning on child speech, which greatly improves its performance and makes it significantly outperform our base model, a Transformer+CTC. Finally, we study in detail the behaviour of these two models under the real conditions of our application, and show that WavLM base+ is more robust to various reading tasks and noise levels. Index Terms: speech recognition, child speech, self-supervised learning </p>
<blockquote>
<p>å„¿ç«¥è¯­éŸ³è¯†åˆ«ä»ç„¶æ˜¯ä¸€ä¸ªç ”ç©¶ä¸è¶³é¢†åŸŸï¼Œç”±äºç¼ºä¹æ•°æ®ï¼ˆå°¤å…¶æ˜¯éè‹±è¯­æ•°æ®ï¼‰ä»¥åŠè¯¥ä»»åŠ¡çš„ç‰¹å®šéš¾åº¦ã€‚åœ¨ä¹‹å‰çš„å·¥ä½œä¸­ï¼Œæˆ‘ä»¬æ¢ç´¢äº†å„ç§å„¿ç«¥è¯­éŸ³è¯†åˆ«æ¶æ„ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬å…³æ³¨æœ€æ–°çš„è‡ªç›‘ç£æ¨¡å‹ã€‚æˆ‘ä»¬é¦–å…ˆå¯¹æ¯”äº†é’ˆå¯¹æ³•è¯­å„¿ç«¥è¯­éŸ³çš„éŸ³ç´ è¯†åˆ«è€Œæ”¹ç¼–çš„wav2vec 2.0ã€HuBERTå’ŒWavLMæ¨¡å‹ï¼Œå¹¶ä½¿ç”¨å…¶ä¸­è¡¨ç°æœ€ä½³çš„WavLM base+ç»§ç»­è¿›è¡Œå®éªŒã€‚ç„¶åæˆ‘ä»¬é€šè¿‡å¾®è°ƒå„¿ç«¥è¯­éŸ³æ—¶è§£å†»å…¶å˜å‹å™¨å—è¿›ä¸€æ­¥è°ƒæ•´å®ƒï¼Œè¿™æå¤§åœ°æé«˜äº†å…¶æ€§èƒ½å¹¶ä½¿å…¶æ˜¾è‘—ä¼˜äºæˆ‘ä»¬çš„åŸºå‡†æ¨¡å‹Transformer+CTCã€‚æœ€åï¼Œæˆ‘ä»¬è¯¦ç»†ç ”ç©¶äº†è¿™ä¸¤ç§æ¨¡å‹åœ¨å®é™…åº”ç”¨æ¡ä»¶ä¸‹çš„è¡¨ç°ï¼Œå¹¶è¯æ˜WavLM base+å¯¹å„ç§é˜…è¯»ä»»åŠ¡å’Œå™ªå£°æ°´å¹³æ›´åŠ ç¨³å¥ã€‚å…³é”®è¯ï¼šè¯­éŸ³è¯†åˆ«ã€å„¿ç«¥è¯­éŸ³ã€è‡ªç›‘ç£å­¦ä¹ ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.04710v1">PDF</a> This paper was originally published in the Proceedings of Interspeech   2024. DOI: 10.21437&#x2F;Interspeech.2024-1095</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æ¢è®¨äº†å„¿ç«¥è¯­éŸ³è¯†åˆ«é¢†åŸŸçš„æœ€æ–°è¿›å±•ï¼Œç‰¹åˆ«æ˜¯åŸºäºè‡ªç›‘ç£å­¦ä¹ çš„æ¨¡å‹åº”ç”¨ã€‚æ–‡ç« å¯¹æ¯”äº†wav2vec 2.0ã€HuBERTå’ŒWavLMæ¨¡å‹åœ¨æ³•è¯­å„¿ç«¥è¯­éŸ³çš„éŸ³ç´ è¯†åˆ«æ•ˆæœï¼Œå¹¶åŸºäºæœ€ä½³æ¨¡å‹WavLM base+è¿›è¡Œäº†è¿›ä¸€æ­¥ä¼˜åŒ–ã€‚å®éªŒè¡¨æ˜ï¼Œè§£é”å˜å‹å™¨å—åœ¨å„¿ç«¥è¯­éŸ³ä¸Šçš„ç²¾ç»†è°ƒæ•´å¤§å¤§æé«˜äº†å…¶æ€§èƒ½ï¼Œå¹¶åœ¨å®é™…åº”ç”¨ä¸­è¡¨ç°å‡ºæ›´é«˜çš„ç¨³å¥æ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å„¿ç«¥è¯­éŸ³è¯†åˆ«é¢†åŸŸç”±äºæ•°æ®ç¼ºä¹ï¼ˆå°¤å…¶æ˜¯éè‹±è¯­è¯­è¨€æ•°æ®ï¼‰å’Œç‰¹å®šä»»åŠ¡éš¾åº¦ï¼Œä»æ˜¯ä¸€ä¸ªç ”ç©¶ä¸è¶³çš„åŒºåŸŸã€‚</li>
<li>æ–‡ç« ä¸­å¯¹æ¯”äº†wav2vec 2.0ã€HuBERTå’ŒWavLMæ¨¡å‹åœ¨æ³•è¯­å„¿ç«¥è¯­éŸ³çš„éŸ³ç´ è¯†åˆ«æ•ˆæœã€‚</li>
<li>WavLM base+æ¨¡å‹åœ¨å„¿ç«¥è¯­éŸ³çš„éŸ³ç´ è¯†åˆ«ä¸Šè¡¨ç°æœ€ä½³ã€‚</li>
<li>é€šè¿‡è§£é”å˜å‹å™¨å—è¿›è¡Œç²¾ç»†è°ƒæ•´ï¼ŒWavLM base+æ¨¡å‹çš„æ€§èƒ½å¾—åˆ°è¿›ä¸€æ­¥æå‡ã€‚</li>
<li>WavLM base+æ¨¡å‹åœ¨å®é™…åº”ç”¨ä¸­å¯¹ä¸åŒçš„é˜…è¯»ä»»åŠ¡å’Œå™ªå£°æ°´å¹³å…·æœ‰æ›´é«˜çš„ç¨³å¥æ€§ã€‚</li>
<li>è‡ªç›‘ç£å­¦ä¹ åœ¨å„¿ç«¥è¯­éŸ³è¯†åˆ«ä¸­å‘æŒ¥äº†é‡è¦ä½œç”¨ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.04710">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-1e9f7e53052fc1603f69837036a2a251.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-1e06eab19b066abfa2e65ec81756cd6d.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-ec972a8030a8d4a67769d212757b9c5c.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-e8fc7df2e42fe074ab1770f390e0ec2a.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="Dual-Class-Prompt-Generation-Enhancing-Indonesian-Gender-Based-Hate-Speech-Detection-through-Data-Augmentation"><a href="#Dual-Class-Prompt-Generation-Enhancing-Indonesian-Gender-Based-Hate-Speech-Detection-through-Data-Augmentation" class="headerlink" title="Dual-Class Prompt Generation: Enhancing Indonesian Gender-Based Hate   Speech Detection through Data Augmentation"></a>Dual-Class Prompt Generation: Enhancing Indonesian Gender-Based Hate   Speech Detection through Data Augmentation</h2><p><strong>Authors:Muhammad Amien Ibrahim,  Faisal, Tora Sangputra Yopie Winarto, Zefanya Delvin Sulistiya</strong></p>
<p>Detecting gender-based hate speech in Indonesian social media remains challenging due to limited labeled datasets. While binary hate speech classification has advanced, a more granular category like gender-targeted hate speech is understudied because of class imbalance issues. This paper addresses this gap by comparing three data augmentation techniques for Indonesian gender-based hate speech detection. We evaluate backtranslation, single-class prompt generation (using only hate speech examples), and our proposed dual-class prompt generation (using both hate speech and non-hate speech examples). Experiments show all augmentation methods improve classification performance, with our dual-class approach achieving the best results (88.5% accuracy, 88.1% F1-score using Random Forest). Semantic similarity analysis reveals dual-class prompt generation produces the most novel content, while T-SNE visualizations confirm these samples occupy distinct feature space regions while maintaining class characteristics. Our findings suggest that incorporating examples from both classes helps language models generate more diverse yet representative samples, effectively addressing limited data challenges in specialized hate speech detection. </p>
<blockquote>
<p>æ£€æµ‹å°å°¼ç¤¾äº¤åª’ä½“ä¸­çš„åŸºäºæ€§åˆ«çš„ä»‡æ¨è¨€è®ºä»ç„¶æ˜¯ä¸€ä¸ªæŒ‘æˆ˜ï¼Œå› ä¸ºæ ‡è®°çš„æ•°æ®é›†æœ‰é™ã€‚è™½ç„¶äºŒå…ƒä»‡æ¨è¨€è®ºåˆ†ç±»å·²ç»å–å¾—è¿›å±•ï¼Œä½†ç”±äºç±»åˆ«ä¸å¹³è¡¡é—®é¢˜ï¼Œæ›´ç²¾ç»†çš„ç±»åˆ«ï¼ˆå¦‚é’ˆå¯¹æ€§åˆ«çš„ä»‡æ¨è¨€è®ºï¼‰çš„ç ”ç©¶ä»ç„¶ä¸è¶³ã€‚æœ¬æ–‡é€šè¿‡æ¯”è¾ƒä¸‰ç§æ•°æ®å¢å¼ºæŠ€æœ¯æ¥è§£å†³è¿™ä¸€ç©ºç™½ï¼Œç”¨äºæ£€æµ‹å°å°¼åŸºäºæ€§åˆ«çš„ä»‡æ¨è¨€è®ºã€‚æˆ‘ä»¬è¯„ä¼°äº†åå‘ç¿»è¯‘ã€å•ç±»æç¤ºç”Ÿæˆï¼ˆä»…ä½¿ç”¨ä»‡æ¨è¨€è®ºç¤ºä¾‹ï¼‰å’Œæˆ‘ä»¬æå‡ºçš„åŒç±»æç¤ºç”Ÿæˆï¼ˆä½¿ç”¨ä»‡æ¨è¨€è®ºå’Œéä»‡æ¨è¨€è®ºç¤ºä¾‹ï¼‰ã€‚å®éªŒè¡¨æ˜ï¼Œæ‰€æœ‰å¢å¼ºæ–¹æ³•éƒ½æé«˜äº†åˆ†ç±»æ€§èƒ½ï¼Œæˆ‘ä»¬çš„åŒç±»æ–¹æ³•å–å¾—äº†æœ€ä½³ç»“æœï¼ˆä½¿ç”¨éšæœºæ£®æ—è¾¾åˆ°88.5%çš„å‡†ç¡®ç‡å’Œ88.1%çš„F1åˆ†æ•°ï¼‰ã€‚è¯­ä¹‰ç›¸ä¼¼æ€§åˆ†ææ˜¾ç¤ºï¼ŒåŒç±»æç¤ºç”Ÿæˆäº§ç”Ÿçš„å†…å®¹æœ€æ–°é¢–ï¼Œè€ŒT-SNEå¯è§†åŒ–ç¡®è®¤è¿™äº›æ ·æœ¬å æ®ä¸åŒçš„ç‰¹å¾ç©ºé—´åŒºåŸŸï¼ŒåŒæ—¶ä¿æŒç±»åˆ«ç‰¹å¾ã€‚æˆ‘ä»¬çš„ç ”ç©¶ç»“æœè¡¨æ˜ï¼Œç»“åˆä¸¤ä¸ªç±»åˆ«çš„ä¾‹å­æœ‰åŠ©äºè¯­è¨€æ¨¡å‹ç”Ÿæˆæ›´å¤šæ ·åŒ–ä¸”å…·æœ‰ä»£è¡¨æ€§çš„æ ·æœ¬ï¼Œæœ‰æ•ˆè§£å†³ç‰¹å®šä»‡æ¨è¨€è®ºæ£€æµ‹ä¸­çš„æœ‰é™æ•°æ®æŒ‘æˆ˜ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.04279v1">PDF</a> Accepted to the 8th World Conference on Computing and Communication   Technologies (WCCCT 2025)</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ç ”ç©¶äº†å°å°¼ç¤¾äº¤åª’ä½“ä¸­çš„æ€§åˆ«ä»‡æ¨è¨€è®ºæ£€æµ‹é—®é¢˜ï¼Œé’ˆå¯¹å› æ•°æ®é›†ä¸è¶³è€Œå¯¼è‡´çš„æŒ‘æˆ˜ï¼Œæå‡ºäº†ä¸‰ç§æ•°æ®å¢å¼ºæŠ€æœ¯è¿›è¡Œæ¯”è¾ƒç ”ç©¶ã€‚é€šè¿‡å¯¹æ¯”åç¿»è¯‘ã€å•ç±»æç¤ºç”ŸæˆæŠ€æœ¯å’Œä½œè€…æå‡ºçš„åŒç±»æç¤ºç”ŸæˆæŠ€æœ¯ï¼Œå‘ç°æ‰€æœ‰æ•°æ®å¢å¼ºæ–¹æ³•éƒ½èƒ½æé«˜åˆ†ç±»æ€§èƒ½ï¼Œå…¶ä¸­åŒç±»æç¤ºç”ŸæˆæŠ€æœ¯è¡¨ç°æœ€ä½³ï¼Œå‡†ç¡®ç‡é«˜è¾¾88.5%ï¼ŒF1åˆ†æ•°ä¸º88.1%ï¼Œå¹¶ä½¿ç”¨éšæœºæ£®æ—è¿›è¡Œå®ç°ã€‚æ­¤æ–¹æ³•ä¸ä»…èƒ½äº§ç”Ÿæ›´å…·åˆ›æ–°æ€§çš„å†…å®¹ï¼Œè¿˜èƒ½æœ‰æ•ˆè§£å†³ç‰¹æ®Šä»‡æ¨è¨€è®ºæ£€æµ‹ä¸­çš„æœ‰é™æ•°æ®æŒ‘æˆ˜ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å°å°¼ç¤¾äº¤åª’ä½“ä¸­çš„æ€§åˆ«ä»‡æ¨è¨€è®ºæ£€æµ‹é¢ä¸´æŒ‘æˆ˜ï¼Œä¸»è¦ç”±äºæ•°æ®é›†æœ‰é™ã€‚</li>
<li>æ•°æ®å¢å¼ºæŠ€æœ¯è¢«ç”¨äºè§£å†³æ­¤é—®é¢˜ï¼ŒåŒ…æ‹¬åç¿»è¯‘ã€å•ç±»æç¤ºç”Ÿæˆå’ŒåŒç±»æç¤ºç”Ÿæˆã€‚</li>
<li>åŒç±»æç¤ºç”ŸæˆæŠ€æœ¯è¡¨ç°æœ€ä½³ï¼Œå‡†ç¡®ç‡é«˜è¾¾88.5%ï¼ŒF1åˆ†æ•°ä¸º88.1%ã€‚</li>
<li>åŒç±»æç¤ºç”Ÿæˆæ³•èƒ½äº§ç”Ÿæœ€å…·æœ‰åˆ›æ–°æ€§çš„å†…å®¹ã€‚</li>
<li>é€šè¿‡T-SNEå¯è§†åŒ–åˆ†æï¼ŒåŒç±»æç¤ºç”Ÿæˆçš„æ ·æœ¬å æ®ç‹¬ç‰¹çš„ç‰¹å¾ç©ºé—´åŒºåŸŸï¼ŒåŒæ—¶ä¿æŒç±»åˆ«ç‰¹æ€§ã€‚</li>
<li>ç»“åˆä¸¤ç±»æ ·æœ¬æœ‰åŠ©äºè¯­è¨€æ¨¡å‹ç”Ÿæˆæ›´å¤šæ ·åŒ–ä¸”å…·ä»£è¡¨æ€§çš„æ ·æœ¬ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.04279">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-efc009d5ee709236c0aae16f733a87ea.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-1170a332641a5559609d1804a17e90f6.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-66dac92e54a583ba84d889a6e962015c.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-60d54c3602e421702168c74aad36c6ea.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-bb1c88f03f9427abd2fc33cac8b25193.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-60667fd989ffbd657bea217c163ec9c3.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="FREAK-Frequency-modulated-High-fidelity-and-Real-time-Audio-driven-Talking-Portrait-Synthesis"><a href="#FREAK-Frequency-modulated-High-fidelity-and-Real-time-Audio-driven-Talking-Portrait-Synthesis" class="headerlink" title="FREAK: Frequency-modulated High-fidelity and Real-time Audio-driven   Talking Portrait Synthesis"></a>FREAK: Frequency-modulated High-fidelity and Real-time Audio-driven   Talking Portrait Synthesis</h2><p><strong>Authors:Ziqi Ni, Ao Fu, Yi Zhou</strong></p>
<p>Achieving high-fidelity lip-speech synchronization in audio-driven talking portrait synthesis remains challenging. While multi-stage pipelines or diffusion models yield high-quality results, they suffer from high computational costs. Some approaches perform well on specific individuals with low resources, yet still exhibit mismatched lip movements. The aforementioned methods are modeled in the pixel domain. We observed that there are noticeable discrepancies in the frequency domain between the synthesized talking videos and natural videos. Currently, no research on talking portrait synthesis has considered this aspect. To address this, we propose a FREquency-modulated, high-fidelity, and real-time Audio-driven talKing portrait synthesis framework, named FREAK, which models talking portraits from the frequency domain perspective, enhancing the fidelity and naturalness of the synthesized portraits. FREAK introduces two novel frequency-based modules: 1) the Visual Encoding Frequency Modulator (VEFM) to couple multi-scale visual features in the frequency domain, better preserving visual frequency information and reducing the gap in the frequency spectrum between synthesized and natural frames. and 2) the Audio Visual Frequency Modulator (AVFM) to help the model learn the talking pattern in the frequency domain and improve audio-visual synchronization. Additionally, we optimize the model in both pixel domain and frequency domain jointly. Furthermore, FREAK supports seamless switching between one-shot and video dubbing settings, offering enhanced flexibility. Due to its superior performance, it can simultaneously support high-resolution video results and real-time inference. Extensive experiments demonstrate that our method synthesizes high-fidelity talking portraits with detailed facial textures and precise lip synchronization in real-time, outperforming state-of-the-art methods. </p>
<blockquote>
<p>åœ¨éŸ³é¢‘é©±åŠ¨çš„è¯´è¯è‚–åƒåˆæˆä¸­å®ç°é«˜ä¿çœŸå”‡è¯­éŸ³åŒæ­¥ä»ç„¶æ˜¯ä¸€ä¸ªæŒ‘æˆ˜ã€‚è™½ç„¶å¤šé˜¶æ®µç®¡é“æˆ–æ‰©æ•£æ¨¡å‹èƒ½äº§ç”Ÿé«˜è´¨é‡çš„ç»“æœï¼Œä½†å®ƒä»¬å­˜åœ¨è®¡ç®—æˆæœ¬é«˜çš„ç¼ºç‚¹ã€‚ä¸€äº›æ–¹æ³•åœ¨èµ„æºè¾ƒå°‘çš„ç‰¹å®šä¸ªäººä¸Šè¡¨ç°è‰¯å¥½ï¼Œä½†ä»ä¼šå‡ºç°å”‡éƒ¨åŠ¨ä½œä¸åŒ¹é…çš„æƒ…å†µã€‚ä¸Šè¿°æ–¹æ³•éƒ½æ˜¯åœ¨åƒç´ åŸŸå»ºæ¨¡çš„ã€‚æˆ‘ä»¬è§‚å¯Ÿåˆ°ï¼Œåˆæˆè¯´è¯è§†é¢‘å’Œè‡ªç„¶è§†é¢‘åœ¨é¢‘ç‡åŸŸä¸Šå­˜åœ¨æ˜æ˜¾çš„å·®å¼‚ã€‚ç›®å‰ï¼Œæ²¡æœ‰å…³äºè¯´è¯è‚–åƒåˆæˆçš„ç ”ç©¶è€ƒè™‘è¿™ä¸€æ–¹é¢çš„å› ç´ ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§è°ƒé¢‘ã€é«˜ä¿çœŸã€å®æ—¶çš„éŸ³é¢‘é©±åŠ¨è¯´è¯è‚–åƒåˆæˆæ¡†æ¶ï¼Œåä¸ºFREAKï¼Œå®ƒä»é¢‘ç‡åŸŸçš„è§’åº¦å¯¹è¯´è¯è‚–åƒè¿›è¡Œå»ºæ¨¡ï¼Œæé«˜äº†åˆæˆè‚–åƒçš„ä¿çœŸåº¦å’Œè‡ªç„¶åº¦ã€‚FREAKå¼•å…¥äº†ä¸¤ä¸ªæ–°çš„åŸºäºé¢‘ç‡çš„æ¨¡å—ï¼š1ï¼‰è§†è§‰ç¼–ç é¢‘ç‡è°ƒåˆ¶å™¨ï¼ˆVEFMï¼‰ï¼Œç”¨äºè€¦åˆé¢‘ç‡åŸŸä¸­çš„å¤šå°ºåº¦è§†è§‰ç‰¹å¾ï¼Œæ›´å¥½åœ°ä¿ç•™è§†è§‰é¢‘ç‡ä¿¡æ¯ï¼Œå‡å°‘åˆæˆå¸§å’Œè‡ªç„¶å¸§ä¹‹é—´é¢‘è°±çš„å·®è·ï¼›2ï¼‰è§†å¬é¢‘ç‡è°ƒåˆ¶å™¨ï¼ˆAVFMï¼‰ï¼Œå¸®åŠ©æ¨¡å‹å­¦ä¹ é¢‘ç‡åŸŸçš„è¯´è¯æ¨¡å¼ï¼Œæé«˜è§†å¬åŒæ­¥ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å¯¹åƒç´ åŸŸå’Œé¢‘ç‡åŸŸä¸­çš„æ¨¡å‹è¿›è¡Œäº†è”åˆä¼˜åŒ–ã€‚æ­¤å¤–ï¼ŒFREAKæ”¯æŒåœ¨ä¸€é”®å¼å’Œè§†é¢‘é…éŸ³è®¾ç½®ä¹‹é—´è¿›è¡Œæ— ç¼åˆ‡æ¢ï¼Œæä¾›äº†å¢å¼ºçš„çµæ´»æ€§ã€‚å‡­å€Ÿå…¶å“è¶Šçš„æ€§èƒ½ï¼Œå®ƒå¯ä»¥åŒæ—¶æ”¯æŒé«˜åˆ†è¾¨ç‡è§†é¢‘ç»“æœå’Œå®æ—¶æ¨ç†ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨å®æ—¶åˆæˆé«˜ä¿çœŸè¯´è¯è‚–åƒæ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œå…·æœ‰è¯¦ç»†çš„é¢éƒ¨çº¹ç†å’Œç²¾ç¡®çš„å”‡éƒ¨åŒæ­¥ï¼Œè¶…è¶Šäº†æœ€å…ˆè¿›çš„æ–¹æ³•ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.04067v1">PDF</a> </p>
<p><strong>æ‘˜è¦</strong></p>
<p>å®ç°é«˜ä¿çœŸåº¦çš„å”‡è¯­éŸ³åŒæ­¥åœ¨éŸ³é¢‘é©±åŠ¨çš„äººåƒåˆæˆä¸­ä»ç„¶æ˜¯ä¸€ä¸ªæŒ‘æˆ˜ã€‚è™½ç„¶å¤šé˜¶æ®µç®¡é“æˆ–æ‰©æ•£æ¨¡å‹èƒ½äº§ç”Ÿé«˜è´¨é‡çš„ç»“æœï¼Œä½†å®ƒä»¬è®¡ç®—æˆæœ¬é«˜æ˜‚ã€‚ä¸€äº›æ–¹æ³•åœ¨ä½èµ„æºæ¡ä»¶ä¸‹å¯¹ç‰¹å®šä¸ªä½“è¡¨ç°è‰¯å¥½ï¼Œä½†ä»å­˜åœ¨å”‡éƒ¨åŠ¨ä½œä¸åŒ¹é…çš„é—®é¢˜ã€‚å½“å‰çš„ç ”ç©¶éƒ½åœ¨åƒç´ åŸŸè¿›è¡Œå»ºæ¨¡ï¼Œè€Œæˆ‘ä»¬åœ¨é¢‘ç‡åŸŸè§‚å¯Ÿåˆ°äº†åˆæˆè§†é¢‘ä¸è‡ªç„¶è§†é¢‘ä¹‹é—´çš„æ˜æ˜¾å·®å¼‚ã€‚æœ¬æ–‡æå‡ºçš„FRCéŸ³é©±åŠ¨åŠ¨æ€äººè„¸è¯†åˆ«è‚–åƒåˆæˆæ¡†æ¶è€ƒè™‘äº†è¿™ä¸€é—®é¢˜ã€‚æˆ‘ä»¬å¼•å…¥äº†ä¸¤ä¸ªåŸºäºé¢‘ç‡çš„æ–°æ¨¡å—ï¼šè§†è§‰ç¼–ç é¢‘ç‡è°ƒåˆ¶å™¨ï¼ˆVEFMï¼‰å’ŒéŸ³é¢‘è§†è§‰é¢‘ç‡è°ƒåˆ¶å™¨ï¼ˆAVFMï¼‰ï¼Œæ—¨åœ¨æ›´å¥½åœ°ä¿å­˜å’Œåè°ƒè§†è§‰é¢‘ç‡ä¿¡æ¯ï¼Œå¹¶æ”¹è¿›éŸ³é¢‘è§†é¢‘åŒæ­¥ã€‚æˆ‘ä»¬çš„æ¨¡å‹åŒæ—¶åœ¨åƒç´ åŸŸå’Œé¢‘ç‡åŸŸè¿›è¡Œä¼˜åŒ–ï¼Œå…·æœ‰çµæ´»çš„è¯­éŸ³è®¾ç½®åˆ‡æ¢èƒ½åŠ›ï¼Œèƒ½æ”¯æŒé«˜åˆ†è¾¨ç‡è§†é¢‘ç»“æœå¹¶å®æ—¶æ¨æ–­ã€‚å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•èƒ½åœ¨å®æ—¶åˆæˆé«˜ä¿çœŸåº¦çš„äººåƒè¯´è¯å†…å®¹ï¼Œç²¾ç»†çš„é¢éƒ¨çº¹ç†å’Œç²¾ç¡®çš„å”‡åŒæ­¥ä¸Šè¶…è¶Šç°æœ‰æŠ€æœ¯çš„æ–¹æ³•ã€‚</p>
<p><strong>å…³é”®è§è§£</strong></p>
<ol>
<li>éŸ³é¢‘é©±åŠ¨çš„äººåƒåˆæˆä¸­å”‡è¯­éŸ³åŒæ­¥å®ç°é«˜ä¿çœŸåº¦ä»ç„¶å…·æœ‰æŒ‘æˆ˜æ€§ã€‚</li>
<li>å½“å‰æ–¹æ³•åœ¨åƒç´ åŸŸå»ºæ¨¡ï¼Œå¿½è§†äº†é¢‘ç‡åŸŸçš„å·®å¼‚ã€‚</li>
<li>æå‡ºä¸€ç§åä¸ºFREAKçš„æ–°æ¡†æ¶ï¼Œä»é¢‘ç‡åŸŸè§’åº¦è¿›è¡Œäººåƒåˆæˆï¼Œæé«˜åˆæˆè‚–åƒçš„çœŸå®æ€§å’Œè‡ªç„¶æ€§ã€‚</li>
<li>å¼•å…¥ä¸¤ä¸ªæ–°çš„é¢‘ç‡æ¨¡å—ï¼šVEFMå’ŒAVFMï¼Œä»¥æ”¹å–„è§†è§‰é¢‘ç‡ä¿¡æ¯çš„ä¿å­˜å’ŒéŸ³é¢‘è§†é¢‘åŒæ­¥ã€‚</li>
<li>FREAKèƒ½åŒæ—¶åœ¨åƒç´ åŸŸå’Œé¢‘ç‡åŸŸä¼˜åŒ–æ¨¡å‹ï¼Œå¹¶æ”¯æŒè¯­éŸ³è®¾ç½®çš„çµæ´»åˆ‡æ¢ã€‚</li>
<li>FREAKå¯ä»¥æ”¯æŒé«˜åˆ†è¾¨ç‡è§†é¢‘ç»“æœå¹¶å®æ—¶æ¨æ–­ã€‚</li>
<li>å®éªŒè¡¨æ˜ï¼ŒFREAKåœ¨å®æ—¶åˆæˆé«˜ä¿çœŸåº¦çš„äººåƒè¯´è¯å†…å®¹ä¸Šä¼˜äºç°æœ‰æŠ€æœ¯ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.04067">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-fc024781182ea0718cfa0b3aa164adb1.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-c82da61db7ff856715585c9cfa33c208.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-17578f7a96ae57ce53d129176ed17992.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-d4e24bb171471ffbd7e8f84d43dbd30e.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="Pruning-Deep-Neural-Networks-via-a-Combination-of-the-Marchenko-Pastur-Distribution-and-Regularization"><a href="#Pruning-Deep-Neural-Networks-via-a-Combination-of-the-Marchenko-Pastur-Distribution-and-Regularization" class="headerlink" title="Pruning Deep Neural Networks via a Combination of the Marchenko-Pastur   Distribution and Regularization"></a>Pruning Deep Neural Networks via a Combination of the Marchenko-Pastur   Distribution and Regularization</h2><p><strong>Authors:Leonid Berlyand, Theo Bourdais, Houman Owhadi, Yitzchak Shmalo</strong></p>
<p>Deep neural networks (DNNs) have brought significant advancements in various applications in recent years, such as image recognition, speech recognition, and natural language processing. In particular, Vision Transformers (ViTs) have emerged as a powerful class of models in the field of deep learning for image classification. In this work, we propose a novel Random Matrix Theory (RMT)-based method for pruning pre-trained DNNs, based on the sparsification of weights and singular vectors, and apply it to ViTs. RMT provides a robust framework to analyze the statistical properties of large matrices, which has been shown to be crucial for understanding and optimizing the performance of DNNs. We demonstrate that our RMT-based pruning can be used to reduce the number of parameters of ViT models (trained on ImageNet) by 30-50% with less than 1% loss in accuracy. To our knowledge, this represents the state-of-the-art in pruning for these ViT models. Furthermore, we provide a rigorous mathematical underpinning of the above numerical studies, namely we proved a theorem for fully connected DNNs, and other more general DNN structures, describing how the randomness in the weight matrices of a DNN decreases as the weights approach a local or global minimum (during training). We verify this theorem through numerical experiments on fully connected DNNs, providing empirical support for our theoretical findings. Moreover, we prove a theorem that describes how DNN loss decreases as we remove randomness in the weight layers, and show a monotone dependence of the decrease in loss with the amount of randomness that we remove. Our results also provide significant RMT-based insights into the role of regularization during training and pruning. </p>
<blockquote>
<p>è¿‘å¹´æ¥ï¼Œæ·±åº¦ç¥ç»ç½‘ç»œï¼ˆDNNsï¼‰åœ¨å„ç§åº”ç”¨ä¸­å–å¾—äº†é‡å¤§è¿›å±•ï¼Œä¾‹å¦‚å›¾åƒè¯†åˆ«ã€è¯­éŸ³è¯†åˆ«å’Œè‡ªç„¶è¯­è¨€å¤„ç†ã€‚ç‰¹åˆ«æ˜¯ï¼ŒVision Transformersï¼ˆViTsï¼‰ä½œä¸ºæ·±åº¦å­¦ä¹ é¢†åŸŸå›¾åƒåˆ†ç±»æ¨¡å‹ä¸­çš„å¼ºå¤§ç±»åˆ«è€Œå‡ºç°ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åŸºäºéšæœºçŸ©é˜µç†è®ºï¼ˆRMTï¼‰çš„æ–°æ–¹æ³•ï¼Œç”¨äºä¿®å‰ªé¢„è®­ç»ƒçš„DNNsï¼Œè¯¥æ–¹æ³•åŸºäºæƒé‡å’Œå¥‡å¼‚å‘é‡çš„ç¨€ç–åŒ–ï¼Œå¹¶é€‚ç”¨äºViTsã€‚RMTæä¾›äº†ä¸€ä¸ªåˆ†æå¤§å‹çŸ©é˜µç»Ÿè®¡ç‰¹æ€§çš„ç¨³å¥æ¡†æ¶ï¼Œå·²è¢«è¯æ˜å¯¹äºç†è§£å’Œä¼˜åŒ–DNNçš„æ€§èƒ½è‡³å…³é‡è¦ã€‚æˆ‘ä»¬è¯æ˜ï¼Œæˆ‘ä»¬çš„åŸºäºRMTçš„ä¿®å‰ªæ–¹æ³•å¯ç”¨äºå°†å·²åœ¨ImageNetä¸Šè®­ç»ƒçš„ViTæ¨¡å‹çš„å‚æ•°æ•°é‡å‡å°‘30-50%ï¼ŒåŒæ—¶ç²¾åº¦æŸå¤±ä¸åˆ°1%ã€‚æ®æˆ‘ä»¬æ‰€çŸ¥ï¼Œè¿™æ˜¯è¿™äº›ViTæ¨¡å‹ä¿®å‰ªçš„æœ€æ–°æŠ€æœ¯ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å¯¹ä¸Šè¿°æ•°å€¼ç ”ç©¶è¿›è¡Œäº†ä¸¥æ ¼çš„æ•°å­¦è®ºè¯ï¼Œå³æˆ‘ä»¬ä¸ºå…¨è¿æ¥DNNså’Œå…¶ä»–æ›´ä¸€èˆ¬çš„DNNç»“æ„è¯æ˜äº†ä¸€ä¸ªå®šç†ï¼Œæè¿°äº†DNNæƒé‡çŸ©é˜µä¸­çš„éšæœºæ€§å¦‚ä½•éšç€æƒé‡æ¥è¿‘å±€éƒ¨æˆ–å…¨å±€æœ€å°å€¼ï¼ˆåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼‰è€Œå‡å°‘ã€‚æˆ‘ä»¬é€šè¿‡å…¨è¿æ¥DNNä¸Šçš„æ•°å€¼å®éªŒéªŒè¯äº†è¿™ä¸€å®šç†ï¼Œä¸ºæˆ‘ä»¬çš„ç†è®ºå‘ç°æä¾›äº†å®è¯æ”¯æŒã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¯æ˜äº†å¦ä¸€ä¸ªå®šç†ï¼Œæè¿°äº†éšç€æˆ‘ä»¬åœ¨æƒé‡å±‚ä¸­æ¶ˆé™¤éšæœºæ€§ï¼ŒDNNæŸå¤±å¦‚ä½•å‡å°‘ï¼Œå¹¶æ˜¾ç¤ºäº†æŸå¤±å‡å°‘ä¸æˆ‘ä»¬æ¶ˆé™¤çš„éšæœºé‡ä¹‹é—´çš„å•è°ƒä¾èµ–æ€§ã€‚æˆ‘ä»¬çš„ç»“æœè¿˜æä¾›äº†åŸºäºRMTçš„å…³äºè®­ç»ƒå’Œä¿®å‰ªè¿‡ç¨‹ä¸­æ­£åˆ™åŒ–ä½œç”¨çš„æ·±åˆ»è§è§£ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.01922v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºä¸€ç§åŸºäºéšæœºçŸ©é˜µç†è®ºï¼ˆRMTï¼‰çš„æ–¹æ³•ï¼Œç”¨äºå¯¹é¢„è®­ç»ƒçš„æ·±åº¦ç¥ç»ç½‘ç»œï¼ˆDNNï¼‰è¿›è¡Œå‰ªæï¼Œå¹¶å°†å…¶åº”ç”¨äºè§†è§‰è½¬æ¢å™¨ï¼ˆViTï¼‰æ¨¡å‹ã€‚è¯¥æ–¹æ³•åŸºäºæƒé‡å’Œå¥‡å¼‚å‘é‡çš„ç¨€ç–åŒ–ï¼Œåˆ©ç”¨RMTåˆ†æå¤§å‹çŸ©é˜µçš„ç»Ÿè®¡ç‰¹æ€§ï¼Œä»¥ç†è§£å’Œä¼˜åŒ–DNNçš„æ€§èƒ½ã€‚å®éªŒè¡¨æ˜ï¼Œä½¿ç”¨RMTçš„å‰ªææŠ€æœ¯å¯å°†è®­ç»ƒåœ¨ImageNetä¸Šçš„ViTæ¨¡å‹å‚æ•°å‡å°‘30-50%ï¼ŒåŒæ—¶ç²¾åº¦æŸå¤±å°äº1%ã€‚æ­¤å¤–ï¼Œæœ¬æ–‡è¿˜æä¾›äº†ä¸¥æ ¼çš„æ•°å­¦è¯æ˜å’Œå®éªŒæ”¯æŒã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¼•å…¥äº†ä¸€ç§åŸºäºéšæœºçŸ©é˜µç†è®ºï¼ˆRMTï¼‰çš„å‰ªææ–¹æ³•ï¼Œç”¨äºé¢„è®­ç»ƒçš„æ·±åº¦ç¥ç»ç½‘ç»œï¼ˆDNNï¼‰ã€‚</li>
<li>è¯¥æ–¹æ³•é€šè¿‡æƒé‡å’Œå¥‡å¼‚å‘é‡çš„ç¨€ç–åŒ–å®ç°ï¼Œç‰¹åˆ«é€‚ç”¨äºè§†è§‰è½¬æ¢å™¨ï¼ˆViTï¼‰æ¨¡å‹ã€‚</li>
<li>RMTä¸ºåˆ†æå¤§å‹çŸ©é˜µçš„ç»Ÿè®¡ç‰¹æ€§æä¾›äº†ç¨³å¥çš„æ¡†æ¶ï¼Œæœ‰åŠ©äºç†è§£å’Œä¼˜åŒ–DNNæ€§èƒ½ã€‚</li>
<li>å®éªŒæ˜¾ç¤ºï¼Œä½¿ç”¨RMTçš„å‰ªææŠ€æœ¯å¯å¤§å¹…å‡å°‘ViTæ¨¡å‹çš„å‚æ•°ï¼ŒåŒæ—¶ä¿æŒé«˜ç²¾åº¦ã€‚</li>
<li>æä¾›äº†ä¸¥æ ¼çš„æ•°å­¦è¯æ˜ï¼ŒåŒ…æ‹¬é’ˆå¯¹å…¨è¿æ¥DNNå’Œå…¶ä»–ç»“æ„çš„å®šç†ã€‚</li>
<li>è¯æ˜äº†DNNæŸå¤±éšæƒé‡å±‚éšæœºæ€§çš„å‡å°‘è€Œå‡å°‘çš„è§„å¾‹ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.01922">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-c5813982102f754e4ac159ad35ca9b0b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-18678ad6b7f893f31ed1928aca7f7c8c.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="BackdoorMBTI-A-Backdoor-Learning-Multimodal-Benchmark-Tool-Kit-for-Backdoor-Defense-Evaluation"><a href="#BackdoorMBTI-A-Backdoor-Learning-Multimodal-Benchmark-Tool-Kit-for-Backdoor-Defense-Evaluation" class="headerlink" title="BackdoorMBTI: A Backdoor Learning Multimodal Benchmark Tool Kit for   Backdoor Defense Evaluation"></a>BackdoorMBTI: A Backdoor Learning Multimodal Benchmark Tool Kit for   Backdoor Defense Evaluation</h2><p><strong>Authors:Haiyang Yu, Tian Xie, Jiaping Gui, Pengyang Wang, Ping Yi, Yue Wu</strong></p>
<p>Over the past few years, the emergence of backdoor attacks has presented significant challenges to deep learning systems, allowing attackers to insert backdoors into neural networks. When data with a trigger is processed by a backdoor model, it can lead to mispredictions targeted by attackers, whereas normal data yields regular results. The scope of backdoor attacks is expanding beyond computer vision and encroaching into areas such as natural language processing and speech recognition. Nevertheless, existing backdoor defense methods are typically tailored to specific data modalities, restricting their application in multimodal contexts. While multimodal learning proves highly applicable in facial recognition, sentiment analysis, action recognition, visual question answering, the security of these models remains a crucial concern. Specifically, there are no existing backdoor benchmarks targeting multimodal applications or related tasks.   In order to facilitate the research in multimodal backdoor, we introduce BackdoorMBTI, the first backdoor learning toolkit and benchmark designed for multimodal evaluation across three representative modalities from eleven commonly used datasets. BackdoorMBTI provides a systematic backdoor learning pipeline, encompassing data processing, data poisoning, backdoor training, and evaluation. The generated poison datasets and backdoor models enable detailed evaluation of backdoor defenses. Given the diversity of modalities, BackdoorMBTI facilitates systematic evaluation across different data types. Furthermore, BackdoorMBTI offers a standardized approach to handling practical factors in backdoor learning, such as issues related to data quality and erroneous labels. We anticipate that BackdoorMBTI will expedite future research in backdoor defense methods within a multimodal context. Code is available at <a target="_blank" rel="noopener" href="https://github.com/SJTUHaiyangYu/BackdoorMBTI">https://github.com/SJTUHaiyangYu/BackdoorMBTI</a>. </p>
<blockquote>
<p>è¿‡å»å‡ å¹´ï¼Œåé—¨æ”»å‡»çš„å‡ºç°ç»™æ·±åº¦å­¦ä¹ ç³»ç»Ÿå¸¦æ¥äº†é‡å¤§æŒ‘æˆ˜ï¼Œæ”»å‡»è€…èƒ½å¤Ÿåœ¨ç¥ç»ç½‘ç»œä¸­æ’å…¥åé—¨ã€‚å½“å¸¦æœ‰è§¦å‘å™¨çš„æ•°æ®è¢«åé—¨æ¨¡å‹å¤„ç†æ—¶ï¼Œå®ƒä¼šå¯¼è‡´æ”»å‡»è€…æ‰€é’ˆå¯¹çš„é¢„æµ‹é”™è¯¯ï¼Œè€Œæ­£å¸¸æ•°æ®åˆ™ä¼šäº§ç”Ÿå¸¸è§„ç»“æœã€‚åé—¨æ”»å‡»çš„èŒƒå›´æ­£åœ¨æ‰©å¤§ï¼Œå·²ç»è¶…è¶Šäº†è®¡ç®—æœºè§†è§‰é¢†åŸŸï¼Œæ­£åœ¨ä¾µå…¥è‡ªç„¶è¯­è¨€å¤„ç†å’Œè¯­éŸ³è¯†åˆ«ç­‰é¢†åŸŸã€‚ç„¶è€Œï¼Œç°æœ‰çš„åé—¨é˜²å¾¡æ–¹æ³•é€šå¸¸é’ˆå¯¹ç‰¹å®šçš„æ•°æ®æ¨¡å¼ï¼Œé™åˆ¶äº†å®ƒä»¬åœ¨å¤šæ¨¡å¼ä¸Šä¸‹æ–‡ä¸­çš„åº”ç”¨ã€‚è™½ç„¶å¤šæ¨¡å¼å­¦ä¹ åœ¨äººè„¸è¯†åˆ«ã€æƒ…æ„Ÿåˆ†æã€åŠ¨ä½œè¯†åˆ«ã€è§†è§‰é—®ç­”ç­‰æ–¹é¢è¡¨ç°å‡ºé«˜åº¦é€‚ç”¨æ€§ï¼Œä½†è¿™äº›æ¨¡å‹çš„å®‰å…¨æ€§ä»æ˜¯å…³é”®é—®é¢˜ã€‚ç‰¹åˆ«æ˜¯ï¼Œé’ˆå¯¹å¤šæ¨¡å¼åº”ç”¨æˆ–ç›¸å…³ä»»åŠ¡çš„åé—¨åŸºå‡†æµ‹è¯•å¹¶ä¸å­˜åœ¨ã€‚ä¸ºäº†ä¿ƒè¿›å¤šæ¨¡å¼åé—¨ç›¸å…³ç ”ç©¶ï¼Œæˆ‘ä»¬å¼•å…¥äº†BackdoorMBTIï¼Œè¿™æ˜¯ç¬¬ä¸€ä¸ªä¸ºè·¨ä¸‰ç§ä»£è¡¨æ€§æ¨¡å¼çš„å¤šæ¨¡å¼è¯„ä¼°è®¾è®¡çš„åé—¨å­¦ä¹ å·¥å…·åŒ…å’ŒåŸºå‡†æµ‹è¯•ï¼Œæ¶‰åŠ11ä¸ªå¸¸ç”¨æ•°æ®é›†ã€‚BackdoorMBTIæä¾›äº†ä¸€ä¸ªç³»ç»Ÿçš„åé—¨å­¦ä¹ ç®¡é“ï¼ŒåŒ…æ‹¬æ•°æ®å¤„ç†ã€æ•°æ®ä¸­æ¯’ã€åé—¨è®­ç»ƒå’Œè¯„ä¼°ã€‚ç”Ÿæˆçš„æ¯’æ•°æ®é›†å’Œåé—¨æ¨¡å‹èƒ½å¤Ÿè¯¦ç»†è¯„ä¼°åé—¨é˜²å¾¡ã€‚è€ƒè™‘åˆ°æ¨¡å¼çš„å¤šæ ·æ€§ï¼ŒBackdoorMBTIä¾¿äºè·¨ä¸åŒæ•°æ®ç±»å‹è¿›è¡Œç³»ç»Ÿçš„è¯„ä¼°ã€‚æ­¤å¤–ï¼ŒBackdoorMBTIè¿˜æä¾›äº†ä¸€ç§æ ‡å‡†åŒ–æ–¹æ³•æ¥å¤„ç†åé—¨å­¦ä¹ ä¸­çš„å®é™…é—®é¢˜ï¼Œä¾‹å¦‚ä¸æ•°æ®è´¨é‡å’Œé”™è¯¯æ ‡ç­¾ç›¸å…³çš„é—®é¢˜ã€‚æˆ‘ä»¬é¢„è®¡BackdoorMBTIå°†åŠ å¿«å¤šæ¨¡å¼ä¸‹çš„åé—¨é˜²å¾¡æ–¹æ³•çš„ç ”ç©¶ã€‚ä»£ç å¯é€šè¿‡<a target="_blank" rel="noopener" href="https://github.com/SJTUHaiyangYu/BackdoorMBTI%E8%AE%BF%E9%97%AE%E3%80%82">https://github.com/SJTUHaiyangYu/BackdoorMBTIè®¿é—®ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2411.11006v2">PDF</a> </p>
<p><strong>æ‘˜è¦</strong></p>
<p>è¿‡å»å‡ å¹´ä¸­ï¼Œåé—¨æ”»å‡»çš„å‡ºç°ç»™æ·±åº¦å­¦ä¹ ç³»ç»Ÿå¸¦æ¥äº†é‡å¤§æŒ‘æˆ˜ï¼Œæ”»å‡»è€…èƒ½å¤Ÿåœ¨ç¥ç»ç½‘ç»œä¸­æ¤å…¥åé—¨ã€‚å½“å¸¦æœ‰è§¦å‘å™¨çš„æ•°æ®è¢«åé—¨æ¨¡å‹å¤„ç†æ—¶ï¼Œå®ƒä¼šå¯¼è‡´æ”»å‡»è€…ç›®æ ‡å¯¼å‘çš„è¯¯é¢„æµ‹ï¼Œè€Œæ­£å¸¸æ•°æ®åˆ™ä¼šäº§ç”Ÿå¸¸è§„ç»“æœã€‚åé—¨æ”»å‡»çš„èŒƒå›´æ­£åœ¨ä»è®¡ç®—æœºè§†è§‰æ‰©å±•åˆ°è‡ªç„¶è¯­è¨€å¤„ç†å’Œè¯­éŸ³è¯†åˆ«ç­‰é¢†åŸŸã€‚ç„¶è€Œï¼Œç°æœ‰çš„åé—¨é˜²å¾¡æ–¹æ³•é€šå¸¸é’ˆå¯¹ç‰¹å®šçš„æ•°æ®æ¨¡å¼ï¼Œé™åˆ¶äº†å®ƒä»¬åœ¨å¤šæ¨¡å¼ä¸Šä¸‹æ–‡ä¸­çš„åº”ç”¨ã€‚å¤šæ¨¡å¼å­¦ä¹ åœ¨äººè„¸è¯†åˆ«ã€æƒ…æ„Ÿåˆ†æã€åŠ¨ä½œè¯†åˆ«ã€è§†è§‰é—®ç­”ç­‰æ–¹é¢å…·æœ‰é«˜åº¦é€‚ç”¨æ€§ï¼Œä½†è¿™äº›æ¨¡å‹çš„å®‰å…¨æ€§ä»æ˜¯äººä»¬å…³æ³¨çš„é‡ç‚¹ã€‚å°¤å…¶æ˜¯ï¼Œæ²¡æœ‰é’ˆå¯¹å¤šæ¨¡å¼åº”ç”¨æˆ–ç›¸å…³ä»»åŠ¡çš„åé—¨åŸºå‡†æµ‹è¯•ã€‚ä¸ºäº†ä¿ƒè¿›å¤šæ¨¡å¼åé—¨ç ”ç©¶ï¼Œæˆ‘ä»¬å¼•å…¥äº†BackdoorMBTIï¼Œè¿™æ˜¯ç¬¬ä¸€ä¸ªä¸ºè·¨ä¸‰ç§ä»£è¡¨æ€§æ¨¡å¼çš„å¤šæ¨¡å¼è¯„ä¼°è®¾è®¡çš„åé—¨å­¦ä¹ å·¥å…·å’ŒåŸºå‡†æµ‹è¯•ï¼Œæ¶µç›–äº†åä¸€ä¸ªå¸¸ç”¨æ•°æ®é›†çš„è¯„ä¼°ã€‚BackdoorMBTIæä¾›äº†ä¸€ä¸ªç³»ç»Ÿçš„åé—¨å­¦ä¹ ç®¡é“ï¼ŒåŒ…æ‹¬æ•°æ®å¤„ç†ã€æ•°æ®ä¸­æ¯’ã€åé—¨è®­ç»ƒå’Œè¯„ä¼°ã€‚ç”Ÿæˆçš„æ¯’æ•°æ®é›†å’Œåé—¨æ¨¡å‹èƒ½å¤Ÿè¯¦ç»†è¯„ä¼°åé—¨é˜²å¾¡ã€‚é‰´äºæ¨¡å¼çš„å¤šæ ·æ€§ï¼ŒBackdoorMBTIä¿ƒè¿›äº†ä¸åŒæ•°æ®ç±»å‹ä¹‹é—´çš„ç³»ç»Ÿè¯„ä¼°ã€‚æ­¤å¤–ï¼ŒBackdoorMBTIè¿˜æä¾›äº†ä¸€ç§æ ‡å‡†åŒ–æ–¹æ³•ï¼Œç”¨äºå¤„ç†åé—¨å­¦ä¹ ä¸­çš„å®é™…é—®é¢˜ï¼Œå¦‚ä¸æ•°æ®è´¨é‡å’Œé”™è¯¯æ ‡ç­¾ç›¸å…³çš„é—®é¢˜ã€‚æˆ‘ä»¬é¢„è®¡BackdoorMBTIå°†åŠ é€Ÿå¤šæ¨¡å¼ä¸‹çš„åé—¨é˜²å¾¡æ–¹æ³•çš„ç ”ç©¶ã€‚ä»£ç å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/SJTUHaiyangYu/BackdoorMBTI">https://github.com/SJTUHaiyangYu/BackdoorMBTI</a>æ‰¾åˆ°ã€‚</p>
<p><strong>å…³é”®è§è§£</strong></p>
<ol>
<li>åé—¨æ”»å‡»å¯¹æ·±åº¦å­¦ä¹ ç³»ç»Ÿæ„æˆé‡å¤§æŒ‘æˆ˜ï¼Œèƒ½å¤Ÿåœ¨ç¥ç»ç½‘ç»œä¸­æ¤å…¥åé—¨ï¼Œå¯¼è‡´ç‰¹å®šæ•°æ®è§¦å‘è¯¯é¢„æµ‹ã€‚</li>
<li>åé—¨æ”»å‡»çš„èŒƒå›´å·²æ‰©å±•åˆ°è‡ªç„¶è¯­è¨€å¤„ç†å’Œè¯­éŸ³è¯†åˆ«ç­‰é¢†åŸŸã€‚</li>
<li>ç°æœ‰çš„åé—¨é˜²å¾¡æ–¹æ³•é€šå¸¸é’ˆå¯¹ç‰¹å®šæ•°æ®æ¨¡å¼ï¼Œç¼ºä¹å¤šæ¨¡å¼ä¸Šä¸‹æ–‡ä¸­çš„åº”ç”¨èƒ½åŠ›ã€‚</li>
<li>å¤šæ¨¡å¼å­¦ä¹ åœ¨å¤šä¸ªé¢†åŸŸå…·æœ‰é€‚ç”¨æ€§ï¼Œä½†æ¨¡å‹çš„å®‰å…¨æ€§ä»æ˜¯å…³é”®å…³æ³¨ç‚¹ã€‚</li>
<li>ç›®å‰ç¼ºä¹é’ˆå¯¹å¤šæ¨¡å¼åº”ç”¨æˆ–ç›¸å…³ä»»åŠ¡çš„åé—¨åŸºå‡†æµ‹è¯•ã€‚</li>
<li>BackdoorMBTIæ˜¯é¦–ä¸ªä¸ºè·¨å¤šç§æ¨¡å¼çš„å¤šæ¨¡å¼è¯„ä¼°è®¾è®¡çš„åé—¨å­¦ä¹ å·¥å…·å’ŒåŸºå‡†æµ‹è¯•ï¼Œæ¶µç›–äº†åä¸€ä¸ªæ•°æ®é›†ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2411.11006">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-33a87def5ef1c24490d8f6b840d6f213.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-69f2d014025c8d046a57ce88d1220a62.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-5ef7352fb9dbf48955921bd84cb02ac6.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b11758cfc698a00cdee3d7a9c60eebcd.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-0179407fdb92ec208ccd566c02917281.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-06b4cf68106e24037974fea70518288b.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="SonicSim-A-customizable-simulation-platform-for-speech-processing-in-moving-sound-source-scenarios"><a href="#SonicSim-A-customizable-simulation-platform-for-speech-processing-in-moving-sound-source-scenarios" class="headerlink" title="SonicSim: A customizable simulation platform for speech processing in   moving sound source scenarios"></a>SonicSim: A customizable simulation platform for speech processing in   moving sound source scenarios</h2><p><strong>Authors:Kai Li, Wendi Sang, Chang Zeng, Runxuan Yang, Guo Chen, Xiaolin Hu</strong></p>
<p>Systematic evaluation of speech separation and enhancement models under moving sound source conditions requires extensive and diverse data. However, real-world datasets often lack sufficient data for training and evaluation, and synthetic datasets, while larger, lack acoustic realism. Consequently, neither effectively meets practical needs. To address this issue, we introduce SonicSim, a synthetic toolkit based on the embodied AI simulation platform Habitat-sim, designed to generate highly customizable data for moving sound sources. SonicSim supports multi-level adjustments, including scene-level, microphone-level, and source-level adjustments, enabling the creation of more diverse synthetic data. Leveraging SonicSim, we constructed a benchmark dataset called SonicSet, utilizing LibriSpeech, Freesound Dataset 50k (FSD50K), Free Music Archive (FMA), and 90 scenes from Matterport3D to evaluate speech separation and enhancement models. Additionally, to investigate the differences between synthetic and real-world data, we selected 5 hours of raw, non-reverberant data from the SonicSet validation set and recorded a real-world speech separation dataset, providing a reference for comparing SonicSet with other synthetic datasets. For speech enhancement, we utilized the real-world dataset RealMAN to validate the acoustic gap between SonicSet and existing synthetic datasets. The results indicate that models trained on SonicSet generalize better to real-world scenarios compared to other synthetic datasets. The code is publicly available at <a target="_blank" rel="noopener" href="https://cslikai.cn/SonicSim/">https://cslikai.cn/SonicSim/</a>. </p>
<blockquote>
<p>å¯¹ç§»åŠ¨å£°æºæ¡ä»¶ä¸‹çš„è¯­éŸ³åˆ†ç¦»å’Œå¢å¼ºæ¨¡å‹è¿›è¡Œç³»ç»Ÿè¯„ä¼°éœ€è¦å¤§é‡çš„å¤šæ ·åŒ–æ•°æ®ã€‚ç„¶è€Œï¼Œç°å®ä¸–ç•Œçš„æ•°æ®é›†é€šå¸¸ç¼ºä¹è¶³å¤Ÿçš„ç”¨äºè®­ç»ƒå’Œè¯„ä¼°çš„æ•°æ®ï¼Œè€Œåˆæˆæ•°æ®é›†è™½ç„¶è§„æ¨¡è¾ƒå¤§ï¼Œä½†ç¼ºä¹å£°éŸ³çš„çœŸå®æ€§ã€‚å› æ­¤ï¼Œå®ƒä»¬éƒ½ä¸èƒ½æœ‰æ•ˆåœ°æ»¡è¶³å®é™…éœ€æ±‚ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬å¼•å…¥äº†SonicSimï¼Œè¿™æ˜¯ä¸€ä¸ªåŸºäºå®ä½“AIä»¿çœŸå¹³å°Habitat-simçš„åˆæˆå·¥å…·åŒ…ï¼Œæ—¨åœ¨ç”Ÿæˆç”¨äºç§»åŠ¨å£°æºçš„é«˜åº¦å¯å®šåˆ¶æ•°æ®ã€‚SonicSimæ”¯æŒå¤šçº§è°ƒæ•´ï¼ŒåŒ…æ‹¬åœºæ™¯çº§ã€éº¦å…‹é£çº§å’Œæºçº§è°ƒæ•´ï¼Œèƒ½å¤Ÿåˆ›å»ºæ›´å¤šæ ·åŒ–çš„åˆæˆæ•°æ®ã€‚åˆ©ç”¨SonicSimï¼Œæˆ‘ä»¬æ„å»ºäº†ä¸€ä¸ªåä¸ºSonicSetçš„åŸºå‡†æ•°æ®é›†ï¼Œåˆ©ç”¨LibriSpeechã€Freesoundæ•°æ®é›†50kï¼ˆFSD50Kï¼‰ã€è‡ªç”±éŸ³ä¹æ¡£æ¡ˆï¼ˆFMAï¼‰å’ŒMatterport3Dçš„90ä¸ªåœºæ™¯æ¥è¯„ä¼°è¯­éŸ³åˆ†ç¦»å’Œå¢å¼ºæ¨¡å‹ã€‚æ­¤å¤–ï¼Œä¸ºäº†ç ”ç©¶åˆæˆæ•°æ®ä¸ç°å®æ•°æ®ä¹‹é—´çš„å·®å¼‚ï¼Œæˆ‘ä»¬ä»SonicSetéªŒè¯é›†ä¸­é€‰æ‹©äº†5å°æ—¶çš„åŸç”Ÿéæ··å“æ•°æ®ï¼Œå¹¶å½•åˆ¶äº†ä¸€ä¸ªç°å®è¯­éŸ³åˆ†ç¦»æ•°æ®é›†ï¼Œä¸ºå°†SonicSetä¸å…¶ä»–åˆæˆæ•°æ®é›†è¿›è¡Œæ¯”è¾ƒæä¾›äº†å‚è€ƒã€‚å¯¹äºè¯­éŸ³å¢å¼ºï¼Œæˆ‘ä»¬åˆ©ç”¨ç°å®ä¸–ç•Œçš„æ•°æ®é›†RealMANæ¥éªŒè¯SonicSetä¸å…¶ä»–åˆæˆæ•°æ®é›†ä¹‹é—´çš„å£°å­¦å·®è·ã€‚ç»“æœè¡¨æ˜ï¼Œåœ¨SonicSetä¸Šè®­ç»ƒçš„æ¨¡å‹åœ¨ç°å®ä¸–ç•Œåœºæ™¯ä¸­çš„æ³›åŒ–èƒ½åŠ›æ¯”å…¶ä»–åˆæˆæ•°æ®é›†æ›´å¥½ã€‚ä»£ç å·²å…¬å¼€åœ¨<a target="_blank" rel="noopener" href="https://cslikai.cn/SonicSim/">https://cslikai.cn/SonicSim/</a>ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2410.01481v2">PDF</a> Accepted by ICLR 2025</p>
<p><strong>æ‘˜è¦</strong></p>
<p>æ–‡ç« ä»‹ç»äº†SonicSimï¼Œä¸€ä¸ªåŸºäºè™šæ‹Ÿä»¿çœŸå¹³å°Embodied AI Simulationçš„è¯­éŸ³åˆæˆå·¥å…·åŒ…ï¼Œç”¨äºç”Ÿæˆå…·æœ‰ç§»åŠ¨å£°æºçš„é«˜å®šåˆ¶åŒ–æ•°æ®ã€‚å€ŸåŠ©SonicSimå·¥å…·åŒ…åˆ›å»ºçš„æ•°æ®é›†SonicSetç”¨äºè¯„ä¼°è¯­éŸ³åˆ†ç¦»å’Œå¢å¼ºæ¨¡å‹ã€‚è¯¥æ•°æ®é›†èåˆäº†LibriSpeechã€Freesound Dataset 50kã€Free Music Archiveä»¥åŠMatterport3Dçš„90ä¸ªåœºæ™¯æ•°æ®ã€‚æ–‡ç« è¿˜æ¢è®¨äº†åˆæˆæ•°æ®ä¸çœŸå®æ•°æ®ä¹‹é—´çš„å·®å¼‚ï¼Œå¹¶å…¬å¼€äº†ä»£ç ã€‚ç ”ç©¶ç»“æœè¡¨æ˜ï¼ŒåŸºäºSonicSetè®­ç»ƒçš„æ¨¡å‹åœ¨çœŸå®åœºæ™¯ä¸­çš„æ³›åŒ–èƒ½åŠ›ç›¸è¾ƒäºå…¶ä»–åˆæˆæ•°æ®é›†æœ‰æ‰€æå‡ã€‚</p>
<p><strong>å…³é”®è§è§£</strong></p>
<ol>
<li>æ–‡ç« å¼ºè°ƒäº†åœ¨ç§»åŠ¨å£°æºæ¡ä»¶ä¸‹è¯„ä¼°è¯­éŸ³åˆ†ç¦»å’Œå¢å¼ºæ¨¡å‹çš„ç³»ç»Ÿæ€§è¯„ä¼°éœ€è¦å¤šæ ·ä¸”å¹¿æ³›çš„æ•°æ®é›†ã€‚</li>
<li>çœŸå®æ•°æ®é›†å¸¸å¸¸ç¼ºä¹è¶³å¤Ÿçš„è®­ç»ƒä¸è¯„ä¼°æ•°æ®ï¼Œè€Œåˆæˆæ•°æ®é›†è™½ç„¶è§„æ¨¡è¾ƒå¤§ä½†ç¼ºä¹å£°å­¦çœŸå®æ€§ã€‚</li>
<li>ä»‹ç»äº†SonicSimå·¥å…·åŒ…ï¼Œè¯¥å·¥å…·åŒ…èƒ½åœ¨åœºæ™¯ã€éº¦å…‹é£å’ŒéŸ³æºç­‰å¤šä¸ªå±‚é¢è¿›è¡Œè°ƒæ•´ï¼Œä»è€Œç”Ÿæˆæ›´ä¸ºå¤šæ ·åŒ–çš„åˆæˆæ•°æ®ã€‚</li>
<li>ä½¿ç”¨SonicSimåˆ›å»ºçš„SonicSetæ•°æ®é›†èåˆäº†å¤šç§æ•°æ®æºï¼Œç”¨äºè¯„ä¼°è¯­éŸ³åˆ†ç¦»å’Œå¢å¼ºæ¨¡å‹ã€‚</li>
<li>ä¸ºäº†ç ”ç©¶åˆæˆæ•°æ®ä¸çœŸå®æ•°æ®ä¹‹é—´çš„å·®å¼‚ï¼Œæ–‡ç« é€‰æ‹©äº†SonicSetéªŒè¯é›†çš„5å°æ—¶éæ··å“æ•°æ®è¿›è¡Œè®°å½•ï¼Œå¹¶åˆ›å»ºäº†ä¸€ä¸ªçœŸå®ä¸–ç•Œçš„è¯­éŸ³åˆ†ç¦»æ•°æ®é›†ã€‚</li>
<li>å¯¹æ¯”å…¶ä»–åˆæˆæ•°æ®é›†ï¼ŒåŸºäºSonicSetè®­ç»ƒçš„æ¨¡å‹åœ¨çœŸå®åœºæ™¯ä¸­çš„è¡¨ç°æ›´ä½³ã€‚</li>
<li>æ–‡ç« å…¬å¼€äº†SonicSimå·¥å…·çš„ä»£ç ï¼Œä¾¿äºåç»­ç ”ç©¶ä½¿ç”¨ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2410.01481">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-c54e1fccbc995f97fe4928bd3db2d1f8.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-833b7525cba684dd13b2a90b7fbb4eb8.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c4c6597a8af3c741680749b5d3602c30.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-61990e9b45d2aa771ed13a890718f9b7.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-60a8084c864c83ee226eade96a16ecf3.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="TIGER-Time-frequency-Interleaved-Gain-Extraction-and-Reconstruction-for-Efficient-Speech-Separation"><a href="#TIGER-Time-frequency-Interleaved-Gain-Extraction-and-Reconstruction-for-Efficient-Speech-Separation" class="headerlink" title="TIGER: Time-frequency Interleaved Gain Extraction and Reconstruction for   Efficient Speech Separation"></a>TIGER: Time-frequency Interleaved Gain Extraction and Reconstruction for   Efficient Speech Separation</h2><p><strong>Authors:Mohan Xu, Kai Li, Guo Chen, Xiaolin Hu</strong></p>
<p>In recent years, much speech separation research has focused primarily on improving model performance. However, for low-latency speech processing systems, high efficiency is equally important. Therefore, we propose a speech separation model with significantly reduced parameters and computational costs: Time-frequency Interleaved Gain Extraction and Reconstruction network (TIGER). TIGER leverages prior knowledge to divide frequency bands and compresses frequency information. We employ a multi-scale selective attention module to extract contextual features while introducing a full-frequency-frame attention module to capture both temporal and frequency contextual information. Additionally, to more realistically evaluate the performance of speech separation models in complex acoustic environments, we introduce a dataset called EchoSet. This dataset includes noise and more realistic reverberation (e.g., considering object occlusions and material properties), with speech from two speakers overlapping at random proportions. Experimental results showed that models trained on EchoSet had better generalization ability than those trained on other datasets compared to the data collected in the physical world, which validated the practical value of the EchoSet. On EchoSet and real-world data, TIGER significantly reduces the number of parameters by 94.3% and the MACs by 95.3% while achieving performance surpassing the state-of-the-art (SOTA) model TF-GridNet. </p>
<blockquote>
<p>è¿‘å¹´æ¥ï¼Œè¯­éŸ³åˆ†ç¦»ç ”ç©¶ä¸»è¦é›†ä¸­åœ¨æé«˜æ¨¡å‹æ€§èƒ½ä¸Šã€‚ç„¶è€Œï¼Œå¯¹äºä½å»¶è¿Ÿè¯­éŸ³å¤„ç†ç³»ç»Ÿæ¥è¯´ï¼Œé«˜æ•ˆç‡åŒæ ·é‡è¦ã€‚å› æ­¤ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§å‚æ•°å’Œè®¡ç®—æˆæœ¬å¤§å¹…å‡å°‘çš„è¯­éŸ³åˆ†ç¦»æ¨¡å‹ï¼šæ—¶é—´-é¢‘ç‡äº¤é”™å¢ç›Šæå–ä¸é‡å»ºç½‘ç»œï¼ˆTIGERï¼‰ã€‚TIGERåˆ©ç”¨å…ˆéªŒçŸ¥è¯†åˆ’åˆ†é¢‘å¸¦å¹¶å‹ç¼©é¢‘ç‡ä¿¡æ¯ã€‚æˆ‘ä»¬é‡‡ç”¨å¤šå°ºåº¦é€‰æ‹©æ€§æ³¨æ„æ¨¡å—æ¥æå–ä¸Šä¸‹æ–‡ç‰¹å¾ï¼Œå¹¶å¼•å…¥å…¨é¢‘å¸§æ³¨æ„æ¨¡å—æ¥æ•è·æ—¶é—´å’Œé¢‘ç‡ä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚æ­¤å¤–ï¼Œä¸ºäº†æ›´çœŸå®åœ°è¯„ä¼°å¤æ‚å£°å­¦ç¯å¢ƒä¸­è¯­éŸ³åˆ†ç¦»æ¨¡å‹çš„æ€§èƒ½ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ä¸ªåä¸ºEchoSetçš„æ•°æ®é›†ã€‚è¯¥æ•°æ®é›†åŒ…æ‹¬å™ªå£°å’Œæ›´ç°å®çš„æ··å“ï¼ˆä¾‹å¦‚ï¼Œè€ƒè™‘å¯¹è±¡é®æŒ¡å’Œææ–™å±æ€§ï¼‰ï¼Œæ¥è‡ªä¸¤ä¸ªè¯´è¯äººçš„è¯­éŸ³ä»¥éšæœºæ¯”ä¾‹é‡å ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œä¸åœ¨ç‰©ç†ä¸–ç•Œä¸­æ”¶é›†çš„æ•°æ®ç›¸æ¯”ï¼Œåœ¨EchoSetä¸Šè®­ç»ƒçš„æ¨¡å‹å…·æœ‰æ›´å¥½çš„æ³›åŒ–èƒ½åŠ›ã€‚è¿™éªŒè¯äº†EchoSetçš„å®ç”¨ä»·å€¼ã€‚åœ¨EchoSetå’ŒçœŸå®ä¸–ç•Œæ•°æ®ä¸Šï¼ŒTIGERåœ¨å‚æ•°æ•°é‡ä¸Šå‡å°‘äº†94.3%ï¼Œä¹˜åŠ æ“ä½œï¼ˆMACsï¼‰å‡å°‘äº†95.3%ï¼ŒåŒæ—¶æ€§èƒ½è¶…è¶Šäº†å½“å‰æœ€ä½³æ¨¡å‹TF-GridNetã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2410.01469v2">PDF</a> Accepted by ICLR 2025, demo page: <a target="_blank" rel="noopener" href="https://cslikai.cn/TIGER/">https://cslikai.cn/TIGER/</a></p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸ºTIGERçš„è¯­éŸ³åˆ†ç¦»æ¨¡å‹ï¼Œå…·æœ‰æ˜¾è‘—å‡å°‘çš„å‚æ•°å’Œè®¡ç®—æˆæœ¬ã€‚è¯¥æ¨¡å‹åˆ©ç”¨å…ˆéªŒçŸ¥è¯†åˆ’åˆ†é¢‘æ®µå¹¶å‹ç¼©é¢‘ç‡ä¿¡æ¯ï¼Œé‡‡ç”¨å¤šå°ºåº¦é€‰æ‹©æ€§æ³¨æ„æ¨¡å—æå–ä¸Šä¸‹æ–‡ç‰¹å¾ï¼Œå¹¶å¼•å…¥å…¨é¢‘å¸§æ³¨æ„æ¨¡å—æ•æ‰æ—¶é—´å’Œé¢‘ç‡ä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚ä¸ºæ›´ç°å®åœ°è¯„ä¼°è¯­éŸ³åˆ†ç¦»æ¨¡å‹åœ¨å¤æ‚å£°å­¦ç¯å¢ƒä¸­çš„æ€§èƒ½ï¼Œå¼•å…¥äº†EchoSetæ•°æ®é›†ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œåœ¨ç‰©ç†ä¸–ç•Œæ”¶é›†çš„æ•°æ®ä¸å…¶ä»–æ•°æ®é›†ç›¸æ¯”ï¼Œåœ¨EchoSetå’Œç°å®ä¸–ç•Œæ•°æ®ä¸Šè®­ç»ƒçš„æ¨¡å‹å…·æœ‰æ›´å¥½çš„æ³›åŒ–èƒ½åŠ›ï¼ŒéªŒè¯äº†EchoSetçš„å®ç”¨ä»·å€¼ã€‚TIGERæ¨¡å‹åœ¨å‚æ•°å’ŒMACæ–¹é¢åˆ†åˆ«å‡å°‘äº†94.3%å’Œ95.3%ï¼ŒåŒæ—¶æ€§èƒ½è¶…è¶Šäº†ç°æœ‰æ¨¡å‹TF-GridNetã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>è¯­éŸ³åˆ†ç¦»ç ”ç©¶è¿‘å¹´æ¥ä¸»è¦å…³æ³¨æé«˜æ¨¡å‹æ€§èƒ½ï¼Œä½†å¯¹äºä½å»¶è¿Ÿè¯­éŸ³å¤„ç†ç³»ç»Ÿï¼Œé«˜æ•ˆç‡åŒæ ·é‡è¦ã€‚</li>
<li>æå‡ºäº†ä¸€ç§æ–°çš„è¯­éŸ³åˆ†ç¦»æ¨¡å‹TIGERï¼Œå…·æœ‰æ˜¾è‘—å‡å°‘çš„å‚æ•°å’Œè®¡ç®—æˆæœ¬ã€‚</li>
<li>TIGERæ¨¡å‹åˆ©ç”¨å…ˆéªŒçŸ¥è¯†å¤„ç†é¢‘ç‡ä¿¡æ¯ï¼Œå¹¶é‡‡ç”¨å¤šå°ºåº¦é€‰æ‹©æ€§æ³¨æ„æ¨¡å—å’Œå…¨é¢‘å¸§æ³¨æ„æ¨¡å—æ¥æ•æ‰ä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚</li>
<li>å¼•å…¥äº†EchoSetæ•°æ®é›†ï¼Œæ›´ç°å®åœ°æ¨¡æ‹Ÿå¤æ‚å£°å­¦ç¯å¢ƒä¸‹çš„è¯­éŸ³åˆ†ç¦»ã€‚</li>
<li>åœ¨EchoSetå’Œç°å®ä¸–ç•Œæ•°æ®ä¸Šè®­ç»ƒçš„æ¨¡å‹å…·æœ‰æ›´å¥½çš„æ³›åŒ–èƒ½åŠ›ï¼ŒéªŒè¯äº†EchoSetçš„å®ç”¨ä»·å€¼ã€‚</li>
<li>TIGERæ¨¡å‹åœ¨å‚æ•°å’Œè®¡ç®—é‡æ–¹é¢æœ‰è¾ƒå¤§ä¼˜åŒ–ï¼Œåˆ†åˆ«å‡å°‘äº†94.3%å’Œ95.3%ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2410.01469">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-2b0bbb0cec2cd19abb5ee58def14256b.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-a1f97bddee9135de5b6c3255177ecd9e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-cd9813dde0d765a687d5539cab54b75b.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-bd97e0ae85678a31ced107c22d1ac6d4.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-03-09/Speech/">https://kedreamix.github.io/Talk2Paper/Paper/2025-03-09/Speech/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/Speech/">
                                    <span class="chip bg-color">Speech</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-03-09/GAN/">
                    <div class="card-image">
                        
                        <img src="https://pic1.zhimg.com/v2-c30907be9e88147d3a507b7df4033fca.jpg" class="responsive-img" alt="GAN">
                        
                        <span class="card-title">GAN</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            GAN æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-03-09  Generating Novel Brain Morphology by Deforming Learned Templates
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-03-09
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/GAN/" class="post-category">
                                    GAN
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/GAN/">
                        <span class="chip bg-color">GAN</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-03-09/%E5%8C%BB%E5%AD%A6%E5%BD%B1%E5%83%8F_Breast%20Ultrasound/">
                    <div class="card-image">
                        
                        <img src="https://pic1.zhimg.com/v2-948d1250612ec8d4f62580fdc376390f.jpg" class="responsive-img" alt="åŒ»å­¦å½±åƒ/Breast Ultrasound">
                        
                        <span class="card-title">åŒ»å­¦å½±åƒ/Breast Ultrasound</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            åŒ»å­¦å½±åƒ/Breast Ultrasound æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-03-09  Enhancing SAM with Efficient Prompting and Preference Optimization for   Semi-supervised Medical Image Segmentation
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-03-09
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/%E5%8C%BB%E5%AD%A6%E5%BD%B1%E5%83%8F-Breast-Ultrasound/" class="post-category">
                                    åŒ»å­¦å½±åƒ/Breast Ultrasound
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/%E5%8C%BB%E5%AD%A6%E5%BD%B1%E5%83%8F-Breast-Ultrasound/">
                        <span class="chip bg-color">åŒ»å­¦å½±åƒ/Breast Ultrasound</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">15444.6k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
