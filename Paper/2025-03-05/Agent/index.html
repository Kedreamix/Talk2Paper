<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Agent">
    <meta name="description" content="Agent æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-03-05  FACT-AUDIT An Adaptive Multi-Agent Framework for Dynamic Fact-Checking   Evaluation of Large Language Models">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>Agent | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://pic1.zhimg.com/v2-3de82161d67aeb20a744e490e5639f7c.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Agent</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/Agent/">
                                <span class="chip bg-color">Agent</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/Agent/" class="post-category">
                                Agent
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-03-05
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-05-14
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    17k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    69 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-03-05-æ›´æ–°"><a href="#2025-03-05-æ›´æ–°" class="headerlink" title="2025-03-05 æ›´æ–°"></a>2025-03-05 æ›´æ–°</h1><h2 id="FACT-AUDIT-An-Adaptive-Multi-Agent-Framework-for-Dynamic-Fact-Checking-Evaluation-of-Large-Language-Models"><a href="#FACT-AUDIT-An-Adaptive-Multi-Agent-Framework-for-Dynamic-Fact-Checking-Evaluation-of-Large-Language-Models" class="headerlink" title="FACT-AUDIT: An Adaptive Multi-Agent Framework for Dynamic Fact-Checking   Evaluation of Large Language Models"></a>FACT-AUDIT: An Adaptive Multi-Agent Framework for Dynamic Fact-Checking   Evaluation of Large Language Models</h2><p><strong>Authors:Hongzhan Lin, Yang Deng, Yuxuan Gu, Wenxuan Zhang, Jing Ma, See-Kiong Ng, Tat-Seng Chua</strong></p>
<p>Large Language Models (LLMs) have significantly advanced the fact-checking studies. However, existing automated fact-checking evaluation methods rely on static datasets and classification metrics, which fail to automatically evaluate the justification production and uncover the nuanced limitations of LLMs in fact-checking. In this work, we introduce FACT-AUDIT, an agent-driven framework that adaptively and dynamically assesses LLMsâ€™ fact-checking capabilities. Leveraging importance sampling principles and multi-agent collaboration, FACT-AUDIT generates adaptive and scalable datasets, performs iterative model-centric evaluations, and updates assessments based on model-specific responses. By incorporating justification production alongside verdict prediction, this framework provides a comprehensive and evolving audit of LLMsâ€™ factual reasoning capabilities, to investigate their trustworthiness. Extensive experiments demonstrate that FACT-AUDIT effectively differentiates among state-of-the-art LLMs, providing valuable insights into model strengths and limitations in model-centric fact-checking analysis. </p>
<blockquote>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨äº‹å®æ ¸æŸ¥ç ”ç©¶æ–¹é¢å–å¾—äº†æ˜¾è‘—è¿›å±•ã€‚ç„¶è€Œï¼Œç°æœ‰çš„è‡ªåŠ¨åŒ–äº‹å®æ ¸æŸ¥è¯„ä¼°æ–¹æ³•ä¾èµ–äºé™æ€æ•°æ®é›†å’Œåˆ†ç±»æŒ‡æ ‡ï¼Œè¿™äº›æ–¹æ³•æ— æ³•è‡ªåŠ¨è¯„ä¼°ç†ç”±çš„äº§ç”Ÿï¼Œå¹¶ä¸”æ— æ³•æ­ç¤ºå¤§å‹è¯­è¨€æ¨¡å‹åœ¨äº‹å®æ ¸æŸ¥æ–¹é¢çš„å¾®å¦™å±€é™æ€§ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬å¼•å…¥äº†FACT-AUDITï¼Œä¸€ä¸ªç”±ä»£ç†é©±åŠ¨çš„æ¡†æ¶ï¼Œå®ƒè‡ªé€‚åº”ä¸”åŠ¨æ€åœ°è¯„ä¼°å¤§å‹è¯­è¨€æ¨¡å‹çš„äº‹å®æ ¸æŸ¥èƒ½åŠ›ã€‚åˆ©ç”¨é‡è¦æ€§é‡‡æ ·åŸç†å’Œå¤šå…ƒåˆä½œæœºåˆ¶ï¼ŒFACT-AUDITç”Ÿæˆè‡ªé€‚åº”çš„å¯æ‰©å±•æ•°æ®é›†ï¼Œæ‰§è¡Œè¿­ä»£æ¨¡å‹ä¸ºä¸­å¿ƒçš„è¯„ä¼°ï¼Œå¹¶æ ¹æ®æ¨¡å‹ç‰¹å®šçš„å“åº”æ›´æ–°è¯„ä¼°ç»“æœã€‚é€šè¿‡ç»“åˆç†ç”±äº§ç”Ÿå’Œåˆ¤å†³é¢„æµ‹ï¼Œè¯¥æ¡†æ¶æä¾›äº†å¯¹å¤§å‹è¯­è¨€æ¨¡å‹çš„æ¨ç†èƒ½åŠ›çš„å…¨é¢è€Œä¸æ–­å‘å±•çš„å®¡è®¡ï¼Œä»¥è°ƒæŸ¥å…¶å¯ä¿¡åº¦ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼ŒFACT-AUDITåœ¨ä¸»æµçš„å¤§å‹è¯­è¨€æ¨¡å‹ä¹‹é—´è¿›è¡Œæœ‰æ•ˆåŒºåˆ†ï¼Œä¸ºæ¨¡å‹ä¸ºä¸­å¿ƒçš„äº‹å®æ ¸æŸ¥åˆ†æä¸­çš„æ¨¡å‹ä¼˜åŠ¿å’Œå±€é™æ€§æä¾›äº†æœ‰ä»·å€¼çš„è§è§£ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.17924v2">PDF</a> </p>
<p><strong>Summary</strong><br>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨äº‹å®æ ¸æŸ¥ç ”ç©¶ä¸­å–å¾—äº†æ˜¾è‘—è¿›å±•ã€‚ç„¶è€Œï¼Œç°æœ‰çš„è‡ªåŠ¨åŒ–äº‹å®æ ¸æŸ¥è¯„ä¼°æ–¹æ³•ä¾èµ–äºé™æ€æ•°æ®é›†å’Œåˆ†ç±»æŒ‡æ ‡ï¼Œæ— æ³•è‡ªåŠ¨è¯„ä¼°æ¨ç†äº§ç”Ÿçš„è¿‡ç¨‹å¹¶å‘ç°LLMåœ¨äº‹å®æ ¸æŸ¥ä¸­çš„å¾®å¦™å±€é™ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬å¼•å…¥äº†FACT-AUDITè¿™ä¸€ä»£ç†é©±åŠ¨æ¡†æ¶ï¼Œè¯¥æ¡†æ¶ä»¥é‡è¦æŠ½æ ·åŸåˆ™å’Œå¤šä»£ç†åä½œä¸ºæ ¸å¿ƒï¼Œèƒ½å¤Ÿè‡ªé€‚åº”ä¸”åŠ¨æ€åœ°è¯„ä¼°LLMçš„äº‹å®æ ¸æŸ¥èƒ½åŠ›ã€‚ç»“åˆåˆ¤å®šç»“æœçš„é¢„æµ‹å’Œæ¨ç†è¿‡ç¨‹ï¼Œè¯¥æ¡†æ¶æä¾›äº†å¯¹LLMäº‹å®æ¨ç†èƒ½åŠ›çš„å…¨é¢ä¸”ä¸æ–­å‘å±•çš„å®¡è®¡ï¼Œä»¥è°ƒæŸ¥å…¶å¯ä¿¡åº¦ã€‚å¤§é‡å®éªŒè¯æ˜ï¼ŒFACT-AUDITèƒ½æœ‰æ•ˆåŒºåˆ†ä¸åŒå…ˆè¿›æ°´å¹³çš„LLMï¼Œä¸ºæ¨¡å‹ä¸­å¿ƒçš„äº‹å®æ ¸æŸ¥åˆ†ææä¾›äº†å®è´µçš„è§è§£ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨äº‹å®æ ¸æŸ¥é¢†åŸŸæœ‰é‡è¦è¿›å±•ã€‚</li>
<li>ç°æœ‰è¯„ä¼°æ–¹æ³•ä¸»è¦ä¾èµ–é™æ€æ•°æ®é›†å’Œåˆ†ç±»æŒ‡æ ‡ï¼Œå­˜åœ¨å±€é™æ€§ã€‚</li>
<li>FACT-AUDITæ¡†æ¶èƒ½è‡ªé€‚åº”ã€åŠ¨æ€åœ°è¯„ä¼°LLMçš„äº‹å®æ ¸æŸ¥èƒ½åŠ›ã€‚</li>
<li>è¯¥æ¡†æ¶ç»“åˆåˆ¤å®šç»“æœçš„é¢„æµ‹å’Œæ¨ç†è¿‡ç¨‹ï¼Œæä¾›å…¨é¢çš„å®¡è®¡ã€‚</li>
<li>FACT-AUDITé€šè¿‡é‡è¦æŠ½æ ·åŸåˆ™å’Œå¤šä»£ç†åä½œå®ç°è¯„ä¼°ã€‚</li>
<li>å®éªŒè¯æ˜FACT-AUDITèƒ½æœ‰æ•ˆåŒºåˆ†ä¸åŒæ°´å¹³çš„LLMã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.17924">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-600dcf78bb9e54f3945d62b5039a5a08.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d5e1d1a6ae7aa971d262a57bb974958f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-2766002e220373f4f271299095bdb086.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-34bea02d7527c279f8cda28a1a1e5fe8.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="A-MEM-Agentic-Memory-for-LLM-Agents"><a href="#A-MEM-Agentic-Memory-for-LLM-Agents" class="headerlink" title="A-MEM: Agentic Memory for LLM Agents"></a>A-MEM: Agentic Memory for LLM Agents</h2><p><strong>Authors:Wujiang Xu, Zujie Liang, Kai Mei, Hang Gao, Juntao Tan, Yongfeng Zhang</strong></p>
<p>While large language model (LLM) agents can effectively use external tools for complex real-world tasks, they require memory systems to leverage historical experiences. Current memory systems enable basic storage and retrieval but lack sophisticated memory organization, despite recent attempts to incorporate graph databases. Moreover, these systemsâ€™ fixed operations and structures limit their adaptability across diverse tasks. To address this limitation, this paper proposes a novel agentic memory system for LLM agents that can dynamically organize memories in an agentic way. Following the basic principles of the Zettelkasten method, we designed our memory system to create interconnected knowledge networks through dynamic indexing and linking. When a new memory is added, we generate a comprehensive note containing multiple structured attributes, including contextual descriptions, keywords, and tags. The system then analyzes historical memories to identify relevant connections, establishing links where meaningful similarities exist. Additionally, this process enables memory evolution - as new memories are integrated, they can trigger updates to the contextual representations and attributes of existing historical memories, allowing the memory network to continuously refine its understanding. Our approach combines the structured organization principles of Zettelkasten with the flexibility of agent-driven decision making, allowing for more adaptive and context-aware memory management. Empirical experiments on six foundation models show superior improvement against existing SOTA baselines. The source code is available at <a target="_blank" rel="noopener" href="https://github.com/WujiangXu/AgenticMemory">https://github.com/WujiangXu/AgenticMemory</a>. </p>
<blockquote>
<p>è™½ç„¶å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä»£ç†å¯ä»¥æœ‰æ•ˆåœ°åˆ©ç”¨å¤–éƒ¨å·¥å…·æ¥å®Œæˆå¤æ‚çš„ç°å®ä¸–ç•Œä»»åŠ¡ï¼Œä½†å®ƒä»¬éœ€è¦è®°å¿†ç³»ç»Ÿæ¥åˆ©ç”¨å†å²ç»éªŒã€‚å½“å‰çš„è®°å¿†ç³»ç»Ÿè™½ç„¶å®ç°äº†åŸºæœ¬çš„å­˜å‚¨å’Œæ£€ç´¢åŠŸèƒ½ï¼Œä½†ç¼ºä¹é«˜çº§çš„è®°å¿†ç»„ç»‡åŠŸèƒ½ï¼Œå°½ç®¡æœ€è¿‘å°è¯•å¼•å…¥äº†å›¾æ•°æ®åº“ã€‚æ­¤å¤–ï¼Œè¿™äº›ç³»ç»Ÿçš„å›ºå®šæ“ä½œå’Œç»“æ„é™åˆ¶äº†å®ƒä»¬åœ¨å¤šæ ·åŒ–ä»»åŠ¡ä¸­çš„é€‚åº”æ€§ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é™åˆ¶ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°å‹çš„å¤§å‹è¯­è¨€æ¨¡å‹ä»£ç†çš„è®°å¿†ç³»ç»Ÿï¼Œè¯¥ç³»ç»Ÿèƒ½å¤Ÿä»¥åŠ¨æ€çš„æ–¹å¼ç»„ç»‡è®°å¿†ã€‚æˆ‘ä»¬éµå¾ªZettelkastenæ–¹æ³•çš„åŸºæœ¬åŸåˆ™ï¼Œè®¾è®¡äº†ä¸€ä¸ªè®°å¿†ç³»ç»Ÿï¼Œé€šè¿‡åŠ¨æ€ç´¢å¼•å’Œé“¾æ¥åˆ›å»ºç›¸äº’å…³è”çš„çŸ¥è¯†ç½‘ç»œã€‚æ¯å½“æ·»åŠ ä¸€ä¸ªæ–°è®°å¿†æ—¶ï¼Œæˆ‘ä»¬ä¼šç”Ÿæˆä¸€ä¸ªåŒ…å«å¤šä¸ªç»“æ„åŒ–å±æ€§çš„ç»¼åˆç¬”è®°ï¼ŒåŒ…æ‹¬ä¸Šä¸‹æ–‡æè¿°ã€å…³é”®è¯å’Œæ ‡ç­¾ã€‚ç„¶åï¼Œç³»ç»Ÿåˆ†æå†å²è®°å¿†ä»¥è¯†åˆ«ç›¸å…³è”ç³»ï¼Œåœ¨å­˜åœ¨æœ‰æ„ä¹‰çš„ç›¸ä¼¼æ€§æ—¶å»ºç«‹é“¾æ¥ã€‚æ­¤å¤–ï¼Œè¿™ä¸ªè¿‡ç¨‹å®ç°äº†è®°å¿†çš„è¿›åŒ–â€”â€”æ–°è®°å¿†çš„é›†æˆå¯ä»¥è§¦å‘å¯¹ç°æœ‰å†å²è®°å¿†çš„ä¸Šä¸‹æ–‡è¡¨ç¤ºå’Œå±æ€§çš„æ›´æ–°ï¼Œä½¿è®°å¿†ç½‘ç»œèƒ½å¤Ÿä¸æ–­åœ°æé«˜å…¶ç†è§£ã€‚æˆ‘ä»¬çš„æ–¹æ³•ç»“åˆäº†Zettelkastençš„ç»“æ„åŒ–ç»„ç»‡åŸåˆ™ä¸ä»£ç†é©±åŠ¨å†³ç­–çš„çµæ´»æ€§ï¼Œå®ç°äº†æ›´é€‚åº”ä¸Šä¸‹æ–‡çš„è®°å¿†ç®¡ç†ã€‚åœ¨å…­ä¸ªåŸºç¡€æ¨¡å‹ä¸Šçš„å®è¯å®éªŒè¡¨æ˜ï¼Œä¸ç°æœ‰çš„æœ€ä½³åŸºçº¿ç›¸æ¯”ï¼Œæˆ‘ä»¬çš„æ–¹æ³•æœ‰æ˜æ˜¾çš„æ”¹è¿›ã€‚æºä»£ç å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/WujiangXu/AgenticMemory%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/WujiangXu/AgenticMemoryæ‰¾åˆ°ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.12110v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºä¸€ç§ç”¨äºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„æ–°å‹æ™ºèƒ½è®°å¿†ç³»ç»Ÿï¼Œè¯¥ç³»ç»Ÿé‡‡ç”¨åŠ¨æ€ç»„ç»‡æ–¹å¼ï¼Œå¯å»ºç«‹çŸ¥è¯†ç½‘ç»œï¼Œæé«˜è®°å¿†ç®¡ç†çš„é€‚åº”æ€§å’Œä¸Šä¸‹æ–‡æ„ŸçŸ¥èƒ½åŠ›ã€‚é€šè¿‡ç”ŸæˆåŒ…å«å¤šä¸ªç»“æ„åŒ–å±æ€§çš„å…¨é¢ç¬”è®°ï¼Œå¹¶åˆ†æå†å²è®°å¿†æ¥å»ºç«‹è”ç³»ï¼Œå®ç°è®°å¿†ç½‘ç»œçš„æŒç»­å®Œå–„ã€‚åœ¨å…­ä¸ªåŸºç¡€æ¨¡å‹ä¸Šçš„å®è¯å®éªŒè¡¨æ˜ï¼Œè¯¥ç³»ç»Ÿçš„æ€§èƒ½ä¼˜äºç°æœ‰æœ€ä½³åŸºçº¿ã€‚æºä»£ç å·²å…¬å¼€ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰éœ€è¦è®°å¿†ç³»ç»Ÿåˆ©ç”¨å†å²ç»éªŒæ¥å®Œæˆå¤æ‚ä»»åŠ¡ã€‚</li>
<li>å½“å‰è®°å¿†ç³»ç»Ÿä¸»è¦æ”¯æŒåŸºæœ¬å­˜å‚¨å’Œæ£€ç´¢åŠŸèƒ½ï¼Œç¼ºä¹é«˜çº§è®°å¿†ç»„ç»‡èƒ½åŠ›å’Œé€‚åº”æ€§ã€‚</li>
<li>è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§æ–°å‹æ™ºèƒ½è®°å¿†ç³»ç»Ÿï¼Œå¯åŠ¨æ€ç»„ç»‡çŸ¥è¯†ç½‘ç»œä»¥åº”å¯¹ä¸åŒä»»åŠ¡çš„éœ€æ±‚ã€‚</li>
<li>ç³»ç»Ÿé‡‡ç”¨Zettelkastenæ–¹æ³•çš„ç»“æ„åŒ–ç»„ç»‡åŸåˆ™ï¼Œé€šè¿‡åŠ¨æ€ç´¢å¼•å’Œé“¾æ¥åˆ›å»ºäº’è”çŸ¥è¯†ç½‘ç»œã€‚</li>
<li>è¯¥ç³»ç»Ÿå¯ç”ŸæˆåŒ…å«ç»“æ„åŒ–å±æ€§çš„å…¨é¢ç¬”è®°ï¼Œå¹¶è¿›è¡Œåˆ†æä»¥è¯†åˆ«ä¸ç°æœ‰è®°å¿†çš„å…³è”ï¼Œä»è€Œå®ç°è®°å¿†ç½‘ç»œçš„æŒç»­æ”¹è¿›ã€‚</li>
<li>æ™ºèƒ½è®°å¿†ç³»ç»Ÿç»“åˆäº†Zettelkastençš„ç»“æ„åŒ–åŸåˆ™å’Œè‡ªä¸»å†³ç­–çš„æ™ºèƒ½é€‰æ‹©èƒ½åŠ›ï¼Œå¢å¼ºäº†ä¸Šä¸‹æ–‡æ„ŸçŸ¥å’Œé€‚åº”æ€§ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.12110">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-0b44fb6a7330174e92fa48274f525e20.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-43f60cff38e4f45d95c7cc2c7568c14b.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-6d4a3e95cf2de0ecf3b48d938d5aff05.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="Leveraging-Dual-Process-Theory-in-Language-Agent-Framework-for-Real-time-Simultaneous-Human-AI-Collaboration"><a href="#Leveraging-Dual-Process-Theory-in-Language-Agent-Framework-for-Real-time-Simultaneous-Human-AI-Collaboration" class="headerlink" title="Leveraging Dual Process Theory in Language Agent Framework for Real-time   Simultaneous Human-AI Collaboration"></a>Leveraging Dual Process Theory in Language Agent Framework for Real-time   Simultaneous Human-AI Collaboration</h2><p><strong>Authors:Shao Zhang, Xihuai Wang, Wenhao Zhang, Chaoran Li, Junru Song, Tingyu Li, Lin Qiu, Xuezhi Cao, Xunliang Cai, Wen Yao, Weinan Zhang, Xinbing Wang, Ying Wen</strong></p>
<p>Agents built on large language models (LLMs) have excelled in turn-by-turn human-AI collaboration but struggle with simultaneous tasks requiring real-time interaction. Latency issues and the challenge of inferring variable human strategies hinder their ability to make autonomous decisions without explicit instructions. Through experiments with current independent System 1 and System 2 methods, we validate the necessity of using Dual Process Theory (DPT) in real-time tasks. We propose DPT-Agent, a novel language agent framework that integrates System 1 and System 2 for efficient real-time simultaneous human-AI collaboration. DPT-Agentâ€™s System 1 uses a Finite-state Machine (FSM) and code-as-policy for fast, intuitive, and controllable decision-making. DPT-Agentâ€™s System 2 integrates Theory of Mind (ToM) and asynchronous reflection to infer human intentions and perform reasoning-based autonomous decisions. We demonstrate the effectiveness of DPT-Agent through further experiments with rule-based agents and human collaborators, showing significant improvements over mainstream LLM-based frameworks. DPT-Agent can effectively help LLMs convert correct slow thinking and reasoning into executable actions, thereby improving performance. To the best of our knowledge, DPT-Agent is the first language agent framework that achieves successful real-time simultaneous human-AI collaboration autonomously. Code of DPT-Agent can be found in <a target="_blank" rel="noopener" href="https://github.com/sjtu-marl/DPT-Agent">https://github.com/sjtu-marl/DPT-Agent</a>. </p>
<blockquote>
<p>åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„ä»£ç†åœ¨äººæœºåä½œæ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œä½†åœ¨éœ€è¦å®æ—¶äº¤äº’çš„åŒæ—¶ä»»åŠ¡æ–¹é¢é‡åˆ°äº†æŒ‘æˆ˜ã€‚å»¶è¿Ÿé—®é¢˜å’Œæ¨æ–­å¯å˜äººç±»ç­–ç•¥çš„å›°éš¾é˜»ç¢äº†å®ƒä»¬åœ¨æ²¡æœ‰æ˜ç¡®æŒ‡ä»¤çš„æƒ…å†µä¸‹è¿›è¡Œè‡ªä¸»å†³ç­–çš„èƒ½åŠ›ã€‚æˆ‘ä»¬é€šè¿‡ç›®å‰ç‹¬ç«‹çš„System 1å’ŒSystem 2æ–¹æ³•çš„å®éªŒï¼ŒéªŒè¯äº†å®æ—¶ä»»åŠ¡ä¸­ä½¿ç”¨åŒè¿‡ç¨‹ç†è®ºï¼ˆDPTï¼‰çš„å¿…è¦æ€§ã€‚æˆ‘ä»¬æå‡ºäº†DPT-Agentï¼Œè¿™æ˜¯ä¸€ç§æ–°å‹çš„è¯­è¨€ä»£ç†æ¡†æ¶ï¼Œå®ƒæ•´åˆäº†System 1å’ŒSystem 2ï¼Œä»¥å®ç°é«˜æ•ˆå®æ—¶çš„åŒæ—¶äººæœºåä½œã€‚DPT-Agentçš„System 1ä½¿ç”¨æœ‰é™çŠ¶æ€æœºï¼ˆFSMï¼‰å’Œä»£ç ç­–ç•¥è¿›è¡Œå¿«é€Ÿã€ç›´è§‚ä¸”å¯æ§çš„å†³ç­–ã€‚DPT-Agentçš„System 2ç»“åˆäº†å¿ƒæ™ºç†è®ºï¼ˆToMï¼‰å’Œå¼‚æ­¥åå°„æ¥æ¨æ–­äººç±»æ„å›¾å¹¶è¿›è¡ŒåŸºäºæ¨ç†çš„è‡ªä¸»å†³ç­–ã€‚æˆ‘ä»¬é€šè¿‡è¿›ä¸€æ­¥çš„ä¸åŸºäºè§„åˆ™çš„ä»£ç†å’Œäººç±»åˆä½œè€…è¿›è¡Œçš„å®éªŒè¯æ˜äº†DPT-Agentçš„æœ‰æ•ˆæ€§ï¼Œæ˜¾ç¤ºå‡ºå¯¹ä¸»æµLLMæ¡†æ¶çš„é‡å¤§æ”¹è¿›ã€‚DPT-Agentå¯ä»¥æœ‰æ•ˆåœ°å¸®åŠ©LLMå°†æ­£ç¡®çš„æ…¢æ€è€ƒå’Œæ¨ç†è½¬åŒ–ä¸ºå¯æ‰§è¡ŒåŠ¨ä½œï¼Œä»è€Œæé«˜æ€§èƒ½ã€‚æ®æˆ‘ä»¬æ‰€çŸ¥ï¼ŒDPT-Agentæ˜¯é¦–ä¸ªæˆåŠŸå®ç°å®æ—¶åŒæ­¥äººæœºåä½œçš„è‡ªä¸»è¯­è¨€ä»£ç†æ¡†æ¶ã€‚DPT-Agentçš„ä»£ç å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/sjtu-marl/DPT-Agent">https://github.com/sjtu-marl/DPT-Agent</a>ä¸­æ‰¾åˆ°ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.11882v3">PDF</a> Preprint under review. Update the experimental results of the   DeepSeek-R1 series models, o3-mini-high and o3-mini-medium</p>
<p><strong>Summary</strong>ï¼š<br>åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹çš„ä»£ç†åœ¨é€æ­¥äººæœºåä½œä¸­è¡¨ç°å‡ºè‰²ï¼Œä½†åœ¨éœ€è¦å®æ—¶äº¤äº’çš„åŒæ—¶ä»»åŠ¡ä¸­é‡åˆ°å›°éš¾ã€‚é€šè¿‡ç»“åˆç³»ç»Ÿä¸€å’Œç³»ç»ŸäºŒçš„åŒè¿‡ç¨‹ç†è®ºï¼Œæå‡ºäº†ä¸€ä¸ªæ–°å‹è¯­è¨€ä»£ç†æ¡†æ¶DPT-Agentï¼Œèƒ½æœ‰æ•ˆå®ç°å®æ—¶çš„äººæœºåä½œã€‚DPT-AgentåŒ…æ‹¬ç³»ç»Ÿä¸€å’Œç³»ç»ŸäºŒä¸¤éƒ¨åˆ†ï¼Œç³»ç»Ÿä¸€é‡‡ç”¨æœ‰é™çŠ¶æ€æœºå®ç°å¿«é€Ÿã€ç›´è§‚å’Œå¯æ§çš„å†³ç­–åˆ¶å®šï¼Œç³»ç»ŸäºŒç»“åˆäº†å¿ƒæ™ºç†è®ºï¼Œèƒ½å¤Ÿæ¨æ–­äººç±»æ„å›¾å¹¶è¿›è¡ŒåŸºäºæ¨ç†çš„è‡ªä¸»å†³ç­–ã€‚ç›¸è¾ƒäºä¸»æµçš„å¤§å‹è¯­è¨€æ¨¡å‹æ¡†æ¶ï¼ŒDPT-Agentæ˜¾è‘—æ”¹å–„æ€§èƒ½ã€‚å®ƒæ˜¯é¦–ä¸ªæˆåŠŸå®ç°å®æ—¶åŒæ­¥äººæœºåä½œçš„è‡ªä¸»è¯­è¨€ä»£ç†æ¡†æ¶ã€‚</p>
<p><strong>Key Takeaways</strong>ï¼š</p>
<ol>
<li>å¤§å‹è¯­è¨€æ¨¡å‹ä»£ç†åœ¨å®æ—¶å¤šä»»åŠ¡åä½œä¸­é¢ä¸´æŒ‘æˆ˜ã€‚</li>
<li>åŒè¿‡ç¨‹ç†è®ºï¼ˆDPTï¼‰å¯¹äºå®æ—¶ä»»åŠ¡ä¸­çš„äººæœºåä½œè‡³å…³é‡è¦ã€‚</li>
<li>DPT-Agentç»“åˆäº†ç³»ç»Ÿä¸€å’Œç³»ç»ŸäºŒçš„ç†è®ºï¼Œå®ç°é«˜æ•ˆå®æ—¶äººæœºåä½œã€‚</li>
<li>DPT-Agentçš„ç³»ç»Ÿä¸€é‡‡ç”¨æœ‰é™çŠ¶æ€æœºè¿›è¡Œå¿«é€Ÿå†³ç­–ã€‚</li>
<li>DPT-Agentçš„ç³»ç»ŸäºŒç»“åˆäº†å¿ƒæ™ºç†è®ºï¼Œèƒ½æ¨æ–­äººç±»æ„å›¾å¹¶è‡ªä¸»å†³ç­–ã€‚</li>
<li>ä¸ä¸»æµçš„å¤§å‹è¯­è¨€æ¨¡å‹æ¡†æ¶ç›¸æ¯”ï¼ŒDPT-Agentæ˜¾è‘—æ”¹å–„æ€§èƒ½ã€‚</li>
<li>DPT-Agentæ˜¯é¦–ä¸ªæˆåŠŸå®ç°å®æ—¶åŒæ­¥äººæœºåä½œçš„è‡ªä¸»è¯­è¨€ä»£ç†æ¡†æ¶ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.11882">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-fb6a5ca4530593d8a9e82bd7a6f2c701.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c027fcd0b63915ce5f245556cb626eed.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-733c9d53acc340f1f314af5fd4ae9d7d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d6e817bd16d42e0f5cbcf78ed174e105.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="STMA-A-Spatio-Temporal-Memory-Agent-for-Long-Horizon-Embodied-Task-Planning"><a href="#STMA-A-Spatio-Temporal-Memory-Agent-for-Long-Horizon-Embodied-Task-Planning" class="headerlink" title="STMA: A Spatio-Temporal Memory Agent for Long-Horizon Embodied Task   Planning"></a>STMA: A Spatio-Temporal Memory Agent for Long-Horizon Embodied Task   Planning</h2><p><strong>Authors:Mingcong Lei, Yiming Zhao, Ge Wang, Zhixin Mai, Shuguang Cui, Yatong Han, Jinke Ren</strong></p>
<p>A key objective of embodied intelligence is enabling agents to perform long-horizon tasks in dynamic environments while maintaining robust decision-making and adaptability. To achieve this goal, we propose the Spatio-Temporal Memory Agent (STMA), a novel framework designed to enhance task planning and execution by integrating spatio-temporal memory. STMA is built upon three critical components: (1) a spatio-temporal memory module that captures historical and environmental changes in real time, (2) a dynamic knowledge graph that facilitates adaptive spatial reasoning, and (3) a planner-critic mechanism that iteratively refines task strategies. We evaluate STMA in the TextWorld environment on 32 tasks, involving multi-step planning and exploration under varying levels of complexity. Experimental results demonstrate that STMA achieves a 31.25% improvement in success rate and a 24.7% increase in average score compared to the state-of-the-art model. The results highlight the effectiveness of spatio-temporal memory in advancing the memory capabilities of embodied agents. </p>
<blockquote>
<p>ä½“æ„Ÿæ™ºèƒ½çš„å…³é”®ç›®æ ‡æ˜¯åœ¨åŠ¨æ€ç¯å¢ƒä¸­å®ç°é•¿å‘¨æœŸä»»åŠ¡çš„æ‰§è¡Œï¼ŒåŒæ—¶ä¿æŒå†³ç­–ç¨³å¥æ€§å’Œé€‚åº”æ€§ã€‚ä¸ºå®ç°è¿™ä¸€ç›®æ ‡ï¼Œæˆ‘ä»¬æå‡ºäº†æ—¶ç©ºè®°å¿†æ™ºèƒ½ä½“ï¼ˆSTMAï¼‰ï¼Œè¿™æ˜¯ä¸€ç§æ–°å‹æ¡†æ¶ï¼Œæ—¨åœ¨é€šè¿‡é›†æˆæ—¶ç©ºè®°å¿†å¢å¼ºä»»åŠ¡è§„åˆ’å’Œæ‰§è¡Œã€‚STMAå»ºç«‹åœ¨ä¸‰ä¸ªå…³é”®ç»„ä»¶ä¹‹ä¸Šï¼šï¼ˆ1ï¼‰æ—¶ç©ºè®°å¿†æ¨¡å—ï¼Œå®æ—¶æ•è·å†å²å’Œç¯å¢ƒå˜åŒ–ï¼›ï¼ˆ2ï¼‰åŠ¨æ€çŸ¥è¯†å›¾è°±ï¼Œä¿ƒè¿›è‡ªé€‚åº”ç©ºé—´æ¨ç†ï¼›ï¼ˆ3ï¼‰è®¡åˆ’è¯„ä»·è€…æœºåˆ¶ï¼Œè¿­ä»£ä¼˜åŒ–ä»»åŠ¡ç­–ç•¥ã€‚æˆ‘ä»¬åœ¨TextWorldç¯å¢ƒä¸­å¯¹STMAè¿›è¡Œäº†32é¡¹ä»»åŠ¡è¯„ä¼°ï¼Œæ¶‰åŠå¤šæ­¥éª¤è§„åˆ’å’Œåœ¨ä¸åŒå¤æ‚ç¨‹åº¦ä¸‹çš„æ¢ç´¢ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œä¸æœ€æ–°æ¨¡å‹ç›¸æ¯”ï¼ŒSTMAæˆåŠŸç‡æé«˜äº†31.25%ï¼Œå¹³å‡å¾—åˆ†æé«˜äº†24.7%ã€‚ç»“æœçªå‡ºäº†æ—¶ç©ºè®°å¿†åœ¨æå‡ä½“æ„Ÿæ™ºèƒ½ä½“çš„è®°å¿†èƒ½åŠ›æ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.10177v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†ä½“æ™ºèƒ½çš„å…³é”®ç›®æ ‡ï¼Œå³å®ç°åœ¨åŠ¨æ€ç¯å¢ƒä¸­æ‰§è¡Œé•¿æœŸä»»åŠ¡çš„åŒæ—¶ä¿æŒç¨³å¥çš„å†³ç­–å’Œé€‚åº”æ€§ã€‚ä¸ºå®ç°è¿™ä¸€ç›®æ ‡ï¼Œæå‡ºäº†ä¸€ç§æ–°å‹æ¡†æ¶â€”â€”æ—¶ç©ºè®°å¿†æ™ºèƒ½ä½“ï¼ˆSTMAï¼‰ï¼Œé€šè¿‡æ•´åˆæ—¶ç©ºè®°å¿†æ¥å¢å¼ºä»»åŠ¡è§„åˆ’å’Œæ‰§è¡Œã€‚STMAç”±ä¸‰ä¸ªå…³é”®ç»„ä»¶æ„æˆï¼šï¼ˆ1ï¼‰æ—¶ç©ºè®°å¿†æ¨¡å—ï¼Œå®æ—¶æ•è·å†å²å’Œç¯å¢ƒçš„å˜è¿ï¼›ï¼ˆ2ï¼‰åŠ¨æ€çŸ¥è¯†å›¾è°±ï¼Œä¿ƒè¿›è‡ªé€‚åº”ç©ºé—´æ¨ç†ï¼›ï¼ˆ3ï¼‰è®¡åˆ’-æ‰¹åˆ¤æœºåˆ¶ï¼Œè¿­ä»£ä¼˜åŒ–ä»»åŠ¡ç­–ç•¥ã€‚åœ¨TextWorldç¯å¢ƒä¸­å¯¹æ¶‰åŠä¸åŒå¤æ‚ç¨‹åº¦çš„å¤šæ­¥éª¤è§„åˆ’å’Œæ¢ç´¢çš„32é¡¹ä»»åŠ¡è¿›è¡Œè¯„ä¼°ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œä¸æœ€æ–°æ¨¡å‹ç›¸æ¯”ï¼ŒSTMAæˆåŠŸç‡æé«˜äº†31.25%ï¼Œå¹³å‡å¾—åˆ†å¢åŠ äº†24.7%ï¼Œçªæ˜¾äº†æ—¶ç©ºè®°å¿†åœ¨æå‡æ™ºèƒ½ä½“çš„è®°å¿†èƒ½åŠ›æ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ä½“æ™ºèƒ½çš„ç›®æ ‡æ˜¯è®©æ™ºèƒ½ä½“åœ¨åŠ¨æ€ç¯å¢ƒä¸­æ‰§è¡Œé•¿æœŸä»»åŠ¡æ—¶ä¿æŒç¨³å¥å†³ç­–å’Œé€‚åº”æ€§ã€‚</li>
<li>æå‡ºäº†æ–°å‹æ¡†æ¶STMAï¼Œé€šè¿‡æ•´åˆæ—¶ç©ºè®°å¿†å¢å¼ºä»»åŠ¡è§„åˆ’å’Œæ‰§è¡Œã€‚</li>
<li>STMAç”±ä¸‰ä¸ªå…³é”®ç»„ä»¶æ„æˆï¼šæ—¶ç©ºè®°å¿†æ¨¡å—ã€åŠ¨æ€çŸ¥è¯†å›¾è°±å’Œè®¡åˆ’-æ‰¹åˆ¤æœºåˆ¶ã€‚</li>
<li>æ—¶ç©ºè®°å¿†æ¨¡å—èƒ½å®æ—¶æ•è·å†å²å’Œç¯å¢ƒçš„å˜è¿ã€‚</li>
<li>åŠ¨æ€çŸ¥è¯†å›¾è°±ä¿ƒè¿›æ™ºèƒ½ä½“çš„è‡ªé€‚åº”ç©ºé—´æ¨ç†ã€‚</li>
<li>åœ¨TextWorldç¯å¢ƒä¸‹çš„å®éªŒè¡¨æ˜ï¼ŒSTMAåœ¨å¤šé¡¹ä»»åŠ¡ä¸Šçš„è¡¨ç°ä¼˜äºç°æœ‰æ¨¡å‹ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.10177">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-90f2fb632a1794ed52fd799aa4889879.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a5032240702c6d5629d1bb9eb6fd4edd.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-b601e9bee7225044ff0909ba0dd1831d.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="Speaking-the-Language-of-Teamwork-LLM-Guided-Credit-Assignment-in-Multi-Agent-Reinforcement-Learning"><a href="#Speaking-the-Language-of-Teamwork-LLM-Guided-Credit-Assignment-in-Multi-Agent-Reinforcement-Learning" class="headerlink" title="Speaking the Language of Teamwork: LLM-Guided Credit Assignment in   Multi-Agent Reinforcement Learning"></a>Speaking the Language of Teamwork: LLM-Guided Credit Assignment in   Multi-Agent Reinforcement Learning</h2><p><strong>Authors:Muhan Lin, Shuyang Shi, Yue Guo, Vaishnav Tadiparthi, Behdad Chalaki, Ehsan Moradi Pari, Simon Stepputtis, Woojun Kim, Joseph Campbell, Katia Sycara</strong></p>
<p>Credit assignment, the process of attributing credit or blame to individual agents for their contributions to a teamâ€™s success or failure, remains a fundamental challenge in multi-agent reinforcement learning (MARL), particularly in environments with sparse rewards. Commonly-used approaches such as value decomposition often lead to suboptimal policies in these settings, and designing dense reward functions that align with human intuition can be complex and labor-intensive. In this work, we propose a novel framework where a large language model (LLM) generates dense, agent-specific rewards based on a natural language description of the task and the overall team goal. By learning a potential-based reward function over multiple queries, our method reduces the impact of ranking errors while allowing the LLM to evaluate each agentâ€™s contribution to the overall task. Through extensive experiments, we demonstrate that our approach achieves faster convergence and higher policy returns compared to state-of-the-art MARL baselines. </p>
<blockquote>
<p>åœ¨å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ ï¼ˆMARLï¼‰ä¸­ï¼Œç‰¹åˆ«æ˜¯åœ¨å¥–åŠ±ç¨€ç–çš„ç¯å¢ƒä¸­ï¼Œå¯¹æ™ºèƒ½ä½“çš„è´¡çŒ®è¿›è¡Œä¿¡ç”¨åˆ†é…ï¼Œå³ä¸ºå…¶å¯¹å›¢é˜ŸæˆåŠŸæˆ–å¤±è´¥çš„è´¡çŒ®èµ‹äºˆä¿¡ç”¨æˆ–è´£ä»»ï¼Œä»ç„¶æ˜¯ä¸€ä¸ªåŸºæœ¬æŒ‘æˆ˜ã€‚å¸¸ç”¨çš„æ–¹æ³•å¦‚å€¼åˆ†è§£åœ¨è¿™äº›åœºæ™¯ä¸­å¸¸å¸¸ä¼šå¯¼è‡´æ¬¡ä¼˜ç­–ç•¥ï¼Œè€Œè®¾è®¡ç¬¦åˆäººç±»ç›´è§‰çš„å¯†é›†å¥–åŠ±å‡½æ•°å¯èƒ½å¤æ‚ä¸”è€—æ—¶ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°çš„æ¡†æ¶ï¼Œå…¶ä¸­å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åŸºäºä»»åŠ¡çš„è‡ªç„¶è¯­è¨€æè¿°å’Œæ•´ä½“å›¢é˜Ÿç›®æ ‡ç”Ÿæˆå¯†é›†ã€é’ˆå¯¹æ™ºèƒ½ä½“çš„å¥–åŠ±ã€‚é€šè¿‡åŸºäºå¤šä¸ªæŸ¥è¯¢å­¦ä¹ åŸºäºæ½œåŠ›çš„å¥–åŠ±å‡½æ•°ï¼Œæˆ‘ä»¬çš„æ–¹æ³•å‡å°‘äº†æ’åé”™è¯¯çš„å½±å“ï¼ŒåŒæ—¶å…è®¸LLMè¯„ä¼°æ¯ä¸ªæ™ºèƒ½ä½“å¯¹æ•´ä½“ä»»åŠ¡çš„è´¡çŒ®ã€‚é€šè¿‡å¹¿æ³›çš„å®éªŒï¼Œæˆ‘ä»¬è¯æ˜æˆ‘ä»¬çš„æ–¹æ³•ä¸æœ€æ–°çš„MARLåŸºå‡†ç›¸æ¯”ï¼Œå®ç°äº†æ›´å¿«çš„æ”¶æ•›é€Ÿåº¦å’Œæ›´é«˜çš„ç­–ç•¥å›æŠ¥ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.03723v2">PDF</a> 11 pages, 6 figures. Added the acknowledgement section</p>
<p><strong>Summary</strong>ï¼šåœ¨å›¢é˜ŸæˆåŠŸæˆ–å¤±è´¥æ—¶åˆ†é…åŠŸåŠ³æˆ–è´£ä»»æ˜¯å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ ä¸­çš„ä¸€ä¸ªåŸºæœ¬æŒ‘æˆ˜ï¼Œç‰¹åˆ«æ˜¯åœ¨å¥–åŠ±ç¨€ç–çš„ç¯å¢ƒä¸­ã€‚ä¼ ç»Ÿçš„ä»·å€¼åˆ†è§£æ–¹æ³•å¸¸å¸¸å¯¼è‡´æ¬¡ä¼˜ç­–ç•¥ï¼Œè®¾è®¡ç¬¦åˆäººç±»ç›´è§‰çš„å¯†é›†å¥–åŠ±å‡½æ•°å¯èƒ½å¤æ‚ä¸”è€—æ—¶ã€‚æœ¬ç ”ç©¶æå‡ºäº†ä¸€ç§æ–°çš„æ¡†æ¶ï¼Œåˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹æ ¹æ®ä»»åŠ¡çš„è‡ªç„¶è¯­è¨€æè¿°å’Œæ•´ä½“å›¢é˜Ÿç›®æ ‡ç”Ÿæˆå¯†é›†ã€ç‰¹å®šäºæ™ºèƒ½ä½“çš„å¥–åŠ±ã€‚é€šè¿‡åŸºäºå¤šä¸ªæŸ¥è¯¢å­¦ä¹ æ½œåœ¨å¥–åŠ±å‡½æ•°ï¼Œæˆ‘ä»¬çš„æ–¹æ³•å‡å°‘äº†æ’åé”™è¯¯çš„å½±å“ï¼Œå¹¶å…è®¸è¯­è¨€æ¨¡å‹è¯„ä¼°æ¯ä¸ªæ™ºèƒ½ä½“å¯¹æ•´ä½“ä»»åŠ¡çš„è´¡çŒ®ã€‚å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•ç›¸è¾ƒäºæœ€å…ˆè¿›çš„MARLåŸºçº¿æ–¹æ³•ï¼Œå®ç°äº†æ›´å¿«çš„æ”¶æ•›é€Ÿåº¦å’Œæ›´é«˜çš„ç­–ç•¥å›æŠ¥ã€‚</p>
<p><strong>Key Takeaways</strong>ï¼š</p>
<ol>
<li>ä¿¡ç”¨åˆ†é…åœ¨å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ ä¸­æ˜¯ä¸€ä¸ªæŒ‘æˆ˜ï¼Œç‰¹åˆ«æ˜¯åœ¨å¥–åŠ±ç¨€ç–çš„ç¯å¢ƒä¸­ã€‚</li>
<li>ä¼ ç»Ÿä»·å€¼åˆ†è§£æ–¹æ³•å¯èƒ½å¯¼è‡´æ¬¡ä¼˜ç­–ç•¥ã€‚</li>
<li>å¤§å‹è¯­è¨€æ¨¡å‹å¯ä»¥æ ¹æ®ä»»åŠ¡çš„è‡ªç„¶è¯­è¨€æè¿°å’Œå›¢é˜Ÿç›®æ ‡ç”Ÿæˆç‰¹å®šäºæ™ºèƒ½ä½“çš„å¯†é›†å¥–åŠ±ã€‚</li>
<li>é€šè¿‡å­¦ä¹ åŸºäºå¤šä¸ªæŸ¥è¯¢çš„æ½œåœ¨å¥–åŠ±å‡½æ•°ï¼Œå¯ä»¥å‡å°‘æ’åé”™è¯¯çš„å½±å“ã€‚</li>
<li>è¯­è¨€æ¨¡å‹èƒ½å¤Ÿè¯„ä¼°æ¯ä¸ªæ™ºèƒ½ä½“å¯¹æ•´ä½“ä»»åŠ¡çš„è´¡çŒ®ã€‚</li>
<li>è¯¥æ–¹æ³•å®ç°äº†æ›´å¿«çš„æ”¶æ•›é€Ÿåº¦ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.03723">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-818ce65d55d5af690c5c42ff5f325116.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-47da08c727129841e086d8015c88ab0e.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="A-Mixed-Integer-Conic-Program-for-the-Multi-Agent-Moving-Target-Traveling-Salesman-Problem"><a href="#A-Mixed-Integer-Conic-Program-for-the-Multi-Agent-Moving-Target-Traveling-Salesman-Problem" class="headerlink" title="A Mixed-Integer Conic Program for the Multi-Agent Moving-Target   Traveling Salesman Problem"></a>A Mixed-Integer Conic Program for the Multi-Agent Moving-Target   Traveling Salesman Problem</h2><p><strong>Authors:Allen George Philip, Zhongqiang Ren, Sivakumar Rathinam, Howie Choset</strong></p>
<p>The Moving-Target Traveling Salesman Problem (MT-TSP) seeks a shortest path for an agent that starts at a stationary depot, visits a set of moving targets exactly once, each within one of their respective time windows, and returns to the depot. In this paper, we introduce a new Mixed-Integer Conic Program (MICP) formulation for the Multi-Agent Moving-Target Traveling Salesman Problem (MA-MT-TSP), a generalization of the MT-TSP involving multiple agents. Our approach begins by restating the current state-of-the-art MICP formulation for MA-MT-TSP as a Nonconvex Mixed-Integer Nonlinear Program (MINLP), followed by a novel reformulation into a new MICP. We present computational results demonstrating that our formulation outperforms the state-of-the-art, achieving up to two orders of magnitude reduction in runtime, and over 90% improvement in optimality gap. </p>
<blockquote>
<p>ç§»åŠ¨ç›®æ ‡æ—…è¡Œå•†é—®é¢˜ï¼ˆMT-TSPï¼‰æ—¨åœ¨ä¸ºä»é™æ­¢çš„ä»“åº“å‡ºå‘çš„ä»£ç†å¯»æ‰¾ä¸€æ¡æœ€çŸ­è·¯å¾„ï¼Œè¯¥è·¯å¾„æ°å¥½è®¿é—®ä¸€ç»„ç§»åŠ¨ç›®æ ‡ä¸€æ¬¡ï¼Œæ¯ä¸ªç›®æ ‡éƒ½åœ¨å…¶å„è‡ªçš„æ—¶é—´çª—å£å†…ï¼Œå¹¶æœ€ç»ˆè¿”å›ä»“åº“ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬ä¸ºå¤šä»£ç†ç§»åŠ¨ç›®æ ‡æ—…è¡Œå•†é—®é¢˜ï¼ˆMA-MT-TSPï¼‰å¼•å…¥äº†ä¸€ç§æ–°çš„æ··åˆæ•´æ•°é”¥è§„åˆ’ï¼ˆMICPï¼‰å…¬å¼ï¼Œè¿™æ˜¯å¯¹æ¶‰åŠå¤šä¸ªä»£ç†çš„MT-TSPçš„ä¸€ç§æ¦‚æ‹¬ã€‚æˆ‘ä»¬çš„æ–¹æ³•é¦–å…ˆæ˜¯å°†ç°æœ‰çš„æœ€å…ˆè¿›çš„MICPå…¬å¼é‡æ–°è¡¨è¿°ä¸ºé’ˆå¯¹MA-MT-TSPçš„éå‡¸æ··åˆæ•´æ•°éçº¿æ€§è§„åˆ’ï¼ˆMINLPï¼‰ï¼Œç„¶åè¿›è¡Œæ–°çš„å…¬å¼æ”¹é©ä»¥å½¢æˆæ–°çš„MICPã€‚æˆ‘ä»¬æä¾›äº†è®¡ç®—ç»“æœï¼Œè¯æ˜äº†æˆ‘ä»¬çš„å…¬å¼ä¼˜äºç°æœ‰æŠ€æœ¯ï¼Œå®ç°äº†è¿è¡Œæ—¶é«˜è¾¾ä¸¤ä¸ªæ•°é‡çº§çš„å‡å°‘ï¼Œå¹¶ä¸”åœ¨æœ€ä¼˜æ€§å·®è·ä¸Šæé«˜äº†è¶…è¿‡90%ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.06130v2">PDF</a> 7 pages, 3 figures</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ç ”ç©¶äº†å¤šä»£ç†ç§»åŠ¨ç›®æ ‡æ—…è¡Œå•†é—®é¢˜ï¼ˆMA-MT-TSPï¼‰ï¼Œå…¶ä¸­å¤šä¸ªä»£ç†éœ€è¦å¯»æ‰¾æœ€çŸ­è·¯å¾„ä»¥è®¿é—®ä¸€ç»„ç§»åŠ¨ç›®æ ‡ã€‚é’ˆå¯¹æ­¤é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„æ··åˆæ•´æ•°é”¥è§„åˆ’ï¼ˆMICPï¼‰è§£å†³æ–¹æ¡ˆã€‚é€šè¿‡å°†ç°æœ‰æŠ€æœ¯è½¬åŒ–ä¸ºéå‡¸æ··åˆæ•´æ•°éçº¿æ€§è§„åˆ’ï¼ˆMINLPï¼‰ï¼Œç„¶åå¯¹å…¶è¿›è¡Œé‡æ–°åˆ¶å®šï¼Œå½¢æˆæ–°çš„MICPæ–¹æ¡ˆã€‚è®¡ç®—ç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ¡ˆæ¯”ç°æœ‰æŠ€æœ¯æ›´åŠ ä¼˜ç§€ï¼Œè¿è¡Œæ—¶ç¼©çŸ­äº†ä¸¤ä¸ªæ•°é‡çº§ï¼Œæœ€ä¼˜è§£æ”¹å–„å¹…åº¦è¶…è¿‡90%ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>ç ”ç©¶è§£å†³äº†å¤šä»£ç†ç§»åŠ¨ç›®æ ‡æ—…è¡Œå•†é—®é¢˜ï¼ˆMA-MT-TSPï¼‰ã€‚</li>
<li>æå‡ºäº†ä¸€ç§æ–°çš„æ··åˆæ•´æ•°é”¥è§„åˆ’ï¼ˆMICPï¼‰è§£å†³æ–¹æ¡ˆã€‚</li>
<li>å°†ç°æœ‰æŠ€æœ¯è½¬åŒ–ä¸ºéå‡¸æ··åˆæ•´æ•°éçº¿æ€§è§„åˆ’ï¼ˆMINLPï¼‰ã€‚</li>
<li>æå‡ºäº†ä¸€ç§æ–°çš„MICPæ–¹æ¡ˆå¯¹åŸé—®é¢˜è¿›è¡Œé‡æ–°åˆ¶å®šã€‚</li>
<li>è¯¥æ–¹æ¡ˆè®¡ç®—æ€§èƒ½æ˜¾è‘—ï¼Œè¿è¡Œæ—¶ç¼©çŸ­äº†ä¸¤ä¸ªæ•°é‡çº§ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.06130">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-708dda33f6268688a48a66c6e90f3843.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-1286356cda7e8c71b2c50940ea68bc34.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-8cd9267ee04c81172eb8f8b93dd1f8d7.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="TradingAgents-Multi-Agents-LLM-Financial-Trading-Framework"><a href="#TradingAgents-Multi-Agents-LLM-Financial-Trading-Framework" class="headerlink" title="TradingAgents: Multi-Agents LLM Financial Trading Framework"></a>TradingAgents: Multi-Agents LLM Financial Trading Framework</h2><p><strong>Authors:Yijia Xiao, Edward Sun, Di Luo, Wei Wang</strong></p>
<p>Significant progress has been made in automated problem-solving using societies of agents powered by large language models (LLMs). In finance, efforts have largely focused on single-agent systems handling specific tasks or multi-agent frameworks independently gathering data. However, multi-agent systemsâ€™ potential to replicate real-world trading firmsâ€™ collaborative dynamics remains underexplored. TradingAgents proposes a novel stock trading framework inspired by trading firms, featuring LLM-powered agents in specialized roles such as fundamental analysts, sentiment analysts, technical analysts, and traders with varied risk profiles. The framework includes Bull and Bear researcher agents assessing market conditions, a risk management team monitoring exposure, and traders synthesizing insights from debates and historical data to make informed decisions. By simulating a dynamic, collaborative trading environment, this framework aims to improve trading performance. Detailed architecture and extensive experiments reveal its superiority over baseline models, with notable improvements in cumulative returns, Sharpe ratio, and maximum drawdown, highlighting the potential of multi-agent LLM frameworks in financial trading. TradingAgents is available at <a target="_blank" rel="noopener" href="https://github.com/PioneerFintech">https://github.com/PioneerFintech</a>. </p>
<blockquote>
<p>åœ¨åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰é©±åŠ¨çš„æ™ºèƒ½ä½“ç¤¾ä¼šè¿›è¡Œè‡ªåŠ¨åŒ–é—®é¢˜è§£å†³æ–¹é¢ï¼Œå·²ç»å–å¾—äº†é‡å¤§è¿›å±•ã€‚åœ¨é‡‘èé¢†åŸŸï¼Œç›¸å…³åŠªåŠ›ä¸»è¦é›†ä¸­åœ¨å¤„ç†ç‰¹å®šä»»åŠ¡çš„å•ä¸€æ™ºèƒ½ä½“ç³»ç»Ÿæˆ–ç‹¬ç«‹æ”¶é›†æ•°æ®çš„å¤šæ™ºèƒ½ä½“æ¡†æ¶ä¸Šã€‚ç„¶è€Œï¼Œå¤šæ™ºèƒ½ä½“ç³»ç»Ÿåœ¨å¤åˆ¶ç°å®ä¸–ç•Œäº¤æ˜“å…¬å¸çš„åä½œåŠ¨æ€æ–¹é¢çš„æ½œåŠ›å°šæœªå¾—åˆ°å……åˆ†æ¢ç´¢ã€‚ã€ŠTradingAgentsã€‹æå‡ºäº†ä¸€ä¸ªå—äº¤æ˜“å…¬å¸å¯å‘çš„æ–°å‹è‚¡ç¥¨äº¤æ˜“æ¡†æ¶ï¼Œå…¶ä¸­åŒ…æ‹¬ç”±å¤§å‹è¯­è¨€æ¨¡å‹é©±åŠ¨çš„ä¸“é—¨ä»äº‹ç‰¹å®šè§’è‰²çš„æ™ºèƒ½ä½“ï¼Œå¦‚åŸºæœ¬é¢åˆ†æå¸ˆã€æƒ…ç»ªåˆ†æå¸ˆã€æŠ€æœ¯åˆ†æå¸ˆå’Œä¸åŒé£é™©çº§åˆ«çš„äº¤æ˜“å‘˜ã€‚è¯¥æ¡†æ¶åŒ…æ‹¬ç‰›å¸‚å’Œç†Šå¸‚ç ”ç©¶è€…æ™ºèƒ½ä½“å¯¹å¸‚åœºçŠ¶å†µè¿›è¡Œè¯„ä¼°ï¼Œä¸€ä¸ªé£é™©ç®¡ç†å›¢é˜Ÿç›‘æ§æ›å…‰åº¦ï¼Œä»¥åŠäº¤æ˜“å‘˜æ ¹æ®è¾©è®ºå’Œå†å²æ•°æ®åˆæˆè§è§£ä»¥åšå‡ºæ˜æ™ºå†³ç­–ã€‚é€šè¿‡æ¨¡æ‹ŸåŠ¨æ€åä½œçš„äº¤æ˜“ç¯å¢ƒï¼Œè¯¥æ¡†æ¶æ—¨åœ¨æé«˜äº¤æ˜“æ€§èƒ½ã€‚è¯¦ç»†çš„æ¶æ„å’Œå¹¿æ³›çš„å®éªŒè¡¨æ˜å…¶åœ¨ç´¯ç§¯å›æŠ¥ã€å¤æ™®æ¯”ç‡å’Œæœ€å¤§å›æ’¤æ–¹é¢ä¼˜äºåŸºçº¿æ¨¡å‹ï¼Œå‡¸æ˜¾äº†å¤šæ™ºèƒ½ä½“LLMæ¡†æ¶åœ¨é‡‘èäº¤æ˜“ä¸­çš„æ½œåŠ›ã€‚ã€ŠTradingAgentsã€‹å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/PioneerFintech%E4%B8%8A%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/PioneerFintechä¸Šæ‰¾åˆ°ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.20138v5">PDF</a> Multi-Agent AI in the Real World @ AAAI 2025</p>
<p><strong>Summary</strong>ï¼šåŸºäºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„ä»£ç†ç¤¾ä¼šåœ¨è‡ªåŠ¨åŒ–é—®é¢˜è§£å†³æ–¹é¢å–å¾—äº†æ˜¾è‘—è¿›å±•ã€‚åœ¨é‡‘èé¢†åŸŸï¼Œå°½ç®¡å•ä»£ç†ç³»ç»Ÿå¤„ç†ç‰¹å®šä»»åŠ¡æˆ–å¤šä»£ç†æ¡†æ¶ç‹¬ç«‹æ”¶é›†æ•°æ®çš„å·¥ä½œå·²å¹¿æ³›å±•å¼€ï¼Œä½†å¤šä»£ç†ç³»ç»Ÿåœ¨æ¨¡æ‹ŸçœŸå®äº¤æ˜“å…¬å¸çš„åä½œåŠ¨æ€æ–¹é¢çš„æ½œåŠ›å°šæœªå¾—åˆ°å……åˆ†æ¢ç´¢ã€‚TradingAgentsæå‡ºäº†ä¸€ä¸ªå—äº¤æ˜“å…¬å¸å¯å‘çš„è‚¡ç¥¨äº¤æ˜“æ–°æ¡†æ¶ï¼Œè¯¥æ¡†æ¶å…·æœ‰å¤šç§è§’è‰²ï¼ŒåŒ…æ‹¬åŸºäºLLMçš„ä¸“èŒåˆ†æå¸ˆã€æƒ…ç»ªåˆ†æå¸ˆã€æŠ€æœ¯åˆ†æå¸ˆå’Œå…·æœ‰ä¸åŒé£é™©ç‰¹å¾çš„äº¤æ˜“å‘˜ã€‚é€šè¿‡æ¨¡æ‹ŸåŠ¨æ€åä½œçš„äº¤æ˜“ç¯å¢ƒï¼Œè¯¥æ¡†æ¶æ—¨åœ¨æé«˜äº¤æ˜“æ€§èƒ½ã€‚è¯¦ç»†çš„æ¶æ„å’Œå¹¿æ³›çš„å®éªŒè¡¨æ˜ï¼Œå…¶åœ¨ç´¯ç§¯å›æŠ¥ã€å¤æ™®æ¯”ç‡å’Œæœ€å¤§å›æ’¤ç­‰æ–¹é¢ä¼˜äºåŸºå‡†æ¨¡å‹ï¼Œçªæ˜¾äº†å¤šä»£ç†LLMæ¡†æ¶åœ¨é‡‘èäº¤æ˜“ä¸­çš„æ½œåŠ›ã€‚</p>
<p><strong>Key Takeaways</strong>ï¼š</p>
<ol>
<li>ä»£ç†ç¤¾ä¼šåœ¨è‡ªåŠ¨åŒ–é—®é¢˜è§£å†³ä¸Šå–å¾—äº†è¿›å±•ï¼Œç‰¹åˆ«æ˜¯åœ¨é‡‘èé¢†åŸŸçš„åº”ç”¨ã€‚</li>
<li>ç›®å‰é‡‘èé¢†åŸŸçš„ç ”ç©¶ä¸»è¦é›†ä¸­åœ¨å•ä»£ç†ç³»ç»Ÿå¤„ç†ç‰¹å®šä»»åŠ¡æˆ–ç‹¬ç«‹çš„å¤šä»£ç†æ¡†æ¶æ”¶é›†æ•°æ®ä¸Šã€‚</li>
<li>å¤šä»£ç†ç³»ç»Ÿåœ¨æ¨¡æ‹ŸçœŸå®äº¤æ˜“å…¬å¸çš„åä½œåŠ¨æ€æ–¹é¢çš„æ½œåŠ›å°šæœªå¾—åˆ°å……åˆ†æ¢ç´¢ã€‚</li>
<li>TradingAgentsæ¡†æ¶é‡‡ç”¨åŸºäºLLMçš„ä»£ç†ï¼ŒåŒ…æ‹¬åˆ†æå¸ˆå’Œäº¤æ˜“å‘˜ç­‰ä¸åŒè§’è‰²ï¼Œæ—¨åœ¨æ¨¡æ‹ŸçœŸå®äº¤æ˜“ç¯å¢ƒå¹¶æé«˜äº¤æ˜“æ€§èƒ½ã€‚</li>
<li>è¯¥æ¡†æ¶çš„è¯¦ç»†æ¶æ„å’Œå®éªŒç»“æœè¡¨æ˜å…¶åœ¨å¤šä¸ªå…³é”®æŒ‡æ ‡ä¸Šä¼˜äºåŸºå‡†æ¨¡å‹ã€‚</li>
<li>TradingAgentsæ¡†æ¶å¯ç”¨äºæ¨¡æ‹Ÿè‚¡ç¥¨äº¤æ˜“ï¼Œå¹¶åœ¨ç´¯ç§¯å›æŠ¥ã€å¤æ™®æ¯”ç‡å’Œæœ€å¤§å›æ’¤ç­‰æ–¹é¢æ˜¾ç¤ºå‡ºä¼˜åŠ¿ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.20138">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-43d3c5b706ca46af0a668e41df169b3d.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-9899c981abc8be1ebf44346399f3f2dd.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-34cc5bf9c6b593ef2c17231b3b472346.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-92c873ecba85e2d8289a18d1e8f25d0d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-eba4b8a51ddba76a7d9ed986fefccd57.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="CaPo-Cooperative-Plan-Optimization-for-Efficient-Embodied-Multi-Agent-Cooperation"><a href="#CaPo-Cooperative-Plan-Optimization-for-Efficient-Embodied-Multi-Agent-Cooperation" class="headerlink" title="CaPo: Cooperative Plan Optimization for Efficient Embodied Multi-Agent   Cooperation"></a>CaPo: Cooperative Plan Optimization for Efficient Embodied Multi-Agent   Cooperation</h2><p><strong>Authors:Jie Liu, Pan Zhou, Yingjun Du, Ah-Hwee Tan, Cees G. M. Snoek, Jan-Jakob Sonke, Efstratios Gavves</strong></p>
<p>In this work, we address the cooperation problem among large language model (LLM) based embodied agents, where agents must cooperate to achieve a common goal. Previous methods often execute actions extemporaneously and incoherently, without long-term strategic and cooperative planning, leading to redundant steps, failures, and even serious repercussions in complex tasks like search-and-rescue missions where discussion and cooperative plan are crucial. To solve this issue, we propose Cooperative Plan Optimization (CaPo) to enhance the cooperation efficiency of LLM-based embodied agents. Inspired by human cooperation schemes, CaPo improves cooperation efficiency with two phases: 1) meta-plan generation, and 2) progress-adaptive meta-plan and execution. In the first phase, all agents analyze the task, discuss, and cooperatively create a meta-plan that decomposes the task into subtasks with detailed steps, ensuring a long-term strategic and coherent plan for efficient coordination. In the second phase, agents execute tasks according to the meta-plan and dynamically adjust it based on their latest progress (e.g., discovering a target object) through multi-turn discussions. This progress-based adaptation eliminates redundant actions, improving the overall cooperation efficiency of agents. Experimental results on the ThreeDworld Multi-Agent Transport and Communicative Watch-And-Help tasks demonstrate that CaPo achieves much higher task completion rate and efficiency compared with state-of-the-arts.The code is released at <a target="_blank" rel="noopener" href="https://github.com/jliu4ai/CaPo">https://github.com/jliu4ai/CaPo</a>. </p>
<blockquote>
<p>åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬è§£å†³äº†åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„å®ä½“ä»£ç†ä¹‹é—´çš„åˆä½œé—®é¢˜ï¼Œåœ¨è¿™äº›ä»£ç†ä¸­ï¼Œå¿…é¡»åˆä½œä»¥å®ç°å…±åŒç›®æ ‡ã€‚ä¹‹å‰çš„æ–¹æ³•é€šå¸¸å³å…´ä¸”ä¸ä¸€è‡´åœ°æ‰§è¡Œæ“ä½œï¼Œæ²¡æœ‰é•¿æœŸæˆ˜ç•¥å’Œåˆä½œè§„åˆ’ï¼Œè¿™ä¼šå¯¼è‡´å†—ä½™æ­¥éª¤ã€å¤±è´¥ï¼Œç”šè‡³åœ¨æœç´¢å’Œæ•‘æ´ç­‰å¤æ‚ä»»åŠ¡ä¸­äº§ç”Ÿä¸¥é‡åæœï¼Œå…¶ä¸­è®¨è®ºå’Œåˆä½œè®¡åˆ’è‡³å…³é‡è¦ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†åˆä½œè®¡åˆ’ä¼˜åŒ–ï¼ˆCaPoï¼‰æ¥æé«˜åŸºäºLLMçš„å®ä½“ä»£ç†çš„åˆä½œæ•ˆç‡ã€‚å—äººç±»åˆä½œæ–¹æ¡ˆçš„å¯å‘ï¼ŒCaPoé€šè¿‡ä¸¤ä¸ªé˜¶æ®µæé«˜åˆä½œæ•ˆç‡ï¼š1ï¼‰å…ƒè®¡åˆ’ç”Ÿæˆï¼›å’Œè¿›å±•è‡ªé€‚åº”çš„å…ƒè®¡åˆ’ä¸æ‰§è¡Œé˜¶æ®µã€‚åœ¨ç¬¬ä¸€é˜¶æ®µï¼Œæ‰€æœ‰ä»£ç†åˆ†æä»»åŠ¡ã€è®¨è®ºå¹¶åˆä½œç”Ÿæˆä¸€ä¸ªå…ƒè®¡åˆ’ï¼Œè¯¥è®¡åˆ’å°†ä»»åŠ¡åˆ†è§£ä¸ºå…·æœ‰è¯¦ç»†æ­¥éª¤çš„å­ä»»åŠ¡ï¼Œç¡®ä¿é•¿æœŸæˆ˜ç•¥å’Œè¿è´¯æ€§è®¡åˆ’ä»¥å®ç°æœ‰æ•ˆåè°ƒã€‚åœ¨ç¬¬äºŒé˜¶æ®µä¸­ï¼Œä»£ç†æ ¹æ®å…ƒè®¡åˆ’æ‰§è¡Œä»»åŠ¡å¹¶é€šè¿‡å¤šæ¬¡è®¨è®ºæ ¹æ®å…¶æœ€æ–°è¿›å±•ï¼ˆä¾‹å¦‚å‘ç°ç›®æ ‡å¯¹è±¡ï¼‰åŠ¨æ€è°ƒæ•´è®¡åˆ’ã€‚è¿™ç§åŸºäºè¿›åº¦çš„é€‚åº”æ€§æ¶ˆé™¤äº†å†—ä½™æ“ä½œï¼Œæé«˜äº†ä»£ç†çš„æ•´ä½“åˆä½œæ•ˆç‡ã€‚åœ¨ThreeDworldå¤šä»»åŠ¡ååŒé€šè®¯ã€è§‚çœ‹å’Œè¾…åŠ©ä»»åŠ¡ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼Œä¸å½“å‰æœ€å…ˆè¿›æŠ€æœ¯ç›¸æ¯”ï¼ŒCaPoå¤§å¤§æé«˜äº†ä»»åŠ¡å®Œæˆç‡å’Œæ•ˆç‡ã€‚<a target="_blank" rel="noopener" href="https://github.com/jliu4ai/CaPo%E3%80%82">ä»£ç å‘å¸ƒåœ¨https://github.com/jliu4ai/CaPoã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2411.04679v2">PDF</a> Accepted in ICLR2025</p>
<p><strong>Summary</strong></p>
<p>è¯¥æ–‡ç« ç ”ç©¶äº†åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„å®ä½“ä»£ç†äººåœ¨åˆä½œé—®é¢˜ä¸Šé‡åˆ°çš„æŒ‘æˆ˜ã€‚ä¸ºäº†è§£å†³æ‰§è¡ŒåŠ¨ä½œæ—¶çš„ä¸´æ—¶æ€§å’Œéè¿è´¯æ€§ï¼Œæ–‡ç« æå‡ºäº†åˆä½œè®¡åˆ’ä¼˜åŒ–ï¼ˆCaPoï¼‰æ–¹æ³•ï¼Œé€šè¿‡ä¸¤ä¸ªé˜¶æ®µæé«˜åˆä½œæ•ˆç‡ï¼šé¦–å…ˆæ˜¯ç”Ÿæˆå…ƒè®¡åˆ’ï¼Œç„¶åæ˜¯è¿›åº¦è‡ªé€‚åº”çš„å…ƒè®¡åˆ’å’Œæ‰§è¡Œã€‚CaPoé€šè¿‡æ¨¡æ‹Ÿäººç±»åˆä½œæ–¹æ¡ˆï¼Œæé«˜äº†å®ä½“ä»£ç†äººçš„åˆä½œæ•ˆç‡ã€‚åœ¨ä¸‰ç»´ä¸–ç•Œå¤šæ™ºèƒ½ä½“è¿è¾“å’Œæ²Ÿé€šè§‚å¯Ÿæ•‘åŠ©ä»»åŠ¡ä¸­ï¼ŒCaPoç›¸è¾ƒäºç°æœ‰æŠ€æœ¯å–å¾—äº†æ›´é«˜çš„ä»»åŠ¡å®Œæˆç‡å’Œæ•ˆç‡ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹çš„å®ä½“ä»£ç†äººåœ¨åˆä½œé—®é¢˜ä¸Šå­˜åœ¨æŒ‘æˆ˜ã€‚</li>
<li>ä¼ ç»Ÿæ–¹æ³•åœ¨æ‰§è¡ŒåŠ¨ä½œæ—¶å­˜åœ¨ä¸´æ—¶æ€§å’Œéè¿è´¯æ€§é—®é¢˜ã€‚</li>
<li>åˆä½œè®¡åˆ’ä¼˜åŒ–ï¼ˆCaPoï¼‰æ–¹æ³•æ—¨åœ¨æé«˜å®ä½“ä»£ç†äººçš„åˆä½œæ•ˆç‡ã€‚</li>
<li>CaPoåˆ†ä¸ºä¸¤ä¸ªé˜¶æ®µï¼šç”Ÿæˆå…ƒè®¡åˆ’å’Œè¿›åº¦è‡ªé€‚åº”çš„å…ƒè®¡åˆ’å’Œæ‰§è¡Œã€‚</li>
<li>å…ƒè®¡åˆ’ç¡®ä¿äº†é•¿æœŸæˆ˜ç•¥å’Œè¿è´¯æ€§ï¼Œæœ‰åŠ©äºé«˜æ•ˆåè°ƒã€‚</li>
<li>é€šè¿‡æ¨¡æ‹Ÿäººç±»åˆä½œæ–¹æ¡ˆï¼ŒCaPoæé«˜äº†å®ä½“ä»£ç†äººçš„åˆä½œæ•ˆç‡ã€‚</li>
<li>åœ¨ä¸‰ç»´ä¸–ç•Œå¤šæ™ºèƒ½ä½“è¿è¾“å’Œæ²Ÿé€šè§‚å¯Ÿæ•‘åŠ©ä»»åŠ¡ä¸­ï¼ŒCaPoè¡¨ç°å‡ºæ›´é«˜çš„ä»»åŠ¡å®Œæˆç‡å’Œæ•ˆç‡ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2411.04679">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-1b0db52762326d17e6f602e0153b3fc1.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-0fa45dd4cfef736e4bd66d3a4235db95.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-62367ff4010b8707856cfae462b469cc.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-291a13c9e4f5faf6f4c8615a74ea0bca.jpg" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="CUIfy-the-XR-An-Open-Source-Package-to-Embed-LLM-powered-Conversational-Agents-in-XR"><a href="#CUIfy-the-XR-An-Open-Source-Package-to-Embed-LLM-powered-Conversational-Agents-in-XR" class="headerlink" title="CUIfy the XR: An Open-Source Package to Embed LLM-powered Conversational   Agents in XR"></a>CUIfy the XR: An Open-Source Package to Embed LLM-powered Conversational   Agents in XR</h2><p><strong>Authors:Kadir Burak Buldu, SÃ¼leyman Ã–zdel, Ka Hei Carrie Lau, Mengdi Wang, Daniel Saad, Sofie SchÃ¶nborn, Auxane Boch, Enkelejda Kasneci, Efe Bozkir</strong></p>
<p>Recent developments in computer graphics, machine learning, and sensor technologies enable numerous opportunities for extended reality (XR) setups for everyday life, from skills training to entertainment. With large corporations offering affordable consumer-grade head-mounted displays (HMDs), XR will likely become pervasive, and HMDs will develop as personal devices like smartphones and tablets. However, having intelligent spaces and naturalistic interactions in XR is as important as technological advances so that users grow their engagement in virtual and augmented spaces. To this end, large language model (LLM)â€“powered non-player characters (NPCs) with speech-to-text (STT) and text-to-speech (TTS) models bring significant advantages over conventional or pre-scripted NPCs for facilitating more natural conversational user interfaces (CUIs) in XR. This paper provides the community with an open-source, customizable, extendable, and privacy-aware Unity package, CUIfy, that facilitates speech-based NPC-user interaction with widely used LLMs, STT, and TTS models. Our package also supports multiple LLM-powered NPCs per environment and minimizes latency between different computational models through streaming to achieve usable interactions between users and NPCs. We publish our source code in the following repository: <a target="_blank" rel="noopener" href="https://gitlab.lrz.de/hctl/cuify">https://gitlab.lrz.de/hctl/cuify</a> </p>
<blockquote>
<p>è¿‘æœŸè®¡ç®—æœºå›¾å½¢å­¦ã€æœºå™¨å­¦ä¹ å’Œä¼ æ„Ÿå™¨æŠ€æœ¯çš„è¿›å±•ä¸ºæ‰©å±•ç°å®ï¼ˆXRï¼‰åœ¨æ—¥å¸¸ç”Ÿæ´»ä¸­çš„å¹¿æ³›åº”ç”¨æä¾›äº†æ— æ•°æœºä¼šï¼Œä»æŠ€èƒ½åŸ¹è®­åˆ°å¨±ä¹ç­‰å„ä¸ªé¢†åŸŸã€‚éšç€å¤§å‹å…¬å¸æä¾›è´Ÿæ‹…å¾—èµ·çš„æ¶ˆè´¹çº§å¤´æˆ´æ˜¾ç¤ºå™¨ï¼ˆHMDsï¼‰ï¼ŒXRå¯èƒ½ä¼šå˜å¾—æ™®åŠï¼Œè€ŒHMDså°†åƒæ™ºèƒ½æ‰‹æœºå’Œå¹³æ¿ç”µè„‘ä¸€æ ·å‘å±•æˆä¸ºä¸ªäººè®¾å¤‡ã€‚ç„¶è€Œï¼Œæ‹¥æœ‰æ™ºèƒ½ç©ºé—´å’Œè‡ªç„¶äººæœºäº¤äº’åŒæ ·é‡è¦ï¼Œè¿™æ ·ç”¨æˆ·æ‰èƒ½å¢åŠ å¯¹è™šæ‹Ÿå’Œå¢å¼ºç©ºé—´çš„å‚ä¸åº¦ã€‚ä¸ºæ­¤ï¼Œåˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰é©±åŠ¨çš„éç©å®¶è§’è‰²ï¼ˆNPCsï¼‰é€šè¿‡è¯­éŸ³è½¬æ–‡æœ¬ï¼ˆSTTï¼‰å’Œæ–‡æœ¬è½¬è¯­éŸ³ï¼ˆTTSï¼‰æ¨¡å‹ï¼Œä¸ºXRä¸­æ›´è‡ªç„¶çš„å¯¹è¯å¼ç”¨æˆ·ç•Œé¢ï¼ˆCUIsï¼‰æä¾›äº†ä¼ ç»Ÿæˆ–é¢„è®¾NPCæ— æ³•æ¯”æ‹Ÿçš„ä¼˜åŠ¿ã€‚æœ¬æ–‡ä¸ºç¤¾åŒºæä¾›äº†ä¸€ä¸ªå¼€æºã€å¯å®šåˆ¶ã€å¯æ‰©å±•å’Œæ³¨é‡éšç§çš„Unityè½¯ä»¶åŒ…CUIfyï¼Œå®ƒä¿ƒè¿›äº†åŸºäºè¯­éŸ³çš„NPCä¸ç”¨æˆ·ä¹‹é—´çš„äº¤äº’ï¼Œå¹¿æ³›ä½¿ç”¨äº†LLMã€STTå’ŒTTSæ¨¡å‹ã€‚æˆ‘ä»¬çš„è½¯ä»¶åŒ…è¿˜æ”¯æŒæ¯ä¸ªç¯å¢ƒæœ‰å¤šä¸ªLLMé©±åŠ¨çš„NPCï¼Œå¹¶é€šè¿‡æµæŠ€æœ¯æœ€å°åŒ–ä¸åŒè®¡ç®—æ¨¡å‹ä¹‹é—´çš„å»¶è¿Ÿï¼Œä»¥å®ç°ç”¨æˆ·å’ŒNPCä¹‹é—´å¯ç”¨çš„äº¤äº’ã€‚æˆ‘ä»¬å·²å°†æºä»£ç å‘å¸ƒåœ¨ä»¥ä¸‹å­˜å‚¨åº“ä¸­ï¼š[<a target="_blank" rel="noopener" href="https://gitlab.lrz.de/hctl/cuify]">https://gitlab.lrz.de/hctl/cuify]</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2411.04671v3">PDF</a> 7th IEEE International Conference on Artificial Intelligence &amp;   eXtended and Virtual Reality (IEEE AIxVR 2025)</p>
<p><strong>Summary</strong><br>     è¿‘æœŸè®¡ç®—æœºå›¾å½¢å­¦ã€æœºå™¨å­¦ä¹ å’Œä¼ æ„Ÿå™¨æŠ€æœ¯çš„å‘å±•ä¸ºæ‰©å±•ç°å®ï¼ˆXRï¼‰åœ¨æ—¥å¸¸ç”Ÿæ´»ä¸­çš„è¿ç”¨æä¾›äº†æ— é™å¯èƒ½ï¼Œå¦‚æŠ€èƒ½åŸ¹è®­åˆ°å¨±ä¹ç­‰ã€‚éšç€å¤§å‹ä¼ä¸šæä¾›ç»æµå®æƒ çš„æ¶ˆè´¹çº§å¤´æˆ´æ˜¾ç¤ºå™¨ï¼ˆHMDsï¼‰ï¼ŒXRæœ‰æœ›æˆä¸ºæ™®åŠæ€§æŠ€æœ¯ï¼ŒHMDså°†å¦‚åŒæ™ºèƒ½æ‰‹æœºå’Œå¹³æ¿ä¸€æ ·æˆä¸ºä¸ªäººè®¾å¤‡ã€‚ä¸ºäº†åœ¨XRä¸­å®ç°æ™ºèƒ½ç©ºé—´å’Œè‡ªç„¶äº¤äº’ï¼Œé‡‡ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰é©±åŠ¨çš„éç©å®¶è§’è‰²ï¼ˆNPCsï¼‰ç»“åˆè¯­éŸ³è¯†åˆ«å’Œæ–‡æœ¬åˆæˆæŠ€æœ¯ï¼Œèƒ½ä¸ºç”¨æˆ·æä¾›æ›´è‡ªç„¶çš„äº¤äº’ç•Œé¢ã€‚æœ¬æ–‡ä¸ºç¤¾åŒºæä¾›äº†ä¸€ä¸ªå¼€æºã€å¯å®šåˆ¶ã€å¯æ‰©å±•ä¸”æ³¨é‡éšç§çš„Unityè½¯ä»¶åŒ…CUIfyï¼Œå®ƒæ”¯æŒåŸºäºè¯­éŸ³çš„NPC-ç”¨æˆ·äº¤äº’ï¼Œå¯ä¸å¹¿æ³›ä½¿ç”¨çš„LLMã€STTå’ŒTTSæ¨¡å‹é…åˆä½¿ç”¨ã€‚æˆ‘ä»¬çš„è½¯ä»¶åŒ…è¿˜æ”¯æŒå¤šä¸ªç¯å¢ƒå†…çš„LLMé©±åŠ¨NPCsï¼Œå¹¶é€šè¿‡æµæŠ€æœ¯æœ€å°åŒ–ä¸åŒè®¡ç®—æ¨¡å‹ä¹‹é—´çš„å»¶è¿Ÿï¼Œä»¥å®ç°ç”¨æˆ·å’ŒNPCä¹‹é—´çš„å¯ç”¨äº¤äº’ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>è®¡ç®—æœºå›¾å½¢å­¦ã€æœºå™¨å­¦ä¹ å’Œä¼ æ„Ÿå™¨æŠ€æœ¯çš„æœ€æ–°å‘å±•ä¿ƒè¿›äº†æ‰©å±•ç°å®ï¼ˆXRï¼‰åœ¨æ—¥å¸¸ç”Ÿæ´»ä¸­çš„å¹¿æ³›åº”ç”¨ã€‚</li>
<li>å¤´æˆ´æ˜¾ç¤ºå™¨ï¼ˆHMDsï¼‰çš„æ™®åŠä½¿å¾—XRæŠ€æœ¯å°†æˆä¸ºä¸ªäººè®¾å¤‡çš„ä¸€éƒ¨åˆ†ï¼Œå¦‚åŒæ™ºèƒ½æ‰‹æœºå’Œå¹³æ¿ã€‚</li>
<li>åœ¨XRä¸­å®ç°æ™ºèƒ½ç©ºé—´å’Œè‡ªç„¶äº¤äº’è‡³å…³é‡è¦ï¼Œå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰é©±åŠ¨çš„éç©å®¶è§’è‰²ï¼ˆNPCsï¼‰ç»“åˆè¯­éŸ³è¯†åˆ«å’Œæ–‡æœ¬åˆæˆæŠ€æœ¯ä¸ºç”¨æˆ·æä¾›äº†æ›´è‡ªç„¶çš„äº¤äº’ç•Œé¢ã€‚</li>
<li>æœ¬æ–‡ä»‹ç»äº†ä¸€ä¸ªå¼€æºçš„Unityè½¯ä»¶åŒ…CUIfyï¼Œå®ƒæ”¯æŒåŸºäºè¯­éŸ³çš„NPC-ç”¨æˆ·äº¤äº’ï¼Œå¹¶å¯ä¸å¤§å‹è¯­è¨€æ¨¡å‹ã€è¯­éŸ³è¯†åˆ«å’Œæ–‡æœ¬åˆæˆæŠ€æœ¯ç»“åˆä½¿ç”¨ã€‚</li>
<li>CUIfyè½¯ä»¶åŒ…æ”¯æŒå¤šä¸ªç¯å¢ƒå†…çš„å¤šä¸ªLLMé©±åŠ¨NPCsã€‚</li>
<li>è½¯ä»¶åŒ…é€šè¿‡æµæŠ€æœ¯ä¼˜åŒ–ä¸åŒè®¡ç®—æ¨¡å‹ä¹‹é—´çš„äº¤äº’ï¼Œå‡å°‘å»¶è¿Ÿã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2411.04671">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-b0ebd2f9422e2d2b3a61905fe37529e6.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-90d7d8da6b3bb3b9a79de2dd574a8070.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-273f6ac1d026cc6465dee7b4dc46e0d1.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-b7298009103c19166d86615b5e16a162.jpg" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1><h2 id="Kinetix-Investigating-the-Training-of-General-Agents-through-Open-Ended-Physics-Based-Control-Tasks"><a href="#Kinetix-Investigating-the-Training-of-General-Agents-through-Open-Ended-Physics-Based-Control-Tasks" class="headerlink" title="Kinetix: Investigating the Training of General Agents through Open-Ended   Physics-Based Control Tasks"></a>Kinetix: Investigating the Training of General Agents through Open-Ended   Physics-Based Control Tasks</h2><p><strong>Authors:Michael Matthews, Michael Beukman, Chris Lu, Jakob Foerster</strong></p>
<p>While large models trained with self-supervised learning on offline datasets have shown remarkable capabilities in text and image domains, achieving the same generalisation for agents that act in sequential decision problems remains an open challenge. In this work, we take a step towards this goal by procedurally generating tens of millions of 2D physics-based tasks and using these to train a general reinforcement learning (RL) agent for physical control. To this end, we introduce Kinetix: an open-ended space of physics-based RL environments that can represent tasks ranging from robotic locomotion and grasping to video games and classic RL environments, all within a unified framework. Kinetix makes use of our novel hardware-accelerated physics engine Jax2D that allows us to cheaply simulate billions of environment steps during training. Our trained agent exhibits strong physical reasoning capabilities in 2D space, being able to zero-shot solve unseen human-designed environments. Furthermore, fine-tuning this general agent on tasks of interest shows significantly stronger performance than training an RL agent <em>tabula rasa</em>. This includes solving some environments that standard RL training completely fails at. We believe this demonstrates the feasibility of large scale, mixed-quality pre-training for online RL and we hope that Kinetix will serve as a useful framework to investigate this further. </p>
<blockquote>
<p>è™½ç„¶ä½¿ç”¨è‡ªç›‘ç£å­¦ä¹ åœ¨ç¦»çº¿æ•°æ®é›†ä¸Šè®­ç»ƒçš„å¤§å‹æ¨¡å‹åœ¨æ–‡æœ¬å’Œå›¾åƒé¢†åŸŸè¡¨ç°å‡ºäº†æ˜¾è‘—çš„èƒ½åŠ›ï¼Œä½†å¯¹äºåœ¨åºåˆ—å†³ç­–é—®é¢˜ä¸­è¡ŒåŠ¨çš„ä»£ç†ï¼Œå®ç°åŒæ ·çš„æ³›åŒ–ä»ç„¶æ˜¯ä¸€ä¸ªå¼€æ”¾æ€§çš„æŒ‘æˆ˜ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬é€šè¿‡ç¨‹åºç”Ÿæˆæ•°äº¿ä¸ªåŸºäºç‰©ç†çš„2Dä»»åŠ¡æ¥å®ç°è¿™ä¸€ç›®æ ‡ï¼Œå¹¶ä½¿ç”¨è¿™äº›ä»»åŠ¡æ¥è®­ç»ƒç”¨äºç‰©ç†æ§åˆ¶çš„é€šç”¨å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰ä»£ç†ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬æ¨å‡ºäº†Kinetixï¼šä¸€ä¸ªå¼€æ”¾çš„ã€åŸºäºç‰©ç†çš„RLç¯å¢ƒç©ºé—´ï¼Œå®ƒå¯ä»¥è¡¨ç¤ºä»æœºå™¨äººè¿åŠ¨ã€æŠ“å–åˆ°ç”µå­æ¸¸æˆå’Œç»å…¸RLç¯å¢ƒçš„å„ç§ä»»åŠ¡ï¼Œéƒ½åœ¨ä¸€ä¸ªç»Ÿä¸€æ¡†æ¶å†…ã€‚Kinetixåˆ©ç”¨æˆ‘ä»¬æ–°å‹ç¡¬ä»¶åŠ é€Ÿçš„ç‰©ç†å¼•æ“Jax2Dï¼Œå®ƒå…è®¸æˆ‘ä»¬åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å»‰ä»·åœ°æ¨¡æ‹Ÿæ•°åäº¿çš„ç¯å¢ƒæ­¥éª¤ã€‚æˆ‘ä»¬è®­ç»ƒçš„ä»£ç†åœ¨2Dç©ºé—´ä¸­å±•ç°å‡ºå¼ºå¤§çš„ç‰©ç†æ¨ç†èƒ½åŠ›ï¼Œèƒ½å¤Ÿé›¶å°„å‡»è§£å†³æœªè§è¿‡çš„äººç±»è®¾è®¡ç¯å¢ƒã€‚æ­¤å¤–ï¼Œå¯¹æ„Ÿå…´è¶£çš„ä»»åŠ¡å¯¹ä»£ç†è¿›è¡Œå¾®è°ƒæ˜¾ç¤ºå‡ºäº†æ¯”ä»å¤´å¼€å§‹è®­ç»ƒRLä»£ç†æ˜¾è‘—æ›´å¼ºçš„æ€§èƒ½ã€‚è¿™åŒ…æ‹¬è§£å†³ä¸€äº›æ ‡å‡†RLè®­ç»ƒå®Œå…¨å¤±è´¥çš„ç¯å¢ƒã€‚æˆ‘ä»¬ç›¸ä¿¡è¿™è¯æ˜äº†å¤§è§„æ¨¡æ··åˆè´¨é‡é¢„è®­ç»ƒåœ¨çº¿å¼ºåŒ–å­¦ä¹ çš„å¯è¡Œæ€§ï¼Œæˆ‘ä»¬å¸Œæœ›Kinetixèƒ½ä½œä¸ºä¸€ä¸ªæœ‰ç”¨çš„æ¡†æ¶æ¥è¿›ä¸€æ­¥ç ”ç©¶è¿™ä¸€é¢†åŸŸã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2410.23208v2">PDF</a> ICLR 2025 Oral. The first two authors contributed equally. Project   page located at: <a target="_blank" rel="noopener" href="https://kinetix-env.github.io/">https://kinetix-env.github.io/</a></p>
<p><strong>Summary</strong>ï¼š</p>
<p>æœ¬æ–‡ä»‹ç»äº†ä¸€ç§åä¸ºKinetixçš„åŸºäºç‰©ç†çš„å¼ºåŒ–å­¦ä¹ ç¯å¢ƒï¼Œå®ƒèƒ½ç”Ÿæˆæ•°äº¿ä¸ªäºŒç»´ä»»åŠ¡ç”¨äºè®­ç»ƒæ™ºèƒ½ä½“è¿›è¡Œç‰©ç†æ§åˆ¶ã€‚Kinetixåˆ©ç”¨é«˜æ•ˆçš„ç¡¬ä»¶åŠ é€Ÿç‰©ç†å¼•æ“Jax2Dï¼Œèƒ½å¤Ÿåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­æ¨¡æ‹Ÿæ•°åäº¿çš„ç¯å¢ƒæ­¥éª¤ã€‚è®­ç»ƒå‡ºçš„æ™ºèƒ½ä½“å±•ç°å‡ºå¼ºå¤§çš„äºŒç»´ç©ºé—´ç‰©ç†æ¨ç†èƒ½åŠ›ï¼Œèƒ½å¤Ÿé›¶æ ·æœ¬è§£å†³æœªè§è¿‡çš„äººç±»è®¾è®¡ç¯å¢ƒã€‚æ­¤å¤–ï¼Œå¯¹æ„Ÿå…´è¶£çš„ä»»åŠ¡è¿›è¡Œå¾®è°ƒï¼Œè¡¨ç°å‡ºæ¯”ä»å¤´å¼€å§‹è®­ç»ƒæ›´å¼ºçš„æ€§èƒ½ï¼ŒåŒ…æ‹¬è§£å†³æ ‡å‡†å¼ºåŒ–å­¦ä¹ è®­ç»ƒæ— æ³•è§£å†³çš„é—®é¢˜ã€‚è¿™è¯æ˜äº†å¤§è§„æ¨¡æ··åˆè´¨é‡é¢„è®­ç»ƒå¯¹äºåœ¨çº¿å¼ºåŒ–å­¦ä¹ çš„å¯è¡Œæ€§ã€‚</p>
<p><strong>Key Takeaways</strong>ï¼š</p>
<ol>
<li>Kinetixæ˜¯ä¸€ä¸ªåŸºäºç‰©ç†çš„å¼ºåŒ–å­¦ä¹ ç¯å¢ƒï¼Œèƒ½ç”Ÿæˆå¤§é‡äºŒç»´ä»»åŠ¡ç”¨äºè®­ç»ƒæ™ºèƒ½ä½“è¿›è¡Œç‰©ç†æ§åˆ¶ã€‚</li>
<li>Kinetixåˆ©ç”¨Jax2Dç¡¬ä»¶åŠ é€Ÿç‰©ç†å¼•æ“ï¼Œå¯æ¨¡æ‹Ÿæ•°åäº¿ç¯å¢ƒæ­¥éª¤ã€‚</li>
<li>è®­ç»ƒå‡ºçš„æ™ºèƒ½ä½“å±•ç°å‡ºå¼ºå¤§çš„äºŒç»´ç©ºé—´ç‰©ç†æ¨ç†èƒ½åŠ›ï¼Œèƒ½å¤Ÿé›¶æ ·æœ¬è§£å†³æœªè§è¿‡çš„ç¯å¢ƒã€‚</li>
<li>å¯¹æ„Ÿå…´è¶£çš„ä»»åŠ¡è¿›è¡Œå¾®è°ƒèƒ½æå‡æ™ºèƒ½ä½“çš„æ€§èƒ½ã€‚</li>
<li>Kinetixå¹³å°èƒ½æ˜¾è‘—æé«˜å¼ºåŒ–å­¦ä¹ åœ¨å¤æ‚ç¯å¢ƒä¸­çš„æ³›åŒ–èƒ½åŠ›ã€‚</li>
<li>ä¸æ ‡å‡†å¼ºåŒ–å­¦ä¹ è®­ç»ƒç›¸æ¯”ï¼ŒKinetixçš„æ–¹æ³•åœ¨æŸäº›ç¯å¢ƒä¸­è¡¨ç°å‡ºæ›´å¥½çš„æ€§èƒ½ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2410.23208">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-70f247aec3fd917ee7a2c25633c46fbd.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c3aacb2bce8534c7a318054037de13b4.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-cab5621f5046081f927a43c21749f71f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-3259d25f230b9586011a1d98277d29db.jpg" align="middle">
</details>


<h1 id="-9"><a href="#-9" class="headerlink" title=""></a></h1><h2 id="MACPO-Weak-to-Strong-Alignment-via-Multi-Agent-Contrastive-Preference-Optimization"><a href="#MACPO-Weak-to-Strong-Alignment-via-Multi-Agent-Contrastive-Preference-Optimization" class="headerlink" title="MACPO: Weak-to-Strong Alignment via Multi-Agent Contrastive Preference   Optimization"></a>MACPO: Weak-to-Strong Alignment via Multi-Agent Contrastive Preference   Optimization</h2><p><strong>Authors:Yougang Lyu, Lingyong Yan, Zihan Wang, Dawei Yin, Pengjie Ren, Maarten de Rijke, Zhaochun Ren</strong></p>
<p>As large language models (LLMs) are rapidly advancing and achieving near-human capabilities on specific tasks, aligning them with human values is becoming more urgent. In scenarios where LLMs outperform humans, we face a weak-to-strong alignment problem where we need to effectively align strong student LLMs through weak supervision generated by weak teachers. Existing alignment methods mainly focus on strong-to-weak alignment and self-alignment settings, and it is impractical to adapt them to the much harder weak-to-strong alignment setting. To fill this gap, we propose a multi-agent contrastive preference optimization (MACPO) framework. MACPO facilitates weak teachers and strong students to learn from each other by iteratively reinforcing unfamiliar positive behaviors while penalizing familiar negative ones. To get this, we devise a mutual positive behavior augmentation strategy to encourage weak teachers and strong students to learn from each otherâ€™s positive behavior and further provide higher quality positive behavior for the next iteration. Additionally, we propose a hard negative behavior construction strategy to induce weak teachers and strong students to generate familiar negative behavior by fine-tuning on negative behavioral data. Experimental results on the HH-RLHF and PKU-SafeRLHF datasets, evaluated using both automatic metrics and human judgments, demonstrate that MACPO simultaneously improves the alignment performance of strong students and weak teachers. Moreover, as the number of weak teachers increases, MACPO achieves better weak-to-strong alignment performance through more iteration optimization rounds. </p>
<blockquote>
<p>éšç€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„å¿«é€Ÿå‘å±•ä»¥åŠåœ¨ç‰¹å®šä»»åŠ¡ä¸Šæ¥è¿‘äººç±»çš„æ€§èƒ½ï¼Œå°†å…¶ä¸äººç±»ä»·å€¼è§‚å¯¹é½å˜å¾—æ›´ä¸ºç´§è¿«ã€‚åœ¨LLMè¡¨ç°è¶…è¶Šäººç±»çš„åœºæ™¯ä¸­ï¼Œæˆ‘ä»¬é¢ä¸´ä¸€ä¸ªä»å¼±åˆ°å¼ºçš„å¯¹é½é—®é¢˜ï¼Œæˆ‘ä»¬éœ€è¦é€šè¿‡å¼±ç›‘ç£æ¥æœ‰æ•ˆåœ°å¯¹é½å¼ºå¤§çš„å­¦ç”ŸLLMã€‚ç°æœ‰çš„å¯¹é½æ–¹æ³•ä¸»è¦é›†ä¸­åœ¨å¼ºå¯¹å¼±å¯¹é½å’Œè‡ªæˆ‘å¯¹é½è®¾ç½®ä¸Šï¼Œå°†å®ƒä»¬é€‚åº”åˆ°æ›´å›°éš¾çš„ä»å¼±åˆ°å¼ºå¯¹é½è®¾ç½®æ˜¯ä¸åˆ‡å®é™…çš„ã€‚ä¸ºäº†å¡«è¡¥è¿™ä¸€ç©ºç™½ï¼Œæˆ‘ä»¬æå‡ºäº†å¤šä»£ç†å¯¹æ¯”åå¥½ä¼˜åŒ–ï¼ˆMACPOï¼‰æ¡†æ¶ã€‚MACPOé€šè¿‡é¼“åŠ±å¼±æ•™å¸ˆå¼ºå­¦ç”Ÿå½¼æ­¤ç›¸äº’å­¦ä¹ æ¥ä¿ƒä½¿ä»–ä»¬è¿­ä»£å¼ºåŒ–ä¸ç†Ÿæ‚‰çš„æ­£å‘è¡Œä¸ºå¹¶æƒ©ç½šç†Ÿæ‚‰çš„è´Ÿé¢è¡Œä¸ºã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬è®¾è®¡äº†ä¸€ç§ç›¸äº’æ­£å‘è¡Œä¸ºå¢å¼ºç­–ç•¥ï¼Œä»¥é¼“åŠ±å¼±æ•™å¸ˆå’Œå¼ºå­¦ç”Ÿä»å½¼æ­¤çš„æ­£å‘è¡Œä¸ºä¸­å­¦ä¹ ï¼Œå¹¶ä¸ºä¸‹ä¸€æ¬¡è¿­ä»£æä¾›æ›´ä¼˜è´¨çš„æ­£å‘è¡Œä¸ºã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜æå‡ºäº†ä¸€ç§ç¡¬è´Ÿé¢è¡Œä¸ºæ„å»ºç­–ç•¥ï¼Œé€šè¿‡å¾®è°ƒè´Ÿé¢è¡Œä¸ºæ•°æ®æ¥å¼•å¯¼å¼±æ•™å¸ˆå’Œå¼ºå­¦ç”Ÿäº§ç”Ÿç†Ÿæ‚‰çš„è´Ÿé¢è¡Œä¸ºã€‚åœ¨HH-RLHFå’ŒPKU-SafeRLHFæ•°æ®é›†ä¸Šçš„å®éªŒç»“æœé€šè¿‡è‡ªåŠ¨æŒ‡æ ‡å’Œäººç±»åˆ¤æ–­è¿›è¡Œè¯„ä¼°ï¼Œè¡¨æ˜MACPOåŒæ—¶æé«˜äº†å¼ºå­¦ç”Ÿå’Œå¼±æ•™å¸ˆçš„å¯¹é½æ€§èƒ½ã€‚è€Œä¸”ï¼Œéšç€å¼±æ•™å¸ˆæ•°é‡çš„å¢åŠ ï¼Œé€šè¿‡æ›´å¤šçš„è¿­ä»£ä¼˜åŒ–è½®æ¬¡ï¼ŒMACPOå®ç°äº†æ›´å¥½çš„ä»å¼±åˆ°å¼ºçš„å¯¹é½æ€§èƒ½ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2410.07672v2">PDF</a> ICLR 2025</p>
<p><strong>Summary</strong></p>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„å¿«é€Ÿå‘å±•ä½¿å…¶åœ¨ç‰¹å®šä»»åŠ¡ä¸Šå…·å¤‡äº†æ¥è¿‘äººç±»çš„æ€§èƒ½ï¼Œå› æ­¤å°†å…¶ä¸äººç±»ä»·å€¼è§‚å¯¹é½å˜å¾—æ›´ä¸ºç´§è¿«ã€‚åœ¨LLMè¡¨ç°è¶…è¶Šäººç±»çš„åœºæ™¯ä¸­ï¼Œæˆ‘ä»¬é¢ä¸´å¼±åˆ°å¼ºçš„å¯¹é½é—®é¢˜ï¼Œéœ€è¦æœ‰æ•ˆåœ°é€šè¿‡å¼±ç›‘ç£å¯¹é½å¼ºå¤§çš„å­¦ç”ŸLLMä¸å¼±æ•™å¸ˆã€‚ç°æœ‰å¯¹é½æ–¹æ³•ä¸»è¦å…³æ³¨å¼ºåˆ°å¼±å¯¹é½å’Œè‡ªæˆ‘å¯¹é½è®¾ç½®ï¼Œéš¾ä»¥é€‚åº”æ›´å›°éš¾çš„å¼±åˆ°å¼ºå¯¹é½è®¾ç½®ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬æå‡ºå¤šä»£ç†å¯¹æ¯”åå¥½ä¼˜åŒ–ï¼ˆMACPOï¼‰æ¡†æ¶ã€‚MACPOä¿ƒè¿›å¼±æ•™å¸ˆå’Œå¼ºå­¦ç”Ÿé€šè¿‡ç›¸äº’å­¦ä¹ è¿›è¡Œè¿­ä»£å¼ºåŒ–ä¸ç†Ÿæ‚‰çš„ç§¯æè¡Œä¸ºå¹¶æƒ©ç½šç†Ÿæ‚‰çš„æ¶ˆæè¡Œä¸ºã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æå‡ºç¡¬è´Ÿè¡Œä¸ºæ„å»ºç­–ç•¥ï¼Œé€šè¿‡å¾®è°ƒè´Ÿè¡Œä¸ºæ•°æ®è¯±å¯¼å¼±æ•™å¸ˆå’Œå¼ºå­¦ç”Ÿäº§ç”Ÿç†Ÿæ‚‰çš„æ¶ˆæè¡Œä¸ºã€‚åœ¨HH-RLHFå’ŒPKU-SafeRLHFæ•°æ®é›†ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼ŒMACPOåŒæ—¶æé«˜äº†å¼ºå­¦ç”Ÿå’Œå¼±æ•™å¸ˆçš„å¯¹é½æ€§èƒ½ã€‚éšç€å¼±æ•™å¸ˆæ•°é‡çš„å¢åŠ ï¼Œé€šè¿‡æ›´å¤šçš„è¿­ä»£ä¼˜åŒ–è½®æ¬¡ï¼ŒMACPOå®ç°äº†æ›´å¥½çš„å¼±åˆ°å¼ºå¯¹é½æ€§èƒ½ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„å¿«é€Ÿå‘å±•ä½¿å…¶é¢ä¸´ä¸äººç±»ä»·å€¼è§‚å¯¹é½çš„ç´§è¿«æ€§ã€‚</li>
<li>åœ¨LLMè¶…è¶Šäººç±»è¡¨ç°çš„åœºæ™¯ä¸­ï¼Œå­˜åœ¨å¼±åˆ°å¼ºçš„å¯¹é½é—®é¢˜ã€‚</li>
<li>ç°æœ‰å¯¹é½æ–¹æ³•ä¸»è¦å…³æ³¨å¼ºåˆ°å¼±å’Œå¯¹é½è‡ªæˆ‘å¯¹é½è®¾ç½®ï¼Œä¸é€‚åº”å¼±åˆ°å¼ºå¯¹é½çš„å›°éš¾åœºæ™¯ã€‚</li>
<li>MACPOæ¡†æ¶é€šè¿‡ä¿ƒè¿›å¼±æ•™å¸ˆå’Œå¼ºå­¦ç”Ÿä¹‹é—´çš„ç›¸äº’å­¦ä¹ æ¥è§£å†³å¼±åˆ°å¼ºå¯¹é½é—®é¢˜ã€‚</li>
<li>MACPOé‡‡ç”¨è¿­ä»£å¼ºåŒ–ç§¯æè¡Œä¸ºå¹¶æƒ©ç½šæ¶ˆæè¡Œä¸ºçš„ç­–ç•¥ã€‚</li>
<li>æå‡ºç›¸äº’ç§¯æè¡Œä¸ºå¢å¼ºç­–ç•¥å’Œç¡¬è´Ÿè¡Œä¸ºæ„å»ºç­–ç•¥æ¥ä¼˜åŒ–MACPOæ¡†æ¶ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2410.07672">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-8330879161590feafd86f156f6201639.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-50a187996816d8f980246c98c510c7c2.jpg" align="middle">
</details>


<h1 id="-10"><a href="#-10" class="headerlink" title=""></a></h1><h2 id="LTLf-Synthesis-on-First-Order-Agent-Programs-in-Nondeterministic-Environments"><a href="#LTLf-Synthesis-on-First-Order-Agent-Programs-in-Nondeterministic-Environments" class="headerlink" title="LTLf Synthesis on First-Order Agent Programs in Nondeterministic   Environments"></a>LTLf Synthesis on First-Order Agent Programs in Nondeterministic   Environments</h2><p><strong>Authors:Till Hofmann, Jens ClaÃŸen</strong></p>
<p>We investigate the synthesis of policies for high-level agent programs expressed in Golog, a language based on situation calculus that incorporates nondeterministic programming constructs. Unlike traditional approaches for program realization that assume full agent control or rely on incremental search, we address scenarios where environmental nondeterminism significantly influences program outcomes. Our synthesis problem involves deriving a policy that successfully realizes a given Golog program while ensuring the satisfaction of a temporal specification, expressed in Linear Temporal Logic on finite traces (LTLf), across all possible environmental behaviors. By leveraging an expressive class of first-order action theories, we construct a finite game arena that encapsulates program executions and tracks the satisfaction of the temporal goal. A game-theoretic approach is employed to derive such a policy. Experimental results demonstrate this approachâ€™s feasibility in domains with unbounded objects and non-local effects. This work bridges agent programming and temporal logic synthesis, providing a framework for robust agent behavior in nondeterministic environments. </p>
<blockquote>
<p>æˆ‘ä»¬ç ”ç©¶äº†åœ¨Gologè¯­è¨€ä¸­è¡¨è¾¾çš„é«˜çº§ä»£ç†ç¨‹åºçš„ç­–ç•¥åˆæˆã€‚Gologæ˜¯ä¸€ç§åŸºäºæƒ…å†µè®¡ç®—çš„è¯­è¨€ï¼Œå®ƒç»“åˆäº†éç¡®å®šæ€§ç¼–ç¨‹ç»“æ„ã€‚ä¸ä¼ ç»Ÿçš„ç¨‹åºå®ç°æ–¹æ³•ä¸åŒï¼Œåè€…å‡è®¾äº†å®Œå…¨çš„ä»£ç†æ§åˆ¶æˆ–ä¾èµ–äºå¢é‡æœç´¢ï¼Œæˆ‘ä»¬è§£å†³äº†ç¯å¢ƒéç¡®å®šæ€§æ˜¾è‘—å½±å“ç¨‹åºç»“æœçš„æƒ…å†µã€‚æˆ‘ä»¬çš„åˆæˆé—®é¢˜æ¶‰åŠæ¨å¯¼å‡ºæˆåŠŸå®ç°ç»™å®šGologç¨‹åºçš„ç­–ç•¥ï¼ŒåŒæ—¶ç¡®ä¿åœ¨æœ‰é™è½¨è¿¹ä¸Šçš„çº¿æ€§æ—¶åºé€»è¾‘ï¼ˆLTLfï¼‰è¡¨è¾¾çš„æ—¶åºè§„èŒƒåœ¨æ‰€æœ‰å¯èƒ½çš„ç¯å¢ƒè¡Œä¸ºä¸­å¾—åˆ°æ»¡è¶³ã€‚é€šè¿‡åˆ©ç”¨ä¸€é˜¶åŠ¨ä½œç†è®ºçš„è¡¨ç°åŠ›å¼ºå¤§çš„ç±»åˆ«ï¼Œæˆ‘ä»¬æ„å»ºäº†ä¸€ä¸ªæœ‰é™çš„åšå¼ˆåœºæ‰€ï¼Œè¯¥åœºæ‰€æ¶µç›–äº†ç¨‹åºæ‰§è¡Œå¹¶è·Ÿè¸ªæ—¶åºç›®æ ‡çš„æ»¡è¶³æƒ…å†µã€‚é‡‡ç”¨åšå¼ˆè®ºæ–¹æ³•æ¥æ¨å¯¼æ­¤ç±»ç­–ç•¥ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å…·æœ‰æ— é™å¯¹è±¡å’Œéå±€éƒ¨æ•ˆåº”çš„é¢†åŸŸä¸­å…·æœ‰å¯è¡Œæ€§ã€‚è¿™é¡¹å·¥ä½œå°†ä»£ç†ç¼–ç¨‹å’Œæ—¶åºé€»è¾‘åˆæˆç›¸ç»“åˆï¼Œä¸ºåœ¨éç¡®å®šæ€§ç¯å¢ƒä¸­å®ç°ç¨³å¥çš„ä»£ç†è¡Œä¸ºæä¾›äº†æ¡†æ¶ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2410.00726v3">PDF</a> AAAIâ€™25</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ç ”ç©¶äº†åœ¨åŸºäºæƒ…å¢ƒè®¡ç®—çš„è¯­è¨€Gologä¸­è¡¨è¾¾çš„é«˜çº§ä»£ç†ç¨‹åºçš„ç­–ç•¥åˆæˆã€‚é’ˆå¯¹ç¯å¢ƒéç¡®å®šæ€§å¯¹ç¨‹åºç»“æœäº§ç”Ÿæ˜¾è‘—å½±å“çš„æƒ…å†µï¼Œæå‡ºäº†ä¸€ç§æ–°çš„è§£å†³æ–¹æ¡ˆã€‚é€šè¿‡åˆ©ç”¨ä¸€é˜¶è¡ŒåŠ¨ç†è®ºï¼Œæ„é€ äº†ä¸€ä¸ªæœ‰é™çš„æ¸¸æˆåœºæ™¯ï¼Œå¯¹ç¨‹åºæ‰§è¡Œè¿›è¡Œå°è£…ï¼Œå¹¶è·Ÿè¸ªæ—¶é—´ç›®æ ‡çš„æ»¡è¶³æƒ…å†µã€‚é‡‡ç”¨åšå¼ˆç†è®ºçš„æ–¹æ³•æ¨å¯¼å‡ºè¿™æ ·çš„ç­–ç•¥ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å…·æœ‰æ— é™å¯¹è±¡å’Œéå±€éƒ¨æ•ˆåº”çš„é¢†åŸŸä¸­æ˜¯å¯è¡Œçš„ã€‚è¿™é¡¹å·¥ä½œå°†ä»£ç†ç¼–ç¨‹å’Œæ—¶åºé€»è¾‘åˆæˆè”ç³»åœ¨ä¸€èµ·ï¼Œä¸ºéçº¿æ€§ç¯å¢ƒä¸­ä»£ç†çš„ç¨³å¥è¡Œä¸ºæä¾›äº†æ¡†æ¶ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æœ¬æ–‡ç ”ç©¶äº†åœ¨Gologè¯­è¨€ä¸­åˆæˆé«˜çº§ä»£ç†ç¨‹åºç­–ç•¥çš„æ–¹æ³•ï¼ŒGologæ˜¯ä¸€ç§åŸºäºæƒ…å¢ƒè®¡ç®—çš„è¯­è¨€ï¼Œèå…¥äº†éç¡®å®šæ€§ç¼–ç¨‹ç»“æ„ã€‚</li>
<li>é’ˆå¯¹ç¯å¢ƒéç¡®å®šæ€§å¯¹ç¨‹åºç»“æœäº§ç”Ÿå½±å“çš„åœºæ™¯ï¼Œæå‡ºäº†ä¸€ç§æ–°çš„è§£å†³æ–¹æ¡ˆï¼Œè¯¥æ–¹æ¡ˆåœ¨æ¨å¯¼ç­–ç•¥æ—¶è€ƒè™‘åˆ°äº†æ‰€æœ‰å¯èƒ½çš„ç¯å¢ƒè¡Œä¸ºã€‚</li>
<li>é€šè¿‡åˆ©ç”¨ä¸€é˜¶è¡ŒåŠ¨ç†è®ºï¼Œæ„å»ºäº†ä¸€ä¸ªæœ‰é™çš„æ¸¸æˆåœºæ™¯æ¥å°è£…ç¨‹åºæ‰§è¡Œï¼Œå¹¶è·Ÿè¸ªæ—¶é—´ç›®æ ‡çš„æ»¡è¶³æƒ…å†µã€‚</li>
<li>é‡‡ç”¨åšå¼ˆç†è®ºçš„æ–¹æ³•æ¨å¯¼å‡ºç­–ç•¥ï¼Œä»¥ç¡®ä¿Gologç¨‹åºçš„å®ç°å¹¶æ»¡è¶³çº¿æ€§æ—¶åºé€»è¾‘è¡¨è¾¾çš„æ—¶é—´è§„èŒƒã€‚</li>
<li>å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å…·æœ‰æ— é™å¯¹è±¡å’Œéå±€éƒ¨æ•ˆåº”çš„é¢†åŸŸä¸­æ˜¯æœ‰æ•ˆçš„ã€‚</li>
<li>æœ¬æ–‡å·¥ä½œæœ‰åŠ©äºæ¡¥æ¥ä»£ç†ç¼–ç¨‹å’Œæ—¶åºé€»è¾‘åˆæˆï¼Œä¸ºåœ¨éçº¿æ€§ç¯å¢ƒä¸­çš„ç¨³å¥ä»£ç†è¡Œä¸ºæä¾›äº†æ¡†æ¶ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2410.00726">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-47f83af0e0626138cae63f7bd40df1fa.jpg" align="middle">
</details>


<h1 id="-11"><a href="#-11" class="headerlink" title=""></a></h1><h2 id="Automated-Design-of-Agentic-Systems"><a href="#Automated-Design-of-Agentic-Systems" class="headerlink" title="Automated Design of Agentic Systems"></a>Automated Design of Agentic Systems</h2><p><strong>Authors:Shengran Hu, Cong Lu, Jeff Clune</strong></p>
<p>Researchers are investing substantial effort in developing powerful general-purpose agents, wherein Foundation Models are used as modules within agentic systems (e.g. Chain-of-Thought, Self-Reflection, Toolformer). However, the history of machine learning teaches us that hand-designed solutions are eventually replaced by learned solutions. We describe a newly forming research area, Automated Design of Agentic Systems (ADAS), which aims to automatically create powerful agentic system designs, including inventing novel building blocks and&#x2F;or combining them in new ways. We further demonstrate that there is an unexplored yet promising approach within ADAS where agents can be defined in code and new agents can be automatically discovered by a meta agent programming ever better ones in code. Given that programming languages are Turing Complete, this approach theoretically enables the learning of any possible agentic system: including novel prompts, tool use, workflows, and combinations thereof. We present a simple yet effective algorithm named Meta Agent Search to demonstrate this idea, where a meta agent iteratively programs interesting new agents based on an ever-growing archive of previous discoveries. Through extensive experiments across multiple domains including coding, science, and math, we show that our algorithm can progressively invent agents with novel designs that greatly outperform state-of-the-art hand-designed agents. Importantly, we consistently observe the surprising result that agents invented by Meta Agent Search maintain superior performance even when transferred across domains and models, demonstrating their robustness and generality. Provided we develop it safely, our work illustrates the potential of an exciting new research direction toward automatically designing ever-more powerful agentic systems to benefit humanity. </p>
<blockquote>
<p>ç ”ç©¶è€…æ­£åœ¨æŠ•å…¥å¤§é‡ç²¾åŠ›å¼€å‘åŠŸèƒ½å¼ºå¤§çš„é€šç”¨æ™ºèƒ½ä½“ï¼Œå…¶ä¸­åŸºç¡€æ¨¡å‹è¢«ç”¨ä½œæ™ºèƒ½ä½“ç³»ç»Ÿï¼ˆå¦‚æ€ç»´é“¾ã€è‡ªæˆ‘åæ€ã€å·¥å…·å˜å½¢å™¨ï¼‰ä¸­çš„æ¨¡å—ã€‚ç„¶è€Œï¼Œæœºå™¨å­¦ä¹ çš„å†å²å‘Šè¯‰æˆ‘ä»¬ï¼Œæ‰‹å·¥è®¾è®¡çš„è§£å†³æ–¹æ¡ˆæœ€ç»ˆä¼šè¢«å­¦ä¹ åˆ°çš„è§£å†³æ–¹æ¡ˆæ‰€å–ä»£ã€‚æˆ‘ä»¬æè¿°äº†ä¸€ä¸ªæ–°å…´çš„ç ”ç©¶é¢†åŸŸâ€”â€”è‡ªåŠ¨è®¾è®¡æ™ºèƒ½ç³»ç»Ÿï¼ˆADASï¼‰ï¼Œè¯¥é¢†åŸŸçš„ç›®æ ‡æ˜¯è‡ªåŠ¨åˆ›å»ºå¼ºå¤§çš„æ™ºèƒ½ç³»ç»Ÿè®¾è®¡æ–¹æ¡ˆï¼ŒåŒ…æ‹¬å‘æ˜æ–°å‹æ„å»ºå—å¹¶ä»¥æ–°çš„æ–¹å¼å°†å®ƒä»¬ç»„åˆèµ·æ¥ã€‚æˆ‘ä»¬è¿˜è¯æ˜ï¼Œåœ¨ADASä¸­å­˜åœ¨ä¸€ç§å°šæœªæ¢ç´¢ä½†å‰æ™¯çœ‹å¥½çš„æ–¹æ³•ï¼Œå³å¯ä»¥åœ¨ä»£ç ä¸­å®šä¹‰æ™ºèƒ½ä½“ï¼Œå¹¶é€šè¿‡å…ƒä»£ç†ç¨‹åºè‡ªåŠ¨å‘ç°æ–°çš„æ™ºèƒ½ä½“ï¼Œä»¥æ›´å¥½åœ°ç¼–å†™ä»£ç ã€‚é‰´äºç¼–ç¨‹è¯­è¨€æ˜¯å›¾çµå®Œå¤‡çš„ï¼Œè¿™ç§æ–¹æ³•ç†è®ºä¸Šèƒ½å¤Ÿå­¦ä¹ ä»»ä½•å¯èƒ½çš„æ™ºèƒ½ç³»ç»Ÿï¼ŒåŒ…æ‹¬æ–°å‹æç¤ºã€å·¥å…·ä½¿ç”¨ã€å·¥ä½œæµç¨‹åŠå…¶ç»„åˆã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªç®€å•æœ‰æ•ˆçš„ç®—æ³•ï¼Œåä¸ºå…ƒä»£ç†æœç´¢ï¼Œä»¥è¯æ˜è¿™ä¸€æƒ³æ³•ï¼Œè¯¥ç®—æ³•åŸºäºä¸æ–­å¢é•¿çš„å…ˆå‰å‘ç°æ¡£æ¡ˆï¼Œè¿­ä»£åœ°ç¼–ç¨‹æœ‰è¶£çš„æ–°æ™ºèƒ½ä½“ã€‚é€šè¿‡ç¼–ç ã€ç§‘å­¦å’Œæ•°å­¦ç­‰å¤šä¸ªé¢†åŸŸçš„å¹¿æ³›å®éªŒï¼Œæˆ‘ä»¬è¯æ˜æˆ‘ä»¬çš„ç®—æ³•å¯ä»¥é€æ­¥å‘æ˜å…·æœ‰æ–°é¢–è®¾è®¡çš„æ™ºèƒ½ä½“ï¼Œè¿™äº›æ™ºèƒ½ä½“åœ¨å¾ˆå¤§ç¨‹åº¦ä¸Šä¼˜äºæœ€æ–°çš„æ‰‹å·¥è®¾è®¡æ™ºèƒ½ä½“ã€‚é‡è¦çš„æ˜¯ï¼Œæˆ‘ä»¬ä¸€è´¯è§‚å¯Ÿåˆ°ä»¤äººæƒŠè®¶çš„ç»“æœæ˜¯ï¼Œå…ƒä»£ç†æœç´¢æ‰€å‘æ˜çš„æ™ºèƒ½ä½“å³ä½¿åœ¨è·¨é¢†åŸŸå’Œæ¨¡å‹è½¬ç§»æ—¶ä¹Ÿèƒ½ä¿æŒå“è¶Šçš„æ€§èƒ½ï¼Œè¯æ˜äº†å®ƒä»¬çš„ç¨³å¥æ€§å’Œæ™®éæ€§ã€‚åªè¦æˆ‘ä»¬å®‰å…¨åœ°å‘å±•å®ƒï¼Œæˆ‘ä»¬çš„å·¥ä½œå±•ç¤ºäº†æœç€è‡ªåŠ¨è®¾è®¡è¶Šæ¥è¶Šå¼ºå¤§çš„æ™ºèƒ½ç³»ç»Ÿè¿™ä¸€ä»¤äººå…´å¥‹çš„æ–°ç ”ç©¶æ–¹å‘çš„æ½œåŠ›ï¼Œè¿™å°†ä¸ºäººç±»å¸¦æ¥å¥½å¤„ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2408.08435v2">PDF</a> Website: <a target="_blank" rel="noopener" href="https://shengranhu.com/ADAS">https://shengranhu.com/ADAS</a></p>
<p><strong>Summary</strong><br>     è¿‘æœŸï¼Œç ”ç©¶è€…æ­£è‡´åŠ›äºå¼€å‘å¼ºå¤§çš„é€šç”¨ä»£ç†ï¼Œä½¿ç”¨åŸºç¡€æ¨¡å‹ä½œä¸ºä»£ç†ç³»ç»Ÿå†…çš„æ¨¡å—ã€‚å†å²å‘Šè¯‰æˆ‘ä»¬ï¼Œæ‰‹å·¥è®¾è®¡çš„è§£å†³æ–¹æ¡ˆæœ€ç»ˆä¼šè¢«å­¦ä¹ åˆ°çš„è§£å†³æ–¹æ¡ˆæ‰€å–ä»£ã€‚æ–°å…´çš„ç ”ç©¶é¢†åŸŸâ€”â€”è‡ªåŠ¨åŒ–ä»£ç†ç³»ç»Ÿè®¾è®¡ï¼ˆADASï¼‰æ—¨åœ¨è‡ªåŠ¨åˆ›å»ºå¼ºå¤§çš„ä»£ç†ç³»ç»Ÿè®¾è®¡ï¼ŒåŒ…æ‹¬å‘æ˜æ–°å‹æ„å»ºæ¨¡å—å’Œ&#x2F;æˆ–ä»¥æ–°æ–¹å¼ç»„åˆå®ƒä»¬ã€‚ç‰¹åˆ«åœ°ï¼Œå­˜åœ¨ä¸€ç§ç†è®ºä¸Šæœ‰å‰æ™¯çš„æ–¹æ³•ï¼Œå³é€šè¿‡åœ¨ä»£ç ä¸­å®šä¹‰ä»£ç†å¹¶ä½¿ç”¨å…ƒä»£ç†ç¨‹åºè‡ªåŠ¨å‘ç°æ–°ä»£ç†æ¥ä¼˜åŒ–ã€‚è¿™ç§æ–¹æ³•ç†è®ºä¸Šå¯ä»¥å­¦ä¹ ä»»ä½•å¯èƒ½çš„ä»£ç†ç³»ç»Ÿï¼ŒåŒ…æ‹¬æ–°é¢–çš„æç¤ºã€å·¥å…·ä½¿ç”¨ã€å·¥ä½œæµç¨‹åŠå…¶ç»„åˆã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªç®€å•çš„ç®—æ³•â€”â€”å…ƒä»£ç†æœç´¢æ¥æ¼”ç¤ºè¿™ä¸ªæƒ³æ³•ï¼Œè¯¥ç®—æ³•ä½¿å…ƒä»£ç†èƒ½å¤ŸåŸºäºä¸æ–­å¢é•¿çš„å…ˆå‰å‘ç°æ¡£æ¡ˆæ¥ç¼–ç¨‹æœ‰è¶£çš„æ–°ä»£ç†ã€‚ç»è¿‡åœ¨å¤šä¸ªé¢†åŸŸè¿›è¡Œçš„å¤§é‡å®éªŒè¯æ˜ï¼Œæˆ‘ä»¬çš„ç®—æ³•å¯ä»¥é€æ­¥å‘æ˜å…·æœ‰æ–°é¢–è®¾è®¡çš„ä»£ç†ï¼Œè¿™äº›ä»£ç†åœ¨æ€§èƒ½ä¸Šå¤§å¤§ä¼˜äºæœ€æ–°çš„æ‰‹å·¥è®¾è®¡ä»£ç†ã€‚æ›´é‡è¦çš„æ˜¯ï¼Œæˆ‘ä»¬è§‚å¯Ÿåˆ°ä»¤äººæƒŠè®¶çš„ç»“æœï¼Œå³å…ƒä»£ç†æœç´¢å‘æ˜çš„ä»£ç†åœ¨è·¨åŸŸå’Œæ¨¡å‹è½¬ç§»æ—¶ä»èƒ½ä¿æŒå“è¶Šçš„æ€§èƒ½ï¼Œè¯æ˜äº†å®ƒä»¬çš„ç¨³å¥æ€§å’Œæ™®éæ€§ã€‚åœ¨ç¡®ä¿å®‰å…¨å¼€å‘çš„å‰æä¸‹ï¼Œæˆ‘ä»¬çš„å·¥ä½œå±•ç¤ºäº†æœç€è‡ªåŠ¨è®¾è®¡è¶Šæ¥è¶Šå¼ºå¤§çš„ä»£ç†ç³»ç»Ÿè¿™ä¸€ä»¤äººå…´å¥‹çš„æ–°ç ”ç©¶æ–¹å‘çš„æ½œåŠ›ï¼Œæœ€ç»ˆä¸ºäººç±»çš„åˆ©ç›ŠæœåŠ¡ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ç ”ç©¶è€…æ­£è‡´åŠ›äºå¼€å‘é€šç”¨ä»£ç†ï¼Œä½¿ç”¨åŸºç¡€æ¨¡å‹ä½œä¸ºæ¨¡å—ã€‚</li>
<li>æ‰‹å·¥è®¾è®¡çš„ä»£ç†è§£å†³æ–¹æ¡ˆæœ€ç»ˆå¯èƒ½è¢«å­¦ä¹ åˆ°çš„è§£å†³æ–¹æ¡ˆæ‰€å–ä»£ã€‚</li>
<li>æ–°å…´ç ”ç©¶é¢†åŸŸADASæ—¨åœ¨è‡ªåŠ¨åˆ›å»ºå¼ºå¤§çš„ä»£ç†ç³»ç»Ÿè®¾è®¡ã€‚</li>
<li>é€šè¿‡åœ¨ä»£ç ä¸­å®šä¹‰ä»£ç†å¹¶ä½¿ç”¨å…ƒä»£ç†ç¨‹åºï¼Œç†è®ºä¸Šå¯ä»¥å­¦ä¹ ä»»ä½•å¯èƒ½çš„ä»£ç†ç³»ç»Ÿã€‚</li>
<li>å…ƒä»£ç†æœç´¢ç®—æ³•èƒ½åŸºäºå…ˆå‰å‘ç°è‡ªåŠ¨ç¼–ç¨‹æ–°ä»£ç†ã€‚</li>
<li>è¯¥ç®—æ³•å‘æ˜çš„ä»£ç†åœ¨è·¨åŸŸå’Œæ¨¡å‹è½¬ç§»æ—¶ä¿æŒå“è¶Šæ€§èƒ½ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2408.08435">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-2265409c6e19a1e4cd416dbd221a88d7.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-d27baeaad68b992bd07ca1021a74d37f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f5544edfd8bcba1cb808a6d461690958.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-628885d48667b41d55492d48b0aba6f8.jpg" align="middle">
</details>


<h1 id="-12"><a href="#-12" class="headerlink" title=""></a></h1><h2 id="POGEMA-A-Benchmark-Platform-for-Cooperative-Multi-Agent-Pathfinding"><a href="#POGEMA-A-Benchmark-Platform-for-Cooperative-Multi-Agent-Pathfinding" class="headerlink" title="POGEMA: A Benchmark Platform for Cooperative Multi-Agent Pathfinding"></a>POGEMA: A Benchmark Platform for Cooperative Multi-Agent Pathfinding</h2><p><strong>Authors:Alexey Skrynnik, Anton Andreychuk, Anatolii Borzilov, Alexander Chernyavskiy, Konstantin Yakovlev, Aleksandr Panov</strong></p>
<p>Multi-agent reinforcement learning (MARL) has recently excelled in solving challenging cooperative and competitive multi-agent problems in various environments, typically involving a small number of agents and full observability. Moreover, a range of crucial robotics-related tasks, such as multi-robot pathfinding, which have traditionally been approached with classical non-learnable methods (e.g., heuristic search), are now being suggested for solution using learning-based or hybrid methods. However, in this domain, it remains difficult, if not impossible, to conduct a fair comparison between classical, learning-based, and hybrid approaches due to the lack of a unified framework that supports both learning and evaluation. To address this, we introduce POGEMA, a comprehensive set of tools that includes a fast environment for learning, a problem instance generator, a collection of predefined problem instances, a visualization toolkit, and a benchmarking tool for automated evaluation. We also introduce and define an evaluation protocol that specifies a range of domain-related metrics, computed based on primary evaluation indicators (such as success rate and path length), enabling a fair multi-fold comparison. The results of this comparison, which involves a variety of state-of-the-art MARL, search-based, and hybrid methods, are presented. </p>
<blockquote>
<p>å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ ï¼ˆMARLï¼‰æœ€è¿‘åœ¨è§£å†³å„ç§ç¯å¢ƒä¸­çš„æŒ‘æˆ˜æ€§åˆä½œå’Œç«äº‰æ€§å¤šæ™ºèƒ½ä½“é—®é¢˜ä¸Šè¡¨ç°å‡ºè‰²ï¼Œé€šå¸¸æ¶‰åŠå°‘é‡æ™ºèƒ½ä½“å’Œå®Œå…¨å¯è§‚å¯Ÿæ€§ã€‚æ­¤å¤–ï¼Œä¸€ç³»åˆ—å…³é”®çš„æœºå™¨äººç›¸å…³ä»»åŠ¡ï¼Œå¦‚ä½¿ç”¨ä¼ ç»Ÿä¸å¯å­¦ä¹ çš„æ–¹æ³•ï¼ˆå¦‚å¯å‘å¼æœç´¢ï¼‰è§£å†³çš„å¤šæœºå™¨äººè·¯å¾„è§„åˆ’ï¼Œç°åœ¨å»ºè®®ä½¿ç”¨åŸºäºå­¦ä¹ æˆ–æ··åˆæ–¹æ³•æ¥è§£å†³ã€‚ç„¶è€Œï¼Œåœ¨è¿™ä¸ªé¢†åŸŸï¼Œç”±äºç¼ºä¹ä¸€ä¸ªæ—¢æ”¯æŒå­¦ä¹ å’Œè¯„ä¼°çš„ç»Ÿä¸€æ¡†æ¶ï¼Œè¿›è¡Œç»å…¸æ–¹æ³•ã€åŸºäºå­¦ä¹ çš„æ–¹æ³•å’Œæ··åˆæ–¹æ³•ä¹‹é—´çš„å…¬å¹³æ¯”è¾ƒå˜å¾—å›°éš¾ç”šè‡³ä¸å¯èƒ½ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬å¼•å…¥äº†POGEMAï¼Œè¿™æ˜¯ä¸€å¥—ç»¼åˆå·¥å…·ï¼ŒåŒ…æ‹¬ç”¨äºå­¦ä¹ çš„å¿«é€Ÿç¯å¢ƒã€é—®é¢˜å®ä¾‹ç”Ÿæˆå™¨ã€é¢„å®šä¹‰é—®é¢˜å®ä¾‹é›†åˆã€å¯è§†åŒ–å·¥å…·åŒ…å’Œç”¨äºè‡ªåŠ¨åŒ–è¯„ä¼°çš„åŸºå‡†æµ‹è¯•å·¥å…·ã€‚æˆ‘ä»¬è¿˜ä»‹ç»å¹¶å®šä¹‰äº†ä¸€ä¸ªè¯„ä¼°åè®®ï¼Œè¯¥åè®®è§„å®šäº†åŸºäºä¸»è¦è¯„ä¼°æŒ‡æ ‡ï¼ˆå¦‚æˆåŠŸç‡å’Œè·¯å¾„é•¿åº¦ï¼‰çš„ä¸€ç³»åˆ—ä¸é¢†åŸŸç›¸å…³çš„æŒ‡æ ‡ï¼Œä»è€Œå®ç°å…¬å¹³çš„å¤šé‡æ¯”è¾ƒã€‚æ¶‰åŠå¤šç§æœ€å…ˆè¿›çš„MARLã€åŸºäºæœç´¢çš„æ··åˆæ–¹æ³•çš„æ¯”è¾ƒç»“æœåœ¨æ­¤å‘ˆç°ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2407.14931v2">PDF</a> Published as a conference paper at The International Conference on   Learning Representations 2025</p>
<p><strong>Summary</strong></p>
<p>å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ ï¼ˆMARLï¼‰åœ¨è§£å†³å„ç§ç¯å¢ƒä¸­çš„åˆä½œä¸ç«äº‰å¤šæ™ºèƒ½ä½“é—®é¢˜ä¸Šè¡¨ç°å‡ºè‰²ï¼Œç‰¹åˆ«æ˜¯åœ¨æ¶‰åŠå°‘é‡æ™ºèƒ½ä½“å’Œå®Œå…¨å¯è§‚å¯Ÿæ€§çš„æƒ…å†µä¸‹ã€‚é’ˆå¯¹ä¼ ç»Ÿä¸Šä½¿ç”¨ç»å…¸éå­¦ä¹ æ–¹æ³•ï¼ˆå¦‚å¯å‘å¼æœç´¢ï¼‰è§£å†³çš„å¤šæœºå™¨äººè·¯å¾„æŸ¥æ‰¾ç­‰æœºå™¨äººç›¸å…³ä»»åŠ¡ï¼Œå»ºè®®ä½¿ç”¨åŸºäºå­¦ä¹ æˆ–æ··åˆæ–¹æ³•æ¥è§£å†³ã€‚ç„¶è€Œï¼Œç”±äºç¼ºä¹æ”¯æŒå­¦ä¹ å’Œè¯„ä¼°çš„ç»Ÿä¸€æ¡†æ¶ï¼Œéš¾ä»¥å¯¹ç»å…¸æ–¹æ³•ã€åŸºäºå­¦ä¹ çš„æ–¹æ³•å’Œæ··åˆæ–¹æ³•è¿›è¡Œå…¬å¹³æ¯”è¾ƒã€‚ä¸ºè§£å†³è¿™ä¸€é—®é¢˜ï¼Œæœ¬æ–‡ä»‹ç»äº†POGEMAå·¥å…·é›†ï¼ŒåŒ…æ‹¬å­¦ä¹ å¿«é€Ÿç¯å¢ƒã€é—®é¢˜å®ä¾‹ç”Ÿæˆå™¨ã€é¢„å®šé—®é¢˜å®ä¾‹é›†åˆã€å¯è§†åŒ–å·¥å…·åŒ…å’Œè‡ªåŠ¨åŒ–è¯„ä¼°åŸºå‡†å·¥å…·ã€‚æ­¤å¤–ï¼Œæœ¬æ–‡è¿˜ä»‹ç»å¹¶å®šä¹‰äº†ä¸€ç§è¯„ä¼°åè®®ï¼Œè¯¥åè®®è§„å®šäº†åŸºäºä¸»è¦è¯„ä¼°æŒ‡æ ‡ï¼ˆå¦‚æˆåŠŸç‡å’Œè·¯å¾„é•¿åº¦ï¼‰è®¡ç®—çš„ä¸€ç³»åˆ—é¢†åŸŸç›¸å…³æŒ‡æ ‡ï¼Œä»¥å®ç°å…¬å¹³çš„å¤šé‡æ¯”è¾ƒã€‚ç»™å‡ºäº†æ¶‰åŠå¤šç§å…ˆè¿›MARLã€åŸºäºæœç´¢çš„æ··åˆæ–¹æ³•çš„æ¯”è¾ƒç»“æœã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ ï¼ˆMARLï¼‰åœ¨å¤„ç†åˆä½œä¸ç«äº‰å¤šæ™ºèƒ½ä½“é—®é¢˜ä¸Šè¡¨ç°ä¼˜ç§€ï¼Œå°¤å…¶åœ¨ç¯å¢ƒè§‚å¯Ÿå®Œæ•´ä¸”æ™ºèƒ½ä½“æ•°é‡è¾ƒå°‘æ—¶ã€‚</li>
<li>ç»å…¸çš„éå­¦ä¹ æ–¹æ³•ï¼ˆå¦‚å¯å‘å¼æœç´¢ï¼‰é€šå¸¸ç”¨äºè§£å†³å¤šæœºå™¨äººè·¯å¾„æŸ¥æ‰¾ç­‰æœºå™¨äººä»»åŠ¡ï¼Œä½†ç°åœ¨æœ‰æè®®ä½¿ç”¨åŸºäºå­¦ä¹ æˆ–æ··åˆæ–¹æ³•æ¥è§£å†³è¿™äº›é—®é¢˜ã€‚</li>
<li>ç¼ºä¹ç»Ÿä¸€æ¡†æ¶ï¼Œéš¾ä»¥å…¬å¹³æ¯”è¾ƒç»å…¸æ–¹æ³•ã€åŸºäºå­¦ä¹ çš„æ–¹æ³•å’Œæ··åˆæ–¹æ³•ã€‚</li>
<li>POGEMAå·¥å…·é›†æä¾›äº†ä¸€ç³»åˆ—å·¥å…·ï¼ŒåŒ…æ‹¬å­¦ä¹ ç¯å¢ƒã€é—®é¢˜å®ä¾‹ç”Ÿæˆå™¨ã€å¯è§†åŒ–å·¥å…·åŒ…å’Œè‡ªåŠ¨åŒ–è¯„ä¼°åŸºå‡†ï¼Œä»¥è§£å†³è¿™ä¸€é—®é¢˜ã€‚</li>
<li>è¯„ä¼°åè®®è§„å®šäº†åŸºäºä¸»è¦è¯„ä¼°æŒ‡æ ‡ï¼ˆå¦‚æˆåŠŸç‡å’Œè·¯å¾„é•¿åº¦ï¼‰çš„é¢†åŸŸç›¸å…³æŒ‡æ ‡è®¡ç®—ï¼Œä»¥å®ç°å¤šç§æ–¹æ³•çš„å…¬å¹³æ¯”è¾ƒã€‚</li>
<li>æ¯”è¾ƒæ¶‰åŠå¤šç§å…ˆè¿›çš„MARLã€åŸºäºæœç´¢çš„æ··åˆæ–¹æ³•ï¼Œå±•ç¤ºäº†ä¸åŒæ–¹æ³•ä¹‹é—´çš„æ€§èƒ½å·®å¼‚ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2407.14931">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-5de1e1a41b59207e0d0966c92f115307.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-5f1ed62ad0f994971cfadb8ff37e3fa6.jpg" align="middle">
</details>


<h1 id="-13"><a href="#-13" class="headerlink" title=""></a></h1><h2 id="Adaptive-In-conversation-Team-Building-for-Language-Model-Agents"><a href="#Adaptive-In-conversation-Team-Building-for-Language-Model-Agents" class="headerlink" title="Adaptive In-conversation Team Building for Language Model Agents"></a>Adaptive In-conversation Team Building for Language Model Agents</h2><p><strong>Authors:Linxin Song, Jiale Liu, Jieyu Zhang, Shaokun Zhang, Ao Luo, Shijian Wang, Qingyun Wu, Chi Wang</strong></p>
<p>Leveraging multiple large language model (LLM) agents has shown to be a promising approach for tackling complex tasks, while the effective design of multiple agents for a particular application remains an art. It is thus intriguing to answer a critical question: Given a task, how can we build a team of LLM agents to solve it effectively? Our new adaptive team-building paradigm offers a flexible solution, realized through a novel agent design named Captain Agent. It dynamically forms and manages teams for each step of a task-solving process, utilizing nested group conversations and reflection to ensure diverse expertise and prevent stereotypical outputs, allowing for a flexible yet structured approach to problem-solving. A comprehensive evaluation across six real-world scenarios demonstrates that Captain Agent significantly outperforms existing multi-agent methods with 21.94% improvement in average accuracy, providing outstanding performance without requiring task-specific prompt engineering. Our exploration of different backbone LLM and cost analysis further shows that Captain Agent can improve the conversation quality of weak LLM and achieve competitive performance with extremely low cost, which illuminates the application of multi-agent systems. </p>
<blockquote>
<p>åˆ©ç”¨å¤šä¸ªå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä»£ç†å·²ç»æˆä¸ºè§£å†³å¤æ‚ä»»åŠ¡çš„å¾ˆæœ‰å‰é€”çš„æ–¹æ³•ï¼Œè€Œå¯¹äºç‰¹å®šåº”ç”¨çš„å¤šä¸ªä»£ç†çš„æœ‰æ•ˆè®¾è®¡ä»ç„¶æ˜¯ä¸€é—¨è‰ºæœ¯ã€‚å› æ­¤ï¼Œå›ç­”ä¸€ä¸ªå…³é”®é—®é¢˜æ˜¯å¾ˆæœ‰å¸å¼•åŠ›çš„ï¼šç»™å®šä¸€ä¸ªä»»åŠ¡ï¼Œæˆ‘ä»¬å¦‚ä½•å»ºç«‹ä¸€ä¸ªLLMä»£ç†å›¢é˜Ÿæ¥æœ‰æ•ˆåœ°è§£å†³å®ƒï¼Ÿæˆ‘ä»¬æ–°çš„è‡ªé€‚åº”å›¢é˜Ÿæ„å»ºèŒƒå¼æä¾›äº†ä¸€ç§çµæ´»çš„è§£å†³æ–¹æ¡ˆï¼Œè¿™æ˜¯é€šè¿‡ä¸€ç§åä¸ºCaptain Agentçš„æ–°å‹ä»£ç†è®¾è®¡å®ç°çš„ã€‚å®ƒä¸ºä»»åŠ¡è§£å†³è¿‡ç¨‹çš„æ¯ä¸ªæ­¥éª¤åŠ¨æ€åœ°ç»„å»ºå’Œç®¡ç†å›¢é˜Ÿï¼Œåˆ©ç”¨åµŒå¥—çš„å°ç»„å¯¹è¯å’Œåæ€æ¥ç¡®ä¿å¤šæ ·åŒ–çš„ä¸“ä¸šçŸ¥è¯†ï¼Œé˜²æ­¢åˆ»æ¿è¾“å‡ºï¼Œå…è®¸çµæ´»è€Œæœ‰æ¡ç†åœ°è§£å†³é—®é¢˜ã€‚åœ¨å…­ä¸ªçœŸå®åœºæ™¯çš„ç»¼åˆè¯„ä¼°ä¸­ï¼ŒCaptain Agentæ˜¾è‘—ä¼˜äºç°æœ‰çš„å¤šä»£ç†æ–¹æ³•ï¼Œå¹³å‡å‡†ç¡®ç‡æé«˜äº†21.94%ï¼Œåœ¨ä¸éœ€è¦é’ˆå¯¹ä»»åŠ¡è¿›è¡Œç‰¹å®šæç¤ºå·¥ç¨‹çš„æƒ…å†µä¸‹è¡¨ç°å‡ºå“è¶Šæ€§èƒ½ã€‚æˆ‘ä»¬å¯¹ä¸åŒåç›¾LLMçš„æ¢ç´¢å’Œæˆæœ¬åˆ†æè¿›ä¸€æ­¥è¡¨æ˜ï¼ŒCaptain Agentå¯ä»¥æé«˜å¼±LLMçš„å¯¹è¯è´¨é‡ï¼Œå¹¶ä»¥æä½çš„æˆæœ¬å®ç°å…·æœ‰ç«äº‰åŠ›çš„æ€§èƒ½ï¼Œè¿™è¿›ä¸€æ­¥è¡¨æ˜äº†å¤šä»£ç†ç³»ç»Ÿçš„åº”ç”¨å‰æ™¯ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2405.19425v3">PDF</a> </p>
<p><strong>Summary</strong><br>å¤šå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ååŒåˆä½œæ˜¯è§£å†³å¤æ‚ä»»åŠ¡çš„æœ‰æ•ˆæ–¹æ³•ã€‚ä¸ºå®ç°åŠ¨æ€çµæ´»çš„å›¢é˜Ÿåˆä½œï¼Œæå‡ºäº†åä¸ºCaptain Agentçš„æ–°å‹æ™ºèƒ½ä½“è®¾è®¡ã€‚å…¶åœ¨ä¸åŒä»»åŠ¡é˜¶æ®µå½¢æˆå¹¶ç®¡ç†å›¢é˜Ÿï¼Œåˆ©ç”¨åµŒå¥—ç¾¤ç»„å¯¹è¯ä¸åæ€ç¡®ä¿ä¸“ä¸šæŠ€èƒ½å¤šæ ·æ€§ï¼Œé¿å…åˆ»æ¿è¾“å‡ºã€‚ç»¼åˆè¯„ä¼°æ˜¾ç¤ºï¼ŒCaptain Agentåœ¨å¹³å‡å‡†ç¡®åº¦ä¸Šæ˜¾è‘—ä¼˜äºç°æœ‰å¤šæ™ºèƒ½ä½“æ–¹æ³•ï¼Œæå‡å¹…åº¦è¾¾21.94%ï¼Œå¹¶åœ¨ä¸åŒèƒŒæ™¯LLMä¸­è¡¨ç°å‡ºå“è¶Šæ€§èƒ½ä¸æˆæœ¬ä¼˜åŠ¿ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>åˆ©ç”¨å¤šä¸ªå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰è§£å†³å¤æ‚ä»»åŠ¡å±•ç°æ˜æ˜¾ä¼˜åŠ¿ã€‚</li>
<li>æ–°å‹çš„Captain Agentæ™ºèƒ½ä½“è®¾è®¡èƒ½å®ç°åŠ¨æ€å›¢é˜Ÿåˆä½œä»¥å®Œæˆä¸åŒä»»åŠ¡ã€‚</li>
<li>é€šè¿‡åµŒå¥—ç¾¤ç»„å¯¹è¯å’Œåæ€ç¡®ä¿å›¢é˜Ÿæˆå‘˜çš„æŠ€èƒ½å¤šæ ·æ€§å¹¶é¿å…åˆ»æ¿è¾“å‡ºã€‚</li>
<li>Captain Agentåœ¨å¹³å‡å‡†ç¡®åº¦ä¸Šæ˜¾è‘—ä¼˜äºç°æœ‰å¤šæ™ºèƒ½ä½“æ–¹æ³•ï¼Œæå‡å¹…åº¦è¾¾21.94%ã€‚</li>
<li>Captain Agentèƒ½æå‡è¾ƒå¼±LLMçš„å¯¹è¯è´¨é‡å¹¶å®ç°å…·æœ‰ç«äº‰åŠ›çš„æ€§èƒ½ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2405.19425">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-3de82161d67aeb20a744e490e5639f7c.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-229c866ac2e1f9a87ec4e49bf25bed38.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d1f4ad33d00a947dc2f30173d542df6c.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-c99decc9aec60cf88393b18ff29eddd6.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-55b7c981adbe18183059d98bd2e2b9fe.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-5fe778e8e81c6b9da5c1f9e6d28e2a48.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-7b362957d3306081f4278f8609f03b5f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-dbbf23c29c3c13665fb3af8562470af1.jpg" align="middle">
</details>


<h1 id="-14"><a href="#-14" class="headerlink" title=""></a></h1><h2 id="SheetAgent-Towards-A-Generalist-Agent-for-Spreadsheet-Reasoning-and-Manipulation-via-Large-Language-Models"><a href="#SheetAgent-Towards-A-Generalist-Agent-for-Spreadsheet-Reasoning-and-Manipulation-via-Large-Language-Models" class="headerlink" title="SheetAgent: Towards A Generalist Agent for Spreadsheet Reasoning and   Manipulation via Large Language Models"></a>SheetAgent: Towards A Generalist Agent for Spreadsheet Reasoning and   Manipulation via Large Language Models</h2><p><strong>Authors:Yibin Chen, Yifu Yuan, Zeyu Zhang, Yan Zheng, Jinyi Liu, Fei Ni, Jianye Hao, Hangyu Mao, Fuzheng Zhang</strong></p>
<p>Spreadsheets are ubiquitous across the World Wide Web, playing a critical role in enhancing work efficiency across various domains. Large language model (LLM) has been recently attempted for automatic spreadsheet manipulation but has not yet been investigated in complicated and realistic tasks where reasoning challenges exist (e.g., long horizon manipulation with multi-step reasoning and ambiguous requirements). To bridge the gap with the real-world requirements, we introduce SheetRM, a benchmark featuring long-horizon and multi-category tasks with reasoning-dependent manipulation caused by real-life challenges. To mitigate the above challenges, we further propose SheetAgent, a novel autonomous agent that utilizes the power of LLMs. SheetAgent consists of three collaborative modules: Planner, Informer, and Retriever, achieving both advanced reasoning and accurate manipulation over spreadsheets without human interaction through iterative task reasoning and reflection. Extensive experiments demonstrate that SheetAgent delivers 20â€“40% pass rate improvements on multiple benchmarks over baselines, achieving enhanced precision in spreadsheet manipulation and demonstrating superior table reasoning abilities. More details and visualizations are available at the project website: <a target="_blank" rel="noopener" href="https://sheetagent.github.io/">https://sheetagent.github.io/</a>. The datasets and source code are available at <a target="_blank" rel="noopener" href="https://anonymous.4open.science/r/SheetAgent">https://anonymous.4open.science/r/SheetAgent</a>. </p>
<blockquote>
<p>ç½‘é¡µè¡¨æ ¼ï¼ˆSpreadsheetsï¼‰åœ¨ä¸‡ç»´ç½‘ä¸Šæ— å¤„ä¸åœ¨ï¼Œå¯¹äºæé«˜ä¸åŒé¢†åŸŸçš„å·¥ä½œæ•ˆç‡èµ·ç€è‡³å…³é‡è¦çš„ä½œç”¨ã€‚å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æœ€è¿‘å·²è¢«å°è¯•ç”¨äºè‡ªåŠ¨æ“ä½œè¡¨æ ¼æ•°æ®ï¼Œä½†åœ¨å­˜åœ¨æ¨ç†æŒ‘æˆ˜çš„å¤æ‚å’ŒçœŸå®ä»»åŠ¡ä¸­å°šæœªè¿›è¡Œç ”ç©¶ï¼ˆä¾‹å¦‚ï¼Œå…·æœ‰å¤šæ­¥éª¤æ¨ç†å’Œæ¨¡ç³Šè¦æ±‚çš„é•¿æœŸæ“ä½œï¼‰ã€‚ä¸ºäº†å¼¥è¡¥ç°å®ä¸–ç•Œéœ€æ±‚ä¹‹é—´çš„å·®è·ï¼Œæˆ‘ä»¬å¼•å…¥äº†SheetRMï¼Œè¿™æ˜¯ä¸€ä¸ªä»¥é•¿æœŸå’Œå¤šç±»åˆ«ä»»åŠ¡ä¸ºç‰¹è‰²çš„åŸºå‡†æµ‹è¯•å¹³å°ï¼ŒåŒ…å«ç”±ç°å®æŒ‘æˆ˜å¯¼è‡´çš„ä¾èµ–äºæ¨ç†çš„æ“ä½œã€‚ä¸ºäº†ç¼“è§£ä¸Šè¿°æŒ‘æˆ˜ï¼Œæˆ‘ä»¬è¿›ä¸€æ­¥æå‡ºäº†SheetAgentï¼Œè¿™æ˜¯ä¸€ç§åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹èƒ½åŠ›çš„æ–°å‹è‡ªä¸»ä»£ç†ã€‚SheetAgentç”±ä¸‰ä¸ªåä½œæ¨¡å—ç»„æˆï¼šè§„åˆ’å™¨ï¼ˆPlannerï¼‰ã€ä¿¡æ¯æä¾›è€…ï¼ˆInformerï¼‰å’Œæ£€ç´¢å™¨ï¼ˆRetrieverï¼‰ï¼Œé€šè¿‡è¿­ä»£ä»»åŠ¡æ¨ç†å’Œåæ€ï¼Œæ— éœ€äººå·¥äº¤äº’å³å¯å®ç°é«˜çº§æ¨ç†å’Œå‡†ç¡®çš„è¡¨æ ¼æ“ä½œã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼Œä¸åŸºå‡†æµ‹è¯•ç›¸æ¯”ï¼ŒSheetAgentåœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•å¹³å°ä¸Šå®ç°äº†20%~40%é€šè¿‡ç‡æå‡ï¼Œæé«˜äº†è¡¨æ ¼æ“ä½œçš„ç²¾åº¦å¹¶å±•ç¤ºäº†å‡ºè‰²çš„è¡¨æ ¼æ¨ç†èƒ½åŠ›ã€‚æ›´å¤šè¯¦ç»†ä¿¡æ¯å’Œå¯è§†åŒ–å†…å®¹è¯·è®¿é—®é¡¹ç›®ç½‘ç«™ï¼š<a target="_blank" rel="noopener" href="https://sheetagent.github.io/%E3%80%82%E6%95%B0%E6%8D%AE%E9%9B%86%E5%92%8C%E6%BA%90%E4%BB%A3%E7%A0%81%E5%8F%AF%E5%9C%A8https://anonymous.4open.science/r/SheetAgent%E6%89%BE%E5%88%B0%E3%80%82">https://sheetagent.github.io/ã€‚æ•°æ®é›†å’Œæºä»£ç å¯åœ¨https://anonymous.4open.science/r/SheetAgentæ‰¾åˆ°ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2403.03636v3">PDF</a> Accepted by International World Wide Web Conference (WWW) 2025 (oral)</p>
<p><strong>Summary</strong><br>è¿™ä»½æ‘˜è¦ä»¥ç®€åŒ–ä¸­æ–‡ç®€æ´åœ°è¡¨è¾¾äº†æ–‡ç« çš„æ ¸å¿ƒå†…å®¹ï¼šä»‹ç»äº†ä¸€ç§åä¸ºSheetAgentçš„æ–°å‹è‡ªä¸»ä»£ç†ï¼Œå®ƒç»“åˆäº†å¤§å‹è¯­è¨€æ¨¡å‹çš„åŠ›é‡ï¼Œç”¨äºå¤„ç†ç°å®ä¸–ç•Œä¸­çš„å¤æ‚ç”µå­è¡¨æ ¼æ“ä½œä»»åŠ¡ã€‚é€šè¿‡å¼•å…¥ä¸‰ä¸ªåä½œæ¨¡å—ï¼šPlannerã€Informerå’ŒRetrieverï¼ŒSheetAgentå¯å®ç°å…ˆè¿›çš„æ¨ç†å’Œç”µå­è¡¨æ ¼ç²¾å‡†æ“ä½œï¼Œæ— éœ€äººä¸ºå¹²é¢„ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼ŒSheetAgentåœ¨å¤šé¡¹åŸºå‡†æµ‹è¯•ä¸­è¾ƒåŸºå‡†æ¨¡å‹æé«˜äº†20%~40%çš„é€šè¿‡ç‡ï¼Œå±•ç°äº†å‡ºè‰²çš„è¡¨æ ¼æ¨ç†èƒ½åŠ›ã€‚æ›´å¤šè¯¦æƒ…å’Œå¯è§†åŒ–å†…å®¹å¯è®¿é—®é¡¹ç›®ç½‘ç«™ã€‚æ•°æ®é›†å’Œæºä»£ç å¯ä¾›ä¸‹è½½ã€‚</p>
<p><strong>Key Takeaways</strong><br>ä»¥ä¸‹æ˜¯æ–‡ç« çš„ä¸»è¦è§è§£ï¼š</p>
<ul>
<li>ç”µå­è¡¨æ ¼åœ¨ä¸–ç•Œå„åœ°å¹¿æ³›ä½¿ç”¨ï¼Œç”¨äºæé«˜ä¸åŒé¢†åŸŸçš„å·¥ä½œæ•ˆç‡ã€‚å¤§å‹è¯­è¨€æ¨¡å‹å·²ç»åœ¨è‡ªåŠ¨ç”µå­è¡¨æ ¼æ“çºµä¸­å¾—åˆ°åº”ç”¨ã€‚</li>
<li>å­˜åœ¨ç”µå­è¡¨æ ¼æ“ä½œçš„ç°å®æŒ‘æˆ˜ï¼Œä¾‹å¦‚é•¿æ—¶è§†å›¾çš„æ“çºµå’Œå¤šæ­¥éª¤æ¨ç†ç­‰ã€‚å› æ­¤ç›®å‰æœ‰å¿…è¦æ„å»ºæ›´ç¬¦åˆå®é™…æƒ…å†µçš„æµ‹è¯•æ ‡å‡†ã€‚</li>
<li>ä¸ºäº†è§£å†³è¿™äº›æŒ‘æˆ˜ï¼Œå¼•å…¥äº†SheetRMåŸºå‡†æµ‹è¯•æ ‡å‡†ï¼Œè¯¥æ ‡å‡†åŒ…å«é•¿æ—¶è§†å›¾å’Œå¤šç§ç±»åˆ«çš„ä»»åŠ¡ï¼Œå¹¶æ¶‰åŠç”±ç°å®æŒ‘æˆ˜å¼•èµ·çš„æ¨ç†ä¾èµ–æ“çºµã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2403.03636">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-9a09809ad2d4da54fcaae23926e57683.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-dd90d4ab0a308679f0d6b1ef00d33340.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-34618186749ef95dbfcbfbcb4055d924.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d2f9e7b050662f9bed2b2f44cfeb7ea5.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-314f257c960de57a4cb2edac9004cfed.jpg" align="middle">
</details>


<h1 id="-15"><a href="#-15" class="headerlink" title=""></a></h1><h2 id="A-Survey-on-Large-Language-Model-based-Autonomous-Agents"><a href="#A-Survey-on-Large-Language-Model-based-Autonomous-Agents" class="headerlink" title="A Survey on Large Language Model based Autonomous Agents"></a>A Survey on Large Language Model based Autonomous Agents</h2><p><strong>Authors:Lei Wang, Chen Ma, Xueyang Feng, Zeyu Zhang, Hao Yang, Jingsen Zhang, Zhiyuan Chen, Jiakai Tang, Xu Chen, Yankai Lin, Wayne Xin Zhao, Zhewei Wei, Ji-Rong Wen</strong></p>
<p>Autonomous agents have long been a prominent research focus in both academic and industry communities. Previous research in this field often focuses on training agents with limited knowledge within isolated environments, which diverges significantly from human learning processes, and thus makes the agents hard to achieve human-like decisions. Recently, through the acquisition of vast amounts of web knowledge, large language models (LLMs) have demonstrated remarkable potential in achieving human-level intelligence. This has sparked an upsurge in studies investigating LLM-based autonomous agents. In this paper, we present a comprehensive survey of these studies, delivering a systematic review of the field of LLM-based autonomous agents from a holistic perspective. More specifically, we first discuss the construction of LLM-based autonomous agents, for which we propose a unified framework that encompasses a majority of the previous work. Then, we present a comprehensive overview of the diverse applications of LLM-based autonomous agents in the fields of social science, natural science, and engineering. Finally, we delve into the evaluation strategies commonly used for LLM-based autonomous agents. Based on the previous studies, we also present several challenges and future directions in this field. To keep track of this field and continuously update our survey, we maintain a repository of relevant references at <a target="_blank" rel="noopener" href="https://github.com/Paitesanshi/LLM-Agent-Survey">https://github.com/Paitesanshi/LLM-Agent-Survey</a>. </p>
<blockquote>
<p>è‡ªä¸»å­¦ä¹ ä»£ç†é•¿æœŸä»¥æ¥ä¸€ç›´æ˜¯å­¦æœ¯ç•Œå’Œå·¥ä¸šç•Œç¤¾åŒºçš„é‡è¦ç ”ç©¶ç„¦ç‚¹ã€‚ä»¥å¾€è¯¥é¢†åŸŸçš„ç ”ç©¶ç»å¸¸å…³æ³¨åœ¨éš”ç¦»ç¯å¢ƒä¸­è®­ç»ƒå…·æœ‰æœ‰é™çŸ¥è¯†çš„ä»£ç†ï¼Œè¿™ä¸äººç±»å­¦ä¹ è¿‡ç¨‹æœ‰å¾ˆå¤§çš„å·®å¼‚ï¼Œå› æ­¤ä½¿å¾—ä»£ç†éš¾ä»¥å®ç°äººç±»èˆ¬çš„å†³ç­–ã€‚æœ€è¿‘ï¼Œé€šè¿‡è·å–å¤§é‡çš„ç½‘ç»œçŸ¥è¯†ï¼Œå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨å®ç°äººç±»æ°´å¹³æ™ºèƒ½æ–¹é¢å±•ç°å‡ºäº†æ˜¾è‘—æ½œåŠ›ã€‚è¿™å¼•å‘äº†ä¸€è‚¡ç ”ç©¶LLMè‡ªä¸»ä»£ç†çš„çƒ­æ½®ã€‚åœ¨è¿™ç¯‡è®ºæ–‡ä¸­ï¼Œæˆ‘ä»¬å¯¹è¿™äº›ç ”ç©¶è¿›è¡Œäº†å…¨é¢çš„ç»¼è¿°ï¼Œä»å…¨é¢çš„è§’åº¦å¯¹åŸºäºLLMçš„è‡ªä¸»ä»£ç†é¢†åŸŸè¿›è¡Œäº†ç³»ç»Ÿçš„å›é¡¾ã€‚æ›´å…·ä½“åœ°è¯´ï¼Œæˆ‘ä»¬é¦–å…ˆè®¨è®ºäº†åŸºäºLLMçš„è‡ªä¸»ä»£ç†çš„æ„å»ºï¼Œä¸ºæ­¤æˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªç»Ÿä¸€çš„æ¡†æ¶ï¼Œæ¶µç›–äº†å¤§å¤šæ•°ä¹‹å‰çš„å·¥ä½œã€‚ç„¶åï¼Œæˆ‘ä»¬å…¨é¢æ¦‚è¿°äº†åŸºäºLLMçš„è‡ªä¸»ä»£ç†åœ¨ç¤¾ä¼šç§‘å­¦ã€è‡ªç„¶ç§‘å­¦å’Œå·¥ç¨‹é¢†åŸŸçš„å„ç§åº”ç”¨ã€‚æœ€åï¼Œæˆ‘ä»¬æ·±å…¥æ¢è®¨äº†è¯„ä¼°åŸºäºLLMçš„è‡ªä¸»ä»£ç†é€šå¸¸ä½¿ç”¨çš„è¯„ä¼°ç­–ç•¥ã€‚åŸºäºä»¥å¾€çš„ç ”ç©¶ï¼Œæˆ‘ä»¬è¿˜æå‡ºäº†è¯¥é¢†åŸŸçš„å‡ ä¸ªæŒ‘æˆ˜å’Œæœªæ¥å‘å±•æ–¹å‘ã€‚ä¸ºäº†è·Ÿè¸ªè¯¥é¢†åŸŸå¹¶ä¸æ–­æ›´æ–°æˆ‘ä»¬çš„è°ƒæŸ¥ï¼Œæˆ‘ä»¬åœ¨<a target="_blank" rel="noopener" href="https://github.com/Paitesanshi/LLM-Agent-Survey%E7%BB%B4%E6%8A%A4%E4%BA%86%E7%9B%B8%E5%85%B3%E5%8F%82%E8%80%83%E6%96%87%E7%8C%AE%E7%9A%84%E4%BB%93%E5%BA%93%E3%80%82">https://github.com/Paitesanshi/LLM-Agent-Surveyç»´æŠ¤äº†ç›¸å…³å‚è€ƒæ–‡çŒ®çš„ä»“åº“ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11432v7">PDF</a> Correcting several typos, 35 pages, 5 figures, 3 tables</p>
<p><strong>Summary</strong></p>
<p>åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹çš„è‡ªä¸»æ™ºèƒ½ä½“ç ”ç©¶ç»¼è¿°ã€‚æ–‡ç« ä»‹ç»äº†è‡ªä¸»æ™ºèƒ½ä½“çš„ç ”ç©¶èƒŒæ™¯ï¼Œæå‡ºä¸€ä¸ªç»Ÿä¸€çš„æ¡†æ¶æ¶µç›–å‰æœŸå·¥ä½œï¼Œæ¦‚è¿°æ™ºèƒ½ä½“åœ¨ç¤¾ä¼šç§‘å­¦ã€è‡ªç„¶ç§‘å­¦å’Œå·¥ç¨‹é¢†åŸŸçš„åº”ç”¨ï¼Œå¹¶æ¢è®¨æ™ºèƒ½ä½“çš„è¯„ä¼°ç­–ç•¥ï¼Œæœ€åæå‡ºè¯¥é¢†åŸŸçš„æŒ‘æˆ˜å’Œæœªæ¥å‘å±•æ–¹å‘ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤§å‹è¯­è¨€æ¨¡å‹ä¸ºè‡ªä¸»æ™ºèƒ½ä½“ç ”ç©¶å¸¦æ¥æ˜¾è‘—è¿›å±•ï¼Œæ¨åŠ¨è‡ªä¸»æ™ºèƒ½ä½“é¢†åŸŸçš„ç ”ç©¶çƒ­æ½®ã€‚</li>
<li>æ–‡ç« æå‡ºäº†ä¸€ä¸ªæ¶µç›–å¤§éƒ¨åˆ†å‰æœŸå·¥ä½œçš„ç»Ÿä¸€æ¡†æ¶ï¼Œç”¨äºæ„å»ºåŸºäºå¤§å‹è¯­è¨€æ¨¡å‹çš„è‡ªä¸»æ™ºèƒ½ä½“ã€‚</li>
<li>åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹çš„è‡ªä¸»æ™ºèƒ½ä½“åœ¨ç¤¾ä¼šç§‘å­¦ã€è‡ªç„¶ç§‘å­¦å’Œå·¥ç¨‹é¢†åŸŸæœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ã€‚</li>
<li>æ–‡ç« ä»‹ç»äº†ç”¨äºè¯„ä¼°è‡ªä¸»æ™ºèƒ½ä½“çš„å¸¸è§ç­–ç•¥ã€‚</li>
<li>å½“å‰è‡ªä¸»æ™ºèƒ½ä½“ç ”ç©¶é¢ä¸´ä¸€äº›æŒ‘æˆ˜ï¼Œå¦‚å®ç°æ›´äººæ€§åŒ–çš„å†³ç­–ã€æé«˜é²æ£’æ€§å’Œå¯è§£é‡Šæ€§ç­‰ã€‚</li>
<li>ä¸ºæŒç»­è·Ÿè¸ªå’Œæ›´æ–°ç›¸å…³ç ”ç©¶ï¼Œæ–‡ç« æä¾›äº†ä¸€ä¸ªç›¸å…³å‚è€ƒæ–‡çŒ®çš„ä»“åº“ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2308.11432">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-5d3723098ca511182117cfdcd4886dfd.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-6439629fc666bbee75cf5bcca3eb3e67.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e5dc98dc46bca049e47b6cce2f1b0b2d.jpg" align="middle">
</details>


<h1 id="-16"><a href="#-16" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-03-05/Agent/">https://kedreamix.github.io/Talk2Paper/Paper/2025-03-05/Agent/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/Agent/">
                                    <span class="chip bg-color">Agent</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-03-05/Few-Shot/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-359b7d32c8d2e3115557c0e7d2f42cbd.jpg" class="responsive-img" alt="Few-Shot">
                        
                        <span class="card-title">Few-Shot</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Few-Shot æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-03-05  Learning to Learn Weight Generation via Trajectory Diffusion
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-03-05
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Few-Shot/" class="post-category">
                                    Few-Shot
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Few-Shot/">
                        <span class="chip bg-color">Few-Shot</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-03-05/LLM/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-1807107d98319b98694e460d22bd098d.jpg" class="responsive-img" alt="LLM">
                        
                        <span class="card-title">LLM</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            LLM æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-03-05  ECLeKTic a Novel Challenge Set for Evaluation of Cross-Lingual   Knowledge Transfer
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-03-05
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/LLM/" class="post-category">
                                    LLM
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/LLM/">
                        <span class="chip bg-color">LLM</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">28051.5k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
