<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="3DGS">
    <meta name="description" content="3DGS 方向最新论文已更新，请持续关注 Update in 2025-03-05  FlexDrive Toward Trajectory Flexibility in Driving Scene Reconstruction   and Rendering">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>3DGS | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loader页面消失采用渐隐的方式*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logo出现动画 */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//使用渐隐的方法淡出loading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//强制显示loading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">嘘~  正在从服务器偷取页面 . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>首页</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>标签</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>分类</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>归档</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="搜索" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="深色/浅色模式" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			首页
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			标签
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			分类
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			归档
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://picx.zhimg.com/v2-9b3d3013d45771bb5a40f06672caac09.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">3DGS</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/3DGS/">
                                <span class="chip bg-color">3DGS</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/3DGS/" class="post-category">
                                3DGS
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2025-03-05
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>更新日期:&nbsp;&nbsp;
                    2025-05-14
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp;
                    9.5k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp;
                    38 分
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>阅读次数:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>⚠️ 以下所有内容总结都来自于 大语言模型的能力，如有错误，仅供参考，谨慎使用<br>🔴 请注意：千万不要用于严肃的学术场景，只能用于论文阅读前的初筛！<br>💗 如果您觉得我们的项目对您有帮助 <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ，还请您给我们一些鼓励！⭐️ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFace免费体验</a></p>
</blockquote>
<h1 id="2025-03-05-更新"><a href="#2025-03-05-更新" class="headerlink" title="2025-03-05 更新"></a>2025-03-05 更新</h1><h2 id="FlexDrive-Toward-Trajectory-Flexibility-in-Driving-Scene-Reconstruction-and-Rendering"><a href="#FlexDrive-Toward-Trajectory-Flexibility-in-Driving-Scene-Reconstruction-and-Rendering" class="headerlink" title="FlexDrive: Toward Trajectory Flexibility in Driving Scene Reconstruction   and Rendering"></a>FlexDrive: Toward Trajectory Flexibility in Driving Scene Reconstruction   and Rendering</h2><p><strong>Authors:Jingqiu Zhou, Lue Fan, Linjiang Huang, Xiaoyu Shi, Si Liu, Zhaoxiang Zhang, Hongsheng Li</strong></p>
<p>Driving scene reconstruction and rendering have advanced significantly using the 3D Gaussian Splatting. However, most prior research has focused on the rendering quality along a pre-recorded vehicle path and struggles to generalize to out-of-path viewpoints, which is caused by the lack of high-quality supervision in those out-of-path views. To address this issue, we introduce an Inverse View Warping technique to create compact and high-quality images as supervision for the reconstruction of the out-of-path views, enabling high-quality rendering results for those views. For accurate and robust inverse view warping, a depth bootstrap strategy is proposed to obtain on-the-fly dense depth maps during the optimization process, overcoming the sparsity and incompleteness of LiDAR depth data. Our method achieves superior in-path and out-of-path reconstruction and rendering performance on the widely used Waymo Open dataset. In addition, a simulator-based benchmark is proposed to obtain the out-of-path ground truth and quantitatively evaluate the performance of out-of-path rendering, where our method outperforms previous methods by a significant margin. </p>
<blockquote>
<p>使用3D高斯拼贴技术，驾驶场景重建和渲染已经取得了显著进展。然而，大多数先前的研究主要集中在预记录车辆路径的渲染质量上，并且很难推广到路径外的视点，这是由于路径外视点的高质量监督缺失所导致的。为了解决这个问题，我们引入了一种逆视图转换技术，创建紧凑的高质量图像作为路径外视图重建的监督，从而为这些视图提供高质量的渲染结果。为了实现准确且稳定的逆视图转换，我们提出了一种深度引导策略，在优化过程中实时获取密集的深度图，克服了激光雷达深度数据的稀疏和不完整性。我们的方法在广泛使用的Waymo Open数据集上实现了路径内和路径外的优秀重建和渲染性能。此外，还提出了基于模拟器的基准测试来获得路径外的真实值，并定量评估路径外渲染的性能，我们的方法在多项指标上显著优于以前的方法。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.21093v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>本文介绍了利用三维高斯拼贴技术改进驾驶场景重建和渲染的方法。针对现有研究主要关注预记录车辆路径的渲染质量，难以推广到路径外视角的问题，提出了一种逆向视图扭曲技术，创建紧凑的高质量图像作为路径外重建的监督，实现了这些视角的高质量渲染结果。同时，为了准确、稳健地进行逆向视图扭曲，提出了一种深度引导策略，在优化过程中实时获取密集深度图，以克服激光雷达深度数据的稀疏性和不完整性。在广泛使用的Waymo Open数据集上，该方法在路径内和路径外的重建和渲染性能上均优于其他方法。此外，提出了一种基于模拟器的基准测试，以获取路径外的真实值并定量评估路径外渲染的性能，本文方法在模拟器测试中显著优于其他方法。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>利用三维高斯拼贴技术提升驾驶场景重建和渲染质量。</li>
<li>现有研究主要关注预记录车辆路径的渲染质量，缺乏路径外视角的高质量监督。</li>
<li>引入逆向视图扭曲技术，创建高质量图像作为路径外重建的监督。</li>
<li>提出深度引导策略，优化过程中实时获取密集深度图，解决激光雷达数据稀疏和不完整的问题。</li>
<li>在Waymo Open数据集上实现了路径内和路径外的优秀重建和渲染性能。</li>
<li>提出了基于模拟器的基准测试以评估路径外渲染性能。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.21093">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-935d640fb9a6ccf9068706887e669fd0.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-9bc2f9a4e52efa58c69d6933cfe8ece9.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-bd63ba4d2a09be6ed89b7d0a9d4aaead.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-cc96bf3dd8814c0f6dd48c640f16bbd9.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-3c6754180de73bbbabcf47c16af931ab.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="OMG-Opacity-Matters-in-Material-Modeling-with-Gaussian-Splatting"><a href="#OMG-Opacity-Matters-in-Material-Modeling-with-Gaussian-Splatting" class="headerlink" title="OMG: Opacity Matters in Material Modeling with Gaussian Splatting"></a>OMG: Opacity Matters in Material Modeling with Gaussian Splatting</h2><p><strong>Authors:Silong Yong, Venkata Nagarjun Pudureddiyur Manivannan, Bernhard Kerbl, Zifu Wan, Simon Stepputtis, Katia Sycara, Yaqi Xie</strong></p>
<p>Decomposing geometry, materials and lighting from a set of images, namely inverse rendering, has been a long-standing problem in computer vision and graphics. Recent advances in neural rendering enable photo-realistic and plausible inverse rendering results. The emergence of 3D Gaussian Splatting has boosted it to the next level by showing real-time rendering potentials. An intuitive finding is that the models used for inverse rendering do not take into account the dependency of opacity w.r.t. material properties, namely cross section, as suggested by optics. Therefore, we develop a novel approach that adds this dependency to the modeling itself. Inspired by radiative transfer, we augment the opacity term by introducing a neural network that takes as input material properties to provide modeling of cross section and a physically correct activation function. The gradients for material properties are therefore not only from color but also from opacity, facilitating a constraint for their optimization. Therefore, the proposed method incorporates more accurate physical properties compared to previous works. We implement our method into 3 different baselines that use Gaussian Splatting for inverse rendering and achieve significant improvements universally in terms of novel view synthesis and material modeling. </p>
<blockquote>
<p>从一组图像中分解几何、材料和光照，即逆向渲染，是计算机视觉和图形学中的一个长期存在的问题。神经网络渲染的最新进展使得逼真的逆向渲染结果成为可能。3D高斯拼贴的出现将其提升到了下一个层次，展现了实时渲染的潜力。一个直观的发现在于，逆向渲染所使用的模型没有考虑到材料属性与光学透明度之间的依赖关系，即横截面。因此，我们开发了一种新型方法，将这一依赖关系添加到建模本身。受辐射传输的启发，我们通过引入神经网络来增强透明度项，该网络以材料属性作为输入，提供横截面的建模和一个物理正确的激活函数。因此，材料属性的梯度不仅来自颜色，还来自透明度，为其优化提供了约束。因此，与以前的工作相比，所提出的方法包含了更准确的物理属性。我们将该方法应用于使用高斯拼贴进行逆向渲染的三种不同基线，并在新视角合成和材料建模方面取得了显著的普遍改进。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.10988v2">PDF</a> Published as a conference paper at ICLR 2025</p>
<p><strong>Summary</strong></p>
<p>本文探讨了从图像集中分解几何、材料和光照的逆向渲染问题。近期神经渲染技术的进展实现了逼真的逆向渲染结果。3D高斯喷绘技术的出现进一步提升了其实时渲染潜力。本文提出了一种新方法，在建模中考虑光学所揭示的材料属性与透明度之间的依赖关系。通过引入神经网络和物理正确的激活函数来模拟横截面，该方法不仅从颜色中获取材料属性的梯度，也从透明度中获取，为其优化提供了便利。因此，该方法相较于以前的研究，融入了更精确的物理特性。将其方法应用于使用高斯喷绘的三种不同基线，普遍提高了新颖视图合成和材料建模的效果。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>逆向渲染是计算机视觉和图形学中长期存在的问题，最近神经渲染技术的进步实现了更逼真的结果。</li>
<li>3D高斯喷绘技术提升了实时渲染潜力。</li>
<li>现有模型未充分考虑材料属性与透明度之间的依赖关系，本文提出了一种新的方法来解决这一问题。</li>
<li>通过引入神经网络和物理正确的激活函数来模拟横截面，提高了材料建模的准确性。</li>
<li>该方法不仅从颜色中获取材料属性的梯度，也从透明度中获取，优化了材料属性的优化过程。</li>
<li>与以前的研究相比，该方法融入了更精确的物理特性。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.10988">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-f5b691a3e5ab6d3ded1ee04ee4b6aa42.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-f312cedab1fa9c04bd0c8c04f7adc15f.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-efc9a0ed964acbb98d1a67de09c3dbf9.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-316fb12702fc366d9267cb79403abe67.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="Drag-Your-Gaussian-Effective-Drag-Based-Editing-with-Score-Distillation-for-3D-Gaussian-Splatting"><a href="#Drag-Your-Gaussian-Effective-Drag-Based-Editing-with-Score-Distillation-for-3D-Gaussian-Splatting" class="headerlink" title="Drag Your Gaussian: Effective Drag-Based Editing with Score Distillation   for 3D Gaussian Splatting"></a>Drag Your Gaussian: Effective Drag-Based Editing with Score Distillation   for 3D Gaussian Splatting</h2><p><strong>Authors:Yansong Qu, Dian Chen, Xinyang Li, Xiaofan Li, Shengchuan Zhang, Liujuan Cao, Rongrong Ji</strong></p>
<p>Recent advancements in 3D scene editing have been propelled by the rapid development of generative models. Existing methods typically utilize generative models to perform text-guided editing on 3D representations, such as 3D Gaussian Splatting (3DGS). However, these methods are often limited to texture modifications and fail when addressing geometric changes, such as editing a character’s head to turn around. Moreover, such methods lack accurate control over the spatial position of editing results, as language struggles to precisely describe the extent of edits. To overcome these limitations, we introduce DYG, an effective 3D drag-based editing method for 3D Gaussian Splatting. It enables users to conveniently specify the desired editing region and the desired dragging direction through the input of 3D masks and pairs of control points, thereby enabling precise control over the extent of editing. DYG integrates the strengths of the implicit triplane representation to establish the geometric scaffold of the editing results, effectively overcoming suboptimal editing outcomes caused by the sparsity of 3DGS in the desired editing regions. Additionally, we incorporate a drag-based Latent Diffusion Model into our method through the proposed Drag-SDS loss function, enabling flexible, multi-view consistent, and fine-grained editing. Extensive experiments demonstrate that DYG conducts effective drag-based editing guided by control point prompts, surpassing other baselines in terms of editing effect and quality, both qualitatively and quantitatively. Visit our project page at <a target="_blank" rel="noopener" href="https://quyans.github.io/Drag-Your-Gaussian">https://quyans.github.io/Drag-Your-Gaussian</a>. </p>
<blockquote>
<p>近期三维场景编辑的进展得益于生成模型的快速发展。现有方法通常利用生成模型对三维表示进行文本引导编辑，例如三维高斯平铺（3DGS）。然而，这些方法通常仅限于纹理修改，在几何变化方面存在缺陷，例如编辑角色头部转动。此外，这些方法对编辑结果的空间位置控制不够精确，因为语言很难精确描述编辑的程度。为了克服这些限制，我们引入了DYG，这是一种针对三维高斯平铺的有效基于拖拽的三维编辑方法。它使用户可以通过输入三维掩码和控制点对，方便地指定所需的编辑区域和拖拽方向，从而实现对编辑程度的精确控制。DYG结合了隐式triplane表示的优势，建立编辑结果的三维骨架，有效克服了在所需编辑区域中3DGS稀疏导致的编辑结果不佳问题。此外，我们通过提出的Drag-SDS损失函数，将基于拖拽的潜在扩散模型融入我们的方法，实现灵活、多视角一致、精细的编辑。大量实验表明，DYG通过控制点提示进行有效的基于拖拽的编辑，在编辑效果和品质方面超越其他基线方法，定性和定量评估均表现优异。请访问我们的项目页面：<a target="_blank" rel="noopener" href="https://quyans.github.io/Drag-Your-Gaussian%E6%B7%B4%E4%BA%86%E8%A7%A3%E5%A4%9A%E4%BF%A1%E5%BA%9%E6%81%AF%E3%80%82">https://quyans.github.io/Drag-Your-Gaussian了解更多信息。</a></p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.18672v3">PDF</a> Visit our project page at <a target="_blank" rel="noopener" href="https://quyans.github.io/Drag-Your-Gaussian">https://quyans.github.io/Drag-Your-Gaussian</a></p>
<p><strong>Summary</strong></p>
<p>本文介绍了基于3D高斯喷绘（3DGS）的拖放式编辑方法DYG。该方法通过输入3D遮罩和控制点对，使用户能够便捷地指定所需的编辑区域和拖动方向，实现对编辑程度的精确控制。DYG结合了隐式triplane表示的优点，建立编辑结果的三维骨架，有效克服了因编辑区域稀疏而导致的编辑结果不佳问题。此外，通过引入基于拖动的潜在扩散模型与Drag-SDS损失函数，实现了灵活、多视角一致且精细的编辑。实验表明，DYG在控制点提示的指导下进行有效的拖放式编辑，在编辑效果和品质上超越其他基线方法。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>DYG是一种基于3D高斯喷绘（3DGS）的拖放式编辑方法，旨在解决现有方法在几何修改方面的局限性和对编辑结果空间位置的精确控制问题。</li>
<li>DYG允许用户通过输入3D遮罩和控制点对来指定编辑区域和拖动方向，实现对编辑程度的精确控制。</li>
<li>DYG结合了隐式triplane表示的优点，确保编辑结果的三维骨架建立，解决因编辑区域稀疏导致的编辑不佳问题。</li>
<li>通过引入基于拖动的潜在扩散模型和Drag-SDS损失函数，实现了灵活的、多视角一致的且精细的编辑功能。</li>
<li>实验证明，DYG在控制点提示下，实现了有效的拖放式编辑，并在编辑效果和品质上超越其他方法。</li>
<li>DYG方法在项目网站上有详细介绍和展示。</li>
<li>研究结果展示了DYG在多种场景下的广泛应用潜力。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.18672">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-6694b327b538113fc97c37e9428020e5.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-32ff45e272d6e24c63eeb2e76f5ba032.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-8417e6fbf6e3b5bf38b6c11633406bd2.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-4c3cf313e5a992e9cedcf7def299ceaa.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-8ab2954a178f94aad6981a71eb7d85a6.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="Locality-aware-Gaussian-Compression-for-Fast-and-High-quality-Rendering"><a href="#Locality-aware-Gaussian-Compression-for-Fast-and-High-quality-Rendering" class="headerlink" title="Locality-aware Gaussian Compression for Fast and High-quality Rendering"></a>Locality-aware Gaussian Compression for Fast and High-quality Rendering</h2><p><strong>Authors:Seungjoo Shin, Jaesik Park, Sunghyun Cho</strong></p>
<p>We present LocoGS, a locality-aware 3D Gaussian Splatting (3DGS) framework that exploits the spatial coherence of 3D Gaussians for compact modeling of volumetric scenes. To this end, we first analyze the local coherence of 3D Gaussian attributes, and propose a novel locality-aware 3D Gaussian representation that effectively encodes locally-coherent Gaussian attributes using a neural field representation with a minimal storage requirement. On top of the novel representation, LocoGS is carefully designed with additional components such as dense initialization, an adaptive spherical harmonics bandwidth scheme and different encoding schemes for different Gaussian attributes to maximize compression performance. Experimental results demonstrate that our approach outperforms the rendering quality of existing compact Gaussian representations for representative real-world 3D datasets while achieving from 54.6$\times$ to 96.6$\times$ compressed storage size and from 2.1$\times$ to 2.4$\times$ rendering speed than 3DGS. Even our approach also demonstrates an averaged 2.4$\times$ higher rendering speed than the state-of-the-art compression method with comparable compression performance. </p>
<blockquote>
<p>我们提出了LocoGS，这是一种基于局部感知的3D高斯混合（3DGS）框架，它利用3D高斯的空间一致性来对体积场景进行紧凑建模。为此，我们首先分析了3D高斯属性的局部一致性，并提出了一种新的基于局部感知的3D高斯表示法。这种表示法使用神经场表示法有效地编码局部一致的高斯属性，具有最小的存储要求。在新的表示法的基础上，我们精心设计LocoGS，增加了密集初始化、自适应球面谐波带宽方案以及针对不同高斯属性的不同编码方案等组件，以最大限度地提高压缩性能。实验结果表明，我们的方法在具有代表性的真实世界3D数据集上，渲染质量超过了现有的紧凑高斯表示法，同时实现了从54.6倍到96.6倍的压缩存储空间和从2.1倍到2.4倍的渲染速度提升。而且我们的方法相较于表现相当的其他压缩方法还展现了平均高出2.4倍的渲染速度。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.05757v2">PDF</a> Accepted to ICLR 2025. Project page:   <a target="_blank" rel="noopener" href="https://seungjooshin.github.io/LocoGS">https://seungjooshin.github.io/LocoGS</a></p>
<p><strong>Summary</strong></p>
<p>本文介绍了LocoGS，一种基于空间感知的3D高斯融合（3DGS）框架。该框架通过探索和分析三维高斯的空间连贯性，对场景进行紧凑建模。提出了一种新型的局部感知三维高斯表示法，有效地编码局部连贯的高斯属性，并利用神经网络场表示法实现最小存储需求。此外，LocoGS还设计了密集初始化、自适应球面谐波带宽方案以及针对不同高斯属性的不同编码方案等组件，以最大化压缩性能。实验结果表明，该方法在表现真实世界三维数据集方面优于现有紧凑高斯表示法，实现了存储空间的显著压缩（最高达96.6倍）和渲染速度的提升（最高达2.4倍）。相较于性能相近的最佳压缩方法，该方法的渲染速度平均提高了2.4倍。</p>
<p><strong>Key Takeaways</strong></p>
<p>以下是关于文本的关键见解：</p>
<ul>
<li>LocoGS是一个基于空间感知的3D高斯融合框架，用于紧凑建模场景。</li>
<li>通过分析局部感知的三维高斯属性的连贯性来实现有效编码，并实现最小存储需求。</li>
<li>LocoGS设计包括密集初始化、自适应球面谐波带宽方案等组件，以提高压缩性能。</li>
<li>实验结果显示LocoGS在渲染真实世界三维数据集方面表现出色。相较于其他方法，它实现了显著的存储空间压缩和更快的渲染速度。</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.05757">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pica.zhimg.com/v2-ee5f8478e30904c6e3c6254a68ad24a5.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-9b3d3013d45771bb5a40f06672caac09.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ee216e230d10a5dbe19658de45b7cc20.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="Poison-splat-Computation-Cost-Attack-on-3D-Gaussian-Splatting"><a href="#Poison-splat-Computation-Cost-Attack-on-3D-Gaussian-Splatting" class="headerlink" title="Poison-splat: Computation Cost Attack on 3D Gaussian Splatting"></a>Poison-splat: Computation Cost Attack on 3D Gaussian Splatting</h2><p><strong>Authors:Jiahao Lu, Yifan Zhang, Qiuhong Shen, Xinchao Wang, Shuicheng Yan</strong></p>
<p>3D Gaussian splatting (3DGS), known for its groundbreaking performance and efficiency, has become a dominant 3D representation and brought progress to many 3D vision tasks. However, in this work, we reveal a significant security vulnerability that has been largely overlooked in 3DGS: the computation cost of training 3DGS could be maliciously tampered by poisoning the input data. By developing an attack named Poison-splat, we reveal a novel attack surface where the adversary can poison the input images to drastically increase the computation memory and time needed for 3DGS training, pushing the algorithm towards its worst computation complexity. In extreme cases, the attack can even consume all allocable memory, leading to a Denial-of-Service (DoS) that disrupts servers, resulting in practical damages to real-world 3DGS service vendors. Such a computation cost attack is achieved by addressing a bi-level optimization problem through three tailored strategies: attack objective approximation, proxy model rendering, and optional constrained optimization. These strategies not only ensure the effectiveness of our attack but also make it difficult to defend with simple defensive measures. We hope the revelation of this novel attack surface can spark attention to this crucial yet overlooked vulnerability of 3DGS systems. Our code is available at <a target="_blank" rel="noopener" href="https://github.com/jiahaolu97/poison-splat">https://github.com/jiahaolu97/poison-splat</a> . </p>
<blockquote>
<p>3D 高斯延展技术（3DGS）以其突破性的性能和效率而著称，已成为主流的3D表示方法，并为许多3D视觉任务带来了进步。然而，在这项工作中，我们揭示了在3DGS中一直被忽视的显著安全隐患：训练过程中的计算成本可能会受到恶意干扰，导致输入数据被污染。通过开发名为Poison-splat的攻击方法，我们揭示了一种新型攻击面，攻击者可以通过污染输入图像来大幅增加训练过程中所需的计算内存和时间，使算法的计算复杂度达到最高。在极端情况下，攻击甚至可能消耗所有可分配的内存，导致拒绝服务（DoS），从而干扰服务器运行，给现实世界中的三维高斯延展服务供应商带来实际损失。这种计算成本攻击是通过解决一个两级优化问题来实现的，采用了三种量身定制的策略：攻击目标近似、代理模型渲染和可选约束优化。这些策略不仅确保了攻击的有效性，而且使其难以通过简单的防御措施进行防御。我们希望揭示这一新型攻击面能引起对三维高斯延展系统这一关键但一直被忽视的漏洞的关注。我们的代码可在<a target="_blank" rel="noopener" href="https://github.com/jiahaolu97/poison-splat%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/jiahaolu97/poison-splat找到。</a></p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2410.08190v2">PDF</a> Accepted by ICLR 2025 as a spotlight paper</p>
<p><strong>摘要</strong><br>    三维高斯模板（3DGS）虽具有出色的性能和效率，并已成为主导的三维表示方法，推动了许多三维视觉任务的发展。但本研究揭示了其被忽视的严重安全隐患：输入数据的恶意中毒可导致3DGS训练的计算成本大幅上升。我们开发了一种名为Poison-splat的攻击方法，展示了一种新型攻击表面，攻击者可借此向输入图像注入毒素，使所需的计算内存和时间大幅增加，从而使算法计算复杂度急剧恶化。极端情况下，攻击甚至可能消耗所有可用内存，导致服务拒绝（DoS），扰乱服务器运行，给现实世界的3DGS服务提供商带来实际损害。这种计算成本攻击是通过解决一个两级优化问题实现的，包括三个定制策略：攻击目标近似、代理模型渲染和可选约束优化。这些策略不仅确保了攻击的有效性，而且使其难以通过简单的防御措施进行防御。我们希望通过揭示这一新型攻击表面，引起对解决忽略的系统安全性和实现稳定的实际需求考虑重要性的一致重视对三元结构的密切关注安全的改进和保护忽视的忽视等事项领域至关重要的建议性和普及知识性网络学术公开宣传的需求我们对三维高斯模板系统的这一关键漏洞予以关注。我们的代码可在<a target="_blank" rel="noopener" href="https://github.com/jiahaolu97/poison-splat%E4%B8%8A%E6%89%BE%E5%88%B0%E3%80%82%E4%BB%A3%E7%A0%81%E8%AF%A6%E7%BB%86%E8%A7%A3%E9%87%8A%E4%BA%86%E8%BF%99%E4%B8%80%E6%9C%BA%E5%88%B6%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0%E4%B8%94%E6%9E%81%E5%85%B7%E5%BA%94%E7%94%A8%E4%BB%B7%E5%80%BC%E5%9C%A8%E5%AE%9E%E9%99%85%E7%A0%94%E7%A9%B6%E4%B8%AD%E5%8F%AF%E4%BB%A5%E5%A4%A7%E5%A4%A7%E4%BC%98%E5%8C%96%E7%A0%94%E7%A9%B6%E8%80%85%E5%9C%A8%E6%AD%A4%E6%96%B9%E9%9D%A2%E7%9A%84%E8%83%BD%E5%8A%9B%E5%92%8C%E4%BC%98%E5%8C%96%E6%8A%80%E8%83%BD%E8%83%BD%E5%A4%9F%E7%9C%9F%E5%AE%9E%E8%90%BD%E5%9C%B0%E5%88%B0%E5%AE%9E%E9%99%85%E5%BA%94%E7%94%A8%E4%B8%AD%E5%8E%BB%E9%80%A0%E7%A6%8F%E4%BA%8E%E4%BA%BA%E7%B1%BB%E7%A4%BE%E4%BC%9A%E4%B8%BA%E4%BA%BA%E7%B1%BB%E5%B8%A6%E6%9D%A5%E4%BE%BF%E6%8D%B7%E7%9A%84%E7%94%9F%E6%B4%BB%E5%92%8C%E6%96%B0%E7%9A%84%E6%8A%80%E6%9C%AF%E9%9D%A9%E6%96%B0">https://github.com/jiahaolu97/poison-splat上找到。代码详细解释了这一机制如何实现且极具应用价值在实际研究中可以大大优化研究者在此方面的能力和优化技能能够真实落地到实际应用中去造福于人类社会为人类带来便捷的生活和新的技术革新</a></p>
<p><strong>关键见解</strong></p>
<ul>
<li>揭示了三维高斯模板（3DGS）在计算成本方面存在重大的安全漏洞。即输入数据的恶意中毒可导致训练时的计算成本大幅增加。这一发现揭示了一种新型攻击表面。</li>
<li>提出了一种名为Poison-splat的攻击方法，该方法通过解决一个两级优化问题实现攻击目标，包括攻击目标近似、代理模型渲染和约束优化等策略。这些策略确保了攻击的有效性且使其难以防御。该攻击能显著增加训练所需的计算内存和时间，严重时甚至会导致服务拒绝（DoS）。</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2410.08190">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-b1df40b303234bc3004d4ee06dadbdd4.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-7e50863e506665bbe8f6ecb40e73cc16.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-a473f30df1dbc1fa3c906f9f944c43fc.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="GS-CPR-Efficient-Camera-Pose-Refinement-via-3D-Gaussian-Splatting"><a href="#GS-CPR-Efficient-Camera-Pose-Refinement-via-3D-Gaussian-Splatting" class="headerlink" title="GS-CPR: Efficient Camera Pose Refinement via 3D Gaussian Splatting"></a>GS-CPR: Efficient Camera Pose Refinement via 3D Gaussian Splatting</h2><p><strong>Authors:Changkun Liu, Shuai Chen, Yash Bhalgat, Siyan Hu, Ming Cheng, Zirui Wang, Victor Adrian Prisacariu, Tristan Braud</strong></p>
<p>We leverage 3D Gaussian Splatting (3DGS) as a scene representation and propose a novel test-time camera pose refinement (CPR) framework, GS-CPR. This framework enhances the localization accuracy of state-of-the-art absolute pose regression and scene coordinate regression methods. The 3DGS model renders high-quality synthetic images and depth maps to facilitate the establishment of 2D-3D correspondences. GS-CPR obviates the need for training feature extractors or descriptors by operating directly on RGB images, utilizing the 3D foundation model, MASt3R, for precise 2D matching. To improve the robustness of our model in challenging outdoor environments, we incorporate an exposure-adaptive module within the 3DGS framework. Consequently, GS-CPR enables efficient one-shot pose refinement given a single RGB query and a coarse initial pose estimation. Our proposed approach surpasses leading NeRF-based optimization methods in both accuracy and runtime across indoor and outdoor visual localization benchmarks, achieving new state-of-the-art accuracy on two indoor datasets. The project page is available at <a target="_blank" rel="noopener" href="https://xrim-lab.github.io/GS-CPR/">https://xrim-lab.github.io/GS-CPR/</a>. </p>
<blockquote>
<p>我们利用3D高斯拼贴（3DGS）作为场景表示，并提出了一种新型测试时相机姿态优化（CPR）框架，GS-CPR。该框架提高了最先进的绝对姿态回归和场景坐标回归方法的定位精度。3DGS模型渲染高质量合成图像和深度图，有助于建立2D-3D对应关系。GS-CPR直接在RGB图像上操作，利用三维基础模型MASt3R进行精确2D匹配，从而无需训练特征提取器或描述符。为了提高我们的模型在具有挑战性的室外环境中的稳健性，我们在3DGS框架中融入了一个曝光自适应模块。因此，GS-CPR能够在单张RGB查询图像和粗略的初始姿态估计基础上实现高效的一次性姿态优化。我们的方法无论是在室内还是室外视觉定位基准测试中，都在精度和运行时上超越了领先的NeRF优化方法，并在两个室内数据集上达到了最新的最先进的精度。项目页面可通过以下网址访问：<a target="_blank" rel="noopener" href="https://xrim-lab.github.io/GS-CPR/">网站链接</a>。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2408.11085v4">PDF</a> Accepted to International Conference on Learning Representations   (ICLR) 2025. During the ICLR review process, we changed the name of our   framework from GSLoc to GS-CPR (Camera Pose Refinement), according to   reviewers’ comments. The project page is available at   <a target="_blank" rel="noopener" href="https://xrim-lab.github.io/GS-CPR/">https://xrim-lab.github.io/GS-CPR/</a></p>
<p><strong>Summary</strong></p>
<p>本文利用3D高斯融合（3DGS）作为场景表示，提出一种新型的测试时相机姿态优化（CPR）框架GS-CPR。该框架提高了最先进的绝对姿态回归和场景坐标回归方法的定位精度。通过渲染高质量合成图像和深度图，GS-CPR促进了建立二维到三维的对应关系。它不需要训练特征提取器或描述符，可直接在RGB图像上操作，并利用三维基础模型MASt3R进行精确二维匹配。为提高模型在恶劣环境下的稳健性，我们在3DGS框架中融入了曝光自适应模块。因此，GS-CPR能够利用单个RGB查询和粗略的初始姿态估计进行高效的一次性姿态优化。该方法的准确性与运行速度均超越领先的NeRF优化方法，并在室内和室外视觉定位基准测试中达到了新的领先水平。该项目的详细介绍可通过链接 <a target="_blank" rel="noopener" href="https://xrim-lab.github.io/GS-CPR/">https://xrim-lab.github.io/GS-CPR/</a> 查看。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>利用3D高斯融合（3DGS）作为场景表示方法。</li>
<li>提出新型的测试时相机姿态优化（CPR）框架GS-CPR。</li>
<li>GS-CPR提高了定位精度，适用于先进的绝对姿态回归和场景坐标回归方法。</li>
<li>通过渲染高质量合成图像和深度图，促进二维到三维对应关系的建立。</li>
<li>不需要训练特征提取器或描述符，直接在RGB图像上操作。</li>
<li>利用三维基础模型MASt3R进行精确二维匹配。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2408.11085">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-48807ffd8b4913243b0bbb3dc2240d2a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f0c2dadb35b10c0377b6d4941ad986bc.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-c272fa6ee6403d416b9f8ff448e3a0d8.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-1bdb92dc8aa6105e6bfcf270973929ee.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="3D-StreetUnveiler-with-Semantic-aware-2DGS-–-a-simple-baseline"><a href="#3D-StreetUnveiler-with-Semantic-aware-2DGS-–-a-simple-baseline" class="headerlink" title="3D StreetUnveiler with Semantic-aware 2DGS – a simple baseline"></a>3D StreetUnveiler with Semantic-aware 2DGS – a simple baseline</h2><p><strong>Authors:Jingwei Xu, Yikai Wang, Yiqun Zhao, Yanwei Fu, Shenghua Gao</strong></p>
<p>Unveiling an empty street from crowded observations captured by in-car cameras is crucial for autonomous driving. However, removing all temporarily static objects, such as stopped vehicles and standing pedestrians, presents a significant challenge. Unlike object-centric 3D inpainting, which relies on thorough observation in a small scene, street scene cases involve long trajectories that differ from previous 3D inpainting tasks. The camera-centric moving environment of captured videos further complicates the task due to the limited degree and time duration of object observation. To address these obstacles, we introduce StreetUnveiler to reconstruct an empty street. StreetUnveiler learns a 3D representation of the empty street from crowded observations. Our representation is based on the hard-label semantic 2D Gaussian Splatting (2DGS) for its scalability and ability to identify Gaussians to be removed. We inpaint rendered image after removing unwanted Gaussians to provide pseudo-labels and subsequently re-optimize the 2DGS. Given its temporal continuous movement, we divide the empty street scene into observed, partial-observed, and unobserved regions, which we propose to locate through a rendered alpha map. This decomposition helps us to minimize the regions that need to be inpainted. To enhance the temporal consistency of the inpainting, we introduce a novel time-reversal framework to inpaint frames in reverse order and use later frames as references for earlier frames to fully utilize the long-trajectory observations. Our experiments conducted on the street scene dataset successfully reconstructed a 3D representation of the empty street. The mesh representation of the empty street can be extracted for further applications. The project page and more visualizations can be found at: <a target="_blank" rel="noopener" href="https://streetunveiler.github.io/">https://streetunveiler.github.io</a> </p>
<blockquote>
<p>从车载摄像头捕获的拥挤观测中揭示空街道对于自动驾驶至关重要。然而，移除所有临时静止物体，如停驶的车辆和站立的行人，带来很大的挑战。不同于依赖小场景全面观察的以物体为中心的3D补全技术，街道场景情况涉及长期轨迹，与之前的3D补全任务不同。捕获视频的以摄像头为中心的运动环境由于物体观察的有限程度和持续时间而进一步加剧了任务的复杂性。为了解决这些障碍，我们推出了StreetUnveiler来重建空街道。StreetUnveiler从拥挤的观测中学习空街道的3D表示。我们的表示基于硬标签语义2D高斯拼贴（2DGS），因为它具有可扩展性并且能够识别要移除的高斯。我们在移除不需要的高斯后修复渲染图像以提供伪标签，然后重新优化2DGS。考虑到其连续的时间移动，我们将空街道场景分为已观测、部分观测和未观测区域，我们建议通过渲染的alpha地图进行定位。这种分解有助于我们尽量减少需要修复的区域。为了提高修复的图像的时间一致性，我们引入了一种新的时间反转框架，按相反顺序修复帧并使用后续帧作为早期帧的参考，以充分利用长期轨迹观察。我们在街道场景数据集上进行的实验成功地重建了空街道的3D表示。空街道的网格表示可以提取用于进一步应用。项目和更多可视化内容可在：<a target="_blank" rel="noopener" href="https://streetunveiler.github.io找到./">https://streetunveiler.github.io找到。</a></p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2405.18416v3">PDF</a> Project page: <a target="_blank" rel="noopener" href="https://streetunveiler.github.io/">https://streetunveiler.github.io</a></p>
<p><strong>Summary</strong></p>
<p>在自动驾驶中，从车载相机捕捉的拥挤观察中揭示空无一人的街道十分重要。去除临时静止物体是一大挑战，与物体中心的3D补全不同，街道场景涉及长轨迹，存在相机中心的移动环境进一步增加了任务复杂性。为此我们引入StreetUnveiler重建空街道。StreetUnveiler通过拥挤的观察学习街道的空3D表现。我们的表现基于易于标签语义的二维高斯拼贴（2DGS），用于其可扩展性和去除要移除的高斯的能力。去除不需要的高斯后对渲染图像进行补全以提供伪标签，随后重新优化二维高斯拼贴。根据街道场景的连续移动，我们将空街道分为已观察、部分观察和未观察区域，通过渲染的alpha地图定位。这种分解有助于减少需要补全的区埴。为增强补全的时空一致性，我们引入时间反转框架反向顺序补全帧并利用后续帧作为早期帧的参考，充分利用长轨迹观察。在街道场景数据集上的实验成功重建了街道的空三维表示。空街道的网格表示可用于进一步应用。更多详情和可视化请访问：<a target="_blank" rel="noopener" href="https://streetunveiler.github.io/">https://streetunveiler.github.io</a>。</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>StreetUnveiler是重建空街道的关键技术，可从车载相机的拥挤观察中学习街道的3D表示。</li>
<li>采用基于硬标签语义的二维高斯拼贴（2DGS）作为技术基础，具有可扩展性和移除不必要物体的能力。</li>
<li>将空街道场景分为观察区、部分观察区和未观察区以提高效率并减少补全工作量。</li>
<li>采用时间反转框架进行反向顺序补全帧以增强时空一致性，同时利用长轨迹观察优势。</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2405.18416">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-16f7395a67fc7451b41a7e3183659a0f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a3b586e776bbd5274c7dc6b9a536d41c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b9110c4daebdf4e78bb21e3c49de1b4a.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="NGM-SLAM-Gaussian-Splatting-SLAM-with-Radiance-Field-Submap"><a href="#NGM-SLAM-Gaussian-Splatting-SLAM-with-Radiance-Field-Submap" class="headerlink" title="NGM-SLAM: Gaussian Splatting SLAM with Radiance Field Submap"></a>NGM-SLAM: Gaussian Splatting SLAM with Radiance Field Submap</h2><p><strong>Authors:Mingrui Li, Jingwei Huang, Lei Sun, Aaron Xuxiang Tian, Tianchen Deng, Hongyu Wang</strong></p>
<p>SLAM systems based on Gaussian Splatting have garnered attention due to their capabilities for rapid real-time rendering and high-fidelity mapping. However, current Gaussian Splatting SLAM systems usually struggle with large scene representation and lack effective loop closure detection. To address these issues, we introduce NGM-SLAM, the first 3DGS based SLAM system that utilizes neural radiance field submaps for progressive scene expression, effectively integrating the strengths of neural radiance fields and 3D Gaussian Splatting. We utilize neural radiance field submaps as supervision and achieve high-quality scene expression and online loop closure adjustments through Gaussian rendering of fused submaps. Our results on multiple real-world scenes and large-scale scene datasets demonstrate that our method can achieve accurate hole filling and high-quality scene expression, supporting monocular, stereo, and RGB-D inputs, and achieving state-of-the-art scene reconstruction and tracking performance. </p>
<blockquote>
<p>基于高斯拼贴（Gaussian Splatting）的SLAM系统因其快速实时渲染和高保真映射的能力而受到关注。然而，当前的基于高斯拼贴的SLAM系统在大场景表示方面通常存在困难，并且缺乏有效的闭环检测。为了解决这些问题，我们引入了NGM-SLAM，这是第一个基于3DGS的SLAM系统，它利用神经辐射场子图进行渐进场景表达，有效地结合了神经辐射场和3D高斯拼贴的优点。我们以神经辐射场子图作为监督，并通过融合子图的高斯渲染实现高质量的场景表达和在线闭环调整。我们在多个真实场景和大场景数据集上的结果表明，我们的方法可以实现精确的空洞填充和高质量的场景表达，支持单目、立体和RGB-D输入，实现最先进的场景重建和跟踪性能。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2405.05702v7">PDF</a> 9pages, 4 figures</p>
<p><strong>Summary</strong></p>
<p>基于高斯拼贴技术的SLAM系统因其快速实时渲染和高保真映射能力而受到关注，但在大场景表示和环路闭合检测方面存在挑战。为解决这些问题，我们推出NGM-SLAM，首个利用神经辐射场子图进行渐进场景表达的基于高斯拼贴的SLAM系统。该系统结合了神经辐射场和高斯拼贴的优势，通过融合子图的高斯渲染实现高质量场景表达和在线环路闭合调整。多项真实场景和大场景数据集的实验结果表明，该方法可实现精准空洞填充和高质量场景表达，支持单目、立体和RGB-D输入，达到先进的场景重建和跟踪性能。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>基于高斯拼贴的SLAM系统受到广泛关注，但在大场景表示和环路闭合检测方面存在挑战。</li>
<li>NGM-SLAM是首个结合神经辐射场子图和3D高斯拼贴技术的SLAM系统。</li>
<li>NGM-SLAM利用神经辐射场子图作为监督，实现高质量场景表达。</li>
<li>通过融合子图的高斯渲染，NGM-SLAM可在线进行环路闭合调整。</li>
<li>该方法支持多种输入模式，包括单目、立体和RGB-D输入。</li>
<li>在真实场景和大场景数据集上的实验结果表明NGM-SLAM具有先进的场景重建和跟踪性能。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2405.05702">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-4f700ceb7d1dff5993a7421ad5046710.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-a6056f9bb0573a7ce1992c7675476283.jpg" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="Dynamic-Gaussians-Mesh-Consistent-Mesh-Reconstruction-from-Dynamic-Scenes"><a href="#Dynamic-Gaussians-Mesh-Consistent-Mesh-Reconstruction-from-Dynamic-Scenes" class="headerlink" title="Dynamic Gaussians Mesh: Consistent Mesh Reconstruction from Dynamic   Scenes"></a>Dynamic Gaussians Mesh: Consistent Mesh Reconstruction from Dynamic   Scenes</h2><p><strong>Authors:Isabella Liu, Hao Su, Xiaolong Wang</strong></p>
<p>Modern 3D engines and graphics pipelines require mesh as a memory-efficient representation, which allows efficient rendering, geometry processing, texture editing, and many other downstream operations. However, it is still highly difficult to obtain high-quality mesh in terms of detailed structure and time consistency from dynamic observations. To this end, we introduce Dynamic Gaussians Mesh (DG-Mesh), a framework to reconstruct a high-fidelity and time-consistent mesh from dynamic input. Our work leverages the recent advancement in 3D Gaussian Splatting to construct the mesh sequence with temporal consistency from dynamic observations. Building on top of this representation, DG-Mesh recovers high-quality meshes from the Gaussian points and can track the mesh vertices over time, which enables applications such as texture editing on dynamic objects. We introduce the Gaussian-Mesh Anchoring, which encourages evenly distributed Gaussians, resulting better mesh reconstruction through mesh-guided densification and pruning on the deformed Gaussians. By applying cycle-consistent deformation between the canonical and the deformed space, we can project the anchored Gaussian back to the canonical space and optimize Gaussians across all time frames. During the evaluation on different datasets, DG-Mesh provides significantly better mesh reconstruction and rendering than baselines. Project page: <a target="_blank" rel="noopener" href="https://www.liuisabella.com/DG-Mesh">https://www.liuisabella.com/DG-Mesh</a> </p>
<blockquote>
<p>现代3D引擎和图形管道需要网格作为内存高效的表示形式，这可以实现高效的渲染、几何处理、纹理编辑和许多其他后续操作。然而，从动态观察中获得高质量、细节丰富且时间一致的网格仍然非常困难。为此，我们引入了动态高斯网格（DG-Mesh），这是一个从动态输入重建高保真和时间一致网格的框架。我们的工作利用了最新的3D高斯贴图技术，从动态观察中构建具有时间一致性的网格序列。基于这种表示，DG-Mesh可以从高斯点恢复高质量的网格，并可以随时间跟踪网格顶点，这启用了对动态对象的纹理编辑应用程序。我们引入了高斯网格锚定，它鼓励高斯分布均匀，通过网格指导的密集化和修剪变形高斯，实现更好的网格重建。通过应用规范空间和变形空间之间的循环一致变形，我们可以将锚定的高斯投影回规范空间，并在所有时间帧中优化高斯。在不同的数据集上进行评估时，DG-Mesh在网格重建和渲染方面均显著优于基线方法。项目页面：<a target="_blank" rel="noopener" href="https://www.liuisabella.com/DG-Mesh">https://www.liuisabella.com/DG-Mesh</a></p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2404.12379v3">PDF</a> Project page: <a target="_blank" rel="noopener" href="https://www.liuisabella.com/DG-Mesh">https://www.liuisabella.com/DG-Mesh</a></p>
<p><strong>Summary</strong><br>高质量的三维网格在动态观测中难以获得，需要兼顾详细结构和时间一致性。为此，我们推出动态高斯网格（DG-Mesh）框架，利用三维高斯贴图技术从动态输入中重建高质量且时间一致的三维网格。DG-Mesh可追踪网格顶点随时间的变化，适用于动态对象的纹理编辑等应用。通过高斯网格锚定技术，实现高斯分布的均匀分布，优化网格重建。通过跨时间帧优化循环一致的变形，将锚定的高斯投影回规范空间，提高不同数据集上的网格重建和渲染效果。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>动态高斯网格（DG-Mesh）是一个从动态输入中重建高质量、时间一致三维网格的框架。</li>
<li>DG-Mesh利用三维高斯贴图技术，可实现高效的网格重建。</li>
<li>DG-Mesh能够追踪网格顶点随时间的变化，适用于动态对象的纹理编辑。</li>
<li>高斯网格锚定技术可实现高斯分布的均匀分布，从而优化网格重建效果。</li>
<li>通过跨时间帧的优化，DG-Mesh提高了网格重建的稳定性。</li>
<li>DG-Mesh在循环一致的变形处理上表现出优势。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2404.12379">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-75fa5eb37a56c02765aaecf586634076.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-6b41016872cf02c75d4172607aa3fa12.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-6983b60f6b97a0fbcd7ccb940b2000fa.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-13ebe96223f8052283ded149b40aa25a.jpg" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        文章作者:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        文章链接:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-03-05/3DGS/">https://kedreamix.github.io/Talk2Paper/Paper/2025-03-05/3DGS/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        版权声明:
                    </i>
                </span>
                <span class="reprint-info">
                    本博客所有文章除特別声明外，均采用
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    许可协议。转载请注明来源
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/3DGS/">
                                    <span class="chip bg-color">3DGS</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;上一篇</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-03-05/NeRF/">
                    <div class="card-image">
                        
                        <img src="https://pic1.zhimg.com/v2-c272fa6ee6403d416b9f8ff448e3a0d8.jpg" class="responsive-img" alt="NeRF">
                        
                        <span class="card-title">NeRF</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            NeRF 方向最新论文已更新，请持续关注 Update in 2025-03-05  GS-CPR Efficient Camera Pose Refinement via 3D Gaussian Splatting
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-03-05
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/NeRF/" class="post-category">
                                    NeRF
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/NeRF/">
                        <span class="chip bg-color">NeRF</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-03-05/GAN/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-3d636710aa028483211d346b3e40dd7d.jpg" class="responsive-img" alt="GAN">
                        
                        <span class="card-title">GAN</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            GAN 方向最新论文已更新，请持续关注 Update in 2025-03-05  LANTERN Accelerating Visual Autoregressive Models with Relaxed   Speculative Decoding
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-03-05
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/GAN/" class="post-category">
                                    GAN
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/GAN/">
                        <span class="chip bg-color">GAN</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- 代码语言 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span
                        class="white-color">19211.3k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- 运行天数提醒. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // 区分是否有年份.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = '本站已运行 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                daysTip = '本站已運行 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = '本站已运行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = '本站已運行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="关注我的知乎: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">知</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- 白天和黑夜主题 -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // 只在桌面版网页启用特效
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- 雪花特效 -->
    

    <!-- 鼠标星星特效 -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--腾讯兔小巢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- 动态标签 -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Σ(っ °Д °;)っ诶，页面崩溃了嘛？", clearTimeout(st)) : (document.title = "φ(゜▽゜*)♪咦，又好了！", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
