<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="åŒ»å­¦å›¾åƒ">
    <meta name="description" content="åŒ»å­¦å›¾åƒ æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-06-08  Refer to Anything with Vision-Language Prompts">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>åŒ»å­¦å›¾åƒ | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://picx.zhimg.com/v2-b4ae01e9699b2cf20a94369249f41db9.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">åŒ»å­¦å›¾åƒ</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/">
                                <span class="chip bg-color">åŒ»å­¦å›¾åƒ</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/" class="post-category">
                                åŒ»å­¦å›¾åƒ
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-06-08
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-07-06
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    17.1k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    71 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-06-08-æ›´æ–°"><a href="#2025-06-08-æ›´æ–°" class="headerlink" title="2025-06-08 æ›´æ–°"></a>2025-06-08 æ›´æ–°</h1><h2 id="Refer-to-Anything-with-Vision-Language-Prompts"><a href="#Refer-to-Anything-with-Vision-Language-Prompts" class="headerlink" title="Refer to Anything with Vision-Language Prompts"></a>Refer to Anything with Vision-Language Prompts</h2><p><strong>Authors:Shengcao Cao, Zijun Wei, Jason Kuen, Kangning Liu, Lingzhi Zhang, Jiuxiang Gu, HyunJoon Jung, Liang-Yan Gui, Yu-Xiong Wang</strong></p>
<p>Recent image segmentation models have advanced to segment images into high-quality masks for visual entities, and yet they cannot provide comprehensive semantic understanding for complex queries based on both language and vision. This limitation reduces their effectiveness in applications that require user-friendly interactions driven by vision-language prompts. To bridge this gap, we introduce a novel task of omnimodal referring expression segmentation (ORES). In this task, a model produces a group of masks based on arbitrary prompts specified by text only or text plus reference visual entities. To address this new challenge, we propose a novel framework to â€œRefer to Any Segmentation Mask Groupâ€ (RAS), which augments segmentation models with complex multimodal interactions and comprehension via a mask-centric large multimodal model. For training and benchmarking ORES models, we create datasets MaskGroups-2M and MaskGroups-HQ to include diverse mask groups specified by text and reference entities. Through extensive evaluation, we demonstrate superior performance of RAS on our new ORES task, as well as classic referring expression segmentation (RES) and generalized referring expression segmentation (GRES) tasks. Project page: <a target="_blank" rel="noopener" href="https://ref2any.github.io/">https://Ref2Any.github.io</a>. </p>
<blockquote>
<p>è¿‘æœŸå›¾åƒåˆ†å‰²æ¨¡å‹å·²ç»å‘å±•åˆ°äº†å¯ä»¥å°†å›¾åƒåˆ†å‰²æˆé«˜è´¨é‡è§†è§‰å®ä½“çš„æ©è†œï¼Œä½†å®ƒä»¬æ— æ³•åŸºäºè¯­è¨€å’Œè§†è§‰ä¸ºå¤æ‚æŸ¥è¯¢æä¾›å…¨é¢çš„è¯­ä¹‰ç†è§£ã€‚è¿™ä¸€å±€é™æ€§é™ä½äº†è¿™äº›æ¨¡å‹åœ¨å¤„ç†è§†è§‰è¯­è¨€æç¤ºé©±åŠ¨çš„å‹å¥½ç”¨æˆ·äº¤äº’åº”ç”¨çš„æ•ˆèƒ½ã€‚ä¸ºäº†å¡«è¡¥è¿™ä¸€ç©ºç™½ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€é¡¹æ–°çš„å¤šæ¨¡å¼æŒ‡ä»£è¡¨è¾¾å¼åˆ†å‰²ä»»åŠ¡ï¼ˆORESï¼‰ã€‚åœ¨æ­¤ä»»åŠ¡ä¸­ï¼Œæ¨¡å‹æ ¹æ®ä»…ç”±æ–‡æœ¬æŒ‡å®šæˆ–æ–‡æœ¬å’Œå‚è€ƒè§†è§‰å®ä½“å…±åŒæŒ‡å®šçš„ä»»æ„æç¤ºç”Ÿæˆä¸€ç»„æ©è†œã€‚ä¸ºäº†åº”å¯¹è¿™ä¸€æ–°æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åä¸ºâ€œæŒ‡å‘ä»»æ„åˆ†å‰²æ©è†œç»„â€ï¼ˆRASï¼‰çš„æ–°æ¡†æ¶ï¼Œé€šè¿‡æ©è†œä¸­å¿ƒå¤§å‹å¤šæ¨¡å¼æ¨¡å‹å¢å¼ºåˆ†å‰²æ¨¡å‹çš„å¤æ‚å¤šæ¨¡å¼äº¤äº’å’Œç†è§£èƒ½åŠ›ã€‚ä¸ºäº†è®­ç»ƒå’Œè¯„ä¼°ORESæ¨¡å‹ï¼Œæˆ‘ä»¬åˆ›å»ºäº†MaskGroups-2Må’ŒMaskGroups-HQæ•°æ®é›†ï¼ŒåŒ…å«ç”±æ–‡æœ¬å’Œå‚è€ƒå®ä½“æŒ‡å®šçš„å„ç§æ©è†œç»„ã€‚é€šè¿‡å¹¿æ³›è¯„ä¼°ï¼Œæˆ‘ä»¬åœ¨æ–°çš„ORESä»»åŠ¡ä»¥åŠç»å…¸æŒ‡ä»£è¡¨è¾¾å¼åˆ†å‰²ï¼ˆRESï¼‰å’Œå¹¿ä¹‰æŒ‡ä»£è¡¨è¾¾å¼åˆ†å‰²ï¼ˆGRESï¼‰ä»»åŠ¡ä¸Šå±•ç¤ºäº†RASçš„å“è¶Šæ€§èƒ½ã€‚é¡¹ç›®é¡µé¢ï¼š<a target="_blank" rel="noopener" href="https://ref2any.github.io./">https://Ref2Any.github.ioã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.05342v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºäº†ä¸€é¡¹æ–°çš„ä»»åŠ¡â€”â€”å¤šæ¨¡æ€å¼•ç”¨è¡¨è¾¾å¼åˆ†å‰²ï¼ˆORESï¼‰ï¼Œæ—¨åœ¨è§£å†³ç°æœ‰å›¾åƒåˆ†å‰²æ¨¡å‹æ— æ³•åŸºäºè¯­è¨€å’Œè§†è§‰æä¾›å…¨é¢çš„è¯­ä¹‰ç†è§£çš„é—®é¢˜ã€‚ä¸ºäº†åº”å¯¹è¿™ä¸€æŒ‘æˆ˜ï¼Œæå‡ºäº†ä¸€ç§åä¸ºRASçš„æ–°å‹æ¡†æ¶ï¼Œè¯¥æ¡†æ¶é€šè¿‡å¤§å‹å¤šæ¨¡æ€æ¨¡å‹å¢å¼ºåˆ†å‰²æ¨¡å‹çš„å¤æ‚å¤šæ¨¡æ€äº¤äº’å’Œæ©ç ç†è§£ã€‚åŒæ—¶ï¼Œä¸ºäº†è®­ç»ƒå’Œè¯„ä¼°ORESæ¨¡å‹ï¼Œåˆ›å»ºäº†MaskGroups-2Må’ŒMaskGroups-HQæ•°æ®é›†ã€‚å®éªŒè¡¨æ˜RASåœ¨ORESä»»åŠ¡ä»¥åŠç»å…¸å¼•ç”¨è¡¨è¾¾å¼åˆ†å‰²ï¼ˆRESï¼‰å’Œå¹¿ä¹‰å¼•ç”¨è¡¨è¾¾å¼åˆ†å‰²ï¼ˆGRESï¼‰ä»»åŠ¡ä¸Šçš„ä¼˜è¶Šæ€§èƒ½ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å½“å‰å›¾åƒåˆ†å‰²æ¨¡å‹æ— æ³•æä¾›åŸºäºè¯­è¨€å’Œè§†è§‰çš„å…¨é¢è¯­ä¹‰ç†è§£ã€‚</li>
<li>æå‡ºäº†ä¸€ç§æ–°å‹ä»»åŠ¡â€”â€”å¤šæ¨¡æ€å¼•ç”¨è¡¨è¾¾å¼åˆ†å‰²ï¼ˆORESï¼‰ï¼Œæ—¨åœ¨è§£å†³è¿™ä¸€é—®é¢˜ã€‚</li>
<li>ä»‹ç»äº†åä¸ºRASçš„æ–°å‹æ¡†æ¶ï¼Œå®ƒé€šè¿‡å¤§å‹å¤šæ¨¡æ€æ¨¡å‹å¢å¼ºåˆ†å‰²æ¨¡å‹çš„å¤æ‚äº¤äº’å’Œæ©ç ç†è§£ã€‚</li>
<li>åˆ›å»ºäº†MaskGroups-2Må’ŒMaskGroups-HQæ•°æ®é›†ï¼Œç”¨äºè®­ç»ƒå’Œè¯„ä¼°ORESæ¨¡å‹ã€‚<br>5.RASåœ¨ORESä»»åŠ¡ä¸Šçš„æ€§èƒ½è¡¨ç°ä¼˜è¶Šã€‚<br>6.RASä¹Ÿèƒ½å¾ˆå¥½åœ°åº”å¯¹ç»å…¸å¼•ç”¨è¡¨è¾¾å¼åˆ†å‰²ï¼ˆRESï¼‰å’Œå¹¿ä¹‰å¼•ç”¨è¡¨è¾¾å¼åˆ†å‰²ï¼ˆGRESï¼‰ä»»åŠ¡ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.05342">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-2b107ce9f22addb139eeabfe2703f702.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-0dc4dae8c7cc1cca57c9f23c62b5e087.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-1bf9bbee3d4f6cf85ce44d3caa26af9f.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-2bc02c66a12907c02c9e161579366b00.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-e8c2d8a3942f2d5cbbfac3bdda13d820.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="DM-SegNet-Dual-Mamba-Architecture-for-3D-Medical-Image-Segmentation-with-Global-Context-Modeling"><a href="#DM-SegNet-Dual-Mamba-Architecture-for-3D-Medical-Image-Segmentation-with-Global-Context-Modeling" class="headerlink" title="DM-SegNet: Dual-Mamba Architecture for 3D Medical Image Segmentation   with Global Context Modeling"></a>DM-SegNet: Dual-Mamba Architecture for 3D Medical Image Segmentation   with Global Context Modeling</h2><p><strong>Authors:Hangyu Ji</strong></p>
<p>Accurate 3D medical image segmentation demands architectures capable of reconciling global context modeling with spatial topology preservation. While State Space Models (SSMs) like Mamba show potential for sequence modeling, existing medical SSMs suffer from encoder-decoder incompatibility: the encoderâ€™s 1D sequence flattening compromises spatial structures, while conventional decoders fail to leverage Mambaâ€™s state propagation. We present DM-SegNet, a Dual-Mamba architecture integrating directional state transitions with anatomy-aware hierarchical decoding. The core innovations include a quadri-directional spatial Mamba module employing four-directional 3D scanning to maintain anatomical spatial coherence, a gated spatial convolution layer that enhances spatially sensitive feature representation prior to state modeling, and a Mamba-driven decoding framework enabling bidirectional state synchronization across scales. Extensive evaluation on two clinically significant benchmarks demonstrates the efficacy of DM-SegNet: achieving state-of-the-art Dice Similarity Coefficient (DSC) of 85.44% on the Synapse dataset for abdominal organ segmentation and 90.22% on the BraTS2023 dataset for brain tumor segmentation. </p>
<blockquote>
<p>ç²¾ç¡®çš„ä¸‰ç»´åŒ»å­¦å›¾åƒåˆ†å‰²éœ€è¦èƒ½å¤Ÿåè°ƒå…¨å±€ä¸Šä¸‹æ–‡å»ºæ¨¡ä¸ç©ºé—´æ‹“æ‰‘ä¿æŒçš„æ¶æ„ã€‚è™½ç„¶åƒMambaè¿™æ ·çš„çŠ¶æ€ç©ºé—´æ¨¡å‹ï¼ˆSSMsï¼‰åœ¨åºåˆ—å»ºæ¨¡æ–¹é¢æ˜¾ç¤ºå‡ºæ½œåŠ›ï¼Œä½†ç°æœ‰çš„åŒ»å­¦SSMså—åˆ°ç¼–ç å™¨-è§£ç å™¨ä¸å…¼å®¹çš„é™åˆ¶ï¼šç¼–ç å™¨çš„1Dåºåˆ—å±•å¹³ä¼šæŸå®³ç©ºé—´ç»“æ„ï¼Œè€Œä¼ ç»Ÿè§£ç å™¨åˆ™æ— æ³•åˆ©ç”¨Mambaçš„çŠ¶æ€ä¼ æ’­ã€‚æˆ‘ä»¬æå‡ºäº†DM-SegNetï¼Œè¿™æ˜¯ä¸€ç§ç»“åˆäº†æ–¹å‘çŠ¶æ€è½¬æ¢å’Œè§£å‰–ç»“æ„æ„ŸçŸ¥å±‚æ¬¡è§£ç çš„åŒMambaæ¶æ„ã€‚æ ¸å¿ƒåˆ›æ–°åŒ…æ‹¬é‡‡ç”¨å››æ–¹å‘ä¸‰ç»´æ‰«æçš„å››æ–¹å‘ç©ºé—´Mambaæ¨¡å—ï¼Œä»¥ç»´æŒè§£å‰–ç©ºé—´è¿è´¯æ€§ï¼Œä¸€ä¸ªé—¨æ§ç©ºé—´å·ç§¯å±‚ï¼Œåœ¨çŠ¶æ€å»ºæ¨¡ä¹‹å‰å¢å¼ºç©ºé—´æ•æ„Ÿç‰¹å¾è¡¨ç¤ºï¼Œä»¥åŠä¸€ä¸ªç”±Mambaé©±åŠ¨çš„è§£ç æ¡†æ¶ï¼Œå®ç°è·¨å°ºåº¦çš„åŒå‘çŠ¶æ€åŒæ­¥ã€‚åœ¨ä¸¤ä¸ªå…·æœ‰é‡è¦ä¸´åºŠæ„ä¹‰çš„åŸºå‡†æµ‹è¯•ä¸Šçš„å¹¿æ³›è¯„ä¼°è¯æ˜äº†DM-SegNetçš„æœ‰æ•ˆæ€§ï¼šåœ¨è…¹éƒ¨å™¨å®˜åˆ†å‰²çš„Synapseæ•°æ®é›†ä¸Šå®ç°äº†æœ€å…ˆè¿›çš„Diceç›¸ä¼¼ç³»æ•°ï¼ˆDSCï¼‰85.44%ï¼Œåœ¨BraTS2023æ•°æ®é›†ä¸Šçš„è„‘è‚¿ç˜¤åˆ†å‰²è¾¾åˆ°äº†90.22%ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.05297v1">PDF</a> </p>
<p><strong>Summary</strong><br>åŒ»å­¦å›¾åƒç²¾å‡†ä¸‰ç»´åˆ†å‰²éœ€è¦å…¼é¡¾å…¨å±€ä¸Šä¸‹æ–‡å»ºæ¨¡ä¸ç©ºé—´æ‹“æ‰‘ä¿æŒçš„æ¶æ„ã€‚ç°æœ‰åŒ»ç–—ç©ºé—´æ¨¡å‹ï¼ˆSSMsï¼‰å¦‚Mambaåœ¨åºåˆ—å»ºæ¨¡æ–¹é¢å±•ç°æ½œåŠ›ï¼Œä½†å­˜åœ¨ç¼–ç å™¨å’Œè§£ç å™¨ä¸å…¼å®¹çš„é—®é¢˜ã€‚æœ¬æ–‡æå‡ºDM-SegNetæ¶æ„ï¼Œç»“åˆæ–¹å‘æ€§çŠ¶æ€è½¬æ¢ä¸è§£å‰–ç»“æ„æ„ŸçŸ¥å±‚æ¬¡è§£ç ã€‚æ ¸å¿ƒåˆ›æ–°åŒ…æ‹¬å››æ–¹å‘ç©ºé—´Mambaæ¨¡å—ã€é—¨æ§ç©ºé—´å·ç§¯å±‚å’ŒMambaé©±åŠ¨è§£ç æ¡†æ¶ã€‚åœ¨ä¸¤å¤§ä¸´åºŠåŸºå‡†æµ‹è¯•ä¸Šè¡¨ç°å“è¶Šï¼Œè…¹éƒ¨å™¨å®˜åˆ†å‰²çš„Diceç›¸ä¼¼ç³»æ•°è¾¾85.44%ï¼Œè„‘è‚¿ç˜¤åˆ†å‰²çš„DSCä¸º90.22%ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>åŒ»å­¦å›¾åƒ3Dåˆ†å‰²éœ€å…¼é¡¾å…¨å±€ä¸Šä¸‹æ–‡ä¸ç©ºé—´æ‹“æ‰‘ã€‚</li>
<li>SSMsï¼ˆå¦‚Mambaï¼‰åœ¨åŒ»å­¦å›¾åƒåˆ†å‰²ä¸­æœ‰æ½œåŠ›ï¼Œä½†é¢ä¸´ç¼–ç è§£ç ä¸å…¼å®¹é—®é¢˜ã€‚</li>
<li>DM-SegNetæ¶æ„ç»“åˆæ–¹å‘æ€§çŠ¶æ€è½¬æ¢ä¸è§£å‰–ç»“æ„æ„ŸçŸ¥å±‚æ¬¡è§£ç ã€‚</li>
<li>å››æ–¹å‘ç©ºé—´Mambaæ¨¡å—ç»´æŒè§£å‰–ç©ºé—´è¿è´¯æ€§ã€‚</li>
<li>é—¨æ§ç©ºé—´å·ç§¯å±‚å¼ºåŒ–ç©ºé—´æ•æ„Ÿç‰¹å¾è¡¨ç¤ºã€‚</li>
<li>Mambaé©±åŠ¨è§£ç æ¡†æ¶å®ç°è·¨å°ºåº¦åŒå‘çŠ¶æ€åŒæ­¥ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.05297">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-6dd958b4c91746e8100a18a01eaf74cb.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-2e2541d4285e40875a7cce2c3531ba07.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-824f50cdfceb6401fc802f723f085399.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-3d12b1312608911bd485f516d2e194ab.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-9c184bf5cddcff53b8722850e6cbdd9c.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="Unraveling-the-structure-of-the-stratified-ultra-fast-outflows-in-PDS-456-with-XRISM"><a href="#Unraveling-the-structure-of-the-stratified-ultra-fast-outflows-in-PDS-456-with-XRISM" class="headerlink" title="Unraveling the structure of the stratified ultra-fast outflows in PDS   456 with XRISM"></a>Unraveling the structure of the stratified ultra-fast outflows in PDS   456 with XRISM</h2><p><strong>Authors:Yerong Xu, Luigi C. Gallo, Kouichi Hagino, James N. Reeves, Francesco Tombesi, Misaki Mizumoto, Alfredo Luminari, Adam G. Gonzalez, Ehud Behar, Rozenn Boissay-Malaquin, Valentina Braito, Pierpaolo Condo, Chris Done, Aiko Miyamoto, Ryuki Mizukawa, Hirokazu Odaka, Riki Sato, Atsushi Tanimoto, Makoto Tashiro, Tahir Yaqoob, Satoshi Yamada</strong></p>
<p>Multiple clumpy wind components ($v_{out}\sim0.2-0.3c$) in the luminous quasar PDS 456 have recently been resolved by XRISM in the Fe-K band for the first time. In this paper, we investigate the structure of ultra-fast outflows (UFOs) using coordinated observations from XRISM, XMM-Newton, and NuSTAR, along with the self-consistently calculated photoionization model \texttt{PION}. Our results reveal a stratified ionization structure likely driven by the radiation field, characterized by a relation between wind velocity and ionization parameter $v_{out}\propto\xi^{(0.38\pm0.06)}$. To evaluate the impact of the screening effect, we tested all possible order permutations of six \texttt{PION} components. We find that highly ionized UFOs ($\log\xi&gt;4.5$) are insensitive to their relative positions, whereas the soft X-ray UFO ($\log\xi\sim3$ and $v_{out}\sim0.27c$) and the lowest-ionized hard X-ray UFO ($\log\xi\sim4.1$ and $v_ {out}\sim0.23c$) are statistically favored â€“ based on the evidence from both the C-statistic and Bayesian analysis â€“ to occupy the middle and innermost layers, respectively. This suggests a possible trend where slower UFOs are launched from regions closer to the supermassive black hole (SMBH). The soft X-ray UFO is found to be thermally unstable, regardless of its relative position. However, its location remains unclear. Our sequence analysis and its similarity to hard X-ray UFOs suggest that they may be co-spatial, while variability constraints support its location within the broad-line region at sub-parsec scales. Simulations with the gate-valve opened XRISM show that high-resolution soft X-ray data can enhance the reliability of our results. Furthermore, simulations with the future X-ray mission NewAthena demonstrate its capability to resolve the absorber sequence and spatial distributions, enabling the determination of UFO structures and their roles in AGN feedback. </p>
<blockquote>
<p>åœ¨æ˜äº®çš„ç±»æ˜Ÿä½“PDS 456ä¸­ï¼Œå¤šä¸ªå—çŠ¶é£æˆåˆ†ï¼ˆé€Ÿåº¦çº¦ä¸ºå…‰é€Ÿçš„0.2~0.3å€ï¼‰æœ€è¿‘åœ¨é“-Kæ³¢æ®µé¦–æ¬¡è¢«XRISMè§£æå‡ºæ¥ã€‚æœ¬æ–‡åˆ©ç”¨XRISMã€XMM-Newtonå’ŒNuSTARçš„ååŒè§‚æµ‹ä»¥åŠè‡ªæ´½çš„å…‰ç¦»å­åŒ–æ¨¡å‹\texttt{PION}ï¼Œç ”ç©¶äº†è¶…å¿«å¤–æµï¼ˆUFOsï¼‰çš„ç»“æ„ã€‚æˆ‘ä»¬çš„ç»“æœè¡¨æ˜ï¼Œå¯èƒ½å­˜åœ¨ç”±è¾å°„åœºé©±åŠ¨çš„åˆ†å±‚ç”µç¦»ç»“æ„ï¼Œå…¶è¡¨ç°ä¸ºé£é€Ÿä¸ç”µç¦»å‚æ•°ä¹‹é—´çš„å…³ç³»ä¸º$v_{out}\propto\xi^{(0.38\pm0.06)}$ã€‚ä¸ºäº†è¯„ä¼°å±è”½æ•ˆåº”çš„å½±å“ï¼Œæˆ‘ä»¬æµ‹è¯•äº†å…­ç§ä¸åŒ\texttt{PION}æˆåˆ†çš„æ‰€æœ‰å¯èƒ½çš„æ’åˆ—ç»„åˆã€‚æˆ‘ä»¬å‘ç°é«˜ç”µç¦»çš„å¤–æµï¼ˆç”µç¦»åº¦å¤§äº4.5ï¼‰å¯¹å…¶ç›¸å¯¹ä½ç½®å¹¶ä¸æ•æ„Ÿï¼Œè€Œè½¯Xå°„çº¿å¤–æµï¼ˆç”µç¦»åº¦çº¦ä¸º3ï¼Œé€Ÿåº¦çº¦ä¸ºå…‰é€Ÿçš„0.27å€ï¼‰å’Œæœ€ä½ç”µç¦»çš„ç¡¬Xå°„çº¿å¤–æµï¼ˆç”µç¦»åº¦çº¦ä¸º4.1ï¼Œé€Ÿåº¦çº¦ä¸ºå…‰é€Ÿçš„0.23å€ï¼‰åœ¨ç»Ÿè®¡ä¸Šå æ®ä¸­é—´å±‚å’Œæœ€å†…å±‚ï¼Œåˆ†åˆ«åŸºäºCç»Ÿè®¡å’Œè´å¶æ–¯åˆ†æçš„ç»“æœã€‚è¿™è¡¨æ˜è¾ƒæ…¢çš„å¤–æµå¯èƒ½ä»æ¥è¿‘è¶…å¤§è´¨é‡é»‘æ´ï¼ˆSMBHï¼‰çš„åŒºåŸŸå‘å°„å‡ºæ¥ã€‚è½¯Xå°„çº¿å¤–æµçš„çƒ­ç¨³å®šæ€§ä¸ä½³ï¼Œä¸å…¶ç›¸å¯¹ä½ç½®æ— å…³ã€‚ç„¶è€Œï¼Œå®ƒçš„ä½ç½®ä»ç„¶ä¸æ˜ç¡®ã€‚æˆ‘ä»¬çš„åºåˆ—åˆ†æä¸ç¡¬Xå°„çº¿å¤–æµçš„ç›¸ä¼¼æ€§è¡¨æ˜å®ƒä»¬å¯èƒ½å…±å¤„äºåŒä¸€ä½ç½®ï¼Œè€Œå˜å¼‚æ€§çº¦æŸæ”¯æŒå…¶åœ¨äºšç§’çº§å°ºåº¦ä¸Šçš„å®½çº¿åŒºå†…ã€‚ä½¿ç”¨å¼€å¯çš„XRISMé—¨é˜€è¿›è¡Œçš„æ¨¡æ‹Ÿè¡¨æ˜ï¼Œé«˜åˆ†è¾¨ç‡çš„è½¯Xå°„çº¿æ•°æ®å¯ä»¥æé«˜æˆ‘ä»¬ç»“æœçš„å¯é æ€§ã€‚æ­¤å¤–ï¼Œæœªæ¥çš„Xå°„çº¿ä»»åŠ¡NewAthenaçš„æ¨¡æ‹Ÿå±•ç¤ºäº†å…¶è§£å†³å¸æ”¶ä½“åºåˆ—å’Œç©ºé—´åˆ†å¸ƒçš„èƒ½åŠ›ï¼Œä»è€Œèƒ½å¤Ÿç¡®å®šUFOçš„ç»“æ„åŠå…¶åœ¨æ´»æ€§æ˜Ÿç³»æ ¸åé¦ˆä¸­çš„ä½œç”¨ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.05273v1">PDF</a> 22 pages, 18 figures, and 2 tables, accepted for publication in PASJ   for the XRISM special issue</p>
<p><strong>Summary</strong></p>
<p>æœ¬ç ”ç©¶åˆ©ç”¨XRISMã€XMM-Newtonå’ŒNuSTARçš„è”åˆè§‚æµ‹ï¼Œä»¥åŠè‡ªæ´½çš„å…‰ç”µç¦»æ¨¡å‹\texttt{PION}ï¼Œå¯¹è¶…å¿«å¤–æµï¼ˆUFOsï¼‰çš„ç»“æ„è¿›è¡Œäº†æ¢ç©¶ã€‚ç ”ç©¶å‘ç°é£é€Ÿåº¦ä¸ç”µç¦»å‚æ•°ä¹‹é—´å­˜åœ¨å…³ç³»ï¼Œ$v_{out}\propto\xi^{(0.38\pm0.06)}$ã€‚ä¸åŒç”µç¦»çŠ¶æ€çš„UFOsçš„ä½ç½®æ’åºå¯¹ç­›é€‰æ•ˆæœå½±å“ä¸ä¸€ã€‚åŸºäºCç»Ÿè®¡é‡å’Œè´å¶æ–¯åˆ†æï¼Œé«˜åº¦ç”µç¦»çš„UFOså¯¹ç›¸å¯¹ä½ç½®ä¸æ•æ„Ÿï¼Œè€Œè½¯Xå°„çº¿UFOå’Œæœ€ä½ç”µç¦»çš„ç¡¬Xå°„çº¿UFOåˆ™æ›´å€¾å‘äºå æ®ä¸­é—´å’Œå†…éƒ¨å±‚ã€‚æš—ç¤ºè¾ƒæ…¢çš„UFOså¯èƒ½ä»æ¥è¿‘è¶…å¤§è´¨é‡é»‘æ´ï¼ˆSMBHï¼‰çš„åŒºåŸŸå‘å°„ã€‚æ­¤å¤–ï¼Œè½¯Xå°„çº¿UFOè¡¨ç°å‡ºçƒ­ä¸ç¨³å®šï¼Œä½†å…¶ä½ç½®å°šä¸æ¸…æ¥šã€‚æ–°Athenaæœªæ¥Xå°„çº¿ä»»åŠ¡æœ‰æœ›è§£å†³å¸æ”¶å™¨åºåˆ—å’Œç©ºé—´åˆ†å¸ƒï¼Œæœ‰åŠ©äºç¡®å®šUFOç»“æ„å’Œåœ¨AGNåé¦ˆä¸­çš„ä½œç”¨ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>åˆ©ç”¨XRISMç­‰è§‚æµ‹è®¾å¤‡è§£æäº†PDS 456ä¸­çš„å¤šé‡å—çŠ¶é£æˆåˆ†ã€‚</li>
<li>é€šè¿‡åè°ƒè§‚æµ‹å’Œè‡ªæ´½çš„å…‰ç”µç¦»æ¨¡å‹\texttt{PION}ï¼Œæ­ç¤ºäº†UFOsçš„åˆ†å±‚ç”µç¦»ç»“æ„ã€‚</li>
<li>è§‚å¯Ÿåˆ°é£é€Ÿåº¦ä¸ç”µç¦»å‚æ•°ä¹‹é—´çš„å…³ç³»ï¼š$v_{out}\propto\xi^{(0.38\pm0.06)}$ã€‚</li>
<li>é«˜ç”µç¦»UFOsç›¸å¯¹ä½ç½®å¯¹ç­›é€‰æ•ˆæœä¸æ•æ„Ÿï¼Œè€Œç‰¹å®šç”µç¦»çŠ¶æ€çš„UFOså æ®ç‰¹å®šä½ç½®ã€‚</li>
<li>è½¯Xå°„çº¿UFOçš„çƒ­ä¸ç¨³å®šæ€§è¢«å‘ç°ï¼Œä½ç½®å°šä¸æ˜ç¡®ã€‚å…¶ä¸ç¡¬Xå°„çº¿UFOså¯èƒ½å…±å­˜çš„è¿¹è±¡è¢«æå‡ºã€‚</li>
<li>åŸºäºè§‚æµ‹è¯æ®ï¼Œè¾ƒæ…¢çš„UFOså¯èƒ½æºäºæ¥è¿‘SMBHçš„åŒºåŸŸã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.05273">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-fa932f585cdca14f7b12e29d4b016cce.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-cbf4e06af2e5754020ed3fdfa019d644.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b4f310811cf186bec73a7b126bcd50bf.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-1d3a35aa2cc55b4894dc9360fb54589b.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="SAM-aware-Test-time-Adaptation-for-Universal-Medical-Image-Segmentation"><a href="#SAM-aware-Test-time-Adaptation-for-Universal-Medical-Image-Segmentation" class="headerlink" title="SAM-aware Test-time Adaptation for Universal Medical Image Segmentation"></a>SAM-aware Test-time Adaptation for Universal Medical Image Segmentation</h2><p><strong>Authors:Jianghao Wu, Yicheng Wu, Yutong Xie, Wenjia Bai, You Zhang, Feilong Tang, Yulong Li, Yasmeen George, Imran Razzak</strong></p>
<p>Universal medical image segmentation using the Segment Anything Model (SAM) remains challenging due to its limited adaptability to medical domains. Existing adaptations, such as MedSAM, enhance SAMâ€™s performance in medical imaging but at the cost of reduced generalization to unseen data. Therefore, in this paper, we propose SAM-aware Test-Time Adaptation (SAM-TTA), a fundamentally different pipeline that preserves the generalization of SAM while improving its segmentation performance in medical imaging via a test-time framework. SAM-TTA tackles two key challenges: (1) input-level discrepancies caused by differences in image acquisition between natural and medical images and (2) semantic-level discrepancies due to fundamental differences in object definition between natural and medical domains (e.g., clear boundaries vs. ambiguous structures). Specifically, our SAM-TTA framework comprises (1) Self-adaptive Bezier Curve-based Transformation (SBCT), which adaptively converts single-channel medical images into three-channel SAM-compatible inputs while maintaining structural integrity, to mitigate the input gap between medical and natural images, and (2) Dual-scale Uncertainty-driven Mean Teacher adaptation (DUMT), which employs consistency learning to align SAMâ€™s internal representations to medical semantics, enabling efficient adaptation without auxiliary supervision or expensive retraining. Extensive experiments on five public datasets demonstrate that our SAM-TTA outperforms existing TTA approaches and even surpasses fully fine-tuned models such as MedSAM in certain scenarios, establishing a new paradigm for universal medical image segmentation. Code can be found at <a target="_blank" rel="noopener" href="https://github.com/JianghaoWu/SAM-TTA">https://github.com/JianghaoWu/SAM-TTA</a>. </p>
<blockquote>
<p>ä½¿ç”¨Segment Anything Modelï¼ˆSAMï¼‰è¿›è¡Œé€šç”¨åŒ»å­¦å›¾åƒåˆ†å‰²ä»ç„¶æ˜¯ä¸€ä¸ªæŒ‘æˆ˜ï¼Œå› ä¸ºå®ƒå¯¹åŒ»å­¦é¢†åŸŸçš„é€‚åº”æ€§æœ‰é™ã€‚ç°æœ‰çš„é€‚åº”æ–¹æ³•ï¼Œå¦‚MedSAMï¼Œè™½ç„¶æé«˜äº†SAMåœ¨åŒ»å­¦æˆåƒä¸­çš„æ€§èƒ½ï¼Œä½†é™ä½äº†å…¶å¯¹æœªè§æ•°æ®çš„æ³›åŒ–èƒ½åŠ›ã€‚å› æ­¤ï¼Œåœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†SAMæ„ŸçŸ¥æµ‹è¯•æ—¶é—´é€‚åº”ï¼ˆSAM-TTAï¼‰ï¼Œè¿™æ˜¯ä¸€ä¸ªæ ¹æœ¬ä¸åŒçš„ç®¡é“ï¼Œå®ƒä¿ç•™äº†SAMçš„æ³›åŒ–èƒ½åŠ›ï¼ŒåŒæ—¶é€šè¿‡æµ‹è¯•æ—¶é—´æ¡†æ¶æé«˜äº†å…¶åœ¨åŒ»å­¦æˆåƒä¸­çš„åˆ†å‰²æ€§èƒ½ã€‚SAM-TTAè§£å†³äº†ä¸¤ä¸ªå…³é”®æŒ‘æˆ˜ï¼šï¼ˆ1ï¼‰ç”±äºè‡ªç„¶å›¾åƒå’ŒåŒ»å­¦å›¾åƒåœ¨å›¾åƒé‡‡é›†æ–¹é¢çš„å·®å¼‚å¯¼è‡´çš„è¾“å…¥çº§å·®å¼‚ï¼›ï¼ˆ2ï¼‰ç”±äºè‡ªç„¶åŸŸå’ŒåŒ»å­¦åŸŸåœ¨å¯¹è±¡å®šä¹‰ä¸Šçš„æ ¹æœ¬å·®å¼‚å¯¼è‡´çš„è¯­ä¹‰çº§å·®å¼‚ï¼ˆä¾‹å¦‚ï¼Œæ¸…æ™°çš„è¾¹ç•Œä¸æ¨¡ç³Šçš„ç»“æ„ï¼‰ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬çš„SAM-TTAæ¡†æ¶åŒ…æ‹¬ï¼ˆ1ï¼‰åŸºäºè‡ªé€‚åº”Bezieræ›²çº¿çš„è½¬æ¢ï¼ˆSBCTï¼‰ï¼Œå®ƒè‡ªé€‚åº”åœ°å°†å•é€šé“åŒ»å­¦å›¾åƒè½¬æ¢ä¸ºä¸‰é€šé“SAMå…¼å®¹è¾“å…¥ï¼ŒåŒæ—¶ä¿æŒç»“æ„å®Œæ•´æ€§ï¼Œä»¥å‡è½»åŒ»å­¦å›¾åƒå’Œè‡ªç„¶å›¾åƒä¹‹é—´çš„è¾“å…¥å·®è·ï¼›ï¼ˆ2ï¼‰åŒå°ºåº¦ä¸ç¡®å®šæ€§é©±åŠ¨çš„å¹³å‡æ•™å¸ˆé€‚åº”ï¼ˆDUMTï¼‰ï¼Œå®ƒé‡‡ç”¨ä¸€è‡´æ€§å­¦ä¹ æ¥ä½¿SAMçš„å†…éƒ¨è¡¨ç¤ºä¸åŒ»å­¦è¯­ä¹‰å¯¹é½ï¼Œå®ç°æœ‰æ•ˆçš„é€‚åº”ï¼Œè€Œæ— éœ€é¢å¤–çš„ç›‘ç£æˆ–æ˜‚è´µçš„é‡æ–°è®­ç»ƒã€‚åœ¨äº”ä¸ªå…¬å…±æ•°æ®é›†ä¸Šçš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„SAM-TTAä¼˜äºç°æœ‰çš„TTAæ–¹æ³•ï¼Œå¹¶ä¸”åœ¨æŸäº›æƒ…å†µä¸‹ç”šè‡³è¶…è¶Šäº†å®Œå…¨å¾®è°ƒè¿‡çš„æ¨¡å‹ï¼ˆå¦‚MedSAMï¼‰ï¼Œä¸ºé€šç”¨åŒ»å­¦å›¾åƒåˆ†å‰²å»ºç«‹äº†æ–°çš„èŒƒå¼ã€‚ä»£ç å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/JianghaoWu/SAM-TTA">https://github.com/JianghaoWu/SAM-TTA</a>æ‰¾åˆ°ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.05221v1">PDF</a> 10 pages, 4 figures</p>
<p><strong>æ‘˜è¦</strong></p>
<p>æœ¬æ–‡æå‡ºä¸€ç§åä¸ºSAM-TTAçš„æ–°å‹æµ‹è¯•æ—¶è‡ªé€‚åº”æ–¹æ³•ï¼Œç”¨äºæé«˜åŒ»å­¦å›¾åƒåˆ†å‰²çš„é€šç”¨æ€§å’Œæ€§èƒ½ã€‚è¯¥æ–¹æ³•é€šè¿‡è§£å†³è¾“å…¥å’Œè¯­ä¹‰å±‚é¢çš„å·®å¼‚ï¼Œæ”¹è¿›äº†SAMæ¨¡å‹åœ¨åŒ»å­¦å›¾åƒåˆ†å‰²ä¸­çš„è¡¨ç°ã€‚SAM-TTAåŒ…æ‹¬SBCTå’ŒDUMTä¸¤ä¸ªå…³é”®ç»„ä»¶ï¼Œåˆ†åˆ«ç”¨äºè‡ªé€‚åº”è½¬æ¢åŒ»å­¦å›¾åƒå’Œé€‚åº”SAMæ¨¡å‹çš„å†…éƒ¨è¡¨ç¤ºã€‚å®éªŒè¯æ˜ï¼ŒSAM-TTAåœ¨å¤šä¸ªå…¬å…±æ•°æ®é›†ä¸Šçš„è¡¨ç°ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œç”šè‡³åœ¨æŸäº›æƒ…å†µä¸‹è¶…è¶Šäº†MedSAMç­‰å®Œå…¨å¾®è°ƒè¿‡çš„æ¨¡å‹ï¼Œä¸ºé€šç”¨åŒ»å­¦å›¾åƒåˆ†å‰²æä¾›äº†æ–°çš„èŒƒä¾‹ã€‚</p>
<p><strong>å…³é”®è§è§£</strong></p>
<ol>
<li>SAM-TTAæ–¹æ³•ç»“åˆäº†æµ‹è¯•æ—¶è‡ªé€‚åº”æŠ€æœ¯ï¼Œæ—¨åœ¨æé«˜åŒ»å­¦å›¾åƒåˆ†å‰²æ¨¡å‹çš„é€šç”¨æ€§å’Œæ€§èƒ½ã€‚</li>
<li>è¾“å…¥å±‚é¢çš„å·®å¼‚ç”±äºè‡ªç„¶å›¾åƒå’ŒåŒ»å­¦å›¾åƒåœ¨å›¾åƒé‡‡é›†ä¸Šçš„å·®å¼‚è€Œå¯¼è‡´ï¼ŒSAM-TTAé€šè¿‡SBCTè¿›è¡Œè‡ªé€‚åº”è½¬æ¢æ¥è§£å†³è¿™ä¸€é—®é¢˜ã€‚</li>
<li>è¯­ä¹‰å±‚é¢çš„å·®å¼‚æºäºè‡ªç„¶å’ŒåŒ»å­¦é¢†åŸŸå¯¹è±¡å®šä¹‰çš„æ ¹æœ¬å·®å¼‚ï¼ŒSAM-TTAé€šè¿‡DUMTè¿›è¡Œä¸€è‡´æ€§å­¦ä¹ æ¥é€‚åº”è¿™ç§å·®å¼‚ã€‚</li>
<li>ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼ŒSAM-TTAåœ¨å¤šä¸ªå…¬å…±æ•°æ®é›†ä¸Šå®ç°äº†ä¼˜è¶Šçš„æ€§èƒ½ã€‚</li>
<li>SAM-TTAç”šè‡³åœ¨æŸäº›æƒ…å†µä¸‹è¶…è¶Šäº†å®Œå…¨å¾®è°ƒè¿‡çš„æ¨¡å‹ï¼Œå¦‚MedSAMã€‚</li>
<li>SAM-TTAä¸ºé€šç”¨åŒ»å­¦å›¾åƒåˆ†å‰²æä¾›äº†æ–°çš„èŒƒä¾‹ï¼Œå¼ºè°ƒäº†æµ‹è¯•æ—¶è‡ªé€‚åº”æŠ€æœ¯çš„é‡è¦æ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.05221">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-d350f83d2593e39bea684caf1de63595.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b3046bf09f10d1325f680e3be0a80b29.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-6354e2f28d4d0c12abb3c94d82b25ca5.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b35ce5ec5c91f48a08306d9d2be9e933.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="Single-GPU-Task-Adaptation-of-Pathology-Foundation-Models-for-Whole-Slide-Image-Analysis"><a href="#Single-GPU-Task-Adaptation-of-Pathology-Foundation-Models-for-Whole-Slide-Image-Analysis" class="headerlink" title="Single GPU Task Adaptation of Pathology Foundation Models for Whole   Slide Image Analysis"></a>Single GPU Task Adaptation of Pathology Foundation Models for Whole   Slide Image Analysis</h2><p><strong>Authors:Neeraj Kumar, Swaraj Nanda, Siddharth Singi, Jamal Benhamida, David Kim, Jie-Fu Chen, Amir Momeni-Boroujeni, Gregory M. Goldgof, Gabriele Campanella, Chad Vanderbilt</strong></p>
<p>Pathology foundation models (PFMs) have emerged as powerful tools for analyzing whole slide images (WSIs). However, adapting these pretrained PFMs for specific clinical tasks presents considerable challenges, primarily due to the availability of only weak (WSI-level) labels for gigapixel images, necessitating multiple instance learning (MIL) paradigm for effective WSI analysis. This paper proposes a novel approach for single-GPU \textbf{T}ask \textbf{A}daptation of \textbf{PFM}s (TAPFM) that uses vision transformer (\vit) attention for MIL aggregation while optimizing both for feature representations and attention weights. The proposed approach maintains separate computational graphs for MIL aggregator and the PFM to create stable training dynamics that align with downstream task objectives during end-to-end adaptation. Evaluated on mutation prediction tasks for bladder cancer and lung adenocarcinoma across institutional and TCGA cohorts, TAPFM consistently outperforms conventional approaches, with H-Optimus-0 (TAPFM) outperforming the benchmarks. TAPFM effectively handles multi-label classification of actionable mutations as well. Thus, TAPFM makes adaptation of powerful pre-trained PFMs practical on standard hardware for various clinical applications. </p>
<blockquote>
<p>ç—…ç†å­¦åŸºç¡€æ¨¡å‹ï¼ˆPFMsï¼‰ä½œä¸ºåˆ†æå…¨åˆ‡ç‰‡å›¾åƒï¼ˆWSIsï¼‰çš„å¼ºå¤§å·¥å…·å·²ç»å‡ºç°ã€‚ç„¶è€Œï¼Œå°†è¿™äº›é¢„è®­ç»ƒçš„PFMsé€‚åº”äºç‰¹å®šçš„ä¸´åºŠä»»åŠ¡å´é¢ä¸´å·¨å¤§æŒ‘æˆ˜ï¼Œè¿™ä¸»è¦æ˜¯å› ä¸ºå¯¹äºgigapixelå›¾åƒåªæœ‰è¾ƒå¼±çš„ï¼ˆWSIçº§åˆ«ï¼‰æ ‡ç­¾å¯ç”¨ï¼Œéœ€è¦è¿›è¡Œå¤šæ¬¡å®ä¾‹å­¦ä¹ ï¼ˆMILï¼‰æ¨¡å¼æ‰èƒ½è¿›è¡Œæœ‰æ•ˆçš„WSIåˆ†æã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°å‹çš„å•GPUä»»åŠ¡é€‚åº”PFMï¼ˆTAPFMï¼‰æ–¹æ³•ï¼Œè¯¥æ–¹æ³•ä½¿ç”¨è§†è§‰è½¬æ¢å™¨ï¼ˆ\vitï¼‰æ³¨æ„åŠ›è¿›è¡ŒMILèšåˆï¼ŒåŒæ—¶ä¼˜åŒ–ç‰¹å¾è¡¨ç¤ºå’Œæ³¨æ„åŠ›æƒé‡ã€‚æ‰€æå‡ºçš„æ–¹æ³•ä¸ºMILèšåˆå™¨å’ŒPFMä¿æŒå•ç‹¬çš„è®¡ç®—å›¾ï¼Œä»¥åˆ›å»ºç¨³å®šçš„è®­ç»ƒåŠ¨æ€ï¼Œåœ¨ç«¯åˆ°ç«¯é€‚åº”è¿‡ç¨‹ä¸­ä¸ä¸‹æ¸¸ä»»åŠ¡ç›®æ ‡ä¿æŒä¸€è‡´ã€‚åœ¨è†€èƒ±ç™Œå’Œè‚ºè…ºç™Œçš„çªå˜é¢„æµ‹ä»»åŠ¡ä¸Šï¼ŒTAPFMå§‹ç»ˆä¼˜äºä¼ ç»Ÿæ–¹æ³•ï¼Œå…¶ä¸­H-Optimus-0ï¼ˆTAPFMï¼‰è¶…è¿‡äº†åŸºå‡†æµ‹è¯•ã€‚TAPFMè¿˜èƒ½æœ‰æ•ˆåœ°å¤„ç†å¯æ“ä½œçªå˜çš„å¤šæ ‡ç­¾åˆ†ç±»ã€‚å› æ­¤ï¼ŒTAPFMä½¿åœ¨æ ‡å‡†ç¡¬ä»¶ä¸Šé€‚åº”å¼ºå¤§çš„é¢„è®­ç»ƒPFMså¯¹äºå„ç§ä¸´åºŠåº”ç”¨å˜å¾—å®ç”¨ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.05184v1">PDF</a> </p>
<p><strong>Summary</strong><br>     è®ºæ–‡ä»‹ç»äº†é’ˆå¯¹åŒ»å­¦å›¾åƒåˆ†æä¸­çš„ç—…ç†åŸºç¡€æ¨¡å‹ï¼ˆPFMsï¼‰çš„ä»»åŠ¡é€‚åº”æ€§æ–¹æ³•ã€‚ç”±äºå¼±æ ‡ç­¾ï¼ˆWSIçº§åˆ«ï¼‰å’Œè®¡ç®—èµ„æºé™åˆ¶çš„æŒ‘æˆ˜ï¼Œè¯¥è®ºæ–‡æå‡ºäº†ä¸€ç§åœ¨å•GPUä¸Šè¿›è¡ŒPFMä»»åŠ¡é€‚åº”ï¼ˆTAPFMï¼‰çš„æ–°æ–¹æ³•ã€‚è¯¥æ–¹æ³•ä½¿ç”¨è§†è§‰Transformerï¼ˆViTï¼‰æ³¨æ„åŠ›è¿›è¡Œå¤šå®ä¾‹å­¦ä¹ ï¼ˆMILï¼‰èšåˆï¼ŒåŒæ—¶ä¼˜åŒ–ç‰¹å¾è¡¨ç¤ºå’Œæ³¨æ„åŠ›æƒé‡ã€‚TAPFMåœ¨ä¸åŒæœºæ„åŠTCGAé˜Ÿåˆ—çš„çªå˜é¢„æµ‹ä»»åŠ¡ä¸­è¡¨ç°ä¼˜è¶Šï¼Œå¹¶å¯æœ‰æ•ˆå¤„ç†å¤šæ ‡ç­¾åˆ†ç±»çš„çªå˜ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>PFMsåœ¨WSIåˆ†æä¸­å…·æœ‰å¼ºå¤§çš„æ½œåŠ›ï¼Œä½†é’ˆå¯¹ç‰¹å®šä¸´åºŠä»»åŠ¡è¿›è¡Œé€‚åº”é¢ä¸´æŒ‘æˆ˜ã€‚</li>
<li>ç”±äºå¼±æ ‡ç­¾å’Œè®¡ç®—èµ„æºé™åˆ¶ï¼Œéœ€è¦å¼€å‘æ–°çš„æ–¹æ³•æ¥è¿›è¡Œä»»åŠ¡é€‚åº”ã€‚</li>
<li>TAPFMæ–¹æ³•ç»“åˆäº†è§†è§‰Transformerï¼ˆViTï¼‰æ³¨æ„åŠ›ä¸å¤šå®ä¾‹å­¦ä¹ ï¼ˆMILï¼‰èšåˆï¼Œä¼˜åŒ–ç‰¹å¾è¡¨ç¤ºå’Œæ³¨æ„åŠ›æƒé‡ã€‚</li>
<li>TAPFMé€šè¿‡ç»´æŒç‹¬ç«‹çš„è®¡ç®—å›¾è¿›è¡ŒMILèšåˆå™¨å’ŒPFMçš„ä¼˜åŒ–ï¼Œå®ç°ç¨³å®šçš„è®­ç»ƒåŠ¨æ€ï¼Œä¸ä¸‹æ¸¸ä»»åŠ¡ç›®æ ‡å¯¹é½ã€‚</li>
<li>TAPFMåœ¨çªå˜é¢„æµ‹ä»»åŠ¡ä¸­è¡¨ç°ä¼˜è¶Šï¼Œèƒ½å¤Ÿæœ‰æ•ˆå¤„ç†å¤šæ ‡ç­¾åˆ†ç±»é—®é¢˜ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.05184">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-8b16efa91c6b39087908ac297e2b48c4.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-547dc48bf99f44a838d9eda8fe4f6965.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="Statistical-microlocal-analysis-in-two-dimensional-X-ray-CT"><a href="#Statistical-microlocal-analysis-in-two-dimensional-X-ray-CT" class="headerlink" title="Statistical microlocal analysis in two-dimensional X-ray CT"></a>Statistical microlocal analysis in two-dimensional X-ray CT</h2><p><strong>Authors:Anuj Abhishek, Alexander Katsevich, James W. Webber</strong></p>
<p>In many imaging applications it is important to assess how well the edges of the original object, $f$, are resolved in an image, $f^\text{rec}$, reconstructed from the measured data, $g$. In this paper we consider the case of image reconstruction in 2D X-ray Computed Tomography (CT). Let $f$ be a function describing the object being scanned, and $g&#x3D;Rf + \eta$ be the Radon transform data in $\mathbb{R}^2$ corrupted by noise, $\eta$, and sampled with step size $\sim\epsilon$. Conventional microlocal analysis provides conditions for edge detectability based on the scanner geometry in the case of continuous, noiseless data (when $\eta &#x3D; 0$), but does not account for noise and finite sampling step size. We develop a novel technique called \emph{Statistical Microlocal Analysis} (SMA), which uses a statistical hypothesis testing framework to determine if an image edge (singularity) of $f$ is detectable from $f^\text{rec}$, and we quantify edge detectability using the statistical power of the test. Our approach is based on the theory we developed in \cite{AKW2024_1}, which provides a characterization of $f^\text{rec}$ in local $O(\epsilon)$-size neighborhoods when $\eta \neq 0$. We derive a statistical test for the presence and direction of an edge microlocally given the magnitude of $\eta$ and data sampling step size. Using the properties of the null distribution of the test, we quantify the uncertainty of the edge magnitude and direction. We validate our theory using simulations, which show strong agreement between our predictions and experimental observations. Our work is not only of practical value, but of theoretical value as well. SMA is a natural extension of classical microlocal analysis theory which accounts for practical measurement imperfections, such as noise and finite step size, at the highest possible resolution compatible with the data. </p>
<blockquote>
<p>åœ¨è®¸å¤šæˆåƒåº”ç”¨ä¸­ï¼Œè¯„ä¼°åŸå§‹å¯¹è±¡$ f $çš„è¾¹ç¼˜åœ¨ç”±æµ‹é‡æ•°æ®$ g $é‡å»ºçš„å›¾åƒ$ f^\text{rec} $ä¸­æ¢å¤å¾—å¦‚ä½•éå¸¸é‡è¦ã€‚æœ¬æ–‡è€ƒè™‘äºŒç»´Xå°„çº¿è®¡ç®—æœºæ–­å±‚æ‰«æï¼ˆCTï¼‰ä¸­çš„å›¾åƒé‡å»ºæƒ…å†µã€‚è®¾$ f $ä¸ºæè¿°è¢«æ‰«æå¯¹è±¡çš„å‡½æ•°ï¼Œ$ g&#x3D;Rf+\eta $ä¸ºå—åˆ°å™ªå£°$ \eta $å½±å“çš„ Radon å˜æ¢æ•°æ®åœ¨$ \mathbb{R}^2 $ä¸­çš„è¡¨ç¤ºï¼Œå¹¶ä¸”ä»¥æ­¥é•¿$ \sim\epsilon $è¿›è¡Œé‡‡æ ·ã€‚ä¼ ç»Ÿçš„å¾®å±€éƒ¨åˆ†æä¸ºè¿ç»­ä¸”æ— å™ªå£°æ•°æ®ï¼ˆå½“$ \eta &#x3D; euver 0 $æ—¶ï¼‰çš„æƒ…å†µæä¾›äº†åŸºäºæ‰«æä»ªå‡ ä½•çš„è¾¹ç¼˜æ£€æµ‹æ¡ä»¶ï¼Œä½†å®ƒæ²¡æœ‰è€ƒè™‘åˆ°å™ªå£°å’Œæœ‰é™çš„é‡‡æ ·æ­¥é•¿ã€‚æˆ‘ä»¬å¼€å‘äº†ä¸€ç§ç§°ä¸ºç»Ÿè®¡å¾®å±€éƒ¨åˆ†æï¼ˆSMAï¼‰çš„æ–°æŠ€æœ¯ï¼Œå®ƒä½¿ç”¨ç»Ÿè®¡å‡è®¾æ£€éªŒæ¡†æ¶æ¥ç¡®å®šæ˜¯å¦å¯ä»¥ä»$ f^\text{rec} $æ£€æµ‹å›¾åƒè¾¹ç¼˜ï¼ˆå¥‡å¼‚æ€§ï¼‰ï¼Œå¹¶ä¸”æˆ‘ä»¬ä½¿ç”¨æ£€éªŒçš„ç»Ÿè®¡æ•ˆåŠ›æ¥é‡åŒ–è¾¹ç¼˜æ£€æµ‹èƒ½åŠ›ã€‚æˆ‘ä»¬çš„æ–¹æ³•åŸºäºæˆ‘ä»¬åœ¨\cite{AKW2024_1}ä¸­å¼€å‘çš„ç†è®ºï¼Œè¯¥ç†è®ºåœ¨$ \eta \neq 0 $æ—¶æè¿°äº†å±€éƒ¨$ O(\epsilon) $-å¤§å°é‚»åŸŸä¸­çš„$ f^\text{rec} $çš„ç‰¹å¾ã€‚æˆ‘ä»¬æ ¹æ®$ \eta $çš„å¹…åº¦å’Œæ•°æ®é‡‡æ ·æ­¥é•¿æ¨å¯¼å‡ºæ˜¯å¦å­˜åœ¨è¾¹ç¼˜ä»¥åŠå…¶æ–¹å‘çš„ç»Ÿè®¡æ£€éªŒã€‚åˆ©ç”¨æ£€éªŒçš„ç©ºåˆ†å¸ƒå±æ€§ï¼Œæˆ‘ä»¬é‡åŒ–äº†è¾¹ç¼˜å¹…åº¦å’Œæ–¹å‘çš„ä¸ç¡®å®šæ€§ã€‚æˆ‘ä»¬é€šè¿‡æ¨¡æ‹ŸéªŒè¯äº†æˆ‘ä»¬çš„ç†è®ºï¼Œæ¨¡æ‹Ÿç»“æœä¸æˆ‘ä»¬é¢„æµ‹çš„ç»“æœå»åˆè‰¯å¥½ã€‚æˆ‘ä»¬çš„å·¥ä½œä¸ä»…å…·æœ‰å®ç”¨ä»·å€¼ï¼Œè€Œä¸”å…·æœ‰ç†è®ºä»·å€¼ã€‚SMAæ˜¯ç»å…¸å¾®å±€éƒ¨åˆ†æç†è®ºçš„è‡ªç„¶æ‰©å±•ï¼Œå®ƒè€ƒè™‘äº†å®é™…æµ‹é‡ä¸­çš„ä¸å®Œç¾ä¹‹å¤„ï¼Œä¾‹å¦‚å™ªå£°å’Œæœ‰é™çš„æ­¥é•¿ï¼Œå¹¶ä¸”æ˜¯åœ¨ä¸æ•°æ®å…¼å®¹çš„æœ€é«˜å¯èƒ½åˆ†è¾¨ç‡ä¸‹è¿›è¡Œçš„ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.05113v1">PDF</a> 27 pages, 13 figures</p>
<p><strong>æ‘˜è¦</strong></p>
<p>åœ¨å›¾åƒé‡å»ºè¿‡ç¨‹ä¸­ï¼Œè¾¹ç¼˜è§£æèƒ½åŠ›å°¤ä¸ºé‡è¦ã€‚æœ¬æ–‡ç ”ç©¶äº†äºŒç»´Xå°„çº¿è®¡ç®—æœºæ–­å±‚æ‰«æï¼ˆCTï¼‰ä¸­çš„å›¾åƒé‡å»ºé—®é¢˜ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§åä¸ºç»Ÿè®¡å¾®å±€éƒ¨åˆ†æï¼ˆSMAï¼‰çš„æ–°æŠ€æœ¯ï¼Œè¯¥æŠ€æœ¯ä½¿ç”¨ç»Ÿè®¡å‡è®¾æ£€éªŒæ¡†æ¶æ¥ç¡®å®šä»é‡å»ºå›¾åƒä¸­æ˜¯å¦å¯æ£€æµ‹åŸå§‹å¯¹è±¡çš„è¾¹ç¼˜ï¼ˆå¥‡ç‚¹ï¼‰ã€‚æˆ‘ä»¬çš„æ–¹æ³•åŸºäºæ–‡çŒ®ä¸­çš„ç†è®ºï¼Œè¯¥ç†è®ºæè¿°äº†å½“å­˜åœ¨å™ªå£°æ—¶ï¼Œåœ¨å±€éƒ¨Îµå¤§å°é‚»åŸŸå†…é‡å»ºå›¾åƒçš„è¡¨å¾ã€‚æˆ‘ä»¬é’ˆå¯¹è¾¹ç¼˜çš„å­˜åœ¨å’Œæ–¹å‘æ¨å¯¼äº†ä¸€ä¸ªç»Ÿè®¡æµ‹è¯•ï¼Œç»™å®šå™ªå£°å¹…åº¦å’Œæ•°æ®é‡‡æ ·æ­¥é•¿ã€‚åˆ©ç”¨æµ‹è¯•çš„ç©ºåˆ†å¸ƒå±æ€§ï¼Œæˆ‘ä»¬å¯¹è¾¹ç¼˜å¹…åº¦å’Œæ–¹å‘çš„ä¸ç¡®å®šæ€§è¿›è¡Œäº†é‡åŒ–ã€‚é€šè¿‡æ¨¡æ‹ŸéªŒè¯äº†æˆ‘ä»¬çš„ç†è®ºï¼Œæ¨¡æ‹Ÿç»“æœä¸æˆ‘ä»¬é¢„æµ‹çš„ç»“æœå»åˆè‰¯å¥½ã€‚æˆ‘ä»¬çš„å·¥ä½œä¸ä»…å…·æœ‰å®ç”¨ä»·å€¼ï¼Œè¿˜å…·æœ‰ç†è®ºä»·å€¼ã€‚ä½œä¸ºå¯¹ç»å…¸å¾®å±€éƒ¨åˆ†æç†è®ºçš„è‡ªç„¶æ‰©å±•ï¼ŒSMAèƒ½å¤Ÿè€ƒè™‘å®è·µä¸­çš„æµ‹é‡ä¸å®Œç¾ï¼Œå¦‚å™ªå£°å’Œæœ‰é™çš„æ­¥é•¿ï¼Œåœ¨å…¼å®¹æ•°æ®çš„æœ€é«˜åˆ†è¾¨ç‡ä¸‹è¿›è¡Œåˆ†æã€‚</p>
<p><strong>å…³é”®è§è§£</strong></p>
<ol>
<li>åœ¨å›¾åƒé‡å»ºè¿‡ç¨‹ä¸­è¯„ä¼°è¾¹ç¼˜è§£æèƒ½åŠ›è‡³å…³é‡è¦ã€‚</li>
<li>æå‡ºäº†ç»Ÿè®¡å¾®å±€éƒ¨åˆ†æï¼ˆSMAï¼‰æ–°æŠ€æœ¯ï¼Œè¯¥æŠ€æœ¯åˆ©ç”¨ç»Ÿè®¡å‡è®¾æ£€éªŒæ¡†æ¶æ¥æ£€æµ‹å›¾åƒè¾¹ç¼˜ã€‚</li>
<li>åŸºäºç°æœ‰ç†è®ºï¼Œç ”ç©¶äº†å™ªå£°å­˜åœ¨æ—¶çš„å›¾åƒè¡¨å¾é—®é¢˜ã€‚</li>
<li>å¯¼å‡ºäº†é’ˆå¯¹è¾¹ç¼˜å­˜åœ¨å’Œæ–¹å‘çš„ç»Ÿè®¡æµ‹è¯•ï¼Œè€ƒè™‘äº†å™ªå£°å¹…åº¦å’Œæ•°æ®é‡‡æ ·æ­¥é•¿ã€‚</li>
<li>åˆ©ç”¨æµ‹è¯•çš„åˆ†å¸ƒå±æ€§å¯¹è¾¹ç¼˜å¹…åº¦å’Œæ–¹å‘çš„ä¸ç¡®å®šæ€§è¿›è¡Œé‡åŒ–ã€‚</li>
<li>é€šè¿‡æ¨¡æ‹ŸéªŒè¯äº†ç†è®ºçš„æ­£ç¡®æ€§ï¼Œæ¨¡æ‹Ÿç»“æœä¸é¢„æµ‹ç›¸ç¬¦ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.05113">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-7adff853edc219e9caf4ca73f75da115.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="Wind-fed-Supermassive-Black-Hole-Accretion-by-the-Nuclear-Star-Cluster-the-Case-of-M31"><a href="#Wind-fed-Supermassive-Black-Hole-Accretion-by-the-Nuclear-Star-Cluster-the-Case-of-M31" class="headerlink" title="Wind-fed Supermassive Black Hole Accretion by the Nuclear Star Cluster:   the Case of M31*"></a>Wind-fed Supermassive Black Hole Accretion by the Nuclear Star Cluster:   the Case of M31*</h2><p><strong>Authors:Zhao Su, Zhiyuan Li, Zongnan Li</strong></p>
<p>The central supermassive black hole (SMBH) of the Andromeda galaxy, known as M31*, exhibits dim electromagnetic emission and is inferred to have an extremely low accretion rate for its remarkable mass ($\sim10^8<del>\rm</del>M_\odot$). In this work, we use three-dimensional hydrodynamical simulations to explore a previously untested scenario, in which M31* is fed by the collective stellar mass-loss from its surrounding nuclear star cluster, manifested as a famous eccentric disk of predominantly old stellar populations. The stellar mass-loss is assumed to be dominated by the slow and cold winds from 100 asymptotic giant-branch stars, which follow well-constrained Keplerian orbits around M31* and together provide a mass injection rate of $\sim4\times10^{-5}\rm<del>M_\odot</del>yr^{-1}$. The simulations achieve a quasi-steady state on a Myr timescale, at which point a quasi-Keplerian, cool ($T\sim10^3-10^4<del>\rm K$) gas disk extending several parsecs is established. This disk is continuously supplied by the stellar winds and itself feeds the central SMBH. At the end of the simulations at 2 Myr, an accretion rate of $\sim2\times10^{-5}\rm</del>M_\odot<del>yr^{-1}$ is found but could vary by a factor of few depending on whether the subdominant gravity of the NSC or a moderate global inflow is included. The predicted X-ray luminosity of $\sim10^{36}</del>\rm erg<del>s^{-1}$, dominated by the hot ($T\sim10^7-10^8</del>\rm K$) plasma within 0.2 parsec of the SMBH, is well consistent with Chandra observations. We conclude that the feeding mechanism of M31* is successfully identified, which has important implications for the working of dormant SMBHs prevalent in the local universe. </p>
<blockquote>
<p>ä»™å¥³æ˜Ÿç³»ä¸­å¤®çš„å·¨å¤§é»‘æ´ï¼ˆSMBHï¼‰ï¼Œè¢«ç§°ä¸ºM31<em>ï¼Œè¡¨ç°å‡ºå¾®å¼±çš„ç”µç£å‘å°„ï¼Œæ ¹æ®å…¶æ˜¾è‘—è´¨é‡ï¼ˆçº¦ä¸º$10^8$ MâŠ™ï¼‰ï¼Œæ¨æ–­å…¶å¸ç§¯ç‡æä½ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨ä¸‰ç»´æµä½“åŠ¨åŠ›å­¦æ¨¡æ‹Ÿæ¥æ¢ç´¢ä¸€ä¸ªå…ˆå‰æœªç»æµ‹è¯•çš„åœºæ™¯ï¼Œå³M31</em>å—åˆ°å‘¨å›´æ ¸æ˜Ÿå›¢é›†ä½“æ’æ˜Ÿè´¨é‡æŸå¤±çš„æ»‹å…»ï¼Œè¡¨ç°ä¸ºè‘—åçš„åå¿ƒç›˜ï¼Œä¸»è¦ç”±è€å¹´æ’æ˜Ÿç»„æˆã€‚å‡è®¾æ’æ˜Ÿè´¨é‡æŸå¤±ä¸»è¦ç”±æ¥è‡ªçº¦100é¢—æ¸è¿‘å·¨æ˜Ÿåˆ†æ”¯çš„ç¼“æ…¢ä¸”å†·é£ä¸»å¯¼ï¼Œå®ƒä»¬åœ¨M31å‘¨å›´éµå¾ªä¸¥æ ¼çš„å¼€æ™®å‹’è½¨é“è¿åŠ¨ï¼Œå¹¶å…±åŒæä¾›çº¦$4\times10^{-5}$ MâŠ™ å¹´^{-1}çš„è´¨é‡æ³¨å…¥é€Ÿç‡ã€‚æ¨¡æ‹Ÿåœ¨ç™¾ä¸‡å¹´å°ºåº¦ä¸Šè¾¾åˆ°å‡†ç¨³æ€ï¼Œæ­¤æ—¶å»ºç«‹äº†ä¸€ä¸ªå»¶ä¼¸è‡³æ•°å¸•çš„å‡†å¼€æ™®å‹’ã€æ¸©åº¦çº¦ä¸º$10^3-10^4$ Kçš„å†·æ°”ä½“ç›˜ã€‚è¿™ä¸ªç›˜å­æŒç»­ç”±æ’æ˜Ÿé£ä¾›åº”ï¼Œæœ¬èº«åˆæ»‹å…»ç€ä¸­å¤®çš„è¶…å¤§è´¨é‡é»‘æ´ã€‚åœ¨æ¨¡æ‹Ÿçš„æœ€åé˜¶æ®µä¸ºä¸¤ç™¾ä¸‡å¹´ç»“æŸæ—¶ï¼Œå‘ç°å¸ç§¯ç‡çº¦ä¸º$\sim2\times10^{-5}$ MâŠ™ å¹´^{-1}ï¼Œä½†æ ¹æ®æ˜¯å¦è€ƒè™‘æ ¸çƒæ¬¡è¦çš„å¼•åŠ›æˆ–é€‚åº¦çš„å…¨å±€æµå…¥ï¼Œè¿™ä¸€æ•°å€¼å¯èƒ½ä¼šæœ‰æ•°å€çš„å·®å¼‚ã€‚é¢„æµ‹çš„åœ¨é»‘æ´å‰è·ç¦»å†…äº§ç”Ÿçš„çº¦ä¸º$\sim10^{36}$ergç§’^{-1}çš„Xå°„çº¿å…‰åº¦ç”±æ¸©åº¦ä¸º$T\sim è®¾å®šä¸ºç¬¦å·æ ‡æ³¨çš„å…³é”®å†…å®¹â„ƒ ä¸ç®€åŒ–çš„ç»“æœå’Œé˜è¿°ç›¸åº”çš„ä¸Šä¸‹æ–‡ç´§å¯†ç›¸è¿å³ ä¸ªå¯èƒ½çš„è¯´æ³•ç›¸ä¼¼ç›¸ç¬¦ç»“åˆå¯¹äºçŸ¥è¯†éƒ¨åˆ†ç‰¹å®šæƒ…å†µä¸‹è¾¾æˆæ²Ÿé€šæä¾›åŸºæœ¬å‡†å¤‡é…åˆè¡Œä¸ºæ˜¾ç¤ºå‡ºå†…å¿ƒå½“ä¸­çš„æ€è·¯å˜æ¸…æ–°çš„æœºåˆ¶ç»“æ„å°†å¯¹æ˜ç¡®è¿‡ç¨‹çš„æ·±å±‚æ¬¡ç»“æ„å¹¶å®ç°æ‰€æœ‰å¿…éœ€çš„å…ƒè¡Œä¸ºä½“éªŒå…·æœ‰è‰¯å¥½çš„æ¨åŠ¨åŠ›ä»è€Œä½¿æ··ä¹±ä¸æ˜ä¸ç®€æ´çš„ä¸»ä½“ä¸»åŠ¨å‘ˆç°å¹¶æ¿€å‘ä¸»ä½“å†…éƒ¨çš„ç»“æ„å’Œè¿‡ç¨‹æ„è¯†ä¸ºå®Œæˆè‡ªæˆ‘æ›´æ–°å’Œé‡å¡‘åšå¥½å‡†å¤‡å¯¹é—®é¢˜çš„æœ¬è´¨å’Œæ·±åº¦çš„åæ€å¡‘é€ æ›´ä½³çš„ç‹¬ç«‹æˆæœçš„å¯èƒ½æ¢å¥è¯è¯´ç§‘å­¦çš„å¯è¡Œæ€§è§£æåŠ›é‡å€Ÿä»¥æ¥é©¾é©­æˆå°±ä¸°åšçš„è‰¯å¥½è¡¨è¾¾æ–¹å¼è¿™æ­£æ˜¯æŒ‡å¯¼æœåŠ¡å®ä½“çš„å§‹ç»ˆå¼•åŠ›ä»è€Œå¯¹æ‰“å¼€ä»¥åè¾¹ç•Œå’Œæœªæ¥çš„å¯èƒ½æ€§æä¾›æŒ‡å¼•å¹¶æ¨åŠ¨ç§‘å­¦çš„è¿›æ­¥å’Œå‘å±•å…·æœ‰æ·±è¿œæ„ä¹‰ç®€åŒ–é—®é¢˜æœ¬è´¨æ­ç¤ºé—®é¢˜æ ¸å¿ƒæ˜ç¡®é—®é¢˜ç»“æ„å®ç°è‡ªæˆ‘è¶…è¶Šåœ¨ç§‘ç ”å·¥ä½œä¸­å…·æœ‰æ·±è¿œå½±å“åœ¨ä»™å¥³æ˜Ÿç³»ä¸­å¤®è¶…å¤§è´¨é‡é»‘æ´çš„ç§‘å­¦æ¢ç´¢ä¸­å¼€è¾Ÿäº†ä¸€æ¡æ–°çš„è·¯å¾„ã€‚\nç®€åŒ–åï¼š\nä»™å¥³æ˜Ÿç³»çš„è¶…å¤§è´¨é‡é»‘æ´ï¼ˆSMBHï¼‰M31*å¸ç§¯ç‡æä½ï¼Œä½†å…¶å‘¨å›´çš„æ’æ˜Ÿé£ä¸ºå…¶æä¾›äº†è´¨é‡æ¥æºã€‚ä¸‰ç»´æµä½“åŠ¨åŠ›å­¦æ¨¡æ‹Ÿæ˜¾ç¤ºï¼Œè¿™äº›æ’æ˜Ÿé£å½¢æˆå†·æ°”ä½“ç›˜æ»‹å…»é»‘æ´ã€‚æ¨¡æ‹Ÿé¢„æµ‹Xå°„çº¿å…‰åº¦ä¸è§‚æµ‹ç›¸ç¬¦ï¼Œè¡¨æ˜è¿™ç§å–‚å…»æœºåˆ¶æ˜¯æœ‰æ•ˆçš„ã€‚è¿™æœ‰åŠ©äºç†è§£æœ¬åœ°å®‡å®™ä¸­ä¼‘çœ SMBHçš„å·¥ä½œæ–¹å¼ã€‚\nè§£é‡Šï¼š\næœ¬ç ”ç©¶åˆ©ç”¨æ¨¡æ‹Ÿæ­ç¤ºäº†ä»™å¥³æ˜Ÿç³»ä¸­è¶…å¤§è´¨é‡é»‘æ´çš„æ–°å–‚å…»æœºåˆ¶ï¼šå‘¨å›´çš„æ’æ˜Ÿé£å½¢æˆæ°”ä½“ç›˜æ»‹å…»é»‘æ´ã€‚é¢„æµ‹ä¸è§‚æµ‹ç›¸ç¬¦ï¼Œæ­¤æœºåˆ¶å¯¹ç†è§£æœ¬åœ°å®‡å®™ä¸­ä¼‘çœ SMBHæœ‰é‡è¦æ„ä¹‰ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.04778v1">PDF</a> 15 pages, 5 figures. Accepted by ApJ</p>
<p><strong>Summary</strong></p>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.04778">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-476fa373d3e880253109a2be3d18f6b4.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-caf1ffd7b63e560cd2178a21040e0d0c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-4524feacdc4d40f81b46664d921e2625.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="Diffusion-Tensor-MRI-and-Spherical-Deconvolution-Based-Tractography-on-an-Ultra-Low-Field-Portable-MRI-System"><a href="#Diffusion-Tensor-MRI-and-Spherical-Deconvolution-Based-Tractography-on-an-Ultra-Low-Field-Portable-MRI-System" class="headerlink" title="Diffusion Tensor MRI and Spherical-Deconvolution-Based Tractography on   an Ultra-Low Field Portable MRI System"></a>Diffusion Tensor MRI and Spherical-Deconvolution-Based Tractography on   an Ultra-Low Field Portable MRI System</h2><p><strong>Authors:James Gholam, Phil Schmid, Joshua Ametepe, Alix Plumley, Leandro Beltrachini, Francesco Padormo, Rui Teixeira, Rafael OHalloran, Kaloian Petkov, Klaus Engel, Steven CR Williams, Sean Deoni, Mara Cercignani, Derek K Jones</strong></p>
<p>Ultra-low-field (ULF) MRI is emerging as an alternative modality to high-field (HF) MRI due to its lower cost, minimal siting requirements, portability, and enhanced accessibility factors that enable large-scale deployment. Although ULF-MRI exhibits lower signal-to-noise ratio (SNR), advanced imaging and data-driven denoising methods enabled by high-performance computing have made contrasts like diffusion-weighted imaging (DWI) feasible at ULF. This study investigates the potential and limitations of ULF tractography, using data acquired on a 0.064 T commercially available mobile point-of-care MRI scanner. The results demonstrate that most major white matter bundles can be successfully retrieved in healthy adult brains within clinically tolerable scan times. This study also examines the recovery of diffusion tensor imaging (DTI)-derived scalar maps, including fractional anisotropy and mean diffusivity. Strong correspondence is observed between scalar maps obtained with ULF-MRI and those acquired at high field strengths. Furthermore, fibre orientation distribution functions reconstructed from ULF data show good agreement with high-field references, supporting the feasibility of using ULF-MRI for reliable tractography. These findings open new opportunities to use ULF-MRI in studies of brain health, development, and disease progression particularly in populations traditionally underserved due to geographic or economic constraints. The results show that robust assessments of white matter microstructure can be achieved with ULF-MRI, effectively democratising microstructural MRI and extending advanced imaging capabilities to a broader range of research and clinical settings where resources are typically limited. </p>
<blockquote>
<p>è¶…ä½åœºï¼ˆULFï¼‰MRIå› å…¶æˆæœ¬è¾ƒä½ã€åœºåœ°è¦æ±‚å°ã€ä¾¿æºæ€§å¼ºå’Œæ˜“äºæ™®åŠç­‰å› ç´ ï¼Œæ­£é€æ¸æˆä¸ºé«˜åœºï¼ˆHFï¼‰MRIçš„ä¸€ç§æ›¿ä»£æ¨¡å¼ï¼Œä»è€Œå®ç°å¤§è§„æ¨¡éƒ¨ç½²ã€‚å°½ç®¡ULF-MRIçš„ä¿¡å™ªæ¯”ï¼ˆSNRï¼‰è¾ƒä½ï¼Œä½†é«˜æ€§èƒ½è®¡ç®—èµ‹èƒ½çš„å…ˆè¿›æˆåƒå’ŒåŸºäºæ•°æ®å»å™ªæ–¹æ³•ä½¿å¾—æ‰©æ•£åŠ æƒæˆåƒï¼ˆDWIï¼‰ç­‰å¯¹æ¯”æˆä¸ºå¯èƒ½ã€‚æœ¬ç ”ç©¶ä½¿ç”¨ä¸€å°å•†ç”¨ç§»åŠ¨å¼åŒ»ç–—ç‚¹MRIæ‰«æä»ªï¼ˆåœºå¼ºä¸º0.064Tï¼‰é‡‡é›†çš„æ•°æ®ï¼Œæ¢è®¨äº†ULF tractographyçš„æ½œåŠ›å’Œå±€é™æ€§ã€‚ç»“æœè¡¨æ˜ï¼Œåœ¨å¯æ¥å—çš„æ‰«ææ—¶é—´å†…ï¼Œå¯åœ¨æˆäººå¥åº·å¤§è„‘å†…æˆåŠŸæ£€ç´¢åˆ°å¤§å¤šæ•°ä¸»è¦ç™½è´¨æŸã€‚è¯¥ç ”ç©¶è¿˜æ¢è®¨äº†æ‰©æ•£å¼ é‡æˆåƒï¼ˆDTIï¼‰è¡ç”Ÿçš„æ ‡é‡å›¾çš„æ¢å¤æƒ…å†µï¼ŒåŒ…æ‹¬éƒ¨åˆ†å˜å¼‚æ€§å’Œå¹³å‡æ‰©æ•£æ€§ã€‚åœ¨ULF-MRIä¸å¼ºç£åœºä¸‹è·å¾—çš„æ ‡é‡å›¾ä¹‹é—´è§‚å¯Ÿåˆ°å¼ºçƒˆçš„å¯¹åº”å…³ç³»ã€‚æ­¤å¤–ï¼Œç”±ULFæ•°æ®é‡å»ºçš„çº¤ç»´æ–¹å‘åˆ†å¸ƒå‡½æ•°ä¸é«˜åœºå‚è€ƒç»“æœå…·æœ‰è‰¯å¥½çš„ä¸€è‡´æ€§ï¼Œæ”¯æŒä½¿ç”¨ULF-MRIè¿›è¡Œå¯é çš„tractographyçš„å¯è¡Œæ€§ã€‚è¿™äº›å‘ç°ä½¿å¾—åœ¨åœ°ç†æˆ–ç»æµçº¦æŸçš„ä¼ ç»Ÿä¸Šè¢«å¿½è§†çš„äººç¾¤ä¸­ï¼Œä½¿ç”¨ULF-MRIç ”ç©¶å¤§è„‘å¥åº·ã€å‘è‚²å’Œç–¾ç—…è¿›å±•æä¾›äº†æ–°çš„æœºä¼šã€‚ç»“æœè¡¨æ˜ï¼Œä½¿ç”¨ULF-MRIå¯ä»¥å®ç°ç¨³å¥çš„ç™½è´¨å¾®è§‚ç»“æ„è¯„ä¼°ï¼Œæœ‰æ•ˆåœ°æ™®åŠå¾®è§‚ç»“æ„MRIï¼Œå¹¶å°†å…ˆè¿›çš„æˆåƒèƒ½åŠ›æ‰©å±•åˆ°èµ„æºå’Œæ¡ä»¶é€šå¸¸æœ‰é™çš„æ›´å¹¿æ³›çš„ç ”ç©¶å’Œä¸´åºŠç¯å¢ƒä¸­ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.04473v1">PDF</a> </p>
<p><strong>Summary</strong><br>     è¶…ä½åœºï¼ˆULFï¼‰MRIå› æˆæœ¬ä½ã€åœºåœ°è¦æ±‚ä½ã€ä¾¿æºæ€§å¼ºã€æ™®åŠæ€§å¹¿ç­‰ä¼˜ç‚¹ï¼Œæ­£æˆä¸ºé«˜åœºï¼ˆHFï¼‰MRIçš„ä¸€ç§æ›¿ä»£æ¨¡å¼ï¼Œå¹¿æ³›åº”ç”¨äºå¤§è§„æ¨¡éƒ¨ç½²ã€‚å°½ç®¡ULF-MRIä¿¡å™ªæ¯”ï¼ˆSNRï¼‰è¾ƒä½ï¼Œä½†é«˜æ€§èƒ½è®¡ç®—ä½¿æ‰©æ•£åŠ æƒæˆåƒï¼ˆDWIï¼‰ç­‰å¯¹æ¯”åº¦æˆåƒæˆä¸ºå¯èƒ½ã€‚æœ¬ç ”ç©¶é‡‡ç”¨å•†ç”¨å¯ç§»åŠ¨çš„ç‚¹åŒ»ç–—æŠ¤ç†MRIæ‰«æä»ªè¿›è¡ŒULFé€ å½±çš„æ½œåŠ›ä¸å±€é™æ€§åˆ†æã€‚ç»“æœæ˜¾ç¤ºï¼Œå¤§å¤šæ•°ä¸»è¦ç™½è´¨æŸå¯åœ¨ä¸´åºŠä¸Šå¯å®¹å¿çš„æ‰«ææ—¶é—´å†…æˆåŠŸæ£€ç´¢å‡ºæ¥ã€‚æ­¤å¤–ï¼Œæœ¬ç ”ç©¶è¿˜æ¢è®¨äº†æ‰©æ•£å¼ é‡æˆåƒï¼ˆDTIï¼‰è¡ç”Ÿçš„æ ‡é‡å›¾çš„æ¢å¤æƒ…å†µï¼ŒåŒ…æ‹¬åˆ†æ•°å¼‚å‘æ€§å’Œå¹³å‡æ‰©æ•£æ€§ã€‚ULF-MRIè·å¾—çš„æ ‡é‡å›¾ä¸é«˜åœºå¼ºä¸‹è·å¾—çš„æ ‡é‡å›¾ä¹‹é—´å­˜åœ¨å¾ˆå¼ºçš„å¯¹åº”å…³ç³»ã€‚çº¤ç»´å–å‘åˆ†å¸ƒå‡½æ•°ä»ULFæ•°æ®ä¸­é‡å»ºï¼Œä¸é«˜åœºå‚è€ƒæ•°æ®æœ‰å¾ˆå¥½çš„ä¸€è‡´æ€§ï¼Œè¯æ˜äº†ä½¿ç”¨ULF-MRIè¿›è¡Œå¯é é€ å½±çš„å¯è¡Œæ€§ã€‚è¿™äº›å‘ç°å¼€å¯äº†ä½¿ç”¨ULF-MRIç ”ç©¶å¤§è„‘å¥åº·ã€å‘è‚²å’Œç–¾ç—…è¿›å±•çš„æ–°æœºä¼šï¼Œå°¤å…¶æ˜¯åœ¨åœ°ç†æˆ–ç»æµçº¦æŸä¸‹ä¼ ç»Ÿä¸Šæ— æ³•è¦†ç›–çš„äººç¾¤ä¸­ã€‚ULF-MRIèƒ½å¤Ÿå®ç°ç¨³å¥çš„ç™½è´¨å¾®è§‚ç»“æ„è¯„ä¼°ï¼Œæœ‰æ•ˆæ™®åŠå¾®è§‚ç»“æ„MRIï¼Œå¹¶å°†å…ˆè¿›çš„æˆåƒèƒ½åŠ›æ‰©å±•åˆ°èµ„æºå’Œè®¾å¤‡é€šå¸¸æœ‰é™çš„æ›´å¹¿æ³›çš„ç§‘ç ”å’Œä¸´åºŠç¯å¢ƒä¸­ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ULF-MRIä½œä¸ºæ›¿ä»£é«˜åœºMRIçš„ä¸€ç§æ–°å…´æ¨¡å¼ï¼Œå…·æœ‰æˆæœ¬ä½ã€åœºåœ°è¦æ±‚ä½ã€ä¾¿æºæ€§å¼ºç­‰ä¼˜ç‚¹ï¼Œæœ‰åˆ©äºå¤§è§„æ¨¡éƒ¨ç½²ã€‚</li>
<li>è™½ç„¶ULF-MRIçš„ä¿¡å™ªæ¯”ä½ï¼Œä½†é€šè¿‡å…ˆè¿›æˆåƒå’Œæ•°æ®å¤„ç†æ–¹æ³•ä»å¯å®ç°é«˜è´¨é‡å¯¹æ¯”åº¦æˆåƒï¼Œå¦‚æ‰©æ•£åŠ æƒæˆåƒï¼ˆDWIï¼‰ã€‚</li>
<li>ç ”ç©¶ä½¿ç”¨å•†ç”¨å¯ç§»åŠ¨ç‚¹åŒ»ç–—æŠ¤ç†MRIæ‰«æä»ªè¿›è¡ŒULFé€ å½±åˆ†æï¼Œè¯æ˜å¤§å¤šæ•°ä¸»è¦ç™½è´¨æŸå¯åœ¨ä¸´åºŠå¯å®¹å¿æ—¶é—´å†…æˆåŠŸæ£€ç´¢ã€‚</li>
<li>ULF-MRIåœ¨æ¢å¤æ‰©æ•£å¼ é‡æˆåƒï¼ˆDTIï¼‰è¡ç”Ÿçš„æ ‡é‡å›¾æ–¹é¢è¡¨ç°å‡ºè‰¯å¥½çš„æ€§èƒ½ï¼Œä¸é«˜åœºå¼ºä¸‹è·å¾—çš„å›¾åƒå­˜åœ¨å¼ºçƒˆçš„å¯¹åº”å…³ç³»ã€‚</li>
<li>ULFæ•°æ®é‡å»ºçš„çº¤ç»´å–å‘åˆ†å¸ƒå‡½æ•°ä¸é«˜åœºå‚è€ƒæ•°æ®ä¸€è‡´ï¼Œè¯æ˜äº†ULF-MRIçš„å¯é æ€§ã€‚</li>
<li>ULF-MRIåœ¨å¤§è„‘å¥åº·ã€å‘è‚²å’Œç–¾ç—…è¿›å±•ç ”ç©¶ä¸­æœ‰å¹¿æ³›åº”ç”¨å‰æ™¯ï¼Œå°¤å…¶åœ¨åœ°ç†æˆ–ç»æµçº¦æŸä¸‹æ— æ³•è¦†ç›–çš„äººç¾¤ä¸­ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.04473">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-796c86a1afb6bea89fec57230e044740.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-cc68882b34e7d3d11da5c6c008232d3a.jpg" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="MedVAE-Efficient-Automated-Interpretation-of-Medical-Images-with-Large-Scale-Generalizable-Autoencoders"><a href="#MedVAE-Efficient-Automated-Interpretation-of-Medical-Images-with-Large-Scale-Generalizable-Autoencoders" class="headerlink" title="MedVAE: Efficient Automated Interpretation of Medical Images with   Large-Scale Generalizable Autoencoders"></a>MedVAE: Efficient Automated Interpretation of Medical Images with   Large-Scale Generalizable Autoencoders</h2><p><strong>Authors:Maya Varma, Ashwin Kumar, Rogier van der Sluijs, Sophie Ostmeier, Louis Blankemeier, Pierre Chambon, Christian Bluethgen, Jip Prince, Curtis Langlotz, Akshay Chaudhari</strong></p>
<p>Medical images are acquired at high resolutions with large fields of view in order to capture fine-grained features necessary for clinical decision-making. Consequently, training deep learning models on medical images can incur large computational costs. In this work, we address the challenge of downsizing medical images in order to improve downstream computational efficiency while preserving clinically-relevant features. We introduce MedVAE, a family of six large-scale 2D and 3D autoencoders capable of encoding medical images as downsized latent representations and decoding latent representations back to high-resolution images. We train MedVAE autoencoders using a novel two-stage training approach with 1,052,730 medical images. Across diverse tasks obtained from 20 medical image datasets, we demonstrate that (1) utilizing MedVAE latent representations in place of high-resolution images when training downstream models can lead to efficiency benefits (up to 70x improvement in throughput) while simultaneously preserving clinically-relevant features and (2) MedVAE can decode latent representations back to high-resolution images with high fidelity. Our work demonstrates that large-scale, generalizable autoencoders can help address critical efficiency challenges in the medical domain. Our code is available at <a target="_blank" rel="noopener" href="https://github.com/StanfordMIMI/MedVAE">https://github.com/StanfordMIMI/MedVAE</a>. </p>
<blockquote>
<p>åŒ»å­¦å›¾åƒä»¥é«˜åˆ†è¾¨ç‡å’Œå¤§è§†é‡è·å–ï¼Œä»¥æ•æ‰ä¸´åºŠå†³ç­–æ‰€éœ€çš„åŸºæœ¬ç‰¹å¾ã€‚å› æ­¤ï¼Œåœ¨åŒ»å­¦å›¾åƒä¸Šè®­ç»ƒæ·±åº¦å­¦ä¹ æ¨¡å‹å¯èƒ½ä¼šäº§ç”Ÿå·¨å¤§çš„è®¡ç®—æˆæœ¬ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬è§£å†³äº†ç¼©å°åŒ»å­¦å›¾åƒå°ºå¯¸çš„æŒ‘æˆ˜ï¼Œä»¥æé«˜ä¸‹æ¸¸è®¡ç®—æ•ˆç‡ï¼ŒåŒæ—¶ä¿ç•™ä¸ä¸´åºŠç›¸å…³çš„ç‰¹å¾ã€‚æˆ‘ä»¬å¼•å…¥äº†MedVAEï¼Œè¿™æ˜¯ä¸€ä¸ªåŒ…å«å…­ç§å¤§å‹äºŒç»´å’Œä¸‰ç»´è‡ªç¼–ç å™¨çš„å®¶æ—ï¼Œèƒ½å¤Ÿå°†åŒ»å­¦å›¾åƒç¼–ç ä¸ºç¼©å°çš„æ½œåœ¨è¡¨ç¤ºå½¢å¼ï¼Œå¹¶å°†æ½œåœ¨è¡¨ç¤ºå½¢å¼è§£ç å›é«˜åˆ†è¾¨ç‡å›¾åƒã€‚æˆ‘ä»¬ä½¿ç”¨ä¸€ç§æ–°å‹çš„ä¸¤é˜¶æ®µåŸ¹è®­æ–¹æ³•ï¼Œä½¿ç”¨1,052,730å¼ åŒ»å­¦å›¾åƒæ¥è®­ç»ƒMedVAEè‡ªç¼–ç å™¨ã€‚ä»20ä¸ªåŒ»å­¦å›¾åƒæ•°æ®é›†ä¸­è·å¾—çš„å„ç§ä»»åŠ¡è¡¨æ˜ï¼šï¼ˆ1ï¼‰åœ¨è®­ç»ƒä¸‹æ¸¸æ¨¡å‹æ—¶ä½¿ç”¨MedVAEæ½œåœ¨è¡¨ç¤ºå½¢å¼ä»£æ›¿é«˜åˆ†è¾¨ç‡å›¾åƒï¼Œå¯ä»¥åœ¨ä¿ç•™ä¸ä¸´åºŠç›¸å…³çš„ç‰¹å¾çš„åŒæ—¶å¸¦æ¥æ•ˆç‡æ•ˆç›Šï¼ˆååé‡æœ€å¤šæé«˜70å€ï¼‰ï¼›ï¼ˆ2ï¼‰MedVAEå¯ä»¥å°†æ½œåœ¨è¡¨ç¤ºå½¢å¼è§£ç å›é«˜åˆ†è¾¨ç‡å›¾åƒï¼Œå¹¶ä¿æŒé«˜åº¦ä¿çœŸã€‚æˆ‘ä»¬çš„ç ”ç©¶è¡¨æ˜ï¼Œå¤§è§„æ¨¡ã€é€šç”¨åŒ–çš„è‡ªç¼–ç å™¨æœ‰åŠ©äºè§£å†³åŒ»å­¦é¢†åŸŸçš„å…³é”®æ•ˆç‡æŒ‘æˆ˜ã€‚æˆ‘ä»¬çš„ä»£ç ä½äºï¼š<a target="_blank" rel="noopener" href="https://github.com/StanfordMIMI/MedVAE%E3%80%82">https://github.com/StanfordMIMI/MedVAEã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.14753v2">PDF</a> MIDL 2025 (Oral)</p>
<p><strong>Summary</strong></p>
<p>æœ¬è®ºæ–‡ä»‹ç»äº†MedVAEï¼Œä¸€ä¸ªç”¨äºåŒ»å­¦å›¾åƒå‹ç¼©çš„æ·±åº¦å­¦ä¹ æ¨¡å‹ã€‚è¯¥æ¨¡å‹èƒ½åœ¨é™ä½è®¡ç®—æˆæœ¬çš„åŒæ—¶ä¿ç•™åŒ»å­¦å›¾åƒçš„å…³é”®ä¸´åºŠç‰¹å¾ã€‚å®éªŒè¡¨æ˜ï¼Œä½¿ç”¨MedVAEå¯ä»¥é™ä½ä¸‹æ¸¸æ¨¡å‹çš„è®¡ç®—è´Ÿæ‹…ï¼Œå¹¶æé«˜å¤„ç†é€Ÿåº¦ï¼ŒåŒæ—¶é‡å»ºçš„é«˜åˆ†è¾¨ç‡å›¾åƒè´¨é‡é«˜ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>åŒ»å­¦å›¾åƒç”±äºå…¶é«˜åˆ†è¾¨ç‡å’Œå¤§è§†é‡ç‰¹æ€§ï¼Œå¯¼è‡´è®¡ç®—æˆæœ¬é«˜æ˜‚ã€‚</li>
<li>MedVAEæ¨¡å‹è¢«è®­ç»ƒç”¨äºå°†åŒ»å­¦å›¾åƒç¼–ç ä¸ºç®€åŒ–çš„æ½œåœ¨è¡¨ç¤ºå½¢å¼ï¼ŒåŒæ—¶ä¿ç•™å…³é”®ä¸´åºŠç‰¹å¾ã€‚</li>
<li>MedVAEä½¿ç”¨ä¸¤é˜¶æ®µè®­ç»ƒæ³•ï¼Œç”¨å¤§é‡åŒ»å­¦å›¾åƒæ•°æ®é›†è¿›è¡Œè®­ç»ƒã€‚</li>
<li>ä½¿ç”¨MedVAEæ½œåœ¨è¡¨ç¤ºä»£æ›¿é«˜åˆ†è¾¨ç‡å›¾åƒè®­ç»ƒä¸‹æ¸¸æ¨¡å‹å¯æé«˜è®¡ç®—æ•ˆç‡å¹¶ä¿ç•™å…³é”®ç‰¹å¾ã€‚</li>
<li>MedVAEèƒ½å°†æ½œåœ¨è¡¨ç¤ºè§£ç å›é«˜è´¨é‡çš„é«˜åˆ†è¾¨ç‡å›¾åƒã€‚</li>
<li>MedVAEæ¨¡å‹åœ¨å¤šä¸ªåŒ»å­¦å›¾åƒæ•°æ®é›†ä¸Šçš„å®éªŒè¡¨ç°å‡ºè‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.14753">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-b8783d875cea17c6a9bd2a90a230a600.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-26eb210ab033769bcacfbfd825617c48.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-4952d50ce501ba9e3ed34410ddcc2d00.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e48a163156bed070723f4bad107d233a.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-d5031b4bbfb37e8e60748ae9d32207a2.jpg" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1><h2 id="BatAnalysis-â€“-A-Comprehensive-Python-Pipeline-for-Swift-BAT-Time-Tagged-Event-Data-Analysis"><a href="#BatAnalysis-â€“-A-Comprehensive-Python-Pipeline-for-Swift-BAT-Time-Tagged-Event-Data-Analysis" class="headerlink" title="BatAnalysis â€“ A Comprehensive Python Pipeline for Swift BAT Time-Tagged   Event Data Analysis"></a>BatAnalysis â€“ A Comprehensive Python Pipeline for Swift BAT Time-Tagged   Event Data Analysis</h2><p><strong>Authors:Tyler Parsotan, David M. Palmer, Samuele Ronchini, James Delaunay, Aaron Tohuvavohu, Sibasish Laha, Amy Lien, S. Bradley Cenko, Hans Krimm, Craig Markwardt</strong></p>
<p>The Swift Burst Alert Telescope (BAT) is a coded aperture gamma-ray instrument with a large field of view that was designed to detect and localize transient events. When a transient is detected, either on-board or externally, the BAT saves time-tagged event (TTE) data which provides the highest quality information of the locations of the photons on the detector plane and their energies. This data can be used to produce spectra, lightcurves, and sky images of a transient event. While these data products are produced by the Swift Data Center and can be produced by current software, they are often preset to certain time and energy intervals which has limited their use in the current time domain and multi-messenger environment. Here, we introduce a new capability for the BatAnalysis python package to download and process TTE data under an open-source pythonic framework that allows for easy interfacing with other python packages. The new capabilities of the BatAnalysis software allows for TTE data to be used by the community in a variety of advanced customized analyses of astrophysical sources which BAT may have TTE data for, such as Fast Radio Bursts (FRBs), Gamma-ray Bursts (GRBs), Low Mass X-ray Binaries (LMXB), Soft Gamma Repeaters, magnetars, and many other sources. We highlight the usefulness of the BatAnalysis package in analyzing TTE data produced by an on-board GRB trigger, a FRB external trigger, a sub-threshold detection of the LMXB EXO 0748-676, and an external trigger of a GRB that BAT detected during a slew. </p>
<blockquote>
<p>Swift Burst Alertæœ›è¿œé•œï¼ˆBATï¼‰æ˜¯ä¸€ç§å¤§è§†é‡çš„ç¼–ç å­”å¾„ä¼½é©¬å°„çº¿ä»ªå™¨ï¼Œä¸“é—¨è®¾è®¡ç”¨äºæ£€æµ‹å’Œå®šä½çŸ­æš‚äº‹ä»¶ã€‚å½“æ£€æµ‹åˆ°çŸ­æš‚äº‹ä»¶æ—¶ï¼Œæ— è®ºæ˜¯åœ¨æœºä¸Šè¿˜æ˜¯å¤–éƒ¨ï¼ŒBATéƒ½ä¼šä¿å­˜æ—¶é—´æ ‡ç­¾äº‹ä»¶ï¼ˆTTEï¼‰æ•°æ®ï¼Œè¿™äº›æ•°æ®æä¾›äº†æ¢æµ‹å™¨å¹³é¢ä¸Šå…‰å­ä½ç½®åŠå…¶èƒ½é‡çš„æœ€é«˜å“è´¨ä¿¡æ¯ã€‚è¿™äº›æ•°æ®å¯ç”¨äºç”ŸæˆçŸ­æš‚äº‹ä»¶çš„å…‰è°±ã€å…‰å˜æ›²çº¿å’Œå¤©ç©ºå›¾åƒã€‚è™½ç„¶è¿™äº›äº§å“æ˜¯ç”±Swiftæ•°æ®ä¸­å¿ƒç”Ÿäº§çš„ï¼Œå¹¶ä¸”å¯ä»¥ç”±å½“å‰è½¯ä»¶ç”Ÿäº§ï¼Œä½†å®ƒä»¬é€šå¸¸é¢„è®¾ä¸ºç‰¹å®šçš„æ—¶é—´å’Œèƒ½é‡é—´éš”ï¼Œè¿™åœ¨å½“å‰çš„æ—¶é—´åŸŸå’Œå¤šä¿¡ä½¿ç¯å¢ƒä¸­é™åˆ¶äº†å…¶ä½¿ç”¨ã€‚åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬ä¸ºBatAnalysis pythonåŒ…å¼•å…¥äº†ä¸€ç§æ–°çš„åŠŸèƒ½ï¼Œå¯ä»¥åœ¨å¼€æºçš„pythonicæ¡†æ¶ä¸‹ä¸‹è½½å’Œå¤„ç†TTEæ•°æ®ï¼Œè¿™å…è®¸ä¸å…¶ä»–pythonåŒ…è½»æ¾æ¥å£ã€‚BatAnalysisè½¯ä»¶çš„æ–°åŠŸèƒ½ä½¿å¾—ç¤¾åŒºèƒ½å¤Ÿä½¿ç”¨TTEæ•°æ®è¿›è¡Œå„ç§å…ˆè¿›çš„è‡ªå®šä¹‰åˆ†æï¼Œè¿™äº›åˆ†æå¯èƒ½æ¶‰åŠBATæ‹¥æœ‰TTEæ•°æ®çš„å¤©æ–‡ç‰©ç†æºï¼Œä¾‹å¦‚å¿«é€Ÿå°„ç”µçˆ†å‘ï¼ˆFRBsï¼‰ã€ä¼½é©¬å°„çº¿çˆ†å‘ï¼ˆGRBsï¼‰ã€ä½è´¨é‡Xå°„çº¿åŒæ˜Ÿï¼ˆLMXBï¼‰ã€è½¯ä¼½é©¬é‡å¤å™¨ã€ç£æ˜Ÿå’Œå…¶ä»–è®¸å¤šæºã€‚æˆ‘ä»¬å¼ºè°ƒäº†BatAnalysisè½¯ä»¶åŒ…åœ¨åˆ†æç”±æœºä¸ŠGRBè§¦å‘ã€FRBå¤–éƒ¨è§¦å‘ã€LMXB EXO 0748-676çš„äºšé˜ˆå€¼æ£€æµ‹ä»¥åŠBATåœ¨è½¬åŠ¨è¿‡ç¨‹ä¸­æ£€æµ‹åˆ°çš„GRBå¤–éƒ¨è§¦å‘äº§ç”Ÿçš„TTEæ•°æ®ä¸­çš„å®ç”¨æ€§ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.00278v2">PDF</a> 13 pages, 8 figures, accepted to ApJ, BatAnalysis github link is:   <a target="_blank" rel="noopener" href="https://github.com/parsotat/BatAnalysis">https://github.com/parsotat/BatAnalysis</a></p>
<p><strong>æ‘˜è¦</strong><br>    è™è åˆ†æè½¯ä»¶å…·å¤‡å¤„ç†æ—¶é—´æ ‡ç­¾äº‹ä»¶æ•°æ®çš„æ–°åŠŸèƒ½ï¼Œæ­¤å¼€æºçš„pythonicæ¡†æ¶ä¾¿äºä¸å…¶ä»–è½¯ä»¶åŒ…æ¥å£ï¼Œå¯ç”¨äºå¤©æ–‡æºçš„é«˜çº§å®šåˆ¶åŒ–åˆ†æã€‚è™è åˆ†æè½¯ä»¶çš„æ–°åŠŸèƒ½å…è®¸ç¤¾åŒºä½¿ç”¨TTEæ•°æ®å¯¹å„ç§å¤©æ–‡æºè¿›è¡Œåˆ†æï¼Œä¾‹å¦‚å¿«é€Ÿå°„ç”µæš´ã€ä¼½é©¬å°„çº¿æš´ç­‰ã€‚å®ƒç‰¹åˆ«é€‚ç”¨äºåˆ†æç”±å†…ç½®GRBè§¦å‘å™¨å’Œå¤–éƒ¨FRBè§¦å‘å™¨ç­‰äº§ç”Ÿçš„TTEæ•°æ®ã€‚</p>
<p><strong>è¦ç‚¹</strong></p>
<ol>
<li>è™è Burst Alertæœ›è¿œé•œï¼ˆBATï¼‰ç”¨äºæ£€æµ‹å®šä½ç¬æ€äº‹ä»¶ï¼Œå¯è·å–é«˜è´¨é‡å…‰å­ä½ç½®ä¸èƒ½é‡ä¿¡æ¯çš„æ—¶é—´æ ‡ç­¾äº‹ä»¶ï¼ˆTTEï¼‰æ•°æ®ã€‚</li>
<li>TTEæ•°æ®å¯ç”¨äºç”Ÿæˆå…‰è°±ã€å…‰å˜æ›²çº¿å’Œå¤©ç©ºå›¾åƒç­‰ã€‚</li>
<li>å½“å‰æ•°æ®å¤„ç†è½¯ä»¶åœ¨æ—¶é—´å’Œèƒ½é‡é—´éš”ä¸Šæœ‰æ‰€é™åˆ¶ï¼Œéš¾ä»¥é€‚åº”å½“å‰æ—¶é—´åŸŸå’Œå¤šä¿¡ä½¿ç¯å¢ƒã€‚</li>
<li>æ–°å¢çš„è™è åˆ†æè½¯ä»¶åŠŸèƒ½å…è®¸ç¤¾åŒºåœ¨å¤šç§é«˜çº§å®šåˆ¶åŒ–åˆ†æä¸­åˆ©ç”¨TTEæ•°æ®ã€‚</li>
<li>æ–°åŠŸèƒ½é€‚ç”¨äºåˆ†æåŒ…æ‹¬å¿«é€Ÿå°„ç”µæš´ï¼ˆFRBsï¼‰ã€ä¼½é©¬å°„çº¿æš´ï¼ˆGRBsï¼‰ç­‰å¤šç§å¤©æ–‡æºçš„æ•°æ®ã€‚</li>
<li>åˆ†æäº†ç”±å†…ç½®GRBè§¦å‘å™¨å’Œå¤–éƒ¨FRBè§¦å‘å™¨ç­‰äº§ç”Ÿçš„TTEæ•°æ®çš„å®ç”¨æ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.00278">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-54a876f458c1f559a0363e66a9f8a860.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-5db8d85fb38502c9da7364b590025c68.jpg" align="middle">
</details>


<h1 id="-9"><a href="#-9" class="headerlink" title=""></a></h1><h2 id="Text-to-CAD-Generation-Through-Infusing-Visual-Feedback-in-Large-Language-Models"><a href="#Text-to-CAD-Generation-Through-Infusing-Visual-Feedback-in-Large-Language-Models" class="headerlink" title="Text-to-CAD Generation Through Infusing Visual Feedback in Large   Language Models"></a>Text-to-CAD Generation Through Infusing Visual Feedback in Large   Language Models</h2><p><strong>Authors:Ruiyu Wang, Yu Yuan, Shizhao Sun, Jiang Bian</strong></p>
<p>Creating Computer-Aided Design (CAD) models requires significant expertise and effort. Text-to-CAD, which converts textual descriptions into CAD parametric sequences, is crucial in streamlining this process. Recent studies have utilized ground-truth parametric sequences, known as sequential signals, as supervision to achieve this goal. However, CAD models are inherently multimodal, comprising parametric sequences and corresponding rendered visual objects. Besides,the rendering process from parametric sequences to visual objects is many-to-one. Therefore, both sequential and visual signals are critical for effective training. In this work, we introduce CADFusion, a framework that uses Large Language Models (LLMs) as the backbone and alternates between two training stages: the sequential learning (SL) stage and the visual feedback (VF) stage. In the SL stage, we train LLMs using ground-truth parametric sequences, enabling the generation of logically coherent parametric sequences. In the VF stage, we reward parametric sequences that render into visually preferred objects and penalize those that do not, allowing LLMs to learn how rendered visual objects are perceived and evaluated. These two stages alternate throughout the training, ensuring balanced learning and preserving benefits of both signals. Experiments demonstrate that CADFusion significantly improves performance, both qualitatively and quantitatively. </p>
<blockquote>
<p>åˆ›å»ºè®¡ç®—æœºè¾…åŠ©è®¾è®¡ï¼ˆCADï¼‰æ¨¡å‹éœ€è¦ä¸“ä¸šçŸ¥è¯†å’Œå¤§é‡åŠªåŠ›ã€‚æ–‡æœ¬åˆ°CADæŠ€æœ¯èƒ½å¤Ÿå°†æ–‡æœ¬æè¿°è½¬åŒ–ä¸ºCADå‚æ•°åºåˆ—ï¼Œå¯¹äºç®€åŒ–è¿™ä¸€æµç¨‹è‡³å…³é‡è¦ã€‚è¿‘æœŸç ”ç©¶ä½¿ç”¨çœŸå®å‚æ•°åºåˆ—ï¼ˆç§°ä¸ºé¡ºåºä¿¡å·ï¼‰ä½œä¸ºç›‘ç£æ¥å®ç°è¿™ä¸€ç›®æ ‡ã€‚ç„¶è€Œï¼ŒCADæ¨¡å‹æœ¬è´¨ä¸Šæ˜¯å¤šæ¨¡å¼çš„ï¼ŒåŒ…å«å‚æ•°åºåˆ—å’Œç›¸åº”çš„æ¸²æŸ“è§†è§‰å¯¹è±¡ã€‚æ­¤å¤–ï¼Œä»å‚æ•°åºåˆ—åˆ°è§†è§‰å¯¹è±¡çš„æ¸²æŸ“è¿‡ç¨‹æ˜¯å¤šå¯¹ä¸€çš„ã€‚å› æ­¤ï¼Œé¡ºåºä¿¡å·å’Œè§†è§‰ä¿¡å·å¯¹äºæœ‰æ•ˆè®­ç»ƒéƒ½è‡³å…³é‡è¦ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬å¼•å…¥äº†CADFusionæ¡†æ¶ï¼Œè¯¥æ¡†æ¶ä»¥å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä¸ºä¸»å¹²ï¼Œå¹¶åœ¨ä¸¤ä¸ªè®­ç»ƒé˜¶æ®µä¹‹é—´è¿›è¡Œäº¤æ›¿ï¼šé¡ºåºå­¦ä¹ ï¼ˆSLï¼‰é˜¶æ®µå’Œè§†è§‰åé¦ˆï¼ˆVFï¼‰é˜¶æ®µã€‚åœ¨SLé˜¶æ®µï¼Œæˆ‘ä»¬ä½¿ç”¨çœŸå®å‚æ•°åºåˆ—è®­ç»ƒLLMï¼Œä½¿å…¶èƒ½å¤Ÿç”Ÿæˆé€»è¾‘è¿è´¯çš„å‚æ•°åºåˆ—ã€‚åœ¨VFé˜¶æ®µï¼Œæˆ‘ä»¬å¥–åŠ±é‚£äº›èƒ½å¤Ÿæ¸²æŸ“æˆè§†è§‰ä¸Šæ›´å—æ¬¢è¿å¯¹è±¡çš„å‚æ•°åºåˆ—ï¼Œå¹¶æƒ©ç½šé‚£äº›ä¸èƒ½çš„åºåˆ—ï¼Œè¿™è®©LLMå­¦ä¹ å¦‚ä½•æ„ŸçŸ¥å’Œè¯„ä¼°æ¸²æŸ“çš„è§†è§‰å¯¹è±¡ã€‚è¿™ä¸¤ä¸ªé˜¶æ®µåœ¨æ•´ä¸ªè®­ç»ƒè¿‡ç¨‹ä¸­äº¤æ›¿è¿›è¡Œï¼Œç¡®ä¿å¹³è¡¡å­¦ä¹ å¹¶ä¿ç•™ä¸¤ç§ä¿¡å·çš„ä¼˜åŠ¿ã€‚å®éªŒè¡¨æ˜ï¼ŒCADFusionåœ¨å®šæ€§å’Œå®šé‡æ–¹é¢éƒ½æ˜¾è‘—æé«˜äº†æ€§èƒ½ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.19054v3">PDF</a> ICML 2025 camera ready</p>
<p><strong>Summary</strong></p>
<p>æ–‡æœ¬æè¿°äº†ä¸€ç§å°†æ–‡æœ¬æè¿°è½¬åŒ–ä¸ºCADå‚æ•°åºåˆ—çš„æŠ€æœ¯â€”â€”Text-to-CADçš„é‡è¦æ€§ï¼Œå®ƒåœ¨ç®€åŒ–è®¾è®¡è¿‡ç¨‹æ–¹é¢å‘æŒ¥ç€å…³é”®ä½œç”¨ã€‚è¿‘æœŸç ”ç©¶ä½¿ç”¨ç§°ä¸ºåºåˆ—ä¿¡å·çš„çœŸå®å‚æ•°åºåˆ—ä½œä¸ºç›‘ç£æ¥å®ç°è¿™ä¸€ç›®æ ‡ã€‚ç„¶è€Œï¼ŒCADæ¨¡å‹å…·æœ‰å†…åœ¨çš„å¤šæ¨¡æ€æ€§ï¼ŒåŒ…å«å‚æ•°åºåˆ—å’Œç›¸åº”çš„æ¸²æŸ“è§†è§‰å¯¹è±¡ã€‚æ­¤å¤–ï¼Œä»å‚æ•°åºåˆ—åˆ°è§†è§‰å¯¹è±¡çš„æ¸²æŸ“è¿‡ç¨‹æ˜¯å¤šå¯¹ä¸€çš„ã€‚å› æ­¤ï¼Œåºåˆ—å’Œè§†è§‰ä¿¡å·å¯¹äºæœ‰æ•ˆè®­ç»ƒéƒ½æ˜¯è‡³å…³é‡è¦çš„ã€‚åœ¨æ­¤å·¥ä½œä¸­ï¼Œä»‹ç»äº†ä¸€ä¸ªä½¿ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä½œä¸ºéª¨å¹²çš„CADFusionæ¡†æ¶ï¼Œè¯¥æ¡†æ¶åœ¨åºåˆ—å­¦ä¹ ï¼ˆSLï¼‰é˜¶æ®µå’Œè§†è§‰åé¦ˆï¼ˆVFï¼‰é˜¶æ®µä¹‹é—´è¿›è¡Œäº¤æ›¿ã€‚SLé˜¶æ®µä½¿ç”¨çœŸå®å‚æ•°åºåˆ—è®­ç»ƒLLMï¼Œç”Ÿæˆé€»è¾‘è¿è´¯çš„å‚æ•°åºåˆ—ã€‚VFé˜¶æ®µåˆ™å¥–åŠ±é‚£äº›æ¸²æŸ“æˆè§†è§‰ä¸Šæ›´å—æ¬¢è¿å¯¹è±¡çš„å‚æ•°åºåˆ—ï¼Œå¹¶æƒ©ç½šé‚£äº›ä¸èƒ½åšåˆ°è¿™ä¸€ç‚¹çš„åºåˆ—ï¼Œä½¿LLMå­¦ä¹ å¦‚ä½•æ„ŸçŸ¥å’Œè¯„ä¼°æ¸²æŸ“çš„è§†è§‰å¯¹è±¡ã€‚è¿™ä¸¤ä¸ªé˜¶æ®µçš„äº¤æ›¿è®­ç»ƒç¡®ä¿äº†å­¦ä¹ çš„å¹³è¡¡ï¼Œå¹¶ä¿ç•™äº†ä¸¤ç§ä¿¡å·çš„ä¼˜åŠ¿ã€‚å®éªŒè¡¨æ˜ï¼ŒCADFusionåœ¨å®šæ€§å’Œå®šé‡æ–¹é¢å‡æ˜¾è‘—æé«˜äº†æ€§èƒ½ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>Text-to-CADæŠ€æœ¯èƒ½å¤Ÿå°†æ–‡æœ¬æè¿°è½¬åŒ–ä¸ºCADå‚æ•°åºåˆ—ï¼Œä»è€Œç®€åŒ–è®¾è®¡è¿‡ç¨‹ã€‚</li>
<li>CADæ¨¡å‹å…·æœ‰å¤šæ¨¡æ€æ€§ï¼ŒåŒ…å«å‚æ•°åºåˆ—å’Œå¯¹åº”çš„æ¸²æŸ“è§†è§‰å¯¹è±¡ã€‚</li>
<li>ä»å‚æ•°åºåˆ—åˆ°è§†è§‰å¯¹è±¡çš„æ¸²æŸ“è¿‡ç¨‹æ˜¯å¤šå¯¹ä¸€çš„ã€‚</li>
<li>åºåˆ—ä¿¡å·å’Œè§†è§‰ä¿¡å·å¯¹äºè®­ç»ƒéƒ½æ˜¯é‡è¦çš„ã€‚</li>
<li>CADFusionæ¡†æ¶ç»“åˆäº†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ï¼Œå¹¶åœ¨åºåˆ—å­¦ä¹ ï¼ˆSLï¼‰å’Œè§†è§‰åé¦ˆï¼ˆVFï¼‰ä¸¤ä¸ªé˜¶æ®µä¹‹é—´äº¤æ›¿ã€‚</li>
<li>SLé˜¶æ®µé€šè¿‡çœŸå®å‚æ•°åºåˆ—è®­ç»ƒLLMä»¥ç”Ÿæˆé€»è¾‘è¿è´¯çš„å‚æ•°åºåˆ—ã€‚</li>
<li>VFé˜¶æ®µé€šè¿‡è§†è§‰åé¦ˆæ¥å¥–åŠ±æˆ–æƒ©ç½šå‚æ•°åºåˆ—çš„æ¸²æŸ“æ•ˆæœï¼Œä½¿LLMèƒ½å¤Ÿå­¦ä¹ å¦‚ä½•è¯„ä¼°æ¸²æŸ“çš„è§†è§‰å¯¹è±¡ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.19054">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-1b603496dbe40e409cca9104bb6dd634.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-16b8cbe0e070f7d291f2988ff050e552.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b4ae01e9699b2cf20a94369249f41db9.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-f9691662dfb1b4a8a3affe7ed24228bb.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-c4616959546ba0d7388958f479194563.jpg" align="middle">
</details>


<h1 id="-10"><a href="#-10" class="headerlink" title=""></a></h1><h2 id="Likelihood-Scheduled-Score-Based-Generative-Modeling-for-Fully-3D-PET-Image-Reconstruction"><a href="#Likelihood-Scheduled-Score-Based-Generative-Modeling-for-Fully-3D-PET-Image-Reconstruction" class="headerlink" title="Likelihood-Scheduled Score-Based Generative Modeling for Fully 3D PET   Image Reconstruction"></a>Likelihood-Scheduled Score-Based Generative Modeling for Fully 3D PET   Image Reconstruction</h2><p><strong>Authors:George Webber, Yuya Mizuno, Oliver D. Howes, Alexander Hammers, Andrew P. King, Andrew J. Reader</strong></p>
<p>Medical image reconstruction with pre-trained score-based generative models (SGMs) has advantages over other existing state-of-the-art deep-learned reconstruction methods, including improved resilience to different scanner setups and advanced image distribution modeling. SGM-based reconstruction has recently been applied to simulated positron emission tomography (PET) datasets, showing improved contrast recovery for out-of-distribution lesions relative to the state-of-the-art. However, existing methods for SGM-based reconstruction from PET data suffer from slow reconstruction, burdensome hyperparameter tuning and slice inconsistency effects (in 3D). In this work, we propose a practical methodology for fully 3D reconstruction that accelerates reconstruction and reduces the number of critical hyperparameters by matching the likelihood of an SGMâ€™s reverse diffusion process to a current iterate of the maximum-likelihood expectation maximization algorithm. Using the example of low-count reconstruction from simulated [$^{18}$F]DPA-714 datasets, we show our methodology can match or improve on the NRMSE and SSIM of existing state-of-the-art SGM-based PET reconstruction while reducing reconstruction time and the need for hyperparameter tuning. We evaluate our methodology against state-of-the-art supervised and conventional reconstruction algorithms. Finally, we demonstrate a first-ever implementation of SGM-based reconstruction for real 3D PET data, specifically [$^{18}$F]DPA-714 data, where we integrate perpendicular pre-trained SGMs to eliminate slice inconsistency issues. </p>
<blockquote>
<p>åˆ©ç”¨é¢„è®­ç»ƒçš„åŸºäºåˆ†æ•°çš„ç”Ÿæˆæ¨¡å‹ï¼ˆSGMsï¼‰è¿›è¡ŒåŒ»å­¦å›¾åƒé‡å»ºï¼Œç›¸è¾ƒäºå…¶ä»–ç°æœ‰çš„æœ€å…ˆè¿›çš„æ·±åº¦å­¦ä¹ é‡å»ºæ–¹æ³•å…·æœ‰ä¼˜åŠ¿ï¼ŒåŒ…æ‹¬å¯¹ä¸åŒæ‰«æä»ªè®¾ç½®çš„é€‚åº”æ€§æ›´å¼ºå’Œæ›´å…ˆè¿›çš„å›¾åƒåˆ†å¸ƒå»ºæ¨¡ã€‚åŸºäºSGMçš„é‡å»ºæ–¹æ³•æœ€è¿‘å·²åº”ç”¨äºæ¨¡æ‹Ÿçš„æ­£ç”µå­å‘å°„æ–­å±‚æ‰«æï¼ˆPETï¼‰æ•°æ®é›†ï¼Œç›¸å¯¹äºç°æœ‰æŠ€æœ¯ï¼Œå¯¹äºåˆ†å¸ƒå¤–çš„ç—…å˜çš„å¯¹æ¯”åº¦æ¢å¤æœ‰æ‰€æ”¹å–„ã€‚ç„¶è€Œï¼Œä»PETæ•°æ®ä¸­è¿›è¡ŒåŸºäºSGMçš„é‡å»ºçš„ç°æœ‰æ–¹æ³•å­˜åœ¨é‡å»ºé€Ÿåº¦æ…¢ã€è¶…å‚æ•°è°ƒæ•´ç¹çä»¥åŠåœ¨ä¸‰ç»´ä¸­çš„åˆ‡ç‰‡ä¸ä¸€è‡´æ•ˆåº”ç­‰é—®é¢˜ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§ç”¨äºå®Œå…¨ä¸‰ç»´é‡å»ºçš„å®ç”¨æ–¹æ³•ï¼Œé€šè¿‡åŒ¹é…SGMåå‘æ‰©æ•£è¿‡ç¨‹çš„æ¦‚ç‡ä¸æœ€å¤§ä¼¼ç„¶æœŸæœ›æœ€å¤§åŒ–ç®—æ³•çš„å½“å‰è¿­ä»£ï¼Œæ¥åŠ é€Ÿé‡å»ºå¹¶å‡å°‘å…³é”®è¶…å‚æ•°çš„æ•°é‡ã€‚ä»¥æ¨¡æ‹Ÿçš„$^{18}$F-DPA-714æ•°æ®é›†çš„ä½è®¡æ•°é‡å»ºä¸ºä¾‹ï¼Œæˆ‘ä»¬å±•ç¤ºäº†æˆ‘ä»¬çš„æ–¹æ³•èƒ½å¤Ÿåœ¨å½’ä¸€åŒ–å‡æ–¹æ ¹è¯¯å·®ï¼ˆNRMSEï¼‰å’Œç»“æ„ç›¸ä¼¼æ€§åº¦é‡ï¼ˆSSIMï¼‰ä¸ŠåŒ¹é…æˆ–è¶…è¶Šç°æœ‰æœ€å…ˆè¿›çš„SGM-based PETé‡å»ºæ–¹æ³•ï¼ŒåŒæ—¶å‡å°‘é‡å»ºæ—¶é—´å’Œå¯¹è¶…å‚æ•°è°ƒæ•´çš„éœ€æ±‚ã€‚æˆ‘ä»¬å°†æˆ‘ä»¬çš„æ–¹æ³•ä¸æœ€å…ˆè¿›çš„ç›‘ç£å¼å’Œä¼ ç»Ÿé‡å»ºç®—æ³•è¿›è¡Œäº†è¯„ä¼°æ¯”è¾ƒã€‚æœ€åï¼Œæˆ‘ä»¬å±•ç¤ºäº†åŸºäºSGMçš„é’ˆå¯¹çœŸå®ä¸‰ç»´PETæ•°æ®ï¼ˆç‰¹åˆ«æ˜¯$^{18}$F-DPA-714æ•°æ®ï¼‰çš„é¦–æ¬¡å®ç°é‡å»ºï¼Œæˆ‘ä»¬é€šè¿‡é›†æˆå‚ç›´æ–¹å‘çš„é¢„è®­ç»ƒSGMæ¥æ¶ˆé™¤åˆ‡ç‰‡ä¸ä¸€è‡´é—®é¢˜ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.04339v2">PDF</a> 12 pages, 14 figures. Authorâ€™s accepted manuscript, IEEE Transactions   on Medical Imaging</p>
<p><strong>Summary</strong></p>
<p>åŸºäºé¢„è®­ç»ƒå¾—åˆ†ç”Ÿæˆæ¨¡å‹ï¼ˆSGMï¼‰çš„åŒ»ç–—å›¾åƒé‡å»ºå…·æœ‰ç›¸å¯¹äºå…¶ä»–å…ˆè¿›çš„æ·±åº¦å­¦ä¹ æ–¹æ³•æ‰€ä¸å…·å¤‡çš„ä¼˜åŠ¿ï¼ŒåŒ…æ‹¬å¯¹ä¸åŒæ‰«æè®¾ç½®çš„ç¨³å¥æ€§å’Œé«˜çº§å›¾åƒåˆ†å¸ƒå»ºæ¨¡èƒ½åŠ›ã€‚æœ¬ç ”ç©¶æå‡ºä¸€ç§ç”¨äºå®Œå…¨ä¸‰ç»´é‡å»ºçš„å®é™…æ–¹æ³•ï¼Œè¯¥æ–¹æ³•é€šè¿‡åŒ¹é…SGMåå‘æ‰©æ•£è¿‡ç¨‹çš„æ¦‚ç‡ä¸æœ€å¤§ä¼¼ç„¶æœŸæœ›æœ€å¤§åŒ–ç®—æ³•çš„å½“å‰è¿­ä»£å€¼ï¼Œä»è€ŒåŠ é€Ÿé‡å»ºè¿‡ç¨‹å¹¶å‡å°‘å…³é”®è¶…å‚æ•°çš„æ•°é‡ã€‚æœ¬ç ”ç©¶ä½¿ç”¨ä½è®¡æ•°é‡å»ºæ¨¡æ‹Ÿæ•°æ®é›†è¿›è¡Œç¤ºä¾‹æ¼”ç¤ºï¼ŒåŒæ—¶å±•ç¤ºè¯¥æ–¹æ³•çš„ä¼˜å¼‚æ€§èƒ½å’Œç›¸è¾ƒäºç°æœ‰æŠ€æœ¯çš„ä¼˜åŠ¿ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬é¦–æ¬¡å®ç°äº†åŸºäºSGMçš„çœŸå®ä¸‰ç»´PETæ•°æ®é‡å»ºï¼Œè§£å†³äº†åˆ‡ç‰‡ä¸ä¸€è‡´çš„é—®é¢˜ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>é¢„è®­ç»ƒå¾—åˆ†ç”Ÿæˆæ¨¡å‹ï¼ˆSGMï¼‰åœ¨åŒ»ç–—å›¾åƒé‡å»ºä¸­å…·æœ‰ä¼˜åŠ¿ï¼ŒåŒ…æ‹¬å¯¹ä¸åŒæ‰«æè®¾ç½®çš„ç¨³å¥æ€§å’Œé«˜çº§å›¾åƒåˆ†å¸ƒå»ºæ¨¡èƒ½åŠ›ã€‚</li>
<li>ä¸ç°æœ‰æŠ€æœ¯ç›¸æ¯”ï¼ŒSGMåœ¨æ¨¡æ‹Ÿçš„PETæ•°æ®é›†ä¸Šæ˜¾ç¤ºå‡ºæ›´å¥½çš„å¯¹æ¯”æ¢å¤æ€§èƒ½ã€‚</li>
<li>æå‡ºä¸€ç§åŸºäºSGMçš„ä¸‰ç»´é‡å»ºæ–¹æ³•ï¼Œå¯åŠ é€Ÿé‡å»ºè¿‡ç¨‹å¹¶å‡å°‘è¶…å‚æ•°è°ƒæ•´çš„è´Ÿæ‹…ã€‚</li>
<li>åœ¨ä½è®¡æ•°é‡å»ºæ¨¡æ‹Ÿæ•°æ®é›†ä¸Šçš„å®éªŒè¯æ˜è¯¥æ–¹æ³•ä¸ç°æœ‰æŠ€æœ¯ç›¸å½“æˆ–æ›´å¥½ã€‚</li>
<li>è¯¥æ–¹æ³•å‡å°‘äº†é‡å»ºæ—¶é—´å¹¶é™ä½äº†å¯¹è¶…å‚æ•°è°ƒæ•´çš„éœ€æ±‚ã€‚</li>
<li>ç¬¬ä¸€æ¬¡å®ç°äº†åŸºäºSGMçš„çœŸå®ä¸‰ç»´PETæ•°æ®é‡å»ºã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.04339">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-9b0ddf9f7d4a6269c377a27b4e854ae2.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-d13ce29929d0192a2d064782abf22bc3.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-3510858c29b4549b87e045ba85ca6b74.jpg" align="middle">
</details>


<h1 id="-11"><a href="#-11" class="headerlink" title=""></a></h1><h2 id="Quantifying-Observational-Projection-Effects-with-a-Simulation-based-hot-CGM-model"><a href="#Quantifying-Observational-Projection-Effects-with-a-Simulation-based-hot-CGM-model" class="headerlink" title="Quantifying Observational Projection Effects with a Simulation-based hot   CGM model"></a>Quantifying Observational Projection Effects with a Simulation-based hot   CGM model</h2><p><strong>Authors:Soumya Shreeram, Johan Comparat, Andrea Merloni, Yi Zhang, Gabriele Ponti, Kirpal Nandra, John ZuHone, Ilaria Marini, Stephan Vladutescu-Zopp, Paola Popesso, Ruediger Pakmor, Riccardo Seppi, Celine Peroux, Daniele Sorini</strong></p>
<p>The hot phase of the circumgalactic medium (CGM) allows us to probe the inflow and outflow of gas within a galaxy, which is responsible for dictating the evolution of the galaxy. Studying the hot CGM sheds light on a better understanding of gas physics, which is crucial to inform and constrain simulation models. With the recent advances in observational measurements probing the hot CGM in X-rays and tSZ, we have a new avenue for widening our knowledge of gas physics and feedback by exploiting the information from current&#x2F;future observations. In this paper, we use the TNG300 hydrodynamical simulations to build a fully self-consistent forward model for the hot CGM. We construct a lightcone and generate mock X-ray observations. We quantify the projection effects, namely the locally correlated large-scale structure in X-rays and the effect due to satellite galaxies misclassified as centrals which affects the measured hot CGM galactocentric profiles in stacking experiments. We present an analytical model that describes the intrinsic X-ray surface brightness profile across the stellar and halo mass bins. The increasing stellar mass bins result in decreasing values of $\beta$, the exponent quantifying the slope of the intrinsic galactocentric profiles. We carry forward the current state-of-the-art by also showing the impact of the locally correlated environment on the measured X-ray surface brightness profiles. We also present, for the first time, the effect of misclassified centrals in stacking experiments for three stellar mass bins: $10^{10.5-11}\ M_\odot$, $10^{11-11.2}\ M_\odot$, and $10^{11.2-11.5}\ M_\odot$. We find that the contaminating effect of the misclassified centrals on the stacked profiles increases when the stellar mass decreases. </p>
<blockquote>
<p>å…³äºç¯æ˜Ÿç³»ä»‹è´¨ï¼ˆCGMï¼‰çš„çƒ­ç›¸ç ”ç©¶ä½¿æˆ‘ä»¬èƒ½å¤Ÿæ¢æµ‹æ˜Ÿç³»å†…çš„æ°”ä½“æµå…¥å’Œæµå‡ºï¼Œè¿™å†³å®šäº†æ˜Ÿç³»çš„æ¼”åŒ–è¿‡ç¨‹ã€‚ç ”ç©¶çƒ­ç›¸CGMæœ‰åŠ©äºæ›´å¥½åœ°ç†è§£æ°”ä½“ç‰©ç†å­¦ï¼Œè¿™å¯¹äºæ¨¡æ‹Ÿæ¨¡å‹æä¾›ä¿¡æ¯å’Œçº¦æŸè‡³å…³é‡è¦ã€‚éšç€æœ€è¿‘åœ¨Xå°„çº¿å’ŒtSZæ¢æµ‹ä¸­è§‚æµ‹æµ‹é‡æŠ€æœ¯çš„è¿›å±•ï¼Œæˆ‘ä»¬æœ‰äº†åˆ©ç”¨å½“å‰å’Œæœªæ¥è§‚æµ‹ç»“æœæ‰©å¤§æˆ‘ä»¬å¯¹æ°”ä½“ç‰©ç†å­¦å’Œåé¦ˆçŸ¥è¯†çš„æ–°é€”å¾„ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨TNG300æµä½“åŠ¨åŠ›å­¦æ¨¡æ‹Ÿæ¥æ„å»ºçƒ­ç›¸CGMçš„å®Œå…¨è‡ªæ´½å‰å‘æ¨¡å‹ã€‚æˆ‘ä»¬æ„å»ºäº†ä¸€ä¸ªå…‰é”¥å¹¶ç”Ÿæˆäº†æ¨¡æ‹Ÿçš„Xå°„çº¿è§‚æµ‹ç»“æœã€‚æˆ‘ä»¬é‡åŒ–äº†æŠ•å½±æ•ˆåº”ï¼Œå³Xå°„çº¿ä¸­çš„å±€éƒ¨ç›¸å…³çš„å¤§è§„æ¨¡ç»“æ„å’Œç”±äºè¯¯å°†å«æ˜Ÿæ˜Ÿç³»å½’ç±»ä¸ºä¸­å¿ƒæ˜Ÿç³»è€Œå¯¹å †å å®éªŒä¸­æµ‹é‡çš„çƒ­ç›¸CGMå‘å¿ƒè½®å»“äº§ç”Ÿçš„å½±å“ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªåˆ†ææ¨¡å‹ï¼Œæè¿°äº†è·¨è¶Šæ’æ˜Ÿå’Œæš—ç‰©è´¨æ™•è´¨é‡èŒƒå›´å†…çš„å›ºæœ‰Xå°„çº¿è¡¨é¢äº®åº¦åˆ†å¸ƒç‰¹å¾ã€‚éšç€æ’æ˜Ÿè´¨é‡åˆ†ç»„çš„å¢åŠ ï¼ŒÎ²å€¼ä¸‹é™ï¼ŒÎ²æ˜¯æŒ‡æ•°ï¼Œé‡åŒ–å›ºæœ‰å‘å¿ƒè½®å»“çš„æ–œç‡ã€‚æˆ‘ä»¬ç§‰æ‰¿äº†å½“å‰æœ€æ–°çŠ¶æ€ï¼ŒåŒæ—¶å±•ç¤ºäº†å±€éƒ¨ç›¸å…³ç¯å¢ƒå¯¹æµ‹é‡çš„Xå°„çº¿è¡¨é¢äº®åº¦åˆ†å¸ƒç‰¹å¾çš„å½±å“ã€‚æˆ‘ä»¬è¿˜é¦–æ¬¡å±•ç¤ºäº†ä¸‰ä¸ªæ’æ˜Ÿè´¨é‡åˆ†ç»„ä¸­è¯¯åˆ†ç±»ä¸­å¿ƒå¯¹å †å å®éªŒçš„å½±å“ï¼š$10^{10.5-11} M_\odot$ã€$10^{11-11.2} M_\odot$å’Œ$10^{11.2-11.5} M_\odot$ã€‚æˆ‘ä»¬å‘ç°è¯¯åˆ†ç±»ä¸­å¿ƒå¯¹å åŠ åˆ†å¸ƒç‰¹å¾çš„æ±¡æŸ“æ•ˆåº”éšç€æ’æ˜Ÿè´¨é‡çš„å‡å°‘è€Œå¢åŠ ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2409.10397v2">PDF</a> 14 pages, 10 figures, Accepted in A&amp;A</p>
<p><strong>Summary</strong><br>     ç ”ç©¶çƒ­æ€æ˜Ÿå‘¨ä»‹è´¨ï¼ˆCGMï¼‰æœ‰åŠ©äºäº†è§£æ˜Ÿç³»å†…çš„æ°”ä½“æµå…¥æµå‡ºæƒ…å†µï¼Œå½±å“æ˜Ÿç³»æ¼”åŒ–ã€‚é€šè¿‡æ¢è®¨çƒ­æ€CGMï¼Œèƒ½æ›´å¥½åœ°ç†è§£æ°”ä½“ç‰©ç†å­¦ï¼Œä¸ºæ¨¡æ‹Ÿæ¨¡å‹æä¾›ä¿¡æ¯å’Œçº¦æŸã€‚å½“å‰Xå°„çº¿å’ŒtSZè§‚æµ‹æŠ€æœ¯çš„è¿›æ­¥ä¸ºé€šè¿‡å½“å‰å’Œæœªæ¥è§‚æµ‹æ•°æ®äº†è§£æ°”ä½“ç‰©ç†å­¦å’Œåé¦ˆæä¾›äº†æ–°çš„é€”å¾„ã€‚æœ¬æ–‡åˆ©ç”¨TNG300æµä½“åŠ¨åŠ›å­¦æ¨¡æ‹Ÿæ„å»ºäº†ä¸€ä¸ªå®Œå…¨è‡ªæ´½çš„å‰å‘æ¨¡å‹ï¼Œå¯¹çƒ­æ€CGMè¿›è¡Œç ”ç©¶ã€‚é€šè¿‡æ¨¡æ‹Ÿå…‰é”¥å’Œç”ŸæˆXå°„çº¿æ¨¡æ‹Ÿè§‚æµ‹æ•°æ®ï¼Œæˆ‘ä»¬é‡åŒ–äº†æŠ•å½±æ•ˆåº”ï¼Œæå‡ºäº†ä¸€ç§æè¿°æ’æ˜Ÿå’Œæš—ç‰©è´¨è´¨é‡ç®±å†…å›ºæœ‰Xå°„çº¿è¡¨é¢äº®åº¦åˆ†å¸ƒçš„åˆ†ææ¨¡å‹ã€‚éšç€æ’æ˜Ÿè´¨é‡åˆ†ç®±çš„å¢å¤§ï¼ŒÎ²å€¼å‡å°ï¼Œå›ºæœ‰ä¸­å¿ƒæ˜Ÿå‘¨åˆ†å¸ƒæ–œç‡å‡å°‘ã€‚æˆ‘ä»¬è¿˜å±•ç¤ºäº†å±€éƒ¨ç›¸å…³ç¯å¢ƒå¯¹æµ‹é‡çš„Xå°„çº¿è¡¨é¢äº®åº¦åˆ†å¸ƒçš„å½±å“ï¼Œå¹¶é¦–æ¬¡å±•ç¤ºäº†åˆ†ç±»é”™è¯¯ä¸­å¿ƒä½“åœ¨å †ç§¯å®éªŒä¸­å¯¹ä¸‰ä¸ªæ’æ˜Ÿè´¨é‡åˆ†ç®±çš„å½±å“ã€‚å‘ç°åˆ†ç±»é”™è¯¯çš„ä¸­å¿ƒä½“å¯¹å åŠ åˆ†æçš„å½±å“éšç€æ’æ˜Ÿè´¨é‡çš„å‡å°è€Œå¢å¤§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ç ”ç©¶çƒ­æ€æ˜Ÿå‘¨ä»‹è´¨(CGM)å¯ä»¥äº†è§£æ˜Ÿç³»å†…æ°”ä½“æµå…¥æµå‡ºçš„æƒ…å†µï¼Œå½±å“æ˜Ÿç³»æ¼”åŒ–è¿›ç¨‹ã€‚</li>
<li>é€šè¿‡æ¢è®¨çƒ­æ€CGMèƒ½æ›´å¥½åœ°ç†è§£æ°”ä½“ç‰©ç†å­¦ï¼Œä¸ºæ¨¡æ‹Ÿæ¨¡å‹æä¾›ä¿¡æ¯å’Œçº¦æŸã€‚</li>
<li>å½“å‰Xå°„çº¿å’ŒtSZè§‚æµ‹æŠ€æœ¯çš„è¿›æ­¥ä¸ºæ‹“å®½å¯¹æ°”ä½“ç‰©ç†å­¦çš„çŸ¥è¯†æä¾›äº†æ–°é€”å¾„ã€‚</li>
<li>åˆ©ç”¨TNG300æµä½“åŠ¨åŠ›å­¦æ¨¡æ‹Ÿæ„å»ºäº†ä¸€ä¸ªå®Œå…¨è‡ªæ´½çš„å‰å‘æ¨¡å‹æ¥ç ”ç©¶çƒ­æ€CGMã€‚</li>
<li>æŠ•å½±æ•ˆåº”è¢«é‡åŒ–ï¼Œå¹¶æå‡ºäº†æè¿°æ’æ˜Ÿå’Œæš—ç‰©è´¨è´¨é‡ç®±å†…å›ºæœ‰Xå°„çº¿è¡¨é¢äº®åº¦åˆ†å¸ƒçš„åˆ†ææ¨¡å‹ã€‚</li>
<li>æ’æ˜Ÿè´¨é‡åˆ†ç®±å¢å¤§æ—¶ï¼Œæè¿°äº®åº¦åˆ†å¸ƒçš„Î²å€¼å‡å°ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2409.10397">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-847f28a842052b943296f83b7f1378c9.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b93a3c48a2ba431c7ac349fdb41ffa6d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f96149013aed9aaf28e5d42901abad66.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-cea4154425b4b80e4c84e59e729fbce9.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-71970ae2af9fdf0ea6ef5f0e92f4efce.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-2cc41c129a1186fc18fc0ae016f6ec84.jpg" align="middle">
</details>


<h1 id="-12"><a href="#-12" class="headerlink" title=""></a></h1><h2 id="QueryCAD-Grounded-Question-Answering-for-CAD-Models"><a href="#QueryCAD-Grounded-Question-Answering-for-CAD-Models" class="headerlink" title="QueryCAD: Grounded Question Answering for CAD Models"></a>QueryCAD: Grounded Question Answering for CAD Models</h2><p><strong>Authors:Claudius Kienle, Benjamin Alt, Darko Katic, Rainer JÃ¤kel, Jan Peters</strong></p>
<p>CAD models are widely used in industry and are essential for robotic automation processes. However, these models are rarely considered in novel AI-based approaches, such as the automatic synthesis of robot programs, as there are no readily available methods that would allow CAD models to be incorporated for the analysis, interpretation, or extraction of information. To address these limitations, we propose QueryCAD, the first system designed for CAD question answering, enabling the extraction of precise information from CAD models using natural language queries. QueryCAD incorporates SegCAD, an open-vocabulary instance segmentation model we developed to identify and select specific parts of the CAD model based on part descriptions. We further propose a CAD question answering benchmark to evaluate QueryCAD and establish a foundation for future research. Lastly, we integrate QueryCAD within an automatic robot program synthesis framework, validating its ability to enhance deep-learning solutions for robotics by enabling them to process CAD models (<a target="_blank" rel="noopener" href="https://claudius-kienle.github.com/querycad">https://claudius-kienle.github.com/querycad</a>). </p>
<blockquote>
<p>CADæ¨¡å‹åœ¨å·¥ä¸šç•Œæœ‰å¹¿æ³›åº”ç”¨ï¼Œå¯¹äºæœºå™¨äººè‡ªåŠ¨åŒ–æµç¨‹è‡³å…³é‡è¦ã€‚ç„¶è€Œï¼Œè¿™äº›æ¨¡å‹åœ¨åŸºäºAIçš„æ–°æ–¹æ³•ä¸­å¾ˆå°‘è¢«è€ƒè™‘ï¼Œå¦‚æœºå™¨äººç¨‹åºçš„è‡ªåŠ¨åˆæˆã€‚å› ä¸ºæ²¡æœ‰ç°æˆçš„æ–¹æ³•å¯ä»¥è®©CADæ¨¡å‹ç”¨äºåˆ†æã€è§£é‡Šæˆ–æå–ä¿¡æ¯ã€‚ä¸ºäº†å…‹æœè¿™äº›å±€é™æ€§ï¼Œæˆ‘ä»¬æå‡ºäº†QueryCADç³»ç»Ÿï¼Œè¿™æ˜¯é¦–ä¸ªä¸ºCADé—®ç­”è®¾è®¡çš„ç³»ç»Ÿï¼Œèƒ½å¤Ÿé€šè¿‡è‡ªç„¶è¯­è¨€æŸ¥è¯¢ä»CADæ¨¡å‹ä¸­æå–ç²¾ç¡®ä¿¡æ¯ã€‚QueryCADé›†æˆäº†æˆ‘ä»¬å¼€å‘çš„SegCADï¼Œè¿™æ˜¯ä¸€ç§å¼€æ”¾è¯æ±‡å®ä¾‹åˆ†å‰²æ¨¡å‹ï¼Œèƒ½å¤Ÿæ ¹æ®é›¶ä»¶æè¿°æ¥è¯†åˆ«å’Œé€‰æ‹©CADæ¨¡å‹ä¸­çš„ç‰¹å®šéƒ¨åˆ†ã€‚æˆ‘ä»¬è¿˜æå‡ºäº†ä¸€ä¸ªCADé—®ç­”åŸºå‡†æµ‹è¯•æ¥è¯„ä¼°QueryCADå¹¶ä¸ºæœªæ¥çš„ç ”ç©¶å¥ å®šåŸºç¡€ã€‚æœ€åï¼Œæˆ‘ä»¬å°†QueryCADé›†æˆåˆ°è‡ªåŠ¨æœºå™¨äººç¨‹åºåˆæˆæ¡†æ¶ä¸­ï¼ŒéªŒè¯äº†å®ƒå¢å¼ºæœºå™¨äººæ·±åº¦å­¦ä¹ èƒ½åŠ›çš„èƒ½åŠ›ï¼Œä½¿å…¶èƒ½å¤Ÿå¤„ç†CADæ¨¡å‹ï¼ˆ<a target="_blank" rel="noopener" href="https://claudius-kienle.github.com/querycad%EF%BC%89%E3%80%82">https://claudius-kienle.github.com/querycadï¼‰ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2409.08704v4">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>CADæ¨¡å‹åœ¨å·¥ä¸šä¸­å¹¿æ³›åº”ç”¨ï¼Œå¯¹æœºå™¨äººè‡ªåŠ¨åŒ–æµç¨‹è‡³å…³é‡è¦ã€‚ä½†åœ¨åŸºäºAIçš„è‡ªåŠ¨æœºå™¨äººç¨‹åºåˆæˆç­‰æ–°å‹æ–¹æ³•ä¸­ï¼ŒCADæ¨¡å‹çš„åº”ç”¨å´è¢«å¿½è§†ã€‚ä¸ºè§£å†³æ­¤é—®é¢˜ï¼Œæå‡ºQueryCADç³»ç»Ÿï¼Œåˆ©ç”¨è‡ªç„¶è¯­è¨€æŸ¥è¯¢ä»CADæ¨¡å‹ä¸­æå–ç²¾ç¡®ä¿¡æ¯ã€‚è¯¥ç³»ç»ŸåŒ…æ‹¬SegCADï¼Œä¸€ä¸ªåŸºäºå¼€æ”¾è¯æ±‡çš„å®ä¾‹åˆ†å‰²æ¨¡å‹ï¼Œå¯è¯†åˆ«å¹¶é€‰æ‹©CADæ¨¡å‹ä¸­çš„ç‰¹å®šéƒ¨åˆ†ã€‚æ­¤å¤–ï¼Œè¿˜æå‡ºCADé—®ç­”åŸºå‡†æµ‹è¯•ä»¥è¯„ä¼°QueryCADå¹¶ä¸ºæœªæ¥ç ”ç©¶å¥ å®šåŸºç¡€ã€‚æœ€åï¼Œå°†QueryCADé›†æˆåˆ°è‡ªåŠ¨æœºå™¨äººç¨‹åºåˆæˆæ¡†æ¶ä¸­ï¼ŒéªŒè¯äº†å…¶åœ¨æœºå™¨äººæ·±åº¦å­¦ä¹ è§£å†³æ–¹æ¡ˆä¸­çš„å¢å¼ºèƒ½åŠ›ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>CADæ¨¡å‹åœ¨å·¥ä¸šæœºå™¨äººè‡ªåŠ¨åŒ–æµç¨‹ä¸­å æ®é‡è¦åœ°ä½ï¼Œä½†åœ¨æ–°å‹AIæ–¹æ³•ä¸­åº”ç”¨è¾ƒå°‘ã€‚</li>
<li>QueryCADç³»ç»Ÿèƒ½åˆ©ç”¨è‡ªç„¶è¯­è¨€æŸ¥è¯¢ä»CADæ¨¡å‹ä¸­æå–ç²¾ç¡®ä¿¡æ¯ï¼Œè§£å†³äº†è¿™ä¸€é—®é¢˜ã€‚</li>
<li>SegCADæ˜¯QueryCADçš„æ ¸å¿ƒç»„æˆéƒ¨åˆ†ï¼Œå¯ä»¥è¯†åˆ«å¹¶é€‰æ‹©CADæ¨¡å‹ä¸­çš„ç‰¹å®šéƒ¨åˆ†ã€‚</li>
<li>æå‡ºäº†CADé—®ç­”åŸºå‡†æµ‹è¯•ä»¥è¯„ä¼°QueryCADæ€§èƒ½ï¼Œå¹¶ä¸ºæœªæ¥ç ”ç©¶æä¾›åŸºç¡€ã€‚</li>
<li>QueryCADç³»ç»Ÿè¢«æˆåŠŸé›†æˆåˆ°è‡ªåŠ¨æœºå™¨äººç¨‹åºåˆæˆæ¡†æ¶ä¸­ã€‚</li>
<li>QueryCADå¢å¼ºäº†æ·±åº¦å­¦ä¹ åœ¨æœºå™¨äººé¢†åŸŸçš„åº”ç”¨èƒ½åŠ›ï¼Œèƒ½å¤Ÿå¤„ç†CADæ¨¡å‹ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2409.08704">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-255c70e30eefa5f52a8a04827c18e1ac.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-96c33fa56208c952cc0fc8ecd4740aa4.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-8b21c6936622c87b1b5db75adc245e92.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-5aa577d286527968688fb1b8abea2c99.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c1a740930cdbf321cef797795942e8b6.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-7434b261d161306e0c5184b22e895937.jpg" align="middle">
</details>


<h1 id="-13"><a href="#-13" class="headerlink" title=""></a></h1><h2 id="Direct3Î³-A-Pipeline-for-Direct-Three-gamma-PET-Image-Reconstruction"><a href="#Direct3Î³-A-Pipeline-for-Direct-Three-gamma-PET-Image-Reconstruction" class="headerlink" title="Direct3Î³: A Pipeline for Direct Three-gamma PET Image   Reconstruction"></a>Direct3Î³: A Pipeline for Direct Three-gamma PET Image   Reconstruction</h2><p><strong>Authors:Youness Mellak, Alexandre Bousse, Thibaut Merlin, Debora Giovagnoli, Dimitris Visvikis</strong></p>
<p>This paper presents a novel image reconstruction pipeline for three-gamma (3-{\gamma}) positron emission tomography (PET) aimed at improving spatial resolution and reducing noise in nuclear medicine. The proposed Direct3{\gamma} pipeline addresses the inherent challenges in 3-{\gamma} PET systems, such as detector imperfections and uncertainty in photon interaction points. A key feature of the pipeline is its ability to determine the order of interactions through a model trained on Monte Carlo (MC) simulations using the Geant4 Application for Tomography Emission (GATE) toolkit, thus providing the necessary information to construct Compton cones which intersect with the line of response (LOR) to provide an estimate of the emission point. The pipeline processes 3-{\gamma} PET raw data, reconstructs histoimages by propagating energy and spatial uncertainties along the LOR, and applies a 3-D convolutional neural network (CNN) to refine these intermediate images into high-quality reconstructions. To further enhance image quality, the pipeline leverages both supervised learning and adversarial losses, the latter preserving fine structural details. Experimental results show that Direct3{\gamma} consistently outperforms conventional 200-ps time-of-flight (TOF) PET in terms of SSIM and PSNR. </p>
<blockquote>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ç§é’ˆå¯¹ä¸‰ä¼½é©¬ï¼ˆ3-Î³ï¼‰æ­£ç”µå­å‘å°„æ–­å±‚æ‰«æï¼ˆPETï¼‰çš„æ–°å‹å›¾åƒé‡å»ºæµæ°´çº¿ï¼Œæ—¨åœ¨æé«˜æ ¸åŒ»å­¦ä¸­çš„ç©ºé—´åˆ†è¾¨ç‡å¹¶é™ä½å™ªå£°ã€‚æ‰€æå‡ºçš„Direct3Î³æµæ°´çº¿è§£å†³äº†3-Î³ PETç³»ç»Ÿå›ºæœ‰çš„æŒ‘æˆ˜ï¼Œå¦‚æ¢æµ‹å™¨ç¼ºé™·å’Œå…‰å­äº¤äº’ç‚¹çš„ä¸ç¡®å®šæ€§ã€‚æµæ°´çº¿çš„ä¸€ä¸ªå…³é”®åŠŸèƒ½æ˜¯å…¶é€šè¿‡åˆ©ç”¨åŸºäºè’™ç‰¹å¡æ´›ï¼ˆMCï¼‰æ¨¡æ‹Ÿè®­ç»ƒçš„æ¨¡å‹ç¡®å®šäº¤äº’é¡ºåºçš„èƒ½åŠ›ï¼Œè¯¥æ¨¡å‹ä½¿ç”¨GATEï¼ˆGeant4æ±¤å§†æ£®å‘å°„åº”ç”¨ç¨‹åºï¼‰å·¥å…·åŒ…ï¼Œä»è€Œæä¾›æ„å»ºä¸å“åº”çº¿ï¼ˆLORï¼‰ç›¸äº¤çš„åº·æ™®é¡¿é”¥çš„å¿…è¦ä¿¡æ¯ï¼Œä»¥ä¼°è®¡å‘å°„ç‚¹ã€‚è¯¥æµæ°´çº¿å¤„ç†3-Î³ PETåŸå§‹æ•°æ®ï¼Œé€šè¿‡æ²¿LORä¼ æ’­èƒ½é‡å’Œç©ºé—´ä¸ç¡®å®šæ€§æ¥é‡å»ºç›´æ–¹å›¾åƒï¼Œå¹¶åº”ç”¨ä¸‰ç»´å·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNï¼‰å¯¹è¿™äº›ä¸­é—´å›¾åƒè¿›è¡Œç²¾ç»†å¤„ç†ä»¥è·å¾—é«˜è´¨é‡é‡å»ºã€‚ä¸ºäº†è¿›ä¸€æ­¥æ”¹å–„å›¾åƒè´¨é‡ï¼Œæµæ°´çº¿ç»“åˆäº†ç›‘ç£å­¦ä¹ å’Œå¯¹æŠ—æ€§æŸå¤±ï¼Œåè€…ä¿ç•™äº†ç²¾ç»†çš„ç»“æ„ç»†èŠ‚ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒDirect3Î³åœ¨ç»“æ„ç›¸ä¼¼æ€§åº¦é‡ï¼ˆSSIMï¼‰å’Œå³°å€¼ä¿¡å™ªæ¯”ï¼ˆPSNRï¼‰æ–¹é¢å§‹ç»ˆä¼˜äºä¼ ç»Ÿçš„200çš®ç§’é£è¡Œæ—¶é—´ï¼ˆTOFï¼‰PETã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2407.18337v5">PDF</a> 11 pages, 11 figures, 2 tables</p>
<p><strong>Summary</strong><br>     æœ¬æ–‡æå‡ºäº†ä¸€ç§é’ˆå¯¹ä¸‰ä¼½é©¬ï¼ˆ3-Î³ï¼‰æ­£ç”µå­å‘å°„æ–­å±‚æ‰«æï¼ˆPETï¼‰å›¾åƒé‡å»ºçš„æ–°æµç¨‹ï¼Œæ—¨åœ¨æé«˜æ ¸åŒ»å­¦ä¸­çš„ç©ºé—´åˆ†è¾¨ç‡å¹¶é™ä½å™ªå£°ã€‚è¯¥æµç¨‹é€šè¿‡æ¨¡æ‹Ÿè’™ç‰¹å¡æ´›ï¼ˆMCï¼‰ä»¿çœŸæ•°æ®ï¼Œåˆ©ç”¨Geant4 Application for Tomography Emissionï¼ˆGATEï¼‰å·¥å…·ç®±è¿›è¡Œè®­ç»ƒæ¨¡å‹æ¥è§£å†³äº’åŠ¨ç‚¹çš„ä¸ç¡®å®šæ€§ç­‰å›ºæœ‰éš¾é¢˜ã€‚ä½¿ç”¨æ·±åº¦å­¦ä¹ çš„ç›´æ¥å»ºæ¨¡æ–¹æ³•æ¥ç”Ÿæˆå›¾åƒçš„é«˜åˆ†è¾¨ç‡é‡å»ºï¼Œå¹¶é€šè¿‡å®éªŒè¯æ˜å…¶æ€§èƒ½ä¼˜äºä¼ ç»Ÿçš„TOF PETæˆåƒæŠ€æœ¯ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>è¯¥è®ºæ–‡æå‡ºäº†ä¸€ç§æ–°çš„å›¾åƒé‡å»ºæµç¨‹ï¼Œä¸“é—¨ç”¨äºå¤„ç†ä¸‰ä¼½é©¬ï¼ˆ3-Î³ï¼‰æ­£ç”µå­å‘å°„æ–­å±‚æ‰«æï¼ˆPETï¼‰ã€‚</li>
<li>é€šè¿‡Monte Carloæ¨¡æ‹Ÿå’ŒGeant4 Application for Tomography Emissionå·¥å…·è®­ç»ƒæ¨¡å‹è§£å†³å›ºæœ‰çš„éš¾é¢˜ï¼Œå¦‚æ¢æµ‹å™¨çš„ä¸å®Œç¾å’Œå…‰å­äº¤äº’ç‚¹çš„ä¸ç¡®å®šæ€§ã€‚</li>
<li>é€šè¿‡é¡ºåºæ¨æ–­æŠ€æœ¯æ„å»ºåº·æ™®é¡¿é”¥ï¼Œç»“åˆå“åº”çº¿ï¼ˆLORï¼‰ä¼°è®¡å‘å°„ç‚¹ã€‚</li>
<li>è¯¥æµç¨‹èƒ½å¤Ÿå¤„ç†åŸå§‹æ•°æ®å¹¶é‡å»ºå›¾åƒï¼Œé€šè¿‡æ²¿å“åº”çº¿ä¼ æ’­èƒ½é‡å’Œç©ºé—´ä¸ç¡®å®šæ€§æ¥ç”Ÿæˆé«˜è´¨é‡çš„å›¾åƒé‡å»ºã€‚</li>
<li>ä½¿ç”¨ä¸‰ç»´å·ç§¯ç¥ç»ç½‘ç»œå¯¹å›¾åƒè¿›è¡Œå¾®è°ƒï¼Œè¿›ä¸€æ­¥æé«˜å›¾åƒè´¨é‡ã€‚</li>
<li>è¯¥æµç¨‹é‡‡ç”¨ç›‘ç£å­¦ä¹ å’Œå¯¹æŠ—æ€§æŸå¤±ç›¸ç»“åˆçš„ç­–ç•¥æ¥å¢å¼ºå›¾åƒè´¨é‡ï¼Œå°¤å…¶æ˜¯å¯¹æŠ—æ€§æŸå¤±åœ¨ä¿ç•™ç»†å¾®ç»“æ„æ–¹é¢æ•ˆæœæ˜¾è‘—ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2407.18337">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-9acfbe1ba1dce6f209661ba26723d295.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c237686cd3535fc11daea7695616bd21.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-9d686919113adf714ed5302f80c19123.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-bf6181951dfb16932106658d26fa1577.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-0d3193083c913e5a2bbde118dd4d3bc2.jpg" align="middle">
</details>


<h1 id="-14"><a href="#-14" class="headerlink" title=""></a></h1><h2 id="Eddeep-Fast-eddy-current-distortion-correction-for-diffusion-MRI-with-deep-learning"><a href="#Eddeep-Fast-eddy-current-distortion-correction-for-diffusion-MRI-with-deep-learning" class="headerlink" title="Eddeep: Fast eddy-current distortion correction for diffusion MRI with   deep learning"></a>Eddeep: Fast eddy-current distortion correction for diffusion MRI with   deep learning</h2><p><strong>Authors:Antoine Legouhy, Ross Callaghan, Whitney Stee, Philippe Peigneux, Hojjat Azadbakht, Hui Zhang</strong></p>
<p>Modern diffusion MRI sequences commonly acquire a large number of volumes with diffusion sensitization gradients of differing strengths or directions. Such sequences rely on echo-planar imaging (EPI) to achieve reasonable scan duration. However, EPI is vulnerable to off-resonance effects, leading to tissue susceptibility and eddy-current induced distortions. The latter is particularly problematic because it causes misalignment between volumes, disrupting downstream modelling and analysis. The essential correction of eddy distortions is typically done post-acquisition, with image registration. However, this is non-trivial because correspondence between volumes can be severely disrupted due to volume-specific signal attenuations induced by varying directions and strengths of the applied gradients. This challenge has been successfully addressed by the popular FSL<del>Eddy tool but at considerable computational cost. We propose an alternative approach, leveraging recent advances in image processing enabled by deep learning (DL). It consists of two convolutional neural networks: 1) An image translator to restore correspondence between images; 2) A registration model to align the translated images. Results demonstrate comparable distortion estimates to FSL</del>Eddy, while requiring only modest training sample sizes. This work, to the best of our knowledge, is the first to tackle this problem with deep learning. Together with recently developed DL-based susceptibility correction techniques, they pave the way for real-time preprocessing of diffusion MRI, facilitating its wider uptake in the clinic. </p>
<blockquote>
<p>ç°ä»£æ‰©æ•£MRIåºåˆ—é€šå¸¸è·å–å¤§é‡ä½“ç§¯æ•°æ®ï¼Œè¿™äº›æ•°æ®å…·æœ‰ä¸åŒå¼ºåº¦æˆ–æ–¹å‘çš„æ‰©æ•£å¢æ•æ¢¯åº¦ã€‚æ­¤ç±»åºåˆ—ä¾èµ–äºå›æ³¢å¹³é¢æˆåƒï¼ˆEPIï¼‰æ¥å®ç°åˆç†çš„æ‰«ææ—¶é—´ã€‚ç„¶è€Œï¼ŒEPIå®¹æ˜“å—åˆ°é¢‘ç‡åç§»æ•ˆåº”çš„å½±å“ï¼Œå¯¼è‡´ç»„ç»‡ç£åŒ–ç‡å’Œæ¶¡æµå¼•èµ·çš„å¤±çœŸã€‚åè€…ç‰¹åˆ«æˆé—®é¢˜ï¼Œå› ä¸ºå®ƒä¼šå¯¼è‡´ä¸åŒä½“ç§¯ä¹‹é—´çš„ä¸å¯¹å‡†ï¼Œä»è€Œç ´åä¸‹æ¸¸å»ºæ¨¡å’Œåˆ†æã€‚æ¶¡æµå¤±çœŸçš„åŸºæœ¬æ ¡æ­£é€šå¸¸åœ¨é‡‡é›†åè¿›è¡Œï¼Œé€šè¿‡å›¾åƒé…å‡†å®ç°ã€‚ç„¶è€Œï¼Œè¿™å¹¶ä¸å®¹æ˜“ï¼Œå› ä¸ºç”±äºåº”ç”¨æ¢¯åº¦çš„æ–¹å‘å’Œå¼ºåº¦å˜åŒ–å¯¼è‡´çš„ç‰¹å®šä½“ç§¯ä¿¡å·è¡°å‡ï¼Œä¸åŒä½“ç§¯ä¹‹é—´çš„å¯¹åº”å…³ç³»å¯èƒ½ä¼šå—åˆ°ä¸¥é‡ç ´åã€‚è¿™ä¸€æŒ‘æˆ˜å·²ç»é€šè¿‡æµè¡Œçš„FSL<del>Eddyå·¥å…·æˆåŠŸè§£å†³ï¼Œä½†è®¡ç®—æˆæœ¬ç›¸å½“é«˜ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§æ›¿ä»£æ–¹æ³•ï¼Œåˆ©ç”¨æ·±åº¦å­¦ä¹ ï¼ˆDLï¼‰åœ¨å›¾åƒå¤„ç†æ–¹é¢çš„æœ€æ–°è¿›å±•ã€‚å®ƒåŒ…å«ä¸¤ä¸ªå·ç§¯ç¥ç»ç½‘ç»œï¼š1ï¼‰å›¾åƒç¿»è¯‘å™¨ï¼Œç”¨äºæ¢å¤å›¾åƒä¹‹é—´çš„å¯¹åº”å…³ç³»ï¼›2ï¼‰æ³¨å†Œæ¨¡å‹ï¼Œç”¨äºå¯¹é½ç¿»è¯‘åçš„å›¾åƒã€‚ç»“æœè¡¨æ˜ï¼Œå…¶ç•¸å˜ä¼°è®¡ä¸FSL</del>Eddyç›¸å½“ï¼ŒåŒæ—¶åªéœ€ä¸­ç­‰å¤§å°çš„è®­ç»ƒæ ·æœ¬é‡ã€‚æ®æˆ‘ä»¬æ‰€çŸ¥ï¼Œè¿™æ˜¯é¦–æ¬¡ä½¿ç”¨æ·±åº¦å­¦ä¹ æ¥è§£å†³è¿™ä¸€é—®é¢˜çš„å·¥ä½œã€‚ä¸æœ€è¿‘å¼€å‘çš„åŸºäºDLçš„ç£åŒ–ç‡æ ¡æ­£æŠ€æœ¯ç›¸ç»“åˆï¼Œå®ƒä»¬ä¸ºæ‰©æ•£MRIçš„å®æ—¶é¢„å¤„ç†é“ºå¹³äº†é“è·¯ï¼Œä¿ƒè¿›äº†å…¶åœ¨ä¸´åºŠçš„å¹¿æ³›åº”ç”¨ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2405.10723v3">PDF</a> Accepted in MICCAI 2024 conference (without rebuttal). Github repo:   <a target="_blank" rel="noopener" href="https://github.com/CIG-UCL/eddeep">https://github.com/CIG-UCL/eddeep</a></p>
<p><strong>æ‘˜è¦</strong><br>    æœ¬æ–‡ä»‹ç»äº†ç°ä»£æ‰©æ•£MRIåºåˆ—åœ¨é‡‡é›†å¤§é‡ä½“ç§¯æ•°æ®æ—¶é¢ä¸´çš„æŒ‘æˆ˜ï¼Œå¦‚ç»„ç»‡ç£åŒ–ç‡å’Œæ¶¡æµå¼•èµ·çš„å¤±çœŸã€‚é’ˆå¯¹æ¶¡æµå¼•èµ·çš„å¤±çœŸé—®é¢˜ï¼Œæå‡ºäº†åŸºäºæ·±åº¦å­¦ä¹ çš„å›¾åƒå¤„ç†æ–¹æ³•ï¼ŒåŒ…æ‹¬å›¾åƒç¿»è¯‘å™¨å’Œæ³¨å†Œæ¨¡å‹ï¼Œä»¥æ¢å¤å›¾åƒé—´çš„å¯¹åº”å…³ç³»å¹¶è¿›è¡Œå¯¹é½ã€‚è¯¥æ–¹æ³•ä¸FSL~Eddyå·¥å…·ç›¸æ¯”ï¼Œåœ¨å¤±çœŸä¼°è®¡æ–¹é¢è¡¨ç°å‡ºç›¸å½“çš„æ€§èƒ½ï¼Œå¹¶ä¸”åªéœ€é€‚ä¸­çš„è®­ç»ƒæ ·æœ¬å¤§å°ã€‚è¿™æ˜¯é¦–æ¬¡å°è¯•ä½¿ç”¨æ·±åº¦å­¦ä¹ è§£å†³æ­¤é—®é¢˜ï¼Œä¸ºæ‰©æ•£MRIçš„å®æ—¶é¢„å¤„ç†é“ºå¹³äº†é“è·¯ï¼Œæœ‰åŠ©äºå…¶åœ¨ä¸´åºŠçš„å¹¿æ³›åº”ç”¨ã€‚</p>
<p><strong>è¦ç‚¹</strong></p>
<ol>
<li>ç°ä»£æ‰©æ•£MRIåºåˆ—åœ¨é‡‡é›†å¤§é‡æ•°æ®æ—¶é¢ä¸´ç»„ç»‡ç£åŒ–ç‡å’Œæ¶¡æµå¼•èµ·çš„å¤±çœŸé—®é¢˜ã€‚</li>
<li>æ¶¡æµå¼•èµ·çš„å¤±çœŸä¼šå¯¼è‡´ä½“ç§¯é—´çš„ä¸å¯¹é½ï¼Œç»™ä¸‹æ¸¸å»ºæ¨¡å’Œåˆ†æå¸¦æ¥å¹²æ‰°ã€‚</li>
<li>æµè¡Œçš„FSL~Eddyå·¥å…·å¯ä»¥è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œä½†è®¡ç®—æˆæœ¬è¾ƒé«˜ã€‚</li>
<li>æå‡ºäº†ä¸€ç§åŸºäºæ·±åº¦å­¦ä¹ çš„æ›¿ä»£æ–¹æ³•ï¼ŒåŒ…æ‹¬å›¾åƒç¿»è¯‘å™¨å’Œæ³¨å†Œæ¨¡å‹ï¼Œä»¥æ¢å¤å›¾åƒé—´çš„å¯¹åº”å…³ç³»å¹¶è¿›è¡Œå¯¹é½ã€‚</li>
<li>è¯¥æ–¹æ³•åœ¨å¤±çœŸä¼°è®¡æ–¹é¢è¡¨ç°å‡ºä¸FSL~Eddyç›¸å½“çš„æ€§èƒ½ï¼Œä¸”åªéœ€é€‚ä¸­çš„è®­ç»ƒæ ·æœ¬å¤§å°ã€‚</li>
<li>è¿™æ˜¯é¦–æ¬¡å°è¯•ä½¿ç”¨æ·±åº¦å­¦ä¹ è§£å†³æ­¤é—®é¢˜ã€‚</li>
<li>è¯¥æ–¹æ³•ä¸åŸºäºæ·±åº¦å­¦ä¹ çš„ç£åŒ–ç‡æ ¡æ­£æŠ€æœ¯ç›¸ç»“åˆï¼Œä¸ºæ‰©æ•£MRIçš„å®æ—¶é¢„å¤„ç†æ‰“å¼€äº†å¤§é—¨ï¼Œæœ‰åŠ©äºå…¶åœ¨ä¸´åºŠçš„å¹¿æ³›åº”ç”¨ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2405.10723">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-39ab4198179037a1cdd201b7858b4bed.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f5e01bfa814480a3549b97b74686dfa7.jpg" align="middle">
</details>


<h1 id="-15"><a href="#-15" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-06-08/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/">https://kedreamix.github.io/Talk2Paper/Paper/2025-06-08/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/">
                                    <span class="chip bg-color">åŒ»å­¦å›¾åƒ</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-06-08/TTS/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-ea75cef42263d3c92ec1b1503f7dec38.jpg" class="responsive-img" alt="TTS">
                        
                        <span class="card-title">TTS</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            TTS æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-06-08  Kinetics Rethinking Test-Time Scaling Laws
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-06-08
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/TTS/" class="post-category">
                                    TTS
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/TTS/">
                        <span class="chip bg-color">TTS</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-06-08/Diffusion%20Models/">
                    <div class="card-image">
                        
                        <img src="https://pica.zhimg.com/v2-b07b4027ffc3ee280a3b21e0c6311fea.jpg" class="responsive-img" alt="Diffusion Models">
                        
                        <span class="card-title">Diffusion Models</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Diffusion Models æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-06-08  Contrastive Flow Matching
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-06-08
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Diffusion-Models/" class="post-category">
                                    Diffusion Models
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Diffusion-Models/">
                        <span class="chip bg-color">Diffusion Models</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">30666.7k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
