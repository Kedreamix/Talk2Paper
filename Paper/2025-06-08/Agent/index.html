<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Agent">
    <meta name="description" content="Agent æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-06-08  Truly Self-Improving Agents Require Intrinsic Metacognitive Learning">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>Agent | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://picx.zhimg.com/v2-96d12c51275a45c5dadcb236c0b4f035.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Agent</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/Agent/">
                                <span class="chip bg-color">Agent</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/Agent/" class="post-category">
                                Agent
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-06-08
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-07-06
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    14.8k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    60 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-06-08-æ›´æ–°"><a href="#2025-06-08-æ›´æ–°" class="headerlink" title="2025-06-08 æ›´æ–°"></a>2025-06-08 æ›´æ–°</h1><h2 id="Truly-Self-Improving-Agents-Require-Intrinsic-Metacognitive-Learning"><a href="#Truly-Self-Improving-Agents-Require-Intrinsic-Metacognitive-Learning" class="headerlink" title="Truly Self-Improving Agents Require Intrinsic Metacognitive Learning"></a>Truly Self-Improving Agents Require Intrinsic Metacognitive Learning</h2><p><strong>Authors:Tennison Liu, Mihaela van der Schaar</strong></p>
<p>Self-improving agents aim to continuously acquire new capabilities with minimal supervision. However, current approaches face two key limitations: their self-improvement processes are often rigid, fail to generalize across tasks domains, and struggle to scale with increasing agent capabilities. We argue that effective self-improvement requires intrinsic metacognitive learning, defined as an agentâ€™s intrinsic ability to actively evaluate, reflect on, and adapt its own learning processes. Drawing inspiration from human metacognition, we introduce a formal framework comprising three components: metacognitive knowledge (self-assessment of capabilities, tasks, and learning strategies), metacognitive planning (deciding what and how to learn), and metacognitive evaluation (reflecting on learning experiences to improve future learning). Analyzing existing self-improving agents, we find they rely predominantly on extrinsic metacognitive mechanisms, which are fixed, human-designed loops that limit scalability and adaptability. Examining each component, we contend that many ingredients for intrinsic metacognition are already present. Finally, we explore how to optimally distribute metacognitive responsibilities between humans and agents, and robustly evaluate and improve intrinsic metacognitive learning, key challenges that must be addressed to enable truly sustained, generalized, and aligned self-improvement. </p>
<blockquote>
<p>è‡ªæˆ‘å®Œå–„ä»£ç†æ—¨åœ¨ä»¥æœ€å°çš„ç›‘ç£æŒç»­è·å–æ–°çš„èƒ½åŠ›ã€‚ç„¶è€Œï¼Œå½“å‰çš„æ–¹æ³•é¢ä¸´ä¸¤ä¸ªä¸»è¦å±€é™æ€§ï¼šå®ƒä»¬çš„è‡ªæˆ‘å®Œå–„è¿‡ç¨‹é€šå¸¸å¾ˆåƒµåŒ–ï¼Œæ— æ³•è·¨ä»»åŠ¡é¢†åŸŸè¿›è¡Œæ¨å¹¿ï¼Œå¹¶ä¸”å¾ˆéš¾éšç€ä»£ç†èƒ½åŠ›çš„å¢å¼ºè€Œæ‰©å±•ã€‚æˆ‘ä»¬è®¤ä¸ºæœ‰æ•ˆçš„è‡ªæˆ‘å®Œå–„éœ€è¦å†…åœ¨çš„è®¤çŸ¥å­¦ä¹ ï¼Œè¿™è¢«å®šä¹‰ä¸ºä»£ç†ä¸»åŠ¨è¯„ä¼°ã€åæ€å’Œé€‚åº”å…¶è‡ªèº«å­¦ä¹ è¿‡ç¨‹çš„å†…ç”Ÿèƒ½åŠ›ã€‚ä»äººç±»è®¤çŸ¥ä¸­æ±²å–çµæ„Ÿï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ä¸ªæ­£å¼æ¡†æ¶ï¼ŒåŒ…æ‹¬ä¸‰ä¸ªç»„æˆéƒ¨åˆ†ï¼šè®¤çŸ¥çŸ¥è¯†ï¼ˆå¯¹èƒ½åŠ›ã€ä»»åŠ¡å’Œç­–ç•¥çš„è‡ªæˆ‘è¯„ä»·ï¼‰ã€è®¤çŸ¥è§„åˆ’ï¼ˆå†³å®šè¦å­¦ä¹ ä»€ä¹ˆå’Œå¦‚ä½•å­¦ä¹ ï¼‰ã€è®¤çŸ¥è¯„ä¼°ï¼ˆåæ€å­¦ä¹ ç»éªŒä»¥æ”¹è¿›æœªæ¥çš„å­¦ä¹ ï¼‰ã€‚åˆ†æç°æœ‰çš„è‡ªæˆ‘å®Œå–„ä»£ç†ï¼Œæˆ‘ä»¬å‘ç°å®ƒä»¬ä¸»è¦ä¾èµ–äºå¤–åœ¨çš„è®¤çŸ¥æœºåˆ¶ï¼Œè¿™äº›æœºåˆ¶æ˜¯å›ºå®šçš„ã€äººä¸ºè®¾è®¡çš„å¾ªç¯ï¼Œé™åˆ¶äº†å¯æ‰©å±•æ€§å’Œé€‚åº”æ€§ã€‚è€ƒå¯Ÿæ¯ä¸ªç»„æˆéƒ¨åˆ†ï¼Œæˆ‘ä»¬è®¤ä¸ºå†…åœ¨è®¤çŸ¥çš„è®¸å¤šè¦ç´ å·²ç»å­˜åœ¨ã€‚æœ€åï¼Œæˆ‘ä»¬æ¢è®¨äº†å¦‚ä½•åœ¨äººç±»å’Œä»£ç†ä¹‹é—´æœ€ä¼˜åœ°åˆ†é…è®¤çŸ¥è´£ä»»ï¼Œå¹¶ç¨³å¥åœ°è¯„ä¼°å’Œæ”¹è¿›å†…åœ¨çš„è®¤çŸ¥å­¦ä¹ ï¼Œè¿™æ˜¯å¿…é¡»è§£å†³çš„å…³é”®æŒ‘æˆ˜ï¼Œä»¥å®ç°çœŸæ­£æŒç»­ã€é€šç”¨å’Œå¯¹é½çš„è‡ªæˆ‘å®Œå–„ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.05109v1">PDF</a> Published as a conference paper at ICML 2025</p>
<p><strong>Summary</strong>ï¼š<br>è‡ªæˆ‘æå‡çš„æ™ºèƒ½ä½“æ—¨åœ¨ä»¥æœ€å°çš„ç›‘ç£æŒç»­è·å¾—æ–°çš„èƒ½åŠ›ã€‚ç„¶è€Œï¼Œå½“å‰çš„æ–¹æ³•é¢ä¸´ä¸¤å¤§å±€é™ï¼šå®ƒä»¬çš„è‡ªæˆ‘æå‡è¿‡ç¨‹å¾€å¾€åƒµåŒ–ï¼Œæ— æ³•è·¨ä»»åŠ¡åŸŸè¿›è¡Œæ¨å¹¿ï¼Œå¹¶ä¸”éš¾ä»¥éšç€æ™ºèƒ½ä½“èƒ½åŠ›çš„æå‡è€Œæ‰©å±•ã€‚æœ¬æ–‡ä¸»å¼ æœ‰æ•ˆçš„è‡ªæˆ‘æå‡éœ€è¦å†…åœ¨å…ƒè®¤çŸ¥å­¦ä¹ ï¼Œè¿™è¢«å®šä¹‰ä¸ºæ™ºèƒ½ä½“å¯¹å…¶è‡ªèº«å­¦ä¹ è¿‡ç¨‹çš„ä¸»åŠ¨è¯„ä¼°ã€åæ€å’Œé€‚åº”çš„å†…åœ¨èƒ½åŠ›ã€‚æœ¬æ–‡å€Ÿé‰´äººç±»å…ƒè®¤çŸ¥çš„çµæ„Ÿï¼Œå¼•å…¥äº†ä¸€ä¸ªåŒ…å«ä¸‰ä¸ªç»„ä»¶çš„æ­£å¼æ¡†æ¶ï¼šå…ƒè®¤çŸ¥çŸ¥è¯†ï¼ˆå¯¹èƒ½åŠ›ã€ä»»åŠ¡å’Œç­–ç•¥çš„è‡ªæˆ‘è¯„ä»·ï¼‰ã€å…ƒè®¤çŸ¥è§„åˆ’ï¼ˆå†³å®šå­¦ä»€ä¹ˆä»¥åŠå¦‚ä½•å­¦ä¹ ï¼‰å’Œå…ƒè®¤çŸ¥è¯„ä¼°ï¼ˆå¯¹å­¦ä¹ ç»éªŒçš„åæ€ä»¥æ”¹è¿›æœªæ¥çš„å­¦ä¹ ï¼‰ã€‚é€šè¿‡åˆ†æç°æœ‰çš„è‡ªæˆ‘æå‡æ™ºèƒ½ä½“ï¼Œæˆ‘ä»¬å‘ç°å®ƒä»¬ä¸»è¦ä¾èµ–äºå¤–åœ¨çš„å…ƒè®¤çŸ¥æœºåˆ¶ï¼Œè¿™äº›æœºåˆ¶æ˜¯å›ºå®šçš„ã€äººä¸ºè®¾è®¡çš„å¾ªç¯ï¼Œé™åˆ¶äº†å¯æ‰©å±•æ€§å’Œé€‚åº”æ€§ã€‚æœ¬æ–‡æ¢è®¨äº†æ¯ä¸ªç»„ä»¶ä¸­å†…åœ¨å…ƒè®¤çŸ¥çš„ç°æœ‰æˆåˆ†ï¼Œå¹¶æ¢è®¨äº†å¦‚ä½•åœ¨äººç±»å’Œæ™ºèƒ½ä½“ä¹‹é—´æœ€ä¼˜åœ°åˆ†é…å…ƒè®¤çŸ¥è´£ä»»ï¼Œä»¥åŠå¦‚ä½•ç¨³å¥åœ°è¯„ä¼°å’Œæ”¹è¿›å†…åœ¨å…ƒè®¤çŸ¥å­¦ä¹ ï¼Œè¿™æ˜¯å®ç°çœŸæ­£æŒç»­ã€é€šç”¨å’Œå¯¹é½çš„è‡ªæˆ‘æå‡å¿…é¡»è§£å†³çš„å…³é”®æŒ‘æˆ˜ã€‚</p>
<p><strong>Key Takeaways</strong>ï¼š</p>
<ol>
<li>è‡ªæˆ‘æå‡çš„æ™ºèƒ½ä½“æ—¨åœ¨æŒç»­è·å–æ–°èƒ½åŠ›ï¼Œä½†å½“å‰æ–¹æ³•é¢ä¸´è¿‡ç¨‹åƒµåŒ–å’Œæ— æ³•è·¨ä»»åŠ¡åŸŸæ¨å¹¿çš„é—®é¢˜ã€‚</li>
<li>æœ‰æ•ˆçš„è‡ªæˆ‘æå‡éœ€è¦å†…åœ¨å…ƒè®¤çŸ¥å­¦ä¹ ï¼ŒåŒ…æ‹¬è‡ªæˆ‘è¯„ä¼°ã€è§„åˆ’å’Œè¯„ä¼°çš„æ™ºèƒ½ä½“èƒ½åŠ›ã€‚</li>
<li>ç°æœ‰æ™ºèƒ½ä½“ä¸»è¦ä¾èµ–å¤–åœ¨å…ƒè®¤çŸ¥æœºåˆ¶ï¼Œé™åˆ¶äº†å…¶å¯æ‰©å±•æ€§å’Œé€‚åº”æ€§ã€‚</li>
<li>å€Ÿé‰´äººç±»å…ƒè®¤çŸ¥çš„çµæ„Ÿï¼Œæå‡ºäº†åŒ…å«å…ƒè®¤çŸ¥çŸ¥è¯†ã€è§„åˆ’å’Œè¯„ä¼°çš„æ­£å¼æ¡†æ¶ã€‚</li>
<li>åˆ†æè®¤ä¸ºï¼Œè®¸å¤šå†…åœ¨å…ƒè®¤çŸ¥çš„æˆåˆ†å·²ç»å­˜åœ¨äºç°æœ‰çš„æ™ºèƒ½ä½“ä¸­ã€‚</li>
<li>æœ€ä¼˜åœ°åˆ†é…äººç±»å’Œæ™ºèƒ½ä½“ä¹‹é—´çš„å…ƒè®¤çŸ¥è´£ä»»æ˜¯å…³é”®æŒ‘æˆ˜ä¹‹ä¸€ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.05109">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-88928a05b0ad08bcd07b97fea4366dab.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-584b9a216681c5da9b4fa5c30954b890.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-79efe9a73014f4c76a28222f533fa17d.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="Empowering-Economic-Simulation-for-Massively-Multiplayer-Online-Games-through-Generative-Agent-Based-Modeling"><a href="#Empowering-Economic-Simulation-for-Massively-Multiplayer-Online-Games-through-Generative-Agent-Based-Modeling" class="headerlink" title="Empowering Economic Simulation for Massively Multiplayer Online Games   through Generative Agent-Based Modeling"></a>Empowering Economic Simulation for Massively Multiplayer Online Games   through Generative Agent-Based Modeling</h2><p><strong>Authors:Bihan Xu, Shiwei Zhao, Runze Wu, Zhenya Huang, Jiawei Wang, Zhipeng Hu, Kai Wang, Haoyu Liu, Tangjie Lv, Le Li, Changjie Fan, Xin Tong, Jiangze Han</strong></p>
<p>Within the domain of Massively Multiplayer Online (MMO) economy research, Agent-Based Modeling (ABM) has emerged as a robust tool for analyzing game economics, evolving from rule-based agents to decision-making agents enhanced by reinforcement learning. Nevertheless, existing works encounter significant challenges when attempting to emulate human-like economic activities among agents, particularly regarding agent reliability, sociability, and interpretability. In this study, we take a preliminary step in introducing a novel approach using Large Language Models (LLMs) in MMO economy simulation. Leveraging LLMsâ€™ role-playing proficiency, generative capacity, and reasoning aptitude, we design LLM-driven agents with human-like decision-making and adaptability. These agents are equipped with the abilities of role-playing, perception, memory, and reasoning, addressing the aforementioned challenges effectively. Simulation experiments focusing on in-game economic activities demonstrate that LLM-empowered agents can promote emergent phenomena like role specialization and price fluctuations in line with market rules. </p>
<blockquote>
<p>åœ¨å¤§å‹å¤šäººåœ¨çº¿ï¼ˆMMOï¼‰ç»æµç ”ç©¶é¢†åŸŸï¼ŒåŸºäºä»£ç†çš„å»ºæ¨¡ï¼ˆABMï¼‰å·²æˆä¸ºåˆ†ææ¸¸æˆç»æµå­¦çš„å¼ºå¤§å·¥å…·ï¼Œä»åŸºäºè§„åˆ™çš„ä»£ç†å‘å±•åˆ°é€šè¿‡å¼ºåŒ–å­¦ä¹ å¢å¼ºçš„å†³ç­–ä»£ç†ã€‚ç„¶è€Œï¼Œç°æœ‰å·¥ä½œåœ¨å°è¯•æ¨¡æ‹Ÿä»£ç†ä¹‹é—´çš„äººç±»ç»æµæ´»åŠ¨æ—¶é¢ä¸´é‡å¤§æŒ‘æˆ˜ï¼Œç‰¹åˆ«æ˜¯åœ¨ä»£ç†çš„å¯é æ€§ã€ç¤¾äº¤å’Œå¯è§£é‡Šæ€§æ–¹é¢ã€‚åœ¨è¿™é¡¹ç ”ç©¶ä¸­ï¼Œæˆ‘ä»¬åˆæ­¥å¼•å…¥äº†ä¸€ç§æ–°çš„æ–¹æ³•ï¼Œåˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰è¿›è¡ŒMMOç»æµæ¨¡æ‹Ÿã€‚å€ŸåŠ©LLMçš„è§’è‰²æ‰®æ¼”èƒ½åŠ›ã€ç”Ÿæˆèƒ½åŠ›å’Œæ¨ç†èƒ½åŠ›ï¼Œæˆ‘ä»¬è®¾è®¡äº†å…·æœ‰äººç±»å¼å†³ç­–å’Œé€‚åº”èƒ½åŠ›çš„LLMé©±åŠ¨ä»£ç†ã€‚è¿™äº›ä»£ç†å…·å¤‡è§’è‰²æ‰®æ¼”ã€æ„ŸçŸ¥ã€è®°å¿†å’Œæ¨ç†çš„èƒ½åŠ›ï¼Œæœ‰æ•ˆåœ°è§£å†³äº†ä¸Šè¿°æŒ‘æˆ˜ã€‚ä»¥æ¸¸æˆå†…ç»æµæ´»åŠ¨ä¸ºé‡ç‚¹çš„æ¨¡æ‹Ÿå®éªŒè¡¨æ˜ï¼Œé‡‡ç”¨LLMèµ‹èƒ½çš„ä»£ç†å¯ä»¥ä¿ƒè¿›è¯¸å¦‚è§’è‰²ä¸“ä¸šåŒ–ã€ä»·æ ¼æ³¢ç­‰ä¸å¸‚åœºç»æµè§„åˆ™ç›¸ç¬¦çš„çªå‘ç°è±¡ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.04699v1">PDF</a> KDD2025 Accepted</p>
<p><strong>Summary</strong></p>
<p>åœ¨å¤§å‹å¤šäººåœ¨çº¿ï¼ˆMMOï¼‰ç»æµç ”ç©¶é¢†åŸŸï¼ŒåŸºäºä»£ç†çš„å»ºæ¨¡ï¼ˆABMï¼‰å·²å‘å±•ä¸ºä¸€ç§å¼ºå¤§çš„æ¸¸æˆç»æµåˆ†æå·¥å…·ï¼Œä»åŸºäºè§„åˆ™çš„ä»£ç†è¿›åŒ–åˆ°ç”±å¼ºåŒ–å­¦ä¹ å¢å¼ºå†³ç­–èƒ½åŠ›çš„ä»£ç†ã€‚ç„¶è€Œï¼Œç°æœ‰ç ”ç©¶åœ¨å°è¯•æ¨¡æ‹Ÿä»£ç†ä¹‹é—´çš„äººç±»ç»æµæ´»åŠ¨æ—¶é¢ä¸´è¯¸å¤šæŒ‘æˆ˜ï¼Œå°¤å…¶æ˜¯åœ¨ä»£ç†çš„å¯é æ€§ã€ç¤¾äº¤æ€§å’Œå¯è§£é‡Šæ€§æ–¹é¢ã€‚æœ¬ç ”ç©¶åˆæ­¥å¼•å…¥äº†ä¸€ç§æ–°çš„æ–¹æ³•ï¼Œå³åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰è¿›è¡ŒMMOç»æµæ¨¡æ‹Ÿã€‚å€ŸåŠ©LLMsçš„è§’è‰²æ‰®æ¼”èƒ½åŠ›ã€ç”Ÿæˆèƒ½åŠ›å’Œæ¨ç†èƒ½åŠ›ï¼Œæˆ‘ä»¬è®¾è®¡äº†å…·æœ‰äººç±»å†³ç­–å’Œé€‚åº”èƒ½åŠ›çš„LLMé©±åŠ¨ä»£ç†ã€‚è¿™äº›ä»£ç†å…·å¤‡è§’è‰²æ‰®æ¼”ã€æ„ŸçŸ¥ã€è®°å¿†å’Œæ¨ç†çš„èƒ½åŠ›ï¼Œæœ‰æ•ˆåœ°è§£å†³äº†ä¸Šè¿°æŒ‘æˆ˜ã€‚ä»¥æ¸¸æˆå†…ç»æµæ´»åŠ¨ä¸ºé‡ç‚¹çš„æ¨¡æ‹Ÿå®éªŒè¡¨æ˜ï¼Œé‡‡ç”¨LLMæŠ€æœ¯çš„ä»£ç†å¯ä»¥ä¿ƒè¿›è§’è‰²ä¸“ä¸šåŒ–å¹¶ä¸å¸‚åœºè§„åˆ™ç›¸ç¬¦çš„ä»·æ ¼æ³¢åŠ¨ç­‰çªå‘ç°è±¡ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ABMå·²ç”¨äºMMOç»æµç ”ç©¶ä¸­ï¼Œä½†æ¨¡æ‹Ÿäººç±»ç»æµæ´»åŠ¨ä»å­˜åœ¨æŒ‘æˆ˜ï¼Œç‰¹åˆ«æ˜¯åœ¨ä»£ç†çš„å¯é æ€§ã€ç¤¾äº¤æ€§å’Œå¯è§£é‡Šæ€§æ–¹é¢ã€‚</li>
<li>LLMsè¢«å¼•å…¥MMOç»æµæ¨¡æ‹Ÿä¸­ï¼Œç”¨ä»¥å¢å¼ºä»£ç†çš„è§’è‰²æ‰®æ¼”ã€ç”Ÿæˆå’Œæ¨ç†èƒ½åŠ›ã€‚</li>
<li>LLMsé©±åŠ¨çš„ä»£ç†å…·å¤‡äººç±»å†³ç­–å’Œé€‚åº”èƒ½åŠ›ï¼Œèƒ½å¤Ÿè§£å†³ç°æœ‰æ¨¡æ‹Ÿä¸­çš„æŒ‘æˆ˜ã€‚</li>
<li>é€šè¿‡æ¨¡æ‹Ÿå®éªŒå‘ç°ï¼Œé‡‡ç”¨LLMæŠ€æœ¯çš„ä»£ç†åœ¨æ¸¸æˆå†…ç»æµæ´»åŠ¨ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œå¦‚è§’è‰²ä¸“ä¸šåŒ–å’Œä»·æ ¼æ³¢åŠ¨çš„å‡ºç°ã€‚</li>
<li>LLMsçš„åº”ç”¨æœ‰åŠ©äºæ›´çœŸå®ã€æ›´æ·±å…¥åœ°æ¨¡æ‹Ÿå’Œäº†è§£MMOç»æµç³»ç»Ÿã€‚</li>
<li>è¯¥ç ”ç©¶ä¸ºæœªæ¥çš„MMOç»æµæ¨¡æ‹Ÿæä¾›äº†æ–°çš„æ–¹å‘ï¼Œå³ç»“åˆLLMså’ŒABMæ¥å¢å¼ºæ¨¡æ‹Ÿçš„é€¼çœŸåº¦å’Œæ•ˆæœã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.04699">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-5597fceac849f54973a291c81cd2ce9c.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-345ed8147158bbfcb8e5549f55c94871.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-7b4a2980f6fb752bd47f508d606fa674.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-1115abba10b0aec7debaa6bb475c23fe.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-f1c0d607ab82234d0592acc390c1e4b6.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="Gen-n-Val-Agentic-Image-Data-Generation-and-Validation"><a href="#Gen-n-Val-Agentic-Image-Data-Generation-and-Validation" class="headerlink" title="Gen-n-Val: Agentic Image Data Generation and Validation"></a>Gen-n-Val: Agentic Image Data Generation and Validation</h2><p><strong>Authors:Jing-En Huang, I-Sheng Fang, Tzuhsuan Huang, Chih-Yu Wang, Jun-Cheng Chen</strong></p>
<p>Recently, Large Language Models (LLMs) and Vision Large Language Models (VLLMs) have demonstrated impressive performance as agents across various tasks while data scarcity and label noise remain significant challenges in computer vision tasks, such as object detection and instance segmentation. A common solution for resolving these issues is to generate synthetic data. However, current synthetic data generation methods struggle with issues, such as multiple objects per mask, inaccurate segmentation, and incorrect category labels, limiting their effectiveness. To address these issues, we introduce Gen-n-Val, a novel agentic data generation framework that leverages Layer Diffusion (LD), LLMs, and VLLMs to produce high-quality, single-object masks and diverse backgrounds. Gen-n-Val consists of two agents: (1) The LD prompt agent, an LLM, optimizes prompts for LD to generate high-quality foreground instance images and segmentation masks. These optimized prompts ensure the generation of single-object synthetic data with precise instance masks and clean backgrounds. (2) The data validation agent, a VLLM, which filters out low-quality synthetic instance images. The system prompts for both agents are refined through TextGrad. Additionally, we use image harmonization to combine multiple instances within scenes. Compared to state-of-the-art synthetic data approaches like MosaicFusion, our approach reduces invalid synthetic data from 50% to 7% and improves performance by 1% mAP on rare classes in COCO instance segmentation with YOLOv9c and YOLO11m. Furthermore, Gen-n-Val shows significant improvements (7. 1% mAP) over YOLO-Worldv2-M in open-vocabulary object detection benchmarks with YOLO11m. Moreover, Gen-n-Val improves the performance of YOLOv9 and YOLO11 families in instance segmentation and object detection. </p>
<blockquote>
<p>æœ€è¿‘ï¼Œå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å’Œè§†è§‰å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆVLLMsï¼‰åœ¨å„ç§ä»»åŠ¡ä¸­ä½œä¸ºä»£ç†è¡¨ç°å‡ºäº†ä»¤äººå°è±¡æ·±åˆ»çš„æ€§èƒ½ï¼Œè€Œåœ¨è®¡ç®—æœºè§†è§‰ä»»åŠ¡ï¼ˆå¦‚ç›®æ ‡æ£€æµ‹å’Œå®ä¾‹åˆ†å‰²ï¼‰ä¸­ï¼Œæ•°æ®ç¨€ç¼ºå’Œæ ‡ç­¾å™ªå£°ä»ç„¶æ˜¯å·¨å¤§çš„æŒ‘æˆ˜ã€‚è§£å†³è¿™äº›é—®é¢˜çš„å¸¸è§æ–¹æ³•æ˜¯ç”Ÿæˆåˆæˆæ•°æ®ã€‚ç„¶è€Œï¼Œå½“å‰çš„åˆæˆæ•°æ®ç”Ÿæˆæ–¹æ³•é¢ä¸´å¤šé‡å¯¹è±¡æ¯æ©è†œã€åˆ†å‰²ä¸å‡†ç¡®å’Œç±»åˆ«æ ‡ç­¾ä¸æ­£ç¡®ç­‰é—®é¢˜ï¼Œé™åˆ¶äº†å…¶æœ‰æ•ˆæ€§ã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬å¼•å…¥äº†Gen-n-Valï¼Œè¿™æ˜¯ä¸€ç§æ–°å‹ä»£ç†æ•°æ®ç”Ÿæˆæ¡†æ¶ï¼Œå®ƒåˆ©ç”¨å±‚æ‰©æ•£ï¼ˆLDï¼‰ã€LLMså’ŒVLLMsç”Ÿæˆé«˜è´¨é‡çš„å•å¯¹è±¡æ©è†œå’Œå¤šæ ·åŒ–çš„èƒŒæ™¯ã€‚Gen-n-Valç”±ä¸¤ä¸ªä»£ç†ç»„æˆï¼šï¼ˆ1ï¼‰LDæç¤ºä»£ç†ï¼Œè¿™æ˜¯ä¸€ä¸ªLLMï¼Œä¼˜åŒ–LDçš„æç¤ºä»¥ç”Ÿæˆé«˜è´¨é‡çš„å‰æ™¯å®ä¾‹å›¾åƒå’Œåˆ†å‰²æ©è†œã€‚è¿™äº›ä¼˜åŒ–æç¤ºç¡®ä¿ç”Ÿæˆå•å¯¹è±¡åˆæˆæ•°æ®ï¼Œå…·æœ‰ç²¾ç¡®å®ä¾‹æ©è†œå’Œå¹²å‡€èƒŒæ™¯ã€‚ï¼ˆ2ï¼‰æ•°æ®éªŒè¯ä»£ç†ï¼Œè¿™æ˜¯ä¸€ä¸ªVLLMï¼Œç”¨äºè¿‡æ»¤å‡ºä½è´¨é‡çš„åˆæˆå®ä¾‹å›¾åƒã€‚æˆ‘ä»¬ç³»ç»Ÿé€šè¿‡TextGradå®Œå–„äº†è¿™ä¸¤ä¸ªä»£ç†çš„æç¤ºã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜ä½¿ç”¨å›¾åƒèåˆæŠ€æœ¯å°†åœºæ™¯å†…çš„å¤šä¸ªå®ä¾‹ç»„åˆåœ¨ä¸€èµ·ã€‚ä¸æœ€å…ˆè¿›çš„åˆæˆæ•°æ®æ–¹æ³•ï¼ˆå¦‚MosaicFusionï¼‰ç›¸æ¯”ï¼Œæˆ‘ä»¬çš„æ–¹æ³•å°†æ— æ•ˆåˆæˆæ•°æ®ä»50%å‡å°‘åˆ°7%ï¼Œå¹¶åœ¨ä½¿ç”¨YOLOv9cå’ŒYOLO11mçš„COCOå®ä¾‹åˆ†å‰²ä»»åŠ¡ä¸Šæé«˜äº†1%çš„mAPæ€§èƒ½ã€‚æ­¤å¤–ï¼Œåœ¨å¼€æ”¾è¯æ±‡å¯¹è±¡æ£€æµ‹åŸºå‡†æµ‹è¯•ä¸­ï¼ŒGen-n-Valåœ¨YOLO11mçš„åŸºç¡€ä¸Šæ˜¾è‘—æé«˜äº†YOLO-Worldv2-Mçš„7. 1% mAPã€‚è€Œä¸”Gen-n-Valæ”¹è¿›äº†YOLOv9å’ŒYOLO11ç³»åˆ—åœ¨å®ä¾‹åˆ†å‰²å’Œç›®æ ‡æ£€æµ‹æ–¹é¢çš„æ€§èƒ½ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.04676v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å’Œè§†è§‰å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆVLLMsï¼‰çš„Gen-n-Valæ¡†æ¶è§£å†³äº†è®¡ç®—æœºè§†è§‰ä»»åŠ¡ä¸­æ•°æ®ç¨€ç¼ºå’Œæ ‡ç­¾å™ªå£°çš„æŒ‘æˆ˜ã€‚è¯¥æ¡†æ¶åˆ©ç”¨å±‚æ‰©æ•£ï¼ˆLDï¼‰æŠ€æœ¯ç”Ÿæˆé«˜è´¨é‡çš„å•å¯¹è±¡æ©æ¨¡å’Œå¤šæ ·åŒ–çš„èƒŒæ™¯ï¼Œå¹¶é€šè¿‡ä¸¤ä¸ªä»£ç†è¿›è¡Œä¼˜åŒ–å’ŒéªŒè¯ã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼ŒGen-n-Valæ˜¾è‘—æé«˜äº†åˆæˆæ•°æ®çš„è´¨é‡å’Œæ€§èƒ½ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>Gen-n-Valæ˜¯ä¸€ä¸ªåˆ©ç”¨LLMså’ŒVLLMsè§£å†³æ•°æ®ç¨€ç¼ºå’Œæ ‡ç­¾å™ªå£°é—®é¢˜çš„æ–°å‹æ•°æ®ç”Ÿæˆæ¡†æ¶ã€‚</li>
<li>è¯¥æ¡†æ¶åˆ©ç”¨å±‚æ‰©æ•£æŠ€æœ¯ç”Ÿæˆé«˜è´¨é‡çš„å•å¯¹è±¡æ©æ¨¡å’Œå¤šæ ·åŒ–çš„èƒŒæ™¯ã€‚</li>
<li>Gen-n-ValåŒ…æ‹¬ä¸¤ä¸ªä»£ç†ï¼šLDæç¤ºä»£ç†ä¼˜åŒ–æç¤ºä»¥ç”Ÿæˆé«˜è´¨é‡çš„å‰æ™¯å®ä¾‹å›¾åƒå’Œåˆ†å‰²æ©æ¨¡ï¼Œæ•°æ®éªŒè¯ä»£ç†è¿‡æ»¤æ‰ä½è´¨é‡çš„åˆæˆå®ä¾‹å›¾åƒã€‚</li>
<li>Gen-n-Valæ˜¾è‘—æé«˜äº†åˆæˆæ•°æ®çš„è´¨é‡å’Œæ€§èƒ½ï¼Œå‡å°‘äº†æ— æ•ˆåˆæˆæ•°æ®ï¼Œæé«˜äº†åœ¨COCOå®ä¾‹åˆ†å‰²å’Œå¼€æ”¾è¯æ±‡å¯¹è±¡æ£€æµ‹åŸºå‡†æµ‹è¯•ä¸Šçš„æ€§èƒ½ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.04676">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-e3073c1618f77e54f3554ebb954dee67.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-ba0a3a56cd0d3de24c1f8e2a778553bd.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-84926fb98f8687acc3758c9528fb3978.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-1f862a70f986d704a2ded157a5f1d52d.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-fe7bbf34c3fbac88deecf9bf7c7c5030.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="Flex-TravelPlanner-A-Benchmark-for-Flexible-Planning-with-Language-Agents"><a href="#Flex-TravelPlanner-A-Benchmark-for-Flexible-Planning-with-Language-Agents" class="headerlink" title="Flex-TravelPlanner: A Benchmark for Flexible Planning with Language   Agents"></a>Flex-TravelPlanner: A Benchmark for Flexible Planning with Language   Agents</h2><p><strong>Authors:Juhyun Oh, Eunsu Kim, Alice Oh</strong></p>
<p>Real-world planning problems require constant adaptation to changing requirements and balancing of competing constraints. However, current benchmarks for evaluating LLMsâ€™ planning capabilities primarily focus on static, single-turn scenarios. We introduce Flex-TravelPlanner, a benchmark that evaluates language modelsâ€™ ability to reason flexibly in dynamic planning scenarios. Building on the TravelPlanner dataset~\citep{xie2024travelplanner}, we introduce two novel evaluation settings: (1) sequential constraint introduction across multiple turns, and (2) scenarios with explicitly prioritized competing constraints. Our analysis of GPT-4o and Llama 3.1 70B reveals several key findings: modelsâ€™ performance on single-turn tasks poorly predicts their ability to adapt plans across multiple turns; constraint introduction order significantly affects performance; and models struggle with constraint prioritization, often incorrectly favoring newly introduced lower priority preferences over existing higher-priority constraints. These findings highlight the importance of evaluating LLMs in more realistic, dynamic planning scenarios and suggest specific directions for improving model performance on complex planning tasks. The code and dataset for our framework are publicly available at <a target="_blank" rel="noopener" href="https://github.com/juhyunohh/FlexTravelBench">https://github.com/juhyunohh/FlexTravelBench</a>. </p>
<blockquote>
<p>ç°å®ä¸–ç•Œä¸­çš„è§„åˆ’é—®é¢˜è¦æ±‚ä¸æ–­é€‚åº”å˜åŒ–çš„éœ€æ±‚å¹¶å¹³è¡¡ç›¸äº’ç«äº‰çš„çº¦æŸã€‚ç„¶è€Œï¼Œå½“å‰è¯„ä¼°å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰è§„åˆ’èƒ½åŠ›çš„åŸºå‡†æµ‹è¯•ä¸»è¦é›†ä¸­äºé™æ€çš„å•å›åˆåœºæ™¯ã€‚æˆ‘ä»¬å¼•å…¥äº†Flex-TravelPlanneråŸºå‡†æµ‹è¯•ï¼Œè¯¥æµ‹è¯•æ—¨åœ¨è¯„ä¼°è¯­è¨€æ¨¡å‹åœ¨åŠ¨æ€è§„åˆ’åœºæ™¯ä¸­çµæ´»æ¨ç†çš„èƒ½åŠ›ã€‚åŸºäºTravelPlanneræ•°æ®é›†\citep{xie2024travelplanner}ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸¤ç§æ–°çš„è¯„ä¼°è®¾ç½®ï¼šï¼ˆ1ï¼‰å¤šå›åˆçš„è¿ç»­çº¦æŸå¼•å…¥ï¼Œä»¥åŠï¼ˆ2ï¼‰å…·æœ‰æ˜ç¡®ä¼˜å…ˆçº§çš„ç«äº‰çº¦æŸåœºæ™¯ã€‚æˆ‘ä»¬å¯¹GPT-4oå’ŒLlama 3.1 70Bçš„åˆ†ææ­ç¤ºäº†å‡ ä¸ªå…³é”®å‘ç°ï¼šæ¨¡å‹åœ¨å•å›åˆä»»åŠ¡ä¸Šçš„è¡¨ç°å¹¶ä¸èƒ½å¾ˆå¥½åœ°é¢„æµ‹å®ƒä»¬åœ¨å¤šå›åˆé€‚åº”è®¡åˆ’çš„èƒ½åŠ›ï¼›çº¦æŸå¼•å…¥çš„é¡ºåºå¯¹æ€§èƒ½æœ‰é‡å¤§å½±å“ï¼›æ¨¡å‹åœ¨çº¦æŸä¼˜å…ˆçº§æ’åºæ–¹é¢é‡åˆ°å›°éš¾ï¼Œå¾€å¾€ä¼šé”™è¯¯åœ°åå¥½æ–°å¼•å…¥çš„ä½ä¼˜å…ˆçº§åå¥½è€Œä¸æ˜¯ç°æœ‰çš„é«˜ä¼˜å…ˆçº§çº¦æŸã€‚è¿™äº›å‘ç°å¼ºè°ƒäº†ä»¥æ›´ç°å®çš„åŠ¨æ€è§„åˆ’åœºæ™¯è¯„ä¼°LLMsçš„é‡è¦æ€§ï¼Œå¹¶ä¸ºæé«˜æ¨¡å‹åœ¨å¤æ‚è§„åˆ’ä»»åŠ¡ä¸Šçš„æ€§èƒ½æä¾›äº†å…·ä½“çš„æ”¹è¿›æ–¹å‘ã€‚æˆ‘ä»¬çš„æ¡†æ¶çš„ä»£ç å’Œæ•°æ®é›†å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/juhyunohh/FlexTravelBench%E4%B8%8A%E5%85%AC%E5%BC%80%E8%8E%B7%E5%8F%96%E3%80%82">https://github.com/juhyunohh/FlexTravelBenchä¸Šå…¬å¼€è·å–ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.04649v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>Flex-TravelPlanneråŸºå‡†æµ‹è¯•è¯„ä¼°äº†è¯­è¨€æ¨¡å‹åœ¨åŠ¨æ€è§„åˆ’åœºæ™¯ä¸­çš„çµæ´»æ¨ç†èƒ½åŠ›ã€‚å®ƒå»ºç«‹åœ¨TravelPlanneræ•°æ®é›†çš„åŸºç¡€ä¸Šï¼Œå¹¶å¼•å…¥äº†ä¸¤ç§æ–°çš„è¯„ä¼°è®¾ç½®ï¼šå¤šè½®è¿ç»­çš„çº¦æŸå¼•å…¥å’Œå…·æœ‰æ˜ç¡®ä¼˜å…ˆçº§çš„ç«äº‰çº¦æŸåœºæ™¯ã€‚åˆ†æGPT-4oå’ŒLlama 3.1 70Bçš„è¡¨ç°ï¼Œå‘ç°æ¨¡å‹åœ¨å•è½®ä»»åŠ¡ä¸Šçš„è¡¨ç°å¹¶ä¸èƒ½é¢„æµ‹å…¶åœ¨å¤šè½®é€‚åº”è®¡åˆ’çš„èƒ½åŠ›ï¼Œçº¦æŸå¼•å…¥çš„é¡ºåºå¯¹æ€§èƒ½æœ‰é‡å¤§å½±å“ï¼Œä¸”æ¨¡å‹åœ¨çº¦æŸä¼˜å…ˆçº§ä¸ŠæŒ£æ‰ï¼Œå¸¸å¸¸é”™è¯¯åœ°é‡è§†æ–°å¼•å…¥çš„ä½ä¼˜å…ˆçº§åå¥½è€Œéç°æœ‰çš„é«˜ä¼˜å…ˆçº§çº¦æŸã€‚è¿™å¼ºè°ƒäº†åœ¨å®é™…ã€åŠ¨æ€çš„è§„åˆ’åœºæ™¯ä¸­è¯„ä¼°å¤§å‹è¯­è¨€æ¨¡å‹çš„é‡è¦æ€§ï¼Œå¹¶ä¸ºæ”¹è¿›æ¨¡å‹åœ¨å¤æ‚è§„åˆ’ä»»åŠ¡ä¸Šçš„è¡¨ç°æä¾›äº†æ–¹å‘ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>Flex-TravelPlanneråŸºå‡†æµ‹è¯•ç”¨äºè¯„ä¼°è¯­è¨€æ¨¡å‹åœ¨åŠ¨æ€è§„åˆ’åœºæ™¯ä¸­çš„çµæ´»æ¨ç†èƒ½åŠ›ã€‚</li>
<li>æ–°åŸºå‡†æµ‹è¯•åŒ…æ‹¬ä¸¤ç§è¯„ä¼°è®¾ç½®ï¼šå¤šè½®è¿ç»­çš„çº¦æŸå¼•å…¥å’Œå…·æœ‰æ˜ç¡®ä¼˜å…ˆçº§çš„ç«äº‰çº¦æŸåœºæ™¯ã€‚</li>
<li>ç°æœ‰æ¨¡å‹åœ¨å•è½®ä»»åŠ¡ä¸Šçš„è¡¨ç°å¹¶ä¸èƒ½é¢„æµ‹å…¶åœ¨å¤šè½®é€‚åº”è®¡åˆ’çš„èƒ½åŠ›ã€‚</li>
<li>çº¦æŸå¼•å…¥çš„é¡ºåºå¯¹è¯­è¨€æ¨¡å‹çš„æ€§èƒ½æœ‰é‡å¤§å½±å“ã€‚</li>
<li>è¯­è¨€æ¨¡å‹åœ¨çº¦æŸä¼˜å…ˆçº§ä¸Šè¡¨ç°æŒ£æ‰ï¼Œæœ‰æ—¶é”™è¯¯åœ°é‡è§†æ–°å¼•å…¥çš„ä½ä¼˜å…ˆçº§åå¥½ã€‚</li>
<li>è¯„ä¼°å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å®é™…ã€åŠ¨æ€çš„è§„åˆ’åœºæ™¯ä¸­çš„é‡è¦æ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.04649">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-b0285c7a34e251a20f0442a8e59d5d4b.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-38f52c886f9e980fff55901b128108d0.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-9a01d083fd212e6bedf522fcd3a629cb.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-60f94ab8766bb4ba147baaf4c811bebe.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-b897b85699b2d970bd238cc8d26f8d72.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d9c99c0fa108f2b6ab041a3012256ef4.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="Regret-Optimal-Q-Learning-with-Low-Cost-for-Single-Agent-and-Federated-Reinforcement-Learning"><a href="#Regret-Optimal-Q-Learning-with-Low-Cost-for-Single-Agent-and-Federated-Reinforcement-Learning" class="headerlink" title="Regret-Optimal Q-Learning with Low Cost for Single-Agent and Federated   Reinforcement Learning"></a>Regret-Optimal Q-Learning with Low Cost for Single-Agent and Federated   Reinforcement Learning</h2><p><strong>Authors:Haochen Zhang, Zhong Zheng, Lingzhou Xue</strong></p>
<p>Motivated by real-world settings where data collection and policy deployment â€“ whether for a single agent or across multiple agents â€“ are costly, we study the problem of on-policy single-agent reinforcement learning (RL) and federated RL (FRL) with a focus on minimizing burn-in costs (the sample sizes needed to reach near-optimal regret) and policy switching or communication costs. In parallel finite-horizon episodic Markov Decision Processes (MDPs) with $S$ states and $A$ actions, existing methods either require superlinear burn-in costs in $S$ and $A$ or fail to achieve logarithmic switching or communication costs. We propose two novel model-free RL algorithms â€“ Q-EarlySettled-LowCost and FedQ-EarlySettled-LowCost â€“ that are the first in the literature to simultaneously achieve: (i) the best near-optimal regret among all known model-free RL or FRL algorithms, (ii) low burn-in cost that scales linearly with $S$ and $A$, and (iii) logarithmic policy switching cost for single-agent RL or communication cost for FRL. Additionally, we establish gap-dependent theoretical guarantees for both regret and switching&#x2F;communication costs, improving or matching the best-known gap-dependent bounds. </p>
<blockquote>
<p>åœ¨ç°å®ä¸–ç•Œç¯å¢ƒä¸­ï¼Œæ— è®ºæ˜¯ä¸ºå•ä¸€ä»£ç†è¿˜æ˜¯å¤šä¸ªä»£ç†è¿›è¡Œæ•°æ®é‡‡é›†å’Œæ”¿ç­–éƒ¨ç½²éƒ½æ˜¯æˆæœ¬é«˜æ˜‚çš„ï¼Œæˆ‘ä»¬ç ”ç©¶äº†å¸¦æœ‰ç­–ç•¥çš„å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰å’Œè”é‚¦å¼ºåŒ–å­¦ä¹ ï¼ˆFRLï¼‰çš„é—®é¢˜ï¼Œé‡ç‚¹å…³æ³¨å¦‚ä½•æœ€å°åŒ–ç£¨åˆæˆæœ¬ï¼ˆè¾¾åˆ°æ¥è¿‘æœ€ä¼˜é—æ†¾æ‰€éœ€çš„æ ·æœ¬è§„æ¨¡ï¼‰ä»¥åŠç­–ç•¥åˆ‡æ¢æˆ–é€šä¿¡æˆæœ¬ã€‚åœ¨å…·æœ‰Sä¸ªçŠ¶æ€å’ŒAä¸ªåŠ¨ä½œçš„å¹¶è¡Œæœ‰é™æ—¶é—´åŸŸé˜¶æ®µæ€§é©¬å°”å¯å¤«å†³ç­–è¿‡ç¨‹ï¼ˆMDPsï¼‰ä¸­ï¼Œç°æœ‰æ–¹æ³•è¦ä¹ˆéœ€è¦è¶…çº¿æ€§ç£¨åˆæˆæœ¬ï¼ˆåœ¨Så’ŒAä¸­ï¼‰ï¼Œè¦ä¹ˆæ— æ³•å®ç°å¯¹æ•°åˆ‡æ¢æˆ–é€šä¿¡æˆæœ¬ã€‚æˆ‘ä»¬æå‡ºäº†ä¸¤ç§æ–°å‹æ— æ¨¡å‹RLç®—æ³•â€”â€”Q-EarlySettled-LowCostå’ŒFedQ-EarlySettled-LowCostï¼Œè¿™ä¸¤ç§ç®—æ³•æ˜¯æ–‡çŒ®ä¸­é¦–æ¬¡åŒæ—¶å®ç°ä»¥ä¸‹ç›®æ ‡ï¼šï¼ˆiï¼‰åœ¨æ‰€æœ‰å·²çŸ¥çš„æ— æ¨¡å‹RLæˆ–FRLç®—æ³•ä¸­è¾¾åˆ°æœ€ä½³æ¥è¿‘æœ€ä¼˜é—æ†¾ï¼Œï¼ˆiiï¼‰ä½ç£¨åˆæˆæœ¬ï¼Œéšç€Så’ŒAçº¿æ€§å¢é•¿ï¼Œï¼ˆiiiï¼‰å•ä¸€ä»£ç†RLçš„å¯¹æ•°ç­–ç•¥åˆ‡æ¢æˆæœ¬æˆ–FRLçš„é€šä¿¡æˆæœ¬ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜å»ºç«‹äº†ä¸é—´éš”ç›¸å…³çš„ç†è®ºä¿è¯ï¼Œä»¥æ”¹å–„æˆ–åŒ¹é…å·²çŸ¥çš„æœ€ä½³é—´éš”ä¾èµ–ç•Œé™ï¼ŒåŒ…æ‹¬é—æ†¾å’Œåˆ‡æ¢&#x2F;é€šä¿¡æˆæœ¬ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.04626v1">PDF</a> arXiv admin note: text overlap with arXiv:2502.02859</p>
<p><strong>Summary</strong>ï¼š<br>é’ˆå¯¹ç°å®ä¸–ç•Œä¸­æ•°æ®é‡‡é›†å’Œç­–ç•¥éƒ¨ç½²æˆæœ¬é«˜æ˜‚çš„é—®é¢˜ï¼Œç ”ç©¶äº†å¸¦æœ‰ç­–ç•¥åˆ‡æ¢æˆ–é€šä¿¡æˆæœ¬çš„æœ€å°åŒ–çƒ§å…¥æˆæœ¬çš„åœ¨çº¿ç­–ç•¥å•æ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰å’Œè”é‚¦å¼ºåŒ–å­¦ä¹ ï¼ˆFRLï¼‰ã€‚ç°æœ‰æ–¹æ³•è¦ä¹ˆéœ€è¦è¶…çº§çƒ§å…¥æˆæœ¬ï¼Œè¦ä¹ˆæ— æ³•å®ç°å¯¹æ•°åˆ‡æ¢æˆ–é€šä¿¡æˆæœ¬ã€‚æœ¬æ–‡æå‡ºäº†ä¸¤ç§æ–°å‹æ— æ¨¡å‹RLç®—æ³•ï¼Œå¯åŒæ—¶å®ç°æœ€ä½³è¿‘æœ€ä¼˜é—æ†¾ã€çº¿æ€§çƒ§å…¥æˆæœ¬å’Œå¯¹æ•°ç­–ç•¥åˆ‡æ¢æˆæœ¬æˆ–è”é‚¦é€šä¿¡æˆæœ¬ã€‚åŒæ—¶å»ºç«‹äº†ä¸å·®è·ç›¸å…³çš„ç†è®ºä¿è¯ã€‚</p>
<p><strong>Key Takeaways</strong>ï¼š</p>
<ol>
<li>é’ˆå¯¹ç°å®ä¸–ç•Œçš„å¼ºåŒ–å­¦ä¹ é—®é¢˜ï¼Œç ”ç©¶å¦‚ä½•åœ¨å•æ™ºèƒ½ä½“å’Œè”é‚¦å¼ºåŒ–å­¦ä¹ ä¸­æœ€å°åŒ–çƒ§å…¥æˆæœ¬ã€ç­–ç•¥åˆ‡æ¢æˆæœ¬å’Œé€šä¿¡æˆæœ¬ã€‚</li>
<li>ç°æœ‰æ–¹æ³•å­˜åœ¨è¶…çº§çº¿æ€§çƒ§å…¥æˆæœ¬æˆ–åœ¨å®ç°ç­–ç•¥åˆ‡æ¢æˆ–é€šä¿¡æˆæœ¬çš„ä¼˜åŒ–æ–¹é¢å­˜åœ¨å±€é™ã€‚</li>
<li>æå‡ºäº†ä¸¤ç§æ–°å‹æ— æ¨¡å‹RLç®—æ³•ï¼ŒQ-EarlySettled-LowCostå’ŒFedQ-EarlySettled-LowCostã€‚</li>
<li>è¿™ä¸¤ç§ç®—æ³•èƒ½å¤ŸåŒæ—¶å®ç°æœ€ä½³è¿‘æœ€ä¼˜é—æ†¾ã€çº¿æ€§çƒ§å…¥æˆæœ¬å’Œå¯¹æ•°ç­–ç•¥åˆ‡æ¢æˆæœ¬ï¼ˆå•æ™ºèƒ½ä½“RLï¼‰æˆ–å¯¹æ•°é€šä¿¡æˆæœ¬ï¼ˆè”é‚¦å¼ºåŒ–å­¦ä¹ ï¼‰ã€‚</li>
<li>å»ºç«‹äº†ä¸å·®è·ç›¸å…³çš„ç†è®ºä¿è¯ï¼Œæ”¹è¿›æˆ–åŒ¹é…äº†æœ€ä½³å·²çŸ¥å·®è·ç›¸å…³çš„ç•Œé™ã€‚</li>
<li>è¿™äº›ç®—æ³•åœ¨ç†è®ºåˆ†æå’Œå®é™…åº”ç”¨ä¸­å…·æœ‰æ½œåŠ›ï¼Œæœ‰åŠ©äºé™ä½å¼ºåŒ–å­¦ä¹ åœ¨å®é™…åº”ç”¨ä¸­çš„æˆæœ¬å’Œæé«˜æ•ˆç‡ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.04626">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-77b320abdf51c0d45ba40e570a1c3633.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-1155641ad3a66ec6d1520adda381b1d2.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b19490d7715df5c3b5fae4b78c62fd72.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="SmartAvatar-Text-and-Image-Guided-Human-Avatar-Generation-with-VLM-AI-Agents"><a href="#SmartAvatar-Text-and-Image-Guided-Human-Avatar-Generation-with-VLM-AI-Agents" class="headerlink" title="SmartAvatar: Text- and Image-Guided Human Avatar Generation with VLM AI   Agents"></a>SmartAvatar: Text- and Image-Guided Human Avatar Generation with VLM AI   Agents</h2><p><strong>Authors:Alexander Huang-Menders, Xinhang Liu, Andy Xu, Yuyao Zhang, Chi-Keung Tang, Yu-Wing Tai</strong></p>
<p>SmartAvatar is a vision-language-agent-driven framework for generating fully rigged, animation-ready 3D human avatars from a single photo or textual prompt. While diffusion-based methods have made progress in general 3D object generation, they continue to struggle with precise control over human identity, body shape, and animation readiness. In contrast, SmartAvatar leverages the commonsense reasoning capabilities of large vision-language models (VLMs) in combination with off-the-shelf parametric human generators to deliver high-quality, customizable avatars. A key innovation is an autonomous verification loop, where the agent renders draft avatars, evaluates facial similarity, anatomical plausibility, and prompt alignment, and iteratively adjusts generation parameters for convergence. This interactive, AI-guided refinement process promotes fine-grained control over both facial and body features, enabling users to iteratively refine their avatars via natural-language conversations. Unlike diffusion models that rely on static pre-trained datasets and offer limited flexibility, SmartAvatar brings users into the modeling loop and ensures continuous improvement through an LLM-driven procedural generation and verification system. The generated avatars are fully rigged and support pose manipulation with consistent identity and appearance, making them suitable for downstream animation and interactive applications. Quantitative benchmarks and user studies demonstrate that SmartAvatar outperforms recent text- and image-driven avatar generation systems in terms of reconstructed mesh quality, identity fidelity, attribute accuracy, and animation readiness, making it a versatile tool for realistic, customizable avatar creation on consumer-grade hardware. </p>
<blockquote>
<p>SmartAvataræ˜¯ä¸€ä¸ªç”±è§†è§‰è¯­è¨€ä»£ç†é©±åŠ¨çš„æ¡†æ¶ï¼Œå®ƒå¯ä»¥ä»å•å¼ ç…§ç‰‡æˆ–æ–‡æœ¬æç¤ºç”Ÿæˆå®Œå…¨é…å¤‡ã€é€‚åˆåŠ¨ç”»çš„3Däººç±»è§’è‰²ã€‚è™½ç„¶åŸºäºæ‰©æ•£çš„æ–¹æ³•åœ¨ä¸€èˆ¬çš„3Då¯¹è±¡ç”Ÿæˆæ–¹é¢å–å¾—äº†è¿›å±•ï¼Œä½†å®ƒä»¬å¯¹äºäººç±»èº«ä»½ã€ä½“å½¢å’ŒåŠ¨ç”»å‡†å¤‡çš„æ§åˆ¶ä»æ„Ÿåˆ°æ£˜æ‰‹ã€‚ä¸æ­¤ç›¸åï¼ŒSmartAvataråˆ©ç”¨å¤§å‹è§†è§‰è¯­è¨€æ¨¡å‹çš„å¸¸è¯†æ¨ç†èƒ½åŠ›ï¼Œç»“åˆç°æˆçš„å‚æ•°åŒ–äººç±»ç”Ÿæˆå™¨ï¼Œæä¾›é«˜è´¨é‡ã€å¯å®šåˆ¶çš„ä¸ªæ€§åŒ–è§’è‰²ã€‚ä¸€ä¸ªå…³é”®çš„åˆ›æ–°ä¹‹å¤„åœ¨äºè‡ªä¸»éªŒè¯å¾ªç¯ï¼Œä»£ç†åœ¨æ­¤å¾ªç¯ä¸­æ¸²æŸ“è§’è‰²è‰ç¨¿ï¼Œè¯„ä¼°é¢éƒ¨ç›¸ä¼¼æ€§ã€è§£å‰–åˆç†æ€§å’Œæç¤ºå¯¹é½åº¦ï¼Œå¹¶è¿­ä»£è°ƒæ•´ç”Ÿæˆå‚æ•°ä»¥è¾¾æˆæ”¶æ•›ã€‚è¿™ç§äº¤äº’å¼çš„ã€AIå¼•å¯¼çš„ç»†åŒ–è¿‡ç¨‹ä¿ƒè¿›å¯¹é¢éƒ¨å’Œèº«ä½“ç‰¹å¾çš„ç²¾ç»†æ§åˆ¶ï¼Œä½¿ç”¨æˆ·èƒ½å¤Ÿé€šè¿‡è‡ªç„¶è¯­è¨€å¯¹è¯é€æ­¥ç»†åŒ–ä»–ä»¬çš„è§’è‰²ã€‚ä¸ä¾èµ–é™æ€é¢„è®­ç»ƒæ•°æ®é›†ã€çµæ´»æ€§æœ‰é™çš„æ‰©æ•£æ¨¡å‹ä¸åŒï¼ŒSmartAvatarå°†ç”¨æˆ·çº³å…¥å»ºæ¨¡å¾ªç¯ï¼Œå¹¶é€šè¿‡LLMé©±åŠ¨çš„ç”Ÿæˆå’ŒéªŒè¯ç³»ç»Ÿç¡®ä¿æŒç»­æ”¹è¿›ã€‚ç”Ÿæˆçš„ä¸ªæ€§åŒ–è§’è‰²é…å¤‡å®Œå…¨ï¼Œæ”¯æŒå§¿åŠ¿æ“ä½œï¼Œå…·æœ‰ä¸€è‡´çš„èº«ä»½å’Œå¤–è§‚ï¼Œä½¿å…¶é€‚åˆç”¨äºä¸‹æ¸¸åŠ¨ç”»å’Œäº¤äº’å¼åº”ç”¨ã€‚å®šé‡åŸºå‡†æµ‹è¯•å’Œç”¨æˆ·ç ”ç©¶è¡¨æ˜ï¼ŒSmartAvataråœ¨é‡å»ºç½‘æ ¼è´¨é‡ã€èº«ä»½ä¿çœŸåº¦ã€å±æ€§å‡†ç¡®æ€§å’ŒåŠ¨ç”»å‡†å¤‡æ–¹é¢è¶…è¶Šäº†æœ€æ–°çš„æ–‡æœ¬å’Œå›¾åƒé©±åŠ¨çš„ä¸ªæ€§åŒ–è§’è‰²ç”Ÿæˆç³»ç»Ÿï¼Œæˆä¸ºåœ¨æ¶ˆè´¹çº§ç¡¬ä»¶ä¸Šåˆ›å»ºé€¼çœŸã€å¯å®šåˆ¶çš„ä¸ªæ€§åŒ–è§’è‰²çš„é€šç”¨å·¥å…·ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.04606v1">PDF</a> 16 pages</p>
<p><strong>æ‘˜è¦</strong><br>SmartAvataræ˜¯ä¸€æ¬¾åŸºäºè§†è§‰è¯­è¨€é©±åŠ¨çš„æ¡†æ¶ï¼Œèƒ½å¤Ÿä»å•ä¸€ç…§ç‰‡æˆ–æ–‡æœ¬æç¤ºç”Ÿæˆå…¨å‰¯æ­¦è£…ã€éšæ—¶å‡†å¤‡åŠ¨ç”»æ•ˆæœçš„3Däººç‰©è§’è‰²ã€‚å°½ç®¡æ‰©æ•£æ¨¡å‹å·²ç»åœ¨ä¸€èˆ¬ç‰©ä½“ç”Ÿæˆæ–¹é¢å–å¾—äº†è¿›å±•ï¼Œä½†åœ¨ç²¾ç¡®æ§åˆ¶äººç‰©èº«ä»½ã€ä½“å‹å’ŒåŠ¨ç”»æ•ˆæœæ–¹é¢ä»å­˜åœ¨æŒ‘æˆ˜ã€‚ä¸æ­¤ç›¸åï¼ŒSmartAvatarå€ŸåŠ©å¤§å‹è§†è§‰è¯­è¨€æ¨¡å‹çš„å¸¸è¯†æ¨ç†èƒ½åŠ›ï¼Œç»“åˆç°æˆçš„å‚æ•°åŒ–äººç‰©ç”Ÿæˆå™¨ï¼Œæä¾›é«˜è´¨é‡çš„å¯å®šåˆ¶è§’è‰²ã€‚å…¶å…³é”®åˆ›æ–°ä¹‹å¤„åœ¨äºè‡ªä¸»éªŒè¯å¾ªç¯ï¼Œä»£ç†èƒ½å¤Ÿæ¸²æŸ“è§’è‰²è‰ç¨¿ï¼Œè¯„ä¼°é¢éƒ¨ç›¸ä¼¼æ€§ã€è§£å‰–åˆç†æ€§å’Œæç¤ºå¯¹é½æ€§ï¼Œå¹¶è¿­ä»£è°ƒæ•´ç”Ÿæˆå‚æ•°ä»¥è¾¾åˆ°æ”¶æ•›ã€‚è¿™ç§äº¤äº’å¼çš„AIå¼•å¯¼ç»†åŒ–æµç¨‹æä¾›äº†å¯¹é¢éƒ¨å’Œèº«ä½“ç‰¹å¾çš„ç²¾ç»†æ§åˆ¶ï¼Œä½¿ç”¨æˆ·èƒ½å¤Ÿé€šè¿‡è‡ªç„¶è¯­è¨€å¯¹è¯é€æ­¥ä¼˜åŒ–ä»–ä»¬çš„è§’è‰²ã€‚ä¸ä¾èµ–é™æ€é¢„è®­ç»ƒæ•°æ®é›†å¹¶æä¾›æœ‰é™çµæ´»æ€§çš„æ‰©æ•£æ¨¡å‹ä¸åŒï¼ŒSmartAvatarå°†ç”¨æˆ·çº³å…¥å»ºæ¨¡å¾ªç¯ï¼Œå¹¶é€šè¿‡LLMé©±åŠ¨çš„ç”Ÿæˆå’ŒéªŒè¯ç³»ç»Ÿç¡®ä¿æŒç»­æ”¹è¿›ã€‚ç”Ÿæˆçš„è§’è‰²é…å¤‡å®Œæ•´è£…å¤‡ï¼Œæ”¯æŒå§¿åŠ¿æ“ä½œå¹¶ä¿æŒä¸€è‡´çš„å¤–è§‚å’Œèº«ä»½ï¼Œä½¿å…¶é€‚åˆç”¨äºä¸‹æ¸¸åŠ¨ç”»å’Œäº¤äº’å¼åº”ç”¨ã€‚å®šé‡åŸºå‡†æµ‹è¯•å’Œç”¨æˆ·ä½“éªŒç ”ç©¶è¯æ˜ï¼ŒSmartAvataråœ¨é‡å»ºç½‘æ ¼è´¨é‡ã€èº«ä»½ä¿çœŸåº¦ã€å±æ€§å‡†ç¡®æ€§å’ŒåŠ¨ç”»æ•ˆæœæ–¹é¢ä¼˜äºæœ€è¿‘çš„æ–‡æœ¬å’Œå›¾åƒé©±åŠ¨çš„è§’è‰²ç”Ÿæˆç³»ç»Ÿã€‚</p>
<p><strong>å…³é”®è§è§£</strong></p>
<ol>
<li>SmartAvataræ˜¯ä¸€ä¸ªåŸºäºè§†è§‰è¯­è¨€é©±åŠ¨çš„æ¡†æ¶ï¼Œå¯ä»¥ä»å•ä¸€ç…§ç‰‡æˆ–æ–‡æœ¬æç¤ºç”Ÿæˆå…¨å‰¯æ­¦è£…ã€å‡†å¤‡åŠ¨ç”»çš„3Däººç‰©è§’è‰²ã€‚</li>
<li>å®ƒå€ŸåŠ©å¤§å‹è§†è§‰è¯­è¨€æ¨¡å‹çš„å¸¸è¯†æ¨ç†èƒ½åŠ›ï¼Œæé«˜äº†è§’è‰²ç”Ÿæˆçš„ç²¾åº¦å’Œå®šåˆ¶æ€§ã€‚</li>
<li>SmartAvatarå…·å¤‡è‡ªä¸»éªŒè¯å¾ªç¯ï¼Œèƒ½å¤Ÿç»†åŒ–è§’è‰²ç‰¹å¾å¹¶ä¿éšœåŠ¨ç”»æ•ˆæœã€‚</li>
<li>ä¸å…¶ä»–æ–¹æ³•ç›¸æ¯”ï¼ŒSmartAvatarç”Ÿæˆçš„è§’è‰²çš„è´¨é‡æ›´é«˜ï¼Œæ›´é€‚åˆç”¨äºåŠ¨ç”»å’Œäº¤äº’å¼åº”ç”¨ã€‚</li>
<li>å®ƒçš„ä¼˜ç‚¹åœ¨äºå°†ç”¨æˆ·çº³å…¥å»ºæ¨¡å¾ªç¯ï¼Œå¹¶æä¾›æ›´ç²¾ç»†çš„æ§åˆ¶é€‰é¡¹ã€‚</li>
<li>SmartAvataråœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­è¡¨ç°å‡ºä¼˜å¼‚çš„æ€§èƒ½ï¼ŒåŒ…æ‹¬é‡å»ºç½‘æ ¼è´¨é‡ã€èº«ä»½ä¿çœŸåº¦ç­‰ã€‚</li>
<li>SmartAvataræ˜¯ä¸€ä¸ªå¤šåŠŸèƒ½å·¥å…·ï¼Œé€‚ç”¨äºæ¶ˆè´¹è€…çº§ç¡¬ä»¶ä¸Šçš„çœŸå®å¯å®šåˆ¶è§’è‰²åˆ›å»ºã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.04606">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-2e20bc90edb684c380c4b047dedb8f66.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-beb19d30c3e36234caa3be1acbdbcf30.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-00b06c789a384d477fec83b08e72360f.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="macOSWorld-A-Multilingual-Interactive-Benchmark-for-GUI-Agents"><a href="#macOSWorld-A-Multilingual-Interactive-Benchmark-for-GUI-Agents" class="headerlink" title="macOSWorld: A Multilingual Interactive Benchmark for GUI Agents"></a>macOSWorld: A Multilingual Interactive Benchmark for GUI Agents</h2><p><strong>Authors:Pei Yang, Hai Ci, Mike Zheng Shou</strong></p>
<p>Graphical User Interface (GUI) agents show promising capabilities for automating computer-use tasks and facilitating accessibility, but existing interactive benchmarks are mostly English-only, covering web-use or Windows, Linux, and Android environments, but not macOS. macOS is a major OS with distinctive GUI patterns and exclusive applications. To bridge the gaps, we present macOSWorld, the first comprehensive benchmark for evaluating GUI agents on macOS. macOSWorld features 202 multilingual interactive tasks across 30 applications (28 macOS-exclusive), with task instructions and OS interfaces offered in 5 languages (English, Chinese, Arabic, Japanese, and Russian). As GUI agents are shown to be vulnerable to deception attacks, macOSWorld also includes a dedicated safety benchmarking subset. Our evaluation on six GUI agents reveals a dramatic gap: proprietary computer-use agents lead at above 30% success rate, while open-source lightweight research models lag at below 2%, highlighting the need for macOS domain adaptation. Multilingual benchmarks also expose common weaknesses, especially in Arabic, with a 27.5% average degradation compared to English. Results from safety benchmarking also highlight that deception attacks are more general and demand immediate attention. macOSWorld is available at <a target="_blank" rel="noopener" href="https://github.com/showlab/macosworld">https://github.com/showlab/macosworld</a>. </p>
<blockquote>
<p>å›¾å½¢ç”¨æˆ·ç•Œé¢ï¼ˆGUIï¼‰ä»£ç†åœ¨è‡ªåŠ¨åŒ–è®¡ç®—æœºä½¿ç”¨ä»»åŠ¡å’Œä¿ƒè¿›å¯è®¿é—®æ€§æ–¹é¢æ˜¾ç¤ºå‡ºå·¨å¤§çš„æ½œåŠ›ï¼Œä½†ç°æœ‰çš„äº¤äº’åŸºå‡†æµ‹è¯•å¤§å¤šä»…é™äºè‹±è¯­ï¼Œæ¶µç›–ç½‘é¡µä½¿ç”¨æˆ–Windowsã€Linuxå’ŒAndroidç¯å¢ƒï¼Œå¹¶ä¸åŒ…æ‹¬macOSã€‚macOSæ˜¯ä¸€ä¸ªå…·æœ‰ç‹¬ç‰¹GUIæ¨¡å¼å’Œä¸“å±åº”ç”¨ç¨‹åºçš„ä¸»è¦æ“ä½œç³»ç»Ÿã€‚ä¸ºäº†å¼¥è¡¥è¿™ä¸€ç©ºç™½ï¼Œæˆ‘ä»¬æ¨å‡ºäº†macOSWorldï¼Œè¿™æ˜¯ç¬¬ä¸€ä¸ªç”¨äºè¯„ä¼°macOSä¸ŠGUIä»£ç†çš„ç»¼åˆåŸºå‡†æµ‹è¯•ã€‚macOSWorldåŒ…å«30ä¸ªåº”ç”¨ç¨‹åºï¼ˆ28ä¸ªä¸ºmacOSä¸“å±ï¼‰ä¸­çš„202ä¸ªè·¨è¯­è¨€äº¤äº’å¼ä»»åŠ¡ï¼Œä»»åŠ¡è¯´æ˜å’Œæ“ä½œç³»ç»Ÿç•Œé¢æä¾›äº”ç§è¯­è¨€ï¼ˆè‹±è¯­ã€ä¸­æ–‡ã€é˜¿æ‹‰ä¼¯è¯­ã€æ—¥è¯­å’Œä¿„è¯­ï¼‰ã€‚ç”±äºGUIä»£ç†å·²æ˜¾ç¤ºå‡ºå®¹æ˜“å—åˆ°æ¬ºéª—æ”»å‡»ï¼ŒmacOSWorldè¿˜åŒ…å«ä¸€ä¸ªä¸“ç”¨çš„å®‰å…¨åŸºå‡†æµ‹è¯•å­é›†ã€‚æˆ‘ä»¬å¯¹å…­ä¸ªGUIä»£ç†çš„è¯„ä¼°æ­ç¤ºäº†å·¨å¤§çš„å·®è·ï¼šä¸“æœ‰è®¡ç®—æœºä½¿ç”¨ä»£ç†çš„æˆåŠŸç‡è¶…è¿‡30%ï¼Œè€Œå¼€æºè½»å‹ç ”ç©¶æ¨¡å‹çš„æˆåŠŸç‡ä½äº2%ï¼Œè¿™å‡¸æ˜¾äº†macOSåŸŸé€‚åº”çš„éœ€æ±‚ã€‚å¤šè¯­è¨€åŸºå‡†æµ‹è¯•è¿˜æš´éœ²äº†å¸¸è§çš„å¼±ç‚¹ï¼Œç‰¹åˆ«æ˜¯åœ¨é˜¿æ‹‰ä¼¯è¯­æ–¹é¢ï¼Œä¸è‹±è¯­ç›¸æ¯”å¹³å‡ä¸‹é™äº†27.5%ã€‚å®‰å…¨åŸºå‡†æµ‹è¯•çš„ç»“æœä¹Ÿè¡¨æ˜æ¬ºéª—æ”»å‡»æ›´ä¸ºæ™®éï¼Œéœ€è¦ç«‹å³å…³æ³¨ã€‚macOSWorldå¯åœ¨[<a target="_blank" rel="noopener" href="https://github.com/showlab/macosworld%E4%B8%8A%E8%8E%B7%E5%BE%97%E3%80%82]">https://github.com/showlab/macosworldä¸Šè·å¾—ã€‚]</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.04135v2">PDF</a> Error regarding experiment results</p>
<p><strong>Summary</strong></p>
<p>è¯¥æ–‡ä»‹ç»äº†ä¸€ä¸ªé’ˆå¯¹ macOS ç³»ç»Ÿä¸Š GUI è‡ªåŠ¨åŒ–ä»£ç†çš„ç»¼åˆè¯„ä¼°åŸºå‡†â€”â€”macOSWorldã€‚è¯¥åŸºå‡†åŒ…å«å¤šè¯­è¨€äº¤äº’å¼ä»»åŠ¡ï¼Œæ¶µç›– 30 ä¸ªåº”ç”¨ç¨‹åºï¼ˆå…¶ä¸­ 28 ä¸ªä¸º macOS ç‹¬å®¶åº”ç”¨ï¼‰ï¼Œå¹¶æä¾›äº”ç§è¯­è¨€çš„ä»»åŠ¡æŒ‡ä»¤å’Œæ“ä½œç³»ç»Ÿç•Œé¢ï¼ˆè‹±è¯­ã€ä¸­æ–‡ã€é˜¿æ‹‰ä¼¯è¯­ã€æ—¥è¯­å’Œä¿„è¯­ï¼‰ã€‚åŒæ—¶ï¼Œå®ƒä¹ŸåŒ…å«ç”¨äºè¯„ä¼°ä»£ç†å®‰å…¨æ€§çš„ä¸“é—¨åŸºå‡†ã€‚å®éªŒè¯„ä¼°æ˜¾ç¤ºï¼Œä¸“ç”¨è®¡ç®—æœºä½¿ç”¨ä»£ç†åœ¨ macOS ä¸Šçš„æˆåŠŸç‡è¶…è¿‡ 30%ï¼Œè€Œå¼€æºè½»é‡çº§ç ”ç©¶æ¨¡å‹çš„æˆåŠŸç‡ä½äº 2%ï¼Œçªæ˜¾äº†é€‚åº” macOS åŸŸçš„éœ€æ±‚ã€‚å¤šè¯­è¨€åŸºå‡†æš´éœ²äº†åœ¨é˜¿æ‹‰ä¼¯è¯­ç¯å¢ƒä¸­çš„æ™®éå¼±ç‚¹ï¼Œä¸è‹±è¯­ç›¸æ¯”å¹³å‡æ€§èƒ½ä¸‹é™ 27.5%ã€‚å®‰å…¨æ€§è¯„ä¼°ç»“æœä¹Ÿè¡¨æ˜æ¬ºéª—æ”»å‡»æ›´ä¸ºæ™®éï¼Œéœ€è¦å¼•èµ·å…³æ³¨ã€‚macOSWorld åŸºå‡†å·²åœ¨ GitHub ä¸Šå‘å¸ƒã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>macOSWorld æ˜¯ç¬¬ä¸€ä¸ªé’ˆå¯¹ macOS ä¸Š GUI è‡ªåŠ¨åŒ–ä»£ç†çš„ç»¼åˆè¯„ä¼°åŸºå‡†ã€‚</li>
<li>å®ƒåŒ…å« 202 ä¸ªå¤šè¯­è¨€äº¤äº’å¼ä»»åŠ¡ï¼Œæ¶µç›– 30 ä¸ªåº”ç”¨ç¨‹åºï¼Œå¹¶æä¾›äº”ç§è¯­è¨€çš„ä»»åŠ¡æŒ‡ä»¤å’Œæ“ä½œç³»ç»Ÿç•Œé¢ã€‚</li>
<li>GUI è‡ªåŠ¨åŒ–ä»£ç†å®¹æ˜“å—åˆ°æ¬ºéª—æ”»å‡»ï¼Œéœ€è¦å…³æ³¨å®‰å…¨æ€§è¯„ä¼°ã€‚</li>
<li>å®éªŒè¯„ä¼°æ˜¾ç¤ºï¼Œä¸“ç”¨è®¡ç®—æœºä½¿ç”¨ä»£ç†åœ¨ macOS ä¸Šçš„è¡¨ç°è¿œä¼˜äºå¼€æºè½»é‡çº§ç ”ç©¶æ¨¡å‹ã€‚</li>
<li>å¤šè¯­è¨€ç¯å¢ƒä¸‹çš„è¯„ä¼°ç»“æœè¡¨æ˜ï¼Œé˜¿æ‹‰ä¼¯è¯­ç¯å¢ƒä¸­çš„æ€§èƒ½é—®é¢˜è¾ƒä¸ºçªå‡ºã€‚</li>
<li>macOSWorld åŸºå‡†å·²åœ¨ GitHub ä¸Šå‘å¸ƒï¼Œä¾¿äºå…¬ä¼—è®¿é—®å’Œä½¿ç”¨ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.04135">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-714bb0ebda4cd0a01cfa9a439f04d895.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-04c89ccdf1de85aeed30db2f04039684.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-7c1ef3c4afddf3963c4ee6646e2088cb.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-67303a00ae452baf550de3156d3b065f.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-42f03fa750fe55465e2707bc591d906e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-10cd1ec42668427458bcb3704fe9d0c8.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="MIRROR-Multi-agent-Intra-and-Inter-Reflection-for-Optimized-Reasoning-in-Tool-Learning"><a href="#MIRROR-Multi-agent-Intra-and-Inter-Reflection-for-Optimized-Reasoning-in-Tool-Learning" class="headerlink" title="MIRROR: Multi-agent Intra- and Inter-Reflection for Optimized Reasoning   in Tool Learning"></a>MIRROR: Multi-agent Intra- and Inter-Reflection for Optimized Reasoning   in Tool Learning</h2><p><strong>Authors:Zikang Guo, Benfeng Xu, Xiaorui Wang, Zhendong Mao</strong></p>
<p>Complex tasks involving tool integration pose significant challenges for Large Language Models (LLMs), leading to the emergence of multi-agent workflows as a promising solution. Reflection has emerged as an effective strategy for correcting erroneous trajectories in agentic workflows. However, existing approaches only exploit such capability in the post-action stage, where the agent observes the execution outcomes. We argue that, like humans, LLMs can also engage in reflection before action execution: the agent can anticipate undesirable outcomes from its own decisions, which not only provides a necessarily complementary perspective to evaluate the decision but also prevents the propagation of errors throughout the trajectory. In this paper, we propose MIRROR, a framework that consists of both intra-reflection, which critically assesses intended actions before execution, and inter-reflection, which further adjusts the trajectory based on observations. This design systematically leverages LLM reflection capabilities to eliminate and rectify erroneous actions on a more comprehensive scope. Evaluations on both the StableToolBench and TravelPlanner benchmarks demonstrate MIRRORâ€™s superior performance, achieving state-of-the-art results compared to existing approaches. </p>
<blockquote>
<p>æ¶‰åŠå·¥å…·é›†æˆçš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä»»åŠ¡é¢ä¸´å·¨å¤§æŒ‘æˆ˜ï¼Œå¤šæ™ºèƒ½ä½“å·¥ä½œæµç¨‹ä½œä¸ºè§£å†³è¿™ä¸€é—®é¢˜çš„æ–°å…´æ–¹æ¡ˆã€‚åæ€ä½œä¸ºä¸€ç§æœ‰æ•ˆçš„ç­–ç•¥ï¼Œåœ¨æ™ºèƒ½ä½“å·¥ä½œæµç¨‹ä¸­å¯ä»¥çº æ­£é”™è¯¯çš„è½¨è¿¹ã€‚ç„¶è€Œï¼Œç°æœ‰çš„æ–¹æ³•åªå°†åæ€èƒ½åŠ›åº”ç”¨äºäº‹åé˜¶æ®µï¼Œæ­¤æ—¶æ™ºèƒ½ä½“é€šè¿‡è§‚å¯Ÿç»“æœæ¥è¿›è¡Œåˆ¤æ–­ã€‚æˆ‘ä»¬è®¤ä¸ºï¼Œå°±åƒäººç±»ä¸€æ ·ï¼ŒLLMä¹Ÿå¯ä»¥åœ¨æ‰§è¡Œè¡ŒåŠ¨ä¹‹å‰è¿›è¡Œåæ€ï¼šæ™ºèƒ½ä½“å¯ä»¥é¢„æµ‹å…¶è‡ªèº«å†³ç­–å¯èƒ½å¸¦æ¥çš„ä¸è‰¯åæœï¼Œè¿™ä¸ä»…æä¾›äº†ä¸€ä¸ªå¿…è¦çš„è§’åº¦å¯¹å†³ç­–è¿›è¡Œè¯„ä¼°ï¼Œè€Œä¸”é˜²æ­¢äº†é”™è¯¯åœ¨æ•´ä¸ªè½¨è¿¹ä¸­çš„ä¼ æ’­ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸ºMIRRORçš„æ¡†æ¶ï¼Œå®ƒç»“åˆäº†å†…åæ€å’Œå¤–åæ€ä¸¤ä¸ªæ¨¡å—ã€‚å†…åæ€æ¨¡å—åœ¨è¡ŒåŠ¨æ‰§è¡Œå‰å¯¹è®¡åˆ’è¡ŒåŠ¨è¿›è¡Œæ‰¹åˆ¤æ€§è¯„ä¼°ï¼Œè€Œå¤–åæ€æ¨¡å—åˆ™åŸºäºè§‚å¯Ÿè¿›ä¸€æ­¥è°ƒæ•´è½¨è¿¹ã€‚è¿™ç§è®¾è®¡ç³»ç»Ÿåˆ©ç”¨LLMçš„åæ€èƒ½åŠ›åœ¨æ›´å¹¿æ³›çš„èŒƒå›´å†…æ¶ˆé™¤å’Œçº æ­£é”™è¯¯è¡Œä¸ºã€‚åœ¨StableToolBenchå’ŒTravelPlanneråŸºå‡†æµ‹è¯•ä¸Šçš„è¯„ä¼°è¯æ˜äº†MIRRORçš„å“è¶Šæ€§èƒ½ï¼Œä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”å–å¾—äº†æœ€å…ˆè¿›çš„æˆæœã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.20670v2">PDF</a> Accepted to 34rd International Joint Conference on Artificial   Intelligence (IJCAI 2025)</p>
<p><strong>Summary</strong></p>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨æ¶‰åŠå·¥å…·æ•´åˆçš„å¤æ‚ä»»åŠ¡ä¸Šé¢ä¸´æŒ‘æˆ˜ï¼Œå¤šä»£ç†å·¥ä½œæµç¨‹åº”è¿è€Œç”Ÿä¸ºè§£å†³æ­¤é—®é¢˜çš„ä¸€ç§æœ‰å‰é€”çš„æ–¹æ¡ˆã€‚åæ€å·²æˆä¸ºçº æ­£ä»£ç†å·¥ä½œæµç¨‹ä¸­é”™è¯¯è½¨è¿¹çš„æœ‰æ•ˆç­–ç•¥ã€‚ç„¶è€Œï¼Œç°æœ‰æ–¹æ³•ä»…åœ¨ä»£ç†è§‚å¯Ÿæ‰§è¡Œç»“æœçš„åè¡ŒåŠ¨é˜¶æ®µåˆ©ç”¨è¿™ç§èƒ½åŠ›ã€‚æœ¬æ–‡æå‡ºï¼Œä¸äººç±»ä¸€æ ·ï¼ŒLLMä¹Ÿå¯ä»¥åœ¨è¡ŒåŠ¨æ‰§è¡Œå‰è¿›è¡Œåæ€ï¼šä»£ç†å¯ä»¥é¢„è§åˆ°è‡ªå·±å†³ç­–çš„ä¸ç†æƒ³ç»“æœï¼Œè¿™ä¸ä»…æä¾›äº†è¯„ä¼°å†³ç­–çš„å¿…è¦çš„è¡¥å……è§†è§’ï¼Œè€Œä¸”é˜²æ­¢äº†é”™è¯¯åœ¨æ•´ä¸ªè½¨è¿¹ä¸­çš„ä¼ æ’­ã€‚æœ¬æ–‡æå‡ºäº†MIRRORæ¡†æ¶ï¼ŒåŒ…æ‹¬æ‰§è¡Œå‰åæ€ï¼ˆintra-reflectionï¼‰å’Œæ‰§è¡Œååæ€ï¼ˆinter-reflectionï¼‰ï¼Œå‰è€…å¯¹é¢„å®šè¡ŒåŠ¨è¿›è¡Œæ‰¹åˆ¤æ€§è¯„ä¼°ï¼Œåè€…åŸºäºè§‚å¯Ÿè¿›ä¸€æ­¥è°ƒæ•´è½¨è¿¹ã€‚æ­¤è®¾è®¡ç³»ç»Ÿåœ°åˆ©ç”¨LLMçš„åæ€èƒ½åŠ›ï¼Œåœ¨æ›´å¹¿æ³›çš„èŒƒå›´å†…æ¶ˆé™¤å’Œçº æ­£é”™è¯¯è¡ŒåŠ¨ã€‚åœ¨StableToolBenchå’ŒTravelPlanneråŸºå‡†æµ‹è¯•ä¸Šçš„è¯„ä¼°è¡¨æ˜ï¼ŒMIRRORæ€§èƒ½å“è¶Šï¼Œä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”è¾¾åˆ°äº†æœ€æ–°æ°´å¹³ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨å¤„ç†æ¶‰åŠå·¥å…·æ•´åˆçš„å¤æ‚ä»»åŠ¡æ—¶é¢ä¸´æŒ‘æˆ˜ã€‚</li>
<li>å¤šä»£ç†å·¥ä½œæµç¨‹æ˜¯è§£å†³è¿™äº›é—®é¢˜çš„æœ‰å‰é€”çš„æ–¹æ¡ˆã€‚</li>
<li>åæ€æ˜¯çº æ­£ä»£ç†å·¥ä½œæµç¨‹ä¸­é”™è¯¯è½¨è¿¹çš„æœ‰æ•ˆæ–¹æ³•ã€‚</li>
<li>ç°æœ‰æ–¹æ³•ä¸»è¦åœ¨è¡ŒåŠ¨åçš„é˜¶æ®µåˆ©ç”¨åæ€èƒ½åŠ›ã€‚</li>
<li>LLMå¯ä»¥åœ¨è¡ŒåŠ¨å‰è¿›è¡Œåæ€ï¼Œé¢„æµ‹å¹¶é˜²æ­¢å†³ç­–ä¸­çš„é”™è¯¯ã€‚</li>
<li>MIRRORæ¡†æ¶ç»“åˆäº†è¡ŒåŠ¨å‰å’Œè¡ŒåŠ¨åçš„åæ€ï¼Œä»¥æ¶ˆé™¤å’Œçº æ­£é”™è¯¯ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.20670">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-33df328a360d4d8a3ff7b8e3a293127d.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-b085e8d312f42dc9b711e0d735357c49.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-b928fccaa6007c42ef6b2423cb3aa723.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e3d0579a45d0bc94f2df2ca855db4a18.jpg" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="OmniCharacter-Towards-Immersive-Role-Playing-Agents-with-Seamless-Speech-Language-Personality-Interaction"><a href="#OmniCharacter-Towards-Immersive-Role-Playing-Agents-with-Seamless-Speech-Language-Personality-Interaction" class="headerlink" title="OmniCharacter: Towards Immersive Role-Playing Agents with Seamless   Speech-Language Personality Interaction"></a>OmniCharacter: Towards Immersive Role-Playing Agents with Seamless   Speech-Language Personality Interaction</h2><p><strong>Authors:Haonan Zhang, Run Luo, Xiong Liu, Yuchuan Wu, Ting-En Lin, Pengpeng Zeng, Qiang Qu, Feiteng Fang, Min Yang, Lianli Gao, Jingkuan Song, Fei Huang, Yongbin Li</strong></p>
<p>Role-Playing Agents (RPAs), benefiting from large language models, is an emerging interactive AI system that simulates roles or characters with diverse personalities. However, existing methods primarily focus on mimicking dialogues among roles in textual form, neglecting the roleâ€™s voice traits (e.g., voice style and emotions) as playing a crucial effect in interaction, which tends to be more immersive experiences in realistic scenarios. Towards this goal, we propose OmniCharacter, a first seamless speech-language personality interaction model to achieve immersive RPAs with low latency. Specifically, OmniCharacter enables agents to consistently exhibit role-specific personality traits and vocal traits throughout the interaction, enabling a mixture of speech and language responses. To align the model with speech-language scenarios, we construct a dataset named OmniCharacter-10K, which involves more distinctive characters (20), richly contextualized multi-round dialogue (10K), and dynamic speech response (135K). Experimental results showcase that our method yields better responses in terms of both content and style compared to existing RPAs and mainstream speech-language models, with a response latency as low as 289ms. Code and dataset are available at <a target="_blank" rel="noopener" href="https://github.com/AlibabaResearch/DAMO-ConvAI/tree/main/OmniCharacter">https://github.com/AlibabaResearch/DAMO-ConvAI/tree/main/OmniCharacter</a>. </p>
<blockquote>
<p>è§’è‰²æ‰®æ¼”ä»£ç†ï¼ˆRPAsï¼‰å—ç›Šäºå¤§å‹è¯­è¨€æ¨¡å‹ï¼Œæ˜¯ä¸€ç§æ–°å…´çš„äº’åŠ¨äººå·¥æ™ºèƒ½ç³»ç»Ÿï¼Œèƒ½å¤Ÿæ¨¡æ‹Ÿå…·æœ‰ä¸åŒä¸ªæ€§çš„è§’è‰²æˆ–äººç‰©ã€‚ç„¶è€Œï¼Œç°æœ‰æ–¹æ³•ä¸»è¦é›†ä¸­åœ¨ä»¥æ–‡æœ¬å½¢å¼æ¨¡ä»¿è§’è‰²ä¹‹é—´çš„å¯¹è¯ï¼Œå¿½è§†äº†è§’è‰²çš„è¯­éŸ³ç‰¹å¾ï¼ˆä¾‹å¦‚è¯­éŸ³é£æ ¼å’Œæƒ…æ„Ÿï¼‰åœ¨äº’åŠ¨ä¸­çš„å…³é”®ä½œç”¨ï¼Œè¿™åœ¨ç°å®åœºæ™¯ä¸­å¾€å¾€èƒ½å¸¦æ¥æ›´å…·æ²‰æµ¸æ„Ÿçš„ä½“éªŒã€‚åŸºäºæ­¤ç›®æ ‡ï¼Œæˆ‘ä»¬æå‡ºäº†OmniCharacterï¼Œé¦–ä¸ªæ— ç¼è¯­éŸ³-è¯­è¨€ä¸ªæ€§äº’åŠ¨æ¨¡å‹ï¼Œæ—¨åœ¨å®ç°å…·æœ‰ä½å»¶è¿Ÿçš„æ²‰æµ¸å¼RPAsã€‚å…·ä½“æ¥è¯´ï¼ŒOmniCharacterä½¿ä»£ç†èƒ½å¤Ÿåœ¨äº’åŠ¨ä¸­æŒç»­å±•ç°å‡ºç‰¹å®šè§’è‰²çš„ä¸ªæ€§ç‰¹å¾å’Œè¯­éŸ³ç‰¹å¾ï¼Œå®ç°è¯­éŸ³å’Œè¯­è¨€å“åº”çš„æ··åˆã€‚ä¸ºäº†å°†æ¨¡å‹ä¸è¯­éŸ³è¯­è¨€åœºæ™¯ç›¸ç»“åˆï¼Œæˆ‘ä»¬æ„å»ºäº†ä¸€ä¸ªåä¸ºOmniCharacter-10Kçš„æ•°æ®é›†ï¼Œå…¶ä¸­åŒ…æ‹¬æ›´å¤šç‹¬ç‰¹çš„äººç‰©ï¼ˆ20ä¸ªï¼‰ã€ä¸°å¯Œçš„ä¸Šä¸‹æ–‡å¤šè½®å¯¹è¯ï¼ˆ10Kï¼‰å’ŒåŠ¨æ€è¯­éŸ³å“åº”ï¼ˆ135Kï¼‰ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨å†…å®¹å’Œé£æ ¼æ–¹é¢çš„å›åº”éƒ½ä¼˜äºç°æœ‰RPAså’Œä¸»æµè¯­éŸ³è¯­è¨€æ¨¡å‹ï¼Œå“åº”å»¶è¿Ÿä½è‡³289æ¯«ç§’ã€‚ä»£ç å’Œæ•°æ®é›†å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/AlibabaResearch/DAMO-ConvAI/tree/main/OmniCharacter%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/AlibabaResearch/DAMO-ConvAI/tree/main/OmniCharacteræ‰¾åˆ°ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.20277v2">PDF</a> 14 pages, 6 figures</p>
<p><strong>Summary</strong></p>
<p>åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹çš„è§’è‰²æ‰®æ¼”ä»£ç†ï¼ˆRPAsï¼‰æ˜¯ä¸€ç§æ–°å…´çš„æ™ºèƒ½äº¤äº’ç³»ç»Ÿï¼Œèƒ½æ¨¡æ‹Ÿå…·æœ‰ä¸åŒä¸ªæ€§çš„è§’è‰²ã€‚ç„¶è€Œï¼Œç°æœ‰æ–¹æ³•ä¸»è¦å…³æ³¨æ–‡æœ¬å½¢å¼çš„å¯¹è¯æ¨¡ä»¿ï¼Œå¿½è§†äº†è§’è‰²çš„è¯­éŸ³ç‰¹è´¨ï¼ˆå¦‚è¯­éŸ³é£æ ¼å’Œæƒ…æ„Ÿï¼‰åœ¨äº¤äº’ä¸­çš„é‡è¦ä½œç”¨ï¼Œè¿™åœ¨ç°å®åœºæ™¯ä¸­å¾€å¾€èƒ½æä¾›æ›´æ²‰æµ¸çš„ä½“éªŒã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬æå‡ºOmniCharacterï¼Œä¸€ä¸ªæ— ç¼çš„è¯­éŸ³-è¯­è¨€ä¸ªæ€§äº¤äº’æ¨¡å‹ï¼Œæ—¨åœ¨å®ç°å…·æœ‰ä½å»¶è¿Ÿçš„æ²‰æµ¸å¼RPAsã€‚OmniCharacterä½¿ä»£ç†èƒ½å¤Ÿåœ¨äº¤äº’ä¸­å§‹ç»ˆè¡¨ç°å‡ºç‰¹å®šçš„è§’è‰²ä¸ªæ€§å’Œè¯­éŸ³ç‰¹è´¨ï¼Œå®ç°è¯­éŸ³å’Œè¯­è¨€å“åº”çš„æ··åˆã€‚ä¸ºäº†ä¸è¯­éŸ³-è¯­è¨€åœºæ™¯å¯¹é½ï¼Œæˆ‘ä»¬æ„å»ºäº†åä¸ºOmniCharacter-10Kçš„æ•°æ®é›†ï¼ŒåŒ…å«æ›´å¤šé²œæ˜çš„è§’è‰²ï¼ˆ20ä¸ªï¼‰ã€ä¸°å¯Œçš„ä¸Šä¸‹æ–‡å¤šè½®å¯¹è¯ï¼ˆ10Kï¼‰å’ŒåŠ¨æ€è¯­éŸ³å“åº”ï¼ˆ135Kï¼‰ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨å†…å®¹å’Œé£æ ¼ä¸Šçš„å“åº”ä¼˜äºç°æœ‰RPAså’Œä¸»æµè¯­éŸ³-è¯­è¨€æ¨¡å‹ï¼Œå“åº”å»¶è¿Ÿä½è‡³289æ¯«ç§’ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>è§’è‰²æ‰®æ¼”ä»£ç†ï¼ˆRPAsï¼‰æ˜¯æ–°å…´çš„æ™ºèƒ½äº¤äº’ç³»ç»Ÿï¼Œå¯æ¨¡æ‹Ÿå…·æœ‰ä¸åŒä¸ªæ€§çš„è§’è‰²ã€‚</li>
<li>ç°æœ‰æ–¹æ³•ä¸»è¦å…³æ³¨æ–‡æœ¬å¯¹è¯çš„æ¨¡ä»¿ï¼Œå¿½è§†äº†è§’è‰²çš„è¯­éŸ³ç‰¹è´¨åœ¨äº¤äº’ä¸­çš„é‡è¦æ€§ã€‚</li>
<li>OmniCharacteræ¨¡å‹å®ç°äº†æ— ç¼çš„è¯­éŸ³-è¯­è¨€ä¸ªæ€§äº¤äº’ï¼Œæ—¨åœ¨å®ç°æ²‰æµ¸å¼RPAsï¼Œå¹¶å…·æœ‰ä½å»¶è¿Ÿç‰¹ç‚¹ã€‚</li>
<li>OmniCharacterä½¿ä»£ç†èƒ½åœ¨äº¤äº’ä¸­å±•ç°è§’è‰²ç‰¹å®šçš„ä¸ªæ€§å’Œè¯­éŸ³ç‰¹è´¨ã€‚</li>
<li>ä¸ºé…åˆè¯­éŸ³-è¯­è¨€åœºæ™¯ï¼Œæ„å»ºäº†OmniCharacter-10Kæ•°æ®é›†ï¼ŒåŒ…å«ä¸°å¯Œå¤šæ ·çš„è§’è‰²ã€å¯¹è¯å’Œè¯­éŸ³å“åº”ã€‚</li>
<li>å®éªŒç»“æœè¡¨æ˜ï¼ŒOmniCharacteråœ¨å†…å®¹å’Œé£æ ¼ä¸Šçš„å“åº”ä¼˜äºå…¶ä»–æ¨¡å‹ï¼Œå“åº”å»¶è¿Ÿè¾ƒä½ã€‚</li>
<li>è¯¥ç ”ç©¶çš„ä»£ç å’Œæ•°æ®é›†å·²å…¬å¼€å¯ç”¨ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.20277">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-1e2e1f49162bdad468b2a1ecc1e04038.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-2621d575740d87c46551a528309d0d65.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-751a473bb018f2f4255f73b8f42147a2.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-164aa89b5d00b38f915ab43a129436f5.jpg" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1><h2 id="Offline-Multi-agent-Reinforcement-Learning-via-Score-Decomposition"><a href="#Offline-Multi-agent-Reinforcement-Learning-via-Score-Decomposition" class="headerlink" title="Offline Multi-agent Reinforcement Learning via Score Decomposition"></a>Offline Multi-agent Reinforcement Learning via Score Decomposition</h2><p><strong>Authors:Dan Qiao, Wenhao Li, Shanchao Yang, Hongyuan Zha, Baoxiang Wang</strong></p>
<p>Offline cooperative multi-agent reinforcement learning (MARL) faces unique challenges due to distributional shifts, particularly stemming from the high dimensionality of joint action spaces and the presence of out-of-distribution joint action selections. In this work, we highlight that a fundamental challenge in offline MARL arises from the multi-equilibrium nature of cooperative tasks, which induces a highly multimodal joint behavior policy space coupled with heterogeneous-quality behavior data. This makes it difficult for individual policy regularization to align with a consistent coordination pattern, leading to the policy distribution shift problems. To tackle this challenge, we design a sequential score function decomposition method that distills per-agent regularization signals from the joint behavior policy, which induces coordinated modality selection under decentralized execution constraints. Then we leverage a flexible diffusion-based generative model to learn these score functions from multimodal offline data, and integrate them into joint-action critics to guide policy updates toward high-reward, in-distribution regions under a shared team reward. Our approach achieves state-of-the-art performance across multiple particle environments and Multi-agent MuJoCo benchmarks consistently. To the best of our knowledge, this is the first work to explicitly address the distributional gap between offline and online MARL, paving the way for more generalizable offline policy-based MARL methods. </p>
<blockquote>
<p>ç¦»çº¿å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ ï¼ˆMARLï¼‰é¢ä¸´ç€ç”±äºåˆ†å¸ƒè½¬ç§»å¸¦æ¥çš„ç‹¬ç‰¹æŒ‘æˆ˜ï¼Œç‰¹åˆ«æ˜¯æºäºè”åˆåŠ¨ä½œç©ºé—´çš„é«˜ç»´åº¦å’Œå­˜åœ¨è¶…å‡ºåˆ†å¸ƒèŒƒå›´çš„è”åˆåŠ¨ä½œé€‰æ‹©ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬å¼ºè°ƒç¦»çº¿MARLä¸­çš„åŸºæœ¬æŒ‘æˆ˜æ¥è‡ªäºåˆä½œä»»åŠ¡çš„å¤šä¸ªå‡è¡¡çŠ¶æ€æ€§è´¨ï¼Œè¿™å¯¼è‡´äº†ä¸€ä¸ªä¸å¼‚è´¨è´¨é‡è¡Œä¸ºæ•°æ®ç›¸ç»“åˆçš„ã€é«˜åº¦å¤šæ¨¡æ€çš„è”åˆè¡Œä¸ºç­–ç•¥ç©ºé—´ã€‚è¿™ä½¿å¾—ä¸ªä½“ç­–ç•¥æ­£åˆ™åŒ–éš¾ä»¥ä¸ä¸€è‡´çš„åè°ƒæ¨¡å¼å¯¹é½ï¼Œä»è€Œå¯¼è‡´ç­–ç•¥åˆ†å¸ƒè½¬ç§»é—®é¢˜ã€‚ä¸ºäº†åº”å¯¹è¿™ä¸€æŒ‘æˆ˜ï¼Œæˆ‘ä»¬è®¾è®¡äº†ä¸€ç§é¡ºåºå¾—åˆ†å‡½æ•°åˆ†è§£æ–¹æ³•ï¼Œä»è”åˆè¡Œä¸ºç­–ç•¥ä¸­æç‚¼å‡ºé’ˆå¯¹æ¯ä¸ªæ™ºèƒ½ä½“çš„æ­£åˆ™åŒ–ä¿¡å·ï¼Œåœ¨åˆ†å¸ƒå¼æ‰§è¡Œçº¦æŸä¸‹è¯±å¯¼åè°ƒæ¨¡å¼é€‰æ‹©ã€‚ç„¶åï¼Œæˆ‘ä»¬åˆ©ç”¨çµæ´»çš„åŸºäºæ‰©æ•£çš„ç”Ÿæˆæ¨¡å‹ä»è¿™äº›å¤šæ¨¡æ€ç¦»çº¿æ•°æ®ä¸­å­¦ä¹ è¿™äº›å¾—åˆ†å‡½æ•°ï¼Œå¹¶å°†å®ƒä»¬æ•´åˆåˆ°è”åˆåŠ¨ä½œæ‰¹è¯„è€…ä¸­ï¼Œä»¥æŒ‡å¯¼ç­–ç•¥æ›´æ–°æœç€é«˜å¥–åŠ±ã€åœ¨åˆ†å¸ƒèŒƒå›´å†…çš„åŒºåŸŸå‘å±•ï¼Œä»¥å®ç°å…±äº«çš„å›¢é˜Ÿå¥–åŠ±ã€‚æˆ‘ä»¬çš„æ–¹æ³•åœ¨å¤šä¸ªç²’å­ç¯å¢ƒå’Œå¤šæ™ºèƒ½ä½“MuJoCoåŸºå‡†æµ‹è¯•ä¸­å®ç°äº†æœ€æ–°æ€§èƒ½ã€‚æ®æˆ‘ä»¬æ‰€çŸ¥ï¼Œè¿™æ˜¯ç¬¬ä¸€é¡¹æ˜ç¡®è§£å†³ç¦»çº¿ä¸åœ¨çº¿MARLä¹‹é—´åˆ†å¸ƒå·®è·çš„å·¥ä½œï¼Œä¸ºæ›´é€šç”¨çš„ç¦»çº¿ç­–ç•¥å‹MARLæ–¹æ³•é“ºå¹³äº†é“è·¯ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.05968v2">PDF</a> Working papers</p>
<p><strong>Summary</strong><br>     ç¦»çº¿å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ ï¼ˆMARLï¼‰é¢ä¸´åˆ†å¸ƒè½¬ç§»çš„ç‹¬ç‰¹æŒ‘æˆ˜ï¼Œç‰¹åˆ«æ˜¯æºäºè”åˆåŠ¨ä½œç©ºé—´çš„é«˜ç»´åº¦å’Œå­˜åœ¨è¶…å‡ºåˆ†å¸ƒèŒƒå›´çš„è”åˆåŠ¨ä½œé€‰æ‹©ã€‚æœ¬æ–‡å¼ºè°ƒï¼Œç¦»çº¿MARLçš„ä¸€ä¸ªåŸºæœ¬æŒ‘æˆ˜æ¥è‡ªäºåˆä½œä»»åŠ¡çš„å¤šå…ƒå¹³è¡¡æ€§è´¨ï¼Œè¿™å¯¼è‡´äº†å¤æ‚çš„è”åˆè¡Œä¸ºç­–ç•¥ç©ºé—´ä»¥åŠå¼‚è´¨è´¨é‡çš„è¡Œä¸ºæ•°æ®ã€‚è¿™ä½¿å¾—ä¸ªä½“ç­–ç•¥æ­£åˆ™åŒ–éš¾ä»¥ä¸ä¸€è‡´çš„åè°ƒæ¨¡å¼å¯¹é½ï¼Œä»è€Œå¯¼è‡´ç­–ç•¥åˆ†å¸ƒè½¬ç§»é—®é¢˜ã€‚æœ¬ç ”ç©¶è®¾è®¡äº†ä¸€ç§é¡ºåºå¾—åˆ†å‡½æ•°åˆ†è§£æ–¹æ³•ï¼Œä»è”åˆè¡Œä¸ºç­–ç•¥ä¸­æç‚¼å‡ºæ™ºèƒ½ä½“ç­–ç•¥æ­£åˆ™åŒ–ä¿¡å·ï¼Œå¹¶åœ¨åˆ†æ•£æ‰§è¡Œçº¦æŸä¸‹å¼•å¯¼åè°ƒæ¨¡æ€é€‰æ‹©ã€‚ç„¶ååˆ©ç”¨çµæ´»çš„åŸºäºæ‰©æ•£çš„ç”Ÿæˆæ¨¡å‹ä»è¿™äº›å¤šæ¨¡æ€ç¦»çº¿æ•°æ®ä¸­å­¦ä¹ å¾—åˆ†å‡½æ•°ï¼Œå¹¶å°†å…¶æ•´åˆåˆ°è”åˆåŠ¨ä½œè¯„ä»·ä¸­ï¼Œä»¥æŒ‡å¯¼ç­–ç•¥æ›´æ–°æœå‘é«˜å¥–åŠ±ã€åœ¨åˆ†å¸ƒåŒºåŸŸå†…çš„å…±äº«å›¢é˜Ÿå¥–åŠ±ã€‚è¯¥æ–¹æ³•åœ¨å¤šæ™ºèƒ½ä½“ç¯å¢ƒå’ŒMuJoCoåŸºå‡†æµ‹è¯•ä¸­å–å¾—äº†æœ€ä½³æ€§èƒ½ã€‚æ®æˆ‘ä»¬æ‰€çŸ¥ï¼Œè¿™æ˜¯é¦–æ¬¡æ˜ç¡®è§£å†³ç¦»çº¿ä¸åœ¨çº¿MARLä¹‹é—´çš„åˆ†å¸ƒå·®è·çš„å·¥ä½œï¼Œä¸ºæ›´é€šç”¨çš„ç¦»çº¿ç­–ç•¥å‹MARLæ–¹æ³•é“ºå¹³äº†é“è·¯ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ç¦»çº¿å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ ï¼ˆMARLï¼‰é¢ä¸´ç‹¬ç‰¹çš„æŒ‘æˆ˜ï¼ŒåŒ…æ‹¬åˆ†å¸ƒè½¬ç§»ã€è”åˆåŠ¨ä½œç©ºé—´çš„é«˜ç»´åº¦ä»¥åŠè¶…å‡ºåˆ†å¸ƒèŒƒå›´çš„è”åˆåŠ¨ä½œé€‰æ‹©ã€‚</li>
<li>åˆä½œä»»åŠ¡çš„å¤šå…ƒå¹³è¡¡æ€§è´¨å¯¼è‡´å¤æ‚çš„è”åˆè¡Œä¸ºç­–ç•¥ç©ºé—´å’Œå¼‚è´¨è´¨é‡çš„è¡Œä¸ºæ•°æ®ï¼Œå¢åŠ äº†ç­–ç•¥æ­£åˆ™åŒ–çš„éš¾åº¦ã€‚</li>
<li>è®¾è®¡çš„é¡ºåºå¾—åˆ†å‡½æ•°åˆ†è§£æ–¹æ³•å¯ä»¥ä»è”åˆè¡Œä¸ºç­–ç•¥ä¸­æç‚¼å‡ºæ™ºèƒ½ä½“ç­–ç•¥æ­£åˆ™åŒ–ä¿¡å·ï¼Œå¼•å¯¼åè°ƒæ¨¡æ€é€‰æ‹©ã€‚</li>
<li>åˆ©ç”¨åŸºäºæ‰©æ•£çš„ç”Ÿæˆæ¨¡å‹å­¦ä¹ å¤šæ¨¡æ€ç¦»çº¿æ•°æ®ä¸­çš„å¾—åˆ†å‡½æ•°ï¼Œæ•´åˆåˆ°è”åˆåŠ¨ä½œè¯„ä»·ä¸­ã€‚</li>
<li>æ–¹æ³•æ—¨åœ¨å°†ç­–ç•¥æ›´æ–°å¯¼å‘é«˜å¥–åŠ±ã€åœ¨åˆ†å¸ƒåŒºåŸŸå†…çš„å…±äº«å›¢é˜Ÿå¥–åŠ±ã€‚</li>
<li>åœ¨å¤šä¸ªæ™ºèƒ½ä½“ç¯å¢ƒå’ŒMuJoCoåŸºå‡†æµ‹è¯•ä¸­å–å¾—äº†æœ€ä½³æ€§èƒ½è¡¨ç°ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.05968">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-b1c643a700627aec2e3975e41c7ace4a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-bce985f5f2f4cd9085eb2909a65472ed.jpg" align="middle">
</details>


<h1 id="-9"><a href="#-9" class="headerlink" title=""></a></h1><h2 id="AGENTFUZZER-Generic-Black-Box-Fuzzing-for-Indirect-Prompt-Injection-against-LLM-Agents"><a href="#AGENTFUZZER-Generic-Black-Box-Fuzzing-for-Indirect-Prompt-Injection-against-LLM-Agents" class="headerlink" title="AGENTFUZZER: Generic Black-Box Fuzzing for Indirect Prompt Injection   against LLM Agents"></a>AGENTFUZZER: Generic Black-Box Fuzzing for Indirect Prompt Injection   against LLM Agents</h2><p><strong>Authors:Zhun Wang, Vincent Siu, Zhe Ye, Tianneng Shi, Yuzhou Nie, Xuandong Zhao, Chenguang Wang, Wenbo Guo, Dawn Song</strong></p>
<p>The strong planning and reasoning capabilities of Large Language Models (LLMs) have fostered the development of agent-based systems capable of leveraging external tools and interacting with increasingly complex environments. However, these powerful features also introduce a critical security risk: indirect prompt injection, a sophisticated attack vector that compromises the core of these agents, the LLM, by manipulating contextual information rather than direct user prompts. In this work, we propose a generic black-box fuzzing framework, AgentFuzzer, designed to automatically discover and exploit indirect prompt injection vulnerabilities across diverse LLM agents. Our approach starts by constructing a high-quality initial seed corpus, then employs a seed selection algorithm based on Monte Carlo Tree Search (MCTS) to iteratively refine inputs, thereby maximizing the likelihood of uncovering agent weaknesses. We evaluate AgentFuzzer on two public benchmarks, AgentDojo and VWA-adv, where it achieves 71% and 70% success rates against agents based on o3-mini and GPT-4o, respectively, nearly doubling the performance of baseline attacks. Moreover, AgentFuzzer exhibits strong transferability across unseen tasks and internal LLMs, as well as promising results against defenses. Beyond benchmark evaluations, we apply our attacks in real-world environments, successfully misleading agents to navigate to arbitrary URLs, including malicious sites. </p>
<blockquote>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„å¼ºå¤§è§„åˆ’å’Œæ¨ç†èƒ½åŠ›ä¿ƒè¿›äº†åŸºäºä»£ç†çš„ç³»ç»Ÿçš„å¼€å‘ï¼Œè¿™äº›ç³»ç»Ÿèƒ½å¤Ÿåˆ©ç”¨å¤–éƒ¨å·¥å…·å¹¶ä¸æ—¥ç›Šå¤æ‚çš„ç¯å¢ƒè¿›è¡Œäº¤äº’ã€‚ç„¶è€Œï¼Œè¿™äº›å¼ºå¤§åŠŸèƒ½ä¹Ÿå¼•å…¥äº†ä¸€ä¸ªå…³é”®çš„å®‰å…¨é£é™©ï¼šé—´æ¥æç¤ºæ³¨å…¥ï¼Œè¿™æ˜¯ä¸€ç§é«˜çº§æ”»å‡»å‘é‡ï¼Œé€šè¿‡æ“çºµä¸Šä¸‹æ–‡ä¿¡æ¯è€Œä¸æ˜¯ç›´æ¥ç”¨æˆ·æç¤ºæ¥å±å®³è¿™äº›ä»£ç†çš„æ ¸å¿ƒâ€”â€”LLMã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§é€šç”¨çš„é»‘ç›’æ¨¡ç³Šæµ‹è¯•æ¡†æ¶AgentFuzzerï¼Œæ—¨åœ¨è‡ªåŠ¨å‘ç°å’Œåˆ©ç”¨LLMä»£ç†ä¸­çš„é—´æ¥æç¤ºæ³¨å…¥æ¼æ´ã€‚æˆ‘ä»¬çš„æ–¹æ³•é¦–å…ˆæ„å»ºé«˜è´¨é‡çš„åˆå§‹ç§å­è¯­æ–™åº“ï¼Œç„¶åé‡‡ç”¨åŸºäºè’™ç‰¹å¡æ´›æ ‘æœç´¢ï¼ˆMCTSï¼‰çš„ç§å­é€‰æ‹©ç®—æ³•æ¥è¿­ä»£ä¼˜åŒ–è¾“å…¥ï¼Œä»è€Œæœ€å¤§åŒ–å‘ç°ä»£ç†å¼±ç‚¹çš„å¯èƒ½æ€§ã€‚æˆ‘ä»¬åœ¨ä¸¤ä¸ªå…¬å…±åŸºå‡†æµ‹è¯•AgentDojoå’ŒVWA-advä¸Šè¯„ä¼°äº†AgentFuzzerçš„æ€§èƒ½ï¼Œåœ¨åŸºäºo3-miniå’ŒGPT-4oçš„ä»£ç†ä¸Šåˆ†åˆ«å®ç°äº†71%å’Œ70%çš„æˆåŠŸç‡ï¼Œå‡ ä¹å°†åŸºçº¿æ”»å‡»çš„æ€§èƒ½æé«˜äº†ä¸€å€ã€‚æ­¤å¤–ï¼ŒAgentFuzzeråœ¨è·¨æœªè§ä»»åŠ¡å’Œå†…éƒ¨LLMçš„è¿ç§»æ–¹é¢å…·æœ‰å¼ºå¤§çš„å¯è¿ç§»æ€§ï¼Œå¹¶ä¸”åœ¨é˜²å¾¡æªæ–½é¢å‰ä¹Ÿè¡¨ç°å‡ºæœ‰å‰æ™¯çš„ç»“æœã€‚é™¤äº†åŸºå‡†æµ‹è¯•è¯„ä¼°å¤–ï¼Œæˆ‘ä»¬è¿˜å°†åœ¨çœŸå®ç¯å¢ƒä¸­åº”ç”¨æ”»å‡»ï¼ŒæˆåŠŸè¯¯å¯¼ä»£ç†è®¿é—®ä»»æ„URLï¼ŒåŒ…æ‹¬æ¶æ„ç½‘ç«™ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.05849v3">PDF</a> </p>
<p><strong>Summary</strong>ï¼šå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„å¼ºå¤§è§„åˆ’å’Œæ¨ç†èƒ½åŠ›ä¿ƒè¿›äº†åŸºäºä»£ç†çš„ç³»ç»Ÿçš„å¼€å‘ï¼Œä½¿å¾—ä»£ç†ç³»ç»Ÿèƒ½å¤Ÿåˆ©ç”¨å¤–éƒ¨å·¥å…·å¹¶ä¸æ—¥ç›Šå¤æ‚çš„äº¤äº’ç¯å¢ƒäº’åŠ¨ã€‚ç„¶è€Œï¼Œè¿™åŒæ—¶å¸¦æ¥äº†ä¸€ç§ä¸¥é‡çš„å®‰å…¨é£é™©â€”â€”é—´æ¥æç¤ºæ³¨å…¥æ”»å‡»ã€‚æœ¬æ¬¡ç ”ç©¶ä¸­æå‡ºäº†ä¸€ç§é€šç”¨çš„é»‘ç®±æ¨¡ç³Šæµ‹è¯•æ¡†æ¶AgentFuzzerï¼Œå®ƒèƒ½å¤Ÿè‡ªåŠ¨å‘ç°å¹¶åˆ©ç”¨LLMä¸­çš„é—´æ¥æç¤ºæ³¨å…¥æ¼æ´ã€‚æ¡†æ¶åŸºäºé«˜è´¨é‡åˆå§‹ç§å­è¯­æ–™åº“å¹¶åˆ©ç”¨è’™ç‰¹å¡ç½—æ ‘æœç´¢è¿›è¡Œç§å­é€‰æ‹©ï¼Œä»¥æœ€å¤§åŒ–å‘ç°ä»£ç†å¼±ç‚¹ã€‚åœ¨AgentDojoå’ŒVWA-advä¸¤ä¸ªå…¬å¼€åŸºå‡†æµ‹è¯•ä¸Šï¼ŒAgentFuzzeråœ¨é’ˆå¯¹åŸºäºo3-miniå’ŒGPT-4oçš„ä»£ç†æ–¹é¢è¡¨ç°ä¼˜ç§€ï¼Œç›¸è¾ƒäºåŸºç¡€æ”»å‡»æé«˜äº†è¿‘ä¸¤å€æ€§èƒ½ã€‚è€Œä¸”å…¶è¡¨ç°å‡ºå‡ºè‰²çš„ä»»åŠ¡è¿ç§»æ€§å’Œå†…éƒ¨LLMæ€§èƒ½ï¼Œå¹¶åœ¨é˜²å¾¡æ–¹é¢å±•ç°å‡ºè‰¯å¥½å‰æ™¯ã€‚æ­¤å¤–ï¼Œåœ¨çœŸå®ç¯å¢ƒä¸­åº”ç”¨æ”»å‡»æ—¶ï¼ŒæˆåŠŸè¯¯å¯¼ä»£ç†è®¿é—®ä»»æ„URLï¼ŒåŒ…æ‹¬æ¶æ„ç½‘ç«™ã€‚</p>
<p><strong>Key Takeaways</strong>ï¼š</p>
<ol>
<li>LLMçš„å¼ºå¤§è§„åˆ’å’Œæ¨ç†èƒ½åŠ›æ¨åŠ¨äº†åŸºäºä»£ç†çš„ç³»ç»Ÿçš„è¿›æ­¥ã€‚</li>
<li>é—´æ¥æç¤ºæ³¨å…¥æ˜¯ä¸€ç§ä¸¥é‡çš„å®‰å…¨é£é™©ï¼Œèƒ½å±åŠLLMçš„æ ¸å¿ƒå®‰å…¨ã€‚</li>
<li>AgentFuzzeræ˜¯ä¸€ä¸ªé€šç”¨çš„é»‘ç®±æ¨¡ç³Šæµ‹è¯•æ¡†æ¶ï¼Œç”¨äºè‡ªåŠ¨å‘ç°å¹¶åˆ©ç”¨LLMä¸­çš„é—´æ¥æç¤ºæ³¨å…¥æ¼æ´ã€‚</li>
<li>AgentFuzzerä½¿ç”¨é«˜è´¨é‡åˆå§‹ç§å­è¯­æ–™åº“å’ŒåŸºäºè’™ç‰¹å¡ç½—æ ‘æœç´¢çš„ç§å­é€‰æ‹©ç®—æ³•ã€‚</li>
<li>AgentFuzzeråœ¨å…¬å¼€åŸºå‡†æµ‹è¯•ä¸Šçš„è¡¨ç°ä¼˜äºå…¶ä»–æ”»å‡»æ–¹å¼ï¼Œå¹¶å…·å¤‡å‡ºè‰²çš„ä»»åŠ¡è¿ç§»æ€§å’Œå†…éƒ¨LLMæ€§èƒ½ã€‚</li>
<li>AgentFuzzeråœ¨çœŸå®ç¯å¢ƒä¸­æˆåŠŸè¯¯å¯¼ä»£ç†è®¿é—®æ¶æ„ç½‘ç«™ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.05849">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-7e1645bb7f08e884cc82f3eac37ac280.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-595f19d74553f10bf4e047b1a0ea38a9.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f0433441d55fa2d63c4b6a0b7ffd73da.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-7e858f1847fc6ff8e3495f4b225fe4d2.jpg" align="middle">
</details>


<h1 id="-10"><a href="#-10" class="headerlink" title=""></a></h1><h2 id="Text-to-Decision-Agent-Offline-Meta-Reinforcement-Learning-from-Natural-Language-Supervision"><a href="#Text-to-Decision-Agent-Offline-Meta-Reinforcement-Learning-from-Natural-Language-Supervision" class="headerlink" title="Text-to-Decision Agent: Offline Meta-Reinforcement Learning from Natural   Language Supervision"></a>Text-to-Decision Agent: Offline Meta-Reinforcement Learning from Natural   Language Supervision</h2><p><strong>Authors:Shilin Zhang, Zican Hu, Wenhao Wu, Xinyi Xie, Jianxiang Tang, Chunlin Chen, Daoyi Dong, Yu Cheng, Zhenhong Sun, Zhi Wang</strong></p>
<p>Offline meta-RL usually tackles generalization by inferring task beliefs from high-quality samples or warmup explorations. The restricted form limits their generality and usability since these supervision signals are expensive and even infeasible to acquire in advance for unseen tasks. Learning directly from the raw text about decision tasks is a promising alternative to leverage a much broader source of supervision. In the paper, we propose \textbf{T}ext-to-\textbf{D}ecision \textbf{A}gent (\textbf{T2DA}), a simple and scalable framework that supervises offline meta-RL with natural language. We first introduce a generalized world model to encode multi-task decision data into a dynamics-aware embedding space. Then, inspired by CLIP, we predict which textual description goes with which decision embedding, effectively bridging their semantic gap via contrastive language-decision pre-training and aligning the text embeddings to comprehend the environment dynamics. After training the text-conditioned generalist policy, the agent can directly realize zero-shot text-to-decision generation in response to language instructions. Comprehensive experiments on MuJoCo and Meta-World benchmarks show that T2DA facilitates high-capacity zero-shot generalization and outperforms various types of baselines. Our code is available at <a target="_blank" rel="noopener" href="https://github.com/NJU-RL/T2DA">https://github.com/NJU-RL/T2DA</a>. </p>
<blockquote>
<p>ç¦»çº¿å…ƒå¼ºåŒ–å­¦ä¹ é€šå¸¸é€šè¿‡ä»é«˜è´¨é‡æ ·æœ¬æˆ–é¢„çƒ­æ¢ç´¢ä¸­æ¨æ–­ä»»åŠ¡ä¿¡å¿µæ¥è§£å†³æ³›åŒ–é—®é¢˜ã€‚è¿™ç§æœ‰é™çš„å½¢å¼é™åˆ¶äº†å…¶é€šç”¨æ€§å’Œå¯ç”¨æ€§ï¼Œå› ä¸ºè¿™äº›ç›‘ç£ä¿¡å·åœ¨é¢„å…ˆè·å–æ–¹é¢éå¸¸æ˜‚è´µï¼Œç”šè‡³å¯¹äºæœªè§è¿‡çš„ä»»åŠ¡æ¥è¯´æ˜¯ä¸å¯èƒ½çš„ã€‚ç›´æ¥ä»å…³äºå†³ç­–ä»»åŠ¡çš„åŸå§‹æ–‡æœ¬ä¸­å­¦ä¹ æ˜¯ä¸€ä¸ªæœ‰å‰æ™¯çš„æ›¿ä»£æ–¹æ¡ˆï¼Œå¯ä»¥å……åˆ†åˆ©ç”¨æ›´å¹¿æ³›çš„ç›‘ç£èµ„æºã€‚åœ¨è®ºæ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†æ–‡æœ¬åˆ°å†³ç­–ä»£ç†ï¼ˆT2DAï¼‰ï¼Œè¿™æ˜¯ä¸€ä¸ªç®€å•ä¸”å¯æ‰©å±•çš„æ¡†æ¶ï¼Œå¯ä»¥é€šè¿‡è‡ªç„¶è¯­è¨€å¯¹ç¦»çº¿å…ƒå¼ºåŒ–å­¦ä¹ è¿›è¡Œç›‘ç£ã€‚æˆ‘ä»¬é¦–å…ˆå¼•å…¥ä¸€ä¸ªé€šç”¨ä¸–ç•Œæ¨¡å‹ï¼Œå°†å¤šä»»åŠ¡å†³ç­–æ•°æ®ç¼–ç åˆ°å…·æœ‰åŠ¨æ€æ„ŸçŸ¥çš„åµŒå…¥ç©ºé—´ã€‚ç„¶åï¼Œå—åˆ°CLIPçš„å¯å‘ï¼Œæˆ‘ä»¬é¢„æµ‹å“ªç§æ–‡æœ¬æè¿°ä¸å“ªç§å†³ç­–åµŒå…¥ç›¸åŒ¹é…ï¼Œé€šè¿‡å¯¹æ¯”è¯­è¨€å†³ç­–é¢„è®­ç»ƒæœ‰æ•ˆåœ°å¼¥åˆäº†å®ƒä»¬çš„è¯­ä¹‰é¸¿æ²Ÿå¹¶è°ƒæ•´äº†æ–‡æœ¬åµŒå…¥ä»¥ç†è§£ç¯å¢ƒåŠ¨æ€ã€‚åœ¨è®­ç»ƒå‡ºæ–‡æœ¬æ¡ä»¶ä¸‹çš„é€šç”¨ç­–ç•¥åï¼Œä»£ç†å¯ä»¥ç›´æ¥å®ç°é›¶å¯åŠ¨æ–‡æœ¬åˆ°å†³ç­–ç”Ÿæˆï¼Œä»¥å“åº”è¯­è¨€æŒ‡ä»¤ã€‚åœ¨MuJoCoå’ŒMeta-WorldåŸºå‡†æµ‹è¯•ä¸Šçš„ç»¼åˆå®éªŒè¡¨æ˜ï¼ŒT2DAä¿ƒè¿›äº†é«˜å®¹é‡é›¶å¯åŠ¨æ³›åŒ–å¹¶è¶…è¶Šäº†å„ç§ç±»å‹çš„åŸºçº¿ã€‚æˆ‘ä»¬çš„ä»£ç å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/NJU-RL/T2DA%E4%B8%8A%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/NJU-RL/T2DAä¸Šæ‰¾åˆ°ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.15046v4">PDF</a> 18 pages, 8 figures</p>
<p><strong>Summary</strong>ï¼š</p>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ä¸ªåä¸ºT2DAçš„æ–‡æœ¬å†³ç­–ä»£ç†æ¡†æ¶ï¼Œè¯¥æ¡†æ¶åˆ©ç”¨è‡ªç„¶è¯­è¨€å¯¹ç¦»çº¿å…ƒå¼ºåŒ–å­¦ä¹ è¿›è¡Œç›‘ç®¡ã€‚é€šè¿‡å¼•å…¥é€šç”¨ä¸–ç•Œæ¨¡å‹å’Œå¤šä»»åŠ¡å†³ç­–æ•°æ®ç¼–ç æˆåŠ¨æ€æ„ŸçŸ¥åµŒå…¥ç©ºé—´ï¼Œä»¥åŠå—åˆ°CLIPå¯å‘çš„æ–‡æœ¬æè¿°ä¸å†³ç­–åµŒå…¥çš„é¢„æµ‹ï¼ŒæˆåŠŸå®ç°äº†æ–‡æœ¬åˆ°å†³ç­–çš„é›¶å°„å‡»ç”Ÿæˆã€‚å®éªŒè¡¨æ˜ï¼ŒT2DAåœ¨MuJoCoå’ŒMeta-WorldåŸºå‡†æµ‹è¯•ä¸­è¡¨ç°å‡ºå“è¶Šçš„é«˜å®¹é‡é›¶å°„å‡»æ³›åŒ–èƒ½åŠ›å¹¶ä¼˜äºå„ç±»åŸºçº¿ã€‚</p>
<p><strong>Key Takeaways</strong>ï¼š</p>
<ol>
<li>T2DAæ˜¯ä¸€ä¸ªæ–‡æœ¬å†³ç­–ä»£ç†æ¡†æ¶ï¼Œæ—¨åœ¨é€šè¿‡è‡ªç„¶è¯­è¨€ç›‘ç£ç¦»çº¿å…ƒå¼ºåŒ–å­¦ä¹ ã€‚</li>
<li>å®ƒå¼•å…¥äº†é€šç”¨ä¸–ç•Œæ¨¡å‹æ¥ç¼–ç å¤šä»»åŠ¡å†³ç­–æ•°æ®ï¼Œå¹¶ç”Ÿæˆä¸€ä¸ªåŠ¨æ€æ„ŸçŸ¥åµŒå…¥ç©ºé—´ã€‚</li>
<li>é‡‡ç”¨å—CLIPå¯å‘çš„é¢„æµ‹æœºåˆ¶ï¼Œå®ç°äº†æ–‡æœ¬æè¿°ä¸å†³ç­–åµŒå…¥çš„å…³è”ï¼Œç¼©å‡äº†è¯­ä¹‰é¸¿æ²Ÿã€‚</li>
<li>é€šè¿‡å¯¹æ¯”è¯­è¨€å†³ç­–é¢„è®­ç»ƒï¼Œä½¿æ–‡æœ¬åµŒå…¥ç†è§£ç¯å¢ƒåŠ¨æ€ã€‚</li>
<li>è®­ç»ƒåçš„æ–‡æœ¬æ¡ä»¶é€šç”¨ç­–ç•¥å¯å®ç°ç›´æ¥é›¶å°„å‡»æ–‡æœ¬åˆ°å†³ç­–ç”Ÿæˆï¼Œå“åº”è¯­è¨€æŒ‡ä»¤ã€‚</li>
<li>åœ¨MuJoCoå’ŒMeta-WorldåŸºå‡†æµ‹è¯•ä¸­ï¼ŒT2DAè¡¨ç°å‡ºå“è¶Šçš„é«˜å®¹é‡é›¶å°„å‡»æ³›åŒ–èƒ½åŠ›ã€‚</li>
<li>T2DAçš„ä»£ç å·²å…¬å¼€åœ¨<a target="_blank" rel="noopener" href="https://github.com/NJU-RL/T2DA%E3%80%82">https://github.com/NJU-RL/T2DAã€‚</a></li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.15046">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-961958e737b777d47232d95314f7a6d7.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b897c05f7b661ae5a60e78260f325c3d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-10d740b23cebe8a186144c562d6634c0.jpg" align="middle">
</details>


<h1 id="-11"><a href="#-11" class="headerlink" title=""></a></h1><h2 id="EmbodiedBench-Comprehensive-Benchmarking-Multi-modal-Large-Language-Models-for-Vision-Driven-Embodied-Agents"><a href="#EmbodiedBench-Comprehensive-Benchmarking-Multi-modal-Large-Language-Models-for-Vision-Driven-Embodied-Agents" class="headerlink" title="EmbodiedBench: Comprehensive Benchmarking Multi-modal Large Language   Models for Vision-Driven Embodied Agents"></a>EmbodiedBench: Comprehensive Benchmarking Multi-modal Large Language   Models for Vision-Driven Embodied Agents</h2><p><strong>Authors:Rui Yang, Hanyang Chen, Junyu Zhang, Mark Zhao, Cheng Qian, Kangrui Wang, Qineng Wang, Teja Venkat Koripella, Marziyeh Movahedi, Manling Li, Heng Ji, Huan Zhang, Tong Zhang</strong></p>
<p>Leveraging Multi-modal Large Language Models (MLLMs) to create embodied agents offers a promising avenue for tackling real-world tasks. While language-centric embodied agents have garnered substantial attention, MLLM-based embodied agents remain underexplored due to the lack of comprehensive evaluation frameworks. To bridge this gap, we introduce EmbodiedBench, an extensive benchmark designed to evaluate vision-driven embodied agents. EmbodiedBench features: (1) a diverse set of 1,128 testing tasks across four environments, ranging from high-level semantic tasks (e.g., household) to low-level tasks involving atomic actions (e.g., navigation and manipulation); and (2) six meticulously curated subsets evaluating essential agent capabilities like commonsense reasoning, complex instruction understanding, spatial awareness, visual perception, and long-term planning. Through extensive experiments, we evaluated 24 leading proprietary and open-source MLLMs within EmbodiedBench. Our findings reveal that: MLLMs excel at high-level tasks but struggle with low-level manipulation, with the best model, GPT-4o, scoring only 28.9% on average. EmbodiedBench provides a multifaceted standardized evaluation platform that not only highlights existing challenges but also offers valuable insights to advance MLLM-based embodied agents. Our code and dataset are available at <a target="_blank" rel="noopener" href="https://embodiedbench.github.io/">https://embodiedbench.github.io</a>. </p>
<blockquote>
<p>åˆ©ç”¨å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰åˆ›å»ºå®ä½“ä»£ç†ä¸ºè§£å†³ç°å®ä¸–ç•Œä»»åŠ¡æä¾›äº†æœ‰å‰æ™¯çš„é€”å¾„ã€‚è™½ç„¶ä»¥è¯­è¨€ä¸ºä¸­å¿ƒçš„å®ä½“ä»£ç†å·²ç»å¼•èµ·äº†å¹¿æ³›å…³æ³¨ï¼Œä½†åŸºäºMLLMçš„å®ä½“ä»£ç†ç”±äºç¼ºå°‘å…¨é¢çš„è¯„ä¼°æ¡†æ¶è€Œå°šæœªå¾—åˆ°å……åˆ†æ¢ç´¢ã€‚ä¸ºäº†å¼¥è¡¥è¿™ä¸€å·®è·ï¼Œæˆ‘ä»¬å¼•å…¥äº†EmbodiedBenchï¼Œè¿™æ˜¯ä¸€ä¸ªæ—¨åœ¨è¯„ä¼°è§†è§‰é©±åŠ¨çš„å®ä½“ä»£ç†çš„å¹¿æ³›åŸºå‡†æµ‹è¯•ã€‚EmbodiedBenchçš„ç‰¹ç‚¹åŒ…æ‹¬ï¼šï¼ˆ1ï¼‰è·¨è¶Šå››ä¸ªç¯å¢ƒçš„1128ä¸ªæµ‹è¯•ä»»åŠ¡é›†ï¼Œä»é«˜çº§è¯­ä¹‰ä»»åŠ¡ï¼ˆä¾‹å¦‚å®¶åº­ä»»åŠ¡ï¼‰åˆ°æ¶‰åŠåŸå­åŠ¨ä½œçš„ä½çº§ä»»åŠ¡ï¼ˆä¾‹å¦‚å¯¼èˆªå’Œæ“ä½œï¼‰ï¼›ï¼ˆ2ï¼‰å…­ä¸ªç²¾å¿ƒç­–åˆ’çš„å­é›†ï¼Œè¯„ä¼°ä»£ç†çš„å¿…è¦èƒ½åŠ›ï¼Œå¦‚å¸¸è¯†æ¨ç†ã€å¤æ‚æŒ‡ä»¤ç†è§£ã€ç©ºé—´æ„ŸçŸ¥ã€è§†è§‰æ„ŸçŸ¥å’Œé•¿æœŸè§„åˆ’ã€‚é€šè¿‡å¹¿æ³›çš„å®éªŒï¼Œæˆ‘ä»¬åœ¨EmbodiedBenchä¸­è¯„ä¼°äº†24ä¸ªé¢†å…ˆçš„ä¸“ä¸šå’Œå¼€æºMLLMã€‚æˆ‘ä»¬çš„ç ”ç©¶å‘ç°ï¼šMLLMåœ¨é«˜çº§ä»»åŠ¡ä¸Šè¡¨ç°å‡ºè‰²ï¼Œä½†åœ¨ä½çº§æ“ä½œæ–¹é¢é‡åˆ°å›°éš¾ï¼Œæœ€ä½³æ¨¡å‹GPT-4oçš„å¹³å‡å¾—åˆ†ä»…ä¸º28.9%ã€‚EmbodiedBenchæä¾›äº†ä¸€ä¸ªå¤šæ–¹é¢çš„æ ‡å‡†åŒ–è¯„ä¼°å¹³å°ï¼Œå®ƒä¸ä»…çªå‡ºäº†ç°æœ‰æŒ‘æˆ˜ï¼Œè€Œä¸”ä¸ºæ¨è¿›åŸºäºMLLMçš„å®ä½“ä»£ç†æä¾›äº†å®è´µè§è§£ã€‚æˆ‘ä»¬çš„ä»£ç å’Œæ•°æ®é›†å¯åœ¨<a target="_blank" rel="noopener" href="https://embodiedbench.github.io/">https://embodiedbench.github.io</a>è·å–ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.09560v3">PDF</a> Accepted to ICML 2025</p>
<p><strong>Summary</strong></p>
<p>åˆ©ç”¨å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰åˆ›å»ºå®ä½“ä»£ç†ä¸ºè§£å†³ç°å®ä¸–ç•Œä»»åŠ¡æä¾›äº†æœ‰å‰æ™¯çš„é€”å¾„ã€‚å°½ç®¡è¯­è¨€ä¸ºä¸­å¿ƒçš„å®ä½“ä»£ç†å·²ç»å¼•èµ·äº†å¹¿æ³›å…³æ³¨ï¼Œä½†åŸºäºMLLMçš„å®ä½“ä»£ç†ç”±äºç¼ºå°‘å…¨é¢çš„è¯„ä¼°æ¡†æ¶è€Œä»è¢«è¾ƒå°‘æ¢ç´¢ã€‚ä¸ºäº†å¼¥è¡¥è¿™ä¸€å·®è·ï¼Œæˆ‘ä»¬å¼•å…¥äº†EmbodiedBenchï¼Œè¿™æ˜¯ä¸€ä¸ªæ—¨åœ¨è¯„ä¼°è§†è§‰é©±åŠ¨çš„å®ä½“ä»£ç†çš„å¹¿æ³›åŸºå‡†ã€‚EmbodiedBenchçš„ç‰¹è‰²åœ¨äºï¼šï¼ˆ1ï¼‰æ¶µç›–å››ç§ç¯å¢ƒçš„1,128é¡¹æµ‹è¯•ä»»åŠ¡ï¼ŒèŒƒå›´ä»é«˜çº§è¯­ä¹‰ä»»åŠ¡ï¼ˆå¦‚å®¶åº­ä»»åŠ¡ï¼‰åˆ°æ¶‰åŠåŸå­åŠ¨ä½œçš„ä½çº§ä»»åŠ¡ï¼ˆå¦‚å¯¼èˆªå’Œæ“ä½œï¼‰ï¼›ï¼ˆ2ï¼‰å…­ä¸ªç²¾å¿ƒç­–åˆ’çš„å­é›†è¯„ä¼°äº†ä»£ç†çš„å¿…è¦èƒ½åŠ›ï¼Œå¦‚å¸¸è¯†æ¨ç†ã€å¤æ‚æŒ‡ä»¤ç†è§£ã€ç©ºé—´æ„è¯†ã€è§†è§‰æ„ŸçŸ¥å’Œé•¿æœŸè§„åˆ’ã€‚é€šè¿‡å¹¿æ³›å®éªŒï¼Œæˆ‘ä»¬åœ¨EmbodiedBenchä¸­è¯„ä¼°äº†24ä¸ªé¢†å…ˆçš„ä¸“ä¸šå’Œå¼€æºMLLMsã€‚æˆ‘ä»¬å‘ç°ï¼šMLLMsåœ¨é«˜çº§ä»»åŠ¡ä¸Šè¡¨ç°å‡ºè‰²ï¼Œä½†åœ¨ä½çº§æ“ä½œä»»åŠ¡ä¸Šé‡åˆ°å›°éš¾ï¼Œæœ€ä½³æ¨¡å‹GPT-4oçš„å¹³å‡å¾—åˆ†ä»…ä¸º28.9%ã€‚EmbodiedBenchæä¾›äº†ä¸€ä¸ªå¤šæ–¹é¢çš„æ ‡å‡†åŒ–è¯„ä¼°å¹³å°ï¼Œä¸ä»…çªå‡ºäº†ç°æœ‰æŒ‘æˆ˜ï¼Œè€Œä¸”ä¸ºæ¨è¿›åŸºäºMLLMçš„å®ä½“ä»£ç†æä¾›äº†æœ‰ä»·å€¼çš„ä¿¡æ¯ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰åœ¨åˆ›å»ºå®ä½“ä»£ç†ä»¥å®Œæˆç°å®ä¸–ç•Œä»»åŠ¡æ–¹é¢å…·å‰æ™¯ã€‚<br>2.ç”±äºç¼ºä¹å…¨é¢çš„è¯„ä¼°æ¡†æ¶ï¼ŒåŸºäºMLLMçš„å®ä½“ä»£ç†ç ”ç©¶ä»è¾ƒå°‘ã€‚</li>
<li>EmbodiedBenchæ˜¯ä¸€ä¸ªæ—¨åœ¨è¯„ä¼°è§†è§‰é©±åŠ¨å®ä½“ä»£ç†æ€§èƒ½çš„å¹¿æ³›åŸºå‡†ã€‚</li>
<li>EmbodiedBenchåŒ…å«å¤šæ ·åŒ–çš„æµ‹è¯•ä»»åŠ¡ï¼Œæ¶µç›–ä»é«˜çº§è¯­ä¹‰åˆ°ä½çº§åŸå­åŠ¨ä½œçš„ä»»åŠ¡ã€‚</li>
<li>MLLMsåœ¨é«˜çº§ä»»åŠ¡ä¸Šè¡¨ç°è‰¯å¥½ï¼Œä½†åœ¨ä½çº§æ“ä½œä»»åŠ¡ä¸Šè¡¨ç°ä¸ä½³ï¼Œæœ€ä½³æ¨¡å‹å¹³å‡å¾—åˆ†ä»…ä¸º28.9%ã€‚</li>
<li>EmbodiedBenchçªå‡ºæ˜¾ç¤ºäº†å®ä½“ä»£ç†æ‰€é¢ä¸´çš„ç°æœ‰æŒ‘æˆ˜ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.09560">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-9c61d678425645d267c31143809336e7.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-4a54c5045d65762a16238b03044c9f29.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d173b3158ccb0ad550455db8d58cca86.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-96d12c51275a45c5dadcb236c0b4f035.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-5ab4d898f72691edf47dfd4fe1eddd3c.jpg" align="middle">
</details>


<h1 id="-12"><a href="#-12" class="headerlink" title=""></a></h1><h2 id="EnIGMA-Interactive-Tools-Substantially-Assist-LM-Agents-in-Finding-Security-Vulnerabilities"><a href="#EnIGMA-Interactive-Tools-Substantially-Assist-LM-Agents-in-Finding-Security-Vulnerabilities" class="headerlink" title="EnIGMA: Interactive Tools Substantially Assist LM Agents in Finding   Security Vulnerabilities"></a>EnIGMA: Interactive Tools Substantially Assist LM Agents in Finding   Security Vulnerabilities</h2><p><strong>Authors:Talor Abramovich, Meet Udeshi, Minghao Shao, Kilian Lieret, Haoran Xi, Kimberly Milner, Sofija Jancheska, John Yang, Carlos E. Jimenez, Farshad Khorrami, Prashanth Krishnamurthy, Brendan Dolan-Gavitt, Muhammad Shafique, Karthik Narasimhan, Ramesh Karri, Ofir Press</strong></p>
<p>Although language model (LM) agents have demonstrated increased performance in multiple domains, including coding and web-browsing, their success in cybersecurity has been limited. We present EnIGMA, an LM agent for autonomously solving Capture The Flag (CTF) challenges. We introduce new tools and interfaces to improve the agentâ€™s ability to find and exploit security vulnerabilities, focusing on interactive terminal programs. These novel Interactive Agent Tools enable LM agents, for the first time, to run interactive utilities, such as a debugger and a server connection tool, which are essential for solving these challenges. Empirical analysis on 390 CTF challenges across four benchmarks demonstrate that these new tools and interfaces substantially improve our agentâ€™s performance, achieving state-of-the-art results on NYU CTF, Intercode-CTF, and CyBench. Finally, we analyze data leakage, developing new methods to quantify it and identifying a new phenomenon we term soliloquizing, where the model self-generates hallucinated observations without interacting with the environment. Our code and development dataset are available at <a target="_blank" rel="noopener" href="https://github.com/SWE-agent/SWE-agent/tree/v0.7">https://github.com/SWE-agent/SWE-agent/tree/v0.7</a> and <a target="_blank" rel="noopener" href="https://github.com/NYU-LLM-CTF/NYU_CTF_Bench/tree/main/development">https://github.com/NYU-LLM-CTF/NYU_CTF_Bench/tree/main/development</a> respectively. </p>
<blockquote>
<p>å°½ç®¡è¯­è¨€æ¨¡å‹ï¼ˆLMï¼‰ä»£ç†åœ¨ç¼–ç å’Œç½‘é¡µæµè§ˆç­‰å¤šä¸ªé¢†åŸŸè¡¨ç°å‡ºæ€§èƒ½æå‡ï¼Œä½†åœ¨ç½‘ç»œå®‰å…¨æ–¹é¢çš„æˆåŠŸå´æœ‰é™ã€‚æˆ‘ä»¬æ¨å‡ºäº†EnIGMAï¼Œè¿™æ˜¯ä¸€æ¬¾ç”¨äºè‡ªä¸»è§£å†³Capture The Flagï¼ˆCTFï¼‰æŒ‘æˆ˜çš„è¯­è¨€æ¨¡å‹ä»£ç†ã€‚æˆ‘ä»¬å¼•å…¥äº†æ–°å·¥å…·å’Œç•Œé¢ï¼Œä»¥æé«˜ä»£ç†å‘ç°å’Œåˆ©ç”¨å®‰å…¨æ¼æ´çš„èƒ½åŠ›ï¼Œé‡ç‚¹é’ˆå¯¹äº¤äº’å¼ç»ˆç«¯ç¨‹åºã€‚è¿™äº›æ–°å‹äº¤äº’å¼ä»£ç†å·¥å…·ä½¿å¾—è¯­è¨€æ¨¡å‹ä»£ç†é¦–æ¬¡èƒ½å¤Ÿè¿è¡Œäº¤äº’å¼å®ç”¨ç¨‹åºï¼Œå¦‚è°ƒè¯•å™¨å’ŒæœåŠ¡å™¨è¿æ¥å·¥å…·ï¼Œè¿™å¯¹äºè§£å†³è¿™äº›æŒ‘æˆ˜è‡³å…³é‡è¦ã€‚åœ¨å››é¡¹æŒ‡æ ‡çš„390é¡¹CTFæŒ‘æˆ˜ä¸Šçš„å®è¯åˆ†æè¡¨æ˜ï¼Œè¿™äº›æ–°å·¥å…·å’Œç•Œé¢æå¤§åœ°æé«˜äº†æˆ‘ä»¬çš„ä»£ç†æ€§èƒ½ï¼Œåœ¨NYU CTFã€Intercode-CTFå’ŒCyBenchä¸Šè¾¾åˆ°äº†æœ€æ–°ç»“æœã€‚æœ€åï¼Œæˆ‘ä»¬åˆ†æäº†æ•°æ®æ³„éœ²é—®é¢˜ï¼Œå¼€å‘äº†æ–°çš„é‡åŒ–æ–¹æ³•ï¼Œå¹¶è¯†åˆ«å‡ºä¸€ç§æˆ‘ä»¬ç§°ä¹‹ä¸ºè‡ªè¨€è‡ªè¯­çš„æ–°ç°è±¡ï¼Œå³æ¨¡å‹åœ¨æ²¡æœ‰ä¸ç¯å¢ƒäº¤äº’çš„æƒ…å†µä¸‹è‡ªæˆ‘ç”Ÿæˆè™šæ„çš„è§‚å¯Ÿç»“æœã€‚æˆ‘ä»¬çš„ä»£ç å’Œå¼€å‘æ•°æ®é›†åˆ†åˆ«ä½äº<a target="_blank" rel="noopener" href="https://github.com/SWE-agent/SWE-agent/tree/v0.7">https://github.com/SWE-agent/SWE-agent/tree/v0.7</a>å’Œ<a target="_blank" rel="noopener" href="https://github.com/NYU-LLM-CTF/NYU_CTF_Bench/tree/main/development">https://github.com/NYU-LLM-CTF/NYU_CTF_Bench/tree/main/development</a>ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2409.16165v3">PDF</a> ICML 2025; Project website <a target="_blank" rel="noopener" href="https://enigma-agent.com/">https://enigma-agent.com</a></p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†ä¸€ç§åä¸ºEnIGMAçš„LMä»£ç†ï¼Œä¸“é—¨ç”¨äºè‡ªä¸»è§£å†³Capture The Flagï¼ˆCTFï¼‰æŒ‘æˆ˜ã€‚æ–‡ç« æå‡ºäº†æ–°å·¥å…·å’Œç•Œé¢æ¥æ”¹å–„ä»£ç†æ‰¾åˆ°å¹¶åˆ©ç”¨å®‰å…¨æ¼æ´çš„èƒ½åŠ›ï¼Œé‡ç‚¹åœ¨äº¤äº’å¼ç»ˆç«¯ç¨‹åºã€‚è¿™äº›æ–°é¢–çš„äº’åŠ¨ä»£ç†å·¥å…·ä½¿å¾—LMä»£ç†é¦–æ¬¡èƒ½å¤Ÿè¿è¡Œå…³é”®å®ç”¨ç¨‹åºï¼Œå¦‚è°ƒè¯•å™¨å’ŒæœåŠ¡å™¨è¿æ¥å·¥å…·ã€‚ç»éªŒåˆ†æè¡¨æ˜ï¼Œæ–°å·¥å…·å’Œæ¥å£å¤§å¤§æé«˜äº†ä»£ç†æ€§èƒ½ï¼Œå¹¶åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­è¾¾åˆ°æœ€æ–°æ°´å¹³ã€‚æ­¤å¤–ï¼Œæ–‡ç« è¿˜åˆ†æäº†æ•°æ®æ³„éœ²ç°è±¡ï¼Œå¹¶å¼€å‘äº†æ–°çš„é‡åŒ–æ–¹æ³•ï¼Œè¯†åˆ«äº†ä¸€ç§æ–°ç°è±¡â€”â€”â€œè‡ªè¨€è‡ªè¯­â€ï¼Œå³æ¨¡å‹åœ¨ä¸ä¸ç¯å¢ƒäº¤äº’çš„æƒ…å†µä¸‹è‡ªæˆ‘ç”Ÿæˆå¹»è§‰è§‚å¯Ÿã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>EnIGMAæ˜¯ä¸€ä¸ªç”¨äºè§£å†³Capture The Flagï¼ˆCTFï¼‰æŒ‘æˆ˜çš„LMä»£ç†ã€‚</li>
<li>ä»‹ç»äº†æ–°å·¥å…·å’Œç•Œé¢ï¼Œæé«˜äº†ä»£ç†åœ¨æŸ¥æ‰¾å’Œåˆ©ç”¨å®‰å…¨æ¼æ´æ–¹é¢çš„èƒ½åŠ›ã€‚</li>
<li>äº’åŠ¨ä»£ç†å·¥å…·ä½¿LMä»£ç†èƒ½è¿è¡Œå…³é”®å®ç”¨ç¨‹åºï¼Œå¦‚è°ƒè¯•å™¨å’ŒæœåŠ¡å™¨è¿æ¥å·¥å…·ã€‚</li>
<li>æ–°å·¥å…·å’Œæ¥å£æ˜¾è‘—æå‡äº†ä»£ç†æ€§èƒ½ï¼Œè¾¾åˆ°æˆ–è¶…è¶Šäº†æœ€æ–°æ°´å¹³ã€‚</li>
<li>æ–‡ç« åˆ†æäº†æ•°æ®æ³„éœ²ç°è±¡ï¼Œå¹¶å¼€å‘äº†æ–°çš„é‡åŒ–æ–¹æ³•ã€‚</li>
<li>è¯†åˆ«äº†ä¸€ç§æ–°ç°è±¡â€”â€”â€œè‡ªè¨€è‡ªè¯­â€ï¼Œå³æ¨¡å‹è‡ªæˆ‘ç”Ÿæˆå¹»è§‰è§‚å¯Ÿã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2409.16165">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-6f6501626cfba6baed56b014d2271ce8.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-7a7bdb0f17a38d81c6cb448aab7a0aec.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c322c79dccb249c91ceabf3d7a262af2.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f8680861f7ceb58a3856a428203f41e3.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-88c5abbbc44c9f9c4635c8525d7b4492.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-fc9d25080dcf1f8011bc8e730eaccd60.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b837bf6044a3cf284ff4a4e8f6bd58d9.jpg" align="middle">
</details>


<h1 id="-13"><a href="#-13" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-06-08/Agent/">https://kedreamix.github.io/Talk2Paper/Paper/2025-06-08/Agent/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/Agent/">
                                    <span class="chip bg-color">Agent</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-06-08/Few-Shot/">
                    <div class="card-image">
                        
                        <img src="https://pica.zhimg.com/v2-0e52c6ee4cd9ee24a5c221b6ed9faf13.jpg" class="responsive-img" alt="Few-Shot">
                        
                        <span class="card-title">Few-Shot</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Few-Shot æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-06-08  Just a Scratch Enhancing LLM Capabilities for Self-harm Detection   through Intent Differentiation and Emoji Interpretation
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-06-08
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Few-Shot/" class="post-category">
                                    Few-Shot
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Few-Shot/">
                        <span class="chip bg-color">Few-Shot</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-06-08/LLM/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-31593c9a93ac5fd04bd000716e4cef24.jpg" class="responsive-img" alt="LLM">
                        
                        <span class="card-title">LLM</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            LLM æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-06-08  SparseMM Head Sparsity Emerges from Visual Concept Responses in MLLMs
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-06-08
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/LLM/" class="post-category">
                                    LLM
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/LLM/">
                        <span class="chip bg-color">LLM</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">24231k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
