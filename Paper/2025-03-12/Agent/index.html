<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Agent">
    <meta name="description" content="Agent 方向最新论文已更新，请持续关注 Update in 2025-03-12  MedAgentsBench Benchmarking Thinking Models and Agent Frameworks for   Complex Medical Reasoning">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>Agent | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loader页面消失采用渐隐的方式*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logo出现动画 */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//使用渐隐的方法淡出loading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//强制显示loading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">嘘~  正在从服务器偷取页面 . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>首页</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>标签</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>分类</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>归档</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="搜索" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="深色/浅色模式" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			首页
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			标签
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			分类
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			归档
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://pic1.zhimg.com/v2-536557dd7e4e6f8850f7384f7de041ee.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Agent</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/Agent/">
                                <span class="chip bg-color">Agent</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/Agent/" class="post-category">
                                Agent
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2025-03-12
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>更新日期:&nbsp;&nbsp;
                    2025-05-14
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp;
                    12.5k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp;
                    50 分
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>阅读次数:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>⚠️ 以下所有内容总结都来自于 大语言模型的能力，如有错误，仅供参考，谨慎使用<br>🔴 请注意：千万不要用于严肃的学术场景，只能用于论文阅读前的初筛！<br>💗 如果您觉得我们的项目对您有帮助 <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ，还请您给我们一些鼓励！⭐️ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFace免费体验</a></p>
</blockquote>
<h1 id="2025-03-12-更新"><a href="#2025-03-12-更新" class="headerlink" title="2025-03-12 更新"></a>2025-03-12 更新</h1><h2 id="MedAgentsBench-Benchmarking-Thinking-Models-and-Agent-Frameworks-for-Complex-Medical-Reasoning"><a href="#MedAgentsBench-Benchmarking-Thinking-Models-and-Agent-Frameworks-for-Complex-Medical-Reasoning" class="headerlink" title="MedAgentsBench: Benchmarking Thinking Models and Agent Frameworks for   Complex Medical Reasoning"></a>MedAgentsBench: Benchmarking Thinking Models and Agent Frameworks for   Complex Medical Reasoning</h2><p><strong>Authors:Xiangru Tang, Daniel Shao, Jiwoong Sohn, Jiapeng Chen, Jiayi Zhang, Jinyu Xiang, Fang Wu, Yilun Zhao, Chenglin Wu, Wenqi Shi, Arman Cohan, Mark Gerstein</strong></p>
<p>Large Language Models (LLMs) have shown impressive performance on existing medical question-answering benchmarks. This high performance makes it increasingly difficult to meaningfully evaluate and differentiate advanced methods. We present MedAgentsBench, a benchmark that focuses on challenging medical questions requiring multi-step clinical reasoning, diagnosis formulation, and treatment planning-scenarios where current models still struggle despite their strong performance on standard tests. Drawing from seven established medical datasets, our benchmark addresses three key limitations in existing evaluations: (1) the prevalence of straightforward questions where even base models achieve high performance, (2) inconsistent sampling and evaluation protocols across studies, and (3) lack of systematic analysis of the interplay between performance, cost, and inference time. Through experiments with various base models and reasoning methods, we demonstrate that the latest thinking models, DeepSeek R1 and OpenAI o3, exhibit exceptional performance in complex medical reasoning tasks. Additionally, advanced search-based agent methods offer promising performance-to-cost ratios compared to traditional approaches. Our analysis reveals substantial performance gaps between model families on complex questions and identifies optimal model selections for different computational constraints. Our benchmark and evaluation framework are publicly available at <a target="_blank" rel="noopener" href="https://github.com/gersteinlab/medagents-benchmark">https://github.com/gersteinlab/medagents-benchmark</a>. </p>
<blockquote>
<p>大规模语言模型（LLMs）在现有的医疗问答基准测试中表现出了令人印象深刻的性能。这种高性能使得有意义地评估和区分先进方法变得越来越困难。我们推出了MedAgentsBench基准测试，它专注于具有挑战性的医疗问题，需要多步骤的临床推理、诊断制定和治疗规划方案，尽管当前模型在标准测试上的表现强劲，但在这些场景中仍然面临困难。我们从七个已建立的医疗数据集中汲取数据，基准测试解决了现有评估中的三个关键局限性：（1）简单问题普遍存在，即使基础模型也能取得良好的性能；（2）各研究之间的采样和评估协议不一致；（3）缺乏对性能、成本和推理时间之间相互作用的系统性分析。通过对各种基础模型和推理方法进行实验，我们证明了最新的思维模型，如DeepSeek R1和OpenAI o3，在复杂的医疗推理任务中表现出卓越的性能。此外，与传统方法相比，先进的基于搜索的代理方法提供了有前景的性能价格比。我们的分析揭示了不同模型家族在复杂问题上的性能差距，并针对不同计算约束条件确定了最佳模型选择。我们的基准测试和评估框架可在<a target="_blank" rel="noopener" href="https://github.com/gersteinlab/medagents-benchmark%E4%B8%8A%E5%85%AC%E5%BC%80%E8%AE%BF%E9%97%AE%E3%80%82">https://github.com/gersteinlab/medagents-benchmark上公开访问。</a></p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.07459v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>大型语言模型（LLMs）在现有的医疗问答基准测试中表现出卓越性能。然而，这导致难以对先进方法进行有意义地评估和区分。为此，我们提出了MedAgentsBench基准测试，它专注于挑战需要多步骤临床推理、诊断制定和治疗规划的医疗问题。该基准测试从七个已建立的医疗数据集中抽取数据，解决了现有评估中的三个关键局限性：一是简单问题过多，即使是基础模型也能实现高性能；二是研究间的采样和评估协议不一致；三是缺乏关于性能、成本和推理时间之间相互作用的系统性分析。通过一系列实验，我们证明了最新的思考模型DeepSeek R1和OpenAI o3在复杂的医疗推理任务中表现出卓越性能。此外，与传统方法相比，先进的基于搜索的代理方法提供了有前景的性能成本比。我们的分析揭示了不同模型家族在复杂问题上的性能差距，并针对不同计算约束确定了最佳模型选择。我们的基准测试和评估框架可在<a target="_blank" rel="noopener" href="https://github.com/gersteinlab/medagents-benchmark%E8%AE%BF%E9%97%AE%E3%80%82">https://github.com/gersteinlab/medagents-benchmark访问。</a></p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>大型语言模型（LLMs）在医疗问答方面表现出色，但现有评估方法难以区分不同模型的性能。</li>
<li>MedAgentsBench基准测试旨在解决现有评估中的三个关键局限性：简单问题过多、采样和评估协议不一致以及缺乏性能、成本和推理时间的综合分析。</li>
<li>最新思考模型DeepSeek R1和OpenAI o3在复杂的医疗推理任务中表现突出。</li>
<li>与传统方法相比，先进的基于搜索的代理方法具有吸引力的性能成本比。</li>
<li>不同模型家族在复杂问题上的性能存在差距，需要根据计算约束选择合适的模型。</li>
<li>MedAgentsBench提供了评估和比较模型的框架。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.07459">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-2372f71d7c08d0c0447848bda43d1852.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-77a8eeb27761ffb85c39029465caf05e.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-887da8e131c5d782c91256d66dcf6959.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c22a174577809b271182779a14fd292c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-eee2f745610bd4ddbbac7581210e7c03.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-1ce04950da29119dbc5e6ca26832740d.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="Automated-Movie-Generation-via-Multi-Agent-CoT-Planning"><a href="#Automated-Movie-Generation-via-Multi-Agent-CoT-Planning" class="headerlink" title="Automated Movie Generation via Multi-Agent CoT Planning"></a>Automated Movie Generation via Multi-Agent CoT Planning</h2><p><strong>Authors:Weijia Wu, Zeyu Zhu, Mike Zheng Shou</strong></p>
<p>Existing long-form video generation frameworks lack automated planning, requiring manual input for storylines, scenes, cinematography, and character interactions, resulting in high costs and inefficiencies. To address these challenges, we present MovieAgent, an automated movie generation via multi-agent Chain of Thought (CoT) planning. MovieAgent offers two key advantages: 1) We firstly explore and define the paradigm of automated movie&#x2F;long-video generation. Given a script and character bank, our MovieAgent can generates multi-scene, multi-shot long-form videos with a coherent narrative, while ensuring character consistency, synchronized subtitles, and stable audio throughout the film. 2) MovieAgent introduces a hierarchical CoT-based reasoning process to automatically structure scenes, camera settings, and cinematography, significantly reducing human effort. By employing multiple LLM agents to simulate the roles of a director, screenwriter, storyboard artist, and location manager, MovieAgent streamlines the production pipeline. Experiments demonstrate that MovieAgent achieves new state-of-the-art results in script faithfulness, character consistency, and narrative coherence. Our hierarchical framework takes a step forward and provides new insights into fully automated movie generation. The code and project website are available at: <a target="_blank" rel="noopener" href="https://github.com/showlab/MovieAgent">https://github.com/showlab/MovieAgent</a> and <a target="_blank" rel="noopener" href="https://weijiawu.github.io/MovieAgent">https://weijiawu.github.io/MovieAgent</a>. </p>
<blockquote>
<p>现有长视频生成框架缺乏自动化规划，需要手动输入故事情节、场景、摄像和角色互动，导致成本高且效率低下。为解决这些挑战，我们推出了MovieAgent，一种通过多智能体思维链（CoT）规划实现电影自动化生成的方法。MovieAgent提供两个主要优势：</p>
</blockquote>
<p>1）我们首次探索和定义了电影&#x2F;长视频生成的自动化范式。给定剧本和角色库，我们的MovieAgent可以生成多场景、多镜头的长视频，具有连贯的叙事，同时确保角色一致性、字幕同步和电影全程稳定的音频。</p>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.07314v1">PDF</a> The code and project website are available at:   <a target="_blank" rel="noopener" href="https://github.com/showlab/MovieAgent">https://github.com/showlab/MovieAgent</a> and   <a target="_blank" rel="noopener" href="https://weijiawu.github.io/MovieAgent">https://weijiawu.github.io/MovieAgent</a></p>
<p><strong>Summary</strong></p>
<p>MovieAgent实现多代理Chain of Thought（CoT）规划自动化电影生成，解决现有长视频生成框架缺乏自动化规划的问题。给定剧本和角色库，MovieAgent能生成具有连贯叙事的多场景、多镜头长视频，确保角色一致性、字幕同步和音频稳定。通过层次化的CoT推理过程自动构建场景、相机设置和电影制作，显著减少人力投入。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>MovieAgent使用多代理Chain of Thought（CoT）规划实现电影自动生成。</li>
<li>解决了现有长视频生成框架需要手动输入故事线、场景、摄影和角色互动的缺点。</li>
<li>MovieAgent能生成具有连贯叙事的多场景、多镜头长视频，确保角色一致性、字幕同步和音频稳定。</li>
<li>通过层次化的CoT推理过程自动构建场景、相机设置和电影制作，降低人力成本。</li>
<li>采用多个大型语言模型（LLM）代理模拟导演、编剧、分镜师和场地经理的角色，优化生产流程。</li>
<li>实验证明，MovieAgent在剧本忠实度、角色一致性和叙事连贯性方面达到新的先进水平。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.07314">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pica.zhimg.com/v2-5400767bc698e49ce71fb00746590bd3.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-5e251d10f2325746416d23c137f4a3d0.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a7458f8e354a4b3c496f913875dda839.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-7cc42a9d9139e11bc099f4d36c2e30b0.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-e7f98ccc22438731d7fa779e33a8223d.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="DatawiseAgent-A-Notebook-Centric-LLM-Agent-Framework-for-Automated-Data-Science"><a href="#DatawiseAgent-A-Notebook-Centric-LLM-Agent-Framework-for-Automated-Data-Science" class="headerlink" title="DatawiseAgent: A Notebook-Centric LLM Agent Framework for Automated Data   Science"></a>DatawiseAgent: A Notebook-Centric LLM Agent Framework for Automated Data   Science</h2><p><strong>Authors:Ziming You, Yumiao Zhang, Dexuan Xu, Yiwei Lou, Yandong Yan, Wei Wang, Huaming Zhang, Yu Huang</strong></p>
<p>Data Science tasks are multifaceted, dynamic, and often domain-specific. Existing LLM-based approaches largely concentrate on isolated phases, neglecting the interdependent nature of many data science tasks and limiting their capacity for comprehensive end-to-end support. We propose DatawiseAgent, a notebook-centric LLM agent framework that unifies interactions among user, agent and the computational environment through markdown and executable code cells, supporting flexible and adaptive automated data science. Built on a Finite State Transducer(FST), DatawiseAgent orchestrates four stages, including DSF-like planning, incremental execution, self-debugging, and post-filtering. Specifically, the DFS-like planning stage systematically explores the solution space, while incremental execution harnesses real-time feedback and accommodates LLM’s limited capabilities to progressively complete tasks. The self-debugging and post-filtering modules further enhance reliability by diagnosing and correcting errors and pruning extraneous information. Extensive experiments on diverse tasks, including data analysis, visualization, and data modeling, show that DatawiseAgent consistently outperforms or matches state-of-the-art methods across multiple model settings. These results highlight its potential to generalize across data science scenarios and lay the groundwork for more efficient, fully automated workflows. </p>
<blockquote>
<p>数据科学任务具有多面性、动态性，并且通常是特定领域的。现有的基于大型语言模型（LLM）的方法主要关注孤立的阶段，忽略了数据科学任务之间的相互依赖性，并限制了它们进行全面端到端支持的能力。我们提出了DatawiseAgent，这是一个以笔记本为中心的LLM代理框架，它通过markdown和可执行代码单元格统一了用户、代理和计算环境之间的交互，支持灵活和自适应的自动化数据科学。DatawiseAgent建立在有限状态转换器（FST）上，协调四个阶段，包括类似DSF的规划、增量执行、自我调试和后期过滤。具体来说，类似DFS的规划阶段系统地探索了解空间，而增量执行利用实时反馈并适应LLM的有限能力来逐步完成任务。自我调试和后期过滤模块通过诊断和纠正错误以及删除多余信息，进一步提高了可靠性。在包括数据分析、可视化和数据建模等多样化任务上的大量实验表明，DatawiseAgent在多个模型设置下始终优于或匹配最新方法。这些结果突显了其在数据科学场景中的通用潜力，并为更高效、更全自动化的工作流程奠定了基础。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.07044v1">PDF</a> </p>
<p><strong>Summary</strong><br>     数据科学任务具有多面性、动态性和领域特异性。现有基于大型语言模型（LLM）的方法主要关注孤立阶段，忽视数据科学任务间的相互依赖性，并限制其全面端到端支持能力。我们提出DatawiseAgent，一种以笔记本为中心的LLM代理框架，通过markdown和可执行代码单元格统一用户、代理和计算环境之间的交互，支持灵活和自适应的自动化数据科学。该框架基于有限状态转换器（FST），包含类似DSF的规划、增量执行、自我调试和后期过滤四个阶段。规划阶段系统地探索解决方案空间，增量执行阶段利用实时反馈并适应LLM的有限能力以逐步完成任务。自我调试和后期过滤模块进一步通过诊断和校正错误以及删除多余信息来提高可靠性。在包括数据分析、可视化和数据建模在内的各种任务上的广泛实验表明，DatawiseAgent在多种模型设置下始终优于或匹配最新方法，突显其在数据科学场景中的通用潜力，并为更高效、完全自动化的工作流程奠定基础。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>数据科学任务具有多面性、动态性和领域特异性。</li>
<li>现有LLM方法主要关注孤立阶段，缺乏全面端到端的支持。</li>
<li>DatawiseAgent是一个以笔记本为中心的LLM代理框架，支持灵活和自适应的自动化数据科学。</li>
<li>DatawiseAgent通过四个阶段实现功能：类似DSF的规划、增量执行、自我调试和后期过滤。</li>
<li>规划阶段系统地探索解决方案空间。</li>
<li>增量执行阶段利用实时反馈并适应LLM的有限能力逐步完成任务。</li>
<li>自我调试和后期过滤模块提高了可靠性，通过诊断和校正错误以及删除多余信息。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.07044">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-d39d77b8b9bfdf17377e83c85077ca9f.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-9e26c9164ffe5b1f405e774400f0d73e.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-235ddb8f1a62379d7212aea854f69cde.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="Can-Proof-Assistants-Verify-Multi-Agent-Systems"><a href="#Can-Proof-Assistants-Verify-Multi-Agent-Systems" class="headerlink" title="Can Proof Assistants Verify Multi-Agent Systems?"></a>Can Proof Assistants Verify Multi-Agent Systems?</h2><p><strong>Authors:Julian Alfredo Mendez, Timotheus Kampik</strong></p>
<p>This paper presents the Soda language for verifying multi-agent systems. Soda is a high-level functional and object-oriented language that supports the compilation of its code not only to Scala, a strongly statically typed high-level programming language, but also to Lean, a proof assistant and programming language. Given these capabilities, Soda can implement multi-agent systems, or parts thereof, that can then be integrated into a mainstream software ecosystem on the one hand and formally verified with state-of-the-art tools on the other hand. We provide a brief and informal introduction to Soda and the aforementioned interoperability capabilities, as well as a simple demonstration of how interaction protocols can be designed and verified with Soda. In the course of the demonstration, we highlight challenges with respect to real-world applicability. </p>
<blockquote>
<p>本文介绍了用于验证多智能体系统的Soda语言。Soda是一种高级函数和面向对象的语言，它支持其代码不仅编译为Scala（一种强静态类型高级编程语言），还编译为Lean（一种证明助理和编程语言）。基于这些功能，Soda可以实现多智能体系统或其部分，一方面可以将其集成到主流软件生态系统中，另一方面可以运用最新的工具对其进行形式化验证。我们对Soda及其上述互操作功能进行了简短的非正式介绍，并简单演示了如何使用Soda设计和验证交互协议。在演示过程中，我们强调了实际应用所面临的挑战。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.06812v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>Soda语言用于验证多代理系统，是一门高级功能性和面向对象的语言。它可以编译为Scala和Lean两种语言，实现多代理系统或其部分的实现，并可以集成到主流软件生态系统中，同时使用最新工具进行形式化验证。本文简要介绍了Soda及其与两种语言的互通性能力，并通过简单的演示展示了如何使用Soda设计和验证交互协议，同时强调了其在现实世界应用中的挑战。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>Soda是一种用于验证多代理系统的高级功能性和面向对象的语言。</li>
<li>Soda可以将代码编译为Scala和Lean两种语言。</li>
<li>Soda可以实现多代理系统或其部分，并集成到主流软件生态系统中。</li>
<li>Soda可以使用最新工具进行形式化验证。</li>
<li>本文提供了Soda与两种语言的互通性能力的简要介绍。</li>
<li>演示展示了如何使用Soda设计和验证交互协议。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.06812">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-30201036ac28315ebb96a752572d0309.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="AutoMisty-A-Multi-Agent-LLM-Framework-for-Automated-Code-Generation-in-the-Misty-Social-Robot"><a href="#AutoMisty-A-Multi-Agent-LLM-Framework-for-Automated-Code-Generation-in-the-Misty-Social-Robot" class="headerlink" title="AutoMisty: A Multi-Agent LLM Framework for Automated Code Generation in   the Misty Social Robot"></a>AutoMisty: A Multi-Agent LLM Framework for Automated Code Generation in   the Misty Social Robot</h2><p><strong>Authors:Xiao Wang, Lu Dong, Sahana Rangasrinivasan, Ifeoma Nwogu, Srirangaraj Setlur, Venugopal Govindaraju</strong></p>
<p>The social robot’s open API allows users to customize open-domain interactions. However, it remains inaccessible to those without programming experience. In this work, we introduce AutoMisty, the first multi-agent collaboration framework powered by large language models (LLMs), to enable the seamless generation of executable Misty robot code from natural language instructions. AutoMisty incorporates four specialized agent modules to manage task decomposition, assignment, problem-solving, and result synthesis. Each agent incorporates a two-layer optimization mechanism, with self-reflection for iterative refinement and human-in-the-loop for better alignment with user preferences. AutoMisty ensures a transparent reasoning process, allowing users to iteratively refine tasks through natural language feedback for precise execution. To evaluate AutoMisty’s effectiveness, we designed a benchmark task set spanning four levels of complexity and conducted experiments in a real Misty robot environment. Extensive evaluations demonstrate that AutoMisty not only consistently generates high-quality code but also enables precise code control, significantly outperforming direct reasoning with ChatGPT-4o and ChatGPT-o1. All code, optimized APIs, and experimental videos will be publicly released through the webpage: <a target="_blank" rel="noopener" href="https://wangxiaoshawn.github.io/AutoMisty.html">https://wangxiaoshawn.github.io/AutoMisty.html</a> </p>
<blockquote>
<p>社交机器人的开放API允许用户进行开放领域的交互定制。然而，对于没有编程经验的人来说，这一功能仍然无法访问。在这项工作中，我们引入了AutoMisty，这是一个由大型语言模型（LLM）驱动的多智能体协作框架，能够直接从自然语言指令无缝生成可执行的Misty机器人代码。AutoMisty集成了四个专业智能体模块，负责管理任务分解、分配、问题解决和结果合成。每个智能体都采用了两层优化机制，通过自我反思进行迭代优化，并结合人工参与以更好地符合用户偏好。AutoMisty确保了一个透明的推理过程，允许用户通过自然语言反馈来迭代优化任务，以实现精确执行。为了评估AutoMisty的有效性，我们设计了一套跨越四个难度级别的基准任务集，并在真实的Misty机器人环境中进行了实验。广泛评估表明，AutoMisty不仅持续生成高质量代码，而且能够实现精确的代码控制，显著优于直接使用ChatGPT-4o和ChatGPT-o1进行推理。所有代码、优化API和实验视频将通过网页公开发布：<a target="_blank" rel="noopener" href="https://wangxiaoshawn.github.io/AutoMisty.html">https://wangxiaoshawn.github.io/AutoMisty.html</a></p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.06791v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>基于社交机器人的开放API，用户可自定义开放域交互，但对无编程经验者仍不可行。本研究引入AutoMisty，首个由大型语言模型驱动的多智能体协作框架，可从自然语言指令无缝生成可执行机器人代码。AutoMisty包含四个专门智能体模块，负责任务分解、分配、问题解决和结果合成。每个智能体采用两层优化机制，通过自我反思进行迭代优化，并结合人类反馈提高与用户偏好的对齐。AutoMisty确保透明推理过程，允许用户通过自然语言反馈进行任务迭代细化，以实现精确执行。我们在真实机器人环境中进行实验评估，证明AutoMisty不仅持续生成高质量代码，而且实现了精确的代码控制，优于直接推理。所有代码、优化API和实验视频将通过网页公开发布：<a target="_blank" rel="noopener" href="https://wangxiaoshawn.github.io/AutoMisty.html">https://wangxiaoshawn.github.io/AutoMisty.html</a>。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>社交机器人开放API允许用户自定义开放域交互，但编程经验不足的用户难以使用。</li>
<li>AutoMisty框架引入多智能体协作，利用大型语言模型实现自然语言指令到机器人代码的无缝生成。</li>
<li>AutoMisty包含四个智能体模块负责任务分解、分配、问题解决和结果合成。</li>
<li>每个智能体采用两层优化机制，包括自我反思迭代优化和结合人类反馈提高与用户偏好对齐。</li>
<li>AutoMisty确保透明推理过程，允许用户通过自然语言反馈细化任务。</li>
<li>在真实机器人环境中的实验评估表明，AutoMisty生成的代码质量高且能实现精确的代码控制。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.06791">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pica.zhimg.com/v2-d6de22b1c25a1d4d0dacf7c5000c0afd.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-3ff67f2b8c0c5ab98acaf85be5f044c9.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-5ea0d2e697fea9a31c842d9e4cf00ea8.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-00c6aa7a5fdb840eb2f52601e8b655c4.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-5ebe1f45cac68e89123d7e555cc428ca.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-c429593ae50edf99416e343729e91f5e.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="Generator-Assistant-Stepwise-Rollback-Framework-for-Large-Language-Model-Agent"><a href="#Generator-Assistant-Stepwise-Rollback-Framework-for-Large-Language-Model-Agent" class="headerlink" title="Generator-Assistant Stepwise Rollback Framework for Large Language Model   Agent"></a>Generator-Assistant Stepwise Rollback Framework for Large Language Model   Agent</h2><p><strong>Authors:Xingzuo Li, Kehai Chen, Yunfei Long, Xuefeng Bai, Yong Xu, Min Zhang</strong></p>
<p>Large language model (LLM) agents typically adopt a step-by-step reasoning framework, in which they interleave the processes of thinking and acting to accomplish the given task. However, this paradigm faces a deep-rooted one-pass issue whereby each generated intermediate thought is plugged into the trajectory regardless of its correctness, which can cause irreversible error propagation. To address the issue, this paper proposes a novel framework called Generator-Assistant Stepwise Rollback (GA-Rollback) to induce better decision-making for LLM agents. Particularly, GA-Rollback utilizes a generator to interact with the environment and an assistant to examine each action produced by the generator, where the assistant triggers a rollback operation upon detection of incorrect actions. Moreover, we introduce two additional strategies tailored for the rollback scenario to further improve its effectiveness. Extensive experiments show that GA-Rollback achieves significant improvements over several strong baselines on three widely used benchmarks. Our analysis further reveals that GA-Rollback can function as a robust plug-and-play module, integrating seamlessly with other methods. </p>
<blockquote>
<p>大型语言模型（LLM）代理通常采用逐步推理框架，在该框架中，它们将思考和行动过程交织在一起，以完成给定的任务。然而，这种范式面临一个根深蒂固的一次性通过问题，即无论中间产生的想法是否正确，都会将其插入到轨迹中，这可能导致不可逆的错误传播。为了解决这一问题，本文提出了一种名为生成器辅助逐步回滚（GA-Rollback）的新型框架，以引导LLM代理做出更好的决策。特别是，GA-Rollback利用生成器与环境进行交互，并利用助理检查生成器产生的每个动作，当检测到不正确的动作时，助理会触发回滚操作。此外，我们还引入了两种针对回滚场景的其他策略，以进一步提高其有效性。大量实验表明，在三个广泛使用的基准测试中，GA-Rollback相对于几个强大的基线取得了显著改进。我们的分析还表明，GA-Rollback可以作为一个强大的即插即用模块，能够无缝地与其他方法集成。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.02519v2">PDF</a> </p>
<p><strong>Summary</strong><br>大型语言模型（LLM）代理通常采用逐步推理框架执行任务，但存在一次性问题，可能导致错误传播。本文提出了一种名为Generator-Assistant Stepwise Rollback（GA-Rollback）的新框架，以更好地进行决策。GA-Rollback利用生成器与环境进行交互，并利用助理检查生成器的每个动作。一旦发现错误动作，助理将触发回滚操作。此外，还引入两种针对回滚场景的策略来提高其有效性。实验表明，GA-Rollback在广泛使用的三个基准测试上优于多个强大的基线模型。分析表明，GA-Rollback可以作为一个强大的即插即用模块与其他方法无缝集成。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>大型语言模型（LLM）代理在执行任务时通常采用逐步推理框架。</li>
<li>存在一种名为“一次性问题”的深层问题，可能导致错误传播。</li>
<li>GA-Rollback框架旨在解决这一问题，包括生成器与环境的交互以及助理的功能来检查每个动作。</li>
<li>当检测到错误的动作时，GA-Rollback会触发回滚操作以纠正错误。</li>
<li>引入两种针对回滚场景的策略以提高其有效性。</li>
<li>实验表明，GA-Rollback在多个基准测试上优于其他强大的模型。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.02519">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-07006fc081cb5c00c9e564243ef0ce5d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b82006f12ff1675a9bfae6c53113f654.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-e651f69779712bb9d217572d19509bd5.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-78c320d48c7dee25782a8690d989b8c6.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="RAG-Enhanced-Collaborative-LLM-Agents-for-Drug-Discovery"><a href="#RAG-Enhanced-Collaborative-LLM-Agents-for-Drug-Discovery" class="headerlink" title="RAG-Enhanced Collaborative LLM Agents for Drug Discovery"></a>RAG-Enhanced Collaborative LLM Agents for Drug Discovery</h2><p><strong>Authors:Namkyeong Lee, Edward De Brouwer, Ehsan Hajiramezanali, Tommaso Biancalani, Chanyoung Park, Gabriele Scalia</strong></p>
<p>Recent advances in large language models (LLMs) have shown great potential to accelerate drug discovery. However, the specialized nature of biochemical data often necessitates costly domain-specific fine-tuning, posing critical challenges. First, it hinders the application of more flexible general-purpose LLMs in cutting-edge drug discovery tasks. More importantly, it impedes the rapid integration of the vast amounts of scientific data continuously generated through experiments and research. To investigate these challenges, we propose CLADD, a retrieval-augmented generation (RAG)-empowered agentic system tailored to drug discovery tasks. Through the collaboration of multiple LLM agents, CLADD dynamically retrieves information from biomedical knowledge bases, contextualizes query molecules, and integrates relevant evidence to generate responses – all without the need for domain-specific fine-tuning. Crucially, we tackle key obstacles in applying RAG workflows to biochemical data, including data heterogeneity, ambiguity, and multi-source integration. We demonstrate the flexibility and effectiveness of this framework across a variety of drug discovery tasks, showing that it outperforms general-purpose and domain-specific LLMs as well as traditional deep learning approaches. </p>
<blockquote>
<p>最近的大型语言模型（LLM）的进步显示出加速药物发现的巨大潜力。然而，生化数据的特殊性通常需要进行昂贵的特定领域微调，这带来了重大挑战。首先，它阻碍了更灵活的通用LLM在前沿药物发现任务中的应用。更重要的是，它阻碍了通过试验和研究连续生成的大量科学数据的快速整合。为了研究这些挑战，我们提出了CLADD，这是一个用于药物发现任务的检索增强生成（RAG）赋能的代理系统。通过多个LLM代理的协作，CLADD能够动态地从生物医学知识库中检索信息，对查询分子进行语境化，并整合相关证据以生成响应，而无需特定的领域微调。最重要的是，我们解决了将RAG工作流程应用于生化数据的关键障碍，包括数据异质性、模糊性和多源集成。我们在各种药物发现任务中展示了该框架的灵活性和有效性，表明其在通用和特定领域的LLM以及传统的深度学习方法上表现出更高的性能。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.17506v2">PDF</a> Machine Learning, Drug Discovery</p>
<p><strong>Summary</strong><br>大规模语言模型（LLMs）在加速药物发现方面具有巨大潜力，但生化数据的特殊性需要昂贵的特定领域微调，带来挑战。我们提出CLADD系统，一个用于药物发现任务的检索增强生成（RAG）赋能代理系统，无需特定领域微调，即可通过多个LLM代理协作，从生物医学知识库中动态检索信息、上下文化查询分子并整合相关证据以生成响应。我们解决了将RAG工作流程应用于生化数据的关键障碍，并在多种药物发现任务中展示了该框架的灵活性和有效性。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>大规模语言模型在药物发现中具有巨大潜力。</li>
<li>生化数据的特殊性需要特定领域微调，增加了成本和挑战。</li>
<li>CLADD系统是一个用于药物发现任务的RAG赋能代理系统。</li>
<li>CLADD通过多个LLM代理协作，无需特定领域微调。</li>
<li>CLADD能从生物医学知识库中动态检索信息，并整合相关证据生成响应。</li>
<li>CLADD解决了将RAG工作流程应用于生化数据的关键障碍。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.17506">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-9e8e8f8df0f0d43a9572a49f2a92d7cc.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-7a9f5a5ef2648a2d78dec2132d13faa7.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-fc48e024f0816cf00d9d7e003b36f5d9.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="Leveraging-Dual-Process-Theory-in-Language-Agent-Framework-for-Real-time-Simultaneous-Human-AI-Collaboration"><a href="#Leveraging-Dual-Process-Theory-in-Language-Agent-Framework-for-Real-time-Simultaneous-Human-AI-Collaboration" class="headerlink" title="Leveraging Dual Process Theory in Language Agent Framework for Real-time   Simultaneous Human-AI Collaboration"></a>Leveraging Dual Process Theory in Language Agent Framework for Real-time   Simultaneous Human-AI Collaboration</h2><p><strong>Authors:Shao Zhang, Xihuai Wang, Wenhao Zhang, Chaoran Li, Junru Song, Tingyu Li, Lin Qiu, Xuezhi Cao, Xunliang Cai, Wen Yao, Weinan Zhang, Xinbing Wang, Ying Wen</strong></p>
<p>Agents built on large language models (LLMs) have excelled in turn-by-turn human-AI collaboration but struggle with simultaneous tasks requiring real-time interaction. Latency issues and the challenge of inferring variable human strategies hinder their ability to make autonomous decisions without explicit instructions. Through experiments with current independent System 1 and System 2 methods, we validate the necessity of using Dual Process Theory (DPT) in real-time tasks. We propose DPT-Agent, a novel language agent framework that integrates System 1 and System 2 for efficient real-time simultaneous human-AI collaboration. DPT-Agent’s System 1 uses a Finite-state Machine (FSM) and code-as-policy for fast, intuitive, and controllable decision-making. DPT-Agent’s System 2 integrates Theory of Mind (ToM) and asynchronous reflection to infer human intentions and perform reasoning-based autonomous decisions. We demonstrate the effectiveness of DPT-Agent through further experiments with rule-based agents and human collaborators, showing significant improvements over mainstream LLM-based frameworks. DPT-Agent can effectively help LLMs convert correct slow thinking and reasoning into executable actions, thereby improving performance. To the best of our knowledge, DPT-Agent is the first language agent framework that achieves successful real-time simultaneous human-AI collaboration autonomously. Code of DPT-Agent can be found in <a target="_blank" rel="noopener" href="https://github.com/sjtu-marl/DPT-Agent">https://github.com/sjtu-marl/DPT-Agent</a>. </p>
<blockquote>
<p>基于大型语言模型（LLM）的代理人在逐轮的人机协作中表现出色，但在需要实时交互的同时任务中遇到了困难。延迟问题和推断可变人类策略的挑战影响了它们在没有明确指令的情况下进行自主决策的能力。通过当前独立的System 1和System 2方法的实验，我们验证了在实时任务中使用双过程理论（DPT）的必要性。我们提出了DPT-Agent，这是一种新型的语言代理框架，它整合了System 1和System 2，以实现高效实时的同时人机协作。DPT-Agent的System 1使用有限状态机（FSM）和代码即策略来进行快速、直观和可控的决策。DPT-Agent的System 2结合了心智理论（ToM）和异步反射来推断人类意图并进行基于推理的自主决策。我们通过与基于规则的代理和人类合作者进一步实验，证明了DPT-Agent的有效性，显示出在主流LLM框架上有显著改进。DPT-Agent可以有效地帮助LLM将正确的慢思考和推理转化为可执行行动，从而提高性能。据我们所知，DPT-Agent是第一个成功实现实时同步人机协作的自主语言代理框架。DPT-Agent的代码可在<a target="_blank" rel="noopener" href="https://github.com/sjtu-marl/DPT-Agent">https://github.com/sjtu-marl/DPT-Agent</a>找到。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.11882v4">PDF</a> Preprint under review. Update the experimental results of the   DeepSeek-R1 series models, QwQ-32b, o3-mini-high and o3-mini-medium</p>
<p><strong>摘要</strong></p>
<p>基于大型语言模型（LLM）的代理在逐步的人类-人工智能协作中表现出色，但在需要实时交互的同时任务中表现挣扎。延迟问题和推断可变人类策略的挑战限制了其在没有明确指令的情况下做出自主决策的能力。通过当前独立的System 1和System 2方法的实验验证，我们认识到在实时任务中应用双过程理论（DPT）的必要性。我们提出一种新型的语言代理框架DPT-Agent，它整合了System 1和System 2，以实现高效实时的同时人类-人工智能协作。DPT-Agent的System 1使用有限状态机（FSM）和代码即策略，以快速、直观和可控的方式进行决策。而System 2则融入了心智理论（ToM）和异步反射，以推断人类意图并进行基于推理的自主决策。我们通过与基于规则的代理和人类合作者进一步实验证明了DPT-Agent的有效性，显示其在主流LLM框架上有显著改进。DPT-Agent能有效帮助LLM将正确的慢思考和推理转化为可执行动作，从而提高性能。据我们所知，DPT-Agent是首个实现实时同步人类-人工智能协作的自主语言代理框架。有关DPT-Agent的代码可在<a target="_blank" rel="noopener" href="https://github.com/sjtu-marl/DPT-Agent%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/sjtu-marl/DPT-Agent找到。</a></p>
<p><strong>关键见解</strong></p>
<ol>
<li>基于大型语言模型的代理在实时交互任务中存在挑战，如延迟和推断可变人类策略的问题。</li>
<li>双过程理论（DPT）对于实现实时任务中的自主决策至关重要。</li>
<li>DPT-Agent是一个新型语言代理框架，融合了System 1和System 2以实现高效实时人类-人工智能协作。</li>
<li>DPT-Agent的System 1使用有限状态机和代码即策略进行快速决策。</li>
<li>DPT-Agent的System 2能够推断人类意图并进行基于推理的自主决策，通过心智理论和异步反射实现。</li>
<li>实验表明，DPT-Agent在主流的大型语言模型框架上实现了显著的性能改进。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.11882">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-d82fbec6191f6705034b940b59cac8b9.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c027fcd0b63915ce5f245556cb626eed.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-733c9d53acc340f1f314af5fd4ae9d7d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d6e817bd16d42e0f5cbcf78ed174e105.jpg" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="TimeCAP-Learning-to-Contextualize-Augment-and-Predict-Time-Series-Events-with-Large-Language-Model-Agents"><a href="#TimeCAP-Learning-to-Contextualize-Augment-and-Predict-Time-Series-Events-with-Large-Language-Model-Agents" class="headerlink" title="TimeCAP: Learning to Contextualize, Augment, and Predict Time Series   Events with Large Language Model Agents"></a>TimeCAP: Learning to Contextualize, Augment, and Predict Time Series   Events with Large Language Model Agents</h2><p><strong>Authors:Geon Lee, Wenchao Yu, Kijung Shin, Wei Cheng, Haifeng Chen</strong></p>
<p>Time series data is essential in various applications, including climate modeling, healthcare monitoring, and financial analytics. Understanding the contextual information associated with real-world time series data is often essential for accurate and reliable event predictions. In this paper, we introduce TimeCAP, a time-series processing framework that creatively employs Large Language Models (LLMs) as contextualizers of time series data, extending their typical usage as predictors. TimeCAP incorporates two independent LLM agents: one generates a textual summary capturing the context of the time series, while the other uses this enriched summary to make more informed predictions. In addition, TimeCAP employs a multi-modal encoder that synergizes with the LLM agents, enhancing predictive performance through mutual augmentation of inputs with in-context examples. Experimental results on real-world datasets demonstrate that TimeCAP outperforms state-of-the-art methods for time series event prediction, including those utilizing LLMs as predictors, achieving an average improvement of 28.75% in F1 score. </p>
<blockquote>
<p>时间序列数据在各种应用中至关重要，包括气候建模、健康监测和财务分析。理解现实世界时间序列数据相关的上下文信息对于准确可靠的事件预测通常至关重要。在本文中，我们介绍了TimeCAP，这是一个时间序列处理框架，创造性地利用大型语言模型（LLM）作为时间序列数据的语境化工具，扩展了其作为预测器的典型用途。TimeCAP集成了两个独立的大型语言模型代理：一个生成文本摘要，捕捉时间序列的上下文，另一个则利用这个丰富的摘要做出更有根据的预测。此外，TimeCAP采用多模态编码器，与大型语言模型代理协同工作，通过相互增强输入和上下文实例，提高预测性能。在真实数据集上的实验结果表明，TimeCAP在事件预测方面优于最新时间序列预测方法，包括使用大型语言模型作为预测器的方法，在F1分数上平均提高了28.75%。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.11418v2">PDF</a> AAAI 2025</p>
<p><strong>Summary</strong><br>时间序列数据在气候建模、健康监测和金融分析等多个领域都有广泛应用。理解真实世界时间序列数据相关的上下文信息对于准确可靠的事件预测至关重要。本文介绍了一个时间序列处理框架TimeCAP，它创造性地利用大型语言模型（LLM）作为时间序列数据的上下文解析器，扩展了它们作为预测器的典型用途。TimeCAP包含两个独立的LLM代理，一个生成捕获时间序列上下文的文本摘要，另一个使用这个丰富的摘要来做出更明智的预测。此外，TimeCAP还采用多模式编码器，与LLM代理协同工作，通过上下文示例的输入互增，提高预测性能。在真实数据集上的实验结果表明，TimeCAP在事件预测方面优于现有技术方法，包括使用LLM作为预测器的方法，在F1分数上平均提高了28.75%。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>时间序列数据在多个领域有广泛应用，包括气候建模、健康监测和金融分析等。</li>
<li>理解时间序列数据的上下文信息对准确预测事件至关重要。</li>
<li>TimeCAP是一个基于大型语言模型（LLM）的时间序列处理框架，用于解析时间序列数据的上下文信息。</li>
<li>TimeCAP包含两个独立的LLM代理，一个生成文本摘要，另一个基于该摘要进行预测。</li>
<li>TimeCAP采用多模式编码器，与LLM代理协同工作，提高预测性能。</li>
<li>TimeCAP在真实数据集上的实验结果表明其优于现有技术方法，包括使用LLM作为预测器的方法。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.11418">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-c405a270025d4d46cb5d3e72ba7b4fa4.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-1ed3f57b79eebddb30b6f3bb6ac8a76b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-da43aaf78f35205dac4d4afa9b741047.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-62c8c8bd0cdef1400b9c939542dd8f20.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-bf92a72b74760c2bed789aa54b989967.jpg" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1><h2 id="SafeAgentBench-A-Benchmark-for-Safe-Task-Planning-of-Embodied-LLM-Agents"><a href="#SafeAgentBench-A-Benchmark-for-Safe-Task-Planning-of-Embodied-LLM-Agents" class="headerlink" title="SafeAgentBench: A Benchmark for Safe Task Planning of Embodied LLM   Agents"></a>SafeAgentBench: A Benchmark for Safe Task Planning of Embodied LLM   Agents</h2><p><strong>Authors:Sheng Yin, Xianghe Pang, Yuanzhuo Ding, Menglan Chen, Yutong Bi, Yichen Xiong, Wenhao Huang, Zhen Xiang, Jing Shao, Siheng Chen</strong></p>
<p>With the integration of large language models (LLMs), embodied agents have strong capabilities to understand and plan complicated natural language instructions. However, a foreseeable issue is that those embodied agents can also flawlessly execute some hazardous tasks, potentially causing damages in the real world. Existing benchmarks predominantly overlook critical safety risks, focusing solely on planning performance, while a few evaluate LLMs’ safety awareness only on non-interactive image-text data. To address this gap, we present SafeAgentBench-the first benchmark for safety-aware task planning of embodied LLM agents in interactive simulation environments. SafeAgentBench includes: (1) an executable, diverse, and high-quality dataset of 750 tasks, rigorously curated to cover 10 potential hazards and 3 task types; (2) SafeAgentEnv, a universal embodied environment with a low-level controller, supporting multi-agent execution with 17 high-level actions for 8 state-of-the-art baselines; and (3) reliable evaluation methods from both execution and semantic perspectives. Experimental results show that, although agents based on different design frameworks exhibit substantial differences in task success rates, their overall safety awareness remains weak. The most safety-conscious baseline achieves only a 10% rejection rate for detailed hazardous tasks. Moreover, simply replacing the LLM driving the agent does not lead to notable improvements in safety awareness. More details and code are available at <a target="_blank" rel="noopener" href="https://github.com/shengyin1224/SafeAgentBench">https://github.com/shengyin1224/SafeAgentBench</a>. </p>
<blockquote>
<p>随着大型语言模型（LLM）的集成，实体代理具有强大的理解和规划复杂自然语言指令的能力。然而，一个可预见的问题是他们也能完美执行一些危险任务，可能在现实世界中造成损害。现有的基准测试主要忽视了关键的安全风险，只专注于规划性能，而少数测试只在非交互式的图像文本数据上评估LLM的安全意识。为了弥补这一空白，我们推出了SafeAgentBench——首个用于交互式模拟环境中实体LLM代理的安全意识任务规划的基准测试。SafeAgentBench包括：（1）750个可执行、多样化、高质量的任务数据集，经过严格筛选，涵盖10种潜在危险和3种任务类型；（2）SafeAgentEnv，一个通用实体环境，具有低级控制器，支持多代理执行，具有17个高级动作，适用于8种最新基线；（3）从执行和语义两个方面的可靠评估方法。实验结果表明，虽然基于不同设计框架的代理在任务成功率方面存在显著差异，但他们的整体安全意识仍然薄弱。最具有安全意识的基线只对详细的危险任务实现了10%的拒绝率。此外，仅仅更换驱动代理的LLM并不会导致安全意识显著提高。更多细节和代码请访问：<a target="_blank" rel="noopener" href="https://github.com/shengyin1224/SafeAgentBench%E3%80%82">https://github.com/shengyin1224/SafeAgentBench。</a></p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.13178v4">PDF</a> 23 pages, 17 tables, 14 figures</p>
<p><strong>Summary</strong></p>
<p>本文介绍了一个名为SafeAgentBench的新基准测试，该测试旨在评估大型语言模型驱动的智能实体代理在交互式模拟环境中的安全感知任务规划能力。SafeAgentBench包括一个多样化的高质量数据集，一个通用的智能实体环境，以及从执行和语义两个角度的可靠评估方法。实验结果显示，虽然不同设计框架的代理在任务成功率上有显著差异，但它们在整体安全感知方面仍存在较大不足。最注重安全的基线仅实现了对危险任务的10%拒绝率，简单地更换驱动代理的大型语言模型并不能显著提高安全感知能力。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>SafeAgentBench是首个针对智能实体代理的安全感知任务规划能力的基准测试。</li>
<li>该基准测试包括一个多样化的高质量数据集，涵盖10种潜在危险和3种任务类型。</li>
<li>SafeAgentBench提供了一个通用的智能实体环境，支持多代理执行，并具有从执行和语义两个角度的可靠评估方法。</li>
<li>实验结果显示智能实体代理在整体安全感知方面存在不足。</li>
<li>不同设计框架的代理在任务成功率上有显著差异。</li>
<li>最注重安全的基线仅实现了对危险任务的较低拒绝率。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.13178">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-8ecbd373c96081429580f6c27345a43a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-0b92710f7199402e0ce6b99474d840ac.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-60debbb135120476bf3743e11a7d0eba.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-2e51420564a676076b3ae3b4a34b9297.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-536557dd7e4e6f8850f7384f7de041ee.jpg" align="middle">
</details>


<h1 id="-9"><a href="#-9" class="headerlink" title=""></a></h1><h2 id="EvoAgent-Towards-Automatic-Multi-Agent-Generation-via-Evolutionary-Algorithms"><a href="#EvoAgent-Towards-Automatic-Multi-Agent-Generation-via-Evolutionary-Algorithms" class="headerlink" title="EvoAgent: Towards Automatic Multi-Agent Generation via Evolutionary   Algorithms"></a>EvoAgent: Towards Automatic Multi-Agent Generation via Evolutionary   Algorithms</h2><p><strong>Authors:Siyu Yuan, Kaitao Song, Jiangjie Chen, Xu Tan, Dongsheng Li, Deqing Yang</strong></p>
<p>The rise of powerful large language models (LLMs) has spurred a new trend in building LLM-based autonomous agents for solving complex tasks, especially multi-agent systems. Despite the remarkable progress, we notice that existing works are heavily dependent on human-designed frameworks, which greatly limits the functional scope and scalability of agent systems. How to automatically extend the specialized agent to multi-agent systems to improve task-solving capability still remains a significant challenge. In this paper, we introduce EvoAgent, a generic method to automatically extend specialized agents to multi-agent systems via the evolutionary algorithm, thereby improving the effectiveness of LLM-based agents in solving tasks. Specifically, we consider the existing agent frameworks as the initial individual and then apply a series of evolutionary operators (e.g., mutation, crossover, selection, etc.) to generate multiple agents with diverse settings. Experimental results across various tasks show that EvoAgent can significantly enhance the task-solving capability of LLM-based agents, and can be generalized to any LLM-based agent framework to extend them into multi-agent systems. Resources are available at <a target="_blank" rel="noopener" href="https://evo-agent.github.io/">https://evo-agent.github.io/</a>. </p>
<blockquote>
<p>随着强大的大型语言模型（LLM）的兴起，基于LLM构建自主代理来解决复杂任务，尤其是多代理系统，已经成为了一种新的趋势。尽管取得了显著的进步，但我们注意到现有工作严重依赖于人工设计的框架，这极大地限制了代理系统的功能范围和可扩展性。如何将专用代理自动扩展到多代理系统以提高任务解决能力仍然是一个巨大的挑战。在本文中，我们介绍了EvoAgent，这是一种通过进化算法将专用代理自动扩展到多代理系统的通用方法，从而提高了基于LLM的代理在完成任务方面的有效性。具体来说，我们将现有的代理框架视为初始个体，然后应用一系列进化算子（例如变异、交叉、选择等）来生成具有不同设置的多个代理。跨越各种任务的实验结果表明，EvoAgent可以显著提高基于LLM的代理的任务解决能力，并且可以推广到其他任何基于LLM的代理框架中，将它们扩展到多代理系统。相关资源可在<a target="_blank" rel="noopener" href="https://evo-agent.github.io/%E6%89%BE%E5%88%B0%E3%80%82">https://evo-agent.github.io/找到。</a></p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2406.14228v3">PDF</a> Accepted as a main conference paper at NAACL 2025</p>
<p><strong>Summary</strong></p>
<p>基于大型语言模型（LLM）的自主代理的发展为解决复杂任务提供了新的趋势，特别是在多代理系统方面。然而，现有工作大多依赖于人工设计的框架，限制了代理系统的功能范围和可扩展性。本文提出EvoAgent方法，通过进化算法自动将专用代理扩展到多代理系统，从而提高LLM基代理的任务解决能力。实验结果表明，EvoAgent能显著提高LLM基代理的任务解决能力，并可推广至任何LLM基代理框架，将其扩展为多代理系统。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>大型语言模型（LLM）的崛起为构建自主代理提供了新趋势，特别是在解决复杂任务和多代理系统方面。</li>
<li>现有代理系统大多依赖于人工设计框架，这限制了它们的功能和可扩展性。</li>
<li>EvoAgent是一种通过将专用代理自动扩展到多代理系统的方法，以提高基于LLM的代理的任务解决能力。</li>
<li>EvoAgent使用进化算法，将现有代理框架视为初始个体，并通过一系列进化算子（如变异、交叉、选择等）生成多个具有不同设置的代理。</li>
<li>实验结果表明，EvoAgent在多种任务上显著提高了基于LLM的代理的任务解决能力。</li>
<li>EvoAgent可以推广至任何LLM基代理框架，实现多代理系统的扩展。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2406.14228">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-b1f2cdf0e0454178e8288d40cbe0341a.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-bbd0d306f7e5c4b511e28c6134e4857e.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-e7c56f5ba82e58605acecc93490e8eac.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-cce8d11133addefe6c30f84916f16d32.jpg" align="middle">
</details>


<h1 id="-10"><a href="#-10" class="headerlink" title=""></a></h1><h2 id="Robust-and-Performance-Incentivizing-Algorithms-for-Multi-Armed-Bandits-with-Strategic-Agents"><a href="#Robust-and-Performance-Incentivizing-Algorithms-for-Multi-Armed-Bandits-with-Strategic-Agents" class="headerlink" title="Robust and Performance Incentivizing Algorithms for Multi-Armed Bandits   with Strategic Agents"></a>Robust and Performance Incentivizing Algorithms for Multi-Armed Bandits   with Strategic Agents</h2><p><strong>Authors:Seyed A. Esmaeili, Suho Shin, Aleksandrs Slivkins</strong></p>
<p>Motivated by applications such as online labor markets we consider a variant of the stochastic multi-armed bandit problem where we have a collection of arms representing strategic agents with different performance characteristics. The platform (principal) chooses an agent in each round to complete a task. Unlike the standard setting, when an arm is pulled it can modify its reward by absorbing it or improving it at the expense of a higher cost. The principle has to solve a mechanism design problem to incentivize the arms to give their best performance. However, since even with an effective mechanism agents may still deviate from rational behavior, the principal wants a robust algorithm that also gives a non-vacuous guarantee on the total accumulated rewards under non-equilibrium behavior. In this paper, we introduce a class of bandit algorithms that meet the two objectives of performance incentivization and robustness simultaneously. We do this by identifying a collection of intuitive properties that a bandit algorithm has to satisfy to achieve these objectives. Finally, we show that settings where the principal has no information about the arms’ performance characteristics can be handled by combining ideas from second price auctions with our algorithms. </p>
<blockquote>
<p>受在线劳动市场等应用驱动的启发，我们考虑随机多臂老虎机问题的一个变体。在这个变体中，我们有一组代表具有不同性能特征的策略性代理的“手臂”。平台（委托人）每轮都会选择一个代理来完成任务。与标准设置不同，当拉动一个“手臂”时，它可以通过吸收或提高奖励来改进其奖励，但这需要以更高的成本为代价。委托人需要解决一个机制设计问题，以激励“手臂”发挥最佳性能。然而，由于即使有了有效的机制，代理人仍可能偏离理性行为，委托人需要一个稳健的算法，该算法在非均衡行为下也能提供非空的总体累积奖励保证。在本文中，我们介绍了一类满足激励性能和稳健性两个目标的强盗算法。我们通过识别一系列直观属性来实现这一点，这些属性是强盗算法必须满足的以实现这些目标。最后，我们展示了当委托人没有任何关于手臂性能特征的信息时，可以通过将第二价格拍卖的想法与我们的算法相结合来处理这种情况。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2312.07929v2">PDF</a> </p>
<p><strong>总结</strong></p>
<p>在在线劳动市场等应用背景下，考虑了一种随机多臂赌博问题的变体。平台（委托人）每轮选择一个代理人完成任务。不同于标准设置，当拉动一个手臂时，它可以通过吸收或提高奖励来改善其表现，但需要付出更高的成本。委托人需要解决机制设计问题，以激励手臂发挥最佳性能。然而，即使有有效的机制，代理人仍可能偏离理性行为，因此委托人需要一个既满足性能激励要求又具有对非均衡行为下的总累积奖励的非真空保证的稳健算法。本文引入了一类赌博算法，可以同时实现性能激励和稳健性的目标。我们通过识别一系列直觉属性来实现这一点，这些属性必须被满足以达到这些目标。最后，我们展示了当委托人无法了解手臂的性能特征时，可以通过将第二价格拍卖的理念与我们的算法相结合来应对挑战。 </p>
<p><strong>要点分析</strong></p>
<ul>
<li>考虑在线劳动市场背景下的随机多臂赌博问题变体。</li>
<li>平台（委托人）每轮选择代理人完成任务，代理人可调整其奖励以提高表现的成本不同。 </li>
<li>需要解决机制设计问题来激励手臂的最佳表现，并解决代理人在非均衡情况下的偏离问题。 </li>
<li>引入同时实现性能激励和稳健性的赌博算法类。 </li>
<li>算法满足直观属性以达到激励和稳健目标。 </li>
<li>当委托人没有关于手臂性能特征的信息时，可以通过结合第二价格拍卖的理念来应对挑战。这是一个有效的策略来激发战略性行为的有效表现和鼓励参与者在未知环境中的自我提升等行为的考虑融入在线劳务市场中实施和优化自动化策略的动态模拟分析中作为新领域的发展讨论和未来趋势的分析具有重要的应用前景并启示我们从多维度的角度来综合考虑和设计更高效稳定的智能任务分配和自动化管理机制来实现理论研究成果在实践中的应用与突破促进人工智能技术的高速发展与变革解决了当代挑战如制定稳定激励机制如何动态反应分配者现有能力与利用机制的可靠稳健决策策略实现大规模智能化应用的突破点在此我们认识到高效可靠稳定的算法对构建公正可持续智能任务市场的重要性并在实践中通过实施监控调整改进以及实践验证其应用的有效性和稳定性为未来的人工智能应用奠定基础贡献了新的解决方案以推动相关行业的创新发展回应问题和质疑与解答用户对该研究的见解和分析呈现的研究意义和展望具有重要应用价值促进了对未知领域更深层次的探讨并可能激发未来的深入研究从而不断推动科技领域的前进发展开启新篇章基于提供的这些见解我们将对原始研究提出新的问题并进一步研究未来的发展方向和创新可能性为该领域的未来贡献新的观点和见解促进理论的突破和实践的应用作为对于研究的思考和启发面向未来发展提供了一种深入的理解和实施方案的灵感以期在该领域发挥积极的作用解决面临的各种问题和挑战回应评论进一步探究实施效果和相关解决方案以提高服务质量为未来应用的推进注入新的活力和方向展示技术的价值优势对于相关研究具有重要价值可能开辟新研究路径未来相关领域发展方向的深度分析在未来实践应用中将会展现出强大的应用前景助力科技发展引领未来的研究和探索具有重要意义</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2312.07929">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-e8b5050a17199cf7082e8c4aac9604e9.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-20ecf2d41961d42cfaa45f3aaee292af.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-51ad9309728fd754b40b8ae586c49124.jpg" align="middle">
</details>


<h1 id="-11"><a href="#-11" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        文章作者:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        文章链接:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-03-12/Agent/">https://kedreamix.github.io/Talk2Paper/Paper/2025-03-12/Agent/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        版权声明:
                    </i>
                </span>
                <span class="reprint-info">
                    本博客所有文章除特別声明外，均采用
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    许可协议。转载请注明来源
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/Agent/">
                                    <span class="chip bg-color">Agent</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;上一篇</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-03-12/MMT/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-3c6e299ad16040444d5c2bb0c92c3a51.jpg" class="responsive-img" alt="MMT">
                        
                        <span class="card-title">MMT</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            MMT 方向最新论文已更新，请持续关注 Update in 2025-03-12  Property Enhanced Instruction Tuning for Multi-task Molecule Generation   with Large Language Models
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-03-12
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/MMT/" class="post-category">
                                    MMT
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/MMT/">
                        <span class="chip bg-color">MMT</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-03-12/LLM/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-22c1cab13206bae677ca24ed494c6e63.jpg" class="responsive-img" alt="LLM">
                        
                        <span class="card-title">LLM</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            LLM 方向最新论文已更新，请持续关注 Update in 2025-03-12  V2Flow Unifying Visual Tokenization and Large Language Model   Vocabularies for Autoregressive Image Generation
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-03-12
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/LLM/" class="post-category">
                                    LLM
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/LLM/">
                        <span class="chip bg-color">LLM</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- 代码语言 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span
                        class="white-color">28315.1k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- 运行天数提醒. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // 区分是否有年份.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = '本站已运行 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                daysTip = '本站已運行 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = '本站已运行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = '本站已運行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="关注我的知乎: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">知</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- 白天和黑夜主题 -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // 只在桌面版网页启用特效
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- 雪花特效 -->
    

    <!-- 鼠标星星特效 -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--腾讯兔小巢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- 动态标签 -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Σ(っ °Д °;)っ诶，页面崩溃了嘛？", clearTimeout(st)) : (document.title = "φ(゜▽゜*)♪咦，又好了！", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
