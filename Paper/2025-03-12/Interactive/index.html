<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Interactive">
    <meta name="description" content="Interactive 方向最新论文已更新，请持续关注 Update in 2025-03-12  KwaiChat A Large-Scale Video-Driven Multilingual Mixed-Type Dialogue   Corpus">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>Interactive | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loader页面消失采用渐隐的方式*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logo出现动画 */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//使用渐隐的方法淡出loading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//强制显示loading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">嘘~  正在从服务器偷取页面 . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>首页</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>标签</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>分类</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>归档</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="搜索" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="深色/浅色模式" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			首页
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			标签
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			分类
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			归档
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://picx.zhimg.com/v2-d4365d3f35c533643161154d734be9aa.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Interactive</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/Interactive/">
                                <span class="chip bg-color">Interactive</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/Interactive/" class="post-category">
                                Interactive
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2025-03-12
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>更新日期:&nbsp;&nbsp;
                    2025-05-14
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp;
                    6.1k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp;
                    24 分
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>阅读次数:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>⚠️ 以下所有内容总结都来自于 大语言模型的能力，如有错误，仅供参考，谨慎使用<br>🔴 请注意：千万不要用于严肃的学术场景，只能用于论文阅读前的初筛！<br>💗 如果您觉得我们的项目对您有帮助 <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ，还请您给我们一些鼓励！⭐️ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFace免费体验</a></p>
</blockquote>
<h1 id="2025-03-12-更新"><a href="#2025-03-12-更新" class="headerlink" title="2025-03-12 更新"></a>2025-03-12 更新</h1><h2 id="KwaiChat-A-Large-Scale-Video-Driven-Multilingual-Mixed-Type-Dialogue-Corpus"><a href="#KwaiChat-A-Large-Scale-Video-Driven-Multilingual-Mixed-Type-Dialogue-Corpus" class="headerlink" title="KwaiChat: A Large-Scale Video-Driven Multilingual Mixed-Type Dialogue   Corpus"></a>KwaiChat: A Large-Scale Video-Driven Multilingual Mixed-Type Dialogue   Corpus</h2><p><strong>Authors:Xiaoming Shi, Zeming Liu, Yiming Lei, Chenkai Zhang, Haitao Leng, Chuan Wang, Qingjie Liu, Wanxiang Che, Shaoguo Liu, Size Li, Yunhong Wang</strong></p>
<p>Video-based dialogue systems, such as education assistants, have compelling application value, thereby garnering growing interest. However, the current video-based dialogue systems are limited by their reliance on a single dialogue type, which hinders their versatility in practical applications across a range of scenarios, including question-answering, emotional dialog, etc. In this paper, we identify this challenge as how to generate video-driven multilingual mixed-type dialogues. To mitigate this challenge, we propose a novel task and create a human-to-human video-driven multilingual mixed-type dialogue corpus, termed KwaiChat, containing a total of 93,209 videos and 246,080 dialogues, across 4 dialogue types, 30 domains, 4 languages, and 13 topics. Additionally, we establish baseline models on KwaiChat. An extensive analysis of 7 distinct LLMs on KwaiChat reveals that GPT-4o achieves the best performance but still cannot perform well in this situation even with the help of in-context learning and fine-tuning, which indicates that the task is not trivial and needs further research. </p>
<blockquote>
<p>基于视频的对话系统，如教育助理，具有引人注目的应用价值，因此正日益受到关注。然而，当前的基于视频的对话系统受限于其依赖单一对话类型，这阻碍了它们在多种场景下的实际应用通用性，包括问答、情感对话等。在本文中，我们将这一挑战识别为如何生成视频驱动的多语言混合类型对话。为了缓解这一挑战，我们提出了一个新任务，并创建了一个人机视频驱动的多语言混合类型对话语料库，名为KwaiChat。它包含93,209个视频和246,080个对话，涵盖4种对话类型、30个领域、4种语言和13个主题。此外，我们在KwaiChat上建立了基线模型。对KwaiChat的7种不同大型语言模型的广泛分析表明，GPT-4o取得了最佳性能，但在这种情境下，即使在上下文学习和微调的支持下，其表现仍不尽如人意，这表明该任务并非微不足道，需要进一步研究。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.06899v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>视频对话系统在教育助理等领域具有应用价值，并受到越来越多的关注。然而，当前视频对话系统主要依赖于单一对话类型，限制了它们在问答、情感对话等多种场景中的应用。本文提出了一项新任务，并创建了一个名为KwaiChat的人与人视频驱动的多语言混合对话语料库，包含93,209个视频和246,080个对话。通过对七种大型语言模型的深入分析，发现GPT-4o表现最佳，但仍需要在该任务上进一步研究和改进。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>视频对话系统在教育助理等领域具有广泛的应用价值。</li>
<li>当前视频对话系统主要依赖于单一对话类型，限制了其在多种场景中的应用。</li>
<li>本文提出了一个新的任务，即生成视频驱动的多语言混合对话。</li>
<li>创建了名为KwaiChat的视频驱动多语言混合对话语料库，包含大量视频和对话数据。</li>
<li>通过对七种大型语言模型的深入分析，发现GPT-4o在KwaiChat上的表现最佳。</li>
<li>GPT-4o虽然表现较好，但仍需进一步研究和改进。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.06899">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-2a5ad67abafbfb10f89a9b1dffe85b7d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-354cf50a1d07d9ddd526867be6e786c4.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-8b324e46d67d90c495677dfdf68fe1eb.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-fdb73488fba3bbd3ddefeb2971b87ca3.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-50caa674ae84de3241f19bdc0ef922f9.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="PFDial-A-Structured-Dialogue-Instruction-Fine-tuning-Method-Based-on-UML-Flowcharts"><a href="#PFDial-A-Structured-Dialogue-Instruction-Fine-tuning-Method-Based-on-UML-Flowcharts" class="headerlink" title="PFDial: A Structured Dialogue Instruction Fine-tuning Method Based on   UML Flowcharts"></a>PFDial: A Structured Dialogue Instruction Fine-tuning Method Based on   UML Flowcharts</h2><p><strong>Authors:Ming Zhang, Yuhui Wang, Yujiong Shen, Tingyi Yang, Changhao Jiang, Yilong Wu, Shihan Dou, Qinhao Chen, Zhiheng Xi, Zhihao Zhang, Yi Dong, Zhen Wang, Zhihui Fei, Mingyang Wan, Tao Liang, Guojun Ma, Qi Zhang, Tao Gui, Xuanjing Huang</strong></p>
<p>Process-driven dialogue systems, which operate under strict predefined process constraints, are essential in customer service and equipment maintenance scenarios. Although Large Language Models (LLMs) have shown remarkable progress in dialogue and reasoning, they still struggle to solve these strictly constrained dialogue tasks. To address this challenge, we construct Process Flow Dialogue (PFDial) dataset, which contains 12,705 high-quality Chinese dialogue instructions derived from 440 flowcharts containing 5,055 process nodes. Based on PlantUML specification, each UML flowchart is converted into atomic dialogue units i.e., structured five-tuples. Experimental results demonstrate that a 7B model trained with merely 800 samples, and a 0.5B model trained on total data both can surpass 90% accuracy. Additionally, the 8B model can surpass GPT-4o up to 43.88% with an average of 11.00%. We further evaluate models’ performance on challenging backward transitions in process flows and conduct an in-depth analysis of various dataset formats to reveal their impact on model performance in handling decision and sequential branches. The data is released in <a target="_blank" rel="noopener" href="https://github.com/KongLongGeFDU/PFDial">https://github.com/KongLongGeFDU/PFDial</a>. </p>
<blockquote>
<p>流程驱动的对话系统在客户服务和设备维护场景中至关重要，这些系统受到严格的预先定义流程约束的限制。尽管大型语言模型（LLM）在对话和推理方面取得了显著进展，但它们仍然难以解决这些受严格约束的对话任务。为了应对这一挑战，我们构建了流程对话（PFDial）数据集，其中包含12705条高质量中文对话指令，这些指令来源于包含5055个流程节点的440个流程图。基于PlantUML规范，每个UML流程图被转换为原子对话单元，即结构化五元组。实验结果表明，仅使用800个样本训练的7B模型以及使用全部数据训练的0.5B模型，其准确率均可达到超过90%。此外，8B模型的性能可以超过GPT-4o高达43.88%，平均提高11.00%。我们还进一步评估了模型在处理流程中的逆向转换等挑战方面的性能，并对各种数据集格式进行了深入分析，以揭示它们对模型处理决策和顺序分支的性能的影响。数据已发布在<a target="_blank" rel="noopener" href="https://github.com/KongLongGeFDU/PFDial%E3%80%82">https://github.com/KongLongGeFDU/PFDial。</a></p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.06706v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>流程驱动型对话系统在客户服务和设备维护场景中发挥着关键作用。针对大型语言模型在解决这类受严格预设流程约束的任务时的挑战，我们构建了包含高质量中文对话指令的“流程对话”（PFDial）数据集。该数据集基于PlantUML规范，将UML流程图转换为结构化对话单元。实验结果显示，训练模型在数据集上的表现优异，尤其是大型模型。同时，我们还对模型在处理流程中的反向转换以及不同数据集格式对模型性能的影响进行了深入分析和评估。数据集已公开发布。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>流程驱动型对话系统在客户服务、设备维护等领域有重要作用。</li>
<li>大型语言模型在处理严格预设流程约束的对话任务时面临挑战。</li>
<li>构建了包含高质量中文对话指令的“流程对话”（PFDial）数据集。</li>
<li>数据集基于PlantUML规范，将UML流程图转换为结构化对话单元。</li>
<li>实验显示，训练模型在数据集上的表现优异，尤其是大型模型。</li>
<li>模型在处理流程中的反向转换方面的性能得到了评估。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.06706">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-aaa9d3f20639f8ea8577669f9cdae481.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f49121ab5fbb12dbb4dca45096581171.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-bdddc5ec03970c2b485d13d22602795f.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-0b838b1b3421821e35729466bcc0016f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-629b9034a222fcc71056028bf8e92d8e.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="StreamMind-Unlocking-Full-Frame-Rate-Streaming-Video-Dialogue-through-Event-Gated-Cognition"><a href="#StreamMind-Unlocking-Full-Frame-Rate-Streaming-Video-Dialogue-through-Event-Gated-Cognition" class="headerlink" title="StreamMind: Unlocking Full Frame Rate Streaming Video Dialogue through   Event-Gated Cognition"></a>StreamMind: Unlocking Full Frame Rate Streaming Video Dialogue through   Event-Gated Cognition</h2><p><strong>Authors:Xin Ding, Hao Wu, Yifan Yang, Shiqi Jiang, Donglin Bai, Zhibo Chen, Ting Cao</strong></p>
<p>With the rise of real-world human-AI interaction applications, such as AI assistants, the need for Streaming Video Dialogue is critical. To address this need, we introduce \sys, a video LLM framework that achieves ultra-FPS streaming video processing (100 fps on a single A100) and enables proactive, always-on responses in real time, without explicit user intervention.   To solve the key challenge of the contradiction between linear video streaming speed and quadratic transformer computation cost, we propose a novel perception-cognition interleaving paradigm named ‘’event-gated LLM invocation’’, in contrast to the existing per-time-step LLM invocation. By introducing a Cognition Gate network between the video encoder and the LLM, LLM is only invoked when relevant events occur. To realize the event feature extraction with constant cost, we propose Event-Preserving Feature Extractor (EPFE) based on state-space method, generating a single perception token for spatiotemporal features. These techniques enable the video LLM with full-FPS perception and real-time cognition response.   Experiments on Ego4D and SoccerNet streaming tasks, as well as standard offline benchmarks, demonstrate state-of-the-art performance in both model capability and real-time efficiency, paving the way for ultra-high-FPS applications, such as Game AI Copilot and interactive media. </p>
<blockquote>
<p>随着人工智能助手等现实世界人机交互应用的兴起，对流式视频对话的需求变得至关重要。为了解决这一需求，我们引入了\sys，这是一个视频LLM框架，实现了超FPS流式视频处理（单A100上可达100帧每秒），并能够在不明确的用户干预下实现实时主动响应。为了解决线性视频流速度与处理成本呈二次方的转换器计算之间的主要矛盾，我们提出了一种名为“事件门控LLM调用”的新型感知认知交错范式，这与现有的每时间步长LLM调用形成对比。通过在视频编码器和LLM之间引入认知门网络，只有在相关事件发生时才会调用LLM。为了实现恒定成本的事件特征提取，我们提出了基于状态空间方法的Event-Preserving Feature Extractor（EPFE），为时空特征生成单个感知令牌。这些技术使视频LLM具备全FPS感知和实时认知响应能力。在Ego4D和SoccerNet流媒体任务以及标准离线基准测试上的实验证明了该模型在能力和实时效率方面的先进性，为超高FPS应用（如游戏AI副驾驶和交互式媒体）铺平了道路。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.06220v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>随着人工智能助手等现实世界中的人机交互应用的兴起，流式视频对话的需求变得至关重要。为应对这一需求，我们推出了视频LLM框架——sys，它实现了超高帧率（FPS）的视频流处理（单个A100上可达100 FPS），并可在不显式用户干预的情况下实时主动响应。为解决视频流速度线性而转换器计算成本二次方之间的矛盾，我们提出了名为“事件门控LLM调用”的新型感知认知交替范式，区别于现有的按时间步长调用LLM的方法。通过引入认知门网络，只有在发生相关事件时才调用LLM。为实现恒定成本的事件特征提取，我们提出了基于状态空间方法的Event-Preserving Feature Extractor（EPFE），为时空特征生成单个感知令牌。这些技术使得视频LLM具有全FPS感知能力和实时认知响应能力。在Ego4D、SoccerNet流媒体任务以及标准离线基准测试上的实验证明了其在模型能力和实时效率方面的卓越性能，为超高FPS应用如游戏AI助手和交互式媒体铺平了道路。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>流式视频对话需求随着人工智能助手等现实世界中的人机交互应用的兴起而增加。</li>
<li>sys是一个视频LLM框架，能够实现超高帧率（FPS）的视频流处理，并支持实时主动响应。</li>
<li>引入了事件门控LLM调用的新型感知认知交替范式，优化了对LLM的调用方式。</li>
<li>提出了Event-Preserving Feature Extractor（EPFE），能够在恒定成本下实现事件特征提取。</li>
<li>技术使得视频LLM具有全FPS感知能力和实时认知响应能力。</li>
<li>实验在多个任务上证明了sys在模型能力和实时效率方面的卓越性能。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.06220">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pica.zhimg.com/v2-88685f4cdf7cbe326813713c366225fe.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-256aef52eb786d6f7eba53fc8197aab6.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-eeb115a5203f28e0dbc4b903ecc95cf9.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-d4365d3f35c533643161154d734be9aa.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-3fcbb9d2d7eeb9a2ea5b44ccce00a126.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b6a102c40fc07abe5e8f07d5023053f8.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-51b4063d3a52b916e7cbc63094b6274e.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-4c1fd060dfe8d17a63331c806ea89c54.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="Dialogue-Systems-for-Emotional-Support-via-Value-Reinforcement"><a href="#Dialogue-Systems-for-Emotional-Support-via-Value-Reinforcement" class="headerlink" title="Dialogue Systems for Emotional Support via Value Reinforcement"></a>Dialogue Systems for Emotional Support via Value Reinforcement</h2><p><strong>Authors:Juhee Kim, Chunghu Mok, Jisun Lee, Hyang Sook Kim, Yohan Jo</strong></p>
<p>Emotional support dialogue systems aim to reduce help-seekers’ distress and help them overcome challenges. While human values$\unicode{x2013}$core beliefs that shape an individual’s priorities$\unicode{x2013}$are increasingly emphasized in contemporary psychological therapy for their role in fostering internal transformation and long-term emotional well-being, their integration into emotional support systems remains underexplored. To bridge this gap, we present a value-driven method for training emotional support dialogue systems designed to reinforce positive values in seekers. Notably, our model identifies which values to reinforce at each turn and how to do so, by leveraging online support conversations from Reddit. We evaluate the method across support skills, seekers’ emotional intensity, and value reinforcement. Our method consistently outperforms various baselines, effectively exploring and eliciting values from seekers. Additionally, leveraging crowd knowledge from Reddit significantly enhances its effectiveness. Therapists highlighted its ability to validate seekers’ challenges and emphasize positive aspects of their situations$\unicode{x2013}$both crucial elements of value reinforcement. Our work, being the first to integrate value reinforcement into emotional support systems, demonstrates its promise and establishes a foundation for future research. </p>
<blockquote>
<p>情感支持对话系统的目标是减轻求助者的压力，帮助他们克服挑战。在当代心理治疗过程中，人的价值观——塑造个人优先事项的核心信念——越来越被强调其在促进内部转变和长期情感健康方面的作用。然而，将其融入情感支持系统仍被较少探索。为了弥补这一差距，我们提出了一种以价值观为导向的方法，用于训练旨在加强寻求者积极价值观的情感支持对话系统。值得注意的是，我们的模型能够识别每次对话中需要强化的价值观以及如何进行强化，通过利用Reddit上的在线支持对话。我们在支持技能、求助者的情感强度和价值观强化等方面对方法进行了评估。该方法始终优于各种基线方法，能够有效地探索和激发求助者的价值观。此外，利用Reddit上的群体知识显著增强了其有效性。心理学家强调其能够验证求助者的挑战并强调其处境的积极方面——这两个都是价值观强化的关键要素。我们的工作首次将价值观强化整合到情感支持系统中，展示了其潜力并为未来的研究奠定了基础。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.17182v2">PDF</a> 34 pages, 4 figures</p>
<p><strong>Summary</strong><br>情感支持对话系统旨在帮助求助者减轻压力并克服挑战。当代心理治疗越来越强调人的价值观在促进内心转变和长期情感健康方面的作用，但在情感支持系统中对其整合的研究仍然不足。为了弥补这一差距，我们提出了一种以价值为导向的方法，设计用于强化求助者正面价值观的情感支持对话系统训练模型。该模型能够识别在每次对话中需要强化的价值观，并知道如何操作。通过对支持技能、求助者情绪强度和价值观强化进行评估，我们的方法在各种基线之上表现出一致性优势，有效地探索和激发求助者的价值观。此外，利用Reddit上的群众知识显著提高了其有效性。治疗师强调了该方法验证求助者挑战和强调其处境积极面的能力——这两个都是价值观强化的关键要素。我们的工作是将价值观强化首次整合到情感支持系统中，展现了其潜力并为未来研究奠定了基础。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>情感支持对话系统的主要目标是减少求助者的困扰并助其克服挑战。</li>
<li>当代心理治疗强调人的价值观在促进长期情感健康方面的作用，但在情感支持系统中对其整合仍然不足。</li>
<li>提出了一种以价值为导向的方法训练情感支持对话系统，旨在强化求助者的正面价值观。</li>
<li>该方法能够识别每次对话中需要强化的价值观，并知道如何操作。</li>
<li>方法评估涵盖支持技能、求助者情绪强度和价值观强化方面，表现优于多种基线方法。</li>
<li>利用Reddit上的群众知识增强了方法的有效性。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.17182">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-4bdbc750319843b237bf561462c2c53c.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-eed557a2fdcdea88d49b5740f5621ad5.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-35ebe58d6a648d504a0baebd97177ddd.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-6af77170a15e93cdcdefa7fb230ed9ce.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-7f91470bca79bee36701e76ceabda10b.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="log-RRIM-Yield-Prediction-via-Local-to-global-Reaction-Representation-Learning-and-Interaction-Modeling"><a href="#log-RRIM-Yield-Prediction-via-Local-to-global-Reaction-Representation-Learning-and-Interaction-Modeling" class="headerlink" title="log-RRIM: Yield Prediction via Local-to-global Reaction Representation   Learning and Interaction Modeling"></a>log-RRIM: Yield Prediction via Local-to-global Reaction Representation   Learning and Interaction Modeling</h2><p><strong>Authors:Xiao Hu, Ziqi Chen, Bo Peng, Daniel Adu-Ampratwum, Xia Ning</strong></p>
<p>Accurate prediction of chemical reaction yields is crucial for optimizing organic synthesis, potentially reducing time and resources spent on experimentation. With the rise of artificial intelligence (AI), there is growing interest in leveraging AI-based methods to accelerate yield predictions without conducting in vitro experiments. We present log-RRIM, an innovative graph transformer-based framework designed for predicting chemical reaction yields. A key feature of log-RRIM is its integration of a cross-attention mechanism that focuses on the interplay between reagents and reaction centers. This design reflects a fundamental principle in chemical reactions: the crucial role of reagents in influencing bond-breaking and formation processes, which ultimately affect reaction yields. log-RRIM also implements a local-to-global reaction representation learning strategy. This approach initially captures detailed molecule-level information and then models and aggregates intermolecular interactions. Through this hierarchical process, log-RRIM effectively captures how different molecular fragments contribute to and influence the overall reaction yield, regardless of their size variations. log-RRIM shows superior performance in our experiments, especially for medium to high-yielding reactions, proving its reliability as a predictor. The framework’s sophisticated modeling of reactant-reagent interactions and precise capture of molecular fragment contributions make it a valuable tool for reaction planning and optimization in chemical synthesis. The data and codes of log-RRIM are accessible through <a target="_blank" rel="noopener" href="https://github.com/ninglab/Yield_log_RRIM">https://github.com/ninglab/Yield_log_RRIM</a>. </p>
<blockquote>
<p>精确预测化学反应产率对于优化有机合成至关重要，可能减少实验的时间和资源消耗。随着人工智能（AI）的兴起，人们越来越感兴趣利用AI方法来加速产率预测，而无需进行体外实验。我们提出了log-RRIM，这是一个基于图变压器的预测化学反应产率的新型框架。Log-RRIM的一个关键特征是融合了跨注意机制，专注于试剂与反应中心之间的相互作用。这一设计反映了化学反应中的基本原理：试剂在影响键断裂和形成过程中的关键作用，最终影响反应产率。Log-RRIM还实现了从局部到全局的反应表示学习策略。这种方法首先捕获分子级别的详细信息，然后建模和聚合分子间的相互作用。通过这一分层过程，Log-RRIM有效地捕获了不同分子片段如何贡献和影响总体反应产率，无论其大小变化如何。在我们的实验中，Log-RRIM表现出卓越的性能，特别是在中等至高产量反应中，证明了其作为预测器的可靠性。该框架对反应物-试剂交互的精细建模以及对分子片段贡献的精确捕获，使其成为化学合成中反应规划和优化的有价值工具。Log-RRIM的数据和代码可通过<a target="_blank" rel="noopener" href="https://github.com/ninglab/Yield_log_RRIM%E8%8E%B7%E5%8F%96%E3%80%82">https://github.com/ninglab/Yield_log_RRIM获取。</a></p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2411.03320v4">PDF</a> 45 pages, 8 figures</p>
<p><strong>Summary</strong><br>     利用人工智能预测化学反应收率对于优化有机合成至关重要。log-RRIM是一个基于图变换的预测框架，通过交叉注意机制关注试剂与反应中心的相互作用，实现化学反应收率的准确预测。它采用从分子级别到全局反应表示的学习策略，有效捕捉不同分子片段对反应收率的贡献和影响。log-RRIM在实验中表现出卓越性能，尤其是预测中等至高收率的反应，成为化学合成中反应规划和优化的重要工具。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>AI在预测化学反应收率方面的应用日益受到关注，有助于优化有机合成，减少实验时间和资源的消耗。</li>
<li>log-RRIM是一个基于图变换的预测框架，专为预测化学 反应收率设计。</li>
<li>log-RRIM通过交叉注意机制关注试剂与反应中心的互动，反映化学反应中的关键原则。</li>
<li>log-RRIM实施从分子级别到全局反应表示的学习策略，有效捕捉不同分子片段对反应收率的贡献。</li>
<li>log-RRIM在实验中表现出卓越性能，特别是在预测中等至高收率的反应方面。</li>
<li>log-RRIM的精细建模反应物-试剂相互作用和精确捕捉分子片段贡献使其成为化学合成中反应规划和优化的有价值工具。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2411.03320">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pica.zhimg.com/v2-d4a743c42dd48a50fda41ffd471d5051.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="A-Zero-Shot-Open-Vocabulary-Pipeline-for-Dialogue-Understanding"><a href="#A-Zero-Shot-Open-Vocabulary-Pipeline-for-Dialogue-Understanding" class="headerlink" title="A Zero-Shot Open-Vocabulary Pipeline for Dialogue Understanding"></a>A Zero-Shot Open-Vocabulary Pipeline for Dialogue Understanding</h2><p><strong>Authors:Abdulfattah Safa, Gözde Gül Şahin</strong></p>
<p>Dialogue State Tracking (DST) is crucial for understanding user needs and executing appropriate system actions in task-oriented dialogues. Majority of existing DST methods are designed to work within predefined ontologies and assume the availability of gold domain labels, struggling with adapting to new slots values. While Large Language Models (LLMs)-based systems show promising zero-shot DST performance, they either require extensive computational resources or they underperform existing fully-trained systems, limiting their practicality. To address these limitations, we propose a zero-shot, open-vocabulary system that integrates domain classification and DST in a single pipeline. Our approach includes reformulating DST as a question-answering task for less capable models and employing self-refining prompts for more adaptable ones. Our system does not rely on fixed slot values defined in the ontology allowing the system to adapt dynamically. We compare our approach with existing SOTA, and show that it provides up to 20% better Joint Goal Accuracy (JGA) over previous methods on datasets like Multi-WOZ 2.1, with up to 90% fewer requests to the LLM API. </p>
<blockquote>
<p>对话状态跟踪（DST）对于理解用户需求和在执行任务导向型对话中执行适当的系统操作至关重要。现有的大多数DST方法都是为在预定义的本体上工作而设计的，并假定有黄金领域标签可用，但在适应新槽值时遇到了困难。虽然基于大型语言模型（LLM）的系统显示出有前景的零样本DST性能，但它们要么需要大量的计算资源，要么在性能上不如现有的完全训练的系统，从而限制了它们的实用性。为了解决这些局限性，我们提出了一种零样本、开放词汇的系统，它将领域分类和DST集成在一个单一的管道中。我们的方法包括将DST重新表述为一个问答任务，以适应能力较差的模型，并为适应性较强的模型使用自我改进提示。我们的系统不依赖于本体中定义的固定槽值，允许系统动态适应。我们将我们的方法与现有的最佳技术进行了比较，并证明在Multi-WOZ 2.1等数据集上，我们的方法在联合目标准确率（JGA）上比以前的方法提高了高达20%，而且对LLM API的请求减少了高达90%。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2409.15861v3">PDF</a> Accepted to NAACL 2025</p>
<p><strong>Summary</strong></p>
<p>本文主要探讨了对话状态追踪（DST）在任务导向对话中的重要性，以及现有DST方法在新槽值适应方面的局限性。为了解决这个问题，提出了一种零启动、开放词汇的系统，该系统将领域分类和DST集成在一个单一的管道中。该方法将DST重新构建为对不太强大的模型的问答任务，并为更灵活的模型使用自我改进提示。系统能够适应动态变化，不需要依赖本体论中定义的固定槽值。在Multi-WOZ 2.1等数据集上，与现有先进技术相比，该方法联合目标准确率（JGA）提高了高达20%，对LLM API的请求减少了高达90%。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>对话状态追踪（DST）在任务导向对话中至关重要，涉及理解用户需求和执行适当系统操作。</li>
<li>现有DST方法大多依赖于预定义的本体论和黄金领域标签，难以适应新槽值。</li>
<li>大型语言模型（LLM）为基础的系统展现出零启动DST的潜力，但存在计算资源需求大或性能不足的问题。</li>
<li>提出的系统将领域分类和DST集成在一个管道中，实现零启动和开放词汇。</li>
<li>通过将DST重新构建为问答任务，为较弱模型提供策略，并为较灵活模型使用自我改进提示。</li>
<li>系统可动态适应，无需依赖本体论中的固定槽值。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2409.15861">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-294b319970e09f946c8c21732ece62e8.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-834e57677efa9be4bb631b4357786491.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-df961a3badd4e37160aa520cb6ab7b1e.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        文章作者:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        文章链接:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-03-12/Interactive/">https://kedreamix.github.io/Talk2Paper/Paper/2025-03-12/Interactive/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        版权声明:
                    </i>
                </span>
                <span class="reprint-info">
                    本博客所有文章除特別声明外，均采用
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    许可协议。转载请注明来源
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/Interactive/">
                                    <span class="chip bg-color">Interactive</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;上一篇</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-03-12/Talking%20Head%20Generation/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-1ddf09040f9bee11fa9d3d87dd11d184.jpg" class="responsive-img" alt="Talking Head Generation">
                        
                        <span class="card-title">Talking Head Generation</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Talking Head Generation 方向最新论文已更新，请持续关注 Update in 2025-03-12  Removing Averaging Personalized Lip-Sync Driven Characters Based on   Identity Adapter
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-03-12
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Talking-Head-Generation/" class="post-category">
                                    Talking Head Generation
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Talking-Head-Generation/">
                        <span class="chip bg-color">Talking Head Generation</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-03-12/TTS/">
                    <div class="card-image">
                        
                        <img src="https://pic1.zhimg.com/v2-3b30d3ad12a009fd1a97361cbc68898b.jpg" class="responsive-img" alt="TTS">
                        
                        <span class="card-title">TTS</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            TTS 方向最新论文已更新，请持续关注 Update in 2025-03-12  Clip-TTS Contrastive Text-content and Mel-spectrogram, A High-Quality   Text-to-Speech Method based on Contextual Semantic Understanding
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-03-12
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/TTS/" class="post-category">
                                    TTS
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/TTS/">
                        <span class="chip bg-color">TTS</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- 代码语言 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span
                        class="white-color">23901.5k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- 运行天数提醒. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // 区分是否有年份.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = '本站已运行 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                daysTip = '本站已運行 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = '本站已运行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = '本站已運行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="关注我的知乎: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">知</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- 白天和黑夜主题 -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // 只在桌面版网页启用特效
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- 雪花特效 -->
    

    <!-- 鼠标星星特效 -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--腾讯兔小巢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- 动态标签 -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Σ(っ °Д °;)っ诶，页面崩溃了嘛？", clearTimeout(st)) : (document.title = "φ(゜▽゜*)♪咦，又好了！", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
