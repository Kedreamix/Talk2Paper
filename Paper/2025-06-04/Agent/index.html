<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Agent">
    <meta name="description" content="Agent 方向最新论文已更新，请持续关注 Update in 2025-06-04  AutoChemSchematic AI A Closed-Loop, Physics-Aware Agentic Framework for   Auto-Generating Chemical Process and Instrumentation Diagrams">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>Agent | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loader页面消失采用渐隐的方式*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logo出现动画 */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//使用渐隐的方法淡出loading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//强制显示loading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">嘘~  正在从服务器偷取页面 . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>首页</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>标签</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>分类</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>归档</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="搜索" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="深色/浅色模式" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			首页
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			标签
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			分类
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			归档
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://picx.zhimg.com/v2-f8188d87da012f86325b12f57afd9ec1.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Agent</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/Agent/">
                                <span class="chip bg-color">Agent</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/Agent/" class="post-category">
                                Agent
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2025-06-04
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>更新日期:&nbsp;&nbsp;
                    2025-07-06
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp;
                    10.1k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp;
                    41 分
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>阅读次数:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>⚠️ 以下所有内容总结都来自于 大语言模型的能力，如有错误，仅供参考，谨慎使用<br>🔴 请注意：千万不要用于严肃的学术场景，只能用于论文阅读前的初筛！<br>💗 如果您觉得我们的项目对您有帮助 <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ，还请您给我们一些鼓励！⭐️ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFace免费体验</a></p>
</blockquote>
<h1 id="2025-06-04-更新"><a href="#2025-06-04-更新" class="headerlink" title="2025-06-04 更新"></a>2025-06-04 更新</h1><h2 id="AutoChemSchematic-AI-A-Closed-Loop-Physics-Aware-Agentic-Framework-for-Auto-Generating-Chemical-Process-and-Instrumentation-Diagrams"><a href="#AutoChemSchematic-AI-A-Closed-Loop-Physics-Aware-Agentic-Framework-for-Auto-Generating-Chemical-Process-and-Instrumentation-Diagrams" class="headerlink" title="AutoChemSchematic AI: A Closed-Loop, Physics-Aware Agentic Framework for   Auto-Generating Chemical Process and Instrumentation Diagrams"></a>AutoChemSchematic AI: A Closed-Loop, Physics-Aware Agentic Framework for   Auto-Generating Chemical Process and Instrumentation Diagrams</h2><p><strong>Authors:Sakhinana Sagar Srinivas, Shivam Gupta, Venkataramana Runkana</strong></p>
<p>Recent advancements in generative AI have accelerated the discovery of novel chemicals and materials; however, transitioning these discoveries to industrial-scale production remains a critical bottleneck, as it requires the development of entirely new chemical manufacturing processes. Current AI methods cannot auto-generate PFDs or PIDs, despite their critical role in scaling chemical processes, while adhering to engineering constraints. We present a closed loop, physics aware framework for the automated generation of industrially viable PFDs and PIDs. The framework integrates domain specialized small scale language models (SLMs) (trained for chemical process QA tasks) with first principles simulation, leveraging three key components: (1) a hierarchical knowledge graph of process flow and instrumentation descriptions for 1,020+ chemicals, (2) a multi-stage training pipeline that fine tunes domain specialized SLMs on synthetic datasets via Supervised Fine-Tuning (SFT), Direct Preference Optimization (DPO), and Retrieval-Augmented Instruction Tuning (RAIT), and (3) DWSIM based simulator in the loop validation to ensure feasibility. To improve both runtime efficiency and model compactness, the framework incorporates advanced inference time optimizations including FlashAttention, Lookahead Decoding, PagedAttention with KV-cache quantization, and Test Time Inference Scaling and independently applies structural pruning techniques (width and depth) guided by importance heuristics to reduce model size with minimal accuracy loss. Experiments demonstrate that the framework generates simulator-validated process descriptions with high fidelity, outperforms baseline methods in correctness, and generalizes to unseen chemicals. By bridging AI-driven design with industrial-scale feasibility, this work significantly reduces R&amp;D timelines from lab discovery to plant deployment. </p>
<blockquote>
<p>近期生成式人工智能的进步加速了新型化学物质和材料的发现；然而，将这些发现转化为工业规模的生产仍然是一个关键的瓶颈，因为这需要开发全新的化学制造工艺。尽管人工智能方法在规模化学过程中发挥着至关重要的作用，但目前的AI方法无法自动生成工艺流程图（PFDs）或工艺流程说明（PIDs），同时还需要遵守工程约束。我们提出了一种用于自动生成具有工业可行性的工艺流程图（PFDs）和工艺流程说明（PIDs）的闭环、物理感知框架。该框架结合了领域专业化的小规模语言模型（SLM）（针对化学过程问答任务进行训练）与基于第一性原则的模拟，利用三个关键组件：（1）包含1020+化学物质的工艺流程和仪器描述分层知识图谱；（2）多阶段训练管道，通过监督微调（SFT）、直接偏好优化（DPO）和检索增强指令调整（RAIT）在合成数据集上微调领域专业化的SLM；（3）基于DWSIM的模拟循环验证，以确保可行性。为了提高运行效率和模型紧凑性，该框架采用了先进的推理时间优化技术，包括FlashAttention、前瞻解码、带KV缓存量化的PagedAttention以及测试时间推理缩放，并独立应用结构修剪技术（宽度和深度），以重要性启发式为指导，以尽量减少精度损失来减小模型大小。实验表明，该框架生成了模拟验证的高保真度工艺流程描述，在正确性方面优于基准方法，并能推广到未见过的化学物质。这项工作通过桥梁AI驱动的设计与工业规模可行性之间的联系，显著缩短了从实验室发现到工厂部署的研发时间。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.24584v2">PDF</a> </p>
<p><strong>Summary</strong><br>     最新进展的生成式AI已加速新型化学物质与材料的发现，但将其转化为工业规模生产仍是瓶颈，需开发全新化学制造工艺。针对此问题，我们提出了一个闭环、物理感知的框架，用于自动生成符合工业要求的PFDs和PIDs。该框架结合了针对化学工艺问答任务训练的领域专用小型语言模型、基于第一原理的仿真，并借助三个关键组件实现：包含超过一千种化学品的工艺流和仪器描述的分层知识图谱、多阶段训练管道以及DWSIM仿真验证确保可行性。为提高运行效率和模型紧凑性，该框架采用FlashAttention等先进推理时间优化技术，并独立应用结构剪枝技术减小模型大小同时保持准确性损失最小。实验证明，该框架生成的仿真验证工艺描述具有高保真度，在正确性方面优于基准方法，并能泛化至未见化学品。该工作通过桥接AI驱动设计与工业规模可行性，显著缩短从实验室发现到工厂部署的研发周期。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>生成式AI在化学发现和材料领域取得进展，但工业规模生产的转化仍是关键挑战。</li>
<li>需要开发新的化学制造工艺来实现工业应用。</li>
<li>提出的框架能自动生成符合工业要求的PFDs和PIDs，整合了小型语言模型、第一原理仿真和知识图谱。</li>
<li>框架采用多阶段训练管道和仿真验证确保工艺描述的准确性和可行性。</li>
<li>通过采用推理时间优化技术和结构剪枝技术，提高了框架的运行效率和模型紧凑性。</li>
<li>实验证明该框架生成的工艺描述具有高保真度，优于基准方法。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.24584">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-238b0504040d6251fc4793018f33f2e3.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-8124b1329bf708d3356c5d77642bf90d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e3187f64448014e03deaf4a610f26608.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="Can-Compressed-LLMs-Truly-Act-An-Empirical-Evaluation-of-Agentic-Capabilities-in-LLM-Compression"><a href="#Can-Compressed-LLMs-Truly-Act-An-Empirical-Evaluation-of-Agentic-Capabilities-in-LLM-Compression" class="headerlink" title="Can Compressed LLMs Truly Act? An Empirical Evaluation of Agentic   Capabilities in LLM Compression"></a>Can Compressed LLMs Truly Act? An Empirical Evaluation of Agentic   Capabilities in LLM Compression</h2><p><strong>Authors:Peijie Dong, Zhenheng Tang, Xiang Liu, Lujun Li, Xiaowen Chu, Bo Li</strong></p>
<p>Post-training compression reduces the computational and memory costs of large language models (LLMs), enabling resource-efficient deployment. However, existing compression benchmarks only focus on language modeling (e.g., perplexity) and natural language understanding tasks (e.g., GLUE accuracy), ignoring the agentic capabilities - workflow, tool use&#x2F;function call, long-context understanding and real-world application. We introduce the Agent Compression Benchmark (ACBench), the first comprehensive benchmark for evaluating how compression impacts LLMs’ agentic abilities. ACBench spans (1) 12 tasks across 4 capabilities (e.g., WorfBench for workflow generation, Needle-in-Haystack for long-context retrieval), (2) quantization (GPTQ, AWQ) and pruning (Wanda, SparseGPT), and (3) 15 models, including small (Gemma-2B), standard (Qwen2.5 7B-32B), and distilled reasoning LLMs (DeepSeek-R1-Distill). Our experiments reveal compression tradeoffs: 4-bit quantization preserves workflow generation and tool use (1%-3% drop) but degrades real-world application accuracy by 10%-15%. We introduce ERank, Top-k Ranking Correlation and Energy to systematize analysis. ACBench provides actionable insights for optimizing LLM compression in agentic scenarios. The code can be found in <a target="_blank" rel="noopener" href="https://github.com/pprp/ACBench">https://github.com/pprp/ACBench</a>. </p>
<blockquote>
<p>训练后压缩技术可以降低大型语言模型（LLM）的计算和内存成本，从而实现资源高效部署。然而，现有的压缩基准测试只关注语言建模（例如困惑度）和自然语言理解任务（例如GLUE准确性），忽略了代理能力——工作流程、工具使用&#x2F;函数调用、长上下文理解和实际应用。我们引入了Agent Compression Benchmark（ACBench），这是第一个全面评估压缩对LLM代理能力影响的基准测试。ACBench包括（1）4种能力下的12项任务（例如，WorfBench用于生成工作流程，Needle-in-Haystack用于长上下文检索），（2）量化（GPTQ，AWQ）和修剪（Wanda，SparseGPT），以及（3）包括小型（Gemma-2B）、标准（Qwen2.5 7B-32B）和蒸馏推理LLM（DeepSeek-R1-Distill）在内的15个模型。我们的实验揭示了压缩的权衡：4位量化保留了工作流程生成和工具使用（下降1%-3%），但降低了实际应用准确性达10%-15%。我们引入了ERank、Top-k排名相关性指标和能量来进行系统分析。ACBench为优化LLM在代理场景中的压缩提供了可操作的见解。代码可在<a target="_blank" rel="noopener" href="https://github.com/pprp/ACBench%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/pprp/ACBench找到。</a></p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.19433v2">PDF</a> Accepted by ICML2025 as Poster</p>
<p><strong>Summary</strong></p>
<p>本文介绍了针对大型语言模型（LLM）的压缩技术，重点强调了现有压缩评估标准在评估模型代理能力方面的不足。为此，作者引入了Agent Compression Benchmark（ACBench），这是一个全面评估压缩对LLM代理能力影响的基准测试。实验结果显示，量化与剪枝技术在不同任务中存在权衡。ACBench为优化LLM在代理场景中的压缩提供了重要见解。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>现有压缩基准测试主要关注语言建模和自然语言理解任务，忽略了大型语言模型的代理能力，如工作流程、工具使用&#x2F;函数调用、长上下文理解和实际应用。</li>
<li>引入Agent Compression Benchmark（ACBench），首次全面评估压缩对LLM代理能力的影响。</li>
<li>ACBench包含12个任务，跨越4种能力，包括工作流程生成、长上下文检索等。</li>
<li>量化（GPTQ，AWQ）和剪枝（Wanda，SparseGPT）技术在LLM压缩中的应用被探讨。</li>
<li>实验显示，4位量化可以较好地保留工作流程生成和工具使用能力，但可能降低实际应用准确性。</li>
<li>引入ERank、Top-k排名关联度和能量等指标，以系统化分析压缩效果。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.19433">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-bdc52bb7ee30f8ae05777156c4de65a7.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-1d7aae20cbdc938ac81622397ad8aab6.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-29b10b732e4ec79bef671b67edbe6976.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-857803399878e346ac4a5718f4838562.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-20ff3eeb772513d18a039161c67567a6.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-923ce3ba45b98a6b963d2aa27cb6d5e8.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="Which-Agent-Causes-Task-Failures-and-When-On-Automated-Failure-Attribution-of-LLM-Multi-Agent-Systems"><a href="#Which-Agent-Causes-Task-Failures-and-When-On-Automated-Failure-Attribution-of-LLM-Multi-Agent-Systems" class="headerlink" title="Which Agent Causes Task Failures and When? On Automated Failure   Attribution of LLM Multi-Agent Systems"></a>Which Agent Causes Task Failures and When? On Automated Failure   Attribution of LLM Multi-Agent Systems</h2><p><strong>Authors:Shaokun Zhang, Ming Yin, Jieyu Zhang, Jiale Liu, Zhiguang Han, Jingyang Zhang, Beibin Li, Chi Wang, Huazheng Wang, Yiran Chen, Qingyun Wu</strong></p>
<p>Failure attribution in LLM multi-agent systems-identifying the agent and step responsible for task failures-provides crucial clues for systems debugging but remains underexplored and labor-intensive. In this paper, we propose and formulate a new research area: automated failure attribution for LLM multi-agent systems. To support this initiative, we introduce the Who&amp;When dataset, comprising extensive failure logs from 127 LLM multi-agent systems with fine-grained annotations linking failures to specific agents and decisive error steps. Using the Who&amp;When, we develop and evaluate three automated failure attribution methods, summarizing their corresponding pros and cons. The best method achieves 53.5% accuracy in identifying failure-responsible agents but only 14.2% in pinpointing failure steps, with some methods performing below random. Even SOTA reasoning models, such as OpenAI o1 and DeepSeek R1, fail to achieve practical usability. These results highlight the task’s complexity and the need for further research in this area. Code and dataset are available at <a target="_blank" rel="noopener" href="https://github.com/mingyin1/Agents_Failure_Attribution">https://github.com/mingyin1/Agents_Failure_Attribution</a> </p>
<blockquote>
<p>在大规模语言模型（LLM）多智能体系统中的故障归属问题，即确定导致任务失败的智能体和步骤，为系统调试提供了关键线索。然而，这个问题尚未得到充分探索，并且需要大量人工操作。在本文中，我们提出并形成了一个新的研究领域：自动化的大规模语言模型多智能体系统的故障归属。为了支持这项工作，我们引入了Who&amp;When数据集，该数据集包含来自127个LLM多智能体系统的详尽失败日志，其中包括精细的注释，能够将失败与特定的智能体和关键的错误步骤相关联。使用Who&amp;When数据集，我们开发并评估了三种自动化的故障归属方法，并总结了它们各自的优缺点。其中最好的方法在确定负责失败的智能体方面达到了53.5%的准确率，但在确定失败步骤方面仅达到14.2%，部分方法的性能甚至低于随机水平。即使是如OpenAI o1和DeepSeek R1等最新推理模型也无法实现实际可用性。这些结果突出了该任务的复杂性，并凸显了在这个领域进行进一步研究的必要性。相关代码和数据集可通过<a target="_blank" rel="noopener" href="https://github.com/mingyin1/Agents_Failure_Attribution%E8%AE%BF%E9%97%AE%E3%80%82">https://github.com/mingyin1/Agents_Failure_Attribution访问。</a></p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.00212v3">PDF</a> camera-ready</p>
<p><strong>Summary</strong></p>
<p>大型语言模型（LLM）多智能体系统中的故障归属问题对于系统调试至关重要，但现有研究不足且需要大量人工。本文提出并定义了一个新的研究领域：LLM多智能体系统的自动化故障归属。为支持此领域研究，引入了Who&amp;When数据集，包含来自127个LLM多智能体系统的详细失败日志，并进行了精细的标注，将失败与特定智能体和关键错误步骤相关联。基于Who&amp;When数据集，本文开发并评估了三种自动化故障归属方法，总结了其优缺点。最佳方法的准确率为智能体责任人识别为53.5%，但关键错误步骤的识别率仅为14.2%，某些方法的表现甚至低于随机水平。即使是最先进的推理模型，如OpenAI o1和DeepSeek R1，也无法实现实际可用性。这凸显了任务的复杂性，并强调了在这一领域进行进一步研究的必要性。数据集和代码已公开分享在GitHub上。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>大型语言模型（LLM）多智能体系统的故障归属对于系统调试至关重要。</li>
<li>现有研究在LLM多智能体系统的故障归属方面不足，且该任务需要大量人工。</li>
<li>论文提出并定义了一个新的研究领域：LLM多智能体系统的自动化故障归属。</li>
<li>引入了Who&amp;When数据集，包含详细失败日志和精细标注，以支持该领域的研究。</li>
<li>基于Who&amp;When数据集，开发了三种自动化故障归属方法，但表现并不理想，最佳方法的智能体责任人识别准确率为53.5%，关键错误步骤识别率仅为14.2%。</li>
<li>先进的推理模型如OpenAI o1和DeepSeek R1在自动化故障归属任务上的表现不佳。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.00212">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-f348b01e07d182e3396fd2cfcad15dae.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-30f5b857aa609ee4549998549002027b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f8188d87da012f86325b12f57afd9ec1.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d5debe9dd7cfc5de666a7228fab3bcf8.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="SynWorld-Virtual-Scenario-Synthesis-for-Agentic-Action-Knowledge-Refinement"><a href="#SynWorld-Virtual-Scenario-Synthesis-for-Agentic-Action-Knowledge-Refinement" class="headerlink" title="SynWorld: Virtual Scenario Synthesis for Agentic Action Knowledge   Refinement"></a>SynWorld: Virtual Scenario Synthesis for Agentic Action Knowledge   Refinement</h2><p><strong>Authors:Runnan Fang, Xiaobin Wang, Yuan Liang, Shuofei Qiao, Jialong Wu, Zekun Xi, Ningyu Zhang, Yong Jiang, Pengjun Xie, Fei Huang, Huajun Chen</strong></p>
<p>In the interaction between agents and their environments, agents expand their capabilities by planning and executing actions. However, LLM-based agents face substantial challenges when deployed in novel environments or required to navigate unconventional action spaces. To empower agents to autonomously explore environments, optimize workflows, and enhance their understanding of actions, we propose SynWorld, a framework that allows agents to synthesize possible scenarios with multi-step action invocation within the action space and perform Monte Carlo Tree Search (MCTS) exploration to effectively refine their action knowledge in the current environment. Our experiments demonstrate that SynWorld is an effective and general approach to learning action knowledge in new environments. Code is available at <a target="_blank" rel="noopener" href="https://github.com/zjunlp/SynWorld">https://github.com/zjunlp/SynWorld</a>. </p>
<blockquote>
<p>在智能体与其环境之间的交互中，智能体通过规划和执行行动来扩展其能力。然而，当部署在新型环境中或需要执行非常规动作时，基于大型语言模型的智能体会面临重大挑战。为了增强智能体自主探索环境的能力，优化工作流程，并增强其对动作的理解，我们提出了SynWorld框架。该框架允许智能体在动作空间内执行多步骤动作调用，合成可能场景，并执行蒙特卡洛树搜索（MCTS）探索，以有效地在当前环境中优化其动作知识。我们的实验表明，SynWorld是一种在新环境中学习动作知识的有效且通用的方法。代码可在<a target="_blank" rel="noopener" href="https://github.com/zjunlp/SynWorld%E8%8E%B7%E5%8F%96%E3%80%82">https://github.com/zjunlp/SynWorld获取。</a></p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.03561v3">PDF</a> ACL 2025</p>
<p><strong>总结</strong></p>
<p>基于大型语言模型的智能代理在面临新的环境或者需要在未知行动空间中操作时面临着重大挑战。为解决这些问题，本文提出SynWorld框架，通过该框架代理能自主在环境中进行探索、优化工作流程和对行动的理解。它允许代理合成多步骤行动的场景进行模拟分析并执行蒙特卡洛树搜索以改进代理对现行环境的理解。实验证明SynWorld是一种有效且通用的学习新环境行动知识的方法。代码可在<a target="_blank" rel="noopener" href="https://github.com/zjunlp/SynWorld">链接</a>找到。</p>
<p><strong>关键见解</strong></p>
<ol>
<li>智能代理在面临新环境或未知行动空间时面临挑战。</li>
<li>SynWorld框架允许代理自主探索环境，优化工作流程并增强对行动的理解。</li>
<li>SynWorld通过合成多步骤行动场景进行模拟分析。</li>
<li>通过蒙特卡洛树搜索，SynWorld能有效改进代理对当前环境的理解。</li>
<li>SynWorld框架具有通用性，适用于多种新环境的行动知识学习。</li>
<li>实验证明SynWorld方法的有效性。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.03561">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-245cff783d21761fd5e148eccb1a4900.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-5b06fca3d8fa227acc07e5128e2533f9.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-0daf6717e1a34d1f73ddb49930f675d8.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-0ba058e549f3f1e0d1bf4d9dee7766ff.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="Understanding-Inequality-of-LLM-Fact-Checking-over-Geographic-Regions-with-Agent-and-Retrieval-models"><a href="#Understanding-Inequality-of-LLM-Fact-Checking-over-Geographic-Regions-with-Agent-and-Retrieval-models" class="headerlink" title="Understanding Inequality of LLM Fact-Checking over Geographic Regions   with Agent and Retrieval models"></a>Understanding Inequality of LLM Fact-Checking over Geographic Regions   with Agent and Retrieval models</h2><p><strong>Authors:Bruno Coelho, Shujaat Mirza, Yuyuan Cui, Christina Pöpper, Damon McCoy</strong></p>
<p>Fact-checking is a potentially useful application of Large Language Models (LLMs) to combat the growing dissemination of disinformation. However, the performance of LLMs varies across geographic regions. In this paper, we evaluate the factual accuracy of open and private models across a diverse set of regions and scenarios.   Using a dataset containing 600 fact-checked statements balanced across six global regions we examine three experimental setups of fact-checking a statement: (1) when just the statement is available, (2) when an LLM-based agent with Wikipedia access is utilized, and (3) as a best case scenario when a Retrieval-Augmented Generation (RAG) system provided with the official fact check is employed. Our findings reveal that regardless of the scenario and LLM used, including GPT-4, Claude Sonnet, and LLaMA, statements from the Global North perform substantially better than those from the Global South. Furthermore, this gap is broadened for the more realistic case of a Wikipedia agent-based system, highlighting that overly general knowledge bases have a limited ability to address region-specific nuances. These results underscore the urgent need for better dataset balancing and robust retrieval strategies to enhance LLM fact-checking capabilities, particularly in geographically diverse contexts. </p>
<blockquote>
<p>事实核查是大型语言模型（LLM）一个潜在有用的应用，有助于对抗日益蔓延的虚假信息的传播。然而，LLM的性能在不同地理区域有所不同。在本文中，我们评估了不同区域和场景下开源模型与私有模型的事实准确性。通过使用包含600个事实核查语句的平衡数据集，这些语句来自全球六个不同区域，我们研究了三种事实核查语句的实验设置：（1）仅提供语句时的情况，（2）利用基于LLM的代理访问维基百科的情况，以及（3）在最佳情况下，当使用提供官方事实核查的检索增强生成（RAG）系统时的情况。我们的研究发现，无论场景和使用的LLM（包括GPT-4、Claude Sonnet和LLaMA）如何，来自全球北方的陈述在事实核查方面的表现都明显优于来自全球南方的陈述。此外，在更现实的基于维基百科代理系统的案例中，这一差距进一步拉大，这表明过于通用的知识库在解决地区特定细微差别方面的能力有限。这些结果强调了在地理多样性背景下，为了增强LLM的事实核查能力，迫切需要更好的数据集平衡和稳健的检索策略。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.22877v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>大型语言模型（LLM）在事实核查方面具有潜在应用价值，有助于应对日益严重的虚假信息传播问题。然而，LLM在不同地理区域的性能表现存在差异。本文评估了开放和私有模型在不同区域和场景下的事实核查准确性。通过包含600个经过事实核查的语句的数据集，我们研究了三种事实核查方案。研究发现，无论采用哪种方案和LLM（包括GPT-4、Claude Sonnet和LLaMA），来自全球北方的陈述表现均优于全球南方。这一差距在基于Wikipedia的系统中更为明显，表明过于通用的知识库在解决地区特定细微差别方面能力有限。结果突显了更好地平衡数据集和采用稳健检索策略以改进LLM事实核查能力的紧迫需求，特别是在地理多元化背景下。</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>大型语言模型（LLM）可用于事实核查，以应对虚假信息的传播。</li>
<li>LLM在不同地理区域的事实核查性能存在差异。</li>
<li>研究评估了多种事实核查方案，包括仅使用陈述、使用基于LLM的Wikipedia访问代理以及使用最佳情景下的检索增强生成（RAG）系统。</li>
<li>全球北方的陈述在事实核查中表现优于全球南方。</li>
<li>基于Wikipedia的代理系统进一步扩大了这一差距，表明需要更细粒度的地区知识库。</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.22877">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-4f0d6bae18ebf57cb1666a65ebb6835e.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="RAG-Gym-Systematic-Optimization-of-Language-Agents-for-Retrieval-Augmented-Generation"><a href="#RAG-Gym-Systematic-Optimization-of-Language-Agents-for-Retrieval-Augmented-Generation" class="headerlink" title="RAG-Gym: Systematic Optimization of Language Agents for   Retrieval-Augmented Generation"></a>RAG-Gym: Systematic Optimization of Language Agents for   Retrieval-Augmented Generation</h2><p><strong>Authors:Guangzhi Xiong, Qiao Jin, Xiao Wang, Yin Fang, Haolin Liu, Yifan Yang, Fangyuan Chen, Zhixing Song, Dengyu Wang, Minjia Zhang, Zhiyong Lu, Aidong Zhang</strong></p>
<p>Retrieval-augmented generation (RAG) has shown great promise for knowledge-intensive tasks and recently advanced with agentic RAG, where language agents engage in multi-round interactions with external knowledge sources for adaptive information retrieval. However, existing agentic RAG methods often depend on ad-hoc prompt engineering and lack a unified optimization framework. We introduce RAG-Gym, a comprehensive platform that systematically explores three optimization dimensions: (1) prompt engineering, (2) actor tuning, and (3) critic training. For prompt engineering, we propose Re$^2$Search, a novel agent incorporating reasoning reflection that significantly outperforms standard prompts. In actor tuning, we evaluate three popular post-training algorithms with fine-grained process supervision and identify direct preference optimization as the most effective. We further demonstrate that a trained critic can enhance inference by selecting higher-quality intermediate reasoning steps. Together, these findings lead to the optimized Re$^2$Search++ agent, which surpasses most recent methods like Search-R1 by a relative increase of 3.2% to 11.6% in average F1. Finally, we examine the impact of different reward sources and analyze scaling properties in training and inference, offering practical insights for agentic RAG optimization. The project homepage is available at <a target="_blank" rel="noopener" href="https://rag-gym.github.io/">https://rag-gym.github.io</a>. </p>
<blockquote>
<p>检索增强生成（RAG）在知识密集型任务中显示出巨大潜力，最近通过加入代理RAG进一步发展，语言代理与外部知识源进行多轮交互以进行自适应信息检索。然而，现有的代理RAG方法往往依赖于临时提示工程，缺乏统一的优化框架。我们引入了RAG-Gym综合平台，该平台系统地探索了三个优化维度：（1）提示工程、（2）演员调整、（3）评论家训练。在提示工程中，我们提出了Re$^2$Search这一新型代理，它结合了推理反射，显著优于标准提示。在演员调整方面，我们评估了三种流行的后训练算法，通过精细的过程监督，确定了直接偏好优化最为有效。我们进一步证明，经过训练的评论家可以通过选择更高质量的中间推理步骤来提高推理能力。这些成果共同推动了优化的Re$^2$Search++代理的发展，该代理超越了最新的方法，如Search-R1，在平均F1分数上相对提高了3.2%至11.6%。最后，我们研究了不同奖励源的影响，分析了训练和推理中的扩展属性，为代理RAG优化提供了实际见解。项目主页可在<a target="_blank" rel="noopener" href="https://rag-gym.github.io访问./">https://rag-gym.github.io访问。</a></p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.13957v2">PDF</a> Homepage: <a target="_blank" rel="noopener" href="https://rag-gym.github.io/">https://rag-gym.github.io</a>; Code:   <a target="_blank" rel="noopener" href="https://github.com/RAG-Gym/RAG-Gym">https://github.com/RAG-Gym/RAG-Gym</a></p>
<p><strong>Summary</strong></p>
<p>本文介绍了基于检索增强的生成模型（RAG）的优化平台RAG-Gym。该平台系统地探索了三个优化维度：提示工程、演员调整和评论家训练。引入了一种新的带有推理反射的搜索代理Re$^2$Search，并评价了三种流行的后训练算法。最终通过优化得到的Re$^2$Search++代理，在平均F1分数上超过了最近的方法，如Search-R1。同时探讨了不同奖励源的影响和训练推理的可扩展性。</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>RAG-Gym是一个用于优化基于检索增强的生成模型（RAG）的综合平台。</li>
<li>平台探索了三个优化维度：提示工程、演员调整和评论家训练。</li>
<li>引入了一种新的搜索代理Re$^2$Search，结合了推理反射技术，表现优于标准提示。</li>
<li>评估了三种后训练算法，发现直接偏好优化最为有效。</li>
<li>训练有素的评论家能够提升推理质量，选择更高质量的中间推理步骤。</li>
<li>优化后的Re$^2$Search++代理在平均F1分数上表现优异，超过最近的方法如Search-R1。</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.13957">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-f32a6da3b905aaf82a5d842a0508cd21.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-40eeaa01c9430b2f48fad4371e673015.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ff97d5d9899bc6a379233eeef87c822f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-47e74a7919f2018b72725075bbf75910.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="Principal-Agent-Bandit-Games-with-Self-Interested-and-Exploratory-Learning-Agents"><a href="#Principal-Agent-Bandit-Games-with-Self-Interested-and-Exploratory-Learning-Agents" class="headerlink" title="Principal-Agent Bandit Games with Self-Interested and Exploratory   Learning Agents"></a>Principal-Agent Bandit Games with Self-Interested and Exploratory   Learning Agents</h2><p><strong>Authors:Junyan Liu, Lillian J. Ratliff</strong></p>
<p>We study the repeated principal-agent bandit game, where the principal indirectly interacts with the unknown environment by proposing incentives for the agent to play arms. Most existing work assumes the agent has full knowledge of the reward means and always behaves greedily, but in many online marketplaces, the agent needs to learn the unknown environment and sometimes explore. Motivated by such settings, we model a self-interested learning agent with exploration behaviors who iteratively updates reward estimates and either selects an arm that maximizes the estimated reward plus incentive or explores arbitrarily with a certain probability. As a warm-up, we first consider a self-interested learning agent without exploration. We propose algorithms for both i.i.d. and linear reward settings with bandit feedback in a finite horizon $T$, achieving regret bounds of $\widetilde{O}(\sqrt{T})$ and $\widetilde{O}( T^{2&#x2F;3} )$, respectively. Specifically, these algorithms are established upon a novel elimination framework coupled with newly-developed search algorithms which accommodate the uncertainty arising from the learning behavior of the agent. We then extend the framework to handle the exploratory learning agent and develop an algorithm to achieve a $\widetilde{O}(T^{2&#x2F;3})$ regret bound in i.i.d. reward setup by enhancing the robustness of our elimination framework to the potential agent exploration. Finally, when reducing our agent behaviors to the one studied in (Dogan et al., 2023a), we propose an algorithm based on our robust framework, which achieves a $\widetilde{O}(\sqrt{T})$ regret bound, significantly improving upon their $\widetilde{O}(T^{11&#x2F;12})$ bound. </p>
<blockquote>
<p>我们研究了重复的主-代理强盗游戏，其中主体通过为代理提出激励来间接地与未知环境进行交互以选择行动。大多数现有工作假设代理对奖励手段有充分了解并始终表现出贪婪行为，但在许多在线市场中，代理需要了解未知环境并有时进行探索。受这些设置的启发，我们构建了一个具有探索行为的自利学习代理模型，该代理会不断迭代更新奖励估计，并会选择最大化估算奖励与激励之和的行动，或者以一定概率进行任意探索。首先，作为热身，我们考虑一个没有探索行为的自利学习代理。我们为独立同分布和线性奖励设置提出了算法，在有限的$T$时间范围内提供强盗反馈，实现了$\widetilde{O}(\sqrt{T})$和$\widetilde{O}(T^{2&#x2F;3})$的遗憾界限，分别对应。具体来说，这些算法是基于一个新型的消除框架构建的，该框架结合了新开发的搜索算法，以适应由代理学习行为所产生的不确定性。然后，我们扩展了框架来处理探索性学习代理，并开发了一种算法，通过在独立同分布奖励设置中增强我们消除框架的稳健性，以实现$\widetilde{O}(T^{2&#x2F;3})$的遗憾界限，应对代理可能的探索行为。最后，当我们将代理行为简化为（Dogan等人，2023a）所研究的行为时，我们基于稳健的框架提出了一个算法，实现了$\widetilde{O}(\sqrt{T})$的遗憾界限，显著改善了他们的$\widetilde{O}(T^{11&#x2F;12})$界限。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.16318v2">PDF</a> 48 pages, ICML 2025</p>
<p><strong>Summary</strong><br>     研究了一种基于委托代理的重复博弈问题，其中委托人通过为代理人提供激励来间接与环境互动。现有研究假设代理人完全了解奖励均值并总是表现出贪婪行为，但在在线市场等环境中，代理人需要学习未知环境并探索。基于此背景，研究了一个具有探索行为的自利学习代理人模型，该代理人会不断更新奖励估计，并基于最大化估计奖励与激励或按一定概率探索来选择行动。文章首先研究了无探索行为的自利学习代理人模型，提出了针对独立同分布和线性奖励设置的算法，实现了$\sqrt{T}$和$T^{2&#x2F;3}$的遗憾界。然后扩展了模型来处理探索性学习的代理人，并开发出一种新的算法达到更小的遗憾界。最后通过改进前人研究的算法进一步提升了其性能。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>研究了一种基于委托代理的重复博弈问题，其中委托人通过激励代理人来间接与环境互动。</li>
<li>考虑到在线市场等环境中的现实情况，提出了一种具有探索行为的自利学习代理人的模型。</li>
<li>在无探索行为的假设下，针对独立同分布和线性奖励设置提出了算法，并给出了相应的遗憾界。</li>
<li>扩展了模型来处理探索性学习的代理人，针对独立同分布奖励设置开发了一种新的算法。</li>
<li>通过增强模型的稳健性来处理代理人的探索行为。</li>
<li>在简化代理人行为后，提出了一种改进的算法，实现了更小的遗憾界，相较于前人研究有显著改进。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.16318">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-cc6a077756885c180e270ded0ce674b4.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-78ba8c93b4fdf84f9709889888ca3586.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="Foundations-and-Recent-Trends-in-Multimodal-Mobile-Agents-A-Survey"><a href="#Foundations-and-Recent-Trends-in-Multimodal-Mobile-Agents-A-Survey" class="headerlink" title="Foundations and Recent Trends in Multimodal Mobile Agents: A Survey"></a>Foundations and Recent Trends in Multimodal Mobile Agents: A Survey</h2><p><strong>Authors:Biao Wu, Yanda Li, Yunchao Wei, Meng Fang, Ling Chen</strong></p>
<p>Mobile agents are essential for automating tasks in complex and dynamic mobile environments. As foundation models evolve, the demands for agents that can adapt in real-time and process multimodal data have grown. This survey provides a comprehensive review of mobile agent technologies, focusing on recent advancements that enhance real-time adaptability and multimodal interaction. Recent evaluation benchmarks have been developed better to capture the static and interactive environments of mobile tasks, offering more accurate assessments of agents’ performance. We then categorize these advancements into two main approaches: prompt-based methods, which utilize large language models (LLMs) for instruction-based task execution, and training-based methods, which fine-tune multimodal models for mobile-specific applications. Additionally, we explore complementary technologies that augment agent performance. By discussing key challenges and outlining future research directions, this survey offers valuable insights for advancing mobile agent technologies. A comprehensive resource list is available at <a target="_blank" rel="noopener" href="https://github.com/aialt/awesome-mobile-agents">https://github.com/aialt/awesome-mobile-agents</a> </p>
<blockquote>
<p>移动代理是自动化复杂动态移动环境中任务的关键。随着基础模型的演变，对能够在实时环境中适应并处理多模式数据的需求不断增长。这篇综述全面回顾了移动代理技术，重点关注了最近的进步，这些进步增强了实时适应性和多模式交互的能力。为了更好地捕捉移动任务的静态和交互式环境，已经开发出了最新的评估基准，为评估代理性能提供了更准确的依据。然后，我们将这些进步分为两大类方法：基于提示的方法，利用大型语言模型进行基于指令的任务执行；基于训练的方法，对多模式模型进行微调以适应移动特定应用。此外，我们还探讨了增强代理性能的辅助技术。通过讨论关键挑战并概述未来的研究方向，这篇综述为推进移动代理技术提供了有价值的见解。详细的资源列表请访问：[<a target="_blank" rel="noopener" href="https://github.com/aialt/awesome-mobile-agents]%EF%BC%88%E4%B8%AD%E6%96%87%E7%89%88%E8%AF%B7%E5%8F%82%E8%80%83%E6%AD%A4%E9%93%BE%E6%8E%A5%EF%BC%89%E3%80%82">https://github.com/aialt/awesome-mobile-agents]（中文版请参考此链接）。</a></p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2411.02006v2">PDF</a> 8 pages, 1 figure</p>
<p><strong>Summary</strong></p>
<p>本文介绍了移动代理技术在自动化处理复杂动态移动环境任务方面的关键作用。随着基础模型的发展，需要能在实时环境下自适应并处理多模态数据的代理需求不断增长。本文全面回顾了移动代理技术的最新进展，特别是增强实时自适应和多模态交互的进展。本文还将这些进展分为两类方法：基于提示的方法，利用大型语言模型进行指令式任务执行；基于训练的方法，对多模态模型进行微调以适应移动特定应用。此外，本文还探讨了增强代理性能的互补技术，并讨论了关键挑战和未来的研究方向。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>移动代理技术对于自动化处理复杂动态环境中的任务至关重要。</li>
<li>随着基础模型的发展，对实时自适应并处理多模态数据的代理需求增加。</li>
<li>移动代理技术的最新进展包括增强实时自适应和多模态交互的能力。</li>
<li>移动代理技术分为两类方法：基于提示的方法和基于训练的方法。</li>
<li>基于提示的方法利用大型语言模型进行指令式任务执行。</li>
<li>基于训练的方法对多模态模型进行微调以适应移动特定应用。</li>
<li>互补技术可以进一步增强代理性能。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2411.02006">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-421eafdb2bb56406ae47552dc582eb20.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-f504241c90af48a386d7160af20de634.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b6947c1a4cf911e8b7cf9f81b0d68912.jpg" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="AdvAgent-Controllable-Blackbox-Red-teaming-on-Web-Agents"><a href="#AdvAgent-Controllable-Blackbox-Red-teaming-on-Web-Agents" class="headerlink" title="AdvAgent: Controllable Blackbox Red-teaming on Web Agents"></a>AdvAgent: Controllable Blackbox Red-teaming on Web Agents</h2><p><strong>Authors:Chejian Xu, Mintong Kang, Jiawei Zhang, Zeyi Liao, Lingbo Mo, Mengqi Yuan, Huan Sun, Bo Li</strong></p>
<p>Foundation model-based agents are increasingly used to automate complex tasks, enhancing efficiency and productivity. However, their access to sensitive resources and autonomous decision-making also introduce significant security risks, where successful attacks could lead to severe consequences. To systematically uncover these vulnerabilities, we propose AdvAgent, a black-box red-teaming framework for attacking web agents. Unlike existing approaches, AdvAgent employs a reinforcement learning-based pipeline to train an adversarial prompter model that optimizes adversarial prompts using feedback from the black-box agent. With careful attack design, these prompts effectively exploit agent weaknesses while maintaining stealthiness and controllability. Extensive evaluations demonstrate that AdvAgent achieves high success rates against state-of-the-art GPT-4-based web agents across diverse web tasks. Furthermore, we find that existing prompt-based defenses provide only limited protection, leaving agents vulnerable to our framework. These findings highlight critical vulnerabilities in current web agents and emphasize the urgent need for stronger defense mechanisms. We release code at <a target="_blank" rel="noopener" href="https://ai-secure.github.io/AdvAgent/">https://ai-secure.github.io/AdvAgent/</a>. </p>
<blockquote>
<p>基于模型的智能代理越来越多地被用于自动化复杂任务，以提高效率和生产力。然而，它们访问敏感资源和自主决策的能力也带来了重大的安全风险，一旦攻击成功可能导致严重后果。为了系统地发现这些漏洞，我们提出了AdvAgent，这是一个用于攻击网络智能代理的黑箱红队框架。不同于现有的方法，AdvAgent采用基于强化学习的管道来训练对抗性提示模型，该模型使用来自黑箱智能代理的反馈来优化对抗性提示。通过精心的攻击设计，这些提示有效地利用智能代理的弱点，同时保持隐蔽性和可控性。广泛评估表明，AdvAgent在最先进的GPT-4网络智能代理上实现了高成功率，涵盖了多种网络任务。此外，我们发现现有的基于提示的防御措施只提供了有限的保护，使智能代理面临我们框架的攻击风险。这些发现突出了当前网络智能代理的关键漏洞，并强调了更强大防御机制的迫切需要。我们在<a target="_blank" rel="noopener" href="https://ai-secure.github.io/AdvAgent/%E5%8F%91%E5%B8%83%E4%BB%A3%E7%A0%81%E3%80%82">https://ai-secure.github.io/AdvAgent/发布代码。</a></p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2410.17401v4">PDF</a> ICML 2025</p>
<p><strong>Summary</strong></p>
<p>基于模型的自动化代理在处理复杂任务时表现出高效性，但其访问敏感资源和自主决策能力也带来了安全风险。针对这些风险，提出一种名为AdvAgent的黑箱红队攻击框架。通过强化学习训练对抗提示模型，利用代理反馈优化对抗提示，在精心设计的攻击下有效揭示代理弱点，保持隐蔽性和可控性。评估显示，AdvAgent针对GPT-4网代理的多样任务成功率高，现有提示防护方法效果不佳，突出重要弱点，强调迫切需要更强的防护机制。已发布代码于<a target="_blank" rel="noopener" href="https://ai-secure.github.io/AdvAgent/%E3%80%82">https://ai-secure.github.io/AdvAgent/。</a></p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>基于模型的代理在自动化复杂任务中表现出高效性，但也存在安全风险。</li>
<li>AdvAgent是一种黑箱红队攻击框架，用于揭示代理的安全漏洞。</li>
<li>AdvAgent使用强化学习训练对抗提示模型，利用代理反馈优化对抗提示。</li>
<li>精心设计的攻击能有效揭示代理弱点并保持隐蔽性和可控性。</li>
<li>AdvAgent针对GPT-4网代理的多样任务成功率高。</li>
<li>当前提示防护方法效果有限，存在显著漏洞。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2410.17401">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-ea4eb5ac9d5584989f5b6a679eed9ba2.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-1af14ba502e59f478326583210ee94c0.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-2b5e8483666edfd754e7fc271ce4cb33.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-3742d0d340ab12e4a2ccabc021aec430.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-6662a0e79642f9509e2fd2553458c5bd.jpg" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1><h2 id="Quantifying-Misalignment-Between-Agents-Towards-a-Sociotechnical-Understanding-of-Alignment"><a href="#Quantifying-Misalignment-Between-Agents-Towards-a-Sociotechnical-Understanding-of-Alignment" class="headerlink" title="Quantifying Misalignment Between Agents: Towards a Sociotechnical   Understanding of Alignment"></a>Quantifying Misalignment Between Agents: Towards a Sociotechnical   Understanding of Alignment</h2><p><strong>Authors:Aidan Kierans, Avijit Ghosh, Hananel Hazan, Shiri Dori-Hacohen</strong></p>
<p>Existing work on the alignment problem has focused mainly on (1) qualitative descriptions of the alignment problem; (2) attempting to align AI actions with human interests by focusing on value specification and learning; and&#x2F;or (3) focusing on a single agent or on humanity as a monolith. Recent sociotechnical approaches highlight the need to understand complex misalignment among multiple human and AI agents. We address this gap by adapting a computational social science model of human contention to the alignment problem. Our model quantifies misalignment in large, diverse agent groups with potentially conflicting goals across various problem areas. Misalignment scores in our framework depend on the observed agent population, the domain in question, and conflict between agents’ weighted preferences. Through simulations, we demonstrate how our model captures intuitive aspects of misalignment across different scenarios. We then apply our model to two case studies, including an autonomous vehicle setting, showcasing its practical utility. Our approach offers enhanced explanatory power for complex sociotechnical environments and could inform the design of more aligned AI systems in real-world applications. </p>
<blockquote>
<p>关于对齐问题的现有研究主要集中在以下几个方面：（1）对齐问题的定性描述；（2）通过关注价值规范和机器学习来尝试使AI行为与人类的利益保持一致；（3）关注单一代理或单一的人类群体。最近的社会技术方法强调需要理解人类和AI代理之间复杂的错位问题。我们通过将计算社会科学模型中的人类争议适应到对齐问题来解决这一差距。我们的模型量化大型、多样化的代理群体在不同问题领域中潜在目标冲突的不对齐情况。在我们的框架中，错位得分取决于观察到的代理群体、相关域以及代理加权偏好之间的冲突。通过模拟，我们展示了我们的模型如何在不同场景中捕捉错位直觉。然后，我们将模型应用于两个案例研究，包括自动驾驶汽车设置，展示其实用性。我们的方法对于复杂的社会技术环境提供了增强的解释力，并能够在实际应用中的AI系统设计方面提供更多指导。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2406.04231v4">PDF</a> 7 pages, 8 figures, 3 tables, forthcoming at the AAAI-25 Special   Track on AI Alignment</p>
<p><strong>Summary</strong></p>
<p>本文介绍了人工智能（AI）与人类之间的对齐问题，指出现有研究主要集中在定性描述对齐问题、通过价值规范和学习的焦点来对齐AI行动和人类利益，以及关注单一代理或人类整体等方面。近期社会技术方法强调理解复杂人类和AI代理之间的多重错误对齐的重要性。本文采用计算社会科学模型来解决这一问题，该模型量化大型、多样化代理群体在不同问题领域的潜在冲突目标中的错误对齐情况。模拟结果表明，该模型能够捕获不同场景中错误对齐的直观方面。最后，本文将模型应用于两个案例研究，包括自动驾驶汽车环境，展示了其实用性。本研究为提高复杂社会技术环境的解释能力提供了有力工具，并为实际应用的更对齐AI系统设计提供了参考。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>当前关于人工智能（AI）与人类之间的对齐问题主要集中在定性描述上。</li>
<li>社会技术方法的重要性在于理解复杂的人类和AI代理之间的多重错误对齐问题。</li>
<li>采用计算社会科学模型来解决AI与人类的对齐问题，可以量化大型、多样化代理群体中的错误对齐情况。</li>
<li>该模型考虑了观察到的代理群体、特定领域以及代理间冲突权重偏好等因素来计算错误对齐得分。</li>
<li>模拟结果表明该模型能够捕获不同场景中错误对齐的直观方面。</li>
<li>模型被应用于自动驾驶汽车环境的案例研究，展示了其实用性。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2406.04231">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pica.zhimg.com/v2-8642e995774b93b5b0115ddd55f1b846.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-75c86f941e361844cb112187039f6425.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-3be978ba7964c8842983a40a7918738a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-449af438e8844ef56c977209a09faad3.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-36b6714dabfa37d7b2c6e9513d8d8980.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-71723fa9999b8c89d853fb3f2cdbad48.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-62ae1d55c14f80fe186213e5dcb33859.jpg" align="middle">
</details>


<h1 id="-9"><a href="#-9" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        文章作者:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        文章链接:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-06-04/Agent/">https://kedreamix.github.io/Talk2Paper/Paper/2025-06-04/Agent/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        版权声明:
                    </i>
                </span>
                <span class="reprint-info">
                    本博客所有文章除特別声明外，均采用
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    许可协议。转载请注明来源
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/Agent/">
                                    <span class="chip bg-color">Agent</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;上一篇</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-06-04/Few-Shot/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-93ec5c199a3111735cbe5faf45431d31.jpg" class="responsive-img" alt="Few-Shot">
                        
                        <span class="card-title">Few-Shot</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Few-Shot 方向最新论文已更新，请持续关注 Update in 2025-06-04  Data Whisperer Efficient Data Selection for Task-Specific LLM   Fine-Tuning via Few-Shot In-Context Learning
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-06-04
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Few-Shot/" class="post-category">
                                    Few-Shot
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Few-Shot/">
                        <span class="chip bg-color">Few-Shot</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-06-04/LLM/">
                    <div class="card-image">
                        
                        <img src="https://pic1.zhimg.com/v2-d3c03365170299397c44c4faec81cd22.jpg" class="responsive-img" alt="LLM">
                        
                        <span class="card-title">LLM</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            LLM 方向最新论文已更新，请持续关注 Update in 2025-06-04  AutoChemSchematic AI A Closed-Loop, Physics-Aware Agentic Framework for   Auto-Generating Chemical Process and Instrumentation Diagrams
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-06-04
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/LLM/" class="post-category">
                                    LLM
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/LLM/">
                        <span class="chip bg-color">LLM</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- 代码语言 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span
                        class="white-color">26548.9k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- 运行天数提醒. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // 区分是否有年份.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = '本站已运行 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                daysTip = '本站已運行 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = '本站已运行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = '本站已運行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="关注我的知乎: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">知</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- 白天和黑夜主题 -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // 只在桌面版网页启用特效
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- 雪花特效 -->
    

    <!-- 鼠标星星特效 -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--腾讯兔小巢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- 动态标签 -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Σ(っ °Д °;)っ诶，页面崩溃了嘛？", clearTimeout(st)) : (document.title = "φ(゜▽゜*)♪咦，又好了！", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
