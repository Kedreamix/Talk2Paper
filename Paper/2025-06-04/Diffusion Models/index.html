<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Diffusion Models">
    <meta name="description" content="Diffusion Models æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-06-04  OpenUni A Simple Baseline for Unified Multimodal Understanding and   Generation">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>Diffusion Models | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://pic1.zhimg.com/v2-32f95dfd51ea03a183c4ed355570c4e2.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Diffusion Models</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/Diffusion-Models/">
                                <span class="chip bg-color">Diffusion Models</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/Diffusion-Models/" class="post-category">
                                Diffusion Models
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-06-04
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-07-06
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    9.7k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    39 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-06-04-æ›´æ–°"><a href="#2025-06-04-æ›´æ–°" class="headerlink" title="2025-06-04 æ›´æ–°"></a>2025-06-04 æ›´æ–°</h1><h2 id="OpenUni-A-Simple-Baseline-for-Unified-Multimodal-Understanding-and-Generation"><a href="#OpenUni-A-Simple-Baseline-for-Unified-Multimodal-Understanding-and-Generation" class="headerlink" title="OpenUni: A Simple Baseline for Unified Multimodal Understanding and   Generation"></a>OpenUni: A Simple Baseline for Unified Multimodal Understanding and   Generation</h2><p><strong>Authors:Size Wu, Zhonghua Wu, Zerui Gong, Qingyi Tao, Sheng Jin, Qinyue Li, Wei Li, Chen Change Loy</strong></p>
<p>In this report, we present OpenUni, a simple, lightweight, and fully open-source baseline for unifying multimodal understanding and generation. Inspired by prevailing practices in unified model learning, we adopt an efficient training strategy that minimizes the training complexity and overhead by bridging the off-the-shelf multimodal large language models (LLMs) and diffusion models through a set of learnable queries and a light-weight transformer-based connector. With a minimalist choice of architecture, we demonstrate that OpenUni can: 1) generate high-quality and instruction-aligned images, and 2) achieve exceptional performance on standard benchmarks such as GenEval, DPG- Bench, and WISE, with only 1.1B and 3.1B activated parameters. To support open research and community advancement, we release all model weights, training code, and our curated training datasets (including 23M image-text pairs) at <a target="_blank" rel="noopener" href="https://github.com/wusize/OpenUni">https://github.com/wusize/OpenUni</a>. </p>
<blockquote>
<p>åœ¨è¿™ä»½æŠ¥å‘Šä¸­ï¼Œæˆ‘ä»¬ä»‹ç»äº†OpenUniï¼Œè¿™æ˜¯ä¸€ä¸ªç®€å•ã€è½»é‡çº§ã€å®Œå…¨å¼€æºçš„å¤šæ¨¡æ€ç†è§£å’Œç”Ÿæˆç»Ÿä¸€åŸºå‡†ã€‚æˆ‘ä»¬å—åˆ°ç»Ÿä¸€æ¨¡å‹å­¦ä¹ æµè¡Œå®è·µçš„å¯å‘ï¼Œé‡‡ç”¨äº†ä¸€ç§é«˜æ•ˆçš„è®­ç»ƒç­–ç•¥ï¼Œé€šè¿‡ä¸€ç»„å¯å­¦ä¹ çš„æŸ¥è¯¢å’Œä¸€ä¸ªåŸºäºè½»é‡çº§å˜å‹å™¨çš„è¿æ¥å™¨ï¼Œå°†ç°æˆçš„å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å’Œæ‰©æ•£æ¨¡å‹è”ç³»èµ·æ¥ï¼Œä»è€Œæœ€å°åŒ–è®­ç»ƒå¤æ‚æ€§å’Œå¼€é”€ã€‚é€šè¿‡é€‰æ‹©æœ€ç®€æ´çš„æ¶æ„ï¼Œæˆ‘ä»¬è¯æ˜OpenUniå¯ä»¥ï¼š1ï¼‰ç”Ÿæˆé«˜è´¨é‡ä¸”ç¬¦åˆæŒ‡ä»¤çš„å›¾åƒï¼›2ï¼‰åœ¨GenEvalã€DPG-Benchå’ŒWISEç­‰æ ‡å‡†åŸºå‡†æµ‹è¯•ä¸Šå®ç°å“è¶Šæ€§èƒ½ï¼Œä»…éœ€1.1Bå’Œ3.1Bæ¿€æ´»å‚æ•°ã€‚ä¸ºäº†æ”¯æŒå¼€æ”¾ç ”ç©¶å’Œç¤¾åŒºå‘å±•ï¼Œæˆ‘ä»¬åœ¨<a target="_blank" rel="noopener" href="https://github.com/wusize/OpenUni">https://github.com/wusize/OpenUni</a>ä¸Šå‘å¸ƒäº†æ‰€æœ‰æ¨¡å‹æƒé‡ã€è®­ç»ƒä»£ç å’Œæˆ‘ä»¬ç²¾é€‰çš„è®­ç»ƒæ•°æ®é›†ï¼ˆåŒ…æ‹¬2300ä¸‡å¼ å›¾åƒæ–‡æœ¬å¯¹ï¼‰ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.23661v3">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>OpenUniæ˜¯ä¸€ä¸ªç®€å•ã€è½»é‡çº§ã€å®Œå…¨å¼€æºçš„å¤šæ¨¡æ€ç†è§£å’Œç”Ÿæˆç»Ÿä¸€åŸºå‡†ã€‚å®ƒé€šè¿‡é«˜æ•ˆçš„è®­ç»ƒç­–ç•¥ï¼Œé‡‡ç”¨ç°æˆçš„å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹å’Œæ‰©æ•£æ¨¡å‹ï¼Œé€šè¿‡ä¸€ç»„å¯å­¦ä¹ çš„æŸ¥è¯¢å’Œè½»é‡çº§åŸºäºå˜å‹å™¨çš„è¿æ¥å™¨ï¼Œä»¥å‡å°è®­ç»ƒå¤æ‚æ€§å’Œå¼€é”€ã€‚OpenUnièƒ½å¤Ÿç”Ÿæˆé«˜è´¨é‡ã€æŒ‡ä»¤å¯¹é½çš„å›¾åƒï¼Œå¹¶åœ¨GenEvalã€DPG-Benchå’ŒWISEç­‰æ ‡å‡†åŸºå‡†æµ‹è¯•ä¸­å®ç°å“è¶Šæ€§èƒ½ï¼Œä»…éœ€1.1Bå’Œ3.1Bæ¿€æ´»å‚æ•°ã€‚æ‰€æœ‰æ¨¡å‹æƒé‡ã€è®­ç»ƒä»£ç å’Œè®­ç»ƒæ•°æ®é›†å·²åœ¨GitHubä¸Šå‘å¸ƒï¼Œä»¥æ”¯æŒå¼€æ”¾ç ”ç©¶å’Œç¤¾åŒºå‘å±•ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>OpenUniæ˜¯ä¸€ä¸ªç»Ÿä¸€å¤šæ¨¡æ€ç†è§£å’Œç”Ÿæˆä»»åŠ¡çš„å¼€æºæ¡†æ¶ã€‚</li>
<li>å®ƒé€šè¿‡è½»é‡çº§è®¾è®¡å®ç°äº†é«˜æ•ˆè®­ç»ƒç­–ç•¥ï¼Œé™ä½äº†è®­ç»ƒå¤æ‚æ€§å’Œå¼€é”€ã€‚</li>
<li>OpenUniç»“åˆäº†ç°æˆçš„å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹å’Œæ‰©æ•£æ¨¡å‹ã€‚</li>
<li>é€šè¿‡å¯å­¦ä¹ çš„æŸ¥è¯¢å’ŒåŸºäºå˜å‹å™¨çš„è¿æ¥å™¨å®ç°æ¨¡å‹é—´çš„æ¡¥æ¢ã€‚</li>
<li>OpenUnièƒ½ç”Ÿæˆé«˜è´¨é‡ã€ä¸æŒ‡ä»¤å¯¹é½çš„å›¾åƒã€‚</li>
<li>åœ¨å¤šä¸ªæ ‡å‡†åŸºå‡†æµ‹è¯•ä¸­è¡¨ç°å‡ºå“è¶Šæ€§èƒ½ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.23661">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-03d54df6a0a77105f39c534998910b1c.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-a2bbcb0e9d34e13c915cfb04cef56811.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-2246c41aef27268222410d66d168b5e5.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-509b0b1f9d90cd173b67a77a448fb623.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-740b5c6b356ed58fbab5c59791c4e552.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="ITA-MDT-Image-Timestep-Adaptive-Masked-Diffusion-Transformer-Framework-for-Image-Based-Virtual-Try-On"><a href="#ITA-MDT-Image-Timestep-Adaptive-Masked-Diffusion-Transformer-Framework-for-Image-Based-Virtual-Try-On" class="headerlink" title="ITA-MDT: Image-Timestep-Adaptive Masked Diffusion Transformer Framework   for Image-Based Virtual Try-On"></a>ITA-MDT: Image-Timestep-Adaptive Masked Diffusion Transformer Framework   for Image-Based Virtual Try-On</h2><p><strong>Authors:Ji Woo Hong, Tri Ton, Trung X. Pham, Gwanhyeong Koo, Sunjae Yoon, Chang D. Yoo</strong></p>
<p>This paper introduces ITA-MDT, the Image-Timestep-Adaptive Masked Diffusion Transformer Framework for Image-Based Virtual Try-On (IVTON), designed to overcome the limitations of previous approaches by leveraging the Masked Diffusion Transformer (MDT) for improved handling of both global garment context and fine-grained details. The IVTON task involves seamlessly superimposing a garment from one image onto a person in another, creating a realistic depiction of the person wearing the specified garment. Unlike conventional diffusion-based virtual try-on models that depend on large pre-trained U-Net architectures, ITA-MDT leverages a lightweight, scalable transformer-based denoising diffusion model with a mask latent modeling scheme, achieving competitive results while reducing computational overhead. A key component of ITA-MDT is the Image-Timestep Adaptive Feature Aggregator (ITAFA), a dynamic feature aggregator that combines all of the features from the image encoder into a unified feature of the same size, guided by diffusion timestep and garment image complexity. This enables adaptive weighting of features, allowing the model to emphasize either global information or fine-grained details based on the requirements of the denoising stage. Additionally, the Salient Region Extractor (SRE) module is presented to identify complex region of the garment to provide high-resolution local information to the denoising model as an additional condition alongside the global information of the full garment image. This targeted conditioning strategy enhances detail preservation of fine details in highly salient garment regions, optimizing computational resources by avoiding unnecessarily processing entire garment image. Comparative evaluations confirms that ITA-MDT improves efficiency while maintaining strong performance, reaching state-of-the-art results in several metrics. </p>
<blockquote>
<p>æœ¬æ–‡ä»‹ç»äº†é’ˆå¯¹åŸºäºå›¾åƒçš„è™šæ‹Ÿè¯•ç©¿ï¼ˆIVTONï¼‰è®¾è®¡çš„å›¾åƒæ—¶åºè‡ªé€‚åº”æ©è†œæ‰©æ•£å˜æ¢æ¡†æ¶ITA-MDTã€‚è¯¥æ¡†æ¶æ—¨åœ¨å…‹æœä»¥å‰æ–¹æ³•çš„å±€é™æ€§ï¼Œåˆ©ç”¨æ©è†œæ‰©æ•£å˜æ¢å™¨ï¼ˆMDTï¼‰æ”¹è¿›å…¨å±€æœè£…ä¸Šä¸‹æ–‡å’Œç²¾ç»†ç»†èŠ‚çš„å¤„ç†ã€‚IVTONä»»åŠ¡æ¶‰åŠå°†ä¸€å¼ å›¾åƒä¸­çš„æœè£…æ— ç¼åœ°å åŠ åˆ°å¦ä¸€å¼ å›¾åƒä¸­çš„äººç‰©èº«ä¸Šï¼Œåˆ›å»ºäººç‰©ç©¿ç€æŒ‡å®šæœè£…çš„ç°å®ä¸»ä¹‰æç»˜ã€‚ä¸åŒäºä¾èµ–å¤§å‹é¢„è®­ç»ƒU-Netæ¶æ„çš„ä¼ ç»ŸåŸºäºæ‰©æ•£çš„è™šæ‹Ÿè¯•ç©¿æ¨¡å‹ï¼ŒITA-MDTåˆ©ç”¨äº†ä¸€ä¸ªè½»é‡çº§ã€å¯æ‰©å±•çš„åŸºäºå˜æ¢å™¨çš„å»å™ªæ‰©æ•£æ¨¡å‹ï¼Œå¹¶é‡‡ç”¨äº†æ©è†œæ½œåœ¨å»ºæ¨¡æ–¹æ¡ˆï¼Œåœ¨é™ä½è®¡ç®—å¼€é”€çš„åŒæ—¶å®ç°äº†å…·æœ‰ç«äº‰åŠ›çš„ç»“æœã€‚ITA-MDTçš„å…³é”®ç»„ä»¶æ˜¯å›¾åƒæ—¶åºè‡ªé€‚åº”ç‰¹å¾èšåˆå™¨ï¼ˆITAFAï¼‰ï¼Œè¿™æ˜¯ä¸€ä¸ªåŠ¨æ€ç‰¹å¾èšåˆå™¨ï¼Œå®ƒå°†æ¥è‡ªå›¾åƒç¼–ç å™¨çš„æ‰€æœ‰ç‰¹å¾åˆå¹¶ä¸ºå…·æœ‰ç›¸åŒå¤§å°çš„ç»Ÿä¸€ç‰¹å¾ï¼Œå—æ‰©æ•£æ­¥éª¤å’Œæœè£…å›¾åƒå¤æ‚æ€§çš„å¼•å¯¼ã€‚è¿™å®ç°äº†ç‰¹å¾çš„è‡ªé€‚åº”åŠ æƒï¼Œä½¿æ¨¡å‹èƒ½å¤Ÿæ ¹æ®å»å™ªé˜¶æ®µçš„éœ€è¦åœ¨å…¨å±€ä¿¡æ¯æˆ–ç²¾ç»†ç»†èŠ‚ä¹‹é—´è¿›è¡Œæƒè¡¡ã€‚æ­¤å¤–ï¼Œè¿˜ä»‹ç»äº†æ˜¾è‘—åŒºåŸŸæå–å™¨ï¼ˆSREï¼‰æ¨¡å—ï¼Œç”¨äºè¯†åˆ«æœè£…çš„å¤æ‚åŒºåŸŸï¼Œä¸ºå»å™ªæ¨¡å‹æä¾›é«˜åˆ†è¾¨ç‡çš„å±€éƒ¨ä¿¡æ¯ï¼Œä½œä¸ºå…¨å±€ä¿¡æ¯çš„é™„åŠ æ¡ä»¶ã€‚è¿™ç§æœ‰é’ˆå¯¹æ€§çš„æ¡ä»¶ç­–ç•¥æœ‰åŠ©äºä¿ç•™æœè£…é«˜åº¦æ˜¾è‘—åŒºåŸŸçš„ç»†èŠ‚ï¼Œå¹¶é€šè¿‡é¿å…ä¸å¿…è¦åœ°å¤„ç†æ•´ä¸ªæœè£…å›¾åƒæ¥ä¼˜åŒ–è®¡ç®—èµ„æºã€‚æ¯”è¾ƒè¯„ä¼°è¯å®ï¼ŒITA-MDTåœ¨æé«˜æ•ˆç‡çš„åŒæ—¶ä¿æŒäº†å¼ºå¤§çš„æ€§èƒ½ï¼Œåœ¨å¤šä¸ªæŒ‡æ ‡ä¸Šè¾¾åˆ°äº†æœ€æ–°æ°´å¹³ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.20418v2">PDF</a> CVPR 2025, Project Page: <a target="_blank" rel="noopener" href="https://jiwoohong93.github.io/ita-mdt/">https://jiwoohong93.github.io/ita-mdt/</a></p>
<p><strong>Summary</strong></p>
<p>è¯¥è®ºæ–‡æå‡ºäº†åŸºäºå›¾åƒæ—¶åºè‡ªé€‚åº”æ©è†œæ‰©æ•£è½¬æ¢å™¨æ¡†æ¶ï¼ˆITA-MDTï¼‰çš„å›¾åƒè™šæ‹Ÿè¯•ç©¿ï¼ˆIVTONï¼‰æ–°æ–¹æ³•ã€‚å®ƒå…‹æœäº†å…ˆå‰æ–¹æ³•çš„å±€é™æ€§ï¼Œåˆ©ç”¨æ©è†œæ‰©æ•£è½¬æ¢å™¨ï¼ˆMDTï¼‰å¤„ç†å…¨å±€æœè£…ä¸Šä¸‹æ–‡å’Œç²¾ç»†ç»†èŠ‚çš„èƒ½åŠ›ã€‚IVTONä»»åŠ¡æ˜¯å°†ä¸€å¼ å›¾åƒä¸­çš„æœè£…æ— ç¼åœ°å åŠ åˆ°å¦ä¸€å¼ å›¾åƒä¸­çš„äººç‰©ä¸Šï¼Œåˆ›é€ å‡ºäººç‰©ç©¿ç€æŒ‡å®šæœè£…çš„ç°å®ä¸»ä¹‰æç»˜ã€‚ä¸åŒäºä¼ ç»Ÿçš„åŸºäºæ‰©æ•£çš„è™šæ‹Ÿè¯•ç©¿æ¨¡å‹ä¾èµ–å¤§å‹é¢„è®­ç»ƒU-Netæ¶æ„ï¼ŒITA-MDTé‡‡ç”¨äº†ä¸€ç§è½»é‡çº§ã€å¯æ‰©å±•çš„åŸºäºå˜æ¢å™¨çš„å»å™ªæ‰©æ•£æ¨¡å‹ï¼Œå¹¶ç»“åˆæ©è†œæ½œåœ¨å»ºæ¨¡æ–¹æ¡ˆï¼Œåœ¨é™ä½è®¡ç®—å¼€é”€çš„åŒæ—¶å®ç°äº†ç«äº‰æ€§çš„ç»“æœã€‚ITA-MDTçš„å…³é”®ç»„ä»¶åŒ…æ‹¬å›¾åƒæ—¶åºè‡ªé€‚åº”ç‰¹å¾èšåˆå™¨ï¼ˆITAFAï¼‰å’Œæ˜¾è‘—åŒºåŸŸæå–å™¨ï¼ˆSREï¼‰æ¨¡å—ï¼Œå®ƒä»¬åˆ†åˆ«é€šè¿‡è‡ªé€‚åº”åœ°åŠ æƒç‰¹å¾å’Œè¯†åˆ«æœè£…çš„å¤æ‚åŒºåŸŸï¼Œæé«˜äº†æ¨¡å‹åœ¨é™å™ªé˜¶æ®µçš„æ€§èƒ½ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ITA-MDTæ¡†æ¶ç»“åˆäº†æ©è†œæ‰©æ•£è½¬æ¢å™¨ï¼ˆMDTï¼‰ç”¨äºå›¾åƒè™šæ‹Ÿè¯•ç©¿ï¼ˆIVTONï¼‰ï¼Œæé«˜äº†å¤„ç†å…¨å±€æœè£…ä¸Šä¸‹æ–‡å’Œç²¾ç»†ç»†èŠ‚çš„èƒ½åŠ›ã€‚</li>
<li>ä¸åŒäºä¼ ç»Ÿçš„æ‰©æ•£è™šæ‹Ÿè¯•ç©¿æ¨¡å‹ä¾èµ–å¤§å‹U-Netæ¶æ„ï¼ŒITA-MDTé‡‡ç”¨è½»é‡çº§ã€å¯æ‰©å±•çš„åŸºäºå˜æ¢å™¨çš„å»å™ªæ‰©æ•£æ¨¡å‹ï¼Œé™ä½äº†è®¡ç®—å¼€é”€ã€‚</li>
<li>ITA-MDTå¼•å…¥äº†å›¾åƒæ—¶åºè‡ªé€‚åº”ç‰¹å¾èšåˆå™¨ï¼ˆITAFAï¼‰ï¼Œèƒ½å¤Ÿæ ¹æ®æ‰©æ•£æ­¥éª¤å’Œæœè£…å›¾åƒå¤æ‚åº¦åŠ¨æ€èšåˆç‰¹å¾ã€‚</li>
<li>æ˜¾è‘—åŒºåŸŸæå–å™¨ï¼ˆSREï¼‰æ¨¡å—èƒ½å¤Ÿè¯†åˆ«æœè£…çš„å¤æ‚åŒºåŸŸï¼Œä¸ºå»å™ªæ¨¡å‹æä¾›é«˜åˆ†è¾¨ç‡çš„å±€éƒ¨ä¿¡æ¯ï¼Œæé«˜ç»†èŠ‚ä¿ç•™èƒ½åŠ›ã€‚</li>
<li>ITA-MDTé€šè¿‡é’ˆå¯¹æ˜¾è‘—åŒºåŸŸçš„æ¡ä»¶ç­–ç•¥ï¼Œä¼˜åŒ–äº†èµ„æºåˆ†é…ï¼Œé¿å…äº†ä¸å¿…è¦åœ°å¤„ç†æ•´ä¸ªæœè£…å›¾åƒã€‚</li>
<li>è¯„ä¼°ç»“æœè¡¨æ˜ï¼ŒITA-MDTåœ¨æé«˜æ•ˆç‡çš„åŒæ—¶ä¿æŒäº†å¼ºå¤§çš„æ€§èƒ½ï¼Œè¾¾åˆ°äº†å¤šä¸ªæŒ‡æ ‡çš„æœ€å…ˆè¿›æ°´å¹³ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.20418">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-32f95dfd51ea03a183c4ed355570c4e2.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b5c65a9a21e551cbc0c0b026bdebf7bb.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a0817bc3128d28e3e0b5881607aca546.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-2019ea280ffbeb288ea84251e8dfa417.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="TSD-SR-One-Step-Diffusion-with-Target-Score-Distillation-for-Real-World-Image-Super-Resolution"><a href="#TSD-SR-One-Step-Diffusion-with-Target-Score-Distillation-for-Real-World-Image-Super-Resolution" class="headerlink" title="TSD-SR: One-Step Diffusion with Target Score Distillation for Real-World   Image Super-Resolution"></a>TSD-SR: One-Step Diffusion with Target Score Distillation for Real-World   Image Super-Resolution</h2><p><strong>Authors:Linwei Dong, Qingnan Fan, Yihong Guo, Zhonghao Wang, Qi Zhang, Jinwei Chen, Yawei Luo, Changqing Zou</strong></p>
<p>Pre-trained text-to-image diffusion models are increasingly applied to real-world image super-resolution (Real-ISR) task. Given the iterative refinement nature of diffusion models, most existing approaches are computationally expensive. While methods such as SinSR and OSEDiff have emerged to condense inference steps via distillation, their performance in image restoration or details recovery is not satisfied. To address this, we propose TSD-SR, a novel distillation framework specifically designed for real-world image super-resolution, aiming to construct an efficient and effective one-step model. We first introduce the Target Score Distillation, which leverages the priors of diffusion models and real image references to achieve more realistic image restoration. Secondly, we propose a Distribution-Aware Sampling Module to make detail-oriented gradients more readily accessible, addressing the challenge of recovering fine details. Extensive experiments demonstrate that our TSD-SR has superior restoration results (most of the metrics perform the best) and the fastest inference speed (e.g. 40 times faster than SeeSR) compared to the past Real-ISR approaches based on pre-trained diffusion priors. </p>
<blockquote>
<p>é¢„è®­ç»ƒçš„æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹è¶Šæ¥è¶Šå¤šåœ°åº”ç”¨äºç°å®ä¸–ç•Œå›¾åƒè¶…åˆ†è¾¨ç‡ï¼ˆReal-ISRï¼‰ä»»åŠ¡ã€‚ç”±äºæ‰©æ•£æ¨¡å‹çš„è¿­ä»£ç»†åŒ–ç‰¹æ€§ï¼Œå¤§å¤šæ•°ç°æœ‰æ–¹æ³•è®¡ç®—é‡å¤§ã€‚è™½ç„¶SinSRå’ŒOSEDiffç­‰æ–¹æ³•å·²ç»å‡ºç°ï¼Œé€šè¿‡è’¸é¦æ¥ç²¾ç®€æ¨ç†æ­¥éª¤ï¼Œä½†å®ƒä»¬åœ¨å›¾åƒæ¢å¤æˆ–ç»†èŠ‚æ¢å¤æ–¹é¢çš„æ€§èƒ½å¹¶ä¸ä»¤äººæ»¡æ„ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†TSD-SRï¼Œè¿™æ˜¯ä¸€ç§ä¸“é—¨ç”¨äºç°å®ä¸–ç•Œå›¾åƒè¶…åˆ†è¾¨ç‡çš„æ–°å‹è’¸é¦æ¡†æ¶ï¼Œæ—¨åœ¨æ„å»ºé«˜æ•ˆä¸”æœ‰æ•ˆçš„ä¸€æ­¥æ¨¡å‹ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬å¼•å…¥äº†ç›®æ ‡åˆ†æ•°è’¸é¦ï¼Œå®ƒåˆ©ç”¨æ‰©æ•£æ¨¡å‹å’ŒçœŸå®å›¾åƒå¼•ç”¨çš„å…ˆéªŒçŸ¥è¯†æ¥å®ç°æ›´çœŸå®çš„å›¾åƒæ¢å¤ã€‚å…¶æ¬¡ï¼Œæˆ‘ä»¬æå‡ºäº†åˆ†å¸ƒæ„ŸçŸ¥é‡‡æ ·æ¨¡å—ï¼Œä½¿ç»†èŠ‚å¯¼å‘çš„æ¢¯åº¦æ›´å®¹æ˜“è·å–ï¼Œè§£å†³æ¢å¤ç²¾ç»†ç»†èŠ‚çš„æŒ‘æˆ˜ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼Œä¸åŸºäºé¢„è®­ç»ƒæ‰©æ•£å…ˆéªŒçš„è¿‡å»Real-ISRæ–¹æ³•ç›¸æ¯”ï¼Œæˆ‘ä»¬çš„TSD-SRå…·æœ‰ä¼˜è¶Šçš„å¤åŸæ•ˆæœï¼ˆå¤§å¤šæ•°æŒ‡æ ‡è¡¨ç°æœ€ä½³ï¼‰å’Œæœ€å¿«çš„æ¨ç†é€Ÿåº¦ï¼ˆä¾‹å¦‚ï¼Œæ¯”SeeSRå¿«40å€ï¼‰ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2411.18263v4">PDF</a> </p>
<p><strong>æ‘˜è¦</strong></p>
<p>é¢„è®­ç»ƒæ–‡æœ¬è½¬å›¾åƒæ‰©æ•£æ¨¡å‹è¶Šæ¥è¶Šå¤šåœ°åº”ç”¨äºç°å®å›¾åƒè¶…åˆ†è¾¨ç‡ï¼ˆReal-ISRï¼‰ä»»åŠ¡ã€‚è™½ç„¶ç°æœ‰æ–¹æ³•å¦‚SinSRå’ŒOSEDiffé€šè¿‡è’¸é¦æŠ€æœ¯ç®€åŒ–äº†æ¨ç†æ­¥éª¤ï¼Œä½†åœ¨å›¾åƒæ¢å¤æˆ–ç»†èŠ‚æ¢å¤æ–¹é¢çš„æ€§èƒ½å°šä¸æ»¡è¶³è¦æ±‚ã€‚ä¸ºè§£å†³æ­¤é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºTSD-SRï¼Œä¸€ç§ä¸“ä¸ºç°å®å›¾åƒè¶…åˆ†è¾¨ç‡è®¾è®¡çš„å…¨æ–°è’¸é¦æ¡†æ¶ï¼Œæ—¨åœ¨æ„å»ºé«˜æ•ˆä¸”æœ‰æ•ˆçš„ä¸€æ­¥æ¨¡å‹ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬å¼•å…¥ç›®æ ‡åˆ†æ•°è’¸é¦æŠ€æœ¯ï¼Œåˆ©ç”¨æ‰©æ•£æ¨¡å‹çš„å…ˆéªŒçŸ¥è¯†å’ŒçœŸå®å›¾åƒå‚è€ƒæ¥å®ç°æ›´é€¼çœŸçš„å›¾åƒæ¢å¤ã€‚å…¶æ¬¡ï¼Œæˆ‘ä»¬æå‡ºåˆ†å¸ƒæ„ŸçŸ¥é‡‡æ ·æ¨¡å—ï¼Œä½¿ç»†èŠ‚å¯¼å‘çš„æ¢¯åº¦æ›´å®¹æ˜“è·å–ï¼Œè§£å†³æ¢å¤ç²¾ç»†ç»†èŠ‚çš„æŒ‘æˆ˜ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„TSD-SRå…·æœ‰ä¼˜å¼‚çš„æ¢å¤æ•ˆæœï¼ˆå¤šæ•°æŒ‡æ ‡è¡¨ç°æœ€ä½³ï¼‰å’Œæœ€å¿«çš„æ¨ç†é€Ÿåº¦ï¼ˆä¾‹å¦‚ï¼Œæ¯”SeeSRå¿«40å€ï¼‰ï¼Œç›¸è¾ƒäºåŸºäºé¢„è®­ç»ƒæ‰©æ•£å…ˆéªŒçš„è¿‡å¾€Real-ISRæ–¹æ³•ã€‚</p>
<p><strong>å…³é”®è§è§£</strong></p>
<ol>
<li>é¢„è®­ç»ƒæ–‡æœ¬è½¬å›¾åƒæ‰©æ•£æ¨¡å‹åœ¨Real-ISRä»»åŠ¡ä¸­çš„åº”ç”¨è¶Šæ¥è¶Šå¹¿æ³›ã€‚</li>
<li>ç°æœ‰æ–¹æ³•å¦‚SinSRå’ŒOSEDiffè™½ç„¶ç®€åŒ–äº†æ¨ç†æ­¥éª¤ï¼Œä½†åœ¨å›¾åƒæ¢å¤ç»†èŠ‚æ–¹é¢æ€§èƒ½ä¸è¶³ã€‚</li>
<li>TSD-SRæ¡†æ¶æ—¨åœ¨æ„å»ºé«˜æ•ˆä¸”æœ‰æ•ˆçš„ä¸€æ­¥æ¨¡å‹ï¼Œç”¨äºç°å®å›¾åƒè¶…åˆ†è¾¨ç‡ã€‚</li>
<li>ç›®æ ‡åˆ†æ•°è’¸é¦æŠ€æœ¯åˆ©ç”¨æ‰©æ•£æ¨¡å‹å…ˆéªŒå’ŒçœŸå®å›¾åƒå‚è€ƒï¼Œå®ç°æ›´é€¼çœŸçš„å›¾åƒæ¢å¤ã€‚</li>
<li>åˆ†å¸ƒæ„ŸçŸ¥é‡‡æ ·æ¨¡å—ä½¿ç»†èŠ‚å¯¼å‘çš„æ¢¯åº¦æ›´æ˜“è·å–ï¼Œæ”¹å–„ç²¾ç»†ç»†èŠ‚çš„æ¢å¤ã€‚</li>
<li>TSD-SRåœ¨æ¢å¤æ•ˆæœä¸Šè¡¨ç°ä¼˜å¼‚ï¼Œå¤šæ•°æŒ‡æ ‡è¾¾åˆ°æœ€ä½³ã€‚</li>
<li>TSD-SRå…·æœ‰å¿«é€Ÿçš„æ¨ç†é€Ÿåº¦ï¼Œç›¸è¾ƒäºå…¶ä»–æ–¹æ³•æœ‰æ˜æ˜¾ä¼˜åŠ¿ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2411.18263">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-a784edc48467dacba05fb267ec88226d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-dd23620f041b52442392f284d869c353.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-15889efae840cede118dfb149267a970.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-563936f99f598115b76546470b27e6ae.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="HandCraft-Anatomically-Correct-Restoration-of-Malformed-Hands-in-Diffusion-Generated-Images"><a href="#HandCraft-Anatomically-Correct-Restoration-of-Malformed-Hands-in-Diffusion-Generated-Images" class="headerlink" title="HandCraft: Anatomically Correct Restoration of Malformed Hands in   Diffusion Generated Images"></a>HandCraft: Anatomically Correct Restoration of Malformed Hands in   Diffusion Generated Images</h2><p><strong>Authors:Zhenyue Qin, Yiqun Zhang, Yang Liu, Dylan Campbell</strong></p>
<p>Generative text-to-image models, such as Stable Diffusion, have demonstrated a remarkable ability to generate diverse, high-quality images. However, they are surprisingly inept when it comes to rendering human hands, which are often anatomically incorrect or reside in the â€œuncanny valleyâ€. In this paper, we propose a method HandCraft for restoring such malformed hands. This is achieved by automatically constructing masks and depth images for hands as conditioning signals using a parametric model, allowing a diffusion-based image editor to fix the handâ€™s anatomy and adjust its pose while seamlessly integrating the changes into the original image, preserving pose, color, and style. Our plug-and-play hand restoration solution is compatible with existing pretrained diffusion models, and the restoration process facilitates adoption by eschewing any fine-tuning or training requirements for the diffusion models. We also contribute MalHand datasets that contain generated images with a wide variety of malformed hands in several styles for hand detector training and hand restoration benchmarking, and demonstrate through qualitative and quantitative evaluation that HandCraft not only restores anatomical correctness but also maintains the integrity of the overall image. </p>
<blockquote>
<p>ç”Ÿæˆå¼æ–‡æœ¬åˆ°å›¾åƒæ¨¡å‹ï¼Œå¦‚Stable Diffusionï¼Œå·²ç»æ˜¾ç¤ºå‡ºç”Ÿæˆå¤šæ ·ã€é«˜è´¨é‡å›¾åƒçš„æ˜¾è‘—èƒ½åŠ›ã€‚ç„¶è€Œï¼Œå½“æ¶‰åŠåˆ°å‘ˆç°äººç±»æ‰‹éƒ¨æ—¶ï¼Œå®ƒä»¬å´è¡¨ç°å‡ºæƒŠäººçš„æ— èƒ½ï¼Œæ‰‹éƒ¨é€šå¸¸è§£å‰–ç»“æ„ä¸æ­£ç¡®æˆ–å¤„äºâ€œè¯¡å¼‚è°·â€ä¹‹ä¸­ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åä¸ºHandCraftçš„æ–¹æ³•ï¼Œç”¨äºä¿®å¤è¿™ç§ç•¸å½¢çš„æ‰‹éƒ¨ã€‚è¿™æ˜¯é€šè¿‡åˆ©ç”¨å‚æ•°æ¨¡å‹è‡ªåŠ¨æ„å»ºæ‰‹éƒ¨æ©è†œå’Œæ·±åº¦å›¾åƒä½œä¸ºæ¡ä»¶ä¿¡å·æ¥å®ç°çš„ï¼Œè¿™ä½¿å¾—åŸºäºæ‰©æ•£çš„å›¾åƒç¼–è¾‘å™¨èƒ½å¤Ÿä¿®å¤æ‰‹éƒ¨çš„è§£å‰–ç»“æ„å¹¶è°ƒæ•´å…¶å§¿æ€ï¼ŒåŒæ—¶æ— ç¼åœ°å°†æ›´æ”¹é›†æˆåˆ°åŸå§‹å›¾åƒä¸­ï¼Œä¿æŒå§¿æ€ã€é¢œè‰²å’Œé£æ ¼ã€‚æˆ‘ä»¬çš„å³æ’å³ç”¨å¼æ‰‹éƒ¨ä¿®å¤è§£å†³æ–¹æ¡ˆä¸ç°æœ‰çš„é¢„è®­ç»ƒæ‰©æ•£æ¨¡å‹å…¼å®¹ï¼Œä¿®å¤è¿‡ç¨‹é€šè¿‡é¿å…å¯¹æ‰©æ•£æ¨¡å‹çš„ä»»ä½•å¾®è°ƒæˆ–åŸ¹è®­è¦æ±‚ï¼Œä¿ƒè¿›äº†é‡‡ç”¨ã€‚æˆ‘ä»¬è¿˜è´¡çŒ®äº†MalHandæ•°æ®é›†ï¼Œå…¶ä¸­åŒ…å«å¤šç§é£æ ¼å’Œå¤šç§ç•¸å½¢æ‰‹éƒ¨çš„ç”Ÿæˆå›¾åƒï¼Œç”¨äºæ‰‹éƒ¨æ£€æµ‹å™¨è®­ç»ƒå’Œæ‰‹éƒ¨ä¿®å¤åŸºå‡†æµ‹è¯•ï¼Œå¹¶é€šè¿‡å®šæ€§å’Œå®šé‡è¯„ä¼°è¯æ˜ï¼ŒHandCraftä¸ä»…æ¢å¤äº†è§£å‰–ç»“æ„çš„æ­£ç¡®æ€§ï¼Œè¿˜ä¿æŒäº†æ•´ä½“å›¾åƒçš„å®Œæ•´æ€§ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2411.04332v3">PDF</a> 2025 IEEE&#x2F;CVF Winter Conference on Applications of Computer Vision   (WACV)</p>
<p><strong>Summary</strong></p>
<p>æ–‡æœ¬ä»‹ç»äº†Stable Diffusionç­‰ç”Ÿæˆå¼æ–‡æœ¬è½¬å›¾åƒæ¨¡å‹åœ¨ç”Ÿæˆå›¾åƒæ—¶å¯¹æ‰‹éƒ¨æ¸²æŸ“çš„ä¸è¶³ï¼Œæå‡ºäº†HandCraftæ–¹æ³•æ¥è§£å†³è¿™ä¸€é—®é¢˜ã€‚HandCrafté€šè¿‡è‡ªåŠ¨æ„å»ºæ‰‹éƒ¨æ©è†œå’Œæ·±åº¦å›¾åƒä½œä¸ºæ¡ä»¶ä¿¡å·ï¼Œåˆ©ç”¨å‚æ•°æ¨¡å‹å®ç°æ‰©æ•£å¼å›¾åƒç¼–è¾‘å™¨çš„ä¿®å¤æ‰‹éƒ¨è§£å‰–ç»“æ„å’Œè°ƒæ•´æ‰‹éƒ¨å§¿æ€çš„åŠŸèƒ½ï¼ŒåŒæ—¶æ— ç¼é›†æˆæ›´æ”¹åˆ°åŸå§‹å›¾åƒä¸­ã€‚è¯¥æ–¹æ³•å…¼å®¹ç°æœ‰é¢„è®­ç»ƒçš„æ‰©æ•£æ¨¡å‹ï¼Œæ— éœ€å¯¹å…¶è¿›è¡Œå¾®è°ƒæˆ–è®­ç»ƒè¦æ±‚ã€‚æ­¤å¤–ï¼Œè¯¥ç ”ç©¶è¿˜æä¾›äº†MalHandæ•°æ®é›†ï¼Œç”¨äºæ‰‹æ£€æµ‹å™¨è®­ç»ƒå’Œæ‰‹ä¿®å¤åŸºå‡†æµ‹è¯•ï¼Œå¹¶é€šè¿‡å®šæ€§å’Œå®šé‡è¯„ä¼°è¯æ˜äº†HandCraftæ–¹æ³•ä¸ä»…å¯æ¢å¤æ‰‹éƒ¨è§£å‰–æ­£ç¡®æ€§ï¼Œè¿˜èƒ½ä¿æŒæ•´ä½“å›¾åƒçš„å®Œæ•´æ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ç”Ÿæˆå¼æ–‡æœ¬è½¬å›¾åƒæ¨¡å‹å¦‚Stable Diffusionåœ¨æ¸²æŸ“æ‰‹éƒ¨æ—¶å­˜åœ¨ç¼ºé™·ã€‚</li>
<li>HandCraftæ–¹æ³•æ—¨åœ¨è§£å†³è¿™ä¸€é—®é¢˜ï¼Œé€šè¿‡æ„å»ºæ‰‹éƒ¨æ©è†œå’Œæ·±åº¦å›¾åƒä½œä¸ºæ¡ä»¶ä¿¡å·ï¼Œåˆ©ç”¨å‚æ•°æ¨¡å‹ä¿®å¤æ‰‹éƒ¨è§£å‰–ç»“æ„å’Œè°ƒæ•´å§¿æ€ã€‚</li>
<li>HandCraftæ–¹æ³•ä¸ç°æœ‰é¢„è®­ç»ƒçš„æ‰©æ•£æ¨¡å‹å…¼å®¹ï¼Œæ— éœ€è¿›è¡Œé¢å¤–çš„è®­ç»ƒæˆ–å¾®è°ƒã€‚</li>
<li>HandCraftèƒ½å¤Ÿåœ¨ä¿æŒæ•´ä½“å›¾åƒå®Œæ•´æ€§çš„åŒæ—¶ï¼Œæ¢å¤æ‰‹éƒ¨çš„è§£å‰–æ­£ç¡®æ€§ã€‚</li>
<li>ç ”ç©¶æä¾›äº†MalHandæ•°æ®é›†ï¼ŒåŒ…å«å¤šç§é£æ ¼å’Œå½¢æ€å¼‚å¸¸çš„æ‰‹éƒ¨å›¾åƒï¼Œç”¨äºæ‰‹æ£€æµ‹å™¨è®­ç»ƒå’Œæ‰‹ä¿®å¤åŸºå‡†æµ‹è¯•ã€‚</li>
<li>é€šè¿‡å®šæ€§å’Œå®šé‡è¯„ä¼°ï¼Œè¯æ˜äº†HandCraftæ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2411.04332">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-1e66585e4732eefd2adaa8ac467ac81e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-31ce498138ec528755ed81846a8237ac.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-f559207be7b17548e754a3efd0f51897.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-9495ee625d7e44e45b49c467f72e072b.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="Flex3D-Feed-Forward-3D-Generation-with-Flexible-Reconstruction-Model-and-Input-View-Curation"><a href="#Flex3D-Feed-Forward-3D-Generation-with-Flexible-Reconstruction-Model-and-Input-View-Curation" class="headerlink" title="Flex3D: Feed-Forward 3D Generation with Flexible Reconstruction Model   and Input View Curation"></a>Flex3D: Feed-Forward 3D Generation with Flexible Reconstruction Model   and Input View Curation</h2><p><strong>Authors:Junlin Han, Jianyuan Wang, Andrea Vedaldi, Philip Torr, Filippos Kokkinos</strong></p>
<p>Generating high-quality 3D content from text, single images, or sparse view images remains a challenging task with broad applications. Existing methods typically employ multi-view diffusion models to synthesize multi-view images, followed by a feed-forward process for 3D reconstruction. However, these approaches are often constrained by a small and fixed number of input views, limiting their ability to capture diverse viewpoints and, even worse, leading to suboptimal generation results if the synthesized views are of poor quality. To address these limitations, we propose Flex3D, a novel two-stage framework capable of leveraging an arbitrary number of high-quality input views. The first stage consists of a candidate view generation and curation pipeline. We employ a fine-tuned multi-view image diffusion model and a video diffusion model to generate a pool of candidate views, enabling a rich representation of the target 3D object. Subsequently, a view selection pipeline filters these views based on quality and consistency, ensuring that only the high-quality and reliable views are used for reconstruction. In the second stage, the curated views are fed into a Flexible Reconstruction Model (FlexRM), built upon a transformer architecture that can effectively process an arbitrary number of inputs. FlemRM directly outputs 3D Gaussian points leveraging a tri-plane representation, enabling efficient and detailed 3D generation. Through extensive exploration of design and training strategies, we optimize FlexRM to achieve superior performance in both reconstruction and generation tasks. Our results demonstrate that Flex3D achieves state-of-the-art performance, with a user study winning rate of over 92% in 3D generation tasks when compared to several of the latest feed-forward 3D generative models. </p>
<blockquote>
<p>ä»æ–‡æœ¬ã€å•å¼ å›¾åƒæˆ–ç¨€ç–è§†å›¾å›¾åƒç”Ÿæˆé«˜è´¨é‡3Då†…å®¹ä»ç„¶æ˜¯ä¸€ä¸ªå…·æœ‰å¹¿æ³›åº”ç”¨æŒ‘æˆ˜æ€§çš„ä»»åŠ¡ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸é‡‡ç”¨å¤šè§†å›¾æ‰©æ•£æ¨¡å‹åˆæˆå¤šè§†å›¾å›¾åƒï¼Œç„¶åè¿›è¡Œå‰é¦ˆè¿‡ç¨‹è¿›è¡Œ3Dé‡å»ºã€‚ç„¶è€Œï¼Œè¿™äº›æ–¹æ³•é€šå¸¸å—é™äºè¾“å…¥è§†å›¾çš„å°è€Œå›ºå®šçš„æ•°é‡ï¼Œå¯¼è‡´å®ƒä»¬æ— æ³•æ•æ‰å¤šç§è§†ç‚¹ï¼Œæ›´ç³Ÿç³•çš„æ˜¯ï¼Œå¦‚æœåˆæˆçš„è§†å›¾è´¨é‡è¾ƒå·®ï¼Œè¿˜ä¼šå¯¼è‡´ç”Ÿæˆç»“æœä¸ç†æƒ³ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†Flex3Dï¼Œè¿™æ˜¯ä¸€ä¸ªæ–°å‹çš„ä¸¤é˜¶æ®µæ¡†æ¶ï¼Œèƒ½å¤Ÿåˆ©ç”¨ä»»æ„æ•°é‡çš„é«˜è´¨é‡è¾“å…¥è§†å›¾ã€‚ç¬¬ä¸€é˜¶æ®µåŒ…æ‹¬å€™é€‰è§†å›¾ç”Ÿæˆå’Œç­›é€‰ç®¡é“ã€‚æˆ‘ä»¬é‡‡ç”¨å¾®è°ƒçš„å¤šè§†å›¾å›¾åƒæ‰©æ•£æ¨¡å‹å’Œè§†é¢‘æ‰©æ•£æ¨¡å‹æ¥ç”Ÿæˆå€™é€‰è§†å›¾æ± ï¼Œå®ç°å¯¹ç›®æ ‡3Då¯¹è±¡çš„ä¸°å¯Œè¡¨ç¤ºã€‚éšåï¼Œè§†å›¾é€‰æ‹©ç®¡é“æ ¹æ®è´¨é‡å’Œä¸€è‡´æ€§è¿‡æ»¤è¿™äº›è§†å›¾ï¼Œç¡®ä¿åªä½¿ç”¨é«˜è´¨é‡å’Œå¯é çš„è§†å›¾è¿›è¡Œé‡å»ºã€‚åœ¨ç¬¬äºŒé˜¶æ®µï¼Œç²¾é€‰çš„è§†å›¾è¢«è¾“å…¥åˆ°çµæ´»é‡å»ºæ¨¡å‹ï¼ˆFlexRMï¼‰ä¸­ï¼Œè¯¥æ¨¡å‹åŸºäºèƒ½å¤Ÿæœ‰æ•ˆå¤„ç†ä»»æ„æ•°é‡è¾“å…¥çš„å˜å‹å™¨æ¶æ„ã€‚FlemRMç›´æ¥è¾“å‡ºåˆ©ç”¨ä¸‰é‡å¹³é¢è¡¨ç¤ºçš„3Dé«˜æ–¯ç‚¹ï¼Œå®ç°é«˜æ•ˆä¸”è¯¦ç»†çš„3Dç”Ÿæˆã€‚é€šè¿‡è®¾è®¡å’Œè®­ç»ƒç­–ç•¥çš„å¹¿æ³›æ¢ç´¢ï¼Œæˆ‘ä»¬ä¼˜åŒ–äº†FlexRMï¼Œåœ¨é‡å»ºå’Œç”Ÿæˆä»»åŠ¡ä¸­éƒ½å®ç°äº†å“è¶Šçš„æ€§èƒ½ã€‚æˆ‘ä»¬çš„ç»“æœè¡¨æ˜ï¼ŒFlex3Dåœ¨æ€§èƒ½ä¸Šè¾¾åˆ°äº†æœ€æ–°æ°´å¹³ï¼Œåœ¨ä¸å‡ ç§æœ€æ–°çš„å‰é¦ˆ3Dç”Ÿæˆæ¨¡å‹çš„æ¯”è¾ƒä¸­ï¼Œç”¨æˆ·ç ”ç©¶è·èƒœç‡é«˜è¾¾92%ä»¥ä¸Šã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2410.00890v3">PDF</a> ICML 25. Project page: <a target="_blank" rel="noopener" href="https://junlinhan.github.io/projects/flex3d/">https://junlinhan.github.io/projects/flex3d/</a></p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºä¸€ç§åä¸ºFlex3Dçš„ä¸¤é˜¶æ®µæ¡†æ¶ï¼Œç”¨äºä»æ–‡æœ¬ã€å•å¼ å›¾åƒæˆ–ç¨€ç–è§†å›¾å›¾åƒç”Ÿæˆé«˜è´¨é‡3Då†…å®¹ã€‚ç¬¬ä¸€é˜¶æ®µé€šè¿‡å¾®è°ƒçš„å¤šè§†å›¾å›¾åƒæ‰©æ•£æ¨¡å‹å’Œè§†é¢‘æ‰©æ•£æ¨¡å‹ç”Ÿæˆå€™é€‰è§†å›¾ï¼Œå¹¶è¿›è¡Œç­›é€‰å’Œç­›é€‰ã€‚ç¬¬äºŒé˜¶æ®µä½¿ç”¨åŸºäºtransformeræ¶æ„çš„çµæ´»é‡å»ºæ¨¡å‹ï¼ˆFlexRMï¼‰å¤„ç†ä»»æ„æ•°é‡çš„è¾“å…¥è§†å›¾ï¼Œç›´æ¥è¾“å‡ºåŸºäºtri-planeè¡¨ç¤ºçš„3Dé«˜æ–¯ç‚¹äº‘ã€‚è¯¥æ–¹æ³•ä¼˜åŒ–äº†FlexRMçš„è®¾è®¡å’ŒåŸ¹è®­ç­–ç•¥ï¼Œåœ¨é‡å»ºå’Œç”Ÿæˆä»»åŠ¡ä¸­è¡¨ç°å‡ºå“è¶Šæ€§èƒ½ã€‚ç”¨æˆ·ç ”ç©¶ç»“æœæ˜¾ç¤ºï¼ŒFlex3Dåœ¨ä¸å…¶ä»–æœ€æ–°å‰é¦ˆ3Dç”Ÿæˆæ¨¡å‹çš„æ¯”è¾ƒä¸­èµ¢å¾—äº†è¶…è¿‡92%çš„èƒœç‡ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<p>ä»¥ä¸‹æ˜¯å…³äºFlex3Dæ¡†æ¶çš„å…³é”®è§è§£ï¼š</p>
<ol>
<li>Flex3Dæ˜¯ä¸€ä¸ªä¸¤é˜¶æ®µæ¡†æ¶ï¼Œå¯ä»¥å……åˆ†åˆ©ç”¨ä»»æ„æ•°é‡çš„é«˜è´¨é‡è¾“å…¥è§†å›¾ç”Ÿæˆé«˜è´¨é‡çš„3Då†…å®¹ã€‚</li>
<li>ç¬¬ä¸€é˜¶æ®µåŒ…æ‹¬å€™é€‰è§†å›¾ç”Ÿæˆå’Œç­›é€‰æµç¨‹ï¼Œé€šè¿‡å¾®è°ƒçš„å¤šè§†å›¾å›¾åƒæ‰©æ•£æ¨¡å‹å’Œè§†é¢‘æ‰©æ•£æ¨¡å‹æ¥ç”Ÿæˆä¸°å¯Œçš„ç›®æ ‡3Då¯¹è±¡è¡¨ç¤ºã€‚</li>
<li>ç¬¬äºŒé˜¶æ®µä½¿ç”¨çµæ´»é‡å»ºæ¨¡å‹ï¼ˆFlexRMï¼‰å¤„ç†ç­›é€‰åçš„è§†å›¾ï¼Œå¹¶ç›´æ¥è¾“å‡ºåŸºäºtri-planeè¡¨ç¤ºçš„3Dé«˜æ–¯ç‚¹äº‘ã€‚è¯¥æ¨¡å‹å¯ä»¥æœ‰æ•ˆå¤„ç†ä»»æ„æ•°é‡çš„è¾“å…¥ï¼Œå¹¶å®ç°äº†é«˜æ•ˆçš„è¯¦ç»†3Dç”Ÿæˆã€‚</li>
<li>FlexRMçš„ä¼˜åŒ–è®¾è®¡åŒ…æ‹¬åŸ¹è®­ç­–ç•¥çš„è°ƒæ•´ï¼Œä½¿å…¶åœ¨é‡å»ºå’Œç”Ÿæˆä»»åŠ¡ä¸­è¡¨ç°å‡ºå“è¶Šæ€§èƒ½ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2410.00890">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-90b6efa6b95dc58dfdf4f7618662e83e.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-cf07cc1d61f98f2658b4a5cb3de6e227.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-54e208d4337574a47319e32da5be3849.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-5dc69b67b56980918bed3f8de9aed560.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-950c93122d34728c65a73de25dc9adbb.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="Conditional-Image-Synthesis-with-Diffusion-Models-A-Survey"><a href="#Conditional-Image-Synthesis-with-Diffusion-Models-A-Survey" class="headerlink" title="Conditional Image Synthesis with Diffusion Models: A Survey"></a>Conditional Image Synthesis with Diffusion Models: A Survey</h2><p><strong>Authors:Zheyuan Zhan, Defang Chen, Jian-Ping Mei, Zhenghe Zhao, Jiawei Chen, Chun Chen, Siwei Lyu, Can Wang</strong></p>
<p>Conditional image synthesis based on user-specified requirements is a key component in creating complex visual content. In recent years, diffusion-based generative modeling has become a highly effective way for conditional image synthesis, leading to exponential growth in the literature. However, the complexity of diffusion-based modeling, the wide range of image synthesis tasks, and the diversity of conditioning mechanisms present significant challenges for researchers to keep up with rapid developments and to understand the core concepts on this topic. In this survey, we categorize existing works based on how conditions are integrated into the two fundamental components of diffusion-based modeling, $\textit{i.e.}$, the denoising network and the sampling process. We specifically highlight the underlying principles, advantages, and potential challenges of various conditioning approaches during the training, re-purposing, and specialization stages to construct a desired denoising network. We also summarize six mainstream conditioning mechanisms in the sampling process. All discussions are centered around popular applications. Finally, we pinpoint several critical yet still unsolved problems and suggest some possible solutions for future research. Our reviewed works are itemized at <a target="_blank" rel="noopener" href="https://github.com/zju-pi/Awesome-Conditional-Diffusion-Models">https://github.com/zju-pi/Awesome-Conditional-Diffusion-Models</a>. </p>
<blockquote>
<p>åŸºäºç”¨æˆ·æŒ‡å®šè¦æ±‚çš„æœ‰æ¡ä»¶å›¾åƒåˆæˆæ˜¯åˆ›å»ºå¤æ‚è§†è§‰å†…å®¹çš„å…³é”®ç»„æˆéƒ¨åˆ†ã€‚è¿‘å¹´æ¥ï¼ŒåŸºäºæ‰©æ•£çš„ç”Ÿæˆæ¨¡å‹å·²æˆä¸ºæœ‰æ¡ä»¶å›¾åƒåˆæˆçš„é«˜æ•ˆæ–¹å¼ï¼Œç›¸å…³æ–‡çŒ®å‘ˆæŒ‡æ•°çº§å¢é•¿ã€‚ç„¶è€Œï¼ŒåŸºäºæ‰©æ•£çš„å»ºæ¨¡å¤æ‚æ€§ã€å›¾åƒåˆæˆä»»åŠ¡çš„å¹¿æ³›æ€§ä»¥åŠè°ƒèŠ‚æœºåˆ¶çš„å¤šæ ·æ€§ï¼Œä¸ºç ”ç©¶è€…å¸¦æ¥äº†è·Ÿä¸Šå¿«é€Ÿå‘å±•å’Œäº†è§£æ ¸å¿ƒæ¦‚å¿µçš„é‡å¤§æŒ‘æˆ˜ã€‚åœ¨è¿™é¡¹è°ƒæŸ¥ä¸­ï¼Œæˆ‘ä»¬æ ¹æ®æ¡ä»¶æ˜¯å¦‚ä½•é›†æˆåˆ°åŸºäºæ‰©æ•£å»ºæ¨¡çš„ä¸¤ä¸ªåŸºæœ¬ç»„æˆéƒ¨åˆ†ï¼ˆå³å»å™ªç½‘ç»œå’Œé‡‡æ ·è¿‡ç¨‹ï¼‰æ¥å¯¹ç°æœ‰å·¥ä½œè¿›è¡Œå½’ç±»ã€‚æˆ‘ä»¬ç‰¹åˆ«å¼ºè°ƒåœ¨è®­ç»ƒã€é‡æ–°åˆ©ç”¨å’Œä¸“ä¸šåŒ–é˜¶æ®µå„ç§è°ƒèŠ‚æ–¹æ³•çš„å†…åœ¨åŸç†ã€ä¼˜ç‚¹å’Œæ½œåœ¨æŒ‘æˆ˜ï¼Œä»¥æ„å»ºæ‰€éœ€çš„å»å™ªç½‘ç»œã€‚æˆ‘ä»¬è¿˜æ€»ç»“äº†é‡‡æ ·è¿‡ç¨‹ä¸­å…­ç§ä¸»æµçš„è°ƒèŠ‚æœºåˆ¶ã€‚æ‰€æœ‰çš„è®¨è®ºéƒ½å›´ç»•çƒ­é—¨åº”ç”¨å±•å¼€ã€‚æœ€åï¼Œæˆ‘ä»¬æŒ‡å‡ºäº†å‡ ä¸ªå…³é”®ä½†å°šæœªè§£å†³çš„é—®é¢˜ï¼Œå¹¶ä¸ºæœªæ¥çš„ç ”ç©¶æå‡ºäº†å¯èƒ½çš„è§£å†³æ–¹æ¡ˆã€‚æˆ‘ä»¬è¯„è¿°çš„ä½œå“è¯¦åˆ—åœ¨<a target="_blank" rel="noopener" href="https://github.com/zju-pi/Awesome-Conditional-Diffusion-Models%E3%80%82">https://github.com/zju-pi/Awesome-Conditional-Diffusion-Modelsã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2409.19365v3">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ç»¼è¿°äº†åŸºäºæ‰©æ•£æ¨¡å‹çš„å›¾åƒåˆæˆæŠ€æœ¯ï¼Œè¯¦ç»†ä»‹ç»äº†å¦‚ä½•å°†æ¡ä»¶å› ç´ èå…¥æ‰©æ•£æ¨¡å‹çš„ä¸¤ä¸ªåŸºæœ¬ç»„æˆéƒ¨åˆ†â€”â€”å»å™ªç½‘ç»œå’Œé‡‡æ ·è¿‡ç¨‹ã€‚æ–‡ç« é‡ç‚¹ä»‹ç»äº†ä¸åŒæ¡ä»¶ä¸‹çš„è®­ç»ƒã€å†åˆ©ç”¨å’Œä¸“ä¸šåŒ–é˜¶æ®µçš„åŸç†ã€ä¼˜åŠ¿å’Œæ½œåœ¨æŒ‘æˆ˜ï¼Œå¹¶æ€»ç»“äº†å…­ç§ä¸»æµçš„é‡‡æ ·è¿‡ç¨‹ä¸­çš„æ¡ä»¶æœºåˆ¶ã€‚æœ¬æ–‡æ—¨åœ¨å¸®åŠ©è¯»è€…äº†è§£æ‰©æ•£æ¨¡å‹åœ¨å›¾åƒåˆæˆé¢†åŸŸçš„åº”ç”¨å’Œå‘å±•ç°çŠ¶ï¼ŒåŒæ—¶æä¾›äº†ä¸€äº›æœªæ¥ç ”ç©¶å¯èƒ½çš„è§£å†³æ–¹æ¡ˆã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>æ‰©æ•£æ¨¡å‹å·²æˆä¸ºæ¡ä»¶å›¾åƒåˆæˆçš„ä¸€ç§é«˜æ•ˆæ–¹æ³•ï¼Œé©±åŠ¨äº†å¤§é‡æ–‡çŒ®çš„å‡ºç°ã€‚</li>
<li>æ¡ä»¶å› ç´ è¢«èå…¥æ‰©æ•£æ¨¡å‹çš„ä¸¤ä¸ªåŸºæœ¬ç»„æˆéƒ¨åˆ†ï¼šå»å™ªç½‘ç»œå’Œé‡‡æ ·è¿‡ç¨‹ã€‚</li>
<li>æ–‡ç« è¯¦ç»†é˜è¿°äº†ä¸åŒæ¡ä»¶ä¸‹è®­ç»ƒã€å†åˆ©ç”¨å’Œä¸“ä¸šåŒ–é˜¶æ®µçš„åŸç†ã€ä¼˜åŠ¿å’Œæ½œåœ¨æŒ‘æˆ˜ã€‚</li>
<li>æ€»ç»“äº†å…­ç§ä¸»æµçš„é‡‡æ ·è¿‡ç¨‹ä¸­çš„æ¡ä»¶æœºåˆ¶ã€‚</li>
<li>æ–‡ç« å›´ç»•æµè¡Œåº”ç”¨è¿›è¡Œè®¨è®ºã€‚</li>
<li>æŒ‡å‡ºäº†ä¸€äº›å…³é”®ä½†å°šæœªè§£å†³çš„é—®é¢˜ï¼Œå¹¶ä¸ºæœªæ¥ç ”ç©¶æä¾›äº†å¯èƒ½çš„è§£å†³æ–¹æ¡ˆã€‚</li>
<li>æ¨èçš„å®¡æŸ¥å·¥ä½œåˆ—è¡¨å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/zju-pi/Awesome-Conditional-Diffusion-Models%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/zju-pi/Awesome-Conditional-Diffusion-Modelsæ‰¾åˆ°ã€‚</a></li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2409.19365">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-d8d027299fae999a1870cb0b97b4f828.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-f282647e6696d641d0be298ba23a462e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-06d48b0750aed60e959633abf388f971.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="LaWa-Using-Latent-Space-for-In-Generation-Image-Watermarking"><a href="#LaWa-Using-Latent-Space-for-In-Generation-Image-Watermarking" class="headerlink" title="LaWa: Using Latent Space for In-Generation Image Watermarking"></a>LaWa: Using Latent Space for In-Generation Image Watermarking</h2><p><strong>Authors:Ahmad Rezaei, Mohammad Akbari, Saeed Ranjbar Alvar, Arezou Fatemi, Yong Zhang</strong></p>
<p>With generative models producing high quality images that are indistinguishable from real ones, there is growing concern regarding the malicious usage of AI-generated images. Imperceptible image watermarking is one viable solution towards such concerns. Prior watermarking methods map the image to a latent space for adding the watermark. Moreover, Latent Diffusion Models (LDM) generate the image in the latent space of a pre-trained autoencoder. We argue that this latent space can be used to integrate watermarking into the generation process. To this end, we present LaWa, an in-generation image watermarking method designed for LDMs. By using coarse-to-fine watermark embedding modules, LaWa modifies the latent space of pre-trained autoencoders and achieves high robustness against a wide range of image transformations while preserving perceptual quality of the image. We show that LaWa can also be used as a general image watermarking method. Through extensive experiments, we demonstrate that LaWa outperforms previous works in perceptual quality, robustness against attacks, and computational complexity, while having very low false positive rate. Code is available here. </p>
<blockquote>
<p>éšç€ç”Ÿæˆæ¨¡å‹äº§ç”Ÿçš„å›¾åƒè´¨é‡è¶Šæ¥è¶Šé«˜ï¼Œä¸çœŸå®å›¾åƒæ— æ³•åŒºåˆ†ï¼Œäººä»¬è¶Šæ¥è¶Šæ‹…å¿ƒAIç”Ÿæˆå›¾åƒè¢«æ¶æ„ä½¿ç”¨çš„é—®é¢˜ã€‚ä¸æ˜“å¯Ÿè§‰çš„å›¾åƒæ°´å°æŠ€æœ¯æ˜¯ä¸€ç§å¯è¡Œçš„è§£å†³æ–¹æ¡ˆã€‚ä»¥å¾€çš„æ°´å°æ–¹æ³•å°†å›¾åƒæ˜ å°„åˆ°æ½œåœ¨ç©ºé—´ä»¥æ·»åŠ æ°´å°ã€‚æ­¤å¤–ï¼Œæ½œåœ¨æ‰©æ•£æ¨¡å‹ï¼ˆLDMï¼‰åœ¨é¢„è®­ç»ƒè‡ªç¼–ç å™¨çš„æ½œåœ¨ç©ºé—´ä¸­ç”Ÿæˆå›¾åƒã€‚æˆ‘ä»¬è®¤ä¸ºï¼Œå¯ä»¥åˆ©ç”¨è¿™ä¸ªæ½œåœ¨ç©ºé—´å°†æ°´å°é›†æˆåˆ°ç”Ÿæˆè¿‡ç¨‹ä¸­ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬æå‡ºäº†LaWaï¼Œè¿™æ˜¯ä¸€ç§ä¸ºLDMè®¾è®¡çš„åœ¨ç”Ÿæˆå›¾åƒè¿‡ç¨‹ä¸­çš„æ°´å°æ–¹æ³•ã€‚é€šè¿‡ä½¿ç”¨ä»ç²—ç³™åˆ°ç²¾ç»†çš„æ°´å°åµŒå…¥æ¨¡å—ï¼ŒLaWaä¿®æ”¹äº†é¢„è®­ç»ƒè‡ªç¼–ç å™¨çš„æ½œåœ¨ç©ºé—´ï¼Œå¹¶åœ¨å¯¹æŠ—å„ç§å›¾åƒè½¬æ¢æ—¶å®ç°äº†é«˜åº¦çš„ç¨³å¥æ€§ï¼ŒåŒæ—¶ä¿æŒäº†å›¾åƒçš„æ„ŸçŸ¥è´¨é‡ã€‚æˆ‘ä»¬å±•ç¤ºLaWaä¹Ÿå¯ä»¥ä½œä¸ºä¸€ç§é€šç”¨çš„å›¾åƒæ°´å°æ–¹æ³•ä½¿ç”¨ã€‚é€šè¿‡å¤§é‡å®éªŒï¼Œæˆ‘ä»¬è¯æ˜LaWaåœ¨æ„ŸçŸ¥è´¨é‡ã€å¯¹æŠ—æ”»å‡»çš„ç¨³å¥æ€§å’Œè®¡ç®—å¤æ‚æ€§æ–¹é¢ä¼˜äºä»¥å‰çš„å·¥ä½œï¼ŒåŒæ—¶è¯¯æŠ¥ç‡éå¸¸ä½ã€‚ä»£ç å¯åœ¨æ­¤å¤„è·å–ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2408.05868v3">PDF</a> Accepted to ECCV 2024</p>
<p><strong>Summary</strong><br>     éšç€ç”Ÿæˆæ¨¡å‹äº§å‡ºé«˜è´¨é‡ã€éš¾ä»¥è¾¨åˆ«çœŸä¼ªçš„å›¾åƒï¼Œäººä»¬è¶Šæ¥è¶Šæ‹…å¿§AIç”Ÿæˆå›¾åƒè¢«æ¶æ„ä½¿ç”¨çš„é—®é¢˜ã€‚éšå½¢å›¾åƒæ°´å°æŠ€æœ¯æ˜¯ä¸€ç§å¯è¡Œçš„è§£å†³æ–¹æ¡ˆã€‚ä»¥å‰çš„æ°´å°æ–¹æ³•å°†å›¾åƒæ˜ å°„åˆ°æ½œåœ¨ç©ºé—´ä»¥æ·»åŠ æ°´å°ã€‚æ­¤å¤–ï¼Œæ½œåœ¨æ‰©æ•£æ¨¡å‹ï¼ˆLDMï¼‰åœ¨é¢„è®­ç»ƒè‡ªç¼–ç å™¨çš„æ½œåœ¨ç©ºé—´ä¸­ç”Ÿæˆå›¾åƒã€‚æˆ‘ä»¬è®¤ä¸ºå¯ä»¥åˆ©ç”¨è¿™ä¸ªæ½œåœ¨ç©ºé—´å°†æ°´å°é›†æˆåˆ°ç”Ÿæˆè¿‡ç¨‹ä¸­ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬æå‡ºäº†é¢å‘LDMçš„ç”Ÿæˆä¸­å›¾åƒæ°´å°æ–¹æ³•LaWaã€‚é€šè¿‡ä½¿ç”¨ç²—ç»†ç»“åˆçš„æ°´å°åµŒå…¥æ¨¡å—ï¼ŒLaWaä¿®æ”¹äº†é¢„è®­ç»ƒè‡ªç¼–ç å™¨çš„æ½œåœ¨ç©ºé—´ï¼Œå¯¹å„ç§å›¾åƒå˜æ¢å…·æœ‰é«˜åº¦çš„é²æ£’æ€§ï¼ŒåŒæ—¶ä¿æŒäº†å›¾åƒæ„ŸçŸ¥è´¨é‡ã€‚æˆ‘ä»¬è¿˜è¯æ˜äº†LaWaä¹Ÿå¯ä»¥ä½œä¸ºä¸€ç§é€šç”¨çš„å›¾åƒæ°´å°æ–¹æ³•ä½¿ç”¨ã€‚é€šè¿‡å¤§é‡å®éªŒï¼Œæˆ‘ä»¬è¯æ˜äº†LaWaåœ¨æ„ŸçŸ¥è´¨é‡ã€æŠ—æ”»å‡»æ€§ã€è®¡ç®—å¤æ‚æ€§æ–¹é¢ä¼˜äºä»¥å‰çš„å·¥ä½œï¼Œå¹¶ä¸”å…·æœ‰æä½çš„è¯¯æŠ¥ç‡ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ç”Ÿæˆæ¨¡å‹äº§å‡ºçš„é«˜è´¨é‡å›¾åƒéš¾ä»¥è¾¨åˆ«çœŸä¼ªï¼Œå¼•å‘å¯¹æ¶æ„ä½¿ç”¨çš„æ‹…å¿§ã€‚</li>
<li>éšå½¢å›¾åƒæ°´å°æŠ€æœ¯æ˜¯è§£å†³è¿™ä¸€é—®é¢˜çš„å¯è¡Œæ–¹æ¡ˆã€‚</li>
<li>LaWaæ˜¯ä¸€ç§é¢å‘æ½œåœ¨æ‰©æ•£æ¨¡å‹ï¼ˆLDMï¼‰çš„ç”Ÿæˆä¸­å›¾åƒæ°´å°æ–¹æ³•ã€‚</li>
<li>LaWaåˆ©ç”¨ç²—ç»†ç»“åˆçš„æ°´å°åµŒå…¥æ¨¡å—ä¿®æ”¹é¢„è®­ç»ƒè‡ªç¼–ç å™¨çš„æ½œåœ¨ç©ºé—´ã€‚</li>
<li>LaWaå¯¹å„ç§å›¾åƒå˜æ¢å…·æœ‰é«˜åº¦çš„é²æ£’æ€§ï¼ŒåŒæ—¶ä¿æŒå›¾åƒæ„ŸçŸ¥è´¨é‡ã€‚</li>
<li>LaWaå¯ä½œä¸ºé€šç”¨å›¾åƒæ°´å°æ–¹æ³•ä½¿ç”¨ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2408.05868">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-8ba9a30eda06ce466b136906dbb06ef8.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-3aabf8bcf63f3cffe3abd553f29f3bc9.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-6fbea1d802bc4934f95f063d2242a526.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-5f01d92700a1f2c299a8452272c3ac9b.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="SemanticDraw-Towards-Real-Time-Interactive-Content-Creation-from-Image-Diffusion-Models"><a href="#SemanticDraw-Towards-Real-Time-Interactive-Content-Creation-from-Image-Diffusion-Models" class="headerlink" title="SemanticDraw: Towards Real-Time Interactive Content Creation from Image   Diffusion Models"></a>SemanticDraw: Towards Real-Time Interactive Content Creation from Image   Diffusion Models</h2><p><strong>Authors:Jaerin Lee, Daniel Sungho Jung, Kanggeon Lee, Kyoung Mu Lee</strong></p>
<p>We introduce SemanticDraw, a new paradigm of interactive content creation where high-quality images are generated in near real-time from given multiple hand-drawn regions, each encoding prescribed semantic meaning. In order to maximize the productivity of content creators and to fully realize their artistic imagination, it requires both quick interactive interfaces and fine-grained regional controls in their tools. Despite astonishing generation quality from recent diffusion models, we find that existing approaches for regional controllability are very slow (52 seconds for $512 \times 512$ image) while not compatible with acceleration methods such as LCM, blocking their huge potential in interactive content creation. From this observation, we build our solution for interactive content creation in two steps: (1) we establish compatibility between region-based controls and acceleration techniques for diffusion models, maintaining high fidelity of multi-prompt image generation with $\times 10$ reduced number of inference steps, (2) we increase the generation throughput with our new multi-prompt stream batch pipeline, enabling low-latency generation from multiple, region-based text prompts on a single RTX 2080 Ti GPU. Our proposed framework is generalizable to any existing diffusion models and acceleration schedulers, allowing sub-second (0.64 seconds) image content creation application upon well-established image diffusion models. Our project page is: <a target="_blank" rel="noopener" href="https://jaerinlee.com/research/semantic-draw">https://jaerinlee.com/research/semantic-draw</a> </p>
<blockquote>
<p>æˆ‘ä»¬ä»‹ç»äº†SemanticDrawï¼Œè¿™æ˜¯ä¸€ç§æ–°çš„äº¤äº’å¼å†…å®¹åˆ›å»ºèŒƒå¼ï¼Œå®ƒå¯ä»¥ä»ç»™å®šçš„å¤šä¸ªæ‰‹ç»˜åŒºåŸŸä¸­å®æ—¶ç”Ÿæˆé«˜è´¨é‡å›¾åƒï¼Œæ¯ä¸ªåŒºåŸŸéƒ½ç¼–ç äº†è§„å®šçš„è¯­ä¹‰å«ä¹‰ã€‚ä¸ºäº†æœ€å¤§åŒ–å†…å®¹åˆ›ä½œè€…çš„ç”Ÿäº§åŠ›å¹¶å®ç°ä»–ä»¬çš„è‰ºæœ¯æƒ³è±¡åŠ›ï¼Œè¿™éœ€è¦å¿«é€Ÿçš„äº¤äº’å¼æ¥å£å’Œå·¥å…·ä¸­çš„ç²¾ç»†åŒºåŸŸæ§åˆ¶ã€‚å°½ç®¡æœ€è¿‘çš„æ‰©æ•£æ¨¡å‹äº§ç”Ÿäº†æƒŠäººçš„ç”Ÿæˆè´¨é‡ï¼Œä½†æˆ‘ä»¬å‘ç°ç°æœ‰çš„åŒºåŸŸå¯æ§æ€§æ–¹æ³•éå¸¸ç¼“æ…¢ï¼ˆå¯¹äº512x512å›¾åƒéœ€è¦52ç§’ï¼‰ï¼Œè€Œä¸”ä¸å…¼å®¹å¦‚LCMç­‰åŠ é€Ÿæ–¹æ³•ï¼Œè¿™é˜»ç¢äº†å®ƒä»¬åœ¨äº¤äº’å¼å†…å®¹åˆ›å»ºä¸­çš„å·¨å¤§æ½œåŠ›ã€‚åŸºäºè¿™äº›è§‚å¯Ÿï¼Œæˆ‘ä»¬å°†äº¤äº’å¼å†…å®¹åˆ›å»ºçš„è§£å†³æ–¹æ¡ˆåˆ†ä¸ºä¸¤æ­¥æ„å»ºï¼šé¦–å…ˆï¼Œæˆ‘ä»¬å»ºç«‹äº†åŸºäºåŒºåŸŸçš„æ§åˆ¶ä¸æ‰©æ•£æ¨¡å‹çš„åŠ é€ŸæŠ€æœ¯ä¹‹é—´çš„å…¼å®¹æ€§ï¼Œé€šè¿‡å‡å°‘æ¨ç†æ­¥éª¤çš„æ•°é‡ï¼ˆå‡å°‘10å€ï¼‰ï¼Œä¿æŒå¤šæç¤ºå›¾åƒç”Ÿæˆçš„é«˜ä¿çœŸåº¦ï¼›å…¶æ¬¡ï¼Œæˆ‘ä»¬ä½¿ç”¨äº†æ–°çš„å¤šæç¤ºæµæ‰¹å¤„ç†ç®¡é“ï¼Œæé«˜äº†ç”Ÿæˆååé‡ï¼Œèƒ½å¤Ÿåœ¨å•ä¸ªRTX 2080 Ti GPUä¸Šå®ç°å¤šä¸ªåŸºäºåŒºåŸŸçš„æ–‡æœ¬æç¤ºçš„ä½å»¶è¿Ÿç”Ÿæˆã€‚æˆ‘ä»¬æå‡ºçš„æ¡†æ¶å¯ä»¥åº”ç”¨äºä»»ä½•ç°æœ‰çš„æ‰©æ•£æ¨¡å‹å’ŒåŠ é€Ÿè°ƒåº¦å™¨ï¼Œå…è®¸åœ¨æˆç†Ÿçš„å›¾åƒæ‰©æ•£æ¨¡å‹ä¸Šè¿›è¡Œå­ç§’çº§ï¼ˆ0.64ç§’ï¼‰çš„å›¾åƒå†…å®¹åˆ›å»ºåº”ç”¨ã€‚æˆ‘ä»¬çš„é¡¹ç›®é¡µé¢æ˜¯ï¼š<a target="_blank" rel="noopener" href="https://jaerinlee.com/research/semantic-draw">https://jaerinlee.com/research/semantic-draw</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2403.09055v4">PDF</a> CVPR 2025 camera ready</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†SemanticDrawï¼Œè¿™æ˜¯ä¸€ç§æ–°çš„äº¤äº’å¼å†…å®¹åˆ›å»ºèŒƒå¼ã€‚å®ƒåˆ©ç”¨æ‰©æ•£æ¨¡å‹ï¼Œæ ¹æ®å¤šä¸ªæ‰‹ç»˜åŒºåŸŸç”Ÿæˆé«˜è´¨é‡å›¾åƒï¼Œæ¯ä¸ªåŒºåŸŸéƒ½æœ‰è§„å®šçš„è¯­ä¹‰æ„ä¹‰ã€‚ä¸ºäº†æé«˜å†…å®¹åˆ›ä½œè€…çš„æ•ˆç‡å’Œå®ç°ä»–ä»¬çš„è‰ºæœ¯æƒ³è±¡åŠ›ï¼Œéœ€è¦å¿«é€Ÿäº¤äº’å¼æ¥å£å’Œå·¥å…·ä¸­çš„ç²¾ç»†åŒºåŸŸæ§åˆ¶ã€‚ç°æœ‰æ‰©æ•£æ¨¡å‹çš„åŒºåŸŸæ§åˆ¶æ–¹æ³•è™½ç„¶ç”Ÿæˆè´¨é‡æƒŠäººï¼Œä½†é€Ÿåº¦è¾ƒæ…¢ï¼Œä¸”ä¸å…¼å®¹åŠ é€Ÿæ–¹æ³•ï¼Œå¦‚LCMï¼Œé˜»ç¢äº†å®ƒä»¬åœ¨äº¤äº’å¼å†…å®¹åˆ›å»ºä¸­çš„å·¨å¤§æ½œåŠ›ã€‚å› æ­¤ï¼Œè¯¥ç ”ç©¶é€šè¿‡å»ºç«‹åŒºåŸŸæ§åˆ¶ä¸åŠ é€ŸæŠ€æœ¯ä¹‹é—´çš„å…¼å®¹æ€§ï¼Œå‡å°‘æ¨ç†æ­¥éª¤æ•°é‡ï¼Œæé«˜å¤šæç¤ºæµæ‰¹é‡ç®¡é“ç”Ÿæˆååé‡ï¼Œå®ç°äº†ä½å»¶è¿Ÿçš„å¤šåŒºåŸŸæ–‡æœ¬æç¤ºç”Ÿæˆã€‚è¯¥ç ”ç©¶æå‡ºçš„æ¡†æ¶å¯å¹¿æ³›åº”ç”¨äºç°æœ‰æ‰©æ•£æ¨¡å‹å’ŒåŠ é€Ÿè°ƒåº¦å™¨ï¼Œå…è®¸åœ¨æˆç†Ÿçš„å›¾åƒæ‰©æ•£æ¨¡å‹ä¸Šå®ç°å­ç§’çº§ï¼ˆ0.64ç§’ï¼‰çš„å›¾åƒå†…å®¹åˆ›å»ºåº”ç”¨ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>SemanticDrawæ˜¯ä¸€ç§åŸºäºæ‰©æ•£æ¨¡å‹çš„æ–°çš„äº¤äº’å¼å†…å®¹åˆ›å»ºæ–¹æ³•ï¼Œå¯ä»¥ä»å¤šä¸ªæ‰‹ç»˜åŒºåŸŸç”Ÿæˆé«˜è´¨é‡å›¾åƒã€‚</li>
<li>ç°æœ‰æ‰©æ•£æ¨¡å‹çš„åŒºåŸŸæ§åˆ¶æ–¹æ³•è™½ç„¶ç”Ÿæˆè´¨é‡é«˜ï¼Œä½†é€Ÿåº¦æ…¢ï¼Œä¸”ä¸å…¼å®¹ç°æœ‰åŠ é€Ÿæ–¹æ³•ã€‚</li>
<li>ç ”ç©¶è€…é€šè¿‡å»ºç«‹åŒºåŸŸæ§åˆ¶ä¸åŠ é€ŸæŠ€æœ¯ä¹‹é—´çš„å…¼å®¹æ€§æ¥æé«˜æ•ˆç‡ã€‚</li>
<li>é€šè¿‡å‡å°‘æ¨ç†æ­¥éª¤æ•°é‡ï¼Œç»´æŒå¤šæç¤ºå›¾åƒç”Ÿæˆçš„é«˜ä¿çœŸåº¦ã€‚</li>
<li>æ–°çš„å¤šæç¤ºæµæ‰¹é‡ç®¡é“æé«˜äº†ç”Ÿæˆååé‡ï¼Œå®ç°äº†ä½å»¶è¿Ÿçš„å¤šåŒºåŸŸæ–‡æœ¬æç¤ºç”Ÿæˆã€‚</li>
<li>è¯¥ç ”ç©¶æå‡ºçš„æ¡†æ¶å¯å¹¿æ³›åº”ç”¨äºç°æœ‰çš„æ‰©æ•£æ¨¡å‹å’ŒåŠ é€Ÿè°ƒåº¦å™¨ã€‚</li>
<li>åœ¨æˆç†Ÿçš„å›¾åƒæ‰©æ•£æ¨¡å‹ä¸Šï¼Œèƒ½å¤Ÿå®ç°å­ç§’çº§ï¼ˆ0.64ç§’ï¼‰çš„å›¾åƒå†…å®¹åˆ›å»ºåº”ç”¨ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2403.09055">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-f7b91bfcdbb84be89cfb9ed2b92a6bfe.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-38067a34fd290635b6da1362323bf686.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ccd86768c8b44865ee38c47109727b1a.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-c7db3232ba790c6d630c9416c8bfc890.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-a2ad0e342308f900da738ab691f88959.jpg" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="Detecting-Multimedia-Generated-by-Large-AI-Models-A-Survey"><a href="#Detecting-Multimedia-Generated-by-Large-AI-Models-A-Survey" class="headerlink" title="Detecting Multimedia Generated by Large AI Models: A Survey"></a>Detecting Multimedia Generated by Large AI Models: A Survey</h2><p><strong>Authors:Li Lin, Neeraj Gupta, Yue Zhang, Hainan Ren, Chun-Hao Liu, Feng Ding, Xin Wang, Xin Li, Luisa Verdoliva, Shu Hu</strong></p>
<p>The rapid advancement of Large AI Models (LAIMs), particularly diffusion models and large language models, has marked a new era where AI-generated multimedia is increasingly integrated into various aspects of daily life. Although beneficial in numerous fields, this content presents significant risks, including potential misuse, societal disruptions, and ethical concerns. Consequently, detecting multimedia generated by LAIMs has become crucial, with a marked rise in related research. Despite this, there remains a notable gap in systematic surveys that focus specifically on detecting LAIM-generated multimedia. Addressing this, we provide the first survey to comprehensively cover existing research on detecting multimedia (such as text, images, videos, audio, and multimodal content) created by LAIMs. Specifically, we introduce a novel taxonomy for detection methods, categorized by media modality, and aligned with two perspectives: pure detection (aiming to enhance detection performance) and beyond detection (adding attributes like generalizability, robustness, and interpretability to detectors). Additionally, we have presented a brief overview of generation mechanisms, public datasets, online detection tools, and evaluation metrics to provide a valuable resource for researchers and practitioners in this field. Most importantly, we offer a focused analysis from a social media perspective to highlight their broader societal impact. Furthermore, we identify current challenges in detection and propose directions for future research that address unexplored, ongoing, and emerging issues in detecting multimedia generated by LAIMs. Our aim for this survey is to fill an academic gap and contribute to global AI security efforts, helping to ensure the integrity of information in the digital realm. The project link is <a target="_blank" rel="noopener" href="https://github.com/Purdue-M2/Detect-LAIM-generated-Multimedia-Survey">https://github.com/Purdue-M2/Detect-LAIM-generated-Multimedia-Survey</a>. </p>
<blockquote>
<p>å¤§å‹äººå·¥æ™ºèƒ½æ¨¡å‹ï¼ˆLAIMsï¼‰çš„å¿«é€Ÿå‘å±•ï¼Œç‰¹åˆ«æ˜¯æ‰©æ•£æ¨¡å‹å’Œå¤§è¯­è¨€æ¨¡å‹ï¼Œæ ‡å¿—ç€ä¸€ä¸ªäººå·¥æ™ºèƒ½ç”Ÿæˆå¤šåª’ä½“æ—¥ç›Šèå…¥æ—¥å¸¸ç”Ÿæ´»çš„å…¨æ–°æ—¶ä»£çš„æ¥ä¸´ã€‚å°½ç®¡è¿™äº›æŠ€æœ¯åœ¨è®¸å¤šé¢†åŸŸéƒ½å¸¦æ¥äº†å¥½å¤„ï¼Œä½†è¿™äº›å†…å®¹ä¹Ÿå­˜åœ¨é‡å¤§é£é™©ï¼ŒåŒ…æ‹¬æ½œåœ¨è¯¯ç”¨ã€ç¤¾ä¼šæ··ä¹±å’Œé“å¾·æ‹…å¿§ã€‚å› æ­¤ï¼Œæ£€æµ‹ç”±LAIMç”Ÿæˆçš„å¤šåª’ä½“å†…å®¹å˜å¾—è‡³å…³é‡è¦ï¼Œç›¸å…³ç ”ç©¶çš„å¢é•¿ä¹Ÿæä¸ºæ˜¾è‘—ã€‚å°½ç®¡å¦‚æ­¤ï¼Œä¸“é—¨é’ˆå¯¹æ£€æµ‹LAIMç”Ÿæˆå¤šåª’ä½“çš„ç³»ç»Ÿæ€§ç»¼è¿°ä»å­˜åœ¨æ˜æ˜¾å·®è·ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬æä¾›äº†ç¬¬ä¸€ç¯‡å…¨é¢æ¶µç›–ç°æœ‰æ£€æµ‹LAIMç”Ÿæˆå¤šåª’ä½“ï¼ˆå¦‚æ–‡æœ¬ã€å›¾åƒã€è§†é¢‘ã€éŸ³é¢‘å’Œå¤šæ¨¡æ€å†…å®¹ï¼‰çš„ç ”ç©¶ç»¼è¿°ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§æ–°çš„æ£€æµ‹æ–¹æ³•è®ºåˆ†ç±»ï¼ŒæŒ‰åª’ä½“æ¨¡æ€åˆ†ç±»ï¼Œå¹¶ä»ä¸¤ä¸ªè§’åº¦è¿›è¡Œé˜è¿°ï¼šçº¯æ£€æµ‹ï¼ˆæ—¨åœ¨æé«˜æ£€æµ‹æ€§èƒ½ï¼‰å’Œè¶…è¶Šæ£€æµ‹ï¼ˆå‘æ£€æµ‹å™¨æ·»åŠ é€šç”¨æ€§ã€ç¨³å¥æ€§å’Œå¯è§£é‡Šæ€§ç­‰å±æ€§ï¼‰ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜ç®€è¦æ¦‚è¿°äº†ç”Ÿæˆæœºåˆ¶ã€å…¬å¼€æ•°æ®é›†ã€åœ¨çº¿æ£€æµ‹å·¥å…·å’Œè¯„ä¼°æŒ‡æ ‡ï¼Œä¸ºè¿™ä¸€é¢†åŸŸçš„ç ”ç©¶äººå‘˜å’Œå®è·µè€…æä¾›äº†æœ‰ä»·å€¼çš„èµ„æºã€‚æœ€é‡è¦çš„æ˜¯ï¼Œæˆ‘ä»¬ä»ç¤¾äº¤åª’ä½“çš„è§’åº¦è¿›è¡Œäº†æ·±å…¥åˆ†æï¼Œä»¥çªå‡ºå…¶æ›´å¹¿æ³›çš„ç¤¾ä¼šå½±å“ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜ç¡®å®šäº†å½“å‰æ£€æµ‹çš„æŒ‘æˆ˜ï¼Œå¹¶æå‡ºäº†æœªæ¥ç ”ç©¶çš„æ–¹å‘ï¼Œä»¥è§£å†³åœ¨æ£€æµ‹ç”±LAIMç”Ÿæˆçš„å¤šåª’ä½“æ–¹é¢å°šæœªæ¢ç´¢ã€æ­£åœ¨å‡ºç°å’Œæ–°å…´çš„é—®é¢˜ã€‚æœ¬ç»¼è¿°æ—¨åœ¨å¡«è¡¥å­¦æœ¯ç©ºç™½ï¼Œä¸ºå…¨çƒäººå·¥æ™ºèƒ½å®‰å…¨åŠªåŠ›åšå‡ºè´¡çŒ®ï¼Œå¸®åŠ©ç¡®ä¿æ•°å­—é¢†åŸŸçš„ä¿¡æ¯å®Œæ•´æ€§ã€‚é¡¹ç›®é“¾æ¥ä¸ºï¼š<a target="_blank" rel="noopener" href="https://github.com/Purdue-M2/Detect-LAIM-generated-Multimedia-Survey%E3%80%82">https://github.com/Purdue-M2/Detect-LAIM-generated-Multimedia-Surveyã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2402.00045v6">PDF</a> </p>
<p><strong>æ‘˜è¦</strong><br>æ‰©æ•£æ¨¡å‹ç­‰å¤§å‹AIæ¨¡å‹ï¼ˆLAIMsï¼‰çš„å¿«é€Ÿå‘å±•æ ‡å¿—ç€AIç”Ÿæˆå¤šåª’ä½“å†…å®¹åœ¨æ—¥å¸¸ç”Ÿæ´»ä¸­çš„èå…¥ç¨‹åº¦è¶Šæ¥è¶Šé«˜ã€‚è™½ç„¶è¿™äº›æŠ€æœ¯åœ¨è®¸å¤šé¢†åŸŸå…·æœ‰åº”ç”¨ä»·å€¼ï¼Œä½†åŒæ—¶ä¹Ÿå­˜åœ¨æ½œåœ¨çš„è¯¯ç”¨é£é™©ã€ç¤¾ä¼šæ··ä¹±å’Œä¼¦ç†é—®é¢˜ã€‚å› æ­¤ï¼Œæ£€æµ‹LAIMç”Ÿæˆçš„å¤šåª’ä½“å†…å®¹å˜å¾—è‡³å…³é‡è¦ï¼Œç›¸å…³ç ”ç©¶ä¹Ÿæ—¥æ¸å¢å¤šã€‚æœ¬æ–‡é¦–æ¬¡å…¨é¢å›é¡¾äº†æ£€æµ‹LAIMç”Ÿæˆçš„å¤šåª’ä½“ï¼ˆå¦‚æ–‡æœ¬ã€å›¾åƒã€è§†é¢‘ã€éŸ³é¢‘å’Œå¤šæ¨¡æ€å†…å®¹ï¼‰çš„ç°æœ‰ç ”ç©¶ã€‚ä»‹ç»äº†æ–°é¢–çš„æ£€æµ‹æ–¹æ³•åˆ†ç±»ï¼Œåˆ†ä¸ºçº¯æ£€æµ‹ï¼ˆæ—¨åœ¨æé«˜æ£€æµ‹æ€§èƒ½ï¼‰å’Œè¶…è¶Šæ£€æµ‹ï¼ˆå¢åŠ é€šç”¨æ€§ã€é²æ£’æ€§å’Œæ£€æµ‹å™¨çš„å¯è§£é‡Šæ€§ï¼‰ã€‚æ­¤å¤–ï¼Œæœ¬æ–‡ç®€è¦æ¦‚è¿°äº†ç”Ÿæˆæœºåˆ¶ã€å…¬å¼€æ•°æ®é›†ã€åœ¨çº¿æ£€æµ‹å·¥å…·å’Œè¯„ä¼°æŒ‡æ ‡ï¼Œä¸ºç ”ç©¶äººå‘˜å’Œå®è·µè€…æä¾›æœ‰ä»·å€¼çš„èµ„æºã€‚æœ¬æ–‡ä»ç¤¾äº¤åª’ä½“çš„è§’åº¦è¿›è¡Œäº†æ·±å…¥åˆ†æï¼Œå¼ºè°ƒäº†å…¶æ›´å¹¿æ³›çš„ç¤¾ä¼šå½±å“ã€‚åŒæ—¶ï¼Œæœ¬æ–‡è¿˜æŒ‡å‡ºäº†å½“å‰æ£€æµ‹é¢ä¸´çš„æŒ‘æˆ˜ï¼Œå¹¶æ¢è®¨äº†æœªæ¥ç ”ç©¶çš„æ–¹å‘ï¼Œä»¥è§£å†³æ£€æµ‹LAIMç”Ÿæˆçš„å¤šåª’ä½“ä¸­çš„æœªæ¢ç´¢ã€æŒç»­å’Œæ–°å…´é—®é¢˜ã€‚æœ¬æ–‡æ—¨åœ¨å¡«è¡¥å­¦æœ¯ç©ºç™½ï¼Œä¸ºå…¨çƒAIå®‰å…¨åšå‡ºè´¡çŒ®ï¼Œç¡®ä¿æ•°å­—é¢†åŸŸçš„èµ„è®¯å®Œæ•´æ€§ã€‚</p>
<p><strong>å…³é”®è§è§£</strong></p>
<ul>
<li>å¤§å‹AIæ¨¡å‹ï¼ˆLAIMsï¼‰çš„å¿«é€Ÿå‘å±•æ¨åŠ¨äº†AIç”Ÿæˆå¤šåª’ä½“å†…å®¹çš„å¹¿æ³›åº”ç”¨ã€‚</li>
<li>AIç”Ÿæˆçš„å¤šåª’ä½“å†…å®¹åœ¨æ—¥å¸¸ç”Ÿæ´»ä¸­çš„èå…¥å¸¦æ¥äº†ä¸€ç³»åˆ—é£é™©ï¼ŒåŒ…æ‹¬æ½œåœ¨è¯¯ç”¨ã€ç¤¾ä¼šæ··ä¹±å’Œä¼¦ç†é—®é¢˜ã€‚</li>
<li>æ£€æµ‹LAIMç”Ÿæˆçš„å¤šåª’ä½“å†…å®¹å·²æˆä¸ºå…³é”®è®®é¢˜ï¼Œç›¸å…³ç ”ç©¶é€æ¸å¢å¤šã€‚</li>
<li>æœ¬æ–‡é¦–æ¬¡å…¨é¢ç»¼è¿°äº†æ£€æµ‹LAIMç”Ÿæˆçš„å¤šåª’ä½“çš„ç°æœ‰ç ”ç©¶ï¼Œæ¶‰åŠçº¯æ£€æµ‹å’Œè¶…è¶Šæ£€æµ‹çš„åˆ†ç±»æ–¹æ³•ã€‚</li>
<li>ä»‹ç»äº†ç”Ÿæˆæœºåˆ¶ã€å…¬å¼€æ•°æ®é›†ã€åœ¨çº¿æ£€æµ‹å·¥å…·å’Œè¯„ä¼°æŒ‡æ ‡çš„æ¦‚è¿°ã€‚</li>
<li>ä»ç¤¾äº¤åª’ä½“è§’åº¦æ·±å…¥åˆ†æäº†ç¤¾ä¼šå½±å“ã€‚</li>
<li>æŒ‡å‡ºäº†å½“å‰æ£€æµ‹é¢ä¸´çš„æŒ‘æˆ˜ï¼Œå¹¶æå‡ºäº†æœªæ¥ç ”ç©¶çš„æ–¹å‘ï¼Œä»¥åº”å¯¹æœªæ¢ç´¢ã€æŒç»­å’Œæ–°å…´é—®é¢˜ã€‚</li>
<li>æœ¬æ–‡æ—¨åœ¨å¡«è¡¥å­¦æœ¯ç©ºç™½ï¼Œä¸ºAIå®‰å…¨åšå‡ºè´¡çŒ®ï¼Œç¡®ä¿æ•°å­—èµ„è®¯çš„å®Œæ•´æ€§ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2402.00045">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-0f4420a0e524daa3fee95ef84ca8c592.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-4449c26a66fa7efc16665b06f1085c45.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e36dde2ecf62f34529e06bdea81c9bac.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-55ce1bca568eabaeb44b6b66e4bb1a9e.jpg" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-06-04/Diffusion%20Models/">https://kedreamix.github.io/Talk2Paper/Paper/2025-06-04/Diffusion%20Models/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/Diffusion-Models/">
                                    <span class="chip bg-color">Diffusion Models</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-06-04/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-2c958068ec93320796409d041fee6521.jpg" class="responsive-img" alt="åŒ»å­¦å›¾åƒ">
                        
                        <span class="card-title">åŒ»å­¦å›¾åƒ</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            åŒ»å­¦å›¾åƒ æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-06-04  NMCSE Noise-Robust Multi-Modal Coupling Signal Estimation Method via   Optimal Transport for Cardiovascular Disease Detection
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-06-04
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/" class="post-category">
                                    åŒ»å­¦å›¾åƒ
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/">
                        <span class="chip bg-color">åŒ»å­¦å›¾åƒ</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-06-04/NeRF/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-bc3ae20ded0fbbf0abafdafd8f321e01.jpg" class="responsive-img" alt="NeRF">
                        
                        <span class="card-title">NeRF</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            NeRF æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-06-04  RenderBender A Survey on Adversarial Attacks Using Differentiable   Rendering
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-06-04
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/NeRF/" class="post-category">
                                    NeRF
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/NeRF/">
                        <span class="chip bg-color">NeRF</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">31879.7k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
