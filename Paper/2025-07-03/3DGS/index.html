<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="3DGS">
    <meta name="description" content="3DGS æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-07-03  MILo Mesh-In-the-Loop Gaussian Splatting for Detailed and Efficient   Surface Reconstruction">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>3DGS | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://pic1.zhimg.com/v2-1c6c7ff641e2e607d996db2ab0a9b6f8.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">3DGS</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/3DGS/">
                                <span class="chip bg-color">3DGS</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/3DGS/" class="post-category">
                                3DGS
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-07-03
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-07-09
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    20.4k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    83 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-07-03-æ›´æ–°"><a href="#2025-07-03-æ›´æ–°" class="headerlink" title="2025-07-03 æ›´æ–°"></a>2025-07-03 æ›´æ–°</h1><h2 id="MILo-Mesh-In-the-Loop-Gaussian-Splatting-for-Detailed-and-Efficient-Surface-Reconstruction"><a href="#MILo-Mesh-In-the-Loop-Gaussian-Splatting-for-Detailed-and-Efficient-Surface-Reconstruction" class="headerlink" title="MILo: Mesh-In-the-Loop Gaussian Splatting for Detailed and Efficient   Surface Reconstruction"></a>MILo: Mesh-In-the-Loop Gaussian Splatting for Detailed and Efficient   Surface Reconstruction</h2><p><strong>Authors:Antoine GuÃ©don, Diego Gomez, Nissim Maruani, Bingchen Gong, George Drettakis, Maks Ovsjanikov</strong></p>
<p>While recent advances in Gaussian Splatting have enabled fast reconstruction of high-quality 3D scenes from images, extracting accurate surface meshes remains a challenge. Current approaches extract the surface through costly post-processing steps, resulting in the loss of fine geometric details or requiring significant time and leading to very dense meshes with millions of vertices. More fundamentally, the a posteriori conversion from a volumetric to a surface representation limits the ability of the final mesh to preserve all geometric structures captured during training. We present MILo, a novel Gaussian Splatting framework that bridges the gap between volumetric and surface representations by differentiably extracting a mesh from the 3D Gaussians. We design a fully differentiable procedure that constructs the mesh-including both vertex locations and connectivity-at every iteration directly from the parameters of the Gaussians, which are the only quantities optimized during training. Our method introduces three key technical contributions: a bidirectional consistency framework ensuring both representations-Gaussians and the extracted mesh-capture the same underlying geometry during training; an adaptive mesh extraction process performed at each training iteration, which uses Gaussians as differentiable pivots for Delaunay triangulation; a novel method for computing signed distance values from the 3D Gaussians that enables precise surface extraction while avoiding geometric erosion. Our approach can reconstruct complete scenes, including backgrounds, with state-of-the-art quality while requiring an order of magnitude fewer mesh vertices than previous methods. Due to their light weight and empty interior, our meshes are well suited for downstream applications such as physics simulations or animation. </p>
<blockquote>
<p>è™½ç„¶é«˜æ–¯æ¶‚æŠ¹ï¼ˆGaussian Splattingï¼‰çš„è¿‘æœŸè¿›å±•å·²ç»å®ç°äº†ä»å›¾åƒå¿«é€Ÿé‡å»ºé«˜è´¨é‡çš„ä¸‰ç»´åœºæ™¯ï¼Œä½†æå–ç²¾ç¡®çš„è¡¨é¢ç½‘æ ¼ä»ç„¶æ˜¯ä¸€ä¸ªæŒ‘æˆ˜ã€‚å½“å‰çš„æ–¹æ³•é€šè¿‡æ˜‚è´µçš„åå¤„ç†æ­¥éª¤æå–è¡¨é¢ï¼Œå¯¼è‡´ä¸¢å¤±äº†ç²¾ç»†çš„å‡ ä½•ç»†èŠ‚ï¼Œæˆ–è€…éœ€è¦èŠ±è´¹å¤§é‡æ—¶é—´ï¼Œå¹¶äº§ç”Ÿéå¸¸å¯†é›†çš„ç½‘æ ¼ï¼ŒåŒ…å«æ•°ç™¾ä¸‡ä¸ªé¡¶ç‚¹ã€‚æ›´æ ¹æœ¬çš„æ˜¯ï¼Œä»ä½“ç§¯è¡¨ç¤ºåˆ°è¡¨é¢è¡¨ç¤ºçš„åæœŸè½¬æ¢é™åˆ¶äº†æœ€ç»ˆç½‘æ ¼ä¿ç•™åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­æ•è·çš„æ‰€æœ‰å‡ ä½•ç»“æ„çš„èƒ½åŠ›ã€‚æˆ‘ä»¬æå‡ºäº†MILoï¼Œè¿™æ˜¯ä¸€ç§æ–°å‹çš„é«˜æ–¯æ¶‚æŠ¹æ¡†æ¶ï¼Œå®ƒé€šè¿‡ä»ä¸‰ç»´é«˜æ–¯ä¸­å¯å¾®æå–ç½‘æ ¼æ¥å¼¥åˆä½“ç§¯è¡¨ç¤ºå’Œè¡¨é¢è¡¨ç¤ºä¹‹é—´çš„å·®è·ã€‚æˆ‘ä»¬è®¾è®¡äº†ä¸€ç§å®Œå…¨å¯å¾®çš„ç¨‹åºï¼Œè¯¥ç¨‹åºå¯ä»¥ç›´æ¥ä»é«˜æ–¯å‚æ•°ï¼ˆåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å”¯ä¸€ä¼˜åŒ–çš„é‡ï¼‰ä¸­ï¼Œåœ¨æ¯æ¬¡è¿­ä»£æ—¶æ„å»ºç½‘æ ¼ï¼ŒåŒ…æ‹¬é¡¶ç‚¹çš„ä½ç½®å’Œè¿æ¥ã€‚æˆ‘ä»¬çš„æ–¹æ³•å¼•å…¥äº†ä¸‰ä¸ªå…³é”®çš„æŠ€æœ¯è´¡çŒ®ï¼šä¸€ç§åŒå‘ä¸€è‡´æ€§æ¡†æ¶ï¼Œç¡®ä¿é«˜æ–¯å’Œæå–çš„ç½‘æ ¼åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­æ•è·ç›¸åŒçš„åº•å±‚å‡ ä½•ï¼›ä¸€ç§åœ¨æ¯ä¸ªè®­ç»ƒè¿­ä»£ä¸­è¿›è¡Œçš„è‡ªé€‚åº”ç½‘æ ¼æå–è¿‡ç¨‹ï¼Œå®ƒä½¿ç”¨é«˜æ–¯ä½œä¸ºDelaunayä¸‰è§’å‰–åˆ†çš„å¯å¾®æ”¯ç‚¹ï¼›ä¸€ç§ä»ä¸‰ç»´é«˜æ–¯è®¡ç®—å¸¦ç¬¦å·è·ç¦»å€¼çš„æ–°æ–¹æ³•ï¼Œè¯¥æ–¹æ³•å¯å®ç°ç²¾ç¡®çš„è¡¨é¢æå–ï¼ŒåŒæ—¶é¿å…å‡ ä½•ä¾µèš€ã€‚æˆ‘ä»¬çš„æ–¹æ³•å¯ä»¥é‡å»ºåŒ…æ‹¬èƒŒæ™¯åœ¨å†…çš„å®Œæ•´åœºæ™¯ï¼Œè¾¾åˆ°æœ€å…ˆè¿›çš„å“è´¨ï¼ŒåŒæ—¶æ‰€éœ€çš„ç½‘æ ¼é¡¶ç‚¹æ¯”ä»¥å‰çš„æ–¹æ³•å°‘ä¸€ä¸ªæ•°é‡çº§ã€‚ç”±äºæˆ‘ä»¬çš„ç½‘æ ¼è½»ä¾¿ä¸”å†…éƒ¨ä¸ºç©ºï¼Œå› æ­¤éå¸¸é€‚åˆç”¨äºç‰©ç†æ¨¡æ‹Ÿæˆ–åŠ¨ç”»ç­‰ä¸‹æ¸¸åº”ç”¨ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.24096v1">PDF</a> 10 pages. A presentation video of our approach is available at   <a target="_blank" rel="noopener" href="https://youtu.be/_SGNhhNz0fE">https://youtu.be/_SGNhhNz0fE</a></p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†åŸºäºé«˜æ–¯æ‹¼è´´çš„æ–°æ–¹æ³•MILOï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ç›´æ¥ä»é«˜æ–¯å‚æ•°æ„å»ºç½‘æ ¼ï¼Œå®ç°äº†ä»ä½“ç§¯è¡¨ç¤ºåˆ°è¡¨é¢è¡¨ç¤ºçš„æ¡¥æ¢ã€‚è¯¥æ–¹æ³•å…·æœ‰ä¸‰ä¸ªå…³é”®æŠ€æœ¯è´¡çŒ®ï¼šåŒå‘ä¸€è‡´æ€§æ¡†æ¶ã€è‡ªé€‚åº”ç½‘æ ¼æå–è¿‡ç¨‹å’Œè®¡ç®—é«˜æ–¯çš„ä¸‰ç»´å¸¦ç¬¦å·è·ç¦»å€¼çš„æ–¹æ³•ã€‚è¯¥æ–¹æ³•èƒ½å¤Ÿé‡å»ºé«˜è´¨é‡çš„åœºæ™¯ï¼ŒåŒ…æ‹¬èƒŒæ™¯ï¼Œä¸”ç”Ÿæˆçš„ç½‘æ ¼å…·æœ‰è½»é‡çº§å’Œç©ºå¿ƒçš„ç‰¹ç‚¹ï¼Œé€‚ç”¨äºç‰©ç†æ¨¡æ‹Ÿå’ŒåŠ¨ç”»ç­‰ä¸‹æ¸¸åº”ç”¨ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>MILOæ˜¯ä¸€ç§åŸºäºé«˜æ–¯æ‹¼è´´çš„æ–°æ–¹æ³•ï¼Œèƒ½å¤Ÿåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ç›´æ¥ä»é«˜æ–¯å‚æ•°æ„å»ºç½‘æ ¼ã€‚</li>
<li>åŒå‘ä¸€è‡´æ€§æ¡†æ¶ç¡®ä¿é«˜æ–¯å’Œæå–çš„ç½‘æ ¼åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­æ•æ‰ç›¸åŒçš„åº•å±‚å‡ ä½•ç»“æ„ã€‚</li>
<li>è‡ªé€‚åº”ç½‘æ ¼æå–è¿‡ç¨‹åœ¨æ¯ä¸ªè®­ç»ƒè¿­ä»£ä¸­è¿›è¡Œï¼Œä½¿ç”¨é«˜æ–¯ä½œä¸ºå¯å¾®åˆ†çš„Delaunayä¸‰è§’å‰–åˆ†çš„æ”¯ç‚¹ã€‚</li>
<li>è®¡ç®—ä»ä¸‰ç»´é«˜æ–¯ä¸­å¾—åˆ°çš„å¸¦ç¬¦å·è·ç¦»å€¼ï¼Œå®ç°ç²¾ç¡®çš„è¡¨é¢æå–ï¼Œé¿å…å‡ ä½•ä¾µèš€ã€‚</li>
<li>è¯¥æ–¹æ³•èƒ½å¤Ÿé‡å»ºé«˜è´¨é‡çš„åœºæ™¯ï¼ŒåŒ…æ‹¬èƒŒæ™¯ï¼Œä¸”ç”Ÿæˆçš„ç½‘æ ¼å…·æœ‰è½»é‡çº§å’Œç©ºå¿ƒçš„ç‰¹ç‚¹ã€‚</li>
<li>MILOç”Ÿæˆçš„ç½‘æ ¼é€‚ç”¨äºç‰©ç†æ¨¡æ‹Ÿå’ŒåŠ¨ç”»ç­‰ä¸‹æ¸¸åº”ç”¨ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.24096">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-7115c4dc1ea32ee47fcdfc4bec8e9b25.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d84a5caa54e309870c180ad6be118195.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-1f1a052e97063ac5a5983b33ca568ba6.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-8e89514375222e0401373b8c6ce3a880.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-81b2042b11705b69b7f0fc8fa6122f01.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="GaVS-3D-Grounded-Video-Stabilization-via-Temporally-Consistent-Local-Reconstruction-and-Rendering"><a href="#GaVS-3D-Grounded-Video-Stabilization-via-Temporally-Consistent-Local-Reconstruction-and-Rendering" class="headerlink" title="GaVS: 3D-Grounded Video Stabilization via Temporally-Consistent Local   Reconstruction and Rendering"></a>GaVS: 3D-Grounded Video Stabilization via Temporally-Consistent Local   Reconstruction and Rendering</h2><p><strong>Authors:Zinuo You, Stamatios Georgoulis, Anpei Chen, Siyu Tang, Dengxin Dai</strong></p>
<p>Video stabilization is pivotal for video processing, as it removes unwanted shakiness while preserving the original user motion intent. Existing approaches, depending on the domain they operate, suffer from several issues (e.g. geometric distortions, excessive cropping, poor generalization) that degrade the user experience. To address these issues, we introduce \textbf{GaVS}, a novel 3D-grounded approach that reformulates video stabilization as a temporally-consistent &#96;local reconstruction and renderingâ€™ paradigm. Given 3D camera poses, we augment a reconstruction model to predict Gaussian Splatting primitives, and finetune it at test-time, with multi-view dynamics-aware photometric supervision and cross-frame regularization, to produce temporally-consistent local reconstructions. The model are then used to render each stabilized frame. We utilize a scene extrapolation module to avoid frame cropping. Our method is evaluated on a repurposed dataset, instilled with 3D-grounded information, covering samples with diverse camera motions and scene dynamics. Quantitatively, our method is competitive with or superior to state-of-the-art 2D and 2.5D approaches in terms of conventional task metrics and new geometry consistency. Qualitatively, our method produces noticeably better results compared to alternatives, validated by the user study. </p>
<blockquote>
<p>è§†é¢‘ç¨³å®šå¯¹è§†é¢‘å¤„ç†è‡³å…³é‡è¦ï¼Œå®ƒèƒ½æ¶ˆé™¤ä¸å¿…è¦çš„æŠ–åŠ¨ï¼ŒåŒæ—¶ä¿ç•™ç”¨æˆ·åŸå§‹çš„è¿åŠ¨æ„å›¾ã€‚ç°æœ‰æ–¹æ³•æ ¹æ®å…¶åº”ç”¨é¢†åŸŸå­˜åœ¨å¤šç§é—®é¢˜ï¼ˆä¾‹å¦‚å‡ ä½•å¤±çœŸã€è¿‡åº¦è£å‰ªã€æ³›åŒ–èƒ½åŠ›å·®ç­‰ï¼‰ï¼Œè¿™äº›é—®é¢˜ä¼šé™ä½ç”¨æˆ·ä½“éªŒã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬å¼•å…¥äº†\textbf{GaVS}ï¼Œè¿™æ˜¯ä¸€ç§æ–°å‹åŸºäº3Dçš„è§†é¢‘ç¨³å®šæ–¹æ³•ï¼Œå®ƒå°†è§†é¢‘ç¨³å®šé‡æ–°å®šä¹‰ä¸ºæ—¶é—´ä¸€è‡´çš„â€œå±€éƒ¨é‡å»ºå’Œæ¸²æŸ“â€èŒƒå¼ã€‚ç»™å®š3Dç›¸æœºå§¿æ€ï¼Œæˆ‘ä»¬å¢å¼ºé‡å»ºæ¨¡å‹ä»¥é¢„æµ‹é«˜æ–¯SplattingåŸå§‹æ•°æ®ï¼Œå¹¶åœ¨æµ‹è¯•æ—¶å¯¹å…¶è¿›è¡Œå¾®è°ƒï¼Œåˆ©ç”¨å¤šè§†è§’åŠ¨æ€çš„å…‰åº¦ç›‘ç£å’Œè·¨å¸§æ­£åˆ™åŒ–ï¼Œä»¥äº§ç”Ÿæ—¶é—´ä¸€è‡´çš„å±€éƒ¨é‡å»ºã€‚ç„¶åï¼Œè¿™äº›æ¨¡å‹è¢«ç”¨æ¥æ¸²æŸ“æ¯ä¸ªç¨³å®šçš„å¸§ã€‚æˆ‘ä»¬ä½¿ç”¨åœºæ™¯å¤–æ¨æ¨¡å—æ¥é¿å…å¸§è£å‰ªã€‚æˆ‘ä»¬çš„æ–¹æ³•æ˜¯åœ¨ä¸€ä¸ªé‡æ–°æ•´ç†çš„æ•°æ®é›†ä¸Šè¿›è¡Œè¯„ä¼°çš„ï¼Œè¯¥æ•°æ®é›†åŒ…å«äº†åŸºäºä¸‰ç»´ä¿¡æ¯çš„æ•°æ®æ ·æœ¬ï¼Œæ¶µç›–äº†å¤šç§ç›¸æœºè¿åŠ¨å’Œåœºæ™¯åŠ¨æ€ã€‚ä»å®šé‡è§’åº¦çœ‹ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨å¸¸è§„ä»»åŠ¡æŒ‡æ ‡å’Œæ–°å‡ ä½•ä¸€è‡´æ€§æ–¹é¢ä¸æœ€å…ˆè¿›çš„äºŒç»´å’ŒäºŒç»´åŠæ–¹æ³•ç›¸å½“æˆ–æ›´ä¼˜è¶Šã€‚ä»å®šæ€§è§’åº¦çœ‹ï¼Œæˆ‘ä»¬çš„æ–¹æ³•ä¸æ›¿ä»£æ–¹æ¡ˆç›¸æ¯”äº§ç”Ÿäº†æ˜æ˜¾æ›´å¥½çš„ç»“æœï¼Œå¾—åˆ°äº†ç”¨æˆ·ç ”ç©¶çš„éªŒè¯ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.23957v1">PDF</a> siggraph 2025, project website: <a target="_blank" rel="noopener" href="https://sinoyou.github.io/gavs">https://sinoyou.github.io/gavs</a></p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†è§†é¢‘ç¨³å®šåŒ–çš„é‡è¦æ€§ï¼Œé’ˆå¯¹ç°æœ‰æ–¹æ³•å­˜åœ¨çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§æ–°å‹çš„åŸºäºä¸‰ç»´é‡å»ºçš„å±€éƒ¨é‡å»ºå’Œæ¸²æŸ“çš„è§†é¢‘ç¨³å®šåŒ–æ–¹æ³•ï¼Œå³GaVSã€‚è¯¥æ–¹æ³•ä½¿ç”¨é‡å»ºæ¨¡å‹é¢„æµ‹é«˜æ–¯æ‹¼è´´ï¼ˆGaussian Splattingï¼‰åŸå§‹å½¢æ€ï¼Œå¹¶åœ¨æµ‹è¯•æ—¶è¿›è¡Œå¾®è°ƒï¼Œä»¥è·å¾—æ—¶é—´ä¸Šä¸€è‡´çš„å±€éƒ¨é‡å»ºã€‚é€šè¿‡åœºæ™¯å¤–æ¨æ¨¡å—é¿å…å¸§è£å‰ªï¼Œåœ¨å…·æœ‰ä¸åŒç›¸æœºè¿åŠ¨å’Œåœºæ™¯åŠ¨æ€æ€§çš„æ•°æ®é›†ä¸Šè¿›è¡Œäº†è¯„ä¼°ï¼Œå¹¶åœ¨ä»»åŠ¡æŒ‡æ ‡å’Œå‡ ä½•ä¸€è‡´æ€§æ–¹é¢ä¸ç°æœ‰çš„äºŒç»´å’ŒäºŒç»´åŠæ–¹æ³•ç›¸æ¯”å…·æœ‰ç«äº‰åŠ›æˆ–æ›´ä¼˜è¶Šçš„è¡¨ç°ã€‚ç”¨æˆ·ç ”ç©¶éªŒè¯äº†å…¶æ˜¾è‘—ä¼˜äºå…¶ä»–æ–¹æ³•çš„ç»“æœã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>è§†é¢‘ç¨³å®šåŒ–å¯¹äºè§†é¢‘å¤„ç†è‡³å…³é‡è¦ï¼Œå¯æ¶ˆé™¤ä¸å¿…è¦çš„æŠ–åŠ¨å¹¶ä¿æŒåŸå§‹ç”¨æˆ·è¿åŠ¨æ„å›¾ã€‚</li>
<li>ç°æœ‰æ–¹æ³•å­˜åœ¨å‡ ä½•å¤±çœŸã€è¿‡åº¦è£å‰ªå’Œæ³›åŒ–èƒ½åŠ›å·®ç­‰é—®é¢˜ã€‚</li>
<li>GaVSæ˜¯ä¸€ç§åŸºäºä¸‰ç»´é‡å»ºçš„è§†é¢‘ç¨³å®šåŒ–æ–°æ–¹æ³•ï¼Œé‡‡ç”¨å±€éƒ¨é‡å»ºå’Œæ¸²æŸ“æ¨¡å¼ã€‚</li>
<li>åˆ©ç”¨é‡å»ºæ¨¡å‹é¢„æµ‹é«˜æ–¯æ‹¼è´´åŸå§‹å½¢æ€ï¼Œå¹¶é€šè¿‡æµ‹è¯•æ—¶çš„å¾®è°ƒè·å¾—æ—¶é—´ä¸Šä¸€è‡´çš„å±€éƒ¨é‡å»ºã€‚</li>
<li>é€šè¿‡åœºæ™¯å¤–æ¨æ¨¡å—é¿å…å¸§è£å‰ªã€‚</li>
<li>GaVSåœ¨å¤šç§æ•°æ®é›†ä¸Šè¡¨ç°è‰¯å¥½ï¼Œåœ¨ä»»åŠ¡æŒ‡æ ‡å’Œå‡ ä½•ä¸€è‡´æ€§æ–¹é¢ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”å…·æœ‰ç«äº‰åŠ›æˆ–æ›´ä¼˜è¶Šã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.23957">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-2c64a049a9c4fde6899fdbf6c5fabf8d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-cc41a6e866df25c27b959ec427f5aa6d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b7923ead3b37d5a0b63845f27a86bae1.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b648818e39f301b05fec0475aecdc6bf.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="AttentionGS-Towards-Initialization-Free-3D-Gaussian-Splatting-via-Structural-Attention"><a href="#AttentionGS-Towards-Initialization-Free-3D-Gaussian-Splatting-via-Structural-Attention" class="headerlink" title="AttentionGS: Towards Initialization-Free 3D Gaussian Splatting via   Structural Attention"></a>AttentionGS: Towards Initialization-Free 3D Gaussian Splatting via   Structural Attention</h2><p><strong>Authors:Ziao Liu, Zhenjia Li, Yifeng Shi, Xiangang Li</strong></p>
<p>3D Gaussian Splatting (3DGS) is a powerful alternative to Neural Radiance Fields (NeRF), excelling in complex scene reconstruction and efficient rendering. However, it relies on high-quality point clouds from Structure-from-Motion (SfM), limiting its applicability. SfM also fails in texture-deficient or constrained-view scenarios, causing severe degradation in 3DGS reconstruction. To address this limitation, we propose AttentionGS, a novel framework that eliminates the dependency on high-quality initial point clouds by leveraging structural attention for direct 3D reconstruction from randomly initialization. In the early training stage, we introduce geometric attention to rapidly recover the global scene structure. As training progresses, we incorporate texture attention to refine fine-grained details and enhance rendering quality. Furthermore, we employ opacity-weighted gradients to guide Gaussian densification, leading to improved surface reconstruction. Extensive experiments on multiple benchmark datasets demonstrate that AttentionGS significantly outperforms state-of-the-art methods, particularly in scenarios where point cloud initialization is unreliable. Our approach paves the way for more robust and flexible 3D Gaussian Splatting in real-world applications. </p>
<blockquote>
<p>3Dé«˜æ–¯æ‘Šé“ºï¼ˆ3DGSï¼‰æ˜¯ç¥ç»è¾å°„åœºï¼ˆNeRFï¼‰çš„æœ‰åŠ›æ›¿ä»£æ–¹æ¡ˆï¼Œåœ¨å¤æ‚åœºæ™¯é‡å»ºå’Œé«˜æ•ˆæ¸²æŸ“æ–¹é¢è¡¨ç°å‡ºè‰²ã€‚ç„¶è€Œï¼Œå®ƒä¾èµ–äºè¿åŠ¨ç»“æ„ï¼ˆSfMï¼‰çš„é«˜è´¨é‡ç‚¹äº‘ï¼Œé™åˆ¶äº†å…¶åº”ç”¨èŒƒå›´ã€‚SfMåœ¨çº¹ç†ç¼ºå¤±æˆ–è§†è§’å—é™çš„åœºæ™¯ä¸­ä¹Ÿä¼šå¤±æ•ˆï¼Œå¯¼è‡´3DGSé‡å»ºä¸¥é‡é€€åŒ–ã€‚ä¸ºäº†è§£å†³è¿™ä¸€å±€é™æ€§ï¼Œæˆ‘ä»¬æå‡ºäº†AttentionGSè¿™ä¸€æ–°å‹æ¡†æ¶ï¼Œé€šè¿‡åˆ©ç”¨ç»“æ„æ³¨æ„åŠ›æ¥ç›´æ¥ä»éšæœºåˆå§‹åŒ–è¿›è¡Œ3Dé‡å»ºï¼Œä»è€Œæ¶ˆé™¤äº†å¯¹é«˜è´¨é‡åˆå§‹ç‚¹äº‘çš„ä¾èµ–ã€‚åœ¨è®­ç»ƒåˆæœŸï¼Œæˆ‘ä»¬å¼•å…¥å‡ ä½•æ³¨æ„åŠ›æ¥å¿«é€Ÿæ¢å¤å…¨å±€åœºæ™¯ç»“æ„ã€‚éšç€è®­ç»ƒçš„è¿›è¡Œï¼Œæˆ‘ä»¬ç»“åˆçº¹ç†æ³¨æ„åŠ›æ¥ç»†åŒ–ç»†èŠ‚å¹¶å¢å¼ºæ¸²æŸ“è´¨é‡ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜é‡‡ç”¨ä¸é€æ˜åº¦åŠ æƒæ¢¯åº¦æ¥æŒ‡å¯¼é«˜æ–¯ç¨ å¯†åŒ–ï¼Œä»è€Œæ”¹è¿›è¡¨é¢é‡å»ºã€‚åœ¨å¤šä¸ªåŸºå‡†æ•°æ®é›†ä¸Šçš„å¤§é‡å®éªŒè¡¨æ˜ï¼ŒAttentionGSæ˜¾è‘—ä¼˜äºæœ€æ–°æ–¹æ³•ï¼Œç‰¹åˆ«æ˜¯åœ¨ç‚¹äº‘åˆå§‹åŒ–ä¸å¯é çš„åœºæ™¯ä¸­ã€‚æˆ‘ä»¬çš„æ–¹æ³•ä¸ºæ›´ç¨³å¥å’Œçµæ´»çš„3Dé«˜æ–¯æ‘Šé“ºåœ¨ç°å®ä¸–ç•Œåº”ç”¨ä¸­çš„ä½¿ç”¨é“ºå¹³äº†é“è·¯ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.23611v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†3D Gaussian Splattingï¼ˆ3DGSï¼‰æŠ€æœ¯åŠå…¶åœ¨å¤æ‚åœºæ™¯é‡å»ºå’Œé«˜æ•ˆæ¸²æŸ“æ–¹é¢çš„ä¼˜åŠ¿ã€‚ç„¶è€Œï¼Œå®ƒä¾èµ–äºé«˜è´¨é‡çš„ç‚¹äº‘æ•°æ®ï¼Œè¿™åœ¨æŸäº›åœºæ™¯ä¸‹å­˜åœ¨å±€é™æ€§ã€‚ä¸ºæ­¤ï¼Œæå‡ºäº†ä¸€ç§æ–°å‹æ¡†æ¶AttentionGSï¼Œåˆ©ç”¨ç»“æ„æ³¨æ„åŠ›æœºåˆ¶å®ç°ä»éšæœºåˆå§‹åŒ–ç›´æ¥è¿›è¡Œ3Dé‡å»ºã€‚è¯¥æ¡†æ¶åœ¨è®­ç»ƒåˆæœŸé€šè¿‡å‡ ä½•æ³¨æ„åŠ›å¿«é€Ÿæ¢å¤å…¨å±€åœºæ™¯ç»“æ„ï¼Œéšç€è®­ç»ƒè¿›å±•ï¼Œç»“åˆçº¹ç†æ³¨æ„åŠ›ç»†åŒ–ç»†èŠ‚å¹¶æé«˜æ¸²æŸ“è´¨é‡ã€‚æ­¤å¤–ï¼Œè¿˜é‡‡ç”¨åŸºäºä¸é€æ˜åº¦çš„æ¢¯åº¦å¼•å¯¼é«˜æ–¯ç¨ å¯†åŒ–ï¼Œæ”¹å–„è¡¨é¢é‡å»ºæ•ˆæœã€‚å®éªŒè¯æ˜ï¼ŒAttentionGSåœ¨å¤šä¸ªåŸºå‡†æ•°æ®é›†ä¸Šæ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œç‰¹åˆ«æ˜¯åœ¨ç‚¹äº‘åˆå§‹åŒ–ä¸å¯é çš„åœºæ™¯ä¸‹è¡¨ç°æ›´ä¼˜ç§€ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>3DGSæ˜¯ä¸€ç§å¼ºå¤§çš„NeRFæ›¿ä»£æŠ€æœ¯ï¼Œæ“…é•¿å¤æ‚åœºæ™¯é‡å»ºå’Œé«˜æ•ˆæ¸²æŸ“ã€‚</li>
<li>3DGSä¾èµ–äºé«˜è´¨é‡ç‚¹äº‘æ•°æ®ï¼Œè¿™åœ¨æŸäº›åœºæ™¯ä¸­æ˜¯ä¸€ä¸ªé™åˆ¶ã€‚</li>
<li>AttentionGSæ¡†æ¶é€šè¿‡åˆ©ç”¨ç»“æ„æ³¨æ„åŠ›æœºåˆ¶æ¶ˆé™¤å¯¹é«˜è´¨é‡åˆå§‹ç‚¹äº‘çš„ä¾èµ–ï¼Œå®ç°ä»éšæœºåˆå§‹åŒ–ç›´æ¥è¿›è¡Œ3Dé‡å»ºã€‚</li>
<li>AttentionGSåœ¨è®­ç»ƒåˆæœŸé€šè¿‡å‡ ä½•æ³¨æ„åŠ›æ¢å¤å…¨å±€åœºæ™¯ç»“æ„ï¼Œéšåç»“åˆçº¹ç†æ³¨æ„åŠ›ç»†åŒ–ç»†èŠ‚ï¼Œæé«˜æ¸²æŸ“è´¨é‡ã€‚</li>
<li>é‡‡ç”¨åŸºäºä¸é€æ˜åº¦çš„æ¢¯åº¦å¼•å¯¼é«˜æ–¯ç¨ å¯†åŒ–ï¼Œæ”¹å–„è¡¨é¢é‡å»ºæ•ˆæœã€‚</li>
<li>AttentionGSåœ¨å¤šä¸ªæ•°æ®é›†ä¸Šè¡¨ç°ä¼˜å¼‚ï¼Œç‰¹åˆ«æ˜¯åœ¨ç‚¹äº‘åˆå§‹åŒ–ä¸å¯é çš„åœºæ™¯ä¸­ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.23611">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-ad3aa318d3a239901bdf263109cc9f16.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-47ffdc35cbe002cf5d2c0ebcc5dd0acd.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-cb373851513c8a57bdbcd4a7fac1d8cd.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ef675a5e8826902351fdf54f1f16b97e.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-69f58f2f818926d946b958e83ab8cac6.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="SurgTPGS-Semantic-3D-Surgical-Scene-Understanding-with-Text-Promptable-Gaussian-Splatting"><a href="#SurgTPGS-Semantic-3D-Surgical-Scene-Understanding-with-Text-Promptable-Gaussian-Splatting" class="headerlink" title="SurgTPGS: Semantic 3D Surgical Scene Understanding with Text Promptable   Gaussian Splatting"></a>SurgTPGS: Semantic 3D Surgical Scene Understanding with Text Promptable   Gaussian Splatting</h2><p><strong>Authors:Yiming Huang, Long Bai, Beilei Cui, Kun Yuan, Guankun Wang, Mobarak I. Hoque, Nicolas Padoy, Nassir Navab, Hongliang Ren</strong></p>
<p>In contemporary surgical research and practice, accurately comprehending 3D surgical scenes with text-promptable capabilities is particularly crucial for surgical planning and real-time intra-operative guidance, where precisely identifying and interacting with surgical tools and anatomical structures is paramount. However, existing works focus on surgical vision-language model (VLM), 3D reconstruction, and segmentation separately, lacking support for real-time text-promptable 3D queries. In this paper, we present SurgTPGS, a novel text-promptable Gaussian Splatting method to fill this gap. We introduce a 3D semantics feature learning strategy incorporating the Segment Anything model and state-of-the-art vision-language models. We extract the segmented language features for 3D surgical scene reconstruction, enabling a more in-depth understanding of the complex surgical environment. We also propose semantic-aware deformation tracking to capture the seamless deformation of semantic features, providing a more precise reconstruction for both texture and semantic features. Furthermore, we present semantic region-aware optimization, which utilizes regional-based semantic information to supervise the training, particularly promoting the reconstruction quality and semantic smoothness. We conduct comprehensive experiments on two real-world surgical datasets to demonstrate the superiority of SurgTPGS over state-of-the-art methods, highlighting its potential to revolutionize surgical practices. SurgTPGS paves the way for developing next-generation intelligent surgical systems by enhancing surgical precision and safety. Our code is available at: <a target="_blank" rel="noopener" href="https://github.com/lastbasket/SurgTPGS">https://github.com/lastbasket/SurgTPGS</a>. </p>
<blockquote>
<p>åœ¨å½“ä»£çš„åŒ»å­¦ç ”ç©¶å’Œå®è·µä¸­ï¼Œèƒ½å¤Ÿä½¿ç”¨æ–‡æœ¬æç¤ºåŠŸèƒ½å‡†ç¡®åœ°ç†è§£ä¸‰ç»´æ‰‹æœ¯åœºæ™¯å¯¹äºæ‰‹æœ¯è§„åˆ’å’Œå®æ—¶æ‰‹æœ¯è¿‡ç¨‹ä¸­çš„æŒ‡å¯¼å°¤ä¸ºå…³é”®ã€‚åœ¨è¿™ç§ç¯å¢ƒä¸‹ï¼Œç²¾ç¡®åœ°è¯†åˆ«å¹¶ä¸æ‰‹æœ¯å·¥å…·å’Œè§£å‰–ç»“æ„è¿›è¡Œäº¤äº’æ˜¯æå…¶é‡è¦çš„ã€‚ç„¶è€Œï¼Œç°æœ‰çš„å·¥ä½œä¸»è¦é›†ä¸­åœ¨æ‰‹æœ¯è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMï¼‰ã€ä¸‰ç»´é‡å»ºå’Œåˆ†å‰²ä¸Šï¼Œç¼ºä¹æ”¯æŒå®æ—¶æ–‡æœ¬æç¤ºçš„ä¸‰ç»´æŸ¥è¯¢åŠŸèƒ½ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†SurgTPGSï¼Œè¿™æ˜¯ä¸€ç§æ–°çš„æ–‡æœ¬æç¤ºé«˜æ–¯Splattingæ–¹æ³•ï¼Œä»¥å¡«è¡¥è¿™ä¸€ç©ºç™½ã€‚æˆ‘ä»¬ä»‹ç»äº†ä¸€ç§ä¸‰ç»´è¯­ä¹‰ç‰¹å¾å­¦ä¹ ç­–ç•¥ï¼Œèåˆäº†ä»»ä½•åˆ†æ®µæ¨¡å‹å’Œæœ€å…ˆè¿›çš„è§†è§‰è¯­è¨€æ¨¡å‹ã€‚æˆ‘ä»¬æå–äº†ç”¨äºä¸‰ç»´æ‰‹æœ¯åœºæ™¯é‡å»ºçš„åˆ†å‰²è¯­è¨€ç‰¹å¾ï¼Œä»¥ä¾¿æ›´æ·±å…¥åœ°ç†è§£å¤æ‚çš„æ‰‹æœ¯ç¯å¢ƒã€‚æˆ‘ä»¬è¿˜æå‡ºäº†è¯­ä¹‰æ„ŸçŸ¥å˜å½¢è·Ÿè¸ªæŠ€æœ¯ï¼Œä»¥æ•æ‰è¯­ä¹‰ç‰¹å¾çš„æ— ç¼å˜å½¢ï¼Œä¸ºçº¹ç†å’Œè¯­ä¹‰ç‰¹å¾æä¾›æ›´ç²¾ç¡®çš„é‡å»ºã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜æå‡ºäº†è¯­ä¹‰åŒºåŸŸæ„ŸçŸ¥ä¼˜åŒ–æ–¹æ³•ï¼Œè¯¥æ–¹æ³•åˆ©ç”¨åŸºäºåŒºåŸŸçš„è¯­ä¹‰ä¿¡æ¯æ¥ç›‘ç£è®­ç»ƒï¼Œå°¤å…¶èƒ½æé«˜é‡å»ºè´¨é‡å’Œè¯­ä¹‰å¹³æ»‘åº¦ã€‚æˆ‘ä»¬åœ¨ä¸¤ä¸ªçœŸå®ä¸–ç•Œçš„æ‰‹æœ¯æ•°æ®é›†ä¸Šè¿›è¡Œäº†å…¨é¢çš„å®éªŒï¼Œè¯æ˜äº†SurgTPGSç›¸è¾ƒäºæœ€å…ˆè¿›çš„æ–¹æ³•å…·æœ‰ä¼˜è¶Šæ€§ï¼Œçªå‡ºäº†å…¶åœ¨æ‰‹æœ¯å®è·µä¸­è¿›è¡Œé©å‘½æ€§æ”¹è¿›çš„å·¨å¤§æ½œåŠ›ã€‚SurgTPGSä¸ºå¼€å‘ä¸‹ä¸€ä»£æ™ºèƒ½æ‰‹æœ¯ç³»ç»Ÿé“ºå¹³äº†é“è·¯ï¼Œé€šè¿‡æé«˜æ‰‹æœ¯çš„ç²¾ç¡®æ€§å’Œå®‰å…¨æ€§æ¥æ¨åŠ¨åŒ»å­¦æŠ€æœ¯çš„è¿›æ­¥ã€‚æˆ‘ä»¬çš„ä»£ç å¯åœ¨ï¼š<a target="_blank" rel="noopener" href="https://github.com/lastbasket/SurgTPGS%E8%8E%B7%E5%8F%96%E3%80%82">https://github.com/lastbasket/SurgTPGSè·å–ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.23309v2">PDF</a> MICCAI 2025. Project Page:   <a target="_blank" rel="noopener" href="https://lastbasket.github.io/MICCAI-2025-SurgTPGS/">https://lastbasket.github.io/MICCAI-2025-SurgTPGS/</a></p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†ä¸€ç§åŸºäºæ–‡æœ¬æç¤ºçš„3Dæ‰‹æœ¯åœºæ™¯é‡å»ºæ–¹æ³•SurgTPGSï¼Œè¯¥æ–¹æ³•é‡‡ç”¨é«˜æ–¯æ‰©å±•æŠ€æœ¯ï¼Œå¡«è¡¥å®æ—¶æ–‡æœ¬æç¤º3DæŸ¥è¯¢çš„ç©ºç™½ã€‚é€šè¿‡ç»“åˆå…ˆè¿›çš„è§†è§‰è¯­è¨€æ¨¡å‹å’Œè¯­ä¹‰åˆ†å‰²æŠ€æœ¯ï¼ŒSurgTPGSèƒ½å¤Ÿæ›´å¥½åœ°ç†è§£å¤æ‚çš„æ‰‹æœ¯ç¯å¢ƒï¼Œæä¾›ç²¾ç¡®çš„è¯­ä¹‰ç‰¹å¾é‡å»ºã€‚æ­¤å¤–ï¼Œè¯¥æŠ€æœ¯è¿˜å…·å¤‡è¯­ä¹‰æ„ŸçŸ¥å˜å½¢è·Ÿè¸ªå’ŒåŒºåŸŸæ„ŸçŸ¥ä¼˜åŒ–åŠŸèƒ½ï¼Œæé«˜äº†é‡å»ºè´¨é‡å’Œè¯­ä¹‰å¹³æ»‘åº¦ã€‚å®éªŒè¯æ˜ï¼ŒSurgTPGSåœ¨çœŸå®æ‰‹æœ¯æ•°æ®é›†ä¸Šçš„è¡¨ç°ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œä¸ºå¼€å‘ä¸‹ä¸€ä»£æ™ºèƒ½æ‰‹æœ¯ç³»ç»Ÿæä¾›äº†æ½œåŠ›ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>SurgTPGSå¡«è¡¥äº†åœ¨æ‰‹æœ¯è§„åˆ’å’Œå®æ—¶æ‰‹æœ¯è¿‡ç¨‹ä¸­å®ç°å®æ—¶æ–‡æœ¬æç¤ºçš„ç©ºç™½ã€‚</li>
<li>é€šè¿‡ç»“åˆè§†è§‰è¯­è¨€æ¨¡å‹å’Œè¯­ä¹‰åˆ†å‰²æŠ€æœ¯ï¼ŒSurgTPGSèƒ½æ›´å¥½åœ°ç†è§£å¤æ‚çš„æ‰‹æœ¯ç¯å¢ƒã€‚</li>
<li>SurgTPGSå…·å¤‡è¯­ä¹‰æ„ŸçŸ¥å˜å½¢è·Ÿè¸ªåŠŸèƒ½ï¼Œèƒ½æ— ç¼æ•æ‰è¯­ä¹‰ç‰¹å¾çš„å˜å½¢ã€‚</li>
<li>é€šè¿‡åŒºåŸŸæ„ŸçŸ¥ä¼˜åŒ–æŠ€æœ¯ï¼ŒSurgTPGSæé«˜äº†é‡å»ºè´¨é‡å’Œè¯­ä¹‰å¹³æ»‘åº¦ã€‚</li>
<li>å®éªŒè¯æ˜ï¼ŒSurgTPGSåœ¨çœŸå®æ‰‹æœ¯æ•°æ®é›†ä¸Šçš„è¡¨ç°ä¼˜äºå…¶ä»–ç°æœ‰æ–¹æ³•ã€‚</li>
<li>SurgTPGSæœ‰åŠ©äºå¼€å‘ä¸‹ä¸€ä»£æ™ºèƒ½æ‰‹æœ¯ç³»ç»Ÿï¼Œæé«˜æ‰‹æœ¯çš„ç²¾ç¡®æ€§å’Œå®‰å…¨æ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.23309">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-7592293aff6c6a46b72bb635f2acb850.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-d4f8d9adad1b62a12388b540bf601efc.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-020980491ed3d2fbf0bf6328f0fcd405.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-1910ca05fc8200640c62109961b11780.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="Endo-4DGX-Robust-Endoscopic-Scene-Reconstruction-and-Illumination-Correction-with-Gaussian-Splatting"><a href="#Endo-4DGX-Robust-Endoscopic-Scene-Reconstruction-and-Illumination-Correction-with-Gaussian-Splatting" class="headerlink" title="Endo-4DGX: Robust Endoscopic Scene Reconstruction and Illumination   Correction with Gaussian Splatting"></a>Endo-4DGX: Robust Endoscopic Scene Reconstruction and Illumination   Correction with Gaussian Splatting</h2><p><strong>Authors:Yiming Huang, Long Bai, Beilei Cui, Yanheng Li, Tong Chen, Jie Wang, Jinlin Wu, Zhen Lei, Hongbin Liu, Hongliang Ren</strong></p>
<p>Accurate reconstruction of soft tissue is crucial for advancing automation in image-guided robotic surgery. The recent 3D Gaussian Splatting (3DGS) techniques and their variants, 4DGS, achieve high-quality renderings of dynamic surgical scenes in real-time. However, 3D-GS-based methods still struggle in scenarios with varying illumination, such as low light and over-exposure. Training 3D-GS in such extreme light conditions leads to severe optimization problems and devastating rendering quality. To address these challenges, we present Endo-4DGX, a novel reconstruction method with illumination-adaptive Gaussian Splatting designed specifically for endoscopic scenes with uneven lighting. By incorporating illumination embeddings, our method effectively models view-dependent brightness variations. We introduce a region-aware enhancement module to model the sub-area lightness at the Gaussian level and a spatial-aware adjustment module to learn the view-consistent brightness adjustment. With the illumination adaptive design, Endo-4DGX achieves superior rendering performance under both low-light and over-exposure conditions while maintaining geometric accuracy. Additionally, we employ an exposure control loss to restore the appearance from adverse exposure to the normal level for illumination-adaptive optimization. Experimental results demonstrate that Endo-4DGX significantly outperforms combinations of state-of-the-art reconstruction and restoration methods in challenging lighting environments, underscoring its potential to advance robot-assisted surgical applications. Our code is available at <a target="_blank" rel="noopener" href="https://github.com/lastbasket/Endo-4DGX">https://github.com/lastbasket/Endo-4DGX</a>. </p>
<blockquote>
<p>è½¯ç»„ç»‡é‡å»ºçš„å‡†ç¡®æ€§å¯¹äºæ¨åŠ¨å›¾åƒå¼•å¯¼æœºå™¨äººæ‰‹æœ¯çš„è‡ªåŠ¨åŒ–è‡³å…³é‡è¦ã€‚æœ€è¿‘å‡ºç°çš„3Dé«˜æ–¯æ¸²æŸ“ï¼ˆ3DGSï¼‰æŠ€æœ¯åŠå…¶å˜ä½“ï¼ˆå¦‚å››ç»´æ¸²æŸ“ï¼‰å¯ä»¥å®æ—¶é«˜è´¨é‡æ¸²æŸ“åŠ¨æ€æ‰‹æœ¯åœºæ™¯ã€‚ç„¶è€Œï¼ŒåŸºäºé«˜æ–¯çƒç®—æ³•çš„æ–¹æ³•åœ¨å…‰ç…§æ¡ä»¶ä¸åŒçš„åœºæ™¯ä¸­ä»é¢ä¸´æŒ‘æˆ˜ï¼Œå¦‚ä½å…‰å’Œè¿‡åº¦æ›å…‰ç¯å¢ƒã€‚åœ¨è¿™ç§æç«¯å…‰ç…§æ¡ä»¶ä¸‹è®­ç»ƒä¸‰ç»´GSä¼šå¯¼è‡´ä¸¥é‡çš„ä¼˜åŒ–é—®é¢˜å’Œç¾éš¾æ€§çš„æ¸²æŸ“è´¨é‡ã€‚ä¸ºäº†è§£å†³è¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åä¸ºEndo-4DGXçš„æ–°å‹é‡å»ºæ–¹æ³•ï¼Œå®ƒé‡‡ç”¨è‡ªé€‚åº”å…‰ç…§é«˜æ–¯æ¸²æŸ“æŠ€æœ¯ï¼Œä¸“ä¸ºå†…çª¥é•œåœºæ™¯è®¾è®¡ï¼Œåœºæ™¯ä¸­å­˜åœ¨ä¸å‡åŒ€ç…§æ˜ã€‚é€šè¿‡å¼•å…¥å…‰ç…§åµŒå…¥æŠ€æœ¯ï¼Œæˆ‘ä»¬çš„æ–¹æ³•å¯ä»¥æœ‰æ•ˆåœ°æ¨¡æ‹Ÿä¾èµ–äºè§†å›¾çš„äº®åº¦å˜åŒ–ã€‚æˆ‘ä»¬å¼•å…¥äº†åŒºåŸŸæ„ŸçŸ¥å¢å¼ºæ¨¡å—ï¼Œåœ¨é«˜æ–¯å±‚æ¬¡å¯¹å­åŒºåŸŸäº®åº¦è¿›è¡Œå»ºæ¨¡ï¼Œä»¥åŠç©ºé—´æ„ŸçŸ¥è°ƒæ•´æ¨¡å—ï¼Œå­¦ä¹ è§†å›¾ä¸€è‡´çš„äº®åº¦è°ƒæ•´æ–¹æ³•ã€‚é€šè¿‡è‡ªé€‚åº”å…‰ç…§è®¾è®¡ï¼ŒEndo-4DGXåœ¨ä½å…‰å’Œè¿‡åº¦æ›å…‰æ¡ä»¶ä¸‹å®ç°äº†å‡ºè‰²çš„æ¸²æŸ“æ€§èƒ½ï¼ŒåŒæ—¶ä¿æŒäº†å‡ ä½•ç²¾åº¦ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜é‡‡ç”¨æ›å…‰æ§åˆ¶æŸå¤±æ¢å¤ä»ä¸è‰¯æ›å…‰åˆ°æ­£å¸¸æ°´å¹³çš„å¤–è§‚æ•°æ®ç”¨äºå…‰ç…§è‡ªé€‚åº”ä¼˜åŒ–ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œåœ¨å……æ»¡æŒ‘æˆ˜çš„å…‰ç…§ç¯å¢ƒä¸­ï¼ŒEndo-4DGXæ˜¾è‘—ä¼˜äºæœ€å…ˆè¿›ç»„åˆçš„é‡æ„å’Œæ¢å¤æ–¹æ³•çš„åº”ç”¨æ½œèƒ½å·¨å¤§ã€‚æˆ‘ä»¬çš„ä»£ç å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/lastbasket/Endo-4DGX%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/lastbasket/Endo-4DGXæ‰¾åˆ°ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.23308v1">PDF</a> MICCAI 2025. Project Page:   <a target="_blank" rel="noopener" href="https://lastbasket.github.io/MICCAI-2025-Endo-4DGX/">https://lastbasket.github.io/MICCAI-2025-Endo-4DGX/</a></p>
<p><strong>æ‘˜è¦</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†åœ¨å›¾åƒå¼•å¯¼æœºå™¨äººæ‰‹æœ¯ä¸­è‡ªåŠ¨åŒ–è½¯ç»„ç»‡é‡å»ºçš„é‡è¦æ€§ã€‚é’ˆå¯¹æœ€æ–°çš„ä¸‰ç»´é«˜æ–¯æ•£æ–‘æŠ€æœ¯åŠå…¶å˜ä½“ï¼Œåœ¨å®æ—¶åŠ¨æ€æ‰‹æœ¯åœºæ™¯æ¸²æŸ“ä¸­å–å¾—äº†é«˜è´¨é‡çš„æ•ˆæœã€‚ç„¶è€Œï¼ŒåŸºäºä¸‰ç»´é«˜æ–¯æ•£æ–‘çš„æ–¹æ³•åœ¨å…‰ç…§å˜åŒ–åœºæ™¯ï¼Œå¦‚ä½å…‰å’Œè¿‡æ›å…‰åœºæ™¯ä¸­ï¼Œä»ç„¶å­˜åœ¨æŒ‘æˆ˜ã€‚æœ¬æ–‡æå‡ºä¸€ç§æ–°å‹çš„é‡å»ºæ–¹æ³•â€”â€”Endo-4DGXï¼Œå…·æœ‰è‡ªé€‚åº”å…‰ç…§çš„é«˜æ–¯æ•£æ–‘è®¾è®¡ï¼Œä¸“ä¸ºå…‰ç…§ä¸å‡åŒ€çš„å†…çª¥é•œåœºæ™¯è®¾è®¡ã€‚é€šè¿‡èå…¥å…‰ç…§åµŒå…¥æŠ€æœ¯ï¼Œè¯¥æ–¹æ³•å¯æœ‰æ•ˆæ¨¡æ‹Ÿè§†è§‰äº®åº¦å˜åŒ–ã€‚åŒæ—¶ä»‹ç»äº†ä¸€ä¸ªåŒºåŸŸæ„ŸçŸ¥å¢å¼ºæ¨¡å—ï¼Œå¯¹é«˜æ–¯æ°´å¹³ä¸Šçš„å­åŒºåŸŸäº®åº¦è¿›è¡Œå»ºæ¨¡ï¼Œä»¥åŠä¸€ä¸ªç©ºé—´æ„ŸçŸ¥è°ƒæ•´æ¨¡å—ï¼Œå­¦ä¹ ä¸€è‡´çš„äº®åº¦è°ƒæ•´ã€‚å‡­å€Ÿè‡ªé€‚åº”å…‰ç…§è®¾è®¡ï¼ŒEndo-4DGXåœ¨ä½å…‰å’Œè¿‡æ›å…‰æ¡ä»¶ä¸‹å‡å®ç°äº†å“è¶Šçš„æ¸²æŸ“æ€§èƒ½ï¼ŒåŒæ—¶ä¿æŒäº†å‡ ä½•ç²¾åº¦ã€‚æ­¤å¤–ï¼Œæœ¬æ–‡è¿˜é‡‡ç”¨æ›å…‰æ§åˆ¶æŸå¤±ï¼Œå°†ä¸è‰¯æ›å…‰ä¸‹çš„å¤–è§‚æ¢å¤åˆ°æ­£å¸¸æ°´å¹³ï¼Œä»¥å®ç°è‡ªé€‚åº”å…‰ç…§ä¼˜åŒ–ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒEndo-4DGXåœ¨å…·æœ‰æŒ‘æˆ˜æ€§çš„å…‰ç…§ç¯å¢ƒä¸­æ˜¾è‘—ä¼˜äºæœ€å…ˆè¿›çš„é‡å»ºå’Œæ¢å¤æ–¹æ³•ç»„åˆï¼Œçªæ˜¾å…¶åœ¨æœºå™¨äººè¾…åŠ©æ‰‹æœ¯åº”ç”¨ä¸­çš„æ½œåŠ›ã€‚ä»£ç å¯é€šè¿‡<a target="_blank" rel="noopener" href="https://github.com/lastbasket/Endo-4DGX">https://github.com/lastbasket/Endo-4DGX</a> è·å–ã€‚</p>
<p><strong>è¦ç‚¹åˆ†æ</strong></p>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.23308">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-7427b6c27970e0617a17136467b95137.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-efac474fd1d91ac16eba21345dfea07f.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-536e66e627f68835631022938d272afd.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-5a2cc950cff85a613d14c1c65e639013.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="TVG-SLAM-Robust-Gaussian-Splatting-SLAM-with-Tri-view-Geometric-Constraints"><a href="#TVG-SLAM-Robust-Gaussian-Splatting-SLAM-with-Tri-view-Geometric-Constraints" class="headerlink" title="TVG-SLAM: Robust Gaussian Splatting SLAM with Tri-view Geometric   Constraints"></a>TVG-SLAM: Robust Gaussian Splatting SLAM with Tri-view Geometric   Constraints</h2><p><strong>Authors:Zhen Tan, Xieyuanli Chen, Lei Feng, Yangbing Ge, Shuaifeng Zhi, Jiaxiong Liu, Dewen Hu</strong></p>
<p>Recent advances in 3D Gaussian Splatting (3DGS) have enabled RGB-only SLAM systems to achieve high-fidelity scene representation. However, the heavy reliance of existing systems on photometric rendering loss for camera tracking undermines their robustness, especially in unbounded outdoor environments with severe viewpoint and illumination changes. To address these challenges, we propose TVG-SLAM, a robust RGB-only 3DGS SLAM system that leverages a novel tri-view geometry paradigm to ensure consistent tracking and high-quality mapping. We introduce a dense tri-view matching module that aggregates reliable pairwise correspondences into consistent tri-view matches, forming robust geometric constraints across frames. For tracking, we propose Hybrid Geometric Constraints, which leverage tri-view matches to construct complementary geometric cues alongside photometric loss, ensuring accurate and stable pose estimation even under drastic viewpoint shifts and lighting variations. For mapping, we propose a new probabilistic initialization strategy that encodes geometric uncertainty from tri-view correspondences into newly initialized Gaussians. Additionally, we design a Dynamic Attenuation of Rendering Trust mechanism to mitigate tracking drift caused by mapping latency. Experiments on multiple public outdoor datasets show that our TVG-SLAM outperforms prior RGB-only 3DGS-based SLAM systems. Notably, in the most challenging dataset, our method improves tracking robustness, reducing the average Absolute Trajectory Error (ATE) by 69.0% while achieving state-of-the-art rendering quality. The implementation of our method will be released as open-source. </p>
<blockquote>
<p>è¿‘æœŸä¸‰ç»´é«˜æ–¯æ‘Šé“ºï¼ˆ3DGSï¼‰çš„è¿›å±•ä½¿å¾—ä»…ä½¿ç”¨RGBçš„SLAMç³»ç»Ÿèƒ½å¤Ÿå®ç°é«˜ä¿çœŸåœºæ™¯è¡¨ç¤ºã€‚ç„¶è€Œï¼Œç°æœ‰ç³»ç»Ÿå¯¹åŸºäºå…‰åº¦æ¸²æŸ“æŸå¤±è¿›è¡Œç›¸æœºè·Ÿè¸ªçš„è¿‡åº¦ä¾èµ–ï¼ŒæŸå®³äº†å…¶åœ¨åœºæ™¯ä¸‹çš„ç¨³å¥æ€§ï¼Œç‰¹åˆ«æ˜¯åœ¨æ— è¾¹ç•Œçš„å®¤å¤–ç¯å¢ƒä¸­ï¼Œè§†è§’å’Œå…‰ç…§å˜åŒ–å‰§çƒˆã€‚ä¸ºäº†åº”å¯¹è¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†TVG-SLAMï¼Œè¿™æ˜¯ä¸€ä¸ªç¨³å¥çš„ä»…ä½¿ç”¨RGBçš„3DGS SLAMç³»ç»Ÿï¼Œå®ƒé‡‡ç”¨æ–°é¢–çš„ä¸‰è§†å›¾å‡ ä½•èŒƒå¼ç¡®ä¿ä¸€è‡´çš„è·Ÿè¸ªå’Œé«˜è´¨é‡çš„æ˜ å°„ã€‚æˆ‘ä»¬å¼•å…¥äº†ä¸€ä¸ªå¯†é›†çš„ä¸‰è§†å›¾åŒ¹é…æ¨¡å—ï¼Œè¯¥æ¨¡å—å°†å¯é çš„æˆå¯¹å¯¹åº”å…³ç³»èšé›†ä¸ºä¸€è‡´çš„ä¸‰è§†å›¾åŒ¹é…ï¼Œåœ¨å¸§ä¹‹é—´å½¢æˆç¨³å¥çš„å‡ ä½•çº¦æŸã€‚åœ¨è·Ÿè¸ªæ–¹é¢ï¼Œæˆ‘ä»¬æå‡ºäº†æ··åˆå‡ ä½•çº¦æŸï¼Œåˆ©ç”¨ä¸‰è§†å›¾åŒ¹é…æ¥æ„å»ºä¸å…‰åº¦æŸå¤±ç›¸è¾…ç›¸æˆçš„å‡ ä½•çº¿ç´¢ï¼Œå³ä½¿åœ¨è§†è§’å˜åŒ–å’Œå…‰ç…§å˜åŒ–å‰§çƒˆçš„æƒ…å†µä¸‹ï¼Œä¹Ÿèƒ½ç¡®ä¿å‡†ç¡®ç¨³å®šçš„å§¿æ€ä¼°è®¡ã€‚å¯¹äºæ˜ å°„ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°çš„æ¦‚ç‡åˆå§‹åŒ–ç­–ç•¥ï¼Œå®ƒå°†ä¸‰è§†å›¾å¯¹åº”å…³ç³»ä¸­çš„å‡ ä½•ä¸ç¡®å®šæ€§ç¼–ç åˆ°åˆå§‹åŒ–çš„é«˜æ–¯åˆ†å¸ƒä¸­ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜è®¾è®¡äº†ä¸€ç§åŠ¨æ€è¡°å‡æ¸²æŸ“ä¿¡ä»»æœºåˆ¶ï¼Œä»¥å‡è½»ç”±æ˜ å°„å»¶è¿Ÿå¼•èµ·çš„è·Ÿè¸ªæ¼‚ç§»ã€‚åœ¨å¤šä¸ªå…¬å…±å®¤å¤–æ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„TVG-SLAMä¼˜äºå…ˆå‰çš„ä»…ä½¿ç”¨RGBçš„åŸºäº3DGSçš„SLAMç³»ç»Ÿã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œåœ¨æœ€å…·æŒ‘æˆ˜æ€§çš„æ•°æ®é›†ä¸Šï¼Œæˆ‘ä»¬çš„æ–¹æ³•æé«˜äº†è·Ÿè¸ªçš„ç¨³å¥æ€§ï¼Œå¹³å‡ç»å¯¹è½¨è¿¹è¯¯å·®ï¼ˆATEï¼‰é™ä½äº†69.0%ï¼ŒåŒæ—¶å®ç°äº†æœ€å…ˆè¿›çš„æ¸²æŸ“è´¨é‡ã€‚æˆ‘ä»¬çš„æ–¹æ³•å®ç°å°†ä½œä¸ºå¼€æºå‘å¸ƒã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.23207v1">PDF</a> </p>
<p><strong>æ‘˜è¦</strong></p>
<p>æœ€è¿‘ï¼Œä¸‰ç»´é«˜æ–¯æ¶‚æŠ¹ï¼ˆ3DGSï¼‰æŠ€æœ¯çš„è¿›å±•ä½¿å¾—ä»…ä½¿ç”¨RGBçš„SLAMç³»ç»Ÿèƒ½å¤Ÿå®ç°é«˜ä¿çœŸåœºæ™¯è¡¨ç¤ºã€‚ç„¶è€Œï¼Œç°æœ‰ç³»ç»Ÿå¯¹å…‰åº¦æ¸²æŸ“æŸå¤±çš„ä¸¥é‡ä¾èµ–å½±å“äº†å…¶åœ¨é¢å¯¹åœºæ™¯æ—¶çš„ç¨³å¥æ€§ï¼Œç‰¹åˆ«æ˜¯åœ¨è§†ç‚¹æ— è¾¹ç•Œçš„æˆ·å¤–ç¯å¢ƒä¸­å’Œå…‰ç…§æ¡ä»¶å‘ç”Ÿæ”¹å˜æ—¶ã€‚ä¸ºè§£å†³è¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†TVG-SLAMï¼Œä¸€ä¸ªç¨³å¥çš„ä»…ä½¿ç”¨RGBçš„3DGS SLAMç³»ç»Ÿã€‚è¯¥ç³»ç»Ÿé‡‡ç”¨æ–°å‹çš„ä¸‰è§†å›¾å‡ ä½•æ¨¡å¼ç¡®ä¿ä¸€è‡´çš„è·Ÿè¸ªå’Œé«˜è´¨é‡æ˜ å°„ã€‚æˆ‘ä»¬å¼•å…¥å¯†é›†ä¸‰è§†å›¾åŒ¹é…æ¨¡å—ï¼Œå°†å¯é çš„é…å¯¹å¯¹åº”ç‰©èšåˆä¸ºä¸€è‡´çš„ä¸‰è§†å›¾åŒ¹é…ï¼Œåœ¨å¸§ä¹‹é—´å½¢æˆç¨³å¥çš„å‡ ä½•çº¦æŸã€‚å¯¹äºè·Ÿè¸ªï¼Œæˆ‘ä»¬æå‡ºæ··åˆå‡ ä½•çº¦æŸï¼Œåˆ©ç”¨ä¸‰è§†å›¾åŒ¹é…æ„å»ºä¸å…‰åº¦æŸå¤±ç›¸è¾…ç›¸æˆçš„å‡ ä½•çº¿ç´¢ï¼Œç¡®ä¿å³ä½¿åœ¨è§†ç‚¹å‰§çƒˆå˜åŒ–å’Œå…‰ç…§å˜åŒ–çš„æƒ…å†µä¸‹ä¹Ÿèƒ½è¿›è¡Œå‡†ç¡®ç¨³å®šçš„å§¿æ€ä¼°è®¡ã€‚å¯¹äºæ˜ å°„ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°çš„æ¦‚ç‡åˆå§‹åŒ–ç­–ç•¥ï¼Œå°†ä¸‰è§†å›¾å¯¹åº”çš„å‡ ä½•ä¸ç¡®å®šæ€§ç¼–ç åˆ°åˆå§‹åŒ–åçš„é«˜æ–¯åˆ†å¸ƒä¸­ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜è®¾è®¡äº†ä¸€ç§åŠ¨æ€è¡°å‡æ¸²æŸ“ä¿¡ä»»æœºåˆ¶ï¼Œä»¥å‡è½»ç”±æ˜ å°„å»¶è¿Ÿå¼•èµ·çš„è·Ÿè¸ªæ¼‚ç§»ã€‚åœ¨å¤šä¸ªå…¬å…±æˆ·å¤–æ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„TVG-SLAMä¼˜äºå…ˆå‰çš„ä»…ä½¿ç”¨RGBçš„åŸºäº3DGSçš„SLAMç³»ç»Ÿã€‚ç‰¹åˆ«æ˜¯åœ¨æœ€å…·æŒ‘æˆ˜æ€§çš„æ•°æ®é›†ä¸­ï¼Œæˆ‘ä»¬çš„æ–¹æ³•æé«˜äº†è·Ÿè¸ªçš„ç¨³å¥æ€§ï¼Œå°†å¹³å‡ç»å¯¹è½¨è¿¹è¯¯å·®ï¼ˆATEï¼‰é™ä½äº†69.0%ï¼ŒåŒæ—¶å®ç°äº†æœ€å…ˆè¿›çš„æ¸²æŸ“è´¨é‡ã€‚æˆ‘ä»¬çš„æ–¹æ³•å°†ä½œä¸ºå¼€æºå‘å¸ƒã€‚</p>
<p><strong>è¦ç‚¹å½’çº³</strong></p>
<ol>
<li>RGB-only SLAMç³»ç»Ÿå€ŸåŠ©æœ€è¿‘å‘å±•çš„3DGSæŠ€æœ¯å®ç°é«˜ä¿çœŸåœºæ™¯è¡¨ç¤ºã€‚</li>
<li>ç°æœ‰ç³»ç»Ÿä¾èµ–å…‰åº¦æ¸²æŸ“æŸå¤±è¿›è¡Œç›¸æœºè·Ÿè¸ªï¼Œä½†åœ¨æˆ·å¤–ç¯å¢ƒä¸­å­˜åœ¨è§†è§’å’Œå…‰ç…§å˜åŒ–çš„æŒ‘æˆ˜ã€‚</li>
<li>TVG-SLAMé€šè¿‡å¼•å…¥ä¸‰è§†å›¾å‡ ä½•æ¨¡å¼æ¥æé«˜RGB-only 3DGS SLAMç³»ç»Ÿçš„ç¨³å¥æ€§ã€‚</li>
<li>æå‡ºå¯†é›†ä¸‰è§†å›¾åŒ¹é…æ¨¡å—å’Œä¸‰è§†å›¾å‡ ä½•çº¦æŸä»¥å¢å¼ºè·Ÿè¸ªçš„å‡†ç¡®æ€§åŠç¨³å®šæ€§ã€‚</li>
<li>æ–°é¢–çš„æ¦‚ç‡åˆå§‹åŒ–ç­–ç•¥å’ŒåŠ¨æ€è¡°å‡æ¸²æŸ“ä¿¡ä»»æœºåˆ¶æ”¹å–„æ˜ å°„å¹¶é™ä½è·Ÿè¸ªæ¼‚ç§»ã€‚</li>
<li>åœ¨å…¬å…±æˆ·å¤–æ•°æ®é›†ä¸Šçš„å®éªŒè¯æ˜TVG-SLAMçš„æ€§èƒ½è¶…è¶Šç°æœ‰æ–¹æ³•ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.23207">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-817934896ac4a0f880d3cf9255c1e267.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e8b30d5374f74c6764e1aab556334a12.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-a4435cfe8711acd1220ac7d99dc35942.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d7e995bedf2cacb8d73a84726005f6a1.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="STD-GS-Exploring-Frame-Event-Interaction-for-SpatioTemporal-Disentangled-Gaussian-Splatting-to-Reconstruct-High-Dynamic-Scene"><a href="#STD-GS-Exploring-Frame-Event-Interaction-for-SpatioTemporal-Disentangled-Gaussian-Splatting-to-Reconstruct-High-Dynamic-Scene" class="headerlink" title="STD-GS: Exploring Frame-Event Interaction for   SpatioTemporal-Disentangled Gaussian Splatting to Reconstruct High-Dynamic   Scene"></a>STD-GS: Exploring Frame-Event Interaction for   SpatioTemporal-Disentangled Gaussian Splatting to Reconstruct High-Dynamic   Scene</h2><p><strong>Authors:Hanyu Zhou, Haonan Wang, Haoyue Liu, Yuxing Duan, Luxin Yan, Gim Hee Lee</strong></p>
<p>High-dynamic scene reconstruction aims to represent static background with rigid spatial features and dynamic objects with deformed continuous spatiotemporal features. Typically, existing methods adopt unified representation model (e.g., Gaussian) to directly match the spatiotemporal features of dynamic scene from frame camera. However, this unified paradigm fails in the potential discontinuous temporal features of objects due to frame imaging and the heterogeneous spatial features between background and objects. To address this issue, we disentangle the spatiotemporal features into various latent representations to alleviate the spatiotemporal mismatching between background and objects. In this work, we introduce event camera to compensate for frame camera, and propose a spatiotemporal-disentangled Gaussian splatting framework for high-dynamic scene reconstruction. As for dynamic scene, we figure out that background and objects have appearance discrepancy in frame-based spatial features and motion discrepancy in event-based temporal features, which motivates us to distinguish the spatiotemporal features between background and objects via clustering. As for dynamic object, we discover that Gaussian representations and event data share the consistent spatiotemporal characteristic, which could serve as a prior to guide the spatiotemporal disentanglement of object Gaussians. Within Gaussian splatting framework, the cumulative scene-object disentanglement can improve the spatiotemporal discrimination between background and objects to render the time-continuous dynamic scene. Extensive experiments have been performed to verify the superiority of the proposed method. </p>
<blockquote>
<p>åŠ¨æ€åœºæ™¯é‡å»ºæ—¨åœ¨è¡¨ç¤ºå…·æœ‰åˆšä½“ç©ºé—´ç‰¹å¾çš„é™æ€èƒŒæ™¯å’Œå…·æœ‰å˜å½¢è¿ç»­æ—¶ç©ºç‰¹å¾çš„åŠ¨æ€å¯¹è±¡ã€‚é€šå¸¸ï¼Œç°æœ‰æ–¹æ³•é‡‡ç”¨ç»Ÿä¸€è¡¨ç¤ºæ¨¡å‹ï¼ˆä¾‹å¦‚é«˜æ–¯æ¨¡å‹ï¼‰æ¥ç›´æ¥åŒ¹é…åŠ¨æ€åœºæ™¯çš„æ—¶ç©ºç‰¹å¾ã€‚ç„¶è€Œï¼Œç”±äºå¸§æˆåƒçš„æ½œåœ¨ä¸è¿ç»­æ—¶é—´ç‰¹å¾å’ŒèƒŒæ™¯ä¸å¯¹è±¡ä¹‹é—´çš„å¼‚æ„å›¾ç©ºé—´ç‰¹å¾ï¼Œè¿™ç§ç»Ÿä¸€çš„æ–¹æ³•å¹¶ä¸å¥æ•ˆã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬å°†æ—¶ç©ºç‰¹å¾åˆ†è§£æˆå„ç§æ½œåœ¨è¡¨ç°å½¢å¼ï¼Œä»¥å‡è½»èƒŒæ™¯å’Œå¯¹è±¡ä¹‹é—´çš„æ—¶ç©ºä¸åŒ¹é…é—®é¢˜ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬å¼•å…¥äº‹ä»¶ç›¸æœºæ¥è¡¥å¿å¸§ç›¸æœºï¼Œå¹¶æå‡ºä¸€ç§æ—¶ç©ºåˆ†ç¦»çš„åŸºäºé«˜æ–¯è´´å›¾çš„é«˜åŠ¨æ€åœºæ™¯é‡å»ºæ¡†æ¶ã€‚å¯¹äºåŠ¨æ€åœºæ™¯ï¼Œæˆ‘ä»¬å‘ç°èƒŒæ™¯å’Œå¯¹è±¡åœ¨åŸºäºå¸§çš„ç©ºé—´ç‰¹å¾å’ŒåŸºäºäº‹ä»¶çš„æ—¶åºç‰¹å¾æ–¹é¢å­˜åœ¨å¤–è§‚å’Œè¿åŠ¨å·®å¼‚ï¼Œè¿™ä¿ƒä½¿æˆ‘ä»¬é€šè¿‡èšç±»æ¥åŒºåˆ†èƒŒæ™¯å’Œå¯¹è±¡ä¹‹é—´çš„æ—¶ç©ºç‰¹å¾ã€‚å¯¹äºåŠ¨æ€å¯¹è±¡ï¼Œæˆ‘ä»¬å‘ç°é«˜æ–¯è¡¨ç¤ºå’Œäº‹ä»¶æ•°æ®å…·æœ‰ä¸€è‡´çš„æ—¶ç©ºç‰¹æ€§ï¼Œå¯ä½œä¸ºå¼•å¯¼å¯¹è±¡é«˜æ–¯æ—¶ç©ºåˆ†ç¦»çš„å…ˆéªŒä¿¡æ¯ã€‚åœ¨é«˜æ–¯è´´å›¾æ¡†æ¶å†…ï¼Œç´¯ç§¯çš„åœºæ™¯å¯¹è±¡åˆ†ç¦»å¯ä»¥æé«˜èƒŒæ™¯å’Œå¯¹è±¡ä¹‹é—´çš„æ—¶ç©ºé‰´åˆ«èƒ½åŠ›ï¼Œä»¥å‘ˆç°è¿ç»­çš„æ—¶é—´åŠ¨æ€åœºæ™¯ã€‚å·²ç»è¿›è¡Œäº†å¤§é‡å®éªŒæ¥éªŒè¯æ‰€æå‡ºæ–¹æ³•çš„ä¼˜è¶Šæ€§ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.23157v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>é«˜åŠ¨æ€åœºæ™¯é‡å»ºä¸­ï¼Œä¼ ç»Ÿç»Ÿä¸€æ¨¡å‹åœ¨æ—¶ç©ºç‰¹å¾è¡¨è¾¾ä¸Šè¡¨ç°ä¸è¶³ã€‚ä¸ºè§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæœ¬æ–‡æå‡ºå°†æ—¶ç©ºç‰¹å¾åˆ†ç¦»æˆå¤šç§æ½œåœ¨è¡¨è¾¾ï¼Œå¼•å…¥äº‹ä»¶ç›¸æœºè¡¥å¿å¸§ç›¸æœºï¼Œæ„å»ºæ—¶ç©ºåˆ†ç¦»çš„Gaussian splattingæ¡†æ¶ã€‚é€šè¿‡èšç±»åŒºåˆ†èƒŒæ™¯å’Œå¯¹è±¡çš„æ—¶ç©ºç‰¹å¾ï¼Œå¹¶åˆ©ç”¨Gaussianè¡¨è¾¾å’Œäº‹ä»¶æ•°æ®çš„æ—¶ç©ºä¸€è‡´æ€§ï¼Œæé«˜åŠ¨æ€ç‰©ä½“çš„æ—¶ç©ºåˆ†ç¦»æ•ˆæœã€‚å®éªŒéªŒè¯æ‰€ææ–¹æ³•ä¼˜è¶Šæ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>é«˜åŠ¨æ€åœºæ™¯é‡å»ºéœ€åŒºåˆ†é™æ€èƒŒæ™¯ä¸åŠ¨æ€å¯¹è±¡çš„æ—¶ç©ºç‰¹å¾ã€‚</li>
<li>ä¼ ç»Ÿç»Ÿä¸€æ¨¡å‹åœ¨è¡¨è¾¾æ—¶ç©ºç‰¹å¾æ—¶å­˜åœ¨æ½œåœ¨ä¸è¿ç»­æ€§å’Œå¼‚è´¨æ€§é—®é¢˜ã€‚</li>
<li>å¼•å…¥äº‹ä»¶ç›¸æœºè¡¥å¿å¸§ç›¸æœºï¼Œæ„å»ºæ—¶ç©ºåˆ†ç¦»çš„Gaussian splattingæ¡†æ¶ã€‚</li>
<li>é€šè¿‡èšç±»åŒºåˆ†èƒŒæ™¯å’Œå¯¹è±¡çš„æ—¶ç©ºç‰¹å¾ã€‚</li>
<li>Gaussianè¡¨è¾¾å’Œäº‹ä»¶æ•°æ®åœ¨æ—¶ç©ºç‰¹å¾ä¸Šå…·æœ‰ä¸€è‡´æ€§ï¼Œå¯ä½œä¸ºæ—¶ç©ºåˆ†ç¦»çš„å…ˆéªŒä¿¡æ¯ã€‚</li>
<li>åœ¨Gaussian splattingæ¡†æ¶ä¸‹ï¼Œåœºæ™¯ä¸ç‰©ä½“çš„æ—¶ç©ºåˆ†ç¦»èƒ½æé«˜èƒŒæ™¯ä¸ç‰©ä½“çš„åŒºåˆ†åº¦ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.23157">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-245a1ad64dbc030ddfe2d753a8e071e5.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d41e4c581c3ba6e0bc2ee876072fff74.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-c33e8725a8d70f128e13ce1da6cb994a.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-225f44ef390a5de2f96b468b56973400.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-97f6dd15ed461031a4c4419784e3119a.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-fa55c47d668e377454e692ec9472fa7e.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="From-Coarse-to-Fine-Learnable-Discrete-Wavelet-Transforms-for-Efficient-3D-Gaussian-Splatting"><a href="#From-Coarse-to-Fine-Learnable-Discrete-Wavelet-Transforms-for-Efficient-3D-Gaussian-Splatting" class="headerlink" title="From Coarse to Fine: Learnable Discrete Wavelet Transforms for Efficient   3D Gaussian Splatting"></a>From Coarse to Fine: Learnable Discrete Wavelet Transforms for Efficient   3D Gaussian Splatting</h2><p><strong>Authors:Hung Nguyen, An Le, Runfa Li, Truong Nguyen</strong></p>
<p>3D Gaussian Splatting has emerged as a powerful approach in novel view synthesis, delivering rapid training and rendering but at the cost of an ever-growing set of Gaussian primitives that strains memory and bandwidth. We introduce AutoOpti3DGS, a training-time framework that automatically restrains Gaussian proliferation without sacrificing visual fidelity. The key idea is to feed the input images to a sequence of learnable Forward and Inverse Discrete Wavelet Transforms, where low-pass filters are kept fixed, high-pass filters are learnable and initialized to zero, and an auxiliary orthogonality loss gradually activates fine frequencies. This wavelet-driven, coarse-to-fine process delays the formation of redundant fine Gaussians, allowing 3DGS to capture global structure first and refine detail only when necessary. Through extensive experiments, AutoOpti3DGS requires just a single filter learning-rate hyper-parameter, integrates seamlessly with existing efficient 3DGS frameworks, and consistently produces sparser scene representations more compatible with memory or storage-constrained hardware. </p>
<blockquote>
<p>3Dé«˜æ–¯å±•å¼€ä½œä¸ºä¸€ç§æ–°å‹è§†å›¾åˆæˆä¸­çš„å¼ºå¤§æ–¹æ³•ï¼Œè™½ç„¶å¯ä»¥å®ç°å¿«é€Ÿè®­ç»ƒå’Œæ¸²æŸ“ï¼Œä½†å…¶ä»£ä»·æ˜¯ä¸æ–­å¢åŠ çš„é«˜æ–¯åŸºæœ¬å…ƒç´ é›†ï¼Œè¿™ä¼šç»™å†…å­˜å’Œå¸¦å®½å¸¦æ¥å‹åŠ›ã€‚æˆ‘ä»¬å¼•å…¥äº†AutoOpti3DGSï¼Œè¿™æ˜¯ä¸€ä¸ªè®­ç»ƒæ—¶æ¡†æ¶ï¼Œèƒ½å¤Ÿè‡ªåŠ¨æŠ‘åˆ¶é«˜æ–¯åŸºæœ¬å…ƒç´ çš„å¢æ®–ï¼ŒåŒæ—¶ä¸ç‰ºç‰²è§†è§‰ä¿çœŸåº¦ã€‚ä¸»è¦æ€æƒ³æ˜¯å°†è¾“å…¥å›¾åƒè¾“å…¥åˆ°ä¸€ç³»åˆ—å¯å­¦ä¹ çš„å‰å‘å’Œåå‘ç¦»æ•£å°æ³¢å˜æ¢ä¸­ï¼Œå…¶ä¸­ä½é€šæ»¤æ³¢å™¨ä¿æŒä¸å˜ï¼Œé«˜é€šæ»¤æ³¢å™¨å¯å­¦ä¹ å¹¶åˆå§‹åŒ–ä¸ºé›¶ï¼Œä¸€ä¸ªè¾…åŠ©æ­£äº¤æ€§æŸå¤±é€æ¸æ¿€æ´»ç²¾ç»†é¢‘ç‡ã€‚è¿™ç§å°æ³¢é©±åŠ¨çš„ç”±ç²—åˆ°ç»†çš„è¿‡ç¨‹å»¶è¿Ÿäº†å†—ä½™ç²¾ç»†é«˜æ–¯çš„å½¢æˆï¼Œä½¿å¾—3DGSå¯ä»¥å…ˆæ•æ‰å…¨å±€ç»“æ„ï¼Œåªåœ¨å¿…è¦æ—¶è¿›è¡Œç»†èŠ‚ä¼˜åŒ–ã€‚é€šè¿‡å¹¿æ³›çš„å®éªŒï¼ŒAutoOpti3DGSåªéœ€è¦ä¸€ä¸ªå•ä¸€æ»¤æ³¢å™¨å­¦ä¹ ç‡è¶…å‚æ•°ï¼Œå¯ä»¥ä¸ç°æœ‰çš„é«˜æ•ˆ3DGSæ¡†æ¶æ— ç¼é›†æˆï¼Œå¹¶ä¸”å§‹ç»ˆäº§ç”Ÿæ›´ç¨€ç–çš„åœºæ™¯è¡¨ç¤ºï¼Œä¸å†…å­˜æˆ–å­˜å‚¨å—é™çš„ç¡¬ä»¶æ›´å…¼å®¹ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.23042v1">PDF</a> Accepted to ICCV Workshop</p>
<p><strong>Summary</strong></p>
<p>åœ¨ä¸‰ç»´é«˜æ–¯å˜å½¢ï¼ˆ3DGSï¼‰æŠ€æœ¯ä¸­ï¼Œéšç€è§†è§’åˆæˆï¼ˆNovel View Synthesisï¼‰çš„å¿«é€Ÿè®­ç»ƒä¸æ¸²æŸ“è¿‡ç¨‹çš„éœ€æ±‚ï¼Œä¸€ç§åä¸ºAutoOpti3DGSçš„è®­ç»ƒæ—¶é—´æ¡†æ¶åº”è¿è€Œç”Ÿã€‚è¯¥æ¡†æ¶èƒ½å¤Ÿè‡ªåŠ¨æŠ‘åˆ¶é«˜æ–¯åŸºå…ƒï¼ˆGaussian primitivesï¼‰çš„è¿‡åº¦å¢é•¿ï¼ŒåŒæ—¶ä¸æŸå¤±è§†è§‰ä¿çœŸåº¦ã€‚å…¶æ ¸å¿ƒæ€æƒ³æ˜¯é€šè¿‡å¼•å…¥ç¦»æ•£å°æ³¢å˜æ¢ï¼Œå…ˆå­¦ä¹ åœºæ™¯çš„ä½é¢‘ç»“æ„ä¿¡æ¯ï¼Œé€æ¸æ·»åŠ é«˜é¢‘ç»†èŠ‚ã€‚æ­¤æ–¹æ³•æ—¢æ»¡è¶³äº†å¿«é€Ÿçš„è®­ç»ƒå’Œæ¸²æŸ“éœ€æ±‚ï¼Œåˆèƒ½é¿å…ç”±äºé«˜æ–¯åŸºå…ƒçš„å¢å¤šè€Œå¼•å‘çš„å†…å­˜å’Œå¸¦å®½é—®é¢˜ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>AutoOpti3DGSæ¡†æ¶é€šè¿‡å¼•å…¥ç¦»æ•£å°æ³¢å˜æ¢æ¥æŠ‘åˆ¶é«˜æ–¯åŸºå…ƒçš„è¿‡åº¦å¢é•¿ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.23042">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-b59d09e903bb92c142f28bb78af459bc.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-4397ae23dc0201793d9ab3070a37fb30.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-117e85e0a4393c13b0a9a5cc6507e5f5.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-3bec9c0e330c1cff828ff8e397522ab1.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-55529e19e17c4d2954deb98cde51afd1.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-2b2b03cfb8ffac1a42ff47066bdb5d79.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-825da03c12c22041546381554c9bce50.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-c20e3d807b3ffee9542bea05c047b497.jpg" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="Confident-Splatting-Confidence-Based-Compression-of-3D-Gaussian-Splatting-via-Learnable-Beta-Distributions"><a href="#Confident-Splatting-Confidence-Based-Compression-of-3D-Gaussian-Splatting-via-Learnable-Beta-Distributions" class="headerlink" title="Confident Splatting: Confidence-Based Compression of 3D Gaussian   Splatting via Learnable Beta Distributions"></a>Confident Splatting: Confidence-Based Compression of 3D Gaussian   Splatting via Learnable Beta Distributions</h2><p><strong>Authors:AmirHossein Naghi Razlighi, Elaheh Badali Golezani, Shohreh Kasaei</strong></p>
<p>3D Gaussian Splatting enables high-quality real-time rendering but often produces millions of splats, resulting in excessive storage and computational overhead. We propose a novel lossy compression method based on learnable confidence scores modeled as Beta distributions. Each splatâ€™s confidence is optimized through reconstruction-aware losses, enabling pruning of low-confidence splats while preserving visual fidelity. The proposed approach is architecture-agnostic and can be applied to any Gaussian Splatting variant. In addition, the average confidence values serve as a new metric to assess the quality of the scene. Extensive experiments demonstrate favorable trade-offs between compression and fidelity compared to prior work. Our code and data are publicly available at <a target="_blank" rel="noopener" href="https://github.com/amirhossein-razlighi/Confident-Splatting">https://github.com/amirhossein-razlighi/Confident-Splatting</a> </p>
<blockquote>
<p>3Dé«˜æ–¯å»¶å±•æŠ€æœ¯èƒ½å¤Ÿå®ç°é«˜è´¨é‡å®æ—¶æ¸²æŸ“ï¼Œä½†é€šå¸¸ä¼šäº§ç”Ÿæ•°ç™¾ä¸‡ä¸ªå±•ç‚¹ï¼Œå¯¼è‡´å­˜å‚¨å’Œè®¡ç®—å¼€é”€è¿‡å¤§ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§åŸºäºå¯å­¦ä¹ ç½®ä¿¡åº¦åˆ†æ•°çš„æœ‰æŸå‹ç¼©æ–¹æ³•ï¼Œè¿™äº›ç½®ä¿¡åº¦åˆ†æ•°è¢«å»ºæ¨¡ä¸ºBetaåˆ†å¸ƒã€‚æ¯ä¸ªå±•ç‚¹çš„ç½®ä¿¡åº¦é€šè¿‡é‡å»ºæ„ŸçŸ¥æŸå¤±è¿›è¡Œä¼˜åŒ–ï¼Œèƒ½å¤Ÿåœ¨ä¿æŒè§†è§‰ä¿çœŸåº¦çš„åŒæ—¶å‰”é™¤ä½ç½®ä¿¡åº¦å±•ç‚¹ã€‚æ‰€æå‡ºçš„æ–¹æ³•ä¸ä¾èµ–äºç‰¹å®šæ¶æ„ï¼Œå¯åº”ç”¨äºä»»ä½•é«˜æ–¯å»¶å±•æŠ€æœ¯å˜ä½“ã€‚æ­¤å¤–ï¼Œå¹³å‡ç½®ä¿¡å€¼å¯ä½œä¸ºè¯„ä¼°åœºæ™¯è´¨é‡çš„æ–°æŒ‡æ ‡ã€‚å¤§é‡å®éªŒè¯æ˜ï¼Œä¸å…ˆå‰çš„å·¥ä½œç›¸æ¯”ï¼Œè¯¥æ–¹æ³•åœ¨å‹ç¼©å’Œä¿çœŸåº¦ä¹‹é—´å–å¾—äº†æœ‰åˆ©çš„æƒè¡¡ã€‚æˆ‘ä»¬çš„ä»£ç å’Œæ•°æ®å…¬å¼€åœ¨<a target="_blank" rel="noopener" href="https://github.com/amirhossein-razlighi/Confident-Splatting%E3%80%82">https://github.com/amirhossein-razlighi/Confident-Splattingã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.22973v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†åŸºäºå¯å­¦ä¹ çš„ç½®ä¿¡åº¦åˆ†æ•°æ¨¡å‹çš„æŸå¤±å‹ç¼©æ–¹æ³•ï¼Œç”¨äºä¼˜åŒ–3Dé«˜æ–¯å–·æº…æ¸²æŸ“ã€‚è¯¥æ–¹æ³•é€šè¿‡é‡å»ºæ„ŸçŸ¥æŸå¤±ä¼˜åŒ–æ¯ä¸ªå–·æº…çš„ç½®ä¿¡åº¦ï¼Œèƒ½å¤Ÿåœ¨ä¿ç•™è§†è§‰ä¿çœŸåº¦çš„åŒæ—¶åˆ é™¤ä½ç½®ä¿¡åº¦çš„å–·æº…ã€‚æ­¤æ–¹æ³•å…·æœ‰é€šç”¨æ€§ï¼Œå¯åº”ç”¨äºä»»ä½•é«˜æ–¯å–·æº…å˜ä½“ã€‚åŒæ—¶ï¼Œå¹³å‡ç½®ä¿¡å€¼ä½œä¸ºè¯„ä¼°åœºæ™¯è´¨é‡çš„æ–°æŒ‡æ ‡ã€‚å®éªŒè¯æ˜ï¼Œä¸å…ˆå‰çš„å·¥ä½œç›¸æ¯”ï¼Œè¯¥æ–¹æ³•åœ¨å‹ç¼©å’Œä¿çœŸåº¦ä¹‹é—´å–å¾—äº†æœ‰åˆ©çš„æƒè¡¡ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>3Dé«˜æ–¯å–·æº…å®æ—¶æ¸²æŸ“è´¨é‡é«˜ï¼Œä½†äº§ç”Ÿå¤§é‡å–·æº…æ•°æ®ï¼Œå¯¼è‡´å­˜å‚¨å’Œè®¡ç®—å¼€é”€å¤§ã€‚</li>
<li>æå‡ºäº†ä¸€ç§åŸºäºå¯å­¦ä¹ ç½®ä¿¡åº¦åˆ†æ•°çš„æŸå¤±å‹ç¼©æ–¹æ³•ï¼Œä¼˜åŒ–æ¯ä¸ªå–·æº…çš„ç½®ä¿¡åº¦ã€‚</li>
<li>é€šè¿‡é‡å»ºæ„ŸçŸ¥æŸå¤±ä¼˜åŒ–ç½®ä¿¡åº¦ï¼Œèƒ½åœ¨ä¿ç•™è§†è§‰ä¿çœŸåº¦çš„åŒæ—¶åˆ é™¤ä½ç½®ä¿¡åº¦çš„å–·æº…ã€‚</li>
<li>è¯¥æ–¹æ³•å…·æœ‰é€šç”¨æ€§ï¼Œé€‚ç”¨äºä»»ä½•é«˜æ–¯å–·æº…å˜ä½“ã€‚</li>
<li>å¹³å‡ç½®ä¿¡å€¼å¯ä½œä¸ºè¯„ä¼°åœºæ™¯è´¨é‡çš„æ–°æŒ‡æ ‡ã€‚</li>
<li>å®éªŒæ˜¾ç¤ºï¼Œä¸ä»¥å‰çš„æ–¹æ³•ç›¸æ¯”ï¼Œè¯¥æ–¹æ³•åœ¨å‹ç¼©å’Œä¿çœŸåº¦ä¹‹é—´å–å¾—äº†æ›´å¥½çš„å¹³è¡¡ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.22973">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-35a58bbe0db969a36c7a71858771ed82.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-4a2f62fa3eaf18e4dda8a3e565ee8140.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-8dac93d899f17188fac95f2da4dea981.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-92ea4eec2b4c39838ffab0baf31bf507.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-2942823b5306f36d3455c8d82458985b.jpg" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1><h2 id="RGE-GS-Reward-Guided-Expansive-Driving-Scene-Reconstruction-via-Diffusion-Priors"><a href="#RGE-GS-Reward-Guided-Expansive-Driving-Scene-Reconstruction-via-Diffusion-Priors" class="headerlink" title="RGE-GS: Reward-Guided Expansive Driving Scene Reconstruction via   Diffusion Priors"></a>RGE-GS: Reward-Guided Expansive Driving Scene Reconstruction via   Diffusion Priors</h2><p><strong>Authors:Sicong Du, Jiarun Liu, Qifeng Chen, Hao-Xiang Chen, Tai-Jiang Mu, Sheng Yang</strong></p>
<p>A single-pass driving clip frequently results in incomplete scanning of the road structure, making reconstructed scene expanding a critical requirement for sensor simulators to effectively regress driving actions. Although contemporary 3D Gaussian Splatting (3DGS) techniques achieve remarkable reconstruction quality, their direct extension through the integration of diffusion priors often introduces cumulative physical inconsistencies and compromises training efficiency. To address these limitations, we present RGE-GS, a novel expansive reconstruction framework that synergizes diffusion-based generation with reward-guided Gaussian integration. The RGE-GS framework incorporates two key innovations: First, we propose a reward network that learns to identify and prioritize consistently generated patterns prior to reconstruction phases, thereby enabling selective retention of diffusion outputs for spatial stability. Second, during the reconstruction process, we devise a differentiated training strategy that automatically adjust Gaussian optimization progress according to scene converge metrics, which achieving better convergence than baseline methods. Extensive evaluations of publicly available datasets demonstrate that RGE-GS achieves state-of-the-art performance in reconstruction quality. Our source-code will be made publicly available at <a target="_blank" rel="noopener" href="https://github.com/CN-ADLab/RGE-GS">https://github.com/CN-ADLab/RGE-GS</a>. (Camera-ready version incorporating reviewer suggestions will be updated soon.) </p>
<blockquote>
<p>ä½¿ç”¨å•é€šé“é©¾é©¶è§†é¢‘ç‰‡æ®µç»å¸¸å¯¼è‡´å¯¹é“è·¯ç»“æ„çš„ä¸å®Œå…¨æ‰«æï¼Œè¿™ä½¿å¾—é‡å»ºåœºæ™¯å¯¹äºä¼ æ„Ÿå™¨æ¨¡æ‹Ÿå™¨æœ‰æ•ˆåœ°å›å½’é©¾é©¶åŠ¨ä½œè‡³å…³é‡è¦ã€‚å°½ç®¡å½“å‰çš„3Dé«˜æ–¯æ‹¼è´´ï¼ˆ3DGSï¼‰æŠ€æœ¯å®ç°äº†ä»¤äººå°è±¡æ·±åˆ»çš„é‡å»ºè´¨é‡ï¼Œä½†å®ƒä»¬é€šè¿‡é›†æˆæ‰©æ•£å…ˆéªŒçš„ç›´æ¥æ‰©å±•ç»å¸¸å¼•å…¥ç´¯ç§¯çš„ç‰©ç†ä¸ä¸€è‡´æ€§å¹¶æŸå®³è®­ç»ƒæ•ˆç‡ã€‚ä¸ºäº†è§£å†³è¿™äº›å±€é™æ€§ï¼Œæˆ‘ä»¬æå‡ºäº†RGE-GSï¼Œè¿™æ˜¯ä¸€ç§æ–°å‹æ‰©å±•é‡å»ºæ¡†æ¶ï¼Œå®ƒååŒåŸºäºæ‰©æ•£çš„ç”Ÿæˆä¸å¥–åŠ±å¼•å¯¼çš„é«˜æ–¯ç§¯åˆ†ã€‚RGE-GSæ¡†æ¶åŒ…å«ä¸¤ä¸ªå…³é”®åˆ›æ–°ç‚¹ï¼šé¦–å…ˆï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§å¥–åŠ±ç½‘ç»œï¼Œè¯¥ç½‘ç»œåœ¨é‡å»ºé˜¶æ®µä¹‹å‰å­¦ä¹ è¯†åˆ«å’Œä¼˜å…ˆç”Ÿæˆä¸€è‡´çš„æ¨¡å¼ï¼Œä»è€Œèƒ½å¤Ÿæœ‰é€‰æ‹©åœ°ä¿ç•™æ‰©æ•£è¾“å‡ºä»¥å®ç°ç©ºé—´ç¨³å®šæ€§ã€‚å…¶æ¬¡ï¼Œåœ¨é‡å»ºè¿‡ç¨‹ä¸­ï¼Œæˆ‘ä»¬è®¾è®¡äº†ä¸€ç§å·®å¼‚åŒ–çš„è®­ç»ƒç­–ç•¥ï¼Œè¯¥ç­–ç•¥èƒ½å¤Ÿæ ¹æ®åœºæ™¯æ”¶æ•›æŒ‡æ ‡è‡ªåŠ¨è°ƒæ•´é«˜æ–¯ä¼˜åŒ–è¿›åº¦ï¼Œä»è€Œå®ç°æ¯”åŸºçº¿æ–¹æ³•æ›´å¥½çš„æ”¶æ•›ã€‚å¯¹å…¬å¼€å¯ç”¨æ•°æ®é›†çš„å¹¿æ³›è¯„ä¼°è¡¨æ˜ï¼ŒRGE-GSåœ¨é‡å»ºè´¨é‡æ–¹é¢è¾¾åˆ°äº†æœ€æ–°æŠ€æœ¯æ°´å¹³ã€‚æˆ‘ä»¬çš„æºä»£ç å°†åœ¨<a target="_blank" rel="noopener" href="https://github.com/CN-ADLab/RGE-GS%E4%B8%8A%E5%85%AC%E5%BC%80%E3%80%82(%E5%8C%B9%E4%BB%AC%E4%BA%BA%E7%BB%B4%E5%BB%BA%E8%AE%AE%E7%9A%84%E7%BB%AA%E5%AD%A3%E7%89%88%E6%9C%AC%E5%B0%86%E5%BF%AB%E9%80%9F%E6%9B%B4%E6%96%B0%">https://github.com/CN-ADLab/RGE-GSä¸Šå…¬å¼€ã€‚(åŒ…å«å®¡ç¨¿äººå»ºè®®çš„æœ€ç»ˆç‰ˆæœ¬å°†å¾ˆå¿«æ›´æ–°ã€‚)</a>ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.22800v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>è¯¥æ–‡æœ¬ä»‹ç»äº†ä¸€ç§åä¸ºRGE-GSçš„æ–°å‹é‡å»ºæ¡†æ¶ï¼Œè¯¥æ¡†æ¶ç»“åˆäº†æ‰©æ•£ç”Ÿæˆå’Œå¥–åŠ±å¼•å¯¼çš„é«˜æ–¯ç§¯åˆ†ï¼Œç”¨äºè§£å†³å•é€šé“é©¾é©¶è§†é¢‘ä¸­çš„é“è·¯ç»“æ„æ‰«æä¸å®Œæ•´é—®é¢˜ã€‚RGE-GSé€šè¿‡å¼•å…¥å¥–åŠ±ç½‘ç»œå’Œå·®å¼‚åŒ–è®­ç»ƒç­–ç•¥ï¼Œæé«˜äº†é‡å»ºè´¨é‡å’Œè®­ç»ƒæ•ˆç‡ï¼Œè¾¾åˆ°ä¸šç•Œé¢†å…ˆæ°´å¹³ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å½“ä»£3D Gaussian Splattingï¼ˆ3DGSï¼‰æŠ€æœ¯åœ¨é‡å»ºè´¨é‡ä¸Šè¡¨ç°å‡ºè‰²ï¼Œä½†å…¶é€šè¿‡é›†æˆæ‰©æ•£å…ˆéªŒçš„ç›´æ¥æ‰©å±•ç»å¸¸å¼•å…¥ç´¯ç§¯çš„ç‰©ç†ä¸ä¸€è‡´æ€§å¹¶å½±å“è®­ç»ƒæ•ˆç‡ã€‚</li>
<li>RGE-GSæ¡†æ¶æå‡ºäº†ä¸€ç§å¥–åŠ±ç½‘ç»œï¼Œç”¨äºåœ¨é‡å»ºé˜¶æ®µå‰è¯†åˆ«å’Œä¼˜å…ˆå¤„ç†ä¸€è‡´ç”Ÿæˆçš„å›¾æ¡ˆï¼Œä»è€Œå®ç°é€‰æ‹©æ€§ä¿ç•™æ‰©æ•£è¾“å‡ºä»¥æé«˜ç©ºé—´ç¨³å®šæ€§ã€‚</li>
<li>RGE-GSåœ¨é‡å»ºè¿‡ç¨‹ä¸­é‡‡ç”¨å·®å¼‚åŒ–è®­ç»ƒç­–ç•¥ï¼Œæ ¹æ®åœºæ™¯æ”¶æ•›æŒ‡æ ‡è‡ªåŠ¨è°ƒæ•´é«˜æ–¯ä¼˜åŒ–è¿›åº¦ï¼Œå®ç°æ¯”åŸºçº¿æ–¹æ³•æ›´å¥½çš„æ”¶æ•›æ•ˆæœã€‚</li>
<li>RGE-GSæ¡†æ¶è§£å†³äº†å•é€šé“é©¾é©¶è§†é¢‘ä¸­çš„é“è·¯ç»“æ„æ‰«æä¸å®Œæ•´é—®é¢˜ï¼Œé€‚ç”¨äºä¼ æ„Ÿå™¨æ¨¡æ‹Ÿå™¨çš„æœ‰æ•ˆå›å½’é©¾é©¶åŠ¨ä½œã€‚</li>
<li>å…¬å¼€æ•°æ®é›†çš„å¤§é‡è¯„ä¼°è¡¨æ˜ï¼ŒRGE-GSåœ¨é‡å»ºè´¨é‡æ–¹é¢è¾¾åˆ°äº†ä¸šç•Œé¢†å…ˆæ°´å¹³ã€‚</li>
<li>è¯¥ç ”ç©¶çš„æºä»£ç å°†å…¬å¼€å‘å¸ƒåœ¨<a target="_blank" rel="noopener" href="https://github.com/CN-ADLab/RGE-GS%E3%80%82">https://github.com/CN-ADLab/RGE-GSã€‚</a></li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.22800">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-52c760043e80db2da3b1435542669688.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-1dc5887293733c727875ceffbd312327.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ffd42b51e074e2189a0c65965ba9df18.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-73e2f805a3e25c6c18ce0fe89808a8f1.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-0029c7ffe1bb6375c7a29d1eb5592e8a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-4c882a867aa4e3ae448661277cc4105e.jpg" align="middle">
</details>


<h1 id="-9"><a href="#-9" class="headerlink" title=""></a></h1><h2 id="VoteSplat-Hough-Voting-Gaussian-Splatting-for-3D-Scene-Understanding"><a href="#VoteSplat-Hough-Voting-Gaussian-Splatting-for-3D-Scene-Understanding" class="headerlink" title="VoteSplat: Hough Voting Gaussian Splatting for 3D Scene Understanding"></a>VoteSplat: Hough Voting Gaussian Splatting for 3D Scene Understanding</h2><p><strong>Authors:Minchao Jiang, Shunyu Jia, Jiaming Gu, Xiaoyuan Lu, Guangming Zhu, Anqi Dong, Liang Zhang</strong></p>
<p>3D Gaussian Splatting (3DGS) has become horsepower in high-quality, real-time rendering for novel view synthesis of 3D scenes. However, existing methods focus primarily on geometric and appearance modeling, lacking deeper scene understanding while also incurring high training costs that complicate the originally streamlined differentiable rendering pipeline. To this end, we propose VoteSplat, a novel 3D scene understanding framework that integrates Hough voting with 3DGS. Specifically, Segment Anything Model (SAM) is utilized for instance segmentation, extracting objects, and generating 2D vote maps. We then embed spatial offset vectors into Gaussian primitives. These offsets construct 3D spatial votes by associating them with 2D image votes, while depth distortion constraints refine localization along the depth axis. For open-vocabulary object localization, VoteSplat maps 2D image semantics to 3D point clouds via voting points, reducing training costs associated with high-dimensional CLIP features while preserving semantic unambiguity. Extensive experiments demonstrate effectiveness of VoteSplat in open-vocabulary 3D instance localization, 3D point cloud understanding, click-based 3D object localization, hierarchical segmentation, and ablation studies. Our code is available at <a target="_blank" rel="noopener" href="https://sy-ja.github.io/votesplat/">https://sy-ja.github.io/votesplat/</a> </p>
<blockquote>
<p>ä¸‰ç»´é«˜æ–¯Splattingï¼ˆ3DGSï¼‰å·²ç»æˆä¸ºé«˜è´¨é‡å®æ—¶æ¸²æŸ“ä¸­ä¸‰ç»´åœºæ™¯æ–°å‹è§†è§’åˆæˆçš„æ ¸å¿ƒåŠ¨åŠ›ã€‚ç„¶è€Œï¼Œç°æœ‰æ–¹æ³•ä¸»è¦é›†ä¸­åœ¨å‡ ä½•å’Œå¤–è§‚å»ºæ¨¡ä¸Šï¼Œç¼ºä¹æ›´æ·±å±‚æ¬¡çš„åœºæ™¯ç†è§£ï¼ŒåŒæ—¶äº§ç”Ÿäº†é«˜æ˜‚çš„è®­ç»ƒæˆæœ¬ï¼Œè¿™å¤æ‚åŒ–äº†åŸæœ¬æµç¨‹åŒ–çš„å¯å¾®åˆ†æ¸²æŸ“ç®¡çº¿ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬æå‡ºäº†VoteSplatï¼Œè¿™æ˜¯ä¸€ç§æ–°å‹çš„ä¸‰ç»´åœºæ™¯ç†è§£æ¡†æ¶ï¼Œå®ƒå°†éœå¤«æŠ•ç¥¨ä¸3DGSç›¸ç»“åˆã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬ä½¿ç”¨Segment Anything Modelï¼ˆSAMï¼‰è¿›è¡Œå®ä¾‹åˆ†å‰²ï¼Œæå–å¯¹è±¡å¹¶ç”ŸæˆäºŒç»´æŠ•ç¥¨å›¾ã€‚ç„¶åæˆ‘ä»¬å°†ç©ºé—´åç§»å‘é‡åµŒå…¥åˆ°é«˜æ–¯åŸºå…ƒä¸­ã€‚è¿™äº›åç§»é‡é€šè¿‡ä¸äºŒç»´å›¾åƒæŠ•ç¥¨ç›¸å…³è”æ¥æ„å»ºä¸‰ç»´ç©ºé—´æŠ•ç¥¨ï¼Œè€Œæ·±åº¦å¤±çœŸçº¦æŸåˆ™æ²¿æ·±åº¦è½´å®Œå–„å®šä½ã€‚å¯¹äºå¼€æ”¾è¯æ±‡å¯¹è±¡å®šä½ï¼ŒVoteSplaté€šè¿‡æŠ•ç¥¨ç‚¹å°†äºŒç»´å›¾åƒè¯­ä¹‰æ˜ å°„åˆ°ä¸‰ç»´ç‚¹äº‘ï¼Œé™ä½äº†ä¸é«˜ç»´CLIPç‰¹å¾ç›¸å…³çš„è®­ç»ƒæˆæœ¬ï¼ŒåŒæ—¶ä¿æŒè¯­ä¹‰æ¸…æ™°ã€‚å¤§é‡å®éªŒè¯æ˜äº†VoteSplatåœ¨å¼€æ”¾è¯æ±‡ä¸‰ç»´å®ä¾‹å®šä½ã€ä¸‰ç»´ç‚¹äº‘ç†è§£ã€åŸºäºç‚¹å‡»çš„ä¸‰ç»´å¯¹è±¡å®šä½ã€å±‚æ¬¡åˆ†å‰²å’Œæ¶ˆèç ”ç©¶ä¸­çš„æœ‰æ•ˆæ€§ã€‚æˆ‘ä»¬çš„ä»£ç å¯åœ¨[<a target="_blank" rel="noopener" href="https://sy-ja.github.io/votesplat/]%E4%B8%8A%E6%89%BE%E5%88%B0%E3%80%82">https://sy-ja.github.io/votesplat/]ä¸Šæ‰¾åˆ°ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.22799v1">PDF</a> Accepted to ICCV 2025</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†åä¸ºVoteSplatçš„æ–°å‹ä¸‰ç»´åœºæ™¯ç†è§£æ¡†æ¶ï¼Œè¯¥æ¡†æ¶ç»“åˆäº†éœå¤«æŠ•ç¥¨ä¸é«˜æ–¯å–·æ¶‚æŠ€æœ¯ï¼Œå¹¶ä½¿ç”¨äº†åä¸ºSAMçš„æ¨¡å‹å®ç°å®ä¾‹åˆ†å‰²ï¼Œæå‡äº†ä¸‰ç»´åœºæ™¯æ¸²æŸ“ä¸­å¯¹åœºæ™¯çš„æ·±å…¥ç†è§£ä¸è®­ç»ƒæ•ˆç‡çš„æå‡ã€‚æŠ•ç¥¨æŠ€æœ¯å¸®åŠ©è¿›è¡Œç‰©ä½“å®šä½å’Œä¸‰ç»´ç‚¹äº‘è§£æï¼Œç®€åŒ–äº†å¤æ‚çš„è®­ç»ƒè¿‡ç¨‹ã€‚VoteSplatæ¡†æ¶å¯¹äºå¼€æ”¾è¯æ±‡è¡¨çš„ä¸‰ç»´ç‰©ä½“å®šä½ã€ä¸‰ç»´ç‚¹äº‘ç†è§£ã€ç‚¹å‡»å¼ä¸‰ç»´ç‰©ä½“å®šä½ä»¥åŠå±‚æ¬¡åˆ†å‰²ç­‰ä»»åŠ¡å±•ç°å‡ºæ˜¾è‘—æ•ˆæœã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>VoteSplatæ˜¯ä¸€ä¸ªæ–°å‹çš„ä¸‰ç»´åœºæ™¯ç†è§£æ¡†æ¶ï¼Œç»“åˆäº†éœå¤«æŠ•ç¥¨ä¸ä¸‰ç»´é«˜æ–¯å–·æ¶‚æŠ€æœ¯ï¼ˆ3DGSï¼‰ã€‚</li>
<li>ä½¿ç”¨Segment Anything Modelï¼ˆSAMï¼‰è¿›è¡Œå®ä¾‹åˆ†å‰²ï¼Œæå–å¯¹è±¡å¹¶ç”ŸæˆäºŒç»´æŠ•ç¥¨å›¾ã€‚</li>
<li>é€šè¿‡åµŒå…¥ç©ºé—´åç§»å‘é‡åˆ°é«˜æ–¯åŸºæœ¬ä½“ä¸­ï¼Œæ„å»ºä¸‰ç»´ç©ºé—´æŠ•ç¥¨ã€‚</li>
<li>æ·±åº¦æ‰­æ›²çº¦æŸç”¨äºæ²¿æ·±åº¦è½´æ”¹è¿›å®šä½ç²¾åº¦ã€‚</li>
<li>VoteSplaté€šè¿‡æŠ•ç¥¨ç‚¹å°†äºŒç»´å›¾åƒè¯­ä¹‰æ˜ å°„åˆ°ä¸‰ç»´ç‚¹äº‘ä¸­ï¼Œé™ä½é«˜ç»´CLIPç‰¹å¾çš„è®­ç»ƒæˆæœ¬ï¼ŒåŒæ—¶ä¿æŒè¯­ä¹‰æ˜ç¡®æ€§ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.22799">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-ad8bb4b5ef5621d96b3e663552a52624.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-7d378e4740e3f2e72e6db0ae42111dcb.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-64e4711b24799afea28268f09c24d295.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-62661cd69b7a5fa02ce0a32232bda233.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f64b1a623eba6b755d5467ee4814ca50.jpg" align="middle">
</details>


<h1 id="-10"><a href="#-10" class="headerlink" title=""></a></h1><h2 id="RoboPearls-Editable-Video-Simulation-for-Robot-Manipulation"><a href="#RoboPearls-Editable-Video-Simulation-for-Robot-Manipulation" class="headerlink" title="RoboPearls: Editable Video Simulation for Robot Manipulation"></a>RoboPearls: Editable Video Simulation for Robot Manipulation</h2><p><strong>Authors:Tao Tang, Likui Zhang, Youpeng Wen, Kaidong Zhang, Jia-Wang Bian, xia zhou, Tianyi Yan, Kun Zhan, Peng Jia, Hefeng Wu, Liang Lin, Xiaodan Liang</strong></p>
<p>The development of generalist robot manipulation policies has seen significant progress, driven by large-scale demonstration data across diverse environments. However, the high cost and inefficiency of collecting real-world demonstrations hinder the scalability of data acquisition. While existing simulation platforms enable controlled environments for robotic learning, the challenge of bridging the sim-to-real gap remains. To address these challenges, we propose RoboPearls, an editable video simulation framework for robotic manipulation. Built on 3D Gaussian Splatting (3DGS), RoboPearls enables the construction of photo-realistic, view-consistent simulations from demonstration videos, and supports a wide range of simulation operators, including various object manipulations, powered by advanced modules like Incremental Semantic Distillation (ISD) and 3D regularized NNFM Loss (3D-NNFM). Moreover, by incorporating large language models (LLMs), RoboPearls automates the simulation production process in a user-friendly manner through flexible command interpretation and execution. Furthermore, RoboPearls employs a vision-language model (VLM) to analyze robotic learning issues to close the simulation loop for performance enhancement. To demonstrate the effectiveness of RoboPearls, we conduct extensive experiments on multiple datasets and scenes, including RLBench, COLOSSEUM, Ego4D, Open X-Embodiment, and a real-world robot, which demonstrate our satisfactory simulation performance. </p>
<blockquote>
<p>é€šç”¨æœºå™¨äººæ“ä½œç­–ç•¥çš„å‘å±•å·²ç»å–å¾—äº†æ˜¾è‘—çš„è¿›æ­¥ï¼Œè¿™å¾—ç›Šäºåœ¨å¤šç§ç¯å¢ƒä¸­æ”¶é›†çš„å¤§è§„æ¨¡æ¼”ç¤ºæ•°æ®ã€‚ç„¶è€Œï¼Œæ”¶é›†çœŸå®ä¸–ç•Œæ¼”ç¤ºçš„é«˜æˆæœ¬å’Œä¸æ•ˆç‡é˜»ç¢äº†æ•°æ®è·å–çš„æ‰©å±•æ€§ã€‚ç°æœ‰çš„ä»¿çœŸå¹³å°ä¸ºæœºå™¨äººå­¦ä¹ æä¾›äº†å—æ§ç¯å¢ƒï¼Œä½†å¼¥åˆä»¿çœŸä¸çœŸå®ä¹‹é—´çš„å·®è·çš„æŒ‘æˆ˜ä»ç„¶å­˜åœ¨ã€‚ä¸ºäº†è§£å†³è¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†RoboPearlsï¼Œè¿™æ˜¯ä¸€ä¸ªç”¨äºæœºå™¨äººæ“ä½œçš„ç¼–è¾‘è§†é¢‘ä»¿çœŸæ¡†æ¶ã€‚å®ƒå»ºç«‹åœ¨ä¸‰ç»´é«˜æ–¯æ‹¼è´´ï¼ˆ3DGSï¼‰çš„åŸºç¡€ä¸Šï¼Œä½¿å¾—èƒ½å¤Ÿä»æ¼”ç¤ºè§†é¢‘ä¸­æ„å»ºé€¼çœŸçš„ã€è§†å›¾ä¸€è‡´çš„ä»¿çœŸï¼Œå¹¶æ”¯æŒå¹¿æ³›çš„ä»¿çœŸæ“ä½œï¼ŒåŒ…æ‹¬å„ç§å¯¹è±¡æ“ä½œï¼Œè¿™å¾—ç›Šäºå¢é‡è¯­ä¹‰è’¸é¦ï¼ˆISDï¼‰å’Œä¸‰ç»´æ­£åˆ™åŒ–NNFMæŸå¤±ï¼ˆ3D-NNFMï¼‰ç­‰å…ˆè¿›æ¨¡å—çš„æ”¯æŒã€‚æ­¤å¤–ï¼Œé€šè¿‡èå…¥å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ï¼ŒRoboPearlsä»¥ç”¨æˆ·å‹å¥½çš„æ–¹å¼é€šè¿‡çµæ´»çš„è§£é‡Šå’Œæ‰§è¡Œå‘½ä»¤è‡ªåŠ¨åŒ–ä»¿çœŸç”Ÿäº§è¿‡ç¨‹ã€‚è€Œä¸”ï¼ŒRoboPearlsè¿˜é‡‡ç”¨è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMï¼‰æ¥åˆ†ææœºå™¨äººå­¦ä¹ é—®é¢˜ï¼Œä»¥å®Œå–„ä»¿çœŸå¾ªç¯ï¼Œä»è€Œæé«˜æ€§èƒ½ã€‚ä¸ºäº†è¯æ˜RoboPearlsçš„æœ‰æ•ˆæ€§ï¼Œæˆ‘ä»¬åœ¨å¤šä¸ªæ•°æ®é›†å’Œåœºæ™¯ä¸Šè¿›è¡Œäº†å¹¿æ³›å®éªŒï¼ŒåŒ…æ‹¬RLBenchã€COLOSSEUMã€Ego4Dã€Open X-Embodimentå’ŒçœŸå®ä¸–ç•Œæœºå™¨äººï¼Œå®éªŒç»“æœè¯æ˜äº†æˆ‘ä»¬çš„ä»¿çœŸæ€§èƒ½ä»¤äººæ»¡æ„ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.22756v1">PDF</a> ICCV 2025</p>
<p><strong>Summary</strong></p>
<p>åŸºäºå¤§è§„æ¨¡æ¼”ç¤ºæ•°æ®çš„æœºå™¨äººé€šç”¨æ“ä½œç­–ç•¥å¼€å‘å–å¾—æ˜¾è‘—è¿›å±•ï¼Œä½†ä»é¢ä¸´çœŸå®ä¸–ç•Œæ•°æ®é‡‡é›†çš„é«˜æˆæœ¬å’Œä½æ•ˆé—®é¢˜ã€‚ä»¿çœŸå¹³å°è™½èƒ½ä¸ºæœºå™¨äººå­¦ä¹ æä¾›å—æ§ç¯å¢ƒï¼Œä½†æ¨¡æ‹Ÿåˆ°ç°å®çš„å·®è·ä»æ˜¯æŒ‘æˆ˜ã€‚æˆ‘ä»¬æå‡ºRoboPearlsï¼Œä¸€ä¸ªåŸºäº3Dé«˜æ–¯æ‹¼è´´æŠ€æœ¯çš„å¯ç¼–è¾‘è§†é¢‘ä»¿çœŸæ¡†æ¶ï¼Œç”¨äºæœºå™¨äººæ“ä½œã€‚å®ƒæ”¯æŒä»æ¼”ç¤ºè§†é¢‘æ„å»ºé€¼çœŸçš„æ¨¡æ‹Ÿç¯å¢ƒï¼Œæ¶µç›–å¹¿æ³›çš„æ¨¡æ‹Ÿæ“ä½œï¼Œå€ŸåŠ©å¢é‡è¯­ä¹‰è’¸é¦å’Œ3Dæ­£åˆ™åŒ–NNFMæŸå¤±ç­‰é«˜çº§æ¨¡å—æ¨åŠ¨æ¨¡æ‹Ÿå‘å±•ã€‚æ­¤å¤–ï¼ŒRoboPearlså€ŸåŠ©å¤§å‹è¯­è¨€æ¨¡å‹è‡ªåŠ¨åŒ–ä»¿çœŸç”Ÿäº§æµç¨‹ï¼Œå¹¶å¼•å…¥è§†è§‰è¯­è¨€æ¨¡å‹åˆ†ææœºå™¨äººå­¦ä¹ é—®é¢˜ï¼Œä»¥æ”¹è¿›æ¨¡æ‹Ÿæ€§èƒ½ã€‚é€šè¿‡å®éªŒéªŒè¯ï¼ŒRoboPearlsåœ¨å¤šä¸ªæ•°æ®é›†å’Œåœºæ™¯ä¸Šè¡¨ç°å‡ºè‰¯å¥½çš„æ¨¡æ‹Ÿæ€§èƒ½ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>åŸºäºå¤§è§„æ¨¡æ¼”ç¤ºæ•°æ®çš„æœºå™¨äººé€šç”¨æ“ä½œç­–ç•¥å¼€å‘å·²å–å¾—æ˜¾è‘—è¿›å±•ã€‚</li>
<li>çœŸå®ä¸–ç•Œæ•°æ®é‡‡é›†çš„é«˜æˆæœ¬å’Œä½æ•ˆæ€§ä»æ˜¯é¢ä¸´çš„æŒ‘æˆ˜ã€‚</li>
<li>ä»¿çœŸå¹³å°ä¸ºæœºå™¨äººå­¦ä¹ æä¾›å—æ§ç¯å¢ƒï¼Œä½†æ¨¡æ‹Ÿåˆ°ç°å®çš„å·®è·ä»éœ€è§£å†³ã€‚</li>
<li>RoboPearlsæ˜¯ä¸€ä¸ªåŸºäº3DGSçš„è§†é¢‘ä»¿çœŸæ¡†æ¶ï¼Œæ”¯æŒä»æ¼”ç¤ºè§†é¢‘æ„å»ºé€¼çœŸçš„æ¨¡æ‹Ÿç¯å¢ƒã€‚</li>
<li>RoboPearlså…·æœ‰å¹¿æ³›çš„æ¨¡æ‹Ÿæ“ä½œèƒ½åŠ›ï¼ŒåŒ…æ‹¬å„ç§å¯¹è±¡æ“ä½œã€‚</li>
<li>RoboPearlså€ŸåŠ©é«˜çº§æ¨¡å—ï¼ˆå¦‚ISDå’Œ3D-NNFM Lossï¼‰æ¨åŠ¨æ¨¡æ‹Ÿå‘å±•ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.22756">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-c6b658d9da15260d167a7827085e1587.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-7d849d28fc3c0a967beb69913c0808fa.jpg" align="middle">
</details>


<h1 id="-11"><a href="#-11" class="headerlink" title=""></a></h1><h2 id="Part-Segmentation-and-Motion-Estimation-for-Articulated-Objects-with-Dynamic-3D-Gaussians"><a href="#Part-Segmentation-and-Motion-Estimation-for-Articulated-Objects-with-Dynamic-3D-Gaussians" class="headerlink" title="Part Segmentation and Motion Estimation for Articulated Objects with   Dynamic 3D Gaussians"></a>Part Segmentation and Motion Estimation for Articulated Objects with   Dynamic 3D Gaussians</h2><p><strong>Authors:Jun-Jee Chao, Qingyuan Jiang, Volkan Isler</strong></p>
<p>Part segmentation and motion estimation are two fundamental problems for articulated object motion analysis. In this paper, we present a method to solve these two problems jointly from a sequence of observed point clouds of a single articulated object. The main challenge in our problem setting is that the point clouds are not assumed to be generated by a fixed set of moving points. Instead, each point cloud in the sequence could be an arbitrary sampling of the object surface at that particular time step. Such scenarios occur when the object undergoes major occlusions, or if the dataset is collected using measurements from multiple sensors asynchronously. In these scenarios, methods that rely on tracking point correspondences are not appropriate. We present an alternative approach based on a compact but effective representation where we represent the object as a collection of simple building blocks modeled as 3D Gaussians. We parameterize the Gaussians with time-dependent rotations, translations, and scales that are shared across all time steps. With our representation, part segmentation can be achieved by building correspondences between the observed points and the Gaussians. Moreover, the transformation of each point across time can be obtained by following the poses of the assigned Gaussian (even when the point is not observed). Experiments show that our method outperforms existing methods that solely rely on finding point correspondences. Additionally, we extend existing datasets to emulate real-world scenarios by considering viewpoint occlusions. We further demonstrate that our method is more robust to missing points as compared to existing approaches on these challenging datasets, even when some parts are completely occluded in some time-steps. Notably, our part segmentation performance outperforms the state-of-the-art method by 13% on point clouds with occlusions. </p>
<blockquote>
<p>é’ˆå¯¹å…³èŠ‚å¯¹è±¡è¿åŠ¨åˆ†æï¼Œéƒ¨ä»¶åˆ†å‰²å’Œè¿åŠ¨ä¼°è®¡æ˜¯ä¸¤ä¸ªåŸºæœ¬é—®é¢˜ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–¹æ³•ï¼Œå¯ä»¥ä»å•ä¸ªå…³èŠ‚å¯¹è±¡çš„ç‚¹äº‘åºåˆ—ä¸­è”åˆè§£å†³è¿™ä¸¤ä¸ªé—®é¢˜ã€‚æˆ‘ä»¬é¢ä¸´çš„é—®é¢˜çš„ä¸»è¦æŒ‘æˆ˜åœ¨äºï¼Œç‚¹äº‘å¹¶ä¸æ˜¯ç”±ä¸€ç»„å›ºå®šçš„ç§»åŠ¨ç‚¹ç”Ÿæˆçš„ã€‚ç›¸åï¼Œåºåˆ—ä¸­çš„æ¯ä¸ªç‚¹äº‘éƒ½å¯èƒ½æ˜¯è¯¥å¯¹è±¡è¡¨é¢åœ¨ç‰¹å®šæ—¶é—´æ­¥é•¿çš„ä»»æ„é‡‡æ ·ã€‚å½“å¯¹è±¡é­å—ä¸»è¦é®æŒ¡æˆ–æ•°æ®é›†æ˜¯ä½¿ç”¨å¤šä¸ªå¼‚æ­¥ä¼ æ„Ÿå™¨æ”¶é›†çš„æµ‹é‡å€¼æ—¶ï¼Œå°±ä¼šå‡ºç°è¿™ç§æƒ…å†µã€‚åœ¨è¿™äº›åœºæ™¯ä¸­ï¼Œä¾èµ–è·Ÿè¸ªç‚¹å¯¹åº”çš„çš„æ–¹æ³•å¹¶ä¸é€‚ç”¨ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§åŸºäºç´§å‡‘è€Œæœ‰æ•ˆçš„è¡¨ç¤ºæ–¹æ³•çš„æ›¿ä»£æ–¹æ¡ˆï¼Œæˆ‘ä»¬å°†å¯¹è±¡è¡¨ç¤ºä¸ºä½œä¸ºä¸‰ç»´é«˜æ–¯æ¨¡å‹çš„ç®€å•æ„å»ºå—çš„é›†åˆã€‚æˆ‘ä»¬ç”¨æ—¶é—´ç›¸å…³çš„æ—‹è½¬ã€å¹³ç§»å’Œç¼©æ”¾å‚æ•°åŒ–é«˜æ–¯ï¼Œè¿™äº›å‚æ•°åœ¨æ‰€æœ‰æ—¶é—´æ­¥é•¿ä¸­éƒ½æ˜¯å…±äº«çš„ã€‚é€šè¿‡æˆ‘ä»¬çš„è¡¨ç¤ºæ–¹æ³•ï¼Œå¯ä»¥é€šè¿‡åœ¨è§‚å¯Ÿåˆ°çš„ç‚¹å’Œé«˜æ–¯ä¹‹é—´å»ºç«‹å¯¹åº”å…³ç³»æ¥å®ç°éƒ¨ä»¶åˆ†å‰²ã€‚æ­¤å¤–ï¼Œæ¯ä¸ªç‚¹éšæ—¶é—´å˜åŒ–çš„å˜åŒ–å¯ä»¥é€šè¿‡è·ŸéšæŒ‡å®šçš„é«˜æ–¯å§¿æ€æ¥è·å¾—ï¼ˆå³ä½¿ç‚¹æ²¡æœ‰è¢«è§‚å¯Ÿåˆ°ï¼‰ã€‚å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨ä»…ä¾èµ–äºå¯»æ‰¾ç‚¹å¯¹åº”çš„æ–¹æ³•ä¸Šè¡¨ç°æ›´å¥½ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬é€šè¿‡è€ƒè™‘è§†ç‚¹é®æŒ¡æ¥æ¨¡æ‹Ÿç°å®ä¸–ç•Œåœºæ™¯ï¼Œå¯¹ç°æœ‰æ•°æ®é›†è¿›è¡Œäº†æ‰©å±•ã€‚æˆ‘ä»¬è¿›ä¸€æ­¥è¯æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨ç¼ºå¤±ç‚¹ä¸Šç›¸æ¯”è¿™äº›å…·æœ‰æŒ‘æˆ˜æ€§çš„æ•°æ®é›†ä¸Šçš„ç°æœ‰æ–¹æ³•æ›´å…·é²æ£’æ€§ï¼Œå³ä½¿åœ¨æŸäº›æ—¶é—´æ­¥é•¿ä¸­æŸäº›éƒ¨åˆ†è¢«å®Œå…¨é®æŒ¡ä¹Ÿæ˜¯å¦‚æ­¤ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œæˆ‘ä»¬çš„éƒ¨ä»¶åˆ†å‰²æ€§èƒ½åœ¨å¸¦æœ‰é®æŒ¡çš„ç‚¹äº‘ä¸Šæ¯”æœ€æ–°æŠ€æœ¯é«˜å‡º13%ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.22718v1">PDF</a> </p>
<p><strong>æ‘˜è¦</strong><br>    æœ¬æ–‡æå‡ºä¸€ç§æ–¹æ³•ï¼Œä»å•ä¸ªå¯åŠ¨å¯¹è±¡çš„ç‚¹äº‘åºåˆ—ä¸­è”åˆè§£å†³éƒ¨åˆ†åˆ†å‰²å’Œè¿åŠ¨ä¼°è®¡è¿™ä¸¤ä¸ªåŸºæœ¬é—®é¢˜ã€‚è¯¥æ–¹æ³•ä¸å‡å®šç‚¹äº‘ç”±å›ºå®šçš„ä¸€ç»„ç§»åŠ¨ç‚¹ç”Ÿæˆï¼Œè€Œæ˜¯è®¤ä¸ºæ¯ä¸ªç‚¹äº‘å¯èƒ½æ˜¯å¯¹è±¡è¡¨é¢åœ¨è¯¥æ—¶é—´æ­¥çš„ä»»æ„é‡‡æ ·ã€‚åœ¨å¯¹è±¡é­å—ä¸»è¦é®æŒ¡æˆ–ä½¿ç”¨å¤šä¸ªå¼‚æ­¥ä¼ æ„Ÿå™¨è¿›è¡Œæµ‹é‡çš„æƒ…å†µä¸‹ï¼Œä¾èµ–è·Ÿè¸ªç‚¹å¯¹åº”çš„æ–¹æ³•ä¸é€‚ç”¨ã€‚ç›¸åï¼Œæœ¬æ–‡é‡‡ç”¨ç´§å‡‘æœ‰æ•ˆçš„è¡¨ç¤ºæ–¹æ³•ï¼Œå°†å¯¹è±¡è¡¨ç¤ºä¸ºç”±æ—¶é—´ä¾èµ–çš„æ—‹è½¬ã€å¹³ç§»å’Œç¼©æ”¾å‚æ•°åŒ–çš„ä¸‰ç»´é«˜æ–¯ç®€å•æ„å»ºå—é›†åˆã€‚é€šè¿‡æ„å»ºè§‚å¯Ÿåˆ°çš„ç‚¹ä¸é«˜æ–¯ä¹‹é—´çš„å¯¹åº”å…³ç³»ï¼Œå¯ä»¥å®ç°éƒ¨åˆ†åˆ†å‰²ã€‚æ­¤å¤–ï¼Œå¯ä»¥é€šè¿‡è¿½è¸ªæŒ‡å®šé«˜æ–¯çš„çŠ¶æ€è·å¾—å„ç‚¹éšæ—¶é—´çš„å˜åŒ–ï¼ˆå³ä½¿è¯¥ç‚¹æœªè¢«è§‚å¯Ÿåˆ°ï¼‰ã€‚å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•ä¼˜äºä»…ä¾èµ–æ‰¾ç‚¹å¯¹åº”çš„æ–¹æ³•ã€‚æ­¤å¤–ï¼Œé€šè¿‡è€ƒè™‘è§†è§’é®æŒ¡æ¥æ¨¡æ‹Ÿç°å®åœºæ™¯ï¼Œæ‰©å±•ç°æœ‰æ•°æ®é›†ã€‚è¿›ä¸€æ­¥è¯æ˜è¯¥æ–¹æ³•åœ¨å…·æœ‰æŒ‘æˆ˜æ€§çš„æ•°æ®é›†ä¸Šæ¯”ç°æœ‰æ–¹æ³•æ›´ç¨³å¥åœ°å¤„ç†ç¼ºå¤±ç‚¹ï¼Œå³ä½¿åœ¨æŸäº›æ—¶é—´æ­¥ä¸­æŸäº›éƒ¨åˆ†è¢«å®Œå…¨é®æŒ¡çš„æƒ…å†µä¸‹ï¼Œæœ¬æ–‡çš„éƒ¨åˆ†åˆ†å‰²æ€§èƒ½ä¹Ÿæ¯”æœ€æ–°æŠ€æœ¯é«˜å‡º13%ã€‚</p>
<p><strong>è¦ç‚¹æŒæ¡</strong></p>
<ol>
<li>æœ¬æ–‡è§£å†³äº†å¯åŠ¨å¯¹è±¡çš„ç‚¹äº‘åºåˆ—ä¸­çš„éƒ¨åˆ†åˆ†å‰²å’Œè¿åŠ¨ä¼°è®¡é—®é¢˜ã€‚</li>
<li>æå‡ºä¸€ç§åŸºäºä¸‰ç»´é«˜æ–¯ç®€å•æ„å»ºå—çš„è¡¨ç¤ºæ–¹æ³•ï¼Œé€‚ç”¨äºå¯¹è±¡è¡¨é¢çš„ä»»æ„é‡‡æ ·ã€‚</li>
<li>æ–¹æ³•ä¸ä¾èµ–å›ºå®šçš„ç‚¹å¯¹åº”è·Ÿè¸ªï¼Œè€Œæ˜¯é€šè¿‡æ„å»ºè§‚å¯Ÿåˆ°çš„ç‚¹ä¸é«˜æ–¯ä¹‹é—´çš„å¯¹åº”å…³ç³»å®ç°éƒ¨åˆ†åˆ†å‰²ã€‚</li>
<li>å¯ä»¥è¿½è¸ªæŒ‡å®šé«˜æ–¯çš„çŠ¶æ€è·å¾—å„ç‚¹éšæ—¶é—´çš„å˜åŒ–ã€‚</li>
<li>æ–¹æ³•åœ¨å®éªŒä¸­è¡¨ç°å‡ºä¼˜äºç°æœ‰æ–¹æ³•çš„æ€§èƒ½ï¼Œç‰¹åˆ«æ˜¯åœ¨å¤„ç†é®æŒ¡å’Œç¼ºå¤±ç‚¹çš„ç°å®åœºæ™¯ä¸­ã€‚</li>
<li>å¯¹ç°æœ‰æ•°æ®é›†è¿›è¡Œäº†æ‰©å±•ï¼Œä»¥æ¨¡æ‹Ÿç°å®ä¸–ç•Œçš„é®æŒ¡æƒ…å†µã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.22718">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-cac3f59e714acda98b200515b61e4c63.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a9923029b83a858482a2a1f7640b6827.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-58388b50cc278d263854bc33eb58862b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ab1cb576ce0b3e6ee482ebaedd12adc3.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-4aa57704269213b3e4b2c69c6603bdf6.jpg" align="middle">
</details>


<h1 id="-12"><a href="#-12" class="headerlink" title=""></a></h1><h2 id="DIGS-Dynamic-CBCT-Reconstruction-using-Deformation-Informed-4D-Gaussian-Splatting-and-a-Low-Rank-Free-Form-Deformation-Model"><a href="#DIGS-Dynamic-CBCT-Reconstruction-using-Deformation-Informed-4D-Gaussian-Splatting-and-a-Low-Rank-Free-Form-Deformation-Model" class="headerlink" title="DIGS: Dynamic CBCT Reconstruction using Deformation-Informed 4D Gaussian   Splatting and a Low-Rank Free-Form Deformation Model"></a>DIGS: Dynamic CBCT Reconstruction using Deformation-Informed 4D Gaussian   Splatting and a Low-Rank Free-Form Deformation Model</h2><p><strong>Authors:Yuliang Huang, Imraj Singh, Thomas Joyce, Kris Thielemans, Jamie R. McClelland</strong></p>
<p>3D Cone-Beam CT (CBCT) is widely used in radiotherapy but suffers from motion artifacts due to breathing. A common clinical approach mitigates this by sorting projections into respiratory phases and reconstructing images per phase, but this does not account for breathing variability. Dynamic CBCT instead reconstructs images at each projection, capturing continuous motion without phase sorting. Recent advancements in 4D Gaussian Splatting (4DGS) offer powerful tools for modeling dynamic scenes, yet their application to dynamic CBCT remains underexplored. Existing 4DGS methods, such as HexPlane, use implicit motion representations, which are computationally expensive. While explicit low-rank motion models have been proposed, they lack spatial regularization, leading to inconsistencies in Gaussian motion. To address these limitations, we introduce a free-form deformation (FFD)-based spatial basis function and a deformation-informed framework that enforces consistency by coupling the temporal evolution of Gaussianâ€™s mean position, scale, and rotation under a unified deformation field. We evaluate our approach on six CBCT datasets, demonstrating superior image quality with a 6x speedup over HexPlane. These results highlight the potential of deformation-informed 4DGS for efficient, motion-compensated CBCT reconstruction. The code is available at <a target="_blank" rel="noopener" href="https://github.com/Yuliang-Huang/DIGS">https://github.com/Yuliang-Huang/DIGS</a>. </p>
<blockquote>
<p>ä¸‰ç»´é”¥å½¢æŸCTï¼ˆCBCTï¼‰åœ¨æ”¾å°„æ²»ç–—ä¸­å¾—åˆ°å¹¿æ³›åº”ç”¨ï¼Œä½†ç”±äºå‘¼å¸äº§ç”Ÿçš„è¿åŠ¨ä¼ªå½±è€Œå—åˆ°å½±å“ã€‚ä¸€ç§å¸¸è§çš„ä¸´åºŠæ–¹æ³•æ˜¯æŒ‰å‘¼å¸é˜¶æ®µå¯¹æŠ•å½±è¿›è¡Œæ’åºï¼Œå¹¶æŒ‰é˜¶æ®µé‡å»ºå›¾åƒï¼Œä½†è¿™å¹¶æ²¡æœ‰è€ƒè™‘åˆ°å‘¼å¸å˜åŒ–ã€‚åŠ¨æ€CBCTåˆ™ä¼šåœ¨æ¯ä¸ªæŠ•å½±æ—¶é‡å»ºå›¾åƒï¼Œæ•æ‰è¿ç»­è¿åŠ¨è€Œæ— éœ€è¿›è¡Œé˜¶æ®µæ’åºã€‚æœ€è¿‘ï¼Œå››ç»´é«˜æ–¯æç”»ï¼ˆ4DGSï¼‰åœ¨æ¨¡æ‹ŸåŠ¨æ€åœºæ™¯æ–¹é¢çš„è¿›å±•æä¾›äº†å¼ºå¤§çš„å·¥å…·ï¼Œä½†å…¶åº”ç”¨äºåŠ¨æ€CBCTä»è¢«æ¢ç´¢ä¸è¶³ã€‚ç°æœ‰çš„4DGSæ–¹æ³•ï¼ˆå¦‚HexPlaneï¼‰ä½¿ç”¨éšå¼è¿åŠ¨è¡¨ç¤ºï¼Œè®¡ç®—æˆæœ¬é«˜æ˜‚ã€‚è™½ç„¶å·²æå‡ºæ˜¾å¼çš„ä½ç§©è¿åŠ¨æ¨¡å‹ï¼Œä½†å®ƒä»¬ç¼ºä¹ç©ºé—´æ­£åˆ™åŒ–ï¼Œå¯¼è‡´é«˜æ–¯è¿åŠ¨çš„ä¸ä¸€è‡´æ€§ã€‚ä¸ºäº†è§£å†³è¿™äº›å±€é™æ€§ï¼Œæˆ‘ä»¬å¼•å…¥åŸºäºè‡ªç”±å½¢å¼å˜å½¢ï¼ˆFFDï¼‰çš„ç©ºé—´åŸºå‡½æ•°å’Œå˜å½¢ä¿¡æ¯æ¡†æ¶ï¼Œé€šè¿‡è€¦åˆé«˜æ–¯å‡å€¼ä½ç½®ã€å°ºåº¦å’Œæ—‹è½¬çš„æš‚æ—¶æ¼”å˜ï¼Œåœ¨ç»Ÿä¸€å˜å½¢åœºä¸‹å¼ºåˆ¶æ‰§è¡Œä¸€è‡´æ€§ã€‚æˆ‘ä»¬åœ¨å…­ä¸ªCBCTæ•°æ®é›†ä¸Šè¯„ä¼°äº†æˆ‘ä»¬çš„æ–¹æ³•ï¼Œè¯æ˜å…¶å›¾åƒè´¨é‡ä¼˜è¶Šï¼Œç›¸å¯¹äºHexPlaneæœ‰6å€çš„åŠ é€Ÿæ•ˆæœã€‚è¿™äº›ç»“æœçªå‡ºäº†å˜å½¢ä¿¡æ¯4DGSåœ¨é«˜æ•ˆã€è¿åŠ¨è¡¥å¿CBCTé‡å»ºä¸­çš„æ½œåŠ›ã€‚ä»£ç å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/Yuliang-Huang/DIGS%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/Yuliang-Huang/DIGSæ‰¾åˆ°ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.22280v1">PDF</a> Accepted by MICCAI 2025</p>
<p><strong>Summary</strong><br>     æœ¬æ–‡ä»‹ç»äº†åŠ¨æ€ä¸‰ç»´é”¥å½¢æŸè®¡ç®—æœºæ–­å±‚æ‰«æï¼ˆCBCTï¼‰æŠ€æœ¯ä¸­çš„è¿åŠ¨è¡¥å¿é—®é¢˜ã€‚æ–‡ç« æå‡ºäº†ä¸€ç§åŸºäºè‡ªç”±å˜å½¢ï¼ˆFFDï¼‰çš„ç©ºé—´åŸºå‡½æ•°å’Œå˜å½¢ä¿¡æ¯æ¡†æ¶ï¼Œç”¨äºè§£å†³ç°æœ‰å››ç»´é«˜æ–¯å–·ç»˜ï¼ˆ4DGSï¼‰æ–¹æ³•åœ¨åŠ¨æ€CBCTé‡å»ºä¸­çš„å±€é™æ€§ã€‚æ–°æ–¹æ³•é€šè¿‡ç»Ÿä¸€å˜å½¢åœºè€¦åˆé«˜æ–¯å‡å€¼ä½ç½®ã€å°ºåº¦å’Œæ—‹è½¬çš„æš‚æ—¶æ¼”å˜ï¼Œå®ç°äº†è¿åŠ¨è¡¥å¿ï¼Œæé«˜äº†å›¾åƒè´¨é‡ï¼Œå¹¶åœ¨å…­ä¸ªCBCTæ•°æ®é›†ä¸Šè¿›è¡Œäº†éªŒè¯ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>3D Cone-Beam CT (CBCT) åœ¨æ”¾å°„æ²»ç–—ä¸­çš„å¹¿æ³›åº”ç”¨åŠå…¶å› å‘¼å¸è¿åŠ¨äº§ç”Ÿçš„è¿åŠ¨ä¼ªå½±é—®é¢˜ã€‚</li>
<li>ç°æœ‰ä¸´åºŠæ–¹æ³•é€šè¿‡æŒ‰å‘¼å¸é˜¶æ®µæ’åºæŠ•å½±å¹¶å¯¹æ¯ä¸ªé˜¶æ®µè¿›è¡Œå›¾åƒé‡å»ºæ¥å‡è½»è¿åŠ¨ä¼ªå½±ï¼Œä½†ä¸è€ƒè™‘å‘¼å¸å˜åŒ–æ€§ã€‚</li>
<li>åŠ¨æ€CBCTæŠ€æœ¯èƒ½å¤Ÿåœ¨æ¯ä¸ªæŠ•å½±æ—¶é‡å»ºå›¾åƒï¼Œæ•æ‰è¿ç»­è¿åŠ¨ï¼Œæ— éœ€é˜¶æ®µæ’åºã€‚</li>
<li>å››ç»´é«˜æ–¯å–·ç»˜ï¼ˆ4DGSï¼‰åœ¨å»ºæ¨¡åŠ¨æ€åœºæ™¯æ–¹é¢çš„æœ€æ–°è¿›å±•åŠå…¶åœ¨åŠ¨æ€CBCTä¸­çš„åº”ç”¨å°šæœªå¾—åˆ°å……åˆ†æ¢ç´¢ã€‚</li>
<li>ç°æœ‰4DGSæ–¹æ³•ï¼ˆå¦‚HexPlaneï¼‰ä½¿ç”¨éšå¼è¿åŠ¨è¡¨ç¤ºï¼Œè®¡ç®—æˆæœ¬é«˜ã€‚</li>
<li>æ˜¾å¼ä½ç§©è¿åŠ¨æ¨¡å‹è™½æå‡ºï¼Œä½†ç¼ºä¹ç©ºé—´æ­£åˆ™åŒ–ï¼Œå¯¼è‡´é«˜æ–¯è¿åŠ¨ä¸ä¸€è‡´ã€‚</li>
<li>æœ¬æ–‡ä»‹ç»äº†ä¸€ç§åŸºäºè‡ªç”±å½¢å¼å˜å½¢ï¼ˆFFDï¼‰çš„ç©ºé—´åŸºå‡½æ•°å’Œå˜å½¢ä¿¡æ¯æ¡†æ¶ï¼Œä»¥è§£å†³ä¸Šè¿°é—®é¢˜ã€‚</li>
<li>è¯¥æ–¹æ³•åœ¨å…­ä¸ªCBCTæ•°æ®é›†ä¸Šè¿›è¡Œäº†è¯„ä¼°ï¼Œæ˜¾ç¤ºå‡ºå›¾åƒè´¨é‡ä¼˜åŠ¿ï¼Œç›¸å¯¹äºHexPlaneæœ‰6å€çš„é€Ÿåº¦æå‡ã€‚</li>
<li>å˜å½¢ä¿¡æ¯æ¡†æ¶é€šè¿‡è€¦åˆé«˜æ–¯çš„å‡å€¼ä½ç½®ã€å°ºåº¦å’Œæ—‹è½¬çš„æš‚æ—¶æ¼”å˜ï¼Œåœ¨ç»Ÿä¸€å˜å½¢åœºä¸‹å®ç°è¿åŠ¨è¡¥å¿ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.22280">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-bf900d9683582e6713c937f768cd6247.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-4b0e7246e527533457718f14aa9c59d9.jpg" align="middle">
</details>


<h1 id="-13"><a href="#-13" class="headerlink" title=""></a></h1><h2 id="BezierGS-Dynamic-Urban-Scene-Reconstruction-with-Bezier-Curve-Gaussian-Splatting"><a href="#BezierGS-Dynamic-Urban-Scene-Reconstruction-with-Bezier-Curve-Gaussian-Splatting" class="headerlink" title="BÃ©zierGS: Dynamic Urban Scene Reconstruction with BÃ©zier Curve   Gaussian Splatting"></a>BÃ©zierGS: Dynamic Urban Scene Reconstruction with BÃ©zier Curve   Gaussian Splatting</h2><p><strong>Authors:Zipei Ma, Junzhe Jiang, Yurui Chen, Li Zhang</strong></p>
<p>The realistic reconstruction of street scenes is critical for developing real-world simulators in autonomous driving. Most existing methods rely on object pose annotations, using these poses to reconstruct dynamic objects and move them during the rendering process. This dependence on high-precision object annotations limits large-scale and extensive scene reconstruction. To address this challenge, we propose B&#39;ezier curve Gaussian splatting (B&#39;ezierGS), which represents the motion trajectories of dynamic objects using learnable B&#39;ezier curves. This approach fully leverages the temporal information of dynamic objects and, through learnable curve modeling, automatically corrects pose errors. By introducing additional supervision on dynamic object rendering and inter-curve consistency constraints, we achieve reasonable and accurate separation and reconstruction of scene elements. Extensive experiments on the Waymo Open Dataset and the nuPlan benchmark demonstrate that B&#39;ezierGS outperforms state-of-the-art alternatives in both dynamic and static scene components reconstruction and novel view synthesis. </p>
<blockquote>
<p>åœ¨ç°å®ä¸–ç•Œä¸­é‡å»ºè¡—é“åœºæ™¯å¯¹äºå¼€å‘è‡ªåŠ¨é©¾é©¶æ¨¡æ‹Ÿå™¨è‡³å…³é‡è¦ã€‚ç°æœ‰çš„å¤§å¤šæ•°æ–¹æ³•éƒ½ä¾èµ–äºç‰©ä½“å§¿æ€æ ‡æ³¨ï¼Œåˆ©ç”¨è¿™äº›å§¿æ€æ¥é‡å»ºåŠ¨æ€ç‰©ä½“å¹¶åœ¨æ¸²æŸ“è¿‡ç¨‹ä¸­ç§»åŠ¨å®ƒä»¬ã€‚å¯¹é«˜ç²¾åº¦ç‰©ä½“æ ‡æ³¨çš„ä¾èµ–é™åˆ¶äº†å¤§è§„æ¨¡å’Œå¹¿æ³›çš„åœºæ™¯é‡å»ºã€‚ä¸ºäº†åº”å¯¹è¿™ä¸€æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä½¿ç”¨Bezieræ›²çº¿é«˜æ–¯æ‹¼è´´ï¼ˆBezierGSï¼‰çš„æ–¹æ³•ï¼Œè¯¥æ–¹æ³•ä½¿ç”¨å¯å­¦ä¹ çš„Bezieræ›²çº¿è¡¨ç¤ºåŠ¨æ€ç‰©ä½“çš„è¿åŠ¨è½¨è¿¹ã€‚è¿™ç§æ–¹æ³•å……åˆ†åˆ©ç”¨äº†åŠ¨æ€ç‰©ä½“çš„æ—¶é—´ä¿¡æ¯ï¼Œå¹¶é€šè¿‡å¯å­¦ä¹ çš„æ›²çº¿æ¨¡å‹è‡ªåŠ¨æ ¡æ­£å§¿æ€è¯¯å·®ã€‚é€šè¿‡å¯¹åŠ¨æ€å¯¹è±¡æ¸²æŸ“å¼•å…¥é¢å¤–çš„ç›‘ç£ä»¥åŠæ›²çº¿é—´ä¸€è‡´æ€§çº¦æŸï¼Œæˆ‘ä»¬å®ç°äº†åœºæ™¯å…ƒç´ çš„åˆç†å‡†ç¡®åˆ†ç¦»å’Œé‡å»ºã€‚åœ¨Waymo Open Datasetå’ŒnuPlanåŸºå‡†æµ‹è¯•çš„å¤§é‡å®éªŒè¡¨æ˜ï¼ŒBezierGSåœ¨åŠ¨æ€å’Œé™æ€åœºæ™¯ç»„ä»¶çš„é‡å»ºä»¥åŠæ–°è§†è§’åˆæˆæ–¹é¢å‡ä¼˜äºæœ€æ–°æ›¿ä»£æ–¹æ³•ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.22099v2">PDF</a> Accepted at ICCV 2025, Project Page:   <a target="_blank" rel="noopener" href="https://github.com/fudan-zvg/BezierGS">https://github.com/fudan-zvg/BezierGS</a></p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºäº†åˆ©ç”¨BÃ©zieræ›²çº¿é«˜æ–¯å–·æ¶‚æŠ€æœ¯ï¼ˆBÃ©zierGSï¼‰æ¥è§£å†³è‡ªä¸»é©¾é©¶æ¨¡æ‹Ÿå™¨ä¸­çš„å¤§è§„æ¨¡åœºæ™¯é‡å»ºé—®é¢˜ã€‚è¯¥æ–¹æ³•åˆ©ç”¨å¯å­¦ä¹ çš„BÃ©zieræ›²çº¿è¡¨ç¤ºåŠ¨æ€ç‰©ä½“çš„è¿åŠ¨è½¨è¿¹ï¼Œå¹¶åˆ©ç”¨æ—¶é—´ä¿¡æ¯è‡ªåŠ¨æ ¡æ­£å§¿æ€è¯¯å·®ã€‚é€šè¿‡å¼•å…¥åŠ¨æ€å¯¹è±¡æ¸²æŸ“çš„é™„åŠ ç›‘ç£ä»¥åŠæ›²çº¿é—´çš„ä¸€è‡´æ€§çº¦æŸï¼Œå®ç°äº†åœºæ™¯å…ƒç´ çš„åˆç†å‡†ç¡®åˆ†ç¦»å’Œé‡å»ºã€‚åœ¨Waymoå…¬å¼€æ•°æ®é›†å’ŒnuPlanåŸºå‡†æµ‹è¯•ä¸­ï¼ŒBÃ©zierGSåœ¨åŠ¨æ€å’Œé™æ€åœºæ™¯ç»„ä»¶é‡å»ºä»¥åŠæ–°é¢–è§†å›¾åˆæˆæ–¹é¢å‡ä¼˜äºç°æœ‰æŠ€æœ¯ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>çœŸå®è¡—é“åœºæ™¯çš„é‡å»ºå¯¹äºè‡ªä¸»é©¾é©¶æ¨¡æ‹Ÿå™¨çš„å‘å±•è‡³å…³é‡è¦ã€‚</li>
<li>å½“å‰æ–¹æ³•ä¾èµ–äºé«˜ç²¾åº¦å¯¹è±¡å§¿æ€æ³¨é‡Šï¼Œè¿™é™åˆ¶äº†å¤§è§„æ¨¡åœºæ™¯é‡å»ºã€‚</li>
<li>BÃ©zieræ›²çº¿é«˜æ–¯å–·æ¶‚æŠ€æœ¯ï¼ˆBÃ©zierGSï¼‰è¢«æå‡ºç”¨äºè§£å†³è¿™ä¸€é—®é¢˜ã€‚</li>
<li>BÃ©zierGSåˆ©ç”¨å¯å­¦ä¹ çš„BÃ©zieræ›²çº¿è¡¨ç¤ºåŠ¨æ€ç‰©ä½“çš„è¿åŠ¨è½¨è¿¹ã€‚</li>
<li>BÃ©zierGSå……åˆ†åˆ©ç”¨åŠ¨æ€ç‰©ä½“çš„æ—¶é—´ä¿¡æ¯ï¼Œå¹¶è‡ªåŠ¨æ ¡æ­£å§¿æ€è¯¯å·®ã€‚</li>
<li>é€šè¿‡å¼•å…¥é™„åŠ ç›‘ç£å’Œæ›²çº¿é—´ä¸€è‡´æ€§çº¦æŸï¼Œå®ç°äº†åœºæ™¯å…ƒç´ çš„å‡†ç¡®åˆ†ç¦»å’Œé‡å»ºã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.22099">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-567880cb979707ace47416e0b857c8e6.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-b1415a055c870b00b8b342128f34f450.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-dfb106784f1a18e6108a3af5eac23b38.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-65b920605b1d7f0b761bedef1449c5c1.jpg" align="middle">
</details>


<h1 id="-14"><a href="#-14" class="headerlink" title=""></a></h1><h2 id="SkinningGS-Editable-Dynamic-Human-Scene-Reconstruction-Using-Gaussian-Splatting-Based-on-a-Skinning-Model"><a href="#SkinningGS-Editable-Dynamic-Human-Scene-Reconstruction-Using-Gaussian-Splatting-Based-on-a-Skinning-Model" class="headerlink" title="SkinningGS: Editable Dynamic Human Scene Reconstruction Using Gaussian   Splatting Based on a Skinning Model"></a>SkinningGS: Editable Dynamic Human Scene Reconstruction Using Gaussian   Splatting Based on a Skinning Model</h2><p><strong>Authors:Da Li, Donggang Jia, Markus Hadwiger, Ivan Viola</strong></p>
<p>Reconstructing an interactive human avatar and the background from a monocular video of a dynamic human scene is highly challenging. In this work we adopt a strategy of point cloud decoupling and joint optimization to achieve the decoupled reconstruction of backgrounds and human bodies while preserving the interactivity of human motion. We introduce a position texture to subdivide the Skinned Multi-Person Linear (SMPL) body modelâ€™s surface and grow the human point cloud. To capture fine details of human dynamics and deformations, we incorporate a convolutional neural network structure to predict human body point cloud features based on texture. This strategy makes our approach free of hyperparameter tuning for densification and efficiently represents human points with half the point cloud of HUGS. This approach ensures high-quality human reconstruction and reduces GPU resource consumption during training. As a result, our method surpasses the previous state-of-the-art HUGS in reconstruction metrics while maintaining the ability to generalize to novel poses and views. Furthermore, our technique achieves real-time rendering at over 100 FPS, $\sim$6$\times$ the HUGS speed using only Linear Blend Skinning (LBS) weights for human transformation. Additionally, this work demonstrates that this framework can be extended to animal scene reconstruction when an accurately-posed model of an animal is available. </p>
<blockquote>
<p>ä»åŠ¨æ€äººä½“åœºæ™¯çš„å•ç›®è§†é¢‘ä¸­é‡å»ºä¸€ä¸ªäº¤äº’å¼çš„è™šæ‹Ÿäººç‰©å’Œå…¶èƒŒæ™¯æ˜¯ä¸€é¡¹éå¸¸å¤§çš„æŒ‘æˆ˜ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬é‡‡ç”¨äº†ç‚¹äº‘è§£è€¦å’Œè”åˆä¼˜åŒ–çš„ç­–ç•¥ï¼Œå®ç°äº†èƒŒæ™¯å’Œäººä½“ä¹‹é—´çš„è§£è€¦é‡å»ºï¼ŒåŒæ—¶ä¿ç•™äº†äººä½“è¿åŠ¨çš„äº¤äº’æ€§ã€‚æˆ‘ä»¬å¼•å…¥äº†ä¸€ç§ä½ç½®çº¹ç†ï¼Œä»¥ç»†åˆ†çš®è‚¤å¤šäººçº¿æ€§ï¼ˆSMPLï¼‰äººä½“æ¨¡å‹çš„è¡¨é¢å¹¶æ‰©å¤§äººä½“ç‚¹äº‘ã€‚ä¸ºäº†æ•æ‰äººä½“åŠ¨æ€å’Œå˜å½¢çš„ç»†èŠ‚ï¼Œæˆ‘ä»¬é‡‡ç”¨äº†ä¸€ç§å·ç§¯ç¥ç»ç½‘ç»œç»“æ„ï¼ŒåŸºäºçº¹ç†é¢„æµ‹äººä½“ç‚¹äº‘ç‰¹å¾ã€‚è¿™ä¸€ç­–ç•¥ä½¿æˆ‘ä»¬çš„æ–¹æ³•å…å»äº†å¯¹ç¨ åŒ–çš„è¶…å‚æ•°è°ƒæ•´ï¼Œå¹¶ä½¿ç”¨ä¸€åŠçš„ç‚¹äº‘é«˜æ•ˆåœ°è¡¨ç¤ºäº†äººä½“ç‚¹ã€‚è¿™ç§æ–¹æ³•ä¿è¯äº†é«˜è´¨é‡çš„äººä½“é‡å»ºï¼Œå¹¶é™ä½äº†è®­ç»ƒè¿‡ç¨‹ä¸­çš„GPUèµ„æºæ¶ˆè€—ã€‚å› æ­¤ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨é‡å»ºæŒ‡æ ‡ä¸Šè¶…è¶Šäº†ä¹‹å‰çš„å…ˆè¿›HUGSæŠ€æœ¯ï¼ŒåŒæ—¶ä¿æŒäº†å¯¹æ–°å‹å§¿åŠ¿å’Œè§†è§’çš„æ³›åŒ–èƒ½åŠ›ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬çš„æŠ€æœ¯å®ç°äº†è¶…è¿‡100FPSçš„å®æ—¶æ¸²æŸ“ï¼Œä»…ä½¿ç”¨çº¿æ€§æ··åˆè’™çš®ï¼ˆLBSï¼‰æƒé‡è¿›è¡Œäººç±»å˜æ¢ï¼Œå¤§çº¦æ˜¯HUGSé€Ÿåº¦çš„6å€ã€‚å¦å¤–ï¼Œè¿™é¡¹å·¥ä½œè¯æ˜ï¼Œå½“æä¾›å‡†ç¡®çš„åŠ¨ç‰©æ¨¡å‹æ—¶ï¼Œè¯¥æ¡†æ¶å¯ä»¥æ‰©å±•åˆ°åŠ¨ç‰©åœºæ™¯çš„é‡å»ºã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.21632v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>è¯¥æ–‡ä»‹ç»äº†ä¸€ç§åŸºäºç‚¹äº‘è§£è€¦å’Œè”åˆä¼˜åŒ–çš„ç­–ç•¥ï¼Œå®ç°ä»åŠ¨æ€äººç±»åœºæ™¯çš„å•ç›®è§†é¢‘ä¸­é‡å»ºäº¤äº’å¼äººç±»è§’è‰²å’ŒèƒŒæ™¯ã€‚é€šè¿‡å¼•å…¥ä½ç½®çº¹ç†å’Œå·ç§¯ç¥ç»ç½‘ç»œç»“æ„ï¼Œå®ç°äº†é«˜è´¨é‡çš„äººç±»é‡å»ºï¼ŒåŒæ—¶é™ä½äº†GPUèµ„æºæ¶ˆè€—ï¼Œå¹¶è¶…è¶Šäº†ç°æœ‰æŠ€æœ¯ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•å¯å®ç°å®æ—¶æ¸²æŸ“ï¼Œé€Ÿåº¦è¿œè¶…ç°æœ‰æŠ€æœ¯ï¼Œå¹¶å¯æ‰©å±•è‡³åŠ¨ç‰©åœºæ™¯é‡å»ºã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>é‡‡ç”¨ç‚¹äº‘è§£è€¦å’Œè”åˆä¼˜åŒ–ç­–ç•¥ï¼Œå®ç°èƒŒæ™¯å’Œäººä½“è§’è‰²çš„è§£è€¦é‡å»ºï¼ŒåŒæ—¶ä¿æŒäººç±»åŠ¨ä½œçš„äº¤äº’æ€§ã€‚</li>
<li>å¼•å…¥ä½ç½®çº¹ç†æŠ€æœ¯ï¼Œç”¨äºç»†åˆ†SMPLäººä½“æ¨¡å‹çš„è¡¨é¢å¹¶æ‰©å±•äººä½“ç‚¹äº‘ï¼Œæ•æ‰äººç±»åŠ¨æ€å’Œå˜å½¢çš„ç»†èŠ‚ã€‚</li>
<li>ç»“åˆå·ç§¯ç¥ç»ç½‘ç»œç»“æ„ï¼ŒåŸºäºçº¹ç†é¢„æµ‹äººä½“ç‚¹äº‘ç‰¹å¾ï¼Œä½¿æ–¹æ³•æ‘†è„±äº†å¯¹å¯†é›†åŒ–çš„è¶…å‚æ•°è°ƒæ•´éœ€æ±‚ã€‚</li>
<li>è¯¥æ–¹æ³•å®ç°äº†é«˜è´¨é‡çš„äººç±»é‡å»ºï¼Œå‡å°‘äº†GPUèµ„æºæ¶ˆè€—ï¼Œå¹¶è¶…è¶Šäº†ç°æœ‰æŠ€æœ¯ï¼ˆHUGSï¼‰åœ¨é‡å»ºæŒ‡æ ‡ä¸Šçš„è¡¨ç°ã€‚</li>
<li>æ–¹æ³•èƒ½å¤Ÿæ¨å¹¿åˆ°æ–°å‹å§¿æ€å’Œè§†è§’çš„æ³›åŒ–èƒ½åŠ›ã€‚</li>
<li>å®ç°å®æ—¶æ¸²æŸ“ï¼Œé€Ÿåº¦è¶…è¿‡100 FPSï¼Œæ˜¯ä½¿ç”¨çº¿æ€§æ··åˆçš®è‚¤æƒé‡ï¼ˆLBSï¼‰è¿›è¡Œäººç±»è½¬æ¢çš„HUGSé€Ÿåº¦çš„çº¦6å€ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.21632">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-adc6a0ccf2e35ec441b672cbec858593.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-d2a0b3a6c5030436a37da6da6a251e0a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-2c58e1824293433187abe2187342b732.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-2a7a615523d4558edf00015c49d39392.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-23cab2fa0f877a168aaa7cdb4113a37f.jpg" align="middle">
</details>


<h1 id="-15"><a href="#-15" class="headerlink" title=""></a></h1><h2 id="Curve-Aware-Gaussian-Splatting-for-3D-Parametric-Curve-Reconstruction"><a href="#Curve-Aware-Gaussian-Splatting-for-3D-Parametric-Curve-Reconstruction" class="headerlink" title="Curve-Aware Gaussian Splatting for 3D Parametric Curve Reconstruction"></a>Curve-Aware Gaussian Splatting for 3D Parametric Curve Reconstruction</h2><p><strong>Authors:Zhirui Gao, Renjiao Yi, Yaqiao Dai, Xuening Zhu, Wei Chen, Chenyang Zhu, Kai Xu</strong></p>
<p>This paper presents an end-to-end framework for reconstructing 3D parametric curves directly from multi-view edge maps. Contrasting with existing two-stage methods that follow a sequential &#96;&#96;edge point cloud reconstruction and parametric curve fittingâ€™â€™ pipeline, our one-stage approach optimizes 3D parametric curves directly from 2D edge maps, eliminating error accumulation caused by the inherent optimization gap between disconnected stages. However, parametric curves inherently lack suitability for rendering-based multi-view optimization, necessitating a complementary representation that preserves their geometric properties while enabling differentiable rendering. We propose a novel bi-directional coupling mechanism between parametric curves and edge-oriented Gaussian components. This tight correspondence formulates a curve-aware Gaussian representation, \textbf{CurveGaussian}, that enables differentiable rendering of 3D curves, allowing direct optimization guided by multi-view evidence. Furthermore, we introduce a dynamically adaptive topology optimization framework during training to refine curve structures through linearization, merging, splitting, and pruning operations. Comprehensive evaluations on the ABC dataset and real-world benchmarks demonstrate our one-stage methodâ€™s superiority over two-stage alternatives, particularly in producing cleaner and more robust reconstructions. Additionally, by directly optimizing parametric curves, our method significantly reduces the parameter count during training, achieving both higher efficiency and superior performance compared to existing approaches. </p>
<blockquote>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ç§ç«¯åˆ°ç«¯çš„æ¡†æ¶ï¼Œå¯ç›´æ¥ä»å¤šè§†è§’è¾¹ç¼˜åœ°å›¾é‡å»º3Då‚æ•°æ›²çº¿ã€‚ä¸ç°æœ‰çš„ä¸¤é˜¶æ®µæ–¹æ³•ï¼ˆéµå¾ªâ€œè¾¹ç¼˜ç‚¹äº‘é‡å»ºå’Œå‚æ•°æ›²çº¿æ‹Ÿåˆâ€çš„æµæ°´çº¿ï¼‰å½¢æˆå¯¹æ¯”ï¼Œæˆ‘ä»¬çš„å•é˜¶æ®µæ–¹æ³•ç›´æ¥ä»äºŒç»´è¾¹ç¼˜åœ°å›¾ä¼˜åŒ–ä¸‰ç»´å‚æ•°æ›²çº¿ï¼Œæ¶ˆé™¤äº†ç”±äºä¸åŒé˜¶æ®µä¹‹é—´å›ºæœ‰çš„ä¼˜åŒ–é—´éš”æ‰€å¯¼è‡´çš„è¯¯å·®ç´¯ç§¯ã€‚ç„¶è€Œï¼Œå‚æ•°æ›²çº¿åœ¨åŸºäºæ¸²æŸ“çš„å¤šè§†è§’ä¼˜åŒ–æ–¹é¢å­˜åœ¨å›ºæœ‰çš„å±€é™æ€§ï¼Œå› æ­¤éœ€è¦ä¸€ç§èƒ½å¤Ÿä¿ç•™å…¶å‡ ä½•å±æ€§åŒæ—¶å®ç°å¯å¾®åˆ†æ¸²æŸ“çš„äº’è¡¥è¡¨ç¤ºã€‚æˆ‘ä»¬æå‡ºäº†å‚æ•°æ›²çº¿å’Œè¾¹ç¼˜å®šå‘é«˜æ–¯ç»„ä»¶ä¹‹é—´çš„æ–°å‹åŒå‘è€¦åˆæœºåˆ¶ã€‚è¿™ç§ç´§å¯†å¯¹åº”å…³ç³»å½¢æˆäº†ä¸€ç§æ›²çº¿æ„ŸçŸ¥é«˜æ–¯è¡¨ç¤ºï¼ˆCurveGaussianï¼‰ï¼Œå®ƒèƒ½å¤Ÿå®ç°ä¸‰ç»´æ›²çº¿çš„å¯å¾®åˆ†æ¸²æŸ“ï¼Œå…è®¸ç›´æ¥ä¼˜åŒ–ä»¥å¤šè§†è§’è¯æ®ä¸ºæŒ‡å¯¼ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å¼•å…¥äº†ä¸€ä¸ªåŠ¨æ€è‡ªé€‚åº”æ‹“æ‰‘ä¼˜åŒ–æ¡†æ¶ï¼Œé€šè¿‡çº¿æ€§åŒ–ã€åˆå¹¶ã€åˆ†å‰²å’Œä¿®å‰ªæ“ä½œæ¥å®Œå–„æ›²çº¿ç»“æ„ã€‚åœ¨ABCæ•°æ®é›†å’Œç°å®ä¸–ç•ŒåŸºå‡†æµ‹è¯•ä¸Šçš„ç»¼åˆè¯„ä¼°è¡¨æ˜ï¼Œæˆ‘ä»¬çš„å•é˜¶æ®µæ–¹æ³•åœ¨å¤šä¸ªæ–¹é¢ä¼˜äºä¸¤é˜¶æ®µæ–¹æ³•ï¼Œå°¤å…¶æ˜¯åœ¨ç”Ÿæˆæ›´å¹²å‡€ã€æ›´ç¨³å¥çš„é‡å»ºæ–¹é¢è¡¨ç°ä¼˜è¶Šã€‚æ­¤å¤–ï¼Œé€šè¿‡ç›´æ¥ä¼˜åŒ–å‚æ•°æ›²çº¿ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨è®­ç»ƒæœŸé—´å¤§å¤§å‡å°‘äº†å‚æ•°è®¡æ•°ï¼Œä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”å®ç°äº†æ›´é«˜çš„æ•ˆç‡å’Œæ€§èƒ½æå‡ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.21401v2">PDF</a> Accepted by ICCV 2025 Code:   <a target="_blank" rel="noopener" href="https://github.com/zhirui-gao/Curve-Gaussian">https://github.com/zhirui-gao/Curve-Gaussian</a></p>
<p><strong>Summary</strong></p>
<p>è¯¥è®ºæ–‡æå‡ºä¸€ç§ç«¯åˆ°ç«¯çš„æ¡†æ¶ï¼Œèƒ½å¤Ÿä»å¤šè§†è§’è¾¹ç¼˜åœ°å›¾ç›´æ¥é‡å»º3Då‚æ•°æ›²çº¿ã€‚ä¸åŒäºç°æœ‰çš„ä¸¤é˜¶æ®µæ–¹æ³•ï¼ˆä¾æ¬¡è¿›è¡Œè¾¹ç¼˜ç‚¹äº‘é‡å»ºå’Œå‚æ•°æ›²çº¿æ‹Ÿåˆï¼‰ï¼Œæˆ‘ä»¬çš„å•é˜¶æ®µæ–¹æ³•ç›´æ¥ä»2Dè¾¹ç¼˜åœ°å›¾ä¼˜åŒ–3Då‚æ•°æ›²çº¿ï¼Œé¿å…äº†å› é˜¶æ®µé—´ä¼˜åŒ–å·®è·å¯¼è‡´çš„è¯¯å·®ç´¯ç§¯ã€‚ä¸ºå…‹æœå‚æ•°æ›²çº¿åœ¨åŸºäºæ¸²æŸ“çš„å¤šè§†è§’ä¼˜åŒ–ä¸­çš„ä¸é€‚ç”¨æ€§é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°å‹çš„åŒå‘è€¦åˆæœºåˆ¶ï¼Œå°†å‚æ•°æ›²çº¿ä¸è¾¹ç¼˜å®šå‘é«˜æ–¯ç»„ä»¶ç›¸ç»“åˆã€‚è¿™ç§ç´§å¯†å¯¹åº”å…³ç³»å½¢æˆäº†ä¸€ç§æ›²çº¿æ„ŸçŸ¥çš„é«˜æ–¯è¡¨ç¤ºï¼ˆCurveGaussianï¼‰ï¼Œèƒ½å¤Ÿå®ç°3Dæ›²çº¿çš„å¯å¾®æ¸²æŸ“ï¼Œå¹¶å¯ç›´æ¥ç”±å¤šè§†è§’è¯æ®è¿›è¡Œä¼˜åŒ–æŒ‡å¯¼ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜å¼•å…¥äº†ä¸€ä¸ªåŠ¨æ€è‡ªé€‚åº”æ‹“æ‰‘ä¼˜åŒ–æ¡†æ¶ï¼Œåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­é€šè¿‡çº¿æ€§åŒ–ã€åˆå¹¶ã€æ‹†åˆ†å’Œä¿®å‰ªæ“ä½œæ¥ä¼˜åŒ–æ›²çº¿ç»“æ„ã€‚åœ¨ABCæ•°æ®é›†å’ŒçœŸå®ä¸–ç•ŒåŸºå‡†æµ‹è¯•ä¸Šçš„ç»¼åˆè¯„ä¼°è¡¨æ˜ï¼Œæˆ‘ä»¬çš„å•é˜¶æ®µæ–¹æ³•ä¼˜äºä¸¤é˜¶æ®µæ–¹æ³•ï¼Œç‰¹åˆ«æ˜¯åœ¨äº§ç”Ÿæ›´å¹²å‡€ã€æ›´ç¨³å¥çš„é‡å»ºç»“æœæ–¹é¢ã€‚æ­¤å¤–ï¼Œé€šè¿‡ç›´æ¥ä¼˜åŒ–å‚æ•°æ›²çº¿ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å‡å°‘äº†å‚æ•°æ•°é‡ï¼Œæé«˜äº†æ•ˆç‡å¹¶è¶…è¶Šäº†ç°æœ‰æ–¹æ³•ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æå‡ºäº†ä¸€ç§ç«¯åˆ°ç«¯çš„æ¡†æ¶ï¼Œç›´æ¥ä»å¤šè§†è§’è¾¹ç¼˜åœ°å›¾é‡å»º3Då‚æ•°æ›²çº¿ã€‚</li>
<li>ä¸ä¸¤é˜¶æ®µæ–¹æ³•ç›¸æ¯”ï¼Œå‡å°‘äº†è¯¯å·®ç´¯ç§¯ã€‚</li>
<li>å¼•å…¥äº†å‚æ•°æ›²çº¿å’Œè¾¹ç¼˜å®šå‘é«˜æ–¯ç»„ä»¶çš„åŒå‘è€¦åˆæœºåˆ¶ï¼Œå½¢æˆäº†æ›²çº¿æ„ŸçŸ¥çš„é«˜æ–¯è¡¨ç¤ºï¼ˆCurveGaussianï¼‰ã€‚</li>
<li>å®ç°äº†3Dæ›²çº¿çš„å¯å¾®æ¸²æŸ“ï¼Œå¯ç›´æ¥ç”±å¤šè§†è§’è¯æ®è¿›è¡Œä¼˜åŒ–æŒ‡å¯¼ã€‚</li>
<li>æå‡ºäº†åŠ¨æ€è‡ªé€‚åº”æ‹“æ‰‘ä¼˜åŒ–æ¡†æ¶ï¼Œåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ä¼˜åŒ–æ›²çº¿ç»“æ„ã€‚</li>
<li>åœ¨ABCæ•°æ®é›†å’ŒçœŸå®ä¸–ç•ŒåŸºå‡†æµ‹è¯•ä¸Šè¡¨ç°å‡ºä¼˜è¶Šæ€§èƒ½ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.21401">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-0034bc1911428ed666d0d6190a8b399e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-161ddf1b18f8e406a6399c904ea5327f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-04a59bec2f761aadf0d7be3d8ddb89cf.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-7f3aa127fff7de46b555f639ac309080.jpg" align="middle">
</details>


<h1 id="-16"><a href="#-16" class="headerlink" title=""></a></h1><h2 id="Mesh-Learner-Texturing-Mesh-with-Spherical-Harmonics"><a href="#Mesh-Learner-Texturing-Mesh-with-Spherical-Harmonics" class="headerlink" title="Mesh-Learner: Texturing Mesh with Spherical Harmonics"></a>Mesh-Learner: Texturing Mesh with Spherical Harmonics</h2><p><strong>Authors:Yunfei Wan, Jianheng Liu, Chunran Zheng, Jiarong Lin, Fu Zhang</strong></p>
<p>In this paper, we present a 3D reconstruction and rendering framework termed Mesh-Learner that is natively compatible with traditional rasterization pipelines. It integrates mesh and spherical harmonic (SH) texture (i.e., texture filled with SH coefficients) into the learning process to learn each mesh s view-dependent radiance end-to-end. Images are rendered by interpolating surrounding SH Texels at each pixel s sampling point using a novel interpolation method. Conversely, gradients from each pixel are back-propagated to the related SH Texels in SH textures. Mesh-Learner exploits graphic features of rasterization pipeline (texture sampling, deferred rendering) to render, which makes Mesh-Learner naturally compatible with tools (e.g., Blender) and tasks (e.g., 3D reconstruction, scene rendering, reinforcement learning for robotics) that are based on rasterization pipelines. Our system can train vast, unlimited scenes because we transfer only the SH textures within the frustum to the GPU for training. At other times, the SH textures are stored in CPU RAM, which results in moderate GPU memory usage. The rendering results on interpolation and extrapolation sequences in the Replica and FAST-LIVO2 datasets achieve state-of-the-art performance compared to existing state-of-the-art methods (e.g., 3D Gaussian Splatting and M2-Mapping). To benefit the society, the code will be available at <a target="_blank" rel="noopener" href="https://github.com/hku-mars/Mesh-Learner">https://github.com/hku-mars/Mesh-Learner</a>. </p>
<blockquote>
<p>æœ¬æ–‡ä»‹ç»äº†ä¸€ä¸ªåä¸ºMesh-Learnerçš„3Dé‡å»ºå’Œæ¸²æŸ“æ¡†æ¶ï¼Œå®ƒä¸ä¼ ç»Ÿå…‰æ …åŒ–æµæ°´çº¿å…¼å®¹ã€‚å®ƒé›†æˆäº†ç½‘æ ¼å’Œçƒé¢è°æ³¢ï¼ˆSHï¼‰çº¹ç†ï¼ˆå³å¡«å……SHç³»æ•°çš„çº¹ç†ï¼‰åˆ°å­¦ä¹ è¿‡ç¨‹ä¸­ï¼Œä»¥ç«¯åˆ°ç«¯çš„æ–¹å¼å­¦ä¹ æ¯ä¸ªç½‘æ ¼çš„è§†å·®ç›¸å…³è¾å°„ç‡ã€‚å›¾åƒæ˜¯é€šè¿‡ä¸€ç§æ–°å‹æ’å€¼æ–¹æ³•ï¼Œåœ¨æ¯ä¸ªåƒç´ é‡‡æ ·ç‚¹æ’å€¼å‘¨å›´çš„SHçº¹ç†å…ƒç´ æ¥å‘ˆç°çš„ã€‚ç›¸åï¼Œæ¯ä¸ªåƒç´ çš„æ¢¯åº¦ä¼šåå‘ä¼ æ’­åˆ°ç›¸å…³çš„SHçº¹ç†ä¸­çš„SHçº¹ç†å…ƒç´ ã€‚Mesh-Learneråˆ©ç”¨å…‰æ …åŒ–æµæ°´çº¿ï¼ˆçº¹ç†é‡‡æ ·ã€å»¶è¿Ÿæ¸²æŸ“ï¼‰çš„å›¾å½¢ç‰¹å¾è¿›è¡Œæ¸²æŸ“ï¼Œè¿™ä½¿å¾—Mesh-Learnerè‡ªç„¶åœ°ä¸åŸºäºå…‰æ …åŒ–æµæ°´çº¿çš„å·¥å…·ï¼ˆä¾‹å¦‚Blenderï¼‰å’Œä»»åŠ¡ï¼ˆä¾‹å¦‚3Dé‡å»ºã€åœºæ™¯æ¸²æŸ“ã€æœºå™¨äººå¼ºåŒ–å­¦ä¹ ï¼‰å…¼å®¹ã€‚æˆ‘ä»¬çš„ç³»ç»Ÿå¯ä»¥è®­ç»ƒå¤§é‡æ— é™çš„åœºæ™¯ï¼Œå› ä¸ºæˆ‘ä»¬å°†ä»…å°†è§†é”¥ä½“å†…çš„SHçº¹ç†ä¼ è¾“åˆ°GPUè¿›è¡Œè®­ç»ƒã€‚åœ¨å…¶ä»–æ—¶é—´ï¼ŒSHçº¹ç†å­˜å‚¨åœ¨CPU RAMä¸­ï¼Œè¿™å¯¼è‡´GPUå†…å­˜ä½¿ç”¨é€‚ä¸­ã€‚åœ¨Replicaå’ŒFAST-LIVO2æ•°æ®é›†ä¸Šçš„æ’å€¼å’Œå¤–æ¨åºåˆ—çš„æ¸²æŸ“ç»“æœè¾¾åˆ°äº†ä¸ç°æœ‰æœ€å…ˆè¿›æ–¹æ³•ï¼ˆä¾‹å¦‚3Dé«˜æ–¯æº…å°„å’ŒM2-Mappingï¼‰ç›¸æ¯”çš„å…ˆè¿›æ€§èƒ½ã€‚ä¸ºäº†é€ ç¦ç¤¾ä¼šï¼Œä»£ç å°†åœ¨<a target="_blank" rel="noopener" href="https://github.com/hku-mars/Mesh-Learner">https://github.com/hku-mars/Mesh-Learner</a>ä¸Šæä¾›ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.19938v2">PDF</a> IROS2025 Accepted</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†ä¸€ç§åä¸ºMesh-Learnerçš„3Dé‡å»ºå’Œæ¸²æŸ“æ¡†æ¶ï¼Œè¯¥æ¡†æ¶ä¸ä¼ ç»Ÿçš„å…‰çº¿è¿½è¸ªæ¸²æŸ“ç®¡çº¿å…¼å®¹ã€‚å®ƒé€šè¿‡æ•´åˆç½‘æ ¼å’Œçƒé¢è°æ³¢çº¹ç†ï¼Œå®ç°äº†ç«¯åˆ°ç«¯çš„è§†å›¾ç›¸å…³è¾å°„ç‡å­¦ä¹ ã€‚é‡‡ç”¨æ–°å‹æ’å€¼æ–¹æ³•ä¸ºåƒç´ é‡‡æ ·ç‚¹æ’å€¼æ¸²æŸ“å›¾åƒï¼ŒåŒæ—¶æ¢¯åº¦åå‘ä¼ æ’­è‡³ç›¸å…³çš„SHçº¹ç†ã€‚Mesh-Learneråˆ©ç”¨å…‰çº¿è¿½è¸ªæ¸²æŸ“ç®¡çº¿ï¼ˆçº¹ç†é‡‡æ ·ã€å»¶è¿Ÿæ¸²æŸ“ï¼‰çš„ç‰¹æ€§è¿›è¡Œæ¸²æŸ“ï¼Œä½¿å…¶è‡ªç„¶åœ°ä¸åŸºäºå…‰çº¿è¿½è¸ªçš„å·¥å…·å’Œä»»åŠ¡å…¼å®¹ã€‚ç”±äºå…¶ä»…ä¼ è¾“è§†é”¥ä½“å†…çš„SHçº¹ç†åˆ°GPUè¿›è¡Œè®­ç»ƒï¼Œå› æ­¤å¯è®­ç»ƒå¤§è§„æ¨¡æ— é™åœºæ™¯ã€‚æ­¤å¤–ï¼Œå®ƒåœ¨Replicaå’ŒFAST-LIVO2æ•°æ®é›†ä¸Šçš„æ¸²æŸ“ç»“æœè¾¾åˆ°æˆ–è¶…è¶Šäº†ç°æœ‰å…ˆè¿›æ–¹æ³•ã€‚ç›¸å…³ä»£ç å°†åœ¨<a target="_blank" rel="noopener" href="https://github.com/hku-mars/Mesh-Learner%E4%B8%8A%E5%85%AC%E5%BC%80%E3%80%82">https://github.com/hku-mars/Mesh-Learnerä¸Šå…¬å¼€ã€‚</a></p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>Mesh-Learneræ¡†æ¶èåˆäº†ç½‘æ ¼æŠ€æœ¯ä¸çƒé¢è°æ³¢çº¹ç†ï¼Œæ”¯æŒç«¯åˆ°ç«¯çš„è§†å›¾ç›¸å…³è¾å°„ç‡å­¦ä¹ ã€‚</li>
<li>é‡‡ç”¨äº†æ–°é¢–çš„åƒç´ æ’å€¼æ–¹æ³•å’Œæ¢¯åº¦åå‘ä¼ æ’­æŠ€æœ¯ã€‚</li>
<li>Mesh-Learnerå¤©ç„¶å…¼å®¹ä¼ ç»Ÿå…‰çº¿è¿½è¸ªæ¸²æŸ“ç®¡çº¿ï¼Œå¯èå…¥ç°æœ‰å·¥å…·å’Œä»»åŠ¡ã€‚</li>
<li>è¯¥æ¡†æ¶èƒ½é«˜æ•ˆè®­ç»ƒå¤§è§„æ¨¡ã€æ— é™åœºæ™¯ï¼Œé€šè¿‡ä»…ä¼ è¾“è§†é”¥ä½“å†…çš„SHçº¹ç†è‡³GPUè¿›è¡Œè®­ç»ƒã€‚</li>
<li>SHçº¹ç†å¯å­˜å‚¨åœ¨CPU RAMä¸­ï¼Œé™ä½GPUå†…å­˜ä½¿ç”¨ã€‚</li>
<li>åœ¨æ ‡å‡†æ•°æ®é›†ä¸Šçš„æ¸²æŸ“ç»“æœè¾¾åˆ°äº†å…ˆè¿›æ°´å‡†ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.19938">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-57ab7a6ea3d93d889542813bc7e5840c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-337bc6d2fd66e3505eccbe6f39b24c64.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b2ab021890874788265b584a3fa44d4f.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-1c6c7ff641e2e607d996db2ab0a9b6f8.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d6d1021eae5c93406c4df34991ace5da.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-03b50012df314884f14ce933b07fb8e9.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-34b46b6850ffe46f3c9db3b96a63ce56.jpg" align="middle">
</details>


<h1 id="-17"><a href="#-17" class="headerlink" title=""></a></h1><h2 id="Audio-Plane-Audio-Factorization-Plane-Gaussian-Splatting-for-Real-Time-Talking-Head-Synthesis"><a href="#Audio-Plane-Audio-Factorization-Plane-Gaussian-Splatting-for-Real-Time-Talking-Head-Synthesis" class="headerlink" title="Audio-Plane: Audio Factorization Plane Gaussian Splatting for Real-Time   Talking Head Synthesis"></a>Audio-Plane: Audio Factorization Plane Gaussian Splatting for Real-Time   Talking Head Synthesis</h2><p><strong>Authors:Shuai Shen, Wanhua Li, Yunpeng Zhang, Yap-Peng Tan, Jiwen Lu</strong></p>
<p>Talking head synthesis has emerged as a prominent research topic in computer graphics and multimedia, yet most existing methods often struggle to strike a balance between generation quality and computational efficiency, particularly under real-time constraints. In this paper, we propose a novel framework that integrates Gaussian Splatting with a structured Audio Factorization Plane (Audio-Plane) to enable high-quality, audio-synchronized, and real-time talking head generation. For modeling a dynamic talking head, a 4D volume representation, which consists of three axes in 3D space and one temporal axis aligned with audio progression, is typically required. However, directly storing and processing a dense 4D grid is impractical due to the high memory and computation cost, and lack of scalability for longer durations. We address this challenge by decomposing the 4D volume representation into a set of audio-independent spatial planes and audio-dependent planes, forming a compact and interpretable representation for talking head modeling that we refer to as the Audio-Plane. This factorized design allows for efficient and fine-grained audio-aware spatial encoding, and significantly enhances the modelâ€™s ability to capture complex lip dynamics driven by speech signals. To further improve region-specific motion modeling, we introduce an audio-guided saliency splatting mechanism based on region-aware modulation, which adaptively emphasizes highly dynamic regions such as the mouth area. This allows the model to focus its learning capacity on where it matters most for accurate speech-driven animation. Extensive experiments on both the self-driven and the cross-driven settings demonstrate that our method achieves state-of-the-art visual quality, precise audio-lip synchronization, and real-time performance, outperforming prior approaches across both 2D- and 3D-based paradigms. </p>
<blockquote>
<p>è°ˆè¯å¤´åˆæˆå·²æˆä¸ºè®¡ç®—æœºå›¾å½¢å­¦å’Œå¤šåª’ä½“é¢†åŸŸçš„ä¸€ä¸ªé‡è¦ç ”ç©¶è¯¾é¢˜ï¼Œç„¶è€Œï¼Œå¤§å¤šæ•°ç°æœ‰æ–¹æ³•å¾€å¾€éš¾ä»¥åœ¨ç”Ÿæˆè´¨é‡å’Œè®¡ç®—æ•ˆç‡ä¹‹é—´å–å¾—å¹³è¡¡ï¼Œç‰¹åˆ«æ˜¯åœ¨å®æ—¶çº¦æŸä¸‹ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªç»“åˆé«˜æ–¯Splattingå’Œç»“æ„åŒ–çš„éŸ³é¢‘å› å­å¹³é¢ï¼ˆAudio-Planeï¼‰çš„æ–°å‹æ¡†æ¶ï¼Œä»¥å®ç°é«˜è´¨é‡ã€éŸ³é¢‘åŒæ­¥å’Œå®æ—¶çš„è°ˆè¯å¤´ç”Ÿæˆã€‚ä¸ºäº†æ¨¡æ‹ŸåŠ¨æ€çš„è°ˆè¯å¤´ï¼Œé€šå¸¸éœ€è¦ä¸€ä¸ª4Dä½“ç§¯è¡¨ç¤ºï¼Œè¯¥è¡¨ç¤ºç”±ä¸‰ä¸ªç©ºé—´è½´å’Œä¸€ä¸ªä¸éŸ³é¢‘è¿›å±•å¯¹é½çš„æ—¶é—´è½´ç»„æˆã€‚ç„¶è€Œï¼Œç”±äºç›´æ¥å­˜å‚¨å’Œå¤„ç†å¯†é›†çš„4Dç½‘æ ¼å­˜åœ¨å†…å­˜å’Œè®¡ç®—æˆæœ¬é«˜ä»¥åŠé•¿æœŸç¼ºä¹å¯æ‰©å±•æ€§çš„é—®é¢˜ï¼Œå› æ­¤å¹¶ä¸å®ç”¨ã€‚æˆ‘ä»¬é€šè¿‡å°†4Dä½“ç§¯è¡¨ç¤ºåˆ†è§£ä¸ºä¸€ç³»åˆ—éŸ³é¢‘ç‹¬ç«‹çš„å¹³é¢å’ŒéŸ³é¢‘ä¾èµ–çš„å¹³é¢æ¥è§£å†³è¿™ä¸€æŒ‘æˆ˜ï¼Œå½¢æˆäº†ä¸€ç§ç´§å‡‘ä¸”å¯è§£é‡Šçš„è°ˆè¯å¤´æ¨¡å‹è¡¨ç¤ºï¼Œæˆ‘ä»¬ç§°ä¹‹ä¸ºAudio-Planeã€‚è¿™ç§å› å­åŒ–çš„è®¾è®¡å…è®¸é«˜æ•ˆä¸”ç²¾ç»†çš„éŸ³é¢‘æ„ŸçŸ¥ç©ºé—´ç¼–ç ï¼Œå¹¶æ˜¾ç€æé«˜äº†æ¨¡å‹æ•æ‰ç”±è¯­éŸ³ä¿¡å·é©±åŠ¨çš„å¤æ‚å˜´å”‡åŠ¨æ€çš„èƒ½åŠ›. ä¸ºäº†è¿›ä¸€æ­¥æ”¹è¿›ç‰¹å®šåŒºåŸŸçš„è¿åŠ¨å»ºæ¨¡ï¼Œæˆ‘ä»¬å¼•å…¥äº†åŸºäºåŒºåŸŸæ„ŸçŸ¥è°ƒåˆ¶çš„éŸ³é¢‘å¼•å¯¼æ˜¾è‘—æ€§Splattingæœºåˆ¶ï¼Œè¯¥æœºåˆ¶å¯è‡ªé€‚åº”åœ°å¼ºè°ƒé«˜åº¦åŠ¨æ€çš„åŒºåŸŸï¼Œå¦‚å˜´å·´åŒºåŸŸã€‚è¿™ä½¿æ¨¡å‹èƒ½å¤Ÿä¸“æ³¨äºæœ€å…³é”®çš„åŒºåŸŸï¼Œä»¥å®ç°ç²¾ç¡®çš„è¯­è¨€é©±åŠ¨åŠ¨ç”»ã€‚åœ¨è‡ªé©±åŠ¨å’Œäº¤å‰é©±åŠ¨è®¾ç½®ä¸Šçš„å¤§é‡å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•è¾¾åˆ°äº†æœ€å…ˆè¿›çš„è§†è§‰è´¨é‡ã€ç²¾ç¡®çš„éŸ³é¢‘-å˜´å”‡åŒæ­¥å’Œå®æ—¶æ€§èƒ½ï¼Œåœ¨2Då’Œ3DåŸºäºèŒƒå¼çš„æ–¹æ³•ä¸­éƒ½ä¼˜äºå…ˆå‰çš„æ–¹æ³•ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.22605v2">PDF</a> Demo video at \url{<a target="_blank" rel="noopener" href="https://sstzal.github.io/Audio-Plane/%7D">https://sstzal.github.io/Audio-Plane/}</a></p>
<p><strong>Summary</strong><br>    æœ¬æ–‡æå‡ºä¸€ç§ç»“åˆé«˜æ–¯æ¶‚æ–‘æŠ€æœ¯å’Œç»“æ„åŒ–éŸ³é¢‘å› å­å¹³é¢ï¼ˆAudio-Planeï¼‰çš„æ–°æ¡†æ¶ï¼Œå®ç°äº†é«˜è´¨é‡ã€éŸ³é¢‘åŒæ­¥çš„å®æ—¶å¤´éƒ¨ç”Ÿæˆã€‚ä¸ºè§£å†³ç›´æ¥å¤„ç†å¯†é›†4Dç½‘æ ¼å¸¦æ¥çš„é«˜å†…å­˜å’Œè®¡ç®—æˆæœ¬é—®é¢˜ï¼Œé‡‡ç”¨éŸ³é¢‘ç‹¬ç«‹çš„ç©ºé—´å¹³é¢å’ŒéŸ³é¢‘ä¾èµ–å¹³é¢æ„æˆç´§å‡‘ã€å¯è§£é‡Šçš„å¤´éƒ¨æ¨¡å‹è¡¨ç¤ºã€‚å¼•å…¥éŸ³é¢‘å¼•å¯¼æ˜¾è‘—æ€§æ¶‚æ–‘æœºåˆ¶ï¼Œè‡ªé€‚åº”å¼ºè°ƒé«˜åº¦åŠ¨æ€åŒºåŸŸï¼Œå¦‚å£éƒ¨åŒºåŸŸï¼Œè¿›ä¸€æ­¥æé«˜åŒºåŸŸç‰¹å®šè¿åŠ¨å»ºæ¨¡ã€‚å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨è‡ªé©±åŠ¨å’Œè·¨é©±åŠ¨è®¾ç½®ä¸­å‡å®ç°æœ€ä½³è§†è§‰è´¨é‡ã€ç²¾ç¡®çš„éŸ³é¢‘-å”‡éƒ¨åŒæ­¥å’Œå®æ—¶æ€§èƒ½ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æå‡ºäº†ç»“åˆé«˜æ–¯æ¶‚æ–‘ä¸ç»“æ„åŒ–éŸ³é¢‘å› å­å¹³é¢ï¼ˆAudio-Planeï¼‰çš„æ¡†æ¶ï¼Œå®ç°é«˜è´¨é‡å®æ—¶å¤´éƒ¨ç”Ÿæˆã€‚</li>
<li>è§£å†³ç›´æ¥å¤„ç†å¯†é›†4Dç½‘æ ¼å¯¼è‡´çš„é«˜å†…å­˜å’Œè®¡ç®—æˆæœ¬é—®é¢˜ã€‚</li>
<li>é‡‡ç”¨éŸ³é¢‘ç‹¬ç«‹çš„ç©ºé—´å¹³é¢å’ŒéŸ³é¢‘ä¾èµ–å¹³é¢æ„æˆç´§å‡‘çš„å¤´éƒ¨æ¨¡å‹è¡¨ç¤ºï¼Œå³Audio-Planeã€‚</li>
<li>å¼•å…¥éŸ³é¢‘å¼•å¯¼æ˜¾è‘—æ€§æ¶‚æ–‘æœºåˆ¶ï¼Œå¼ºè°ƒé«˜åº¦åŠ¨æ€åŒºåŸŸå¦‚å£éƒ¨åŒºåŸŸã€‚</li>
<li>æ–¹æ³•å®ç°äº†ç²¾ç¡®çš„éŸ³é¢‘-å”‡éƒ¨åŒæ­¥ã€‚</li>
<li>åœ¨è‡ªé©±åŠ¨å’Œè·¨é©±åŠ¨è®¾ç½®ä¸­å‡è¡¨ç°å‡ºä¼˜å¼‚çš„è§†è§‰è´¨é‡å’Œå®æ—¶æ€§èƒ½ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.22605">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-b4421c32e1377871bb4076391b2450f8.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-1a354e62ab47877e903079e3a52c528a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-4419f5ce49feac3a2a446fdb2cfae702.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-722d595511ab12179aecd25f16179962.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-a3bcbeb9dc09f309aeb2b3230feddadd.jpg" align="middle">
</details>


<h1 id="-18"><a href="#-18" class="headerlink" title=""></a></h1><h2 id="GRaD-Nav-Efficiently-Learning-Visual-Drone-Navigation-with-Gaussian-Radiance-Fields-and-Differentiable-Dynamics"><a href="#GRaD-Nav-Efficiently-Learning-Visual-Drone-Navigation-with-Gaussian-Radiance-Fields-and-Differentiable-Dynamics" class="headerlink" title="GRaD-Nav: Efficiently Learning Visual Drone Navigation with Gaussian   Radiance Fields and Differentiable Dynamics"></a>GRaD-Nav: Efficiently Learning Visual Drone Navigation with Gaussian   Radiance Fields and Differentiable Dynamics</h2><p><strong>Authors:Qianzhong Chen, Jiankai Sun, Naixiang Gao, JunEn Low, Timothy Chen, Mac Schwager</strong></p>
<p>Autonomous visual navigation is an essential element in robot autonomy. Reinforcement learning (RL) offers a promising policy training paradigm. However existing RL methods suffer from high sample complexity, poor sim-to-real transfer, and limited runtime adaptability to navigation scenarios not seen during training. These problems are particularly challenging for drones, with complex nonlinear and unstable dynamics, and strong dynamic coupling between control and perception. In this paper, we propose a novel framework that integrates 3D Gaussian Splatting (3DGS) with differentiable deep reinforcement learning (DDRL) to train vision-based drone navigation policies. By leveraging high-fidelity 3D scene representations and differentiable simulation, our method improves sample efficiency and sim-to-real transfer. Additionally, we incorporate a Context-aided Estimator Network (CENet) to adapt to environmental variations at runtime. Moreover, by curriculum training in a mixture of different surrounding environments, we achieve in-task generalization, the ability to solve new instances of a task not seen during training. Drone hardware experiments demonstrate our methodâ€™s high training efficiency compared to state-of-the-art RL methods, zero shot sim-to-real transfer for real robot deployment without fine tuning, and ability to adapt to new instances within the same task class (e.g. to fly through a gate at different locations with different distractors in the environment). Our simulator and training framework are open-sourced at: <a target="_blank" rel="noopener" href="https://github.com/Qianzhong-Chen/grad_nav">https://github.com/Qianzhong-Chen/grad_nav</a>. </p>
<blockquote>
<p>è‡ªä¸»è§†è§‰å¯¼èˆªæ˜¯æœºå™¨äººè‡ªä¸»æ€§çš„ä¸€ä¸ªé‡è¦ç»„æˆéƒ¨åˆ†ã€‚å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰æä¾›äº†ä¸€ä¸ªæœ‰å‰æ™¯çš„ç­–ç•¥è®­ç»ƒèŒƒå¼ã€‚ç„¶è€Œï¼Œç°æœ‰çš„å¼ºåŒ–å­¦ä¹ æ–¹æ³•å­˜åœ¨æ ·æœ¬å¤æ‚åº¦é«˜ã€æ¨¡æ‹Ÿåˆ°ç°å®çš„è½¬ç§»æ€§èƒ½å·®ä»¥åŠåœ¨è®­ç»ƒæœŸé—´å¯¹æœªè§è¿‡çš„å¯¼èˆªåœºæ™¯çš„å®æ—¶é€‚åº”èƒ½åŠ›æœ‰é™ç­‰é—®é¢˜ã€‚å¯¹äºå…·æœ‰å¤æ‚éçº¿æ€§ã€ä¸ç¨³å®šåŠ¨åŠ›å­¦ä»¥åŠæ§åˆ¶å’Œæ„ŸçŸ¥ä¹‹é—´å¼ºåŠ¨æ€è€¦åˆçš„æ— äººæœºæ¥è¯´ï¼Œè¿™äº›é—®é¢˜æ›´å…·æŒ‘æˆ˜æ€§ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°é¢–æ¡†æ¶ï¼Œè¯¥æ¡†æ¶å°†ä¸‰ç»´é«˜æ–¯å–·æ¶‚ï¼ˆ3DGSï¼‰ä¸å¯å¾®æ·±åº¦å­¦ä¹ å¼ºåŒ–å­¦ä¹ ï¼ˆDDRLï¼‰ç›¸ç»“åˆï¼Œä»¥è®­ç»ƒåŸºäºè§†è§‰çš„æ— äººæœºå¯¼èˆªç­–ç•¥ã€‚é€šè¿‡åˆ©ç”¨é«˜ä¿çœŸä¸‰ç»´åœºæ™¯è¡¨ç¤ºå’Œå¯å¾®åˆ†æ¨¡æ‹Ÿï¼Œæˆ‘ä»¬çš„æ–¹æ³•æé«˜äº†æ ·æœ¬æ•ˆç‡å’Œæ¨¡æ‹Ÿåˆ°ç°å®çš„è½¬ç§»èƒ½åŠ›ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸Šä¸‹æ–‡è¾…åŠ©ä¼°è®¡ç½‘ç»œï¼ˆCENetï¼‰ä»¥åœ¨è¿è¡Œæ—¶é€‚åº”ç¯å¢ƒå˜åŒ–ã€‚è€Œä¸”ï¼Œé€šè¿‡åœ¨ä¸åŒå‘¨å›´ç¯å¢ƒçš„æ··åˆä¸­è¿›è¡Œè¯¾ç¨‹è®­ç»ƒï¼Œæˆ‘ä»¬å®ç°äº†ä»»åŠ¡å†…æ³›åŒ–ï¼Œå³è§£å†³åœ¨è®­ç»ƒæœŸé—´æœªè§çš„æ–°ä»»åŠ¡å®ä¾‹çš„èƒ½åŠ›ã€‚æ— äººæœºç¡¬ä»¶å®éªŒè¯æ˜ï¼Œä¸æœ€æ–°å¼ºåŒ–å­¦ä¹ æ–¹æ³•ç›¸æ¯”ï¼Œæˆ‘ä»¬çš„æ–¹æ³•å…·æœ‰é«˜æ•ˆç‡çš„è®­ç»ƒèƒ½åŠ›ã€æ— éœ€å¾®è°ƒå³å¯å®ç°æ¨¡æ‹Ÿåˆ°ç°å®åœºæ™¯çš„é›¶å°„è½¬ç§»èƒ½åŠ›ä»¥åŠåœ¨åŒç±»ä»»åŠ¡ä¸­é€‚åº”æ–°å®ä¾‹çš„èƒ½åŠ›ï¼ˆä¾‹å¦‚ï¼Œåœ¨ç¯å¢ƒä¸­æœ‰ä¸åŒå¹²æ‰°ç‰©çš„æƒ…å†µä¸‹åœ¨ä¸åŒçš„ä½ç½®ç©¿è¶Šæ …é—¨ï¼‰ã€‚æˆ‘ä»¬çš„æ¨¡æ‹Ÿå™¨å’Œè®­ç»ƒæ¡†æ¶åœ¨ <a target="_blank" rel="noopener" href="https://github.com/Qianzhong-Chen/grad_nav">https://github.com/Qianzhong-Chen/grad_nav</a> ä¸Šå¼€æºã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.03984v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºä¸€ç§ç»“åˆ3Dé«˜æ–¯æ‹¼è´´ï¼ˆ3DGSï¼‰ä¸å¯å¾®åˆ†æ·±åº¦å¼ºåŒ–å­¦ä¹ ï¼ˆDDRLï¼‰çš„æ¡†æ¶ï¼Œç”¨äºè®­ç»ƒåŸºäºè§†è§‰çš„æ— äººæœºå¯¼èˆªç­–ç•¥ã€‚è¯¥æ¡†æ¶åˆ©ç”¨é«˜ä¿çœŸ3Dåœºæ™¯è¡¨ç¤ºå’Œå¯å¾®åˆ†æ¨¡æ‹Ÿï¼Œæé«˜äº†æ ·æœ¬æ•ˆç‡å’Œæ¨¡æ‹Ÿåˆ°ç°å®çš„è½¬ç§»èƒ½åŠ›ã€‚æ­¤å¤–ï¼Œè¿˜èå…¥äº†ä¸Šä¸‹æ–‡è¾…åŠ©ä¼°è®¡ç½‘ç»œï¼ˆCENetï¼‰ä»¥é€‚åº”ç¯å¢ƒå˜åŒ–çš„è¿è¡Œæ—¶çš„éœ€æ±‚ã€‚é€šè¿‡åœ¨ä¸åŒç¯å¢ƒæ··åˆä¸­çš„è¯¾ç¨‹è®­ç»ƒï¼Œå®ç°äº†ä»»åŠ¡å†…æ³›åŒ–ï¼Œå³è§£å†³è®­ç»ƒæœŸé—´æœªè§çš„æ–°ä»»åŠ¡å®ä¾‹çš„èƒ½åŠ›ã€‚æ— äººæœºç¡¬ä»¶å®éªŒè¯æ˜äº†è¯¥æ–¹æ³•çš„é«˜æ•ˆè®­ç»ƒã€æ— éœ€å¾®è°ƒå³å¯å®ç°æ¨¡æ‹Ÿåˆ°ç°å®çš„é›¶å°„å‡»è½¬ç§»ï¼Œä»¥åŠé€‚åº”æ–°ä»»åŠ¡å®ä¾‹çš„èƒ½åŠ›ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æå‡ºäº†ç»“åˆ3DGSå’ŒDDRLçš„æ¡†æ¶ï¼Œç”¨äºè®­ç»ƒæ— äººæœºè§†è§‰å¯¼èˆªç­–ç•¥ã€‚</li>
<li>åˆ©ç”¨é«˜ä¿çœŸ3Dåœºæ™¯è¡¨ç¤ºå’Œå¯å¾®åˆ†æ¨¡æ‹Ÿæé«˜æ ·æœ¬æ•ˆç‡å’Œæ¨¡æ‹Ÿåˆ°ç°å®çš„è½¬ç§»èƒ½åŠ›ã€‚</li>
<li>èå…¥CENetä»¥é€‚åº”ç¯å¢ƒå˜åŒ–ï¼Œå¢å¼ºè¿è¡Œæ—¶çš„é€‚åº”èƒ½åŠ›ã€‚</li>
<li>é€šè¿‡è¯¾ç¨‹è®­ç»ƒå®ç°ä»»åŠ¡å†…æ³›åŒ–ï¼Œè§£å†³æœªè§çš„æ–°ä»»åŠ¡å®ä¾‹ã€‚</li>
<li>æ— äººæœºç¡¬ä»¶å®éªŒè¯æ˜äº†æ–¹æ³•çš„é«˜æ•ˆè®­ç»ƒã€æ¨¡æ‹Ÿåˆ°ç°å®çš„é›¶å°„å‡»è½¬ç§»èƒ½åŠ›ã€‚</li>
<li>å…¬å¼€äº†æ¨¡æ‹Ÿå™¨ä¸è®­ç»ƒæ¡†æ¶ï¼Œä¾¿äºä»–äººä½¿ç”¨ä¸è´¡çŒ®ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.03984">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-c372134ccd6da3c68a81c6d126281762.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-64cb720b3b393ef54a8fb3a3d72e8195.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-31a22f0586d6364c0902265bb22a4fc8.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-bd6a8d2136740f3ba50e73d32515a807.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-49b6b35e41751008c2ae7536b1602097.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-d77c6d8402fdff04a48a21717be9371e.jpg" align="middle">
</details>


<h1 id="-19"><a href="#-19" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-07-03/3DGS/">https://kedreamix.github.io/Talk2Paper/Paper/2025-07-03/3DGS/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/3DGS/">
                                    <span class="chip bg-color">3DGS</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-07-03/NeRF/">
                    <div class="card-image">
                        
                        <img src="https://pica.zhimg.com/v2-8316847a61ca9ce8a873eb8dcbaa3c8a.jpg" class="responsive-img" alt="NeRF">
                        
                        <span class="card-title">NeRF</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            NeRF æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-07-03  AttentionGS Towards Initialization-Free 3D Gaussian Splatting via   Structural Attention
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-07-03
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/NeRF/" class="post-category">
                                    NeRF
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/NeRF/">
                        <span class="chip bg-color">NeRF</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-07-03/%E5%85%83%E5%AE%87%E5%AE%99_%E8%99%9A%E6%8B%9F%E4%BA%BA/">
                    <div class="card-image">
                        
                        <img src="https://pica.zhimg.com/v2-4b10c0e568c6c34bbd6e2f79d5cebe19.jpg" class="responsive-img" alt="å…ƒå®‡å®™/è™šæ‹Ÿäºº">
                        
                        <span class="card-title">å…ƒå®‡å®™/è™šæ‹Ÿäºº</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            å…ƒå®‡å®™/è™šæ‹Ÿäºº æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-07-03  SqueezeMe Mobile-Ready Distillation of Gaussian Full-Body Avatars
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-07-03
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/%E5%85%83%E5%AE%87%E5%AE%99-%E8%99%9A%E6%8B%9F%E4%BA%BA/" class="post-category">
                                    å…ƒå®‡å®™/è™šæ‹Ÿäºº
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/%E5%85%83%E5%AE%87%E5%AE%99-%E8%99%9A%E6%8B%9F%E4%BA%BA/">
                        <span class="chip bg-color">å…ƒå®‡å®™/è™šæ‹Ÿäºº</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">30055.4k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
