<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="I2I Translation">
    <meta name="description" content="I2I Translation æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-07-03  Subjective Camera Bridging Human Cognition and Visual Reconstruction   through Sequence-Aware Sketch-Guided Diffusion">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>I2I Translation | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://picx.zhimg.com/v2-81188eccb11f963c31609e5b758aae9f.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">I2I Translation</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/I2I-Translation/">
                                <span class="chip bg-color">I2I Translation</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/I2I-Translation/" class="post-category">
                                I2I Translation
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-07-03
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-07-09
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    7.7k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    31 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-07-03-æ›´æ–°"><a href="#2025-07-03-æ›´æ–°" class="headerlink" title="2025-07-03 æ›´æ–°"></a>2025-07-03 æ›´æ–°</h1><h2 id="Subjective-Camera-Bridging-Human-Cognition-and-Visual-Reconstruction-through-Sequence-Aware-Sketch-Guided-Diffusion"><a href="#Subjective-Camera-Bridging-Human-Cognition-and-Visual-Reconstruction-through-Sequence-Aware-Sketch-Guided-Diffusion" class="headerlink" title="Subjective Camera: Bridging Human Cognition and Visual Reconstruction   through Sequence-Aware Sketch-Guided Diffusion"></a>Subjective Camera: Bridging Human Cognition and Visual Reconstruction   through Sequence-Aware Sketch-Guided Diffusion</h2><p><strong>Authors:Haoyang Chen, Dongfang Sun, Caoyuan Ma, Shiqin Wang, Kewei Zhang, Zheng Wang, Zhixiang Wang</strong></p>
<p>We propose Subjective Camera, a human-as-imaging-device paradigm that reconstructs real-world scenes from mental impressions through synergistic use of verbal descriptions and progressive rough sketches. This approach overcomes dual limitations of language ambiguity and sketch abstraction by treating the userâ€™s drawing sequence as priors, effectively translating subjective perceptual expectations into photorealistic images.   Existing approaches face three fundamental barriers: (1) user-specific subjective input biases, (2) huge modality gap between planar sketch and 3D priors in diffusion, and (3) sketch quality-sensitive performance degradation. Current solutions either demand resource-intensive model adaptation or impose impractical requirements on sketch precision.   Our framework addresses these challenges through concept-sequential generation. (1) We establish robust appearance priors through text-reward optimization, and then implement sequence-aware disentangled generation that processes concepts in sketching order; these steps accommodate user-specific subjective expectation in a train-free way. (2) We employ latent optimization that effectively bridges the modality gap between planar sketches and 3D priors in diffusion. (3) Our hierarchical reward-guided framework enables the use of rough sketches without demanding artistic expertise. Comprehensive evaluation across diverse datasets demonstrates that our approach achieves state-of-the-art performance in maintaining both semantic and spatial coherence. </p>
<blockquote>
<p>æˆ‘ä»¬æå‡ºäº†ä¸»è§‚ç›¸æœºï¼ˆSubjective Cameraï¼‰è¿™ä¸€æ¦‚å¿µï¼Œè¿™æ˜¯ä¸€ç§ä»¥äººä¸ºæˆåƒè®¾å¤‡èŒƒå¼ï¼Œé€šè¿‡ååŒä½¿ç”¨è¯­è¨€æè¿°å’Œæ¸è¿›å¼ç²—ç•¥è‰å›¾ï¼Œä»å¿ƒç†å°è±¡é‡å»ºçœŸå®åœºæ™¯ã€‚è¯¥æ–¹æ³•é€šè¿‡ç”¨æˆ·çš„ç»˜å›¾åºåˆ—ä½œä¸ºå…ˆéªŒï¼Œå…‹æœäº†è¯­è¨€æ¨¡ç³Šå’Œè‰å›¾æŠ½è±¡æ€§çš„åŒé‡å±€é™æ€§ï¼Œæœ‰æ•ˆåœ°å°†ä¸»è§‚æ„ŸçŸ¥æœŸæœ›è½¬åŒ–ä¸ºé€¼çœŸçš„å›¾åƒã€‚ç°æœ‰æ–¹æ³•é¢ä¸´ä¸‰å¤§åŸºæœ¬éšœç¢ï¼šï¼ˆ1ï¼‰ç”¨æˆ·ç‰¹å®šçš„ä¸»è§‚è¾“å…¥åè§ï¼Œï¼ˆ2ï¼‰å¹³é¢è‰å›¾ä¸æ‰©æ•£ä¸­ä¸‰ç»´å…ˆéªŒä¹‹é—´çš„å·¨å¤§æ¨¡æ€å·®è·ï¼Œï¼ˆ3ï¼‰è‰å›¾è´¨é‡æ•æ„Ÿçš„æ€§èƒ½ä¸‹é™ã€‚ç›®å‰çš„è§£å†³æ–¹æ¡ˆè¦ä¹ˆéœ€è¦å¤§é‡èµ„æºå¯¹æ¨¡å‹è¿›è¡Œé€‚é…ï¼Œè¦ä¹ˆå¯¹è‰å›¾çš„ç²¾ç¡®æ€§æå‡ºä¸åˆ‡å®é™…çš„è¦æ±‚ã€‚æˆ‘ä»¬çš„æ¡†æ¶é€šè¿‡æ¦‚å¿µåºåˆ—ç”Ÿæˆæ¥è§£å†³è¿™äº›æŒ‘æˆ˜ã€‚ï¼ˆ1ï¼‰æˆ‘ä»¬é€šè¿‡æ–‡æœ¬å¥–åŠ±ä¼˜åŒ–å»ºç«‹ç¨³å¥çš„å¤–è§‚å…ˆéªŒï¼Œç„¶åå®ç°åºåˆ—æ„ŸçŸ¥çš„åˆ†ç¦»ç”Ÿæˆï¼ŒæŒ‰è‰å›¾é¡ºåºå¤„ç†æ¦‚å¿µï¼›è¿™äº›æ­¥éª¤ä»¥æ— è®­ç»ƒçš„æ–¹å¼å®¹çº³ç”¨æˆ·ç‰¹å®šçš„ä¸»è§‚æœŸæœ›ã€‚ï¼ˆ2ï¼‰æˆ‘ä»¬é‡‡ç”¨æ½œåœ¨ä¼˜åŒ–ï¼Œæœ‰æ•ˆåœ°ç¼©å°äº†å¹³é¢è‰å›¾å’Œæ‰©æ•£ä¸­ä¸‰ç»´å…ˆéªŒä¹‹é—´çš„æ¨¡æ€å·®è·ã€‚ï¼ˆ3ï¼‰æˆ‘ä»¬çš„åˆ†å±‚å¥–åŠ±å¼•å¯¼æ¡†æ¶å…è®¸ä½¿ç”¨ç²—ç•¥è‰å›¾ï¼Œæ— éœ€è‰ºæœ¯ä¸“ä¸šçŸ¥è¯†ã€‚åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šçš„ç»¼åˆè¯„ä¼°è¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨ä¿æŒè¯­ä¹‰å’Œç©ºé—´è¿è´¯æ€§æ–¹é¢è¾¾åˆ°äº†æœ€æ–°æ€§èƒ½æ°´å¹³ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.23711v1">PDF</a> </p>
<p><strong>Summary</strong>ï¼š</p>
<p>æˆ‘ä»¬æå‡ºäº†ä¸»è§‚ç›¸æœºè¿™ä¸€äººç±»ä½œä¸ºæˆåƒè®¾å¤‡çš„æ–°èŒƒå¼ï¼Œå®ƒé€šè¿‡ååŒä½¿ç”¨è¨€è¯­æè¿°å’Œæ¸è¿›çš„ç²—ç•¥è‰å›¾ï¼Œä»å¿ƒç†å°è±¡é‡å»ºç°å®ä¸–ç•Œåœºæ™¯ã€‚è¿™ç§æ–¹æ³•å…‹æœäº†è¯­è¨€æ¨¡ç³Šå’Œè‰å›¾æŠ½è±¡æ€§çš„åŒé‡å±€é™æ€§ï¼Œé€šè¿‡å°†ç”¨æˆ·çš„ç»˜å›¾åºåˆ—è§†ä¸ºå…ˆéªŒä¿¡æ¯ï¼Œæœ‰æ•ˆåœ°å°†ä¸»è§‚æ„ŸçŸ¥æœŸæœ›è½¬åŒ–ä¸ºé€¼çœŸçš„å›¾åƒã€‚æˆ‘ä»¬çš„æ¡†æ¶é€šè¿‡æ¦‚å¿µåºåˆ—ç”Ÿæˆè§£å†³ç°æœ‰æŒ‘æˆ˜ï¼Œæ— éœ€ç‰¹å®šæ¨¡å‹é€‚åº”æˆ–é«˜è¦æ±‚çš„è‰å›¾ç²¾åº¦è¦æ±‚ï¼ŒåŒæ—¶å®ç°äº†æ–‡æœ¬å¥–åŠ±ä¼˜åŒ–ã€åºåˆ—æ„ŸçŸ¥åˆ†ç¦»ç”Ÿæˆä»¥åŠæ½œåœ¨ä¼˜åŒ–æŠ€æœ¯ã€‚å…¨é¢è¯„ä¼°è¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨ä¿æŒè¯­ä¹‰å’Œç©ºé—´è¿è´¯æ€§æ–¹é¢è¾¾åˆ°äº†æœ€æ–°æŠ€æœ¯æ°´å¹³ã€‚</p>
<p><strong>Key Takeaways</strong>:</p>
<ol>
<li>æå‡ºäº†Subjective Cameraæ–°èŒƒå¼ï¼Œå°†äººç±»è§†ä¸ºæˆåƒè®¾å¤‡ï¼Œç»“åˆè¨€è¯­æè¿°å’Œè‰å›¾é‡å»ºç°å®åœºæ™¯ã€‚</li>
<li>å…‹æœè¯­è¨€æ¨¡ç³Šå’Œè‰å›¾æŠ½è±¡æ€§çš„æŒ‘æˆ˜ï¼Œå°†ç”¨æˆ·ç»˜å›¾åºåˆ—ä½œä¸ºå…ˆéªŒä¿¡æ¯ï¼Œè½¬åŒ–ä¸ºçœŸå®å›¾åƒã€‚</li>
<li>ç°æœ‰æ–¹æ³•é¢ä¸´ç”¨æˆ·ä¸»è§‚è¾“å…¥åè§ã€è‰å›¾ä¸3Då…ˆéªŒé—´çš„æ¨¡æ€å·®è·ä»¥åŠè‰å›¾è´¨é‡æ•æ„Ÿçš„æ€§èƒ½ä¸‹é™ç­‰ä¸‰å¤§éš¾é¢˜ã€‚</li>
<li>é€šè¿‡æ¦‚å¿µåºåˆ—ç”Ÿæˆè§£å†³æŒ‘æˆ˜ï¼ŒåŒ…æ‹¬å»ºç«‹å¤–è§‚å…ˆéªŒã€åºåˆ—æ„ŸçŸ¥åˆ†ç¦»ç”Ÿæˆç­‰ã€‚</li>
<li>é‡‡ç”¨æ–‡æœ¬å¥–åŠ±ä¼˜åŒ–å’Œæ½œåœ¨ä¼˜åŒ–æŠ€æœ¯ï¼Œç¼©å°äº†è‰å›¾ä¸3Då…ˆéªŒä¹‹é—´çš„æ¨¡æ€å·®è·ã€‚</li>
<li>æ¡†æ¶å…è®¸ä½¿ç”¨ç²—ç•¥è‰å›¾ï¼Œæ— éœ€è‰ºæœ¯ä¸“ä¸šæŠ€èƒ½ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.23711">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-932ca9759a24a3d800c524f087069a63.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-2c80c8f5289d0fd3cc83fe324d101116.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-81188eccb11f963c31609e5b758aae9f.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="Towards-Markerless-Intraoperative-Tracking-of-Deformable-Spine-Tissue"><a href="#Towards-Markerless-Intraoperative-Tracking-of-Deformable-Spine-Tissue" class="headerlink" title="Towards Markerless Intraoperative Tracking of Deformable Spine Tissue"></a>Towards Markerless Intraoperative Tracking of Deformable Spine Tissue</h2><p><strong>Authors:Connor Daly, Elettra Marconi, Marco Riva, Jinendra Ekanayake, Daniel S. Elson, Ferdinando Rodriguez y Baena</strong></p>
<p>Consumer-grade RGB-D imaging for intraoperative orthopedic tissue tracking is a promising method with high translational potential. Unlike bone-mounted tracking devices, markerless tracking can reduce operating time and complexity. However, its use has been limited to cadaveric studies. This paper introduces the first real-world clinical RGB-D dataset for spine surgery and develops SpineAlign, a system for capturing deformation between preoperative and intraoperative spine states. We also present an intraoperative segmentation network trained on this data and introduce CorrespondNet, a multi-task framework for predicting key regions for registration in both intraoperative and preoperative scenes. </p>
<blockquote>
<p>æ¶ˆè´¹çº§RGB-Dæˆåƒç”¨äºæœ¯ä¸­éª¨ç§‘ç»„ç»‡è¿½è¸ªæ˜¯ä¸€ç§å…·æœ‰å¾ˆé«˜åº”ç”¨æ½œåŠ›ä¸”å‰æ™¯å…‰æ˜çš„æ–¹æ³•ã€‚ä¸éª¨å®‰è£…å¼è¿½è¸ªè®¾å¤‡ä¸åŒï¼Œæ— æ ‡è®°è¿½è¸ªå¯ä»¥å‡å°‘æ‰‹æœ¯æ—¶é—´å’Œå¤æ‚æ€§ã€‚ç„¶è€Œï¼Œå…¶åº”ç”¨ä»…é™äºå°¸ä½“ç ”ç©¶ã€‚æœ¬æ–‡ä»‹ç»äº†ç¬¬ä¸€ä¸ªç”¨äºè„ŠæŸ±æ‰‹æœ¯çš„å®æ—¶ä¸´åºŠRGB-Dæ•°æ®é›†ï¼Œå¹¶å¼€å‘äº†SpineAlignç³»ç»Ÿï¼Œç”¨äºæ•è·æœ¯å‰å’Œæœ¯ä¸­è„ŠæŸ±çŠ¶æ€ä¹‹é—´çš„å˜å½¢ã€‚æˆ‘ä»¬è¿˜å±•ç¤ºäº†åŸºäºæ­¤æ•°æ®çš„æœ¯ä¸­åˆ†å‰²ç½‘ç»œï¼Œå¹¶å¼•å…¥äº†CorrespondNetå¤šä»»åŠ¡æ¡†æ¶ï¼Œç”¨äºé¢„æµ‹æœ¯ä¸­æƒ…æ™¯å’Œæœ¯å‰æƒ…æ™¯ä¸­çš„å…³é”®åŒºåŸŸçš„æ³¨å†Œã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.23657v2">PDF</a> An improved version of this manuscript was accepted to MICCAI</p>
<p><strong>Summary</strong></p>
<p>æ¶ˆè´¹è€…çº§RGB-Dæˆåƒåœ¨æœ¯ä¸­éª¨ç§‘ç»„ç»‡è¿½è¸ªæ–¹é¢å±•ç°å‡ºå·¨å¤§æ½œåŠ›ï¼Œå…·æœ‰é«˜åº¦çš„ä¸´åºŠè½¬åŒ–æ½œåŠ›ã€‚æ— æ ‡è®°è¿½è¸ªæŠ€æœ¯ç›¸è¾ƒäºéª¨å¤´ä¸Šå®‰è£…çš„è¿½è¸ªè®¾å¤‡ï¼Œèƒ½å¤Ÿå‡å°‘æ‰‹æœ¯æ—¶é—´å’Œå¤æ‚æ€§ã€‚ç„¶è€Œï¼Œå…¶åº”ç”¨ä»…é™äºå°¸ä½“ç ”ç©¶ã€‚æœ¬æ–‡é¦–æ¬¡å¼•å…¥ç”¨äºè„ŠæŸ±å¤–ç§‘çš„çœŸå®ä¸–ç•Œä¸´åºŠRGB-Dæ•°æ®é›†ï¼Œå¹¶å¼€å‘äº†SpineAlignç³»ç»Ÿä»¥æ•è·æœ¯å‰å’Œæœ¯ä¸­è„Šæ¤çŠ¶æ€ä¹‹é—´çš„å˜å½¢æƒ…å†µã€‚æ­¤å¤–ï¼Œæœ¬æ–‡å±•ç¤ºäº†ä¸€ä¸ªåŸºäºè¯¥æ•°æ®è®­ç»ƒçš„æœ¯ä¸­åˆ†å‰²ç½‘ç»œï¼Œå¹¶å¼•å…¥äº†CorrespondNetå¤šä»»åŠ¡æ¡†æ¶ï¼Œç”¨äºé¢„æµ‹æœ¯ä¸­ä¸æœ¯å‰åœºæ™¯çš„æ³¨å†Œå…³é”®åŒºåŸŸã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>RGB-Dæˆåƒåœ¨æœ¯ä¸­éª¨ç§‘ç»„ç»‡è¿½è¸ªæ–¹é¢å…·æœ‰å·¨å¤§æ½œåŠ›ã€‚</li>
<li>æ— æ ‡è®°è¿½è¸ªæŠ€æœ¯ç›¸è¾ƒäºéª¨å¤´ä¸Šå®‰è£…çš„è¿½è¸ªè®¾å¤‡èƒ½å¤Ÿå‡å°‘æ‰‹æœ¯æ—¶é—´å’Œå¤æ‚æ€§ã€‚</li>
<li>RGB-Dæˆåƒçš„åº”ç”¨åœ¨çœŸå®ä¸–ç•Œä¸´åºŠç¯å¢ƒä¸­ä»å¤„äºåˆæ­¥é˜¶æ®µï¼Œä»…é™äºå°¸ä½“ç ”ç©¶ã€‚</li>
<li>é¦–æ¬¡å¼•å…¥ç”¨äºè„ŠæŸ±å¤–ç§‘çš„çœŸå®ä¸–ç•Œä¸´åºŠRGB-Dæ•°æ®é›†ã€‚</li>
<li>å¼€å‘äº†SpineAlignç³»ç»Ÿä»¥æ•æ‰æœ¯å‰å’Œæœ¯ä¸­è„Šæ¤çŠ¶æ€ä¹‹é—´çš„å˜å½¢æƒ…å†µã€‚</li>
<li>å±•ç¤ºäº†ä¸€ä¸ªåŸºäºçœŸå®ä¸–ç•Œä¸´åºŠæ•°æ®è®­ç»ƒçš„æœ¯ä¸­åˆ†å‰²ç½‘ç»œã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.23657">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-67f7fce721c53d3885edc9c65712530c.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-c0cf6ee806eb45b6b29f5c64be18a221.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-d47ca684fdee4c488f875bf7a843e93d.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="CycleVAR-Repurposing-Autoregressive-Model-for-Unsupervised-One-Step-Image-Translation"><a href="#CycleVAR-Repurposing-Autoregressive-Model-for-Unsupervised-One-Step-Image-Translation" class="headerlink" title="CycleVAR: Repurposing Autoregressive Model for Unsupervised One-Step   Image Translation"></a>CycleVAR: Repurposing Autoregressive Model for Unsupervised One-Step   Image Translation</h2><p><strong>Authors:Yi Liu, Shengqian Li, Zuzeng Lin, Feng Wang, Si Liu</strong></p>
<p>The current conditional autoregressive image generation methods have shown promising results, yet their potential remains largely unexplored in the practical unsupervised image translation domain, which operates without explicit cross-domain correspondences. A critical limitation stems from the discrete quantization inherent in traditional Vector Quantization-based frameworks, which disrupts gradient flow between the Variational Autoencoder decoder and causal Transformer, impeding end-to-end optimization during adversarial training in image space. To tackle this issue, we propose using Softmax Relaxed Quantization, a novel approach that reformulates codebook selection as a continuous probability mixing process via Softmax, thereby preserving gradient propagation. Building upon this differentiable foundation, we introduce CycleVAR, which reformulates image-to-image translation as image-conditional visual autoregressive generation by injecting multi-scale source image tokens as contextual prompts, analogous to prefix-based conditioning in language models. CycleVAR exploits two modes to generate the target image tokens, including (1) serial multi-step generation, enabling iterative refinement across scales, and (2) parallel one-step generation synthesizing all resolution outputs in a single forward pass. Experimental findings indicate that the parallel one-step generation mode attains superior translation quality with quicker inference speed than the serial multi-step mode in unsupervised scenarios. Furthermore, both quantitative and qualitative results indicate that CycleVAR surpasses previous state-of-the-art unsupervised image translation models, \textit{e}.\textit{g}., CycleGAN-Turbo. </p>
<blockquote>
<p>å½“å‰çš„æ¡ä»¶è‡ªå›å½’å›¾åƒç”Ÿæˆæ–¹æ³•å·²ç»æ˜¾ç¤ºå‡ºæœ‰å‰æ™¯çš„ç»“æœï¼Œä½†åœ¨å®é™…çš„æ— ç›‘ç£å›¾åƒç¿»è¯‘é¢†åŸŸï¼Œå…¶æ½œåŠ›åœ¨å¾ˆå¤§ç¨‹åº¦ä¸Šå°šæœªè¢«æ¢ç´¢ï¼Œè¿™ä¸€é¢†åŸŸçš„å·¥ä½œä¸éœ€è¦æ˜ç¡®çš„è·¨åŸŸå¯¹åº”ã€‚ä¸€ä¸ªå…³é”®çš„å±€é™æ€§æ¥è‡ªäºä¼ ç»ŸåŸºäºå‘é‡é‡åŒ–çš„æ¡†æ¶ä¸­çš„ç¦»æ•£é‡åŒ–ï¼Œå®ƒç ´åäº†å˜åˆ†è‡ªç¼–ç å™¨è§£ç å™¨å’Œå› æœå˜å‹å™¨ä¹‹é—´çš„æ¢¯åº¦æµï¼Œé˜»ç¢äº†å›¾åƒç©ºé—´å¯¹æŠ—è®­ç»ƒè¿‡ç¨‹ä¸­çš„ç«¯åˆ°ç«¯ä¼˜åŒ–ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†Softmaxæ¾å¼›é‡åŒ–æ–¹æ³•ï¼Œè¿™æ˜¯ä¸€ç§å°†ç æœ¬é€‰æ‹©é‡æ–°åˆ¶å®šä¸ºä¸€ä¸ªè¿ç»­çš„æ¦‚ç‡æ··åˆè¿‡ç¨‹çš„æ–°æ–¹æ³•ï¼Œé€šè¿‡Softmaxä¿ç•™æ¢¯åº¦ä¼ æ’­ã€‚åŸºäºè¿™ä¸ªå¯å¾®åˆ†çš„åŸºç¡€ï¼Œæˆ‘ä»¬å¼•å…¥äº†CycleVARï¼Œå®ƒå°†å›¾åƒåˆ°å›¾åƒçš„ç¿»è¯‘é‡æ–°å®šä¹‰ä¸ºå›¾åƒæ¡ä»¶è§†è§‰è‡ªå›å½’ç”Ÿæˆï¼Œé€šè¿‡æ³¨å…¥å¤šå°ºåº¦æºå›¾åƒæ ‡è®°ä½œä¸ºä¸Šä¸‹æ–‡æç¤ºï¼Œç±»ä¼¼äºè¯­è¨€æ¨¡å‹ä¸­çš„å‰ç¼€æ¡ä»¶ã€‚CycleVARåˆ©ç”¨ä¸¤ç§æ¨¡å¼æ¥ç”Ÿæˆç›®æ ‡å›¾åƒæ ‡è®°ï¼ŒåŒ…æ‹¬ï¼ˆ1ï¼‰ä¸²è¡Œå¤šæ­¥ç”Ÿæˆï¼Œå®ç°è·¨å°ºåº¦çš„è¿­ä»£ç»†åŒ–ï¼›ï¼ˆ2ï¼‰å¹¶è¡Œä¸€æ­¥ç”Ÿæˆï¼Œåœ¨ä¸€æ¬¡å‰å‘ä¼ é€’ä¸­åˆæˆæ‰€æœ‰åˆ†è¾¨ç‡çš„è¾“å‡ºã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œåœ¨æ— äººç›‘ç£çš„æƒ…å†µä¸‹ï¼Œå¹¶è¡Œä¸€æ­¥ç”Ÿæˆæ¨¡å¼å…·æœ‰æ›´é«˜çš„ç¿»è¯‘è´¨é‡å’Œæ›´å¿«çš„æ¨ç†é€Ÿåº¦ï¼Œä¼˜äºä¸²è¡Œå¤šæ­¥æ¨¡å¼ã€‚æ­¤å¤–ï¼Œå®šé‡å’Œå®šæ€§çš„ç»“æœéƒ½è¡¨æ˜ï¼ŒCycleVARè¶…è¶Šäº†ç°æœ‰çš„æœ€å…ˆè¿›çš„æ— ç›‘ç£å›¾åƒç¿»è¯‘æ¨¡å‹ï¼Œä¾‹å¦‚CycleGAN-Turboã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.23347v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>å½“å‰æ¡ä»¶è‡ªå›å½’å›¾åƒç”Ÿæˆæ–¹æ³•å·²æ˜¾ç¤ºå‡ºæœ‰å‰æ™¯çš„ç»“æœï¼Œä½†åœ¨æ— ç›‘ç£å›¾åƒç¿»è¯‘é¢†åŸŸçš„åº”ç”¨æ½œåŠ›å°šæœªå¾—åˆ°å……åˆ†æ¢ç´¢ã€‚é’ˆå¯¹ä¼ ç»ŸåŸºäºå‘é‡é‡åŒ–çš„æ¡†æ¶ä¸­å­˜åœ¨çš„ç¦»æ•£é‡åŒ–é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºä½¿ç”¨Softmax Relaxed Quantizationï¼Œå°†ç æœ¬é€‰æ‹©é‡æ„ä¸ºè¿ç»­çš„æ¦‚ç•¥æ··åˆè¿‡ç¨‹ï¼Œä»è€Œä¿ç•™æ¢¯åº¦ä¼ æ’­ã€‚åœ¨æ­¤åŸºç¡€ä¸Šï¼Œæˆ‘ä»¬å¼•å…¥CycleVARï¼Œå°†å›¾åƒåˆ°å›¾åƒçš„ç¿»è¯‘é‡æ„ä¸ºå›¾åƒæ¡ä»¶è§†è§‰è‡ªå›å½’ç”Ÿæˆï¼Œé€šè¿‡æ³¨å…¥å¤šå°ºåº¦æºå›¾åƒä»¤ç‰Œä½œä¸ºä¸Šä¸‹æ–‡æç¤ºã€‚å®éªŒè¡¨æ˜ï¼Œåœ¨æ— äººç›‘ç£çš„åœºæ™¯ä¸‹ï¼Œå¹¶è¡Œä¸€æ­¥ç”Ÿæˆæ¨¡å¼åœ¨ç¿»è¯‘è´¨é‡å’Œæ¨ç†é€Ÿåº¦ä¸Šä¼˜äºä¸²è¡Œå¤šæ­¥ç”Ÿæˆæ¨¡å¼ã€‚æ­¤å¤–ï¼ŒCycleVARåœ¨å®šé‡å’Œå®šæ€§ç»“æœä¸Šéƒ½è¶…è¶Šäº†ä¹‹å‰çš„æ— ç›‘ç£å›¾åƒç¿»è¯‘æ¨¡å‹ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æ¡ä»¶è‡ªå›å½’å›¾åƒç”Ÿæˆæ–¹æ³•åœ¨æ— ç›‘ç£å›¾åƒç¿»è¯‘é¢†åŸŸåº”ç”¨æ½œåŠ›å·¨å¤§ã€‚</li>
<li>ä¼ ç»ŸåŸºäºå‘é‡é‡åŒ–çš„æ¡†æ¶å­˜åœ¨ç¦»æ•£é‡åŒ–é—®é¢˜ï¼Œå½±å“æ¢¯åº¦æµå’Œç«¯åˆ°ç«¯ä¼˜åŒ–ã€‚</li>
<li>Softmax Relaxed Quantizationæ–¹æ³•å°†ç æœ¬é€‰æ‹©é‡æ„ä¸ºè¿ç»­çš„æ¦‚ç•¥æ··åˆè¿‡ç¨‹ã€‚</li>
<li>CycleVARå°†å›¾åƒåˆ°å›¾åƒçš„ç¿»è¯‘é‡æ„ä¸ºå›¾åƒæ¡ä»¶è§†è§‰è‡ªå›å½’ç”Ÿæˆã€‚</li>
<li>CycleVARåˆ©ç”¨å¤šå°ºåº¦æºå›¾åƒä»¤ç‰Œä½œä¸ºä¸Šä¸‹æ–‡æç¤ºï¼Œå¼•å…¥ä¸¤ç§ç”Ÿæˆæ¨¡å¼ã€‚</li>
<li>å¹¶è¡Œä¸€æ­¥ç”Ÿæˆæ¨¡å¼åœ¨æ— äººç›‘ç£çš„åœºæ™¯ä¸‹è¡¨ç°ä¼˜è¶Šï¼Œç¿»è¯‘è´¨é‡å’Œæ¨ç†é€Ÿåº¦æ›´ä½³ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.23347">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-75dacf7738d1fd1cc56b5439d0ce5391.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-2fc32e83fee4908553aab59432cffafd.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-9f02173296733cda3a97d680413dae74.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="Score-based-Diffusion-Model-for-Unpaired-Virtual-Histology-Staining"><a href="#Score-based-Diffusion-Model-for-Unpaired-Virtual-Histology-Staining" class="headerlink" title="Score-based Diffusion Model for Unpaired Virtual Histology Staining"></a>Score-based Diffusion Model for Unpaired Virtual Histology Staining</h2><p><strong>Authors:Anran Liu, Xiaofei Wang, Jing Cai, Chao Li</strong></p>
<p>Hematoxylin and eosin (H&amp;E) staining visualizes histology but lacks specificity for diagnostic markers. Immunohistochemistry (IHC) staining provides protein-targeted staining but is restricted by tissue availability and antibody specificity. Virtual staining, i.e., computationally translating the H&amp;E image to its IHC counterpart while preserving the tissue structure, is promising for efficient IHC generation. Existing virtual staining methods still face key challenges: 1) effective decomposition of staining style and tissue structure, 2) controllable staining process adaptable to diverse tissue and proteins, and 3) rigorous structural consistency modelling to handle the non-pixel-aligned nature of paired H&amp;E and IHC images. This study proposes a mutual-information (MI)-guided score-based diffusion model for unpaired virtual staining. Specifically, we design 1) a global MI-guided energy function that disentangles the tissue structure and staining characteristics across modalities, 2) a novel timestep-customized reverse diffusion process for precise control of the staining intensity and structural reconstruction, and 3) a local MI-driven contrastive learning strategy to ensure the cellular level structural consistency between H&amp;E-IHC images. Extensive experiments demonstrate the our superiority over state-of-the-art approaches, highlighting its biomedical potential. Codes will be open-sourced upon acceptance. </p>
<blockquote>
<p>è‹æœ¨ç²¾å’Œä¼Šçº¢ï¼ˆHï¼†Eï¼‰æŸ“è‰²èƒ½å¯è§†åŒ–ç»„ç»‡å½¢æ€å­¦ï¼Œä½†ç¼ºä¹ç‰¹å¼‚æ€§è¯Šæ–­æ ‡å¿—ç‰©ã€‚å…ç–«ç»„ç»‡åŒ–å­¦ï¼ˆIHCï¼‰æŸ“è‰²æä¾›é’ˆå¯¹è›‹ç™½è´¨çš„æŸ“è‰²ï¼Œä½†å—åˆ°ç»„ç»‡å¯ç”¨æ€§å’ŒæŠ—ä½“ç‰¹å¼‚æ€§çš„é™åˆ¶ã€‚è™šæ‹ŸæŸ“è‰²å³é€šè¿‡è®¡ç®—å°†Hï¼†Eå›¾åƒç¿»è¯‘æˆå…¶IHCå¯¹åº”ç‰©ï¼ŒåŒæ—¶ä¿ç•™ç»„ç»‡ç»“æ„ï¼Œå¯¹äºé«˜æ•ˆç”ŸæˆIHCéå¸¸æœ‰å‰æ™¯ã€‚ç°æœ‰çš„è™šæ‹ŸæŸ“è‰²æ–¹æ³•ä»é¢ä¸´å…³é”®æŒ‘æˆ˜ï¼š1ï¼‰æœ‰æ•ˆåˆ†è§£æŸ“è‰²é£æ ¼å’Œç»„ç»‡ç»“æ„ï¼›2ï¼‰å¯æ§çš„æŸ“è‰²è¿‡ç¨‹ï¼Œé€‚åº”å„ç§ç»„ç»‡å’Œè›‹ç™½è´¨ï¼›3ï¼‰ä¸¥æ ¼çš„ç»“æ„ä¸€è‡´æ€§å»ºæ¨¡ï¼Œä»¥å¤„ç†æˆå¯¹çš„Hï¼†Eå’ŒIHCå›¾åƒçš„éåƒç´ å¯¹é½æ€§è´¨ã€‚æœ¬ç ”ç©¶æå‡ºäº†ä¸€ç§ç”¨äºéé…å¯¹è™šæ‹ŸæŸ“è‰²çš„åŸºäºäº’ä¿¡æ¯ï¼ˆMIï¼‰å¼•å¯¼å¾—åˆ†æ‰©æ•£æ¨¡å‹ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬è®¾è®¡äº†1ï¼‰ä¸€ç§å…¨å±€MIå¼•å¯¼çš„èƒ½é‡å‡½æ•°ï¼Œè¯¥å‡½æ•°å¯ä»¥è§£å¼€ä¸åŒæ¨¡å¼ä¸‹çš„ç»„ç»‡ç»“æ„å’ŒæŸ“è‰²ç‰¹æ€§ï¼›2ï¼‰ä¸€ç§æ–°å‹çš„å®šæ—¶åå‘æ‰©æ•£è¿‡ç¨‹ï¼Œå®ç°å¯¹æŸ“è‰²å¼ºåº¦çš„ç²¾ç¡®æ§åˆ¶å’Œç»“æ„é‡å»ºï¼›3ï¼‰ä¸€ç§å±€éƒ¨MIé©±åŠ¨çš„å¯¹æ¯”å­¦ä¹ ç­–ç•¥ï¼Œä»¥ç¡®ä¿Hï¼†E-IHCå›¾åƒåœ¨ç»†èƒæ°´å¹³ä¸Šçš„ç»“æ„ä¸€è‡´æ€§ã€‚å¤§é‡å®éªŒè¯æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•ä¼˜äºæœ€æ–°æ–¹æ³•ï¼Œçªæ˜¾äº†å…¶ç”Ÿç‰©åŒ»å­¦æ½œåŠ›ã€‚ä»£ç å°†åœ¨æ¥å—åå¼€æºã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.23184v1">PDF</a> 11 pages, 3 figures</p>
<p><strong>Summary</strong>ï¼š</p>
<p>è¯¥ç ”ç©¶æå‡ºä¸€ç§åŸºäºäº’ä¿¡æ¯æŒ‡å¯¼çš„åˆ†æ•°æ‰©æ•£æ¨¡å‹ç”¨äºéé…å¯¹çš„è™šæ‹ŸæŸ“è‰²æŠ€æœ¯ã€‚é€šè¿‡è®¾è®¡å…¨å±€äº’ä¿¡æ¯å¼•å¯¼çš„èƒ½é‡å‡½æ•°ï¼Œåˆ†ç¦»ä¸åŒæ¨¡æ€ä¸‹çš„ç»„ç»‡ç»“æ„å’ŒæŸ“è‰²ç‰¹å¾ï¼›é‡‡ç”¨æ—¶é—´æ­¥é•¿å®šåˆ¶çš„é€†å‘æ‰©æ•£è¿‡ç¨‹ï¼Œç²¾ç¡®æ§åˆ¶æŸ“è‰²å¼ºåº¦å’Œç»“æ„é‡å»ºï¼›ä½¿ç”¨å±€éƒ¨äº’ä¿¡æ¯é©±åŠ¨å¯¹æ¯”å­¦ä¹ ç­–ç•¥ï¼Œç¡®ä¿H&amp;Eä¸IHCå›¾åƒåœ¨ç»†èƒæ°´å¹³ä¸Šçš„ç»“æ„ä¸€è‡´æ€§ã€‚å®éªŒè¯æ˜è¯¥æ–¹æ³•ä¼˜äºç°æœ‰æŠ€æœ¯ï¼Œå±•ç°å…¶åœ¨ç”Ÿç‰©åŒ»å­¦é¢†åŸŸçš„æ½œåŠ›ã€‚ä»£ç æ¥å—åå°†å¼€æºã€‚</p>
<p><strong>Key Takeaways</strong>ï¼š</p>
<ol>
<li>è™šæ‹ŸæŸ“è‰²æŠ€æœ¯èƒ½å¤Ÿåœ¨è®¡ç®—ä¸Šå°†H&amp;Eå›¾åƒè½¬åŒ–ä¸ºIHCå›¾åƒï¼ŒåŒæ—¶ä¿ç•™ç»„ç»‡ç»“æ„ã€‚</li>
<li>ç°å­˜çš„è™šæ‹ŸæŸ“è‰²æ–¹æ³•é¢ä¸´æœ‰æ•ˆåˆ†è§£æŸ“è‰²é£æ ¼å’Œç»„ç»‡ç»“æ„ã€é€‚åº”å¤šç§ç»„ç»‡å’Œè›‹ç™½è´¨çš„å¯æ§æŸ“è‰²è¿‡ç¨‹ï¼Œä»¥åŠå¤„ç†H&amp;Eå’ŒIHCå›¾åƒéåƒç´ å¯¹é½çš„ä¸¥æ ¼ç»“æ„ä¸€è‡´æ€§å»ºæ¨¡ç­‰æŒ‘æˆ˜ã€‚</li>
<li>è¯¥ç ”ç©¶é€šè¿‡è®¾è®¡å…¨å±€äº’ä¿¡æ¯å¼•å¯¼çš„èƒ½é‡å‡½æ•°ï¼Œå®ç°äº†ä¸åŒæ¨¡æ€ä¸‹ç»„ç»‡ç»“æ„å’ŒæŸ“è‰²ç‰¹å¾çš„åˆ†ç¦»ã€‚</li>
<li>é‡‡ç”¨æ—¶é—´æ­¥é•¿å®šåˆ¶çš„é€†å‘æ‰©æ•£è¿‡ç¨‹ï¼Œå®ç°å¯¹æŸ“è‰²å¼ºåº¦çš„ç²¾ç¡®æ§åˆ¶ä»¥åŠç»“æ„é‡å»ºã€‚</li>
<li>é€šè¿‡å±€éƒ¨äº’ä¿¡æ¯é©±åŠ¨å¯¹æ¯”å­¦ä¹ ç­–ç•¥ï¼Œç¡®ä¿äº†H&amp;Eä¸IHCå›¾åƒåœ¨ç»†èƒæ°´å¹³ä¸Šçš„ç»“æ„ä¸€è‡´æ€§ã€‚</li>
<li>å®éªŒè¯æ˜è¯¥æ–¹æ³•ä¼˜äºç°æœ‰æŠ€æœ¯ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.23184">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-636acd990da94a71dfeea48bad693b37.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-9bcaebf07dda1301a4a44fbe9dea7076.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-6451f883323ab441278ee22c719ba7ea.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="MatChA-Cross-Algorithm-Matching-with-Feature-Augmentation"><a href="#MatChA-Cross-Algorithm-Matching-with-Feature-Augmentation" class="headerlink" title="MatChA: Cross-Algorithm Matching with Feature Augmentation"></a>MatChA: Cross-Algorithm Matching with Feature Augmentation</h2><p><strong>Authors:Paula CarbÃ³ Cubero, Alberto Jaenal GÃ¡lvez, AndrÃ© Mateus, JosÃ© AraÃºjo, Patric Jensfelt</strong></p>
<p>State-of-the-art methods fail to solve visual localization in scenarios where different devices use different sparse feature extraction algorithms to obtain keypoints and their corresponding descriptors. Translating feature descriptors is enough to enable matching. However, performance is drastically reduced in cross-feature detector cases, because current solutions assume common keypoints. This means that the same detector has to be used, which is rarely the case in practice when different descriptors are used. The low repeatability of keypoints, in addition to non-discriminatory and non-distinctive descriptors, make the identification of true correspondences extremely challenging. We present the first method tackling this problem, which performs feature descriptor augmentation targeting cross-detector feature matching, and then feature translation to a latent space. We show that our method significantly improves image matching and visual localization in the cross-feature scenario and evaluate the proposed method on several benchmarks. </p>
<blockquote>
<p>å½“å‰å…ˆè¿›æŠ€æœ¯çš„æ–¹æ³•æ— æ³•åœ¨å¤„ç†è§†è§‰å®šä½çš„åœºæ™¯ä¸­è§£å†³ä¸åŒè®¾å¤‡ä½¿ç”¨ä¸åŒçš„ç¨€ç–ç‰¹å¾æå–ç®—æ³•è·å–å…³é”®ç‚¹å’Œå…¶å¯¹åº”çš„æè¿°ç¬¦çš„é—®é¢˜ã€‚ç¿»è¯‘ç‰¹å¾æè¿°ç¬¦è¶³ä»¥å®ç°åŒ¹é…ã€‚ä½†åœ¨è·¨ç‰¹å¾æ£€æµ‹å™¨çš„æƒ…å†µä¸‹ï¼Œæ€§èƒ½ä¼šå¤§å¤§é™ä½ï¼Œå› ä¸ºå½“å‰è§£å†³æ–¹æ¡ˆå‡è®¾äº†å…±åŒçš„å…³é”®ç‚¹ã€‚è¿™æ„å‘³ç€å¿…é¡»ä½¿ç”¨ç›¸åŒçš„æ£€æµ‹å™¨ï¼Œä½†åœ¨å®è·µä¸­å½“ä½¿ç”¨ä¸åŒçš„æè¿°ç¬¦æ—¶ï¼Œè¿™ç§æƒ…å†µå¾ˆå°‘è§ã€‚å…³é”®ç‚¹çš„ä½é‡å¤æ€§ä»¥åŠéæ­§è§†æ€§å’Œéç‹¬ç‰¹æ€§æè¿°ç¬¦ï¼Œä½¿å¾—è¯†åˆ«çœŸæ­£çš„å¯¹åº”å…³ç³»æå…·æŒ‘æˆ˜æ€§ã€‚æˆ‘ä»¬æå‡ºäº†ç¬¬ä¸€ç§è§£å†³æ­¤é—®é¢˜çš„æ–¹æ³•ï¼Œè¯¥æ–¹æ³•é’ˆå¯¹è·¨æ£€æµ‹å™¨ç‰¹å¾åŒ¹é…è¿›è¡Œç‰¹å¾æè¿°ç¬¦å¢å¼ºï¼Œç„¶åå°†å…¶è½¬æ¢ä¸ºæ½œåœ¨ç©ºé—´ã€‚æˆ‘ä»¬è¯æ˜äº†è¯¥æ–¹æ³•åœ¨è·¨ç‰¹å¾åœºæ™¯ä¸­æ˜¾è‘—æé«˜äº†å›¾åƒåŒ¹é…å’Œè§†è§‰å®šä½çš„èƒ½åŠ›ï¼Œå¹¶åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸Šå¯¹æ‰€æå‡ºçš„æ–¹æ³•è¿›è¡Œäº†è¯„ä¼°ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.22336v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†ä¸åŒè®¾å¤‡ä½¿ç”¨ä¸åŒç¨€ç–ç‰¹å¾æå–ç®—æ³•è¿›è¡Œå…³é”®ç‚¹åŠå…¶å¯¹åº”æè¿°ç¬¦æå–æ—¶ï¼Œè§†è§‰å®šä½é¢ä¸´çš„æŒ‘æˆ˜ã€‚å½“å‰è§£å†³æ–¹æ¡ˆå‡è®¾å…±åŒå…³é”®ç‚¹ï¼Œä½†åœ¨è·¨ç‰¹å¾æ£€æµ‹å™¨æƒ…å†µä¸‹æ€§èƒ½å¤§å¹…é™ä½ã€‚ä¸ºæ­¤ï¼Œæœ¬æ–‡æå‡ºä¸€ç§è§£å†³æ­¤é—®é¢˜çš„æ–¹æ³•ï¼Œé€šè¿‡ç‰¹å¾æè¿°ç¬¦å¢å¼ºå’Œè·¨æ£€æµ‹å™¨ç‰¹å¾åŒ¹é…ï¼Œç„¶åå°†ç‰¹å¾ç¿»è¯‘åˆ°æ½œåœ¨ç©ºé—´ã€‚å®éªŒè¯æ˜ï¼Œè¯¥æ–¹æ³•åœ¨è·¨ç‰¹å¾åœºæ™¯ä¸­èƒ½æ˜¾è‘—æé«˜å›¾åƒåŒ¹é…å’Œè§†è§‰å®šä½æ•ˆæœã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ä¸åŒè®¾å¤‡ä½¿ç”¨ä¸åŒçš„ç¨€ç–ç‰¹å¾æå–ç®—æ³•æ—¶ï¼Œè§†è§‰å®šä½é¢ä¸´æŒ‘æˆ˜ã€‚</li>
<li>å½“å‰è§£å†³æ–¹æ¡ˆå‡è®¾å…±åŒå…³é”®ç‚¹ï¼Œå¯¼è‡´è·¨ç‰¹å¾æ£€æµ‹å™¨æƒ…å†µä¸‹æ€§èƒ½é™ä½ã€‚</li>
<li>ç‰¹å¾æè¿°ç¬¦çš„ç¿»è¯‘æ˜¯ä½¿åŒ¹é…æˆä¸ºå¯èƒ½çš„å…³é”®ã€‚</li>
<li>å…³é”®ç‚¹ä½é‡å¤ç‡ä»¥åŠæè¿°ç¬¦çš„éæ­§è§†æ€§å’Œéç‹¬ç‰¹æ€§ä½¿å¾—è¯†åˆ«çœŸæ­£çš„å¯¹åº”å…³ç³»æå…·æŒ‘æˆ˜æ€§ã€‚</li>
<li>æœ¬æ–‡æå‡ºä¸€ç§è§£å†³æ­¤é—®é¢˜çš„æ–¹æ³•ï¼Œé€šè¿‡ç‰¹å¾æè¿°ç¬¦å¢å¼ºå’ŒåŒ¹é…ï¼Œé’ˆå¯¹è·¨æ£€æµ‹å™¨è¿›è¡Œç‰¹å¾ç¿»è¯‘è‡³æ½œåœ¨ç©ºé—´ã€‚</li>
<li>è¯¥æ–¹æ³•åœ¨è·¨ç‰¹å¾åœºæ™¯ä¸­èƒ½æ˜¾è‘—æé«˜å›¾åƒåŒ¹é…å’Œè§†è§‰å®šä½æ•ˆæœã€‚</li>
<li>æœ¬æ–‡æ–¹æ³•åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•é›†ä¸Šè¿›è¡Œäº†è¯„ä¼°ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.22336">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-6f9ffa97727a9c930077974202df399d.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-ee9327c08e91c7a01e25d5f5a303b4e8.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-0ee1507eb437ba2d3346e5c9c88c3834.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="3D-Telepathy-Reconstructing-3D-Objects-from-EEG-Signals"><a href="#3D-Telepathy-Reconstructing-3D-Objects-from-EEG-Signals" class="headerlink" title="3D-Telepathy: Reconstructing 3D Objects from EEG Signals"></a>3D-Telepathy: Reconstructing 3D Objects from EEG Signals</h2><p><strong>Authors:Yuxiang Ge, Jionghao Cheng, Ruiquan Ge, Zhaojie Fang, Gangyong Jia, Xiang Wan, Nannan Li, Ahmed Elazab, Changmiao Wang</strong></p>
<p>Reconstructing 3D visual stimuli from Electroencephalography (EEG) data holds significant potential for applications in Brain-Computer Interfaces (BCIs) and aiding individuals with communication disorders. Traditionally, efforts have focused on converting brain activity into 2D images, neglecting the translation of EEG data into 3D objects. This limitation is noteworthy, as the human brain inherently processes three-dimensional spatial information regardless of whether observing 2D images or the real world. The neural activities captured by EEG contain rich spatial information that is inevitably lost when reconstructing only 2D images, thus limiting its practical applications in BCI. The transition from EEG data to 3D object reconstruction faces considerable obstacles. These include the presence of extensive noise within EEG signals and a scarcity of datasets that include both EEG and 3D information, which complicates the extraction process of 3D visual data. Addressing this challenging task, we propose an innovative EEG encoder architecture that integrates a dual self-attention mechanism. We use a hybrid training strategy to train the EEG Encoder, which includes cross-attention, contrastive learning, and self-supervised learning techniques. Additionally, by employing stable diffusion as a prior distribution and utilizing Variational Score Distillation to train a neural radiation field, we successfully generate 3D objects with similar content and structure from EEG data. </p>
<blockquote>
<p>ä»è„‘ç”µå›¾ï¼ˆEEGï¼‰æ•°æ®ä¸­é‡å»º3Dè§†è§‰åˆºæ¿€åœ¨è„‘æœºæ¥å£ï¼ˆBCIï¼‰åº”ç”¨ä¸­å…·æœ‰æ˜¾è‘—æ½œåŠ›ï¼Œå¹¶èƒ½å¸®åŠ©æœ‰äº¤æµéšœç¢çš„äººã€‚ä¼ ç»Ÿä¸Šï¼Œäººä»¬è‡´åŠ›äºå°†è„‘æ´»åŠ¨è½¬åŒ–ä¸ºäºŒç»´å›¾åƒï¼Œå´å¿½è§†äº†å°†è„‘ç”µå›¾æ•°æ®è½¬åŒ–ä¸ºä¸‰ç»´ç‰©ä½“çš„å¯èƒ½æ€§ã€‚è¿™ç§å±€é™æ€§å€¼å¾—æ³¨æ„ï¼Œå› ä¸ºæ— è®ºè§‚å¯ŸäºŒç»´å›¾åƒè¿˜æ˜¯çœŸå®ä¸–ç•Œï¼Œäººç±»å¤§è„‘éƒ½å†…åœ¨åœ°å¤„ç†ä¸‰ç»´ç©ºé—´ä¿¡æ¯ã€‚è„‘ç”µå›¾æ•æ‰åˆ°çš„ç¥ç»æ´»åŠ¨åŒ…å«ä¸°å¯Œçš„ç©ºé—´ä¿¡æ¯ï¼Œåœ¨ä»…é‡å»ºäºŒç»´å›¾åƒæ—¶ä¼šä¸å¯é¿å…åœ°ä¸¢å¤±ï¼Œä»è€Œé™åˆ¶äº†å…¶åœ¨è„‘æœºæ¥å£ä¸­çš„å®é™…åº”ç”¨ã€‚ä»è„‘ç”µå›¾æ•°æ®è¿‡æ¸¡åˆ°ä¸‰ç»´ç‰©ä½“é‡å»ºé¢ä¸´ç€ç›¸å½“å¤§çš„éšœç¢ã€‚å…¶ä¸­åŒ…æ‹¬è„‘ç”µå›¾ä¿¡å·ä¸­å­˜åœ¨å¤§é‡å™ªå£°ï¼Œä»¥åŠç¼ºä¹åŒæ—¶åŒ…å«è„‘ç”µå›¾å’Œä¸‰ç»´ä¿¡æ¯çš„æ•°æ®é›†ï¼Œè¿™ä½¿å¾—ä¸‰ç»´è§†è§‰æ•°æ®çš„æå–è¿‡ç¨‹å˜å¾—å¤æ‚ã€‚ä¸ºäº†åº”å¯¹è¿™ä¸€å…·æœ‰æŒ‘æˆ˜æ€§çš„ä»»åŠ¡ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åˆ›æ–°çš„è„‘ç”µå›¾ç¼–ç å™¨æ¶æ„ï¼Œè¯¥æ¶æ„ç»“åˆäº†åŒé‡è‡ªæ³¨æ„åŠ›æœºåˆ¶ã€‚æˆ‘ä»¬ä½¿ç”¨æ··åˆè®­ç»ƒç­–ç•¥æ¥è®­ç»ƒè„‘ç”µå›¾ç¼–ç å™¨ï¼ŒåŒ…æ‹¬äº¤å‰æ³¨æ„åŠ›ã€å¯¹æ¯”å­¦ä¹ å’Œè‡ªæˆ‘ç›‘ç£å­¦ä¹ æŠ€æœ¯ã€‚æ­¤å¤–ï¼Œé€šè¿‡é‡‡ç”¨ç¨³å®šæ‰©æ•£ä½œä¸ºå…ˆéªŒåˆ†å¸ƒï¼Œå¹¶åˆ©ç”¨å˜åˆ†åˆ†æ•°è’¸é¦è®­ç»ƒç¥ç»è¾å°„åœºï¼Œæˆ‘ä»¬æˆåŠŸåœ°ä»è„‘ç”µå›¾æ•°æ®ä¸­ç”Ÿæˆäº†å…·æœ‰ç›¸ä¼¼å†…å®¹å’Œç»“æ„çš„ä¸‰ç»´ç‰©ä½“ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.21843v1">PDF</a> </p>
<p><strong>Summary</strong>ï¼šåˆ©ç”¨è„‘ç”µå›¾ï¼ˆEEGï¼‰æ•°æ®é‡å»ºä¸‰ç»´è§†è§‰åˆºæ¿€åœ¨è„‘æœºæ¥å£ï¼ˆBCIï¼‰å’Œè¾…åŠ©æ²Ÿé€šéšœç¢ä¸ªä½“æ–¹é¢å…·æœ‰å·¨å¤§æ½œåŠ›ã€‚ä¼ ç»Ÿä¸Šï¼Œç ”ç©¶ä¸»è¦å…³æ³¨å°†è„‘æ´»åŠ¨è½¬åŒ–ä¸ºäºŒç»´å›¾åƒï¼Œä½†å°†EEGæ•°æ®ç¿»è¯‘ä¸ºä¸‰ç»´ç‰©ä½“çš„ç ”ç©¶å°šæœªå¾—åˆ°è¶³å¤Ÿé‡è§†ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§åˆ›æ–°çš„EEGç¼–ç å™¨æ¶æ„ï¼Œé‡‡ç”¨åŒé‡è‡ªæ³¨æ„åŠ›æœºåˆ¶ï¼Œé€šè¿‡æ··åˆè®­ç»ƒç­–ç•¥ï¼ŒæˆåŠŸä»EEGæ•°æ®ä¸­ç”Ÿæˆå…·æœ‰ç›¸ä¼¼å†…å®¹å’Œç»“æ„çš„ä¸‰ç»´ç‰©ä½“ã€‚</p>
<p><strong>Key Takeaways</strong>ï¼š</p>
<ol>
<li>EEGæ•°æ®é‡å»ºä¸‰ç»´è§†è§‰åˆºæ¿€åœ¨è„‘æœºæ¥å£åŠè¾…åŠ©æ²Ÿé€šéšœç¢é¢†åŸŸå…·æœ‰æ˜¾è‘—æ½œåŠ›ã€‚</li>
<li>ä¼ ç»Ÿæ–¹æ³•ä¸»è¦å°†è„‘æ´»åŠ¨è½¬åŒ–ä¸ºäºŒç»´å›¾åƒï¼Œå¿½è§†äº†ä»EEGæ•°æ®ç¿»è¯‘åˆ°ä¸‰ç»´ç‰©ä½“çš„ç ”ç©¶ã€‚</li>
<li>EEGä¿¡å·ä¸­åŒ…å«ä¸°å¯Œçš„ç©ºé—´ä¿¡æ¯ï¼Œåœ¨é‡å»ºè¿‡ç¨‹ä¸­ä¸å¯é¿å…åœ°ä¼šä¸¢å¤±éƒ¨åˆ†ä¿¡æ¯ã€‚</li>
<li>ä»EEGæ•°æ®åˆ°ä¸‰ç»´ç‰©ä½“é‡å»ºå­˜åœ¨æŒ‘æˆ˜ï¼ŒåŒ…æ‹¬EEGä¿¡å·ä¸­çš„å¤§é‡å™ªå£°å’Œç¼ºä¹åŒ…å«EEGå’Œä¸‰ç»´ä¿¡æ¯çš„æ•°æ®é›†ã€‚</li>
<li>åˆ›æ–°çš„EEGç¼–ç å™¨æ¶æ„ç»“åˆäº†åŒé‡è‡ªæ³¨æ„åŠ›æœºåˆ¶ï¼Œä¸ºåº”å¯¹è¿™äº›æŒ‘æˆ˜æä¾›äº†æ–°çš„æ–¹å‘ã€‚</li>
<li>ä½¿ç”¨æ··åˆè®­ç»ƒç­–ç•¥ï¼ŒåŒ…æ‹¬äº¤å‰æ³¨æ„åŠ›ã€å¯¹æ¯”å­¦ä¹ å’Œè‡ªç›‘ç£å­¦ä¹ æŠ€æœ¯æ¥è®­ç»ƒEEGç¼–ç å™¨ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.21843">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-b3ce0267bd6b8b78e2f48689f13f2839.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-3befbf42cf6722e3dce22b576ad640c4.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-761fa84734c47207cd4726fd883036c5.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-bed351bc97a56e5648a54710cb9c5617.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-bbe14b684a0ff1d40cecd71c37c2a2da.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="Score-based-Generative-Diffusion-Models-to-Synthesize-Full-dose-FDG-Brain-PET-from-MRI-in-Epilepsy-Patients"><a href="#Score-based-Generative-Diffusion-Models-to-Synthesize-Full-dose-FDG-Brain-PET-from-MRI-in-Epilepsy-Patients" class="headerlink" title="Score-based Generative Diffusion Models to Synthesize Full-dose FDG   Brain PET from MRI in Epilepsy Patients"></a>Score-based Generative Diffusion Models to Synthesize Full-dose FDG   Brain PET from MRI in Epilepsy Patients</h2><p><strong>Authors:Jiaqi Wu, Jiahong Ouyang, Farshad Moradi, Mohammad Mehdi Khalighi, Greg Zaharchuk</strong></p>
<p>Fluorodeoxyglucose (FDG) PET to evaluate patients with epilepsy is one of the most common applications for simultaneous PET&#x2F;MRI, given the need to image both brain structure and metabolism, but is suboptimal due to the radiation dose in this young population. Little work has been done synthesizing diagnostic quality PET images from MRI data or MRI data with ultralow-dose PET using advanced generative AI methods, such as diffusion models, with attention to clinical evaluations tailored for the epilepsy population. Here we compared the performance of diffusion- and non-diffusion-based deep learning models for the MRI-to-PET image translation task for epilepsy imaging using simultaneous PET&#x2F;MRI in 52 subjects (40 train&#x2F;2 validate&#x2F;10 hold-out test). We tested three different models: 2 score-based generative diffusion models (SGM-Karras Diffusion [SGM-KD] and SGM-variance preserving [SGM-VP]) and a Transformer-Unet. We report results on standard image processing metrics as well as clinically relevant metrics, including congruency measures (Congruence Index and Congruency Mean Absolute Error) that assess hemispheric metabolic asymmetry, which is a key part of the clinical analysis of these images. The SGM-KD produced the best qualitative and quantitative results when synthesizing PET purely from T1w and T2 FLAIR images with the least mean absolute error in whole-brain specific uptake value ratio (SUVR) and highest intraclass correlation coefficient. When 1% low-dose PET images are included in the inputs, all models improve significantly and are interchangeable for quantitative performance and visual quality. In summary, SGMs hold great potential for pure MRI-to-PET translation, while all 3 model types can synthesize full-dose FDG-PET accurately using MRI and ultralow-dose PET. </p>
<blockquote>
<p>ä½¿ç”¨æ°Ÿè„±æ°§è‘¡è„ç³–ï¼ˆFDGï¼‰PETè¯„ä¼°ç™«ç—«æ‚£è€…æ˜¯åŒæ—¶PET&#x2F;MRIæœ€å¸¸è§çš„åº”ç”¨ä¹‹ä¸€ï¼Œç”±äºéœ€è¦åŒæ—¶æ˜¾ç¤ºå¤§è„‘ç»“æ„å’Œä»£è°¢ã€‚ä½†æ˜¯ç”±äºå¹´è½»æ‚£è€…çš„è¾å°„å‰‚é‡é—®é¢˜ï¼Œå…¶æ•ˆæœå¹¶ä¸ç†æƒ³ã€‚ç›®å‰å¾ˆå°‘æœ‰å·¥ä½œä½¿ç”¨å…ˆè¿›çš„ç”Ÿæˆå¼äººå·¥æ™ºèƒ½æ–¹æ³•ï¼ˆå¦‚æ‰©æ•£æ¨¡å‹ï¼‰åˆæˆå…·æœ‰è¯Šæ–­è´¨é‡çš„PETå›¾åƒæˆ–MRIæ•°æ®ä¸è¶…ä½å‰‚é‡PETçš„MRIæ•°æ®ï¼Œå¹¶é’ˆå¯¹ç™«ç—«äººç¾¤è¿›è¡Œä¸´åºŠè¯„ä¼°ã€‚åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬æ¯”è¾ƒäº†åŸºäºæ‰©æ•£å’Œéæ‰©æ•£æ·±åº¦å­¦ä¹ æ¨¡å‹åœ¨MRIåˆ°PETå›¾åƒè½¬æ¢ä»»åŠ¡ä¸Šçš„è¡¨ç°ï¼Œä½¿ç”¨åŒæ—¶PET&#x2F;MRIå¯¹52åç™«ç—«æ‚£è€…ï¼ˆ40åè®­ç»ƒ&#x2F; 2åéªŒè¯&#x2F; 10åä¿ç•™æµ‹è¯•ï¼‰è¿›è¡Œæˆåƒã€‚æˆ‘ä»¬æµ‹è¯•äº†ä¸‰ç§ä¸åŒçš„æ¨¡å‹ï¼šä¸¤ç§åŸºäºåˆ†æ•°çš„ç”Ÿæˆæ‰©æ•£æ¨¡å‹ï¼ˆSGM-Karrasæ‰©æ•£[SGM-KD]å’ŒSGM-æ–¹å·®ä¿ç•™[SGM-VP]ï¼‰å’Œä¸€ä¸ªTransformer-Unetã€‚æˆ‘ä»¬æŠ¥å‘Šäº†æ ‡å‡†å›¾åƒå¤„ç†æŒ‡æ ‡çš„ç»“æœä»¥åŠä¸ä¸´åºŠç›¸å…³çš„æŒ‡æ ‡ï¼ŒåŒ…æ‹¬è¯„ä¼°åŠçƒä»£è°¢ä¸å¯¹ç§°æ€§çš„ç¬¦åˆåº¦æŒ‡æ ‡ï¼ˆç¬¦åˆåº¦æŒ‡æ•°å’Œç¬¦åˆåº¦å¹³å‡ç»å¯¹è¯¯å·®ï¼‰ã€‚ç¬¦åˆåº¦æŒ‡æ•°æ˜¯è¿™äº›å›¾åƒä¸´åºŠåˆ†æçš„å…³é”®éƒ¨åˆ†ã€‚SGM-KDåœ¨ä»…ä½¿ç”¨T1wå’ŒT2 FLAIRå›¾åƒåˆæˆPETæ—¶äº§ç”Ÿäº†æœ€ä½³çš„ä¸»è§‚å’Œå®¢è§‚ç»“æœï¼Œå…·æœ‰æœ€ä½çš„å…¨è„‘ç‰¹å¼‚æ€§æ‘„å–å€¼æ¯”ç‡ï¼ˆSUVRï¼‰å¹³å‡ç»å¯¹è¯¯å·®å’Œæœ€é«˜çš„ç»„å†…ç›¸å…³ç³»æ•°ã€‚å½“åŒ…å«1%ä½å‰‚é‡PETå›¾åƒæ—¶ï¼Œæ‰€æœ‰æ¨¡å‹çš„å®šé‡æ€§èƒ½å’Œè§†è§‰è´¨é‡å‡å¾—åˆ°æ˜¾ç€æé«˜å¹¶ä¸”å¯ä»¥äº’æ¢ä½¿ç”¨ã€‚æ€»ä¹‹ï¼ŒSGMåœ¨çº¯MRIåˆ°PETç¿»è¯‘æ–¹é¢æ˜¾ç¤ºå‡ºå·¨å¤§æ½œåŠ›ï¼Œè€Œæ‰€æœ‰ä¸‰ç§ç±»å‹çš„æ¨¡å‹éƒ½å¯ä»¥ä½¿ç”¨MRIå’Œè¶…ä½å‰‚é‡PETå‡†ç¡®åˆæˆå…¨å‰‚é‡FDG-PETå›¾åƒã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.11297v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æ¢è®¨äº†åˆ©ç”¨æ·±åº¦å­¦ä¹ æ¨¡å‹åœ¨MRIå›¾åƒåŸºç¡€ä¸ŠåˆæˆPETå›¾åƒçš„æ–¹æ³•ï¼Œå¯¹æ¯”äº†æ‰©æ•£æ¨¡å‹ä¸éæ‰©æ•£æ¨¡å‹åœ¨ç™«ç—«ç—…äººæˆåƒä¸­çš„è¡¨ç°ã€‚ç ”ç©¶å‘ç°ï¼ŒåŸºäºæ‰©æ•£æ¨¡å‹çš„SGM-KDåœ¨çº¯MRIå›¾åƒä¸Šè¡¨ç°æœ€ä½³ï¼Œè€Œæ‰€æœ‰æ¨¡å‹åœ¨ç»“åˆè¶…ä½å‰‚é‡PETæ—¶éƒ½èƒ½å‡†ç¡®åˆæˆå…¨å‰‚é‡FDG-PETå›¾åƒã€‚</p>
<p><strong>Key Takeaways</strong></p>
<p>1.æ°Ÿä»£è„±æ°§è‘¡è„ç³–ï¼ˆFDGï¼‰PETç”¨äºè¯„ä¼°ç™«ç—«æ‚£è€…çš„åº”ç”¨æ˜¯æœ€å¸¸è§çš„PET&#x2F;MRIåŒæ—¶åº”ç”¨ä¹‹ä¸€ï¼Œä½†éœ€è¦åŒæ—¶æˆåƒå¤§è„‘ç»“æ„å’Œä»£è°¢ã€‚<br>2.ç”±äºå¹´è½»äººå£çš„è¾å°„å‰‚é‡é—®é¢˜ï¼Œå½“å‰çš„åº”ç”¨è¢«è®¤ä¸ºæ˜¯ä¸ç†æƒ³çš„ã€‚<br>3.æœ¬ç ”ç©¶ä½¿ç”¨æ·±åº¦å­¦ä¹ æ¨¡å‹ï¼ŒåŒ…æ‹¬æ‰©æ•£æ¨¡å‹ï¼Œå¯¹MRIåˆ°PETçš„å›¾åƒè½¬æ¢ä»»åŠ¡è¿›è¡Œäº†æ¯”è¾ƒã€‚<br>4.åœ¨ç™«ç—«æˆåƒæ–¹é¢ï¼Œç ”ç©¶å¯¹ä¸‰ç§æ¨¡å‹è¿›è¡Œäº†æµ‹è¯•ï¼šåŸºäºæ‰©æ•£çš„SGM-KDå’ŒSGM-VPæ¨¡å‹ä»¥åŠTransformer-Unetæ¨¡å‹ã€‚<br>5.SGM-KDæ¨¡å‹åœ¨çº¯MRIå›¾åƒä¸Šè¡¨ç°å‡ºæœ€ä½³çš„å®šæ€§å’Œå®šé‡ç»“æœï¼Œå…·æœ‰æœ€å°çš„å…¨è„‘ç‰¹å®šæ‘„å–å€¼æ¯”ç‡ï¼ˆSUVRï¼‰å¹³å‡ç»å¯¹è¯¯å·®å’Œæœ€é«˜çš„ç»„å†…ç›¸å…³ç³»æ•°ã€‚<br>6.å½“åŠ å…¥è¶…ä½å‰‚é‡PETå›¾åƒæ—¶ï¼Œæ‰€æœ‰æ¨¡å‹çš„è¡¨ç°éƒ½å¾—åˆ°äº†æ˜¾è‘—æé«˜ï¼Œå¹¶ä¸”åœ¨å®šé‡æ€§èƒ½å’Œè§†è§‰è´¨é‡æ–¹é¢å˜å¾—å¯äº’æ¢ã€‚</p>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.11297">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-eaf7094ff06c73fad53595e19dbc7273.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ac385a6974423ebb1624f29d8cd0913f.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-fd6fafd44448ae724af6eddad5cf165a.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="A-Wavelet-Diffusion-GAN-for-Image-Super-Resolution"><a href="#A-Wavelet-Diffusion-GAN-for-Image-Super-Resolution" class="headerlink" title="A Wavelet Diffusion GAN for Image Super-Resolution"></a>A Wavelet Diffusion GAN for Image Super-Resolution</h2><p><strong>Authors:Lorenzo Aloisi, Luigi Sigillo, Aurelio Uncini, Danilo Comminiello</strong></p>
<p>In recent years, diffusion models have emerged as a superior alternative to generative adversarial networks (GANs) for high-fidelity image generation, with wide applications in text-to-image generation, image-to-image translation, and super-resolution. However, their real-time feasibility is hindered by slow training and inference speeds. This study addresses this challenge by proposing a wavelet-based conditional Diffusion GAN scheme for Single-Image Super-Resolution (SISR). Our approach utilizes the diffusion GAN paradigm to reduce the timesteps required by the reverse diffusion process and the Discrete Wavelet Transform (DWT) to achieve dimensionality reduction, decreasing training and inference times significantly. The results of an experimental validation on the CelebA-HQ dataset confirm the effectiveness of our proposed scheme. Our approach outperforms other state-of-the-art methodologies successfully ensuring high-fidelity output while overcoming inherent drawbacks associated with diffusion models in time-sensitive applications. </p>
<blockquote>
<p>è¿‘å¹´æ¥ï¼Œæ‰©æ•£æ¨¡å‹å·²ç»ä½œä¸ºç”Ÿæˆå¯¹æŠ—ç½‘ç»œï¼ˆGANsï¼‰çš„ä¼˜è´¨æ›¿ä»£æ–¹æ¡ˆï¼Œåœ¨é«˜ä¿çœŸå›¾åƒç”Ÿæˆæ–¹é¢å±•ç°å‡ºä¼˜åŠ¿ï¼Œå¹¿æ³›åº”ç”¨äºæ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆã€å›¾åƒåˆ°å›¾åƒè½¬æ¢å’Œè¶…åˆ†è¾¨ç‡å¤„ç†ã€‚ç„¶è€Œï¼Œç”±äºå…¶è®­ç»ƒå’Œæ¨ç†é€Ÿåº¦æ…¢ï¼Œå®æ—¶æ€§èƒ½å—é™ã€‚æœ¬ç ”ç©¶é’ˆå¯¹è¿™ä¸€æŒ‘æˆ˜ï¼Œæå‡ºä¸€ç§åŸºäºå°æ³¢æ¡ä»¶çš„æ‰©æ•£GANæ–¹æ¡ˆï¼Œç”¨äºå•å›¾åƒè¶…åˆ†è¾¨ç‡ï¼ˆSISRï¼‰ã€‚æˆ‘ä»¬çš„æ–¹æ³•åˆ©ç”¨æ‰©æ•£GANèŒƒå¼å‡å°‘åå‘æ‰©æ•£è¿‡ç¨‹æ‰€éœ€çš„æ—¶é—´æ­¥é•¿ï¼Œå¹¶åˆ©ç”¨ç¦»æ•£å°æ³¢å˜æ¢ï¼ˆDWTï¼‰å®ç°é™ç»´ï¼Œä»è€Œæ˜¾è‘—ç¼©çŸ­è®­ç»ƒå’Œæ¨ç†æ—¶é—´ã€‚åœ¨CelebA-HQæ•°æ®é›†ä¸Šçš„å®éªŒéªŒè¯ç»“æœè¯å®äº†æˆ‘ä»¬æ–¹æ¡ˆçš„æœ‰æ•ˆæ€§ã€‚æˆ‘ä»¬çš„æ–¹æ³•æˆåŠŸè¶…è¶Šäº†å…¶ä»–æœ€å…ˆè¿›çš„æ–¹æ³•ï¼Œæ—¢ä¿è¯äº†é«˜ä¿çœŸè¾“å‡ºï¼Œåˆå…‹æœäº†æ‰©æ•£æ¨¡å‹åœ¨æ—¶é—´æ•æ„Ÿåº”ç”¨ä¸­çš„å›ºæœ‰ç¼ºé™·ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2410.17966v2">PDF</a> The paper has been accepted at Italian Workshop on Neural Networks   (WIRN) 2024</p>
<p><strong>Summary</strong></p>
<p>è¿‘å¹´æ¥ï¼Œæ‰©æ•£æ¨¡å‹å·²é€æ¸å–ä»£ç”Ÿæˆå¯¹æŠ—ç½‘ç»œï¼ˆGANsï¼‰ï¼Œæˆä¸ºé«˜ä¿çœŸå›¾åƒç”Ÿæˆçš„é¦–é€‰æ–¹æ³•ï¼Œå¹¿æ³›åº”ç”¨äºæ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆã€å›¾åƒåˆ°å›¾åƒè½¬æ¢ä»¥åŠè¶…åˆ†è¾¨ç‡ç­‰é¢†åŸŸã€‚ç„¶è€Œï¼Œå…¶å®æ—¶å¯è¡Œæ€§å—åˆ°è®­ç»ƒé€Ÿåº¦æ…¢å’Œæ¨ç†é€Ÿåº¦æ…¢çš„é˜»ç¢ã€‚æœ¬ç ”ç©¶é€šè¿‡æå‡ºä¸€ç§åŸºäºå°æ³¢çš„æ¡ä»¶æ‰©æ•£GANæ–¹æ¡ˆæ¥è§£å†³è¿™ä¸€æŒ‘æˆ˜ï¼Œç”¨äºå•å›¾åƒè¶…åˆ†è¾¨ç‡ï¼ˆSISRï¼‰ã€‚æˆ‘ä»¬çš„æ–¹æ³•åˆ©ç”¨æ‰©æ•£GANèŒƒå¼å‡å°‘äº†åå‘æ‰©æ•£è¿‡ç¨‹æ‰€éœ€çš„æ—¶é—´æ­¥é•¿ï¼Œå¹¶åˆ©ç”¨ç¦»æ•£å°æ³¢å˜æ¢ï¼ˆDWTï¼‰å®ç°é™ç»´ï¼Œä»è€Œæ˜¾è‘—å‡å°‘è®­ç»ƒå’Œæ¨ç†æ—¶é—´ã€‚åœ¨CelebA-HQæ•°æ®é›†ä¸Šçš„å®éªŒéªŒè¯ç»“æœè¡¨æ˜äº†æœ¬æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚æœ¬æ–¹æ³•æˆåŠŸè¶…è¶Šäº†å…¶ä»–å…ˆè¿›çš„æ–¹æ³•è®ºï¼Œç¡®ä¿äº†é«˜ä¿çœŸè¾“å‡ºï¼Œå¹¶å…‹æœäº†æ‰©æ•£æ¨¡å‹åœ¨æ—¶é—´æ•æ„Ÿåº”ç”¨ä¸­çš„å›ºæœ‰ç¼ºé™·ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æ‰©æ•£æ¨¡å‹å·²æˆä¸ºé«˜ä¿çœŸå›¾åƒç”Ÿæˆçš„ä¸»æµæ–¹æ³•ï¼Œæ›¿ä»£äº†ç”Ÿæˆå¯¹æŠ—ç½‘ç»œï¼ˆGANsï¼‰ã€‚</li>
<li>æ‰©æ•£æ¨¡å‹åœ¨å®æ—¶åº”ç”¨ä¸­é¢ä¸´è®­ç»ƒå’Œæ¨ç†é€Ÿåº¦æ…¢çš„éš¾é¢˜ã€‚</li>
<li>æœ¬ç ”ç©¶æå‡ºä¸€ç§åŸºäºå°æ³¢çš„æ¡ä»¶æ‰©æ•£GANæ–¹æ¡ˆï¼Œæ—¨åœ¨è§£å†³æ‰©æ•£æ¨¡å‹åœ¨å®æ—¶åº”ç”¨ä¸­çš„ç“¶é¢ˆã€‚</li>
<li>æ–¹æ³•åˆ©ç”¨æ‰©æ•£GANèŒƒå¼å‡å°‘æ—¶é—´æ­¥é•¿ï¼Œå¹¶åˆ©ç”¨ç¦»æ•£å°æ³¢å˜æ¢ï¼ˆDWTï¼‰å®ç°é™ç»´ã€‚</li>
<li>å®éªŒåœ¨CelebA-HQæ•°æ®é›†ä¸Šè¿›è¡Œï¼Œè¯æ˜äº†è¯¥æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚</li>
<li>è¯¥æ–¹æ³•æˆåŠŸè¶…è¶Šäº†å…¶ä»–å…ˆè¿›çš„æ–¹æ³•ï¼Œä¿è¯äº†é«˜ä¿çœŸè¾“å‡ºã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2410.17966">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-f8c61ed71f06e8e110baf528da95acf8.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b7987eb632319509c4054fc4bf32519b.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-407a35b38a6f7e683a27c6fc037fc2c2.jpg" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-07-03/I2I%20Translation/">https://kedreamix.github.io/Talk2Paper/Paper/2025-07-03/I2I%20Translation/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/I2I-Translation/">
                                    <span class="chip bg-color">I2I Translation</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-07-03/%E8%A7%86%E9%A2%91%E7%90%86%E8%A7%A3/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-3031c37fcfad37945b20e4cbd021760e.jpg" class="responsive-img" alt="è§†é¢‘ç†è§£">
                        
                        <span class="card-title">è§†é¢‘ç†è§£</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            è§†é¢‘ç†è§£ æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-07-03  Flash-VStream Efficient Real-Time Understanding for Long Video Streams
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-07-03
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/%E8%A7%86%E9%A2%91%E7%90%86%E8%A7%A3/" class="post-category">
                                    è§†é¢‘ç†è§£
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/%E8%A7%86%E9%A2%91%E7%90%86%E8%A7%A3/">
                        <span class="chip bg-color">è§†é¢‘ç†è§£</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-07-03/Few-Shot/">
                    <div class="card-image">
                        
                        <img src="https://pic1.zhimg.com/v2-16540274011f2d1c616a2978dc5fcede.jpg" class="responsive-img" alt="Few-Shot">
                        
                        <span class="card-title">Few-Shot</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Few-Shot æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-07-03  STACK Adversarial Attacks on LLM Safeguard Pipelines
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-07-03
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Few-Shot/" class="post-category">
                                    Few-Shot
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Few-Shot/">
                        <span class="chip bg-color">Few-Shot</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">27348.8k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
