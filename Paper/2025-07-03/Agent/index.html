<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Agent">
    <meta name="description" content="Agent æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-07-03  Agent.xpu Efficient Scheduling of Agentic LLM Workloads on   Heterogeneous SoC">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>Agent | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://picx.zhimg.com/v2-e906d407c81f51945c0316d5fc30ddd0.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Agent</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/Agent/">
                                <span class="chip bg-color">Agent</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/Agent/" class="post-category">
                                Agent
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-07-03
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-07-09
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    14k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    56 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-07-03-æ›´æ–°"><a href="#2025-07-03-æ›´æ–°" class="headerlink" title="2025-07-03 æ›´æ–°"></a>2025-07-03 æ›´æ–°</h1><h2 id="Agent-xpu-Efficient-Scheduling-of-Agentic-LLM-Workloads-on-Heterogeneous-SoC"><a href="#Agent-xpu-Efficient-Scheduling-of-Agentic-LLM-Workloads-on-Heterogeneous-SoC" class="headerlink" title="Agent.xpu: Efficient Scheduling of Agentic LLM Workloads on   Heterogeneous SoC"></a>Agent.xpu: Efficient Scheduling of Agentic LLM Workloads on   Heterogeneous SoC</h2><p><strong>Authors:Xinming Wei, Jiahao Zhang, Haoran Li, Jiayu Chen, Rui Qu, Maoliang Li, Xiang Chen, Guojie Luo</strong></p>
<p>The proliferation of agentic Large Language Models (LLMs) on personal devices introduces a new class of workloads characterized by a dichotomy of objectives. Reactive tasks, initiated by users, demand immediate, low-latency responses, while proactive tasks operate invisibly and prioritize throughput. Existing on-device LLM engines, designed for isolated inferences, fail to efficiently manage these concurrent and conflicting requests on consumer-grade heterogeneous SoCs with CPU, integrated GPU, and NPU. This paper introduces Agent.xpu, an efficient serving system for agentic LLM workloads on memory-unified heterogeneous SoCs. With dedicated offline profiling, Agent.xpu first constructs a heterogeneous execution graph, which fuses and chunks model kernels for affinity-guided, elastic accelerator mapping with predictive kernel annotation. At runtime, its online scheduler enables fine-grained, kernel-level preemption to guarantee the responsiveness of reactive tasks. To maximize SoC utilization, it adopts slack-aware kernel backfill to opportunistically append proactive tasks, and mitigates NPU-iGPU contention via bandwidth-aware dispatch. Evaluation on an Intel Core Ultra SoC shows that Agent.xpu achieves 4.6$\times$ lower latency for reactive tasks and sustains 1.6$\times$-6.8$\times$ higher throughput for proactive tasks compared to state-of-the-art inference engines. </p>
<blockquote>
<p>ä¸ªäººè®¾å¤‡ä¸Šä»£ç†å‹å¤§è§„æ¨¡è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„æ¿€å¢å¼•å‘äº†ä¸€ç§æ–°çš„å·¥ä½œè´Ÿè½½ç‰¹å¾ï¼Œè¡¨ç°ä¸ºç›®æ ‡çš„ä¸¤é‡æ€§ã€‚ç”¨æˆ·å‘èµ·çš„ååº”å¼ä»»åŠ¡éœ€è¦å³æ—¶ã€ä½å»¶è¿Ÿçš„å“åº”ï¼Œè€Œä¸»åŠ¨ä»»åŠ¡åˆ™éšå½¢è¿è¡Œå¹¶ä¼˜å…ˆè¿›è¡Œååé‡æ“ä½œã€‚ç°æœ‰çš„ç”¨äºå­¤ç«‹æ¨ç†çš„ç‰‡ä¸ŠLLMå¼•æ“æ— æ³•æœ‰æ•ˆç®¡ç†è¿™äº›å¹¶å‘ä¸”ç›¸äº’å†²çªçš„æ¶ˆè´¹çº§å¼‚æ„SoCè¯·æ±‚ï¼Œè¿™äº›SoCåŒ…æ‹¬CPUã€é›†æˆGPUå’ŒNPUã€‚æœ¬æ–‡ä»‹ç»äº†Agent.xpuï¼Œè¿™æ˜¯ä¸€ä¸ªåœ¨å†…å­˜ç»Ÿä¸€å¼‚æ„SoCä¸Šé«˜æ•ˆè¿è¡Œä»£ç†å‹LLMå·¥ä½œè´Ÿè½½çš„æœåŠ¡ç³»ç»Ÿã€‚é€šè¿‡ä¸“ç”¨çš„ç¦»çº¿åˆ†æï¼ŒAgent.xpué¦–å…ˆæ„å»ºäº†ä¸€ä¸ªå¼‚æ„æ‰§è¡Œå›¾ï¼Œè¯¥å›¾èåˆäº†æ¨¡å‹å†…æ ¸å¹¶è¿›è¡Œåˆ†å—ï¼Œä»¥å®ç°åŸºäºäº²å’ŒåŠ›çš„å¼¹æ€§åŠ é€Ÿå™¨æ˜ å°„å’Œé¢„æµ‹å†…æ ¸æ³¨é‡Šã€‚åœ¨è¿è¡Œæ—¶ï¼Œå…¶åœ¨çº¿è°ƒåº¦ç¨‹åºå¯å®ç°ç²¾ç»†ç²’åº¦çš„å†…æ ¸çº§æŠ¢å ï¼Œä»¥ä¿è¯ååº”å¼ä»»åŠ¡çš„å“åº”èƒ½åŠ›ã€‚ä¸ºäº†æœ€å¤§åŒ–SoCåˆ©ç”¨ç‡ï¼Œå®ƒé‡‡ç”¨ç©ºé—²å†…æ ¸å›å¡«æ¥é€‚æ—¶è¿½åŠ ä¸»åŠ¨ä»»åŠ¡ï¼Œå¹¶é€šè¿‡å¸¦å®½æ„ŸçŸ¥è°ƒåº¦æ¥ç¼“è§£NPU-iGPUäº‰ç”¨æƒ…å†µã€‚åœ¨Intel Core Ultra SoCä¸Šçš„è¯„ä¼°è¡¨æ˜ï¼Œä¸æœ€æ–°çš„æ¨ç†å¼•æ“ç›¸æ¯”ï¼ŒAgent.xpuå°†ååº”å¼ä»»åŠ¡çš„å»¶è¿Ÿé™ä½äº†4.6å€ï¼Œå¹¶å°†ä¸»åŠ¨ä»»åŠ¡çš„ååé‡æé«˜äº†1.6å€è‡³6.8å€ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.24045v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>è¯¥æ–‡ä»‹ç»äº†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨ä¸ªäººè®¾å¤‡ä¸Šçš„æ™®åŠå¸¦æ¥äº†ä¸€ç§æ–°çš„å·¥ä½œè´Ÿè½½ç±»åˆ«ï¼Œå…·æœ‰ç›®æ ‡äºŒå…ƒæ€§çš„ç‰¹å¾ã€‚ååº”æ€§ä»»åŠ¡éœ€è¦å³æ—¶ã€ä½å»¶è¿Ÿçš„å“åº”ï¼Œè€Œä¸»åŠ¨æ€§ä»»åŠ¡åˆ™éšå½¢è¿è¡Œå¹¶ä¼˜å…ˆæ³¨é‡ååé‡ã€‚ç°æœ‰çš„é’ˆå¯¹å­¤ç«‹æ¨ç†è®¾è®¡çš„LLMå¼•æ“æ— æ³•æœ‰æ•ˆç®¡ç†è¿™äº›å¹¶å‘ä¸”ç›¸äº’å†²çªçš„è¯·æ±‚ã€‚ä¸ºæ­¤ï¼Œæœ¬æ–‡æå‡ºäº†Agent.xpuç³»ç»Ÿï¼Œè¯¥ç³»ç»Ÿä¸“ä¸ºå†…å­˜ç»Ÿä¸€çš„å¼‚æ„SoCä¸Šçš„LLMå·¥ä½œè´Ÿè½½æœåŠ¡è®¾è®¡ã€‚é€šè¿‡ä¸“ç”¨çš„ç¦»çº¿åˆ†æï¼ŒAgent.xpué¦–å…ˆæ„å»ºäº†ä¸€ä¸ªå¼‚æ„æ‰§è¡Œå›¾ï¼Œç”¨äºèåˆå’Œåˆ†æ®µæ¨¡å‹å†…æ ¸ä»¥å®ç°å¼¹æ€§åŠ é€Ÿå™¨æ˜ å°„å’Œé¢„æµ‹å†…æ ¸æ³¨é‡Šã€‚å…¶åœ¨çº¿è°ƒåº¦å™¨ä¿è¯äº†ååº”æ€§ä»»åŠ¡çš„å“åº”æ€§ï¼Œå¹¶æœ€å¤§é™åº¦åœ°æé«˜äº†SoCçš„åˆ©ç”¨ç‡ã€‚è¯„ä¼°æ˜¾ç¤ºï¼Œä¸æœ€æ–°çš„æ¨ç†å¼•æ“ç›¸æ¯”ï¼ŒAgent.xpuåœ¨ååº”æ€§ä»»åŠ¡ä¸Šå®ç°äº†4.6å€çš„å»¶è¿Ÿé™ä½ï¼Œå¹¶åœ¨ä¸»åŠ¨æ€§ä»»åŠ¡ä¸Šä¿æŒäº†1.6-6.8å€çš„ååé‡æå‡ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨ä¸ªäººè®¾å¤‡ä¸Šçš„æ™®åŠå¸¦æ¥äº†ååº”æ€§å’Œä¸»åŠ¨æ€§å¹¶å­˜çš„æ–°å·¥ä½œè´Ÿè½½ç±»åˆ«ã€‚</li>
<li>ç°æœ‰LLMå¼•æ“è®¾è®¡æ— æ³•æœ‰æ•ˆå¤„ç†å¹¶å‘ä¸”å†²çªçš„ä»»åŠ¡è¯·æ±‚ã€‚</li>
<li>Agent.xpuç³»ç»Ÿä¸“ä¸ºå†…å­˜ç»Ÿä¸€çš„å¼‚æ„SoCä¸Šçš„LLMå·¥ä½œè´Ÿè½½æœåŠ¡è®¾è®¡ã€‚</li>
<li>Agent.xpué€šè¿‡æ„å»ºå¼‚æ„æ‰§è¡Œå›¾æ¥ä¼˜åŒ–ä»»åŠ¡å¤„ç†ã€‚</li>
<li>Agent.xpuå®ç°äº†å¼¹æ€§åŠ é€Ÿå™¨æ˜ å°„å’Œé¢„æµ‹å†…æ ¸æ³¨é‡Šä»¥æé«˜æ•ˆç‡ã€‚</li>
<li>Agent.xpuçš„åœ¨çº¿è°ƒåº¦å™¨ç¡®ä¿äº†ååº”æ€§ä»»åŠ¡çš„å“åº”æ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.24045">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-00a7a1fa85d82a22e28f51cc77bdb7df.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-1e271aee1bc55ed03180c2d307c01dad.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f56f585a2475bacbbfce20981976ea91.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-679532e05f4abf3635c387fff5d1c8fe.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="Ella-Embodied-Social-Agents-with-Lifelong-Memory"><a href="#Ella-Embodied-Social-Agents-with-Lifelong-Memory" class="headerlink" title="Ella: Embodied Social Agents with Lifelong Memory"></a>Ella: Embodied Social Agents with Lifelong Memory</h2><p><strong>Authors:Hongxin Zhang, Zheyuan Zhang, Zeyuan Wang, Zunzhe Zhang, Lixing Fang, Qinhong Zhou, Chuang Gan</strong></p>
<p>We introduce Ella, an embodied social agent capable of lifelong learning within a community in a 3D open world, where agents accumulate experiences and acquire knowledge through everyday visual observations and social interactions. At the core of Ellaâ€™s capabilities is a structured, long-term multimodal memory system that stores, updates, and retrieves information effectively. It consists of a name-centric semantic memory for organizing acquired knowledge and a spatiotemporal episodic memory for capturing multimodal experiences. By integrating this lifelong memory system with foundation models, Ella retrieves relevant information for decision-making, plans daily activities, builds social relationships, and evolves autonomously while coexisting with other intelligent beings in the open world. We conduct capability-oriented evaluations in a dynamic 3D open world where 15 agents engage in social activities for days and are assessed with a suite of unseen controlled evaluations. Experimental results show that Ella can influence, lead, and cooperate with other agents well to achieve goals, showcasing its ability to learn effectively through observation and social interaction. Our findings highlight the transformative potential of combining structured memory systems with foundation models for advancing embodied intelligence. More videos can be found at <a target="_blank" rel="noopener" href="https://umass-embodied-agi.github.io/Ella/">https://umass-embodied-agi.github.io/Ella/</a>. </p>
<blockquote>
<p>æˆ‘ä»¬ä»‹ç»äº†Ellaï¼Œè¿™æ˜¯ä¸€ä¸ªèƒ½å¤Ÿåœ¨ä¸‰ç»´å¼€æ”¾ä¸–ç•Œç¤¾åŒºä¸­è¿›è¡Œç»ˆç”Ÿå­¦ä¹ çš„å®ä½“ç¤¾äº¤ä»£ç†ã€‚åœ¨è¿™ä¸ªä¸–ç•Œä¸­ï¼Œä»£ç†é€šè¿‡æ—¥å¸¸çš„è§†è§‰è§‚å¯Ÿå’Œç¤¾ä¼šäº’åŠ¨ç§¯ç´¯ç»éªŒå¹¶è·å–çŸ¥è¯†ã€‚Ellaçš„æ ¸å¿ƒèƒ½åŠ›æ˜¯ä¸€ä¸ªç»“æ„åŒ–çš„é•¿æœŸå¤šæ¨¡å¼è®°å¿†ç³»ç»Ÿï¼Œå®ƒèƒ½æœ‰æ•ˆåœ°å­˜å‚¨ã€æ›´æ–°å’Œæ£€ç´¢ä¿¡æ¯ã€‚å®ƒç”±ä¸€ä¸ªä»¥åå­—ä¸ºä¸­å¿ƒçš„è¯­ä¹‰è®°å¿†ç»„æˆï¼Œç”¨äºç»„ç»‡è·å¾—çš„çŸ¥è¯†ï¼Œä»¥åŠä¸€ä¸ªæ—¶ç©ºæƒ…æ™¯è®°å¿†ï¼Œç”¨äºæ•æ‰å¤šæ¨¡å¼ç»éªŒã€‚é€šè¿‡å°†è¿™ç§ç»ˆèº«è®°å¿†ç³»ç»Ÿä¸åŸºç¡€æ¨¡å‹ç›¸ç»“åˆï¼ŒEllaå¯ä»¥æ£€ç´¢ä¸å†³ç­–ç›¸å…³çš„ä¿¡æ¯ï¼Œè§„åˆ’æ—¥å¸¸æ´»åŠ¨ï¼Œå»ºç«‹ç¤¾ä¼šå…³ç³»ï¼Œå¹¶åœ¨ä¸å…¶ä»–æ™ºèƒ½ç”Ÿç‰©å…±å­˜çš„åŒæ—¶è‡ªä¸»è¿›åŒ–ã€‚æˆ‘ä»¬åœ¨ä¸€ä¸ªåŠ¨æ€çš„ä¸‰ç»´å¼€æ”¾ä¸–ç•Œè¿›è¡Œäº†é¢å‘èƒ½åŠ›çš„è¯„ä¼°ï¼Œåœ¨è¿™é‡Œï¼Œ15ä¸ªä»£ç†å‚ä¸ç¤¾äº¤æ´»åŠ¨æ•°å¤©ï¼Œå¹¶é€šè¿‡ä¸€ç³»åˆ—æœªè§è¿‡çš„å—æ§è¯„ä¼°è¿›è¡Œè¯„ä¼°ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒEllaèƒ½å¤Ÿå¾ˆå¥½åœ°å½±å“ã€å¸¦é¢†å…¶ä»–ä»£ç†ï¼Œå¹¶ä¸å®ƒä»¬åˆä½œå®ç°ç›®æ ‡ï¼Œå±•ç¤ºäº†å…¶é€šè¿‡è§‚å¯Ÿå’Œç¤¾äº¤äº’åŠ¨è¿›è¡Œæœ‰æ•ˆå­¦ä¹ çš„èƒ½åŠ›ã€‚æˆ‘ä»¬çš„ç ”ç©¶ç»“æœçªå‡ºäº†å°†ç»“æ„åŒ–è®°å¿†ç³»ç»Ÿä¸åŸºç¡€æ¨¡å‹ç›¸ç»“åˆåœ¨æ¨åŠ¨å®ä½“æ™ºèƒ½æ–¹é¢çš„å˜é©æ½œåŠ›ã€‚æ›´å¤šè§†é¢‘å¯åœ¨<a target="_blank" rel="noopener" href="https://umass-embodied-agi.github.io/Ella/">https://umass-embodied-agi.github.io/Ella/</a> æ‰¾åˆ°ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.24019v1">PDF</a> </p>
<p><strong>Summary</strong><br>Ellaæ˜¯ä¸€æ¬¾èƒ½å¤Ÿåœ¨ä¸‰ç»´å¼€æ”¾ä¸–ç•Œä¸­æŒç»­å­¦ä¹ çš„å®ä½“ç¤¾äº¤ä»£ç†ã€‚Ellaé€šè¿‡æ—¥å¸¸è§†è§‰è§‚å¯Ÿå’Œç¤¾ä¼šäº’åŠ¨ç§¯ç´¯ç»éªŒå’ŒçŸ¥è¯†ï¼Œå…¶æ ¸å¿ƒæ˜¯ä¸€ä¸ªç»“æ„åŒ–çš„é•¿æœŸå¤šæ¨¡æ€è®°å¿†ç³»ç»Ÿï¼Œæœ‰æ•ˆåœ°å­˜å‚¨ã€æ›´æ–°å’Œæ£€ç´¢ä¿¡æ¯ã€‚è¯¥è®°å¿†ç³»ç»Ÿç”±ç”¨äºç»„ç»‡è·å–çŸ¥è¯†çš„ä»¥åå­—ä¸ºä¸­å¿ƒè¯­ä¹‰è®°å¿†å’Œç”¨äºæ•æ‰å¤šæ¨¡å¼ç»å†çš„æ—¶ç©ºäº‹ä»¶è®°å¿†ç»„æˆã€‚é€šè¿‡ä¸åŸºç¡€æ¨¡å‹çš„é›†æˆï¼ŒEllaå¯ä»¥æ£€ç´¢ç›¸å…³ä¿¡æ¯è¿›è¡Œå†³ç­–ã€è§„åˆ’æ—¥å¸¸æ´»åŠ¨ã€å»ºç«‹ç¤¾ä¼šå…³ç³»ï¼Œå¹¶åœ¨å¼€æ”¾ä¸–ç•Œä¸­ä¸å…¶ä»–æ™ºèƒ½ç”Ÿç‰©å…±å­˜å¹¶è‡ªä¸»å‘å±•ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒEllaèƒ½å¾ˆå¥½åœ°å½±å“ã€é¢†å¯¼å¹¶ä¸å…¶ä»–ä»£ç†åˆä½œå®ç°ç›®æ ‡ï¼Œå±•ç¤ºäº†å…¶é€šè¿‡è§‚å¯Ÿå’Œç¤¾äº¤äº’åŠ¨è¿›è¡Œæœ‰æ•ˆå­¦ä¹ çš„èƒ½åŠ›ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>Ellaæ˜¯ä¸€ä¸ªèƒ½åœ¨ä¸‰ç»´å¼€æ”¾ä¸–ç•Œä¸­è¿›è¡Œç»ˆèº«å­¦ä¹ çš„å®ä½“ç¤¾äº¤ä»£ç†ã€‚</li>
<li>Ellaé€šè¿‡æ—¥å¸¸è§†è§‰è§‚å¯Ÿå’Œç¤¾ä¼šäº’åŠ¨ç§¯ç´¯ç»éªŒå’ŒçŸ¥è¯†ã€‚</li>
<li>Ellaçš„æ ¸å¿ƒæ˜¯ä¸€ä¸ªç»“æ„åŒ–çš„é•¿æœŸå¤šæ¨¡æ€è®°å¿†ç³»ç»Ÿï¼ŒåŒ…æ‹¬ä»¥åå­—ä¸ºä¸­å¿ƒçš„è¯­ä¹‰è®°å¿†å’Œæ—¶ç©ºäº‹ä»¶è®°å¿†ã€‚</li>
<li>Ellaèƒ½å¤Ÿæ£€ç´¢ä¿¡æ¯è¿›è¡Œå†³ç­–ã€è§„åˆ’æ—¥å¸¸æ´»åŠ¨å¹¶å»ºç«‹ç¤¾ä¼šå…³ç³»ã€‚</li>
<li>Ellaå¯ä»¥ä¸å…¶ä»–æ™ºèƒ½ç”Ÿç‰©å…±å­˜å¹¶è‡ªä¸»å‘å±•ã€‚</li>
<li>Ellaèƒ½å¤Ÿå¾ˆå¥½åœ°å½±å“ã€é¢†å¯¼å¹¶ä¸å…¶ä»–ä»£ç†åˆä½œå®ç°ç›®æ ‡ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.24019">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-abab5e47c19a1361e806b1ce2a73d8a8.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-892b5e5a5aaa8911d6d9fdb60a511398.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-6dabfab114453e5c41b84f46e12c6a65.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-fc3872283fee48926edc37d52e85d3cd.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="Harnessing-AI-Agents-to-Advance-Research-on-Refugee-Child-Mental-Health"><a href="#Harnessing-AI-Agents-to-Advance-Research-on-Refugee-Child-Mental-Health" class="headerlink" title="Harnessing AI Agents to Advance Research on Refugee Child Mental Health"></a>Harnessing AI Agents to Advance Research on Refugee Child Mental Health</h2><p><strong>Authors:Aditya Shrivastava, Komal Gupta, Shraddha Arora</strong></p>
<p>The international refugee crisis deepens, exposing millions of dis placed children to extreme psychological trauma. This research suggests a com pact, AI-based framework for processing unstructured refugee health data and distilling knowledge on child mental health. We compare two Retrieval-Aug mented Generation (RAG) pipelines, Zephyr-7B-beta and DeepSeek R1-7B, to determine how well they process challenging humanitarian datasets while avoid ing hallucination hazards. By combining cutting-edge AI methods with migration research and child psychology, this study presents a scalable strategy to assist policymakers, mental health practitioners, and humanitarian agencies to better assist displaced children and recognize their mental wellbeing. In total, both the models worked properly but significantly Deepseek R1 is superior to Zephyr with an accuracy of answer relevance 0.91 </p>
<blockquote>
<p>éšç€å›½é™…éš¾æ°‘å±æœºæ—¥ç›ŠåŠ å‰§ï¼Œæ•°ç™¾ä¸‡æµç¦»å¤±æ‰€çš„å„¿ç«¥é¢ä¸´ç€æç«¯å¿ƒç†åˆ›ä¼¤ã€‚æœ¬ç ”ç©¶æå‡ºäº†ä¸€ç§åŸºäºäººå·¥æ™ºèƒ½çš„ç´§å‡‘æ¡†æ¶ï¼Œç”¨äºå¤„ç†éç»“æ„åŒ–çš„éš¾æ°‘å¥åº·æ•°æ®å¹¶æç‚¼æœ‰å…³å„¿ç«¥ç²¾ç¥å¥åº·çš„çŸ¥è¯†ã€‚æˆ‘ä»¬æ¯”è¾ƒäº†ä¸¤ç§æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰ç®¡é“ï¼ŒZephyr-7B-betaå’ŒDeepSeek R1-7Bï¼Œä»¥ç¡®å®šå®ƒä»¬åœ¨å¤„ç†å…·æœ‰æŒ‘æˆ˜çš„äººé“ä¸»ä¹‰æ•°æ®é›†æ—¶å¦‚ä½•é¿å…å¹»è§†é£é™©ã€‚æœ¬ç ”ç©¶å°†æœ€å‰æ²¿çš„AIæ–¹æ³•ä¸ç§»æ°‘ç ”ç©¶å’Œå„¿ç«¥å¿ƒç†å­¦ç›¸ç»“åˆï¼Œä¸ºå†³ç­–è€…ã€ç²¾ç¥å¥åº·ä¸“ä¸šäººå£«å’Œäººé“ä¸»ä¹‰æœºæ„æä¾›äº†ä¸€ç§å¯æ‰©å±•çš„ç­–ç•¥ï¼Œä»¥æ›´å¥½åœ°å¸®åŠ©æµç¦»å¤±æ‰€çš„å„¿ç«¥å¹¶æ‰¿è®¤ä»–ä»¬çš„ç²¾ç¥ç¦ç¥‰ã€‚æ€»çš„æ¥è¯´ï¼Œä¸¤ä¸ªæ¨¡å‹è¿è¡Œæ­£å¸¸ï¼Œä½†Deepseek R1æ˜æ˜¾ä¼˜äºZephyrï¼Œå…¶ç­”æ¡ˆçš„ç›¸å…³æ€§å‡†ç¡®åº¦ä¸º0.91ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.23992v1">PDF</a> 14 page , 2 image , 2 tables , accepted under 5th International   Conference on Innovations in Computational Intelligence and Computer Vision   (ICICV-2025)</p>
<p><strong>Summary</strong></p>
<p>éšç€å›½é™…éš¾æ°‘å±æœºåŠ æ·±ï¼Œæ•°ç™¾ä¸‡çš„æµç¦»å¤±æ‰€å„¿ç«¥é¢ä¸´æç«¯å¿ƒç†åˆ›ä¼¤ã€‚æœ¬ç ”ç©¶æå‡ºäº†ä¸€ç§ç´§å‡‘çš„ã€åŸºäºäººå·¥æ™ºèƒ½çš„æ¡†æ¶ï¼Œç”¨äºå¤„ç†éç»“æ„åŒ–çš„éš¾æ°‘å¥åº·æ•°æ®å¹¶æç‚¼å…³äºå„¿ç«¥ç²¾ç¥å¥åº·çš„çŸ¥è¯†ã€‚é€šè¿‡æ¯”è¾ƒZephyr-7B-betaå’ŒDeepSeek R1-7Bä¸¤ç§æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰ç®¡é“ï¼Œç ”ç©¶ç¡®å®šå®ƒä»¬å¦‚ä½•å¤„ç†å…·æœ‰æŒ‘æˆ˜çš„äººé“ä¸»ä¹‰æ•°æ®é›†ï¼ŒåŒæ—¶é¿å…è™šæ„é£é™©ã€‚ç»“åˆå‰æ²¿çš„AIæ–¹æ³•ã€ç§»æ°‘ç ”ç©¶å’Œå„¿ç«¥å¿ƒç†å­¦ï¼Œæœ¬ç ”ç©¶ä¸ºæ”¿ç­–åˆ¶å®šè€…ã€ç²¾ç¥å¥åº·ä¸“ä¸šäººå£«å’Œäººé“ä¸»ä¹‰æœºæ„æä¾›äº†ä¸€ç§å¯ä¼¸ç¼©çš„ç­–ç•¥ï¼Œä»¥æ›´å¥½åœ°å¸®åŠ©æµç¦»å¤±æ‰€çš„å„¿ç«¥å¹¶å…³æ³¨ä»–ä»¬çš„ç²¾ç¥ç¦ç¥‰ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å›½é™…éš¾æ°‘å±æœºæ­£åœ¨åŠ å‰§ï¼Œå½±å“æ•°ç™¾ä¸‡å„¿ç«¥çš„å¿ƒç†å¥åº·ã€‚</li>
<li>ç ”ç©¶æå‡ºäº†ä¸€ä¸ªåŸºäºAIçš„æ¡†æ¶ç”¨äºå¤„ç†éš¾æ°‘å¥åº·æ•°æ®ï¼Œèšç„¦äºå„¿ç«¥ç²¾ç¥å¥åº·æ–¹é¢çš„çŸ¥è¯†çš„æç‚¼ã€‚</li>
<li>æ¯”è¾ƒäº†ä¸¤ç§æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰ç®¡é“Zephyr-7B-betaå’ŒDeepSeek R1-7Bçš„æ€§èƒ½ã€‚</li>
<li>DeepSeek R1åœ¨å¤„ç†äººé“ä¸»ä¹‰æ•°æ®é›†æ–¹é¢è¡¨ç°è¾ƒå¥½ï¼Œç­”æ¡ˆçš„å‡†ç¡®æ€§è¾¾åˆ°äº†0.91ã€‚</li>
<li>ç»“åˆå‰æ²¿AIæ–¹æ³•ã€ç§»æ°‘ç ”ç©¶å’Œå„¿ç«¥å¿ƒç†å­¦ï¼Œè¯¥ç ”ç©¶ä¸ºæ”¿ç­–åˆ¶å®šè€…å’Œäººé“ä¸»ä¹‰æœºæ„æä¾›äº†æœ‰æ•ˆå¸®åŠ©æµç¦»å¤±æ‰€å„¿ç«¥çš„ç­–ç•¥ã€‚</li>
<li>è¯¥ç­–ç•¥å¯æé«˜å¯¹å„¿ç«¥ç²¾ç¥å¥åº·çš„å…³æ³¨å’ŒååŠ©ï¼Œæœ‰åŠ©äºæ›´å¥½åœ°æ»¡è¶³æµç¦»å¤±æ‰€å„¿ç«¥çš„éœ€æ±‚ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.23992">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-c674c074173d98ca811fc4a712ecffcd.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-07546a7476004d9ef7acab02fd4f771c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d7e94b00e0bad25e24dd35ca49c7e53d.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="Leveraging-a-Multi-Agent-LLM-Based-System-to-Educate-Teachers-in-Hate-Incidents-Management"><a href="#Leveraging-a-Multi-Agent-LLM-Based-System-to-Educate-Teachers-in-Hate-Incidents-Management" class="headerlink" title="Leveraging a Multi-Agent LLM-Based System to Educate Teachers in Hate   Incidents Management"></a>Leveraging a Multi-Agent LLM-Based System to Educate Teachers in Hate   Incidents Management</h2><p><strong>Authors:Ewelina Gajewska, Michal Wawer, Katarzyna Budzynska, JarosÅ‚aw A. Chudziak</strong></p>
<p>Computer-aided teacher training is a state-of-the-art method designed to enhance teachersâ€™ professional skills effectively while minimising concerns related to costs, time constraints, and geographical limitations. We investigate the potential of large language models (LLMs) in teacher education, using a case of teaching hate incidents management in schools. To this end, we create a multi-agent LLM-based system that mimics realistic situations of hate, using a combination of retrieval-augmented prompting and persona modelling. It is designed to identify and analyse hate speech patterns, predict potential escalation, and propose effective intervention strategies. By integrating persona modelling with agentic LLMs, we create contextually diverse simulations of hate incidents, mimicking real-life situations. The system allows teachers to analyse and understand the dynamics of hate incidents in a safe and controlled environment, providing valuable insights and practical knowledge to manage such situations confidently in real life. Our pilot evaluation demonstrates teachersâ€™ enhanced understanding of the nature of annotator disagreements and the role of context in hate speech interpretation, leading to the development of more informed and effective strategies for addressing hate in classroom settings. </p>
<blockquote>
<p>è®¡ç®—æœºè¾…åŠ©æ•™å¸ˆåŸ¹è®­æ˜¯ä¸€ç§å…ˆè¿›çš„æ–¹æ³•ï¼Œæ—¨åœ¨æœ‰æ•ˆåœ°æå‡æ•™å¸ˆçš„ä¸“ä¸šæŠ€èƒ½ï¼ŒåŒæ—¶æœ€å¤§é™åº¦åœ°å‡å°‘ä¸æˆæœ¬ã€æ—¶é—´é™åˆ¶å’Œåœ°ç†é™åˆ¶ç›¸å…³çš„æ‹…å¿§ã€‚æˆ‘ä»¬è°ƒæŸ¥å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨æ•™å¸ˆæ•™è‚²ä¸­çš„æ½œåŠ›ï¼Œä»¥å­¦æ ¡ä»‡æ¨äº‹ä»¶ç®¡ç†æ•™å­¦ä¸ºä¾‹ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬åˆ›å»ºäº†ä¸€ä¸ªåŸºäºå¤šä»£ç†çš„LLMç³»ç»Ÿï¼Œæ¨¡æ‹Ÿä»‡æ¨çš„ç°å®æƒ…å¢ƒï¼Œç»“åˆæ£€ç´¢å¢å¼ºæç¤ºå’Œäººæ ¼å»ºæ¨¡ã€‚å®ƒæ—¨åœ¨è¯†åˆ«å’Œåˆ†æä»‡æ¨è¨€è®ºæ¨¡å¼ï¼Œé¢„æµ‹å¯èƒ½çš„å‡çº§ï¼Œå¹¶æå‡ºæœ‰æ•ˆçš„å¹²é¢„ç­–ç•¥ã€‚é€šè¿‡äººæ ¼å»ºæ¨¡ä¸ä»£ç†LLMçš„ç»“åˆï¼Œæˆ‘ä»¬åˆ›å»ºäº†ä»‡æ¨äº‹ä»¶çš„ä¸Šä¸‹æ–‡å¤šæ ·æ¨¡æ‹Ÿï¼Œæ¨¡æ‹ŸçœŸå®ç”Ÿæ´»æƒ…å¢ƒã€‚è¯¥ç³»ç»Ÿå…è®¸æ•™å¸ˆåœ¨å®‰å…¨å¯æ§çš„ç¯å¢ƒä¸­åˆ†æä»‡æ¨äº‹ä»¶çš„åŠ¨åŠ›ï¼Œæä¾›æœ‰ä»·å€¼çš„è§è§£å’Œå®ç”¨çŸ¥è¯†ï¼Œä»¥ä¾¿åœ¨ç°å®ç”Ÿæ´»ä¸­è‡ªä¿¡åœ°å¤„ç†è¿™ç§æƒ…å†µã€‚æˆ‘ä»¬çš„åˆæ­¥è¯„ä¼°è¡¨æ˜ï¼Œæ•™å¸ˆå¢å¼ºäº†ä»–ä»¬å¯¹æ³¨é‡Šè€…åˆ†æ­§çš„æ€§è´¨ä»¥åŠä¸Šä¸‹æ–‡åœ¨ä»‡æ¨è¨€è®ºè§£é‡Šä¸­çš„ä½œç”¨çš„ç†è§£ï¼Œä»è€Œåˆ¶å®šå‡ºæ›´æœ‰é’ˆå¯¹æ€§å’Œæœ‰æ•ˆçš„ç­–ç•¥æ¥è§£å†³è¯¾å ‚ç¯å¢ƒä¸­çš„ä»‡æ¨é—®é¢˜ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.23774v1">PDF</a> 8 pages, 1 figure</p>
<p><strong>Summary</strong>ï¼šè®¡ç®—æœºè¾…åŠ©æ•™å­¦åŸ¹è®­æ˜¯ä¸€ç§å…ˆè¿›çš„æ–¹æ³•ï¼Œæ—¨åœ¨æœ‰æ•ˆåœ°æé«˜æ•™å¸ˆçš„ä¸“ä¸šæŠ€èƒ½ï¼ŒåŒæ—¶æœ€å°åŒ–æˆæœ¬ã€æ—¶é—´é™åˆ¶å’Œåœ°ç†é™åˆ¶ç›¸å…³çš„æ‹…å¿§ã€‚æœ¬ç ”ç©¶è°ƒæŸ¥å¤§å‹è¯­è¨€æ¨¡å‹åœ¨æ•™å¸ˆæ•™è‚²ä¸­çš„æ½œåŠ›ï¼Œä»¥ç®¡ç†æ ¡å›­ä»‡æ¨äº‹ä»¶ä¸ºä¾‹ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬åˆ›å»ºäº†ä¸€ä¸ªåŸºäºå¤šä»£ç†çš„å¤§å‹è¯­è¨€æ¨¡å‹çš„ç³»ç»Ÿï¼Œæ¨¡æ‹Ÿä»‡æ¨çš„çœŸå®æƒ…å¢ƒï¼Œç»“åˆå¢å¼ºæ£€ç´¢æç¤ºå’Œäººæ ¼å»ºæ¨¡ã€‚è¯¥ç³»ç»Ÿæ—¨åœ¨è¯†åˆ«å’Œåˆ†æä»‡æ¨è¨€è®ºæ¨¡å¼ï¼Œé¢„æµ‹æ½œåœ¨å‡çº§ï¼Œå¹¶æå‡ºæœ‰æ•ˆçš„å¹²é¢„ç­–ç•¥ã€‚é€šè¿‡äººæ ¼å»ºæ¨¡ä¸ä»£ç†å¤§å‹è¯­è¨€æ¨¡å‹çš„ç»“åˆï¼Œæˆ‘ä»¬åˆ›å»ºäº†ä»‡æ¨äº‹ä»¶çš„ä¸Šä¸‹æ–‡å¤šæ ·æ€§æ¨¡æ‹Ÿï¼Œæ¨¡æ‹ŸçœŸå®ç”Ÿæ´»æƒ…å¢ƒã€‚è¯¥ç³»ç»Ÿå…è®¸æ•™å¸ˆåœ¨å®‰å…¨å’Œå—æ§çš„ç¯å¢ƒä¸­åˆ†æä»‡æ¨äº‹ä»¶çš„åŠ¨æ€ï¼Œä¸ºç®¡ç†æ­¤ç±»æƒ…å†µæä¾›å®è´µçš„è§è§£å’Œå®ç”¨çŸ¥è¯†ã€‚æ•™å¸ˆè¯•ç‚¹è¯„ä¼°æ˜¾ç¤ºï¼Œä»–ä»¬æ›´æ·±å…¥åœ°ç†è§£äº†æ³¨é‡Šè€…åˆ†æ­§çš„æœ¬è´¨å’Œåœ¨ä»‡æ¨è¨€è®ºè§£è¯»ä¸­ä¸Šä¸‹æ–‡çš„ä½œç”¨ï¼Œä»è€Œå‘å±•å‡ºæ›´åŠ æ˜æ™ºæœ‰æ•ˆçš„åº”å¯¹è¯¾å ‚ä»‡æ¨çš„ç­–ç•¥ã€‚</p>
<p><strong>Key Takeaways</strong>ï¼š</p>
<ol>
<li>è®¡ç®—æœºè¾…åŠ©æ•™å­¦åŸ¹è®­æ—¨åœ¨æé«˜æ•™å¸ˆä¸“ä¸šæŠ€èƒ½ï¼ŒåŒæ—¶è€ƒè™‘æˆæœ¬ã€æ—¶é—´å’Œåœ°ç†é™åˆ¶ã€‚</li>
<li>å¤§å‹è¯­è¨€æ¨¡å‹åœ¨æ•™å¸ˆæ•™è‚²ä¸­æœ‰å·¨å¤§æ½œåŠ›ï¼Œå¯åº”ç”¨äºç®¡ç†æ ¡å›­ä»‡æ¨äº‹ä»¶ã€‚</li>
<li>åŸºäºå¤šä»£ç†çš„å¤§å‹è¯­è¨€æ¨¡å‹ç³»ç»Ÿèƒ½æ¨¡æ‹Ÿä»‡æ¨çš„çœŸå®æƒ…å¢ƒã€‚</li>
<li>è¯¥ç³»ç»Ÿå¯è¯†åˆ«å’Œåˆ†æä»‡æ¨è¨€è®ºæ¨¡å¼ï¼Œé¢„æµ‹æ½œåœ¨å‡çº§ã€‚</li>
<li>é€šè¿‡äººæ ¼å»ºæ¨¡ä¸ä»£ç†å¤§å‹è¯­è¨€æ¨¡å‹çš„ç»“åˆï¼Œåˆ›å»ºäº†ä»‡æ¨äº‹ä»¶çš„ä¸Šä¸‹æ–‡å¤šæ ·æ€§æ¨¡æ‹Ÿã€‚</li>
<li>æ•™å¸ˆåœ¨å®‰å…¨å’Œå—æ§çš„ç¯å¢ƒä¸­é€šè¿‡è¯¥ç³»ç»Ÿèƒ½åˆ†æä»‡æ¨äº‹ä»¶çš„åŠ¨æ€ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.23774">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-4b47b8a4d9dc79f4e6fd0a7b83b133e1.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-9d9debc3b407564fa7f7671b0bf28bb3.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-5ab5a6f8aeb71b8d0885dcaa3d236ebd.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="DABstep-Data-Agent-Benchmark-for-Multi-step-Reasoning"><a href="#DABstep-Data-Agent-Benchmark-for-Multi-step-Reasoning" class="headerlink" title="DABstep: Data Agent Benchmark for Multi-step Reasoning"></a>DABstep: Data Agent Benchmark for Multi-step Reasoning</h2><p><strong>Authors:Alex Egg, Martin Iglesias Goyanes, Friso Kingma, Andreu Mora, Leandro von Werra, Thomas Wolf</strong></p>
<p>We introduce DABstep, a novel benchmark for evaluating AI agents on realistic multi-step data analysis tasks. DABstep comprises over 450 real-world challenges derived from a financial analytics platform, requiring models to combine code-based data processing with contextual reasoning over heterogeneous documentation. Each task demands an iterative, multi-step problem-solving approach, testing capabilities in data manipulation, cross-referencing multiple sources, and precise result reporting. The benchmark provides a factoid-style answer format with automatic correctness checks for objective scoring at scale. We evaluate leading LLM-based agents, revealing a substantial performance gap: even the best agent achieves only 14.55% accuracy on the hardest tasks. We detail our benchmarkâ€™s design, dataset composition, task formulation, evaluation protocol, report baseline results and analyze failure modes. DABstep is released with a public leaderboard and toolkit to accelerate research in autonomous data analysis. </p>
<blockquote>
<p>æˆ‘ä»¬ä»‹ç»äº†DABstepï¼Œè¿™æ˜¯ä¸€ä¸ªç”¨äºè¯„ä¼°AIä»£ç†åœ¨ç°å®å¤šæ­¥éª¤æ•°æ®åˆ†æä»»åŠ¡ä¸Šçš„æ–°å‹åŸºå‡†æµ‹è¯•ã€‚DABstepåŒ…å«æ¥è‡ªé‡‘èåˆ†æå¹³å°çš„450å¤šä¸ªç°å®æŒ‘æˆ˜ï¼Œè¦æ±‚æ¨¡å‹ç»“åˆåŸºäºä»£ç çš„æ•°æ®å¤„ç†å’Œå¯¹å¼‚è´¨æ–‡æ¡£çš„ä¸Šä¸‹æ–‡æ¨ç†ã€‚æ¯ä¸ªä»»åŠ¡éƒ½éœ€è¦è¿­ä»£ã€å¤šæ­¥éª¤çš„é—®é¢˜è§£å†³æ–¹å¼ï¼Œæµ‹è¯•æ•°æ®æ“çºµã€è·¨æºå‚ç…§å’Œç²¾ç¡®ç»“æœæŠ¥å‘Šçš„èƒ½åŠ›ã€‚è¯¥åŸºå‡†æµ‹è¯•æä¾›äº†ä¸€ç§äº‹å®å‹ç­”æ¡ˆæ ¼å¼ï¼Œå¹¶æä¾›äº†å¤§è§„æ¨¡å®¢è§‚è¯„åˆ†çš„è‡ªåŠ¨æ­£ç¡®æ€§æ£€æŸ¥ã€‚æˆ‘ä»¬è¯„ä¼°äº†åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„é¢†å…ˆä»£ç†ï¼Œç»“æœæ˜¾ç¤ºå‡ºæ˜¾è‘—çš„æ€§èƒ½å·®è·ï¼šå³ä½¿åœ¨æœ€å›°éš¾çš„ä»»åŠ¡ä¸Šï¼Œæœ€ä½³ä»£ç†ä¹Ÿåªè¾¾åˆ°äº†14.55%çš„å‡†ç¡®ç‡ã€‚æˆ‘ä»¬è¯¦ç»†ä»‹ç»äº†åŸºå‡†æµ‹è¯•çš„è®¾è®¡ã€æ•°æ®é›†ç»„æˆã€ä»»åŠ¡åˆ¶å®šã€è¯„ä¼°åè®®ã€æŠ¥å‘ŠåŸºçº¿ç»“æœå’Œåˆ†æå¤±è´¥æ¨¡å¼ã€‚DABstepä¸å…¬å¼€æ’è¡Œæ¦œå’Œå·¥å…·åŒ…ä¸€èµ·å‘å¸ƒï¼Œä»¥åŠ å¿«è‡ªä¸»æ•°æ®åˆ†æçš„ç ”ç©¶è¿›ç¨‹ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.23719v1">PDF</a> 13 pages, 5 figures</p>
<p><strong>Summary</strong></p>
<p>DABstepæ˜¯ä¸€ä¸ªæ–°å‹åŸºå‡†æµ‹è¯•ï¼Œç”¨äºè¯„ä¼°AIä»£ç†åœ¨çœŸå®çš„å¤šæ­¥éª¤æ•°æ®åˆ†æä»»åŠ¡ä¸Šçš„è¡¨ç°ã€‚å®ƒåŒ…å«450å¤šä¸ªæ¥è‡ªé‡‘èåˆ†æå¹³å°çš„çœŸå®ä¸–ç•ŒæŒ‘æˆ˜ï¼Œè¦æ±‚æ¨¡å‹ç»“åˆä»£ç æ•°æ®å¤„ç†å’Œè·¨å¼‚æ„æ–‡æ¡£è¿›è¡Œä¸Šä¸‹æ–‡æ¨ç†ã€‚æ­¤åŸºå‡†æµ‹è¯•æ­ç¤ºäº†é¡¶å°–çš„å¤§å‹è¯­è¨€æ¨¡å‹ä»£ç†ä¹‹é—´çš„æ€§èƒ½å·®è·ï¼Œå¹¶è¯¦ç»†è¯´æ˜äº†å…¶è®¾è®¡ã€æ•°æ®é›†æ„æˆã€ä»»åŠ¡åˆ¶å®šã€è¯„ä¼°åè®®ã€åŸºå‡†æµ‹è¯•ç»“æœå’Œå¤±è´¥æ¨¡å¼ã€‚DABstepå·²å‘å¸ƒå…¬å¼€æ’è¡Œæ¦œå’Œå·¥å…·åŒ…ï¼Œä»¥åŠ é€Ÿè‡ªä¸»æ•°æ®ç ”ç©¶ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>DABstepæ˜¯ä¸€ä¸ªç”¨äºè¯„ä¼°AIä»£ç†å¤šæ­¥éª¤æ•°æ®åˆ†æèƒ½åŠ›çš„åŸºå‡†æµ‹è¯•ã€‚</li>
<li>å®ƒåŒ…å«450å¤šä¸ªçœŸå®ä¸–ç•ŒæŒ‘æˆ˜ï¼Œæ¥æºäºé‡‘èåˆ†æå¹³å°ã€‚</li>
<li>DABstepè¦æ±‚æ¨¡å‹ç»“åˆä»£ç æ•°æ®å¤„ç†å’Œè·¨å¼‚æ„æ–‡æ¡£è¿›è¡Œä¸Šä¸‹æ–‡æ¨ç†ã€‚</li>
<li>åŸºå‡†æµ‹è¯•è¦æ±‚è¿­ä»£ã€å¤šæ­¥éª¤çš„è§£å†³é—®é¢˜çš„æ–¹æ³•ã€‚</li>
<li>è¯„ä¼°åè®®åŒ…æ‹¬æ•°æ®æ“ä½œã€è·¨æºå‚è€ƒå’Œç²¾ç¡®ç»“æœæŠ¥å‘Šçš„èƒ½åŠ›æµ‹è¯•ã€‚</li>
<li>é¡¶å°–çš„å¤§å‹è¯­è¨€æ¨¡å‹ä»£ç†åœ¨DABstepä¸Šçš„æ€§èƒ½å­˜åœ¨æ˜¾è‘—å·®è·ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.23719">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-6b6ece718e98f8241275d507acba7990.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-b19baa7a56a62e9d94bdd5efe7a20970.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-3550d27f9908bfff5c2d90be8b069aa5.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-48e2c8a176efbf9b8517e278288cf0f7.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="PokeAI-A-Goal-Generating-Battle-Optimizing-Multi-agent-System-for-Pokemon-Red"><a href="#PokeAI-A-Goal-Generating-Battle-Optimizing-Multi-agent-System-for-Pokemon-Red" class="headerlink" title="PokÃ©AI: A Goal-Generating, Battle-Optimizing Multi-agent System for   Pokemon Red"></a>PokÃ©AI: A Goal-Generating, Battle-Optimizing Multi-agent System for   Pokemon Red</h2><p><strong>Authors:Zihao Liu, Xinhang Sui, Yueran Song, Siwen Wang</strong></p>
<p>We introduce Pok&#39;eAI, the first text-based, multi-agent large language model (LLM) framework designed to autonomously play and progress through Pok&#39;emon Red. Our system consists of three specialized agents-Planning, Execution, and Critique-each with its own memory bank, role, and skill set. The Planning Agent functions as the central brain, generating tasks to progress through the game. These tasks are then delegated to the Execution Agent, which carries them out within the game environment. Upon task completion, the Critique Agent evaluates the outcome to determine whether the objective was successfully achieved. Once verification is complete, control returns to the Planning Agent, forming a closed-loop decision-making system.   As a preliminary step, we developed a battle module within the Execution Agent. Our results show that the battle AI achieves an average win rate of 80.8% across 50 wild encounters, only 6% lower than the performance of an experienced human player. Furthermore, we find that a modelâ€™s battle performance correlates strongly with its LLM Arena score on language-related tasks, indicating a meaningful link between linguistic ability and strategic reasoning. Finally, our analysis of gameplay logs reveals that each LLM exhibits a unique playstyle, suggesting that individual models develop distinct strategic behaviors. </p>
<blockquote>
<p>æˆ‘ä»¬ä»‹ç»äº†PokÃ©AIï¼Œè¿™æ˜¯é¦–æ¬¾åŸºäºæ–‡æœ¬çš„å¤šæ™ºèƒ½ä½“å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ¡†æ¶ï¼Œæ—¨åœ¨è‡ªä¸»ç©å’Œæ¨è¿›PokÃ©mon Redæ¸¸æˆã€‚æˆ‘ä»¬çš„ç³»ç»Ÿç”±ä¸‰ä¸ªä¸“ä¸šæ™ºèƒ½ä½“ç»„æˆï¼šè§„åˆ’ã€æ‰§è¡Œå’Œæ‰¹åˆ¤ï¼Œæ¯ä¸ªæ™ºèƒ½ä½“éƒ½æœ‰è‡ªå·±çš„è®°å¿†åº“ã€è§’è‰²å’ŒæŠ€èƒ½é›†ã€‚è§„åˆ’æ™ºèƒ½ä½“å……å½“ä¸­å¤®å¤§è„‘ï¼Œç”Ÿæˆä»»åŠ¡ä»¥æ¨åŠ¨æ¸¸æˆè¿›ç¨‹ã€‚è¿™äº›ä»»åŠ¡ç„¶ååˆ†é…ç»™æ‰§è¡Œæ™ºèƒ½ä½“ï¼Œå®ƒåœ¨æ¸¸æˆç¯å¢ƒä¸­æ‰§è¡Œå®ƒä»¬ã€‚ä»»åŠ¡å®Œæˆåï¼Œæ‰¹åˆ¤æ™ºèƒ½ä½“ä¼šè¯„ä¼°ç»“æœï¼Œä»¥ç¡®å®šç›®æ ‡æ˜¯å¦æˆåŠŸå®ç°ã€‚ä¸€æ—¦éªŒè¯å®Œæˆï¼Œæ§åˆ¶æƒå°†è¿”å›ç»™è§„åˆ’æ™ºèƒ½ä½“ï¼Œå½¢æˆä¸€ä¸ªé—­ç¯å†³ç­–ç³»ç»Ÿã€‚ä½œä¸ºåˆæ­¥å·¥ä½œï¼Œæˆ‘ä»¬åœ¨æ‰§è¡Œæ™ºèƒ½ä½“å†…å¼€å‘äº†ä¸€ä¸ªæˆ˜æ–—æ¨¡å—ã€‚æˆ‘ä»¬çš„ç»“æœè¡¨æ˜ï¼Œæˆ˜æ–—äººå·¥æ™ºèƒ½åœ¨50åœºé‡ç”Ÿé­é‡ä¸­çš„å¹³å‡èƒœç‡ä¸º80.8%ï¼Œæ¯”ç»éªŒä¸°å¯Œçš„ç©å®¶ä½ä»…6%ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å‘ç°ä¸€ä¸ªæ¨¡å‹çš„æˆ˜æ–—æ€§èƒ½ä¸å…¶åœ¨LLM Arenaä¸Šçš„è¯­è¨€ç›¸å…³ä»»åŠ¡çš„å¾—åˆ†å…·æœ‰å¾ˆå¼ºçš„ç›¸å…³æ€§ï¼Œè¡¨æ˜è¯­è¨€èƒ½åŠ›å’Œæˆ˜ç•¥æ¨ç†ä¹‹é—´å­˜åœ¨æœ‰æ„ä¹‰çš„è”ç³»ã€‚æœ€åï¼Œæˆ‘ä»¬å¯¹æ¸¸æˆæ—¥å¿—çš„åˆ†æè¡¨æ˜ï¼Œæ¯ä¸ªLLMéƒ½è¡¨ç°å‡ºç‹¬ç‰¹çš„æ¸¸æˆé£æ ¼ï¼Œè¿™è¡¨æ˜ä¸ªåˆ«æ¨¡å‹ä¼šå‘å±•å‡ºä¸åŒçš„æˆ˜ç•¥è¡Œä¸ºã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.23689v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†PokÃ©AIï¼Œé¦–æ¬¾åŸºäºæ–‡æœ¬çš„å¤šæ™ºèƒ½ä½“å¤§å‹è¯­è¨€æ¨¡å‹æ¡†æ¶ï¼Œæ—¨åœ¨è‡ªä¸»ç©å¹¶æ¨è¿›PokÃ©mon Redæ¸¸æˆã€‚è¯¥ç³»ç»ŸåŒ…æ‹¬è§„åˆ’ã€æ‰§è¡Œå’Œè¯„è®ºä¸‰ä¸ªæ™ºèƒ½ä½“ï¼Œæ¯ä¸ªæ™ºèƒ½ä½“éƒ½æœ‰è‡ªå·±çš„è®°å¿†åº“ã€è§’è‰²å’ŒæŠ€èƒ½é›†ã€‚è§„åˆ’æ™ºèƒ½ä½“ä½œä¸ºä¸­å¤®å¤§è„‘ï¼Œç”Ÿæˆä»»åŠ¡æ¨è¿›æ¸¸æˆã€‚ç„¶åï¼Œæ‰§è¡Œä»»åŠ¡è¢«å§”æ´¾ç»™æ‰§è¡Œæ™ºèƒ½ä½“ï¼Œå…¶åœ¨æ¸¸æˆç¯å¢ƒä¸­æ‰§è¡Œä»»åŠ¡ã€‚ä»»åŠ¡å®Œæˆåï¼Œè¯„ä¼°æ™ºèƒ½ä½“ä¼šè¯„ä¼°ç»“æœä»¥ç¡®å®šç›®æ ‡æ˜¯å¦æˆåŠŸå®ç°ã€‚éªŒè¯å®Œæˆåï¼Œæ§åˆ¶æƒè¿”å›è§„åˆ’æ™ºèƒ½ä½“ï¼Œå½¢æˆä¸€ä¸ªé—­ç¯å†³ç­–ç³»ç»Ÿã€‚åˆæ­¥å¼€å‘äº†ä¸€ä¸ªæˆ˜æ–—æ¨¡å—åœ¨æ‰§è¡Œæ™ºèƒ½ä½“ä¸­ï¼Œæˆ˜æ–—äººå·¥æ™ºèƒ½å¹³å‡èƒœç‡ä¸º80.8%ï¼Œåœ¨é‡å¤–é­é‡ä¸­ç•¥ä½äºç†Ÿç»ƒäººç±»ç©å®¶çš„è¡¨ç°ã€‚è¿˜å‘ç°æ¨¡å‹æˆ˜æ–—æ€§èƒ½ä¸å…¶åœ¨å¤§å‹è¯­è¨€æ¨¡å‹ç«æŠ€åœºä¸Šçš„è¯­è¨€ä»»åŠ¡å¾—åˆ†å¯†åˆ‡ç›¸å…³ï¼Œè¡¨æ˜è¯­è¨€èƒ½åŠ›å’Œæˆ˜ç•¥æ¨ç†ä¹‹é—´å­˜åœ¨è”ç³»ã€‚æœ€åï¼Œå¯¹æ¸¸æˆæ—¥å¿—çš„åˆ†ææ˜¾ç¤ºæ¯ä¸ªå¤§å‹è¯­è¨€æ¨¡å‹å±•ç°å‡ºç‹¬ç‰¹çš„æ¸¸æˆé£æ ¼ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>PokÃ©AIæ˜¯é¦–ä¸ªåŸºäºæ–‡æœ¬çš„å¤šæ™ºèƒ½ä½“å¤§å‹è¯­è¨€æ¨¡å‹æ¡†æ¶ï¼Œç”¨äºè‡ªä¸»ç©å¹¶æ¨è¿›PokÃ©mon Redæ¸¸æˆã€‚</li>
<li>ç³»ç»ŸåŒ…å«ä¸‰ä¸ªæ™ºèƒ½ä½“ï¼šè§„åˆ’ã€æ‰§è¡Œå’Œè¯„è®ºï¼Œæ¯ä¸ªæ™ºèƒ½ä½“æœ‰è‡ªå·±çš„è®°å¿†åº“ã€è§’è‰²å’ŒæŠ€èƒ½é›†ã€‚</li>
<li>è§„åˆ’æ™ºèƒ½ä½“ç”Ÿæˆä»»åŠ¡æ¨è¿›æ¸¸æˆï¼Œæ‰§è¡Œæ™ºèƒ½ä½“åœ¨æ¸¸æˆç¯å¢ƒä¸­æ‰§è¡Œä»»åŠ¡ï¼Œè¯„è®ºæ™ºèƒ½ä½“è¯„ä¼°ä»»åŠ¡ç»“æœã€‚</li>
<li>åˆæ­¥å¼€å‘çš„æˆ˜æ–—æ¨¡å—åœ¨æ‰§è¡Œæ™ºèƒ½ä½“ä¸­è¡¨ç°å‡ºè¾ƒé«˜çš„èƒœç‡ã€‚</li>
<li>æ¨¡å‹æˆ˜æ–—æ€§èƒ½ä¸å…¶åœ¨è¯­è¨€ä»»åŠ¡ä¸Šçš„è¡¨ç°å¯†åˆ‡ç›¸å…³ï¼Œè¡¨æ˜è¯­è¨€èƒ½åŠ›å’Œæˆ˜ç•¥æ¨ç†ä¹‹é—´çš„è”ç³»ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.23689">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-7c24b98462408ff76ddcc78f309e7cb4.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-95754261fc816754832fe1d44e45cc34.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-bbf1eaa048dd2c1a186a495a3ba6d844.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-7d57ca48cbf03741baccd76269a8221d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-723011d4692fe33464768308fc6567ca.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="L0-Reinforcement-Learning-to-Become-General-Agents"><a href="#L0-Reinforcement-Learning-to-Become-General-Agents" class="headerlink" title="L0: Reinforcement Learning to Become General Agents"></a>L0: Reinforcement Learning to Become General Agents</h2><p><strong>Authors:Junjie Zhang, Jingyi Xi, Zhuoyang Song, Junyu Lu, Yuhua Ke, Ting Sun, Yukun Yang, Jiaxing Zhang, Songxin Zhang, Zejian Xie</strong></p>
<p>Training large language models (LLMs) to act as autonomous agents for multi-turn, long-horizon tasks remains significant challenges in scalability and training efficiency. To address this, we introduce L-Zero (L0), a scalable, end-to-end training pipeline for general-purpose agents. Featuring a low-cost, extensible, and sandboxed concurrent agent worker pool, L0 lowers the barrier for applying reinforcement learning in complex environments. We also introduce NB-Agent, the agent scaffold within L0, which operates in a â€œcode-as-actionâ€ fashion via a Read-Eval-Print-Loop (REPL). We evaluate L0 on factuality question-answering benchmarks. Our experiments demonstrate that a base model can develop robust problem-solving skills using solely Reinforcement Learning with Verifiable Rewards (RLVR). On the Qwen2.5-7B-Instruct model, our method boosts accuracy on SimpleQA from 30 % to 80 % and on HotpotQA from 22 % to 41 %. We have open-sourced the entire L0 system, including our L0 series models, the NB-Agent, a complete training pipeline, and the corresponding training recipes on (<a target="_blank" rel="noopener" href="https://github.com/cmriat/l0">https://github.com/cmriat/l0</a>). </p>
<blockquote>
<p>è®­ç»ƒå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä»¥æ‰§è¡Œå¤šè½®ã€é•¿æœŸä»»åŠ¡ä½œä¸ºè‡ªä¸»ä»£ç†ä»ç„¶å­˜åœ¨å¯æ‰©å±•æ€§å’Œè®­ç»ƒæ•ˆç‡æ–¹é¢çš„é‡å¤§æŒ‘æˆ˜ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬æ¨å‡ºäº†L-Zeroï¼ˆL0ï¼‰ï¼Œè¿™æ˜¯ä¸€ä¸ªç”¨äºé€šç”¨ä»£ç†çš„å¯æ‰©å±•ç«¯åˆ°ç«¯è®­ç»ƒç®¡é“ã€‚L0é‡‡ç”¨ä½æˆæœ¬ã€å¯æ‰©å±•å’Œæ²™ç®±å¹¶å‘ä»£ç†å·¥ä½œæ± çš„æ–¹å¼ï¼Œé™ä½äº†åœ¨å¤æ‚ç¯å¢ƒä¸­åº”ç”¨å¼ºåŒ–å­¦ä¹ çš„é—¨æ§›ã€‚æˆ‘ä»¬è¿˜ä»‹ç»äº†L0å†…çš„ä»£ç†è„šæ‰‹æ¶NB-Agentï¼Œå®ƒé‡‡ç”¨â€œä»£ç å³è¡ŒåŠ¨â€çš„æ–¹å¼ï¼Œé€šè¿‡Read-Eval-Print-Loopï¼ˆREPLï¼‰è¿›è¡Œæ“ä½œã€‚æˆ‘ä»¬åœ¨äº‹å®æ€§é—®é¢˜å›ç­”åŸºå‡†æµ‹è¯•ä¸Šå¯¹L0è¿›è¡Œäº†è¯„ä¼°ã€‚å®éªŒè¡¨æ˜ï¼ŒåŸºç¡€æ¨¡å‹ä»…ä½¿ç”¨å¯éªŒè¯å¥–åŠ±å¼ºåŒ–å­¦ä¹ ï¼ˆRLVRï¼‰å°±èƒ½å‘å±•å‡ºç¨³å¥çš„é—®é¢˜è§£å†³èƒ½åŠ›ã€‚åœ¨Qwen2.5-7B-Instructæ¨¡å‹ä¸Šï¼Œæˆ‘ä»¬çš„æ–¹æ³•å°†SimpleQAçš„å‡†ç¡®ç‡ä»30%æé«˜åˆ°80%ï¼ŒHotpotQAçš„å‡†ç¡®ç‡ä»22%æé«˜åˆ°41%ã€‚æˆ‘ä»¬å·²å…¬å¼€äº†æ•´ä¸ªL0ç³»ç»Ÿï¼ŒåŒ…æ‹¬æˆ‘ä»¬çš„L0ç³»åˆ—æ¨¡å‹ã€NB-Agentã€å®Œæ•´çš„è®­ç»ƒç®¡é“å’Œç›¸åº”è®­ç»ƒé…æ–¹ï¼ˆ<a target="_blank" rel="noopener" href="https://github.com/cmriat/l0%EF%BC%89%E3%80%82">https://github.com/cmriat/l0ï¼‰ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.23667v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>L-Zeroï¼ˆL0ï¼‰æ˜¯ä¸€ä¸ªç”¨äºé€šç”¨ä»£ç†çš„å¯æ‰©å±•ç«¯åˆ°ç«¯è®­ç»ƒç®¡é“ï¼Œè§£å†³äº†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨å¤šè½®é•¿æ—¶é—´ä»»åŠ¡ä¸­çš„å¯æ‰©å±•æ€§å’Œè®­ç»ƒæ•ˆç‡çš„æŒ‘æˆ˜ã€‚å®ƒé‡‡ç”¨ä½æˆæœ¬ã€å¯æ‰©å±•å’Œæ²™ç®±åŒ–çš„å¹¶å‘ä»£ç†å·¥ä½œè€…æ± ï¼Œé™ä½äº†åœ¨å¤æ‚ç¯å¢ƒä¸­åº”ç”¨å¼ºåŒ–å­¦ä¹ çš„é—¨æ§›ã€‚é€šè¿‡â€œä»£ç å³è¡ŒåŠ¨â€çš„æ–¹å¼ï¼ŒL0ä¸­çš„NB-Agentä»£ç†æ¶æ„åœ¨Read-Eval-Print-Loopï¼ˆREPLï¼‰ä¸­è¿›è¡Œæ“ä½œã€‚è¯„ä¼°è¡¨æ˜ï¼ŒL0åœ¨äº‹å®æ€§é—®é¢˜å›ç­”åŸºå‡†æµ‹è¯•ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œä»…ä½¿ç”¨å¯éªŒè¯å¥–åŠ±çš„å¼ºåŒ–å­¦ä¹ ï¼ŒåŸºç¡€æ¨¡å‹çš„é—®é¢˜è§£å†³èƒ½åŠ›å°±èƒ½å¾—åˆ°æ˜¾è‘—æå‡ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>L-Zeroï¼ˆL0ï¼‰æ˜¯ä¸€ä¸ªç”¨äºé€šç”¨ä»£ç†çš„å¯æ‰©å±•ç«¯åˆ°ç«¯è®­ç»ƒç®¡é“ï¼Œæ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨å¤šè½®é•¿æ—¶é—´ä»»åŠ¡ä¸­çš„è®­ç»ƒæŒ‘æˆ˜ã€‚</li>
<li>L0é‡‡ç”¨ä½æˆæœ¬ã€å¯æ‰©å±•å’Œæ²™ç®±åŒ–çš„å¹¶å‘ä»£ç†å·¥ä½œè€…æ± ï¼Œé™ä½åœ¨å¤æ‚ç¯å¢ƒä¸­åº”ç”¨å¼ºåŒ–å­¦ä¹ çš„é—¨æ§›ã€‚</li>
<li>NB-Agentæ˜¯L0ä¸­çš„ä»£ç†æ¶æ„ï¼Œä»¥â€œä»£ç å³è¡ŒåŠ¨â€çš„æ–¹å¼åœ¨Read-Eval-Print-Loopï¼ˆREPLï¼‰ä¸­æ“ä½œã€‚</li>
<li>L0é€šè¿‡å¼ºåŒ–å­¦ä¹ ä¸å¯éªŒè¯å¥–åŠ±ï¼ˆRLVRï¼‰æå‡åŸºç¡€æ¨¡å‹çš„é—®é¢˜è§£å†³èƒ½åŠ›ã€‚</li>
<li>åœ¨äº‹å®æ€§é—®é¢˜å›ç­”åŸºå‡†æµ‹è¯•ä¸­ï¼ŒL0è¡¨ç°å‡ºè‰²ï¼Œå¦‚SimpleQAçš„å‡†ç¡®ç‡ä»30%æå‡è‡³80%ï¼ŒHotpotQAçš„å‡†ç¡®ç‡ä»22%æå‡è‡³41%ã€‚</li>
<li>L0ç³»ç»Ÿå·²å¼€æºï¼ŒåŒ…æ‹¬L0ç³»åˆ—æ¨¡å‹ã€NB-Agentã€å®Œæ•´çš„è®­ç»ƒç®¡é“å’Œç›¸åº”çš„è®­ç»ƒé…æ–¹ã€‚</li>
<li>L0çš„å¼€æºç³»ç»Ÿä¸ºå¤§å‹è¯­è¨€æ¨¡å‹çš„è®­ç»ƒå’Œä»£ç†æ¶æ„çš„å‘å±•æä¾›äº†é‡è¦èµ„æºå’Œå‚è€ƒã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.23667">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-44951a14875bbfa96c69286b8c12e04a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c3b048ce4e1516cb699b937da9c5ae24.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-bdffdb834dc9781be557047c33b9a8f5.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-15b38f0a442261e065f3d1b347947839.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="Thought-Augmented-Planning-for-LLM-Powered-Interactive-Recommender-Agent"><a href="#Thought-Augmented-Planning-for-LLM-Powered-Interactive-Recommender-Agent" class="headerlink" title="Thought-Augmented Planning for LLM-Powered Interactive Recommender Agent"></a>Thought-Augmented Planning for LLM-Powered Interactive Recommender Agent</h2><p><strong>Authors:Haocheng Yu, Yaxiong Wu, Hao Wang, Wei Guo, Yong Liu, Yawen Li, Yuyang Ye, Junping Du, Enhong Chen</strong></p>
<p>Interactive recommendation is a typical information-seeking task that allows users to interactively express their needs through natural language and obtain personalized recommendations. Large language model-powered (LLM-powered) agents have become a new paradigm in interactive recommendations, effectively capturing usersâ€™ real-time needs and enhancing personalized experiences. However, due to limited planning and generalization capabilities, existing formulations of LLM-powered interactive recommender agents struggle to effectively address diverse and complex user intents, such as intuitive, unrefined, or occasionally ambiguous requests. To tackle this challenge, we propose a novel thought-augmented interactive recommender agent system (TAIRA) that addresses complex user intents through distilled thought patterns. Specifically, TAIRA is designed as an LLM-powered multi-agent system featuring a manager agent that orchestrates recommendation tasks by decomposing user needs and planning subtasks, with its planning capacity strengthened through Thought Pattern Distillation (TPD), a thought-augmentation method that extracts high-level thoughts from the agentâ€™s and human expertsâ€™ experiences. Moreover, we designed a set of user simulation schemes to generate personalized queries of different difficulties and evaluate the recommendations based on specific datasets. Through comprehensive experiments conducted across multiple datasets, TAIRA exhibits significantly enhanced performance compared to existing methods. Notably, TAIRA shows a greater advantage on more challenging tasks while generalizing effectively on novel tasks, further validating its superiority in managing complex user intents within interactive recommendation systems. The code is publicly available at:<a target="_blank" rel="noopener" href="https://github.com/Alcein/TAIRA">https://github.com/Alcein/TAIRA</a>. </p>
<blockquote>
<p>äº’åŠ¨æ¨èæ˜¯ä¸€ç§å…¸å‹çš„ä¿¡æ¯æœç´¢ä»»åŠ¡ï¼Œå…è®¸ç”¨æˆ·é€šè¿‡è‡ªç„¶è¯­è¨€è¿›è¡Œäº’åŠ¨è¡¨è¾¾ä»–ä»¬çš„éœ€æ±‚ï¼Œå¹¶è·å¾—ä¸ªæ€§åŒ–çš„æ¨èã€‚ä»¥å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä¸ºåŠ¨åŠ›çš„ä»£ç†å·²æˆä¸ºäº’åŠ¨æ¨èçš„æ–°èŒƒå¼ï¼Œèƒ½å¤Ÿæœ‰æ•ˆæ•æ‰ç”¨æˆ·çš„å®æ—¶éœ€æ±‚å¹¶å¢å¼ºä¸ªæ€§åŒ–ä½“éªŒã€‚ç„¶è€Œï¼Œç”±äºè§„åˆ’å’Œæ³›åŒ–èƒ½åŠ›çš„é™åˆ¶ï¼Œç°æœ‰çš„LLMé©±åŠ¨å‹äº’åŠ¨æ¨èä»£ç†éš¾ä»¥æœ‰æ•ˆåº”å¯¹å¤šæ ·ä¸”å¤æ‚çš„ç”¨æˆ·æ„å›¾ï¼Œå¦‚ç›´è§‰æ€§ã€æœªå®Œæˆæˆ–å¶å°”æ¨¡ç³Šçš„è¯·æ±‚ã€‚ä¸ºäº†åº”å¯¹è¿™ä¸€æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°å‹æ€æƒ³å¢å¼ºå‹äº’åŠ¨æ¨èä»£ç†ç³»ç»Ÿï¼ˆTAIRAï¼‰ï¼Œå®ƒé€šè¿‡æç‚¼æ€æƒ³æ¨¡å¼æ¥åº”å¯¹å¤æ‚çš„ç”¨æˆ·æ„å›¾ã€‚å…·ä½“æ¥è¯´ï¼ŒTAIRAè¢«è®¾è®¡ä¸ºä¸€ä¸ªä»¥LLMä¸ºåŠ¨åŠ›çš„å¤šä»£ç†ç³»ç»Ÿï¼Œå…·æœ‰ä¸€ä¸ªç®¡ç†ä»£ç†ï¼Œé€šè¿‡åˆ†è§£ç”¨æˆ·éœ€æ±‚å¹¶è§„åˆ’å­ä»»åŠ¡æ¥åè°ƒæ¨èä»»åŠ¡ã€‚å…¶è§„åˆ’èƒ½åŠ›é€šè¿‡æ€æƒ³æ¨¡å¼è’¸é¦ï¼ˆTPDï¼‰å¢å¼ºï¼Œè¿™æ˜¯ä¸€ç§æ€æƒ³å¢å¼ºæ–¹æ³•ï¼Œä»ä»£ç†å’Œäººç±»ä¸“å®¶çš„ç»éªŒä¸­æå–é«˜çº§æ€æƒ³ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è®¾è®¡äº†ä¸€ç³»åˆ—ç”¨æˆ·æ¨¡æ‹Ÿæ–¹æ¡ˆï¼Œä»¥ç”Ÿæˆä¸åŒéš¾åº¦çš„ä¸ªæ€§åŒ–æŸ¥è¯¢ï¼Œå¹¶æ ¹æ®ç‰¹å®šæ•°æ®é›†å¯¹æ¨èè¿›è¡Œè¯„ä¼°ã€‚é€šè¿‡å¤šä¸ªæ•°æ®é›†è¿›è¡Œçš„ç»¼åˆå®éªŒè¡¨æ˜ï¼ŒTAIRAä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼Œè¡¨ç°å‡ºæ˜¾è‘—å¢å¼ºçš„æ€§èƒ½ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼ŒTAIRAåœ¨æ›´å…·æŒ‘æˆ˜æ€§çš„ä»»åŠ¡ä¸Šæ˜¾ç¤ºå‡ºæ›´å¤§çš„ä¼˜åŠ¿ï¼Œå¹¶åœ¨æ–°å‹ä»»åŠ¡ä¸Šå®ç°æœ‰æ•ˆæ³›åŒ–ï¼Œè¿›ä¸€æ­¥éªŒè¯äº†å…¶åœ¨äº’åŠ¨æ¨èç³»ç»Ÿä¸­ç®¡ç†å¤æ‚ç”¨æˆ·æ„å›¾çš„ä¼˜è¶Šæ€§ã€‚ä»£ç å…¬å¼€åœ¨ï¼š<a target="_blank" rel="noopener" href="https://github.com/Alcein/TAIRA">https://github.com/Alcein/TAIRA</a>ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.23485v1">PDF</a> </p>
<p><strong>Summary</strong><br>äº’åŠ¨æ¨èæ˜¯ä¸€ç§å…¸å‹çš„ä¿¡æ¯æ£€ç´¢ä»»åŠ¡ï¼Œå…è®¸ç”¨æˆ·é€šè¿‡è‡ªç„¶è¯­è¨€è¿›è¡Œäº’åŠ¨è¡¨è¾¾éœ€æ±‚å¹¶è·å¾—ä¸ªæ€§åŒ–æ¨èã€‚å¤§å‹è¯­è¨€æ¨¡å‹é©±åŠ¨çš„ä»£ç†å·²æˆä¸ºäº’åŠ¨æ¨èçš„æ–°æ¨¡å¼ï¼Œèƒ½æœ‰æ•ˆæ•æ‰ç”¨æˆ·çš„å®æ—¶éœ€æ±‚å¹¶å¢å¼ºä¸ªæ€§åŒ–ä½“éªŒã€‚ä¸ºè§£å†³ç°æœ‰å¤§å‹è¯­è¨€æ¨¡å‹é©±åŠ¨çš„äº’åŠ¨æ¨èä»£ç†åœ¨åº”å¯¹å¤æ‚ç”¨æˆ·éœ€æ±‚æ–¹é¢çš„å±€é™æ€§ï¼Œæˆ‘ä»¬æå‡ºäº†æ€æƒ³å¢å¼ºçš„äº’åŠ¨æ¨èä»£ç†ç³»ç»Ÿï¼ˆTAIRAï¼‰ï¼Œé€šè¿‡æç‚¼æ€æƒ³æ¨¡å¼æ¥åº”å¯¹å¤æ‚çš„ç”¨æˆ·éœ€æ±‚ã€‚TAIRAè¢«è®¾è®¡ä¸ºä¸€ä¸ªå¤šä»£ç†ç³»ç»Ÿï¼Œé€šè¿‡åˆ†è§£ç”¨æˆ·éœ€æ±‚å¹¶è§„åˆ’å­ä»»åŠ¡æ¥åè°ƒæ¨èä»»åŠ¡ï¼Œå…¶è§„åˆ’èƒ½åŠ›é€šè¿‡æ€æƒ³æ¨¡å¼è’¸é¦å¾—åˆ°å¢å¼ºã€‚å®éªŒè¡¨æ˜ï¼ŒTAIRAåœ¨åº”å¯¹ä¸åŒéš¾åº¦çš„ä¸ªæ€§åŒ–æŸ¥è¯¢å’Œç‰¹å®šæ•°æ®é›†çš„è¯„ä»·æ–¹é¢è¡¨ç°å‡ºæ˜¾è‘—ä¼˜åŠ¿ï¼Œå°¤å…¶åœ¨æ›´å…·æŒ‘æˆ˜æ€§çš„ä»»åŠ¡ä¸Šè¡¨ç°å‡ºæ›´å¤§çš„ä¼˜åŠ¿å¹¶åœ¨æ–°é¢–ä»»åŠ¡ä¸Šå®ç°äº†æœ‰æ•ˆçš„æ³›åŒ–ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>äº’åŠ¨æ¨èå…è®¸ç”¨æˆ·é€šè¿‡è‡ªç„¶è¯­è¨€äº’åŠ¨è¡¨è¾¾éœ€æ±‚å¹¶è·å¾—ä¸ªæ€§åŒ–æ¨èã€‚</li>
<li>å¤§å‹è¯­è¨€æ¨¡å‹é©±åŠ¨çš„ä»£ç†å·²æˆä¸ºäº’åŠ¨æ¨èçš„æ–°æ¨¡å¼ã€‚</li>
<li>ç°æœ‰å¤§å‹è¯­è¨€æ¨¡å‹é©±åŠ¨çš„äº’åŠ¨æ¨èä»£ç†åœ¨åº”å¯¹å¤æ‚ç”¨æˆ·éœ€æ±‚æ–¹é¢å­˜åœ¨æŒ‘æˆ˜ã€‚</li>
<li>æå‡ºäº†æ€æƒ³å¢å¼ºçš„äº’åŠ¨æ¨èä»£ç†ç³»ç»Ÿï¼ˆTAIRAï¼‰ä»¥åº”å¯¹å¤æ‚ç”¨æˆ·éœ€æ±‚ã€‚</li>
<li>TAIRAæ˜¯ä¸€ä¸ªå¤šä»£ç†ç³»ç»Ÿï¼Œå…·æœ‰åˆ†è§£å¹¶åè°ƒæ¨èä»»åŠ¡çš„èƒ½åŠ›ã€‚</li>
<li>TAIRAé€šè¿‡æ€æƒ³æ¨¡å¼è’¸é¦å¢å¼ºè§„åˆ’èƒ½åŠ›ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.23485">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-20d3789d5697902e5168c05ac36608ba.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-0ad39b26927294a1c1a36b793852f8e9.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-5800f814bc239406ce09b74743356602.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-ad5001a0d06221d184227972116d43e5.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-0e7b4fc40c9ea7600f0b4875fc5d1161.jpg" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="IR3D-Bench-Evaluating-Vision-Language-Model-Scene-Understanding-as-Agentic-Inverse-Rendering"><a href="#IR3D-Bench-Evaluating-Vision-Language-Model-Scene-Understanding-as-Agentic-Inverse-Rendering" class="headerlink" title="IR3D-Bench: Evaluating Vision-Language Model Scene Understanding as   Agentic Inverse Rendering"></a>IR3D-Bench: Evaluating Vision-Language Model Scene Understanding as   Agentic Inverse Rendering</h2><p><strong>Authors:Parker Liu, Chenxin Li, Zhengxin Li, Yipeng Wu, Wuyang Li, Zhiqin Yang, Zhenyuan Zhang, Yunlong Lin, Sirui Han, Brandon Y. Feng</strong></p>
<p>Vision-language models (VLMs) excel at descriptive tasks, but whether they truly understand scenes from visual observations remains uncertain. We introduce IR3D-Bench, a benchmark challenging VLMs to demonstrate understanding through active creation rather than passive recognition. Grounded in the analysis-by-synthesis paradigm, IR3D-Bench tasks Vision-Language Agents (VLAs) with actively using programming and rendering tools to recreate the underlying 3D structure of an input image, achieving agentic inverse rendering through tool use. This â€œunderstanding-by-creatingâ€ approach probes the tool-using generative capacity of VLAs, moving beyond the descriptive or conversational capacity measured by traditional scene understanding benchmarks. We provide a comprehensive suite of metrics to evaluate geometric accuracy, spatial relations, appearance attributes, and overall plausibility. Initial experiments on agentic inverse rendering powered by various state-of-the-art VLMs highlight current limitations, particularly in visual precision rather than basic tool usage. IR3D-Bench, including data and evaluation protocols, is released to facilitate systematic study and development of tool-using VLAs towards genuine scene understanding by creating. </p>
<blockquote>
<p>è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMsï¼‰åœ¨æè¿°æ€§ä»»åŠ¡æ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œä½†å®ƒä»¬æ˜¯å¦çœŸæ­£é€šè¿‡è§†è§‰è§‚å¯Ÿç†è§£åœºæ™¯ä»å­˜åœ¨ä¸ç¡®å®šæ€§ã€‚æˆ‘ä»¬å¼•å…¥äº†IR3D-Benchï¼Œè¿™æ˜¯ä¸€ä¸ªæŒ‘æˆ˜VLMsçš„åŸºå‡†æµ‹è¯•ï¼Œé€šè¿‡ä¸»åŠ¨åˆ›é€ è€Œéè¢«åŠ¨è¯†åˆ«æ¥å±•ç¤ºç†è§£åŠ›ã€‚åŸºäºåˆæˆåˆ†æèŒƒå¼ï¼ŒIR3D-Benchè¦æ±‚è§†è§‰è¯­è¨€ä»£ç†ï¼ˆVLAsï¼‰ç§¯æä½¿ç”¨ç¼–ç¨‹å’Œæ¸²æŸ“å·¥å…·æ¥é‡æ–°åˆ›å»ºè¾“å…¥å›¾åƒçš„åŸºç¡€3Dç»“æ„ï¼Œé€šè¿‡å·¥å…·ä½¿ç”¨å®ç°ä»£ç†é€†å‘æ¸²æŸ“ã€‚è¿™ç§â€œé€šè¿‡åˆ›é€ æ¥ç†è§£â€çš„æ–¹æ³•æ¢ç´¢äº†VLAsçš„å·¥å…·ä½¿ç”¨ç”Ÿæˆèƒ½åŠ›ï¼Œè¶…è¶Šäº†ä¼ ç»Ÿåœºæ™¯ç†è§£åŸºå‡†æµ‹è¯•æ‰€è¡¡é‡çš„æè¿°æ€§æˆ–ä¼šè¯èƒ½åŠ›ã€‚æˆ‘ä»¬æä¾›äº†ä¸€å¥—ç»¼åˆæŒ‡æ ‡æ¥è¯„ä¼°å‡ ä½•ç²¾åº¦ã€ç©ºé—´å…³ç³»ã€å¤–è§‚å±æ€§å’Œæ•´ä½“å¯è¡Œæ€§ã€‚åœ¨å„ç§æœ€å…ˆè¿›çš„VLMsé©±åŠ¨çš„ä»£ç†é€†å‘æ¸²æŸ“çš„åˆæ­¥å®éªŒçªå‡ºäº†å½“å‰çš„å±€é™æ€§ï¼Œç‰¹åˆ«æ˜¯åœ¨è§†è§‰ç²¾åº¦è€Œä¸æ˜¯åŸºæœ¬å·¥å…·ä½¿ç”¨æ–¹é¢ã€‚IR3D-BenchåŒ…æ‹¬æ•°æ®å’Œè¯„ä¼°åè®®ï¼Œæ—¨åœ¨ä¿ƒè¿›å·¥å…·ä½¿ç”¨VLAsçš„ç³»ç»Ÿç ”ç©¶å’Œå‘å±•ï¼Œä»¥å®ç°é€šè¿‡åˆ›é€ çœŸæ­£ç†è§£åœºæ™¯ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.23329v1">PDF</a> Project Page: <a target="_blank" rel="noopener" href="https://ir3d-bench.github.io/">https://ir3d-bench.github.io/</a></p>
<p><strong>Summary</strong><br>åœ¨è§†è§‰è§‚å¯Ÿåœºæ™¯ä¸­ï¼Œè§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMsï¼‰çš„ç†è§£ç¨‹åº¦ä»å­˜åœ¨ä¸ç¡®å®šæ€§ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬æ¨å‡ºäº†IR3D-BenchåŸºå‡†æµ‹è¯•ï¼ŒæŒ‘æˆ˜VLMsé€šè¿‡ä¸»åŠ¨åˆ›é€ è€Œéè¢«åŠ¨è¯†åˆ«æ¥å±•ç¤ºç†è§£ã€‚è¯¥åŸºå‡†æµ‹è¯•åŸºäºåˆ†æç»¼åˆèŒƒå¼ï¼Œè¦æ±‚è§†è§‰è¯­è¨€ä»£ç†ï¼ˆVLAsï¼‰ç§¯æä½¿ç”¨ç¼–ç¨‹å’Œæ¸²æŸ“å·¥å…·é‡æ–°åˆ›å»ºè¾“å…¥å›¾åƒçš„åº•å±‚3Dç»“æ„ï¼Œé€šè¿‡å·¥å…·ä½¿ç”¨å®ç°ä»£ç†é€†å‘æ¸²æŸ“ã€‚è¿™ç§â€œé€šè¿‡åˆ›é€ æ¥ç†è§£â€çš„æ–¹æ³•æ¢ç´¢äº†VLAsçš„å·¥å…·ä½¿ç”¨ç”Ÿæˆèƒ½åŠ›ï¼Œè¶…è¶Šäº†ä¼ ç»Ÿåœºæ™¯ç†è§£åŸºå‡†æµ‹è¯•æ‰€è¡¡é‡çš„æè¿°æ€§æˆ–ä¼šè¯èƒ½åŠ›ã€‚æˆ‘ä»¬æä¾›äº†ä¸€å¥—ç»¼åˆæŒ‡æ ‡æ¥è¯„ä¼°å‡ ä½•ç²¾åº¦ã€ç©ºé—´å…³ç³»ã€å¤–è§‚å±æ€§å’Œæ•´ä½“å¯è¡Œæ€§ã€‚åˆæ­¥å®éªŒè¡¨æ˜ï¼Œå½“å‰æœ€å…ˆè¿›çš„VLMsåœ¨è§†è§‰ç²¾åº¦æ–¹é¢å­˜åœ¨å±€é™ï¼Œè€ŒéåŸºæœ¬å·¥å…·ä½¿ç”¨æ–¹é¢ã€‚IR3D-BenchåŒ…æ‹¬æ•°æ®å’Œè¯„ä¼°åè®®ï¼Œæ—¨åœ¨ä¿ƒè¿›å·¥å…·ä½¿ç”¨VLAsçš„ç³»ç»Ÿç ”ç©¶å’Œå‘å±•ï¼Œä»¥å®ç°é€šè¿‡åˆ›é€ çœŸæ­£ç†è§£åœºæ™¯ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMsï¼‰åœ¨æè¿°ä»»åŠ¡ä¸Šè¡¨ç°å‡ºè‰²ï¼Œä½†å®ƒä»¬æ˜¯å¦çœŸæ­£ç†è§£ä»è§†è§‰è§‚å¯Ÿä¸­è·å¾—çš„åœºæ™¯ä»å­˜åœ¨ç–‘é—®ã€‚</li>
<li>IR3D-BenchåŸºå‡†æµ‹è¯•æ—¨åœ¨æŒ‘æˆ˜VLMsé€šè¿‡ä¸»åŠ¨åˆ›é€ æ¥å±•ç¤ºç†è§£ï¼Œè€Œä¸ä»…ä»…æ˜¯è¢«åŠ¨è¯†åˆ«ã€‚</li>
<li>IR3D-BenchåŸºäºåˆ†æç»¼åˆèŒƒå¼ï¼Œè¦æ±‚VLAsä½¿ç”¨ç¼–ç¨‹å’Œæ¸²æŸ“å·¥å…·é‡æ–°åˆ›å»ºè¾“å…¥å›¾åƒçš„åº•å±‚3Dç»“æ„ã€‚</li>
<li>â€œé€šè¿‡åˆ›é€ æ¥ç†è§£â€çš„æ–¹æ³•å¼ºè°ƒVLAsçš„å·¥å…·ä½¿ç”¨ç”Ÿæˆèƒ½åŠ›ã€‚</li>
<li>åˆæ­¥å®éªŒæ­ç¤ºäº†å½“å‰VLMsåœ¨è§†è§‰ç²¾åº¦æ–¹é¢çš„å±€é™ï¼Œè€ŒéåŸºæœ¬å·¥å…·ä½¿ç”¨ä¸Šçš„é—®é¢˜ã€‚</li>
<li>IR3D-BenchåŒ…æ‹¬æ•°æ®å’Œè¯„ä¼°åè®®ï¼Œä»¥æ¨åŠ¨VLAsçš„ç³»ç»Ÿç ”ç©¶å’Œå‘å±•ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.23329">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-52ed67073a50c2ba5ea481c1597e6552.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-0ffa5ecb21e086e1ecc41686bd6e7e1a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-15e951f62ca2401d30e0d84723485af3.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-5bb93767493d4623e1604f60f1014bc6.jpg" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1><h2 id="GATSim-Urban-Mobility-Simulation-with-Generative-Agents"><a href="#GATSim-Urban-Mobility-Simulation-with-Generative-Agents" class="headerlink" title="GATSim: Urban Mobility Simulation with Generative Agents"></a>GATSim: Urban Mobility Simulation with Generative Agents</h2><p><strong>Authors:Qi Liu, Can Li, Wanjing Ma</strong></p>
<p>Traditional agent-based urban mobility simulations rely on rigid rule-based systems that fail to capture the complexity, adaptability, and behavioral diversity characteristic of human travel decision-making. Recent advances in large language models and AI agent technology offer opportunities to create agents with reasoning capabilities, persistent memory, and adaptive learning mechanisms. We propose GATSim (Generative-Agent Transport Simulation), a novel framework that leverages these advances to create generative agents with rich behavioral characteristics for urban mobility simulation. Unlike conventional approaches, GATSim agents possess diverse socioeconomic attributes, individual lifestyles, and evolving preferences that shape their mobility decisions through psychologically-informed memory systems, tool usage capabilities, and lifelong learning mechanisms. The main contributions of this study include: (1) a comprehensive architecture combining an urban mobility foundation model with agent cognitive systems and transport simulation environment, (2) a fully functional prototype implementation, and (3) systematic validation demonstrating that generative agents produce believable travel behaviors. Through designed reflection processes, generative agents in this study can transform specific travel experiences into generalized insights, enabling realistic behavioral adaptation over time with specialized mechanisms for activity planning and real-time reactive behaviors tailored to urban mobility contexts. Experiments show that generative agents perform competitively with human annotators in mobility scenarios while naturally producing macroscopic traffic evolution patterns. The code for the prototype system is shared at <a target="_blank" rel="noopener" href="https://github.com/qiliuchn/gatsim">https://github.com/qiliuchn/gatsim</a>. </p>
<blockquote>
<p>ä¼ ç»ŸåŸºäºä»£ç†çš„åŸå¸‚äº¤é€šæ¨¡æ‹Ÿä¾èµ–äºåƒµåŒ–çš„åŸºäºè§„åˆ™çš„ç³»ç»Ÿï¼Œè¿™äº›ç³»ç»Ÿæ— æ³•æ•æ‰åˆ°äººç±»å‡ºè¡Œå†³ç­–ç‰¹å¾çš„å¤æ‚æ€§ã€é€‚åº”æ€§å’Œè¡Œä¸ºå¤šæ ·æ€§ã€‚å¤§å‹è¯­è¨€æ¨¡å‹å’ŒAIä»£ç†æŠ€æœ¯çš„æœ€æ–°è¿›å±•æä¾›äº†åˆ›å»ºå…·æœ‰æ¨ç†èƒ½åŠ›ã€æŒä¹…æ€§è®°å¿†å’Œè‡ªé€‚åº”å­¦ä¹ æœºåˆ¶çš„ä»£ç†çš„æœºä¼šã€‚æˆ‘ä»¬æå‡ºäº†GATSimï¼ˆç”Ÿæˆå¼äº¤é€šæ¨¡æ‹Ÿï¼‰ï¼Œè¿™æ˜¯ä¸€ä¸ªåˆ©ç”¨è¿™äº›æŠ€æœ¯åˆ›å»ºå…·æœ‰ä¸°å¯Œè¡Œä¸ºç‰¹å¾çš„ç”Ÿæˆå¼ä»£ç†ï¼Œç”¨äºåŸå¸‚äº¤é€šæ¨¡æ‹Ÿçš„æ–°å‹æ¡†æ¶ã€‚ä¸ä¼ ç»Ÿçš„äº¤é€šæ¨¡æ‹Ÿæ–¹æ³•ä¸åŒï¼ŒGATSimä¸­çš„ç”Ÿæˆå¼ä»£ç†æ‹¥æœ‰å¤šæ ·åŒ–çš„ç¤¾ä¼šç»æµå±æ€§ã€ä¸ªäººç”Ÿæ´»æ–¹å¼å’Œä¸æ–­å‘å±•çš„åå¥½ï¼Œé€šè¿‡å¿ƒç†å­¦æŒ‡å¯¼ä¸‹çš„è®°å¿†ç³»ç»Ÿã€å·¥å…·ä½¿ç”¨èƒ½åŠ›å’Œç»ˆèº«å­¦ä¹ æœºåˆ¶æ¥å½±å“ä»–ä»¬çš„å‡ºè¡Œå†³ç­–ã€‚è¯¥ç ”ç©¶çš„ä¸»è¦è´¡çŒ®åŒ…æ‹¬ï¼šï¼ˆ1ï¼‰ä¸€ä¸ªç»“åˆäº†åŸå¸‚äº¤é€šåŸºç¡€æ¨¡å‹ä¸ä»£ç†è®¤çŸ¥ç³»ç»Ÿå’Œäº¤é€šæ¨¡æ‹Ÿç¯å¢ƒçš„ç»¼åˆæ¶æ„ï¼Œï¼ˆ2ï¼‰ä¸€ä¸ªåŠŸèƒ½é½å…¨çš„åŸå‹å®ç°ï¼Œï¼ˆ3ï¼‰ç³»ç»Ÿæ€§éªŒè¯è¡¨æ˜ç”Ÿæˆå¼ä»£ç†å¯ä»¥äº§ç”Ÿå¯ä¿¡çš„å‡ºè¡Œè¡Œä¸ºã€‚æœ¬ç ”ç©¶ä¸­çš„ç”Ÿæˆå¼ä»£ç†èƒ½å¤Ÿé€šè¿‡è®¾è®¡çš„åæ€è¿‡ç¨‹å°†ç‰¹å®šçš„æ—…è¡Œç»å†è½¬åŒ–ä¸ºä¸€èˆ¬æ€§è§è§£ï¼Œå®ç°éšæ—¶é—´æ¨ç§»çš„å®é™…è¡Œä¸ºé€‚åº”ï¼Œå¹¶å…·æœ‰é’ˆå¯¹åŸå¸‚å‡ºè¡Œç¯å¢ƒçš„æ´»åŠ¨è§„åˆ’å’Œå®æ—¶ååº”è¡Œä¸ºçš„ä¸“é—¨æœºåˆ¶ã€‚å®éªŒè¡¨æ˜ï¼Œåœ¨äº¤é€šåœºæ™¯ä¸­ï¼Œç”Ÿæˆå¼ä»£ç†çš„è¡¨ç°ä¸äººç±»æ³¨é‡Šå™¨ç›¸å½“ï¼Œå¹¶èƒ½è‡ªç„¶åœ°äº§ç”Ÿå®è§‚çš„äº¤é€šæ¼”å˜æ¨¡å¼ã€‚è¯¥åŸå‹ç³»ç»Ÿçš„ä»£ç å…±äº«åœ¨<a target="_blank" rel="noopener" href="https://github.com/qiliuchn/gatsim%E4%B8%8A%E3%80%82">https://github.com/qiliuchn/gatsimä¸Šã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.23306v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºä¸€ç§æ–°çš„åŸå¸‚å‡ºè¡Œä»¿çœŸæ¡†æ¶GATSimï¼ˆç”Ÿæˆå¼ä»£ç†äº¤é€šä»¿çœŸï¼‰ï¼Œè¯¥æ¡†æ¶åˆ©ç”¨å…ˆè¿›çš„è¯­è¨€æ¨¡å‹å’ŒAIä»£ç†æŠ€æœ¯ï¼Œåˆ›å»ºå…·æœ‰ä¸°å¯Œè¡Œä¸ºç‰¹å¾çš„ç”Ÿæˆå¼ä»£ç†æ¥è¿›è¡ŒåŸå¸‚å‡ºè¡Œä»¿çœŸã€‚ä¸ä¼ ç»Ÿä»¿çœŸæ–¹æ³•ä¸åŒï¼ŒGATSimçš„ä»£ç†æ‹¥æœ‰å¤šæ ·çš„ç¤¾ä¼šç»æµå±æ€§ã€ä¸ªäººç”Ÿæ´»æ–¹å¼å’Œä¸æ–­å˜åŒ–çš„åå¥½ï¼Œé€šè¿‡å¿ƒç†æ„ŸçŸ¥çš„è®°å¿†ç³»ç»Ÿã€å·¥å…·ä½¿ç”¨èƒ½åŠ›å’Œç»ˆèº«å­¦ä¹ æœºåˆ¶æ¥å½±å“å‡ºè¡Œå†³ç­–ã€‚ç ”ç©¶çš„ä¸»è¦è´¡çŒ®åŒ…æ‹¬ï¼šç»¼åˆæ€§æ¶æ„ã€åŸå‹å®ç°å’Œç³»ç»ŸéªŒè¯ã€‚ç”Ÿæˆå¼ä»£ç†èƒ½å¤Ÿé€šè¿‡è®¾è®¡åæ€è¿‡ç¨‹å°†ç‰¹å®šå‡ºè¡Œç»éªŒè½¬åŒ–ä¸ºé€šç”¨è§è§£ï¼Œå®ç°éšæ—¶é—´å˜åŒ–çš„ç°å®è¡Œä¸ºé€‚åº”ï¼Œå¹¶å…·å¤‡é’ˆå¯¹åŸå¸‚å‡ºè¡Œç¯å¢ƒçš„ä¸“é—¨æ´»åŠ¨è§„åˆ’å’Œå®æ—¶ååº”è¡Œä¸ºæœºåˆ¶ã€‚å®éªŒè¡¨æ˜ï¼Œç”Ÿæˆå¼ä»£ç†åœ¨äººç±»å‡ºè¡Œåœºæ™¯ä¸­çš„è¡¨ç°å…·æœ‰ç«äº‰åŠ›ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>GATSimåˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹å’ŒAIæŠ€æœ¯åˆ›å»ºç”Ÿæˆå¼ä»£ç†è¿›è¡ŒåŸå¸‚å‡ºè¡Œä»¿çœŸã€‚</li>
<li>ç”Ÿæˆå¼ä»£ç†å…·æœ‰å¤šæ ·çš„ç¤¾ä¼šç»æµå±æ€§ã€ä¸ªäººç”Ÿæ´»æ–¹å¼å’Œå˜åŒ–çš„åå¥½ï¼Œå½±å“å‡ºè¡Œå†³ç­–ã€‚</li>
<li>ç»¼åˆæ¶æ„ç»“åˆäº†åŸå¸‚å‡ºè¡ŒåŸºç¡€æ¨¡å‹ä¸ä»£ç†è®¤çŸ¥ç³»ç»Ÿå’Œäº¤é€šä»¿çœŸç¯å¢ƒã€‚</li>
<li>åŸå‹å®ç°å…·å¤‡åŠŸèƒ½å®Œå¤‡æ€§ã€‚</li>
<li>ç³»ç»ŸéªŒè¯æ˜¾ç¤ºç”Ÿæˆå¼ä»£ç†èƒ½å±•ç°å¯ä¿¡çš„å‡ºè¡Œè¡Œä¸ºã€‚</li>
<li>ç”Ÿæˆå¼ä»£ç†èƒ½å°†ç‰¹å®šå‡ºè¡Œç»éªŒè½¬åŒ–ä¸ºé€šç”¨è§è§£ï¼Œå®ç°è¡Œä¸ºé€‚åº”å’Œè§„åˆ’ååº”ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.23306">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-ead8fc018b156684a8bc343f3088866b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-0fb8c80aa55733d0aca15c6bc15e7cc4.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-dc9f2d2a768677e2b631d3e544313dfb.jpg" align="middle">
</details>


<h1 id="-9"><a href="#-9" class="headerlink" title=""></a></h1><h2 id="CARTS-Collaborative-Agents-for-Recommendation-Textual-Summarization"><a href="#CARTS-Collaborative-Agents-for-Recommendation-Textual-Summarization" class="headerlink" title="CARTS: Collaborative Agents for Recommendation Textual Summarization"></a>CARTS: Collaborative Agents for Recommendation Textual Summarization</h2><p><strong>Authors:Jiao Chen, Kehui Yao, Reza Yousefi Maragheh, Kai Zhao, Jianpeng Xu, Jason Cho, Evren Korpeoglu, Sushant Kumar, Kannan Achan</strong></p>
<p>Current recommendation systems often require some form of textual data summarization, such as generating concise and coherent titles for product carousels or other grouped item displays. While large language models have shown promise in NLP domains for textual summarization, these approaches do not directly apply to recommendation systems, where explanations must be highly relevant to the core features of item sets, adhere to strict word limit constraints. In this paper, we propose CARTS (Collaborative Agents for Recommendation Textual Summarization), a multi-agent LLM framework designed for structured summarization in recommendation systems. CARTS decomposes the task into three stages-Generation Augmented Generation (GAG), refinement circle, and arbitration, where successive agent roles are responsible for extracting salient item features, iteratively refining candidate titles based on relevance and length feedback, and selecting the final title through a collaborative arbitration process. Experiments on large-scale e-commerce data and live A&#x2F;B testing show that CARTS significantly outperforms single-pass and chain-of-thought LLM baselines, delivering higher title relevance and improved user engagement metrics. </p>
<blockquote>
<p>å½“å‰æ¨èç³»ç»Ÿé€šå¸¸éœ€è¦æŸç§å½¢å¼çš„æ–‡æœ¬æ•°æ®æ‘˜è¦ï¼Œä¾‹å¦‚ä¸ºäº§å“è½®æ’­å›¾æˆ–å…¶ä»–åˆ†ç»„é¡¹ç›®æ˜¾ç¤ºç”Ÿæˆç®€æ´è¿è´¯çš„æ ‡é¢˜ã€‚è™½ç„¶å¤§å‹è¯­è¨€æ¨¡å‹åœ¨NLPé¢†åŸŸçš„æ–‡æœ¬æ‘˜è¦æ–¹é¢æ˜¾ç¤ºå‡ºæ½œåŠ›ï¼Œä½†è¿™äº›æ–¹æ³•å¹¶ä¸ç›´æ¥é€‚ç”¨äºæ¨èç³»ç»Ÿï¼Œå› ä¸ºæ¨èç³»ç»Ÿçš„è§£é‡Šå¿…é¡»é«˜åº¦ç›¸å…³äºé¡¹ç›®é›†çš„æ ¸å¿ƒåŠŸèƒ½ï¼Œå¹¶å—åˆ°ä¸¥æ ¼çš„å­—æ•°é™åˆ¶çº¦æŸã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†CARTSï¼ˆæ¨èæ–‡æœ¬æ‘˜è¦åä½œä»£ç†ï¼ŒCollaborative Agents for Recommendation Textual Summarizationï¼‰ï¼Œè¿™æ˜¯ä¸€ä¸ªå¤šä»£ç†LLMæ¡†æ¶ï¼Œä¸“ä¸ºæ¨èç³»ç»Ÿä¸­çš„ç»“æ„åŒ–æ‘˜è¦è€Œè®¾è®¡ã€‚CARTSå°†ä»»åŠ¡åˆ†è§£ä¸ºä¸‰ä¸ªé˜¶æ®µï¼šç”Ÿæˆå¢å¼ºç”Ÿæˆï¼ˆGAGï¼‰ã€æ”¹è¿›å¾ªç¯å’Œä»²è£ï¼Œå…¶ä¸­è¿ç»­ä»£ç†è§’è‰²è´Ÿè´£æå–é‡è¦çš„é¡¹ç›®ç‰¹å¾ã€åŸºäºç›¸å…³æ€§å’Œé•¿åº¦åé¦ˆè¿­ä»£æ”¹è¿›å€™é€‰æ ‡é¢˜ï¼Œå¹¶é€šè¿‡åä½œä»²è£è¿‡ç¨‹é€‰æ‹©æœ€ç»ˆæ ‡é¢˜ã€‚åœ¨å¤§å‹ç”µå­å•†åŠ¡æ•°æ®å’Œå®æ—¶A&#x2F;Bæµ‹è¯•ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒCARTSåœ¨å•é€šé“å’Œæ€ç»´é“¾å¼LLMåŸºå‡†æµ‹è¯•æ–¹é¢è¡¨ç°å‡ºæ˜¾è‘—ä¼˜åŠ¿ï¼Œæé«˜äº†æ ‡é¢˜ç›¸å…³æ€§å’Œç”¨æˆ·å‚ä¸åº¦æŒ‡æ ‡ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.17765v2">PDF</a> </p>
<p><strong>æ€»ç»“</strong></p>
<p>æœ¬è®ºæ–‡é’ˆå¯¹æ¨èç³»ç»Ÿä¸­çš„æ–‡æœ¬æ‘˜è¦é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åä¸ºCARTSçš„å¤šæ™ºèƒ½ä½“LLMæ¡†æ¶ã€‚è¯¥æ¡†æ¶é€šè¿‡ä¸‰ä¸ªé˜¶æ®µå®Œæˆç»“æ„åŒ–æ‘˜è¦ä»»åŠ¡ï¼šç”Ÿæˆå¢å¼ºç”Ÿæˆé˜¶æ®µã€ç²¾ç»†åŒ–å¾ªç¯å’Œä»²è£é˜¶æ®µã€‚é€šè¿‡è¿ç»­çš„æ™ºèƒ½ä½“è§’è‰²è´Ÿè´£æå–é‡è¦é¡¹ç›®ç‰¹å¾ï¼ŒåŸºäºç›¸å…³æ€§å’Œé•¿åº¦åé¦ˆè¿›è¡Œè¿­ä»£ç²¾ç‚¼å€™é€‰æ ‡é¢˜ï¼Œå¹¶é€šè¿‡åä½œä»²è£è¿‡ç¨‹é€‰æ‹©æœ€ç»ˆæ ‡é¢˜ã€‚å®éªŒè¡¨æ˜ï¼ŒCARTSåœ¨å¤§å‹ç”µå­å•†åŠ¡æ•°æ®å’Œå®æ—¶A&#x2F;Bæµ‹è¯•ä¸­æ˜¾è‘—ä¼˜äºå•é€šé“å’Œé“¾å¼æ€ç»´LLMåŸºçº¿ï¼Œæé«˜äº†æ ‡é¢˜ç›¸å…³æ€§å’Œç”¨æˆ·å‚ä¸åº¦æŒ‡æ ‡ã€‚</p>
<p><strong>å…³é”®è§è§£</strong></p>
<ol>
<li>æ¨èç³»ç»Ÿéœ€è¦å¤„ç†æ–‡æœ¬æ‘˜è¦ï¼Œå¦‚ç”Ÿæˆäº§å“è½®æ’­æˆ–å…¶ä»–åˆ†ç»„é¡¹ç›®æ˜¾ç¤ºçš„ç®€æ´è¿è´¯æ ‡é¢˜ã€‚</li>
<li>å¤§å‹è¯­è¨€æ¨¡å‹åœ¨NLPé¢†åŸŸçš„æ–‡æœ¬æ‘˜è¦ä¸­æ˜¾ç¤ºå‡ºæ½œåŠ›ï¼Œä½†ç›´æ¥åº”ç”¨äºæ¨èç³»ç»Ÿçš„æ–¹æ³•å¹¶ä¸é€‚ç”¨ã€‚</li>
<li>æ¨èç³»ç»Ÿçš„è§£é‡Šå¿…é¡»é«˜åº¦ç›¸å…³äºé¡¹ç›®é›†çš„æ ¸å¿ƒç‰¹å¾ï¼Œå¹¶ç¬¦åˆä¸¥æ ¼çš„å­—æ•°é™åˆ¶ã€‚</li>
<li>CARTSæ˜¯ä¸€ä¸ªå¤šæ™ºèƒ½ä½“LLMæ¡†æ¶ï¼Œä¸“ä¸ºæ¨èç³»ç»Ÿä¸­çš„ç»“æ„åŒ–æ‘˜è¦è®¾è®¡ã€‚</li>
<li>CARTSå°†ä»»åŠ¡åˆ†è§£ä¸ºä¸‰ä¸ªé˜¶æ®µï¼šç”Ÿæˆå¢å¼ºç”Ÿæˆã€ç²¾ç»†åŒ–å¾ªç¯å’Œä»²è£ã€‚</li>
<li>é€šè¿‡å®éªŒå’Œå®æ—¶A&#x2F;Bæµ‹è¯•ï¼ŒCARTSæ˜¾è‘—ä¼˜äºå…¶ä»–æ–¹æ³•ï¼Œæé«˜äº†æ ‡é¢˜ç›¸å…³æ€§å’Œç”¨æˆ·å‚ä¸åº¦ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.17765">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-c4afbfe7e9ea4e5569f817271a3e5425.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b27ff79e3915f677a45d9ef1f54f73e1.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-6b871810ab18bb66b687cdecbda645fe.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-a253f3a0333aeac305599423db81f9cb.jpg" align="middle">
</details>


<h1 id="-10"><a href="#-10" class="headerlink" title=""></a></h1><h2 id="BIMgent-Towards-Autonomous-Building-Modeling-via-Computer-use-Agents"><a href="#BIMgent-Towards-Autonomous-Building-Modeling-via-Computer-use-Agents" class="headerlink" title="BIMgent: Towards Autonomous Building Modeling via Computer-use Agents"></a>BIMgent: Towards Autonomous Building Modeling via Computer-use Agents</h2><p><strong>Authors:Zihan Deng, Changyu Du, Stavros Nousias, AndrÃ© Borrmann</strong></p>
<p>Existing computer-use agents primarily focus on general-purpose desktop automation tasks, with limited exploration of their application in highly specialized domains. In particular, the 3D building modeling process in the Architecture, Engineering, and Construction (AEC) sector involves open-ended design tasks and complex interaction patterns within Building Information Modeling (BIM) authoring software, which has yet to be thoroughly addressed by current studies. In this paper, we propose BIMgent, an agentic framework powered by multimodal large language models (LLMs), designed to enable autonomous building model authoring via graphical user interface (GUI) operations. BIMgent automates the architectural building modeling process, including multimodal input for conceptual design, planning of software-specific workflows, and efficient execution of the authoring GUI actions. We evaluate BIMgent on real-world building modeling tasks, including both text-based conceptual design generation and reconstruction from existing building design. The design quality achieved by BIMgent was found to be reasonable. Its operations achieved a 32% success rate, whereas all baseline models failed to complete the tasks (0% success rate). Results demonstrate that BIMgent effectively reduces manual workload while preserving design intent, highlighting its potential for practical deployment in real-world architectural modeling scenarios. Project page: <a target="_blank" rel="noopener" href="https://tumcms.github.io/BIMgent.github.io/">https://tumcms.github.io/BIMgent.github.io/</a> </p>
<blockquote>
<p>ç°æœ‰è®¡ç®—æœºä½¿ç”¨ä»£ç†ä¸»è¦å…³æ³¨é€šç”¨æ¡Œé¢è‡ªåŠ¨åŒ–ä»»åŠ¡ï¼Œå¯¹å…¶åœ¨é«˜åº¦ä¸“ä¸šåŒ–é¢†åŸŸçš„åº”ç”¨æ¢ç´¢æœ‰é™ã€‚ç‰¹åˆ«æ˜¯åœ¨å»ºç­‘ã€å·¥ç¨‹å’Œå»ºç­‘ï¼ˆAECï¼‰é¢†åŸŸçš„3Då»ºç­‘å»ºæ¨¡è¿‡ç¨‹ä¸­ï¼Œæ¶‰åŠå¼€æ”¾è®¾è®¡ä»»åŠ¡å’Œå»ºç­‘ä¿¡æ¯å»ºæ¨¡ï¼ˆBIMï¼‰è®¾è®¡è½¯ä»¶å†…çš„å¤æ‚äº¤äº’æ¨¡å¼ï¼Œå°šæœªå¾—åˆ°å½“å‰ç ”ç©¶çš„å……åˆ†è§£å†³ã€‚æœ¬æ–‡æå‡ºBIMgentï¼Œè¿™æ˜¯ä¸€ä¸ªç”±å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰é©±åŠ¨çš„ä»£ç†æ¡†æ¶ï¼Œæ—¨åœ¨é€šè¿‡å›¾å½¢ç”¨æˆ·ç•Œé¢ï¼ˆGUIï¼‰æ“ä½œå®ç°è‡ªä¸»å»ºç­‘æ¨¡å‹åˆ›ä½œã€‚BIMgentè‡ªåŠ¨åŒ–å»ºç­‘å»ºæ¨¡è¿‡ç¨‹ï¼ŒåŒ…æ‹¬å¤šæ¨¡æ€è¾“å…¥æ¦‚å¿µè®¾è®¡ã€è½¯ä»¶ç‰¹å®šå·¥ä½œæµç¨‹çš„è§„åˆ’ä»¥åŠä½œè€…GUIåŠ¨ä½œçš„æœ‰æ•ˆæ‰§è¡Œã€‚æˆ‘ä»¬åœ¨ç°å®ä¸–ç•Œå»ºç­‘å»ºæ¨¡ä»»åŠ¡ä¸Šè¯„ä¼°äº†BIMgentï¼ŒåŒ…æ‹¬åŸºäºæ–‡æœ¬çš„æ¦‚å¿µè®¾è®¡ç”Ÿæˆå’Œä»ç°æœ‰è®¾è®¡ä¸­é‡å»ºã€‚BIMgentçš„è®¾è®¡è´¨é‡è¢«è®¤ä¸ºæ˜¯åˆç†çš„ã€‚å…¶æ“ä½œå®ç°äº†32%çš„æˆåŠŸç‡ï¼Œè€Œæ‰€æœ‰åŸºçº¿æ¨¡å‹å‡æœªèƒ½å®Œæˆä»»åŠ¡ï¼ˆæˆåŠŸç‡ä¸º0%ï¼‰ã€‚ç»“æœè¡¨æ˜ï¼ŒBIMgentåœ¨å‡å°‘æ‰‹åŠ¨å·¥ä½œé‡çš„åŒæ—¶ä¿æŒäº†è®¾è®¡æ„å›¾ï¼Œçªæ˜¾å…¶åœ¨ç°å®å»ºç­‘å»ºæ¨¡åœºæ™¯ä¸­çš„å®é™…åº”ç”¨æ½œåŠ›ã€‚é¡¹ç›®é¡µé¢ï¼š<a target="_blank" rel="noopener" href="https://tumcms.github.io/BIMgent.github.io/">https://tumcms.github.io/BIMgent.github.io/</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.07217v2">PDF</a> ICML 2025 Workshop on Computer Use Agents</p>
<p><strong>Summary</strong><br>BIMgentæ¡†æ¶åˆ©ç”¨å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰é©±åŠ¨ï¼Œæ—¨åœ¨é€šè¿‡å›¾å½¢ç”¨æˆ·ç•Œé¢ï¼ˆGUIï¼‰æ“ä½œå®ç°å»ºç­‘æ¨¡å‹çš„è‡ªä¸»åˆ›å»ºã€‚è¯¥æ¡†æ¶è‡ªåŠ¨åŒ–å»ºç­‘å»ºæ¨¡æµç¨‹ï¼ŒåŒ…æ‹¬æ¦‚å¿µè®¾è®¡çš„å¤šæ¨¡æ€è¾“å…¥ã€ç‰¹å®šè½¯ä»¶çš„å·¥ä½œæµè§„åˆ’ä»¥åŠé«˜æ•ˆæ‰§è¡ŒGUIåŠ¨ä½œã€‚åœ¨çœŸå®å»ºç­‘å»ºæ¨¡ä»»åŠ¡ä¸Šçš„è¯„ä¼°æ˜¾ç¤ºï¼ŒBIMgentçš„è®¾è®¡è´¨é‡è‰¯å¥½ï¼Œæ“ä½œæˆåŠŸç‡è¾¾åˆ°32%ï¼Œè€Œæ‰€æœ‰åŸºçº¿æ¨¡å‹å‡æœªèƒ½å®Œæˆä»»åŠ¡ï¼ˆæˆåŠŸç‡ä¸º0%ï¼‰ã€‚è¿™è¯æ˜äº†BIMgentåœ¨å‡å°‘æ‰‹åŠ¨å·¥ä½œé‡çš„åŒæ—¶ï¼Œæœ‰æ•ˆä¿æŒè®¾è®¡åˆè¡·ï¼Œå±•ç°äº†å…¶åœ¨çœŸå®å»ºç­‘å»ºæ¨¡åœºæ™¯ä¸­çš„éƒ¨ç½²æ½œåŠ›ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å½“å‰è®¡ç®—æœºä½¿ç”¨ä»£ç†ä¸»è¦é›†ä¸­åœ¨é€šç”¨æ¡Œé¢è‡ªåŠ¨åŒ–ä»»åŠ¡ä¸Šï¼Œç¼ºä¹é«˜åº¦ä¸“ä¸šåŒ–çš„åº”ç”¨é¢†åŸŸçš„æ¢ç´¢ã€‚ç‰¹åˆ«æ˜¯åœ¨å»ºç­‘ä¿¡æ¯å»ºæ¨¡ï¼ˆBIMï¼‰è½¯ä»¶çš„å¤æ‚äº¤äº’æ¨¡å¼æ–¹é¢å°šæœªå¾—åˆ°å……åˆ†ç ”ç©¶ã€‚</li>
<li>BIMgentæ˜¯ä¸€ä¸ªåŸºäºå¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹çš„ä»£ç†æ¡†æ¶ï¼Œæ—¨åœ¨é€šè¿‡å›¾å½¢ç”¨æˆ·ç•Œé¢ï¼ˆGUIï¼‰æ“ä½œå®ç°è‡ªä¸»çš„å»ºç­‘æ¨¡å‹åˆ›å»ºã€‚</li>
<li>BIMgentå¯ä»¥è‡ªåŠ¨åŒ–å»ºç­‘å»ºæ¨¡æµç¨‹ï¼ŒåŒ…æ‹¬æ¦‚å¿µè®¾è®¡çš„å¤šæ¨¡æ€è¾“å…¥ã€ç‰¹å®šè½¯ä»¶çš„å·¥ä½œæµè§„åˆ’ä»¥åŠGUIåŠ¨ä½œçš„å¿«é€Ÿæ‰§è¡Œã€‚</li>
<li>BIMgentçš„è®¾è®¡è´¨é‡è‰¯å¥½ï¼Œåœ¨å®é™…å»ºç­‘å»ºæ¨¡ä»»åŠ¡ä¸Šçš„æˆåŠŸç‡ä¸º32%ï¼Œæ˜¾ç¤ºå‡ºå…¶æ½œåŠ›ã€‚</li>
<li>ä¸æ‰€æœ‰åŸºçº¿æ¨¡å‹ç›¸æ¯”ï¼ŒBIMgentæ˜¯å”¯ä¸€èƒ½å¤Ÿå®Œæˆä»»åŠ¡çš„æ¨¡å‹ï¼Œå…¶ä»–æ¨¡å‹å‡æœªèƒ½å®ç°ä»»ä½•ä»»åŠ¡æˆåŠŸå®Œæˆï¼ˆæˆåŠŸç‡ä¸º0%ï¼‰ã€‚</li>
<li>BIMgentåœ¨å‡å°‘æ‰‹åŠ¨å·¥ä½œé‡çš„åŒæ—¶ä¿æŒäº†è®¾è®¡åˆè¡·ï¼Œå±•ç°äº†å…¶åœ¨çœŸå®åœºæ™¯ä¸­çš„å®ç”¨æ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.07217">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-0720d166ece1461c22566f948d3f9400.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a7f84ca0cacf92de71e147b1f3632525.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-eb5853986b7c8abb55d184a8642ce984.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-9601b400d26b53830406dba8039691fa.jpg" align="middle">
</details>


<h1 id="-11"><a href="#-11" class="headerlink" title=""></a></h1><h2 id="LibVulnWatch-A-Deep-Assessment-Agent-System-and-Leaderboard-for-Uncovering-Hidden-Vulnerabilities-in-Open-Source-AI-Libraries"><a href="#LibVulnWatch-A-Deep-Assessment-Agent-System-and-Leaderboard-for-Uncovering-Hidden-Vulnerabilities-in-Open-Source-AI-Libraries" class="headerlink" title="LibVulnWatch: A Deep Assessment Agent System and Leaderboard for   Uncovering Hidden Vulnerabilities in Open-Source AI Libraries"></a>LibVulnWatch: A Deep Assessment Agent System and Leaderboard for   Uncovering Hidden Vulnerabilities in Open-Source AI Libraries</h2><p><strong>Authors:Zekun Wu, Seonglae Cho, Umar Mohammed, Cristian Munoz, Kleyton Costa, Xin Guan, Theo King, Ze Wang, Emre Kazim, Adriano Koshiyama</strong></p>
<p>Open-source AI libraries are foundational to modern AI systems, yet they present significant, underexamined risks spanning security, licensing, maintenance, supply chain integrity, and regulatory compliance. We introduce LibVulnWatch, a system that leverages recent advances in large language models and agentic workflows to perform deep, evidence-based evaluations of these libraries. Built on a graph-based orchestration of specialized agents, the framework extracts, verifies, and quantifies risk using information from repositories, documentation, and vulnerability databases. LibVulnWatch produces reproducible, governance-aligned scores across five critical domains, publishing results to a public leaderboard for ongoing ecosystem monitoring. Applied to 20 widely used libraries, including ML frameworks, LLM inference engines, and agent orchestration tools, our approach covers up to 88% of OpenSSF Scorecard checks while surfacing up to 19 additional risks per library, such as critical RCE vulnerabilities, missing SBOMs, and regulatory gaps. By integrating advanced language technologies with the practical demands of software risk assessment, this work demonstrates a scalable, transparent mechanism for continuous supply chain evaluation and informed library selection. </p>
<blockquote>
<p>å¼€æºäººå·¥æ™ºèƒ½åº“æ˜¯ç°ä»£äººå·¥æ™ºèƒ½ç³»ç»Ÿçš„åŸºç¡€ï¼Œä½†å®ƒä»¬å¸¦æ¥äº†æ¶µç›–å®‰å…¨ã€è®¸å¯ã€ç»´æŠ¤ã€ä¾›åº”é“¾å®Œæ•´æ€§å’Œæ³•è§„éµä»æ€§ç­‰æ–¹é¢çš„é‡å¤§ä¸”å°šæœªå¾—åˆ°å……åˆ†ç ”ç©¶çš„é£é™©ã€‚æˆ‘ä»¬ä»‹ç»äº†LibVulnWatchç³»ç»Ÿï¼Œå®ƒåˆ©ç”¨æœ€æ–°çš„äººå·¥æ™ºèƒ½è¯­è¨€æ¨¡å‹å’ŒæŠ€æœ¯ä»£ç†å·¥ä½œæµç¨‹ï¼Œå¯¹è¿™äº›åº“è¿›è¡Œæ·±åº¦ã€åŸºäºè¯æ®çš„è¯„ä»·ã€‚è¯¥ç³»ç»Ÿå»ºç«‹åœ¨åŸºäºå›¾çš„ç‰¹æ®Šä»£ç†ç¼–æ’ä¹‹ä¸Šï¼Œåˆ©ç”¨æ¥è‡ªä»“åº“ã€æ–‡æ¡£å’Œæ¼æ´æ•°æ®åº“çš„ä¿¡æ¯æå–ã€éªŒè¯å’Œé‡åŒ–é£é™©ã€‚LibVulnWatchåœ¨äº”ä¸ªå…³é”®é¢†åŸŸäº§ç”Ÿå¯é‡ç°ã€ç¬¦åˆæ²»ç†çš„åˆ†æ•°ï¼Œå¹¶å°†ç»“æœå‘å¸ƒåˆ°å…¬å…±æ’è¡Œæ¦œä¸Šï¼Œç”¨äºæŒç»­ç›‘æ§ç”Ÿæ€ç³»ç»Ÿã€‚è¯¥æ–¹æ³•åº”ç”¨äº20ä¸ªå¹¿æ³›ä½¿ç”¨çš„åº“ï¼ŒåŒ…æ‹¬æœºå™¨å­¦ä¹ æ¡†æ¶ã€å¤§å‹è¯­è¨€æ¨¡å‹æ¨ç†å¼•æ“å’Œä»£ç†ç¼–æ’å·¥å…·ç­‰ï¼Œè¦†ç›–OpenSSFè®°åˆ†å¡æ£€æŸ¥çš„88%ï¼ŒåŒæ—¶æ˜¾ç¤ºå‡ºæ¯ä¸ªåº“çš„å¦å¤–å¤šè¾¾19ä¸ªé£é™©ï¼Œä¾‹å¦‚å…³é”®çš„è¿œç¨‹ä»£ç æ‰§è¡Œæ¼æ´ã€ç¼ºå°‘SBOMå’Œæ³•è§„ç©ºç™½ç­‰ã€‚é€šè¿‡å°†å…ˆè¿›çš„è¯­è¨€æŠ€æœ¯ä¸è½¯ä»¶é£é™©è¯„ä¼°çš„å®é™…éœ€æ±‚ç›¸ç»“åˆï¼Œè¿™é¡¹å·¥ä½œå±•ç¤ºäº†ä¸€ç§ç”¨äºæŒç»­ä¾›åº”é“¾è¯„ä¼°å’ŒçŸ¥æƒ…çš„åº“é€‰æ‹©çš„è§„æ¨¡åŒ–ã€é€æ˜æœºåˆ¶ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.08842v2">PDF</a> ACL 2025 Student Research Workshop and ICML 2025 TAIG Workshop</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†Open-source AIåº“åœ¨ç°ä»£AIç³»ç»Ÿä¸­çš„é‡è¦æ€§ï¼Œä½†ä¹ŸæŒ‡å‡ºäº†å…¶å­˜åœ¨çš„é£é™©ï¼ŒåŒ…æ‹¬å®‰å…¨ã€è®¸å¯ã€ç»´æŠ¤ã€ä¾›åº”é“¾å®Œæ•´æ€§å’Œæ³•è§„åˆè§„æ€§ç­‰æ–¹é¢çš„é—®é¢˜ã€‚ä¸ºæ­¤ï¼Œæå‡ºäº†ä¸€ç§åä¸ºLibVulnWatchçš„ç³»ç»Ÿï¼Œè¯¥ç³»ç»Ÿåˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹å’Œä»£ç†å·¥ä½œæµç¨‹çš„æœ€æ–°è¿›å±•ï¼Œå¯¹AIåº“è¿›è¡Œæ·±åº¦ã€åŸºäºè¯æ®çš„è¯„ä»·ã€‚è¯¥æ¡†æ¶é€šè¿‡å›¾å½¢åŒ–ç¼–æ’çš„ä¸“ç”¨ä»£ç†æå–ã€éªŒè¯å’Œé‡åŒ–é£é™©ï¼Œå¹¶ä½¿ç”¨æ¥è‡ªä»“åº“ã€æ–‡æ¡£å’Œæ¼æ´æ•°æ®åº“çš„ä¿¡æ¯ã€‚LibVulnWatchåœ¨äº”ä¸ªå…³é”®é¢†åŸŸäº§ç”Ÿå¯é‡ç°ã€ç¬¦åˆæ²»ç†çš„åˆ†æ•°ï¼Œå¹¶å°†ç»“æœå‘å¸ƒåˆ°å…¬å…±æ’è¡Œæ¦œä¸Šï¼Œç”¨äºæŒç»­ç›‘æ§ç”Ÿæ€ç³»ç»Ÿã€‚åº”ç”¨äºå¹¿æ³›ä½¿ç”¨çš„åº“ï¼ŒåŒ…æ‹¬æœºå™¨å­¦ä¹ æ¡†æ¶ã€å¤§å‹è¯­è¨€æ¨¡å‹æ¨ç†å¼•æ“å’Œä»£ç†ç¼–æ’å·¥å…·ç­‰ï¼Œè¯¥ç³»ç»Ÿçš„è¦†ç›–ç‡é«˜è¾¾OssF Scorecardæ£€æŸ¥çš„88%ï¼ŒåŒæ—¶å‘ç°æ¯ä¸ªåº“çš„é¢å¤–é£é™©é«˜è¾¾19ä¸ªï¼Œå¦‚å…³é”®è¿œç¨‹ä»£ç æ‰§è¡Œæ¼æ´ã€ç¼ºå°‘SBOMå’Œæ³•è§„å·®è·ç­‰ã€‚è¯¥å·¥ä½œå°†å…ˆè¿›çš„è¯­è¨€æŠ€æœ¯ä¸è½¯ä»¶é£é™©è¯„ä¼°çš„å®é™…éœ€æ±‚ç›¸ç»“åˆï¼Œå±•ç¤ºäº†å¯æ‰©å±•ã€é€æ˜çš„æŒç»­ä¾›åº”é“¾è¯„ä¼°æœºåˆ¶å’Œæœ‰é’ˆå¯¹æ€§çš„åº“é€‰æ‹©ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>Open-source AIåº“åœ¨ç°ä»£AIç³»ç»Ÿä¸­è‡³å…³é‡è¦ï¼Œä½†ä¹Ÿå­˜åœ¨å¤šæ–¹é¢çš„é£é™©ã€‚</li>
<li>LibVulnWatchç³»ç»Ÿåˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹å’Œä»£ç†å·¥ä½œæµç¨‹è¿›è¡Œæ·±åº¦é£é™©è¯„ä¼°ã€‚</li>
<li>è¯¥ç³»ç»Ÿé€šè¿‡å›¾å½¢åŒ–ç¼–æ’çš„ä¸“ç”¨ä»£ç†æå–é£é™©ä¿¡æ¯å¹¶è¿›è¡ŒéªŒè¯å’Œé‡åŒ–ã€‚</li>
<li>LibVulnWatchè¦†ç›–OssF Scorecardæ£€æŸ¥çš„88%ï¼Œå¹¶å‘ç°é¢å¤–çš„é£é™©å¦‚æ¼æ´å’Œæ³•è§„å·®è·ç­‰ã€‚</li>
<li>è¯¥ç³»ç»Ÿé€‚ç”¨äºå¤šç§ç±»å‹çš„åº“ï¼ŒåŒ…æ‹¬æœºå™¨å­¦ä¹ æ¡†æ¶å’Œå¤§å‹è¯­è¨€æ¨¡å‹æ¨ç†å¼•æ“ç­‰ã€‚</li>
<li>LibVulnWatché‡‡ç”¨å¯é‡ç°çš„è¯„ä¼°æ–¹æ³•ï¼Œå¹¶é€šè¿‡å…¬å…±æ’è¡Œæ¦œè¿›è¡ŒæŒç»­ç›‘æ§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.08842">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-68618fbb592d7593449799dae38d1449.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-3ec646df01f6479008521ce95ddefb93.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e906d407c81f51945c0316d5fc30ddd0.jpg" align="middle">
</details>


<h1 id="-12"><a href="#-12" class="headerlink" title=""></a></h1><h2 id="AutoToM-Scaling-Model-based-Mental-Inference-via-Automated-Agent-Modeling"><a href="#AutoToM-Scaling-Model-based-Mental-Inference-via-Automated-Agent-Modeling" class="headerlink" title="AutoToM: Scaling Model-based Mental Inference via Automated Agent   Modeling"></a>AutoToM: Scaling Model-based Mental Inference via Automated Agent   Modeling</h2><p><strong>Authors:Zhining Zhang, Chuanyang Jin, Mung Yao Jia, Shunchi Zhang, Tianmin Shu</strong></p>
<p>Theory of Mind (ToM), the ability to understand peopleâ€™s minds based on their behavior, is key to developing socially intelligent agents. Current approaches to ToM reasoning either rely on prompting Large Language Models (LLMs), which are prone to systematic errors, or use handcrafted, rigid agent models for model-based inference, which are more robust but fail to generalize across domains. In this work, we introduce AutoToM, an automated agent modeling method for scalable, robust, and interpretable mental inference. Given a ToM problem, AutoToM first proposes an initial agent model and then performs automated Bayesian inverse planning based on this model, leveraging an LLM backend. Guided by inference uncertainty, it iteratively refines the model by introducing additional mental variables and&#x2F;or incorporating more timesteps in the context. Across five diverse benchmarks, AutoToM outperforms existing ToM methods and even large reasoning models. Additionally, we show that AutoToM can produce human-like confidence estimates and enable online mental inference for embodied decision-making. </p>
<blockquote>
<p>å¿ƒç†ç†è®ºï¼ˆToMï¼‰æ˜¯æ ¹æ®äººä»¬çš„è¡Œä¸ºç†è§£ä»–ä»¬å¿ƒç†çš„èƒ½åŠ›ï¼Œæ˜¯å¼€å‘ç¤¾ä¼šæ™ºèƒ½ä»£ç†çš„å…³é”®ã€‚å½“å‰çš„å¿ƒç†ç†è®ºæ¨ç†æ–¹æ³•è¦ä¹ˆä¾èµ–äºæç¤ºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ï¼Œè¿™å®¹æ˜“äº§ç”Ÿç³»ç»Ÿè¯¯å·®ï¼Œè¦ä¹ˆä½¿ç”¨åŸºäºæ‰‹å·¥åˆ¶ä½œçš„åƒµåŒ–ä»£ç†æ¨¡å‹è¿›è¡ŒåŸºäºæ¨¡å‹çš„æ¨ç†ï¼Œè¿™åœ¨è·¨åŸŸæ¨å¹¿æ—¶è™½ç„¶æ›´ç¨³å¥ä½†æ— æ³•æ¦‚æ‹¬ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬ä»‹ç»äº†AutoToMï¼Œè¿™æ˜¯ä¸€ç§ç”¨äºå¯æ‰©å±•ã€ç¨³å¥å’Œå¯è§£é‡Šçš„å¿ƒç†æ¨ç†çš„è‡ªåŠ¨åŒ–ä»£ç†å»ºæ¨¡æ–¹æ³•ã€‚ç»™å®šä¸€ä¸ªå¿ƒç†ç†è®ºé—®é¢˜ï¼ŒAutoToMé¦–å…ˆæå‡ºä¸€ä¸ªåˆæ­¥çš„ä»£ç†æ¨¡å‹ï¼Œç„¶ååŸºäºæ­¤æ¨¡å‹è¿›è¡Œè‡ªåŠ¨åŒ–è´å¶æ–¯é€†å‘è§„åˆ’ï¼Œå¹¶åˆ©ç”¨LLMåç«¯ã€‚åœ¨æ¨ç†ä¸ç¡®å®šæ€§çš„æŒ‡å¯¼ä¸‹ï¼Œå®ƒé€šè¿‡å¼•å…¥é¢å¤–çš„å¿ƒç†å˜é‡å’Œ&#x2F;æˆ–åœ¨èƒŒæ™¯ä¸‹èå…¥æ›´å¤šçš„æ—¶é—´æ­¥é•¿æ¥è¿­ä»£ä¼˜åŒ–æ¨¡å‹ã€‚åœ¨äº”ä¸ªä¸åŒçš„åŸºå‡†æµ‹è¯•ä¸­ï¼ŒAutoToMçš„è¡¨ç°ä¼˜äºç°æœ‰çš„å¿ƒç†ç†è®ºæ–¹æ³•å’Œå¤§å‹æ¨ç†æ¨¡å‹ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜å±•ç¤ºäº†AutoToMèƒ½å¤Ÿäº§ç”Ÿç±»ä¼¼äººç±»çš„ä¿¡å¿ƒä¼°è®¡ï¼Œå¹¶èƒ½å¤Ÿå®ç°åœ¨çº¿å¿ƒç†æ¨ç†ï¼Œç”¨äºå®ä½“å†³ç­–åˆ¶å®šã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.15676v2">PDF</a> 39 pages, 10 figures, 13 tables. Website at   <a target="_blank" rel="noopener" href="https://chuanyangjin.com/AutoToM/">https://chuanyangjin.com/AutoToM/</a></p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†ç†è®ºæ€ç»´ï¼ˆToMï¼‰åœ¨å¼€å‘ç¤¾ä¼šæ™ºèƒ½ä»£ç†ä¸­çš„é‡è¦æ€§ã€‚å½“å‰çš„ç†è®ºæ€ç»´æ¨ç†æ–¹æ³•å­˜åœ¨ç¼ºé™·ï¼Œè¦ä¹ˆä¾èµ–äºæ˜“äº§ç”Ÿç³»ç»Ÿè¯¯å·®çš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ï¼Œè¦ä¹ˆä½¿ç”¨åŸºäºæ¨¡å‹çš„æ¨ç†çš„åƒµåŒ–ä»£ç†æ¨¡å‹ï¼Œéš¾ä»¥è·¨é¢†åŸŸæ¨å¹¿ã€‚æœ¬æ–‡æå‡ºäº†AutoToMè¿™ä¸€è‡ªåŠ¨åŒ–ä»£ç†å»ºæ¨¡æ–¹æ³•ï¼Œç”¨äºå®ç°å¯ä¼¸ç¼©ã€ç¨³å¥å’Œå¯è§£é‡Šçš„å¿ƒç†æ¨ç†ã€‚AutoToMé’ˆå¯¹ç†è®ºæ€ç»´é—®é¢˜é¦–å…ˆæå‡ºåˆå§‹ä»£ç†æ¨¡å‹ï¼Œç„¶ååŸºäºè¯¥æ¨¡å‹è¿›è¡Œè‡ªåŠ¨åŒ–è´å¶æ–¯é€†å‘è§„åˆ’ï¼Œå¹¶åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹åç«¯ã€‚åœ¨äº”ä¸ªä¸åŒçš„åŸºå‡†æµ‹è¯•ä¸­ï¼ŒAutoToMçš„è¡¨ç°å‡ä¼˜äºç°æœ‰çš„ç†è®ºæ€ç»´æ–¹æ³•å’Œå¤§å‹æ¨ç†æ¨¡å‹ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜å±•ç¤ºäº†AutoToMå¯ä»¥äº§ç”Ÿç±»ä¼¼äººç±»çš„ä¿¡å¿ƒä¼°è®¡ï¼Œå¹¶ç”¨äºåœ¨çº¿å¿ƒç†æ¨ç†å’Œå†³ç­–åˆ¶å®šã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ç†è®ºæ€ç»´ï¼ˆToMï¼‰æ˜¯å¼€å‘ç¤¾ä¼šæ™ºèƒ½ä»£ç†çš„å…³é”®ã€‚</li>
<li>å½“å‰çš„ç†è®ºæ€ç»´æ¨ç†æ–¹æ³•å­˜åœ¨ç¼ºé™·ï¼Œéœ€è¦æ–°æ–¹æ³•æ¥è§£å†³ã€‚</li>
<li>AutoToMæ˜¯ä¸€ç§æ–°çš„è‡ªåŠ¨åŒ–ä»£ç†å»ºæ¨¡æ–¹æ³•ï¼Œç”¨äºå¿ƒç†æ¨ç†ã€‚</li>
<li>AutoToMç»“åˆåˆå§‹ä»£ç†æ¨¡å‹å’Œè´å¶æ–¯é€†å‘è§„åˆ’è¿›è¡Œæ¨ç†ã€‚</li>
<li>AutoToMåˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹åç«¯ï¼Œé€šè¿‡å¼•å…¥å¿ƒç†å˜é‡å’Œæ—¶é—´æ­¥é•¿æ¥ä¸æ–­ä¼˜åŒ–æ¨¡å‹ã€‚</li>
<li>AutoToMåœ¨äº”ä¸ªåŸºå‡†æµ‹è¯•ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œä¼˜äºç°æœ‰çš„ç†è®ºæ€ç»´æ–¹æ³•å’Œå¤§å‹æ¨ç†æ¨¡å‹ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.15676">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-60591187316980b3108f0bbb309c18ad.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-aa7b8ebc3d3d937757df93cfbf4d7f80.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-d641de0172372f76eebda3909854fd90.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-4747a398ffff5a288bc84b85de93d9fe.jpg" align="middle">
</details>


<h1 id="-13"><a href="#-13" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-07-03/Agent/">https://kedreamix.github.io/Talk2Paper/Paper/2025-07-03/Agent/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/Agent/">
                                    <span class="chip bg-color">Agent</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-07-03/Few-Shot/">
                    <div class="card-image">
                        
                        <img src="https://pic1.zhimg.com/v2-16540274011f2d1c616a2978dc5fcede.jpg" class="responsive-img" alt="Few-Shot">
                        
                        <span class="card-title">Few-Shot</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Few-Shot æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-07-03  STACK Adversarial Attacks on LLM Safeguard Pipelines
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-07-03
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Few-Shot/" class="post-category">
                                    Few-Shot
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Few-Shot/">
                        <span class="chip bg-color">Few-Shot</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-07-03/LLM/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-47b30a4ff914de705cc022b85fe30c9c.jpg" class="responsive-img" alt="LLM">
                        
                        <span class="card-title">LLM</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            LLM æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-07-03  Positional Bias in Binary Question Answering How Uncertainty Shapes   Model Preferences
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-07-03
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/LLM/" class="post-category">
                                    LLM
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/LLM/">
                        <span class="chip bg-color">LLM</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">29739.9k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
