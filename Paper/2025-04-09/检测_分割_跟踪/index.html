<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="æ£€æµ‹/åˆ†å‰²/è·Ÿè¸ª">
    <meta name="description" content="æ£€æµ‹/åˆ†å‰²/è·Ÿè¸ª æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-04-09  SSLFusion Scale &amp; Space Aligned Latent Fusion Model for Multimodal 3D   Object Detection">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>æ£€æµ‹/åˆ†å‰²/è·Ÿè¸ª | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://pic1.zhimg.com/v2-b0bdf034384f8da4962c37811fdb7ccf.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">æ£€æµ‹/åˆ†å‰²/è·Ÿè¸ª</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/%E6%A3%80%E6%B5%8B-%E5%88%86%E5%89%B2-%E8%B7%9F%E8%B8%AA/">
                                <span class="chip bg-color">æ£€æµ‹/åˆ†å‰²/è·Ÿè¸ª</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/%E6%A3%80%E6%B5%8B-%E5%88%86%E5%89%B2-%E8%B7%9F%E8%B8%AA/" class="post-category">
                                æ£€æµ‹/åˆ†å‰²/è·Ÿè¸ª
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-04-09
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-05-14
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    7k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    28 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-04-09-æ›´æ–°"><a href="#2025-04-09-æ›´æ–°" class="headerlink" title="2025-04-09 æ›´æ–°"></a>2025-04-09 æ›´æ–°</h1><h2 id="SSLFusion-Scale-Space-Aligned-Latent-Fusion-Model-for-Multimodal-3D-Object-Detection"><a href="#SSLFusion-Scale-Space-Aligned-Latent-Fusion-Model-for-Multimodal-3D-Object-Detection" class="headerlink" title="SSLFusion: Scale &amp; Space Aligned Latent Fusion Model for Multimodal 3D   Object Detection"></a>SSLFusion: Scale &amp; Space Aligned Latent Fusion Model for Multimodal 3D   Object Detection</h2><p><strong>Authors:Bonan Ding, Jin Xie, Jing Nie, Jiale Cao</strong></p>
<p>Multimodal 3D object detection based on deep neural networks has indeed made significant progress. However, it still faces challenges due to the misalignment of scale and spatial information between features extracted from 2D images and those derived from 3D point clouds. Existing methods usually aggregate multimodal features at a single stage. However, leveraging multi-stage cross-modal features is crucial for detecting objects of various scales. Therefore, these methods often struggle to integrate features across different scales and modalities effectively, thereby restricting the accuracy of detection. Additionally, the time-consuming Query-Key-Value-based (QKV-based) cross-attention operations often utilized in existing methods aid in reasoning the location and existence of objects by capturing non-local contexts. However, this approach tends to increase computational complexity. To address these challenges, we present SSLFusion, a novel Scale &amp; Space Aligned Latent Fusion Model, consisting of a scale-aligned fusion strategy (SAF), a 3D-to-2D space alignment module (SAM), and a latent cross-modal fusion module (LFM). SAF mitigates scale misalignment between modalities by aggregating features from both images and point clouds across multiple levels. SAM is designed to reduce the inter-modal gap between features from images and point clouds by incorporating 3D coordinate information into 2D image features. Additionally, LFM captures cross-modal non-local contexts in the latent space without utilizing the QKV-based attention operations, thus mitigating computational complexity. Experiments on the KITTI and DENSE datasets demonstrate that our SSLFusion outperforms state-of-the-art methods. Our approach obtains an absolute gain of 2.15% in 3D AP, compared with the state-of-art method GraphAlign on the moderate level of the KITTI test set. </p>
<blockquote>
<p>åŸºäºæ·±åº¦ç¥ç»ç½‘ç»œçš„å¤šæ¨¡æ€ä¸‰ç»´ç‰©ä½“æ£€æµ‹ç¡®å®å·²ç»å–å¾—äº†æ˜¾è‘—çš„è¿›å±•ã€‚ç„¶è€Œï¼Œç”±äºä»äºŒç»´å›¾åƒæå–çš„ç‰¹å¾ä¸ä»ä¸‰ç»´ç‚¹äº‘è¡ç”Ÿçš„ç‰¹å¾åœ¨è§„æ¨¡å’Œç©ºé—´ä¿¡æ¯ä¸Šçš„ä¸åŒ¹é…ï¼Œå®ƒä»ç„¶é¢ä¸´æŒ‘æˆ˜ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸åœ¨å•ä¸€é˜¶æ®µèšåˆå¤šæ¨¡æ€ç‰¹å¾ã€‚ç„¶è€Œï¼Œåˆ©ç”¨å¤šé˜¶æ®µçš„è·¨æ¨¡æ€ç‰¹å¾å¯¹äºæ£€æµ‹å„ç§è§„æ¨¡çš„ç›®æ ‡è‡³å…³é‡è¦ã€‚å› æ­¤ï¼Œè¿™äº›æ–¹æ³•åœ¨æ•´åˆä¸åŒè§„æ¨¡å’Œæ¨¡æ€çš„ç‰¹å¾æ—¶å¾€å¾€é¢ä¸´å›°éš¾ï¼Œä»è€Œé™åˆ¶äº†æ£€æµ‹ç²¾åº¦ã€‚æ­¤å¤–ï¼Œç°æœ‰æ–¹æ³•ä¸­å¸¸ç”¨çš„åŸºäºæŸ¥è¯¢-é”®-å€¼ï¼ˆQKVï¼‰çš„è·¨æ³¨æ„åŠ›æ“ä½œè™½ç„¶æœ‰åŠ©äºé€šè¿‡æ•æ‰éå±€éƒ¨ä¸Šä¸‹æ–‡æ¥æ¨ç†ç‰©ä½“çš„ä½ç½®å’Œå­˜åœ¨ï¼Œä½†è¿™ç§æ–¹æ³•å¾€å¾€ä¼šå¢åŠ è®¡ç®—å¤æ‚æ€§ã€‚ä¸ºäº†åº”å¯¹è¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†SSLFusionï¼Œè¿™æ˜¯ä¸€ç§æ–°çš„è§„æ¨¡å’Œç©ºé—´å¯¹é½æ½œåœ¨èåˆæ¨¡å‹ï¼ŒåŒ…æ‹¬è§„æ¨¡å¯¹é½èåˆç­–ç•¥ï¼ˆSAFï¼‰ã€3Dåˆ°2Dç©ºé—´å¯¹é½æ¨¡å—ï¼ˆSAMï¼‰å’Œæ½œåœ¨è·¨æ¨¡æ€èåˆæ¨¡å—ï¼ˆLFMï¼‰ã€‚SAFé€šè¿‡åœ¨ä¸åŒå±‚çº§ä¸Šèšåˆå›¾åƒå’Œç‚¹äº‘çš„ç‰¹å¾ï¼Œç¼“è§£æ¨¡æ€ä¹‹é—´çš„è§„æ¨¡ä¸åŒ¹é…é—®é¢˜ã€‚SAMé€šè¿‡èå…¥3Dåæ ‡ä¿¡æ¯åˆ°2Då›¾åƒç‰¹å¾ä¸­ï¼Œæ—¨åœ¨ç¼©å°å›¾åƒå’Œç‚¹äº‘ç‰¹å¾ä¹‹é—´çš„è·¨æ¨¡æ€å·®è·ã€‚æ­¤å¤–ï¼ŒLFMåœ¨æ½œåœ¨ç©ºé—´ä¸­æ•æ‰è·¨æ¨¡æ€çš„éå±€éƒ¨ä¸Šä¸‹æ–‡ï¼Œè€Œä¸ä½¿ç”¨QKVåŸºäºæ³¨æ„åŠ›çš„æ“ä½œï¼Œä»è€Œç¼“è§£è®¡ç®—å¤æ‚æ€§ã€‚åœ¨KITTIå’ŒDENSEæ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„SSLFusionä¼˜äºæœ€æ–°æ–¹æ³•ã€‚æˆ‘ä»¬çš„æ–¹æ³•åœ¨KITTIæµ‹è¯•é›†çš„é€‚åº¦æ°´å¹³ä¸Šï¼Œä¸æœ€æ–°æ–¹æ³•GraphAlignç›¸æ¯”ï¼Œ3D APç»å¯¹æå‡äº†2.15%ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.05170v1">PDF</a> Accepted by AAAI 2025</p>
<p><strong>Summary</strong><br>åŸºäºæ·±åº¦ç¥ç»ç½‘ç»œçš„å¤šæ¨¡æ€ä¸‰ç»´ç‰©ä½“æ£€æµ‹æŠ€æœ¯å·²ç»å–å¾—æ˜¾è‘—è¿›å±•ï¼Œä½†ä»é¢ä¸´äºŒç»´å›¾åƒå’Œä¸‰ç»´ç‚¹äº‘ç‰¹å¾å°ºåº¦ä¸ç©ºé—´ä¿¡æ¯ä¸å¯¹é½çš„æŒ‘æˆ˜ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸åœ¨å•ä¸€é˜¶æ®µè¿›è¡Œå¤šæ¨¡æ€ç‰¹å¾èšåˆï¼Œéš¾ä»¥æœ‰æ•ˆæ•´åˆä¸åŒå°ºåº¦å’Œæ¨¡æ€çš„ç‰¹å¾ï¼Œå½±å“æ£€æµ‹å‡†ç¡®æ€§ã€‚é’ˆå¯¹è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†SSLFusionæ¨¡å‹ï¼ŒåŒ…æ‹¬å°ºåº¦å¯¹é½èåˆç­–ç•¥ï¼ˆSAFï¼‰ã€ä¸‰ç»´åˆ°äºŒç»´ç©ºé—´å¯¹é½æ¨¡å—ï¼ˆSAMï¼‰å’Œæ½œåœ¨è·¨æ¨¡æ€èåˆæ¨¡å—ï¼ˆLFMï¼‰ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤šæ¨¡æ€ä¸‰ç»´ç‰©ä½“æ£€æµ‹åŸºäºæ·±åº¦ç¥ç»ç½‘ç»œæœ‰æ˜¾è‘—çš„è¿›æ­¥ï¼Œä½†å­˜åœ¨ç‰¹å¾å’Œå°ºåº¦ä¸å¯¹é½çš„é—®é¢˜ã€‚</li>
<li>ç°æœ‰æ–¹æ³•é€šå¸¸åœ¨å•ä¸€é˜¶æ®µè¿›è¡Œå¤šæ¨¡æ€ç‰¹å¾èšåˆï¼Œéš¾ä»¥æ£€æµ‹ä¸åŒå°ºåº¦çš„ç‰©ä½“ã€‚</li>
<li>SSLFusionæ¨¡å‹åŒ…æ‹¬å°ºåº¦å¯¹é½èåˆç­–ç•¥ï¼ˆSAFï¼‰ï¼Œç”¨äºè§£å†³è·¨æ¨¡æ€çš„å°ºåº¦ä¸å¯¹é½é—®é¢˜ã€‚</li>
<li>ä¸‰ç»´åˆ°äºŒç»´ç©ºé—´å¯¹é½æ¨¡å—ï¼ˆSAMï¼‰é€šè¿‡èå…¥ä¸‰ç»´åæ ‡ä¿¡æ¯æ¥ç¼©å°è·¨æ¨¡æ€ç‰¹å¾ä¹‹é—´çš„å·®è·ã€‚</li>
<li>æ½œåœ¨è·¨æ¨¡æ€èåˆæ¨¡å—ï¼ˆLFMï¼‰èƒ½å¤Ÿåœ¨æ½œåœ¨ç©ºé—´ä¸­æ•è·è·¨æ¨¡æ€çš„éå±€éƒ¨ä¸Šä¸‹æ–‡ï¼ŒåŒæ—¶ä¸å¢åŠ è®¡ç®—å¤æ‚æ€§ã€‚</li>
<li>SSLFusionæ¨¡å‹åœ¨KITTIå’ŒDENSEæ•°æ®é›†ä¸Šçš„è¡¨ç°ä¼˜äºç°æœ‰æœ€å…ˆè¿›çš„æ£€æµ‹æ–¹æ³•ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.05170">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-35b7ed9d4ec41b7cfee1d53a24f4a90a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e2e10343a1a3c7299709152b1bc11d77.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-bcac2332f9cd07ae12e69adde284b0a3.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-642b151a4e155f8a43f0327fdfc06c1f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-6e3d18f077a48b7b1a76d7e72bde0f28.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-727abfa8d0044d6c63863893e0cccb88.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-7350f0ddf8cfe0675c059d476861db3a.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="DFormerv2-Geometry-Self-Attention-for-RGBD-Semantic-Segmentation"><a href="#DFormerv2-Geometry-Self-Attention-for-RGBD-Semantic-Segmentation" class="headerlink" title="DFormerv2: Geometry Self-Attention for RGBD Semantic Segmentation"></a>DFormerv2: Geometry Self-Attention for RGBD Semantic Segmentation</h2><p><strong>Authors:Bo-Wen Yin, Jiao-Long Cao, Ming-Ming Cheng, Qibin Hou</strong></p>
<p>Recent advances in scene understanding benefit a lot from depth maps because of the 3D geometry information, especially in complex conditions (e.g., low light and overexposed). Existing approaches encode depth maps along with RGB images and perform feature fusion between them to enable more robust predictions. Taking into account that depth can be regarded as a geometry supplement for RGB images, a straightforward question arises: Do we really need to explicitly encode depth information with neural networks as done for RGB images? Based on this insight, in this paper, we investigate a new way to learn RGBD feature representations and present DFormerv2, a strong RGBD encoder that explicitly uses depth maps as geometry priors rather than encoding depth information with neural networks. Our goal is to extract the geometry clues from the depth and spatial distances among all the image patch tokens, which will then be used as geometry priors to allocate attention weights in self-attention. Extensive experiments demonstrate that DFormerv2 exhibits exceptional performance in various RGBD semantic segmentation benchmarks. Code is available at: <a target="_blank" rel="noopener" href="https://github.com/VCIP-RGBD/DFormer">https://github.com/VCIP-RGBD/DFormer</a>. </p>
<blockquote>
<p>æœ€è¿‘ï¼Œåœºæ™¯ç†è§£çš„è¿›æ­¥åœ¨å¾ˆå¤§ç¨‹åº¦ä¸Šå¾—ç›Šäºæ·±åº¦å›¾æ‰€åŒ…å«çš„3Då‡ ä½•ä¿¡æ¯ï¼Œç‰¹åˆ«æ˜¯åœ¨å¤æ‚æ¡ä»¶ä¸‹ï¼ˆä¾‹å¦‚ä½å…‰å’Œè¿‡åº¦æ›å…‰ï¼‰ã€‚ç°æœ‰æ–¹æ³•å°†æ·±åº¦å›¾ä¸RGBå›¾åƒè¿›è¡Œç¼–ç ï¼Œå¹¶åœ¨ä¸¤è€…ä¹‹é—´æ‰§è¡Œç‰¹å¾èåˆï¼Œä»¥å®ç°æ›´ç¨³å¥çš„é¢„æµ‹ã€‚è€ƒè™‘åˆ°æ·±åº¦å¯è¢«è§†ä¸ºRGBå›¾åƒçš„å‡ ä½•è¡¥å……ï¼Œä¸€ä¸ªç›´æ¥çš„é—®é¢˜å‡ºç°äº†ï¼šæˆ‘ä»¬æ˜¯å¦çœŸçš„éœ€è¦å°†æ·±åº¦ä¿¡æ¯åƒå¤„ç†RGBå›¾åƒé‚£æ ·æ˜¾å¼åœ°ç¼–ç åˆ°ç¥ç»ç½‘ç»œä¸­ï¼ŸåŸºäºè¿™ä¸€è§è§£ï¼Œæœ¬æ–‡ç ”ç©¶äº†ä¸€ç§æ–°çš„RGBDç‰¹å¾è¡¨ç¤ºå­¦ä¹ æ–¹æ³•ï¼Œå¹¶æ¨å‡ºäº†DFormerv2ï¼Œè¿™æ˜¯ä¸€ç§å¼ºå¤§çš„RGBDç¼–ç å™¨ï¼Œå®ƒæ˜¾å¼åœ°ä½¿ç”¨æ·±åº¦å›¾ä½œä¸ºå‡ ä½•å…ˆéªŒï¼Œè€Œä¸æ˜¯é€šè¿‡ç¥ç»ç½‘ç»œç¼–ç æ·±åº¦ä¿¡æ¯ã€‚æˆ‘ä»¬çš„ç›®æ ‡æ˜¯ä»æ·±åº¦å’Œæ‰€æœ‰å›¾åƒè¡¥ä¸æ ‡è®°ä¹‹é—´çš„ç©ºé—´è·ç¦»ä¸­æå–å‡ ä½•çº¿ç´¢ï¼Œç„¶åå°†è¿™äº›çº¿ç´¢ç”¨ä½œå‡ ä½•å…ˆéªŒæ¥åˆ†é…è‡ªæ³¨æ„åŠ›ä¸­çš„æ³¨æ„åŠ›æƒé‡ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼ŒDFormerv2åœ¨å„ç§RGBDè¯­ä¹‰åˆ†å‰²åŸºå‡†æµ‹è¯•ä¸­è¡¨ç°å‡ºå“è¶Šçš„æ€§èƒ½ã€‚ä»£ç å¯åœ¨ä»¥ä¸‹ç½‘å€æ‰¾åˆ°ï¼š<a target="_blank" rel="noopener" href="https://github.com/VCIP-RGBD/DFormer%E3%80%82">https://github.com/VCIP-RGBD/DFormerã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.04701v1">PDF</a> Accepted by CVPR 2025</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æ¢è®¨äº†RGBDç‰¹å¾è¡¨ç¤ºçš„æ–°å­¦ä¹ æ–¹æ³•ï¼Œæå‡ºäº†ä¸€ç§åä¸ºDFormerv2çš„å¼ºRGBDç¼–ç å™¨ï¼Œå®ƒåˆ©ç”¨æ·±åº¦å›¾ä½œä¸ºå‡ ä½•å…ˆéªŒä¿¡æ¯ï¼Œè€Œä¸æ˜¯é€šè¿‡ç¥ç»ç½‘ç»œå¯¹æ·±åº¦ä¿¡æ¯è¿›è¡Œç¼–ç ã€‚è¯¥ç ”ç©¶çš„ç›®æ ‡æ˜¯ä»æ·±åº¦å›¾å’Œå›¾åƒå—ä»¤ç‰Œé—´çš„ç©ºé—´è·ç¦»ä¸­æå–å‡ ä½•çº¿ç´¢ï¼Œå°†å…¶ä½œä¸ºå‡ ä½•å…ˆéªŒä¿¡æ¯ç”¨äºåˆ†é…è‡ªæ³¨æ„åŠ›ä¸­çš„æ³¨æ„åŠ›æƒé‡ã€‚å®éªŒè¡¨æ˜ï¼ŒDFormerv2åœ¨å¤šç§RGBDè¯­ä¹‰åˆ†å‰²åŸºå‡†æµ‹è¯•ä¸­è¡¨ç°å‡ºå“è¶Šæ€§èƒ½ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>DFormerv2åˆ©ç”¨æ·±åº¦å›¾ä½œä¸ºå‡ ä½•å…ˆéªŒä¿¡æ¯ï¼Œæå‡ºäº†æ–°çš„RGBDç‰¹å¾è¡¨ç¤ºå­¦ä¹ æ–¹æ³•ã€‚</li>
<li>ç°æœ‰æ–¹æ³•é€šå¸¸å°†æ·±åº¦å›¾ä¸RGBå›¾åƒä¸€èµ·ç¼–ç ï¼Œå¹¶è¿›è¡Œç‰¹å¾èåˆï¼Œè€ŒDFormerv2åˆ™å°†æ·±åº¦ä¿¡æ¯ç›´æ¥ç”¨äºåˆ†é…è‡ªæ³¨æ„åŠ›ä¸­çš„æƒé‡ã€‚</li>
<li>è¯¥æ–¹æ³•ä»æ·±åº¦å›¾å’Œç©ºé—´è·ç¦»ä¸­æå–å‡ ä½•çº¿ç´¢ï¼Œä»¥å¢å¼ºå›¾åƒç†è§£ã€‚</li>
<li>DFormerv2åœ¨å¤šç§RGBDè¯­ä¹‰åˆ†å‰²åŸºå‡†æµ‹è¯•ä¸­è¡¨ç°å‡ºå“è¶Šæ€§èƒ½ã€‚</li>
<li>è¯¥ç ”ç©¶å¼ºè°ƒäº†æ·±åº¦ä¿¡æ¯åœ¨å¤æ‚æ¡ä»¶ä¸‹çš„é‡è¦æ€§ï¼Œå¦‚ä½å…‰å’Œè¿‡æ›å…‰ç¯å¢ƒã€‚</li>
<li>DFormerv2çš„ç›®æ ‡æ˜¯é€šè¿‡åˆ©ç”¨æ·±åº¦å›¾çš„å‡ ä½•ä¿¡æ¯æ¥æ”¹è¿›RGBå›¾åƒçš„è¡¨ç¤ºèƒ½åŠ›ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.04701">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-71d0ee06075620376b456cef8464cf22.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-6ea1145438cafaf3eb6e4e124dcf955e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c295887bec639d85a9a63f4e9b1f058f.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-2343e404f7acb1ab7324f17fef6f3c81.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-8f3ad0e8f3d76a1c86042ce78f904690.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c1314d817d2dc531996637685d5e37b6.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="Enhance-Then-Search-An-Augmentation-Search-Strategy-with-Foundation-Models-for-Cross-Domain-Few-Shot-Object-Detection"><a href="#Enhance-Then-Search-An-Augmentation-Search-Strategy-with-Foundation-Models-for-Cross-Domain-Few-Shot-Object-Detection" class="headerlink" title="Enhance Then Search: An Augmentation-Search Strategy with Foundation   Models for Cross-Domain Few-Shot Object Detection"></a>Enhance Then Search: An Augmentation-Search Strategy with Foundation   Models for Cross-Domain Few-Shot Object Detection</h2><p><strong>Authors:Jiancheng Pan, Yanxing Liu, Xiao He, Long Peng, Jiahao Li, Yuze Sun, Xiaomeng Huang</strong></p>
<p>Foundation models pretrained on extensive datasets, such as GroundingDINO and LAE-DINO, have performed remarkably in the cross-domain few-shot object detection (CD-FSOD) task. Through rigorous few-shot training, we found that the integration of image-based data augmentation techniques and grid-based sub-domain search strategy significantly enhances the performance of these foundation models. Building upon GroundingDINO, we employed several widely used image augmentation methods and established optimization objectives to effectively navigate the expansive domain space in search of optimal sub-domains. This approach facilitates efficient few-shot object detection and introduces an approach to solving the CD-FSOD problem by efficiently searching for the optimal parameter configuration from the foundation model. Our findings substantially advance the practical deployment of vision-language models in data-scarce environments, offering critical insights into optimizing their cross-domain generalization capabilities without labor-intensive retraining. Code is available at <a target="_blank" rel="noopener" href="https://github.com/jaychempan/ETS">https://github.com/jaychempan/ETS</a>. </p>
<blockquote>
<p>åŸºäºå¤§è§„æ¨¡æ•°æ®é›†é¢„è®­ç»ƒçš„æ¨¡å‹ï¼Œå¦‚GroundingDINOå’ŒLAE-DINOï¼Œåœ¨è·¨åŸŸå°‘æ ·æœ¬ç›®æ ‡æ£€æµ‹ï¼ˆCD-FSODï¼‰ä»»åŠ¡ä¸­è¡¨ç°çªå‡ºã€‚é€šè¿‡ä¸¥æ ¼çš„å°‘æ ·æœ¬è®­ç»ƒï¼Œæˆ‘ä»¬å‘ç°ç»“åˆåŸºäºå›¾åƒçš„æ•°æ®å¢å¼ºæŠ€æœ¯å’ŒåŸºäºç½‘æ ¼çš„å­åŸŸæœç´¢ç­–ç•¥ï¼Œå¯ä»¥æ˜¾è‘—æé«˜è¿™äº›åŸºç¡€æ¨¡å‹çš„æ€§èƒ½ã€‚åœ¨GroundingDINOçš„åŸºç¡€ä¸Šï¼Œæˆ‘ä»¬é‡‡ç”¨äº†å‡ ç§å¸¸ç”¨çš„å›¾åƒå¢å¼ºæ–¹æ³•ï¼Œå¹¶å»ºç«‹äº†ä¼˜åŒ–ç›®æ ‡ï¼Œä»¥æœ‰æ•ˆåœ°éå†åºå¤§çš„åŸŸç©ºé—´ï¼Œå¯»æ‰¾æœ€ä½³å­åŸŸã€‚è¿™ç§æ–¹æ³•ä¿ƒè¿›äº†é«˜æ•ˆå°‘æ ·æœ¬ç›®æ ‡æ£€æµ‹ï¼Œå¹¶é€šè¿‡ä»åŸºç¡€æ¨¡å‹ä¸­æœ‰æ•ˆæœç´¢æœ€ä½³å‚æ•°é…ç½®æ¥è§£å†³CD-FSODé—®é¢˜ã€‚æˆ‘ä»¬çš„ç ”ç©¶ä¸ºåœ¨æ•°æ®ç¨€ç¼ºç¯å¢ƒä¸­éƒ¨ç½²è§†è§‰è¯­è¨€æ¨¡å‹æä¾›äº†é‡å¤§è¿›å±•ï¼Œå¹¶ä¸ºåœ¨ä¸è¿›è¡ŒåŠ³åŠ¨å¯†é›†å‹å†è®­ç»ƒçš„æƒ…å†µä¸‹ä¼˜åŒ–å…¶è·¨åŸŸæ³›åŒ–èƒ½åŠ›æä¾›äº†å…³é”®è§è§£ã€‚ä»£ç å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/jaychempan/ETS%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/jaychempan/ETSæ‰¾åˆ°ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.04517v1">PDF</a> 9 pages, 6 figures</p>
<p><strong>Summary</strong></p>
<p>åŸºäºå¤§è§„æ¨¡æ•°æ®é›†é¢„è®­ç»ƒçš„æ¨¡å‹ï¼Œå¦‚GroundingDINOå’ŒLAE-DINOï¼Œåœ¨è·¨åŸŸå°‘æ ·æœ¬ç›®æ ‡æ£€æµ‹ä»»åŠ¡ä¸­è¡¨ç°å‡ºå“è¶Šæ€§èƒ½ã€‚ç ”ç©¶é€šè¿‡ä¸¥æ ¼å°‘æ ·æœ¬è®­ç»ƒå‘ç°ï¼Œå›¾åƒæ•°æ®å¢å¼ºæŠ€æœ¯ä¸åŸºäºç½‘æ ¼çš„å­åŸŸæœç´¢ç­–ç•¥çš„ç»“åˆï¼Œæ˜¾è‘—æå‡äº†è¿™äº›é¢„è®­ç»ƒæ¨¡å‹çš„æ€§èƒ½ã€‚åœ¨GroundingDINOåŸºç¡€ä¸Šï¼Œç ”ç©¶é‡‡ç”¨å¤šç§å¸¸ç”¨å›¾åƒå¢å¼ºæ–¹æ³•å¹¶å»ºç«‹ä¼˜åŒ–ç›®æ ‡ï¼Œä»¥æœ‰æ•ˆéå†å¹¿é˜”åŸŸç©ºé—´å¹¶å¯»æ‰¾æœ€ä½³å­åŸŸï¼Œä¸ºè§£å†³CD-FSODé—®é¢˜æä¾›äº†ä¸€ç§æ–¹æ³•ã€‚è¯¥ç ”ç©¶æœ‰åŠ©äºé«˜æ•ˆå°‘æ ·æœ¬ç›®æ ‡æ£€æµ‹ï¼Œå¹¶ä¸ºä¼˜åŒ–è§†è§‰è¯­è¨€æ¨¡å‹åœ¨æ•°æ®ç¨€ç¼ºç¯å¢ƒä¸­çš„è·¨åŸŸæ³›åŒ–èƒ½åŠ›æä¾›äº†å…³é”®è§è§£ã€‚ä»£ç å·²å…¬å¼€äºGitHubä¸Šã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>é¢„è®­ç»ƒçš„æ¨¡å‹ï¼Œå¦‚GroundingDINOå’ŒLAE-DINOï¼Œåœ¨è·¨åŸŸå°‘æ ·æœ¬ç›®æ ‡æ£€æµ‹ä¸­è¡¨ç°å‡ºä¼˜å¼‚æ€§èƒ½ã€‚</li>
<li>å›¾åƒæ•°æ®å¢å¼ºæŠ€æœ¯ç»“åˆåŸºäºç½‘æ ¼çš„å­åŸŸæœç´¢ç­–ç•¥æ˜¾è‘—æå‡äº†æ¨¡å‹æ€§èƒ½ã€‚</li>
<li>åœ¨GroundingDINOåŸºç¡€ä¸Šï¼Œé‡‡ç”¨å¤šç§å›¾åƒå¢å¼ºæ–¹æ³•å’Œä¼˜åŒ–ç›®æ ‡ï¼Œæœ‰æ•ˆæœç´¢æœ€ä½³å­åŸŸã€‚</li>
<li>è¯¥æ–¹æ³•ä¸ºè§£å†³CD-FSODé—®é¢˜æä¾›äº†ä¸€ç§æœ‰æ•ˆé€”å¾„ã€‚</li>
<li>ç ”ç©¶æœ‰åŠ©äºæé«˜å°‘æ ·æœ¬ç›®æ ‡æ£€æµ‹çš„æ•ˆç‡å’Œå‡†ç¡®æ€§ã€‚</li>
<li>ç ”ç©¶ä¸ºä¼˜åŒ–è§†è§‰è¯­è¨€æ¨¡å‹åœ¨æ•°æ®ç¨€ç¼ºç¯å¢ƒä¸­çš„è·¨åŸŸæ³›åŒ–èƒ½åŠ›æä¾›äº†å…³é”®è§è§£ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.04517">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-8c564e6d6460ed39ed6dc4ae1d09760e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-abb71328397a8a6629b09d0f5deca41d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-2b97486cbb59d8ed4ff67480f97f9709.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-b6681ab63f960004e9c81babead169da.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-448d085c3070c8f578c770982352a618.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-6652620b7293f64921df0d7bc485518e.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="Prompt-Categories-Cluster-for-Weakly-Supervised-Semantic-Segmentation"><a href="#Prompt-Categories-Cluster-for-Weakly-Supervised-Semantic-Segmentation" class="headerlink" title="Prompt Categories Cluster for Weakly Supervised Semantic Segmentation"></a>Prompt Categories Cluster for Weakly Supervised Semantic Segmentation</h2><p><strong>Authors:Wangyu Wu, Xianglin Qiu, Siqi Song, Xiaowei Huang, Fei Ma, Jimin Xiao</strong></p>
<p>Weakly Supervised Semantic Segmentation (WSSS), which leverages image-level labels, has garnered significant attention due to its cost-effectiveness. The previous methods mainly strengthen the inter-class differences to avoid class semantic ambiguity which may lead to erroneous activation. However, they overlook the positive function of some shared information between similar classes. Categories within the same cluster share some similar features. Allowing the model to recognize these features can further relieve the semantic ambiguity between these classes. To effectively identify and utilize this shared information, in this paper, we introduce a novel WSSS framework called Prompt Categories Clustering (PCC). Specifically, we explore the ability of Large Language Models (LLMs) to derive category clusters through prompts. These clusters effectively represent the intrinsic relationships between categories. By integrating this relational information into the training network, our model is able to better learn the hidden connections between categories. Experimental results demonstrate the effectiveness of our approach, showing its ability to enhance performance on the PASCAL VOC 2012 dataset and surpass existing state-of-the-art methods in WSSS. </p>
<blockquote>
<p>å¼±ç›‘ç£è¯­ä¹‰åˆ†å‰²ï¼ˆWSSSï¼‰åˆ©ç”¨å›¾åƒçº§åˆ«çš„æ ‡ç­¾ï¼Œå› å…¶æˆæœ¬æ•ˆç›Šè€Œå¤‡å—å…³æ³¨ã€‚ä¹‹å‰çš„æ–¹æ³•ä¸»è¦å¼ºè°ƒç±»é—´å·®å¼‚ï¼Œä»¥é¿å…å¯èƒ½å¯¼è‡´é”™è¯¯æ¿€æ´»çš„ç±»è¯­ä¹‰æ¨¡ç³Šã€‚ç„¶è€Œï¼Œä»–ä»¬å¿½è§†äº†ç±»ä¼¼ç±»åˆ«ä¹‹é—´å…±äº«ä¿¡æ¯çš„ç§¯æä½œç”¨ã€‚åŒä¸€èšç±»ä¸­çš„ç±»åˆ«å…±äº«ä¸€äº›ç›¸ä¼¼ç‰¹å¾ã€‚å…è®¸æ¨¡å‹è¯†åˆ«è¿™äº›ç‰¹å¾å¯ä»¥è¿›ä¸€æ­¥ç¼“è§£è¿™äº›ç±»åˆ«ä¹‹é—´çš„è¯­ä¹‰æ¨¡ç³Šã€‚ä¸ºäº†æœ‰æ•ˆè¯†åˆ«å’Œåˆ©ç”¨è¿™äº›å…±äº«ä¿¡æ¯ï¼Œæœ¬æ–‡å¼•å…¥äº†ä¸€ç§æ–°å‹çš„WSSSæ¡†æ¶ï¼Œç§°ä¸ºæç¤ºç±»åˆ«èšç±»ï¼ˆPCCï¼‰ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬æ¢ç´¢äº†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰é€šè¿‡æç¤ºæ¨å¯¼ç±»åˆ«èšç±»çš„èƒ½åŠ›ã€‚è¿™äº›èšç±»æœ‰æ•ˆåœ°ä»£è¡¨äº†ç±»åˆ«ä¹‹é—´çš„å†…åœ¨å…³ç³»ã€‚é€šè¿‡å°†è¿™ç§å…³ç³»ä¿¡æ¯é›†æˆåˆ°è®­ç»ƒç½‘ç»œä¸­ï¼Œæˆ‘ä»¬çš„æ¨¡å‹èƒ½å¤Ÿæ›´å¥½åœ°å­¦ä¹ ç±»åˆ«ä¹‹é—´çš„éšè—è¿æ¥ã€‚å®éªŒç»“æœè¯æ˜äº†æˆ‘ä»¬çš„æ–¹æ³•çš„æœ‰æ•ˆæ€§ï¼Œè¡¨æ˜å…¶åœ¨PASCAL VOC 2012æ•°æ®é›†ä¸Šçš„æ€§èƒ½æœ‰æ‰€æå‡ï¼Œå¹¶è¶…è¶Šäº†ç°æœ‰çš„WSSSå…ˆè¿›æ–¹æ³•ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.13823v2">PDF</a> Accepted at CVPR 2025 ELVM</p>
<p><strong>æ‘˜è¦</strong></p>
<p>åŸºäºå›¾åƒçº§æ ‡ç­¾çš„å¼±ç›‘ç£è¯­ä¹‰åˆ†å‰²ï¼ˆWSSSï¼‰å› å…¶æˆæœ¬æ•ˆç›Šè€Œå—åˆ°å¹¿æ³›å…³æ³¨ã€‚ä»¥å¾€çš„æ–¹æ³•ä¸»è¦å¼ºåŒ–ç±»é—´å·®å¼‚ä»¥é¿å…è¯­ä¹‰æ¨¡ç³Šå¯¼è‡´çš„é”™è¯¯æ¿€æ´»ï¼Œä½†å¿½ç•¥äº†ç›¸ä¼¼ç±»åˆ«é—´å…±äº«ä¿¡æ¯çš„ç§¯æä½œç”¨ã€‚æœ¬æ–‡å¼•å…¥äº†ä¸€ç§åä¸ºPrompt Categories Clusteringï¼ˆPCCï¼‰çš„æ–°å‹WSSSæ¡†æ¶ï¼Œèƒ½å¤Ÿè¯†åˆ«å¹¶åˆ©ç”¨ç±»åˆ«é—´çš„å…±äº«ä¿¡æ¯ã€‚é€šè¿‡å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„æç¤ºèƒ½åŠ›ï¼Œæˆ‘ä»¬æ¢ç´¢äº†ç±»åˆ«èšç±»çš„å½¢æˆï¼Œè¿™äº›èšç±»æœ‰æ•ˆåœ°ä»£è¡¨äº†ç±»åˆ«ä¹‹é—´çš„å†…åœ¨å…³ç³»ã€‚é€šè¿‡å°†è¿™ç§å…³ç³»ä¿¡æ¯æ•´åˆåˆ°è®­ç»ƒç½‘ç»œä¸­ï¼Œæˆ‘ä»¬çš„æ¨¡å‹èƒ½å¤Ÿæ›´å¥½åœ°å­¦ä¹ ç±»åˆ«ä¹‹é—´çš„éšè—è”ç³»ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨PASCAL VOC 2012æ•°æ®é›†ä¸Šçš„æ€§èƒ½æœ‰æ‰€æå‡ï¼Œå¹¶è¶…è¶Šäº†ç°æœ‰çš„WSSSé¢†åŸŸæœ€å…ˆè¿›çš„æ–¹æ³•ã€‚</p>
<p><strong>è¦ç‚¹é€Ÿè§ˆ</strong></p>
<ul>
<li>WSSSæ–¹æ³•åˆ©ç”¨å›¾åƒçº§æ ‡ç­¾ï¼Œæ—¨åœ¨è§£å†³è¯­ä¹‰æ¨¡ç³Šé—®é¢˜ã€‚</li>
<li>ä»¥å¾€æ–¹æ³•ä¸»è¦å¼ºåŒ–ç±»é—´å·®å¼‚ï¼Œä½†å¿½ç•¥äº†ç›¸ä¼¼ç±»åˆ«é—´å…±äº«ä¿¡æ¯çš„ç§¯æä½œç”¨ã€‚</li>
<li>æœ¬ç ”ç©¶å¼•å…¥äº†Prompt Categories Clusteringï¼ˆPCCï¼‰æ¡†æ¶ï¼Œåˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹è¯†åˆ«ç±»åˆ«é—´çš„å…±äº«ä¿¡æ¯ã€‚</li>
<li>PCCé€šè¿‡å½¢æˆç±»åˆ«èšç±»æ¥ä»£è¡¨ç±»åˆ«é—´çš„å†…åœ¨å…³ç³»ã€‚</li>
<li>å°†å…³ç³»ä¿¡æ¯æ•´åˆåˆ°è®­ç»ƒç½‘ç»œä¸­ï¼Œæå‡æ¨¡å‹å­¦ä¹ ç±»åˆ«é—´éšè—è”ç³»çš„èƒ½åŠ›ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.13823">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-db08b845ae6f3b0bc4429182ec8cb64d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-7fc0d8b5c152b0b199031e611bca1f22.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-78a3be64951c4c0690c870c14da38a1a.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="LUIEO-A-Lightweight-Model-for-Integrating-Underwater-Image-Enhancement-and-Object-Detection"><a href="#LUIEO-A-Lightweight-Model-for-Integrating-Underwater-Image-Enhancement-and-Object-Detection" class="headerlink" title="LUIEO: A Lightweight Model for Integrating Underwater Image Enhancement   and Object Detection"></a>LUIEO: A Lightweight Model for Integrating Underwater Image Enhancement   and Object Detection</h2><p><strong>Authors:Bin Li, Li Li, Zhenwei Zhang, Yuping Duan</strong></p>
<p>Underwater optical images inevitably suffer from various degradation factors such as blurring, low contrast, and color distortion, which hinder the accuracy of object detection tasks. Due to the lack of paired underwater&#x2F;clean images, most research methods adopt a strategy of first enhancing and then detecting, resulting in a lack of feature communication between the two learning tasks. On the other hand, due to the contradiction between the diverse degradation factors of underwater images and the limited number of samples, existing underwater enhancement methods are difficult to effectively enhance degraded images of unknown water bodies, thereby limiting the improvement of object detection accuracy. Therefore, most underwater target detection results are still displayed on degraded images, making it difficult to visually judge the correctness of the detection results. To address the above issues, this paper proposes a multi-task learning method that simultaneously enhances underwater images and improves detection accuracy. Compared with single-task learning, the integrated model allows for the dynamic adjustment of information communication and sharing between different tasks. Due to the fact that real underwater images can only provide annotated object labels, this paper introduces physical constraints to ensure that object detection tasks do not interfere with image enhancement tasks. Therefore, this article introduces a physical module to decompose underwater images into clean images, background light, and transmission images and uses a physical model to calculate underwater images for self-supervision. Numerical experiments demonstrate that the proposed model achieves satisfactory results in visual performance, object detection accuracy, and detection efficiency compared to state-of-the-art comparative methods. </p>
<blockquote>
<p>æ°´ä¸‹å…‰å­¦å›¾åƒä¸å¯é¿å…åœ°å—åˆ°æ¨¡ç³Šã€ä½å¯¹æ¯”åº¦å’Œé¢œè‰²å¤±çœŸç­‰å¤šç§é™è´¨å› ç´ çš„å½±å“ï¼Œä»è€Œé˜»ç¢äº†ç›®æ ‡æ£€æµ‹ä»»åŠ¡çš„å‡†ç¡®æ€§ã€‚ç”±äºç¼ºå°‘é…å¯¹çš„æ°´ä¸‹&#x2F;æ¸…æ´å›¾åƒï¼Œå¤§å¤šæ•°ç ”ç©¶æ–¹æ³•é‡‡ç”¨å…ˆå¢å¼ºåæ£€æµ‹çš„ç­–ç•¥ï¼Œå¯¼è‡´ä¸¤ä¸ªå­¦ä¹ ä»»åŠ¡ä¹‹é—´ç¼ºä¹ç‰¹å¾äº¤æµã€‚å¦ä¸€æ–¹é¢ï¼Œç”±äºæ°´ä¸‹å›¾åƒçš„å„ç§é™è´¨å› ç´ ä¸æ ·æœ¬æ•°é‡æœ‰é™ä¹‹é—´çš„çŸ›ç›¾ï¼Œç°æœ‰çš„æ°´ä¸‹å¢å¼ºæ–¹æ³•éš¾ä»¥æœ‰æ•ˆå¢å¼ºæœªçŸ¥æ°´ä½“çš„é€€åŒ–å›¾åƒï¼Œä»è€Œé™åˆ¶äº†ç›®æ ‡æ£€æµ‹å‡†ç¡®åº¦çš„æé«˜ã€‚å› æ­¤ï¼Œå¤§å¤šæ•°æ°´ä¸‹ç›®æ ‡æ£€æµ‹ç»“æœä»æ˜¾ç¤ºåœ¨é€€åŒ–å›¾åƒä¸Šï¼Œå¾ˆéš¾ç›´è§‚åˆ¤æ–­æ£€æµ‹ç»“æœçš„æ­£ç¡®æ€§ã€‚ä¸ºäº†è§£å†³ä¸Šè¿°é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§å¤šä»»åŠ¡å­¦ä¹ æ–¹æ³•ï¼ŒåŒæ—¶å¢å¼ºæ°´ä¸‹å›¾åƒå¹¶æé«˜æ£€æµ‹å‡†ç¡®æ€§ã€‚ä¸å•ä»»åŠ¡å­¦ä¹ ç›¸æ¯”ï¼Œé›†æˆæ¨¡å‹å…è®¸ä¸åŒä»»åŠ¡ä¹‹é—´åŠ¨æ€è°ƒæ•´ä¿¡æ¯é€šä¿¡å’Œå…±äº«ã€‚ç”±äºçœŸå®æ°´ä¸‹å›¾åƒåªèƒ½æä¾›æ³¨é‡Šçš„å¯¹è±¡æ ‡ç­¾ï¼Œæœ¬æ–‡å¼•å…¥ç‰©ç†çº¦æŸä»¥ç¡®ä¿ç›®æ ‡æ£€æµ‹ä»»åŠ¡ä¸ä¼šå¹²æ‰°å›¾åƒå¢å¼ºä»»åŠ¡ã€‚å› æ­¤ï¼Œæœ¬æ–‡å¼•å…¥äº†ä¸€ä¸ªç‰©ç†æ¨¡å—æ¥å°†æ°´ä¸‹å›¾åƒåˆ†è§£ä¸ºæ¸…æ´å›¾åƒã€èƒŒæ™¯å…‰å’Œä¼ è¾“å›¾åƒï¼Œå¹¶ä½¿ç”¨ç‰©ç†æ¨¡å‹è®¡ç®—æ°´ä¸‹å›¾åƒè¿›è¡Œè‡ªæˆ‘ç›‘ç£ã€‚æ•°å€¼å®éªŒè¡¨æ˜ï¼Œä¸æœ€å…ˆè¿›çš„æ¯”è¾ƒæ–¹æ³•ç›¸æ¯”ï¼Œæ‰€ææ¨¡å‹åœ¨è§†è§‰æ€§èƒ½ã€ç›®æ ‡æ£€æµ‹å‡†ç¡®æ€§å’Œæ£€æµ‹æ•ˆç‡æ–¹é¢éƒ½å–å¾—äº†ä»¤äººæ»¡æ„çš„ç»“æœã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.07009v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºä¸€ç§å¤šä»»åŠ¡å­¦ä¹ æ–¹æ³•ï¼Œæ—¨åœ¨åŒæ—¶æå‡æ°´ä¸‹å›¾åƒè´¨é‡å¹¶æé«˜å…¶æ£€æµ‹ç²¾åº¦ã€‚é¢å¯¹æ°´ä¸‹å›¾åƒæ¨¡ç³Šã€å¯¹æ¯”åº¦ä½ã€è‰²å½©å¤±çœŸç­‰é€€åŒ–é—®é¢˜ï¼Œä»¥åŠç¼ºä¹é…å¯¹çš„æ°´ä¸‹&#x2F;æ¸…æ™°å›¾åƒæ ·æœ¬ï¼Œè¯¥ç ”ç©¶é€šè¿‡å¼•å…¥ç‰©ç†çº¦æŸæ¨¡å—åˆ†è§£æ°´ä¸‹å›¾åƒä¸ºæ¸…æ´å›¾åƒã€èƒŒæ™¯å…‰å’Œé€å°„å›¾åƒï¼Œå¹¶åˆ©ç”¨ç‰©ç†æ¨¡å‹è®¡ç®—æ°´ä¸‹å›¾åƒè¿›è¡Œè‡ªæˆ‘ç›‘ç£ï¼Œå®ç°åŠ¨æ€è°ƒæ•´ä¸åŒä»»åŠ¡é—´çš„ä¿¡æ¯å…±äº«ä¸äº¤æµã€‚å®éªŒè¡¨æ˜ï¼Œè¯¥æ¨¡å‹åœ¨è§†è§‰æ€§èƒ½ã€ç›®æ ‡æ£€æµ‹ç²¾åº¦å’Œæ£€æµ‹æ•ˆç‡æ–¹é¢å‡å–å¾—æ»¡æ„ç»“æœã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æ°´ä¸‹å›¾åƒé€€åŒ–é—®é¢˜å¦‚æ¨¡ç³Šã€ä½å¯¹æ¯”åº¦å’Œè‰²å½©å¤±çœŸç­‰ï¼Œå½±å“ç›®æ ‡æ£€æµ‹çš„å‡†ç¡®æ€§ã€‚</li>
<li>ç¼ºä¹é…å¯¹çš„æ°´ä¸‹&#x2F;æ¸…æ™°å›¾åƒæ ·æœ¬ï¼Œä½¿å¾—ç°æœ‰æ°´ä¸‹å¢å¼ºæ–¹æ³•åœ¨æœªçŸ¥æ°´ä½“ä¸­çš„å›¾åƒå¢å¼ºæ•ˆæœæœ‰é™ã€‚</li>
<li>æå‡ºä¸€ç§å¤šä»»åŠ¡å­¦ä¹ æ–¹æ³•ï¼ŒåŒæ—¶å¢å¼ºæ°´ä¸‹å›¾åƒå¹¶æå‡æ£€æµ‹ç²¾åº¦ã€‚</li>
<li>å¼•å…¥ç‰©ç†çº¦æŸæ¨¡å—åˆ†è§£æ°´ä¸‹å›¾åƒï¼Œä¾¿äºè‡ªæˆ‘ç›‘ç£å’Œå­¦ä¹ ã€‚</li>
<li>æ¨¡å‹é€šè¿‡åŠ¨æ€è°ƒæ•´ä¸åŒä»»åŠ¡é—´çš„ä¿¡æ¯å…±äº«ä¸äº¤æµï¼Œä¼˜åŒ–æ£€æµ‹æ•ˆæœã€‚</li>
<li>å®éªŒè¯æ˜è¯¥æ¨¡å‹åœ¨è§†è§‰æ€§èƒ½ã€ç›®æ ‡æ£€æµ‹ç²¾åº¦å’Œæ£€æµ‹æ•ˆç‡ä¸Šè¡¨ç°ä¼˜å¼‚ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.07009">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-9b6214872956c977f479a0f7d339ddfe.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-384e68499488a0c885e7e2bd1e85533b.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-d4da24f58bd8a02392303291144d0fa4.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-a5b64145dbd3e42a6714aac945c01e61.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-2765fe9af753475265324ca57f60103f.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-8a52cdf41c73bdc2a2676f5e2ec8a8d8.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-fac922265dc3184831cd349fccf0d438.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="Distilling-Spectral-Graph-for-Object-Context-Aware-Open-Vocabulary-Semantic-Segmentation"><a href="#Distilling-Spectral-Graph-for-Object-Context-Aware-Open-Vocabulary-Semantic-Segmentation" class="headerlink" title="Distilling Spectral Graph for Object-Context Aware Open-Vocabulary   Semantic Segmentation"></a>Distilling Spectral Graph for Object-Context Aware Open-Vocabulary   Semantic Segmentation</h2><p><strong>Authors:Chanyoung Kim, Dayun Ju, Woojung Han, Ming-Hsuan Yang, Seong Jae Hwang</strong></p>
<p>Open-Vocabulary Semantic Segmentation (OVSS) has advanced with recent vision-language models (VLMs), enabling segmentation beyond predefined categories through various learning schemes. Notably, training-free methods offer scalable, easily deployable solutions for handling unseen data, a key goal of OVSS. Yet, a critical issue persists: lack of object-level context consideration when segmenting complex objects in the challenging environment of OVSS based on arbitrary query prompts. This oversight limits modelsâ€™ ability to group semantically consistent elements within object and map them precisely to user-defined arbitrary classes. In this work, we introduce a novel approach that overcomes this limitation by incorporating object-level contextual knowledge within images. Specifically, our model enhances intra-object consistency by distilling spectral-driven features from vision foundation models into the attention mechanism of the visual encoder, enabling semantically coherent components to form a single object mask. Additionally, we refine the text embeddings with zero-shot object presence likelihood to ensure accurate alignment with the specific objects represented in the images. By leveraging object-level contextual knowledge, our proposed approach achieves state-of-the-art performance with strong generalizability across diverse datasets. </p>
<blockquote>
<p>å¼€æ”¾è¯æ±‡è¯­ä¹‰åˆ†å‰²ï¼ˆOVSSï¼‰éšç€æœ€è¿‘çš„è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMsï¼‰çš„å‘å±•è€Œè¿›æ­¥ï¼Œé€šè¿‡å„ç§å­¦ä¹ æ–¹æ¡ˆå®ç°äº†è¶…å‡ºé¢„å®šç±»åˆ«çš„åˆ†å‰²ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œæ— è®­ç»ƒæ–¹æ³•ä¸ºå¤„ç†æœªè§æ•°æ®æä¾›äº†å¯æ‰©å±•ã€æ˜“äºéƒ¨ç½²çš„è§£å†³æ–¹æ¡ˆï¼Œè¿™æ˜¯OVSSçš„å…³é”®ç›®æ ‡ã€‚ç„¶è€Œï¼Œä¸€ä¸ªå…³é”®é—®é¢˜ä¾ç„¶å­˜åœ¨ï¼šåœ¨åŸºäºä»»æ„æŸ¥è¯¢æç¤ºçš„OVSSçš„å¤æ‚ç¯å¢ƒä¸­ï¼Œå¯¹å¤æ‚å¯¹è±¡è¿›è¡Œåˆ†å‰²æ—¶ç¼ºä¹å¯¹è±¡çº§åˆ«çš„ä¸Šä¸‹æ–‡è€ƒè™‘ã€‚è¿™ç§ç–å¿½é™åˆ¶äº†æ¨¡å‹åœ¨å¯¹è±¡å†…ç»„åˆè¯­ä¹‰ä¸€è‡´å…ƒç´ çš„èƒ½åŠ›ï¼Œå¹¶å‡†ç¡®åœ°å°†å®ƒä»¬æ˜ å°„åˆ°ç”¨æˆ·å®šä¹‰çš„ä»»æ„ç±»åˆ«ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬ä»‹ç»äº†ä¸€ç§å…‹æœè¿™ä¸€é™åˆ¶çš„æ–°æ–¹æ³•ï¼Œè¯¥æ–¹æ³•é€šè¿‡åœ¨å›¾åƒä¸­èå…¥å¯¹è±¡çº§åˆ«çš„ä¸Šä¸‹æ–‡çŸ¥è¯†ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬çš„æ¨¡å‹é€šè¿‡ä»è§†è§‰åŸºç¡€æ¨¡å‹ä¸­æç‚¼å…‰è°±é©±åŠ¨ç‰¹å¾å¹¶å°†å…¶è’¸é¦åˆ°è§†è§‰ç¼–ç å™¨çš„æ³¨æ„åŠ›æœºåˆ¶ä¸­ï¼Œå¢å¼ºäº†å¯¹è±¡å†…éƒ¨çš„è¿è´¯æ€§ï¼Œä½¿å¾—è¯­ä¹‰ä¸€è‡´çš„ç»„ä»¶èƒ½å¤Ÿå½¢æˆå•ä¸ªå¯¹è±¡æ©ç ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜é€šè¿‡é›¶æ ·æœ¬å¯¹è±¡å­˜åœ¨æ¦‚ç‡å¯¹æ–‡æœ¬åµŒå…¥è¿›è¡Œäº†ç²¾ç‚¼ï¼Œä»¥ç¡®ä¿ä¸å›¾åƒä¸­è¡¨ç¤ºçš„ç‰¹å®šå¯¹è±¡çš„å‡†ç¡®å¯¹é½ã€‚é€šè¿‡åˆ©ç”¨å¯¹è±¡çº§åˆ«çš„ä¸Šä¸‹æ–‡çŸ¥è¯†ï¼Œæˆ‘ä»¬æå‡ºçš„æ–¹æ³•åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šå®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œå¹¶å…·æœ‰è¾ƒå¼ºçš„æ³›åŒ–èƒ½åŠ›ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2411.17150v3">PDF</a> </p>
<p><strong>Summary</strong><br>æœ¬æ–‡ä¸»è¦ä»‹ç»äº†å¼€æ”¾è¯æ±‡è¯­ä¹‰åˆ†å‰²ï¼ˆOVSSï¼‰çš„æœ€æ–°è¿›å±•ï¼Œç‰¹åˆ«æ˜¯å¦‚ä½•åˆ©ç”¨è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMsï¼‰çš„å…ˆè¿›æŠ€æœ¯å®ç°è¶…è¶Šé¢„å®šç±»åˆ«çš„åˆ†å‰²ã€‚æ–‡ç« é‡ç‚¹ä»‹ç»äº†ä¸€ç§æ–°çš„æ–¹æ³•ï¼Œé€šè¿‡èå…¥å¯¹è±¡çº§åˆ«çš„ä¸Šä¸‹æ–‡çŸ¥è¯†æ¥è§£å†³åœ¨å¼€æ”¾è¯æ±‡è¯­ä¹‰åˆ†å‰²ä¸­å› ä»»æ„æŸ¥è¯¢æç¤ºè€Œå¯¼è‡´çš„å¤æ‚å¯¹è±¡åˆ†å‰²é—®é¢˜ã€‚è¯¥æ–¹æ³•æé«˜äº†æ¨¡å‹çš„æ€§èƒ½ï¼Œä½¿æ¨¡å‹èƒ½å¤Ÿåœ¨å„ç§æ•°æ®é›†ä¸Šå®ç°æœ€å…ˆè¿›çš„æ€§èƒ½å¹¶å…·æœ‰å¼ºå¤§çš„æ³›åŒ–èƒ½åŠ›ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¼€æ”¾è¯æ±‡è¯­ä¹‰åˆ†å‰²ï¼ˆOVSSï¼‰å€ŸåŠ©è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMsï¼‰çš„å…ˆè¿›æŠ€æœ¯ï¼Œå®ç°äº†è¶…è¶Šé¢„å®šç±»åˆ«çš„åˆ†å‰²ã€‚</li>
<li>è®­ç»ƒå…è´¹çš„æ–¹æ³•ä¸ºå¤„ç†æœªè§æ•°æ®æä¾›äº†å¯ä¼¸ç¼©å’Œæ˜“äºéƒ¨ç½²çš„è§£å†³æ–¹æ¡ˆï¼Œè¿™æ˜¯OVSSçš„å…³é”®ç›®æ ‡ã€‚</li>
<li>å½“å‰å­˜åœ¨çš„é—®é¢˜æ˜¯ï¼Œåœ¨åŸºäºä»»æ„æŸ¥è¯¢æç¤ºçš„å¼€æ”¾è¯æ±‡è¯­ä¹‰åˆ†å‰²çš„å¤æ‚ç¯å¢ƒä¸­ï¼Œç¼ºä¹å¯¹è±¡çº§åˆ«çš„ä¸Šä¸‹æ–‡è€ƒè™‘ã€‚</li>
<li>æ–°æ–¹æ³•é€šè¿‡èå…¥å¯¹è±¡çº§åˆ«çš„ä¸Šä¸‹æ–‡çŸ¥è¯†æ¥è§£å†³æ­¤é—®é¢˜ï¼Œæé«˜äº†æ¨¡å‹å¯¹å¯¹è±¡å†…éƒ¨ä¸€è‡´æ€§çš„è¡¨ç°ã€‚</li>
<li>è¯¥æ–¹æ³•é€šè¿‡æç‚¼è§†è§‰åŸºç¡€æ¨¡å‹çš„é¢‘è°±é©±åŠ¨ç‰¹å¾å¹¶æ³¨å…¥è§†è§‰ç¼–ç å™¨çš„æ³¨æ„åŠ›æœºåˆ¶æ¥å®ç°ã€‚</li>
<li>å¯¹æ–‡æœ¬åµŒå…¥è¿›è¡Œæ”¹è¿›ï¼Œä½¿ç”¨é›¶æ ·æœ¬å¯¹è±¡å­˜åœ¨å¯èƒ½æ€§æ¥ç¡®ä¿ä¸å›¾åƒä¸­è¡¨ç¤ºçš„ç‰¹å®šå¯¹è±¡çš„å‡†ç¡®å¯¹é½ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2411.17150">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-38ce5f2d9890b4959a80e23e4bff8955.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-5b17542025b8df1633d8f8c54cbb60b5.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-b0bdf034384f8da4962c37811fdb7ccf.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-70e98ebfbdecc978c059d2cb079af8da.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-e5470087ecfe696acad0206281682d35.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="A-Survey-and-Evaluation-of-Adversarial-Attacks-for-Object-Detection"><a href="#A-Survey-and-Evaluation-of-Adversarial-Attacks-for-Object-Detection" class="headerlink" title="A Survey and Evaluation of Adversarial Attacks for Object Detection"></a>A Survey and Evaluation of Adversarial Attacks for Object Detection</h2><p><strong>Authors:Khoi Nguyen Tiet Nguyen, Wenyu Zhang, Kangkang Lu, Yuhuan Wu, Xingjian Zheng, Hui Li Tan, Liangli Zhen</strong></p>
<p>Deep learning models achieve remarkable accuracy in computer vision tasks, yet remain vulnerable to adversarial examplesâ€“carefully crafted perturbations to input images that can deceive these models into making confident but incorrect predictions. This vulnerability pose significant risks in high-stakes applications such as autonomous vehicles, security surveillance, and safety-critical inspection systems. While the existing literature extensively covers adversarial attacks in image classification, comprehensive analyses of such attacks on object detection systems remain limited. This paper presents a novel taxonomic framework for categorizing adversarial attacks specific to object detection architectures, synthesizes existing robustness metrics, and provides a comprehensive empirical evaluation of state-of-the-art attack methodologies on popular object detection models, including both traditional detectors and modern detectors with vision-language pretraining. Through rigorous analysis of open-source attack implementations and their effectiveness across diverse detection architectures, we derive key insights into attack characteristics. Furthermore, we delineate critical research gaps and emerging challenges to guide future investigations in securing object detection systems against adversarial threats. Our findings establish a foundation for developing more robust detection models while highlighting the urgent need for standardized evaluation protocols in this rapidly evolving domain. </p>
<blockquote>
<p>æ·±åº¦å­¦ä¹ æ¨¡å‹åœ¨è®¡ç®—æœºè§†è§‰ä»»åŠ¡ä¸­å–å¾—äº†ä»¤äººç©ç›®çš„å‡†ç¡®æ€§ï¼Œä½†ä»ç„¶å®¹æ˜“å—åˆ°å¯¹æŠ—æ ·æœ¬çš„å¨èƒã€‚å¯¹æŠ—æ ·æœ¬æ˜¯å¯¹è¾“å…¥å›¾åƒè¿›è¡Œç²¾å¿ƒåˆ¶ä½œçš„æ‰°åŠ¨ï¼Œå¯ä»¥æ¬ºéª—è¿™äº›æ¨¡å‹åšå‡ºè‡ªä¿¡ä½†é”™è¯¯çš„é¢„æµ‹ã€‚è¿™ç§è„†å¼±æ€§åœ¨é«˜é£é™©åº”ç”¨ï¼ˆå¦‚è‡ªåŠ¨é©¾é©¶ã€å®‰å…¨ç›‘æ§å’Œå…³é”®å®‰å…¨æ£€æµ‹ç³»ç»Ÿï¼‰ä¸­æ„æˆäº†é‡å¤§é£é™©ã€‚å°½ç®¡ç°æœ‰æ–‡çŒ®å¹¿æ³›æ¶µç›–äº†å›¾åƒåˆ†ç±»ä¸­çš„å¯¹æŠ—æ€§æ”»å‡»ï¼Œä½†å¯¹ç›®æ ‡æ£€æµ‹ç³»ç»Ÿä¸­æ­¤ç±»æ”»å‡»çš„ç»¼åˆåˆ†æä»ç„¶æœ‰é™ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ä¸ªé’ˆå¯¹ç›®æ ‡æ£€æµ‹æ¶æ„çš„å¯¹æŠ—æ€§æ”»å‡»çš„æ–°å‹åˆ†ç±»æ¡†æ¶ï¼Œå¯¹ç°æœ‰çš„ç¨³å¥æ€§æŒ‡æ ‡è¿›è¡Œäº†ç»¼åˆï¼Œå¯¹æµè¡Œçš„ç›®æ ‡æ£€æµ‹æ¨¡å‹ä¸Šçš„æœ€æ–°æ”»å‡»æ–¹æ³•è¿›è¡Œäº†å…¨é¢çš„ç»éªŒè¯„ä¼°ï¼ŒåŒ…æ‹¬ä¼ ç»Ÿæ£€æµ‹å™¨å’Œä½¿ç”¨è§†è§‰è¯­è¨€é¢„è®­ç»ƒçš„ç°ä»£æ£€æµ‹å™¨ã€‚é€šè¿‡å¯¹å¼€æºæ”»å‡»å®ç°åŠå…¶åœ¨ä¸åŒæ£€æµ‹æ¶æ„ä¸­çš„æœ‰æ•ˆæ€§è¿›è¡Œä¸¥è°¨åˆ†æï¼Œæˆ‘ä»¬è·å¾—äº†å…³äºæ”»å‡»ç‰¹æ€§çš„å…³é”®è§è§£ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æŒ‡å‡ºäº†å…³é”®çš„ç ”ç©¶ç©ºç™½å’Œæ–°å…´æŒ‘æˆ˜ï¼Œä¸ºæœªæ¥çš„ç ”ç©¶æä¾›äº†æŒ‡å¯¼ï¼Œä»¥ä¿æŠ¤ç›®æ ‡æ£€æµ‹ç³»ç»Ÿå…å—å¯¹æŠ—æ€§å¨èƒã€‚æˆ‘ä»¬çš„ç ”ç©¶ä¸ºå¼€å‘æ›´ç¨³å¥çš„æ£€æµ‹æ¨¡å‹å¥ å®šäº†åŸºç¡€ï¼ŒåŒæ—¶å¼ºè°ƒäº†åœ¨è¿™ä¸€å¿«é€Ÿå‘å±•é¢†åŸŸåˆ¶å®šæ ‡å‡†åŒ–è¯„ä¼°åè®®çš„ç´§è¿«éœ€æ±‚ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2408.01934v4">PDF</a> Accepted for publication in the IEEE Transactions on Neural Networks   and Learning Systems (TNNLS)</p>
<p><strong>Summary</strong></p>
<p>æ·±åº¦å­¦ä¹ æ¨¡å‹åœ¨è®¡ç®—æœºè§†è§‰ä»»åŠ¡ä¸­å–å¾—äº†æƒŠäººçš„å‡†ç¡®æ€§ï¼Œä½†åœ¨é¢ä¸´å¯¹æŠ—æ ·æœ¬æ—¶ä»æ˜¾å¾—è„†å¼±ã€‚å¯¹æŠ—æ ·æœ¬æ˜¯ç²¾å¿ƒåˆ¶ä½œçš„è¾“å…¥å›¾åƒçš„æ‰°åŠ¨ï¼Œå¯ä»¥æ¬ºéª—æ¨¡å‹åšå‡ºè‡ªä¿¡ä½†é”™è¯¯çš„é¢„æµ‹ã€‚è¿™ä¸€æ¼æ´åœ¨é«˜é£é™©åº”ç”¨ï¼ˆå¦‚è‡ªåŠ¨é©¾é©¶ã€å®‰å…¨ç›‘æ§å’Œå…³é”®å®‰å…¨æ£€æŸ¥ç³»ç»Ÿï¼‰ä¸­æ„æˆé‡å¤§é£é™©ã€‚æœ¬æ–‡æå‡ºäº†é’ˆå¯¹å¯¹è±¡æ£€æµ‹æ¶æ„çš„å¯¹æŠ—æ”»å‡»çš„æ–°å‹åˆ†ç±»æ¡†æ¶ï¼Œç»¼åˆäº†ç°æœ‰çš„ç¨³å¥æ€§æŒ‡æ ‡ï¼Œå¹¶å¯¹æµè¡Œå¯¹è±¡æ£€æµ‹æ¨¡å‹ä¸Šçš„æœ€æ–°æ”»å‡»æ–¹æ³•è¿›è¡Œäº†å…¨é¢çš„å®è¯è¯„ä¼°ï¼ŒåŒ…æ‹¬ä¼ ç»Ÿæ£€æµ‹å™¨å’Œå…·æœ‰è§†è§‰è¯­è¨€é¢„è®­ç»ƒçš„ç°ä»£æ£€æµ‹å™¨ã€‚é€šè¿‡å¯¹å¼€æºæ”»å‡»å®ç°çš„ä¸¥æ ¼åˆ†æä»¥åŠå®ƒä»¬åœ¨å„ç§æ£€æµ‹æ¶æ„ä¸­çš„æœ‰æ•ˆæ€§ï¼Œæˆ‘ä»¬è·å¾—äº†å…³äºæ”»å‡»ç‰¹æ€§çš„å…³é”®è§è§£ã€‚æˆ‘ä»¬çš„å‘ç°ä¸ºå¼€å‘æ›´ç¨³å¥çš„æ£€æµ‹æ¨¡å‹å¥ å®šäº†åŸºç¡€ï¼ŒåŒæ—¶å¼ºè°ƒäº†åœ¨è¿™ä¸€å¿«é€Ÿå‘å±•é¢†åŸŸä¸­å¯¹æ ‡å‡†åŒ–è¯„ä¼°åè®®çš„è¿«åˆ‡éœ€æ±‚ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æ·±åº¦å­¦ä¹ æ¨¡å‹åœ¨è®¡ç®—æœºè§†è§‰ä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ï¼Œä½†åœ¨é¢å¯¹å¯¹æŠ—æ ·æœ¬æ—¶ä»å®¹æ˜“å‡ºé”™ã€‚</li>
<li>å¯¹æŠ—æ ·æœ¬å¯ä»¥æ¬ºéª—æ¨¡å‹åšå‡ºè‡ªä¿¡ä½†é”™è¯¯çš„é¢„æµ‹ï¼Œè¿™åœ¨é«˜é£é™©åº”ç”¨ä¸­æ„æˆé‡å¤§é£é™©ã€‚</li>
<li>å½“å‰æ–‡çŒ®å¯¹å›¾åƒåˆ†ç±»ä¸­çš„å¯¹æŠ—æ”»å‡»è¿›è¡Œäº†å¹¿æ³›è¦†ç›–ï¼Œä½†å¯¹å¯¹è±¡æ£€æµ‹ç³»ç»Ÿä¸­çš„å¯¹æŠ—æ”»å‡»çš„ç»¼åˆåˆ†æä»ç„¶æœ‰é™ã€‚</li>
<li>æœ¬æ–‡æå‡ºäº†é’ˆå¯¹å¯¹è±¡æ£€æµ‹æ¶æ„çš„å¯¹æŠ—æ”»å‡»çš„æ–°å‹åˆ†ç±»æ¡†æ¶ã€‚</li>
<li>ç»¼åˆäº†ç°æœ‰çš„ç¨³å¥æ€§æŒ‡æ ‡ï¼Œå¹¶å¯¹æœ€æ–°æ”»å‡»æ–¹æ³•åœ¨æµè¡Œå¯¹è±¡æ£€æµ‹æ¨¡å‹ä¸Šçš„è¡¨ç°è¿›è¡Œäº†å…¨é¢è¯„ä¼°ã€‚</li>
<li>é€šè¿‡å¯¹å¼€æºæ”»å‡»å®æ–½çš„ä¸¥æ ¼åˆ†æï¼Œè·å¾—äº†å…³äºæ”»å‡»ç‰¹æ€§çš„å…³é”®è§è§£ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2408.01934">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-67ab0cf66053c977b94a36e3e0975279.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-cee0fb9ffa038544d3d77616647ca7f4.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-737ba1841bf835060cb5f0aa6d336ee5.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-7c530ba2881a7bf706d2fdcb528cd247.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ee6fec97784057899f8d30b2277adfd7.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-e436f56f2fb30525a668208ad651dac4.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-04-09/%E6%A3%80%E6%B5%8B_%E5%88%86%E5%89%B2_%E8%B7%9F%E8%B8%AA/">https://kedreamix.github.io/Talk2Paper/Paper/2025-04-09/%E6%A3%80%E6%B5%8B_%E5%88%86%E5%89%B2_%E8%B7%9F%E8%B8%AA/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/%E6%A3%80%E6%B5%8B-%E5%88%86%E5%89%B2-%E8%B7%9F%E8%B8%AA/">
                                    <span class="chip bg-color">æ£€æµ‹/åˆ†å‰²/è·Ÿè¸ª</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-04-09/%E4%BA%BA%E8%84%B8%E7%9B%B8%E5%85%B3/">
                    <div class="card-image">
                        
                        <img src="https://pic1.zhimg.com/v2-d76c24baec6d4a4fe77761b9e60f2809.jpg" class="responsive-img" alt="äººè„¸ç›¸å…³">
                        
                        <span class="card-title">äººè„¸ç›¸å…³</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            äººè„¸ç›¸å…³ æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-04-09  Semantic Contextualization of Face Forgery A New Definition, Dataset,   and Detection Method
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-04-09
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/%E4%BA%BA%E8%84%B8%E7%9B%B8%E5%85%B3/" class="post-category">
                                    äººè„¸ç›¸å…³
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/%E4%BA%BA%E8%84%B8%E7%9B%B8%E5%85%B3/">
                        <span class="chip bg-color">äººè„¸ç›¸å…³</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-04-09/Vision%20Transformer/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-5773c7a05e0a6ee5893e1685bcfd7008.jpg" class="responsive-img" alt="Vision Transformer">
                        
                        <span class="card-title">Vision Transformer</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Vision Transformer æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-04-09  DA2Diff Exploring Degradation-aware Adaptive Diffusion Priors for   All-in-One Weather Restoration
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-04-09
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Vision-Transformer/" class="post-category">
                                    Vision Transformer
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Vision-Transformer/">
                        <span class="chip bg-color">Vision Transformer</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">28051.5k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
