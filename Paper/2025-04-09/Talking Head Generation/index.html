<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Talking Head Generation">
    <meta name="description" content="Talking Head Generation 方向最新论文已更新，请持续关注 Update in 2025-04-09  FantasyTalking Realistic Talking Portrait Generation via Coherent   Motion Synthesis">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>Talking Head Generation | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loader页面消失采用渐隐的方式*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logo出现动画 */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//使用渐隐的方法淡出loading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//强制显示loading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">嘘~  正在从服务器偷取页面 . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>首页</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>标签</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>分类</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>归档</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="搜索" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="深色/浅色模式" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			首页
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			标签
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			分类
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			归档
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://picx.zhimg.com/v2-6c7cfe9c395994af06b7f3b93da88bdc.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Talking Head Generation</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/Talking-Head-Generation/">
                                <span class="chip bg-color">Talking Head Generation</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/Talking-Head-Generation/" class="post-category">
                                Talking Head Generation
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2025-04-09
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>更新日期:&nbsp;&nbsp;
                    2025-04-21
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp;
                    5.7k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp;
                    23 分
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>阅读次数:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>⚠️ 以下所有内容总结都来自于 大语言模型的能力，如有错误，仅供参考，谨慎使用<br>🔴 请注意：千万不要用于严肃的学术场景，只能用于论文阅读前的初筛！<br>💗 如果您觉得我们的项目对您有帮助 <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ，还请您给我们一些鼓励！⭐️ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFace免费体验</a></p>
</blockquote>
<h1 id="2025-04-09-更新"><a href="#2025-04-09-更新" class="headerlink" title="2025-04-09 更新"></a>2025-04-09 更新</h1><h2 id="FantasyTalking-Realistic-Talking-Portrait-Generation-via-Coherent-Motion-Synthesis"><a href="#FantasyTalking-Realistic-Talking-Portrait-Generation-via-Coherent-Motion-Synthesis" class="headerlink" title="FantasyTalking: Realistic Talking Portrait Generation via Coherent   Motion Synthesis"></a>FantasyTalking: Realistic Talking Portrait Generation via Coherent   Motion Synthesis</h2><p><strong>Authors:Mengchao Wang, Qiang Wang, Fan Jiang, Yaqi Fan, Yunpeng Zhang, Yonggang Qi, Kun Zhao, Mu Xu</strong></p>
<p>Creating a realistic animatable avatar from a single static portrait remains challenging. Existing approaches often struggle to capture subtle facial expressions, the associated global body movements, and the dynamic background. To address these limitations, we propose a novel framework that leverages a pretrained video diffusion transformer model to generate high-fidelity, coherent talking portraits with controllable motion dynamics. At the core of our work is a dual-stage audio-visual alignment strategy. In the first stage, we employ a clip-level training scheme to establish coherent global motion by aligning audio-driven dynamics across the entire scene, including the reference portrait, contextual objects, and background. In the second stage, we refine lip movements at the frame level using a lip-tracing mask, ensuring precise synchronization with audio signals. To preserve identity without compromising motion flexibility, we replace the commonly used reference network with a facial-focused cross-attention module that effectively maintains facial consistency throughout the video. Furthermore, we integrate a motion intensity modulation module that explicitly controls expression and body motion intensity, enabling controllable manipulation of portrait movements beyond mere lip motion. Extensive experimental results show that our proposed approach achieves higher quality with better realism, coherence, motion intensity, and identity preservation. Ours project page: <a target="_blank" rel="noopener" href="https://fantasy-amap.github.io/fantasy-talking/">https://fantasy-amap.github.io/fantasy-talking/</a>. </p>
<blockquote>
<p>从单一静态肖像创建逼真的可动画头像仍然是一个挑战。现有方法往往难以捕捉微妙的面部表情、相关的全身动作和动态背景。为了解决这些局限性，我们提出了一种新型框架，该框架利用预训练的视频扩散变压器模型生成高保真、连贯的说话肖像，具有可控的运动动态。我们工作的核心是双重阶段的音频视觉对齐策略。在第一阶段，我们采用剪辑级训练方案，通过在整个场景（包括参考肖像、上下文对象和背景）中对齐音频驱动的动态，建立连贯的全身运动。在第二阶段，我们在帧级别使用唇部追踪蒙版来微调唇部运动，确保与音频信号的精确同步。为了在不损害运动灵活性的情况下保留身份，我们用一个面部重点交叉注意模块取代了常用的参考网络，该模块可以有效地在整个视频中保持面部一致性。此外，我们集成了一个运动强度调制模块，该模块可以明确地控制表情和躯体运动的强度，实现对肖像运动的可控操纵，而不仅仅是唇部运动。大量的实验结果表明，我们提出的方法在质量、真实性、连贯性、运动强度和身份保留方面达到了更高的水平。我们的项目页面为：<a target="_blank" rel="noopener" href="https://fantasy-amap.github.io/fantasy-talking/%E3%80%82">https://fantasy-amap.github.io/fantasy-talking/。</a></p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.04842v1">PDF</a> </p>
<p><strong>Summary</strong>：</p>
<p>本文提出了一种新的框架，利用预训练的视频扩散变压器模型生成高保真、连贯的动画肖像，具有可控的运动动态。该框架采用双阶段音频视觉对齐策略，第一阶段通过剪辑级训练方案建立全局运动的一致性，第二阶段在帧级别细化唇部运动，同时确保与音频信号的精确同步。此外，还采用了面部重点交叉注意力模块和运动强度调制模块，以在保持身份的同时实现灵活的运动控制。</p>
<p><strong>Key Takeaways</strong>：</p>
<ol>
<li>利用预训练的视频扩散变压器模型生成动画肖像。</li>
<li>采用双阶段音频视觉对齐策略，确保音频驱动的动态与整个场景的一致性。</li>
<li>在第一阶段建立全局运动的一致性。</li>
<li>在第二阶段细化唇部运动，并与音频信号精确同步。</li>
<li>采用面部重点交叉注意力模块以保持身份的一致性。</li>
<li>引入运动强度调制模块，控制表达和身体运动的强度。</li>
<li>实验结果表明，该方法在质量、现实感、连贯性、运动强度和身份保持方面表现优异。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.04842">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-5d83e683bd9c983836313816d19dc9b4.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-8295f4690fbcd94c40eee6ad4bd40f9b.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-88fd928bc304bf67efce4a9f28e00d3a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-0f58490100d9687eff5e28f436c3a20a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-33c9cfa6ddd6647787d8c2bd956a8752.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-13b7935e32885132fa6ebfa9b694a2e1.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="FluentLip-A-Phonemes-Based-Two-stage-Approach-for-Audio-Driven-Lip-Synthesis-with-Optical-Flow-Consistency"><a href="#FluentLip-A-Phonemes-Based-Two-stage-Approach-for-Audio-Driven-Lip-Synthesis-with-Optical-Flow-Consistency" class="headerlink" title="FluentLip: A Phonemes-Based Two-stage Approach for Audio-Driven Lip   Synthesis with Optical Flow Consistency"></a>FluentLip: A Phonemes-Based Two-stage Approach for Audio-Driven Lip   Synthesis with Optical Flow Consistency</h2><p><strong>Authors:Shiyan Liu, Rui Qu, Yan Jin</strong></p>
<p>Generating consecutive images of lip movements that align with a given speech in audio-driven lip synthesis is a challenging task. While previous studies have made strides in synchronization and visual quality, lip intelligibility and video fluency remain persistent challenges. This work proposes FluentLip, a two-stage approach for audio-driven lip synthesis, incorporating three featured strategies. To improve lip synchronization and intelligibility, we integrate a phoneme extractor and encoder to generate a fusion of audio and phoneme information for multimodal learning. Additionally, we employ optical flow consistency loss to ensure natural transitions between image frames. Furthermore, we incorporate a diffusion chain during the training of Generative Adversarial Networks (GANs) to improve both stability and efficiency. We evaluate our proposed FluentLip through extensive experiments, comparing it with five state-of-the-art (SOTA) approaches across five metrics, including a proposed metric called Phoneme Error Rate (PER) that evaluates lip pose intelligibility and video fluency. The experimental results demonstrate that our FluentLip approach is highly competitive, achieving significant improvements in smoothness and naturalness. In particular, it outperforms these SOTA approaches by approximately $\textbf{16.3%}$ in Fr&#39;echet Inception Distance (FID) and $\textbf{35.2%}$ in PER. </p>
<blockquote>
<p>生成与给定语音相对应的连续唇部动作图像在音频驱动唇部合成中是一项具有挑战性的任务。尽管之前的研究在同步和视觉质量方面取得了进展，但唇部的清晰度和视频流畅度仍然是一个持久的挑战。这项工作提出了FluentLip，这是一种用于音频驱动的唇部合成的两阶段方法，结合了三种特色策略。为了改善唇部同步和清晰度，我们整合了音素提取器和编码器，以生成音频和音素信息的融合，用于多模态学习。另外，我们采用光流一致性损失来确保图像帧之间的自然过渡。此外，我们在生成对抗网络（GANs）的训练过程中引入了扩散链，以提高稳定性和效率。我们通过大量实验评估了所提出的FluentLip，将其与五种最新方法进行比较，包括一个名为音素错误率（PER）的提出指标，该指标评估唇部姿态的清晰度和视频流畅度。实验结果证明，我们的FluentLip方法具有很强的竞争力，在平滑度和自然度方面取得了显著改进。特别是，它在Fréchet Inception Distance（FID）上比这些最新方法高出约**16.3%<strong>，在PER上高出</strong>35.2%**。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.04427v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>本文提出一种名为FluentLip的两阶段音频驱动唇动图像生成方法，旨在解决音频与唇动图像同步生成时的挑战。该方法通过融合音频和音素信息、采用光学流一致性损失以及改进生成对抗网络训练过程中的扩散链等技术，提高了唇同步、可理解性和视频流畅性。实验结果表明，FluentLip在平滑度和自然度方面表现出高度竞争力，与现有先进方法相比，在Fréchet Inception Distance（FID）和 Phoneme Error Rate（PER）等评价指标上实现了显著改进。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>FluentLip是一种两阶段的音频驱动唇动图像生成方法，旨在解决音频与唇动图像同步生成的挑战。</li>
<li>通过融合音频和音素信息，提高唇同步和可理解性。</li>
<li>采用光学流一致性损失，确保图像帧之间的自然过渡。</li>
<li>改进生成对抗网络训练过程中的扩散链，提高稳定性和效率。</li>
<li>通过广泛实验评估FluentLip性能，与五种最新技术进行对比。</li>
<li>提出一种新的评价指标——Phoneme Error Rate（PER），用于评估唇姿态可理解性和视频流畅性。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.04427">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-056ed506fe6242396706a46f04d89ba1.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b33d9786d642b3fc67945c9c133127cc.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-f96bfbf7f491342e293c76ea50d76fb7.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="What-Large-Language-Models-Do-Not-Talk-About-An-Empirical-Study-of-Moderation-and-Censorship-Practices"><a href="#What-Large-Language-Models-Do-Not-Talk-About-An-Empirical-Study-of-Moderation-and-Censorship-Practices" class="headerlink" title="What Large Language Models Do Not Talk About: An Empirical Study of   Moderation and Censorship Practices"></a>What Large Language Models Do Not Talk About: An Empirical Study of   Moderation and Censorship Practices</h2><p><strong>Authors:Sander Noels, Guillaume Bied, Maarten Buyl, Alexander Rogiers, Yousra Fettach, Jefrey Lijffijt, Tijl De Bie</strong></p>
<p>Large Language Models (LLMs) are increasingly deployed as gateways to information, yet their content moderation practices remain underexplored. This work investigates the extent to which LLMs refuse to answer or omit information when prompted on political topics. To do so, we distinguish between hard censorship (i.e., generated refusals, error messages, or canned denial responses) and soft censorship (i.e., selective omission or downplaying of key elements), which we identify in LLMs’ responses when asked to provide information on a broad range of political figures. Our analysis covers 14 state-of-the-art models from Western countries, China, and Russia, prompted in all six official United Nations (UN) languages. Our analysis suggests that although censorship is observed across the board, it is predominantly tailored to an LLM provider’s domestic audience and typically manifests as either hard censorship or soft censorship (though rarely both concurrently). These findings underscore the need for ideological and geographic diversity among publicly available LLMs, and greater transparency in LLM moderation strategies to facilitate informed user choices. All data are made freely available. </p>
<blockquote>
<p>大型语言模型（LLM）越来越多地被部署为信息网关，但它们的内容管理实践仍未得到充分探索。本研究调查了LLM在政治话题提示下拒绝回答或省略信息的程度。为此，我们区分了硬审查（例如生成的拒绝、错误消息或标准的拒绝回答）和软审查（例如选择性遗漏或淡化关键要素），这在LLM被要求对一系列政治人物提供信息时才会显露出来。我们的分析涵盖了来自西方、中国和俄罗斯的共十四种最先进模型，并在联合国六种官方语言中进行了提示。我们的分析表明，尽管普遍存在着审查现象，但审查主要还是针对LLM供应商的国内受众的，主要表现为硬审查或软审查（但通常不并发）。这些发现突显出公开可用的LLM需要在意识形态和地理上具有多样性，以及LLM管理策略需要更大的透明度，以便用户做出明智的选择。所有数据均已免费公开。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.03803v1">PDF</a> 17 pages, 38 pages in total including appendix; 5 figures, 22 figures   in appendix</p>
<p><strong>摘要</strong><br>LLM作为信息检索的门户越来越受欢迎，但其内容管理实践尚未得到充分研究。本研究探讨了LLM在政治话题上拒绝回答或省略信息的程度。我们区分了硬审查（如生成的拒绝回答、错误消息或标准拒绝响应）和软审查（如选择性遗漏或淡化关键元素），这些在针对一系列政治人物的提问时存在于LLM的响应中。我们的分析涵盖了来自西方、中国和俄罗斯的最新技术模型共十四种模型，并用联合国六种官方语言提示它们。分析表明，尽管普遍存在审查现象，但主要是针对LLM供应商国内受众量身定制的，通常表现为硬审查或软审查（很少同时出现）。这些发现强调，公众可用LLM模型中需要增加意识形态和地理多样性，并且在LLM的调节策略中需要更多的透明度以促进用户做出明智的选择。所有数据可自由获取。</p>
<p><strong>关键见解</strong></p>
<ul>
<li>LLM被越来越多地用作信息检索的门户，但其内容管理实践仍然未被充分研究。</li>
<li>在对政治话题的提示下，LLM表现出拒绝回答或省略信息的现象。</li>
<li>我们区分了硬审查和软审查两种审查方式，存在于LLM对一系列政治人物的回应中。</li>
<li>LLM审查现象普遍存在，但主要是根据LLM供应商国内受众量身定制的。</li>
<li>LLM模型需要更多的意识形态和地理多样性。</li>
<li>在LLM的调节策略中需要更大的透明度以促进用户做出明智的选择。</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.03803">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-24bfbe2e15829c08e719507f55bbe3b4.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-086f18907a4f84fbae83dd5fcf2d905c.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="Audio-visual-Controlled-Video-Diffusion-with-Masked-Selective-State-Spaces-Modeling-for-Natural-Talking-Head-Generation"><a href="#Audio-visual-Controlled-Video-Diffusion-with-Masked-Selective-State-Spaces-Modeling-for-Natural-Talking-Head-Generation" class="headerlink" title="Audio-visual Controlled Video Diffusion with Masked Selective State   Spaces Modeling for Natural Talking Head Generation"></a>Audio-visual Controlled Video Diffusion with Masked Selective State   Spaces Modeling for Natural Talking Head Generation</h2><p><strong>Authors:Fa-Ting Hong, Zunnan Xu, Zixiang Zhou, Jun Zhou, Xiu Li, Qin Lin, Qinglin Lu, Dan Xu</strong></p>
<p>Talking head synthesis is vital for virtual avatars and human-computer interaction. However, most existing methods are typically limited to accepting control from a single primary modality, restricting their practical utility. To this end, we introduce \textbf{ACTalker}, an end-to-end video diffusion framework that supports both multi-signals control and single-signal control for talking head video generation. For multiple control, we design a parallel mamba structure with multiple branches, each utilizing a separate driving signal to control specific facial regions. A gate mechanism is applied across all branches, providing flexible control over video generation. To ensure natural coordination of the controlled video both temporally and spatially, we employ the mamba structure, which enables driving signals to manipulate feature tokens across both dimensions in each branch. Additionally, we introduce a mask-drop strategy that allows each driving signal to independently control its corresponding facial region within the mamba structure, preventing control conflicts. Experimental results demonstrate that our method produces natural-looking facial videos driven by diverse signals and that the mamba layer seamlessly integrates multiple driving modalities without conflict. The project website can be found at <a target="_blank" rel="noopener" href="https://harlanhong.github.io/publications/actalker/index.html">https://harlanhong.github.io/publications/actalker/index.html</a>. </p>
<blockquote>
<p>谈话头部合成对于虚拟角色和人机交互至关重要。然而，大多数现有方法通常仅限于接受单一主要模态的控制，限制了其实用性。为此，我们引入了<strong>ACTalker</strong>，这是一个端到端的视频扩散框架，支持多信号控制和单信号控制用于谈话头部视频生成。对于多模态控制，我们设计了一个并行mamba结构，包含多个分支，每个分支利用一个单独的驱动信号来控制特定的面部区域。在所有分支上应用门控机制，为视频生成提供灵活控制。为了确保生成的视频在时间和空间上的协调自然，我们采用了mamba结构，使驱动信号能够在每个分支的两个维度上操作特征标记。此外，我们还引入了一种mask-drop策略，允许每个驱动信号独立控制mamba结构内相应的面部区域，防止控制冲突。实验结果表明，我们的方法能够生成由多种信号驱动的自然面部视频，mamba层能够无缝集成多种驱动模式，无冲突。项目网站可访问：<a target="_blank" rel="noopener" href="https://harlanhong.github.io/publications/actalker/index.html%E3%80%82">https://harlanhong.github.io/publications/actalker/index.html。</a></p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.02542v3">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>本文介绍了针对虚拟角色和人机交互的说话人头部合成技术。针对现有方法的局限性，提出了一种名为ACTalker的端到端视频扩散框架，支持多信号控制和单信号控制进行说话人头部视频生成。该框架采用并行mamba结构，通过多个分支利用不同的驱动信号控制面部特定区域，实现灵活的视频生成控制。同时引入mask-drop策略，防止控制冲突。实验结果表明，该方法能够生成自然逼真的面部视频，并由多种信号驱动，mamba层无缝集成多种驱动模式。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>说话头合成在虚拟角色和人机交互中很重要。</li>
<li>现有方法通常局限于单一的控制模式，限制了其实用性。</li>
<li>ACTalker框架支持多信号和单信号控制，用于生成说话头视频。</li>
<li>并行mamba结构允许多个分支利用不同的驱动信号控制面部特定区域。</li>
<li>引入的gate机制提供了灵活的视频生成控制。</li>
<li>mamba结构确保受控制视频的时空自然协调。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.02542">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-dc881410520e36239973163727b4452e.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-dc9c1142b1de1f3081c5651c66a39089.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-296b0c1b126310ae671ff1341078d391.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-8d8a669726f9c06cc99e03612c0ea7d6.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f0d90568590ed990a72794432167d5fd.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="CyberHost-Taming-Audio-driven-Avatar-Diffusion-Model-with-Region-Codebook-Attention"><a href="#CyberHost-Taming-Audio-driven-Avatar-Diffusion-Model-with-Region-Codebook-Attention" class="headerlink" title="CyberHost: Taming Audio-driven Avatar Diffusion Model with Region   Codebook Attention"></a>CyberHost: Taming Audio-driven Avatar Diffusion Model with Region   Codebook Attention</h2><p><strong>Authors:Gaojie Lin, Jianwen Jiang, Chao Liang, Tianyun Zhong, Jiaqi Yang, Yanbo Zheng</strong></p>
<p>Diffusion-based video generation technology has advanced significantly, catalyzing a proliferation of research in human animation. However, the majority of these studies are confined to same-modality driving settings, with cross-modality human body animation remaining relatively underexplored. In this paper, we introduce, an end-to-end audio-driven human animation framework that ensures hand integrity, identity consistency, and natural motion. The key design of CyberHost is the Region Codebook Attention mechanism, which improves the generation quality of facial and hand animations by integrating fine-grained local features with learned motion pattern priors. Furthermore, we have developed a suite of human-prior-guided training strategies, including body movement map, hand clarity score, pose-aligned reference feature, and local enhancement supervision, to improve synthesis results. To our knowledge, CyberHost is the first end-to-end audio-driven human diffusion model capable of facilitating zero-shot video generation within the scope of human body. Extensive experiments demonstrate that CyberHost surpasses previous works in both quantitative and qualitative aspects. </p>
<blockquote>
<p>基于扩散的视频生成技术取得了显著的进步，催生了人体动画领域的广泛研究。然而，大多数研究仅限于相同模态的驱动设置，跨模态人体动画的研究相对较少。本文介绍了一种端到端的音频驱动人体动画框架，称为CyberHost，它确保手部完整性、身份一致性和自然运动。CyberHost的关键设计是区域代码本注意机制，它通过整合精细的局部特征与学习的运动模式先验，提高了面部和手部动画的生成质量。此外，我们还开发了一套人体先验引导的训练策略，包括身体运动图、手部清晰度评分、姿态对齐参考特征和局部增强监督，以提高合成结果。据我们所知，CyberHost是首个端到端的音频驱动人体扩散模型，能够促进人体范围内零样本视频生成。大量实验表明，无论是在定量还是定性方面，CyberHost都超越了以前的工作。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2409.01876v3">PDF</a> ICLR 2025 (Oral), Homepage: <a target="_blank" rel="noopener" href="https://cyberhost.github.io/">https://cyberhost.github.io/</a></p>
<p><strong>Summary</strong><br>视频生成技术发展迅速，驱动人类动画的研究不断增多。然而，大多数研究局限于相同模态的驱动设置，跨模态人体动画相对较少。本文介绍了一种端到端的音频驱动人体动画框架CyberHost，它保证了手的完整性、身份一致性和自然运动。关键设计是区域代码簿注意力机制，它通过整合精细的局部特征与学习的运动模式先验，提高了面部和手部动画的生成质量。此外，还开发了一系列人体优先训练策略，包括身体运动地图、手部清晰度评分、姿态对齐参考特征和局部增强监督，以提高合成结果。据我们所知，CyberHost是首个端到端的音频驱动人体扩散模型，能够在人体范围内实现零样本视频生成。实验表明，无论是在定量还是定性方面，CyberHost都超过了以前的工作。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>音频驱动的人体动画技术是当前研究的热点。</li>
<li>当前研究大多局限于相同模态的驱动设置，跨模态人体动画研究较少。</li>
<li>CyberHost是一个端到端的音频驱动人体动画框架，保证了动画的自然性和身份一致性。</li>
<li>区域代码簿注意力机制是CyberHost的关键设计，通过整合局部特征与运动模式先验，提高动画生成质量。</li>
<li>CyberHost开发了一系列人体优先训练策略，包括身体运动地图、手部清晰度评分等，以优化合成结果。</li>
<li>据悉，CyberHost是首个音频驱动的零样本视频生成的人体扩散模型。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2409.01876">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-6c7cfe9c395994af06b7f3b93da88bdc.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a2ff3923fe0516dc768ac0ed24cde260.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-dab93f1215cf00aa09aa854fdf63c016.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ccaa839bfed295384e2059ac6628671a.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="MobilePortrait-Real-Time-One-Shot-Neural-Head-Avatars-on-Mobile-Devices"><a href="#MobilePortrait-Real-Time-One-Shot-Neural-Head-Avatars-on-Mobile-Devices" class="headerlink" title="MobilePortrait: Real-Time One-Shot Neural Head Avatars on Mobile Devices"></a>MobilePortrait: Real-Time One-Shot Neural Head Avatars on Mobile Devices</h2><p><strong>Authors:Jianwen Jiang, Gaojie Lin, Zhengkun Rong, Chao Liang, Yongming Zhu, Jiaqi Yang, Tianyun Zhong</strong></p>
<p>Existing neural head avatars methods have achieved significant progress in the image quality and motion range of portrait animation. However, these methods neglect the computational overhead, and to the best of our knowledge, none is designed to run on mobile devices. This paper presents MobilePortrait, a lightweight one-shot neural head avatars method that reduces learning complexity by integrating external knowledge into both the motion modeling and image synthesis, enabling real-time inference on mobile devices. Specifically, we introduce a mixed representation of explicit and implicit keypoints for precise motion modeling and precomputed visual features for enhanced foreground and background synthesis. With these two key designs and using simple U-Nets as backbones, our method achieves state-of-the-art performance with less than one-tenth the computational demand. It has been validated to reach speeds of over 100 FPS on mobile devices and support both video and audio-driven inputs. </p>
<blockquote>
<p>现有神经头像技术方法在肖像动画的图像质量和运动范围方面取得了显著进展。然而，这些方法忽视了计算开销，据我们所知，没有一种方法是为移动设备设计。本文介绍了MobilePortrait，这是一种轻量级的单镜头神经头像技术方法，它通过整合外部知识到运动建模和图像合成中，降低了学习复杂性，实现在移动设备上的实时推理。具体来说，我们引入了显式关键点和隐式关键点的混合表示来进行精确运动建模，以及预计算的视觉特征来增强前景和背景合成。通过这两个关键设计和使用简单的U-Nets作为骨干网，我们的方法在不到十分之一计算需求的情况下实现了最先进的性能。经验证，它在移动设备上达到了超过每秒100帧的速度，并支持视频和音频驱动输入。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2407.05712v2">PDF</a> CVPR 2024</p>
<p><strong>摘要</strong></p>
<p>现有神经网络头像技术虽然在肖像动画的图像质量和运动范围方面取得了显著进展，但这些方法忽略了计算开销，并且据我们所知，目前尚无专为移动设备设计的技术。本文提出了MobilePortrait，一种轻量级的单次神经网络头像方法，它通过整合外部知识到运动建模和图像合成中，降低了学习复杂性，实现了在移动设备上的实时推理。具体来说，我们引入了显式与隐式关键点的混合表示进行精确运动建模，以及预计算的视觉特征用于增强前景和背景合成。凭借这两种关键设计以及使用简单的U-Nets作为骨干网，我们的方法在减少十分之一计算需求的情况下达到了最先进的性能。该方法经测试可在移动设备上实现超过每秒百帧的速度运行，并支持视频和音频驱动输入。</p>
<p><strong>要点</strong></p>
<ol>
<li>MobilePortrait是首个专为移动设备设计的神经网络头像技术。</li>
<li>通过整合外部知识到运动建模和图像合成中，降低学习复杂性。</li>
<li>采用显式与隐式关键点的混合表示进行精确运动建模。</li>
<li>利用预计算的视觉特征增强前景和背景合成。</li>
<li>使用简单的U-Nets作为骨干网实现高性能。</li>
<li>方法性能达到了业界先进水平，计算需求远低于其他技术。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2407.05712">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-db530ecf72b335fe7000be180e109649.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-e76bf61a2edc074441e8ac3eaa911d9d.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-f91c77ec3d5c4828683cc17007e6a195.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        文章作者:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        文章链接:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-04-09/Talking%20Head%20Generation/">https://kedreamix.github.io/Talk2Paper/Paper/2025-04-09/Talking%20Head%20Generation/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        版权声明:
                    </i>
                </span>
                <span class="reprint-info">
                    本博客所有文章除特別声明外，均采用
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    许可协议。转载请注明来源
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/Talking-Head-Generation/">
                                    <span class="chip bg-color">Talking Head Generation</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;上一篇</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-04-09/Text-to-Motion/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-ea9bf2804d6b87cc4cc40478f031b843.jpg" class="responsive-img" alt="Text-to-Motion">
                        
                        <span class="card-title">Text-to-Motion</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Text-to-Motion 方向最新论文已更新，请持续关注 Update in 2025-04-09  DanceMosaic High-Fidelity Dance Generation with Multimodal Editability
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-04-09
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Text-to-Motion/" class="post-category">
                                    Text-to-Motion
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Text-to-Motion/">
                        <span class="chip bg-color">Text-to-Motion</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-04-09/Interactive/">
                    <div class="card-image">
                        
                        <img src="https://pic1.zhimg.com/v2-e960cc4afc6fc4f81a1f7d8d42289545.jpg" class="responsive-img" alt="Interactive">
                        
                        <span class="card-title">Interactive</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Interactive 方向最新论文已更新，请持续关注 Update in 2025-04-09  Anisotropic space-time goal-oriented error control and mesh adaptivity   for convection-diffusion-reaction equations
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-04-09
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Interactive/" class="post-category">
                                    Interactive
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Interactive/">
                        <span class="chip bg-color">Interactive</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- 代码语言 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span
                        class="white-color">16065k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- 运行天数提醒. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // 区分是否有年份.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = '本站已运行 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                daysTip = '本站已運行 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = '本站已运行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = '本站已運行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="关注我的知乎: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">知</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- 白天和黑夜主题 -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // 只在桌面版网页启用特效
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- 雪花特效 -->
    

    <!-- 鼠标星星特效 -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--腾讯兔小巢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- 动态标签 -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Σ(っ °Д °;)っ诶，页面崩溃了嘛？", clearTimeout(st)) : (document.title = "φ(゜▽゜*)♪咦，又好了！", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
