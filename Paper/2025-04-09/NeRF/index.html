<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="NeRF">
    <meta name="description" content="NeRF 方向最新论文已更新，请持续关注 Update in 2025-04-09  DeclutterNeRF Generative-Free 3D Scene Recovery for Occlusion Removal">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>NeRF | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loader页面消失采用渐隐的方式*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logo出现动画 */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//使用渐隐的方法淡出loading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//强制显示loading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">嘘~  正在从服务器偷取页面 . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>首页</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>标签</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>分类</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>归档</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="搜索" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="深色/浅色模式" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			首页
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			标签
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			分类
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			归档
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://picx.zhimg.com/v2-f57da3615c8eb9d74925d80c987ef4f2.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">NeRF</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/NeRF/">
                                <span class="chip bg-color">NeRF</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/NeRF/" class="post-category">
                                NeRF
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2025-04-09
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>更新日期:&nbsp;&nbsp;
                    2025-04-21
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp;
                    6k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp;
                    24 分
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>阅读次数:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>⚠️ 以下所有内容总结都来自于 大语言模型的能力，如有错误，仅供参考，谨慎使用<br>🔴 请注意：千万不要用于严肃的学术场景，只能用于论文阅读前的初筛！<br>💗 如果您觉得我们的项目对您有帮助 <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ，还请您给我们一些鼓励！⭐️ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFace免费体验</a></p>
</blockquote>
<h1 id="2025-04-09-更新"><a href="#2025-04-09-更新" class="headerlink" title="2025-04-09 更新"></a>2025-04-09 更新</h1><h2 id="DeclutterNeRF-Generative-Free-3D-Scene-Recovery-for-Occlusion-Removal"><a href="#DeclutterNeRF-Generative-Free-3D-Scene-Recovery-for-Occlusion-Removal" class="headerlink" title="DeclutterNeRF: Generative-Free 3D Scene Recovery for Occlusion Removal"></a>DeclutterNeRF: Generative-Free 3D Scene Recovery for Occlusion Removal</h2><p><strong>Authors:Wanzhou Liu, Zhexiao Xiong, Xinyu Li, Nathan Jacobs</strong></p>
<p>Recent novel view synthesis (NVS) techniques, including Neural Radiance Fields (NeRF) and 3D Gaussian Splatting (3DGS) have greatly advanced 3D scene reconstruction with high-quality rendering and realistic detail recovery. Effectively removing occlusions while preserving scene details can further enhance the robustness and applicability of these techniques. However, existing approaches for object and occlusion removal predominantly rely on generative priors, which, despite filling the resulting holes, introduce new artifacts and blurriness. Moreover, existing benchmark datasets for evaluating occlusion removal methods lack realistic complexity and viewpoint variations. To address these issues, we introduce DeclutterSet, a novel dataset featuring diverse scenes with pronounced occlusions distributed across foreground, midground, and background, exhibiting substantial relative motion across viewpoints. We further introduce DeclutterNeRF, an occlusion removal method free from generative priors. DeclutterNeRF introduces joint multi-view optimization of learnable camera parameters, occlusion annealing regularization, and employs an explainable stochastic structural similarity loss, ensuring high-quality, artifact-free reconstructions from incomplete images. Experiments demonstrate that DeclutterNeRF significantly outperforms state-of-the-art methods on our proposed DeclutterSet, establishing a strong baseline for future research. </p>
<blockquote>
<p>最新的视点合成（NVS）技术，包括神经辐射场（NeRF）和三维高斯展开（3DGS），已经极大地推动了三维场景重建的高质量渲染和真实细节的恢复。在保留场景细节的同时有效地去除遮挡物，可以进一步增强这些技术的稳健性和适用性。然而，现有的物体和遮挡物去除方法主要依赖于生成先验，尽管可以填充由此产生的空洞，但也会引入新的伪影和模糊。此外，用于评估遮挡物去除方法的现有基准数据集缺乏现实的复杂性和视点变化。为了解决这些问题，我们引入了DeclutterSet，一个具有鲜明遮挡物的多样化场景的新数据集，这些遮挡物分布在前景、中景和背景上，并在不同视点之间表现出大量的相对运动。我们还介绍了DeclutterNeRF，一种无需生成先验的遮挡物去除方法。DeclutterNeRF引入了可学习相机参数的联合多视角优化、遮挡退火正则化，并采用可解释的随机结构相似性损失，确保从不完整图像中进行高质量、无伪影的重建。实验表明，在我们的提出的DeclutterSet上，DeclutterNeRF显著优于最先进的方法，为未来的研究建立了强大的基准。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.04679v1">PDF</a> Accepted by CVPR 2025 4th CV4Metaverse Workshop. 15 pages, 10   figures. Code and data at: <a target="_blank" rel="noopener" href="https://github.com/wanzhouliu/declutter-nerf">https://github.com/wanzhouliu/declutter-nerf</a></p>
<p><strong>Summary</strong></p>
<p>NeRF和3DGS等新型视图合成技术已广泛应用于3D场景重建，但现有技术存在去除遮挡时产生的模糊和伪影问题。为解决这些问题，我们引入了DeclutterSet数据集和DeclutterNeRF方法。DeclutterSet包含具有不同遮挡的多样场景，而DeclutterNeRF则通过联合多视角优化学习相机参数、引入遮挡退火正则化，并采用可解释的随机结构相似性损失，确保从不完整图像中进行高质量、无伪影的重建。实验证明，DeclutterNeRF在DeclutterSet上的表现显著优于现有方法，为未来研究奠定了坚实基础。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>NeRF和3DGS等技术推动了3D场景重建的发展，但去除遮挡时存在模糊和伪影问题。</li>
<li>现有遮挡去除方法主要依赖生成先验，虽然能填补空洞但会引入新伪影。</li>
<li>引入的DeclutterSet数据集包含多样场景，展现不同遮挡的复杂性。</li>
<li>提出的DeclutterNeRF方法通过联合多视角优化相机参数，实现无生成先验的遮挡去除。</li>
<li>DeclutterNeRF采用遮挡退火正则化和可解释的随机结构相似性损失，确保高质量重建。</li>
<li>实验证明，DeclutterNeRF在DeclutterSet上的表现优于现有方法。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.04679">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-19fbf9cae2da7d297367328e01541b38.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-fff8fbfe0808cf428889777054f40288.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-af0ebf63427d642319122994e7412687.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e0ca639c588edbdfd830c6caa834440e.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-f16bd9d5b8361feb1489b81af6cb5c59.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="Thermoxels-a-voxel-based-method-to-generate-simulation-ready-3D-thermal-models"><a href="#Thermoxels-a-voxel-based-method-to-generate-simulation-ready-3D-thermal-models" class="headerlink" title="Thermoxels: a voxel-based method to generate simulation-ready 3D thermal   models"></a>Thermoxels: a voxel-based method to generate simulation-ready 3D thermal   models</h2><p><strong>Authors:Etienne Chassaing, Florent Forest, Olga Fink, Malcolm Mielle</strong></p>
<p>In the European Union, buildings account for 42% of energy use and 35% of greenhouse gas emissions. Since most existing buildings will still be in use by 2050, retrofitting is crucial for emissions reduction. However, current building assessment methods rely mainly on qualitative thermal imaging, which limits data-driven decisions for energy savings. On the other hand, quantitative assessments using finite element analysis (FEA) offer precise insights but require manual CAD design, which is tedious and error-prone. Recent advances in 3D reconstruction, such as Neural Radiance Fields (NeRF) and Gaussian Splatting, enable precise 3D modeling from sparse images but lack clearly defined volumes and the interfaces between them needed for FEA. We propose Thermoxels, a novel voxel-based method able to generate FEA-compatible models, including both geometry and temperature, from a sparse set of RGB and thermal images. Using pairs of RGB and thermal images as input, Thermoxels represents a scene’s geometry as a set of voxels comprising color and temperature information. After optimization, a simple process is used to transform Thermoxels’ models into tetrahedral meshes compatible with FEA. We demonstrate Thermoxels’ capability to generate RGB+Thermal meshes of 3D scenes, surpassing other state-of-the-art methods. To showcase the practical applications of Thermoxels’ models, we conduct a simple heat conduction simulation using FEA, achieving convergence from an initial state defined by Thermoxels’ thermal reconstruction. Additionally, we compare Thermoxels’ image synthesis abilities with current state-of-the-art methods, showing competitive results, and discuss the limitations of existing metrics in assessing mesh quality. </p>
<blockquote>
<p>在欧盟，建筑物占能源使用的42%和温室气体排放的35%。由于大多数现有建筑在2050年仍将继续使用，因此改造对于减少排放至关重要。然而，目前的建筑评估方法主要依赖于定性的热成像技术，这限制了基于数据驱动的节能决策。另一方面，使用有限元分析（FEA）的定量评估提供了精确的见解，但需要手动CAD设计，这既繁琐又容易出错。最近的三维重建技术进展，如神经辐射场（NeRF）和高斯溅射，能够从稀疏图像进行精确的三维建模，但缺乏用于有限元分析的明确定义的体积和它们之间的界面。我们提出了Thermoxels，这是一种基于体素的新方法，能够生成包括几何和温度信息的有限元分析兼容模型，这些模型从稀疏的RGB和热图像集中生成。使用成对的RGB和热图像作为输入，Thermoxels将场景的几何表示为包含颜色和温度信息的体素集。经过优化后，使用简单的过程将Thermoxels模型转换为与FEA兼容的四面体网格。我们展示了Thermoxels生成RGB+热网格三维场景的能力，超越了其他最先进的方法。为了展示Thermoxels模型的实际应用，我们使用有限元分析进行简单的热传导模拟，从Thermoxels热重建定义的初始状态实现收敛。此外，我们将Thermoxels的图像合成能力与当前最先进的方法进行比较，展示了具有竞争力的结果，并讨论了现有指标在评估网格质量方面的局限性。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.04448v1">PDF</a> 7 pages, 2 figures</p>
<p><strong>Summary</strong></p>
<p>基于NeRF技术的Thermoxels方法，能够从稀疏的RGB和红外图像生成兼容有限元分析的模型，用于建筑物的精准三维建模和温度分析。此方法解决了现有建筑评估方法的局限性，为欧盟的节能减排提供了新的解决方案。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>欧洲联盟中，建筑物能耗占42%，温室气体排放占35%，因此翻新改造对减排至关重要。</li>
<li>当前建筑评估方法主要依赖定性热成像，限制了数据驱动的节能决策。</li>
<li>定量评估使用的有限元分析（FEA）提供精确见解，但需要手动CAD设计，过程繁琐且易出错。</li>
<li>Neural Radiance Fields（NeRF）等3D重建技术的最新进展能够实现从稀疏图像进行精准三维建模。</li>
<li>Thermoxels方法结合NeRF技术生成包含几何和温度信息的有限元分析兼容模型，从稀疏的RGB和红外图像中进行创建。</li>
<li>Thermoxels展示了一种将模型转化为与有限元分析兼容的四面体网格的简单过程。</li>
<li>实验结果表明，Thermoxels在生成RGB+热网格的3D场景方面超越其他最新方法，并且成功应用于热传导模拟仿真中。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.04448">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-69902a83801dc06d1b1d278a30309244.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-35596417805808688f6c69093fc60c5c.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-cc885b0ca20339af953135051aa399e5.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-627ce00fd37dba50a2ff20159f8b3639.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="RNG-Relightable-Neural-Gaussians"><a href="#RNG-Relightable-Neural-Gaussians" class="headerlink" title="RNG: Relightable Neural Gaussians"></a>RNG: Relightable Neural Gaussians</h2><p><strong>Authors:Jiahui Fan, Fujun Luan, Jian Yang, Miloš Hašan, Beibei Wang</strong></p>
<p>3D Gaussian Splatting (3DGS) has shown impressive results for the novel view synthesis task, where lighting is assumed to be fixed. However, creating relightable 3D assets, especially for objects with ill-defined shapes (fur, fabric, etc.), remains a challenging task. The decomposition between light, geometry, and material is ambiguous, especially if either smooth surface assumptions or surfacebased analytical shading models do not apply. We propose Relightable Neural Gaussians (RNG), a novel 3DGS-based framework that enables the relighting of objects with both hard surfaces or soft boundaries, while avoiding assumptions on the shading model. We condition the radiance at each point on both view and light directions. We also introduce a shadow cue, as well as a depth refinement network to improve shadow accuracy. Finally, we propose a hybrid forward-deferred fitting strategy to balance geometry and appearance quality. Our method achieves significantly faster training (1.3 hours) and rendering (60 frames per second) compared to a prior method based on neural radiance fields and produces higher-quality shadows than a concurrent 3DGS-based method. Project page: <a target="_blank" rel="noopener" href="https://www.whois-jiahui.fun/project_pages/RNG">https://www.whois-jiahui.fun/project_pages/RNG</a>. </p>
<blockquote>
<p>3D高斯融合（3DGS）在新视角合成任务中取得了令人印象深刻的结果，该任务假设光照是固定的。然而，创建可重新照明的3D资产，特别是对于形状不明确的对象（如皮毛、织物等），仍然是一项具有挑战性的任务。光、几何形状和材料之间的分解是模糊的，尤其是当光滑表面假设或基于表面的分析着色模型不适用时。我们提出可重新照明的神经高斯（RNG），这是一种基于3DGS的新型框架，能够实现具有硬表面或软边界的对象的重新照明，同时避免对着色模型进行假设。我们将每个点的辐射率取决于视图和光线的方向。我们还引入了一个阴影提示和一个深度细化网络来提高阴影的准确性。最后，我们提出了一种混合的前向延迟拟合策略来平衡几何形状和外观质量。我们的方法与前一种基于神经辐射场的方法相比，实现了更快的训练（1.3小时）和渲染（每秒60帧），并且比同期基于3DGS的方法产生了更高质量的阴影。项目页面：<a target="_blank" rel="noopener" href="https://www.whois-jiahui.fun/project_pages/RNG%E3%80%82">https://www.whois-jiahui.fun/project_pages&#x2F;RNG。</a></p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2409.19702v5">PDF</a> Camera-ready version. Proceedings of CVPR 2025</p>
<p><strong>Summary</strong></p>
<p>该文本主要介绍了Relightable Neural Gaussians（RNG）框架，这是一个基于3D Gaussian Splatting（3DGS）的模型，能够实现对具有硬表面或软边界的对象的重新照明，无需对阴影模型进行假设。该框架引入了一种阴影线索和深度细化网络以提高阴影准确性，并提出了混合正向延迟拟合策略以平衡几何和外观质量。与传统的基于神经辐射场的方法相比，RNG具有更快的训练和渲染速度，同时产生更高质量的阴影。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>RNG框架基于3DGS，可实现对象的重新照明，适用于硬表面或软边界对象。</li>
<li>RNG不需要对阴影模型进行假设，通过引入阴影线索和深度细化网络提高阴影准确性。</li>
<li>RNG提出了混合正向延迟拟合策略，以平衡几何和外观质量。</li>
<li>与传统基于神经辐射场的方法相比，RNG具有更快的训练和渲染速度。</li>
<li>RNG产生的阴影质量更高，比现有的3DGS方法更优越。</li>
<li>RNG框架的更多细节和实现在项目页面（<a target="_blank" rel="noopener" href="https://www.whois-jiahui.fun/project_pages/RNG%EF%BC%89%E4%B8%8A%E6%8F%90%E4%BE%9B%E3%80%82">https://www.whois-jiahui.fun/project_pages/RNG）上提供。</a></li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2409.19702">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-5623541c6f6e44caa9f179fc060a805e.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-2f7a2a2bb6183ffea7599ff23098f6d0.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c20d546954b3a9e1bf33f2c1c1149206.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-3cf94761c46975cf6949ae4dc8f22102.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="Expansive-Supervision-for-Neural-Radiance-Field"><a href="#Expansive-Supervision-for-Neural-Radiance-Field" class="headerlink" title="Expansive Supervision for Neural Radiance Field"></a>Expansive Supervision for Neural Radiance Field</h2><p><strong>Authors:Weixiang Zhang, Shuzhao Xie, Shijia Ge, Wei Yao, Chen Tang, Zhi Wang</strong></p>
<p>Neural Radiance Field (NeRF) has achieved remarkable success in creating immersive media representations through its exceptional reconstruction capabilities. However, the computational demands of dense forward passes and volume rendering during training continue to challenge its real-world applications. In this paper, we introduce Expansive Supervision to reduce time and memory costs during NeRF training from the perspective of partial ray selection for supervision. Specifically, we observe that training errors exhibit a long-tail distribution correlated with image content. Based on this observation, our method selectively renders a small but crucial subset of pixels and expands their values to estimate errors across the entire area for each iteration. Compared to conventional supervision, our approach effectively bypasses redundant rendering processes, resulting in substantial reductions in both time and memory consumption. Experimental results demonstrate that integrating Expansive Supervision within existing state-of-the-art acceleration frameworks achieves 52% memory savings and 16% time savings while maintaining comparable visual quality. </p>
<blockquote>
<p>神经辐射场（NeRF）凭借其出色的重建能力，在创建沉浸式媒体表示方面取得了显著的成功。然而，训练过程中的密集前向传递和体积渲染的计算需求仍然对其实际应用提出了挑战。本文引入扩展监督（Expansive Supervision）从部分射线选择监督的角度减少NeRF训练的时间和内存成本。具体来说，我们观察到训练错误与图像内容呈现长尾分布相关。基于此观察，我们的方法选择渲染一小部分但至关重要的像素，并扩大它们的值来估计每个迭代整个区域的误差。与传统的监督方法相比，我们的方法有效地绕过了冗余的渲染过程，导致时间和内存消耗的显著减少。实验结果表明，在现有的最先进的加速框架中融入扩展监督方法，可在保持相当视觉质量的同时，实现52%的内存节省和16%的时间节省。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2409.08056v3">PDF</a> Accepted by ICME 2025</p>
<p><strong>Summary</strong></p>
<p>本文介绍了NeRF技术在训练过程中的计算需求挑战其实际应用的问题。针对这一问题，文章提出了Expansive Supervision方法，通过选择性渲染关键像素并扩大其值来估算误差，从而减少时间和内存成本。实验结果显示，结合现有的加速框架使用此方法实现了内存节省和时间节省。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>NeRF技术已在创建沉浸式媒体表示方面取得了显著成功。</li>
<li>训练过程中的密集正向传递和体积渲染计算需求挑战了其实际应用。</li>
<li>Expansive Supervision方法通过选择性渲染关键像素并扩大其值来估算误差，从而减少时间和内存成本。</li>
<li>Expansive Supervision方法观察到训练错误与图像内容之间存在长尾分布关系。</li>
<li>Expansive Supervision方法可以有效地绕过冗余的渲染过程。</li>
<li>结合现有加速框架使用此方法实现了内存节省和时间节省，分别为52%和16%。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2409.08056">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-b655720b737d97ba2cc9013d9ea2e74f.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-d4ea3704d85ade747c861da9b707fa81.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-0ed932e627b6480a89a87c4e03df6b01.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-507c4de7b17683bca5531453fb8d35f3.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-5bc2f30c44a0aad6ec176d5f988b745b.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-e835b3940c9d1278585ab7d2509e6b2d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-7a1976482a5117263b46a432c012ed69.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c8508378103f666567971895f8731797.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-3702436ad662d9bba27328501d6cc987.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="Enhancing-Temporal-Consistency-in-Video-Editing-by-Reconstructing-Videos-with-3D-Gaussian-Splatting"><a href="#Enhancing-Temporal-Consistency-in-Video-Editing-by-Reconstructing-Videos-with-3D-Gaussian-Splatting" class="headerlink" title="Enhancing Temporal Consistency in Video Editing by Reconstructing Videos   with 3D Gaussian Splatting"></a>Enhancing Temporal Consistency in Video Editing by Reconstructing Videos   with 3D Gaussian Splatting</h2><p><strong>Authors:Inkyu Shin, Qihang Yu, Xiaohui Shen, In So Kweon, Kuk-Jin Yoon, Liang-Chieh Chen</strong></p>
<p>Recent advancements in zero-shot video diffusion models have shown promise for text-driven video editing, but challenges remain in achieving high temporal consistency. To address this, we introduce Video-3DGS, a 3D Gaussian Splatting (3DGS)-based video refiner designed to enhance temporal consistency in zero-shot video editors. Our approach utilizes a two-stage 3D Gaussian optimizing process tailored for editing dynamic monocular videos. In the first stage, Video-3DGS employs an improved version of COLMAP, referred to as MC-COLMAP, which processes original videos using a Masked and Clipped approach. For each video clip, MC-COLMAP generates the point clouds for dynamic foreground objects and complex backgrounds. These point clouds are utilized to initialize two sets of 3D Gaussians (Frg-3DGS and Bkg-3DGS) aiming to represent foreground and background views. Both foreground and background views are then merged with a 2D learnable parameter map to reconstruct full views. In the second stage, we leverage the reconstruction ability developed in the first stage to impose the temporal constraints on the video diffusion model. To demonstrate the efficacy of Video-3DGS on both stages, we conduct extensive experiments across two related tasks: Video Reconstruction and Video Editing. Video-3DGS trained with 3k iterations significantly improves video reconstruction quality (+3 PSNR, +7 PSNR increase) and training efficiency (x1.9, x4.5 times faster) over NeRF-based and 3DGS-based state-of-art methods on DAVIS dataset, respectively. Moreover, it enhances video editing by ensuring temporal consistency across 58 dynamic monocular videos. </p>
<blockquote>
<p>最近，零样本视频扩散模型的发展在文本驱动的视频编辑方面显示出前景。然而，在提高时间一致性方面仍然存在挑战。为了解决这个问题，我们引入了Video-3DGS，这是一种基于三维高斯喷涂（3DGS）的视频细化器，旨在提高零样本视频编辑器的时间一致性。我们的方法利用两阶段三维高斯优化过程，针对动态单目视频编辑而量身定制。在第一阶段，Video-3DGS采用改进的COLMAP版本，称为MC-COLMAP，它采用掩膜和裁剪方法对原始视频进行处理。对于每个视频片段，MC-COLMAP会生成动态前景对象和复杂背景的点云。这些点云用于初始化两组三维高斯分布（Frg-3DGS和Bkg-3DGS），旨在表示前景和背景视图。然后将前景和背景视图与二维可学习参数图合并，以重建全视图。在第二阶段，我们利用第一阶段开发的重建能力对视频扩散模型施加时间约束。为了证明Video-3DGS在两个阶段的有效性，我们在两个相关任务上进行了大量实验：视频重建和视频编辑。Video-3DGS经过3k次迭代训练后，在DAVIS数据集上与基于NeRF和基于3DGS的先进技术方法相比，视频重建质量提高了（+3 PSNR，+7 PSNR增加），训练效率也显著提高（分别提高了1.9倍和4.5倍）。此外，它通过确保58个动态单目视频的时间一致性，提高了视频编辑的质量。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2406.02541v4">PDF</a> Accepted to TMLR 2025. Project page at   <a target="_blank" rel="noopener" href="https://video-3dgs-project.github.io/">https://video-3dgs-project.github.io/</a></p>
<p><strong>摘要</strong></p>
<p>近期零样本视频扩散模型在文本驱动的视频编辑方面展现出潜力，但在实现高时间一致性方面仍存在挑战。为解决此问题，我们推出Video-3DGS，一种基于3D高斯喷绘（3DGS）的视频精炼器，旨在增强零样本视频编辑器的时间一致性。该方法采用两阶段3D高斯优化流程，专门针对动态单目视频编辑。第一阶段，Video-3DGS采用改进版COLMAP（称为MC-COLMAP），通过遮罩和裁剪方法处理原始视频。MC-COLMAP为每段视频生成动态前景对象和复杂背景的点云，用于初始化两组3D高斯（Frg-3DGS和Bkg-3DGS），旨在表示前景和背景视图。然后，将前景和背景视图与2D可学习参数图合并，以重建全视图。第二阶段，我们利用第一阶段的重建能力，对视频扩散模型施加时间约束。我们在视频重建和视频编辑两个任务上进行了大量实验，证明了Video-3DGS在两个阶段的有效性。在DAVIS数据集上，Video-3DGS经过3k次迭代训练，显著提高了视频重建质量（PSNR提高3点和7点），并提高了训练效率（分别为1.9倍和4.5倍）。此外，它能确保在58个动态单目视频中的时间一致性，从而增强视频编辑效果。</p>
<p><strong>关键见解</strong></p>
<ol>
<li>Video-3DGS被设计用于增强零样本视频编辑器的时间一致性，针对动态单目视频编辑。</li>
<li>Video-3DGS采用两阶段3D高斯优化流程，包括利用MC-COLMAP生成点云和初始化两组3D高斯。</li>
<li>MC-COLMAP通过处理原始视频生成点云，用于重建前景和背景视图。</li>
<li>Video-3DGS将前景和背景视图与2D可学习参数图合并，以提高视频重建质量。</li>
<li>第二阶段利用重建能力对视频扩散模型施加时间约束。</li>
<li>Video-3DGS在DAVIS数据集上的实验表明，与基于NeRF和基于3DGS的现有方法相比，它在视频重建质量、训练效率和视频编辑的临时一致性方面有显著改进。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2406.02541">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-db1aa88f168a9dc813b77e27508dbcdb.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-32f0c93b2bde571af9c5b7f26846f95a.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-1a14b4762fcc70b5d04b3be32f030a61.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c135640fbe09b755272b0ea0d6f15254.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a37a69fc232575f75630c7c0a178d297.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="ARC-NeRF-Area-Ray-Casting-for-Broader-Unseen-View-Coverage-in-Few-shot-Object-Rendering"><a href="#ARC-NeRF-Area-Ray-Casting-for-Broader-Unseen-View-Coverage-in-Few-shot-Object-Rendering" class="headerlink" title="ARC-NeRF: Area Ray Casting for Broader Unseen View Coverage in Few-shot   Object Rendering"></a>ARC-NeRF: Area Ray Casting for Broader Unseen View Coverage in Few-shot   Object Rendering</h2><p><strong>Authors:Seunghyeon Seo, Yeonjin Chang, Jayeon Yoo, Seungwoo Lee, Hojun Lee, Nojun Kwak</strong></p>
<p>Recent advancements in the Neural Radiance Field (NeRF) have enhanced its capabilities for novel view synthesis, yet its reliance on dense multi-view training images poses a practical challenge, often leading to artifacts and a lack of fine object details. Addressing this, we propose ARC-NeRF, an effective regularization-based approach with a novel Area Ray Casting strategy. While the previous ray augmentation methods are limited to covering only a single unseen view per extra ray, our proposed Area Ray covers a broader range of unseen views with just a single ray and enables an adaptive high-frequency regularization based on target pixel photo-consistency. Moreover, we propose luminance consistency regularization, which enhances the consistency of relative luminance between the original and Area Ray, leading to more accurate object textures. The relative luminance, as a free lunch extra data easily derived from RGB images, can be effectively utilized in few-shot scenarios where available training data is limited. Our ARC-NeRF outperforms its baseline and achieves competitive results on multiple benchmarks with sharply rendered fine details. </p>
<blockquote>
<p>尽管Neural Radiance Field（NeRF）的最新进展增强了其在新型视图合成方面的能力，但它对密集多视图训练图像的依赖构成了实际应用中的挑战，常常导致伪影和对象细节缺乏精细度。为解决这一问题，我们提出了ARC-NeRF，这是一种基于有效正则化的方法，并采用了新型的区域光线投射策略。尽管之前的射线增强方法仅限于每额外射线只覆盖一个未见视图，我们提出的地域射线仅需一条射线就能覆盖更广泛的未见视图，并实现了基于目标像素照片一致性的自适应高频正则化。此外，我们提出了亮度一致性正则化，它增强了原始射线和区域射线之间相对亮度的一致性，从而得到更精确的对象纹理。相对亮度作为从RGB图像轻松派生的免费额外数据，在可用训练数据有限的少量场景中可以得到有效利用。我们的ARC-NeRF超越了基线，并在多个基准测试上取得了具有精细渲染细节的竞争结果。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2403.10906v2">PDF</a> CVPR 2025 Workshop: 4th Computer Vision for Metaverse Workshop</p>
<p><strong>Summary</strong><br>NeRF技术的新进展提升了其在新型视角合成方面的能力，但仍面临依赖于密集多角度训练图像的问题，导致出现伪影和细节缺失等缺陷。为解决这一问题，我们提出了ARC-NeRF方案，采用基于正则化的新方法及创新的Area Ray Casting策略。相较于仅通过额外射线覆盖单一未见视角的现有射线增强方法，Area Ray能更广泛地覆盖未见视角，并通过目标像素的光一致性实现自适应高频正则化。此外，我们还提出了亮度一致性正则化，提高了原始图像和Area Ray之间的相对亮度一致性，从而得到更准确的物体纹理。利用相对亮度这一容易从RGB图像中获取的额外数据，ARC-NeRF在少量训练数据的情况下也能表现出色。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>NeRF技术在新型视角合成方面取得进展，但依赖于密集多角度训练图像导致伪影和细节缺失问题。</li>
<li>提出了ARC-NeRF方案，采用基于正则化的新方法和Area Ray Casting策略解决现有问题。</li>
<li>Area Ray能覆盖更广泛的未见视角，通过目标像素的光一致性实现自适应高频正则化。</li>
<li>引入亮度一致性正则化，提高物体纹理的准确性。</li>
<li>ARC-NeRF方案利用相对亮度这一额外数据，能在有限训练数据的情况下表现良好。</li>
<li>ARC-NeRF在多个基准测试中表现优于基准方法，能够精细呈现细节。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2403.10906">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-29ae4f85a7b28fd50d9d2762409032f4.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f57da3615c8eb9d74925d80c987ef4f2.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d8a15ff01bb329f42513133df2ad9003.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-31310efbe9b4a478693df17b94ac64fb.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        文章作者:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        文章链接:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-04-09/NeRF/">https://kedreamix.github.io/Talk2Paper/Paper/2025-04-09/NeRF/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        版权声明:
                    </i>
                </span>
                <span class="reprint-info">
                    本博客所有文章除特別声明外，均采用
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    许可协议。转载请注明来源
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/NeRF/">
                                    <span class="chip bg-color">NeRF</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;上一篇</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-04-09/Diffusion%20Models/">
                    <div class="card-image">
                        
                        <img src="https://pic1.zhimg.com/v2-1d874aa872307bde9e8a53820468e24f.jpg" class="responsive-img" alt="Diffusion Models">
                        
                        <span class="card-title">Diffusion Models</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Diffusion Models 方向最新论文已更新，请持续关注 Update in 2025-04-09  Gaussian Mixture Flow Matching Models
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-04-09
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Diffusion-Models/" class="post-category">
                                    Diffusion Models
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Diffusion-Models/">
                        <span class="chip bg-color">Diffusion Models</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-04-09/3DGS/">
                    <div class="card-image">
                        
                        <img src="https://pic1.zhimg.com/v2-96820a96652e1b4e81f4a21511556126.jpg" class="responsive-img" alt="3DGS">
                        
                        <span class="card-title">3DGS</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            3DGS 方向最新论文已更新，请持续关注 Update in 2025-04-09  Let it Snow! Animating Static Gaussian Scenes With Dynamic Weather   Effects
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-04-09
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/3DGS/" class="post-category">
                                    3DGS
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/3DGS/">
                        <span class="chip bg-color">3DGS</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- 代码语言 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span
                        class="white-color">16905.3k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- 运行天数提醒. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // 区分是否有年份.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = '本站已运行 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                daysTip = '本站已運行 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = '本站已运行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = '本站已運行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="关注我的知乎: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">知</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- 白天和黑夜主题 -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // 只在桌面版网页启用特效
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- 雪花特效 -->
    

    <!-- 鼠标星星特效 -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--腾讯兔小巢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- 动态标签 -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Σ(っ °Д °;)っ诶，页面崩溃了嘛？", clearTimeout(st)) : (document.title = "φ(゜▽゜*)♪咦，又好了！", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
