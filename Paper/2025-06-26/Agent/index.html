<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Agent">
    <meta name="description" content="Agent 方向最新论文已更新，请持续关注 Update in 2025-06-26  MAM Modular Multi-Agent Framework for Multi-Modal Medical Diagnosis via   Role-Specialized Collaboration">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>Agent | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loader页面消失采用渐隐的方式*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logo出现动画 */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//使用渐隐的方法淡出loading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//强制显示loading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">嘘~  正在从服务器偷取页面 . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>首页</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>标签</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>分类</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>归档</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="搜索" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="深色/浅色模式" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			首页
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			标签
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			分类
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			归档
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://picx.zhimg.com/v2-43911e7a52debe8d9745cab395780d94.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Agent</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/Agent/">
                                <span class="chip bg-color">Agent</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/Agent/" class="post-category">
                                Agent
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2025-06-26
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>更新日期:&nbsp;&nbsp;
                    2025-07-06
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp;
                    8.6k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp;
                    34 分
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>阅读次数:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>⚠️ 以下所有内容总结都来自于 大语言模型的能力，如有错误，仅供参考，谨慎使用<br>🔴 请注意：千万不要用于严肃的学术场景，只能用于论文阅读前的初筛！<br>💗 如果您觉得我们的项目对您有帮助 <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ，还请您给我们一些鼓励！⭐️ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFace免费体验</a></p>
</blockquote>
<h1 id="2025-06-26-更新"><a href="#2025-06-26-更新" class="headerlink" title="2025-06-26 更新"></a>2025-06-26 更新</h1><h2 id="MAM-Modular-Multi-Agent-Framework-for-Multi-Modal-Medical-Diagnosis-via-Role-Specialized-Collaboration"><a href="#MAM-Modular-Multi-Agent-Framework-for-Multi-Modal-Medical-Diagnosis-via-Role-Specialized-Collaboration" class="headerlink" title="MAM: Modular Multi-Agent Framework for Multi-Modal Medical Diagnosis via   Role-Specialized Collaboration"></a>MAM: Modular Multi-Agent Framework for Multi-Modal Medical Diagnosis via   Role-Specialized Collaboration</h2><p><strong>Authors:Yucheng Zhou, Lingran Song, Jianbing Shen</strong></p>
<p>Recent advancements in medical Large Language Models (LLMs) have showcased their powerful reasoning and diagnostic capabilities. Despite their success, current unified multimodal medical LLMs face limitations in knowledge update costs, comprehensiveness, and flexibility. To address these challenges, we introduce the Modular Multi-Agent Framework for Multi-Modal Medical Diagnosis (MAM). Inspired by our empirical findings highlighting the benefits of role assignment and diagnostic discernment in LLMs, MAM decomposes the medical diagnostic process into specialized roles: a General Practitioner, Specialist Team, Radiologist, Medical Assistant, and Director, each embodied by an LLM-based agent. This modular and collaborative framework enables efficient knowledge updates and leverages existing medical LLMs and knowledge bases. Extensive experimental evaluations conducted on a wide range of publicly accessible multimodal medical datasets, incorporating text, image, audio, and video modalities, demonstrate that MAM consistently surpasses the performance of modality-specific LLMs. Notably, MAM achieves significant performance improvements ranging from 18% to 365% compared to baseline models. Our code is released at <a target="_blank" rel="noopener" href="https://github.com/yczhou001/MAM">https://github.com/yczhou001/MAM</a>. </p>
<blockquote>
<p>近期，医疗领域的大型语言模型（LLM）取得了显著的进展，展示了其强大的推理和诊断能力。然而，尽管取得了成功，当前的统一多模式医疗LLM在知识更新成本、全面性和灵活性方面仍存在局限性。为了解决这些挑战，我们引入了用于多模式医疗诊断的模块化多智能体框架（MAM）。受我们实证研究的启发，该实证研究突出了角色分配和诊断识别在LLM中的优势，MAM将医疗诊断过程分解为专门的角色：全科医生、专业团队、放射科医生、医疗助理和主任，每个角色均由基于LLM的智能体体现。这种模块化和协作的框架能够实现高效的知识更新，并充分利用现有的医疗LLM和知识库。在包含文本、图像、音频和视频模式的公开可访问的多模式医疗数据集上进行的广泛实验评估表明，MAM的性能始终超过特定模态的LLM。值得注意的是，与基准模型相比，MAM实现了从18%到365%的显著性能提升。我们的代码已发布在<a target="_blank" rel="noopener" href="https://github.com/yczhou000/MAM%E4%B8%8A%E3%80%82">https://github.com/yczhou000/MAM上。</a></p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.19835v1">PDF</a> ACL 2025 Findings</p>
<p><strong>Summary</strong><br>     医疗领域的大型语言模型（LLM）最新进展展示了其强大的推理和诊断能力。然而，现有的统一多模式医疗LLM在知识更新成本、全面性和灵活性方面存在局限。为解决这些问题，我们提出了模块化多智能体框架（MAM），用于多模式医疗诊断。MAM将医疗诊断过程分解为专业角色，利用LLM智能体扮演全科医生、专家团队、放射科医生、医疗助理和主任等角色。该模块化协作框架可实现高效知识更新，利用现有医疗LLM和知识库。在包含文本、图像、音频和视频模式的公开多模式医疗数据集上进行的广泛实验评估表明，MAM的性能持续超越特定模态LLM的性能，与基线模型相比，性能提高了18％至365％。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>医疗大型语言模型（LLM）具备强大的推理和诊断能力。</li>
<li>当前统一多模式医疗LLM存在知识更新成本、全面性和灵活性方面的挑战。</li>
<li>提出模块化多智能体框架（MAM）进行多模式医疗诊断。</li>
<li>MAM将医疗诊断过程分解为专业角色，如全科医生、专家团队等，并由LLM智能体扮演。</li>
<li>MAM利用模块化协作框架实现高效知识更新，并利用现有医疗LLM和知识库。</li>
<li>在多模式医疗数据集上的实验评估显示，MAM性能优于模态特定LLM。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.19835">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-7b9c6a0c23235ace69af8d6dd4dd5c3e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-dccbccaef9a18cf4f368eaf89e5a4e69.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-a3fddf03b8db99bdf9503d907ea7f746.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e5701d717bfa9108fe91b6b0d5ce368f.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="From-Reproduction-to-Replication-Evaluating-Research-Agents-with-Progressive-Code-Masking"><a href="#From-Reproduction-to-Replication-Evaluating-Research-Agents-with-Progressive-Code-Masking" class="headerlink" title="From Reproduction to Replication: Evaluating Research Agents with   Progressive Code Masking"></a>From Reproduction to Replication: Evaluating Research Agents with   Progressive Code Masking</h2><p><strong>Authors:Gyeongwon James Kim, Alex Wilf, Louis-Philippe Morency, Daniel Fried</strong></p>
<p>Recent progress in autonomous code generation has fueled excitement around AI agents capable of accelerating scientific discovery by running experiments. However, there is currently no benchmark that evaluates whether such agents can implement scientific ideas when given varied amounts of code as a starting point, interpolating between reproduction (running code) and from-scratch replication (fully re-implementing and running code). We introduce AutoExperiment, a benchmark that evaluates AI agents’ ability to implement and run machine learning experiments based on natural language descriptions in research papers. In each task, agents are given a research paper, a codebase with key functions masked out, and a command to run the experiment. The goal is to generate the missing code, execute the experiment in a sandboxed environment, and reproduce the results. AutoExperiment scales in difficulty by varying the number of missing functions $n$, ranging from partial reproduction to full replication. We evaluate state-of-the-art agents and find that performance degrades rapidly as $n$ increases. Agents that can dynamically interact with the environment (e.g. to debug their code) can outperform agents in fixed “agentless” harnesses, and there exists a significant gap between single-shot and multi-trial success rates (Pass@1 vs. Pass@5), motivating verifier approaches to our benchmark. Our findings highlight critical challenges in long-horizon code generation, context retrieval, and autonomous experiment execution, establishing AutoExperiment as a new benchmark for evaluating progress in AI-driven scientific experimentation. Our data and code are open-sourced at <a target="_blank" rel="noopener" href="https://github.com/j1mk1m/AutoExperiment">https://github.com/j1mk1m/AutoExperiment</a> . </p>
<blockquote>
<p>近期自主代码生成的进展激发了人们对能够加速科学发现的人工智能代理的兴奋之情。然而，目前尚没有一个基准测试来评估这些代理在给定的不同数量的代码起点上实现科学想法的能力，这些代码起点介于复制（运行代码）和从头开始复制（完全重新实现和运行代码）之间。我们引入了AutoExperiment，这是一个评估人工智能代理根据研究论文中的自然语言描述来实现和运行机器学习实验能力的基准测试。在每个任务中，代理会收到一篇研究论文、一个带有关键功能被遮蔽的代码库以及一个运行实验的命令。目标是生成缺失的代码，在沙箱环境中执行实验并再现结果。AutoExperiment的难度通过调整缺失函数$ n $的数量来增加，从部分复制扩展到完全复制。我们评估了最先进的代理，并发现随着$ n $的增加，性能迅速下降。能够与环境动态交互的代理（例如用于调试代码）可以超越固定“无代理”框架中的代理，单次试验成功率与多次试验成功率之间存在较大差距（Pass@1与Pass@5），这激发了对我们基准测试的验证器方法的研究。我们的研究发现了长周期代码生成、上下文检索和自主实验执行方面的关键挑战，确立了AutoExperiment作为评估人工智能驱动科学实验进展的新基准。我们的数据和代码已开源，网址为：<a target="_blank" rel="noopener" href="https://github.com/j1mk1m/AutoExperiment%E3%80%82">https://github.com/j1mk1m/AutoExperiment。</a></p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.19724v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>本文主要介绍了一项新技术——AutoExperiment基准测试。这项测试旨在评估人工智能代理是否能根据研究论文中的自然语言描述来实现和运行机器学习实验。该测试包括在给定研究论文、代码库及缺失函数的任务下，生成缺失代码、在沙箱环境中进行实验并复现结果的能力。AutoExperiment通过调整缺失函数数量n的多少来增加难度，从部分复现到完全复制不等。评估发现，随着n的增加，代理性能迅速下降。此外，能与环境动态交互的代理表现优于固定框架中的代理，单次与多次试验成功率之间存在较大差距，这激发了验证器方法的发展。此研究为长期视角的代码生成、上下文检索和自主实验执行提出了关键挑战，同时建立了一个新的评估基准。有关数据和代码已在公开渠道获取：<a target="_blank" rel="noopener" href="https://github.com/j1mk1m/AutoExperiment">https://github.com/j1mk1m/AutoExperiment</a>。</p>
<p><strong>Key Takeaways</strong></p>
<p>以下是基于文本的关键见解：</p>
<ol>
<li>AutoExperiment是一个新的基准测试，用于评估AI代理在根据自然语言描述实现和运行机器学习实验方面的能力。</li>
<li>测试包括生成缺失代码、在沙箱环境中进行实验并复现结果的任务。</li>
<li>测试难度通过调整缺失函数数量n来调整，涵盖从部分复现到完全复制的不同难度级别。</li>
<li>评估发现，随着缺失函数数量的增加，代理性能迅速下降。</li>
<li>动态交互的代理表现优于固定框架中的代理。</li>
<li>单次与多次试验成功率之间存在差距，这突显了验证器方法的重要性。</li>
<li>此研究为代码生成、上下文检索和自主实验执行提出了挑战，并建立了新的评估基准。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.19724">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-8ccf575ea3423dd7a16556fc3a58490d.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-8a4303fcd5279252d7bf825fbae60d13.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-bff53db5f5cd55413aa7fa53eff5bf6b.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-279ab7c0427dbfedb2fd7fa6117713fb.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a187f41d5feab6e2923e8cf2af03437f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-88c2fa9f6a0a230e83b703dcfac04763.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-91a96b0137fb259dfc20ecc1e549b479.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-43911e7a52debe8d9745cab395780d94.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="MATE-LLM-Powered-Multi-Agent-Translation-Environment-for-Accessibility-Applications"><a href="#MATE-LLM-Powered-Multi-Agent-Translation-Environment-for-Accessibility-Applications" class="headerlink" title="MATE: LLM-Powered Multi-Agent Translation Environment for Accessibility   Applications"></a>MATE: LLM-Powered Multi-Agent Translation Environment for Accessibility   Applications</h2><p><strong>Authors:Aleksandr Algazinov, Matt Laing, Paul Laban</strong></p>
<p>Accessibility remains a critical concern in today’s society, as many technologies are not developed to support the full range of user needs. Existing multi-agent systems (MAS) often cannot provide comprehensive assistance for users in need due to the lack of customization stemming from closed-source designs. Consequently, individuals with disabilities frequently encounter significant barriers when attempting to interact with digital environments. We introduce MATE, a multimodal accessibility MAS, which performs the modality conversions based on the user’s needs. The system is useful for assisting people with disabilities by ensuring that data will be converted to an understandable format. For instance, if the user cannot see well and receives an image, the system converts this image to its audio description. MATE can be applied to a wide range of domains, industries, and areas, such as healthcare, and can become a useful assistant for various groups of users. The system supports multiple types of models, ranging from LLM API calling to using custom machine learning (ML) classifiers. This flexibility ensures that the system can be adapted to various needs and is compatible with a wide variety of hardware. Since the system is expected to run locally, it ensures the privacy and security of sensitive information. In addition, the framework can be effectively integrated with institutional technologies (e.g., digital healthcare service) for real-time user assistance. Furthermore, we introduce ModCon-Task-Identifier, a model that is capable of extracting the precise modality conversion task from the user input. Numerous experiments show that ModCon-Task-Identifier consistently outperforms other LLMs and statistical models on our custom data. Our code and data are publicly available at <a target="_blank" rel="noopener" href="https://github.com/AlgazinovAleksandr/Multi-Agent-MATE">https://github.com/AlgazinovAleksandr/Multi-Agent-MATE</a>. </p>
<blockquote>
<p>在当今社会，无障碍性仍然是一个关键问题，因为许多技术并非为了支持各种用户需求而开发。现有的多智能体系统（MAS）往往无法为有特殊需求的用户提供全面的帮助，这主要是因为其封闭源代码设计导致缺乏个性化定制。因此，残疾人在尝试与数字环境交互时经常遇到重大障碍。我们介绍了MATE，这是一个多模式无障碍MAS，它可以根据用户的需求进行模式转换。该系统通过确保数据转换为可理解格式，对于帮助残疾人非常有用。例如，如果用户视力不佳并收到一张图片，系统会将该图片转换为音频描述。MATE可广泛应用于各种领域、行业和地区，如医疗保健，可以成为各种用户的实用助手。该系统支持多种类型的模型，从调用大型语言模型API到使用自定义机器学习（ML）分类器。这种灵活性确保了系统可以根据各种需求进行适应，并且与各种硬件兼容。由于系统预计将在本地运行，因此它确保了敏感信息的隐私和安全。此外，该框架可以有效地与机构技术（例如数字医疗服务）集成，以进行实时用户协助。此外，我们还介绍了ModCon-Task-Identifier模型，该模型能够从用户输入中精确提取模式转换任务。大量实验表明，ModCon-Task-Identifier在我们的自定义数据上始终优于其他大型语言模型和统计模型。我们的代码和数据公开可用在<a target="_blank" rel="noopener" href="https://github.com/AlgazinovAleksandr/Multi-Agent-MATE%E3%80%82">https://github.com/AlgazinovAleksandr/Multi-Agent-MATE。</a></p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.19502v1">PDF</a> </p>
<p><strong>摘要</strong></p>
<p>当今社会，无障碍性依然是一个关键问题，因为许多技术并未开发以支持用户的全面需求。现有的多智能体系统（MAS）常常无法为用户提供全面的帮助，因为它们源于封闭式设计导致缺乏个性化定制。因此，残疾人个体在与数字环境交互时经常面临重大障碍。我们引入了多模态访问MAS——MATE，它能根据用户的需求进行模态转换。该系统通过将数据转换成用户可理解的形式，帮助有需求的人。比如，如果用户视力不佳并收到图像信息，该系统可将图像转换成音频描述。MATE可广泛应用于各种领域、行业和区域，如医疗保健，成为各种用户的实用助理。该系统支持多种类型的模型，从调用大型语言模型API到使用自定义机器学习分类器。这种灵活性确保了系统可以根据各种需求进行适应并与广泛的硬件兼容。由于系统预计将在本地运行，因此它确保了敏感信息的隐私和安全。此外，该框架可以与机构技术（如数字医疗服务）有效集成，为用户提供实时帮助。我们还介绍了ModCon-Task-Identifier模型，它能够精确提取用户输入中的模态转换任务。多项实验表明，ModCon-Task-Identifier在我们的自定义数据上始终优于其他大型语言模型和统计模型。我们的代码和数据公开在<a target="_blank" rel="noopener" href="https://github.com/AlgazinovAleksandr/Multi-Agent-MATE%E3%80%82">https://github.com/AlgazinovAleksandr/Multi-Agent-MATE。</a></p>
<p><strong>要点摘要</strong></p>
<ol>
<li>多模态访问MAS——MATE能够解决现有技术无法满足用户需求的问题，尤其在帮助残疾人与数字环境交互方面发挥重要作用。</li>
<li>MATE能根据用户需求进行模态转换，比如将图像转换为音频描述，满足不同的用户需求。</li>
<li>MATE具有广泛的应用领域，如医疗保健等，并适用于各种用户群体。</li>
<li>系统支持多种类型的模型并具有灵活性，能适应各种需求并与广泛的硬件兼容。</li>
<li>MATE注重用户隐私和数据安全，能够在本地运行确保敏感信息的安全。</li>
<li>MATE可以与机构技术集成，提供实时用户帮助。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.19502">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-76ee1ec3ab98a6ed7ff3a4657e95e9e7.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-702397add5a0b4936f22e36f83192db9.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-11751aae4e0aeb2bfffe7e66619cd275.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-389cb863835e3683e467a840ab41be94.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="Augmenting-Multi-Agent-Communication-with-State-Delta-Trajectory"><a href="#Augmenting-Multi-Agent-Communication-with-State-Delta-Trajectory" class="headerlink" title="Augmenting Multi-Agent Communication with State Delta Trajectory"></a>Augmenting Multi-Agent Communication with State Delta Trajectory</h2><p><strong>Authors:Yichen Tang, Weihang Su, Yujia Zhou, Yiqun Liu, Min Zhang, Shaoping Ma, Qingyao Ai</strong></p>
<p>Multi-agent techniques such as role playing or multi-turn debates have been shown to be effective in improving the performance of large language models (LLMs) in downstream tasks. Despite their differences in workflows, existing LLM-based multi-agent systems mostly use natural language for agent communication. While this is appealing for its simplicity and interpretability, it also introduces inevitable information loss as one model must down sample its continuous state vectors to concrete tokens before transferring them to the other model. Such losses are particularly significant when the information to transfer is not simple facts, but reasoning logics or abstractive thoughts. To tackle this problem, we propose a new communication protocol that transfers both natural language tokens and token-wise state transition trajectory from one agent to another. Particularly, compared to the actual state value, we find that the sequence of state changes in LLMs after generating each token can better reflect the information hidden behind the inference process, so we propose a State Delta Encoding (SDE) method to represent state transition trajectories. The experimental results show that multi-agent systems with SDE achieve SOTA performance compared to other communication protocols, particularly in tasks that involve complex reasoning. This shows the potential of communication augmentation for LLM-based multi-agent systems. </p>
<blockquote>
<p>多智能体技术，如角色扮演或多轮辩论，已被证明在改善大型语言模型（LLM）在下游任务中的性能方面非常有效。尽管它们的工作流程存在差异，但现有的基于LLM的多智能体系统大多使用自然语言进行智能体之间的通信。虽然这种方式的简单性和可解释性很吸引人，但它也带来了不可避免的信息损失，因为一个模型必须将连续的状态向量下采样为具体的令牌，然后再将它们传输给另一个模型。当要传输的信息不是简单的事实，而是推理逻辑或抽象思想时，这种损失尤其显著。为了解决这一问题，我们提出了一种新的通信协议，该协议可以将一个智能体的自然语言令牌和令牌级的状态转换轨迹传输到另一个智能体。特别是，与实际状态值相比，我们发现LLM在生成每个令牌后的状态变化序列能更好地反映推理过程背后隐藏的信息，因此我们提出了一种状态增量编码（SDE）方法来表示状态转换轨迹。实验结果表明，采用SDE的多智能体系统与其他通信协议相比实现了最佳性能，特别是在涉及复杂推理的任务中。这显示了通信增强对于基于LLM的多智能体系统的潜力。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.19209v1">PDF</a> 22 pages, 5 figures</p>
<p><strong>Summary</strong></p>
<p>本文探讨了多智能体技术在大型语言模型（LLM）下游任务中的应用，并提出了新的通信协议和状态变化编码方法。实验结果表明，采用状态差分编码（SDE）的多智能体系统在复杂推理任务上实现了最佳性能，展示了通信增强在LLM基多智能体系统中的潜力。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>多智能体技术如角色扮演和多轮辩论能有效提高大型语言模型（LLM）在下游任务中的性能。</li>
<li>当前LLM基多智能体系统主要使用自然语言进行智能体间的通信。</li>
<li>使用自然语言进行通信会导致信息损失，特别是在传递推理逻辑和抽象思想时。</li>
<li>提出了一种新的通信协议，能够同时传递自然语言标记和标记级别的状态转换轨迹。</li>
<li>与实际状态值相比，LLM生成每个标记后的状态变化序列能更好地反映推理过程背后的信息。</li>
<li>引入了状态差分编码（SDE）方法来表示状态转换轨迹。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.19209">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-15d5f7a3ac54d03ac013b5ca548649ca.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-bce11f3f46bb6e3c8201000860d3caea.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="From-Web-Search-towards-Agentic-Deep-Research-Incentivizing-Search-with-Reasoning-Agents"><a href="#From-Web-Search-towards-Agentic-Deep-Research-Incentivizing-Search-with-Reasoning-Agents" class="headerlink" title="From Web Search towards Agentic Deep Research: Incentivizing Search with   Reasoning Agents"></a>From Web Search towards Agentic Deep Research: Incentivizing Search with   Reasoning Agents</h2><p><strong>Authors:Weizhi Zhang, Yangning Li, Yuanchen Bei, Junyu Luo, Guancheng Wan, Liangwei Yang, Chenxuan Xie, Yuyao Yang, Wei-Chieh Huang, Chunyu Miao, Henry Peng Zou, Xiao Luo, Yusheng Zhao, Yankai Chen, Chunkit Chan, Peilin Zhou, Xinyang Zhang, Chenwei Zhang, Jingbo Shang, Ming Zhang, Yangqiu Song, Irwin King, Philip S. Yu</strong></p>
<p>Information retrieval is a cornerstone of modern knowledge acquisition, enabling billions of queries each day across diverse domains. However, traditional keyword-based search engines are increasingly inadequate for handling complex, multi-step information needs. Our position is that Large Language Models (LLMs), endowed with reasoning and agentic capabilities, are ushering in a new paradigm termed Agentic Deep Research. These systems transcend conventional information search techniques by tightly integrating autonomous reasoning, iterative retrieval, and information synthesis into a dynamic feedback loop. We trace the evolution from static web search to interactive, agent-based systems that plan, explore, and learn. We also introduce a test-time scaling law to formalize the impact of computational depth on reasoning and search. Supported by benchmark results and the rise of open-source implementations, we demonstrate that Agentic Deep Research not only significantly outperforms existing approaches, but is also poised to become the dominant paradigm for future information seeking. All the related resources, including industry products, research papers, benchmark datasets, and open-source implementations, are collected for the community in <a target="_blank" rel="noopener" href="https://github.com/DavidZWZ/Awesome-Deep-Research">https://github.com/DavidZWZ/Awesome-Deep-Research</a>. </p>
<blockquote>
<p>信息检索是现代知识获取的核心基石，每天能够在各种领域处理数十亿次的查询请求。然而，传统的基于关键词的搜索引擎已经越来越不能满足复杂、多步骤的信息需求。我们的观点是，拥有推理和智能能力的大型语言模型（LLM）正在开创一种名为智能深度研究的新范式。这些系统通过紧密集成自主推理、迭代检索和信息合成到一个动态反馈循环中，从而超越了传统的信息搜索技术。我们追溯了从静态网页搜索到交互式、基于智能系统的演变过程，这些系统可以计划、探索和学习的能力。我们还引入了一个测试时间尺度定律来正式计算深度对推理和搜索的影响。在基准测试结果的支持下以及开源实现的兴起中，我们证明了智能深度研究不仅显著优于现有方法，而且已成为未来信息搜索的主导范式。所有相关资源，包括工业产品、研究论文、基准数据集和开源实现，都收集在 <a target="_blank" rel="noopener" href="https://github.com/DavidZWZ/Awesome-Deep-Research%EF%BC%8C%E4%BE%9B%E7%A4%BE%E5%8C%BA%E4%BD%BF%E7%94%A8%E3%80%82">https://github.com/DavidZWZ/Awesome-Deep-Research，供社区使用。</a></p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.18959v1">PDF</a> </p>
<p><strong>Summary</strong><br>在信息检索领域，传统基于关键词的搜索引擎在处理复杂、多步骤的信息需求时显得越来越不足。大型语言模型（LLMs）的出现推动了新的研究范式——Agentic深度研究，通过紧密集成自主推理、迭代检索和信息合成，超越传统信息搜索技术，形成动态反馈循环。Agentic深度研究不仅显著优于现有方法，而且可能成为未来信息搜索的主导范式。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>信息检索是现代知识获取的核心，大型语言模型（LLMs）的出现推动了信息检索的新发展。</li>
<li>传统基于关键词的搜索引擎在处理复杂、多步骤的信息需求时存在不足。</li>
<li>Agentic深度研究是一种新的研究范式，集成了自主推理、迭代检索和信息合成。</li>
<li>Agentic深度研究通过动态反馈循环超越传统信息搜索技术。</li>
<li>Agentic深度研究不仅显著优于现有方法，而且有潜力成为未来信息搜索的主导范式。</li>
<li>相关信息资源，包括工业产品、研究论文、基准数据集和开源实现，都已收集在特定仓库中供社区使用。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.18959">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-070f0fb313cdc1362efe4b9cf6eee5b3.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-76a584b347a5f8a48347111db296ccc0.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-155280869ad2bd126b54c3da5ebc7cd6.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="Breaking-Single-Tester-Limits-Multi-Agent-LLMs-for-Multi-User-Feature-Testing"><a href="#Breaking-Single-Tester-Limits-Multi-Agent-LLMs-for-Multi-User-Feature-Testing" class="headerlink" title="Breaking Single-Tester Limits: Multi-Agent LLMs for Multi-User Feature   Testing"></a>Breaking Single-Tester Limits: Multi-Agent LLMs for Multi-User Feature   Testing</h2><p><strong>Authors:Sidong Feng, Changhao Du, Huaxiao Liu, Qingnan Wang, Zhengwei Lv, Mengfei Wang, Chunyang Chen</strong></p>
<p>The growing dependence on mobile phones and their apps has made multi-user interactive features, like chat calls, live streaming, and video conferencing, indispensable for bridging the gaps in social connectivity caused by physical and situational barriers. However, automating these interactive features for testing is fraught with challenges, owing to their inherent need for timely, dynamic, and collaborative user interactions, which current automated testing methods inadequately address. Inspired by the concept of agents designed to autonomously and collaboratively tackle problems, we propose MAdroid, a novel multi-agent approach powered by the Large Language Models (LLMs) to automate the multi-user interactive task for app feature testing. Specifically, MAdroid employs two functional types of multi-agents: user agents (Operator) and supervisor agents (Coordinator and Observer). Each agent takes a specific role: the Coordinator directs the interactive task; the Operator mimics user interactions on the device; and the Observer monitors and reviews the task automation process. Our evaluation, which included 41 multi-user interactive tasks, demonstrates the effectiveness of our approach, achieving 82.9% of the tasks with 96.8% action similarity, outperforming the ablation studies and state-of-the-art baselines. Additionally, a preliminary investigation underscores MAdroid’s practicality by helping identify 11 multi-user interactive bugs during regression app testing, confirming its potential value in real-world software development contexts. </p>
<blockquote>
<p>随着对手机和应用程序的依赖程度不断增长，诸如聊天呼叫、直播和视频会议等多用户交互功能已成为弥合因物理和情境障碍造成的社交连接间隙不可或缺的工具。然而，自动化这些交互功能的测试却充满挑战，因为它们需要及时、动态和协作性的用户交互，而当前自动化测试方法无法充分满足这一需求。受旨在自主协作解决问题的智能代理概念启发，我们提出MAdroid，这是一种新型的多智能体方法，借助大型语言模型（LLM）的力量，自动化应用程序功能测试的多用户交互任务。具体而言，MAdroid采用两种功能类型的多智能体：用户智能体（操作员）和监督智能体（协调员和观察者）。每个智能体都扮演着特定的角色：协调员指导交互任务；操作员模仿设备上的用户交互；观察者监控和审查任务自动化过程。我们的评估包括41个多用户交互任务，证明了我们的方法的有效性，以82.9%的任务完成度和96.8%的动作相似性超越了对照组研究和最先进的基线。此外，初步调查通过帮助在回归应用测试中识别出11个多用户交互错误来强调MAdroid的实用性，这证实了其在现实软件开发环境中的潜在价值。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.17539v2">PDF</a> Accepted to International Conference on Software Engineering (ICSE   2026). arXiv admin note: substantial text overlap with arXiv:2504.15474</p>
<p><strong>Summary</strong><br>移动应用和交互功能如聊天、直播和视频会议对于消除社交障碍至关重要。然而，自动化测试这些交互功能面临挑战。为此，我们提出MAdroid，一种基于大型语言模型的多智能体方法，用于自动化多用户交互任务测试。智能体包括用户代理（操作者）和监督代理（协调者和观察者），各自扮演特定角色，能有效完成测试任务并识别bug。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>移动应用和交互功能对消除社交障碍起到重要作用。</li>
<li>自动化测试多用户交互功能面临挑战，需要及时的、动态的、协作的用户交互。</li>
<li>MAdroid是一种基于大型语言模型的多智能体方法，旨在解决多用户交互任务的自动化测试问题。</li>
<li>MAdroid包括三种功能型智能体：协调者、操作者和观察者。</li>
<li>协调者负责指导交互任务，操作者模仿用户设备上的交互，观察者监控和审查任务自动化过程。</li>
<li>MAdroid在41个多用户交互任务中的评估中表现出色，实现了82.9%的任务完成率，并识别出回归应用测试中的多个bug。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.17539">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-fcec7889245de93df5601a390d9fe792.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-1678a97a4c1d753555143225debd48ad.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-7774f273e5784f6561674045b8c1d0fe.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f1157d34653e22f096167b62b0e54ab4.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-fd121859df1656f7141a482808b13266.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-80bb75064fd53fc02cd2b4c31490c49e.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="TRAIL-Trace-Reasoning-and-Agentic-Issue-Localization"><a href="#TRAIL-Trace-Reasoning-and-Agentic-Issue-Localization" class="headerlink" title="TRAIL: Trace Reasoning and Agentic Issue Localization"></a>TRAIL: Trace Reasoning and Agentic Issue Localization</h2><p><strong>Authors:Darshan Deshpande, Varun Gangal, Hersh Mehta, Jitin Krishnan, Anand Kannappan, Rebecca Qian</strong></p>
<p>The increasing adoption of agentic workflows across diverse domains brings a critical need to scalably and systematically evaluate the complex traces these systems generate. Current evaluation methods depend on manual, domain-specific human analysis of lengthy workflow traces - an approach that does not scale with the growing complexity and volume of agentic outputs. Error analysis in these settings is further complicated by the interplay of external tool outputs and language model reasoning, making it more challenging than traditional software debugging. In this work, we (1) articulate the need for robust and dynamic evaluation methods for agentic workflow traces, (2) introduce a formal taxonomy of error types encountered in agentic systems, and (3) present a set of 148 large human-annotated traces (TRAIL) constructed using this taxonomy and grounded in established agentic benchmarks. To ensure ecological validity, we curate traces from both single and multi-agent systems, focusing on real-world applications such as software engineering and open-world information retrieval. Our evaluations reveal that modern long context LLMs perform poorly at trace debugging, with the best Gemini-2.5-pro model scoring a mere 11% on TRAIL. Our dataset and code are made publicly available to support and accelerate future research in scalable evaluation for agentic workflows. </p>
<blockquote>
<p>随着代理工作流在各个领域中的日益普及，对可扩展且系统地评估这些系统产生的复杂轨迹的需求变得至关重要。当前的评估方法依赖于对冗长工作流轨迹进行手动、特定领域的人类分析——这种方法无法随着代理输出的复杂性和数量的增长而扩展。这些环境中的错误分析因外部工具输出和语言模型推理的相互作用而变得更加复杂，使其比传统软件调试更具挑战性。在这项工作中，我们（1）阐述了针对代理工作流轨迹的稳健和动态评估方法的必要性，（2）介绍了在代理系统中遇到错误类型的正式分类，以及（3）根据此分类和基于已建立的代理基准测试，呈现了一组由人类标注的包含大型轨迹（TRAIL）的数据集，总计包含有 148 条轨迹。为了确保生态有效性，我们从单代理系统和多代理系统中筛选轨迹，重点关注现实世界的应用，如软件工程和开放世界信息检索。我们的评估显示现代长上下文LLM在轨迹调试方面表现不佳，最佳模型Gemini-2.5 评分仅为TRAIL数据集上的 11%。我们的数据集和代码已公开提供，以支持和加速针对代理工作流的可扩展评估的未来研究。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.08638v3">PDF</a> Dataset: <a target="_blank" rel="noopener" href="https://huggingface.co/datasets/PatronusAI/TRAIL">https://huggingface.co/datasets/PatronusAI/TRAIL</a></p>
<p><strong>Summary</strong></p>
<p>该文本介绍了随着跨领域代理工作流程的增加，亟需系统评估这些系统产生的复杂痕迹。当前评估方法依赖于手动分析冗长的工作流程痕迹，这无法满足代理输出增长带来的需求。错误分析由于外部工具输出和语言模型推理的交织变得更加复杂。本文提出了对代理工作流程痕迹的稳健动态评估方法的需求，引入代理系统中遇到的错误类型正式分类，并提出基于该分类和代理基准测试构建的大型人类注释痕迹集（TRAIL）。通过现实应用如软件工程和开放世界信息检索的单代理和多代理系统的痕迹筛选，确保生态有效性。评估显示现代大型语言模型在痕迹调试方面表现不佳，最佳模型得分仅为11%。公开提供数据集和代码以支持并加速未来对代理工作流程的可扩展评估研究。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>随着代理工作流程在多个领域的广泛应用，需要系统和可扩展地评估这些系统产生的复杂痕迹。</li>
<li>当前评估方法主要依赖手动分析，无法适应代理输出的增长和复杂性。</li>
<li>错误分析在代理系统中更为复杂，涉及外部工具输出和语言模型推理的交互。</li>
<li>提出了对代理工作流程痕迹的评估需求，并引入错误类型的正式分类。</li>
<li>构建了基于分类和代理基准测试的大型人类注释痕迹集（TRAIL）。</li>
<li>数据集包含来自单代理和多代理系统的痕迹，专注于现实应用如软件工程和开放世界信息检索。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.08638">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-765e2d9d82512f3e2c971c90fdbb0a9c.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-7462c4ecedd4ce98e5f0213a4e4750ac.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-9bb85c0eb0e4c4a8f5e27ff312564ae5.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="CVE-Bench-A-Benchmark-for-AI-Agents’-Ability-to-Exploit-Real-World-Web-Application-Vulnerabilities"><a href="#CVE-Bench-A-Benchmark-for-AI-Agents’-Ability-to-Exploit-Real-World-Web-Application-Vulnerabilities" class="headerlink" title="CVE-Bench: A Benchmark for AI Agents’ Ability to Exploit Real-World Web   Application Vulnerabilities"></a>CVE-Bench: A Benchmark for AI Agents’ Ability to Exploit Real-World Web   Application Vulnerabilities</h2><p><strong>Authors:Yuxuan Zhu, Antony Kellermann, Dylan Bowman, Philip Li, Akul Gupta, Adarsh Danda, Richard Fang, Conner Jensen, Eric Ihli, Jason Benn, Jet Geronimo, Avi Dhir, Sudhit Rao, Kaicheng Yu, Twm Stone, Daniel Kang</strong></p>
<p>Large language model (LLM) agents are increasingly capable of autonomously conducting cyberattacks, posing significant threats to existing applications. This growing risk highlights the urgent need for a real-world benchmark to evaluate the ability of LLM agents to exploit web application vulnerabilities. However, existing benchmarks fall short as they are limited to abstracted Capture the Flag competitions or lack comprehensive coverage. Building a benchmark for real-world vulnerabilities involves both specialized expertise to reproduce exploits and a systematic approach to evaluating unpredictable threats. To address this challenge, we introduce CVE-Bench, a real-world cybersecurity benchmark based on critical-severity Common Vulnerabilities and Exposures. In CVE-Bench, we design a sandbox framework that enables LLM agents to exploit vulnerable web applications in scenarios that mimic real-world conditions, while also providing effective evaluation of their exploits. Our evaluation shows that the state-of-the-art agent framework can resolve up to 13% of vulnerabilities. </p>
<blockquote>
<p>大型语言模型（LLM）代理能够越来越自主地开展网络攻击，对现有应用构成重大威胁。这种日益增长的风险突显了现实世界基准测试评估LLM代理利用网页应用漏洞能力的迫切需求。然而，现有基准测试未能满足需求，因为它们仅限于抽象的夺旗竞赛，或者缺乏全面覆盖。构建针对现实世界漏洞的基准测试需要专业化的专业知识来重现漏洞以及系统的方法来评估不可预测的威胁。为了解决这一挑战，我们引入了CVE基准测试（CVE-Bench），这是一个基于关键严重性常见漏洞和暴露的网络安全现实基准测试。在CVE基准测试中，我们设计了一个沙箱框架，使LLM代理能够在模拟现实条件的场景中利用易受攻击的网页应用，同时有效地评估其漏洞利用情况。我们的评估显示，最先进的代理框架可以解决高达百分之十三的漏洞。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.17332v4">PDF</a> 15 pages, 4 figures, 5 tables</p>
<p><strong>Summary</strong></p>
<p>大型语言模型（LLM）代理具备自主开展网络攻击的能力，对现有应用构成重大威胁。当前缺乏一个现实世界基准来评估LLM代理利用Web应用程序漏洞的能力，导致这一风险日益凸显。为解决这一挑战，本文提出CVE-Bench，一个基于关键严重性常见漏洞和暴露的网络安全现实基准。CVE-Bench设计了一个沙箱框架，使LLM代理能够在模拟现实条件的场景中利用易受攻击的Web应用程序，同时有效评估其漏洞利用情况。评估显示，当前最先进的代理框架可以解决高达13%的漏洞。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>大型语言模型（LLM）代理具备自主网络攻击能力。</li>
<li>LLM代理对现有的应用程序构成了重大威胁。</li>
<li>当前缺乏一个现实世界基准来评估LLM代理利用Web应用程序漏洞的能力。</li>
<li>CVE-Bench是一个基于关键严重性常见漏洞和暴露的网络安全现实基准。</li>
<li>CVE-Bench设计了一个沙箱框架，以模拟现实环境中的场景来评估LLM代理对Web应用程序的攻击能力。</li>
<li>现有最先进的代理框架可以解决高达13%的漏洞。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.17332">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-7abf9352c083e7177ae4c523ad1e66ab.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a2c6bfe2ef1da3f1424472977797cdcf.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b265418d83bc57742b57caa2c1d446bc.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-752ab4f432f20447483bd54441ebcbaf.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-01aea1cec18b498b484f5c55739bc109.jpg" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        文章作者:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        文章链接:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-06-26/Agent/">https://kedreamix.github.io/Talk2Paper/Paper/2025-06-26/Agent/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        版权声明:
                    </i>
                </span>
                <span class="reprint-info">
                    本博客所有文章除特別声明外，均采用
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    许可协议。转载请注明来源
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/Agent/">
                                    <span class="chip bg-color">Agent</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;上一篇</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-06-26/MMT/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-c3b1de4600da704bc6e504563c96f6b9.jpg" class="responsive-img" alt="MMT">
                        
                        <span class="card-title">MMT</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            MMT 方向最新论文已更新，请持续关注 Update in 2025-06-26  Impact of Visual Context on Noisy Multimodal NMT An Empirical Study for   English to Indian Languages
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-06-26
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/MMT/" class="post-category">
                                    MMT
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/MMT/">
                        <span class="chip bg-color">MMT</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-06-26/LLM/">
                    <div class="card-image">
                        
                        <img src="https://pic1.zhimg.com/v2-fe150bde0113af265eac13e528652ce5.jpg" class="responsive-img" alt="LLM">
                        
                        <span class="card-title">LLM</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            LLM 方向最新论文已更新，请持续关注 Update in 2025-06-26  MAM Modular Multi-Agent Framework for Multi-Modal Medical Diagnosis via   Role-Specialized Collaboration
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-06-26
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/LLM/" class="post-category">
                                    LLM
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/LLM/">
                        <span class="chip bg-color">LLM</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- 代码语言 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span
                        class="white-color">29301k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- 运行天数提醒. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // 区分是否有年份.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = '本站已运行 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                daysTip = '本站已運行 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = '本站已运行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = '本站已運行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="关注我的知乎: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">知</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- 白天和黑夜主题 -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // 只在桌面版网页启用特效
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- 雪花特效 -->
    

    <!-- 鼠标星星特效 -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--腾讯兔小巢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- 动态标签 -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Σ(っ °Д °;)っ诶，页面崩溃了嘛？", clearTimeout(st)) : (document.title = "φ(゜▽゜*)♪咦，又好了！", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
