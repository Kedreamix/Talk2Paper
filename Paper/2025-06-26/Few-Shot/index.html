<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Few-Shot">
    <meta name="description" content="Few-Shot 方向最新论文已更新，请持续关注 Update in 2025-06-26  UltraAD Fine-Grained Ultrasound Anomaly Classification via Few-Shot   CLIP Adaptation">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>Few-Shot | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loader页面消失采用渐隐的方式*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logo出现动画 */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//使用渐隐的方法淡出loading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//强制显示loading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">嘘~  正在从服务器偷取页面 . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>首页</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>标签</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>分类</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>归档</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="搜索" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="深色/浅色模式" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			首页
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			标签
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			分类
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			归档
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://picx.zhimg.com/v2-f187459b97356a43ee42829244f71039.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Few-Shot</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/Few-Shot/">
                                <span class="chip bg-color">Few-Shot</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/Few-Shot/" class="post-category">
                                Few-Shot
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2025-06-26
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>更新日期:&nbsp;&nbsp;
                    2025-07-06
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp;
                    6.2k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp;
                    25 分
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>阅读次数:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>⚠️ 以下所有内容总结都来自于 大语言模型的能力，如有错误，仅供参考，谨慎使用<br>🔴 请注意：千万不要用于严肃的学术场景，只能用于论文阅读前的初筛！<br>💗 如果您觉得我们的项目对您有帮助 <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ，还请您给我们一些鼓励！⭐️ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFace免费体验</a></p>
</blockquote>
<h1 id="2025-06-26-更新"><a href="#2025-06-26-更新" class="headerlink" title="2025-06-26 更新"></a>2025-06-26 更新</h1><h2 id="UltraAD-Fine-Grained-Ultrasound-Anomaly-Classification-via-Few-Shot-CLIP-Adaptation"><a href="#UltraAD-Fine-Grained-Ultrasound-Anomaly-Classification-via-Few-Shot-CLIP-Adaptation" class="headerlink" title="UltraAD: Fine-Grained Ultrasound Anomaly Classification via Few-Shot   CLIP Adaptation"></a>UltraAD: Fine-Grained Ultrasound Anomaly Classification via Few-Shot   CLIP Adaptation</h2><p><strong>Authors:Yue Zhou, Yuan Bi, Wenjuan Tong, Wei Wang, Nassir Navab, Zhongliang Jiang</strong></p>
<p>Precise anomaly detection in medical images is critical for clinical decision-making. While recent unsupervised or semi-supervised anomaly detection methods trained on large-scale normal data show promising results, they lack fine-grained differentiation, such as benign vs. malignant tumors. Additionally, ultrasound (US) imaging is highly sensitive to devices and acquisition parameter variations, creating significant domain gaps in the resulting US images. To address these challenges, we propose UltraAD, a vision-language model (VLM)-based approach that leverages few-shot US examples for generalized anomaly localization and fine-grained classification. To enhance localization performance, the image-level token of query visual prototypes is first fused with learnable text embeddings. This image-informed prompt feature is then further integrated with patch-level tokens, refining local representations for improved accuracy. For fine-grained classification, a memory bank is constructed from few-shot image samples and corresponding text descriptions that capture anatomical and abnormality-specific features. During training, the stored text embeddings remain frozen, while image features are adapted to better align with medical data. UltraAD has been extensively evaluated on three breast US datasets, outperforming state-of-the-art methods in both lesion localization and fine-grained medical classification. The code will be released upon acceptance. </p>
<blockquote>
<p>精确医学图像异常检测对于临床决策至关重要。虽然最近基于大规模正常数据的无监督或半监督异常检测方法显示出有前景的结果，但它们缺乏精细的区分，如良性与恶性肿瘤等。此外，超声（US）成像对设备和采集参数的变化高度敏感，导致超声图像存在显著的域差异。为了解决这些挑战，我们提出了UltraAD，一种基于视觉语言模型（VLM）的方法，利用少量超声图像例子进行通用异常定位和精细分类。为了提高定位性能，首先融合查询视觉原型的图像级令牌和可学习的文本嵌入。然后，将图像信息提示特征与补丁级令牌进一步集成，以细化局部表示并提高准确性。对于精细分类，从少量图像样本和相应的文本描述中构建了一个内存银行，以捕获解剖结构和异常特定的特征。在训练过程中，存储的文本嵌入保持不变，而图像特征更好地适应医学数据。UltraAD在三个乳腺超声数据集上进行了广泛评估，在病灶定位和精细医学分类方面都优于最新方法。代码将在接受后发布。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.19694v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>本文介绍了医疗图像精准异常检测的重要性，针对现有方法缺乏精细粒度区分（如良性与恶性肿瘤）以及超声成像中的设备与采集参数变化带来的领域差距问题，提出了基于视觉语言模型的UltraAD方法。该方法利用少量超声图像样本进行通用异常定位和精细粒度分类。通过融合图像级令牌与可学习文本嵌入，提高定位性能。同时，利用记忆库存储少量图像样本及其文本描述，进行精细粒度分类。在三个乳腺超声数据集上的评估表明，UltraAD在病灶定位与精细粒度医学分类方面均优于现有方法。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>医疗图像精准异常检测对临床决策至关重要。</li>
<li>现有方法缺乏精细粒度区分，如良性与恶性肿瘤的区分。</li>
<li>UltraAD方法基于视觉语言模型，利用少量超声图像样本进行通用异常定位和精细粒度分类。</li>
<li>UltraAD通过融合图像级令牌与可学习文本嵌入提高定位性能。</li>
<li>利用记忆库存储图像样本及其文本描述，进行精细粒度分类。</li>
<li>UltraAD在病灶定位与精细粒度医学分类方面均表现出优异性能。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.19694">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-9228d5cad6de18bc5dfc422f865ea5d6.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-3a7d1ed8f49296903372cbc391abecf4.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-194586963cfb90b18014120ac78c2ba0.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="Correcting-Hallucinations-in-News-Summaries-Exploration-of-Self-Correcting-LLM-Methods-with-External-Knowledge"><a href="#Correcting-Hallucinations-in-News-Summaries-Exploration-of-Self-Correcting-LLM-Methods-with-External-Knowledge" class="headerlink" title="Correcting Hallucinations in News Summaries: Exploration of   Self-Correcting LLM Methods with External Knowledge"></a>Correcting Hallucinations in News Summaries: Exploration of   Self-Correcting LLM Methods with External Knowledge</h2><p><strong>Authors:Juraj Vladika, Ihsan Soydemir, Florian Matthes</strong></p>
<p>While large language models (LLMs) have shown remarkable capabilities to generate coherent text, they suffer from the issue of hallucinations – factually inaccurate statements. Among numerous approaches to tackle hallucinations, especially promising are the self-correcting methods. They leverage the multi-turn nature of LLMs to iteratively generate verification questions inquiring additional evidence, answer them with internal or external knowledge, and use that to refine the original response with the new corrections. These methods have been explored for encyclopedic generation, but less so for domains like news summarization. In this work, we investigate two state-of-the-art self-correcting systems by applying them to correct hallucinated summaries using evidence from three search engines. We analyze the results and provide insights into systems’ performance, revealing interesting practical findings on the benefits of search engine snippets and few-shot prompts, as well as high alignment of G-Eval and human evaluation. </p>
<blockquote>
<p>虽然大型语言模型（LLM）在生成连贯文本方面表现出了显著的能力，但它们存在虚构问题，即事实上不准确的说法。在解决虚构问题的众多方法中，特别有前景的是自我校正方法。它们利用LLM的多轮对话性质来生成验证问题，询问额外的证据，用内部或外部知识回答问题，并利用这些新修正来完善原始回答。这些方法在百科全书生成方面已被探索过，但在新闻摘要等领域则较少探索。在这项工作中，我们通过将两种最先进的自我校正系统应用于使用来自三个搜索引擎的证据来纠正虚构摘要，从而进行研究。我们分析了结果，并深入了解了系统的性能，揭示了关于搜索引擎片段和少量提示的实际好处的一些有趣发现，以及G-Eval与人类评估的高度一致性。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.19607v1">PDF</a> Accepted to FEVER @ ACL 2025</p>
<p><strong>Summary</strong>：<br>大型语言模型在生成连贯文本方面表现出显著的能力，但它们存在事实不准确的问题。自我校正方法通过利用LLM的多轮特性生成验证问题、寻找额外证据来回答问题，并使用这些来修正原始响应。尽管这些方法在百科全书生成方面得到了探索，但在新闻摘要等领域的应用较少。本研究将两种先进的自我校正系统应用于纠正因幻觉产生的摘要，并利用来自三个搜索引擎的证据。我们分析了结果，并深入了解了系统的性能，发现了搜索引擎片段和少量提示的实用优势，以及G-Eval与人类评价的极高一致性。</p>
<p><strong>Key Takeaways</strong>:</p>
<ol>
<li>大型语言模型虽然能生成连贯文本，但存在事实不准确的问题，即“幻觉”。</li>
<li>自我校正方法通过生成验证问题、寻找额外证据来修正原始响应，是解决幻觉问题的有前途的方法。</li>
<li>自我校正方法在百科全书生成方面得到了探索，但在新闻摘要等领域的应用较少。</li>
<li>研究中，两种先进的自我校正系统被应用于纠正因幻觉产生的摘要。</li>
<li>利用来自三个搜索引擎的证据来提高校正效果。</li>
<li>分析结果显示搜索引擎片段和少量提示具有实用优势。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.19607">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-ccc9b3f30c78599e189ed6d6ad3f005b.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-ebb00fb259ad16d30775f3c5b19a3ded.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b94e569fee22090b23f31b24a4c9a8bb.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="FAF-A-Feature-Adaptive-Framework-for-Few-Shot-Time-Series-Forecasting"><a href="#FAF-A-Feature-Adaptive-Framework-for-Few-Shot-Time-Series-Forecasting" class="headerlink" title="FAF: A Feature-Adaptive Framework for Few-Shot Time Series Forecasting"></a>FAF: A Feature-Adaptive Framework for Few-Shot Time Series Forecasting</h2><p><strong>Authors:Pengpeng Ouyang, Dong Chen, Tong Yang, Shuo Feng, Zhao Jin, Mingliang Xu</strong></p>
<p>Multi-task and few-shot time series forecasting tasks are commonly encountered in scenarios such as the launch of new products in different cities. However, traditional time series forecasting methods suffer from insufficient historical data, which stems from a disregard for the generalized and specific features among different tasks. For the aforementioned challenges, we propose the Feature-Adaptive Time Series Forecasting Framework (FAF), which consists of three key components: the Generalized Knowledge Module (GKM), the Task-Specific Module (TSM), and the Rank Module (RM). During training phase, the GKM is updated through a meta-learning mechanism that enables the model to extract generalized features across related tasks. Meanwhile, the TSM is trained to capture diverse local dynamics through multiple functional regions, each of which learns specific features from individual tasks. During testing phase, the RM dynamically selects the most relevant functional region from the TSM based on input sequence features, which is then combined with the generalized knowledge learned by the GKM to generate accurate forecasts. This design enables FAF to achieve robust and personalized forecasting even with sparse historical observations We evaluate FAF on five diverse real-world datasets under few-shot time series forecasting settings. Experimental results demonstrate that FAF consistently outperforms baselines that include three categories of time series forecasting methods. In particular, FAF achieves a 41.81% improvement over the best baseline, iTransformer, on the CO$_2$ emissions dataset. </p>
<blockquote>
<p>多任务与少样本时间序列预测任务在诸如不同城市推出新产品等场景中经常遇到。然而，传统的时间序列预测方法面临历史数据不足的问题，这源于它们忽视了不同任务之间的通用和特定特征。针对上述挑战，我们提出了特征自适应时间序列预测框架（FAF），它包括三个关键组件：通用知识模块（GKM）、任务特定模块（TSM）和排名模块（RM）。在训练阶段，GKM通过元学习机制进行更新，使模型能够在相关任务中提取通用特征。同时，TSM经过训练，通过多个功能区域捕捉不同的局部动态，每个功能区域都从单个任务中学习特定特征。在测试阶段，RM根据输入序列特征动态选择最相关的功能区域，然后将其与GKM中学习的通用知识相结合，生成准确的预测。这种设计使FAF即使在稀疏的历史观测下也能实现稳健和个性化的预测。我们在五个不同的真实数据集上评估了FAF在少样本时间序列预测设置下的表现。实验结果表明，FAF持续优于包括三类时间序列预测方法在内的基线模型。特别地，FAF在二氧化碳排放数据集上相较于最佳基线模型iTransformer实现了41.81%的改进。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.19567v1">PDF</a> 12 pages,4 figures, 8 tables</p>
<p><strong>Summary</strong></p>
<p>在推出新产品于不同城市的情境中，经常遇到多任务与少样本时间序列预测任务。传统的时间序列预测方法因缺乏历史数据而受限，忽视了不同任务间的通用和特定特征。为应对这些挑战，我们提出了特征自适应时间序列预测框架（FAF），包含三个关键组件：通用知识模块（GKM）、任务特定模块（TSM）和排名模块（RM）。在训练阶段，GKM通过元学习机制更新，使模型能够提取相关任务间的通用特征。TSM则训练以捕捉不同功能区域的局部动态，每个区域从个别任务中学习特定特征。在测试阶段，RM根据输入序列特征动态选择最相关的功能区域，并与GKM学到的通用知识结合，生成准确预测。即使历史观测数据稀疏，这种设计也使FAF能够实现稳健和个性化的预测。在五个真实世界数据集上进行少样本时间序列预测设置评估，实验结果表明，FAF持续优于基线，特别是在二氧化碳排放数据集上，相对于最佳基线iTransformer，FAF实现了41.81%的改进。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>多任务与少样本时间序列预测在实际场景中很常见，特别是在新产品在不同城市的推广过程中。</li>
<li>传统的时间序列预测方法存在对历史数据不足的问题，这主要源于它们忽视了不同任务之间的通用和特定特征。</li>
<li>提出的特征自适应时间序列预测框架（FAF）包括三个核心组件：用于提取通用特征的广义知识模块（GKM），用于捕捉特定任务的特定特征的任务特定模块（TSM），以及根据输入选择相关功能的排名模块（RM）。</li>
<li>在训练阶段，FAF通过元学习更新GKM，并训练TSM以捕捉不同功能区域的局部动态。</li>
<li>在测试阶段，RM动态选择功能区域，结合GKM的通用知识做出预测。</li>
<li>FAF框架对于历史数据稀疏的情况依然有效，能够实现稳健和个性化的预测。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.19567">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-76d0d962eef76659dfbf782f067a028e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-8c1ff9a9b78cf333103607ae57db9df3.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-200464aedb8859b8e99b98ab62679137.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="ConCM-Consistency-Driven-Calibration-and-Matching-for-Few-Shot-Class-Incremental-Learning"><a href="#ConCM-Consistency-Driven-Calibration-and-Matching-for-Few-Shot-Class-Incremental-Learning" class="headerlink" title="ConCM: Consistency-Driven Calibration and Matching for Few-Shot   Class-Incremental Learning"></a>ConCM: Consistency-Driven Calibration and Matching for Few-Shot   Class-Incremental Learning</h2><p><strong>Authors:QinZhe Wang, Zixuan Chen, Keke Huang, Xiu Su, Chunhua Yang, Chang Xu</strong></p>
<p>Few-Shot Class-Incremental Learning (FSCIL) requires models to adapt to novel classes with limited supervision while preserving learned knowledge. Existing prospective learning-based space construction methods reserve space to accommodate novel classes. However, prototype deviation and structure fixity limit the expressiveness of the embedding space. In contrast to fixed space reservation, we explore the optimization of feature-structure dual consistency and propose a Consistency-driven Calibration and Matching Framework (ConCM) that systematically mitigate the knowledge conflict inherent in FSCIL. Specifically, inspired by hippocampal associative memory, we design a memory-aware prototype calibration that extracts generalized semantic attributes from base classes and reintegrates them into novel classes to enhance the conceptual center consistency of features. Further, we propose dynamic structure matching, which adaptively aligns the calibrated features to a session-specific optimal manifold space, ensuring cross-session structure consistency. Theoretical analysis shows that our method satisfies both geometric optimality and maximum matching, thereby overcoming the need for class-number priors. On large-scale FSCIL benchmarks including mini-ImageNet and CUB200, ConCM achieves state-of-the-art performance, surpassing current optimal method by 3.20% and 3.68% in harmonic accuracy of incremental sessions. </p>
<blockquote>
<p>少量类别增量学习（FSCIL）要求模型在有限监督下适应新类别，同时保留已学习的知识。现有的基于前瞻性学习空间构建的方法保留空间来容纳新类别。然而，原型偏差和结构固定性限制了嵌入空间的表达能力。与固定空间预留相反，我们探索特征结构双重一致性的优化，并提出一种一致性驱动校准和匹配框架（ConCM），系统地减轻FSCIL中固有的知识冲突。具体来说，受到海马体关联记忆的启发，我们设计了一种记忆感知原型校准，从基础类别中提取通用语义属性，并将其重新整合到新类别中，以增强特征的概念中心一致性。此外，我们提出了动态结构匹配，自适应地将校准后的特征对齐到会话特定的最优流形空间，确保跨会话结构一致性。理论分析表明，我们的方法满足几何最优性和最大匹配度，从而不需要类别数量先验。在包括mini-ImageNet和CUB200的大规模FSCIL基准测试中，ConCM实现了最先进的性能，在增量会话的调和准确性上分别比当前最优方法高出3.20%和3.68%。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.19558v1">PDF</a> 9 pages, 5 figures(Excluding the appendix)</p>
<p><strong>Summary</strong></p>
<p>本文探讨了Few-Shot类增量学习（FSCIL）中的嵌入空间构建方法的问题。现有方法主要通过固定空间预留来适应新类，但存在原型偏差和结构固定性，限制了表达性。本文提出了一个一致性驱动校准和匹配框架（ConCM），通过优化特征结构一致性来解决FSCIL中的知识冲突问题。该框架包含记忆感知原型校准和动态结构匹配，分别在特征的概念中心一致性和跨会话结构一致性上实现优化。在大型FSCIL基准测试上，ConCM实现了最先进的性能，超越了当前最优方法。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>Few-Shot类增量学习（FSCIL）要求模型在有限监督下适应新类，同时保留已学习知识。</li>
<li>现有基于空间的构建方法主要通过固定空间预留来适应新类，但存在原型偏差和结构固定性的限制。</li>
<li>ConCM框架通过优化特征结构一致性来解决FSCIL中的知识冲突问题。</li>
<li>ConCM包含记忆感知原型校准，从基础类中提取广义语义属性并重新集成到新类中，以增强特征的概念中心一致性。</li>
<li>动态结构匹配技术被提出，以自适应地对齐校准特征到会话特定的最优流形空间，确保跨会话的结构一致性。</li>
<li>ConCM在大型FSCIL基准测试上实现了最先进的性能。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.19558">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-52a375ccd2d588804322c7e301eba872.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-65e2d5b4ecfcc0ba68cd69536bd0f2c7.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-7bcad7994f2e05229684512d69feacc4.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-9e5e95a406b1d45e16625a59327ce577.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="General-Methods-Make-Great-Domain-specific-Foundation-Models-A-Case-study-on-Fetal-Ultrasound"><a href="#General-Methods-Make-Great-Domain-specific-Foundation-Models-A-Case-study-on-Fetal-Ultrasound" class="headerlink" title="General Methods Make Great Domain-specific Foundation Models: A   Case-study on Fetal Ultrasound"></a>General Methods Make Great Domain-specific Foundation Models: A   Case-study on Fetal Ultrasound</h2><p><strong>Authors:Jakob Ambsdorf, Asbjørn Munk, Sebastian Llambias, Anders Nymark Christensen, Kamil Mikolaj, Randall Balestriero, Martin Tolsgaard, Aasa Feragen, Mads Nielsen</strong></p>
<p>With access to large-scale, unlabeled medical datasets, researchers are confronted with two questions: Should they attempt to pretrain a custom foundation model on this medical data, or use transfer-learning from an existing generalist model? And, if a custom model is pretrained, are novel methods required? In this paper we explore these questions by conducting a case-study, in which we train a foundation model on a large regional fetal ultrasound dataset of 2M images. By selecting the well-established DINOv2 method for pretraining, we achieve state-of-the-art results on three fetal ultrasound datasets, covering data from different countries, classification, segmentation, and few-shot tasks. We compare against a series of models pretrained on natural images, ultrasound images, and supervised baselines. Our results demonstrate two key insights: (i) Pretraining on custom data is worth it, even if smaller models are trained on less data, as scaling in natural image pretraining does not translate to ultrasound performance. (ii) Well-tuned methods from computer vision are making it feasible to train custom foundation models for a given medical domain, requiring no hyperparameter tuning and little methodological adaptation. Given these findings, we argue that a bias towards methodological innovation should be avoided when developing domain specific foundation models under common computational resource constraints. </p>
<blockquote>
<p>在面对大规模的无标签医疗数据集时，研究人员面临两个问题：他们是否应该尝试在此医疗数据上预训练一个自定义基础模型，还是使用从现有通用模型进行迁移学习？如果预训练了自定义模型，是否需要新颖的方法？在本文中，我们通过进行案例研究来探讨这些问题。我们在一个包含2百万图像的大规模区域性胎儿超声数据集上训练了一个基础模型。通过选择成熟的DINOv2方法进行预训练，我们在三个胎儿超声数据集上实现了最新结果，这些数据集涵盖了不同国家的数据、分类、分割和少量任务。我们将预训练在自然图像、超声图像上的模型以及与监督基准模型进行了一系列比较。我们的结果证明了两个关键见解：(i)即使在较少的数据上训练较小的模型，对自定义数据进行预训练也是值得的，因为自然图像预训练的扩展并不等同于超声性能。(ii)经过良好调整的计算视觉方法使得训练针对给定医疗领域的自定义基础模型成为可能，无需调整超参数和少量的方法论适应。根据这些发现，我们认为在开发特定领域的模型时，应尽量避免倾向于方法创新的偏见，尤其是在常见的计算资源约束下。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.19552v1">PDF</a> Submitted version of paper accepted at MICCAI 2025</p>
<p><strong>Summary</strong></p>
<p>大型无标签医学数据集的使用面临选择：是尝试预训练一个定制的基础模型，还是使用从现有通用模型进行的迁移学习？本文通过一个案例研究探讨了这些问题。我们在一个包含2百万张胎儿超声图像的大型区域超声数据集上训练了一个基础模型，并使用成熟的DINOv2预训练技术取得了最先进的成果。我们的研究结果显示，针对特定医学领域的定制基础模型预训练是值得的，即使使用较小的模型处理较少的数据。此外，计算机视觉领域的良好调整方法使得训练针对特定医学领域的定制基础模型成为可能，无需进行超参数调整和方法轻微调整。因此，在开发特定领域的基础模型时，应避免偏向方法创新的倾向。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>面对大型无标签医学数据集，应探讨是否预训练定制基础模型或采用迁移学习。</li>
<li>在胎儿超声数据集上预训练的定制基础模型取得了先进成果。</li>
<li>预训练在特定医学领域值得投入，即使处理数据量和模型规模相对较小。</li>
<li>自然图像预训练的可扩展性并不等同于超声性能的提升。</li>
<li>计算机视觉领域的方法使得训练特定医学领域的定制基础模型成为可能。</li>
<li>训练这样的模型无需大量超参数调整和方法适应。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.19552">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-3e62c6ee38cc8295c946d79104144a2d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f187459b97356a43ee42829244f71039.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-c97adca598dc8ee954f72c7289c06656.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c15499e903613e58b2484c581e68a730.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="FineCLIPER-Multi-modal-Fine-grained-CLIP-for-Dynamic-Facial-Expression-Recognition-with-AdaptERs"><a href="#FineCLIPER-Multi-modal-Fine-grained-CLIP-for-Dynamic-Facial-Expression-Recognition-with-AdaptERs" class="headerlink" title="FineCLIPER: Multi-modal Fine-grained CLIP for Dynamic Facial Expression   Recognition with AdaptERs"></a>FineCLIPER: Multi-modal Fine-grained CLIP for Dynamic Facial Expression   Recognition with AdaptERs</h2><p><strong>Authors:Haodong Chen, Haojian Huang, Junhao Dong, Mingzhe Zheng, Dian Shao</strong></p>
<p>Dynamic Facial Expression Recognition (DFER) is crucial for understanding human behavior. However, current methods exhibit limited performance mainly due to the scarcity of high-quality data, the insufficient utilization of facial dynamics, and the ambiguity of expression semantics, etc. To this end, we propose a novel framework, named Multi-modal Fine-grained CLIP for Dynamic Facial Expression Recognition with AdaptERs (FineCLIPER), incorporating the following novel designs: 1) To better distinguish between similar facial expressions, we extend the class labels to textual descriptions from both positive and negative aspects, and obtain supervision by calculating the cross-modal similarity based on the CLIP model; 2) Our FineCLIPER adopts a hierarchical manner to effectively mine useful cues from DFE videos. Specifically, besides directly embedding video frames as input (low semantic level), we propose to extract the face segmentation masks and landmarks based on each frame (middle semantic level) and utilize the Multi-modal Large Language Model (MLLM) to further generate detailed descriptions of facial changes across frames with designed prompts (high semantic level). Additionally, we also adopt Parameter-Efficient Fine-Tuning (PEFT) to enable efficient adaptation of large pre-trained models (i.e., CLIP) for this task. Our FineCLIPER achieves SOTA performance on the DFEW, FERV39k, and MAFW datasets in both supervised and zero-shot settings with few tunable parameters. Project Page: <a target="_blank" rel="noopener" href="https://haroldchen19.github.io/FineCLIPER-Page/">https://haroldchen19.github.io/FineCLIPER-Page/</a> </p>
<blockquote>
<p>动态面部表情识别（DFER）对于理解人类行为至关重要。然而，当前的方法表现有限，主要是由于高质量数据的稀缺、面部动态利用不足以及表达语义的模糊等原因。为此，我们提出了一种名为Multi-modal Fine-grained CLIP for Dynamic Facial Expression Recognition with AdaptERs（FineCLIPER）的新型框架，并融入了以下新颖设计：1）为了更好地区分相似的面部表情，我们将类别标签扩展到正面和负面方面的文本描述，并通过基于CLIP模型的跨模态相似性计算来获得监督；2）我们的FineCLIPER采用分层方式，有效地从DFE视频中挖掘有用线索。具体来说，除了直接将视频帧嵌入作为输入（低语义级别）外，我们还提议基于每帧提取面部分割掩码和地标（中级语义级别），并利用多模态大型语言模型（MLLM）来进一步生成跨帧面部变化的详细描述（高级语义级别）。此外，我们还采用参数高效微调（PEFT）技术，使大型预训练模型（例如CLIP）能够高效适应此任务。我们的FineCLIPER在DFEW、FERV39k和MAFW数据集上实现了监督学习和零样本设置下的最佳性能，并且只需要调整很少的参。项目页面：<a target="_blank" rel="noopener" href="https://haroldchen19.github.io/FineCLIPER-Page/">https://haroldchen19.github.io/FineCLIPER-Page/</a></p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2407.02157v3">PDF</a> Accepted to ACM MM 2024</p>
<p><strong>Summary</strong>：基于多模态精细粒度CLIP模型的动态面部表情识别新方法FineCLIPER，通过结合跨模态相似性进行标签扩展，并采用层次化方式挖掘DFE视频中的有用线索，实现面部表情识别的优异性能。同时，通过参数高效微调技术适应大型预训练模型，可在监督学习和零样本设置下实现SOTA性能。</p>
<p><strong>Key Takeaways</strong>：</p>
<ol>
<li>动态面部表情识别（DFER）对于理解人类行为至关重要。</li>
<li>当前方法性能受限，主要由于高质量数据稀缺、面部动态利用不足和表情语义模糊等原因。</li>
<li>FineCLIPER框架通过结合多模态信息提高DFER性能。</li>
<li>采用标签扩展方法，通过计算跨模态相似性进行正面和负面方面的文本描述监督。</li>
<li>FineCLIPER采用层次化方式挖掘DFE视频中的有用线索，包括直接嵌入视频帧、提取面部分割掩膜和地标，以及利用多模态大型语言模型生成面部变化详细描述。</li>
<li>采用参数高效微调（PEFT）技术，使大型预训练模型适应此任务。</li>
<li>FineCLIPER在DFEW、FERV39k和MAFW数据集上实现监督学习和零样本设置下的SOTA性能。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2407.02157">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-901cf3ca4f8b16d6b07ef5f32ce61537.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a55b7d603f224d527cb35177c32463bd.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-10bdce68bc89a8a500462f232994c2a0.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-92376192f54ea866a516cf0a450f15ca.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-82fd615a2ca8dd507ccbf4bd07463a7d.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-1d8fb774ed91338ff406202a04ad71ea.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        文章作者:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        文章链接:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-06-26/Few-Shot/">https://kedreamix.github.io/Talk2Paper/Paper/2025-06-26/Few-Shot/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        版权声明:
                    </i>
                </span>
                <span class="reprint-info">
                    本博客所有文章除特別声明外，均采用
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    许可协议。转载请注明来源
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/Few-Shot/">
                                    <span class="chip bg-color">Few-Shot</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;上一篇</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-06-26/I2I%20Translation/">
                    <div class="card-image">
                        
                        <img src="https://pica.zhimg.com/v2-c15499e903613e58b2484c581e68a730.jpg" class="responsive-img" alt="I2I Translation">
                        
                        <span class="card-title">I2I Translation</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            I2I Translation 方向最新论文已更新，请持续关注 Update in 2025-06-26  General Methods Make Great Domain-specific Foundation Models A   Case-study on Fetal Ultrasound
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-06-26
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/I2I-Translation/" class="post-category">
                                    I2I Translation
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/I2I-Translation/">
                        <span class="chip bg-color">I2I Translation</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-06-26/MMT/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-c3b1de4600da704bc6e504563c96f6b9.jpg" class="responsive-img" alt="MMT">
                        
                        <span class="card-title">MMT</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            MMT 方向最新论文已更新，请持续关注 Update in 2025-06-26  Impact of Visual Context on Noisy Multimodal NMT An Empirical Study for   English to Indian Languages
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-06-26
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/MMT/" class="post-category">
                                    MMT
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/MMT/">
                        <span class="chip bg-color">MMT</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- 代码语言 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span
                        class="white-color">27348.8k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- 运行天数提醒. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // 区分是否有年份.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = '本站已运行 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                daysTip = '本站已運行 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = '本站已运行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = '本站已運行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="关注我的知乎: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">知</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- 白天和黑夜主题 -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // 只在桌面版网页启用特效
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- 雪花特效 -->
    

    <!-- 鼠标星星特效 -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--腾讯兔小巢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- 动态标签 -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Σ(っ °Д °;)っ诶，页面崩溃了嘛？", clearTimeout(st)) : (document.title = "φ(゜▽゜*)♪咦，又好了！", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
