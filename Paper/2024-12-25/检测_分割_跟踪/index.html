<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="æ£€æµ‹/åˆ†å‰²/è·Ÿè¸ª">
    <meta name="description" content="æ£€æµ‹/åˆ†å‰²/è·Ÿè¸ª æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2024-12-25  AFANet Adaptive Frequency-Aware Network for Weakly-Supervised Few-Shot   Semantic Segmentation">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>æ£€æµ‹/åˆ†å‰²/è·Ÿè¸ª | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://pica.zhimg.com/v2-a5aeb105f8d135e7b875ae4d8798eea5.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">æ£€æµ‹/åˆ†å‰²/è·Ÿè¸ª</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/%E6%A3%80%E6%B5%8B-%E5%88%86%E5%89%B2-%E8%B7%9F%E8%B8%AA/">
                                <span class="chip bg-color">æ£€æµ‹/åˆ†å‰²/è·Ÿè¸ª</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/%E6%A3%80%E6%B5%8B-%E5%88%86%E5%89%B2-%E8%B7%9F%E8%B8%AA/" class="post-category">
                                æ£€æµ‹/åˆ†å‰²/è·Ÿè¸ª
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2024-12-25
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2024-12-25
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    6.2k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    25 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2024-12-25-æ›´æ–°"><a href="#2024-12-25-æ›´æ–°" class="headerlink" title="2024-12-25 æ›´æ–°"></a>2024-12-25 æ›´æ–°</h1><h2 id="AFANet-Adaptive-Frequency-Aware-Network-for-Weakly-Supervised-Few-Shot-Semantic-Segmentation"><a href="#AFANet-Adaptive-Frequency-Aware-Network-for-Weakly-Supervised-Few-Shot-Semantic-Segmentation" class="headerlink" title="AFANet: Adaptive Frequency-Aware Network for Weakly-Supervised Few-Shot   Semantic Segmentation"></a>AFANet: Adaptive Frequency-Aware Network for Weakly-Supervised Few-Shot   Semantic Segmentation</h2><p><strong>Authors:Jiaqi Ma, Guo-Sen Xie, Fang Zhao, Zechao Li</strong></p>
<p>Few-shot learning aims to recognize novel concepts by leveraging prior knowledge learned from a few samples. However, for visually intensive tasks such as few-shot semantic segmentation, pixel-level annotations are time-consuming and costly. Therefore, in this paper, we utilize the more challenging image-level annotations and propose an adaptive frequency-aware network (AFANet) for weakly-supervised few-shot semantic segmentation (WFSS). Specifically, we first propose a cross-granularity frequency-aware module (CFM) that decouples RGB images into high-frequency and low-frequency distributions and further optimizes semantic structural information by realigning them. Unlike most existing WFSS methods using the textual information from the multi-modal language-vision model, e.g., CLIP, in an offline learning manner, we further propose a CLIP-guided spatial-adapter module (CSM), which performs spatial domain adaptive transformation on textual information through online learning, thus providing enriched cross-modal semantic information for CFM. Extensive experiments on the Pascal-5\textsuperscript{i} and COCO-20\textsuperscript{i} datasets demonstrate that AFANet has achieved state-of-the-art performance. The code is available at <a target="_blank" rel="noopener" href="https://github.com/jarch-ma/AFANet">https://github.com/jarch-ma/AFANet</a>. </p>
<blockquote>
<p>å°‘é‡å­¦ä¹ æ—¨åœ¨é€šè¿‡ä»å°‘é‡æ ·æœ¬ä¸­å­¦ä¹ åˆ°çš„å…ˆéªŒçŸ¥è¯†æ¥è¯†åˆ«æ–°æ¦‚å¿µã€‚ç„¶è€Œï¼Œå¯¹äºè§†è§‰å¯†é›†å‹ä»»åŠ¡ï¼ˆå¦‚å°‘é‡è¯­ä¹‰åˆ†å‰²ï¼‰æ¥è¯´ï¼Œåƒç´ çº§æ³¨é‡Šæ—¢è€—æ—¶åˆæˆæœ¬é«˜æ˜‚ã€‚å› æ­¤ï¼Œæœ¬æ–‡åˆ©ç”¨æ›´å…·æŒ‘æˆ˜æ€§çš„å›¾åƒçº§æ³¨é‡Šï¼Œå¹¶æå‡ºä¸€ç§è‡ªé€‚åº”é¢‘ç‡æ„ŸçŸ¥ç½‘ç»œï¼ˆAFANetï¼‰è¿›è¡Œå¼±ç›‘ç£å°‘é‡è¯­ä¹‰åˆ†å‰²ï¼ˆWFSSï¼‰ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬é¦–å…ˆæå‡ºäº†è·¨ç²’åº¦é¢‘ç‡æ„ŸçŸ¥æ¨¡å—ï¼ˆCFMï¼‰ï¼Œå®ƒå°†RGBå›¾åƒåˆ†è§£ä¸ºé«˜é¢‘å’Œä½é¢‘åˆ†å¸ƒï¼Œå¹¶é€šè¿‡é‡æ–°å¯¹é½è¿›ä¸€æ­¥ä¼˜åŒ–è¯­ä¹‰ç»“æ„ä¿¡æ¯ã€‚ä¸å¤§å¤šæ•°ç°æœ‰çš„ä½¿ç”¨å¤šæ¨¡æ€è¯­è¨€è§†è§‰æ¨¡å‹çš„æ–‡æœ¬ä¿¡æ¯çš„WFSSæ–¹æ³•ä¸åŒï¼Œä¾‹å¦‚ä»¥ç¦»çº¿å­¦ä¹ æ–¹å¼ä½¿ç”¨çš„CLIPï¼Œæˆ‘ä»¬è¿›ä¸€æ­¥æå‡ºäº†CLIPå¼•å¯¼çš„ç©ºé—´é€‚é…å™¨æ¨¡å—ï¼ˆCSMï¼‰ï¼Œè¯¥æ¨¡å—é€šè¿‡åœ¨çº¿å­¦ä¹ åœ¨æ–‡æœ¬ä¿¡æ¯ä¸Šæ‰§è¡Œç©ºé—´åŸŸè‡ªé€‚åº”è½¬æ¢ï¼Œä»è€Œä¸ºCFMæä¾›ä¸°å¯Œçš„è·¨æ¨¡æ€è¯­ä¹‰ä¿¡æ¯ã€‚åœ¨Pascal-5iå’ŒCOCO-20iæ•°æ®é›†ä¸Šçš„å¤§é‡å®éªŒè¡¨æ˜ï¼ŒAFANetå·²ç»è¾¾åˆ°äº†æœ€æ–°æ€§èƒ½æ°´å¹³ã€‚ä»£ç å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/jarch-ma/AFANet%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/jarch-ma/AFANetæ‰¾åˆ°ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.17601v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºè‡ªé€‚åº”é¢‘ç‡æ„ŸçŸ¥ç½‘ç»œï¼ˆAFANetï¼‰çš„å¼±ç›‘ç£å°‘æ ·æœ¬è¯­ä¹‰åˆ†å‰²ï¼ˆWFSSï¼‰æ–¹æ³•ã€‚è¯¥æ–¹æ³•åˆ©ç”¨å›¾åƒçº§æ ‡æ³¨ï¼Œé€šè¿‡è·¨ç²’åº¦é¢‘ç‡æ„ŸçŸ¥æ¨¡å—ï¼ˆCFMï¼‰å°†å›¾åƒåˆ†è§£ä¸ºé«˜é¢‘å’Œä½é¢‘åˆ†å¸ƒï¼Œå¹¶é‡æ–°å¯¹é½ä»¥ä¼˜åŒ–è¯­ä¹‰ç»“æ„ä¿¡æ¯ã€‚åŒæ—¶ï¼Œå¼•å…¥CLIPå¼•å¯¼çš„çš„ç©ºé—´é€‚é…å™¨æ¨¡å—ï¼ˆCSMï¼‰ï¼Œé€šè¿‡åœ¨çº¿å­¦ä¹ å¯¹æ–‡æœ¬ä¿¡æ¯è¿›è¡Œç©ºé—´åŸŸè‡ªé€‚åº”å˜æ¢ï¼Œä¸ºCFMæä¾›ä¸°å¯Œçš„è·¨æ¨¡æ€è¯­ä¹‰ä¿¡æ¯ã€‚åœ¨Pascal-5iå’ŒCOCO-20iæ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒAFANetè¾¾åˆ°äº†æœ€æ–°æŠ€æœ¯æ°´å¹³ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æœ¬æ–‡å…³æ³¨å°‘æ ·æœ¬è¯­ä¹‰åˆ†å‰²é—®é¢˜ï¼Œæå‡ºè‡ªé€‚åº”é¢‘ç‡æ„ŸçŸ¥ç½‘ç»œï¼ˆAFANetï¼‰è§£å†³æ–¹æ¡ˆã€‚</li>
<li>åˆ©ç”¨å›¾åƒçº§æ ‡æ³¨ï¼Œé¿å…åƒç´ çº§æ ‡æ³¨çš„æ—¶é—´æˆæœ¬å’Œæˆæœ¬é«˜æ˜‚é—®é¢˜ã€‚</li>
<li>å¼•å…¥è·¨ç²’åº¦é¢‘ç‡æ„ŸçŸ¥æ¨¡å—ï¼ˆCFMï¼‰ï¼Œåˆ†è§£å›¾åƒä¸ºé«˜é¢‘å’Œä½é¢‘åˆ†å¸ƒï¼Œä¼˜åŒ–è¯­ä¹‰ç»“æ„ä¿¡æ¯ã€‚</li>
<li>ä¸å¤§å¤šæ•°ä½¿ç”¨ç¦»çº¿å­¦ä¹ æ–¹å¼çš„WFSSæ–¹æ³•ä¸åŒï¼Œæå‡ºCLIPå¼•å¯¼çš„çš„ç©ºé—´é€‚é…å™¨æ¨¡å—ï¼ˆCSMï¼‰ï¼Œé€šè¿‡åœ¨çº¿å­¦ä¹ è¿›è¡Œç©ºé—´åŸŸè‡ªé€‚åº”å˜æ¢ã€‚</li>
<li>CSAMæ¨¡å—å¯Œé›†äº†è·¨æ¨¡æ€è¯­ä¹‰ä¿¡æ¯ï¼Œä¸ºCFMæä¾›æ›´å¤šä¸Šä¸‹æ–‡ã€‚</li>
<li>åœ¨Pascal-5iå’ŒCOCO-20iæ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒAFANetæ€§èƒ½è¾¾åˆ°æœ€æ–°æŠ€æœ¯æ°´å¹³ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.17601">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-c286b546a7b8b112f49e70c8c692a052.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-92b12f4ef3edec5343b33d63af5f2e4b.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-ef3c89546934a25924e4a0910914e013.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-912009cb34665b008f15f63397f9a37e.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="Feature-Based-Methods-Domain-Adaptation-for-Object-Detection-A-Review-Paper"><a href="#Feature-Based-Methods-Domain-Adaptation-for-Object-Detection-A-Review-Paper" class="headerlink" title="Feature Based Methods Domain Adaptation for Object Detection: A Review   Paper"></a>Feature Based Methods Domain Adaptation for Object Detection: A Review   Paper</h2><p><strong>Authors:Helia Mohamadi, Mohammad Ali Keyvanrad, Mohammad Reza Mohammadi</strong></p>
<p>Domain adaptation, a pivotal branch of transfer learning, aims to enhance the performance of machine learning models when deployed in target domains with distinct data distributions. This is particularly critical for object detection tasks, where domain shifts (caused by factors such as lighting conditions, viewing angles, and environmental variations) can lead to significant performance degradation. This review delves into advanced methodologies for domain adaptation, including adversarial learning, discrepancy-based, multi-domain, teacher-student, ensemble, and VLM techniques, emphasizing their efficacy in reducing domain gaps and enhancing model robustness. Feature-based methods have emerged as powerful tools for addressing these challenges by harmonizing feature representations across domains. These techniques, such as Feature Alignment, Feature Augmentation&#x2F;Reconstruction, and Feature Transformation, are employed alongside or as integral parts of other domain adaptation strategies to minimize domain gaps and improve model performance. Special attention is given to strategies that minimize the reliance on extensive labeled data and using unlabeled data, particularly in scenarios involving synthetic-to-real domain shifts. Applications in fields such as autonomous driving and medical imaging are explored, showcasing the potential of these methods to ensure reliable object detection in diverse and complex settings. By providing a thorough analysis of state-of-the-art techniques, challenges, and future directions, this work offers a valuable reference for researchers striving to develop resilient and adaptable object detection frameworks, advancing the seamless deployment of artificial intelligence in dynamic environments. </p>
<blockquote>
<p>é¢†åŸŸè‡ªé€‚åº”æ˜¯è¿ç§»å­¦ä¹ çš„ä¸€ä¸ªé‡è¦åˆ†æ”¯ï¼Œæ—¨åœ¨æé«˜æœºå™¨å­¦ä¹ æ¨¡å‹åœ¨å…·æœ‰ä¸åŒæ•°æ®åˆ†å¸ƒçš„ç›®æ ‡åŸŸä¸­çš„æ€§èƒ½ã€‚è¿™å¯¹äºå¯¹è±¡æ£€æµ‹ä»»åŠ¡å°¤ä¸ºé‡è¦ï¼Œå› ä¸ºåŸŸåç§»ï¼ˆç”±å…‰ç…§æ¡ä»¶ã€è§‚çœ‹è§’åº¦å’Œç¯å¢ƒå˜åŒ–ç­‰å› ç´ å¼•èµ·ï¼‰å¯èƒ½å¯¼è‡´æ€§èƒ½æ˜¾è‘—ä¸‹é™ã€‚æœ¬æ–‡æ·±å…¥æ¢è®¨äº†é¢†åŸŸè‡ªé€‚åº”çš„é«˜çº§æ–¹æ³•ï¼ŒåŒ…æ‹¬å¯¹æŠ—æ€§å­¦ä¹ ã€åŸºäºå·®å¼‚çš„æ–¹æ³•ã€å¤šåŸŸæ–¹æ³•ã€å¸ˆå¾’æ–¹æ³•ã€é›†æˆæ–¹æ³•å’ŒVLMæŠ€æœ¯ï¼Œé‡ç‚¹ä»‹ç»äº†å®ƒä»¬åœ¨å‡å°‘åŸŸå·®è·å’Œæé«˜æ¨¡å‹ç¨³å¥æ€§æ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚åŸºäºç‰¹å¾çš„æ–¹æ³•å·²æˆä¸ºè§£å†³è¿™äº›æŒ‘æˆ˜çš„å¼ºå¤§å·¥å…·ï¼Œé€šè¿‡åè°ƒä¸åŒé¢†åŸŸçš„ç‰¹å¾è¡¨ç¤ºã€‚è¿™äº›æ–¹æ³•ï¼Œå¦‚ç‰¹å¾å¯¹é½ã€ç‰¹å¾å¢å¼º&#x2F;é‡å»ºå’Œç‰¹å¾å˜æ¢ç­‰ï¼Œä¸å…¶ä»–é¢†åŸŸè‡ªé€‚åº”ç­–ç•¥ä¸€èµ·ä½¿ç”¨æˆ–ä½œä¸ºå…¶ä¸å¯æˆ–ç¼ºçš„ä¸€éƒ¨åˆ†ï¼Œä»¥æœ€å°åŒ–é¢†åŸŸå·®è·å¹¶æé«˜æ¨¡å‹æ€§èƒ½ã€‚åœ¨å‡å°‘å¯¹å¤§é‡æ ‡è®°æ•°æ®çš„ä¾èµ–å’Œåˆ©ç”¨æ— æ ‡è®°æ•°æ®æ–¹é¢ç»™äºˆäº†ç‰¹åˆ«å…³æ³¨ï¼Œç‰¹åˆ«æ˜¯åœ¨æ¶‰åŠä»åˆæˆåˆ°çœŸå®åŸŸçš„è½¬ç§»åœºæ™¯ä¸­ã€‚æœ¬æ–‡æ¢è®¨äº†è‡ªåŠ¨é©¾é©¶å’ŒåŒ»å­¦å½±åƒç­‰é¢†åŸŸçš„åº”ç”¨ï¼Œå±•ç¤ºäº†è¿™äº›æ–¹æ³•åœ¨å¤šæ ·åŒ–å’Œå¤æ‚ç¯å¢ƒä¸­ç¡®ä¿å¯é å¯¹è±¡æ£€æµ‹çš„æ½œåŠ›ã€‚é€šè¿‡å¯¹æœ€æ–°æŠ€æœ¯ã€æŒ‘æˆ˜å’Œæœªæ¥æ–¹å‘çš„æ·±å…¥åˆ†æï¼Œæœ¬æ–‡ä¸ºé‚£äº›åŠªåŠ›å¼€å‘å…·æœ‰å¼¹æ€§å’Œé€‚åº”æ€§çš„å¯¹è±¡æ£€æµ‹æ¡†æ¶çš„ç ”ç©¶äººå‘˜æä¾›äº†å®è´µçš„å‚è€ƒï¼Œæ¨åŠ¨äº†äººå·¥æ™ºèƒ½åœ¨åŠ¨æ€ç¯å¢ƒä¸­çš„æ— ç¼éƒ¨ç½²ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.17325v1">PDF</a> 46 pages, 13 figures, It will be submitted to a journal</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ç»¼è¿°äº†é¢†åŸŸè‡ªé€‚åº”æŠ€æœ¯åœ¨å¯¹è±¡æ£€æµ‹ä»»åŠ¡ä¸­çš„é‡è¦æ€§ï¼Œä»‹ç»äº†å¤šç§å…ˆè¿›çš„é¢†åŸŸè‡ªé€‚åº”æ–¹æ³•ï¼Œå¦‚å¯¹æŠ—æ€§å­¦ä¹ ã€å·®å¼‚æ³•ã€å¤šé¢†åŸŸæ³•ã€æ•™å¸ˆ-å­¦ç”Ÿæ³•ã€é›†æˆæ³•å’ŒVLMæŠ€æœ¯ç­‰ï¼Œå¼ºè°ƒå…¶åœ¨ç¼©å°é¢†åŸŸå·®è·å’Œå¢å¼ºæ¨¡å‹ç¨³å¥æ€§æ–¹é¢çš„ä½œç”¨ã€‚æ–‡ä¸­è¯¦ç»†è®¨è®ºäº†ç‰¹å¾åŸºæ–¹æ³•ï¼Œå¦‚ç‰¹å¾å¯¹é½ã€ç‰¹å¾å¢å¼º&#x2F;é‡å»ºå’Œç‰¹å¾å˜æ¢ç­‰ï¼Œè¿™äº›æ–¹æ³•ä½œä¸ºå…¶ä»–é¢†åŸŸè‡ªé€‚åº”ç­–ç•¥çš„è¡¥å……æˆ–é‡è¦ç»„æˆéƒ¨åˆ†ï¼Œç”¨äºæœ€å°åŒ–é¢†åŸŸå·®è·å¹¶æé«˜æ¨¡å‹æ€§èƒ½ã€‚æ–‡ç« è¿˜é‡ç‚¹å…³æ³¨äº†å¦‚ä½•åˆ©ç”¨æ— æ ‡ç­¾æ•°æ®å‡å°‘ä¾èµ–å¤§é‡æ ‡ç­¾æ•°æ®çš„æ–¹æ³•ï¼Œç‰¹åˆ«æ˜¯åœ¨åˆæˆåˆ°çœŸå®é¢†åŸŸè½¬ç§»çš„åœºæ™¯ä¸­ã€‚æœ¬æ–‡æ¢è®¨äº†è¿™äº›æŠ€æœ¯åœ¨è‡ªåŠ¨é©¾é©¶å’ŒåŒ»å­¦å½±åƒç­‰é¢†åŸŸçš„åº”ç”¨ï¼Œå±•ç¤ºäº†å®ƒä»¬åœ¨ç¡®ä¿åœ¨å„ç§å¤æ‚ç¯å¢ƒä¸­å¯é å¯¹è±¡æ£€æµ‹æ–¹é¢çš„æ½œåŠ›ã€‚æ–‡ç« å¯¹æœ€æ–°æŠ€æœ¯ã€æŒ‘æˆ˜å’Œæœªæ¥æ–¹å‘è¿›è¡Œäº†æ·±å…¥åˆ†æï¼Œä¸ºå¼€å‘å…·æœ‰å¼¹æ€§å’Œé€‚åº”æ€§çš„å¯¹è±¡æ£€æµ‹æ¡†æ¶çš„ç ”ç©¶äººå‘˜æä¾›äº†å®è´µçš„å‚è€ƒã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>é¢†åŸŸè‡ªé€‚åº”æ˜¯è¿ç§»å­¦ä¹ çš„é‡è¦åˆ†æ”¯ï¼Œæ—¨åœ¨æé«˜æœºå™¨å­¦ä¹ æ¨¡å‹åœ¨æ•°æ®åˆ†å¸ƒä¸åŒçš„ç›®æ ‡é¢†åŸŸçš„æ€§èƒ½ã€‚</li>
<li>å¯¹è±¡æ£€æµ‹ä»»åŠ¡ä¸­ï¼Œé¢†åŸŸåç§»å¯èƒ½ä¼šå¯¼è‡´æ€§èƒ½æ˜¾è‘—ä¸‹é™ã€‚</li>
<li>å…ˆè¿›çš„é¢†åŸŸè‡ªé€‚åº”æ–¹æ³•åŒ…æ‹¬å¯¹æŠ—æ€§å­¦ä¹ ã€å·®å¼‚æ³•ã€å¤šé¢†åŸŸæ³•ã€æ•™å¸ˆ-å­¦ç”Ÿæ³•ã€é›†æˆæ³•å’ŒVLMæŠ€æœ¯ç­‰ã€‚</li>
<li>ç‰¹å¾åŸºæ–¹æ³•ï¼Œå¦‚ç‰¹å¾å¯¹é½ã€ç‰¹å¾å¢å¼º&#x2F;é‡å»ºå’Œç‰¹å¾å˜æ¢ç­‰ï¼Œæ˜¯ç¼©å°é¢†åŸŸå·®è·å’Œæé«˜æ¨¡å‹ç¨³å¥æ€§çš„æœ‰æ•ˆå·¥å…·ã€‚</li>
<li>åˆ©ç”¨æ— æ ‡ç­¾æ•°æ®å‡å°‘é¢†åŸŸè‡ªé€‚åº”ä¸­å¯¹æ ‡ç­¾æ•°æ®çš„ä¾èµ–æ˜¯ä¸€ä¸ªé‡è¦è¶‹åŠ¿ã€‚</li>
<li>é¢†åŸŸè‡ªé€‚åº”æŠ€æœ¯åœ¨è‡ªåŠ¨é©¾é©¶å’ŒåŒ»å­¦å½±åƒç­‰é¢†åŸŸæœ‰å¹¿æ³›åº”ç”¨ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.17325">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-748c3a9695025aa2bd2de4f2aba26c2a.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-1ed71143650c945b4b3164125982ef07.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-a5aeb105f8d135e7b875ae4d8798eea5.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-379994f5fd8b1a3ec1fc3a2f93540757.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-5be7338ce8911038dca90e90927b3433.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="Object-Detection-Approaches-to-Identifying-Hand-Images-with-High-Forensic-Values"><a href="#Object-Detection-Approaches-to-Identifying-Hand-Images-with-High-Forensic-Values" class="headerlink" title="Object Detection Approaches to Identifying Hand Images with High   Forensic Values"></a>Object Detection Approaches to Identifying Hand Images with High   Forensic Values</h2><p><strong>Authors:Thanh Thi Nguyen, Campbell Wilson, Imad Khan, Janis Dalins</strong></p>
<p>Forensic science plays a crucial role in legal investigations, and the use of advanced technologies, such as object detection based on machine learning methods, can enhance the efficiency and accuracy of forensic analysis. Human hands are unique and can leave distinct patterns, marks, or prints that can be utilized for forensic examinations. This paper compares various machine learning approaches to hand detection and presents the application results of employing the best-performing model to identify images of significant importance in forensic contexts. We fine-tune YOLOv8 and vision transformer-based object detection models on four hand image datasets, including the 11k hands dataset with our own bounding boxes annotated by a semi-automatic approach. Two YOLOv8 variants, i.e., YOLOv8 nano (YOLOv8n) and YOLOv8 extra-large (YOLOv8x), and two vision transformer variants, i.e., DEtection TRansformer (DETR) and Detection Transformers with Assignment (DETA), are employed for the experiments. Experimental results demonstrate that the YOLOv8 models outperform DETR and DETA on all datasets. The experiments also show that YOLOv8 approaches result in superior performance compared with existing hand detection methods, which were based on YOLOv3 and YOLOv4 models. Applications of our fine-tuned YOLOv8 models for identifying hand images (or frames in a video) with high forensic values produce excellent results, significantly reducing the time required by forensic experts. This implies that our approaches can be implemented effectively for real-world applications in forensics or related fields. </p>
<blockquote>
<p>æ³•åŒ»å­¦åœ¨æ³•å¾‹è°ƒæŸ¥ä¸­å‘æŒ¥ç€è‡³å…³é‡è¦çš„ä½œç”¨ï¼Œä½¿ç”¨å…ˆè¿›æŠ€æœ¯ï¼Œå¦‚åŸºäºæœºå™¨å­¦ä¹ æ–¹æ³•çš„ç‰©ä½“æ£€æµ‹ï¼Œå¯ä»¥æé«˜æ³•åŒ»å­¦åˆ†æçš„æ•ˆç‡å’Œå‡†ç¡®æ€§ã€‚äººæ‰‹æ˜¯ç‹¬ä¸€æ— äºŒçš„ï¼Œå¯ä»¥ç•™ä¸‹ç‹¬ç‰¹çš„å›¾æ¡ˆã€ç—•è¿¹æˆ–å°è®°ï¼Œå¯ç”¨äºæ³•åŒ»å­¦æ£€éªŒã€‚æœ¬æ–‡æ¯”è¾ƒäº†å„ç§æœºå™¨å­¦ä¹ åœ¨æ‰‹éƒ¨æ£€æµ‹æ–¹é¢çš„åº”ç”¨æ–¹æ³•ï¼Œå¹¶å±•ç¤ºäº†ä½¿ç”¨è¡¨ç°æœ€ä½³çš„æ¨¡å‹åœ¨æ³•åŒ»å­¦èƒŒæ™¯ä¸­è¯†åˆ«å…·æœ‰é‡è¦æ„ä¹‰çš„å›¾åƒçš„åº”ç”¨ç»“æœã€‚æˆ‘ä»¬å¯¹YOLOv8å’ŒåŸºäºè§†è§‰å˜æ¢å™¨çš„ç‰©ä½“æ£€æµ‹æ¨¡å‹è¿›è¡Œäº†å¾®è°ƒï¼Œä½¿ç”¨äº†å››ä¸ªæ‰‹éƒ¨å›¾åƒæ•°æ®é›†ï¼ŒåŒ…æ‹¬æˆ‘ä»¬è‡ªå·±é€šè¿‡åŠè‡ªåŠ¨æ–¹æ³•æ ‡æ³¨è¾¹ç•Œæ¡†çš„åŒ…å«1.1ä¸‡å¼ æ‰‹éƒ¨å›¾åƒçš„æ•°æ®é›†ã€‚å®éªŒé‡‡ç”¨äº†ä¸¤ç§YOLOv8å˜ä½“ï¼Œå³YOLOv8 nanoï¼ˆYOLOv8nï¼‰å’ŒYOLOv8 extra-largeï¼ˆYOLOv8xï¼‰ï¼Œä»¥åŠä¸¤ç§è§†è§‰å˜æ¢å™¨å˜ä½“ï¼Œå³DEtection TRansformerï¼ˆDETRï¼‰å’Œå¸¦æœ‰åˆ†é…åŠŸèƒ½çš„Detection Transformersï¼ˆDETAï¼‰ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒYOLOv8æ¨¡å‹åœ¨æ‰€æœ‰æ•°æ®é›†ä¸Šçš„è¡¨ç°ä¼˜äºDETRå’ŒDETAã€‚å®éªŒè¿˜æ˜¾ç¤ºï¼Œä¸åŸºäºYOLOv3å’ŒYOLOv4æ¨¡å‹çš„æ‰‹éƒ¨æ£€æµ‹æ–¹æ³•ç›¸æ¯”ï¼ŒYOLOv8æ–¹æ³•å…·æœ‰æ›´å¥½çš„æ€§èƒ½ã€‚æˆ‘ä»¬å¾®è°ƒåçš„YOLOv8æ¨¡å‹åœ¨è¯†åˆ«å…·æœ‰é«˜æ³•åŒ»å­¦ä»·å€¼çš„æ‰‹éƒ¨å›¾åƒï¼ˆæˆ–è§†é¢‘ä¸­çš„å¸§ï¼‰æ–¹é¢çš„åº”ç”¨å–å¾—äº†ä¼˜å¼‚çš„ç»“æœï¼Œæ˜¾è‘—å‡å°‘äº†æ³•åŒ»å­¦ä¸“å®¶æ‰€éœ€çš„æ—¶é—´ã€‚è¿™æ„å‘³ç€æˆ‘ä»¬çš„æ–¹æ³•å¯ä»¥æœ‰æ•ˆåœ°åº”ç”¨äºæ³•åŒ»å­¦æˆ–ç›¸å…³é¢†åŸŸçš„å®é™…åº”ç”¨ä¸­ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.16431v1">PDF</a> Accepted at 2024 IEEE International Conference on Systems, Man, and   Cybernetics (SMC)</p>
<p><strong>Summary</strong><br>     æœ¬æ–‡æ¢è®¨äº†æœºå™¨å­¦ä¹ æ–¹æ³•åœ¨æ³•åŒ»å­¦æ‰‹å°æ£€æµ‹ä¸­çš„åº”ç”¨ã€‚é€šè¿‡å¯¹æ¯”ä¸åŒçš„æœºå™¨å­¦ä¹ æ¨¡å‹ï¼Œå¦‚YOLOv8ç³»åˆ—æ¨¡å‹å’Œè§†è§‰è½¬æ¢å™¨æ¨¡å‹ï¼Œå‘ç°YOLOv8æ¨¡å‹åœ¨æ‰‹å°æ£€æµ‹æ–¹é¢è¡¨ç°å‡ºå“è¶Šæ€§èƒ½ï¼Œèƒ½å¤Ÿæ˜¾è‘—æé«˜æ³•åŒ»å­¦åˆ†æçš„æ•ˆç‡å’Œå‡†ç¡®æ€§ï¼Œæœ‰åŠ©äºæ³•åŒ»ä¸“å®¶å¿«é€Ÿè¯†åˆ«é«˜ä»·å€¼çš„æ‰‹å°å›¾åƒã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æ³•åŒ»å­¦ä¸­æ‰‹å°æ£€æµ‹çš„é‡è¦æ€§åŠå…¶åœ¨æé«˜è°ƒæŸ¥æ•ˆç‡ä¸å‡†ç¡®æ€§æ–¹é¢çš„ä½œç”¨ã€‚</li>
<li>æœºå™¨å­¦ä¹ æ–¹æ³•å¦‚YOLOv8æ¨¡å‹å’Œè§†è§‰è½¬æ¢å™¨æ¨¡å‹åœ¨æ‰‹å°æ£€æµ‹ä¸­çš„åº”ç”¨ã€‚</li>
<li>YOLOv8æ¨¡å‹åŒ…æ‹¬YOLOv8 nanoå’ŒYOLOv8 extra-largeä¸¤ç§å˜ä½“ï¼Œåœ¨æ‰‹å°æ£€æµ‹æ–¹é¢è¡¨ç°ä¼˜è¶Šã€‚</li>
<li>å¯¹æ¯”å®éªŒæ˜¾ç¤ºYOLOv8æ¨¡å‹ç›¸è¾ƒäºåŸºäºYOLOv3å’ŒYOLOv4æ¨¡å‹çš„æ£€æµ‹æ–¹æ³•å’Œè§†è§‰è½¬æ¢å™¨æ¨¡å‹å…·æœ‰æ›´å¥½çš„æ€§èƒ½ã€‚</li>
<li>YOLOv8æ¨¡å‹çš„ç²¾ç»†è°ƒæ•´æœ‰åŠ©äºå¿«é€Ÿè¯†åˆ«é«˜ä»·å€¼çš„æ‰‹å°å›¾åƒæˆ–è§†é¢‘å¸§ã€‚</li>
<li>æ­¤ç ”ç©¶èƒ½å¤Ÿä¸ºå®ç°æ‰‹å°æ£€æµ‹çš„æœ‰æ•ˆåº”ç”¨å¥ å®šåŸºç¡€ï¼Œå°¤å…¶åœ¨æ³•åŒ»å­¦å’Œç›¸å…³é¢†åŸŸã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.16431">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-ebbfb22973252dc72268b1f78e452f7e.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-b91c2f537649ae2ba0f971ebae622041.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-62b8d13f4dcbe934a840851b9d3cbb95.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b973137a421206abf3f84a12aaedf03f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-78e0339b3e8dce446fa0c8f380c08066.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-26894bd28a019fcd1c161bb6c7539e03.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-ce821da2aa65c02bb41d7fbd7773f73d.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-97d0431035cac33e912791f8a6743233.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="Cognition-Transferring-and-Decoupling-for-Text-supervised-Egocentric-Semantic-Segmentation"><a href="#Cognition-Transferring-and-Decoupling-for-Text-supervised-Egocentric-Semantic-Segmentation" class="headerlink" title="Cognition Transferring and Decoupling for Text-supervised Egocentric   Semantic Segmentation"></a>Cognition Transferring and Decoupling for Text-supervised Egocentric   Semantic Segmentation</h2><p><strong>Authors:Zhaofeng Shi, Heqian Qiu, Lanxiao Wang, Fanman Meng, Qingbo Wu, Hongliang Li</strong></p>
<p>In this paper, we explore a novel Text-supervised Egocentic Semantic Segmentation (TESS) task that aims to assign pixel-level categories to egocentric images weakly supervised by texts from image-level labels. In this task with prospective potential, the egocentric scenes contain dense wearer-object relations and inter-object interference. However, most recent third-view methods leverage the frozen Contrastive Language-Image Pre-training (CLIP) model, which is pre-trained on the semantic-oriented third-view data and lapses in the egocentric view due to the &#96;&#96;relation insensitiveâ€ problem. Hence, we propose a Cognition Transferring and Decoupling Network (CTDN) that first learns the egocentric wearer-object relations via correlating the image and text. Besides, a Cognition Transferring Module (CTM) is developed to distill the cognitive knowledge from the large-scale pre-trained model to our model for recognizing egocentric objects with various semantics. Based on the transferred cognition, the Foreground-background Decoupling Module (FDM) disentangles the visual representations to explicitly discriminate the foreground and background regions to mitigate false activation areas caused by foreground-background interferential objects during egocentric relation learning. Extensive experiments on four TESS benchmarks demonstrate the effectiveness of our approach, which outperforms many recent related methods by a large margin. Code will be available at <a target="_blank" rel="noopener" href="https://github.com/ZhaofengSHI/CTDN">https://github.com/ZhaofengSHI/CTDN</a>. </p>
<blockquote>
<p>æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æ¢ç´¢äº†ä¸€é¡¹æ–°å‹çš„æ–‡æœ¬ç›‘ç£çš„ä»¥è‡ªæˆ‘ä¸ºä¸­å¿ƒçš„è¯­ä¹‰åˆ†å‰²ï¼ˆTESSï¼‰ä»»åŠ¡ï¼Œè¯¥ä»»åŠ¡æ—¨åœ¨ä¸ºä»¥è‡ªæˆ‘ä¸ºä¸­å¿ƒçš„å›¾åƒåˆ†é…åƒç´ çº§ç±»åˆ«ï¼Œè¿™äº›å›¾åƒä»…é€šè¿‡å›¾åƒçº§æ ‡ç­¾çš„æ–‡æœ¬è¿›è¡Œå¼±ç›‘ç£ã€‚åœ¨è¿™ä¸ªå…·æœ‰æ½œåŠ›çš„ä»»åŠ¡ä¸­ï¼Œä»¥è‡ªæˆ‘ä¸ºä¸­å¿ƒçš„åœºæ™¯åŒ…å«å¯†é›†çš„ç©¿æˆ´è€…-ç‰©ä½“å…³ç³»å’Œç‰©ä½“é—´çš„ç›¸äº’å¹²æ‰°ã€‚ç„¶è€Œï¼Œæœ€è¿‘çš„å¤§å¤šæ•°ç¬¬ä¸‰äººç§°è§†è§’çš„æ–¹æ³•éƒ½åˆ©ç”¨å†»ç»“çš„å¯¹æ¯”è¯­è¨€-å›¾åƒé¢„è®­ç»ƒï¼ˆCLIPï¼‰æ¨¡å‹ï¼Œè¯¥æ¨¡å‹åœ¨è¯­ä¹‰å¯¼å‘çš„ç¬¬ä¸‰äººç§°è§†è§’æ•°æ®ä¸Šè¿›è¡Œé¢„è®­ç»ƒï¼Œå¹¶åœ¨ä»¥è‡ªæˆ‘ä¸ºä¸­å¿ƒçš„è§†è§’ä¸­å­˜åœ¨â€œå…³ç³»ä¸æ•æ„Ÿâ€é—®é¢˜ã€‚å› æ­¤ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§è®¤çŸ¥è½¬ç§»å’Œè§£è€¦ç½‘ç»œï¼ˆCTDNï¼‰ï¼Œè¯¥ç½‘ç»œé¦–å…ˆé€šè¿‡å›¾åƒå’Œæ–‡æœ¬çš„ç›¸å…³æ€§æ¥å­¦ä¹ ä»¥è‡ªæˆ‘ä¸ºä¸­å¿ƒçš„ç©¿æˆ´è€…-ç‰©ä½“å…³ç³»ã€‚æ­¤å¤–ï¼Œè¿˜å¼€å‘äº†ä¸€ç§è®¤çŸ¥è½¬ç§»æ¨¡å—ï¼ˆCTMï¼‰ï¼Œç”¨äºä»å¤§è§„æ¨¡é¢„è®­ç»ƒæ¨¡å‹ä¸­æç‚¼è®¤çŸ¥çŸ¥è¯†ï¼Œä»¥è¯†åˆ«å…·æœ‰å„ç§è¯­ä¹‰çš„ä»¥è‡ªæˆ‘ä¸ºä¸­å¿ƒçš„å¯¹è±¡ã€‚åŸºäºè½¬ç§»çš„è®¤çŸ¥ï¼Œå‰æ™¯-èƒŒæ™¯è§£è€¦æ¨¡å—ï¼ˆFDMï¼‰è§£å¼€è§†è§‰è¡¨ç¤ºï¼Œæ˜ç¡®åŒºåˆ†å‰æ™¯å’ŒèƒŒæ™¯åŒºåŸŸï¼Œä»¥å‡è½»ç”±å‰æ™¯-èƒŒæ™¯å¹²æ‰°ç‰©ä½“å¼•èµ·çš„é”™è¯¯æ¿€æ´»åŒºåŸŸï¼Œä»è€Œä¿ƒè¿›ä»¥è‡ªæˆ‘ä¸ºä¸­å¿ƒçš„å…³è”å­¦ä¹ ã€‚åœ¨å››ä¸ªTESSåŸºå‡†æµ‹è¯•ä¸Šçš„å¤§é‡å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•æ•ˆæœæ˜¾è‘—ï¼Œå¤§å¤§è¶…è¶Šäº†æœ€è¿‘çš„ç›¸å…³æ–¹æ³•ã€‚ä»£ç å°†åœ¨<a target="_blank" rel="noopener" href="https://github.com/ZhaofengSHI/CTDN%E4%B8%8A%E6%8F%90%E4%BE%9B%E3%80%82">https://github.com/ZhaofengSHI/CTDNä¸Šæä¾›ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2410.01341v2">PDF</a> Accepted by IEEE Transactions on Circuits and Systems for Video   Technology (TCSVT)</p>
<p><strong>Summary</strong>ï¼š<br>æœ¬æ–‡æ¢ç´¢äº†ä¸€é¡¹æ–°å‹çš„æ–‡æœ¬ç›‘ç£çš„ä»¥è‡ªæˆ‘ä¸ºä¸­å¿ƒçš„è¯­ä¹‰åˆ†å‰²ï¼ˆTESSï¼‰ä»»åŠ¡ï¼Œæ—¨åœ¨åˆ©ç”¨å›¾åƒçº§åˆ«çš„æ ‡ç­¾æ–‡æœ¬å¯¹ä»¥è‡ªæˆ‘ä¸ºä¸­å¿ƒçš„å›¾åƒè¿›è¡Œåƒç´ çº§åˆ«çš„ç±»åˆ«åˆ†é…ã€‚é’ˆå¯¹è¯¥ä»»åŠ¡ä¸­å­˜åœ¨çš„ç©¿æˆ´è€…-ç‰©ä½“å…³ç³»å¯†é›†å’Œç‰©ä½“é—´å¹²æ‰°é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§è®¤çŸ¥è½¬ç§»å’Œè§£è€¦ç½‘ç»œï¼ˆCTDNï¼‰ã€‚é€šè¿‡å…³è”å›¾åƒå’Œæ–‡æœ¬ï¼Œå­¦ä¹ ä»¥è‡ªæˆ‘ä¸ºä¸­å¿ƒçš„ç©¿æˆ´è€…-ç‰©ä½“å…³ç³»ï¼Œå¹¶å¼€å‘äº†ä¸€ä¸ªè®¤çŸ¥è½¬ç§»æ¨¡å—ï¼ˆCTMï¼‰ï¼Œç”¨äºä»å¤§è§„æ¨¡é¢„è®­ç»ƒæ¨¡å‹ä¸­æç‚¼è®¤çŸ¥çŸ¥è¯†ï¼Œä»¥è¯†åˆ«å…·æœ‰ä¸åŒè¯­ä¹‰çš„è‡ªæˆ‘ä¸­å¿ƒç‰©ä½“ã€‚åŸºäºè½¬ç§»çš„è®¤çŸ¥ï¼Œå‰æ™¯-èƒŒæ™¯è§£è€¦æ¨¡å—ï¼ˆFDMï¼‰é€šè¿‡è§£æè§†è§‰è¡¨å¾æ¥æ˜ç¡®åŒºåˆ†å‰æ™¯å’ŒèƒŒæ™¯åŒºåŸŸï¼Œä»¥å‡å°‘ç”±å‰æ™¯-èƒŒæ™¯å¹²æ‰°ç‰©ä½“å¼•èµ·çš„é”™è¯¯æ¿€æ´»åŒºåŸŸã€‚åœ¨å››ä¸ªTESSåŸºå‡†æµ‹è¯•ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•å¤§å¤§ä¼˜äºè¿‘æœŸç›¸å…³æ–¹æ³•ã€‚</p>
<p><strong>Key Takeaways</strong>ï¼š</p>
<ol>
<li>ä»‹ç»äº†æ–‡æœ¬ç›‘ç£çš„ä»¥è‡ªæˆ‘ä¸ºä¸­å¿ƒçš„è¯­ä¹‰åˆ†å‰²ï¼ˆTESSï¼‰ä»»åŠ¡ï¼Œè¯¥ä»»åŠ¡æ—¨åœ¨åˆ©ç”¨å›¾åƒçº§åˆ«çš„æ ‡ç­¾æ–‡æœ¬è¿›è¡Œåƒç´ çº§åˆ«çš„ç±»åˆ«åˆ†é…ã€‚</li>
<li>é’ˆå¯¹TESSä»»åŠ¡ä¸­å­˜åœ¨çš„ç©¿æˆ´è€…-ç‰©ä½“å…³ç³»å¯†é›†å’Œç‰©ä½“é—´å¹²æ‰°é—®é¢˜ï¼Œæå‡ºäº†è®¤çŸ¥è½¬ç§»å’Œè§£è€¦ç½‘ç»œï¼ˆCTDNï¼‰ã€‚</li>
<li>CTDNä¸­çš„è®¤çŸ¥è½¬ç§»æ¨¡å—ï¼ˆCTMï¼‰èƒ½å¤Ÿä»å¤§è§„æ¨¡é¢„è®­ç»ƒæ¨¡å‹ä¸­æç‚¼è®¤çŸ¥çŸ¥è¯†ï¼Œç”¨äºè¯†åˆ«å…·æœ‰ä¸åŒè¯­ä¹‰çš„è‡ªæˆ‘ä¸­å¿ƒç‰©ä½“ã€‚</li>
<li>CTDNä¸­çš„å‰æ™¯-èƒŒæ™¯è§£è€¦æ¨¡å—ï¼ˆFDMï¼‰èƒ½å¤Ÿå‡å°‘å‰æ™¯-èƒŒæ™¯å¹²æ‰°ç‰©ä½“å¼•èµ·çš„é”™è¯¯æ¿€æ´»åŒºåŸŸã€‚</li>
<li>åœ¨å››ä¸ªTESSåŸºå‡†æµ‹è¯•ä¸Šï¼ŒCTDNçš„æ–¹æ³•å¤§å¤§ä¼˜äºè¿‘æœŸç›¸å…³æ–¹æ³•ã€‚</li>
<li>è®ºæ–‡æä¾›äº†æœ‰æ•ˆçš„è§£å†³æ–¹æ¡ˆæ¥è§£å†³â€œå…³ç³»ä¸æ•æ„Ÿâ€é—®é¢˜ï¼Œè¯¥é—®é¢˜åœ¨å°†é¢„è®­ç»ƒæ¨¡å‹åº”ç”¨äºè‡ªæˆ‘ä¸­å¿ƒè§†å›¾æ—¶ä¼šå‡ºç°ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2410.01341">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-38acffd39459a5120128bded80c6d10b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-37008b202d84d304a7f3fdb8911cafd7.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-7bbb90111b01d67b3ca6b04f2e959c68.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="Enhanced-Generative-Data-Augmentation-for-Semantic-Segmentation-via-Stronger-Guidance"><a href="#Enhanced-Generative-Data-Augmentation-for-Semantic-Segmentation-via-Stronger-Guidance" class="headerlink" title="Enhanced Generative Data Augmentation for Semantic Segmentation via   Stronger Guidance"></a>Enhanced Generative Data Augmentation for Semantic Segmentation via   Stronger Guidance</h2><p><strong>Authors:Quang-Huy Che, Duc-Tri Le, Bich-Nga Pham, Duc-Khai Lam, Vinh-Tiep Nguyen</strong></p>
<p>Data augmentation is crucial for pixel-wise annotation tasks like semantic segmentation, where labeling requires significant effort and intensive labor. Traditional methods, involving simple transformations such as rotations and flips, create new images but often lack diversity along key semantic dimensions and fail to alter high-level semantic properties. To address this issue, generative models have emerged as an effective solution for augmenting data by generating synthetic images. Controllable Generative models offer data augmentation methods for semantic segmentation tasks by using prompts and visual references from the original image. However, these models face challenges in generating synthetic images that accurately reflect the content and structure of the original image due to difficulties in creating effective prompts and visual references. In this work, we introduce an effective data augmentation pipeline for semantic segmentation using Controllable Diffusion model. Our proposed method includes efficient prompt generation using \textit{Class-Prompt Appending} and \textit{Visual Prior Blending} to enhance attention to labeled classes in real images, allowing the pipeline to generate a precise number of augmented images while preserving the structure of segmentation-labeled classes. In addition, we implement a \textit{class balancing algorithm} to ensure a balanced training dataset when merging the synthetic and original images. Evaluation on PASCAL VOC datasets, our pipeline demonstrates its effectiveness in generating high-quality synthetic images for semantic segmentation. Our code is available at \href{<a target="_blank" rel="noopener" href="https://github.com/chequanghuy/Enhanced-Generative-Data-Augmentation-for-Semantic-Segmentation-via-Stronger-Guidance%7D%7Bthis">https://github.com/chequanghuy/Enhanced-Generative-Data-Augmentation-for-Semantic-Segmentation-via-Stronger-Guidance}{this</a> https URL}. </p>
<blockquote>
<p>æ•°æ®å¢å¼ºå¯¹äºåƒç´ çº§çš„æ ‡æ³¨ä»»åŠ¡ï¼Œå¦‚è¯­ä¹‰åˆ†å‰²ï¼Œæ˜¯è‡³å…³é‡è¦çš„ã€‚è¯­ä¹‰åˆ†å‰²éœ€è¦æŠ•å…¥å¤§é‡çš„æ ‡æ³¨å·¥ä½œã€‚ä¼ ç»Ÿçš„æ–¹æ³•ï¼Œå¦‚æ—‹è½¬å’Œç¿»è½¬ç­‰ç®€å•å˜æ¢ï¼Œå¯ä»¥åˆ›å»ºæ–°çš„å›¾åƒï¼Œä½†å¾€å¾€åœ¨å…³é”®çš„è¯­ä¹‰ç»´åº¦ä¸Šç¼ºä¹å¤šæ ·æ€§ï¼Œå¹¶ä¸”æ— æ³•æ”¹å˜é«˜çº§è¯­ä¹‰å±æ€§ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œç”Ÿæˆæ¨¡å‹ä½œä¸ºä¸€ç§æœ‰æ•ˆçš„æ•°æ®å¢å¼ºæ–¹æ³•åº”è¿è€Œç”Ÿï¼Œé€šè¿‡ç”Ÿæˆåˆæˆå›¾åƒæ¥å¢å¼ºæ•°æ®ã€‚å¯æ§ç”Ÿæˆæ¨¡å‹ä¸ºè¯­ä¹‰åˆ†å‰²ä»»åŠ¡æä¾›äº†æ•°æ®å¢å¼ºæ–¹æ³•ï¼Œé€šè¿‡ä½¿ç”¨åŸå§‹å›¾åƒçš„æç¤ºå’Œè§†è§‰å‚è€ƒæ¥ç”Ÿæˆæ–°çš„æ•°æ®ã€‚ç„¶è€Œï¼Œè¿™äº›æ¨¡å‹åœ¨ç”Ÿæˆå‡†ç¡®åæ˜ åŸå§‹å›¾åƒå†…å®¹å’Œç»“æ„çš„åˆæˆå›¾åƒæ—¶é¢ä¸´æŒ‘æˆ˜ï¼Œå› ä¸ºåˆ›å»ºæœ‰æ•ˆçš„æç¤ºå’Œè§†è§‰å‚è€ƒå­˜åœ¨å›°éš¾ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä½¿ç”¨å¯æ§æ‰©æ•£æ¨¡å‹çš„è¯­ä¹‰åˆ†å‰²æœ‰æ•ˆæ•°æ®å¢å¼ºç®¡é“ã€‚æˆ‘ä»¬æå‡ºçš„æ–¹æ³•åŒ…æ‹¬ä½¿ç”¨â€œç±»æç¤ºé™„åŠ â€å’Œâ€œè§†è§‰å…ˆéªŒæ··åˆâ€è¿›è¡Œé«˜æ•ˆæç¤ºç”Ÿæˆï¼Œä»¥æé«˜å¯¹çœŸå®å›¾åƒä¸­æ ‡è®°ç±»çš„æ³¨æ„åŠ›ï¼Œä½¿ç®¡é“èƒ½å¤Ÿåœ¨ä¿ç•™åˆ†å‰²æ ‡è®°ç±»ç»“æ„çš„åŒæ—¶ï¼Œç”Ÿæˆç²¾ç¡®æ•°é‡çš„å¢å¼ºå›¾åƒã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å®ç°äº†â€œç±»åˆ«å¹³è¡¡ç®—æ³•â€ï¼Œä»¥ç¡®ä¿åœ¨åˆå¹¶åˆæˆå›¾åƒå’ŒåŸå§‹å›¾åƒæ—¶ï¼Œè®­ç»ƒæ•°æ®é›†ä¿æŒå¹³è¡¡ã€‚åœ¨PASCAL VOCæ•°æ®é›†ä¸Šçš„è¯„ä¼°è¡¨æ˜ï¼Œæˆ‘ä»¬çš„ç®¡é“åœ¨ç”Ÿæˆé«˜è´¨é‡åˆæˆå›¾åƒè¿›è¡Œè¯­ä¹‰åˆ†å‰²æ–¹é¢éå¸¸æœ‰æ•ˆã€‚æˆ‘ä»¬çš„ä»£ç ä½äºï¼š<a target="_blank" rel="noopener" href="https://github.com/chequanghuy/Enhanced-Generative-Data-Augmentation-for-Semantic-Segmentation-via-Stronger-Guidance%E3%80%82">https://github.com/chequanghuy/Enhanced-Generative-Data-Augmentation-for-Semantic-Segmentation-via-Stronger-Guidanceã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2409.06002v3">PDF</a> Accepted to ICPRAM 2025</p>
<p><strong>Summary</strong><br>æ•°æ®å¢å¼ºå¯¹äºåƒç´ çº§æ ‡æ³¨ä»»åŠ¡å¦‚è¯­ä¹‰åˆ†å‰²è‡³å…³é‡è¦ï¼Œä¼ ç»Ÿæ–¹æ³•ç¼ºä¹å¤šæ ·æ€§å¹¶æ— æ³•æ”¹å˜é«˜çº§è¯­ä¹‰å±æ€§ã€‚ä¸ºæ­¤ï¼Œé‡‡ç”¨ç”Ÿæˆæ¨¡å‹è¿›è¡Œæ•°æ®å¢å¼ºæˆä¸ºæœ‰æ•ˆçš„è§£å†³æ–¹æ¡ˆã€‚æœ¬ç ”ç©¶æå‡ºäº†ä¸€ç§ä½¿ç”¨å¯æ§æ‰©æ•£æ¨¡å‹è¿›è¡Œæ•°æ®å¢å¼ºçš„æœ‰æ•ˆæ–¹æ³•ï¼Œåˆ©ç”¨â€œClass-Prompt Appendingâ€å’Œâ€œVisual Prior Blendingâ€ç­‰æŠ€æœ¯å¢å¼ºå…³æ³¨æ ‡æ³¨ç±»åˆ«å¹¶ç”Ÿæˆç²¾ç¡®çš„å›¾åƒæ•°é‡åŒæ—¶ä¿æŒæ ‡æ³¨ç»“æ„çš„å®Œæ•´æ€§ã€‚å®ç°ç±»å¹³è¡¡ç®—æ³•ç¡®ä¿åˆå¹¶æ•°æ®é›†æ—¶å¹³è¡¡æ€§ã€‚åœ¨PASCAL VOCæ•°æ®é›†ä¸Šçš„è¯„ä¼°æ˜¾ç¤ºæœ¬æ–¹æ³•æœ‰æ•ˆç”Ÿæˆé«˜è´¨é‡å›¾åƒã€‚ç›¸å…³ä»£ç å¯åœ¨æä¾›çš„URLé“¾æ¥ä¸­æŸ¥é˜…ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2409.06002">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-7fbdaf4c72fdcbe13e289d445d413692.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-ca6f23b95f20add47a4d0515e8947a89.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-91dd43e3d48806df3e2fa23090a86993.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-9b3c65fb7936a29984cc349b14779630.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-5a097a22cba61b6668399667be306c49.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c298870b43ce121bb270ff9dab12e16e.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="SUSTechGAN-Image-Generation-for-Object-Detection-in-Adverse-Conditions-of-Autonomous-Driving"><a href="#SUSTechGAN-Image-Generation-for-Object-Detection-in-Adverse-Conditions-of-Autonomous-Driving" class="headerlink" title="SUSTechGAN: Image Generation for Object Detection in Adverse Conditions   of Autonomous Driving"></a>SUSTechGAN: Image Generation for Object Detection in Adverse Conditions   of Autonomous Driving</h2><p><strong>Authors:Gongjin Lan, Yang Peng, Qi Hao, Chengzhong Xu</strong></p>
<p>Autonomous driving significantly benefits from data-driven deep neural networks. However, the data in autonomous driving typically fits the long-tailed distribution, in which the critical driving data in adverse conditions is hard to collect. Although generative adversarial networks (GANs) have been applied to augment data for autonomous driving, generating driving images in adverse conditions is still challenging. In this work, we propose a novel framework, SUSTechGAN, with customized dual attention modules, multi-scale generators, and a novel loss function to generate driving images for improving object detection of autonomous driving in adverse conditions. We test the SUSTechGAN and the well-known GANs to generate driving images in adverse conditions of rain and night and apply the generated images to retrain object detection networks. Specifically, we add generated images into the training datasets to retrain the well-known YOLOv5 and evaluate the improvement of the retrained YOLOv5 for object detection in adverse conditions. The experimental results show that the generated driving images by our SUSTechGAN significantly improved the performance of retrained YOLOv5 in rain and night conditions, which outperforms the well-known GANs. The open-source code, video description and datasets are available on the page 1 to facilitate image generation development in autonomous driving under adverse conditions. </p>
<blockquote>
<p>è‡ªåŠ¨é©¾é©¶å—ç›Šäºæ•°æ®é©±åŠ¨çš„æ·±åº¦ç¥ç»ç½‘ç»œã€‚ç„¶è€Œï¼Œè‡ªåŠ¨é©¾é©¶ä¸­çš„æ•°æ®é€šå¸¸ç¬¦åˆé•¿å°¾åˆ†å¸ƒï¼Œå…¶ä¸­åœ¨æ¶åŠ£æ¡ä»¶ä¸‹çš„å…³é”®é©¾é©¶æ•°æ®æ”¶é›†èµ·æ¥éå¸¸å›°éš¾ã€‚è™½ç„¶ç”Ÿæˆå¯¹æŠ—ç½‘ç»œï¼ˆGANsï¼‰å·²è¢«åº”ç”¨äºå¢å¼ºè‡ªåŠ¨é©¾é©¶çš„æ•°æ®ï¼Œä½†åœ¨æ¶åŠ£æ¡ä»¶ä¸‹ç”Ÿæˆé©¾é©¶å›¾åƒä»ç„¶å…·æœ‰æŒ‘æˆ˜æ€§ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°å‹æ¡†æ¶SUSTechGANï¼Œå®ƒå…·æœ‰å®šåˆ¶çš„åŒé‡æ³¨æ„åŠ›æ¨¡å—ã€å¤šå°ºåº¦ç”Ÿæˆå™¨å’Œæ–°å‹æŸå¤±å‡½æ•°ï¼Œç”¨äºç”Ÿæˆé©¾é©¶å›¾åƒï¼Œä»¥æé«˜æ¶åŠ£æ¡ä»¶ä¸‹çš„è‡ªåŠ¨é©¾é©¶ç›®æ ‡æ£€æµ‹æ€§èƒ½ã€‚æˆ‘ä»¬å¯¹SUSTechGANå’Œè‘—åçš„GANsè¿›è¡Œäº†æµ‹è¯•ï¼Œä»¥ç”Ÿæˆé›¨å¤©å’Œå¤œæ™šçš„é©¾é©¶å›¾åƒï¼Œå¹¶å°†ç”Ÿæˆçš„å›¾åƒç”¨äºé‡æ–°è®­ç»ƒç›®æ ‡æ£€æµ‹ç½‘ç»œã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬å°†ç”Ÿæˆçš„å›¾åƒæ·»åŠ åˆ°è®­ç»ƒæ•°æ®é›†ä¸­ï¼Œä»¥é‡æ–°è®­ç»ƒçŸ¥åçš„YOLOv5ç½‘ç»œï¼Œå¹¶è¯„ä¼°é‡æ–°è®­ç»ƒçš„YOLOv5åœ¨æ¶åŠ£æ¡ä»¶ä¸‹çš„ç›®æ ‡æ£€æµ‹æ€§èƒ½çš„æå‡æƒ…å†µã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„SUSTechGANç”Ÿæˆçš„é©¾é©¶å›¾åƒæ˜¾è‘—æé«˜äº†é‡æ–°è®­ç»ƒçš„YOLOv5åœ¨é›¨å¤©å’Œå¤œæ™šæ¡ä»¶ä¸‹çš„æ€§èƒ½ï¼Œä¸”ä¼˜äºå·²çŸ¥çš„GANsã€‚ä¸ºäº†æ–¹ä¾¿åœ¨æ¶åŠ£æ¡ä»¶ä¸‹è‡ªåŠ¨é©¾é©¶çš„å›¾åƒç”Ÿæˆå¼€å‘ï¼Œå¼€æºä»£ç ã€è§†é¢‘æè¿°å’Œæ•°æ®é›†å‡å¯åœ¨ç¬¬1é¡µä¸Šæ‰¾åˆ°ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2408.01430v2">PDF</a> 10 pages, 9 figures</p>
<p><strong>Summary</strong></p>
<p>æ•°æ®é©±åŠ¨æ·±åº¦ç¥ç»ç½‘ç»œä¸ºè‡ªåŠ¨é©¾é©¶å¸¦æ¥äº†æ˜¾è‘—çš„åˆ©ç›Šï¼Œä½†ç”±äºå…³é”®é©¾é©¶æ•°æ®çš„æ”¶é›†å›°éš¾ï¼Œå¦‚æ¶åŠ£ç¯å¢ƒä¸‹çš„æ•°æ®ï¼Œå®é™…åº”ç”¨ä¸­ä»å­˜åœ¨æŒ‘æˆ˜ã€‚é’ˆå¯¹è¿™ä¸€é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°å‹æ¡†æ¶SUSTechGANï¼ŒåŒ…å«å®šåˆ¶åŒ–çš„åŒé‡æ³¨æ„åŠ›æ¨¡å—ã€å¤šå°ºåº¦ç”Ÿæˆå™¨å’Œæ–°å‹æŸå¤±å‡½æ•°ï¼Œä»¥ç”Ÿæˆæ¶åŠ£ç¯å¢ƒä¸‹çš„é©¾é©¶å›¾åƒï¼Œæ”¹å–„è‡ªåŠ¨é©¾é©¶çš„ç›®æ ‡æ£€æµ‹æ€§èƒ½ã€‚å®éªŒè¯æ˜ï¼Œä½¿ç”¨SUSTechGANç”Ÿæˆçš„å›¾åƒèƒ½æ˜¾è‘—æå‡YOLOv5åœ¨æ¶åŠ£ç¯å¢ƒä¸‹çš„æ£€æµ‹æ€§èƒ½ï¼Œä¼˜äºå…¶ä»–çŸ¥åGANsã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>è‡ªåŠ¨é©¾é©¶å—ç›Šäºæ•°æ®é©±åŠ¨çš„æ·±åº¦ç¥ç»ç½‘ç»œï¼Œä½†æ¶åŠ£ç¯å¢ƒä¸‹çš„æ•°æ®æ”¶é›†æ˜¯æŒ‘æˆ˜ã€‚</li>
<li>SUSTechGANæ¡†æ¶è¢«æå‡ºï¼ŒåŒ…å«åŒé‡æ³¨æ„åŠ›æ¨¡å—ã€å¤šå°ºåº¦ç”Ÿæˆå™¨å’Œæ–°å‹æŸå¤±å‡½æ•°ã€‚</li>
<li>SUSTechGANèƒ½ç”Ÿæˆæ¶åŠ£ç¯å¢ƒä¸‹çš„é©¾é©¶å›¾åƒï¼Œå¦‚é›¨å¤©å’Œå¤œæ™šã€‚</li>
<li>ä½¿ç”¨ç”Ÿæˆå›¾åƒé‡è®­YOLOv5ï¼Œåœ¨æ¶åŠ£ç¯å¢ƒä¸‹æ˜¾è‘—æå‡ç›®æ ‡æ£€æµ‹æ€§èƒ½ã€‚</li>
<li>SUSTechGANæ€§èƒ½ä¼˜äºå…¶ä»–çŸ¥åGANsã€‚</li>
<li>å¼€æ”¾æºä»£ç ã€è§†é¢‘æè¿°å’Œæ•°æ®é›†ï¼Œä¾¿äºè‡ªåŠ¨é©¾é©¶æ¶åŠ£ç¯å¢ƒä¸‹çš„å›¾åƒç”Ÿæˆå¼€å‘ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2408.01430">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-71fbd0807d6125a79bb6fad1dd2d9ed8.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-79cb91f79ce8ba808f6f8ec8ee38ef59.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f8d49c6c97ef85390475e96011df3ed6.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-33095258c062129b7a447afdf1d299e9.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-fa1fa71e3105a754ecc19056620d8d54.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-78add10e5da2b098fc5bd7c80782b565.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-41240ffa89b085cb91772f2c6f4a18b6.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-2c838ba300add13cdf195c8ad037cfb0.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2024-12-25/%E6%A3%80%E6%B5%8B_%E5%88%86%E5%89%B2_%E8%B7%9F%E8%B8%AA/">https://kedreamix.github.io/Talk2Paper/Paper/2024-12-25/%E6%A3%80%E6%B5%8B_%E5%88%86%E5%89%B2_%E8%B7%9F%E8%B8%AA/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/%E6%A3%80%E6%B5%8B-%E5%88%86%E5%89%B2-%E8%B7%9F%E8%B8%AA/">
                                    <span class="chip bg-color">æ£€æµ‹/åˆ†å‰²/è·Ÿè¸ª</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2024-12-25/%E4%BA%BA%E8%84%B8%E7%9B%B8%E5%85%B3/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-e8fa632daabb9a31309d1873c622815c.jpg" class="responsive-img" alt="äººè„¸ç›¸å…³">
                        
                        <span class="card-title">äººè„¸ç›¸å…³</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            äººè„¸ç›¸å…³ æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2024-12-25  ErasableMask A Robust and Erasable Privacy Protection Scheme against   Black-box Face Recognition Models
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2024-12-25
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/%E4%BA%BA%E8%84%B8%E7%9B%B8%E5%85%B3/" class="post-category">
                                    äººè„¸ç›¸å…³
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/%E4%BA%BA%E8%84%B8%E7%9B%B8%E5%85%B3/">
                        <span class="chip bg-color">äººè„¸ç›¸å…³</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2024-12-25/Vision%20Transformer/">
                    <div class="card-image">
                        
                        <img src="https://pica.zhimg.com/v2-35224d9cdd3096a810256c323eb9f00f.jpg" class="responsive-img" alt="Vision Transformer">
                        
                        <span class="card-title">Vision Transformer</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Vision Transformer æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2024-12-25  Kernel-Aware Graph Prompt Learning for Few-Shot Anomaly Detection
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2024-12-25
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Vision-Transformer/" class="post-category">
                                    Vision Transformer
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Vision-Transformer/">
                        <span class="chip bg-color">Vision Transformer</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">24474.2k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
