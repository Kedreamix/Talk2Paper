<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="TTS">
    <meta name="description" content="TTS æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2024-12-25  VERSA A Versatile Evaluation Toolkit for Speech, Audio, and Music">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>TTS | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://picx.zhimg.com/v2-46660c58a4177a91d3aa3f203cdd12d5.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">TTS</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/TTS/">
                                <span class="chip bg-color">TTS</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/TTS/" class="post-category">
                                TTS
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2024-12-25
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2024-12-25
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    8.5k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    34 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2024-12-25-æ›´æ–°"><a href="#2024-12-25-æ›´æ–°" class="headerlink" title="2024-12-25 æ›´æ–°"></a>2024-12-25 æ›´æ–°</h1><h2 id="VERSA-A-Versatile-Evaluation-Toolkit-for-Speech-Audio-and-Music"><a href="#VERSA-A-Versatile-Evaluation-Toolkit-for-Speech-Audio-and-Music" class="headerlink" title="VERSA: A Versatile Evaluation Toolkit for Speech, Audio, and Music"></a>VERSA: A Versatile Evaluation Toolkit for Speech, Audio, and Music</h2><p><strong>Authors:Jiatong Shi, Hye-jin Shim, Jinchuan Tian, Siddhant Arora, Haibin Wu, Darius Petermann, Jia Qi Yip, You Zhang, Yuxun Tang, Wangyou Zhang, Dareen Safar Alharthi, Yichen Huang, Koichi Saito, Jionghao Han, Yiwen Zhao, Chris Donahue, Shinji Watanabe</strong></p>
<p>In this work, we introduce VERSA, a unified and standardized evaluation toolkit designed for various speech, audio, and music signals. The toolkit features a Pythonic interface with flexible configuration and dependency control, making it user-friendly and efficient. With full installation, VERSA offers 63 metrics with 711 metric variations based on different configurations. These metrics encompass evaluations utilizing diverse external resources, including matching and non-matching reference audio, text transcriptions, and text captions. As a lightweight yet comprehensive toolkit, VERSA is versatile to support the evaluation of a wide range of downstream scenarios. To demonstrate its capabilities, this work highlights example use cases for VERSA, including audio coding, speech synthesis, speech enhancement, singing synthesis, and music generation. The toolkit is available at <a target="_blank" rel="noopener" href="https://github.com/shinjiwlab/versa">https://github.com/shinjiwlab/versa</a>. </p>
<blockquote>
<p>åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬ä»‹ç»äº†VERSAï¼Œè¿™æ˜¯ä¸€ä¸ªç»Ÿä¸€æ ‡å‡†åŒ–çš„è¯„ä¼°å·¥å…·åŒ…ï¼Œç”¨äºå„ç§è¯­éŸ³ã€éŸ³é¢‘å’ŒéŸ³ä¹ä¿¡å·ã€‚è¯¥å·¥å…·åŒ…å…·æœ‰Pythoné£æ ¼çš„æ¥å£ï¼Œå…·æœ‰çµæ´»çš„é…ç½®å’Œä¾èµ–æ§åˆ¶ï¼Œä½¿å…¶å‹å¥½é«˜æ•ˆã€‚åœ¨å®Œå…¨å®‰è£…åï¼ŒVERSAæä¾›åŸºäºä¸åŒé…ç½®çš„63ä¸ªæŒ‡æ ‡ï¼Œå…±è®¡æœ‰711ç§æŒ‡æ ‡å˜åŒ–ã€‚è¿™äº›æŒ‡æ ‡åŒ…æ‹¬åˆ©ç”¨å„ç§å¤–éƒ¨èµ„æºçš„è¯„ä¼°ï¼ŒåŒ…æ‹¬åŒ¹é…å’ŒéåŒ¹é…çš„å‚è€ƒéŸ³é¢‘ã€æ–‡æœ¬è½¬å½•å’Œæ–‡æœ¬æè¿°ã€‚ä½œä¸ºä¸€ä¸ªè½»ä¾¿è€Œå…¨é¢çš„å·¥å…·åŒ…ï¼ŒVERSAèƒ½å¤Ÿæ”¯æŒå¯¹å„ç§ä¸‹æ¸¸åœºæ™¯çš„è¯„ä¼°ã€‚ä¸ºäº†å±•ç¤ºå…¶èƒ½åŠ›ï¼Œè¿™é¡¹å·¥ä½œçªå‡ºäº†VERSAçš„ä¸€äº›ç”¨ä¾‹ç¤ºä¾‹ï¼ŒåŒ…æ‹¬éŸ³é¢‘ç¼–ç ã€è¯­éŸ³åˆæˆã€è¯­éŸ³å¢å¼ºã€æ­Œå”±åˆæˆå’ŒéŸ³ä¹ç”Ÿæˆã€‚è¯¥å·¥å…·åŒ…å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/shinjiwlab/versa%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/shinjiwlab/versaæ‰¾åˆ°ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.17667v1">PDF</a> </p>
<p><strong>Summary</strong><br>     æœ¬æ–‡ä»‹ç»äº†VERSAè¿™ä¸€ç»Ÿä¸€æ ‡å‡†åŒ–çš„è¯„ä¼°å·¥å…·åŒ…ï¼Œé€‚ç”¨äºå„ç§è¯­éŸ³ã€éŸ³é¢‘å’ŒéŸ³ä¹ä¿¡å·çš„è¯„ä¼°ã€‚å®ƒå…·å¤‡Pythonicæ¥å£ï¼Œé…ç½®çµæ´»ï¼Œä¾èµ–æ§åˆ¶æ€§å¼ºï¼Œä½¿ç”¨æ–¹ä¾¿ä¸”æ•ˆç‡é«˜ã€‚VERSAæä¾›63ç§åº¦é‡æŒ‡æ ‡ï¼ŒåŸºäºä¸åŒé…ç½®æœ‰711ç§åº¦é‡æŒ‡æ ‡å˜åŒ–ã€‚å®ƒèƒ½åˆ©ç”¨åŒ…æ‹¬åŒ¹é…å’ŒéåŒ¹é…å‚è€ƒéŸ³é¢‘ã€æ–‡æœ¬è½¬å½•å’Œæ–‡æœ¬å­—å¹•åœ¨å†…çš„å¤–éƒ¨èµ„æºè¿›è¡Œè¯„ä»·ã€‚ä½œä¸ºè½»ä¾¿è€Œå…¨é¢çš„å·¥å…·åŒ…ï¼ŒVERSAæ”¯æŒå„ç§ä¸‹æ¸¸åœºæ™¯çš„è¯„ä¼°ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>VERSAæ˜¯ä¸€ä¸ªç»Ÿä¸€æ ‡å‡†åŒ–çš„è¯„ä¼°å·¥å…·åŒ…ï¼Œé€‚ç”¨äºè¯­éŸ³ã€éŸ³é¢‘å’ŒéŸ³ä¹ä¿¡å·çš„è¯„ä¼°ã€‚</li>
<li>VERSAå…·å¤‡Pythonicæ¥å£ï¼Œå…·æœ‰çµæ´»çš„é…ç½®å’Œä¾èµ–æ§åˆ¶ã€‚</li>
<li>VERSAæä¾›å¤šç§åº¦é‡æŒ‡æ ‡ï¼Œå¯æ ¹æ®ä¸åŒé…ç½®äº§ç”Ÿä¸åŒçš„åº¦é‡æŒ‡æ ‡å˜åŒ–ã€‚</li>
<li>VERSAèƒ½åˆ©ç”¨å¤–éƒ¨èµ„æºè¿›è¡Œè¯„ä»·ï¼ŒåŒ…æ‹¬åŒ¹é…å’ŒéåŒ¹é…å‚è€ƒéŸ³é¢‘ã€æ–‡æœ¬è½¬å½•å’Œæ–‡æœ¬å­—å¹•ã€‚</li>
<li>VERSAæ”¯æŒå¤šç§ä¸‹æ¸¸åœºæ™¯çš„è¯„ä¼°ï¼Œå¦‚éŸ³é¢‘ç¼–ç ã€è¯­éŸ³åˆæˆã€è¯­éŸ³å¢å¼ºã€æ­Œå”±åˆæˆå’ŒéŸ³ä¹ç”Ÿæˆç­‰ã€‚</li>
<li>VERSAå·¥å…·åŒ…å·²å…¬å¼€å‘å¸ƒï¼Œå¯ä¾›å…¬ä¼—ä½¿ç”¨ã€‚</li>
<li>VERSAå·¥å…·åŒ…ç½‘å€ä¸º<a target="_blank" rel="noopener" href="https://github.com/shinjiwlab/versa%E3%80%82">https://github.com/shinjiwlab/versaã€‚</a></li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.17667">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-ca5810467e21064aad7ef23ae592e12a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f43ca7b05cd368a4682ed95008e06032.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-105333784beee2cd2b863f3f3fd741b3.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-00d391b42d6acbe6ed460f7bb19e84c9.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-081514bb790a0108b7e0dde5a0b7d40d.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="Incremental-Disentanglement-for-Environment-Aware-Zero-Shot-Text-to-Speech-Synthesis"><a href="#Incremental-Disentanglement-for-Environment-Aware-Zero-Shot-Text-to-Speech-Synthesis" class="headerlink" title="Incremental Disentanglement for Environment-Aware Zero-Shot   Text-to-Speech Synthesis"></a>Incremental Disentanglement for Environment-Aware Zero-Shot   Text-to-Speech Synthesis</h2><p><strong>Authors:Ye-Xin Lu, Hui-Peng Du, Zheng-Yan Sheng, Yang Ai, Zhen-Hua Ling</strong></p>
<p>This paper proposes an Incremental Disentanglement-based Environment-Aware zero-shot text-to-speech (TTS) method, dubbed IDEA-TTS, that can synthesize speech for unseen speakers while preserving the acoustic characteristics of a given environment reference speech. IDEA-TTS adopts VITS as the TTS backbone. To effectively disentangle the environment, speaker, and text factors, we propose an incremental disentanglement process, where an environment estimator is designed to first decompose the environmental spectrogram into an environment mask and an enhanced spectrogram. The environment mask is then processed by an environment encoder to extract environment embeddings, while the enhanced spectrogram facilitates the subsequent disentanglement of the speaker and text factors with the condition of the speaker embeddings, which are extracted from the environmental speech using a pretrained environment-robust speaker encoder. Finally, both the speaker and environment embeddings are conditioned into the decoder for environment-aware speech generation. Experimental results demonstrate that IDEA-TTS achieves superior performance in the environment-aware TTS task, excelling in speech quality, speaker similarity, and environmental similarity. Additionally, IDEA-TTS is also capable of the acoustic environment conversion task and achieves state-of-the-art performance. </p>
<blockquote>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºå¢é‡è§£è€¦çš„ç¯å¢ƒæ„ŸçŸ¥é›¶æ ·æœ¬æ–‡æœ¬åˆ°è¯­éŸ³ï¼ˆTTSï¼‰æ–¹æ³•ï¼Œç§°ä¸ºIDEA-TTSã€‚è¯¥æ–¹æ³•å¯ä»¥åœ¨æœªè§è¿‡è¯´è¯äººçš„æƒ…å†µä¸‹åˆæˆè¯­éŸ³ï¼ŒåŒæ—¶ä¿ç•™ç»™å®šç¯å¢ƒå‚è€ƒè¯­éŸ³çš„å£°å­¦ç‰¹å¾ã€‚IDEA-TTSé‡‡ç”¨VITSä½œä¸ºTTSçš„éª¨å¹²ã€‚ä¸ºäº†æœ‰æ•ˆåœ°è§£å¼€ç¯å¢ƒã€è¯´è¯äººå’Œæ–‡æœ¬å› ç´ ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªå¢é‡è§£è€¦è¿‡ç¨‹ï¼Œå…¶ä¸­è®¾è®¡äº†ä¸€ä¸ªç¯å¢ƒä¼°è®¡å™¨ï¼Œé¦–å…ˆå°†ç¯å¢ƒé¢‘è°±å›¾åˆ†è§£ä¸ºä¸€ä¸ªç¯å¢ƒæ©ç å’Œä¸€ä¸ªå¢å¼ºé¢‘è°±å›¾ã€‚ç„¶åï¼Œç¯å¢ƒæ©ç è¢«ç¯å¢ƒç¼–ç å™¨å¤„ç†ä»¥æå–ç¯å¢ƒåµŒå…¥ï¼Œè€Œå¢å¼ºé¢‘è°±å›¾æœ‰åŠ©äºåœ¨è¯´è¯äººåµŒå…¥çš„æ¡ä»¶ä¸‹è§£å¼€è¯´è¯äººå’Œæ–‡æœ¬å› ç´ ï¼Œè¿™äº›è¯´è¯äººåµŒå…¥æ˜¯ä»ç¯å¢ƒè¯­éŸ³ä¸­ä½¿ç”¨é¢„è®­ç»ƒçš„ç¯å¢ƒé²æ£’è¯´è¯äººç¼–ç å™¨æå–çš„ã€‚æœ€åï¼Œè¯´è¯äººå’Œç¯å¢ƒåµŒå…¥éƒ½è¢«è¾“å…¥åˆ°è§£ç å™¨ä¸­è¿›è¡Œç¯å¢ƒæ„ŸçŸ¥çš„è¯­éŸ³ç”Ÿæˆã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒIDEA-TTSåœ¨ç¯å¢ƒæ„ŸçŸ¥TTSä»»åŠ¡ä¸­å–å¾—äº†ä¼˜è¶Šçš„æ€§èƒ½ï¼Œåœ¨è¯­éŸ³è´¨é‡ã€è¯´è¯äººç›¸ä¼¼åº¦å’Œç¯å¢ƒç›¸ä¼¼åº¦æ–¹é¢è¡¨ç°å‡ºè‰²ã€‚æ­¤å¤–ï¼ŒIDEA-TTSè¿˜å…·å¤‡å£°éŸ³ç¯å¢ƒè½¬æ¢ä»»åŠ¡çš„èƒ½åŠ›ï¼Œå¹¶è¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.16977v1">PDF</a> Accepted to ICASSP 2025</p>
<p><strong>Summary</strong></p>
<p>è¯¥è®ºæ–‡æå‡ºäº†ä¸€ç§åŸºäºå¢é‡è§£è€¦çš„ç¯å¢ƒæ„ŸçŸ¥é›¶æ ·æœ¬æ–‡æœ¬è½¬è¯­éŸ³ï¼ˆTTSï¼‰æ–¹æ³•ï¼Œåä¸ºIDEA-TTSã€‚è¯¥æ–¹æ³•èƒ½å¤Ÿåˆæˆæœªè§è¿‡çš„è¯´è¯äººçš„è¯­éŸ³ï¼ŒåŒæ—¶ä¿ç•™ç»™å®šç¯å¢ƒå‚è€ƒè¯­éŸ³çš„å£°å­¦ç‰¹å¾ã€‚IDEA-TTSé‡‡ç”¨VITSä½œä¸ºTTSéª¨æ¶ï¼Œå¹¶é€šè¿‡å¢é‡è§£è€¦è¿‡ç¨‹æœ‰æ•ˆåœ°è§£å¼€ç¯å¢ƒã€è¯´è¯äººå’Œæ–‡æœ¬å› ç´ ã€‚é¦–å…ˆï¼Œç¯å¢ƒä¼°è®¡å™¨å°†ç¯å¢ƒé¢‘è°±å›¾åˆ†è§£ä¸ºç¯å¢ƒæ©ç å’Œå¢å¼ºé¢‘è°±å›¾ã€‚ç¯å¢ƒæ©ç ç»ç¯å¢ƒç¼–ç å™¨å¤„ç†æå–ç¯å¢ƒåµŒå…¥ï¼ŒåŒæ—¶å¢å¼ºé¢‘è°±å›¾åœ¨è¯´è¯äººåµŒå…¥çš„æ¡ä»¶ä¸‹ä¿ƒè¿›è¯´è¯äººå’Œæ–‡æœ¬å› ç´ çš„åç»­è§£è€¦ã€‚è¯´è¯äººåµŒå…¥æ˜¯ä»ç¯å¢ƒè¯­éŸ³ä¸­ä½¿ç”¨é¢„è®­ç»ƒçš„ç¯å¢ƒé²æ£’è¯´è¯äººç¼–ç å™¨æå–çš„ã€‚æœ€åï¼Œå°†è¯´è¯äººå’Œç¯å¢ƒåµŒå…¥ä½œä¸ºæ¡ä»¶è¾“å…¥åˆ°è§£ç å™¨ä¸­ï¼Œä»¥è¿›è¡Œç¯å¢ƒæ„ŸçŸ¥çš„è¯­éŸ³ç”Ÿæˆã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒIDEA-TTSåœ¨ç¯å¢ƒæ„ŸçŸ¥TTSä»»åŠ¡ä¸Šå–å¾—å“è¶Šæ€§èƒ½ï¼Œå°¤å…¶åœ¨è¯­éŸ³è´¨é‡ã€è¯´è¯äººç›¸ä¼¼æ€§å’Œç¯å¢ƒç›¸ä¼¼æ€§æ–¹é¢ã€‚æ­¤å¤–ï¼ŒIDEA-TTSè¿˜å…·å¤‡å£°éŸ³ç¯å¢ƒè½¬æ¢ä»»åŠ¡çš„èƒ½åŠ›ï¼Œå¹¶è¾¾åˆ°æœ€æ–°æŠ€æœ¯æ°´å¹³ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>IDEA-TTSæ˜¯ä¸€ç§ç¯å¢ƒæ„ŸçŸ¥çš„é›¶æ ·æœ¬æ–‡æœ¬è½¬è¯­éŸ³ï¼ˆTTSï¼‰æ–¹æ³•ï¼Œèƒ½åˆæˆæœªè§è¿‡çš„è¯´è¯äººçš„è¯­éŸ³ï¼ŒåŒæ—¶ä¿ç•™ç¯å¢ƒå‚è€ƒè¯­éŸ³çš„å£°å­¦ç‰¹å¾ã€‚</li>
<li>IDEA-TTSé‡‡ç”¨å¢é‡è§£è€¦è¿‡ç¨‹ï¼Œæœ‰æ•ˆè§£å¼€ç¯å¢ƒã€è¯´è¯äººå’Œæ–‡æœ¬å› ç´ ã€‚</li>
<li>ç¯å¢ƒä¼°è®¡å™¨èƒ½åˆ†è§£ç¯å¢ƒé¢‘è°±å›¾ï¼Œç”Ÿæˆç¯å¢ƒæ©ç å’Œå¢å¼ºé¢‘è°±å›¾ã€‚</li>
<li>ç¯å¢ƒç¼–ç å™¨å’Œè¯´è¯äººç¼–ç å™¨åˆ†åˆ«æå–ç¯å¢ƒåµŒå…¥å’Œè¯´è¯äººåµŒå…¥ã€‚</li>
<li>IDEA-TTSå°†è¯´è¯äººå’Œç¯å¢ƒåµŒå…¥ä½œä¸ºæ¡ä»¶è¾“å…¥åˆ°è§£ç å™¨ï¼Œè¿›è¡Œç¯å¢ƒæ„ŸçŸ¥çš„è¯­éŸ³ç”Ÿæˆã€‚</li>
<li>å®éªŒè¡¨æ˜ï¼ŒIDEA-TTSåœ¨ç¯å¢ƒæ„ŸçŸ¥TTSä»»åŠ¡ä¸Šè¡¨ç°å“è¶Šï¼Œå°¤å…¶åœ¨è¯­éŸ³è´¨é‡ã€è¯´è¯äººç›¸ä¼¼æ€§ã€ç¯å¢ƒç›¸ä¼¼æ€§æ–¹é¢ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.16977">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-281a5d9690211cc4f718b2a9083136cc.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c9eb575ca2c3c0ececfdc76e7e109d20.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-8437713026e3aa8d147083e65ab6fb41.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="Autoregressive-Speech-Synthesis-with-Next-Distribution-Prediction"><a href="#Autoregressive-Speech-Synthesis-with-Next-Distribution-Prediction" class="headerlink" title="Autoregressive Speech Synthesis with Next-Distribution Prediction"></a>Autoregressive Speech Synthesis with Next-Distribution Prediction</h2><p><strong>Authors:Xinfa Zhu, Wenjie Tian, Lei Xie</strong></p>
<p>We introduce KALL-E, a novel autoregressive (AR) language modeling approach with next-distribution prediction for text-to-speech (TTS) synthesis. Unlike existing methods, KALL-E directly models and predicts the continuous speech distribution conditioned on text without relying on VAE- or diffusion-based components. Specifically, we use WaveVAE to extract continuous speech distributions from waveforms instead of using discrete speech tokens. A single AR language model predicts these continuous speech distributions from text, with a Kullback-Leibler divergence loss as the constraint. Experimental results show that KALL-E outperforms open-source implementations of YourTTS, VALL-E, NaturalSpeech 2, and CosyVoice in terms of naturalness and speaker similarity in zero-shot TTS scenarios. Moreover, KALL-E demonstrates exceptional zero-shot capabilities in emotion and accent cloning. Importantly, KALL-E presents a more straightforward and effective paradigm for using continuous speech representations in TTS. Audio samples are available at: \url{<a target="_blank" rel="noopener" href="https://zxf-icpc.github.io/kalle/%7D">https://zxf-icpc.github.io/kalle/}</a>. </p>
<blockquote>
<p>æˆ‘ä»¬ä»‹ç»äº†KALL-Eï¼Œè¿™æ˜¯ä¸€ç§æ–°å‹çš„è‡ªå›å½’ï¼ˆARï¼‰è¯­è¨€å»ºæ¨¡æ–¹æ³•ï¼Œå…·æœ‰åŸºäºæ–‡æœ¬åˆ°è¯­éŸ³ï¼ˆTTSï¼‰åˆæˆçš„ä¸‹ä¸€ä¸ªåˆ†å¸ƒé¢„æµ‹åŠŸèƒ½ã€‚ä¸ç°æœ‰æ–¹æ³•ä¸åŒï¼ŒKALL-Eç›´æ¥å¯¹æ–‡æœ¬æ¡ä»¶ä¸‹çš„è¿ç»­è¯­éŸ³åˆ†å¸ƒè¿›è¡Œå»ºæ¨¡å’Œé¢„æµ‹ï¼Œæ— éœ€ä¾èµ–VAEæˆ–åŸºäºæ‰©æ•£çš„ç»„ä»¶ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬ä½¿ç”¨WaveVAEä»æ³¢å½¢ä¸­æå–è¿ç»­è¯­éŸ³åˆ†å¸ƒï¼Œè€Œä¸æ˜¯ä½¿ç”¨ç¦»æ•£è¯­éŸ³æ ‡è®°ã€‚ä¸€ä¸ªå•ä¸€çš„ARè¯­è¨€æ¨¡å‹æ ¹æ®æ–‡æœ¬é¢„æµ‹è¿™äº›è¿ç»­çš„è¯­éŸ³åˆ†å¸ƒï¼Œä»¥Kullback-Leibleræ•£åº¦æŸå¤±ä½œä¸ºçº¦æŸã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œåœ¨é›¶æ ·æœ¬TTSåœºæ™¯ä¸­ï¼ŒKALL-Eåœ¨è‡ªç„¶åº¦å’Œè¯´è¯äººç›¸ä¼¼æ€§æ–¹é¢ä¼˜äºYourTTSã€VALL-Eã€NaturalSpeech 2å’ŒCosyVoiceçš„å¼€æºå®ç°ã€‚æ­¤å¤–ï¼ŒKALL-Eåœ¨æƒ…æ„Ÿå’Œå£éŸ³å…‹éš†æ–¹é¢è¡¨ç°å‡ºå‡ºè‰²çš„é›¶æ ·æœ¬èƒ½åŠ›ã€‚é‡è¦çš„æ˜¯ï¼ŒKALL-Eä¸ºåœ¨TTSä¸­ä½¿ç”¨è¿ç»­è¯­éŸ³è¡¨ç¤ºæä¾›äº†æ›´ç®€å•æœ‰æ•ˆçš„èŒƒå¼ã€‚éŸ³é¢‘æ ·æœ¬å¯åœ¨ï¼š[<a target="_blank" rel="noopener" href="https://zxf-icpc.github.io/kalle/]%E8%8E%B7%E5%8F%96%E3%80%82">https://zxf-icpc.github.io/kalle/]è·å–ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.16846v1">PDF</a> Technical report, work in progress</p>
<p><strong>Summary</strong><br>     æœ¬æ–‡ä»‹ç»äº†KALL-Eï¼Œä¸€ç§æ–°å‹çš„ç”¨äºæ–‡æœ¬è½¬è¯­éŸ³ï¼ˆTTSï¼‰åˆæˆçš„è‡ªå›å½’ï¼ˆARï¼‰è¯­è¨€å»ºæ¨¡æ–¹æ³•ã€‚è¯¥æ–¹æ³•ç›´æ¥å¯¹æ–‡æœ¬æ¡ä»¶ä¸‹çš„è¿ç»­è¯­éŸ³åˆ†å¸ƒè¿›è¡Œå»ºæ¨¡å’Œé¢„æµ‹ï¼Œæ— éœ€ä¾èµ–VAEæˆ–æ‰©æ•£æ¨¡å‹ã€‚ä½¿ç”¨WaveVAEä»æ³¢å½¢ä¸­æå–è¿ç»­è¯­éŸ³åˆ†å¸ƒï¼Œå¹¶ç”±å•ä¸€ARè¯­è¨€æ¨¡å‹é¢„æµ‹è¿™äº›åˆ†å¸ƒï¼Œä»¥Kullback-Leibleræ•£åº¦æŸå¤±ä½œä¸ºçº¦æŸã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒKALL-Eåœ¨è‡ªç„¶åº¦å’Œè¯´è¯äººç›¸ä¼¼æ€§æ–¹é¢ä¼˜äºå…¶ä»–å¼€æºTTSå®ç°ï¼Œå¹¶å±•ç°å‡ºå“è¶Šçš„é›¶æ ·æœ¬æƒ…æ„Ÿå’Œå£éŸ³æ¨¡ä»¿èƒ½åŠ›ã€‚æ­¤å¤–ï¼ŒKALL-Eä¸ºTTSä¸­ä½¿ç”¨è¿ç»­è¯­éŸ³è¡¨ç¤ºæä¾›äº†æ›´ç®€æ´æœ‰æ•ˆçš„èŒƒå¼ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>KALL-Eæ˜¯ä¸€ç§æ–°å‹çš„æ–‡æœ¬è½¬è¯­éŸ³ï¼ˆTTSï¼‰åˆæˆæ–¹æ³•ï¼Œé‡‡ç”¨è‡ªå›å½’ï¼ˆARï¼‰è¯­è¨€å»ºæ¨¡æŠ€æœ¯ã€‚</li>
<li>ä¸ä¼ ç»Ÿæ–¹æ³•ä¸åŒï¼ŒKALL-Eç›´æ¥é¢„æµ‹æ–‡æœ¬æ¡ä»¶ä¸‹çš„è¿ç»­è¯­éŸ³åˆ†å¸ƒï¼Œæ— éœ€ä¾èµ–VAEæˆ–æ‰©æ•£æ¨¡å‹ã€‚</li>
<li>KALL-Eä½¿ç”¨WaveVAEä»æ³¢å½¢ä¸­æå–è¿ç»­è¯­éŸ³åˆ†å¸ƒã€‚</li>
<li>KALL-Eåœ¨è‡ªç„¶åº¦å’Œè¯´è¯äººç›¸ä¼¼æ€§æ–¹é¢è¡¨ç°å‡ºä¼˜å¼‚æ€§èƒ½ï¼Œä¼˜äºå…¶ä»–å¼€æºTTSå®ç°ã€‚</li>
<li>KALL-Eå±•ç°å‡ºé›¶æ ·æœ¬æƒ…æ„Ÿå’Œå£éŸ³æ¨¡ä»¿èƒ½åŠ›ã€‚</li>
<li>KALL-Eä¸ºTTSä¸­çš„è¿ç»­è¯­éŸ³è¡¨ç¤ºæä¾›äº†ç®€æ´æœ‰æ•ˆçš„èŒƒå¼ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.16846">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-fe269f8abdb949147d2793d77a5f4ee1.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-2d21003a0e48ef2fa88626ea3b3c0f63.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-bdd91cd9027a0ffae81fcec129b8cdb3.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-25e0b9d9457f25b72ec15db514170b9e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e679efd03e9fa4af064d827be73db8d8.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="Interleaved-Speech-Text-Language-Models-are-Simple-Streaming-Text-to-Speech-Synthesizers"><a href="#Interleaved-Speech-Text-Language-Models-are-Simple-Streaming-Text-to-Speech-Synthesizers" class="headerlink" title="Interleaved Speech-Text Language Models are Simple Streaming Text to   Speech Synthesizers"></a>Interleaved Speech-Text Language Models are Simple Streaming Text to   Speech Synthesizers</h2><p><strong>Authors:Yifan Yang, Ziyang Ma, Shujie Liu, Jinyu Li, Hui Wang, Lingwei Meng, Haiyang Sun, Yuzhe Liang, Ruiyang Xu, Yuxuan Hu, Yan Lu, Rui Zhao, Xie Chen</strong></p>
<p>This paper introduces Interleaved Speech-Text Language Model (IST-LM) for streaming zero-shot Text-to-Speech (TTS). Unlike many previous approaches, IST-LM is directly trained on interleaved sequences of text and speech tokens with a fixed ratio, eliminating the need for additional efforts in duration prediction and grapheme-to-phoneme alignment. The ratio of text chunk size to speech chunk size is crucial for the performance of IST-LM. To explore this, we conducted a comprehensive series of statistical analyses on the training data and performed correlation analysis with the final performance, uncovering several key factors: 1) the distance between speech tokens and their corresponding text tokens, 2) the number of future text tokens accessible to each speech token, and 3) the frequency of speech tokens precedes their corresponding text tokens. Experimental results demonstrate how to achieve an optimal streaming TTS system without complicated engineering optimization, which has a limited gap with the non-streaming system. IST-LM is conceptually simple and empirically powerful, paving the way for streaming TTS with minimal overhead while largely maintaining performance, showcasing broad prospects coupled with real-time text stream from LLMs. </p>
<blockquote>
<p>æœ¬æ–‡ä»‹ç»äº†ç”¨äºæµå¼é›¶ç‚¹å‡»æ–‡æœ¬è½¬è¯­éŸ³ï¼ˆTTSï¼‰çš„äº¤ç»‡è¯­éŸ³æ–‡æœ¬è¯­è¨€æ¨¡å‹ï¼ˆIST-LMï¼‰ã€‚ä¸åŒäºè®¸å¤šä¹‹å‰çš„æ–¹æ³•ï¼ŒIST-LMç›´æ¥åœ¨å›ºå®šæ¯”ä¾‹çš„äº¤ç»‡æ–‡æœ¬å’Œè¯­éŸ³ä»¤ç‰Œåºåˆ—ä¸Šè¿›è¡Œè®­ç»ƒï¼Œæ— éœ€åœ¨æŒç»­æ—¶é—´é¢„æµ‹å’Œå­—æ¯åˆ°éŸ³ç´ çš„å¯¹é½æ–¹é¢ä»˜å‡ºé¢å¤–çš„åŠªåŠ›ã€‚æ–‡æœ¬å—å¤§å°ä¸è¯­éŸ³å—å¤§å°çš„æ¯”ä¾‹å¯¹IST-LMçš„æ€§èƒ½è‡³å…³é‡è¦ã€‚ä¸ºäº†æ¢ç©¶è¿™ä¸€ç‚¹ï¼Œæˆ‘ä»¬å¯¹è®­ç»ƒæ•°æ®è¿›è¡Œäº†å…¨é¢çš„ç»Ÿè®¡åˆ†æï¼Œå¹¶ä¸æœ€ç»ˆæ€§èƒ½è¿›è¡Œäº†ç›¸å…³æ€§åˆ†æï¼Œå‘ç°äº†å‡ ä¸ªå…³é”®å› ç´ ï¼š1ï¼‰è¯­éŸ³ä»¤ç‰Œä¸å…¶å¯¹åº”æ–‡æœ¬ä»¤ç‰Œä¹‹é—´çš„è·ç¦»ï¼›2ï¼‰æ¯ä¸ªè¯­éŸ³ä»¤ç‰Œå¯è®¿é—®çš„æœªæ¥æ–‡æœ¬ä»¤ç‰Œçš„æ•°é‡ï¼›3ï¼‰è¯­éŸ³ä»¤ç‰Œå…ˆäºå…¶å¯¹åº”è¯¥æ–‡æœ¬ä»¤ç‰Œå‡ºç°çš„é¢‘ç‡ã€‚å®éªŒç»“æœå±•ç¤ºäº†å¦‚ä½•æ„å»ºä¸€ä¸ªæ— éœ€å¤æ‚å·¥ç¨‹ä¼˜åŒ–çš„æœ€ä½³æµå¼TTSç³»ç»Ÿï¼Œå…¶ä¸éæµå¼ç³»ç»Ÿçš„å·®è·æœ‰é™ã€‚IST-LMæ¦‚å¿µç®€å•ï¼Œç»éªŒå¼ºå¤§ï¼Œä¸ºæµå¼TTSé“ºå¹³äº†é“è·¯ï¼Œåœ¨ä¿æŒæ€§èƒ½çš„åŒæ—¶å®ç°äº†æœ€å°çš„é¢å¤–å¼€é”€ï¼Œå±•ç¤ºäº†ä¸æ¥è‡ªå¤§å‹è¯­è¨€æ¨¡å‹çš„å®æ—¶æ–‡æœ¬æµç›¸ç»“åˆçš„å¹¿é˜”å‰æ™¯ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.16102v2">PDF</a> Submitted to ICME 2025</p>
<p><strong>Summary</strong></p>
<p>æœ¬è®ºæ–‡ä»‹ç»äº†ç”¨äºæµå¼é›¶åŸºç¡€Text-to-Speechï¼ˆTTSï¼‰çš„äº¤ç»‡è¯­éŸ³æ–‡æœ¬è¯­è¨€æ¨¡å‹ï¼ˆIST-LMï¼‰ã€‚IST-LMç›´æ¥è®­ç»ƒäº¤ç»‡åºåˆ—çš„æ–‡æœ¬å’Œè¯­éŸ³æ ‡è®°ï¼Œé€šè¿‡å›ºå®šæ¯”ä¾‹æ¶ˆé™¤å¯¹æŒç»­æ—¶é—´é¢„æµ‹å’Œå­—æ¯åˆ°éŸ³ç´ å¯¹é½çš„é¢å¤–éœ€æ±‚ã€‚æ–‡æœ¬å—å¤§å°ä¸è¯­éŸ³å—å¤§å°çš„æ¯”ä¾‹å¯¹IST-LMçš„æ€§èƒ½è‡³å…³é‡è¦ã€‚é€šè¿‡ä¸€ç³»åˆ—ç»Ÿè®¡åˆ†æå’Œä¸æœ€ç»ˆæ€§èƒ½çš„ç›¸å…³æ€§åˆ†æï¼Œå‘ç°äº†å½±å“æ€§èƒ½çš„å…³é”®å› ç´ ï¼ŒåŒ…æ‹¬è¯­éŸ³æ ‡è®°ä¸å…¶å¯¹åº”æ–‡æœ¬æ ‡è®°ä¹‹é—´çš„è·ç¦»ã€æ¯ä¸ªè¯­éŸ³æ ‡è®°å¯è®¿é—®çš„æœªæ¥æ–‡æœ¬æ ‡è®°çš„æ•°é‡ä»¥åŠè¯­éŸ³æ ‡è®°çš„é¢‘ç‡å…ˆäºå®ƒä»¬çš„å¯¹åº”æ–‡æœ¬æ ‡è®°ã€‚å®éªŒç»“æœè¯æ˜äº†å®ç°æœ€ä½³æµå¼TTSç³»ç»Ÿçš„å¯èƒ½æ€§ï¼Œæ— éœ€å¤æ‚çš„å·¥ç¨‹ä¼˜åŒ–ï¼Œä¸éæµå¼ç³»ç»Ÿä¹‹é—´çš„å·®è·æœ‰é™ã€‚IST-LMæ¦‚å¿µç®€å•ï¼Œç»éªŒå¼ºå¤§ï¼Œä¸ºæµå¼TTSæä¾›äº†å¹¿é˜”çš„å‰æ™¯ï¼Œå…·æœ‰å®æ—¶æ–‡æœ¬æµçš„èƒ½åŠ›ï¼ŒåŒæ—¶æ€§èƒ½æŸå¤±è¾ƒå°ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>IST-LMæ¨¡å‹å¯ç›´æ¥è®­ç»ƒäº¤ç»‡åºåˆ—çš„æ–‡æœ¬å’Œè¯­éŸ³æ ‡è®°ï¼Œé€šè¿‡å›ºå®šæ¯”ä¾‹è¿›è¡Œè®­ç»ƒï¼Œç®€åŒ–äº†æµç¨‹ã€‚</li>
<li>æ–‡æœ¬å—ä¸è¯­éŸ³å—å¤§å°çš„æ¯”ä¾‹å¯¹IST-LMæ¨¡å‹æ€§èƒ½è‡³å…³é‡è¦ã€‚</li>
<li>é€šè¿‡ç»Ÿè®¡åˆ†æå‘ç°å½±å“IST-LMæ€§èƒ½çš„å…³é”®å› ç´ åŒ…æ‹¬è¯­éŸ³å’Œæ–‡æœ¬æ ‡è®°ä¹‹é—´çš„è·ç¦»ã€æœªæ¥æ–‡æœ¬æ ‡è®°çš„å¯è®¿é—®æ•°é‡ä»¥åŠè¯­éŸ³æ ‡è®°è¶…å‰äºæ–‡æœ¬æ ‡è®°çš„é¢‘ç‡ã€‚</li>
<li>å®éªŒç»“æœè¯æ˜äº†å®ç°æµå¼TTSç³»ç»Ÿçš„å¯èƒ½æ€§ï¼Œæ— éœ€å¤æ‚çš„å·¥ç¨‹ä¼˜åŒ–ã€‚</li>
<li>IST-LMæ¨¡å‹ä¸éæµå¼ç³»ç»Ÿä¹‹é—´çš„æ€§èƒ½å·®è·æœ‰é™ã€‚</li>
<li>IST-LMæ¨¡å‹æ¦‚å¿µç®€å•ä¸”ç»éªŒå¼ºå¤§ï¼Œä¸ºæµå¼TTSæä¾›äº†å¹¿é˜”çš„åº”ç”¨å‰æ™¯ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.16102">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-528ded899ca23c84cd30cf5769c9df27.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-835525750dfd2222025634d9b5a5b476.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-37a239013f7ea19152afe4629b276fb7.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-53c91f1d9dcb6c44fe8e3e361bf6e252.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="Multi-Source-Spatial-Knowledge-Understanding-for-Immersive-Visual-Text-to-Speech"><a href="#Multi-Source-Spatial-Knowledge-Understanding-for-Immersive-Visual-Text-to-Speech" class="headerlink" title="Multi-Source Spatial Knowledge Understanding for Immersive Visual   Text-to-Speech"></a>Multi-Source Spatial Knowledge Understanding for Immersive Visual   Text-to-Speech</h2><p><strong>Authors:Shuwei He, Rui Liu</strong></p>
<p>Visual Text-to-Speech (VTTS) aims to take the environmental image as the prompt to synthesize reverberant speech for the spoken content. Previous works focus on the RGB modality for global environmental modeling, overlooking the potential of multi-source spatial knowledge like depth, speaker position, and environmental semantics. To address these issues, we propose a novel multi-source spatial knowledge understanding scheme for immersive VTTS, termed MS2KU-VTTS. Specifically, we first prioritize RGB image as the dominant source and consider depth image, speaker position knowledge from object detection, and Gemini-generated semantic captions as supplementary sources. Afterwards, we propose a serial interaction mechanism to effectively integrate both dominant and supplementary sources. The resulting multi-source knowledge is dynamically integrated based on the respective contributions of each source.This enriched interaction and integration of multi-source spatial knowledge guides the speech generation model, enhancing the immersive speech experience. Experimental results demonstrate that the MS$^2$KU-VTTS surpasses existing baselines in generating immersive speech. Demos and code are available at: <a target="_blank" rel="noopener" href="https://github.com/AI-S2-Lab/MS2KU-VTTS">https://github.com/AI-S2-Lab/MS2KU-VTTS</a>. </p>
<blockquote>
<p>è§†è§‰æ–‡æœ¬åˆ°è¯­éŸ³ï¼ˆVTTSï¼‰æ—¨åœ¨ä»¥ç¯å¢ƒå›¾åƒä¸ºæç¤ºï¼Œåˆæˆå›å“çš„è¯­éŸ³å†…å®¹ã€‚ä»¥å‰çš„å·¥ä½œä¸»è¦å…³æ³¨RGBæ¨¡å¼è¿›è¡Œå…¨å±€ç¯å¢ƒå»ºæ¨¡ï¼Œå¿½ç•¥äº†æ·±åº¦ã€è¯´è¯è€…ä½ç½®å’Œç¯å¢ƒè¯­ä¹‰ç­‰å¤šæºç©ºé—´çŸ¥è¯†çš„æ½œåŠ›ã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§ç”¨äºæ²‰æµ¸å¼VTTSçš„å¤šæºç©ºé—´çŸ¥è¯†ç†è§£æ–¹æ¡ˆï¼Œç§°ä¸ºMS2KU-VTTSã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬é¦–å…ˆä»¥RGBå›¾åƒä½œä¸ºä¸»è¦æ¥æºï¼Œå¹¶å°†æ·±åº¦å›¾åƒã€æ¥è‡ªå¯¹è±¡æ£€æµ‹çš„è¯´è¯è€…ä½ç½®çŸ¥è¯†ä»¥åŠGeminiç”Ÿæˆçš„è¯­ä¹‰å­—å¹•ä½œä¸ºè¾…åŠ©æ¥æºã€‚ç„¶åï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§ä¸²è¡Œäº¤äº’æœºåˆ¶ï¼Œä»¥æœ‰æ•ˆåœ°æ•´åˆä¸»è¦å’Œè¾…åŠ©æ¥æºã€‚æœ€ç»ˆçš„å¤šæºçŸ¥è¯†æ˜¯åŸºäºæ¯ä¸ªæºçš„å„è‡ªè´¡çŒ®åŠ¨æ€åœ°é›†æˆçš„ã€‚è¿™ç§å¤šæºç©ºé—´çŸ¥è¯†çš„ä¸°å¯Œäº¤äº’å’Œæ•´åˆæŒ‡å¯¼è¯­éŸ³ç”Ÿæˆæ¨¡å‹ï¼Œå¢å¼ºæ²‰æµ¸å¼çš„è¯­éŸ³ä½“éªŒã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒMS$^2$KU-VTTSåœ¨ç”Ÿæˆæ²‰æµ¸å¼è¯­éŸ³æ–¹é¢è¶…è¿‡äº†ç°æœ‰åŸºçº¿ã€‚æ¼”ç¤ºå’Œä»£ç å¯åœ¨ï¼š<a target="_blank" rel="noopener" href="https://github.com/AI-S2-Lab/MS2KU-VTTS%E8%8E%B7%E5%8F%96%E3%80%82">https://github.com/AI-S2-Lab/MS2KU-VTTSè·å–ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2410.14101v2">PDF</a> 5 pages, 1 figure, Accepted by ICASSPâ€™2025</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†è§†è§‰æ–‡æœ¬è¯­éŸ³è½¬æ¢ï¼ˆVTTSï¼‰çš„ç›®æ ‡ï¼Œå¹¶æŒ‡å‡ºä»¥å¾€çš„ç ”ç©¶ä¸»è¦å…³æ³¨RGBæ¨¡æ€çš„å…¨å±€ç¯å¢ƒå»ºæ¨¡ï¼Œå¿½è§†äº†æ·±åº¦ã€è¯´è¯äººä½ç½®å’Œç¯å¢ƒè¯­ä¹‰ç­‰å¤šæºç©ºé—´çŸ¥è¯†çš„æ½œåŠ›ã€‚ä¸ºè§£å†³è¿™äº›é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸ºMS^2KU-VTTSçš„å¤šæºç©ºé—´çŸ¥è¯†ç†è§£æ–¹æ¡ˆï¼Œè¯¥æ–¹æ¡ˆä»¥RGBå›¾åƒä¸ºä¸»è¦æ¥æºï¼ŒåŒæ—¶è€ƒè™‘æ·±åº¦å›¾åƒã€è¯´è¯äººä½ç½®çŸ¥è¯†å’ŒGeminiç”Ÿæˆçš„è¯­ä¹‰å­—å¹•ç­‰è¾…åŠ©æ¥æºã€‚é€šè¿‡ä¸²è¡Œäº¤äº’æœºåˆ¶æœ‰æ•ˆåœ°æ•´åˆäº†ä¸»è¦å’Œè¾…åŠ©æ¥æºï¼ŒåŸºäºå„æ¥æºçš„è´¡çŒ®åŠ¨æ€æ•´åˆå¤šæºçŸ¥è¯†ã€‚è¿™ç§å¤šæºç©ºé—´çŸ¥è¯†çš„ä¸°å¯Œäº¤äº’å’Œæ•´åˆï¼Œæé«˜äº†è¯­éŸ³ç”Ÿæˆæ¨¡å‹çš„æŒ‡å¯¼æ•ˆæœï¼Œå¢å¼ºäº†æ²‰æµ¸å¼è¯­éŸ³ä½“éªŒã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒMS^2KU-VTTSåœ¨ç”Ÿæˆæ²‰æµ¸å¼è¯­éŸ³æ–¹é¢è¶…è¶Šäº†ç°æœ‰åŸºçº¿ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>VTTSæ—¨åœ¨æ ¹æ®ç¯å¢ƒå›¾åƒåˆæˆå›å£°è¯­éŸ³ã€‚</li>
<li>ä»¥å¾€ç ”ç©¶ä¸»è¦å…³æ³¨RGBæ¨¡æ€çš„ç¯å¢ƒå»ºæ¨¡ï¼Œå¿½è§†äº†å¤šæºç©ºé—´çŸ¥è¯†çš„é‡è¦æ€§ã€‚</li>
<li>MS^2KU-VTTSæ–¹æ¡ˆæå‡ºä»¥RGBå›¾åƒä¸ºä¸»è¦æ¥æºï¼Œå¹¶ç»“åˆæ·±åº¦å›¾åƒã€è¯´è¯äººä½ç½®çŸ¥è¯†å’Œè¯­ä¹‰å­—å¹•ç­‰è¾…åŠ©æ¥æºã€‚</li>
<li>é€šè¿‡ä¸²è¡Œäº¤äº’æœºåˆ¶æ•´åˆä¸»è¦å’Œè¾…åŠ©æ¥æºï¼Œå®ç°å¤šæºçŸ¥è¯†çš„åŠ¨æ€æ•´åˆã€‚</li>
<li>å¤šæºç©ºé—´çŸ¥è¯†çš„ä¸°å¯Œäº¤äº’å’Œæ•´åˆå¢å¼ºäº†è¯­éŸ³ç”Ÿæˆæ¨¡å‹çš„æŒ‡å¯¼æ•ˆæœã€‚</li>
<li>MS^2KU-VTTSåœ¨ç”Ÿæˆæ²‰æµ¸å¼è¯­éŸ³æ–¹é¢è¶…è¶Šäº†ç°æœ‰æ–¹æ³•ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2410.14101">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-ee089c9ec8bc48e5c25843602bb9fc8e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-540d0f9217aeacd256de2408315bcfc1.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-8e31971a3fc3fb4ba42d0e51ee726c39.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-8f68267381a7a6bcaa435ccbd94eb08c.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="NanoVoice-Efficient-Speaker-Adaptive-Text-to-Speech-for-Multiple-Speakers"><a href="#NanoVoice-Efficient-Speaker-Adaptive-Text-to-Speech-for-Multiple-Speakers" class="headerlink" title="NanoVoice: Efficient Speaker-Adaptive Text-to-Speech for Multiple   Speakers"></a>NanoVoice: Efficient Speaker-Adaptive Text-to-Speech for Multiple   Speakers</h2><p><strong>Authors:Nohil Park, Heeseung Kim, Che Hyun Lee, Jooyoung Choi, Jiheum Yeom, Sungroh Yoon</strong></p>
<p>We present NanoVoice, a personalized text-to-speech model that efficiently constructs voice adapters for multiple speakers simultaneously. NanoVoice introduces a batch-wise speaker adaptation technique capable of fine-tuning multiple references in parallel, significantly reducing training time. Beyond building separate adapters for each speaker, we also propose a parameter sharing technique that reduces the number of parameters used for speaker adaptation. By incorporating a novel trainable scale matrix, NanoVoice mitigates potential performance degradation during parameter sharing. NanoVoice achieves performance comparable to the baselines, while training 4 times faster and using 45 percent fewer parameters for speaker adaptation with 40 reference voices. Extensive ablation studies and analysis further validate the efficiency of our model. </p>
<blockquote>
<p>æˆ‘ä»¬æå‡ºäº†NanoVoiceï¼Œè¿™æ˜¯ä¸€ç§ä¸ªæ€§åŒ–çš„æ–‡æœ¬åˆ°è¯­éŸ³æ¨¡å‹ï¼Œèƒ½å¤Ÿé«˜æ•ˆåœ°åŒæ—¶ä¸ºå¤šä¸ªè¯´è¯è€…æ„å»ºè¯­éŸ³é€‚é…å™¨ã€‚NanoVoiceå¼•å…¥äº†ä¸€ç§æ‰¹å¤„ç†è¯´è¯è€…è‡ªé€‚åº”æŠ€æœ¯ï¼Œèƒ½å¤Ÿå¹¶è¡Œå¾®è°ƒå¤šä¸ªå‚è€ƒï¼Œä»è€Œæ˜¾è‘—å‡å°‘è®­ç»ƒæ—¶é—´ã€‚é™¤äº†ä¸ºæ¯ä¸ªè¯´è¯è€…æ„å»ºå•ç‹¬çš„é€‚é…å™¨å¤–ï¼Œæˆ‘ä»¬è¿˜æå‡ºäº†ä¸€ç§å‚æ•°å…±äº«æŠ€æœ¯ï¼Œä»¥å‡å°‘ç”¨äºè¯´è¯è€…è‡ªé€‚åº”çš„å‚æ•°æ•°é‡ã€‚é€šè¿‡å¼•å…¥ä¸€ä¸ªæ–°å‹çš„å¯è®­ç»ƒæ¯”ä¾‹çŸ©é˜µï¼ŒNanoVoiceç¼“è§£äº†å‚æ•°å…±äº«æœŸé—´å¯èƒ½å‡ºç°çš„æ€§èƒ½ä¸‹é™é—®é¢˜ã€‚NanoVoiceçš„æ€§èƒ½ä¸åŸºçº¿ç›¸å½“ï¼ŒåŒæ—¶è®­ç»ƒé€Ÿåº¦æ˜¯åŸºçº¿çš„4å€ï¼Œä½¿ç”¨å‚æ•°è¿›è¡Œè¯´è¯è€…è‡ªé€‚åº”æ—¶å‡å°‘äº†45%ã€‚å¹¿æ³›çš„æ¶ˆèç ”ç©¶å’Œåˆ†æè¿›ä¸€æ­¥éªŒè¯äº†æˆ‘ä»¬çš„æ¨¡å‹æ•ˆç‡ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2409.15760v2">PDF</a> IEEE International Conference on Acoustics, Speech, and Signal   Processing (ICASSP), 2025, Demo Page: <a target="_blank" rel="noopener" href="https://nanovoice.github.io/">https://nanovoice.github.io/</a></p>
<p><strong>Summary</strong></p>
<p>NanoVoiceæ˜¯ä¸€ä¸ªä¸ªæ€§åŒ–çš„æ–‡æœ¬åˆ°è¯­éŸ³æ¨¡å‹ï¼Œå¯é«˜æ•ˆåœ°åŒæ—¶ä¸ºå¤šä¸ªè¯´è¯è€…æ„å»ºè¯­éŸ³é€‚é…å™¨ã€‚å®ƒå¼•å…¥äº†ä¸€ç§æ‰¹å¤„ç†è¯´è¯è€…é€‚åº”æŠ€æœ¯ï¼Œèƒ½å¤Ÿå¹¶è¡Œå¾®è°ƒå¤šä¸ªå‚è€ƒé¡¹ï¼Œä»è€Œå¤§å¤§ç¼©çŸ­è®­ç»ƒæ—¶é—´ã€‚é™¤äº†ä¸ºæ¯ä¸ªè¯´è¯è€…æ„å»ºå•ç‹¬çš„é€‚é…å™¨å¤–ï¼Œè¿˜æå‡ºäº†ä¸€ç§å‚æ•°å…±äº«æŠ€æœ¯ï¼Œå‡å°‘äº†ç”¨äºè¯´è¯è€…é€‚åº”çš„å‚æ•°æ•°é‡ã€‚é€šè¿‡å¼•å…¥æ–°å‹çš„å¯è®­ç»ƒæ¯”ä¾‹çŸ©é˜µï¼ŒNanoVoiceåœ¨å‚æ•°å…±äº«æ—¶å‡è½»äº†æ€§èƒ½ä¸‹é™çš„æ½œåœ¨é£é™©ã€‚NanoVoiceçš„æ€§èƒ½ä¸åŸºçº¿ç›¸å½“ï¼Œè®­ç»ƒé€Ÿåº¦æé«˜äº†4å€ï¼Œä½¿ç”¨å‚æ•°è¿›è¡Œè¯´è¯è€…é€‚åº”æ—¶å‡å°‘äº†45%ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>NanoVoiceæ˜¯ä¸€ä¸ªæ–‡æœ¬åˆ°è¯­éŸ³æ¨¡å‹ï¼Œèƒ½åŒæ—¶ä¸ºå¤šä¸ªè¯´è¯è€…æ„å»ºè¯­éŸ³é€‚é…å™¨ã€‚</li>
<li>å®ƒé‡‡ç”¨æ‰¹å¤„ç†è¯´è¯è€…é€‚åº”æŠ€æœ¯ï¼Œèƒ½å¹¶è¡Œå¾®è°ƒå¤šä¸ªå‚è€ƒé¡¹ï¼Œæé«˜è®­ç»ƒæ•ˆç‡ã€‚</li>
<li>NanoVoiceæå‡ºå‚æ•°å…±äº«æŠ€æœ¯ï¼Œå‡å°‘è¯´è¯è€…é€‚åº”æ‰€éœ€çš„å‚æ•°æ•°é‡ã€‚</li>
<li>é€šè¿‡å¼•å…¥å¯è®­ç»ƒæ¯”ä¾‹çŸ©é˜µï¼ŒNanoVoiceåœ¨å‚æ•°å…±äº«æ—¶ä¿æŒæ€§èƒ½ç¨³å®šã€‚</li>
<li>NanoVoiceçš„æ€§èƒ½ä¸åŸºçº¿ç›¸å½“ï¼Œè®­ç»ƒé€Ÿåº¦æå‡4å€ï¼Œå‚æ•°ä½¿ç”¨å‡å°‘45%ã€‚</li>
<li>è¿›è¡Œäº†å¹¿æ³›çš„æ¶ˆèç ”ç©¶å’Œåˆ†æï¼Œè¿›ä¸€æ­¥éªŒè¯äº†æ¨¡å‹çš„æ•ˆç‡ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2409.15760">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-b9785a5a98711f10b8167a1c69c0266a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f6d1f62781447f565b27d2b15c775630.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-9b58f850e7947ac5983ff7f0a0a990b5.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-60eb50c57418bf7d0814c984ebe6bd4a.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="VoiceGuider-Enhancing-Out-of-Domain-Performance-in-Parameter-Efficient-Speaker-Adaptive-Text-to-Speech-via-Autoguidance"><a href="#VoiceGuider-Enhancing-Out-of-Domain-Performance-in-Parameter-Efficient-Speaker-Adaptive-Text-to-Speech-via-Autoguidance" class="headerlink" title="VoiceGuider: Enhancing Out-of-Domain Performance in Parameter-Efficient   Speaker-Adaptive Text-to-Speech via Autoguidance"></a>VoiceGuider: Enhancing Out-of-Domain Performance in Parameter-Efficient   Speaker-Adaptive Text-to-Speech via Autoguidance</h2><p><strong>Authors:Jiheum Yeom, Heeseung Kim, Jooyoung Choi, Che Hyun Lee, Nohil Park, Sungroh Yoon</strong></p>
<p>When applying parameter-efficient finetuning via LoRA onto speaker adaptive text-to-speech models, adaptation performance may decline compared to full-finetuned counterparts, especially for out-of-domain speakers. Here, we propose VoiceGuider, a parameter-efficient speaker adaptive text-to-speech system reinforced with autoguidance to enhance the speaker adaptation performance, reducing the gap against full-finetuned models. We carefully explore various ways of strengthening autoguidance, ultimately finding the optimal strategy. VoiceGuider as a result shows robust adaptation performance especially on extreme out-of-domain speech data. We provide audible samples in our demo page. </p>
<blockquote>
<p>å½“é€šè¿‡LoRAåº”ç”¨å‚æ•°é«˜æ•ˆçš„å¾®è°ƒè‡³è‡ªé€‚åº”è¯´è¯äººçš„æ–‡æœ¬åˆ°è¯­éŸ³æ¨¡å‹æ—¶ï¼Œä¸å…¨å¾®è°ƒæ¨¡å‹ç›¸æ¯”ï¼Œè‡ªé€‚åº”æ€§èƒ½å¯èƒ½ä¼šä¸‹é™ï¼Œç‰¹åˆ«æ˜¯å¯¹äºéåŸŸå†…çš„è¯´è¯äººã€‚é’ˆå¯¹è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†VoiceGuiderï¼Œè¿™æ˜¯ä¸€ä¸ªé€šè¿‡è‡ªåŠ¨æŒ‡å¯¼å¢å¼ºçš„å‚æ•°é«˜æ•ˆè‡ªé€‚åº”æ–‡æœ¬åˆ°è¯­éŸ³ç³»ç»Ÿï¼Œä»¥æé«˜è¯´è¯äººè‡ªé€‚åº”æ€§èƒ½ï¼Œç¼©å°ä¸å…¨å¾®è°ƒæ¨¡å‹ä¹‹é—´çš„å·®è·ã€‚æˆ‘ä»¬å°å¿ƒç¿¼ç¿¼åœ°æ¢ç´¢äº†åŠ å¼ºè‡ªåŠ¨æŒ‡å¯¼çš„å„ç§æ–¹å¼ï¼Œå¹¶æ‰¾åˆ°äº†æœ€ä½³ç­–ç•¥ã€‚VoiceGuiderçš„ç»“æœæ˜¾ç¤ºï¼Œå…¶åœ¨æç«¯éåŸŸè¯­éŸ³æ•°æ®ä¸Šè¡¨ç°å‡ºç¨³å¥çš„è‡ªé€‚åº”æ€§èƒ½ã€‚æˆ‘ä»¬åœ¨æ¼”ç¤ºé¡µé¢ä¸Šæä¾›äº†å¯å¬çš„æ ·æœ¬ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2409.15759v2">PDF</a> IEEE International Conference on Acoustics, Speech, and Signal   Processing (ICASSP), 2025, Demo Page: <a target="_blank" rel="noopener" href="https://voiceguider.github.io/">https://voiceguider.github.io/</a></p>
<p><strong>Summary</strong></p>
<p>åœ¨é‡‡ç”¨LoRAè¿›è¡Œå‚æ•°æœ‰æ•ˆå¾®è°ƒä»¥é€‚é…è¯­éŸ³è‡ªé€‚åº”æ–‡æœ¬åˆ°è¯­éŸ³æ¨¡å‹æ—¶ï¼Œç›¸æ¯”å…¨å¾®è°ƒçš„æ¨¡å‹ï¼Œé€‚é…æ€§èƒ½å¯èƒ½ä¼šå‡ºç°ä¸‹é™ï¼Œç‰¹åˆ«æ˜¯é’ˆå¯¹éåŸŸå†…çš„å‘è¨€äººã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬æå‡ºäº†VoiceGuiderï¼Œè¿™æ˜¯ä¸€ä¸ªå‚æ•°é«˜æ•ˆçš„è¯­éŸ³è‡ªé€‚åº”æ–‡æœ¬åˆ°è¯­éŸ³ç³»ç»Ÿï¼Œé€šè¿‡è‡ªåŠ¨æŒ‡å¯¼å¼ºåŒ–æ¥æå‡è¯­éŸ³é€‚é…æ€§èƒ½ï¼Œç¼©å°ä¸å…¨å¾®è°ƒæ¨¡å‹çš„å·®è·ã€‚æˆ‘ä»¬æ·±å…¥æ¢ç´¢äº†å¢å¼ºè‡ªåŠ¨æŒ‡å¯¼çš„å„ç§æ–¹æ³•ï¼Œå¹¶æ‰¾åˆ°äº†æœ€ä½³ç­–ç•¥ã€‚VoiceGuideråœ¨æç«¯éåŸŸè¯­éŸ³æ•°æ®ä¸Šå±•ç°å‡ºå¼ºå¤§çš„é€‚åº”æ€§ã€‚æˆ‘ä»¬åœ¨æ¼”ç¤ºé¡µé¢ä¸Šæä¾›äº†å¯å¬çš„æ ·æœ¬ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>LoRAåº”ç”¨äºè¯­éŸ³è‡ªé€‚åº”æ–‡æœ¬åˆ°è¯­éŸ³æ¨¡å‹çš„å‚æ•°å¾®è°ƒå¯èƒ½ä¸å¦‚å…¨å¾®è°ƒæ¨¡å‹æ•ˆæœå¥½ï¼Œç‰¹åˆ«æ˜¯å¯¹äºéåŸŸå†…çš„å‘è¨€äººã€‚</li>
<li>VoiceGuideræ˜¯ä¸€ä¸ªå‚æ•°é«˜æ•ˆçš„è¯­éŸ³è‡ªé€‚åº”æ–‡æœ¬åˆ°è¯­éŸ³ç³»ç»Ÿï¼Œæ—¨åœ¨æé«˜è¯­éŸ³é€‚é…æ€§èƒ½ã€‚</li>
<li>VoiceGuideré€šè¿‡å¼ºåŒ–è‡ªåŠ¨æŒ‡å¯¼æ¥ç¼©å°ä¸å…¨å¾®è°ƒæ¨¡å‹çš„æ€§èƒ½å·®è·ã€‚</li>
<li>VoiceGuideråœ¨æ¢ç´¢å¢å¼ºè‡ªåŠ¨æŒ‡å¯¼æ–¹æ³•çš„è¿‡ç¨‹ä¸­æ‰¾åˆ°äº†æœ€ä½³ç­–ç•¥ã€‚</li>
<li>VoiceGuideråœ¨æç«¯éåŸŸè¯­éŸ³æ•°æ®ä¸Šå±•ç°å‡ºå¼ºå¤§çš„é€‚åº”æ€§ã€‚</li>
<li>æ¼”ç¤ºé¡µé¢ä¸Šæä¾›äº†å¯å¬çš„æ ·æœ¬ï¼Œä»¥ä¾¿è¯„ä¼°VoiceGuiderçš„æ€§èƒ½ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2409.15759">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-9112fc85431af49e01e11faab161dbf6.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-05889e4ac4ae9f23063e3d916d892b99.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-5c7b2a9efa449e1ddaaad87e7454b04a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-016703487e861605fd3629e812d9d0fc.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f5af3f8574589d06a6556533f9cd8bc9.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="Full-text-Error-Correction-for-Chinese-Speech-Recognition-with-Large-Language-Model"><a href="#Full-text-Error-Correction-for-Chinese-Speech-Recognition-with-Large-Language-Model" class="headerlink" title="Full-text Error Correction for Chinese Speech Recognition with Large   Language Model"></a>Full-text Error Correction for Chinese Speech Recognition with Large   Language Model</h2><p><strong>Authors:Zhiyuan Tang, Dong Wang, Shen Huang, Shidong Shang</strong></p>
<p>Large Language Models (LLMs) have demonstrated substantial potential for error correction in Automatic Speech Recognition (ASR). However, most research focuses on utterances from short-duration speech recordings, which are the predominant form of speech data for supervised ASR training. This paper investigates the effectiveness of LLMs for error correction in full-text generated by ASR systems from longer speech recordings, such as transcripts from podcasts, news broadcasts, and meetings. First, we develop a Chinese dataset for full-text error correction, named ChFT, utilizing a pipeline that involves text-to-speech synthesis, ASR, and error-correction pair extractor. This dataset enables us to correct errors across contexts, including both full-text and segment, and to address a broader range of error types, such as punctuation restoration and inverse text normalization, thus making the correction process comprehensive. Second, we fine-tune a pre-trained LLM on the constructed dataset using a diverse set of prompts and target formats, and evaluate its performance on full-text error correction. Specifically, we design prompts based on full-text and segment, considering various output formats, such as directly corrected text and JSON-based error-correction pairs. Through various test settings, including homogeneous, up-to-date, and hard test sets, we find that the fine-tuned LLMs perform well in the full-text setting with different prompts, each presenting its own strengths and weaknesses. This establishes a promising baseline for further research. The dataset is available on the website. </p>
<blockquote>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨è‡ªåŠ¨è¯­éŸ³è¯†åˆ«ï¼ˆASRï¼‰çš„é”™è¯¯çº æ­£æ–¹é¢å±•ç°å‡ºäº†å·¨å¤§çš„æ½œåŠ›ã€‚ç„¶è€Œï¼Œå¤§å¤šæ•°ç ”ç©¶éƒ½é›†ä¸­åœ¨æ¥è‡ªçŸ­æœŸè¯­éŸ³è®°å½•çš„ç‰‡æ®µä¸Šï¼Œè¿™æ˜¯æœ‰ç›‘ç£çš„ASRè®­ç»ƒçš„ä¸»è¦å½¢å¼ã€‚æœ¬æ–‡ç ”ç©¶äº†LLMåœ¨ç”±ASRç³»ç»Ÿä»è¾ƒé•¿çš„è¯­éŸ³è®°å½•ç”Ÿæˆçš„å®Œæ•´æ–‡æœ¬ä¸­çš„é”™è¯¯çº æ­£æ•ˆæœï¼Œä¾‹å¦‚æ¥è‡ªæ’­å®¢ã€æ–°é—»å¹¿æ’­å’Œä¼šè®®çš„è½¬å½•æ–‡æœ¬ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬å¼€å‘äº†ä¸€ä¸ªç”¨äºå…¨æ–‡é”™è¯¯çº æ­£çš„ä¸­æ–‡æ•°æ®é›†ï¼Œåä¸ºChFTï¼Œè¯¥æ•°æ®é›†é‡‡ç”¨æ¶‰åŠæ–‡æœ¬åˆ°è¯­éŸ³åˆæˆã€ASRå’Œé”™è¯¯æ ¡æ­£å¯¹æå–å™¨çš„ç®¡é“ã€‚è¯¥æ•°æ®é›†ä½¿æˆ‘ä»¬èƒ½å¤Ÿåœ¨ä¸åŒè¯­å¢ƒä¸­çº æ­£é”™è¯¯ï¼ŒåŒ…æ‹¬å…¨æ–‡å’Œç‰‡æ®µï¼Œå¹¶å¤„ç†æ›´å¹¿æ³›çš„é”™è¯¯ç±»å‹ï¼Œå¦‚æ ‡ç‚¹æ¢å¤å’Œé€†æ–‡æœ¬è§„èŒƒåŒ–ï¼Œä»è€Œä½¿æ ¡æ­£è¿‡ç¨‹æ›´åŠ å…¨é¢ã€‚å…¶æ¬¡ï¼Œæˆ‘ä»¬åœ¨æ„å»ºçš„æ•°æ®é›†ä¸Šå¯¹é¢„è®­ç»ƒçš„LLMè¿›è¡Œäº†å¾®è°ƒï¼Œä½¿ç”¨äº†å„ç§æç¤ºå’Œç›®æ ‡æ ¼å¼ï¼Œå¹¶è¯„ä¼°äº†å…¶åœ¨å…¨æ–‡é”™è¯¯çº æ­£æ–¹é¢çš„æ€§èƒ½ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬åŸºäºå…¨æ–‡å’Œç‰‡æ®µè®¾è®¡æç¤ºï¼Œè€ƒè™‘å„ç§è¾“å‡ºæ ¼å¼ï¼Œå¦‚ç›´æ¥æ ¡æ­£çš„æ–‡æœ¬å’ŒåŸºäºJSONçš„é”™è¯¯æ ¡æ­£å¯¹ã€‚é€šè¿‡åŒ…æ‹¬åŒè´¨ã€æœ€æ–°å’Œå›°éš¾æµ‹è¯•é›†åœ¨å†…çš„å„ç§æµ‹è¯•ç¯å¢ƒï¼Œæˆ‘ä»¬å‘ç°ç»è¿‡å¾®è°ƒåçš„LLMåœ¨ä¸åŒçš„æç¤ºä¸‹è¡¨ç°è‰¯å¥½ï¼Œå„æœ‰å…¶ä¼˜åŠ¿å’ŒåŠ£åŠ¿ã€‚è¿™ä¸ºæœªæ¥çš„ç ”ç©¶å¥ å®šäº†æœ‰å‰æ™¯çš„åŸºå‡†ã€‚æ•°æ®é›†å¯åœ¨ç½‘ç«™ä¸Šè·å¾—ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2409.07790v2">PDF</a> ICASSP 2025</p>
<p><strong>æ‘˜è¦</strong></p>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨è‡ªåŠ¨è¯­éŸ³è¯†åˆ«ï¼ˆASRï¼‰çš„é”™è¯¯æ ¡æ­£æ–¹é¢æ˜¾ç¤ºå‡ºå·¨å¤§æ½œåŠ›ã€‚ç„¶è€Œï¼Œå¤§å¤šæ•°ç ”ç©¶éƒ½é›†ä¸­åœ¨æ¥è‡ªçŸ­è¯­éŸ³å½•éŸ³çš„è¯­éŸ³ç‰‡æ®µä¸Šï¼Œè¿™äº›æ˜¯ç›®å‰ç›‘ç£å¼ASRè®­ç»ƒçš„ä¸»è¦å½¢å¼ã€‚æœ¬æ–‡æ¢è®¨äº†LLMåœ¨ç”±ASRç³»ç»Ÿä»è¾ƒé•¿è¯­éŸ³å½•éŸ³ï¼ˆå¦‚æ’­å®¢ã€æ–°é—»å¹¿æ’­å’Œä¼šè®®è®°å½•ï¼‰ç”Ÿæˆçš„å…¨æ–‡ä¸Šçš„é”™è¯¯æ ¡æ­£æ•ˆæœã€‚é¦–å…ˆï¼Œæˆ‘ä»¬å¼€å‘äº†ä¸€ä¸ªç”¨äºå…¨æ–‡é”™è¯¯æ ¡æ­£çš„ä¸­æ–‡æ•°æ®é›†ChFTï¼Œè¯¥æ•°æ®é›†é‡‡ç”¨æ–‡æœ¬åˆ°è¯­éŸ³åˆæˆã€ASRå’Œé”™è¯¯æ ¡æ­£å¯¹æå–å™¨æ„æˆçš„ç®¡é“å®ç°ã€‚è¯¥æ•°æ®é›†ä½¿æˆ‘ä»¬èƒ½å¤Ÿåœ¨ä¸åŒè¯­å¢ƒä¸­çº æ­£é”™è¯¯ï¼ŒåŒ…æ‹¬å…¨æ–‡å’Œæ®µè½ï¼Œå¹¶å¤„ç†æ›´å¹¿æ³›çš„é”™è¯¯ç±»å‹ï¼Œå¦‚æ ‡ç‚¹æ¢å¤å’Œåå‘æ–‡æœ¬å½’ä¸€åŒ–ï¼Œä»è€Œä½¿æ ¡æ­£è¿‡ç¨‹æ›´åŠ å…¨é¢ã€‚å…¶æ¬¡ï¼Œæˆ‘ä»¬åœ¨æ„å»ºçš„æ•°æ®é›†ä¸Šå¯¹é¢„è®­ç»ƒçš„LLMè¿›è¡Œäº†å¾®è°ƒï¼Œä½¿ç”¨äº†å„ç§æç¤ºå’Œç›®æ ‡æ ¼å¼ï¼Œå¹¶å¯¹å…¨æ–‡é”™è¯¯æ ¡æ­£çš„æ€§èƒ½è¿›è¡Œäº†è¯„ä¼°ã€‚ç‰¹åˆ«æ˜¯ï¼Œæˆ‘ä»¬è®¾è®¡äº†åŸºäºå…¨æ–‡å’Œæ®µè½çš„æç¤ºï¼Œå¹¶è€ƒè™‘äº†å„ç§è¾“å‡ºæ ¼å¼ï¼Œå¦‚ç›´æ¥çº æ­£çš„æ–‡æœ¬å’ŒåŸºäºJSONçš„é”™è¯¯æ ¡æ­£å¯¹ã€‚é€šè¿‡åŒ…æ‹¬åŒè´¨çš„ã€æœ€æ–°çš„å’Œå›°éš¾çš„æµ‹è¯•é›†åœ¨å†…çš„å„ç§æµ‹è¯•è®¾ç½®ï¼Œæˆ‘ä»¬å‘ç°ç»è¿‡å¾®è°ƒåçš„LLMåœ¨ä¸åŒçš„æç¤ºä¸‹ï¼Œåœ¨å…¨æ–‡è®¾ç½®ä¸­è¡¨ç°è‰¯å¥½ï¼Œå„æœ‰å…¶ä¼˜ç¼ºç‚¹ã€‚è¿™ä¸ºæœªæ¥çš„ç ”ç©¶æä¾›äº†ä¸€ä¸ªæœ‰å¸Œæœ›çš„åŸºå‡†ã€‚æ•°æ®é›†å¯åœ¨ç½‘ç«™ä¸Šè·å¾—ã€‚</p>
<p><strong>å…³é”®è§è§£</strong></p>
<ol>
<li>å¤§å‹è¯­è¨€æ¨¡å‹åœ¨è‡ªåŠ¨è¯­éŸ³è¯†åˆ«ä¸­çš„é”™è¯¯æ ¡æ­£æ–¹é¢è¡¨ç°å‡ºå·¨å¤§æ½œåŠ›ã€‚</li>
<li>ç°æœ‰çš„ç ”ç©¶ä¸»è¦å…³æ³¨çŸ­è¯­éŸ³å½•éŸ³çš„è¯­éŸ³ç‰‡æ®µï¼Œæœ¬æ–‡åˆ™ä¸“æ³¨äºç”±ASRç³»ç»Ÿç”Ÿæˆçš„å…¨æ–‡é”™è¯¯æ ¡æ­£ã€‚</li>
<li>å¼€å‘äº†ä¸€ä¸ªç”¨äºå…¨æ–‡é”™è¯¯æ ¡æ­£çš„ä¸­æ–‡æ•°æ®é›†ChFTï¼Œè¯¥æ•°æ®é›†èƒ½åœ¨ä¸åŒè¯­å¢ƒä¸­çº æ­£é”™è¯¯å¹¶å¤„ç†å¹¿æ³›çš„é”™è¯¯ç±»å‹ã€‚</li>
<li>é€šè¿‡å¾®è°ƒé¢„è®­ç»ƒçš„LLMå’Œå¯¹ä¸åŒæç¤ºåŠç›®æ ‡æ ¼å¼çš„ä½¿ç”¨ï¼Œå¯¹LLMåœ¨å…¨æ–‡é”™è¯¯æ ¡æ­£ä¸­çš„æ€§èƒ½è¿›è¡Œäº†è¯„ä¼°ã€‚</li>
<li>åœ¨å¤šç§æµ‹è¯•è®¾ç½®ä¸‹ï¼Œå‘ç°ç»è¿‡å¾®è°ƒåçš„LLMåœ¨å…¨æ–‡è®¾ç½®ä¸­è¡¨ç°è‰¯å¥½ã€‚</li>
<li>LLMçš„æç¤ºè®¾è®¡åœ¨å…¨æ–‡å’Œæ®µè½çº§åˆ«éƒ½æœ‰è€ƒè™‘ï¼Œå¹¶è€ƒè™‘äº†å¤šç§è¾“å‡ºæ ¼å¼ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2409.07790">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-2b65f4d824e1db9858fb68cb7a985861.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-26be500de3a31e2fa5336219bb82d568.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d53bac2df374ec0bdb946ce3369c3d6e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-6425d0d71f48f50bba28352e7a21696e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-46660c58a4177a91d3aa3f203cdd12d5.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-db5b0db0a3844add6c2b0a17f8e97838.jpg" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="vec2wav-2-0-Advancing-Voice-Conversion-via-Discrete-Token-Vocoders"><a href="#vec2wav-2-0-Advancing-Voice-Conversion-via-Discrete-Token-Vocoders" class="headerlink" title="vec2wav 2.0: Advancing Voice Conversion via Discrete Token Vocoders"></a>vec2wav 2.0: Advancing Voice Conversion via Discrete Token Vocoders</h2><p><strong>Authors:Yiwei Guo, Zhihan Li, Junjie Li, Chenpeng Du, Hankun Wang, Shuai Wang, Xie Chen, Kai Yu</strong></p>
<p>We propose a new speech discrete token vocoder, vec2wav 2.0, which advances voice conversion (VC). We use discrete tokens from speech self-supervised models as the content features of source speech, and treat VC as a prompted vocoding task. To amend the loss of speaker timbre in the content tokens, vec2wav 2.0 utilizes the WavLM features to provide strong timbre-dependent information. A novel adaptive Snake activation function is proposed to better incorporate timbre into the waveform reconstruction process. In this way, vec2wav 2.0 learns to alter the speaker timbre appropriately given different reference prompts. Also, no supervised data is required for vec2wav 2.0 to be effectively trained. Experimental results demonstrate that vec2wav 2.0 outperforms all other baselines to a considerable margin in terms of audio quality and speaker similarity in any-to-any VC. Ablation studies verify the effects made by the proposed techniques. Moreover, vec2wav 2.0 achieves competitive cross-lingual VC even only trained on monolingual corpus. Thus, vec2wav 2.0 shows timbre can potentially be manipulated only by speech token vocoders, pushing the frontiers of VC and speech synthesis. </p>
<blockquote>
<p>æˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°çš„è¯­éŸ³ç¦»æ•£ä»¤ç‰Œç¼–è§£ç å™¨vec2wav 2.0ï¼Œå®ƒæ”¹è¿›äº†è¯­éŸ³è½¬æ¢ï¼ˆVCï¼‰ã€‚æˆ‘ä»¬ä½¿ç”¨è¯­éŸ³è‡ªç›‘ç£æ¨¡å‹çš„ç¦»æ•£ä»¤ç‰Œä½œä¸ºæºè¯­éŸ³çš„å†…å®¹ç‰¹å¾ï¼Œå¹¶å°†VCè§†ä¸ºæç¤ºæ€§ç¼–è§£ç ä»»åŠ¡ã€‚ä¸ºäº†è§£å†³å†…å®¹ä»¤ç‰Œä¸­æ‰¬å£°å™¨éŸ³è‰²çš„æŸå¤±é—®é¢˜ï¼Œvec2wav 2.0åˆ©ç”¨WavLMç‰¹å¾æä¾›å¼ºå¤§çš„éŸ³è‰²ç›¸å…³ä¿¡æ¯ã€‚æå‡ºäº†ä¸€ç§æ–°å‹çš„è‡ªé€‚åº”Snakeæ¿€æ´»å‡½æ•°ï¼Œä»¥æ›´å¥½åœ°å°†éŸ³è‰²èå…¥æ³¢å½¢é‡å»ºè¿‡ç¨‹ã€‚é€šè¿‡è¿™ç§æ–¹å¼ï¼Œvec2wav 2.0èƒ½å¤Ÿåœ¨ç»™å®šä¸åŒçš„å‚è€ƒæç¤ºæ—¶å­¦ä¼šé€‚å½“åœ°æ”¹å˜æ¼”è®²è€…çš„éŸ³è‰²ã€‚æ­¤å¤–ï¼Œä¸éœ€è¦å¯¹vec2wav 2.0è¿›è¡Œæœ‰ç›‘ç£æ•°æ®çš„è®­ç»ƒï¼Œå°±èƒ½ä½¿å…¶æœ‰æ•ˆåœ°å·¥ä½œã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œåœ¨ä»»æ„åˆ°ä»»æ„çš„VCä¸­ï¼Œvec2wav 2.0åœ¨éŸ³é¢‘è´¨é‡å’Œè¯´è¯äººç›¸ä¼¼æ€§æ–¹é¢å¤§å¤§è¶…è¿‡äº†æ‰€æœ‰å…¶ä»–åŸºçº¿ã€‚æ¶ˆèç ”ç©¶éªŒè¯äº†æ‰€æå‡ºæŠ€æœ¯çš„å½±å“ã€‚æ­¤å¤–ï¼Œvec2wav 2.0å³ä½¿åœ¨ä»…ä½¿ç”¨å•è¯­è¯­æ–™åº“è¿›è¡Œè®­ç»ƒçš„æƒ…å†µä¸‹ï¼Œä¹Ÿå®ç°äº†å…·æœ‰ç«äº‰åŠ›çš„è·¨è¯­è¨€VCã€‚å› æ­¤ï¼Œvec2wav 2.0è¡¨æ˜ï¼Œåªéœ€è¯­éŸ³ä»¤ç‰Œç¼–è§£ç å™¨å³å¯æ“çºµéŸ³è‰²ï¼Œä»è€Œæ¨åŠ¨VCå’Œè¯­éŸ³åˆæˆçš„å‰æ²¿ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2409.01995v3">PDF</a> 5 pages, 4 figures. Demo page:   <a target="_blank" rel="noopener" href="https://cantabile-kwok.github.io/vec2wav2/">https://cantabile-kwok.github.io/vec2wav2/</a></p>
<p><strong>Summary</strong></p>
<p>æ–°ä¸€ä»£è¯­éŸ³ç¦»æ•£ä»¤ç‰Œç¼–ç å™¨vec2wav 2.0æå‡ºï¼Œå°†è¯­éŸ³è‡ªç›‘ç£æ¨¡å‹çš„ç¦»æ•£ä»¤ç‰Œä½œä¸ºæºè¯­éŸ³çš„å†…å®¹ç‰¹å¾ï¼Œå¹¶å°†è¯­éŸ³è½¬æ¢ï¼ˆVCï¼‰è§†ä¸ºæç¤ºç¼–ç ä»»åŠ¡ã€‚ä¸ºå¼¥è¡¥å†…å®¹ä»¤ç‰Œä¸­æ¼”è®²è€…éŸ³è‰²çš„æŸå¤±ï¼Œvec2wav 2.0åˆ©ç”¨WavLMç‰¹å¾æä¾›å¼ºçƒˆçš„éŸ³è‰²ç›¸å…³ä¿¡æ¯ã€‚æå‡ºä¸€ç§æ–°å‹è‡ªé€‚åº”Snakeæ¿€æ´»å‡½æ•°ï¼Œæ›´å¥½åœ°å°†éŸ³è‰²èå…¥æ³¢å½¢é‡å»ºè¿‡ç¨‹ã€‚å› æ­¤ï¼Œvec2wav 2.0èƒ½å¤Ÿåœ¨ç»™å®šä¸åŒå‚è€ƒæç¤ºçš„æƒ…å†µä¸‹ï¼Œå­¦ä¹ é€‚å½“åœ°æ”¹å˜æ¼”è®²è€…çš„éŸ³è‰²ã€‚æ­¤å¤–ï¼Œè®­ç»ƒvec2wav 2.0æ— éœ€ç›‘ç£æ•°æ®ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œåœ¨ä»»æ„åˆ°ä»»æ„çš„è¯­éŸ³è½¬æ¢ä¸­ï¼Œvec2wav 2.0åœ¨éŸ³é¢‘è´¨é‡å’Œè¯´è¯äººç›¸ä¼¼æ€§æ–¹é¢å¤§å¤§ä¼˜äºæ‰€æœ‰å…¶ä»–åŸºçº¿ã€‚æ¶ˆèç ”ç©¶è¯å®äº†æ‰€æå‡ºæŠ€æœ¯çš„æ•ˆæœã€‚è€Œä¸”ï¼Œä»…åœ¨å•è¯­è¯­æ–™åº“ä¸Šè®­ç»ƒçš„vec2wav 2.0å®ç°äº†æœ‰ç«äº‰åŠ›çš„è·¨è¯­è¨€è¯­éŸ³è½¬æ¢ã€‚å› æ­¤ï¼Œvec2wav 2.0æ˜¾ç¤ºäº†éŸ³è‰²å¯èƒ½ä»…é€šè¿‡è¯­éŸ³ä»¤ç‰Œç¼–ç å™¨è¿›è¡Œæ“ä½œï¼Œæ¨åŠ¨äº†è¯­éŸ³è½¬æ¢å’Œè¯­éŸ³åˆæˆçš„å‰æ²¿ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>vec2wav 2.0æ˜¯ä¸€ç§æ–°çš„è¯­éŸ³ç¦»æ•£ä»¤ç‰Œvocoderï¼Œç”¨äºæ¨è¿›è¯­éŸ³è½¬æ¢ï¼ˆVCï¼‰æŠ€æœ¯ã€‚</li>
<li>è¯¥æ–¹æ³•ä½¿ç”¨è¯­éŸ³è‡ªç›‘ç£æ¨¡å‹çš„ç¦»æ•£ä»¤ç‰Œä½œä¸ºæºè¯­éŸ³çš„å†…å®¹ç‰¹å¾ï¼Œå¹¶å°†VCè§†ä¸ºæç¤ºç¼–ç ä»»åŠ¡ã€‚</li>
<li>WavLMç‰¹å¾è¢«ç”¨æ¥æä¾›å¼ºçƒˆçš„éŸ³è‰²ç›¸å…³ä¿¡æ¯ï¼Œä»¥å¼¥è¡¥å†…å®¹ä»¤ç‰Œä¸­æ¼”è®²è€…éŸ³è‰²çš„æŸå¤±ã€‚</li>
<li>å¼•å…¥äº†ä¸€ç§æ–°å‹è‡ªé€‚åº”Snakeæ¿€æ´»å‡½æ•°ï¼Œä»¥æ›´å¥½åœ°å°†éŸ³è‰²èå…¥æ³¢å½¢é‡å»ºè¿‡ç¨‹ã€‚</li>
<li>vec2wav 2.0èƒ½åœ¨ç»™å®šä¸åŒå‚è€ƒæç¤ºçš„æƒ…å†µä¸‹å­¦ä¹ é€‚å½“æ”¹å˜æ¼”è®²è€…çš„éŸ³è‰²ã€‚</li>
<li>è¯¥æ¨¡å‹æ— éœ€ç›‘ç£æ•°æ®å³å¯è¿›è¡Œæœ‰æ•ˆè®­ç»ƒã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2409.01995">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-86dd9465920d3500042377129434fea7.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d2e0b8d17c174e3b7daaabd526766acb.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-aa91c8e5dce637dbdb885a86d0e9ff10.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-5981cb1d57b1df06f385dff6e7f8f131.jpg" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2024-12-25/TTS/">https://kedreamix.github.io/Talk2Paper/Paper/2024-12-25/TTS/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/TTS/">
                                    <span class="chip bg-color">TTS</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2024-12-25/Interactive/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-1e402cfd0177540f4f3424d40e20680e.jpg" class="responsive-img" alt="Interactive">
                        
                        <span class="card-title">Interactive</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Interactive æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2024-12-25  RF-GML Reference-Free Generative Machine Listener
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2024-12-25
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Interactive/" class="post-category">
                                    Interactive
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Interactive/">
                        <span class="chip bg-color">Interactive</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2024-12-25/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-cc8da03525039b4ae3e9044e917243e7.jpg" class="responsive-img" alt="åŒ»å­¦å›¾åƒ">
                        
                        <span class="card-title">åŒ»å­¦å›¾åƒ</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            åŒ»å­¦å›¾åƒ æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2024-12-25  FaceLift Single Image to 3D Head with View Generation and GS-LRM
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2024-12-25
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/" class="post-category">
                                    åŒ»å­¦å›¾åƒ
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/">
                        <span class="chip bg-color">åŒ»å­¦å›¾åƒ</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">11676k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
