<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="3DGS">
    <meta name="description" content="3DGS æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2024-12-25  FaceLift Single Image to 3D Head with View Generation and GS-LRM">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>3DGS | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://picx.zhimg.com/v2-c4bd39fe1382d5c5937f6b8f92557747.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">3DGS</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/3DGS/">
                                <span class="chip bg-color">3DGS</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/3DGS/" class="post-category">
                                3DGS
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2024-12-25
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2024-12-25
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    16.8k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    68 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2024-12-25-æ›´æ–°"><a href="#2024-12-25-æ›´æ–°" class="headerlink" title="2024-12-25 æ›´æ–°"></a>2024-12-25 æ›´æ–°</h1><h2 id="FaceLift-Single-Image-to-3D-Head-with-View-Generation-and-GS-LRM"><a href="#FaceLift-Single-Image-to-3D-Head-with-View-Generation-and-GS-LRM" class="headerlink" title="FaceLift: Single Image to 3D Head with View Generation and GS-LRM"></a>FaceLift: Single Image to 3D Head with View Generation and GS-LRM</h2><p><strong>Authors:Weijie Lyu, Yi Zhou, Ming-Hsuan Yang, Zhixin Shu</strong></p>
<p>We present FaceLift, a feed-forward approach for rapid, high-quality, 360-degree head reconstruction from a single image. Our pipeline begins by employing a multi-view latent diffusion model that generates consistent side and back views of the head from a single facial input. These generated views then serve as input to a GS-LRM reconstructor, which produces a comprehensive 3D representation using Gaussian splats. To train our system, we develop a dataset of multi-view renderings using synthetic 3D human head as-sets. The diffusion-based multi-view generator is trained exclusively on synthetic head images, while the GS-LRM reconstructor undergoes initial training on Objaverse followed by fine-tuning on synthetic head data. FaceLift excels at preserving identity and maintaining view consistency across views. Despite being trained solely on synthetic data, FaceLift demonstrates remarkable generalization to real-world images. Through extensive qualitative and quantitative evaluations, we show that FaceLift outperforms state-of-the-art methods in 3D head reconstruction, highlighting its practical applicability and robust performance on real-world images. In addition to single image reconstruction, FaceLift supports video inputs for 4D novel view synthesis and seamlessly integrates with 2D reanimation techniques to enable 3D facial animation. Project page: <a target="_blank" rel="noopener" href="https://weijielyu.github.io/FaceLift">https://weijielyu.github.io/FaceLift</a>. </p>
<blockquote>
<p>æˆ‘ä»¬æå‡ºäº†FaceLiftï¼Œè¿™æ˜¯ä¸€ç§å‰é¦ˆæ–¹æ³•ï¼Œå¯ä»¥ä»å•å¼ å›¾åƒå¿«é€Ÿè¿›è¡Œé«˜è´¨é‡ã€360åº¦çš„å¤´éƒ¨é‡å»ºã€‚æˆ‘ä»¬çš„æµç¨‹é¦–å…ˆé‡‡ç”¨å¤šè§†è§’æ½œåœ¨æ‰©æ•£æ¨¡å‹ï¼Œä»å•å¼ é¢éƒ¨è¾“å…¥ç”Ÿæˆä¸€è‡´çš„å¤´éƒ¨ä¾§é¢å’ŒèƒŒé¢è§†å›¾ã€‚è¿™äº›ç”Ÿæˆçš„è§†å›¾ç„¶åä½œä¸ºGS-LRMé‡å»ºå™¨çš„è¾“å…¥ï¼Œä½¿ç”¨é«˜æ–¯çƒæ–‘æŠ€æœ¯äº§ç”Ÿå…¨é¢çš„3Dè¡¨ç¤ºã€‚ä¸ºäº†è®­ç»ƒæˆ‘ä»¬çš„ç³»ç»Ÿï¼Œæˆ‘ä»¬ä½¿ç”¨åˆæˆ3Däººå¤´æ•°æ®é›†å¼€å‘äº†ä¸€ä¸ªå¤šè§†è§’æ¸²æŸ“æ•°æ®é›†ã€‚åŸºäºæ‰©æ•£çš„å¤šè§†è§’ç”Ÿæˆå™¨ä»…åœ¨åˆæˆå¤´éƒ¨å›¾åƒä¸Šè¿›è¡Œè®­ç»ƒï¼Œè€ŒGS-LRMé‡å»ºå™¨é¦–å…ˆåœ¨Objaverseä¸Šè¿›è¡Œåˆæ­¥è®­ç»ƒï¼Œç„¶ååœ¨åˆæˆå¤´éƒ¨æ•°æ®ä¸Šè¿›è¡Œå¾®è°ƒã€‚FaceLiftæ“…é•¿äºä¿æŒèº«ä»½ä¸€è‡´æ€§å¹¶ç»´æŒè§†è§’çš„ä¸€è‡´æ€§ã€‚å°½ç®¡åªåœ¨åˆæˆæ•°æ®ä¸Šè¿›è¡Œè®­ç»ƒï¼ŒFaceLiftåœ¨çœŸå®ä¸–ç•Œå›¾åƒä¸Šè¡¨ç°å‡ºäº†æƒŠäººçš„æ³›åŒ–èƒ½åŠ›ã€‚é€šè¿‡å¹¿æ³›çš„è´¨é‡å’Œæ•°é‡è¯„ä¼°ï¼Œæˆ‘ä»¬è¯æ˜äº†FaceLiftåœ¨3Då¤´éƒ¨é‡å»ºæ–¹é¢ä¼˜äºæœ€æ–°æŠ€æœ¯ï¼Œçªå‡ºäº†å…¶åœ¨çœŸå®ä¸–ç•Œå›¾åƒä¸Šçš„å®ç”¨æ€§å’Œç¨³å¥æ€§èƒ½ã€‚é™¤äº†å•å›¾åƒé‡å»ºå¤–ï¼ŒFaceLiftè¿˜æ”¯æŒè§†é¢‘è¾“å…¥ç”¨äº4Dæ–°é¢–è§†å›¾åˆæˆï¼Œå¹¶ä¸2DåŠ¨ç”»æŠ€æœ¯æ— ç¼é›†æˆä»¥å®ç°3Dé¢éƒ¨åŠ¨ç”»ã€‚é¡¹ç›®é¡µé¢ï¼š<a target="_blank" rel="noopener" href="https://weijielyu.github.io/FaceLift%E3%80%82">https://weijielyu.github.io/FaceLiftã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.17812v1">PDF</a> Project page: <a target="_blank" rel="noopener" href="https://weijielyu.github.io/FaceLift">https://weijielyu.github.io/FaceLift</a></p>
<p><strong>Summary</strong></p>
<p>FaceLiftæ˜¯ä¸€ç§åŸºäºå‰é¦ˆæ–¹æ³•çš„å¿«é€Ÿé«˜è´¨é‡å•å›¾åƒ360åº¦å¤´éƒ¨é‡å»ºæŠ€æœ¯ã€‚å®ƒé€šè¿‡å¤šè§†è§’æ½œåœ¨æ‰©æ•£æ¨¡å‹ç”Ÿæˆä¸€è‡´çš„å¤´ä¾§å’ŒèƒŒé¢è§†å›¾ï¼Œç„¶ååˆ©ç”¨GS-LRMé‡å»ºå™¨ç”Ÿæˆå…¨é¢çš„3Dè¡¨ç¤ºã€‚FaceLiftåœ¨åˆæˆæ•°æ®é›†ä¸Šè®­ç»ƒï¼Œèƒ½åœ¨çœŸå®ä¸–ç•Œå›¾åƒä¸­å±•ç°å‡ºè‰¯å¥½çš„æ³›åŒ–æ€§èƒ½ï¼Œå¹¶åœ¨å•å›¾åƒé‡å»ºå’Œè§†é¢‘è¾“å…¥çš„æ–°å‹è§†å›¾åˆæˆæ–¹é¢è¡¨ç°å‡ºä¼˜å¼‚æ€§èƒ½ï¼Œè¿˜æ”¯æŒ3Dé¢éƒ¨åŠ¨ç”»ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>FaceLiftæ˜¯ä¸€ç§å¿«é€Ÿã€é«˜è´¨é‡çš„å¤´éƒ¨é‡å»ºæ–¹æ³•ï¼Œèƒ½å¤Ÿä»å•ä¸€å›¾åƒå®ç°360åº¦å¤´éƒ¨é‡å»ºã€‚</li>
<li>FaceLiftä½¿ç”¨å¤šè§†è§’æ½œåœ¨æ‰©æ•£æ¨¡å‹ç”Ÿæˆä¸€è‡´çš„å¤´ä¾§å’ŒèƒŒé¢è§†å›¾ã€‚</li>
<li>GS-LRMé‡å»ºå™¨ç”¨äºç”Ÿæˆå…¨é¢çš„3Dè¡¨ç¤ºã€‚</li>
<li>FaceLiftåœ¨åˆæˆæ•°æ®é›†ä¸Šè¿›è¡Œè®­ç»ƒï¼Œä½†èƒ½åœ¨çœŸå®ä¸–ç•Œå›¾åƒä¸­å±•ç°å‡ºè‰¯å¥½çš„æ³›åŒ–æ€§èƒ½ã€‚</li>
<li>FaceLiftåœ¨å•å›¾åƒé‡å»ºå’Œè§†é¢‘è¾“å…¥çš„æ–°å‹è§†å›¾åˆæˆæ–¹é¢è¡¨ç°å‡ºä¼˜å¼‚æ€§èƒ½ã€‚</li>
<li>FaceLiftæ”¯æŒ3Dé¢éƒ¨åŠ¨ç”»ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.17812">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-349eec9112cef735aaf6ae4647cdbd29.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-cc8da03525039b4ae3e9044e917243e7.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-fd63245f29e72293d12e29ceb8c5e623.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a1e271b62307e29e5a34919c49d9602d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-5e78fba8fb441278560f1de775d5d63b.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-62f6ee998869e53fbfbf42868e93a43d.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="ActiveGS-Active-Scene-Reconstruction-using-Gaussian-Splatting"><a href="#ActiveGS-Active-Scene-Reconstruction-using-Gaussian-Splatting" class="headerlink" title="ActiveGS: Active Scene Reconstruction using Gaussian Splatting"></a>ActiveGS: Active Scene Reconstruction using Gaussian Splatting</h2><p><strong>Authors:Liren Jin, Xingguang Zhong, Yue Pan, Jens Behley, Cyrill Stachniss, Marija PopoviÄ‡</strong></p>
<p>Robotics applications often rely on scene reconstructions to enable downstream tasks. In this work, we tackle the challenge of actively building an accurate map of an unknown scene using an on-board RGB-D camera. We propose a hybrid map representation that combines a Gaussian splatting map with a coarse voxel map, leveraging the strengths of both representations: the high-fidelity scene reconstruction capabilities of Gaussian splatting and the spatial modelling strengths of the voxel map. The core of our framework is an effective confidence modelling technique for the Gaussian splatting map to identify under-reconstructed areas, while utilising spatial information from the voxel map to target unexplored areas and assist in collision-free path planning. By actively collecting scene information in under-reconstructed and unexplored areas for map updates, our approach achieves superior Gaussian splatting reconstruction results compared to state-of-the-art approaches. Additionally, we demonstrate the applicability of our active scene reconstruction framework in the real world using an unmanned aerial vehicle. </p>
<blockquote>
<p>æœºå™¨äººåº”ç”¨é€šå¸¸ä¾èµ–äºåœºæ™¯é‡å»ºæ¥å®ç°åç»­ä»»åŠ¡ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬è§£å†³äº†ä½¿ç”¨è½¦è½½RGB-Dç›¸æœºä¸»åŠ¨æ„å»ºæœªçŸ¥åœºæ™¯ç²¾ç¡®åœ°å›¾çš„æŒ‘æˆ˜ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§æ··åˆåœ°å›¾è¡¨ç¤ºæ–¹æ³•ï¼Œç»“åˆäº†é«˜æ–¯æ‹¼è´´åœ°å›¾å’Œç²—ç³™ä½“ç´ åœ°å›¾ï¼Œåˆ©ç”¨ä¸¤è€…çš„ä¼˜åŠ¿ï¼šé«˜æ–¯æ‹¼è´´çš„é«˜ä¿çœŸåœºæ™¯é‡å»ºèƒ½åŠ›å’Œä½“ç´ åœ°å›¾çš„ç©ºé—´å»ºæ¨¡ä¼˜åŠ¿ã€‚æˆ‘ä»¬æ¡†æ¶çš„æ ¸å¿ƒæ˜¯å¯¹é«˜æ–¯æ‹¼è´´åœ°å›¾è¿›è¡Œç½®ä¿¡å»ºæ¨¡çš„æœ‰æ•ˆæŠ€æœ¯ï¼Œä»¥è¯†åˆ«æœªé‡å»ºåŒºåŸŸï¼ŒåŒæ—¶åˆ©ç”¨ä½“ç´ åœ°å›¾çš„ç©ºé—´ä¿¡æ¯è¿›è¡Œé’ˆå¯¹æ€§æ¢ç´¢ï¼Œå¹¶è¾…åŠ©å®ç°æ— ç¢°æ’è·¯å¾„è§„åˆ’ã€‚é€šè¿‡ä¸»åŠ¨æ”¶é›†æœªé‡å»ºå’Œæ¢ç´¢åŒºåŸŸçš„åœºæ™¯ä¿¡æ¯è¿›è¡Œåœ°å›¾æ›´æ–°ï¼Œæˆ‘ä»¬çš„æ–¹æ³•ä¸æœ€å…ˆè¿›çš„æ–¹æ³•ç›¸æ¯”ï¼Œå®ç°äº†ä¼˜è¶Šçš„é«˜æ–¯æ‹¼è´´é‡å»ºç»“æœã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜ä½¿ç”¨æ— äººæœºåœ¨å®é™…ä¸–ç•Œä¸­å±•ç¤ºäº†æˆ‘ä»¬çš„ä¸»åŠ¨åœºæ™¯é‡å»ºæ¡†æ¶çš„é€‚ç”¨æ€§ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.17769v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡è§£å†³çš„æ˜¯ä½¿ç”¨æœºè½½RGB-Dç›¸æœºå¯¹æœªçŸ¥åœºæ™¯è¿›è¡Œç²¾ç¡®åœ°å›¾æ„å»ºçš„æŒ‘æˆ˜ã€‚æ–‡ç« æå‡ºäº†ä¸€ç§æ··åˆåœ°å›¾è¡¨ç¤ºæ–¹æ³•ï¼Œç»“åˆäº†é«˜æ–¯å–·ç»˜åœ°å›¾å’Œç²—ç³™ä½“ç´ åœ°å›¾çš„ä¼˜åŠ¿ã€‚è¯¥æ¡†æ¶çš„æ ¸å¿ƒæ˜¯ä¸€ç§æœ‰æ•ˆçš„ç½®ä¿¡åº¦å»ºæ¨¡æŠ€æœ¯ï¼Œç”¨äºè¯†åˆ«é«˜æ–¯å–·ç»˜åœ°å›¾çš„æœªé‡å»ºåŒºåŸŸï¼ŒåŒæ—¶åˆ©ç”¨ä½“ç´ åœ°å›¾çš„ç©ºé—´ä¿¡æ¯æ¥å®šä½æœªæ¢ç´¢çš„åŒºåŸŸï¼Œè¾…åŠ©æ— ç¢°æ’è·¯å¾„è§„åˆ’ã€‚é€šè¿‡ä¸»åŠ¨æ”¶é›†æœªé‡å»ºå’Œæœªæ¢ç´¢åŒºåŸŸçš„åœºæ™¯ä¿¡æ¯è¿›è¡Œåœ°å›¾æ›´æ–°ï¼Œè¯¥æ–¹æ³•å®ç°äº†ä¼˜äºç°æœ‰æŠ€æœ¯çš„é«˜æ–¯å–·ç»˜é‡å»ºç»“æœï¼Œå¹¶åœ¨æ— äººæœºä¸Šå±•ç¤ºäº†å…¶å®é™…åº”ç”¨æ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æ–‡ç« è§£å†³äº†ä½¿ç”¨RGB-Dç›¸æœºå¯¹æœªçŸ¥åœºæ™¯è¿›è¡Œä¸»åŠ¨ç²¾ç¡®åœ°å›¾æ„å»ºçš„æŒ‘æˆ˜ã€‚</li>
<li>æå‡ºäº†ä¸€ç§æ··åˆåœ°å›¾è¡¨ç¤ºæ–¹æ³•ï¼Œç»“åˆäº†é«˜æ–¯å–·ç»˜åœ°å›¾å’Œä½“ç´ åœ°å›¾çš„ä¼˜åŠ¿ã€‚</li>
<li>ç½®ä¿¡åº¦å»ºæ¨¡æŠ€æœ¯ç”¨äºè¯†åˆ«é«˜æ–¯å–·ç»˜åœ°å›¾çš„æœªé‡å»ºåŒºåŸŸã€‚</li>
<li>åˆ©ç”¨ä½“ç´ åœ°å›¾çš„ç©ºé—´ä¿¡æ¯æ¥å®šä½æœªæ¢ç´¢çš„åŒºåŸŸï¼Œè¾…åŠ©æ— ç¢°æ’è·¯å¾„è§„åˆ’ã€‚</li>
<li>é€šè¿‡ä¸»åŠ¨æ”¶é›†åœºæ™¯ä¿¡æ¯æ›´æ–°åœ°å›¾ï¼Œå®ç°äº†ä¼˜è¶Šçš„é«˜æ–¯å–·ç»˜é‡å»ºç»“æœã€‚</li>
<li>æ–‡ç« å±•ç¤ºäº†è¯¥æ–¹æ³•åœ¨æ— äººæœºä¸Šçš„å®é™…åº”ç”¨æ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.17769">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-6ef7d8dce75716d8901ffae087fc90d3.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-daeb1d4e6e2d27889bc39c1fd6eed23d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d744d1df63ab0f4b5f404bcb0ec952e3.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-3d31fcba7e1c4bcd38fd8abfa8b318ef.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="GaussianPainter-Painting-Point-Cloud-into-3D-Gaussians-with-Normal-Guidance"><a href="#GaussianPainter-Painting-Point-Cloud-into-3D-Gaussians-with-Normal-Guidance" class="headerlink" title="GaussianPainter: Painting Point Cloud into 3D Gaussians with Normal   Guidance"></a>GaussianPainter: Painting Point Cloud into 3D Gaussians with Normal   Guidance</h2><p><strong>Authors:Jingqiu Zhou, Lue Fan, Xuesong Chen, Linjiang Huang, Si Liu, Hongsheng Li</strong></p>
<p>In this paper, we present GaussianPainter, the first method to paint a point cloud into 3D Gaussians given a reference image. GaussianPainter introduces an innovative feed-forward approach to overcome the limitations of time-consuming test-time optimization in 3D Gaussian splatting. Our method addresses a critical challenge in the field: the non-uniqueness problem inherent in the large parameter space of 3D Gaussian splatting. This space, encompassing rotation, anisotropic scales, and spherical harmonic coefficients, introduces the challenge of rendering similar images from substantially different Gaussian fields. As a result, feed-forward networks face instability when attempting to directly predict high-quality Gaussian fields, struggling to converge on consistent parameters for a given output. To address this issue, we propose to estimate a surface normal for each point to determine its Gaussian rotation. This strategy enables the network to effectively predict the remaining Gaussian parameters in the constrained space. We further enhance our approach with an appearance injection module, incorporating reference image appearance into Gaussian fields via a multiscale triplane representation. Our method successfully balances efficiency and fidelity in 3D Gaussian generation, achieving high-quality, diverse, and robust 3D content creation from point clouds in a single forward pass. </p>
<blockquote>
<p>æœ¬æ–‡ä»‹ç»äº†GaussianPainterï¼Œè¿™æ˜¯ä¸€ç§å°†ç‚¹äº‘ç»˜åˆ¶æˆä¸‰ç»´é«˜æ–¯ä½“çš„æ–°æ–¹æ³•ï¼Œåªéœ€æä¾›ä¸€å¼ å‚è€ƒå›¾åƒå³å¯ã€‚GaussianPainterå¼•å…¥äº†ä¸€ç§åˆ›æ–°çš„å‰é¦ˆæ–¹æ³•ï¼Œå…‹æœäº†ä¸‰ç»´é«˜æ–¯æ¶‚æŠ¹ä¸­è€—æ—¶æµ‹è¯•ä¼˜åŒ–çš„å±€é™æ€§ã€‚æˆ‘ä»¬çš„æ–¹æ³•è§£å†³äº†è¯¥é¢†åŸŸçš„ä¸€ä¸ªå…³é”®æŒ‘æˆ˜ï¼šä¸‰ç»´é«˜æ–¯æ¶‚æŠ¹çš„å¤§å‚æ•°ç©ºé—´æ‰€å›ºæœ‰çš„éå”¯ä¸€æ€§é—®é¢˜ã€‚è¿™ä¸ªç©ºé—´åŒ…æ‹¬æ—‹è½¬ã€å„å‘å¼‚æ€§å°ºåº¦å’Œçƒé¢è°æ³¢ç³»æ•°ï¼Œä»å®è´¨ä¸Šä¸åŒçš„é«˜æ–¯åœºæ¸²æŸ“ç›¸ä¼¼å›¾åƒçš„æŒ‘æˆ˜ã€‚å› æ­¤ï¼Œå‰é¦ˆç½‘ç»œåœ¨å°è¯•ç›´æ¥é¢„æµ‹é«˜è´¨é‡é«˜æ–¯åœºæ—¶é¢ä¸´ä¸ç¨³å®šé—®é¢˜ï¼Œéš¾ä»¥åœ¨ç»™å®šè¾“å‡ºä¸Šæ”¶æ•›äºä¸€è‡´å‚æ•°ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºä¸ºæ¯ä¸ªç‚¹ä¼°è®¡æ³•çº¿ä»¥ç¡®å®šå…¶é«˜æ–¯æ—‹è½¬ã€‚è¿™ä¸€ç­–ç•¥ä½¿ç½‘ç»œèƒ½å¤Ÿåœ¨çº¦æŸç©ºé—´ä¸­æœ‰æ•ˆåœ°é¢„æµ‹å‰©ä½™çš„é«˜æ–¯å‚æ•°ã€‚æˆ‘ä»¬è¿›ä¸€æ­¥é€šè¿‡å¤–è§‚æ³¨å…¥æ¨¡å—å¢å¼ºäº†æˆ‘ä»¬çš„æ–¹æ³•ï¼Œè¯¥æ¨¡å—é€šè¿‡å¤šå°ºåº¦triplaneè¡¨ç¤ºå°†å‚è€ƒå›¾åƒå¤–è§‚èå…¥åˆ°é«˜æ–¯åœºä¸­ã€‚æˆ‘ä»¬çš„æ–¹æ³•åœ¨ä¸‰ç»´é«˜æ–¯ç”Ÿæˆä¸­æˆåŠŸå®ç°äº†æ•ˆç‡å’Œä¿çœŸåº¦çš„å¹³è¡¡ï¼Œå•æ¬¡å‰å‘ä¼ é€’å³å¯å®ç°é«˜è´¨é‡ã€å¤šæ ·åŒ–å’Œç¨³å¥çš„3Då†…å®¹åˆ›å»ºã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.17715v1">PDF</a> To appear in AAAI 2025</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†GaussianPainteræ–¹æ³•ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿå°†ç‚¹äº‘ç»˜åˆ¶æˆ3Dé«˜æ–¯å›¾åƒç»™å®šå‚è€ƒå›¾åƒã€‚GaussianPainteré‡‡ç”¨åˆ›æ–°çš„å‰é¦ˆæ–¹æ³•ï¼Œå…‹æœäº†3Dé«˜æ–¯å–·æ¶‚ä¸­è€—æ—¶çš„æ—¶é—´ä¼˜åŒ–æ–¹æ³•çš„å±€é™æ€§ã€‚è¯¥æ–¹æ³•è§£å†³äº†é¢†åŸŸä¸­çš„ä¸€ä¸ªå…³é”®æŒ‘æˆ˜ï¼š3Dé«˜æ–¯å–·æ¶‚å‚æ•°ç©ºé—´ä¸­çš„éå”¯ä¸€æ€§é—®é¢˜ã€‚æ­¤ç©ºé—´åŒ…å«æ—‹è½¬ã€å„å‘å¼‚æ€§å°ºåº¦å’Œè°æ³¢ç³»æ•°ç­‰é—®é¢˜ï¼Œä½¿å¾—ä»å®è´¨ä¸Šä¸åŒçš„é«˜æ–¯åœºæ¸²æŸ“ç›¸ä¼¼å›¾åƒå˜å¾—å›°éš¾ã€‚ä¸ºè§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºä¸ºæ¯ä¸ªç‚¹ä¼°ç®—è¡¨é¢æ³•çº¿ä»¥ç¡®å®šå…¶é«˜æ–¯æ—‹è½¬ã€‚æ­¤ç­–ç•¥ä½¿ç½‘ç»œèƒ½å¤Ÿåœ¨çº¦æŸç©ºé—´ä¸­æœ‰æ•ˆé¢„æµ‹å…¶ä½™çš„é«˜æ–¯å‚æ•°ã€‚æˆ‘ä»¬è¿›ä¸€æ­¥é€šè¿‡å¤–è§‚æ³¨å…¥æ¨¡å—å¢å¼ºæˆ‘ä»¬çš„æ–¹æ³•ï¼Œé€šè¿‡å¤šå°ºåº¦triplaneè¡¨ç¤ºæ³•å°†å‚è€ƒå›¾åƒå¤–è§‚èå…¥é«˜æ–¯åœºã€‚æˆ‘ä»¬çš„æ–¹æ³•åœ¨æ•ˆç‡å’Œä¿çœŸåº¦ä¹‹é—´å–å¾—äº†å¹³è¡¡ï¼Œåœ¨å•æ¬¡å‰å‘ä¼ é€’ä¸­å®ç°äº†é«˜è´¨é‡ã€å¤šæ ·åŒ–å’Œç¨³å¥çš„3Då†…å®¹åˆ›å»ºã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>GaussianPainteræ˜¯ç¬¬ä¸€ä¸ªèƒ½å°†ç‚¹äº‘ç»˜åˆ¶æˆ3Dé«˜æ–¯å›¾åƒçš„æ–¹æ³•ï¼Œç»™å®šä¸€ä¸ªå‚è€ƒå›¾åƒã€‚</li>
<li>è¯¥æ–¹æ³•é‡‡ç”¨å‰é¦ˆæ–¹æ³•ï¼Œå…‹æœäº†3Dé«˜æ–¯å–·æ¶‚ä¸­çš„æ—¶é—´ä¼˜åŒ–éš¾é¢˜ã€‚</li>
<li>è§£å†³äº†3Dé«˜æ–¯å–·æ¶‚å‚æ•°ç©ºé—´ä¸­çš„éå”¯ä¸€æ€§é—®é¢˜ï¼Œè¯¥ç©ºé—´åŒ…å«æ—‹è½¬ã€å„å‘å¼‚æ€§å°ºåº¦å’Œè°æ³¢ç³»æ•°ç­‰é—®é¢˜ã€‚</li>
<li>é€šè¿‡ä¼°ç®—æ¯ä¸ªç‚¹çš„è¡¨é¢æ³•çº¿æ¥è§£å†³éå”¯ä¸€æ€§é—®é¢˜ï¼Œä»è€Œç¡®å®šé«˜æ–¯æ—‹è½¬ã€‚</li>
<li>å¼•å…¥å¤–è§‚æ³¨å…¥æ¨¡å—ï¼Œé€šè¿‡å¤šå°ºåº¦triplaneè¡¨ç¤ºæ³•å°†å‚è€ƒå›¾åƒèå…¥é«˜æ–¯åœºã€‚</li>
<li>è¯¥æ–¹æ³•åœ¨æ•ˆç‡å’Œä¿çœŸåº¦ä¹‹é—´å–å¾—äº†å¹³è¡¡ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.17715">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-bf4032b95a97941e03a0889a6300f8d7.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-1c894df3d1fce513f3b3c749f55c0c22.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-ab56aa1db148141494c9da56b9467397.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-8768ec1417414ca540fbbb39b69caa0b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-86538d2b3e1d51a23ac39020eb2e5ac3.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-04f484d16b83b7468009bf46c175785b.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="LangSurf-Language-Embedded-Surface-Gaussians-for-3D-Scene-Understanding"><a href="#LangSurf-Language-Embedded-Surface-Gaussians-for-3D-Scene-Understanding" class="headerlink" title="LangSurf: Language-Embedded Surface Gaussians for 3D Scene Understanding"></a>LangSurf: Language-Embedded Surface Gaussians for 3D Scene Understanding</h2><p><strong>Authors:Hao Li, Roy Qin, Zhengyu Zou, Diqi He, Bohan Li, Bingquan Dai, Dingewn Zhang, Junwei Han</strong></p>
<p>Applying Gaussian Splatting to perception tasks for 3D scene understanding is becoming increasingly popular. Most existing works primarily focus on rendering 2D feature maps from novel viewpoints, which leads to an imprecise 3D language field with outlier languages, ultimately failing to align objects in 3D space. By utilizing masked images for feature extraction, these approaches also lack essential contextual information, leading to inaccurate feature representation. To this end, we propose a Language-Embedded Surface Field (LangSurf), which accurately aligns the 3D language fields with the surface of objects, facilitating precise 2D and 3D segmentation with text query, widely expanding the downstream tasks such as removal and editing. The core of LangSurf is a joint training strategy that flattens the language Gaussian on the object surfaces using geometry supervision and contrastive losses to assign accurate language features to the Gaussians of objects. In addition, we also introduce the Hierarchical-Context Awareness Module to extract features at the image level for contextual information then perform hierarchical mask pooling using masks segmented by SAM to obtain fine-grained language features in different hierarchies. Extensive experiments on open-vocabulary 2D and 3D semantic segmentation demonstrate that LangSurf outperforms the previous state-of-the-art method LangSplat by a large margin. As shown in Fig.~\ref{fig:teaser}, our method is capable of segmenting objects in 3D space, thus boosting the effectiveness of our approach in instance recognition, removal, and editing, which is also supported by comprehensive experiments. \url{<a target="_blank" rel="noopener" href="https://langsurf.github.io}{project/">https://langsurf.github.io}{Project</a> Page}. </p>
<blockquote>
<p>å°†é«˜æ–¯æ‘Šé“ºåº”ç”¨äº3Dåœºæ™¯ç†è§£çš„æ„ŸçŸ¥ä»»åŠ¡è¶Šæ¥è¶Šå—æ¬¢è¿ã€‚ç°æœ‰çš„å¤§å¤šæ•°å·¥ä½œä¸»è¦é›†ä¸­åœ¨ä»æ–°é¢–è§†è§’æ¸²æŸ“2Dç‰¹å¾å›¾ï¼Œè¿™å¯¼è‡´3Dè¯­è¨€åœºå­˜åœ¨ç¦»ç¾¤å€¼è¯­è¨€ï¼Œæœ€ç»ˆæ— æ³•å°†å¯¹è±¡å¯¹é½åˆ°ä¸‰ç»´ç©ºé—´ä¸­ã€‚è¿™äº›æ–¹æ³•é€šè¿‡åˆ©ç”¨é®ç½©å›¾åƒè¿›è¡Œç‰¹å¾æå–ï¼Œä¹Ÿç¼ºä¹å¿…è¦çš„ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œå¯¼è‡´ç‰¹å¾è¡¨ç¤ºä¸å‡†ç¡®ã€‚å› æ­¤ï¼Œæˆ‘ä»¬æå‡ºäº†è¯­è¨€åµŒå…¥è¡¨é¢åœºï¼ˆLangSurfï¼‰ï¼Œå®ƒèƒ½å¤Ÿå‡†ç¡®åœ°å°†3Dè¯­è¨€åœºä¸ç‰©ä½“è¡¨é¢å¯¹é½ï¼Œä¾¿äºé€šè¿‡æ–‡æœ¬æŸ¥è¯¢è¿›è¡Œç²¾ç¡®çš„äºŒç»´å’Œä¸‰ç»´åˆ†å‰²ï¼Œå¹¶å¹¿æ³›æ‰©å±•ä¸‹æ¸¸ä»»åŠ¡ï¼Œå¦‚ç§»é™¤å’Œç¼–è¾‘ã€‚LangSurfçš„æ ¸å¿ƒæ˜¯ä¸€ç§è”åˆè®­ç»ƒç­–ç•¥ï¼Œå®ƒé€šè¿‡å‡ ä½•ç›‘ç£å’Œå¯¹æ¯”æŸå¤±å°†è¯­è¨€çš„Gaussianæ‘Šåœ¨ç‰©ä½“è¡¨é¢ï¼Œä¸ºç‰©ä½“çš„Gaussiansåˆ†é…å‡†ç¡®çš„è¯­è¨€ç‰¹å¾ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜å¼•å…¥äº†å±‚æ¬¡ä¸Šä¸‹æ–‡æ„ŸçŸ¥æ¨¡å—ï¼Œä»¥åœ¨å›¾åƒçº§åˆ«æå–ç‰¹å¾ä»¥è·å¾—ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œç„¶åä½¿ç”¨SAMåˆ†å‰²çš„é®ç½©è¿›è¡Œåˆ†å±‚é®ç½©æ± åŒ–ï¼Œä»¥åœ¨ä¸åŒå±‚æ¬¡ä¸Šè·å¾—ç²¾ç»†çš„è¯­è¨€ç‰¹å¾ã€‚åœ¨å¼€æ”¾è¯æ±‡çš„äºŒç»´å’Œä¸‰ç»´è¯­ä¹‰åˆ†å‰²æ–¹é¢çš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼ŒLangSurfæ˜æ˜¾ä¼˜äºä¹‹å‰çš„æœ€å…ˆè¿›æ–¹æ³•LangSplatã€‚å¦‚å›¾~\ref{fig:teaser}æ‰€ç¤ºï¼Œæˆ‘ä»¬çš„æ–¹æ³•èƒ½å¤Ÿåœ¨ä¸‰ç»´ç©ºé—´ä¸­å¯¹ç‰©ä½“è¿›è¡Œåˆ†å‰²ï¼Œä»è€Œæé«˜äº†åœ¨å®ä¾‹è¯†åˆ«ã€ç§»é™¤å’Œç¼–è¾‘æ–¹é¢çš„æ–¹æ³•çš„æœ‰æ•ˆæ€§ï¼Œè¿™ä¹Ÿæ˜¯ç”±ç»¼åˆå®éªŒæ‰€æ”¯æŒçš„ã€‚<a target="_blank" rel="noopener" href="https://langsurf.github.io/">é¡¹ç›®é¡µé¢</a>ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.17635v1">PDF</a> \url{<a target="_blank" rel="noopener" href="https://langsurf.github.io}{project/">https://langsurf.github.io}{Project</a> Page}</p>
<p><strong>æ‘˜è¦</strong><br>    åŸºäºé«˜æ–¯å–·æº…æŠ€æœ¯ï¼Œæå‡ºä¸€ç§è¯­è¨€åµŒå…¥è¡¨é¢åœºï¼ˆLangSurfï¼‰ï¼Œç”¨äºç²¾å‡†å¯¹é½3Dè¯­è¨€åœºä¸ç‰©ä½“è¡¨é¢ï¼Œå®ç°é€šè¿‡æ–‡æœ¬æŸ¥è¯¢è¿›è¡Œç²¾ç¡®çš„2Då’Œ3Dåˆ†å‰²ï¼Œå¹¶å¤§å¤§æ‰©å±•äº†å¦‚ä¸‹æ¸¸ä»»åŠ¡ï¼Œå¦‚ç§»é™¤å’Œç¼–è¾‘ã€‚æ ¸å¿ƒåœ¨äºé‡‡ç”¨è”åˆè®­ç»ƒç­–ç•¥ï¼Œé€šè¿‡å‡ ä½•ç›‘ç£å’Œå¯¹æ¯”æŸå¤±ï¼Œå°†è¯­è¨€ç‰¹å¾å‡†ç¡®åˆ†é…ç»™ç‰©ä½“çš„é«˜æ–¯å›¾ã€‚å¼•å…¥å±‚æ¬¡ä¸Šä¸‹æ–‡æ„ŸçŸ¥æ¨¡å—ï¼Œæå–å›¾åƒçº§åˆ«çš„ç‰¹å¾è¿›è¡Œä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œç„¶åä½¿ç”¨å±‚æ¬¡æ©è†œæ± åŒ–è·å¾—ä¸åŒå±‚æ¬¡çš„ç²¾ç»†è¯­è¨€ç‰¹å¾ã€‚åœ¨å¼€æ”¾è¯æ±‡è¡¨çš„2Då’Œ3Dè¯­ä¹‰åˆ†å‰²å®éªŒä¸­ï¼ŒLangSurfæ˜¾è‘—ä¼˜äºä¹‹å‰çš„æœ€æ–°æ–¹æ³•LangSplatã€‚å¦‚å›¾ã€Šfig:teaserã€‹æ‰€ç¤ºï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿåˆ†å‰²3Dç©ºé—´ä¸­çš„ç‰©ä½“ï¼Œæé«˜äº†åœ¨å®ä¾‹è¯†åˆ«ã€ç§»é™¤å’Œç¼–è¾‘ä¸­çš„æœ‰æ•ˆæ€§ã€‚</p>
<p><strong>å…³é”®è§è§£</strong></p>
<ol>
<li>æå‡ºäº†ä¸€ç§æ–°çš„æ–¹æ³•LangSurfï¼ŒåŸºäºé«˜æ–¯å–·æº…æŠ€æœ¯ï¼Œç”¨äºæ”¹å–„3Dåœºæ™¯ç†è§£ä¸­çš„æ„ŸçŸ¥ä»»åŠ¡ã€‚</li>
<li>LangSurfèƒ½å¤Ÿç²¾å‡†å¯¹é½3Dè¯­è¨€åœºä¸ç‰©ä½“è¡¨é¢ï¼Œå®ç°é€šè¿‡æ–‡æœ¬æŸ¥è¯¢è¿›è¡Œç²¾ç¡®çš„2Då’Œ3Dåˆ†å‰²ã€‚</li>
<li>å¼•å…¥è”åˆè®­ç»ƒç­–ç•¥ï¼Œé€šè¿‡å‡ ä½•ç›‘ç£å’Œå¯¹æ¯”æŸå¤±ï¼Œä»¥åˆ†é…å‡†ç¡®çš„è¯­è¨€ç‰¹å¾åˆ°ç‰©ä½“çš„é«˜æ–¯å›¾ã€‚</li>
<li>å¼•å…¥äº†å±‚æ¬¡ä¸Šä¸‹æ–‡æ„ŸçŸ¥æ¨¡å—æ¥æå–å›¾åƒçº§åˆ«çš„ç‰¹å¾ï¼Œå¹¶é€šè¿‡å±‚æ¬¡æ©è†œæ± åŒ–è·å–ä¸åŒå±‚æ¬¡çš„ç²¾ç»†è¯­è¨€ç‰¹å¾ã€‚</li>
<li>LangSurfåœ¨å¼€æ”¾è¯æ±‡è¡¨çš„2Då’Œ3Dè¯­ä¹‰åˆ†å‰²å®éªŒä¸­æ˜¾è‘—ä¼˜äºä¹‹å‰çš„æœ€æ–°æ–¹æ³•ã€‚</li>
<li>è¯¥æ–¹æ³•èƒ½å¤Ÿåˆ†å‰²3Dç©ºé—´ä¸­çš„ç‰©ä½“ï¼Œæé«˜äº†å®ä¾‹è¯†åˆ«ã€ç§»é™¤å’Œç¼–è¾‘çš„æœ‰æ•ˆæ€§ã€‚</li>
<li>æä¾›äº†é¡¹ç›®é¡µé¢é“¾æ¥ï¼Œå¯ä»¥è¿›ä¸€æ­¥äº†è§£è¯¥æ–¹æ³•çš„ç›¸å…³ç»†èŠ‚å’Œå®ç°ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.17635">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-10eb5f8050a367be798866d1ee59015c.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-f167f47e1427d1bec9829597af12110d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ad8ca5b04bdbf25cbed4b35948bb5e02.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-8c93930476a808cdc9708f7513edda1d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-fe4d231b9ecd58708da37cf1f2220c33.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="CoSurfGS-Collaborative-3D-Surface-Gaussian-Splatting-with-Distributed-Learning-for-Large-Scene-Reconstruction"><a href="#CoSurfGS-Collaborative-3D-Surface-Gaussian-Splatting-with-Distributed-Learning-for-Large-Scene-Reconstruction" class="headerlink" title="CoSurfGS:Collaborative 3D Surface Gaussian Splatting with Distributed   Learning for Large Scene Reconstruction"></a>CoSurfGS:Collaborative 3D Surface Gaussian Splatting with Distributed   Learning for Large Scene Reconstruction</h2><p><strong>Authors:Yuanyuan Gao, Yalun Dai, Hao Li, Weicai Ye, Junyi Chen, Danpeng Chen, Dingwen Zhang, Tong He, Guofeng Zhang, Junwei Han</strong></p>
<p>3D Gaussian Splatting (3DGS) has demonstrated impressive performance in scene reconstruction. However, most existing GS-based surface reconstruction methods focus on 3D objects or limited scenes. Directly applying these methods to large-scale scene reconstruction will pose challenges such as high memory costs, excessive time consumption, and lack of geometric detail, which makes it difficult to implement in practical applications. To address these issues, we propose a multi-agent collaborative fast 3DGS surface reconstruction framework based on distributed learning for large-scale surface reconstruction. Specifically, we develop local model compression (LMC) and model aggregation schemes (MAS) to achieve high-quality surface representation of large scenes while reducing GPU memory consumption. Extensive experiments on Urban3d, MegaNeRF, and BlendedMVS demonstrate that our proposed method can achieve fast and scalable high-fidelity surface reconstruction and photorealistic rendering. Our project page is available at \url{<a target="_blank" rel="noopener" href="https://gyy456.github.io/CoSurfGS%7D">https://gyy456.github.io/CoSurfGS}</a>. </p>
<blockquote>
<p>3Dé«˜æ–¯æ··åˆï¼ˆ3DGSï¼‰åœ¨åœºæ™¯é‡å»ºä¸­å±•ç°äº†ä»¤äººå°è±¡æ·±åˆ»çš„æ€§èƒ½ã€‚ç„¶è€Œï¼Œå¤§å¤šæ•°ç°æœ‰çš„åŸºäºGSçš„è¡¨é¢é‡å»ºæ–¹æ³•ä¸»è¦å…³æ³¨äº3Då¯¹è±¡æˆ–æœ‰é™çš„åœºæ™¯ã€‚ç›´æ¥å°†è¿™äº›æ–¹æ³•åº”ç”¨äºå¤§è§„æ¨¡åœºæ™¯é‡å»ºå°†é¢ä¸´é«˜å†…å­˜æˆæœ¬ã€æ—¶é—´æ¶ˆè€—è¿‡å¤šä»¥åŠç¼ºä¹å‡ ä½•ç»†èŠ‚ç­‰æŒ‘æˆ˜ï¼Œè¿™ä½¿å¾—åœ¨å®é™…åº”ç”¨ä¸­éš¾ä»¥å®ç°ã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åŸºäºåˆ†å¸ƒå¼å­¦ä¹ çš„å¤šæ™ºèƒ½ä½“åä½œå¿«é€Ÿ3DGSè¡¨é¢é‡å»ºæ¡†æ¶ï¼Œç”¨äºå¤§è§„æ¨¡è¡¨é¢é‡å»ºã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬å¼€å‘äº†æœ¬åœ°æ¨¡å‹å‹ç¼©ï¼ˆLMCï¼‰å’Œæ¨¡å‹èšåˆæ–¹æ¡ˆï¼ˆMASï¼‰ï¼Œä»¥å®ç°å¤§å‹åœºæ™¯çš„é«˜è´¨é‡è¡¨é¢è¡¨ç¤ºï¼ŒåŒæ—¶é™ä½GPUå†…å­˜æ¶ˆè€—ã€‚åœ¨Urban3dã€MegaNeRFå’ŒBlendedMVSä¸Šçš„å¤§é‡å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬æå‡ºçš„æ–¹æ³•å¯ä»¥å®ç°å¿«é€Ÿã€å¯æ‰©å±•çš„é«˜ä¿çœŸè¡¨é¢é‡å»ºå’Œé€¼çœŸçš„æ¸²æŸ“ã€‚æˆ‘ä»¬çš„é¡¹ç›®é¡µé¢å¯é€šè¿‡ç½‘å€<a target="_blank" rel="noopener" href="https://gyy456.github.io/CoSurfGS%E8%AE%BF%E9%97%AE%E3%80%82">https://gyy456.github.io/CoSurfGSè®¿é—®ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.17612v1">PDF</a> Our project page is available at   \url{<a target="_blank" rel="noopener" href="https://gyy456.github.io/CoSurfGS%7D">https://gyy456.github.io/CoSurfGS}</a></p>
<p><strong>Summary</strong></p>
<p>3DGSåœ¨åœºæ™¯é‡å»ºä¸­è¡¨ç°ä¼˜å¼‚ï¼Œä½†ç°æœ‰æ–¹æ³•ä¸»è¦å…³æ³¨äºå°è§„æ¨¡çš„3Då¯¹è±¡æˆ–åœºæ™¯ï¼Œéš¾ä»¥ç›´æ¥åº”ç”¨äºå¤§è§„æ¨¡åœºæ™¯é‡å»ºã€‚é’ˆå¯¹æ­¤é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºåŸºäºå¤šæ™ºèƒ½ä½“åä½œçš„å¿«é€Ÿä¸‰ç»´é«˜æ–¯å±•å¼€è¡¨é¢é‡å»ºæ¡†æ¶ï¼Œåˆ©ç”¨åˆ†å¸ƒå¼å­¦ä¹ å®ç°å¤§è§„æ¨¡è¡¨é¢é‡å»ºã€‚é€šè¿‡å¼€å‘æœ¬åœ°æ¨¡å‹å‹ç¼©å’Œæ¨¡å‹èšåˆæ–¹æ¡ˆï¼Œå®ç°é«˜è´¨é‡çš„åœºæ™¯è¡¨é¢è¡¨ç¤ºï¼ŒåŒæ—¶é™ä½GPUå†…å­˜æ¶ˆè€—ã€‚å®éªŒè¯æ˜ï¼Œè¯¥æ–¹æ³•å¯å®ç°å¿«é€Ÿã€å¯æ‰©å±•çš„é«˜ä¿çœŸè¡¨é¢é‡å»ºå’Œé€¼çœŸçš„æ¸²æŸ“ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ç°æœ‰åŸºäºé«˜æ–¯å±•å¼€çš„é‡å»ºæ–¹æ³•é¢ä¸´å¤§è§„æ¨¡åœºæ™¯é‡å»ºçš„æŒ‘æˆ˜ã€‚</li>
<li>æå‡ºåŸºäºå¤šæ™ºèƒ½ä½“åä½œçš„å¿«é€Ÿä¸‰ç»´é«˜æ–¯å±•å¼€è¡¨é¢é‡å»ºæ¡†æ¶ï¼Œé€‚ç”¨äºå¤§è§„æ¨¡åœºæ™¯ã€‚</li>
<li>é€šè¿‡æœ¬åœ°æ¨¡å‹å‹ç¼©å’Œæ¨¡å‹èšåˆæ–¹æ¡ˆå®ç°é«˜è´¨é‡çš„åœºæ™¯è¡¨é¢è¡¨ç¤ºã€‚</li>
<li>æ–¹æ³•èƒ½é™ä½GPUå†…å­˜æ¶ˆè€—ï¼Œæé«˜è¡¨é¢é‡å»ºçš„æ•ˆç‡ã€‚</li>
<li>åœ¨Urban3dã€MegaNeRFå’ŒBlendedMVSç­‰æ•°æ®é›†ä¸Šè¿›è¡Œäº†å¹¿æ³›çš„å®éªŒéªŒè¯ã€‚</li>
<li>å®éªŒè¯æ˜è¯¥æ–¹æ³•å¯å®ç°å¿«é€Ÿã€å¯æ‰©å±•çš„é«˜ä¿çœŸè¡¨é¢é‡å»ºå’Œé€¼çœŸçš„æ¸²æŸ“ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.17612">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-3b120d2cdbcc401ec081a9bb8b83e1a3.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d44ecd1a805eaeb6e1a1a916d6c3b392.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f7913f93bc1e7e12952ba8d344fa854f.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="GSemSplat-Generalizable-Semantic-3D-Gaussian-Splatting-from-Uncalibrated-Image-Pairs"><a href="#GSemSplat-Generalizable-Semantic-3D-Gaussian-Splatting-from-Uncalibrated-Image-Pairs" class="headerlink" title="GSemSplat: Generalizable Semantic 3D Gaussian Splatting from   Uncalibrated Image Pairs"></a>GSemSplat: Generalizable Semantic 3D Gaussian Splatting from   Uncalibrated Image Pairs</h2><p><strong>Authors:Xingrui Wang, Cuiling Lan, Hanxin Zhu, Zhibo Chen, Yan Lu</strong></p>
<p>Modeling and understanding the 3D world is crucial for various applications, from augmented reality to robotic navigation. Recent advancements based on 3D Gaussian Splatting have integrated semantic information from multi-view images into Gaussian primitives. However, these methods typically require costly per-scene optimization from dense calibrated images, limiting their practicality. In this paper, we consider the new task of generalizable 3D semantic field modeling from sparse, uncalibrated image pairs. Building upon the Splatt3R architecture, we introduce GSemSplat, a framework that learns open-vocabulary semantic representations linked to 3D Gaussians without the need for per-scene optimization, dense image collections or calibration. To ensure effective and reliable learning of semantic features in 3D space, we employ a dual-feature approach that leverages both region-specific and context-aware semantic features as supervision in the 2D space. This allows us to capitalize on their complementary strengths. Experimental results on the ScanNet++ dataset demonstrate the effectiveness and superiority of our approach compared to the traditional scene-specific method. We hope our work will inspire more research into generalizable 3D understanding. </p>
<blockquote>
<p>å¯¹ä¸‰ç»´ä¸–ç•Œçš„å»ºæ¨¡å’Œç†è§£å¯¹äºå„ç§åº”ç”¨è‡³å…³é‡è¦ï¼Œä»å¢å¼ºç°å®åˆ°æœºå™¨äººå¯¼èˆªéƒ½æ˜¯å¦‚æ­¤ã€‚æœ€è¿‘åŸºäºä¸‰ç»´é«˜æ–¯è´´å›¾æŠ€æœ¯çš„è¿›å±•å·²ç»å°†å¤šè§†è§’å›¾åƒä¸­çš„è¯­ä¹‰ä¿¡æ¯é›†æˆåˆ°é«˜æ–¯åŸºæœ¬å…ƒç´ ä¸­ã€‚ç„¶è€Œï¼Œè¿™äº›æ–¹æ³•é€šå¸¸éœ€è¦æ˜‚è´µçš„åœºæ™¯ä¼˜åŒ–æ­¥éª¤ï¼Œä¾èµ–å¯†é›†çš„æ ¡å‡†å›¾åƒï¼Œé™åˆ¶äº†å…¶å®é™…åº”ç”¨æ€§ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ç¨€ç–ã€æœªç»æ ¡å‡†çš„å›¾åƒå¯¹çš„ä¸€èˆ¬æ€§ä¸‰ç»´è¯­ä¹‰åœºå»ºæ¨¡çš„æ–°ä»»åŠ¡ã€‚åœ¨Splatt3Ræ¶æ„çš„åŸºç¡€ä¸Šï¼Œæˆ‘ä»¬å¼•å…¥äº†GSemSplatæ¡†æ¶ï¼Œå®ƒèƒ½å¤Ÿåœ¨æ— éœ€è¿›è¡Œåœºæ™¯ä¼˜åŒ–ã€å¯†é›†çš„å›¾åƒé›†æˆ–æ ¡å‡†çš„æƒ…å†µä¸‹å­¦ä¹ å¼€æ”¾è¯æ±‡çš„è¯­ä¹‰è¡¨ç¤ºï¼Œå¹¶å°†å…¶é“¾æ¥åˆ°ä¸‰ç»´é«˜æ–¯å›¾ä¸Šã€‚ä¸ºäº†ä¿è¯åœ¨ä¸‰ç»´ç©ºé—´ä¸­æœ‰æ•ˆåœ°å­¦ä¹ è¯­ä¹‰ç‰¹å¾ï¼Œæˆ‘ä»¬é‡‡ç”¨äº†ä¸€ç§åŒé‡ç‰¹å¾æ–¹æ³•ï¼Œåœ¨äºŒç»´ç©ºé—´ä¸­åˆ©ç”¨ç‰¹å®šåŒºåŸŸå’Œä¸Šä¸‹æ–‡æ„ŸçŸ¥è¯­ä¹‰ç‰¹å¾ä½œä¸ºç›‘ç£ï¼Œè¿™è®©æˆ‘ä»¬å¯ä»¥å……åˆ†åˆ©ç”¨ä¸¤è€…çš„äº’è¡¥ä¼˜åŠ¿ã€‚åœ¨ScanNet++æ•°æ®é›†ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼Œä¸ä¼ ç»Ÿé’ˆå¯¹ç‰¹å®šåœºæ™¯çš„æ–¹æ³•ç›¸æ¯”ï¼Œæˆ‘ä»¬çš„æ–¹æ³•å…·æœ‰æœ‰æ•ˆæ€§å’Œä¼˜è¶Šæ€§ã€‚æˆ‘ä»¬å¸Œæœ›è¿™é¡¹å·¥ä½œèƒ½æ¿€å‘æ›´å¤šå…³äºé€šç”¨ä¸‰ç»´ç†è§£çš„ç ”ç©¶çµæ„Ÿã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.16932v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>åŸºäº3Dé«˜æ–¯å–·æº…æŠ€æœ¯çš„æœ€æ–°è¿›å±•ï¼Œå·²ç»èƒ½å¤Ÿå°†å¤šè§†è§’å›¾åƒçš„è¯­ä¹‰ä¿¡æ¯é›†æˆåˆ°é«˜æ–¯åŸºæœ¬å•å…ƒä¸­ã€‚ç„¶è€Œï¼Œè¿™äº›æ–¹æ³•é€šå¸¸éœ€è¦å¯†é›†æ ¡å‡†å›¾åƒçš„æ˜‚è´µåœºæ™¯ä¼˜åŒ–ï¼Œé™åˆ¶äº†å…¶å®ç”¨æ€§ã€‚æœ¬ç ”ç©¶è€ƒè™‘ä»ç¨€ç–ã€æœªæ ¡å‡†çš„å›¾åƒå¯¹ä¸­å»ºç«‹é€šç”¨çš„3Dè¯­ä¹‰åœºæ¨¡å‹çš„æ–°ä»»åŠ¡ã€‚åŸºäºSplatt3Ræ¶æ„ï¼Œæˆ‘ä»¬å¼•å…¥äº†GSemSplatæ¡†æ¶ï¼Œèƒ½å¤Ÿæ— éœ€åœºæ™¯ä¼˜åŒ–ã€å¯†é›†å›¾åƒé›†åˆæˆ–æ ¡å‡†ï¼Œç›´æ¥å…³è”å¼€æ”¾å¼è¯æ±‡è¯­ä¹‰è¡¨ç¤ºä¸3Dé«˜æ–¯åˆ†å¸ƒã€‚ä¸ºç¡®ä¿åœ¨3Dç©ºé—´ä¸­æœ‰æ•ˆå¯é åœ°å­¦ä¹ è¯­ä¹‰ç‰¹å¾ï¼Œæˆ‘ä»¬é‡‡ç”¨åŒé‡ç‰¹å¾æ–¹æ³•ï¼Œåˆ©ç”¨åŒºåŸŸç‰¹å®šå’Œä¸Šä¸‹æ–‡æ„ŸçŸ¥çš„è¯­ä¹‰ç‰¹å¾åœ¨äºŒç»´ç©ºé—´ä¸­è¿›è¡Œç›‘ç£ï¼Œå……åˆ†å‘æŒ¥å…¶äº’è¡¥ä¼˜åŠ¿ã€‚åœ¨ScanNet++æ•°æ®é›†ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•ç›¸è¾ƒäºä¼ ç»Ÿåœºæ™¯ç‰¹å®šæ–¹æ³•æ›´ä¸ºæœ‰æ•ˆå’Œä¼˜è¶Šã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>3Dä¸–ç•Œå»ºæ¨¡å¯¹äºå¢å¼ºç°å®å’Œæœºå™¨äººå¯¼èˆªç­‰åº”ç”¨è‡³å…³é‡è¦ã€‚</li>
<li>æœ€æ–°ç ”ç©¶é‡‡ç”¨åŸºäº3Dé«˜æ–¯å–·æº…çš„æŠ€æœ¯é›†æˆå¤šè§†è§’å›¾åƒçš„è¯­ä¹‰ä¿¡æ¯ã€‚</li>
<li>å½“å‰æ–¹æ³•éœ€è¦å¯†é›†æ ¡å‡†å›¾åƒçš„æ˜‚è´µåœºæ™¯ä¼˜åŒ–ï¼Œé™åˆ¶äº†å®ç”¨æ€§ã€‚</li>
<li>ç ”ç©¶æå‡ºäº†ä¸€ç§æ–°çš„ä»»åŠ¡ï¼šä»ç¨€ç–ã€æœªæ ¡å‡†çš„å›¾åƒå¯¹ä¸­è¿›è¡Œé€šç”¨3Dè¯­ä¹‰åœºå»ºæ¨¡ã€‚</li>
<li>å¼•å…¥GSemSplatæ¡†æ¶ï¼Œæ— éœ€åœºæ™¯ä¼˜åŒ–æˆ–å¯†é›†å›¾åƒé›†åˆå³å¯å…³è”å¼€æ”¾å¼è¯æ±‡è¯­ä¹‰è¡¨ç¤ºä¸3Dé«˜æ–¯åˆ†å¸ƒã€‚</li>
<li>é‡‡ç”¨åŒé‡ç‰¹å¾æ–¹æ³•ï¼Œç»“åˆåŒºåŸŸç‰¹å®šå’Œä¸Šä¸‹æ–‡æ„ŸçŸ¥çš„è¯­ä¹‰ç‰¹å¾åœ¨äºŒç»´ç©ºé—´ä¸­è¿›è¡Œç›‘ç£ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.16932">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-c4bd39fe1382d5c5937f6b8f92557747.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-3273ff5e9ab8ebd06775e9a2dba94d53.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-1c77dd3d7ffcd055d35ec4a36255abd3.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2024-12-25\./crop_3DGS/2412.16932v1/page_4_0.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-fdac69dcb8c9f0d300fdb6a4c2bc6dcf.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="GeoTexDensifier-Geometry-Texture-Aware-Densification-for-High-Quality-Photorealistic-3D-Gaussian-Splatting"><a href="#GeoTexDensifier-Geometry-Texture-Aware-Densification-for-High-Quality-Photorealistic-3D-Gaussian-Splatting" class="headerlink" title="GeoTexDensifier: Geometry-Texture-Aware Densification for High-Quality   Photorealistic 3D Gaussian Splatting"></a>GeoTexDensifier: Geometry-Texture-Aware Densification for High-Quality   Photorealistic 3D Gaussian Splatting</h2><p><strong>Authors:Hanqing Jiang, Xiaojun Xiang, Han Sun, Hongjie Li, Liyang Zhou, Xiaoyu Zhang, Guofeng Zhang</strong></p>
<p>3D Gaussian Splatting (3DGS) has recently attracted wide attentions in various areas such as 3D navigation, Virtual Reality (VR) and 3D simulation, due to its photorealistic and efficient rendering performance. High-quality reconstrution of 3DGS relies on sufficient splats and a reasonable distribution of these splats to fit real geometric surface and texture details, which turns out to be a challenging problem. We present GeoTexDensifier, a novel geometry-texture-aware densification strategy to reconstruct high-quality Gaussian splats which better comply with the geometric structure and texture richness of the scene. Specifically, our GeoTexDensifier framework carries out an auxiliary texture-aware densification method to produce a denser distribution of splats in fully textured areas, while keeping sparsity in low-texture regions to maintain the quality of Gaussian point cloud. Meanwhile, a geometry-aware splitting strategy takes depth and normal priors to guide the splitting sampling and filter out the noisy splats whose initial positions are far from the actual geometric surfaces they aim to fit, under a Validation of Depth Ratio Change checking. With the help of relative monocular depth prior, such geometry-aware validation can effectively reduce the influence of scattered Gaussians to the final rendering quality, especially in regions with weak textures or without sufficient training views. The texture-aware densification and geometry-aware splitting strategies are fully combined to obtain a set of high-quality Gaussian splats. We experiment our GeoTexDensifier framework on various datasets and compare our Novel View Synthesis results to other state-of-the-art 3DGS approaches, with detailed quantitative and qualitative evaluations to demonstrate the effectiveness of our method in producing more photorealistic 3DGS models. </p>
<blockquote>
<p>3Dé«˜æ–¯æ‘Šé“ºï¼ˆ3DGSï¼‰å› å…¶é€¼çœŸçš„é«˜æ•ˆæ¸²æŸ“æ€§èƒ½ï¼Œåœ¨è¯¸å¦‚3Då¯¼èˆªã€è™šæ‹Ÿç°å®ï¼ˆVRï¼‰å’Œ3Dæ¨¡æ‹Ÿç­‰é¢†åŸŸå¼•èµ·äº†å¹¿æ³›å…³æ³¨ã€‚é«˜è´¨é‡çš„3DGSé‡å»ºä¾èµ–äºè¶³å¤Ÿçš„æ‘Šç‰‡å’Œè¿™äº›æ‘Šç‰‡çš„åˆç†åˆ†å¸ƒï¼Œä»¥æ‹ŸåˆçœŸå®å‡ ä½•è¡¨é¢å’Œçº¹ç†ç»†èŠ‚ï¼Œè¿™è¯æ˜æ˜¯ä¸€ä¸ªå…·æœ‰æŒ‘æˆ˜æ€§çš„é—®é¢˜ã€‚æˆ‘ä»¬æå‡ºäº†GeoTexDensifierï¼Œè¿™æ˜¯ä¸€ç§æ–°å‹å‡ ä½•çº¹ç†æ„ŸçŸ¥çš„å¯†é›†åŒ–ç­–ç•¥ï¼Œç”¨äºé‡å»ºé«˜è´¨é‡çš„é«˜æ–¯æ‘Šç‰‡ï¼Œæ›´å¥½åœ°ç¬¦åˆåœºæ™¯çš„å‡ ä½•ç»“æ„å’Œçº¹ç†ä¸°å¯Œæ€§ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬çš„GeoTexDensifieræ¡†æ¶é‡‡ç”¨è¾…åŠ©çº¹ç†æ„ŸçŸ¥å¯†é›†åŒ–æ–¹æ³•ï¼Œåœ¨æœ‰çº¹ç†çš„åŒºåŸŸäº§ç”Ÿæ›´å¯†é›†çš„æ‘Šç‰‡åˆ†å¸ƒï¼ŒåŒæ—¶åœ¨ä½çº¹ç†åŒºåŸŸä¿æŒç¨€ç–æ€§ï¼Œä»¥ä¿æŒé«˜æ–¯ç‚¹äº‘çš„è´¨é‡ã€‚åŒæ—¶ï¼Œå‡ ä½•æ„ŸçŸ¥åˆ†å‰²ç­–ç•¥é‡‡ç”¨æ·±åº¦å’Œæ³•çº¿å…ˆéªŒæ¥æŒ‡å¯¼åˆ†å‰²é‡‡æ ·ï¼Œå¹¶è¿‡æ»¤æ‰åˆå§‹ä½ç½®è¿œç¦»å…¶æ‹Ÿåˆçš„å®é™…å‡ ä½•è¡¨é¢çš„å™ªå£°æ‘Šç‰‡ï¼Œè¿›è¡Œæ·±åº¦æ¯”ç‡å˜åŒ–æ£€æŸ¥ã€‚å€ŸåŠ©ç›¸å¯¹çš„å•çœ¼æ·±åº¦å…ˆéªŒï¼Œè¿™æ ·çš„å‡ ä½•æ„ŸçŸ¥éªŒè¯å¯ä»¥æœ‰æ•ˆåœ°å‡å°‘æ•£å°„é«˜æ–¯å¯¹æœ€ç»ˆæ¸²æŸ“è´¨é‡çš„å½±å“ï¼Œç‰¹åˆ«æ˜¯åœ¨çº¹ç†è¾ƒå¼±æˆ–ç¼ºä¹è¶³å¤Ÿè®­ç»ƒè§†å›¾çš„åŒºåŸŸã€‚çº¹ç†æ„ŸçŸ¥å¯†é›†åŒ–å’Œå‡ ä½•æ„ŸçŸ¥åˆ†å‰²ç­–ç•¥å……åˆ†ç»“åˆï¼Œè·å¾—ä¸€ç»„é«˜è´¨é‡çš„é«˜æ–¯æ‘Šç‰‡ã€‚æˆ‘ä»¬åœ¨å„ç§æ•°æ®é›†ä¸Šå®éªŒäº†GeoTexDensifieræ¡†æ¶ï¼Œå¹¶å°†æˆ‘ä»¬çš„æ–°å‹è§†å›¾åˆæˆç»“æœä¸å…¶ä»–æœ€å…ˆè¿›çš„3DGSæ–¹æ³•è¿›è¡Œæ¯”è¾ƒï¼Œé€šè¿‡è¯¦ç»†çš„å®šé‡å’Œå®šæ€§è¯„ä¼°ï¼Œè¯æ˜æˆ‘ä»¬çš„æ–¹æ³•åœ¨ç”Ÿæˆæ›´é€¼çœŸçš„3DGSæ¨¡å‹æ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.16809v1">PDF</a> 12 pages, 8 figures, 1 table</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†3D Gaussian Splattingï¼ˆ3DGSï¼‰æŠ€æœ¯åœ¨ä¸‰ç»´å¯¼èˆªã€è™šæ‹Ÿç°å®å’Œä¸‰ç»´ä»¿çœŸç­‰é¢†åŸŸä¸­çš„å¹¿æ³›åº”ç”¨ï¼Œä»¥åŠå…¶é¢ä¸´çš„é«˜è´¨é‡é—®é¢˜æŒ‘æˆ˜ã€‚æå‡ºäº†ä¸€ç§æ–°å‹çš„å‡ ä½•çº¹ç†æ„ŸçŸ¥å¯†åŒ–ç­–ç•¥GeoTexDensifierï¼Œé€šè¿‡è¾…åŠ©çº¹ç†æ„ŸçŸ¥å¯†åŒ–æ–¹æ³•å’Œå‡ ä½•æ„ŸçŸ¥åˆ†å‰²ç­–ç•¥ï¼Œèƒ½å¤Ÿåœ¨å……åˆ†çº¹ç†çš„åŒºåŸŸäº§ç”Ÿæ›´å¯†é›†çš„splatåˆ†å¸ƒï¼ŒåŒæ—¶ä¿æŒä½çº¹ç†åŒºåŸŸçš„ç¨€ç–æ€§ï¼Œä»è€Œæé«˜é«˜æ–¯ç‚¹äº‘çš„è´¨é‡ã€‚è¯¥ç­–ç•¥é€šè¿‡æ·±åº¦å’Œé¢„å…ˆçš„å‡ ä½•æ„ŸçŸ¥éªŒè¯ï¼Œå‡å°‘äº†æ•£å°„é«˜æ–¯å¯¹æœ€ç»ˆæ¸²æŸ“è´¨é‡çš„å½±å“ï¼Œå°¤å…¶æ˜¯åœ¨çº¹ç†è¾ƒå¼±æˆ–ç¼ºä¹è¶³å¤Ÿè®­ç»ƒè§†å›¾çš„åŒºåŸŸã€‚é€šè¿‡å®éªŒéªŒè¯ï¼Œè¯¥æ¡†æ¶èƒ½å¤Ÿæœ‰æ•ˆç”Ÿæˆæ›´é€¼çœŸçš„3DGSæ¨¡å‹ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>3DGSæŠ€æœ¯åœ¨å¤šä¸ªé¢†åŸŸå¾—åˆ°å¹¿æ³›åº”ç”¨ï¼Œä½†é«˜è´¨é‡é‡å»ºé¢ä¸´æŒ‘æˆ˜ã€‚</li>
<li>GeoTexDensifieræ¡†æ¶é‡‡ç”¨å‡ ä½•çº¹ç†æ„ŸçŸ¥å¯†åŒ–ç­–ç•¥è§£å†³æ­¤é—®é¢˜ã€‚</li>
<li>è¾…åŠ©çº¹ç†æ„ŸçŸ¥å¯†åŒ–æ–¹æ³•ç”¨äºäº§ç”Ÿæ›´å¯†é›†çš„splatåˆ†å¸ƒï¼Œç‰¹åˆ«æ˜¯åœ¨çº¹ç†ä¸°å¯Œçš„åŒºåŸŸã€‚</li>
<li>å‡ ä½•æ„ŸçŸ¥åˆ†å‰²ç­–ç•¥åˆ©ç”¨æ·±åº¦å’Œé¢„å…ˆçš„å‡ ä½•æ„ŸçŸ¥éªŒè¯æ¥ä¼˜åŒ–åˆ†è£‚é‡‡æ ·å¹¶è¿‡æ»¤è¿œç¦»å®é™…å‡ ä½•è¡¨é¢çš„å™ªå£°splatã€‚</li>
<li>è¯¥ç­–ç•¥æœ‰æ•ˆå‡å°‘äº†æ•£å°„é«˜æ–¯å¯¹æœ€ç»ˆæ¸²æŸ“è´¨é‡çš„å½±å“ï¼Œç‰¹åˆ«æ˜¯åœ¨çº¹ç†è¾ƒå¼±æˆ–æ— è¶³å¤Ÿè®­ç»ƒè§†å›¾çš„åŒºåŸŸã€‚</li>
<li>GeoTexDensifieræ¡†æ¶åœ¨å„ç§æ•°æ®é›†ä¸Šçš„å®éªŒéªŒè¯äº†å…¶æœ‰æ•ˆæ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.16809">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-59f444f4c0d1d4dc3428421dbc3a7466.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-33039c20b6d17b0577cd9e26be183b81.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-ae8f6622d56b616151d10376a10fa63b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-5b3a5558a81726669b3a00fa3e4c9b0a.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-4a89e7b0dbdc1e02349635705cbb6e0e.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="Topology-Aware-3D-Gaussian-Splatting-Leveraging-Persistent-Homology-for-Optimized-Structural-Integrity"><a href="#Topology-Aware-3D-Gaussian-Splatting-Leveraging-Persistent-Homology-for-Optimized-Structural-Integrity" class="headerlink" title="Topology-Aware 3D Gaussian Splatting: Leveraging Persistent Homology for   Optimized Structural Integrity"></a>Topology-Aware 3D Gaussian Splatting: Leveraging Persistent Homology for   Optimized Structural Integrity</h2><p><strong>Authors:Tianqi Shen, Shaohua Liu, Jiaqi Feng, Ziye Ma, Ning An</strong></p>
<p>Gaussian Splatting (GS) has emerged as a crucial technique for representing discrete volumetric radiance fields. It leverages unique parametrization to mitigate computational demands in scene optimization. This work introduces Topology-Aware 3D Gaussian Splatting (Topology-GS), which addresses two key limitations in current approaches: compromised pixel-level structural integrity due to incomplete initial geometric coverage, and inadequate feature-level integrity from insufficient topological constraints during optimization. To overcome these limitations, Topology-GS incorporates a novel interpolation strategy, Local Persistent Voronoi Interpolation (LPVI), and a topology-focused regularization term based on persistent barcodes, named PersLoss. LPVI utilizes persistent homology to guide adaptive interpolation, enhancing point coverage in low-curvature areas while preserving topological structure. PersLoss aligns the visual perceptual similarity of rendered images with ground truth by constraining distances between their topological features. Comprehensive experiments on three novel-view synthesis benchmarks demonstrate that Topology-GS outperforms existing methods in terms of PSNR, SSIM, and LPIPS metrics, while maintaining efficient memory usage. This study pioneers the integration of topology with 3D-GS, laying the groundwork for future research in this area. </p>
<blockquote>
<p>é«˜æ–¯é‡‡æ ·ï¼ˆGSï¼‰å·²ç»æˆä¸ºè¡¨ç¤ºç¦»æ•£ä½“ç§¯è¾å°„åœºçš„å…³é”®æŠ€æœ¯ã€‚å®ƒåˆ©ç”¨ç‹¬ç‰¹çš„å‚æ•°åŒ–æ–¹æ³•ï¼Œä»¥å‡è½»åœºæ™¯ä¼˜åŒ–ä¸­çš„è®¡ç®—éœ€æ±‚ã€‚æœ¬æ–‡ä»‹ç»äº†æ‹“æ‰‘æ„ŸçŸ¥ä¸‰ç»´é«˜æ–¯é‡‡æ ·ï¼ˆTopology-GSï¼‰ï¼Œè§£å†³äº†å½“å‰æ–¹æ³•çš„ä¸¤ä¸ªä¸»è¦å±€é™æ€§ï¼šç”±äºåˆå§‹å‡ ä½•è¦†ç›–ä¸å®Œæ•´è€ŒæŸå®³åƒç´ çº§ç»“æ„å®Œæ•´æ€§ï¼Œä»¥åŠåœ¨ä¼˜åŒ–è¿‡ç¨‹ä¸­ç”±äºæ‹“æ‰‘çº¦æŸä¸è¶³è€Œå¯¼è‡´ç‰¹å¾çº§å®Œæ•´æ€§ä¸è¶³ã€‚ä¸ºäº†å…‹æœè¿™äº›å±€é™æ€§ï¼ŒTopology-GSèå…¥äº†ä¸€ç§æ–°å‹æ’å€¼ç­–ç•¥â€”â€”å±€éƒ¨æŒä¹…Voronoiæ’å€¼ï¼ˆLPVIï¼‰å’Œä¸€ç§åŸºäºæŒä¹…æ¡å½¢ç çš„æ‹“æ‰‘é‡ç‚¹æ­£åˆ™åŒ–æœ¯è¯­ï¼Œç§°ä¸ºPersLossã€‚LPVIåˆ©ç”¨æŒä¹…åŒæºæ€§å¼•å¯¼è‡ªé€‚åº”æ’å€¼ï¼Œåœ¨ä½æ›²ç‡åŒºåŸŸå¢å¼ºç‚¹è¦†ç›–çš„åŒæ—¶ä¿æŒæ‹“æ‰‘ç»“æ„ã€‚PersLossé€šè¿‡çº¦æŸæ¸²æŸ“å›¾åƒä¸çœŸå®å›¾åƒä¹‹é—´æ‹“æ‰‘ç‰¹å¾çš„è·ç¦»ï¼Œä½¿æ¸²æŸ“å›¾åƒçš„è§†è§‰æ„ŸçŸ¥ç›¸ä¼¼æ€§ç¬¦åˆçœŸå®æƒ…å†µã€‚åœ¨ä¸‰ä¸ªå…¨æ–°è§†å›¾åˆæˆåŸºå‡†æµ‹è¯•ä¸Šçš„ç»¼åˆå®éªŒè¡¨æ˜ï¼ŒTopology-GSåœ¨PSNRã€SSIMå’ŒLPIPSæŒ‡æ ‡ä¸Šä¼˜äºç°æœ‰æ–¹æ³•ï¼ŒåŒæ—¶ä¿æŒæœ‰æ•ˆçš„å†…å­˜ä½¿ç”¨ã€‚æœ¬ç ”ç©¶é¦–åˆ›äº†æ‹“æ‰‘ä¸3D-GSçš„é›†æˆï¼Œä¸ºæœªæ¥è¯¥é¢†åŸŸçš„ç ”ç©¶å¥ å®šäº†åŸºç¡€ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.16619v1">PDF</a> </p>
<p><strong>Summary</strong><br>    æ‹“æ‰‘æ„ŸçŸ¥ä¸‰ç»´é«˜æ–¯æŠ•ç‚¹æ³•ï¼ˆTopology-GSï¼‰æ˜¯ä¸€ç§é’ˆå¯¹ç¦»æ•£ä½“ç§¯è¾å°„åœºè¡¨ç¤ºçš„å…³é”®æŠ€æœ¯ï¼Œå®ƒé€šè¿‡ç‹¬ç‰¹çš„å‚æ•°åŒ–æ–¹æ³•å‡è½»äº†åœºæ™¯ä¼˜åŒ–ä¸­çš„è®¡ç®—è´Ÿæ‹…ã€‚è¯¥æ–¹æ³•è§£å†³äº†ç°æœ‰æ–¹æ³•çš„ä¸¤ä¸ªå…³é”®é—®é¢˜ï¼šç”±äºåˆå§‹å‡ ä½•è¦†ç›–ä¸å®Œæ•´å¯¼è‡´çš„åƒç´ çº§ç»“æ„å®Œæ•´æ€§å—æŸï¼Œä»¥åŠåœ¨ä¼˜åŒ–è¿‡ç¨‹ä¸­ç”±äºæ‹“æ‰‘çº¦æŸä¸è¶³å¯¼è‡´çš„ç‰¹å¾çº§å®Œæ•´æ€§ä¸è¶³ã€‚ä¸ºæ­¤ï¼ŒTopology-GSå¼•å…¥äº†ä¸€ç§æ–°çš„æ’å€¼ç­–ç•¥â€”â€”å±€éƒ¨æŒä¹…å†¯è¯ºä¼Šæ›¼æ’å€¼ï¼ˆLPVIï¼‰å’ŒåŸºäºæŒä¹…æ¡å½¢ç çš„æ‹“æ‰‘é‡ç‚¹æ­£åˆ™åŒ–æœ¯è¯­PersLossã€‚LPVIåˆ©ç”¨æŒä¹…åŒæºæ€§å¼•å¯¼è‡ªé€‚åº”æ’å€¼ï¼Œå¢å¼ºä½æ›²ç‡åŒºåŸŸçš„ç‚¹è¦†ç›–ï¼ŒåŒæ—¶ä¿æŒæ‹“æ‰‘ç»“æ„ã€‚PersLossé€šè¿‡å¯¹æ‹“æ‰‘ç‰¹å¾ä¹‹é—´çš„è·ç¦»è¿›è¡Œçº¦æŸï¼Œä½¿æ¸²æŸ“å›¾åƒçš„è§†è§‰æ„ŸçŸ¥ä¸åœ°é¢çœŸå®æƒ…å†µä¿æŒä¸€è‡´ã€‚åœ¨ä¸‰ä¸ªå…¨æ–°è§†å›¾åˆæˆåŸºå‡†æµ‹è¯•ä¸Šçš„ç»¼åˆå®éªŒè¡¨æ˜ï¼ŒTopology-GSåœ¨PSNRã€SSIMå’ŒLPIPSæŒ‡æ ‡ä¸Šä¼˜äºç°æœ‰æ–¹æ³•ï¼ŒåŒæ—¶ä¿æŒé«˜æ•ˆçš„å†…å­˜ä½¿ç”¨ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>Topology-GSè§£å†³äº†å½“å‰æ–¹æ³•ä¸­ç”±äºåˆå§‹å‡ ä½•è¦†ç›–ä¸è¶³å’Œæ‹“æ‰‘çº¦æŸä¸è¶³å¯¼è‡´çš„é—®é¢˜ã€‚</li>
<li>LPVIåˆ©ç”¨æŒä¹…åŒæºæ€§è¿›è¡Œè‡ªé€‚åº”æ’å€¼ï¼Œæå‡ç‚¹è¦†ç›–å¹¶ç»´æŒæ‹“æ‰‘ç»“æ„ã€‚</li>
<li>PersLossçº¦æŸäº†æ¸²æŸ“å›¾åƒä¸çœŸå®å›¾åƒåœ¨æ‹“æ‰‘ç‰¹å¾ä¸Šçš„è·ç¦»ï¼Œæé«˜äº†è§†è§‰æ„ŸçŸ¥çš„ç›¸ä¼¼æ€§ã€‚</li>
<li>Topology-GSåœ¨æ–°å‹è§†å›¾åˆæˆåŸºå‡†æµ‹è¯•ä¸­è¡¨ç°ä¼˜è¶Šï¼Œä¼˜äºå…¶ä»–æ–¹æ³•ï¼Œä¸”å†…å­˜ä½¿ç”¨æ•ˆç‡é«˜ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.16619">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-52869adb755a86f2d0dfd96bd43fb048.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f48338fb3a9c2f9825df52c4f60f7b7f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-589046678f1809f9de7a75fc6200ed90.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f878cc7393aaae48224bb1ba8997fc7e.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-198a24d54bafbf53013410e2db12b29a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-59c01f6c4020253d8553a5ad9c140b05.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-1a1d68cef98b1654b51bf225ad37bebf.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-f99d376e15640d0f41139b9352e1f5f0.jpg" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="SOUS-VIDE-Cooking-Visual-Drone-Navigation-Policies-in-a-Gaussian-Splatting-Vacuum"><a href="#SOUS-VIDE-Cooking-Visual-Drone-Navigation-Policies-in-a-Gaussian-Splatting-Vacuum" class="headerlink" title="SOUS VIDE: Cooking Visual Drone Navigation Policies in a Gaussian   Splatting Vacuum"></a>SOUS VIDE: Cooking Visual Drone Navigation Policies in a Gaussian   Splatting Vacuum</h2><p><strong>Authors:JunEn Low, Maximilian Adang, Javier Yu, Keiko Nagami, Mac Schwager</strong></p>
<p>We propose a new simulator, training approach, and policy architecture, collectively called SOUS VIDE, for end-to-end visual drone navigation. Our trained policies exhibit zero-shot sim-to-real transfer with robust real-world performance using only on-board perception and computation. Our simulator, called FiGS, couples a computationally simple drone dynamics model with a high visual fidelity Gaussian Splatting scene reconstruction. FiGS can quickly simulate drone flights producing photorealistic images at up to 130 fps. We use FiGS to collect 100k-300k observation-action pairs from an expert MPC with privileged state and dynamics information, randomized over dynamics parameters and spatial disturbances. We then distill this expert MPC into an end-to-end visuomotor policy with a lightweight neural architecture, called SV-Net. SV-Net processes color image, optical flow and IMU data streams into low-level body rate and thrust commands at 20Hz onboard a drone. Crucially, SV-Net includes a Rapid Motor Adaptation (RMA) module that adapts at runtime to variations in drone dynamics. In a campaign of 105 hardware experiments, we show SOUS VIDE policies to be robust to 30% mass variations, 40 m&#x2F;s wind gusts, 60% changes in ambient brightness, shifting or removing objects from the scene, and people moving aggressively through the droneâ€™s visual field. Code, data, and experiment videos can be found on our project page: <a target="_blank" rel="noopener" href="https://stanfordmsl.github.io/SousVide/">https://stanfordmsl.github.io/SousVide/</a>. </p>
<blockquote>
<p>æˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°çš„æ¨¡æ‹Ÿå™¨ã€è®­ç»ƒæ–¹æ³•å’Œç­–ç•¥æ¶æ„ï¼Œç»Ÿç§°ä¸ºSOUS VIDEï¼Œç”¨äºç«¯åˆ°ç«¯çš„è§†è§‰æ— äººæœºå¯¼èˆªã€‚æˆ‘ä»¬è®­ç»ƒçš„ç­–ç•¥è¡¨ç°å‡ºé›¶æ ·æœ¬ä»¿çœŸåˆ°ç°å®çš„è¿ç§»èƒ½åŠ›ï¼Œä»…ä½¿ç”¨æœºè½½æ„ŸçŸ¥å’Œè®¡ç®—åŠŸèƒ½å°±èƒ½å®ç°ç¨³å¥çš„ç°å®ä¸–ç•Œæ€§èƒ½ã€‚æˆ‘ä»¬çš„æ¨¡æ‹Ÿå™¨åä¸ºFiGSï¼Œå®ƒå°†è®¡ç®—ç®€å•çš„æ— äººæœºåŠ¨åŠ›å­¦æ¨¡å‹ä¸é«˜æ–¯æ‹¼è´´åœºæ™¯é‡å»ºçš„é«˜è§†è§‰ä¿çœŸåº¦ç›¸ç»“åˆã€‚FiGSèƒ½å¤Ÿè¿…é€Ÿæ¨¡æ‹Ÿæ— äººæœºé£è¡Œï¼Œä»¥é«˜è¾¾130å¸§&#x2F;ç§’çš„é€Ÿåº¦ç”Ÿæˆé€¼çœŸçš„å›¾åƒã€‚æˆ‘ä»¬ä½¿ç”¨FiGSæ”¶é›†æ¥è‡ªæ‹¥æœ‰ç‰¹æƒçŠ¶æ€å’ŒåŠ¨åŠ›å­¦ä¿¡æ¯çš„ä¸“å®¶MPCçš„10ä¸‡è‡³30ä¸‡è§‚å¯Ÿè¡ŒåŠ¨å¯¹ï¼Œåœ¨åŠ¨åŠ›å­¦å‚æ•°å’Œç©ºé—´å¹²æ‰°ä¸Šè¿›è¡ŒéšæœºåŒ–ã€‚ç„¶åæˆ‘ä»¬å°†è¿™ä¸ªä¸“å®¶MPCè’¸é¦æˆä¸€ä¸ªå…·æœ‰è½»é‡çº§ç¥ç»ç½‘ç»œæ¶æ„çš„ç«¯åˆ°ç«¯è§†è§‰è¿åŠ¨ç­–ç•¥ï¼Œç§°ä¸ºSV-Netã€‚SV-Netå¤„ç†å½©è‰²å›¾åƒã€å…‰æµå’ŒIMUæ•°æ®æµï¼Œç”Ÿæˆä½çº§åˆ«çš„æœºä½“é€Ÿç‡å’Œæ¨åŠ›æŒ‡ä»¤ï¼Œåœ¨æ— äººæœºä¸Šè¾¾åˆ°20Hzã€‚å…³é”®çš„æ˜¯ï¼ŒSV-NetåŒ…å«ä¸€ä¸ªå¿«é€Ÿç”µæœºé€‚åº”ï¼ˆRMAï¼‰æ¨¡å—ï¼Œè¯¥æ¨¡å—åœ¨è¿è¡Œæ—¶èƒ½å¤Ÿé€‚åº”æ— äººæœºåŠ¨åŠ›å­¦çš„å˜åŒ–ã€‚åœ¨105æ¬¡ç¡¬ä»¶å®éªŒæ´»åŠ¨ä¸­ï¼Œæˆ‘ä»¬å±•ç¤ºäº†SOUS VIDEç­–ç•¥å¯¹äº30%çš„è´¨é‡å˜åŒ–ã€40ç±³&#x2F;ç§’çš„é£æš´ã€ç¯å¢ƒäº®åº¦å˜åŒ–60%ã€åœºæ™¯ä¸­ç‰©ä½“ç§»åŠ¨æˆ–ç§»é™¤ä»¥åŠäººä»¬åœ¨æ— äººæœºè§†é‡ä¸­æ¿€çƒˆç§»åŠ¨ç­‰æƒ…å†µå…·æœ‰ç¨³å¥æ€§ã€‚ä»£ç ã€æ•°æ®å’Œå®éªŒè§†é¢‘å¯ä»¥åœ¨æˆ‘ä»¬çš„é¡¹ç›®é¡µé¢æ‰¾åˆ°ï¼š<a target="_blank" rel="noopener" href="https://stanfordmsl.github.io/SousVide/">https://stanfordmsl.github.io/SousVide/</a>ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.16346v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†åä¸ºSOUS VIDEçš„ç«¯åˆ°ç«¯è§†è§‰æ— äººæœºå¯¼èˆªæ¨¡æ‹Ÿå™¨ã€è®­ç»ƒæ–¹æ³•å’Œæ”¿ç­–æ¶æ„ã€‚è¯¥æ¨¡æ‹Ÿå™¨ä½¿ç”¨FiGSï¼Œç»“åˆç®€å•çš„æ— äººæœºåŠ¨åŠ›å­¦æ¨¡å‹å’Œé«˜è§†è§‰ä¿çœŸåº¦çš„Gaussian Splattingåœºæ™¯é‡å»ºï¼Œèƒ½å¿«é€Ÿæ¨¡æ‹Ÿæ— äººæœºé£è¡Œå¹¶ç”Ÿæˆé«˜è¾¾130å¸§&#x2F;ç§’çš„ç…§ç‰‡çº§å›¾åƒã€‚é€šè¿‡æ”¶é›†ä¸“å®¶MPCçš„è§‚å¯Ÿè¡ŒåŠ¨å¯¹å¹¶éšæœºåŒ–å…¶åŠ¨åŠ›å­¦å‚æ•°å’Œç©ºé—´å¹²æ‰°ï¼Œç ”ç©¶è€…è’¸é¦å‡ºç«¯åˆ°ç«¯çš„è§†è§‰è¿åŠ¨æ”¿ç­–SV-Netã€‚SV-Netèƒ½å¤„ç†å½©è‰²å›¾åƒã€å…‰æµå’ŒIMUæ•°æ®æµï¼Œç”Ÿæˆä½çº§åˆ«çš„æœºä½“é€Ÿç‡å’Œæ¨åŠ›æŒ‡ä»¤ï¼Œå¹¶åœ¨æ— äººæœºä¸Šå®ç°20Hzçš„è¿è¡Œé¢‘ç‡ã€‚å…³é”®çš„æ˜¯ï¼ŒSV-NetåŒ…å«è¿è¡Œæ—¶é€‚åº”æ— äººæœºåŠ¨åŠ›å­¦å˜åŒ–çš„å¿«é€Ÿç”µæœºé€‚åº”æ¨¡å—ã€‚é€šè¿‡ä¸€ç³»åˆ—ç¡¬ä»¶å®éªŒéªŒè¯ï¼ŒSOUS VIDEæ”¿ç­–åœ¨å¤šç§åœºæ™¯ä¸‹è¡¨ç°å‡ºç¨³å¥æ€§ï¼ŒåŒ…æ‹¬è´¨é‡å˜åŒ–ã€é£é€Ÿå¹²æ‰°ã€äº®åº¦å˜åŒ–ã€åœºæ™¯ç‰©ä½“ç§»åŠ¨ä»¥åŠè§†è§‰åœºå†…äººå‘˜åŠ¨æ€ç§»åŠ¨ç­‰ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æå‡ºäº†åä¸ºSOUS VIDEçš„ç«¯åˆ°ç«¯è§†è§‰æ— äººæœºå¯¼èˆªç³»ç»Ÿï¼ŒåŒ…æ‹¬æ–°æ¨¡æ‹Ÿå™¨FiGSã€è®­ç»ƒæ–¹æ³•å’Œæ”¿ç­–æ¶æ„ã€‚</li>
<li>FiGSæ¨¡æ‹Ÿå™¨ç»“åˆäº†ç®€å•æ— äººæœºåŠ¨åŠ›å­¦æ¨¡å‹å’Œé«˜è§†è§‰ä¿çœŸåº¦çš„åœºæ™¯é‡å»ºã€‚</li>
<li>FiGSèƒ½é«˜æ•ˆæ¨¡æ‹Ÿæ— äººæœºé£è¡Œï¼Œç”Ÿæˆé«˜è´¨é‡å›¾åƒï¼Œæœ€é«˜è¾¾130å¸§&#x2F;ç§’ã€‚</li>
<li>é€šè¿‡ä¸“å®¶MPCæ•°æ®ï¼Œç ”ç©¶è€…è®­ç»ƒå‡ºåä¸ºSV-Netçš„è§†å¬è§‰è¿åŠ¨æ”¿ç­–ç½‘ç»œã€‚</li>
<li>SV-Netèƒ½å¤„ç†å¤šç§æ•°æ®è¾“å…¥å¹¶è¾“å‡ºä½çº§åˆ«æŒ‡ä»¤ï¼Œå…·å¤‡20Hzçš„è¿è¡Œé¢‘ç‡ã€‚</li>
<li>SV-NetåŒ…å«å¿«é€Ÿç”µæœºé€‚åº”æ¨¡å—ï¼Œèƒ½é€‚åº”æ— äººæœºåŠ¨åŠ›å­¦å˜åŒ–ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.16346">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-178c5c3ea0561fc849145aed9254a367.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-d409c265170cab1970c713e9048ef3de.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-f248f9d4fc72d9ff8c3f0f0803ba8fab.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-1a172d35be318af7aa7b1e187c2f3d0e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-49c94acd6494884bf029bb35bf5f15bc.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-96a778df311995e24c99141a73d31f23.jpg" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1><h2 id="SqueezeMe-Efficient-Gaussian-Avatars-for-VR"><a href="#SqueezeMe-Efficient-Gaussian-Avatars-for-VR" class="headerlink" title="SqueezeMe: Efficient Gaussian Avatars for VR"></a>SqueezeMe: Efficient Gaussian Avatars for VR</h2><p><strong>Authors:Shunsuke Saito, Stanislav Pidhorskyi, Igor Santesteban, Forrest Iandola, Divam Gupta, Anuj Pahuja, Nemanja Bartolovic, Frank Yu, Emanuel Garbin, Tomas Simon</strong></p>
<p>Gaussian Splatting has enabled real-time 3D human avatars with unprecedented levels of visual quality. While previous methods require a desktop GPU for real-time inference of a single avatar, we aim to squeeze multiple Gaussian avatars onto a portable virtual reality headset with real-time drivable inference. We begin by training a previous work, Animatable Gaussians, on a high quality dataset captured with 512 cameras. The Gaussians are animated by controlling base set of Gaussians with linear blend skinning (LBS) motion and then further adjusting the Gaussians with a neural network decoder to correct their appearance. When deploying the model on a Meta Quest 3 VR headset, we find two major computational bottlenecks: the decoder and the rendering. To accelerate the decoder, we train the Gaussians in UV-space instead of pixel-space, and we distill the decoder to a single neural network layer. Further, we discover that neighborhoods of Gaussians can share a single corrective from the decoder, which provides an additional speedup. To accelerate the rendering, we develop a custom pipeline in Vulkan that runs on the mobile GPU. Putting it all together, we run 3 Gaussian avatars concurrently at 72 FPS on a VR headset. Demo videos are at <a target="_blank" rel="noopener" href="https://forresti.github.io/squeezeme">https://forresti.github.io/squeezeme</a>. </p>
<blockquote>
<p>é«˜æ–¯æ‹¼è´´æŠ€æœ¯ä¸ºå®æ—¶3Däººç±»åŒ–èº«å¸¦æ¥äº†å‰æ‰€æœªæœ‰çš„è§†è§‰å“è´¨ã€‚è™½ç„¶ä¹‹å‰çš„æ–¹æ³•éœ€è¦æ¡Œé¢GPUæ¥è¿›è¡Œå•ä¸ªåŒ–èº«å®æ—¶æ¨ç†ï¼Œæˆ‘ä»¬çš„ç›®æ ‡æ˜¯å°†å¤šä¸ªé«˜æ–¯åŒ–èº«æŒ¤å‹åˆ°ä¾¿æºå¼è™šæ‹Ÿç°å®å¤´ç›”ä¸Šï¼Œå®ç°å®æ—¶é©±åŠ¨æ¨ç†ã€‚æˆ‘ä»¬é¦–å…ˆè®­ç»ƒä¸€ä¸ªä»¥å‰çš„å·¥ä½œâ€œå¯åŠ¨ç”»é«˜æ–¯â€ï¼Œä½¿ç”¨ç”±512å°ç›¸æœºæ•è·çš„é«˜è´¨é‡æ•°æ®é›†ã€‚é«˜æ–¯é€šè¿‡æ§åˆ¶åŸºç¡€é«˜æ–¯é›†è¿›è¡ŒåŠ¨ç”»æ¸²æŸ“ï¼Œä½¿ç”¨çº¿æ€§æ··åˆè’™çš®ï¼ˆLBSï¼‰è¿åŠ¨å¯¹é«˜æ–¯è¿›è¡ŒåŠ¨ç”»å¤„ç†ï¼Œç„¶åé€šè¿‡ç¥ç»ç½‘ç»œè§£ç å™¨è¿›ä¸€æ­¥è°ƒæ•´é«˜æ–¯ä»¥æ ¡æ­£å…¶å¤–è§‚ã€‚åœ¨Meta Quest 3 VRå¤´ç›”ä¸Šéƒ¨ç½²æ¨¡å‹æ—¶ï¼Œæˆ‘ä»¬å‘ç°ä¸¤ä¸ªä¸»è¦çš„è®¡ç®—ç“¶é¢ˆï¼šè§£ç å™¨å’Œæ¸²æŸ“å™¨ã€‚ä¸ºäº†åŠ é€Ÿè§£ç å™¨ï¼Œæˆ‘ä»¬åœ¨UVç©ºé—´è€Œä¸æ˜¯åƒç´ ç©ºé—´è®­ç»ƒé«˜æ–¯ï¼Œå¹¶å°†è§£ç å™¨è’¸é¦åˆ°å•ä¸ªç¥ç»ç½‘ç»œå±‚ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å‘ç°é‚»è¿‘çš„é«˜æ–¯å¯ä»¥ä»è§£ç å™¨å…±äº«å•ä¸ªæ ¡æ­£ï¼Œè¿™æä¾›äº†é¢å¤–çš„åŠ é€Ÿã€‚ä¸ºäº†åŠ é€Ÿæ¸²æŸ“å™¨ï¼Œæˆ‘ä»¬åœ¨Vulkanä¸­å¼€å‘äº†ä¸€ä¸ªè‡ªå®šä¹‰ç®¡é“ï¼Œè¯¥ç®¡é“åœ¨ç§»åŠ¨GPUä¸Šè¿è¡Œã€‚ç»¼ä¸Šæ‰€è¿°ï¼Œæˆ‘ä»¬åœ¨VRå¤´ç›”ä¸ŠåŒæ—¶è¿è¡Œä¸‰ä¸ªé«˜æ–¯åŒ–èº«ï¼Œå¸§é€Ÿç‡ä¸ºæ¯ç§’72å¸§ã€‚æ¼”ç¤ºè§†é¢‘è¯·è®¿é—®ï¼š[<a target="_blank" rel="noopener" href="https://forresti.github.io/squeezeme/]">https://forresti.github.io/squeezeme/]</a> ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.15171v2">PDF</a> v2</p>
<p><strong>Summary</strong></p>
<p>åŸºäºé«˜æ–¯æŠ€æœ¯çš„æ–°è¿›å±•ï¼Œç ”ç©¶å›¢é˜Ÿå®ç°äº†å¯ä»¥åœ¨VRå¤´æ˜¾ä¸­ä»¥å®æ—¶é©±åŠ¨æ¸²æŸ“çš„é«˜é€¼çœŸåº¦å®æ—¶åŠ¨æ€3Däººç±»è§’è‰²ã€‚å…¶é€šè¿‡å¯¹ä»¥å¾€å·¥ä½œè¿›è¡Œäº†æ”¹è¿›å’Œåˆ›æ–°è®­ç»ƒè¿‡ç¨‹ï¼Œåœ¨VRå¤´æ˜¾ä¸Šå®ç°äº†å¤šè§’è‰²åŒæ—¶æ¸²æŸ“ï¼Œè§£å†³äº†æ¸²æŸ“å’Œæ¨¡å‹è§£ç ä¸¤å¤§ç“¶é¢ˆé—®é¢˜ã€‚æ­¤æŠ€æœ¯ä¸ä»…æå‡äº†è§†è§‰æ•ˆæœï¼Œè¿˜å®ç°äº†ä¾¿æºæ€§ã€‚ç›¸å…³æ¼”ç¤ºè§†é¢‘å¯åœ¨ç›¸å…³ç½‘ç«™æ‰¾åˆ°ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>é«˜æ–¯æŠ€æœ¯ç”¨äºåˆ›å»ºé«˜é€¼çœŸåº¦çš„å®æ—¶åŠ¨æ€3Däººç±»è§’è‰²ã€‚</li>
<li>ç ”ç©¶äººå‘˜æˆåŠŸå°†å¤šä¸ªé«˜æ–¯è§’è‰²æŒ¤å‹åˆ°ä¾¿æºå¼VRå¤´æ˜¾ä¸Šï¼Œå®ç°å®æ—¶é©±åŠ¨æ¸²æŸ“ã€‚</li>
<li>ç ”ç©¶å›¢é˜Ÿå¯¹æ—§æœ‰æŠ€æœ¯è¿›è¡Œæ”¹è¿›å’Œåˆ›æ–°è®­ç»ƒè¿‡ç¨‹ï¼Œåˆ©ç”¨çº¿æ€§æ··åˆè’™çš®åŠ¨ç”»æŠ€æœ¯å¯¹é«˜æ–¯è§’è‰²è¿›è¡ŒåŠ¨ç”»è®¾è®¡ï¼Œå¹¶åˆ©ç”¨ç¥ç»ç½‘ç»œè§£ç å™¨æ ¡æ­£å…¶å¤–è§‚ã€‚</li>
<li>æ¨¡å‹è§£ç å’Œæ¸²æŸ“æ˜¯è¯¥æŠ€æœ¯çš„ä¸¤å¤§ç“¶é¢ˆé—®é¢˜ï¼Œç ”ç©¶å›¢é˜Ÿé’ˆå¯¹è¿™ä¸¤ä¸ªé—®é¢˜æå‡ºäº†è§£å†³æ–¹æ¡ˆã€‚</li>
<li>ç ”ç©¶äººå‘˜é€šè¿‡åœ¨UVç©ºé—´è€Œéåƒç´ ç©ºé—´è®­ç»ƒé«˜æ–¯è§’è‰²ï¼Œå¹¶ç®€åŒ–äº†ç¥ç»ç½‘ç»œè§£ç å™¨ä»¥åŠ é€Ÿè§£ç è¿‡ç¨‹ã€‚é‚»è¿‘çš„é«˜æ–¯è§’è‰²å¯ä»¥å…±äº«è§£ç å™¨çš„æ ¡æ­£ç»“æœï¼Œè¿›ä¸€æ­¥æé«˜äº†æ•ˆç‡ã€‚</li>
<li>ç ”ç©¶å›¢é˜Ÿå¼€å‘äº†ä¸€ä¸ªè‡ªå®šä¹‰çš„Vulkanæ¸²æŸ“ç®¡çº¿ï¼Œèƒ½åœ¨ç§»åŠ¨GPUä¸Šè¿è¡Œï¼Œè§£å†³äº†VRå¤´æ˜¾ä¸Šçš„æ¸²æŸ“ç“¶é¢ˆé—®é¢˜ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.15171">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-05c4355c4bee5c851215015e80eca4d8.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-5a92b7175ebf9b8027621de562007c32.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-c4f9af30502b0169ae8b8ee5351080e2.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c2f597543e4e7717f3143f846e26bb84.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-89cacd28b69b1477987fa08ac9589fbe.jpg" align="middle">
</details>


<h1 id="-9"><a href="#-9" class="headerlink" title=""></a></h1><h2 id="DGNS-Deformable-Gaussian-Splatting-and-Dynamic-Neural-Surface-for-Monocular-Dynamic-3D-Reconstruction"><a href="#DGNS-Deformable-Gaussian-Splatting-and-Dynamic-Neural-Surface-for-Monocular-Dynamic-3D-Reconstruction" class="headerlink" title="DGNS: Deformable Gaussian Splatting and Dynamic Neural Surface for   Monocular Dynamic 3D Reconstruction"></a>DGNS: Deformable Gaussian Splatting and Dynamic Neural Surface for   Monocular Dynamic 3D Reconstruction</h2><p><strong>Authors:Xuesong Li, Jinguang Tong, Jie Hong, Vivien Rolland, Lars Petersson</strong></p>
<p>Dynamic scene reconstruction from monocular video is critical for real-world applications. This paper tackles the dual challenges of dynamic novel-view synthesis and 3D geometry reconstruction by introducing a hybrid framework: Deformable Gaussian Splatting and Dynamic Neural Surfaces (DGNS), in which both modules can leverage each other for both tasks. During training, depth maps generated by the deformable Gaussian splatting module guide the ray sampling for faster processing and provide depth supervision within the dynamic neural surface module to improve geometry reconstruction. Simultaneously, the dynamic neural surface directs the distribution of Gaussian primitives around the surface, enhancing rendering quality. To further refine depth supervision, we introduce a depth-filtering process on depth maps derived from Gaussian rasterization. Extensive experiments on public datasets demonstrate that DGNS achieves state-of-the-art performance in both novel-view synthesis and 3D reconstruction. </p>
<blockquote>
<p>ä»å•ç›®è§†é¢‘ä¸­é‡å»ºåŠ¨æ€åœºæ™¯å¯¹å®é™…åº”ç”¨è‡³å…³é‡è¦ã€‚æœ¬æ–‡é€šè¿‡å¼•å…¥æ··åˆæ¡†æ¶â€”â€”å¯å˜å½¢é«˜æ–¯å–·æ¶‚å’ŒåŠ¨æ€ç¥ç»ç½‘ç»œè¡¨é¢ï¼ˆDGNSï¼‰ï¼Œè§£å†³äº†åŠ¨æ€æ–°è§†è§’åˆæˆå’Œ3Då‡ ä½•é‡å»ºçš„åŒé‡æŒ‘æˆ˜ã€‚åœ¨è¯¥æ¡†æ¶ä¸­ï¼Œä¸¤ä¸ªæ¨¡å—å¯ä»¥ç›¸äº’åˆ©ç”¨ï¼Œå…±åŒå®Œæˆè¿™ä¸¤ä¸ªä»»åŠ¡ã€‚åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œå¯å˜å½¢é«˜æ–¯å–·æ¶‚æ¨¡å—ç”Ÿæˆçš„æ·±åº¦å›¾å¼•å¯¼å…‰çº¿é‡‡æ ·ï¼ŒåŠ å¿«å¤„ç†é€Ÿåº¦ï¼Œå¹¶åœ¨åŠ¨æ€ç¥ç»ç½‘ç»œæ¨¡å—å†…æä¾›æ·±åº¦ç›‘ç£ï¼Œä»¥æ”¹è¿›å‡ ä½•é‡å»ºã€‚åŒæ—¶ï¼ŒåŠ¨æ€ç¥ç»ç½‘ç»œå¼•å¯¼é«˜æ–¯åŸå§‹å…ƒç´ åœ¨è¡¨é¢å‘¨å›´çš„åˆ†å¸ƒï¼Œæé«˜æ¸²æŸ“è´¨é‡ã€‚ä¸ºäº†è¿›ä¸€æ­¥ä¼˜åŒ–æ·±åº¦ç›‘ç£ï¼Œæˆ‘ä»¬åœ¨ä»é«˜æ–¯æ …æ ¼åŒ–æ´¾ç”Ÿçš„æ·±åº¦å›¾ä¸Šå®æ–½äº†æ·±åº¦è¿‡æ»¤è¿‡ç¨‹ã€‚åœ¨å…¬å…±æ•°æ®é›†ä¸Šçš„å¤§é‡å®éªŒè¡¨æ˜ï¼ŒDGNSåœ¨æ–°è§†è§’åˆæˆå’Œ3Dé‡å»ºæ–¹é¢éƒ½è¾¾åˆ°äº†æœ€æ–°æŠ€æœ¯æ°´å¹³ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.03910v2">PDF</a> </p>
<p><strong>æ€»ç»“</strong><br>    DGNSæ··åˆæ¡†æ¶é€šè¿‡åˆ©ç”¨å¯å˜å½¢çš„é«˜æ–¯å–·æ¶‚æ¨¡å—å’ŒåŠ¨æ€ç¥ç»ç½‘ç»œæ¨¡å—ï¼Œè§£å†³äº†åŠ¨æ€åœºæ™¯é‡å»ºä¸­çš„æ–°è§†è§’åˆæˆå’Œä¸‰ç»´å‡ ä½•é‡å»ºåŒé‡æŒ‘æˆ˜ã€‚è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œæ·±åº¦å›¾æŒ‡å¯¼å…‰çº¿é‡‡æ ·ä»¥æé«˜å¤„ç†é€Ÿåº¦ï¼ŒåŒæ—¶ä¸ºåŠ¨æ€ç¥ç»ç½‘ç»œæ¨¡å—æä¾›æ·±åº¦ç›‘ç£ä»¥æ”¹å–„å‡ ä½•é‡å»ºã€‚æ­¤å¤–ï¼ŒåŠ¨æ€ç¥ç»ç½‘ç»œå¼•å¯¼é«˜æ–¯åŸå§‹æ•°æ®åœ¨è¡¨é¢å‘¨å›´çš„åˆ†å¸ƒï¼Œæé«˜æ¸²æŸ“è´¨é‡ã€‚å¯¹å…¬å…±æ•°æ®é›†çš„å¤§é‡å®éªŒè¡¨æ˜ï¼ŒDGNSåœ¨æ–°å‹è§†è§’åˆæˆå’Œä¸‰ç»´é‡å»ºæ–¹é¢å‡è¾¾åˆ°æœ€ä½³æ€§èƒ½ã€‚</p>
<p><strong>å…³é”®è§è§£</strong></p>
<ol>
<li>DGNSæ··åˆæ¡†æ¶è§£å†³äº†åŠ¨æ€åœºæ™¯é‡å»ºä¸­çš„æ–°è§†è§’åˆæˆå’Œä¸‰ç»´å‡ ä½•é‡å»ºåŒé‡æŒ‘æˆ˜ã€‚</li>
<li>DGNSåˆ©ç”¨å¯å˜å½¢çš„é«˜æ–¯å–·æ¶‚æ¨¡å—ç”Ÿæˆæ·±åº¦å›¾ï¼ŒæŒ‡å¯¼å…‰çº¿é‡‡æ ·å¹¶æ”¹å–„å‡ ä½•é‡å»ºã€‚</li>
<li>åŠ¨æ€ç¥ç»ç½‘ç»œæ¨¡å—é€šè¿‡åˆ©ç”¨æ·±åº¦å›¾æä¾›çš„æ·±åº¦ç›‘ç£ï¼Œæé«˜äº†æ¸²æŸ“è´¨é‡ã€‚</li>
<li>DGNSå¼•å…¥äº†æ·±åº¦è¿‡æ»¤è¿‡ç¨‹ï¼Œå¯¹ç”±é«˜æ–¯å…‰æ …åŒ–ç”Ÿæˆçš„æ·±åº¦å›¾è¿›è¡Œè¿›ä¸€æ­¥ä¼˜åŒ–ã€‚</li>
<li>DGNSåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ä¸¤ä¸ªæ¨¡å—å¯ä»¥ç›¸äº’ä¿ƒè¿›ï¼Œå…±åŒæé«˜æ€§èƒ½ã€‚</li>
<li>å¤§é‡åœ¨å…¬å…±æ•°æ®é›†ä¸Šçš„å®éªŒéªŒè¯äº†DGNSæ¡†æ¶çš„æœ‰æ•ˆæ€§å’Œä¼˜è¶Šæ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.03910">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-d770955bb7e769248f3d296b1ea5e5d7.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-23366726d2293d5da079f25a8312178a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d4d870c1655b63e28b1a30aa805acdcc.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-62fb860626da7152901a6a743ebf3ad3.jpg" align="middle">
</details>


<h1 id="-10"><a href="#-10" class="headerlink" title=""></a></h1><h2 id="HiCoM-Hierarchical-Coherent-Motion-for-Streamable-Dynamic-Scene-with-3D-Gaussian-Splatting"><a href="#HiCoM-Hierarchical-Coherent-Motion-for-Streamable-Dynamic-Scene-with-3D-Gaussian-Splatting" class="headerlink" title="HiCoM: Hierarchical Coherent Motion for Streamable Dynamic Scene with 3D   Gaussian Splatting"></a>HiCoM: Hierarchical Coherent Motion for Streamable Dynamic Scene with 3D   Gaussian Splatting</h2><p><strong>Authors:Qiankun Gao, Jiarui Meng, Chengxiang Wen, Jie Chen, Jian Zhang</strong></p>
<p>The online reconstruction of dynamic scenes from multi-view streaming videos faces significant challenges in training, rendering and storage efficiency. Harnessing superior learning speed and real-time rendering capabilities, 3D Gaussian Splatting (3DGS) has recently demonstrated considerable potential in this field. However, 3DGS can be inefficient in terms of storage and prone to overfitting by excessively growing Gaussians, particularly with limited views. This paper proposes an efficient framework, dubbed HiCoM, with three key components. First, we construct a compact and robust initial 3DGS representation using a perturbation smoothing strategy. Next, we introduce a Hierarchical Coherent Motion mechanism that leverages the inherent non-uniform distribution and local consistency of 3D Gaussians to swiftly and accurately learn motions across frames. Finally, we continually refine the 3DGS with additional Gaussians, which are later merged into the initial 3DGS to maintain consistency with the evolving scene. To preserve a compact representation, an equivalent number of low-opacity Gaussians that minimally impact the representation are removed before processing subsequent frames. Extensive experiments conducted on two widely used datasets show that our framework improves learning efficiency of the state-of-the-art methods by about $20%$ and reduces the data storage by $85%$, achieving competitive free-viewpoint video synthesis quality but with higher robustness and stability. Moreover, by parallel learning multiple frames simultaneously, our HiCoM decreases the average training wall time to $&lt;2$ seconds per frame with negligible performance degradation, substantially boosting real-world applicability and responsiveness. </p>
<blockquote>
<p>ä»å¤šè§†è§’æµè§†é¢‘ä¸­åœ¨çº¿é‡å»ºåŠ¨æ€åœºæ™¯é¢ä¸´ç€è®­ç»ƒã€æ¸²æŸ“å’Œå­˜å‚¨æ•ˆç‡æ–¹é¢çš„é‡å¤§æŒ‘æˆ˜ã€‚å‡­å€Ÿå“è¶Šçš„å­¦ä¹ é€Ÿåº¦å’Œå®æ—¶æ¸²æŸ“èƒ½åŠ›ï¼Œ3Dé«˜æ–¯å–·ç»˜ï¼ˆ3DGSï¼‰åœ¨è¯¥é¢†åŸŸå±•ç¤ºäº†å·¨å¤§çš„æ½œåŠ›ã€‚ç„¶è€Œï¼Œ3DGSåœ¨å­˜å‚¨æ–¹é¢å¯èƒ½æ•ˆç‡ä½ä¸‹ï¼Œå¹¶ä¸”ç”±äºé«˜æ–¯è¿‡åº¦å¢é•¿è€Œå®¹æ˜“è¿‡åº¦æ‹Ÿåˆï¼Œç‰¹åˆ«æ˜¯åœ¨è§†è§’æœ‰é™çš„æƒ…å†µä¸‹ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ä¸ªé«˜æ•ˆçš„æ¡†æ¶ï¼Œç§°ä¸ºHiCoMï¼ŒåŒ…å«ä¸‰ä¸ªå…³é”®ç»„ä»¶ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬ä½¿ç”¨æ‰°åŠ¨å¹³æ»‘ç­–ç•¥æ„å»ºç´§å‡‘ä¸”ç¨³å¥çš„åˆå§‹3DGSè¡¨ç¤ºã€‚å…¶æ¬¡ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§åˆ†å±‚ä¸€è‡´è¿åŠ¨æœºåˆ¶ï¼Œè¯¥æœºåˆ¶åˆ©ç”¨3Dé«˜æ–¯æœ¬èº«çš„éå‡åŒ€åˆ†å¸ƒå’Œå±€éƒ¨ä¸€è‡´æ€§ï¼Œå¿«é€Ÿå‡†ç¡®åœ°å­¦ä¹ å¸§ä¹‹é—´çš„è¿åŠ¨ã€‚æœ€åï¼Œæˆ‘ä»¬ç»§ç»­ä½¿ç”¨é¢å¤–çš„é«˜æ–¯å¯¹3DGSè¿›è¡ŒæŒç»­ä¼˜åŒ–ï¼Œç„¶åå°†è¿™äº›é«˜æ–¯åˆå¹¶åˆ°åˆå§‹çš„3DGSä¸­ï¼Œä»¥ä¿æŒä¸ä¸æ–­å˜åŒ–çš„åœºæ™¯çš„ä¸€è‡´æ€§ã€‚ä¸ºäº†ä¿æŒç´§å‡‘çš„è¡¨ç¤ºå½¢å¼ï¼Œåœ¨å¤„ç†åç»­å¸§ä¹‹å‰ï¼Œä¼šç§»é™¤å¯¹è¡¨ç¤ºå½±å“æœ€å°çš„ç­‰æ•ˆæ•°é‡çš„ä½é€æ˜åº¦é«˜æ–¯ã€‚åœ¨å¹¿æ³›ä½¿ç”¨çš„ä¸¤ä¸ªæ•°æ®é›†ä¸Šè¿›è¡Œçš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ¡†æ¶æé«˜äº†ç°æœ‰æ–¹æ³•çš„å­¦ä¹ æ•ˆç‡çº¦20%ï¼Œå¹¶å‡å°‘äº†æ•°æ®å­˜å‚¨é‡é«˜è¾¾85%ï¼Œè¾¾åˆ°äº†å…·æœ‰ç«äº‰åŠ›çš„è‡ªç”±è§†ç‚¹è§†é¢‘åˆæˆè´¨é‡ï¼Œä½†å…·æœ‰æ›´é«˜çš„ç¨³å¥æ€§å’Œç¨³å®šæ€§ã€‚æ­¤å¤–ï¼Œé€šè¿‡å¹¶è¡Œå­¦ä¹ å¤šä¸ªå¸§ï¼Œæˆ‘ä»¬çš„HiCoMå°†å¹³å‡è®­ç»ƒæ—¶é—´å‡å°‘åˆ°æ¯å¸§å°äº2ç§’ï¼Œä¸”æ€§èƒ½å‡ ä¹æ²¡æœ‰ä¸‹é™ï¼Œå¤§å¤§æé«˜äº†å®é™…åº”ç”¨çš„é€‚ç”¨æ€§å’Œå“åº”é€Ÿåº¦ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2411.07541v2">PDF</a> Accepted to NeurIPS 2024; Code is avaliable at   <a target="_blank" rel="noopener" href="https://github.com/gqk/HiCoM">https://github.com/gqk/HiCoM</a></p>
<p><strong>æ‘˜è¦</strong><br>    é’ˆå¯¹åœ¨çº¿åŠ¨æ€åœºæ™¯é‡å»ºé¢ä¸´çš„æŒ‘æˆ˜ï¼Œåˆ©ç”¨å¼ºå¤§çš„å­¦ä¹ é€Ÿåº¦å’Œå®æ—¶æ¸²æŸ“èƒ½åŠ›ï¼Œè®ºæ–‡æå‡ºäº†ä¸€ç§é«˜æ•ˆçš„æ¡†æ¶HiCoMï¼Œåˆ©ç”¨ä¸‰ç»´é«˜æ–¯å–·ç»˜æŠ€æœ¯å®ç°å¤šè§†è§’æµåª’ä½“è§†é¢‘çš„åœ¨çº¿é‡å»ºã€‚è¯¥æ¡†æ¶å…·æœ‰ç´§å‡‘ä¸”ç¨³å¥çš„åˆå§‹ä¸‰ç»´é«˜æ–¯å–·ç»˜è¡¨ç¤ºï¼Œå¼•å…¥å±‚æ¬¡åŒ–ååŒè¿åŠ¨æœºåˆ¶ï¼Œå¹¶åˆ©ç”¨é«˜æ–¯åˆ†å¸ƒçš„éå‡åŒ€åˆ†å¸ƒå’Œå±€éƒ¨ä¸€è‡´æ€§ï¼Œå®ç°å¿«é€Ÿå‡†ç¡®çš„å­¦ä¹ è¿åŠ¨è¿‡ç¨‹ã€‚æ­¤å¤–ï¼Œé€šè¿‡ä¸æ–­ç²¾ç‚¼ä¸‰ç»´é«˜æ–¯å–·ç»˜æŠ€æœ¯ï¼Œåˆ©ç”¨èåˆç­–ç•¥ä¼˜åŒ–æ¨¡å‹ï¼Œæœ€ç»ˆæå‡äº†æ¨¡å‹çš„æ€§èƒ½å’Œé€‚åº”æ€§ã€‚å®éªŒè¯æ˜ï¼ŒHiCoMæ¡†æ¶å¯æé«˜å­¦ä¹ æ•ˆç‡çº¦20%ï¼Œå‡å°‘æ•°æ®å­˜å‚¨ç©ºé—´é«˜è¾¾85%ï¼Œå®ç°äº†ç«äº‰æ€§çš„è‡ªç”±è§†è§’è§†é¢‘åˆæˆè´¨é‡ã€‚åŒæ—¶ï¼ŒHiCoMæ”¯æŒå¹¶è¡Œå­¦ä¹ å¤šä¸ªå¸§ï¼Œå¹³å‡è®­ç»ƒæ—¶é—´ç¼©çŸ­è‡³æ¯å¸§å°äº2ç§’ï¼Œæé«˜äº†å®é™…åº”ç”¨ä¸­çš„å“åº”é€Ÿåº¦å’Œå¯ç”¨æ€§ã€‚</p>
<p><strong>å…³é”®è§è§£</strong></p>
<ol>
<li>å¤šè§†è§’æµåª’ä½“è§†é¢‘çš„åœ¨çº¿é‡å»ºé¢ä¸´å¤šæ–¹é¢çš„æŒ‘æˆ˜ã€‚é‡‡ç”¨å…ˆè¿›çš„è®­ç»ƒã€æ¸²æŸ“å’Œå­˜å‚¨æ•ˆç‡ç­–ç•¥ã€‚</li>
<li>ä¸‰ç»´é«˜æ–¯å–·ç»˜æŠ€æœ¯åœ¨å¤„ç†æ­¤ç±»ä»»åŠ¡æ—¶å…·æœ‰æ˜¾è‘—æ½œåŠ›ã€‚ç„¶è€Œï¼Œå®ƒä¹Ÿå­˜åœ¨å­˜å‚¨æ•ˆç‡ä½å’Œè¿‡åº¦æ‹Ÿåˆçš„é—®é¢˜ã€‚</li>
<li>HiCoMæ¡†æ¶é€šè¿‡æ„å»ºç´§å‡‘ä¸”ç¨³å¥çš„ä¸‰ç»´é«˜æ–¯å–·ç»˜åˆå§‹è¡¨ç¤ºæ¥è§£å†³ä¸Šè¿°é—®é¢˜ã€‚é‡‡ç”¨æ‰°åŠ¨å¹³æ»‘ç­–ç•¥å®ç°åˆå§‹è¡¨ç¤ºã€‚</li>
<li>å¼•å…¥å±‚æ¬¡åŒ–ååŒè¿åŠ¨æœºåˆ¶ï¼Œåˆ©ç”¨é«˜æ–¯åˆ†å¸ƒçš„éå‡åŒ€æ€§å’Œå±€éƒ¨ä¸€è‡´æ€§ï¼Œæé«˜å­¦ä¹ è¿åŠ¨çš„å‡†ç¡®æ€§å’Œé€Ÿåº¦ã€‚</li>
<li>é€šè¿‡ä¸æ–­ç²¾ç‚¼å’Œä¼˜åŒ–ä¸‰ç»´é«˜æ–¯å–·ç»˜æŠ€æœ¯æ¥æé«˜æ¨¡å‹çš„æ€§èƒ½å’Œé€‚åº”æ€§ã€‚é‡‡ç”¨åˆå¹¶ç­–ç•¥æ¥å¤„ç†æ–°å¢çš„é«˜æ–¯æ•°æ®ä»¥ä¿æŒæ¨¡å‹ä¸€è‡´æ€§ã€‚</li>
<li>å®éªŒè¯æ˜HiCoMæ¡†æ¶åœ¨æå‡å­¦ä¹ æ•ˆç‡å’Œå‡å°‘æ•°æ®å­˜å‚¨æ–¹é¢è¡¨ç°å‡ºæ˜¾è‘—ä¼˜åŠ¿ã€‚ç›¸è¾ƒäºç°æœ‰æŠ€æœ¯ï¼Œå­¦ä¹ æ•ˆç‡æé«˜çº¦20%ï¼Œå­˜å‚¨ç©ºé—´å‡å°‘é«˜è¾¾85%ã€‚åŒæ—¶å®ç°äº†é«˜è´¨é‡çš„è§†é¢‘åˆæˆæ•ˆæœã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2411.07541">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-14fa37c5aaa98c86bdf9f92b729cfae3.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-40fdaab3e808c28c7e840993bc571fa9.jpg" align="middle">
</details>


<h1 id="-11"><a href="#-11" class="headerlink" title=""></a></h1><h2 id="UW-GS-Distractor-Aware-3D-Gaussian-Splatting-for-Enhanced-Underwater-Scene-Reconstruction"><a href="#UW-GS-Distractor-Aware-3D-Gaussian-Splatting-for-Enhanced-Underwater-Scene-Reconstruction" class="headerlink" title="UW-GS: Distractor-Aware 3D Gaussian Splatting for Enhanced Underwater   Scene Reconstruction"></a>UW-GS: Distractor-Aware 3D Gaussian Splatting for Enhanced Underwater   Scene Reconstruction</h2><p><strong>Authors:Haoran Wang, Nantheera Anantrasirichai, Fan Zhang, David Bull</strong></p>
<p>3D Gaussian splatting (3DGS) offers the capability to achieve real-time high quality 3D scene rendering. However, 3DGS assumes that the scene is in a clear medium environment and struggles to generate satisfactory representations in underwater scenes, where light absorption and scattering are prevalent and moving objects are involved. To overcome these, we introduce a novel Gaussian Splatting-based method, UW-GS, designed specifically for underwater applications. It introduces a color appearance that models distance-dependent color variation, employs a new physics-based density control strategy to enhance clarity for distant objects, and uses a binary motion mask to handle dynamic content. Optimized with a well-designed loss function supporting for scattering media and strengthened by pseudo-depth maps, UW-GS outperforms existing methods with PSNR gains up to 1.26dB. To fully verify the effectiveness of the model, we also developed a new underwater dataset, S-UW, with dynamic object masks. </p>
<blockquote>
<p>3Dé«˜æ–¯å–·æ¶‚æŠ€æœ¯ï¼ˆ3DGSï¼‰å¯ä»¥å®ç°å®æ—¶é«˜è´¨é‡3Dåœºæ™¯æ¸²æŸ“ã€‚ç„¶è€Œï¼Œ3DGSå‡è®¾åœºæ™¯å¤„äºæ¸…æ™°çš„ä»‹è´¨ç¯å¢ƒä¸­ï¼Œå¯¹äºæ°´ä¸‹åœºæ™¯ï¼Œç”±äºå…‰çº¿å¸æ”¶å’Œæ•£å°„æ™®éå­˜åœ¨ä»¥åŠæ¶‰åŠç§»åŠ¨ç‰©ä½“ï¼Œå®ƒéš¾ä»¥äº§ç”Ÿä»¤äººæ»¡æ„çš„è¡¨ç¤ºã€‚ä¸ºäº†å…‹æœè¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§åŸºäºé«˜æ–¯å–·æ¶‚çš„æ–°æ–¹æ³•UW-GSï¼Œä¸“é—¨ç”¨äºæ°´ä¸‹åº”ç”¨ã€‚å®ƒå¼•å…¥äº†ä¸€ç§é¢œè‰²å¤–è§‚ï¼Œè¯¥é¢œè‰²å¤–è§‚æ¨¡æ‹Ÿä¸è·ç¦»ç›¸å…³çš„é¢œè‰²å˜åŒ–ï¼Œé‡‡ç”¨äº†ä¸€ç§åŸºäºç‰©ç†çš„æ–°å‹å¯†åº¦æ§åˆ¶ç­–ç•¥æ¥æé«˜è¿œè·ç¦»ç‰©ä½“çš„æ¸…æ™°åº¦ï¼Œå¹¶ä½¿ç”¨äºŒè¿›åˆ¶è¿åŠ¨è’™ç‰ˆæ¥å¤„ç†åŠ¨æ€å†…å®¹ã€‚é€šè¿‡ç²¾å¿ƒè®¾è®¡çš„æŸå¤±å‡½æ•°æ”¯æŒæ•£å°„ä»‹è´¨ï¼Œå¹¶é€šè¿‡ä¼ªæ·±åº¦å›¾å¢å¼ºï¼ŒUW-GSçš„æ€§èƒ½ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œå³°å€¼ä¿¡å™ªæ¯”æé«˜é«˜è¾¾1.26dBã€‚ä¸ºäº†å……åˆ†éªŒè¯æ¨¡å‹çš„æœ‰æ•ˆæ€§ï¼Œæˆ‘ä»¬è¿˜å¼€å‘äº†ä¸€ä¸ªæ–°çš„æ°´ä¸‹æ•°æ®é›†S-UWï¼Œå…¶ä¸­åŒ…å«åŠ¨æ€å¯¹è±¡è’™ç‰ˆã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2410.01517v2">PDF</a> Accepted at IEEE&#x2F;CVF WACV 2025</p>
<p><strong>æ‘˜è¦</strong></p>
<p>æœ¬æ–‡æ¢è®¨äº†ä½¿ç”¨æ”¹è¿›åçš„æ°´ä¸‹åœºæ™¯çš„é«˜æ–¯ç«‹ä½“æº…æ•£ï¼ˆUW-GSï¼‰æ–¹æ³•è¿›è¡Œå®æ—¶é«˜è´¨é‡ä¸‰ç»´åœºæ™¯æ¸²æŸ“ã€‚é’ˆå¯¹æ°´ä¸‹åœºæ™¯ä¸­çš„å…‰çº¿å¸æ”¶å’Œæ•£å°„é—®é¢˜ä»¥åŠåŠ¨æ€ç‰©ä½“çš„é—®é¢˜ï¼ŒUW-GSå¼•å…¥äº†åŸºäºé«˜æ–¯æº…æ•£çš„æ–¹æ³•ï¼Œè€ƒè™‘äº†è·ç¦»ä¾èµ–çš„é¢œè‰²å˜åŒ–æ¨¡å‹ï¼Œé‡‡ç”¨äº†æ–°çš„åŸºäºç‰©ç†çš„å¯†åº¦æ§åˆ¶ç­–ç•¥ï¼Œæé«˜äº†è¿œè·ç¦»ç‰©ä½“çš„æ¸…æ™°åº¦ï¼Œå¹¶ä½¿ç”¨äºŒè¿›åˆ¶è¿åŠ¨æ©è†œå¤„ç†åŠ¨æ€å†…å®¹ã€‚é€šè¿‡è®¾è®¡æ”¯æŒæ•£å°„ä»‹è´¨çš„æŸå¤±å‡½æ•°å’Œå¢å¼ºä¼ªæ·±åº¦å›¾ï¼ŒUW-GSåœ¨æ€§èƒ½ä¸Šä¼˜äºç°æœ‰æ–¹æ³•ï¼Œå³°å€¼ä¿¡å™ªæ¯”å¢ç›Šé«˜è¾¾1.26dBã€‚åŒæ—¶ä¸ºäº†éªŒè¯æ¨¡å‹çš„æœ‰æ•ˆæ€§ï¼Œæˆ‘ä»¬è¿˜å¼€å‘äº†æ–°çš„æ°´ä¸‹æ•°æ®é›†S-UWï¼ŒåŒ…å«åŠ¨æ€ç‰©ä½“æ©è†œã€‚</p>
<p><strong>è¦ç‚¹æ‘˜è¦</strong></p>
<ul>
<li>3DGSåœ¨æ¸…æ™°ä»‹è´¨ç¯å¢ƒä¸‹å¯å®ç°é«˜è´¨é‡çš„ä¸‰ç»´åœºæ™¯æ¸²æŸ“ã€‚</li>
<li>æ°´ä¸‹åœºæ™¯ä¸­çš„å…‰çº¿å¸æ”¶å’Œæ•£å°„ä½¿å¾—3DGSéš¾ä»¥ç”Ÿæˆæ»¡æ„çš„æ•ˆæœã€‚</li>
<li>æå‡ºäº†ä¸€ç§åŸºäºé«˜æ–¯æº…æ•£çš„æ–°æ–¹æ³•UW-GSï¼Œä¸“é—¨ç”¨äºæ°´ä¸‹åº”ç”¨ã€‚</li>
<li>è€ƒè™‘è·ç¦»ä¾èµ–çš„é¢œè‰²å˜åŒ–æ¨¡å‹ï¼Œå¢å¼ºè¿œè·ç¦»ç‰©ä½“çš„æ¸…æ™°åº¦ã€‚</li>
<li>é‡‡ç”¨æ–°çš„åŸºäºç‰©ç†çš„å¯†åº¦æ§åˆ¶ç­–ç•¥ä¼˜åŒ–è¿œè·ç¦»ç‰©ä½“æ¸²æŸ“ã€‚</li>
<li>ä½¿ç”¨äºŒè¿›åˆ¶è¿åŠ¨æ©è†œå¤„ç†åŠ¨æ€å†…å®¹ã€‚</li>
<li>é€šè¿‡è®¾è®¡æ”¯æŒæ•£å°„ä»‹è´¨çš„æŸå¤±å‡½æ•°å’Œå¢å¼ºä¼ªæ·±åº¦å›¾ä¼˜åŒ–æ¨¡å‹æ€§èƒ½ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2410.01517">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-13183eef628f2697e39bb2e377fa659e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-8a262e5a283eb4e48d34f2d26252cd23.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-71e6aa7d310dd51d665c78894d036d08.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-fdb6fe617f56341b05124eeb35ed89fe.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-56c875bcf1439b169069ab560a6dc3ec.jpg" align="middle">
</details>


<h1 id="-12"><a href="#-12" class="headerlink" title=""></a></h1><h2 id="3D-GSW-3D-Gaussian-Splatting-for-Robust-Watermarking"><a href="#3D-GSW-3D-Gaussian-Splatting-for-Robust-Watermarking" class="headerlink" title="3D-GSW: 3D Gaussian Splatting for Robust Watermarking"></a>3D-GSW: 3D Gaussian Splatting for Robust Watermarking</h2><p><strong>Authors:Youngdong Jang, Hyunje Park, Feng Yang, Heeju Ko, Euijin Choo, Sangpil Kim</strong></p>
<p>As 3D Gaussian Splatting<del>(3D-GS) gains significant attention and its commercial usage increases, the need for watermarking technologies to prevent unauthorized use of the 3D-GS models and rendered images has become increasingly important. In this paper, we introduce a robust watermarking method for 3D-GS that secures ownership of both the model and its rendered images. Our proposed method remains robust against distortions in rendered images and model attacks while maintaining high rendering quality. To achieve these objectives, we present Frequency-Guided Densification</del>(FGD), which removes 3D Gaussians based on their contribution to rendering quality, enhancing real-time rendering and the robustness of the message. FGD utilizes Discrete Fourier Transform to split 3D Gaussians in high-frequency areas, improving rendering quality. Furthermore, we employ a gradient mask for 3D Gaussians and design a wavelet-subband loss to enhance rendering quality. Our experiments show that our method embeds the message in the rendered images invisibly and robustly against various attacks, including model distortion. Our method achieves state-of-the-art performance. Project page: <a target="_blank" rel="noopener" href="https://kuai-lab.github.io/3dgsw2024/">https://kuai-lab.github.io/3dgsw2024/</a> </p>
<blockquote>
<p>éšç€ä¸‰ç»´é«˜æ–¯æ··åˆæŠ€æœ¯ï¼ˆ3DGSï¼‰å—åˆ°è¶Šæ¥è¶Šå¤šçš„å…³æ³¨ï¼Œå…¶å•†ä¸šåº”ç”¨ä¹Ÿåœ¨ä¸æ–­å¢åŠ ã€‚ä¸ºäº†é˜²æ­¢æœªç»æˆæƒçš„3DGSæ¨¡å‹å’Œæ¸²æŸ“å›¾åƒçš„ä½¿ç”¨ï¼Œæ°´å°æŠ€æœ¯çš„éœ€æ±‚å˜å¾—è¶Šæ¥è¶Šé‡è¦ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬ä¸ºä¸‰ç»´é«˜æ–¯æ··åˆæå‡ºäº†ä¸€ç§ç¨³å¥çš„æ°´å°æ–¹æ³•ï¼Œè¯¥æ–¹æ³•æ—¢ä¿æŠ¤æ¨¡å‹çš„æ‰€æœ‰æƒï¼Œåˆä¿æŠ¤å…¶æ¸²æŸ“å›¾åƒçš„æ‰€æœ‰æƒã€‚æ‰€æå‡ºçš„æ–¹æ³•å¯¹äºæ¸²æŸ“å›¾åƒçš„ç•¸å˜å’Œæ¨¡å‹æ”»å‡»å…·æœ‰å¾ˆå¼ºçš„é²æ£’æ€§ï¼ŒåŒæ—¶ä¿æŒäº†é«˜è´¨é‡çš„æ¸²æŸ“æ•ˆæœã€‚ä¸ºäº†å®ç°è¿™äº›ç›®æ ‡ï¼Œæˆ‘ä»¬æå‡ºäº†é¢‘ç‡å¼•å¯¼è‡´å¯†åŒ–ï¼ˆFGDï¼‰çš„æ–¹æ³•ï¼Œè¯¥æ–¹æ³•æ ¹æ®å…¶å¯¹æ¸²æŸ“è´¨é‡çš„è´¡çŒ®å»é™¤ä¸‰ç»´é«˜æ–¯ï¼Œä»è€Œæé«˜å®æ—¶æ¸²æŸ“å’Œä¿¡æ¯å†…å®¹çš„ç¨³å¥æ€§ã€‚FGDåˆ©ç”¨ç¦»æ•£å‚…é‡Œå¶å˜æ¢å°†ä¸‰ç»´é«˜æ–¯åœ¨é«˜é¢‘åŒºåŸŸè¿›è¡Œåˆ†å‰²ï¼Œä»¥æé«˜æ¸²æŸ“è´¨é‡ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å¯¹ä¸‰ç»´é«˜æ–¯è¿›è¡Œäº†æ¢¯åº¦æ©è†œå¤„ç†ï¼Œå¹¶è®¾è®¡äº†ä¸€ç§å°æ³¢å­å¸¦æŸå¤±æ¥æé«˜æ¸²æŸ“è´¨é‡ã€‚å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•å°†ä¿¡æ¯åµŒå…¥åˆ°æ¸²æŸ“å›¾åƒä¸­ï¼Œå¯¹å„ç§æ”»å‡»å…·æœ‰ä¸å¯è§æ€§å’Œç¨³å¥æ€§ï¼ŒåŒ…æ‹¬æ¨¡å‹ç•¸å˜ã€‚æˆ‘ä»¬çš„æ–¹æ³•è¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚é¡¹ç›®é¡µé¢ï¼š<a target="_blank" rel="noopener" href="https://kuai-lab.github.io/3dgsw2024/">https://kuai-lab.github.io/3dgsw2024/</a>ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2409.13222v3">PDF</a> </p>
<p><strong>æ‘˜è¦</strong><br>    éšç€3Dé«˜æ–¯å±•é“ºï¼ˆ3D-GSï¼‰å—åˆ°å¹¿æ³›å…³æ³¨åŠå•†ä¸šåº”ç”¨çš„å¢åŠ ï¼Œé˜²æ­¢æœªç»æˆæƒä½¿ç”¨3D-GSæ¨¡å‹å’Œæ¸²æŸ“å›¾åƒçš„éœ€æ±‚æ—¥ç›Šé‡è¦ã€‚æœ¬æ–‡ä»‹ç»äº†ä¸€ç§é’ˆå¯¹3D-GSçš„ç¨³å¥æ°´å°æ–¹æ³•ï¼Œç¡®ä¿æ¨¡å‹å’Œæ¸²æŸ“å›¾åƒçš„æ‰€æœ‰æƒå®‰å…¨ã€‚è¯¥æ–¹æ³•å¯¹æ¸²æŸ“å›¾åƒçš„å¤±çœŸå’Œæ¨¡å‹æ”»å‡»å…·æœ‰é²æ£’æ€§ï¼ŒåŒæ—¶ä¿æŒé«˜è´¨é‡çš„æ¸²æŸ“ã€‚é€šè¿‡æå‡ºé¢‘ç‡å¼•å¯¼å¯†å®åŒ–ï¼ˆFGDï¼‰å®ç°è¿™ä¸€ç›®æ ‡ï¼Œè¯¥æ–¹æ³•æ ¹æ®å…¶å¯¹æ¸²æŸ“è´¨é‡çš„è´¡çŒ®å»é™¤3Dé«˜æ–¯ï¼Œæé«˜å®æ—¶æ¸²æŸ“å’Œä¿¡æ¯é²æ£’æ€§ã€‚FGDåˆ©ç”¨ç¦»æ•£å‚…é‡Œå¶å˜æ¢å°†3Dé«˜æ–¯åˆ†è£‚ä¸ºé«˜é¢‘åŒºåŸŸï¼Œæé«˜æ¸²æŸ“è´¨é‡ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å¯¹3Dé«˜æ–¯é‡‡ç”¨æ¢¯åº¦æ©è†œï¼Œå¹¶è®¾è®¡å°æ³¢å­å¸¦æŸå¤±æ¥æé«˜æ¸²æŸ“è´¨é‡ã€‚å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•å°†ä¿¡æ¯åµŒå…¥æ¸²æŸ“å›¾åƒä¸­ï¼Œå¯¹å„ç§æ”»å‡»å…·æœ‰éšå½¢å’Œé²æ£’æ€§ï¼ŒåŒ…æ‹¬æ¨¡å‹å¤±çœŸã€‚è¯¥æ–¹æ³•è¾¾åˆ°æœ€æ–°æ€§èƒ½æ°´å¹³ã€‚</p>
<p><strong>è¦ç‚¹</strong></p>
<ol>
<li>éšç€3D-GSå—åˆ°å…³æ³¨åŠå•†ä¸šåº”ç”¨å¢é•¿ï¼Œä¿æŠ¤3Dæ¨¡å‹åŠæ¸²æŸ“å›¾åƒæ‰€æœ‰æƒçš„éœ€æ±‚å¢å¼ºã€‚</li>
<li>å¼•å…¥ä¸€ç§é’ˆå¯¹3D-GSçš„ç¨³å¥æ°´å°æ–¹æ³•ï¼Œç¡®ä¿æ¨¡å‹å’Œæ¸²æŸ“å›¾åƒçš„æ‰€æœ‰æƒã€‚</li>
<li>æå‡ºé¢‘ç‡å¼•å¯¼å¯†å®åŒ–ï¼ˆFGDï¼‰æ–¹æ³•ï¼Œæ ¹æ®å¯¹æ¸²æŸ“è´¨é‡çš„è´¡çŒ®å¤„ç†3Dé«˜æ–¯ã€‚</li>
<li>FGDåˆ©ç”¨ç¦»æ•£å‚…é‡Œå¶å˜æ¢åˆ†è£‚3Dé«˜æ–¯ä¸ºé«˜é¢‘åŒºåŸŸï¼Œæé«˜æ¸²æŸ“è´¨é‡ã€‚</li>
<li>é‡‡ç”¨æ¢¯åº¦æ©è†œåŠå°æ³¢å­å¸¦æŸå¤±å¢å¼ºæ¸²æŸ“è´¨é‡ã€‚</li>
<li>å®éªŒæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•èƒ½éšå½¢ä¸”ç¨³å¥åœ°å°†ä¿¡æ¯åµŒå…¥æ¸²æŸ“å›¾åƒï¼Œå¯¹æŠ—åŒ…æ‹¬æ¨¡å‹å¤±çœŸåœ¨å†…çš„å„ç§æ”»å‡»ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2409.13222">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-594b5efc3fc65535a23bb54bc71c4b54.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-17493ae1c826c9e9d1642b87372e9bdb.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-12203e93cf60417115582e52db8c0b1d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-5162a52706f15cbf7b91ac5e9073a8dc.jpg" align="middle">
</details>


<h1 id="-13"><a href="#-13" class="headerlink" title=""></a></h1><h2 id="DrivingForward-Feed-forward-3D-Gaussian-Splatting-for-Driving-Scene-Reconstruction-from-Flexible-Surround-view-Input"><a href="#DrivingForward-Feed-forward-3D-Gaussian-Splatting-for-Driving-Scene-Reconstruction-from-Flexible-Surround-view-Input" class="headerlink" title="DrivingForward: Feed-forward 3D Gaussian Splatting for Driving Scene   Reconstruction from Flexible Surround-view Input"></a>DrivingForward: Feed-forward 3D Gaussian Splatting for Driving Scene   Reconstruction from Flexible Surround-view Input</h2><p><strong>Authors:Qijian Tian, Xin Tan, Yuan Xie, Lizhuang Ma</strong></p>
<p>We propose DrivingForward, a feed-forward Gaussian Splatting model that reconstructs driving scenes from flexible surround-view input. Driving scene images from vehicle-mounted cameras are typically sparse, with limited overlap, and the movement of the vehicle further complicates the acquisition of camera extrinsics. To tackle these challenges and achieve real-time reconstruction, we jointly train a pose network, a depth network, and a Gaussian network to predict the Gaussian primitives that represent the driving scenes. The pose network and depth network determine the position of the Gaussian primitives in a self-supervised manner, without using depth ground truth and camera extrinsics during training. The Gaussian network independently predicts primitive parameters from each input image, including covariance, opacity, and spherical harmonics coefficients. At the inference stage, our model can achieve feed-forward reconstruction from flexible multi-frame surround-view input. Experiments on the nuScenes dataset show that our model outperforms existing state-of-the-art feed-forward and scene-optimized reconstruction methods in terms of reconstruction. </p>
<blockquote>
<p>æˆ‘ä»¬æå‡ºäº†DrivingForwardè¿™ä¸€å‰é¦ˆé«˜æ–¯æ‹¼è´´æ¨¡å‹ï¼Œè¯¥æ¨¡å‹èƒ½å¤Ÿä»çµæ´»çš„å¤šè§†è§’è¾“å…¥é‡å»ºé©¾é©¶åœºæ™¯ã€‚è½¦è½½ç›¸æœºæ‹æ‘„çš„é©¾é©¶åœºæ™¯å›¾åƒé€šå¸¸ç¨€ç–ä¸”é‡å æœ‰é™ï¼Œè½¦è¾†çš„è¿åŠ¨è¿›ä¸€æ­¥å¢åŠ äº†è·å–ç›¸æœºå¤–éƒ¨å‚æ•°çš„éš¾åº¦ã€‚ä¸ºäº†åº”å¯¹è¿™äº›æŒ‘æˆ˜å¹¶å®ç°å®æ—¶é‡å»ºï¼Œæˆ‘ä»¬è”åˆè®­ç»ƒäº†ä¸€ä¸ªå§¿æ€ç½‘ç»œã€ä¸€ä¸ªæ·±åº¦ç½‘ç»œå’Œä¸€ä¸ªé«˜æ–¯ç½‘ç»œï¼Œä»¥é¢„æµ‹ä»£è¡¨é©¾é©¶åœºæ™¯çš„é«˜æ–¯åŸºæœ¬ä½“ã€‚å§¿æ€ç½‘ç»œå’Œæ·±åº¦ç½‘ç»œä»¥è‡ªæˆ‘ç›‘ç£çš„æ–¹å¼ç¡®å®šé«˜æ–¯åŸºæœ¬ä½“çš„ä½ç½®ï¼Œåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ä¸ä½¿ç”¨æ·±åº¦çœŸå®å€¼å’Œç›¸æœºå¤–éƒ¨å‚æ•°ã€‚é«˜æ–¯ç½‘ç»œç‹¬ç«‹åœ°ä»æ¯ä¸ªè¾“å…¥å›¾åƒé¢„æµ‹åŸºæœ¬ä½“å‚æ•°ï¼ŒåŒ…æ‹¬åæ–¹å·®ã€ä¸é€æ˜åº¦å’Œçƒé¢è°æ³¢ç³»æ•°ã€‚åœ¨æ¨ç†é˜¶æ®µï¼Œæˆ‘ä»¬çš„æ¨¡å‹å¯ä»¥ä»çµæ´»çš„å¤šè§†è§’è¾“å…¥å®ç°å‰é¦ˆé‡å»ºã€‚åœ¨nuScenesæ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ¨¡å‹åœ¨é‡å»ºæ–¹é¢ä¼˜äºç°æœ‰çš„æœ€å…ˆè¿›çš„å‰é¦ˆå’Œåœºæ™¯ä¼˜åŒ–é‡å»ºæ–¹æ³•ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2409.12753v2">PDF</a> Accept by AAAI 2025. Project Page:   <a target="_blank" rel="noopener" href="https://fangzhou2000.github.io/projects/drivingforward/">https://fangzhou2000.github.io/projects/drivingforward/</a></p>
<p><strong>æ‘˜è¦</strong></p>
<p>æå‡ºäº†ä¸€ç§åä¸ºDrivingForwardçš„å‘å‰ä¼ é€’é«˜æ–¯æ¶‚æ–‘æ¨¡å‹ï¼Œè¯¥æ¨¡å‹èƒ½å¤Ÿä»çµæ´»çš„ç¯ç»•è§†å›¾è¾“å…¥é‡å»ºé©¾é©¶åœºæ™¯ã€‚é’ˆå¯¹è½¦è½½ç›¸æœºæ‹æ‘„çš„é©¾é©¶åœºæ™¯å›¾åƒç¨€ç–ã€é‡å æœ‰é™ï¼Œä»¥åŠè½¦è¾†è¿åŠ¨å¯¼è‡´ç›¸æœºå¤–éƒ¨å‚æ•°è·å–å›°éš¾ç­‰é—®é¢˜ï¼Œæˆ‘ä»¬è”åˆè®­ç»ƒäº†ä¸€ä¸ªå§¿æ€ç½‘ç»œã€æ·±åº¦ç½‘ç»œå’Œé«˜æ–¯ç½‘ç»œï¼Œä»¥é¢„æµ‹ä»£è¡¨é©¾é©¶åœºæ™¯çš„é«˜æ–¯åŸºå…ƒã€‚å§¿æ€ç½‘ç»œå’Œæ·±åº¦ç½‘ç»œä»¥è‡ªæˆ‘ç›‘ç£çš„æ–¹å¼ç¡®å®šé«˜æ–¯åŸºå…ƒçš„ä½ç½®ï¼Œè®­ç»ƒè¿‡ç¨‹ä¸­æ— éœ€ä½¿ç”¨æ·±åº¦åœ°é¢çœŸå®å€¼å’Œç›¸æœºå¤–éƒ¨å‚æ•°ã€‚é«˜æ–¯ç½‘ç»œç‹¬ç«‹é¢„æµ‹æ¯ä¸ªè¾“å…¥å›¾åƒçš„é«˜æ–¯åŸºå…ƒå‚æ•°ï¼ŒåŒ…æ‹¬åæ–¹å·®ã€ä¸é€æ˜åº¦å’Œçƒé¢è°æ³¢ç³»æ•°ã€‚åœ¨æ¨ç†é˜¶æ®µï¼Œæˆ‘ä»¬çš„æ¨¡å‹èƒ½å¤Ÿå®ç°ä»çµæ´»çš„å¤šå¸§ç¯ç»•è§†å›¾è¾“å…¥çš„å‘å‰é‡å»ºã€‚åœ¨nuScenesæ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ¨¡å‹åœ¨é‡å»ºæ–¹é¢ä¼˜äºç°æœ‰çš„æœ€å…ˆè¿›çš„å‘å‰ä¼ é€’å’Œåœºæ™¯ä¼˜åŒ–é‡å»ºæ–¹æ³•ã€‚</p>
<p><strong>è¦ç‚¹</strong></p>
<ol>
<li>æå‡ºä¸€ç§åä¸ºDrivingForwardçš„å‘å‰ä¼ é€’é«˜æ–¯æ¶‚æ–‘æ¨¡å‹ï¼Œèƒ½å¤Ÿä»çµæ´»çš„ç¯ç»•è§†å›¾è¾“å…¥é‡å»ºé©¾é©¶åœºæ™¯ã€‚</li>
<li>è”åˆè®­ç»ƒå§¿æ€ç½‘ç»œã€æ·±åº¦ç½‘ç»œå’Œé«˜æ–¯ç½‘ç»œï¼Œä»¥é¢„æµ‹ä»£è¡¨é©¾é©¶åœºæ™¯çš„é«˜æ–¯åŸºå…ƒã€‚</li>
<li>å§¿æ€ç½‘ç»œå’Œæ·±åº¦ç½‘ç»œä»¥è‡ªæˆ‘ç›‘ç£çš„æ–¹å¼å·¥ä½œï¼Œæ— éœ€æ·±åº¦åœ°é¢çœŸå®å€¼å’Œç›¸æœºå¤–éƒ¨å‚æ•°ã€‚</li>
<li>é«˜æ–¯ç½‘ç»œé¢„æµ‹æ¯ä¸ªè¾“å…¥å›¾åƒçš„é«˜æ–¯åŸºå…ƒå‚æ•°ï¼ŒåŒ…æ‹¬åæ–¹å·®ã€ä¸é€æ˜åº¦å’Œçƒé¢è°æ³¢ç³»æ•°ã€‚</li>
<li>æ¨¡å‹åœ¨æ¨ç†é˜¶æ®µèƒ½å¤Ÿå®ç°å¤šå¸§ç¯ç»•è§†å›¾è¾“å…¥çš„å‘å‰é‡å»ºã€‚</li>
<li>åœ¨nuScenesæ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œè¯¥æ¨¡å‹åœ¨é‡å»ºæ€§èƒ½ä¸Šä¼˜äºç°æœ‰æ–¹æ³•ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2409.12753">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-6acfcff749dc4ac371843c85ee57efac.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-d0693ae63259c42eb4da9873d521ac4c.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-7360b8507bf0593534289e237d341c49.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-9003f418d96593f71a3d5c424d494f16.jpg" align="middle">
</details>


<h1 id="-14"><a href="#-14" class="headerlink" title=""></a></h1><h2 id="HeadStudio-Text-to-Animatable-Head-Avatars-with-3D-Gaussian-Splatting"><a href="#HeadStudio-Text-to-Animatable-Head-Avatars-with-3D-Gaussian-Splatting" class="headerlink" title="HeadStudio: Text to Animatable Head Avatars with 3D Gaussian Splatting"></a>HeadStudio: Text to Animatable Head Avatars with 3D Gaussian Splatting</h2><p><strong>Authors:Zhenglin Zhou, Fan Ma, Hehe Fan, Zongxin Yang, Yi Yang</strong></p>
<p>Creating digital avatars from textual prompts has long been a desirable yet challenging task. Despite the promising results achieved with 2D diffusion priors, current methods struggle to create high-quality and consistent animated avatars efficiently. Previous animatable head models like FLAME have difficulty in accurately representing detailed texture and geometry. Additionally, high-quality 3D static representations face challenges in semantically driving with dynamic priors. In this paper, we introduce \textbf{HeadStudio}, a novel framework that utilizes 3D Gaussian splatting to generate realistic and animatable avatars from text prompts. Firstly, we associate 3D Gaussians with animatable head prior model, facilitating semantic animation on high-quality 3D representations. To ensure consistent animation, we further enhance the optimization from initialization, distillation, and regularization to jointly learn the shape, texture, and animation. Extensive experiments demonstrate the efficacy of HeadStudio in generating animatable avatars from textual prompts, exhibiting appealing appearances. The avatars are capable of rendering high-quality real-time ($\geq 40$ fps) novel views at a resolution of 1024. Moreover, These avatars can be smoothly driven by real-world speech and video. We hope that HeadStudio can enhance digital avatar creation and gain popularity in the community. Code is at: <a target="_blank" rel="noopener" href="https://github.com/ZhenglinZhou/HeadStudio">https://github.com/ZhenglinZhou/HeadStudio</a>. </p>
<blockquote>
<p>ä»æ–‡æœ¬æç¤ºåˆ›å»ºæ•°å­—åŒ–èº«ä¸€ç›´æ˜¯ä¸€é¡¹ä»¤äººå‘å¾€ä½†å…·æœ‰æŒ‘æˆ˜æ€§çš„ä»»åŠ¡ã€‚å°½ç®¡äºŒç»´æ‰©æ•£å…ˆéªŒå–å¾—äº†æœ‰å‰æ™¯çš„ç»“æœï¼Œä½†å½“å‰çš„æ–¹æ³•ä»ç„¶éš¾ä»¥é«˜æ•ˆåœ°åˆ›å»ºé«˜è´¨é‡ä¸”è¿è´¯çš„åŠ¨ç”»åŒ–èº«ã€‚åƒFLAMEè¿™æ ·çš„å…ˆå‰å¯åŠ¨ç”»å¤´éƒ¨æ¨¡å‹åœ¨å‡†ç¡®è¡¨ç¤ºç²¾ç»†çº¹ç†å’Œå‡ ä½•ç»“æ„æ–¹é¢å­˜åœ¨å›°éš¾ã€‚æ­¤å¤–ï¼Œé«˜è´¨é‡çš„ä¸‰ç»´é™æ€è¡¨ç¤ºåœ¨è¯­ä¹‰é©±åŠ¨çš„åŠ¨æ€å…ˆéªŒæ–¹é¢ä¹Ÿé¢ä¸´æŒ‘æˆ˜ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬ä»‹ç»äº†HeadStudioï¼Œè¿™æ˜¯ä¸€ä¸ªåˆ©ç”¨ä¸‰ç»´é«˜æ–¯æ‹¼è´´æ³•ä»æ–‡æœ¬æç¤ºç”Ÿæˆé€¼çœŸä¸”å¯åŠ¨ç”»çš„åŒ–èº«çš„æ–°å‹æ¡†æ¶ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬å°†ä¸‰ç»´é«˜æ–¯ä¸å¯åŠ¨ç”»å¤´éƒ¨å…ˆéªŒæ¨¡å‹ç›¸å…³è”ï¼Œä¿ƒè¿›é«˜è´¨é‡ä¸‰ç»´è¡¨ç¤ºä¸Šçš„è¯­ä¹‰åŠ¨ç”»ã€‚ä¸ºäº†ç¡®ä¿è¿è´¯çš„åŠ¨ç”»ï¼Œæˆ‘ä»¬è¿›ä¸€æ­¥å¢å¼ºäº†ä»åˆå§‹åŒ–ã€è’¸é¦å’Œæ­£åˆ™åŒ–å¼€å§‹çš„ä¼˜åŒ–ï¼Œä»¥è”åˆå­¦ä¹ å½¢çŠ¶ã€çº¹ç†å’ŒåŠ¨ç”»ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼ŒHeadStudioåœ¨ä»æ–‡æœ¬æç¤ºç”Ÿæˆå¯åŠ¨ç”»åŒ–èº«æ–¹é¢éå¸¸æœ‰æ•ˆï¼Œå…·æœ‰å¸å¼•äººçš„å¤–è§‚ã€‚è¿™äº›åŒ–èº«èƒ½å¤Ÿä»¥é«˜äºæˆ–ç­‰äº40å¸§&#x2F;ç§’çš„é€Ÿåº¦å‘ˆç°é«˜è´¨é‡å®æ—¶ï¼ˆâ‰¥40å¸§&#x2F;ç§’ï¼‰çš„æ–°è§†è§’ï¼Œåˆ†è¾¨ç‡é«˜è¾¾1024ã€‚æ­¤å¤–ï¼Œè¿™äº›åŒ–èº«å¯ä»¥è¢«ç°å®ä¸–ç•Œä¸­çš„è¯­éŸ³å’Œè§†é¢‘æµç•…é©±åŠ¨ã€‚æˆ‘ä»¬å¸Œæœ›HeadStudioèƒ½å¢å¼ºæ•°å­—åŒ–èº«çš„åˆ›å»ºå¹¶åœ¨ç¤¾åŒºä¸­å¹¿å—æ¬¢è¿ã€‚ä»£ç åœ°å€ä¸ºï¼š<a target="_blank" rel="noopener" href="https://github.com/ZhenglinZhou/HeadStudio%E3%80%82">https://github.com/ZhenglinZhou/HeadStudioã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2402.06149v2">PDF</a> 26 pages, 18 figures, accepted by ECCV 2024</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†ä¸€ç§åä¸ºHeadStudioçš„æ–°å‹æ¡†æ¶ï¼Œå®ƒåˆ©ç”¨3Dé«˜æ–¯æ¶‚æ–‘æŠ€æœ¯ä»æ–‡æœ¬æç¤ºç”ŸæˆçœŸå®ä¸”å¯åŠ¨ç”»çš„å¤´åƒã€‚HeadStudioç»“åˆå¯åŠ¨ç”»çš„å¤´éƒ¨å…ˆéªŒæ¨¡å‹ä¸3Dé«˜æ–¯ï¼Œå®ç°åœ¨é«˜è´¨é‡3Dè¡¨ç¤ºä¸Šçš„è¯­ä¹‰åŠ¨ç”»ã€‚é€šè¿‡ä¼˜åŒ–åˆå§‹åŒ–ã€è’¸é¦å’Œæ­£åˆ™åŒ–ï¼Œè”åˆå­¦ä¹ å½¢çŠ¶ã€çº¹ç†å’ŒåŠ¨ç”»ã€‚å®éªŒè¡¨æ˜ï¼ŒHeadStudioèƒ½ä»æœªåŠ å·¥çš„æ–‡æœ¬ä¸­ç”Ÿæˆå¯åŠ¨ç”»çš„å¤´åƒï¼Œå±•ç°å¸å¼•äººçš„å¤–è§‚ï¼Œå¹¶ä»¥é«˜è´¨é‡å®æ—¶æ¸²æŸ“ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>HeadStudioåˆ©ç”¨3Dé«˜æ–¯æ¶‚æ–‘æŠ€æœ¯ç”ŸæˆçœŸå®ä¸”å¯åŠ¨ç”»çš„å¤´åƒã€‚</li>
<li>ç»“åˆå¯åŠ¨ç”»çš„å¤´éƒ¨å…ˆéªŒæ¨¡å‹ä¸3Dé«˜æ–¯ï¼Œå®ç°é«˜è´¨é‡3Dè¡¨ç¤ºä¸Šçš„è¯­ä¹‰åŠ¨ç”»ã€‚</li>
<li>é€šè¿‡ä¼˜åŒ–åˆå§‹åŒ–ã€è’¸é¦å’Œæ­£åˆ™åŒ–ï¼Œè”åˆå­¦ä¹ å½¢çŠ¶ã€çº¹ç†å’ŒåŠ¨ç”»ï¼Œç¡®ä¿åŠ¨ç”»çš„ä¸€è‡´æ€§ã€‚</li>
<li>HeadStudioå¯ä»æ–‡æœ¬æç¤ºç”Ÿæˆå¯åŠ¨ç”»çš„å¤´åƒï¼Œå±•ç°å¸å¼•äººçš„å¤–è§‚ã€‚</li>
<li>ç”Ÿæˆçš„å¤´åƒèƒ½ä»¥é«˜è´¨é‡å®æ—¶æ¸²æŸ“ï¼Œæ¸²æŸ“é€Ÿåº¦è¾¾åˆ°æˆ–è¶…è¿‡40å¸§æ¯ç§’ã€‚</li>
<li>è¿™äº›å¤´åƒå¯ä»¥è¢«çœŸå®ä¸–ç•Œçš„è¯­éŸ³å’Œè§†é¢‘æµç•…é©±åŠ¨ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2402.06149">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-215d6480ae84da5896c28fbfbfba36d0.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-70eb1a7b18cd38c2ce7113fe7c708209.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-dfa619e455be609c31826d56564bb1b5.jpg" align="middle">
</details>


<h1 id="-15"><a href="#-15" class="headerlink" title=""></a></h1><h2 id="WavePlanes-Compact-Hex-Planes-for-Dynamic-Novel-View-Synthesis"><a href="#WavePlanes-Compact-Hex-Planes-for-Dynamic-Novel-View-Synthesis" class="headerlink" title="WavePlanes: Compact Hex Planes for Dynamic Novel View Synthesis"></a>WavePlanes: Compact Hex Planes for Dynamic Novel View Synthesis</h2><p><strong>Authors:Adrian Azzarelli, Nantheera Anantrasirichai, David R Bull</strong></p>
<p>Dynamic Novel View Synthesis (Dynamic NVS) enhances NVS technologies to model moving 3-D scenes. However, current methods are resource intensive and challenging to compress. To address this, we present WavePlanes, a fast and more compact hex plane representation, applicable to both Neural Radiance Fields and Gaussian Splatting methods. Rather than modeling many feature scales separately (as done previously), we use the inverse discrete wavelet transform to reconstruct features at varying scales. This leads to a more compact representation and allows us to explore wavelet-based compression schemes for further gains. The proposed compression scheme exploits the sparsity of wavelet coefficients, by applying hard thresholding to the wavelet planes and storing nonzero coefficients and their locations on each plane in a Hash Map. Compared to the state-of-the-art (SotA), WavePlanes is significantly smaller, less resource demanding and competitive in reconstruction quality. Compared to small SotA models, WavePlanes outperforms methods in both model size and quality of novel views. </p>
<blockquote>
<p>åŠ¨æ€åœºæ™¯è§†å›¾åˆæˆæŠ€æœ¯ï¼ˆDynamic Novel View Synthesisï¼Œç®€ç§°Dynamic NVSï¼‰æ—¨åœ¨å¢å¼ºNVSæŠ€æœ¯åœ¨æ¨¡æ‹Ÿç§»åŠ¨ä¸‰ç»´åœºæ™¯æ–¹é¢çš„èƒ½åŠ›ã€‚ç„¶è€Œï¼Œå½“å‰çš„æ–¹æ³•èµ„æºæ¶ˆè€—å¤§ä¸”å‹ç¼©å…·æœ‰æŒ‘æˆ˜æ€§ã€‚é’ˆå¯¹è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†WavePlanesï¼Œè¿™æ˜¯ä¸€ç§å¿«é€Ÿä¸”æ›´ç´§å‡‘çš„å…­å¹³é¢è¡¨ç¤ºæ³•ï¼Œé€‚ç”¨äºç¥ç»ç½‘ç»œè¾å°„åœºå’Œé«˜æ–¯è´´å›¾æ–¹æ³•ã€‚æˆ‘ä»¬ä¸å†åƒè¿‡å»é‚£æ ·å•ç‹¬å»ºæ¨¡è®¸å¤šç‰¹å¾å°ºåº¦ï¼Œè€Œæ˜¯ä½¿ç”¨é€†ç¦»æ•£å°æ³¢å˜æ¢æ¥é‡å»ºä¸åŒå°ºåº¦çš„ç‰¹å¾ã€‚è¿™å¯¼è‡´äº†æ›´ç´§å‡‘çš„è¡¨ç¤ºå½¢å¼ï¼Œå¹¶å…è®¸æˆ‘ä»¬è¿›ä¸€æ­¥æ¢ç´¢åŸºäºå°æ³¢å‹ç¼©æ–¹æ¡ˆä»¥è·å¾—æ›´å¤šæ”¶ç›Šã€‚æ‰€æå‡ºçš„å‹ç¼©æ–¹æ¡ˆé€šè¿‡åˆ©ç”¨å°æ³¢ç³»æ•°çš„ç¨€ç–æ€§ï¼Œå¯¹å°æ³¢å¹³é¢åº”ç”¨ç¡¬é˜ˆå€¼å¤„ç†ï¼Œå¹¶åœ¨å“ˆå¸Œè¡¨ä¸­å­˜å‚¨æ¯ä¸ªå¹³é¢ä¸Šçš„éé›¶ç³»æ•°åŠå…¶ä½ç½®ã€‚ä¸ç°æœ‰æŠ€æœ¯ç›¸æ¯”ï¼ŒWavePlanesä½“ç§¯æ›´å°ã€èµ„æºæ¶ˆè€—æ›´ä½ä¸”åœ¨é‡å»ºè´¨é‡æ–¹é¢å…·æœ‰ç«äº‰åŠ›ã€‚ç›¸è¾ƒäºå°å‹ç°æœ‰æŠ€æœ¯æ¨¡å‹ï¼ŒWavePlanesåœ¨æ¨¡å‹å¤§å°å’Œæ–°è§†å›¾è´¨é‡æ–¹é¢éƒ½è¡¨ç°å‡ºä¼˜è¶Šæ€§èƒ½ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2312.02218v4">PDF</a> </p>
<p><strong>Summary</strong><br>åŠ¨æ€åœºæ™¯å»ºæ¨¡æŠ€æœ¯åŠ¨æ€å°è¯´è§†å›¾åˆæˆï¼ˆDynamic NVSï¼‰æé«˜äº†NVSæŠ€æœ¯çš„æ€§èƒ½ï¼Œä½†å½“å‰æ–¹æ³•èµ„æºå¯†é›†ä¸”å‹ç¼©å›°éš¾ã€‚æœ¬ç ”ç©¶æå‡ºäº†WavePlanesï¼Œä¸€ç§å¿«é€Ÿä¸”æ›´ç´§å‡‘çš„å…­å¹³é¢è¡¨ç¤ºæ–¹æ³•ï¼Œé€‚ç”¨äºç¥ç»è¾å°„åœºå’Œé«˜æ–¯æº…å°„æ–¹æ³•ã€‚æˆ‘ä»¬åˆ©ç”¨é€†ç¦»æ•£å°æ³¢å˜æ¢é‡æ„ä¸åŒå°ºåº¦çš„ç‰¹å¾ï¼Œå®ç°äº†æ›´ç´§å‡‘çš„è¡¨ç¤ºï¼Œå¹¶æ¢ç´¢äº†åŸºäºå°æ³¢çš„æ›´é«˜æ•ˆçš„å‹ç¼©æ–¹æ¡ˆã€‚å‹ç¼©æ–¹æ¡ˆåˆ©ç”¨å°æ³¢ç³»æ•°çš„ç¨€ç–æ€§ï¼Œé€šè¿‡å¯¹å°æ³¢å¹³é¢åº”ç”¨ç¡¬é˜ˆå€¼å¤„ç†å¹¶å­˜å‚¨æ¯ä¸ªå¹³é¢ä¸Šçš„éé›¶ç³»æ•°åŠå…¶ä½ç½®æ¥å®ç°é«˜æ•ˆçš„å­˜å‚¨ã€‚ä¸æœ€æ–°æŠ€æœ¯ç›¸æ¯”ï¼ŒWavePlanesä½“ç§¯æ›´å°ã€èµ„æºéœ€æ±‚æ›´ä½ï¼Œåœ¨é‡å»ºè´¨é‡æ–¹é¢å…·æœ‰ç«äº‰åŠ›ï¼›åœ¨å°æ¨¡å‹æ–¹é¢ï¼ŒWavePlanesåœ¨æ¨¡å‹å¤§å°å’Œè´¨é‡ä¸Šå‡è¡¨ç°å‡ºä¼˜åŠ¿ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>åŠ¨æ€åœºæ™¯å»ºæ¨¡æŠ€æœ¯ä¸­çš„Dynamic NVSé¢ä¸´èµ„æºå¯†é›†å’Œå‹ç¼©å›°éš¾çš„é—®é¢˜ã€‚</li>
<li>WavePlanesæ˜¯ä¸€ç§æ–°çš„å…­å¹³é¢è¡¨ç¤ºæ–¹æ³•ï¼Œé€‚ç”¨äºç¥ç»è¾å°„åœºå’Œé«˜æ–¯æº…å°„æ–¹æ³•ã€‚</li>
<li>åˆ©ç”¨é€†ç¦»æ•£å°æ³¢å˜æ¢é‡æ„ä¸åŒå°ºåº¦çš„ç‰¹å¾ï¼Œå®ç°æ›´ç´§å‡‘çš„æ¨¡å‹è¡¨ç¤ºã€‚</li>
<li>åŸºäºå°æ³¢ç³»æ•°çš„ç¨€ç–æ€§ï¼Œæå‡ºäº†é«˜æ•ˆçš„å‹ç¼©æ–¹æ¡ˆã€‚</li>
<li>é€šè¿‡ç¡¬é˜ˆå€¼å¤„ç†å°æ³¢å¹³é¢å¹¶å­˜å‚¨éé›¶ç³»æ•°åŠå…¶ä½ç½®æ¥å®ç°å­˜å‚¨ä¼˜åŒ–ã€‚</li>
<li>ä¸ç°æœ‰æŠ€æœ¯ç›¸æ¯”ï¼ŒWavePlanesæ¨¡å‹æ›´å°ã€èµ„æºéœ€æ±‚æ›´ä½ï¼Œåœ¨é‡å»ºè´¨é‡æ–¹é¢å…·æœ‰ç«äº‰åŠ›ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2312.02218">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-7173d381f3f168972b0e17b820a77066.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-057c14a7b87f9b7beda558e34f75f6b8.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-00e6963b44a714894d16b37492c972e1.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d0796692f66ff58ea127b82f5711bf19.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-7676642074a4bb3e44d5abf80728104c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-80a24dbac7b953ff7aacba1b0d035bd9.jpg" align="middle">
</details>


<h1 id="-16"><a href="#-16" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2024-12-25/3DGS/">https://kedreamix.github.io/Talk2Paper/Paper/2024-12-25/3DGS/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/3DGS/">
                                    <span class="chip bg-color">3DGS</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2024-12-25/NeRF/">
                    <div class="card-image">
                        
                        <img src="https://pic1.zhimg.com/v2-707173a3a7fc763b3069420ce0526011.jpg" class="responsive-img" alt="NeRF">
                        
                        <span class="card-title">NeRF</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            NeRF æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2024-12-25  Editing Implicit and Explicit Representations of Radiance Fields A   Survey
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2024-12-25
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/NeRF/" class="post-category">
                                    NeRF
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/NeRF/">
                        <span class="chip bg-color">NeRF</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2024-12-25/%E5%85%83%E5%AE%87%E5%AE%99_%E8%99%9A%E6%8B%9F%E4%BA%BA/">
                    <div class="card-image">
                        
                        <img src="https://pica.zhimg.com/v2-3769c34386028559346ecacead8ad08c.jpg" class="responsive-img" alt="å…ƒå®‡å®™/è™šæ‹Ÿäºº">
                        
                        <span class="card-title">å…ƒå®‡å®™/è™šæ‹Ÿäºº</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            å…ƒå®‡å®™/è™šæ‹Ÿäºº æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2024-12-25  FADA Fast Diffusion Avatar Synthesis with Mixed-Supervised Multi-CFG   Distillation
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2024-12-25
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/%E5%85%83%E5%AE%87%E5%AE%99-%E8%99%9A%E6%8B%9F%E4%BA%BA/" class="post-category">
                                    å…ƒå®‡å®™/è™šæ‹Ÿäºº
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/%E5%85%83%E5%AE%87%E5%AE%99-%E8%99%9A%E6%8B%9F%E4%BA%BA/">
                        <span class="chip bg-color">å…ƒå®‡å®™/è™šæ‹Ÿäºº</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">29580.4k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
