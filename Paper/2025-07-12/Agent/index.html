<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Agent">
    <meta name="description" content="Agent 方向最新论文已更新，请持续关注 Update in 2025-07-12  MIRIX Multi-Agent Memory System for LLM-Based Agents">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>Agent | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loader页面消失采用渐隐的方式*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logo出现动画 */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//使用渐隐的方法淡出loading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//强制显示loading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">嘘~  正在从服务器偷取页面 . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>首页</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>标签</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>分类</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>归档</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="搜索" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="深色/浅色模式" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			首页
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			标签
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			分类
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			归档
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://pic1.zhimg.com/v2-8e4695ba8c675a41df6074f72e8d36bb.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Agent</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/Agent/">
                                <span class="chip bg-color">Agent</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/Agent/" class="post-category">
                                Agent
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2025-07-12
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>更新日期:&nbsp;&nbsp;
                    2025-08-19
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp;
                    14.5k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp;
                    58 分
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>阅读次数:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>⚠️ 以下所有内容总结都来自于 大语言模型的能力，如有错误，仅供参考，谨慎使用<br>🔴 请注意：千万不要用于严肃的学术场景，只能用于论文阅读前的初筛！<br>💗 如果您觉得我们的项目对您有帮助 <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ，还请您给我们一些鼓励！⭐️ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFace免费体验</a></p>
</blockquote>
<h1 id="2025-07-12-更新"><a href="#2025-07-12-更新" class="headerlink" title="2025-07-12 更新"></a>2025-07-12 更新</h1><h2 id="MIRIX-Multi-Agent-Memory-System-for-LLM-Based-Agents"><a href="#MIRIX-Multi-Agent-Memory-System-for-LLM-Based-Agents" class="headerlink" title="MIRIX: Multi-Agent Memory System for LLM-Based Agents"></a>MIRIX: Multi-Agent Memory System for LLM-Based Agents</h2><p><strong>Authors:Yu Wang, Xi Chen</strong></p>
<p>Although memory capabilities of AI agents are gaining increasing attention, existing solutions remain fundamentally limited. Most rely on flat, narrowly scoped memory components, constraining their ability to personalize, abstract, and reliably recall user-specific information over time. To this end, we introduce MIRIX, a modular, multi-agent memory system that redefines the future of AI memory by solving the field’s most critical challenge: enabling language models to truly remember. Unlike prior approaches, MIRIX transcends text to embrace rich visual and multimodal experiences, making memory genuinely useful in real-world scenarios. MIRIX consists of six distinct, carefully structured memory types: Core, Episodic, Semantic, Procedural, Resource Memory, and Knowledge Vault, coupled with a multi-agent framework that dynamically controls and coordinates updates and retrieval. This design enables agents to persist, reason over, and accurately retrieve diverse, long-term user data at scale. We validate MIRIX in two demanding settings. First, on ScreenshotVQA, a challenging multimodal benchmark comprising nearly 20,000 high-resolution computer screenshots per sequence, requiring deep contextual understanding and where no existing memory systems can be applied, MIRIX achieves 35% higher accuracy than the RAG baseline while reducing storage requirements by 99.9%. Second, on LOCOMO, a long-form conversation benchmark with single-modal textual input, MIRIX attains state-of-the-art performance of 85.4%, far surpassing existing baselines. These results show that MIRIX sets a new performance standard for memory-augmented LLM agents. To allow users to experience our memory system, we provide a packaged application powered by MIRIX. It monitors the screen in real time, builds a personalized memory base, and offers intuitive visualization and secure local storage to ensure privacy. </p>
<blockquote>
<p>尽管人工智能代理的记忆能力日益受到关注，但现有解决方案仍存在根本性局限。大多数依赖平面、范围狭窄的记忆组件，限制了它们随着时间个性化、抽象和可靠回忆用户特定信息的能力。为此，我们引入了MIRIX，这是一个模块化、多代理记忆系统，通过解决该领域最关键的挑战来重新定义AI记忆的未来，即实现语言模型真正的记忆能力。不同于以往的方法，MIRIX超越了文本，拥抱丰富的视觉和多模式体验，使记忆在真实场景中具有真正的实用性。MIRIX由六种独特且精心结构的记忆类型组成：核心记忆、情景记忆、语义记忆、程序记忆、资源记忆和知识宝库，以及一个动态控制和协调更新和检索的多代理框架。这种设计使代理能够大规模持久保存、推理和准确检索多样化的长期用户数据。我们在两个有挑战性的环境中验证了MIRIX的有效性。首先，在ScreenshotVQA上，这是一个包含每序列近2万个高分辨率计算机截图的多模式基准测试，需要深入上下文理解，且现有记忆系统无法应用，MIRIX的准确度比RAG基准高出35%，同时减少存储需求达99.9%。其次，在LOCOMO上，这是一个具有单模态文本输入的长对话基准测试，MIRIX达到了最先进的性能，达到85.4%，远远超出当前基准。这些结果表明，MIRIX为内存增强的大型语言模型代理设定了新的性能标准。为了让用户体验我们的记忆系统，我们提供了一个由MIRIX驱动的应用程序。它实时监控屏幕，建立个性化记忆库，并提供直观可视化和安全本地存储以确保隐私。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2507.07957v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>本文介绍了AI代理的记忆能力虽然受到越来越多的关注，但现有解决方案仍存在根本性限制。为解决此问题，提出了MIRIX这一模块化、多代理记忆系统，它重新定义了AI记忆的未来，解决了该领域最关键的挑战，即让语言模型真正能够记忆。MIRIX超越了文本，拥抱丰富的视觉和多模式体验，使记忆在真实场景中有真正的用处。通过六种不同的记忆类型和多重代理框架的结合，MIRIX使代理能够持久、推理并准确检索大规模、长期的用户数据。在ScreenshotVQA和LOCOMO两个需求高的环境中验证了MIRIX的有效性，其表现超越了现有基线。此外，还提供了由MIRIX驱动的应用程序，可实时监控屏幕、建立个性化记忆库，并提供直观可视化和安全本地存储以确保隐私。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>AI代理的记忆能力虽受关注，但现有解决方案存在根本性限制，主要依赖平坦、范围狭窄的记忆组件。</li>
<li>MIRIX是一个模块化、多代理记忆系统，重新定义了AI记忆的未来。</li>
<li>MIRIX解决了语言模型记忆能力方面的最关键挑战，即让语言模型真正能够记忆。</li>
<li>MIRIX超越文本，结合丰富的视觉和多模式体验，使记忆在真实场景中有用。</li>
<li>MIRIX包含六种不同的记忆类型，通过多代理框架动态控制和协调更新和检索。</li>
<li>MIRIX在ScreenshotVQA和LOCOMO两个环境中表现优越，超越了现有基线。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2507.07957">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-0bf542b4356fc691ab7ef7e1fcdfc516.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e8f9933212e66073dcf5a841f9f38de6.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-008ecc74c82d6d85ef78cea9d2e1e135.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-e37d57a7dc0e3a1add7a98d70058d04b.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="Agentic-Retrieval-of-Topics-and-Insights-from-Earnings-Calls"><a href="#Agentic-Retrieval-of-Topics-and-Insights-from-Earnings-Calls" class="headerlink" title="Agentic Retrieval of Topics and Insights from Earnings Calls"></a>Agentic Retrieval of Topics and Insights from Earnings Calls</h2><p><strong>Authors:Anant Gupta, Rajarshi Bhowmik, Geoffrey Gunow</strong></p>
<p>Tracking the strategic focus of companies through topics in their earnings calls is a key task in financial analysis. However, as industries evolve, traditional topic modeling techniques struggle to dynamically capture emerging topics and their relationships. In this work, we propose an LLM-agent driven approach to discover and retrieve emerging topics from quarterly earnings calls. We propose an LLM-agent to extract topics from documents, structure them into a hierarchical ontology, and establish relationships between new and existing topics through a topic ontology. We demonstrate the use of extracted topics to infer company-level insights and emerging trends over time. We evaluate our approach by measuring ontology coherence, topic evolution accuracy, and its ability to surface emerging financial trends. </p>
<blockquote>
<p>通过跟踪企业收益电话会议中的主题来关注公司的战略重点，是财务分析中的一项关键任务。然而，随着行业的不断发展，传统的主题建模技术很难动态捕捉新兴主题及其关系。在这项工作中，我们提出了一种由大型语言模型（LLM）驱动的方法来发现和检索季度收益电话会议中的新兴主题。我们提议使用一个大型语言模型代理程序从文件中提取主题，将它们结构化为层次化本体，并通过主题本体建立新主题和现有主题之间的关系。我们展示了使用提取的主题来推断公司层面的见解以及随时间发展的新兴趋势。我们通过测量本体一致性、主题演化准确性和发现新兴金融趋势的能力来评估我们的方法。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2507.07906v1">PDF</a> The 2nd Workshop on Financial Information Retrieval in the Era of   Generative AI, The 48th International ACM SIGIR Conference on Research and   Development in Information Retrieval July 13-17, 2025 | Padua, Italy</p>
<p><strong>Summary</strong></p>
<p>本文提出利用LLM-agent从季度财报电话会议中发现和检索新兴话题的方法。该方法能够将话题从文档中抽取出来，构建成层次化的本体结构，并通过话题本体建立新旧话题之间的关系。通过提取的话题，可以推断出公司层面的见解和随时间出现的新兴趋势。本文评估了该方法在语义连贯性、话题演变准确性和捕捉新兴金融趋势方面的能力。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>LLM-agent用于从季度财报电话会议中发现和检索新兴话题。</li>
<li>构建话题的层次化本体结构以描述不同话题之间的关系。</li>
<li>通过提取的话题，可以了解公司层面的见解和随时间出现的新兴趋势。</li>
<li>所提出的方法在语义连贯性、话题演变准确性和捕捉新兴金融趋势方面进行了评估。</li>
<li>传统的话题建模技术在捕捉动态变化的行业中的新兴话题时面临挑战。</li>
<li>LLM-agent能够帮助解决这一挑战，提供对新兴话题的更全面和深入的理解。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2507.07906">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-32ac428b27403e99b117876b2777d043.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-ab2a953e7f240e5d43b1917d4ebd0991.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-0a45f519acfcc92d06a2ee4a4e1714e6.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-2a636d6d3b77830906bffdc531c8dc7f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-6ff0461bf778625c5293910de4155e51.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-90d8fe9fdaae752e550e7b94765c1afb.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-218b9200dde16a40e067c2da9175ca1d.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-189b377dc6fad29783db3245d8670bfa.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="Toward-Real-World-Chinese-Psychological-Support-Dialogues-CPsDD-Dataset-and-a-Co-Evolving-Multi-Agent-System"><a href="#Toward-Real-World-Chinese-Psychological-Support-Dialogues-CPsDD-Dataset-and-a-Co-Evolving-Multi-Agent-System" class="headerlink" title="Toward Real-World Chinese Psychological Support Dialogues: CPsDD Dataset   and a Co-Evolving Multi-Agent System"></a>Toward Real-World Chinese Psychological Support Dialogues: CPsDD Dataset   and a Co-Evolving Multi-Agent System</h2><p><strong>Authors:Yuanchen Shi, Longyin Zhang, Fang Kong</strong></p>
<p>The growing need for psychological support due to increasing pressures has exposed the scarcity of relevant datasets, particularly in non-English languages. To address this, we propose a framework that leverages limited real-world data and expert knowledge to fine-tune two large language models: Dialog Generator and Dialog Modifier. The Generator creates large-scale psychological counseling dialogues based on predefined paths, which guide system response strategies and user interactions, forming the basis for effective support. The Modifier refines these dialogues to align with real-world data quality. Through both automated and manual review, we construct the Chinese Psychological support Dialogue Dataset (CPsDD), containing 68K dialogues across 13 groups, 16 psychological problems, 13 causes, and 12 support focuses. Additionally, we introduce the Comprehensive Agent Dialogue Support System (CADSS), where a Profiler analyzes user characteristics, a Summarizer condenses dialogue history, a Planner selects strategies, and a Supporter generates empathetic responses. The experimental results of the Strategy Prediction and Emotional Support Conversation (ESC) tasks demonstrate that CADSS achieves state-of-the-art performance on both CPsDD and ESConv datasets. </p>
<blockquote>
<p>随着压力的不断增加，对心理支持的需求日益增长，这暴露出了相关数据集，特别是在非英语语境下的稀缺性。为了解决这一问题，我们提出了一个利用有限现实数据和专业知识来调整两个大型语言模型的框架：对话生成器和对话修饰器。生成器基于预定义路径创建大规模心理咨询对话，引导系统响应策略和用户交互，为有效支持奠定基础。修饰器则对这些对话进行改进，以符合现实数据的质量。通过自动和手动审查，我们构建了中文心理支持对话数据集（CPsDD），包含13组、16个心理问题、13个原因和12个支持重点的6.8万条对话。此外，我们还引入了综合代理对话支持系统（CADSS），其中分析器分析用户特征，摘要器浓缩对话历史，规划器选择策略，支持者生成富有同情心的回应。策略和情绪支持对话任务（ESC）的实验结果表明，CADSS在CPsDD和ESConv数据集上均达到了最先进的性能表现。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2507.07509v1">PDF</a> 10pages,8 figures</p>
<p><strong>Summary</strong><br>心理支持需求随着压力增大而不断增长，相关数据集匮乏，特别是在非英语领域。为此，我们提出一个框架，利用有限现实数据和专家知识微调两个大型语言模型：对话生成器和对话修饰器。生成器基于预设路径创建大规模心理咨询对话，引导系统响应策略和用户体验，为有效支持奠定基础。修饰器则完善这些对话以符合现实数据质量。我们构建了中文心理支持对话数据集（CPsDD），包含6.8万条对话，涵盖不同群体、心理问题、原因和支持重点。同时，我们推出综合代理对话支持系统（CADSS），包括分析用户特性的分析器、精简对话历史的概述器、选择策略的计划器以及生成富有同情心回应的支持者。实验结果表明，CADSS在CPsDD和ESConv数据集上实现最先进的性能表现。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>随着压力增加，心理支持需求增长，而非英语领域的心理数据集较为匮乏。</li>
<li>提出的框架结合有限现实数据和专家知识，通过对话生成器和修饰器两个大型语言模型来应对这一挑战。</li>
<li>对话生成器基于预设路径创建心理咨询对话，为有效支持奠定基础。</li>
<li>对话修饰器用于完善对话内容，以符合现实数据质量。</li>
<li>构建了中文心理支持对话数据集（CPsDD），包含丰富的对话样本，覆盖不同群体、心理问题等。</li>
<li>综合代理对话支持系统（CADSS）包括分析用户特性的分析器、概述器、计划器和支持者。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2507.07509">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-4def290a3d4c1540e937a7f1ed969fb9.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-af2f1fc3fbce749855bdafb0ce8b6ff1.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a1e39cd22b17c58eeb49d2f3dffcb649.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-ef26e4869806e50bdbbc97649f6b1773.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-999b2aed19ba40817b043ed7a7181add.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-9bd2f7c062998e2213ad5b8284402e39.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-16d6bd77798695a199e9336619e4342e.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="StarDojo-Benchmarking-Open-Ended-Behaviors-of-Agentic-Multimodal-LLMs-in-Production-Living-Simulations-with-Stardew-Valley"><a href="#StarDojo-Benchmarking-Open-Ended-Behaviors-of-Agentic-Multimodal-LLMs-in-Production-Living-Simulations-with-Stardew-Valley" class="headerlink" title="StarDojo: Benchmarking Open-Ended Behaviors of Agentic Multimodal LLMs   in Production-Living Simulations with Stardew Valley"></a>StarDojo: Benchmarking Open-Ended Behaviors of Agentic Multimodal LLMs   in Production-Living Simulations with Stardew Valley</h2><p><strong>Authors:Weihao Tan, Changjiu Jiang, Yu Duan, Mingcong Lei, Jiageng Li, Yitian Hong, Xinrun Wang, Bo An</strong></p>
<p>Autonomous agents navigating human society must master both production activities and social interactions, yet existing benchmarks rarely evaluate these skills simultaneously. To bridge this gap, we introduce StarDojo, a novel benchmark based on Stardew Valley, designed to assess AI agents in open-ended production-living simulations. In StarDojo, agents are tasked to perform essential livelihood activities such as farming and crafting, while simultaneously engaging in social interactions to establish relationships within a vibrant community. StarDojo features 1,000 meticulously curated tasks across five key domains: farming, crafting, exploration, combat, and social interactions. Additionally, we provide a compact subset of 100 representative tasks for efficient model evaluation. The benchmark offers a unified, user-friendly interface that eliminates the need for keyboard and mouse control, supports all major operating systems, and enables the parallel execution of multiple environment instances, making it particularly well-suited for evaluating the most capable foundation agents, powered by multimodal large language models (MLLMs). Extensive evaluations of state-of-the-art MLLMs agents demonstrate substantial limitations, with the best-performing model, GPT-4.1, achieving only a 12.7% success rate, primarily due to challenges in visual understanding, multimodal reasoning and low-level manipulation. As a user-friendly environment and benchmark, StarDojo aims to facilitate further research towards robust, open-ended agents in complex production-living environments. </p>
<blockquote>
<p>智能代理在人类社会中的导航必须掌握生产活动和社会交互，但现有的基准测试很少同时评估这些技能。为了弥补这一差距，我们推出了StarDojo，这是一个基于星露谷物的新基准测试，旨在评估智能代理在开放式生产生活模拟中的表现。在StarDojo中，代理被要求执行基本的生计活动，如耕作和制作工艺品，同时参与社交互动以建立充满活力的社区内的关系。StarDojo涵盖了五大领域：耕作、制作工艺品、探索、战斗和社交互动，总计精心策划了1000个任务。此外，我们还提供了包含100个代表性任务的紧凑子集，以便高效模型评估。该基准测试提供了一个统一且用户友好的界面，无需使用键盘和鼠标控制，支持所有主要操作系统，并可以并行执行多个环境实例，因此特别适合评估由多模态大型语言模型驱动的最先进智能代理。对最新多模态大型语言模型代理的广泛评估表明存在显著局限性，表现最佳的GPT-4.1模型成功率仅为12.7%，这主要是由于视觉理解、多模态推理和低级操作方面的挑战所致。作为一个用户友好的环境和基准测试平台，StarDojo旨在促进进一步研究，以开发在复杂生产生活环境中具有鲁棒性的开放式智能代理。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2507.07445v1">PDF</a> Project website: <a target="_blank" rel="noopener" href="https://weihaotan.github.io/StarDojo">https://weihaotan.github.io/StarDojo</a></p>
<p><strong>Summary</strong><br>     星界谷基准测试（StarDojo）是一个基于游戏Stardew Valley的新型基准测试，旨在评估人工智能代理在开放生产生活模拟中的表现。它要求代理同时掌握生产活动和社会交互技能。StarDojo包含1000个精心策划的任务，涵盖五个关键领域：农业、工艺、探索、战斗和社会互动。它为模型评估提供了一个紧凑的任务子集，并为用户提供了一个友好的界面。然而，当前最先进的模型在StarDojo中的表现有限，GPT-4.1的成功率仅为12.7%。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>StarDojo是一个基于游戏Stardew Valley的新型基准测试，旨在评估AI代理在模拟生产生活环境中的表现。</li>
<li>它要求代理同时掌握生产活动和社会交互技能，涵盖农业、工艺、探索、战斗和社会互动五个领域。</li>
<li>StarDojo提供了1000个任务以及一个紧凑的任务子集，用于高效模型评估。</li>
<li>用户友好型界面支持所有主要操作系统，并允许并行执行多个环境实例。</li>
<li>当前最先进的模型在StarDojo中的表现有限，GPT-4.1的成功率仅为12.7%，表明存在视觉理解、多模式推理和低级操作方面的挑战。</li>
<li>StarDojo旨在促进对复杂生产生活环境中健壮、开放的人工智能代理的研究。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2507.07445">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-c295a7c0d7f985963568b88bf7772a56.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-1ed1909374620bb0ad439f51ef6ea13f.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-b111ce6a93c45367e9777b31b9466dd3.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-5f2a72c1cac1f8721b3dc2bc5d906071.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-02ff39695d48148ce012872fe44567f0.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="SAND-Boosting-LLM-Agents-with-Self-Taught-Action-Deliberation"><a href="#SAND-Boosting-LLM-Agents-with-Self-Taught-Action-Deliberation" class="headerlink" title="SAND: Boosting LLM Agents with Self-Taught Action Deliberation"></a>SAND: Boosting LLM Agents with Self-Taught Action Deliberation</h2><p><strong>Authors:Yu Xia, Yiran Jenny Shen, Junda Wu, Tong Yu, Sungchul Kim, Ryan A. Rossi, Lina Yao, Julian McAuley</strong></p>
<p>Large Language Model (LLM) agents are commonly tuned with supervised finetuning on ReAct-style expert trajectories or preference optimization over pairwise rollouts. Most of these methods focus on imitating specific expert behaviors or promoting chosen reasoning thoughts and actions over rejected ones. However, without reasoning and comparing over alternatives actions, LLM agents finetuned with these methods may over-commit towards seemingly plausible but suboptimal actions due to limited action space exploration. To address this, in this paper we propose Self-taught ActioN Deliberation (SAND) framework, enabling LLM agents to explicitly deliberate over candidate actions before committing to one. To tackle the challenges of when and what to deliberate given large action space and step-level action evaluation, we incorporate self-consistency action sampling and execution-guided action critique to help synthesize step-wise action deliberation thoughts using the base model of the LLM agent. In an iterative manner, the deliberation trajectories are then used to finetune the LLM agent itself. Evaluating on two representative interactive agent tasks, SAND achieves an average 20% improvement over initial supervised finetuning and also outperforms state-of-the-art agent tuning approaches. </p>
<blockquote>
<p>大型语言模型（LLM）代理通常通过反应式专家轨迹的监督微调或成对推出中的偏好优化来进行调整。这些方法大多侧重于模仿特定专家的行为或促进选择的推理思考和行动，而不是拒绝的行动。然而，如果不理性并比较替代行动，通过这些方法微调的LLM代理可能会因行动空间探索有限而过度承诺看似合理但次优的行动。为了解决这个问题，本文提出了自我教行动审议（SAND）框架，使LLM代理能够在承诺行动之前明确地对候选行动进行审议。为了解决在给定大行动空间和步骤级行动评估时何时审议以及审议什么内容的挑战，我们引入了自我一致性行动采样和执行指导行动评论，帮助利用LLM代理的基础模型合成步骤级行动审议思想。通过迭代的方式，审议轨迹然后用于微调LLM代理本身。在两个具有代表性的交互式代理任务上评估，SAND相较于初始的监督微调平均提高了20%的效果，并且优于最新的代理调整方法。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2507.07441v1">PDF</a> </p>
<p><strong>Summary</strong><br>大型语言模型（LLM）代理通常采用监督微调的方法，模仿专家轨迹或偏好优化配对回放。但这些方法可能使代理过度依赖看似合理但实际是次优的行动。本文提出了自我行动决策（SAND）框架，使LLM代理能够明确地对候选行动进行权衡后再采取行动。通过自我一致性行动采样和执行指导行动评价，合成逐步行动决策思维，使用LLM代理的基础模型。迭代过程中，通过权衡轨迹对LLM代理进行微调。在两项代表性的交互式代理任务上，SAND相较于初始监督微调平均提升了20%，并超越了现有的代理调整方法。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>LLM代理通常通过模仿专家轨迹或优化偏好配对回放来进行监督微调。</li>
<li>这些方法可能导致LLM代理过度依赖看似合理但实际上是次优的行动。</li>
<li>SAND框架使LLM代理能够明确对候选行动进行权衡，从而避免过早承诺次优行动。</li>
<li>SAND通过自我一致性行动采样和执行指导行动评价，合成逐步决策思维。</li>
<li>SAND框架使用LLM代理的基础模型进行迭代调整。</li>
<li>在两项代表性的交互式代理任务上，SAND相较于传统方法取得了显著改进。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2507.07441">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-1a749514e8a7ee0d9a77dba1e720762e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b4845d56cb36fc7e06ed73a5c7024a15.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-9e2d64a0f0424451a1a997b3d87fdd76.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-49145de2e0487f9c94b403d7b7762126.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="Multi-Agent-Retrieval-Augmented-Framework-for-Evidence-Based-Counterspeech-Against-Health-Misinformation"><a href="#Multi-Agent-Retrieval-Augmented-Framework-for-Evidence-Based-Counterspeech-Against-Health-Misinformation" class="headerlink" title="Multi-Agent Retrieval-Augmented Framework for Evidence-Based   Counterspeech Against Health Misinformation"></a>Multi-Agent Retrieval-Augmented Framework for Evidence-Based   Counterspeech Against Health Misinformation</h2><p><strong>Authors:Anirban Saha Anik, Xiaoying Song, Elliott Wang, Bryan Wang, Bengisu Yarimbas, Lingzi Hong</strong></p>
<p>Large language models (LLMs) incorporated with Retrieval-Augmented Generation (RAG) have demonstrated powerful capabilities in generating counterspeech against misinformation. However, current studies rely on limited evidence and offer less control over final outputs. To address these challenges, we propose a Multi-agent Retrieval-Augmented Framework to generate counterspeech against health misinformation, incorporating multiple LLMs to optimize knowledge retrieval, evidence enhancement, and response refinement. Our approach integrates both static and dynamic evidence, ensuring that the generated counterspeech is relevant, well-grounded, and up-to-date. Our method outperforms baseline approaches in politeness, relevance, informativeness, and factual accuracy, demonstrating its effectiveness in generating high-quality counterspeech. To further validate our approach, we conduct ablation studies to verify the necessity of each component in our framework. Furthermore, human evaluations reveal that refinement significantly enhances counterspeech quality and obtains human preference. </p>
<blockquote>
<p>将大型语言模型（LLMs）与检索增强生成（RAG）相结合，已显示出在生成对抗误导信息的反驳言论方面的强大能力。然而，当前的研究依赖于有限的证据，并且最终输出的可控性较低。为了解决这些挑战，我们提出了一种多代理检索增强框架，用于生成对抗健康误导信息的反驳言论，通过结合多个LLMs来优化知识检索、证据增强和响应细化。我们的方法结合了静态和动态证据，确保生成的反驳言论是相关、有根据的，并且是最新的。我们的方法在礼貌、相关性、信息量和事实准确性方面优于基线方法，证明了其在生成高质量反驳言论方面的有效性。为了进一步验证我们的方法，我们进行了剔除研究，以验证我们框架中每个组件的必要性。此外，人类评估表明，细化显著提高了反驳言论的质量，并获得了人类偏好。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2507.07307v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>大型语言模型结合检索增强生成技术，在应对错误信息生成反驳言论方面表现出强大能力。但现有研究证据有限，最终输出控制力较弱。为解决这些问题，我们提出多代理检索增强框架，用于生成针对健康误信息的反驳言论，整合多个大型语言模型，优化知识检索、证据增强和响应优化。该方法整合静态和动态证据，确保生成的反驳言论与事实相关、有事实依据并实时更新。在礼貌、相关性、信息量和事实准确性方面，该方法优于基线方法，证明其在生成高质量反驳言论方面的有效性。通过消融研究验证了框架中每个组件的必要性，人类评估显示进一步优化显著提高了反驳言论的质量并获得了人类偏好。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>大型语言模型结合检索增强生成技术能有效生成针对误信息的反驳言论。</li>
<li>现有研究在证据有限和输出控制方面存在挑战。</li>
<li>提出多代理检索增强框架，整合多个大型语言模型以优化知识检索、证据增强和响应优化。</li>
<li>框架整合静态和动态证据，确保生成的反驳言论与事实相关、有事实依据并实时更新。</li>
<li>该方法在礼貌、相关性、信息量和事实准确性方面优于基线方法。</li>
<li>消融研究验证了框架中每个组件的必要性。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2507.07307">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pica.zhimg.com/v2-f71065a8d9f57575335da9be07f449e5.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-54296732431fb7436455afc0bd7ee62f.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-a6c46f6a233b57f36941a494bb3c1fc1.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="ViDove-A-Translation-Agent-System-with-Multimodal-Context-and-Memory-Augmented-Reasoning"><a href="#ViDove-A-Translation-Agent-System-with-Multimodal-Context-and-Memory-Augmented-Reasoning" class="headerlink" title="ViDove: A Translation Agent System with Multimodal Context and   Memory-Augmented Reasoning"></a>ViDove: A Translation Agent System with Multimodal Context and   Memory-Augmented Reasoning</h2><p><strong>Authors:Yichen Lu, Wei Dai, Jiaen Liu, Ching Wing Kwok, Zongheng Wu, Xudong Xiao, Ao Sun, Sheng Fu, Jianyuan Zhan, Yian Wang, Takatomo Saito, Sicheng Lai</strong></p>
<p>LLM-based translation agents have achieved highly human-like translation results and are capable of handling longer and more complex contexts with greater efficiency. However, they are typically limited to text-only inputs. In this paper, we introduce ViDove, a translation agent system designed for multimodal input. Inspired by the workflow of human translators, ViDove leverages visual and contextual background information to enhance the translation process. Additionally, we integrate a multimodal memory system and long-short term memory modules enriched with domain-specific knowledge, enabling the agent to perform more accurately and adaptively in real-world scenarios. As a result, ViDove achieves significantly higher translation quality in both subtitle generation and general translation tasks, with a 28% improvement in BLEU scores and a 15% improvement in SubER compared to previous state-of-the-art baselines. Moreover, we introduce DoveBench, a new benchmark for long-form automatic video subtitling and translation, featuring 17 hours of high-quality, human-annotated data. Our code is available here: <a target="_blank" rel="noopener" href="https://github.com/pigeonai-org/ViDove">https://github.com/pigeonai-org/ViDove</a> </p>
<blockquote>
<p>基于LLM的翻译代理已经实现了高度人性化的翻译结果，并能够更有效地处理更长、更复杂的上下文。然而，它们通常仅限于文本输入。在本文中，我们介绍了ViDove，一个为多种模式输入设计的翻译代理系统。ViDove受到人类翻译工作流程的启发，利用视觉和上下文背景信息来增强翻译过程。此外，我们整合了多种模式记忆系统和长期短期记忆模块，这些模块融合了特定领域的知识，使代理能够在真实场景中更精确、更自适应地执行。因此，ViDove在字幕生成和一般翻译任务中实现了更高的翻译质量，与之前的最新技术相比，BLEU得分提高了28%，SubER提高了15%。此外，我们还推出了DoveBench，这是一个新的长格式自动视频字幕和翻译的基准测试，包含17小时高质量、经过人工注释的数据。我们的代码可在<a target="_blank" rel="noopener" href="https://github.com/pigeonai-org/ViDove%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/pigeonai-org/ViDove找到。</a></p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2507.07306v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>基于LLM的翻译代理已经实现了高度人性化的翻译结果，并能够在处理更长的复杂上下文时表现出更高的效率。然而，它们通常仅限于文本输入。本文介绍了ViDove，一个为多媒体输入设计的翻译代理系统。ViDove利用视觉和上下文背景信息，激发人类翻译的工作流程，增强翻译过程。此外，我们整合了多媒体内存系统和丰富的领域特定知识的长短时记忆模块，使代理在真实场景中表现得更准确、更适应。因此，ViDove在字幕生成和一般翻译任务中实现了更高的翻译质量，与最新的先进基线相比，BLEU得分提高了28%，SubER提高了15%。我们还引入了DoveBench，这是一个新的长格式自动视频字幕和翻译基准测试，包含17小时高质量、经过人类注释的数据。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>LLM-based translation agents have achieved human-like translation results and can handle complex contexts efficiently.</li>
<li>ViDove系统是一个为多媒体输入设计的翻译代理，融合了视觉和上下文背景信息以提升翻译质量。</li>
<li>ViDove利用多媒体内存系统和长短时记忆模块，结合领域特定知识，提高代理在真实场景中的准确性和适应性。</li>
<li>ViDove在字幕生成和一般翻译任务中表现出更高的翻译质量，相比先进基线有显著的改进。</li>
<li>DoveBench是一个新的长格式自动视频字幕和翻译基准测试，为评估翻译系统的性能提供了新的标准。</li>
<li>ViDove系统公开了源代码，便于进一步的研究和开发。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2507.07306">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-ea1772e954eda01c01d88ab97402d15d.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-39acad041d18f7b3f7dbec0c9be8d199.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-099fdd8e59a02e599a46352ae3a93527.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-26a24c827328e6e1a751f471e80bfc4f.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="Open-Source-Planning-Control-System-with-Language-Agents-for-Autonomous-Scientific-Discovery"><a href="#Open-Source-Planning-Control-System-with-Language-Agents-for-Autonomous-Scientific-Discovery" class="headerlink" title="Open Source Planning &amp; Control System with Language Agents for   Autonomous Scientific Discovery"></a>Open Source Planning &amp; Control System with Language Agents for   Autonomous Scientific Discovery</h2><p><strong>Authors:Licong Xu, Milind Sarkar, Anto I. Lonappan, Íñigo Zubeldia, Pablo Villanueva-Domingo, Santiago Casas, Christian Fidler, Chetana Amancharla, Ujjwal Tiwari, Adrian Bayer, Chadi Ait Ekiou, Miles Cranmer, Adrian Dimitrov, James Fergusson, Kahaan Gandhi, Sven Krippendorf, Andrew Laverick, Julien Lesgourgues, Antony Lewis, Thomas Meier, Blake Sherwin, Kristen Surrao, Francisco Villaescusa-Navarro, Chi Wang, Xueqing Xu, Boris Bolliet</strong></p>
<p>We present a multi-agent system for automation of scientific research tasks, cmbagent. The system is formed by about 30 Large Language Model (LLM) agents and implements a Planning &amp; Control strategy to orchestrate the agentic workflow, with no human-in-the-loop at any point. Each agent specializes in a different task (performing retrieval on scientific papers and codebases, writing code, interpreting results, critiquing the output of other agents) and the system is able to execute code locally. We successfully apply cmbagent to carry out a PhD level cosmology task (the measurement of cosmological parameters using supernova data) and evaluate its performance on two benchmark sets, finding superior performance over state-of-the-art LLMs. The source code is available on GitHub, demonstration videos are also available, and the system is deployed on HuggingFace and will be available on the cloud. </p>
<blockquote>
<p>我们提出一个用于自动化科学研究任务的多智能体系统，名为cmbagent。该系统由大约30个大型语言模型（LLM）智能体组成，采用规划与控制策略来协调智能体的工作流程，整个流程中无需人工参与。每个智能体都专注于不同的任务（如执行科学论文和代码库的检索、编写代码、解释结果、评估其他智能体的输出），并且系统能够在本地执行代码。我们成功地将cmbagent应用于一个博士学位级别的宇宙学任务（使用超新星数据测量宇宙学参数），并在两个基准测试集上评估了其性能，发现其性能优于最新的大型语言模型。源代码可在GitHub上获得，还有演示视频可供参考，该系统已部署在HuggingFace上，并将在云端提供。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2507.07257v1">PDF</a> Accepted contribution to the ICML 2025 Workshop on Machine Learning   for Astrophysics. Code: <a target="_blank" rel="noopener" href="https://github.com/CMBAgents/cmbagent">https://github.com/CMBAgents/cmbagent</a>; Videos:   <a target="_blank" rel="noopener" href="https://www.youtube.com/@cmbagent">https://www.youtube.com/@cmbagent</a>; HuggingFace:   <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/astropilot-ai/cmbagent">https://huggingface.co/spaces/astropilot-ai/cmbagent</a>; Cloud:   <a target="_blank" rel="noopener" href="https://cmbagent.cloud/">https://cmbagent.cloud</a></p>
<p><strong>Summary</strong></p>
<p>该系统是一个用于自动化科研任务的多智能体系统，名为cmbagent。系统由大约30个大型语言模型（LLM）智能体组成，采用计划与控制策略来协调智能体的工作流程，无需人工介入。智能体分别负责不同的任务，如检索科学论文和代码库、编写代码、解读结果、评估其他智能体的输出等。系统可本地执行代码。我们将cmbagent成功应用于执行博士级别的宇宙学任务（使用超新星数据测量宇宙学参数），并在两个基准测试集上评估其性能，发现其性能优于最先进的大型语言模型。源代码已在GitHub上提供，还有演示视频，该系统已部署在HuggingFace上，并将在云端提供。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>cmbagent是一个多智能体系统，用于自动化科研任务。</li>
<li>系统由30个大型语言模型（LLM）智能体组成，无需人工干预。</li>
<li>智能体分别负责不同的任务，如检索、编码、解读和批评。</li>
<li>系统可在本地执行代码。</li>
<li>cmbagent成功完成博士级别的宇宙学任务，并表现出卓越性能。</li>
<li>cmbagent的源代码已公开在GitHub上，还有演示视频可供参考。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2507.07257">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-8819950590cd2463a58fd2b28b61eec8.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-9f2f31b594fbad129469e80447815f92.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-6bb365510d5fd9e59e822406ce69b5d8.jpg" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="The-Dark-Side-of-LLMs-Agent-based-Attacks-for-Complete-Computer-Takeover"><a href="#The-Dark-Side-of-LLMs-Agent-based-Attacks-for-Complete-Computer-Takeover" class="headerlink" title="The Dark Side of LLMs: Agent-based Attacks for Complete Computer   Takeover"></a>The Dark Side of LLMs: Agent-based Attacks for Complete Computer   Takeover</h2><p><strong>Authors:Matteo Lupinacci, Francesco Aurelio Pironti, Francesco Blefari, Francesco Romeo, Luigi Arena, Angelo Furfaro</strong></p>
<p>The rapid adoption of Large Language Model (LLM) agents and multi-agent systems enables unprecedented capabilities in natural language processing and generation. However, these systems have introduced unprecedented security vulnerabilities that extend beyond traditional prompt injection attacks. This paper presents the first comprehensive evaluation of LLM agents as attack vectors capable of achieving complete computer takeover through the exploitation of trust boundaries within agentic AI systems where autonomous entities interact and influence each other. We demonstrate that adversaries can leverage three distinct attack surfaces - direct prompt injection, RAG backdoor attacks, and inter-agent trust exploitation - to coerce popular LLMs (including GPT-4o, Claude-4 and Gemini-2.5) into autonomously installing and executing malware on victim machines. Our evaluation of 17 state-of-the-art LLMs reveals an alarming vulnerability hierarchy: while 41.2% of models succumb to direct prompt injection, 52.9% are vulnerable to RAG backdoor attacks, and a critical 82.4% can be compromised through inter-agent trust exploitation. Notably, we discovered that LLMs which successfully resist direct malicious commands will execute identical payloads when requested by peer agents, revealing a fundamental flaw in current multi-agent security models. Our findings demonstrate that only 5.9% of tested models (1&#x2F;17) proved resistant to all attack vectors, with the majority exhibiting context-dependent security behaviors that create exploitable blind spots. Our findings also highlight the need to increase awareness and research on the security risks of LLMs, showing a paradigm shift in cybersecurity threats, where AI tools themselves become sophisticated attack vectors. </p>
<blockquote>
<p>大型语言模型（LLM）代理的快速采用和多代理系统的出现，为自然语言处理和生成提供了前所未有的能力。然而，这些系统也引入了前所未有的安全漏洞，这些漏洞超出了传统的提示注入攻击的范围。本文首次全面评估了LLM代理作为攻击向量的能力，能够通过利用代理人工智能系统内的信任边界来实现对计算机的完全控制，在这些系统中，自主实体相互交互和影响。我们证明，敌人可以利用三种不同的攻击表面——直接提示注入、RAG后门攻击和代理间信任利用——来迫使流行的LLM（包括GPT-4o、Claude-4和Gemini-2.5）在受害机器上自主安装和执行恶意软件。我们对17款最先进LLM的评估揭示了一个令人警觉的漏洞层次：虽然41.2%的模型会屈服于直接的提示注入，但52.9%的模型容易受到RAG后门攻击，而高达82.4%的模型可以通过代理间的信任利用受到攻击。值得注意的是，我们发现即使LLM成功抵抗了直接的恶意命令，只要同伴代理提出要求，它们就会执行相同的有效载荷，这揭示了当前多代理安全模型中的根本缺陷。我们的研究结果表明，只有5.9%的测试模型（即17个中的1个）能够抵抗所有攻击向量，而大多数模型表现出依赖于上下文的安全行为，这些行为创造了可利用的盲点。我们的研究结果还强调了提高人们对LLM安全风险的意识以及进行相关研究的必要性，这显示了网络安全威胁的转变，即人工智能工具本身成为高级攻击向量。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2507.06850v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>大型语言模型（LLM）和多智能体系统的快速采纳，使得自然语言处理和生成能力得到了前所未有的提升，但同时也引入了前所未有的安全漏洞，这些漏洞超出了传统提示注入攻击的范围。本文首次全面评估了LLM代理作为攻击向量的能力，能够通过利用智能体AI系统内的信任边界，实现计算机系统的完全接管。通过展示三种独特的攻击面——直接提示注入、RAG后门攻击和智能体间信任剥削，我们能够诱导流行的LLM自主地在受害者机器上安装并执行恶意软件。对17款最新LLM的评估揭示了一个令人警觉的漏洞层次结构：尽管有41.2%的模型会屈服于直接的提示注入，但有高达82.4%的模型会通过智能体间的信任剥削受到攻击。尤其值得注意的是，即使LLM成功抵抗直接的恶意命令，当受到同伴智能体的请求时，仍会执行相同的恶意载荷，这揭示了当前多智能体安全模型中的根本缺陷。大部分模型表现出上下文相关的安全行为，创造了可利用的盲点。因此，必须提高人们对LLM安全风险的认识，并加强对相关风险的研究。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>LLM和多智能体系统的快速采纳带来了前所未有的自然语处理与生成能力，但也引入了新的安全漏洞。</li>
<li>LLMs可被用作攻击向量，通过利用信任边界实现计算机系统的完全接管。</li>
<li>存在三种主要的攻击方式：直接提示注入、RAG后门攻击和智能体间信任剥削。</li>
<li>17款最新LLM中有高达82.4%可通过智能体间的信任剥削受到攻击。</li>
<li>即使LLM抵抗直接恶意命令，仍会通过同伴智能体的请求执行恶意载荷，显示多智能体安全模型的根本缺陷。</li>
<li>大部分LLM表现出上下文相关的安全行为，存在可利用的盲点。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2507.06850">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pica.zhimg.com/v2-0f06208d3b4499ee86f914c046f51416.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-fb30ade488ab8d6950b300d12eb2d276.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-3c213c1e3cbfce5771a7ea0c75ac6efe.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-5f56a393a613ad5e63e8b550d39f04ec.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-8392915aa8f538a5a9dac2c1342dfdb7.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-4fb059459b3c503815875a6f49b5360e.jpg" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1><h2 id="GTA1-GUI-Test-time-Scaling-Agent"><a href="#GTA1-GUI-Test-time-Scaling-Agent" class="headerlink" title="GTA1: GUI Test-time Scaling Agent"></a>GTA1: GUI Test-time Scaling Agent</h2><p><strong>Authors:Yan Yang, Dongxu Li, Yutong Dai, Yuhao Yang, Ziyang Luo, Zirui Zhao, Zhiyuan Hu, Junzhe Huang, Amrita Saha, Zeyuan Chen, Ran Xu, Liyuan Pan, Caiming Xiong, Junnan Li</strong></p>
<p>Graphical user interface (GUI) agents autonomously operate across platforms (e.g., Linux) to complete tasks by interacting with visual elements. Specifically, a user instruction is decomposed into a sequence of action proposals, each corresponding to an interaction with the GUI. After each action, the agent observes the updated GUI environment to plan the next step. However, two main challenges arise: i) resolving ambiguity in task planning (i.e., the action proposal sequence), where selecting an appropriate plan is non-trivial, as many valid ones may exist; ii) accurately grounding actions in complex and high-resolution interfaces, i.e., precisely interacting with visual targets.   This paper investigates the two aforementioned challenges with our GUI Test-time Scaling Agent, namely GTA1. First, to select the most appropriate action proposal, we introduce a test-time scaling method. At each step, we sample multiple candidate action proposals and leverage a judge model to evaluate and select the most suitable one. It trades off computation for better decision quality by concurrent sampling, shortening task execution steps, and improving overall performance. Second, we propose a model that achieves improved accuracy when grounding the selected action proposal to its corresponding visual elements. Our key insight is that reinforcement learning (RL) facilitates visual grounding through inherent objective alignments, rewarding successful clicks on interface elements.   Experimentally, our method establishes state-of-the-art performance across diverse benchmarks. For example, GTA1-7B achieves 50.1%, 92.4%, and 67.7% accuracies on Screenspot-Pro, Screenspot-V2, and OSWorld-G, respectively. When paired with a planner applying our test-time scaling strategy, it exhibits state-of-the-art agentic performance (e.g., 45.2% task success rate on OSWorld). We open-source our code and models here. </p>
<blockquote>
<p>图形用户界面（GUI）代理能够跨平台（例如Linux）自主操作，通过与视觉元素交互来完成任务。具体地，用户指令被分解为一系列动作提案，每个提案对应于与GUI的一次交互。每个动作后，代理观察更新的GUI环境以计划下一步。然而，出现了两个主要挑战：i）解决任务规划中的歧义（即动作提案序列），选择合适的计划并不简单，因为可能存在许多有效的计划；ii）在复杂和高分辨率的接口上准确实现动作，即与视觉目标精确交互。</p>
</blockquote>
<p>本文使用我们的GUI测试时间缩放代理，即GTA1，来研究上述两个挑战。首先，为了选择最合适的动作提案，我们引入了一种测试时间缩放方法。在每一步，我们采样多个候选动作提案，并利用评判模型来评估和选择最合适的一个。它通过并发采样、缩短任务执行步骤、提高整体性能来平衡计算与决策质量。其次，我们提出了一种模型，该模型在将所选动作提案与其相应的视觉元素相结合时提高了准确性。我们的关键见解是，强化学习（RL）通过固有的目标对齐来促进视觉定位，奖励成功点击界面元素。</p>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2507.05791v3">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>本文介绍了一种名为GTA1的图形用户界面（GUI）测试时缩放代理。该代理旨在解决两个主要挑战：一是任务规划中的歧义问题，即选择适当的行动方案序列；二是准确地在复杂和高分辨率的接口中进行行动。为解决这两个问题，文章提出了一种测试时缩放方法和一个利用强化学习实现视觉定位准确性的模型。通过实验验证，该方法的性能达到业界最佳水平。同时开源代码和模型以供共享和使用。简而言之，这篇文章研究了通过提升精准决策能力和行动精度解决自主界面任务的技术问题，以此达到人工智能系统更智能的目标。具体方法包括采用测试时缩放策略，提高决策质量；使用强化学习实现精准点击等。其技术成果具有广泛的应用前景和实用价值。车程约谈代码精准判断触发度更专业模型组合优异表达现状发展使用力度精细标注工作流程涵盖建模先进版本逐渐持续检测错误观察文字开发基于最需求需要值得显著思考真实把握提供多样融合拓展突破模式高开发。仅需数行代码便可调用图像类场景展示运行检测所需文件组件所需设置多样化和平台技术内容承载输出表达能力反馈实用可靠兼容多样环境可维护性较好且能够提升用户交互体验以及促进技术领域的拓展与革新。核心思想是通过强化学习解决视觉定位问题，通过测试时缩放策略提高任务执行效率。对现有的模型和方法进行了改进和优化，提高了其性能和实用性。本论文不仅研究目标明确思路清晰设计先进更重要的是为我们提供了更智能的用户界面代理提供了有效的技术解决方案为解决相关问题具有重要的参考价值和实践意义。总的来说这是一个值得关注和研究的课题领域。 </p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>GUI代理面临的主要挑战包括任务规划中的歧义性和在复杂界面中的精准动作定位。</li>
<li>GTA1代理通过测试时缩放方法选择最合适的行动方案，提高了决策质量和任务执行效率。</li>
<li>强化学习被用于提高代理在视觉定位方面的准确性，通过奖励成功的点击来优化界面元素的交互。</li>
<li>GTA1代理在多个基准测试中实现了业界最佳性能，如Screenspot-Pro、Screenspot-V2和OSWorld-G等。</li>
<li>开源代码和模型的共享促进了技术的进一步发展和社区贡献。</li>
<li>该研究为我们提供了更智能的用户界面代理的技术解决方案，具有重要的参考价值和实践意义。</li>
<li>GTA1代理的核心优势在于其强大的决策能力、精准的动作定位以及对复杂界面环境的适应性。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2507.05791">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-7cfd3ef9b8045aaef06a640b2a14aa43.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d16b6068ece5c4e359e36c556d754294.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b98aa080765ce2ec864f1dd5fa8f892f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-efbe691089d62bb6b3e9605080395a6c.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-52ba28ff97cf2dd4086c8a29fe07368c.jpg" align="middle">
</details>


<h1 id="-9"><a href="#-9" class="headerlink" title=""></a></h1><h2 id="Establishing-Best-Practices-for-Building-Rigorous-Agentic-Benchmarks"><a href="#Establishing-Best-Practices-for-Building-Rigorous-Agentic-Benchmarks" class="headerlink" title="Establishing Best Practices for Building Rigorous Agentic Benchmarks"></a>Establishing Best Practices for Building Rigorous Agentic Benchmarks</h2><p><strong>Authors:Yuxuan Zhu, Tengjun Jin, Yada Pruksachatkun, Andy Zhang, Shu Liu, Sasha Cui, Sayash Kapoor, Shayne Longpre, Kevin Meng, Rebecca Weiss, Fazl Barez, Rahul Gupta, Jwala Dhamala, Jacob Merizian, Mario Giulianelli, Harry Coppock, Cozmin Ududec, Jasjeet Sekhon, Jacob Steinhardt, Antony Kellerman, Sarah Schwettmann, Matei Zaharia, Ion Stoica, Percy Liang, Daniel Kang</strong></p>
<p>Benchmarks are essential for quantitatively tracking progress in AI. As AI agents become increasingly capable, researchers and practitioners have introduced agentic benchmarks to evaluate agents on complex, real-world tasks. These benchmarks typically measure agent capabilities by evaluating task outcomes via specific reward designs. However, we show that many agentic benchmarks have issues in task setup or reward design. For example, SWE-bench Verified uses insufficient test cases, while TAU-bench counts empty responses as successful. Such issues can lead to under- or overestimation of agents’ performance by up to 100% in relative terms. To make agentic evaluation rigorous, we introduce the Agentic Benchmark Checklist (ABC), a set of guidelines that we synthesized from our benchmark-building experience, a survey of best practices, and previously reported issues. When applied to CVE-Bench, a benchmark with a particularly complex evaluation design, ABC reduces the performance overestimation by 33%. </p>
<blockquote>
<p>基准测试是跟踪人工智能进步的关键。随着人工智能代理变得越来越强大，研究者和实践者已经引入了代理基准测试来评估代理在复杂现实世界任务中的表现。这些基准测试通常通过特定的奖励设计来评估任务结果，从而衡量代理的能力。然而，我们发现有多个代理基准测试在任务设置或奖励设计方面存在问题。例如，SWE-bench Verified使用的测试用例不足，而TAU-bench将空白的回答算作成功。这些问题可能导致对代理性能的相对高估或低估，最高达100%。为了严谨地评估代理性能，我们引入了代理基准测试清单（ABC），这是一套我们从基准测试构建经验、最佳实践调查和已报告的问题中综合得出的指南。当应用于具有特别复杂评估设计的CVE-Bench时，ABC将性能高估的情况减少了33%。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2507.02825v3">PDF</a> 39 pages, 15 tables, 6 figures</p>
<p><strong>Summary</strong><br>     人工智能的基准测试对于量化跟踪其进步至关重要。随着人工智能代理变得越来越强大，研究人员和实践者已经引入了代理基准测试来评估代理在复杂现实世界任务上的表现。然而，许多代理基准测试在任务设置或奖励设计方面存在问题。为此，我们提出代理基准测试清单（ABC），以指导最佳实践，解决先前存在的问题，减少性能评估中的误差。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>基准测试对于评估人工智能的进步至关重要。</li>
<li>代理基准测试被用来评估人工智能代理在复杂现实世界任务上的表现。</li>
<li>许多现有的代理基准测试在任务设置或奖励设计方面存在问题。</li>
<li>这些问题可能导致对人工智能代理性能的过度或低估。</li>
<li>我们提出了代理基准测试清单（ABC）来解决这些问题。</li>
<li>ABC结合了我们的经验、最佳实践和先前存在的问题。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2507.02825">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-b659a7d21c47c0b240325270974af236.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e5429fedddb3d4aceb2dfb0b3d763b45.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-2f8d87f213032020bca0595566627995.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-8e4695ba8c675a41df6074f72e8d36bb.jpg" align="middle">
</details>


<h1 id="-10"><a href="#-10" class="headerlink" title=""></a></h1><h2 id="MAEBE-Multi-Agent-Emergent-Behavior-Framework"><a href="#MAEBE-Multi-Agent-Emergent-Behavior-Framework" class="headerlink" title="MAEBE: Multi-Agent Emergent Behavior Framework"></a>MAEBE: Multi-Agent Emergent Behavior Framework</h2><p><strong>Authors:Sinem Erisken, Timothy Gothard, Martin Leitgab, Ram Potham</strong></p>
<p>Traditional AI safety evaluations on isolated LLMs are insufficient as multi-agent AI ensembles become prevalent, introducing novel emergent risks. This paper introduces the Multi-Agent Emergent Behavior Evaluation (MAEBE) framework to systematically assess such risks. Using MAEBE with the Greatest Good Benchmark (and a novel double-inversion question technique), we demonstrate that: (1) LLM moral preferences, particularly for Instrumental Harm, are surprisingly brittle and shift significantly with question framing, both in single agents and ensembles. (2) The moral reasoning of LLM ensembles is not directly predictable from isolated agent behavior due to emergent group dynamics. (3) Specifically, ensembles exhibit phenomena like peer pressure influencing convergence, even when guided by a supervisor, highlighting distinct safety and alignment challenges. Our findings underscore the necessity of evaluating AI systems in their interactive, multi-agent contexts. </p>
<blockquote>
<p>随着多智能体AI集群的普及，传统的针对孤立大型语言模型（LLM）的AI安全评估已不足以应对新兴风险。本文介绍了多智能体新兴行为评估（MAEBE）框架，以系统地评估这些风险。使用MAEBE与最大利益基准（以及一种新型双重反转问题技术），我们证明了以下几点：（1）LLM的道德偏好，特别是对工具性伤害的偏好，在单一智能体和集群中都令人惊讶地脆弱，并会随着问题的框架而显著改变。（2）由于新兴群体动力学的影响，LLM集群的道德推理不可直接从孤立智能体的行为预测。（3）特别是，即使受到监督者的引导，集群也会表现出诸如同伴压力影响收敛的现象，这突显了独特的安全和对齐挑战。我们的研究结果表明，在交互式多智能体的背景下评估AI系统是必要的。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.03053v2">PDF</a> Preprint. This work has been submitted to the Multi-Agent Systems   Workshop at ICML 2025 for review</p>
<p><strong>Summary</strong><br>     随着多智能体AI集群的普及，传统的孤立大型语言模型（LLM）的AI安全评估已不足以应对新型出现的风险。本文引入了多智能体新兴行为评估（MAEBE）框架，以系统地评估此类风险。利用MAEBE与最大利益基准（结合新型双重反转问题技术），我们发现：LLM的道德偏好，尤其在工具性伤害方面，在问题设定上表现出惊人的脆弱性，并在单一智能体和集群中发生显著变化；由于新兴群体动态，无法直接从孤立智能体的行为预测集群的道德推理；特别是，即使在监督者的引导下，群体压力影响收敛现象依然存在，这突显出交互式多智能体环境下的AI系统评估的必要性。本文揭示了重新思考和开发新的AI评估和调试技术的重要性。这些技术不仅需要能够解释复杂的智能体行为，还需要模拟可能的安全风险场景来系统地进行多智能体风险评估和应对准备。多智能体环境中的智能体动态研究应该超越分析单一智能体的行为，更多地关注智能体之间的交互和新兴行为。此外，还需要进一步探索如何有效指导智能体在复杂环境中进行决策和应对挑战的策略和方法。这不仅是一个巨大的挑战，也是未来人工智能研究的重要方向之一。评估这些系统不仅是为了了解它们单独的表现，也是为了理解它们作为一个整体如何共同行动并可能出现何种意外的风险。在将来的AI发展中需要跨领域合作并共同努力进行此类评估和验证工作以实现安全和负责任的人工智能开发。这为构建未来安全的AI系统提供了新的视角和启示。传统的AI安全评估已不足以应对新兴的多智能体AI集群带来的风险和挑战。因此，需要跨领域合作并共同努力进行系统性的评估和验证工作以实现安全可控的人工智能技术并防范可能出现的未知风险和问题。<strong>Key Takeaways</strong></p>
<pre><code> 1. 多智能体AI集群的出现导致传统的AI安全评估方法不足以应对新型出现的风险。
 2. 引入Multi-Agent Emergent Behavior Evaluation (MAEBE)框架来评估多智能体AI集群的风险。
 3. LLM的道德偏好在问题设定上表现出脆弱性，并在单一智能体和集群中显著变化。
 4. 集群的智能体道德推理无法直接从孤立智能体的行为预测。
 5. 群体压力影响收敛现象存在于多智能体环境中，突显评估的必要性。
 6. 需要重新思考和开发新的AI评估和调试技术以适应多智能体环境。
</code></pre>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.03053">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-985ef77aa7e54153dc98226b2881a214.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-7abe03e310510ceccb7147cb8c38d241.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-6185d95ead3f29e99e0b4dfbd268fb45.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-3d5b2d6dc2cf33f105eb5c83cb37652a.jpg" align="middle">
</details>


<h1 id="-11"><a href="#-11" class="headerlink" title=""></a></h1><h2 id="Evaluating-LLM-Agent-Adherence-to-Hierarchical-Safety-Principles-A-Lightweight-Benchmark-for-Probing-Foundational-Controllability-Components"><a href="#Evaluating-LLM-Agent-Adherence-to-Hierarchical-Safety-Principles-A-Lightweight-Benchmark-for-Probing-Foundational-Controllability-Components" class="headerlink" title="Evaluating LLM Agent Adherence to Hierarchical Safety Principles: A   Lightweight Benchmark for Probing Foundational Controllability Components"></a>Evaluating LLM Agent Adherence to Hierarchical Safety Principles: A   Lightweight Benchmark for Probing Foundational Controllability Components</h2><p><strong>Authors:Ram Potham</strong></p>
<p>Credible safety plans for advanced AI development require methods to verify agent behavior and detect potential control deficiencies early. A fundamental aspect is ensuring agents adhere to safety-critical principles, especially when these conflict with operational goals. This paper introduces a lightweight, interpretable benchmark to evaluate an LLM agent’s ability to uphold a high-level safety principle when faced with conflicting task instructions. Our evaluation of six LLMs reveals two primary findings: (1) a quantifiable “cost of compliance” where safety constraints degrade task performance even when compliant solutions exist, and (2) an “illusion of compliance” where high adherence often masks task incompetence rather than principled choice. These findings provide initial evidence that while LLMs can be influenced by hierarchical directives, current approaches lack the consistency required for reliable safety governance. </p>
<blockquote>
<p>可信的安全计划对于先进的人工智能发展至关重要，这需要方法来验证代理行为并尽早检测潜在的控制缺陷。一个基本方面是确保代理遵守安全关键原则，尤其是在与安全目标相冲突时。本文介绍了一种轻便、可解释的基准测试，以评估大型语言模型代理在面临相互冲突的任务指令时，坚持高级安全原则的能力。我们对六个大型语言模型的评估得出了两个主要发现：（1）可量化的“合规成本”，即安全约束会降低任务性能，即使存在合规解决方案；（2）“合规假象”，即高度的合规性往往掩盖了任务无能，而非基于原则的选择。这些发现初步表明，虽然大型语言模型可以受到层次指令的影响，但当前的方法缺乏可靠安全治理所需的一致性。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.02357v2">PDF</a> Preprint. This work has been submitted to the Technical AI Governance   Workshop at ICML 2025 for review</p>
<p><strong>Summary</strong><br>     本文介绍了一种评估大型语言模型（LLM）代理在面临冲突任务指令时能否遵守高级安全原则的可解释性基准。研究发现，安全约束可能会降低任务性能，即使存在合规解决方案；同时，高合规性可能掩盖任务无能而非基于原则的选择。</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>先进AI的安全计划需要验证代理行为并早期检测潜在的控制缺陷。</li>
<li>保证代理遵守安全关键原则至关重要，尤其在与安全目标冲突时。</li>
<li>引入了一种可解释的基准来评估LLM代理在面临冲突时的安全原则遵守能力。</li>
<li>安全约束可能会降低任务性能，即使存在合规解决方案，这被称为“合规的成本”。</li>
<li>高合规性可能掩盖任务无能而非基于原则的选择，这种现象被称为“合规的假象”。</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.02357">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-9cac816285d0a762f6b9e4f31deb334e.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-448bc99e1be6e30ff727fc853f0a0ee3.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-8dcf3005dc5ac6e94fa6cfd76b4e9c8e.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-ddaee0d33fb84b31221492c017b6735c.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-c1af790c025ab526004afed972de0332.jpg" align="middle">
</details>


<h1 id="-12"><a href="#-12" class="headerlink" title=""></a></h1><h2 id="Task-Assignment-and-Exploration-Optimization-for-Low-Altitude-UAV-Rescue-via-Generative-AI-Enhanced-Multi-agent-Reinforcement-Learning"><a href="#Task-Assignment-and-Exploration-Optimization-for-Low-Altitude-UAV-Rescue-via-Generative-AI-Enhanced-Multi-agent-Reinforcement-Learning" class="headerlink" title="Task Assignment and Exploration Optimization for Low Altitude UAV Rescue   via Generative AI Enhanced Multi-agent Reinforcement Learning"></a>Task Assignment and Exploration Optimization for Low Altitude UAV Rescue   via Generative AI Enhanced Multi-agent Reinforcement Learning</h2><p><strong>Authors:Xin Tang, Qian Chen, Wenjie Weng, Chao Jin, Zhang Liu, Jiacheng Wang, Geng Sun, Xiaohuan Li, Dusit Niyato</strong></p>
<p>The integration of emerging uncrewed aerial vehicles (UAVs) with artificial intelligence (AI) and ground-embedded robots (GERs) has transformed emergency rescue operations in unknown environments. However, the high computational demands often exceed a single UAV’s capacity, making it difficult to continuously provide stable high-level services. To address this, this paper proposes a cooperation framework involving UAVs, GERs, and airships. The framework enables resource pooling through UAV-to-GER (U2G) and UAV-to-airship (U2A) links, offering computing services for offloaded tasks. Specifically, we formulate the multi-objective problem of task assignment and exploration as a dynamic long-term optimization problem aiming to minimize task completion time and energy use while ensuring stability. Using Lyapunov optimization, we transform it into a per-slot deterministic problem and propose HG-MADDPG, which combines the Hungarian algorithm with a GDM-based multi-agent deep deterministic policy gradient. Simulations demonstrate significant improvements in offloading efficiency, latency, and system stability over baselines. </p>
<blockquote>
<p>新兴的无人机（UAV）与人工智能（AI）和地面嵌入式机器人（GER）的融合，已经转变了未知环境下的紧急救援行动。然而，高计算需求通常超出单个无人机的能力，难以持续提供稳定的高级服务。为了解决这一问题，本文提出了一个涉及无人机、地面嵌入式机器人和飞艇的合作框架。该框架通过无人机与地面嵌入式机器人（U2G）和无人机与飞艇（U2A）之间的链接，实现资源池化，为卸载的任务提供计算服务。具体来说，我们将任务分配和探索的多目标问题制定为一个动态长期优化问题，旨在最小化任务完成时间和能源消耗，同时确保稳定性。我们使用Lyapunov优化将其转化为每个时隙的确定性问题，并提出HG-MADDPG，它将匈牙利算法与基于GDM的多智能体深度确定性策略梯度相结合。模拟结果表明，与基线相比，在卸载效率、延迟和系统稳定性方面都有显著提高。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2504.13554v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>新兴无人航空器（UAVs）、人工智能（AI）与地面嵌入式机器人（GERs）的融合推动了未知环境下的紧急救援行动变革。然而，高计算需求常超出单一UAV的处理能力，难以持续提供稳定的高级服务。为应对此问题，本文提出一个涵盖UAVs、GERs和气浮船的合作框架，通过UAV-to-GER（U2G）和UAV-to-airship（U2A）链接实现资源池化，为卸载的任务提供计算服务。我们制定了一个动态长期优化问题，旨在最小化任务完成时间和能耗，同时保证稳定性。结合李雅普诺夫优化，我们将其转化为每槽确定性问题，并提出HG-MADDPG，它将匈牙利算法与基于GDM的多智能体深度确定性策略梯度相结合。模拟结果显示，相较于基线，HG-MADDPG在卸载效率、延迟和系统稳定性方面均有显著改善。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>新兴无人航空器、人工智能和地面嵌入式机器人的结合推动了紧急救援操作的创新。</li>
<li>高计算需求超出单一无人航空器的处理能力，需要新的解决方案。</li>
<li>提出一个涵盖UAVs、GERs和气浮船的合作框架，实现资源池化，为卸载的任务提供计算服务。</li>
<li>将多目标任务分配和探索问题制定为动态长期优化问题，旨在最小化任务完成时间和能耗。</li>
<li>利用李雅普诺夫优化将问题转化为每槽确定性问题。</li>
<li>提出HG-MADDPG算法，结合匈牙利算法和基于GDM的多智能体深度确定性策略梯度。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2504.13554">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-881f558974adf9f3303c9831a6d88979.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-92236f187d789fc3356f4b9b59c3454f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-0233faeddc95a1aa0e267592bad0b7ca.jpg" align="middle">
</details>


<h1 id="-13"><a href="#-13" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        文章作者:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        文章链接:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-07-12/Agent/">https://kedreamix.github.io/Talk2Paper/Paper/2025-07-12/Agent/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        版权声明:
                    </i>
                </span>
                <span class="reprint-info">
                    本博客所有文章除特別声明外，均采用
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    许可协议。转载请注明来源
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/Agent/">
                                    <span class="chip bg-color">Agent</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;上一篇</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-07-12/Few-Shot/">
                    <div class="card-image">
                        
                        <img src="https://pic1.zhimg.com/v2-8ba91514f3a7eff3c529ac15fa41b684.jpg" class="responsive-img" alt="Few-Shot">
                        
                        <span class="card-title">Few-Shot</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Few-Shot 方向最新论文已更新，请持续关注 Update in 2025-07-12  Doodle Your Keypoints Sketch-Based Few-Shot Keypoint Detection
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-07-12
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Few-Shot/" class="post-category">
                                    Few-Shot
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Few-Shot/">
                        <span class="chip bg-color">Few-Shot</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-07-12/LLM/">
                    <div class="card-image">
                        
                        <img src="https://pic1.zhimg.com/v2-761089c4b6a6698f306d441b68c0664e.jpg" class="responsive-img" alt="LLM">
                        
                        <span class="card-title">LLM</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            LLM 方向最新论文已更新，请持续关注 Update in 2025-07-12  Multi-Granular Spatio-Temporal Token Merging for Training-Free   Acceleration of Video LLMs
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-07-12
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/LLM/" class="post-category">
                                    LLM
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/LLM/">
                        <span class="chip bg-color">LLM</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- 代码语言 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span
                        class="white-color">30191.9k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- 运行天数提醒. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // 区分是否有年份.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = '本站已运行 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                daysTip = '本站已運行 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = '本站已运行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = '本站已運行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="关注我的知乎: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">知</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- 白天和黑夜主题 -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // 只在桌面版网页启用特效
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- 雪花特效 -->
    

    <!-- 鼠标星星特效 -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--腾讯兔小巢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- 动态标签 -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Σ(っ °Д °;)っ诶，页面崩溃了嘛？", clearTimeout(st)) : (document.title = "φ(゜▽゜*)♪咦，又好了！", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
