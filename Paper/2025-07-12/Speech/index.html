<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Speech">
    <meta name="description" content="Speech æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-07-12  Edge-ASR Towards Low-Bit Quantization of Automatic Speech Recognition   Models">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>Speech | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://pic1.zhimg.com/v2-ae2f4e86851fece17070a92ed39cb4cd.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Speech</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/Speech/">
                                <span class="chip bg-color">Speech</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/Speech/" class="post-category">
                                Speech
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-07-12
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-08-09
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    7.3k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    29 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-07-12-æ›´æ–°"><a href="#2025-07-12-æ›´æ–°" class="headerlink" title="2025-07-12 æ›´æ–°"></a>2025-07-12 æ›´æ–°</h1><h2 id="Edge-ASR-Towards-Low-Bit-Quantization-of-Automatic-Speech-Recognition-Models"><a href="#Edge-ASR-Towards-Low-Bit-Quantization-of-Automatic-Speech-Recognition-Models" class="headerlink" title="Edge-ASR: Towards Low-Bit Quantization of Automatic Speech Recognition   Models"></a>Edge-ASR: Towards Low-Bit Quantization of Automatic Speech Recognition   Models</h2><p><strong>Authors:Chen Feng, Yicheng Lin, Shaojie Zhuo, Chenzheng Su, Ramchalam Kinattinkara Ramakrishnan, Zhaocong Yuan, Xiaopeng Zhang</strong></p>
<p>Recent advances in Automatic Speech Recognition (ASR) have demonstrated remarkable accuracy and robustness in diverse audio applications, such as live transcription and voice command processing. However, deploying these models on resource constrained edge devices (e.g., IoT device, wearables) still presents substantial challenges due to strict limits on memory, compute and power. Quantization, particularly Post-Training Quantization (PTQ), offers an effective way to reduce model size and inference cost without retraining. Despite its importance, the performance implications of various advanced quantization methods and bit-width configurations on ASR models remain unclear. In this work, we present a comprehensive benchmark of eight state-of-the-art (SOTA) PTQ methods applied to two leading edge-ASR model families, Whisper and Moonshine. We systematically evaluate model performances (i.e., accuracy, memory I&#x2F;O and bit operations) across seven diverse datasets from the open ASR leaderboard, analyzing the impact of quantization and various configurations on both weights and activations. Built on an extension of the LLM compression toolkit, our framework integrates edge-ASR models, diverse advanced quantization algorithms, a unified calibration and evaluation data pipeline, and detailed analysis tools. Our results characterize the trade-offs between efficiency and accuracy, demonstrating that even 3-bit quantization can succeed on high capacity models when using advanced PTQ techniques. These findings provide valuable insights for optimizing ASR models on low-power, always-on edge devices. </p>
<blockquote>
<p>æœ€è¿‘ï¼Œè‡ªåŠ¨è¯­éŸ³è¯†åˆ«ï¼ˆASRï¼‰æŠ€æœ¯çš„è¿›å±•åœ¨å„ç§éŸ³é¢‘åº”ç”¨ï¼ˆå¦‚å®æ—¶è½¬å½•å’Œè¯­éŸ³å‘½ä»¤å¤„ç†ï¼‰ä¸­è¡¨ç°å‡ºäº†ä»¤äººå°è±¡æ·±åˆ»çš„å‡†ç¡®æ€§å’Œç¨³å¥æ€§ã€‚ç„¶è€Œï¼Œå°†è¿™äº›æ¨¡å‹éƒ¨ç½²åœ¨èµ„æºå—é™çš„è¾¹ç¼˜è®¾å¤‡ï¼ˆä¾‹å¦‚ç‰©è”ç½‘è®¾å¤‡å’Œå¯ç©¿æˆ´è®¾å¤‡ï¼‰ä¸Šä»ç„¶é¢ä¸´å·¨å¤§æŒ‘æˆ˜ï¼Œè¿™ä¸»è¦æ˜¯å› ä¸ºå†…å­˜ã€è®¡ç®—å’Œç”µæºæ–¹é¢çš„ä¸¥æ ¼é™åˆ¶ã€‚é‡åŒ–ï¼Œå°¤å…¶æ˜¯è®­ç»ƒåé‡åŒ–ï¼ˆPTQï¼‰ï¼Œæä¾›äº†ä¸€ç§æœ‰æ•ˆçš„æ–¹å¼æ¥å‡å°‘æ¨¡å‹å¤§å°å’Œæ¨ç†æˆæœ¬è€Œæ— éœ€é‡æ–°è®­ç»ƒã€‚å°½ç®¡å…¶é‡è¦æ€§ä¸è¨€è€Œå–»ï¼Œä½†å„ç§å…ˆè¿›çš„é‡åŒ–æ–¹æ³•å’Œä½å®½é…ç½®å¯¹ASRæ¨¡å‹æ€§èƒ½çš„å½±å“ä»ä¸æ¸…æ¥šã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬å¯¹åº”ç”¨äºä¸¤ä¸ªå‰æ²¿è¾¹ç¼˜ASRæ¨¡å‹å®¶æ—Whisperå’ŒMoonshineçš„å…«ç§æœ€å…ˆè¿›çš„PTQæ–¹æ³•è¿›è¡Œäº†å…¨é¢åŸºå‡†æµ‹è¯•ã€‚æˆ‘ä»¬ç³»ç»Ÿåœ°è¯„ä¼°äº†æ¨¡å‹åœ¨ä¸ƒä¸ªå…¬å¼€ASRæ’è¡Œæ¦œæ•°æ®é›†ä¸Šçš„æ€§èƒ½ï¼ˆå³å‡†ç¡®æ€§ã€å†…å­˜è¾“å…¥&#x2F;è¾“å‡ºå’Œä½æ“ä½œï¼‰ï¼Œåˆ†æäº†é‡åŒ–å’Œå„ç§é…ç½®å¯¹æƒé‡å’Œæ¿€æ´»çš„å½±å“ã€‚æˆ‘ä»¬çš„æ¡†æ¶åŸºäºLLMå‹ç¼©å·¥å…·åŒ…çš„æ‰©å±•ï¼Œé›†æˆäº†è¾¹ç¼˜ASRæ¨¡å‹ã€å„ç§å…ˆè¿›é‡åŒ–ç®—æ³•ã€ç»Ÿä¸€çš„æ ¡å‡†å’Œè¯„ä»·æ•°æ®ç®¡é“ä»¥åŠè¯¦ç»†çš„åˆ†æå·¥å…·ã€‚æˆ‘ä»¬çš„ç»“æœæè¿°äº†æ•ˆç‡å’Œå‡†ç¡®æ€§ä¹‹é—´çš„æƒè¡¡ï¼Œè¡¨æ˜åœ¨ä½¿ç”¨å…ˆè¿›çš„PTQæŠ€æœ¯æ—¶ï¼Œå³ä½¿3ä½é‡åŒ–ä¹Ÿå¯ä»¥åœ¨é«˜æ€§èƒ½æ¨¡å‹ä¸­å–å¾—æˆåŠŸã€‚è¿™äº›å‘ç°å¯¹äºåœ¨ä½åŠŸè€—ã€å§‹ç»ˆå¼€å¯çš„è¾¹ç¼˜è®¾å¤‡ä¸Šä¼˜åŒ–ASRæ¨¡å‹æä¾›äº†å®è´µçš„è§è§£ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2507.07877v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ç ”ç©¶äº†è‡ªåŠ¨è¯­éŸ³è¯†åˆ«ï¼ˆASRï¼‰æ¨¡å‹åœ¨è¾¹ç¼˜è®¾å¤‡ä¸Šçš„éƒ¨ç½²æŒ‘æˆ˜ï¼Œç‰¹åˆ«æ˜¯èµ„æºå—é™çš„è®¾å¤‡ã€‚æ–‡ç« å¯¹ä¸¤ç§é¢†å…ˆçš„è¾¹ç¼˜ASRæ¨¡å‹å®¶æ—â€”â€”Whisperå’ŒMoonshineï¼Œåº”ç”¨äº†å…«ç§æœ€å…ˆè¿›çš„PTQï¼ˆåè®­ç»ƒé‡åŒ–ï¼‰æ–¹æ³•ï¼Œå¹¶åœ¨ä¸ƒä¸ªå…¬å¼€ASRæ’è¡Œæ¦œæ•°æ®é›†ä¸Šè¿›è¡Œäº†ç³»ç»Ÿè¯„ä¼°ã€‚ç ”ç©¶ç»“æœè¡¨æ˜ï¼Œä½¿ç”¨å…ˆè¿›çš„PTQæŠ€æœ¯ï¼Œç”šè‡³3ä½é‡åŒ–ä¹Ÿå¯åœ¨é«˜å®¹é‡æ¨¡å‹ä¸Šå–å¾—æˆåŠŸã€‚è¿™ä¸ºåœ¨ä½åŠŸè€—ã€å§‹ç»ˆå¼€å¯çš„è¾¹ç¼˜è®¾å¤‡ä¸Šä¼˜åŒ–ASRæ¨¡å‹æä¾›äº†å®è´µè§è§£ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æœ€è¿‘ASRæŠ€æœ¯çš„è¿›å±•åœ¨å„ç§éŸ³é¢‘åº”ç”¨ä¸­è¡¨ç°å‡ºæƒŠäººçš„å‡†ç¡®æ€§å’Œç¨³å¥æ€§ã€‚</li>
<li>åœ¨èµ„æºå—é™çš„è¾¹ç¼˜è®¾å¤‡ä¸Šéƒ¨ç½²ASRæ¨¡å‹ä»å­˜åœ¨æŒ‘æˆ˜ï¼Œå¦‚å†…å­˜ã€è®¡ç®—å’Œç”µåŠ›é™åˆ¶ã€‚</li>
<li>åè®­ç»ƒé‡åŒ–ï¼ˆPTQï¼‰æ˜¯å‡å°‘æ¨¡å‹å¤§å°å’Œæ¨ç†æˆæœ¬çš„æœ‰æ•ˆæ–¹æ³•ã€‚</li>
<li>æ–‡ç« å¯¹ä¸¤ç§è¾¹ç¼˜ASRæ¨¡å‹å®¶æ—åº”ç”¨äº†å…«ç§æœ€å…ˆè¿›çš„PTQæ–¹æ³•ï¼Œå¹¶åœ¨ä¸ƒä¸ªæ•°æ®é›†ä¸Šè¿›è¡Œäº†è¯„ä¼°ã€‚</li>
<li>ç ”ç©¶å‘ç°ï¼Œä½¿ç”¨å…ˆè¿›çš„PTQæŠ€æœ¯ï¼Œç”šè‡³3ä½é‡åŒ–ä¹Ÿå¯åœ¨é«˜å®¹é‡æ¨¡å‹ä¸Šå®ç°è‰¯å¥½æ€§èƒ½ã€‚</li>
<li>æ–‡ç« æä¾›äº†ä¸€ä¸ªæ¡†æ¶ï¼Œæ•´åˆäº†è¾¹ç¼˜ASRæ¨¡å‹ã€å„ç§å…ˆè¿›é‡åŒ–ç®—æ³•ã€ç»Ÿä¸€çš„æ ¡å‡†å’Œè¯„ä»·æ•°æ®ç®¡é“ä»¥åŠè¯¦ç»†çš„åˆ†æå·¥å…·ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2507.07877">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-9153cbb118f236d3186270846defcba6.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-0749006f5e05809c517af069de198cf9.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-1e75300f6a64ef230f4b74b9297b8985.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f77eb6f7c78f97b3db046f96e514def7.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-da90195f974760fc52f7d6279f6d85bd.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-f7e6446ea1ed1ad1783c9c1906def3a6.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-f04140017f1979953c06d3a58bba3cb6.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="End-to-end-Acoustic-linguistic-Emotion-and-Intent-Recognition-Enhanced-by-Semi-supervised-Learning"><a href="#End-to-end-Acoustic-linguistic-Emotion-and-Intent-Recognition-Enhanced-by-Semi-supervised-Learning" class="headerlink" title="End-to-end Acoustic-linguistic Emotion and Intent Recognition Enhanced   by Semi-supervised Learning"></a>End-to-end Acoustic-linguistic Emotion and Intent Recognition Enhanced   by Semi-supervised Learning</h2><p><strong>Authors:Zhao Ren, Rathi Adarshi Rammohan, Kevin Scheck, Sheng Li, Tanja Schultz</strong></p>
<p>Emotion and intent recognition from speech is essential and has been widely investigated in human-computer interaction. The rapid development of social media platforms, chatbots, and other technologies has led to a large volume of speech data streaming from users. Nevertheless, annotating such data manually is expensive, making it challenging to train machine learning models for recognition purposes. To this end, we propose applying semi-supervised learning to incorporate a large scale of unlabelled data alongside a relatively smaller set of labelled data. We train end-to-end acoustic and linguistic models, each employing multi-task learning for emotion and intent recognition. Two semi-supervised learning approaches, including fix-match learning and full-match learning, are compared. The experimental results demonstrate that the semi-supervised learning approaches improve model performance in speech emotion and intent recognition from both acoustic and text data. The late fusion of the best models outperforms the acoustic and text baselines by joint recognition balance metrics of 12.3% and 10.4%, respectively. </p>
<blockquote>
<p>è¯­éŸ³ä¸­çš„æƒ…æ„Ÿå’Œæ„å›¾è¯†åˆ«å¯¹äºäººæœºäº¤äº’è‡³å…³é‡è¦ï¼Œå¹¶å·²å¾—åˆ°å¹¿æ³›ç ”ç©¶ã€‚ç¤¾äº¤åª’ä½“å¹³å°ã€èŠå¤©æœºå™¨äººç­‰æŠ€æœ¯çš„å¿«é€Ÿå‘å±•å¯¼è‡´äº†å¤§é‡ç”¨æˆ·è¯­éŸ³æ•°æ®çš„æµã€‚ç„¶è€Œï¼Œæ‰‹åŠ¨æ ‡æ³¨è¿™äº›æ•°æ®æˆæœ¬é«˜æ˜‚ï¼Œä¸ºè®­ç»ƒç”¨äºè¯†åˆ«ç›®çš„çš„æœºå™¨å­¦ä¹ æ¨¡å‹å¸¦æ¥äº†æŒ‘æˆ˜ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬æå‡ºäº†åº”ç”¨åŠç›‘ç£å­¦ä¹ ï¼Œå°†å¤§è§„æ¨¡æœªæ ‡è®°æ•°æ®ä¸ç›¸å¯¹è¾ƒå°çš„æ ‡è®°æ•°æ®é›†åˆç»“åˆèµ·æ¥ã€‚æˆ‘ä»¬è®­ç»ƒç«¯åˆ°ç«¯çš„å£°å­¦æ¨¡å‹å’Œè¯­è¨€å­¦æ¨¡å‹ï¼Œæ¯ä¸ªæ¨¡å‹éƒ½é‡‡ç”¨å¤šä»»åŠ¡å­¦ä¹ è¿›è¡Œæƒ…æ„Ÿå’Œæ„å›¾è¯†åˆ«ã€‚å¯¹æ¯”äº†åŒ…æ‹¬å›ºå®šåŒ¹é…å­¦ä¹ å’Œå…¨åŒ¹é…å­¦ä¹ åœ¨å†…çš„ä¸¤ç§åŠç›‘ç£å­¦ä¹ æ–¹æ³•ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒåŠç›‘ç£å­¦ä¹ æ–¹æ³•åœ¨è¯­éŸ³æƒ…æ„Ÿå’Œæ„å›¾è¯†åˆ«æ–¹é¢æé«˜äº†æ¨¡å‹æ€§èƒ½ï¼Œæ—¢é€‚ç”¨äºéŸ³é¢‘æ•°æ®ä¹Ÿé€‚ç”¨äºæ–‡æœ¬æ•°æ®ã€‚æœ€ä½³æ¨¡å‹çš„åæœŸèåˆé€šè¿‡è”åˆè¯†åˆ«å¹³è¡¡æŒ‡æ ‡åˆ†åˆ«é«˜å‡ºéŸ³é¢‘å’Œæ–‡æœ¬åŸºçº¿12.3%å’Œ10.4%ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2507.07806v1">PDF</a> Accepted by EMBC 2025</p>
<p><strong>æ‘˜è¦</strong></p>
<p>éšç€ç¤¾äº¤åª’ä½“å¹³å°ã€èŠå¤©æœºå™¨äººç­‰æŠ€æœ¯çš„å¿«é€Ÿå‘å±•ï¼Œç”¨æˆ·äº§ç”Ÿçš„è¯­éŸ³æ•°æ®é‡å¤§å¹…å¢åŠ ã€‚æ‰‹åŠ¨æ ‡æ³¨è¿™äº›æ•°æ®éå¸¸æ˜‚è´µï¼Œå› æ­¤è®­ç»ƒç”¨äºè¯†åˆ«ç›®çš„æœºå™¨å­¦ä¹ æ¨¡å‹å…·æœ‰æŒ‘æˆ˜æ€§ã€‚ä¸ºæ­¤ï¼Œæœ¬æ–‡æå‡ºåº”ç”¨åŠç›‘ç£å­¦ä¹ ï¼Œç»“åˆå¤§è§„æ¨¡æœªæ ‡æ³¨æ•°æ®å’Œç›¸å¯¹è¾ƒå°çš„æ ‡æ³¨æ•°æ®é›†ã€‚æœ¬æ–‡è®­ç»ƒç«¯åˆ°ç«¯çš„å£°å­¦æ¨¡å‹å’Œè¯­è¨€å­¦æ¨¡å‹ï¼Œä¸¤è€…å‡é‡‡ç”¨å¤šä»»åŠ¡å­¦ä¹ è¿›è¡Œæƒ…æ„Ÿå’Œæ„å›¾è¯†åˆ«ã€‚æ¯”è¾ƒäº†å›ºå®šåŒ¹é…å­¦ä¹ å’Œå®Œå…¨åŒ¹é…å­¦ä¹ ä¸¤ç§åŠç›‘ç£å­¦ä¹ æ–¹æ³•ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒåŠç›‘ç£å­¦ä¹ æ–¹æ³•å¯ä»¥æé«˜è¯­éŸ³æƒ…æ„Ÿå’Œæ„å›¾è¯†åˆ«çš„æ¨¡å‹æ€§èƒ½ï¼Œæ— è®ºæ˜¯ä»éŸ³é¢‘è¿˜æ˜¯æ–‡æœ¬æ•°æ®ä¸­ã€‚æœ€ä½³æ¨¡å‹çš„åæœŸèåˆåœ¨è¯†åˆ«å¹³è¡¡æŒ‡æ ‡ä¸Šä¼˜äºå£°å­¦æ¨¡å‹å’Œæ–‡æœ¬åŸºçº¿ï¼Œåˆ†åˆ«æé«˜äº†12.3%å’Œ10.4%ã€‚</p>
<p><strong>è¦ç‚¹æŒæ¡</strong></p>
<ol>
<li>æƒ…æ„Ÿå’Œæ„å›¾è¯†åˆ«åœ¨äººæœºäº¤äº’ä¸­è‡³å…³é‡è¦ï¼Œé¢ä¸´å¤§é‡è¯­éŸ³æ•°æ®çš„æ ‡æ³¨æŒ‘æˆ˜ã€‚</li>
<li>æå‡ºåº”ç”¨åŠç›‘ç£å­¦ä¹ ç»“åˆå¤§é‡æœªæ ‡æ³¨æ•°æ®å’Œè¾ƒå°‘æ ‡æ³¨æ•°æ®ã€‚</li>
<li>è®­ç»ƒäº†ç«¯åˆ°ç«¯çš„å£°å­¦æ¨¡å‹å’Œè¯­è¨€å­¦æ¨¡å‹ï¼Œé‡‡ç”¨å¤šä»»åŠ¡å­¦ä¹ è¿›è¡Œæƒ…æ„Ÿå’Œæ„å›¾è¯†åˆ«ã€‚</li>
<li>æ¯”è¾ƒäº†å›ºå®šåŒ¹é…å­¦ä¹ å’Œå®Œå…¨åŒ¹é…å­¦ä¹ ä¸¤ç§åŠç›‘ç£æ–¹æ³•ã€‚</li>
<li>å®éªŒè¡¨æ˜åŠç›‘ç£å­¦ä¹ æ–¹æ³•èƒ½æé«˜è¯­éŸ³æƒ…æ„Ÿå’Œæ„å›¾è¯†åˆ«çš„æ¨¡å‹æ€§èƒ½ã€‚</li>
<li>æœ€ä½³æ¨¡å‹çš„åæœŸèåˆåœ¨è¯†åˆ«æ•ˆæœä¸Šæ˜¾è‘—æå‡ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2507.07806">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-b5f31b370abc628c445337fda18dfa3c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-debe484cf4a20c1c3b63d458f340e2bd.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-55c1a076296b9282317cdd6ceafacf5d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-5648f08a58d5992b6619f976321e9453.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-4238b42a9d1f21b4e1d6e02237b52da0.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="StreamUni-Achieving-Streaming-Speech-Translation-with-a-Unified-Large-Speech-Language-Model"><a href="#StreamUni-Achieving-Streaming-Speech-Translation-with-a-Unified-Large-Speech-Language-Model" class="headerlink" title="StreamUni: Achieving Streaming Speech Translation with a Unified Large   Speech-Language Model"></a>StreamUni: Achieving Streaming Speech Translation with a Unified Large   Speech-Language Model</h2><p><strong>Authors:Shoutao Guo, Xiang Li, Shaolei Zhang, Mengge Liu, Wei Chen, Yang Feng</strong></p>
<p>Streaming speech translation (StreamST) requires determining appropriate timing, known as policy, to generate translations while continuously receiving source speech inputs, balancing low latency with high translation quality. However, existing StreamST methods typically operate on sentence-level speech segments, referred to as simultaneous speech translation (SimulST). In practice, they require collaboration with segmentation models to accomplish StreamST, where the truncated speech segments constrain SimulST models to make policy decisions and generate translations based on limited contextual information. Moreover, SimulST models struggle to learn effective policies due to the complexity of speech inputs and cross-lingual generation. To address these challenges, we propose StreamUni, which achieves StreamST through a unified Large Speech-Language Model (LSLM). Specifically, StreamUni incorporates speech Chain-of-Thought (CoT) in guiding the LSLM to generate multi-stage outputs. Leveraging these multi-stage outputs, StreamUni simultaneously accomplishes speech segmentation, policy decision, and translation generation, completing StreamST without requiring massive policy-specific training. Additionally, we propose a streaming CoT training method that enhances low-latency policy decisions and generation capabilities using limited CoT data. Experiments demonstrate that our approach achieves state-of-the-art performance on StreamST tasks. </p>
<blockquote>
<p>æµå¼è¯­éŸ³ç¿»è¯‘ï¼ˆStreamSTï¼‰è¦æ±‚åœ¨è¿ç»­æ¥æ”¶æºè¯­éŸ³è¾“å…¥çš„è¿‡ç¨‹ä¸­ç¡®å®šé€‚å½“çš„ç¿»è¯‘ç”Ÿæˆæ—¶æœºï¼Œå³ç­–ç•¥ï¼Œä»¥åœ¨ä½å»¶è¿Ÿå’Œé«˜ç¿»è¯‘è´¨é‡ä¹‹é—´å–å¾—å¹³è¡¡ã€‚ç„¶è€Œï¼Œç°æœ‰çš„StreamSTæ–¹æ³•é€šå¸¸è¿è¡Œåœ¨å¥å­çº§åˆ«çš„è¯­éŸ³æ®µä¸Šï¼Œç§°ä¸ºåŒæ­¥è¯­éŸ³ç¿»è¯‘ï¼ˆSimulSTï¼‰ã€‚åœ¨å®è·µä¸­ï¼Œå®ƒä»¬éœ€è¦ä¸åˆ†å‰²æ¨¡å‹åä½œæ¥å®ŒæˆStreamSTï¼Œè¢«æˆªæ–­çš„è¯­éŸ³æ®µé™åˆ¶SimulSTæ¨¡å‹åŸºäºæœ‰é™çš„ä¸Šä¸‹æ–‡ä¿¡æ¯åšå‡ºç­–ç•¥å†³ç­–å’Œç”Ÿæˆç¿»è¯‘ã€‚è€Œä¸”ï¼Œç”±äºè¯­éŸ³è¾“å…¥çš„å¤æ‚æ€§å’Œè·¨è¯­è¨€ç”Ÿæˆï¼ŒSimulSTæ¨¡å‹åœ¨å­¦ä¹ æœ‰æ•ˆç­–ç•¥æ–¹é¢æ„Ÿåˆ°å›°éš¾ã€‚ä¸ºäº†è§£å†³è¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†StreamUniï¼Œå®ƒé€šè¿‡ç»Ÿä¸€çš„å¤§å‹è¯­éŸ³è¯­è¨€æ¨¡å‹ï¼ˆLSLMï¼‰å®ç°äº†StreamSTã€‚å…·ä½“æ¥è¯´ï¼ŒStreamUniåœ¨å¼•å¯¼LSLMç”Ÿæˆå¤šé˜¶æ®µè¾“å‡ºæ—¶çº³å…¥äº†è¯­éŸ³æ€ç»´é“¾ï¼ˆCoTï¼‰ã€‚åˆ©ç”¨è¿™äº›å¤šé˜¶æ®µè¾“å‡ºï¼ŒStreamUniå¯ä»¥åŒæ—¶å®Œæˆè¯­éŸ³åˆ†å‰²ã€ç­–ç•¥å†³ç­–å’Œç¿»è¯‘ç”Ÿæˆï¼Œæ— éœ€å¤§é‡çš„ç‰¹å®šç­–ç•¥è®­ç»ƒå³å¯å®ŒæˆStreamSTã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æµå¼CoTè®­ç»ƒæ–¹æ³•ï¼Œä½¿ç”¨æœ‰é™çš„CoTæ•°æ®å¢å¼ºä½å»¶è¿Ÿçš„ç­–ç•¥å†³ç­–å’Œç”Ÿæˆèƒ½åŠ›ã€‚å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨StreamSTä»»åŠ¡ä¸Šè¾¾åˆ°äº†æœ€æ–°æŠ€æœ¯æ°´å¹³ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2507.07803v1">PDF</a> The code is at <a target="_blank" rel="noopener" href="https://github.com/ictnlp/StreamUni">https://github.com/ictnlp/StreamUni</a>; The model is at   <a target="_blank" rel="noopener" href="https://huggingface.co/ICTNLP/StreamUni-Phi4">https://huggingface.co/ICTNLP/StreamUni-Phi4</a></p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä¸»è¦ä»‹ç»äº†æµå¼è¯­éŸ³è¯†åˆ«ç¿»è¯‘ï¼ˆStreamSTï¼‰é¢ä¸´çš„æŒ‘æˆ˜åŠè§£å†³æ–¹æ¡ˆã€‚ç°æœ‰çš„æ–¹æ³•é€šå¸¸åŸºäºå¥å­çº§åˆ«çš„è¯­éŸ³æ®µè¿›è¡Œç¿»è¯‘ï¼Œç§°ä¸ºåŒæ­¥è¯­éŸ³è¯†åˆ«ç¿»è¯‘ï¼ˆSimulSTï¼‰ã€‚ç„¶è€Œï¼ŒSimulSTæ¨¡å‹éœ€è¦åœ¨æœ‰é™çš„ä¸Šä¸‹æ–‡ä¿¡æ¯ä¸‹åšå‡ºç­–ç•¥å†³ç­–å’Œç”Ÿæˆç¿»è¯‘ï¼Œå¯¼è‡´æ€§èƒ½å—é™ã€‚ä¸ºæ­¤ï¼Œæœ¬æ–‡æå‡ºäº†StreamUniæ–¹æ³•ï¼Œé€šè¿‡ç»Ÿä¸€çš„å¤§å‹è¯­éŸ³è¯†åˆ«è¯­è¨€æ¨¡å‹ï¼ˆLSLMï¼‰å®ç°StreamSTã€‚StreamUniç»“åˆäº†è¯­éŸ³é“¾æ€ç»´ï¼ˆCoTï¼‰æ¥æŒ‡å¯¼ç”Ÿæˆå¤šé˜¶æ®µè¾“å‡ºï¼Œä»è€ŒåŒæ—¶å®Œæˆè¯­éŸ³åˆ†å‰²ã€ç­–ç•¥å†³ç­–å’Œç¿»è¯‘ç”Ÿæˆã€‚æ­¤å¤–ï¼Œè¿˜æå‡ºäº†ä¸€ç§æµå¼CoTè®­ç»ƒæ–¹æ³•ï¼Œä»¥æé«˜åœ¨ä½å»¶è¿Ÿç­–ç•¥å†³ç­–å’Œç”Ÿæˆèƒ½åŠ›æ–¹é¢çš„è¡¨ç°ã€‚å®éªŒè¯æ˜ï¼Œè¯¥æ–¹æ³•åœ¨StreamSTä»»åŠ¡ä¸Šè¾¾åˆ°äº†é¢†å…ˆæ°´å¹³ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æµå¼è¯­éŸ³è¯†åˆ«ç¿»è¯‘ï¼ˆStreamSTï¼‰éœ€è¦åœ¨ä½å»¶è¿Ÿå’Œé«˜ç¿»è¯‘è´¨é‡ä¹‹é—´æ‰¾åˆ°é€‚å½“çš„å¹³è¡¡ã€‚</li>
<li>ç°æœ‰çš„åŒæ­¥è¯­éŸ³è¯†åˆ«ç¿»è¯‘ï¼ˆSimulSTï¼‰æ–¹æ³•ä¾èµ–äºå¥å­çº§åˆ«çš„è¯­éŸ³æ®µï¼Œéœ€è¦é…åˆåˆ†å‰²æ¨¡å‹å®Œæˆç¿»è¯‘ä»»åŠ¡ã€‚</li>
<li>SimulSTæ¨¡å‹å—é™äºä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œéš¾ä»¥åšå‡ºæœ‰æ•ˆçš„ç­–ç•¥å†³ç­–å’Œç”Ÿæˆé«˜è´¨é‡çš„ç¿»è¯‘ã€‚</li>
<li>StreamUniæ–¹æ³•é€šè¿‡ç»Ÿä¸€çš„Large Speech-Language Modelï¼ˆLSLMï¼‰å®ç°StreamSTï¼Œæ— éœ€å¤§è§„æ¨¡çš„ç­–ç•¥ç‰¹å®šè®­ç»ƒã€‚</li>
<li>StreamUniç»“åˆäº†è¯­éŸ³é“¾æ€ç»´ï¼ˆCoTï¼‰æ¥ç”Ÿæˆå¤šé˜¶æ®µè¾“å‡ºï¼Œå®ç°è¯­éŸ³åˆ†å‰²ã€ç­–ç•¥å†³ç­–å’Œç¿»è¯‘ç”Ÿæˆçš„åŒæ—¶å®Œæˆã€‚</li>
<li>æµå¼CoTè®­ç»ƒæ–¹æ³•å¯ä»¥æé«˜ä½å»¶è¿Ÿç­–ç•¥å†³ç­–å’Œç”Ÿæˆèƒ½åŠ›ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2507.07803">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-62b622e38d4fe482bb18dd09bfe868c4.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-cb5687da2a0140e0a72d7d68eba827e1.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-39483ed4c1810579c02d11932d5c9584.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-96fbccb328040e28f695ae29bb9c45c3.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a38f2576b62c39aeb1af709c2871479c.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="DMF2Mel-A-Dynamic-Multiscale-Fusion-Network-for-EEG-Driven-Mel-Spectrogram-Reconstruction"><a href="#DMF2Mel-A-Dynamic-Multiscale-Fusion-Network-for-EEG-Driven-Mel-Spectrogram-Reconstruction" class="headerlink" title="DMF2Mel: A Dynamic Multiscale Fusion Network for EEG-Driven Mel   Spectrogram Reconstruction"></a>DMF2Mel: A Dynamic Multiscale Fusion Network for EEG-Driven Mel   Spectrogram Reconstruction</h2><p><strong>Authors:Cunhang Fan, Sheng Zhang, Jingjing Zhang, Enrui Liu, Xinhui Li, Minggang Zhao, Zhao Lv</strong></p>
<p>Decoding speech from brain signals is a challenging research problem. Although existing technologies have made progress in reconstructing the mel spectrograms of auditory stimuli at the word or letter level, there remain core challenges in the precise reconstruction of minute-level continuous imagined speech: traditional models struggle to balance the efficiency of temporal dependency modeling and information retention in long-sequence decoding. To address this issue, this paper proposes the Dynamic Multiscale Fusion Network (DMF2Mel), which consists of four core components: the Dynamic Contrastive Feature Aggregation Module (DC-FAM), the Hierarchical Attention-Guided Multi-Scale Network (HAMS-Net), the SplineMap attention mechanism, and the bidirectional state space module (convMamba). Specifically, the DC-FAM separates speech-related â€œforeground featuresâ€ from noisy â€œbackground featuresâ€ through local convolution and global attention mechanisms, effectively suppressing interference and enhancing the representation of transient signals. HAMS-Net, based on the U-Net framework,achieves cross-scale fusion of high-level semantics and low-level details. The SplineMap attention mechanism integrates the Adaptive Gated Kolmogorov-Arnold Network (AGKAN) to combine global context modeling with spline-based local fitting. The convMamba captures long-range temporal dependencies with linear complexity and enhances nonlinear dynamic modeling capabilities. Results on the SparrKULee dataset show that DMF2Mel achieves a Pearson correlation coefficient of 0.074 in mel spectrogram reconstruction for known subjects (a 48% improvement over the baseline) and 0.048 for unknown subjects (a 35% improvement over the baseline).Code is available at: <a target="_blank" rel="noopener" href="https://github.com/fchest/DMF2Mel">https://github.com/fchest/DMF2Mel</a>. </p>
<blockquote>
<p>ä»è„‘ç”µæ³¢è§£ç è¯­éŸ³æ˜¯ä¸€ä¸ªå…·æœ‰æŒ‘æˆ˜æ€§çš„ç ”ç©¶è¯¾é¢˜ã€‚å°½ç®¡ç°æœ‰æŠ€æœ¯å·²åœ¨é‡å»ºå¬è§‰åˆºæ¿€çš„æ¢…å°”é¢‘è°±å›¾ï¼ˆå¦‚å•è¯æˆ–å­—æ¯çº§åˆ«ï¼‰æ–¹é¢å–å¾—äº†è¿›å±•ï¼Œä½†åœ¨ç²¾ç¡®é‡å»ºåˆ†é’Ÿçº§åˆ«çš„è¿ç»­æƒ³è±¡ä¸­çš„è¯­éŸ³æ–¹é¢ä»å­˜åœ¨æ ¸å¿ƒæŒ‘æˆ˜ï¼šä¼ ç»Ÿæ¨¡å‹åœ¨å¹³è¡¡æ—¶é—´åºåˆ—ä¾èµ–å»ºæ¨¡çš„æ•ˆç‡å’Œé•¿åºåˆ—è§£ç ä¸­çš„ä¿¡æ¯ä¿ç•™æ–¹é¢é‡åˆ°å›°éš¾ã€‚é’ˆå¯¹è¿™ä¸€é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†åŠ¨æ€å¤šå°ºåº¦èåˆç½‘ç»œï¼ˆDMF2Melï¼‰ï¼Œå®ƒåŒ…å«å››ä¸ªæ ¸å¿ƒç»„ä»¶ï¼šåŠ¨æ€å¯¹æ¯”ç‰¹å¾èšåˆæ¨¡å—ï¼ˆDC-FAMï¼‰ã€åˆ†å±‚æ³¨æ„åŠ›å¼•å¯¼å¤šå°ºåº¦ç½‘ç»œï¼ˆHAMS-Netï¼‰ã€SplineMapæ³¨æ„åŠ›æœºåˆ¶å’ŒåŒå‘çŠ¶æ€ç©ºé—´æ¨¡å—ï¼ˆconvMambaï¼‰ã€‚å…·ä½“æ¥è¯´ï¼ŒDC-FAMé€šè¿‡å±€éƒ¨å·ç§¯å’Œå…¨å±€æ³¨æ„åŠ›æœºåˆ¶ï¼Œå°†è¯­éŸ³ç›¸å…³çš„â€œå‰æ™¯ç‰¹å¾â€ä»å˜ˆæ‚çš„â€œèƒŒæ™¯ç‰¹å¾â€ä¸­åˆ†ç¦»å‡ºæ¥ï¼Œæœ‰æ•ˆåœ°æŠ‘åˆ¶äº†å¹²æ‰°å¹¶å¢å¼ºäº†ç¬æ€ä¿¡å·çš„è¡¨ç¤ºã€‚HAMS-NetåŸºäºU-Netæ¡†æ¶ï¼Œå®ç°äº†é«˜çº§è¯­ä¹‰å’Œä½çº§ç»†èŠ‚çš„è·¨å°ºåº¦èåˆã€‚SplineMapæ³¨æ„åŠ›æœºåˆ¶ç»“åˆäº†è‡ªé€‚åº”é—¨æ§Kolmogorov-Arnoldç½‘ç»œï¼ˆAGKANï¼‰ï¼Œå°†å…¨å±€ä¸Šä¸‹æ–‡å»ºæ¨¡ä¸åŸºäºæ ·æ¡çš„å±€éƒ¨æ‹Ÿåˆç›¸ç»“åˆã€‚convMambaä»¥çº¿æ€§å¤æ‚åº¦æ•è·é•¿æœŸæ—¶é—´ä¾èµ–å…³ç³»ï¼Œå¹¶å¢å¼ºäº†éçº¿æ€§åŠ¨æ€å»ºæ¨¡èƒ½åŠ›ã€‚åœ¨SparrKULeeæ•°æ®é›†ä¸Šçš„ç»“æœè¡¨æ˜ï¼ŒDMF2Melåœ¨å·²çŸ¥ä¸»é¢˜çš„æ¢…å°”é¢‘è°±å›¾é‡å»ºä¸­å®ç°äº†0.074çš„çš®å°”é€Šç›¸å…³ç³»æ•°ï¼ˆæ¯”åŸºçº¿æé«˜äº†48%ï¼‰ï¼Œåœ¨æœªçŸ¥ä¸»é¢˜ä¸Šå®ç°äº†0.048ï¼ˆæ¯”åŸºçº¿æé«˜äº†35%ï¼‰ã€‚ä»£ç å¯è®¿é—®äºï¼š<a target="_blank" rel="noopener" href="https://github.com/fchest/DMF2Mel%E3%80%82">https://github.com/fchest/DMF2Melã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2507.07526v1">PDF</a> Accepted by ACM MM 2025</p>
<p><strong>æ‘˜è¦</strong><br>è§£ç å¤§è„‘ä¿¡å·ä¸­çš„è¯­éŸ³æ˜¯ä¸€ä¸ªå……æ»¡æŒ‘æˆ˜çš„ç ”ç©¶é—®é¢˜ã€‚ç°æœ‰æŠ€æœ¯åœ¨é‡å»ºå¬è§‰åˆºæ¿€çš„æ¢…å°”é¢‘è°±å›¾æ–¹é¢å·²å–å¾—è¿›å±•ï¼Œä½†ä»é¢ä¸´ç²¾ç¡®é‡å»ºåˆ†é’Ÿçº§è¿ç»­æƒ³è±¡è¯­éŸ³çš„æ ¸å¿ƒæŒ‘æˆ˜ã€‚ä¼ ç»Ÿæ¨¡å‹åœ¨å¹³è¡¡æ—¶é—´åºåˆ—ä¾èµ–æ€§å»ºæ¨¡çš„æ•ˆç‡å’Œé•¿æœŸåºåˆ—è§£ç çš„ä¿¡æ¯ä¿ç•™æ–¹é¢å­˜åœ¨å›°éš¾ã€‚ä¸ºè§£å†³æ­¤é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†åŠ¨æ€å¤šå°ºåº¦èåˆç½‘ç»œï¼ˆDMF2Melï¼‰ï¼ŒåŒ…æ‹¬å››ä¸ªæ ¸å¿ƒç»„ä»¶ï¼šåŠ¨æ€å¯¹æ¯”ç‰¹å¾èšåˆæ¨¡å—ï¼ˆDC-FAMï¼‰ã€åˆ†å±‚æ³¨æ„åŠ›å¼•å¯¼å¤šå°ºåº¦ç½‘ç»œï¼ˆHAMS-Netï¼‰ã€SplineMapæ³¨æ„åŠ›æœºåˆ¶å’ŒåŒå‘çŠ¶æ€ç©ºé—´æ¨¡å—ï¼ˆconvMambaï¼‰ã€‚ç‰¹åˆ«æ˜¯DC-FAMé€šè¿‡å±€éƒ¨å·ç§¯å’Œå…¨å±€æ³¨æ„åŠ›æœºåˆ¶ï¼Œæœ‰æ•ˆåˆ†ç¦»è¯­éŸ³ç›¸å…³çš„â€œå‰æ™¯ç‰¹å¾â€å’Œå™ªå£°â€œèƒŒæ™¯ç‰¹å¾â€ï¼ŒæŠ‘åˆ¶å¹²æ‰°å¹¶å¢å¼ºç¬æ€ä¿¡å·çš„è¡¨ç¤ºã€‚HAMS-NetåŸºäºU-Netæ¡†æ¶å®ç°é«˜çº§è¯­ä¹‰å’Œä½çº§ç»†èŠ‚çš„è·¨å°ºåº¦èåˆã€‚SplineMapæ³¨æ„åŠ›æœºåˆ¶ç»“åˆäº†è‡ªé€‚åº”é—¨æ§Kolmogorov-Arnoldç½‘ç»œï¼ˆAGKANï¼‰è¿›è¡Œå…¨å±€ä¸Šä¸‹æ–‡å»ºæ¨¡å’ŒåŸºäºæ ·æ¡çš„å±€éƒ¨æ‹Ÿåˆã€‚convMambaä»¥çº¿æ€§å¤æ‚åº¦æ•è·é•¿æœŸæ—¶é—´ä¾èµ–æ€§ï¼Œå¹¶å¢å¼ºéçº¿æ€§åŠ¨æ€å»ºæ¨¡èƒ½åŠ›ã€‚åœ¨SparrKULeeæ•°æ®é›†ä¸Šçš„ç»“æœè¡¨æ˜ï¼ŒDMF2Melåœ¨å·²çŸ¥ä¸»é¢˜çš„æ¢…å°”é¢‘è°±å›¾é‡å»ºä¸­å®ç°äº†0.074çš„çš®å°”é€Šç›¸å…³ç³»æ•°ï¼ˆè¾ƒåŸºçº¿æé«˜äº†48%ï¼‰ï¼Œåœ¨æœªçŸ¥ä¸»é¢˜ä¸Šå®ç°äº†0.048ï¼ˆè¾ƒåŸºçº¿æé«˜äº†35%ï¼‰ã€‚ä»£ç å¯ç”¨<a target="_blank" rel="noopener" href="https://github.com/fchest/DMF2Mel%E8%AE%BF%E9%97%AE%E3%80%82">https://github.com/fchest/DMF2Melè®¿é—®ã€‚</a></p>
<p><strong>å…³é”®è§è§£</strong></p>
<ol>
<li>è§£ç å¤§è„‘ä¿¡å·ä¸­çš„è¯­éŸ³æ˜¯ä¸€ä¸ªæŒ‘æˆ˜æ€§é—®é¢˜ï¼Œå°¤å…¶æ˜¯ç²¾ç¡®é‡å»ºåˆ†é’Ÿçº§è¿ç»­æƒ³è±¡è¯­éŸ³ã€‚</li>
<li>ä¼ ç»Ÿæ¨¡å‹åœ¨å¹³è¡¡æ—¶é—´åºåˆ—ä¾èµ–æ€§å»ºæ¨¡çš„æ•ˆç‡å’Œé•¿æœŸåºåˆ—è§£ç çš„ä¿¡æ¯ä¿ç•™æ–¹é¢é‡åˆ°å›°éš¾ã€‚</li>
<li>DMF2Melç½‘ç»œç”±å››ä¸ªæ ¸å¿ƒç»„ä»¶æ„æˆï¼Œæ—¨åœ¨è§£å†³è¿™ä¸€éš¾é¢˜ã€‚</li>
<li>DC-FAMèƒ½å¤Ÿåˆ†ç¦»è¯­éŸ³ç›¸å…³çš„å…³é”®ç‰¹å¾ï¼ŒæŠ‘åˆ¶å¹²æ‰°å¹¶å¢å¼ºç¬æ€ä¿¡å·çš„è¡¨ç¤ºã€‚</li>
<li>HAMS-Netç»“åˆé«˜çº§è¯­ä¹‰å’Œä½çº§ç»†èŠ‚è¿›è¡Œè·¨å°ºåº¦èåˆã€‚</li>
<li>SplineMapæ³¨æ„åŠ›æœºåˆ¶å’ŒAGKANç»“åˆè¿›è¡Œå…¨å±€å’Œå±€éƒ¨å»ºæ¨¡ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2507.07526">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-87bd7690186a01b16a249bc7a4db9d15.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-6f0e79f97d9502168453674b2e693d68.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-cda5a2b51211f1faf9948e972ee09eaf.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="Audio-Visual-Speech-Separation-via-Bottleneck-Iterative-Network"><a href="#Audio-Visual-Speech-Separation-via-Bottleneck-Iterative-Network" class="headerlink" title="Audio-Visual Speech Separation via Bottleneck Iterative Network"></a>Audio-Visual Speech Separation via Bottleneck Iterative Network</h2><p><strong>Authors:Sidong Zhang, Shiv Shankar, Trang Nguyen, Andrea Fanelli, Madalina Fiterau</strong></p>
<p>Integration of information from non-auditory cues can significantly improve the performance of speech-separation models. Often such models use deep modality-specific networks to obtain unimodal features, and risk being too costly or lightweight but lacking capacity. In this work, we present an iterative representation refinement approach called Bottleneck Iterative Network (BIN), a technique that repeatedly progresses through a lightweight fusion block, while bottlenecking fusion representations by fusion tokens. This helps improve the capacity of the model, while avoiding major increase in model size and balancing between the model performance and training cost. We test BIN on challenging noisy audio-visual speech separation tasks, and show that our approach consistently outperforms state-of-the-art benchmark models with respect to SI-SDRi on NTCD-TIMIT and LRS3+WHAM! datasets, while simultaneously achieving a reduction of more than 50% in training and GPU inference time across nearly all settings. </p>
<blockquote>
<p>ä»éå¬è§‰çº¿ç´¢ä¸­æ•´åˆä¿¡æ¯å¯ä»¥æ˜¾è‘—æ”¹å–„è¯­éŸ³åˆ†ç¦»æ¨¡å‹çš„æ€§èƒ½ã€‚é€šå¸¸ï¼Œæ­¤ç±»æ¨¡å‹ä½¿ç”¨æ·±åº¦æ¨¡æ€ç‰¹å®šç½‘ç»œæ¥è·å–å•æ¨¡æ€ç‰¹å¾ï¼Œä½†è¿™æ ·åšå¯èƒ½æˆæœ¬å¤ªé«˜æˆ–è¿‡äºç®€å•ç¼ºä¹èƒ½åŠ›ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§ç§°ä¸ºç“¶é¢ˆè¿­ä»£ç½‘ç»œï¼ˆBINï¼‰çš„è¿­ä»£è¡¨ç¤ºç»†åŒ–æ–¹æ³•ï¼Œè¿™æ˜¯ä¸€ç§é€šè¿‡èåˆå—è¿›è¡Œåå¤è¿­ä»£çš„æŠ€æœ¯ï¼ŒåŒæ—¶é€šè¿‡èåˆä»¤ç‰Œå¯¹èåˆè¡¨ç¤ºè¿›è¡Œç“¶é¢ˆå¤„ç†ã€‚è¿™æœ‰åŠ©äºæé«˜æ¨¡å‹çš„å®¹é‡ï¼ŒåŒæ—¶é¿å…æ¨¡å‹å¤§å°çš„é‡å¤§å¢åŠ ï¼Œå¹¶åœ¨æ¨¡å‹æ€§èƒ½å’Œè®­ç»ƒæˆæœ¬ä¹‹é—´å–å¾—å¹³è¡¡ã€‚æˆ‘ä»¬åœ¨å…·æœ‰æŒ‘æˆ˜æ€§çš„å˜ˆæ‚éŸ³é¢‘-è§†è§‰è¯­éŸ³åˆ†ç¦»ä»»åŠ¡ä¸Šæµ‹è¯•äº†BINï¼Œç»“æœè¡¨æ˜æˆ‘ä»¬çš„æ–¹æ³•åœ¨NTCD-TIMITå’ŒLRS3+WHAMï¼æ•°æ®é›†ä¸Šçš„SI-SDRiæ–¹é¢å§‹ç»ˆä¼˜äºæœ€æ–°åŸºå‡†æ¨¡å‹ï¼ŒåŒæ—¶åœ¨æ‰€æœ‰è®¾ç½®ä¸‹è®­ç»ƒå’ŒGPUæ¨ç†æ—¶é—´å‡å°‘è¶…è¿‡50%ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2507.07270v1">PDF</a> Accepted to the 42nd International Conference on Machine Learning   Workshop on Machine Learning for Audio</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºéå¬è§‰çº¿ç´¢ä¿¡æ¯çš„èåˆæ–¹æ³•ï¼Œå¯æ˜¾è‘—æé«˜è¯­éŸ³åˆ†ç¦»æ¨¡å‹çš„æ€§èƒ½ã€‚é€šè¿‡ä½¿ç”¨ç“¶é¢ˆè¿­ä»£ç½‘ç»œï¼ˆBINï¼‰çš„è¿­ä»£è¡¨ç¤ºä¼˜åŒ–æŠ€æœ¯ï¼Œè¯¥æ¨¡å‹èƒ½å¤Ÿåœ¨è½»é‡çº§èåˆå—ä¸­ä¸æ–­è¿›æ­¥ï¼Œå¹¶é€šè¿‡èåˆä»¤ç‰Œè¿›è¡Œç“¶é¢ˆèåˆè¡¨ç¤ºï¼Œæé«˜äº†æ¨¡å‹çš„å®¹é‡ï¼ŒåŒæ—¶é¿å…äº†æ¨¡å‹å°ºå¯¸çš„å¤§å¹…å¢åŠ ï¼Œå¹¶å¹³è¡¡äº†æ¨¡å‹æ€§èƒ½å’Œè®­ç»ƒæˆæœ¬ã€‚åœ¨å…·æœ‰æŒ‘æˆ˜æ€§çš„å™ªå£°éŸ³é¢‘è§†è§‰è¯­éŸ³åˆ†ç¦»ä»»åŠ¡ä¸Šæµ‹è¯•BINï¼Œç»“æœè¡¨æ˜è¯¥æ–¹æ³•åœ¨NTCD-TIMITå’ŒLRS3+WHAMï¼æ•°æ®é›†ä¸Šçš„SI-SDRiè¡¨ç°å§‹ç»ˆä¼˜äºæœ€æ–°åŸºå‡†æ¨¡å‹ï¼ŒåŒæ—¶åœ¨æ‰€æœ‰è®¾ç½®ä¸‹è®­ç»ƒå’ŒGPUæ¨ç†æ—¶é—´å‡å°‘è¶…è¿‡50%ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>éå¬è§‰çº¿ç´¢ä¿¡æ¯çš„èåˆèƒ½æ˜¾è‘—æå‡è¯­éŸ³åˆ†ç¦»æ¨¡å‹çš„æ€§èƒ½ã€‚</li>
<li>ç“¶é¢ˆè¿­ä»£ç½‘ç»œï¼ˆBINï¼‰æ˜¯ä¸€ç§è¿­ä»£è¡¨ç¤ºä¼˜åŒ–æŠ€æœ¯ï¼Œé€‚ç”¨äºè¯­éŸ³åˆ†ç¦»ä»»åŠ¡ã€‚</li>
<li>BINé€šè¿‡è½»é‡çº§èåˆå—å®ç°æ¨¡å‹æ€§èƒ½çš„è¿›æ­¥ã€‚</li>
<li>èåˆä»¤ç‰Œç”¨äºç“¶é¢ˆèåˆè¡¨ç¤ºï¼Œæé«˜æ¨¡å‹å®¹é‡ã€‚</li>
<li>BINåœ¨å™ªå£°éŸ³é¢‘è§†è§‰è¯­éŸ³åˆ†ç¦»ä»»åŠ¡ä¸Šè¡¨ç°ä¼˜å¼‚ã€‚</li>
<li>ä¸æœ€æ–°åŸºå‡†æ¨¡å‹ç›¸æ¯”ï¼ŒBINåœ¨SI-SDRiè¡¨ç°ä¸Šæ›´ä¼˜ç§€ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2507.07270">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-7544fb8331a45081e72a364f7d1b12ef.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-93e0ff88b00cd15e5f2ed422c2c25b14.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-87c55f84ce7d41de1013186b7d1d5b67.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-ae2f4e86851fece17070a92ed39cb4cd.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-91519ee3d97597eb1efe20ba5780b8f4.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="What-do-self-supervised-speech-models-know-about-Dutch-Analyzing-advantages-of-language-specific-pre-training"><a href="#What-do-self-supervised-speech-models-know-about-Dutch-Analyzing-advantages-of-language-specific-pre-training" class="headerlink" title="What do self-supervised speech models know about Dutch? Analyzing   advantages of language-specific pre-training"></a>What do self-supervised speech models know about Dutch? Analyzing   advantages of language-specific pre-training</h2><p><strong>Authors:Marianne de Heer Kloots, Hosein Mohebbi, Charlotte Pouw, Gaofei Shen, Willem Zuidema, Martijn Bentum</strong></p>
<p>How language-specific are speech representations learned by self-supervised models? Existing work has shown that a range of linguistic features can be successfully decoded from end-to-end models trained only on speech recordings. However, itâ€™s less clear to what extent pre-training on specific languages improves language-specific linguistic information. Here we test the encoding of Dutch phonetic and lexical information in internal representations of self-supervised Wav2Vec2 models. Pre-training exclusively on Dutch improves the representation of Dutch linguistic features as compared to pre-training on similar amounts of English or larger amounts of multilingual data. This language-specific advantage is well-detected by trained clustering or classification probes, and partially observable using zero-shot metrics. Furthermore, the language-specific benefit on linguistic feature encoding aligns with downstream performance on Automatic Speech Recognition. </p>
<blockquote>
<p>é€šè¿‡è‡ªæˆ‘ç›‘ç£æ¨¡å‹å­¦åˆ°çš„è¯­éŸ³è¡¨ç¤ºå…·æœ‰å¤šå¤§çš„è¯­è¨€ç‰¹å¼‚æ€§ï¼Ÿç°æœ‰å·¥ä½œå·²ç»è¡¨æ˜ï¼Œä»…é€šè¿‡è¯­éŸ³å½•éŸ³è®­ç»ƒç«¯åˆ°ç«¯æ¨¡å‹ï¼Œå¯ä»¥æˆåŠŸè§£ç ä¸€ç³»åˆ—è¯­è¨€ç‰¹å¾ã€‚ä½†æ˜¯ï¼Œé¢„è®­ç»ƒç‰¹å®šè¯­è¨€èƒ½åœ¨å¤šå¤§ç¨‹åº¦ä¸Šæé«˜è¯­è¨€ç‰¹å®šçš„è¯­è¨€ä¿¡æ¯å°šä¸æ¸…æ¥šã€‚åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬æµ‹è¯•äº†è‡ªæˆ‘ç›‘ç£çš„Wav2Vec2æ¨¡å‹ä¸­è·å…°è¯­éŸ³å’Œè¯æ±‡ä¿¡æ¯çš„ç¼–ç ã€‚ä»…å¯¹è·å…°è¯­è¿›è¡Œé¢„è®­ç»ƒï¼Œæé«˜äº†è·å…°è¯­è¯­è¨€ç‰¹å¾çš„è¡¨ç¤ºï¼Œä¸é¢„è®­ç»ƒè‹±è¯­æˆ–å¤§é‡å¤šè¯­è¨€æ•°æ®ç›¸æ¯”ã€‚è¿™ç§è¯­è¨€ç‰¹å®šçš„ä¼˜åŠ¿è¢«è®­ç»ƒè¿‡çš„èšç±»æˆ–åˆ†ç±»æ¢é’ˆå¾ˆå¥½åœ°æ£€æµ‹å‡ºæ¥ï¼Œä½¿ç”¨é›¶æ ·æœ¬æŒ‡æ ‡ä¹Ÿå¯ä»¥éƒ¨åˆ†è§‚å¯Ÿåˆ°ã€‚æ­¤å¤–ï¼Œè¯­è¨€ç‰¹å¾ç¼–ç ä¸Šçš„è¯­è¨€ç‰¹å¼‚æ€§ä¼˜åŠ¿ä¸è‡ªåŠ¨è¯­éŸ³è¯†åˆ«ä»»åŠ¡çš„ä¸‹æ¸¸æ€§èƒ½è¡¨ç°ä¸€è‡´ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.00981v2">PDF</a> Accepted to Interspeech 2025. For model, code, and materials, see   <a target="_blank" rel="noopener" href="https://github.com/mdhk/SSL-NL-eval">https://github.com/mdhk/SSL-NL-eval</a></p>
<p><strong>Summary</strong>ï¼š<br>è‡ªç›‘ç£æ¨¡å‹å­¦ä¹ çš„è¯­éŸ³è¡¨ç¤ºå…·æœ‰è¯­è¨€ç‰¹å¼‚æ€§ã€‚å¯¹è·å…°è¯­è¯­éŸ³è¿›è¡Œé¢„è®­ç»ƒå¯ä»¥æé«˜æ¨¡å‹å¯¹è·å…°è¯­è¯­è¨€ç‰¹å¾è¡¨ç¤ºçš„ç¼–ç è´¨é‡ï¼Œç›¸è¾ƒäºé¢„è®­ç»ƒè‹±è¯­æˆ–å¤šè¯­è¨€æ•°æ®ï¼Œè¿™ç§ä¼˜åŠ¿å¯é€šè¿‡è®­ç»ƒèšç±»æˆ–åˆ†ç±»æ¢é’ˆæ£€æµ‹ã€‚æ­¤å¤–ï¼Œè¿™ç§è¯­è¨€ç‰¹å¼‚æ€§å¯¹è¯­éŸ³ç¼–ç çš„ç›Šå¤„ä¸è‡ªåŠ¨è¯­éŸ³è¯†åˆ«ä¸‹æ¸¸æ€§èƒ½è¡¨ç°ä¸€è‡´ã€‚</p>
<p><strong>Key Takeaways</strong>ï¼š</p>
<ol>
<li>è‡ªç›‘ç£æ¨¡å‹å­¦ä¹ çš„è¯­éŸ³è¡¨ç¤ºå…·æœ‰è¯­è¨€ç‰¹å¼‚æ€§ã€‚</li>
<li>é¢„è®­ç»ƒè·å…°è¯­èƒ½æé«˜æ¨¡å‹å¯¹è·å…°è¯­è¯­è¨€ç‰¹å¾çš„ç¼–ç è´¨é‡ã€‚</li>
<li>ä¸é¢„è®­ç»ƒè‹±è¯­æˆ–å¤šè¯­è¨€æ•°æ®ç›¸æ¯”ï¼Œé¢„è®­ç»ƒè·å…°è¯­çš„ä¼˜åŠ¿å¯é€šè¿‡åˆ†ç±»æˆ–èšç±»æ¢é’ˆæ£€æµ‹ã€‚</li>
<li>è¯­è¨€ç‰¹å¼‚æ€§å¯¹è¯­éŸ³ç¼–ç çš„ç›Šå¤„ä¸è‡ªåŠ¨è¯­éŸ³è¯†åˆ«ï¼ˆASRï¼‰çš„ä¸‹æ¸¸æ€§èƒ½è¡¨ç°ä¸€è‡´ã€‚</li>
<li>ç ”ç©¶å¼ºè°ƒäº†è¯­è¨€ç‰¹å¼‚æ€§åœ¨è¯­éŸ³è¡¨ç¤ºå­¦ä¹ ä¸­çš„é‡è¦æ€§ã€‚</li>
<li>é¢„è®­ç»ƒç‰¹å®šè¯­è¨€çš„æ¨¡å‹å¯èƒ½æœ‰åŠ©äºæé«˜å…¶åœ¨å®é™…è¯­è¨€ä»»åŠ¡ä¸­çš„è¡¨ç°ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.00981">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-67d1004d2d42b8d9745a2d4b99855de5.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-9e3329da3eb0caaaf7f96cf29b8946c1.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-59eb9e898147b794242b2f88c7a7cb6e.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="Tiny-Align-Bridging-Automatic-Speech-Recognition-and-Large-Language-Model-on-the-Edge"><a href="#Tiny-Align-Bridging-Automatic-Speech-Recognition-and-Large-Language-Model-on-the-Edge" class="headerlink" title="Tiny-Align: Bridging Automatic Speech Recognition and Large Language   Model on the Edge"></a>Tiny-Align: Bridging Automatic Speech Recognition and Large Language   Model on the Edge</h2><p><strong>Authors:Ruiyang Qin, Dancheng Liu, Gelei Xu, Zheyu Yan, Chenhui Xu, Yuting Hu, X. Sharon Hu, Jinjun Xiong, Yiyu Shi</strong></p>
<p>The combination of Large Language Models (LLM) and Automatic Speech Recognition (ASR), when deployed on edge devices (called edge ASR-LLM), can serve as a powerful personalized assistant to enable audio-based interaction for users. Compared to text-based interaction, edge ASR-LLM allows accessible and natural audio interactions. Unfortunately, existing ASR-LLM models are mainly trained in high-performance computing environments and produce substantial model weights, making them difficult to deploy on edge devices. More importantly, to better serve usersâ€™ personalized needs, the ASR-LLM must be able to learn from each distinct user, given that audio input often contains highly personalized characteristics that necessitate personalized on-device training. Since individually fine-tuning the ASR or LLM often leads to suboptimal results due to modality-specific limitations, end-to-end training ensures seamless integration of audio features and language understanding (cross-modal alignment), ultimately enabling a more personalized and efficient adaptation on edge devices. However, due to the complex training requirements and substantial computational demands of existing approaches, cross-modal alignment between ASR audio and LLM can be challenging on edge devices. In this work, we propose a resource-efficient cross-modal alignment framework that bridges ASR and LLMs on edge devices to handle personalized audio input. Our framework enables efficient ASR-LLM alignment on resource-constrained devices like NVIDIA Jetson Orin (8GB RAM), achieving 50x training time speedup while improving the alignment quality by more than 50%. To the best of our knowledge, this is the first work to study efficient ASR-LLM alignment on resource-constrained edge devices. </p>
<blockquote>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä¸è‡ªåŠ¨è¯­éŸ³è¯†åˆ«ï¼ˆASRï¼‰çš„ç»“åˆï¼Œåœ¨è¾¹ç¼˜è®¾å¤‡ä¸Šéƒ¨ç½²ï¼ˆç§°ä¸ºè¾¹ç¼˜ASR-LLMï¼‰æ—¶ï¼Œå¯ä½œä¸ºå¼ºå¤§çš„ä¸ªæ€§åŒ–åŠ©æ‰‹ï¼Œä½¿ç”¨æˆ·èƒ½å¤ŸåŸºäºéŸ³é¢‘è¿›è¡Œäº¤äº’ã€‚ä¸åŸºäºæ–‡æœ¬çš„äº¤äº’ç›¸æ¯”ï¼Œè¾¹ç¼˜ASR-LLMå…è®¸å¯è®¿é—®å’Œè‡ªç„¶çš„éŸ³é¢‘äº¤äº’ã€‚ç„¶è€Œï¼Œç°æœ‰çš„ASR-LLMæ¨¡å‹ä¸»è¦åœ¨é«˜æ€§èƒ½è®¡ç®—ç¯å¢ƒä¸­è¿›è¡Œè®­ç»ƒï¼Œäº§ç”Ÿå¤§é‡çš„æ¨¡å‹æƒé‡ï¼Œè¿™ä½¿å¾—å®ƒä»¬éš¾ä»¥åœ¨è¾¹ç¼˜è®¾å¤‡ä¸Šéƒ¨ç½²ã€‚æ›´é‡è¦çš„æ˜¯ï¼Œä¸ºäº†æ›´å¥½åœ°æ»¡è¶³ç”¨æˆ·çš„ä¸ªæ€§åŒ–éœ€æ±‚ï¼ŒASR-LLMå¿…é¡»èƒ½å¤Ÿä»æ¯ä¸ªä¸åŒçš„ç”¨æˆ·èº«ä¸Šè¿›è¡Œå­¦ä¹ ï¼Œé‰´äºéŸ³é¢‘è¾“å…¥é€šå¸¸åŒ…å«é«˜åº¦ä¸ªæ€§åŒ–çš„ç‰¹å¾ï¼Œéœ€è¦è¿›è¡Œä¸ªæ€§åŒ–çš„è®¾å¤‡ç«¯è®­ç»ƒã€‚ç”±äºå•ç‹¬å¾®è°ƒASRæˆ–LLMå¾€å¾€ä¼šå¯¼è‡´æ¬¡ä¼˜ç»“æœï¼Œç«¯åˆ°ç«¯è®­ç»ƒç¡®ä¿éŸ³é¢‘ç‰¹å¾å’Œè¯­è¨€ç†è§£çš„æ— ç¼é›†æˆï¼ˆè·¨æ¨¡æ€å¯¹é½ï¼‰ï¼Œæœ€ç»ˆå®ç°åœ¨è¾¹ç¼˜è®¾å¤‡ä¸Šæ›´ä¸ªæ€§åŒ–å’Œæœ‰æ•ˆçš„é€‚åº”ã€‚ç„¶è€Œï¼Œç”±äºç°æœ‰æ–¹æ³•çš„å¤æ‚è®­ç»ƒè¦æ±‚å’Œå·¨å¤§çš„è®¡ç®—éœ€æ±‚ï¼ŒASRéŸ³é¢‘å’ŒLLMä¹‹é—´çš„è·¨æ¨¡æ€å¯¹é½åœ¨è¾¹ç¼˜è®¾å¤‡ä¸Šå¯èƒ½å…·æœ‰æŒ‘æˆ˜æ€§ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªèµ„æºé«˜æ•ˆçš„è·¨æ¨¡æ€å¯¹é½æ¡†æ¶ï¼Œè¯¥æ¡†æ¶èƒ½å¤Ÿåœ¨è¾¹ç¼˜è®¾å¤‡ä¸Šæ¡¥æ¥ASRå’ŒLLMï¼Œå¤„ç†ä¸ªæ€§åŒ–çš„éŸ³é¢‘è¾“å…¥ã€‚æˆ‘ä»¬çš„æ¡†æ¶èƒ½å¤Ÿåœ¨èµ„æºå—é™çš„è®¾å¤‡ä¸Šå®ç°é«˜æ•ˆçš„ASR-LLMå¯¹é½ï¼Œå¦‚NVIDIA Jetson Orinï¼ˆ8GB RAMï¼‰ï¼Œå®ç°50å€çš„åŸ¹è®­æ—¶é—´åŠ é€Ÿï¼ŒåŒæ—¶æé«˜å¯¹é½è´¨é‡è¶…è¿‡50%ã€‚æ®æˆ‘ä»¬æ‰€çŸ¥ï¼Œè¿™æ˜¯ç¬¬ä¸€é¡¹åœ¨èµ„æºå—é™çš„è¾¹ç¼˜è®¾å¤‡ä¸Šç ”ç©¶é«˜æ•ˆASR-LLMå¯¹é½çš„å·¥ä½œã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2411.13766v3">PDF</a> Accepted by ICCADâ€™25</p>
<p><strong>æ‘˜è¦</strong></p>
<p>åœ¨è¾¹ç¼˜è®¾å¤‡ä¸Šéƒ¨ç½²å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å’Œè‡ªåŠ¨è¯­éŸ³è¯†åˆ«ï¼ˆASRï¼‰çš„ç»„åˆï¼ˆç§°ä¸ºè¾¹ç¼˜ASR-LLMï¼‰ï¼Œå¯ä½œä¸ºå¼ºå¤§çš„ä¸ªæ€§åŒ–åŠ©æ‰‹ï¼Œå®ç°åŸºäºéŸ³é¢‘çš„ç”¨æˆ·äº¤äº’ã€‚ç›¸æ¯”æ–‡æœ¬äº¤äº’ï¼Œè¾¹ç¼˜ASR-LLMæ”¯æŒä¾¿æ·çš„è‡ªç„¶éŸ³é¢‘äº¤äº’ã€‚ç„¶è€Œï¼Œç°æœ‰ASR-LLMæ¨¡å‹ä¸»è¦åœ¨é«˜æ€§èƒ½è®¡ç®—ç¯å¢ƒä¸­è®­ç»ƒï¼Œæ¨¡å‹ä½“ç§¯åºå¤§ï¼Œéš¾ä»¥éƒ¨ç½²åœ¨è¾¹ç¼˜è®¾å¤‡ä¸Šã€‚ä¸ºäº†æ›´å¥½æœåŠ¡ç”¨æˆ·çš„ä¸ªæ€§åŒ–éœ€æ±‚ï¼ŒASR-LLMéœ€è¦ä»æ¯ä¸ªç”¨æˆ·èº«ä¸Šå­¦ä¹ ï¼Œå› ä¸ºéŸ³é¢‘è¾“å…¥é€šå¸¸åŒ…å«é«˜åº¦ä¸ªæ€§åŒ–çš„ç‰¹å¾ï¼Œéœ€è¦è¿›è¡Œä¸ªæ€§åŒ–è®¾å¤‡ç«¯è®­ç»ƒã€‚ç”±äºå•ç‹¬å¾®è°ƒASRæˆ–LLMå¾€å¾€å› æ¨¡æ€ç‰¹å®šé™åˆ¶è€Œå¯¼è‡´ç»“æœä¸ä½³ï¼Œç«¯åˆ°ç«¯è®­ç»ƒå¯ç¡®ä¿éŸ³é¢‘ç‰¹å¾ä¸è¯­è¨€ç†è§£æ— ç¼é›†æˆï¼ˆè·¨æ¨¡æ€å¯¹é½ï¼‰ï¼Œæœ€ç»ˆåœ¨è¾¹ç¼˜è®¾å¤‡ä¸Šå®ç°æ›´ä¸ªæ€§åŒ–å’Œé«˜æ•ˆçš„é€‚åº”ã€‚ç„¶è€Œï¼Œç”±äºç°æœ‰æ–¹æ³•çš„å¤æ‚è®­ç»ƒè¦æ±‚å’Œå·¨å¤§çš„è®¡ç®—éœ€æ±‚ï¼Œåœ¨è¾¹ç¼˜è®¾å¤‡ä¸Šå®ç°ASRéŸ³é¢‘å’ŒLLMä¹‹é—´çš„è·¨æ¨¡æ€å¯¹é½å…·æœ‰æŒ‘æˆ˜æ€§ã€‚æœ¬ç ”ç©¶æå‡ºäº†ä¸€ç§èµ„æºé«˜æ•ˆçš„è·¨æ¨¡æ€å¯¹é½æ¡†æ¶ï¼Œè¯¥æ¡†æ¶å¯åœ¨è¾¹ç¼˜è®¾å¤‡ä¸Šå®ç°ASRå’ŒLLMçš„æ¡¥æ¢ä½œç”¨ï¼Œå¤„ç†ä¸ªæ€§åŒ–éŸ³é¢‘è¾“å…¥ã€‚æˆ‘ä»¬çš„æ¡†æ¶å¯åœ¨èµ„æºå—é™çš„è®¾å¤‡ä¸Šå®ç°é«˜æ•ˆçš„ASR-LLMå¯¹é½ï¼Œå¦‚NVIDIA Jetson Orinï¼ˆ8GB RAMï¼‰ï¼Œå®ç°50å€çš„è®­ç»ƒæ—¶é—´åŠ é€Ÿï¼ŒåŒæ—¶æé«˜å¯¹é½è´¨é‡è¶…è¿‡50ï¼…ã€‚æ®æˆ‘ä»¬æ‰€çŸ¥ï¼Œè¿™æ˜¯ç¬¬ä¸€é¡¹åœ¨èµ„æºå—é™çš„è¾¹ç¼˜è®¾å¤‡ä¸Šç ”ç©¶é«˜æ•ˆASR-LLMå¯¹é½çš„å·¥ä½œã€‚</p>
<p><strong>å…³é”®è§è§£</strong></p>
<ol>
<li>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å’Œè‡ªåŠ¨è¯­éŸ³è¯†åˆ«ï¼ˆASRï¼‰çš„ç»“åˆï¼Œåœ¨è¾¹ç¼˜è®¾å¤‡ä¸Šä½œä¸ºä¸ªæ€§åŒ–åŠ©æ‰‹å…·æœ‰å·¨å¤§æ½œåŠ›ï¼Œå¯å®ç°è‡ªç„¶éŸ³é¢‘äº¤äº’ã€‚</li>
<li>ç°æœ‰ASR-LLMæ¨¡å‹ä¸»è¦åœ¨é«˜æ€§èƒ½è®¡ç®—ç¯å¢ƒä¸­è®­ç»ƒï¼Œéš¾ä»¥éƒ¨ç½²åœ¨èµ„æºæœ‰é™çš„è¾¹ç¼˜è®¾å¤‡ä¸Šã€‚</li>
<li>ä¸ªæ€§åŒ–éŸ³é¢‘è¾“å…¥éœ€è¦ä¸ªæ€§åŒ–è®¾å¤‡ç«¯è®­ç»ƒï¼Œå› ä¸ºéŸ³é¢‘è¾“å…¥åŒ…å«é«˜åº¦ä¸ªæ€§åŒ–çš„ç‰¹å¾ã€‚</li>
<li>å•ç‹¬çš„ASRæˆ–LLMå¾®è°ƒå› æ¨¡æ€ç‰¹å®šé™åˆ¶å¯èƒ½æ•ˆæœä¸ä½³ï¼Œç«¯åˆ°ç«¯è®­ç»ƒå¯å®ç°è·¨æ¨¡æ€å¯¹é½ï¼Œæé«˜é€‚åº”æ€§å’Œä¸ªæ€§åŒ–ç¨‹åº¦ã€‚</li>
<li>è·¨æ¨¡æ€å¯¹é½åœ¨è¾¹ç¼˜è®¾å¤‡ä¸Šå…·æœ‰æŒ‘æˆ˜æ€§ï¼Œå› ä¸ºç°æœ‰æ–¹æ³•éœ€è¦å¤æ‚çš„è®­ç»ƒå’Œå¤§é‡çš„è®¡ç®—èµ„æºã€‚</li>
<li>ç ”ç©¶æå‡ºäº†ä¸€ç§èµ„æºé«˜æ•ˆçš„è·¨æ¨¡æ€å¯¹é½æ¡†æ¶ï¼Œå¯åœ¨èµ„æºå—é™çš„è¾¹ç¼˜è®¾å¤‡ä¸Šå®ç°ASRå’ŒLLMçš„æœ‰æ•ˆå¯¹é½ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2411.13766">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-2f9aea71e7356066d4095c4963700fe8.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-777a1bedc89f16a499c8ed120fba64f6.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-14077e5b275adf181c92b7c6d9a2b37e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-6fb780f993d6475ac9ad5e06c367a034.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-07-12/Speech/">https://kedreamix.github.io/Talk2Paper/Paper/2025-07-12/Speech/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/Speech/">
                                    <span class="chip bg-color">Speech</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-07-12/GAN/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-19bf915952f0961f0bd4826afaadac3e.jpg" class="responsive-img" alt="GAN">
                        
                        <span class="card-title">GAN</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            GAN æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-07-12  Degradation-Agnostic Statistical Facial Feature Transformation for Blind   Face Restoration in Adverse Weather Conditions
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-07-12
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/GAN/" class="post-category">
                                    GAN
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/GAN/">
                        <span class="chip bg-color">GAN</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-07-12/%E6%97%A0%E7%9B%91%E7%9D%A3_%E5%8D%8A%E7%9B%91%E7%9D%A3_%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-a1e3a96f3e4c2dca5c69ba585cdf0674.jpg" class="responsive-img" alt="æ— ç›‘ç£/åŠç›‘ç£/å¯¹æ¯”å­¦ä¹ ">
                        
                        <span class="card-title">æ— ç›‘ç£/åŠç›‘ç£/å¯¹æ¯”å­¦ä¹ </span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            æ— ç›‘ç£/åŠç›‘ç£/å¯¹æ¯”å­¦ä¹  æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-07-12  CL-Polyp A Contrastive Learning-Enhanced Network for Accurate Polyp   Segmentation
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-07-12
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/%E6%97%A0%E7%9B%91%E7%9D%A3-%E5%8D%8A%E7%9B%91%E7%9D%A3-%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0/" class="post-category">
                                    æ— ç›‘ç£/åŠç›‘ç£/å¯¹æ¯”å­¦ä¹ 
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/%E6%97%A0%E7%9B%91%E7%9D%A3-%E5%8D%8A%E7%9B%91%E7%9D%A3-%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0/">
                        <span class="chip bg-color">æ— ç›‘ç£/åŠç›‘ç£/å¯¹æ¯”å­¦ä¹ </span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">25156.8k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
