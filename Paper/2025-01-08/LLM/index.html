<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="LLM">
    <meta name="description" content="LLM æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-01-08  Dispider Enabling Video LLMs with Active Real-Time Interaction via   Disentangled Perception, Decision, and Reaction">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>LLM | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://picx.zhimg.com/v2-c403d08709970285ab560d34bba0b7cc.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">LLM</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/LLM/">
                                <span class="chip bg-color">LLM</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/LLM/" class="post-category">
                                LLM
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-01-08
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-01-08
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    15.9k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    65 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-01-08-æ›´æ–°"><a href="#2025-01-08-æ›´æ–°" class="headerlink" title="2025-01-08 æ›´æ–°"></a>2025-01-08 æ›´æ–°</h1><h2 id="Dispider-Enabling-Video-LLMs-with-Active-Real-Time-Interaction-via-Disentangled-Perception-Decision-and-Reaction"><a href="#Dispider-Enabling-Video-LLMs-with-Active-Real-Time-Interaction-via-Disentangled-Perception-Decision-and-Reaction" class="headerlink" title="Dispider: Enabling Video LLMs with Active Real-Time Interaction via   Disentangled Perception, Decision, and Reaction"></a>Dispider: Enabling Video LLMs with Active Real-Time Interaction via   Disentangled Perception, Decision, and Reaction</h2><p><strong>Authors:Rui Qian, Shuangrui Ding, Xiaoyi Dong, Pan Zhang, Yuhang Zang, Yuhang Cao, Dahua Lin, Jiaqi Wang</strong></p>
<p>Active Real-time interaction with video LLMs introduces a new paradigm for human-computer interaction, where the model not only understands user intent but also responds while continuously processing streaming video on the fly. Unlike offline video LLMs, which analyze the entire video before answering questions, active real-time interaction requires three capabilities: 1) Perception: real-time video monitoring and interaction capturing. 2) Decision: raising proactive interaction in proper situations, 3) Reaction: continuous interaction with users. However, inherent conflicts exist among the desired capabilities. The Decision and Reaction require a contrary Perception scale and grain, and the autoregressive decoding blocks the real-time Perception and Decision during the Reaction. To unify the conflicted capabilities within a harmonious system, we present Dispider, a system that disentangles Perception, Decision, and Reaction. Dispider features a lightweight proactive streaming video processing module that tracks the video stream and identifies optimal moments for interaction. Once the interaction is triggered, an asynchronous interaction module provides detailed responses, while the processing module continues to monitor the video in the meantime. Our disentangled and asynchronous design ensures timely, contextually accurate, and computationally efficient responses, making Dispider ideal for active real-time interaction for long-duration video streams. Experiments show that Dispider not only maintains strong performance in conventional video QA tasks, but also significantly surpasses previous online models in streaming scenario responses, thereby validating the effectiveness of our architecture. The code and model are released at \url{<a target="_blank" rel="noopener" href="https://github.com/Mark12Ding/Dispider%7D">https://github.com/Mark12Ding/Dispider}</a>. </p>
<blockquote>
<p>ä¸»åŠ¨å®æ—¶ä¸è§†é¢‘LLMäº¤äº’ä¸ºäººæœºäº¤äº’å¼•å…¥äº†ä¸€ç§æ–°çš„èŒƒå¼ã€‚åœ¨æ­¤èŒƒå¼ä¸­ï¼Œæ¨¡å‹ä¸ä»…ç†è§£ç”¨æˆ·æ„å›¾ï¼Œè€Œä¸”åœ¨è¿ç»­å¤„ç†æµå¼è§†é¢‘çš„åŒæ—¶è¿›è¡Œå“åº”ã€‚ä¸åŒäºç¦»çº¿è§†é¢‘LLMï¼Œåè€…åœ¨å›ç­”é—®é¢˜ä¹‹å‰ä¼šåˆ†ææ•´ä¸ªè§†é¢‘ï¼Œä¸»åŠ¨å®æ—¶äº¤äº’éœ€è¦ä¸‰ç§èƒ½åŠ›ï¼š1ï¼‰æ„ŸçŸ¥ï¼šå®æ—¶è§†é¢‘ç›‘æ§å’Œäº¤äº’æ•è·ã€‚2ï¼‰å†³ç­–ï¼šåœ¨é€‚å½“çš„æƒ…å¢ƒä¸‹ä¸»åŠ¨äº¤äº’ã€‚3ï¼‰ååº”ï¼šä¸ç”¨æˆ·æŒç»­äº¤äº’ã€‚ç„¶è€Œï¼Œæ‰€æœŸæœ›çš„è¿™äº›èƒ½åŠ›ä¹‹é—´å­˜åœ¨å›ºæœ‰å†²çªã€‚å†³ç­–å’Œååº”éœ€è¦ç›¸åçš„æ„ŸçŸ¥å°ºåº¦å’Œç²’åº¦ï¼Œè€Œä¸”è‡ªå›å½’è§£ç åœ¨ååº”æœŸé—´é˜»æ­¢äº†å®æ—¶æ„ŸçŸ¥å’Œå†³ç­–ã€‚ä¸ºäº†åœ¨ä¸€ä¸ªå’Œè°ç³»ç»Ÿä¸­ç»Ÿä¸€è¿™äº›å†²çªçš„èƒ½åŠ›ï¼Œæˆ‘ä»¬æå‡ºäº†Dispiderç³»ç»Ÿï¼Œå®ƒèƒ½è§£å¼€æ„ŸçŸ¥ã€å†³ç­–å’Œååº”ã€‚Dispiderç³»ç»Ÿå…·æœ‰ä¸€ä¸ªè½»é‡çº§çš„ä¸»åŠ¨æµå¼è§†é¢‘å¤„ç†æ¨¡å—ï¼Œè¯¥æ¨¡å—è·Ÿè¸ªè§†é¢‘æµå¹¶è¯†åˆ«äº¤äº’çš„æœ€ä½³æ—¶åˆ»ã€‚ä¸€æ—¦è§¦å‘äº¤äº’ï¼Œå¼‚æ­¥äº¤äº’æ¨¡å—ä¼šæä¾›è¯¦ç»†å“åº”ï¼ŒåŒæ—¶å¤„ç†æ¨¡å—ä¼šç»§ç»­ç›‘æ§è§†é¢‘ã€‚æˆ‘ä»¬è§£è€¦å’Œå¼‚æ­¥çš„è®¾è®¡ç¡®ä¿äº†åŠæ—¶ã€ä¸Šä¸‹æ–‡å‡†ç¡®å’Œè®¡ç®—é«˜æ•ˆçš„å“åº”ï¼Œä½¿Dispideræˆä¸ºé•¿æ—¶é•¿è§†é¢‘æµçš„ä¸»åŠ¨å®æ—¶äº¤äº’çš„ç†æƒ³é€‰æ‹©ã€‚å®éªŒè¡¨æ˜ï¼ŒDispiderä¸ä»…åœ¨ä¼ ç»Ÿçš„è§†é¢‘é—®ç­”ä»»åŠ¡ä¸­ä¿æŒå¼ºåŠ²æ€§èƒ½ï¼Œè€Œä¸”åœ¨æµå¼åœºæ™¯å“åº”ä¸­æ˜¾è‘—è¶…è¶Šå…ˆå‰çš„åœ¨çº¿æ¨¡å‹ï¼Œä»è€ŒéªŒè¯äº†æˆ‘ä»¬çš„æ¶æ„çš„æœ‰æ•ˆæ€§ã€‚ä»£ç å’Œæ¨¡å‹å·²å‘å¸ƒåœ¨[<a target="_blank" rel="noopener" href="https://github.com/Mark12Ding/Dispider%E3%80%82]">https://github.com/Mark12Ding/Dispiderã€‚]</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.03218v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†ä¸»åŠ¨å®æ—¶äº’åŠ¨è§†é¢‘LLMçš„æ–°èŒƒå¼ï¼Œå®ƒéœ€è¦æ„ŸçŸ¥ã€å†³ç­–å’Œååº”ä¸‰ç§èƒ½åŠ›ã€‚ç„¶è€Œï¼Œè¿™äº›èƒ½åŠ›ä¹‹é—´å­˜åœ¨å†…åœ¨å†²çªã€‚ä¸ºäº†ç»Ÿä¸€è¿™äº›å†²çªçš„èƒ½åŠ›ï¼Œæå‡ºäº†Dispiderç³»ç»Ÿï¼Œå®ƒå®ç°äº†æ„ŸçŸ¥ã€å†³ç­–å’Œååº”çš„åˆ†ç¦»å’Œè§£è€¦ã€‚è¯¥ç³»ç»Ÿå¯ç¡®ä¿åŠæ—¶ã€ä¸Šä¸‹æ–‡å‡†ç¡®å’Œè®¡ç®—é«˜æ•ˆçš„å“åº”ï¼Œéå¸¸é€‚åˆé•¿æ—¶é—´çš„å®æ—¶è§†é¢‘æµäº¤äº’ã€‚å®éªŒè¡¨æ˜ï¼ŒDispideråœ¨å¸¸è§„è§†é¢‘é—®ç­”ä»»åŠ¡ä¸­è¡¨ç°å¼ºåŠ²ï¼Œå¹¶åœ¨æµåª’ä½“åœºæ™¯å“åº”ä¸­æ˜¾è‘—è¶…è¶Šå…ˆå‰æ¨¡å‹ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ä¸»åŠ¨å®æ—¶äº’åŠ¨è§†é¢‘LLMå¼•å…¥äº†ä¸€ç§æ–°çš„äº¤äº’èŒƒå¼ï¼ŒåŒ…æ‹¬æ„ŸçŸ¥ã€å†³ç­–å’Œååº”ä¸‰ç§å…³é”®èƒ½åŠ›ã€‚</li>
<li>æ„ŸçŸ¥èƒ½åŠ›æ¶‰åŠå®æ—¶è§†é¢‘ç›‘æ§å’Œäº¤äº’æ•è·ï¼›å†³ç­–èƒ½åŠ›è¦æ±‚åœ¨é€‚å½“æƒ…å†µä¸‹ä¸»åŠ¨äº¤äº’ï¼›ååº”èƒ½åŠ›åˆ™è¦æ±‚ä¸ç”¨æˆ·æŒç»­äº’åŠ¨ã€‚</li>
<li>æ„ŸçŸ¥ã€å†³ç­–å’Œååº”ä¹‹é—´å­˜åœ¨å†…åœ¨å†²çªï¼Œç‰¹åˆ«æ˜¯åœ¨å†³ç­–å’Œååº”å¯¹æ„ŸçŸ¥å°ºåº¦å’Œç²¾ç»†åº¦çš„è¦æ±‚ç›¸åä»¥åŠååº”è¿‡ç¨‹ä¸­çš„è‡ªå›å½’è§£ç ä¼šé˜»ç¢å®æ—¶æ„ŸçŸ¥å’Œå†³ç­–ã€‚</li>
<li>Dispiderç³»ç»Ÿé€šè¿‡è§£è€¦è¿™ä¸‰ç§èƒ½åŠ›ï¼Œå®ç°äº†å’Œè°ç»Ÿä¸€ã€‚å®ƒé‡‡ç”¨è½»é‡çº§çš„ä¸»åŠ¨æµè§†é¢‘å¤„ç†æ¨¡å—æ¥è·Ÿè¸ªè§†é¢‘æµå¹¶è¯†åˆ«æœ€ä½³äº¤äº’æ—¶åˆ»ã€‚</li>
<li>ä¸€æ—¦è§¦å‘äº¤äº’ï¼Œå¼‚æ­¥äº¤äº’æ¨¡å—æä¾›è¯¦ç»†å“åº”ï¼ŒåŒæ—¶å¤„ç†æ¨¡å—ç»§ç»­ç›‘æ§è§†é¢‘ã€‚</li>
<li>å®éªŒè¡¨æ˜ï¼ŒDispideråœ¨å¸¸è§„è§†é¢‘é—®ç­”ä»»åŠ¡ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œå¹¶åœ¨æµåª’ä½“åœºæ™¯å“åº”ä¸­æ˜¾è‘—è¶…è¶Šå…ˆå‰æ¨¡å‹ï¼ŒéªŒè¯äº†å…¶æ¶æ„çš„æœ‰æ•ˆæ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.03218">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-d0f923a8593833f15839a5a94294d83d.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-61e698c144b8171e1636a777c612c962.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="The-FACTS-Grounding-Leaderboard-Benchmarking-LLMsâ€™-Ability-to-Ground-Responses-to-Long-Form-Input"><a href="#The-FACTS-Grounding-Leaderboard-Benchmarking-LLMsâ€™-Ability-to-Ground-Responses-to-Long-Form-Input" class="headerlink" title="The FACTS Grounding Leaderboard: Benchmarking LLMsâ€™ Ability to Ground   Responses to Long-Form Input"></a>The FACTS Grounding Leaderboard: Benchmarking LLMsâ€™ Ability to Ground   Responses to Long-Form Input</h2><p><strong>Authors:Alon Jacovi, Andrew Wang, Chris Alberti, Connie Tao, Jon Lipovetz, Kate Olszewska, Lukas Haas, Michelle Liu, Nate Keating, Adam Bloniarz, Carl Saroufim, Corey Fry, Dror Marcus, Doron Kukliansky, Gaurav Singh Tomar, James Swirhun, Jinwei Xing, Lily Wang, Madhu Gurumurthy, Michael Aaron, Moran Ambar, Rachana Fellinger, Rui Wang, Zizhao Zhang, Sasha Goldshtein, Dipanjan Das</strong></p>
<p>We introduce FACTS Grounding, an online leaderboard and associated benchmark that evaluates language modelsâ€™ ability to generate text that is factually accurate with respect to given context in the user prompt. In our benchmark, each prompt includes a user request and a full document, with a maximum length of 32k tokens, requiring long-form responses. The long-form responses are required to be fully grounded in the provided context document while fulfilling the user request. Models are evaluated using automated judge models in two phases: (1) responses are disqualified if they do not fulfill the user request; (2) they are judged as accurate if the response is fully grounded in the provided document. The automated judge models were comprehensively evaluated against a held-out test-set to pick the best prompt template, and the final factuality score is an aggregate of multiple judge models to mitigate evaluation bias. The FACTS Grounding leaderboard will be actively maintained over time, and contains both public and private splits to allow for external participation while guarding the integrity of the leaderboard. It can be found at <a target="_blank" rel="noopener" href="https://www.kaggle.com/facts-leaderboard">https://www.kaggle.com/facts-leaderboard</a>. </p>
<blockquote>
<p>æˆ‘ä»¬å¼•å…¥äº†FACTS Groundingï¼Œè¿™æ˜¯ä¸€ä¸ªåœ¨çº¿æ’è¡Œæ¦œåŠç›¸å…³åŸºå‡†æµ‹è¯•ï¼Œç”¨äºè¯„ä¼°è¯­è¨€æ¨¡å‹åœ¨ç”¨æˆ·æç¤ºçš„ç»™å®šä¸Šä¸‹æ–‡ä¸­ç”Ÿæˆæ–‡æœ¬çš„äº‹å®å‡†ç¡®æ€§èƒ½åŠ›ã€‚åœ¨æˆ‘ä»¬çš„åŸºå‡†æµ‹è¯•ä¸­ï¼Œæ¯ä¸ªæç¤ºéƒ½åŒ…æ‹¬ç”¨æˆ·è¯·æ±‚å’Œå®Œæ•´æ–‡æ¡£ï¼Œæ–‡æ¡£æœ€é•¿å¯è¾¾32kä¸ªæ ‡è®°ï¼Œéœ€è¦é•¿å½¢å¼å›åº”ã€‚é•¿å½¢å¼å›åº”å¿…é¡»åœ¨æä¾›çš„ä¸Šä¸‹æ–‡æ–‡æ¡£ä¸­å®Œå…¨ç«‹è¶³ï¼ŒåŒæ—¶æ»¡è¶³ç”¨æˆ·éœ€æ±‚ã€‚æˆ‘ä»¬ä½¿ç”¨è‡ªåŠ¨åŒ–è¯„ä¼°æ¨¡å‹å¯¹æ¨¡å‹è¿›è¡Œä¸¤ä¸ªé˜¶æ®µè¯„ä¼°ï¼šï¼ˆ1ï¼‰å¦‚æœå›åº”ä¸èƒ½æ»¡è¶³ç”¨æˆ·éœ€æ±‚ï¼Œåˆ™å°†å…¶è§†ä¸ºä¸åˆæ ¼ï¼›ï¼ˆ2ï¼‰å¦‚æœå›åº”åœ¨æä¾›çš„æ–‡æ¡£ä¸­å®Œå…¨ç«‹è¶³ï¼Œåˆ™å°†å…¶è§†ä¸ºå‡†ç¡®ã€‚é’ˆå¯¹ç¦»ç¾¤æµ‹è¯•é›†å…¨é¢è¯„ä¼°è‡ªåŠ¨åŒ–è¯„ä¼°æ¨¡å‹ï¼Œä»¥é€‰æ‹©æœ€ä½³æç¤ºæ¨¡æ¿ï¼Œæœ€ç»ˆçš„äº‹å®å¾—åˆ†æ˜¯å¤šä¸ªè¯„ä¼°æ¨¡å‹çš„æ±‡æ€»ï¼Œä»¥å‡è½»è¯„ä¼°åè§ã€‚FACTS Groundingæ’è¡Œæ¦œå°†éšæ—¶é—´ç§¯æç»´æŠ¤ï¼ŒåŒ…å«å…¬å…±å’Œç§æœ‰åˆ†å‰²ï¼Œå…è®¸å¤–éƒ¨å‚ä¸åŒæ—¶ä¿è¯æ’è¡Œæ¦œçš„å®Œæ•´æ€§ã€‚å¯ä»¥åœ¨<a target="_blank" rel="noopener" href="https://www.kaggle.com/facts-leaderboard%E6%89%BE%E5%88%B0%E5%AE%83%E3%80%82">https://www.kaggle.com/facts-leaderboardæ‰¾åˆ°å®ƒã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.03200v1">PDF</a> </p>
<p><strong>Summary</strong>ï¼šæˆ‘ä»¬æ¨å‡ºFACTSæ¥åœ°åœ¨çº¿æ’è¡Œæ¦œåŠç›¸å…³åŸºå‡†æµ‹è¯•ï¼Œè¯„ä¼°è¯­è¨€æ¨¡å‹åœ¨ç”¨æˆ·æç¤ºçš„ç»™å®šä¸Šä¸‹æ–‡ä¸­çš„äº‹å®å‡†ç¡®æ€§ç”Ÿæˆæ–‡æœ¬çš„èƒ½åŠ›ã€‚è¯¥åŸºå‡†æµ‹è¯•åŒ…å«ç”¨æˆ·è¯·æ±‚å’Œå…¨æ–‡æ–‡æ¡£ï¼Œè¦æ±‚é•¿æ ¼å¼å“åº”ï¼Œå¹¶ä¸”å¿…é¡»å®Œå…¨åŸºäºæä¾›çš„æ–‡æ¡£æ¥æ»¡è¶³ç”¨æˆ·è¯·æ±‚ã€‚æ¨¡å‹ä½¿ç”¨è‡ªåŠ¨åŒ–åˆ¤æ–­æ¨¡å‹è¿›è¡Œä¸¤ä¸ªé˜¶æ®µè¯„ä¼°ï¼šé¦–å…ˆï¼Œä¸æ»¡è¶³ç”¨æˆ·éœ€æ±‚çš„å“åº”å°†è¢«æ·˜æ±°ï¼›å…¶æ¬¡ï¼Œå¦‚æœå“åº”å®Œå…¨åŸºäºæä¾›çš„æ–‡æ¡£ï¼Œåˆ™å°†å…¶åˆ¤å®šä¸ºå‡†ç¡®ã€‚é’ˆå¯¹è‡ªåŠ¨åŒ–åˆ¤æ–­æ¨¡å‹è¿›è¡Œå¹¿æ³›è¯„ä¼°ä»¥ç¡®å®šæœ€ä½³æç¤ºæ¨¡æ¿ï¼Œæœ€ç»ˆçš„å‡†ç¡®æ€§å¾—åˆ†æ˜¯å¤šä¸ªåˆ¤æ–­æ¨¡å‹çš„æ±‡æ€»ç»“æœï¼Œä»¥å‡å°‘è¯„ä¼°åè§ã€‚FACTSæ¥åœ°æ’è¡Œæ¦œå°†éšæ—¶é—´æŒç»­ç»´æŠ¤ï¼ŒåŒ…å«å…¬å¼€å’Œç§æœ‰åˆ†å‰²ï¼Œå…è®¸å¤–éƒ¨å‚ä¸åŒæ—¶ä¿æŠ¤æ’è¡Œæ¦œçš„å®Œæ•´æ€§ã€‚å¯ä»¥åœ¨<a target="_blank" rel="noopener" href="https://www.kaggle.com/facts-leaderboard%E6%89%BE%E5%88%B0%E5%AE%83%E3%80%82">https://www.kaggle.com/facts-leaderboardæ‰¾åˆ°å®ƒã€‚</a></p>
<p><strong>Key Takeaways</strong>ï¼š</p>
<ol>
<li>FACTS Groundingæ˜¯ä¸€ä¸ªåœ¨çº¿æ’è¡Œæ¦œå’ŒåŸºå‡†æµ‹è¯•ï¼Œæ—¨åœ¨è¯„ä¼°è¯­è¨€æ¨¡å‹åœ¨ç»™å®šä¸Šä¸‹æ–‡ä¸­çš„äº‹å®å‡†ç¡®æ€§ç”Ÿæˆæ–‡æœ¬çš„èƒ½åŠ›ã€‚</li>
<li>æ¯ä¸ªæç¤ºåŒ…å«ç”¨æˆ·è¯·æ±‚å’Œå…¨æ–‡æ–‡æ¡£ï¼Œå“åº”å¿…é¡»å®Œå…¨åŸºäºæ–‡æ¡£å†…å®¹æ¥æ»¡è¶³ç”¨æˆ·è¯·æ±‚ã€‚</li>
<li>æ¨¡å‹è¯„ä¼°åˆ†ä¸ºä¸¤ä¸ªé˜¶æ®µï¼šé¦–å…ˆç­›é€‰ä¸æ»¡è¶³ç”¨æˆ·éœ€æ±‚çš„å“åº”ï¼Œç„¶ååˆ¤æ–­å“åº”æ˜¯å¦å®Œå…¨åŸºäºæ–‡æ¡£ã€‚</li>
<li>è‡ªåŠ¨åŒ–åˆ¤æ–­æ¨¡å‹ç»è¿‡å¹¿æ³›è¯„ä¼°ä»¥ç¡®å®šæœ€ä½³æç¤ºæ¨¡æ¿ï¼Œå‡å°‘è¯„ä¼°åè§ã€‚</li>
<li>FACTS Groundingæ’è¡Œæ¦œå°†é•¿æœŸç»´æŠ¤å¹¶å…¬å¼€éƒ¨åˆ†ç»“æœä»¥é¼“åŠ±å¤–éƒ¨å‚ä¸åŒæ—¶ä¿è¯å…¬å¹³æ€§ã€‚å¯ä»¥åœ¨ç‰¹å®šç½‘ç«™æ‰¾åˆ°è¯¥æ’è¡Œæ¦œã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.03200">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-ea14ad3ec3c48fc25b4e784bce58b274.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-9d4f1ecc143cc7e802d07cf39322e570.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-706e3d355460e56a4338fd5592023eb8.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-03dae65966eeab3606d6a85b48c45803.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b188bb028e75dbb25072f5355c6bd8d1.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="Semantic-Captioning-Benchmark-Dataset-and-Graph-Aware-Few-Shot-In-Context-Learning-for-SQL2Text"><a href="#Semantic-Captioning-Benchmark-Dataset-and-Graph-Aware-Few-Shot-In-Context-Learning-for-SQL2Text" class="headerlink" title="Semantic Captioning: Benchmark Dataset and Graph-Aware Few-Shot   In-Context Learning for SQL2Text"></a>Semantic Captioning: Benchmark Dataset and Graph-Aware Few-Shot   In-Context Learning for SQL2Text</h2><p><strong>Authors:Ali Al-Lawati, Jason Lucas, Prasenjit Mitra</strong></p>
<p>Large Language Models (LLMs) have demonstrated remarkable performance in various NLP tasks, including semantic parsing, which trans lates natural language into formal code representations. However, the reverse process, translating code into natural language, termed semantic captioning, has received less attention. This task is becoming increasingly important as LLMs are integrated into platforms for code generation, security analysis, and educational purposes. In this paper, we focus on the captioning of SQL query (SQL2Text) to address the critical need for understanding and explaining SQL queries in an era where LLM-generated code poses potential security risks. We repurpose Text2SQL datasets for SQL2Text by introducing an iterative ICL prompt using GPT-4o to generate multiple additional utterances, which enhances the robustness of the datasets for the reverse task. We conduct our experiments using in-context learning (ICL) based on different sample selection methods, emphasizing smaller, more computationally efficient LLMs. Our findings demonstrate that leveraging the inherent graph properties of SQL for ICL sample selection significantly outperforms random selection by up to 39% on BLEU score and provides better results than alternative methods. Dataset and codes are published: \url{<a target="_blank" rel="noopener" href="https://github.com/aliwister/ast-icl%7D">https://github.com/aliwister/ast-icl}</a>. </p>
<blockquote>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨å„ç§è‡ªç„¶è¯­è¨€å¤„ç†ä»»åŠ¡ä¸­è¡¨ç°å‡ºäº†æ˜¾è‘—çš„æ€§èƒ½ï¼ŒåŒ…æ‹¬å°†è‡ªç„¶è¯­è¨€è½¬æ¢ä¸ºæ­£å¼ä»£ç è¡¨ç¤ºçš„è¯­ä¹‰è§£æã€‚ç„¶è€Œï¼Œå°†ä»£ç è½¬æ¢ä¸ºè‡ªç„¶è¯­è¨€çš„é€†å‘è¿‡ç¨‹ï¼Œå³è¯­ä¹‰å­—å¹•ï¼Œå—åˆ°çš„å…³æ³¨åº¦è¾ƒä½ã€‚éšç€LLMè¢«é›†æˆåˆ°ä»£ç ç”Ÿæˆã€å®‰å…¨åˆ†æå’Œæ•™è‚²å¹³å°ï¼Œè¿™é¡¹ä»»åŠ¡å˜å¾—è¶Šæ¥è¶Šé‡è¦ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬å…³æ³¨SQLæŸ¥è¯¢çš„å­—å¹•ï¼ˆSQL2Textï¼‰ï¼Œä»¥è§£å†³åœ¨LLMç”Ÿæˆçš„ä»£ç å¯èƒ½å¸¦æ¥æ½œåœ¨å®‰å…¨é£é™©çš„æ—¶ä»£ï¼Œç†è§£å’Œè§£é‡ŠSQLæŸ¥è¯¢çš„è¿«åˆ‡éœ€æ±‚ã€‚æˆ‘ä»¬é€šè¿‡å¯¹GPT-4oå¼•å…¥è¿­ä»£ICLæç¤ºæ¥é‡æ–°åˆ©ç”¨Text2SQLæ•°æ®é›†è¿›è¡ŒSQL2Textï¼Œç”Ÿæˆå¤šä¸ªé™„åŠ è¯è¯­ï¼Œå¢å¼ºäº†åå‘ä»»åŠ¡çš„æ•°æ®é›†ç¨³å¥æ€§ã€‚æˆ‘ä»¬çš„å®éªŒé‡‡ç”¨åŸºäºä¸åŒæ ·æœ¬é€‰æ‹©æ–¹æ³•çš„ä¸Šä¸‹æ–‡å­¦ä¹ ï¼ˆICLï¼‰ï¼Œå¼ºè°ƒæ›´å°ã€æ›´èŠ‚çœè®¡ç®—èµ„æºçš„å°å‹LLMã€‚ç ”ç©¶ç»“æœè¡¨æ˜ï¼Œåˆ©ç”¨SQLçš„å†…åœ¨å›¾å½¢å±æ€§è¿›è¡ŒICLæ ·æœ¬é€‰æ‹©æ˜¾è‘—ä¼˜äºéšæœºé€‰æ‹©ï¼ŒBLEUåˆ†æ•°æœ€é«˜å¯æé«˜39%ï¼Œå¹¶ä¸”æ¯”å…¶ä»–æ–¹æ³•æä¾›æ›´å¥½çš„ç»“æœã€‚æ•°æ®é›†å’Œä»£ç å·²å‘å¸ƒï¼š<a target="_blank" rel="noopener" href="https://github.com/aliwister/ast-icl%E3%80%82">https://github.com/aliwister/ast-iclã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.03166v1">PDF</a> Accepted to COLINGâ€™25</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æ¢è®¨äº†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨è¯­ä¹‰æ ‡æ³¨ä»»åŠ¡ä¸­çš„åº”ç”¨ï¼Œç‰¹åˆ«æ˜¯é’ˆå¯¹SQLæŸ¥è¯¢çš„æ ‡æ³¨ï¼ˆSQL2Textï¼‰ã€‚é’ˆå¯¹LLMç”Ÿæˆçš„ä»£ç å¯èƒ½å¸¦æ¥çš„æ½œåœ¨å®‰å…¨é£é™©ï¼Œè¯¥æ–‡æå‡ºäº†åˆ©ç”¨GPT-4oç”Ÿæˆå¤šç§é¢å¤–è¡¨è¿°æ¥å¢å¼ºæ•°æ®é›†é²æ£’æ€§çš„æ–¹æ³•ã€‚é€šè¿‡åŸºäºä¸åŒæ ·æœ¬é€‰æ‹©æ–¹æ³•çš„ä¸Šä¸‹æ–‡å­¦ä¹ ï¼ˆICLï¼‰å®éªŒï¼Œç»“æœæ˜¾ç¤ºåˆ©ç”¨SQLçš„å†…åœ¨å›¾å±æ€§è¿›è¡ŒICLæ ·æœ¬é€‰æ‹©æ˜¾è‘—ä¼˜äºéšæœºé€‰æ‹©ï¼ŒBLEUåˆ†æ•°æé«˜äº†é«˜è¾¾39%ã€‚ç›¸å…³æ•°æ®é›†å’Œä»£ç å·²å…¬å¼€å‘å¸ƒã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>LLMåœ¨è¯­ä¹‰æ ‡æ³¨ä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ï¼Œç‰¹åˆ«æ˜¯åœ¨å°†è‡ªç„¶è¯­è¨€è½¬åŒ–ä¸ºä»£ç è¡¨ç¤ºæ–¹é¢ã€‚</li>
<li>SQLæŸ¥è¯¢æ ‡æ³¨ï¼ˆSQL2Textï¼‰æ˜¯ä¸€ä¸ªå…³é”®éœ€æ±‚ï¼Œæœ‰åŠ©äºç†è§£å’Œè§£é‡ŠSQLæŸ¥è¯¢ã€‚</li>
<li>LLMç”Ÿæˆçš„ä»£ç å¯èƒ½å¸¦æ¥æ½œåœ¨å®‰å…¨é£é™©ï¼Œéœ€è¦æœ‰æ•ˆæ ‡æ³¨ä»¥åº”å¯¹ã€‚</li>
<li>åˆ©ç”¨GPT-4oç”Ÿæˆå¤šç§é¢å¤–è¡¨è¿°æ¥å¢å¼ºæ•°æ®é›†é²æ£’æ€§ã€‚</li>
<li>é€šè¿‡åŸºäºä¸åŒæ ·æœ¬é€‰æ‹©æ–¹æ³•çš„ä¸Šä¸‹æ–‡å­¦ä¹ ï¼ˆICLï¼‰å®éªŒéªŒè¯æ–¹æ³•æœ‰æ•ˆæ€§ã€‚</li>
<li>åˆ©ç”¨SQLçš„å†…åœ¨å›¾å±æ€§è¿›è¡ŒICLæ ·æœ¬é€‰æ‹©æ˜¾è‘—ä¼˜äºéšæœºé€‰æ‹©ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.03166">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-26fb357827978697f05a64db295a6a1b.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-99b3b8bfbaa07b56c9cd7ac29d35a5e7.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-9160cd6db4dc6a9866e9a383d80a8947.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-aa801f8289f43e48bb19dbe024fb5efe.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="Large-language-models-for-artificial-general-intelligence-AGI-A-survey-of-foundational-principles-and-approaches"><a href="#Large-language-models-for-artificial-general-intelligence-AGI-A-survey-of-foundational-principles-and-approaches" class="headerlink" title="Large language models for artificial general intelligence (AGI): A   survey of foundational principles and approaches"></a>Large language models for artificial general intelligence (AGI): A   survey of foundational principles and approaches</h2><p><strong>Authors:Alhassan Mumuni, Fuseini Mumuni</strong></p>
<p>Generative artificial intelligence (AI) systems based on large-scale pretrained foundation models (PFMs) such as vision-language models, large language models (LLMs), diffusion models and vision-language-action (VLA) models have demonstrated the ability to solve complex and truly non-trivial AI problems in a wide variety of domains and contexts. Multimodal large language models (MLLMs), in particular, learn from vast and diverse data sources, allowing rich and nuanced representations of the world and, thereby, providing extensive capabilities, including the ability to reason, engage in meaningful dialog; collaborate with humans and other agents to jointly solve complex problems; and understand social and emotional aspects of humans. Despite this impressive feat, the cognitive abilities of state-of-the-art LLMs trained on large-scale datasets are still superficial and brittle. Consequently, generic LLMs are severely limited in their generalist capabilities. A number of foundational problems â€“ embodiment, symbol grounding, causality and memory â€“ are required to be addressed for LLMs to attain human-level general intelligence. These concepts are more aligned with human cognition and provide LLMs with inherent human-like cognitive properties that support the realization of physically-plausible, semantically meaningful, flexible and more generalizable knowledge and intelligence. In this work, we discuss the aforementioned foundational issues and survey state-of-the art approaches for implementing these concepts in LLMs. Specifically, we discuss how the principles of embodiment, symbol grounding, causality and memory can be leveraged toward the attainment of artificial general intelligence (AGI) in an organic manner. </p>
<blockquote>
<p>åŸºäºå¤§è§„æ¨¡é¢„è®­ç»ƒåŸºç¡€æ¨¡å‹ï¼ˆPFMsï¼‰çš„ç”Ÿæˆå¼äººå·¥æ™ºèƒ½ï¼ˆAIï¼‰ç³»ç»Ÿï¼Œå¦‚è§†è§‰è¯­è¨€æ¨¡å‹ã€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ã€æ‰©æ•£æ¨¡å‹å’Œè§†è§‰è¯­è¨€è¡ŒåŠ¨ï¼ˆVLAï¼‰æ¨¡å‹ç­‰ï¼Œå·²è¯æ˜èƒ½å¤Ÿåœ¨å¹¿æ³›é¢†åŸŸå’ŒèƒŒæ™¯ä¸‹è§£å†³å¤æ‚ä¸”éå¹³å‡¡çš„äººå·¥æ™ºèƒ½é—®é¢˜ã€‚ç‰¹åˆ«æ˜¯å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰ï¼Œå®ƒä»¬ä»å¤§é‡å¤šæ ·åŒ–çš„æ•°æ®æºä¸­å­¦ä¹ ï¼Œå…è®¸å¯¹ä¸–ç•Œçš„ä¸°å¯Œå’Œç»†å¾®è¡¨ç¤ºï¼Œå› æ­¤æä¾›äº†å¹¿æ³›çš„èƒ½åŠ›ï¼ŒåŒ…æ‹¬æ¨ç†ã€è¿›è¡Œæœ‰æ„ä¹‰çš„å¯¹è¯ã€ä¸äººç±»å’Œå…¶ä»–ä»£ç†åä½œä»¥å…±åŒè§£å†³å¤æ‚é—®é¢˜ä»¥åŠç†è§£äººç±»çš„ç¤¾ä¼šå’Œæƒ…æ„Ÿæ–¹é¢ã€‚å°½ç®¡å¦‚æ­¤ï¼Œå°½ç®¡æœ€å…ˆè¿›çš„LLMsåœ¨å¤§å‹æ•°æ®é›†ä¸Šè®­ç»ƒå‡ºäº†ä»¤äººå°è±¡æ·±åˆ»çš„è®¤çŸ¥èƒ½åŠ›ï¼Œä½†è¿™äº›èƒ½åŠ›ä»ç„¶æ˜¯è‚¤æµ…å’Œè„†å¼±çš„ã€‚å› æ­¤ï¼Œé€šç”¨LLMsåœ¨å…¶é€šç”¨èƒ½åŠ›æ–¹é¢å—åˆ°ä¸¥é‡é™åˆ¶ã€‚è¦è§£å†³LLMsè¾¾åˆ°äººç±»æ°´å¹³çš„é€šç”¨æ™ºèƒ½ï¼Œéœ€è¦è§£å†³ä¸€ç³»åˆ—åŸºç¡€é—®é¢˜ï¼ŒåŒ…æ‹¬å…·ä½“åŒ–ã€ç¬¦å·æ¥åœ°ã€å› æœå…³ç³»å’Œè®°å¿†ã€‚è¿™äº›é—®é¢˜æ›´ç¬¦åˆäººç±»è®¤çŸ¥ï¼Œä¸ºLLMsæä¾›å›ºæœ‰çš„ç±»ä¼¼äººç±»çš„è®¤çŸ¥å±æ€§ï¼Œæ”¯æŒå®ç°ç‰©ç†ä¸Šå¯ä¿¡ã€è¯­ä¹‰ä¸Šæœ‰æ„ä¹‰ã€çµæ´»å’Œæ›´å…·é€šç”¨æ€§çš„çŸ¥è¯†å’Œæ™ºèƒ½ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬è®¨è®ºäº†ä¸Šè¿°åŸºç¡€é—®é¢˜ï¼Œå¹¶è°ƒæŸ¥äº†å®ç°LLMsä¸­è¿™äº›æ¦‚å¿µçš„æœ€æ–°æ–¹æ³•ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬è®¨è®ºäº†å¦‚ä½•ä»¥æœ‰æœºçš„æ–¹å¼åˆ©ç”¨å…·ä½“åŒ–ã€ç¬¦å·æ¥åœ°ã€å› æœå…³ç³»å’Œè®°å¿†çš„åŸåˆ™æ¥å®ç°äººå·¥æ™ºèƒ½é€šç”¨æ™ºèƒ½ï¼ˆAGIï¼‰ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.03151v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>åŸºäºå¤§è§„æ¨¡é¢„è®­ç»ƒåŸºç¡€æ¨¡å‹ï¼ˆPFMsï¼‰çš„ç”Ÿæˆäººå·¥æ™ºèƒ½ï¼ˆAIï¼‰ç³»ç»Ÿï¼Œå¦‚è§†è§‰è¯­è¨€æ¨¡å‹ã€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ã€æ‰©æ•£æ¨¡å‹å’Œè§†è§‰è¯­è¨€åŠ¨ä½œï¼ˆVLAï¼‰æ¨¡å‹ï¼Œèƒ½å¤Ÿåœ¨å¤šç§é¢†åŸŸå’Œä¸Šä¸‹æ–‡ä¸­è§£å†³å¤æ‚ä¸”éå¸¸è§„çš„AIé—®é¢˜ã€‚å°¤å…¶æ˜¯å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰ï¼Œèƒ½å¤Ÿä»åºå¤§å’Œå¤šæ ·åŒ–çš„æ•°æ®æºä¸­å­¦ä¹ ï¼Œæä¾›ä¸°å¯Œçš„ä¸–ç•Œè¡¨ç¤ºï¼Œå¹¶å…·å¤‡æ¨ç†ã€å‚ä¸æœ‰æ„ä¹‰çš„å¯¹è¯ã€ä¸äººç±»å’Œå…¶ä»–æ™ºèƒ½ä½“åä½œè§£å†³å¤æ‚é—®é¢˜ä»¥åŠç†è§£äººç±»ç¤¾äº¤å’Œæƒ…æ„Ÿæ–¹é¢çš„èƒ½åŠ›ã€‚ç„¶è€Œï¼Œå½“å‰å…ˆè¿›çš„å¤§å‹è¯­è¨€æ¨¡å‹çš„è®¤çŸ¥èƒ½åŠ›ä»ç„¶è‚¤æµ…ä¸”è„†å¼±ï¼Œå…¶é€šç”¨èƒ½åŠ›å—åˆ°ä¸¥é‡é™åˆ¶ã€‚è¦å®ç°äººç±»æ°´å¹³çš„é€šç”¨æ™ºèƒ½ï¼Œå¿…é¡»è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹çš„åŸºç¡€é—®é¢˜ï¼Œå¦‚å®ä½“æ€§ã€ç¬¦å·æ¥åœ°ã€å› æœå…³ç³»å’Œè®°å¿†ç­‰ã€‚æœ¬æ–‡è®¨è®ºäº†ä¸Šè¿°é—®é¢˜ï¼Œå¹¶æ¦‚è¿°äº†å®ç°è¿™äº›æ¦‚å¿µåœ¨å¤§å‹è¯­è¨€æ¨¡å‹ä¸­çš„æœ€æ–°æ–¹æ³•ã€‚ç‰¹åˆ«æ˜¯ï¼Œæˆ‘ä»¬è®¨è®ºäº†å¦‚ä½•åˆ©ç”¨å®ä½“æ€§ã€ç¬¦å·æ¥åœ°ã€å› æœå…³ç³»å’Œè®°å¿†çš„åŸåˆ™ä»¥æœ‰æœºçš„æ–¹å¼å®ç°äººå·¥æ™ºèƒ½é€šç”¨æ™ºèƒ½ï¼ˆAGIï¼‰ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ç”Ÿæˆäººå·¥æ™ºèƒ½ç³»ç»ŸåŸºäºå¤§è§„æ¨¡é¢„è®­ç»ƒåŸºç¡€æ¨¡å‹ï¼Œèƒ½å¤Ÿåœ¨å¤šä¸ªé¢†åŸŸè§£å†³å¤æ‚å’Œéå¹³å‡¡çš„AIé—®é¢˜ã€‚</li>
<li>å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰å¯ä»¥ä»å¤šæ ·åŒ–å’Œå¤§è§„æ¨¡çš„æ•°æ®æºä¸­å­¦ä¹ ï¼Œæä¾›ä¸°å¯Œçš„ä¸–ç•Œè¡¨ç¤ºã€‚</li>
<li>MLLMså…·å¤‡æ¨ç†ã€å¯¹è¯ã€åä½œä»¥åŠç†è§£äººç±»ç¤¾äº¤å’Œæƒ…æ„Ÿæ–¹é¢çš„èƒ½åŠ›ã€‚</li>
<li>å½“å‰å¤§å‹è¯­è¨€æ¨¡å‹çš„è®¤çŸ¥èƒ½åŠ›ä»ç„¶è‚¤æµ…ä¸”è„†å¼±ï¼Œå…¶é€šç”¨èƒ½åŠ›å—é™ã€‚</li>
<li>å®ç°äººç±»æ°´å¹³çš„é€šç”¨æ™ºèƒ½éœ€è¦è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹çš„åŸºç¡€é—®é¢˜ï¼Œå¦‚å®ä½“æ€§ã€ç¬¦å·æ¥åœ°ã€å› æœå…³ç³»å’Œè®°å¿†ã€‚</li>
<li>å®ä½“æ€§ã€ç¬¦å·æ¥åœ°ã€å› æœå…³ç³»å’Œè®°å¿†ç­‰æ¦‚å¿µå¯¹äºæé«˜å¤§å‹è¯­è¨€æ¨¡å‹çš„è®¤çŸ¥èƒ½åŠ›è‡³å…³é‡è¦ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.03151">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-a6c4bc2390842e3a8b5bfe9ff6794bbf.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-c75c99561b17f4b6d1993b3e4a9f7028.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-491f714b606ea2f4e6ea88081c0581ac.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c93a8a02d9e84ee26df479b355a1d301.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="VicSim-Enhancing-Victim-Simulation-with-Emotional-and-Linguistic-Fidelity"><a href="#VicSim-Enhancing-Victim-Simulation-with-Emotional-and-Linguistic-Fidelity" class="headerlink" title="VicSim: Enhancing Victim Simulation with Emotional and Linguistic   Fidelity"></a>VicSim: Enhancing Victim Simulation with Emotional and Linguistic   Fidelity</h2><p><strong>Authors:Yerong Li, Yiren Liu, Yun Huang</strong></p>
<p>Scenario-based training has been widely adopted in many public service sectors. Recent advancements in Large Language Models (LLMs) have shown promise in simulating diverse personas to create these training scenarios. However, little is known about how LLMs can be developed to simulate victims for scenario-based training purposes. In this paper, we introduce VicSim (victim simulator), a novel model that addresses three key dimensions of user simulation: informational faithfulness, emotional dynamics, and language style (e.g., grammar usage). We pioneer the integration of scenario-based victim modeling with GAN-based training workflow and key-information-based prompting, aiming to enhance the realism of simulated victims. Our adversarial training approach teaches the discriminator to recognize grammar and emotional cues as reliable indicators of synthetic content. According to evaluations by human raters, the VicSim model outperforms GPT-4 in terms of human-likeness. </p>
<blockquote>
<p>æƒ…æ™¯æ¨¡æ‹Ÿè®­ç»ƒå·²åœ¨è®¸å¤šå…¬å…±æœåŠ¡é¢†åŸŸå¾—åˆ°å¹¿æ³›åº”ç”¨ã€‚è¿‘æœŸå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„è¿›æ­¥åœ¨æ¨¡æ‹Ÿå¤šç§è§’è‰²ä»¥åˆ›å»ºè¿™äº›è®­ç»ƒåœºæ™¯æ–¹é¢æ˜¾ç¤ºå‡ºå¸Œæœ›ã€‚ç„¶è€Œï¼Œå…³äºå¦‚ä½•å¼€å‘LLMæ¥æ¨¡æ‹Ÿå—å®³è€…ä»¥è¿›è¡ŒåŸºäºæƒ…æ™¯çš„è®­ç»ƒç›®çš„çš„ç ”ç©¶å´çŸ¥ä¹‹ç”šå°‘ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬ä»‹ç»äº†VicSimï¼ˆå—å®³è€…æ¨¡æ‹Ÿå™¨ï¼‰ï¼Œè¿™æ˜¯ä¸€ç§æ–°å‹æ¨¡å‹ï¼Œè§£å†³äº†ç”¨æˆ·æ¨¡æ‹Ÿçš„ä¸‰ä¸ªå…³é”®ç»´åº¦ï¼šä¿¡æ¯çœŸå®æ€§ã€æƒ…æ„ŸåŠ¨æ€å’Œè¯­è¨€é£æ ¼ï¼ˆä¾‹å¦‚è¯­æ³•ä½¿ç”¨ï¼‰ã€‚æˆ‘ä»¬é¦–åˆ›äº†åŸºäºæƒ…æ™¯çš„å—å®³è€…å»ºæ¨¡ä¸åŸºäºGANçš„è®­ç»ƒå·¥ä½œæµç¨‹å’ŒåŸºäºå…³é”®ä¿¡æ¯çš„æç¤ºçš„é›†æˆï¼Œæ—¨åœ¨æé«˜æ¨¡æ‹Ÿå—å®³è€…çš„çœŸå®æ€§ã€‚æˆ‘ä»¬çš„å¯¹æŠ—è®­ç»ƒæ³•æ•™ä¼šåˆ¤åˆ«å™¨è¯†åˆ«è¯­æ³•å’Œæƒ…æ„Ÿçº¿ç´¢ï¼Œä½œä¸ºåˆæˆå†…å®¹å¯é æŒ‡æ ‡ã€‚æ ¹æ®äººç±»è¯„ä¼°è€…çš„è¯„ä¼°ï¼ŒVicSimæ¨¡å‹åœ¨æ‹ŸäººåŒ–æ–¹é¢ä¼˜äºGPT-4ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.03139v1">PDF</a> 21 pages, 10 figures</p>
<p><strong>Summary</strong></p>
<p>åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„æƒ…å¢ƒæ¨¡æ‹Ÿè®­ç»ƒå·²å¹¿æ³›åº”ç”¨äºå…¬å…±æœåŠ¡é¢†åŸŸã€‚æœ¬æ–‡ä»‹ç»äº†ä¸€ç§æ–°å‹å—å®³è€…æ¨¡æ‹Ÿå™¨ï¼ˆVicSimï¼‰ï¼Œå®ƒèƒ½å¤Ÿæ¨¡æ‹Ÿå—å®³è€…çš„ä¿¡æ¯çœŸå®æ€§ã€æƒ…æ„ŸåŠ¨æ€å’Œè¯­è¨€é£æ ¼ã€‚VicSimç»“åˆäº†åŸºäºåœºæ™¯çš„å—å®³è€…å»ºæ¨¡ã€åŸºäºGANçš„è®­ç»ƒæµç¨‹å’ŒåŸºäºå…³é”®ä¿¡æ¯çš„æç¤ºæŠ€æœ¯ï¼Œä»¥æé«˜æ¨¡æ‹Ÿå—å®³è€…çš„é€¼çœŸåº¦ã€‚å…¶å¯¹æŠ—æ€§è®­ç»ƒä½¿åˆ¤åˆ«å™¨èƒ½å¤Ÿè¯†åˆ«è¯­æ³•å’Œæƒ…æ„Ÿçº¿ç´¢ï¼Œä½œä¸ºåˆæˆå†…å®¹å¯é æŒ‡æ ‡ã€‚æ®äººç±»è¯„ä¼°è€…è¯„ä»·ï¼ŒVicSimæ¨¡å‹åœ¨äººæ€§åŒ–æ–¹é¢ä¼˜äºGPT-4ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>LLMså·²å¹¿æ³›åº”ç”¨äºå…¬å…±æœåŠ¡é¢†åŸŸçš„æƒ…å¢ƒæ¨¡æ‹Ÿè®­ç»ƒã€‚</li>
<li>VicSimæ˜¯ä¸€ç§æ–°å‹å—å®³è€…æ¨¡æ‹Ÿå™¨ï¼Œèƒ½æ¨¡æ‹Ÿå—å®³è€…çš„ä¿¡æ¯çœŸå®æ€§ã€æƒ…æ„ŸåŠ¨æ€å’Œè¯­è¨€é£æ ¼ã€‚</li>
<li>VicSimç»“åˆäº†åœºæ™¯å—å®³è€…å»ºæ¨¡ã€åŸºäºGANçš„è®­ç»ƒæµç¨‹å’Œå…³é”®ä¿¡æ¯æç¤ºæŠ€æœ¯ã€‚</li>
<li>å¯¹æŠ—æ€§è®­ç»ƒä½¿åˆ¤åˆ«å™¨èƒ½å¤Ÿè¯†åˆ«è¯­æ³•å’Œæƒ…æ„Ÿçº¿ç´¢ï¼Œä½œä¸ºåˆæˆå†…å®¹çš„å¯é æŒ‡æ ‡ã€‚</li>
<li>VicSimåœ¨æ¨¡æ‹Ÿå—å®³è€…çš„é€¼çœŸåº¦æ–¹é¢è¶…è¶Šäº†GPT-4ã€‚<br>6.VicSimæ¨¡å‹åœ¨æƒ…å¢ƒæ¨¡æ‹Ÿè®­ç»ƒä¸­å…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ï¼Œå°¤å…¶æ˜¯åœ¨å…¬å…±æœåŠ¡é¢†åŸŸã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.03139">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-2efd92c0882b778af27fd07c3e688b27.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-a8dcc57bde9f1d72d191497f48e5610e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-bf83ce1d508141a6a7d5c9790a7186a8.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="Retrieval-Augmented-TLAPS-Proof-Generation-with-Large-Language-Models"><a href="#Retrieval-Augmented-TLAPS-Proof-Generation-with-Large-Language-Models" class="headerlink" title="Retrieval-Augmented TLAPS Proof Generation with Large Language Models"></a>Retrieval-Augmented TLAPS Proof Generation with Large Language Models</h2><p><strong>Authors:Yuhao Zhou</strong></p>
<p>We present a novel approach to automated proof generation for the TLA+ Proof System (TLAPS) using Large Language Models (LLMs). Our method combines two key components: a sub-proof obligation generation phase that breaks down complex proof obligations into simpler sub-obligations, and a proof generation phase that leverages Retrieval-Augmented Generation with verified proof examples. We evaluate our approach using proof obligations from varying complexity levels of proof obligations, spanning from fundamental arithmetic properties to the properties of algorithms. Our experiments demonstrate that while the method successfully generates valid proofs for intermediate-complexity obligations, it faces limitations with more complex theorems. These results indicate that our approach can effectively assist in proof development for certain classes of properties, contributing to the broader goal of integrating LLMs into formal verification workflows. </p>
<blockquote>
<p>æˆ‘ä»¬æå‡ºäº†ä¸€ç§åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä¸ºTLA+è¯æ˜ç³»ç»Ÿï¼ˆTLAPSï¼‰è‡ªåŠ¨ç”Ÿæˆè¯æ˜çš„æ–°æ–¹æ³•ã€‚æˆ‘ä»¬çš„æ–¹æ³•ç»“åˆäº†ä¸¤ä¸ªå…³é”®ç»„æˆéƒ¨åˆ†ï¼šä¸€ä¸ªå­è¯æ˜ä¹‰åŠ¡ç”Ÿæˆé˜¶æ®µï¼Œè¯¥é˜¶æ®µå°†å¤æ‚çš„è¯æ˜ä¹‰åŠ¡åˆ†è§£ä¸ºæ›´ç®€å•çš„å­ä¹‰åŠ¡ï¼›ä»¥åŠä¸€ä¸ªåˆ©ç”¨æ£€ç´¢å¢å¼ºç”Ÿæˆæ³•åŠ ä¸Šå·²éªŒè¯è¯æ˜èŒƒä¾‹çš„è¯æ˜ç”Ÿæˆé˜¶æ®µã€‚æˆ‘ä»¬é€šè¿‡å¯¹ä¸åŒå¤æ‚ç¨‹åº¦çš„è¯æ˜ä¹‰åŠ¡è¿›è¡Œè¯„ä¼°æ¥æ£€éªŒæˆ‘ä»¬çš„æ–¹æ³•ï¼Œè¿™äº›è¯æ˜ä¹‰åŠ¡æ¶µç›–äº†ä»åŸºæœ¬çš„ç®—æœ¯å±æ€§åˆ°ç®—æ³•å±æ€§ã€‚å®éªŒè¡¨æ˜ï¼Œè™½ç„¶è¯¥æ–¹æ³•æˆåŠŸä¸ºä¸­ç­‰å¤æ‚åº¦çš„ä¹‰åŠ¡ç”Ÿæˆäº†æœ‰æ•ˆè¯æ˜ï¼Œä½†åœ¨å¤„ç†æ›´å¤æ‚çš„å®šç†æ—¶ä»é¢ä¸´å±€é™ã€‚è¿™äº›ç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•å¯ä»¥æœ‰æ•ˆåœ°å¸®åŠ©å¼€å‘æŸäº›ç±»åˆ«çš„å±æ€§è¯æ˜ï¼Œä¸ºå®ç°å°†LLMæ•´åˆåˆ°å½¢å¼åŒ–éªŒè¯å·¥ä½œæµä¸­çš„æ›´å¹¿æ³›ç›®æ ‡åšå‡ºè´¡çŒ®ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.03073v1">PDF</a> </p>
<p><strong>æ‘˜è¦</strong><br>é’ˆå¯¹TLA+è¯æ˜ç³»ç»Ÿï¼ˆTLAPSï¼‰çš„è‡ªåŠ¨åŒ–è¯æ˜ç”Ÿæˆï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§ä½¿ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„æ–°æ–¹æ³•ã€‚è¯¥æ–¹æ³•ç»“åˆäº†ä¸¤ä¸ªå…³é”®ç»„æˆéƒ¨åˆ†ï¼šä¸€ä¸ªå­è¯æ˜ä¹‰åŠ¡ç”Ÿæˆé˜¶æ®µï¼Œå°†å¤æ‚çš„è¯æ˜ä¹‰åŠ¡åˆ†è§£æˆæ›´ç®€å•çš„å­ä¹‰åŠ¡ï¼›ä»¥åŠä¸€ä¸ªåˆ©ç”¨å¸¦æœ‰éªŒè¯è¯æ˜ç¤ºä¾‹çš„æ£€ç´¢å¢å¼ºç”Ÿæˆçš„è¯æ˜ç”Ÿæˆé˜¶æ®µã€‚æˆ‘ä»¬é€šè¿‡å¯¹ä¸åŒå¤æ‚ç¨‹åº¦çš„è¯æ˜ä¹‰åŠ¡è¿›è¡Œå®éªŒè¯„ä¼°ï¼Œä»åŸºæœ¬çš„ç®—æœ¯å±æ€§åˆ°ç®—æ³•å±æ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•è™½ç„¶èƒ½æˆåŠŸä¸ºä¸­ç­‰å¤æ‚åº¦çš„ä¹‰åŠ¡ç”Ÿæˆæœ‰æ•ˆè¯æ˜ï¼Œä½†åœ¨å¤„ç†æ›´å¤æ‚å®šç†æ—¶å­˜åœ¨å±€é™æ€§ã€‚è¿™äº›ç»“æœè¯´æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•å¯ä»¥æœ‰æ•ˆåœ°ååŠ©æŸäº›ç±»åˆ«å±æ€§çš„è¯æ˜å¼€å‘ï¼Œæœ‰åŠ©äºå°†å¤§å‹è¯­è¨€æ¨¡å‹é›†æˆåˆ°å½¢å¼åŒ–éªŒè¯å·¥ä½œæµç¨‹ä¸­çš„æ›´å¹¿æ³›ç›®æ ‡ã€‚</p>
<p><strong>å…³é”®è§è§£</strong></p>
<ol>
<li>æå‡ºäº†ä¸€ç§ç»“åˆå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„æ–°æ–¹æ³•ï¼Œç”¨äºTLA+è¯æ˜ç³»ç»Ÿçš„è‡ªåŠ¨åŒ–è¯æ˜ç”Ÿæˆã€‚</li>
<li>æ–¹æ³•åŒ…æ‹¬å­è¯æ˜ä¹‰åŠ¡ç”Ÿæˆé˜¶æ®µå’Œè¯æ˜ç”Ÿæˆé˜¶æ®µã€‚</li>
<li>å­è¯æ˜ä¹‰åŠ¡ç”Ÿæˆé˜¶æ®µå°†å¤æ‚è¯æ˜ä¹‰åŠ¡åˆ†è§£ä¸ºæ›´ç®€å•çš„å­ä¹‰åŠ¡ã€‚</li>
<li>è¯æ˜ç”Ÿæˆé˜¶æ®µåˆ©ç”¨å¸¦æœ‰éªŒè¯è¯æ˜ç¤ºä¾‹çš„æ£€ç´¢å¢å¼ºç”Ÿæˆã€‚</li>
<li>æ–¹æ³•æˆåŠŸä¸ºä¸­ç­‰å¤æ‚åº¦çš„ä¹‰åŠ¡ç”Ÿæˆæœ‰æ•ˆè¯æ˜ã€‚</li>
<li>åœ¨å¤„ç†æ›´å¤æ‚å®šç†æ—¶å­˜åœ¨å±€é™æ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.03073">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-eb667981c0772e5056571311d61b8966.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-bbf198f638b9b215fd003a50fde2003b.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-dd183b03930bd08893f6ef969ddf611b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-1ad9c7016997e8ba8d56abe6be18fe37.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="ChronoSense-Exploring-Temporal-Understanding-in-Large-Language-Models-with-Time-Intervals-of-Events"><a href="#ChronoSense-Exploring-Temporal-Understanding-in-Large-Language-Models-with-Time-Intervals-of-Events" class="headerlink" title="ChronoSense: Exploring Temporal Understanding in Large Language Models   with Time Intervals of Events"></a>ChronoSense: Exploring Temporal Understanding in Large Language Models   with Time Intervals of Events</h2><p><strong>Authors:Duygu Sezen Islakoglu, Jan-Christoph Kalo</strong></p>
<p>Large Language Models (LLMs) have achieved remarkable success in various NLP tasks, yet they still face significant challenges in reasoning and arithmetic. Temporal reasoning, a critical component of natural language understanding, has raised increasing research attention. However, comprehensive testing of Allenâ€™s interval relations (e.g., before, after, during) â€“ a fundamental framework for temporal relationships â€“ remains underexplored. To fill this gap, we present ChronoSense, a new benchmark for evaluating LLMsâ€™ temporal understanding. It includes 16 tasks, focusing on identifying the Allen relation between two temporal events and temporal arithmetic, using both abstract events and real-world data from Wikidata. We assess the performance of seven recent LLMs using this benchmark and the results indicate that models handle Allen relations, even symmetrical ones, quite differently. Moreover, the findings suggest that the models may rely on memorization to answer time-related questions. Overall, the modelsâ€™ low performance highlights the need for improved temporal understanding in LLMs and ChronoSense offers a robust framework for future research in this area. Our dataset and the source code are available at <a target="_blank" rel="noopener" href="https://github.com/duyguislakoglu/chronosense">https://github.com/duyguislakoglu/chronosense</a>. </p>
<blockquote>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨å„ç§NLPä»»åŠ¡ä¸­å–å¾—äº†æ˜¾è‘—çš„æˆåŠŸï¼Œä½†åœ¨æ¨ç†å’Œç®—æœ¯æ–¹é¢ä»é¢ä¸´é‡å¤§æŒ‘æˆ˜ã€‚æ—¶é—´æ¨ç†æ˜¯è‡ªç„¶è¯­è¨€ç†è§£çš„é‡è¦ç»„æˆéƒ¨åˆ†ï¼Œå·²ç»å¼•èµ·äº†è¶Šæ¥è¶Šå¤šçš„ç ”ç©¶å…³æ³¨ã€‚ç„¶è€Œï¼Œå…³äºè‰¾ä¼¦æ—¶é—´é—´éš”å…³ç³»ï¼ˆå¦‚ä¹‹å‰ã€ä¹‹åã€æœŸé—´ç­‰ï¼‰çš„å…¨é¢æµ‹è¯•â€”â€”æ—¶é—´å…³ç³»çš„åŸºæœ¬æ¡†æ¶â€”â€”ä»ç„¶è¢«æ¢ç´¢ä¸è¶³ã€‚ä¸ºäº†å¡«è¡¥è¿™ä¸€ç©ºç™½ï¼Œæˆ‘ä»¬æå‡ºäº†ChronoSenseï¼Œè¿™æ˜¯ä¸€ä¸ªç”¨äºè¯„ä¼°LLMæ—¶é—´ç†è§£çš„æ–°åŸºå‡†æµ‹è¯•ã€‚å®ƒåŒ…å«16ä¸ªä»»åŠ¡ï¼Œä¾§é‡äºè¯†åˆ«ä¸¤ä¸ªæ—¶é—´äº‹ä»¶ä¹‹é—´çš„è‰¾ä¼¦å…³ç³»å’Œæ—¶é—´ç®—æœ¯ï¼Œä½¿ç”¨æ¥è‡ªç»´åŸºç™¾ç§‘çš„æŠ½è±¡äº‹ä»¶å’Œç°å®ä¸–ç•Œæ•°æ®ã€‚æˆ‘ä»¬ä½¿ç”¨æ­¤åŸºå‡†æµ‹è¯•è¯„ä¼°äº†ä¸ƒä¸ªæœ€æ–°çš„LLMæ€§èƒ½ï¼Œç»“æœè¡¨æ˜ï¼Œæ¨¡å‹å¤„ç†è‰¾ä¼¦å…³ç³»ï¼Œç”šè‡³æ˜¯å¯¹ç§°å…³ç³»ï¼Œéƒ½æœ‰å¾ˆå¤§çš„å·®å¼‚ã€‚æ­¤å¤–ï¼Œç ”ç©¶ç»“æœè¿˜è¡¨æ˜ï¼Œæ¨¡å‹å¯èƒ½ä¾é è®°å¿†æ¥å›ç­”ä¸æ—¶é—´ç›¸å…³çš„é—®é¢˜ã€‚æ€»ä½“è€Œè¨€ï¼Œæ¨¡å‹çš„è¡¨ç°ä¸ä½³çªæ˜¾äº†æé«˜LLMæ—¶é—´ç†è§£çš„å¿…è¦æ€§ï¼Œè€ŒChronoSenseä¸ºè¿™ä¸€é¢†åŸŸçš„æœªæ¥ç ”ç©¶æä¾›äº†ç¨³å¥çš„æ¡†æ¶ã€‚æˆ‘ä»¬çš„æ•°æ®é›†å’Œæºä»£ç å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/duyguislakoglu/chronosense%E4%B8%8A%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/duyguislakoglu/chronosenseä¸Šæ‰¾åˆ°ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.03040v1">PDF</a> 14 pages, 2 figures</p>
<p><strong>Summary</strong></p>
<p>LLMsåœ¨NLPä»»åŠ¡ä¸­å–å¾—äº†æ˜¾è‘—æˆåŠŸï¼Œä½†åœ¨æ¨ç†å’Œç®—æœ¯æ–¹é¢ä»é¢ä¸´æŒ‘æˆ˜ã€‚é’ˆå¯¹æ—¶é—´æ¨ç†è¿™ä¸€è‡ªç„¶è¯­è¨€ç†è§£çš„å…³é”®ç»„æˆéƒ¨åˆ†ï¼Œæå‡ºäº†æ–°çš„è¯„ä»·åŸºå‡†ChronoSenseã€‚è¯¥åŸºå‡†åŒ…æ‹¬16é¡¹ä»»åŠ¡ï¼Œä¾§é‡äºè¯†åˆ«ä¸¤ä¸ªæ—¶é—´äº‹ä»¶ä¹‹é—´çš„Allenå…³ç³»å’Œæ—¶é—´ç®—æœ¯ï¼Œä½¿ç”¨æŠ½è±¡äº‹ä»¶å’Œæ¥è‡ªWikidataçš„å®æ—¶æ•°æ®ã€‚å¯¹ä¸ƒä¸ªæœ€æ–°LLMsçš„è¯„ä¼°ç»“æœè¡¨æ˜ï¼Œæ¨¡å‹åœ¨å¤„ç†Allenå…³ç³»ï¼ˆåŒ…æ‹¬å¯¹ç§°å…³ç³»ï¼‰æ—¶å­˜åœ¨æ˜¾è‘—å·®å¼‚ï¼Œä¸”å¯èƒ½ä¾èµ–è®°å¿†æ¥å›ç­”ä¸æ—¶é—´ç›¸å…³çš„é—®é¢˜ã€‚æ€»ä½“è€Œè¨€ï¼Œæ¨¡å‹åœ¨æ—¶ç©ºç†è§£æ–¹é¢çš„è¡¨ç°ä¸ä½³çªæ˜¾äº†æ”¹è¿›çš„å¿…è¦æ€§ï¼Œè€ŒChronoSenseä¸ºæœªæ¥çš„ç ”ç©¶æä¾›äº†ç¨³å¥çš„æ¡†æ¶ã€‚æ•°æ®é›†å’Œæºä»£ç å¯åœ¨GitHubä¸Šæ‰¾åˆ°ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>LLMsåœ¨è‡ªç„¶è¯­è¨€å¤„ç†ä»»åŠ¡ä¸­å–å¾—äº†æ˜¾è‘—è¿›å±•ï¼Œä½†åœ¨æ—¶é—´æ¨ç†æ–¹é¢ä»å­˜åœ¨æŒ‘æˆ˜ã€‚</li>
<li>ChronoSenseæ˜¯ä¸€ä¸ªæ–°çš„åŸºå‡†æµ‹è¯•ï¼Œæ—¨åœ¨è¯„ä¼°LLMsåœ¨æ—¶é—´ç†è§£æ–¹é¢çš„èƒ½åŠ›ï¼ŒåŒ…æ‹¬è¯†åˆ«Allenå…³ç³»å’Œæ—¶é—´ç®—æœ¯ã€‚</li>
<li>ChronoSenseåŒ…å«16é¡¹ä»»åŠ¡ï¼Œæ¶µç›–æŠ½è±¡äº‹ä»¶å’Œå®æ—¶æ•°æ®ã€‚</li>
<li>å¯¹å¤šä¸ªLLMsçš„è¯„ä¼°è¡¨æ˜ï¼Œåœ¨å¤„ç†Allenå…³ç³»æ—¶å­˜åœ¨å·®å¼‚ï¼Œä¸”å¯èƒ½è¿‡åº¦ä¾èµ–è®°å¿†ã€‚</li>
<li>LLMsåœ¨æ—¶ç©ºç†è§£æ–¹é¢çš„æ€§èƒ½ä¸ä½³çªæ˜¾äº†æ”¹è¿›çš„å¿…è¦æ€§ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.03040">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-b0a434c1bf8781bbf6ea5040698675b2.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-5dbfc7f96c1d8fd09df981285af4f3ad.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c7b55c1086fd754d6e08a62387bb4eb9.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-6ce8093d90b706f91b5c11c7d7e1b284.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ddcf49ea4038aec425c87b7cfd89cb9c.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="Empowering-Bengali-Education-with-AI-Solving-Bengali-Math-Word-Problems-through-Transformer-Models"><a href="#Empowering-Bengali-Education-with-AI-Solving-Bengali-Math-Word-Problems-through-Transformer-Models" class="headerlink" title="Empowering Bengali Education with AI: Solving Bengali Math Word Problems   through Transformer Models"></a>Empowering Bengali Education with AI: Solving Bengali Math Word Problems   through Transformer Models</h2><p><strong>Authors:Jalisha Jashim Era, Bidyarthi Paul, Tahmid Sattar Aothoi, Mirazur Rahman Zim, Faisal Muhammad Shah</strong></p>
<p>Mathematical word problems (MWPs) involve the task of converting textual descriptions into mathematical equations. This poses a significant challenge in natural language processing, particularly for low-resource languages such as Bengali. This paper addresses this challenge by developing an innovative approach to solving Bengali MWPs using transformer-based models, including Basic Transformer, mT5, BanglaT5, and mBART50. To support this effort, the â€œPatiGonitâ€ dataset was introduced, containing 10,000 Bengali math problems, and these models were fine-tuned to translate the word problems into equations accurately. The evaluation revealed that the mT5 model achieved the highest accuracy of 97.30%, demonstrating the effectiveness of transformer models in this domain. This research marks a significant step forward in Bengali natural language processing, offering valuable methodologies and resources for educational AI tools. By improving math education, it also supports the development of advanced problem-solving skills for Bengali-speaking students. </p>
<blockquote>
<p>æ•°å­¦æ–‡å­—é¢˜ï¼ˆMWPsï¼‰æ¶‰åŠå°†æ–‡æœ¬æè¿°è½¬æ¢ä¸ºæ•°å­¦æ–¹ç¨‹çš„ä»»åŠ¡ã€‚è¿™å¯¹è‡ªç„¶è¯­è¨€å¤„ç†æå‡ºäº†å·¨å¤§çš„æŒ‘æˆ˜ï¼Œç‰¹åˆ«æ˜¯å¯¹äºå­ŸåŠ æ‹‰è¯­è¿™æ ·çš„ä½èµ„æºè¯­è¨€æ›´æ˜¯å¦‚æ­¤ã€‚æœ¬æ–‡é€šè¿‡ä½¿ç”¨åŸºäºè½¬æ¢æ¨¡å‹çš„åˆ›æ–°æ–¹æ³•æ¥è§£å†³å­ŸåŠ æ‹‰è¯­MWPsæ¥åº”å¯¹è¿™ä¸€æŒ‘æˆ˜ï¼ŒåŒ…æ‹¬åŸºæœ¬è½¬æ¢æ¨¡å‹ã€mT5ã€BanglaT5å’ŒmBART50ã€‚ä¸ºäº†æ”¯æŒè¿™é¡¹å·¥ä½œï¼Œå¼•å…¥äº†åŒ…å«1ä¸‡é“å­ŸåŠ æ‹‰æ•°å­¦é—®é¢˜çš„â€œPatiGonitâ€æ•°æ®é›†ï¼Œå¹¶å¯¹æ­¤ç±»æ¨¡å‹è¿›è¡Œå¾®è°ƒï¼Œä»¥å‡†ç¡®åœ°å°†æ–‡å­—é—®é¢˜ç¿»è¯‘æˆæ–¹ç¨‹å¼ã€‚è¯„ä¼°è¡¨æ˜ï¼ŒmT5æ¨¡å‹çš„å‡†ç¡®åº¦æœ€é«˜ï¼Œè¾¾åˆ°äº†97.3%ï¼Œè¿™è¯æ˜äº†è½¬æ¢æ¨¡å‹åœ¨è¯¥é¢†åŸŸçš„æœ‰æ•ˆæ€§ã€‚è¿™é¡¹ç ”ç©¶åœ¨å­ŸåŠ æ‹‰è¯­è‡ªç„¶è¯­è¨€å¤„ç†æ–¹é¢è¿ˆå‡ºäº†é‡è¦çš„ä¸€æ­¥ï¼Œä¸ºæ•™è‚²äººå·¥æ™ºèƒ½å·¥å…·æä¾›äº†å®è´µçš„æ–¹æ³•å’Œèµ„æºã€‚é€šè¿‡æ”¹è¿›æ•°å­¦æ•™è‚²ï¼Œå®ƒè¿˜æ”¯æŒå­ŸåŠ æ‹‰è¯­å­¦ç”Ÿå‘å±•é«˜çº§é—®é¢˜è§£å†³èƒ½åŠ›ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.02599v1">PDF</a> </p>
<p><strong>Summary</strong><br>     æœ¬æ–‡è§£å†³å­ŸåŠ æ‹‰è¯­æ•°å­¦æ–‡å­—é—®é¢˜ï¼ˆMWPsï¼‰çš„æŒ‘æˆ˜ï¼Œé€šè¿‡è¿ç”¨å˜å‹å™¨æ¨¡å‹ï¼ˆåŒ…æ‹¬Basic Transformerã€mT5ã€BanglaT5å’ŒmBART50ï¼‰è¿›è¡Œè®­ç»ƒã€‚å¼•å…¥â€œPatiGonitâ€æ•°æ®é›†æ”¯æŒç ”ç©¶ï¼ŒåŒ…å«1ä¸‡é“å­ŸåŠ æ‹‰æ•°å­¦é¢˜ç›®ï¼Œæ¨¡å‹ç»å¾®è°ƒå¯å‡†ç¡®å°†æ–‡å­—é—®é¢˜è½¬åŒ–ä¸ºæ–¹ç¨‹å¼ã€‚è¯„ä¼°ç»“æœæ˜¾ç¤ºmT5æ¨¡å‹å‡†ç¡®ç‡æœ€é«˜ï¼Œè¾¾97.30%ï¼Œæ ‡å¿—ç€å­ŸåŠ æ‹‰è¯­è‡ªç„¶è¯­è¨€å¤„ç†é¢†åŸŸçš„é‡è¦è¿›æ­¥ï¼Œä¸ºæ•™è‚²AIå·¥å…·æä¾›å®è´µçš„æ–¹æ³•å’Œèµ„æºï¼Œæœ‰åŠ©äºæ”¹å–„æ•°å­¦æ•™è‚²å’ŒåŸ¹å…»å­ŸåŠ æ‹‰è¯­å­¦ç”Ÿçš„é—®é¢˜è§£å†³èƒ½åŠ›ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æ•°å­¦æ–‡å­—é—®é¢˜ï¼ˆMWPsï¼‰æ˜¯å°†æ–‡æœ¬æè¿°è½¬åŒ–ä¸ºæ•°å­¦æ–¹ç¨‹çš„ä»»åŠ¡ï¼Œå¯¹è‡ªç„¶è¯­è¨€å¤„ç†æ˜¯ä¸€ä¸ªæŒ‘æˆ˜ï¼Œç‰¹åˆ«æ˜¯å¯¹ä½èµ„æºè¯­è¨€å¦‚å­ŸåŠ æ‹‰è¯­ã€‚</li>
<li>ä¸ºåº”å¯¹æ­¤æŒ‘æˆ˜ï¼Œè®ºæ–‡é‡‡ç”¨åŸºäºå˜å‹å™¨çš„æ¨¡å‹è¿›è¡Œè®­ç»ƒã€‚</li>
<li>å¼•å…¥â€œPatiGonitâ€æ•°æ®é›†ï¼ŒåŒ…å«1ä¸‡é“å­ŸåŠ æ‹‰æ•°å­¦é¢˜ç›®ï¼Œç”¨äºæ”¯æŒæ¨¡å‹è®­ç»ƒã€‚</li>
<li>ç»è¿‡å¾®è°ƒï¼Œè¿™äº›æ¨¡å‹èƒ½å¤Ÿå‡†ç¡®åœ°å°†æ–‡å­—é—®é¢˜è½¬åŒ–ä¸ºæ–¹ç¨‹å¼ã€‚</li>
<li>mT5æ¨¡å‹åœ¨å‡†ç¡®ç‡æ–¹é¢è¡¨ç°æœ€ä½³ï¼Œè¾¾åˆ°97.3%ã€‚</li>
<li>ç ”ç©¶ç»“æœæ ‡å¿—ç€å­ŸåŠ æ‹‰è¯­è‡ªç„¶è¯­è¨€å¤„ç†çš„é‡è¦è¿›æ­¥ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.02599">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-4eb049e316561a39f911c5cf4f8b0e8f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-6d0bb9d8fb637b516f11778ff23f4f28.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-9379a699e7b571595660031094b4ea63.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-ecd1cb5f4d390fa72a253469587b0ee7.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-6e84a4591325df453cd4b85de6c0ce37.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-6687bcc0169b5fb52002d7ad05284b91.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-5ca2f0714aedee0c5b84c6cbfbce166f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e898cdb576bd89fd6ba3ff5ed2e60d92.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-dc1f3d98ecbba2b0d7e86ed397aa11ba.jpg" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="GIT-CXR-End-to-End-Transformer-for-Chest-X-Ray-Report-Generation"><a href="#GIT-CXR-End-to-End-Transformer-for-Chest-X-Ray-Report-Generation" class="headerlink" title="GIT-CXR: End-to-End Transformer for Chest X-Ray Report Generation"></a>GIT-CXR: End-to-End Transformer for Chest X-Ray Report Generation</h2><p><strong>Authors:Iustin SÃ®rbu, Iulia-Renata SÃ®rbu, Jasmina Bogojeska, Traian Rebedea</strong></p>
<p>Medical imaging is crucial for diagnosing, monitoring, and treating medical conditions. The medical reports of radiology images are the primary medium through which medical professionals attest their findings, but their writing is time consuming and requires specialized clinical expertise. The automated generation of radiography reports has thus the potential to improve and standardize patient care and significantly reduce clinicians workload. Through our work, we have designed and evaluated an end-to-end transformer-based method to generate accurate and factually complete radiology reports for X-ray images. Additionally, we are the first to introduce curriculum learning for end-to-end transformers in medical imaging and demonstrate its impact in obtaining improved performance. The experiments have been conducted using the MIMIC-CXR-JPG database, the largest available chest X-ray dataset. The results obtained are comparable with the current state-of-the-art on the natural language generation (NLG) metrics BLEU and ROUGE-L, while setting new state-of-the-art results on F1 examples-averaged, F1-macro and F1-micro metrics for clinical accuracy and on the METEOR metric widely used for NLG. </p>
<blockquote>
<p>åŒ»å­¦å½±åƒåœ¨è¯Šæ–­ã€ç›‘æ§å’Œæ²»ç–—åŒ»ç–—çŠ¶å†µä¸­èµ·ç€è‡³å…³é‡è¦çš„ä½œç”¨ã€‚æ”¾å°„å½±åƒçš„åŒ»å­¦æŠ¥å‘Šæ˜¯åŒ»å­¦ä¸“ä¸šäººå‘˜è¿›è¡Œç—…æƒ…æŠ¥å‘Šçš„ä¸»è¦åª’ä»‹ï¼Œä½†å…¶å†™ä½œè¿‡ç¨‹è€—æ—¶ä¸”éœ€è¦ä¸“ä¸šçš„ä¸´åºŠç»éªŒã€‚å› æ­¤ï¼Œè‡ªåŠ¨ç”Ÿæˆçš„æ”¾å°„å­¦æŠ¥å‘Šå…·æœ‰æ”¹å–„å’Œæ ‡å‡†åŒ–æ‚£è€…æŠ¤ç†ä»¥åŠæ˜¾è‘—é™ä½ä¸´åºŠåŒ»ç”Ÿå·¥ä½œé‡çš„æ½œåŠ›ã€‚é€šè¿‡æˆ‘ä»¬çš„ç ”ç©¶ï¼Œæˆ‘ä»¬è®¾è®¡å¹¶è¯„ä¼°äº†ä¸€ç§åŸºäºç«¯åˆ°ç«¯è½¬æ¢å™¨çš„æ–¹æ³•ï¼Œå¯ä¸ºXå°„çº¿å›¾åƒç”Ÿæˆå‡†ç¡®ä¸”äº‹å®å®Œæ•´çš„æ”¾å°„å­¦æŠ¥å‘Šã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æ˜¯é¦–æ¬¡åœ¨åŒ»å­¦å½±åƒä¸­å°†è¯¾ç¨‹å­¦ä¹ å¼•å…¥ç«¯åˆ°ç«¯è½¬æ¢å™¨å¹¶è¯æ˜äº†å…¶å¯¹æé«˜æ€§èƒ½çš„å½±å“ã€‚å®éªŒä½¿ç”¨äº†å¯ç”¨çš„æœ€å¤§èƒ¸éƒ¨Xå°„çº¿æ•°æ®é›†MIMIC-CXR-JPGæ•°æ®åº“ã€‚æ‰€è·å¾—çš„ç»“æœä¸è‡ªç„¶è¯­è¨€ç”Ÿæˆï¼ˆNLGï¼‰æŒ‡æ ‡BLEUå’ŒROUGE-Lçš„å½“å‰æœ€æ–°æ°´å¹³ç›¸å½“ï¼ŒåŒæ—¶åœ¨F1ç¤ºä¾‹å¹³å‡å€¼ã€F1å®è§‚å’ŒF1å¾®è§‚çš„ä¸´åºŠå‡†ç¡®æ€§æŒ‡æ ‡ä»¥åŠå¹¿æ³›ä½¿ç”¨çš„NLGåº¦é‡æ ‡å‡†METEORä¸Šå–å¾—äº†æ–°çš„æœ€æ–°æˆæœã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.02598v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>åŒ»ç–—å½±åƒå­¦åœ¨è¯Šæ–­ã€ç›‘æ§å’Œæ²»ç–—åŒ»å­¦çŠ¶å†µä¸­è‡³å…³é‡è¦ã€‚è™½ç„¶åŒ»å­¦ä¸“å®¶é€šè¿‡æ”¾å°„å­¦å›¾åƒçš„åŒ»ç–—æŠ¥å‘Šæ¥è¯å®ä»–ä»¬çš„å‘ç°ï¼Œä½†ä¹¦å†™è¿™äº›æŠ¥å‘Šæ—¢è€—æ—¶åˆéœ€è¦ä¸“ä¸šçš„ä¸´åºŠç»éªŒã€‚å› æ­¤ï¼Œæ”¾å°„æŠ¥å‘Šçš„è‡ªåŠ¨ç”Ÿæˆå…·æœ‰æ”¹å–„å’Œæ ‡å‡†åŒ–ç—…äººæŠ¤ç†ä»¥åŠæ˜¾è‘—å‡å°‘ä¸´åºŠåŒ»ç”Ÿå·¥ä½œé‡çš„æ½œåŠ›ã€‚æœ¬ç ”ç©¶è®¾è®¡å¹¶è¯„ä¼°äº†ä¸€ç§åŸºäºç«¯åˆ°ç«¯è½¬æ¢å™¨çš„æ–¹æ³•ï¼Œç”¨äºç”Ÿæˆé’ˆå¯¹Xå…‰å›¾åƒçš„å‡†ç¡®ä¸”äº‹å®å®Œæ•´çš„æ”¾å°„æŠ¥å‘Šã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜é¦–æ¬¡å°†è¯¾ç¨‹å­¦ä¹ å¼•å…¥åŒ»å­¦æˆåƒç«¯åˆ°ç«¯è½¬æ¢å™¨ä¸­ï¼Œå¹¶è¯æ˜äº†å…¶å¯¹æé«˜æ€§èƒ½çš„å½±å“ã€‚å®éªŒä½¿ç”¨æœ€å¤§çš„å¯ç”¨èƒ¸Xå…‰å›¾åƒæ•°æ®é›†MIMIC-CXR-JPGæ•°æ®åº“è¿›è¡Œï¼Œè·å¾—çš„ç»“æœåœ¨è‡ªç„¶è¯­è¨€ç”Ÿæˆï¼ˆNLGï¼‰æŒ‡æ ‡BLEUå’ŒROUGE-Læ–¹é¢ä¸å½“å‰å…ˆè¿›æ°´å¹³ç›¸å½“ï¼Œå¹¶åœ¨ä¸´åºŠå‡†ç¡®æ€§çš„F1å®ä¾‹å¹³å‡ã€F1å®å¾®è§‚æŒ‡æ ‡åŠNLGå¹¿æ³›ä½¿ç”¨çš„METEORæŒ‡æ ‡æ–¹é¢å–å¾—æ–°çš„å…ˆè¿›æ°´å¹³ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>åŒ»ç–—å½±åƒå­¦åœ¨åŒ»ç–—ä¸­å…·æœ‰é‡è¦ä½œç”¨ï¼Œæ¶‰åŠè¯Šæ–­ã€ç›‘æ§å’Œæ²»ç–—è¿‡ç¨‹ã€‚</li>
<li>åŒ»ç–—æŠ¥å‘Šä¹¦å†™æ—¢è€—æ—¶åˆéœ€è¦ä¸“ä¸šä¸´åºŠç»éªŒã€‚</li>
<li>è‡ªåŠ¨ç”Ÿæˆæ”¾å°„æŠ¥å‘Šå¯æ”¹å–„å’Œæ ‡å‡†åŒ–ç—…äººæŠ¤ç†ï¼Œå¹¶æ˜¾è‘—é™ä½ä¸´åºŠåŒ»ç”Ÿçš„å·¥ä½œé‡ã€‚</li>
<li>ç ”ç©¶é‡‡ç”¨åŸºäºç«¯åˆ°ç«¯è½¬æ¢å™¨çš„æ–¹æ³•ç”Ÿæˆé’ˆå¯¹Xå…‰å›¾åƒçš„å‡†ç¡®ä¸”äº‹å®å®Œæ•´çš„æ”¾å°„æŠ¥å‘Šã€‚</li>
<li>è¯¾ç¨‹å­¦ä¹ é¦–æ¬¡è¢«å¼•å…¥åŒ»å­¦æˆåƒç«¯åˆ°ç«¯è½¬æ¢å™¨ä¸­ä»¥æé«˜æ€§èƒ½ã€‚</li>
<li>å®éªŒä½¿ç”¨MIMIC-CXR-JPGæ•°æ®åº“è¿›è¡Œï¼Œè·å¾—çš„ç»“æœä¸è‡ªç„¶è¯­è¨€ç”Ÿæˆï¼ˆNLGï¼‰æŒ‡æ ‡çš„å½“å‰å…ˆè¿›æ°´å¹³ç›¸å½“ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.02598">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-56f0455f018110ba41997ceac1b7c6a1.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-29078a2d076fa6d59441eaa6e21883e1.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-7f619545d8505138f3f31803e9908adc.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c403d08709970285ab560d34bba0b7cc.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c0bd72c6c61bf995a845dae28d62bf3f.jpg" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1><h2 id="Evaluation-of-the-Code-Generation-Capabilities-of-ChatGPT-4-A-Comparative-Analysis-in-19-Programming-Languages"><a href="#Evaluation-of-the-Code-Generation-Capabilities-of-ChatGPT-4-A-Comparative-Analysis-in-19-Programming-Languages" class="headerlink" title="Evaluation of the Code Generation Capabilities of ChatGPT 4: A   Comparative Analysis in 19 Programming Languages"></a>Evaluation of the Code Generation Capabilities of ChatGPT 4: A   Comparative Analysis in 19 Programming Languages</h2><p><strong>Authors:L. C. Gilbert</strong></p>
<p>This bachelorâ€™s thesis examines the capabilities of ChatGPT 4 in code generation across 19 programming languages. The study analyzed solution rates across three difficulty levels, types of errors encountered, and code quality in terms of runtime and memory efficiency through a quantitative experiment. A total of 188 programming problems were selected from the LeetCode platform, and ChatGPT 4 was given three attempts to produce a correct solution with feedback. ChatGPT 4 successfully solved 39.67% of all tasks, with success rates decreasing significantly as problem complexity increased. Notably, the model faced considerable challenges with hard problems across all languages. ChatGPT 4 demonstrated higher competence in widely used languages, likely due to a larger volume and higher quality of training data. The solution rates also revealed a preference for languages with low abstraction levels and static typing. For popular languages, the most frequent error was â€œWrong Answer,â€ whereas for less popular languages, compiler and runtime errors prevailed, suggesting frequent misunderstandings and confusion regarding the structural characteristics of these languages. The model exhibited above-average runtime efficiency in all programming languages, showing a tendency toward statically typed and low-abstraction languages. Memory efficiency results varied significantly, with above-average performance in 14 languages and below-average performance in five languages. A slight preference for low-abstraction languages and a leaning toward dynamically typed languages in terms of memory efficiency were observed. Future research should include a larger number of tasks, iterations, and less popular languages. Additionally, ChatGPT 4â€™s abilities in code interpretation and summarization, debugging, and the development of complex, practical code could be analyzed further. </p>
<blockquote>
<p>è¿™ç¯‡å­¦å£«å­¦ä½è®ºæ–‡ç ”ç©¶äº†ChatGPT 4åœ¨19ç§ç¼–ç¨‹è¯­è¨€ä¸­çš„ä»£ç ç”Ÿæˆèƒ½åŠ›ã€‚è¯¥ç ”ç©¶é€šè¿‡å®šé‡å®éªŒåˆ†æäº†ä¸‰ä¸ªéš¾åº¦çº§åˆ«çš„è§£å†³æ–¹æ¡ˆç‡ã€é‡åˆ°çš„é”™è¯¯ç±»å‹ä»¥åŠè¿è¡Œæ—¶é—´å’Œå†…å­˜æ•ˆç‡æ–¹é¢çš„ä»£ç è´¨é‡ã€‚ä¸€å…±ä»LeetCodeå¹³å°é€‰æ‹©äº†188ä¸ªç¼–ç¨‹é—®é¢˜ï¼Œå¹¶ç»™äºˆChatGPT 4ä¸‰æ¬¡å°è¯•äº§ç”Ÿæ­£ç¡®è§£å†³æ–¹æ¡ˆå¹¶åé¦ˆã€‚ChatGPT 4æˆåŠŸè§£å†³äº†39.67%çš„æ‰€æœ‰ä»»åŠ¡ï¼Œéšç€é—®é¢˜å¤æ‚æ€§çš„å¢åŠ ï¼ŒæˆåŠŸç‡æ˜¾è‘—ä¸‹é™ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œè¯¥æ¨¡å‹åœ¨æ‰€æœ‰è¯­è¨€çš„éš¾é¢˜ä¸Šéƒ½é¢ä¸´ç€å·¨å¤§çš„æŒ‘æˆ˜ã€‚ChatGPT 4åœ¨å¸¸ç”¨è¯­è¨€ä¸­è¡¨ç°å‡ºè¾ƒé«˜çš„èƒ½åŠ›ï¼Œè¿™å¯èƒ½æ˜¯ç”±äºè®­ç»ƒæ•°æ®é‡å¤§ä¸”è´¨é‡è¾ƒé«˜ã€‚è§£å†³æ–¹æ¡ˆç‡è¿˜è¡¨æ˜äº†å¯¹å…·æœ‰ä½æŠ½è±¡çº§åˆ«å’Œé™æ€ç±»å‹è¯­è¨€çš„åå¥½ã€‚å¯¹äºæµè¡Œè¯­è¨€ï¼Œæœ€å¸¸è§çš„é”™è¯¯æ˜¯â€œé”™è¯¯ç­”æ¡ˆâ€ï¼Œè€Œå¯¹äºä¸å¤ªæµè¡Œçš„è¯­è¨€ï¼Œç¼–è¯‘å™¨å’Œè¿è¡Œæ—¶é”™è¯¯æ›´ä¸ºæ™®éï¼Œè¿™è¡¨æ˜å¯¹è¿™äº›è¯­è¨€çš„ç»“æ„ç‰¹å¾å­˜åœ¨é¢‘ç¹è¯¯è§£å’Œæ··æ·†ã€‚è¯¥æ¨¡å‹åœ¨æ‰€æœ‰ç¼–ç¨‹è¯­è¨€ä¸­éƒ½è¡¨ç°å‡ºå¹³å‡ä»¥ä¸Šçš„è¿è¡Œæ•ˆç‡ï¼Œå€¾å‘äºé™æ€ç±»å‹å’Œä½æŠ½è±¡è¯­è¨€ã€‚å†…å­˜æ•ˆç‡ç»“æœå·®å¼‚å¾ˆå¤§ï¼Œå…¶ä¸­14ç§è¯­è¨€è¡¨ç°ä¼˜äºå¹³å‡æ°´å¹³ï¼Œ5ç§è¯­è¨€è¡¨ç°ä½äºå¹³å‡æ°´å¹³ã€‚è§‚å¯Ÿåˆ°å¯¹ä½æŠ½è±¡è¯­è¨€çš„è½»å¾®åå¥½ï¼Œä»¥åŠåœ¨å†…å­˜æ•ˆç‡æ–¹é¢å€¾å‘äºåŠ¨æ€ç±»å‹è¯­è¨€ã€‚æœªæ¥çš„ç ”ç©¶åº”åŒ…æ‹¬æ›´å¤šçš„ä»»åŠ¡ã€è¿­ä»£å’Œä¸é‚£ä¹ˆæµè¡Œçš„è¯­è¨€ã€‚æ­¤å¤–ï¼Œå¯ä»¥è¿›ä¸€æ­¥åˆ†æChatGPT 4åœ¨ä»£ç è§£é‡Šå’Œæ‘˜è¦ã€è°ƒè¯•ä»¥åŠå¼€å‘å¤æ‚å®ç”¨ä»£ç æ–¹é¢çš„èƒ½åŠ›ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.02338v1">PDF</a> 65 pages, in German, Bachelorâ€™s thesis on the evaluation of ChatGPT   4â€™s code generation capabilities in 19 programming languages, University of   Potsdam, June 2024</p>
<p><strong>Summary</strong><br>     è¯¥è®ºæ–‡æ¢è®¨äº†ChatGPT 4åœ¨19ç§ç¼–ç¨‹è¯­è¨€ä¸­çš„ä»£ç ç”Ÿæˆèƒ½åŠ›ã€‚é€šè¿‡å®šé‡å®éªŒï¼Œåˆ†æäº†ä¸åŒéš¾åº¦çº§åˆ«çš„è§£å†³æ–¹æ¡ˆç‡ã€é‡åˆ°çš„é”™è¯¯ç±»å‹ä»¥åŠè¿è¡Œæ—¶é—´å’Œå†…å­˜æ•ˆç‡æ–¹é¢çš„ä»£ç è´¨é‡ã€‚ChatGPT 4åœ¨è§£å†³è¾ƒç®€å•é—®é¢˜æ—¶è¡¨ç°è¾ƒå¥½ï¼Œä½†éšç€é—®é¢˜å¤æ‚æ€§çš„å¢åŠ ï¼ŒæˆåŠŸç‡æ˜¾è‘—ä¸‹é™ã€‚å…¶åœ¨æµè¡Œè¯­è¨€ä¸­çš„è¡¨ç°è¾ƒå¥½ï¼Œå¯èƒ½ä¸å¤§é‡çš„é«˜è´¨é‡è®­ç»ƒæ•°æ®æœ‰å…³ã€‚æ­¤å¤–ï¼Œè¿˜å‘ç°æ¨¡å‹å¯¹ä½æŠ½è±¡çº§åˆ«å’Œé™æ€ç±»å‹è¯­è¨€æœ‰åå¥½ã€‚è¿è¡Œæ•ˆç‡æ™®éè¾ƒé«˜ï¼Œå†…å­˜æ•ˆç‡è¡¨ç°åˆ™å‚å·®ä¸é½ã€‚æœªæ¥ç ”ç©¶åº”å¢åŠ ä»»åŠ¡æ•°é‡ã€è¿­ä»£æ¬¡æ•°ä»¥åŠå¯¹è¾ƒä¸å—æ¬¢è¿çš„è¯­è¨€çš„è€ƒå¯Ÿï¼Œå¹¶è¿›ä¸€æ­¥ç ”ç©¶ChatGPT 4åœ¨ä»£ç è§£è¯»ã€æ‘˜è¦ã€è°ƒè¯•åŠå¤æ‚å®ç”¨ä»£ç å¼€å‘æ–¹é¢çš„èƒ½åŠ›ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ChatGPT 4æˆåŠŸè§£å†³äº†188ä¸ªç¼–ç¨‹é—®é¢˜ä¸­çš„çº¦ä¸‰åˆ†ä¹‹ä¸€ï¼Œä¸”è§£å†³ç‡éšé—®é¢˜éš¾åº¦çš„å¢åŠ è€Œé™ä½ã€‚</li>
<li>åœ¨æ‰€æœ‰è¯­è¨€ä¸­ï¼ŒChatGPT 4å¯¹æµè¡Œè¯­è¨€çš„å¤„ç†èƒ½åŠ›è¾ƒå¼ºï¼Œç‰¹åˆ«æ˜¯åœ¨æœ‰å¤§é‡è®­ç»ƒæ•°æ®çš„è¯­è¨€ä¸­ã€‚</li>
<li>ChatGPT 4æ›´æ“…é•¿å¤„ç†ä½æŠ½è±¡çº§åˆ«å’Œé™æ€ç±»å‹çš„ç¼–ç¨‹è¯­è¨€ã€‚</li>
<li>åœ¨è§£å†³ç¼–ç¨‹é—®é¢˜æ—¶ï¼ŒChatGPT 4çš„ä¸»è¦é”™è¯¯ç±»å‹åŒ…æ‹¬â€œé”™è¯¯ç­”æ¡ˆâ€ï¼Œä»¥åŠåœ¨è¾ƒå°‘ä½¿ç”¨çš„è¯­è¨€ä¸­é‡åˆ°çš„ç¼–è¯‘å’Œè¿è¡Œæ—¶é”™è¯¯ã€‚</li>
<li>ChatGPT 4åœ¨è¿è¡Œæ•ˆç‡æ–¹é¢è¡¨ç°è‰¯å¥½ï¼Œä½†åœ¨å†…å­˜æ•ˆç‡æ–¹é¢å­˜åœ¨å·®å¼‚ï¼Œéœ€è¦åœ¨æ›´å¤šè¯­è¨€ä¸­è¿›è¡Œæµ‹è¯•å’Œæ”¹è¿›ã€‚</li>
<li>ç ”ç©¶å»ºè®®å¢åŠ ä»»åŠ¡æ•°é‡å’Œè¿­ä»£æ¬¡æ•°ï¼Œä»¥åŠå¯¹ä¸å¤ªæµè¡Œçš„è¯­è¨€è¿›è¡Œç ”ç©¶ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.02338">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-400316b82278a869eeeeb49aa5aa9401.jpg" align="middle">
</details>


<h1 id="-9"><a href="#-9" class="headerlink" title=""></a></h1><h2 id="Reinforcement-Learning-from-Automatic-Feedback-for-High-Quality-Unit-Test-Generation"><a href="#Reinforcement-Learning-from-Automatic-Feedback-for-High-Quality-Unit-Test-Generation" class="headerlink" title="Reinforcement Learning from Automatic Feedback for High-Quality Unit   Test Generation"></a>Reinforcement Learning from Automatic Feedback for High-Quality Unit   Test Generation</h2><p><strong>Authors:Benjamin Steenhoek, Michele Tufano, Neel Sundaresan, Alexey Svyatkovskiy</strong></p>
<p>Software testing is a crucial but time-consuming aspect of software development, and recently, Large Language Models (LLMs) have gained popularity for automated test case generation. However, because LLMs are trained on vast amounts of open-source code, they often generate test cases that do not adhere to best practices and may even contain test smells (anti-patterns). To address this issue, we propose Reinforcement Learning from Static Quality Metrics (RLSQM), wherein we utilize Reinforcement Learning to generate high-quality unit tests based on static analysis-based quality metrics. First, we analyzed LLM-generated tests and show that LLMs frequently do generate undesirable test smells â€“ up to 37% of the time. Then, we implemented lightweight static analysis-based reward model and trained LLMs using this reward model to optimize for five code quality metrics. Our experimental results demonstrate that the RL-optimized Codex model consistently generated higher-quality test cases than the base LLM, improving quality metrics by up to 23%, and generated nearly 100% syntactically-correct code. RLSQM also outperformed GPT-4 on all code quality metrics, in spite of training a substantially cheaper Codex model. We provide insights into how reliably utilize RL to improve test generation quality and show that RLSQM is a significant step towards enhancing the overall efficiency and reliability of automated software testing. Our data are available at <a target="_blank" rel="noopener" href="https://doi.org/10.6084/m9.figshare.25983166">https://doi.org/10.6084/m9.figshare.25983166</a>. </p>
<blockquote>
<p>è½¯ä»¶æµ‹è¯•æ˜¯è½¯ä»¶å¼€å‘ä¸­è‡³å…³é‡è¦ä½†è€—æ—¶çš„ä¸€ä¸ªç¯èŠ‚ã€‚è¿‘å¹´æ¥ï¼Œå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨è‡ªåŠ¨æµ‹è¯•ç”¨ä¾‹ç”Ÿæˆæ–¹é¢è¶Šæ¥è¶Šå—æ¬¢è¿ã€‚ç„¶è€Œï¼Œç”±äºLLMæ˜¯åœ¨å¤§é‡å¼€æºä»£ç ä¸Šè®­ç»ƒçš„ï¼Œå®ƒä»¬ç»å¸¸ç”Ÿæˆçš„æµ‹è¯•ç”¨ä¾‹å¹¶ä¸ç¬¦åˆæœ€ä½³å®è·µï¼Œç”šè‡³å¯èƒ½åŒ…å«æµ‹è¯•å¼‚å‘³ï¼ˆåæ¨¡å¼ï¼‰ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†åŸºäºé™æ€è´¨é‡æŒ‡æ ‡çš„å¼ºåŒ–å­¦ä¹ ï¼ˆRLSQMï¼‰æ–¹æ³•ã€‚æˆ‘ä»¬åˆ©ç”¨å¼ºåŒ–å­¦ä¹ æ¥åŸºäºé™æ€åˆ†æçš„è´¨é‡æŒ‡æ ‡ç”Ÿæˆé«˜è´¨é‡çš„å•å…ƒæµ‹è¯•ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬åˆ†æäº†LLMç”Ÿæˆçš„æµ‹è¯•ï¼Œå¹¶å‘ç°LLMç»å¸¸äº§ç”Ÿä¸å—æ¬¢è¿çš„æµ‹è¯•å¼‚å‘³ï¼Œé«˜è¾¾37%ã€‚ç„¶åï¼Œæˆ‘ä»¬å®æ–½äº†åŸºäºè½»é‡çº§é™æ€åˆ†æçš„å¥–åŠ±æ¨¡å‹ï¼Œå¹¶ä½¿ç”¨æ­¤å¥–åŠ±æ¨¡å‹å¯¹LLMè¿›è¡Œè®­ç»ƒï¼Œä»¥ä¼˜åŒ–äº”ä¸ªä»£ç è´¨é‡æŒ‡æ ‡ã€‚æˆ‘ä»¬çš„å®éªŒç»“æœè¡¨æ˜ï¼Œç»è¿‡å¼ºåŒ–å­¦ä¹ ä¼˜åŒ–çš„Codexæ¨¡å‹ç”Ÿæˆçš„æµ‹è¯•ç”¨ä¾‹è´¨é‡å§‹ç»ˆé«˜äºåŸºç¡€LLMï¼Œè´¨é‡æŒ‡æ ‡æé«˜äº†é«˜è¾¾23%ï¼Œä¸”ç”Ÿæˆçš„ä»£ç è¯­æ³•æ­£ç¡®ç‡é«˜è¾¾è¿‘100%ã€‚å°½ç®¡è®­ç»ƒäº†ä¸€ä¸ªç›¸å¯¹ä¾¿å®œçš„Codexæ¨¡å‹ï¼ŒRLSQMåœ¨æ‰€æœ‰ä»£ç è´¨é‡æŒ‡æ ‡ä¸Šçš„è¡¨ç°éƒ½ä¼˜äºGPT-4ã€‚æˆ‘ä»¬æ·±å…¥æ¢è®¨äº†å¦‚ä½•åˆ©ç”¨å¼ºåŒ–å­¦ä¹ æé«˜æµ‹è¯•ç”Ÿæˆè´¨é‡ï¼Œå¹¶è¯æ˜RLSQMæ˜¯æœç€æé«˜è‡ªåŠ¨åŒ–è½¯ä»¶æµ‹è¯•çš„æ•´ä½“æ•ˆç‡å’Œå¯é æ€§è¿ˆå‡ºçš„é‡è¦ä¸€æ­¥ã€‚æˆ‘ä»¬çš„æ•°æ®å¯åœ¨<a target="_blank" rel="noopener" href="https://doi.org/10.6084/m9.figshare.25983166%E4%B8%8A%E6%89%BE%E5%88%B0%E3%80%82">https://doi.org/10.6084/m9.figshare.25983166ä¸Šæ‰¾åˆ°ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.14308v2">PDF</a> This work was intended as a replacement of arXiv:2310.02368 and any   subsequent updates will appear there</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æ¢è®¨äº†è½¯ä»¶æµ‹è¯•çš„é‡è¦æ€§ä»¥åŠå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨è‡ªåŠ¨åŒ–æµ‹è¯•ç”¨ä¾‹ç”Ÿæˆæ–¹é¢çš„åº”ç”¨ã€‚é’ˆå¯¹LLMç”Ÿæˆçš„æµ‹è¯•æ¡ˆä¾‹å¸¸å¸¸ä¸ç¬¦åˆæœ€ä½³å®è·µï¼Œç”šè‡³åŒ…å«æµ‹è¯•å¼‚å‘³ï¼ˆanti-patternsï¼‰çš„é—®é¢˜ï¼Œæå‡ºäº†åŸºäºé™æ€è´¨é‡æŒ‡æ ‡çš„å¼ºåŒ–å­¦ä¹ ï¼ˆRLSQMï¼‰æ–¹æ³•ã€‚é€šè¿‡å¼ºåŒ–å­¦ä¹ è®­ç»ƒLLMï¼Œä»¥é™æ€åˆ†æä¸ºåŸºç¡€çš„è´¨é‡æŒ‡æ ‡ä¸ºå¥–åŠ±æ¨¡å‹ï¼Œä¼˜åŒ–ä»£ç è´¨é‡æŒ‡æ ‡ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒRL-ä¼˜åŒ–çš„Codexæ¨¡å‹ç”Ÿæˆçš„æµ‹è¯•ç”¨ä¾‹è´¨é‡æ›´é«˜ï¼Œè´¨é‡æŒ‡æ ‡æå‡äº†é«˜è¾¾23%ï¼Œä¸”ç”Ÿæˆçš„ä»£ç è¯­æ³•æ­£ç¡®ç‡é«˜è¾¾100%ã€‚RLSQMåœ¨ä»£ç è´¨é‡æŒ‡æ ‡æ–¹é¢ä¼˜äºGPT-4ï¼Œå³ä½¿ä½¿ç”¨çš„Codexæ¨¡å‹è®­ç»ƒæˆæœ¬æ›´ä½ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>LLMså·²ç”¨äºè‡ªåŠ¨åŒ–æµ‹è¯•æ¡ˆä¾‹ç”Ÿæˆï¼Œä½†å­˜åœ¨è´¨é‡é—®é¢˜ã€‚</li>
<li>LLMsç”Ÿæˆçš„æµ‹è¯•æ¡ˆä¾‹ä¸­ï¼Œé«˜è¾¾37%åŒ…å«ä¸è‰¯çš„æµ‹è¯•å¼‚å‘³ï¼ˆanti-patternsï¼‰ã€‚</li>
<li>æå‡ºRLSQMæ–¹æ³•ï¼Œåˆ©ç”¨å¼ºåŒ–å­¦ä¹ åŸºäºé™æ€åˆ†æçš„è´¨é‡æŒ‡æ ‡æ¥ç”Ÿæˆé«˜è´¨é‡çš„å•å…ƒæµ‹è¯•ã€‚</li>
<li>ç›¸è¾ƒäºåŸºç¡€LLMï¼ŒRL-ä¼˜åŒ–çš„Codexæ¨¡å‹ç”Ÿæˆçš„æµ‹è¯•æ¡ˆä¾‹è´¨é‡æ˜¾è‘—æå‡ï¼Œè´¨é‡æŒ‡æ ‡æ”¹å–„å¹…åº¦è¾¾23%ã€‚</li>
<li>RLSQMç”Ÿæˆçš„ä»£ç è¯­æ³•æ­£ç¡®ç‡é«˜è¾¾100%ã€‚</li>
<li>RLSQMåœ¨ä»£ç è´¨é‡æ–¹é¢ä¼˜äºGPT-4ï¼Œä¸”Codexæ¨¡å‹è®­ç»ƒæˆæœ¬è¾ƒä½ã€‚</li>
<li>RLSQMæ–¹æ³•ä¸ºæå‡è‡ªåŠ¨åŒ–è½¯ä»¶æµ‹è¯•çš„æ•´ä½“æ•ˆç‡å’Œå¯é æ€§æä¾›äº†é‡è¦æ­¥éª¤ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.14308">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-9a8a857910541ef2f1b5f7c5a3c86929.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-01d9b6a2b5197d28511c1cd09d65c0bc.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-0948c7885bf75852be6c34594ba6fdbe.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-bccdff41ece64af782769d729430b699.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-a05df6e11810e60894ac52152c9f9d4b.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-7d92f4a918db5cc6188bc8c0fbd7e029.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-381fda811db2419d68c3222ac0f86c40.jpg" align="middle">
</details>


<h1 id="-10"><a href="#-10" class="headerlink" title=""></a></h1><h2 id="Are-Your-LLMs-Capable-of-Stable-Reasoning"><a href="#Are-Your-LLMs-Capable-of-Stable-Reasoning" class="headerlink" title="Are Your LLMs Capable of Stable Reasoning?"></a>Are Your LLMs Capable of Stable Reasoning?</h2><p><strong>Authors:Junnan Liu, Hongwei Liu, Linchen Xiao, Ziyi Wang, Kuikun Liu, Songyang Gao, Wenwei Zhang, Songyang Zhang, Kai Chen</strong></p>
<p>The rapid advancement of Large Language Models (LLMs) has demonstrated remarkable progress in complex reasoning tasks. However, a significant discrepancy persists between benchmark performances and real-world applications. We identify this gap as primarily stemming from current evaluation protocols and metrics, which inadequately capture the full spectrum of LLM capabilities, particularly in complex reasoning tasks where both accuracy and consistency are crucial. This work makes two key contributions. First, we introduce G-Pass@k, a novel evaluation metric that provides a continuous assessment of model performance across multiple sampling attempts, quantifying both the modelâ€™s peak performance potential and its stability. Second, we present LiveMathBench, a dynamic benchmark comprising challenging, contemporary mathematical problems designed to minimize data leakage risks during evaluation. Through extensive experiments using G-Pass@k on state-of-the-art LLMs with LiveMathBench, we provide comprehensive insights into both their maximum capabilities and operational consistency. Our findings reveal substantial room for improvement in LLMsâ€™ â€œrealisticâ€ reasoning capabilities, highlighting the need for more robust evaluation methods. The benchmark and detailed results are available at: <a target="_blank" rel="noopener" href="https://github.com/open-compass/GPassK">https://github.com/open-compass/GPassK</a>. </p>
<blockquote>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„å¿«é€Ÿå‘å±•åœ¨å¤æ‚çš„æ¨ç†ä»»åŠ¡ä¸­å–å¾—äº†æ˜¾è‘—çš„è¿›æ­¥ã€‚ç„¶è€Œï¼ŒåŸºå‡†æµ‹è¯•æ€§èƒ½ä¸å®é™…åº”ç”¨ä¹‹é—´ä»å­˜åœ¨å·¨å¤§å·®å¼‚ã€‚æˆ‘ä»¬è®¤ä¸ºè¿™ä¸€å·®è·ä¸»è¦æºäºå½“å‰çš„è¯„ä¼°åè®®å’ŒæŒ‡æ ‡ï¼Œå®ƒä»¬æ— æ³•å……åˆ†æ•æ‰LLMçš„å…¨éƒ¨èƒ½åŠ›ï¼Œç‰¹åˆ«æ˜¯åœ¨éœ€è¦å‡†ç¡®æ€§å’Œä¸€è‡´æ€§çš„å¤æ‚æ¨ç†ä»»åŠ¡ä¸­ã€‚æœ¬æ–‡åšå‡ºäº†ä¸¤ä¸ªä¸»è¦è´¡çŒ®ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬å¼•å…¥äº†G-Pass@kï¼Œè¿™æ˜¯ä¸€ä¸ªæ–°çš„è¯„ä¼°æŒ‡æ ‡ï¼Œå®ƒå¯ä»¥åœ¨å¤šæ¬¡é‡‡æ ·å°è¯•ä¸­æŒç»­è¯„ä¼°æ¨¡å‹æ€§èƒ½ï¼Œé‡åŒ–æ¨¡å‹çš„å³°å€¼æ€§èƒ½æ½œåŠ›å’Œç¨³å®šæ€§ã€‚å…¶æ¬¡ï¼Œæˆ‘ä»¬æ¨å‡ºäº†LiveMathBenchï¼Œè¿™æ˜¯ä¸€ä¸ªåŠ¨æ€åŸºå‡†æµ‹è¯•ï¼ŒåŒ…å«å…·æœ‰æŒ‘æˆ˜æ€§çš„ç°ä»£æ•°å­¦é—®é¢˜ï¼Œæ—¨åœ¨æœ€å°åŒ–è¯„ä¼°è¿‡ç¨‹ä¸­çš„æ•°æ®æ³„éœ²é£é™©ã€‚é€šè¿‡åœ¨å›½å®¶çº§LLMä¸Šä½¿ç”¨G-Pass@kå¯¹LiveMathBenchè¿›è¡Œçš„å¹¿æ³›å®éªŒï¼Œæˆ‘ä»¬å¯¹å®ƒä»¬çš„æœ€å¤§èƒ½åŠ›å’Œæ“ä½œä¸€è‡´æ€§æä¾›äº†å…¨é¢çš„è§è§£ã€‚æˆ‘ä»¬çš„ç ”ç©¶ç»“æœè¡¨æ˜ï¼ŒLLMåœ¨â€œç°å®â€æ¨ç†èƒ½åŠ›æ–¹é¢ä»æœ‰å¾ˆå¤§çš„æå‡ç©ºé—´ï¼Œè¿™å¼ºè°ƒäº†éœ€è¦æ›´ç¨³å¥çš„è¯„ä¼°æ–¹æ³•ã€‚åŸºå‡†æµ‹è¯•å’Œè¯¦ç»†ç»“æœå¯è®¿é—®äºï¼š<a target="_blank" rel="noopener" href="https://github.com/open-compass/GPassK%E3%80%82">https://github.com/open-compass/GPassKã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.13147v3">PDF</a> Preprint, work in progress</p>
<p><strong>Summary</strong></p>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨å¤æ‚æ¨ç†ä»»åŠ¡ä¸Šå–å¾—äº†æ˜¾è‘—è¿›æ­¥ï¼Œä½†å­˜åœ¨åŸºå‡†æµ‹è¯•ä¸å®é™…åº”ç”¨çš„å·®å¼‚ã€‚æœ¬æ–‡ä¸»è¦è§£å†³äº†è¿™ä¸€é—®é¢˜ï¼Œæå‡ºG-Pass@kè¿™ä¸€æ–°è¯„ä¼°æŒ‡æ ‡ä¸LiveMathBenchåŠ¨æ€åŸºå‡†æµ‹è¯•é›†ã€‚æ–°è¯„ä»·æŒ‡æ ‡è¿ç»­è¯„ä¼°æ¨¡å‹å¤šæ¬¡é‡‡æ ·è¡¨ç°ï¼ŒåŒæ—¶è€ƒé‡æ¨¡å‹çš„é¡¶å³°è¡¨ç°ä¸å…¶ç¨³å®šæ€§ã€‚å®éªŒç»“æœè¡¨æ˜LLMçš„â€œçœŸå®â€æ¨ç†èƒ½åŠ›ä»æœ‰è®¸å¤šæå‡ç©ºé—´ï¼Œå¹¶å¼ºè°ƒéœ€è¦æ›´ç¨³å¥çš„è¯„ä¼°æ–¹æ³•ã€‚è¯¦ç»†ä¿¡æ¯å¯è®¿é—®ï¼š<a target="_blank" rel="noopener" href="https://github.com/open-compass/GPassK%E3%80%82">https://github.com/open-compass/GPassKã€‚</a></p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨å¤æ‚æ¨ç†ä»»åŠ¡ä¸Šçš„å‘å±•ä»ç„¶é¢ä¸´ä»åŸºå‡†æµ‹è¯•åˆ°å®é™…åº”ç”¨çš„æ€§èƒ½å·®å¼‚é—®é¢˜ã€‚</li>
<li>è¿™ç§å·®å¼‚ä¸»è¦æºäºç°æœ‰çš„è¯„ä¼°æ–¹æ³•å’ŒæŒ‡æ ‡æ— æ³•å…¨é¢æ•æ‰LLMçš„å®é™…èƒ½åŠ›ï¼Œç‰¹åˆ«æ˜¯åœ¨å‡†ç¡®æ€§å’Œä¸€è‡´æ€§è‡³å…³é‡è¦çš„å¤æ‚æ¨ç†ä»»åŠ¡ä¸­ã€‚</li>
<li>è®ºæ–‡æå‡ºäº†G-Pass@kè¿™ä¸€æ–°è¯„ä¼°æŒ‡æ ‡ï¼Œæ—¨åœ¨è¿ç»­è¯„ä¼°æ¨¡å‹æ€§èƒ½å¹¶é‡åŒ–å…¶å³°å€¼è¡¨ç°å’Œç¨³å®šæ€§ã€‚</li>
<li>åŒæ—¶ï¼Œè®ºæ–‡ä»‹ç»äº†LiveMathBenchåŠ¨æ€åŸºå‡†æµ‹è¯•é›†ï¼ŒåŒ…å«ç°ä»£æ•°å­¦éš¾é¢˜ï¼Œæ—¨åœ¨å‡å°‘æ•°æ®æ³„éœ²é£é™©ã€‚</li>
<li>é€šè¿‡åœ¨æœ€æ–°LLMä¸Šè¿›è¡Œçš„å¤§é‡å®éªŒè¡¨æ˜ï¼ŒLLMåœ¨â€œçœŸå®â€æ¨ç†èƒ½åŠ›æ–¹é¢è¿˜æœ‰å¾ˆå¤§æå‡ç©ºé—´ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.13147">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-b0f3399512af4b8acdb041de7b0499f3.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-9ac43717f50f27fea4c6348f8bba9de3.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-3406b42726c08ea66f17fb60b8d62e33.jpg" align="middle">
</details>


<h1 id="-11"><a href="#-11" class="headerlink" title=""></a></h1><h2 id="Do-Large-Language-Models-Speak-Scientific-Workflows"><a href="#Do-Large-Language-Models-Speak-Scientific-Workflows" class="headerlink" title="Do Large Language Models Speak Scientific Workflows?"></a>Do Large Language Models Speak Scientific Workflows?</h2><p><strong>Authors:Orcun Yildiz, Tom Peterka</strong></p>
<p>With the advent of large language models (LLMs), there is a growing interest in applying LLMs to scientific tasks. In this work, we conduct an experimental study to explore applicability of LLMs for configuring, annotating, translating, explaining, and generating scientific workflows. We use 5 different workflow specific experiments and evaluate several open- and closed-source language models using state-of-the-art workflow systems. Our studies reveal that LLMs often struggle with workflow related tasks due to their lack of knowledge of scientific workflows. We further observe that the performance of LLMs varies across experiments and workflow systems. Our findings can help workflow developers and users in understanding LLMs capabilities in scientific workflows, and motivate further research applying LLMs to workflows. </p>
<blockquote>
<p>éšç€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„å‡ºç°ï¼Œå°†LLMåº”ç”¨äºç§‘å­¦ä»»åŠ¡çš„å…´è¶£æ—¥ç›Šæµ“åšã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬é€šè¿‡å®éªŒç ”ç©¶äº†å°†LLMåº”ç”¨äºé…ç½®ã€æ³¨é‡Šã€ç¿»è¯‘ã€è§£é‡Šå’Œç”Ÿæˆç§‘å­¦å·¥ä½œæµçš„å¯è¡Œæ€§ã€‚æˆ‘ä»¬ä½¿ç”¨äº†5ç§ä¸åŒçš„å·¥ä½œæµç¨‹ç›¸å…³å®éªŒï¼Œå¹¶åˆ©ç”¨æœ€å…ˆè¿›çš„æµç¨‹ç³»ç»Ÿå¯¹å¤šä¸ªå¼€æºå’Œé—­æºè¯­è¨€æ¨¡å‹è¿›è¡Œäº†è¯„ä¼°ã€‚æˆ‘ä»¬çš„ç ”ç©¶è¡¨æ˜ï¼Œç”±äºLLMç¼ºä¹ç§‘å­¦å·¥ä½œæµçš„çŸ¥è¯†ï¼Œå®ƒä»¬åœ¨å¤„ç†ä¸å·¥ä½œæµç›¸å…³çš„ä»»åŠ¡æ—¶ç»å¸¸é‡åˆ°å›°éš¾ã€‚æˆ‘ä»¬è¿˜è§‚å¯Ÿåˆ°ï¼ŒLLMçš„æ€§èƒ½åœ¨ä¸åŒçš„å®éªŒå’Œå·¥ä½œæµç³»ç»Ÿä¸­æœ‰æ‰€ä¸åŒã€‚æˆ‘ä»¬çš„ç ”ç©¶ç»“æœå¯ä»¥å¸®åŠ©å·¥ä½œæµç¨‹å¼€å‘äººå‘˜å’Œç”¨æˆ·äº†è§£LLMåœ¨ç§‘å­¦å·¥ä½œæµä¸­çš„èƒ½åŠ›ï¼Œå¹¶æ¿€åŠ±å°†LLMè¿›ä¸€æ­¥åº”ç”¨äºå·¥ä½œæµç¨‹çš„ç ”ç©¶ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2412.10606v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>éšç€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„å‡ºç°ï¼Œå°†å…¶åº”ç”¨äºç§‘å­¦ä»»åŠ¡çš„å…´è¶£æ—¥ç›Šæµ“åšã€‚æœ¬ç ”ç©¶é€šè¿‡å®éªŒæ¢ç´¢äº†LLMåœ¨é…ç½®ã€æ³¨é‡Šã€ç¿»è¯‘ã€è§£é‡Šå’Œç”Ÿæˆç§‘å­¦å·¥ä½œæµç¨‹æ–¹é¢çš„é€‚ç”¨æ€§ã€‚æˆ‘ä»¬ä½¿ç”¨5ä¸ªä¸åŒçš„å·¥ä½œæµç¨‹ç‰¹å®šå®éªŒï¼Œè¯„ä¼°äº†å¤šä¸ªå¼€æºå’Œé—­æºè¯­è¨€æ¨¡å‹åœ¨æœ€æ–°å·¥ä½œæµç¨‹ç³»ç»Ÿä¸­çš„è¡¨ç°ã€‚ç ”ç©¶å‘ç°ï¼Œç”±äºç¼ºä¹å¯¹ç§‘å­¦å·¥ä½œæµç¨‹çš„äº†è§£ï¼ŒLLMåœ¨å·¥ä½œæµç›¸å…³ä»»åŠ¡ä¸Šç»å¸¸é‡åˆ°å›°éš¾ã€‚æ­¤å¤–ï¼ŒLLMåœ¨ä¸åŒå®éªŒå’Œå·¥ä½œæµç¨‹ç³»ç»Ÿä¸­çš„è¡¨ç°å­˜åœ¨å·®å¼‚ã€‚æœ¬ç ”ç©¶æœ‰åŠ©äºå·¥ä½œæµç¨‹å¼€å‘äººå‘˜å’Œç”¨æˆ·äº†è§£LLMåœ¨ç§‘å­¦å·¥ä½œæµç¨‹ä¸­çš„èƒ½åŠ›ï¼Œå¹¶æ¿€åŠ±å°†LLMè¿›ä¸€æ­¥åº”ç”¨äºå·¥ä½œæµç¨‹çš„ç ”ç©¶ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨ç§‘å­¦ä»»åŠ¡ä¸­çš„åº”ç”¨æ—¥ç›Šå—åˆ°å…³æ³¨ã€‚</li>
<li>æœ¬ç ”ç©¶é€šè¿‡å®éªŒæ¢ç´¢äº†LLMåœ¨é…ç½®ã€æ³¨é‡Šã€ç¿»è¯‘ã€è§£é‡Šå’Œç”Ÿæˆç§‘å­¦å·¥ä½œæµç¨‹æ–¹é¢çš„è¡¨ç°ã€‚</li>
<li>LLMåœ¨åº”å¯¹ç§‘å­¦å·¥ä½œæµç¨‹ç›¸å…³ä»»åŠ¡æ—¶ï¼Œç”±äºç¼ºä¹å¯¹ç§‘å­¦å·¥ä½œæµçš„äº†è§£è€Œç»å¸¸é‡åˆ°å›°éš¾ã€‚</li>
<li>ä¸åŒç±»å‹çš„å·¥ä½œæµç¨‹å®éªŒå’Œç³»ç»Ÿä¸­ï¼ŒLLMçš„è¡¨ç°å­˜åœ¨å·®å¼‚ã€‚</li>
<li>ç ”ç©¶ç»“æœæœ‰åŠ©äºå·¥ä½œæµç¨‹å¼€å‘äººå‘˜å’Œç”¨æˆ·äº†è§£LLMçš„æ½œåŠ›ä¸å±€é™ã€‚</li>
<li>ä¸ºè¿›ä¸€æ­¥å°†LLMåº”ç”¨äºå·¥ä½œæµç¨‹æä¾›äº†æ¿€åŠ±å’Œç ”ç©¶æ–¹å‘ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2412.10606">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-e7ca06bff7d4092059c641f97c2a2090.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-1e36bf2db9aaf00a28b57a2eb6c3777f.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-5de363619da13ca400fbf556927ad6f4.jpg" align="middle">
</details>


<h1 id="-12"><a href="#-12" class="headerlink" title=""></a></h1><h2 id="RA-PbRL-Provably-Efficient-Risk-Aware-Preference-Based-Reinforcement-Learning"><a href="#RA-PbRL-Provably-Efficient-Risk-Aware-Preference-Based-Reinforcement-Learning" class="headerlink" title="RA-PbRL: Provably Efficient Risk-Aware Preference-Based Reinforcement   Learning"></a>RA-PbRL: Provably Efficient Risk-Aware Preference-Based Reinforcement   Learning</h2><p><strong>Authors:Yujie Zhao, Jose Efraim Aguilar Escamill, Weyl Lu, Huazheng Wang</strong></p>
<p>Reinforcement Learning from Human Feedback (RLHF) has recently surged in popularity, particularly for aligning large language models and other AI systems with human intentions. At its core, RLHF can be viewed as a specialized instance of Preference-based Reinforcement Learning (PbRL), where the preferences specifically originate from human judgments rather than arbitrary evaluators. Despite this connection, most existing approaches in both RLHF and PbRL primarily focus on optimizing a mean reward objective, neglecting scenarios that necessitate risk-awareness, such as AI safety, healthcare, and autonomous driving. These scenarios often operate under a one-episode-reward setting, which makes conventional risk-sensitive objectives inapplicable. To address this, we explore and prove the applicability of two risk-aware objectives to PbRL : nested and static quantile risk objectives. We also introduce Risk-AwarePbRL (RA-PbRL), an algorithm designed to optimize both nested and static objectives. Additionally, we provide a theoretical analysis of the regret upper bounds, demonstrating that they are sublinear with respect to the number of episodes, and present empirical results to support our findings. Our code is available in <a target="_blank" rel="noopener" href="https://github.com/aguilarjose11/PbRLNeurips">https://github.com/aguilarjose11/PbRLNeurips</a>. </p>
<blockquote>
<p>å¼ºåŒ–å­¦ä¹ ä»äººç±»åé¦ˆï¼ˆRLHFï¼‰è¿‘æœŸå—åˆ°å¹¿æ³›å…³æ³¨ï¼Œç‰¹åˆ«æ˜¯åœ¨å°†å¤§å‹è¯­è¨€æ¨¡å‹å’Œå…¶ä»–äººå·¥æ™ºèƒ½ç³»ç»Ÿä¸äººç±»æ„å›¾å¯¹é½æ–¹é¢ã€‚å…¶æ ¸å¿ƒå¯è§†ä¸ºåŸºäºåå¥½çš„å¼ºåŒ–å­¦ä¹ ï¼ˆPbRLï¼‰çš„ä¸€ä¸ªç‰¹æ®Šå®ä¾‹ï¼Œå…¶ä¸­åå¥½å…·ä½“æ¥è‡ªäººç±»åˆ¤æ–­è€Œéä»»æ„è¯„ä¼°è€…ã€‚å°½ç®¡å­˜åœ¨è¿™ç§è”ç³»ï¼Œä½†RLHFå’ŒPbRLä¸­çš„å¤§å¤šæ•°ç°æœ‰æ–¹æ³•ä¸»è¦ä¾§é‡äºä¼˜åŒ–å¹³å‡å¥–åŠ±ç›®æ ‡ï¼Œå¿½è§†äº†éœ€è¦é£é™©æ„è¯†çš„åœºæ™¯ï¼Œå¦‚äººå·¥æ™ºèƒ½å®‰å…¨ã€åŒ»ç–—ä¿å¥å’Œè‡ªåŠ¨é©¾é©¶ç­‰ã€‚è¿™äº›åœºæ™¯é€šå¸¸åœ¨ä¸€é›†å¥–åŠ±è®¾ç½®ä¸‹è¿è¡Œï¼Œè¿™ä½¿å¾—å¸¸è§„çš„é£é™©æ•æ„Ÿç›®æ ‡ä¸é€‚ç”¨ã€‚ä¸ºè§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬æ¢ç´¢å’Œè¯æ˜äº†ä¸¤ç§é£é™©æ„è¯†ç›®æ ‡åœ¨PbRLä¸­çš„åº”ç”¨ï¼šåµŒå¥—å’Œé™æ€åˆ†ä½æ•°é£é™©ç›®æ ‡ã€‚æˆ‘ä»¬è¿˜ä»‹ç»äº†é£é™©æ„ŸçŸ¥PbRLï¼ˆRA-PbRLï¼‰ï¼Œè¿™æ˜¯ä¸€ç§æ—¨åœ¨ä¼˜åŒ–åµŒå¥—å’Œé™æ€ç›®æ ‡çš„ç®—æ³•ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å¯¹åæ‚”ä¸Šç•Œè¿›è¡Œäº†ç†è®ºåˆ†æï¼Œè¯æ˜å…¶ä¸é›†æ•°å‘ˆæ¬¡çº¿æ€§å…³ç³»ï¼Œå¹¶é€šè¿‡å®éªŒç»“æœæ”¯æŒæˆ‘ä»¬çš„å‘ç°ã€‚æˆ‘ä»¬çš„ä»£ç å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/aguilarjose11/PbRLNeurips%E4%B8%AD%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/aguilarjose11/PbRLNeuripsä¸­æ‰¾åˆ°ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2410.23569v3">PDF</a> </p>
<p><strong>Summary</strong><br>å¤§å—æ¬¢è¿çš„å¼ºåŒ–å­¦ä¹ æŠ€æœ¯æ­£ä»äººç±»åé¦ˆï¼ˆRLHFï¼‰ä¸­æ±²å–çµæ„Ÿï¼Œç‰¹åˆ«æ˜¯ç”¨äºå°†å¤§å‹è¯­è¨€æ¨¡å‹å’Œå…¶ä»–AIç³»ç»Ÿä¸äººç±»æ„å›¾å¯¹é½ã€‚å…¶æ ¸å¿ƒå¯è§†ä¸ºåŸºäºäººç±»åˆ¤æ–­çš„ç‰¹æ®Šåå¥½å¼ºåŒ–å­¦ä¹ ï¼ˆPbRLï¼‰ã€‚ç„¶è€Œï¼Œç°æœ‰çš„RLHFå’ŒPbRLæ–¹æ³•ä¸»è¦å…³æ³¨ä¼˜åŒ–å¹³å‡å¥–åŠ±ç›®æ ‡ï¼Œå¿½ç•¥äº†é£é™©æ„è¯†éœ€æ±‚è¾ƒå¤§çš„åœºæ™¯ï¼Œå¦‚äººå·¥æ™ºèƒ½å®‰å…¨ã€åŒ»ç–—ä¿å¥å’Œè‡ªåŠ¨é©¾é©¶ç­‰ã€‚è¿™äº›åœºæ™¯é€šå¸¸åœ¨ä¸€ä¸ªå•é›†å¥–åŠ±è®¾ç½®ä¸‹è¿è¡Œï¼Œä½¿å¾—ä¼ ç»Ÿçš„é£é™©æ•æ„Ÿç›®æ ‡ä¸é€‚ç”¨ã€‚ä¸ºè§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬æ¢è®¨äº†é€‚ç”¨äºPbRLçš„ä¸¤ç§é£é™©æ„è¯†ç›®æ ‡ï¼šåµŒå¥—å’Œé™æ€åˆ†ä½é£é™©ç›®æ ‡ï¼Œå¹¶ä»‹ç»äº†ä¸“ä¸ºä¼˜åŒ–è¿™ä¸¤ç§ç›®æ ‡è€Œè®¾è®¡çš„é£é™©æ„è¯†PbRLï¼ˆRA-PbRLï¼‰ç®—æ³•ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜è¿›è¡Œäº†ç†è®ºä¸Šçš„åæ‚”ä¸Šé™åˆ†æï¼Œè¯æ˜å…¶ä¸é›†æ•°éçº¿æ€§å¢é•¿ç›¸å…³ï¼Œå¹¶æä¾›å®è¯ç»“æœä»¥æ”¯æŒæˆ‘ä»¬çš„ç†è®ºã€‚ç›¸å…³ä»£ç å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/aguilarjose11/PbRLNeurips%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/aguilarjose11/PbRLNeuripsæ‰¾åˆ°ã€‚</a></p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>å¼ºåŒ–å­¦ä¹ ä»äººç±»åé¦ˆï¼ˆRLHFï¼‰å·²æˆä¸ºAIç³»ç»Ÿä¸äººç±»æ„å›¾å¯¹é½çš„å…³é”®æŠ€æœ¯ã€‚</li>
<li>PbRLä½œä¸ºRLHFçš„æ ¸å¿ƒï¼Œä¸»è¦å…³æ³¨åŸºäºäººç±»åˆ¤æ–­çš„ä¼˜åŒ–ã€‚</li>
<li>ç°æœ‰æ–¹æ³•ä¸»è¦å…³æ³¨å¹³å‡å¥–åŠ±ç›®æ ‡çš„ä¼˜åŒ–ï¼Œå¿½è§†äº†é£é™©æ„è¯†åœ¨ç‰¹å®šåœºæ™¯ä¸­çš„é‡è¦æ€§ã€‚</li>
<li>æå‡ºäº†é€‚ç”¨äºPbRLçš„ä¸¤ç§é£é™©æ„è¯†ç›®æ ‡ï¼šåµŒå¥—å’Œé™æ€åˆ†ä½é£é™©ç›®æ ‡ã€‚</li>
<li>ä»‹ç»äº†RA-PbRLç®—æ³•ï¼Œæ—¨åœ¨ä¼˜åŒ–è¿™ä¸¤ç§é£é™©æ„è¯†ç›®æ ‡ã€‚</li>
<li>è¿›è¡Œäº†ç†è®ºä¸Šçš„åæ‚”ä¸Šé™åˆ†æï¼Œè¯æ˜å…¶ä¸é›†æ•°çš„å…³ç³»æ˜¯äºšçº¿æ€§çš„ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2410.23569">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-9d4d0acca225dd026963b4e520907132.jpg" align="middle">
</details>


<h1 id="-13"><a href="#-13" class="headerlink" title=""></a></h1><h2 id="Leveraging-Large-Language-Models-to-Detect-npm-Malicious-Packages"><a href="#Leveraging-Large-Language-Models-to-Detect-npm-Malicious-Packages" class="headerlink" title="Leveraging Large Language Models to Detect npm Malicious Packages"></a>Leveraging Large Language Models to Detect npm Malicious Packages</h2><p><strong>Authors:Nusrat Zahan, Philipp Burckhardt, Mikola Lysenko, Feross Aboukhadijeh, Laurie Williams</strong></p>
<p>Existing malicious code detection techniques demand the integration of multiple tools to detect different malware patterns, often suffering from high misclassification rates. Therefore, malicious code detection techniques could be enhanced by adopting advanced, more automated approaches to achieve high accuracy and a low misclassification rate. The goal of this study is to aid security analysts in detecting malicious packages by empirically studying the effectiveness of Large Language Models (LLMs) in detecting malicious code. We present SocketAI, a malicious code review workflow to detect malicious code. To evaluate the effectiveness of SocketAI, we leverage a benchmark dataset of 5,115 npm packages, of which 2,180 packages have malicious code. We conducted a baseline comparison of GPT-3 and GPT-4 models with the state-of-the-art CodeQL static analysis tool, using 39 custom CodeQL rules developed in prior research to detect malicious Javascript code. We also compare the effectiveness of static analysis as a pre-screener with SocketAI workflow, measuring the number of files that need to be analyzed. and the associated costs. Additionally, we performed a qualitative study to understand the types of malicious activities detected or missed by our workflow. Our baseline comparison demonstrates a 16% and 9% improvement over static analysis in precision and F1 scores, respectively. GPT-4 achieves higher accuracy with 99% precision and 97% F1 scores, while GPT-3 offers a more cost-effective balance at 91% precision and 94% F1 scores. Pre-screening files with a static analyzer reduces the number of files requiring LLM analysis by 77.9% and decreases costs by 60.9% for GPT-3 and 76.1% for GPT-4. Our qualitative analysis identified data theft, execution of arbitrary code, and suspicious domain categories as the top detected malicious packages. </p>
<blockquote>
<p>ç°æœ‰çš„æ¶æ„ä»£ç æ£€æµ‹æŠ€æœ¯åœ¨æ£€æµ‹ä¸åŒæ¶æ„è½¯ä»¶æ¨¡å¼æ—¶éœ€è¦é›†æˆå¤šç§å·¥å…·ï¼Œå¾€å¾€å­˜åœ¨è¾ƒé«˜çš„è¯¯åˆ†ç±»ç‡ã€‚å› æ­¤ï¼Œå¯ä»¥é€šè¿‡é‡‡ç”¨å…ˆè¿›çš„æ›´è‡ªåŠ¨åŒ–çš„æ–¹æ³•æ¥æé«˜æ¶æ„ä»£ç æ£€æµ‹æŠ€æœ¯çš„å‡†ç¡®æ€§å¹¶é™ä½è¯¯åˆ†ç±»ç‡ã€‚æœ¬ç ”ç©¶æ—¨åœ¨é€šè¿‡å®è¯ç ”ç©¶å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨æ£€æµ‹æ¶æ„ä»£ç æ–¹é¢çš„æœ‰æ•ˆæ€§ï¼Œå¸®åŠ©å®‰å…¨åˆ†æå¸ˆæ£€æµ‹æ¶æ„è½¯ä»¶åŒ…ã€‚æˆ‘ä»¬æå‡ºäº†SocketAIæ¶æ„ä»£ç å®¡æŸ¥å·¥ä½œæµç¨‹æ¥è¿›è¡Œæ¶æ„ä»£ç æ£€æµ‹ã€‚ä¸ºäº†è¯„ä¼°SocketAIçš„æœ‰æ•ˆæ€§ï¼Œæˆ‘ä»¬ä½¿ç”¨äº†åŒ…å«5115ä¸ªnpmè½¯ä»¶åŒ…çš„åŸºå‡†æ•°æ®é›†ï¼Œå…¶ä¸­2180ä¸ªè½¯ä»¶åŒ…å«æœ‰æ¶æ„ä»£ç ã€‚æˆ‘ä»¬å¯¹GPT-3å’ŒGPT-4æ¨¡å‹è¿›è¡Œäº†åŸºçº¿å¯¹æ¯”ï¼Œå¹¶ä¸å½“å‰å…ˆè¿›çš„CodeQLé™æ€åˆ†æå·¥å…·è¿›è¡Œäº†æ¯”è¾ƒï¼Œåˆ©ç”¨å…ˆå‰ç ”ç©¶ä¸­å¼€å‘çš„39æ¡è‡ªå®šä¹‰CodeQLè§„åˆ™æ¥æ£€æµ‹æ¶æ„JavaScriptä»£ç ã€‚æˆ‘ä»¬è¿˜æ¯”è¾ƒäº†é™æ€åˆ†æä½œä¸ºé¢„ç­›é€‰å™¨ä¸SocketAIå·¥ä½œæµç¨‹çš„æœ‰æ•ˆæ€§ï¼Œæµ‹é‡äº†éœ€è¦åˆ†æçš„æ–‡ä»¶æ•°é‡åŠç›¸å…³æˆæœ¬ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜è¿›è¡Œäº†ä¸€é¡¹å®šæ€§ç ”ç©¶ï¼Œä»¥äº†è§£æˆ‘ä»¬çš„å·¥ä½œæµç¨‹æ‰€æ£€æµ‹åˆ°çš„æˆ–é—æ¼çš„æ¶æ„æ´»åŠ¨çš„ç±»å‹ã€‚æˆ‘ä»¬çš„åŸºçº¿å¯¹æ¯”è¡¨æ˜ï¼Œåœ¨ç²¾ç¡®åº¦å’ŒF1åˆ†æ•°æ–¹é¢åˆ†åˆ«æ¯”é™æ€åˆ†ææé«˜äº†16%å’Œ9%ã€‚GPT-4çš„ç²¾ç¡®åº¦è¾¾åˆ°99%ï¼ŒF1åˆ†æ•°ä¸º97%ï¼Œè¡¨ç°å‡ºæ›´é«˜çš„å‡†ç¡®æ€§ï¼›è€ŒGPT-3åœ¨ç²¾ç¡®åº¦å’ŒF1åˆ†æ•°æ–¹é¢åˆ†åˆ«ä¸º91%å’Œ94%ï¼Œæä¾›äº†æ›´å…·æˆæœ¬æ•ˆç›Šçš„å¹³è¡¡ã€‚ä½¿ç”¨é™æ€åˆ†æå™¨é¢„å…ˆç­›é€‰æ–‡ä»¶å¯å‡å°‘éœ€è¦LLMåˆ†æçš„æ–‡ä»¶æ•°é‡ï¼ŒGPT-3å’ŒGPT-4åˆ†åˆ«å‡å°‘äº†77.9%å’Œ76.1%ï¼Œå¹¶åˆ†åˆ«é™ä½äº†60.9%å’Œæˆæœ¬ã€‚æˆ‘ä»¬çš„å®šæ€§åˆ†æç¡®å®šäº†æ•°æ®ç›—çªƒã€æ‰§è¡Œä»»æ„ä»£ç å’Œå¯ç–‘åŸŸç±»åˆ«ä¸ºæ£€æµ‹åˆ°çš„é¡¶çº§æ¶æ„è½¯ä»¶åŒ…ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2403.12196v4">PDF</a> 13 pages, 2 Figure, 6 tables</p>
<p><strong>Summary</strong></p>
<p>åŸºäºå½“å‰æ¶æ„ä»£ç æ£€æµ‹æŠ€æœ¯çš„ä¸è¶³ï¼Œæœ¬ç ”ç©¶æ—¨åœ¨åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨æ£€æµ‹æ¶æ„ä»£ç æ–¹é¢çš„ä¼˜åŠ¿ï¼Œä»¥å¢å¼ºæ¶æ„ä»£ç æ£€æµ‹çš„å‡†ç¡®æ€§å¹¶é™ä½è¯¯æŠ¥ç‡ã€‚ç ”ç©¶å›¢é˜Ÿæå‡ºäº†ä¸€ç§åä¸ºSocketAIçš„æ¶æ„ä»£ç å®¡æŸ¥å·¥ä½œæµç¨‹ï¼Œå¹¶åˆ©ç”¨ä¸€ä¸ªåŒ…å«5,115ä¸ªnpmåŒ…çš„æ•°æ®é›†æ¥è¯„ä¼°å…¶æ•ˆæœã€‚å¯¹æ¯”äº†GPT-3å’ŒGPT-4æ¨¡å‹ä¸å…ˆè¿›çš„CodeQLé™æ€åˆ†æå·¥å…·åœ¨æ£€æµ‹æ¶æ„JavaScriptä»£ç æ–¹é¢çš„æ€§èƒ½ã€‚ç ”ç©¶ç»“æœæ˜¾ç¤ºï¼ŒSocketAIç›¸è¾ƒäºé™æ€åˆ†æåœ¨ç²¾åº¦å’ŒF1åˆ†æ•°ä¸Šåˆ†åˆ«æé«˜äº†16%å’Œ9%ã€‚GPT-4çš„ç²¾åº¦å’ŒF1åˆ†æ•°åˆ†åˆ«è¾¾åˆ°äº†99%å’Œ97%ï¼Œè€ŒGPT-3åˆ™åœ¨ç²¾åº¦å’Œæˆæœ¬ä¹‹é—´è¾¾åˆ°äº†å¹³è¡¡ã€‚é€šè¿‡é¢„ç­›é€‰æ–‡ä»¶ï¼Œå¯å‡å°‘éœ€è¦LLMåˆ†æçš„æ–‡ä»¶æ•°é‡ï¼Œé™ä½åˆ†ææˆæœ¬ã€‚å®šæ€§åˆ†ææ˜¾ç¤ºï¼Œæ•°æ®ç›—çªƒã€æ‰§è¡Œä»»æ„ä»£ç å’Œå¯ç–‘åŸŸç±»åˆ«æ˜¯æ£€æµ‹åˆ°çš„æœ€ä¸»è¦çš„æ¶æ„åŒ…ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å½“å‰æ¶æ„ä»£ç æ£€æµ‹æŠ€æœ¯å­˜åœ¨é«˜è¯¯æŠ¥ç‡çš„é—®é¢˜ï¼Œéœ€è¦æ›´å‡†ç¡®çš„æ£€æµ‹æ–¹æ³•ã€‚</li>
<li>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨æ£€æµ‹æ¶æ„ä»£ç æ–¹é¢å…·æœ‰æ½œåœ¨ä¼˜åŠ¿ã€‚</li>
<li>ç ”ç©¶å›¢é˜Ÿæå‡ºäº†SocketAIå·¥ä½œæµç¨‹ï¼Œå¹¶è¿›è¡Œäº†å®è¯è¯„ä¼°ã€‚</li>
<li>GPT-4æ¨¡å‹åœ¨ç²¾åº¦å’ŒF1åˆ†æ•°ä¸Šè¡¨ç°æœ€ä½³ï¼ŒGPT-3æ›´å…·æˆæœ¬æ•ˆç›Šã€‚</li>
<li>é¢„ç­›é€‰æ–‡ä»¶å¯ä»¥æ˜¾è‘—å‡å°‘éœ€è¦LLMåˆ†æçš„æ–‡ä»¶æ•°é‡ï¼Œé™ä½åˆ†ææˆæœ¬ã€‚</li>
<li>æ•°æ®ç›—çªƒã€æ‰§è¡Œä»»æ„ä»£ç å’Œå¯ç–‘åŸŸç±»åˆ«æ˜¯æ£€æµ‹åˆ°çš„æœ€ä¸»è¦çš„æ¶æ„åŒ…ç±»å‹ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2403.12196">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-ce556cf1e590130038e030877f0d1286.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-df262acb5125de43405dae23f0e37c19.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-64deeb58cf22bc5495620b2c250f86eb.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-1c2b3c9af872f37a6ac406b3114df7de.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a611f5be2f65370d30f1e672ab01167f.jpg" align="middle">
</details>


<h1 id="-14"><a href="#-14" class="headerlink" title=""></a></h1><h2 id="Reinforcement-Learning-from-Automatic-Feedback-for-High-Quality-Unit-Test-Generation-1"><a href="#Reinforcement-Learning-from-Automatic-Feedback-for-High-Quality-Unit-Test-Generation-1" class="headerlink" title="Reinforcement Learning from Automatic Feedback for High-Quality Unit   Test Generation"></a>Reinforcement Learning from Automatic Feedback for High-Quality Unit   Test Generation</h2><p><strong>Authors:Benjamin Steenhoek, Michele Tufano, Neel Sundaresan, Alexey Svyatkovskiy</strong></p>
<p>Software testing is a crucial aspect of software development, and the creation of high-quality tests that adhere to best practices is essential for effective maintenance. Recently, Large Language Models (LLMs) have gained popularity for code generation, including the automated creation of test cases. However, these LLMs are often trained on vast amounts of publicly available code, which may include test cases that do not adhere to best practices and may even contain test smells (anti-patterns). To address this issue, we propose a novel technique called Reinforcement Learning from Static Quality Metrics (RLSQM). To begin, we analyze the anti-patterns generated by the LLM and show that LLMs can generate undesirable test smells. Thus, we train specific reward models for each static quality metric, then utilize Proximal Policy Optimization (PPO) to train models for optimizing a single quality metric at a time. Furthermore, we amalgamate these rewards into a unified reward model aimed at capturing different best practices and quality aspects of tests. By comparing RL-trained models with those trained using supervised learning, we provide insights into how reliably utilize RL to improve test generation quality and into the effects of various training strategies. Our experimental results demonstrate that the RL-optimized model consistently generated high-quality test cases compared to the base LLM, improving the model by up to 21%, and successfully generates nearly 100% syntactically correct code. RLSQM also outperformed GPT-4 on four out of seven metrics. This represents a significant step towards enhancing the overall efficiency and reliability of software testing through Reinforcement Learning and static quality metrics. Our data are available at <a target="_blank" rel="noopener" href="https://figshare.com/s/ded476c8d4c221222849">https://figshare.com/s/ded476c8d4c221222849</a>. </p>
<blockquote>
<p>è½¯ä»¶æµ‹è¯•æ˜¯è½¯ä»¶å¼€å‘çš„å…³é”®ç¯èŠ‚ï¼Œåˆ›å»ºéµå¾ªæœ€ä½³å®è·µçš„é«˜è´¨é‡æµ‹è¯•å¯¹äºæœ‰æ•ˆç»´æŠ¤è‡³å…³é‡è¦ã€‚æœ€è¿‘ï¼Œå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨ä»£ç ç”Ÿæˆæ–¹é¢å¤§å—æ¬¢è¿ï¼ŒåŒ…æ‹¬è‡ªåŠ¨åˆ›å»ºæµ‹è¯•ç”¨ä¾‹ã€‚ç„¶è€Œï¼Œè¿™äº›LLMé€šå¸¸æ˜¯åœ¨å¤§é‡å…¬å¼€å¯ç”¨çš„ä»£ç ä¸Šè¿›è¡Œè®­ç»ƒçš„ï¼Œè¿™äº›ä»£ç å¯èƒ½åŒ…æ‹¬ä¸ç¬¦åˆæœ€ä½³å®è·µçš„æµ‹è¯•ç”¨ä¾‹ï¼Œç”šè‡³å¯èƒ½åŒ…å«æµ‹è¯•å¼‚å‘³ï¼ˆåæ¨¡å¼ï¼‰ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åä¸ºâ€œåŸºäºé™æ€è´¨é‡æŒ‡æ ‡çš„å¼ºåŒ–å­¦ä¹ â€ï¼ˆRLSQMï¼‰çš„æ–°æŠ€æœ¯ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬åˆ†æäº†LLMç”Ÿæˆçš„åæ¨¡å¼ï¼Œå¹¶è¯æ˜LLMå¯ä»¥ç”Ÿæˆä¸ç†æƒ³çš„æµ‹è¯•å¼‚å‘³ã€‚å› æ­¤ï¼Œæˆ‘ä»¬é’ˆå¯¹æ¯ä¸ªé™æ€è´¨é‡æŒ‡æ ‡è®­ç»ƒç‰¹å®šçš„å¥–åŠ±æ¨¡å‹ï¼Œç„¶åä½¿ç”¨è¿‘ç«¯ç­–ç•¥ä¼˜åŒ–ï¼ˆPPOï¼‰æ¥è®­ç»ƒæ¨¡å‹ï¼Œä»¥ä¸€æ¬¡ä¼˜åŒ–ä¸€ä¸ªè´¨é‡æŒ‡æ ‡ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å°†è¿™äº›å¥–åŠ±åˆå¹¶æˆä¸€ä¸ªç»Ÿä¸€çš„å¥–åŠ±æ¨¡å‹ï¼Œæ—¨åœ¨æ•æ‰æµ‹è¯•çš„æœ€ä½³å®è·µå’Œè´¨é‡æ–¹é¢çš„ä¸åŒç‚¹ã€‚é€šè¿‡æ¯”è¾ƒä½¿ç”¨å¼ºåŒ–å­¦ä¹ è®­ç»ƒçš„æ¨¡å‹ä¸ä½¿ç”¨ç›‘ç£å­¦ä¹ è®­ç»ƒçš„æ¨¡å‹ï¼Œæˆ‘ä»¬æä¾›äº†å¦‚ä½•å¯é åœ°ä½¿ç”¨å¼ºåŒ–å­¦ä¹ æ¥æé«˜æµ‹è¯•ç”Ÿæˆè´¨é‡ä»¥åŠä¸åŒè®­ç»ƒç­–ç•¥çš„å½±å“çš„è§è§£ã€‚æˆ‘ä»¬çš„å®éªŒç»“æœè¡¨æ˜ï¼Œä¸åŸºç¡€LLMç›¸æ¯”ï¼Œç»è¿‡RLä¼˜åŒ–çš„æ¨¡å‹æŒç»­ç”Ÿæˆé«˜è´¨é‡çš„æµ‹è¯•ç”¨ä¾‹ï¼Œæé«˜äº†é«˜è¾¾21%ï¼Œå¹¶æˆåŠŸç”Ÿæˆäº†è¿‘100%è¯­æ³•æ­£ç¡®çš„ä»£ç ã€‚RLSQMåœ¨ä¸ƒä¸ªæŒ‡æ ‡ä¸­çš„å››ä¸ªæŒ‡æ ‡ä¸Šä¹Ÿä¼˜äºGPT-4ã€‚è¿™æ ‡å¿—ç€é€šè¿‡å¼ºåŒ–å­¦ä¹ å’Œé™æ€è´¨é‡æŒ‡æ ‡æé«˜è½¯ä»¶æµ‹è¯•çš„æ•´ä½“æ•ˆç‡å’Œå¯é æ€§æ–¹é¢å–å¾—äº†é‡å¤§è¿›å±•ã€‚æˆ‘ä»¬çš„æ•°æ®å¯åœ¨<a target="_blank" rel="noopener" href="https://figshare.com/s/ded476c8d4c221222849%E4%B8%8A%E6%89%BE%E5%88%B0%E3%80%82">https://figshare.com/s/ded476c8d4c221222849ä¸Šæ‰¾åˆ°ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.02368v2">PDF</a> Accepted to DeepTest 2025 (ICSE Workshop). Previously this version   appeared as arXiv:2412.14308 which was submitted as a new work by accident</p>
<p><strong>Summary</strong></p>
<p>åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„è½¯ä»¶æµ‹è¯•æ˜¯è½¯ä»¶å¼€å‘çš„å¿…è¦ç¯èŠ‚ã€‚æœ€è¿‘ï¼ŒLLMåœ¨ä»£ç ç”Ÿæˆæ–¹é¢è·å¾—äº†å¹¿æ³›åº”ç”¨ï¼ŒåŒ…æ‹¬è‡ªåŠ¨åŒ–æµ‹è¯•ç”¨ä¾‹çš„åˆ›å»ºã€‚ç„¶è€Œï¼ŒLLMè®­ç»ƒçš„ä»£ç åŸºç¡€å¯èƒ½åŒ…å«ä¸ç¬¦åˆæœ€ä½³å®è·µçš„æµ‹è¯•æ¡ˆä¾‹ç”šè‡³æµ‹è¯•å¼‚å‘³ï¼ˆanti-patternsï¼‰ã€‚ä¸ºè§£å†³è¿™ä¸€é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸ºReinforcement Learning from Static Quality Metricsï¼ˆRLSQMï¼‰çš„æ–°æŠ€æœ¯ã€‚é€šè¿‡å¼ºåŒ–å­¦ä¹ è®­ç»ƒæ¨¡å‹ä»¥ä¼˜åŒ–å•ä¸€è´¨é‡æŒ‡æ ‡ï¼Œå¹¶ç»“åˆå¤šä¸ªå¥–åŠ±æ¨¡å‹æ¥æ•æ‰æµ‹è¯•çš„æœ€ä½³å®è·µå’Œè´¨é‡æ–¹é¢ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œç›¸æ¯”åŸºç¡€LLMæ¨¡å‹å’Œç›‘ç£å­¦ä¹ æ¨¡å‹ï¼ŒRLSQMèƒ½æ›´å¯é åœ°ç”Ÿæˆé«˜è´¨é‡æµ‹è¯•ç”¨ä¾‹ï¼Œæé«˜æ¨¡å‹æ€§èƒ½è¾¾21%ï¼Œå¹¶æˆåŠŸç”Ÿæˆè¿‘100%è¯­æ³•æ­£ç¡®çš„ä»£ç ã€‚è¯¥ç ”ç©¶ä¸ºæé«˜è½¯ä»¶æµ‹è¯•çš„æ•ˆç‡å’Œå¯é æ€§è¿ˆå‡ºé‡è¦ä¸€æ­¥ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨è½¯ä»¶æµ‹è¯•ä¸­æ‰®æ¼”ç€é‡è¦è§’è‰²ï¼Œç”¨äºè‡ªåŠ¨åŒ–æµ‹è¯•ç”¨ä¾‹çš„åˆ›å»ºã€‚</li>
<li>LLMè®­ç»ƒçš„ä»£ç åŸºç¡€å¯èƒ½åŒ…å«ä¸ç¬¦åˆæœ€ä½³å®è·µçš„æµ‹è¯•æ¡ˆä¾‹ã€‚</li>
<li>æå‡ºäº†ä¸€ç§æ–°æŠ€æœ¯Reinforcement Learning from Static Quality Metricsï¼ˆRLSQMï¼‰æ¥è§£å†³ä¸Šè¿°é—®é¢˜ã€‚</li>
<li>ä½¿ç”¨Proximal Policy Optimizationï¼ˆPPOï¼‰æ¥è®­ç»ƒæ¨¡å‹ä»¥ä¼˜åŒ–å•ä¸€è´¨é‡æŒ‡æ ‡ã€‚</li>
<li>æ•´åˆå¤šä¸ªå¥–åŠ±æ¨¡å‹ä»¥æ•æ‰æµ‹è¯•çš„æœ€ä½³å®è·µå’Œè´¨é‡æ–¹é¢ã€‚</li>
<li>å®éªŒç»“æœè¡¨æ˜ï¼ŒRLSQMèƒ½ç”Ÿæˆé«˜è´¨é‡æµ‹è¯•ç”¨ä¾‹ï¼Œæé«˜æ¨¡å‹æ€§èƒ½è¾¾21%ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2310.02368">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-0f681dcc04d9d0dfa6cf241de941d1d1.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-01d9b6a2b5197d28511c1cd09d65c0bc.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-0948c7885bf75852be6c34594ba6fdbe.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-bccdff41ece64af782769d729430b699.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-a05df6e11810e60894ac52152c9f9d4b.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-7d92f4a918db5cc6188bc8c0fbd7e029.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-381fda811db2419d68c3222ac0f86c40.jpg" align="middle">
</details>


<h1 id="-15"><a href="#-15" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-01-08/LLM/">https://kedreamix.github.io/Talk2Paper/Paper/2025-01-08/LLM/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/LLM/">
                                    <span class="chip bg-color">LLM</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-01-08/Agent/">
                    <div class="card-image">
                        
                        <img src="https://pic1.zhimg.com/v2-cd8b1838a9cf106514ab81e73a560f38.jpg" class="responsive-img" alt="Agent">
                        
                        <span class="card-title">Agent</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Agent æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-01-08  Revisiting Communication Efficiency in Multi-Agent Reinforcement   Learning from the Dimensional Analysis Perspective
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-01-08
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Agent/" class="post-category">
                                    Agent
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Agent/">
                        <span class="chip bg-color">Agent</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-01-07/Interactive/">
                    <div class="card-image">
                        
                        <img src="https://pica.zhimg.com/v2-fa14582c2f1a796c7b3367d7ddd20883.jpg" class="responsive-img" alt="Interactive">
                        
                        <span class="card-title">Interactive</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Interactive æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-01-07  Reading to Listen at the Cocktail Party Multi-Modal Speech Separation
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-01-07
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Interactive/" class="post-category">
                                    Interactive
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Interactive/">
                        <span class="chip bg-color">Interactive</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">9633.5k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
