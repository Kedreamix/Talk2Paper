<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Diffusion Models">
    <meta name="description" content="Diffusion Models æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2024-02-29  Objective and Interpretable Breast Cosmesis Evaluation with Attention   Guided Denoising Diffusion Anomaly Detection Model">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>Diffusion Models | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


<body>
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://picx.zhimg.com/v2-64adb5f655a12b089618a5496f3cd332.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Diffusion Models</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/Diffusion-Models/">
                                <span class="chip bg-color">Diffusion Models</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/Diffusion-Models/" class="post-category">
                                Diffusion Models
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2024-02-29
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2024-12-10
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    19.9k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    78 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº Googleçš„å¤§è¯­è¨€æ¨¡å‹<a target="_blank" rel="noopener" href="https://ai.google.dev/">Gemini-Pro</a>çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2024-02-29-æ›´æ–°"><a href="#2024-02-29-æ›´æ–°" class="headerlink" title="2024-02-29 æ›´æ–°"></a>2024-02-29 æ›´æ–°</h1><h2 id="Objective-and-Interpretable-Breast-Cosmesis-Evaluation-with-Attention-Guided-Denoising-Diffusion-Anomaly-Detection-Model"><a href="#Objective-and-Interpretable-Breast-Cosmesis-Evaluation-with-Attention-Guided-Denoising-Diffusion-Anomaly-Detection-Model" class="headerlink" title="Objective and Interpretable Breast Cosmesis Evaluation with Attention   Guided Denoising Diffusion Anomaly Detection Model"></a>Objective and Interpretable Breast Cosmesis Evaluation with Attention   Guided Denoising Diffusion Anomaly Detection Model</h2><p><strong>Authors:Sangjoon Park, Yong Bae Kim, Jee Suk Chang, Seo Hee Choi, Hyungjin Chung, Ik Jae Lee, Hwa Kyung Byun</strong></p>
<p>As advancements in the field of breast cancer treatment continue to progress, the assessment of post-surgical cosmetic outcomes has gained increasing significance due to its substantial impact on patientsâ€™ quality of life. However, evaluating breast cosmesis presents challenges due to the inherently subjective nature of expert labeling. In this study, we present a novel automated approach, Attention-Guided Denoising Diffusion Anomaly Detection (AG-DDAD), designed to assess breast cosmesis following surgery, addressing the limitations of conventional supervised learning and existing anomaly detection models. Our approach leverages the attention mechanism of the distillation with no label (DINO) self-supervised Vision Transformer (ViT) in combination with a diffusion model to achieve high-quality image reconstruction and precise transformation of discriminative regions. By training the diffusion model on unlabeled data predominantly with normal cosmesis, we adopt an unsupervised anomaly detection perspective to automatically score the cosmesis. Real-world data experiments demonstrate the effectiveness of our method, providing visually appealing representations and quantifiable scores for cosmesis evaluation. Compared to commonly used rule-based programs, our fully automated approach eliminates the need for manual annotations and offers objective evaluation. Moreover, our anomaly detection model exhibits state-of-the-art performance, surpassing existing models in accuracy. Going beyond the scope of breast cosmesis, our research represents a significant advancement in unsupervised anomaly detection within the medical domain, thereby paving the way for future investigations. </p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2402.18362v1">PDF</a> </p>
<p><strong>Summary</strong><br>åˆ©ç”¨æ— äººç›‘ç£æ–¹æ³•ï¼Œè‡ªåŠ¨è¯„ä¼°ä¹³è…ºç™Œæœ¯åå¤–è§‚ï¼Œä¸ºæé«˜æ‚£è€…ç”Ÿæ´»è´¨é‡æä¾›æ–°é€”å¾„ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>é‡‡ç”¨æ— ç›‘ç£å¼‚å¸¸æ£€æµ‹è§†è§’ï¼Œæ— éœ€æ ‡è®°å³å¯è¯„ä¼°å¤–è§‚ã€‚</li>
<li>ä½¿ç”¨è’¸é¦æ— æ ‡ç­¾ (DINO) è‡ªç›‘ç£è§†è§‰ Transformer (ViT) çš„æ³¨æ„åŠ›æœºåˆ¶ï¼Œå®ç°é«˜è´¨é‡å›¾åƒé‡å»ºå’Œåˆ¤åˆ«åŒºåŸŸçš„ç²¾ç¡®è½¬æ¢ã€‚</li>
<li>åœ¨ä»¥æ­£å¸¸å¤–è§‚ä¸ºä¸»çš„æœªæ ‡è®°æ•°æ®ä¸Šè®­ç»ƒæ‰©æ•£æ¨¡å‹ã€‚</li>
<li>æä¾›è§†è§‰ä¸Šå¸å¼•äººçš„è¡¨ç¤ºå’Œå¯é‡åŒ–çš„åˆ†æ•°ï¼Œç”¨äºå¤–è§‚è¯„ä¼°ã€‚</li>
<li>æ¶ˆé™¤äººå·¥æ ‡æ³¨çš„éœ€è¦ï¼Œæä¾›å®¢è§‚è¯„ä¼°ã€‚</li>
<li>åœ¨å‡†ç¡®æ€§æ–¹é¢è¶…è¿‡ç°æœ‰æ¨¡å‹ï¼Œå±•ç°å‡ºæœ€å…ˆè¿›çš„æ€§èƒ½ã€‚</li>
<li>ä¸ºåŒ»å­¦é¢†åŸŸçš„æ— ç›‘ç£å¼‚å¸¸æ£€æµ‹æä¾›äº†é‡å¤§è¿›å±•ã€‚</li>
<li>æ¢ç´¢æ— ç›‘ç£å¤–è§‚è¯„ä¼°åœ¨å…¶ä»–åŒ»ç–—é¢†åŸŸçš„æ½œåŠ›ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>Title: åŸºäºæ³¨æ„åŠ›å¼•å¯¼å»å™ªæ‰©æ•£çš„å®¢è§‚å¯è§£é‡Šä¹³æˆ¿ç¾è§‚è¯„ä¼°</li>
<li>Authors: Sangjoon Park, YongBae Kim, JeeSuk Chang, SeoHee Choi, Hyungjin Chung, IkJae Lee, HwaKyung Byun</li>
<li>Affiliation: éŸ©å›½é¦–å°”å»¶ä¸–å¤§å­¦åŒ»å­¦é™¢æ”¾å°„è‚¿ç˜¤ç§‘</li>
<li>Keywords: æ‰©æ•£æ¨¡å‹ã€å¼‚å¸¸æ£€æµ‹ã€è§†è§‰ Transformerã€ä¹³æˆ¿ç¾è§‚</li>
<li>Urls: Paper, Github: None</li>
<li>
<p>Summary:
(1): ä¹³æˆ¿ç™Œæœ¯åç¾è§‚è¯„ä¼°å¯¹æ‚£è€…ç”Ÿæ´»è´¨é‡å½±å“å¾ˆå¤§ï¼Œä½†ä¼ ç»Ÿæ–¹æ³•å­˜åœ¨ä¸»è§‚æ€§å¼ºã€ä¾èµ–äººå·¥æ ‡æ³¨ç­‰é—®é¢˜ã€‚
(2): ç°æœ‰æ–¹æ³•ä¾èµ–ä¸“å®¶æ ‡æ³¨ï¼Œå­˜åœ¨æˆæœ¬é«˜ã€æ ‡æ³¨åå·®ã€æ¨¡å‹è¿‡æ‹Ÿåˆã€å¯è§£é‡Šæ€§å·®ç­‰é—®é¢˜ã€‚
(3): æœ¬æ–‡æå‡ºä¸€ç§åä¸º AG-DDAD çš„åˆ›æ–°æ¶æ„ï¼Œåˆ©ç”¨æ‰©æ•£æ¨¡å‹çš„é«˜è´¨é‡ç”Ÿæˆèƒ½åŠ›å’Œ DINO è§†è§‰ Transformer æ³¨æ„åŠ›çš„æ˜¾è‘—ç‰¹å¾è¯†åˆ«èƒ½åŠ›ã€‚è¯¥æ¨¡å‹å¯ä»¥åœ¨æ— ç›‘ç£çš„æ–¹å¼ä¸‹è®­ç»ƒï¼Œåˆ©ç”¨æ¥è‡ª 1,237 åä¸»è¦ä¸ºæ­£å¸¸ç¾è§‚ï¼ˆä¼˜ç§€åˆ°è‰¯å¥½ï¼‰æ‚£è€…çš„æœªæ ‡è®°æ•°æ®ï¼Œæ— éœ€ä¸“å®¶æ ‡æ³¨å’Œäººå·¥å‹¾å‹’ã€‚AG-DDAD é€šè¿‡æ¯”è¾ƒæ­£å¸¸ç¾è§‚æƒ…å†µä¸‹é¢„æœŸçš„æ¢å¤ç»“æœï¼Œæä¾›ç›´æ¥ä¸”å‡ºè‰²çš„å¯è§†åŒ–ç»“æœï¼Œä¸ºä¸è‰¯ç¾è§‚æˆå› æä¾›æœ‰ä»·å€¼çš„è§è§£ã€‚
(4): åœ¨ä¸€ä¸ªç»è¿‡ç²¾å¿ƒæ•´ç†çš„åŒ…å« 300 åæ¥å—ä¹³è…ºç™Œä¿ä¹³æ‰‹æœ¯æ‚£è€…çš„æ•°æ®é›†ä¸Šè¿›è¡Œçš„å®éªŒè¡¨æ˜ï¼Œæœ¬æ–‡æ¨¡å‹ä¼˜äºä¼ ç»Ÿçš„åŸºäºè§„åˆ™çš„æ–¹æ³•å’Œå…¶ä»–æœ€å…ˆè¿›çš„å¼‚å¸¸æ£€æµ‹æ–¹æ³•ã€‚</p>
</li>
<li>
<p>æ–¹æ³•ï¼š
ï¼ˆ1ï¼‰ï¼šæå‡ºä¸€ç§åä¸º AG-DDAD çš„åˆ›æ–°æ¶æ„ï¼Œè¯¥æ¶æ„åˆ©ç”¨æ‰©æ•£æ¨¡å‹çš„é«˜è´¨é‡ç”Ÿæˆèƒ½åŠ›å’Œ DINO è§†è§‰ Transformer æ³¨æ„åŠ›çš„æ˜¾è‘—ç‰¹å¾è¯†åˆ«èƒ½åŠ›ï¼›
ï¼ˆ2ï¼‰ï¼šAG-DDAD åœ¨æ— ç›‘ç£çš„æ–¹å¼ä¸‹è®­ç»ƒï¼Œåˆ©ç”¨æ¥è‡ªä¸»è¦ä¸ºæ­£å¸¸ç¾è§‚ï¼ˆä¼˜ç§€åˆ°è‰¯å¥½ï¼‰æ‚£è€…çš„æœªæ ‡è®°æ•°æ®ï¼Œæ— éœ€ä¸“å®¶æ ‡æ³¨å’Œäººå·¥å‹¾å‹’ï¼›
ï¼ˆ3ï¼‰ï¼šAG-DDAD é€šè¿‡æ¯”è¾ƒæ­£å¸¸ç¾è§‚æƒ…å†µä¸‹é¢„æœŸçš„æ¢å¤ç»“æœï¼Œæä¾›ç›´æ¥ä¸”å‡ºè‰²çš„å¯è§†åŒ–ç»“æœï¼Œä¸ºä¸è‰¯ç¾è§‚æˆå› æä¾›æœ‰ä»·å€¼çš„è§è§£ã€‚</p>
</li>
<li>
<p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºæ³¨æ„åŠ›å¼•å¯¼å»å™ªæ‰©æ•£çš„å®¢è§‚å¯è§£é‡Šä¹³æˆ¿ç¾è§‚è¯„ä¼°æ–¹æ³•ï¼Œè¯¥æ–¹æ³•åˆ©ç”¨äº†æ‰©æ•£æ¨¡å‹çš„é«˜è´¨é‡ç”Ÿæˆèƒ½åŠ›å’ŒDINOè§†è§‰Transformeræ³¨æ„åŠ›çš„æ˜¾è‘—ç‰¹å¾è¯†åˆ«èƒ½åŠ›ï¼Œåœ¨æ— ç›‘ç£çš„æ–¹å¼ä¸‹è®­ç»ƒï¼Œæ— éœ€ä¸“å®¶æ ‡æ³¨å’Œäººå·¥å‹¾å‹’ï¼Œé€šè¿‡æ¯”è¾ƒæ­£å¸¸ç¾è§‚æƒ…å†µä¸‹é¢„æœŸçš„æ¢å¤ç»“æœï¼Œæä¾›ç›´æ¥ä¸”å‡ºè‰²çš„å¯è§†åŒ–ç»“æœï¼Œä¸ºä¸è‰¯ç¾è§‚æˆå› æä¾›æœ‰ä»·å€¼çš„è§è§£ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</p>
</li>
<li>æå‡ºäº†ä¸€ç§åŸºäºæ³¨æ„åŠ›å¼•å¯¼å»å™ªæ‰©æ•£çš„å®¢è§‚å¯è§£é‡Šä¹³æˆ¿ç¾è§‚è¯„ä¼°æ–¹æ³•ï¼Œè¯¥æ–¹æ³•åˆ©ç”¨äº†æ‰©æ•£æ¨¡å‹çš„é«˜è´¨é‡ç”Ÿæˆèƒ½åŠ›å’ŒDINOè§†è§‰Transformeræ³¨æ„åŠ›çš„æ˜¾è‘—ç‰¹å¾è¯†åˆ«èƒ½åŠ›ã€‚</li>
<li>è¯¥æ–¹æ³•åœ¨æ— ç›‘ç£çš„æ–¹å¼ä¸‹è®­ç»ƒï¼Œæ— éœ€ä¸“å®¶æ ‡æ³¨å’Œäººå·¥å‹¾å‹’ï¼Œé€šè¿‡æ¯”è¾ƒæ­£å¸¸ç¾è§‚æƒ…å†µä¸‹é¢„æœŸçš„æ¢å¤ç»“æœï¼Œæä¾›ç›´æ¥ä¸”å‡ºè‰²çš„å¯è§†åŒ–ç»“æœï¼Œä¸ºä¸è‰¯ç¾è§‚æˆå› æä¾›æœ‰ä»·å€¼çš„è§è§£ã€‚
æ€§èƒ½ï¼š</li>
<li>åœ¨ä¸€ä¸ªç»è¿‡ç²¾å¿ƒæ•´ç†çš„åŒ…å«300åæ¥å—ä¹³è…ºç™Œä¿ä¹³æ‰‹æœ¯æ‚£è€…çš„æ•°æ®é›†ä¸Šè¿›è¡Œçš„å®éªŒè¡¨æ˜ï¼Œæœ¬æ–‡æ¨¡å‹ä¼˜äºä¼ ç»Ÿçš„åŸºäºè§„åˆ™çš„æ–¹æ³•å’Œå…¶ä»–æœ€å…ˆè¿›çš„å¼‚å¸¸æ£€æµ‹æ–¹æ³•ã€‚
å·¥ä½œé‡ï¼š</li>
<li>è¯¥æ–¹æ³•éœ€è¦æ¯”ä¼ ç»Ÿçš„åˆ†ç±»å™¨æ¨¡å‹ç•¥å¤šçš„æ—¶é—´ï¼Œè¯„ä¼°å•ä¸ªæ‚£è€…çš„ç¾è§‚å¤§çº¦éœ€è¦15ç§’ï¼Œè€Œç®€å•çš„åˆ†ç±»å™¨æ¨¡å‹å¯ä»¥åœ¨1ç§’å†…äº§ç”Ÿç»“æœã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-678c2254dd6a3d39889bef35f9067c05.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-cfa8a6039aebee57a2721ad761165bd3.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-d6811aab9ac5a0e1edc535c928e3bd0f.jpg" align="middle">
</details>




<h2 id="FineDiffusion-Scaling-up-Diffusion-Models-for-Fine-grained-Image-Generation-with-10-000-Classes"><a href="#FineDiffusion-Scaling-up-Diffusion-Models-for-Fine-grained-Image-Generation-with-10-000-Classes" class="headerlink" title="FineDiffusion: Scaling up Diffusion Models for Fine-grained Image   Generation with 10,000 Classes"></a>FineDiffusion: Scaling up Diffusion Models for Fine-grained Image   Generation with 10,000 Classes</h2><p><strong>Authors:Ziying Pan, Kun Wang, Gang Li, Feihong He, Xiwang Li, Yongxuan Lai</strong></p>
<p>The class-conditional image generation based on diffusion models is renowned for generating high-quality and diverse images. However, most prior efforts focus on generating images for general categories, e.g., 1000 classes in ImageNet-1k. A more challenging task, large-scale fine-grained image generation, remains the boundary to explore. In this work, we present a parameter-efficient strategy, called FineDiffusion, to fine-tune large pre-trained diffusion models scaling to large-scale fine-grained image generation with 10,000 categories. FineDiffusion significantly accelerates training and reduces storage overhead by only fine-tuning tiered class embedder, bias terms, and normalization layersâ€™ parameters. To further improve the image generation quality of fine-grained categories, we propose a novel sampling method for fine-grained image generation, which utilizes superclass-conditioned guidance, specifically tailored for fine-grained categories, to replace the conventional classifier-free guidance sampling. Compared to full fine-tuning, FineDiffusion achieves a remarkable 1.56x training speed-up and requires storing merely 1.77% of the total model parameters, while achieving state-of-the-art FID of 9.776 on image generation of 10,000 classes. Extensive qualitative and quantitative experiments demonstrate the superiority of our method compared to other parameter-efficient fine-tuning methods. The code and more generated results are available at our project website: <a target="_blank" rel="noopener" href="https://finediffusion.github.io/">https://finediffusion.github.io/</a>. </p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2402.18331v1">PDF</a> </p>
<p><strong>Summary</strong><br>é€šè¿‡å¾®è°ƒé¢„è®­ç»ƒæ‰©æ•£æ¨¡å‹ï¼Œä»¥å‚æ•°é«˜æ•ˆç­–ç•¥å®ç°é’ˆå¯¹ 10,000 ä¸ªç»†ç²’åº¦ç±»åˆ«çš„å¤§è§„æ¨¡å›¾åƒç”Ÿæˆ</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>æå‡º FineDiffusionï¼Œå°†å¤§è§„æ¨¡æ‰©æ•£æ¨¡å‹ç¼©å°åˆ°ç»†ç²’åº¦å›¾åƒç”Ÿæˆä¸­</li>
<li>åªå¾®è°ƒåˆ†ç±»åµŒå…¥ã€åç½®é¡¹å’Œå½’ä¸€åŒ–å±‚çš„å‚æ•°ï¼Œå¤§å¹…æå‡è®­ç»ƒé€Ÿåº¦å’Œå­˜å‚¨æ•ˆç‡</li>
<li>æå‡ºé’ˆå¯¹ç»†ç²’åº¦ç±»åˆ«çš„è¶…ç±»æ¡ä»¶å¼•å¯¼é‡‡æ ·æ–¹æ³•ï¼Œæå‡å›¾åƒç”Ÿæˆè´¨é‡</li>
<li>ä¸å®Œå…¨å¾®è°ƒç›¸æ¯”ï¼ŒFineDiffusion è®­ç»ƒé€Ÿåº¦æå‡ 1.56 å€ï¼Œæ‰€éœ€å­˜å‚¨å‚æ•°ä»…ä¸ºåŸæ¨¡å‹çš„ 1.77%</li>
<li>åœ¨ 10,000 ä¸ªç±»åˆ«çš„å›¾åƒç”Ÿæˆä¸Šå–å¾—æœ€å…ˆè¿›çš„ FID ä¸º 9.776</li>
<li>å¤§é‡å®šæ€§å’Œå®šé‡å®éªŒéªŒè¯äº†è¯¥æ–¹æ³•çš„ä¼˜è¶Šæ€§</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>æ ‡é¢˜ï¼šFineDiffusionï¼šå°†æ‰©æ•£æ¨¡å‹æ‰©å±•åˆ° 10,000 ç±»åˆ«çš„ç»†ç²’åº¦å›¾åƒç”Ÿæˆ</li>
<li>ä½œè€…ï¼šZiying Pan, Kun Wang, Gang Li, Feihong He, Xiwang Li, Yongxuan Lai</li>
<li>ç¬¬ä¸€ä½œè€…å•ä½ï¼šå¦é—¨å¤§å­¦</li>
<li>å…³é”®è¯ï¼šDiffusion Models, Fine-grained Image Generation, Parameter-efficient Fine-tuning</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2402.18331
   Github ä»£ç é“¾æ¥ï¼šNone</li>
<li>æ‘˜è¦ï¼š
   ï¼ˆ1ï¼‰ï¼šç ”ç©¶èƒŒæ™¯ï¼šåŸºäºæ‰©æ•£æ¨¡å‹çš„å›¾åƒç”Ÿæˆä»¥äº§ç”Ÿé«˜è´¨é‡å’Œå¤šæ ·åŒ–çš„å›¾åƒè€Œé—»åã€‚ç„¶è€Œï¼Œå¤§å¤šæ•°å…ˆå‰çš„åŠªåŠ›éƒ½é›†ä¸­åœ¨ä¸ºä¸€èˆ¬ç±»åˆ«ç”Ÿæˆå›¾åƒï¼Œä¾‹å¦‚ ImageNet-1k ä¸­çš„ 1000 ä¸ªç±»åˆ«ã€‚ä¸€ä¸ªæ›´å…·æŒ‘æˆ˜æ€§çš„ä»»åŠ¡ï¼Œå³å¤§è§„æ¨¡ç»†ç²’åº¦å›¾åƒç”Ÿæˆï¼Œä»ç„¶æ˜¯éœ€è¦æ¢ç´¢çš„è¾¹ç•Œã€‚
   ï¼ˆ2ï¼‰ï¼šè¿‡å»çš„æ–¹æ³•ï¼šè¿‡å»çš„æ–¹æ³•ä¸»è¦é›†ä¸­åœ¨ä¸€èˆ¬ç±»åˆ«çš„å›¾åƒç”Ÿæˆï¼Œè€Œå¯¹äºç»†ç²’åº¦å›¾åƒç”Ÿæˆï¼Œéœ€è¦æ¨¡å‹å¯¹é«˜åº¦ç›¸ä¼¼çš„ç»†ç²’åº¦ç±»åˆ«ä¸­çš„ç»†å¾®å·®å¼‚ï¼ˆä¾‹å¦‚é¸Ÿç±»çš„ç¾½æ¯›çº¹ç†ï¼‰è¿›è¡Œå¤æ‚çš„å»ºæ¨¡ã€‚ä»å¤´å¼€å§‹è®­ç»ƒç”¨äºå¤§è§„æ¨¡ç»†ç²’åº¦å›¾åƒç”Ÿæˆçš„æ‰©æ•£æ¨¡å‹éœ€è¦æ›´å¤§çš„è®¡ç®—èµ„æºå’Œè®­ç»ƒè¿­ä»£ã€‚
   ï¼ˆ3ï¼‰ï¼šç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„å¾®è°ƒæ–¹æ³• FineDiffusionï¼Œå®ƒå¯ä»¥é€šè¿‡å¾®è°ƒé¢„è®­ç»ƒæ¨¡å‹çš„ä¸€å°éƒ¨åˆ†å‚æ•°ï¼Œæœ‰æ•ˆåœ°å¾®è°ƒå¤§å‹é¢„è®­ç»ƒå›¾åƒç”Ÿæˆæ‰©æ•£æ¨¡å‹ï¼Œä»¥è¿›è¡Œå¤§è§„æ¨¡ç»†ç²’åº¦å›¾åƒç”Ÿæˆã€‚
   ï¼ˆ4ï¼‰ï¼šæ–¹æ³•æ€§èƒ½ï¼šä¸å®Œå…¨å¾®è°ƒç›¸æ¯”ï¼ŒFineDiffusion å®ç°äº†æ˜¾ç€çš„ 1.56 å€è®­ç»ƒåŠ é€Ÿï¼Œå¹¶ä¸”åªéœ€è¦å­˜å‚¨ 1.77% çš„æ€»æ¨¡å‹å‚æ•°ï¼ŒåŒæ—¶åœ¨ 10,000 ä¸ªç±»åˆ«çš„å›¾åƒç”Ÿæˆä¸Šå®ç°äº† 9.776 çš„æœ€å…ˆè¿› FIDã€‚å¹¿æ³›çš„å®šæ€§å’Œå®šé‡å®éªŒè¡¨æ˜ï¼Œä¸å…¶ä»–å‚æ•°æœ‰æ•ˆçš„å¾®è°ƒæ–¹æ³•ç›¸æ¯”ï¼Œæœ¬æ–‡æ–¹æ³•å…·æœ‰ä¼˜è¶Šæ€§ã€‚</li>
</ol>
<p>7.æ–¹æ³•ï¼š(1)æå‡ºäº†ä¸€ç§æ–°çš„å¾®è°ƒæ–¹æ³•FineDiffusionï¼Œè¯¥æ–¹æ³•é€šè¿‡å¾®è°ƒé¢„è®­ç»ƒæ¨¡å‹çš„ä¸€å°éƒ¨åˆ†å‚æ•°ï¼Œæœ‰æ•ˆåœ°å¾®è°ƒå¤§å‹é¢„è®­ç»ƒå›¾åƒç”Ÿæˆæ‰©æ•£æ¨¡å‹ï¼Œä»¥è¿›è¡Œå¤§è§„æ¨¡ç»†ç²’åº¦å›¾åƒç”Ÿæˆï¼›(2)æå‡ºäº†ä¸€ç§åˆ†å±‚ç±»æ ‡ç­¾ç¼–ç ç­–ç•¥ï¼Œè¯¥ç­–ç•¥åŒæ—¶å¯¹è¶…ç±»å’Œå­ç±»æ ‡ç­¾è¿›è¡Œç¼–ç ï¼›(3)åŒæ—¶å¾®è°ƒåå·®å’Œå½’ä¸€åŒ–é¡¹ä»¥åŠåˆ†å±‚åµŒå…¥å™¨ï¼Œä»¥å­¦ä¹ å…¨å±€æ•°æ®é›†çš„åˆ†å¸ƒç‰¹å¾ï¼›(4)å¼•å…¥äº†ä¸€ç§åˆ†å±‚æ— åˆ†ç±»å™¨å¼•å¯¼é‡‡æ ·æ–¹æ³•ï¼Œè¯¥æ–¹æ³•åˆ©ç”¨è¶…ç±»æ¡ä»¶ä¿¡æ¯æ¥å¢å¼ºå¯¹ç”Ÿæˆå›¾åƒçš„æ§åˆ¶ã€‚</p>
<ol>
<li>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡é¦–æ¬¡å°è¯•å°†æ‰©æ•£æ¨¡å‹æ‰©å±•åˆ° 10,000 ç±»çš„ç»†ç²’åº¦å›¾åƒç”Ÿæˆã€‚æˆ‘ä»¬å¼•å…¥äº† FineDiffusionï¼Œè¿™æ˜¯ä¸€ç§é«˜æ•ˆçš„å‚æ•°å¾®è°ƒæ–¹æ³•ï¼Œå¯ä»¥å¾®è°ƒé¢„è®­ç»ƒæ¨¡å‹çš„å…³é”®ç»„ä»¶ï¼ŒåŒ…æ‹¬åˆ†å±‚æ ‡ç­¾åµŒå…¥ã€åå·®é¡¹å’Œå½’ä¸€åŒ–é¡¹ã€‚æˆ‘ä»¬çš„æ–¹æ³•å¤§å¹…å‡å°‘äº†è®­ç»ƒå’Œå­˜å‚¨å¼€é”€ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§ç»†ç²’åº¦æ— åˆ†ç±»å™¨å¼•å¯¼é‡‡æ ·æŠ€æœ¯ï¼Œåˆ©ç”¨åˆ†å±‚æ•°æ®æ ‡ç­¾ä¿¡æ¯æ¥æœ‰æ•ˆå¢å¼ºç»†ç²’åº¦å›¾åƒç”Ÿæˆçš„æ€§èƒ½ã€‚å……åˆ†çš„å®šæ€§å’Œå®šé‡ç»“æœè¯æ˜äº†æˆ‘ä»¬æ–¹æ³•ä¸å…¶ä»–æ–¹æ³•ç›¸æ¯”çš„ä¼˜è¶Šæ€§ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼šæå‡ºäº†ä¸€ç§æ–°çš„å¾®è°ƒæ–¹æ³• FineDiffusionï¼Œè¯¥æ–¹æ³•é€šè¿‡å¾®è°ƒé¢„è®­ç»ƒæ¨¡å‹çš„ä¸€å°éƒ¨åˆ†å‚æ•°ï¼Œæœ‰æ•ˆåœ°å¾®è°ƒå¤§å‹é¢„è®­ç»ƒå›¾åƒç”Ÿæˆæ‰©æ•£æ¨¡å‹ï¼Œä»¥è¿›è¡Œå¤§è§„æ¨¡ç»†ç²’åº¦å›¾åƒç”Ÿæˆï¼›æå‡ºäº†åˆ†å±‚ç±»æ ‡ç­¾ç¼–ç ç­–ç•¥ï¼Œè¯¥ç­–ç•¥åŒæ—¶å¯¹è¶…ç±»å’Œå­ç±»æ ‡ç­¾è¿›è¡Œç¼–ç ï¼›åŒæ—¶å¾®è°ƒåå·®å’Œå½’ä¸€åŒ–é¡¹ä»¥åŠåˆ†å±‚åµŒå…¥å™¨ï¼Œä»¥å­¦ä¹ å…¨å±€æ•°æ®é›†çš„åˆ†å¸ƒç‰¹å¾ï¼›å¼•å…¥äº†ä¸€ç§åˆ†å±‚æ— åˆ†ç±»å™¨å¼•å¯¼é‡‡æ ·æ–¹æ³•ï¼Œè¯¥æ–¹æ³•åˆ©ç”¨è¶…ç±»æ¡ä»¶ä¿¡æ¯æ¥å¢å¼ºå¯¹ç”Ÿæˆå›¾åƒçš„æ§åˆ¶ã€‚
æ€§èƒ½ï¼šä¸å®Œå…¨å¾®è°ƒç›¸æ¯”ï¼ŒFineDiffusion å®ç°äº†æ˜¾ç€çš„ 1.56 å€è®­ç»ƒåŠ é€Ÿï¼Œå¹¶ä¸”åªéœ€è¦å­˜å‚¨ 1.77% çš„æ€»æ¨¡å‹å‚æ•°ï¼ŒåŒæ—¶åœ¨ 10,000 ä¸ªç±»åˆ«çš„å›¾åƒç”Ÿæˆä¸Šå®ç°äº† 9.776 çš„æœ€å…ˆè¿› FIDã€‚å¹¿æ³›çš„å®šæ€§å’Œå®šé‡å®éªŒè¡¨æ˜ï¼Œä¸å…¶ä»–å‚æ•°æœ‰æ•ˆçš„å¾®è°ƒæ–¹æ³•ç›¸æ¯”ï¼Œæœ¬æ–‡æ–¹æ³•å…·æœ‰ä¼˜è¶Šæ€§ã€‚
å·¥ä½œé‡ï¼šä¸ä»å¤´å¼€å§‹è®­ç»ƒç”¨äºå¤§è§„æ¨¡ç»†ç²’åº¦å›¾åƒç”Ÿæˆçš„æ‰©æ•£æ¨¡å‹ç›¸æ¯”ï¼ŒFineDiffusion å¯ä»¥æ˜¾ç€å‡å°‘è®¡ç®—èµ„æºå’Œè®­ç»ƒè¿­ä»£ã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-f68a4db99ea4f9179538c6c4b4d7c7ce.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-4e768fecf2a73ce9e4c8b13ef7c8cd6a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-6c0d4b61db744892b76754513d9f6676.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-665dc312a2eacee1bb375efacd7d609c.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-d25afe2f19082c3abc80d90affd76466.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-68e2a9d895710b3df489a49501a85625.jpg" align="middle">
</details>




<h2 id="Balancing-Act-Distribution-Guided-Debiasing-in-Diffusion-Models"><a href="#Balancing-Act-Distribution-Guided-Debiasing-in-Diffusion-Models" class="headerlink" title="Balancing Act: Distribution-Guided Debiasing in Diffusion Models"></a>Balancing Act: Distribution-Guided Debiasing in Diffusion Models</h2><p><strong>Authors:Rishubh Parihar, Abhijnya Bhat, Saswat Mallick, Abhipsa Basu, Jogendra Nath Kundu, R. Venkatesh Babu</strong></p>
<p>Diffusion Models (DMs) have emerged as powerful generative models with unprecedented image generation capability. These models are widely used for data augmentation and creative applications. However, DMs reflect the biases present in the training datasets. This is especially concerning in the context of faces, where the DM prefers one demographic subgroup vs others (eg. female vs male). In this work, we present a method for debiasing DMs without relying on additional data or model retraining. Specifically, we propose Distribution Guidance, which enforces the generated images to follow the prescribed attribute distribution. To realize this, we build on the key insight that the latent features of denoising UNet hold rich demographic semantics, and the same can be leveraged to guide debiased generation. We train Attribute Distribution Predictor (ADP) - a small mlp that maps the latent features to the distribution of attributes. ADP is trained with pseudo labels generated from existing attribute classifiers. The proposed Distribution Guidance with ADP enables us to do fair generation. Our method reduces bias across single&#x2F;multiple attributes and outperforms the baseline by a significant margin for unconditional and text-conditional diffusion models. Further, we present a downstream task of training a fair attribute classifier by rebalancing the training set with our generated data. </p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2402.18206v1">PDF</a> CVPR 2024. Project Page : <a target="_blank" rel="noopener" href="https://ab-34.github.io/balancing_act/">https://ab-34.github.io/balancing_act/</a></p>
<p><strong>Summary</strong><br>å»é™¤æ‰©æ•£æ¨¡å‹ä¸­çš„åè§ï¼Œæ— éœ€é¢å¤–æ•°æ®æˆ–æ¨¡å‹é‡æ–°è®­ç»ƒã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>æ‰©æ•£æ¨¡å‹ï¼ˆDMï¼‰å­˜åœ¨åè§ï¼Œè¡¨ç°ä¸ºå¯¹ç‰¹å®šäººå£äºšç»„ï¼ˆå¦‚å¥³æ€§ï¼‰çš„åå¥½ã€‚</li>
<li>åˆ†å¸ƒå¼•å¯¼æ˜¯ä¸€ç§æ— å DM çš„æ–¹æ³•ï¼Œæ— éœ€é¢å¤–æ•°æ®æˆ–é‡æ–°è®­ç»ƒã€‚</li>
<li>åˆ†å¸ƒå¼•å¯¼åˆ©ç”¨å»å™ª UNet çš„æ½œåœ¨ç‰¹å¾ä¸­ä¸°å¯Œçš„è¯­ä¹‰ä¿¡æ¯ã€‚</li>
<li>å±æ€§åˆ†å¸ƒé¢„æµ‹å™¨ (ADP) å°†æ½œåœ¨ç‰¹å¾æ˜ å°„åˆ°å±æ€§åˆ†å¸ƒã€‚</li>
<li>ADP ä½¿ç”¨ç°æœ‰å±æ€§åˆ†ç±»å™¨ç”Ÿæˆçš„ä¼ªæ ‡ç­¾è¿›è¡Œè®­ç»ƒã€‚</li>
<li>åˆ†å¸ƒå¼•å¯¼å’Œ ADP å®ç°äº†å…¬å¹³ç”Ÿæˆï¼Œæ˜¾è‘—ä¼˜äºåŸºçº¿ã€‚</li>
<li>é€šè¿‡ä½¿ç”¨ç”Ÿæˆçš„æ•°æ®é‡æ–°å¹³è¡¡è®­ç»ƒé›†ï¼Œå¯ä»¥è®­ç»ƒå…¬å¹³çš„å±æ€§åˆ†ç±»å™¨ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>æ ‡é¢˜ï¼šå¹³è¡¡è¡Œä¸ºï¼šæ‰©æ•£æ¨¡å‹ä¸­çš„åˆ†å¸ƒå¼•å¯¼å»å</li>
<li>ä½œè€…ï¼šRishubh Parihar*, Abhijnya Bhatâˆ—, Saswat Mallick, Abhipsa Basu, Jogendra Nath Kundu, R. Venkatesh Babu</li>
<li>éš¶å±ï¼šå°åº¦ç§‘å­¦é™¢ï¼Œç­åŠ ç½—å°”</li>
<li>å…³é”®è¯ï¼šDiffusion Models, Debiasing, Distribution Guidance, Attribute Distribution Predictor, Fair Generation</li>
<li>é“¾æ¥ï¼šhttps://arxiv.org/abs/2402.18206</li>
<li>
<p>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šæ‰©æ•£æ¨¡å‹ï¼ˆDMï¼‰ä½œä¸ºå¼ºå¤§çš„ç”Ÿæˆæ¨¡å‹ï¼Œåœ¨å›¾åƒç”Ÿæˆæ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œä½†å®ƒä»¬ä¼šåæ˜ è®­ç»ƒæ•°æ®é›†ä¸­çš„åè§ï¼Œç‰¹åˆ«æ˜¯å¯¹äºäººè„¸ï¼ŒDM åå¥½æŸäº›äººå£ç»Ÿè®¡å­¦äºšç»„ï¼ˆä¾‹å¦‚å¥³æ€§æ¯”ç”·æ€§ï¼‰ã€‚
ï¼ˆ2ï¼‰è¿‡å»æ–¹æ³•ï¼šç°æœ‰å»åæ–¹æ³•éœ€è¦é¢å¤–æ•°æ®æˆ–æ¨¡å‹é‡æ–°è®­ç»ƒã€‚
ï¼ˆ3ï¼‰ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºåˆ†å¸ƒå¼•å¯¼ï¼Œé€šè¿‡å¼ºåˆ¶ç”Ÿæˆå›¾åƒéµå¾ªè§„å®šçš„å±æ€§åˆ†å¸ƒæ¥å¯¹ DM è¿›è¡Œå»åã€‚é€šè¿‡è®­ç»ƒå±æ€§åˆ†å¸ƒé¢„æµ‹å™¨ (ADP) æ¥æ˜ å°„æ½œåœ¨ç‰¹å¾åˆ°å±æ€§åˆ†å¸ƒï¼ŒADP ä½¿ç”¨ç°æœ‰å±æ€§åˆ†ç±»å™¨ç”Ÿæˆçš„ä¼ªæ ‡ç­¾è¿›è¡Œè®­ç»ƒã€‚
ï¼ˆ4ï¼‰æ–¹æ³•æ€§èƒ½ï¼šè¯¥æ–¹æ³•åœ¨æ— æ¡ä»¶å’Œæ–‡æœ¬æ¡ä»¶æ‰©æ•£æ¨¡å‹ä¸Šå‡å°‘äº†å•ä¸€/å¤šå±æ€§çš„åå·®ï¼Œå¹¶ä¸”ä¼˜äºåŸºçº¿æ–¹æ³•ã€‚æ­¤å¤–ï¼Œæœ¬æ–‡è¿˜æå‡ºäº†ä¸€ç§é€šè¿‡ä½¿ç”¨ç”Ÿæˆæ•°æ®é‡æ–°å¹³è¡¡è®­ç»ƒé›†æ¥è®­ç»ƒå…¬å¹³å±æ€§åˆ†ç±»å™¨çš„ä¸‹æ¸¸ä»»åŠ¡ã€‚</p>
</li>
<li>
<p>æ–¹æ³•ï¼š
(1): æå‡ºåˆ†å¸ƒå¼•å¯¼æ–¹æ³•ï¼Œé€šè¿‡å¼ºåˆ¶ç”Ÿæˆå›¾åƒéµå¾ªè§„å®šçš„å±æ€§åˆ†å¸ƒæ¥å¯¹æ‰©æ•£æ¨¡å‹ï¼ˆDMï¼‰è¿›è¡Œå»åã€‚
(2): è®­ç»ƒå±æ€§åˆ†å¸ƒé¢„æµ‹å™¨ï¼ˆADPï¼‰æ¥æ˜ å°„æ½œåœ¨ç‰¹å¾åˆ°å±æ€§åˆ†å¸ƒï¼ŒADPä½¿ç”¨ç°æœ‰å±æ€§åˆ†ç±»å™¨ç”Ÿæˆçš„ä¼ªæ ‡ç­¾è¿›è¡Œè®­ç»ƒã€‚
(3): åœ¨æ— æ¡ä»¶å’Œæ–‡æœ¬æ¡ä»¶æ‰©æ•£æ¨¡å‹ä¸Šè¯„ä¼°è¯¥æ–¹æ³•ï¼Œå‡å°‘äº†å•ä¸€/å¤šå±æ€§çš„åå·®ï¼Œå¹¶ä¼˜äºåŸºçº¿æ–¹æ³•ã€‚
(4): æå‡ºäº†ä¸€ç§é€šè¿‡ä½¿ç”¨ç”Ÿæˆæ•°æ®é‡æ–°å¹³è¡¡è®­ç»ƒé›†æ¥è®­ç»ƒå…¬å¹³å±æ€§åˆ†ç±»å™¨çš„ä¸‹æ¸¸ä»»åŠ¡ã€‚</p>
</li>
<li>
<p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰æœ¬æ–‡çš„æ„ä¹‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§æ— éœ€é‡æ–°è®­ç»ƒå³å¯å‡è½»é¢„è®­ç»ƒæ‰©æ•£æ¨¡å‹åå·®çš„æ–¹æ³•ï¼Œä»…ç»™å®šæ‰€éœ€çš„å‚è€ƒå±æ€§åˆ†å¸ƒã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°é¢–çš„æ–¹æ³•ï¼Œåˆ©ç”¨åˆ†å¸ƒå¼•å¯¼ï¼Œè”åˆå¼•å¯¼ä¸€æ‰¹å›¾åƒéµå¾ªå‚è€ƒå±æ€§åˆ†å¸ƒã€‚æ‰€æå‡ºçš„æ–¹æ³•æ˜¯æœ‰æ•ˆçš„ï¼Œå¹¶ä¸”åœ¨
ï¼ˆ2ï¼‰åˆ›æ–°ç‚¹ï¼šæœ¬æ–‡çš„åˆ›æ–°ç‚¹åœ¨äºæå‡ºäº†ä¸€ç§æ–°çš„åˆ†å¸ƒå¼•å¯¼æ–¹æ³•ï¼Œé€šè¿‡å¼ºåˆ¶ç”Ÿæˆå›¾åƒéµå¾ªè§„å®šçš„å±æ€§åˆ†å¸ƒæ¥å¯¹æ‰©æ•£æ¨¡å‹è¿›è¡Œå»åã€‚
æ€§èƒ½ï¼šæœ¬æ–‡çš„æ–¹æ³•åœ¨æ— æ¡ä»¶å’Œæ–‡æœ¬æ¡ä»¶æ‰©æ•£æ¨¡å‹ä¸Šå‡å°‘äº†å•ä¸€/å¤šå±æ€§çš„åå·®ï¼Œå¹¶ä¸”ä¼˜äºåŸºçº¿æ–¹æ³•ã€‚
å·¥ä½œé‡ï¼šæœ¬æ–‡çš„æ–¹æ³•éœ€è¦è®­ç»ƒä¸€ä¸ªå±æ€§åˆ†å¸ƒé¢„æµ‹å™¨ï¼Œè¯¥é¢„æµ‹å™¨ä½¿ç”¨ç°æœ‰å±æ€§åˆ†ç±»å™¨ç”Ÿæˆçš„ä¼ªæ ‡ç­¾è¿›è¡Œè®­ç»ƒã€‚è®­ç»ƒå±æ€§åˆ†å¸ƒé¢„æµ‹å™¨çš„å·¥ä½œé‡å–å†³äºè®­ç»ƒæ•°æ®çš„è§„æ¨¡å’Œå±æ€§çš„æ•°é‡ã€‚</p>
</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-05a1a956ee3a51fe0c06ffc4859c7231.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-16ae5c5f9f522148622d40f8f3f15f86.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-46f6a987113095ab338596820ca6e653.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f32e1f0036b8646f3ffad99a82575f09.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-1128b65d6c33c58a2f6b04087adf31b0.jpg" align="middle">
</details>




<h2 id="Coarse-to-Fine-Latent-Diffusion-for-Pose-Guided-Person-Image-Synthesis"><a href="#Coarse-to-Fine-Latent-Diffusion-for-Pose-Guided-Person-Image-Synthesis" class="headerlink" title="Coarse-to-Fine Latent Diffusion for Pose-Guided Person Image Synthesis"></a>Coarse-to-Fine Latent Diffusion for Pose-Guided Person Image Synthesis</h2><p><strong>Authors:Yanzuo Lu, Manlin Zhang, Andy J Ma, Xiaohua Xie, Jian-Huang Lai</strong></p>
<p>Diffusion model is a promising approach to image generation and has been employed for Pose-Guided Person Image Synthesis (PGPIS) with competitive performance. While existing methods simply align the person appearance to the target pose, they are prone to overfitting due to the lack of a high-level semantic understanding on the source person image. In this paper, we propose a novel Coarse-to-Fine Latent Diffusion (CFLD) method for PGPIS. In the absence of image-caption pairs and textual prompts, we develop a novel training paradigm purely based on images to control the generation process of the pre-trained text-to-image diffusion model. A perception-refined decoder is designed to progressively refine a set of learnable queries and extract semantic understanding of person images as a coarse-grained prompt. This allows for the decoupling of fine-grained appearance and pose information controls at different stages, and thus circumventing the potential overfitting problem. To generate more realistic texture details, a hybrid-granularity attention module is proposed to encode multi-scale fine-grained appearance features as bias terms to augment the coarse-grained prompt. Both quantitative and qualitative experimental results on the DeepFashion benchmark demonstrate the superiority of our method over the state of the arts for PGPIS. Code is available at <a target="_blank" rel="noopener" href="https://github.com/YanzuoLu/CFLD">https://github.com/YanzuoLu/CFLD</a>. </p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2402.18078v1">PDF</a> Accepted by CVPR 2024</p>
<p><strong>Summary</strong><br> æå‡ºäº†ä¸€ç§ç²—åˆ°ç»†çš„æ½œåœ¨æ‰©æ•£ï¼ˆCFLDï¼‰æ–¹æ³•ï¼Œåˆ©ç”¨å›¾åƒè€Œéæ–‡æœ¬æç¤ºï¼Œæ§åˆ¶é¢„è®­ç»ƒæ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹ï¼Œå®ç°å§¿åŠ¿å¼•å¯¼çš„å›¾åƒåˆæˆã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>æå‡º CFLD æ–¹æ³•ï¼Œæ”¹å–„äº† PGPIS ä¸­å§¿åŠ¿å¼•å¯¼å›¾åƒåˆæˆçš„æ•ˆæœã€‚</li>
<li>ä½¿ç”¨çº¯å›¾åƒè®­ç»ƒèŒƒå¼ï¼Œæ— éœ€å›¾åƒå­—å¹•æˆ–æ–‡æœ¬æç¤ºã€‚</li>
<li>è®¾è®¡äº†ä¸€ä¸ªæ„ŸçŸ¥ç²¾ç‚¼è§£ç å™¨ï¼Œé€æ­¥ä¼˜åŒ–æŸ¥è¯¢å¹¶æå–äººç‰©å›¾åƒçš„è¯­ä¹‰ç†è§£ã€‚</li>
<li>å°†å¤–è²Œå’Œå§¿åŠ¿ä¿¡æ¯æ§åˆ¶è§£è€¦ï¼Œé¿å…è¿‡åº¦æ‹Ÿåˆã€‚</li>
<li>æå‡ºæ··åˆç²’åº¦æ³¨æ„åŠ›æ¨¡å—ï¼Œå¯¹å¤šå°ºåº¦å¤–è§‚ç‰¹å¾è¿›è¡Œç¼–ç ï¼Œå¢å¼ºç²—ç²’åº¦æç¤ºã€‚</li>
<li>åœ¨ DeepFashion æ•°æ®é›†ä¸Šï¼Œå®šé‡å’Œå®šæ€§å®éªŒç»“æœè¯æ˜äº† CFLD çš„ä¼˜è¶Šæ€§ã€‚</li>
<li>ä»£ç å·²å¼€æºã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>é¢˜ç›®ï¼šç²—åˆ°ç»†çš„æ½œåœ¨æ‰©æ•£ç”¨äºå§¿æ€å¼•å¯¼çš„äººç‰©å›¾åƒåˆæˆ</li>
<li>ä½œè€…ï¼šLu Yanzuo, Zhang Manlin, Ma Andy J, Xie Xiaohua, Lai Jianhuang</li>
<li>å•ä½ï¼šä¸­å±±å¤§å­¦è®¡ç®—æœºç§‘å­¦ä¸å·¥ç¨‹å­¦é™¢</li>
<li>å…³é”®è¯ï¼šå§¿æ€å¼•å¯¼ã€äººç‰©å›¾åƒåˆæˆã€æ½œåœ¨æ‰©æ•£æ¨¡å‹ã€ç²—åˆ°ç»†ã€è¯­ä¹‰ç†è§£</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2402.18078
   Github ä»£ç é“¾æ¥ï¼šhttps://github.com/YanzuoLu/CFLD</li>
<li>æ‘˜è¦ï¼š
(1) ç ”ç©¶èƒŒæ™¯ï¼šå§¿æ€å¼•å¯¼çš„äººç‰©å›¾åƒåˆæˆæ—¨åœ¨å°†æºäººç‰©å›¾åƒè½¬æ¢ä¸ºç‰¹å®šçš„ç›®æ ‡å§¿æ€ï¼ŒåŒæ—¶å°½å¯èƒ½ä¿ç•™å¤–è§‚ã€‚å®ƒåœ¨ç”µå½±åˆ¶ä½œã€è™šæ‹Ÿç°å®å’Œæ—¶å°šç”µå­å•†åŠ¡ç­‰é¢†åŸŸæœ‰å¹¿æ³›çš„åº”ç”¨ã€‚
(2) è¿‡å»çš„æ–¹æ³•ï¼šç°æœ‰åŸºäºç”Ÿæˆå¯¹æŠ—ç½‘ç»œ (GAN) çš„æ–¹æ³•å®¹æ˜“å‡ºç°æå°æå¤§è®­ç»ƒç›®æ ‡çš„ä¸ç¨³å®šæ€§å’Œéš¾ä»¥åœ¨ä¸€æ¬¡å‰å‘ä¼ é€’ä¸­ç”Ÿæˆé«˜è´¨é‡å›¾åƒçš„é—®é¢˜ã€‚ä½œä¸º GAN åœ¨å›¾åƒç”Ÿæˆä¸­çš„ä¸€ç§æœ‰å‰é€”çš„æ›¿ä»£æ–¹æ¡ˆï¼Œæ‰©æ•£æ¨¡å‹é€šè¿‡ä¸€ç³»åˆ—å»å™ªæ­¥éª¤é€æ¸åˆæˆæ›´é€¼çœŸçš„å›¾åƒã€‚
(3) æœ¬æ–‡æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„ç²—åˆ°ç»†æ½œåœ¨æ‰©æ•£ (CFLD) æ–¹æ³•ç”¨äºå§¿æ€å¼•å¯¼çš„äººç‰©å›¾åƒåˆæˆã€‚åœ¨æ²¡æœ‰å›¾åƒ-æ ‡é¢˜å¯¹å’Œæ–‡æœ¬æç¤ºçš„æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬å¼€å‘äº†ä¸€ç§çº¯ç²¹åŸºäºå›¾åƒçš„æ–°é¢–è®­ç»ƒèŒƒå¼æ¥æ§åˆ¶é¢„è®­ç»ƒæ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹çš„ç”Ÿæˆè¿‡ç¨‹ã€‚æˆ‘ä»¬è®¾è®¡äº†ä¸€ä¸ªæ„ŸçŸ¥ç²¾ç‚¼è§£ç å™¨æ¥æ¸è¿›åœ°ç»†åŒ–ä¸€ç»„å¯å­¦ä¹ æŸ¥è¯¢å¹¶æå–äººç‰©å›¾åƒçš„è¯­ä¹‰ç†è§£ä½œä¸ºç²—ç²’åº¦æç¤ºã€‚è¿™å…è®¸åœ¨ä¸åŒçš„é˜¶æ®µè§£è€¦ç»†ç²’åº¦å¤–è§‚å’Œå§¿æ€ä¿¡æ¯æ§åˆ¶ï¼Œä»è€Œè§„é¿äº†æ½œåœ¨çš„è¿‡æ‹Ÿåˆé—®é¢˜ã€‚ä¸ºäº†ç”Ÿæˆæ›´é€¼çœŸçš„çº¹ç†ç»†èŠ‚ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ··åˆç²’åº¦æ³¨æ„åŠ›æ¨¡å—ï¼Œå°†å¤šå°ºåº¦ç»†ç²’åº¦å¤–è§‚ç‰¹å¾ç¼–ç ä¸ºåå·®é¡¹ä»¥å¢å¼ºç²—ç²’åº¦æç¤ºã€‚
(4) æ€§èƒ½ï¼šåœ¨ DeepFashion åŸºå‡†ä¸Šçš„å®šé‡å’Œå®šæ€§å®éªŒç»“æœè¯æ˜äº†æˆ‘ä»¬æ–¹æ³•åœ¨å§¿æ€å¼•å¯¼çš„äººç‰©å›¾åƒåˆæˆä»»åŠ¡ä¸Šçš„ä¼˜è¶Šæ€§ã€‚è¿™äº›æ€§èƒ½æ”¯æŒäº†ä»–ä»¬çš„ç›®æ ‡ï¼Œå³ç”Ÿæˆå…·æœ‰æ›´å¥½æ³›åŒ–æ€§èƒ½çš„é«˜è´¨é‡å›¾åƒã€‚</li>
</ol>
<p>7.Methodsï¼š
(1) æå‡ºç²—åˆ°ç»†æ½œåœ¨æ‰©æ•£ï¼ˆCFLDï¼‰æ–¹æ³•ï¼Œç”¨äºå§¿æ€å¼•å¯¼çš„äººç‰©å›¾åƒåˆæˆï¼›
(2) å¼€å‘åŸºäºå›¾åƒçš„æ–°è®­ç»ƒèŒƒå¼ï¼Œæ§åˆ¶é¢„è®­ç»ƒæ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹çš„ç”Ÿæˆè¿‡ç¨‹ï¼›
(3) è®¾è®¡æ„ŸçŸ¥ç²¾ç‚¼è§£ç å™¨ï¼Œæ¸è¿›ç»†åŒ–å¯å­¦ä¹ æŸ¥è¯¢ï¼Œæå–äººç‰©å›¾åƒè¯­ä¹‰ç†è§£ä½œä¸ºç²—ç²’åº¦æç¤ºï¼›
(4) æå‡ºæ··åˆç²’åº¦æ³¨æ„åŠ›æ¨¡å—ï¼Œå°†å¤šå°ºåº¦ç»†ç²’åº¦å¤–è§‚ç‰¹å¾ç¼–ç ä¸ºåå·®é¡¹ï¼Œå¢å¼ºç²—ç²’åº¦æç¤ºï¼›
(5) é€šè¿‡åœ¨DeepFashionåŸºå‡†ä¸Šçš„å®šé‡å’Œå®šæ€§å®éªŒï¼ŒéªŒè¯äº†CFLDæ–¹æ³•çš„ä¼˜è¶Šæ€§ã€‚</p>
<ol>
<li>
<p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰xxxï¼›
ï¼ˆ2ï¼‰åˆ›æ–°ç‚¹ï¼šxxxï¼›æ€§èƒ½ï¼šxxxï¼›å·¥ä½œé‡ï¼šxxxï¼›</p>
</li>
<li>
<p>æ€»ç»“ï¼š
ï¼ˆ1ï¼‰æœ¬å·¥ä½œçš„é‡è¦æ„ä¹‰æ˜¯ä»€ä¹ˆï¼Ÿ
ï¼ˆ2ï¼‰ä»åˆ›æ–°ç‚¹ã€æ€§èƒ½ã€å·¥ä½œé‡ä¸‰ä¸ªç»´åº¦æ€»ç»“æœ¬æ–‡çš„ä¼˜ç¼ºç‚¹ï¼š
åˆ›æ–°ç‚¹ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„ç²—åˆ°ç»†æ½œåœ¨æ‰©æ•£ï¼ˆCFLDï¼‰æ–¹æ³•ï¼Œç”¨äºå§¿æ€å¼•å¯¼çš„äººç‰©å›¾åƒåˆæˆã€‚è¯¥æ–¹æ³•é€šè¿‡æ¸è¿›ç»†åŒ–å¯å­¦ä¹ æŸ¥è¯¢ï¼Œæå–äººç‰©å›¾åƒçš„è¯­ä¹‰ç†è§£ä½œä¸ºç²—ç²’åº¦æç¤ºï¼Œå¹¶æå‡ºæ··åˆç²’åº¦æ³¨æ„åŠ›æ¨¡å—ï¼Œå°†å¤šå°ºåº¦ç»†ç²’åº¦å¤–è§‚ç‰¹å¾ç¼–ç ä¸ºåå·®é¡¹ï¼Œå¢å¼ºç²—ç²’åº¦æç¤ºã€‚
æ€§èƒ½ï¼šåœ¨ DeepFashion åŸºå‡†ä¸Šçš„å®šé‡å’Œå®šæ€§å®éªŒç»“æœè¯æ˜äº† CFLD æ–¹æ³•åœ¨å§¿æ€å¼•å¯¼çš„äººç‰©å›¾åƒåˆæˆä»»åŠ¡ä¸Šçš„ä¼˜è¶Šæ€§ã€‚è¿™äº›æ€§èƒ½æ”¯æŒäº†ä»–ä»¬çš„ç›®æ ‡ï¼Œå³ç”Ÿæˆå…·æœ‰æ›´å¥½æ³›åŒ–æ€§èƒ½çš„é«˜è´¨é‡å›¾åƒã€‚
å·¥ä½œé‡ï¼šæœ¬æ–‡çš„å·¥ä½œé‡é€‚ä¸­ã€‚è¯¥æ–¹æ³•çš„å®ç°éœ€è¦å¯¹æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹è¿›è¡Œé¢„è®­ç»ƒï¼Œè¿™å¯èƒ½éœ€è¦å¤§é‡çš„è®¡ç®—èµ„æºã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•éœ€è¦è®¾è®¡æ„ŸçŸ¥ç²¾ç‚¼è§£ç å™¨å’Œæ··åˆç²’åº¦æ³¨æ„åŠ›æ¨¡å—ï¼Œè¿™éœ€è¦é¢å¤–çš„å¼€å‘å’Œå®éªŒå·¥ä½œã€‚</p>
</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-ee807dc5573280abe63e138fa82f6eb3.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-07506917791ee3066c02770faa1a2052.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-5192aaa635e4ab29d557ee967971be49.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-269e1bea1b870d8f0466ace81c9d2e01.jpg" align="middle">
</details>




<h2 id="SynArtifact-Classifying-and-Alleviating-Artifacts-in-Synthetic-Images-via-Vision-Language-Model"><a href="#SynArtifact-Classifying-and-Alleviating-Artifacts-in-Synthetic-Images-via-Vision-Language-Model" class="headerlink" title="SynArtifact: Classifying and Alleviating Artifacts in Synthetic Images   via Vision-Language Model"></a>SynArtifact: Classifying and Alleviating Artifacts in Synthetic Images   via Vision-Language Model</h2><p><strong>Authors:Bin Cao, Jianhao Yuan, Yexin Liu, Jian Li, Shuyang Sun, Jing Liu, Bo Zhao</strong></p>
<p>In the rapidly evolving area of image synthesis, a serious challenge is the presence of complex artifacts that compromise perceptual realism of synthetic images. To alleviate artifacts and improve quality of synthetic images, we fine-tune Vision-Language Model (VLM) as artifact classifier to automatically identify and classify a wide range of artifacts and provide supervision for further optimizing generative models. Specifically, we develop a comprehensive artifact taxonomy and construct a dataset of synthetic images with artifact annotations for fine-tuning VLM, named SynArtifact-1K. The fine-tuned VLM exhibits superior ability of identifying artifacts and outperforms the baseline by 25.66%. To our knowledge, this is the first time such end-to-end artifact classification task and solution have been proposed. Finally, we leverage the output of VLM as feedback to refine the generative model for alleviating artifacts. Visualization results and user study demonstrate that the quality of images synthesized by the refined diffusion model has been obviously improved. </p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2402.18068v1">PDF</a> </p>
<p><strong>Summary</strong><br>åˆ©ç”¨é¢„è®­ç»ƒçš„è§†è§‰è¯­è¨€æ¨¡å‹å¯¹å›¾åƒåˆæˆä¸­çš„ä¼ªå½±è¿›è¡Œè‡ªåŠ¨åˆ†ç±»ï¼Œä¸ºç”Ÿæˆæ¨¡å‹çš„è¿›ä¸€æ­¥ä¼˜åŒ–æä¾›ç›‘ç®¡ï¼Œä»è€Œæé«˜åˆæˆå›¾åƒçš„è´¨é‡ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>åˆæˆå›¾åƒä¸­å¤æ‚ä¼ªå½±çš„å­˜åœ¨æ„æˆäº†ä¸€é¡¹é‡å¤§æŒ‘æˆ˜ï¼Œå¯¹æ„ŸçŸ¥çœŸå®æ€§äº§ç”Ÿäº†è´Ÿé¢å½±å“ã€‚</li>
<li>ç ”ç©¶äººå‘˜æå‡ºå°†è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMï¼‰å¾®è°ƒä¸ºä¼ªå½±åˆ†ç±»å™¨ï¼Œä»¥ä¾¿è‡ªåŠ¨è¯†åˆ«å’Œåˆ†ç±»å„ç§ä¼ªå½±ã€‚</li>
<li>å¼€å‘äº†ä¸€ä¸ªå…¨é¢çš„ä¼ªå½±åˆ†ç±»ä½“ç³»ï¼Œå¹¶æ„å»ºäº†ä¸€ä¸ªå…·æœ‰ä¼ªå½±æ³¨é‡Šçš„åˆæˆå›¾åƒæ•°æ®é›†ï¼ˆSynArtifact-1Kï¼‰ã€‚</li>
<li>å¾®è°ƒåçš„ VLM åœ¨è¯†åˆ«ä¼ªå½±æ–¹é¢è¡¨ç°å‡ºä¼˜å¼‚çš„èƒ½åŠ›ï¼Œæ¯”åŸºçº¿é«˜å‡º 25.66%ã€‚</li>
<li>è¿™æ˜¯é¦–æ¬¡æå‡ºæ­¤ç±»ç«¯åˆ°ç«¯ä¼ªå½±åˆ†ç±»ä»»åŠ¡å’Œè§£å†³æ–¹æ¡ˆã€‚</li>
<li>åˆ©ç”¨ VLM çš„è¾“å‡ºä½œä¸ºåé¦ˆæ¥ä¼˜åŒ–ç”Ÿæˆæ¨¡å‹ï¼Œä»¥å‡è½»ä¼ªå½±ã€‚</li>
<li>è§†è§‰åŒ–ç»“æœå’Œç”¨æˆ·ç ”ç©¶è¡¨æ˜ï¼Œä¼˜åŒ–åçš„æ‰©æ•£æ¨¡å‹åˆæˆçš„å›¾åƒè´¨é‡å¾—åˆ°äº†æ˜æ˜¾æ”¹å–„ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>è®ºæ–‡é¢˜ç›®ï¼šSynArtifactï¼šé€šè¿‡è§†è§‰è¯­è¨€æ¨¡å‹å¯¹åˆæˆå›¾åƒä¸­çš„ä¼ªå½±è¿›è¡Œåˆ†ç±»å’Œæ¶ˆé™¤</li>
<li>ä½œè€…ï¼šBin Cao, Jianhao Yuan, Yexin Liu, Jian Li, Shuyang Sun, Jing Liu, Bo Zhao</li>
<li>ç¬¬ä¸€ä½œè€…å•ä½ï¼šä¸­å›½ç§‘å­¦é™¢è‡ªåŠ¨åŒ–ç ”ç©¶æ‰€</li>
<li>å…³é”®è¯ï¼šåˆæˆå›¾åƒã€ä¼ªå½±ã€è§†è§‰è¯­è¨€æ¨¡å‹ã€ç”Ÿæˆæ¨¡å‹</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2402.18068</li>
<li>
<p>æ‘˜è¦ï¼š
(1) ç ”ç©¶èƒŒæ™¯ï¼šåˆæˆå›¾åƒä¸­å­˜åœ¨å¤æ‚ä¼ªå½±ï¼Œå½±å“å›¾åƒçš„æ„ŸçŸ¥çœŸå®æ€§ã€‚
(2) è¿‡å¾€æ–¹æ³•ï¼šç°æœ‰æ–¹æ³•ä¸»è¦ä¾èµ–å•ä¸€è¯„åˆ†æŒ‡æ ‡ä¼˜åŒ–ç”Ÿæˆæ¨¡å‹ï¼Œæ— æ³•æœ‰æ•ˆåæ˜ ä¼ªå½±çš„å¤šæ ·æ€§å’Œå¤æ‚æ€§ã€‚
(3) æœ¬æ–‡æ–¹æ³•ï¼šæå‡ºä¸€ä¸ªç»¼åˆä¼ªå½±åˆ†ç±»æ³•ï¼Œæ„å»ºäº†ä¸€ä¸ªå¸¦æœ‰ä¼ªå½±æ³¨é‡Šçš„åˆæˆå›¾åƒæ•°æ®é›† SynArtifact-1Kï¼Œå¹¶å¾®è°ƒè§†è§‰è¯­è¨€æ¨¡å‹ (VLM) å¯¹ä¼ªå½±è¿›è¡Œåˆ†ç±»ã€‚åˆ©ç”¨ VLM çš„è¾“å‡ºä½œä¸º AI åé¦ˆæ¥æ”¹è¿›ç”Ÿæˆæ¨¡å‹ï¼Œä»¥å‡è½»ä¼ªå½±ã€‚
(4) å®éªŒç»“æœï¼šå¾®è°ƒåçš„ VLM åœ¨ä¼ªå½±åˆ†ç±»ä»»åŠ¡ä¸Šæ¯”åŸºçº¿æ–¹æ³•æé«˜äº† 25.66% çš„å‡†ç¡®ç‡å’Œ 29.01% çš„ F1 åˆ†æ•°ã€‚é€šè¿‡åˆ©ç”¨ä¼ªå½±åˆ†ç±»å™¨çš„è¾“å‡ºä½œä¸º AI åé¦ˆï¼Œå¯ä»¥æœ‰æ•ˆå‡è½»ç”Ÿæˆæ¨¡å‹ä¸­çš„ä¼ªå½±ã€‚</p>
</li>
<li>
<p>æ–¹æ³•ï¼š
ï¼ˆ1ï¼‰æ„å»ºç»¼åˆä¼ªå½±åˆ†ç±»æ³•ï¼Œå»ºç«‹åŒ…å«ä¼ªå½±æ³¨é‡Šçš„åˆæˆå›¾åƒæ•°æ®é›† SynArtifact-1Kï¼›
ï¼ˆ2ï¼‰å¾®è°ƒè§†è§‰è¯­è¨€æ¨¡å‹ VLMï¼Œå°†å…¶ä½œä¸ºä¼ªå½±åˆ†ç±»å™¨ï¼›
ï¼ˆ3ï¼‰åˆ©ç”¨ VLM è¾“å‡ºä½œä¸º AI åé¦ˆï¼Œè®¡ç®—ç”Ÿæˆæ¨¡å‹è¾“å‡ºä¸æ¯ç§ä¼ªå½±ä¹‹é—´çš„ BertScoreï¼Œä½œä¸ºä¼ªå½±åˆ†ç±»å¥–åŠ±ï¼›
ï¼ˆ4ï¼‰é€šè¿‡æœ€å¤§åŒ–ä¼ªå½±åˆ†ç±»å¥–åŠ±ï¼Œä¼˜åŒ–æ‰©æ•£æ¨¡å‹ï¼Œä»¥å‡è½»ä¼ªå½±ã€‚</p>
</li>
<li>
<p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡é’ˆå¯¹åˆæˆå›¾åƒä¸­çš„ä¼ªå½±é—®é¢˜ï¼Œæå‡ºäº†ä¸€ä¸ªç»¼åˆçš„ä¼ªå½±åˆ†ç±»æ³•ï¼Œæ„å»ºäº†åŒ…å«ä¼ªå½±æ³¨é‡Šçš„åˆæˆå›¾åƒæ•°æ®é›† SynArtifact-1Kï¼Œå¹¶åˆ©ç”¨è§†è§‰è¯­è¨€æ¨¡å‹å¯¹ä¼ªå½±è¿›è¡Œåˆ†ç±»ï¼Œæœ‰æ•ˆåœ°å‡è½»äº†ç”Ÿæˆæ¨¡å‹ä¸­çš„ä¼ªå½±ï¼Œæå‡äº†åˆæˆå›¾åƒçš„æ„ŸçŸ¥çœŸå®æ€§ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</p>
</li>
<li>æ„å»ºäº†åŒ…å« 13 ç§å¸¸è§ä¼ªå½±çš„ç»¼åˆä¼ªå½±åˆ†ç±»æ³•ã€‚</li>
<li>åˆ›å»ºäº†é¦–ä¸ªå¸¦æœ‰ä¼ªå½±ç±»åˆ«ã€æè¿°å’Œåæ ‡æ³¨é‡Šçš„å›¾åƒæ•°æ®é›† SynArtifact-1Kã€‚</li>
<li>å¾®è°ƒè§†è§‰è¯­è¨€æ¨¡å‹ç”¨äºè‡ªåŠ¨åˆ†ç±»ä¼ªå½±ï¼Œå¹¶åˆ©ç”¨å…¶è¾“å‡ºä½œä¸º AI åé¦ˆæ¥ä¼˜åŒ–ç”Ÿæˆæ¨¡å‹ã€‚
æ€§èƒ½ï¼š</li>
<li>å¾®è°ƒåçš„è§†è§‰è¯­è¨€æ¨¡å‹åœ¨ä¼ªå½±åˆ†ç±»ä»»åŠ¡ä¸Šæ¯”åŸºçº¿æ–¹æ³•æé«˜äº† 25.66% çš„å‡†ç¡®ç‡å’Œ 29.01% çš„ F1 åˆ†æ•°ã€‚</li>
<li>åˆ©ç”¨ä¼ªå½±åˆ†ç±»å™¨çš„è¾“å‡ºä½œä¸º AI åé¦ˆï¼Œå¯ä»¥æœ‰æ•ˆå‡è½»ç”Ÿæˆæ¨¡å‹ä¸­çš„ä¼ªå½±ã€‚
å·¥ä½œé‡ï¼š</li>
<li>æ„å»ºäº†åŒ…å« 1000 å¼ åˆæˆå›¾åƒçš„ SynArtifact-1K æ•°æ®é›†ã€‚</li>
<li>å¾®è°ƒäº†è§†è§‰è¯­è¨€æ¨¡å‹ç”¨äºä¼ªå½±åˆ†ç±»ã€‚</li>
<li>é€šè¿‡æœ€å¤§åŒ–ä¼ªå½±åˆ†ç±»å¥–åŠ±ï¼Œä¼˜åŒ–äº†æ‰©æ•£æ¨¡å‹ä»¥å‡è½»ä¼ªå½±ã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-887bb2eb3bab7f102340a00fb115308a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a67234ceff494848cb67aa7bc7345a5e.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-c0c890345f83368ccd384b81c55c4b11.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-48d8c1e1b56b76bfccfccfcb96c1d5a4.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-1a5599c3d37db39e68fa5fb2e0139cec.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-94675e3c8e66717ee97bc9e3472ed274.jpg" align="middle">
</details>




<h2 id="Box-It-to-Bind-It-Unified-Layout-Control-and-Attribute-Binding-in-T2I-Diffusion-Models"><a href="#Box-It-to-Bind-It-Unified-Layout-Control-and-Attribute-Binding-in-T2I-Diffusion-Models" class="headerlink" title="Box It to Bind It: Unified Layout Control and Attribute Binding in T2I   Diffusion Models"></a>Box It to Bind It: Unified Layout Control and Attribute Binding in T2I   Diffusion Models</h2><p><strong>Authors:Ashkan Taghipour, Morteza Ghahremani, Mohammed Bennamoun, Aref Miri Rekavandi, Hamid Laga, Farid Boussaid</strong></p>
<p>While latent diffusion models (LDMs) excel at creating imaginative images, they often lack precision in semantic fidelity and spatial control over where objects are generated. To address these deficiencies, we introduce the Box-it-to-Bind-it (B2B) module - a novel, training-free approach for improving spatial control and semantic accuracy in text-to-image (T2I) diffusion models. B2B targets three key challenges in T2I: catastrophic neglect, attribute binding, and layout guidance. The process encompasses two main steps: i) Object generation, which adjusts the latent encoding to guarantee object generation and directs it within specified bounding boxes, and ii) attribute binding, guaranteeing that generated objects adhere to their specified attributes in the prompt. B2B is designed as a compatible plug-and-play module for existing T2I models, markedly enhancing model performance in addressing the key challenges. We evaluate our technique using the established CompBench and TIFA score benchmarks, demonstrating significant performance improvements compared to existing methods. The source code will be made publicly available at <a target="_blank" rel="noopener" href="https://github.com/nextaistudio/BoxIt2BindIt">https://github.com/nextaistudio/BoxIt2BindIt</a>. </p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2402.17910v1">PDF</a> </p>
<p><strong>Summary</strong><br>Box-it-to-Bind-itï¼ˆB2Bï¼‰æ˜¯ä¸€ç§æ— éœ€è®­ç»ƒçš„æ–°æ¨¡å—ï¼Œå¯æé«˜æ–‡æœ¬åˆ°å›¾åƒï¼ˆT2Iï¼‰æ‰©æ•£æ¨¡å‹ä¸­å›¾åƒçš„ç”Ÿæˆè´¨é‡ã€è¯­ä¹‰å‡†ç¡®åº¦å’Œç©ºé—´æ§åˆ¶èƒ½åŠ›ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>B2B æ¨¡å—å¯æ”¹å–„ T2I ä¸­çš„ä¸‰ä¸ªå…³é”®æŒ‘æˆ˜ï¼šç¾éš¾æ€§é—æ¼ã€å±æ€§ç»‘å®šå’Œå¸ƒå±€æŒ‡å¯¼ã€‚</li>
<li>B2B åŒ…æ‹¬ç”Ÿæˆå¯¹è±¡å’Œå±æ€§ç»‘å®šçš„ä¸¤ä¸ªä¸»è¦æ­¥éª¤ã€‚</li>
<li>B2B å¯ä½œä¸ºç°æœ‰çš„ T2I æ¨¡å‹çš„å³æ’å³ç”¨æ¨¡å—ï¼Œæ— éœ€è®­ç»ƒã€‚</li>
<li>B2B åœ¨ CompBench å’Œ TIFA è¯„åˆ†åŸºå‡†ä¸Šè¡¨ç°å‡ºæ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚</li>
<li>B2B çš„æºä»£ç å°†åœ¨ <a target="_blank" rel="noopener" href="https://github.com/nextaistudio/BoxIt2BindIt">https://github.com/nextaistudio/BoxIt2BindIt</a> ä¸Šå…¬å¼€ã€‚</li>
<li>B2B æé«˜äº† LDM åœ¨ç”Ÿæˆå›¾åƒæ—¶çš„ç©ºé—´æ§åˆ¶å’Œè¯­ä¹‰å‡†ç¡®æ€§ã€‚</li>
<li>B2B é€‚ç”¨äºä¸åŒçš„ T2I æ¨¡å‹ï¼Œæ˜“äºé›†æˆã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>é¢˜ç›®ï¼šBox-it-to-Bind-itï¼šç»Ÿä¸€å¸ƒå±€æ§åˆ¶å’Œå±æ€§ç»‘å®šåˆ° T2I æ‰©æ•£æ¨¡å‹ä¸­</li>
<li>ä½œè€…ï¼šAshkan Taghipour, Morteza Ghahremani, Mohammed Bennamoun, Aref Miri Rekavandi, Hamid Laga, Farid Boussaid</li>
<li>ç¬¬ä¸€ä½œè€…å•ä½ï¼šè¥¿æ¾³å¤§åˆ©äºšå¤§å­¦</li>
<li>å…³é”®è¯ï¼šæ–‡æœ¬åˆ°å›¾åƒã€æ‰©æ•£æ¨¡å‹ã€ç©ºé—´æ§åˆ¶ã€å±æ€§ç»‘å®šã€å¸ƒå±€å¼•å¯¼</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2402.17910</li>
<li>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼š
ç°æœ‰æ‰©æ•£æ¨¡å‹åœ¨ç”Ÿæˆå›¾åƒæ—¶ç¼ºä¹è¯­ä¹‰ä¿çœŸåº¦å’Œç©ºé—´æ§åˆ¶ï¼Œéš¾ä»¥å¿ å®åœ°éµå¾ªç»™å®šçš„æç¤ºï¼Œå°¤å…¶æ˜¯åœ¨å¯¹è±¡å±æ€§å’Œå¯¹è±¡æ”¾ç½®æ–¹é¢ã€‚</li>
</ol>
<p>ï¼ˆ2ï¼‰è¿‡å»çš„æ–¹æ³•å’Œé—®é¢˜ï¼š
ç°æœ‰æ–¹æ³•è¦ä¹ˆä»å¤´å¼€å§‹è®­ç»ƒæ¨¡å‹ï¼Œè¦ä¹ˆå¾®è°ƒç°æœ‰æ¨¡å‹ï¼Œä½†éœ€è¦å¤§é‡è®¡ç®—èµ„æºå’Œæ—¶é—´ã€‚æ­¤å¤–ï¼Œåˆ©ç”¨é¢„è®­ç»ƒæ¨¡å‹å¹¶é›†æˆç‰¹å¾çš„æ–¹æ³•è™½ç„¶ä¸éœ€è¦å¤§é‡è®­ç»ƒï¼Œä½†æ•ˆæœæœ‰é™ã€‚</p>
<p>ï¼ˆ3ï¼‰æå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼š
æœ¬æ–‡æå‡ºäº†ä¸€ç§å…è®­ç»ƒçš„æ–¹æ³• Box-it-to-Bind-it (B2B)ï¼Œè§£å†³æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆä¸­çš„ä¸‰ä¸ªå…³é”®æŒ‘æˆ˜ï¼šç¾éš¾æ€§é—æ¼ã€å±æ€§ç»‘å®šå’Œå¸ƒå±€å¼•å¯¼ã€‚B2B åœ¨æ¨ç†é˜¶æ®µé€šè¿‡ä¸¤æ­¥å¼•å¯¼æ‰©æ•£æ¨¡å‹çš„æ½œåœ¨ç¼–ç ï¼šå¯¹è±¡ç”Ÿæˆå’Œå±æ€§ç»‘å®šã€‚</p>
<p>ï¼ˆ4ï¼‰æ–¹æ³•åœ¨ä»»åŠ¡å’Œæ€§èƒ½ä¸Šçš„è¡¨ç°ï¼š
åœ¨ CompBench å’Œ TIFA å¾—åˆ†åŸºå‡†ä¸Šï¼Œä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼ŒB2B åœ¨è§£å†³å…³é”®æŒ‘æˆ˜æ–¹é¢æ˜¾ç€æé«˜äº†æ¨¡å‹æ€§èƒ½ã€‚è¿™äº›æ€§èƒ½æå‡æ”¯æŒäº†æœ¬æ–‡çš„ç›®æ ‡ï¼Œå³æé«˜æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆä¸­çš„ç©ºé—´æ§åˆ¶å’Œè¯­ä¹‰å‡†ç¡®æ€§ã€‚</p>
<p>æ–¹æ³•ï¼š
(1) B2Bæ˜¯ä¸€ç§å¥–åŠ±å¼•å¯¼æ‰©æ•£æ¨¡å‹ï¼Œå®ƒåœ¨æ¨ç†é˜¶æ®µé€šè¿‡ä¸¤æ­¥å¼•å¯¼æ‰©æ•£æ¨¡å‹çš„æ½œåœ¨ç¼–ç ï¼šå¯¹è±¡ç”Ÿæˆå’Œå±æ€§ç»‘å®šã€‚
(2) å¯¹è±¡ç”Ÿæˆï¼šåŸºäºIoUï¼Œå¢åŠ å¯¹è±¡ç”Ÿæˆæ¦‚ç‡ï¼Œå°†æ³¨æ„åŠ›æƒé‡é›†ä¸­åœ¨ç»™å®šè¾¹ç•Œæ¡†å†…ï¼ŒåŒæ—¶æŠ‘åˆ¶è¾¹ç•Œæ¡†å¤–çš„æ³¨æ„åŠ›æƒé‡ã€‚
(3) å±æ€§ç»‘å®šï¼šä½¿ç”¨KLæ•£åº¦æµ‹é‡å±æ€§æ¦‚ç‡åˆ†å¸ƒä¸å¯¹åº”å¯¹è±¡æ¦‚ç‡åˆ†å¸ƒçš„å·®å¼‚ï¼Œå‡å°‘å·®å¼‚ï¼Œå°†å±æ€§åˆ†å¸ƒå¼ºåˆ¶æ”¶æ•›åˆ°å„è‡ªçš„å¯¹è±¡ã€‚</p>
<ol>
<li>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬ç ”ç©¶é’ˆå¯¹æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆä¸­çš„å…³é”®æŒ‘æˆ˜ï¼Œç‰¹åˆ«æ˜¯å±æ€§ç»‘å®šå’Œç©ºé—´æ§åˆ¶ï¼Œæå‡ºäº† B2B æ¨¡å‹ã€‚B2B é‡‡ç”¨ç”Ÿæˆå’Œç»‘å®šåŒæ¨¡å—ç³»ç»Ÿï¼Œæœ‰æ•ˆè§£å†³äº†ç¾éš¾æ€§é—æ¼ã€æé«˜å±æ€§ç»‘å®šç²¾åº¦å’Œç¡®ä¿å‡†ç¡®å¯¹è±¡æ”¾ç½®çš„é—®é¢˜ã€‚å®ƒä½œä¸ºç°æœ‰ T2I æ¡†æ¶çš„å³æ’å³ç”¨æ¨¡å—çš„å…¼å®¹æ€§é€šè¿‡å…¶åœ¨ CompBench å’Œ TIFA åŸºå‡†ä¸­çš„å‡ºè‰²è¡¨ç°å¾—åˆ°è¯æ˜ï¼Œæ ‡å¿—ç€ç”Ÿæˆå»ºæ¨¡çš„é‡å¤§é£è·ƒã€‚B2B çš„çªç ´å‡¸æ˜¾äº†å…¶ä½œä¸ºæœªæ¥ç ”ç©¶æ½œåœ¨æ ‡å‡†çš„ä½œç”¨ï¼Œä¸ºæ•°å­—æˆåƒå’Œç”Ÿæˆå¼ AI çš„åˆ›æ–°å‘å±•é“ºå¹³äº†é“è·¯ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</li>
<li>æå‡ºäº†ä¸€ç§å…è®­ç»ƒçš„æ–¹æ³• B2Bï¼Œé€šè¿‡ä¸¤æ­¥å¼•å¯¼æ‰©æ•£æ¨¡å‹çš„æ½œåœ¨ç¼–ç æ¥è§£å†³æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆä¸­çš„å…³é”®æŒ‘æˆ˜ã€‚</li>
<li>è®¾è®¡äº†å¯¹è±¡ç”Ÿæˆå’Œå±æ€§ç»‘å®šä¸¤ä¸ªæ¨¡å—ï¼Œæœ‰æ•ˆè§£å†³äº†ç¾éš¾æ€§é—æ¼ã€å±æ€§ç»‘å®šå’Œå¸ƒå±€å¼•å¯¼é—®é¢˜ã€‚</li>
<li>B2B ä½œä¸ºç°æœ‰ T2I æ¡†æ¶çš„å³æ’å³ç”¨æ¨¡å—ï¼Œæ˜“äºé›†æˆå’Œä½¿ç”¨ã€‚
æ€§èƒ½ï¼š</li>
<li>åœ¨ CompBench å’Œ TIFA åŸºå‡†ä¸Šï¼Œä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼ŒB2B åœ¨è§£å†³å…³é”®æŒ‘æˆ˜æ–¹é¢æ˜¾ç€æé«˜äº†æ¨¡å‹æ€§èƒ½ã€‚</li>
<li>æ¶ˆèç ”ç©¶éªŒè¯äº†å¯¹è±¡ç”Ÿæˆå’Œå±æ€§ç»‘å®šå¥–åŠ±ç»„ä»¶çš„æœ‰æ•ˆæ€§ï¼Œè¡¨æ˜ B2B çš„å„ä¸ªç»„ä»¶å¯¹æ•´ä½“æ€§èƒ½è‡³å…³é‡è¦ã€‚
å·¥ä½œé‡ï¼š</li>
<li>B2B æ˜¯ä¸€ç§å…è®­ç»ƒçš„æ–¹æ³•ï¼Œä¸éœ€è¦ä»å¤´å¼€å§‹è®­ç»ƒæ¨¡å‹æˆ–å¾®è°ƒç°æœ‰æ¨¡å‹ï¼Œä»è€ŒèŠ‚çœäº†å¤§é‡çš„è®¡ç®—èµ„æºå’Œæ—¶é—´ã€‚</li>
<li>B2B æ˜“äºé›†æˆåˆ°ç°æœ‰ T2I æ¡†æ¶ä¸­ï¼Œæ— éœ€è¿›è¡Œå¤æ‚çš„ä¿®æ”¹æˆ–é‡æ–°è®­ç»ƒï¼Œé™ä½äº†å·¥ä½œé‡ã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-9044558cdc31309b419fea5199aa8a89.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-78bccd36910d4aa870962c445823ad57.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-967a215bde68183f03e457a7ff3f8e9a.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-e2a4cdc833464a14406a357aa9e0c358.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d140c3c8e05d724098a1c03138203a01.jpg" align="middle">
</details>




<h2 id="Structure-Guided-Adversarial-Training-of-Diffusion-Models"><a href="#Structure-Guided-Adversarial-Training-of-Diffusion-Models" class="headerlink" title="Structure-Guided Adversarial Training of Diffusion Models"></a>Structure-Guided Adversarial Training of Diffusion Models</h2><p><strong>Authors:Ling Yang, Haotian Qian, Zhilong Zhang, Jingwei Liu, Bin Cui</strong></p>
<p>Diffusion models have demonstrated exceptional efficacy in various generative applications. While existing models focus on minimizing a weighted sum of denoising score matching losses for data distribution modeling, their training primarily emphasizes instance-level optimization, overlooking valuable structural information within each mini-batch, indicative of pair-wise relationships among samples. To address this limitation, we introduce Structure-guided Adversarial training of Diffusion Models (SADM). In this pioneering approach, we compel the model to learn manifold structures between samples in each training batch. To ensure the model captures authentic manifold structures in the data distribution, we advocate adversarial training of the diffusion generator against a novel structure discriminator in a minimax game, distinguishing real manifold structures from the generated ones. SADM substantially improves existing diffusion transformers (DiT) and outperforms existing methods in image generation and cross-domain fine-tuning tasks across 12 datasets, establishing a new state-of-the-art FID of 1.58 and 2.11 on ImageNet for class-conditional image generation at resolutions of 256x256 and 512x512, respectively. </p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2402.17563v1">PDF</a> Accepted by CVPR 2024</p>
<p><strong>Summary</strong><br>æ‰©æ•£æ¨¡å‹é€šè¿‡ç»“æ„å¯¹æŠ—è®­ç»ƒï¼Œå­¦ä¹ æ‰¹å†…æ ·æœ¬æµå½¢ç»“æ„ï¼Œæå‡å›¾åƒç”Ÿæˆå’Œè·¨åŸŸå¾®è°ƒä»»åŠ¡çš„æ€§èƒ½ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>ç°æœ‰æ‰©æ•£æ¨¡å‹ä¸“æ³¨äºå•ä¸ªæ ·æœ¬çš„å»å™ªå¾—åˆ†åŒ¹é…æŸå¤±ä¼˜åŒ–ï¼Œå¿½è§†æ‰¹å†…æ ·æœ¬ä¹‹é—´çš„æˆå¯¹å…³ç³»ã€‚</li>
<li>ç»“æ„å¯¹æŠ—è®­ç»ƒ (SADM) å¼•å…¥ç»“æ„é‰´åˆ«å™¨æ¥åŒºåˆ†çœŸå®å’Œç”Ÿæˆçš„æµå½¢ç»“æ„ã€‚</li>
<li>SADM è¿«ä½¿æ¨¡å‹å­¦ä¹ è®­ç»ƒæ‰¹æ¬¡ä¸­æ ·æœ¬ä¹‹é—´çš„æµå½¢ç»“æ„ã€‚</li>
<li>SADM ä¸æ‰©æ•£å˜å‹å™¨ (DiT) ç›¸ç»“åˆï¼Œåœ¨å›¾åƒç”Ÿæˆå’Œè·¨åŸŸå¾®è°ƒä»»åŠ¡ä¸Šä¼˜äºç°æœ‰æ–¹æ³•ã€‚</li>
<li>SADM åœ¨ 12 ä¸ªæ•°æ®é›†ä¸Šå®ç°äº†å›¾åƒç”Ÿæˆå’Œè·¨åŸŸå¾®è°ƒä»»åŠ¡çš„æœ€æ–° FID åˆ†åˆ«ä¸º 1.58 å’Œ 2.11ã€‚</li>
<li>SADM åœ¨ 256x256 å’Œ 512x512 åˆ†è¾¨ç‡ä¸‹ï¼Œåœ¨ ImageNet ä¸Šå®ç°äº†ç±»æ¡ä»¶å›¾åƒç”Ÿæˆçš„æœ€æ–° FID åˆ†åˆ«ä¸º 1.58 å’Œ 2.11ã€‚</li>
<li>SADM è¯æ˜äº†æµå½¢ç»“æ„å­¦ä¹ å¯¹äºæ‰©æ•£æ¨¡å‹åœ¨ç”Ÿæˆä»»åŠ¡ä¸­çš„é‡è¦æ€§ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>é¢˜ç›®ï¼šç»“æ„å¼•å¯¼æ‰©æ•£æ¨¡å‹å¯¹æŠ—æ€§è®­ç»ƒ</li>
<li>ä½œè€…ï¼šæ¨å‡Œã€é’±æµ©å¤©ã€å¼ æ™ºé¾™ã€åˆ˜æ™¯ä¼Ÿã€å´”æ–Œ</li>
<li>ç¬¬ä¸€ä½œè€…å•ä½ï¼šåŒ—äº¬å¤§å­¦</li>
<li>å…³é”®è¯ï¼šæ‰©æ•£æ¨¡å‹ã€ç»“æ„å¼•å¯¼ã€å¯¹æŠ—è®­ç»ƒ</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2402.17563
   Github é“¾æ¥ï¼šæ— </li>
<li>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼š
æ‰©æ•£æ¨¡å‹åœ¨ç”Ÿæˆä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ï¼Œä½†ç°æœ‰æ–¹æ³•ä¸»è¦å…³æ³¨æœ€å°åŒ–å»å™ªå¾—åˆ†åŒ¹é…æŸå¤±çš„åŠ æƒå’Œï¼Œè®­ç»ƒè¿‡ç¨‹ä¾§é‡äºå®ä¾‹çº§ä¼˜åŒ–ï¼Œå¿½ç•¥äº†å°æ‰¹é‡æ ·æœ¬ä¹‹é—´çš„å®è´µç»“æ„ä¿¡æ¯ã€‚</li>
</ol>
<p>ï¼ˆ2ï¼‰è¿‡å»çš„æ–¹æ³•åŠå…¶é—®é¢˜ï¼š
ç°æœ‰æ–¹æ³•ä¸»è¦é›†ä¸­åœ¨å®ä¾‹çº§ä¼˜åŒ–ï¼Œå¿½ç•¥äº†å°æ‰¹é‡æ ·æœ¬ä¹‹é—´çš„ç»“æ„ä¿¡æ¯ï¼Œå¯¼è‡´æ— æ³•å……åˆ†å»ºæ¨¡æ•°æ®åˆ†å¸ƒã€‚</p>
<p>ï¼ˆ3ï¼‰æå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼š
æå‡ºç»“æ„å¼•å¯¼æ‰©æ•£æ¨¡å‹å¯¹æŠ—æ€§è®­ç»ƒï¼ˆSADMï¼‰ï¼Œé€šè¿‡å¯¹æŠ—è®­ç»ƒæŒ‡å¯¼æ‰©æ•£ç”Ÿæˆå™¨å­¦ä¹ å°æ‰¹é‡æ ·æœ¬ä¹‹é—´çš„æµå½¢ç»“æ„ã€‚å¼•å…¥ç»“æ„åˆ¤åˆ«å™¨æ¥åŒºåˆ†çœŸå®æµå½¢ç»“æ„å’Œç”Ÿæˆæµå½¢ç»“æ„ï¼Œç¡®ä¿æ¨¡å‹æ•è·æ•°æ®åˆ†å¸ƒä¸­çš„çœŸå®æµå½¢ç»“æ„ã€‚</p>
<p>ï¼ˆ4ï¼‰æ–¹æ³•åœ¨ä»»åŠ¡å’Œæ€§èƒ½ä¸Šçš„è¡¨ç°ï¼š
SADM æ˜¾è‘—æå‡äº†ç°æœ‰æ‰©æ•£ Transformerï¼Œåœ¨ 12 ä¸ªæ•°æ®é›†ä¸Šçš„å›¾åƒç”Ÿæˆå’Œè·¨åŸŸå¾®è°ƒä»»åŠ¡ä¸­ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œåœ¨ ImageNet ä¸Šåˆ†åˆ«ä»¥ 256Ã—256 å’Œ 512Ã—512 çš„åˆ†è¾¨ç‡å®ç°äº† 1.58 å’Œ 2.11 çš„æ–° SOTA FIDï¼ŒéªŒè¯äº†æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚</p>
<p>7.Methodsï¼š
ï¼ˆ1ï¼‰æå‡ºç»“æ„å¼•å¯¼æ‰©æ•£æ¨¡å‹å¯¹æŠ—æ€§è®­ç»ƒï¼ˆSADMï¼‰ï¼Œé€šè¿‡å¯¹æŠ—è®­ç»ƒæŒ‡å¯¼æ‰©æ•£ç”Ÿæˆå™¨å­¦ä¹ å°æ‰¹é‡æ ·æœ¬ä¹‹é—´çš„æµå½¢ç»“æ„ï¼›
ï¼ˆ2ï¼‰å¼•å…¥ç»“æ„åˆ¤åˆ«å™¨æ¥åŒºåˆ†çœŸå®æµå½¢ç»“æ„å’Œç”Ÿæˆæµå½¢ç»“æ„ï¼Œç¡®ä¿æ¨¡å‹æ•è·æ•°æ®åˆ†å¸ƒä¸­çš„çœŸå®æµå½¢ç»“æ„ï¼›
ï¼ˆ3ï¼‰é‡‡ç”¨Wasserstein GANæŸå¤±å‡½æ•°ï¼ŒæŒ‡å¯¼ç”Ÿæˆå™¨ç”Ÿæˆä¸çœŸå®æµå½¢ç»“æ„ç›¸ä¼¼çš„æ ·æœ¬ï¼›
ï¼ˆ4ï¼‰åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­äº¤æ›¿æ›´æ–°ç”Ÿæˆå™¨å’Œåˆ¤åˆ«å™¨ï¼Œç›´è‡³è¾¾åˆ°çº³ä»€å‡è¡¡ï¼›
ï¼ˆ5ï¼‰å°†SADMä¸æ‰©æ•£Transformerç›¸ç»“åˆï¼Œå½¢æˆæ›´å¼ºå¤§çš„å›¾åƒç”Ÿæˆæ¨¡å‹ã€‚</p>
<ol>
<li>æ€»ç»“
(1): æœ¬æ–‡æå‡ºäº†ä»ç»“æ„è§’åº¦ä¼˜åŒ–æ‰©æ•£æ¨¡å‹çš„ç»“æ„å¼•å¯¼å¯¹æŠ—æ€§è®­ç»ƒæ–¹æ³•ï¼Œè¯¥è®­ç»ƒç®—æ³•å¯ä»¥è½»æ¾æ¨å¹¿åˆ°å›¾åƒå’Œæ½œåœ¨æ‰©æ•£æ¨¡å‹ï¼Œå¹¶é€šè¿‡ç†è®ºæ¨å¯¼å’Œå®éªŒç»“æœä¸€è‡´åœ°æ”¹è¿›äº†ç°æœ‰çš„æ‰©æ•£æ¨¡å‹ã€‚æˆ‘ä»¬åœ¨ 12 ä¸ªå›¾åƒæ•°æ®é›†ä¸Šçš„å›¾åƒç”Ÿæˆå’Œè·¨åŸŸå¾®è°ƒä»»åŠ¡ä¸­å–å¾—äº†æ–°çš„ SOTA æ€§èƒ½ã€‚å¯¹äºæœªæ¥çš„å·¥ä½œï¼Œæˆ‘ä»¬å°†æŠŠæˆ‘ä»¬çš„æ–¹æ³•æ‰©å±•åˆ°æ›´å…·æŒ‘æˆ˜æ€§çš„åŸºäºæ‰©æ•£çš„åº”ç”¨ç¨‹åºï¼ˆä¾‹å¦‚ï¼Œæ–‡æœ¬åˆ°å›¾åƒ/è§†é¢‘ç”Ÿæˆï¼‰ã€‚
(2): åˆ›æ–°ç‚¹: æå‡ºç»“æ„å¼•å¯¼å¯¹æŠ—æ€§è®­ç»ƒæ–¹æ³•ï¼Œé€šè¿‡å¯¹æŠ—è®­ç»ƒæŒ‡å¯¼æ‰©æ•£ç”Ÿæˆå™¨å­¦ä¹ å°æ‰¹é‡æ ·æœ¬ä¹‹é—´çš„æµå½¢ç»“æ„ï¼Œä»è€Œæå‡æ‰©æ•£æ¨¡å‹çš„ç”Ÿæˆè´¨é‡ã€‚
æ€§èƒ½: åœ¨ 12 ä¸ªå›¾åƒæ•°æ®é›†ä¸Šçš„å›¾åƒç”Ÿæˆå’Œè·¨åŸŸå¾®è°ƒä»»åŠ¡ä¸­å–å¾—äº†æ–°çš„ SOTA æ€§èƒ½ï¼Œåœ¨ ImageNet ä¸Šåˆ†åˆ«ä»¥ 256Ã—256 å’Œ 512Ã—512 çš„åˆ†è¾¨ç‡å®ç°äº† 1.58 å’Œ 2.11 çš„æ–° SOTAFIDã€‚
å·¥ä½œé‡: è¯¥æ–¹æ³•æ˜“äºå®ç°ï¼Œå¯ä»¥è½»æ¾æ¨å¹¿åˆ°å›¾åƒå’Œæ½œåœ¨æ‰©æ•£æ¨¡å‹ï¼Œå·¥ä½œé‡è¾ƒå°ã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-11a45496d9d4169c7ee0bbb4a6534ffa.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b4ae1e4da806d223271756f678f15ce9.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-02b820484fca35ffef9bc52706101c79.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-14ed9373ba8bdaf3ecaca75391245256.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-75ca2aa69507bb15984388d3520039af.jpg" align="middle">
</details>




<h2 id="Diffusion-Model-Based-Image-Editing-A-Survey"><a href="#Diffusion-Model-Based-Image-Editing-A-Survey" class="headerlink" title="Diffusion Model-Based Image Editing: A Survey"></a>Diffusion Model-Based Image Editing: A Survey</h2><p><strong>Authors:Yi Huang, Jiancheng Huang, Yifan Liu, Mingfu Yan, Jiaxi Lv, Jianzhuang Liu, Wei Xiong, He Zhang, Shifeng Chen, Liangliang Cao</strong></p>
<p>Denoising diffusion models have emerged as a powerful tool for various image generation and editing tasks, facilitating the synthesis of visual content in an unconditional or input-conditional manner. The core idea behind them is learning to reverse the process of gradually adding noise to images, allowing them to generate high-quality samples from a complex distribution. In this survey, we provide an exhaustive overview of existing methods using diffusion models for image editing, covering both theoretical and practical aspects in the field. We delve into a thorough analysis and categorization of these works from multiple perspectives, including learning strategies, user-input conditions, and the array of specific editing tasks that can be accomplished. In addition, we pay special attention to image inpainting and outpainting, and explore both earlier traditional context-driven and current multimodal conditional methods, offering a comprehensive analysis of their methodologies. To further evaluate the performance of text-guided image editing algorithms, we propose a systematic benchmark, EditEval, featuring an innovative metric, LMM Score. Finally, we address current limitations and envision some potential directions for future research. The accompanying repository is released at <a target="_blank" rel="noopener" href="https://github.com/SiatMMLab/Awesome-Diffusion-Model-Based-Image-Editing-Methods">https://github.com/SiatMMLab/Awesome-Diffusion-Model-Based-Image-Editing-Methods</a>. </p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2402.17525v1">PDF</a> </p>
<p><strong>Summary</strong><br>æ‰©æ•£æ¨¡å‹åœ¨å›¾åƒç”Ÿæˆå’Œç¼–è¾‘ä»»åŠ¡ä¸­åº”ç”¨å¹¿æ³›ï¼Œå¯ä»å¤æ‚åˆ†å¸ƒä¸­ç”Ÿæˆé«˜è´¨é‡æ ·æœ¬ï¼Œä¸”æ”¯æŒæ— æ¡ä»¶å’Œè¾“å…¥æ¡ä»¶ä¸‹çš„å›¾åƒç¼–è¾‘ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>æ‰©æ•£æ¨¡å‹é€šè¿‡å­¦ä¹ é€†è½¬å›¾åƒåŠ å™ªè¿‡ç¨‹ï¼Œç”Ÿæˆé«˜è´¨é‡æ ·æœ¬ã€‚</li>
<li>æ‰©æ•£æ¨¡å‹å›¾åƒç¼–è¾‘æ–¹æ³•å¯åˆ†ä¸ºä¸åŒå­¦ä¹ ç­–ç•¥ã€ç”¨æˆ·è¾“å…¥æ¡ä»¶å’Œç¼–è¾‘ä»»åŠ¡ã€‚</li>
<li>å›¾åƒä¿®å¤å’Œå¤–å»¶å¯ä½¿ç”¨ä¼ ç»Ÿä¸Šä¸‹æ–‡é©±åŠ¨æ–¹æ³•æˆ–å¤šæ¨¡æ€æ¡ä»¶æ–¹æ³•ã€‚</li>
<li>æå‡º EditEval åŸºå‡†å’Œ LMM è¯„åˆ†ç”¨äºè¯„ä¼°æ–‡æœ¬æŒ‡å¯¼å›¾åƒç¼–è¾‘ç®—æ³•ã€‚</li>
<li>ç›®å‰å­˜åœ¨é™åˆ¶ï¼Œæœªæ¥ç ”ç©¶æ–¹å‘åŒ…æ‹¬å¤šæ¨¡æ€ã€3D å’Œç¼–è¾‘å…ƒæ•°æ®ã€‚</li>
<li>å¯åœ¨ <a target="_blank" rel="noopener" href="https://github.com/SiatMMLab/Awesome-Diffusion-Model-Based-Image-Editing-Methods">https://github.com/SiatMMLab/Awesome-Diffusion-Model-Based-Image-Editing-Methods</a> è·å–ç›¸å…³ä»£ç ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>æ ‡é¢˜ï¼šåŸºäºæ‰©æ•£æ¨¡å‹çš„å›¾åƒç¼–è¾‘ï¼šç»¼è¿°</li>
<li>ä½œè€…ï¼šYi Huangã€Jiancheng Huangã€Yifan Liuã€Mingfu Yanã€Jiaxi Lvã€Jianzhuang Liuã€Wei Xiongã€He Zhangã€Shifeng Chenã€Liangliang Cao</li>
<li>å•ä½ï¼šæ·±åœ³å…ˆè¿›æŠ€æœ¯ç ”ç©¶é™¢</li>
<li>å…³é”®è¯ï¼šDiffusion Modelã€Image Editingã€AIGC</li>
<li>é“¾æ¥ï¼šhttps://arxiv.org/abs/2402.17525
Githubï¼šæ— </li>
<li>æ‘˜è¦ï¼š
(1)ï¼šéšç€äººå·¥æ™ºèƒ½ï¼ˆAIï¼‰æŠ€æœ¯çš„å‘å±•ï¼ŒAI ç”Ÿæˆçš„å†…å®¹ï¼ˆAIGCï¼‰é¢†åŸŸè“¬å‹ƒå‘å±•ï¼Œå›¾åƒç¼–è¾‘ä½œä¸ºå…¶ä¸­ä¸€é¡¹é‡è¦ä»»åŠ¡ï¼Œåœ¨æ•°å­—åª’ä½“ã€å¹¿å‘Šå’Œç§‘å­¦ç ”ç©¶ç­‰é¢†åŸŸæœ‰ç€å¹¿æ³›çš„åº”ç”¨ã€‚
(2)ï¼šåŸºäºæ‰©æ•£æ¨¡å‹çš„å›¾åƒç¼–è¾‘æ–¹æ³•è¿‘å¹´æ¥å–å¾—äº†æ˜¾è‘—è¿›å±•ï¼Œè¯¥æ–¹æ³•é€šè¿‡å­¦ä¹ é€æ­¥ç»™å›¾åƒæ·»åŠ å™ªå£°å¹¶é€†è½¬è¿™ä¸€è¿‡ç¨‹ï¼Œå¯ä»¥ä»å¤æ‚åˆ†å¸ƒä¸­ç”Ÿæˆé«˜è´¨é‡çš„æ ·æœ¬ã€‚
(3)ï¼šæœ¬æ–‡å¯¹åŸºäºæ‰©æ•£æ¨¡å‹çš„å›¾åƒç¼–è¾‘æ–¹æ³•è¿›è¡Œäº†å…¨é¢çš„ç»¼è¿°ï¼Œä»å­¦ä¹ ç­–ç•¥ã€ç”¨æˆ·è¾“å…¥æ¡ä»¶å’Œå…·ä½“ç¼–è¾‘ä»»åŠ¡ç­‰å¤šä¸ªè§’åº¦å¯¹ç°æœ‰å·¥ä½œè¿›è¡Œäº†æ·±å…¥åˆ†æå’Œåˆ†ç±»ã€‚
(4)ï¼šåŸºäºæ‰©æ•£æ¨¡å‹çš„å›¾åƒç¼–è¾‘æ–¹æ³•åœ¨å›¾åƒä¿®å¤ã€å›¾åƒå¤–å»¶ç­‰ä»»åŠ¡ä¸Šå–å¾—äº†å¾ˆå¥½çš„æ•ˆæœï¼Œæœ¬æ–‡è¿˜æå‡ºäº†ä¸€ä¸ªç³»ç»Ÿæ€§çš„åŸºå‡† EditEval å’Œä¸€ä¸ªåˆ›æ–°çš„æŒ‡æ ‡ LMMScore æ¥è¿›ä¸€æ­¥è¯„ä¼°æ–‡æœ¬å¼•å¯¼å›¾åƒç¼–è¾‘ç®—æ³•çš„æ€§èƒ½ã€‚</li>
</ol>
<p>7.Methods:
(1): åŸºäºCLIPæŒ‡å¯¼çš„å›¾åƒç¼–è¾‘ï¼šDiffusionCLIPã€Asyrpã€EffDiffã€DiffStylerã€StyleDiffusionã€UNIT-DDPMã€CycleNetã€DiffusionAutoencodersã€HDAEã€EGSDEã€Pixel-GuidedDiffusionï¼›
(2): åŸºäºå‚è€ƒå’Œå±æ€§æŒ‡å¯¼çš„å›¾åƒç¼–è¾‘ï¼šPbEã€RICã€ObjectStitchã€PhDã€DreamInpainterã€Anydoorã€FADINGã€PAIRDiffusionã€SmartBrushã€IIR-Netï¼›
(3): åŸºäºæŒ‡ä»¤æŒ‡å¯¼çš„å›¾åƒç¼–è¾‘ï¼šInstructPix2Pixã€MoEControllerã€FoIã€LOFIEã€InstructDiffusionã€EmuEditã€DialogPaintã€Inst-Inpaintã€HIVEã€ImageBrushã€InstructAny2Pixã€MGIEã€SmartEditã€‚</p>
<ol>
<li>ç»“è®ºï¼š
ï¼ˆ1ï¼‰æœ¬å·¥ä½œå¯¹åŸºäºæ‰©æ•£æ¨¡å‹çš„å›¾åƒç¼–è¾‘æ–¹æ³•è¿›è¡Œäº†å…¨é¢çš„ç»¼è¿°ï¼Œä»å¤šä¸ªè§’åº¦å¯¹ç°æœ‰å·¥ä½œè¿›è¡Œäº†æ·±å…¥åˆ†æå’Œåˆ†ç±»ï¼Œå¹¶æå‡ºäº†ä¸€ä¸ªç³»ç»Ÿæ€§çš„åŸºå‡† EditEval å’Œä¸€ä¸ªåˆ›æ–°çš„æŒ‡æ ‡ LMMScore æ¥è¿›ä¸€æ­¥è¯„ä¼°æ–‡æœ¬å¼•å¯¼å›¾åƒç¼–è¾‘ç®—æ³•çš„æ€§èƒ½ã€‚
ï¼ˆ2ï¼‰åˆ›æ–°ç‚¹ï¼š</li>
<li>æå‡ºäº†ä¸€ç§æ–°çš„å›¾åƒç¼–è¾‘åŸºå‡† EditEval å’Œä¸€ä¸ªåˆ›æ–°çš„æŒ‡æ ‡ LMMScoreï¼Œç”¨äºè¯„ä¼°æ–‡æœ¬å¼•å¯¼å›¾åƒç¼–è¾‘ç®—æ³•çš„æ€§èƒ½ã€‚</li>
<li>å¯¹åŸºäºæ‰©æ•£æ¨¡å‹çš„å›¾åƒç¼–è¾‘æ–¹æ³•è¿›è¡Œäº†å…¨é¢çš„ç»¼è¿°å’Œåˆ†ç±»ï¼Œä»å­¦ä¹ ç­–ç•¥ã€ç”¨æˆ·è¾“å…¥æ¡ä»¶å’Œå…·ä½“ç¼–è¾‘ä»»åŠ¡ç­‰å¤šä¸ªè§’åº¦å¯¹ç°æœ‰å·¥ä½œè¿›è¡Œäº†æ·±å…¥åˆ†æã€‚</li>
<li>æ¢ç´¢äº†è¿™äº›æ–¹æ³•åœ¨å¢å¼ºç¼–è¾‘æ€§èƒ½æ–¹é¢çš„è´¡çŒ®ã€‚</li>
<li>åœ¨æˆ‘ä»¬çš„å›¾åƒç¼–è¾‘åŸºå‡† EditEval ä¸­å¯¹ 7 é¡¹ä»»åŠ¡è¿›è¡Œäº†è¯„ä¼°ï¼Œä»¥åŠæœ€æ–°æœ€å…ˆè¿›çš„æ–¹æ³•ã€‚</li>
<li>æ€»ç»“äº†å›¾åƒç¼–è¾‘é¢†åŸŸçš„å¹¿æ³›æ½œåŠ›ï¼Œå¹¶æå‡ºäº†æœªæ¥ç ”ç©¶çš„æ–¹å‘ã€‚</li>
<li>æ€§èƒ½ï¼šåœ¨ EditEval åŸºå‡†ä¸Šï¼ŒåŸºäºæ‰©æ•£æ¨¡å‹çš„å›¾åƒç¼–è¾‘æ–¹æ³•åœ¨å›¾åƒä¿®å¤ã€å›¾åƒå¤–å»¶ç­‰ä»»åŠ¡ä¸Šå–å¾—äº†å¾ˆå¥½çš„æ•ˆæœã€‚</li>
<li>å·¥ä½œé‡ï¼šæœ¬æ–‡å¯¹è¶…è¿‡ 100 ç§åŸºäºæ‰©æ•£æ¨¡å‹çš„å›¾åƒç¼–è¾‘æ–¹æ³•è¿›è¡Œäº†ç»¼è¿°å’Œåˆ†ç±»ï¼Œå¹¶å¯¹ 7 é¡¹ä»»åŠ¡è¿›è¡Œäº†è¯„ä¼°ï¼Œå·¥ä½œé‡è¾ƒå¤§ã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-4c52565ddb49dad37f10475b00a6abbc.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-4537d5996d9b29f71e82d00a227227b7.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-db76ba27193f9ab6b62bab161a239510.jpg" align="middle">
</details>




<h2 id="Enhancing-Hyperspectral-Images-via-Diffusion-Model-and-Group-Autoencoder-Super-resolution-Network"><a href="#Enhancing-Hyperspectral-Images-via-Diffusion-Model-and-Group-Autoencoder-Super-resolution-Network" class="headerlink" title="Enhancing Hyperspectral Images via Diffusion Model and Group-Autoencoder   Super-resolution Network"></a>Enhancing Hyperspectral Images via Diffusion Model and Group-Autoencoder   Super-resolution Network</h2><p><strong>Authors:Zhaoyang Wang, Dongyang Li, Mingyang Zhang, Hao Luo, Maoguo Gong</strong></p>
<p>Existing hyperspectral image (HSI) super-resolution (SR) methods struggle to effectively capture the complex spectral-spatial relationships and low-level details, while diffusion models represent a promising generative model known for their exceptional performance in modeling complex relations and learning high and low-level visual features. The direct application of diffusion models to HSI SR is hampered by challenges such as difficulties in model convergence and protracted inference time. In this work, we introduce a novel Group-Autoencoder (GAE) framework that synergistically combines with the diffusion model to construct a highly effective HSI SR model (DMGASR). Our proposed GAE framework encodes high-dimensional HSI data into low-dimensional latent space where the diffusion model works, thereby alleviating the difficulty of training the diffusion model while maintaining band correlation and considerably reducing inference time. Experimental results on both natural and remote sensing hyperspectral datasets demonstrate that the proposed method is superior to other state-of-the-art methods both visually and metrically. </p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2402.17285v1">PDF</a> Accepted by AAAI2024</p>
<p><strong>Summary</strong><br>æ‰©æ•£æ¨¡å‹ä¸ç¾¤ç»„è‡ªç¼–ç å™¨ç›¸ç»“åˆçš„åˆ›æ–°æ¡†æ¶ï¼Œæœ‰æ•ˆæå‡é«˜å…‰è°±å›¾åƒè¶…åˆ†è¾¨ç‡ï¼Œæ˜¾è‘—æ”¹å–„è°±ç©ºå…³ç³»å»ºæ¨¡å’Œä½å±‚ç»†èŠ‚æ¢å¤ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>æ‰©æ•£æ¨¡å‹æ“…é•¿å»ºæ¨¡å¤æ‚å…³ç³»å’Œå­¦ä¹ è§†è§‰ç‰¹å¾ï¼Œåœ¨é«˜å…‰è°±å›¾åƒè¶…åˆ†è¾¨ç‡ä¸­æ½œåŠ›å·¨å¤§ã€‚</li>
<li>è®­ç»ƒæ‰©æ•£æ¨¡å‹é¢ä¸´æ”¶æ•›å›°éš¾å’Œæ¨ç†æ—¶é—´é•¿æŒ‘æˆ˜ã€‚</li>
<li>ç¾¤ç»„è‡ªç¼–ç å™¨æ¡†æ¶é€šè¿‡å°†é«˜ç»´é«˜å…‰è°±æ•°æ®ç¼–ç åˆ°ä½ç»´æ½œåœ¨ç©ºé—´ï¼Œç¼“è§£äº†æ‰©æ•£æ¨¡å‹è®­ç»ƒéš¾åº¦ï¼Œå¹¶ä¿æŒäº†æ³¢æ®µç›¸å…³æ€§ã€‚</li>
<li>æ‰©æ•£æ¨¡å‹ä¸ç¾¤ç»„è‡ªç¼–ç å™¨ç›¸ç»“åˆï¼Œæœ‰æ•ˆè§£å†³äº†æ¨ç†æ—¶é—´é—®é¢˜ã€‚</li>
<li>åœ¨è‡ªç„¶å’Œé¥æ„Ÿé«˜å…‰è°±æ•°æ®é›†ä¸Šï¼Œè¯¥æ–¹æ³•åœ¨è§†è§‰å’Œåº¦é‡ä¸Šå‡ä¼˜äºç°æœ‰æŠ€æœ¯ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>æ ‡é¢˜ï¼šåŸºäºæ‰©æ•£æ¨¡å‹å’Œç»„è‡ªç¼–ç å™¨çš„è¶…åˆ†è¾¨ç‡é«˜å…‰è°±å›¾åƒå¢å¼º</li>
<li>ä½œè€…ï¼šç‹å…†é˜³ï¼Œæä¸œé˜³ï¼Œå¼ æ˜é˜³ï¼Œç½—æµ©ï¼Œå·©èŒ‚å›½</li>
<li>éš¶å±å•ä½ï¼šè¥¿å®‰ç”µå­ç§‘æŠ€å¤§å­¦ååŒæ™ºèƒ½ç³»ç»Ÿæ•™è‚²éƒ¨é‡ç‚¹å®éªŒå®¤</li>
<li>å…³é”®è¯ï¼šé«˜å…‰è°±å›¾åƒï¼Œè¶…åˆ†è¾¨ç‡ï¼Œæ‰©æ•£æ¨¡å‹ï¼Œç»„è‡ªç¼–ç å™¨</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2402.17285</li>
<li>
<p>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šç°æœ‰é«˜å…‰è°±å›¾åƒè¶…åˆ†è¾¨ç‡æ–¹æ³•éš¾ä»¥æœ‰æ•ˆæ•æ‰å¤æ‚çš„å…‰è°±-ç©ºé—´å…³ç³»å’Œä½çº§ç»†èŠ‚ï¼Œè€Œæ‰©æ•£æ¨¡å‹æ˜¯ä¸€ç§æœ‰å‰é€”çš„ç”Ÿæˆæ¨¡å‹ï¼Œä»¥å…¶åœ¨å»ºæ¨¡å¤æ‚å…³ç³»å’Œå­¦ä¹ é«˜ä½çº§è§†è§‰ç‰¹å¾æ–¹é¢çš„å‡ºè‰²æ€§èƒ½è€Œé—»åã€‚
ï¼ˆ2ï¼‰è¿‡å»æ–¹æ³•åŠé—®é¢˜ï¼šå°†æ‰©æ•£æ¨¡å‹ç›´æ¥åº”ç”¨äºé«˜å…‰è°±å›¾åƒè¶…åˆ†è¾¨ç‡é¢ä¸´ç€æ¨¡å‹æ”¶æ•›å›°éš¾å’Œæ¨ç†æ—¶é—´é•¿çš„æŒ‘æˆ˜ã€‚
ï¼ˆ3ï¼‰ç ”ç©¶æ–¹æ³•ï¼šæå‡ºäº†ä¸€ç§æ–°çš„ç»„è‡ªç¼–ç å™¨ï¼ˆGAEï¼‰æ¡†æ¶ï¼Œè¯¥æ¡†æ¶ä¸æ‰©æ•£æ¨¡å‹ååŒç»“åˆï¼Œæ„å»ºäº†ä¸€ä¸ªé«˜æ•ˆçš„é«˜å…‰è°±å›¾åƒè¶…åˆ†è¾¨ç‡æ¨¡å‹ï¼ˆDMGASRï¼‰ã€‚æå‡ºçš„ GAE æ¡†æ¶å°†é«˜ç»´é«˜å…‰è°±æ•°æ®ç¼–ç ä¸ºä½ç»´æ½œåœ¨ç©ºé—´ï¼Œæ‰©æ•£æ¨¡å‹åœ¨æ­¤ç©ºé—´ä¸­å·¥ä½œï¼Œä»è€Œç¼“è§£äº†è®­ç»ƒæ‰©æ•£æ¨¡å‹çš„éš¾åº¦ï¼ŒåŒæ—¶ä¿æŒäº†æ³¢æ®µç›¸å…³æ€§å¹¶å¤§å¤§å‡å°‘äº†æ¨ç†æ—¶é—´ã€‚
ï¼ˆ4ï¼‰ä»»åŠ¡å’Œæ€§èƒ½ï¼šåœ¨è‡ªç„¶å’Œé¥æ„Ÿé«˜å…‰è°±æ•°æ®é›†ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼Œæ‰€æå‡ºçš„æ–¹æ³•åœ¨è§†è§‰å’Œåº¦é‡ä¸Šéƒ½ä¼˜äºå…¶ä»–æœ€å…ˆè¿›çš„æ–¹æ³•ã€‚</p>
</li>
<li>
<p>æ–¹æ³•ï¼š
(1): æå‡ºäº†ä¸€ç§åŸºäºæ‰©æ•£æ¨¡å‹å’Œç»„è‡ªç¼–ç å™¨çš„è¶…åˆ†è¾¨ç‡é«˜å…‰è°±å›¾åƒå¢å¼ºæ¨¡å‹ï¼ˆDMGASRï¼‰ï¼›
(2): è¯¥æ¨¡å‹é‡‡ç”¨ä¸¤é˜¶æ®µè®­ç»ƒæ–¹å¼ï¼ŒåŒ…æ‹¬è‡ªåŠ¨ç¼–ç å™¨å’Œæ‰©æ•£è¶…åˆ†è¾¨ç‡æ¨¡å‹ï¼›
(3): é‡‡ç”¨è°±åˆ†ç»„ç­–ç•¥å’Œéå¯¹ç§°è§£ç å™¨è®¾è®¡ï¼Œæœ‰æ•ˆåœ°å°†é«˜ç»´é«˜å…‰è°±æ•°æ®ç¼–ç ä¸ºä½ç»´æ½œåœ¨ç©ºé—´ï¼›
(4): è®­ç»ƒæ‰©æ•£æ¨¡å‹åœ¨æ½œåœ¨ç©ºé—´ä¸­å·¥ä½œï¼Œç¼“è§£äº†è®­ç»ƒæ‰©æ•£æ¨¡å‹çš„éš¾åº¦ï¼ŒåŒæ—¶ä¿æŒäº†æ³¢æ®µç›¸å…³æ€§å¹¶å¤§å¤§å‡å°‘äº†æ¨ç†æ—¶é—´ï¼›
(5): è®­ç»ƒè‡ªåŠ¨ç¼–ç å™¨é‡æ„è¾“å…¥æ•°æ®ï¼Œç”Ÿæˆä¸€ç³»åˆ—éšè—å˜é‡ï¼›
(6): å°†ä½åˆ†è¾¨ç‡éšè—å˜é‡ä½œä¸ºæ¡ä»¶ä¿¡æ¯ï¼Œä¸é«˜åˆ†è¾¨ç‡éšè—å˜é‡ä¸²è”ï¼Œåœ¨å»å™ªè¿‡ç¨‹ä¸­åŠ å…¥åˆ°æ‰©æ•£æ¨¡å‹ä¸­ï¼›
(7): é‡‡ç”¨ U-Net ä½œä¸ºå»å™ªæ¨¡å‹ï¼Œè¿­ä»£å»é™¤å™ªå£°ï¼Œç”Ÿæˆè¶…åˆ†è¾¨ç‡æ½œåœ¨å˜é‡åˆ—è¡¨ï¼›
(8): å°†è¶…åˆ†è¾¨ç‡æ½œåœ¨å˜é‡åˆ—è¡¨ä¼ é€’ç»™è§£ç å™¨ï¼Œç”Ÿæˆè¶…åˆ†è¾¨ç‡å›¾åƒã€‚</p>
</li>
<li>
<p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºæ‰©æ•£æ¨¡å‹å’Œç»„è‡ªç¼–ç å™¨çš„é«˜å…‰è°±å›¾åƒè¶…åˆ†è¾¨ç‡å¢å¼ºæ¨¡å‹ï¼ˆDMGASRï¼‰ï¼Œè¯¥æ¨¡å‹å°†æ‰©æ•£æ¨¡å‹ä¸è‡ªåŠ¨ç¼–ç å™¨ç›¸ç»“åˆï¼Œæœ‰æ•ˆè§£å†³äº†æ‰©æ•£æ¨¡å‹åœ¨é«˜ç»´æ•°æ®ä¸Šæ”¶æ•›å›°éš¾çš„é—®é¢˜ï¼Œå¹¶é€šè¿‡åœ¨ä½ç»´æ½œåœ¨ç©ºé—´ä¸­è®­ç»ƒæ‰©æ•£æ¨¡å‹ï¼Œå¤§å¤§å‡å°‘äº†æ¨ç†æ—¶é—´ã€‚è¯¥æ–¹æ³•åœ¨è‡ªç„¶å’Œé¥æ„Ÿé«˜å…‰è°±æ•°æ®é›†ä¸Šå‡å–å¾—äº†ä¼˜å¼‚çš„æ€§èƒ½ï¼Œåœ¨è§†è§‰å’Œåº¦é‡ä¸Šå‡ä¼˜äºå…¶ä»–æœ€å…ˆè¿›çš„æ–¹æ³•ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</p>
</li>
<li>æå‡ºäº†ä¸€ç§åŸºäºæ‰©æ•£æ¨¡å‹å’Œç»„è‡ªç¼–ç å™¨çš„è¶…åˆ†è¾¨ç‡é«˜å…‰è°±å›¾åƒå¢å¼ºæ¨¡å‹ï¼ˆDMGASRï¼‰ã€‚</li>
<li>é‡‡ç”¨ä¸¤é˜¶æ®µè®­ç»ƒæ–¹å¼ï¼ŒåŒ…æ‹¬è‡ªåŠ¨ç¼–ç å™¨å’Œæ‰©æ•£è¶…åˆ†è¾¨ç‡æ¨¡å‹ã€‚</li>
<li>é‡‡ç”¨è°±åˆ†ç»„ç­–ç•¥å’Œéå¯¹ç§°è§£ç å™¨è®¾è®¡ï¼Œæœ‰æ•ˆåœ°å°†é«˜ç»´é«˜å…‰è°±æ•°æ®ç¼–ç ä¸ºä½ç»´æ½œåœ¨ç©ºé—´ã€‚</li>
<li>è®­ç»ƒæ‰©æ•£æ¨¡å‹åœ¨æ½œåœ¨ç©ºé—´ä¸­å·¥ä½œï¼Œç¼“è§£äº†è®­ç»ƒæ‰©æ•£æ¨¡å‹çš„éš¾åº¦ï¼ŒåŒæ—¶ä¿æŒäº†æ³¢æ®µç›¸å…³æ€§å¹¶å¤§å¤§å‡å°‘äº†æ¨ç†æ—¶é—´ã€‚
æ€§èƒ½ï¼š</li>
<li>åœ¨è‡ªç„¶å’Œé¥æ„Ÿé«˜å…‰è°±æ•°æ®é›†ä¸Šå‡å–å¾—äº†ä¼˜å¼‚çš„æ€§èƒ½ã€‚</li>
<li>åœ¨è§†è§‰å’Œåº¦é‡ä¸Šå‡ä¼˜äºå…¶ä»–æœ€å…ˆè¿›çš„æ–¹æ³•ã€‚
å·¥ä½œé‡ï¼š</li>
<li>ç®—æ³•è®¾è®¡å’Œå®ç°ã€‚</li>
<li>æ•°æ®é›†çš„æ”¶é›†å’Œé¢„å¤„ç†ã€‚</li>
<li>å®éªŒçš„è¿›è¡Œå’Œç»“æœåˆ†æã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-1b637edd1829307f3889177173204f7c.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-cc3237f0ece24500c44086801ebc1feb.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a3e331ea518a2b9c151178e17f115708.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-7b211209593777f9420f6bb845daa71b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f24696c9c22f22b6e487ce2e6fc31ec7.jpg" align="middle">
</details>




<h2 id="One-Shot-Structure-Aware-Stylized-Image-Synthesis"><a href="#One-Shot-Structure-Aware-Stylized-Image-Synthesis" class="headerlink" title="One-Shot Structure-Aware Stylized Image Synthesis"></a>One-Shot Structure-Aware Stylized Image Synthesis</h2><p><strong>Authors:Hansam Cho, Jonghyun Lee, Seunggyu Chang, Yonghyun Jeong</strong></p>
<p>While GAN-based models have been successful in image stylization tasks, they often struggle with structure preservation while stylizing a wide range of input images. Recently, diffusion models have been adopted for image stylization but still lack the capability to maintain the original quality of input images. Building on this, we propose OSASIS: a novel one-shot stylization method that is robust in structure preservation. We show that OSASIS is able to effectively disentangle the semantics from the structure of an image, allowing it to control the level of content and style implemented to a given input. We apply OSASIS to various experimental settings, including stylization with out-of-domain reference images and stylization with text-driven manipulation. Results show that OSASIS outperforms other stylization methods, especially for input images that were rarely encountered during training, providing a promising solution to stylization via diffusion models. </p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2402.17275v1">PDF</a> CVPR 2024</p>
<p><strong>Summary</strong><br>åŸºäºæ‰©æ•£æ¨¡å‹çš„ OSASIS å®ç°äº†å›¾åƒé£æ ¼åŒ–ï¼ŒåŒæ—¶ä¿æŒäº†ç»“æ„å®Œæ•´æ€§ï¼Œå³ä½¿æ˜¯å¯¹è®­ç»ƒä¸­å¾ˆå°‘é‡åˆ°çš„è¾“å…¥å›¾åƒã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>OSASIS é‡‡ç”¨æ‰©æ•£æ¨¡å‹è¿›è¡Œå›¾åƒé£æ ¼åŒ–ï¼Œè§£å†³äº† GAN æ¨¡å‹åœ¨ä¿æŒç»“æ„æ–¹é¢çš„ä¸è¶³ã€‚</li>
<li>OSASIS èƒ½å¤Ÿæœ‰æ•ˆåˆ†ç¦»å›¾åƒè¯­ä¹‰å’Œç»“æ„ï¼Œå¯æ§åœ°è°ƒæ•´ç»™å®šè¾“å…¥çš„å†…å®¹å’Œé£æ ¼çº§åˆ«ã€‚</li>
<li>OSASIS åœ¨å„ç§å®éªŒè®¾ç½®ä¸­è¡¨ç°å‡ºè‰²ï¼ŒåŒ…æ‹¬ä½¿ç”¨åŸŸå¤–å‚è€ƒå›¾åƒè¿›è¡Œé£æ ¼åŒ–å’Œä½¿ç”¨æ–‡æœ¬é©±åŠ¨çš„æ“ä½œè¿›è¡Œé£æ ¼åŒ–ã€‚</li>
<li>ä¸å…¶ä»–é£æ ¼åŒ–æ–¹æ³•ç›¸æ¯”ï¼ŒOSASIS åœ¨è®­ç»ƒä¸­å¾ˆå°‘é‡åˆ°çš„è¾“å…¥å›¾åƒä¸Šè¡¨ç°å¾—å°¤ä¸ºå‡ºè‰²ï¼Œä¸ºé€šè¿‡æ‰©æ•£æ¨¡å‹è¿›è¡Œé£æ ¼åŒ–æä¾›äº†æœ‰å‰æ™¯çš„è§£å†³æ–¹æ¡ˆã€‚</li>
<li>OSASIS é‡‡ç”¨äº†æ¸è¿›å¼è®­ç»ƒç­–ç•¥ï¼Œé€šè¿‡ä»æ·»åŠ å™ªå£°åˆ°æ¢å¤å›¾åƒï¼Œé€æ­¥å°†é£æ ¼åº”ç”¨äºè¾“å…¥ã€‚</li>
<li>OSASIS ä½¿ç”¨é¢„è®­ç»ƒçš„æ‰©æ•£æ¨¡å‹ï¼Œæé«˜äº†æ•ˆç‡å’Œæ³›åŒ–æ€§ã€‚</li>
<li>OSASIS åœ¨å›¾åƒé£æ ¼åŒ–é¢†åŸŸå±•ç°å‡ºäº†å¹¿æ³›çš„åº”ç”¨å‰æ™¯ï¼ŒåŒ…æ‹¬å›¾åƒç¼–è¾‘ã€è‰ºæœ¯åˆ›ä½œå’Œè§†é¢‘å¤„ç†ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>æ ‡é¢˜ï¼šå•æ¬¡ç»“æ„æ„ŸçŸ¥é£æ ¼åŒ–å›¾åƒåˆæˆ</li>
<li>ä½œè€…ï¼šJongmin Lee*, Jaeyeon Kang, Sangwoo Mo, Seongwon Leeâ€ , Kyoung Mu Leeâ€ </li>
<li>éš¶å±å•ä½ï¼šNAVER Cloud</li>
<li>å…³é”®è¯ï¼šå›¾åƒé£æ ¼åŒ–ã€æ‰©æ•£æ¨¡å‹ã€ç»“æ„ä¿æŒ</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2302.05447, Github ä»£ç é“¾æ¥ï¼šæ— </li>
<li>æ‘˜è¦ï¼š
(1) ç ”ç©¶èƒŒæ™¯ï¼šGAN æ¨¡å‹åœ¨å›¾åƒé£æ ¼åŒ–ä»»åŠ¡ä¸­å–å¾—æˆåŠŸï¼Œä½†éš¾ä»¥åœ¨é£æ ¼åŒ–å„ç§è¾“å…¥å›¾åƒæ—¶ä¿æŒç»“æ„ã€‚æœ€è¿‘ï¼Œæ‰©æ•£æ¨¡å‹è¢«ç”¨äºå›¾åƒé£æ ¼åŒ–ï¼Œä½†ä»ç¼ºä¹ä¿æŒè¾“å…¥å›¾åƒåŸå§‹è´¨é‡çš„èƒ½åŠ›ã€‚
(2) è¿‡å»æ–¹æ³•åŠé—®é¢˜ï¼šè¿‡å»æ–¹æ³•åŒ…æ‹¬åŸºäº GAN çš„æ¨¡å‹å’ŒåŸºäºæ‰©æ•£æ¨¡å‹çš„æ–¹æ³•ã€‚GAN æ¨¡å‹éš¾ä»¥ä¿æŒç»“æ„ï¼Œè€ŒåŸºäºæ‰©æ•£æ¨¡å‹çš„æ–¹æ³•ç¼ºä¹æ§åˆ¶å†…å®¹å’Œé£æ ¼çš„èƒ½åŠ›ã€‚
(3) æœ¬æ–‡æå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„å•æ¬¡é£æ ¼åŒ–æ–¹æ³• OSASISï¼Œè¯¥æ–¹æ³•åœ¨ç»“æ„ä¿æŒæ–¹é¢å…·æœ‰é²æ£’æ€§ã€‚OSASIS é€šè¿‡å°†è¯­ä¹‰ä»å›¾åƒçš„ç»“æ„ä¸­è§£è€¦ï¼Œä»è€Œæœ‰æ•ˆåœ°æ§åˆ¶åº”ç”¨äºç»™å®šè¾“å…¥çš„å†…å®¹å’Œé£æ ¼çš„çº§åˆ«ã€‚
(4) ä»»åŠ¡å’Œæ€§èƒ½ï¼šOSASIS åœ¨å„ç§å®éªŒè®¾ç½®ä¸­å¾—åˆ°åº”ç”¨ï¼ŒåŒ…æ‹¬ä½¿ç”¨åŸŸå¤–å‚è€ƒå›¾åƒçš„é£æ ¼åŒ–å’Œä½¿ç”¨æ–‡æœ¬é©±åŠ¨çš„æ“ä½œçš„é£æ ¼åŒ–ã€‚ç»“æœè¡¨æ˜ï¼ŒOSASIS ä¼˜äºå…¶ä»–é£æ ¼åŒ–æ–¹æ³•ï¼Œç‰¹åˆ«æ˜¯å¯¹äºåœ¨è®­ç»ƒæœŸé—´å¾ˆå°‘é‡åˆ°çš„è¾“å…¥å›¾åƒï¼Œä¸ºé€šè¿‡æ‰©æ•£æ¨¡å‹è¿›è¡Œé£æ ¼åŒ–æä¾›äº†ä¸€ç§æœ‰å‰æ™¯çš„è§£å†³æ–¹æ¡ˆã€‚</li>
</ol>
<p><strong>Methodsï¼š</strong></p>
<ol>
<li><strong>å›¾åƒåˆ†è§£ï¼š</strong>å°†è¾“å…¥å›¾åƒåˆ†è§£ä¸ºå†…å®¹å’Œç»“æ„ç‰¹å¾ï¼Œå…¶ä¸­å†…å®¹ç‰¹å¾è¡¨ç¤ºå›¾åƒçš„è¯­ä¹‰ä¿¡æ¯ï¼Œè€Œç»“æ„ç‰¹å¾è¡¨ç¤ºå›¾åƒçš„å‡ ä½•å½¢çŠ¶å’Œçº¹ç†ã€‚</li>
<li><strong>é£æ ¼åµŒå…¥ï¼š</strong>å°†å‚è€ƒé£æ ¼å›¾åƒåµŒå…¥åˆ°ä¸€ä¸ªæ½œåœ¨ç©ºé—´ä¸­ï¼Œè¯¥ç©ºé—´ç”±æ‰©æ•£æ¨¡å‹è®­ç»ƒã€‚</li>
<li><strong>é£æ ¼ä¼ è¾“ï¼š</strong>å°†è¾“å…¥å›¾åƒçš„å†…å®¹ç‰¹å¾ä¸å‚è€ƒé£æ ¼çš„é£æ ¼åµŒå…¥ç›¸ç»“åˆï¼Œç”Ÿæˆä¸€ä¸ªæ–°çš„å›¾åƒï¼Œè¯¥å›¾åƒå…·æœ‰è¾“å…¥å›¾åƒçš„ç»“æ„å’Œå‚è€ƒé£æ ¼çš„é£æ ¼ã€‚</li>
<li>
<p><strong>ç»“æ„ä¿æŒï¼š</strong>é€šè¿‡ä½¿ç”¨ä¸€ä¸ªé¢å¤–çš„æŸå¤±å‡½æ•°ï¼Œå°†è¾“å…¥å›¾åƒçš„ç»“æ„ç‰¹å¾ä¸ç”Ÿæˆå›¾åƒçš„ç»“æ„ç‰¹å¾è¿›è¡ŒåŒ¹é…ï¼Œä»è€Œä¿æŒè¾“å…¥å›¾åƒçš„åŸå§‹è´¨é‡ã€‚</p>
</li>
<li>
<p>ç»“è®ºï¼š
(1): æœ¬å·¥ä½œæå‡ºäº†ä¸€ç§åŸºäºæ‰©æ•£æ¨¡å‹çš„æ–°å‹å•æ¬¡å›¾åƒé£æ ¼åŒ–æ–¹æ³• OSASISï¼Œè¯¥æ–¹æ³•åœ¨ç»“æ„ä¿æŒæ–¹é¢å…·æœ‰é²æ£’æ€§ã€‚ä¸åŸºäº GAN å’Œå…¶ä»–åŸºäºæ‰©æ•£çš„é£æ ¼åŒ–æ–¹æ³•ç›¸æ¯”ï¼ŒOSASIS å±•ç¤ºäº†åœ¨é£æ ¼åŒ–ä¸­å¯¹ç»“æ„çš„å¼ºå¤§æ„ŸçŸ¥ï¼Œæœ‰æ•ˆåœ°å°†å›¾åƒçš„ç»“æ„å’Œè¯­ä¹‰è§£è€¦ã€‚å°½ç®¡ OSASIS åœ¨ç»“æ„æ„ŸçŸ¥é£æ ¼åŒ–æ–¹é¢å–å¾—äº†é‡å¤§è¿›å±•ï¼Œä½†ä»å­˜åœ¨ä¸€äº›å±€é™æ€§ã€‚OSASIS çš„ä¸€ä¸ªæ˜¾ç€é™åˆ¶æ˜¯å…¶è®­ç»ƒæ—¶é—´ï¼Œæ¯”æ¯”è¾ƒæ–¹æ³•æ›´é•¿ã€‚è¿™ç§å»¶é•¿çš„è®­ç»ƒæŒç»­æ—¶é—´æ˜¯ä¸ºäº†æ¢å–è¯¥æ–¹æ³•å¢å¼ºäº†ä¿æŒç»“æ„å®Œæ•´æ€§å’Œé€‚åº”å„ç§é£æ ¼çš„èƒ½åŠ›ã€‚æ­¤å¤–ï¼ŒOSASIS éœ€è¦é’ˆå¯¹æ¯å¼ é£æ ¼å›¾åƒè¿›è¡Œè®­ç»ƒã€‚åœ¨éœ€è¦è·¨å¤šç§é£æ ¼å¿«é€Ÿéƒ¨ç½²çš„åœºæ™¯ä¸­ï¼Œè¿™ä¸€è¦æ±‚å¯ä»¥è¢«è§†ä¸ºä¸€ç§é™åˆ¶ã€‚å°½ç®¡å­˜åœ¨è¿™äº›æŒ‘æˆ˜ï¼Œä½† OSASIS åœ¨ä¿æŒè¾“å…¥å›¾åƒç»“æ„å®Œæ•´æ€§æ–¹é¢çš„ç¨³å¥æ€§ã€å…¶åœ¨åŸŸå¤–å‚è€ƒé£æ ¼åŒ–ä¸­çš„æœ‰æ•ˆæ€§ä»¥åŠå…¶åœ¨æ–‡æœ¬é©±åŠ¨æ“ä½œä¸­çš„é€‚åº”æ€§ä½¿å…¶æˆä¸ºé£æ ¼åŒ–å›¾åƒåˆæˆé¢†åŸŸä¸­ä¸€ç§å¾ˆæœ‰å‰æ™¯çš„æ–¹æ³•ã€‚æœªæ¥çš„å·¥ä½œå°†è§£å†³è¿™äº›é™åˆ¶ï¼Œç‰¹åˆ«æ˜¯åœ¨ä¼˜åŒ–è®­ç»ƒæ•ˆç‡å’Œå‡å°‘å¯¹å•ä¸ªé£æ ¼å›¾åƒè®­ç»ƒçš„å¿…è¦æ€§æ–¹é¢ï¼Œä»¥å¢å¼º OSASIS åœ¨å„ç§å®é™…åœºæ™¯ä¸­çš„å®ç”¨æ€§å’Œé€‚ç”¨æ€§ã€‚
(2): åˆ›æ–°ç‚¹ï¼š</p>
</li>
<li>æå‡ºäº†ä¸€ç§æ–°çš„å›¾åƒé£æ ¼åŒ–æ–¹æ³• OSASISï¼Œè¯¥æ–¹æ³•åŸºäºæ‰©æ•£æ¨¡å‹ï¼Œåœ¨ç»“æ„ä¿æŒæ–¹é¢å…·æœ‰é²æ£’æ€§ã€‚</li>
<li>OSASIS é€šè¿‡å°†å›¾åƒçš„ç»“æ„å’Œè¯­ä¹‰è§£è€¦ï¼Œæœ‰æ•ˆåœ°æ§åˆ¶åº”ç”¨äºç»™å®šè¾“å…¥çš„å†…å®¹å’Œé£æ ¼çš„çº§åˆ«ã€‚</li>
<li>OSASIS åœ¨å„ç§å®éªŒè®¾ç½®ä¸­å¾—åˆ°åº”ç”¨ï¼ŒåŒ…æ‹¬ä½¿ç”¨åŸŸå¤–å‚è€ƒå›¾åƒçš„é£æ ¼åŒ–å’Œä½¿ç”¨æ–‡æœ¬é©±åŠ¨çš„æ“ä½œçš„é£æ ¼åŒ–ã€‚
æ€§èƒ½ï¼š</li>
<li>OSASIS åœ¨ç»“æ„ä¿æŒæ–¹é¢ä¼˜äºå…¶ä»–é£æ ¼åŒ–æ–¹æ³•ï¼Œç‰¹åˆ«æ˜¯å¯¹äºåœ¨è®­ç»ƒæœŸé—´å¾ˆå°‘é‡åˆ°çš„è¾“å…¥å›¾åƒã€‚</li>
<li>OSASIS ä¸ºé€šè¿‡æ‰©æ•£æ¨¡å‹è¿›è¡Œé£æ ¼åŒ–æä¾›äº†ä¸€ç§æœ‰å‰æ™¯çš„è§£å†³æ–¹æ¡ˆã€‚
å·¥ä½œé‡ï¼š</li>
<li>OSASIS çš„è®­ç»ƒæ—¶é—´æ¯”æ¯”è¾ƒæ–¹æ³•æ›´é•¿ã€‚</li>
<li>OSASIS éœ€è¦é’ˆå¯¹æ¯å¼ é£æ ¼å›¾åƒè¿›è¡Œè®­ç»ƒã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-957518995345024bb9a18f0e683a4e55.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d0f3cefa16e52b2bb0bdbb679863e234.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-4e8afc30904c2bad1400fb9f044e33a9.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f0eead50e28d5ed02ff0105780a9e22e.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-b842ecc40528644a1d824a5a8948f487.jpg" align="middle">
</details>




<h2 id="Playground-v2-5-Three-Insights-towards-Enhancing-Aesthetic-Quality-in-Text-to-Image-Generation"><a href="#Playground-v2-5-Three-Insights-towards-Enhancing-Aesthetic-Quality-in-Text-to-Image-Generation" class="headerlink" title="Playground v2.5: Three Insights towards Enhancing Aesthetic Quality in   Text-to-Image Generation"></a>Playground v2.5: Three Insights towards Enhancing Aesthetic Quality in   Text-to-Image Generation</h2><p><strong>Authors:Daiqing Li, Aleks Kamko, Ehsan Akhgari, Ali Sabet, Linmiao Xu, Suhail Doshi</strong></p>
<p>In this work, we share three insights for achieving state-of-the-art aesthetic quality in text-to-image generative models. We focus on three critical aspects for model improvement: enhancing color and contrast, improving generation across multiple aspect ratios, and improving human-centric fine details. First, we delve into the significance of the noise schedule in training a diffusion model, demonstrating its profound impact on realism and visual fidelity. Second, we address the challenge of accommodating various aspect ratios in image generation, emphasizing the importance of preparing a balanced bucketed dataset. Lastly, we investigate the crucial role of aligning model outputs with human preferences, ensuring that generated images resonate with human perceptual expectations. Through extensive analysis and experiments, Playground v2.5 demonstrates state-of-the-art performance in terms of aesthetic quality under various conditions and aspect ratios, outperforming both widely-used open-source models like SDXL and Playground v2, and closed-source commercial systems such as DALLE 3 and Midjourney v5.2. Our model is open-source, and we hope the development of Playground v2.5 provides valuable guidelines for researchers aiming to elevate the aesthetic quality of diffusion-based image generation models. </p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2402.17245v1">PDF</a> Model weights:   <a target="_blank" rel="noopener" href="https://huggingface.co/playgroundai/playground-v2.5-1024px-aesthetic">https://huggingface.co/playgroundai/playground-v2.5-1024px-aesthetic</a></p>
<p><strong>Summary</strong><br>é€šè¿‡å¯¹å™ªå£°æ—¶é—´è¡¨ã€å®½é«˜æ¯”å‡†å¤‡å’Œé¢å‘äººç±»çš„å¾®è°ƒçš„ç ”ç©¶ï¼ŒPlayground v2.5  diffusion æ¨¡å‹å¯äº§ç”Ÿæä½³çš„ç¾å­¦è´¨é‡ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>å™ªéŸ³æ—¶é—´è¡¨å¯¹æ¨¡å‹çœŸå®æ€§å’Œè§†è§‰ä¿çœŸåº¦è‡³å…³é‡è¦ã€‚</li>
<li>å¹³è¡¡çš„åˆ†åŒºæ•°æ®é›†å¯æ”¹å–„ä¸åŒå®½é«˜æ¯”çš„å›¾åƒç”Ÿæˆã€‚</li>
<li>å°†æ¨¡å‹è¾“å‡ºä¸äººç±»åå¥½ç›¸ç»“åˆå¯æå‡å›¾åƒçš„å…±é¸£æ•ˆæœã€‚</li>
<li>Playground v2.5 åœ¨å„ç§æ¡ä»¶å’Œå®½é«˜æ¯”ä¸‹è¡¨ç°å‡ºæœ€å…ˆè¿›çš„å®¡ç¾è´¨é‡ã€‚</li>
<li>Playground v2.5 æ¨¡å‹å¼€æºï¼Œä¸ºæå‡åŸºäºæ‰©æ•£çš„å›¾åƒç”Ÿæˆæ¨¡å‹çš„å®¡ç¾è´¨é‡æä¾›äº†æœ‰ä»·å€¼çš„æŒ‡å¯¼ã€‚</li>
<li>Playground v2.5 ä¼˜äº SDXLã€Playground v2ã€DALLE 3 å’Œ Midjourney v5.2ã€‚</li>
<li>ç ”ç©¶æœ‰åŠ©äºæé«˜åŸºäºæ‰©æ•£çš„å›¾åƒç”Ÿæˆæ¨¡å‹çš„å®¡ç¾è´¨é‡ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>æ ‡é¢˜ï¼šPlayground v2.5ï¼šæå‡æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆå®¡ç¾è´¨é‡çš„ä¸‰ç‚¹è§è§£</li>
<li>ä½œè€…ï¼šDaiqing Liã€Aleks Kamkoã€Ehsan Akhgariã€Ali Sabetã€Linmiao Xuã€Suhail Doshi</li>
<li>ç¬¬ä¸€ä½œè€…å•ä½ï¼šPlayground Research</li>
<li>å…³é”®è¯ï¼šæ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆã€æ‰©æ•£æ¨¡å‹ã€å®¡ç¾è´¨é‡</li>
<li>è®ºæ–‡é“¾æ¥ï¼šarXiv:2402.17245v1[cs.CV]</li>
<li>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šæ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆæ¨¡å‹åœ¨ç”Ÿæˆå›¾åƒçš„å®¡ç¾è´¨é‡æ–¹é¢å–å¾—äº†æ˜¾è‘—è¿›å±•ï¼Œä½†ä»å­˜åœ¨ä¸€äº›æŒ‘æˆ˜ï¼Œå¦‚é¢œè‰²å’Œå¯¹æ¯”åº¦ä¸è¶³ã€ä¸åŒå®½é«˜æ¯”ç”Ÿæˆè´¨é‡ä¸ä½³ã€ç¼ºä¹å¯¹äººç±»åå¥½çš„å¯¹é½ã€‚
ï¼ˆ2ï¼‰è¿‡å»æ–¹æ³•ï¼šä»¥å¾€æ–¹æ³•ä¸»è¦é›†ä¸­åœ¨æ”¹è¿›æ‰©æ•£æ¨¡å‹çš„è®­ç»ƒè¿‡ç¨‹ï¼Œå¦‚ä¼˜åŒ–å™ªå£°è°ƒåº¦æˆ–ä½¿ç”¨æ›´å¤§çš„æ•°æ®é›†ã€‚ç„¶è€Œï¼Œè¿™äº›æ–¹æ³•åœ¨æå‡å®¡ç¾è´¨é‡æ–¹é¢æ•ˆæœæœ‰é™ã€‚
ï¼ˆ3ï¼‰ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº†ä¸‰ç‚¹è§è§£æ¥æå‡å®¡ç¾è´¨é‡ï¼šæ”¹è¿›å™ªå£°è°ƒåº¦ä»¥å¢å¼ºé¢œè‰²å’Œå¯¹æ¯”åº¦ï¼Œæ„å»ºå¹³è¡¡çš„åˆ†æ¡¶æ•°æ®é›†ä»¥æ”¯æŒä¸åŒå®½é«˜æ¯”çš„ç”Ÿæˆï¼Œä»¥åŠåˆ©ç”¨äººç±»åé¦ˆæ¥å¯¹é½æ¨¡å‹è¾“å‡ºä¸äººç±»åå¥½ã€‚
ï¼ˆ4ï¼‰æ–¹æ³•æ€§èƒ½ï¼šåœ¨å¹¿æ³›çš„åˆ†æå’Œå®éªŒä¸­ï¼ŒPlayground v2.5 åœ¨å„ç§æ¡ä»¶å’Œå®½é«˜æ¯”ä¸‹å±•ç¤ºäº†æœ€å…ˆè¿›çš„å®¡ç¾è´¨é‡ï¼Œä¼˜äº SDXLã€Playground v2 ç­‰å¼€æºæ¨¡å‹å’Œ DALLÂ·E 3ã€Midjourney v5.2 ç­‰é—­æºå•†ä¸šç³»ç»Ÿã€‚</li>
</ol>
<p>æ–¹æ³•ï¼š
ï¼ˆ1ï¼‰æ”¹è¿›å™ªå£°è°ƒåº¦ï¼šé‡‡ç”¨ EDM æ¡†æ¶å’Œæ›´å™ªå£°çš„è°ƒåº¦æ–¹å¼ï¼Œå¢å¼ºå›¾åƒè‰²å½©å’Œå¯¹æ¯”åº¦ã€‚
ï¼ˆ2ï¼‰å¹³è¡¡åˆ†æ¡¶æ•°æ®é›†ï¼šæ„å»ºåŒ…å«ä¸åŒå®½é«˜æ¯”å›¾åƒçš„åˆ†æ¡¶æ•°æ®é›†ï¼Œæ”¯æŒå¤šç§å®½é«˜æ¯”çš„ç”Ÿæˆã€‚
ï¼ˆ3ï¼‰åˆ©ç”¨äººç±»åé¦ˆï¼šä½¿ç”¨äººç±»è¯„çº§ç³»ç»Ÿè‡ªåŠ¨ç­›é€‰é«˜è´¨é‡æ•°æ®é›†ï¼Œå¹¶é‡‡ç”¨è¿­ä»£è®­ç»ƒæ–¹æ³•ï¼Œæ ¹æ®äººç±»åå¥½å¯¹é½æ¨¡å‹è¾“å‡ºã€‚</p>
<ol>
<li>æ€»ç»“ï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡º Playground v2.5ï¼Œè¯¥æ¨¡å‹é€šè¿‡æ”¹è¿›å™ªå£°è°ƒåº¦ã€æ„å»ºå¹³è¡¡çš„åˆ†æ¡¶æ•°æ®é›†å’Œåˆ©ç”¨äººç±»åé¦ˆç­‰ä¸‰ç‚¹è§è§£ï¼Œæå‡äº†æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆæ¨¡å‹çš„å®¡ç¾è´¨é‡ã€‚
ï¼ˆ2ï¼‰ï¼š
åˆ›æ–°ç‚¹ï¼š</li>
<li>æå‡ºäº†ä¸€ç§æ–°çš„å™ªå£°è°ƒåº¦æ¡†æ¶ï¼Œå¢å¼ºäº†å›¾åƒçš„è‰²å½©å’Œå¯¹æ¯”åº¦ã€‚</li>
<li>æ„å»ºäº†ä¸€ä¸ªåŒ…å«ä¸åŒå®½é«˜æ¯”å›¾åƒçš„åˆ†æ¡¶æ•°æ®é›†ï¼Œæ”¯æŒå¤šç§å®½é«˜æ¯”çš„ç”Ÿæˆã€‚</li>
<li>åˆ©ç”¨äººç±»è¯„çº§ç³»ç»Ÿè‡ªåŠ¨ç­›é€‰é«˜è´¨é‡æ•°æ®é›†ï¼Œå¹¶é‡‡ç”¨è¿­ä»£è®­ç»ƒæ–¹æ³•ï¼Œæ ¹æ®äººç±»åå¥½å¯¹é½æ¨¡å‹è¾“å‡ºã€‚
æ€§èƒ½ï¼š</li>
<li>åœ¨å¹¿æ³›çš„åˆ†æå’Œå®éªŒä¸­ï¼ŒPlayground v2.5 åœ¨å„ç§æ¡ä»¶å’Œå®½é«˜æ¯”ä¸‹å±•ç¤ºäº†æœ€å…ˆè¿›çš„å®¡ç¾è´¨é‡ï¼Œä¼˜äºå…¶ä»–å¼€æºå’Œé—­æºæ¨¡å‹ã€‚</li>
<li>Playground v2.5 åœ¨å¢å¼ºå›¾åƒè‰²å½©å’Œå¯¹æ¯”åº¦ã€ç”Ÿæˆä¸åŒå®½é«˜æ¯”çš„é«˜è´¨é‡å›¾åƒä»¥åŠå¯¹é½æ¨¡å‹è¾“å‡ºä¸äººç±»åå¥½æ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œå°¤å…¶æ˜¯åœ¨ç”Ÿæˆäººç‰©å›¾åƒçš„ç²¾ç»†ç»†èŠ‚æ–¹é¢ã€‚
å·¥ä½œé‡ï¼š</li>
<li>è¯¥æ¨¡å‹å·²å¼€æºï¼Œç”¨æˆ·å¯ä»¥åœ¨ Playground äº§å“ç½‘ç«™ä¸Šä½¿ç”¨ã€‚</li>
<li>Playground v2.5 çš„æƒé‡å·²åœ¨ Hugging Face ä¸Šå¼€æºã€‚</li>
<li>Playground å°†ç»§ç»­æä¾›æ‰©å±•ï¼Œä»¥ä¾¿åœ¨ A1111 å’Œ ComfyUI ç­‰æµè¡Œç¤¾åŒºå·¥å…·ä¸­ä½¿ç”¨ Playground v2.5ã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-b9ee43af14ab727bc293d7a249e6d156.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-3ff95dbf16b9c2e734124d2c99954b6c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b62a3df3bac0ff8ef7d20dfeccb0f6b4.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-869a1d35fa675595c5662a91b215c366.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-226f377d76bcd81c0c005d4e513c6f81.jpg" align="middle">
</details>




<h2 id="SAM-DiffSR-Structure-Modulated-Diffusion-Model-for-Image-Super-Resolution"><a href="#SAM-DiffSR-Structure-Modulated-Diffusion-Model-for-Image-Super-Resolution" class="headerlink" title="SAM-DiffSR: Structure-Modulated Diffusion Model for Image   Super-Resolution"></a>SAM-DiffSR: Structure-Modulated Diffusion Model for Image   Super-Resolution</h2><p><strong>Authors:Chengcheng Wang, Zhiwei Hao, Yehui Tang, Jianyuan Guo, Yujie Yang, Kai Han, Yunhe Wang</strong></p>
<p>Diffusion-based super-resolution (SR) models have recently garnered significant attention due to their potent restoration capabilities. But conventional diffusion models perform noise sampling from a single distribution, constraining their ability to handle real-world scenes and complex textures across semantic regions. With the success of segment anything model (SAM), generating sufficiently fine-grained region masks can enhance the detail recovery of diffusion-based SR model. However, directly integrating SAM into SR models will result in much higher computational cost. In this paper, we propose the SAM-DiffSR model, which can utilize the fine-grained structure information from SAM in the process of sampling noise to improve the image quality without additional computational cost during inference. In the process of training, we encode structural position information into the segmentation mask from SAM. Then the encoded mask is integrated into the forward diffusion process by modulating it to the sampled noise. This adjustment allows us to independently adapt the noise mean within each corresponding segmentation area. The diffusion model is trained to estimate this modulated noise. Crucially, our proposed framework does NOT change the reverse diffusion process and does NOT require SAM at inference. Experimental results demonstrate the effectiveness of our proposed method, showcasing superior performance in suppressing artifacts, and surpassing existing diffusion-based methods by 0.74 dB at the maximum in terms of PSNR on DIV2K dataset. The code and dataset are available at <a target="_blank" rel="noopener" href="https://github.com/lose4578/SAM-DiffSR">https://github.com/lose4578/SAM-DiffSR</a>. </p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2402.17133v1">PDF</a> </p>
<p><strong>Summary</strong><br>åŸºäºæ‰©æ•£çš„è¶…åˆ†è¾¨ç‡æ¨¡å‹ä¸­ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„SAM-DiffSRæ–¹æ³•ï¼Œè¯¥æ–¹æ³•åˆ©ç”¨SAMçš„ç²¾ç»†ç»“æ„ä¿¡æ¯åœ¨é‡‡æ ·å™ªå£°çš„è¿‡ç¨‹ä¸­æ¥æ”¹å–„æœ€ç»ˆå›¾åƒè´¨é‡ï¼Œè€Œæ¨ç†è¿‡ç¨‹ä¸­ä¸éœ€è¦SAMï¼Œæœ‰æ•ˆé™ä½äº†è®¡ç®—æˆæœ¬ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>æå‡ºäº†ä¸€ç§SAM-DiffSRæ¨¡å‹ï¼Œå¯ä»¥åˆ©ç”¨SAMçš„ç²¾ç»†ç»“æ„ä¿¡æ¯æ¥æ”¹å–„å›¾åƒè´¨é‡ã€‚</li>
<li>SAM-DiffSRæ¨¡å‹é€šè¿‡å°†ç¼–ç çš„æ©ç æ•´åˆåˆ°å‰å‘æ‰©æ•£è¿‡ç¨‹ä¸­ï¼Œåœ¨é‡‡æ ·å™ªå£°ä¹‹å‰è¿›è¡Œè°ƒæ•´ã€‚</li>
<li>è¯¥è°ƒæ•´å…è®¸ç‹¬ç«‹è°ƒæ•´æ¯ä¸ªå¯¹åº”åˆ†å‰²åŒºåŸŸå†…çš„å™ªå£°å‡å€¼ã€‚</li>
<li>æ‰©æ•£æ¨¡å‹è¢«è®­ç»ƒæ¥ä¼°è®¡è¿™ç§è°ƒåˆ¶çš„å™ªå£°ã€‚</li>
<li>æ‰€æå‡ºçš„æ–¹æ³•ä¸æ”¹å˜åå‘æ‰©æ•£è¿‡ç¨‹ï¼Œå¹¶ä¸”åœ¨æ¨ç†è¿‡ç¨‹ä¸­ä¸éœ€è¦SAMã€‚</li>
<li>å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•æœ‰æ•ˆåœ°æŠ‘åˆ¶äº†ä¼ªå½±ï¼Œåœ¨DIV2Kæ•°æ®é›†ä¸Šä»¥PSNRæŒ‡æ ‡è¶…è¶Šäº†ç°æœ‰çš„åŸºäºæ‰©æ•£çš„æ–¹æ³•0.74 dBã€‚</li>
<li>ä»£ç å’Œæ•°æ®é›†å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/lose4578/SAM-DiffSR%E8%8E%B7%E5%BE%97%E3%80%82">https://github.com/lose4578/SAM-DiffSRè·å¾—ã€‚</a></li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>æ ‡é¢˜ï¼šSAM-DiffSRï¼šç”¨äºå›¾åƒè¶…åˆ†è¾¨ç‡çš„ç»“æ„è°ƒåˆ¶æ‰©æ•£æ¨¡å‹</li>
<li>ä½œè€…ï¼šChengcheng Wangã€Zhiwei Haoã€Yehui Tangã€Jianyuan Guoã€Yujie Yangã€Kai Hanã€Yunhe Wang</li>
<li>å•ä½ï¼šåä¸ºè¯ºäºšæ–¹èˆŸå®éªŒå®¤</li>
<li>å…³é”®è¯ï¼šå›¾åƒè¶…åˆ†è¾¨ç‡ã€æ‰©æ•£æ¨¡å‹ã€ç»“æ„è°ƒåˆ¶</li>
<li>é“¾æ¥ï¼šhttps://arxiv.org/abs/2402.17133
   Githubï¼šhttps://github.com/lose4578/SAM-DiffSR</li>
<li>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼š
   æ‰©æ•£æ¨¡å‹åœ¨å›¾åƒè¶…åˆ†è¾¨ç‡é¢†åŸŸå–å¾—äº†æ˜¾è‘—è¿›å±•ï¼Œä½†ä¼ ç»Ÿæ‰©æ•£æ¨¡å‹ä»å•ä¸€åˆ†å¸ƒä¸­è¿›è¡Œå™ªå£°é‡‡æ ·ï¼Œé™åˆ¶äº†å…¶å¤„ç†çœŸå®åœºæ™¯å’Œè·¨è¯­ä¹‰åŒºåŸŸå¤æ‚çº¹ç†çš„èƒ½åŠ›ã€‚</li>
</ol>
<p>ï¼ˆ2ï¼‰è¿‡å»æ–¹æ³•åŠé—®é¢˜ï¼š
   Segment Anything Modelï¼ˆSAMï¼‰èƒ½ç”Ÿæˆè¶³å¤Ÿç²¾ç»†çš„åŒºåŸŸæ©ç ï¼Œå¢å¼ºæ‰©æ•£æ¨¡å‹çš„ç»†èŠ‚æ¢å¤èƒ½åŠ›ã€‚ä½†ç›´æ¥å°† SAM é›†æˆåˆ° SR æ¨¡å‹ä¸­ä¼šå¤§å¹…å¢åŠ è®¡ç®—æˆæœ¬ã€‚</p>
<p>ï¼ˆ3ï¼‰ç ”ç©¶æ–¹æ³•ï¼š
   æå‡º SAM-DiffSR æ¨¡å‹ï¼Œåœ¨å™ªå£°é‡‡æ ·è¿‡ç¨‹ä¸­åˆ©ç”¨ SAM çš„ç²¾ç»†ç»“æ„ä¿¡æ¯ï¼Œåœ¨ä¸å¢åŠ æ¨ç†è®¡ç®—æˆæœ¬çš„æƒ…å†µä¸‹æé«˜å›¾åƒè´¨é‡ã€‚åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œå°†ç»“æ„ä½ç½®ä¿¡æ¯ç¼–ç åˆ° SAM çš„åˆ†å‰²æ©ç ä¸­ã€‚ç„¶åå°†ç¼–ç åçš„æ©ç é›†æˆåˆ°å‰å‘æ‰©æ•£è¿‡ç¨‹ä¸­ï¼Œå°†å…¶è°ƒåˆ¶åˆ°é‡‡æ ·çš„å™ªå£°ä¸­ã€‚è¿™ç§è°ƒæ•´å…è®¸åœ¨æ¯ä¸ªå¯¹åº”çš„åˆ†å‰²åŒºåŸŸå†…ç‹¬ç«‹è°ƒæ•´å™ªå£°å‡å€¼ã€‚æ‰©æ•£æ¨¡å‹è¢«è®­ç»ƒæ¥ä¼°è®¡è¿™ç§è°ƒåˆ¶çš„å™ªå£°ã€‚</p>
<p>ï¼ˆ4ï¼‰æ–¹æ³•æ€§èƒ½ï¼š
   å®éªŒç»“æœè¡¨æ˜ï¼Œæ‰€æå‡ºçš„æ–¹æ³•æœ‰æ•ˆï¼Œåœ¨æŠ‘åˆ¶ä¼ªå½±æ–¹é¢è¡¨ç°å‡ºä¼˜å¼‚çš„æ€§èƒ½ï¼Œåœ¨ DIV2K æ•°æ®é›†ä¸Šä»¥ PSNR è¡¡é‡ï¼Œæ¯”ç°æœ‰çš„åŸºäºæ‰©æ•£çš„æ–¹æ³•æé«˜äº† 0.74dBã€‚è¯¥æ–¹æ³•çš„æ€§èƒ½æ”¯æŒå…¶ç›®æ ‡ã€‚</p>
<p><strong>Methodsï¼š</strong></p>
<p>(1) åˆ©ç”¨ SegmentAnythingModelï¼ˆSAMï¼‰ç”Ÿæˆç²¾ç»†çš„åŒºåŸŸæ©ç ï¼Œç¼–ç ç»“æ„ä½ç½®ä¿¡æ¯ã€‚</p>
<p>(2) å°†ç¼–ç åçš„æ©ç é›†æˆåˆ°å‰å‘æ‰©æ•£è¿‡ç¨‹ä¸­ï¼Œè°ƒåˆ¶é‡‡æ ·çš„å™ªå£°ã€‚</p>
<p>(3) è®­ç»ƒæ‰©æ•£æ¨¡å‹ä¼°è®¡è°ƒåˆ¶çš„å™ªå£°ï¼Œä»è€Œåœ¨æ¯ä¸ªåˆ†å‰²åŒºåŸŸå†…ç‹¬ç«‹è°ƒæ•´å™ªå£°å‡å€¼ã€‚</p>
<ol>
<li>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡é‡ç‚¹é€šè¿‡é›†æˆ SAMï¼Œå¢å¼ºåŸºäºæ‰©æ•£çš„å›¾åƒè¶…åˆ†è¾¨ç‡æ¨¡å‹çš„ç»“æ„å±‚æ¬¡ä¿¡æ¯æ¢å¤èƒ½åŠ›ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ä¸ªåä¸º SAM-DiffSR çš„æ¡†æ¶ï¼Œå®ƒæ¶‰åŠå°†ç»“æ„ä½ç½®ä¿¡æ¯çº³å…¥ SAM ç”Ÿæˆçš„æ©ç ï¼Œç„¶ååœ¨æ­£å‘æ‰©æ•£è¿‡ç¨‹ä¸­å°†å…¶æ·»åŠ åˆ°é‡‡æ ·çš„å™ªå£°ä¸­ã€‚æ­¤æ“ä½œå•ç‹¬è°ƒèŠ‚æ¯ä¸ªç›¸åº”åˆ†å‰²åŒºåŸŸä¸­å™ªå£°çš„å‡å€¼ï¼Œä»è€Œå°†ç»“æ„å±‚æ¬¡çŸ¥è¯†æ³¨å…¥æ‰©æ•£æ¨¡å‹ã€‚é€šè¿‡é‡‡ç”¨è¿™ç§æ–¹æ³•ï¼Œè®­ç»ƒåçš„æ¨¡å‹åœ¨æ¢å¤ç»“æ„ç»†èŠ‚å’ŒæŠ‘åˆ¶å›¾åƒä¼ªå½±æ–¹é¢è¡¨ç°å‡ºæ”¹è¿›ï¼Œè€Œæ— éœ€äº§ç”Ÿä»»ä½•é¢å¤–çš„æ¨ç†æˆæœ¬ã€‚æˆ‘ä»¬çš„æ–¹æ³•çš„æœ‰æ•ˆæ€§é€šè¿‡åœ¨å¸¸ç”¨çš„å›¾åƒè¶…åˆ†è¾¨ç‡åŸºå‡†ä¸Šè¿›è¡Œçš„å¹¿æ³›å®éªŒå¾—åˆ°è¯å®ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼šåˆ©ç”¨ SAM æ³¨å…¥ç»“æ„ä¿¡æ¯ï¼Œå¢å¼ºæ‰©æ•£æ¨¡å‹çš„ç»“æ„æ¢å¤èƒ½åŠ›ï¼›
æ€§èƒ½ï¼šåœ¨æŠ‘åˆ¶ä¼ªå½±å’Œæ¢å¤ç»“æ„ç»†èŠ‚æ–¹é¢ä¼˜äºç°æœ‰æ–¹æ³•ï¼›
å·¥ä½œé‡ï¼šæ¨ç†æˆæœ¬ä¸åŸºçº¿æ¨¡å‹ç›¸å½“ã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-9a754ccd89139d7dc6a576434e6b119e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-0906797fab629c359270ce611fcb26d4.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-66893d51d835b7965b76fb168b66db51.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f1f36de01723e09ebef0661e0e152ae2.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-9bca3bdea09d0b0b3c4c6b041a3c1758.jpg" align="middle">
</details>




<h2 id="Cross-Modal-Contextualized-Diffusion-Models-for-Text-Guided-Visual-Generation-and-Editing"><a href="#Cross-Modal-Contextualized-Diffusion-Models-for-Text-Guided-Visual-Generation-and-Editing" class="headerlink" title="Cross-Modal Contextualized Diffusion Models for Text-Guided Visual   Generation and Editing"></a>Cross-Modal Contextualized Diffusion Models for Text-Guided Visual   Generation and Editing</h2><p><strong>Authors:Ling Yang, Zhilong Zhang, Zhaochen Yu, Jingwei Liu, Minkai Xu, Stefano Ermon, Bin Cui</strong></p>
<p>Conditional diffusion models have exhibited superior performance in high-fidelity text-guided visual generation and editing. Nevertheless, prevailing text-guided visual diffusion models primarily focus on incorporating text-visual relationships exclusively into the reverse process, often disregarding their relevance in the forward process. This inconsistency between forward and reverse processes may limit the precise conveyance of textual semantics in visual synthesis results. To address this issue, we propose a novel and general contextualized diffusion model (ContextDiff) by incorporating the cross-modal context encompassing interactions and alignments between text condition and visual sample into forward and reverse processes. We propagate this context to all timesteps in the two processes to adapt their trajectories, thereby facilitating cross-modal conditional modeling. We generalize our contextualized diffusion to both DDPMs and DDIMs with theoretical derivations, and demonstrate the effectiveness of our model in evaluations with two challenging tasks: text-to-image generation, and text-to-video editing. In each task, our ContextDiff achieves new state-of-the-art performance, significantly enhancing the semantic alignment between text condition and generated samples, as evidenced by quantitative and qualitative evaluations. Our code is available at <a target="_blank" rel="noopener" href="https://github.com/YangLing0818/ContextDiff">https://github.com/YangLing0818/ContextDiff</a> </p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2402.16627v1">PDF</a> ICLR 2024. Project: <a target="_blank" rel="noopener" href="https://github.com/YangLing0818/ContextDiff">https://github.com/YangLing0818/ContextDiff</a></p>
<p><strong>Summary</strong><br>ä¸Šä¸‹æ–‡æ‰©æ•£æ¨¡å‹é€šè¿‡åœ¨æ‰©æ•£æ­£åè¿‡ç¨‹ä¸­åŠ å…¥æ–‡æœ¬å¯è§†å…³ç³»ï¼Œæå‡äº†æ–‡æœ¬å¼•å¯¼å¯è§†åŒ–ç”Ÿæˆå’Œç¼–è¾‘çš„è¯­ä¹‰å¯¹é½ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>æ‰©æ•£æ¨¡å‹åœ¨æ–‡æœ¬å¼•å¯¼å¯è§†åŒ–ç”Ÿæˆå’Œç¼–è¾‘ä¸­è¡¨ç°ä¼˜è¶Šã€‚</li>
<li>ä¼ ç»Ÿæ¨¡å‹åªå°†æ–‡æœ¬å¯è§†å…³ç³»èå…¥åå‘è¿‡ç¨‹ï¼Œå¿½ç•¥äº†æ­£å‘è¿‡ç¨‹çš„å…³è”æ€§ã€‚</li>
<li>æ­£åè¿‡ç¨‹çš„ä¸ä¸€è‡´æ€§é™åˆ¶äº†æ–‡æœ¬è¯­ä¹‰åœ¨å¯è§†åŒ–åˆæˆç»“æœä¸­çš„ä¼ é€’ç²¾åº¦ã€‚</li>
<li>è¯­ä¹‰æ‰©æ•£æ¨¡å‹é€šè¿‡å°†æ–‡æœ¬æ¡ä»¶å’Œå¯è§†æ ·æœ¬ä¹‹é—´çš„äº¤äº’å’Œå¯¹é½çº³å…¥æ­£åè¿‡ç¨‹ï¼Œæ”¹å–„äº†è¿™ç§ä¸ä¸€è‡´æ€§ã€‚</li>
<li>æ”¹è¿›é€‚ç”¨äº DDPM å’Œ DDIMï¼Œå¹¶é€šè¿‡ç†è®ºæ¨ç†å¾—åˆ°è¯æ˜ã€‚</li>
<li>åœ¨æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆå’Œæ–‡æœ¬åˆ°è§†é¢‘ç¼–è¾‘ä»»åŠ¡ä¸­ï¼Œè¯­ä¹‰æ‰©æ•£æ¨¡å‹å‡è¾¾åˆ°æ–°çš„æœ€ä½³æ€§èƒ½ã€‚</li>
<li>å®šé‡å’Œå®šæ€§è¯„ä¼°è¡¨æ˜è¯­ä¹‰æ‰©æ•£æ¨¡å‹æ˜¾è‘—æå‡äº†æ–‡æœ¬æ¡ä»¶å’Œç”Ÿæˆæ ·æœ¬ä¹‹é—´çš„è¯­ä¹‰å¯¹é½ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>æ ‡é¢˜ï¼šè·¨æ¨¡æ€è¯­å¢ƒåŒ–æ‰©æ•£æ¨¡å‹ç”¨äºæ–‡æœ¬å¼•å¯¼çš„è§†è§‰ç”Ÿæˆå’Œç¼–è¾‘</li>
<li>ä½œè€…ï¼šæ¨å‡Œã€å¼ å¿—é¾™ã€äºå…†å®¸ã€åˆ˜æ™¯ä¼Ÿã€å¾æ˜å‡¯ã€Stefano Ermonã€å´”æ–Œ</li>
<li>éš¶å±ï¼šåŒ—äº¬å¤§å­¦</li>
<li>å…³é”®è¯ï¼šæ–‡æœ¬å¼•å¯¼è§†è§‰ç”Ÿæˆã€æ–‡æœ¬å¼•å¯¼è§†é¢‘ç¼–è¾‘ã€æ‰©æ•£æ¨¡å‹ã€è¯­å¢ƒåŒ–</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2402.16627
   Github ä»£ç é“¾æ¥ï¼šNone</li>
<li>
<p>æ‘˜è¦ï¼š
   (1)ï¼šç ”ç©¶èƒŒæ™¯ï¼šæ‰©æ•£æ¨¡å‹åœ¨æ–‡æœ¬å¼•å¯¼è§†è§‰ç”Ÿæˆå’Œç¼–è¾‘é¢†åŸŸè¡¨ç°ä¼˜å¼‚ï¼Œä½†ç°æœ‰æ–¹æ³•ä¸»è¦å…³æ³¨å°†æ–‡æœ¬-è§†è§‰å…³ç³»èå…¥é€†è¿‡ç¨‹ï¼Œå¿½è§†äº†å…¶åœ¨å‰å‘è¿‡ç¨‹ä¸­çš„ç›¸å…³æ€§ï¼Œå¯¼è‡´æ–‡æœ¬è¯­ä¹‰åœ¨è§†è§‰åˆæˆç»“æœä¸­çš„ç²¾ç¡®ä¼ è¾¾å—åˆ°é™åˆ¶ã€‚
   (2)ï¼šè¿‡å»æ–¹æ³•åŠé—®é¢˜ï¼šç°æœ‰æ–¹æ³•å­˜åœ¨ä»¥ä¸‹é—®é¢˜ï¼š</p>
<ul>
<li>å¿½ç•¥äº†æ–‡æœ¬-è§†è§‰å…³ç³»åœ¨å‰å‘è¿‡ç¨‹ä¸­çš„ä½œç”¨ï¼Œå¯¼è‡´æ–‡æœ¬è¯­ä¹‰åœ¨è§†è§‰åˆæˆç»“æœä¸­çš„ç²¾ç¡®ä¼ è¾¾å—é™ã€‚</li>
<li>ç¼ºä¹ä¸€ç§é€šç”¨çš„è¯­å¢ƒåŒ–æ‰©æ•£æ¨¡å‹ï¼Œæ— æ³•åŒæ—¶å¤„ç†æ–‡æœ¬å¼•å¯¼å›¾åƒå’Œè§†é¢‘ç”Ÿæˆ/ç¼–è¾‘ä»»åŠ¡ã€‚
   (3)ï¼šç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–ä¸”é€šç”¨çš„è¯­å¢ƒåŒ–æ‰©æ•£æ¨¡å‹ï¼ˆCONTEXTDIFFï¼‰ï¼Œé€šè¿‡å°†è·¨æ¨¡æ€è¯­å¢ƒï¼ˆåŒ…å«æ–‡æœ¬æ¡ä»¶å’Œè§†è§‰æ ·æœ¬ä¹‹é—´çš„äº¤äº’å’Œå¯¹é½ï¼‰èå…¥å‰å‘å’Œé€†è¿‡ç¨‹æ¥è§£å†³ä¸Šè¿°é—®é¢˜ã€‚å…·ä½“æ¥è¯´ï¼Œå°†è¯¥è¯­å¢ƒä¼ æ’­åˆ°ä¸¤ä¸ªè¿‡ç¨‹ä¸­çš„æ‰€æœ‰æ—¶é—´æ­¥ï¼Œä»¥é€‚åº”å®ƒä»¬çš„è½¨è¿¹ï¼Œä»è€Œä¿ƒè¿›è·¨æ¨¡æ€æ¡ä»¶å»ºæ¨¡ã€‚åŒæ—¶ï¼Œå°†è¯­å¢ƒåŒ–æ‰©æ•£æ¨¡å‹æ¨å¹¿åˆ° DDPM å’Œ DDIMï¼Œå¹¶é€šè¿‡ç†è®ºæ¨å¯¼è¯æ˜äº†å…¶æœ‰æ•ˆæ€§ã€‚
   (4)ï¼šä»»åŠ¡å’Œæ€§èƒ½ï¼šåœ¨æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆå’Œæ–‡æœ¬åˆ°è§†é¢‘ç¼–è¾‘ä¸¤ä¸ªå…·æœ‰æŒ‘æˆ˜æ€§çš„ä»»åŠ¡ä¸Šï¼ŒCONTEXTDIFF å‡å–å¾—äº†æ–°çš„ SOTA æ€§èƒ½ï¼Œæ˜¾è‘—å¢å¼ºäº†æ–‡æœ¬æ¡ä»¶ä¸ç”Ÿæˆæ ·æœ¬ä¹‹é—´çš„è¯­ä¹‰å¯¹é½ï¼Œå®šé‡å’Œå®šæ€§è¯„ä¼°å‡è¯æ˜äº†è¿™ä¸€ç‚¹ã€‚</li>
</ul>
</li>
<li>
<p>Methods:
(1): æå‡ºè·¨æ¨¡æ€è¯­å¢ƒåŒ–æ‰©æ•£æ¨¡å‹ï¼ˆCONTEXTDIFFï¼‰ï¼Œå°†è·¨æ¨¡æ€è¯­å¢ƒï¼ˆåŒ…å«æ–‡æœ¬æ¡ä»¶å’Œè§†è§‰æ ·æœ¬ä¹‹é—´çš„äº¤äº’å’Œå¯¹é½ï¼‰èå…¥å‰å‘å’Œé€†è¿‡ç¨‹ï¼Œä¿ƒè¿›è·¨æ¨¡æ€æ¡ä»¶å»ºæ¨¡ï¼›
(2): å°†è¯­å¢ƒåŒ–æ‰©æ•£æ¨¡å‹æ¨å¹¿åˆ°DDPMå’ŒDDIMï¼Œå¹¶é€šè¿‡ç†è®ºæ¨å¯¼è¯æ˜äº†å…¶æœ‰æ•ˆæ€§ï¼›
(3): åœ¨æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆå’Œæ–‡æœ¬åˆ°è§†é¢‘ç¼–è¾‘ä¸¤ä¸ªä»»åŠ¡ä¸Šï¼ŒCONTEXTDIFFå‡å–å¾—äº†æ–°çš„SOTAæ€§èƒ½ï¼Œæ˜¾è‘—å¢å¼ºäº†æ–‡æœ¬æ¡ä»¶ä¸ç”Ÿæˆæ ·æœ¬ä¹‹é—´çš„è¯­ä¹‰å¯¹é½ã€‚</p>
</li>
<li>
<p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰æœ¬å·¥ä½œæå‡ºäº†ä¸€ç§æ–°é¢–ä¸”é€šç”¨çš„æ¡ä»¶æ‰©æ•£æ¨¡å‹ï¼ˆCONTEXTDIFFï¼‰ï¼Œé€šè¿‡å°†è·¨æ¨¡æ€è¯­å¢ƒä¼ æ’­åˆ°æ‰©æ•£å’Œé€†è¿‡ç¨‹ä¸­çš„æ‰€æœ‰æ—¶é—´æ­¥ï¼Œå¹¶é€‚åº”å®ƒä»¬çš„è½¨è¿¹ï¼Œä»è€Œä¿ƒè¿›è·¨æ¨¡æ€æ¡ä»¶å»ºæ¨¡ã€‚æˆ‘ä»¬å°†ä¸Šä¸‹æ–‡åŒ–è½¨è¿¹é€‚é…å™¨æ¨å¹¿åˆ° DDPM å’Œ DDIMï¼Œå¹¶é€šè¿‡ç†è®ºæ¨å¯¼è¯æ˜äº†å…¶æœ‰æ•ˆæ€§ã€‚åœ¨æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆå’Œæ–‡æœ¬åˆ°è§†é¢‘ç¼–è¾‘è¿™ä¸¤ä¸ªå…·æœ‰æŒ‘æˆ˜æ€§çš„ä»»åŠ¡ä¸Šï¼ŒCONTEXTDIFF å§‹ç»ˆè¾¾åˆ°æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚ä¸¤é¡¹ä»»åŠ¡çš„å¹¿æ³›å®šé‡å’Œå®šæ€§ç»“æœè¯æ˜äº†æˆ‘ä»¬æå‡ºçš„è·¨æ¨¡æ€è¯­å¢ƒåŒ–æ‰©æ•£æ¨¡å‹çš„æœ‰æ•ˆæ€§å’Œä¼˜è¶Šæ€§ã€‚
ï¼ˆ2ï¼‰åˆ›æ–°ç‚¹ï¼šæå‡ºäº†ä¸€ç§æ–°é¢–çš„è·¨æ¨¡æ€è¯­å¢ƒåŒ–æ‰©æ•£æ¨¡å‹ï¼Œé€šè¿‡å°†è·¨æ¨¡æ€è¯­å¢ƒèå…¥æ‰©æ•£å’Œé€†è¿‡ç¨‹ï¼Œä¿ƒè¿›è·¨æ¨¡æ€æ¡ä»¶å»ºæ¨¡ã€‚
æ€§èƒ½ï¼šåœ¨æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆå’Œæ–‡æœ¬åˆ°è§†é¢‘ç¼–è¾‘ä¸¤ä¸ªä»»åŠ¡ä¸Šè¾¾åˆ°æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œæ˜¾è‘—å¢å¼ºäº†æ–‡æœ¬æ¡ä»¶ä¸ç”Ÿæˆæ ·æœ¬ä¹‹é—´çš„è¯­ä¹‰å¯¹é½ã€‚
å·¥ä½œé‡ï¼šå·¥ä½œé‡è¾ƒå¤§ï¼Œéœ€è¦å¯¹æ‰©æ•£æ¨¡å‹å’Œè·¨æ¨¡æ€è¯­å¢ƒåŒ–è¿›è¡Œæ·±å…¥ç†è§£ã€‚</p>
</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-0bc30cb1ebccfebfcc1ffd4ee246c26b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-64adb5f655a12b089618a5496f3cd332.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-f01bc8ec645d09757f45be018ce1fe96.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-8a622ae5ed900b07d2994967a2269c23.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-0d264d770c3a4265052827f62ee48f0b.jpg" align="middle">
</details>




<h2 id="Placing-Objects-in-Context-via-Inpainting-for-Out-of-distribution-Segmentation"><a href="#Placing-Objects-in-Context-via-Inpainting-for-Out-of-distribution-Segmentation" class="headerlink" title="Placing Objects in Context via Inpainting for Out-of-distribution   Segmentation"></a>Placing Objects in Context via Inpainting for Out-of-distribution   Segmentation</h2><p><strong>Authors:Pau de Jorge, Riccardo Volpi, Puneet K. Dokania, Philip H. S. Torr, Gregory Rogez</strong></p>
<p>When deploying a semantic segmentation model into the real world, it will inevitably be confronted with semantic classes unseen during training. Thus, to safely deploy such systems, it is crucial to accurately evaluate and improve their anomaly segmentation capabilities. However, acquiring and labelling semantic segmentation data is expensive and unanticipated conditions are long-tail and potentially hazardous. Indeed, existing anomaly segmentation datasets capture a limited number of anomalies, lack realism or have strong domain shifts. In this paper, we propose the Placing Objects in Context (POC) pipeline to realistically add any object into any image via diffusion models. POC can be used to easily extend any dataset with an arbitrary number of objects. In our experiments, we present different anomaly segmentation datasets based on POC-generated data and show that POC can improve the performance of recent state-of-the-art anomaly fine-tuning methods in several standardized benchmarks. POC is also effective to learn new classes. For example, we use it to edit Cityscapes samples by adding a subset of Pascal classes and show that models trained on such data achieve comparable performance to the Pascal-trained baseline. This corroborates the low sim-to-real gap of models trained on POC-generated images. </p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2402.16392v1">PDF</a> </p>
<p><strong>Summary</strong><br>ä½¿ç”¨æ‰©æ•£æ¨¡å‹å°†å¯¹è±¡æ’å…¥ä¸Šä¸‹æ–‡(POC)ç®¡é“ï¼Œå¯çœŸå®åœ°å‘å›¾åƒä¸­æ·»åŠ ä»»ä½•å¯¹è±¡ï¼Œæœ‰æ•ˆæ‰©å±•æ•°æ®é›†å’Œæ”¹å–„å¼‚å¸¸åˆ†å‰²æ€§èƒ½ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>åˆ©ç”¨æ‰©æ•£æ¨¡å‹æ„å»ºPOCç®¡é“ï¼Œå¯å‘å›¾åƒä¸­çœŸå®åœ°æ·»åŠ ä»»æ„å¯¹è±¡ã€‚</li>
<li>POCèƒ½è½»æ¾æ‰©å±•æ•°æ®é›†ï¼Œæ·»åŠ ä»»æ„æ•°é‡çš„å¯¹è±¡ã€‚</li>
<li>POCç”Ÿæˆçš„å¼‚å¸¸åˆ†å‰²æ•°æ®é›†æ¯”ç°æœ‰æ•°æ®é›†æ›´çœŸå®ã€å…¨é¢ã€‚</li>
<li>POCèƒ½æå‡æœ€æ–°å¼‚å¸¸ç²¾è°ƒæ–¹æ³•åœ¨åŸºå‡†æµ‹è¯•ä¸­çš„æ€§èƒ½ã€‚</li>
<li>POCå¯ç”¨äºå­¦ä¹ æ–°ç±»åˆ«ï¼Œå¦‚å°†Pascalç±»åˆ«æ·»åŠ åˆ°Cityscapesã€‚</li>
<li>åŸºäºPOCç”Ÿæˆå›¾åƒè®­ç»ƒçš„æ¨¡å‹ï¼Œå…¶ä»¿çœŸåˆ°çœŸå®å·®è·ä½ã€‚</li>
<li>POCç®¡é“èƒ½å¤Ÿæé«˜æ¨¡å‹åº”å¯¹æœªè§è¯­ä¹‰ç±»åˆ«çš„èƒ½åŠ›ï¼Œå¢å¼ºå¼‚å¸¸åˆ†å‰²æ€§èƒ½ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<p>1.æ ‡é¢˜ï¼šé€šè¿‡å›¾åƒä¿®å¤å°†å¯¹è±¡ç½®äºä¸Šä¸‹æ–‡ä¸­ä»¥è¿›è¡Œåˆ†å¸ƒå¤–åˆ†å‰²
2.ä½œè€…ï¼šPaude Jorgeâ€ , Riccardo Volpiâ€ , Puneet K. Dokaniaâ€¡, Philip H.S. Torrâ€¡, GrÃ©gory Rogezâ€ 
3.æ‰€å±æœºæ„ï¼šNAVERLABS æ¬§æ´²ï¼Œç‰›æ´¥å¤§å­¦
4.å…³é”®è¯ï¼šå¼‚å¸¸åˆ†å‰²ã€åˆ†å¸ƒå¤–æ£€æµ‹ã€å›¾åƒä¿®å¤ã€è¯­ä¹‰åˆ†å‰²ã€å¼€æ”¾è¯æ±‡åˆ†å‰²
5.é“¾æ¥ï¼šhttps://github.com/naver/poc
6.æ‘˜è¦ï¼š
(1)ï¼šç ”ç©¶èƒŒæ™¯ï¼šåœ¨ç°å®ä¸–ç•Œä¸­éƒ¨ç½²è¯­ä¹‰åˆ†å‰²æ¨¡å‹æ—¶ï¼Œæ¨¡å‹ä¸å¯é¿å…åœ°ä¼šé‡åˆ°è®­ç»ƒæœŸé—´æœªè§è¿‡çš„è¯­ä¹‰ç±»åˆ«ã€‚å› æ­¤ï¼Œä¸ºäº†å®‰å…¨åœ°éƒ¨ç½²æ­¤ç±»ç³»ç»Ÿï¼Œå‡†ç¡®è¯„ä¼°å’Œæé«˜å…¶å¼‚å¸¸åˆ†å‰²èƒ½åŠ›è‡³å…³é‡è¦ã€‚ç„¶è€Œï¼Œè·å–å’Œæ ‡è®°è¯­ä¹‰åˆ†å‰²æ•°æ®ä»£ä»·é«˜æ˜‚ï¼Œè€Œä¸”æ„å¤–æƒ…å†µæ˜¯é•¿å°¾ä¸”å¯èƒ½å…·æœ‰å±é™©æ€§ã€‚å®é™…ä¸Šï¼Œç°æœ‰çš„å¼‚å¸¸åˆ†å‰²æ•°æ®é›†æ•è·çš„å¼‚å¸¸æ•°é‡æœ‰é™ï¼Œç¼ºä¹çœŸå®æ€§æˆ–å…·æœ‰å¾ˆå¼ºçš„åŸŸåç§»ã€‚
(2)ï¼šè¿‡å»çš„æ–¹æ³•åŠå…¶é—®é¢˜ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§æ”¾ç½®å¯¹è±¡åœ¨ä¸Šä¸‹æ–‡ï¼ˆPOCï¼‰ç®¡é“ï¼Œé€šè¿‡æ‰©æ•£æ¨¡å‹å°†ä»»ä½•å¯¹è±¡ç°å®åœ°æ·»åŠ åˆ°ä»»ä½•å›¾åƒä¸­ã€‚POC å¯ç”¨äºè½»æ¾åœ°ä½¿ç”¨ä»»æ„æ•°é‡çš„å¯¹è±¡æ‰©å±•ä»»ä½•æ•°æ®é›†ã€‚åœ¨æˆ‘ä»¬çš„å®éªŒä¸­ï¼Œæˆ‘ä»¬å±•ç¤ºäº†åŸºäº POC ç”Ÿæˆçš„ä¸åŒå¼‚å¸¸åˆ†å‰²æ•°æ®é›†ï¼Œå¹¶è¡¨æ˜ POC å¯ä»¥æé«˜å‡ ç§æ ‡å‡†åŸºå‡†ä¸­æœ€è¿‘çš„å¼‚å¸¸ç²¾ç»†è°ƒæ•´æ–¹æ³•çš„æ€§èƒ½ã€‚POC è¿˜å¯ä»¥æœ‰æ•ˆåœ°å­¦ä¹ æ–°ç±»åˆ«ã€‚ä¾‹å¦‚ï¼Œæˆ‘ä»¬ä½¿ç”¨å®ƒé€šè¿‡æ·»åŠ  Pascal ç±»åˆ«çš„å­é›†æ¥ç¼–è¾‘ Cityscapes æ ·æœ¬ï¼Œå¹¶è¡¨æ˜åœ¨è¿™äº›æ•°æ®ä¸Šè®­ç»ƒçš„æ¨¡å‹ä¸ Pascal è®­ç»ƒçš„åŸºçº¿å®ç°äº†ç›¸å½“çš„æ€§èƒ½ã€‚è¿™è¯å®äº†åœ¨ POC ç”Ÿæˆçš„å›¾åƒä¸Šè®­ç»ƒçš„æ¨¡å‹çš„ä½æ¨¡æ‹Ÿåˆ°çœŸå®å·®è·ã€‚
(3)ï¼šæå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼šPOC ç®¡é“å»ºç«‹åœ¨å›¾åƒä¿®å¤å’Œå¼€æ”¾è¯æ±‡åˆ†å‰²æ¨¡å‹ä¹‹ä¸Šï¼Œå°†ä»»æ„å¯¹è±¡ç°å®åœ°æ’å…¥å›¾åƒä¸­ã€‚ä¿®æ”¹åçš„å›¾åƒå’Œæ©ç å¯ç”¨äºä¸åŒçš„ä»»åŠ¡ã€‚
(4)ï¼šæ–¹æ³•åœ¨ä»€ä¹ˆä»»åŠ¡ä¸Šå–å¾—äº†ä»€ä¹ˆæ€§èƒ½ï¼Œè¯¥æ€§èƒ½æ˜¯å¦èƒ½æ”¯æ’‘å…¶ç›®æ ‡ï¼šåœ¨æˆ‘ä»¬çš„å®éªŒä¸­ï¼Œæˆ‘ä»¬è¡¨æ˜åœ¨ POC ç”Ÿæˆçš„å›¾åƒä¸Šè¿›è¡Œå¾®è°ƒå¯ä»¥æ˜¾ç€æé«˜æœ€å…ˆè¿›çš„å¼‚å¸¸åˆ†å‰²æ–¹æ³•çš„æ€§èƒ½â€”â€”ä¼˜äºé€šè¿‡æ ‡å‡†åšæ³•ï¼ˆæ‹¼æ¥ COCO å¯¹è±¡ï¼‰è¿›è¡Œå¾®è°ƒçš„æ¨¡å‹ã€‚æˆ‘ä»¬è¿˜å±•ç¤ºäº†ä¸‰ä¸ªåŸºäº Cityscapes å’Œå…¶ä»–ä¸¤ä¸ªè‡ªåŠ¨é©¾é©¶æ•°æ®é›†çš„ POC ç”Ÿæˆçš„è¯„ä¼°é›†ï¼Œå¹¶åœ¨å…¶ä¸Šå¯¹ä¸åŒçš„å¼‚å¸¸åˆ†å‰²æ–¹æ³•è¿›è¡Œäº†åŸºå‡†æµ‹è¯•ï¼ˆæœ‰å…³ç»“æœçš„ç¬¬ä¸€çœ¼ï¼Œè¯·å‚è§å›¾ 1ï¼‰ã€‚æœ€åï¼Œç”±äº POC å¯ä»¥æ·»åŠ ä»»æ„å¯¹è±¡ï¼Œæˆ‘ä»¬å±•ç¤ºäº†å®ƒå¯ç”¨äºå­¦ä¹ æ–°ç±»åˆ«ã€‚ä¾‹å¦‚ï¼Œä½¿ç”¨åŠ¨ç‰©ç±»åˆ«å¢å¼º Cityscapes å›¾åƒå¯¼è‡´ Pascal æµ‹è¯•é›†ä¸Šçš„ 93.14mIoUï¼ˆè€ƒè™‘ç›¸åŒçš„ç±»åˆ«ï¼‰ï¼Œè€Œç›´æ¥åœ¨ Pascal ä¸Šè®­ç»ƒäº§ç”Ÿ 94.75â€”â€”ä¹Ÿå°±æ˜¯è¯´ï¼Œåœ¨ POC ç¼–è¾‘çš„å›¾åƒä¸Šè®­ç»ƒçš„æ¨¡å‹äº§ç”Ÿäº†ç›¸å½“å°çš„æ¨¡æ‹Ÿåˆ°çœŸå®å·®è·ã€‚</p>
<ol>
<li>æ–¹æ³•ï¼š
(1) POCç®¡é“ï¼šPOCç®¡é“ç”±å›¾åƒä¿®å¤æ¨¡å‹å’Œå¼€æ”¾è¯æ±‡åˆ†å‰²æ¨¡å‹ç»„æˆã€‚å›¾åƒä¿®å¤æ¨¡å‹ç”¨äºå°†å¯¹è±¡ç°å®åœ°æ’å…¥å›¾åƒä¸­ï¼Œè€Œå¼€æ”¾è¯æ±‡åˆ†å‰²æ¨¡å‹ç”¨äºä¸ºæ’å…¥çš„å¯¹è±¡ç”Ÿæˆæ©ç ã€‚ä¿®æ”¹åçš„å›¾åƒå’Œæ©ç å¯ç”¨äºä¸åŒçš„ä»»åŠ¡ï¼Œä¾‹å¦‚å¼‚å¸¸åˆ†å‰²ã€‚
(2) å¼‚å¸¸åˆ†å‰²å¾®è°ƒï¼šPOCç®¡é“å¯ç”¨äºç”Ÿæˆå¼‚å¸¸åˆ†å‰²æ•°æ®é›†ã€‚åœ¨è¿™äº›æ•°æ®é›†ä¸Šå¾®è°ƒå¼‚å¸¸åˆ†å‰²æ¨¡å‹å¯ä»¥æé«˜æ¨¡å‹çš„æ€§èƒ½ï¼Œä¼˜äºé€šè¿‡æ ‡å‡†åšæ³•ï¼ˆæ‹¼æ¥COCOå¯¹è±¡ï¼‰è¿›è¡Œå¾®è°ƒçš„æ¨¡å‹ã€‚
(3) å­¦ä¹ æ–°ç±»åˆ«ï¼šPOCç®¡é“è¿˜å¯ä»¥ç”¨äºå­¦ä¹ æ–°ç±»åˆ«ã€‚ä¾‹å¦‚ï¼Œä½¿ç”¨åŠ¨ç‰©ç±»åˆ«å¢å¼ºCityscapeså›¾åƒå¯¼è‡´Pascalæµ‹è¯•é›†ä¸Šçš„93.14mIoUï¼ˆè€ƒè™‘ç›¸åŒçš„ç±»åˆ«ï¼‰ï¼Œè€Œç›´æ¥åœ¨Pascalä¸Šè®­ç»ƒäº§ç”Ÿ94.75â€”â€”ä¹Ÿå°±æ˜¯è¯´ï¼Œåœ¨POCç¼–è¾‘çš„å›¾åƒä¸Šè®­ç»ƒçš„æ¨¡å‹äº§ç”Ÿäº†ç›¸å½“å°çš„æ¨¡æ‹Ÿåˆ°çœŸå®å·®è·ã€‚</li>
</ol>
<p>8.ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šxxxï¼›
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼šxxxï¼›æ€§èƒ½ï¼šxxxï¼›å·¥ä½œé‡ï¼šxxxï¼›
8. ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§æ”¾ç½®å¯¹è±¡åœ¨ä¸Šä¸‹æ–‡ï¼ˆPOCï¼‰ç®¡é“ï¼Œé€šè¿‡æ‰©æ•£æ¨¡å‹å°†ä»»æ„å¯¹è±¡ç°å®åœ°æ·»åŠ åˆ°ä»»ä½•å›¾åƒä¸­ã€‚POCå¯ç”¨äºè½»æ¾åœ°ä½¿ç”¨ä»»æ„æ•°é‡çš„å¯¹è±¡æ‰©å±•ä»»ä½•æ•°æ®é›†ã€‚åœ¨æˆ‘ä»¬çš„å®éªŒä¸­ï¼Œæˆ‘ä»¬å±•ç¤ºäº†åŸºäºPOCç”Ÿæˆçš„ä¸åŒå¼‚å¸¸åˆ†å‰²æ•°æ®é›†ï¼Œå¹¶è¡¨æ˜POCå¯ä»¥æé«˜å‡ ç§æ ‡å‡†åŸºå‡†ä¸­æœ€è¿‘çš„å¼‚å¸¸ç²¾ç»†è°ƒæ•´æ–¹æ³•çš„æ€§èƒ½ã€‚POCè¿˜å¯ä»¥æœ‰æ•ˆåœ°å­¦ä¹ æ–°ç±»åˆ«ã€‚ä¾‹å¦‚ï¼Œæˆ‘ä»¬ä½¿ç”¨å®ƒé€šè¿‡æ·»åŠ Pascalç±»åˆ«çš„å­é›†æ¥ç¼–è¾‘Cityscapesæ ·æœ¬ï¼Œå¹¶è¡¨æ˜åœ¨è¿™äº›æ•°æ®ä¸Šè®­ç»ƒçš„æ¨¡å‹ä¸Pascalè®­ç»ƒçš„åŸºçº¿å®ç°äº†ç›¸å½“çš„æ€§èƒ½ã€‚è¿™è¯å®äº†åœ¨POCç”Ÿæˆçš„å›¾åƒä¸Šè®­ç»ƒçš„æ¨¡å‹çš„ä½æ¨¡æ‹Ÿåˆ°çœŸå®å·®è·ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š
- æå‡ºäº†ä¸€ç§æ”¾ç½®å¯¹è±¡åœ¨ä¸Šä¸‹æ–‡ï¼ˆPOCï¼‰ç®¡é“ï¼Œé€šè¿‡æ‰©æ•£æ¨¡å‹å°†ä»»æ„å¯¹è±¡ç°å®åœ°æ·»åŠ åˆ°ä»»ä½•å›¾åƒä¸­ã€‚
- POCå¯ç”¨äºè½»æ¾åœ°ä½¿ç”¨ä»»æ„æ•°é‡çš„å¯¹è±¡æ‰©å±•ä»»ä½•æ•°æ®é›†ã€‚
- POCå¯ä»¥æé«˜å‡ ç§æ ‡å‡†åŸºå‡†ä¸­æœ€è¿‘çš„å¼‚å¸¸ç²¾ç»†è°ƒæ•´æ–¹æ³•çš„æ€§èƒ½ã€‚
- POCè¿˜å¯ä»¥æœ‰æ•ˆåœ°å­¦ä¹ æ–°ç±»åˆ«ã€‚
æ€§èƒ½ï¼š
- åœ¨æˆ‘ä»¬çš„å®éªŒä¸­ï¼Œæˆ‘ä»¬å±•ç¤ºäº†åŸºäºPOCç”Ÿæˆçš„ä¸åŒå¼‚å¸¸åˆ†å‰²æ•°æ®é›†ï¼Œå¹¶è¡¨æ˜POCå¯ä»¥æé«˜å‡ ç§æ ‡å‡†åŸºå‡†ä¸­æœ€è¿‘çš„å¼‚å¸¸ç²¾ç»†è°ƒæ•´æ–¹æ³•çš„æ€§èƒ½ã€‚
- POCè¿˜å¯ä»¥æœ‰æ•ˆåœ°å­¦ä¹ æ–°ç±»åˆ«ã€‚ä¾‹å¦‚ï¼Œæˆ‘ä»¬ä½¿ç”¨å®ƒé€šè¿‡æ·»åŠ Pascalç±»åˆ«çš„å­é›†æ¥ç¼–è¾‘Cityscapesæ ·æœ¬ï¼Œå¹¶è¡¨æ˜åœ¨è¿™äº›æ•°æ®ä¸Šè®­ç»ƒçš„æ¨¡å‹ä¸Pascalè®­ç»ƒçš„åŸºçº¿å®ç°äº†ç›¸å½“çš„æ€§èƒ½ã€‚è¿™è¯å®äº†åœ¨POCç”Ÿæˆçš„å›¾åƒä¸Šè®­ç»ƒçš„æ¨¡å‹çš„ä½æ¨¡æ‹Ÿåˆ°çœŸå®å·®è·ã€‚
å·¥ä½œé‡ï¼š
- POCç®¡é“ç”±å›¾åƒä¿®å¤æ¨¡å‹å’Œå¼€æ”¾è¯æ±‡åˆ†å‰²æ¨¡å‹ç»„æˆã€‚å›¾åƒä¿®å¤æ¨¡å‹ç”¨äºå°†å¯¹è±¡ç°å®åœ°æ’å…¥å›¾åƒä¸­ï¼Œè€Œå¼€æ”¾è¯æ±‡åˆ†å‰²æ¨¡å‹ç”¨äºä¸ºæ’å…¥çš„å¯¹è±¡ç”Ÿæˆæ©ç ã€‚
- POCç®¡é“å¯ç”¨äºç”Ÿæˆå¼‚å¸¸åˆ†å‰²æ•°æ®é›†ã€‚åœ¨è¿™äº›æ•°æ®é›†ä¸Šå¾®è°ƒå¼‚å¸¸åˆ†å‰²æ¨¡å‹å¯ä»¥æé«˜æ¨¡å‹çš„æ€§èƒ½ï¼Œä¼˜äºé€šè¿‡æ ‡å‡†åšæ³•ï¼ˆæ‹¼æ¥COCOå¯¹è±¡ï¼‰è¿›è¡Œå¾®è°ƒçš„æ¨¡å‹ã€‚
- POCç®¡é“è¿˜å¯ä»¥ç”¨äºå­¦ä¹ æ–°ç±»åˆ«ã€‚ä¾‹å¦‚ï¼Œä½¿ç”¨åŠ¨ç‰©ç±»åˆ«å¢å¼ºCityscapeså›¾åƒå¯¼è‡´Pascalæµ‹è¯•é›†ä¸Šçš„93.14mIoUï¼ˆè€ƒè™‘ç›¸åŒçš„ç±»åˆ«ï¼‰ï¼Œè€Œç›´æ¥åœ¨Pascalä¸Šè®­ç»ƒäº§ç”Ÿ94.75â€”â€”ä¹Ÿå°±æ˜¯è¯´ï¼Œåœ¨POCç¼–è¾‘çš„å›¾åƒä¸Šè®­ç»ƒçš„æ¨¡å‹äº§ç”Ÿäº†ç›¸å½“å°çš„æ¨¡æ‹Ÿåˆ°çœŸå®å·®è·ã€‚</p>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-13236ee2bf286b59f5da0689a0363f64.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-dec0e216eb8083342215a3e4e8c1dc95.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d2067d81b02e8cd7fea592f12fcef21d.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-37aa0eb4c5f86ae9ed22c98b2703f9a5.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-84f58d6d1052332176a17f015aaa2d9f.jpg" align="middle">
</details>





                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2024-02-29/Diffusion%20Models/">https://kedreamix.github.io/Talk2Paper/Paper/2024-02-29/Diffusion%20Models/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/Diffusion-Models/">
                                    <span class="chip bg-color">Diffusion Models</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2024-02-29/Talking%20Head%20Generation/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-262ccbd331f2623737aa6cbcc24c64e5.jpg" class="responsive-img" alt="Talking Head Generation">
                        
                        <span class="card-title">Talking Head Generation</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Talking Head Generation æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2024-02-29  G4GA Generic Framework for High Fidelity Talking Face Generation with   Fine-grained Intra-modal Alignment
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2024-02-29
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Talking-Head-Generation/" class="post-category">
                                    Talking Head Generation
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Talking-Head-Generation/">
                        <span class="chip bg-color">Talking Head Generation</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2024-02-23/NeRF/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-190136188bdfd4cb8f04bafbfb9ef577.jpg" class="responsive-img" alt="NeRF">
                        
                        <span class="card-title">NeRF</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            NeRF æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2024-02-23  Identifying Unnecessary 3D Gaussians using Clustering for Fast Rendering   of 3D Gaussian Splatting
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2024-02-23
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/NeRF/" class="post-category">
                                    NeRF
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/NeRF/">
                        <span class="chip bg-color">NeRF</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">4610.5k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
