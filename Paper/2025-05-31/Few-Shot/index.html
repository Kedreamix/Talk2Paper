<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Few-Shot">
    <meta name="description" content="Few-Shot æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-05-31  FMG-Det Foundation Model Guided Robust Object Detection">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>Few-Shot | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://picx.zhimg.com/v2-6c6fb40fb9641761d614d821c391e191.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Few-Shot</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/Few-Shot/">
                                <span class="chip bg-color">Few-Shot</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/Few-Shot/" class="post-category">
                                Few-Shot
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-05-31
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-06-02
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    7.8k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    31 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-05-31-æ›´æ–°"><a href="#2025-05-31-æ›´æ–°" class="headerlink" title="2025-05-31 æ›´æ–°"></a>2025-05-31 æ›´æ–°</h1><h2 id="FMG-Det-Foundation-Model-Guided-Robust-Object-Detection"><a href="#FMG-Det-Foundation-Model-Guided-Robust-Object-Detection" class="headerlink" title="FMG-Det: Foundation Model Guided Robust Object Detection"></a>FMG-Det: Foundation Model Guided Robust Object Detection</h2><p><strong>Authors:Darryl Hannan, Timothy Doster, Henry Kvinge, Adam Attarian, Yijing Watkins</strong></p>
<p>Collecting high quality data for object detection tasks is challenging due to the inherent subjectivity in labeling the boundaries of an object. This makes it difficult to not only collect consistent annotations across a dataset but also to validate them, as no two annotators are likely to label the same object using the exact same coordinates. These challenges are further compounded when object boundaries are partially visible or blurred, which can be the case in many domains. Training on noisy annotations significantly degrades detector performance, rendering them unusable, particularly in few-shot settings, where just a few corrupted annotations can impact model performance. In this work, we propose FMG-Det, a simple, efficient methodology for training models with noisy annotations. More specifically, we propose combining a multiple instance learning (MIL) framework with a pre-processing pipeline that leverages powerful foundation models to correct labels prior to training. This pre-processing pipeline, along with slight modifications to the detector head, results in state-of-the-art performance across a number of datasets, for both standard and few-shot scenarios, while being much simpler and more efficient than other approaches. </p>
<blockquote>
<p>æ”¶é›†é«˜è´¨é‡çš„å¯¹è±¡æ£€æµ‹ä»»åŠ¡æ•°æ®æ˜¯ä¸€ä¸ªæŒ‘æˆ˜ï¼Œå› ä¸ºæ ‡æ³¨å¯¹è±¡è¾¹ç•Œå­˜åœ¨å›ºæœ‰çš„ä¸»è§‚æ€§ã€‚è¿™å¯¼è‡´ä¸ä»…åœ¨æ•°æ®é›†ä¸Šæ”¶é›†ä¸€è‡´çš„æ³¨é‡Šå˜å¾—å›°éš¾ï¼Œè€Œä¸”éªŒè¯å®ƒä»¬ä¹Ÿå˜å¾—å›°éš¾ï¼Œå› ä¸ºä¸¤ä¸ªæ³¨é‡Šè€…ä¸å¤ªå¯èƒ½ä½¿ç”¨å®Œå…¨ç›¸åŒçš„åæ ‡æ¥æ ‡æ³¨åŒä¸€å¯¹è±¡ã€‚å½“å¯¹è±¡è¾¹ç•Œéƒ¨åˆ†å¯è§æˆ–æ¨¡ç³Šæ—¶ï¼Œè¿™äº›æŒ‘æˆ˜ä¼šè¿›ä¸€æ­¥åŠ å‰§ï¼Œè¿™åœ¨è®¸å¤šé¢†åŸŸéƒ½å¯èƒ½æ˜¯è¿™ç§æƒ…å†µã€‚åœ¨æœ‰å™ªå£°çš„æ³¨é‡Šä¸Šè¿›è¡Œè®­ç»ƒä¼šæ˜¾è‘—é™ä½æ£€æµ‹å™¨çš„æ€§èƒ½ï¼Œä½¿å…¶æ— æ³•ä½¿ç”¨ï¼Œç‰¹åˆ«æ˜¯åœ¨å°æ ·æœ¬è®¾ç½®ä¸­ï¼Œå‡ ä¸ªæŸåçš„æ³¨é‡Šå°±ä¼šå½±å“æ¨¡å‹æ€§èƒ½ã€‚åœ¨æœ¬å·¥ä½œä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†FMG-Detï¼Œè¿™æ˜¯ä¸€ç§ç”¨äºåœ¨æœ‰å™ªå£°çš„æ³¨é‡Šä¸Šè®­ç»ƒæ¨¡å‹ç®€å•é«˜æ•ˆçš„æ–¹æ³•ã€‚æ›´å…·ä½“åœ°è¯´ï¼Œæˆ‘ä»¬æè®®å°†å¤šå®ä¾‹å­¦ä¹ ï¼ˆMILï¼‰æ¡†æ¶ä¸é¢„å¤„ç†ç®¡é“ç›¸ç»“åˆï¼Œè¯¥ç®¡é“åˆ©ç”¨å¼ºå¤§çš„åŸºç¡€æ¨¡å‹åœ¨è®­ç»ƒä¹‹å‰æ ¡æ­£æ ‡ç­¾ã€‚è¯¥é¢„å¤„ç†ç®¡é“ä¸æ£€æµ‹å™¨å¤´éƒ¨çš„è½»å¾®ä¿®æ”¹ç›¸ç»“åˆï¼Œåœ¨å¤šä¸ªæ•°æ®é›†ä¸Šå®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œæ— è®ºæ˜¯æ ‡å‡†åœºæ™¯è¿˜æ˜¯å°æ ·æœ¬åœºæ™¯ï¼ŒåŒæ—¶æ¯”å…¶ä»–æ–¹æ³•æ›´ç®€å•ã€æ›´é«˜æ•ˆã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.23726v1">PDF</a> 10 pages, ICIP 2025</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºä¸€ç§ç®€å•é«˜æ•ˆçš„æ–¹æ³•FMG-Detï¼Œç”¨äºåœ¨å¸¦æœ‰å™ªå£°æ ‡æ³¨çš„æ•°æ®é›†ä¸Šè¿›è¡Œæ¨¡å‹è®­ç»ƒã€‚è¯¥æ–¹æ³•ç»“åˆäº†å¤šé‡å®ä¾‹å­¦ä¹ ï¼ˆMILï¼‰æ¡†æ¶å’Œä¸€ä¸ªé¢„å¤„ç†ç®¡é“ï¼Œåˆ©ç”¨å¼ºå¤§çš„åŸºç¡€æ¨¡å‹åœ¨è®­ç»ƒå‰è¿›è¡Œæ ‡ç­¾æ ¡æ­£ã€‚æ­¤é¢„å¤„ç†ç®¡é“ä¸æ£€æµ‹å™¨å¤´éƒ¨çš„è½»å¾®ä¿®æ”¹ç›¸ç»“åˆï¼Œå¯åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šå®ç°æ ‡å‡†ä¸å°‘æ ·æœ¬åœºæ™¯çš„æœ€ä½³æ€§èƒ½ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æ•°æ®æ”¶é›†æ˜¯ç›®æ ‡æ£€æµ‹ä»»åŠ¡ä¸­çš„ä¸€å¤§æŒ‘æˆ˜ï¼Œæ ‡æ³¨å¯¹è±¡è¾¹ç•Œå…·æœ‰ä¸»è§‚æ€§ï¼Œå¯¼è‡´è·¨æ•°æ®é›†éš¾ä»¥è·å¾—ä¸€è‡´çš„æ³¨é‡Šå¹¶å¯¹å…¶è¿›è¡ŒéªŒè¯ã€‚</li>
<li>å½“å¯¹è±¡è¾¹ç•Œéƒ¨åˆ†å¯è§æˆ–æ¨¡ç³Šæ—¶ï¼ŒæŒ‘æˆ˜è¿›ä¸€æ­¥åŠ å¤§ï¼Œè¿™åœ¨è®¸å¤šé¢†åŸŸéƒ½å¯èƒ½æ˜¯å¸¸æ€ã€‚</li>
<li>å™ªå£°æ ‡æ³¨ä¼šå¯¹æ£€æµ‹å™¨æ€§èƒ½é€ æˆä¸¥é‡å½±å“ï¼Œç‰¹åˆ«æ˜¯åœ¨å°‘æ ·æœ¬åœºæ™¯ä¸‹ï¼Œå‡ ä¸ªè¢«æŸåçš„æ ‡æ³¨å°±ä¼šå½±å“æ¨¡å‹æ€§èƒ½ã€‚</li>
<li>æå‡ºäº†ä¸€ç§æ–°çš„æ–¹æ³•FMG-Detï¼Œç»“åˆå¤šé‡å®ä¾‹å­¦ä¹ ï¼ˆMILï¼‰æ¡†æ¶å’Œé¢„å¤„ç†ç®¡é“æ¥è§£å†³å™ªå£°æ ‡æ³¨é—®é¢˜ã€‚</li>
<li>é¢„å¤„ç†ç®¡é“åˆ©ç”¨å¼ºå¤§çš„åŸºç¡€æ¨¡å‹åœ¨è®­ç»ƒå‰è¿›è¡Œæ ‡ç­¾æ ¡æ­£ï¼Œå¯ä»¥æé«˜æ¨¡å‹å¯¹å„ç§æ•°æ®é›†çš„å¤„ç†èƒ½åŠ›ã€‚</li>
<li>FMG-Detåœ¨æ ‡å‡†ä¸å°‘æ ·æœ¬åœºæ™¯ä¸‹çš„å¤šä¸ªæ•°æ®é›†ä¸Šå®ç°äº†æœ€ä½³æ€§èƒ½ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.23726">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-715bdd16bfc11b694a125733c819d50c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-fe342e3836a41af2a1bb1d144991d80b.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-30ab005fb4752a106260f87b3e5403dd.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-5c402c331f586503387de94acfb99428.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-89971eccca49237ee148a68263449922.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="Few-Shot-Speech-Deepfake-Detection-Adaptation-with-Gaussian-Processes"><a href="#Few-Shot-Speech-Deepfake-Detection-Adaptation-with-Gaussian-Processes" class="headerlink" title="Few-Shot Speech Deepfake Detection Adaptation with Gaussian Processes"></a>Few-Shot Speech Deepfake Detection Adaptation with Gaussian Processes</h2><p><strong>Authors:Neta Glazer, David Chernin, Idan Achituve, Sharon Gannot, Ethan Fetaya</strong></p>
<p>Recent advancements in Text-to-Speech (TTS) models, particularly in voice cloning, have intensified the demand for adaptable and efficient deepfake detection methods. As TTS systems continue to evolve, detection models must be able to efficiently adapt to previously unseen generation models with minimal data. This paper introduces ADD-GP, a few-shot adaptive framework based on a Gaussian Process (GP) classifier for Audio Deepfake Detection (ADD). We show how the combination of a powerful deep embedding model with the Gaussian processes flexibility can achieve strong performance and adaptability. Additionally, we show this approach can also be used for personalized detection, with greater robustness to new TTS models and one-shot adaptability. To support our evaluation, a benchmark dataset is constructed for this task using new state-of-the-art voice cloning models. </p>
<blockquote>
<p>è¿‘æœŸæ–‡æœ¬è½¬è¯­éŸ³ï¼ˆTTSï¼‰æ¨¡å‹çš„è¿›æ­¥ï¼Œå°¤å…¶æ˜¯åœ¨è¯­éŸ³å…‹éš†æ–¹é¢ï¼Œè¿›ä¸€æ­¥åŠ å‰§äº†å¯¹è‡ªé€‚åº”å’Œé«˜æ•ˆæ·±åº¦ä¼ªé€ æ£€æµ‹æ–¹æ³•çš„éœ€æ±‚ã€‚éšç€TTSç³»ç»Ÿçš„ä¸æ–­å‘å±•ï¼Œæ£€æµ‹æ¨¡å‹å¿…é¡»èƒ½å¤Ÿä»¥æœ€å°çš„æ•°æ®é‡é«˜æ•ˆåœ°é€‚åº”ä»¥å‰æœªè§è¿‡çš„ç”Ÿæˆæ¨¡å‹ã€‚æœ¬æ–‡ä»‹ç»äº†ADD-GPï¼Œè¿™æ˜¯ä¸€ç§åŸºäºé«˜æ–¯è¿‡ç¨‹ï¼ˆGPï¼‰åˆ†ç±»å™¨çš„éŸ³é¢‘æ·±åº¦ä¼ªé€ æ£€æµ‹ï¼ˆADDï¼‰çš„å°‘é‡è‡ªé€‚åº”æ¡†æ¶ã€‚æˆ‘ä»¬å±•ç¤ºäº†å¼ºå¤§çš„æ·±åº¦åµŒå…¥æ¨¡å‹ä¸é«˜æ–¯è¿‡ç¨‹çš„çµæ´»æ€§ç›¸ç»“åˆå¦‚ä½•å®ç°å¼ºå¤§çš„æ€§èƒ½å’Œé€‚åº”æ€§ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜å±•ç¤ºäº†è¿™ç§æ–¹æ³•ä¹Ÿå¯ç”¨äºä¸ªæ€§åŒ–æ£€æµ‹ï¼Œå¯¹æ–°TTSæ¨¡å‹çš„é²æ£’æ€§æ›´å¼ºï¼Œå¹¶å…·æœ‰ä¸€æ¬¡é€‚åº”æ€§ã€‚ä¸ºäº†æ”¯æŒæˆ‘ä»¬çš„è¯„ä¼°ï¼Œæˆ‘ä»¬ä½¿ç”¨æœ€æ–°çš„è¯­éŸ³å…‹éš†æ¨¡å‹æ„å»ºäº†ç”¨äºæ­¤ä»»åŠ¡çš„æ ‡å‡†æ•°æ®é›†ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.23619v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>è¿‘æœŸæ–‡æœ¬è½¬è¯­éŸ³ï¼ˆTTSï¼‰æ¨¡å‹çš„è¿›æ­¥ï¼Œç‰¹åˆ«æ˜¯è¯­éŸ³å…‹éš†é¢†åŸŸçš„å‘å±•ï¼Œä½¿å¾—å¯¹é€‚åº”æ€§é«˜ä¸”é«˜æ•ˆçš„æ·±åº¦ä¼ªé€ æ£€æµ‹æ–¹æ³•çš„å‘¼å£°ä¸Šå‡ã€‚æ–‡ç« æå‡ºäº†ADD-GPæ¨¡å‹ï¼Œè¯¥æ¨¡å‹ç»“åˆäº†é«˜æ–¯è¿‡ç¨‹åˆ†ç±»å™¨å’Œæ·±åº¦åµŒå…¥æ¨¡å‹çš„ç‰¹ç‚¹ï¼Œä»¥å®ç°é«˜æ•ˆè€Œé€‚åº”å¤šå˜çš„éŸ³é¢‘æ·±åº¦ä¼ªé€ æ£€æµ‹ï¼ˆADDï¼‰ã€‚ç ”ç©¶è¡¨æ˜ï¼ŒADD-GPæ¡†æ¶å…·æœ‰è‰¯å¥½çš„æ€§èƒ½è¡¨ç°åŠå¯¹æ–°æ¨¡å‹çš„é€‚åº”æ€§ï¼Œå¹¶æ”¯æŒä¸ªæ€§åŒ–æ£€æµ‹ï¼Œå°¤å…¶æ˜¯å¯¹æ–°å‡ºç°çš„TTSæ¨¡å‹çš„å¥å£®æ€§å°¤ä¸ºçªå‡ºï¼Œå¹¶èƒ½è¿›è¡Œå•ä¾‹é€‚åº”æ€§ã€‚æ­¤å¤–ï¼Œè¯¥ç ”ç©¶é€šè¿‡é‡‡ç”¨æœ€æ–°è¯­éŸ³å…‹éš†æ¨¡å‹æ„å»ºåŸºå‡†æ•°æ®é›†ï¼Œå¯¹æå‡ºçš„æ–¹æ¡ˆè¿›è¡Œäº†å…¨é¢è¯„ä¼°ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>TTSæ¨¡å‹çš„æœ€æ–°è¿›å±•æ¨åŠ¨äº†æ·±åº¦ä¼ªé€ æ£€æµ‹æ–¹æ³•çš„è¿›åŒ–éœ€æ±‚ã€‚</li>
<li>ADD-GPæ¨¡å‹ç»“åˆäº†é«˜æ–¯è¿‡ç¨‹åˆ†ç±»å™¨å’Œæ·±åº¦åµŒå…¥æ¨¡å‹çš„ä¼˜åŠ¿ã€‚</li>
<li>ADD-GPæ¡†æ¶è¡¨ç°å‡ºå¼ºå¤§çš„æ€§èƒ½å’Œé€‚åº”æ€§ï¼Œå°¤å…¶æ˜¯å¯¹æ–°å‡ºç°çš„TTSæ¨¡å‹çš„å¥å£®æ€§çªå‡ºã€‚</li>
<li>è¯¥æ–¹æ³•æ”¯æŒä¸ªæ€§åŒ–æ£€æµ‹å¹¶å…·æœ‰å•ä¾‹é€‚åº”æ€§ã€‚</li>
<li>é‡‡ç”¨æœ€æ–°è¯­éŸ³å…‹éš†æ¨¡å‹æ„å»ºçš„åŸºå‡†æ•°æ®é›†ç”¨äºè¯„ä¼°è¯¥æ–¹æ³•çš„æ€§èƒ½ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.23619">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-9c5f0ee5a90d319251cbd329d021d84d.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-c888462649dbd9a9addbc91e785591d3.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-84d3b51910bf7d5a63c9a9661966703f.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="Hierarchical-Material-Recognition-from-Local-Appearance"><a href="#Hierarchical-Material-Recognition-from-Local-Appearance" class="headerlink" title="Hierarchical Material Recognition from Local Appearance"></a>Hierarchical Material Recognition from Local Appearance</h2><p><strong>Authors:Matthew Beveridge, Shree K. Nayar</strong></p>
<p>We introduce a taxonomy of materials for hierarchical recognition from local appearance. Our taxonomy is motivated by vision applications and is arranged according to the physical traits of materials. We contribute a diverse, in-the-wild dataset with images and depth maps of the taxonomy classes. Utilizing the taxonomy and dataset, we present a method for hierarchical material recognition based on graph attention networks. Our model leverages the taxonomic proximity between classes and achieves state-of-the-art performance. We demonstrate the modelâ€™s potential to generalize to adverse, real-world imaging conditions, and that novel views rendered using the depth maps can enhance this capability. Finally, we show the modelâ€™s capacity to rapidly learn new materials in a few-shot learning setting. </p>
<blockquote>
<p>æˆ‘ä»¬ä»‹ç»äº†ä¸€ç§ç”¨äºä»å±€éƒ¨å¤–è§‚è¿›è¡Œå±‚æ¬¡è¯†åˆ«çš„ææ–™åˆ†ç±»ã€‚æˆ‘ä»¬çš„åˆ†ç±»å­¦å—è§†è§‰åº”ç”¨çš„å¯å‘ï¼Œæ ¹æ®ææ–™çš„ç‰©ç†ç‰¹å¾è¿›è¡Œæ’åˆ—ã€‚æˆ‘ä»¬è´¡çŒ®äº†ä¸€ä¸ªåŒ…å«åˆ†ç±»å›¾åƒå’Œæ·±åº¦å›¾çš„å¤šæ ·åŒ–é‡å¤–æ•°æ®é›†ã€‚åˆ©ç”¨åˆ†ç±»å’Œæ•°æ®é›†ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åŸºäºå›¾æ³¨æ„åŠ›ç½‘ç»œçš„å±‚æ¬¡ææ–™è¯†åˆ«æ–¹æ³•ã€‚æˆ‘ä»¬çš„æ¨¡å‹åˆ©ç”¨ç±»ä¹‹é—´çš„åˆ†ç±»é‚»è¿‘æ€§ï¼Œå®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚æˆ‘ä»¬è¯æ˜äº†è¯¥æ¨¡å‹åœ¨æ¶åŠ£çš„ã€çœŸå®ä¸–ç•Œçš„æˆåƒæ¡ä»¶ä¸‹å…·æœ‰æ¨å¹¿æ½œåŠ›ï¼Œä»¥åŠä½¿ç”¨æ·±åº¦å›¾å‘ˆç°çš„æ–°è§†è§’å¯ä»¥å¢å¼ºè¿™ä¸€èƒ½åŠ›ã€‚æœ€åï¼Œæˆ‘ä»¬å±•ç¤ºäº†è¯¥æ¨¡å‹åœ¨å°‘é‡å­¦ä¹ ç¯å¢ƒä¸­å¿«é€Ÿå­¦ä¹ æ–°ææ–™çš„æ½œåŠ›ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.22911v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†ä¸€ç§åŸºäºå±€éƒ¨å¤–è§‚çš„ç”¨äºå±‚æ¬¡è¯†åˆ«çš„ææ–™åˆ†ç±»ä½“ç³»ã€‚è¯¥åˆ†ç±»ä½“ç³»ä»¥è§†è§‰åº”ç”¨ä¸ºåŠ¨æœºï¼Œæ ¹æ®ææ–™çš„ç‰©ç†ç‰¹å¾è¿›è¡Œæ’åˆ—ã€‚æ–‡ç« è´¡çŒ®äº†ä¸€ä¸ªåŒ…å«åˆ†ç±»ç±»åˆ«å›¾åƒå’Œæ·±åº¦å›¾çš„é‡å¤–æ•°æ®é›†ï¼Œå¹¶æå‡ºäº†ä¸€ç§åŸºäºå›¾æ³¨æ„åŠ›ç½‘ç»œçš„æ–¹æ³•æ¥è¿›è¡Œå±‚æ¬¡ææ–™è¯†åˆ«ã€‚è¯¥æ–¹æ³•åˆ©ç”¨ç±»åˆ«ä¹‹é—´çš„åˆ†ç±»æ¥è¿‘æ€§ï¼Œå®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚æ–‡ç« å±•ç¤ºäº†è¯¥æ¨¡å‹åœ¨æ¶åŠ£ç°å®æˆåƒæ¡ä»¶ä¸‹çš„æ³›åŒ–æ½œåŠ›ï¼Œä»¥åŠä½¿ç”¨æ·±åº¦å›¾æ¸²æŸ“çš„æ–°è§†è§’å¢å¼ºæ­¤èƒ½åŠ›çš„å¯èƒ½æ€§ã€‚æœ€åï¼Œå±•ç¤ºäº†è¯¥æ¨¡å‹åœ¨å°‘é‡å­¦ä¹ åœºæ™¯ä¸­çš„å¿«é€Ÿå­¦ä¹ æ–°ææ–™çš„èƒ½åŠ›ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¼•å…¥äº†ä¸€ç§åŸºäºè§†è§‰åº”ç”¨çš„ææ–™åˆ†ç±»ä½“ç³»ï¼Œè¯¥ä½“ç³»æ ¹æ®ææ–™çš„ç‰©ç†ç‰¹å¾è¿›è¡Œåˆ†ç±»ã€‚</li>
<li>æä¾›äº†ä¸€ä¸ªåŒ…å«å›¾åƒå’Œæ·±åº¦å›¾çš„é‡å¤–æ•°æ®é›†ï¼Œç”¨äºå±‚æ¬¡ææ–™è¯†åˆ«ç ”ç©¶ã€‚</li>
<li>æå‡ºäº†ä¸€ç§åŸºäºå›¾æ³¨æ„åŠ›ç½‘ç»œçš„å±‚æ¬¡ææ–™è¯†åˆ«æ–¹æ³•ï¼Œè¯¥æ–¹æ³•åˆ©ç”¨ç±»åˆ«ä¹‹é—´çš„åˆ†ç±»æ¥è¿‘æ€§ã€‚</li>
<li>è¯¥æ¨¡å‹åœ¨æ¶åŠ£ç°å®æˆåƒæ¡ä»¶ä¸‹å…·æœ‰è‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›ã€‚</li>
<li>ä½¿ç”¨æ·±åº¦å›¾æ¸²æŸ“çš„æ–°è§†è§’å¯ä»¥å¢å¼ºæ¨¡å‹çš„è¯†åˆ«èƒ½åŠ›ã€‚</li>
<li>æ¨¡å‹å…·æœ‰å¿«é€Ÿå­¦ä¹ æ–°ææ–™çš„èƒ½åŠ›ï¼Œåœ¨å°‘é‡å­¦ä¹ åœºæ™¯ä¸­è¡¨ç°ä¼˜å¼‚ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.22911">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-b4379d00842132fb989f4296bb98cc47.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e54ed452c901b8dabf804d9cf39e9a12.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-75af70afb0c744287fdb407193bfcd29.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-5e6dac87a7c92374ba073039029d16d1.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-6c6fb40fb9641761d614d821c391e191.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="Sparseformer-a-Transferable-Transformer-with-Multi-granularity-Token-Sparsification-for-Medical-Time-Series-Classification"><a href="#Sparseformer-a-Transferable-Transformer-with-Multi-granularity-Token-Sparsification-for-Medical-Time-Series-Classification" class="headerlink" title="Sparseformer: a Transferable Transformer with Multi-granularity Token   Sparsification for Medical Time Series Classification"></a>Sparseformer: a Transferable Transformer with Multi-granularity Token   Sparsification for Medical Time Series Classification</h2><p><strong>Authors:Jiexia Ye, Weiqi Zhang, Ziyue Li, Jia Li, Fugee Tsung</strong></p>
<p>Medical time series (MedTS) classification is crucial for improved diagnosis in healthcare, and yet it is challenging due to the varying granularity of patterns, intricate inter-channel correlation, information redundancy, and label scarcity. While existing transformer-based models have shown promise in time series analysis, they mainly focus on forecasting and fail to fully exploit the distinctive characteristics of MedTS data. In this paper, we introduce Sparseformer, a transformer specifically designed for MedTS classification. We propose a sparse token-based dual-attention mechanism that enables global modeling and token compression, allowing dynamic focus on the most informative tokens while distilling redundant features. This mechanism is then applied to the multi-granularity, cross-channel encoding of medical signals, capturing intra- and inter-granularity correlations and inter-channel connections. The sparsification design allows our model to handle heterogeneous inputs of varying lengths and channels directly. Further, we introduce an adaptive label encoder to address label space misalignment across datasets, equipping our model with cross-dataset transferability to alleviate the medical label scarcity issue. Our model outperforms 12 baselines across seven medical datasets under supervised learning. In the few-shot learning experiments, our model also achieves superior average results. In addition, the in-domain and cross-domain experiments among three diagnostic scenarios demonstrate our modelâ€™s zero-shot learning capability. Collectively, these findings underscore the robustness and transferability of our model in various medical applications. </p>
<blockquote>
<p>åŒ»ç–—æ—¶é—´åºåˆ—ï¼ˆMedTSï¼‰åˆ†ç±»å¯¹äºæ”¹è¿›åŒ»ç–—ä¿å¥ä¸­çš„è¯Šæ–­è‡³å…³é‡è¦ï¼Œç„¶è€Œç”±äºæ¨¡å¼çš„ä¸åŒç²’åº¦ã€å¤æ‚çš„è·¨é€šé“ç›¸å…³æ€§ã€ä¿¡æ¯å†—ä½™å’Œæ ‡ç­¾ç¨€ç¼ºï¼Œå®ƒä»ç„¶æ˜¯ä¸€ä¸ªæŒ‘æˆ˜ã€‚å°½ç®¡ç°æœ‰çš„åŸºäºå˜å‹å™¨çš„æ¨¡å‹åœ¨æ—¶é—´åºåˆ—åˆ†æä¸­æ˜¾ç¤ºå‡ºå¸Œæœ›ï¼Œä½†å®ƒä»¬ä¸»è¦ä¾§é‡äºé¢„æµ‹ï¼Œæœªèƒ½å……åˆ†åˆ©ç”¨MedTSæ•°æ®çš„ç‰¹å¾ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬ä»‹ç»äº†Sparseformerï¼Œè¿™æ˜¯ä¸€ä¸ªä¸“ä¸ºMedTSåˆ†ç±»è®¾è®¡çš„å˜å‹å™¨ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§åŸºäºç¨€ç–æ ‡è®°çš„åŒé‡æ³¨æ„åŠ›æœºåˆ¶ï¼Œèƒ½å¤Ÿå®ç°å…¨å±€å»ºæ¨¡å’Œæ ‡è®°å‹ç¼©ï¼Œå…è®¸åŠ¨æ€å…³æ³¨æœ€å…·ä¿¡æ¯çš„æ ‡è®°ï¼ŒåŒæ—¶æç‚¼å†—ä½™ç‰¹å¾ã€‚ç„¶åï¼Œè¯¥æœºåˆ¶åº”ç”¨äºåŒ»ç–—ä¿¡å·çš„å¤šç²’åº¦ã€è·¨é€šé“ç¼–ç ï¼Œæ•è·ç²’åº¦å’Œè·¨ç²’åº¦å…³è”ä»¥åŠè·¨é€šé“è¿æ¥ã€‚ç¨€ç–åŒ–è®¾è®¡å…è®¸æˆ‘ä»¬çš„æ¨¡å‹ç›´æ¥å¤„ç†ä¸åŒé•¿åº¦å’Œé€šé“çš„å¼‚æ„è¾“å…¥ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§è‡ªé€‚åº”æ ‡ç­¾ç¼–ç å™¨æ¥è§£å†³æ•°æ®é›†ä¹‹é—´æ ‡ç­¾ç©ºé—´çš„ä¸å¯¹é½é—®é¢˜ï¼Œä¸ºæˆ‘ä»¬çš„æ¨¡å‹é…å¤‡è·¨æ•°æ®é›†çš„å¯è½¬ç§»æ€§ï¼Œä»¥ç¼“è§£åŒ»ç–—æ ‡ç­¾ç¨€ç¼ºé—®é¢˜ã€‚æˆ‘ä»¬çš„æ¨¡å‹åœ¨ä¸ƒä¸ªåŒ»ç–—æ•°æ®é›†çš„ç›‘ç£å­¦ä¹ ä¸‹è¶…è¶Šäº†12ä¸ªåŸºå‡†æµ‹è¯•ã€‚åœ¨å°‘é‡å­¦ä¹ å®éªŒä¸­ï¼Œæˆ‘ä»¬çš„æ¨¡å‹ä¹Ÿå–å¾—äº†ä¼˜è¶Šçš„å¹³å‡ç»“æœã€‚æ­¤å¤–ï¼Œä¸‰ä¸ªè¯Šæ–­åœºæ™¯ä¸­çš„åŸŸå†…å’Œè·¨åŸŸå®éªŒè¯æ˜äº†æˆ‘ä»¬çš„æ¨¡å‹çš„é›¶æ ·æœ¬å­¦ä¹ èƒ½åŠ›ã€‚æ€»çš„æ¥è¯´ï¼Œè¿™äº›å‘ç°å‡¸æ˜¾äº†æˆ‘ä»¬çš„æ¨¡å‹åœ¨å„ç§åŒ»ç–—åº”ç”¨ä¸­çš„ç¨³å¥æ€§å’Œå¯è½¬ç§»æ€§ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.15578v2">PDF</a> 3 figures, 16 pages, 5 tables</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ä¸ªä¸“ä¸ºåŒ»ç–—æ—¶é—´åºåˆ—åˆ†ç±»è®¾è®¡çš„Sparseformeræ¨¡å‹ã€‚è¯¥æ¨¡å‹é‡‡ç”¨ç¨€ç–æ ‡è®°çš„åŸºäºåŒæ³¨æ„åŠ›æœºåˆ¶ï¼Œå®ç°å…¨å±€å»ºæ¨¡å’Œæ ‡è®°å‹ç¼©ï¼Œèƒ½å¤ŸåŠ¨æ€å…³æ³¨æœ€å…·ä¿¡æ¯é‡çš„æ ‡è®°å¹¶è¿‡æ»¤å†—ä½™ç‰¹å¾ã€‚è¯¥æ¨¡å‹åº”ç”¨äºåŒ»ç–—ä¿¡å·çš„è·¨ç²’åº¦ã€è·¨é€šé“ç¼–ç ï¼Œæ•æ‰å†…éƒ¨å’Œå¤–éƒ¨ç²’åº¦çš„å…³è”å’Œé€šé“é—´çš„è¿æ¥ã€‚å…¶ç¨€ç–è®¾è®¡å¯å¤„ç†ä¸åŒé•¿åº¦å’Œé€šé“çš„å¼‚è´¨è¾“å…¥ã€‚æ­¤å¤–ï¼Œä¸ºè§£å†³æ ‡ç­¾ç©ºé—´è·¨æ•°æ®é›†çš„å¯¹é½é—®é¢˜ï¼Œæ¨¡å‹å¼•å…¥äº†è‡ªé€‚åº”æ ‡ç­¾ç¼–ç å™¨ï¼Œèµ‹äºˆäº†å…¶è·¨æ•°æ®é›†è¿ç§»èƒ½åŠ›ï¼Œä»¥ç¼“è§£åŒ»ç–—æ ‡ç­¾ç¨€ç¼ºçš„é—®é¢˜ã€‚Sparseformeræ¨¡å‹åœ¨ä¸ƒä¸ªåŒ»ç–—æ•°æ®é›†ä¸Šçš„ç›‘ç£å­¦ä¹ è¡¨ç°ä¼˜äºåäºŒä¸ªåŸºçº¿æ¨¡å‹ã€‚åœ¨å°‘é‡çš„å­¦ä¹ ä¸­ï¼Œæˆ‘ä»¬çš„æ¨¡å‹ä¹Ÿå–å¾—äº†ä¼˜å¼‚çš„å¹³å‡ç»“æœã€‚åŒæ—¶ï¼Œè·¨ä¸‰ç§è¯Šæ–­åœºæ™¯çš„å®éªŒè¡¨æ˜ï¼Œè¯¥æ¨¡å‹è¿˜å…·å¤‡é›¶æ ·æœ¬å­¦ä¹ èƒ½åŠ›ã€‚è¿™äº›ç»“æœçªæ˜¾äº†æ¨¡å‹åœ¨å„ç§åŒ»ç–—åº”ç”¨ä¸­çš„ç¨³å¥æ€§å’Œè¿ç§»èƒ½åŠ›ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>Sparseformeræ˜¯ä¸€ä¸ªä¸“ä¸ºåŒ»ç–—æ—¶é—´åºåˆ—åˆ†ç±»è®¾è®¡çš„å˜å‹å™¨æ¨¡å‹ã€‚</li>
<li>æ¨¡å‹é‡‡ç”¨ç¨€ç–æ ‡è®°çš„åŸºäºåŒæ³¨æ„åŠ›æœºåˆ¶ï¼Œå®ç°å…¨å±€å»ºæ¨¡å’Œæ ‡è®°å‹ç¼©ã€‚</li>
<li>è¯¥æ¨¡å‹èƒ½å¤Ÿå¤„ç†ä¸åŒé•¿åº¦å’Œé€šé“çš„å¼‚è´¨è¾“å…¥ã€‚</li>
<li>å¼•å…¥è‡ªé€‚åº”æ ‡ç­¾ç¼–ç å™¨ä»¥è§£å†³è·¨æ•°æ®é›†çš„æ ‡ç­¾ç©ºé—´å¯¹é½é—®é¢˜ã€‚</li>
<li>Sparseformeråœ¨å¤šä¸ªåŒ»ç–—æ•°æ®é›†ä¸Šçš„ç›‘ç£å­¦ä¹ è¡¨ç°ä¼˜äºå…¶ä»–æ¨¡å‹ã€‚</li>
<li>åœ¨å°‘é‡å­¦ä¹ åœºæ™¯ä¸­ï¼ŒSparseformerä¹Ÿè¡¨ç°å‡ºä¼˜å¼‚çš„æ€§èƒ½ã€‚</li>
<li>æ¨¡å‹å…·å¤‡é›¶æ ·æœ¬å­¦ä¹ èƒ½åŠ›ï¼Œçªæ˜¾äº†å…¶ç¨³å¥æ€§å’Œè¿ç§»èƒ½åŠ›ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.15578">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-667e036121a176284c82f5d70d6a102b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-012925f43e5abf60ba4981e8dae2e871.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="Do-we-still-need-Human-Annotators-Prompting-Large-Language-Models-for-Aspect-Sentiment-Quad-Prediction"><a href="#Do-we-still-need-Human-Annotators-Prompting-Large-Language-Models-for-Aspect-Sentiment-Quad-Prediction" class="headerlink" title="Do we still need Human Annotators? Prompting Large Language Models for   Aspect Sentiment Quad Prediction"></a>Do we still need Human Annotators? Prompting Large Language Models for   Aspect Sentiment Quad Prediction</h2><p><strong>Authors:Nils Constantin Hellwig, Jakob Fehle, Udo Kruschwitz, Christian Wolff</strong></p>
<p>Aspect sentiment quad prediction (ASQP) facilitates a detailed understanding of opinions expressed in a text by identifying the opinion term, aspect term, aspect category and sentiment polarity for each opinion. However, annotating a full set of training examples to fine-tune models for ASQP is a resource-intensive process. In this study, we explore the capabilities of large language models (LLMs) for zero- and few-shot learning on the ASQP task across five diverse datasets. We report F1 scores almost up to par with those obtained with state-of-the-art fine-tuned models and exceeding previously reported zero- and few-shot performance. In the 20-shot setting on the Rest16 restaurant domain dataset, LLMs achieved an F1 score of 51.54, compared to 60.39 by the best-performing fine-tuned method MVP. Additionally, we report the performance of LLMs in target aspect sentiment detection (TASD), where the F1 scores were close to fine-tuned models, achieving 68.93 on Rest16 in the 30-shot setting, compared to 72.76 with MVP. While human annotators remain essential for achieving optimal performance, LLMs can reduce the need for extensive manual annotation in ASQP tasks. </p>
<blockquote>
<p>é¢å‘æ–¹é¢çš„æƒ…æ„Ÿå››å…ƒé¢„æµ‹ï¼ˆASQPï¼‰é€šè¿‡è¯†åˆ«æ¯ä¸ªæ„è§çš„è§‚ç‚¹è¯ã€æ–¹é¢è¯ã€æ–¹é¢ç±»åˆ«å’Œæƒ…æ„Ÿææ€§ï¼Œä»è€Œä¿ƒè¿›å¯¹æ–‡æœ¬ä¸­æ‰€è¡¨è¾¾æ„è§çš„æ·±åº¦ç†è§£ã€‚ç„¶è€Œï¼Œä¸ºASQPä»»åŠ¡æ ‡æ³¨å…¨å¥—è®­ç»ƒæ ·æœ¬ä»¥å¾®è°ƒæ¨¡å‹æ˜¯ä¸€ä¸ªèµ„æºå¯†é›†å‹çš„æµç¨‹ã€‚åœ¨æœ¬ç ”ç©¶ä¸­ï¼Œæˆ‘ä»¬æ¢ç´¢å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨äº”ä¸ªä¸åŒæ•°æ®é›†ä¸Šæ‰§è¡ŒASQPä»»åŠ¡çš„é›¶æ ·æœ¬å­¦ä¹ å’Œå°‘æ ·æœ¬å­¦ä¹ èƒ½åŠ›ã€‚æˆ‘ä»¬æŠ¥å‘Šçš„F1åˆ†æ•°å‡ ä¹ä¸æœ€å…ˆè¿›ç»è¿‡å¾®è°ƒæ¨¡å‹çš„F1åˆ†æ•°æŒå¹³ï¼Œå¹¶ä¸”è¶…è¿‡äº†å…ˆå‰æŠ¥å‘Šçš„é›¶æ ·æœ¬å’Œå°‘æ ·æœ¬æ€§èƒ½ã€‚åœ¨Rest16é¤å…åŸŸæ•°æ®é›†çš„20æ¬¡å®éªŒä¸­ï¼ŒLLMså–å¾—äº†F1åˆ†æ•°ä¸º51.54çš„åˆ†æ•°ï¼Œè€Œè¡¨ç°æœ€ä½³çš„ç»è¿‡è®­ç»ƒçš„MVPæ–¹æ³•å–å¾—çš„åˆ†æ•°ä¸º60.39ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æŠ¥å‘Šäº†ç›®æ ‡æ–¹é¢æƒ…æ„Ÿæ£€æµ‹ï¼ˆTASDï¼‰ä¸­LLMsçš„æ€§èƒ½è¡¨ç°ã€‚åœ¨Rest16æ•°æ®é›†ä¸Šçš„å¤šé¡¹å®éªŒä¸­ï¼Œå…¶F1åˆ†æ•°æ¥è¿‘ç»è¿‡è®­ç»ƒçš„æ¨¡å‹ï¼Œåœ¨30æ¬¡å®éªŒä¸­å–å¾—äº†68.93çš„åˆ†æ•°ï¼Œè€ŒMVPå–å¾—äº†çš„åˆ†æ•°ä¸º72.76ã€‚è™½ç„¶äººç±»æ³¨é‡Šå™¨å¯¹äºå®ç°æœ€ä½³æ€§èƒ½è‡³å…³é‡è¦ï¼Œä½†LLMså¯ä»¥å‡å°‘ASQPä»»åŠ¡ä¸­å¯¹å¤§é‡æ‰‹åŠ¨æ ‡æ³¨çš„éœ€æ±‚ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.13044v3">PDF</a> </p>
<p><strong>Summary</strong>:</p>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨é›¶æ ·æœ¬å’Œå°‘æ ·æœ¬å­¦ä¹ æ–¹é¢å±•ç°å‡ºå¼ºå¤§çš„èƒ½åŠ›ï¼Œç”¨äºæ‰§è¡Œé¢å‘æ–¹é¢çš„æƒ…æ„Ÿå››é‡é¢„æµ‹ï¼ˆASQPï¼‰ä»»åŠ¡ã€‚æœ¬ç ”ç©¶å±•ç¤ºäº†LLMsåœ¨äº”ä¸ªä¸åŒæ•°æ®é›†ä¸Šçš„æ€§èƒ½ï¼Œå¹¶æŠ¥å‘Šäº†åœ¨è¿‘ä¹å°æ ·æœ¬æ•°æ®ä¸‹çš„æˆç»©å·²æ¥è¿‘å‰æ²¿å¾®è°ƒæ¨¡å‹ã€‚è™½ç„¶LLMsåœ¨æŸäº›æ–¹é¢è¡¨ç°ä¸å¦‚æœ€ä½³å¾®è°ƒæ¨¡å‹ï¼Œä½†å®ƒä»¬æ˜¾è‘—å‡å°‘äº†äººå·¥æ ‡æ³¨çš„éœ€æ±‚ã€‚</p>
<p><strong>Key Takeaways</strong>:</p>
<ol>
<li>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å…·å¤‡é›¶æ ·æœ¬å’Œå°‘æ ·æœ¬å­¦ä¹ çš„èƒ½åŠ›ï¼Œå¯ä»¥åœ¨é¢å‘æ–¹é¢çš„æƒ…æ„Ÿå››é‡é¢„æµ‹ï¼ˆASQPï¼‰ä»»åŠ¡ä¸Šå±•ç°å¼ºå¤§çš„æ€§èƒ½ã€‚</li>
<li>åœ¨äº”ä¸ªä¸åŒçš„æ•°æ®é›†ä¸Šè¿›è¡Œäº†å®éªŒï¼Œå¹¶æŠ¥å‘Šäº†è¿‘ä¹å°æ ·æœ¬æ•°æ®ä¸‹çš„æ€§èƒ½è¡¨ç°ã€‚</li>
<li>LLMsçš„F1å¾—åˆ†ä¸æœ€å‰æ²¿çš„å¾®è°ƒæ¨¡å‹ç›¸å½“ï¼Œå¹¶ä¸”åœ¨æŸäº›åœºæ™¯ä¸‹è¶…è¶Šäº†ä»¥å¾€çš„é›¶æ ·æœ¬å’Œå°‘æ ·æœ¬æ€§èƒ½è®°å½•ã€‚</li>
<li>åœ¨Rest16é¤å…é¢†åŸŸæ•°æ®é›†ä¸Šè¿›è¡Œçš„20æ¬¡å°æ ·æœ¬å®éªŒä¸­ï¼ŒLLMsçš„F1å¾—åˆ†ä¸º51.54ï¼Œè€Œæœ€ä½³å¾®è°ƒæ¨¡å‹MVPçš„å¾—åˆ†ä¸º60.39ã€‚</li>
<li>LLMsåœ¨ç›®æ ‡æ–¹é¢æƒ…æ„Ÿæ£€æµ‹ï¼ˆTASDï¼‰ä»»åŠ¡ä¸­çš„æ€§èƒ½ä¹Ÿæ¥è¿‘å¾®è°ƒæ¨¡å‹ï¼Œåœ¨Rest16æ•°æ®é›†ä¸Šçš„30æ¬¡å°æ ·æœ¬å®éªŒä¸­ï¼Œå…¶F1å¾—åˆ†ä¸º68.93ï¼Œè€ŒMVPçš„å¾—åˆ†ä¸º72.76ã€‚</li>
<li>è™½ç„¶äººå·¥æ ‡æ³¨å¯¹äºå®ç°æœ€ä½³æ€§èƒ½ä»ç„¶è‡³å…³é‡è¦ï¼Œä½†LLMsæ˜¾è‘—å‡å°‘äº†é¢å‘æ–¹é¢çš„æƒ…æ„Ÿé¢„æµ‹ä»»åŠ¡ä¸­å¯¹å¤§é‡äººå·¥æ ‡æ³¨çš„éœ€æ±‚ã€‚</li>
<li>æ­¤ç ”ç©¶è¯å®äº†å¤§å‹è¯­è¨€æ¨¡å‹åœ¨è§£å†³è‡ªç„¶è¯­è¨€å¤„ç†ä»»åŠ¡æ—¶çš„æ½œåœ¨åº”ç”¨ï¼Œå°¤å…¶æ˜¯èµ„æºæœ‰é™çš„æƒ…å†µä¸‹ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.13044">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-839e79d9c16dd00f4d4a96f762c17a03.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f45479c983dba00127f197503deb6840.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-7d0ee2ac98174f58ecfcb13ac3233c21.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-c827ad25f82f2878b3abc79a21649a99.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="CVOCSemRPL-Class-Variance-Optimized-Clustering-Semantic-Information-Injection-and-Restricted-Pseudo-Labeling-based-Improved-Semi-Supervised-Few-Shot-Learning"><a href="#CVOCSemRPL-Class-Variance-Optimized-Clustering-Semantic-Information-Injection-and-Restricted-Pseudo-Labeling-based-Improved-Semi-Supervised-Few-Shot-Learning" class="headerlink" title="CVOCSemRPL: Class-Variance Optimized Clustering, Semantic Information   Injection and Restricted Pseudo Labeling based Improved Semi-Supervised   Few-Shot Learning"></a>CVOCSemRPL: Class-Variance Optimized Clustering, Semantic Information   Injection and Restricted Pseudo Labeling based Improved Semi-Supervised   Few-Shot Learning</h2><p><strong>Authors:Souvik Maji, Rhythm Baghel, Pratik Mazumder</strong></p>
<p>Few-shot learning has been extensively explored to address problems where the amount of labeled samples is very limited for some classes. In the semi-supervised few-shot learning setting, substantial quantities of unlabeled samples are available. Such unlabeled samples are generally cheaper to obtain and can be used to improve the few-shot learning performance of the model. Some of the recent methods for this setting rely on clustering to generate pseudo-labels for the unlabeled samples. Since the effectiveness of clustering heavily influences the labeling of the unlabeled samples, it can significantly affect the few-shot learning performance. In this paper, we focus on improving the representation learned by the model in order to improve the clustering and, consequently, the model performance. We propose an approach for semi-supervised few-shot learning that performs a class-variance optimized clustering coupled with a cluster separation tuner in order to improve the effectiveness of clustering the labeled and unlabeled samples in this setting. It also optimizes the clustering-based pseudo-labeling process using a restricted pseudo-labeling approach and performs semantic information injection in order to improve the semi-supervised few-shot learning performance of the model. We experimentally demonstrate that our proposed approach significantly outperforms recent state-of-the-art methods on the benchmark datasets. </p>
<blockquote>
<p>å°æ ·æœ¬å­¦ä¹ å·²ç»è¢«å¹¿æ³›æ¢ç´¢ï¼Œä»¥è§£å†³æŸäº›ç±»åˆ«çš„æ ‡æ³¨æ ·æœ¬æ•°é‡éå¸¸æœ‰é™çš„é—®é¢˜ã€‚åœ¨åŠç›‘ç£å°æ ·æœ¬å­¦ä¹ ç¯å¢ƒä¸­ï¼Œå­˜åœ¨å¤§é‡çš„æœªæ ‡æ³¨æ ·æœ¬ã€‚è¿™äº›æœªæ ‡æ³¨æ ·æœ¬é€šå¸¸æ›´å®¹æ˜“è·å–ï¼Œå¹¶å¯ç”¨äºæé«˜æ¨¡å‹çš„å°‘æ ·æœ¬å­¦ä¹ æ€§èƒ½ã€‚æœ€è¿‘çš„ä¸€äº›æ–¹æ³•ä¾èµ–äºèšç±»æ¥ä¸ºæœªæ ‡æ³¨æ ·æœ¬ç”Ÿæˆä¼ªæ ‡ç­¾ã€‚ç”±äºèšç±»çš„æœ‰æ•ˆæ€§å¯¹æœªæ ‡æ³¨æ ·æœ¬çš„æ ‡æ³¨æœ‰é‡è¦å½±å“ï¼Œå› æ­¤å®ƒå¯èƒ½ä¼šæ˜¾è‘—å½±å“å°æ ·æœ¬å­¦ä¹ çš„æ€§èƒ½ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬ä¸“æ³¨äºæ”¹è¿›æ¨¡å‹æ‰€å­¦çš„è¡¨ç¤ºï¼Œä»¥æé«˜èšç±»èƒ½åŠ›å’Œæ¨¡å‹æ€§èƒ½ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§åŠç›‘ç£å°æ ·æœ¬å­¦ä¹ æ–¹æ³•ï¼Œé‡‡ç”¨ç±»æ–¹å·®ä¼˜åŒ–èšç±»ä¸èšç±»åˆ†ç¦»è°ƒèŠ‚å™¨ç›¸ç»“åˆï¼Œä»¥æé«˜è¯¥ç¯å¢ƒä¸­å¸¦æ ‡ç­¾å’Œæ— æ ‡ç­¾æ ·æœ¬çš„èšç±»æ•ˆæœã€‚å®ƒè¿˜é€šè¿‡é™åˆ¶ä¼ªæ ‡ç­¾æ–¹æ³•å’Œæ‰§è¡Œè¯­ä¹‰ä¿¡æ¯æ³¨å…¥æ¥ä¼˜åŒ–åŸºäºèšç±»çš„ä¼ªæ ‡ç­¾è¿‡ç¨‹ï¼Œä»¥æé«˜æ¨¡å‹çš„åŠç›‘ç£å°æ ·æœ¬å­¦ä¹ æ€§èƒ½ã€‚å®éªŒè¯æ˜ï¼Œæˆ‘ä»¬æå‡ºçš„æ–¹æ³•åœ¨åŸºå‡†æ•°æ®é›†ä¸Šæ˜¾è‘—ä¼˜äºæœ€æ–°çš„å…ˆè¿›æ–¹æ³•ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.14401v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æ¢è®¨äº†åŠç›‘ç£å°æ ·æœ¬å­¦ä¹ é—®é¢˜ï¼Œå…¶ä¸­æ¶‰åŠå¯¹æ¨¡å‹è¡¨ç¤ºçš„æ”¹è¿›ä»¥æé«˜èšç±»æ•ˆæœã€‚æ–‡ç« æå‡ºäº†ä¸€ç§åŠç›‘ç£å°æ ·æœ¬å­¦ä¹ æ–¹æ³•ï¼Œé€šè¿‡ç±»æ–¹å·®ä¼˜åŒ–èšç±»å’Œé›†ç¾¤åˆ†ç¦»è°ƒèŠ‚å™¨æ”¹è¿›äº†èšç±»æ•ˆæœã€‚åŒæ—¶ï¼Œé€šè¿‡é™åˆ¶ä¼ªæ ‡ç­¾æ–¹æ³•å’Œè¯­ä¹‰ä¿¡æ¯æ³¨å…¥ä¼˜åŒ–äº†åŸºäºèšç±»çš„ä¼ªæ ‡ç­¾è¿‡ç¨‹ã€‚å®éªŒè¯æ˜ï¼Œè¯¥æ–¹æ³•åœ¨åŸºå‡†æ•°æ®é›†ä¸Šæ˜¾è‘—ä¼˜äºç°æœ‰æœ€æ–°æ–¹æ³•ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æ–‡ç« é›†ä¸­åœ¨æ”¹è¿›æ¨¡å‹è¡¨ç¤ºä»¥æ”¹å–„åŠç›‘ç£å°æ ·æœ¬å­¦ä¹ ä¸­çš„èšç±»æ•ˆæœã€‚</li>
<li>æå‡ºäº†ä¸€ç§æ–°çš„åŠç›‘ç£å°æ ·æœ¬å­¦ä¹ æ–¹æ³•ï¼ŒåŒ…æ‹¬ç±»æ–¹å·®ä¼˜åŒ–èšç±»å’Œé›†ç¾¤åˆ†ç¦»è°ƒèŠ‚å™¨ã€‚</li>
<li>é™åˆ¶ä¼ªæ ‡ç­¾æ–¹æ³•å’Œè¯­ä¹‰ä¿¡æ¯æ³¨å…¥æŠ€æœ¯ç”¨äºä¼˜åŒ–åŸºäºèšç±»çš„ä¼ªæ ‡ç­¾è¿‡ç¨‹ã€‚</li>
<li>æ–¹æ³•åœ¨åŸºå‡†æ•°æ®é›†ä¸Šæ˜¾è‘—ä¼˜äºç°æœ‰æœ€æ–°æ–¹æ³•ã€‚</li>
<li>æœªæ ‡æ³¨æ ·æœ¬åœ¨åŠç›‘ç£å°æ ·æœ¬å­¦ä¹ ä¸­æ‰®æ¼”é‡è¦è§’è‰²ï¼Œå¯ä»¥åˆ©ç”¨è¿™äº›æ ·æœ¬æå‡æ¨¡å‹çš„æ€§èƒ½ã€‚</li>
<li>èšç±»æ–¹æ³•çš„ä¼˜åŒ–ç›´æ¥å½±å“æ¨¡å‹å¯¹å°æ ·æœ¬å­¦ä¹ çš„æ•ˆæœã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.14401">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-f8ea77c3826e1d1b2a731d759d490973.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a7ce8092401c029b65b68962884922da.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-54baa5af340fa404f693103841d5a7c9.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="Re-ranking-Using-Large-Language-Models-for-Mitigating-Exposure-to-Harmful-Content-on-Social-Media-Platforms"><a href="#Re-ranking-Using-Large-Language-Models-for-Mitigating-Exposure-to-Harmful-Content-on-Social-Media-Platforms" class="headerlink" title="Re-ranking Using Large Language Models for Mitigating Exposure to   Harmful Content on Social Media Platforms"></a>Re-ranking Using Large Language Models for Mitigating Exposure to   Harmful Content on Social Media Platforms</h2><p><strong>Authors:Rajvardhan Oak, Muhammad Haroon, Claire Jo, Magdalena Wojcieszak, Anshuman Chhabra</strong></p>
<p>Social media platforms utilize Machine Learning (ML) and Artificial Intelligence (AI) powered recommendation algorithms to maximize user engagement, which can result in inadvertent exposure to harmful content. Current moderation efforts, reliant on classifiers trained with extensive human-annotated data, struggle with scalability and adapting to new forms of harm. To address these challenges, we propose a novel re-ranking approach using Large Language Models (LLMs) in zero-shot and few-shot settings. Our method dynamically assesses and re-ranks content sequences, effectively mitigating harmful content exposure without requiring extensive labeled data. Alongside traditional ranking metrics, we also introduce two new metrics to evaluate the effectiveness of re-ranking in reducing exposure to harmful content. Through experiments on three datasets, three models and across three configurations, we demonstrate that our LLM-based approach significantly outperforms existing proprietary moderation approaches, offering a scalable and adaptable solution for harm mitigation. </p>
<blockquote>
<p>ç¤¾äº¤åª’ä½“å¹³å°åˆ©ç”¨æœºå™¨å­¦ä¹ å’Œäººå·¥æ™ºèƒ½é©±åŠ¨çš„æ¨èç®—æ³•æ¥æœ€å¤§åŒ–ç”¨æˆ·å‚ä¸åº¦ï¼Œè¿™å¯èƒ½å¯¼è‡´æ— æ„ä¸­æ¥è§¦åˆ°æœ‰å®³å†…å®¹ã€‚å½“å‰çš„å®¡æ ¸å·¥ä½œä¾èµ–äºä½¿ç”¨å¤§é‡äººå·¥æ³¨é‡Šæ•°æ®è®­ç»ƒçš„åˆ†ç±»å™¨ï¼Œé¢ä¸´ç€å¯æ‰©å±•æ€§å’Œé€‚åº”æ–°å½¢å¼çš„æŒ‘æˆ˜ã€‚ä¸ºäº†è§£å†³è¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åœ¨é›¶æ ·æœ¬å’Œå°‘æ ·æœ¬ç¯å¢ƒä¸‹ä½¿ç”¨å¤§å‹è¯­è¨€æ¨¡å‹è¿›è¡Œå†æ’åºçš„æ–°æ–¹æ³•ã€‚æˆ‘ä»¬çš„æ–¹æ³•åŠ¨æ€åœ°è¯„ä¼°å’Œé‡æ–°æ’åºå†…å®¹åºåˆ—ï¼Œæœ‰æ•ˆåœ°å‡å°‘æ¥è§¦æœ‰å®³å†…å®¹çš„å¯èƒ½æ€§ï¼Œæ— éœ€ä¾èµ–å¤§é‡çš„æ ‡è®°æ•°æ®ã€‚é™¤äº†ä¼ ç»Ÿçš„æ’åæŒ‡æ ‡å¤–ï¼Œæˆ‘ä»¬è¿˜å¼•å…¥äº†ä¸¤ç§æ–°æŒ‡æ ‡æ¥è¯„ä¼°é‡æ–°æ’åºåœ¨å‡å°‘æ¥è§¦æœ‰å®³å†…å®¹æ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚é€šè¿‡å¯¹ä¸‰ä¸ªæ•°æ®é›†ã€ä¸‰ä¸ªæ¨¡å‹ä»¥åŠä¸‰ç§é…ç½®çš„æµ‹è¯•å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹çš„å†æ’åºæ–¹æ³•æ˜¾è‘—ä¼˜äºç°æœ‰çš„ä¸“æœ‰å®¡æ ¸æ–¹æ³•ï¼Œä¸ºå±å®³ç¼“è§£æä¾›äº†å¯æ‰©å±•å’Œå¯é€‚åº”çš„è§£å†³æ–¹æ¡ˆã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.13977v3">PDF</a> Accepted to ACL 2025 Main Conference</p>
<p><strong>Summary</strong>ï¼šç¤¾äº¤åª’ä½“å¹³å°åˆ©ç”¨æœºå™¨å­¦ä¹ å’Œäººå·¥æ™ºèƒ½é©±åŠ¨çš„æ¨èç®—æ³•æ¥æœ€å¤§åŒ–ç”¨æˆ·å‚ä¸åº¦ï¼Œè¿™å¯èƒ½å¯¼è‡´æ— æ„ä¸­æ¥è§¦åˆ°æœ‰å®³å†…å®¹ã€‚ä¸ºè§£å†³å½“å‰ä¾èµ–å¤§é‡äººå·¥æ ‡æ³¨æ•°æ®è®­ç»ƒçš„åˆ†ç±»å™¨åœ¨å¯æ‰©å±•æ€§å’Œé€‚åº”æ–°å½¢å¼å±å®³æ–¹é¢çš„æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰è¿›è¡Œé›¶æ ·æœ¬å’Œå°‘æ ·æœ¬è®¾ç½®çš„æ–°å‹é‡æ–°æ’åºæ–¹æ³•ã€‚è¯¥æ–¹æ³•èƒ½å¤ŸåŠ¨æ€è¯„ä¼°å’Œé‡æ–°æ’åºå†…å®¹åºåˆ—ï¼Œæœ‰æ•ˆåœ°å‡å°‘æœ‰å®³å†…å®¹çš„æš´éœ²ï¼Œä¸”æ— éœ€å¤§é‡æ ‡æ³¨æ•°æ®ã€‚é™¤äº†ä¼ ç»Ÿçš„æ’åæŒ‡æ ‡å¤–ï¼Œæˆ‘ä»¬è¿˜å¼•å…¥äº†ä¸¤ä¸ªæ–°æŒ‡æ ‡æ¥è¯„ä¼°é‡æ–°æ’åºåœ¨å‡å°‘æœ‰å®³å†…å®¹æš´éœ²æ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚é€šè¿‡åœ¨ä¸‰å¥—æ•°æ®é›†ä¸Šè¿›è¡Œçš„å®éªŒæ˜¾ç¤ºï¼ŒåŸºäºLLMçš„æ–¹æ³•æ˜¾è‘—ä¼˜äºç°æœ‰çš„ä¸“æœ‰è°ƒèŠ‚æ–¹æ³•ï¼Œä¸ºå±å®³ç¼“è§£æä¾›äº†å¯æ‰©å±•å’Œå¯é€‚åº”çš„è§£å†³æ–¹æ¡ˆã€‚</p>
<p><strong>Key Takeaways</strong>ï¼š</p>
<ol>
<li>ç¤¾äº¤åª’ä½“å¹³å°åˆ©ç”¨æœºå™¨å­¦ä¹ å’Œäººå·¥æ™ºèƒ½æ¨èç®—æ³•æœ€å¤§åŒ–ç”¨æˆ·å‚ä¸åº¦ï¼Œå¯èƒ½æ— æ„ä¸­æš´éœ²ç”¨æˆ·äºæœ‰å®³å†…å®¹ã€‚</li>
<li>å½“å‰çš„å†…å®¹è°ƒèŠ‚æ–¹æ³•é¢ä¸´å¯æ‰©å±•æ€§å’Œé€‚åº”æ–°å±å®³å½¢å¼çš„æŒ‘æˆ˜ã€‚</li>
<li>æå‡ºä¸€ç§åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„é‡æ–°æ’åºæ–¹æ³•ï¼Œèƒ½åœ¨é›¶æ ·æœ¬å’Œå°‘æ ·æœ¬è®¾ç½®ä¸‹åŠ¨æ€è¯„ä¼°å’Œé‡æ–°æ’åºå†…å®¹åºåˆ—ã€‚</li>
<li>è¯¥æ–¹æ³•æ— éœ€å¤§é‡æ ‡æ³¨æ•°æ®ï¼Œå³å¯æœ‰æ•ˆå‡å°‘æœ‰å®³å†…å®¹çš„æš´éœ²ã€‚</li>
<li>é™¤äº†ä¼ ç»Ÿæ’åæŒ‡æ ‡å¤–ï¼Œè¿˜å¼•å…¥ä¸¤ä¸ªæ–°æŒ‡æ ‡æ¥è¯„ä¼°é‡æ–°æ’åºçš„æ•ˆæœã€‚</li>
<li>å®éªŒè¡¨æ˜ï¼ŒåŸºäºLLMçš„æ–¹æ³•åœ¨å‡å°‘æœ‰å®³å†…å®¹æš´éœ²æ–¹é¢æ˜¾è‘—ä¼˜äºç°æœ‰ä¸“æœ‰è°ƒèŠ‚æ–¹æ³•ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.13977">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-096f58dd2249d0896c8e6c3991db5030.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-60fedf0358b98bcc751591f4e1ecafba.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-091996f8dd1accff063cd47e57f55673.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-e79737b4fd9d9f7b0199330cd48b515b.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="mOSCAR-A-Large-scale-Multilingual-and-Multimodal-Document-level-Corpus"><a href="#mOSCAR-A-Large-scale-Multilingual-and-Multimodal-Document-level-Corpus" class="headerlink" title="mOSCAR: A Large-scale Multilingual and Multimodal Document-level Corpus"></a>mOSCAR: A Large-scale Multilingual and Multimodal Document-level Corpus</h2><p><strong>Authors:Matthieu Futeral, Armel Zebaze, Pedro Ortiz Suarez, Julien Abadji, RÃ©mi Lacroix, Cordelia Schmid, Rachel Bawden, BenoÃ®t Sagot</strong></p>
<p>Multimodal Large Language Models (mLLMs) are trained on a large amount of text-image data. While most mLLMs are trained on caption-like data only, Alayrac et al. (2022) showed that additionally training them on interleaved sequences of text and images can lead to the emergence of in-context learning capabilities. However, the dataset they used, M3W, is not public and is only in English. There have been attempts to reproduce their results but the released datasets are English-only. In contrast, current multilingual and multimodal datasets are either composed of caption-like only or medium-scale or fully private data. This limits mLLM research for the 7,000 other languages spoken in the world. We therefore introduce mOSCAR, to the best of our knowledge the first large-scale multilingual and multimodal document corpus crawled from the web. It covers 163 languages, 303M documents, 200B tokens and 1.15B images. We carefully conduct a set of filtering and evaluation steps to make sure mOSCAR is sufficiently safe, diverse and of good quality. We additionally train two types of multilingual model to prove the benefits of mOSCAR: (1) a model trained on a subset of mOSCAR and captioning data and (2) a model trained on captioning data only. The model additionally trained on mOSCAR shows a strong boost in few-shot learning performance across various multilingual image-text tasks and benchmarks, confirming previous findings for English-only mLLMs. The dataset is released under the Creative Commons CC BY 4.0 license and can be accessed here: <a target="_blank" rel="noopener" href="https://huggingface.co/datasets/oscar-corpus/mOSCAR">https://huggingface.co/datasets/oscar-corpus/mOSCAR</a> </p>
<blockquote>
<p>å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆmLLMsï¼‰æ˜¯åœ¨å¤§é‡çš„æ–‡æœ¬å›¾åƒæ•°æ®ä¸Šè®­ç»ƒçš„ã€‚è™½ç„¶å¤§å¤šæ•°mLLMä»…åœ¨ç±»ä¼¼æ ‡é¢˜çš„æ•°æ®ä¸Šè¿›è¡Œè®­ç»ƒï¼Œä½†Alayracç­‰äººï¼ˆ2022ï¼‰çš„ç ”ç©¶è¡¨æ˜ï¼Œé€šè¿‡åœ¨æ–‡æœ¬å’Œå›¾åƒçš„äº¤é”™åºåˆ—ä¸Šè¿›è¡Œé¢å¤–è®­ç»ƒï¼Œå¯ä»¥äº§ç”Ÿä¸Šä¸‹æ–‡å­¦ä¹ èƒ½åŠ›ã€‚ç„¶è€Œï¼Œä»–ä»¬ä½¿ç”¨çš„æ•°æ®é›†M3Wå¹¶éå…¬å¼€ä¸”ä»…é€‚ç”¨äºè‹±è¯­ã€‚å°½ç®¡æœ‰äººè¯•å›¾å¤åˆ¶ä»–ä»¬çš„ç»“æœï¼Œä½†å‘å¸ƒçš„æ•°æ®é›†éƒ½æ˜¯è‹±è¯­ç‰ˆæœ¬çš„ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼Œå½“å‰çš„å¤šè¯­ç§å’Œå¤šæ¨¡æ€æ•°æ®é›†è¦ä¹ˆä»…åŒ…å«ç±»ä¼¼æ ‡é¢˜çš„æ•°æ®ï¼Œè¦ä¹ˆæ˜¯ä¸­è§„æ¨¡æˆ–å®Œå…¨ç§æœ‰æ•°æ®ã€‚è¿™é™åˆ¶äº†å…¨çƒå…¶ä»–7,000å¤šç§è¯­è¨€çš„å¤šæ¨¡æ€è¯­è¨€æ¨¡å‹ï¼ˆmLLMï¼‰ç ”ç©¶ã€‚å› æ­¤ï¼Œæˆ‘ä»¬æ¨å‡ºäº†mOSCARï¼Œæ®æˆ‘ä»¬æ‰€çŸ¥ï¼Œå®ƒæ˜¯é¦–ä¸ªä»ç½‘ç»œçˆ¬è™«ä¸­è·å–çš„å¤§è§„æ¨¡å¤šè¯­ç§å¤šæ¨¡æ€æ–‡æ¡£è¯­æ–™åº“ã€‚å®ƒæ¶µç›–163ç§è¯­è¨€ã€3.03äº¿ä»½æ–‡æ¡£ã€20äº¿ä¸ªä»¤ç‰Œå’Œ1.15äº¿å¼ å›¾åƒã€‚æˆ‘ä»¬ç²¾å¿ƒè¿›è¡Œäº†ä¸€ç³»åˆ—è¿‡æ»¤å’Œè¯„ä¼°æ­¥éª¤ï¼Œä»¥ç¡®ä¿mOSCARè¶³å¤Ÿå®‰å…¨ã€å¤šæ ·ä¸”è´¨é‡è‰¯å¥½ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜è®­ç»ƒäº†ä¸¤ç§å¤šè¯­ç§æ¨¡å‹æ¥è¯æ˜mOSCARçš„æ•ˆç›Šï¼šï¼ˆ1ï¼‰ä¸€ç§åœ¨mOSCARå­é›†å’Œæè¿°æ•°æ®ä¸Šè®­ç»ƒçš„æ¨¡å‹ï¼Œï¼ˆ2ï¼‰ä»…ç”¨äºæè¿°æ•°æ®è®­ç»ƒçš„æ¨¡å‹ã€‚ç»è¿‡mOSCARé¢å¤–è®­ç»ƒçš„æ¨¡å‹åœ¨å„ç§å¤šè¯­ç§å›¾åƒæ–‡æœ¬ä»»åŠ¡å’ŒåŸºå‡†æµ‹è¯•ä¸Šçš„å°‘æ ·æœ¬å­¦ä¹ èƒ½åŠ›å¾—åˆ°äº†æå¤§çš„æå‡ï¼Œè¿™è¯å®äº†ä¹‹å‰é’ˆå¯¹è‹±è¯­mLLMçš„å‘ç°ã€‚è¯¥æ•°æ®é›†æ˜¯åœ¨åˆ›æ„å…±äº«CC BY 4.0è®¸å¯è¯ä¸‹å‘å¸ƒçš„ï¼Œå¯ä»ä»¥ä¸‹é“¾æ¥è®¿é—®ï¼š<a target="_blank" rel="noopener" href="https://huggingface.co/datasets/oscar-corpus/mOSCAR">https://huggingface.co/datasets/oscar-corpus/mOSCAR</a>ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2406.08707v2">PDF</a> ACL 2025 (Findings)</p>
<p><strong>Summary</strong><br>     å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆmLLMï¼‰è®­ç»ƒæ—¶èåˆäº†æµ·é‡çš„æ–‡æœ¬å’Œå›¾åƒæ•°æ®ã€‚ç›¸è¾ƒäºä»…ä½¿ç”¨æè¿°æ€§æ•°æ®çš„è®­ç»ƒæ–¹å¼ï¼ŒAlayracç­‰äººå±•ç¤ºäº†é€šè¿‡äº¤æ›¿åºåˆ—çš„æ–‡æœ¬å’Œå›¾åƒè¿›è¡Œè®­ç»ƒèƒ½å¤Ÿä¿ƒä½¿æ¨¡å‹å…·å¤‡ä¸Šä¸‹æ–‡å­¦ä¹ èƒ½åŠ›ã€‚ç„¶è€Œï¼Œå…¶ä½¿ç”¨çš„æ•°æ®é›†M3Wå¹¶æœªå…¬å¼€ä¸”ä»…é™äºè‹±è¯­ã€‚å°½ç®¡æœ‰å°è¯•å¤åˆ¶å…¶æˆæœï¼Œä½†å‘å¸ƒçš„æ•°æ®é›†åŒæ ·ä»…é™äºè‹±è¯­ã€‚ç›¸è¾ƒä¹‹ä¸‹ï¼Œç°æœ‰çš„å¤šè¯­è¨€å¤šæ¨¡æ€æ•°æ®é›†è¦ä¹ˆæ˜¯æè¿°æ€§çš„ï¼Œè¦ä¹ˆæ˜¯ä¸­ç­‰è§„æ¨¡æˆ–å°é—­æ€§çš„ï¼Œè¿™é™åˆ¶äº†å…¨çƒå…¶ä»–ä¸ƒåƒç§è¯­è¨€çš„mLLMç ”ç©¶ã€‚ä¸ºæ­¤ï¼Œæ¨å‡ºmOSCARè¿™ä¸€æ®ç§°é¦–ä¸ªå¤§è§„æ¨¡çš„å¤šè¯­è¨€å¤šæ¨¡æ€æ–‡æ¡£è¯­æ–™åº“ï¼Œæ¶µç›–163ç§è¯­è¨€ã€3.03äº¿æ–‡æ¡£ã€20äº¿è¯æ±‡å’Œ1.1äº¿å›¾åƒã€‚ç»è¿‡ä¸¥æ ¼çš„ç­›é€‰å’Œè¯„ä¼°æµç¨‹ï¼Œç¡®ä¿è¯­æ–™åº“çš„ä¼˜è´¨å’Œå®‰å…¨å¤šæ ·æ€§ã€‚é€šè¿‡ä¸¤ç§ç±»å‹çš„å¤šè¯­ç§æ¨¡å‹éªŒè¯äº†mOSCARçš„æ•ˆç›Šï¼šåœ¨mOSCARå­é›†å’Œæè¿°æ•°æ®ä¸Šè®­ç»ƒçš„æ¨¡å‹ä»¥åŠåœ¨ä»…æè¿°æ•°æ®ä¸Šè®­ç»ƒçš„æ¨¡å‹ã€‚é¢å¤–åœ¨mOSCARä¸Šè®­ç»ƒçš„æ¨¡å‹åœ¨å¤šè¯­ç§å›¾åƒæ–‡æœ¬ä»»åŠ¡å’ŒåŸºå‡†æµ‹è¯•ä¸­æ˜¾ç¤ºå‡ºå¼ºå¤§çš„å°‘æ ·æœ¬å­¦ä¹ èƒ½åŠ›æå‡ï¼Œè¯å®äº†è‹±è¯­mLLMçš„å…ˆå‰å‘ç°ã€‚è¯¥æ•°æ®é›†ä»¥åˆ›æ„å…±äº«CC BY 4.0è®¸å¯è¯å‘å¸ƒï¼Œå¯åœ¨æ­¤è®¿é—®ï¼š<a target="_blank" rel="noopener" href="https://huggingface.co/datasets/oscar-corpus/mOSCAR">huggingface.co&#x2F;datasets&#x2F;oscar-corpus&#x2F;mOSCAR</a>ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>mOSCARæ˜¯é¦–ä¸ªå¤§è§„æ¨¡çš„å¤šè¯­è¨€å¤šæ¨¡æ€æ–‡æ¡£è¯­æ–™åº“ï¼Œæ¶µç›–å¤šç§è¯­è¨€ã€‚</li>
<li>mOSCARåŒ…å«æ¥è‡ªç½‘ç»œçš„æ–‡æœ¬å’Œå›¾åƒæ•°æ®ï¼Œæ–‡æ¡£æ•°é‡åºå¤§ä¸”è¦†ç›–é¢å¹¿ã€‚</li>
<li>mOSCARæ•°æ®ç»è¿‡ç­›é€‰å’Œè¯„ä¼°ä»¥ç¡®ä¿è´¨é‡ã€å¤šæ ·æ€§å’Œå®‰å…¨æ€§ã€‚</li>
<li>é€šè¿‡å¤šè¯­ç§æ¨¡å‹çš„è®­ç»ƒéªŒè¯äº†mOSCARçš„æ•ˆç›Šï¼Œå°‘æ ·æœ¬å­¦ä¹ èƒ½åŠ›æœ‰æ‰€æå‡ã€‚</li>
<li>mOSCARæ•°æ®é›†å…·æœ‰åˆ›æ„å…±äº«CC BY 4.0è®¸å¯è¯ï¼Œä¾¿äºè®¿é—®å’Œä½¿ç”¨ã€‚</li>
<li>mOSCARçš„å‘å¸ƒå¡«è¡¥äº†å¤šè¯­è¨€å¤šæ¨¡æ€æ•°æ®é›†é¢†åŸŸçš„ç©ºç™½ï¼Œä¿ƒè¿›äº†å…¨çƒå…¶ä»–è¯­è¨€çš„mLLMç ”ç©¶å‘å±•ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2406.08707">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-6647e5320b8dd98467975775d648ecb3.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-2eefdeab08719210bcbe76bc5d05bc68.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-0b20d104d37f634bac6c1a9af4ebfe6e.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-00aae31414b95a34930255e88fc19be6.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-3e50da50a636af0e129f81aeb6ea33d4.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-adf5cd4428b1b27e8052c84f816990f8.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-e037b51bff2221027547761f6b4adffe.jpg" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-05-31/Few-Shot/">https://kedreamix.github.io/Talk2Paper/Paper/2025-05-31/Few-Shot/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/Few-Shot/">
                                    <span class="chip bg-color">Few-Shot</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-05-31/I2I%20Translation/">
                    <div class="card-image">
                        
                        <img src="https://pica.zhimg.com/v2-0f7d5ba4831bfe386f88647faff46233.jpg" class="responsive-img" alt="I2I Translation">
                        
                        <span class="card-title">I2I Translation</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            I2I Translation æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-05-31  Adaptive Spatial Augmentation for Semi-supervised Semantic Segmentation
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-05-31
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/I2I-Translation/" class="post-category">
                                    I2I Translation
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/I2I-Translation/">
                        <span class="chip bg-color">I2I Translation</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-05-31/Agent/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-49be2282d3d40772916925bc569017cb.jpg" class="responsive-img" alt="Agent">
                        
                        <span class="card-title">Agent</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Agent æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-05-31  ML-Agent Reinforcing LLM Agents for Autonomous Machine Learning   Engineering
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-05-31
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Agent/" class="post-category">
                                    Agent
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Agent/">
                        <span class="chip bg-color">Agent</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">19778.5k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
