<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="TTS">
    <meta name="description" content="TTS æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-05-31  Few-Shot Speech Deepfake Detection Adaptation with Gaussian Processes">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>TTS | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://picx.zhimg.com/v2-cc771af2bdc4ffade361c5cfb5d7e578.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">TTS</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/TTS/">
                                <span class="chip bg-color">TTS</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/TTS/" class="post-category">
                                TTS
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-05-31
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-06-24
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    6.1k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    25 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-05-31-æ›´æ–°"><a href="#2025-05-31-æ›´æ–°" class="headerlink" title="2025-05-31 æ›´æ–°"></a>2025-05-31 æ›´æ–°</h1><h2 id="Few-Shot-Speech-Deepfake-Detection-Adaptation-with-Gaussian-Processes"><a href="#Few-Shot-Speech-Deepfake-Detection-Adaptation-with-Gaussian-Processes" class="headerlink" title="Few-Shot Speech Deepfake Detection Adaptation with Gaussian Processes"></a>Few-Shot Speech Deepfake Detection Adaptation with Gaussian Processes</h2><p><strong>Authors:Neta Glazer, David Chernin, Idan Achituve, Sharon Gannot, Ethan Fetaya</strong></p>
<p>Recent advancements in Text-to-Speech (TTS) models, particularly in voice cloning, have intensified the demand for adaptable and efficient deepfake detection methods. As TTS systems continue to evolve, detection models must be able to efficiently adapt to previously unseen generation models with minimal data. This paper introduces ADD-GP, a few-shot adaptive framework based on a Gaussian Process (GP) classifier for Audio Deepfake Detection (ADD). We show how the combination of a powerful deep embedding model with the Gaussian processes flexibility can achieve strong performance and adaptability. Additionally, we show this approach can also be used for personalized detection, with greater robustness to new TTS models and one-shot adaptability. To support our evaluation, a benchmark dataset is constructed for this task using new state-of-the-art voice cloning models. </p>
<blockquote>
<p>è¿‘æœŸæ–‡æœ¬è½¬è¯­éŸ³ï¼ˆTTSï¼‰æ¨¡å‹çš„è¿›æ­¥ï¼Œç‰¹åˆ«æ˜¯åœ¨è¯­éŸ³å…‹éš†æ–¹é¢ï¼ŒåŠ å‰§äº†å¯¹è‡ªé€‚åº”å’Œé«˜æ•ˆçš„æ·±åº¦ä¼ªé€ æ£€æµ‹æ–¹æ³•çš„éœ€æ±‚ã€‚éšç€TTSç³»ç»Ÿçš„ä¸æ–­å‘å±•ï¼Œæ£€æµ‹æ¨¡å‹å¿…é¡»èƒ½å¤Ÿä»¥æœ€å°çš„æ•°æ®é‡é«˜æ•ˆåœ°é€‚åº”ä»¥å‰æœªè§è¿‡çš„ç”Ÿæˆæ¨¡å‹ã€‚æœ¬æ–‡ä»‹ç»äº†ADD-GPï¼Œè¿™æ˜¯ä¸€ç§åŸºäºé«˜æ–¯è¿‡ç¨‹ï¼ˆGPï¼‰åˆ†ç±»å™¨çš„éŸ³é¢‘æ·±åº¦ä¼ªé€ æ£€æµ‹ï¼ˆADDï¼‰çš„å°‘é‡è‡ªé€‚åº”æ¡†æ¶ã€‚æˆ‘ä»¬å±•ç¤ºäº†å¼ºå¤§çš„æ·±åº¦åµŒå…¥æ¨¡å‹ä¸é«˜æ–¯è¿‡ç¨‹çš„çµæ´»æ€§å¦‚ä½•ç»“åˆï¼Œä»¥å®ç°å¼ºå¤§çš„æ€§èƒ½å’Œé€‚åº”æ€§ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜è¯æ˜è¯¥æ–¹æ³•ä¹Ÿå¯ç”¨äºä¸ªæ€§åŒ–æ£€æµ‹ï¼Œå¯¹æ–°TTSæ¨¡å‹å…·æœ‰æ›´å¼ºçš„é²æ£’æ€§ï¼Œå¹¶å…·å¤‡ä¸€æ¬¡é€‚åº”æ€§ã€‚ä¸ºäº†æ”¯æŒæˆ‘ä»¬çš„è¯„ä¼°ï¼Œæˆ‘ä»¬ä½¿ç”¨äº†æœ€æ–°çš„è¯­éŸ³å…‹éš†æ¨¡å‹æ„å»ºäº†ä¸€ä¸ªç”¨äºæ­¤ä»»åŠ¡çš„æ ‡å‡†æ•°æ®é›†ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.23619v1">PDF</a> </p>
<p><strong>æ€»ç»“</strong><br>éšç€æ–‡æœ¬è½¬è¯­éŸ³ï¼ˆTTSï¼‰æ¨¡å‹çš„è¿›æ­¥ï¼Œç‰¹åˆ«æ˜¯è¯­éŸ³å…‹éš†æŠ€æœ¯çš„å‘å±•ï¼Œå¯¹çµæ´»ä¸”é«˜æ•ˆçš„å£°éŸ³æ·±åº¦ä¼ªé€ æ£€æµ‹æ–¹æ³•çš„éœ€æ±‚æ„ˆå‘å¼ºçƒˆã€‚æœ¬æ–‡ä»‹ç»äº†ä¸€ä¸ªåŸºäºé«˜æ–¯è¿‡ç¨‹ï¼ˆGPï¼‰åˆ†ç±»å™¨çš„ADD-GPå°‘æ•°è‡ªé€‚åº”æ¡†æ¶ï¼Œç”¨äºéŸ³é¢‘æ·±åº¦ä¼ªé€ æ£€æµ‹ï¼ˆADDï¼‰ã€‚ç»“åˆå¼ºå¤§çš„æ·±åº¦åµŒå…¥æ¨¡å‹ä¸é«˜æ–¯è¿‡ç¨‹çš„çµæ´»æ€§ï¼Œè¯¥æ¡†æ¶å¯å®ç°å‡ºè‰²çš„æ€§èƒ½å’Œé€‚åº”æ€§ã€‚æ­¤å¤–ï¼Œè¯¥æ¡†æ¶è¿˜å¯ç”¨äºä¸ªæ€§åŒ–æ£€æµ‹ï¼Œå¯¹æ–°TTSæ¨¡å‹å…·æœ‰æ›´å¼ºçš„é²æ£’æ€§ï¼Œå¹¶å…·æœ‰ä¸€æ¬¡é€‚åº”æ€§ã€‚</p>
<p><strong>å…³é”®è§è§£</strong></p>
<ol>
<li>TTSæ¨¡å‹çš„æœ€æ–°è¿›å±•è¦æ±‚æ£€æµ‹æ¨¡å‹å…·æœ‰å¿«é€Ÿé€‚åº”æ–°ç”Ÿæˆæ¨¡å‹çš„èƒ½åŠ›ã€‚</li>
<li>ADD-GPæ¡†æ¶ç»“åˆäº†æ·±åº¦åµŒå…¥æ¨¡å‹ä¸é«˜æ–¯è¿‡ç¨‹åˆ†ç±»å™¨ï¼Œç”¨äºéŸ³é¢‘æ·±åº¦ä¼ªé€ æ£€æµ‹ã€‚</li>
<li>è¯¥æ¡†æ¶å¯å®ç°å¼ºå¤§çš„æ€§èƒ½å’Œé€‚åº”æ€§ï¼Œå°¤å…¶æ˜¯é’ˆå¯¹æ–°å‡ºç°çš„TTSæ¨¡å‹ã€‚</li>
<li>å¯ä»¥é€šè¿‡ä¸ªæ€§åŒ–æ£€æµ‹å¢å¼ºæ¡†æ¶çš„é²æ£’æ€§ã€‚</li>
<li>ä¸ºæ”¯æŒè¯„ä¼°ï¼Œä½¿ç”¨æœ€æ–°çš„è¯­éŸ³å…‹éš†æ¨¡å‹æ„å»ºäº†é’ˆå¯¹æ­¤ä»»åŠ¡çš„æ ‡å‡†æ•°æ®é›†ã€‚</li>
<li>è¯¥æ¡†æ¶å…·æœ‰ä¸€æ¬¡é€‚åº”æ€§ï¼Œå³èƒ½å¤Ÿä»…é€šè¿‡å°‘é‡æ•°æ®å¿«é€Ÿé€‚åº”æ–°çš„TTSæ¨¡å‹ã€‚</li>
<li>è¿™ç§è‡ªé€‚åº”èƒ½åŠ›å¯¹äºåº”å¯¹ä¸æ–­æ¼”å˜çš„TTSæŠ€æœ¯å…·æœ‰é‡è¦æ„ä¹‰ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.23619">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-9c5f0ee5a90d319251cbd329d021d84d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c888462649dbd9a9addbc91e785591d3.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-84d3b51910bf7d5a63c9a9661966703f.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="EmergentTTS-Eval-Evaluating-TTS-Models-on-Complex-Prosodic-Expressiveness-and-Linguistic-Challenges-Using-Model-as-a-Judge"><a href="#EmergentTTS-Eval-Evaluating-TTS-Models-on-Complex-Prosodic-Expressiveness-and-Linguistic-Challenges-Using-Model-as-a-Judge" class="headerlink" title="EmergentTTS-Eval: Evaluating TTS Models on Complex Prosodic,   Expressiveness, and Linguistic Challenges Using Model-as-a-Judge"></a>EmergentTTS-Eval: Evaluating TTS Models on Complex Prosodic,   Expressiveness, and Linguistic Challenges Using Model-as-a-Judge</h2><p><strong>Authors:Ruskin Raj Manku, Yuzhi Tang, Xingjian Shi, Mu Li, Alex Smola</strong></p>
<p>Text-to-Speech (TTS) benchmarks often fail to capture how well models handle nuanced and semantically complex text. Building on $\textit{EmergentTTS}$, we introduce $\textit{EmergentTTS-Eval}$, a comprehensive benchmark covering six challenging TTS scenarios: emotions, paralinguistics, foreign words, syntactic complexity, complex pronunciation (e.g. URLs, formulas), and questions. Crucially, our framework automates both test-case generation and evaluation, making the benchmark easily extensible. Starting from a small set of human-written seed prompts, we iteratively extend them using LLMs to target specific structural, phonetic and prosodic challenges, resulting in 1,645 diverse test cases. Moreover, we employ a model-as-a-judge approach, using a Large Audio Language Model (LALM) to assess the speech across multiple dimensions such as expressed emotion, prosodic, intonational, and pronunciation accuracy. We evaluate state-of-the-art open-source and proprietary TTS systems, such as 11Labs, Deepgram, and OpenAIâ€™s 4o-mini-TTS, on EmergentTTS-Eval, demonstrating its ability to reveal fine-grained performance differences. Results show that the model-as-a-judge approach offers robust TTS assessment and a high correlation with human preferences. We open source the evaluation $\href{<a target="_blank" rel="noopener" href="https://github.com/boson-ai/EmergentTTS-Eval-public%7D%7Bcode%7D$">https://github.com/boson-ai/EmergentTTS-Eval-public}{code}$</a> and the $\href{<a target="_blank" rel="noopener" href="https://huggingface.co/datasets/bosonai/EmergentTTS-Eval%7D%7Bdataset%7D$">https://huggingface.co/datasets/bosonai/EmergentTTS-Eval}{dataset}$</a>. </p>
<blockquote>
<p>æ–‡æœ¬è½¬è¯­éŸ³ï¼ˆTTSï¼‰åŸºå‡†æµ‹è¯•é€šå¸¸æ— æ³•æ•æ‰æ¨¡å‹å¤„ç†å¾®å¦™å’Œè¯­ä¹‰å¤æ‚æ–‡æœ¬çš„èƒ½åŠ›ã€‚åŸºäº$\textit{EmergentTTS}$ï¼Œæˆ‘ä»¬æ¨å‡ºäº†$\textit{EmergentTTS-Eval}$ï¼Œè¿™æ˜¯ä¸€ä¸ªæ¶µç›–å…­ç§å…·æœ‰æŒ‘æˆ˜æ€§TTSåœºæ™¯çš„å…¨é¢åŸºå‡†æµ‹è¯•ï¼šæƒ…æ„Ÿã€å‰¯è¯­è¨€ã€å¤–æ¥è¯ã€å¥æ³•å¤æ‚æ€§ã€å¤æ‚å‘éŸ³ï¼ˆä¾‹å¦‚ï¼šURLsã€å…¬å¼ï¼‰ä»¥åŠé—®é¢˜ã€‚æˆ‘ä»¬çš„æ¡†æ¶å¯ä»¥è‡ªåŠ¨è¿›è¡Œæµ‹è¯•ç”¨ä¾‹ç”Ÿæˆå’Œè¯„ä¼°ï¼Œä½¿å¾—åŸºå‡†æµ‹è¯•æ˜“äºæ‰©å±•ã€‚æˆ‘ä»¬ä»ä¸€ç»„äººç±»å†™å…¥çš„ç§å­æç¤ºå¼€å§‹ï¼Œé€šè¿‡è¿­ä»£ä½¿ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰æ¥é’ˆå¯¹ç‰¹å®šçš„ç»“æ„ã€è¯­éŸ³å’ŒéŸµå¾‹æŒ‘æˆ˜ï¼Œä»è€Œç”Ÿæˆäº†1645ä¸ªå¤šæ ·åŒ–çš„æµ‹è¯•ç”¨ä¾‹ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬é‡‡ç”¨æ¨¡å‹ä½œä¸ºæ³•å®˜çš„æ–¹æ³•ï¼Œä½¿ç”¨å¤§å‹éŸ³é¢‘è¯­è¨€æ¨¡å‹ï¼ˆLALMï¼‰æ¥è¯„ä¼°è¯­éŸ³çš„å¤šä¸ªç»´åº¦ï¼Œå¦‚è¡¨è¾¾çš„æƒ…æ„Ÿã€éŸµå¾‹ã€è¯­è°ƒä»¥åŠå‘éŸ³å‡†ç¡®æ€§ç­‰ã€‚æˆ‘ä»¬åœ¨EmergentTTS-Evalä¸Šè¯„ä¼°äº†å…ˆè¿›çš„å¼€æºå’Œä¸“æœ‰TTSç³»ç»Ÿï¼Œå¦‚11Labsã€Deepgramå’ŒOpenAIçš„4o-mini-TTSï¼Œå±•ç¤ºäº†å…¶æ­ç¤ºç»†å¾®æ€§èƒ½å·®å¼‚çš„èƒ½åŠ›ã€‚ç»“æœè¡¨æ˜ï¼Œæ¨¡å‹ä½œä¸ºæ³•å®˜çš„æ–¹æ³•ä¸ºTTSè¯„ä¼°æä¾›äº†ç¨³å¥æ€§ï¼Œä¸äººç±»åå¥½é«˜åº¦ç›¸å…³ã€‚æˆ‘ä»¬å…¬å¼€äº†è¯„ä¼°ä»£ç å’Œæ•°æ®é›†ï¼Œåˆ†åˆ«ä½äº$\href{<a target="_blank" rel="noopener" href="https://github.com/boson-ai/EmergentTTS-Eval-public%7D%7B%E6%AD%A4%E5%A4%84%7D$%E5%92%8C$/href%7Bhttps://huggingface.co/datasets/bosonai/EmergentTTS-Eval%7D%7B%E6%AD%A4%E5%A4%84%7D$%E3%80%82">https://github.com/boson-ai/EmergentTTS-Eval-public}{æ­¤å¤„}$å’Œ$\href{https://huggingface.co/datasets/bosonai/EmergentTTS-Eval}{æ­¤å¤„}$ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.23009v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æ–°å…´TTSè¯„æµ‹æ¡†æ¶ç ”ç©¶æ—¨åœ¨å…‹æœç°æœ‰TTSåŸºå‡†æµ‹è¯•æ— æ³•å‡†ç¡®è¯„ä¼°æ¨¡å‹å¤„ç†ç»†å¾®å¤æ‚æ–‡æœ¬çš„é—®é¢˜ã€‚è¯¥ç ”ç©¶å¼•å…¥äº†EmergentTTS-Evalè¯„æµ‹æ¡†æ¶ï¼Œæ¶µç›–æƒ…æ„Ÿã€å‰¯è¯­è¨€ã€å¤–æ¥è¯ã€å¥æ³•å¤æ‚æ€§ã€å¤æ‚å‘éŸ³ï¼ˆå¦‚ç½‘å€ã€å…¬å¼ï¼‰å’Œé—®é¢˜ç­‰å…­ä¸ªæŒ‘æˆ˜åœºæ™¯ã€‚è¯¥æ¡†æ¶å®ç°äº†æµ‹è¯•æ¡ˆä¾‹ç”Ÿæˆå’Œè¯„ä¼°çš„è‡ªåŠ¨åŒ–ï¼Œå¢å¼ºäº†å¯æ‰©å±•æ€§ã€‚é€šè¿‡ä½¿ç”¨å¤§å‹éŸ³é¢‘è¯­è¨€æ¨¡å‹è¯„ä¼°è¯­éŸ³çš„å„ç§ç»´åº¦ï¼ˆå¦‚è¡¨è¾¾æƒ…æ„Ÿã€è¯­è°ƒç­‰ï¼‰ï¼Œå…¶æ€§èƒ½åœ¨è¯„ä¼°é¡¶å°–å¼€æºå’Œä¸“æœ‰TTSç³»ç»Ÿæ—¶å¾—åˆ°äº†éªŒè¯ã€‚æ­¤ç ”ç©¶ä¸ºè¯„ä¼°TTSæ€§èƒ½æä¾›äº†æ–°çš„è§†è§’ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>EmergentTTS-Evalæ˜¯ä¸€ä¸ªå…¨é¢çš„TTSè¯„æµ‹æ¡†æ¶ï¼Œè§£å†³äº†ç°æœ‰åŸºå‡†æµ‹è¯•æ— æ³•å……åˆ†è¯„ä¼°æ¨¡å‹å¤„ç†å¤æ‚æ–‡æœ¬çš„é—®é¢˜ã€‚</li>
<li>è¯¥æ¡†æ¶æ¶µç›–äº†å…­ä¸ªæŒ‘æˆ˜æ€§çš„TTSåœºæ™¯ï¼ŒåŒ…æ‹¬æƒ…æ„Ÿã€å‰¯è¯­è¨€ç­‰ã€‚</li>
<li>é€šè¿‡è‡ªåŠ¨åŒ–æµ‹è¯•æ¡ˆä¾‹ç”Ÿæˆå’Œè¯„ä¼°ï¼Œæé«˜äº†åŸºå‡†æµ‹è¯•çš„æ•ˆç‡å’Œå¯æ‰©å±•æ€§ã€‚</li>
<li>åˆ©ç”¨å¤§å‹éŸ³é¢‘è¯­è¨€æ¨¡å‹ï¼ˆLALMï¼‰ä½œä¸ºè¯„å§”ï¼Œä»å¤šä¸ªç»´åº¦è¯„ä¼°è¯­éŸ³è´¨é‡ã€‚</li>
<li>åœ¨é¡¶å°–å¼€æºå’Œä¸“æœ‰TTSç³»ç»Ÿä¸Šçš„å®éªŒéªŒè¯äº†EmergentTTS-Evalçš„æœ‰æ•ˆæ€§ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.23009">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-a72312e0a309768fd73d1e93aa176ccd.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-2460c9f26012128f1ddc2998ace58c68.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c8c91686bae7c54e61d4fce56ef8e1d4.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="LLM-Synth4KWS-Scalable-Automatic-Generation-and-Synthesis-of-Confusable-Data-for-Custom-Keyword-Spotting"><a href="#LLM-Synth4KWS-Scalable-Automatic-Generation-and-Synthesis-of-Confusable-Data-for-Custom-Keyword-Spotting" class="headerlink" title="LLM-Synth4KWS: Scalable Automatic Generation and Synthesis of Confusable   Data for Custom Keyword Spotting"></a>LLM-Synth4KWS: Scalable Automatic Generation and Synthesis of Confusable   Data for Custom Keyword Spotting</h2><p><strong>Authors:Pai Zhu, Quan Wang, Dhruuv Agarwal, Kurt Partridge</strong></p>
<p>Custom keyword spotting (KWS) allows detecting user-defined spoken keywords from streaming audio. This is achieved by comparing the embeddings from voice enrollments and input audio. State-of-the-art custom KWS models are typically trained contrastively using utterances whose keywords are randomly sampled from training dataset. These KWS models often struggle with confusing keywords, such as â€œblueâ€ versus â€œglueâ€. This paper introduces an effective way to augment the training with confusable utterances where keywords are generated and grouped from large language models (LLMs), and speech signals are synthesized with diverse speaking styles from text-to-speech (TTS) engines. To better measure user experience on confusable KWS, we define a new northstar metric using the average area under DET curve from confusable groups (c-AUC). Featuring high scalability and zero labor cost, the proposed method improves AUC by 3.7% and c-AUC by 11.3% on the Speech Commands testing set. </p>
<blockquote>
<p>è‡ªå®šä¹‰å…³é”®è¯è¯†åˆ«ï¼ˆKWSï¼‰å…è®¸ä»æµå¼éŸ³é¢‘ä¸­æ£€æµ‹ç”¨æˆ·å®šä¹‰çš„è¯­éŸ³å…³é”®è¯ã€‚è¿™æ˜¯é€šè¿‡æ¯”è¾ƒè¯­éŸ³æ³¨å†Œå’Œè¾“å…¥éŸ³é¢‘çš„åµŒå…¥æ¥å®ç°çš„ã€‚ç›®å‰æœ€å…ˆè¿›çš„è‡ªå®šä¹‰KWSæ¨¡å‹é€šå¸¸ä½¿ç”¨éšæœºé‡‡æ ·è‡ªè®­ç»ƒæ•°æ®é›†çš„è¯­éŸ³æ¥è¿›è¡Œå¯¹æ¯”è®­ç»ƒã€‚è¿™äº›KWSæ¨¡å‹ç»å¸¸åœ¨ä¸æ˜“æ··æ·†å…³é”®è¯å¯¹æŠ—æ—¶é‡åˆ°å›°å¢ƒï¼Œä¾‹å¦‚â€œè“è‰²â€ä¸â€œèƒ¶æ°´â€ã€‚æœ¬æ–‡ä»‹ç»äº†ä¸€ç§é€šè¿‡ä½¿ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ç”Ÿæˆå¹¶ç»„åˆå…³é”®è¯ï¼Œå¹¶ç”¨æ–‡æœ¬åˆ°è¯­éŸ³ï¼ˆTTSï¼‰å¼•æ“åˆæˆå…·æœ‰ä¸åŒè¯´è¯é£æ ¼çš„è¯­éŸ³ä¿¡å·æ¥å¢å¼ºè®­ç»ƒçš„æœ‰æ•ˆæ–¹æ³•ã€‚ä¸ºäº†æ›´å¥½åœ°è¡¡é‡ç”¨æˆ·å¯¹æ˜“æ··æ·†KWSçš„ä½“éªŒï¼Œæˆ‘ä»¬ä½¿ç”¨æ¥è‡ªæ··æ·†ç»„çš„DETæ›²çº¿å¹³å‡é¢ç§¯ï¼ˆc-AUCï¼‰å®šä¹‰äº†ä¸€ä¸ªæ–°çš„åŒ—ææ˜ŸæŒ‡æ ‡ã€‚è¯¥æ–¹æ³•å…·æœ‰é«˜åº¦çš„å¯æ‰©å±•æ€§å’Œé›¶äººå·¥æˆæœ¬çš„ç‰¹ç‚¹ï¼Œåœ¨Speech Commandsæµ‹è¯•é›†ä¸Šæé«˜äº†AUC 3.7%å’Œc-AUC 11.3%ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.22995v1">PDF</a> </p>
<p><strong>æ‘˜è¦</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†é€šè¿‡åˆæˆè¯­éŸ³ä¿¡å·å’Œå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ç”Ÿæˆæ··æ·†å…³é”®è¯æ¥å¢å¼ºå¯¹æ¯”å¼è®­ç»ƒå…³é”®è¯è¯†åˆ«æ¨¡å‹çš„æ–¹æ³•ã€‚é€šè¿‡å¼•å…¥æ–°çš„è¯„ä¼°æŒ‡æ ‡c-AUCï¼Œè¯¥æ–¹æ³•æé«˜äº†æ¨¡å‹çš„æ€§èƒ½ï¼Œæé«˜äº†AUCå€¼3.7%ï¼ŒåŒæ—¶æ”¹å–„äº†æ¨¡å‹åœ¨æ··æ·†å…³é”®è¯ä¸Šçš„è¡¨ç°ï¼Œæå‡äº†c-AUCå€¼è¾¾11.3%ã€‚æ­¤æ–¹æ³•å…·æœ‰é«˜å¯æ‰©å±•æ€§å’Œé›¶äººå·¥æˆæœ¬çš„ä¼˜åŠ¿ã€‚</p>
<p><strong>å…³é”®è§è§£</strong></p>
<ol>
<li>ä»‹ç»äº†é€šè¿‡å¯¹æ¯”è¯­éŸ³åµŒå…¥è¿›è¡Œè‡ªå®šä¹‰å…³é”®è¯è¯†åˆ«ï¼ˆKWSï¼‰çš„æ–¹æ³•ã€‚</li>
<li>è®­ç»ƒå…ˆè¿›çš„KWSæ¨¡å‹æ—¶ï¼Œé€šå¸¸ä½¿ç”¨éšæœºé‡‡æ ·çš„å…³é”®è¯è®­ç»ƒé›†è¿›è¡Œå¯¹æ¯”è®­ç»ƒã€‚</li>
<li>ç°æœ‰æ¨¡å‹é¢ä¸´æ··æ·†å…³é”®è¯çš„æŒ‘æˆ˜ï¼Œå¦‚â€è“è‰²â€ä¸â€èƒ¶æ°´â€ã€‚</li>
<li>æå‡ºäº†ä¸€ç§é€šè¿‡å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ç”Ÿæˆå¹¶åˆ†ç»„å…³é”®è¯çš„åˆæˆè¯­éŸ³ä¿¡å·çš„è®­ç»ƒå¢å¼ºæ–¹æ³•ã€‚</li>
<li>ä½¿ç”¨æ–‡æœ¬åˆ°è¯­éŸ³ï¼ˆTTSï¼‰å¼•æ“åˆæˆä¸åŒè¯´è¯é£æ ¼çš„è¯­éŸ³ä¿¡å·ã€‚</li>
<li>ä¸ºäº†æ›´å¥½åœ°è¡¡é‡ç”¨æˆ·å¯¹æ··æ·†KWSçš„ä½“éªŒï¼Œå¼•å…¥äº†ä½¿ç”¨æ··æ·†ç»„å¹³å‡æ£€æµ‹æ›²çº¿ä¸‹çš„é¢ç§¯ï¼ˆc-AUCï¼‰ä½œä¸ºæ–°çš„è¯„ä¼°æŒ‡æ ‡ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.22995">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-48ae05648e3fe3dceb7e121236488093.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-cc771af2bdc4ffade361c5cfb5d7e578.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-2d6815e70782be97b700c8e029b6ade4.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-86edc6acb54381c3609c0f1b94f6bf67.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-7d710fdfce3494309b8f788a96526217.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-be30fc842692a37e4963254acac68256.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="BinauralFlow-A-Causal-and-Streamable-Approach-for-High-Quality-Binaural-Speech-Synthesis-with-Flow-Matching-Models"><a href="#BinauralFlow-A-Causal-and-Streamable-Approach-for-High-Quality-Binaural-Speech-Synthesis-with-Flow-Matching-Models" class="headerlink" title="BinauralFlow: A Causal and Streamable Approach for High-Quality Binaural   Speech Synthesis with Flow Matching Models"></a>BinauralFlow: A Causal and Streamable Approach for High-Quality Binaural   Speech Synthesis with Flow Matching Models</h2><p><strong>Authors:Susan Liang, Dejan Markovic, Israel D. Gebru, Steven Krenn, Todd Keebler, Jacob Sandakly, Frank Yu, Samuel Hassel, Chenliang Xu, Alexander Richard</strong></p>
<p>Binaural rendering aims to synthesize binaural audio that mimics natural hearing based on a mono audio and the locations of the speaker and listener. Although many methods have been proposed to solve this problem, they struggle with rendering quality and streamable inference. Synthesizing high-quality binaural audio that is indistinguishable from real-world recordings requires precise modeling of binaural cues, room reverb, and ambient sounds. Additionally, real-world applications demand streaming inference. To address these challenges, we propose a flow matching based streaming binaural speech synthesis framework called BinauralFlow. We consider binaural rendering to be a generation problem rather than a regression problem and design a conditional flow matching model to render high-quality audio. Moreover, we design a causal U-Net architecture that estimates the current audio frame solely based on past information to tailor generative models for streaming inference. Finally, we introduce a continuous inference pipeline incorporating streaming STFT&#x2F;ISTFT operations, a buffer bank, a midpoint solver, and an early skip schedule to improve rendering continuity and speed. Quantitative and qualitative evaluations demonstrate the superiority of our method over SOTA approaches. A perceptual study further reveals that our model is nearly indistinguishable from real-world recordings, with a $42%$ confusion rate. </p>
<blockquote>
<p>åŒè€³æ¸²æŸ“æ—¨åœ¨æ ¹æ®å•å£°é“éŸ³é¢‘å’Œè¯´è¯äººåŠå¬ä¼—çš„ä½ç½®åˆæˆæ¨¡ä»¿è‡ªç„¶å¬è§‰çš„åŒè€³éŸ³é¢‘ã€‚å°½ç®¡å·²ç»æå‡ºäº†è®¸å¤šæ–¹æ³•æ¥è§£å†³è¿™ä¸€é—®é¢˜ï¼Œä½†å®ƒä»¬åœ¨å¤„ç†æ¸²æŸ“è´¨é‡å’Œæµå¼æ¨æ–­æ–¹é¢é‡åˆ°äº†å›°éš¾ã€‚åˆæˆé«˜è´¨é‡çš„åŒè€³éŸ³é¢‘ï¼Œè¦æ±‚ä¸çœŸå®ä¸–ç•Œå½•éŸ³æ— æ³•åŒºåˆ†ï¼Œéœ€è¦å¯¹åŒè€³çº¿ç´¢ã€æˆ¿é—´å›éŸ³å’Œç¯å¢ƒå£°éŸ³è¿›è¡Œç²¾ç¡®å»ºæ¨¡ã€‚æ­¤å¤–ï¼Œå®é™…åº”ç”¨è¦æ±‚æµå¼æ¨ç†ã€‚ä¸ºäº†åº”å¯¹è¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åŸºäºæµåŒ¹é…çš„æµå¼åŒè€³è¯­éŸ³åˆæˆæ¡†æ¶ï¼Œç§°ä¸ºBinauralFlowã€‚æˆ‘ä»¬è®¤ä¸ºåŒè€³æ¸²æŸ“æ˜¯ä¸€ä¸ªç”Ÿæˆé—®é¢˜ï¼Œè€Œä¸æ˜¯ä¸€ä¸ªå›å½’é—®é¢˜ï¼Œå¹¶è®¾è®¡äº†ä¸€ä¸ªæ¡ä»¶æµåŒ¹é…æ¨¡å‹æ¥æ¸²æŸ“é«˜è´¨é‡éŸ³é¢‘ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è®¾è®¡äº†ä¸€ç§å› æœU-Netæ¶æ„ï¼Œè¯¥æ¶æ„ä»…æ ¹æ®è¿‡å»çš„ä¿¡æ¯æ¥ä¼°è®¡å½“å‰éŸ³é¢‘å¸§ï¼Œä»¥é’ˆå¯¹æµå¼æ¨æ–­å®šåˆ¶ç”Ÿæˆæ¨¡å‹ã€‚æœ€åï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ä¸ªè¿ç»­çš„æ¨ç†ç®¡é“ï¼Œç»“åˆäº†æµå¼STFT&#x2F;ISTFTæ“ä½œã€ç¼“å†²åŒºé“¶è¡Œã€ä¸­ç‚¹è§£ç®—å™¨å’Œæ—©æœŸè·³è¿‡è°ƒåº¦ï¼Œä»¥æé«˜æ¸²æŸ“çš„è¿ç»­æ€§å’Œé€Ÿåº¦ã€‚å®šé‡å’Œå®šæ€§è¯„ä¼°è¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•ä¼˜äºæœ€æ–°æ–¹æ³•ã€‚æ„ŸçŸ¥ç ”ç©¶è¿›ä¸€æ­¥è¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ¨¡å‹ä¸çœŸå®ä¸–ç•Œå½•éŸ³å‡ ä¹æ— æ³•åŒºåˆ†ï¼Œæ··æ·†ç‡ä¸º42%ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.22865v1">PDF</a> ICML 2025, 18 pages</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†åŸºäºæµçš„åŒ¹é…æµæŠ€æœ¯çš„åŒè€³éŸ³é¢‘åˆæˆæ¡†æ¶BinauralFlowã€‚è¯¥æ–¹æ³•å°†åŒè€³æ¸²æŸ“è§†ä¸ºç”Ÿæˆé—®é¢˜è€Œéå›å½’é—®é¢˜ï¼Œé€šè¿‡è®¾è®¡æ¡ä»¶æµåŒ¹é…æ¨¡å‹æ¥åˆæˆé«˜è´¨é‡éŸ³é¢‘ã€‚åŒæ—¶ï¼Œé‡‡ç”¨å› æœU-Netæ¶æ„å®ç°æµå¼æ¨ç†ï¼Œå¹¶å¼•å…¥è¿ç»­æ¨ç†ç®¡é“æé«˜æ¸²æŸ“çš„è¿ç»­æ€§å’Œé€Ÿåº¦ã€‚å®éªŒè¯æ˜ï¼Œè¯¥æ–¹æ³•åœ¨éŸ³è´¨å’Œæµå¼æ¨ç†æ–¹é¢å‡ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œä¸çœŸå®å½•éŸ³çš„æ··æ·†ç‡ä»…ä¸º42%ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>BinauralFlowæ˜¯ä¸€ä¸ªåŸºäºæµçš„åŒ¹é…æµæŠ€æœ¯çš„åŒè€³éŸ³é¢‘åˆæˆæ¡†æ¶ï¼Œæ—¨åœ¨åˆæˆé«˜è´¨é‡çš„åŒè€³éŸ³é¢‘ã€‚</li>
<li>è¯¥æ–¹æ³•å°†åŒè€³æ¸²æŸ“è§†ä¸ºç”Ÿæˆé—®é¢˜ï¼Œé€šè¿‡è®¾è®¡æ¡ä»¶æµåŒ¹é…æ¨¡å‹æ¥åˆæˆé«˜è´¨é‡éŸ³é¢‘ã€‚</li>
<li>é‡‡ç”¨äº†å› æœU-Netæ¶æ„æ¥å®ç°æµå¼æ¨ç†ï¼Œé€‚åº”å®é™…åº”ç”¨çš„éœ€æ±‚ã€‚</li>
<li>å¼•å…¥äº†è¿ç»­æ¨ç†ç®¡é“ï¼ŒåŒ…æ‹¬æµå¼STFT&#x2F;ISTFTæ“ä½œã€ç¼“å†²åŒºé“¶è¡Œã€ä¸­ç‚¹è§£ç®—å™¨å’Œæ—©æœŸè·³è¿‡è°ƒåº¦ï¼Œä»¥æé«˜æ¸²æŸ“çš„è¿ç»­æ€§å’Œé€Ÿåº¦ã€‚</li>
<li>å®šé‡å’Œå®šæ€§è¯„ä¼°è¡¨æ˜ï¼ŒBinauralFlowåœ¨éŸ³è´¨å’Œæµå¼æ¨ç†æ–¹é¢å‡ä¼˜äºç°æœ‰æ–¹æ³•ã€‚</li>
<li>æ„ŸçŸ¥ç ”ç©¶è¡¨æ˜ï¼Œè¯¥æ¨¡å‹çš„éŸ³é¢‘ä¸çœŸå®å½•éŸ³çš„æ··æ·†ç‡ä»…ä¸º42%ï¼Œéš¾ä»¥åŒºåˆ†ã€‚</li>
<li>BinauralFlowå¯¹äºåŒè€³éŸ³é¢‘åˆæˆé¢†åŸŸçš„è¿›æ­¥å…·æœ‰é‡è¦æ„ä¹‰ï¼Œæœ‰æœ›åœ¨è™šæ‹Ÿç°å®ã€å¢å¼ºç°å®ç­‰é¢†åŸŸå¾—åˆ°å¹¿æ³›åº”ç”¨ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.22865">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-074cb3d13270b1e5e6900782debac0dd.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-5be1b000686f050cf5e412ead331bb8b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-246429498d2f202c576c7707358dc6d0.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-8581dda8e2570b8a076e7b97c1517f29.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="Nexus-An-Omni-Perceptive-And-Interactive-Model-for-Language-Audio-And-Vision"><a href="#Nexus-An-Omni-Perceptive-And-Interactive-Model-for-Language-Audio-And-Vision" class="headerlink" title="Nexus: An Omni-Perceptive And -Interactive Model for Language, Audio,   And Vision"></a>Nexus: An Omni-Perceptive And -Interactive Model for Language, Audio,   And Vision</h2><p><strong>Authors:Che Liu, Yingji Zhang, Dong Zhang, Weijie Zhang, Chenggong Gong, Haohan Li, Yu Lu, Shilin Zhou, Yue Lu, Ziliang Gan, Ziao Wang, Junwei Liao, Haipang Wu, Ji Liu, AndrÃ© Freitas, Qifan Wang, Zenglin Xu, Rongjuncheng Zhang, Yong Dai</strong></p>
<p>This work proposes an industry-level omni-modal large language model (LLM) pipeline that integrates auditory, visual, and linguistic modalities to overcome challenges such as limited tri-modal datasets, high computational costs, and complex feature alignments. Our pipeline consists of three main components: First, a modular framework enabling flexible configuration of various encoder-LLM-decoder architectures. Second, a lightweight training strategy that pre-trains audio-language alignment on the state-of-the-art vision-language model Qwen2.5-VL, thus avoiding the costly pre-training of vision-specific modalities. Third, an audio synthesis pipeline that generates high-quality audio-text data from diverse real-world scenarios, supporting applications such as Automatic Speech Recognition and Speech-to-Speech chat. To this end, we introduce an industry-level omni-modal LLM, Nexus. Extensive experiments validate the efficacy of our pipeline, yielding the following key findings:(1) In the visual understanding task, Nexus exhibits superior performance compared with its backbone model - Qwen2.5-VL-7B, validating the efficiency of our training strategy. (2) Within the English Spoken Question-Answering task, the model achieves better accuracy than the same-period competitor (i.e, MiniCPM-o2.6-7B) in the LLaMA Q. benchmark. (3) In our real-world ASR testset, Nexus achieves outstanding performance, indicating its robustness in real scenarios. (4) In the Speech-to-Text Translation task, our model outperforms Qwen2-Audio-Instruct-7B. (5) In the Text-to-Speech task, based on pretrained vocoder (e.g., Fishspeech1.4 or CosyVoice2.0), Nexus is comparable to its backbone vocoder on Seed-TTS benchmark. (6) An in-depth analysis of tri-modal alignment reveals that incorporating the audio modality enhances representational alignment between vision and language. </p>
<blockquote>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ç§è¡Œä¸šçº§çš„è·¨æ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ç®¡é“ï¼Œè¯¥ç®¡é“èåˆäº†å¬è§‰ã€è§†è§‰å’Œè¯­è¨€æ¨¡å¼ï¼Œä»¥å…‹æœå¦‚æœ‰é™çš„ä¸‰æ¨¡æ€æ•°æ®é›†ã€é«˜è®¡ç®—æˆæœ¬å’Œå¤æ‚çš„ç‰¹å¾å¯¹é½ç­‰æŒ‘æˆ˜ã€‚æˆ‘ä»¬çš„ç®¡é“ä¸»è¦ç”±ä¸‰ä¸ªéƒ¨åˆ†ç»„æˆï¼šé¦–å…ˆï¼Œä¸€ä¸ªæ¨¡å—åŒ–æ¡†æ¶ï¼Œèƒ½å¤Ÿçµæ´»é…ç½®å„ç§ç¼–ç å™¨-LLM-è§£ç å™¨æ¶æ„ã€‚å…¶æ¬¡ï¼Œä¸€ç§è½»é‡çº§çš„è®­ç»ƒç­–ç•¥ï¼Œé€šè¿‡åœ¨æœ€å…ˆè¿›çš„è§†è§‰è¯­è¨€æ¨¡å‹Qwen2.5-VLä¸Šè¿›è¡ŒéŸ³é¢‘è¯­è¨€å¯¹é½çš„é¢„è®­ç»ƒï¼Œä»è€Œé¿å…äº†é’ˆå¯¹ç‰¹å®šè§†è§‰æ¨¡å¼çš„æ˜‚è´µé¢„è®­ç»ƒã€‚æœ€åï¼Œä¸€ä¸ªéŸ³é¢‘åˆæˆç®¡é“ï¼Œç”¨äºä»å„ç§çœŸå®åœºæ™¯ç”Ÿæˆé«˜è´¨é‡éŸ³é¢‘æ–‡æœ¬æ•°æ®ï¼Œæ”¯æŒå¦‚è‡ªåŠ¨è¯­éŸ³è¯†åˆ«å’Œè¯­éŸ³åˆ°è¯­éŸ³èŠå¤©ç­‰åº”ç”¨ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§è¡Œä¸šçº§çš„è·¨æ¨¡æ€LLMï¼ŒNexusã€‚å¤§é‡å®éªŒéªŒè¯äº†æˆ‘ä»¬çš„ç®¡é“çš„æœ‰æ•ˆæ€§ï¼Œå¾—å‡ºä»¥ä¸‹å…³é”®å‘ç°ï¼šï¼ˆ1ï¼‰åœ¨è§†è§‰ç†è§£ä»»åŠ¡ä¸­ï¼ŒNexusç›¸è¾ƒäºå…¶éª¨å¹²æ¨¡å‹Qwen2.5-VL-7Bè¡¨ç°å‡ºå“è¶Šçš„æ€§èƒ½ï¼ŒéªŒè¯äº†æˆ‘ä»¬çš„è®­ç»ƒç­–ç•¥çš„æœ‰æ•ˆæ€§ã€‚ï¼ˆ2ï¼‰åœ¨è‹±è¯­å£è¯­é—®ç­”ä»»åŠ¡ä¸­ï¼Œè¯¥æ¨¡å‹åœ¨LLaMA Q. benchmarkä¸Šè¾¾åˆ°äº†æ¯”åŒæœŸç«äº‰å¯¹æ‰‹ï¼ˆå³MiniCPM-o2.6-7Bï¼‰æ›´é«˜çš„å‡†ç¡®æ€§ã€‚ï¼ˆ3ï¼‰åœ¨æˆ‘ä»¬çš„çœŸå®ä¸–ç•ŒASRæµ‹è¯•é›†ä¸Šï¼ŒNexusè¡¨ç°å‡ºå“è¶Šçš„æ€§èƒ½ï¼Œè¡¨æ˜å…¶åœ¨çœŸå®åœºæ™¯ä¸­çš„ç¨³å¥æ€§ã€‚ï¼ˆ4ï¼‰åœ¨è¯­éŸ³åˆ°æ–‡æœ¬ç¿»è¯‘ä»»åŠ¡ä¸­ï¼Œæˆ‘ä»¬çš„æ¨¡å‹ä¼˜äºQwen2-Audio-Instruct-7Bã€‚ï¼ˆ5ï¼‰åœ¨æ–‡æœ¬åˆ°è¯­éŸ³ä»»åŠ¡ä¸­ï¼ŒåŸºäºé¢„è®­ç»ƒçš„vocoderï¼ˆä¾‹å¦‚Fishspeech1.4æˆ–CosyVoice2.0ï¼‰ï¼ŒNexusåœ¨Seed-TTS benchmarkä¸Šçš„è¡¨ç°ä¸å…¶éª¨å¹²vocoderç›¸å½“ã€‚ï¼ˆ6ï¼‰å¯¹ä¸‰æ¨¡æ€å¯¹é½çš„æ·±å…¥åˆ†æè¡¨æ˜ï¼Œèå…¥éŸ³é¢‘æ¨¡å¼å¢å¼ºäº†è§†è§‰å’Œè¯­è¨€ä¹‹é—´çš„ä»£è¡¨æ€§å¯¹é½ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2503.01879v3">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ç§è·¨è¡Œä¸šçš„å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ç®¡é“ï¼Œè¯¥ç®¡é“èåˆäº†å¬è§‰ã€è§†è§‰å’Œè¯­è¨€å­¦ä¸‰å¤§æ¨¡æ€ï¼Œä»¥åº”å¯¹å¦‚æœ‰é™çš„ä¸‰æ¨¡æ€æ•°æ®é›†ã€é«˜è®¡ç®—æˆæœ¬å’Œå¤æ‚ç‰¹å¾å¯¹é½ç­‰æŒ‘æˆ˜ã€‚è¯¥ç®¡é“åŒ…æ‹¬ä¸‰ä¸ªä¸»è¦ç»„ä»¶ï¼šä¸€ä¸ªæ”¯æŒå„ç§ç¼–ç å™¨-LLM-è§£ç å™¨æ¶æ„çµæ´»é…ç½®çš„æ¨¡å—åŒ–æ¡†æ¶ï¼›ä¸€ç§åŸºäºå‰æ²¿è§†è§‰è¯­è¨€æ¨¡å‹Qwen2.5-VLçš„è½»é‡çº§è®­ç»ƒç­–ç•¥ï¼Œé¿å…äº†æ˜‚è´µçš„è§†è§‰ç‰¹å®šæ¨¡æ€é¢„è®­ç»ƒï¼›ä»¥åŠä¸€ä¸ªä»å„ç§ç°å®åœºæ™¯ç”Ÿæˆé«˜è´¨é‡éŸ³é¢‘æ–‡æœ¬æ•°æ®çš„å£°éŸ³åˆæˆç®¡é“ã€‚å¼•è¿›çš„äº§ä¸šçº§å¤šæ¨¡æ€LLM Nexusç»è¿‡å¹¿æ³›å®éªŒéªŒè¯ï¼Œåœ¨å¤šé¡¹ä»»åŠ¡ä¸­è¡¨ç°å‡ºå“è¶Šæ€§èƒ½ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æå‡ºäº†ä¸€ä¸ªå¤šæ¨¡æ€çš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ç®¡é“ï¼Œé›†æˆå¬è§‰ã€è§†è§‰å’Œè¯­è¨€å­¦ä¸‰å¤§æ¨¡æ€ã€‚</li>
<li>ç®¡é“åŒ…å«æ¨¡å—åŒ–æ¡†æ¶ã€è½»é‡çº§è®­ç»ƒç­–ç•¥å’ŒéŸ³é¢‘åˆæˆç®¡é“ä¸‰ä¸ªä¸»è¦ç»„ä»¶ã€‚</li>
<li>Nexusæ¨¡å‹åœ¨è§†è§‰ç†è§£ä»»åŠ¡ä¸­è¡¨ç°å‡ºå“è¶Šæ€§èƒ½ï¼Œç›¸è¾ƒäºå…¶åŸºç¡€æ¨¡å‹Qwen2.5-VL-7Bæœ‰æ˜¾è‘—æå‡ã€‚</li>
<li>åœ¨è‹±è¯­å£è¯­é—®ç­”ä»»åŠ¡ä¸­ï¼ŒNexusæ¨¡å‹è¾¾åˆ°åŒæœŸç«å“ä¹‹ä¸Šçš„å‡†ç¡®æ€§ã€‚</li>
<li>åœ¨å®é™…åœºæ™¯çš„è‡ªåŠ¨è¯­éŸ³è¯†åˆ«ï¼ˆASRï¼‰æµ‹è¯•é›†ä¸­ï¼ŒNexusè¡¨ç°å‡ºå‡ºè‰²æ€§èƒ½ï¼Œä½“ç°äº†å…¶åœ¨çœŸå®åœºæ™¯ä¸­çš„ç¨³å¥æ€§ã€‚</li>
<li>åœ¨è¯­éŸ³åˆ°æ–‡æœ¬ç¿»è¯‘ä»»åŠ¡ä¸­ï¼ŒNexusæ¨¡å‹è¶…è¶Šäº†Qwen2-Audio-Instruct-7Bã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2503.01879">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-e930c62cce7fe631c175d10d960d53d7.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-e47567a66fd0c62723052f4b05ead6ef.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-bb98e337962b4c98b584b1d2718b13e7.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d20fe4d48d94062be0b57cdbfcf57f5e.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="Visatronic-A-Multimodal-Decoder-Only-Model-for-Speech-Synthesis"><a href="#Visatronic-A-Multimodal-Decoder-Only-Model-for-Speech-Synthesis" class="headerlink" title="Visatronic: A Multimodal Decoder-Only Model for Speech Synthesis"></a>Visatronic: A Multimodal Decoder-Only Model for Speech Synthesis</h2><p><strong>Authors:Akshita Gupta, Tatiana Likhomanenko, Karren Dai Yang, Richard He Bai, Zakaria Aldeneh, Navdeep Jaitly</strong></p>
<p>The rapid progress of foundation models and large language models (LLMs) has fueled significantly improvement in the capabilities of machine learning systems that benefit from mutlimodal input data. However, existing multimodal models are predominantly built on top of pre-trained LLMs, which can limit accurate modeling of temporal dependencies across other modalities and thus limit the modelâ€™s ability to jointly process and leverage multimodal inputs. To specifically investigate the alignment of text, video, and speech modalities in LLM-style (decoder-only) models, we consider a simplified multimodal generation task, Video-Text to Speech (VTTS): speech generation conditioned on both its corresponding text and video of talking people. The ultimate goal is to generate speech that not only follows the text but also aligns temporally with the video and is consistent with the facial expressions. In this paper, we first introduce Visatronic, a unified multimodal decoder-only transformer model that adopts an LLM-style architecture to embed visual, textual, and speech inputs into a shared subspace, treating all modalities as temporally aligned token streams. Next, we carefully explore different token mixing strategies to understand the best way to propagate information from the steps where video and text conditioning is input to the steps where the audio is generated. We extensively evaluate Visatronic on the challenging VoxCeleb2 dataset and demonstrate zero-shot generalization to LRS3, where Visatronic, trained on VoxCeleb2, achieves a 4.5% WER, outperforming prior SOTA methods trained only on LRS3, which report a 21.4% WER. Additionally, we propose a new objective metric, TimeSync, specifically designed to measure phoneme-level temporal alignment between generated and reference speech, further ensuring synchronization quality. Demo: <a target="_blank" rel="noopener" href="https://apple.github.io/visatronic-demo/">https://apple.github.io/visatronic-demo/</a> </p>
<blockquote>
<p>éšç€åŸºç¡€æ¨¡å‹å’Œå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„å¿«é€Ÿå‘å±•ï¼Œå—ç›Šäºå¤šæ¨¡æ€è¾“å…¥æ•°æ®çš„æœºå™¨å­¦ä¹ ç³»ç»Ÿçš„èƒ½åŠ›å¾—åˆ°äº†æ˜¾è‘—æå‡ã€‚ç„¶è€Œï¼Œç°æœ‰çš„å¤šæ¨¡æ€æ¨¡å‹ä¸»è¦æ˜¯å»ºç«‹åœ¨é¢„è®­ç»ƒLLMä¹‹ä¸Šï¼Œè¿™å¯èƒ½ä¼šé™åˆ¶è·¨å…¶ä»–æ¨¡æ€çš„æ—¶é—´ä¾èµ–æ€§çš„å‡†ç¡®å»ºæ¨¡ï¼Œä»è€Œé™åˆ¶æ¨¡å‹è”åˆå¤„ç†å¹¶åˆ©ç”¨å¤šæ¨¡æ€è¾“å…¥çš„èƒ½åŠ›ã€‚ä¸ºäº†ä¸“é—¨ç ”ç©¶LLMé£æ ¼ï¼ˆä»…è§£ç å™¨ï¼‰æ¨¡å‹ä¸­æ–‡å­—ã€è§†é¢‘å’Œè¯­éŸ³æ¨¡æ€çš„å¯¹é½é—®é¢˜ï¼Œæˆ‘ä»¬è€ƒè™‘äº†ä¸€ä¸ªç®€åŒ–çš„å¤šæ¨¡æ€ç”Ÿæˆä»»åŠ¡ï¼Œå³è§†é¢‘æ–‡æœ¬è½¬è¯­éŸ³ï¼ˆVTTSï¼‰ï¼šè¯­éŸ³ç”Ÿæˆæ—¢å–å†³äºç›¸åº”çš„æ–‡æœ¬ï¼Œåˆå–å†³äºäººä»¬è®²è¯çš„è§†é¢‘ã€‚æœ€ç»ˆç›®æ ‡æ˜¯ç”Ÿæˆä¸ä»…éµå¾ªæ–‡æœ¬è€Œä¸”ä¸è§†é¢‘åœ¨æ—¶é—´ä¸Šæœ‰å¯¹é½çš„è¯­éŸ³ï¼Œå¹¶ä¸é¢éƒ¨è¡¨æƒ…ä¿æŒä¸€è‡´ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬é¦–å…ˆä»‹ç»äº†Visatronicï¼Œè¿™æ˜¯ä¸€ä¸ªç»Ÿä¸€çš„å¤šæ¨¡æ€ä»…è§£ç å™¨transformeræ¨¡å‹ï¼Œå®ƒé‡‡ç”¨LLMé£æ ¼æ¶æ„å°†è§†è§‰ã€æ–‡æœ¬å’Œè¯­éŸ³è¾“å…¥åµŒå…¥åˆ°å…±äº«å­ç©ºé—´ä¸­ï¼Œå°†æ‰€æœ‰æ¨¡æ€è§†ä¸ºæ—¶é—´å¯¹é½çš„ä»¤ç‰Œæµã€‚æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬ä»”ç»†æ¢ç´¢äº†ä¸åŒçš„ä»¤ç‰Œæ··åˆç­–ç•¥ï¼Œä»¥äº†è§£ä»è§†é¢‘å’Œæ–‡æœ¬è°ƒèŠ‚æ­¥éª¤å‘ç”ŸæˆéŸ³é¢‘æ­¥éª¤ä¼ æ’­ä¿¡æ¯çš„æœ€ä½³æ–¹å¼ã€‚æˆ‘ä»¬åœ¨å…·æœ‰æŒ‘æˆ˜æ€§çš„VoxCeleb2æ•°æ®é›†ä¸Šå¯¹Visatronicè¿›è¡Œäº†å¹¿æ³›è¯„ä¼°ï¼Œå¹¶å±•ç¤ºäº†é›¶æ ·æœ¬æ³›åŒ–åˆ°LRS3çš„èƒ½åŠ›ã€‚åœ¨VoxCeleb2ä¸Šè®­ç»ƒçš„Visatronicåœ¨LRS3ä¸Šå®ç°äº†4.5%çš„WERï¼ˆè¯é”™è¯¯ç‡ï¼‰ï¼Œä¼˜äºä»…é’ˆå¯¹LRS3è¿›è¡Œè®­ç»ƒçš„å…ˆå‰æœ€ä½³æ–¹æ³•ï¼ˆæŠ¥å‘Šäº†21.4%çš„WERï¼‰ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜æå‡ºäº†ä¸€ç§æ–°çš„å®¢è§‚æŒ‡æ ‡TimeSyncï¼Œä¸“é—¨ç”¨äºæµ‹é‡ç”Ÿæˆè¯­éŸ³å’Œå‚è€ƒè¯­éŸ³ä¹‹é—´çš„éŸ³ç´ çº§æ—¶é—´å¯¹é½ï¼Œè¿›ä¸€æ­¥ç¡®ä¿åŒæ­¥è´¨é‡ã€‚æ¼”ç¤ºåœ°å€ï¼š<a target="_blank" rel="noopener" href="https://apple.github.io/visatronic-demo/">https://apple.github.io/visatronic-demo/</a>ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2411.17690v2">PDF</a> </p>
<p><strong>Summary</strong><br>     éšç€åŸºç¡€æ¨¡å‹å’Œå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„å¿«é€Ÿå‘å±•ï¼Œå¤šæ¨¡æ€è¾“å…¥æ•°æ®å¯¹æœºå™¨å­¦ä¹ ç³»ç»Ÿçš„èƒ½åŠ›æå‡æ˜¾è‘—ã€‚ç„¶è€Œï¼Œç°æœ‰çš„å¤šæ¨¡æ€æ¨¡å‹ä¸»è¦ä¾èµ–äºé¢„è®­ç»ƒLLMï¼Œé™åˆ¶äº†è·¨å…¶ä»–æ¨¡æ€çš„æ—¶é—´ä¾èµ–æ€§çš„å‡†ç¡®å»ºæ¨¡ä»¥åŠå¤šæ¨¡æ€è¾“å…¥çš„è”åˆå¤„ç†ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬ç ”ç©¶æ–‡æœ¬ã€è§†é¢‘å’Œè¯­éŸ³æ¨¡æ€çš„å¯¹é½é—®é¢˜ï¼Œåœ¨LLMé£æ ¼ï¼ˆä»…è§£ç å™¨ï¼‰æ¨¡å‹ä¸­è€ƒè™‘ç®€åŒ–çš„å¤šæ¨¡æ€ç”Ÿæˆä»»åŠ¡â€”â€”è§†é¢‘æ–‡æœ¬è½¬è¯­éŸ³ï¼ˆVTTSï¼‰ã€‚ç›®æ ‡æ˜¯ç”Ÿæˆä¸ä»…éµå¾ªæ–‡æœ¬è¿˜ä¸æ—¶é—´è§†é¢‘å¯¹é½ä¸”ç¬¦åˆé¢éƒ¨è¡¨æƒ…çš„è¯­éŸ³ã€‚æœ¬æ–‡ä»‹ç»Visatronicæ¨¡å‹ï¼Œé‡‡ç”¨LLMé£æ ¼æ¶æ„åµŒå…¥è§†è§‰ã€æ–‡æœ¬å’Œè¯­éŸ³è¾“å…¥åˆ°å…±äº«å­ç©ºé—´ï¼Œå°†æ‰€æœ‰æ¨¡æ€è§†ä¸ºæ—¶é—´å¯¹é½çš„ä»¤ç‰Œæµã€‚é€šè¿‡æ¢ç´¢ä¸åŒçš„ä»¤ç‰Œæ··åˆç­–ç•¥ï¼Œæˆ‘ä»¬åœ¨VoxCeleb2æ•°æ®é›†ä¸Šè¯„ä¼°Visatronicï¼Œå¹¶å±•ç¤ºé›¶æ ·æœ¬æ³›åŒ–è‡³LRS3æ•°æ®é›†çš„èƒ½åŠ›ã€‚Visatronicåœ¨VoxCeleb2ä¸Šè®­ç»ƒçš„æ¨¡å‹è¾¾åˆ°4.5%çš„WERï¼Œä¼˜äºä»…åœ¨LRS3ä¸Šè®­ç»ƒçš„å…ˆå‰æœ€ä½³æ–¹æ³•ï¼ˆæŠ¥å‘Šä¸º21.4%çš„WERï¼‰ã€‚æˆ‘ä»¬è¿˜æå‡ºæ–°çš„å®¢è§‚æŒ‡æ ‡TimeSyncï¼Œä¸“é—¨ç”¨äºæµ‹é‡ç”Ÿæˆè¯­éŸ³å’Œå‚è€ƒè¯­éŸ³ä¹‹é—´çš„éŸ³ç´ çº§æ—¶é—´å¯¹é½ï¼Œä»¥ç¡®ä¿åŒæ­¥è´¨é‡ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤šæ¨¡æ€æ¨¡å‹çš„å¿«é€Ÿå‘å±•å—ç›ŠäºåŸºç¡€æ¨¡å‹å’Œå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„è¿›æ­¥ã€‚</li>
<li>å½“å‰å¤šæ¨¡æ€æ¨¡å‹ä¸»è¦åŸºäºé¢„è®­ç»ƒLLMï¼Œå­˜åœ¨å¯¹è·¨æ¨¡æ€æ—¶é—´ä¾èµ–æ€§å»ºæ¨¡çš„é™åˆ¶ã€‚</li>
<li>ç ”ç©¶èšç„¦äºæ–‡æœ¬ã€è§†é¢‘å’Œè¯­éŸ³æ¨¡æ€çš„å¯¹é½é—®é¢˜ï¼Œå¼•å…¥è§†é¢‘æ–‡æœ¬è½¬è¯­éŸ³ï¼ˆVTTSï¼‰ä»»åŠ¡ä½œä¸ºç ”ç©¶ç„¦ç‚¹ã€‚</li>
<li>Visatronicæ¨¡å‹é‡‡ç”¨LLMé£æ ¼æ¶æ„å¤„ç†å¤šæ¨¡æ€è¾“å…¥ï¼Œå®ç°è§†è§‰ã€æ–‡æœ¬å’Œè¯­éŸ³çš„åµŒå…¥ã€‚</li>
<li>é€šè¿‡ä¸åŒçš„ä»¤ç‰Œæ··åˆç­–ç•¥æ¢ç´¢ï¼Œä¼˜åŒ–äº†ä¿¡æ¯ä»è§†é¢‘å’Œæ–‡æœ¬è¾“å…¥æ­¥éª¤åˆ°éŸ³é¢‘ç”Ÿæˆæ­¥éª¤çš„ä¼ æ’­ã€‚</li>
<li>åœ¨VoxCeleb2æ•°æ®é›†ä¸Šçš„è¯„ä¼°æ˜¾ç¤ºVisatronicæ¨¡å‹æ€§èƒ½ä¼˜è¶Šï¼Œå¹¶å®ç°äº†é›¶æ ·æœ¬æ³›åŒ–è‡³LRS3æ•°æ®é›†ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2411.17690">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-45a6c6dfa6b81fd005b779083e2a519a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-fbe22e9665ec8b0309dfaa8a708b8550.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-02c056bd02f973ea4e3070664b7e8576.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-7a90e2243467d0f786c7463ce9e7a5d3.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-acef3515d5a164a7d5b20ebe94e1f514.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e4f4fb89cfe947b46d5aa0b772b4f3ea.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-05-31/TTS/">https://kedreamix.github.io/Talk2Paper/Paper/2025-05-31/TTS/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/TTS/">
                                    <span class="chip bg-color">TTS</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-05-31/Interactive/">
                    <div class="card-image">
                        
                        <img src="https://pica.zhimg.com/v2-19ffc29965317a33915b16d94846495e.jpg" class="responsive-img" alt="Interactive">
                        
                        <span class="card-title">Interactive</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Interactive æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-05-31  MCTSr-Zero Self-Reflective Psychological Counseling Dialogues   Generation via Principles and Adaptive Exploration
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-05-31
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Interactive/" class="post-category">
                                    Interactive
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Interactive/">
                        <span class="chip bg-color">Interactive</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-05-31/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-fa300c0ed08360fc9ae9a8557c55db84.jpg" class="responsive-img" alt="åŒ»å­¦å›¾åƒ">
                        
                        <span class="card-title">åŒ»å­¦å›¾åƒ</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            åŒ»å­¦å›¾åƒ æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-05-31  DeepChest Dynamic Gradient-Free Task Weighting for Effective Multi-Task   Learning in Chest X-ray Classification
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-05-31
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/" class="post-category">
                                    åŒ»å­¦å›¾åƒ
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/">
                        <span class="chip bg-color">åŒ»å­¦å›¾åƒ</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">28292.8k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
