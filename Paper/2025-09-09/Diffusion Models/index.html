<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Diffusion Models">
    <meta name="description" content="Diffusion Models 方向最新论文已更新，请持续关注 Update in 2025-09-09  Painting the market generative diffusion models for financial limit   order book simulation and forecasting">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>Diffusion Models | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loader页面消失采用渐隐的方式*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logo出现动画 */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//使用渐隐的方法淡出loading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//强制显示loading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">嘘~  正在从服务器偷取页面 . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>首页</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>标签</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>分类</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>归档</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="搜索" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="深色/浅色模式" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			首页
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			标签
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			分类
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			归档
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://picx.zhimg.com/v2-fd5a87aae30513f8d86b01c6276963c6.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Diffusion Models</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/Diffusion-Models/">
                                <span class="chip bg-color">Diffusion Models</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/Diffusion-Models/" class="post-category">
                                Diffusion Models
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2025-09-09
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>更新日期:&nbsp;&nbsp;
                    2025-09-13
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp;
                    6.9k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp;
                    27 分
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>阅读次数:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>⚠️ 以下所有内容总结都来自于 大语言模型的能力，如有错误，仅供参考，谨慎使用<br>🔴 请注意：千万不要用于严肃的学术场景，只能用于论文阅读前的初筛！<br>💗 如果您觉得我们的项目对您有帮助 <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ，还请您给我们一些鼓励！⭐️ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFace免费体验</a></p>
</blockquote>
<h1 id="2025-09-09-更新"><a href="#2025-09-09-更新" class="headerlink" title="2025-09-09 更新"></a>2025-09-09 更新</h1><h2 id="Painting-the-market-generative-diffusion-models-for-financial-limit-order-book-simulation-and-forecasting"><a href="#Painting-the-market-generative-diffusion-models-for-financial-limit-order-book-simulation-and-forecasting" class="headerlink" title="Painting the market: generative diffusion models for financial limit   order book simulation and forecasting"></a>Painting the market: generative diffusion models for financial limit   order book simulation and forecasting</h2><p><strong>Authors:Alfred Backhouse, Kang Li, Jakob Foerster, Anisoara Calinescu, Stefan Zohren</strong></p>
<p>Simulating limit order books (LOBs) has important applications across forecasting and backtesting for financial market data. However, deep generative models struggle in this context due to the high noise and complexity of the data. Previous work uses autoregressive models, although these experience error accumulation over longer-time sequences. We introduce a novel approach, converting LOB data into a structured image format, and applying diffusion models with inpainting to generate future LOB states. This method leverages spatio-temporal inductive biases in the order book and enables parallel generation of long sequences overcoming issues with error accumulation. We also publicly contribute to LOB-Bench, the industry benchmark for LOB generative models, to allow fair comparison between models using Level-2 and Level-3 order book data (with or without message level data respectively). We show that our model achieves state-of-the-art performance on LOB-Bench, despite using lower fidelity data as input. We also show that our method prioritises coherent global structures over local, high-fidelity details, providing significant improvements over existing methods on certain metrics. Overall, our method lays a strong foundation for future research into generative diffusion approaches to LOB modelling. </p>
<blockquote>
<p>模拟限价订单簿（LOBs）在金融市场的预测和回溯测试中具有重要应用。然而，由于数据的高噪声和复杂性，深度生成模型在此场景中面临挑战。之前的工作使用自回归模型，尽管这些模型在较长的时间序列上会出现误差累积。我们引入了一种新方法，将LOB数据转换为结构化图像格式，并应用带有填充的扩散模型来生成未来的LOB状态。这种方法利用订单书中的时空归纳偏见，并能够实现并行生成长序列，克服误差累积问题。我们还为LOB生成模型的行业基准LOB-Bench做出贡献，以便使用Level-2和Level-3订单簿数据（分别带有或不带消息级数据）在模型之间进行公平比较。我们显示，尽管我们的模型使用较低保真度的数据作为输入，但在LOB-Bench上实现了最新性能。我们还表明，我们的方法优先关注连贯的全局结构，而非局部的高保真细节，在某些指标上较现有方法取得了显著改进。总的来说，我们的方法为将来研究生成扩散方法在LOB建模中的应用奠定了坚实基础。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.05107v1">PDF</a> Submitted to ICAIF</p>
<p><strong>Summary</strong></p>
<p>模拟限价指令簿（LOBs）在金融市场的预测和回溯测试中具有重要应用。然而，由于数据的高噪声和复杂性，深度生成模型在这方面表现不佳。尽管以前的工作使用了自回归模型，但这些模型在长序列中会出现误差累积。我们提出了一种新方法，将LOB数据转换为结构化图像格式，并应用带有填充的扩散模型来生成未来的LOB状态。此方法利用订单簿中的时空归纳偏见，并能够实现并行生成长序列，克服误差累积问题。我们还为LOB生成模型的行业基准LOB-Bench做出了贡献，以便使用Level-2和Level-3订单簿数据（分别带或不带消息级数据）进行模型之间的公平比较。我们显示，即使使用较低保真度的数据作为输入，我们的模型在LOB-Bench上也能实现最先进的性能。我们还表明，我们的方法优先考虑连贯的全局结构而非局部的、高保真的细节，在某些指标上较现有方法有了显著改进。总体而言，我们的方法为将来研究生成扩散方法在LOB建模中的应用奠定了坚实基础。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>模拟限价指令簿（LOBs）在金融市场的预测和回溯测试中具有重要应用。</li>
<li>深度生成模型在模拟LOB数据时面临高噪声和复杂性数据的挑战。</li>
<li>自回归模型在长序列中存在误差累积问题。</li>
<li>提出一种新方法，将LOB数据转换为结构化图像格式，并应用扩散模型生成未来LOB状态。</li>
<li>该方法利用订单簿的时空归纳偏见，实现并行生成长序列。</li>
<li>对LOB生成模型的行业基准LOB-Bench做出贡献，实现模型间的公平比较。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.05107">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-e94379a2c35b88c3eb25516cf31d7d07.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-fdcd3c9908cb003e89294b65fd625635.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b9424911568848c09befdb0a9b7e26a6.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-cbf061cf7070ec6da279ab3de97730f7.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-4ec18024009bcffc65bd7cd7d2c39e1b.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="Plug-and-Play-Latent-Diffusion-for-Electromagnetic-Inverse-Scattering-with-Application-to-Brain-Imaging"><a href="#Plug-and-Play-Latent-Diffusion-for-Electromagnetic-Inverse-Scattering-with-Application-to-Brain-Imaging" class="headerlink" title="Plug-and-Play Latent Diffusion for Electromagnetic Inverse Scattering   with Application to Brain Imaging"></a>Plug-and-Play Latent Diffusion for Electromagnetic Inverse Scattering   with Application to Brain Imaging</h2><p><strong>Authors:Rui Guo, Yi Zhang, Yhonatan Kvich, Tianyao Huang, Maokun Li, Yonina C. Eldar</strong></p>
<p>Electromagnetic (EM) imaging is an important tool for non-invasive sensing with low-cost and portable devices. One emerging application is EM stroke imaging, which enables early diagnosis and continuous monitoring of brain strokes. Quantitative imaging is achieved by solving an inverse scattering problem (ISP) that reconstructs permittivity and conductivity maps from measurements. In general, the reconstruction accuracy is limited by its inherent nonlinearity and ill-posedness. Existing methods, including learning-free and learning-based approaches, fail to either incorporate complicated prior distributions or provide theoretical guarantees, posing difficulties in balancing interpretability, distortion error, and reliability. To overcome these limitations, we propose a posterior sampling method based on latent diffusion for quantitative EM brain imaging, adapted from a generative plug-and-play (PnP) posterior sampling framework. Our approach allows to flexibly integrate prior knowledge into physics-based inversion without requiring paired measurement-label datasets. We first learn the prior distribution of targets from an unlabeled dataset, and then incorporate the learned prior into posterior sampling. In particular, we train a latent diffusion model on permittivity and conductivity maps to capture their prior distribution. Then, given measurements and the forward model describing EM wave physics, we perform posterior sampling by alternating between two samplers that respectively enforce the likelihood and prior distributions. Finally, reliable reconstruction is obtained through minimum mean squared error (MMSE) estimation based on the samples. Experimental results on brain imaging demonstrate that our approach achieves state-of-the-art performance in reconstruction accuracy and structural similarity while maintaining high measurement fidelity. </p>
<blockquote>
<p>电磁（EM）成像是一种重要的非侵入式感知工具，具有低成本和便携性。其一个新兴应用是电磁卒中成像，能够实现脑卒中的早期发现和持续监控。定量成像通过解决逆散射问题（ISP）实现，即通过对测量值进行重构来生成电容率和电导率图。一般来说，重构的准确性受到其固有非线性性和不适定性的限制。现有方法，包括无学习方法和基于学习的方法，无法融入复杂的先验分布或提供理论保证，难以在可解释性、失真误差和可靠性之间取得平衡。为了克服这些局限性，我们提出了一种基于潜在扩散的贝叶斯采样方法，用于定量电磁脑成像，该方法改编自生成式即插即用（PnP）贝叶斯采样框架。我们的方法允许将先验知识灵活地融入基于物理的反演过程中，而无需配对测量标签数据集。我们首先从无标签数据集中学习目标的先验分布，然后将学到的先验融入贝叶斯采样。具体来说，我们在电容率和电导率图上训练一个潜在扩散模型，以捕捉它们的先验分布。然后，给定测量值和描述电磁波物理的正向模型，我们通过交替使用两个采样器来执行贝叶斯采样，这两个采样器分别强制执行可能性和先验分布。最后，通过基于样本的最小均方误差（MMSE）估计获得可靠的重建结果。在脑成像实验上的结果表明，我们的方法在重建精度和结构相似性方面达到了最先进的性能，同时保持了高测量保真度。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.04860v1">PDF</a> </p>
<p><strong>摘要</strong></p>
<p>电磁（EM）成像是非侵入式感应的重要工具，具有低成本和便携性设备。其新兴应用之一为EM卒中成像，可实现脑卒中的早期诊断和持续监测。定量成像通过解决逆散射问题（ISP）实现，从测量值重建介电常数和电导率图。然而，重建精度通常受限于问题的固有非线性和不适定性。现有方法，包括无学习和基于学习的方法，难以融入复杂的先验分布或提供理论保证，因此在解释性、失真误差和可靠性之间取得平衡存在困难。为克服这些限制，我们提出一种基于潜在扩散的后验采样方法，用于定量EM脑成像，该方法改编自生成式即插即用（PnP）后验采样框架。我们的方法允许灵活地将先验知识融入物理基础的反演中，而无需配对测量标签数据集。我们首先从无标签数据集中学习目标先验分布，然后将学到的先验融入后验采样中。具体来说，我们对介电常数和电导率图训练潜在扩散模型，以捕捉其先验分布。然后，给定测量值和描述电磁波物理的正向模型，我们通过交替使用两个采样器来执行后验采样，分别强制实施似然性和先验分布。最后，通过最小均方误差（MMSE）估计获得可靠的重建结果。在脑成像实验上的结果表明，我们的方法在实现重建精度和结构相似性方面达到最新水平，同时保持高测量保真度。</p>
<p><strong>关键见解</strong></p>
<ol>
<li>电磁成像对于非侵入式感应是一个重要工具，其低成本和便携性使其具有广泛的应用前景。</li>
<li>定量电磁卒中成像可实现早期和持续的脑卒中诊断与监测。</li>
<li>现有电磁成像方法在重建精度上受到限制，面临非线性及不适定性问题。</li>
<li>提出一种基于潜在扩散的后验采样方法用于定量电磁脑成像，该方法结合了物理基础的反演与灵活的先验知识融入。</li>
<li>方法通过训练潜在扩散模型捕捉介电常数和电导率图的先验分布，进而提升重建精度。</li>
<li>结合测量值和电磁波物理的正向模型进行后验采样，通过交替采样器实现似然性和先验性的平衡。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.04860">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-595ab9875a24b7baed3a0cf8cad9dae9.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-656d3388bf818b593712cbc468e3a98c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e16374d50f000f6df42759935cd1c177.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a64b5d3a4dea72154864b5776af925db.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="SemSteDiff-Generative-Diffusion-Model-based-Coverless-Semantic-Steganography-Communication"><a href="#SemSteDiff-Generative-Diffusion-Model-based-Coverless-Semantic-Steganography-Communication" class="headerlink" title="SemSteDiff: Generative Diffusion Model-based Coverless Semantic   Steganography Communication"></a>SemSteDiff: Generative Diffusion Model-based Coverless Semantic   Steganography Communication</h2><p><strong>Authors:Song Gao, Rui Meng, Xiaodong Xu, Haixiao Gao, Yiming Liu, Chenyuan Feng, Ping Zhang, Tony Q. S. Quek, Dusit Niyato</strong></p>
<p>Semantic communication (SemCom), as a novel paradigm for future communication systems, has recently attracted much attention due to its superiority in communication efficiency. However, similar to traditional communication, it also suffers from eavesdropping threats. Intelligent eavesdroppers could launch advanced semantic analysis techniques to infer secret semantic information. Therefore, some researchers have designed Semantic Steganography Communication (SemSteCom) scheme to confuse semantic eavesdroppers. However, the state-of-the-art SemSteCom schemes for image transmission rely on the pre-selected cover image, which limits the universality. To address this issue, we propose a Generative Diffusion Model-based Coverless Semantic Steganography Communication (SemSteDiff) scheme to hide secret images into generated stego images. The semantic related private and public keys enable legitimate receiver to decode secret images correctly while the eavesdropper without completely true key-pairs fail to obtain them. Simulation results demonstrate the effectiveness of the plug-and-play design in different Joint Source-Channel Coding (JSCC) frameworks. The comparison results under different eavesdroppers’ threats show that, when Signal-to-Noise Ratio (SNR) &#x3D; 0 dB, the peak signal-to-noise ratio (PSNR) of the legitimate receiver is 4.14 dB higher than that of the eavesdropper. </p>
<blockquote>
<p>语义通信（SemCom）作为未来通信系统的全新范式，因其通信效率上的优越性而近期备受关注。然而，与传统通信类似，它也面临着窃听威胁。智能窃听者可以发动先进的语义分析技术来推断秘密语义信息。因此，一些研究人员设计了语义隐身通信（SemSteCom）方案来迷惑语义窃听者。然而，当前用于图像传输的SemSteCom方案依赖于预先选择的载体图像，这限制了其通用性。为了解决这一问题，我们提出了一种基于生成扩散模型的无需载体语义隐身通信（SemSteDiff）方案，将秘密图像隐藏在生成的隐写图像中。语义相关的私有和公钥使合法接收者能够正确解码秘密图像，而完全没有完全正确密钥对的窃听者则无法获取它们。仿真结果表明，在不同联合源信道编码（JSCC）框架下，即插即用设计的有效性。在不同窃听者威胁下的比较结果表明，当信噪比（SNR）&#x3D; 0 dB时，合法接收者的峰值信噪比（PSNR）比窃听者高4.14 dB。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.04803v1">PDF</a> 13 pages, 11 figures</p>
<p><strong>Summary</strong><br>     语义通信（SemCom）作为未来通信系统的全新范式，因其在通信效率方面的优越性而备受关注。但同样面临窃听威胁。智能窃听者可能利用高级语义分析技术推断秘密语义信息。为应对这一问题，研究人员设计了语义隐写通信（SemSteCom）方案以迷惑语义窃听者。针对当前图像传输的SemSteCom方案依赖于预选的载体图像，限制了其通用性。我们提出了基于生成扩散模型的无需载体语义隐写通信（SemSteDiff）方案，将秘密图像隐藏在生成的隐写图像中。语义相关的私钥和公钥使合法接收者能够正确解码秘密图像，而窃听者若没有完整的密钥对则无法获取。模拟结果表明，该即插即用设计在不同联合源信道编码（JSCC）框架中的有效性。在不同窃听威胁下的对比结果表明，在信噪比（SNR）&#x3D; 0 dB时，合法接收者的峰值信噪比（PSNR）比窃听者高4.14 dB。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>语义通信（SemCom）能提高通信效率，但面临智能窃听者的威胁。</li>
<li>现有图像传输的SemSteCom方案受限于预选的载体图像，缺乏通用性。</li>
<li>提出基于生成扩散模型的无需载体语义隐写通信（SemSteDiff）方案。</li>
<li>该方案利用语义相关的私钥和公钥，确保合法接收者能正确解码秘密图像。</li>
<li>模拟和对比实验表明，SemSteDiff方案在多种情境下均有效对抗窃听者威胁。</li>
<li>在信噪比（SNR）&#x3D; 0 dB时，合法接收者的PSNR显著高于窃听者。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.04803">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-9b8c31c0106f9278ab5d505502465c84.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-fd5a87aae30513f8d86b01c6276963c6.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-08062089a9962b1d1351c26624c43295.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a90d0dc91e613a76c30d8edf25bd4b32.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="STADI-Fine-Grained-Step-Patch-Diffusion-Parallelism-for-Heterogeneous-GPUs"><a href="#STADI-Fine-Grained-Step-Patch-Diffusion-Parallelism-for-Heterogeneous-GPUs" class="headerlink" title="STADI: Fine-Grained Step-Patch Diffusion Parallelism for Heterogeneous   GPUs"></a>STADI: Fine-Grained Step-Patch Diffusion Parallelism for Heterogeneous   GPUs</h2><p><strong>Authors:Han Liang, Jiahui Zhou, Zicheng Zhou, Xiaoxi Zhang, Xu Chen</strong></p>
<p>The escalating adoption of diffusion models for applications such as image generation demands efficient parallel inference techniques to manage their substantial computational cost. However, existing diffusion parallelism inference schemes often underutilize resources in heterogeneous multi-GPU environments, where varying hardware capabilities or background tasks cause workload imbalance. This paper introduces Spatio-Temporal Adaptive Diffusion Inference (STADI), a novel framework to accelerate diffusion model inference in such settings. At its core is a hybrid scheduler that orchestrates fine-grained parallelism across both temporal and spatial dimensions. Temporally, STADI introduces a novel computation-aware step allocator applied after warmup phases, using a least-common-multiple-minimizing quantization technique to reduce denoising steps on slower GPUs and execution synchronization. To further minimize GPU idle periods, STADI executes an elastic patch parallelism mechanism that allocates variably sized image patches to GPUs according to their computational capability, ensuring balanced workload distribution through a complementary spatial mechanism. Extensive experiments on both load-imbalanced and heterogeneous multi-GPU clusters validate STADI’s efficacy, demonstrating improved load balancing and mitigation of performance bottlenecks. Compared to patch parallelism, a state-of-the-art diffusion inference framework, our method significantly reduces end-to-end inference latency by up to 45% and significantly improves resource utilization on heterogeneous GPUs. </p>
<blockquote>
<p>随着扩散模型在图像生成等应用中的不断采用，需要高效的并行推理技术来管理其巨大的计算成本。然而，现有的扩散并行推理方案在异构多GPU环境中往往不能充分利用资源，其中硬件能力的差异或后台任务会导致工作量不平衡。本文介绍了时空自适应扩散推理（STADI），这是一个加速此类环境中扩散模型推理的新型框架。其核心是一个混合调度器，该调度器在时间和空间维度上协调精细粒度的并行性。在时间上，STADI在预热阶段后引入了一种新型的计算感知步骤分配器，使用最小公倍数最小化量化技术来减少较慢GPU上的降噪步骤和执行同步。为了进一步减少GPU空闲时间，STADI执行弹性补丁并行机制，根据GPU的计算能力分配不同大小的图像补丁，通过互补的空间机制确保工作量平衡分布。在负载不平衡和异构多GPU集群上的广泛实验验证了STADI的有效性，显示出改进了负载均衡并缓解了性能瓶颈。与补丁并行性相比，这是一种先进的扩散推理框架，我们的方法显著减少了端到端推理延迟，最多可达45%，并显著提高了异构GPU上的资源利用率。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.04719v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>扩散模型在图像生成等领域的应用日益广泛，但其计算成本高昂，需要高效的并行推理技术来应对。然而，现有的扩散并行推理方案在异构多GPU环境中未能充分利用资源，存在工作负载不平衡的问题。本文提出Spatio-Temporal Adaptive Diffusion Inference（STADI）框架，通过时空自适应调度加速扩散模型推理。该框架引入了一种计算感知的步骤分配器，使用最小公倍数最小化量化技术减少慢速GPU上的去噪步骤，并执行弹性补丁并行机制，根据GPU的计算能力分配不同大小的图像补丁，确保工作负载平衡。实验证明，STADI能有效改善负载平衡，缓解性能瓶颈，相比现有扩散推理框架，能显著降低端到端推理延迟并提高资源利用率。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>扩散模型在图像生成等领域应用广泛，但需要高效并行推理技术应对计算成本问题。</li>
<li>现有扩散并行推理方案在异构多GPU环境下存在资源利用不足和工作负载不平衡问题。</li>
<li>STADI框架通过时空自适应调度加速扩散模型推理，引入计算感知的步骤分配器和弹性补丁并行机制。</li>
<li>STADI能减少慢速GPU上的去噪步骤，并根据GPU计算能力分配图像补丁，确保工作负载平衡。</li>
<li>实验证明STADI能有效改善负载平衡，缓解性能瓶颈。</li>
<li>与现有扩散推理框架相比，STADI能显著降低端到端推理延迟。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.04719">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic1.zhimg.com/v2-5f52a14af68c4cbb98935ccf6cdf20f1.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-286a19676d2be77276347cd4b5880218.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-0bb8b58673d33fa89b64e43d6a70e5e5.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-dab3c8f6443fdd72f3cd061bdad8c1ec.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-8d3c4a4682029267bd8abb0e90de0517.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a5f388bab71e512506bbb09bf2caee8a.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="DisPatch-Disarming-Adversarial-Patches-in-Object-Detection-with-Diffusion-Models"><a href="#DisPatch-Disarming-Adversarial-Patches-in-Object-Detection-with-Diffusion-Models" class="headerlink" title="DisPatch: Disarming Adversarial Patches in Object Detection with   Diffusion Models"></a>DisPatch: Disarming Adversarial Patches in Object Detection with   Diffusion Models</h2><p><strong>Authors:Jin Ma, Mohammed Aldeen, Christopher Salas, Feng Luo, Mashrur Chowdhury, Mert Pesé, Long Cheng</strong></p>
<p>Object detection is fundamental to various real-world applications, such as security monitoring and surveillance video analysis. Despite their advancements, state-of-theart object detectors are still vulnerable to adversarial patch attacks, which can be easily applied to real-world objects to either conceal actual items or create non-existent ones, leading to severe consequences. Given the current diversity of adversarial patch attacks and potential unknown threats, an ideal defense method should be effective, generalizable, and robust against adaptive attacks. In this work, we introduce DISPATCH, the first diffusion-based defense framework for object detection. Unlike previous works that aim to “detect and remove” adversarial patches, DISPATCH adopts a “regenerate and rectify” strategy, leveraging generative models to disarm attack effects while preserving the integrity of the input image. Specifically, we utilize the in-distribution generative power of diffusion models to regenerate the entire image, aligning it with benign data. A rectification process is then employed to identify and replace adversarial regions with their regenerated benign counterparts. DISPATCH is attack-agnostic and requires no prior knowledge of the existing patches. Extensive experiments across multiple detectors and attacks demonstrate that DISPATCH consistently outperforms state-of-the-art defenses on both hiding attacks and creating attacks, achieving the best overall mAP.5 score of 89.3% on hiding attacks, and lowering the attack success rate to 24.8% on untargeted creating attacks. Moreover, it maintains strong robustness against adaptive attacks, making it a practical and reliable defense for object detection systems. </p>
<blockquote>
<p>对象检测在各类现实应用场景（如安全监控和监控视频分析）中具有重要作用。尽管已有诸多进展，当前顶尖的对象检测器仍然容易受到对抗补丁攻击的影响，这些攻击可以轻易应用于现实对象，用于隐藏实际物品或制造不存在的物品，从而造成严重后果。考虑到当前对抗补丁攻击的多样性和潜在未知威胁，理想的防御方法应该是有效、通用和对抗适应性攻击保持稳健。在这项工作中，我们引入了基于扩散的首个对象检测防御框架——DISPATCH。不同于以往旨在“检测和移除”对抗补丁的方法，DISPATCH采用“再生和纠正”策略，利用生成模型消除攻击效果，同时保持输入图像的完整性。具体来说，我们利用扩散模型的内部分布生成能力，对整个图像进行再生，使其与良性数据对齐。然后采用纠正过程来识别和替换对抗区域，用其再生的良性对应物进行替换。DISPATCH对攻击持中立态度，无需事先了解现有补丁情况。在多个检测器和攻击上的广泛实验表明，无论是在隐藏攻击还是创建攻击方面，DISPATCH都始终优于最先进的防御手段，在隐藏攻击方面取得了最高的mAP分数（89.3%），并将无目标创建攻击的成功率降低到24.8%。此外，它在对抗性攻击面前保持了强大的稳健性，成为对象检测系统实用可靠的防御手段。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.04597v1">PDF</a> </p>
<p><strong>摘要</strong></p>
<p>本文介绍了针对对象检测的新防御框架——DISPATCH。该框架采用基于扩散的策略，旨在抵御对抗性补丁攻击，同时保持输入图像的完整性。不同于以往的“检测和移除”策略，DISPATCH采用“再生和纠正”策略，利用生成模型削弱攻击效果。通过利用扩散模型的内部分布生成能力来再生整个图像，使其与良性数据对齐。随后采用纠正过程识别并替换对抗性区域，以良性区域进行替代。DISATCH对各种攻击具有无差别应对的能力，无需预先了解现有的补丁信息。实验表明，与现有的防御方法相比，DISPATCH在隐藏攻击和创建攻击方面表现更优秀，隐藏攻击的mAP得分达到最高89.3%，无目标创建攻击的成功率降低到24.8%，并在自适应攻击面前保持强大的稳健性，成为对象检测系统实用可靠的防御手段。</p>
<p><strong>关键见解</strong></p>
<ol>
<li>对象检测在现实世界应用中的重要性，特别是在安全监控和监控视频分析中。</li>
<li>尽管取得了进展，最先进的对象检测器仍然容易受到对抗性补丁攻击的影响。这些攻击可能导致实际物品被隐藏或创建不存在的物品，带来严重后果。</li>
<li>当前缺乏一种有效、通用且能抵御自适应攻击的防御方法。</li>
<li>DISPATCH是首个针对对象检测的基于扩散的防御框架。它采用“再生和纠正”策略来削弱攻击效果并保持图像完整性。</li>
<li>DISPATCH利用扩散模型的内部分布生成能力来再生整个图像，使其与良性数据对齐。</li>
<li>实验证明，DISPATCH在隐藏攻击和创建攻击方面表现优异，隐藏攻击的mAP得分达到最高89.3%，无目标创建攻击的成功率降低到24.8%。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.04597">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-c37c942940919f92931b91cd5157f5c4.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-bd804d94664d4948b430286e608d11f2.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-604bfbe6c0ac78e9f40ae3e64711d150.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-839f25549a86991cc434999847eeeef0.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="High-resolution-efficient-image-generation-from-WiFi-CSI-using-a-pretrained-latent-diffusion-model"><a href="#High-resolution-efficient-image-generation-from-WiFi-CSI-using-a-pretrained-latent-diffusion-model" class="headerlink" title="High-resolution efficient image generation from WiFi CSI using a   pretrained latent diffusion model"></a>High-resolution efficient image generation from WiFi CSI using a   pretrained latent diffusion model</h2><p><strong>Authors:Eshan Ramesh, Takayuki Nishio</strong></p>
<p>We present LatentCSI, a novel method for generating images of the physical environment from WiFi CSI measurements that leverages a pretrained latent diffusion model (LDM). Unlike prior approaches that rely on complex and computationally intensive techniques such as GANs, our method employs a lightweight neural network to map CSI amplitudes directly into the latent space of an LDM. We then apply the LDM’s denoising diffusion model to the latent representation with text-based guidance before decoding using the LDM’s pretrained decoder to obtain a high-resolution image. This design bypasses the challenges of pixel-space image generation and avoids the explicit image encoding stage typically required in conventional image-to-image pipelines, enabling efficient and high-quality image synthesis. We validate our approach on two datasets: a wide-band CSI dataset we collected with off-the-shelf WiFi devices and cameras; and a subset of the publicly available MM-Fi dataset. The results demonstrate that LatentCSI outperforms baselines of comparable complexity trained directly on ground-truth images in both computational efficiency and perceptual quality, while additionally providing practical advantages through its unique capacity for text-guided controllability. </p>
<blockquote>
<p>我们提出了LatentCSI，这是一种利用预训练的潜在扩散模型（LDM）从WiFi CSI测量生成物理环境图像的新型方法。不同于依赖复杂且计算密集的技术（如GANs）的先前方法，我们的方法采用轻量级神经网络直接将CSI振幅映射到LDM的潜在空间。然后，我们对潜在表示应用LDM的去噪扩散模型，并使用文本指导，然后使用LDM的预训练解码器进行解码，以获得高分辨率图像。这种设计绕过了像素空间图像生成的挑战，避免了传统图像到图像管道通常需要显式图像编码阶段，从而实现高效且高质量的图像合成。我们在两个数据集上验证了我们的方法：我们使用现成的WiFi设备和相机收集的宽带CSI数据集以及公共可用的MM-Fi数据集的子集。结果表明，LatentCSI在计算效率和感知质量方面都优于直接在真实图像上训练的相似复杂度的基线，同时还可以通过其独特的文本指导可控性提供实际优势。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.10605v3">PDF</a> 6 pages, 4 figures</p>
<p><strong>Summary</strong></p>
<p>LatentCSI是一种基于WiFi CSI测量生成物理环境图像的新方法，它利用预训练的潜在扩散模型（LDM）。不同于依赖复杂且计算密集的技术（如GANs）的先前方法，我们的方法采用轻量级神经网络将CSI振幅直接映射到LDM的潜在空间。然后，我们对潜在表示应用LDM的去噪扩散模型，并使用文本指导，最后使用LDM的预训练解码器进行解码以获得高分辨率图像。这种方法克服了像素空间图像生成的挑战，避免了传统图像到图像管道中通常需要的显式图像编码阶段，实现了高效的高质量图像合成。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>LatentCSI利用WiFi CSI测量生成物理环境图像。</li>
<li>该方法利用预训练的潜在扩散模型（LDM）。</li>
<li>通过轻量级神经网络将CSI振幅映射到LDM的潜在空间。</li>
<li>应用LDM的去噪扩散模型于潜在表示。</li>
<li>使用文本指导生成图像。</li>
<li>方法绕过像素空间图像生成的挑战，实现高效高质量图像合成。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.10605">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-37951aaa697dfae8ecb2979285856833.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-c424edbca4209cbcb8fcd18ec65ba981.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-4dece46f7f839ec7c0d22f8156c78534.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-4d41f37b71ec9e1d3390d2f96aad2ebd.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-af5d7050c427971c85828f58823b5984.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-d9b105e4109970c33688cae85368ab45.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-455d2a886104f9737816ed53d8fa0b91.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ece02ac2c509d49e8d4a6a3aff6186d4.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        文章作者:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        文章链接:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-09-09/Diffusion%20Models/">https://kedreamix.github.io/Talk2Paper/Paper/2025-09-09/Diffusion%20Models/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        版权声明:
                    </i>
                </span>
                <span class="reprint-info">
                    本博客所有文章除特別声明外，均采用
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    许可协议。转载请注明来源
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/Diffusion-Models/">
                                    <span class="chip bg-color">Diffusion Models</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;上一篇</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-09-09/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-ca6e177dc7ad33e2d5a139b77a731ea6.jpg" class="responsive-img" alt="医学图像">
                        
                        <span class="card-title">医学图像</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            医学图像 方向最新论文已更新，请持续关注 Update in 2025-09-09  VLSM-Ensemble Ensembling CLIP-based Vision-Language Models for Enhanced   Medical Image Segmentation
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-09-09
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/" class="post-category">
                                    医学图像
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/">
                        <span class="chip bg-color">医学图像</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-09-09/NeRF/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-943fb92391ceb1d7d3c12043dce80e6a.jpg" class="responsive-img" alt="NeRF">
                        
                        <span class="card-title">NeRF</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            NeRF 方向最新论文已更新，请持续关注 Update in 2025-09-09  BayesSDF Surface-Based Laplacian Uncertainty Estimation for 3D Geometry   with Neural Signed Distance Fields
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-09-09
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/NeRF/" class="post-category">
                                    NeRF
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/NeRF/">
                        <span class="chip bg-color">NeRF</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- 代码语言 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span
                        class="white-color">27663.8k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- 运行天数提醒. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // 区分是否有年份.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = '本站已运行 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                daysTip = '本站已運行 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = '本站已运行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = '本站已運行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="关注我的知乎: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">知</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- 白天和黑夜主题 -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // 只在桌面版网页启用特效
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- 雪花特效 -->
    

    <!-- 鼠标星星特效 -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--腾讯兔小巢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- 动态标签 -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Σ(っ °Д °;)っ诶，页面崩溃了嘛？", clearTimeout(st)) : (document.title = "φ(゜▽゜*)♪咦，又好了！", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
