<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="R1_Reasoning">
    <meta name="description" content="R1_Reasoning æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-09-09  COGITAO A Visual Reasoning Framework To Study Compositionality &amp;   Generalization">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>R1_Reasoning | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('D:\MyBlog\AutoFX\arxiv\2025-09-09\./crop_R1_Reasoning/2509.05249v1/page_4_0.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">R1_Reasoning</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/R1-Reasoning/">
                                <span class="chip bg-color">R1_Reasoning</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/R1-Reasoning/" class="post-category">
                                R1_Reasoning
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-09-09
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-10-07
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    23k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    93 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-09-09-æ›´æ–°"><a href="#2025-09-09-æ›´æ–°" class="headerlink" title="2025-09-09 æ›´æ–°"></a>2025-09-09 æ›´æ–°</h1><h2 id="COGITAO-A-Visual-Reasoning-Framework-To-Study-Compositionality-Generalization"><a href="#COGITAO-A-Visual-Reasoning-Framework-To-Study-Compositionality-Generalization" class="headerlink" title="COGITAO: A Visual Reasoning Framework To Study Compositionality &amp;   Generalization"></a>COGITAO: A Visual Reasoning Framework To Study Compositionality &amp;   Generalization</h2><p><strong>Authors:Yassine Taoudi-Benchekroun, Klim Troyan, Pascal Sager, Stefan Gerber, Lukas Tuggener, Benjamin Grewe</strong></p>
<p>The ability to compose learned concepts and apply them in novel settings is key to human intelligence, but remains a persistent limitation in state-of-the-art machine learning models. To address this issue, we introduce COGITAO, a modular and extensible data generation framework and benchmark designed to systematically study compositionality and generalization in visual domains. Drawing inspiration from ARC-AGIâ€™s problem-setting, COGITAO constructs rule-based tasks which apply a set of transformations to objects in grid-like environments. It supports composition, at adjustable depth, over a set of 28 interoperable transformations, along with extensive control over grid parametrization and object properties. This flexibility enables the creation of millions of unique task rules â€“ surpassing concurrent datasets by several orders of magnitude â€“ across a wide range of difficulties, while allowing virtually unlimited sample generation per rule. We provide baseline experiments using state-of-the-art vision models, highlighting their consistent failures to generalize to novel combinations of familiar elements, despite strong in-domain performance. COGITAO is fully open-sourced, including all code and datasets, to support continued research in this field. </p>
<blockquote>
<p>äººç±»æ™ºèƒ½çš„å…³é”®åœ¨äºèƒ½å¤Ÿç»„åˆå­¦åˆ°çš„æ¦‚å¿µå¹¶å°†å…¶åº”ç”¨äºæ–°çš„æƒ…å¢ƒä¸­ï¼Œä½†åœ¨æœ€å…ˆè¿›çš„æœºå™¨å­¦ä¹ æ¨¡å‹ä¸­ï¼Œè¿™ä»ç„¶æ˜¯ä¸€ä¸ªæŒç»­çš„å±€é™æ€§ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬å¼•å…¥äº†COGITAOï¼Œè¿™æ˜¯ä¸€ä¸ªæ¨¡å—åŒ–ä¸”å¯æ‰©å±•çš„æ•°æ®ç”Ÿæˆæ¡†æ¶å’ŒåŸºå‡†æµ‹è¯•ï¼Œæ—¨åœ¨ç³»ç»Ÿåœ°ç ”ç©¶è§†è§‰é¢†åŸŸçš„ç»„åˆæ€§å’Œæ³›åŒ–æ€§ã€‚COGITAOå€Ÿé‰´ARC-AGIçš„é—®é¢˜è®¾ç½®ï¼Œæ„å»ºåŸºäºè§„åˆ™çš„ä»»åŠ¡ï¼Œå¯¹ç½‘æ ¼ç¯å¢ƒä¸­çš„å¯¹è±¡åº”ç”¨ä¸€ç³»åˆ—è½¬æ¢ã€‚å®ƒåœ¨å¯è°ƒæ•´çš„æ·±åº¦ä¸Šæ”¯æŒ28ä¸ªå¯æ“ä½œè½¬æ¢çš„ç»„åˆï¼Œå¹¶å¯¹ç½‘æ ¼å‚æ•°åŒ–å’Œå¯¹è±¡å±æ€§è¿›è¡Œå¹¿æ³›çš„æ§åˆ¶ã€‚è¿™ç§çµæ´»æ€§ä½¿å¾—èƒ½å¤Ÿåˆ›å»ºæ•°ä»¥ç™¾ä¸‡è®¡çš„ç‹¬ç‰¹ä»»åŠ¡è§„åˆ™â€”â€”åœ¨éš¾åº¦èŒƒå›´ä¸Šè¿œè¿œè¶…è¿‡ç°æœ‰çš„æ•°æ®é›†â€”â€”åŒæ—¶å…è®¸æŒ‰è§„åˆ™è¿›è¡Œå‡ ä¹æ— é™çš„æ ·æœ¬ç”Ÿæˆã€‚æˆ‘ä»¬ä½¿ç”¨æœ€å…ˆè¿›çš„è§†è§‰æ¨¡å‹æä¾›åŸºçº¿å®éªŒï¼Œçªå‡ºæ˜¾ç¤ºå…¶åœ¨é¢å¯¹ç†Ÿæ‚‰å…ƒç´ çš„å…¨æ–°ç»„åˆæ—¶æ— æ³•æ³›åŒ–çš„æŒç»­å¤±è´¥ï¼Œå°½ç®¡å…¶åœ¨é¢†åŸŸå†…çš„è¡¨ç°å¼ºåŠ²ã€‚COGITAOå®Œå…¨å¼€æºï¼ŒåŒ…æ‹¬æ‰€æœ‰ä»£ç å’Œæ•°æ®é›†ï¼Œä»¥æ”¯æŒè¯¥é¢†åŸŸçš„æŒç»­ç ”ç©¶ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.05249v1">PDF</a> 10 main pages, 3 figure, appendix available</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†ä¸ºè§£å†³æœºå™¨å­¦ä¹ ä¸­å¯¹ç»„æˆæ¦‚å¿µçš„é™åˆ¶è€Œå¼€å‘çš„COGITAOæ¡†æ¶ã€‚è¯¥æ¡†æ¶å…·å¤‡æ¨¡å—åŒ–å’Œå¯æ‰©å±•æ€§ï¼Œèƒ½å¤Ÿç³»ç»Ÿåœ°ç ”ç©¶è§†è§‰é¢†åŸŸçš„ç»„åˆæ€§å’Œæ³›åŒ–èƒ½åŠ›ã€‚é€šè¿‡æ„å»ºåŸºäºè§„åˆ™çš„ä»»åŠ¡ï¼Œåº”ç”¨ç½‘æ ¼ç¯å¢ƒä¸­å¯¹è±¡çš„è½¬æ¢ï¼ŒCOGITAOæ”¯æŒåœ¨å¯è°ƒæ•´æ·±åº¦ä¸Šçš„ä¸€ç»„28ç§äº’æ“ä½œè½¬æ¢ã€‚è¿™ä¸ºåˆ›å»ºæ•°ç™¾ä¸‡ç§ç‹¬ç‰¹çš„ä»»åŠ¡è§„åˆ™æä¾›äº†å¯èƒ½ï¼Œå¹¶å…è®¸ä¸ºæ¯ä¸ªè§„åˆ™ç”Ÿæˆå‡ ä¹æ— é™æ•°é‡çš„æ ·æœ¬ã€‚åŒæ—¶ï¼Œæœ¬æ–‡æä¾›äº†ä½¿ç”¨æœ€æ–°è§†è§‰æ¨¡å‹çš„åŸºçº¿å®éªŒï¼Œçªæ˜¾äº†æ¨¡å‹åœ¨ç†Ÿæ‚‰å…ƒç´ çš„æ–°ç»„åˆä¸Šçš„æ³›åŒ–èƒ½åŠ›æŒç»­å¤±è´¥çš„é—®é¢˜ã€‚COGITAOå·²å®Œå…¨å¼€æºï¼ŒåŒ…æ‹¬æ‰€æœ‰ä»£ç å’Œæ•°æ®é›†ï¼Œä»¥æ”¯æŒè¯¥é¢†åŸŸçš„ç ”ç©¶ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>COGITAOæ˜¯ä¸€ä¸ªç”¨äºç ”ç©¶è§†è§‰é¢†åŸŸç»„åˆæ€§å’Œæ³›åŒ–èƒ½åŠ›çš„æ¨¡å—åŒ–ã€å¯æ‰©å±•çš„æ•°æ®ç”Ÿæˆæ¡†æ¶å’ŒåŸºå‡†æµ‹è¯•å¹³å°ã€‚</li>
<li>COGITAOé€šè¿‡æ„å»ºåŸºäºè§„åˆ™çš„ä»»åŠ¡ï¼Œåº”ç”¨ç½‘æ ¼ç¯å¢ƒä¸­å¯¹è±¡çš„è½¬æ¢ï¼Œæ”¯æŒç»„åˆæ€§å¹¶å…·å¤‡å¹¿æ³›çš„ç½‘æ ¼å‚æ•°å’Œå¯¹è±¡å±æ€§æ§åˆ¶ã€‚</li>
<li>COGITAOèƒ½å¤Ÿåˆ›å»ºæ•°ç™¾ä¸‡ç§ç‹¬ç‰¹çš„ä»»åŠ¡è§„åˆ™ï¼Œå¹¶å…è®¸ä¸ºæ¯ä¸ªè§„åˆ™ç”Ÿæˆå‡ ä¹æ— é™æ•°é‡çš„æ ·æœ¬ã€‚</li>
<li>æœ€æ–°è§†è§‰æ¨¡å‹åœ¨ç†Ÿæ‚‰å…ƒç´ çš„æ–°ç»„åˆä¸Šçš„æ³›åŒ–èƒ½åŠ›æœ‰é™ï¼Œå°½ç®¡å®ƒä»¬åœ¨ç‰¹å®šé¢†åŸŸè¡¨ç°è‰¯å¥½ã€‚</li>
<li>COGITAOæä¾›çš„åŸºçº¿å®éªŒçªæ˜¾äº†æœºå™¨å­¦ä¹ ä¸­å­˜åœ¨çš„æŒ‘æˆ˜ï¼Œå³å¦‚ä½•æ›´å¥½åœ°åº”ç”¨å­¦ä¹ åˆ°çš„æ¦‚å¿µäºæ–°æƒ…å¢ƒã€‚</li>
<li>COGITAOæ¡†æ¶å·²å®Œå…¨å¼€æºï¼ŒåŒ…æ‹¬æ‰€æœ‰ä»£ç å’Œæ•°æ®é›†ï¼Œä»¥ä¿ƒè¿›è¯¥é¢†åŸŸçš„ç ”ç©¶è¿›å±•ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.05249">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-09\./crop_R1_Reasoning/2509.05249v1/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-09\./crop_R1_Reasoning/2509.05249v1/page_1_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-09\./crop_R1_Reasoning/2509.05249v1/page_4_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-09\./crop_R1_Reasoning/2509.05249v1/page_5_0.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="MM-DREX-Multimodal-Driven-Dynamic-Routing-of-LLM-Experts-for-Financial-Trading"><a href="#MM-DREX-Multimodal-Driven-Dynamic-Routing-of-LLM-Experts-for-Financial-Trading" class="headerlink" title="MM-DREX: Multimodal-Driven Dynamic Routing of LLM Experts for Financial   Trading"></a>MM-DREX: Multimodal-Driven Dynamic Routing of LLM Experts for Financial   Trading</h2><p><strong>Authors:Yang Chen, Yueheng Jiang, Zhaozhao Ma, Yuchen Cao Jacky Keung, Kun Kuang, Leilei Gan, Yiquan Wu, Fei Wu</strong></p>
<p>The inherent non-stationarity of financial markets and the complexity of multi-modal information pose significant challenges to existing quantitative trading models. Traditional methods relying on fixed structures and unimodal data struggle to adapt to market regime shifts, while large language model (LLM)-driven solutions - despite their multi-modal comprehension - suffer from static strategies and homogeneous expert designs, lacking dynamic adjustment and fine-grained decision mechanisms. To address these limitations, we propose MM-DREX: a Multimodal-driven, Dynamically-Routed EXpert framework based on large language models. MM-DREX explicitly decouples market state perception from strategy execution to enable adaptive sequential decision-making in non-stationary environments. Specifically, it (1) introduces a vision-language model (VLM)-powered dynamic router that jointly analyzes candlestick chart patterns and long-term temporal features to allocate real-time expert weights; (2) designs four heterogeneous trading experts (trend, reversal, breakout, positioning) generating specialized fine-grained sub-strategies; and (3) proposes an SFT-RL hybrid training paradigm to synergistically optimize the routerâ€™s market classification capability and expertsâ€™ risk-adjusted decision-making. Extensive experiments on multi-modal datasets spanning stocks, futures, and cryptocurrencies demonstrate that MM-DREX significantly outperforms 15 baselines (including state-of-the-art financial LLMs and deep reinforcement learning models) across key metrics: total return, Sharpe ratio, and maximum drawdown, validating its robustness and generalization. Additionally, an interpretability module traces routing logic and expert behavior in real time, providing an audit trail for strategy transparency. </p>
<blockquote>
<p>é‡‘èå¸‚åœºå›ºæœ‰çš„éç¨³å®šæ€§å’Œå¤šæ¨¡æ€ä¿¡æ¯çš„å¤æ‚æ€§å¯¹ç°æœ‰é‡åŒ–äº¤æ˜“æ¨¡å‹æ„æˆäº†é‡å¤§æŒ‘æˆ˜ã€‚ä¼ ç»Ÿæ–¹æ³•ä¾èµ–äºå›ºå®šç»“æ„å’Œå•æ¨¡æ€æ•°æ®ï¼Œéš¾ä»¥é€‚åº”å¸‚åœºä½“åˆ¶çš„å˜åŒ–ã€‚è™½ç„¶å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰é©±åŠ¨è§£å†³æ–¹æ¡ˆå…·æœ‰å¤šæ¨¡æ€ç†è§£èƒ½åŠ›ï¼Œä½†å®ƒä»¬å—åˆ°é™æ€ç­–ç•¥å’ŒåŒè´¨åŒ–ä¸“å®¶è®¾è®¡çš„å›°æ‰°ï¼Œç¼ºä¹åŠ¨æ€è°ƒæ•´å’Œç²¾ç»†å†³ç­–æœºåˆ¶ã€‚ä¸ºäº†è§£å†³è¿™äº›å±€é™æ€§ï¼Œæˆ‘ä»¬æå‡ºäº†åŸºäºå¤§è¯­è¨€æ¨¡å‹çš„MM-DREXï¼šä¸€ä¸ªå¤šæ¨¡æ€é©±åŠ¨ã€åŠ¨æ€è·¯ç”±ä¸“å®¶æ¡†æ¶ã€‚MM-DREXæ˜¾å¼åœ°å°†å¸‚åœºçŠ¶æ€æ„ŸçŸ¥ä¸ç­–ç•¥æ‰§è¡Œåˆ†ç¦»ï¼Œåœ¨éçº¿æ€§ç¯å¢ƒä¸­å®ç°è‡ªé€‚åº”åºåˆ—å†³ç­–ã€‚å…·ä½“æ¥è¯´ï¼Œå®ƒï¼ˆ1ï¼‰å¼•å…¥äº†ä¸€ç§ç”±è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMï¼‰é©±åŠ¨çš„åŠ¨æ€è·¯ç”±å™¨ï¼Œè¯¥è·¯ç”±å™¨è”åˆåˆ†æKçº¿å›¾æ¨¡å¼å’Œé•¿æœŸæ—¶é—´ç‰¹å¾ä»¥åˆ†é…å®æ—¶ä¸“å®¶æƒé‡ï¼›ï¼ˆ2ï¼‰è®¾è®¡äº†å››ç§ä¸åŒçš„äº¤æ˜“ä¸“å®¶ï¼ˆè¶‹åŠ¿ã€åè½¬ã€çªç ´ã€å®šä½ï¼‰ï¼Œç”Ÿæˆä¸“ä¸šçš„ç²¾ç»†å­ç­–ç•¥ï¼›ï¼ˆ3ï¼‰æå‡ºäº†ä¸€ç§SFT-RLæ··åˆè®­ç»ƒèŒƒå¼ï¼ŒååŒä¼˜åŒ–è·¯ç”±å™¨çš„å¸‚åœºåˆ†ç±»èƒ½åŠ›å’Œä¸“å®¶çš„é£é™©è°ƒæ•´å†³ç­–èƒ½åŠ›ã€‚åœ¨æ¶µç›–è‚¡ç¥¨ã€æœŸè´§å’ŒåŠ å¯†è´§å¸çš„å¤šæ¨¡æ€æ•°æ®é›†ä¸Šçš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼ŒMM-DREXåœ¨å…³é”®æŒ‡æ ‡ä¸Šæ˜¾è‘—ä¼˜äº15ä¸ªåŸºå‡†æ¨¡å‹ï¼ˆåŒ…æ‹¬æœ€å…ˆè¿›çš„é‡‘èLLMå’Œæ·±åº¦å¼ºåŒ–å­¦ä¹ æ¨¡å‹ï¼‰ï¼Œè¿™äº›æŒ‡æ ‡åŒ…æ‹¬æ€»å›æŠ¥ã€å¤æ™®æ¯”ç‡å’Œæœ€å¤§å›æ’¤ï¼ŒéªŒè¯äº†å…¶ç¨³å¥æ€§å’Œæ³›åŒ–èƒ½åŠ›ã€‚æ­¤å¤–ï¼Œè§£é‡Šæ€§æ¨¡å—å¯å®æ—¶è·Ÿè¸ªè·¯ç”±é€»è¾‘å’Œä¸“å®¶è¡Œä¸ºï¼Œä¸ºç­–ç•¥é€æ˜æ€§æä¾›å®¡è®¡è·Ÿè¸ªã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.05080v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>é‡‘èå¸‚åœºçš„å†…åœ¨éå¹³ç¨³æ€§å’Œå¤šæ¨¡æ€ä¿¡æ¯çš„å¤æ‚æ€§å¯¹ç°æœ‰é‡åŒ–äº¤æ˜“æ¨¡å‹æ„æˆé‡å¤§æŒ‘æˆ˜ã€‚ä¼ ç»Ÿçš„å›ºå®šç»“æ„å•æ¨¡æ€æ•°æ®æ–¹æ³•éš¾ä»¥é€‚åº”å¸‚åœºå˜åŒ–ï¼Œå¤§å‹è¯­è¨€æ¨¡å‹é©±åŠ¨çš„æ–¹æ¡ˆè™½å…·å¤‡å¤šæ¨¡æ€ç†è§£èƒ½åŠ›å´ç¼ºä¹åŠ¨æ€è°ƒæ•´ä¸ç²¾ç»†å†³ç­–æœºåˆ¶ã€‚ä¸ºè§£å†³è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹çš„Multimodalé©±åŠ¨çš„ã€åŠ¨æ€è·¯ç”±çš„ä¸“å®¶æ¡†æ¶MM-DREXã€‚å®ƒå®ç°äº†å¸‚åœºçŠ¶æ€æ„ŸçŸ¥ä¸ç­–ç•¥æ‰§è¡Œçš„è§£è€¦ï¼Œèƒ½åœ¨éå¹³ç¨³ç¯å¢ƒä¸­è¿›è¡Œè‡ªé€‚åº”çš„åºåˆ—å†³ç­–ã€‚é€šè¿‡å¼•å…¥è§†è§‰è¯­è¨€æ¨¡å‹é©±åŠ¨çš„åŠ¨æ€è·¯ç”±å™¨ï¼Œåˆ†æèœ¡çƒ›å›¾æ¨¡å¼å’Œé•¿æœŸæ—¶é—´ç‰¹å¾æ¥åˆ†é…å®æ—¶ä¸“å®¶æƒé‡ï¼›è®¾è®¡å››ç§å¼‚è´¨äº¤æ˜“ä¸“å®¶ç”Ÿæˆä¸“ä¸šç²¾ç»†çš„å­ç­–ç•¥ï¼›å¹¶æå‡ºSFT-RLæ··åˆè®­ç»ƒèŒƒå¼ä¼˜åŒ–è·¯ç”±å™¨çš„å¸‚åœºåˆ†ç±»èƒ½åŠ›å’Œä¸“å®¶çš„é£é™©è°ƒæ•´å†³ç­–èƒ½åŠ›ã€‚å®éªŒè¯æ˜ï¼ŒMM-DREXåœ¨è‚¡ç¥¨ã€æœŸè´§å’ŒåŠ å¯†è´§å¸çš„å¤šæ¨¡æ€æ•°æ®é›†ä¸Šæ˜¾è‘—ä¼˜äº15ç§åŸºçº¿æ–¹æ³•ï¼ŒéªŒè¯äº†å…¶ç¨³å¥æ€§å’Œæ³›åŒ–èƒ½åŠ›ã€‚åŒæ—¶ï¼Œå…¶æä¾›çš„è§£é‡Šæ€§æ¨¡å—å¯å®æ—¶è¿½è¸ªè·¯ç”±é€»è¾‘å’Œä¸“å®¶è¡Œä¸ºï¼Œæé«˜ç­–ç•¥é€æ˜åº¦ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>é‡‘èå¸‚åœºå­˜åœ¨éå¹³ç¨³æ€§å’Œå¤šæ¨¡æ€ä¿¡æ¯å¤æ‚æ€§æŒ‘æˆ˜ã€‚</li>
<li>ä¼ ç»Ÿé‡åŒ–äº¤æ˜“æ¨¡å‹éš¾ä»¥é€‚åº”å¸‚åœºå˜åŒ–å’Œå¤šæ¨¡æ€ä¿¡æ¯ã€‚</li>
<li>MM-DREXæ¡†æ¶å¼•å…¥è§†è§‰è¯­è¨€æ¨¡å‹é©±åŠ¨çš„åŠ¨æ€è·¯ç”±å™¨è¿›è¡Œå®æ—¶å†³ç­–ã€‚</li>
<li>MM-DREXè®¾è®¡å››ç§å¼‚è´¨äº¤æ˜“ä¸“å®¶ç”Ÿæˆä¸“ä¸šç²¾ç»†çš„å­ç­–ç•¥ã€‚</li>
<li>SFT-RLæ··åˆè®­ç»ƒèŒƒå¼ä¼˜åŒ–è·¯ç”±å™¨çš„å¸‚åœºåˆ†ç±»å’Œä¸“å®¶å†³ç­–èƒ½åŠ›ã€‚</li>
<li>MM-DREXåœ¨å¤šä¸ªæ•°æ®é›†ä¸Šè¡¨ç°ä¼˜äºå…¶ä»–æ¨¡å‹ï¼Œå…·æœ‰ç¨³å¥æ€§å’Œæ³›åŒ–èƒ½åŠ›ã€‚</li>
<li>MM-DREXæä¾›è§£é‡Šæ€§æ¨¡å—ï¼Œæé«˜ç­–ç•¥é€æ˜åº¦ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.05080">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-09\./crop_R1_Reasoning/2509.05080v1/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-09\./crop_R1_Reasoning/2509.05080v1/page_2_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-09\./crop_R1_Reasoning/2509.05080v1/page_4_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-09\./crop_R1_Reasoning/2509.05080v1/page_5_0.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="Sticker-TTS-Learn-to-Utilize-Historical-Experience-with-a-Sticker-driven-Test-Time-Scaling-Framework"><a href="#Sticker-TTS-Learn-to-Utilize-Historical-Experience-with-a-Sticker-driven-Test-Time-Scaling-Framework" class="headerlink" title="Sticker-TTS: Learn to Utilize Historical Experience with a   Sticker-driven Test-Time Scaling Framework"></a>Sticker-TTS: Learn to Utilize Historical Experience with a   Sticker-driven Test-Time Scaling Framework</h2><p><strong>Authors:Jie Chen, Jinhao Jiang, Yingqian Min, Zican Dong, Shijie Wang, Wayne Xin Zhao, Ji-Rong Wen</strong></p>
<p>Large reasoning models (LRMs) have exhibited strong performance on complex reasoning tasks, with further gains achievable through increased computational budgets at inference. However, current test-time scaling methods predominantly rely on redundant sampling, ignoring the historical experience utilization, thereby limiting computational efficiency. To overcome this limitation, we propose Sticker-TTS, a novel test-time scaling framework that coordinates three collaborative LRMs to iteratively explore and refine solutions guided by historical attempts. At the core of our framework are distilled key conditions-termed stickers-which drive the extraction, refinement, and reuse of critical information across multiple rounds of reasoning. To further enhance the efficiency and performance of our framework, we introduce a two-stage optimization strategy that combines imitation learning with self-improvement, enabling progressive refinement. Extensive evaluations on three challenging mathematical reasoning benchmarks, including AIME-24, AIME-25, and OlymMATH, demonstrate that Sticker-TTS consistently surpasses strong baselines, including self-consistency and advanced reinforcement learning approaches, under comparable inference budgets. These results highlight the effectiveness of sticker-guided historical experience utilization. Our code and data are available at <a target="_blank" rel="noopener" href="https://github.com/RUCAIBox/Sticker-TTS">https://github.com/RUCAIBox/Sticker-TTS</a>. </p>
<blockquote>
<p>å¤§è§„æ¨¡æ¨ç†æ¨¡å‹ï¼ˆLRMsï¼‰åœ¨å¤æ‚çš„æ¨ç†ä»»åŠ¡ä¸­è¡¨ç°å‡ºäº†å¼ºå¤§çš„æ€§èƒ½ï¼Œé€šè¿‡å¢åŠ æ¨ç†æ—¶çš„è®¡ç®—é¢„ç®—ï¼Œå¯ä»¥è¿›ä¸€æ­¥è·å¾—æ”¶ç›Šã€‚ç„¶è€Œï¼Œå½“å‰çš„æµ‹è¯•æ—¶é—´æ‰©å±•æ–¹æ³•ä¸»è¦ä¾èµ–äºå†—ä½™é‡‡æ ·ï¼Œå¿½ç•¥äº†å†å²ç»éªŒçš„åˆ©ç”¨ï¼Œä»è€Œé™åˆ¶äº†è®¡ç®—æ•ˆç‡ã€‚ä¸ºäº†å…‹æœè¿™ä¸€å±€é™æ€§ï¼Œæˆ‘ä»¬æå‡ºäº†Sticker-TTSï¼Œè¿™æ˜¯ä¸€ç§æ–°å‹çš„æµ‹è¯•æ—¶é—´æ‰©å±•æ¡†æ¶ï¼Œå®ƒåè°ƒä¸‰ä¸ªåä½œçš„LRMsï¼Œä»¥å†å²å°è¯•ä¸ºå¼•å¯¼ï¼Œè¿­ä»£åœ°æ¢ç´¢å’Œç»†åŒ–è§£å†³æ–¹æ¡ˆã€‚æˆ‘ä»¬æ¡†æ¶çš„æ ¸å¿ƒæ˜¯æç‚¼å‡ºçš„å…³é”®æ¡ä»¶â€”â€”è¢«ç§°ä¸ºâ€œè´´çº¸â€ï¼Œå®ƒé©±åŠ¨äº†è·¨å¤šä¸ªæ¨ç†è½®æ¬¡çš„å…³é”®ä¿¡æ¯çš„æå–ã€ç»†åŒ–å’Œå†åˆ©ç”¨ã€‚ä¸ºäº†è¿›ä¸€æ­¥æé«˜æˆ‘ä»¬æ¡†æ¶çš„æ•ˆç‡å’Œæ€§èƒ½ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§ä¸¤é˜¶æ®µä¼˜åŒ–ç­–ç•¥ï¼Œå°†æ¨¡ä»¿å­¦ä¹ ä¸è‡ªæˆ‘æ”¹è¿›ç›¸ç»“åˆï¼Œå®ç°æ¸è¿›ç»†åŒ–ã€‚åœ¨ä¸‰ä¸ªå…·æœ‰æŒ‘æˆ˜æ€§çš„æ•°å­¦æ¨ç†åŸºå‡†æµ‹è¯•ä¸Šçš„å¹¿æ³›è¯„ä¼°ï¼ŒåŒ…æ‹¬AIME-24ã€AIME-25å’Œå¥¥æ—å·´æ–¯æ•°å­¦ï¼Œè¯æ˜Sticker-TTSåœ¨å¯æ¯”è¾ƒæ¨ç†é¢„ç®—ä¸‹ï¼ŒæŒç»­è¶…è¶Šäº†å¼ºå¤§çš„åŸºçº¿ï¼ŒåŒ…æ‹¬è‡ªæˆ‘ä¸€è‡´æ€§æµ‹è¯•å’Œå…ˆè¿›çš„å¼ºåŒ–å­¦ä¹ çš„æ–¹æ³•ã€‚è¿™äº›ç»“æœçªæ˜¾äº†è´´çº¸å¼•å¯¼çš„å†å²ç»éªŒåˆ©ç”¨çš„æœ‰æ•ˆæ€§ã€‚æˆ‘ä»¬çš„ä»£ç å’Œæ•°æ®å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/RUCAIBox/Sticker-TTS%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/RUCAIBox/Sticker-TTSæ‰¾åˆ°ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.05007v1">PDF</a> 11 pages, 1 figures, 5 tables</p>
<p><strong>Summary</strong></p>
<p>å¤§å‹æ¨ç†æ¨¡å‹ï¼ˆLRMsï¼‰åœ¨å¤æ‚æ¨ç†ä»»åŠ¡ä¸Šè¡¨ç°å‡ºå¼ºå¤§çš„æ€§èƒ½ï¼Œé€šè¿‡å¢åŠ è®¡ç®—é¢„ç®—å¯ä»¥åœ¨æ¨ç†æ—¶è¿›ä¸€æ­¥æé«˜æ€§èƒ½ã€‚ç„¶è€Œï¼Œå½“å‰çš„æµ‹è¯•æ—¶é—´æ‰©å±•æ–¹æ³•ä¸»è¦ä¾èµ–äºå†—ä½™é‡‡æ ·ï¼Œå¿½ç•¥äº†å†å²ç»éªŒçš„åˆ©ç”¨ï¼Œä»è€Œé™åˆ¶äº†è®¡ç®—æ•ˆç‡ã€‚ä¸ºäº†å…‹æœè¿™ä¸€å±€é™æ€§ï¼Œæˆ‘ä»¬æå‡ºäº†Sticker-TTSè¿™ä¸€æ–°é¢–çš„æµ‹è¯•æ—¶é—´æ‰©å±•æ¡†æ¶ï¼Œå®ƒé€šè¿‡åè°ƒä¸‰ä¸ªåä½œçš„LRMsæ¥è¿­ä»£åœ°æ¢ç´¢å¹¶ä¼˜åŒ–è§£å†³æ–¹æ¡ˆï¼Œè¿™äº›è§£å†³æ–¹æ¡ˆç”±å†å²å°è¯•å¼•å¯¼ã€‚æ¡†æ¶çš„æ ¸å¿ƒæ˜¯æç‚¼å‡ºçš„å…³é”®æ¡ä»¶â€”â€”è¢«ç§°ä¸ºâ€œè´´çº¸â€ï¼Œå®ƒä»¬é©±åŠ¨å…³é”®ä¿¡æ¯çš„æå–ã€æç‚¼å’Œé‡ç”¨ï¼Œåœ¨å¤šä¸ªæ¨ç†è½®æ¬¡ä¸­ååŒå·¥ä½œã€‚é€šè¿‡å¼•å…¥ä¸¤é˜¶æ®µä¼˜åŒ–ç­–ç•¥ï¼Œç»“åˆæ¨¡ä»¿å­¦ä¹ ä¸è‡ªæˆ‘æ”¹è¿›ï¼Œæˆ‘ä»¬çš„æ¡†æ¶è¿›ä¸€æ­¥æé«˜äº†æ•ˆç‡å’Œæ€§èƒ½ã€‚åœ¨AIME-24ã€AIME-25å’ŒOlymMATHä¸‰ä¸ªå…·æœ‰æŒ‘æˆ˜æ€§çš„æ•°å­¦æ¨ç†åŸºå‡†æµ‹è¯•ä¸Šçš„å¹¿æ³›è¯„ä¼°è¡¨æ˜ï¼ŒSticker-TTSåœ¨å¯æ¯”è¾ƒæ¨ç†é¢„ç®—ä¸‹ï¼ŒæŒç»­è¶…è¶ŠåŒ…æ‹¬è‡ªæˆ‘ä¸€è‡´æ€§å’Œé«˜çº§å¼ºåŒ–å­¦ä¹ æ–¹æ³•ç­‰å¼ºåŸºçº¿ï¼Œè¿™å‡¸æ˜¾äº†è´´çº¸å¼•å¯¼çš„å†å²ç»éªŒåˆ©ç”¨çš„æœ‰æ•ˆæ€§ã€‚æˆ‘ä»¬çš„ä»£ç å’Œæ•°æ®å¯ä»¥åœ¨[ç½‘ç«™é“¾æ¥]ï¼ˆ<a target="_blank" rel="noopener" href="https://github.com/RUCAIBox/Sticker-TTS%EF%BC%89%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/RUCAIBox/Sticker-TTSï¼‰æ‰¾åˆ°ã€‚</a></p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤§å‹æ¨ç†æ¨¡å‹ï¼ˆLRMsï¼‰åœ¨å¤æ‚æ¨ç†ä»»åŠ¡ä¸Šè¡¨ç°å‡ºå¼ºå¤§çš„æ€§èƒ½ï¼Œå¯é€šè¿‡å¢åŠ è®¡ç®—é¢„ç®—è¿›ä¸€æ­¥æé«˜æ€§èƒ½ã€‚</li>
<li>å½“å‰æµ‹è¯•æ—¶é—´æ‰©å±•æ–¹æ³•ä¸»è¦ä¾èµ–å†—ä½™é‡‡æ ·ï¼Œå¿½ç•¥äº†å†å²ç»éªŒåˆ©ç”¨ï¼Œé™åˆ¶äº†è®¡ç®—æ•ˆç‡ã€‚</li>
<li>Sticker-TTSæ¡†æ¶é€šè¿‡åè°ƒä¸‰ä¸ªåä½œçš„LRMsæ¥è¿­ä»£æ¢ç´¢å¹¶ä¼˜åŒ–è§£å†³æ–¹æ¡ˆï¼Œè¿™äº›è§£å†³æ–¹æ¡ˆç”±å†å²å°è¯•å¼•å¯¼ã€‚</li>
<li>æ¡†æ¶æ ¸å¿ƒä¸ºæç‚¼å‡ºçš„å…³é”®æ¡ä»¶ï¼ˆè´´çº¸ï¼‰ï¼Œé©±åŠ¨å…³é”®ä¿¡æ¯çš„æå–ã€æç‚¼å’Œé‡ç”¨ã€‚</li>
<li>å¼•å…¥ä¸¤é˜¶æ®µä¼˜åŒ–ç­–ç•¥ï¼Œç»“åˆæ¨¡ä»¿å­¦ä¹ ä¸è‡ªæˆ‘æ”¹è¿›ï¼Œæé«˜äº†æ¡†æ¶çš„æ•ˆç‡å’Œæ€§èƒ½ã€‚</li>
<li>åœ¨å¤šä¸ªæ•°å­¦æ¨ç†åŸºå‡†æµ‹è¯•ä¸Šï¼ŒSticker-TTSæŒç»­è¶…è¶Šç°æœ‰æ–¹æ³•ï¼Œæ˜¾ç¤ºå‡ºå…¶æœ‰æ•ˆæ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.05007">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-09\./crop_R1_Reasoning/2509.05007v1/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-09\./crop_R1_Reasoning/2509.05007v1/page_1_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-09\./crop_R1_Reasoning/2509.05007v1/page_5_0.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="ACE-RL-Adaptive-Constraint-Enhanced-Reward-for-Long-form-Generation-Reinforcement-Learning"><a href="#ACE-RL-Adaptive-Constraint-Enhanced-Reward-for-Long-form-Generation-Reinforcement-Learning" class="headerlink" title="ACE-RL: Adaptive Constraint-Enhanced Reward for Long-form Generation   Reinforcement Learning"></a>ACE-RL: Adaptive Constraint-Enhanced Reward for Long-form Generation   Reinforcement Learning</h2><p><strong>Authors:Jianghao Chen, Wei Sun, Qixiang Yin, Lingxing Kong, Zhixing Tan, Jiajun Zhang</strong></p>
<p>Large Language Models (LLMs) have demonstrated remarkable progress in long-context understanding, yet they face significant challenges in high-quality long-form generation. Existing studies primarily suffer from two limitations: (1) A heavy reliance on scarce, high-quality long-form response data for supervised fine-tuning (SFT) or for pairwise preference reward in reinforcement learning (RL). (2) Focus on coarse-grained quality optimization dimensions, such as relevance, coherence, and helpfulness, overlooking the fine-grained specifics inherent to diverse long-form generation scenarios. To address this issue, we propose a framework using Adaptive Constraint-Enhanced reward for long-form generation Reinforcement Learning (ACE-RL). ACE-RL first automatically deconstructs each instruction into a set of fine-grained, adaptive constraint criteria by identifying its underlying intents and demands. Subsequently, we design a reward mechanism that quantifies the quality of long-form responses based on their satisfaction over corresponding constraints, converting subjective quality evaluation into constraint verification. Finally, we utilize reinforcement learning to guide models toward superior long-form generation capabilities. Experimental results demonstrate that our ACE-RL framework significantly outperforms existing SFT and RL baselines by 20.70% and 7.32% on WritingBench, and our top-performing model even surpasses proprietary systems like GPT-4o by 7.10%, providing a more effective training paradigm for LLMs to generate high-quality content across diverse long-form generation scenarios. </p>
<blockquote>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨ç†è§£é•¿æ–‡æœ¬æ–¹é¢å–å¾—äº†æ˜¾è‘—çš„è¿›æ­¥ï¼Œä½†åœ¨é«˜è´¨é‡é•¿æ–‡æœ¬ç”Ÿæˆæ–¹é¢ä»é¢ä¸´é‡å¤§æŒ‘æˆ˜ã€‚ç°æœ‰ç ”ç©¶ä¸»è¦å­˜åœ¨ä¸¤ä¸ªå±€é™æ€§ï¼šï¼ˆ1ï¼‰è¿‡äºä¾èµ–ç¨€ç¼ºçš„é«˜è´¨é‡é•¿æ–‡æœ¬å“åº”æ•°æ®è¿›è¡Œç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰æˆ–åœ¨å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰ä¸­çš„æˆå¯¹åå¥½å¥–åŠ±ã€‚ï¼ˆ2ï¼‰å…³æ³¨ç²—ç²’åº¦çš„è´¨é‡ä¼˜åŒ–ç»´åº¦ï¼Œå¦‚ç›¸å…³æ€§ã€è¿è´¯æ€§å’Œæœ‰ç”¨æ€§ï¼Œå¿½è§†äº†é•¿æ–‡æœ¬ç”Ÿæˆåœºæ™¯ä¸­å›ºæœ‰çš„ç»†ç²’åº¦ç»†èŠ‚ã€‚ä¸ºè§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§è‡ªé€‚åº”çº¦æŸå¢å¼ºå¥–åŠ±çš„é•¿æ–‡æœ¬ç”Ÿæˆå¼ºåŒ–å­¦ä¹ æ¡†æ¶ï¼ˆACE-RLï¼‰ã€‚ACE-RLé¦–å…ˆè‡ªåŠ¨å°†æ¯æ¡æŒ‡ä»¤åˆ†è§£ä¸ºä¸€ç»„ç»†ç²’åº¦çš„è‡ªé€‚åº”çº¦æŸæ ‡å‡†ï¼Œé€šè¿‡è¯†åˆ«å…¶æ½œåœ¨æ„å›¾å’Œéœ€æ±‚ã€‚éšåï¼Œæˆ‘ä»¬è®¾è®¡äº†ä¸€ç§å¥–åŠ±æœºåˆ¶ï¼Œæ ¹æ®é•¿æ–‡æœ¬å“åº”å¯¹ç›¸åº”çº¦æŸçš„æ»¡è¶³ç¨‹åº¦æ¥é‡åŒ–å…¶è´¨é‡ï¼Œå°†ä¸»è§‚è´¨é‡è¯„ä»·è½¬åŒ–ä¸ºçº¦æŸéªŒè¯ã€‚æœ€åï¼Œæˆ‘ä»¬ä½¿ç”¨å¼ºåŒ–å­¦ä¹ æ¥æŒ‡å¯¼æ¨¡å‹å®ç°æ›´å‡ºè‰²çš„é•¿æ–‡æœ¬ç”Ÿæˆèƒ½åŠ›ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„ACE-RLæ¡†æ¶åœ¨WritingBenchä¸Šçš„è¡¨ç°æ˜¾è‘—ä¼˜äºç°æœ‰çš„SFTå’ŒRLåŸºçº¿ï¼Œåˆ†åˆ«æé«˜äº†20.70%å’Œ7.32%ï¼Œæˆ‘ä»¬è¡¨ç°æœ€ä½³çš„æ¨¡å‹ç”šè‡³è¶…è¿‡äº†å¦‚GPT-4oç­‰ä¸“æœ‰ç³»ç»Ÿï¼Œè¾¾åˆ°äº†7.10%ï¼Œä¸ºLLMç”Ÿæˆé«˜è´¨é‡å†…å®¹æä¾›äº†æ›´æœ‰æ•ˆçš„è®­ç»ƒèŒƒå¼ï¼Œé€‚ç”¨äºå„ç§é•¿æ–‡æœ¬ç”Ÿæˆåœºæ™¯ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.04903v1">PDF</a> Under review, our code is available at <a target="_blank" rel="noopener" href="https://github.com/ZNLP/ACE-RL">https://github.com/ZNLP/ACE-RL</a></p>
<p><strong>æ‘˜è¦</strong></p>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨ç†è§£é•¿æ–‡æœ¬æ–¹é¢å–å¾—äº†æ˜¾è‘—è¿›å±•ï¼Œä½†åœ¨é«˜è´¨é‡é•¿æ–‡æœ¬ç”Ÿæˆæ–¹é¢ä»é¢ä¸´æŒ‘æˆ˜ã€‚ç°æœ‰ç ”ç©¶ä¸»è¦å­˜åœ¨ä¸¤ä¸ªå±€é™æ€§ï¼šä¸€æ˜¯è¿‡åº¦ä¾èµ–ç¨€ç¼ºçš„é«˜è´¨é‡é•¿æ–‡æœ¬å“åº”æ•°æ®è¿›è¡Œç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰æˆ–å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰ä¸­çš„é…å¯¹åå¥½å¥–åŠ±ï¼›äºŒæ˜¯è¿‡äºå…³æ³¨ç²—ç•¥çš„è´¨é‡ä¼˜åŒ–ç»´åº¦ï¼Œå¦‚ç›¸å…³æ€§ã€è¿è´¯æ€§å’Œæœ‰ç”¨æ€§ï¼Œå¿½è§†äº†é•¿æ–‡æœ¬ç”Ÿæˆåœºæ™¯ä¸­å›ºæœ‰çš„ç»†å¾®å·®åˆ«ã€‚ä¸ºè§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä½¿ç”¨è‡ªé€‚åº”çº¦æŸå¢å¼ºå¥–åŠ±çš„é•¿æ–‡æœ¬ç”Ÿæˆå¼ºåŒ–å­¦ä¹ æ¡†æ¶ï¼ˆACE-RLï¼‰ã€‚ACE-RLé¦–å…ˆè‡ªåŠ¨å°†æ¯ä¸ªæŒ‡ä»¤åˆ†è§£ä¸ºä¸€ç»„ç²¾ç»†çš„ã€è‡ªé€‚åº”çº¦æŸæ ‡å‡†ï¼Œé€šè¿‡è¯†åˆ«å…¶æ½œåœ¨æ„å›¾å’Œéœ€æ±‚æ¥å®ç°ã€‚éšåï¼Œæˆ‘ä»¬è®¾è®¡äº†ä¸€ç§å¥–åŠ±æœºåˆ¶ï¼Œæ ¹æ®é•¿æ–‡æœ¬å“åº”å¯¹ç›¸åº”çº¦æŸçš„æ»¡è¶³ç¨‹åº¦æ¥é‡åŒ–å…¶è´¨é‡ï¼Œå°†ä¸»è§‚è´¨é‡è¯„ä»·è½¬åŒ–ä¸ºçº¦æŸéªŒè¯ã€‚æœ€åï¼Œæˆ‘ä»¬ä½¿ç”¨å¼ºåŒ–å­¦ä¹ æŒ‡å¯¼æ¨¡å‹å®ç°æ›´å‡ºè‰²çš„é•¿æ–‡æœ¬ç”Ÿæˆèƒ½åŠ›ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„ACE-RLæ¡†æ¶åœ¨WritingBenchä¸Šçš„è¡¨ç°æ˜¾è‘—ä¼˜äºç°æœ‰çš„SFTå’ŒRLåŸºå‡†æµ‹è¯•ï¼Œåˆ†åˆ«é«˜å‡º20.70%å’Œ7.32%ï¼Œæˆ‘ä»¬è¡¨ç°æœ€ä½³çš„æ¨¡å‹ç”šè‡³è¶…è¶Šäº†GPT-4oç­‰ä¸“æœ‰ç³»ç»Ÿï¼Œæé«˜äº†7.10%ï¼Œä¸ºLLMç”Ÿæˆé«˜è´¨é‡å†…å®¹æä¾›äº†æ›´æœ‰æ•ˆçš„è®­ç»ƒèŒƒå¼ã€‚</p>
<p><strong>å…³é”®è§è§£</strong></p>
<ol>
<li>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨é•¿æ–‡æœ¬ç”Ÿæˆæ–¹é¢é¢ä¸´æŒ‘æˆ˜ï¼Œå°¤å…¶æ˜¯åœ¨é«˜è´¨é‡å†…å®¹ç”Ÿæˆæ–¹é¢ã€‚</li>
<li>ç°æœ‰ç ”ç©¶ä¸»è¦å—åˆ¶äºå¯¹é«˜è´¨é‡é•¿æ–‡æœ¬å“åº”æ•°æ®çš„ä¾èµ–ä»¥åŠè¿‡äºç²—ç•¥çš„è´¨é‡ä¼˜åŒ–ç»´åº¦ã€‚</li>
<li>ACE-RLæ¡†æ¶é€šè¿‡è‡ªåŠ¨è§£ææŒ‡ä»¤ä¸ºç²¾ç»†çš„ã€è‡ªé€‚åº”çº¦æŸæ ‡å‡†æ¥è§£å†³è¿™äº›é—®é¢˜ã€‚</li>
<li>å¥–åŠ±æœºåˆ¶åŸºäºçº¦æŸæ»¡è¶³ç¨‹åº¦æ¥é‡åŒ–é•¿æ–‡æœ¬å“åº”çš„è´¨é‡ï¼Œå°†ä¸»è§‚è¯„ä»·è½¬åŒ–ä¸ºçº¦æŸéªŒè¯ã€‚</li>
<li>å¼ºåŒ–å­¦ä¹ ç”¨äºæŒ‡å¯¼æ¨¡å‹å®ç°æ›´å‡ºè‰²çš„é•¿æ–‡æœ¬ç”Ÿæˆèƒ½åŠ›ã€‚</li>
<li>ACE-RLæ¡†æ¶åœ¨WritingBenchä¸Šçš„è¡¨ç°ä¼˜äºç°æœ‰åŸºå‡†æµ‹è¯•ï¼Œæ˜¾ç¤ºå‡ºå…¶æœ‰æ•ˆæ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.04903">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-09\./crop_R1_Reasoning/2509.04903v1/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-09\./crop_R1_Reasoning/2509.04903v1/page_2_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-09\./crop_R1_Reasoning/2509.04903v1/page_2_1.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-09\./crop_R1_Reasoning/2509.04903v1/page_3_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-09\./crop_R1_Reasoning/2509.04903v1/page_4_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-09\./crop_R1_Reasoning/2509.04903v1/page_5_0.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="TalkToAgent-A-Human-centric-Explanation-of-Reinforcement-Learning-Agents-with-Large-Language-Models"><a href="#TalkToAgent-A-Human-centric-Explanation-of-Reinforcement-Learning-Agents-with-Large-Language-Models" class="headerlink" title="TalkToAgent: A Human-centric Explanation of Reinforcement Learning   Agents with Large Language Models"></a>TalkToAgent: A Human-centric Explanation of Reinforcement Learning   Agents with Large Language Models</h2><p><strong>Authors:Haechang Kim, Hao Chen, Can Li, Jong Min Lee</strong></p>
<p>Explainable Reinforcement Learning (XRL) has emerged as a promising approach in improving the transparency of Reinforcement Learning (RL) agents. However, there remains a gap between complex RL policies and domain experts, due to the limited comprehensibility of XRL results and isolated coverage of current XRL approaches that leave users uncertain about which tools to employ. To address these challenges, we introduce TalkToAgent, a multi-agent Large Language Models (LLM) framework that delivers interactive, natural language explanations for RL policies. The architecture with five specialized LLM agents (Coordinator, Explainer, Coder, Evaluator, and Debugger) enables TalkToAgent to automatically map user queries to relevant XRL tools and clarify an agentâ€™s actions in terms of either key state variables, expected outcomes, or counterfactual explanations. Moreover, our approach extends previous counterfactual explanations by deriving alternative scenarios from qualitative behavioral descriptions, or even new rule-based policies. We validated TalkToAgent on quadruple-tank process control problem, a well-known nonlinear control benchmark. Results demonstrated that TalkToAgent successfully mapped user queries into XRL tasks with high accuracy, and coder-debugger interactions minimized failures in counterfactual generation. Furthermore, qualitative evaluation confirmed that TalkToAgent effectively interpreted agentâ€™s actions and contextualized their meaning within the problem domain. </p>
<blockquote>
<p>å¯è§£é‡Šæ€§å¼ºåŒ–å­¦ä¹ ï¼ˆXRLï¼‰ä½œä¸ºä¸€ç§æœ‰å‰æ™¯çš„æ–¹æ³•ï¼Œåœ¨æé«˜å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰ä»£ç†çš„é€æ˜åº¦æ–¹é¢å±•ç°å‡ºå·¨å¤§æ½œåŠ›ã€‚ç„¶è€Œï¼Œç”±äºXRLç»“æœçš„å¯ç†è§£æ€§æœ‰é™ä»¥åŠå½“å‰XRLæ–¹æ³•çš„å­¤ç«‹è¦†ç›–ï¼Œä½¿å¾—å¤æ‚RLç­–ç•¥ä¸é¢†åŸŸä¸“å®¶ä¹‹é—´å­˜åœ¨å·®è·ï¼Œä½¿ç”¨æˆ·å¯¹ä½¿ç”¨å“ªç§å·¥å…·æ„Ÿåˆ°ä¸ç¡®å®šã€‚ä¸ºäº†åº”å¯¹è¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬å¼•å…¥äº†TalkToAgentï¼Œè¿™æ˜¯ä¸€ä¸ªå¤šä»£ç†çš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ¡†æ¶ï¼Œä¸ºRLç­–ç•¥æä¾›äº¤äº’å¼è‡ªç„¶è¯­è¨€è§£é‡Šã€‚è¯¥æ¶æ„åŒ…å«äº”ä¸ªä¸“ä¸šLLMä»£ç†ï¼ˆåè°ƒå™¨ã€è§£é‡Šå™¨ã€ç¼–ç å™¨ã€è¯„ä¼°å™¨å’Œè°ƒè¯•å™¨ï¼‰ï¼Œä½¿TalkToAgentèƒ½å¤Ÿè‡ªåŠ¨å°†ç”¨æˆ·æŸ¥è¯¢æ˜ å°„åˆ°ç›¸å…³çš„XRLå·¥å…·ï¼Œå¹¶æ ¹æ®å…³é”®çŠ¶æ€å˜é‡ã€é¢„æœŸç»“æœæˆ–åäº‹å®è§£é‡Šæ¥æ¾„æ¸…ä»£ç†çš„è¡ŒåŠ¨ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬çš„æ–¹æ³•é€šè¿‡ä»å®šæ€§è¡Œä¸ºæè¿°æˆ–ç”šè‡³æ–°çš„åŸºäºè§„åˆ™çš„ç­–ç•¥ä¸­æ¨å¯¼å‡ºæ›¿ä»£åœºæ™¯ï¼Œæ‰©å±•äº†ä¹‹å‰çš„åäº‹å®è§£é‡Šã€‚æˆ‘ä»¬åœ¨è‘—åçš„éçº¿æ€§æ§åˆ¶åŸºå‡†â€”â€”å››ç½è¿‡ç¨‹æ§åˆ¶é—®é¢˜ä¸ŠéªŒè¯äº†TalkToAgentã€‚ç»“æœè¡¨æ˜ï¼ŒTalkToAgentèƒ½å¤Ÿå‡†ç¡®åœ°å°†ç”¨æˆ·æŸ¥è¯¢æ˜ å°„åˆ°XRLä»»åŠ¡ï¼Œå¹¶ä¸”ç¼–ç å™¨å’Œè°ƒè¯•å™¨ä¹‹é—´çš„äº¤äº’å‡å°‘äº†åäº‹å®ç”Ÿæˆä¸­çš„å¤±è´¥ã€‚æ­¤å¤–ï¼Œå®šæ€§è¯„ä¼°è¯å®ï¼ŒTalkToAgentæœ‰æ•ˆåœ°è§£é‡Šäº†ä»£ç†çš„è¡ŒåŠ¨ï¼Œå¹¶å°†å®ƒä»¬çš„é—®é¢˜åŸŸèƒŒæ™¯è”ç³»èµ·æ¥ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.04809v1">PDF</a> 31 pages total</p>
<p><strong>Summary</strong>ï¼š<br>å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰çš„é€æ˜åº¦é—®é¢˜å¯é€šè¿‡è§£é‡Šæ€§å¼ºåŒ–å­¦ä¹ ï¼ˆXRLï¼‰æ”¹å–„ã€‚ç„¶è€Œï¼Œç”±äºXRLç»“æœçš„å¯ç†è§£æ€§æœ‰é™ä»¥åŠå½“å‰XRLæ–¹æ³•çš„å­¤ç«‹æ€§ï¼Œç”¨æˆ·å’Œé¢†åŸŸä¸“å®¶ä¹‹é—´ä»å­˜åœ¨å·®è·ã€‚ä¸ºè§£å†³è¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æ¨å‡ºäº†TalkToAgentï¼Œè¿™æ˜¯ä¸€ä¸ªå¤šæ™ºèƒ½ä½“çš„è‡ªç„¶è¯­è¨€æ¨¡å‹æ¡†æ¶ï¼Œèƒ½ä¸ºRLç­–ç•¥æä¾›äº¤äº’å¼è‡ªç„¶è¯­è¨€è§£é‡Šã€‚TalkToAgentæ‹¥æœ‰äº”ä¸ªä¸“ä¸šæ™ºèƒ½ä½“ï¼ˆåè°ƒå™¨ã€è§£é‡Šå™¨ã€ç¼–ç å‘˜ã€è¯„ä¼°å™¨å’Œè°ƒè¯•å™¨ï¼‰ï¼Œèƒ½è‡ªåŠ¨å°†ç”¨æˆ·æŸ¥è¯¢æ˜ å°„åˆ°ç›¸å…³çš„XRLå·¥å…·ï¼Œå¹¶èƒ½å°±å…³é”®çŠ¶æ€å˜é‡ã€é¢„æœŸç»“æœæˆ–åäº‹å®è§£é‡Šæ¥æ¾„æ¸…æ™ºèƒ½ä½“çš„è¡ŒåŠ¨ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬çš„æ–¹æ³•é€šè¿‡ä»å®šæ€§è¡Œä¸ºæè¿°æˆ–æ–°çš„è§„åˆ™åŸºç¡€ç­–ç•¥ä¸­æ¨å¯¼å‡ºæ›¿ä»£åœºæ™¯ï¼Œæ‰©å±•äº†ä¹‹å‰çš„åäº‹å®è§£é‡Šã€‚åœ¨å››å€æ°´ç®±è¿‡ç¨‹æ§åˆ¶é—®é¢˜ä¸ŠéªŒè¯äº†TalkToAgentçš„æœ‰æ•ˆæ€§ï¼Œå…¶æˆåŠŸåœ°å°†ç”¨æˆ·æŸ¥è¯¢æ˜ å°„åˆ°XRLä»»åŠ¡ä¸­ï¼Œä¸”ç¼–ç å‘˜-è°ƒè¯•å™¨äº’åŠ¨å‡å°‘äº†åäº‹å®ç”Ÿæˆä¸­çš„å¤±è´¥ã€‚æ­¤å¤–ï¼Œå®šæ€§è¯„ä¼°è¯å®TalkToAgentæœ‰æ•ˆåœ°è§£é‡Šäº†æ™ºèƒ½ä½“çš„è¡ŒåŠ¨å¹¶å°†å…¶ç½®äºé—®é¢˜åŸŸä¸­ã€‚</p>
<p><strong>Key Takeaways</strong>ï¼š</p>
<ol>
<li>TalkToAgentæ˜¯ä¸€ä¸ªå¤šæ™ºèƒ½ä½“çš„è‡ªç„¶è¯­è¨€æ¨¡å‹æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³è§£é‡Šæ€§å¼ºåŒ–å­¦ä¹ ï¼ˆXRLï¼‰åœ¨ç”¨æˆ·å’Œé¢†åŸŸä¸“å®¶ä¹‹é—´çš„é¸¿æ²Ÿé—®é¢˜ã€‚</li>
<li>å®ƒåŒ…å«äº”ä¸ªä¸“ä¸šæ™ºèƒ½ä½“ï¼Œèƒ½è‡ªåŠ¨å°†ç”¨æˆ·æŸ¥è¯¢æ˜ å°„åˆ°ç›¸å…³çš„XRLå·¥å…·ï¼Œæä¾›äº¤äº’å¼è‡ªç„¶è¯­è¨€è§£é‡Šã€‚</li>
<li>TalkToAgentå¯ä»¥æä¾›å…³äºæ™ºèƒ½ä½“è¡ŒåŠ¨çš„å…³é”®çŠ¶æ€å˜é‡ã€é¢„æœŸç»“æœæˆ–åäº‹å®è§£é‡Šçš„è§£é‡Šã€‚</li>
<li>è¯¥æ–¹æ³•æ‰©å±•äº†ä¹‹å‰çš„åäº‹å®è§£é‡Šï¼Œé€šè¿‡å®šæ€§è¡Œä¸ºæè¿°å’Œæ–°çš„è§„åˆ™åŸºç¡€ç­–ç•¥æ¥æ¨å¯¼æ›¿ä»£åœºæ™¯ã€‚</li>
<li>åœ¨å››å€æ°´ç®±è¿‡ç¨‹æ§åˆ¶é—®é¢˜ä¸Šçš„éªŒè¯æ˜¾ç¤ºï¼ŒTalkToAgentèƒ½æˆåŠŸåœ°å°†ç”¨æˆ·æŸ¥è¯¢æ˜ å°„åˆ°XRLä»»åŠ¡ä¸­ï¼Œå¹¶å…·æœ‰é«˜åº¦çš„å‡†ç¡®æ€§ã€‚</li>
<li>ç¼–ç å‘˜å’Œè°ƒè¯•å™¨ä¹‹é—´çš„äº’åŠ¨å‡å°‘äº†åäº‹å®ç”Ÿæˆä¸­çš„å¤±è´¥ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.04809">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-09\./crop_R1_Reasoning/2509.04809v1/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-09\./crop_R1_Reasoning/2509.04809v1/page_2_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-09\./crop_R1_Reasoning/2509.04809v1/page_3_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-09\./crop_R1_Reasoning/2509.04809v1/page_5_0.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="Mind-the-Gap-Evaluating-Model-and-Agentic-Level-Vulnerabilities-in-LLMs-with-Action-Graphs"><a href="#Mind-the-Gap-Evaluating-Model-and-Agentic-Level-Vulnerabilities-in-LLMs-with-Action-Graphs" class="headerlink" title="Mind the Gap: Evaluating Model- and Agentic-Level Vulnerabilities in   LLMs with Action Graphs"></a>Mind the Gap: Evaluating Model- and Agentic-Level Vulnerabilities in   LLMs with Action Graphs</h2><p><strong>Authors:Ilham Wicaksono, Zekun Wu, Theo King, Adriano Koshiyama, Philip Treleaven</strong></p>
<p>As large language models transition to agentic systems, current safety evaluation frameworks face critical gaps in assessing deployment-specific risks. We introduce AgentSeer, an observability-based evaluation framework that decomposes agentic executions into granular action and component graphs, enabling systematic agentic-situational assessment. Through cross-model validation on GPT-OSS-20B and Gemini-2.0-flash using HarmBench single turn and iterative refinement attacks, we demonstrate fundamental differences between model-level and agentic-level vulnerability profiles. Model-level evaluation reveals baseline differences: GPT-OSS-20B (39.47% ASR) versus Gemini-2.0-flash (50.00% ASR), with both models showing susceptibility to social engineering while maintaining logic-based attack resistance. However, agentic-level assessment exposes agent-specific risks invisible to traditional evaluation. We discover â€œagentic-onlyâ€ vulnerabilities that emerge exclusively in agentic contexts, with tool-calling showing 24-60% higher ASR across both models. Cross-model analysis reveals universal agentic patterns, agent transfer operations as highest-risk tools, semantic rather than syntactic vulnerability mechanisms, and context-dependent attack effectiveness, alongside model-specific security profiles in absolute ASR levels and optimal injection strategies. Direct attack transfer from model-level to agentic contexts shows degraded performance (GPT-OSS-20B: 57% human injection ASR; Gemini-2.0-flash: 28%), while context-aware iterative attacks successfully compromise objectives that failed at model-level, confirming systematic evaluation gaps. These findings establish the urgent need for agentic-situation evaluation paradigms, with AgentSeer providing the standardized methodology and empirical validation. </p>
<blockquote>
<p>éšç€å¤§å‹è¯­è¨€æ¨¡å‹å‘ä»£ç†ç³»ç»Ÿè¿‡æ¸¡ï¼Œå½“å‰çš„å®‰å…¨è¯„ä¼°æ¡†æ¶åœ¨è¯„ä¼°ç‰¹å®šéƒ¨ç½²é£é™©æ–¹é¢å­˜åœ¨é‡å¤§ç¼ºé™·ã€‚æˆ‘ä»¬å¼•å…¥äº†åŸºäºè§‚å¯ŸåŠ›çš„è¯„ä¼°æ¡†æ¶AgentSeerï¼Œå®ƒå°†ä»£ç†æ‰§è¡Œåˆ†è§£ä¸ºç»†ç²’åº¦çš„æ“ä½œå’Œç»„ä»¶å›¾ï¼Œä»è€Œèƒ½å¤Ÿè¿›è¡Œç³»ç»Ÿçš„ä»£ç†æƒ…å¢ƒè¯„ä¼°ã€‚æˆ‘ä»¬é€šè¿‡ä½¿ç”¨HarmBenchçš„å•è½®å’Œè¿­ä»£æ”¹è¿›æ”»å‡»å¯¹GPT-OSS-20Bå’ŒGemini-2.0-flashè¿›è¡Œè·¨æ¨¡å‹éªŒè¯ï¼Œå±•ç¤ºäº†æ¨¡å‹çº§å’Œä»£ç†çº§æ¼æ´åˆ†å¸ƒä¹‹é—´çš„åŸºæœ¬å·®å¼‚ã€‚æ¨¡å‹çº§è¯„ä¼°æ­ç¤ºäº†åŸºçº¿å·®å¼‚ï¼šGPT-OSS-20Bçš„ASRï¼ˆæ”»å‡»æˆåŠŸç‡ï¼‰ä¸º39.47%ï¼Œè€ŒGemini-2.0-flashçš„ASRä¸º50.00%ï¼Œä¸”ä¸¤ä¸ªæ¨¡å‹éƒ½è¡¨ç°å‡ºå¯¹ç¤¾ä¼šå·¥ç¨‹çš„æ˜“æ„Ÿæ€§ï¼ŒåŒæ—¶ä¿æŒåŸºäºé€»è¾‘çš„æ”»å‡»æŠµæŠ—èƒ½åŠ›ã€‚ç„¶è€Œï¼Œä»£ç†çº§è¯„ä¼°æš´éœ²äº†ä¸ä»£ç†ç›¸å…³çš„ç‰¹å®šé£é™©ï¼Œè¿™äº›é£é™©åœ¨ä¼ ç»Ÿçš„è¯„ä¼°ä¸­æ˜¯ä¸å¯è§çš„ã€‚æˆ‘ä»¬å‘ç°äº†ä¸€äº›â€œä»…ä¸ä»£ç†ç›¸å…³çš„â€æ¼æ´ï¼Œè¿™äº›æ¼æ´ä»…åœ¨ä»£ç†ç¯å¢ƒä¸­å‡ºç°ï¼Œå·¥å…·è°ƒç”¨çš„ASRåœ¨ä¸¤ç§æ¨¡å‹ä¸­é«˜å‡º24-60%ã€‚è·¨æ¨¡å‹åˆ†ææ­ç¤ºäº†é€šç”¨çš„ä»£ç†æ¨¡å¼ã€ä»£ç†è½¬ç§»æ“ä½œä½œä¸ºæœ€é«˜é£é™©å·¥å…·ã€è¯­ä¹‰è€Œéå¥æ³•æ¼æ´æœºåˆ¶ä»¥åŠä¸ä¸Šä¸‹æ–‡ç›¸å…³çš„æ”»å‡»æœ‰æ•ˆæ€§ä»¥åŠæ¨¡å‹ç‰¹å®šçš„å®‰å…¨é…ç½®æ–‡ä»¶åœ¨ç»å¯¹ASRæ°´å¹³å’Œæœ€ä½³æ³¨å…¥ç­–ç•¥æ–¹é¢ã€‚ç›´æ¥ä»æ¨¡å‹çº§åˆ«æ”»å‡»è½¬ç§»åˆ°ä»£ç†ç¯å¢ƒæ˜¾ç¤ºæ€§èƒ½ä¸‹é™ï¼ˆGPT-OSS-20Bï¼šäººç±»æ³¨å…¥ASRä¸º57%ï¼›Gemini-2.0-flashï¼š28%ï¼‰ï¼Œè€Œä¸Šä¸‹æ–‡æ„ŸçŸ¥çš„è¿­ä»£æ”»å‡»æˆåŠŸåœ°å®ç°äº†å¯¹æ¨¡å‹çº§åˆ«æœªèƒ½å®ç°çš„ç›®æ ‡çš„æ”»å‡»ï¼Œè¿™è¯å®äº†ç³»ç»Ÿè¯„ä¼°çš„å·®è·ã€‚è¿™äº›å‘ç°å‡¸æ˜¾äº†ä»£ç†æƒ…å¢ƒè¯„ä¼°æ¨¡å¼çš„è¿«åˆ‡éœ€è¦ï¼Œè€ŒAgentSeeræä¾›äº†æ ‡å‡†åŒ–çš„æ–¹æ³•å’Œå®è¯éªŒè¯ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.04802v1">PDF</a> </p>
<p><strong>æ‘˜è¦</strong></p>
<p>éšç€å¤§å‹è¯­è¨€æ¨¡å‹å‘ä»£ç†ç³»ç»Ÿè¿‡æ¸¡ï¼Œç°æœ‰çš„å®‰å…¨è¯„ä¼°æ¡†æ¶åœ¨è¯„ä¼°éƒ¨ç½²ç‰¹å®šé£é™©æ—¶å­˜åœ¨é‡å¤§ç¼ºé™·ã€‚æœ¬æ–‡ä»‹ç»äº†åŸºäºè§‚å¯ŸåŠ›çš„è¯„ä¼°æ¡†æ¶AgentSeerï¼Œå®ƒå°†ä»£ç†æ‰§è¡Œåˆ†è§£ä¸ºç»†ç²’åº¦çš„åŠ¨ä½œå’Œç»„ä»¶å›¾ï¼Œä»¥å®ç°ç³»ç»Ÿçš„ä»£ç†æƒ…å¢ƒè¯„ä¼°ã€‚é€šè¿‡å¯¹GPT-OSS-20Bå’ŒGemini-2.0-flashçš„è·¨æ¨¡å‹éªŒè¯ï¼Œå±•ç¤ºäº†æ¨¡å‹çº§å’Œä»£ç†çº§æ¼æ´åˆ†å¸ƒçš„æ ¹å·®å¼‚ã€‚æ¨¡å‹çº§åˆ«çš„è¯„ä¼°æ˜¾ç¤ºåŸºçº¿å·®å¼‚ï¼šGPT-OSS-20Bçš„æ”»å‡»æˆåŠŸç‡ï¼ˆASRï¼‰ä¸º39.47%ï¼Œè€ŒGemini-2.0-flashçš„ASRä¸º50.0%ã€‚ä¸¤è€…éƒ½æ˜¾ç¤ºå‡ºå¯¹ç¤¾ä¼šå·¥ç¨‹çš„è„†å¼±æ€§ï¼ŒåŒæ—¶ä¿æŒåŸºäºé€»è¾‘çš„æ”»å‡»æŠµæŠ—èƒ½åŠ›ã€‚ç„¶è€Œï¼Œä»£ç†çº§åˆ«çš„è¯„ä¼°æ­ç¤ºäº†ä¼ ç»Ÿè¯„ä¼°æ— æ³•å‘ç°çš„ä»£ç†ç‰¹å®šé£é™©ã€‚æˆ‘ä»¬å‘ç°â€œä»…ä»£ç†â€çš„æ¼æ´ä»…åœ¨ä»£ç†ç¯å¢ƒä¸­å‡ºç°ï¼Œå·¥å…·è°ƒç”¨åœ¨ä¸¤è€…ä¸­çš„ASRé«˜å‡º24-60%ã€‚è·¨æ¨¡å‹åˆ†ææ­ç¤ºäº†é€šç”¨çš„ä»£ç†æ¨¡å¼ï¼Œä»£ç†ä¼ è¾“æ“ä½œä½œä¸ºæœ€é«˜é£é™©å·¥å…·ï¼Œè¯­ä¹‰è€Œéè¯­æ³•æ¼æ´æœºåˆ¶ä»¥åŠä¸Šä¸‹æ–‡ç›¸å…³çš„æ”»å‡»æœ‰æ•ˆæ€§ï¼Œä»¥åŠæ¨¡å‹ç‰¹å®šçš„å®‰å…¨æ¦‚å†µï¼ˆç»å¯¹ASRæ°´å¹³å’Œæœ€ä½³æ³¨å…¥ç­–ç•¥ï¼‰ã€‚ç›´æ¥ä»æ¨¡å‹çº§åˆ«è½¬ç§»åˆ°ä»£ç†ç¯å¢ƒçš„æ”»å‡»æ˜¾ç¤ºæ€§èƒ½ä¸‹é™ï¼ˆGPT-OSS-20Bï¼šäººç±»æ³¨å…¥ASRä¸º57%ï¼›Gemini-2.0-flashä¸º28%ï¼‰ï¼Œè€Œä¸Šä¸‹æ–‡æ„ŸçŸ¥çš„è¿­ä»£æ”»å‡»æˆåŠŸå®ç°äº†å¯¹æ¨¡å‹çº§åˆ«å¤±è´¥ç›®æ ‡çš„æ”»å‡»ï¼Œè¯å®äº†ç³»ç»Ÿè¯„ä¼°çš„å·®è·ã€‚è¿™äº›å‘ç°å‡¸æ˜¾äº†å¯¹ä»£ç†æƒ…å¢ƒè¯„ä¼°èŒƒå¼çš„è¿«åˆ‡éœ€æ±‚ï¼Œè€ŒAgentSeeræä¾›äº†æ ‡å‡†åŒ–çš„æ–¹æ³•å’Œå®è¯éªŒè¯ã€‚</p>
<p><strong>å…³é”®è§è§£</strong></p>
<ol>
<li>å¤§å‹è¯­è¨€æ¨¡å‹å‘ä»£ç†ç³»ç»Ÿè¿‡æ¸¡è¿‡ç¨‹ä¸­ï¼Œç°æœ‰çš„å®‰å…¨è¯„ä¼°æ¡†æ¶å­˜åœ¨ç¼ºé™·ï¼Œæ— æ³•æœ‰æ•ˆè¯„ä¼°éƒ¨ç½²ç‰¹å®šçš„é£é™©ã€‚</li>
<li>AgentSeeræ¡†æ¶èƒ½å¤Ÿé€šè¿‡è§‚å¯ŸåŠ›è¯„ä¼°ä»£ç†ç³»ç»Ÿçš„å®‰å…¨æ€§ï¼Œå°†ä»£ç†æ‰§è¡Œåˆ†è§£ä¸ºç»†ç²’åº¦çš„åŠ¨ä½œå’Œç»„ä»¶å›¾ã€‚</li>
<li>æ¨¡å‹çº§å’Œä»£ç†çº§æ¼æ´åˆ†å¸ƒå­˜åœ¨æ ¹æœ¬å·®å¼‚ï¼Œéœ€è¦åŒºåˆ†å¯¹å¾…ã€‚</li>
<li>GPT-OSS-20Bå’ŒGemini-2.0-flashåœ¨æ¨¡å‹çº§åˆ«å­˜åœ¨ä¸åŒçš„å®‰å…¨åŸºçº¿ï¼Œä¸”éƒ½é¢ä¸´ç¤¾ä¼šå·¥ç¨‹æ”»å‡»çš„è„†å¼±æ€§ã€‚</li>
<li>ä»£ç†çº§åˆ«çš„è¯„ä¼°æ­ç¤ºäº†ä¼ ç»Ÿè¯„ä¼°æ— æ³•å‘ç°çš„â€œä»…ä»£ç†â€æ¼æ´å’Œä»£ç†ç‰¹å®šé£é™©ã€‚</li>
<li>è·¨æ¨¡å‹åˆ†æå‘ç°é€šç”¨çš„ä»£ç†æ¨¡å¼ï¼Œå¦‚ä»£ç†ä¼ è¾“æ“ä½œçš„é«˜é£é™©æ€§å’Œè¯­ä¹‰æ¼æ´æœºåˆ¶ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.04802">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-09\./crop_R1_Reasoning/2509.04802v1/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-09\./crop_R1_Reasoning/2509.04802v1/page_1_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-09\./crop_R1_Reasoning/2509.04802v1/page_2_0.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="Personality-as-a-Probe-for-LLM-Evaluation-Method-Trade-offs-and-Downstream-Effects"><a href="#Personality-as-a-Probe-for-LLM-Evaluation-Method-Trade-offs-and-Downstream-Effects" class="headerlink" title="Personality as a Probe for LLM Evaluation: Method Trade-offs and   Downstream Effects"></a>Personality as a Probe for LLM Evaluation: Method Trade-offs and   Downstream Effects</h2><p><strong>Authors:Gunmay Handa, Zekun Wu, Adriano Koshiyama, Philip Treleaven</strong></p>
<p>Personality manipulation in large language models (LLMs) is increasingly applied in customer service and agentic scenarios, yet its mechanisms and trade-offs remain unclear. We present a systematic study of personality control using the Big Five traits, comparing in-context learning (ICL), parameter-efficient fine-tuning (PEFT), and mechanistic steering (MS). Our contributions are fourfold. First, we construct a contrastive dataset with balanced high&#x2F;low trait responses, enabling effective steering vector computation and fair cross-method evaluation. Second, we introduce a unified evaluation framework based on within-run $\Delta$ analysis that disentangles, reasoning capability, agent performance, and demographic bias across MMLU, GAIA, and BBQ benchmarks. Third, we develop trait purification techniques to separate openness from conscientiousness, addressing representational overlap in trait encoding. Fourth, we propose a three-level stability framework that quantifies method-, trait-, and combination-level robustness, offering practical guidance under deployment constraints. Experiments on Gemma-2-2B-IT and LLaMA-3-8B-Instruct reveal clear trade-offs: ICL achieves strong alignment with minimal capability loss, PEFT delivers the highest alignment at the cost of degraded task performance, and MS provides lightweight runtime control with competitive effectiveness. Trait-level analysis shows openness as uniquely challenging, agreeableness as most resistant to ICL, and personality encoding consolidating around intermediate layers. Taken together, these results establish personality manipulation as a multi-level probe into behavioral representation, linking surface conditioning, parameter encoding, and activation-level steering, and positioning mechanistic steering as a lightweight alternative to fine-tuning for both deployment and interpretability. </p>
<blockquote>
<p>äººæ ¼æ“æ§åœ¨å¤§è§„æ¨¡è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä¸­çš„åº”ç”¨è¶Šæ¥è¶Šå¤šåœ°åº”ç”¨äºå®¢æˆ·æœåŠ¡å’Œä»£ç†åœºæ™¯ï¼Œä½†å…¶æœºåˆ¶å’Œæƒè¡¡å–èˆä»ä¸æ˜ç¡®ã€‚æˆ‘ä»¬å¯¹ä½¿ç”¨å¤§äº”ç‰¹è´¨è¿›è¡Œäººæ ¼æ§åˆ¶è¿›è¡Œäº†ç³»ç»Ÿç ”ç©¶ï¼Œå¯¹æ¯”äº†ä¸Šä¸‹æ–‡å­¦ä¹ ï¼ˆICLï¼‰ã€å‚æ•°æ•ˆç‡å¾®è°ƒï¼ˆPEFTï¼‰å’Œæœºåˆ¶æ€§å¼•å¯¼ï¼ˆMSï¼‰ã€‚æˆ‘ä»¬çš„è´¡çŒ®æœ‰å››ä¸ªã€‚é¦–å…ˆï¼Œæˆ‘ä»¬æ„å»ºäº†ä¸€ä¸ªå¯¹æ¯”æ•°æ®é›†ï¼Œå…¶ä¸­åŒ…å«å¹³è¡¡çš„é«˜&#x2F;ä½ç‰¹è´¨å“åº”ï¼Œä½¿å¾—èƒ½å¤Ÿæœ‰æ•ˆåœ°è®¡ç®—å¼•å¯¼å‘é‡å¹¶è¿›è¡Œè·¨æ–¹æ³•çš„å…¬å¹³è¯„ä¼°ã€‚å…¶æ¬¡ï¼Œæˆ‘ä»¬åŸºäºå†…éƒ¨è¿è¡Œ$\Delta$åˆ†æå¼•å…¥äº†ä¸€ä¸ªç»Ÿä¸€çš„è¯„ä¼°æ¡†æ¶ï¼Œè¯¥æ¡†æ¶èƒ½å¤Ÿè§£å¼€æ¨ç†èƒ½åŠ›ã€ä»£ç†æ€§èƒ½å’Œäººå£ç»Ÿè®¡åå·®åœ¨MMLUã€GAIAå’ŒBBQåŸºå‡†æµ‹è¯•ä¸­çš„å…³è”ã€‚ç¬¬ä¸‰ï¼Œæˆ‘ä»¬å¼€å‘äº†ç‰¹è´¨å‡€åŒ–æŠ€æœ¯ï¼Œä»¥åˆ†ç¦»å¼€æ”¾æ€§å’Œå°½è´£æ€§ï¼Œè§£å†³ç‰¹è´¨ç¼–ç ä¸­çš„ä»£è¡¨æ€§é‡å é—®é¢˜ã€‚ç¬¬å››ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªä¸‰çº§ç¨³å®šæ€§æ¡†æ¶ï¼Œè¯¥æ¡†æ¶é‡åŒ–æ–¹æ³•ã€ç‰¹è´¨å’Œç»„åˆå±‚é¢çš„ç¨³å¥æ€§ï¼Œä¸ºéƒ¨ç½²çº¦æŸä¸‹çš„å®é™…æ“ä½œæä¾›æŒ‡å¯¼ã€‚åœ¨Gemma-2-2B-ITå’ŒLLaMA-3-8B-Instructä¸Šçš„å®éªŒæ˜¾ç¤ºå‡ºæ˜ç¡®çš„æƒè¡¡ï¼šICLå®ç°å¼ºå¯¹é½ä¸”èƒ½åŠ›æŸå¤±æœ€å°ï¼ŒPEFTä»¥ä»»åŠ¡æ€§èƒ½ä¸‹é™ä¸ºä»£ä»·å®ç°æœ€é«˜å¯¹é½ï¼Œè€ŒMSæä¾›è½»é‡çº§çš„è¿è¡Œæ—¶æ§åˆ¶å¹¶å…·æœ‰ç«äº‰æ€§çš„æœ‰æ•ˆæ€§ã€‚ç‰¹è´¨å±‚é¢çš„åˆ†æè¡¨æ˜ï¼Œå¼€æ”¾æ€§å…·æœ‰ç‹¬ç‰¹æŒ‘æˆ˜æ€§ï¼Œå®œäººæ€§æœ€éš¾ä»¥é€šè¿‡ICLæ”¹å˜ï¼Œäººæ ¼ç¼–ç é›†ä¸­åœ¨ä¸­é—´å±‚ã€‚æ€»çš„æ¥è¯´ï¼Œè¿™äº›ç»“æœç¡®ç«‹äº†äººæ ¼æ“æ§ä½œä¸ºè¡Œä¸ºè¡¨ç¤ºçš„å¤šå±‚æ¬¡æ¢é’ˆï¼Œå°†è¡¨é¢æ¡ä»¶ã€å‚æ•°ç¼–ç å’Œæ¿€æ´»çº§å¼•å¯¼è”ç³»èµ·æ¥ï¼Œå¹¶å°†æœºåˆ¶æ€§å¼•å¯¼å®šä½ä¸ºéƒ¨ç½²å’Œå¯è§£é‡Šæ€§æ–¹é¢çš„è½»é‡çº§æ›¿ä»£æ–¹æ¡ˆã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.04794v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ç³»ç»Ÿç ”ç©¶äº†ä½¿ç”¨å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰è¿›è¡Œäººæ ¼æ§åˆ¶çš„æŠ€æœ¯ï¼ŒåŒ…æ‹¬ä¸Šä¸‹æ–‡å­¦ä¹ ï¼ˆICLï¼‰ã€å‚æ•°æ•ˆç‡å¾®è°ƒï¼ˆPEFTï¼‰å’Œæœºåˆ¶æ§åˆ¶ï¼ˆMSï¼‰ã€‚æ–‡ç« æ„å»ºäº†å¯¹æ¯”æ•°æ®é›†ï¼Œæå‡ºäº†ç»Ÿä¸€è¯„ä¼°æ¡†æ¶ï¼Œå‘å±•äº†ç‰¹è´¨å‡€åŒ–æŠ€æœ¯ï¼Œå¹¶æå‡ºäº†ä¸‰çº§ç¨³å®šæ€§æ¡†æ¶ï¼Œä»¥é‡åŒ–æ–¹æ³•ã€ç‰¹è´¨å’Œç»„åˆå±‚é¢çš„ç¨³å¥æ€§ã€‚å®éªŒç»“æœæ˜¾ç¤ºä¸åŒæ–¹æ³•å„æœ‰ä¼˜ç¼ºç‚¹ï¼Œå…¶ä¸­ICLå¯¹é½æ•ˆæœå¥½ä¸”èƒ½åŠ›æŸå¤±å°ï¼ŒPEFTå¯¹é½åº¦æœ€é«˜ä½†ä»»åŠ¡æ€§èƒ½ä¸‹é™ï¼ŒMSæä¾›è½»é‡çº§è¿è¡Œæ—¶æ§åˆ¶ä¸”æ•ˆæœè¾ƒå¥½ã€‚ç ”ç©¶ç»“æœè¡¨æ˜äººæ ¼æ“æ§æ˜¯ä¸€ä¸ªå¤šå±‚æ¬¡çš„è¡Œä¸ºè¡¨å¾æ¢é’ˆï¼Œæ¶‰åŠè¡¨é¢æ¡ä»¶ã€å‚æ•°ç¼–ç å’Œæ¿€æ´»å±‚é¢çš„æ“æ§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨å®¢æˆ·æœåŠ¡ç­‰åœºæ™¯ä¸­åº”ç”¨è¶Šæ¥è¶Šå¹¿æ³›çš„äººæ ¼æ“æ§æŠ€æœ¯ã€‚</li>
<li>é€šè¿‡ä½¿ç”¨å¯¹æ¯”æ•°æ®é›†ï¼Œè¿›è¡ŒåŸºäºBig Fiveç‰¹è´¨çš„äººæ ¼æ§åˆ¶ç ”ç©¶ã€‚</li>
<li>æ„å»ºç»Ÿä¸€è¯„ä¼°æ¡†æ¶ç”¨äºåˆ†ææ¨ç†èƒ½åŠ›ã€ä»£ç†æ€§èƒ½å’Œäººå£ç»Ÿè®¡åè§ã€‚</li>
<li>å‘å±•ç‰¹è´¨å‡€åŒ–æŠ€æœ¯ä»¥è§£å†³ç‰¹è´¨ç¼–ç ä¸­çš„ä»£è¡¨æ€§é‡å é—®é¢˜ã€‚</li>
<li>æå‡ºä¸‰çº§ç¨³å®šæ€§æ¡†æ¶ä»¥é‡åŒ–ä¸åŒæ–¹æ³•çš„ç¨³å¥æ€§ã€‚</li>
<li>å®éªŒç»“æœæ˜¾ç¤ºä¸åŒäººæ ¼æ“æ§æ–¹æ³•å„æœ‰ä¼˜ç¼ºç‚¹ï¼ŒåŒ…æ‹¬ICLã€PEFTå’ŒMSã€‚</li>
<li>äººæ ¼æ“æ§æ¶‰åŠè¡¨é¢æ¡ä»¶ã€å‚æ•°ç¼–ç å’Œæ¿€æ´»å±‚é¢çš„æ“æ§ï¼Œç ”ç©¶æä¾›å¯¹è¯¥é¢†åŸŸçš„æ·±å…¥ç†è§£ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.04794">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-09\./crop_R1_Reasoning/2509.04794v1/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-09\./crop_R1_Reasoning/2509.04794v1/page_2_0.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="WildScore-Benchmarking-MLLMs-in-the-Wild-Symbolic-Music-Reasoning"><a href="#WildScore-Benchmarking-MLLMs-in-the-Wild-Symbolic-Music-Reasoning" class="headerlink" title="WildScore: Benchmarking MLLMs in-the-Wild Symbolic Music Reasoning"></a>WildScore: Benchmarking MLLMs in-the-Wild Symbolic Music Reasoning</h2><p><strong>Authors:Gagan Mundada, Yash Vishe, Amit Namburi, Xin Xu, Zachary Novack, Julian McAuley, Junda Wu</strong></p>
<p>Recent advances in Multimodal Large Language Models (MLLMs) have demonstrated impressive capabilities across various vision-language tasks. However, their reasoning abilities in the multimodal symbolic music domain remain largely unexplored. We introduce WildScore, the first in-the-wild multimodal symbolic music reasoning and analysis benchmark, designed to evaluate MLLMsâ€™ capacity to interpret real-world music scores and answer complex musicological queries. Each instance in WildScore is sourced from genuine musical compositions and accompanied by authentic user-generated questions and discussions, capturing the intricacies of practical music analysis. To facilitate systematic evaluation, we propose a systematic taxonomy, comprising both high-level and fine-grained musicological ontologies. Furthermore, we frame complex music reasoning as multiple-choice question answering, enabling controlled and scalable assessment of MLLMsâ€™ symbolic music understanding. Empirical benchmarking of state-of-the-art MLLMs on WildScore reveals intriguing patterns in their visual-symbolic reasoning, uncovering both promising directions and persistent challenges for MLLMs in symbolic music reasoning and analysis. We release the dataset and code. </p>
<blockquote>
<p>è¿‘æœŸå¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰çš„è¿›æ­¥åœ¨å„ç§è§†è§‰è¯­è¨€ä»»åŠ¡ä¸­è¡¨ç°å‡ºäº†ä»¤äººå°è±¡æ·±åˆ»çš„èƒ½åŠ›ã€‚ç„¶è€Œï¼Œå®ƒä»¬åœ¨å¤šæ¨¡æ€ç¬¦å·éŸ³ä¹é¢†åŸŸçš„æ¨ç†èƒ½åŠ›ä»æœªå¾—åˆ°å……åˆ†çš„æ¢ç´¢ã€‚æˆ‘ä»¬å¼•å…¥äº†WildScoreï¼Œè¿™æ˜¯é¦–ä¸ªå®é™…åœºæ™¯ä¸­çš„å¤šæ¨¡æ€ç¬¦å·éŸ³ä¹æ¨ç†ä¸åˆ†æåŸºå‡†æµ‹è¯•ï¼Œæ—¨åœ¨è¯„ä¼°MLLMsè§£è¯»ç°å®éŸ³ä¹ä¹è°±å’Œå›ç­”å¤æ‚éŸ³ä¹å­¦é—®é¢˜çš„èƒ½åŠ›ã€‚WildScoreä¸­çš„æ¯ä¸ªå®ä¾‹éƒ½æ¥æºäºçœŸå®çš„éŸ³ä¹ä½œå“ï¼Œå¹¶é™„æœ‰çœŸå®çš„ç”¨æˆ·ç”Ÿæˆçš„é—®é¢˜å’Œè®¨è®ºï¼Œæ•æ‰å®é™…éŸ³ä¹åˆ†æçš„ç»†å¾®ä¹‹å¤„ã€‚ä¸ºäº†ä¿ƒè¿›ç³»ç»Ÿè¯„ä¼°ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªç³»ç»Ÿçš„åˆ†ç±»æ³•ï¼ŒåŒ…æ‹¬é«˜çº§å’Œç²¾ç»†çš„éŸ³ä¹å­¦æœ¬ä½“ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å°†å¤æ‚çš„éŸ³ä¹æ¨ç†æ„å»ºä¸ºé€‰æ‹©é¢˜å›ç­”çš„å½¢å¼ï¼Œä»¥å®ç°å¯¹MLLMsç¬¦å·éŸ³ä¹ç†è§£çš„å—æ§å’Œå¯æ‰©å±•è¯„ä¼°ã€‚åœ¨WildScoreä¸Šå¯¹æœ€æ–°MLLMsçš„å®è¯åŸºå‡†æµ‹è¯•æ­ç¤ºäº†å®ƒä»¬åœ¨è§†è§‰ç¬¦å·æ¨ç†ä¸­çš„æœ‰è¶£æ¨¡å¼ï¼Œæ—¢æ­ç¤ºäº†MLLMsåœ¨ç¬¦å·éŸ³ä¹æ¨ç†å’Œåˆ†ææ–¹é¢çš„æœ‰å‰é€”çš„æ–¹å‘ï¼Œä¹Ÿæ­ç¤ºäº†æŒç»­å­˜åœ¨çš„æŒ‘æˆ˜ã€‚æˆ‘ä»¬å…¬å¼€äº†æ•°æ®é›†å’Œä»£ç ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.04744v1">PDF</a> </p>
<p><strong>Summary</strong>ï¼š<br>æœ€æ–°è¿›å±•çš„å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰åœ¨å„ç§è§†è§‰è¯­è¨€ä»»åŠ¡ä¸­è¡¨ç°å‡ºå¼ºå¤§çš„èƒ½åŠ›ï¼Œä½†åœ¨å¤šæ¨¡æ€ç¬¦å·éŸ³ä¹é¢†åŸŸçš„æ¨ç†èƒ½åŠ›å°šæœªå¾—åˆ°å……åˆ†æ¢ç´¢ã€‚æœ¬æ–‡ä»‹ç»äº†WildScoreï¼Œé¦–ä¸ªé¢å‘çœŸå®ä¸–ç•Œçš„å¤šæ¨¡æ€ç¬¦å·éŸ³ä¹æ¨ç†ä¸åˆ†æåŸºå‡†æµ‹è¯•ï¼Œæ—¨åœ¨è¯„ä¼°MLLMsè§£è¯»çœŸå®ä¸–ç•Œä¹è°±å’Œå›ç­”å¤æ‚éŸ³ä¹å­¦æŸ¥è¯¢çš„èƒ½åŠ›ã€‚WildScoreçš„æ¯ä¸ªå®ä¾‹éƒ½æ¥æºäºçœŸå®çš„éŸ³ä¹ä½œå“ï¼Œå¹¶é™„æœ‰ç”¨æˆ·ç”Ÿæˆçš„é—®é¢˜å’Œè®¨è®ºï¼Œæ•æ‰å®é™…éŸ³ä¹åˆ†æçš„ç»†èŠ‚ã€‚æœ¬æ–‡è¿˜æå‡ºäº†ä¸€ç§ç³»ç»Ÿçš„åˆ†ç±»æ³•ï¼ŒåŒ…æ‹¬é«˜çº§å’Œç²¾ç»†çš„éŸ³ä¹å­¦æœ¬ä½“ï¼Œä»¥ä¿ƒè¿›ç³»ç»Ÿè¯„ä¼°ã€‚é€šè¿‡å°†å¤æ‚çš„éŸ³ä¹æ¨ç†ä½œä¸ºé€‰æ‹©é¢˜æ¥å›ç­”ï¼Œå®ç°äº†å¯¹MLLMsç¬¦å·éŸ³ä¹ç†è§£çš„å—æ§å’Œå¯æ‰©å±•è¯„ä¼°ã€‚å¯¹æœ€æ–°MLLMsåœ¨WildScoreä¸Šçš„å®è¯åŸºå‡†æµ‹è¯•æ­ç¤ºäº†å®ƒä»¬åœ¨è§†è§‰ç¬¦å·æ¨ç†ä¸­çš„æœ‰è¶£æ¨¡å¼ï¼Œä¸ºMLLMsåœ¨ç¬¦å·éŸ³ä¹æ¨ç†å’Œåˆ†æä¸­æ­ç¤ºäº†æœ‰å‰é€”çš„æ–¹å‘å’ŒæŒç»­å­˜åœ¨çš„æŒ‘æˆ˜ã€‚</p>
<p><strong>Key Takeaways</strong>ï¼š</p>
<ol>
<li>å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰åœ¨è§†è§‰è¯­è¨€ä»»åŠ¡ä¸­è¡¨ç°å‡ºå¼ºå¤§çš„èƒ½åŠ›ã€‚</li>
<li>WildScoreæ˜¯é¦–ä¸ªé¢å‘çœŸå®ä¸–ç•Œçš„å¤šæ¨¡æ€ç¬¦å·éŸ³ä¹æ¨ç†ä¸åˆ†æåŸºå‡†æµ‹è¯•ã€‚</li>
<li>WildScoreå®ä¾‹æºäºçœŸå®éŸ³ä¹ä½œå“ï¼Œå¹¶é™„æœ‰ç”¨æˆ·ç”Ÿæˆçš„é—®é¢˜å’Œè®¨è®ºã€‚</li>
<li>æå‡ºäº†ç³»ç»Ÿçš„åˆ†ç±»æ³•ï¼ŒåŒ…æ‹¬é«˜çº§å’Œç²¾ç»†çš„éŸ³ä¹å­¦æœ¬ä½“ï¼Œä»¥ä¿ƒè¿›ç³»ç»Ÿè¯„ä¼°ã€‚</li>
<li>å¤æ‚éŸ³ä¹æ¨ç†è¢«å½¢å¼åŒ–ä¸ºé€‰æ‹©é¢˜å›ç­”ï¼Œä»¥å®ç°ç³»ç»Ÿè¯„ä¼°çš„å—æ§å’Œå¯æ‰©å±•æ€§ã€‚</li>
<li>å®è¯åŸºå‡†æµ‹è¯•æ­ç¤ºäº†MLLMsåœ¨ç¬¦å·éŸ³ä¹æ¨ç†ä¸­çš„æœ‰è¶£æ¨¡å¼ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.04744">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-09\./crop_R1_Reasoning/2509.04744v1/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-09\./crop_R1_Reasoning/2509.04744v1/page_2_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-09\./crop_R1_Reasoning/2509.04744v1/page_3_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-09\./crop_R1_Reasoning/2509.04744v1/page_4_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-09\./crop_R1_Reasoning/2509.04744v1/page_4_1.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-09\./crop_R1_Reasoning/2509.04744v1/page_5_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-09\./crop_R1_Reasoning/2509.04744v1/page_5_1.jpg" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="Evaluating-NL2SQL-via-SQL2NL"><a href="#Evaluating-NL2SQL-via-SQL2NL" class="headerlink" title="Evaluating NL2SQL via SQL2NL"></a>Evaluating NL2SQL via SQL2NL</h2><p><strong>Authors:Mohammadtaher Safarzadeh, Afshin Oroojlooyjadid, Dan Roth</strong></p>
<p>Robust evaluation in the presence of linguistic variation is key to understanding the generalization capabilities of Natural Language to SQL (NL2SQL) models, yet existing benchmarks rarely address this factor in a systematic or controlled manner. We propose a novel schema-aligned paraphrasing framework that leverages SQL-to-NL (SQL2NL) to automatically generate semantically equivalent, lexically diverse queries while maintaining alignment with the original schema and intent. This enables the first targeted evaluation of NL2SQL robustness to linguistic variation in isolation-distinct from prior work that primarily investigates ambiguity or schema perturbations. Our analysis reveals that state-of-the-art models are far more brittle than standard benchmarks suggest. For example, LLaMa3.3-70B exhibits a 10.23% drop in execution accuracy (from 77.11% to 66.9%) on paraphrased Spider queries, while LLaMa3.1-8B suffers an even larger drop of nearly 20% (from 62.9% to 42.5%). Smaller models (e.g., GPT-4o mini) are disproportionately affected. We also find that robustness degradation varies significantly with query complexity, dataset, and domain â€“ highlighting the need for evaluation frameworks that explicitly measure linguistic generalization to ensure reliable performance in real-world settings. </p>
<blockquote>
<p>åœ¨å­˜åœ¨è¯­è¨€å˜ä½“çš„æƒ…å†µä¸‹è¿›è¡Œç¨³å¥è¯„ä¼°æ˜¯äº†è§£è‡ªç„¶è¯­è¨€åˆ°SQLï¼ˆNL2SQLï¼‰æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›çš„å…³é”®ï¼Œä½†ç°æœ‰åŸºå‡†æµ‹è¯•å¾ˆå°‘ä»¥ç³»ç»Ÿæˆ–å—æ§çš„æ–¹å¼å¤„ç†è¿™ä¸€å› ç´ ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°å‹çš„æ¨¡å¼å¯¹é½çš„æ”¹è¿°æ¡†æ¶ï¼Œè¯¥æ¡†æ¶åˆ©ç”¨SQLåˆ°è‡ªç„¶è¯­è¨€ï¼ˆSQL2NLï¼‰è‡ªåŠ¨ç”Ÿæˆè¯­ä¹‰ç­‰æ•ˆã€è¯æ±‡ä¸°å¯Œçš„æŸ¥è¯¢ï¼ŒåŒæ—¶ä¿æŒä¸åŸå§‹æ¨¡å¼å’Œæ„å›¾çš„å¯¹é½ã€‚è¿™ä½¿å¾—é¦–æ¬¡é’ˆå¯¹NL2SQLå¯¹è¯­è¨€å˜åŒ–çš„ç¨³å¥æ€§è¿›è¡Œå®šå‘è¯„ä¼°ï¼Œä¸ä¸»è¦è°ƒæŸ¥æ¨¡ç³Šæ€§æˆ–æ¨¡å¼æ‰°åŠ¨çš„å…ˆå‰å·¥ä½œç›¸åŒºåˆ«ã€‚æˆ‘ä»¬çš„åˆ†æè¡¨æ˜ï¼Œæœ€å…ˆè¿›æ¨¡å‹çš„ç¨³å¥æ€§è¿œè¿œä½äºæ ‡å‡†åŸºå‡†æµ‹è¯•æ‰€æ˜¾ç¤ºçš„æƒ…å†µã€‚ä¾‹å¦‚ï¼ŒLLaMa3.3-70Båœ¨æ”¹è¿°çš„SpideræŸ¥è¯¢ä¸Šçš„æ‰§è¡Œç²¾åº¦ä¸‹é™äº†10.23%ï¼ˆä»77.11%é™è‡³66.9%ï¼‰ï¼Œè€ŒLLaMa3.1-8Bçš„ä¸‹é™å¹…åº¦æ›´å¤§ï¼Œè¿‘ä¹20%ï¼ˆä»62.9%é™è‡³42.5%ï¼‰ã€‚è¾ƒå°çš„æ¨¡å‹ï¼ˆä¾‹å¦‚GPT-4o miniï¼‰å—åˆ°çš„å½±å“å°¤ä¸ºä¸¥é‡ã€‚æˆ‘ä»¬è¿˜å‘ç°ï¼Œç¨³å¥æ€§é€€åŒ–ä¸æŸ¥è¯¢å¤æ‚æ€§ã€æ•°æ®é›†å’Œé¢†åŸŸä¹‹é—´æœ‰ç€æ˜¾è‘—å·®å¼‚â€”â€”è¿™å‡¸æ˜¾äº†éœ€è¦è¯„ä¼°æ¡†æ¶æ˜ç¡®æµ‹é‡è¯­è¨€æ³›åŒ–èƒ½åŠ›ï¼Œä»¥ç¡®ä¿åœ¨çœŸå®ç¯å¢ƒä¸­çš„å¯é æ€§èƒ½ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.04657v1">PDF</a> Accepted to EMNLP 2025</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡å…³æ³¨è‡ªç„¶è¯­è¨€åˆ°SQLï¼ˆNL2SQLï¼‰æ¨¡å‹çš„é€šç”¨åŒ–èƒ½åŠ›è¯„ä»·ï¼Œç‰¹åˆ«æ˜¯åœ¨å­˜åœ¨è¯­è¨€å˜å¼‚çš„æƒ…å†µä¸‹ã€‚æ–‡ç« æå‡ºäº†ä¸€ç§æ–°çš„æ¨¡å¼å¯¹é½çš„æ”¹è¿°æ¡†æ¶ï¼Œè¯¥æ¡†æ¶åˆ©ç”¨SQLåˆ°è‡ªç„¶è¯­è¨€ï¼ˆSQL2NLï¼‰è‡ªåŠ¨ç”Ÿæˆè¯­ä¹‰ç­‰æ•ˆã€è¯æ±‡ä¸°å¯Œçš„æŸ¥è¯¢ï¼ŒåŒæ—¶ä¿æŒä¸åŸå§‹æ¨¡å¼å’Œæ„å›¾çš„å¯¹é½ã€‚è¯¥æ¡†æ¶ä½¿é¦–æ¬¡å¯¹NL2SQLåœ¨è¯­è¨€å˜å¼‚æ–¹é¢çš„ç¨³å¥æ€§è¿›è¡Œæœ‰é’ˆå¯¹æ€§çš„è¯„ä¼°æˆä¸ºå¯èƒ½ï¼Œä¸ä¸»è¦å…³æ³¨æ­§ä¹‰æˆ–æ¨¡å¼æ‰°åŠ¨çš„ç ”ç©¶ä¸åŒã€‚åˆ†æè¡¨æ˜ï¼Œæœ€å…ˆè¿›çš„æ¨¡å‹æ¯”æ ‡å‡†åŸºå‡†æµ‹è¯•æ‰€æ˜¾ç¤ºçš„è¦è„†å¼±å¾—å¤šã€‚ä¾‹å¦‚ï¼ŒLLaMa3.3-70Båœ¨æ”¹è¿°çš„SpideræŸ¥è¯¢ä¸Šæ‰§è¡Œç²¾åº¦ä¸‹é™äº†10.23%ï¼ˆä»77.11%é™è‡³66.9%ï¼‰ï¼ŒLLaMa3.1-8Bçš„ä¸‹é™å¹…åº¦æ›´å¤§ï¼ˆä»62.9%é™è‡³42.5%ï¼‰ã€‚è¾ƒå°çš„æ¨¡å‹å—å½±å“å°¤ä¸ºä¸¥é‡ã€‚æ­¤å¤–ï¼Œè¿˜å‘ç°ç¨³å¥æ€§é€€åŒ–ä¸æŸ¥è¯¢å¤æ‚æ€§ã€æ•°æ®é›†å’Œé¢†åŸŸå˜åŒ–å¯†åˆ‡ç›¸å…³ï¼Œè¿™çªæ˜¾äº†éœ€è¦è¯„ä¼°æ¡†æ¶æ˜ç¡®æµ‹é‡è¯­è¨€æ³›åŒ–ä»¥ç¡®ä¿åœ¨çœŸå®ç¯å¢ƒä¸­çš„å¯é æ€§èƒ½ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>è¯­è¨€å˜å¼‚æ˜¯è¯„ä¼°NL2SQLæ¨¡å‹é€šç”¨åŒ–èƒ½åŠ›çš„é‡è¦å› ç´ ï¼Œç°æœ‰åŸºå‡†æµ‹è¯•å¾ˆå°‘ä»¥ç³»ç»Ÿæˆ–å—æ§çš„æ–¹å¼å¤„ç†è¿™ä¸€å› ç´ ã€‚</li>
<li>æå‡ºäº†ä¸€ç§æ–°çš„æ¨¡å¼å¯¹é½æ”¹è¿°æ¡†æ¶ï¼Œåˆ©ç”¨SQL2NLç”Ÿæˆè¯­ä¹‰ç­‰æ•ˆã€è¯æ±‡ä¸°å¯Œçš„æŸ¥è¯¢ï¼ŒåŒæ—¶ä¿æŒä¸åŸå§‹æ¨¡å¼æ„å›¾çš„å¯¹é½ã€‚</li>
<li>æ–‡ç« å¯¹NL2SQLæ¨¡å‹åœ¨è¯­è¨€å˜å¼‚æ–¹é¢çš„ç¨³å¥æ€§è¿›è¡Œäº†é¦–æ¬¡æœ‰é’ˆå¯¹æ€§çš„è¯„ä¼°ã€‚</li>
<li>æœ€å…ˆè¿›çš„æ¨¡å‹åœ¨æ”¹è¿°æŸ¥è¯¢ä¸Šçš„è¡¨ç°æ¯”æ ‡å‡†åŸºå‡†æµ‹è¯•æ‰€æ˜¾ç¤ºçš„æ›´ä¸ºè„†å¼±ã€‚</li>
<li>ä¸åŒæ¨¡å‹å¯¹è¯­è¨€å˜å¼‚çš„æ•æ„Ÿåº¦ä¸åŒï¼Œè¾ƒå°çš„æ¨¡å‹å—å½±å“å°¤ä¸ºä¸¥é‡ã€‚</li>
<li>ç¨³å¥æ€§é€€åŒ–ä¸æŸ¥è¯¢å¤æ‚æ€§ã€æ•°æ®é›†å’Œé¢†åŸŸå˜åŒ–å¯†åˆ‡ç›¸å…³ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.04657">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-09\./crop_R1_Reasoning/2509.04657v1/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-09\./crop_R1_Reasoning/2509.04657v1/page_2_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-09\./crop_R1_Reasoning/2509.04657v1/page_3_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-09\./crop_R1_Reasoning/2509.04657v1/page_4_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-09\./crop_R1_Reasoning/2509.04657v1/page_5_0.jpg" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1><h2 id="AraHalluEval-A-Fine-grained-Hallucination-Evaluation-Framework-for-Arabic-LLMs"><a href="#AraHalluEval-A-Fine-grained-Hallucination-Evaluation-Framework-for-Arabic-LLMs" class="headerlink" title="AraHalluEval: A Fine-grained Hallucination Evaluation Framework for   Arabic LLMs"></a>AraHalluEval: A Fine-grained Hallucination Evaluation Framework for   Arabic LLMs</h2><p><strong>Authors:Aisha Alansari, Hamzah Luqman</strong></p>
<p>Recently, extensive research on the hallucination of the large language models (LLMs) has mainly focused on the English language. Despite the growing number of multilingual and Arabic-specific LLMs, evaluating LLMsâ€™ hallucination in the Arabic context remains relatively underexplored. The knowledge gap is particularly pressing given Arabicâ€™s widespread use across many regions and its importance in global communication and media. This paper presents the first comprehensive hallucination evaluation of Arabic and multilingual LLMs on two critical Arabic natural language generation tasks: generative question answering (GQA) and summarization. This study evaluates a total of 12 LLMs, including 4 Arabic pre-trained models, 4 multilingual models, and 4 reasoning-based models. To assess the factual consistency and faithfulness of LLMsâ€™ outputs, we developed a fine-grained hallucination evaluation framework consisting of 12 fine-grained hallucination indicators that represent the varying characteristics of each task. The results reveal that factual hallucinations are more prevalent than faithfulness errors across all models and tasks. Notably, the Arabic pre-trained model Allam consistently demonstrates lower hallucination rates than multilingual models and a comparative performance with reasoning-based models. The code is available at: \href{<a target="_blank" rel="noopener" href="https://github.com/aishaalansari57/AraHalluEval%7D%7BGithub">https://github.com/aishaalansari57/AraHalluEval}{Github</a> link}. </p>
<blockquote>
<p>æœ€è¿‘ï¼Œå…³äºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„å¹»è§‰çš„å¹¿æ³›ç ”ç©¶ä¸»è¦é›†ä¸­åœ¨è‹±è¯­ä¸Šã€‚å°½ç®¡å¤šè¯­è¨€åŒ–å’Œé˜¿æ‹‰ä¼¯è¯­è¨€ç‰¹å®šçš„LLMæ•°é‡ä¸æ–­å¢åŠ ï¼Œä½†åœ¨é˜¿æ‹‰ä¼¯è¯­å¢ƒä¸‹è¯„ä¼°LLMçš„å¹»è§‰ä»ç„¶ç›¸å¯¹ç¼ºä¹ç ”ç©¶ã€‚è€ƒè™‘åˆ°é˜¿æ‹‰ä¼¯è¯­åœ¨è®¸å¤šåœ°åŒºçš„å¹¿æ³›ä½¿ç”¨åŠå…¶åœ¨å…¨çƒé€šä¿¡å’Œåª’ä½“ä¸­çš„é‡è¦æ€§ï¼ŒçŸ¥è¯†å·®è·å°¤ä¸ºç´§è¿«ã€‚æœ¬æ–‡é¦–æ¬¡å¯¹é˜¿æ‹‰ä¼¯è¯­å’Œå¤šè¯­è¨€LLMçš„å¹»è§‰è¿›è¡Œäº†å…¨é¢çš„è¯„ä¼°ï¼Œæ¶‰åŠä¸¤ä¸ªå…³é”®çš„é˜¿æ‹‰ä¼¯è¯­è‡ªç„¶è¯­è¨€ç”Ÿæˆä»»åŠ¡ï¼šç”Ÿæˆæ€§é—®é¢˜å›ç­”ï¼ˆGQAï¼‰å’Œæ‘˜è¦ã€‚æœ¬ç ”ç©¶å…±è¯„ä¼°äº†12ä¸ªLLMï¼ŒåŒ…æ‹¬4ä¸ªé˜¿æ‹‰ä¼¯è¯­é¢„è®­ç»ƒæ¨¡å‹ã€4ä¸ªå¤šè¯­è¨€æ¨¡å‹å’Œ4ä¸ªåŸºäºæ¨ç†çš„æ¨¡å‹ã€‚ä¸ºäº†è¯„ä¼°LLMè¾“å‡ºçš„äº‹å®ä¸€è‡´æ€§å’Œå¿ å®åº¦ï¼Œæˆ‘ä»¬å¼€å‘äº†ä¸€ä¸ªç²¾ç»†çš„å¹»è§‰è¯„ä¼°æ¡†æ¶ï¼ŒåŒ…å«12ä¸ªç²¾ç»†çš„å¹»è§‰æŒ‡æ ‡ï¼Œä»£è¡¨æ¯ä¸ªä»»åŠ¡çš„ä¸åŒç‰¹ç‚¹ã€‚ç»“æœè¡¨æ˜ï¼Œäº‹å®å¹»è§‰åœ¨æ‰€æœ‰æ¨¡å‹å’Œä»»åŠ¡ä¸­æ¯”å¿ å®åº¦é”™è¯¯æ›´ä¸ºæ™®éã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œé˜¿æ‹‰ä¼¯è¯­é¢„è®­ç»ƒæ¨¡å‹Allamçš„å¹»è§‰ç‡å§‹ç»ˆä½äºå¤šè¯­è¨€æ¨¡å‹ï¼Œä¸åŸºäºæ¨ç†çš„æ¨¡å‹ç›¸æ¯”è¡¨ç°ã€‚ä»£ç å¯åœ¨Githubé“¾æ¥ï¼š<a target="_blank" rel="noopener" href="https://github.com/aishaalansari57/AraHalluEval">https://github.com/aishaalansari57/AraHalluEval</a>å¤„è·å–ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.04656v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>è¯¥æ–‡é¦–æ¬¡å…¨é¢è¯„ä¼°äº†é˜¿æ‹‰ä¼¯æ–‡å’Œè·¨è¯­è¨€çš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨ç”Ÿæˆé—®é¢˜å›ç­”ï¼ˆGQAï¼‰å’Œæ‘˜è¦ç”Ÿæˆä¸¤ä¸ªå…³é”®ä»»åŠ¡ä¸­çš„å¹»è§‰ç°è±¡ã€‚ç ”ç©¶æ¶‰åŠæ€»è®¡12ç§LLMsï¼ŒåŒ…æ‹¬4ç§é˜¿æ‹‰ä¼¯é¢„è®­ç»ƒæ¨¡å‹ã€4ç§è·¨è¯­è¨€æ¨¡å‹å’Œ4ç§åŸºäºæ¨ç†çš„æ¨¡å‹ã€‚æ–‡ç« åˆ¶å®šäº†ç²¾ç»†çš„å¹»è§‰è¯„ä¼°æ¡†æ¶ï¼ŒåŒ…å«ä»£è¡¨æ¯ä¸ªä»»åŠ¡ä¸åŒç‰¹ç‚¹çš„12ä¸ªç²¾ç»†æŒ‡æ ‡ï¼Œç”¨äºè¯„ä¼°LLMsè¾“å‡ºçš„çœŸå®æ€§å’Œå¯é æ€§ã€‚ç»“æœå‘ç°ï¼Œåœ¨æ‰€æœ‰æ¨¡å‹å’Œä»»åŠ¡ä¸­ï¼Œäº‹å®å¹»è§‰æ™®éé«˜äºçœŸå®é”™è¯¯ã€‚å°¤å…¶æ˜¯é˜¿æ‹‰ä¼¯é¢„è®­ç»ƒæ¨¡å‹â€œAllamâ€çš„å¹»è§‰ç‡è¾ƒä½ï¼Œä¸åŸºäºæ¨ç†çš„æ¨¡å‹è¡¨ç°ç›¸å½“ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æ–‡ç« é¦–æ¬¡å…¨é¢è¯„ä¼°äº†é˜¿æ‹‰ä¼¯æ–‡å’Œè·¨è¯­è¨€çš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨é˜¿æ‹‰ä¼¯è¯­å¢ƒä¸­çš„å¹»è§‰ç°è±¡ã€‚</li>
<li>ç ”ç©¶æ¶‰åŠäº†å¤šç§ä¸åŒçš„LLMsæ¨¡å‹ï¼ŒåŒ…æ‹¬é˜¿æ‹‰ä¼¯é¢„è®­ç»ƒæ¨¡å‹ã€è·¨è¯­è¨€æ¨¡å‹å’ŒåŸºäºæ¨ç†çš„æ¨¡å‹ã€‚</li>
<li>åˆ¶å®šäº†ç²¾ç»†çš„å¹»è§‰è¯„ä¼°æ¡†æ¶ï¼Œç”¨äºè¯„ä¼°LLMsåœ¨å…³é”®ä»»åŠ¡ä¸­çš„è¡¨ç°ã€‚</li>
<li>è¯„ä¼°ç»“æœæ˜¾ç¤ºäº‹å®å¹»è§‰åœ¨æ‰€æœ‰æ¨¡å‹å’Œä»»åŠ¡ä¸­æ™®éå­˜åœ¨ã€‚</li>
<li>é˜¿æ‹‰ä¼¯é¢„è®­ç»ƒæ¨¡å‹â€œAllamâ€çš„å¹»è§‰ç‡è¾ƒä½ï¼Œè¡¨ç°è‰¯å¥½ã€‚</li>
<li>ä¸åŸºäºæ¨ç†çš„æ¨¡å‹ç›¸æ¯”ï¼Œâ€œAllamâ€æ¨¡å‹å…·æœ‰ç›¸å¯¹è¾ƒå¥½çš„æ€§èƒ½ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.04656">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-09\./crop_R1_Reasoning/2509.04656v1/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-09\./crop_R1_Reasoning/2509.04656v1/page_3_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-09\./crop_R1_Reasoning/2509.04656v1/page_5_0.jpg" align="middle">
</details>


<h1 id="-9"><a href="#-9" class="headerlink" title=""></a></h1><h2 id="UI-TARS-2-Technical-Report-Advancing-GUI-Agent-with-Multi-Turn-Reinforcement-Learning"><a href="#UI-TARS-2-Technical-Report-Advancing-GUI-Agent-with-Multi-Turn-Reinforcement-Learning" class="headerlink" title="UI-TARS-2 Technical Report: Advancing GUI Agent with Multi-Turn   Reinforcement Learning"></a>UI-TARS-2 Technical Report: Advancing GUI Agent with Multi-Turn   Reinforcement Learning</h2><p><strong>Authors:Haoming Wang, Haoyang Zou, Huatong Song, Jiazhan Feng, Junjie Fang, Junting Lu, Longxiang Liu, Qinyu Luo, Shihao Liang, Shijue Huang, Wanjun Zhong, Yining Ye, Yujia Qin, Yuwen Xiong, Yuxin Song, Zhiyong Wu, Aoyan Li, Bo Li, Chen Dun, Chong Liu, Daoguang Zan, Fuxing Leng, Hanbin Wang, Hao Yu, Haobin Chen, Hongyi Guo, Jing Su, Jingjia Huang, Kai Shen, Kaiyu Shi, Lin Yan, Peiyao Zhao, Pengfei Liu, Qinghao Ye, Renjie Zheng, Shulin Xin, Wayne Xin Zhao, Wen Heng, Wenhao Huang, Wenqian Wang, Xiaobo Qin, Yi Lin, Youbin Wu, Zehui Chen, Zihao Wang, Baoquan Zhong, Xinchun Zhang, Xujing Li, Yuanfan Li, Zhongkai Zhao, Chengquan Jiang, Faming Wu, Haotian Zhou, Jinlin Pang, Li Han, Qi Liu, Qianli Ma, Siyao Liu, Songhua Cai, Wenqi Fu, Xin Liu, Yaohui Wang, Zhi Zhang, Bo Zhou, Guoliang Li, Jiajun Shi, Jiale Yang, Jie Tang, Li Li, Qihua Han, Taoran Lu, Woyu Lin, Xiaokang Tong, Xinyao Li, Yichi Zhang, Yu Miao, Zhengxuan Jiang, Zili Li, Ziyuan Zhao, Chenxin Li, Dehua Ma, Feng Lin, Ge Zhang, Haihua Yang, Hangyu Guo, Hongda Zhu, Jiaheng Liu, Junda Du, Kai Cai, Kuanye Li, Lichen Yuan, Meilan Han, Minchao Wang, Shuyue Guo, Tianhao Cheng, Xiaobo Ma, Xiaojun Xiao, Xiaolong Huang, Xinjie Chen, Yidi Du, Yilin Chen, Yiwen Wang, Zhaojian Li, Zhenzhu Yang, Zhiyuan Zeng, Chaolin Jin, Chen Li, Hao Chen, Haoli Chen, Jian Chen, Qinghao Zhao, Guang Shi</strong></p>
<p>The development of autonomous agents for graphical user interfaces (GUIs) presents major challenges in artificial intelligence. While recent advances in native agent models have shown promise by unifying perception, reasoning, action, and memory through end-to-end learning, open problems remain in data scalability, multi-turn reinforcement learning (RL), the limitations of GUI-only operation, and environment stability. In this technical report, we present UI-TARS-2, a native GUI-centered agent model that addresses these challenges through a systematic training methodology: a data flywheel for scalable data generation, a stabilized multi-turn RL framework, a hybrid GUI environment that integrates file systems and terminals, and a unified sandbox platform for large-scale rollouts. Empirical evaluation demonstrates that UI-TARS-2 achieves significant improvements over its predecessor UI-TARS-1.5. On GUI benchmarks, it reaches 88.2 on Online-Mind2Web, 47.5 on OSWorld, 50.6 on WindowsAgentArena, and 73.3 on AndroidWorld, outperforming strong baselines such as Claude and OpenAI agents. In game environments, it attains a mean normalized score of 59.8 across a 15-game suite-roughly 60% of human-level performance-and remains competitive with frontier proprietary models (e.g., OpenAI o3) on LMGame-Bench. Additionally, the model can generalize to long-horizon information-seeking tasks and software engineering benchmarks, highlighting its robustness across diverse agent tasks. Detailed analyses of training dynamics further provide insights into achieving stability and efficiency in large-scale agent RL. These results underscore UI-TARS-2â€™s potential to advance the state of GUI agents and exhibit strong generalization to real-world interactive scenarios. </p>
<blockquote>
<p>å›¾å½¢ç”¨æˆ·ç•Œé¢ï¼ˆGUIï¼‰è‡ªä¸»ä»£ç†æŠ€æœ¯çš„å‘å±•åœ¨äººå·¥æ™ºèƒ½é¢†åŸŸå¸¦æ¥äº†é‡å¤§æŒ‘æˆ˜ã€‚å°½ç®¡æœ€è¿‘åœ¨åŸç”Ÿä»£ç†æ¨¡å‹æ–¹é¢çš„è¿›å±•é€šè¿‡ç«¯åˆ°ç«¯å­¦ä¹ å°†æ„ŸçŸ¥ã€æ¨ç†ã€åŠ¨ä½œå’Œè®°å¿†ç»Ÿä¸€èµ·æ¥è€Œæ˜¾ç¤ºå‡ºå¸Œæœ›ï¼Œä½†åœ¨æ•°æ®å¯æ‰©å±•æ€§ã€å¤šè½®å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰ã€ä»…åŸºäºGUIçš„æ“ä½œå±€é™æ€§ä»¥åŠç¯å¢ƒç¨³å®šæ€§ç­‰æ–¹é¢ä»å­˜åœ¨å¼€æ”¾æ€§é—®é¢˜ã€‚åœ¨æœ¬æŠ€æœ¯æŠ¥å‘Šä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†UI-TARS-2ï¼Œè¿™æ˜¯ä¸€ç§ä»¥GUIä¸ºä¸­å¿ƒçš„ä»£ç†æ¨¡å‹ï¼Œé€šè¿‡ç³»ç»Ÿçš„è®­ç»ƒæ–¹æ³•è§£å†³è¿™äº›æŒ‘æˆ˜ï¼šç”¨äºå¯æ‰©å±•æ•°æ®ç”Ÿæˆçš„æ•°æ®é£è½®ã€ç¨³å®šçš„å¤šè½®RLæ¡†æ¶ã€é›†æˆæ–‡ä»¶ç³»ç»Ÿå’Œç»ˆç«¯çš„æ··åˆGUIç¯å¢ƒä»¥åŠç”¨äºå¤§è§„æ¨¡æ¨å‡ºçš„ç»Ÿä¸€æ²™ç®±å¹³å°ã€‚ç»éªŒè¯„ä¼°è¡¨æ˜ï¼ŒUI-TARS-2åœ¨å…¶å‰èº«UI-TARS-1.5çš„åŸºç¡€ä¸Šå–å¾—äº†æ˜¾è‘—æ”¹è¿›ã€‚åœ¨GUIåŸºå‡†æµ‹è¯•ä¸­ï¼Œå®ƒåœ¨Online-Mind2Webä¸Šè¾¾åˆ°88.2ï¼Œåœ¨OSWorldä¸Šè¾¾åˆ°47.5ï¼Œåœ¨WindowsAgentArenaä¸Šè¾¾åˆ°50.6ï¼Œåœ¨AndroidWorldä¸Šè¾¾åˆ°73.3ï¼Œè¶…è¶Šäº†Claudeå’ŒOpenAIä»£ç†ç­‰å¼ºåŠ²åŸºå‡†çº¿ã€‚åœ¨æ¸¸æˆç¯å¢ƒä¸­ï¼Œå®ƒåœ¨15æ¬¾æ¸¸æˆå¥—ä»¶ä¸­çš„å¹³å‡å½’ä¸€åŒ–å¾—åˆ†ä¸º59.8â€”â€”çº¦ä¸ºäººç±»æ€§èƒ½çš„60%ï¼Œå¹¶ä¸”åœ¨LMGame-Benchä¸Šä¸å‰æ²¿ä¸“æœ‰æ¨¡å‹ï¼ˆä¾‹å¦‚OpenAI o3ï¼‰ä¿æŒç«äº‰åŠ›ã€‚æ­¤å¤–ï¼Œè¯¥æ¨¡å‹å¯ä»¥æ¨å¹¿åˆ°é•¿å‘¨æœŸä¿¡æ¯æœç´¢ä»»åŠ¡å’Œè½¯ä»¶å·¥ç¨‹åŸºå‡†æµ‹è¯•ï¼Œçªæ˜¾å…¶åœ¨å„ç§ä»£ç†ä»»åŠ¡ä¸­çš„ç¨³å¥æ€§ã€‚å¯¹è®­ç»ƒåŠ¨æ€çš„è¯¦ç»†åˆ†æè¿›ä¸€æ­¥æä¾›äº†åœ¨å¤§å‹ä»£ç†RLä¸­å®ç°ç¨³å®šæ€§å’Œæ•ˆç‡çš„è§è§£ã€‚è¿™äº›ç»“æœå¼ºè°ƒäº†UI-TARS-2åœ¨æ¨è¿›GUIä»£ç†çŠ¶æ€æ–¹é¢çš„æ½œåŠ›ï¼Œå¹¶è¡¨ç°å‡ºå¯¹ç°å®ä¸–ç•Œäº¤äº’åœºæ™¯çš„å¼ºçƒˆæ³›åŒ–èƒ½åŠ›ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.02544v2">PDF</a> </p>
<p><strong>æ‘˜è¦</strong></p>
<p>åœ¨å›¾å½¢ç”¨æˆ·ç•Œé¢ï¼ˆGUIï¼‰çš„è‡ªä¸»ä»£ç†å¼€å‘é¢†åŸŸï¼Œäººå·¥æ™ºèƒ½é¢ä¸´ç€é‡å¤§æŒ‘æˆ˜ã€‚å°½ç®¡åŸºäºç«¯åˆ°ç«¯å­¦ä¹ çš„åŸç”Ÿä»£ç†æ¨¡å‹åœ¨ç»Ÿä¸€æ„ŸçŸ¥ã€æ¨ç†ã€è¡ŒåŠ¨å’Œè®°å¿†æ–¹é¢å±•ç°å‡ºå‰æ™¯ï¼Œä½†ä»å­˜åœ¨æ•°æ®å¯æ‰©å±•æ€§ã€å¤šå›åˆå¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰çš„ç¨³å®šæ€§ã€GUIæ“ä½œçš„å±€é™æ€§ä»¥åŠç¯å¢ƒç¨³å®šæ€§ç­‰é—®é¢˜ã€‚æœ¬æŠ€æœ¯æŠ¥å‘Šä»‹ç»äº†UI-TARS-2ï¼Œä¸€ç§ä»¥GUIä¸ºä¸­å¿ƒçš„åŸç”Ÿä»£ç†æ¨¡å‹ï¼Œå®ƒé€šè¿‡ç³»ç»ŸåŒ–çš„è®­ç»ƒæ–¹æ³•è§£å†³è¿™äº›æŒ‘æˆ˜ï¼šç”¨äºå¯æ‰©å±•æ•°æ®ç”Ÿæˆçš„â€œæ•°æ®é£è½®â€ã€ç¨³å®šçš„å¤šå›åˆRLæ¡†æ¶ã€é›†æˆæ–‡ä»¶ç³»ç»Ÿå’Œç»ˆç«¯çš„æ··åˆGUIç¯å¢ƒä»¥åŠç”¨äºå¤§è§„æ¨¡å±•å¼€çš„ç»Ÿä¸€æ²™ç›˜å¹³å°ã€‚å®è¯è¯„ä¼°è¡¨æ˜ï¼ŒUI-TARS-2ç›¸è¾ƒäºå…¶å‰èº«UI-TARS-1.5å–å¾—äº†æ˜¾è‘—æ”¹è¿›ã€‚åœ¨GUIåŸºå‡†æµ‹è¯•ä¸­ï¼Œå®ƒåœ¨Online-Mind2Webä¸Šè¾¾åˆ°88.2ï¼ŒOSWorldä¸Šè¾¾åˆ°47.5ï¼ŒWindowsAgentArenaä¸Šè¾¾åˆ°50.6ï¼ŒAndroidWorldä¸Šè¾¾åˆ°73.3ï¼Œè¶…è¶Šäº†Claudeå’ŒOpenAIç­‰å¼ºå¤§åŸºçº¿ä»£ç†ã€‚åœ¨æ¸¸æˆç¯å¢ƒä¸­ï¼Œå®ƒåœ¨åŒ…å«å¤šä¸ªæ¸¸æˆçš„å¥—ä»¶ä¸­å¹³å‡æ ‡å‡†åŒ–å¾—åˆ†è¾¾åˆ°å¹³å‡æ°´å¹³çš„çº¦å…­æˆå·¦å³ï¼Œå¹¶åœ¨LMGame-Benchä¸Šä¸å‰æ²¿ä¸“æœ‰æ¨¡å‹ï¼ˆå¦‚OpenAI o3ï¼‰ä¿æŒç«äº‰åŠ›ã€‚æ­¤å¤–ï¼Œè¯¥æ¨¡å‹èƒ½å¤Ÿæ³›åŒ–åˆ°é•¿å‘¨æœŸä¿¡æ¯æœç´¢ä»»åŠ¡å’Œè½¯ä»¶å·¥ç¨‹åŸºå‡†æµ‹è¯•ï¼Œè¡¨ç°å‡ºåœ¨å¤šæ ·åŒ–ä»£ç†ä»»åŠ¡ä¸­çš„ç¨³å¥æ€§ã€‚å¯¹è®­ç»ƒåŠ¨æ€çš„æ·±å…¥åˆ†æè¿›ä¸€æ­¥æä¾›äº†å®ç°å¤§è§„æ¨¡ä»£ç†RLçš„ç¨³å®šæ€§å’Œæ•ˆç‡çš„ç­–ç•¥ã€‚è¿™äº›ç»“æœå‡¸æ˜¾äº†UI-TARS-2åœ¨æ¨è¿›GUIä»£ç†çŠ¶æ€æ–¹é¢çš„æ½œåŠ›åŠå…¶åœ¨ç°å®ä¸–ç•Œäº¤äº’åœºæ™¯ä¸­çš„å¼ºå¤§æ³›åŒ–èƒ½åŠ›ã€‚ </p>
<p><strong>å…³é”®è§è§£</strong></p>
<ol>
<li>GUIè‡ªä¸»ä»£ç†å¼€å‘åœ¨äººå·¥æ™ºèƒ½é¢†åŸŸé¢ä¸´é‡å¤§æŒ‘æˆ˜ï¼Œå¦‚æ•°æ®å¯æ‰©å±•æ€§ã€å¤šå›åˆå¼ºåŒ–å­¦ä¹ ç¨³å®šæ€§ç­‰ã€‚</li>
<li>UI-TARS-2æ¨¡å‹é€šè¿‡ç³»ç»ŸåŒ–çš„è®­ç»ƒæ–¹æ³•è§£å†³è¿™äº›æŒ‘æˆ˜ï¼ŒåŒ…æ‹¬æ•°æ®ç”Ÿæˆã€ç¨³å®šçš„å¤šå›åˆRLæ¡†æ¶ç­‰ã€‚</li>
<li>UI-TARS-2åœ¨å¤šä¸ªGUIåŸºå‡†æµ‹è¯•ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œæ˜¾è‘—è¶…è¶Šå…ˆå‰æ¨¡å‹ã€‚</li>
<li>åœ¨æ¸¸æˆç¯å¢ƒä¸­ï¼ŒUI-TARS-2å±•ç°å‡ºå¼ºå¤§çš„æ€§èƒ½ï¼Œå¹³å‡å¾—åˆ†æ¥è¿‘äººç±»æ°´å¹³çš„å…­æˆå·¦å³ã€‚</li>
<li>è¯¥æ¨¡å‹èƒ½æ³›åŒ–åˆ°é•¿å‘¨æœŸä¿¡æ¯æœç´¢ä»»åŠ¡å’Œè½¯ä»¶å·¥ç¨‹åŸºå‡†æµ‹è¯•ï¼Œè¡¨æ˜å…¶åœ¨å¤šæ ·åŒ–ä»»åŠ¡ä¸­çš„ç¨³å¥æ€§ã€‚</li>
<li>è¯¦ç»†åˆ†ææä¾›äº†å®ç°å¤§è§„æ¨¡ä»£ç†RLç¨³å®šæ€§å’Œæ•ˆç‡çš„ç­–ç•¥ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.02544">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-09\./crop_R1_Reasoning/2509.02544v2/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-09\./crop_R1_Reasoning/2509.02544v2/page_1_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-09\./crop_R1_Reasoning/2509.02544v2/page_3_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-09\./crop_R1_Reasoning/2509.02544v2/page_5_0.jpg" align="middle">
</details>


<h1 id="-10"><a href="#-10" class="headerlink" title=""></a></h1><h2 id="R-4B-Incentivizing-General-Purpose-Auto-Thinking-Capability-in-MLLMs-via-Bi-Mode-Annealing-and-Reinforce-Learning"><a href="#R-4B-Incentivizing-General-Purpose-Auto-Thinking-Capability-in-MLLMs-via-Bi-Mode-Annealing-and-Reinforce-Learning" class="headerlink" title="R-4B: Incentivizing General-Purpose Auto-Thinking Capability in MLLMs   via Bi-Mode Annealing and Reinforce Learning"></a>R-4B: Incentivizing General-Purpose Auto-Thinking Capability in MLLMs   via Bi-Mode Annealing and Reinforce Learning</h2><p><strong>Authors:Qi Yang, Bolin Ni, Shiming Xiang, Han Hu, Houwen Peng, Jie Jiang</strong></p>
<p>Multimodal Large Language Models (MLLMs) equipped with step-by-step thinking capabilities have demonstrated remarkable performance on complex reasoning problems. However, this thinking process is redundant for simple problems solvable without complex reasoning. To address this inefficiency, we propose R-4B, an auto-thinking MLLM, which can adaptively decide when to think based on problem complexity. The central idea of R-4B is to empower the model with both thinking and non-thinking capabilities using bi-mode annealing, and apply Bi-mode Policy Optimization (BPO) to improve the modelâ€™s accuracy in determining whether to activate the thinking process. Specifically, we first train the model on a carefully curated dataset spanning various topics, which contains samples from both thinking and non-thinking modes. Then it undergoes a second phase of training under an improved GRPO framework, where the policy model is forced to generate responses from both modes for each input query. Experimental results show that R-4B achieves state-of-the-art performance across 25 challenging benchmarks. It outperforms Qwen2.5-VL-7B in most tasks and achieves performance comparable to larger models such as Kimi-VL-A3B-Thinking-2506 (16B) on reasoning-intensive benchmarks with lower computational cost. </p>
<blockquote>
<p>é…å¤‡æœ‰é€æ­¥æ€è€ƒèƒ½åŠ›ï¼ˆstep-by-step thinking capabilitiesï¼‰çš„å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰åœ¨å¤æ‚çš„æ¨ç†é—®é¢˜ä¸Šè¡¨ç°å‡ºäº†æ˜¾è‘—çš„æ€§èƒ½ã€‚ç„¶è€Œï¼Œå¯¹äºä¸éœ€è¦å¤æ‚æ¨ç†å°±èƒ½è§£å†³çš„ç®€å•é—®é¢˜ï¼Œè¿™ç§æ€è€ƒè¿‡ç¨‹æ˜¯å†—ä½™çš„ã€‚ä¸ºäº†è§£å†³è¿™ç§ä½æ•ˆé—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†R-4Bï¼Œä¸€ç§èƒ½å¤Ÿè‡ªé€‚åº”åˆ¤æ–­ä½•æ—¶æ€è€ƒçš„è‡ªæ€è€ƒMLLMæ¨¡å‹ã€‚R-4Bçš„æ ¸å¿ƒæ€æƒ³æ˜¯åˆ©ç”¨åŒæ¨¡å¼é€€ç«æŠ€æœ¯èµ‹äºˆæ¨¡å‹æ€è€ƒå’Œä¸ç”¨æ€è€ƒçš„èƒ½åŠ›ï¼Œå¹¶é€šè¿‡åŒæ¨¡å¼ç­–ç•¥ä¼˜åŒ–ï¼ˆBPOï¼‰æé«˜æ¨¡å‹åœ¨å†³å®šæ˜¯å¦éœ€è¦å¯åŠ¨æ€è€ƒè¿‡ç¨‹æ—¶çš„å‡†ç¡®æ€§ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬é¦–å…ˆåœ¨ä¸€ä¸ªç²¾å¿ƒæŒ‘é€‰çš„æ¶µç›–å„ç§ä¸»é¢˜çš„æ•°æ®é›†ä¸Šè®­ç»ƒæ¨¡å‹ï¼Œè¯¥æ•°æ®é›†åŒ…å«æ¥è‡ªæ€è€ƒå’Œä¸ç”¨æ€è€ƒä¸¤ç§æ¨¡å¼çš„æ ·æœ¬ã€‚ç„¶ååœ¨æ”¹è¿›åçš„GRPOæ¡†æ¶ä¸‹è¿›å…¥ç¬¬äºŒé˜¶æ®µè®­ç»ƒï¼Œåœ¨è¿™ä¸€é˜¶æ®µï¼Œç­–ç•¥æ¨¡å‹å¿…é¡»ä¸ºæ¯ä¸ªè¾“å…¥æŸ¥è¯¢ç”Ÿæˆä¸¤ç§æ¨¡å¼çš„ç­”æ¡ˆã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒR-4Båœ¨25é¡¹å…·æœ‰æŒ‘æˆ˜æ€§çš„åŸºå‡†æµ‹è¯•ä¸­è¾¾åˆ°äº†æœ€æ–°æ°´å¹³ï¼Œå®ƒåœ¨å¤§å¤šæ•°ä»»åŠ¡ä¸­è¶…è¶Šäº†Qwen2.5-VL-7Bçš„è¡¨ç°ï¼Œåœ¨æ¨ç†å¯†é›†å‹åŸºå‡†æµ‹è¯•ä¸­è¾¾åˆ°äº†ä¸æ›´å¤§æ¨¡å‹ï¼ˆå¦‚Kimi-VL-A3B-Thinking-2506çš„ï¼ˆ16Bï¼‰ï¼‰ç›¸å½“çš„æ€§èƒ½è¡¨ç°ï¼ŒåŒæ—¶é™ä½äº†è®¡ç®—æˆæœ¬ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.21113v2">PDF</a> 20 pages, 14 figures, 5 tables</p>
<p><strong>Summary</strong><br>å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å¤æ‚æ¨ç†é—®é¢˜ä¸Šè¡¨ç°å‡ºæ˜¾è‘—æ€§èƒ½ã€‚ä½†å®ƒä»¬åœ¨è§£å†³æ— éœ€å¤æ‚æ¨ç†çš„ç®€å•é—®é¢˜æ—¶å­˜åœ¨å†—ä½™æ€è€ƒè¿‡ç¨‹ã€‚ä¸ºè§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†è‡ªé€‚åº”æ€è€ƒçš„æ¨¡å‹R-4Bï¼Œå®ƒèƒ½æ ¹æ®é—®é¢˜å¤æ‚åº¦æ¥å†³å®šä½•æ—¶æ€è€ƒã€‚R-4Bçš„æ ¸å¿ƒæ€æƒ³æ˜¯åˆ©ç”¨åŒæ¨¡å¼é€€ç«æŠ€æœ¯èµ‹äºˆæ¨¡å‹æ€è€ƒå’Œéæ€è€ƒèƒ½åŠ›ï¼Œå¹¶é€šè¿‡åŒæ¨¡å¼ç­–ç•¥ä¼˜åŒ–ï¼ˆBPOï¼‰æé«˜æ¨¡å‹å†³å®šä½•æ—¶å¯åŠ¨æ€è€ƒè¿‡ç¨‹çš„å‡†ç¡®æ€§ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒR-4Båœ¨25é¡¹å…·æœ‰æŒ‘æˆ˜æ€§çš„åŸºå‡†æµ‹è¯•ä¸­å–å¾—äº†æœ€æ–°æŠ€æœ¯æˆæœï¼Œå¹¶åœ¨å¤§å¤šæ•°ä»»åŠ¡ä¸­ä¼˜äºQwen2.5-VL-7Bæ¨¡å‹ï¼ŒåŒæ—¶åœ¨æ¨ç†å¯†é›†å‹åŸºå‡†æµ‹è¯•ä¸Šçš„æ€§èƒ½ä¸æ›´å¤§çš„æ¨¡å‹å¦‚Kimi-VL-A3B-Thinking-2506ï¼ˆ16Bï¼‰ç›¸å½“ï¼Œä½†è®¡ç®—æˆæœ¬æ›´ä½ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å¤æ‚æ¨ç†é—®é¢˜ä¸Šè¡¨ç°ä¼˜ç§€ã€‚</li>
<li>R-4Bæ¨¡å‹èƒ½æ ¹æ®é—®é¢˜å¤æ‚åº¦è‡ªé€‚åº”å†³å®šä½•æ—¶æ€è€ƒã€‚</li>
<li>R-4Bæ¨¡å‹é€šè¿‡åŒæ¨¡å¼é€€ç«æŠ€æœ¯å®ç°æ€è€ƒå’Œæ€è€ƒèƒ½åŠ›çš„åˆ‡æ¢ã€‚</li>
<li>åŒæ¨¡å¼ç­–ç•¥ä¼˜åŒ–ï¼ˆBPOï¼‰æé«˜äº†æ¨¡å‹å†³å®šå¯åŠ¨æ€è€ƒè¿‡ç¨‹çš„å‡†ç¡®æ€§ã€‚</li>
<li>R-4Bæ¨¡å‹åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œä¼˜äºæŸäº›ç°æœ‰æ¨¡å‹ã€‚</li>
<li>R-4Bæ¨¡å‹çš„æ€§èƒ½ä¸æ›´å¤§æ¨¡å‹ç›¸å½“ï¼Œä½†è®¡ç®—æˆæœ¬æ›´ä½ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.21113">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-09\./crop_R1_Reasoning/2508.21113v2/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-09\./crop_R1_Reasoning/2508.21113v2/page_1_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-09\./crop_R1_Reasoning/2508.21113v2/page_2_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-09\./crop_R1_Reasoning/2508.21113v2/page_3_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-09\./crop_R1_Reasoning/2508.21113v2/page_3_1.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-09\./crop_R1_Reasoning/2508.21113v2/page_4_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-09\./crop_R1_Reasoning/2508.21113v2/page_5_0.jpg" align="middle">
</details>


<h1 id="-11"><a href="#-11" class="headerlink" title=""></a></h1><h2 id="MedGR-2-Breaking-the-Data-Barrier-for-Medical-Reasoning-via-Generative-Reward-Learning"><a href="#MedGR-2-Breaking-the-Data-Barrier-for-Medical-Reasoning-via-Generative-Reward-Learning" class="headerlink" title="MedGR$^2$: Breaking the Data Barrier for Medical Reasoning via   Generative Reward Learning"></a>MedGR$^2$: Breaking the Data Barrier for Medical Reasoning via   Generative Reward Learning</h2><p><strong>Authors:Weihai Zhi, Jiayan Guo, Shangyang Li</strong></p>
<p>The application of Vision-Language Models (VLMs) in medicine is critically hampered by the scarcity of high-quality, expert-annotated data. Supervised Fine-Tuning (SFT) on existing datasets often leads to poor generalization on unseen modalities and tasks, while Reinforcement Learning (RL), a promising alternative, is stymied by the lack of reliable reward signals in this data-scarce domain. To break this impasse, we introduce Generative Reward Learning for Medical Reasoning (MedGR$^2$), a novel framework that creates a self-improving virtuous cycle. MedGR$^2$ co-develops a data generator and a reward model, enabling the automated, continuous creation of high-quality, multi-modal medical data that serves as both a superior training source for SFT and RL. Our experiments demonstrate that SFT with MedGR$^2$-produced data already surpasses baselines trained on large-scale, human-curated datasets. Crucially, when leveraging this data for RL via Group Relative Policy Optimization (GRPO), our model achieves state-of-the-art cross-modality and cross-task generalization, significantly outperforming specialized RL-based methods. Furthermore, our compact model, empowered by MedGR$^2$, achieves performance competitive with foundation models possessing over 10 times more parameters. MedGR$^2$ presents a new paradigm for data-efficient learning in high-stakes domains, transforming the problem from data scarcity to data generation and unlocking the full potential of RL for building truly generalizable medical AI. </p>
<blockquote>
<p>åœ¨åŒ»å­¦é¢†åŸŸåº”ç”¨è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMsï¼‰ä¸¥é‡å—é™äºé«˜è´¨é‡ã€ä¸“å®¶æ ‡æ³¨æ•°æ®çš„ç¨€ç¼ºæ€§ã€‚åœ¨ç°æœ‰æ•°æ®é›†ä¸Šè¿›è¡Œçš„æœ‰ç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰å¾€å¾€å¯¼è‡´åœ¨æœªè§è¿‡çš„æ–°æ¨¡æ€å’Œä»»åŠ¡ä¸Šæ³›åŒ–èƒ½åŠ›è¾ƒå·®ï¼Œè€Œå¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰ä½œä¸ºä¸€ç§æœ‰å‰é€”çš„æ›¿ä»£æ–¹æ¡ˆï¼Œç”±äºåœ¨è¿™ä¸ªæ•°æ®ç¨€ç¼ºé¢†åŸŸç¼ºä¹å¯é çš„å¥–åŠ±ä¿¡å·è€Œå—åˆ°é˜»ç¢ã€‚ä¸ºäº†æ‰“ç ´è¿™ä¸€åƒµå±€ï¼Œæˆ‘ä»¬å¼•å…¥äº†åŒ»ç–—æ¨ç†çš„ç”Ÿæˆå¥–åŠ±å­¦ä¹ ï¼ˆMedGRÂ²ï¼‰è¿™ä¸€æ–°å‹æ¡†æ¶ï¼Œå®ƒåˆ›é€ äº†ä¸€ä¸ªè‡ªæˆ‘æ”¹è¿›çš„è‰¯å¥½å¾ªç¯ã€‚MedGRÂ²å…±åŒå¼€å‘äº†ä¸€ä¸ªæ•°æ®ç”Ÿæˆå™¨å’Œå¥–åŠ±æ¨¡å‹ï¼Œèƒ½å¤Ÿå®ç°é«˜è´¨é‡ã€å¤šæ¨¡æ€åŒ»ç–—æ•°æ®çš„è‡ªåŠ¨åŒ–ã€è¿ç»­åˆ›å»ºï¼Œè¿™äº›æ•°æ®æ—¢å¯ä½œä¸ºæœ‰ç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰çš„ä¼˜è´¨è®­ç»ƒæºï¼Œä¹Ÿå¯ä½œä¸ºå¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰çš„è®­ç»ƒæºã€‚æˆ‘ä»¬çš„å®éªŒè¡¨æ˜ï¼Œä½¿ç”¨MedGRÂ²ç”Ÿæˆçš„æ•°æ®è¿›è¡Œæœ‰ç›‘ç£å¾®è°ƒå·²ç»è¶…è¶Šäº†åœ¨å¤§è§„æ¨¡äººå·¥æ•´ç†æ•°æ®é›†ä¸Šè®­ç»ƒçš„åŸºçº¿ã€‚å…³é”®çš„æ˜¯ï¼Œé€šè¿‡åˆ©ç”¨ç¾¤ä½“ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–ï¼ˆGRPOï¼‰å¯¹æ­¤æ•°æ®è¿›è¡Œå¼ºåŒ–å­¦ä¹ ï¼Œæˆ‘ä»¬çš„æ¨¡å‹å®ç°äº†è·¨æ¨¡æ€å’Œè·¨ä»»åŠ¡çš„æœ€æ–°æœ€å…ˆè¿›çš„æ³›åŒ–èƒ½åŠ›ï¼Œæ˜¾è‘—ä¼˜äºä¸“é—¨çš„åŸºäºRLçš„æ–¹æ³•ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬çš„ç´§å‡‘æ¨¡å‹åœ¨MedGRÂ²çš„æ”¯æŒä¸‹ï¼Œæ€§èƒ½ä¸æ‹¥æœ‰è¶…è¿‡åå€å‚æ•°çš„åŸºç¡€æ¨¡å‹ç›¸ç«äº‰ã€‚MedGRÂ²ä¸ºé«˜é£é™©é¢†åŸŸçš„æ•°æ®é«˜æ•ˆå­¦ä¹ æä¾›äº†æ–°çš„èŒƒå¼ï¼Œä»æ•°æ®ç¨€ç¼ºæ€§è½¬å˜ä¸ºæ•°æ®ç”Ÿæˆï¼Œå¹¶é‡Šæ”¾äº†å¼ºåŒ–å­¦ä¹ åœ¨æ„å»ºçœŸæ­£é€šç”¨åŒ»ç–—äººå·¥æ™ºèƒ½æ–¹é¢çš„å…¨éƒ¨æ½œåŠ›ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.20549v1">PDF</a> 8 pages, 5 figures</p>
<p><strong>Summary</strong></p>
<p>è¯¥æ–‡ä»‹ç»äº†åœ¨åŒ»å­¦é¢†åŸŸåº”ç”¨è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMsï¼‰é¢ä¸´çš„æŒ‘æˆ˜ï¼ŒåŒ…æ‹¬é«˜è´¨é‡ä¸“å®¶æ ‡æ³¨æ•°æ®çš„ç¨€ç¼ºæ€§ã€‚ç°æœ‰çš„ç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰æ–¹æ³•å¾€å¾€æ— æ³•å¾ˆå¥½åœ°é€‚åº”æœªè§è¿‡çš„æ¨¡æ€å’Œä»»åŠ¡ã€‚ä¸ºè§£å†³è¿™äº›é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åä¸ºMedGRÂ²çš„æ–°å‹æ¡†æ¶ï¼Œè¯¥æ¡†æ¶èƒ½å¤Ÿå…±åŒå¼€å‘æ•°æ®ç”Ÿæˆå™¨å’Œå¥–åŠ±æ¨¡å‹ï¼Œå®ç°é«˜è´¨é‡å¤šæ¨¡æ€åŒ»å­¦æ•°æ®çš„è‡ªåŠ¨è¿ç»­ç”Ÿæˆã€‚å®éªŒè¡¨æ˜ï¼Œä½¿ç”¨MedGRÂ²ç”Ÿæˆçš„æ•°æ®è¿›è¡ŒSFTå·²ç»è¶…è¶Šäº†åŸºçº¿æ°´å¹³ã€‚å½“åˆ©ç”¨æ­¤æ•°æ®è¿›è¡Œå¼ºåŒ–å­¦ä¹ æ—¶ï¼Œé€šè¿‡é›†å›¢ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–ï¼ˆGRPOï¼‰ï¼Œæ¨¡å‹å®ç°äº†è·¨æ¨¡æ€å’Œè·¨ä»»åŠ¡çš„æœ€ä½³æ³›åŒ–æ€§èƒ½ï¼Œæ˜¾è‘—ä¼˜äºä¸“é—¨çš„RLæ–¹æ³•ã€‚æ­¤å¤–ï¼Œç”±MedGRÂ²èµ‹èƒ½çš„ç´§å‡‘æ¨¡å‹å®ç°äº†ä¸æ‹¥æœ‰è¶…è¿‡åå€å‚æ•°çš„åŸºç¡€æ¨¡å‹ç›¸ç«äº‰çš„æ€§èƒ½ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>MedGRÂ²æ¡†æ¶è§£å†³äº†åŒ»å­¦é¢†åŸŸåº”ç”¨è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMsï¼‰æ—¶é«˜è´¨é‡ä¸“å®¶æ ‡æ³¨æ•°æ®ç¨€ç¼ºçš„é—®é¢˜ã€‚</li>
<li>ç°æœ‰çš„ç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰æ–¹æ³•åœ¨æ–°æ¨¡æ€å’Œä»»åŠ¡ä¸Šæ³›åŒ–èƒ½åŠ›æœ‰é™ã€‚</li>
<li>MedGRÂ²èƒ½å¤Ÿå…±åŒå¼€å‘æ•°æ®ç”Ÿæˆå™¨å’Œå¥–åŠ±æ¨¡å‹ï¼Œå®ç°é«˜è´¨é‡å¤šæ¨¡æ€åŒ»å­¦æ•°æ®çš„è‡ªåŠ¨è¿ç»­ç”Ÿæˆã€‚</li>
<li>ä½¿ç”¨MedGRÂ²ç”Ÿæˆçš„æ•°æ®è¿›è¡ŒSFTå·²è¶…è¶ŠåŸºçº¿æ°´å¹³ã€‚</li>
<li>ç»“åˆMedGRÂ²å’Œå¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰é€šè¿‡é›†å›¢ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–ï¼ˆGRPOï¼‰å®ç°äº†è·¨æ¨¡æ€å’Œè·¨ä»»åŠ¡çš„æœ€ä½³æ³›åŒ–æ€§èƒ½ã€‚</li>
<li>MedGRÂ²èµ‹èƒ½çš„ç´§å‡‘æ¨¡å‹æ€§èƒ½ä¸å¤§å‹åŸºç¡€æ¨¡å‹ç›¸ç«äº‰ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.20549">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-09\./crop_R1_Reasoning/2508.20549v1/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-09\./crop_R1_Reasoning/2508.20549v1/page_2_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-09\./crop_R1_Reasoning/2508.20549v1/page_3_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-09\./crop_R1_Reasoning/2508.20549v1/page_4_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-09\./crop_R1_Reasoning/2508.20549v1/page_5_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-09\./crop_R1_Reasoning/2508.20549v1/page_5_1.jpg" align="middle">
</details>


<h1 id="-12"><a href="#-12" class="headerlink" title=""></a></h1><h2 id="AI-SearchPlanner-Modular-Agentic-Search-via-Pareto-Optimal-Multi-Objective-Reinforcement-Learning"><a href="#AI-SearchPlanner-Modular-Agentic-Search-via-Pareto-Optimal-Multi-Objective-Reinforcement-Learning" class="headerlink" title="AI-SearchPlanner: Modular Agentic Search via Pareto-Optimal   Multi-Objective Reinforcement Learning"></a>AI-SearchPlanner: Modular Agentic Search via Pareto-Optimal   Multi-Objective Reinforcement Learning</h2><p><strong>Authors:Lang Mei, Zhihan Yang, Chong Chen</strong></p>
<p>Recent studies have explored integrating Large Language Models (LLMs) with search engines to leverage both the LLMsâ€™ internal pre-trained knowledge and external information. Specially, reinforcement learning (RL) has emerged as a promising paradigm for enhancing LLM reasoning through multi-turn interactions with search engines. However, existing RL-based search agents rely on a single LLM to handle both search planning and question-answering (QA) tasks in an end-to-end manner, which limits their ability to optimize both capabilities simultaneously. In practice, sophisticated AI search systems often employ a large, frozen LLM (e.g., GPT-4, DeepSeek-R1) to ensure high-quality QA. Thus, a more effective and efficient approach is to utilize a small, trainable LLM dedicated to search planning. In this paper, we propose \textbf{AI-SearchPlanner}, a novel reinforcement learning framework designed to enhance the performance of frozen QA models by focusing on search planning. Specifically, our approach introduces three key innovations: 1) Decoupling the Architecture of the Search Planner and Generator, 2) Dual-Reward Alignment for Search Planning, and 3) Pareto Optimization of Planning Utility and Cost, to achieve the objectives. Extensive experiments on real-world datasets demonstrate that AI SearchPlanner outperforms existing RL-based search agents in both effectiveness and efficiency, while exhibiting strong generalization capabilities across diverse frozen QA models and data domains. </p>
<blockquote>
<p>æœ€è¿‘çš„ç ”ç©¶æ¢è®¨äº†å¦‚ä½•å°†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä¸æœç´¢å¼•æ“ç›¸ç»“åˆï¼Œä»¥åˆ©ç”¨LLMçš„å†…éƒ¨é¢„è®­ç»ƒçŸ¥è¯†å’Œå¤–éƒ¨ä¿¡æ¯ã€‚ç‰¹åˆ«æ˜¯ï¼Œå¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰å·²ç»æˆä¸ºä¸€ç§æœ‰å‰æ™¯çš„æ¨¡å¼ï¼Œé€šè¿‡å¤šè½®ä¸æœç´¢å¼•æ“çš„äº¤äº’æ¥å¢å¼ºLLMçš„æ¨ç†èƒ½åŠ›ã€‚ç„¶è€Œï¼Œç°æœ‰çš„åŸºäºRLçš„æœç´¢ä»£ç†ä¾èµ–äºå•ä¸ªLLMä»¥ç«¯åˆ°ç«¯çš„æ–¹å¼åŒæ—¶å¤„ç†æœç´¢è§„åˆ’å’Œé—®ç­”ï¼ˆQAï¼‰ä»»åŠ¡ï¼Œè¿™é™åˆ¶äº†å®ƒä»¬åŒæ—¶ä¼˜åŒ–è¿™ä¸¤ç§åŠŸèƒ½çš„èƒ½åŠ›ã€‚åœ¨å®è·µä¸­ï¼Œå¤æ‚çš„AIæœç´¢ç³»ç»Ÿé€šå¸¸ä¼šä½¿ç”¨å¤§å‹ã€å›ºå®šçš„LLMï¼ˆå¦‚GPT-4ã€DeepSeek-R1ï¼‰æ¥ç¡®ä¿é«˜è´¨é‡çš„é—®ç­”ã€‚å› æ­¤ï¼Œä¸€ä¸ªæ›´æœ‰æ•ˆå’Œé«˜æ•ˆçš„æ–¹æ³•æ˜¯ä½¿ç”¨ä¸€ä¸ªå°å‹çš„ã€å¯è®­ç»ƒçš„LLMä¸“é—¨ç”¨äºæœç´¢è§„åˆ’ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†\textbf{AI-SearchPlanner}ï¼Œè¿™æ˜¯ä¸€ç§æ–°å‹çš„å¼ºåŒ–å­¦ä¹ æ¡†æ¶ï¼Œæ—¨åœ¨é€šè¿‡ä¸“æ³¨äºæœç´¢è§„åˆ’æ¥æé«˜å›ºå®šé—®ç­”æ¨¡å‹çš„æ€§èƒ½ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬çš„æ–¹æ³•å¼•å…¥äº†ä¸‰ä¸ªå…³é”®çš„åˆ›æ–°ç‚¹ï¼š1ï¼‰æœç´¢è§„åˆ’å™¨å’Œç”Ÿæˆå™¨çš„æ¶æ„è§£è€¦ï¼Œ2ï¼‰æœç´¢è§„åˆ’çš„åŒå¥–åŠ±å¯¹é½ï¼Œä»¥åŠ3ï¼‰è§„åˆ’å’Œæˆæœ¬çš„å¸•ç´¯æ‰˜ä¼˜åŒ–ï¼Œä»¥å®ç°ç›®æ ‡ã€‚åœ¨çœŸå®æ•°æ®é›†ä¸Šçš„å¤§é‡å®éªŒè¡¨æ˜ï¼ŒAI SearchPlanneråœ¨æœ‰æ•ˆæ€§å’Œæ•ˆç‡æ–¹é¢ä¼˜äºç°æœ‰çš„åŸºäºRLçš„æœç´¢ä»£ç†ï¼ŒåŒæ—¶åœ¨ä¸åŒçš„å›ºå®šé—®ç­”æ¨¡å‹å’Œæ•°æ®é¢†åŸŸè¡¨ç°å‡ºå¼ºå¤§çš„æ³›åŒ–èƒ½åŠ›ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.20368v2">PDF</a> </p>
<p><strong>Summary</strong><br>     è¿‘æœŸç ”ç©¶æ¢ç´¢äº†å°†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä¸æœç´¢å¼•æ“ç›¸ç»“åˆçš„æ–¹æ³•ï¼Œåˆ©ç”¨LLMçš„å†…éƒ¨é¢„è®­ç»ƒçŸ¥è¯†å’Œå¤–éƒ¨ä¿¡æ¯ã€‚å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰å·²æˆä¸ºå¢å¼ºLLMæ¨ç†èƒ½åŠ›çš„ä¸€ç§æœ‰å‰é€”çš„æ¨¡å¼ï¼Œé€šè¿‡ä¸æœç´¢å¼•æ“çš„å¤šè½®äº¤äº’å®ç°ã€‚ç„¶è€Œï¼Œç°æœ‰çš„åŸºäºRLçš„æœç´¢ä»£ç†ä¾èµ–äºå•ä¸€çš„LLMæ¥åŒæ—¶å¤„ç†æœç´¢è§„åˆ’å’Œé—®ç­”ä»»åŠ¡ï¼Œè¿™é™åˆ¶äº†å®ƒä»¬åŒæ—¶ä¼˜åŒ–è¿™ä¸¤ç§åŠŸèƒ½çš„èƒ½åŠ›ã€‚å®è·µä¸­ï¼Œå¤æ‚çš„AIæœç´¢ç³»ç»Ÿé€šå¸¸ä½¿ç”¨å¤§å‹ã€å›ºå®šçš„LLMï¼ˆå¦‚GPT-4ã€DeepSeek-R1ï¼‰æ¥ä¿è¯é«˜è´¨é‡çš„é—®ç­”ã€‚å› æ­¤ï¼Œä¸€ä¸ªæ›´æœ‰æ•ˆå’Œé«˜æ•ˆçš„æ–¹æ³•æ˜¯ä½¿ç”¨ä¸“æ³¨äºæœç´¢è§„åˆ’çš„å°å‹ã€å¯è®­ç»ƒçš„LLMã€‚æœ¬æ–‡æå‡ºäº†åä¸ºAI-SearchPlannerçš„æ–°å‹å¼ºåŒ–å­¦ä¹ æ¡†æ¶ï¼Œæ—¨åœ¨é€šè¿‡ä¸“æ³¨äºæœç´¢è§„åˆ’æ¥æé«˜å›ºå®šé—®ç­”æ¨¡å‹çš„è¡¨ç°ã€‚å®éªŒè¯æ˜ï¼ŒAI SearchPlanneråœ¨æœ‰æ•ˆæ€§å’Œæ•ˆç‡ä¸Šå‡ä¼˜äºç°æœ‰çš„åŸºäºRLçš„æœç´¢ä»£ç†ï¼ŒåŒæ—¶åœ¨ä¸åŒçš„å›ºå®šé—®ç­”æ¨¡å‹å’Œæ•°æ®é¢†åŸŸè¡¨ç°å‡ºå¼ºå¤§çš„æ³›åŒ–èƒ½åŠ›ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä¸æœç´¢å¼•æ“çš„ç»“åˆç ”ç©¶æ—¨åœ¨ç»“åˆLLMçš„å†…éƒ¨é¢„è®­ç»ƒçŸ¥è¯†å’Œå¤–éƒ¨ä¿¡æ¯ã€‚</li>
<li>å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰å·²ç”¨äºå¢å¼ºLLMçš„æ¨ç†èƒ½åŠ›ï¼Œé€šè¿‡å¤šè½®äº¤äº’å®ç°ã€‚</li>
<li>ç°æœ‰åŸºäºRLçš„æœç´¢ä»£ç†ä½¿ç”¨å•ä¸€LLMå¤„ç†æœç´¢è§„åˆ’å’Œé—®ç­”ä»»åŠ¡ï¼Œå­˜åœ¨ä¼˜åŒ–é™åˆ¶ã€‚</li>
<li>å¤æ‚AIæœç´¢ç³»ç»Ÿä¾èµ–å¤§å‹ã€å›ºå®šçš„LLMæ¥ä¿è¯é«˜è´¨é‡é—®ç­”ã€‚</li>
<li>AI-SearchPlanneræ¡†æ¶é€šè¿‡ä¸“æ³¨äºæœç´¢è§„åˆ’æ¥æé«˜å›ºå®šé—®ç­”æ¨¡å‹çš„è¡¨ç°ã€‚</li>
<li>AI SearchPlannerå¼•å…¥ä¸‰ä¸ªå…³é”®åˆ›æ–°ç‚¹ï¼šè§£è€¦æœç´¢è§„åˆ’å™¨å’Œç”Ÿæˆå™¨çš„æ¶æ„ã€åŒé‡å¥–åŠ±å¯¹é½ç”¨äºæœç´¢è§„åˆ’ã€è§„åˆ’æ•ˆç”¨å’Œæˆæœ¬çš„å¸•ç´¯æ‰˜ä¼˜åŒ–ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.20368">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-09\./crop_R1_Reasoning/2508.20368v2/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-09\./crop_R1_Reasoning/2508.20368v2/page_2_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-09\./crop_R1_Reasoning/2508.20368v2/page_5_0.jpg" align="middle">
</details>


<h1 id="-13"><a href="#-13" class="headerlink" title=""></a></h1><h2 id="FedReFT-Federated-Representation-Fine-Tuning-with-All-But-Me-Aggregation"><a href="#FedReFT-Federated-Representation-Fine-Tuning-with-All-But-Me-Aggregation" class="headerlink" title="FedReFT: Federated Representation Fine-Tuning with All-But-Me   Aggregation"></a>FedReFT: Federated Representation Fine-Tuning with All-But-Me   Aggregation</h2><p><strong>Authors:Fatema Siddika, Md Anwar Hossen, J. Pablo MuÃ±oz, Tanya Roosta, Anuj Sharma, Ali Jannesari</strong></p>
<p>Parameter-efficient fine-tuning (PEFT) has attracted significant attention for adapting large pre-trained models by modifying a small subset of parameters. Recently, Representation Fine-tuning (ReFT) has emerged as an effective alternative. ReFT shifts the fine-tuning paradigm from updating model weights to directly manipulating hidden representations that capture rich semantic information, and performs better than state-of-the-art PEFTs in standalone settings. However, its application in Federated Learning (FL) remains challenging due to heterogeneity in clientsâ€™ data distributions, model capacities, and computational resources. To address these challenges, we introduce Federated Representation Fine-Tuning (FedReFT), a novel approach to fine-tune the clientâ€™s hidden representation. FedReFT applies sparse intervention layers to steer hidden representations directly, offering a lightweight and semantically rich fine-tuning alternative ideal for edge devices. However, representation-level updates are especially vulnerable to aggregation mismatch under different task heterogeneity, where naive averaging can corrupt semantic alignment. To mitigate this issue, we propose All-But-Me (ABM) aggregation, where each client receives the aggregated updates of others and partially incorporates them, enabling stable and personalized learning by balancing local focus with global knowledge. We evaluate FedReFT on commonsense reasoning, arithmetic reasoning, instruction-tuning, and GLUE, where it consistently outperforms state-of-the-art PEFT methods in FL, achieving 7x-15x higher parameter efficiency compared to leading LoRA-based approaches. </p>
<blockquote>
<p>å‚æ•°é«˜æ•ˆå¾®è°ƒï¼ˆPEFTï¼‰é€šè¿‡ä¿®æ”¹ä¸€å°éƒ¨åˆ†å‚æ•°æ¥é€‚åº”å¤§å‹é¢„è®­ç»ƒæ¨¡å‹ï¼Œå·²ç»å¼•èµ·äº†äººä»¬çš„å¹¿æ³›å…³æ³¨ã€‚æœ€è¿‘ï¼Œè¡¨ç¤ºå¾®è°ƒï¼ˆReFTï¼‰ä½œä¸ºä¸€ç§æœ‰æ•ˆçš„æ›¿ä»£æ–¹æ³•åº”è¿è€Œç”Ÿã€‚ReFTå°†å¾®è°ƒèŒƒå¼ä»æ›´æ–°æ¨¡å‹æƒé‡è½¬å‘ç›´æ¥æ“ä½œéšè—è¡¨ç¤ºï¼Œè¿™äº›éšè—è¡¨ç¤ºæ•æ‰äº†ä¸°å¯Œçš„è¯­ä¹‰ä¿¡æ¯ï¼Œå¹¶åœ¨ç‹¬ç«‹è®¾ç½®ä¸­è¡¨ç°å¾—æ¯”æœ€å…ˆè¿›çš„PEFTæ›´å¥½ã€‚ç„¶è€Œï¼Œå…¶åœ¨è”é‚¦å­¦ä¹ ï¼ˆFLï¼‰ä¸­çš„åº”ç”¨ä»ç„¶å…·æœ‰æŒ‘æˆ˜æ€§ï¼Œä¸»è¦æ˜¯ç”±äºå®¢æˆ·ç«¯æ•°æ®åˆ†å¸ƒã€æ¨¡å‹å®¹é‡å’Œè®¡ç®—èµ„æºçš„å¼‚è´¨æ€§ã€‚ä¸ºäº†è§£å†³è¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬å¼•å…¥äº†è”é‚¦è¡¨ç¤ºå¾®è°ƒï¼ˆFedReFTï¼‰è¿™ä¸€æ–°å‹éšè—è¡¨ç¤ºå¾®è°ƒæ–¹æ³•ã€‚FedReFTé€šè¿‡ç¨€ç–å¹²é¢„å±‚ç›´æ¥å¼•å¯¼éšè—è¡¨ç¤ºï¼Œæä¾›äº†ä¸€ç§è½»é‡çº§ä¸”è¯­ä¹‰ä¸°å¯Œçš„å¾®è°ƒæ›¿ä»£æ–¹æ¡ˆï¼Œç‰¹åˆ«é€‚åˆè¾¹ç¼˜è®¾å¤‡ã€‚ç„¶è€Œï¼Œåœ¨ä»»åŠ¡å¼‚è´¨æ€§ä¸‹ï¼Œè¡¨ç¤ºçº§æ›´æ–°ç‰¹åˆ«å®¹æ˜“å—åˆ°èšåˆä¸åŒ¹é…çš„å½±å“ï¼Œç®€å•çš„å¹³å‡å¯èƒ½ä¼šç ´åè¯­ä¹‰å¯¹é½ã€‚ä¸ºäº†ç¼“è§£è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†â€œé™¤äº†æˆ‘â€ï¼ˆABMï¼‰èšåˆæ–¹æ³•ï¼Œæ¯ä¸ªå®¢æˆ·ç«¯æ¥æ”¶å…¶ä»–å®¢æˆ·ç«¯çš„èšåˆæ›´æ–°ï¼Œå¹¶éƒ¨åˆ†åœ°èå…¥å®ƒä»¬ï¼Œé€šè¿‡å¹³è¡¡æœ¬åœ°ç„¦ç‚¹å’Œå…¨å±€çŸ¥è¯†æ¥å®ç°ç¨³å®šå’Œä¸ªäººåŒ–çš„å­¦ä¹ ã€‚æˆ‘ä»¬åœ¨å¸¸è¯†æ¨ç†ã€ç®—æœ¯æ¨ç†ã€æŒ‡ä»¤è°ƒæ•´å’ŒGLUEä¸Šå¯¹FedReFTè¿›è¡Œäº†è¯„ä¼°ï¼Œå®ƒå§‹ç»ˆåœ¨FLä¸­è¶…è¶Šæœ€å…ˆè¿›çš„PEFTæ–¹æ³•ï¼Œä¸é¢†å…ˆçš„LoRAæ–¹æ³•ç›¸æ¯”ï¼Œå®ç°äº†7å€è‡³15å€æ›´é«˜çš„å‚æ•°æ•ˆç‡ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.20295v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†é’ˆå¯¹è”é‚¦å­¦ä¹ ä¸­çš„è¡¨ç¤ºç²¾ç»†è°ƒæ•´ï¼ˆReFTï¼‰çš„æ–°æ–¹æ³•â€”â€”Federated Representation Fine-Tuningï¼ˆFedReFTï¼‰ã€‚FedReFTé€šè¿‡åœ¨å®¢æˆ·ç«¯åº”ç”¨ç¨€ç–å¹²é¢„å±‚æ¥ç›´æ¥å¼•å¯¼éšè—è¡¨ç¤ºï¼Œæä¾›äº†ä¸€ç§è½»é‡çº§ä¸”è¯­ä¹‰ä¸°å¯Œçš„ç²¾ç»†è°ƒæ•´æ›¿ä»£æ–¹æ¡ˆï¼Œå°¤å…¶é€‚ç”¨äºè¾¹ç¼˜è®¾å¤‡ã€‚ä¸ºè§£å†³ä¸åŒä»»åŠ¡å¼‚è´¨æ€§ä¸‹çš„èšåˆä¸åŒ¹é…é—®é¢˜ï¼Œæå‡ºAll-But-Meï¼ˆABMï¼‰èšåˆç­–ç•¥ï¼Œä½¿æ¯ä¸ªå®¢æˆ·ç«¯åœ¨å¹³è¡¡å±€éƒ¨ç„¦ç‚¹ä¸å…¨å±€çŸ¥è¯†çš„åŒæ—¶ï¼Œå®ç°ç¨³å®šä¸”ä¸ªæ€§åŒ–çš„å­¦ä¹ ã€‚åœ¨å¸¸è¯†æ¨ç†ã€ç®—æœ¯æ¨ç†ã€æŒ‡ä»¤è°ƒæ•´å’ŒGLUEç­‰ä»»åŠ¡ä¸Šè¯„ä¼°æ—¶ï¼ŒFedReFTåœ¨è”é‚¦å­¦ä¹ ä¸­æŒç»­è¶…è¶Šå…ˆè¿›çš„å‚æ•°æ•ˆç‡å¾®è°ƒæ–¹æ³•ï¼Œç›¸è¾ƒäºé¢†å…ˆçš„LoRAæ–¹æ³•å®ç°äº†7å€è‡³15å€æ›´é«˜çš„å‚æ•°æ•ˆç‡ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>Federated Representation Fine-Tuning (FedReFT) æ˜¯ä¸€ä¸ªæ–°çš„æ–¹æ³•ï¼Œç”¨äºåœ¨è”é‚¦å­¦ä¹ ä¸­ç²¾ç»†è°ƒæ•´è¡¨ç¤ºï¼ˆReFTï¼‰ã€‚</li>
<li>FedReFT é€šè¿‡åœ¨å®¢æˆ·ç«¯åº”ç”¨ç¨€ç–å¹²é¢„å±‚ç›´æ¥å¼•å¯¼éšè—è¡¨ç¤ºï¼Œé€‚åˆåœ¨è¾¹ç¼˜è®¾å¤‡ä½¿ç”¨ã€‚</li>
<li>è”é‚¦å­¦ä¹ ä¸­å­˜åœ¨æ•°æ®åˆ†å¸ƒã€æ¨¡å‹å®¹é‡å’Œè®¡ç®—èµ„æºå¼‚è´¨æ€§çš„é—®é¢˜ã€‚</li>
<li>ä¸ºè§£å†³ä¸åŒä»»åŠ¡å¼‚è´¨æ€§ä¸‹çš„èšåˆä¸åŒ¹é…é—®é¢˜ï¼ŒFedReFT æå‡ºäº† All-But-Meï¼ˆABMï¼‰èšåˆç­–ç•¥ã€‚</li>
<li>ABM èšåˆç­–ç•¥ä½¿æ¯ä¸ªå®¢æˆ·ç«¯èƒ½å¹³è¡¡å±€éƒ¨ç„¦ç‚¹å’Œå…¨å±€çŸ¥è¯†ï¼Œå®ç°ç¨³å®šä¸”ä¸ªæ€§åŒ–çš„å­¦ä¹ ã€‚</li>
<li>FedReFT åœ¨å¤šä¸ªä»»åŠ¡ä¸Šè¡¨ç°å‡ºä¼˜å¼‚çš„æ€§èƒ½ï¼ŒæŒç»­è¶…è¶Šå…ˆè¿›çš„å‚æ•°æ•ˆç‡å¾®è°ƒæ–¹æ³•ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.20295">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-09\./crop_R1_Reasoning/2508.20295v1/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-09\./crop_R1_Reasoning/2508.20295v1/page_1_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-09\./crop_R1_Reasoning/2508.20295v1/page_2_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-09\./crop_R1_Reasoning/2508.20295v1/page_3_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-09\./crop_R1_Reasoning/2508.20295v1/page_4_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-09\./crop_R1_Reasoning/2508.20295v1/page_5_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-09\./crop_R1_Reasoning/2508.20295v1/page_5_1.jpg" align="middle">
</details>


<h1 id="-14"><a href="#-14" class="headerlink" title=""></a></h1><h2 id="Memory-R1-Enhancing-Large-Language-Model-Agents-to-Manage-and-Utilize-Memories-via-Reinforcement-Learning"><a href="#Memory-R1-Enhancing-Large-Language-Model-Agents-to-Manage-and-Utilize-Memories-via-Reinforcement-Learning" class="headerlink" title="Memory-R1: Enhancing Large Language Model Agents to Manage and Utilize   Memories via Reinforcement Learning"></a>Memory-R1: Enhancing Large Language Model Agents to Manage and Utilize   Memories via Reinforcement Learning</h2><p><strong>Authors:Sikuan Yan, Xiufeng Yang, Zuchao Huang, Ercong Nie, Zifeng Ding, Zonggen Li, Xiaowen Ma, Hinrich SchÃ¼tze, Volker Tresp, Yunpu Ma</strong></p>
<p>Large Language Models (LLMs) have demonstrated impressive capabilities across a wide range of NLP tasks, but they remain fundamentally stateless, constrained by limited context windows that hinder long-horizon reasoning. Recent efforts to address this limitation often augment LLMs with an external memory bank, yet most existing pipelines are static and heuristic-driven, lacking any learned mechanism for deciding what to store, update, or retrieve. We present Memory-R1, a reinforcement learning (RL) framework that equips LLMs with the ability to actively manage and utilize external memory through two specialized agents: a Memory Manager that learns to perform structured memory operations, including adding, updating, deleting, or taking no operation on memory entries; and an Answer Agent that selects the most relevant entries and reasons over them to produce an answer. Both agents are fine-tuned with outcome-driven RL (PPO and GRPO), enabling adaptive memory management and utilization with minimal supervision. With as few as 152 question-answer pairs and a corresponding temporal memory bank for training, Memory-R1 outperforms the strongest existing baseline and demonstrates strong generalization across diverse question types and LLM backbones. Beyond presenting an effective approach, this work provides insights into how RL can unlock more agentic, memory-aware behavior in LLMs, pointing toward richer, more persistent reasoning systems. </p>
<blockquote>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨å¹¿æ³›çš„NLPä»»åŠ¡ä¸­è¡¨ç°å‡ºäº†ä»¤äººå°è±¡æ·±åˆ»çš„èƒ½åŠ›ï¼Œä½†å®ƒä»¬æœ¬è´¨ä¸Šæ˜¯æ— çŠ¶æ€çš„ï¼Œå—é™äºæœ‰é™çš„ä¸Šä¸‹æ–‡çª—å£ï¼Œé˜»ç¢äº†é•¿æœŸæ¨ç†ã€‚æœ€è¿‘ä¸ºè§£å†³è¿™ä¸€å±€é™æ€§çš„åŠªåŠ›é€šå¸¸æ˜¯é€šè¿‡ä½¿ç”¨å¤–éƒ¨è®°å¿†åº“æ¥å¢å¼ºLLMï¼Œä½†å¤§å¤šæ•°ç°æœ‰ç®¡é“éƒ½æ˜¯é™æ€çš„å’Œå¯å‘å¼é©±åŠ¨çš„ï¼Œç¼ºä¹ä»»ä½•å­¦ä¹ æœºåˆ¶æ¥å†³å®šå­˜å‚¨ã€æ›´æ–°æˆ–æ£€ç´¢ä»€ä¹ˆã€‚æˆ‘ä»¬æå‡ºäº†Memory-R1ï¼Œè¿™æ˜¯ä¸€ä¸ªå¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰æ¡†æ¶ï¼Œå®ƒä¸ºLLMæä¾›äº†ä¸»åŠ¨ç®¡ç†å’Œåˆ©ç”¨å¤–éƒ¨è®°å¿†çš„èƒ½åŠ›ï¼Œé€šè¿‡ä¸¤ä¸ªä¸“ç”¨ä»£ç†å®ç°ï¼šå†…å­˜ç®¡ç†å™¨å­¦ä¹ æ‰§è¡Œç»“æ„åŒ–å†…å­˜æ“ä½œï¼ŒåŒ…æ‹¬æ·»åŠ ã€æ›´æ–°ã€åˆ é™¤æˆ–å¯¹å†…å­˜æ¡ç›®ä¸æ‰§è¡Œä»»ä½•æ“ä½œï¼›ç­”æ¡ˆä»£ç†é€‰æ‹©æœ€ç›¸å…³çš„æ¡ç›®å¹¶å¯¹å®ƒä»¬è¿›è¡Œæ¨ç†ä»¥äº§ç”Ÿç­”æ¡ˆã€‚ä¸¤ä¸ªä»£ç†éƒ½ä½¿ç”¨ä»¥ç»“æœé©±åŠ¨çš„å¼ºåŒ–å­¦ä¹ ï¼ˆPPOå’ŒGRPOï¼‰è¿›è¡Œå¾®è°ƒï¼Œå®ç°è‡ªé€‚åº”å†…å­˜ç®¡ç†å’Œåˆ©ç”¨ï¼Œç›‘ç£æœ€å°‘ã€‚ä»…ä½¿ç”¨152ä¸ªé—®ç­”å¯¹å’Œç›¸åº”çš„ä¸´æ—¶è®°å¿†åº“è¿›è¡Œè®­ç»ƒï¼ŒMemory-R1è¶…è¶Šäº†æœ€å¼ºçš„ç°æœ‰åŸºçº¿ï¼Œå¹¶åœ¨å„ç§é—®é¢˜å’ŒLLMä¸»å¹²ä¸Šè¡¨ç°å‡ºå¼ºå¤§çš„æ³›åŒ–èƒ½åŠ›ã€‚é™¤äº†æä¾›ä¸€ç§æœ‰æ•ˆçš„æ–¹æ³•å¤–ï¼Œè¿™é¡¹å·¥ä½œè¿˜æ­ç¤ºäº†å¼ºåŒ–å­¦ä¹ å¦‚ä½•è§£é”LLMä¸­æ›´å…·ä»£ç†æ€§çš„ã€å…·æœ‰è®°å¿†æ„è¯†çš„è¡Œä¸ºï¼Œä¸ºæ›´ä¸°å¯Œã€æ›´æŒä¹…çš„æ¨ç†ç³»ç»ŸæŒ‡æ˜äº†æ–¹å‘ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.19828v3">PDF</a> work in progress</p>
<p><strong>Summary</strong></p>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å¤šä¸ªNLPä»»åŠ¡ä¸­è¡¨ç°å‡ºå¼ºå¤§çš„èƒ½åŠ›ï¼Œä½†å®ƒä»¬æœ¬è´¨ä¸Šæ˜¯æ— çŠ¶æ€çš„ï¼Œå—é™äºçŸ­å°çš„ä¸Šä¸‹æ–‡çª—å£ï¼Œå½±å“é•¿è¿œæ¨ç†ã€‚æœ€è¿‘çš„ç ”ç©¶å°è¯•é€šè¿‡å¤–éƒ¨è®°å¿†åº“æ¥å¢å¼ºLLMsçš„èƒ½åŠ›ï¼Œä½†ç°æœ‰ç®¡é“å¤§å¤šæ˜¯é™æ€çš„ã€å¯å‘å¼é©±åŠ¨çš„ï¼Œç¼ºä¹å­¦ä¹ æœºåˆ¶æ¥å†³å®šå­˜å‚¨ã€æ›´æ–°æˆ–æ£€ç´¢ä»€ä¹ˆã€‚æœ¬æ–‡æå‡ºMemory-R1ï¼Œä¸€ä¸ªå¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰æ¡†æ¶ï¼Œä¸ºLLMsé…å¤‡ä¸»åŠ¨ç®¡ç†å’Œåˆ©ç”¨å¤–éƒ¨è®°å¿†çš„èƒ½åŠ›ï¼ŒåŒ…æ‹¬ä¸¤ä¸ªä¸“é—¨ä»£ç†ï¼šå†…å­˜ç®¡ç†å™¨å­¦ä¹ æ‰§è¡Œç»“æ„åŒ–å†…å­˜æ“ä½œï¼ŒåŒ…æ‹¬æ·»åŠ ã€æ›´æ–°ã€åˆ é™¤æˆ–ä¸å¯¹å†…å­˜æ¡ç›®è¿›è¡Œæ“ä½œï¼›ç­”æ¡ˆä»£ç†é€‰æ‹©æœ€ç›¸å…³çš„æ¡ç›®å¹¶è¿›è¡Œæ¨ç†ä»¥äº§ç”Ÿç­”æ¡ˆã€‚ä¸¤ä¸ªä»£ç†å‡é‡‡ç”¨ç›®æ ‡é©±åŠ¨RLï¼ˆPPOå’ŒGRPOï¼‰è¿›è¡Œå¾®è°ƒï¼Œå¯åœ¨æå°‘ç›‘ç£ä¸‹å®ç°è‡ªé€‚åº”å†…å­˜ç®¡ç†å’Œåˆ©ç”¨ã€‚ä»…ä½¿ç”¨å°‘é‡é—®ç­”å¯¹å’Œç›¸åº”çš„æ—¶åºè®°å¿†åº“è¿›è¡Œè®­ç»ƒï¼ŒMemory-R1å³å¯è¶…è¶Šæœ€å¼ºç°æœ‰åŸºçº¿ï¼Œåœ¨å¤šç§é—®é¢˜å’ŒLLMä¸»å¹²ä¸Šå±•ç°å‡ºå¼ºå¤§çš„æ³›åŒ–èƒ½åŠ›ã€‚æœ¬æ–‡ä¸ä»…æä¾›äº†ä¸€ç§æœ‰æ•ˆçš„æ–¹æ³•ï¼Œè¿˜æ­ç¤ºäº†å¼ºåŒ–å­¦ä¹ å¦‚ä½•è§£é”LLMsä¸­æ›´æ™ºèƒ½ã€è®°å¿†æ„ŸçŸ¥çš„è¡Œä¸ºï¼ŒæŒ‡å‘æ›´ä¸°å¯Œã€æ›´æŒä¹…çš„æ¨ç†ç³»ç»Ÿã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å¤„ç†é•¿è¿œæ¨ç†æ—¶å—é™äºä¸Šä¸‹æ–‡çª—å£ã€‚</li>
<li>ç°æœ‰å¢å¼ºLLMsçš„æ–¹æ³•å¤§å¤šé‡‡ç”¨é™æ€ã€å¯å‘å¼é©±åŠ¨çš„æ–¹å¼ï¼Œç¼ºä¹å­¦ä¹ æœºåˆ¶æ¥å†³å®šå†…å­˜ç®¡ç†ã€‚</li>
<li>Memory-R1æ˜¯ä¸€ä¸ªå¼ºåŒ–å­¦ä¹ æ¡†æ¶ï¼Œä¸ºLLMsé…å¤‡ä¸»åŠ¨ç®¡ç†å’Œåˆ©ç”¨å¤–éƒ¨è®°å¿†çš„èƒ½åŠ›ã€‚</li>
<li>Memory-R1åŒ…æ‹¬ä¸¤ä¸ªä¸“é—¨ä»£ç†ï¼šå†…å­˜ç®¡ç†å™¨å’Œç­”æ¡ˆä»£ç†ï¼Œåˆ†åˆ«è´Ÿè´£ç»“æ„åŒ–å†…å­˜æ“ä½œå’Œç­”æ¡ˆç”Ÿæˆã€‚</li>
<li>Memory-R1é€šè¿‡ç›®æ ‡é©±åŠ¨RLè¿›è¡Œå¾®è°ƒï¼Œå®ç°è‡ªé€‚åº”å†…å­˜ç®¡ç†å’Œåˆ©ç”¨ã€‚</li>
<li>ä»…ä½¿ç”¨å°‘é‡é—®ç­”å¯¹è¿›è¡Œè®­ç»ƒï¼ŒMemory-R1å³å¯è¶…è¶Šç°æœ‰æœ€å¼ºåŸºçº¿ï¼Œå±•ç°å‡ºå¼ºå¤§çš„æ³›åŒ–èƒ½åŠ›ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.19828">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-09\./crop_R1_Reasoning/2508.19828v3/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-09\./crop_R1_Reasoning/2508.19828v3/page_1_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-09\./crop_R1_Reasoning/2508.19828v3/page_2_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-09\./crop_R1_Reasoning/2508.19828v3/page_3_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-09\./crop_R1_Reasoning/2508.19828v3/page_5_0.jpg" align="middle">
</details>


<h1 id="-15"><a href="#-15" class="headerlink" title=""></a></h1><h2 id="Understanding-Tool-Integrated-Reasoning"><a href="#Understanding-Tool-Integrated-Reasoning" class="headerlink" title="Understanding Tool-Integrated Reasoning"></a>Understanding Tool-Integrated Reasoning</h2><p><strong>Authors:Heng Lin, Zhongwen Xu</strong></p>
<p>We study why Tool-Integrated Reasoning (TIR) makes Large Language Models (LLMs) more capable. While LLMs integrated with tools like Python code interpreters show great promise, a principled theory explaining why this paradigm is effective has been missing. This work provides the first formal proof that TIR fundamentally expands an LLMâ€™s capabilities. We demonstrate that tools enable a strict expansion of the modelâ€™s empirical and feasible support, breaking the capability ceiling of pure-text models by unlocking problem-solving strategies that are otherwise impossible or intractably verbose. To guide model behavior without compromising training stability and performance, we also introduce Advantage Shaping Policy Optimization (ASPO), a novel algorithm that directly modifies the advantage function to guide the policy behavior. We conduct comprehensive experiments on challenging mathematical benchmarks, leveraging a Python interpreter as the external tool. Our results show that the TIR model decisively outperforms its pure-text counterpart on the pass@k metric. Crucially, this advantage is not confined to computationally-intensive problems but extends to those requiring significant abstract insight. We further identify the emergent cognitive patterns that illustrate how models learn to think with tools. Finally, we report improved tool usage behavior with early code invocation and much more interactive turns with ASPO. Overall, our work provides the first principled explanation for TIRâ€™s success, shifting the focus from the mere fact that tools work to why and how they enable more powerful reasoning. </p>
<blockquote>
<p>æˆ‘ä»¬ç ”ç©¶ä¸ºä»€ä¹ˆå·¥å…·é›†æˆæ¨ç†ï¼ˆTIRï¼‰èƒ½å¤Ÿä½¿å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ›´å…·èƒ½åŠ›ã€‚è™½ç„¶åƒPythonä»£ç è§£é‡Šå™¨ç­‰å·¥å…·ä¸LLMçš„é›†æˆå±•ç°å‡ºå·¨å¤§çš„æ½œåŠ›ï¼Œä½†ç¼ºä¹ä¸€ä¸ªåŸåˆ™æ€§çš„ç†è®ºæ¥è§£é‡Šè¿™ä¸€æ¨¡å¼ä¸ºä½•æœ‰æ•ˆã€‚è¿™é¡¹å·¥ä½œæä¾›äº†é¦–ä¸ªæ­£å¼è¯æ˜ï¼Œè¯æ˜TIRä»æ ¹æœ¬ä¸Šæ‰©å±•äº†LLMçš„èƒ½åŠ›ã€‚æˆ‘ä»¬è¯æ˜ï¼Œå·¥å…·ä½¿æ¨¡å‹çš„å®è¯å’Œå¯è¡Œæ”¯æŒå¾—åˆ°äº†ä¸¥æ ¼çš„æ‰©å±•ï¼Œé€šè¿‡è§£é”é—®é¢˜è§£å†³æ–¹æ¡ˆç­–ç•¥ï¼Œæ‰“ç ´äº†çº¯æ–‡æœ¬æ¨¡å‹çš„èƒ½åŠ›ä¸Šé™ï¼Œå¦åˆ™è¿™äº›ç­–ç•¥æ˜¯ä¸å¯èƒ½æˆ–æå…¶å†—é•¿çš„ã€‚ä¸ºäº†åœ¨ä¸æŸå®³è®­ç»ƒç¨³å®šæ€§å’Œæ€§èƒ½çš„æƒ…å†µä¸‹å¼•å¯¼æ¨¡å‹è¡Œä¸ºï¼Œæˆ‘ä»¬è¿˜å¼•å…¥äº†ä¼˜åŠ¿å¡‘å½¢ç­–ç•¥ä¼˜åŒ–ï¼ˆASPOï¼‰ï¼Œè¿™æ˜¯ä¸€ç§ç›´æ¥ä¿®æ”¹ä¼˜åŠ¿å‡½æ•°ä»¥å¼•å¯¼ç­–ç•¥è¡Œä¸ºçš„æ–°å‹ç®—æ³•ã€‚æˆ‘ä»¬åœ¨å…·æœ‰æŒ‘æˆ˜æ€§çš„æ•°å­¦åŸºå‡†æµ‹è¯•ä¸Šè¿›è¡Œäº†å…¨é¢çš„å®éªŒï¼Œåˆ©ç”¨Pythonè§£é‡Šå™¨ä½œä¸ºå¤–éƒ¨å·¥å…·ã€‚ç»“æœè¡¨æ˜ï¼Œåœ¨kæŒ‡æ ‡æ–¹é¢ï¼ŒTIRæ¨¡å‹æ˜¾è‘—ä¼˜äºçº¯æ–‡æœ¬æ¨¡å‹ã€‚å…³é”®çš„æ˜¯ï¼Œè¿™ä¸€ä¼˜åŠ¿ä¸ä»…é™äºè®¡ç®—å¯†é›†å‹é—®é¢˜ï¼Œè€Œä¸”æ‰©å±•åˆ°äº†éœ€è¦é‡å¤§æŠ½è±¡æ´å¯ŸåŠ›çš„é—®é¢˜ã€‚æˆ‘ä»¬è¿›ä¸€æ­¥ç¡®å®šäº†æ–°å…´çš„è®¤çŸ¥æ¨¡å¼ï¼Œè¯´æ˜äº†æ¨¡å‹å¦‚ä½•ä½¿ç”¨å·¥å…·è¿›è¡Œæ€ç»´ã€‚æœ€åï¼Œæˆ‘ä»¬æŠ¥å‘Šäº†ä½¿ç”¨ASP0çš„æ—©æœŸä»£ç è°ƒç”¨æ”¹å–„äº†å·¥å…·ä½¿ç”¨è¡Œä¸ºï¼Œä»¥åŠä¸æ›´å¤šäº¤äº’å¼å›åˆçš„äº’åŠ¨ã€‚æ€»çš„æ¥è¯´ï¼Œæˆ‘ä»¬çš„å·¥ä½œæä¾›äº†å¯¹TIRæˆåŠŸçš„é¦–æ¬¡åŸåˆ™æ€§è§£é‡Šï¼Œå°†é‡ç‚¹ä»å·¥å…·å·¥ä½œçš„ç®€å•äº‹å®è½¬å‘ä¸ºä»€ä¹ˆä»¥åŠå¦‚ä½•ä½¿å®ƒä»¬èƒ½å¤Ÿæ›´å¼ºå¤§çš„æ¨ç†èƒ½åŠ›ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.19201v1">PDF</a> </p>
<p><strong>Summary</strong><br>åœ¨ç»“åˆäº†å·¥å…·ï¼ˆå¦‚Pythonè§£é‡Šå™¨ï¼‰çš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ä¸­ï¼Œæˆ‘ä»¬ç ”ç©¶å·¥å…·é›†æˆæ¨ç†ï¼ˆTIRï¼‰ä¸ºä»€ä¹ˆèƒ½å¤Ÿå¢å¼ºæ¨¡å‹çš„èƒ½åŠ›ã€‚è¿™é¡¹å·¥ä½œæä¾›äº†ç¬¬ä¸€ä¸ªæ­£å¼è¯æ˜ï¼Œè¯æ˜TIRä»æ ¹æœ¬ä¸Šæ‰©å¤§äº†LLMçš„èƒ½åŠ›ã€‚å·¥å…·çš„ä½¿ç”¨ä½¿å¾—æ¨¡å‹èƒ½å¤Ÿè§£å†³ä¹‹å‰æ— æ³•å®ç°æˆ–éš¾ä»¥è¡¨è¾¾çš„é—®é¢˜è§£å†³ç­–ç•¥ï¼Œçªç ´äº†çº¯æ–‡æœ¬æ¨¡å‹çš„èƒ½åŠ›ä¸Šé™ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°çš„ç®—æ³•ä¼˜åŠ¿å¡‘å½¢ç­–ç•¥ä¼˜åŒ–ï¼ˆASPOï¼‰ï¼Œè¯¥ç®—æ³•é€šè¿‡ç›´æ¥ä¿®æ”¹ä¼˜åŠ¿å‡½æ•°æ¥æŒ‡å¯¼æ¨¡å‹è¡Œä¸ºï¼ŒåŒæ—¶ä¸æŸå®³è®­ç»ƒç¨³å®šæ€§å’Œæ€§èƒ½ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œåœ¨å…·æœ‰æŒ‘æˆ˜æ€§çš„æ•°å­¦åŸºå‡†æµ‹è¯•ä¸­ï¼ŒTIRæ¨¡å‹åœ¨pass@kæŒ‡æ ‡ä¸Šæ˜æ˜¾è¶…è¶Šäº†çº¯æ–‡æœ¬æ¨¡å‹ã€‚å…³é”®çš„æ˜¯ï¼Œè¿™ç§ä¼˜åŠ¿ä¸ä»…é™äºè®¡ç®—å¯†é›†å‹é—®é¢˜ï¼Œè€Œä¸”æ‰©å±•åˆ°äº†éœ€è¦å¤§é‡æŠ½è±¡æ´å¯ŸåŠ›çš„é—®é¢˜ã€‚æˆ‘ä»¬çš„å·¥ä½œæä¾›äº†å¯¹TIRæˆåŠŸçš„é¦–æ¬¡åŸåˆ™æ€§è§£é‡Šï¼Œå°†é‡ç‚¹ä»å·¥å…·å·¥ä½œçš„å•çº¯äº‹å®è½¬å‘å·¥å…·å’Œå¦‚ä½•ä½¿æ¨ç†æ›´å¼ºå¤§çš„åŸå› å’Œæ–¹å¼ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>TIRèƒ½å¤Ÿå¢å¼ºLLMçš„èƒ½åŠ›ï¼šç ”ç©¶è¡¨æ˜å·¥å…·é›†æˆæ¨ç†ï¼ˆTIRï¼‰å¯ä»¥ä½¿å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰æ›´åŠ å¼ºå¤§ï¼Œè¿™ä¸€å‘ç°æœ‰ç€é‡å¤§çš„ç†è®ºå’Œå®è·µæ„ä¹‰ã€‚</li>
<li>TIRæ‰©å¤§äº†LLMçš„å¯è¡Œæ€§å’Œå®è¯æ”¯æŒï¼šå·¥å…·çš„ä½¿ç”¨ä½¿å¾—LLMèƒ½å¤Ÿè§£å†³æ›´å¤æ‚çš„é—®é¢˜ï¼Œçªç ´äº†çº¯æ–‡æœ¬æ¨¡å‹çš„èƒ½åŠ›é™åˆ¶ã€‚</li>
<li>ASPOç®—æ³•ç”¨äºæŒ‡å¯¼æ¨¡å‹è¡Œä¸ºï¼šä»‹ç»äº†ä¸€ç§æ–°çš„ç®—æ³•ä¼˜åŠ¿å¡‘å½¢ç­–ç•¥ä¼˜åŒ–ï¼ˆASPOï¼‰ï¼Œå®ƒå¯ä»¥åœ¨ä¸æŸå®³è®­ç»ƒç¨³å®šæ€§å’Œæ€§èƒ½çš„æƒ…å†µä¸‹ï¼Œç›´æ¥ä¿®æ”¹ä¼˜åŠ¿å‡½æ•°æ¥æŒ‡å¯¼æ¨¡å‹è¡Œä¸ºã€‚</li>
<li>TIRæ¨¡å‹åœ¨åŸºå‡†æµ‹è¯•ä¸­è¡¨ç°ä¼˜å¼‚ï¼šåœ¨å…·æœ‰æŒ‘æˆ˜æ€§çš„æ•°å­¦åŸºå‡†æµ‹è¯•ä¸­ï¼Œç»“åˆå·¥å…·çš„æ¨¡å‹ï¼ˆå¦‚Pythonè§£é‡Šå™¨ï¼‰æ˜¾è‘—ä¼˜äºçº¯æ–‡æœ¬æ¨¡å‹ã€‚</li>
<li>TIRçš„ä¼˜åŠ¿ä¸ä»…é™äºè®¡ç®—å¯†é›†å‹é—®é¢˜ï¼šé™¤äº†è®¡ç®—å¯†é›†å‹é—®é¢˜ï¼Œè¿™ç§ä¼˜åŠ¿è¿˜ä½“ç°åœ¨éœ€è¦æŠ½è±¡æ´å¯ŸåŠ›çš„é—®é¢˜è§£å†³ä¸Šã€‚</li>
<li>TIRçš„æˆåŠŸå¾—åˆ°äº†åŸåˆ™æ€§è§£é‡Šï¼šæˆ‘ä»¬çš„å·¥ä½œæä¾›äº†å¯¹å·¥å…·é›†æˆæ¨ç†ï¼ˆTIRï¼‰æˆåŠŸçš„é¦–æ¬¡åŸåˆ™æ€§è§£é‡Šï¼Œæ·±å…¥æ¢è®¨äº†å…¶èƒŒåçš„åŸç†å’Œæœºåˆ¶ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.19201">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-09\./crop_R1_Reasoning/2508.19201v1/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-09\./crop_R1_Reasoning/2508.19201v1/page_5_0.jpg" align="middle">
</details>


<h1 id="-16"><a href="#-16" class="headerlink" title=""></a></h1><h2 id="STARec-An-Efficient-Agent-Framework-for-Recommender-Systems-via-Autonomous-Deliberate-Reasoning"><a href="#STARec-An-Efficient-Agent-Framework-for-Recommender-Systems-via-Autonomous-Deliberate-Reasoning" class="headerlink" title="STARec: An Efficient Agent Framework for Recommender Systems via   Autonomous Deliberate Reasoning"></a>STARec: An Efficient Agent Framework for Recommender Systems via   Autonomous Deliberate Reasoning</h2><p><strong>Authors:Chenghao Wu, Ruiyang Ren, Junjie Zhang, Ruirui Wang, Zhongrui Ma, Qi Ye, Wayne Xin Zhao</strong></p>
<p>While modern recommender systems are instrumental in navigating information abundance, they remain fundamentally limited by static user modeling and reactive decision-making paradigms. Current large language model (LLM)-based agents inherit these shortcomings through their overreliance on heuristic pattern matching, yielding recommendations prone to shallow correlation bias, limited causal inference, and brittleness in sparse-data scenarios. We introduce STARec, a slow-thinking augmented agent framework that endows recommender systems with autonomous deliberative reasoning capabilities. Each user is modeled as an agent with parallel cognitions: fast response for immediate interactions and slow reasoning that performs chain-of-thought rationales. To cultivate intrinsic slow thinking, we develop anchored reinforcement training - a two-stage paradigm combining structured knowledge distillation from advanced reasoning models with preference-aligned reward shaping. This hybrid approach scaffolds agents in acquiring foundational capabilities (preference summarization, rationale generation) while enabling dynamic policy adaptation through simulated feedback loops. Experiments on MovieLens 1M and Amazon CDs benchmarks demonstrate that STARec achieves substantial performance gains compared with state-of-the-art baselines, despite using only 0.4% of the full training data. </p>
<blockquote>
<p>å°½ç®¡ç°ä»£æ¨èç³»ç»Ÿåœ¨ä¿¡æ¯ä¸°å¯Œæ€§å¯¼èˆªä¸­å‘æŒ¥äº†é‡è¦ä½œç”¨ï¼Œä½†å®ƒä»¬ä»ç„¶å—åˆ°é™æ€ç”¨æˆ·å»ºæ¨¡å’Œååº”å¼å†³ç­–èŒƒå¼çš„æ ¹æœ¬æ€§é™åˆ¶ã€‚å½“å‰åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹çš„ä»£ç†é€šè¿‡è¿‡åº¦ä¾èµ–å¯å‘å¼æ¨¡å¼åŒ¹é…ç»§æ‰¿äº†è¿™äº›ç¼ºç‚¹ï¼Œå¯¼è‡´æ¨èç»“æœå®¹æ˜“å‡ºç°æµ…ç›¸å…³æ€§åè§ã€æœ‰é™çš„å› æœæ¨ç†ä»¥åŠåœ¨æ•°æ®ç¨€ç–åœºæ™¯ä¸­çš„è„†å¼±æ€§ã€‚æˆ‘ä»¬å¼•å…¥äº†STARecï¼Œè¿™æ˜¯ä¸€ç§æ…¢æ€è€ƒå¢å¼ºä»£ç†æ¡†æ¶ï¼Œä¸ºæ¨èç³»ç»Ÿèµ‹äºˆè‡ªä¸»æ¨ç†èƒ½åŠ›ã€‚æ¯ä¸ªç”¨æˆ·éƒ½è¢«å»ºæ¨¡ä¸ºä¸€ä¸ªæ‹¥æœ‰å¹¶è¡Œè®¤çŸ¥çš„ä»£ç†ï¼šå¿«é€Ÿå“åº”å³æ—¶äº¤äº’å’Œæ…¢é€Ÿæ¨ç†ï¼Œè¿›è¡Œé“¾å¼æ€ç»´æ¨ç†ã€‚ä¸ºäº†åŸ¹å…»å†…åœ¨æ…¢æ€è€ƒï¼Œæˆ‘ä»¬å¼€å‘äº†é”šå®šå¼ºåŒ–è®­ç»ƒâ€”â€”ä¸€ä¸ªä¸¤é˜¶æ®µèŒƒå¼ï¼Œç»“åˆä»é«˜çº§æ¨ç†æ¨¡å‹è¿›è¡Œç»“æ„åŒ–çŸ¥è¯†è’¸é¦å’Œåå¥½å¯¹é½å¥–åŠ±å¡‘é€ ã€‚è¿™ç§æ··åˆæ–¹æ³•ä½¿ä»£ç†åœ¨è·å–åŸºç¡€èƒ½åŠ›ï¼ˆåå¥½æ€»ç»“ã€ç†ç”±ç”Ÿæˆï¼‰çš„åŒæ—¶ï¼Œé€šè¿‡æ¨¡æ‹Ÿåé¦ˆå¾ªç¯å®ç°åŠ¨æ€ç­–ç•¥é€‚åº”ã€‚åœ¨MovieLens 1Må’Œäºšé©¬é€ŠCDåŸºå‡†æµ‹è¯•ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒSTARecä¸æœ€æ–°åŸºå‡†ç›¸æ¯”å®ç°äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ï¼Œå°½ç®¡åªä½¿ç”¨äº†å…¨éƒ¨è®­ç»ƒæ•°æ®çš„0.4%ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.18812v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>é¢å¯¹ä¿¡æ¯çˆ†ç‚¸çš„æ—¶ä»£ï¼Œæ¨èç³»ç»Ÿåœ¨å¸®åŠ©äººä»¬å¯¼èˆªä¿¡æ¯æ–¹é¢å‘æŒ¥äº†å…³é”®ä½œç”¨ï¼Œä½†ä»å—é™äºé™æ€ç”¨æˆ·å»ºæ¨¡å’Œååº”å¼å†³ç­–èŒƒå¼ã€‚åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹çš„æ¨èä»£ç†ä¹Ÿé¢ä¸´ç€å¯å‘å¼æ¨¡å¼åŒ¹é…çš„ç¼ºé™·ï¼Œå¯¼è‡´æ¨èç»“æœæ˜“å—è¡¨é¢ç›¸å…³æ€§åè§ã€æœ‰é™çš„å› æœæ¨æ–­å’Œç¨€ç–æ•°æ®åœºæ™¯ä¸­çš„è„†å¼±æ€§å½±å“ã€‚ä¸ºè§£å†³è¿™äº›é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†STARecæ¡†æ¶ï¼Œä¸ºæ¨èç³»ç»Ÿèµ‹äºˆè‡ªä¸»æ¨ç†èƒ½åŠ›ã€‚é€šè¿‡æ¨¡æ‹Ÿç”¨æˆ·çš„å¹¶è¡Œè®¤çŸ¥è¿‡ç¨‹ï¼ŒSTARecå®ç°äº†å¿«é€Ÿå“åº”å³æ—¶äº¤äº’å’Œæ…¢æ€è€ƒè¿›è¡Œæ¨ç†çš„èƒ½åŠ›ã€‚é€šè¿‡é”šå®šå¼ºåŒ–è®­ç»ƒå’Œæ¨¡æ‹Ÿåé¦ˆå¾ªç¯ï¼ŒSTARecåœ¨è·å–åŸºç¡€èƒ½åŠ›çš„åŒæ—¶ï¼Œå®ç°äº†åŠ¨æ€ç­–ç•¥è°ƒæ•´ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œå³ä½¿åœ¨è®­ç»ƒæ•°æ®é‡ä»…ä¸ºå…¨é‡çš„0.4%çš„æƒ…å†µä¸‹ï¼ŒSTARecç›¸è¾ƒäºç°æœ‰å…ˆè¿›æŠ€æœ¯ä»å–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æ¨èç³»ç»Ÿåœ¨ç°ä»£ä¿¡æ¯å¯¼èˆªä¸­è‡³å…³é‡è¦ï¼Œä½†ä»å—é™æ€ç”¨æˆ·å»ºæ¨¡å’Œååº”å¼å†³ç­–çš„é™åˆ¶ã€‚</li>
<li>åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹çš„æ¨èä»£ç†å­˜åœ¨å¯å‘å¼æ¨¡å¼åŒ¹é…çš„ç¼ºé™·ï¼Œå¯¼è‡´æ¨èæ˜“å—è¡¨é¢ç›¸å…³æ€§åè§å½±å“ã€‚</li>
<li>STARecæ¡†æ¶é€šè¿‡æ¨¡æ‹Ÿç”¨æˆ·å¹¶è¡Œè®¤çŸ¥è¿‡ç¨‹ï¼Œèåˆäº†å¿«é€Ÿå“åº”å’Œæ…¢æ€è€ƒæ¨ç†èƒ½åŠ›ã€‚</li>
<li>é”šå®šå¼ºåŒ–è®­ç»ƒç»“åˆç»“æ„åŒ–çŸ¥è¯†è’¸é¦å’Œåå¥½å¯¹é½å¥–åŠ±å¡‘å½¢ï¼ŒåŸ¹å…»ä»£ç†çš„å†…åœ¨æ…¢æ€è€ƒèƒ½åŠ›ã€‚</li>
<li>STARecé€šè¿‡æ¨¡æ‹Ÿåé¦ˆå¾ªç¯å®ç°äº†åŠ¨æ€ç­–ç•¥è°ƒæ•´ã€‚</li>
<li>å®éªŒç»“æœè¡¨æ˜ï¼ŒSTARecåœ¨èµ„æºæœ‰é™çš„æƒ…å†µä¸‹ä»æ˜¾è‘—ä¼˜äºç°æœ‰æŠ€æœ¯ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.18812">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-09\./crop_R1_Reasoning/2508.18812v1/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-09\./crop_R1_Reasoning/2508.18812v1/page_3_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-09\./crop_R1_Reasoning/2508.18812v1/page_3_1.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-09\./crop_R1_Reasoning/2508.18812v1/page_4_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-09\./crop_R1_Reasoning/2508.18812v1/page_5_0.jpg" align="middle">
</details>


<h1 id="-17"><a href="#-17" class="headerlink" title=""></a></h1><h2 id="ThinkDial-An-Open-Recipe-for-Controlling-Reasoning-Effort-in-Large-Language-Models"><a href="#ThinkDial-An-Open-Recipe-for-Controlling-Reasoning-Effort-in-Large-Language-Models" class="headerlink" title="ThinkDial: An Open Recipe for Controlling Reasoning Effort in Large   Language Models"></a>ThinkDial: An Open Recipe for Controlling Reasoning Effort in Large   Language Models</h2><p><strong>Authors:Qianyu He, Siyu Yuan, Xuefeng Li, Mingxuan Wang, Jiangjie Chen</strong></p>
<p>Large language models (LLMs) with chain-of-thought reasoning have demonstrated remarkable problem-solving capabilities, but controlling their computational effort remains a significant challenge for practical deployment. Recent proprietary systems like OpenAIâ€™s gpt-oss series have introduced discrete operational modes for intuitive reasoning control, but the open-source community has largely failed to achieve such capabilities. In this paper, we introduce ThinkDial, the first open-recipe end-to-end framework that successfully implements gpt-oss-style controllable reasoning through discrete operational modes. Our system enables seamless switching between three distinct reasoning regimes: High mode (full reasoning capability), Medium mode (50 percent token reduction with &lt;10 percent performance degradation), and Low mode (75 percent token reduction with &lt;15 percent performance degradation). We achieve this through an end-to-end training paradigm that integrates budget-mode control throughout the entire pipeline: budget-mode supervised fine-tuning that embeds controllable reasoning capabilities directly into the learning process, and two-phase budget-aware reinforcement learning with adaptive reward shaping. Extensive experiments demonstrate that ThinkDial achieves target compression-performance trade-offs with clear response length reductions while maintaining performance thresholds. The framework also exhibits strong generalization capabilities on out-of-distribution tasks. </p>
<blockquote>
<p>å¸¦æœ‰æ€ç»´é“¾æ¨ç†çš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å·²ç»å±•ç°å‡ºå“è¶Šçš„è§£å†³é—®é¢˜èƒ½åŠ›ï¼Œä½†åœ¨å®é™…æ§åˆ¶å…¶è®¡ç®—å·¥ä½œé‡æ–¹é¢ä»å­˜åœ¨é‡å¤§æŒ‘æˆ˜ï¼Œè¿™å¯¹äºå®é™…éƒ¨ç½²å…·æœ‰é‡è¦æ„ä¹‰ã€‚åƒOpenAIçš„GPT-OSSç³»åˆ—ç­‰æœ€è¿‘çš„ä¸“æœ‰ç³»ç»Ÿå·²ç»å¼•å…¥äº†ç”¨äºç›´è§‚æ¨ç†æ§åˆ¶çš„ç¦»æ•£æ“ä½œæ¨¡å¼ï¼Œä½†å¼€æºç¤¾åŒºåœ¨å¾ˆå¤§ç¨‹åº¦ä¸Šæœªèƒ½å®ç°æ­¤ç±»åŠŸèƒ½ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬ä»‹ç»äº†ThinkDialï¼Œå®ƒæ˜¯ç¬¬ä¸€ä¸ªæˆåŠŸå®ç°é€šè¿‡ç¦»æ•£æ“ä½œæ¨¡å¼è¿›è¡ŒGPT-OSSé£æ ¼å¯æ§æ¨ç†çš„å¼€æºç«¯åˆ°ç«¯æ¡†æ¶ã€‚æˆ‘ä»¬çš„ç³»ç»Ÿèƒ½å¤Ÿåœ¨ä¸‰ç§ä¸åŒçš„æ¨ç†æ¨¡å¼ä¹‹é—´è¿›è¡Œæ— ç¼åˆ‡æ¢ï¼šé«˜çº§æ¨¡å¼ï¼ˆå…·å¤‡å®Œå…¨æ¨ç†èƒ½åŠ›ï¼‰ã€ä¸­çº§æ¨¡å¼ï¼ˆä»¤ç‰Œå‡å°‘50%ï¼Œæ€§èƒ½é™ä½ä¸åˆ°10%ï¼‰å’Œä½çº§æ¨¡å¼ï¼ˆä»¤ç‰Œå‡å°‘7 ç»“ï¼Œæ€§èƒ½é™ä½ä¸åˆ°15%ï¼‰ã€‚æˆ‘ä»¬é€šè¿‡ä¸€ç§ç«¯åˆ°ç«¯çš„è®­ç»ƒèŒƒå¼å®ç°äº†è¿™ä¸€ç‚¹ï¼Œè¯¥èŒƒå¼åœ¨æ•´ä¸ªç®¡é“ä¸­é›†æˆäº†é¢„ç®—æ¨¡å¼æ§åˆ¶ï¼šé¢„ç®—æ¨¡å¼ç›‘ç£å¾®è°ƒå°†å¯æ§æ¨ç†èƒ½åŠ›ç›´æ¥åµŒå…¥å­¦ä¹ è¿‡ç¨‹ï¼Œä»¥åŠå…·æœ‰è‡ªé€‚åº”å¥–åŠ±å¡‘é€ çš„ä¸¤é˜¶æ®µé¢„ç®—æ„ŸçŸ¥å¼ºåŒ–å­¦ä¹ ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼ŒThinkDialå®ç°äº†ç›®æ ‡å‹ç¼©ä¸æ€§èƒ½çš„æƒè¡¡ï¼Œåœ¨å‡å°‘å“åº”é•¿åº¦çš„åŒæ—¶ä¿æŒæ€§èƒ½é˜ˆå€¼ã€‚è¯¥æ¡†æ¶åœ¨è¶…å‡ºåˆ†å¸ƒçš„ä»»åŠ¡ä¸­ä¹Ÿè¡¨ç°å‡ºå¼ºå¤§çš„æ³›åŒ–èƒ½åŠ›ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.18773v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å…·å¤‡å‡ºè‰²çš„è§£å†³é—®é¢˜çš„èƒ½åŠ›ï¼Œä½†æ§åˆ¶å…¶è®¡ç®—å·¥ä½œé‡ä»æ˜¯å®é™…åº”ç”¨ä¸­çš„ä¸€å¤§æŒ‘æˆ˜ã€‚æœ¬æ–‡ä»‹ç»äº†ThinkDialï¼Œé¦–ä¸ªæˆåŠŸå®ç°ç±»ä¼¼OpenAI gpt-ossç³»åˆ—çš„å¯æ§æ¨ç†çš„å¼€æºç«¯åˆ°ç«¯æ¡†æ¶ã€‚è¯¥æ¡†æ¶é€šè¿‡ç¦»æ•£æ“ä½œæ¨¡å¼ï¼Œèƒ½å¤Ÿåœ¨ä¸‰ç§ä¸åŒçš„æ¨ç†æ¨¡å¼ä¹‹é—´è¿›è¡Œæ— ç¼åˆ‡æ¢ï¼šé«˜æ€§èƒ½æ¨¡å¼ã€ä¸­ç­‰æ€§èƒ½æ¨¡å¼å’Œä½æ€§èƒ½æ¨¡å¼ã€‚è¿™é€šè¿‡ä¸€ç§ç«¯åˆ°ç«¯çš„è®­ç»ƒèŒƒå¼å®ç°ï¼Œè¯¥èŒƒå¼åœ¨æ•´ä¸ªç®¡é“ä¸­èå…¥é¢„ç®—æ¨¡å¼æ§åˆ¶ï¼ŒåŒ…æ‹¬é¢„ç®—æ¨¡å¼ç›‘ç£å¾®è°ƒï¼Œå°†å¯æ§æ¨ç†èƒ½åŠ›ç›´æ¥åµŒå…¥å­¦ä¹ è¿‡ç¨‹ï¼Œä»¥åŠå¸¦æœ‰è‡ªé€‚åº”å¥–åŠ±å¡‘é€ çš„ä¸¤é˜¶æ®µé¢„ç®—æ„ŸçŸ¥å¼ºåŒ–å­¦ä¹ ã€‚å®éªŒè¡¨æ˜ï¼ŒThinkDialèƒ½å¤Ÿåœ¨å‡å°‘å“åº”é•¿åº¦çš„åŒæ—¶å®ç°ç›®æ ‡å‹ç¼©æ€§èƒ½æŠ˜è¡·ï¼Œå¹¶åœ¨è·¨åˆ†å¸ƒä»»åŠ¡ä¸Šå±•ç°å‡ºå¼ºå¤§çš„æ³›åŒ–èƒ½åŠ›ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨è§£å†³é—®é¢˜æ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œä½†è®¡ç®—å·¥ä½œé‡çš„æ§åˆ¶ä»æ˜¯å®é™…åº”ç”¨ä¸­çš„éš¾é¢˜ã€‚</li>
<li>ThinkDialæ˜¯é¦–ä¸ªæˆåŠŸå®ç°ç±»ä¼¼OpenAI gpt-ossç³»åˆ—çš„å¯æ§æ¨ç†çš„å¼€æºç«¯åˆ°ç«¯æ¡†æ¶ã€‚</li>
<li>ThinkDialæ”¯æŒä¸‰ç§ä¸åŒçš„æ¨ç†æ¨¡å¼ï¼šé«˜æ€§èƒ½æ¨¡å¼ã€ä¸­ç­‰æ€§èƒ½æ¨¡å¼å’Œä½æ€§èƒ½æ¨¡å¼ã€‚</li>
<li>ThinkDialé€šè¿‡é¢„ç®—æ¨¡å¼æ§åˆ¶å’Œç«¯åˆ°ç«¯çš„è®­ç»ƒèŒƒå¼å®ç°æ€§èƒ½ä¼˜åŒ–ã€‚</li>
<li>è¯¥æ¡†æ¶å®ç°äº†é¢„ç®—æ¨¡å¼ç›‘ç£å¾®è°ƒå’Œä¸¤é˜¶æ®µé¢„ç®—æ„ŸçŸ¥å¼ºåŒ–å­¦ä¹ ï¼Œä»¥èå…¥é¢„ç®—æ¨¡å¼æ§åˆ¶ã€‚</li>
<li>å®éªŒè¡¨æ˜ThinkDialèƒ½å¤Ÿåœ¨å‡å°‘å“åº”é•¿åº¦çš„åŒæ—¶å®ç°ç›®æ ‡å‹ç¼©æ€§èƒ½æŠ˜è¡·ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.18773">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-09\./crop_R1_Reasoning/2508.18773v1/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-09\./crop_R1_Reasoning/2508.18773v1/page_1_0.jpg" align="middle">
</details>


<h1 id="-18"><a href="#-18" class="headerlink" title=""></a></h1><h2 id="OwlCap-Harmonizing-Motion-Detail-for-Video-Captioning-via-HMD-270K-and-Caption-Set-Equivalence-Reward"><a href="#OwlCap-Harmonizing-Motion-Detail-for-Video-Captioning-via-HMD-270K-and-Caption-Set-Equivalence-Reward" class="headerlink" title="OwlCap: Harmonizing Motion-Detail for Video Captioning via HMD-270K and   Caption Set Equivalence Reward"></a>OwlCap: Harmonizing Motion-Detail for Video Captioning via HMD-270K and   Caption Set Equivalence Reward</h2><p><strong>Authors:Chunlin Zhong, Qiuxia Hou, Zhangjun Zhou, Shuang Hao, Haonan Lu, Yanhao Zhang, He Tang, Xiang Bai</strong></p>
<p>Video captioning aims to generate comprehensive and coherent descriptions of the video content, contributing to the advancement of both video understanding and generation. However, existing methods often suffer from motion-detail imbalance, as models tend to overemphasize one aspect while neglecting the other. This imbalance results in incomplete captions, which in turn leads to a lack of consistency in video understanding and generation. To address this issue, we propose solutions from two aspects: 1) Data aspect: We constructed the Harmonizing Motion-Detail 270K (HMD-270K) dataset through a two-stage pipeline: Motion-Detail Fusion (MDF) and Fine-Grained Examination (FGE). 2) Optimization aspect: We introduce the Caption Set Equivalence Reward (CSER) based on Group Relative Policy Optimization (GRPO). CSER enhances completeness and accuracy in capturing both motion and details through unit-to-set matching and bidirectional validation. Based on the HMD-270K supervised fine-tuning and GRPO post-training with CSER, we developed OwlCap, a powerful video captioning multi-modal large language model (MLLM) with motion-detail balance. Experimental results demonstrate that OwlCap achieves significant improvements compared to baseline models on two benchmarks: the detail-focused VDC (+4.2 Acc) and the motion-focused DREAM-1K (+4.6 F1). The HMD-270K dataset and OwlCap model will be publicly released to facilitate video captioning research community advancements. </p>
<blockquote>
<p>è§†é¢‘å­—å¹•ç”Ÿæˆæ—¨åœ¨ç”Ÿæˆå¯¹è§†é¢‘å†…å®¹çš„å…¨é¢å’Œè¿è´¯çš„æè¿°ï¼Œä¿ƒè¿›è§†é¢‘ç†è§£å’Œç”Ÿæˆçš„å‘å±•ã€‚ç„¶è€Œï¼Œç°æœ‰æ–¹æ³•å¸¸å¸¸å­˜åœ¨è¿åŠ¨ç»†èŠ‚å¤±è¡¡çš„é—®é¢˜ï¼Œæ¨¡å‹å¾€å¾€è¿‡åˆ†å¼ºè°ƒä¸€æ–¹é¢è€Œå¿½è§†å¦ä¸€æ–¹é¢ã€‚è¿™ç§ä¸å¹³è¡¡å¯¼è‡´å­—å¹•ä¸å®Œæ•´ï¼Œè¿›è€Œé€ æˆè§†é¢‘ç†è§£å’Œç”Ÿæˆçš„ä¸ä¸€è‡´æ€§ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬ä»ä¸¤ä¸ªæ–¹é¢æå‡ºäº†è§£å†³æ–¹æ¡ˆï¼š1ï¼‰æ•°æ®æ–¹é¢ï¼šæˆ‘ä»¬é€šè¿‡ä¸¤é˜¶æ®µç®¡é“â€”â€”è¿åŠ¨ç»†èŠ‚èåˆï¼ˆMDFï¼‰å’Œç²¾ç»†é¢—ç²’åº¦æ£€æŸ¥ï¼ˆFGEï¼‰â€”â€”æ„å»ºäº†å’Œè°è¿åŠ¨ç»†èŠ‚27ä¸‡ï¼ˆHMD-270Kï¼‰æ•°æ®é›†ã€‚2ï¼‰ä¼˜åŒ–æ–¹é¢ï¼šæˆ‘ä»¬å¼•å…¥äº†åŸºäºç¾¤ä½“ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–ï¼ˆGRPOï¼‰çš„å­—å¹•é›†ç­‰ä»·å¥–åŠ±ï¼ˆCSERï¼‰ã€‚CSERé€šè¿‡å•å…ƒåˆ°é›†åˆçš„åŒ¹é…å’ŒåŒå‘éªŒè¯ï¼Œæé«˜äº†æ•æ‰è¿åŠ¨å’Œç»†èŠ‚çš„å®Œæ•´æ€§å’Œå‡†ç¡®æ€§ã€‚åŸºäºHMD-270Kçš„ç›‘ç£å¾®è°ƒä»¥åŠGRPOçš„åç»­è®­ç»ƒå’ŒCSERï¼Œæˆ‘ä»¬å¼€å‘äº†ä¸€æ¬¾å¼ºå¤§çš„è§†é¢‘å­—å¹•å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹OwlCapï¼Œå®ç°äº†è¿åŠ¨ç»†èŠ‚çš„å‡è¡¡ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒOwlCapåœ¨ä¸¤ä¸ªåŸºå‡†æµ‹è¯•ä¸Šè¾ƒåŸºçº¿æ¨¡å‹å–å¾—äº†æ˜¾è‘—æ”¹è¿›ï¼šæ³¨é‡ç»†èŠ‚çš„VDCï¼ˆ+4.2å‡†ç¡®ç‡ï¼‰å’Œæ³¨é‡è¿åŠ¨çš„DREAM-1Kï¼ˆ+4.6 F1ï¼‰ã€‚HMD-27ä¸‡æ•°æ®é›†å’ŒOwlCapæ¨¡å‹å°†å…¬å¼€å‘å¸ƒï¼Œä»¥ä¿ƒè¿›è§†é¢‘å­—å¹•ç ”ç©¶é¢†åŸŸçš„è¿›æ­¥ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.18634v2">PDF</a> 9 pages, 6figures</p>
<p><strong>æ‘˜è¦</strong><br>è¯¥æ–‡æœ¬ä»‹ç»äº†è§†é¢‘æè¿°ç”Ÿæˆçš„ç ”ç©¶ç°çŠ¶ä»¥åŠå­˜åœ¨çš„æŒ‘æˆ˜ã€‚ä¸ºäº†è§£å†³ç°æœ‰æ–¹æ³•ä¸­è¿åŠ¨ç»†èŠ‚å¤±è¡¡çš„é—®é¢˜ï¼Œè¯¥ç ”ç©¶ä»æ•°æ®æ–¹é¢å’Œä¼˜åŒ–æ–¹é¢æå‡ºäº†è§£å†³æ–¹æ¡ˆï¼Œæ„å»ºäº†HMD-270Kæ•°æ®é›†ï¼Œå¹¶å¼€å‘äº†åŸºäºè¯¥æ•°æ®é›†çš„OwlCapæ¨¡å‹ï¼Œé€šè¿‡è§†é¢‘å†…å®¹æ•è·å®Œæ•´ä¸”è¿è´¯çš„æè¿°ã€‚è¯¥æ¨¡å‹åœ¨VDCå’ŒDREAM-1Kä¸¤ä¸ªåŸºå‡†æµ‹è¯•é›†ä¸Šå–å¾—äº†æ˜¾è‘—çš„æ”¹è¿›ã€‚æ•°æ®é›†å’Œæ¨¡å‹å°†å…¬å¼€å‘å¸ƒä»¥ä¿ƒè¿›è§†é¢‘æè¿°ç”Ÿæˆç ”ç©¶çš„å‘å±•ã€‚æ•´ä½“å·¥ä½œç€é‡äºæå‡è§†é¢‘å†…å®¹çš„ç†è§£ä»¥åŠè§†é¢‘æè¿°çš„å®Œæ•´æ€§åŠè¿è´¯æ€§ã€‚ç®€è¦æ¦‚æ‹¬ä¸ºï¼šâ€œè§£å†³è§†é¢‘æè¿°ç”Ÿæˆä¸­çš„è¿åŠ¨ç»†èŠ‚å¤±è¡¡é—®é¢˜ï¼Œæ¨å‡ºæ–°æ•°æ®é›†åŠæ¨¡å‹ä»¥æ”¹è¿›è§†é¢‘å†…å®¹ç†è§£å’Œæè¿°è¿è´¯æ€§ã€‚â€ </p>
<p><strong>å…³é”®è§è§£</strong></p>
<ul>
<li>è§†é¢‘æè¿°ç”Ÿæˆæ—¨åœ¨å…¨é¢è¿è´¯åœ°æè¿°è§†é¢‘å†…å®¹ï¼Œä¿ƒè¿›è§†é¢‘ç†è§£å’Œç”Ÿæˆçš„å‘å±•ã€‚</li>
<li>å½“å‰æ–¹æ³•å­˜åœ¨è¿åŠ¨ç»†èŠ‚å¤±è¡¡çš„é—®é¢˜ï¼Œå¯¼è‡´æè¿°ä¸å®Œæ•´å’Œç¼ºä¹ä¸€è‡´æ€§ã€‚</li>
<li>ä»æ•°æ®æ–¹é¢ï¼Œæ„å»ºäº†HMD-270Kæ•°æ®é›†ï¼Œé€šè¿‡è¿åŠ¨ç»†èŠ‚èåˆå’Œç²¾ç»†ç²’åº¦æ£€æŸ¥ä¸¤ä¸ªé˜¶æ®µè¿›è¡Œã€‚</li>
<li>ä»ä¼˜åŒ–æ–¹é¢ï¼Œå¼•å…¥äº†åŸºäºç»„ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–çš„å­—å¹•é›†ç­‰ä»·å¥–åŠ±ï¼ˆCSERï¼‰ï¼Œæé«˜æ•æ‰è¿åŠ¨å’Œç»†èŠ‚çš„å®Œæ•´æ€§å’Œå‡†ç¡®æ€§ã€‚</li>
<li>ä½¿ç”¨HMD-270Kæ•°æ®é›†è¿›è¡Œç²¾ç»†è°ƒæ•´ï¼Œç»“åˆCSERçš„GRPOåè®­ç»ƒï¼Œå¼€å‘äº†å¹³è¡¡è¿åŠ¨ç»†èŠ‚çš„OwlCapè§†é¢‘æè¿°å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆMLLMï¼‰ã€‚</li>
<li>å®éªŒç»“æœè¡¨æ˜ï¼ŒOwlCapåœ¨VDCå’ŒDREAM-1Kä¸¤ä¸ªåŸºå‡†æµ‹è¯•é›†ä¸Šè¾ƒåŸºçº¿æ¨¡å‹æœ‰æ˜¾è‘—æ”¹å–„ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.18634">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-09\./crop_R1_Reasoning/2508.18634v2/page_0_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-09\./crop_R1_Reasoning/2508.18634v2/page_1_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-09\./crop_R1_Reasoning/2508.18634v2/page_2_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-09\./crop_R1_Reasoning/2508.18634v2/page_3_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-09\./crop_R1_Reasoning/2508.18634v2/page_4_0.jpg" align="middle">
<img src="D:\MyBlog\AutoFX\arxiv\2025-09-09\./crop_R1_Reasoning/2508.18634v2/page_5_0.jpg" align="middle">
</details>


<h1 id="-19"><a href="#-19" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-09-09/R1_Reasoning/">https://kedreamix.github.io/Talk2Paper/Paper/2025-09-09/R1_Reasoning/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/R1-Reasoning/">
                                    <span class="chip bg-color">R1_Reasoning</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-09-09/LLM/">
                    <div class="card-image">
                        
                        <img src="D:\MyBlog\AutoFX\arxiv\2025-09-09\./crop_LLM/2509.04650v1/page_0_0.jpg" class="responsive-img" alt="LLM">
                        
                        <span class="card-title">LLM</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            LLM æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-09-09  Scaling Performance of Large Language Model Pretraining
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-09-09
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/LLM/" class="post-category">
                                    LLM
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/LLM/">
                        <span class="chip bg-color">LLM</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-09-08/TTS/">
                    <div class="card-image">
                        
                        <img src="D:\MyBlog\AutoFX\arxiv\2025-09-08\./crop_TTS/2409.10969v2/page_5_2.jpg" class="responsive-img" alt="TTS">
                        
                        <span class="card-title">TTS</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            TTS æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-09-08  Enhancing Code-switched Text-to-Speech Synthesis Capability in Large   Language Models with only Monolingual Corpora
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-09-08
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/TTS/" class="post-category">
                                    TTS
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/TTS/">
                        <span class="chip bg-color">TTS</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">32298.5k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
