<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="åŒ»å­¦å›¾åƒ">
    <meta name="description" content="åŒ»å­¦å›¾åƒ æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-02-17  Utilizing 3D Fast Spin Echo Anatomical Imaging to Reduce the Number of   Contrast Preparations in $T_{1Ï}$ Quantification of Knee Cartilage Using   Learning-Based Methods">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>åŒ»å­¦å›¾åƒ | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://pica.zhimg.com/v2-4ccec59a98e20bb864e5b8a69ef88467.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">åŒ»å­¦å›¾åƒ</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/">
                                <span class="chip bg-color">åŒ»å­¦å›¾åƒ</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/" class="post-category">
                                åŒ»å­¦å›¾åƒ
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-02-17
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-05-14
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    8.9k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    36 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-02-17-æ›´æ–°"><a href="#2025-02-17-æ›´æ–°" class="headerlink" title="2025-02-17 æ›´æ–°"></a>2025-02-17 æ›´æ–°</h1><h2 id="Utilizing-3D-Fast-Spin-Echo-Anatomical-Imaging-to-Reduce-the-Number-of-Contrast-Preparations-in-T-1Ï-Quantification-of-Knee-Cartilage-Using-Learning-Based-Methods"><a href="#Utilizing-3D-Fast-Spin-Echo-Anatomical-Imaging-to-Reduce-the-Number-of-Contrast-Preparations-in-T-1Ï-Quantification-of-Knee-Cartilage-Using-Learning-Based-Methods" class="headerlink" title="Utilizing 3D Fast Spin Echo Anatomical Imaging to Reduce the Number of   Contrast Preparations in $T_{1Ï}$ Quantification of Knee Cartilage Using   Learning-Based Methods"></a>Utilizing 3D Fast Spin Echo Anatomical Imaging to Reduce the Number of   Contrast Preparations in $T_{1Ï}$ Quantification of Knee Cartilage Using   Learning-Based Methods</h2><p><strong>Authors:Junru Zhong, Chaoxing Huang, Ziqiang Yu, Fan Xiao, Siyue Li, Tim-Yun Michael Ong, Ki-Wai Kevin Ho, Queenie Chan, James F. Griffith, Weitian Chen</strong></p>
<p>Purpose: To propose and evaluate an accelerated $T_{1\rho}$ quantification method that combines $T_{1\rho}$-weighted fast spin echo (FSE) images and proton density (PD)-weighted anatomical FSE images, leveraging deep learning models for $T_{1\rho}$ mapping. The goal is to reduce scan time and facilitate integration into routine clinical workflows for osteoarthritis (OA) assessment. Methods: This retrospective study utilized MRI data from 40 participants (30 OA patients and 10 healthy volunteers). A volume of PD-weighted anatomical FSE images and a volume of $T_{1\rho}$-weighted images acquired at a non-zero spin-lock time were used as input to train deep learning models, including a 2D U-Net and a multi-layer perceptron (MLP). $T_{1\rho}$ maps generated by these models were compared with ground truth maps derived from a traditional non-linear least squares (NLLS) fitting method using four $T_{1\rho}$-weighted images. Evaluation metrics included mean absolute error (MAE), mean absolute percentage error (MAPE), regional error (RE), and regional percentage error (RPE). Results: Deep learning models achieved RPEs below 5% across all evaluated scenarios, outperforming NLLS methods, especially in low signal-to-noise conditions. The best results were obtained using the 2D U-Net, which effectively leveraged spatial information for accurate $T_{1\rho}$ fitting. The proposed method demonstrated compatibility with shorter TSLs, alleviating RF hardware and specific absorption rate (SAR) limitations. Conclusion: The proposed approach enables efficient $T_{1\rho}$ mapping using PD-weighted anatomical images, reducing scan time while maintaining clinical standards. This method has the potential to facilitate the integration of quantitative MRI techniques into routine clinical practice, benefiting OA diagnosis and monitoring. </p>
<blockquote>
<p>ç›®çš„ï¼šæå‡ºå¹¶è¯„ä¼°ä¸€ç§åŠ é€Ÿçš„$T_{1\rho}$å®šé‡æ–¹æ³•ï¼Œè¯¥æ–¹æ³•ç»“åˆäº†$T_{1\rho}$åŠ æƒå¿«é€Ÿè‡ªæ—‹å›æ³¢ï¼ˆFSEï¼‰å›¾åƒå’Œè´¨å­å¯†åº¦ï¼ˆPDï¼‰åŠ æƒè§£å‰–FSEå›¾åƒï¼Œåˆ©ç”¨æ·±åº¦å­¦ä¹ æ¨¡å‹è¿›è¡Œ$T_{1\rho}$æ˜ å°„ã€‚æ—¨åœ¨ç¼©çŸ­æ‰«ææ—¶é—´ï¼Œä¿ƒè¿›å®šé‡ç£å…±æŒ¯æˆåƒæŠ€æœ¯èå…¥ä¸´åºŠæ—¥å¸¸å·¥ä½œä¸­ï¼Œç”¨äºéª¨å…³èŠ‚ç‚ï¼ˆOAï¼‰çš„è¯„ä¼°ã€‚</p>
</blockquote>
<p>æ–¹æ³•ï¼šè¿™é¡¹å›é¡¾æ€§ç ”ç©¶ä½¿ç”¨äº†40åå‚ä¸è€…ï¼ˆ30åOAæ‚£è€…å’Œ10åå¥åº·å¿—æ„¿è€…ï¼‰çš„MRIæ•°æ®ã€‚ä½¿ç”¨ä½“ç§¯PDåŠ æƒè§£å‰–FSEå›¾åƒå’Œä½“ç§¯$T_{1\rho}$åŠ æƒå›¾åƒï¼ˆåœ¨éé›¶è‡ªæ—‹é”å®šæ—¶é—´è·å–ï¼‰æ¥è®­ç»ƒæ·±åº¦å­¦ä¹ æ¨¡å‹ï¼ŒåŒ…æ‹¬äºŒç»´U-Netå’Œå¤šå±‚æ„ŸçŸ¥å™¨ï¼ˆMLPï¼‰ã€‚å°†è¿™äº›æ¨¡å‹ç”Ÿæˆçš„$T_{1\rho$åœ°å›¾ä¸åŸºäºå››å¹…$T_{1\rho}$åŠ æƒå›¾åƒçš„ä¼ ç»Ÿéçº¿æ€§æœ€å°äºŒä¹˜ï¼ˆNLLSï¼‰æ‹Ÿåˆæ–¹æ³•å¾—å‡ºçš„çœŸå®åœ°å›¾è¿›è¡Œæ¯”è¾ƒã€‚è¯„ä¼°æŒ‡æ ‡åŒ…æ‹¬å¹³å‡ç»å¯¹è¯¯å·®ï¼ˆMAEï¼‰ã€å¹³å‡ç»å¯¹ç™¾åˆ†æ¯”è¯¯å·®ï¼ˆMAPEï¼‰ã€åŒºåŸŸè¯¯å·®ï¼ˆREï¼‰å’ŒåŒºåŸŸç™¾åˆ†æ¯”è¯¯å·®ï¼ˆRPEï¼‰ã€‚</p>
<p>ç»“æœï¼šæ·±åº¦å­¦ä¹ æ¨¡å‹çš„RPEåœ¨æ‰€æœ‰è¯„ä¼°åœºæ™¯ä¸­å‡ä½äº5%ï¼Œä¼˜äºNLLSæ–¹æ³•ï¼Œç‰¹åˆ«æ˜¯åœ¨ä½ä¿¡å™ªæ¯”æ¡ä»¶ä¸‹ã€‚ä½¿ç”¨äºŒç»´U-Netè·å¾—æœ€ä½³ç»“æœï¼Œè¯¥ç½‘ç»œæœ‰æ•ˆåˆ©ç”¨ç©ºé—´ä¿¡æ¯ï¼Œå®ç°å‡†ç¡®çš„$T_{1\rho}$æ‹Ÿåˆã€‚æ‰€æå‡ºçš„æ–¹æ³•è¯æ˜ä¸è¾ƒçŸ­çš„TSLå…¼å®¹ï¼Œå‡è½»äº†å°„é¢‘ç¡¬ä»¶å’Œç‰¹å®šå¸æ”¶ç‡ï¼ˆSARï¼‰çš„é™åˆ¶ã€‚</p>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.08973v1">PDF</a> Submitted to Magnetic Resonance in Medicine</p>
<p><strong>æ‘˜è¦</strong><br>    æ·±åº¦å­¦ä¹ æ¨¡å‹ç»“åˆ$T_{1\rho}$åŠ æƒå¿«é€Ÿè‡ªæ—‹å›æ³¢ï¼ˆFSEï¼‰å›¾åƒå’Œè´¨å­å¯†åº¦ï¼ˆPDï¼‰åŠ æƒè§£å‰–FSEå›¾åƒï¼Œå®ç°$T_{1\rho}$é‡åŒ–æ–¹æ³•çš„åŠ é€Ÿï¼Œç”¨äºéª¨å…³èŠ‚ç‚ï¼ˆOAï¼‰è¯„ä¼°ã€‚é€šè¿‡å›é¡¾æ€§ç ”ç©¶åˆ©ç”¨MRIæ•°æ®è®­ç»ƒå’Œè¯„ä¼°æ¨¡å‹ï¼Œç»“æœæ˜¾ç¤ºæ·±åº¦å­¦ä¹ æ¨¡å‹ï¼Œç‰¹åˆ«æ˜¯2D U-Netï¼Œåœ¨$T_{1\rho}$æ˜ å°„ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œå…·æœ‰ç¼©çŸ­æ‰«ææ—¶é—´å¹¶ç»´æŒä¸´åºŠæ ‡å‡†çš„æ½œåŠ›ã€‚</p>
<p><strong>å…³é”®è§è§£</strong></p>
<ol>
<li>ç ”ç©¶æ—¨åœ¨æå‡ºå¹¶è¯„ä¼°ä¸€ç§ç»“åˆ$T_{1\rho}$åŠ æƒå¿«é€Ÿè‡ªæ—‹å›æ³¢ï¼ˆFSEï¼‰å›¾åƒå’Œè´¨å­å¯†åº¦ï¼ˆPDï¼‰åŠ æƒè§£å‰–FSEå›¾åƒçš„åŠ é€Ÿ$T_{1\rho}$é‡åŒ–æ–¹æ³•ã€‚</li>
<li>åˆ©ç”¨æ·±åº¦å­¦ä¹ æ¨¡å‹ï¼ŒåŒ…æ‹¬2D U-Netå’Œå¤šå±‚æ„ŸçŸ¥å™¨ï¼ˆMLPï¼‰ï¼Œè¿›è¡Œ$T_{1\rho}$æ˜ å°„ï¼Œä»¥ç¼©çŸ­æ‰«ææ—¶é—´å¹¶ä¿ƒè¿›åœ¨æ—¥å¸¸ä¸´åºŠå·¥ä½œä¸­çš„é›†æˆã€‚</li>
<li>å›é¡¾æ€§ç ”ç©¶ä½¿ç”¨æ¥è‡ª40åå‚ä¸è€…ï¼ˆ30åOAæ‚£è€…å’Œ10åå¥åº·å¿—æ„¿è€…ï¼‰çš„MRIæ•°æ®è®­ç»ƒå’Œè¯„ä¼°æ¨¡å‹ã€‚</li>
<li>æ·±åº¦å­¦ä¹ æ¨¡å‹åœ¨$T_{1\rho}$æ˜ å°„æ–¹é¢è¡¨ç°å‡ºä¼˜å¼‚çš„æ€§èƒ½ï¼Œä¸åŸºäºä¼ ç»Ÿéçº¿æ€§æœ€å°äºŒä¹˜ï¼ˆNLLSï¼‰æ‹Ÿåˆæ–¹æ³•ç”Ÿæˆçš„åœ°é¢çœŸå®åœ°å›¾ç›¸æ¯”ï¼Œè¯„ä»·æŒ‡æ ‡åŒ…æ‹¬å¹³å‡ç»å¯¹è¯¯å·®ï¼ˆMAEï¼‰ã€å¹³å‡ç»å¯¹ç™¾åˆ†æ¯”è¯¯å·®ï¼ˆMAPEï¼‰ã€åŒºåŸŸè¯¯å·®ï¼ˆREï¼‰å’ŒåŒºåŸŸç™¾åˆ†æ¯”è¯¯å·®ï¼ˆRPEï¼‰ã€‚</li>
<li>2D U-Netåœ¨æœ‰æ•ˆåˆ©ç”¨ç©ºé—´ä¿¡æ¯ä»¥è¿›è¡Œå‡†ç¡®çš„$T_{1\rho}$æ‹Ÿåˆæ–¹é¢è¡¨ç°å‡ºæœ€ä½³ç»“æœã€‚</li>
<li>æ‰€æå‡ºçš„æ–¹æ³•ä¸è¾ƒçŸ­çš„æ—¶é—´é—´éš”ï¼ˆTSLsï¼‰å…¼å®¹ï¼Œå‡è½»äº†å°„é¢‘ç¡¬ä»¶å’Œç‰¹å®šå¸æ”¶ç‡ï¼ˆSARï¼‰çš„é™åˆ¶ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.08973">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-4b1782a4384c231701c17e2ac47664a5.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-84ad763227ea6b3c5e8aee1e1d2a0fd3.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-9ae6b1501f5752e78e56731ab98cce02.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-3f3a15f50bfa67904e188a617612fc8d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-1399151777a3c97a2791e337b16b7c38.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-81d10455e474dbcf6f16bba55960c3de.jpg" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="Exploring-Test-Time-Adaptation-for-Subcortical-Segmentation-of-the-Fetal-Brain-in-3D-Ultrasound"><a href="#Exploring-Test-Time-Adaptation-for-Subcortical-Segmentation-of-the-Fetal-Brain-in-3D-Ultrasound" class="headerlink" title="Exploring Test Time Adaptation for Subcortical Segmentation of the Fetal   Brain in 3D Ultrasound"></a>Exploring Test Time Adaptation for Subcortical Segmentation of the Fetal   Brain in 3D Ultrasound</h2><p><strong>Authors:Joshua Omolegan, Pak Hei Yeung, Madeleine K. Wyburd, Linde Hesse, Monique Haak, Intergrowth-21st Consortium, Ana I. L. Namburete, Nicola K. Dinsdale</strong></p>
<p>Monitoring the growth of subcortical regions of the fetal brain in ultrasound (US) images can help identify the presence of abnormal development. Manually segmenting these regions is a challenging task, but recent work has shown that it can be automated using deep learning. However, applying pretrained models to unseen freehand US volumes often leads to a degradation of performance due to the vast differences in acquisition and alignment. In this work, we first demonstrate that test time adaptation (TTA) can be used to improve model performance in the presence of both real and simulated domain shifts. We further propose a novel TTA method by incorporating a normative atlas as a prior for anatomy. In the presence of various types of domain shifts, we benchmark the performance of different TTA methods and demonstrate the improvements brought by our proposed approach, which may further facilitate automated monitoring of fetal brain development. Our code is available at <a target="_blank" rel="noopener" href="https://github.com/joshuaomolegan/TTA-for-3D-Fetal-Subcortical-Segmentation">https://github.com/joshuaomolegan/TTA-for-3D-Fetal-Subcortical-Segmentation</a>. </p>
<blockquote>
<p>ç›‘æµ‹èƒå„¿å¤§è„‘çš®å±‚ä¸‹åŒºåŸŸåœ¨è¶…å£°ï¼ˆUSï¼‰å›¾åƒä¸­çš„ç”Ÿé•¿æƒ…å†µæœ‰åŠ©äºè¯†åˆ«å¼‚å¸¸å‘è‚²çš„å­˜åœ¨ã€‚æ‰‹åŠ¨åˆ†å‰²è¿™äº›åŒºåŸŸæ˜¯ä¸€é¡¹å…·æœ‰æŒ‘æˆ˜æ€§çš„ä»»åŠ¡ï¼Œä½†æœ€è¿‘çš„å·¥ä½œè¡¨æ˜ï¼Œå¯ä»¥ä½¿ç”¨æ·±åº¦å­¦ä¹ æ¥è‡ªåŠ¨åŒ–å®Œæˆã€‚ç„¶è€Œï¼Œå°†é¢„è®­ç»ƒæ¨¡å‹åº”ç”¨äºæœªè§è¿‡çš„è‡ªç”±æ‰‹è¶…å£°ä½“ç§¯å¸¸å¸¸ä¼šå¯¼è‡´æ€§èƒ½ä¸‹é™ï¼Œè¿™æ˜¯ç”±äºé‡‡é›†å’Œå¯¹é½æ–¹é¢çš„å·¨å¤§å·®å¼‚ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬é¦–å…ˆè¯æ˜æµ‹è¯•æ—¶é—´é€‚åº”ï¼ˆTTAï¼‰å¯ç”¨äºåœ¨å­˜åœ¨çœŸå®å’Œæ¨¡æ‹ŸåŸŸåç§»çš„æƒ…å†µä¸‹æé«˜æ¨¡å‹æ€§èƒ½ã€‚æˆ‘ä»¬è¿›ä¸€æ­¥æå‡ºäº†ä¸€ç§æ–°å‹çš„TTAæ–¹æ³•ï¼Œè¯¥æ–¹æ³•ç»“åˆè§„èŒƒæ€§å›¾è°±ä½œä¸ºè§£å‰–å­¦çš„å…ˆéªŒçŸ¥è¯†ã€‚åœ¨å„ç§ç±»å‹çš„åŸŸåç§»å­˜åœ¨çš„æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬å¯¹ä¸åŒçš„TTAæ–¹æ³•è¿›è¡Œäº†æ€§èƒ½è¯„ä¼°ï¼Œå¹¶å±•ç¤ºäº†æˆ‘ä»¬æ‰€æå‡ºæ–¹æ³•æ‰€å¸¦æ¥çš„æ”¹è¿›ï¼Œè¿™å¯èƒ½æœ‰åŠ©äºè¿›ä¸€æ­¥ä¿ƒè¿›èƒå„¿å¤§è„‘å‘è‚²çš„è‡ªåŠ¨åŒ–ç›‘æµ‹ã€‚æˆ‘ä»¬çš„ä»£ç å¯åœ¨[<a target="_blank" rel="noopener" href="https://github.com/joshuaomolegan/TTA-for-3D-Fetal-Subcortical-Segmentation%E6%89%BE%E5%88%B0%E3%80%82]">https://github.com/joshuaomolegan/TTA-for-3D-Fetal-Subcortical-Segmentationæ‰¾åˆ°ã€‚]</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.08774v1">PDF</a> 5 pages, 5 figures</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æ¢è®¨äº†åˆ©ç”¨è¶…å£°å›¾åƒç›‘æµ‹èƒå„¿å¤§è„‘äºšçš®å±‚åŒºåŸŸå‘è‚²æƒ…å†µçš„é‡è¦æ€§ï¼Œå¹¶æŒ‡å‡ºæ‰‹åŠ¨åˆ†å‰²è¿™äº›åŒºåŸŸæ˜¯ä¸€é¡¹æŒ‘æˆ˜ã€‚ç„¶è€Œï¼Œè¿‘æœŸçš„ç ”ç©¶æ˜¾ç¤ºå¯é€šè¿‡æ·±åº¦å­¦ä¹ å®ç°è‡ªåŠ¨åŒ–ã€‚ä½†å½“å°†é¢„è®­ç»ƒæ¨¡å‹åº”ç”¨äºæœªè§çš„æ‰‹ç»˜è¶…å£°ä½“ç§¯æ•°æ®æ—¶ï¼Œæ€§èƒ½å¾€å¾€ä¼šä¸‹é™ï¼Œå› ä¸ºé‡‡é›†å’Œæ ¡å‡†æ–¹é¢å­˜åœ¨å·¨å¤§å·®å¼‚ã€‚æœ¬æ–‡é¦–å…ˆéªŒè¯äº†æµ‹è¯•æ—¶é—´é€‚åº”ï¼ˆTTAï¼‰æŠ€æœ¯åœ¨çœŸå®å’Œæ¨¡æ‹ŸåŸŸåç§»æƒ…å†µä¸‹çš„æ¨¡å‹æ€§èƒ½æå‡ä½œç”¨ã€‚æ­¤å¤–ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„TTAæ–¹æ³•ï¼Œé€šè¿‡çº³å…¥è§„èŒƒå›¾è°±ä½œä¸ºè§£å‰–å­¦å…ˆéªŒã€‚åœ¨ä¸åŒç±»å‹çš„åŸŸåç§»æƒ…å†µä¸‹ï¼Œæœ¬æ–‡è¯„ä¼°äº†ä¸åŒTTAæ–¹æ³•çš„æ€§èƒ½ï¼Œå¹¶å±•ç¤ºäº†æ‰€æå‡ºçš„æ–¹æ³•åœ¨è‡ªåŠ¨åŒ–ç›‘æµ‹èƒå„¿å¤§è„‘å‘è‚²æ–¹é¢çš„æ”¹è¿›ä¼˜åŠ¿ã€‚ç›¸å…³ä»£ç å¯åœ¨â€‹â€‹<a target="_blank" rel="noopener" href="https://github.com/joshuaomolegan/TTA-for-3D-Fetal-Subcortical-Segmentation%E2%80%8B%E2%80%8B%E8%8E%B7%E5%8F%96%E3%80%82">https://github.com/joshuaomolegan/TTA-for-3D-Fetal-Subcortical-Segmentationâ€‹â€‹è·å–ã€‚</a></p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>è¶…å£°å›¾åƒç›‘æµ‹èƒå„¿å¤§è„‘äºšçš®å±‚åŒºåŸŸå‘è‚²æƒ…å†µå¯¹è¯†åˆ«å¼‚å¸¸å‘è‚²å…·æœ‰é‡è¦æ„ä¹‰ã€‚</li>
<li>æ‰‹åŠ¨åˆ†å‰²èƒå„¿å¤§è„‘çš„äºšçš®å±‚åŒºåŸŸæ˜¯ä¸€é¡¹æŒ‘æˆ˜ï¼Œä½†æ·±åº¦å­¦ä¹ å¯å®ç°è‡ªåŠ¨åŒ–ã€‚</li>
<li>é¢„è®­ç»ƒæ¨¡å‹åº”ç”¨äºæ‰‹ç»˜è¶…å£°ä½“ç§¯æ•°æ®æ—¶æ€§èƒ½å¯èƒ½ä¸‹é™ï¼ŒåŸå› æ˜¯æ•°æ®çš„é‡‡é›†å’Œæ ¡å‡†å·®å¼‚ã€‚</li>
<li>æµ‹è¯•æ—¶é—´é€‚åº”æŠ€æœ¯ï¼ˆTTAï¼‰èƒ½æå‡æ¨¡å‹åœ¨çœŸå®å’Œæ¨¡æ‹ŸåŸŸåç§»æƒ…å†µä¸‹çš„æ€§èƒ½ã€‚</li>
<li>æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„TTAæ–¹æ³•ï¼Œç»“åˆè§„èŒƒå›¾è°±ä½œä¸ºè§£å‰–å­¦å…ˆéªŒæ¥æå‡æ€§èƒ½ã€‚</li>
<li>åœ¨ä¸åŒç±»å‹çš„åŸŸåç§»æƒ…å†µä¸‹ï¼Œæœ¬æ–‡è¯„ä¼°äº†å¤šç§TTAæ–¹æ³•çš„æ€§èƒ½ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.08774">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-9862bc755dbd14ba558cf0a0641d903d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-6fcfb990401544b2ec3b226b4383f07a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e962eea5bb7a8dd73f652e37c608c2a3.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-6d08949e48f53a816663052261a32957.jpg" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="Improving-Lesion-Segmentation-in-Medical-Images-by-Global-and-Regional-Feature-Compensation"><a href="#Improving-Lesion-Segmentation-in-Medical-Images-by-Global-and-Regional-Feature-Compensation" class="headerlink" title="Improving Lesion Segmentation in Medical Images by Global and Regional   Feature Compensation"></a>Improving Lesion Segmentation in Medical Images by Global and Regional   Feature Compensation</h2><p><strong>Authors:Chuhan Wang, Zhenghao Chen, Jean Y. H. Yang, Jinman Kim</strong></p>
<p>Automated lesion segmentation of medical images has made tremendous improvements in recent years due to deep learning advancements. However, accurately capturing fine-grained global and regional feature representations remains a challenge. Many existing methods obtain suboptimal performance on complex lesion segmentation due to information loss during typical downsampling operations and the insufficient capture of either regional or global features. To address these issues, we propose the Global and Regional Compensation Segmentation Framework (GRCSF), which introduces two key innovations: the Global Compensation Unit (GCU) and the Region Compensation Unit (RCU). The proposed GCU addresses resolution loss in the U-shaped backbone by preserving global contextual features and fine-grained details during multiscale downsampling. Meanwhile, the RCU introduces a self-supervised learning (SSL) residual map generated by Masked Autoencoders (MAE), obtained as pixel-wise differences between reconstructed and original images, to highlight regions with potential lesions. These SSL residual maps guide precise lesion localization and segmentation through a patch-based cross-attention mechanism that integrates regional spatial and pixel-level features. Additionally, the RCU incorporates patch-level importance scoring to enhance feature fusion by leveraging global spatial information from the backbone. Experiments on two publicly available medical image segmentation datasets, including brain stroke lesion and coronary artery calcification datasets, demonstrate that our GRCSF outperforms state-of-the-art methods, confirming its effectiveness across diverse lesion types and its potential as a generalizable lesion segmentation solution. </p>
<blockquote>
<p>åŒ»å­¦å›¾åƒè‡ªåŠ¨åŒ–ç—…ç¶åˆ†å‰²åœ¨æœ€è¿‘å‡ å¹´ç”±äºæ·±åº¦å­¦ä¹ çš„å‘å±•è€Œå–å¾—äº†å·¨å¤§çš„è¿›æ­¥ã€‚ç„¶è€Œï¼Œç²¾å‡†æ•æ‰ç²¾ç»†ç²’åº¦çš„å…¨å±€å’Œå±€éƒ¨ç‰¹å¾è¡¨ç¤ºä»ç„¶æ˜¯ä¸€ä¸ªæŒ‘æˆ˜ã€‚ç”±äºå…¸å‹çš„ä¸‹é‡‡æ ·æ“ä½œè¿‡ç¨‹ä¸­çš„ä¿¡æ¯æŸå¤±ä»¥åŠå¯¹å±€éƒ¨æˆ–å…¨å±€ç‰¹å¾çš„æ•æ‰ä¸è¶³ï¼Œè®¸å¤šç°æœ‰æ–¹æ³•åœ¨å¤æ‚ç—…ç¶åˆ†å‰²æ–¹é¢çš„è¡¨ç°å¹¶ä¸ç†æƒ³ã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†å…¨çƒå’ŒåŒºåŸŸè¡¥å¿åˆ†å‰²æ¡†æ¶ï¼ˆGRCSFï¼‰ï¼Œå®ƒå¼•å…¥äº†ä¸¤ä¸ªå…³é”®çš„åˆ›æ–°ç‚¹ï¼šå…¨çƒè¡¥å¿å•å…ƒï¼ˆGCUï¼‰å’ŒåŒºåŸŸè¡¥å¿å•å…ƒï¼ˆRCUï¼‰ã€‚æ‰€æå‡ºçš„GCUé€šè¿‡åœ¨å¤šå°ºåº¦ä¸‹é‡‡æ ·è¿‡ç¨‹ä¸­ä¿ç•™å…¨å±€ä¸Šä¸‹æ–‡ç‰¹å¾å’Œç²¾ç»†ç»†èŠ‚ï¼Œè§£å†³äº†Uå½¢ä¸»å¹²ä¸­çš„åˆ†è¾¨ç‡æŸå¤±é—®é¢˜ã€‚åŒæ—¶ï¼ŒRCUå¼•å…¥äº†ä¸€ç§ç”±Masked Autoencodersï¼ˆMAEï¼‰ç”Ÿæˆçš„è‡ªç›‘ç£å­¦ä¹ ï¼ˆSSLï¼‰æ®‹å·®å›¾ï¼Œè¯¥å›¾æ˜¯é€šè¿‡é‡å»ºå›¾åƒå’ŒåŸå§‹å›¾åƒä¹‹é—´çš„åƒç´ çº§å·®å¼‚è·å¾—çš„ï¼Œä»¥çªå‡ºæ½œåœ¨ç—…ç¶åŒºåŸŸã€‚è¿™äº›SSLæ®‹å·®å›¾é€šè¿‡åŸºäºè¡¥ä¸çš„äº¤å‰æ³¨æ„åŠ›æœºåˆ¶å¼•å¯¼ç²¾ç¡®ç—…ç¶å®šä½å’Œåˆ†å‰²ï¼Œè¯¥æœºåˆ¶èåˆäº†å±€éƒ¨ç©ºé—´ç‰¹å¾å’Œåƒç´ çº§ç‰¹å¾ã€‚æ­¤å¤–ï¼ŒRCUè¿˜ç»“åˆäº†è¡¥ä¸çº§åˆ«çš„é‡è¦æ€§è¯„åˆ†ï¼Œé€šè¿‡åˆ©ç”¨ä¸»å¹²ç½‘ç»œä¸­çš„å…¨å±€ç©ºé—´ä¿¡æ¯æ¥å¢å¼ºç‰¹å¾èåˆã€‚åœ¨åŒ…æ‹¬è„‘å’ä¸­ç—…ç¶å’Œå† çŠ¶åŠ¨è„‰é’™åŒ–æ•°æ®é›†åœ¨å†…çš„ä¸¤ä¸ªå…¬å¼€å¯ç”¨çš„åŒ»å­¦å›¾åƒåˆ†å‰²æ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„GRCSFä¼˜äºæœ€æ–°æ–¹æ³•ï¼Œè¯å®äº†å…¶åœ¨å¤šç§ç—…ç¶ç±»å‹ä¸­çš„æœ‰æ•ˆæ€§ï¼Œä»¥åŠå…¶ä½œä¸ºå¯æ¨å¹¿çš„ç—…ç¶åˆ†å‰²è§£å†³æ–¹æ¡ˆçš„æ½œåŠ›ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.08675v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºä¸€ç§åä¸ºå…¨å±€ä¸åŒºåŸŸè¡¥å¿åˆ†å‰²æ¡†æ¶ï¼ˆGRCSFï¼‰çš„æ–¹æ³•ï¼Œç”¨äºè§£å†³åŒ»å­¦å›¾åƒä¸­ç²¾ç»†ç²’åº¦å…¨å±€å’ŒåŒºåŸŸç‰¹å¾è¡¨ç¤ºæ•æ‰çš„æŒ‘æˆ˜ã€‚è¯¥æ¡†æ¶åŒ…å«ä¸¤ä¸ªå…³é”®åˆ›æ–°ç‚¹ï¼šå…¨å±€è¡¥å¿å•å…ƒï¼ˆGCUï¼‰å’ŒåŒºåŸŸè¡¥å¿å•å…ƒï¼ˆRCUï¼‰ã€‚GCUè§£å†³åœ¨Uå‹éª¨å¹²ç½‘ç»œä¸­çš„åˆ†è¾¨ç‡æŸå¤±é—®é¢˜ï¼Œé€šè¿‡å¤šå°ºåº¦ä¸‹é‡‡æ ·è¿‡ç¨‹ä¸­ä¿ç•™å…¨å±€ä¸Šä¸‹æ–‡ç‰¹å¾å’Œç²¾ç»†ç»†èŠ‚ã€‚RCUåˆ™å¼•å…¥è‡ªç›‘ç£å­¦ä¹ ï¼ˆSSLï¼‰æ®‹å·®å›¾ï¼Œç”±Masked Autoencodersç”Ÿæˆçš„åƒç´ çº§å·®å¼‚å›¾çªå‡ºæ½œåœ¨ç—…å˜åŒºåŸŸã€‚è¿™äº›SSLæ®‹å·®å›¾é€šè¿‡åŸºäºè¡¥ä¸çš„äº¤å‰æ³¨æ„åŠ›æœºåˆ¶å¼•å¯¼ç²¾ç¡®ç—…å˜å®šä½å’Œåˆ†å‰²ï¼ŒèåˆåŒºåŸŸç©ºé—´ç‰¹å¾å’Œåƒç´ çº§ç‰¹å¾ã€‚åœ¨å…¬å¼€å¯ç”¨çš„åŒ»å­¦å›¾åƒåˆ†å‰²æ•°æ®é›†ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼ŒGRCSFæ–¹æ³•ä¼˜äºå½“å‰ä¸»æµæ–¹æ³•ï¼Œè¡¨ç°å‡ºå¯¹ä¸åŒç—…å˜ç±»å‹çš„è‰¯å¥½æ³›åŒ–æ½œåŠ›ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>æ·±åº¦å­¦ä¹ åœ¨åŒ»å­¦å›¾åƒè‡ªåŠ¨åŒ–ç—…å˜åˆ†å‰²æ–¹é¢å–å¾—å·¨å¤§è¿›æ­¥ï¼Œä½†ä»é¢ä¸´æ•æ‰ç²¾ç»†ç²’åº¦å…¨å±€å’ŒåŒºåŸŸç‰¹å¾è¡¨ç¤ºçš„éš¾é¢˜ã€‚</li>
<li>ç°æœ‰æ–¹æ³•åœ¨å¤æ‚ç—…å˜åˆ†å‰²ä¸Šè¡¨ç°ä¸ä½³ï¼Œä¸»è¦ç”±äºä¸‹é‡‡æ ·æ“ä½œä¸­çš„ä¿¡æ¯æŸå¤±ä»¥åŠå¯¹åŒºåŸŸæˆ–å…¨å±€ç‰¹å¾æ•æ‰ä¸è¶³ã€‚</li>
<li>æå‡ºGlobal and Regional Compensation Segmentation Framework (GRCSF)ï¼ŒåŒ…å«Global Compensation Unit (GCU) å’Œ Region Compensation Unit (RCU) ä¸¤ä¸ªå…³é”®åˆ›æ–°ç‚¹ã€‚</li>
<li>GCUè§£å†³Uå‹éª¨å¹²ç½‘ç»œä¸­çš„åˆ†è¾¨ç‡æŸå¤±é—®é¢˜ï¼Œé€šè¿‡å¤šå°ºåº¦ä¸‹é‡‡æ ·ä¿ç•™å…¨å±€ä¸Šä¸‹æ–‡ç‰¹å¾å’Œç²¾ç»†ç»†èŠ‚ã€‚</li>
<li>RCUå¼•å…¥è‡ªç›‘ç£å­¦ä¹ ï¼ˆSSLï¼‰æ®‹å·®å›¾ï¼Œçªå‡ºæ½œåœ¨ç—…å˜åŒºåŸŸï¼Œé€šè¿‡åŸºäºè¡¥ä¸çš„äº¤å‰æ³¨æ„åŠ›æœºåˆ¶å¼•å¯¼ç²¾ç¡®ç—…å˜å®šä½å’Œåˆ†å‰²ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.08675">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-8d61e5beacb98eeb897fc74d4686f720.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-30f91894f0ac912b0ee0e2c0a6e99967.jpg" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="DM-Mamba-Dual-domain-Multi-scale-Mamba-for-MRI-reconstruction"><a href="#DM-Mamba-Dual-domain-Multi-scale-Mamba-for-MRI-reconstruction" class="headerlink" title="DM-Mamba: Dual-domain Multi-scale Mamba for MRI reconstruction"></a>DM-Mamba: Dual-domain Multi-scale Mamba for MRI reconstruction</h2><p><strong>Authors:Yucong Meng, Zhiwei Yang, Zhijian Song, Yonghong Shi</strong></p>
<p>The accelerated MRI reconstruction poses a challenging ill-posed inverse problem due to the significant undersampling in k-space. Deep neural networks, such as CNNs and ViT, have shown substantial performance improvements for this task while encountering the dilemma between global receptive fields and efficient computation. To this end, this paper pioneers exploring Mamba, a new paradigm for long-range dependency modeling with linear complexity, for efficient and effective MRI reconstruction. However, directly applying Mamba to MRI reconstruction faces three significant issues: (1) Mambaâ€™s row-wise and column-wise scanning disrupts k-spaceâ€™s unique spectrum, leaving its potential in k-space learning unexplored. (2) Existing Mamba methods unfold feature maps with multiple lengthy scanning paths, leading to long-range forgetting and high computational burden. (3) Mamba struggles with spatially-varying contents, resulting in limited diversity of local representations. To address these, we propose a dual-domain multi-scale Mamba for MRI reconstruction from the following perspectives: (1) We pioneer vision Mamba in k-space learning. A circular scanning is customized for spectrum unfolding, benefiting the global modeling of k-space. (2) We propose a multi-scale Mamba with an efficient scanning strategy in both image and k-space domains. It mitigates long-range forgetting and achieves a better trade-off between efficiency and performance. (3) We develop a local diversity enhancement module to improve the spatially-varying representation of Mamba. Extensive experiments are conducted on three public datasets for MRI reconstruction under various undersampling patterns. Comprehensive results demonstrate that our method significantly outperforms state-of-the-art methods with lower computational cost. Implementation code will be available at <a target="_blank" rel="noopener" href="https://github.com/XiaoMengLiLiLi/DM-Mamba">https://github.com/XiaoMengLiLiLi/DM-Mamba</a>. </p>
<blockquote>
<p>åŠ é€ŸMRIé‡å»ºæ˜¯ä¸€ä¸ªå…·æœ‰æŒ‘æˆ˜æ€§çš„ä¸é€‚å®šåé—®é¢˜ï¼Œä¸»è¦æ˜¯å› ä¸ºkç©ºé—´å­˜åœ¨å¤§é‡çš„æ¬ é‡‡æ ·ã€‚æ·±åº¦ç¥ç»ç½‘ç»œï¼Œå¦‚å·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNï¼‰å’ŒVision Transformerï¼ˆViTï¼‰ï¼Œåœ¨æ­¤ä»»åŠ¡ä¸Šæ˜¾ç¤ºå‡ºæ˜¾è‘—çš„æ€§èƒ½æå‡ï¼Œä½†åœ¨å…¨å±€æ„Ÿå—é‡å’Œé«˜æ•ˆè®¡ç®—ä¹‹é—´é‡åˆ°äº†å›°å¢ƒã€‚é‰´äºæ­¤ï¼Œæœ¬æ–‡å¼€åˆ›æ€§åœ°æ¢ç´¢äº†Mambaï¼Œè¿™æ˜¯ä¸€ç§å…·æœ‰çº¿æ€§å¤æ‚åº¦çš„é•¿è·ç¦»ä¾èµ–å»ºæ¨¡æ–°èŒƒå¼ï¼Œç”¨äºé«˜æ•ˆä¸”æœ‰æ•ˆçš„MRIé‡å»ºã€‚ç„¶è€Œï¼Œç›´æ¥å°†Mambaåº”ç”¨äºMRIé‡å»ºé¢ä¸´ä¸‰ä¸ªä¸»è¦é—®é¢˜ï¼šï¼ˆ1ï¼‰Mambaçš„è¡Œæ‰«æå’Œåˆ—æ‰«æç ´åäº†kç©ºé—´çš„ç‹¬ç‰¹é¢‘è°±ï¼Œä½¿å…¶å¯¹kç©ºé—´å­¦ä¹ çš„æ½œåŠ›å°šæœªå¾—åˆ°æ¢ç´¢ã€‚ï¼ˆ2ï¼‰ç°æœ‰çš„Mambaæ–¹æ³•å±•å¼€ç‰¹å¾æ˜ å°„å…·æœ‰å¤šæ¡å†—é•¿çš„æ‰«æè·¯å¾„ï¼Œå¯¼è‡´é•¿è·ç¦»é—å¿˜å’Œé«˜è®¡ç®—è´Ÿæ‹…ã€‚ï¼ˆ3ï¼‰Mambaåœ¨ç©ºé—´å†…å®¹å˜åŒ–æ–¹é¢é‡åˆ°å›°éš¾ï¼Œå¯¼è‡´å±€éƒ¨è¡¨ç¤ºå¤šæ ·æ€§æœ‰é™ã€‚ä¸ºè§£å†³è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬ä»ä»¥ä¸‹è§’åº¦æå‡ºäº†ç”¨äºMRIé‡å»ºçš„åŒåŸŸå¤šå°ºåº¦Mambaï¼šï¼ˆ1ï¼‰æˆ‘ä»¬å¼€åˆ›æ€§åœ°æå‡ºäº†kç©ºé—´ä¸­çš„è§†è§‰Mambaã€‚é’ˆå¯¹é¢‘è°±å±•å¼€å®šåˆ¶äº†å¾ªç¯æ‰«æï¼Œæœ‰åˆ©äºkç©ºé—´çš„å…¨å±€å»ºæ¨¡ã€‚ï¼ˆ2ï¼‰æˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªåœ¨å›¾åƒå’Œkç©ºé—´åŸŸéƒ½å…·æœ‰é«˜æ•ˆæ‰«æç­–ç•¥çš„å¤šå°ºåº¦Mambaã€‚å®ƒå‡è½»äº†é•¿è·ç¦»é—å¿˜é—®é¢˜ï¼Œå¹¶åœ¨æ•ˆç‡å’Œæ€§èƒ½ä¹‹é—´å–å¾—äº†æ›´å¥½çš„å¹³è¡¡ã€‚ï¼ˆ3ï¼‰æˆ‘ä»¬å¼€å‘äº†ä¸€ä¸ªå±€éƒ¨å¤šæ ·æ€§å¢å¼ºæ¨¡å—ï¼Œä»¥æé«˜Mambaçš„ç©ºé—´å˜åŒ–è¡¨ç¤ºã€‚åœ¨ä¸‰ä¸ªå…¬å…±æ•°æ®é›†ä¸Šè¿›è¡Œäº†å¹¿æ³›çš„MRIé‡å»ºå®éªŒï¼Œå®éªŒç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨è¾ƒä½çš„è®¡ç®—æˆæœ¬ä¸‹æ˜¾è‘—ä¼˜äºæœ€å…ˆè¿›çš„æ–¹æ³•ã€‚ç›¸å…³å®ç°ä»£ç å°†å‘å¸ƒåœ¨<a target="_blank" rel="noopener" href="https://github.com/XiaoMengLiLiLi/DM-Mamba%E3%80%82">https://github.com/XiaoMengLiLiLi/DM-Mambaã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2501.08163v2">PDF</a> </p>
<p><strong>æ‘˜è¦</strong><br>    è¿™ç¯‡è®ºæ–‡æ¢è®¨äº†åœ¨MRIé‡å»ºä¸­çš„æŒ‘æˆ˜æ€§é—®é¢˜ï¼Œé’ˆå¯¹kç©ºé—´ä¸­æ˜¾è‘—çš„æ¬ é‡‡æ ·ç°è±¡ï¼Œæå‡ºäº†ä¸€ç§æ–°çš„å»ºæ¨¡æ–¹æ³•Mambaã€‚å°½ç®¡Mambaåœ¨è§£å†³é•¿è·ç¦»ä¾èµ–å»ºæ¨¡æ–¹é¢å…·æœ‰çº¿æ€§å¤æ‚æ€§çš„ä¼˜åŠ¿ï¼Œä½†åœ¨ç›´æ¥åº”ç”¨äºMRIé‡å»ºæ—¶é¢ä¸´ä¸‰ä¸ªä¸»è¦é—®é¢˜ã€‚ä¸ºäº†å…‹æœè¿™äº›é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§åŒåŸŸå¤šå°ºåº¦Mambaæ–¹æ³•ï¼Œåœ¨kç©ºé—´å’Œå›¾åƒåŸŸè¿›è¡Œé«˜æ•ˆæ‰«æç­–ç•¥ï¼Œå¹¶å¼€å‘äº†ä¸€ä¸ªå±€éƒ¨å¤šæ ·æ€§å¢å¼ºæ¨¡å—æ¥æ”¹å–„Mambaçš„ç©ºé—´å˜åŒ–è¡¨ç¤ºã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨é™ä½è®¡ç®—æˆæœ¬çš„åŒæ—¶ï¼Œæ˜¾è‘—ä¼˜äºç°æœ‰æŠ€æœ¯ã€‚</p>
<p><strong>å…³é”®è§è§£</strong></p>
<ul>
<li>Mambaä½œä¸ºä¸€ç§æ–°çš„é•¿è·ç¦»ä¾èµ–å»ºæ¨¡æ–¹æ³•ï¼Œå…·æœ‰çº¿æ€§å¤æ‚æ€§ï¼Œåœ¨MRIé‡å»ºä¸­å…·æœ‰æ½œåŠ›ã€‚</li>
<li>ç›´æ¥åº”ç”¨MambaäºMRIé‡å»ºé¢ä¸´ä¸‰ä¸ªä¸»è¦é—®é¢˜ï¼šå¯¹kç©ºé—´ç‹¬ç‰¹è°±çš„å¹²æ‰°ã€ç‰¹å¾æ˜ å°„å±•å¼€è·¯å¾„è¿‡é•¿ä»¥åŠç©ºé—´å†…å®¹å˜åŒ–å¯¼è‡´çš„å±€éƒ¨è¡¨ç¤ºå¤šæ ·æ€§æœ‰é™ã€‚</li>
<li>æå‡ºäº†ä¸€ç§åŒåŸŸå¤šå°ºåº¦Mambaæ–¹æ³•ï¼Œé¦–æ¬¡åœ¨kç©ºé—´ä¸­è¿›è¡Œè§†è§‰Mambaå­¦ä¹ ï¼Œå¹¶å®šåˆ¶äº†å¾ªç¯æ‰«æä»¥å±•å¼€é¢‘è°±ï¼Œæœ‰åˆ©äºå…¨å±€kç©ºé—´å»ºæ¨¡ã€‚</li>
<li>é€šè¿‡åœ¨å›¾åƒå’Œkç©ºé—´åŸŸä¸­é‡‡ç”¨é«˜æ•ˆæ‰«æç­–ç•¥çš„å¤šå°ºåº¦Mambaï¼Œå‡è½»äº†é•¿è·ç¦»é—å¿˜é—®é¢˜ï¼Œå®ç°äº†æ•ˆç‡å’Œæ€§èƒ½ä¹‹é—´çš„æ›´å¥½æƒè¡¡ã€‚</li>
<li>å¼€å‘äº†å±€éƒ¨å¤šæ ·æ€§å¢å¼ºæ¨¡å—ï¼Œæé«˜äº†Mambaçš„ç©ºé—´å˜åŒ–è¡¨ç¤ºã€‚</li>
<li>åœ¨å¤šä¸ªå…¬å…±æ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨MRIé‡å»ºæ–¹é¢æ˜¾è‘—ä¼˜äºç°æœ‰æŠ€æœ¯ï¼Œè®¡ç®—æˆæœ¬æ›´ä½ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2501.08163">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-3d7ea188637ae63208bdf4dfef63927e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ba5d86c1f2df3e7675d79755a39c9046.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-b07a4f395a05bf5ae662d4aa6cf320b1.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-4fc573d035ecb47cf000924ad89bfc68.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d77fe7286b8bb0c4e7c90e02dc479df1.jpg" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="Heuristical-Comparison-of-Vision-Transformers-Against-Convolutional-Neural-Networks-for-Semantic-Segmentation-on-Remote-Sensing-Imagery"><a href="#Heuristical-Comparison-of-Vision-Transformers-Against-Convolutional-Neural-Networks-for-Semantic-Segmentation-on-Remote-Sensing-Imagery" class="headerlink" title="Heuristical Comparison of Vision Transformers Against Convolutional   Neural Networks for Semantic Segmentation on Remote Sensing Imagery"></a>Heuristical Comparison of Vision Transformers Against Convolutional   Neural Networks for Semantic Segmentation on Remote Sensing Imagery</h2><p><strong>Authors:Ashim Dahal, Saydul Akbar Murad, Nick Rahimi</strong></p>
<p>Vision Transformers (ViT) have recently brought a new wave of research in the field of computer vision. These models have performed particularly well in image classification and segmentation. Research on semantic and instance segmentation has accelerated with the introduction of the new architecture, with over 80% of the top 20 benchmarks for the iSAID dataset based on either the ViT architecture or the attention mechanism behind its success. This paper focuses on the heuristic comparison of three key factors of using (or not using) ViT for semantic segmentation of remote sensing aerial images on the iSAID dataset. The experimental results observed during this research were analyzed based on three objectives. First, we studied the use of a weighted fused loss function to maximize the mean Intersection over Union (mIoU) score and Dice score while minimizing entropy or class representation loss. Second, we compared transfer learning on Metaâ€™s MaskFormer, a ViT-based semantic segmentation model, against a generic UNet Convolutional Neural Network (CNN) based on mIoU, Dice scores, training efficiency, and inference time. Third, we examined the trade-offs between the two models in comparison to current state-of-the-art segmentation models. We show that the novel combined weighted loss function significantly boosts the CNN modelâ€™s performance compared to transfer learning with ViT. The code for this implementation can be found at: <a target="_blank" rel="noopener" href="https://github.com/ashimdahal/ViT-vs-CNN-Image-Segmentation">https://github.com/ashimdahal/ViT-vs-CNN-Image-Segmentation</a>. </p>
<blockquote>
<p>Vision Transformersï¼ˆViTï¼‰æœ€è¿‘ä¸ºè®¡ç®—æœºè§†è§‰é¢†åŸŸå¸¦æ¥äº†æ–°çš„ç ”ç©¶æµªæ½®ã€‚è¿™äº›æ¨¡å‹åœ¨å›¾åƒåˆ†ç±»å’Œåˆ†å‰²æ–¹é¢è¡¨ç°å‡ºè‰²ã€‚æ–°æ¶æ„çš„å¼•å…¥åŠ é€Ÿäº†è¯­ä¹‰åˆ†å‰²å’Œå®ä¾‹åˆ†å‰²çš„ç ”ç©¶ï¼ŒiSAIDæ•°æ®é›†çš„å‰20ä¸ªæ¦œå•ä¸­æœ‰è¶…è¿‡80%æ˜¯åŸºäºViTæ¶æ„æˆ–å…¶æˆåŠŸèƒŒåçš„æ³¨æ„åŠ›æœºåˆ¶ã€‚æœ¬æ–‡é‡ç‚¹å…³æ³¨åœ¨iSAIDæ•°æ®é›†ä¸Šä½¿ç”¨ï¼ˆæˆ–ä¸ä½¿ç”¨ï¼‰ViTè¿›è¡Œé¥æ„Ÿå›¾åƒè¯­ä¹‰åˆ†å‰²çš„ä¸‰ä¸ªå…³é”®å› ç´ çš„å¯å‘å¼æ¯”è¾ƒã€‚ç ”ç©¶è¿‡ç¨‹ä¸­çš„å®éªŒç»“æœåŸºäºä»¥ä¸‹ä¸‰ä¸ªç›®æ ‡è¿›è¡Œåˆ†æã€‚é¦–å…ˆï¼Œæˆ‘ä»¬ç ”ç©¶äº†ä½¿ç”¨åŠ æƒèåˆæŸå¤±å‡½æ•°ï¼Œä»¥æœ€å¤§åŒ–å¹³å‡äº¤å¹¶æ¯”ï¼ˆmIoUï¼‰å¾—åˆ†å’ŒDiceå¾—åˆ†ï¼ŒåŒæ—¶æœ€å°åŒ–ï¿½ï¿½eæˆ–ç±»è¡¨ç¤ºæŸå¤±ã€‚å…¶æ¬¡ï¼Œæˆ‘ä»¬æ¯”è¾ƒäº†Metaçš„MaskFormerï¼ˆä¸€ç§åŸºäºViTçš„è¯­ä¹‰åˆ†å‰²æ¨¡å‹ï¼‰çš„è¿ç§»å­¦ä¹ ä¸åŸºäºmIoUã€Diceå¾—åˆ†ã€è®­ç»ƒæ•ˆç‡å’Œæ¨ç†æ—¶é—´çš„é€šç”¨UNetå·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNï¼‰çš„è¿ç§»å­¦ä¹ ã€‚ç¬¬ä¸‰ï¼Œæˆ‘ä»¬æ¯”è¾ƒäº†è¿™ä¸¤ç§æ¨¡å‹ä¸å½“å‰æœ€å…ˆè¿›çš„åˆ†å‰²æ¨¡å‹çš„å¾—å¤±ã€‚æˆ‘ä»¬è¡¨æ˜ï¼Œä¸ViTçš„è¿ç§»å­¦ä¹ ç›¸æ¯”ï¼Œæ–°å‹ç»„åˆåŠ æƒæŸå¤±å‡½æ•°æ˜¾è‘—æé«˜äº†CNNæ¨¡å‹çš„æ€§èƒ½ã€‚è¯¥å®ç°çš„ä»£ç å¯åœ¨ä»¥ä¸‹ç½‘å€æ‰¾åˆ°ï¼š<a target="_blank" rel="noopener" href="https://github.com/ashimdahal/ViT-vs-CNN-Image-Segmentation">https://github.com/ashimdahal/ViT-vs-CNN-Image-Segmentation</a>ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2411.09101v2">PDF</a> </p>
<p><strong>Summary</strong><br>     æœ¬æ–‡ç ”ç©¶äº†ä½¿ç”¨Vision Transformersï¼ˆViTï¼‰è¿›è¡Œé¥æ„Ÿå›¾åƒè¯­ä¹‰åˆ†å‰²çš„ä¼˜ç¼ºç‚¹ï¼Œå¹¶å¯¹æ¯”äº†ViTæ¶æ„å’ŒåŸºäºæ³¨æ„åŠ›æœºåˆ¶çš„æ¨¡å‹åœ¨iSAIDæ•°æ®é›†ä¸Šçš„è¡¨ç°ã€‚æ–‡ç« é‡ç‚¹æ¢è®¨äº†ä¸‰ä¸ªå…³é”®æ–¹é¢ï¼šä½¿ç”¨åŠ æƒèåˆæŸå¤±å‡½æ•°çš„æ•ˆæœã€ä¸åŸºäºViTçš„MaskFormeræ¨¡å‹çš„è¿ç§»å­¦ä¹ å¯¹æ¯”ï¼Œä»¥åŠä¸ä¼ ç»ŸCNNæ¨¡å‹çš„æ€§èƒ½å¯¹æ¯”ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒåŠ æƒæŸå¤±å‡½æ•°èƒ½æœ‰æ•ˆæå‡CNNæ¨¡å‹æ€§èƒ½ï¼Œç›¸è¾ƒäºViTè¿ç§»å­¦ä¹ æœ‰æ›´å¥½çš„è¡¨ç°ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li><p>Vision Transformersï¼ˆViTï¼‰åœ¨å›¾åƒåˆ†ç±»å’Œåˆ†å‰²é¢†åŸŸè¡¨ç°ä¼˜å¼‚ï¼Œå·²æˆä¸ºè®¡ç®—æœºè§†è§‰é¢†åŸŸçš„æ–°ç ”ç©¶çƒ­ç‚¹ã€‚</p>
</li>
<li><p>iSAIDæ•°æ®é›†çš„å‰20åæ¦œå•ä¸­ï¼Œè¶…è¿‡80%æ˜¯åŸºäºViTæ¶æ„æˆ–æ³¨æ„åŠ›æœºåˆ¶çš„æ¨¡å‹ã€‚</p>
</li>
<li><p>åŠ æƒèåˆæŸå¤±å‡½æ•°ç”¨äºæœ€å¤§åŒ–å¹³å‡äº¤å¹¶æ¯”ï¼ˆmIoUï¼‰å’ŒDiceç³»æ•°ï¼ŒåŒæ—¶æœ€å°åŒ–ç†µæˆ–ç±»åˆ«è¡¨ç¤ºæŸå¤±ã€‚</p>
</li>
<li><p>å¯¹æ¯”äº†åŸºäºViTçš„MaskFormeræ¨¡å‹å’Œé€šç”¨UNetå·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNï¼‰åœ¨mIoUã€Diceç³»æ•°ã€è®­ç»ƒæ•ˆç‡å’Œæ¨ç†æ—¶é—´ä¸Šçš„è¡¨ç°ã€‚</p>
</li>
<li><p>åŠ æƒæŸå¤±å‡½æ•°æ˜¾è‘—æå‡CNNæ¨¡å‹æ€§èƒ½ï¼Œç›¸è¾ƒäºViTè¿ç§»å­¦ä¹ æœ‰æ›´å¥½çš„è¡¨ç°ã€‚</p>
</li>
<li><p>ç ”ç©¶ç»“æœæä¾›äº†é¥æ„Ÿå›¾åƒè¯­ä¹‰åˆ†å‰²çš„æ–°è§†è§’å’Œæ–¹æ³•è®ºã€‚</p>
</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2411.09101">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-417b5bf8614515af23c47c85131ebc38.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-73afbad8ac8d34059a643a0505bebe91.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c0b782ce64a1396a6eb68627281a8575.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-2f4fbc3caa3641f4926ebf35519a7c95.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-37eb1c6f292a5d4e9f1fb558c9ced14b.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-1fad05694cea91fc8cfc80ae663ab943.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-12eaf63c35279df8cfd6d41c28acba2c.jpg" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="A-Unified-Model-for-Compressed-Sensing-MRI-Across-Undersampling-Patterns"><a href="#A-Unified-Model-for-Compressed-Sensing-MRI-Across-Undersampling-Patterns" class="headerlink" title="A Unified Model for Compressed Sensing MRI Across Undersampling Patterns"></a>A Unified Model for Compressed Sensing MRI Across Undersampling Patterns</h2><p><strong>Authors:Armeet Singh Jatyani, Jiayun Wang, Aditi Chandrashekar, Zihui Wu, Miguel Liu-Schiaffini, Bahareh Tolooshams, Anima Anandkumar</strong></p>
<p>Compressed Sensing MRI reconstructs images of the bodyâ€™s internal anatomy from undersampled measurements, thereby reducing the scan time - the time subjects need to remain still. Recently, deep neural networks have shown great potential for reconstructing high-fidelity images from highly undersampled measurements in the frequency space. However, one needs to train multiple models for different undersampling patterns and desired output image resolutions, since most networks operate on a fixed discretization. Such approaches are highly impractical in clinical settings, where undersampling patterns and image resolutions are frequently changed to accommodate different real-time imaging and diagnostic requirements.   We propose a unified model robust to different measurement undersampling patterns and image resolutions in compressed sensing MRI. Our model is based on neural operators, a discretization-agnostic architecture. Neural operators are employed in both image and measurement space, which capture local and global image features for MRI reconstruction. Empirically, we achieve consistent performance across different undersampling rates and patterns, with an average 11 percent SSIM and 4dB PSNR improvement over a state-of-the-art CNN, End-to-End VarNet. For efficiency, our inference speed is also 1,400x faster than diffusion methods. The resolution-agnostic design also enhances zero-shot super-resolution and extended field of view in reconstructed images. Our unified model offers a versatile solution for MRI, adapting seamlessly to various measurement undersampling and imaging resolutions, making it highly effective for flexible and reliable clinical imaging. Our code is available at <a target="_blank" rel="noopener" href="https://armeet.ca/nomri">https://armeet.ca/nomri</a>. </p>
<blockquote>
<p>å‹ç¼©æ„ŸçŸ¥MRIé€šè¿‡æ¬ é‡‡æ ·çš„æµ‹é‡é‡å»ºäººä½“å†…éƒ¨è§£å‰–å›¾åƒï¼Œä»è€Œå‡å°‘æ‰«ææ—¶é—´â€”â€”å³æ‚£è€…éœ€è¦ä¿æŒé™æ­¢çš„æ—¶é—´ã€‚æœ€è¿‘ï¼Œæ·±åº¦ç¥ç»ç½‘ç»œåœ¨é¢‘ç‡ç©ºé—´ä»é«˜åº¦æ¬ é‡‡æ ·çš„æµ‹é‡ä¸­é‡å»ºé«˜ä¿çœŸå›¾åƒæ–¹é¢æ˜¾ç¤ºå‡ºå·¨å¤§æ½œåŠ›ã€‚ç„¶è€Œï¼Œç”±äºå¤§å¤šæ•°ç½‘ç»œåœ¨å›ºå®šçš„ç¦»æ•£åŒ–ä¸Šè¿è¡Œï¼Œå› æ­¤éœ€è¦é’ˆå¯¹ä¸åŒçš„æ¬ é‡‡æ ·æ¨¡å¼å’Œæ‰€éœ€çš„è¾“å‡ºå›¾åƒåˆ†è¾¨ç‡è®­ç»ƒå¤šä¸ªæ¨¡å‹ã€‚åœ¨ä¸´åºŠç¯å¢ƒä¸­ï¼Œæ¬ é‡‡æ ·æ¨¡å¼å’Œå›¾åƒåˆ†è¾¨ç‡ç»å¸¸æ›´æ”¹ä»¥é€‚åº”ä¸åŒçš„å®æ—¶æˆåƒå’Œè¯Šæ–­è¦æ±‚ï¼Œå› æ­¤è¿™ç§æ–¹æ³•ä¸å¤ªå®ç”¨ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§é€‚ç”¨äºå‹ç¼©æ„ŸçŸ¥MRIä¸­ä¸åŒæµ‹é‡æ¬ é‡‡æ ·æ¨¡å¼å’Œå›¾åƒåˆ†è¾¨ç‡çš„ç»Ÿä¸€æ¨¡å‹ã€‚æˆ‘ä»¬çš„æ¨¡å‹åŸºäºç¥ç»ç®—å­ï¼Œè¿™æ˜¯ä¸€ç§ä¸å—ç¦»æ•£åŒ–å½±å“çš„æ¶æ„ã€‚ç¥ç»ç®—å­åœ¨å›¾åƒå’Œæµ‹é‡ç©ºé—´ä¸­éƒ½è¢«é‡‡ç”¨ï¼Œèƒ½å¤Ÿæ•æ‰MRIé‡å»ºçš„å±€éƒ¨å’Œå…¨å±€å›¾åƒç‰¹å¾ã€‚ä»ç»éªŒä¸Šçœ‹ï¼Œæˆ‘ä»¬åœ¨ä¸åŒçš„æ¬ é‡‡æ ·ç‡å’Œæ¨¡å¼ä¸Šå®ç°äº†ç¨³å®šçš„æ€§èƒ½ï¼Œä¸æœ€å…ˆè¿›çš„CNN End-to-End VarNetç›¸æ¯”ï¼Œå¹³å‡SSIMæé«˜äº†11%ï¼ŒPSNRæé«˜äº†4dBã€‚ä¸ºäº†æé«˜æ•ˆç‡ï¼Œæˆ‘ä»¬çš„æ¨ç†é€Ÿåº¦ä¹Ÿæ¯”æ‰©æ•£æ–¹æ³•å¿«1400å€ã€‚åˆ†è¾¨ç‡æ— å…³çš„è®¾è®¡è¿˜æé«˜äº†é‡å»ºå›¾åƒçš„é›¶å°„å‡»è¶…åˆ†è¾¨ç‡å’Œæ‰©å±•è§†é‡ã€‚æˆ‘ä»¬çš„ç»Ÿä¸€æ¨¡å‹ä¸ºMRIæä¾›äº†ä¸€ä¸ªé€šç”¨è§£å†³æ–¹æ¡ˆï¼Œå¯ä»¥æ— ç¼é€‚åº”å„ç§æµ‹é‡æ¬ é‡‡æ ·å’Œæˆåƒåˆ†è¾¨ç‡ï¼Œä½¿å…¶æˆä¸ºçµæ´»å¯é çš„ä¸´åºŠæˆåƒçš„é«˜æ•ˆå·¥å…·ã€‚æˆ‘ä»¬çš„ä»£ç å¯åœ¨<a target="_blank" rel="noopener" href="https://armeet.ca/nomri%E8%8E%B7%E5%8F%96%E3%80%82">https://armeet.ca/nomriè·å–ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2410.16290v3">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>åŸºäºå‹ç¼©æ„ŸçŸ¥çš„MRIé€šè¿‡æ¬ é‡‡æ ·çš„æµ‹é‡é‡å»ºèº«ä½“å†…éƒ¨ç»“æ„å›¾åƒï¼Œå‡å°‘äº†æ‰«ææ—¶é—´ã€‚è¿‘æœŸæ·±åº¦ç¥ç»ç½‘ç»œåœ¨é¢‘ç‡ç©ºé—´é«˜åº¦æ¬ é‡‡æ ·çš„æµ‹é‡é‡å»ºé«˜ä¿çœŸå›¾åƒæ–¹é¢å±•ç°å‡ºå·¨å¤§æ½œåŠ›ã€‚ç„¶è€Œï¼Œå¤§å¤šæ•°ç½‘ç»œåœ¨å›ºå®šç¦»æ•£åŒ–ä¸Šæ“ä½œï¼Œéœ€è¦é’ˆå¯¹ä¸åŒçš„æ¬ é‡‡æ ·æ¨¡å¼å’Œæ‰€éœ€çš„è¾“å‡ºå›¾åƒåˆ†è¾¨ç‡è®­ç»ƒå¤šä¸ªæ¨¡å‹ï¼Œè¿™åœ¨ä¸´åºŠç¯å¢ƒä¸­éå¸¸ä¸å®ç”¨ã€‚æˆ‘ä»¬æå‡ºä¸€ç§ç»Ÿä¸€çš„æ¨¡å‹ï¼Œé€‚åº”ä¸åŒçš„æµ‹é‡æ¬ é‡‡æ ·æ¨¡å¼å’Œå›¾åƒåˆ†è¾¨ç‡ã€‚è¯¥æ¨¡å‹åŸºäºç¥ç»ç®—å­ï¼Œæ˜¯ä¸€ç§ä¸å—ç¦»æ•£åŒ–å½±å“çš„æ¶æ„ã€‚ç¥ç»ç®—å­åœ¨å›¾åƒå’Œæµ‹é‡ç©ºé—´ä¸­å‡è¢«é‡‡ç”¨ï¼Œå¯æ•æ‰å±€éƒ¨å’Œå…¨å±€å›¾åƒç‰¹å¾ç”¨äºMRIé‡å»ºã€‚ä¸å½“å‰å…ˆè¿›æŠ€æœ¯ç›¸æ¯”ï¼Œæˆ‘ä»¬çš„æ¨¡å‹åœ¨ä¸åŒçš„æ¬ é‡‡æ ·ç‡å’Œæ¨¡å¼ä¸Šè¡¨ç°ä¸€è‡´ï¼Œå¹³å‡SSIMæé«˜11%ï¼ŒPSNRæé«˜4dBã€‚åŒæ—¶ï¼Œæˆ‘ä»¬çš„æ¨ç†é€Ÿåº¦æ¯”æ‰©æ•£æ–¹æ³•å¿«1400å€ã€‚åˆ†è¾¨ç‡æ— å…³çš„è®¾è®¡è¿˜æé«˜äº†é‡å»ºå›¾åƒçš„é›¶å°„æŸè¶…åˆ†è¾¨ç‡å’Œæ‰©å±•è§†é‡ã€‚æˆ‘ä»¬çš„ç»Ÿä¸€æ¨¡å‹ä¸ºMRIæä¾›äº†é€šç”¨è§£å†³æ–¹æ¡ˆï¼Œå¯è½»æ¾é€‚åº”å„ç§æµ‹é‡æ¬ é‡‡æ ·å’Œæˆåƒåˆ†è¾¨ç‡ï¼Œä¸ºä¸´åºŠæˆåƒæä¾›äº†çµæ´»å¯é çš„é€‰æ‹©ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å‹ç¼©æ„ŸçŸ¥MRIå¯ä»æ¬ é‡‡æ ·æµ‹é‡é‡å»ºå›¾åƒï¼Œç¼©çŸ­æ‰«ææ—¶é—´ã€‚</li>
<li>æ·±åº¦ç¥ç»ç½‘ç»œåœ¨é‡å»ºé«˜é¢‘ç©ºé—´é«˜åº¦æ¬ é‡‡æ ·çš„å›¾åƒæ–¹é¢è¡¨ç°å‡ºå·¨å¤§æ½œåŠ›ã€‚</li>
<li>ç°æœ‰æ–¹æ³•éœ€è¦åœ¨ä¸åŒæ¬ é‡‡æ ·æ¨¡å¼å’Œè¾“å‡ºå›¾åƒåˆ†è¾¨ç‡ä¸Šè®­ç»ƒå¤šä¸ªæ¨¡å‹ï¼Œç¼ºä¹å®ç”¨æ€§ã€‚</li>
<li>æå‡ºä¸€ç§åŸºäºç¥ç»ç®—å­çš„ç»Ÿä¸€æ¨¡å‹ï¼Œé€‚åº”ä¸åŒçš„æµ‹é‡æ¬ é‡‡æ ·æ¨¡å¼å’Œå›¾åƒåˆ†è¾¨ç‡ã€‚</li>
<li>è¯¥æ¨¡å‹åœ¨å¤šç§æ¬ é‡‡æ ·æƒ…å†µä¸‹è¡¨ç°ç¨³å®šï¼Œç›¸è¾ƒäºå…ˆè¿›æŠ€æœ¯æœ‰æ˜¾è‘—çš„SSIMå’ŒPSNRæå‡ã€‚</li>
<li>æ¨¡å‹æ¨ç†é€Ÿåº¦æ˜¾è‘—æé«˜ï¼Œä¸”å…·å¤‡é›¶å°„æŸè¶…åˆ†è¾¨ç‡å’Œæ‰©å±•è§†é‡èƒ½åŠ›ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2410.16290">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-0f957fd37f39cc3f18efb36679e58e28.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-a3ab3f350b3cdb124fabff5e0588202a.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-0480049752d21465ab16f3f2e30561f9.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-962d828834551507a476975771920715.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-875f71c574f205f34e1d0b52979d679b.jpg" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="Fully-Unsupervised-Dynamic-MRI-Reconstruction-via-Diffeo-Temporal-Equivariance"><a href="#Fully-Unsupervised-Dynamic-MRI-Reconstruction-via-Diffeo-Temporal-Equivariance" class="headerlink" title="Fully Unsupervised Dynamic MRI Reconstruction via Diffeo-Temporal   Equivariance"></a>Fully Unsupervised Dynamic MRI Reconstruction via Diffeo-Temporal   Equivariance</h2><p><strong>Authors:Andrew Wang, Mike Davies</strong></p>
<p>Reconstructing dynamic MRI image sequences from undersampled accelerated measurements is crucial for faster and higher spatiotemporal resolution real-time imaging of cardiac motion, free breathing motion and many other applications. Classical paradigms, such as gated cine MRI, assume periodicity, disallowing imaging of true motion. Supervised deep learning methods are fundamentally flawed as, in dynamic imaging, ground truth fully-sampled videos are impossible to truly obtain. We propose an unsupervised framework to learn to reconstruct dynamic MRI sequences from undersampled measurements alone by leveraging natural geometric spatiotemporal equivariances of MRI. Dynamic Diffeomorphic Equivariant Imaging (DDEI) significantly outperforms state-of-the-art unsupervised methods such as SSDU on highly accelerated dynamic cardiac imaging. Our method is agnostic to the underlying neural network architecture and can be used to adapt the latest models and post-processing approaches. Our code and video demos are at <a target="_blank" rel="noopener" href="https://github.com/Andrewwango/ddei">https://github.com/Andrewwango/ddei</a>. </p>
<blockquote>
<p>ä»æ¬ é‡‡æ ·çš„åŠ é€Ÿæµ‹é‡å€¼é‡å»ºåŠ¨æ€MRIå›¾åƒåºåˆ—å¯¹äºæ›´å¿«ã€æ›´é«˜æ—¶ç©ºåˆ†è¾¨ç‡çš„å®æ—¶å¿ƒè„è¿åŠ¨æˆåƒã€è‡ªç”±å‘¼å¸è¿åŠ¨æˆåƒä»¥åŠè®¸å¤šå…¶ä»–åº”ç”¨è‡³å…³é‡è¦ã€‚ç»å…¸çš„æ¨¡å¼ï¼Œå¦‚é—¨æ§ç”µå½±MRIï¼Œå‡è®¾å‘¨æœŸæ€§ï¼Œä¸å…è®¸å¯¹çœŸå®è¿åŠ¨è¿›è¡Œæˆåƒã€‚ç›‘ç£æ·±åº¦å­¦ä¹ æ–¹æ³•å­˜åœ¨æ ¹æœ¬ç¼ºé™·ï¼Œå› ä¸ºåœ¨åŠ¨æ€æˆåƒä¸­ï¼Œä¸å¯èƒ½çœŸæ­£è·å¾—å®Œå…¨é‡‡æ ·çš„åœ°é¢çœŸå®è§†é¢‘ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§æ— ç›‘ç£çš„æ¡†æ¶ï¼Œé€šè¿‡åˆ©ç”¨MRIçš„è‡ªç„¶å‡ ä½•æ—¶ç©ºç­‰ä»·æ€§ï¼Œä»…ä»æ¬ é‡‡æ ·æµ‹é‡ä¸­å­¦ä¹ é‡å»ºåŠ¨æ€MRIåºåˆ—ã€‚åŠ¨æ€å¾®åˆ†ç­‰ä»·æˆåƒï¼ˆDDEIï¼‰åœ¨é«˜åº¦åŠ é€Ÿçš„åŠ¨æ€å¿ƒè„æˆåƒæ–¹é¢æ˜¾è‘—ä¼˜äºæœ€æ–°æ— ç›‘ç£æ–¹æ³•å¦‚SSDUã€‚æˆ‘ä»¬çš„æ–¹æ³•ä¸åº•å±‚ç¥ç»ç½‘ç»œæ¶æ„æ— å…³ï¼Œå¯ç”¨äºé€‚åº”æœ€æ–°æ¨¡å‹å’ŒåæœŸå¤„ç†æ–¹æ³•ã€‚æˆ‘ä»¬çš„ä»£ç å’Œè§†é¢‘æ¼”ç¤ºå¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/Andrewwango/ddei%E6%9F%A5%E7%9C%8B%E3%80%82">https://github.com/Andrewwango/ddeiæŸ¥çœ‹ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2410.08646v2">PDF</a> Conference paper at ISBI 2025</p>
<p><strong>Summary</strong></p>
<p>ä»æ¬ é‡‡æ ·çš„åŠ é€Ÿæµ‹é‡ä¸­é‡å»ºåŠ¨æ€MRIå›¾åƒåºåˆ—å¯¹äºæ›´å¿«ã€æ›´é«˜æ—¶ç©ºåˆ†è¾¨ç‡çš„å®æ—¶å¿ƒè„è¿åŠ¨æˆåƒã€è‡ªç”±å‘¼å¸è¿åŠ¨æˆåƒä»¥åŠè®¸å¤šå…¶ä»–åº”ç”¨è‡³å…³é‡è¦ã€‚ç°æœ‰çš„æ–¹æ³•å¦‚é—¨æ§ç”µå½±MRIå­˜åœ¨å‘¨æœŸæ€§å‡è®¾ï¼Œæ— æ³•çœŸæ­£æˆåƒã€‚ç”±äºæ— æ³•è·å–åŠ¨æ€æˆåƒçš„çœŸå®åœ°é¢å…¨é‡‡æ ·è§†é¢‘ï¼Œç›‘ç£æ·±åº¦å­¦ä¹ æ–¹æ³•å­˜åœ¨æ ¹æœ¬ç¼ºé™·ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§åˆ©ç”¨MRIè‡ªç„¶å‡ ä½•æ—¶ç©ºç­‰ä»·æ€§çš„æ— ç›‘ç£æ¡†æ¶æ¥é‡å»ºåŠ¨æ€MRIåºåˆ—ã€‚åŠ¨æ€å¾®åˆ†ç­‰ä»·æˆåƒï¼ˆDDEIï¼‰åœ¨é«˜åº¦åŠ é€Ÿçš„åŠ¨æ€å¿ƒè„æˆåƒä¸Šæ˜¾è‘—ä¼˜äºæœ€å…ˆè¿›çš„çŠ¶æ€æ— ç›‘ç£æ–¹æ³•ï¼Œå¦‚SSDUã€‚æˆ‘ä»¬çš„æ–¹æ³•ä¸ä¾èµ–äºåº•å±‚ç¥ç»ç½‘ç»œæ¶æ„ï¼Œå¯ç”¨äºé€‚åº”æœ€æ–°æ¨¡å‹å’ŒåæœŸå¤„ç†æ–¹æ³•ã€‚æˆ‘ä»¬çš„ä»£ç å’Œè§†é¢‘æ¼”ç¤ºå¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/Andrewwango/ddei%E6%9F%A5%E7%9C%8B%E3%80%82">https://github.com/Andrewwango/ddeiæŸ¥çœ‹ã€‚</a></p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>åŠ¨æ€MRIå›¾åƒåºåˆ—é‡å»ºæ˜¯åŠ å¿«å®æ—¶æˆåƒé€Ÿåº¦å’Œæé«˜æ—¶ç©ºåˆ†è¾¨ç‡çš„å…³é”®ã€‚</li>
<li>ä¼ ç»Ÿæ–¹æ³•å­˜åœ¨å‘¨æœŸæ€§å‡è®¾é—®é¢˜ï¼Œæ— æ³•çœŸæ­£æ•æ‰è¿åŠ¨çŠ¶æ€ã€‚</li>
<li>ç”±äºæ— æ³•è·å–çœŸå®çš„åœ°é¢å…¨é‡‡æ ·è§†é¢‘ï¼Œç›‘ç£æ·±åº¦å­¦ä¹ æ–¹æ³•å­˜åœ¨æ ¹æœ¬é—®é¢˜ã€‚</li>
<li>æå‡ºäº†ä¸€ç§æ— ç›‘ç£æ¡†æ¶ï¼Œåˆ©ç”¨MRIçš„è‡ªç„¶å‡ ä½•æ—¶ç©ºç­‰ä»·æ€§è¿›è¡Œé‡å»ºã€‚</li>
<li>åŠ¨æ€å¾®åˆ†ç­‰ä»·æˆåƒï¼ˆDDEIï¼‰åœ¨é«˜åº¦åŠ é€Ÿçš„åŠ¨æ€å¿ƒè„æˆåƒä¸Šè¡¨ç°ä¼˜å¼‚ã€‚</li>
<li>DDEIæ–¹æ³•å…·æœ‰é€šç”¨æ€§ï¼Œä¸ä¾èµ–äºç‰¹å®šçš„ç¥ç»ç½‘ç»œæ¶æ„ï¼Œå¯é€‚åº”æœ€æ–°æ¨¡å‹å’ŒåæœŸå¤„ç†æ–¹æ³•ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2410.08646">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-200761d26c364357d149f355f6d90b6a.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-aed6b48bc99f3f2c2869c8a68ad7e638.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-31d7887549efb95ab073af3720c386b6.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-b9918b3f607e209965ab7ce93ebccf81.jpg" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="Multi-level-Asymmetric-Contrastive-Learning-for-Volumetric-Medical-Image-Segmentation-Pre-training"><a href="#Multi-level-Asymmetric-Contrastive-Learning-for-Volumetric-Medical-Image-Segmentation-Pre-training" class="headerlink" title="Multi-level Asymmetric Contrastive Learning for Volumetric Medical Image   Segmentation Pre-training"></a>Multi-level Asymmetric Contrastive Learning for Volumetric Medical Image   Segmentation Pre-training</h2><p><strong>Authors:Shuang Zeng, Lei Zhu, Xinliang Zhang, Micky C Nnamdi, Wenqi Shi, J Ben Tamo, Qian Chen, Hangzhou He, Lujia Jin, Zifeng Tian, Qiushi Ren, Zhaoheng Xie, Yanye Lu</strong></p>
<p>Medical image segmentation is a fundamental yet challenging task due to the arduous process of acquiring large volumes of high-quality labeled data from experts. Contrastive learning offers a promising but still problematic solution to this dilemma. Firstly existing medical contrastive learning strategies focus on extracting image-level representation, which ignores abundant multi-level representations. Furthermore they underutilize the decoder either by random initialization or separate pre-training from the encoder, thereby neglecting the potential collaboration between the encoder and decoder. To address these issues, we propose a novel multi-level asymmetric contrastive learning framework named MACL for volumetric medical image segmentation pre-training. Specifically, we design an asymmetric contrastive learning structure to pre-train encoder and decoder simultaneously to provide better initialization for segmentation models. Moreover, we develop a multi-level contrastive learning strategy that integrates correspondences across feature-level, image-level, and pixel-level representations to ensure the encoder and decoder capture comprehensive details from representations of varying scales and granularities during the pre-training phase. Finally, experiments on 8 medical image datasets indicate our MACL framework outperforms existing 11 contrastive learning strategies. i.e. Our MACL achieves a superior performance with more precise predictions from visualization figures and 1.72%, 7.87%, 2.49% and 1.48% Dice higher than previous best results on ACDC, MMWHS, HVSMR and CHAOS with 10% labeled data, respectively. And our MACL also has a strong generalization ability among 5 variant U-Net backbones. Our code will be released at <a target="_blank" rel="noopener" href="https://github.com/stevezs315/MACL">https://github.com/stevezs315/MACL</a>. </p>
<blockquote>
<p>åŒ»å­¦å›¾åƒåˆ†å‰²æ˜¯ä¸€é¡¹åŸºç¡€ä¸”å…·æœ‰æŒ‘æˆ˜æ€§çš„ä»»åŠ¡ï¼Œä¸»è¦æ˜¯å› ä¸ºä»ä¸“å®¶é‚£é‡Œè·å–å¤§é‡é«˜è´¨é‡æ ‡è®°æ•°æ®çš„è‰°å·¨è¿‡ç¨‹ã€‚å¯¹æ¯”å­¦ä¹ ä¸ºè§£å†³è¿™ä¸€å›°å¢ƒæä¾›äº†æœ‰å‰æ™¯ä½†ä»æœ‰é—®é¢˜çš„è§£å†³æ–¹æ¡ˆã€‚é¦–å…ˆï¼Œç°æœ‰çš„åŒ»å­¦å¯¹æ¯”å­¦ä¹ ç­–ç•¥ä¾§é‡äºæå–å›¾åƒçº§åˆ«çš„è¡¨ç¤ºï¼Œè¿™å¿½ç•¥äº†ä¸°å¯Œçš„å¤šå±‚æ¬¡è¡¨ç¤ºã€‚æ­¤å¤–ï¼Œå®ƒä»¬å¯¹è§£ç å™¨çš„åˆ©ç”¨ä¸è¶³ï¼Œè¦ä¹ˆæ˜¯é€šè¿‡éšæœºåˆå§‹åŒ–ï¼Œè¦ä¹ˆæ˜¯ç¼–ç å™¨ç‹¬ç«‹è¿›è¡Œé¢„è®­ç»ƒï¼Œä»è€Œå¿½ç•¥äº†ç¼–ç å™¨å’Œè§£ç å™¨ä¹‹é—´çš„æ½œåœ¨åä½œã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åä¸ºMACLçš„æ–°å‹å¤šå±‚æ¬¡ä¸å¯¹ç§°å¯¹æ¯”å­¦ä¹ æ¡†æ¶ï¼Œç”¨äºåŒ»å­¦å›¾åƒåˆ†å‰²çš„é¢„è®­ç»ƒã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬è®¾è®¡äº†ä¸€ç§ä¸å¯¹ç§°å¯¹æ¯”å­¦ä¹ ç»“æ„ï¼Œå¯ä»¥åŒæ—¶å¯¹ç¼–ç å™¨å’Œè§£ç å™¨è¿›è¡Œé¢„è®­ç»ƒï¼Œä¸ºåˆ†å‰²æ¨¡å‹æä¾›æ›´å¥½çš„åˆå§‹åŒ–ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å¼€å‘äº†ä¸€ç§å¤šå±‚æ¬¡å¯¹æ¯”å­¦ä¹ ç­–ç•¥ï¼Œè¯¥ç­–ç•¥ç»“åˆäº†ç‰¹å¾çº§åˆ«ã€å›¾åƒçº§åˆ«å’Œåƒç´ çº§åˆ«è¡¨ç¤ºä¹‹é—´çš„å¯¹åº”å…³ç³»ï¼Œä»¥ç¡®ä¿ç¼–ç å™¨å’Œè§£ç å™¨åœ¨é¢„è®­ç»ƒé˜¶æ®µæ•è·ä¸åŒè§„æ¨¡å’Œç²’åº¦çš„è¡¨ç¤ºä¸­çš„ç»¼åˆç»†èŠ‚ã€‚æœ€åï¼Œåœ¨8ä¸ªåŒ»å­¦å›¾åƒæ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„MACLæ¡†æ¶ä¼˜äºç°æœ‰çš„11ç§å¯¹æ¯”å­¦ä¹ ç­–ç•¥ã€‚ä¾‹å¦‚ï¼Œä½¿ç”¨æˆ‘ä»¬çš„MACLï¼Œå¯è§†åŒ–å›¾é¢„æµ‹æ›´å‡†ç¡®ï¼Œåœ¨ACDCã€MMWHSã€HVSMRå’ŒCHAOSæ•°æ®é›†ä¸Šåˆ†åˆ«æ¯”ä¹‹å‰çš„æœ€ä½³ç»“æœé«˜å‡º1.72%ã€7.87%ã€2.49%å’Œ1.48%ã€‚æˆ‘ä»¬çš„MACLè¿˜å…·æœ‰åœ¨5ç§å˜ä½“U-Netéª¨å¹²ç½‘ä¸­å¼ºå¤§çš„æ³›åŒ–èƒ½åŠ›ã€‚æˆ‘ä»¬çš„ä»£ç å°†åœ¨<a target="_blank" rel="noopener" href="https://github.com/stevezs315/MACL%E4%B8%8A%E5%8F%91%E6%98%BE%E3%80%82">https://github.com/stevezs315/MACLä¸Šå‘å¸ƒã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11876v3">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>åŒ»å­¦å›¾åƒåˆ†å‰²æ˜¯ä¸€é¡¹åŸºç¡€ä¸”å…·æŒ‘æˆ˜æ€§çš„ä»»åŠ¡ï¼Œä¸»è¦ç”±äºè·å–å¤§é‡é«˜è´¨é‡ä¸“å®¶æ ‡æ³¨æ•°æ®çš„å›°éš¾ã€‚å¯¹æ¯”å­¦ä¹ ä¸ºæ­¤æä¾›äº†æœ‰å‰æ™¯çš„è§£å†³æ–¹æ¡ˆï¼Œä½†ç°æœ‰åŒ»å­¦å¯¹æ¯”å­¦ä¹ ç­–ç•¥ä¸»è¦å…³æ³¨å›¾åƒçº§åˆ«çš„è¡¨ç¤ºï¼Œå¿½ç•¥äº†å¤šçº§åˆ«çš„ä¸°å¯Œè¡¨ç¤ºã€‚æ­¤å¤–ï¼Œä»–ä»¬æœªå……åˆ†åˆ©ç”¨è§£ç å™¨ï¼Œæˆ–ä¸ç¼–ç å™¨è¿›è¡Œç‹¬ç«‹é¢„è®­ç»ƒï¼Œå¿½è§†äº†äºŒè€…çš„åä½œæ½œåŠ›ã€‚é’ˆå¯¹è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†åä¸ºMACLçš„ä½“ç§¯åŒ»å­¦å›¾åƒåˆ†å‰²é¢„è®­ç»ƒçš„å¤šçº§åˆ«ä¸å¯¹ç§°å¯¹æ¯”å­¦ä¹ æ¡†æ¶ã€‚æˆ‘ä»¬è®¾è®¡äº†ä¸å¯¹ç§°å¯¹æ¯”å­¦ä¹ ç»“æ„ï¼ŒåŒæ—¶é¢„è®­ç»ƒç¼–ç å™¨å’Œè§£ç å™¨ï¼Œä¸ºåˆ†å‰²æ¨¡å‹æä¾›æ›´å¥½çš„åˆå§‹åŒ–ã€‚åŒæ—¶ï¼Œæˆ‘ä»¬å‘å±•äº†å¤šçº§åˆ«å¯¹æ¯”å­¦ä¹ ç­–ç•¥ï¼Œæ•´åˆç‰¹å¾çº§åˆ«ã€å›¾åƒçº§åˆ«å’Œåƒç´ çº§åˆ«è¡¨ç¤ºçš„å¯¹åº”å…³ç³»ï¼Œç¡®ä¿ç¼–ç å™¨å’Œè§£ç å™¨åœ¨é¢„è®­ç»ƒé˜¶æ®µæ•è·ä¸åŒå°ºåº¦å’Œç²’åº¦çš„ç»¼åˆç»†èŠ‚ã€‚åœ¨8ä¸ªåŒ»å­¦å›¾åƒæ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„MACLæ¡†æ¶ä¼˜äºç°æœ‰çš„11ç§å¯¹æ¯”å­¦ä¹ ç­–ç•¥ï¼Œå…·æœ‰æ›´ç²¾ç¡®é¢„æµ‹å’Œæ›´é«˜çš„Diceç³»æ•°ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>åŒ»å­¦å›¾åƒåˆ†å‰²é¢ä¸´è·å–é«˜è´¨é‡æ ‡æ³¨æ•°æ®çš„æŒ‘æˆ˜ã€‚</li>
<li>ç°æœ‰å¯¹æ¯”å­¦ä¹ ç­–ç•¥ä¸»è¦å…³æ³¨å›¾åƒçº§åˆ«è¡¨ç¤ºï¼Œå¿½ç•¥äº†å¤šçº§åˆ«è¡¨ç¤ºã€‚</li>
<li>MACLæ¡†æ¶é€šè¿‡ä¸å¯¹ç§°å¯¹æ¯”å­¦ä¹ ç»“æ„åŒæ—¶é¢„è®­ç»ƒç¼–ç å™¨å’Œè§£ç å™¨ã€‚</li>
<li>MACLé‡‡ç”¨å¤šçº§åˆ«å¯¹æ¯”å­¦ä¹ ç­–ç•¥ï¼Œæ•´åˆä¸åŒçº§åˆ«çš„è¡¨ç¤ºå¯¹åº”å…³ç³»ã€‚</li>
<li>MACLåœ¨å¤šä¸ªåŒ»å­¦å›¾åƒæ•°æ®é›†ä¸Šè¡¨ç°ä¼˜è¶Šï¼Œå…·æœ‰æ›´é«˜çš„Diceç³»æ•°å’Œæ›´ç²¾ç¡®çš„é¢„æµ‹ã€‚</li>
<li>MACLæ¡†æ¶å…·æœ‰å¼ºå¤§çš„æ³›åŒ–èƒ½åŠ›ï¼Œé€‚ç”¨äºå¤šç§U-Netå˜ä½“ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2309.11876">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-5058068fee7b114a97ac48faa8c10d5e.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-2d9eb742709cda02c2e2ad75df504609.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-1014e9c06cb0bce3ebf5edf73f6c289b.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-4ccec59a98e20bb864e5b8a69ef88467.jpg" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-02-17/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/">https://kedreamix.github.io/Talk2Paper/Paper/2025-02-17/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F/">
                                    <span class="chip bg-color">åŒ»å­¦å›¾åƒ</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-02-17/TTS/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-1dbc1710bb8ddeb575b4e1e95fc116b8.jpg" class="responsive-img" alt="TTS">
                        
                        <span class="card-title">TTS</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            TTS æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-02-17  TokenSynth A Token-based Neural Synthesizer for Instrument Cloning and   Text-to-Instrument
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-02-17
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/TTS/" class="post-category">
                                    TTS
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/TTS/">
                        <span class="chip bg-color">TTS</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-02-15/Diffusion%20Models/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-2dcc09f8fe93c0d9bedcec151c2dae43.jpg" class="responsive-img" alt="Diffusion Models">
                        
                        <span class="card-title">Diffusion Models</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Diffusion Models æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-02-15  Diffusing DeBias a Recipe for Turning a Bug into a Feature
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-02-15
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Diffusion-Models/" class="post-category">
                                    Diffusion Models
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Diffusion-Models/">
                        <span class="chip bg-color">Diffusion Models</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">32714.1k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
