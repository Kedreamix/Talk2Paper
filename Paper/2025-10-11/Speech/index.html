<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Speech">
    <meta name="description" content="Speech æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-10-11  MeanVC Lightweight and Streaming Zero-Shot Voice Conversion via Mean   Flows">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>Speech | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://picx.zhimg.com/v2-5af576cacd857cc23f3a3b763f36df56')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Speech</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/Speech/">
                                <span class="chip bg-color">Speech</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/Speech/" class="post-category">
                                Speech
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-10-11
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-11-21
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    7.6k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    31 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-10-11-æ›´æ–°"><a href="#2025-10-11-æ›´æ–°" class="headerlink" title="2025-10-11 æ›´æ–°"></a>2025-10-11 æ›´æ–°</h1><h2 id="MeanVC-Lightweight-and-Streaming-Zero-Shot-Voice-Conversion-via-Mean-Flows"><a href="#MeanVC-Lightweight-and-Streaming-Zero-Shot-Voice-Conversion-via-Mean-Flows" class="headerlink" title="MeanVC: Lightweight and Streaming Zero-Shot Voice Conversion via Mean   Flows"></a>MeanVC: Lightweight and Streaming Zero-Shot Voice Conversion via Mean   Flows</h2><p><strong>Authors:Guobin Ma, Jixun Yao, Ziqian Ning, Yuepeng Jiang, Lingxin Xiong, Lei Xie, Pengcheng Zhu</strong></p>
<p>Zero-shot voice conversion (VC) aims to transfer timbre from a source speaker to any unseen target speaker while preserving linguistic content. Growing application scenarios demand models with streaming inference capabilities. This has created a pressing need for models that are simultaneously fast, lightweight, and high-fidelity. However, existing streaming methods typically rely on either autoregressive (AR) or non-autoregressive (NAR) frameworks, which either require large parameter sizes to achieve strong performance or struggle to generalize to unseen speakers. In this study, we propose MeanVC, a lightweight and streaming zero-shot VC approach. MeanVC introduces a diffusion transformer with a chunk-wise autoregressive denoising strategy, combining the strengths of both AR and NAR paradigms for efficient streaming processing. By introducing mean flows, MeanVC regresses the average velocity field during training, enabling zero-shot VC with superior speech quality and speaker similarity in a single sampling step by directly mapping from the start to the endpoint of the flow trajectory. Additionally, we incorporate diffusion adversarial post-training to mitigate over-smoothing and further enhance speech quality. Experimental results demonstrate that MeanVC significantly outperforms existing zero-shot streaming VC systems, achieving superior conversion quality with higher efficiency and significantly fewer parameters. Audio demos and code are publicly available at <a target="_blank" rel="noopener" href="https://aslp-lab.github.io/MeanVC">https://aslp-lab.github.io/MeanVC</a>. </p>
<blockquote>
<p>é›¶æ ·æœ¬è¯­éŸ³è½¬æ¢ï¼ˆVCï¼‰æ—¨åœ¨å°†æºè¯´è¯è€…çš„éŸ³è´¨è½¬ç§»åˆ°ä»»ä½•æœªè§è¿‡çš„ç›®æ ‡è¯´è¯è€…ï¼ŒåŒæ—¶ä¿ç•™è¯­è¨€å†…å®¹ã€‚ä¸æ–­å¢é•¿çš„åº”ç”¨åœºæ™¯è¦æ±‚æ¨¡å‹å…·å¤‡æµå¼æ¨ç†èƒ½åŠ›ã€‚è¿™äº§ç”Ÿäº†å¯¹åŒæ—¶å…·å¤‡å¿«é€Ÿã€è½»ä¾¿å’Œé«˜ä¿çœŸæ€§èƒ½çš„æ¨¡å‹çš„è¿«åˆ‡éœ€æ±‚ã€‚ç„¶è€Œï¼Œç°æœ‰çš„æµå¼æ–¹æ³•é€šå¸¸ä¾èµ–äºè‡ªå›å½’ï¼ˆARï¼‰æˆ–éè‡ªå›å½’ï¼ˆNARï¼‰æ¡†æ¶ï¼Œè¿™äº›æ¡†æ¶è¦ä¹ˆéœ€è¦è¾ƒå¤§çš„å‚æ•°è§„æ¨¡ä»¥å®ç°å¼ºåŠ²æ€§èƒ½ï¼Œè¦ä¹ˆåœ¨æ¨å¹¿åˆ°æœªè§è¿‡çš„è¯´è¯è€…æ—¶é¢ä¸´å›°éš¾ã€‚åœ¨è¿™é¡¹ç ”ç©¶ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†MeanVCï¼Œè¿™æ˜¯ä¸€ç§è½»ä¾¿çš„æµå¼é›¶æ ·æœ¬VCæ–¹æ³•ã€‚MeanVCå¼•å…¥äº†ä¸€ä¸ªæ‰©æ•£å˜å‹å™¨ï¼Œé‡‡ç”¨åˆ†å—è‡ªå›å½’å»å™ªç­–ç•¥ï¼Œç»“åˆäº†ARå’ŒNARèŒƒå¼çš„ä¼˜ç‚¹ï¼Œä»¥å®ç°é«˜æ•ˆçš„æµå¼å¤„ç†ã€‚é€šè¿‡å¼•å…¥å¹³å‡æµï¼ŒMeanVCåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å›å½’å¹³å‡é€Ÿåº¦åœºï¼Œä½¿é›¶æ ·æœ¬VCèƒ½å¤Ÿåœ¨å•ä¸ªé‡‡æ ·æ­¥éª¤ä¸­ä»¥å“è¶Šçš„è¯­éŸ³è´¨é‡å’Œè¯´è¯äººç›¸ä¼¼æ€§ç›´æ¥ä»æµçš„èµ·ç‚¹æ˜ å°„åˆ°ç»ˆç‚¹ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å¼•å…¥äº†æ‰©æ•£å¯¹æŠ—åè®­ç»ƒï¼Œä»¥å‡è½»è¿‡åº¦å¹³æ»‘å¹¶è¿›ä¸€æ­¥æ”¹å–„è¯­éŸ³è´¨é‡ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒMeanVCæ˜¾è‘—ä¼˜äºç°æœ‰çš„é›¶æ ·æœ¬æµå¼VCç³»ç»Ÿï¼Œå®ç°äº†é«˜è´¨é‡çš„è½¬æ¢æ€§èƒ½ï¼Œå…·æœ‰æ›´é«˜çš„æ•ˆç‡å’Œæ›´å°‘çš„å‚æ•°ã€‚éŸ³é¢‘æ¼”ç¤ºå’Œä»£ç å¯åœ¨<a target="_blank" rel="noopener" href="https://aslp-lab.github.io/MeanVC%E4%B8%8A%E5%85%AC%E5%BC%80%E6%9F%A5%E7%9C%8B%E3%80%82">https://aslp-lab.github.io/MeanVCä¸Šå…¬å¼€æŸ¥çœ‹ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.08392v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬è®ºæ–‡æå‡ºäº†ä¸€ç§åä¸ºMeanVCçš„è½»é‡çº§æµå¼é›¶æ ·æœ¬è¯­éŸ³è½¬æ¢æ–¹æ³•ã€‚å®ƒç»“åˆäº†è‡ªå›å½’å’Œéè‡ªå›å½’æ¡†æ¶çš„ä¼˜åŠ¿ï¼Œé‡‡ç”¨åŸºäºæ‰©æ•£å˜å‹å™¨çš„å—çº§è‡ªå›å½’å»å™ªç­–ç•¥ï¼Œå®ç°é«˜æ•ˆæµå¼å¤„ç†ã€‚é€šè¿‡å¼•å…¥å¹³å‡æµï¼ŒMeanVCåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å›å½’å¹³å‡é€Ÿåº¦åœºï¼Œå®ç°å•æ­¥é‡‡æ ·ä¸­çš„é›¶æ ·æœ¬è¯­éŸ³è½¬æ¢ï¼Œå…·æœ‰å‡ºè‰²çš„è¯­éŸ³è´¨é‡å’Œè¯´è¯äººç›¸ä¼¼æ€§ã€‚æ­¤å¤–ï¼Œè¿˜é‡‡ç”¨æ‰©æ•£å¯¹æŠ—åè®­ç»ƒæ¥ç¼“è§£è¿‡åº¦å¹³æ»‘é—®é¢˜ï¼Œè¿›ä¸€æ­¥æé«˜è¯­éŸ³è´¨é‡ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒMeanVCåœ¨é›¶æ ·æœ¬æµå¼è¯­éŸ³è½¬æ¢ç³»ç»Ÿä¸­æ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œå…·æœ‰æ›´é«˜çš„è½¬æ¢è´¨é‡ã€æ•ˆç‡å’Œè¾ƒå°‘çš„å‚æ•°ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>MeanVCæ˜¯ä¸€ç§è½»é‡çº§çš„æµå¼é›¶æ ·æœ¬è¯­éŸ³è½¬æ¢æ–¹æ³•ï¼Œç»“åˆäº†è‡ªå›å½’å’Œéè‡ªå›å½’æ¡†æ¶çš„ä¼˜ç‚¹ã€‚</li>
<li>é‡‡ç”¨åŸºäºæ‰©æ•£å˜å‹å™¨çš„å—çº§è‡ªå›å½’å»å™ªç­–ç•¥ï¼Œå®ç°é«˜æ•ˆæµå¼å¤„ç†ã€‚</li>
<li>é€šè¿‡å¼•å…¥å¹³å‡æµï¼ŒMeanVCåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å›å½’å¹³å‡é€Ÿåº¦åœºï¼Œæé«˜äº†è¯­éŸ³è½¬æ¢çš„è´¨é‡å’Œæ•ˆç‡ã€‚</li>
<li>MeanVCå®ç°äº†å•æ­¥é‡‡æ ·ä¸­çš„é›¶æ ·æœ¬è¯­éŸ³è½¬æ¢ï¼Œå…·æœ‰å‡ºè‰²çš„è¯­éŸ³è´¨é‡å’Œè¯´è¯äººç›¸ä¼¼æ€§ã€‚</li>
<li>é‡‡ç”¨æ‰©æ•£å¯¹æŠ—åè®­ç»ƒæŠ€æœ¯ï¼Œç¼“è§£è¯­éŸ³è½¬æ¢ä¸­çš„è¿‡åº¦å¹³æ»‘é—®é¢˜ï¼Œè¿›ä¸€æ­¥æå‡è¯­éŸ³è´¨é‡ã€‚</li>
<li>å®éªŒç»“æœè¡¨æ˜ï¼ŒMeanVCæ˜¾è‘—ä¼˜äºç°æœ‰é›¶æ ·æœ¬æµå¼è¯­éŸ³è½¬æ¢ç³»ç»Ÿã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.08392">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-bb7b63cdb43cc11ffc458c855770cf0f" align="middle">
<img src="https://picx.zhimg.com/v2-d865f80258014398c148c2019b637f1d" align="middle">
<img src="https://picx.zhimg.com/v2-73c8643b72f52625d89444d17e6eade3" align="middle">
<img src="https://picx.zhimg.com/v2-4495f14bffa2c624bea30933ef21c8fa" align="middle">
<img src="https://picx.zhimg.com/v2-55f4367afe0ff7482df2100a68f615e0" align="middle">
<img src="https://picx.zhimg.com/v2-081959126068aa8370148a4dd7005e87" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="CS3-Bench-Evaluating-and-Enhancing-Speech-to-Speech-LLMs-for-Mandarin-English-Code-Switching"><a href="#CS3-Bench-Evaluating-and-Enhancing-Speech-to-Speech-LLMs-for-Mandarin-English-Code-Switching" class="headerlink" title="CS3-Bench: Evaluating and Enhancing Speech-to-Speech LLMs for   Mandarin-English Code-Switching"></a>CS3-Bench: Evaluating and Enhancing Speech-to-Speech LLMs for   Mandarin-English Code-Switching</h2><p><strong>Authors:Heyang Liu, Yuhao Wang, Ziyang Cheng, Ronghua Wu, Qunshan Gu, Yanfeng Wang, Yu Wang</strong></p>
<p>The advancement of multimodal large language models has accelerated the development of speech-to-speech interaction systems. While natural monolingual interaction has been achieved, we find existing models exhibit deficiencies in language alignment. In our proposed Code-Switching Speech-to-Speech Benchmark (CS3-Bench), experiments on 7 mainstream models demonstrate a relative performance drop of up to 66% in knowledge-intensive question answering and varying degrees of misunderstanding in open-ended conversations. Starting from a model with severe performance deterioration, we propose both data constructions and training approaches to improve the language alignment capabilities, specifically employing Chain of Recognition (CoR) to enhance understanding and Keyword Highlighting (KH) to guide generation. Our approach improves the knowledge accuracy from 25.14% to 46.13%, with open-ended understanding rate from 64.5% to 86.5%, and significantly reduces pronunciation errors in the secondary language. CS3-Bench is available at <a target="_blank" rel="noopener" href="https://huggingface.co/datasets/VocalNet/CS3-Bench">https://huggingface.co/datasets/VocalNet/CS3-Bench</a>. </p>
<blockquote>
<p>å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹çš„è¿›æ­¥åŠ é€Ÿäº†è¯­éŸ³åˆ°è¯­éŸ³äº¤äº’ç³»ç»Ÿçš„å‘å±•ã€‚è™½ç„¶è‡ªç„¶å•è¯­äº¤äº’å·²ç»å®ç°ï¼Œä½†æˆ‘ä»¬å‘ç°ç°æœ‰æ¨¡å‹åœ¨è¯­è¨€å¯¹é½æ–¹é¢å­˜åœ¨ç¼ºé™·ã€‚åœ¨æˆ‘ä»¬æå‡ºçš„è·¨è¯­è¨€è¯­éŸ³åˆ°è¯­éŸ³åŸºå‡†æµ‹è¯•ï¼ˆCS3-Benchï¼‰ä¸­ï¼Œå¯¹7ç§ä¸»æµæ¨¡å‹çš„å®éªŒè¡¨æ˜ï¼Œåœ¨çŸ¥è¯†å¯†é›†å‹é—®ç­”æ–¹é¢ï¼Œæ€§èƒ½ç›¸å¯¹ä¸‹é™äº†é«˜è¾¾66%ï¼Œåœ¨å¼€æ”¾å¼å¯¹è¯ä¸­å­˜åœ¨ä¸åŒç¨‹åº¦çš„è¯¯è§£ã€‚é’ˆå¯¹æ€§èƒ½ä¸¥é‡é€€åŒ–çš„æ¨¡å‹ï¼Œæˆ‘ä»¬æå‡ºæ•°æ®æ„å»ºå’Œè®­ç»ƒæ–¹æ³•æ¥æé«˜è¯­è¨€å¯¹é½èƒ½åŠ›ï¼Œå…·ä½“é‡‡ç”¨è¯†åˆ«é“¾ï¼ˆCoRï¼‰å¢å¼ºç†è§£å’Œå…³é”®è¯é«˜äº®ï¼ˆKHï¼‰æ¥æŒ‡å¯¼ç”Ÿæˆã€‚æˆ‘ä»¬çš„æ–¹æ³•å°†çŸ¥è¯†å‡†ç¡®æ€§ä»25.14%æé«˜åˆ°46.13%ï¼Œå¼€æ”¾å¯¹è¯çš„ç†è§£ç‡ä»64.5%æé«˜åˆ°86.5%ï¼Œå¹¶æ˜¾è‘—å‡å°‘äº†ç¬¬äºŒè¯­è¨€çš„å‘éŸ³é”™è¯¯ã€‚CS3-Benchå¯åœ¨<a target="_blank" rel="noopener" href="https://huggingface.co/datasets/VocalNet/CS3-Bench%E8%AE%BF%E9%97%AE%E3%80%82">https://huggingface.co/datasets/VocalNet/CS3-Benchè®¿é—®ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.07881v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>éšç€å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹çš„è¿›æ­¥ï¼Œæ¨åŠ¨äº†è¯­éŸ³åˆ°è¯­éŸ³äº¤äº’ç³»ç»Ÿçš„å‘å±•ã€‚å½“å‰æ¨¡å‹åœ¨è‡ªç„¶å•è¯­äº¤äº’æ–¹é¢å–å¾—äº†è¿›å±•ï¼Œä½†åœ¨è¯­è¨€å¯¹é½æ–¹é¢å­˜åœ¨ç¼ºé™·ã€‚åœ¨æå‡ºçš„è·¨è¯­è¨€è¯­éŸ³åˆ°è¯­éŸ³åŸºå‡†æµ‹è¯•ï¼ˆCS3-Benchï¼‰ä¸­ï¼Œå¯¹7ç§ä¸»æµæ¨¡å‹çš„å®éªŒè¡¨æ˜ï¼Œåœ¨çŸ¥è¯†å¯†é›†å‹é—®ç­”æ–¹é¢æ€§èƒ½ä¸‹é™ç›¸å¯¹é«˜è¾¾66%ï¼Œå¹¶ä¸”åœ¨å¼€æ”¾å¼å¯¹è¯ä¸­å­˜åœ¨ä¸åŒç¨‹åº¦çš„è¯¯è§£ã€‚é€šè¿‡æ•°æ®æ„å»ºå’Œè®­ç»ƒæ–¹æ³•çš„æ”¹è¿›ï¼Œç‰¹åˆ«æ˜¯é‡‡ç”¨è¯†åˆ«é“¾ï¼ˆCoRï¼‰å¢å¼ºç†è§£å’Œå…³é”®è¯é«˜äº®ï¼ˆKHï¼‰å¼•å¯¼ç”Ÿæˆçš„æ–¹æ³•ï¼Œæ”¹å–„äº†è¯­è¨€å¯¹é½èƒ½åŠ›ã€‚è¯¥æ–¹æ³•æé«˜äº†çŸ¥è¯†å‡†ç¡®æ€§ä»25.14%è‡³46.13%ï¼Œå¢å¼ºäº†å¼€æ”¾å¼å¯¹è¯çš„ç†è§£ç‡ä»64.5%è‡³86.5%ï¼Œå¹¶æ˜¾è‘—å‡å°‘äº†æ¬¡è¦è¯­è¨€çš„å‘éŸ³é”™è¯¯ã€‚CS3-BenchåŸºå‡†æµ‹è¯•å¯åœ¨<a target="_blank" rel="noopener" href="https://huggingface.co/datasets/VocalNet/CS3%E4%BD%BF%EFF%ACF%BC%EF%BC%BD%E8%AE%BF%E6%B5%8B%E3%80%82">https://huggingface.co/datasets/VocalNet/CS3-Benchè®¿é—®ã€‚</a></p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹çš„è¿›æ­¥æ¨åŠ¨äº†è¯­éŸ³åˆ°è¯­éŸ³äº¤äº’ç³»ç»Ÿçš„å‘å±•ã€‚</li>
<li>å½“å‰æ¨¡å‹åœ¨è‡ªç„¶å•è¯­äº¤äº’æ–¹é¢å­˜åœ¨æ€§èƒ½æå‡ï¼Œä½†åœ¨è¯­è¨€å¯¹é½æ–¹é¢å­˜åœ¨ç¼ºé™·ã€‚</li>
<li>è·¨è¯­è¨€è¯­éŸ³åˆ°è¯­éŸ³åŸºå‡†æµ‹è¯•ï¼ˆCS3-Benchï¼‰æ­ç¤ºäº†ä¸»æµæ¨¡å‹åœ¨çŸ¥è¯†å¯†é›†å‹é—®ç­”æ–¹é¢çš„æ€§èƒ½ä¸‹é™å’Œå¼€æ”¾å¼å¯¹è¯ä¸­çš„è¯¯è§£é—®é¢˜ã€‚</li>
<li>é€šè¿‡æ•°æ®æ„å»ºå’Œè®­ç»ƒæ–¹æ³•çš„æ”¹è¿›ï¼Œæé«˜äº†è¯­è¨€å¯¹é½èƒ½åŠ›ã€‚</li>
<li>é‡‡ç”¨è¯†åˆ«é“¾ï¼ˆCoRï¼‰å’Œå…³é”®è¯é«˜äº®ï¼ˆKHï¼‰çš„æ–¹æ³•æ”¹å–„äº†è¯­è¨€å¯¹é½ï¼Œæé«˜äº†çŸ¥è¯†å‡†ç¡®æ€§å’Œå¼€æ”¾å¼å¯¹è¯çš„ç†è§£ç‡ã€‚</li>
<li>æå‡ºçš„æ”¹è¿›æ–¹æ³•æ˜¾è‘—å‡å°‘äº†æ¬¡è¦è¯­è¨€çš„å‘éŸ³é”™è¯¯ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.07881">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-91c5eb097bc71ac7c95ab86524cf4482" align="middle">
<img src="https://picx.zhimg.com/v2-2c332ff0a963ee3f25b3b28739d98862" align="middle">
<img src="https://picx.zhimg.com/v2-22791f29fdb650d4fdbeb837c4b0be3c" align="middle">
<img src="https://picx.zhimg.com/v2-4dea7fa61914071e59fb73833c2135fd" align="middle">
<img src="https://picx.zhimg.com/v2-f1478c1b86b1adf4073ed69341dc2ee7" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="A-Multimodal-GUI-Architecture-for-Interfacing-with-LLM-Based-Conversational-Assistants"><a href="#A-Multimodal-GUI-Architecture-for-Interfacing-with-LLM-Based-Conversational-Assistants" class="headerlink" title="A Multimodal GUI Architecture for Interfacing with LLM-Based   Conversational Assistants"></a>A Multimodal GUI Architecture for Interfacing with LLM-Based   Conversational Assistants</h2><p><strong>Authors:Hans G. W. van Dam</strong></p>
<p>Advances in large language models (LLMs) and real-time speech recognition now make it possible to issue any graphical user interface (GUI) action through natural language and receive the corresponding system response directly through the GUI. Most production applications were never designed with speech in mind. This article provides a concrete architecture that enables GUIs to interface with LLM-based speech-enabled assistants.   The architecture makes an applicationâ€™s navigation graph and semantics available through the Model Context Protocol (MCP). The ViewModel, part of the MVVM (Model-View-ViewModel) pattern, exposes the applicationâ€™s capabilities to the assistant by supplying both tools applicable to a currently visible view and application-global tools extracted from the GUI tree router. This architecture facilitates full voice accessibility while ensuring reliable alignment between spoken input and the visual interface, accompanied by consistent feedback across modalities. It future-proofs apps for upcoming OS super assistants that employ computer use agents (CUAs) and natively consume MCP if an application provides it.   To address concerns about privacy and data security, the practical effectiveness of locally deployable, open-weight LLMs for speech-enabled multimodal UIs is evaluated. Findings suggest that recent smaller open-weight models approach the performance of leading proprietary models in overall accuracy and require enterprise-grade hardware for fast responsiveness.   A demo implementation of the proposed architecture can be found at <a target="_blank" rel="noopener" href="https://github.com/hansvdam/langbar">https://github.com/hansvdam/langbar</a> </p>
<blockquote>
<p>éšç€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å’Œå®æ—¶è¯­éŸ³è¯†åˆ«æŠ€æœ¯çš„ä¸æ–­è¿›æ­¥ï¼Œç°åœ¨å¯ä»¥é€šè¿‡è‡ªç„¶è¯­è¨€æ‰§è¡Œä»»ä½•å›¾å½¢ç”¨æˆ·ç•Œé¢ï¼ˆGUIï¼‰æ“ä½œï¼Œå¹¶ç›´æ¥é€šè¿‡GUIæ¥æ”¶ç›¸åº”çš„ç³»ç»Ÿå“åº”ã€‚å¤§å¤šæ•°ç”Ÿäº§åº”ç”¨ç¨‹åºåœ¨è®¾è®¡æ—¶å¹¶æœªè€ƒè™‘è¯­éŸ³åŠŸèƒ½ã€‚æœ¬æ–‡æä¾›äº†ä¸€ä¸ªå…·ä½“çš„æ¶æ„ï¼Œä½¿GUIèƒ½å¤Ÿä¸åŸºäºLLMçš„è¯­éŸ³åŠ©æ‰‹è¿›è¡Œäº¤äº’ã€‚è¯¥æ¶æ„é€šè¿‡æ¨¡å‹ä¸Šä¸‹æ–‡åè®®ï¼ˆMCPï¼‰ä½¿åº”ç”¨ç¨‹åºçš„å¯¼èˆªå›¾å’Œè¯­ä¹‰å¾—ä»¥å‘ˆç°ã€‚ä½œä¸ºMVVMï¼ˆModel-View-ViewModelï¼‰æ¨¡å¼çš„ä¸€éƒ¨åˆ†ï¼ŒViewModelé€šè¿‡æä¾›é€‚ç”¨äºå½“å‰å¯è§è§†å›¾çš„å·¥å…·ä»¥åŠä»GUIæ ‘è·¯ç”±å™¨ä¸­æå–çš„åº”ç”¨ç¨‹åºå…¨å±€å·¥å…·ï¼Œå‘åŠ©æ‰‹å…¬å¼€åº”ç”¨ç¨‹åºçš„åŠŸèƒ½ã€‚æ­¤æ¶æ„å®ç°äº†å…¨é¢çš„è¯­éŸ³è®¿é—®åŠŸèƒ½ï¼ŒåŒæ—¶ç¡®ä¿å£å¤´è¾“å…¥ä¸è§†è§‰ç•Œé¢ä¹‹é—´çš„å¯é å¯¹é½ï¼Œå¹¶æä¾›è·¨æ¨¡å¼çš„æŒç»­åé¦ˆã€‚å®ƒä¸ºå³å°†åˆ°æ¥çš„æ“ä½œç³»ç»Ÿè¶…çº§åŠ©æ‰‹æä¾›äº†ä¿éšœï¼Œè¿™äº›åŠ©æ‰‹ä½¿ç”¨è®¡ç®—æœºä½¿ç”¨ä»£ç†ï¼ˆCUAï¼‰å¹¶åŸç”Ÿæ¶ˆè´¹MCPï¼Œå¦‚æœåº”ç”¨ç¨‹åºæä¾›çš„è¯ã€‚ä¸ºäº†åº”å¯¹å…³äºéšç§å’Œæ•°æ®å®‰å…¨çš„æ‹…å¿§ï¼Œè¯„ä¼°äº†ç”¨äºè¯­éŸ³å¯ç”¨çš„å¤šæ¨¡å¼UIçš„å¯åœ¨æœ¬åœ°éƒ¨ç½²çš„å¼€æ”¾æƒé‡LLMçš„å®é™…æœ‰æ•ˆæ€§ã€‚ç ”ç©¶ç»“æœè¡¨æ˜ï¼Œæœ€è¿‘çš„è¾ƒå°å¼€æ”¾æƒé‡æ¨¡å‹åœ¨æ€»ä½“å‡†ç¡®æ€§æ–¹é¢æ¥è¿‘é¢†å…ˆä¸“æœ‰æ¨¡å‹çš„è¡¨ç°ï¼Œå¹¶éœ€è¦ä¼ä¸šçº§ç¡¬ä»¶æ¥å®ç°å¿«é€Ÿå“åº”ã€‚æ‰€æè®®æ¶æ„çš„æ¼”ç¤ºå®ç°å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/hansvdam/langbar">https://github.com/hansvdam/langbar</a> æ‰¾åˆ°ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.06223v2">PDF</a> 24 pages, 19 figures, code available at   <a target="_blank" rel="noopener" href="https://github.com/hansvdam/langbar">https://github.com/hansvdam/langbar</a></p>
<p><strong>Summary</strong></p>
<p>åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„å®æ—¶è¯­éŸ³è¯†åˆ«æŠ€æœ¯ï¼Œç°åœ¨å¯ä»¥é€šè¿‡è‡ªç„¶è¯­è¨€é©±åŠ¨ä»»ä½•å›¾å½¢ç”¨æˆ·ç•Œé¢ï¼ˆGUIï¼‰çš„è¡ŒåŠ¨ï¼Œå¹¶ç›´æ¥é€šè¿‡GUIè·å–ç³»ç»Ÿå›åº”ã€‚æ–‡ç« æå‡ºäº†ä¸€ç§å…·ä½“æ¶æ„ï¼Œä½¿GUIä¸åŸºäºLLMçš„è¯­éŸ³åŠ©æ‰‹è¿›è¡Œäº¤äº’ã€‚è¯¥æ¶æ„é€šè¿‡æ¨¡å‹ä¸Šä¸‹æ–‡åè®®ï¼ˆMCPï¼‰æä¾›åº”ç”¨ç¨‹åºçš„å¯¼èˆªå›¾å’Œè¯­ä¹‰ã€‚æ–‡ç« è¿˜è¯„ä»·äº†å…³äºéšç§å’Œæ•°æ®å®‰å…¨çš„æ‹…å¿§ï¼Œå¹¶å‘ç°å°å‹å¼€æºæ¨¡å‹åœ¨æ€»ä½“å‡†ç¡®æ€§ä¸Šæ¥è¿‘é¢†å…ˆçš„ä¸“ä¸šæ¨¡å‹ï¼Œä½†éœ€è¦ä¼ä¸šçº§ç¡¬ä»¶æ¥å®ç°å¿«é€Ÿå“åº”ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å’Œå®æ—¶è¯­éŸ³è¯†åˆ«æŠ€æœ¯èåˆï¼Œå¯é€šè¿‡è‡ªç„¶è¯­è¨€æ§åˆ¶GUIï¼Œå¹¶è·å–ç³»ç»Ÿåé¦ˆã€‚</li>
<li>æ–‡ç« ä»‹ç»äº†ä¸€ç§å…·ä½“æ¶æ„ï¼Œè¯¥æ¶æ„é€šè¿‡æ¨¡å‹ä¸Šä¸‹æ–‡åè®®ï¼ˆMCPï¼‰ä½¿GUIä¸åŸºäºLLMçš„è¯­éŸ³åŠ©æ‰‹äº¤äº’ã€‚</li>
<li>ViewModelåœ¨MVVMæ¨¡å¼ä¸­çš„ä½œç”¨æ˜¯å‘è¯­éŸ³åŠ©æ‰‹å±•ç¤ºåº”ç”¨ç¨‹åºçš„åŠŸèƒ½ï¼Œæä¾›å½“å‰è§†å›¾å¯ç”¨çš„å·¥å…·å’Œå…¨å±€å·¥å…·ã€‚</li>
<li>è¯¥æ¶æ„ç¡®ä¿äº†è¯­éŸ³è¾“å…¥ä¸è§†è§‰ç•Œé¢çš„å¯é å¯¹é½ï¼Œå¹¶æä¾›äº†è·¨æ¨¡å¼çš„ä¸€è‡´åé¦ˆã€‚</li>
<li>æ–‡ç« è¿˜è€ƒè™‘äº†éšç§å’Œæ•°æ®å®‰å…¨é—®é¢˜ï¼Œè¯„ä»·äº†æœ¬åœ°éƒ¨ç½²çš„å¼€æºLLMåœ¨è¯­éŸ³èµ‹èƒ½å¤šæ¨¡å¼UIä¸­çš„å®é™…æ•ˆæœã€‚</li>
<li>ç ”ç©¶å‘ç°ï¼Œå°å‹å¼€æºæ¨¡å‹åœ¨æ€»ä½“å‡†ç¡®æ€§ä¸Šè¡¨ç°å‡ºè‰²ï¼Œæ¥è¿‘é¢†å…ˆçš„ä¸“ä¸šæ¨¡å‹ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.06223">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-94b0fea6c6374283db76e8440ee8646b" align="middle">
<img src="https://picx.zhimg.com/v2-6b36e1c34b643a1e0b2931b9238ba0c1" align="middle">
<img src="https://picx.zhimg.com/v2-0d132d84af904ccb013926774fcec1d2" align="middle">
<img src="https://picx.zhimg.com/v2-7f9e3a9496979703fb802c7c56b9e7f1" align="middle">
<img src="https://picx.zhimg.com/v2-4da75ead38342e3dff1d7e47d3cd6603" align="middle">
<img src="https://picx.zhimg.com/v2-2b47d9116f17dbac147cb61397bb9229" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="Audio-Conditioned-Diffusion-LLMs-for-ASR-and-Deliberation-Processing"><a href="#Audio-Conditioned-Diffusion-LLMs-for-ASR-and-Deliberation-Processing" class="headerlink" title="Audio-Conditioned Diffusion LLMs for ASR and Deliberation Processing"></a>Audio-Conditioned Diffusion LLMs for ASR and Deliberation Processing</h2><p><strong>Authors:Mengqi Wang, Zhan Liu, Zengrui Jin, Guangzhi Sun, Chao Zhang, Philip C. Woodland</strong></p>
<p>Diffusion-based large language models (DLLMs) have recently attracted growing interest as an alternative to autoregressive decoders. In this work, we present an empirical study on using the diffusion-based large language model LLaDA for automatic speech recognition (ASR). We first investigate its use as an external deliberation-based processing module for Whisper-LLaMA transcripts. By leveraging the bidirectional attention and denoising capabilities of LLaDA, we explore random masking, low-confidence masking, and semi-autoregressive strategies, showing that Whisper-LLaDA substantially reduces WER compared with the baseline. On LibriSpeech, the best cascade system achieves 2.25%&#x2F;4.94% WER on test-clean&#x2F;test-other, representing a 12.3% relative improvement over the Whisper-LLaMA baseline on the test-other split. In contrast, a plain-text LLaDA without acoustic features fails to improve accuracy, highlighting the importance of audio-conditioned embeddings. We further evaluate Whisper-LLaDA as a standalone decoder for ASR with diffusion-based and semi-autoregressive decoding. Most experimental configurations achieve faster inference than the Whisper-LLaMA baseline, although recognition accuracy is slightly lower. These findings offer an empirical view of diffusion-based LLMs for ASR and point to promising directions for improvements. </p>
<blockquote>
<p>åŸºäºæ‰©æ•£çš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆDLLMsï¼‰æœ€è¿‘ä½œä¸ºè‡ªå›å½’è§£ç å™¨çš„æ›¿ä»£æ–¹æ¡ˆè€Œæ—¥ç›Šå—åˆ°å…³æ³¨ã€‚åœ¨è¿™é¡¹ç ”ç©¶ä¸­ï¼Œæˆ‘ä»¬å¯¹ä½¿ç”¨åŸºäºæ‰©æ•£çš„å¤§å‹è¯­è¨€æ¨¡å‹LLaDAè¿›è¡Œè‡ªåŠ¨è¯­éŸ³è¯†åˆ«ï¼ˆASRï¼‰è¿›è¡Œäº†å®è¯ç ”ç©¶ã€‚æˆ‘ä»¬é¦–å…ˆç ”ç©¶å…¶åœ¨åŸºäºå¤–éƒ¨æ·±æ€å¤„ç†æ¨¡å—çš„Whisper-LLaMAè½¬å½•ä¸­çš„åº”ç”¨ã€‚é€šè¿‡åˆ©ç”¨LLaDAçš„åŒå‘æ³¨æ„åŠ›å’Œå»å™ªèƒ½åŠ›ï¼Œæˆ‘ä»¬æ¢ç´¢äº†éšæœºé®æŒ¡ã€ä½ç½®ä¿¡åº¦é®æŒ¡å’ŒåŠè‡ªå›å½’ç­–ç•¥ï¼Œç»“æœè¡¨æ˜Whisper-LLaDAä¸åŸºçº¿ç›¸æ¯”å¤§å¹…é™ä½äº†WERã€‚åœ¨LibriSpeechä¸Šï¼Œæœ€ä½³çº§è”ç³»ç»Ÿåœ¨æµ‹è¯•å¹²å‡€&#x2F;å…¶ä»–æµ‹è¯•ä¸Šçš„WERè¾¾åˆ°2.25%&#x2F;4.94%ï¼Œç›¸å¯¹äºWhisper-LLaMAåŸºçº¿ï¼Œåœ¨å…¶ä»–æµ‹è¯•åˆ†å‰²ä¸Šå®ç°äº†12.3%çš„ç›¸å¯¹æ”¹è¿›ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼Œæ²¡æœ‰å£°å­¦ç‰¹å¾çš„çº¯æ–‡æœ¬LLaDAæœªèƒ½æé«˜å‡†ç¡®æ€§ï¼Œè¿™å‡¸æ˜¾äº†éŸ³é¢‘æ¡ä»¶åµŒå…¥çš„é‡è¦æ€§ã€‚æˆ‘ä»¬è¿›ä¸€æ­¥è¯„ä¼°äº†ä½œä¸ºç‹¬ç«‹è§£ç å™¨çš„Whisper-LLaDAçš„ASRæ€§èƒ½ï¼Œé‡‡ç”¨æ‰©æ•£å’ŒåŠè‡ªå›å½’è§£ç ã€‚å¤§å¤šæ•°å®éªŒé…ç½®å®ç°äº†æ¯”Whisper-LLaMAåŸºçº¿æ›´å¿«çš„æ¨ç†é€Ÿåº¦ï¼Œå°½ç®¡è¯†åˆ«å‡†ç¡®ç‡ç•¥æœ‰ä¸‹é™ã€‚è¿™äº›å‘ç°ä¸ºåŸºäºæ‰©æ•£çš„LLMåœ¨ASRæ–¹é¢çš„åº”ç”¨æä¾›äº†å®è¯è§‚ç‚¹ï¼Œå¹¶æŒ‡å‡ºäº†æ”¹è¿›çš„æœ‰å¸Œæœ›çš„æ–¹å‘ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.16622v2">PDF</a> </p>
<p><strong>Summary</strong>ï¼šåŸºäºæ‰©æ•£çš„å¤§å‹è¯­è¨€æ¨¡å‹LLaDAåœ¨è‡ªåŠ¨è¯­éŸ³è¯†åˆ«ï¼ˆASRï¼‰ä¸­çš„åº”ç”¨è¿›è¡Œäº†å®è¯ç ”ç©¶ã€‚å°†å…¶ä½œä¸ºWhisper-LLaMAçš„å¤–éƒ¨å†³ç­–å¤„ç†æ¨¡å—ï¼Œåˆ©ç”¨LLaDAçš„åŒå‘æ³¨æ„åŠ›å’Œå»å™ªèƒ½åŠ›ï¼Œé€šè¿‡éšæœºæ©è”½ã€ä½ä¿¡å¿ƒæ©è”½å’ŒåŠè‡ªå›å½’ç­–ç•¥ï¼Œæ˜¾è‘—é™ä½äº†è¯é”™è¯¯ç‡ï¼ˆWERï¼‰ã€‚åœ¨LibriSpeechæ•°æ®é›†ä¸Šï¼Œæœ€ä½³çº§è”ç³»ç»Ÿè¾¾åˆ°äº†test-clean&#x2F;test-otherçš„2.25%&#x2F;4.94% WERï¼Œç›¸å¯¹äºWhisper-LLaMAåŸºçº¿åœ¨test-otheråˆ†å‰²ä¸Šå®ç°äº†12.3%çš„ç›¸å¯¹æ”¹è¿›ã€‚ä½†çº¯æ–‡æœ¬LLaDAåœ¨ä¸ä½¿ç”¨éŸ³é¢‘ç‰¹å¾çš„æƒ…å†µä¸‹æ— æ³•æé«˜å‡†ç¡®æ€§ï¼Œè¿™å¼ºè°ƒäº†éŸ³é¢‘æ¡ä»¶åµŒå…¥çš„é‡è¦æ€§ã€‚æ­¤å¤–ï¼Œè¿˜è¯„ä¼°äº†Whisper-LLaDAä½œä¸ºASRçš„ç‹¬ç«‹è§£ç å™¨çš„è¡¨ç°ï¼Œå¤§å¤šæ•°å®éªŒé…ç½®å®ç°äº†æ¯”Whisper-LLaMAåŸºçº¿æ›´å¿«çš„æ¨ç†é€Ÿåº¦ï¼Œå°½ç®¡è¯†åˆ«å‡†ç¡®ç‡ç•¥æœ‰ä¸‹é™ã€‚</p>
<p><strong>Key Takeaways</strong>:</p>
<ol>
<li>åŸºäºæ‰©æ•£çš„å¤§å‹è¯­è¨€æ¨¡å‹LLaDAè¢«ç”¨äºè‡ªåŠ¨è¯­éŸ³è¯†åˆ«ï¼ˆASRï¼‰çš„å®è¯ç ”ç©¶ä¸­ã€‚</li>
<li>LLaDAä½œä¸ºWhisper-LLaMAçš„å¤–éƒ¨å¤„ç†æ¨¡å—ï¼Œé€šè¿‡ç‰¹å®šç­–ç•¥æ˜¾è‘—é™ä½äº†è¯é”™è¯¯ç‡ï¼ˆWERï¼‰ã€‚</li>
<li>åœ¨LibriSpeechæ•°æ®é›†ä¸Šï¼Œçº§è”ç³»ç»Ÿçš„è¡¨ç°ä¼˜äºåŸºçº¿ï¼Œç‰¹åˆ«æ˜¯åœ¨test-otheråˆ†å‰²ä¸Šå®ç°äº†ç›¸å¯¹æ”¹è¿›ã€‚</li>
<li>çº¯æ–‡æœ¬LLaDAåœ¨ä¸ä½¿ç”¨éŸ³é¢‘ç‰¹å¾æ—¶æ— æ³•æé«˜å‡†ç¡®æ€§ï¼Œå¼ºè°ƒéŸ³é¢‘æ¡ä»¶åµŒå…¥çš„é‡è¦æ€§ã€‚</li>
<li>Whisper-LLaDAä½œä¸ºç‹¬ç«‹è§£ç å™¨åœ¨ASRä¸­çš„è¡¨ç°è¢«è¯„ä¼°ï¼Œå¤šæ•°é…ç½®å®ç°å¿«é€Ÿæ¨ç†ï¼Œä½†è¯†åˆ«å‡†ç¡®ç‡ç•¥æœ‰ä¸‹é™ã€‚</li>
<li>å®è¯ç ”ç©¶æä¾›äº†å…³äºæ‰©æ•£åŸºç¡€å¤§å‹è¯­è¨€æ¨¡å‹åœ¨ASRä¸­åº”ç”¨çš„è§è§£ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.16622">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-6bf0a5840a3c3afdeb483b56919d55e2" align="middle">
<img src="https://picx.zhimg.com/v2-7bea0571c1b4ce01ff63f098d63dac62" align="middle">
<img src="https://picx.zhimg.com/v2-5af576cacd857cc23f3a3b763f36df56" align="middle">
<img src="https://picx.zhimg.com/v2-e05e8329ebf3f8b915e8b152ce16eec2" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="I-2-RF-TFCKD-Intra-Inter-Representation-Fusion-with-Time-Frequency-Calibration-Knowledge-Distillation-for-Speech-Enhancement"><a href="#I-2-RF-TFCKD-Intra-Inter-Representation-Fusion-with-Time-Frequency-Calibration-Knowledge-Distillation-for-Speech-Enhancement" class="headerlink" title="I$^2$RF-TFCKD: Intra-Inter Representation Fusion with Time-Frequency   Calibration Knowledge Distillation for Speech Enhancement"></a>I$^2$RF-TFCKD: Intra-Inter Representation Fusion with Time-Frequency   Calibration Knowledge Distillation for Speech Enhancement</h2><p><strong>Authors:Jiaming Cheng, Ruiyu Liang, Ye Ni, Chao Xu, Jing Li, Wei Zhou, Rui Liu, BjÃ¶rn W. Schuller, Xiaoshuai Hao</strong></p>
<p>In this paper, we propose an intra-inter representation fusion knowledge distillation (KD) framework with time-frequency calibration (I$^2$RF-TFCKD) for SE, which achieves distillation through the fusion of multi-layer teacher-student feature flows. Different from previous distillation strategies for SE, the proposed framework fully utilizes the time-frequency differential information of speech while promoting global knowledge flow. Firstly, we construct a collaborative distillation paradigm for intra-set and inter-set correlations. Within a correlated set, multi-layer teacher-student features are pairwise matched for calibrated distillation. Subsequently, we generate representative features from each correlated set through residual fusion to form the fused feature set that enables inter-set knowledge interaction. Secondly, we propose a multi-layer interactive distillation based on dual-stream time-frequency cross-calibration, which calculates the teacher-student similarity calibration weights in the time and frequency domains respectively and performs cross-weighting, thus enabling refined allocation of distillation contributions across different layers according to speech characteristics. The proposed distillation strategy is applied to the dual-path dilated convolutional recurrent network (DPDCRN) that ranked first in the SE track of the L3DAS23 challenge. To evaluate the effectiveness of I$^2$RF-TFCKD, we conduct experiments on both single-channel and multi-channel SE datasets. Objective evaluations demonstrate that the proposed KD strategy consistently and effectively improves the performance of the low-complexity student model and outperforms other distillation schemes. </p>
<blockquote>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºæ—¶é—´é¢‘ç‡æ ¡å‡†çš„å†…å¤–è¡¨ç¤ºèåˆçŸ¥è¯†è’¸é¦ï¼ˆKDï¼‰æ¡†æ¶ï¼ˆç§°ä¸ºI$^2$RF-TFCKDï¼‰ï¼Œç”¨äºSEã€‚è¯¥æ¡†æ¶é€šè¿‡èåˆå¤šå±‚æ•™å¸ˆå­¦ç”Ÿç‰¹å¾æµæ¥å®ç°è’¸é¦ã€‚ä¸åŒäºä»¥å‰çš„SEè’¸é¦ç­–ç•¥ï¼Œè¯¥æ¡†æ¶å……åˆ†åˆ©ç”¨è¯­éŸ³çš„æ—¶é—´é¢‘ç‡å·®å¼‚ä¿¡æ¯ï¼ŒåŒæ—¶ä¿ƒè¿›å…¨å±€çŸ¥è¯†æµã€‚é¦–å…ˆï¼Œæˆ‘ä»¬ä¸ºé›†åˆå†…éƒ¨å’Œé›†åˆä¹‹é—´çš„ç›¸å…³æ€§æ„å»ºäº†ä¸€ç§åä½œè’¸é¦æ¨¡å¼ã€‚åœ¨ç›¸å…³é›†åˆå†…ï¼Œå¤šå±‚æ•™å¸ˆå­¦ç”Ÿç‰¹å¾è¿›è¡Œé…å¯¹æ ¡å‡†è’¸é¦ã€‚ç„¶åï¼Œæˆ‘ä»¬é€šè¿‡æ®‹å·®èåˆç”Ÿæˆæ¯ä¸ªç›¸å…³é›†åˆçš„ä»£è¡¨ç‰¹å¾ï¼Œå½¢æˆèåˆç‰¹å¾é›†ï¼Œä»¥å®ç°é›†åˆé—´çš„çŸ¥è¯†äº¤äº’ã€‚å…¶æ¬¡ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åŸºäºåŒæµæ—¶é—´é¢‘ç‡äº¤å‰æ ¡å‡†çš„å¤šå±‚äº¤äº’è’¸é¦æ–¹æ³•ï¼Œè¯¥æ–¹æ³•åˆ†åˆ«è®¡ç®—æ•™å¸ˆå’Œå­¦ç”Ÿåœ¨æ—¶é—´å’Œé¢‘ç‡åŸŸä¸­çš„ç›¸ä¼¼åº¦æ ¡å‡†æƒé‡ï¼Œå¹¶è¿›è¡Œäº¤å‰åŠ æƒï¼Œä»è€Œèƒ½å¤Ÿæ ¹æ®è¯­éŸ³ç‰¹å¾åœ¨ä¸åŒçš„å±‚æ¬¡ä¸Šç²¾ç»†åˆ†é…è’¸é¦è´¡çŒ®ã€‚æ‰€æå‡ºçš„è’¸é¦ç­–ç•¥åº”ç”¨äºåŒè·¯å¾„æ‰©å¼ å·ç§¯å¾ªç¯ç½‘ç»œï¼ˆDPDCRNï¼‰ï¼Œåœ¨L3DAS23æŒ‘æˆ˜çš„SEèµ›é“ä¸Šæ’åç¬¬ä¸€ã€‚ä¸ºäº†è¯„ä¼°I$^2$RF-TFCKDçš„æœ‰æ•ˆæ€§ï¼Œæˆ‘ä»¬åœ¨å•é€šé“å’Œå¤šé€šé“SEæ•°æ®é›†ä¸Šè¿›è¡Œäº†å®éªŒã€‚å®¢è§‚è¯„ä¼°è¡¨æ˜ï¼Œæ‰€æå‡ºçš„çŸ¥è¯†è’¸é¦ç­–ç•¥æŒç»­æœ‰æ•ˆåœ°æé«˜äº†ä½å¤æ‚åº¦å­¦ç”Ÿæ¨¡å‹çš„æ€§èƒ½ï¼Œå¹¶ä¼˜äºå…¶ä»–è’¸é¦æ–¹æ¡ˆã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2506.13127v2">PDF</a> submitted to Information Fusion</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºæ—¶é—´é¢‘ç‡æ ¡å‡†çš„è·¨å†…å¤–è¡¨ç¤ºèåˆçŸ¥è¯†è’¸é¦ï¼ˆI$^2$RF-TFCKDï¼‰æ¡†æ¶ï¼Œç”¨äºè¯­éŸ³å¢å¼ºï¼ˆSEï¼‰ã€‚è¯¥æ¡†æ¶é€šè¿‡å¤šå±‚æ•™å¸ˆ-å­¦ç”Ÿç‰¹å¾æµçš„èåˆå®ç°è’¸é¦ã€‚ä¸ä»¥å¾€çš„SEè’¸é¦ç­–ç•¥ä¸åŒï¼Œè¯¥æ¡†æ¶å……åˆ†åˆ©ç”¨è¯­éŸ³çš„æ—¶é—´é¢‘ç‡å·®å¼‚ä¿¡æ¯ï¼Œå¹¶ä¿ƒè¿›å…¨å±€çŸ¥è¯†æµåŠ¨ã€‚å®éªŒè¡¨æ˜ï¼Œè¯¥è’¸é¦ç­–ç•¥åœ¨å•é€šé“å’Œå¤šé€šé“SEæ•°æ®é›†ä¸Šå‡è¡¨ç°ä¼˜ç§€ï¼Œæœ‰æ•ˆæå‡äº†ä½å¤æ‚åº¦å­¦ç”Ÿæ¨¡å‹çš„æ€§èƒ½å¹¶ä¼˜äºå…¶ä»–è’¸é¦æ–¹æ¡ˆã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æå‡ºäº†åŸºäºæ—¶é—´é¢‘ç‡æ ¡å‡†çš„è·¨å†…å¤–è¡¨ç¤ºèåˆçŸ¥è¯†è’¸é¦ï¼ˆI$^2$RF-TFCKDï¼‰æ¡†æ¶ã€‚</li>
<li>è¯¥æ¡†æ¶èåˆå¤šå±‚æ•™å¸ˆ-å­¦ç”Ÿç‰¹å¾æµï¼Œå®ç°è¯­éŸ³å¢å¼ºï¼ˆSEï¼‰ä¸­çš„è’¸é¦ã€‚</li>
<li>å……åˆ†åˆ©ç”¨è¯­éŸ³çš„æ—¶é—´é¢‘ç‡å·®å¼‚ä¿¡æ¯ï¼Œä¿ƒè¿›å…¨å±€çŸ¥è¯†æµåŠ¨ã€‚</li>
<li>æ„å»ºäº†ååŒè’¸é¦èŒƒå¼ï¼Œå®ç°æ•°æ®é›†å†…éƒ¨çš„è·¨é›†å’Œå†…éƒ¨ç‰¹å¾åŒ¹é…ã€‚</li>
<li>é€šè¿‡å‰©ä½™èåˆç”Ÿæˆä»£è¡¨æ€§ç‰¹å¾ï¼Œå®ç°è·¨é›†çŸ¥è¯†äº¤äº’ã€‚</li>
<li>æå‡ºäº†åŸºäºåŒæµæ—¶é—´é¢‘ç‡äº¤å‰æ ¡å‡†çš„å¤šå±‚äº¤äº’è’¸é¦æ–¹æ³•ï¼Œæ ¹æ®è¯­éŸ³ç‰¹æ€§è¿›è¡Œä¸åŒå±‚çš„ç²¾ç‚¼åˆ†é…ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2506.13127">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-f0caac560be936413123a81980e453e2" align="middle">
<img src="https://picx.zhimg.com/v2-c2d6801afb558cd29fbe90509e98ce5d" align="middle">
<img src="https://picx.zhimg.com/v2-584eeaa8eb21d95f748e4113ab0669e9" align="middle">
<img src="https://picx.zhimg.com/v2-f462dfc08ddec06bd3ffdb61fa2f06d8" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="SeamlessEdit-Background-Noise-Aware-Zero-Shot-Speech-Editing-with-in-Context-Enhancement"><a href="#SeamlessEdit-Background-Noise-Aware-Zero-Shot-Speech-Editing-with-in-Context-Enhancement" class="headerlink" title="SeamlessEdit: Background Noise Aware Zero-Shot Speech Editing with   in-Context Enhancement"></a>SeamlessEdit: Background Noise Aware Zero-Shot Speech Editing with   in-Context Enhancement</h2><p><strong>Authors:Kuan-Yu Chen, Jeng-Lin Li, Jian-Jiun Ding</strong></p>
<p>With the fast development of zero-shot text-to-speech technologies, it is possible to generate high-quality speech signals that are indistinguishable from the real ones. Speech editing, including speech insertion and replacement, appeals to researchers due to its potential applications. However, existing studies only considered clean speech scenarios. In real-world applications, the existence of environmental noise could significantly degrade the quality of generation. In this study, we propose a noise-resilient speech editing framework, SeamlessEdit, for noisy speech editing. SeamlessEdit adopts a frequency-band-aware noise suppression module and an in-content refinement strategy. It can well address the scenario where the frequency bands of voice and background noise are not separated. The proposed SeamlessEdit framework outperforms state-of-the-art approaches in multiple quantitative and qualitative evaluations. </p>
<blockquote>
<p>éšç€é›¶æ–‡æœ¬è½¬è¯­éŸ³æŠ€æœ¯çš„å¿«é€Ÿå‘å±•ï¼Œç”Ÿæˆé«˜è´¨é‡ã€éš¾ä»¥ä¸çœŸå®è¯­éŸ³åŒºåˆ†çš„è¯­éŸ³ä¿¡å·æˆä¸ºå¯èƒ½ã€‚è¯­éŸ³ç¼–è¾‘ï¼ŒåŒ…æ‹¬è¯­éŸ³æ’å…¥å’Œæ›¿æ¢ï¼Œç”±äºå…¶æ½œåœ¨çš„åº”ç”¨ä»·å€¼è€Œå¸å¼•äº†ç ”ç©¶äººå‘˜çš„å…³æ³¨ã€‚ç„¶è€Œï¼Œç°æœ‰ç ”ç©¶ä»…æ¶‰åŠå¹²å‡€è¯­éŸ³åœºæ™¯ã€‚åœ¨çœŸå®ä¸–ç•Œåº”ç”¨ä¸­ï¼Œç¯å¢ƒå™ªå£°çš„å­˜åœ¨å¯èƒ½ä¼šæ˜¾è‘—é™ä½ç”Ÿæˆè¯­éŸ³çš„è´¨é‡ã€‚æœ¬ç ”ç©¶æå‡ºäº†ä¸€ç§ç”¨äºå™ªå£°è¯­éŸ³ç¼–è¾‘çš„é²æ£’æ€§è¯­éŸ³ç¼–è¾‘æ¡†æ¶SeamlessEditã€‚SeamlessEdité‡‡ç”¨é¢‘å¸¦æ„ŸçŸ¥å™ªå£°æŠ‘åˆ¶æ¨¡å—å’Œå†…å®¹å†…ä¼˜åŒ–ç­–ç•¥ï¼Œèƒ½å¤Ÿå¾ˆå¥½åœ°å¤„ç†è¯­éŸ³å’ŒèƒŒæ™¯å™ªå£°é¢‘ç‡å¸¦æœªåˆ†ç¦»çš„åœºæ™¯ã€‚æ‰€æå‡ºçš„SeamlessEditæ¡†æ¶åœ¨å¤šä¸ªå®šé‡å’Œå®šæ€§è¯„ä¼°ä¸­å‡ä¼˜äºæœ€æ–°æŠ€æœ¯æ–¹æ³•ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2505.14066v2">PDF</a> 5 pages, 3 figures</p>
<p><strong>Summary</strong><br>     éšç€é›¶æ ·æœ¬æ–‡æœ¬è½¬è¯­éŸ³æŠ€æœ¯çš„å¿«é€Ÿå‘å±•ï¼Œç”Ÿæˆé«˜è´¨é‡ã€éš¾ä»¥åŒºåˆ†çœŸå‡çš„è¯­éŸ³ä¿¡å·æˆä¸ºå¯èƒ½ã€‚è¯­éŸ³ç¼–è¾‘ï¼ŒåŒ…æ‹¬è¯­éŸ³æ’å…¥å’Œæ›¿æ¢ï¼Œå› å…¶åœ¨å„ç§åº”ç”¨åœºæ™¯ä¸­çš„æ½œåŠ›è€Œå—åˆ°ç ”ç©¶äººå‘˜çš„å…³æ³¨ã€‚ç„¶è€Œï¼Œç°æœ‰ç ”ç©¶ä¸»è¦é›†ä¸­åœ¨å¹²å‡€è¯­éŸ³åœºæ™¯ã€‚å®é™…åº”ç”¨ä¸­ï¼Œç¯å¢ƒå™ªå£°çš„å­˜åœ¨ä¼šæ˜¾è‘—å½±å“ç”Ÿæˆè¯­éŸ³çš„è´¨é‡ã€‚æœ¬ç ”ç©¶æå‡ºä¸€ç§ç”¨äºå™ªå£°è¯­éŸ³ç¼–è¾‘çš„ç¨³å¥æ¡†æ¶SeamlessEditï¼Œé‡‡ç”¨é¢‘å¸¦æ„ŸçŸ¥å™ªå£°æŠ‘åˆ¶æ¨¡å—å’Œå†…å®¹å†…ä¼˜åŒ–ç­–ç•¥ï¼Œèƒ½å¤Ÿå¾ˆå¥½åœ°å¤„ç†è¯­éŸ³å’ŒèƒŒæ™¯å™ªå£°é¢‘å¸¦ä¸åˆ†ç¦»çš„åœºæ™¯ã€‚SeamlessEditæ¡†æ¶åœ¨å¤šé¡¹å®šé‡å’Œå®šæ€§è¯„ä¼°ä¸­ä¼˜äºç°æœ‰å…ˆè¿›æŠ€æœ¯ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>é›¶æ ·æœ¬æ–‡æœ¬è½¬è¯­éŸ³æŠ€æœ¯å¿«é€Ÿå‘å±•ï¼Œå¯ç”Ÿæˆé«˜è´¨é‡éš¾ä»¥åŒºåˆ†çœŸå‡çš„è¯­éŸ³ä¿¡å·ã€‚</li>
<li>è¯­éŸ³ç¼–è¾‘å…·æœ‰æ½œåœ¨åº”ç”¨ä»·å€¼ï¼ŒåŒ…æ‹¬è¯­éŸ³æ’å…¥å’Œæ›¿æ¢ã€‚</li>
<li>ç°æœ‰ç ”ç©¶ä¸»è¦é›†ä¸­åœ¨å¹²å‡€è¯­éŸ³åœºæ™¯ï¼Œå¿½ç•¥ç¯å¢ƒå™ªå£°çš„å½±å“ã€‚</li>
<li>æœ¬ç ”ç©¶æå‡ºä¸€ç§ç”¨äºå™ªå£°è¯­éŸ³ç¼–è¾‘çš„SeamlessEditæ¡†æ¶ã€‚</li>
<li>SeamlessEdité‡‡ç”¨é¢‘å¸¦æ„ŸçŸ¥å™ªå£°æŠ‘åˆ¶æ¨¡å—å’Œå†…å®¹å†…ä¼˜åŒ–ç­–ç•¥ã€‚</li>
<li>SeamlessEditèƒ½å¤„ç†è¯­éŸ³å’ŒèƒŒæ™¯å™ªå£°é¢‘å¸¦ä¸åˆ†ç¦»çš„åœºæ™¯ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2505.14066">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-658b2cb3d588143d2131de1d0968c722" align="middle">
<img src="https://picx.zhimg.com/v2-33686396df5a918b34909ee013ebfbd0" align="middle">
<img src="https://picx.zhimg.com/v2-f9ec921c8018ee782a66f35be031746a" align="middle">
<img src="https://picx.zhimg.com/v2-a16c006506bf688ae62498df841d00c2" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="A-Differentiable-Alignment-Framework-for-Sequence-to-Sequence-Modeling-via-Optimal-Transport"><a href="#A-Differentiable-Alignment-Framework-for-Sequence-to-Sequence-Modeling-via-Optimal-Transport" class="headerlink" title="A Differentiable Alignment Framework for Sequence-to-Sequence Modeling   via Optimal Transport"></a>A Differentiable Alignment Framework for Sequence-to-Sequence Modeling   via Optimal Transport</h2><p><strong>Authors:Yacouba Kaloga, Shashi Kumar, Petr Motlicek, Ina Kodrasi</strong></p>
<p>Accurate sequence-to-sequence (seq2seq) alignment is critical for applications like medical speech analysis and language learning tools relying on automatic speech recognition (ASR). State-of-the-art end-to-end (E2E) ASR systems, such as the Connectionist Temporal Classification (CTC) and transducer-based models, suffer from peaky behavior and alignment inaccuracies. In this paper, we propose a novel differentiable alignment framework based on one-dimensional optimal transport, enabling the model to learn a single alignment and perform ASR in an E2E manner. We introduce a pseudo-metric, called Sequence Optimal Transport Distance (SOTD), over the sequence space and discuss its theoretical properties. Based on the SOTD, we propose Optimal Temporal Transport Classification (OTTC) loss for ASR and contrast its behavior with CTC. Experimental results on the TIMIT, AMI, and LibriSpeech datasets show that our method considerably improves alignment performance compared to CTC and the more recently proposed Consistency-Regularized CTC, though with a trade-off in ASR performance. We believe this work opens new avenues for seq2seq alignment research, providing a solid foundation for further exploration and development within the community. </p>
<blockquote>
<p>ç²¾ç¡®åºåˆ—åˆ°åºåˆ—ï¼ˆseq2seqï¼‰å¯¹é½å¯¹äºä¾èµ–è‡ªåŠ¨è¯­éŸ³è¯†åˆ«ï¼ˆASRï¼‰çš„åŒ»ç–—è¯­éŸ³åˆ†æå’Œè¯­è¨€å­¦ä¹ å·¥å…·ç­‰åº”ç”¨è‡³å…³é‡è¦ã€‚ç›®å‰æœ€å…ˆè¿›çš„ç«¯åˆ°ç«¯ï¼ˆE2Eï¼‰ASRç³»ç»Ÿï¼Œå¦‚è¿æ¥æ—¶åºåˆ†ç±»ï¼ˆCTCï¼‰å’ŒåŸºäºè½¬æ¢å™¨æ¨¡å‹çš„ï¼Œéƒ½å­˜åœ¨å³°å€¼è¡Œä¸ºå’Œå¯¹é½ä¸å‡†ç¡®çš„é—®é¢˜ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åŸºäºä¸€ç»´æœ€ä¼˜ä¼ è¾“çš„æ–°å‹å¯åŒºåˆ†å¯¹é½æ¡†æ¶ï¼Œä½¿æ¨¡å‹èƒ½å¤Ÿä»¥ç«¯åˆ°ç«¯çš„æ–¹å¼è¿›è¡Œå•ä¸€å¯¹é½å¹¶æ‰§è¡ŒASRã€‚æˆ‘ä»¬å¼•å…¥äº†åºåˆ—æœ€ä¼˜ä¼ è¾“è·ç¦»ï¼ˆSOTDï¼‰çš„ä¼ªåº¦é‡ï¼Œå¹¶è®¨è®ºäº†å…¶ç†è®ºå±æ€§ã€‚åŸºäºSOTDï¼Œæˆ‘ä»¬æå‡ºäº†ç”¨äºASRçš„æœ€ä¼˜æ—¶åºä¼ è¾“åˆ†ç±»ï¼ˆOTTCï¼‰æŸå¤±ï¼Œå¹¶å°†å…¶è¡Œä¸ºä¸CTCè¿›è¡Œäº†å¯¹æ¯”ã€‚åœ¨TIMITã€AMIå’ŒLibriSpeechæ•°æ®é›†ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨æ”¹è¿›å¯¹é½æ€§èƒ½æ–¹é¢ä¸CTCå’Œæœ€è¿‘æå‡ºçš„ä¸€è‡´æ€§æ­£åˆ™åŒ–CTCç›¸æ¯”å…·æœ‰æ˜¾è‘—ä¼˜åŠ¿ï¼Œå°½ç®¡ASRæ€§èƒ½å­˜åœ¨æƒè¡¡ã€‚æˆ‘ä»¬ç›¸ä¿¡è¿™é¡¹å·¥ä½œå¼€è¾Ÿäº†seq2seqå¯¹é½ç ”ç©¶çš„æ–°é€”å¾„ï¼Œä¸ºç¤¾åŒºå†…çš„è¿›ä¸€æ­¥æ¢ç´¢å’Œå‘å±•æä¾›äº†åšå®çš„åŸºç¡€ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2502.01588v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºä¸€ç»´æœ€ä¼˜ä¼ è¾“çš„å¯å¾®æ’åˆ—æ¡†æ¶ï¼Œç”¨äºè§£å†³åºåˆ—åˆ°åºåˆ—ï¼ˆseq2seqï¼‰å¯¹é½é—®é¢˜ï¼Œå¦‚åŒ»ç–—è¯­éŸ³åˆ†æå’Œä¾èµ–è‡ªåŠ¨è¯­éŸ³è¯†åˆ«ï¼ˆASRï¼‰çš„è¯­è¨€å­¦ä¹ å·¥å…·ä¸­çš„å¯¹é½é—®é¢˜ã€‚ä¼ ç»Ÿç«¯åˆ°ç«¯ï¼ˆE2Eï¼‰ASRç³»ç»Ÿå¦‚è¿æ¥å®šæ—¶åˆ†ç±»ï¼ˆCTCï¼‰å’ŒåŸºäºè½¬æ¢å™¨æ¨¡å‹å­˜åœ¨å°–å³°è¡Œä¸ºå’Œæ’åˆ—ä¸ç²¾ç¡®çš„é—®é¢˜ã€‚æœ¬æ–‡å¼•å…¥äº†ä¸€ç§åºåˆ—æœ€ä¼˜ä¼ è¾“è·ç¦»ï¼ˆSOTDï¼‰çš„ä¼ªåº¦é‡ï¼Œå¹¶åŸºäºSOTDæå‡ºäº†æœ€ä¼˜æ—¶é—´ä¼ è¾“åˆ†ç±»ï¼ˆOTTCï¼‰æŸå¤±å‡½æ•°ç”¨äºASRã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œä¸CTCå’Œæœ€è¿‘æå‡ºçš„ä¸€è‡´æ€§æ­£åˆ™åŒ–CTCç›¸æ¯”ï¼Œè¯¥æ–¹æ³•åœ¨TIMITã€AMIå’ŒLibriSpeechæ•°æ®é›†ä¸Šçš„å¯¹é½æ€§èƒ½æœ‰äº†æ˜¾è‘—æé«˜ï¼Œå°½ç®¡ASRæ€§èƒ½å­˜åœ¨æƒè¡¡ã€‚æœ¬æ–‡å·¥ä½œå¼€åˆ›äº†seq2seqå¯¹é½ç ”ç©¶çš„æ–°é€”å¾„ï¼Œä¸ºç¤¾åŒºå†…çš„è¿›ä¸€æ­¥æ¢ç´¢å’Œå‘å±•æä¾›äº†åšå®çš„åŸºç¡€ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å‡†ç¡®åºåˆ—åˆ°åºåˆ—å¯¹é½å¯¹äºä¾èµ–è‡ªåŠ¨è¯­éŸ³è¯†åˆ«ï¼ˆASRï¼‰çš„åº”ç”¨è‡³å…³é‡è¦ï¼Œå¦‚åŒ»ç–—è¯­éŸ³åˆ†æå’Œè¯­è¨€å­¦ä¹ å·¥å…·ã€‚</li>
<li>å½“å‰ç«¯åˆ°ç«¯ï¼ˆE2Eï¼‰ASRç³»ç»Ÿå­˜åœ¨å°–å³°è¡Œä¸ºå’Œæ’åˆ—ä¸ç²¾ç¡®çš„é—®é¢˜ã€‚</li>
<li>å¼•å…¥äº†ä¸€ç§åŸºäºä¸€ç»´æœ€ä¼˜ä¼ è¾“çš„å¯å¾®æ’åˆ—æ¡†æ¶ï¼Œè§£å†³äº†seq2seqå¯¹é½é—®é¢˜ã€‚</li>
<li>æå‡ºäº†åºåˆ—æœ€ä¼˜ä¼ è¾“è·ç¦»ï¼ˆSOTDï¼‰çš„ä¼ªåº¦é‡ï¼Œå¹¶åŸºäºSOTDæ„å»ºäº†Optimal Temporal Transport Classificationï¼ˆOTTCï¼‰æŸå¤±å‡½æ•°ç”¨äºASRã€‚</li>
<li>å®éªŒç»“æœè¡¨æ˜ï¼Œä¸CTCå’Œå…¶ä»–æ–¹æ³•ç›¸æ¯”ï¼Œæ‰€æå‡ºçš„æ–¹æ³•åœ¨å¯¹é½æ€§èƒ½ä¸Šæœ‰äº†æ˜¾è‘—æé«˜ã€‚</li>
<li>è™½ç„¶å­˜åœ¨ASRæ€§èƒ½çš„æƒè¡¡ï¼Œä½†è¿™é¡¹å·¥ä½œä¸ºseq2seqå¯¹é½ç ”ç©¶æä¾›äº†æ–°çš„æ–¹å‘ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2502.01588">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-33d36c1148b4d881a6410834f9c5b794" align="middle">
<img src="https://picx.zhimg.com/v2-4ac1ccf8900f9891e738c6dba833d734" align="middle">
<img src="https://picx.zhimg.com/v2-2cc7453588744a9063fadccc54c2fb91" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="An-Investigation-of-Incorporating-Mamba-for-Speech-Enhancement"><a href="#An-Investigation-of-Incorporating-Mamba-for-Speech-Enhancement" class="headerlink" title="An Investigation of Incorporating Mamba for Speech Enhancement"></a>An Investigation of Incorporating Mamba for Speech Enhancement</h2><p><strong>Authors:Rong Chao, Wen-Huang Cheng, Moreno La Quatra, Sabato Marco Siniscalchi, Chao-Han Huck Yang, Szu-Wei Fu, Yu Tsao</strong></p>
<p>This work aims to investigate the use of a recently proposed, attention-free, scalable state-space model (SSM), Mamba, for the speech enhancement (SE) task. In particular, we employ Mamba to deploy different regression-based SE models (SEMamba) with different configurations, namely basic, advanced, causal, and non-causal. Furthermore, loss functions either based on signal-level distances or metric-oriented are considered. Experimental evidence shows that SEMamba attains a competitive PESQ of 3.55 on the VoiceBank-DEMAND dataset with the advanced, non-causal configuration. A new state-of-the-art PESQ of 3.69 is also reported when SEMamba is combined with Perceptual Contrast Stretching (PCS). Compared against Transformed-based equivalent SE solutions, a noticeable FLOPs reduction up to ~12% is observed with the advanced non-causal configurations. Finally, SEMamba can be used as a pre-processing step before automatic speech recognition (ASR), showing competitive performance against recent SE solutions. </p>
<blockquote>
<p>æœ¬æ–‡æ—¨åœ¨ç ”ç©¶ä¸€ç§æ–°æå‡ºçš„æ— æ³¨æ„åŠ›ã€å¯æ‰©å±•çš„çŠ¶æ€ç©ºé—´æ¨¡å‹ï¼ˆSSMï¼‰ï¼Œåä¸ºMambaï¼Œåœ¨è¯­éŸ³å¢å¼ºï¼ˆSEï¼‰ä»»åŠ¡ä¸­çš„åº”ç”¨ã€‚ç‰¹åˆ«æ˜¯ï¼Œæˆ‘ä»¬é‡‡ç”¨Mambaéƒ¨ç½²ä¸åŒé…ç½®çš„åŸºäºå›å½’çš„SEæ¨¡å‹ï¼ˆSEMambaï¼‰ï¼ŒåŒ…æ‹¬åŸºæœ¬ã€é«˜çº§ã€å› æœå’Œéå› æœé…ç½®ã€‚æ­¤å¤–ï¼Œè¿˜è€ƒè™‘äº†åŸºäºä¿¡å·çº§è·ç¦»æˆ–é¢å‘åº¦é‡çš„æŸå¤±å‡½æ•°ã€‚å®éªŒè¯æ®è¡¨æ˜ï¼ŒSEMambaåœ¨VoiceBank-DEMANDæ•°æ®é›†ä¸Šä½¿ç”¨é«˜çº§éå› æœé…ç½®è¾¾åˆ°äº†æœ‰ç«äº‰åŠ›çš„PESQ 3.55ã€‚å½“SEMambaä¸æ„ŸçŸ¥å¯¹æ¯”åº¦æ‹‰ä¼¸ï¼ˆPCSï¼‰ç»“åˆæ—¶ï¼ŒæŠ¥å‘Šäº†æ–°çš„æœ€é«˜PESQåˆ†æ•°ä¸º3.69ã€‚ä¸åŸºäºè½¬æ¢çš„ç­‰æ•ˆSEè§£å†³æ–¹æ¡ˆç›¸æ¯”ï¼Œé«˜çº§éå› æœé…ç½®ä¸‹è§‚å¯Ÿåˆ°æ˜¾è‘—çš„FLOPså‡å°‘ï¼Œæœ€é«˜å¯è¾¾çº¦12%ã€‚æœ€åï¼ŒSEMambaå¯ä»¥ç”¨ä½œè‡ªåŠ¨è¯­éŸ³è¯†åˆ«ï¼ˆASRï¼‰ä¹‹å‰çš„é¢„å¤„ç†æ­¥éª¤ï¼Œæ˜¾ç¤ºå‡ºä¸æœ€æ–°çš„SEè§£å†³æ–¹æ¡ˆç›¸å½“çš„æ€§èƒ½ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2405.06573v2">PDF</a> Accepted to IEEE SLT 2024</p>
<p><strong>Summary</strong><br>     æœ¬ç ”ç©¶æ—¨åœ¨æ¢ç©¶ä¸€ç§æ–°æå‡ºçš„æ— æ³¨æ„åŠ›ã€å¯æ‰©å±•çš„çŠ¶æ€ç©ºé—´æ¨¡å‹ï¼ˆSSMï¼‰ï¼Œå³Mambaåœ¨è¯­éŸ³å¢å¼ºï¼ˆSEï¼‰ä»»åŠ¡ä¸­çš„åº”ç”¨ã€‚ç ”ç©¶é‡‡ç”¨Mambaéƒ¨ç½²ä¸åŒé…ç½®çš„å›å½’å¼SEæ¨¡å‹ï¼ˆSEMambaï¼‰ï¼ŒåŒ…æ‹¬åŸºæœ¬ã€é«˜çº§ã€å› æœå’Œéå› æœé…ç½®ã€‚åŒæ—¶è€ƒè™‘äº†åŸºäºä¿¡å·çº§åˆ«è·ç¦»æˆ–é¢å‘åº¦é‡çš„æŸå¤±å‡½æ•°ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒSEMambaåœ¨VoiceBank-DEMANDæ•°æ®é›†ä¸Šè·å¾—æœ‰ç«äº‰åŠ›çš„PESQåˆ†æ•°3.55ï¼Œå…¶ä¸­é«˜çº§éå› æœé…ç½®è¡¨ç°æœ€ä½³ã€‚å½“SEMambaä¸æ„ŸçŸ¥å¯¹æ¯”åº¦æ‹‰ä¼¸ï¼ˆPCSï¼‰ç»“åˆæ—¶ï¼ŒæŠ¥å‘Šäº†æ–°çš„æœ€å…ˆè¿›çš„PESQåˆ†æ•°ä¸º3.69ã€‚ä¸åŸºäºå˜æ¢çš„ç­‰æ•ˆSEè§£å†³æ–¹æ¡ˆç›¸æ¯”ï¼Œé«˜çº§éå› æœé…ç½®å®ç°äº†æ˜¾è‘—çš„FLOPså‡å°‘ï¼Œæœ€å¤šå¯è¾¾çº¦12%ã€‚æœ€åï¼ŒSEMambaå¯ä½œä¸ºè‡ªåŠ¨è¯­éŸ³è¯†åˆ«ï¼ˆASRï¼‰ä¹‹å‰çš„é¢„å¤„ç†æ­¥éª¤ï¼Œä¸æœ€æ–°çš„SEè§£å†³æ–¹æ¡ˆç›¸æ¯”è¡¨ç°æœ‰ç«äº‰åŠ›ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>ç ”ç©¶ä½¿ç”¨äº†ä¸€ç§æ–°æå‡ºçš„æ— æ³¨æ„åŠ›çŠ¶æ€ç©ºé—´æ¨¡å‹Mambaåœ¨è¯­éŸ³å¢å¼ºä»»åŠ¡ä¸­çš„åº”ç”¨ã€‚</li>
<li>é€šè¿‡Mambaéƒ¨ç½²äº†ä¸åŒé…ç½®çš„å›å½’å¼SEæ¨¡å‹SEMambaï¼ŒåŒ…æ‹¬åŸºæœ¬ã€é«˜çº§ã€å› æœå’Œéå› æœæ¨¡å‹ã€‚</li>
<li>å®éªŒè¡¨æ˜ï¼ŒSEMambaåœ¨VoiceBank-DEMANDæ•°æ®é›†ä¸Šè·å¾—æœ‰ç«äº‰åŠ›çš„PESQåˆ†æ•°ã€‚</li>
<li>å½“SEMambaä¸æ„ŸçŸ¥å¯¹æ¯”åº¦æ‹‰ä¼¸ï¼ˆPCSï¼‰ç»“åˆæ—¶ï¼Œè¾¾åˆ°äº†æ–°çš„æœ€å…ˆè¿›çš„PESQåˆ†æ•°ã€‚</li>
<li>ä¸åŸºäºå˜æ¢çš„SEè§£å†³æ–¹æ¡ˆç›¸æ¯”ï¼ŒSEMambaåœ¨é«˜çº§éå› æœé…ç½®ä¸‹å®ç°äº†æ˜¾è‘—çš„FLOPså‡å°‘ã€‚</li>
<li>SEMambaå¯ä»¥ç”¨ä½œè‡ªåŠ¨è¯­éŸ³è¯†åˆ«ï¼ˆASRï¼‰çš„é¢„å¤„ç†æ­¥éª¤ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2405.06573">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-fa9b613007c0b05b872d2682745f568c" align="middle">
<img src="https://picx.zhimg.com/v2-47e226ccfb0d8322d763b85d78aaa7c9" align="middle">
<img src="https://picx.zhimg.com/v2-55242756c3ac145de5b5147ae80775d2" align="middle">
<img src="https://picx.zhimg.com/v2-64eae1596c9742db8d2f0696e096d9e4" align="middle">
<img src="https://picx.zhimg.com/v2-155af7e91e50e64a03226f74acc737b7" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-10-11/Speech/">https://kedreamix.github.io/Talk2Paper/Paper/2025-10-11/Speech/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/Speech/">
                                    <span class="chip bg-color">Speech</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-10-11/GAN/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-af916aa2015e25531947898af0f5b2e3" class="responsive-img" alt="GAN">
                        
                        <span class="card-title">GAN</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            GAN æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-10-11  Large Scale Diffusion Distillation via Score-Regularized Continuous-Time   Consistency
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-10-11
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/GAN/" class="post-category">
                                    GAN
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/GAN/">
                        <span class="chip bg-color">GAN</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-10-11/%E6%97%A0%E7%9B%91%E7%9D%A3_%E5%8D%8A%E7%9B%91%E7%9D%A3_%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-94bc23fa748ef40ba5ce1317c1e646a7" class="responsive-img" alt="æ— ç›‘ç£/åŠç›‘ç£/å¯¹æ¯”å­¦ä¹ ">
                        
                        <span class="card-title">æ— ç›‘ç£/åŠç›‘ç£/å¯¹æ¯”å­¦ä¹ </span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            æ— ç›‘ç£/åŠç›‘ç£/å¯¹æ¯”å­¦ä¹  æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-10-11  CAST Contrastive Adaptation and Distillation for Semi-Supervised   Instance Segmentation
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-10-11
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/%E6%97%A0%E7%9B%91%E7%9D%A3-%E5%8D%8A%E7%9B%91%E7%9D%A3-%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0/" class="post-category">
                                    æ— ç›‘ç£/åŠç›‘ç£/å¯¹æ¯”å­¦ä¹ 
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/%E6%97%A0%E7%9B%91%E7%9D%A3-%E5%8D%8A%E7%9B%91%E7%9D%A3-%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0/">
                        <span class="chip bg-color">æ— ç›‘ç£/åŠç›‘ç£/å¯¹æ¯”å­¦ä¹ </span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">33446.1k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
