<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Agent">
    <meta name="description" content="Agent 方向最新论文已更新，请持续关注 Update in 2025-10-11  MATRIX Multimodal Agent Tuning for Robust Tool-Use Reasoning">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>Agent | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loader页面消失采用渐隐的方式*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logo出现动画 */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//使用渐隐的方法淡出loading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//强制显示loading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">嘘~  正在从服务器偷取页面 . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>首页</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>标签</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>分类</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>归档</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="搜索" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="深色/浅色模式" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			首页
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			标签
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			分类
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			归档
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://pic-private.zhihu.com/v2-032121491e3224b8e9447a818f11faf3~resize:0:q75.jpg?source=1f5c5e47&expiration=1760145768&auth_key=1760145768-0-0-c12fae783c952534446a1edee36a27a2&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Agent</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/Agent/">
                                <span class="chip bg-color">Agent</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/Agent/" class="post-category">
                                Agent
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2025-10-11
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>更新日期:&nbsp;&nbsp;
                    2025-10-18
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp;
                    16.2k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp;
                    65 分
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>阅读次数:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>⚠️ 以下所有内容总结都来自于 大语言模型的能力，如有错误，仅供参考，谨慎使用<br>🔴 请注意：千万不要用于严肃的学术场景，只能用于论文阅读前的初筛！<br>💗 如果您觉得我们的项目对您有帮助 <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ，还请您给我们一些鼓励！⭐️ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFace免费体验</a></p>
</blockquote>
<h1 id="2025-10-11-更新"><a href="#2025-10-11-更新" class="headerlink" title="2025-10-11 更新"></a>2025-10-11 更新</h1><h2 id="MATRIX-Multimodal-Agent-Tuning-for-Robust-Tool-Use-Reasoning"><a href="#MATRIX-Multimodal-Agent-Tuning-for-Robust-Tool-Use-Reasoning" class="headerlink" title="MATRIX: Multimodal Agent Tuning for Robust Tool-Use Reasoning"></a>MATRIX: Multimodal Agent Tuning for Robust Tool-Use Reasoning</h2><p><strong>Authors:Tajamul Ashraf, Umair Nawaz, Abdelrahman M. Shaker, Rao Anwer, Philip Torr, Fahad Shahbaz Khan, Salman Khan</strong></p>
<p>Vision language models (VLMs) are increasingly deployed as controllers with access to external tools for complex reasoning and decision-making, yet their effectiveness remains limited by the scarcity of high-quality multimodal trajectories and the cost of manual annotation. We address this challenge with a vision-centric agent tuning framework that automatically synthesizes multimodal trajectories, generates step-wise preference pairs, and trains a VLM controller for robust tool-use reasoning. Our pipeline first constructs M-TRACE, a large-scale dataset of 28.5K multimodal tasks with 177K verified trajectories, enabling imitation-based trajectory tuning. Building on this, we develop MATRIX Agent, a controller finetuned on M-TRACE for step-wise tool reasoning. To achieve finer alignment, we further introduce Pref-X, a set of 11K automatically generated preference pairs, and optimize MATRIX on it via step-wise preference learning. Across three benchmarks, Agent-X, GTA, and GAIA, MATRIX consistently surpasses both open- and closed-source VLMs, demonstrating scalable and effective multimodal tool use. Our data and code is avaliable at <a target="_blank" rel="noopener" href="https://github.com/mbzuai-oryx/MATRIX">https://github.com/mbzuai-oryx/MATRIX</a>. </p>
<blockquote>
<p>视觉语言模型（VLMs）越来越多地被部署为控制器，通过访问外部工具进行复杂的推理和决策。然而，它们的有效性仍然受到高质量多模式轨迹稀缺和手动注释成本高昂的限制。我们通过以视觉为中心的代理调整框架来解决这一挑战，该框架可自动合成多模式轨迹，生成分步偏好对，并训练用于稳健工具使用推理的VLM控制器。我们的管道首先构建M-TRACE，这是一个包含28.5K个多模式任务的大规模数据集，其中包含17.7万条验证过的轨迹，以实现基于模仿的轨迹调整。在此基础上，我们开发了MATRIX Agent，这是一个在M-TRACE上进行微调以进行分步工具推理的控制器。为了实现更精细的对齐，我们进一步引入了Pref-X，这是一组自动生成的包含偏好对的共计一万一千个数据集样本集并对矩阵进行优化以获得每个步骤的最佳选择。在Agent-X、GTA和GAIA三个基准测试中，MATRIX的表现始终超过了开源和闭源的VLMs，证明了其可扩展性和有效的多模式工具使用能力。我们的数据和代码可在<a target="_blank" rel="noopener" href="https://github.com/mbzuai-oryx/MATRIX%E4%B8%8A%E8%8E%B7%E5%8F%96%E3%80%82">https://github.com/mbzuai-oryx/MATRIX上获取。</a></p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.08567v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>本文介绍了一个以视觉为中心的代理调整框架，该框架能够自动合成多模式轨迹，生成步骤式偏好对，并训练用于稳健工具使用推理的VLM控制器。该研究构建了一个大规模数据集M-TRACE，并开发了MATRIX Agent控制器，在M-TRACE上进行微调以实现逐步工具推理。此外，为了更精细的对齐，研究还引入了自动生成的偏好对Pref-X，并通过逐步偏好学习优化MATRIX。在三个基准测试上，MATRIX均超过了开源和闭源的VLMs，证明了其多模式工具使用的可扩展性和有效性。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>VLMs作为控制器在复杂推理和决策制定中的应用越来越广泛，但高质量的多模式轨迹的稀缺性和手动标注的成本限制了其有效性。</li>
<li>研究提出了一种以视觉为中心的代理调整框架，该框架能够自动合成多模式轨迹，有助于解决VLMs面临的上述挑战。</li>
<li>构建了一个大规模数据集M-TRACE，包含28.5K多模式任务和177K验证轨迹，为基于模仿的轨迹调整提供了可能。</li>
<li>开发了MATRIX Agent控制器，在M-TRACE上进行微调，实现逐步工具推理。</li>
<li>引入了自动生成的偏好对Pref-X，实现更精细的对齐，并通过逐步偏好学习优化MATRIX。</li>
<li>MATRIX在三个基准测试上的表现均超过了开源和闭源的VLMs，证明了其多模式工具使用的有效性。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.08567">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic-private.zhihu.com/v2-28ddb784a489005dee88460b30fc8aeb~resize:0:q75.jpg?source=1f5c5e47&expiration=1760145775&auth_key=1760145775-0-0-a170e327a8f9480542a0bf05c8745028&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-c051f3faa5b5b1e5db4c849cb1025d9f~resize:0:q75.jpg?source=1f5c5e47&expiration=1760145782&auth_key=1760145782-0-0-6fe13fce5b03d83c086e7583d7904efd&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-2369f652f8a3e7a5d0a026d2529cd795~resize:0:q75.jpg?source=1f5c5e47&expiration=1760145789&auth_key=1760145789-0-0-4bbe927d95c0e0aaec8616a8c7c3f265&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="CoMAS-Co-Evolving-Multi-Agent-Systems-via-Interaction-Rewards"><a href="#CoMAS-Co-Evolving-Multi-Agent-Systems-via-Interaction-Rewards" class="headerlink" title="CoMAS: Co-Evolving Multi-Agent Systems via Interaction Rewards"></a>CoMAS: Co-Evolving Multi-Agent Systems via Interaction Rewards</h2><p><strong>Authors:Xiangyuan Xue, Yifan Zhou, Guibin Zhang, Zaibin Zhang, Yijiang Li, Chen Zhang, Zhenfei Yin, Philip Torr, Wanli Ouyang, Lei Bai</strong></p>
<p>Self-evolution is a central research topic in enabling large language model (LLM)-based agents to continually improve their capabilities after pretraining. Recent research has witnessed a transition from reinforcement learning (RL)-free to RL-based methods. Current RL-based methods either rely on dense external reward signals or extract intrinsic reward signals from LLMs themselves. However, these approaches diverge from the self-evolution mechanisms observed in human intelligence, where individuals learn and improve through mutual discussion and collaboration. In this work, we introduce Co-Evolving Multi-Agent Systems (CoMAS), a novel framework that enables agents to improve autonomously by learning from inter-agent interactions without external supervision. CoMAS generates intrinsic rewards from rich discussion dynamics, employs an LLM-as-a-judge mechanism to formulate these rewards, and optimizes each agent’s policy through RL, thereby enabling decentralized and scalable co-evolution. Experimental results demonstrate that CoMAS consistently outperforms untrained agents and achieves state-of-the-art performance across most evaluation settings. Ablation studies confirm the necessity of interaction-based reward signals and reveal promising scalability as the number and diversity of agents increase. These findings establish CoMAS as a novel and effective paradigm for self-evolution in LLM-based agents. </p>
<blockquote>
<p>自我进化是使基于大型语言模型的智能体在预训练后能够持续提高其能力的一个核心研究课题。最近的研究见证了从非强化学习向基于强化学习的方法的转变。当前的基于强化学习的方法要么依赖于密集的外部奖励信号，要么从大型语言模型本身提取内在奖励信号。然而，这些方法与人类智能中的自我进化机制背道而驰，人类通过相互讨论和协作来学习和提高。在这项工作中，我们引入了协同进化多智能体系统（CoMAS），这是一个新型框架，使智能体能够通过从智能体之间的交互中学习来自主提高，无需外部监督。CoMAS从丰富的讨论动态中产生内在奖励，采用大型语言模型作为评判机制来制定这些奖励，并通过强化学习优化每个智能体的策略，从而实现分布式和可扩展的协同进化。实验结果表明，CoMAS在大多数情况下都优于未经训练的智能体，并在大多数评估环境中达到了最新技术水平。消融研究证实了基于交互的奖励信号的必要性，并显示出随着智能体数量和多样性的增加，其可扩展性前景广阔。这些发现确立了CoMAS在大型语言模型智能体自我进化领域作为一种新型有效范式。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.08529v1">PDF</a> </p>
<p><strong>Summary</strong><br>自我进化是使基于大型语言模型（LLM）的代理在预训练后能够持续改进其能力的研究核心。近期研究经历了从无强化学习（RL）到RL方法的过程转变。当前RL方法依赖于密集的外界奖励信号或从LLM本身提取的内在奖励信号。然而，这些方法与人类智能中的自我进化机制相悖离，个人通过相互讨论和协作学习和提高。在此研究中，我们引入了协同进化多智能体系统（CoMAS），这是一种新型框架，通过从智能体间互动学习实现无需外部监督的自主进化改进。CoMAS通过丰富的讨论动态生成内在奖励，利用LLM作为评判机制来制定这些奖励，并通过RL优化每个智能体的策略，实现分散和可扩展的协同进化。实验结果显示，CoMAS在各种评估设置中表现最佳。删除研究证实基于互动奖励信号的必要性，随着智能体数量和多样性的增加显示出有前景的可扩展性。这些发现确立了CoMAS在LLM智能体自我进化领域的新颖性和有效性。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>CoMAS是一个新型框架，允许基于LLM的代理通过智能体间的互动学习实现自主进化改进。</li>
<li>该框架通过丰富的讨论动态生成内在奖励，不同于依赖外部奖励信号或仅从LLM中提取内在奖励信号的方法。</li>
<li>CoMAS利用LLM作为评判机制来制定奖励，优化每个智能体的策略，实现分散和可扩展的协同进化。</li>
<li>实验结果显示CoMAS在各种评估设置中表现最佳，显示出其有效性和新颖性。</li>
<li>删除研究证实了互动奖励信号的必要性，这是CoMAS框架成功的关键因素之一。</li>
<li>随着智能体数量和多样性的增加，CoMAS显示出有前景的可扩展性。</li>
<li>该研究为基于LLM的代理的自我进化提供了一种新的和有效的途径。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.08529">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic-private.zhihu.com/v2-c6c34837bff0f4ad8d24310829b02e6a~resize:0:q75.jpg?source=1f5c5e47&expiration=1760145797&auth_key=1760145797-0-0-6f444869bfd36031726d5fc8e6bab264&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-949738b7676f3792c403fa91a7b3982e~resize:0:q75.jpg?source=1f5c5e47&expiration=1760145804&auth_key=1760145804-0-0-5ead63ab0b7006f21454a27cb0ccf2c2&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-6e70f4c8c542fc2eed746a939aef97ed~resize:0:q75.jpg?source=1f5c5e47&expiration=1760145810&auth_key=1760145810-0-0-d7e858b55ea55e3125ba253c1b24b370&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="AutoMLGen-Navigating-Fine-Grained-Optimization-for-Coding-Agents"><a href="#AutoMLGen-Navigating-Fine-Grained-Optimization-for-Coding-Agents" class="headerlink" title="AutoMLGen: Navigating Fine-Grained Optimization for Coding Agents"></a>AutoMLGen: Navigating Fine-Grained Optimization for Coding Agents</h2><p><strong>Authors:Shangheng Du, Xiangchao Yan, Dengyang Jiang, Jiakang Yuan, Yusong Hu, Xin Li, Liang He, Bo Zhang, Lei Bai</strong></p>
<p>Large language models (LLMs) have shown impressive performance in general programming tasks. However, in Machine Learning Engineering (MLE) scenarios such as AutoML and Kaggle competitions, achieving high performance depends heavily on expert intervention and repeated adjustments rather than simply generating correct code. When applied directly to these tasks, LLMs often lack fine-grained domain priors, and existing MLE approaches that use linear or tree-structured searches limit knowledge transfer to adjacent hierarchical links. As a result, they cannot leverage past full trajectories or share information across branches, limiting self-evolving ability and search space diversity. To address these limitations, we introduce AutoMLGen, an LLM-based coding agent that integrates a domain knowledge base for high-quality prior guidance and Monte Carlo Graph Search (MCGS) for efficient exploration. MCGS retains the tree-guided exploration of MCTS while embedding a graph structure into the expansion stage to enable dynamic path reorganization, historical trajectory reuse, and multi-solution fusion to support both self-evolution and collaborative learning. Combined with fine-grained operator sets, this design improves stability and accelerates convergence. Evaluation on the MLE-Bench shows that AutoMLGen achieves state-of-the-art performance in numerous dimensions, such as the average medal rate and the valid submission rate, under a 12-hour budget (half the standard runtime). The code is available at <a target="_blank" rel="noopener" href="https://github.com/Alpha-Innovator/InternAgent">https://github.com/Alpha-Innovator/InternAgent</a>. </p>
<blockquote>
<p>大规模语言模型（LLM）在一般编程任务中表现出了令人印象深刻的性能。然而，在机器学习工程（MLE）场景，如AutoML和Kaggle竞赛中，实现高性能很大程度上依赖于专家干预和重复调整，而不是简单地生成正确代码。当直接应用于这些任务时，LLM往往缺乏精细的域先验知识，而现有的MLE方法使用线性或树状搜索，将知识转移限制在相邻的层次链接上。因此，它们无法利用过去的完整轨迹或在各分支之间共享信息，限制了自我进化能力和搜索空间的多样性。为了解决这些限制，我们引入了AutoMLGen，这是一个基于LLM的编码代理，它整合了领域知识库进行高质量的前期指导，并采用蒙特卡罗图搜索（MCGS）进行有效探索。MCGS保留了MCTS的树状引导探索，同时在扩展阶段嵌入图结构，以实现动态路径重组、历史轨迹重用和多解决方案融合，以支持自我进化和协作学习。结合精细的操作集合，这种设计提高了稳定性并加速了收敛。在MLE-Bench上的评估表明，AutoMLGen在平均奖牌率和有效提交率等多个维度上实现了卓越的性能，在12小时预算（标准运行时的一半）内达到业界领先水平。代码可在<a target="_blank" rel="noopener" href="https://github.com/Alpha-Innovator/InternAgent%E4%B8%8A%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/Alpha-Innovator/InternAgent上找到。</a></p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.08511v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>大型语言模型（LLMs）在通用编程任务中表现出色，但在机器学习工程（MLE）场景如AutoML和Kaggle竞赛中，实现高性能更多依赖于专家干预和重复调整，而非仅生成正确代码。针对LLMs在这些任务中的局限性，如缺乏精细领域先验知识和现有MLE方法的知识转移限制，我们提出了AutoMLGen，一个基于LLM的编码代理，集成了领域知识库以提供高质量先验指导，并采用蒙特卡洛图搜索（MCGS）进行高效探索。MCGS保留了树引导探索的同时，在扩展阶段嵌入图结构，实现动态路径重组、历史轨迹重用和多解决方案融合，支持自我进化和协作学习。结合精细操作集，这种设计提高了稳定性并加速了收敛。在MLE-Bench上的评估显示，AutoMLGen在平均奖牌率和有效提交率等多个维度上实现了卓越性能，并在12小时预算内（为标准运行时的一半）达到了领先水平。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>大型语言模型（LLMs）在编程任务中表现出色，但在机器学习工程（MLE）场景中实现高性能需依赖专家干预。</li>
<li>LLMs在MLE任务中缺乏精细领域先验知识。</li>
<li>现有MLE方法的知识转移仅限于相邻层次链接，无法利用过去的全轨迹或跨分支分享信息。</li>
<li>引入AutoMLGen，一个基于LLM的编码代理，集成了领域知识库和蒙特卡洛图搜索（MCGS）。</li>
<li>MCGS结合树引导探索和图结构，实现动态路径重组、历史轨迹重用和多解决方案融合。</li>
<li>AutoMLGen设计提高了稳定性并加速了收敛，支持自我进化和协作学习。</li>
<li>在MLE-Bench上的评估显示，AutoMLGen实现了卓越性能，并在多个维度上达到领先水平。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.08511">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic-private.zhihu.com/v2-2f78f8ab4f3917a7f0f379e1d3b0dd5e~resize:0:q75.jpg?source=1f5c5e47&expiration=1760145817&auth_key=1760145817-0-0-d73c9fcb108357fe9312f93ff701e8a8&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-8d63880a4d4f492ba270657dbc5b72de~resize:0:q75.jpg?source=1f5c5e47&expiration=1760145825&auth_key=1760145825-0-0-8dae565aafcc18a49f033a6e2d273647&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="Iterated-Agent-for-Symbolic-Regression"><a href="#Iterated-Agent-for-Symbolic-Regression" class="headerlink" title="Iterated Agent for Symbolic Regression"></a>Iterated Agent for Symbolic Regression</h2><p><strong>Authors:Zhuo-Yang Song, Zeyu Cai, Shutao Zhang, Jiashen Wei, Jichen Pan, Shi Qiu, Qing-Hong Cao, Tie-Jiun Hou, Xiaohui Liu, Ming-xing Luo, Hua Xing Zhu</strong></p>
<p>Symbolic regression (SR), the automated discovery of mathematical expressions from data, is a cornerstone of scientific inquiry. However, it is often hindered by the combinatorial explosion of the search space and a tendency to overfit. Popular methods, rooted in genetic programming, explore this space syntactically, often yielding overly complex, uninterpretable models. This paper introduces IdeaSearchFitter, a framework that employs Large Language Models (LLMs) as semantic operators within an evolutionary search. By generating candidate expressions guided by natural-language rationales, our method biases discovery towards models that are not only accurate but also conceptually coherent and interpretable. We demonstrate IdeaSearchFitter’s efficacy across diverse challenges: it achieves competitive, noise-robust performance on the Feynman Symbolic Regression Database (FSReD), outperforming several strong baselines; discovers mechanistically aligned models with good accuracy-complexity trade-offs on real-world data; and derives compact, physically-motivated parametrizations for Parton Distribution Functions in a frontier high-energy physics application. IdeaSearchFitter is a specialized module within our broader iterated agent framework, IdeaSearch, which is publicly available at <a target="_blank" rel="noopener" href="https://www.ideasearch.cn/">https://www.ideasearch.cn/</a>. </p>
<blockquote>
<p>符号回归（SR）是从数据中自动发现数学表达式的过程，是科学研究的基石。然而，它常常受到搜索空间组合爆炸和过度拟合的阻碍。基于遗传编程的流行方法从语法角度探索这个空间，通常会产生过于复杂且不可解释的模型。本文介绍了IdeaSearchFitter框架，它采用大型语言模型（LLM）作为进化搜索中的语义运算符。通过以自然语言理由为指导生成候选表达式，我们的方法使发现偏向于既准确又概念连贯和可解释的模型。我们展示了IdeaSearchFitter在不同挑战中的有效性：它在Feynman符号回归数据库（FSReD）上实现了具有竞争力的噪声鲁棒性能，超越了多个强大的基线；在真实世界数据上发现了具有良好精度复杂性权衡的机械对齐模型；并在前沿高能物理应用中推导出了紧凑的物理驱动参数化粒子分布函数。IdeaSearchFitter是我们更广泛的迭代代理框架IdeaSearch中的专用模块，公开可访问网址为：<a target="_blank" rel="noopener" href="https://www.ideasearch.cn/">https://www.ideasearch.cn/</a>.</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.08317v1">PDF</a> 45 pages, 22 figures, 8 tables</p>
<p><strong>Summary</strong><br>数据驱动的数学表达式自动发现方法——符号回归（SR）是科学探索的重要工具，但面临搜索空间组合爆炸和过度拟合等问题。本文提出IdeaSearchFitter框架，利用大型语言模型（LLMs）在进化搜索中作为语义操作符，生成受自然语言启发候选表达式，使发现模型既准确又概念连贯、可解释性强。IdeaSearchFitter在不同挑战中表现优异，包括在Feynman符号回归数据库（FSReD）上实现与强大基线相当的稳健性能；在现实世界数据上发现具有良好精度复杂度的机械对齐模型；并在高能物理应用的前沿领域推导出紧凑的物理参数化函数。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>IdeaSearchFitter框架结合了符号回归（SR）和大型语言模型（LLM），提高了自动化发现数学表达式的效率。</li>
<li>该框架通过生成受自然语言启发的候选表达式，解决了搜索空间的组合爆炸问题。</li>
<li>IdeaSearchFitter强调模型的准确性、概念连贯性和可解释性，避免过度拟合。</li>
<li>在多个挑战中验证了IdeaSearchFitter的有效性，包括在Feynman符号回归数据库上的性能表现。</li>
<li>该框架能够发现与现实世界数据具有良好精度复杂度的机械对齐模型。</li>
<li>IdeaSearchFitter成功应用于高能物理领域，推导出紧凑的物理参数化函数。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.08317">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic-private.zhihu.com/v2-d2d734190624a59480afdfa41e34196f~resize:0:q75.jpg?source=1f5c5e47&expiration=1760145832&auth_key=1760145832-0-0-bce40bcc549955580ca23ed59dc8925d&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-f4a922b0697d5913d5aaf7b7e7b60300~resize:0:q75.jpg?source=1f5c5e47&expiration=1760145840&auth_key=1760145840-0-0-3f2e2ba1bf5f19cde8adee5a85c334cd&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="Beyond-Turn-Limits-Training-Deep-Search-Agents-with-Dynamic-Context-Window"><a href="#Beyond-Turn-Limits-Training-Deep-Search-Agents-with-Dynamic-Context-Window" class="headerlink" title="Beyond Turn Limits: Training Deep Search Agents with Dynamic Context   Window"></a>Beyond Turn Limits: Training Deep Search Agents with Dynamic Context   Window</h2><p><strong>Authors:Qiaoyu Tang, Hao Xiang, Le Yu, Bowen Yu, Yaojie Lu, Xianpei Han, Le Sun, WenJuan Zhang, Pengbo Wang, Shixuan Liu, Zhenru Zhang, Jianhong Tu, Hongyu Lin, Junyang Lin</strong></p>
<p>While recent advances in reasoning models have demonstrated cognitive behaviors through reinforcement learning, existing approaches struggle to invoke deep reasoning capabilities in multi-turn agents with long-horizon interactions. We propose DeepMiner, a novel framework that elicits such abilities by introducing high-difficulty training tasks and dynamic context window. DeepMiner presents a reverse construction method to generate complex but verifiable question-answer pairs from authentic web sources, which ensures the challenge and reliability of training data while injecting cognitive capabilities into multi-turn reasoning scenarios. We further design an elegant yet effective dynamic context management strategy for both training and inference, utilizing sliding window mechanisms while eliminating the dependency on external summarization models, thereby efficiently empowering the model to handle continuously expanding long-horizon contexts. Through reinforcement learning on Qwen3-32B, we develop DeepMiner-32B, which achieves substantial performance improvements across multiple search agent benchmarks. DeepMiner attains 33.5% accuracy on BrowseComp-en, surpassing the previous best open-source agent by almost 20 percentage points, and demonstrates consistent improvements on BrowseComp-zh, XBench-DeepSearch, and GAIA. Notably, our dynamic context management enables sustained interactions of nearly 100 turns within standard 32k context length, effectively addressing the context limitations that constrain existing multi-turn interaction systems. </p>
<blockquote>
<p>虽然最近的推理模型进步已经通过强化学习展示了认知行为，但现有方法很难在多轮交互代理中激发深度推理能力，特别是具有长期视野的交互。我们提出了DeepMiner，这是一个通过引入高难度训练任务和动态上下文窗口来激发此类能力的新型框架。DeepMiner采用反向构建方法，从真实网络来源生成复杂但可验证的问题答案对，这确保了训练数据的挑战性和可靠性，同时将认知能力注入多轮推理场景中。我们进一步为训练和推理设计了一个优雅而有效的动态上下文管理策略，利用滑动窗口机制，消除对外部摘要模型的依赖，从而有效地增强模型处理不断扩展的长期视野上下文的能力。通过Qwen3-32B上的强化学习，我们开发了DeepMiner-32B，在多个搜索代理基准测试中实现了显著的性能提升。DeepMiner在BrowseComp-en上达到了33.5%的准确率，超过了之前最好的开源代理近20个百分点，并且在BrowseComp-zh、XBench-DeepSearch和GAIA上表现出持续的一致性改进。值得注意的是，我们的动态上下文管理使在标准32k上下文长度内实现了近100轮的持续交互，有效地解决了限制现有多轮交互系统的上下文限制问题。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.08276v1">PDF</a> </p>
<p><strong>Summary</strong>：</p>
<p>近期强化学习模型展现出认知行为能力，但在多轮交互的长周期环境中难以激发深度推理能力。为此，本文提出DeepMiner框架，通过引入高难度训练任务和动态语境窗口来激发深度推理能力。DeepMiner采用反向构建法生成复杂但可验证的问答对，确保训练数据的挑战性和可靠性，并注入多轮推理场景的认知能力。此外，DeepMiner设计动态语境管理策略，用于训练和推理，利用滑动窗口机制，无需依赖外部摘要模型，从而有效处理不断扩展的长周期语境。在Qwen3-32B上进行强化学习，开发出DeepMiner-32B，在多个搜索代理基准测试中实现显著性能提升。</p>
<p><strong>Key Takeaways</strong>：</p>
<ol>
<li>DeepMiner框架通过引入高难度训练任务和动态语境窗口，能够在多轮交互环境中激发深度推理能力。</li>
<li>DeepMiner采用反向构建法生成问答对，确保训练数据的挑战性和可靠性。</li>
<li>DeepMiner注入认知能力到多轮推理场景中。</li>
<li>动态语境管理策略用于训练和推理，能够处理不断扩展的长周期语境。</li>
<li>通过强化学习，DeepMiner在多个搜索代理基准测试中实现显著性能提升。</li>
<li>在BrowseComp-en上，DeepMiner的准确率达到了33.5%，超越了之前最好的开源代理近20个百分点。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.08276">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic-private.zhihu.com/v2-57ed116786cce55fc80da67e3e3bbd8e~resize:0:q75.jpg?source=1f5c5e47&expiration=1760145847&auth_key=1760145847-0-0-6c188adbe647e83c2a47a5a5a9e17c31&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-088612310744cec2fad6ddcfdac17a6c~resize:0:q75.jpg?source=1f5c5e47&expiration=1760145855&auth_key=1760145855-0-0-d66f4a7ca18b6ec6a4f3a60696cc2ca4&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-114502022f12501b5b73219558e0b5b9~resize:0:q75.jpg?source=1f5c5e47&expiration=1760145861&auth_key=1760145861-0-0-8af4b4cd9f8c1927ed0203cf8b7aa8bf&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-e8f07f72a0894d94e5e79b993d8d256f~resize:0:q75.jpg?source=1f5c5e47&expiration=1760145868&auth_key=1760145868-0-0-074d39dc04627349f5415229d79f69a5&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="Multi-Agent-Analysis-of-Off-Exchange-Public-Information-for-Cryptocurrency-Market-Trend-Prediction"><a href="#Multi-Agent-Analysis-of-Off-Exchange-Public-Information-for-Cryptocurrency-Market-Trend-Prediction" class="headerlink" title="Multi-Agent Analysis of Off-Exchange Public Information for   Cryptocurrency Market Trend Prediction"></a>Multi-Agent Analysis of Off-Exchange Public Information for   Cryptocurrency Market Trend Prediction</h2><p><strong>Authors:Kairan Hong, Jinling Gan, Qiushi Tian, Yanglinxuan Guo, Rui Guo, Runnan Li</strong></p>
<p>Cryptocurrency markets present unique prediction challenges due to their extreme volatility, 24&#x2F;7 operation, and hypersensitivity to news events, with existing approaches suffering from key information extraction and poor sideways market detection critical for risk management. We introduce a theoretically-grounded multi-agent cryptocurrency trend prediction framework that advances the state-of-the-art through three key innovations: (1) an information-preserving news analysis system with formal theoretical guarantees that systematically quantifies market impact, regulatory implications, volume dynamics, risk assessment, technical correlation, and temporal effects using large language models; (2) an adaptive volatility-conditional fusion mechanism with proven optimal properties that dynamically combines news sentiment and technical indicators based on market regime detection; (3) a distributed multi-agent coordination architecture with low communication complexity enabling real-time processing of heterogeneous data streams. Comprehensive experimental evaluation on Bitcoin across three prediction horizons demonstrates statistically significant improvements over state-of-the-art natural language processing baseline, establishing a new paradigm for financial machine learning with broad implications for quantitative trading and risk management systems. </p>
<blockquote>
<p>加密货币市场的独特预测挑战体现在其极端波动性、全天候运营以及对新闻事件的极度敏感性上。现有方法面临关键信息提取和横向市场检测不足的问题，这对风险管理至关重要。我们引入了一个有理论支撑的多智能体加密货币趋势预测框架，通过三个关键创新点来推动前沿技术：（1）一个信息保留的新闻分析系统，具有形式化的理论保证，能够系统地量化市场影响、监管影响、交易量动态、风险评估、技术相关性以及时间效应，使用大型语言模型；（2）一种自适应的波动性条件融合机制，具有经过验证的最优属性，能够根据市场状态检测动态地结合新闻情感和基于技术指标的预测；（3）一种具有低通信复杂性的分布式多智能体协调架构，能够实现实时处理异构数据流。在比特币上的三个预测时间点的综合实验评估表明，与传统的自然语言处理基线相比，具有统计学上的显著改进，为金融机器学习建立了新的范式，对定量交易和风险管理系统具有广泛的影响。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.08268v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>这篇文本主要介绍了针对加密货币市场的独特预测挑战，提出了一种基于多智能体的加密货币趋势预测框架。该框架具有三个关键创新点：一是信息保留的新闻分析系统，二是自适应波动条件融合机制，三是分布式多智能体协调架构。这些创新点旨在解决现有方法在信息提取和横向市场检测方面的不足，为风险管理提供新的解决方案。实验评估表明，该框架在比特币预测方面显著优于现有自然语言处理基线，为金融机器学习和量化交易风险管理提供了重要的启示。</p>
<p><strong>Key Takeaways</strong></p>
<p>以下是七个关键见解：</p>
<ul>
<li>加密货币市场具有独特的预测挑战，如极端波动性、全天候操作和新闻事件的敏感性。</li>
<li>现存方法在关键信息提取和横向市场检测方面存在不足。</li>
<li>提出了一种多智能体加密货币趋势预测框架，包括信息保留的新闻分析系统、自适应波动条件融合机制和分布式多智能体协调架构。</li>
<li>信息保留的新闻分析系统使用大型语言模型量化市场影响、监管影响、交易量动态、风险评估、技术关联和时间效应。</li>
<li>自适应波动条件融合机制结合新闻情感和基于市场状态检测的技术指标。</li>
<li>分布式多智能体协调架构具有低通信复杂性，可实时处理异构数据流。</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.08268">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic-private.zhihu.com/v2-278207ab842898d350559ee13081899c~resize:0:q75.jpg?source=1f5c5e47&expiration=1760145876&auth_key=1760145876-0-0-a4f42be051d11ae3a81293a8d4c26cf3&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-ea5c1172cf0543f8aa2f2f8f4de879f8~resize:0:q75.jpg?source=1f5c5e47&expiration=1760145883&auth_key=1760145883-0-0-e3c7e6f946c57d74b9d0dde129b07b61&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-cb28c43ea2c11ae120b6add1f00974be~resize:0:q75.jpg?source=1f5c5e47&expiration=1760145890&auth_key=1760145890-0-0-f7c80c4865ce9c78277047f5b630b954&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-bcfdf1bbaa04a8f83ef4eae0611b61a3~resize:0:q75.jpg?source=1f5c5e47&expiration=1760145897&auth_key=1760145897-0-0-741ee632a08b19d7b2cf34425b869c11&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-2b2504b4df9f481e0844e65013715a43~resize:0:q75.jpg?source=1f5c5e47&expiration=1760145903&auth_key=1760145903-0-0-c3bd399251b6d36a2b51e3385940f996&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-b3fbafb1dfa34ee172866ed044323040~resize:0:q75.jpg?source=1f5c5e47&expiration=1760145909&auth_key=1760145909-0-0-14a4a573132f5687fd67a12df7f8db24&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-385fb8eb89c21c754890b4b46f3b8470~resize:0:q75.jpg?source=1f5c5e47&expiration=1760145916&auth_key=1760145916-0-0-d2473d357d3b82ff7b897e1c509c5834&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="Opponent-Shaping-in-LLM-Agents"><a href="#Opponent-Shaping-in-LLM-Agents" class="headerlink" title="Opponent Shaping in LLM Agents"></a>Opponent Shaping in LLM Agents</h2><p><strong>Authors:Marta Emili Garcia Segura, Stephen Hailes, Mirco Musolesi</strong></p>
<p>Large Language Models (LLMs) are increasingly being deployed as autonomous agents in real-world environments. As these deployments scale, multi-agent interactions become inevitable, making it essential to understand strategic behavior in such systems. A central open question is whether LLM agents, like reinforcement learning agents, can shape the learning dynamics and influence the behavior of others through interaction alone. In this paper, we present the first investigation of opponent shaping (OS) with LLM-based agents. Existing OS algorithms cannot be directly applied to LLMs, as they require higher-order derivatives, face scalability constraints, or depend on architectural components that are absent in transformers. To address this gap, we introduce ShapeLLM, an adaptation of model-free OS methods tailored for transformer-based agents. Using ShapeLLM, we examine whether LLM agents can influence co-players’ learning dynamics across diverse game-theoretic environments. We demonstrate that LLM agents can successfully guide opponents toward exploitable equilibria in competitive games (Iterated Prisoner’s Dilemma, Matching Pennies, and Chicken) and promote coordination and improve collective welfare in cooperative games (Iterated Stag Hunt and a cooperative version of the Prisoner’s Dilemma). Our findings show that LLM agents can both shape and be shaped through interaction, establishing opponent shaping as a key dimension of multi-agent LLM research. </p>
<blockquote>
<p>大型语言模型（LLM）越来越被部署在真实世界环境中作为自主代理。随着这些部署规模的扩大，多智能体交互变得不可避免，因此了解此类系统中的战略行为变得至关重要。一个核心开放的问题是，LLM智能体是否能够像强化学习智能体一样，仅通过交互来塑造学习动态并影响他人的行为。在本文中，我们首次对基于LLM的对手塑造（OS）进行了调查。现有的OS算法不能直接在LLM上应用，因为它们需要高阶导数、面临可扩展性约束或依赖于LLM模型中不存在的架构组件。为了弥补这一空白，我们引入了ShapeLLM，这是一个针对基于转换器的智能体的无模型OS方法的改编。使用ShapeLLM，我们研究了LLM智能体是否能在多种博弈论环境中影响对手的学习动态。我们证明，LLM智能体可以成功引导对手走向竞争游戏中的可剥削平衡（如反复囚徒困境、匹配硬币和鸡肉游戏），并在合作游戏中促进协调和提高集体福利（如反复狩猎阶段和合作版本的囚徒困境）。我们的研究结果表明，LLM智能体既可以通过交互来塑造对手，也可以被对手塑造，从而确立了对手塑造在多智能体LLM研究中的关键维度。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.08255v1">PDF</a> 29 pages, 15 figures, 15 tables</p>
<p><strong>Summary</strong></p>
<p>大型语言模型（LLM）作为自主代理在现实环境中的部署日益增多，多代理交互不可避免。本文首次研究了与LLM代理的对手塑造（OS）问题。针对LLM，我们引入了ShapeLLM，这是一种针对基于变压器的代理的无模型OS方法的改编。研究表明，LLM代理可以在游戏理论环境中影响对手的学习动态。在竞争游戏中，LLM代理可以引导对手走向可剥削的均衡状态，并在合作游戏中促进协调和提高集体福利。因此，对手塑造是LLM多代理研究的关键维度。</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>大型语言模型（LLM）正在被越来越多地部署为自主代理，在多代理交互中，对手塑造（OS）成为关键议题。</li>
<li>现有OS算法不能直接应用于LLM，需要针对基于变压器的代理进行改编。</li>
<li>引入ShapeLLM，一种针对LLM的无模型OS方法。</li>
<li>LLM代理可以在不同的游戏理论环境中影响对手的学习动态。</li>
<li>在竞争游戏中，LLM代理可引导对手至可剥削的均衡状态。</li>
<li>在合作游戏中，LLM代理能促进协调和提高集体福利。</li>
<li>LLM代理既能够塑造对手，也能通过交互被对手塑造。</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.08255">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic-private.zhihu.com/v2-a7e4f9c5f7cad95f3595e39119e154ac~resize:0:q75.jpg?source=1f5c5e47&expiration=1760145924&auth_key=1760145924-0-0-4b65242b9dd88f1e3a6c4cf82d1216f2&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-1c58457c6e9bd4f7222ee4b52fd274b5~resize:0:q75.jpg?source=1f5c5e47&expiration=1760145931&auth_key=1760145931-0-0-5ff99e416d854d85c885a7bd84c61385&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-d6b8d43d2a97a5de8b8ac6d733556b51~resize:0:q75.jpg?source=1f5c5e47&expiration=1760145938&auth_key=1760145938-0-0-0f0120aae86a3bdd3f341d3cc2d9cde5&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="Two-Agents-One-Prompt-and-Your-Weight"><a href="#Two-Agents-One-Prompt-and-Your-Weight" class="headerlink" title="Two Agents, One Prompt, and Your Weight"></a>Two Agents, One Prompt, and Your Weight</h2><p><strong>Authors:Elchanan Mossel, Amnon Schrieber</strong></p>
<p>We investigate a quantitative variant of the classic Two Doors logic puzzle, in which the answer space is no longer binary, for example when the goal is to recover a numerical fact (such as one’s true weight) rather than choose between two doors. The puzzle retains the original structure: one agent always tells the truth, the other always lies. Our central contribution is to identify a class of self-referential prompts that successfully extract the correct quantitative answer under minimal assumptions. We also explore how well does \texttt{ChatGPT} does in reasoning for this problem which is just a little bit out of distribution. </p>
<blockquote>
<p>我们研究了经典的两门逻辑难题的定量变体，在这个变体中，答案空间不再是二元的，例如目标是从两个门中选择一个数字事实（如真实的体重）而不是简单地选择其中一个门。谜题保留了原始结构：一个代理人总是说实话，另一个代理人总是说谎。我们的主要贡献在于识别出一类自指提示，这些提示能够在最少的假设下成功提取正确的定量答案。我们还探讨了ChatGPT在处理这种稍微超出常规范围的问题时的推理能力。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.08232v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>本文探讨了经典的两门逻辑难题的定量变体。当目标不再是二元选择（如选择两扇门中的一扇门），而是恢复数值事实（如真实体重）时，该难题如何保持原有的结构特点：一个代理人总是说实话，另一个总是说谎。本文的核心贡献是识别出一类自我参考的提示，这些提示能在最小的假设下成功提取出正确的定量答案。此外，本文还探讨了ChatGPT在这种稍微超出其常规处理范围的问题上的推理能力。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>本文研究了经典两门逻辑难题的定量变体，其中答案不再是简单的二元选择，而是涉及到数值事实的提取。</li>
<li>问题保持原有的结构特点：一个代理人始终说实话，另一个代理人始终说谎。</li>
<li>论文主要贡献在于找到一种自我参考的提示方法，可以在最少假设下成功提取出正确的定量答案。</li>
<li>论文还探讨了ChatGPT在处理稍微超出其常规范围的问题时的推理能力。</li>
<li>该研究展示了如何通过逻辑推理来解决问题，即使这些问题涉及到数值数据和自我参考的复杂性。</li>
<li>研究结果对于人工智能理解和处理复杂逻辑问题有一定的启示作用。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.08232">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic-private.zhihu.com/v2-18a187ba5e8306e4c53aa661f9cbda95~resize:0:q75.jpg?source=1f5c5e47&expiration=1760145945&auth_key=1760145945-0-0-29d8402b83124b966f8f9671389781cf&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="NavSpace-How-Navigation-Agents-Follow-Spatial-Intelligence-Instructions"><a href="#NavSpace-How-Navigation-Agents-Follow-Spatial-Intelligence-Instructions" class="headerlink" title="NavSpace: How Navigation Agents Follow Spatial Intelligence Instructions"></a>NavSpace: How Navigation Agents Follow Spatial Intelligence Instructions</h2><p><strong>Authors:Haolin Yang, Yuxing Long, Zhuoyuan Yu, Zihan Yang, Minghan Wang, Jiapeng Xu, Yihan Wang, Ziyan Yu, Wenzhe Cai, Lei Kang, Hao Dong</strong></p>
<p>Instruction-following navigation is a key step toward embodied intelligence. Prior benchmarks mainly focus on semantic understanding but overlook systematically evaluating navigation agents’ spatial perception and reasoning capabilities. In this work, we introduce the NavSpace benchmark, which contains six task categories and 1,228 trajectory-instruction pairs designed to probe the spatial intelligence of navigation agents. On this benchmark, we comprehensively evaluate 22 navigation agents, including state-of-the-art navigation models and multimodal large language models. The evaluation results lift the veil on spatial intelligence in embodied navigation. Furthermore, we propose SNav, a new spatially intelligent navigation model. SNav outperforms existing navigation agents on NavSpace and real robot tests, establishing a strong baseline for future work. </p>
<blockquote>
<p>指令跟随导航是实现实体智能的关键步骤。此前的基准测试主要关注语义理解，但忽视了系统地评估导航代理的空间感知和推理能力。在这项工作中，我们引入了NavSpace基准测试，其中包含六个任务类别和1228个轨迹指令对，旨在探测导航代理的空间智能。在此基准测试上，我们全面评估了22个导航代理，包括最先进的导航模型和多模态大型语言模型。评估结果揭示了实体导航中的空间智能。此外，我们提出了一个新的空间智能导航模型SNav。SNav在NavSpace和真实机器人测试中都超越了现有导航代理，为未来的工作建立了强大的基准。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.08173v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>该文介绍了导航智能研究中的一个关键步骤——指令遵循导航。现有基准测试主要关注语义理解，但忽略了系统地评估导航系统的空间感知和推理能力。本研究引入了NavSpace基准测试，包含六个任务类别和1228组轨迹指令对，旨在测试导航系统的空间智能水平。该研究全面评估了包括最新导航模型和跨模态大型语言模型在内的22个导航系统。同时，提出了一种新型的空间智能导航模型SNav，该模型在NavSpace和真实机器人测试中表现出超越现有导航系统的性能，为未来研究奠定了坚实的基准。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>指令遵循导航是智能研究的关键步骤之一。</li>
<li>当前基准测试主要关注语义理解，忽视了导航系统的空间感知和推理能力评估。</li>
<li>NavSpace基准测试旨在全面测试导航系统的空间智能水平，包含六个任务类别和大量轨迹指令对。</li>
<li>研究人员对22个导航系统进行了全面评估，包括最新导航模型和跨模态大型语言模型。</li>
<li>新型空间智能导航模型SNav在NavSpace基准测试和真实机器人测试中表现优异。</li>
<li>SNav模型为未来的导航智能研究提供了坚实的基准。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.08173">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic-private.zhihu.com/v2-69330b7c65afe79182a24fffa54bce9e~resize:0:q75.jpg?source=1f5c5e47&expiration=1760145953&auth_key=1760145953-0-0-2698be2f09e2344dfab72de18dc7ec18&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-25e820a6ccadc2757fb469660d02e2bc~resize:0:q75.jpg?source=1f5c5e47&expiration=1760145960&auth_key=1760145960-0-0-0703a1a0cb90f6a9bc8606f326b868c9&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-947904bffdda38c9ed55a8d4a1c6501c~resize:0:q75.jpg?source=1f5c5e47&expiration=1760145968&auth_key=1760145968-0-0-78f79664b736bbe1c7dca4f772ba1fc6&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-f97e414b8c99bb98749f4529a29e1c20~resize:0:q75.jpg?source=1f5c5e47&expiration=1760145975&auth_key=1760145975-0-0-b16b5f6b1af71f862cff20ee819332b8&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-b08058d1c11972963ea278382aae623b~resize:0:q75.jpg?source=1f5c5e47&expiration=1760145983&auth_key=1760145983-0-0-01314a826029ea4c0317713d260aaf83&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1><h2 id="AI-Knowledge-Assist-An-Automated-Approach-for-the-Creation-of-Knowledge-Bases-for-Conversational-AI-Agents"><a href="#AI-Knowledge-Assist-An-Automated-Approach-for-the-Creation-of-Knowledge-Bases-for-Conversational-AI-Agents" class="headerlink" title="AI Knowledge Assist: An Automated Approach for the Creation of Knowledge   Bases for Conversational AI Agents"></a>AI Knowledge Assist: An Automated Approach for the Creation of Knowledge   Bases for Conversational AI Agents</h2><p><strong>Authors:Md Tahmid Rahman Laskar, Julien Bouvier Tremblay, Xue-Yong Fu, Cheng Chen, Shashi Bhushan TN</strong></p>
<p>The utilization of conversational AI systems by leveraging Retrieval Augmented Generation (RAG) techniques to solve customer problems has been on the rise with the rapid progress of Large Language Models (LLMs). However, the absence of a company-specific dedicated knowledge base is a major barrier to the integration of conversational AI systems in contact centers. To this end, we introduce AI Knowledge Assist, a system that extracts knowledge in the form of question-answer (QA) pairs from historical customer-agent conversations to automatically build a knowledge base. Fine-tuning a lightweight LLM on internal data demonstrates state-of-the-art performance, outperforming larger closed-source LLMs. More specifically, empirical evaluation on 20 companies demonstrates that the proposed AI Knowledge Assist system that leverages the LLaMA-3.1-8B model eliminates the cold-start gap in contact centers by achieving above 90% accuracy in answering information-seeking questions. This enables immediate deployment of RAG-powered chatbots. </p>
<blockquote>
<p>随着大型语言模型（LLM）的快速发展，利用检索增强生成（RAG）技术解决客户问题的对话式人工智能系统的应用正在增加。然而，缺乏针对公司的专用知识库是阻碍对话式人工智能系统在呼叫中心中整合的主要障碍。为此，我们引入了AI知识助手系统，该系统从历史和客服对话中提取以问答对的形式的知识来自动构建知识库。在内部数据上对轻量级LLM进行微调，表现出卓越的性能，超过了较大的闭源LLM。更具体地说，对20家公司的实证评估表明，所提出的利用LLaMA-3.1-8B模型的AI知识助手系统通过实现高达90%的信息查询问题回答准确率，消除了呼叫中心中的冷启动差距。这能够实现RAG驱动的聊天机器人的即时部署。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.08149v1">PDF</a> Accepted to the EMNLP 2025 Industry Track</p>
<p><strong>Summary</strong></p>
<p>基于大型语言模型（LLM）技术的快速发展，利用检索增强生成（RAG）技术解决客户问题的对话AI系统应用日益广泛。然而，缺乏公司特定的专用知识库是集成对话AI系统的主要障碍。为此，我们推出了AI知识助手系统，它可以从历史客户与代理之间的对话中提取问题答案（QA）对来自动构建知识库。在内部数据上微调轻量级LLM，展现出最佳性能，甚至超越了一些大型闭源LLMs。针对二十家公司的实证评估显示，利用LLaMA-3.1-8B模型的AI知识助手系统通过实现高达90%的信息查询问题答案准确性，消除了呼叫中心中的冷启动差距，使得RAG驱动的聊天机器人得以立即部署。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>对话AI系统利用RAG技术解决客户问题正逐渐普及。</li>
<li>公司特定知识库的缺乏是集成对话AI系统的障碍。</li>
<li>AI知识助手系统通过提取QA对自动构建知识库。</li>
<li>轻量级LLM在内部数据上的微调表现出最佳性能。</li>
<li>AI知识助手系统消除了呼叫中心的冷启动差距。</li>
<li>AI知识助手系统的准确性高达90%，适合立即部署RAG驱动的聊天机器人。</li>
<li>实证研究证明了AI知识助手系统的有效性。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.08149">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic-private.zhihu.com/v2-93240272221c8b73469f4fcbcc21750c~resize:0:q75.jpg?source=1f5c5e47&expiration=1760145991&auth_key=1760145991-0-0-cb0f693edcb66be175b0fe901342490f&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-7236752646841659539e2e6c5edf84e3~resize:0:q75.jpg?source=1f5c5e47&expiration=1760145999&auth_key=1760145999-0-0-9e28f70c89d23571b02ee25f386abf42&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-47bfed8186a621cd8975647e0528b5cc~resize:0:q75.jpg?source=1f5c5e47&expiration=1760146006&auth_key=1760146006-0-0-9a7a0ca74dbfe8a5c02c8602b5edf2c1&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-be5b77e3d70885a5f8f6d7bb6f75328d~resize:0:q75.jpg?source=1f5c5e47&expiration=1760146012&auth_key=1760146012-0-0-f2f4fac085651b690d0d88a8e0e32e09&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-48788bff22872227a65d0e8a4d38698a~resize:0:q75.jpg?source=1f5c5e47&expiration=1760146019&auth_key=1760146019-0-0-a0ee05848fe862a7e1f505d541e7ff24&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-11974e7c53233ce1909d7a2ab265ebd2~resize:0:q75.jpg?source=1f5c5e47&expiration=1760146025&auth_key=1760146025-0-0-92fb204a80ac492c16cc7ca61b01a497&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-9"><a href="#-9" class="headerlink" title=""></a></h1><h2 id="L2M-AID-Autonomous-Cyber-Physical-Defense-by-Fusing-Semantic-Reasoning-of-Large-Language-Models-with-Multi-Agent-Reinforcement-Learning-Preprint"><a href="#L2M-AID-Autonomous-Cyber-Physical-Defense-by-Fusing-Semantic-Reasoning-of-Large-Language-Models-with-Multi-Agent-Reinforcement-Learning-Preprint" class="headerlink" title="L2M-AID: Autonomous Cyber-Physical Defense by Fusing Semantic Reasoning   of Large Language Models with Multi-Agent Reinforcement Learning (Preprint)"></a>L2M-AID: Autonomous Cyber-Physical Defense by Fusing Semantic Reasoning   of Large Language Models with Multi-Agent Reinforcement Learning (Preprint)</h2><p><strong>Authors:Tianxiang Xu, Zhichao Wen, Xinyu Zhao, Jun Wang, Yan Li, Chang Liu</strong></p>
<p>The increasing integration of Industrial IoT (IIoT) exposes critical cyber-physical systems to sophisticated, multi-stage attacks that elude traditional defenses lacking contextual awareness. This paper introduces L2M-AID, a novel framework for Autonomous Industrial Defense using LLM-empowered, Multi-agent reinforcement learning. L2M-AID orchestrates a team of collaborative agents, each driven by a Large Language Model (LLM), to achieve adaptive and resilient security. The core innovation lies in the deep fusion of two AI paradigms: we leverage an LLM as a semantic bridge to translate vast, unstructured telemetry into a rich, contextual state representation, enabling agents to reason about adversary intent rather than merely matching patterns. This semantically-aware state empowers a Multi-Agent Reinforcement Learning (MARL) algorithm, MAPPO, to learn complex cooperative strategies. The MARL reward function is uniquely engineered to balance security objectives (threat neutralization) with operational imperatives, explicitly penalizing actions that disrupt physical process stability. To validate our approach, we conduct extensive experiments on the benchmark SWaT dataset and a novel synthetic dataset generated based on the MITRE ATT&amp;CK for ICS framework. Results demonstrate that L2M-AID significantly outperforms traditional IDS, deep learning anomaly detectors, and single-agent RL baselines across key metrics, achieving a 97.2% detection rate while reducing false positives by over 80% and improving response times by a factor of four. Crucially, it demonstrates superior performance in maintaining physical process stability, presenting a robust new paradigm for securing critical national infrastructure. </p>
<blockquote>
<p>随着工业物联网（IIoT）的日益融合，关键的网络物理系统面临高级的多阶段攻击，这些攻击能够躲避缺乏上下文意识的传统防御手段。本文介绍了L2M-AID，这是一个使用大型语言模型赋能的多智能体强化学习的新型自主工业防御框架。L2M-AID协同一组协作的智能体，每个智能体都由大型语言模型（LLM）驱动，以实现自适应和弹性安全。核心创新之处在于两种人工智能范式的深度融合：我们利用大型语言模型作为语义桥梁，将大量非结构化遥测信息转换为丰富的上下文状态表示，使智能体能够推理对手的意图，而不仅仅是匹配模式。这种语义感知状态使得多智能体强化学习（MARL）算法MAPPO能够学习复杂的合作策略。MARL奖励函数是独特设计的，旨在平衡安全目标（威胁中立）与操作要求，明确惩罚破坏物理过程稳定性的行动。为了验证我们的方法，我们在SWaT数据集的标准基准测试以及基于MITRE ATT＆CK for ICS框架生成的新型合成数据集上进行了广泛的实验。结果表明，L2M-AID在关键指标上显著优于传统入侵检测系统、深度学习异常检测器和单智能体强化学习基准线，检测率达到97.2%，同时减少了超过80%的误报，并将响应时间提高了四倍。最重要的是，它在保持物理过程稳定性方面表现出卓越的性能，为关键国家基础设施的安全提供了稳健的新范式。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.07363v1">PDF</a> This preprint was submitted to IEEE TrustCom 2025. The accepted   version will be published under copyright 2025 IEEE</p>
<p><strong>Summary</strong>：随着工业物联网（IIoT）的集成度不断提高，关键的网络物理系统面临复杂的多阶段攻击威胁，传统缺乏上下文意识的防御手段已不足以应对。本文提出了基于大型语言模型赋能的多智能体强化学习的自主工业防御框架L2M-AID。L2M-AID协调智能体团队进行自适应和弹性安全防御。其核心创新在于两种人工智能范式的深度融合：利用大型语言模型作为语义桥梁，将大量非结构化遥测信息转化为丰富的上下文状态表示，使智能体能够推断敌方意图而不仅仅是匹配模式。基于这种语义感知状态，我们利用多智能体强化学习算法MAPPO学习复杂的合作策略。实验结果表明，在关键指标上，L2M-AID显著优于传统入侵检测系统、深度学习异常检测器和单智能体强化学习基线，实现了高达97.2%的检测率，同时减少了超过80%的误报并加快了四倍的响应时间。在维护物理过程稳定性方面表现优异，为关键国家基础设施的安全保护提供了稳健的新范式。</p>
<p><strong>Key Takeaways</strong>:</p>
<ol>
<li>IIoT的集成增加了关键网络物理系统面临的多阶段攻击风险。</li>
<li>L2M-AID是一个利用大型语言模型赋能的多智能体强化学习框架进行自适应和弹性安全防御。</li>
<li>LLM用于将非结构化遥测转化为上下文状态表示，帮助智能体理解敌方意图。</li>
<li>多智能体强化学习算法MAPPO用于学习复杂的合作策略以应对攻击。</li>
<li>L2M-AID在检测率、误报率和响应时间方面表现优于传统安全系统。</li>
<li>L2M-AID在保持物理过程稳定性方面具有出色的性能。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.07363">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic-private.zhihu.com/v2-4af08f18a6f9e028ca97e22e33d12b1f~resize:0:q75.jpg?source=1f5c5e47&expiration=1760146033&auth_key=1760146033-0-0-da52ec2209cdc78db7e1859e630bcf09&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-8c607802bd522c19b0b9779763481abc~resize:0:q75.jpg?source=1f5c5e47&expiration=1760146040&auth_key=1760146040-0-0-d19ea2e3dc361d3093e0bfcf19e7507a&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-9436665c01dbb519f1e08984daeb1cc2~resize:0:q75.jpg?source=1f5c5e47&expiration=1760146046&auth_key=1760146046-0-0-4b566393544dd28875abff91546da353&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-33e1ce80ff17c327a26550cec9d49b77~resize:0:q75.jpg?source=1f5c5e47&expiration=1760146053&auth_key=1760146053-0-0-a50ece1fa691c0aeb16a198601ebea6d&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-382adb3dec2f88d76d9413f15cfb0eea~resize:0:q75.jpg?source=1f5c5e47&expiration=1760146059&auth_key=1760146059-0-0-05280a5f46f3c145e4ab861d6eb3388f&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-76464525abbda66c9424004dd369bab2~resize:0:q75.jpg?source=1f5c5e47&expiration=1760146066&auth_key=1760146066-0-0-7b0b5768599d48b246004e5500d851d0&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-971a73cbdd8677e2e6824e365af2c1a4~resize:0:q75.jpg?source=1f5c5e47&expiration=1760146072&auth_key=1760146072-0-0-7681a427ecf53ea4a9c4edae669a89ea&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-032121491e3224b8e9447a818f11faf3~resize:0:q75.jpg?source=1f5c5e47&expiration=1760146078&auth_key=1760146078-0-0-5b4341f10f618275448957ddb7c6a388&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-58643b3188dce6dedde48b0f44a44a97~resize:0:q75.jpg?source=1f5c5e47&expiration=1760146085&auth_key=1760146085-0-0-e99fb881c5cd34945eaead4eafe9808e&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-10"><a href="#-10" class="headerlink" title=""></a></h1><h2 id="Kimi-Dev-Agentless-Training-as-Skill-Prior-for-SWE-Agents"><a href="#Kimi-Dev-Agentless-Training-as-Skill-Prior-for-SWE-Agents" class="headerlink" title="Kimi-Dev: Agentless Training as Skill Prior for SWE-Agents"></a>Kimi-Dev: Agentless Training as Skill Prior for SWE-Agents</h2><p><strong>Authors:Zonghan Yang, Shengjie Wang, Kelin Fu, Wenyang He, Weimin Xiong, Yibo Liu, Yibo Miao, Bofei Gao, Yejie Wang, Yingwei Ma, Yanhao Li, Yue Liu, Zhenxing Hu, Kaitai Zhang, Shuyi Wang, Huarong Chen, Flood Sung, Yang Liu, Yang Gao, Zhilin Yang, Tianyu Liu</strong></p>
<p>Large Language Models (LLMs) are increasingly applied to software engineering (SWE), with SWE-bench as a key benchmark. Solutions are split into SWE-Agent frameworks with multi-turn interactions and workflow-based Agentless methods with single-turn verifiable steps. We argue these paradigms are not mutually exclusive: reasoning-intensive Agentless training induces skill priors, including localization, code edit, and self-reflection that enable efficient and effective SWE-Agent adaptation. In this work, we first curate the Agentless training recipe and present Kimi-Dev, an open-source SWE LLM achieving 60.4% on SWE-bench Verified, the best among workflow approaches. With additional SFT adaptation on 5k publicly-available trajectories, Kimi-Dev powers SWE-Agents to 48.6% pass@1, on par with that of Claude 3.5 Sonnet (241022 version). These results show that structured skill priors from Agentless training can bridge workflow and agentic frameworks for transferable coding agents. </p>
<blockquote>
<p>大型语言模型（LLMs）越来越多地应用于软件工程（SWE），而SWE-bench是其中的一项关键基准测试。解决方案分为SWE-Agent框架和多轮交互的Agentless方法以及基于工作流的单轮可验证步骤。我们认为这两种范式并不是相互排斥的：注重推理的Agentless训练会引入技能先验，包括定位、代码编辑和自我反思，这些都能实现高效且有效的SWE-Agent适应。在这项工作中，我们首先制定了Agentless训练配方，并推出了Kimi-Dev，这是一个开源的SWE LLM，在SWE-bench Verified上达到了60.4%，是工作流程方法中的最佳成绩。在5k个公开可用的轨迹上进行额外的SFT适应后，Kimi-Dev使SWE-Agents达到48.6%的pass@1，与Claude 3.5 Sonnet（241022版本）持平。这些结果表明，来自Agentless训练的结构化技能先验可以弥合工作流程和智能框架之间的差距，从而打造可迁移的编码代理。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.23045v2">PDF</a> 58 pages</p>
<p><strong>Summary</strong></p>
<p>大型语言模型在软件工程领域的应用日益广泛，其中SWE-bench是重要的基准测试之一。文章介绍了两种解决方案：基于多回合交互的SWE-Agent框架和基于工作流的Agentless方法。文章认为这两种范式并非相互排斥，而是可以通过无代理训练中的推理密集型技能优先事项（如本地化、代码编辑和自我反思）来实现高效的SWE-Agent适应。在此工作中，作者首先制定了无代理训练方案，并推出了Kimi-Dev这一开源软件工程师大型语言模型，在SWE-bench Verified上的表现达到60.4%，在基于工作流的方法中表现最佳。通过对5,000个公开轨迹进行附加的SFT适应，Kimi-Dev使SWE-Agents达到48.6%的pass@1率，与Claude 3.5 Sonnet（241022版本）相当。这些结果表明，来自无代理训练的结构化技能优先级可以弥合工作流和智能代理框架之间的差距，为可迁移编码代理提供可能。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>大型语言模型在软件工程领域的应用正在增长，其中SWE-bench是重要的性能基准。</li>
<li>文章介绍了两种主要的解决方案：基于多回合交互的SWE-Agent框架和基于工作流的Agentless方法。</li>
<li>文章指出这两种解决方案并非相互排斥，而是可以通过无代理训练中的技能优先事项来实现高效适应。</li>
<li>文章提出了无代理训练的方法，并介绍了Kimi-Dev这一开源软件工程师大型语言模型的表现和优势。</li>
<li>Kimi-Dev通过额外的SFT适应提高了性能，与最新的方法表现相当。</li>
<li>结构化的技能优先级可以帮助弥合工作流和智能代理框架之间的差距。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.23045">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic-private.zhihu.com/v2-cd2440f08bbf59a316cd59e6d78b8102~resize:0:q75.jpg?source=1f5c5e47&expiration=1760146092&auth_key=1760146092-0-0-90aab14dc8d24fae63376ae0ae83553e&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-b9f3ec2f3f23d4b01d457b5530fe78a1~resize:0:q75.jpg?source=1f5c5e47&expiration=1760146099&auth_key=1760146099-0-0-43f4399b2536870b05835e09db1e4a91&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-350aba9d3f02d29d655d9f39d6b7f47b~resize:0:q75.jpg?source=1f5c5e47&expiration=1760146105&auth_key=1760146105-0-0-c4e4e428318eaeeed5466d2d5e1b7491&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-c66af6bf5ea5e152ecff9cc47d8d7efc~resize:0:q75.jpg?source=1f5c5e47&expiration=1760146112&auth_key=1760146112-0-0-528f97789ad5e526ecd08e58bbb07000&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-4f2de0cca086d805c8f5d2f8dd117e15~resize:0:q75.jpg?source=1f5c5e47&expiration=1760146118&auth_key=1760146118-0-0-b8a137dec901f6855c1a0ef2b5a6bea1&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-11"><a href="#-11" class="headerlink" title=""></a></h1><h2 id="Hierarchical-Reinforcement-Learning-with-Low-Level-MPC-for-Multi-Agent-Control"><a href="#Hierarchical-Reinforcement-Learning-with-Low-Level-MPC-for-Multi-Agent-Control" class="headerlink" title="Hierarchical Reinforcement Learning with Low-Level MPC for Multi-Agent   Control"></a>Hierarchical Reinforcement Learning with Low-Level MPC for Multi-Agent   Control</h2><p><strong>Authors:Max Studt, Georg Schildbach</strong></p>
<p>Achieving safe and coordinated behavior in dynamic, constraint-rich environments remains a major challenge for learning-based control. Pure end-to-end learning often suffers from poor sample efficiency and limited reliability, while model-based methods depend on predefined references and struggle to generalize. We propose a hierarchical framework that combines tactical decision-making via reinforcement learning (RL) with low-level execution through Model Predictive Control (MPC). For the case of multi-agent systems this means that high-level policies select abstract targets from structured regions of interest (ROIs), while MPC ensures dynamically feasible and safe motion. Tested on a predator-prey benchmark, our approach outperforms end-to-end and shielding-based RL baselines in terms of reward, safety, and consistency, underscoring the benefits of combining structured learning with model-based control. </p>
<blockquote>
<p>在动态、约束丰富的环境中实现安全和协调的行为仍然是基于学习的控制面临的一个主要挑战。纯端到端学习经常面临样本效率低和可靠性有限的问题，而基于模型的方法依赖于预先定义的参考，并且在泛化方面遇到困难。我们提出了一种层次框架，它通过强化学习（RL）进行战术决策，并通过模型预测控制（MPC）进行低级执行。在多智能体系统的情况下，这意味着高级策略从结构化感兴趣区域（ROI）中选择抽象目标，而MPC确保动态可行和安全运动。在捕食者-猎物基准测试上进行的测试表明，我们的方法在奖励、安全性和一致性方面优于端到端和基于屏蔽的RL基准测试，这突出了将结构化学习与基于模型的控制相结合的好处。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.15799v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>在动态、约束丰富的环境中实现安全和协调的行为仍然是基于学习的控制面临的一个主要挑战。纯端到端学习往往存在样本效率低和可靠性有限的问题，而基于模型的方法依赖于预先定义的参考，难以推广。我们提出了一种层次框架，通过强化学习（RL）进行战术决策，通过模型预测控制（MPC）进行低级执行。在多智能体系统中，这意味着高级策略从结构化感兴趣区域（ROI）中选择抽象目标，而MPC确保动态可行和安全运动。在捕食者-猎物基准测试中，我们的方法优于端到端和基于屏蔽的RL基准测试，在奖励、安全性和一致性方面表现出色，突出了结合结构化学习与基于模型的控制的优势。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>实现安全和协调的行为在动态、约束丰富的环境中仍是主要挑战。</li>
<li>纯端到端学习存在样本效率低和可靠性有限的缺陷。</li>
<li>基于模型的方法依赖于预设参考，难以推广。</li>
<li>提出的层次框架结合了强化学习与模型预测控制。</li>
<li>多智能体系统中，高级策略从结构化感兴趣区域选择抽象目标。</li>
<li>模型预测控制确保动态可行和安全运动。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.15799">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic-private.zhihu.com/v2-bc6eef3041bcdbd468ce4d9774b2879c~resize:0:q75.jpg?source=1f5c5e47&expiration=1760146126&auth_key=1760146126-0-0-4ab7a80ab1faa41e912977719b5c6711&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-1b8735852eb03ed47344fa655c95cbce~resize:0:q75.jpg?source=1f5c5e47&expiration=1760146133&auth_key=1760146133-0-0-7f41220ef6a1d9e63de9178e4284d49d&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-9d1cd1620923fea5da54f5bfd1e805ea~resize:0:q75.jpg?source=1f5c5e47&expiration=1760146139&auth_key=1760146139-0-0-c06289320639cbe4c8bddfb7ec87b88f&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-37f5ff28d2ba108f823a4c47cf5b0149~resize:0:q75.jpg?source=1f5c5e47&expiration=1760146145&auth_key=1760146145-0-0-cd0e097ac842bed4d141c1fb7289661a&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-d3f56fde765928e2f109cb8d27a184da~resize:0:q75.jpg?source=1f5c5e47&expiration=1760146152&auth_key=1760146152-0-0-6ffa1cb97a03ba686107deea0aab5a19&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-b2a7bf4d1b2b936f8d072cf62e594c94~resize:0:q75.jpg?source=1f5c5e47&expiration=1760146158&auth_key=1760146158-0-0-b41beb35576c8f4dac5518bc3a900a35&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-bd48eef002e5ffe7919433c074380250~resize:0:q75.jpg?source=1f5c5e47&expiration=1760146164&auth_key=1760146164-0-0-7a4789c79d15bd873b33ab372faeb63b&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-d05f9a029d93bc6a1ba578ff9323075e~resize:0:q75.jpg?source=1f5c5e47&expiration=1760146171&auth_key=1760146171-0-0-69ffe96928ac7865a588fd8a0aadac96&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-12"><a href="#-12" class="headerlink" title=""></a></h1><h2 id="Neuro-Symbolic-Agents-with-Modal-Logic-for-Autonomous-Diagnostics"><a href="#Neuro-Symbolic-Agents-with-Modal-Logic-for-Autonomous-Diagnostics" class="headerlink" title="Neuro-Symbolic Agents with Modal Logic for Autonomous Diagnostics"></a>Neuro-Symbolic Agents with Modal Logic for Autonomous Diagnostics</h2><p><strong>Authors:Antonin Sulc, Thorsten Hellert</strong></p>
<p>The development of intelligent agents, particularly those powered by language models (LMs), has shown the critical role in various environments that require intelligent and autonomous decision. Environments are not passive testing grounds and they represent the data required for agents to learn and exhibit very challenging conditions that require adaptive, complex and autonomous capacity to make decisions. While the paradigm of scaling models and datasets has led to remarkable emergent capabilities, we argue that scaling the structure, fidelity, and logical consistency of agent reasoning within these environments is a crucial, yet underexplored, dimension of AI research. This paper introduces a neuro-symbolic multi-agent architecture where the belief states of individual agents are formally represented as Kripke models. This foundational choice enables them to reason about known concepts of \emph{possibility} and \emph{necessity} using the formal language of modal logic. In this work, we use of immutable, domain-specific knowledge to make infere information, which is encoded as logical constraints essential for proper diagnosis. In the proposed model, we show constraints that actively guide the hypothesis generation of LMs, effectively preventing them from reaching physically or logically untenable conclusions. In a high-fidelity simulated particle accelerator environment, our system successfully diagnoses complex, cascading failures by combining the powerful semantic intuition of LMs with the rigorous, verifiable validation of modal logic and a factual world model and showcasing a viable path toward more robust, reliable, and verifiable autonomous agents. </p>
<blockquote>
<p>智能体，特别是那些由语言模型（LMs）驱动的智能体的发展，已经显示出在各种需要智能和自主决策的环境中发挥着关键作用。环境并不是被动的测试场，它们代表着智能体所需要的数据，并且展示出各种具有挑战性的条件，这些条件需要智能体具备适应性强、复杂和自主的决策能力。尽管扩大模型和数据集的模式已经带来了显著的新兴能力，但我们认为扩大这些环境中智能体的结构、保真度和逻辑一致性是一个关键但尚未被充分研究的AI研究领域维度。本文介绍了一种神经符号多智能体架构，其中单个智能体的信念状态被形式化表示为Kripke模型。这一基本选择使他们能够利用模态逻辑的自然语言来推理“可能性”和“必要性”等已知概念。在这项工作中，我们使用不可变的领域特定知识来进行信息推断，这些信息被编码为逻辑约束，对于适当的诊断至关重要。在提出的模型中，我们展示了能够主动引导LMs假设生成的约束，有效地防止它们得出物理或逻辑上不可持续的结论。在一个高保真模拟粒子加速器环境中，我们的系统成功地结合了LMs的强大语义直觉、模态逻辑的严格可验证验证和一个事实世界模型，对复杂的连锁故障进行了诊断，并展示了一条朝着更稳健、可靠和可验证的自主智能体的可行道路。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.11943v2">PDF</a> 10 pages, 1 figure, Scaling Environments for Agents (SEA) Workshop at   NeuralIPS</p>
<p><strong>Summary</strong></p>
<p>本文探讨了智能代理的发展，特别是在需要智能和自主决策的环境中，如语言模型驱动的智能代理。文章提出了一个神经符号多代理架构，利用模态逻辑的形式语言对可能性和必要性进行推理。该架构利用领域特定知识来推断信息，并展示了指导假设生成的逻辑约束，有效防止了语言模型得出物理或逻辑上不可行的结论。在模拟粒子加速器环境中，该系统成功结合了语言模型的强大语义直觉、模态逻辑的严格验证和现实世界模型，展示了实现更稳健、可靠和可验证的自主代理的可行途径。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>智能代理在需要智能和自主决策的环境中扮演关键角色，特别是在复杂多变的环境中。</li>
<li>语言模型（LMs）是智能代理的重要组成部分，其能力需要在各种环境中进行适应和调整。</li>
<li>神经符号多代理架构利用模态逻辑的形式语言进行推理，实现对可能性和必要性的理解。</li>
<li>该架构利用领域特定知识来推断信息，这是进行适当诊断的逻辑约束的关键。</li>
<li>提出的模型展示了如何指导语言模型的假设生成，防止其得出物理或逻辑上不可行的结论。</li>
<li>在模拟粒子加速器环境中，结合语言模型的语义直觉、模态逻辑的验证和现实世界模型，实现了对复杂级联故障的稳健诊断。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.11943">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic-private.zhihu.com/v2-56c5a3768e31d5cb85f784d6b858ab48~resize:0:q75.jpg?source=1f5c5e47&expiration=1760146178&auth_key=1760146178-0-0-18d69a45c3ecc23597dd7f60caf8bb00&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-13"><a href="#-13" class="headerlink" title=""></a></h1><h2 id="Scaling-up-Multi-Turn-Off-Policy-RL-and-Multi-Agent-Tree-Search-for-LLM-Step-Provers"><a href="#Scaling-up-Multi-Turn-Off-Policy-RL-and-Multi-Agent-Tree-Search-for-LLM-Step-Provers" class="headerlink" title="Scaling up Multi-Turn Off-Policy RL and Multi-Agent Tree Search for LLM   Step-Provers"></a>Scaling up Multi-Turn Off-Policy RL and Multi-Agent Tree Search for LLM   Step-Provers</h2><p><strong>Authors:Ran Xin, Zeyu Zheng, Yanchen Nie, Kun Yuan, Xia Xiao</strong></p>
<p>The integration of Large Language Models (LLMs) into automated theorem proving has shown immense promise, yet is fundamentally constrained by challenges in scaling up both training-time reinforcement learning (RL) and inference-time compute. This paper introduces \texttt{BFS-Prover-V2}, a system designed to address this dual scaling problem. We present two primary innovations. The first is a novel multi-turn off-policy RL framework for continually improving the performance of LLM step-prover at training time. This framework, inspired by the principles of AlphaZero, utilizes a multi-stage expert iteration pipeline featuring adaptive tactic-level data filtering and periodic retraining to surmount the performance plateaus that typically curtail long-term RL in LLM-based agents. The second innovation is a planner-enhanced multi-agent search architecture that scales reasoning capabilities at inference time. This architecture employs a general reasoning model as a high-level planner to iteratively decompose complex theorems into a sequence of simpler subgoals. This hierarchical approach substantially reduces the search space, enabling a team of parallel prover agents to collaborate efficiently by leveraging a shared proof cache. We demonstrate that this dual approach to scaling yields state-of-the-art results on established formal mathematics benchmarks. \texttt{BFS-Prover-V2} achieves 95.08% and 41.4% on the MiniF2F and ProofNet test sets respectively. While demonstrated in the domain of formal mathematics, the RL and inference techniques presented in this work are of broader interest and may be applied to other domains requiring long-horizon multi-turn reasoning and complex search. </p>
<blockquote>
<p>将大型语言模型（LLM）集成到自动化定理证明中显示出巨大的潜力，但从根本上受到训练时强化学习（RL）和推理时计算扩展挑战的限制。本文介绍了<code>BFS-Prover-V2</code>系统，该系统旨在解决这一双重扩展问题。我们提出了两个主要的创新点。第一个是新型的多轮离线策略强化学习框架，旨在不断提高训练时LLM逐步证明的性能。该框架受到AlphaZero原则的启发，采用多阶段专家迭代管道，具有自适应战术级数据过滤和定期重新训练的功能，以克服性能瓶颈，这些瓶颈通常会限制基于LLM的代理的长期强化学习。第二个创新点是一个增强规划的多代理搜索架构，该架构在推理时间扩展了推理能力。该架构采用通用推理模型作为高级规划器，将复杂的定理迭代地分解为一系列更简单的子目标。这种分层方法大大减少了搜索空间，使一组并行证明代理能够高效地协作，利用共享证明缓存。我们证明了这种双重扩展方法在一系列正式的数学基准测试上达到了最新水平的结果。<code>BFS-Prover-V2</code>在MiniF2F和ProofNet测试集上分别达到了95.08%和41.4%的准确率。虽然本工作在形式数学领域得到了验证，但本工作中提出的强化学习和推理技术具有更广泛的兴趣，并可应用于需要长周期多轮推理和复杂搜索的其他领域。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.06493v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>大型语言模型（LLM）在自动化定理证明中的应用展现出巨大的潜力，但面临着训练时强化学习（RL）和推理时计算扩展的双重挑战。本文介绍了\texttt{BFS-Prover-V2}，一个旨在解决这一双重扩展问题的系统。主要创新包括训练时的新型多轮离线RL框架和推理时的规划增强多智能体搜索架构。训练时的RL框架灵感来源于AlphaZero，利用多阶段专家迭代管道、自适应战术级数据过滤和定期再训练，克服了性能瓶颈，提高了LLM步骤证明的性能。推理时的架构采用通用推理模型作为高级规划器，将复杂定理分解为一系列简单子目标。通过采用分层方法，显著减少了搜索空间，使一组并行证明智能体能够通过共享证明缓存进行有效协作。在形式数学基准测试中取得了最新结果。\texttt{BFS-Prover-V2}在MiniF2F和ProofNet测试集上的准确率分别达到95.08%和41.4%。虽然此工作展示的是在形式数学领域的应用，但提出的RL和推理技术具有更广泛的应用前景，可应用于需要长周期多轮推理和复杂搜索的其他领域。</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li><strong>LLM在自动化定理证明中的潜力与挑战</strong>：大型语言模型在自动化定理证明中展现出巨大潜力，但面临训练强化学习和推理计算扩展的双重挑战。</li>
<li><strong>训练时间的新型多轮离线RL框架</strong>：引入了一种新型的多轮离线强化学习框架，以提高LLM的性能，通过多阶段专家迭代管道等方法克服性能瓶颈。</li>
<li><strong>推理时间的规划增强多智能体搜索架构</strong>：采用通用推理模型作为高级规划器，将复杂定理分解为简单子目标，减少搜索空间，提高推理效率。</li>
<li><strong>BFS-Prover-V2系统的创新应用</strong>：系统\texttt{BFS-Prover-V2}通过结合上述两项创新，实现了在形式数学领域的先进结果。</li>
<li><strong>在MiniF2F和ProofNet测试集上的表现</strong>：\texttt{BFS-Prover-V2}在MiniF2F测试集上达到95.08%的准确率，在ProofNet测试集上达到41.4%的准确率。</li>
<li><strong>RL和推理技术的应用广泛性</strong>：虽然工作集中在形式数学领域，但提出的RL和推理技术可应用于需要长周期多轮推理和复杂搜索的其他领域。</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.06493">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic-private.zhihu.com/v2-2077e21fd42b0dc8a812878ce7c79d2d~resize:0:q75.jpg?source=1f5c5e47&expiration=1760146186&auth_key=1760146186-0-0-68fbf6978bf9d1cccafc5e5ba08fc104&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-84858c4f548f5303404a32f3ae383431~resize:0:q75.jpg?source=1f5c5e47&expiration=1760146193&auth_key=1760146193-0-0-cebdbaa9508723b723365a3721a2a6ee&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-bf9d216a016536e180306c0133831217~resize:0:q75.jpg?source=1f5c5e47&expiration=1760146199&auth_key=1760146199-0-0-910b8dd25151775c376154b56baa7ee3&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-67fc817e10239aa01fd578650e9e33d4~resize:0:q75.jpg?source=1f5c5e47&expiration=1760146206&auth_key=1760146206-0-0-66833cd994c5f725772c3bb3d1fef84d&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-14"><a href="#-14" class="headerlink" title=""></a></h1><h2 id="CoCoA-Collaborative-Chain-of-Agents-for-Parametric-Retrieved-Knowledge-Synergy"><a href="#CoCoA-Collaborative-Chain-of-Agents-for-Parametric-Retrieved-Knowledge-Synergy" class="headerlink" title="CoCoA: Collaborative Chain-of-Agents for Parametric-Retrieved Knowledge   Synergy"></a>CoCoA: Collaborative Chain-of-Agents for Parametric-Retrieved Knowledge   Synergy</h2><p><strong>Authors:Yi Jiang, Sendong Zhao, Jianbo Li, Haochun Wang, Lizhe Zhang, Yan Liu, Bing Qin</strong></p>
<p>Retrieval-Augmented Generation (RAG) enhances Large Language Models (LLMs), especially for knowledge-intensive tasks. Despite its advantages, current RAG methods often struggle to fully exploit knowledge during generation. In particular, the synergy between the model’s internal parametric knowledge and external retrieved knowledge remains limited. Retrieved contents may sometimes mislead generation, while certain generated content can guide the model toward more accurate outputs. In this work, we propose Collaborative Chain-of-Agents, a framework designed to enhance explicitly synergy over both parametric and retrieved knowledge. Specifically, we first introduce CoCoA-zero, a multi-agent RAG framework that first performs conditional knowledge induction and then reasons answers. Building on this, we develop CoCoA, a long-chain training strategy that synthesizes extended multi-agent reasoning trajectories from CoCoA-zero to fine-tune the LLM. This strategy enhances the model’s capability to explicitly integrate and jointly leverage parametric and retrieved knowledge. Experimental results demonstrate the superiority of CoCoA in open-domain QA and multi-hop QA. </p>
<blockquote>
<p>检索增强生成（RAG）技术提高了大型语言模型（LLM）的性能，特别是对于知识密集型任务。尽管具有优势，但当前的RAG方法往往难以在生成过程中充分利用知识。特别是，模型内部的参数知识与外部检索知识之间的协同作用仍然有限。检索的内容有时会误导生成，而某些生成的内容可以引导模型走向更准确的输出。在这项工作中，我们提出了协作代理链（Collaborative Chain-of-Agents）框架，该框架旨在增强参数知识和检索知识之间的明确协同。具体来说，我们首先引入了CoCoA-zero多代理RAG框架，先进行条件知识归纳，然后推理答案。在此基础上，我们开发了CoCoA长期训练策略，该策略通过合成来自CoCoA-zero的扩展多代理推理轨迹来微调LLM。这一策略提高了模型显式集成和联合利用参数知识和检索知识的能力。实验结果表明，CoCoA在开放域问答和多跳问答方面的优越性。</p>
</blockquote>
<p><strong>论文及项目相关链接</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.01696v3">PDF</a> code available at <a target="_blank" rel="noopener" href="https://github.com/liunian-Jay/CoCoA">https://github.com/liunian-Jay/CoCoA</a></p>
<p><strong>Summary</strong></p>
<p>RAG（Retrieval-Augmented Generation）模型提高了大型语言模型（LLM）在处理知识密集型任务时的性能。然而，当前RAG方法难以充分利用知识生成过程中的知识。本文提出了Collaborative Chain-of-Agents框架，旨在增强模型内部参数知识和外部检索知识的协同作用。通过引入CoCoA-zero进行条件知识归纳，并结合CoCoA进行长期训练策略，合成多智能体推理轨迹以微调LLM。实验结果表明，CoCoA在开放域问答和多跳问答中表现优异。</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>RAG模型增强了大型语言模型在知识密集型任务上的性能。</li>
<li>当前RAG方法难以充分利用生成过程中的知识。</li>
<li>Collaborative Chain-of-Agents框架旨在增强模型内部参数知识和外部检索知识的协同作用。</li>
<li>CoCoA-zero通过条件知识归纳进行推理答案。</li>
<li>CoCoA是一种长期训练策略，合成多智能体推理轨迹以微调LLM。</li>
<li>CoCoA在开放域问答和多跳问答任务中表现优越。</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.01696">Cool Papers</a></strong> </p>
<details>
  <summary>点此查看论文截图</summary>
<img src="https://pic-private.zhihu.com/v2-f86fc0c5bba386638d48b9283b1f0cbd~resize:0:q75.jpg?source=1f5c5e47&expiration=1760146214&auth_key=1760146214-0-0-1a7677637ea5fe8228389e8a1eefefe9&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-9e677ae400e70fea1dac398b99f1224b~resize:0:q75.jpg?source=1f5c5e47&expiration=1760146221&auth_key=1760146221-0-0-023ef7d8ecec8c089ef1257fc90de6f0&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
<img src="https://pic-private.zhihu.com/v2-34504f880fcf22b7b21ede0a7f221329~resize:0:q75.jpg?source=1f5c5e47&expiration=1760146228&auth_key=1760146228-0-0-25f0c203ca0e9838ca1336070f2b27f7&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" align="middle">
</details>


<h1 id="-15"><a href="#-15" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        文章作者:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        文章链接:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-10-11/Agent/">https://kedreamix.github.io/Talk2Paper/Paper/2025-10-11/Agent/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        版权声明:
                    </i>
                </span>
                <span class="reprint-info">
                    本博客所有文章除特別声明外，均采用
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    许可协议。转载请注明来源
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/Agent/">
                                    <span class="chip bg-color">Agent</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;上一篇</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-10-11/Few-Shot/">
                    <div class="card-image">
                        
                        <img src="https://pic-private.zhihu.com/v2-97c53b7e373b1b8878a6fb5bcb713222~resize:0:q75.jpg?source=1f5c5e47&expiration=1760146235&auth_key=1760146235-0-0-6e7a52425470925b291d058f3c6d0e92&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" class="responsive-img" alt="Few-Shot">
                        
                        <span class="card-title">Few-Shot</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Few-Shot 方向最新论文已更新，请持续关注 Update in 2025-10-11  The Visual Iconicity Challenge Evaluating Vision-Language Models on   Sign Language Form-Meaning Mapping
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-10-11
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Few-Shot/" class="post-category">
                                    Few-Shot
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Few-Shot/">
                        <span class="chip bg-color">Few-Shot</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-10-11/LLM/">
                    <div class="card-image">
                        
                        <img src="https://pic-private.zhihu.com/v2-a7ef7465fa414c8bad36ed951b897930~resize:0:q75.jpg?source=1f5c5e47&expiration=1760145180&auth_key=1760145180-0-0-1a40e4df6f93262ee4e95af44576d06e&protocol=v2&sampling=False&animatedImagePlayCount=1&overTime=60&incremental=False&sceneCode=article_draft_web&animatedImageAutoPlay=False&retryCount=3&precoder=False" class="responsive-img" alt="LLM">
                        
                        <span class="card-title">LLM</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            LLM 方向最新论文已更新，请持续关注 Update in 2025-10-11  NaViL Rethinking Scaling Properties of Native Multimodal Large Language   Models under Data Constraints
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-10-11
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/LLM/" class="post-category">
                                    LLM
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/LLM/">
                        <span class="chip bg-color">LLM</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- 代码语言 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span
                        class="white-color">30666.7k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- 运行天数提醒. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // 区分是否有年份.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = '本站已运行 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                daysTip = '本站已運行 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = '本站已运行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = '本站已運行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="关注我的知乎: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">知</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- 白天和黑夜主题 -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // 只在桌面版网页启用特效
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- 雪花特效 -->
    

    <!-- 鼠标星星特效 -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--腾讯兔小巢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- 动态标签 -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Σ(っ °Д °;)っ诶，页面崩溃了嘛？", clearTimeout(st)) : (document.title = "φ(゜▽゜*)♪咦，又好了！", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
