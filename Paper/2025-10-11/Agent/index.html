<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Agent">
    <meta name="description" content="Agent æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-10-11  MATRIX Multimodal Agent Tuning for Robust Tool-Use Reasoning">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>Agent | Talk2Paper</title>
    <link rel="icon" type="image/png" href="/Talk2Paper/favicon.png">
    
    <style>
        body{
            background-image: url(/Talk2Paper/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/matery.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/my.css">
<link rel="stylesheet" type="text/css" href="/Talk2Paper/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/Talk2Paper/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/Talk2Paper/css/post.css">




    



    <script src="/Talk2Paper/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: 
#FFF;
        text-align: center;
        /* loaderé¡µé¢æ¶ˆå¤±é‡‡ç”¨æ¸éšçš„æ–¹å¼*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid 
#49b1f5;
        border-right-color: 
transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: 
#49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: 
#2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px 
rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logoå‡ºç°åŠ¨ç”» */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//ä½¿ç”¨æ¸éšçš„æ–¹æ³•æ·¡å‡ºloading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//å¼ºåˆ¶æ˜¾ç¤ºloading page 1s  
    };
    loaded();
})()
</script>

 

<body>
    
        <div id="loading-container">
             <p class="loading-text">å˜˜~  æ­£åœ¨ä»æœåŠ¡å™¨å·å–é¡µé¢ . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Talk2Paper/" class="waves-effect waves-light">
                    
                    <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Talk2Paper</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Talk2Paper/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Talk2Paper/medias/talk2paper2.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Talk2Paper</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Talk2Paper/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://picx.zhimg.com/v2-032121491e3224b8e9447a818f11faf3')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Agent</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Talk2Paper/tags/Agent/">
                                <span class="chip bg-color">Agent</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Talk2Paper/categories/Agent/" class="post-category">
                                Agent
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-10-11
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2025-11-18
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    16.2k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    65 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2025-10-11-æ›´æ–°"><a href="#2025-10-11-æ›´æ–°" class="headerlink" title="2025-10-11 æ›´æ–°"></a>2025-10-11 æ›´æ–°</h1><h2 id="MATRIX-Multimodal-Agent-Tuning-for-Robust-Tool-Use-Reasoning"><a href="#MATRIX-Multimodal-Agent-Tuning-for-Robust-Tool-Use-Reasoning" class="headerlink" title="MATRIX: Multimodal Agent Tuning for Robust Tool-Use Reasoning"></a>MATRIX: Multimodal Agent Tuning for Robust Tool-Use Reasoning</h2><p><strong>Authors:Tajamul Ashraf, Umair Nawaz, Abdelrahman M. Shaker, Rao Anwer, Philip Torr, Fahad Shahbaz Khan, Salman Khan</strong></p>
<p>Vision language models (VLMs) are increasingly deployed as controllers with access to external tools for complex reasoning and decision-making, yet their effectiveness remains limited by the scarcity of high-quality multimodal trajectories and the cost of manual annotation. We address this challenge with a vision-centric agent tuning framework that automatically synthesizes multimodal trajectories, generates step-wise preference pairs, and trains a VLM controller for robust tool-use reasoning. Our pipeline first constructs M-TRACE, a large-scale dataset of 28.5K multimodal tasks with 177K verified trajectories, enabling imitation-based trajectory tuning. Building on this, we develop MATRIX Agent, a controller finetuned on M-TRACE for step-wise tool reasoning. To achieve finer alignment, we further introduce Pref-X, a set of 11K automatically generated preference pairs, and optimize MATRIX on it via step-wise preference learning. Across three benchmarks, Agent-X, GTA, and GAIA, MATRIX consistently surpasses both open- and closed-source VLMs, demonstrating scalable and effective multimodal tool use. Our data and code is avaliable at <a target="_blank" rel="noopener" href="https://github.com/mbzuai-oryx/MATRIX">https://github.com/mbzuai-oryx/MATRIX</a>. </p>
<blockquote>
<p>è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMsï¼‰è¶Šæ¥è¶Šå¤šåœ°è¢«éƒ¨ç½²ä¸ºæ§åˆ¶å™¨ï¼Œé€šè¿‡è®¿é—®å¤–éƒ¨å·¥å…·è¿›è¡Œå¤æ‚çš„æ¨ç†å’Œå†³ç­–ã€‚ç„¶è€Œï¼Œå®ƒä»¬çš„æœ‰æ•ˆæ€§ä»ç„¶å—åˆ°é«˜è´¨é‡å¤šæ¨¡å¼è½¨è¿¹ç¨€ç¼ºå’Œæ‰‹åŠ¨æ³¨é‡Šæˆæœ¬é«˜æ˜‚çš„é™åˆ¶ã€‚æˆ‘ä»¬é€šè¿‡ä»¥è§†è§‰ä¸ºä¸­å¿ƒçš„ä»£ç†è°ƒæ•´æ¡†æ¶æ¥è§£å†³è¿™ä¸€æŒ‘æˆ˜ï¼Œè¯¥æ¡†æ¶å¯è‡ªåŠ¨åˆæˆå¤šæ¨¡å¼è½¨è¿¹ï¼Œç”Ÿæˆåˆ†æ­¥åå¥½å¯¹ï¼Œå¹¶è®­ç»ƒç”¨äºç¨³å¥å·¥å…·ä½¿ç”¨æ¨ç†çš„VLMæ§åˆ¶å™¨ã€‚æˆ‘ä»¬çš„ç®¡é“é¦–å…ˆæ„å»ºM-TRACEï¼Œè¿™æ˜¯ä¸€ä¸ªåŒ…å«28.5Kä¸ªå¤šæ¨¡å¼ä»»åŠ¡çš„å¤§è§„æ¨¡æ•°æ®é›†ï¼Œå…¶ä¸­åŒ…å«17.7ä¸‡æ¡éªŒè¯è¿‡çš„è½¨è¿¹ï¼Œä»¥å®ç°åŸºäºæ¨¡ä»¿çš„è½¨è¿¹è°ƒæ•´ã€‚åœ¨æ­¤åŸºç¡€ä¸Šï¼Œæˆ‘ä»¬å¼€å‘äº†MATRIX Agentï¼Œè¿™æ˜¯ä¸€ä¸ªåœ¨M-TRACEä¸Šè¿›è¡Œå¾®è°ƒä»¥è¿›è¡Œåˆ†æ­¥å·¥å…·æ¨ç†çš„æ§åˆ¶å™¨ã€‚ä¸ºäº†å®ç°æ›´ç²¾ç»†çš„å¯¹é½ï¼Œæˆ‘ä»¬è¿›ä¸€æ­¥å¼•å…¥äº†Pref-Xï¼Œè¿™æ˜¯ä¸€ç»„è‡ªåŠ¨ç”Ÿæˆçš„åŒ…å«åå¥½å¯¹çš„å…±è®¡ä¸€ä¸‡ä¸€åƒä¸ªæ•°æ®é›†æ ·æœ¬é›†å¹¶å¯¹çŸ©é˜µè¿›è¡Œä¼˜åŒ–ä»¥è·å¾—æ¯ä¸ªæ­¥éª¤çš„æœ€ä½³é€‰æ‹©ã€‚åœ¨Agent-Xã€GTAå’ŒGAIAä¸‰ä¸ªåŸºå‡†æµ‹è¯•ä¸­ï¼ŒMATRIXçš„è¡¨ç°å§‹ç»ˆè¶…è¿‡äº†å¼€æºå’Œé—­æºçš„VLMsï¼Œè¯æ˜äº†å…¶å¯æ‰©å±•æ€§å’Œæœ‰æ•ˆçš„å¤šæ¨¡å¼å·¥å…·ä½¿ç”¨èƒ½åŠ›ã€‚æˆ‘ä»¬çš„æ•°æ®å’Œä»£ç å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/mbzuai-oryx/MATRIX%E4%B8%8A%E8%8E%B7%E5%8F%96%E3%80%82">https://github.com/mbzuai-oryx/MATRIXä¸Šè·å–ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.08567v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡ä»‹ç»äº†ä¸€ä¸ªä»¥è§†è§‰ä¸ºä¸­å¿ƒçš„ä»£ç†è°ƒæ•´æ¡†æ¶ï¼Œè¯¥æ¡†æ¶èƒ½å¤Ÿè‡ªåŠ¨åˆæˆå¤šæ¨¡å¼è½¨è¿¹ï¼Œç”Ÿæˆæ­¥éª¤å¼åå¥½å¯¹ï¼Œå¹¶è®­ç»ƒç”¨äºç¨³å¥å·¥å…·ä½¿ç”¨æ¨ç†çš„VLMæ§åˆ¶å™¨ã€‚è¯¥ç ”ç©¶æ„å»ºäº†ä¸€ä¸ªå¤§è§„æ¨¡æ•°æ®é›†M-TRACEï¼Œå¹¶å¼€å‘äº†MATRIX Agentæ§åˆ¶å™¨ï¼Œåœ¨M-TRACEä¸Šè¿›è¡Œå¾®è°ƒä»¥å®ç°é€æ­¥å·¥å…·æ¨ç†ã€‚æ­¤å¤–ï¼Œä¸ºäº†æ›´ç²¾ç»†çš„å¯¹é½ï¼Œç ”ç©¶è¿˜å¼•å…¥äº†è‡ªåŠ¨ç”Ÿæˆçš„åå¥½å¯¹Pref-Xï¼Œå¹¶é€šè¿‡é€æ­¥åå¥½å­¦ä¹ ä¼˜åŒ–MATRIXã€‚åœ¨ä¸‰ä¸ªåŸºå‡†æµ‹è¯•ä¸Šï¼ŒMATRIXå‡è¶…è¿‡äº†å¼€æºå’Œé—­æºçš„VLMsï¼Œè¯æ˜äº†å…¶å¤šæ¨¡å¼å·¥å…·ä½¿ç”¨çš„å¯æ‰©å±•æ€§å’Œæœ‰æ•ˆæ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>VLMsä½œä¸ºæ§åˆ¶å™¨åœ¨å¤æ‚æ¨ç†å’Œå†³ç­–åˆ¶å®šä¸­çš„åº”ç”¨è¶Šæ¥è¶Šå¹¿æ³›ï¼Œä½†é«˜è´¨é‡çš„å¤šæ¨¡å¼è½¨è¿¹çš„ç¨€ç¼ºæ€§å’Œæ‰‹åŠ¨æ ‡æ³¨çš„æˆæœ¬é™åˆ¶äº†å…¶æœ‰æ•ˆæ€§ã€‚</li>
<li>ç ”ç©¶æå‡ºäº†ä¸€ç§ä»¥è§†è§‰ä¸ºä¸­å¿ƒçš„ä»£ç†è°ƒæ•´æ¡†æ¶ï¼Œè¯¥æ¡†æ¶èƒ½å¤Ÿè‡ªåŠ¨åˆæˆå¤šæ¨¡å¼è½¨è¿¹ï¼Œæœ‰åŠ©äºè§£å†³VLMsé¢ä¸´çš„ä¸Šè¿°æŒ‘æˆ˜ã€‚</li>
<li>æ„å»ºäº†ä¸€ä¸ªå¤§è§„æ¨¡æ•°æ®é›†M-TRACEï¼ŒåŒ…å«28.5Kå¤šæ¨¡å¼ä»»åŠ¡å’Œ177KéªŒè¯è½¨è¿¹ï¼Œä¸ºåŸºäºæ¨¡ä»¿çš„è½¨è¿¹è°ƒæ•´æä¾›äº†å¯èƒ½ã€‚</li>
<li>å¼€å‘äº†MATRIX Agentæ§åˆ¶å™¨ï¼Œåœ¨M-TRACEä¸Šè¿›è¡Œå¾®è°ƒï¼Œå®ç°é€æ­¥å·¥å…·æ¨ç†ã€‚</li>
<li>å¼•å…¥äº†è‡ªåŠ¨ç”Ÿæˆçš„åå¥½å¯¹Pref-Xï¼Œå®ç°æ›´ç²¾ç»†çš„å¯¹é½ï¼Œå¹¶é€šè¿‡é€æ­¥åå¥½å­¦ä¹ ä¼˜åŒ–MATRIXã€‚</li>
<li>MATRIXåœ¨ä¸‰ä¸ªåŸºå‡†æµ‹è¯•ä¸Šçš„è¡¨ç°å‡è¶…è¿‡äº†å¼€æºå’Œé—­æºçš„VLMsï¼Œè¯æ˜äº†å…¶å¤šæ¨¡å¼å·¥å…·ä½¿ç”¨çš„æœ‰æ•ˆæ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.08567">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-28ddb784a489005dee88460b30fc8aeb" align="middle">
<img src="https://picx.zhimg.com/v2-c051f3faa5b5b1e5db4c849cb1025d9f" align="middle">
<img src="https://picx.zhimg.com/v2-2369f652f8a3e7a5d0a026d2529cd795" align="middle">
</details>


<h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="CoMAS-Co-Evolving-Multi-Agent-Systems-via-Interaction-Rewards"><a href="#CoMAS-Co-Evolving-Multi-Agent-Systems-via-Interaction-Rewards" class="headerlink" title="CoMAS: Co-Evolving Multi-Agent Systems via Interaction Rewards"></a>CoMAS: Co-Evolving Multi-Agent Systems via Interaction Rewards</h2><p><strong>Authors:Xiangyuan Xue, Yifan Zhou, Guibin Zhang, Zaibin Zhang, Yijiang Li, Chen Zhang, Zhenfei Yin, Philip Torr, Wanli Ouyang, Lei Bai</strong></p>
<p>Self-evolution is a central research topic in enabling large language model (LLM)-based agents to continually improve their capabilities after pretraining. Recent research has witnessed a transition from reinforcement learning (RL)-free to RL-based methods. Current RL-based methods either rely on dense external reward signals or extract intrinsic reward signals from LLMs themselves. However, these approaches diverge from the self-evolution mechanisms observed in human intelligence, where individuals learn and improve through mutual discussion and collaboration. In this work, we introduce Co-Evolving Multi-Agent Systems (CoMAS), a novel framework that enables agents to improve autonomously by learning from inter-agent interactions without external supervision. CoMAS generates intrinsic rewards from rich discussion dynamics, employs an LLM-as-a-judge mechanism to formulate these rewards, and optimizes each agentâ€™s policy through RL, thereby enabling decentralized and scalable co-evolution. Experimental results demonstrate that CoMAS consistently outperforms untrained agents and achieves state-of-the-art performance across most evaluation settings. Ablation studies confirm the necessity of interaction-based reward signals and reveal promising scalability as the number and diversity of agents increase. These findings establish CoMAS as a novel and effective paradigm for self-evolution in LLM-based agents. </p>
<blockquote>
<p>è‡ªæˆ‘è¿›åŒ–æ˜¯ä½¿åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹çš„æ™ºèƒ½ä½“åœ¨é¢„è®­ç»ƒåèƒ½å¤ŸæŒç»­æé«˜å…¶èƒ½åŠ›çš„ä¸€ä¸ªæ ¸å¿ƒç ”ç©¶è¯¾é¢˜ã€‚æœ€è¿‘çš„ç ”ç©¶è§è¯äº†ä»éå¼ºåŒ–å­¦ä¹ å‘åŸºäºå¼ºåŒ–å­¦ä¹ çš„æ–¹æ³•çš„è½¬å˜ã€‚å½“å‰çš„åŸºäºå¼ºåŒ–å­¦ä¹ çš„æ–¹æ³•è¦ä¹ˆä¾èµ–äºå¯†é›†çš„å¤–éƒ¨å¥–åŠ±ä¿¡å·ï¼Œè¦ä¹ˆä»å¤§å‹è¯­è¨€æ¨¡å‹æœ¬èº«æå–å†…åœ¨å¥–åŠ±ä¿¡å·ã€‚ç„¶è€Œï¼Œè¿™äº›æ–¹æ³•ä¸äººç±»æ™ºèƒ½ä¸­çš„è‡ªæˆ‘è¿›åŒ–æœºåˆ¶èƒŒé“è€Œé©°ï¼Œäººç±»é€šè¿‡ç›¸äº’è®¨è®ºå’Œåä½œæ¥å­¦ä¹ å’Œæé«˜ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬å¼•å…¥äº†ååŒè¿›åŒ–å¤šæ™ºèƒ½ä½“ç³»ç»Ÿï¼ˆCoMASï¼‰ï¼Œè¿™æ˜¯ä¸€ä¸ªæ–°å‹æ¡†æ¶ï¼Œä½¿æ™ºèƒ½ä½“èƒ½å¤Ÿé€šè¿‡ä»æ™ºèƒ½ä½“ä¹‹é—´çš„äº¤äº’ä¸­å­¦ä¹ æ¥è‡ªä¸»æé«˜ï¼Œæ— éœ€å¤–éƒ¨ç›‘ç£ã€‚CoMASä»ä¸°å¯Œçš„è®¨è®ºåŠ¨æ€ä¸­äº§ç”Ÿå†…åœ¨å¥–åŠ±ï¼Œé‡‡ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ä½œä¸ºè¯„åˆ¤æœºåˆ¶æ¥åˆ¶å®šè¿™äº›å¥–åŠ±ï¼Œå¹¶é€šè¿‡å¼ºåŒ–å­¦ä¹ ä¼˜åŒ–æ¯ä¸ªæ™ºèƒ½ä½“çš„ç­–ç•¥ï¼Œä»è€Œå®ç°åˆ†å¸ƒå¼å’Œå¯æ‰©å±•çš„ååŒè¿›åŒ–ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒCoMASåœ¨å¤§å¤šæ•°æƒ…å†µä¸‹éƒ½ä¼˜äºæœªç»è®­ç»ƒçš„æ™ºèƒ½ä½“ï¼Œå¹¶åœ¨å¤§å¤šæ•°è¯„ä¼°ç¯å¢ƒä¸­è¾¾åˆ°äº†æœ€æ–°æŠ€æœ¯æ°´å¹³ã€‚æ¶ˆèç ”ç©¶è¯å®äº†åŸºäºäº¤äº’çš„å¥–åŠ±ä¿¡å·çš„å¿…è¦æ€§ï¼Œå¹¶æ˜¾ç¤ºå‡ºéšç€æ™ºèƒ½ä½“æ•°é‡å’Œå¤šæ ·æ€§çš„å¢åŠ ï¼Œå…¶å¯æ‰©å±•æ€§å‰æ™¯å¹¿é˜”ã€‚è¿™äº›å‘ç°ç¡®ç«‹äº†CoMASåœ¨å¤§å‹è¯­è¨€æ¨¡å‹æ™ºèƒ½ä½“è‡ªæˆ‘è¿›åŒ–é¢†åŸŸä½œä¸ºä¸€ç§æ–°å‹æœ‰æ•ˆèŒƒå¼ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.08529v1">PDF</a> </p>
<p><strong>Summary</strong><br>è‡ªæˆ‘è¿›åŒ–æ˜¯ä½¿åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„ä»£ç†åœ¨é¢„è®­ç»ƒåèƒ½å¤ŸæŒç»­æ”¹è¿›å…¶èƒ½åŠ›çš„ç ”ç©¶æ ¸å¿ƒã€‚è¿‘æœŸç ”ç©¶ç»å†äº†ä»æ— å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰åˆ°RLæ–¹æ³•çš„è¿‡ç¨‹è½¬å˜ã€‚å½“å‰RLæ–¹æ³•ä¾èµ–äºå¯†é›†çš„å¤–ç•Œå¥–åŠ±ä¿¡å·æˆ–ä»LLMæœ¬èº«æå–çš„å†…åœ¨å¥–åŠ±ä¿¡å·ã€‚ç„¶è€Œï¼Œè¿™äº›æ–¹æ³•ä¸äººç±»æ™ºèƒ½ä¸­çš„è‡ªæˆ‘è¿›åŒ–æœºåˆ¶ç›¸æ‚–ç¦»ï¼Œä¸ªäººé€šè¿‡ç›¸äº’è®¨è®ºå’Œåä½œå­¦ä¹ å’Œæé«˜ã€‚åœ¨æ­¤ç ”ç©¶ä¸­ï¼Œæˆ‘ä»¬å¼•å…¥äº†ååŒè¿›åŒ–å¤šæ™ºèƒ½ä½“ç³»ç»Ÿï¼ˆCoMASï¼‰ï¼Œè¿™æ˜¯ä¸€ç§æ–°å‹æ¡†æ¶ï¼Œé€šè¿‡ä»æ™ºèƒ½ä½“é—´äº’åŠ¨å­¦ä¹ å®ç°æ— éœ€å¤–éƒ¨ç›‘ç£çš„è‡ªä¸»è¿›åŒ–æ”¹è¿›ã€‚CoMASé€šè¿‡ä¸°å¯Œçš„è®¨è®ºåŠ¨æ€ç”Ÿæˆå†…åœ¨å¥–åŠ±ï¼Œåˆ©ç”¨LLMä½œä¸ºè¯„åˆ¤æœºåˆ¶æ¥åˆ¶å®šè¿™äº›å¥–åŠ±ï¼Œå¹¶é€šè¿‡RLä¼˜åŒ–æ¯ä¸ªæ™ºèƒ½ä½“çš„ç­–ç•¥ï¼Œå®ç°åˆ†æ•£å’Œå¯æ‰©å±•çš„ååŒè¿›åŒ–ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒCoMASåœ¨å„ç§è¯„ä¼°è®¾ç½®ä¸­è¡¨ç°æœ€ä½³ã€‚åˆ é™¤ç ”ç©¶è¯å®åŸºäºäº’åŠ¨å¥–åŠ±ä¿¡å·çš„å¿…è¦æ€§ï¼Œéšç€æ™ºèƒ½ä½“æ•°é‡å’Œå¤šæ ·æ€§çš„å¢åŠ æ˜¾ç¤ºå‡ºæœ‰å‰æ™¯çš„å¯æ‰©å±•æ€§ã€‚è¿™äº›å‘ç°ç¡®ç«‹äº†CoMASåœ¨LLMæ™ºèƒ½ä½“è‡ªæˆ‘è¿›åŒ–é¢†åŸŸçš„æ–°é¢–æ€§å’Œæœ‰æ•ˆæ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>CoMASæ˜¯ä¸€ä¸ªæ–°å‹æ¡†æ¶ï¼Œå…è®¸åŸºäºLLMçš„ä»£ç†é€šè¿‡æ™ºèƒ½ä½“é—´çš„äº’åŠ¨å­¦ä¹ å®ç°è‡ªä¸»è¿›åŒ–æ”¹è¿›ã€‚</li>
<li>è¯¥æ¡†æ¶é€šè¿‡ä¸°å¯Œçš„è®¨è®ºåŠ¨æ€ç”Ÿæˆå†…åœ¨å¥–åŠ±ï¼Œä¸åŒäºä¾èµ–å¤–éƒ¨å¥–åŠ±ä¿¡å·æˆ–ä»…ä»LLMä¸­æå–å†…åœ¨å¥–åŠ±ä¿¡å·çš„æ–¹æ³•ã€‚</li>
<li>CoMASåˆ©ç”¨LLMä½œä¸ºè¯„åˆ¤æœºåˆ¶æ¥åˆ¶å®šå¥–åŠ±ï¼Œä¼˜åŒ–æ¯ä¸ªæ™ºèƒ½ä½“çš„ç­–ç•¥ï¼Œå®ç°åˆ†æ•£å’Œå¯æ‰©å±•çš„ååŒè¿›åŒ–ã€‚</li>
<li>å®éªŒç»“æœæ˜¾ç¤ºCoMASåœ¨å„ç§è¯„ä¼°è®¾ç½®ä¸­è¡¨ç°æœ€ä½³ï¼Œæ˜¾ç¤ºå‡ºå…¶æœ‰æ•ˆæ€§å’Œæ–°é¢–æ€§ã€‚</li>
<li>åˆ é™¤ç ”ç©¶è¯å®äº†äº’åŠ¨å¥–åŠ±ä¿¡å·çš„å¿…è¦æ€§ï¼Œè¿™æ˜¯CoMASæ¡†æ¶æˆåŠŸçš„å…³é”®å› ç´ ä¹‹ä¸€ã€‚</li>
<li>éšç€æ™ºèƒ½ä½“æ•°é‡å’Œå¤šæ ·æ€§çš„å¢åŠ ï¼ŒCoMASæ˜¾ç¤ºå‡ºæœ‰å‰æ™¯çš„å¯æ‰©å±•æ€§ã€‚</li>
<li>è¯¥ç ”ç©¶ä¸ºåŸºäºLLMçš„ä»£ç†çš„è‡ªæˆ‘è¿›åŒ–æä¾›äº†ä¸€ç§æ–°çš„å’Œæœ‰æ•ˆçš„é€”å¾„ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.08529">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-c6c34837bff0f4ad8d24310829b02e6a" align="middle">
<img src="https://picx.zhimg.com/v2-949738b7676f3792c403fa91a7b3982e" align="middle">
<img src="https://picx.zhimg.com/v2-6e70f4c8c542fc2eed746a939aef97ed" align="middle">
</details>


<h1 id="-1"><a href="#-1" class="headerlink" title=""></a></h1><h2 id="AutoMLGen-Navigating-Fine-Grained-Optimization-for-Coding-Agents"><a href="#AutoMLGen-Navigating-Fine-Grained-Optimization-for-Coding-Agents" class="headerlink" title="AutoMLGen: Navigating Fine-Grained Optimization for Coding Agents"></a>AutoMLGen: Navigating Fine-Grained Optimization for Coding Agents</h2><p><strong>Authors:Shangheng Du, Xiangchao Yan, Dengyang Jiang, Jiakang Yuan, Yusong Hu, Xin Li, Liang He, Bo Zhang, Lei Bai</strong></p>
<p>Large language models (LLMs) have shown impressive performance in general programming tasks. However, in Machine Learning Engineering (MLE) scenarios such as AutoML and Kaggle competitions, achieving high performance depends heavily on expert intervention and repeated adjustments rather than simply generating correct code. When applied directly to these tasks, LLMs often lack fine-grained domain priors, and existing MLE approaches that use linear or tree-structured searches limit knowledge transfer to adjacent hierarchical links. As a result, they cannot leverage past full trajectories or share information across branches, limiting self-evolving ability and search space diversity. To address these limitations, we introduce AutoMLGen, an LLM-based coding agent that integrates a domain knowledge base for high-quality prior guidance and Monte Carlo Graph Search (MCGS) for efficient exploration. MCGS retains the tree-guided exploration of MCTS while embedding a graph structure into the expansion stage to enable dynamic path reorganization, historical trajectory reuse, and multi-solution fusion to support both self-evolution and collaborative learning. Combined with fine-grained operator sets, this design improves stability and accelerates convergence. Evaluation on the MLE-Bench shows that AutoMLGen achieves state-of-the-art performance in numerous dimensions, such as the average medal rate and the valid submission rate, under a 12-hour budget (half the standard runtime). The code is available at <a target="_blank" rel="noopener" href="https://github.com/Alpha-Innovator/InternAgent">https://github.com/Alpha-Innovator/InternAgent</a>. </p>
<blockquote>
<p>å¤§è§„æ¨¡è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨ä¸€èˆ¬ç¼–ç¨‹ä»»åŠ¡ä¸­è¡¨ç°å‡ºäº†ä»¤äººå°è±¡æ·±åˆ»çš„æ€§èƒ½ã€‚ç„¶è€Œï¼Œåœ¨æœºå™¨å­¦ä¹ å·¥ç¨‹ï¼ˆMLEï¼‰åœºæ™¯ï¼Œå¦‚AutoMLå’ŒKaggleç«èµ›ä¸­ï¼Œå®ç°é«˜æ€§èƒ½å¾ˆå¤§ç¨‹åº¦ä¸Šä¾èµ–äºä¸“å®¶å¹²é¢„å’Œé‡å¤è°ƒæ•´ï¼Œè€Œä¸æ˜¯ç®€å•åœ°ç”Ÿæˆæ­£ç¡®ä»£ç ã€‚å½“ç›´æ¥åº”ç”¨äºè¿™äº›ä»»åŠ¡æ—¶ï¼ŒLLMå¾€å¾€ç¼ºä¹ç²¾ç»†çš„åŸŸå…ˆéªŒçŸ¥è¯†ï¼Œè€Œç°æœ‰çš„MLEæ–¹æ³•ä½¿ç”¨çº¿æ€§æˆ–æ ‘çŠ¶æœç´¢ï¼Œå°†çŸ¥è¯†è½¬ç§»é™åˆ¶åœ¨ç›¸é‚»çš„å±‚æ¬¡é“¾æ¥ä¸Šã€‚å› æ­¤ï¼Œå®ƒä»¬æ— æ³•åˆ©ç”¨è¿‡å»çš„å®Œæ•´è½¨è¿¹æˆ–åœ¨å„åˆ†æ”¯ä¹‹é—´å…±äº«ä¿¡æ¯ï¼Œé™åˆ¶äº†è‡ªæˆ‘è¿›åŒ–èƒ½åŠ›å’Œæœç´¢ç©ºé—´çš„å¤šæ ·æ€§ã€‚ä¸ºäº†è§£å†³è¿™äº›é™åˆ¶ï¼Œæˆ‘ä»¬å¼•å…¥äº†AutoMLGenï¼Œè¿™æ˜¯ä¸€ä¸ªåŸºäºLLMçš„ç¼–ç ä»£ç†ï¼Œå®ƒæ•´åˆäº†é¢†åŸŸçŸ¥è¯†åº“è¿›è¡Œé«˜è´¨é‡çš„å‰æœŸæŒ‡å¯¼ï¼Œå¹¶é‡‡ç”¨è’™ç‰¹å¡ç½—å›¾æœç´¢ï¼ˆMCGSï¼‰è¿›è¡Œæœ‰æ•ˆæ¢ç´¢ã€‚MCGSä¿ç•™äº†MCTSçš„æ ‘çŠ¶å¼•å¯¼æ¢ç´¢ï¼ŒåŒæ—¶åœ¨æ‰©å±•é˜¶æ®µåµŒå…¥å›¾ç»“æ„ï¼Œä»¥å®ç°åŠ¨æ€è·¯å¾„é‡ç»„ã€å†å²è½¨è¿¹é‡ç”¨å’Œå¤šè§£å†³æ–¹æ¡ˆèåˆï¼Œä»¥æ”¯æŒè‡ªæˆ‘è¿›åŒ–å’Œåä½œå­¦ä¹ ã€‚ç»“åˆç²¾ç»†çš„æ“ä½œé›†åˆï¼Œè¿™ç§è®¾è®¡æé«˜äº†ç¨³å®šæ€§å¹¶åŠ é€Ÿäº†æ”¶æ•›ã€‚åœ¨MLE-Benchä¸Šçš„è¯„ä¼°è¡¨æ˜ï¼ŒAutoMLGenåœ¨å¹³å‡å¥–ç‰Œç‡å’Œæœ‰æ•ˆæäº¤ç‡ç­‰å¤šä¸ªç»´åº¦ä¸Šå®ç°äº†å“è¶Šçš„æ€§èƒ½ï¼Œåœ¨12å°æ—¶é¢„ç®—ï¼ˆæ ‡å‡†è¿è¡Œæ—¶çš„ä¸€åŠï¼‰å†…è¾¾åˆ°ä¸šç•Œé¢†å…ˆæ°´å¹³ã€‚ä»£ç å¯åœ¨<a target="_blank" rel="noopener" href="https://github.com/Alpha-Innovator/InternAgent%E4%B8%8A%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/Alpha-Innovator/InternAgentä¸Šæ‰¾åˆ°ã€‚</a></p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.08511v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨é€šç”¨ç¼–ç¨‹ä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ï¼Œä½†åœ¨æœºå™¨å­¦ä¹ å·¥ç¨‹ï¼ˆMLEï¼‰åœºæ™¯å¦‚AutoMLå’ŒKaggleç«èµ›ä¸­ï¼Œå®ç°é«˜æ€§èƒ½æ›´å¤šä¾èµ–äºä¸“å®¶å¹²é¢„å’Œé‡å¤è°ƒæ•´ï¼Œè€Œéä»…ç”Ÿæˆæ­£ç¡®ä»£ç ã€‚é’ˆå¯¹LLMsåœ¨è¿™äº›ä»»åŠ¡ä¸­çš„å±€é™æ€§ï¼Œå¦‚ç¼ºä¹ç²¾ç»†é¢†åŸŸå…ˆéªŒçŸ¥è¯†å’Œç°æœ‰MLEæ–¹æ³•çš„çŸ¥è¯†è½¬ç§»é™åˆ¶ï¼Œæˆ‘ä»¬æå‡ºäº†AutoMLGenï¼Œä¸€ä¸ªåŸºäºLLMçš„ç¼–ç ä»£ç†ï¼Œé›†æˆäº†é¢†åŸŸçŸ¥è¯†åº“ä»¥æä¾›é«˜è´¨é‡å…ˆéªŒæŒ‡å¯¼ï¼Œå¹¶é‡‡ç”¨è’™ç‰¹å¡æ´›å›¾æœç´¢ï¼ˆMCGSï¼‰è¿›è¡Œé«˜æ•ˆæ¢ç´¢ã€‚MCGSä¿ç•™äº†æ ‘å¼•å¯¼æ¢ç´¢çš„åŒæ—¶ï¼Œåœ¨æ‰©å±•é˜¶æ®µåµŒå…¥å›¾ç»“æ„ï¼Œå®ç°åŠ¨æ€è·¯å¾„é‡ç»„ã€å†å²è½¨è¿¹é‡ç”¨å’Œå¤šè§£å†³æ–¹æ¡ˆèåˆï¼Œæ”¯æŒè‡ªæˆ‘è¿›åŒ–å’Œåä½œå­¦ä¹ ã€‚ç»“åˆç²¾ç»†æ“ä½œé›†ï¼Œè¿™ç§è®¾è®¡æé«˜äº†ç¨³å®šæ€§å¹¶åŠ é€Ÿäº†æ”¶æ•›ã€‚åœ¨MLE-Benchä¸Šçš„è¯„ä¼°æ˜¾ç¤ºï¼ŒAutoMLGenåœ¨å¹³å‡å¥–ç‰Œç‡å’Œæœ‰æ•ˆæäº¤ç‡ç­‰å¤šä¸ªç»´åº¦ä¸Šå®ç°äº†å“è¶Šæ€§èƒ½ï¼Œå¹¶åœ¨12å°æ—¶é¢„ç®—å†…ï¼ˆä¸ºæ ‡å‡†è¿è¡Œæ—¶çš„ä¸€åŠï¼‰è¾¾åˆ°äº†é¢†å…ˆæ°´å¹³ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨ç¼–ç¨‹ä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ï¼Œä½†åœ¨æœºå™¨å­¦ä¹ å·¥ç¨‹ï¼ˆMLEï¼‰åœºæ™¯ä¸­å®ç°é«˜æ€§èƒ½éœ€ä¾èµ–ä¸“å®¶å¹²é¢„ã€‚</li>
<li>LLMsåœ¨MLEä»»åŠ¡ä¸­ç¼ºä¹ç²¾ç»†é¢†åŸŸå…ˆéªŒçŸ¥è¯†ã€‚</li>
<li>ç°æœ‰MLEæ–¹æ³•çš„çŸ¥è¯†è½¬ç§»ä»…é™äºç›¸é‚»å±‚æ¬¡é“¾æ¥ï¼Œæ— æ³•åˆ©ç”¨è¿‡å»çš„å…¨è½¨è¿¹æˆ–è·¨åˆ†æ”¯åˆ†äº«ä¿¡æ¯ã€‚</li>
<li>å¼•å…¥AutoMLGenï¼Œä¸€ä¸ªåŸºäºLLMçš„ç¼–ç ä»£ç†ï¼Œé›†æˆäº†é¢†åŸŸçŸ¥è¯†åº“å’Œè’™ç‰¹å¡æ´›å›¾æœç´¢ï¼ˆMCGSï¼‰ã€‚</li>
<li>MCGSç»“åˆæ ‘å¼•å¯¼æ¢ç´¢å’Œå›¾ç»“æ„ï¼Œå®ç°åŠ¨æ€è·¯å¾„é‡ç»„ã€å†å²è½¨è¿¹é‡ç”¨å’Œå¤šè§£å†³æ–¹æ¡ˆèåˆã€‚</li>
<li>AutoMLGenè®¾è®¡æé«˜äº†ç¨³å®šæ€§å¹¶åŠ é€Ÿäº†æ”¶æ•›ï¼Œæ”¯æŒè‡ªæˆ‘è¿›åŒ–å’Œåä½œå­¦ä¹ ã€‚</li>
<li>åœ¨MLE-Benchä¸Šçš„è¯„ä¼°æ˜¾ç¤ºï¼ŒAutoMLGenå®ç°äº†å“è¶Šæ€§èƒ½ï¼Œå¹¶åœ¨å¤šä¸ªç»´åº¦ä¸Šè¾¾åˆ°é¢†å…ˆæ°´å¹³ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.08511">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-2f78f8ab4f3917a7f0f379e1d3b0dd5e" align="middle">
<img src="https://picx.zhimg.com/v2-8d63880a4d4f492ba270657dbc5b72de" align="middle">
</details>


<h1 id="-2"><a href="#-2" class="headerlink" title=""></a></h1><h2 id="Iterated-Agent-for-Symbolic-Regression"><a href="#Iterated-Agent-for-Symbolic-Regression" class="headerlink" title="Iterated Agent for Symbolic Regression"></a>Iterated Agent for Symbolic Regression</h2><p><strong>Authors:Zhuo-Yang Song, Zeyu Cai, Shutao Zhang, Jiashen Wei, Jichen Pan, Shi Qiu, Qing-Hong Cao, Tie-Jiun Hou, Xiaohui Liu, Ming-xing Luo, Hua Xing Zhu</strong></p>
<p>Symbolic regression (SR), the automated discovery of mathematical expressions from data, is a cornerstone of scientific inquiry. However, it is often hindered by the combinatorial explosion of the search space and a tendency to overfit. Popular methods, rooted in genetic programming, explore this space syntactically, often yielding overly complex, uninterpretable models. This paper introduces IdeaSearchFitter, a framework that employs Large Language Models (LLMs) as semantic operators within an evolutionary search. By generating candidate expressions guided by natural-language rationales, our method biases discovery towards models that are not only accurate but also conceptually coherent and interpretable. We demonstrate IdeaSearchFitterâ€™s efficacy across diverse challenges: it achieves competitive, noise-robust performance on the Feynman Symbolic Regression Database (FSReD), outperforming several strong baselines; discovers mechanistically aligned models with good accuracy-complexity trade-offs on real-world data; and derives compact, physically-motivated parametrizations for Parton Distribution Functions in a frontier high-energy physics application. IdeaSearchFitter is a specialized module within our broader iterated agent framework, IdeaSearch, which is publicly available at <a target="_blank" rel="noopener" href="https://www.ideasearch.cn/">https://www.ideasearch.cn/</a>. </p>
<blockquote>
<p>ç¬¦å·å›å½’ï¼ˆSRï¼‰æ˜¯ä»æ•°æ®ä¸­è‡ªåŠ¨å‘ç°æ•°å­¦è¡¨è¾¾å¼çš„è¿‡ç¨‹ï¼Œæ˜¯ç§‘å­¦ç ”ç©¶çš„åŸºçŸ³ã€‚ç„¶è€Œï¼Œå®ƒå¸¸å¸¸å—åˆ°æœç´¢ç©ºé—´ç»„åˆçˆ†ç‚¸å’Œè¿‡åº¦æ‹Ÿåˆçš„é˜»ç¢ã€‚åŸºäºé—ä¼ ç¼–ç¨‹çš„æµè¡Œæ–¹æ³•ä»è¯­æ³•è§’åº¦æ¢ç´¢è¿™ä¸ªç©ºé—´ï¼Œé€šå¸¸ä¼šäº§ç”Ÿè¿‡äºå¤æ‚ä¸”ä¸å¯è§£é‡Šçš„æ¨¡å‹ã€‚æœ¬æ–‡ä»‹ç»äº†IdeaSearchFitteræ¡†æ¶ï¼Œå®ƒé‡‡ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä½œä¸ºè¿›åŒ–æœç´¢ä¸­çš„è¯­ä¹‰è¿ç®—ç¬¦ã€‚é€šè¿‡ä»¥è‡ªç„¶è¯­è¨€ç†ç”±ä¸ºæŒ‡å¯¼ç”Ÿæˆå€™é€‰è¡¨è¾¾å¼ï¼Œæˆ‘ä»¬çš„æ–¹æ³•ä½¿å‘ç°åå‘äºæ—¢å‡†ç¡®åˆæ¦‚å¿µè¿è´¯å’Œå¯è§£é‡Šçš„æ¨¡å‹ã€‚æˆ‘ä»¬å±•ç¤ºäº†IdeaSearchFitteråœ¨ä¸åŒæŒ‘æˆ˜ä¸­çš„æœ‰æ•ˆæ€§ï¼šå®ƒåœ¨Feynmanç¬¦å·å›å½’æ•°æ®åº“ï¼ˆFSReDï¼‰ä¸Šå®ç°äº†å…·æœ‰ç«äº‰åŠ›çš„å™ªå£°é²æ£’æ€§èƒ½ï¼Œè¶…è¶Šäº†å¤šä¸ªå¼ºå¤§çš„åŸºçº¿ï¼›åœ¨çœŸå®ä¸–ç•Œæ•°æ®ä¸Šå‘ç°äº†å…·æœ‰è‰¯å¥½ç²¾åº¦å¤æ‚æ€§æƒè¡¡çš„æœºæ¢°å¯¹é½æ¨¡å‹ï¼›å¹¶åœ¨å‰æ²¿é«˜èƒ½ç‰©ç†åº”ç”¨ä¸­æ¨å¯¼å‡ºäº†ç´§å‡‘çš„ç‰©ç†é©±åŠ¨å‚æ•°åŒ–ç²’å­åˆ†å¸ƒå‡½æ•°ã€‚IdeaSearchFitteræ˜¯æˆ‘ä»¬æ›´å¹¿æ³›çš„è¿­ä»£ä»£ç†æ¡†æ¶IdeaSearchä¸­çš„ä¸“ç”¨æ¨¡å—ï¼Œå…¬å¼€å¯è®¿é—®ç½‘å€ä¸ºï¼š<a target="_blank" rel="noopener" href="https://www.ideasearch.cn/">https://www.ideasearch.cn/</a>.</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.08317v1">PDF</a> 45 pages, 22 figures, 8 tables</p>
<p><strong>Summary</strong><br>æ•°æ®é©±åŠ¨çš„æ•°å­¦è¡¨è¾¾å¼è‡ªåŠ¨å‘ç°æ–¹æ³•â€”â€”ç¬¦å·å›å½’ï¼ˆSRï¼‰æ˜¯ç§‘å­¦æ¢ç´¢çš„é‡è¦å·¥å…·ï¼Œä½†é¢ä¸´æœç´¢ç©ºé—´ç»„åˆçˆ†ç‚¸å’Œè¿‡åº¦æ‹Ÿåˆç­‰é—®é¢˜ã€‚æœ¬æ–‡æå‡ºIdeaSearchFitteræ¡†æ¶ï¼Œåˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨è¿›åŒ–æœç´¢ä¸­ä½œä¸ºè¯­ä¹‰æ“ä½œç¬¦ï¼Œç”Ÿæˆå—è‡ªç„¶è¯­è¨€å¯å‘å€™é€‰è¡¨è¾¾å¼ï¼Œä½¿å‘ç°æ¨¡å‹æ—¢å‡†ç¡®åˆæ¦‚å¿µè¿è´¯ã€å¯è§£é‡Šæ€§å¼ºã€‚IdeaSearchFitteråœ¨ä¸åŒæŒ‘æˆ˜ä¸­è¡¨ç°ä¼˜å¼‚ï¼ŒåŒ…æ‹¬åœ¨Feynmanç¬¦å·å›å½’æ•°æ®åº“ï¼ˆFSReDï¼‰ä¸Šå®ç°ä¸å¼ºå¤§åŸºçº¿ç›¸å½“çš„ç¨³å¥æ€§èƒ½ï¼›åœ¨ç°å®ä¸–ç•Œæ•°æ®ä¸Šå‘ç°å…·æœ‰è‰¯å¥½ç²¾åº¦å¤æ‚åº¦çš„æœºæ¢°å¯¹é½æ¨¡å‹ï¼›å¹¶åœ¨é«˜èƒ½ç‰©ç†åº”ç”¨çš„å‰æ²¿é¢†åŸŸæ¨å¯¼å‡ºç´§å‡‘çš„ç‰©ç†å‚æ•°åŒ–å‡½æ•°ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>IdeaSearchFitteræ¡†æ¶ç»“åˆäº†ç¬¦å·å›å½’ï¼ˆSRï¼‰å’Œå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ï¼Œæé«˜äº†è‡ªåŠ¨åŒ–å‘ç°æ•°å­¦è¡¨è¾¾å¼çš„æ•ˆç‡ã€‚</li>
<li>è¯¥æ¡†æ¶é€šè¿‡ç”Ÿæˆå—è‡ªç„¶è¯­è¨€å¯å‘çš„å€™é€‰è¡¨è¾¾å¼ï¼Œè§£å†³äº†æœç´¢ç©ºé—´çš„ç»„åˆçˆ†ç‚¸é—®é¢˜ã€‚</li>
<li>IdeaSearchFitterå¼ºè°ƒæ¨¡å‹çš„å‡†ç¡®æ€§ã€æ¦‚å¿µè¿è´¯æ€§å’Œå¯è§£é‡Šæ€§ï¼Œé¿å…è¿‡åº¦æ‹Ÿåˆã€‚</li>
<li>åœ¨å¤šä¸ªæŒ‘æˆ˜ä¸­éªŒè¯äº†IdeaSearchFitterçš„æœ‰æ•ˆæ€§ï¼ŒåŒ…æ‹¬åœ¨Feynmanç¬¦å·å›å½’æ•°æ®åº“ä¸Šçš„æ€§èƒ½è¡¨ç°ã€‚</li>
<li>è¯¥æ¡†æ¶èƒ½å¤Ÿå‘ç°ä¸ç°å®ä¸–ç•Œæ•°æ®å…·æœ‰è‰¯å¥½ç²¾åº¦å¤æ‚åº¦çš„æœºæ¢°å¯¹é½æ¨¡å‹ã€‚</li>
<li>IdeaSearchFitteræˆåŠŸåº”ç”¨äºé«˜èƒ½ç‰©ç†é¢†åŸŸï¼Œæ¨å¯¼å‡ºç´§å‡‘çš„ç‰©ç†å‚æ•°åŒ–å‡½æ•°ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.08317">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-d2d734190624a59480afdfa41e34196f" align="middle">
<img src="https://picx.zhimg.com/v2-f4a922b0697d5913d5aaf7b7e7b60300" align="middle">
</details>


<h1 id="-3"><a href="#-3" class="headerlink" title=""></a></h1><h2 id="Beyond-Turn-Limits-Training-Deep-Search-Agents-with-Dynamic-Context-Window"><a href="#Beyond-Turn-Limits-Training-Deep-Search-Agents-with-Dynamic-Context-Window" class="headerlink" title="Beyond Turn Limits: Training Deep Search Agents with Dynamic Context   Window"></a>Beyond Turn Limits: Training Deep Search Agents with Dynamic Context   Window</h2><p><strong>Authors:Qiaoyu Tang, Hao Xiang, Le Yu, Bowen Yu, Yaojie Lu, Xianpei Han, Le Sun, WenJuan Zhang, Pengbo Wang, Shixuan Liu, Zhenru Zhang, Jianhong Tu, Hongyu Lin, Junyang Lin</strong></p>
<p>While recent advances in reasoning models have demonstrated cognitive behaviors through reinforcement learning, existing approaches struggle to invoke deep reasoning capabilities in multi-turn agents with long-horizon interactions. We propose DeepMiner, a novel framework that elicits such abilities by introducing high-difficulty training tasks and dynamic context window. DeepMiner presents a reverse construction method to generate complex but verifiable question-answer pairs from authentic web sources, which ensures the challenge and reliability of training data while injecting cognitive capabilities into multi-turn reasoning scenarios. We further design an elegant yet effective dynamic context management strategy for both training and inference, utilizing sliding window mechanisms while eliminating the dependency on external summarization models, thereby efficiently empowering the model to handle continuously expanding long-horizon contexts. Through reinforcement learning on Qwen3-32B, we develop DeepMiner-32B, which achieves substantial performance improvements across multiple search agent benchmarks. DeepMiner attains 33.5% accuracy on BrowseComp-en, surpassing the previous best open-source agent by almost 20 percentage points, and demonstrates consistent improvements on BrowseComp-zh, XBench-DeepSearch, and GAIA. Notably, our dynamic context management enables sustained interactions of nearly 100 turns within standard 32k context length, effectively addressing the context limitations that constrain existing multi-turn interaction systems. </p>
<blockquote>
<p>è™½ç„¶æœ€è¿‘çš„æ¨ç†æ¨¡å‹è¿›æ­¥å·²ç»é€šè¿‡å¼ºåŒ–å­¦ä¹ å±•ç¤ºäº†è®¤çŸ¥è¡Œä¸ºï¼Œä½†ç°æœ‰æ–¹æ³•å¾ˆéš¾åœ¨å¤šè½®äº¤äº’ä»£ç†ä¸­æ¿€å‘æ·±åº¦æ¨ç†èƒ½åŠ›ï¼Œç‰¹åˆ«æ˜¯å…·æœ‰é•¿æœŸè§†é‡çš„äº¤äº’ã€‚æˆ‘ä»¬æå‡ºäº†DeepMinerï¼Œè¿™æ˜¯ä¸€ä¸ªé€šè¿‡å¼•å…¥é«˜éš¾åº¦è®­ç»ƒä»»åŠ¡å’ŒåŠ¨æ€ä¸Šä¸‹æ–‡çª—å£æ¥æ¿€å‘æ­¤ç±»èƒ½åŠ›çš„æ–°å‹æ¡†æ¶ã€‚DeepMineré‡‡ç”¨åå‘æ„å»ºæ–¹æ³•ï¼Œä»çœŸå®ç½‘ç»œæ¥æºç”Ÿæˆå¤æ‚ä½†å¯éªŒè¯çš„é—®é¢˜ç­”æ¡ˆå¯¹ï¼Œè¿™ç¡®ä¿äº†è®­ç»ƒæ•°æ®çš„æŒ‘æˆ˜æ€§å’Œå¯é æ€§ï¼ŒåŒæ—¶å°†è®¤çŸ¥èƒ½åŠ›æ³¨å…¥å¤šè½®æ¨ç†åœºæ™¯ä¸­ã€‚æˆ‘ä»¬è¿›ä¸€æ­¥ä¸ºè®­ç»ƒå’Œæ¨ç†è®¾è®¡äº†ä¸€ä¸ªä¼˜é›…è€Œæœ‰æ•ˆçš„åŠ¨æ€ä¸Šä¸‹æ–‡ç®¡ç†ç­–ç•¥ï¼Œåˆ©ç”¨æ»‘åŠ¨çª—å£æœºåˆ¶ï¼Œæ¶ˆé™¤å¯¹å¤–éƒ¨æ‘˜è¦æ¨¡å‹çš„ä¾èµ–ï¼Œä»è€Œæœ‰æ•ˆåœ°å¢å¼ºæ¨¡å‹å¤„ç†ä¸æ–­æ‰©å±•çš„é•¿æœŸè§†é‡ä¸Šä¸‹æ–‡çš„èƒ½åŠ›ã€‚é€šè¿‡Qwen3-32Bä¸Šçš„å¼ºåŒ–å­¦ä¹ ï¼Œæˆ‘ä»¬å¼€å‘äº†DeepMiner-32Bï¼Œåœ¨å¤šä¸ªæœç´¢ä»£ç†åŸºå‡†æµ‹è¯•ä¸­å®ç°äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚DeepMineråœ¨BrowseComp-enä¸Šè¾¾åˆ°äº†33.5%çš„å‡†ç¡®ç‡ï¼Œè¶…è¿‡äº†ä¹‹å‰æœ€å¥½çš„å¼€æºä»£ç†è¿‘20ä¸ªç™¾åˆ†ç‚¹ï¼Œå¹¶ä¸”åœ¨BrowseComp-zhã€XBench-DeepSearchå’ŒGAIAä¸Šè¡¨ç°å‡ºæŒç»­çš„ä¸€è‡´æ€§æ”¹è¿›ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œæˆ‘ä»¬çš„åŠ¨æ€ä¸Šä¸‹æ–‡ç®¡ç†ä½¿åœ¨æ ‡å‡†32kä¸Šä¸‹æ–‡é•¿åº¦å†…å®ç°äº†è¿‘100è½®çš„æŒç»­äº¤äº’ï¼Œæœ‰æ•ˆåœ°è§£å†³äº†é™åˆ¶ç°æœ‰å¤šè½®äº¤äº’ç³»ç»Ÿçš„ä¸Šä¸‹æ–‡é™åˆ¶é—®é¢˜ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.08276v1">PDF</a> </p>
<p><strong>Summary</strong>ï¼š</p>
<p>è¿‘æœŸå¼ºåŒ–å­¦ä¹ æ¨¡å‹å±•ç°å‡ºè®¤çŸ¥è¡Œä¸ºèƒ½åŠ›ï¼Œä½†åœ¨å¤šè½®äº¤äº’çš„é•¿å‘¨æœŸç¯å¢ƒä¸­éš¾ä»¥æ¿€å‘æ·±åº¦æ¨ç†èƒ½åŠ›ã€‚ä¸ºæ­¤ï¼Œæœ¬æ–‡æå‡ºDeepMineræ¡†æ¶ï¼Œé€šè¿‡å¼•å…¥é«˜éš¾åº¦è®­ç»ƒä»»åŠ¡å’ŒåŠ¨æ€è¯­å¢ƒçª—å£æ¥æ¿€å‘æ·±åº¦æ¨ç†èƒ½åŠ›ã€‚DeepMineré‡‡ç”¨åå‘æ„å»ºæ³•ç”Ÿæˆå¤æ‚ä½†å¯éªŒè¯çš„é—®ç­”å¯¹ï¼Œç¡®ä¿è®­ç»ƒæ•°æ®çš„æŒ‘æˆ˜æ€§å’Œå¯é æ€§ï¼Œå¹¶æ³¨å…¥å¤šè½®æ¨ç†åœºæ™¯çš„è®¤çŸ¥èƒ½åŠ›ã€‚æ­¤å¤–ï¼ŒDeepMinerè®¾è®¡åŠ¨æ€è¯­å¢ƒç®¡ç†ç­–ç•¥ï¼Œç”¨äºè®­ç»ƒå’Œæ¨ç†ï¼Œåˆ©ç”¨æ»‘åŠ¨çª—å£æœºåˆ¶ï¼Œæ— éœ€ä¾èµ–å¤–éƒ¨æ‘˜è¦æ¨¡å‹ï¼Œä»è€Œæœ‰æ•ˆå¤„ç†ä¸æ–­æ‰©å±•çš„é•¿å‘¨æœŸè¯­å¢ƒã€‚åœ¨Qwen3-32Bä¸Šè¿›è¡Œå¼ºåŒ–å­¦ä¹ ï¼Œå¼€å‘å‡ºDeepMiner-32Bï¼Œåœ¨å¤šä¸ªæœç´¢ä»£ç†åŸºå‡†æµ‹è¯•ä¸­å®ç°æ˜¾è‘—æ€§èƒ½æå‡ã€‚</p>
<p><strong>Key Takeaways</strong>ï¼š</p>
<ol>
<li>DeepMineræ¡†æ¶é€šè¿‡å¼•å…¥é«˜éš¾åº¦è®­ç»ƒä»»åŠ¡å’ŒåŠ¨æ€è¯­å¢ƒçª—å£ï¼Œèƒ½å¤Ÿåœ¨å¤šè½®äº¤äº’ç¯å¢ƒä¸­æ¿€å‘æ·±åº¦æ¨ç†èƒ½åŠ›ã€‚</li>
<li>DeepMineré‡‡ç”¨åå‘æ„å»ºæ³•ç”Ÿæˆé—®ç­”å¯¹ï¼Œç¡®ä¿è®­ç»ƒæ•°æ®çš„æŒ‘æˆ˜æ€§å’Œå¯é æ€§ã€‚</li>
<li>DeepMineræ³¨å…¥è®¤çŸ¥èƒ½åŠ›åˆ°å¤šè½®æ¨ç†åœºæ™¯ä¸­ã€‚</li>
<li>åŠ¨æ€è¯­å¢ƒç®¡ç†ç­–ç•¥ç”¨äºè®­ç»ƒå’Œæ¨ç†ï¼Œèƒ½å¤Ÿå¤„ç†ä¸æ–­æ‰©å±•çš„é•¿å‘¨æœŸè¯­å¢ƒã€‚</li>
<li>é€šè¿‡å¼ºåŒ–å­¦ä¹ ï¼ŒDeepMineråœ¨å¤šä¸ªæœç´¢ä»£ç†åŸºå‡†æµ‹è¯•ä¸­å®ç°æ˜¾è‘—æ€§èƒ½æå‡ã€‚</li>
<li>åœ¨BrowseComp-enä¸Šï¼ŒDeepMinerçš„å‡†ç¡®ç‡è¾¾åˆ°äº†33.5%ï¼Œè¶…è¶Šäº†ä¹‹å‰æœ€å¥½çš„å¼€æºä»£ç†è¿‘20ä¸ªç™¾åˆ†ç‚¹ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.08276">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-57ed116786cce55fc80da67e3e3bbd8e" align="middle">
<img src="https://picx.zhimg.com/v2-088612310744cec2fad6ddcfdac17a6c" align="middle">
<img src="https://picx.zhimg.com/v2-114502022f12501b5b73219558e0b5b9" align="middle">
<img src="https://picx.zhimg.com/v2-e8f07f72a0894d94e5e79b993d8d256f" align="middle">
</details>


<h1 id="-4"><a href="#-4" class="headerlink" title=""></a></h1><h2 id="Multi-Agent-Analysis-of-Off-Exchange-Public-Information-for-Cryptocurrency-Market-Trend-Prediction"><a href="#Multi-Agent-Analysis-of-Off-Exchange-Public-Information-for-Cryptocurrency-Market-Trend-Prediction" class="headerlink" title="Multi-Agent Analysis of Off-Exchange Public Information for   Cryptocurrency Market Trend Prediction"></a>Multi-Agent Analysis of Off-Exchange Public Information for   Cryptocurrency Market Trend Prediction</h2><p><strong>Authors:Kairan Hong, Jinling Gan, Qiushi Tian, Yanglinxuan Guo, Rui Guo, Runnan Li</strong></p>
<p>Cryptocurrency markets present unique prediction challenges due to their extreme volatility, 24&#x2F;7 operation, and hypersensitivity to news events, with existing approaches suffering from key information extraction and poor sideways market detection critical for risk management. We introduce a theoretically-grounded multi-agent cryptocurrency trend prediction framework that advances the state-of-the-art through three key innovations: (1) an information-preserving news analysis system with formal theoretical guarantees that systematically quantifies market impact, regulatory implications, volume dynamics, risk assessment, technical correlation, and temporal effects using large language models; (2) an adaptive volatility-conditional fusion mechanism with proven optimal properties that dynamically combines news sentiment and technical indicators based on market regime detection; (3) a distributed multi-agent coordination architecture with low communication complexity enabling real-time processing of heterogeneous data streams. Comprehensive experimental evaluation on Bitcoin across three prediction horizons demonstrates statistically significant improvements over state-of-the-art natural language processing baseline, establishing a new paradigm for financial machine learning with broad implications for quantitative trading and risk management systems. </p>
<blockquote>
<p>åŠ å¯†è´§å¸å¸‚åœºçš„ç‹¬ç‰¹é¢„æµ‹æŒ‘æˆ˜ä½“ç°åœ¨å…¶æç«¯æ³¢åŠ¨æ€§ã€å…¨å¤©å€™è¿è¥ä»¥åŠå¯¹æ–°é—»äº‹ä»¶çš„æåº¦æ•æ„Ÿæ€§ä¸Šã€‚ç°æœ‰æ–¹æ³•é¢ä¸´å…³é”®ä¿¡æ¯æå–å’Œæ¨ªå‘å¸‚åœºæ£€æµ‹ä¸è¶³çš„é—®é¢˜ï¼Œè¿™å¯¹é£é™©ç®¡ç†è‡³å…³é‡è¦ã€‚æˆ‘ä»¬å¼•å…¥äº†ä¸€ä¸ªæœ‰ç†è®ºæ”¯æ’‘çš„å¤šæ™ºèƒ½ä½“åŠ å¯†è´§å¸è¶‹åŠ¿é¢„æµ‹æ¡†æ¶ï¼Œé€šè¿‡ä¸‰ä¸ªå…³é”®åˆ›æ–°ç‚¹æ¥æ¨åŠ¨å‰æ²¿æŠ€æœ¯ï¼šï¼ˆ1ï¼‰ä¸€ä¸ªä¿¡æ¯ä¿ç•™çš„æ–°é—»åˆ†æç³»ç»Ÿï¼Œå…·æœ‰å½¢å¼åŒ–çš„ç†è®ºä¿è¯ï¼Œèƒ½å¤Ÿç³»ç»Ÿåœ°é‡åŒ–å¸‚åœºå½±å“ã€ç›‘ç®¡å½±å“ã€äº¤æ˜“é‡åŠ¨æ€ã€é£é™©è¯„ä¼°ã€æŠ€æœ¯ç›¸å…³æ€§ä»¥åŠæ—¶é—´æ•ˆåº”ï¼Œä½¿ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼›ï¼ˆ2ï¼‰ä¸€ç§è‡ªé€‚åº”çš„æ³¢åŠ¨æ€§æ¡ä»¶èåˆæœºåˆ¶ï¼Œå…·æœ‰ç»è¿‡éªŒè¯çš„æœ€ä¼˜å±æ€§ï¼Œèƒ½å¤Ÿæ ¹æ®å¸‚åœºçŠ¶æ€æ£€æµ‹åŠ¨æ€åœ°ç»“åˆæ–°é—»æƒ…æ„Ÿå’ŒåŸºäºæŠ€æœ¯æŒ‡æ ‡çš„é¢„æµ‹ï¼›ï¼ˆ3ï¼‰ä¸€ç§å…·æœ‰ä½é€šä¿¡å¤æ‚æ€§çš„åˆ†å¸ƒå¼å¤šæ™ºèƒ½ä½“åè°ƒæ¶æ„ï¼Œèƒ½å¤Ÿå®ç°å®æ—¶å¤„ç†å¼‚æ„æ•°æ®æµã€‚åœ¨æ¯”ç‰¹å¸ä¸Šçš„ä¸‰ä¸ªé¢„æµ‹æ—¶é—´ç‚¹çš„ç»¼åˆå®éªŒè¯„ä¼°è¡¨æ˜ï¼Œä¸ä¼ ç»Ÿçš„è‡ªç„¶è¯­è¨€å¤„ç†åŸºçº¿ç›¸æ¯”ï¼Œå…·æœ‰ç»Ÿè®¡å­¦ä¸Šçš„æ˜¾è‘—æ”¹è¿›ï¼Œä¸ºé‡‘èæœºå™¨å­¦ä¹ å»ºç«‹äº†æ–°çš„èŒƒå¼ï¼Œå¯¹å®šé‡äº¤æ˜“å’Œé£é™©ç®¡ç†ç³»ç»Ÿå…·æœ‰å¹¿æ³›çš„å½±å“ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.08268v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>è¿™ç¯‡æ–‡æœ¬ä¸»è¦ä»‹ç»äº†é’ˆå¯¹åŠ å¯†è´§å¸å¸‚åœºçš„ç‹¬ç‰¹é¢„æµ‹æŒ‘æˆ˜ï¼Œæå‡ºäº†ä¸€ç§åŸºäºå¤šæ™ºèƒ½ä½“çš„åŠ å¯†è´§å¸è¶‹åŠ¿é¢„æµ‹æ¡†æ¶ã€‚è¯¥æ¡†æ¶å…·æœ‰ä¸‰ä¸ªå…³é”®åˆ›æ–°ç‚¹ï¼šä¸€æ˜¯ä¿¡æ¯ä¿ç•™çš„æ–°é—»åˆ†æç³»ç»Ÿï¼ŒäºŒæ˜¯è‡ªé€‚åº”æ³¢åŠ¨æ¡ä»¶èåˆæœºåˆ¶ï¼Œä¸‰æ˜¯åˆ†å¸ƒå¼å¤šæ™ºèƒ½ä½“åè°ƒæ¶æ„ã€‚è¿™äº›åˆ›æ–°ç‚¹æ—¨åœ¨è§£å†³ç°æœ‰æ–¹æ³•åœ¨ä¿¡æ¯æå–å’Œæ¨ªå‘å¸‚åœºæ£€æµ‹æ–¹é¢çš„ä¸è¶³ï¼Œä¸ºé£é™©ç®¡ç†æä¾›æ–°çš„è§£å†³æ–¹æ¡ˆã€‚å®éªŒè¯„ä¼°è¡¨æ˜ï¼Œè¯¥æ¡†æ¶åœ¨æ¯”ç‰¹å¸é¢„æµ‹æ–¹é¢æ˜¾è‘—ä¼˜äºç°æœ‰è‡ªç„¶è¯­è¨€å¤„ç†åŸºçº¿ï¼Œä¸ºé‡‘èæœºå™¨å­¦ä¹ å’Œé‡åŒ–äº¤æ˜“é£é™©ç®¡ç†æä¾›äº†é‡è¦çš„å¯ç¤ºã€‚</p>
<p><strong>Key Takeaways</strong></p>
<p>ä»¥ä¸‹æ˜¯ä¸ƒä¸ªå…³é”®è§è§£ï¼š</p>
<ul>
<li>åŠ å¯†è´§å¸å¸‚åœºå…·æœ‰ç‹¬ç‰¹çš„é¢„æµ‹æŒ‘æˆ˜ï¼Œå¦‚æç«¯æ³¢åŠ¨æ€§ã€å…¨å¤©å€™æ“ä½œå’Œæ–°é—»äº‹ä»¶çš„æ•æ„Ÿæ€§ã€‚</li>
<li>ç°å­˜æ–¹æ³•åœ¨å…³é”®ä¿¡æ¯æå–å’Œæ¨ªå‘å¸‚åœºæ£€æµ‹æ–¹é¢å­˜åœ¨ä¸è¶³ã€‚</li>
<li>æå‡ºäº†ä¸€ç§å¤šæ™ºèƒ½ä½“åŠ å¯†è´§å¸è¶‹åŠ¿é¢„æµ‹æ¡†æ¶ï¼ŒåŒ…æ‹¬ä¿¡æ¯ä¿ç•™çš„æ–°é—»åˆ†æç³»ç»Ÿã€è‡ªé€‚åº”æ³¢åŠ¨æ¡ä»¶èåˆæœºåˆ¶å’Œåˆ†å¸ƒå¼å¤šæ™ºèƒ½ä½“åè°ƒæ¶æ„ã€‚</li>
<li>ä¿¡æ¯ä¿ç•™çš„æ–°é—»åˆ†æç³»ç»Ÿä½¿ç”¨å¤§å‹è¯­è¨€æ¨¡å‹é‡åŒ–å¸‚åœºå½±å“ã€ç›‘ç®¡å½±å“ã€äº¤æ˜“é‡åŠ¨æ€ã€é£é™©è¯„ä¼°ã€æŠ€æœ¯å…³è”å’Œæ—¶é—´æ•ˆåº”ã€‚</li>
<li>è‡ªé€‚åº”æ³¢åŠ¨æ¡ä»¶èåˆæœºåˆ¶ç»“åˆæ–°é—»æƒ…æ„Ÿå’ŒåŸºäºå¸‚åœºçŠ¶æ€æ£€æµ‹çš„æŠ€æœ¯æŒ‡æ ‡ã€‚</li>
<li>åˆ†å¸ƒå¼å¤šæ™ºèƒ½ä½“åè°ƒæ¶æ„å…·æœ‰ä½é€šä¿¡å¤æ‚æ€§ï¼Œå¯å®æ—¶å¤„ç†å¼‚æ„æ•°æ®æµã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.08268">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-278207ab842898d350559ee13081899c" align="middle">
<img src="https://picx.zhimg.com/v2-ea5c1172cf0543f8aa2f2f8f4de879f8" align="middle">
<img src="https://picx.zhimg.com/v2-cb28c43ea2c11ae120b6add1f00974be" align="middle">
<img src="https://picx.zhimg.com/v2-bcfdf1bbaa04a8f83ef4eae0611b61a3" align="middle">
<img src="https://picx.zhimg.com/v2-2b2504b4df9f481e0844e65013715a43" align="middle">
<img src="https://picx.zhimg.com/v2-b3fbafb1dfa34ee172866ed044323040" align="middle">
<img src="https://picx.zhimg.com/v2-385fb8eb89c21c754890b4b46f3b8470" align="middle">
</details>


<h1 id="-5"><a href="#-5" class="headerlink" title=""></a></h1><h2 id="Opponent-Shaping-in-LLM-Agents"><a href="#Opponent-Shaping-in-LLM-Agents" class="headerlink" title="Opponent Shaping in LLM Agents"></a>Opponent Shaping in LLM Agents</h2><p><strong>Authors:Marta Emili Garcia Segura, Stephen Hailes, Mirco Musolesi</strong></p>
<p>Large Language Models (LLMs) are increasingly being deployed as autonomous agents in real-world environments. As these deployments scale, multi-agent interactions become inevitable, making it essential to understand strategic behavior in such systems. A central open question is whether LLM agents, like reinforcement learning agents, can shape the learning dynamics and influence the behavior of others through interaction alone. In this paper, we present the first investigation of opponent shaping (OS) with LLM-based agents. Existing OS algorithms cannot be directly applied to LLMs, as they require higher-order derivatives, face scalability constraints, or depend on architectural components that are absent in transformers. To address this gap, we introduce ShapeLLM, an adaptation of model-free OS methods tailored for transformer-based agents. Using ShapeLLM, we examine whether LLM agents can influence co-playersâ€™ learning dynamics across diverse game-theoretic environments. We demonstrate that LLM agents can successfully guide opponents toward exploitable equilibria in competitive games (Iterated Prisonerâ€™s Dilemma, Matching Pennies, and Chicken) and promote coordination and improve collective welfare in cooperative games (Iterated Stag Hunt and a cooperative version of the Prisonerâ€™s Dilemma). Our findings show that LLM agents can both shape and be shaped through interaction, establishing opponent shaping as a key dimension of multi-agent LLM research. </p>
<blockquote>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰è¶Šæ¥è¶Šè¢«éƒ¨ç½²åœ¨çœŸå®ä¸–ç•Œç¯å¢ƒä¸­ä½œä¸ºè‡ªä¸»ä»£ç†ã€‚éšç€è¿™äº›éƒ¨ç½²è§„æ¨¡çš„æ‰©å¤§ï¼Œå¤šæ™ºèƒ½ä½“äº¤äº’å˜å¾—ä¸å¯é¿å…ï¼Œå› æ­¤äº†è§£æ­¤ç±»ç³»ç»Ÿä¸­çš„æˆ˜ç•¥è¡Œä¸ºå˜å¾—è‡³å…³é‡è¦ã€‚ä¸€ä¸ªæ ¸å¿ƒå¼€æ”¾çš„é—®é¢˜æ˜¯ï¼ŒLLMæ™ºèƒ½ä½“æ˜¯å¦èƒ½å¤Ÿåƒå¼ºåŒ–å­¦ä¹ æ™ºèƒ½ä½“ä¸€æ ·ï¼Œä»…é€šè¿‡äº¤äº’æ¥å¡‘é€ å­¦ä¹ åŠ¨æ€å¹¶å½±å“ä»–äººçš„è¡Œä¸ºã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬é¦–æ¬¡å¯¹åŸºäºLLMçš„å¯¹æ‰‹å¡‘é€ ï¼ˆOSï¼‰è¿›è¡Œäº†è°ƒæŸ¥ã€‚ç°æœ‰çš„OSç®—æ³•ä¸èƒ½ç›´æ¥åœ¨LLMä¸Šåº”ç”¨ï¼Œå› ä¸ºå®ƒä»¬éœ€è¦é«˜é˜¶å¯¼æ•°ã€é¢ä¸´å¯æ‰©å±•æ€§çº¦æŸæˆ–ä¾èµ–äºLLMæ¨¡å‹ä¸­ä¸å­˜åœ¨çš„æ¶æ„ç»„ä»¶ã€‚ä¸ºäº†å¼¥è¡¥è¿™ä¸€ç©ºç™½ï¼Œæˆ‘ä»¬å¼•å…¥äº†ShapeLLMï¼Œè¿™æ˜¯ä¸€ä¸ªé’ˆå¯¹åŸºäºè½¬æ¢å™¨çš„æ™ºèƒ½ä½“çš„æ— æ¨¡å‹OSæ–¹æ³•çš„æ”¹ç¼–ã€‚ä½¿ç”¨ShapeLLMï¼Œæˆ‘ä»¬ç ”ç©¶äº†LLMæ™ºèƒ½ä½“æ˜¯å¦èƒ½åœ¨å¤šç§åšå¼ˆè®ºç¯å¢ƒä¸­å½±å“å¯¹æ‰‹çš„å­¦ä¹ åŠ¨æ€ã€‚æˆ‘ä»¬è¯æ˜ï¼ŒLLMæ™ºèƒ½ä½“å¯ä»¥æˆåŠŸå¼•å¯¼å¯¹æ‰‹èµ°å‘ç«äº‰æ¸¸æˆä¸­çš„å¯å‰¥å‰Šå¹³è¡¡ï¼ˆå¦‚åå¤å›šå¾’å›°å¢ƒã€åŒ¹é…ç¡¬å¸å’Œé¸¡è‚‰æ¸¸æˆï¼‰ï¼Œå¹¶åœ¨åˆä½œæ¸¸æˆä¸­ä¿ƒè¿›åè°ƒå’Œæé«˜é›†ä½“ç¦åˆ©ï¼ˆå¦‚åå¤ç‹©çŒé˜¶æ®µå’Œåˆä½œç‰ˆæœ¬çš„å›šå¾’å›°å¢ƒï¼‰ã€‚æˆ‘ä»¬çš„ç ”ç©¶ç»“æœè¡¨æ˜ï¼ŒLLMæ™ºèƒ½ä½“æ—¢å¯ä»¥é€šè¿‡äº¤äº’æ¥å¡‘é€ å¯¹æ‰‹ï¼Œä¹Ÿå¯ä»¥è¢«å¯¹æ‰‹å¡‘é€ ï¼Œä»è€Œç¡®ç«‹äº†å¯¹æ‰‹å¡‘é€ åœ¨å¤šæ™ºèƒ½ä½“LLMç ”ç©¶ä¸­çš„å…³é”®ç»´åº¦ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.08255v1">PDF</a> 29 pages, 15 figures, 15 tables</p>
<p><strong>Summary</strong></p>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä½œä¸ºè‡ªä¸»ä»£ç†åœ¨ç°å®ç¯å¢ƒä¸­çš„éƒ¨ç½²æ—¥ç›Šå¢å¤šï¼Œå¤šä»£ç†äº¤äº’ä¸å¯é¿å…ã€‚æœ¬æ–‡é¦–æ¬¡ç ”ç©¶äº†ä¸LLMä»£ç†çš„å¯¹æ‰‹å¡‘é€ ï¼ˆOSï¼‰é—®é¢˜ã€‚é’ˆå¯¹LLMï¼Œæˆ‘ä»¬å¼•å…¥äº†ShapeLLMï¼Œè¿™æ˜¯ä¸€ç§é’ˆå¯¹åŸºäºå˜å‹å™¨çš„ä»£ç†çš„æ— æ¨¡å‹OSæ–¹æ³•çš„æ”¹ç¼–ã€‚ç ”ç©¶è¡¨æ˜ï¼ŒLLMä»£ç†å¯ä»¥åœ¨æ¸¸æˆç†è®ºç¯å¢ƒä¸­å½±å“å¯¹æ‰‹çš„å­¦ä¹ åŠ¨æ€ã€‚åœ¨ç«äº‰æ¸¸æˆä¸­ï¼ŒLLMä»£ç†å¯ä»¥å¼•å¯¼å¯¹æ‰‹èµ°å‘å¯å‰¥å‰Šçš„å‡è¡¡çŠ¶æ€ï¼Œå¹¶åœ¨åˆä½œæ¸¸æˆä¸­ä¿ƒè¿›åè°ƒå’Œæé«˜é›†ä½“ç¦åˆ©ã€‚å› æ­¤ï¼Œå¯¹æ‰‹å¡‘é€ æ˜¯LLMå¤šä»£ç†ç ”ç©¶çš„å…³é”®ç»´åº¦ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ­£åœ¨è¢«è¶Šæ¥è¶Šå¤šåœ°éƒ¨ç½²ä¸ºè‡ªä¸»ä»£ç†ï¼Œåœ¨å¤šä»£ç†äº¤äº’ä¸­ï¼Œå¯¹æ‰‹å¡‘é€ ï¼ˆOSï¼‰æˆä¸ºå…³é”®è®®é¢˜ã€‚</li>
<li>ç°æœ‰OSç®—æ³•ä¸èƒ½ç›´æ¥åº”ç”¨äºLLMï¼Œéœ€è¦é’ˆå¯¹åŸºäºå˜å‹å™¨çš„ä»£ç†è¿›è¡Œæ”¹ç¼–ã€‚</li>
<li>å¼•å…¥ShapeLLMï¼Œä¸€ç§é’ˆå¯¹LLMçš„æ— æ¨¡å‹OSæ–¹æ³•ã€‚</li>
<li>LLMä»£ç†å¯ä»¥åœ¨ä¸åŒçš„æ¸¸æˆç†è®ºç¯å¢ƒä¸­å½±å“å¯¹æ‰‹çš„å­¦ä¹ åŠ¨æ€ã€‚</li>
<li>åœ¨ç«äº‰æ¸¸æˆä¸­ï¼ŒLLMä»£ç†å¯å¼•å¯¼å¯¹æ‰‹è‡³å¯å‰¥å‰Šçš„å‡è¡¡çŠ¶æ€ã€‚</li>
<li>åœ¨åˆä½œæ¸¸æˆä¸­ï¼ŒLLMä»£ç†èƒ½ä¿ƒè¿›åè°ƒå’Œæé«˜é›†ä½“ç¦åˆ©ã€‚</li>
<li>LLMä»£ç†æ—¢èƒ½å¤Ÿå¡‘é€ å¯¹æ‰‹ï¼Œä¹Ÿèƒ½é€šè¿‡äº¤äº’è¢«å¯¹æ‰‹å¡‘é€ ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.08255">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-a7e4f9c5f7cad95f3595e39119e154ac" align="middle">
<img src="https://picx.zhimg.com/v2-1c58457c6e9bd4f7222ee4b52fd274b5" align="middle">
<img src="https://picx.zhimg.com/v2-d6b8d43d2a97a5de8b8ac6d733556b51" align="middle">
</details>


<h1 id="-6"><a href="#-6" class="headerlink" title=""></a></h1><h2 id="Two-Agents-One-Prompt-and-Your-Weight"><a href="#Two-Agents-One-Prompt-and-Your-Weight" class="headerlink" title="Two Agents, One Prompt, and Your Weight"></a>Two Agents, One Prompt, and Your Weight</h2><p><strong>Authors:Elchanan Mossel, Amnon Schrieber</strong></p>
<p>We investigate a quantitative variant of the classic Two Doors logic puzzle, in which the answer space is no longer binary, for example when the goal is to recover a numerical fact (such as oneâ€™s true weight) rather than choose between two doors. The puzzle retains the original structure: one agent always tells the truth, the other always lies. Our central contribution is to identify a class of self-referential prompts that successfully extract the correct quantitative answer under minimal assumptions. We also explore how well does \texttt{ChatGPT} does in reasoning for this problem which is just a little bit out of distribution. </p>
<blockquote>
<p>æˆ‘ä»¬ç ”ç©¶äº†ç»å…¸çš„ä¸¤é—¨é€»è¾‘éš¾é¢˜çš„å®šé‡å˜ä½“ï¼Œåœ¨è¿™ä¸ªå˜ä½“ä¸­ï¼Œç­”æ¡ˆç©ºé—´ä¸å†æ˜¯äºŒå…ƒçš„ï¼Œä¾‹å¦‚ç›®æ ‡æ˜¯ä»ä¸¤ä¸ªé—¨ä¸­é€‰æ‹©ä¸€ä¸ªæ•°å­—äº‹å®ï¼ˆå¦‚çœŸå®çš„ä½“é‡ï¼‰è€Œä¸æ˜¯ç®€å•åœ°é€‰æ‹©å…¶ä¸­ä¸€ä¸ªé—¨ã€‚è°œé¢˜ä¿ç•™äº†åŸå§‹ç»“æ„ï¼šä¸€ä¸ªä»£ç†äººæ€»æ˜¯è¯´å®è¯ï¼Œå¦ä¸€ä¸ªä»£ç†äººæ€»æ˜¯è¯´è°ã€‚æˆ‘ä»¬çš„ä¸»è¦è´¡çŒ®åœ¨äºè¯†åˆ«å‡ºä¸€ç±»è‡ªæŒ‡æç¤ºï¼Œè¿™äº›æç¤ºèƒ½å¤Ÿåœ¨æœ€å°‘çš„å‡è®¾ä¸‹æˆåŠŸæå–æ­£ç¡®çš„å®šé‡ç­”æ¡ˆã€‚æˆ‘ä»¬è¿˜æ¢è®¨äº†ChatGPTåœ¨å¤„ç†è¿™ç§ç¨å¾®è¶…å‡ºå¸¸è§„èŒƒå›´çš„é—®é¢˜æ—¶çš„æ¨ç†èƒ½åŠ›ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.08232v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æ¢è®¨äº†ç»å…¸çš„ä¸¤é—¨é€»è¾‘éš¾é¢˜çš„å®šé‡å˜ä½“ã€‚å½“ç›®æ ‡ä¸å†æ˜¯äºŒå…ƒé€‰æ‹©ï¼ˆå¦‚é€‰æ‹©ä¸¤æ‰‡é—¨ä¸­çš„ä¸€æ‰‡é—¨ï¼‰ï¼Œè€Œæ˜¯æ¢å¤æ•°å€¼äº‹å®ï¼ˆå¦‚çœŸå®ä½“é‡ï¼‰æ—¶ï¼Œè¯¥éš¾é¢˜å¦‚ä½•ä¿æŒåŸæœ‰çš„ç»“æ„ç‰¹ç‚¹ï¼šä¸€ä¸ªä»£ç†äººæ€»æ˜¯è¯´å®è¯ï¼Œå¦ä¸€ä¸ªæ€»æ˜¯è¯´è°ã€‚æœ¬æ–‡çš„æ ¸å¿ƒè´¡çŒ®æ˜¯è¯†åˆ«å‡ºä¸€ç±»è‡ªæˆ‘å‚è€ƒçš„æç¤ºï¼Œè¿™äº›æç¤ºèƒ½åœ¨æœ€å°çš„å‡è®¾ä¸‹æˆåŠŸæå–å‡ºæ­£ç¡®çš„å®šé‡ç­”æ¡ˆã€‚æ­¤å¤–ï¼Œæœ¬æ–‡è¿˜æ¢è®¨äº†ChatGPTåœ¨è¿™ç§ç¨å¾®è¶…å‡ºå…¶å¸¸è§„å¤„ç†èŒƒå›´çš„é—®é¢˜ä¸Šçš„æ¨ç†èƒ½åŠ›ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æœ¬æ–‡ç ”ç©¶äº†ç»å…¸ä¸¤é—¨é€»è¾‘éš¾é¢˜çš„å®šé‡å˜ä½“ï¼Œå…¶ä¸­ç­”æ¡ˆä¸å†æ˜¯ç®€å•çš„äºŒå…ƒé€‰æ‹©ï¼Œè€Œæ˜¯æ¶‰åŠåˆ°æ•°å€¼äº‹å®çš„æå–ã€‚</li>
<li>é—®é¢˜ä¿æŒåŸæœ‰çš„ç»“æ„ç‰¹ç‚¹ï¼šä¸€ä¸ªä»£ç†äººå§‹ç»ˆè¯´å®è¯ï¼Œå¦ä¸€ä¸ªä»£ç†äººå§‹ç»ˆè¯´è°ã€‚</li>
<li>è®ºæ–‡ä¸»è¦è´¡çŒ®åœ¨äºæ‰¾åˆ°ä¸€ç§è‡ªæˆ‘å‚è€ƒçš„æç¤ºæ–¹æ³•ï¼Œå¯ä»¥åœ¨æœ€å°‘å‡è®¾ä¸‹æˆåŠŸæå–å‡ºæ­£ç¡®çš„å®šé‡ç­”æ¡ˆã€‚</li>
<li>è®ºæ–‡è¿˜æ¢è®¨äº†ChatGPTåœ¨å¤„ç†ç¨å¾®è¶…å‡ºå…¶å¸¸è§„èŒƒå›´çš„é—®é¢˜æ—¶çš„æ¨ç†èƒ½åŠ›ã€‚</li>
<li>è¯¥ç ”ç©¶å±•ç¤ºäº†å¦‚ä½•é€šè¿‡é€»è¾‘æ¨ç†æ¥è§£å†³é—®é¢˜ï¼Œå³ä½¿è¿™äº›é—®é¢˜æ¶‰åŠåˆ°æ•°å€¼æ•°æ®å’Œè‡ªæˆ‘å‚è€ƒçš„å¤æ‚æ€§ã€‚</li>
<li>ç ”ç©¶ç»“æœå¯¹äºäººå·¥æ™ºèƒ½ç†è§£å’Œå¤„ç†å¤æ‚é€»è¾‘é—®é¢˜æœ‰ä¸€å®šçš„å¯ç¤ºä½œç”¨ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.08232">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-18a187ba5e8306e4c53aa661f9cbda95" align="middle">
</details>


<h1 id="-7"><a href="#-7" class="headerlink" title=""></a></h1><h2 id="NavSpace-How-Navigation-Agents-Follow-Spatial-Intelligence-Instructions"><a href="#NavSpace-How-Navigation-Agents-Follow-Spatial-Intelligence-Instructions" class="headerlink" title="NavSpace: How Navigation Agents Follow Spatial Intelligence Instructions"></a>NavSpace: How Navigation Agents Follow Spatial Intelligence Instructions</h2><p><strong>Authors:Haolin Yang, Yuxing Long, Zhuoyuan Yu, Zihan Yang, Minghan Wang, Jiapeng Xu, Yihan Wang, Ziyan Yu, Wenzhe Cai, Lei Kang, Hao Dong</strong></p>
<p>Instruction-following navigation is a key step toward embodied intelligence. Prior benchmarks mainly focus on semantic understanding but overlook systematically evaluating navigation agentsâ€™ spatial perception and reasoning capabilities. In this work, we introduce the NavSpace benchmark, which contains six task categories and 1,228 trajectory-instruction pairs designed to probe the spatial intelligence of navigation agents. On this benchmark, we comprehensively evaluate 22 navigation agents, including state-of-the-art navigation models and multimodal large language models. The evaluation results lift the veil on spatial intelligence in embodied navigation. Furthermore, we propose SNav, a new spatially intelligent navigation model. SNav outperforms existing navigation agents on NavSpace and real robot tests, establishing a strong baseline for future work. </p>
<blockquote>
<p>æŒ‡ä»¤è·Ÿéšå¯¼èˆªæ˜¯å®ç°å®ä½“æ™ºèƒ½çš„å…³é”®æ­¥éª¤ã€‚æ­¤å‰çš„åŸºå‡†æµ‹è¯•ä¸»è¦å…³æ³¨è¯­ä¹‰ç†è§£ï¼Œä½†å¿½è§†äº†ç³»ç»Ÿåœ°è¯„ä¼°å¯¼èˆªä»£ç†çš„ç©ºé—´æ„ŸçŸ¥å’Œæ¨ç†èƒ½åŠ›ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬å¼•å…¥äº†NavSpaceåŸºå‡†æµ‹è¯•ï¼Œå…¶ä¸­åŒ…å«å…­ä¸ªä»»åŠ¡ç±»åˆ«å’Œ1228ä¸ªè½¨è¿¹æŒ‡ä»¤å¯¹ï¼Œæ—¨åœ¨æ¢æµ‹å¯¼èˆªä»£ç†çš„ç©ºé—´æ™ºèƒ½ã€‚åœ¨æ­¤åŸºå‡†æµ‹è¯•ä¸Šï¼Œæˆ‘ä»¬å…¨é¢è¯„ä¼°äº†22ä¸ªå¯¼èˆªä»£ç†ï¼ŒåŒ…æ‹¬æœ€å…ˆè¿›çš„å¯¼èˆªæ¨¡å‹å’Œå¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ã€‚è¯„ä¼°ç»“æœæ­ç¤ºäº†å®ä½“å¯¼èˆªä¸­çš„ç©ºé—´æ™ºèƒ½ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªæ–°çš„ç©ºé—´æ™ºèƒ½å¯¼èˆªæ¨¡å‹SNavã€‚SNavåœ¨NavSpaceå’ŒçœŸå®æœºå™¨äººæµ‹è¯•ä¸­éƒ½è¶…è¶Šäº†ç°æœ‰å¯¼èˆªä»£ç†ï¼Œä¸ºæœªæ¥çš„å·¥ä½œå»ºç«‹äº†å¼ºå¤§çš„åŸºå‡†ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.08173v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>è¯¥æ–‡ä»‹ç»äº†å¯¼èˆªæ™ºèƒ½ç ”ç©¶ä¸­çš„ä¸€ä¸ªå…³é”®æ­¥éª¤â€”â€”æŒ‡ä»¤éµå¾ªå¯¼èˆªã€‚ç°æœ‰åŸºå‡†æµ‹è¯•ä¸»è¦å…³æ³¨è¯­ä¹‰ç†è§£ï¼Œä½†å¿½ç•¥äº†ç³»ç»Ÿåœ°è¯„ä¼°å¯¼èˆªç³»ç»Ÿçš„ç©ºé—´æ„ŸçŸ¥å’Œæ¨ç†èƒ½åŠ›ã€‚æœ¬ç ”ç©¶å¼•å…¥äº†NavSpaceåŸºå‡†æµ‹è¯•ï¼ŒåŒ…å«å…­ä¸ªä»»åŠ¡ç±»åˆ«å’Œ1228ç»„è½¨è¿¹æŒ‡ä»¤å¯¹ï¼Œæ—¨åœ¨æµ‹è¯•å¯¼èˆªç³»ç»Ÿçš„ç©ºé—´æ™ºèƒ½æ°´å¹³ã€‚è¯¥ç ”ç©¶å…¨é¢è¯„ä¼°äº†åŒ…æ‹¬æœ€æ–°å¯¼èˆªæ¨¡å‹å’Œè·¨æ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å†…çš„22ä¸ªå¯¼èˆªç³»ç»Ÿã€‚åŒæ—¶ï¼Œæå‡ºäº†ä¸€ç§æ–°å‹çš„ç©ºé—´æ™ºèƒ½å¯¼èˆªæ¨¡å‹SNavï¼Œè¯¥æ¨¡å‹åœ¨NavSpaceå’ŒçœŸå®æœºå™¨äººæµ‹è¯•ä¸­è¡¨ç°å‡ºè¶…è¶Šç°æœ‰å¯¼èˆªç³»ç»Ÿçš„æ€§èƒ½ï¼Œä¸ºæœªæ¥ç ”ç©¶å¥ å®šäº†åšå®çš„åŸºå‡†ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æŒ‡ä»¤éµå¾ªå¯¼èˆªæ˜¯æ™ºèƒ½ç ”ç©¶çš„å…³é”®æ­¥éª¤ä¹‹ä¸€ã€‚</li>
<li>å½“å‰åŸºå‡†æµ‹è¯•ä¸»è¦å…³æ³¨è¯­ä¹‰ç†è§£ï¼Œå¿½è§†äº†å¯¼èˆªç³»ç»Ÿçš„ç©ºé—´æ„ŸçŸ¥å’Œæ¨ç†èƒ½åŠ›è¯„ä¼°ã€‚</li>
<li>NavSpaceåŸºå‡†æµ‹è¯•æ—¨åœ¨å…¨é¢æµ‹è¯•å¯¼èˆªç³»ç»Ÿçš„ç©ºé—´æ™ºèƒ½æ°´å¹³ï¼ŒåŒ…å«å…­ä¸ªä»»åŠ¡ç±»åˆ«å’Œå¤§é‡è½¨è¿¹æŒ‡ä»¤å¯¹ã€‚</li>
<li>ç ”ç©¶äººå‘˜å¯¹22ä¸ªå¯¼èˆªç³»ç»Ÿè¿›è¡Œäº†å…¨é¢è¯„ä¼°ï¼ŒåŒ…æ‹¬æœ€æ–°å¯¼èˆªæ¨¡å‹å’Œè·¨æ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ã€‚</li>
<li>æ–°å‹ç©ºé—´æ™ºèƒ½å¯¼èˆªæ¨¡å‹SNavåœ¨NavSpaceåŸºå‡†æµ‹è¯•å’ŒçœŸå®æœºå™¨äººæµ‹è¯•ä¸­è¡¨ç°ä¼˜å¼‚ã€‚</li>
<li>SNavæ¨¡å‹ä¸ºæœªæ¥çš„å¯¼èˆªæ™ºèƒ½ç ”ç©¶æä¾›äº†åšå®çš„åŸºå‡†ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.08173">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-69330b7c65afe79182a24fffa54bce9e" align="middle">
<img src="https://picx.zhimg.com/v2-25e820a6ccadc2757fb469660d02e2bc" align="middle">
<img src="https://picx.zhimg.com/v2-947904bffdda38c9ed55a8d4a1c6501c" align="middle">
<img src="https://picx.zhimg.com/v2-f97e414b8c99bb98749f4529a29e1c20" align="middle">
<img src="https://picx.zhimg.com/v2-b08058d1c11972963ea278382aae623b" align="middle">
</details>


<h1 id="-8"><a href="#-8" class="headerlink" title=""></a></h1><h2 id="AI-Knowledge-Assist-An-Automated-Approach-for-the-Creation-of-Knowledge-Bases-for-Conversational-AI-Agents"><a href="#AI-Knowledge-Assist-An-Automated-Approach-for-the-Creation-of-Knowledge-Bases-for-Conversational-AI-Agents" class="headerlink" title="AI Knowledge Assist: An Automated Approach for the Creation of Knowledge   Bases for Conversational AI Agents"></a>AI Knowledge Assist: An Automated Approach for the Creation of Knowledge   Bases for Conversational AI Agents</h2><p><strong>Authors:Md Tahmid Rahman Laskar, Julien Bouvier Tremblay, Xue-Yong Fu, Cheng Chen, Shashi Bhushan TN</strong></p>
<p>The utilization of conversational AI systems by leveraging Retrieval Augmented Generation (RAG) techniques to solve customer problems has been on the rise with the rapid progress of Large Language Models (LLMs). However, the absence of a company-specific dedicated knowledge base is a major barrier to the integration of conversational AI systems in contact centers. To this end, we introduce AI Knowledge Assist, a system that extracts knowledge in the form of question-answer (QA) pairs from historical customer-agent conversations to automatically build a knowledge base. Fine-tuning a lightweight LLM on internal data demonstrates state-of-the-art performance, outperforming larger closed-source LLMs. More specifically, empirical evaluation on 20 companies demonstrates that the proposed AI Knowledge Assist system that leverages the LLaMA-3.1-8B model eliminates the cold-start gap in contact centers by achieving above 90% accuracy in answering information-seeking questions. This enables immediate deployment of RAG-powered chatbots. </p>
<blockquote>
<p>éšç€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„å¿«é€Ÿå‘å±•ï¼Œåˆ©ç”¨æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰æŠ€æœ¯è§£å†³å®¢æˆ·é—®é¢˜çš„å¯¹è¯å¼äººå·¥æ™ºèƒ½ç³»ç»Ÿçš„åº”ç”¨æ­£åœ¨å¢åŠ ã€‚ç„¶è€Œï¼Œç¼ºä¹é’ˆå¯¹å…¬å¸çš„ä¸“ç”¨çŸ¥è¯†åº“æ˜¯é˜»ç¢å¯¹è¯å¼äººå·¥æ™ºèƒ½ç³»ç»Ÿåœ¨å‘¼å«ä¸­å¿ƒä¸­æ•´åˆçš„ä¸»è¦éšœç¢ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬å¼•å…¥äº†AIçŸ¥è¯†åŠ©æ‰‹ç³»ç»Ÿï¼Œè¯¥ç³»ç»Ÿä»å†å²å’Œå®¢æœå¯¹è¯ä¸­æå–ä»¥é—®ç­”å¯¹çš„å½¢å¼çš„çŸ¥è¯†æ¥è‡ªåŠ¨æ„å»ºçŸ¥è¯†åº“ã€‚åœ¨å†…éƒ¨æ•°æ®ä¸Šå¯¹è½»é‡çº§LLMè¿›è¡Œå¾®è°ƒï¼Œè¡¨ç°å‡ºå“è¶Šçš„æ€§èƒ½ï¼Œè¶…è¿‡äº†è¾ƒå¤§çš„é—­æºLLMã€‚æ›´å…·ä½“åœ°è¯´ï¼Œå¯¹20å®¶å…¬å¸çš„å®è¯è¯„ä¼°è¡¨æ˜ï¼Œæ‰€æå‡ºçš„åˆ©ç”¨LLaMA-3.1-8Bæ¨¡å‹çš„AIçŸ¥è¯†åŠ©æ‰‹ç³»ç»Ÿé€šè¿‡å®ç°é«˜è¾¾90%çš„ä¿¡æ¯æŸ¥è¯¢é—®é¢˜å›ç­”å‡†ç¡®ç‡ï¼Œæ¶ˆé™¤äº†å‘¼å«ä¸­å¿ƒä¸­çš„å†·å¯åŠ¨å·®è·ã€‚è¿™èƒ½å¤Ÿå®ç°RAGé©±åŠ¨çš„èŠå¤©æœºå™¨äººçš„å³æ—¶éƒ¨ç½²ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.08149v1">PDF</a> Accepted to the EMNLP 2025 Industry Track</p>
<p><strong>Summary</strong></p>
<p>åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æŠ€æœ¯çš„å¿«é€Ÿå‘å±•ï¼Œåˆ©ç”¨æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰æŠ€æœ¯è§£å†³å®¢æˆ·é—®é¢˜çš„å¯¹è¯AIç³»ç»Ÿåº”ç”¨æ—¥ç›Šå¹¿æ³›ã€‚ç„¶è€Œï¼Œç¼ºä¹å…¬å¸ç‰¹å®šçš„ä¸“ç”¨çŸ¥è¯†åº“æ˜¯é›†æˆå¯¹è¯AIç³»ç»Ÿçš„ä¸»è¦éšœç¢ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬æ¨å‡ºäº†AIçŸ¥è¯†åŠ©æ‰‹ç³»ç»Ÿï¼Œå®ƒå¯ä»¥ä»å†å²å®¢æˆ·ä¸ä»£ç†ä¹‹é—´çš„å¯¹è¯ä¸­æå–é—®é¢˜ç­”æ¡ˆï¼ˆQAï¼‰å¯¹æ¥è‡ªåŠ¨æ„å»ºçŸ¥è¯†åº“ã€‚åœ¨å†…éƒ¨æ•°æ®ä¸Šå¾®è°ƒè½»é‡çº§LLMï¼Œå±•ç°å‡ºæœ€ä½³æ€§èƒ½ï¼Œç”šè‡³è¶…è¶Šäº†ä¸€äº›å¤§å‹é—­æºLLMsã€‚é’ˆå¯¹äºŒåå®¶å…¬å¸çš„å®è¯è¯„ä¼°æ˜¾ç¤ºï¼Œåˆ©ç”¨LLaMA-3.1-8Bæ¨¡å‹çš„AIçŸ¥è¯†åŠ©æ‰‹ç³»ç»Ÿé€šè¿‡å®ç°é«˜è¾¾90%çš„ä¿¡æ¯æŸ¥è¯¢é—®é¢˜ç­”æ¡ˆå‡†ç¡®æ€§ï¼Œæ¶ˆé™¤äº†å‘¼å«ä¸­å¿ƒä¸­çš„å†·å¯åŠ¨å·®è·ï¼Œä½¿å¾—RAGé©±åŠ¨çš„èŠå¤©æœºå™¨äººå¾—ä»¥ç«‹å³éƒ¨ç½²ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¯¹è¯AIç³»ç»Ÿåˆ©ç”¨RAGæŠ€æœ¯è§£å†³å®¢æˆ·é—®é¢˜æ­£é€æ¸æ™®åŠã€‚</li>
<li>å…¬å¸ç‰¹å®šçŸ¥è¯†åº“çš„ç¼ºä¹æ˜¯é›†æˆå¯¹è¯AIç³»ç»Ÿçš„éšœç¢ã€‚</li>
<li>AIçŸ¥è¯†åŠ©æ‰‹ç³»ç»Ÿé€šè¿‡æå–QAå¯¹è‡ªåŠ¨æ„å»ºçŸ¥è¯†åº“ã€‚</li>
<li>è½»é‡çº§LLMåœ¨å†…éƒ¨æ•°æ®ä¸Šçš„å¾®è°ƒè¡¨ç°å‡ºæœ€ä½³æ€§èƒ½ã€‚</li>
<li>AIçŸ¥è¯†åŠ©æ‰‹ç³»ç»Ÿæ¶ˆé™¤äº†å‘¼å«ä¸­å¿ƒçš„å†·å¯åŠ¨å·®è·ã€‚</li>
<li>AIçŸ¥è¯†åŠ©æ‰‹ç³»ç»Ÿçš„å‡†ç¡®æ€§é«˜è¾¾90%ï¼Œé€‚åˆç«‹å³éƒ¨ç½²RAGé©±åŠ¨çš„èŠå¤©æœºå™¨äººã€‚</li>
<li>å®è¯ç ”ç©¶è¯æ˜äº†AIçŸ¥è¯†åŠ©æ‰‹ç³»ç»Ÿçš„æœ‰æ•ˆæ€§ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.08149">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-93240272221c8b73469f4fcbcc21750c" align="middle">
<img src="https://picx.zhimg.com/v2-7236752646841659539e2e6c5edf84e3" align="middle">
<img src="https://picx.zhimg.com/v2-47bfed8186a621cd8975647e0528b5cc" align="middle">
<img src="https://picx.zhimg.com/v2-be5b77e3d70885a5f8f6d7bb6f75328d" align="middle">
<img src="https://picx.zhimg.com/v2-48788bff22872227a65d0e8a4d38698a" align="middle">
<img src="https://picx.zhimg.com/v2-11974e7c53233ce1909d7a2ab265ebd2" align="middle">
</details>


<h1 id="-9"><a href="#-9" class="headerlink" title=""></a></h1><h2 id="L2M-AID-Autonomous-Cyber-Physical-Defense-by-Fusing-Semantic-Reasoning-of-Large-Language-Models-with-Multi-Agent-Reinforcement-Learning-Preprint"><a href="#L2M-AID-Autonomous-Cyber-Physical-Defense-by-Fusing-Semantic-Reasoning-of-Large-Language-Models-with-Multi-Agent-Reinforcement-Learning-Preprint" class="headerlink" title="L2M-AID: Autonomous Cyber-Physical Defense by Fusing Semantic Reasoning   of Large Language Models with Multi-Agent Reinforcement Learning (Preprint)"></a>L2M-AID: Autonomous Cyber-Physical Defense by Fusing Semantic Reasoning   of Large Language Models with Multi-Agent Reinforcement Learning (Preprint)</h2><p><strong>Authors:Tianxiang Xu, Zhichao Wen, Xinyu Zhao, Jun Wang, Yan Li, Chang Liu</strong></p>
<p>The increasing integration of Industrial IoT (IIoT) exposes critical cyber-physical systems to sophisticated, multi-stage attacks that elude traditional defenses lacking contextual awareness. This paper introduces L2M-AID, a novel framework for Autonomous Industrial Defense using LLM-empowered, Multi-agent reinforcement learning. L2M-AID orchestrates a team of collaborative agents, each driven by a Large Language Model (LLM), to achieve adaptive and resilient security. The core innovation lies in the deep fusion of two AI paradigms: we leverage an LLM as a semantic bridge to translate vast, unstructured telemetry into a rich, contextual state representation, enabling agents to reason about adversary intent rather than merely matching patterns. This semantically-aware state empowers a Multi-Agent Reinforcement Learning (MARL) algorithm, MAPPO, to learn complex cooperative strategies. The MARL reward function is uniquely engineered to balance security objectives (threat neutralization) with operational imperatives, explicitly penalizing actions that disrupt physical process stability. To validate our approach, we conduct extensive experiments on the benchmark SWaT dataset and a novel synthetic dataset generated based on the MITRE ATT&amp;CK for ICS framework. Results demonstrate that L2M-AID significantly outperforms traditional IDS, deep learning anomaly detectors, and single-agent RL baselines across key metrics, achieving a 97.2% detection rate while reducing false positives by over 80% and improving response times by a factor of four. Crucially, it demonstrates superior performance in maintaining physical process stability, presenting a robust new paradigm for securing critical national infrastructure. </p>
<blockquote>
<p>éšç€å·¥ä¸šç‰©è”ç½‘ï¼ˆIIoTï¼‰çš„æ—¥ç›Šèåˆï¼Œå…³é”®çš„ç½‘ç»œç‰©ç†ç³»ç»Ÿé¢ä¸´é«˜çº§çš„å¤šé˜¶æ®µæ”»å‡»ï¼Œè¿™äº›æ”»å‡»èƒ½å¤Ÿèº²é¿ç¼ºä¹ä¸Šä¸‹æ–‡æ„è¯†çš„ä¼ ç»Ÿé˜²å¾¡æ‰‹æ®µã€‚æœ¬æ–‡ä»‹ç»äº†L2M-AIDï¼Œè¿™æ˜¯ä¸€ä¸ªä½¿ç”¨å¤§å‹è¯­è¨€æ¨¡å‹èµ‹èƒ½çš„å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ çš„æ–°å‹è‡ªä¸»å·¥ä¸šé˜²å¾¡æ¡†æ¶ã€‚L2M-AIDååŒä¸€ç»„åä½œçš„æ™ºèƒ½ä½“ï¼Œæ¯ä¸ªæ™ºèƒ½ä½“éƒ½ç”±å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰é©±åŠ¨ï¼Œä»¥å®ç°è‡ªé€‚åº”å’Œå¼¹æ€§å®‰å…¨ã€‚æ ¸å¿ƒåˆ›æ–°ä¹‹å¤„åœ¨äºä¸¤ç§äººå·¥æ™ºèƒ½èŒƒå¼çš„æ·±åº¦èåˆï¼šæˆ‘ä»¬åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ä½œä¸ºè¯­ä¹‰æ¡¥æ¢ï¼Œå°†å¤§é‡éç»“æ„åŒ–é¥æµ‹ä¿¡æ¯è½¬æ¢ä¸ºä¸°å¯Œçš„ä¸Šä¸‹æ–‡çŠ¶æ€è¡¨ç¤ºï¼Œä½¿æ™ºèƒ½ä½“èƒ½å¤Ÿæ¨ç†å¯¹æ‰‹çš„æ„å›¾ï¼Œè€Œä¸ä»…ä»…æ˜¯åŒ¹é…æ¨¡å¼ã€‚è¿™ç§è¯­ä¹‰æ„ŸçŸ¥çŠ¶æ€ä½¿å¾—å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ ï¼ˆMARLï¼‰ç®—æ³•MAPPOèƒ½å¤Ÿå­¦ä¹ å¤æ‚çš„åˆä½œç­–ç•¥ã€‚MARLå¥–åŠ±å‡½æ•°æ˜¯ç‹¬ç‰¹è®¾è®¡çš„ï¼Œæ—¨åœ¨å¹³è¡¡å®‰å…¨ç›®æ ‡ï¼ˆå¨èƒä¸­ç«‹ï¼‰ä¸æ“ä½œè¦æ±‚ï¼Œæ˜ç¡®æƒ©ç½šç ´åç‰©ç†è¿‡ç¨‹ç¨³å®šæ€§çš„è¡ŒåŠ¨ã€‚ä¸ºäº†éªŒè¯æˆ‘ä»¬çš„æ–¹æ³•ï¼Œæˆ‘ä»¬åœ¨SWaTæ•°æ®é›†çš„æ ‡å‡†åŸºå‡†æµ‹è¯•ä»¥åŠåŸºäºMITRE ATTï¼†CK for ICSæ¡†æ¶ç”Ÿæˆçš„æ–°å‹åˆæˆæ•°æ®é›†ä¸Šè¿›è¡Œäº†å¹¿æ³›çš„å®éªŒã€‚ç»“æœè¡¨æ˜ï¼ŒL2M-AIDåœ¨å…³é”®æŒ‡æ ‡ä¸Šæ˜¾è‘—ä¼˜äºä¼ ç»Ÿå…¥ä¾µæ£€æµ‹ç³»ç»Ÿã€æ·±åº¦å­¦ä¹ å¼‚å¸¸æ£€æµ‹å™¨å’Œå•æ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ åŸºå‡†çº¿ï¼Œæ£€æµ‹ç‡è¾¾åˆ°97.2%ï¼ŒåŒæ—¶å‡å°‘äº†è¶…è¿‡80%çš„è¯¯æŠ¥ï¼Œå¹¶å°†å“åº”æ—¶é—´æé«˜äº†å››å€ã€‚æœ€é‡è¦çš„æ˜¯ï¼Œå®ƒåœ¨ä¿æŒç‰©ç†è¿‡ç¨‹ç¨³å®šæ€§æ–¹é¢è¡¨ç°å‡ºå“è¶Šçš„æ€§èƒ½ï¼Œä¸ºå…³é”®å›½å®¶åŸºç¡€è®¾æ–½çš„å®‰å…¨æä¾›äº†ç¨³å¥çš„æ–°èŒƒå¼ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2510.07363v1">PDF</a> This preprint was submitted to IEEE TrustCom 2025. The accepted   version will be published under copyright 2025 IEEE</p>
<p><strong>Summary</strong>ï¼šéšç€å·¥ä¸šç‰©è”ç½‘ï¼ˆIIoTï¼‰çš„é›†æˆåº¦ä¸æ–­æé«˜ï¼Œå…³é”®çš„ç½‘ç»œç‰©ç†ç³»ç»Ÿé¢ä¸´å¤æ‚çš„å¤šé˜¶æ®µæ”»å‡»å¨èƒï¼Œä¼ ç»Ÿç¼ºä¹ä¸Šä¸‹æ–‡æ„è¯†çš„é˜²å¾¡æ‰‹æ®µå·²ä¸è¶³ä»¥åº”å¯¹ã€‚æœ¬æ–‡æå‡ºäº†åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹èµ‹èƒ½çš„å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ çš„è‡ªä¸»å·¥ä¸šé˜²å¾¡æ¡†æ¶L2M-AIDã€‚L2M-AIDåè°ƒæ™ºèƒ½ä½“å›¢é˜Ÿè¿›è¡Œè‡ªé€‚åº”å’Œå¼¹æ€§å®‰å…¨é˜²å¾¡ã€‚å…¶æ ¸å¿ƒåˆ›æ–°åœ¨äºä¸¤ç§äººå·¥æ™ºèƒ½èŒƒå¼çš„æ·±åº¦èåˆï¼šåˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ä½œä¸ºè¯­ä¹‰æ¡¥æ¢ï¼Œå°†å¤§é‡éç»“æ„åŒ–é¥æµ‹ä¿¡æ¯è½¬åŒ–ä¸ºä¸°å¯Œçš„ä¸Šä¸‹æ–‡çŠ¶æ€è¡¨ç¤ºï¼Œä½¿æ™ºèƒ½ä½“èƒ½å¤Ÿæ¨æ–­æ•Œæ–¹æ„å›¾è€Œä¸ä»…ä»…æ˜¯åŒ¹é…æ¨¡å¼ã€‚åŸºäºè¿™ç§è¯­ä¹‰æ„ŸçŸ¥çŠ¶æ€ï¼Œæˆ‘ä»¬åˆ©ç”¨å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ ç®—æ³•MAPPOå­¦ä¹ å¤æ‚çš„åˆä½œç­–ç•¥ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œåœ¨å…³é”®æŒ‡æ ‡ä¸Šï¼ŒL2M-AIDæ˜¾è‘—ä¼˜äºä¼ ç»Ÿå…¥ä¾µæ£€æµ‹ç³»ç»Ÿã€æ·±åº¦å­¦ä¹ å¼‚å¸¸æ£€æµ‹å™¨å’Œå•æ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ åŸºçº¿ï¼Œå®ç°äº†é«˜è¾¾97.2%çš„æ£€æµ‹ç‡ï¼ŒåŒæ—¶å‡å°‘äº†è¶…è¿‡80%çš„è¯¯æŠ¥å¹¶åŠ å¿«äº†å››å€çš„å“åº”æ—¶é—´ã€‚åœ¨ç»´æŠ¤ç‰©ç†è¿‡ç¨‹ç¨³å®šæ€§æ–¹é¢è¡¨ç°ä¼˜å¼‚ï¼Œä¸ºå…³é”®å›½å®¶åŸºç¡€è®¾æ–½çš„å®‰å…¨ä¿æŠ¤æä¾›äº†ç¨³å¥çš„æ–°èŒƒå¼ã€‚</p>
<p><strong>Key Takeaways</strong>:</p>
<ol>
<li>IIoTçš„é›†æˆå¢åŠ äº†å…³é”®ç½‘ç»œç‰©ç†ç³»ç»Ÿé¢ä¸´çš„å¤šé˜¶æ®µæ”»å‡»é£é™©ã€‚</li>
<li>L2M-AIDæ˜¯ä¸€ä¸ªåˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹èµ‹èƒ½çš„å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ æ¡†æ¶è¿›è¡Œè‡ªé€‚åº”å’Œå¼¹æ€§å®‰å…¨é˜²å¾¡ã€‚</li>
<li>LLMç”¨äºå°†éç»“æ„åŒ–é¥æµ‹è½¬åŒ–ä¸ºä¸Šä¸‹æ–‡çŠ¶æ€è¡¨ç¤ºï¼Œå¸®åŠ©æ™ºèƒ½ä½“ç†è§£æ•Œæ–¹æ„å›¾ã€‚</li>
<li>å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ ç®—æ³•MAPPOç”¨äºå­¦ä¹ å¤æ‚çš„åˆä½œç­–ç•¥ä»¥åº”å¯¹æ”»å‡»ã€‚</li>
<li>L2M-AIDåœ¨æ£€æµ‹ç‡ã€è¯¯æŠ¥ç‡å’Œå“åº”æ—¶é—´æ–¹é¢è¡¨ç°ä¼˜äºä¼ ç»Ÿå®‰å…¨ç³»ç»Ÿã€‚</li>
<li>L2M-AIDåœ¨ä¿æŒç‰©ç†è¿‡ç¨‹ç¨³å®šæ€§æ–¹é¢å…·æœ‰å‡ºè‰²çš„æ€§èƒ½ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2510.07363">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-4af08f18a6f9e028ca97e22e33d12b1f" align="middle">
<img src="https://picx.zhimg.com/v2-8c607802bd522c19b0b9779763481abc" align="middle">
<img src="https://picx.zhimg.com/v2-9436665c01dbb519f1e08984daeb1cc2" align="middle">
<img src="https://picx.zhimg.com/v2-33e1ce80ff17c327a26550cec9d49b77" align="middle">
<img src="https://picx.zhimg.com/v2-382adb3dec2f88d76d9413f15cfb0eea" align="middle">
<img src="https://picx.zhimg.com/v2-76464525abbda66c9424004dd369bab2" align="middle">
<img src="https://picx.zhimg.com/v2-971a73cbdd8677e2e6824e365af2c1a4" align="middle">
<img src="https://picx.zhimg.com/v2-032121491e3224b8e9447a818f11faf3" align="middle">
<img src="https://picx.zhimg.com/v2-58643b3188dce6dedde48b0f44a44a97" align="middle">
</details>


<h1 id="-10"><a href="#-10" class="headerlink" title=""></a></h1><h2 id="Kimi-Dev-Agentless-Training-as-Skill-Prior-for-SWE-Agents"><a href="#Kimi-Dev-Agentless-Training-as-Skill-Prior-for-SWE-Agents" class="headerlink" title="Kimi-Dev: Agentless Training as Skill Prior for SWE-Agents"></a>Kimi-Dev: Agentless Training as Skill Prior for SWE-Agents</h2><p><strong>Authors:Zonghan Yang, Shengjie Wang, Kelin Fu, Wenyang He, Weimin Xiong, Yibo Liu, Yibo Miao, Bofei Gao, Yejie Wang, Yingwei Ma, Yanhao Li, Yue Liu, Zhenxing Hu, Kaitai Zhang, Shuyi Wang, Huarong Chen, Flood Sung, Yang Liu, Yang Gao, Zhilin Yang, Tianyu Liu</strong></p>
<p>Large Language Models (LLMs) are increasingly applied to software engineering (SWE), with SWE-bench as a key benchmark. Solutions are split into SWE-Agent frameworks with multi-turn interactions and workflow-based Agentless methods with single-turn verifiable steps. We argue these paradigms are not mutually exclusive: reasoning-intensive Agentless training induces skill priors, including localization, code edit, and self-reflection that enable efficient and effective SWE-Agent adaptation. In this work, we first curate the Agentless training recipe and present Kimi-Dev, an open-source SWE LLM achieving 60.4% on SWE-bench Verified, the best among workflow approaches. With additional SFT adaptation on 5k publicly-available trajectories, Kimi-Dev powers SWE-Agents to 48.6% pass@1, on par with that of Claude 3.5 Sonnet (241022 version). These results show that structured skill priors from Agentless training can bridge workflow and agentic frameworks for transferable coding agents. </p>
<blockquote>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰è¶Šæ¥è¶Šå¤šåœ°åº”ç”¨äºè½¯ä»¶å·¥ç¨‹ï¼ˆSWEï¼‰ï¼Œè€ŒSWE-benchæ˜¯å…¶ä¸­çš„ä¸€é¡¹å…³é”®åŸºå‡†æµ‹è¯•ã€‚è§£å†³æ–¹æ¡ˆåˆ†ä¸ºSWE-Agentæ¡†æ¶å’Œå¤šè½®äº¤äº’çš„Agentlessæ–¹æ³•ä»¥åŠåŸºäºå·¥ä½œæµçš„å•è½®å¯éªŒè¯æ­¥éª¤ã€‚æˆ‘ä»¬è®¤ä¸ºè¿™ä¸¤ç§èŒƒå¼å¹¶ä¸æ˜¯ç›¸äº’æ’æ–¥çš„ï¼šæ³¨é‡æ¨ç†çš„Agentlessè®­ç»ƒä¼šå¼•å…¥æŠ€èƒ½å…ˆéªŒï¼ŒåŒ…æ‹¬å®šä½ã€ä»£ç ç¼–è¾‘å’Œè‡ªæˆ‘åæ€ï¼Œè¿™äº›éƒ½èƒ½å®ç°é«˜æ•ˆä¸”æœ‰æ•ˆçš„SWE-Agenté€‚åº”ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬é¦–å…ˆåˆ¶å®šäº†Agentlessè®­ç»ƒé…æ–¹ï¼Œå¹¶æ¨å‡ºäº†Kimi-Devï¼Œè¿™æ˜¯ä¸€ä¸ªå¼€æºçš„SWE LLMï¼Œåœ¨SWE-bench Verifiedä¸Šè¾¾åˆ°äº†60.4%ï¼Œæ˜¯å·¥ä½œæµç¨‹æ–¹æ³•ä¸­çš„æœ€ä½³æˆç»©ã€‚åœ¨5kä¸ªå…¬å¼€å¯ç”¨çš„è½¨è¿¹ä¸Šè¿›è¡Œé¢å¤–çš„SFTé€‚åº”åï¼ŒKimi-Devä½¿SWE-Agentsè¾¾åˆ°48.6%çš„pass@1ï¼Œä¸Claude 3.5 Sonnetï¼ˆ241022ç‰ˆæœ¬ï¼‰æŒå¹³ã€‚è¿™äº›ç»“æœè¡¨æ˜ï¼Œæ¥è‡ªAgentlessè®­ç»ƒçš„ç»“æ„åŒ–æŠ€èƒ½å…ˆéªŒå¯ä»¥å¼¥åˆå·¥ä½œæµç¨‹å’Œæ™ºèƒ½æ¡†æ¶ä¹‹é—´çš„å·®è·ï¼Œä»è€Œæ‰“é€ å¯è¿ç§»çš„ç¼–ç ä»£ç†ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.23045v2">PDF</a> 58 pages</p>
<p><strong>Summary</strong></p>
<p>å¤§å‹è¯­è¨€æ¨¡å‹åœ¨è½¯ä»¶å·¥ç¨‹é¢†åŸŸçš„åº”ç”¨æ—¥ç›Šå¹¿æ³›ï¼Œå…¶ä¸­SWE-benchæ˜¯é‡è¦çš„åŸºå‡†æµ‹è¯•ä¹‹ä¸€ã€‚æ–‡ç« ä»‹ç»äº†ä¸¤ç§è§£å†³æ–¹æ¡ˆï¼šåŸºäºå¤šå›åˆäº¤äº’çš„SWE-Agentæ¡†æ¶å’ŒåŸºäºå·¥ä½œæµçš„Agentlessæ–¹æ³•ã€‚æ–‡ç« è®¤ä¸ºè¿™ä¸¤ç§èŒƒå¼å¹¶éç›¸äº’æ’æ–¥ï¼Œè€Œæ˜¯å¯ä»¥é€šè¿‡æ— ä»£ç†è®­ç»ƒä¸­çš„æ¨ç†å¯†é›†å‹æŠ€èƒ½ä¼˜å…ˆäº‹é¡¹ï¼ˆå¦‚æœ¬åœ°åŒ–ã€ä»£ç ç¼–è¾‘å’Œè‡ªæˆ‘åæ€ï¼‰æ¥å®ç°é«˜æ•ˆçš„SWE-Agenté€‚åº”ã€‚åœ¨æ­¤å·¥ä½œä¸­ï¼Œä½œè€…é¦–å…ˆåˆ¶å®šäº†æ— ä»£ç†è®­ç»ƒæ–¹æ¡ˆï¼Œå¹¶æ¨å‡ºäº†Kimi-Devè¿™ä¸€å¼€æºè½¯ä»¶å·¥ç¨‹å¸ˆå¤§å‹è¯­è¨€æ¨¡å‹ï¼Œåœ¨SWE-bench Verifiedä¸Šçš„è¡¨ç°è¾¾åˆ°60.4%ï¼Œåœ¨åŸºäºå·¥ä½œæµçš„æ–¹æ³•ä¸­è¡¨ç°æœ€ä½³ã€‚é€šè¿‡å¯¹5,000ä¸ªå…¬å¼€è½¨è¿¹è¿›è¡Œé™„åŠ çš„SFTé€‚åº”ï¼ŒKimi-Devä½¿SWE-Agentsè¾¾åˆ°48.6%çš„pass@1ç‡ï¼Œä¸Claude 3.5 Sonnetï¼ˆ241022ç‰ˆæœ¬ï¼‰ç›¸å½“ã€‚è¿™äº›ç»“æœè¡¨æ˜ï¼Œæ¥è‡ªæ— ä»£ç†è®­ç»ƒçš„ç»“æ„åŒ–æŠ€èƒ½ä¼˜å…ˆçº§å¯ä»¥å¼¥åˆå·¥ä½œæµå’Œæ™ºèƒ½ä»£ç†æ¡†æ¶ä¹‹é—´çš„å·®è·ï¼Œä¸ºå¯è¿ç§»ç¼–ç ä»£ç†æä¾›å¯èƒ½ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å¤§å‹è¯­è¨€æ¨¡å‹åœ¨è½¯ä»¶å·¥ç¨‹é¢†åŸŸçš„åº”ç”¨æ­£åœ¨å¢é•¿ï¼Œå…¶ä¸­SWE-benchæ˜¯é‡è¦çš„æ€§èƒ½åŸºå‡†ã€‚</li>
<li>æ–‡ç« ä»‹ç»äº†ä¸¤ç§ä¸»è¦çš„è§£å†³æ–¹æ¡ˆï¼šåŸºäºå¤šå›åˆäº¤äº’çš„SWE-Agentæ¡†æ¶å’ŒåŸºäºå·¥ä½œæµçš„Agentlessæ–¹æ³•ã€‚</li>
<li>æ–‡ç« æŒ‡å‡ºè¿™ä¸¤ç§è§£å†³æ–¹æ¡ˆå¹¶éç›¸äº’æ’æ–¥ï¼Œè€Œæ˜¯å¯ä»¥é€šè¿‡æ— ä»£ç†è®­ç»ƒä¸­çš„æŠ€èƒ½ä¼˜å…ˆäº‹é¡¹æ¥å®ç°é«˜æ•ˆé€‚åº”ã€‚</li>
<li>æ–‡ç« æå‡ºäº†æ— ä»£ç†è®­ç»ƒçš„æ–¹æ³•ï¼Œå¹¶ä»‹ç»äº†Kimi-Devè¿™ä¸€å¼€æºè½¯ä»¶å·¥ç¨‹å¸ˆå¤§å‹è¯­è¨€æ¨¡å‹çš„è¡¨ç°å’Œä¼˜åŠ¿ã€‚</li>
<li>Kimi-Devé€šè¿‡é¢å¤–çš„SFTé€‚åº”æé«˜äº†æ€§èƒ½ï¼Œä¸æœ€æ–°çš„æ–¹æ³•è¡¨ç°ç›¸å½“ã€‚</li>
<li>ç»“æ„åŒ–çš„æŠ€èƒ½ä¼˜å…ˆçº§å¯ä»¥å¸®åŠ©å¼¥åˆå·¥ä½œæµå’Œæ™ºèƒ½ä»£ç†æ¡†æ¶ä¹‹é—´çš„å·®è·ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.23045">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-cd2440f08bbf59a316cd59e6d78b8102" align="middle">
<img src="https://picx.zhimg.com/v2-b9f3ec2f3f23d4b01d457b5530fe78a1" align="middle">
<img src="https://picx.zhimg.com/v2-350aba9d3f02d29d655d9f39d6b7f47b" align="middle">
<img src="https://picx.zhimg.com/v2-c66af6bf5ea5e152ecff9cc47d8d7efc" align="middle">
<img src="https://picx.zhimg.com/v2-4f2de0cca086d805c8f5d2f8dd117e15" align="middle">
</details>


<h1 id="-11"><a href="#-11" class="headerlink" title=""></a></h1><h2 id="Hierarchical-Reinforcement-Learning-with-Low-Level-MPC-for-Multi-Agent-Control"><a href="#Hierarchical-Reinforcement-Learning-with-Low-Level-MPC-for-Multi-Agent-Control" class="headerlink" title="Hierarchical Reinforcement Learning with Low-Level MPC for Multi-Agent   Control"></a>Hierarchical Reinforcement Learning with Low-Level MPC for Multi-Agent   Control</h2><p><strong>Authors:Max Studt, Georg Schildbach</strong></p>
<p>Achieving safe and coordinated behavior in dynamic, constraint-rich environments remains a major challenge for learning-based control. Pure end-to-end learning often suffers from poor sample efficiency and limited reliability, while model-based methods depend on predefined references and struggle to generalize. We propose a hierarchical framework that combines tactical decision-making via reinforcement learning (RL) with low-level execution through Model Predictive Control (MPC). For the case of multi-agent systems this means that high-level policies select abstract targets from structured regions of interest (ROIs), while MPC ensures dynamically feasible and safe motion. Tested on a predator-prey benchmark, our approach outperforms end-to-end and shielding-based RL baselines in terms of reward, safety, and consistency, underscoring the benefits of combining structured learning with model-based control. </p>
<blockquote>
<p>åœ¨åŠ¨æ€ã€çº¦æŸä¸°å¯Œçš„ç¯å¢ƒä¸­å®ç°å®‰å…¨å’Œåè°ƒçš„è¡Œä¸ºä»ç„¶æ˜¯åŸºäºå­¦ä¹ çš„æ§åˆ¶é¢ä¸´çš„ä¸€ä¸ªä¸»è¦æŒ‘æˆ˜ã€‚çº¯ç«¯åˆ°ç«¯å­¦ä¹ ç»å¸¸é¢ä¸´æ ·æœ¬æ•ˆç‡ä½å’Œå¯é æ€§æœ‰é™çš„é—®é¢˜ï¼Œè€ŒåŸºäºæ¨¡å‹çš„æ–¹æ³•ä¾èµ–äºé¢„å…ˆå®šä¹‰çš„å‚è€ƒï¼Œå¹¶ä¸”åœ¨æ³›åŒ–æ–¹é¢é‡åˆ°å›°éš¾ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§å±‚æ¬¡æ¡†æ¶ï¼Œå®ƒé€šè¿‡å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰è¿›è¡Œæˆ˜æœ¯å†³ç­–ï¼Œå¹¶é€šè¿‡æ¨¡å‹é¢„æµ‹æ§åˆ¶ï¼ˆMPCï¼‰è¿›è¡Œä½çº§æ‰§è¡Œã€‚åœ¨å¤šæ™ºèƒ½ä½“ç³»ç»Ÿçš„æƒ…å†µä¸‹ï¼Œè¿™æ„å‘³ç€é«˜çº§ç­–ç•¥ä»ç»“æ„åŒ–æ„Ÿå…´è¶£åŒºåŸŸï¼ˆROIï¼‰ä¸­é€‰æ‹©æŠ½è±¡ç›®æ ‡ï¼Œè€ŒMPCç¡®ä¿åŠ¨æ€å¯è¡Œå’Œå®‰å…¨è¿åŠ¨ã€‚åœ¨æ•é£Ÿè€…-çŒç‰©åŸºå‡†æµ‹è¯•ä¸Šè¿›è¡Œçš„æµ‹è¯•è¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨å¥–åŠ±ã€å®‰å…¨æ€§å’Œä¸€è‡´æ€§æ–¹é¢ä¼˜äºç«¯åˆ°ç«¯å’ŒåŸºäºå±è”½çš„RLåŸºå‡†æµ‹è¯•ï¼Œè¿™çªå‡ºäº†å°†ç»“æ„åŒ–å­¦ä¹ ä¸åŸºäºæ¨¡å‹çš„æ§åˆ¶ç›¸ç»“åˆçš„å¥½å¤„ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.15799v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>åœ¨åŠ¨æ€ã€çº¦æŸä¸°å¯Œçš„ç¯å¢ƒä¸­å®ç°å®‰å…¨å’Œåè°ƒçš„è¡Œä¸ºä»ç„¶æ˜¯åŸºäºå­¦ä¹ çš„æ§åˆ¶é¢ä¸´çš„ä¸€ä¸ªä¸»è¦æŒ‘æˆ˜ã€‚çº¯ç«¯åˆ°ç«¯å­¦ä¹ å¾€å¾€å­˜åœ¨æ ·æœ¬æ•ˆç‡ä½å’Œå¯é æ€§æœ‰é™çš„é—®é¢˜ï¼Œè€ŒåŸºäºæ¨¡å‹çš„æ–¹æ³•ä¾èµ–äºé¢„å…ˆå®šä¹‰çš„å‚è€ƒï¼Œéš¾ä»¥æ¨å¹¿ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§å±‚æ¬¡æ¡†æ¶ï¼Œé€šè¿‡å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰è¿›è¡Œæˆ˜æœ¯å†³ç­–ï¼Œé€šè¿‡æ¨¡å‹é¢„æµ‹æ§åˆ¶ï¼ˆMPCï¼‰è¿›è¡Œä½çº§æ‰§è¡Œã€‚åœ¨å¤šæ™ºèƒ½ä½“ç³»ç»Ÿä¸­ï¼Œè¿™æ„å‘³ç€é«˜çº§ç­–ç•¥ä»ç»“æ„åŒ–æ„Ÿå…´è¶£åŒºåŸŸï¼ˆROIï¼‰ä¸­é€‰æ‹©æŠ½è±¡ç›®æ ‡ï¼Œè€ŒMPCç¡®ä¿åŠ¨æ€å¯è¡Œå’Œå®‰å…¨è¿åŠ¨ã€‚åœ¨æ•é£Ÿè€…-çŒç‰©åŸºå‡†æµ‹è¯•ä¸­ï¼Œæˆ‘ä»¬çš„æ–¹æ³•ä¼˜äºç«¯åˆ°ç«¯å’ŒåŸºäºå±è”½çš„RLåŸºå‡†æµ‹è¯•ï¼Œåœ¨å¥–åŠ±ã€å®‰å…¨æ€§å’Œä¸€è‡´æ€§æ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œçªå‡ºäº†ç»“åˆç»“æ„åŒ–å­¦ä¹ ä¸åŸºäºæ¨¡å‹çš„æ§åˆ¶çš„ä¼˜åŠ¿ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>å®ç°å®‰å…¨å’Œåè°ƒçš„è¡Œä¸ºåœ¨åŠ¨æ€ã€çº¦æŸä¸°å¯Œçš„ç¯å¢ƒä¸­ä»æ˜¯ä¸»è¦æŒ‘æˆ˜ã€‚</li>
<li>çº¯ç«¯åˆ°ç«¯å­¦ä¹ å­˜åœ¨æ ·æœ¬æ•ˆç‡ä½å’Œå¯é æ€§æœ‰é™çš„ç¼ºé™·ã€‚</li>
<li>åŸºäºæ¨¡å‹çš„æ–¹æ³•ä¾èµ–äºé¢„è®¾å‚è€ƒï¼Œéš¾ä»¥æ¨å¹¿ã€‚</li>
<li>æå‡ºçš„å±‚æ¬¡æ¡†æ¶ç»“åˆäº†å¼ºåŒ–å­¦ä¹ ä¸æ¨¡å‹é¢„æµ‹æ§åˆ¶ã€‚</li>
<li>å¤šæ™ºèƒ½ä½“ç³»ç»Ÿä¸­ï¼Œé«˜çº§ç­–ç•¥ä»ç»“æ„åŒ–æ„Ÿå…´è¶£åŒºåŸŸé€‰æ‹©æŠ½è±¡ç›®æ ‡ã€‚</li>
<li>æ¨¡å‹é¢„æµ‹æ§åˆ¶ç¡®ä¿åŠ¨æ€å¯è¡Œå’Œå®‰å…¨è¿åŠ¨ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.15799">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-bc6eef3041bcdbd468ce4d9774b2879c" align="middle">
<img src="https://picx.zhimg.com/v2-1b8735852eb03ed47344fa655c95cbce" align="middle">
<img src="https://picx.zhimg.com/v2-9d1cd1620923fea5da54f5bfd1e805ea" align="middle">
<img src="https://picx.zhimg.com/v2-37f5ff28d2ba108f823a4c47cf5b0149" align="middle">
<img src="https://picx.zhimg.com/v2-d3f56fde765928e2f109cb8d27a184da" align="middle">
<img src="https://picx.zhimg.com/v2-b2a7bf4d1b2b936f8d072cf62e594c94" align="middle">
<img src="https://picx.zhimg.com/v2-bd48eef002e5ffe7919433c074380250" align="middle">
<img src="https://picx.zhimg.com/v2-d05f9a029d93bc6a1ba578ff9323075e" align="middle">
</details>


<h1 id="-12"><a href="#-12" class="headerlink" title=""></a></h1><h2 id="Neuro-Symbolic-Agents-with-Modal-Logic-for-Autonomous-Diagnostics"><a href="#Neuro-Symbolic-Agents-with-Modal-Logic-for-Autonomous-Diagnostics" class="headerlink" title="Neuro-Symbolic Agents with Modal Logic for Autonomous Diagnostics"></a>Neuro-Symbolic Agents with Modal Logic for Autonomous Diagnostics</h2><p><strong>Authors:Antonin Sulc, Thorsten Hellert</strong></p>
<p>The development of intelligent agents, particularly those powered by language models (LMs), has shown the critical role in various environments that require intelligent and autonomous decision. Environments are not passive testing grounds and they represent the data required for agents to learn and exhibit very challenging conditions that require adaptive, complex and autonomous capacity to make decisions. While the paradigm of scaling models and datasets has led to remarkable emergent capabilities, we argue that scaling the structure, fidelity, and logical consistency of agent reasoning within these environments is a crucial, yet underexplored, dimension of AI research. This paper introduces a neuro-symbolic multi-agent architecture where the belief states of individual agents are formally represented as Kripke models. This foundational choice enables them to reason about known concepts of \emph{possibility} and \emph{necessity} using the formal language of modal logic. In this work, we use of immutable, domain-specific knowledge to make infere information, which is encoded as logical constraints essential for proper diagnosis. In the proposed model, we show constraints that actively guide the hypothesis generation of LMs, effectively preventing them from reaching physically or logically untenable conclusions. In a high-fidelity simulated particle accelerator environment, our system successfully diagnoses complex, cascading failures by combining the powerful semantic intuition of LMs with the rigorous, verifiable validation of modal logic and a factual world model and showcasing a viable path toward more robust, reliable, and verifiable autonomous agents. </p>
<blockquote>
<p>æ™ºèƒ½ä½“ï¼Œç‰¹åˆ«æ˜¯é‚£äº›ç”±è¯­è¨€æ¨¡å‹ï¼ˆLMsï¼‰é©±åŠ¨çš„æ™ºèƒ½ä½“çš„å‘å±•ï¼Œå·²ç»æ˜¾ç¤ºå‡ºåœ¨å„ç§éœ€è¦æ™ºèƒ½å’Œè‡ªä¸»å†³ç­–çš„ç¯å¢ƒä¸­å‘æŒ¥ç€å…³é”®ä½œç”¨ã€‚ç¯å¢ƒå¹¶ä¸æ˜¯è¢«åŠ¨çš„æµ‹è¯•åœºï¼Œå®ƒä»¬ä»£è¡¨ç€æ™ºèƒ½ä½“æ‰€éœ€è¦çš„æ•°æ®ï¼Œå¹¶ä¸”å±•ç¤ºå‡ºå„ç§å…·æœ‰æŒ‘æˆ˜æ€§çš„æ¡ä»¶ï¼Œè¿™äº›æ¡ä»¶éœ€è¦æ™ºèƒ½ä½“å…·å¤‡é€‚åº”æ€§å¼ºã€å¤æ‚å’Œè‡ªä¸»çš„å†³ç­–èƒ½åŠ›ã€‚å°½ç®¡æ‰©å¤§æ¨¡å‹å’Œæ•°æ®é›†çš„æ¨¡å¼å·²ç»å¸¦æ¥äº†æ˜¾è‘—çš„æ–°å…´èƒ½åŠ›ï¼Œä½†æˆ‘ä»¬è®¤ä¸ºæ‰©å¤§è¿™äº›ç¯å¢ƒä¸­æ™ºèƒ½ä½“çš„ç»“æ„ã€ä¿çœŸåº¦å’Œé€»è¾‘ä¸€è‡´æ€§æ˜¯ä¸€ä¸ªå…³é”®ä½†å°šæœªè¢«å……åˆ†ç ”ç©¶çš„AIç ”ç©¶é¢†åŸŸç»´åº¦ã€‚æœ¬æ–‡ä»‹ç»äº†ä¸€ç§ç¥ç»ç¬¦å·å¤šæ™ºèƒ½ä½“æ¶æ„ï¼Œå…¶ä¸­å•ä¸ªæ™ºèƒ½ä½“çš„ä¿¡å¿µçŠ¶æ€è¢«å½¢å¼åŒ–è¡¨ç¤ºä¸ºKripkeæ¨¡å‹ã€‚è¿™ä¸€åŸºæœ¬é€‰æ‹©ä½¿ä»–ä»¬èƒ½å¤Ÿåˆ©ç”¨æ¨¡æ€é€»è¾‘çš„è‡ªç„¶è¯­è¨€æ¥æ¨ç†â€œå¯èƒ½æ€§â€å’Œâ€œå¿…è¦æ€§â€ç­‰å·²çŸ¥æ¦‚å¿µã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨ä¸å¯å˜çš„é¢†åŸŸç‰¹å®šçŸ¥è¯†æ¥è¿›è¡Œä¿¡æ¯æ¨æ–­ï¼Œè¿™äº›ä¿¡æ¯è¢«ç¼–ç ä¸ºé€»è¾‘çº¦æŸï¼Œå¯¹äºé€‚å½“çš„è¯Šæ–­è‡³å…³é‡è¦ã€‚åœ¨æå‡ºçš„æ¨¡å‹ä¸­ï¼Œæˆ‘ä»¬å±•ç¤ºäº†èƒ½å¤Ÿä¸»åŠ¨å¼•å¯¼LMså‡è®¾ç”Ÿæˆçš„çº¦æŸï¼Œæœ‰æ•ˆåœ°é˜²æ­¢å®ƒä»¬å¾—å‡ºç‰©ç†æˆ–é€»è¾‘ä¸Šä¸å¯æŒç»­çš„ç»“è®ºã€‚åœ¨ä¸€ä¸ªé«˜ä¿çœŸæ¨¡æ‹Ÿç²’å­åŠ é€Ÿå™¨ç¯å¢ƒä¸­ï¼Œæˆ‘ä»¬çš„ç³»ç»ŸæˆåŠŸåœ°ç»“åˆäº†LMsçš„å¼ºå¤§è¯­ä¹‰ç›´è§‰ã€æ¨¡æ€é€»è¾‘çš„ä¸¥æ ¼å¯éªŒè¯éªŒè¯å’Œä¸€ä¸ªäº‹å®ä¸–ç•Œæ¨¡å‹ï¼Œå¯¹å¤æ‚çš„è¿é”æ•…éšœè¿›è¡Œäº†è¯Šæ–­ï¼Œå¹¶å±•ç¤ºäº†ä¸€æ¡æœç€æ›´ç¨³å¥ã€å¯é å’Œå¯éªŒè¯çš„è‡ªä¸»æ™ºèƒ½ä½“çš„å¯è¡Œé“è·¯ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.11943v2">PDF</a> 10 pages, 1 figure, Scaling Environments for Agents (SEA) Workshop at   NeuralIPS</p>
<p><strong>Summary</strong></p>
<p>æœ¬æ–‡æ¢è®¨äº†æ™ºèƒ½ä»£ç†çš„å‘å±•ï¼Œç‰¹åˆ«æ˜¯åœ¨éœ€è¦æ™ºèƒ½å’Œè‡ªä¸»å†³ç­–çš„ç¯å¢ƒä¸­ï¼Œå¦‚è¯­è¨€æ¨¡å‹é©±åŠ¨çš„æ™ºèƒ½ä»£ç†ã€‚æ–‡ç« æå‡ºäº†ä¸€ä¸ªç¥ç»ç¬¦å·å¤šä»£ç†æ¶æ„ï¼Œåˆ©ç”¨æ¨¡æ€é€»è¾‘çš„å½¢å¼è¯­è¨€å¯¹å¯èƒ½æ€§å’Œå¿…è¦æ€§è¿›è¡Œæ¨ç†ã€‚è¯¥æ¶æ„åˆ©ç”¨é¢†åŸŸç‰¹å®šçŸ¥è¯†æ¥æ¨æ–­ä¿¡æ¯ï¼Œå¹¶å±•ç¤ºäº†æŒ‡å¯¼å‡è®¾ç”Ÿæˆçš„é€»è¾‘çº¦æŸï¼Œæœ‰æ•ˆé˜²æ­¢äº†è¯­è¨€æ¨¡å‹å¾—å‡ºç‰©ç†æˆ–é€»è¾‘ä¸Šä¸å¯è¡Œçš„ç»“è®ºã€‚åœ¨æ¨¡æ‹Ÿç²’å­åŠ é€Ÿå™¨ç¯å¢ƒä¸­ï¼Œè¯¥ç³»ç»ŸæˆåŠŸç»“åˆäº†è¯­è¨€æ¨¡å‹çš„å¼ºå¤§è¯­ä¹‰ç›´è§‰ã€æ¨¡æ€é€»è¾‘çš„ä¸¥æ ¼éªŒè¯å’Œç°å®ä¸–ç•Œæ¨¡å‹ï¼Œå±•ç¤ºäº†å®ç°æ›´ç¨³å¥ã€å¯é å’Œå¯éªŒè¯çš„è‡ªä¸»ä»£ç†çš„å¯è¡Œé€”å¾„ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li>æ™ºèƒ½ä»£ç†åœ¨éœ€è¦æ™ºèƒ½å’Œè‡ªä¸»å†³ç­–çš„ç¯å¢ƒä¸­æ‰®æ¼”å…³é”®è§’è‰²ï¼Œç‰¹åˆ«æ˜¯åœ¨å¤æ‚å¤šå˜çš„ç¯å¢ƒä¸­ã€‚</li>
<li>è¯­è¨€æ¨¡å‹ï¼ˆLMsï¼‰æ˜¯æ™ºèƒ½ä»£ç†çš„é‡è¦ç»„æˆéƒ¨åˆ†ï¼Œå…¶èƒ½åŠ›éœ€è¦åœ¨å„ç§ç¯å¢ƒä¸­è¿›è¡Œé€‚åº”å’Œè°ƒæ•´ã€‚</li>
<li>ç¥ç»ç¬¦å·å¤šä»£ç†æ¶æ„åˆ©ç”¨æ¨¡æ€é€»è¾‘çš„å½¢å¼è¯­è¨€è¿›è¡Œæ¨ç†ï¼Œå®ç°å¯¹å¯èƒ½æ€§å’Œå¿…è¦æ€§çš„ç†è§£ã€‚</li>
<li>è¯¥æ¶æ„åˆ©ç”¨é¢†åŸŸç‰¹å®šçŸ¥è¯†æ¥æ¨æ–­ä¿¡æ¯ï¼Œè¿™æ˜¯è¿›è¡Œé€‚å½“è¯Šæ–­çš„é€»è¾‘çº¦æŸçš„å…³é”®ã€‚</li>
<li>æå‡ºçš„æ¨¡å‹å±•ç¤ºäº†å¦‚ä½•æŒ‡å¯¼è¯­è¨€æ¨¡å‹çš„å‡è®¾ç”Ÿæˆï¼Œé˜²æ­¢å…¶å¾—å‡ºç‰©ç†æˆ–é€»è¾‘ä¸Šä¸å¯è¡Œçš„ç»“è®ºã€‚</li>
<li>åœ¨æ¨¡æ‹Ÿç²’å­åŠ é€Ÿå™¨ç¯å¢ƒä¸­ï¼Œç»“åˆè¯­è¨€æ¨¡å‹çš„è¯­ä¹‰ç›´è§‰ã€æ¨¡æ€é€»è¾‘çš„éªŒè¯å’Œç°å®ä¸–ç•Œæ¨¡å‹ï¼Œå®ç°äº†å¯¹å¤æ‚çº§è”æ•…éšœçš„ç¨³å¥è¯Šæ–­ã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.11943">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-56c5a3768e31d5cb85f784d6b858ab48" align="middle">
</details>


<h1 id="-13"><a href="#-13" class="headerlink" title=""></a></h1><h2 id="Scaling-up-Multi-Turn-Off-Policy-RL-and-Multi-Agent-Tree-Search-for-LLM-Step-Provers"><a href="#Scaling-up-Multi-Turn-Off-Policy-RL-and-Multi-Agent-Tree-Search-for-LLM-Step-Provers" class="headerlink" title="Scaling up Multi-Turn Off-Policy RL and Multi-Agent Tree Search for LLM   Step-Provers"></a>Scaling up Multi-Turn Off-Policy RL and Multi-Agent Tree Search for LLM   Step-Provers</h2><p><strong>Authors:Ran Xin, Zeyu Zheng, Yanchen Nie, Kun Yuan, Xia Xiao</strong></p>
<p>The integration of Large Language Models (LLMs) into automated theorem proving has shown immense promise, yet is fundamentally constrained by challenges in scaling up both training-time reinforcement learning (RL) and inference-time compute. This paper introduces \texttt{BFS-Prover-V2}, a system designed to address this dual scaling problem. We present two primary innovations. The first is a novel multi-turn off-policy RL framework for continually improving the performance of LLM step-prover at training time. This framework, inspired by the principles of AlphaZero, utilizes a multi-stage expert iteration pipeline featuring adaptive tactic-level data filtering and periodic retraining to surmount the performance plateaus that typically curtail long-term RL in LLM-based agents. The second innovation is a planner-enhanced multi-agent search architecture that scales reasoning capabilities at inference time. This architecture employs a general reasoning model as a high-level planner to iteratively decompose complex theorems into a sequence of simpler subgoals. This hierarchical approach substantially reduces the search space, enabling a team of parallel prover agents to collaborate efficiently by leveraging a shared proof cache. We demonstrate that this dual approach to scaling yields state-of-the-art results on established formal mathematics benchmarks. \texttt{BFS-Prover-V2} achieves 95.08% and 41.4% on the MiniF2F and ProofNet test sets respectively. While demonstrated in the domain of formal mathematics, the RL and inference techniques presented in this work are of broader interest and may be applied to other domains requiring long-horizon multi-turn reasoning and complex search. </p>
<blockquote>
<p>å°†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰é›†æˆåˆ°è‡ªåŠ¨åŒ–å®šç†è¯æ˜ä¸­æ˜¾ç¤ºå‡ºå·¨å¤§çš„æ½œåŠ›ï¼Œä½†ä»æ ¹æœ¬ä¸Šå—åˆ°è®­ç»ƒæ—¶å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰å’Œæ¨ç†æ—¶è®¡ç®—æ‰©å±•æŒ‘æˆ˜çš„é™åˆ¶ã€‚æœ¬æ–‡ä»‹ç»äº†<code>BFS-Prover-V2</code>ç³»ç»Ÿï¼Œè¯¥ç³»ç»Ÿæ—¨åœ¨è§£å†³è¿™ä¸€åŒé‡æ‰©å±•é—®é¢˜ã€‚æˆ‘ä»¬æå‡ºäº†ä¸¤ä¸ªä¸»è¦çš„åˆ›æ–°ç‚¹ã€‚ç¬¬ä¸€ä¸ªæ˜¯æ–°å‹çš„å¤šè½®ç¦»çº¿ç­–ç•¥å¼ºåŒ–å­¦ä¹ æ¡†æ¶ï¼Œæ—¨åœ¨ä¸æ–­æé«˜è®­ç»ƒæ—¶LLMé€æ­¥è¯æ˜çš„æ€§èƒ½ã€‚è¯¥æ¡†æ¶å—åˆ°AlphaZeroåŸåˆ™çš„å¯å‘ï¼Œé‡‡ç”¨å¤šé˜¶æ®µä¸“å®¶è¿­ä»£ç®¡é“ï¼Œå…·æœ‰è‡ªé€‚åº”æˆ˜æœ¯çº§æ•°æ®è¿‡æ»¤å’Œå®šæœŸé‡æ–°è®­ç»ƒçš„åŠŸèƒ½ï¼Œä»¥å…‹æœæ€§èƒ½ç“¶é¢ˆï¼Œè¿™äº›ç“¶é¢ˆé€šå¸¸ä¼šé™åˆ¶åŸºäºLLMçš„ä»£ç†çš„é•¿æœŸå¼ºåŒ–å­¦ä¹ ã€‚ç¬¬äºŒä¸ªåˆ›æ–°ç‚¹æ˜¯ä¸€ä¸ªå¢å¼ºè§„åˆ’çš„å¤šä»£ç†æœç´¢æ¶æ„ï¼Œè¯¥æ¶æ„åœ¨æ¨ç†æ—¶é—´æ‰©å±•äº†æ¨ç†èƒ½åŠ›ã€‚è¯¥æ¶æ„é‡‡ç”¨é€šç”¨æ¨ç†æ¨¡å‹ä½œä¸ºé«˜çº§è§„åˆ’å™¨ï¼Œå°†å¤æ‚çš„å®šç†è¿­ä»£åœ°åˆ†è§£ä¸ºä¸€ç³»åˆ—æ›´ç®€å•çš„å­ç›®æ ‡ã€‚è¿™ç§åˆ†å±‚æ–¹æ³•å¤§å¤§å‡å°‘äº†æœç´¢ç©ºé—´ï¼Œä½¿ä¸€ç»„å¹¶è¡Œè¯æ˜ä»£ç†èƒ½å¤Ÿé«˜æ•ˆåœ°åä½œï¼Œåˆ©ç”¨å…±äº«è¯æ˜ç¼“å­˜ã€‚æˆ‘ä»¬è¯æ˜äº†è¿™ç§åŒé‡æ‰©å±•æ–¹æ³•åœ¨ä¸€ç³»åˆ—æ­£å¼çš„æ•°å­¦åŸºå‡†æµ‹è¯•ä¸Šè¾¾åˆ°äº†æœ€æ–°æ°´å¹³çš„ç»“æœã€‚<code>BFS-Prover-V2</code>åœ¨MiniF2Få’ŒProofNetæµ‹è¯•é›†ä¸Šåˆ†åˆ«è¾¾åˆ°äº†95.08%å’Œ41.4%çš„å‡†ç¡®ç‡ã€‚è™½ç„¶æœ¬å·¥ä½œåœ¨å½¢å¼æ•°å­¦é¢†åŸŸå¾—åˆ°äº†éªŒè¯ï¼Œä½†æœ¬å·¥ä½œä¸­æå‡ºçš„å¼ºåŒ–å­¦ä¹ å’Œæ¨ç†æŠ€æœ¯å…·æœ‰æ›´å¹¿æ³›çš„å…´è¶£ï¼Œå¹¶å¯åº”ç”¨äºéœ€è¦é•¿å‘¨æœŸå¤šè½®æ¨ç†å’Œå¤æ‚æœç´¢çš„å…¶ä»–é¢†åŸŸã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2509.06493v2">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨è‡ªåŠ¨åŒ–å®šç†è¯æ˜ä¸­çš„åº”ç”¨å±•ç°å‡ºå·¨å¤§çš„æ½œåŠ›ï¼Œä½†é¢ä¸´ç€è®­ç»ƒæ—¶å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰å’Œæ¨ç†æ—¶è®¡ç®—æ‰©å±•çš„åŒé‡æŒ‘æˆ˜ã€‚æœ¬æ–‡ä»‹ç»äº†\texttt{BFS-Prover-V2}ï¼Œä¸€ä¸ªæ—¨åœ¨è§£å†³è¿™ä¸€åŒé‡æ‰©å±•é—®é¢˜çš„ç³»ç»Ÿã€‚ä¸»è¦åˆ›æ–°åŒ…æ‹¬è®­ç»ƒæ—¶çš„æ–°å‹å¤šè½®ç¦»çº¿RLæ¡†æ¶å’Œæ¨ç†æ—¶çš„è§„åˆ’å¢å¼ºå¤šæ™ºèƒ½ä½“æœç´¢æ¶æ„ã€‚è®­ç»ƒæ—¶çš„RLæ¡†æ¶çµæ„Ÿæ¥æºäºAlphaZeroï¼Œåˆ©ç”¨å¤šé˜¶æ®µä¸“å®¶è¿­ä»£ç®¡é“ã€è‡ªé€‚åº”æˆ˜æœ¯çº§æ•°æ®è¿‡æ»¤å’Œå®šæœŸå†è®­ç»ƒï¼Œå…‹æœäº†æ€§èƒ½ç“¶é¢ˆï¼Œæé«˜äº†LLMæ­¥éª¤è¯æ˜çš„æ€§èƒ½ã€‚æ¨ç†æ—¶çš„æ¶æ„é‡‡ç”¨é€šç”¨æ¨ç†æ¨¡å‹ä½œä¸ºé«˜çº§è§„åˆ’å™¨ï¼Œå°†å¤æ‚å®šç†åˆ†è§£ä¸ºä¸€ç³»åˆ—ç®€å•å­ç›®æ ‡ã€‚é€šè¿‡é‡‡ç”¨åˆ†å±‚æ–¹æ³•ï¼Œæ˜¾è‘—å‡å°‘äº†æœç´¢ç©ºé—´ï¼Œä½¿ä¸€ç»„å¹¶è¡Œè¯æ˜æ™ºèƒ½ä½“èƒ½å¤Ÿé€šè¿‡å…±äº«è¯æ˜ç¼“å­˜è¿›è¡Œæœ‰æ•ˆåä½œã€‚åœ¨å½¢å¼æ•°å­¦åŸºå‡†æµ‹è¯•ä¸­å–å¾—äº†æœ€æ–°ç»“æœã€‚\texttt{BFS-Prover-V2}åœ¨MiniF2Få’ŒProofNetæµ‹è¯•é›†ä¸Šçš„å‡†ç¡®ç‡åˆ†åˆ«è¾¾åˆ°95.08%å’Œ41.4%ã€‚è™½ç„¶æ­¤å·¥ä½œå±•ç¤ºçš„æ˜¯åœ¨å½¢å¼æ•°å­¦é¢†åŸŸçš„åº”ç”¨ï¼Œä½†æå‡ºçš„RLå’Œæ¨ç†æŠ€æœ¯å…·æœ‰æ›´å¹¿æ³›çš„åº”ç”¨å‰æ™¯ï¼Œå¯åº”ç”¨äºéœ€è¦é•¿å‘¨æœŸå¤šè½®æ¨ç†å’Œå¤æ‚æœç´¢çš„å…¶ä»–é¢†åŸŸã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ol>
<li><strong>LLMåœ¨è‡ªåŠ¨åŒ–å®šç†è¯æ˜ä¸­çš„æ½œåŠ›ä¸æŒ‘æˆ˜</strong>ï¼šå¤§å‹è¯­è¨€æ¨¡å‹åœ¨è‡ªåŠ¨åŒ–å®šç†è¯æ˜ä¸­å±•ç°å‡ºå·¨å¤§æ½œåŠ›ï¼Œä½†é¢ä¸´è®­ç»ƒå¼ºåŒ–å­¦ä¹ å’Œæ¨ç†è®¡ç®—æ‰©å±•çš„åŒé‡æŒ‘æˆ˜ã€‚</li>
<li><strong>è®­ç»ƒæ—¶é—´çš„æ–°å‹å¤šè½®ç¦»çº¿RLæ¡†æ¶</strong>ï¼šå¼•å…¥äº†ä¸€ç§æ–°å‹çš„å¤šè½®ç¦»çº¿å¼ºåŒ–å­¦ä¹ æ¡†æ¶ï¼Œä»¥æé«˜LLMçš„æ€§èƒ½ï¼Œé€šè¿‡å¤šé˜¶æ®µä¸“å®¶è¿­ä»£ç®¡é“ç­‰æ–¹æ³•å…‹æœæ€§èƒ½ç“¶é¢ˆã€‚</li>
<li><strong>æ¨ç†æ—¶é—´çš„è§„åˆ’å¢å¼ºå¤šæ™ºèƒ½ä½“æœç´¢æ¶æ„</strong>ï¼šé‡‡ç”¨é€šç”¨æ¨ç†æ¨¡å‹ä½œä¸ºé«˜çº§è§„åˆ’å™¨ï¼Œå°†å¤æ‚å®šç†åˆ†è§£ä¸ºç®€å•å­ç›®æ ‡ï¼Œå‡å°‘æœç´¢ç©ºé—´ï¼Œæé«˜æ¨ç†æ•ˆç‡ã€‚</li>
<li><strong>BFS-Prover-V2ç³»ç»Ÿçš„åˆ›æ–°åº”ç”¨</strong>ï¼šç³»ç»Ÿ\texttt{BFS-Prover-V2}é€šè¿‡ç»“åˆä¸Šè¿°ä¸¤é¡¹åˆ›æ–°ï¼Œå®ç°äº†åœ¨å½¢å¼æ•°å­¦é¢†åŸŸçš„å…ˆè¿›ç»“æœã€‚</li>
<li><strong>åœ¨MiniF2Få’ŒProofNetæµ‹è¯•é›†ä¸Šçš„è¡¨ç°</strong>ï¼š\texttt{BFS-Prover-V2}åœ¨MiniF2Fæµ‹è¯•é›†ä¸Šè¾¾åˆ°95.08%çš„å‡†ç¡®ç‡ï¼Œåœ¨ProofNetæµ‹è¯•é›†ä¸Šè¾¾åˆ°41.4%çš„å‡†ç¡®ç‡ã€‚</li>
<li><strong>RLå’Œæ¨ç†æŠ€æœ¯çš„åº”ç”¨å¹¿æ³›æ€§</strong>ï¼šè™½ç„¶å·¥ä½œé›†ä¸­åœ¨å½¢å¼æ•°å­¦é¢†åŸŸï¼Œä½†æå‡ºçš„RLå’Œæ¨ç†æŠ€æœ¯å¯åº”ç”¨äºéœ€è¦é•¿å‘¨æœŸå¤šè½®æ¨ç†å’Œå¤æ‚æœç´¢çš„å…¶ä»–é¢†åŸŸã€‚</li>
</ol>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2509.06493">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-2077e21fd42b0dc8a812878ce7c79d2d" align="middle">
<img src="https://picx.zhimg.com/v2-84858c4f548f5303404a32f3ae383431" align="middle">
<img src="https://picx.zhimg.com/v2-bf9d216a016536e180306c0133831217" align="middle">
<img src="https://picx.zhimg.com/v2-67fc817e10239aa01fd578650e9e33d4" align="middle">
</details>


<h1 id="-14"><a href="#-14" class="headerlink" title=""></a></h1><h2 id="CoCoA-Collaborative-Chain-of-Agents-for-Parametric-Retrieved-Knowledge-Synergy"><a href="#CoCoA-Collaborative-Chain-of-Agents-for-Parametric-Retrieved-Knowledge-Synergy" class="headerlink" title="CoCoA: Collaborative Chain-of-Agents for Parametric-Retrieved Knowledge   Synergy"></a>CoCoA: Collaborative Chain-of-Agents for Parametric-Retrieved Knowledge   Synergy</h2><p><strong>Authors:Yi Jiang, Sendong Zhao, Jianbo Li, Haochun Wang, Lizhe Zhang, Yan Liu, Bing Qin</strong></p>
<p>Retrieval-Augmented Generation (RAG) enhances Large Language Models (LLMs), especially for knowledge-intensive tasks. Despite its advantages, current RAG methods often struggle to fully exploit knowledge during generation. In particular, the synergy between the modelâ€™s internal parametric knowledge and external retrieved knowledge remains limited. Retrieved contents may sometimes mislead generation, while certain generated content can guide the model toward more accurate outputs. In this work, we propose Collaborative Chain-of-Agents, a framework designed to enhance explicitly synergy over both parametric and retrieved knowledge. Specifically, we first introduce CoCoA-zero, a multi-agent RAG framework that first performs conditional knowledge induction and then reasons answers. Building on this, we develop CoCoA, a long-chain training strategy that synthesizes extended multi-agent reasoning trajectories from CoCoA-zero to fine-tune the LLM. This strategy enhances the modelâ€™s capability to explicitly integrate and jointly leverage parametric and retrieved knowledge. Experimental results demonstrate the superiority of CoCoA in open-domain QA and multi-hop QA. </p>
<blockquote>
<p>æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰æŠ€æœ¯æé«˜äº†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„æ€§èƒ½ï¼Œç‰¹åˆ«æ˜¯å¯¹äºçŸ¥è¯†å¯†é›†å‹ä»»åŠ¡ã€‚å°½ç®¡å…·æœ‰ä¼˜åŠ¿ï¼Œä½†å½“å‰çš„RAGæ–¹æ³•å¾€å¾€éš¾ä»¥åœ¨ç”Ÿæˆè¿‡ç¨‹ä¸­å……åˆ†åˆ©ç”¨çŸ¥è¯†ã€‚ç‰¹åˆ«æ˜¯ï¼Œæ¨¡å‹å†…éƒ¨çš„å‚æ•°çŸ¥è¯†ä¸å¤–éƒ¨æ£€ç´¢çŸ¥è¯†ä¹‹é—´çš„ååŒä½œç”¨ä»ç„¶æœ‰é™ã€‚æ£€ç´¢çš„å†…å®¹æœ‰æ—¶ä¼šè¯¯å¯¼ç”Ÿæˆï¼Œè€ŒæŸäº›ç”Ÿæˆçš„å†…å®¹å¯ä»¥å¼•å¯¼æ¨¡å‹èµ°å‘æ›´å‡†ç¡®çš„è¾“å‡ºã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†åä½œä»£ç†é“¾ï¼ˆCollaborative Chain-of-Agentsï¼‰æ¡†æ¶ï¼Œè¯¥æ¡†æ¶æ—¨åœ¨å¢å¼ºå‚æ•°çŸ¥è¯†å’Œæ£€ç´¢çŸ¥è¯†ä¹‹é—´çš„æ˜ç¡®ååŒã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬é¦–å…ˆå¼•å…¥äº†CoCoA-zeroå¤šä»£ç†RAGæ¡†æ¶ï¼Œå…ˆè¿›è¡Œæ¡ä»¶çŸ¥è¯†å½’çº³ï¼Œç„¶åæ¨ç†ç­”æ¡ˆã€‚åœ¨æ­¤åŸºç¡€ä¸Šï¼Œæˆ‘ä»¬å¼€å‘äº†CoCoAé•¿æœŸè®­ç»ƒç­–ç•¥ï¼Œè¯¥ç­–ç•¥é€šè¿‡åˆæˆæ¥è‡ªCoCoA-zeroçš„æ‰©å±•å¤šä»£ç†æ¨ç†è½¨è¿¹æ¥å¾®è°ƒLLMã€‚è¿™ä¸€ç­–ç•¥æé«˜äº†æ¨¡å‹æ˜¾å¼é›†æˆå’Œè”åˆåˆ©ç”¨å‚æ•°çŸ¥è¯†å’Œæ£€ç´¢çŸ¥è¯†çš„èƒ½åŠ›ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒCoCoAåœ¨å¼€æ”¾åŸŸé—®ç­”å’Œå¤šè·³é—®ç­”æ–¹é¢çš„ä¼˜è¶Šæ€§ã€‚</p>
</blockquote>
<p><strong>è®ºæ–‡åŠé¡¹ç›®ç›¸å…³é“¾æ¥</strong></p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2508.01696v3">PDF</a> code available at <a target="_blank" rel="noopener" href="https://github.com/liunian-Jay/CoCoA">https://github.com/liunian-Jay/CoCoA</a></p>
<p><strong>Summary</strong></p>
<p>RAGï¼ˆRetrieval-Augmented Generationï¼‰æ¨¡å‹æé«˜äº†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨å¤„ç†çŸ¥è¯†å¯†é›†å‹ä»»åŠ¡æ—¶çš„æ€§èƒ½ã€‚ç„¶è€Œï¼Œå½“å‰RAGæ–¹æ³•éš¾ä»¥å……åˆ†åˆ©ç”¨çŸ¥è¯†ç”Ÿæˆè¿‡ç¨‹ä¸­çš„çŸ¥è¯†ã€‚æœ¬æ–‡æå‡ºäº†Collaborative Chain-of-Agentsæ¡†æ¶ï¼Œæ—¨åœ¨å¢å¼ºæ¨¡å‹å†…éƒ¨å‚æ•°çŸ¥è¯†å’Œå¤–éƒ¨æ£€ç´¢çŸ¥è¯†çš„ååŒä½œç”¨ã€‚é€šè¿‡å¼•å…¥CoCoA-zeroè¿›è¡Œæ¡ä»¶çŸ¥è¯†å½’çº³ï¼Œå¹¶ç»“åˆCoCoAè¿›è¡Œé•¿æœŸè®­ç»ƒç­–ç•¥ï¼Œåˆæˆå¤šæ™ºèƒ½ä½“æ¨ç†è½¨è¿¹ä»¥å¾®è°ƒLLMã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒCoCoAåœ¨å¼€æ”¾åŸŸé—®ç­”å’Œå¤šè·³é—®ç­”ä¸­è¡¨ç°ä¼˜å¼‚ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>RAGæ¨¡å‹å¢å¼ºäº†å¤§å‹è¯­è¨€æ¨¡å‹åœ¨çŸ¥è¯†å¯†é›†å‹ä»»åŠ¡ä¸Šçš„æ€§èƒ½ã€‚</li>
<li>å½“å‰RAGæ–¹æ³•éš¾ä»¥å……åˆ†åˆ©ç”¨ç”Ÿæˆè¿‡ç¨‹ä¸­çš„çŸ¥è¯†ã€‚</li>
<li>Collaborative Chain-of-Agentsæ¡†æ¶æ—¨åœ¨å¢å¼ºæ¨¡å‹å†…éƒ¨å‚æ•°çŸ¥è¯†å’Œå¤–éƒ¨æ£€ç´¢çŸ¥è¯†çš„ååŒä½œç”¨ã€‚</li>
<li>CoCoA-zeroé€šè¿‡æ¡ä»¶çŸ¥è¯†å½’çº³è¿›è¡Œæ¨ç†ç­”æ¡ˆã€‚</li>
<li>CoCoAæ˜¯ä¸€ç§é•¿æœŸè®­ç»ƒç­–ç•¥ï¼Œåˆæˆå¤šæ™ºèƒ½ä½“æ¨ç†è½¨è¿¹ä»¥å¾®è°ƒLLMã€‚</li>
<li>CoCoAåœ¨å¼€æ”¾åŸŸé—®ç­”å’Œå¤šè·³é—®ç­”ä»»åŠ¡ä¸­è¡¨ç°ä¼˜è¶Šã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://papers.cool/arxiv/2508.01696">Cool Papers</a></strong> </p>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-f86fc0c5bba386638d48b9283b1f0cbd" align="middle">
<img src="https://picx.zhimg.com/v2-9e677ae400e70fea1dac398b99f1224b" align="middle">
<img src="https://picx.zhimg.com/v2-34504f880fcf22b7b21ede0a7f221329" align="middle">
</details>


<h1 id="-15"><a href="#-15" class="headerlink" title=""></a></h1>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Talk2Paper/about" rel="external nofollow noreferrer">Kedreamix</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kedreamix.github.io/Talk2Paper/Paper/2025-10-11/Agent/">https://kedreamix.github.io/Talk2Paper/Paper/2025-10-11/Agent/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Talk2Paper/tags/Agent/">
                                    <span class="chip bg-color">Agent</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Talk2Paper/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/Talk2Paper/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-10-11/Few-Shot/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-97c53b7e373b1b8878a6fb5bcb713222" class="responsive-img" alt="Few-Shot">
                        
                        <span class="card-title">Few-Shot</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Few-Shot æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-10-11  The Visual Iconicity Challenge Evaluating Vision-Language Models on   Sign Language Form-Meaning Mapping
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-10-11
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/Few-Shot/" class="post-category">
                                    Few-Shot
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/Few-Shot/">
                        <span class="chip bg-color">Few-Shot</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Talk2Paper/Paper/2025-10-11/LLM/">
                    <div class="card-image">
                        
                        <img src="https://picx.zhimg.com/v2-a7ef7465fa414c8bad36ed951b897930" class="responsive-img" alt="LLM">
                        
                        <span class="card-title">LLM</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            LLM æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2025-10-11  NaViL Rethinking Scaling Properties of Native Multimodal Large Language   Models under Data Constraints
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-10-11
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Talk2Paper/categories/LLM/" class="post-category">
                                    LLM
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Talk2Paper/tags/LLM/">
                        <span class="chip bg-color">LLM</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeBlockFuction.js"></script>



<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/Talk2Paper/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Talk2Paper/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Talk2Paper/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Talk2Paper/libs/aplayer/APlayer.min.js"></script>
<script src="/Talk2Paper/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2024-2025</span>
            
            <a href="/Talk2Paper/about" target="_blank">Kedreamix</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                        class="white-color">32883.8k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2024";
                        var startMonth = "1";
                        var startDate = "1";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Kedreamix" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:kedreamix@gmail.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>











    <a href="https://www.zhihu.com/people/kedreamix" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/kedreamix" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Talk2Paper/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Talk2Paper/libs/materialize/materialize.min.js"></script>
    <script src="/Talk2Paper/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Talk2Paper/libs/aos/aos.js"></script>
    <script src="/Talk2Paper/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Talk2Paper/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Talk2Paper/js/matery.js"></script>

    

    
    
    
        
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/Talk2Paper/libs/others/sakura-reduce.js"><\/script>');
            }
        </script>
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/Talk2Paper/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Talk2Paper/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Talk2Paper/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    

    

    

    
    <script src="/Talk2Paper/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/Talk2Paper/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>

<!-- åŠ¨æ€æ ‡ç­¾ -->
<script type="text/javascript"> var OriginTitile = document.title, st; 
    document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Î£(ã£ Â°Ğ” Â°;)ã£è¯¶ï¼Œé¡µé¢å´©æºƒäº†å˜›ï¼Ÿ", clearTimeout(st)) : (document.title = "Ï†(ã‚œâ–½ã‚œ*)â™ªå’¦ï¼Œåˆå¥½äº†ï¼", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>
